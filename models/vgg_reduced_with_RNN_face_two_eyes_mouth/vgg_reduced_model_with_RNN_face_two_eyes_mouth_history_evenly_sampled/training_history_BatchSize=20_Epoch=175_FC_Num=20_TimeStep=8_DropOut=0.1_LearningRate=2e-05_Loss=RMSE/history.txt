Epoch: 1| Step: 0
Training loss: 5.08513432268135
Validation loss: 5.767938105820032

Epoch: 5| Step: 1
Training loss: 5.996311961623851
Validation loss: 5.742712802450377

Epoch: 5| Step: 2
Training loss: 6.499950702186854
Validation loss: 5.7233814295623295

Epoch: 5| Step: 3
Training loss: 5.983857373990929
Validation loss: 5.70278905490702

Epoch: 5| Step: 4
Training loss: 6.619719794298645
Validation loss: 5.678449676033672

Epoch: 5| Step: 5
Training loss: 5.604487848354959
Validation loss: 5.651057714041883

Epoch: 5| Step: 6
Training loss: 5.040475289474082
Validation loss: 5.620783862174745

Epoch: 5| Step: 7
Training loss: 6.047854637417473
Validation loss: 5.5871273380728

Epoch: 5| Step: 8
Training loss: 5.199777253588703
Validation loss: 5.54969930191739

Epoch: 5| Step: 9
Training loss: 5.212543748996748
Validation loss: 5.508153649566853

Epoch: 5| Step: 10
Training loss: 4.729333188434344
Validation loss: 5.4640477088060075

Epoch: 2| Step: 0
Training loss: 5.621181124179771
Validation loss: 5.414486512428135

Epoch: 5| Step: 1
Training loss: 4.857010931739812
Validation loss: 5.362445046813331

Epoch: 5| Step: 2
Training loss: 6.290011695644743
Validation loss: 5.3084116656876414

Epoch: 5| Step: 3
Training loss: 5.04800015122161
Validation loss: 5.2513666342102

Epoch: 5| Step: 4
Training loss: 5.242376150724829
Validation loss: 5.192036267896138

Epoch: 5| Step: 5
Training loss: 4.508736500837499
Validation loss: 5.128153875247073

Epoch: 5| Step: 6
Training loss: 5.343875995065264
Validation loss: 5.059808844002353

Epoch: 5| Step: 7
Training loss: 4.809637233830107
Validation loss: 4.9881981484529225

Epoch: 5| Step: 8
Training loss: 5.662931595074082
Validation loss: 4.9161411141472735

Epoch: 5| Step: 9
Training loss: 4.906653320840294
Validation loss: 4.845783525790652

Epoch: 5| Step: 10
Training loss: 4.295617935794265
Validation loss: 4.775838196782113

Epoch: 3| Step: 0
Training loss: 5.453636517075187
Validation loss: 4.713356513266197

Epoch: 5| Step: 1
Training loss: 3.9342509594816923
Validation loss: 4.651146545796739

Epoch: 5| Step: 2
Training loss: 4.829521693206922
Validation loss: 4.593857996713826

Epoch: 5| Step: 3
Training loss: 4.7433913586611105
Validation loss: 4.542684753472499

Epoch: 5| Step: 4
Training loss: 3.860096852367277
Validation loss: 4.492614071831171

Epoch: 5| Step: 5
Training loss: 4.9018213974078
Validation loss: 4.451494276345573

Epoch: 5| Step: 6
Training loss: 5.338365128242133
Validation loss: 4.413983277294077

Epoch: 5| Step: 7
Training loss: 3.5722279825620613
Validation loss: 4.381269521039134

Epoch: 5| Step: 8
Training loss: 4.169877963761771
Validation loss: 4.3517016552448435

Epoch: 5| Step: 9
Training loss: 5.038893491291232
Validation loss: 4.325671513930225

Epoch: 5| Step: 10
Training loss: 4.069258716382444
Validation loss: 4.2973184372046465

Epoch: 4| Step: 0
Training loss: 4.399891262444776
Validation loss: 4.267460626388972

Epoch: 5| Step: 1
Training loss: 4.601546956215788
Validation loss: 4.237337538576308

Epoch: 5| Step: 2
Training loss: 4.6154443125654305
Validation loss: 4.204031524507379

Epoch: 5| Step: 3
Training loss: 3.88239419629622
Validation loss: 4.172051612551032

Epoch: 5| Step: 4
Training loss: 3.566503985132269
Validation loss: 4.14172623041578

Epoch: 5| Step: 5
Training loss: 4.214433510430883
Validation loss: 4.114692585394093

Epoch: 5| Step: 6
Training loss: 4.47346599861578
Validation loss: 4.091309604779493

Epoch: 5| Step: 7
Training loss: 4.400850274553553
Validation loss: 4.066931559849998

Epoch: 5| Step: 8
Training loss: 4.485796659856974
Validation loss: 4.04671524929199

Epoch: 5| Step: 9
Training loss: 4.138316997527072
Validation loss: 4.023870705861214

Epoch: 5| Step: 10
Training loss: 4.00870996134657
Validation loss: 4.003731883824558

Epoch: 5| Step: 0
Training loss: 3.7001134803484144
Validation loss: 3.982326462711491

Epoch: 5| Step: 1
Training loss: 3.415996082527005
Validation loss: 3.96159063403503

Epoch: 5| Step: 2
Training loss: 4.231240326322375
Validation loss: 3.9444418735333047

Epoch: 5| Step: 3
Training loss: 4.193457621403818
Validation loss: 3.9269802462631196

Epoch: 5| Step: 4
Training loss: 4.4780792808994025
Validation loss: 3.9253707711142143

Epoch: 5| Step: 5
Training loss: 5.078321811089977
Validation loss: 3.899333323777154

Epoch: 5| Step: 6
Training loss: 3.4934107197739075
Validation loss: 3.8951738470672512

Epoch: 5| Step: 7
Training loss: 4.343655152966292
Validation loss: 3.894500974875516

Epoch: 5| Step: 8
Training loss: 4.10939542235895
Validation loss: 3.879937161620865

Epoch: 5| Step: 9
Training loss: 3.452875326805319
Validation loss: 3.8677235990475856

Epoch: 5| Step: 10
Training loss: 4.0126314991351455
Validation loss: 3.856086475423773

Epoch: 6| Step: 0
Training loss: 3.504444025760363
Validation loss: 3.8514402067632947

Epoch: 5| Step: 1
Training loss: 4.231561267847814
Validation loss: 3.8492570056528317

Epoch: 5| Step: 2
Training loss: 4.2238799376764105
Validation loss: 3.828322321829131

Epoch: 5| Step: 3
Training loss: 3.7984281903070047
Validation loss: 3.8143942309912133

Epoch: 5| Step: 4
Training loss: 4.079947462678628
Validation loss: 3.810886556062389

Epoch: 5| Step: 5
Training loss: 3.0156452395693862
Validation loss: 3.800737489303525

Epoch: 5| Step: 6
Training loss: 4.4685508843724255
Validation loss: 3.8005216530281953

Epoch: 5| Step: 7
Training loss: 4.541926991879168
Validation loss: 3.784132408436874

Epoch: 5| Step: 8
Training loss: 3.923157015079287
Validation loss: 3.770176545395718

Epoch: 5| Step: 9
Training loss: 3.0597398737127306
Validation loss: 3.755486301394323

Epoch: 5| Step: 10
Training loss: 4.630065412285867
Validation loss: 3.7442700338237054

Epoch: 7| Step: 0
Training loss: 4.115633184356778
Validation loss: 3.733086693508315

Epoch: 5| Step: 1
Training loss: 4.322173395564797
Validation loss: 3.721784661053365

Epoch: 5| Step: 2
Training loss: 4.30209022995563
Validation loss: 3.7164443656767934

Epoch: 5| Step: 3
Training loss: 3.6957793313904723
Validation loss: 3.6965550847484585

Epoch: 5| Step: 4
Training loss: 4.301798049790534
Validation loss: 3.684062201348993

Epoch: 5| Step: 5
Training loss: 3.8778219714799538
Validation loss: 3.671503053501888

Epoch: 5| Step: 6
Training loss: 3.643452213740902
Validation loss: 3.662974563176478

Epoch: 5| Step: 7
Training loss: 4.255386305238518
Validation loss: 3.6542038648573536

Epoch: 5| Step: 8
Training loss: 2.9360495699717917
Validation loss: 3.6395081126267526

Epoch: 5| Step: 9
Training loss: 3.151378838441044
Validation loss: 3.6278444077558647

Epoch: 5| Step: 10
Training loss: 3.673072911727749
Validation loss: 3.652527526790823

Epoch: 8| Step: 0
Training loss: 3.8502710123166826
Validation loss: 3.600377690933192

Epoch: 5| Step: 1
Training loss: 2.9416834484050316
Validation loss: 3.5966439699267716

Epoch: 5| Step: 2
Training loss: 4.647447907072245
Validation loss: 3.598954715652444

Epoch: 5| Step: 3
Training loss: 3.285726636069644
Validation loss: 3.5943892428936306

Epoch: 5| Step: 4
Training loss: 3.2608284654653277
Validation loss: 3.587359165604269

Epoch: 5| Step: 5
Training loss: 4.349170842565542
Validation loss: 3.5781756201032615

Epoch: 5| Step: 6
Training loss: 3.7463546837075765
Validation loss: 3.5726409641185697

Epoch: 5| Step: 7
Training loss: 3.335697353036496
Validation loss: 3.559963956463536

Epoch: 5| Step: 8
Training loss: 3.8407552574423174
Validation loss: 3.550304133368726

Epoch: 5| Step: 9
Training loss: 3.783543167232988
Validation loss: 3.5348749455288075

Epoch: 5| Step: 10
Training loss: 4.181860927318087
Validation loss: 3.5284434135120715

Epoch: 9| Step: 0
Training loss: 3.6707368425958204
Validation loss: 3.5155114027696124

Epoch: 5| Step: 1
Training loss: 4.259767639915273
Validation loss: 3.5113389794936865

Epoch: 5| Step: 2
Training loss: 4.138676944457726
Validation loss: 3.5029508483248115

Epoch: 5| Step: 3
Training loss: 3.8992695197665883
Validation loss: 3.4883172554780035

Epoch: 5| Step: 4
Training loss: 3.3637573047049716
Validation loss: 3.480516805563686

Epoch: 5| Step: 5
Training loss: 3.282038711942541
Validation loss: 3.4778263417669915

Epoch: 5| Step: 6
Training loss: 3.4321649939973033
Validation loss: 3.474538165665743

Epoch: 5| Step: 7
Training loss: 3.945293766392714
Validation loss: 3.4682743389737043

Epoch: 5| Step: 8
Training loss: 3.321766254586536
Validation loss: 3.461258007506875

Epoch: 5| Step: 9
Training loss: 3.8977250726786132
Validation loss: 3.4528364377309453

Epoch: 5| Step: 10
Training loss: 3.2193625154366106
Validation loss: 3.4488203688968593

Epoch: 10| Step: 0
Training loss: 4.21096603582052
Validation loss: 3.4431072528535496

Epoch: 5| Step: 1
Training loss: 3.6799474409745256
Validation loss: 3.437719008105644

Epoch: 5| Step: 2
Training loss: 3.50990447129021
Validation loss: 3.4341344920306374

Epoch: 5| Step: 3
Training loss: 4.151861871586339
Validation loss: 3.4310304261216467

Epoch: 5| Step: 4
Training loss: 3.391133213190613
Validation loss: 3.4249845400967986

Epoch: 5| Step: 5
Training loss: 3.067758211120057
Validation loss: 3.4189283302227174

Epoch: 5| Step: 6
Training loss: 3.88058045243584
Validation loss: 3.4126923649427168

Epoch: 5| Step: 7
Training loss: 3.346323609367211
Validation loss: 3.407801242993766

Epoch: 5| Step: 8
Training loss: 3.90332971895758
Validation loss: 3.4019353340370455

Epoch: 5| Step: 9
Training loss: 2.9458094817566898
Validation loss: 3.396138423942131

Epoch: 5| Step: 10
Training loss: 3.787843740243318
Validation loss: 3.392358049589266

Epoch: 11| Step: 0
Training loss: 3.9168982065358513
Validation loss: 3.3857608369692906

Epoch: 5| Step: 1
Training loss: 3.443828790943738
Validation loss: 3.377797005760928

Epoch: 5| Step: 2
Training loss: 3.8792816625828253
Validation loss: 3.3709753415881236

Epoch: 5| Step: 3
Training loss: 3.857563782990989
Validation loss: 3.36495993548002

Epoch: 5| Step: 4
Training loss: 3.1602670015937426
Validation loss: 3.363909399229525

Epoch: 5| Step: 5
Training loss: 2.67472161243755
Validation loss: 3.361088425343257

Epoch: 5| Step: 6
Training loss: 4.122889817073164
Validation loss: 3.3569931205774255

Epoch: 5| Step: 7
Training loss: 3.1370984675403393
Validation loss: 3.3497362317372277

Epoch: 5| Step: 8
Training loss: 3.352476622224751
Validation loss: 3.3482264632840066

Epoch: 5| Step: 9
Training loss: 4.424886048999551
Validation loss: 3.344651646647471

Epoch: 5| Step: 10
Training loss: 3.1249548336579753
Validation loss: 3.3380785235233286

Epoch: 12| Step: 0
Training loss: 4.157589345259866
Validation loss: 3.3326868281426227

Epoch: 5| Step: 1
Training loss: 3.6322376739862037
Validation loss: 3.3313525703349516

Epoch: 5| Step: 2
Training loss: 2.4127261712981927
Validation loss: 3.32805636747912

Epoch: 5| Step: 3
Training loss: 3.8985634823550264
Validation loss: 3.3277849894813825

Epoch: 5| Step: 4
Training loss: 3.3335321049234947
Validation loss: 3.324259069683194

Epoch: 5| Step: 5
Training loss: 3.1420376006364843
Validation loss: 3.322311976408601

Epoch: 5| Step: 6
Training loss: 3.900293309846329
Validation loss: 3.3203305340831504

Epoch: 5| Step: 7
Training loss: 3.859125909218709
Validation loss: 3.3186235222109324

Epoch: 5| Step: 8
Training loss: 3.875263451265143
Validation loss: 3.3149954199274814

Epoch: 5| Step: 9
Training loss: 3.194666267838663
Validation loss: 3.3116187070455667

Epoch: 5| Step: 10
Training loss: 3.4170639148301962
Validation loss: 3.30967750189707

Epoch: 13| Step: 0
Training loss: 4.02067325780707
Validation loss: 3.3063697192027113

Epoch: 5| Step: 1
Training loss: 3.3109262434735207
Validation loss: 3.304706124366432

Epoch: 5| Step: 2
Training loss: 3.9512270265012126
Validation loss: 3.3033151241221264

Epoch: 5| Step: 3
Training loss: 3.7977224903337032
Validation loss: 3.3010176371381985

Epoch: 5| Step: 4
Training loss: 3.2938956588590047
Validation loss: 3.2993419184952666

Epoch: 5| Step: 5
Training loss: 3.3648364716879144
Validation loss: 3.297757149938929

Epoch: 5| Step: 6
Training loss: 4.013139601263394
Validation loss: 3.2947770573107844

Epoch: 5| Step: 7
Training loss: 2.981943308188389
Validation loss: 3.2930170692415075

Epoch: 5| Step: 8
Training loss: 3.4809482299847527
Validation loss: 3.289276512821268

Epoch: 5| Step: 9
Training loss: 3.436526906390335
Validation loss: 3.2882797638389762

Epoch: 5| Step: 10
Training loss: 3.0608555017989767
Validation loss: 3.2855628012511615

Epoch: 14| Step: 0
Training loss: 3.454698161122104
Validation loss: 3.2828494750520476

Epoch: 5| Step: 1
Training loss: 2.682898285549008
Validation loss: 3.28008215728935

Epoch: 5| Step: 2
Training loss: 3.370282302034973
Validation loss: 3.2755236715106464

Epoch: 5| Step: 3
Training loss: 3.4319176863289282
Validation loss: 3.2752921460631472

Epoch: 5| Step: 4
Training loss: 3.1974507012045237
Validation loss: 3.2733177472308164

Epoch: 5| Step: 5
Training loss: 3.952439561607385
Validation loss: 3.270771242086265

Epoch: 5| Step: 6
Training loss: 3.6815478892498255
Validation loss: 3.267069198195918

Epoch: 5| Step: 7
Training loss: 3.8207700490477303
Validation loss: 3.2643819127792977

Epoch: 5| Step: 8
Training loss: 3.814774882022882
Validation loss: 3.264309373515131

Epoch: 5| Step: 9
Training loss: 3.568941282901463
Validation loss: 3.2574509385873585

Epoch: 5| Step: 10
Training loss: 3.5613256827895543
Validation loss: 3.255268617658353

Epoch: 15| Step: 0
Training loss: 3.2586052751028656
Validation loss: 3.2541120371256693

Epoch: 5| Step: 1
Training loss: 3.704363265825882
Validation loss: 3.254858658974373

Epoch: 5| Step: 2
Training loss: 3.6426090188033067
Validation loss: 3.2534207349659336

Epoch: 5| Step: 3
Training loss: 3.5188964542245627
Validation loss: 3.2500688555028225

Epoch: 5| Step: 4
Training loss: 3.5078865842068914
Validation loss: 3.2477239143425387

Epoch: 5| Step: 5
Training loss: 3.7033508489442335
Validation loss: 3.2464797278396724

Epoch: 5| Step: 6
Training loss: 3.4015569992616728
Validation loss: 3.2447376148288085

Epoch: 5| Step: 7
Training loss: 3.969945171948087
Validation loss: 3.2429544833725887

Epoch: 5| Step: 8
Training loss: 3.2996796886005892
Validation loss: 3.242501984619831

Epoch: 5| Step: 9
Training loss: 2.943816677885293
Validation loss: 3.2417005516976647

Epoch: 5| Step: 10
Training loss: 3.444036615148267
Validation loss: 3.239799477793095

Epoch: 16| Step: 0
Training loss: 3.779426324091184
Validation loss: 3.236600299276143

Epoch: 5| Step: 1
Training loss: 3.0151237110675893
Validation loss: 3.236271150272777

Epoch: 5| Step: 2
Training loss: 3.3498552148760585
Validation loss: 3.23571897799691

Epoch: 5| Step: 3
Training loss: 3.705910837952659
Validation loss: 3.234456737441203

Epoch: 5| Step: 4
Training loss: 3.5430524620588626
Validation loss: 3.232443254583093

Epoch: 5| Step: 5
Training loss: 3.1202933916892697
Validation loss: 3.2312461141016016

Epoch: 5| Step: 6
Training loss: 3.455625569396473
Validation loss: 3.230896030529398

Epoch: 5| Step: 7
Training loss: 3.182481892212852
Validation loss: 3.2295498938451983

Epoch: 5| Step: 8
Training loss: 3.5410028321697347
Validation loss: 3.227679113961951

Epoch: 5| Step: 9
Training loss: 3.8749586533832443
Validation loss: 3.226897641226891

Epoch: 5| Step: 10
Training loss: 3.7215935870550765
Validation loss: 3.22601620269076

Epoch: 17| Step: 0
Training loss: 3.7750195332204957
Validation loss: 3.2248338277985265

Epoch: 5| Step: 1
Training loss: 3.44390632842274
Validation loss: 3.223495755298427

Epoch: 5| Step: 2
Training loss: 3.2574749595634067
Validation loss: 3.2216237730846706

Epoch: 5| Step: 3
Training loss: 3.5366033974709996
Validation loss: 3.2213439015430616

Epoch: 5| Step: 4
Training loss: 3.7424790302675293
Validation loss: 3.2197180507975043

Epoch: 5| Step: 5
Training loss: 3.9714027009927046
Validation loss: 3.219036686482599

Epoch: 5| Step: 6
Training loss: 2.8445455255860024
Validation loss: 3.2178082552455907

Epoch: 5| Step: 7
Training loss: 3.065779506511182
Validation loss: 3.2176290460361994

Epoch: 5| Step: 8
Training loss: 2.4583506718255808
Validation loss: 3.218156754528696

Epoch: 5| Step: 9
Training loss: 3.3659014093349913
Validation loss: 3.2226098239670726

Epoch: 5| Step: 10
Training loss: 4.524972289617005
Validation loss: 3.216040670784531

Epoch: 18| Step: 0
Training loss: 3.693040984342867
Validation loss: 3.2128203335622683

Epoch: 5| Step: 1
Training loss: 3.6480592453981022
Validation loss: 3.2117019971570544

Epoch: 5| Step: 2
Training loss: 3.774169345438394
Validation loss: 3.211064843672419

Epoch: 5| Step: 3
Training loss: 3.006168381818249
Validation loss: 3.2092407156931904

Epoch: 5| Step: 4
Training loss: 3.5234005539134876
Validation loss: 3.2089192021056894

Epoch: 5| Step: 5
Training loss: 2.9057792364331863
Validation loss: 3.207177697297394

Epoch: 5| Step: 6
Training loss: 3.042954333446273
Validation loss: 3.2059736109235355

Epoch: 5| Step: 7
Training loss: 3.603536267725427
Validation loss: 3.2048192707414827

Epoch: 5| Step: 8
Training loss: 3.6246573187552174
Validation loss: 3.2026386170833105

Epoch: 5| Step: 9
Training loss: 3.5163174773738177
Validation loss: 3.2009089277570824

Epoch: 5| Step: 10
Training loss: 3.705385443732014
Validation loss: 3.19673006671883

Epoch: 19| Step: 0
Training loss: 2.994479663463257
Validation loss: 3.1940742029035825

Epoch: 5| Step: 1
Training loss: 3.391120979844123
Validation loss: 3.188652462397513

Epoch: 5| Step: 2
Training loss: 3.6419349245712795
Validation loss: 3.184120851374716

Epoch: 5| Step: 3
Training loss: 3.288668719932564
Validation loss: 3.1790088797028315

Epoch: 5| Step: 4
Training loss: 2.1388308391978113
Validation loss: 3.176231255222299

Epoch: 5| Step: 5
Training loss: 3.42685535604081
Validation loss: 3.174122940291818

Epoch: 5| Step: 6
Training loss: 3.6411132485102082
Validation loss: 3.172286912872087

Epoch: 5| Step: 7
Training loss: 3.712094032362669
Validation loss: 3.170343695097086

Epoch: 5| Step: 8
Training loss: 3.502611139945235
Validation loss: 3.168939868811027

Epoch: 5| Step: 9
Training loss: 3.270221742117
Validation loss: 3.1681527734644366

Epoch: 5| Step: 10
Training loss: 4.556790685819365
Validation loss: 3.166047460467798

Epoch: 20| Step: 0
Training loss: 3.238839279705114
Validation loss: 3.164590103438238

Epoch: 5| Step: 1
Training loss: 3.474302916282539
Validation loss: 3.1632663500455194

Epoch: 5| Step: 2
Training loss: 3.6604712482016755
Validation loss: 3.1614905977053107

Epoch: 5| Step: 3
Training loss: 3.9416282447625206
Validation loss: 3.160580421425754

Epoch: 5| Step: 4
Training loss: 3.629123578580426
Validation loss: 3.1589413765523657

Epoch: 5| Step: 5
Training loss: 2.9137859468930665
Validation loss: 3.157725782404687

Epoch: 5| Step: 6
Training loss: 3.0827609553332302
Validation loss: 3.157000396946666

Epoch: 5| Step: 7
Training loss: 2.765087441825955
Validation loss: 3.1568249585192683

Epoch: 5| Step: 8
Training loss: 2.827332190568773
Validation loss: 3.1548819877489094

Epoch: 5| Step: 9
Training loss: 3.883622205956526
Validation loss: 3.156568280699911

Epoch: 5| Step: 10
Training loss: 4.067603558873235
Validation loss: 3.1598772397592385

Epoch: 21| Step: 0
Training loss: 3.867450250504137
Validation loss: 3.149992767302242

Epoch: 5| Step: 1
Training loss: 3.166053428165349
Validation loss: 3.1500279769592625

Epoch: 5| Step: 2
Training loss: 3.872213777094759
Validation loss: 3.1491146000283305

Epoch: 5| Step: 3
Training loss: 3.5997801236716858
Validation loss: 3.147079055423125

Epoch: 5| Step: 4
Training loss: 2.732616360377752
Validation loss: 3.1556584175307147

Epoch: 5| Step: 5
Training loss: 2.8819851812422463
Validation loss: 3.1475424868846162

Epoch: 5| Step: 6
Training loss: 3.269145035806261
Validation loss: 3.148815392404628

Epoch: 5| Step: 7
Training loss: 3.6202483769559306
Validation loss: 3.146931746131567

Epoch: 5| Step: 8
Training loss: 3.735441303047824
Validation loss: 3.1472749221929313

Epoch: 5| Step: 9
Training loss: 3.2189689487691004
Validation loss: 3.142742710077169

Epoch: 5| Step: 10
Training loss: 3.4390446746932692
Validation loss: 3.1418693949270806

Epoch: 22| Step: 0
Training loss: 3.1995776374555236
Validation loss: 3.1412409610650154

Epoch: 5| Step: 1
Training loss: 3.4582521513330557
Validation loss: 3.141353890943492

Epoch: 5| Step: 2
Training loss: 2.97032782135794
Validation loss: 3.1405282844153355

Epoch: 5| Step: 3
Training loss: 3.5350796348742053
Validation loss: 3.1404111068261824

Epoch: 5| Step: 4
Training loss: 3.7026566478862484
Validation loss: 3.1382580023095414

Epoch: 5| Step: 5
Training loss: 3.071937810308078
Validation loss: 3.1363338777386627

Epoch: 5| Step: 6
Training loss: 3.5581327740671265
Validation loss: 3.135173956783459

Epoch: 5| Step: 7
Training loss: 3.1160214951426313
Validation loss: 3.1338089945707917

Epoch: 5| Step: 8
Training loss: 3.405898749763436
Validation loss: 3.1339727747004034

Epoch: 5| Step: 9
Training loss: 3.609480951248636
Validation loss: 3.1318433783322015

Epoch: 5| Step: 10
Training loss: 3.847162608125866
Validation loss: 3.1318722607085405

Epoch: 23| Step: 0
Training loss: 4.135911324205278
Validation loss: 3.130064809574378

Epoch: 5| Step: 1
Training loss: 3.4043374948272276
Validation loss: 3.1287912337367487

Epoch: 5| Step: 2
Training loss: 3.4279139631996487
Validation loss: 3.1284675736658505

Epoch: 5| Step: 3
Training loss: 3.8144073717974147
Validation loss: 3.127703159180258

Epoch: 5| Step: 4
Training loss: 2.906596829628231
Validation loss: 3.126380977875505

Epoch: 5| Step: 5
Training loss: 2.671078747341514
Validation loss: 3.1258973045483636

Epoch: 5| Step: 6
Training loss: 3.4164587903556995
Validation loss: 3.124149449588046

Epoch: 5| Step: 7
Training loss: 3.941355195485119
Validation loss: 3.1237834326146756

Epoch: 5| Step: 8
Training loss: 3.0768268771905496
Validation loss: 3.12338759632624

Epoch: 5| Step: 9
Training loss: 2.9944721792332865
Validation loss: 3.122053853630339

Epoch: 5| Step: 10
Training loss: 3.318777793293755
Validation loss: 3.121760295722618

Epoch: 24| Step: 0
Training loss: 3.286943999293597
Validation loss: 3.120604438152656

Epoch: 5| Step: 1
Training loss: 3.3074776344379306
Validation loss: 3.1196056050747463

Epoch: 5| Step: 2
Training loss: 3.522073350548723
Validation loss: 3.1199359462237806

Epoch: 5| Step: 3
Training loss: 3.3248151340577086
Validation loss: 3.1180828908868317

Epoch: 5| Step: 4
Training loss: 3.378135496223792
Validation loss: 3.1161818523784155

Epoch: 5| Step: 5
Training loss: 3.7257708782324443
Validation loss: 3.115662508014147

Epoch: 5| Step: 6
Training loss: 3.636542261678211
Validation loss: 3.11534297112329

Epoch: 5| Step: 7
Training loss: 3.3411652744567055
Validation loss: 3.1142039569883626

Epoch: 5| Step: 8
Training loss: 2.809519650954216
Validation loss: 3.1122355872368033

Epoch: 5| Step: 9
Training loss: 3.2481276180395513
Validation loss: 3.110402265331746

Epoch: 5| Step: 10
Training loss: 3.6917504851482428
Validation loss: 3.110471715396653

Epoch: 25| Step: 0
Training loss: 3.441328379067194
Validation loss: 3.1108591601632942

Epoch: 5| Step: 1
Training loss: 3.1540773675557396
Validation loss: 3.1088885061066915

Epoch: 5| Step: 2
Training loss: 3.6769659583762286
Validation loss: 3.106372056161966

Epoch: 5| Step: 3
Training loss: 3.5472054348592112
Validation loss: 3.106435713002521

Epoch: 5| Step: 4
Training loss: 3.5249956496191572
Validation loss: 3.1049354698489404

Epoch: 5| Step: 5
Training loss: 3.433988129725794
Validation loss: 3.1031413136050436

Epoch: 5| Step: 6
Training loss: 2.861731053647964
Validation loss: 3.1005043189187678

Epoch: 5| Step: 7
Training loss: 4.3403091524473645
Validation loss: 3.1007117230777252

Epoch: 5| Step: 8
Training loss: 2.289957437910986
Validation loss: 3.0998432823736355

Epoch: 5| Step: 9
Training loss: 3.1389583891279536
Validation loss: 3.0977590552362377

Epoch: 5| Step: 10
Training loss: 3.4240737887836405
Validation loss: 3.0964513085025844

Epoch: 26| Step: 0
Training loss: 3.888398295444554
Validation loss: 3.0945782854160226

Epoch: 5| Step: 1
Training loss: 2.548820454669972
Validation loss: 3.092263947157644

Epoch: 5| Step: 2
Training loss: 3.5298522613559213
Validation loss: 3.094643990793626

Epoch: 5| Step: 3
Training loss: 3.1830832604518453
Validation loss: 3.0927712773515235

Epoch: 5| Step: 4
Training loss: 3.5402223821068795
Validation loss: 3.088744355745509

Epoch: 5| Step: 5
Training loss: 3.108410556300991
Validation loss: 3.0939791252614115

Epoch: 5| Step: 6
Training loss: 3.2795420243201985
Validation loss: 3.096623097268464

Epoch: 5| Step: 7
Training loss: 3.701322479002187
Validation loss: 3.1083599471687324

Epoch: 5| Step: 8
Training loss: 3.2517031095239606
Validation loss: 3.0882194110347827

Epoch: 5| Step: 9
Training loss: 3.1889233870491838
Validation loss: 3.0874953965200125

Epoch: 5| Step: 10
Training loss: 3.756465043753098
Validation loss: 3.1183349313443194

Epoch: 27| Step: 0
Training loss: 3.0929365533635385
Validation loss: 3.115942749128409

Epoch: 5| Step: 1
Training loss: 2.9378788480559392
Validation loss: 3.100520263782509

Epoch: 5| Step: 2
Training loss: 3.429418601093824
Validation loss: 3.0909986927028923

Epoch: 5| Step: 3
Training loss: 3.0480080087411348
Validation loss: 3.0905846986304137

Epoch: 5| Step: 4
Training loss: 2.849773357816016
Validation loss: 3.0895915476819997

Epoch: 5| Step: 5
Training loss: 3.518928569375512
Validation loss: 3.0917215518266046

Epoch: 5| Step: 6
Training loss: 3.3923618069798462
Validation loss: 3.096397015779911

Epoch: 5| Step: 7
Training loss: 3.854039384269508
Validation loss: 3.0958172440015894

Epoch: 5| Step: 8
Training loss: 3.7323880196577455
Validation loss: 3.0879904511700613

Epoch: 5| Step: 9
Training loss: 3.245242818672963
Validation loss: 3.090894222744715

Epoch: 5| Step: 10
Training loss: 3.8831310486942114
Validation loss: 3.0836544191176793

Epoch: 28| Step: 0
Training loss: 3.156749874604098
Validation loss: 3.081846633439762

Epoch: 5| Step: 1
Training loss: 3.5502284661504864
Validation loss: 3.081741877354562

Epoch: 5| Step: 2
Training loss: 3.4337156792735284
Validation loss: 3.085015222073082

Epoch: 5| Step: 3
Training loss: 2.9322223734192083
Validation loss: 3.0797033973424592

Epoch: 5| Step: 4
Training loss: 3.3503207949868457
Validation loss: 3.084596924304919

Epoch: 5| Step: 5
Training loss: 3.1236654865361855
Validation loss: 3.0754873333618944

Epoch: 5| Step: 6
Training loss: 3.3620733734965413
Validation loss: 3.069682628027184

Epoch: 5| Step: 7
Training loss: 3.605355274402661
Validation loss: 3.0693291912367724

Epoch: 5| Step: 8
Training loss: 3.219106413728082
Validation loss: 3.069541320165387

Epoch: 5| Step: 9
Training loss: 3.901072985426198
Validation loss: 3.0685356121221234

Epoch: 5| Step: 10
Training loss: 3.1216980846783957
Validation loss: 3.0666089756605337

Epoch: 29| Step: 0
Training loss: 3.6603007252452575
Validation loss: 3.063246536592761

Epoch: 5| Step: 1
Training loss: 3.350802106341014
Validation loss: 3.065029046797707

Epoch: 5| Step: 2
Training loss: 2.9521431072665245
Validation loss: 3.064395084645948

Epoch: 5| Step: 3
Training loss: 3.5416278762189064
Validation loss: 3.062781776555961

Epoch: 5| Step: 4
Training loss: 3.359990263198187
Validation loss: 3.0621721152029373

Epoch: 5| Step: 5
Training loss: 3.4150861170174767
Validation loss: 3.06069426533696

Epoch: 5| Step: 6
Training loss: 3.068717872466992
Validation loss: 3.0627416716686624

Epoch: 5| Step: 7
Training loss: 2.9272362792396978
Validation loss: 3.065004815718116

Epoch: 5| Step: 8
Training loss: 3.102678304831012
Validation loss: 3.0736462516226486

Epoch: 5| Step: 9
Training loss: 3.535757917765235
Validation loss: 3.0723816709220166

Epoch: 5| Step: 10
Training loss: 3.867278990000466
Validation loss: 3.064690435851638

Epoch: 30| Step: 0
Training loss: 2.886663578316649
Validation loss: 3.0573221868875646

Epoch: 5| Step: 1
Training loss: 2.488787493267657
Validation loss: 3.0551402961734047

Epoch: 5| Step: 2
Training loss: 3.2126975329039684
Validation loss: 3.0537636410498505

Epoch: 5| Step: 3
Training loss: 3.914576087499669
Validation loss: 3.054267385481509

Epoch: 5| Step: 4
Training loss: 3.299029473438176
Validation loss: 3.0530896337842997

Epoch: 5| Step: 5
Training loss: 3.7305366230327475
Validation loss: 3.0525652451674463

Epoch: 5| Step: 6
Training loss: 3.458991129872357
Validation loss: 3.05192293740098

Epoch: 5| Step: 7
Training loss: 3.841330037845715
Validation loss: 3.0516097410314376

Epoch: 5| Step: 8
Training loss: 3.7017301998900893
Validation loss: 3.04820038455401

Epoch: 5| Step: 9
Training loss: 2.559381867377415
Validation loss: 3.049711161828733

Epoch: 5| Step: 10
Training loss: 3.2581767877955587
Validation loss: 3.049323338451194

Epoch: 31| Step: 0
Training loss: 2.6896649002325947
Validation loss: 3.0469976198035194

Epoch: 5| Step: 1
Training loss: 3.1810343371363548
Validation loss: 3.0520198425814296

Epoch: 5| Step: 2
Training loss: 3.724830848898413
Validation loss: 3.0512119253031984

Epoch: 5| Step: 3
Training loss: 3.263206498977388
Validation loss: 3.0515200529021644

Epoch: 5| Step: 4
Training loss: 3.0610550566254737
Validation loss: 3.059752486865539

Epoch: 5| Step: 5
Training loss: 3.682447172098056
Validation loss: 3.050146382351204

Epoch: 5| Step: 6
Training loss: 3.1998676391884078
Validation loss: 3.046644753969049

Epoch: 5| Step: 7
Training loss: 3.538151840703841
Validation loss: 3.0441321038537312

Epoch: 5| Step: 8
Training loss: 3.1044591642137136
Validation loss: 3.0433838116410463

Epoch: 5| Step: 9
Training loss: 3.8635320475974444
Validation loss: 3.044070027744181

Epoch: 5| Step: 10
Training loss: 2.991912271376254
Validation loss: 3.052528100031326

Epoch: 32| Step: 0
Training loss: 3.0083910893384744
Validation loss: 3.0780717449412984

Epoch: 5| Step: 1
Training loss: 3.014431099429949
Validation loss: 3.0448814548901995

Epoch: 5| Step: 2
Training loss: 4.015392489696802
Validation loss: 3.0394412724495967

Epoch: 5| Step: 3
Training loss: 3.6528642416141848
Validation loss: 3.0398597412859325

Epoch: 5| Step: 4
Training loss: 2.761363307411982
Validation loss: 3.0379134664074883

Epoch: 5| Step: 5
Training loss: 3.6967494501510894
Validation loss: 3.0377746176334215

Epoch: 5| Step: 6
Training loss: 3.0083739710323516
Validation loss: 3.0387350854455213

Epoch: 5| Step: 7
Training loss: 3.817839713479316
Validation loss: 3.03781959151813

Epoch: 5| Step: 8
Training loss: 2.9111434593377097
Validation loss: 3.038804495431861

Epoch: 5| Step: 9
Training loss: 3.3427857051337853
Validation loss: 3.040575932367563

Epoch: 5| Step: 10
Training loss: 3.0321487195624073
Validation loss: 3.0373657139487182

Epoch: 33| Step: 0
Training loss: 2.858080795149781
Validation loss: 3.035289733648432

Epoch: 5| Step: 1
Training loss: 2.97862896813033
Validation loss: 3.0340809569326064

Epoch: 5| Step: 2
Training loss: 3.264001324026924
Validation loss: 3.035710280503564

Epoch: 5| Step: 3
Training loss: 3.216130792785976
Validation loss: 3.0538969787574954

Epoch: 5| Step: 4
Training loss: 3.409054642686698
Validation loss: 3.0871125208153187

Epoch: 5| Step: 5
Training loss: 3.13137030760607
Validation loss: 3.04280911520969

Epoch: 5| Step: 6
Training loss: 3.4586241419826718
Validation loss: 3.0296436422163833

Epoch: 5| Step: 7
Training loss: 2.853348180726303
Validation loss: 3.032176637396231

Epoch: 5| Step: 8
Training loss: 3.4726757482403956
Validation loss: 3.0583536198419807

Epoch: 5| Step: 9
Training loss: 4.266132478254923
Validation loss: 3.0643261706507072

Epoch: 5| Step: 10
Training loss: 3.618438438483272
Validation loss: 3.026120396396625

Epoch: 34| Step: 0
Training loss: 3.865663786981099
Validation loss: 3.0226556449017665

Epoch: 5| Step: 1
Training loss: 3.2312854993629943
Validation loss: 3.0259220706176904

Epoch: 5| Step: 2
Training loss: 3.0392082591270695
Validation loss: 3.034640299817661

Epoch: 5| Step: 3
Training loss: 3.204363327704507
Validation loss: 3.0626699414292937

Epoch: 5| Step: 4
Training loss: 3.256376027544066
Validation loss: 3.068291714767855

Epoch: 5| Step: 5
Training loss: 3.42536100726483
Validation loss: 3.0763454037117213

Epoch: 5| Step: 6
Training loss: 3.243529260434297
Validation loss: 3.0616809016624886

Epoch: 5| Step: 7
Training loss: 3.9123865373143283
Validation loss: 3.0473452070345264

Epoch: 5| Step: 8
Training loss: 2.658750546360722
Validation loss: 3.0343711843794314

Epoch: 5| Step: 9
Training loss: 3.59439067934663
Validation loss: 3.031684873894803

Epoch: 5| Step: 10
Training loss: 2.757824689713898
Validation loss: 3.0228809352005213

Epoch: 35| Step: 0
Training loss: 3.1361572979286407
Validation loss: 3.018376863012084

Epoch: 5| Step: 1
Training loss: 3.02144744594029
Validation loss: 3.01574217645024

Epoch: 5| Step: 2
Training loss: 3.4599991122558866
Validation loss: 3.0169336122562047

Epoch: 5| Step: 3
Training loss: 3.4081235160383683
Validation loss: 3.0126754768864576

Epoch: 5| Step: 4
Training loss: 3.1375495693956834
Validation loss: 3.0108333253462978

Epoch: 5| Step: 5
Training loss: 2.9175482552925236
Validation loss: 3.00915797951263

Epoch: 5| Step: 6
Training loss: 3.005505913469218
Validation loss: 3.0086419455445244

Epoch: 5| Step: 7
Training loss: 2.8478833017764456
Validation loss: 3.0124291844436097

Epoch: 5| Step: 8
Training loss: 4.223173859638089
Validation loss: 3.0118547960040414

Epoch: 5| Step: 9
Training loss: 3.4489286998480764
Validation loss: 3.0120257870744798

Epoch: 5| Step: 10
Training loss: 3.5358087601363337
Validation loss: 3.010393482324351

Epoch: 36| Step: 0
Training loss: 3.5952417345969923
Validation loss: 3.0080327162600895

Epoch: 5| Step: 1
Training loss: 3.287281850096687
Validation loss: 3.0092212443706625

Epoch: 5| Step: 2
Training loss: 3.5499864282482925
Validation loss: 3.01059806803186

Epoch: 5| Step: 3
Training loss: 3.865075353403578
Validation loss: 3.0114193178490583

Epoch: 5| Step: 4
Training loss: 3.349217872984344
Validation loss: 3.0118349974143968

Epoch: 5| Step: 5
Training loss: 3.0109241590219167
Validation loss: 3.0157918805774293

Epoch: 5| Step: 6
Training loss: 3.0454548974211657
Validation loss: 3.0094551594462535

Epoch: 5| Step: 7
Training loss: 3.427033598905167
Validation loss: 3.0079585188692612

Epoch: 5| Step: 8
Training loss: 3.501080346265052
Validation loss: 3.0052438456866084

Epoch: 5| Step: 9
Training loss: 2.32189240275827
Validation loss: 3.0053788967372315

Epoch: 5| Step: 10
Training loss: 2.9190777939678703
Validation loss: 3.0070423799688064

Epoch: 37| Step: 0
Training loss: 4.045269857677674
Validation loss: 3.003315322969431

Epoch: 5| Step: 1
Training loss: 2.6993330449639363
Validation loss: 3.0011014557076705

Epoch: 5| Step: 2
Training loss: 3.807834083893549
Validation loss: 2.996902644342475

Epoch: 5| Step: 3
Training loss: 2.6883967478163324
Validation loss: 2.9951368363944186

Epoch: 5| Step: 4
Training loss: 3.503126519072694
Validation loss: 2.9969501708048223

Epoch: 5| Step: 5
Training loss: 2.9876646116227588
Validation loss: 2.9956624170245627

Epoch: 5| Step: 6
Training loss: 3.3089861676505445
Validation loss: 2.9959472555405418

Epoch: 5| Step: 7
Training loss: 3.2855751233218227
Validation loss: 2.9963226733603174

Epoch: 5| Step: 8
Training loss: 2.7433025125538966
Validation loss: 2.9941554015941736

Epoch: 5| Step: 9
Training loss: 3.2984224999473883
Validation loss: 2.9945997185027546

Epoch: 5| Step: 10
Training loss: 3.4684529220247815
Validation loss: 2.9946245329643078

Epoch: 38| Step: 0
Training loss: 3.078151025032748
Validation loss: 2.994659260537622

Epoch: 5| Step: 1
Training loss: 2.999915598635733
Validation loss: 2.993445035647789

Epoch: 5| Step: 2
Training loss: 3.1384152661806253
Validation loss: 2.991913263616365

Epoch: 5| Step: 3
Training loss: 3.8691384066595105
Validation loss: 2.9928147988494516

Epoch: 5| Step: 4
Training loss: 3.2005330833819334
Validation loss: 2.9925324395318933

Epoch: 5| Step: 5
Training loss: 2.580667987076502
Validation loss: 2.991212524770606

Epoch: 5| Step: 6
Training loss: 3.7893994997526437
Validation loss: 2.995405743503049

Epoch: 5| Step: 7
Training loss: 3.5590435459852467
Validation loss: 2.9922173791292797

Epoch: 5| Step: 8
Training loss: 2.847817498810407
Validation loss: 2.988238858383332

Epoch: 5| Step: 9
Training loss: 3.207912830357591
Validation loss: 2.9864588886405556

Epoch: 5| Step: 10
Training loss: 3.5145525165345717
Validation loss: 2.9830945324005063

Epoch: 39| Step: 0
Training loss: 2.651813167486795
Validation loss: 2.983890629221076

Epoch: 5| Step: 1
Training loss: 3.776689916630619
Validation loss: 2.9838725507133916

Epoch: 5| Step: 2
Training loss: 2.885883132926415
Validation loss: 2.9821084131227704

Epoch: 5| Step: 3
Training loss: 3.5377152933447227
Validation loss: 2.9811255889309414

Epoch: 5| Step: 4
Training loss: 3.53461208475862
Validation loss: 2.983325827304923

Epoch: 5| Step: 5
Training loss: 3.331388923653996
Validation loss: 2.9801131871144078

Epoch: 5| Step: 6
Training loss: 3.1321678354497973
Validation loss: 2.9798980103205825

Epoch: 5| Step: 7
Training loss: 3.372772612076515
Validation loss: 2.979209358040822

Epoch: 5| Step: 8
Training loss: 2.9259186369925416
Validation loss: 2.9766615708828663

Epoch: 5| Step: 9
Training loss: 3.32515157483166
Validation loss: 2.9759345793633893

Epoch: 5| Step: 10
Training loss: 3.2802229954349555
Validation loss: 2.9763685223577543

Epoch: 40| Step: 0
Training loss: 2.651097495060151
Validation loss: 2.9764234765371906

Epoch: 5| Step: 1
Training loss: 3.9031761587560636
Validation loss: 2.988663938960057

Epoch: 5| Step: 2
Training loss: 3.268838423924259
Validation loss: 2.9825309077356796

Epoch: 5| Step: 3
Training loss: 2.8128666956587876
Validation loss: 2.9741335799727535

Epoch: 5| Step: 4
Training loss: 2.778633000857542
Validation loss: 2.9715708380867474

Epoch: 5| Step: 5
Training loss: 3.735181266542911
Validation loss: 2.9696163966320546

Epoch: 5| Step: 6
Training loss: 2.6749930230165564
Validation loss: 2.9705112209185636

Epoch: 5| Step: 7
Training loss: 3.1891600829861315
Validation loss: 2.969721306979779

Epoch: 5| Step: 8
Training loss: 3.2041846034652086
Validation loss: 2.968034837091505

Epoch: 5| Step: 9
Training loss: 3.5717213728633217
Validation loss: 2.9673560513547685

Epoch: 5| Step: 10
Training loss: 3.766168325648324
Validation loss: 2.968768017751424

Epoch: 41| Step: 0
Training loss: 3.2950089945692094
Validation loss: 2.967986895114116

Epoch: 5| Step: 1
Training loss: 2.545962398356267
Validation loss: 2.9661704461980167

Epoch: 5| Step: 2
Training loss: 3.607923868276911
Validation loss: 2.9668750828916006

Epoch: 5| Step: 3
Training loss: 3.6658915365087235
Validation loss: 2.9635635831629354

Epoch: 5| Step: 4
Training loss: 3.6469030645576903
Validation loss: 2.9632342944181227

Epoch: 5| Step: 5
Training loss: 2.858117165653812
Validation loss: 2.963007286069547

Epoch: 5| Step: 6
Training loss: 3.461608959360432
Validation loss: 2.9654823527819234

Epoch: 5| Step: 7
Training loss: 2.0289261656478863
Validation loss: 2.964855170669402

Epoch: 5| Step: 8
Training loss: 3.5247296926328877
Validation loss: 2.9633582988906237

Epoch: 5| Step: 9
Training loss: 2.9326114965708183
Validation loss: 2.9607373276361977

Epoch: 5| Step: 10
Training loss: 3.7823310756845263
Validation loss: 2.960427816820487

Epoch: 42| Step: 0
Training loss: 3.6688865675194577
Validation loss: 2.960679384170167

Epoch: 5| Step: 1
Training loss: 3.590140213207317
Validation loss: 2.9619648412789883

Epoch: 5| Step: 2
Training loss: 3.0184801253529696
Validation loss: 2.962900646306685

Epoch: 5| Step: 3
Training loss: 2.8373407932604096
Validation loss: 2.969291557307049

Epoch: 5| Step: 4
Training loss: 2.9460024240643072
Validation loss: 2.9702717109130434

Epoch: 5| Step: 5
Training loss: 3.200118873295593
Validation loss: 2.9737582834004583

Epoch: 5| Step: 6
Training loss: 2.4421475437090487
Validation loss: 2.9667771421046547

Epoch: 5| Step: 7
Training loss: 3.456997042556747
Validation loss: 2.9684426183629564

Epoch: 5| Step: 8
Training loss: 3.3011221624984257
Validation loss: 2.9615744892803617

Epoch: 5| Step: 9
Training loss: 3.3953852133550786
Validation loss: 2.9570762971238

Epoch: 5| Step: 10
Training loss: 3.685899419454426
Validation loss: 2.9561219836574386

Epoch: 43| Step: 0
Training loss: 2.7161195679976817
Validation loss: 2.9528118487726744

Epoch: 5| Step: 1
Training loss: 3.263916444774847
Validation loss: 2.9529577085135363

Epoch: 5| Step: 2
Training loss: 3.243839293557367
Validation loss: 2.9512548055156804

Epoch: 5| Step: 3
Training loss: 3.545214428139954
Validation loss: 2.9516348420523655

Epoch: 5| Step: 4
Training loss: 3.3323052887291826
Validation loss: 2.9493995646389504

Epoch: 5| Step: 5
Training loss: 3.10749169444465
Validation loss: 2.949856520372533

Epoch: 5| Step: 6
Training loss: 3.5667745811560283
Validation loss: 2.949002345636591

Epoch: 5| Step: 7
Training loss: 3.5457119148047105
Validation loss: 2.9504264329363363

Epoch: 5| Step: 8
Training loss: 2.7706311278788522
Validation loss: 2.948163989673004

Epoch: 5| Step: 9
Training loss: 3.440155390844893
Validation loss: 2.9482344850261297

Epoch: 5| Step: 10
Training loss: 2.845771155136552
Validation loss: 2.9463802641412107

Epoch: 44| Step: 0
Training loss: 2.269403293173752
Validation loss: 2.9459091761110794

Epoch: 5| Step: 1
Training loss: 3.4397134763579476
Validation loss: 2.9436263687810555

Epoch: 5| Step: 2
Training loss: 3.6905157397680983
Validation loss: 2.9431164106373124

Epoch: 5| Step: 3
Training loss: 3.363063898274089
Validation loss: 2.9423052396359712

Epoch: 5| Step: 4
Training loss: 3.0430192074001843
Validation loss: 2.94069598657361

Epoch: 5| Step: 5
Training loss: 2.6743776078644954
Validation loss: 2.9402516257943803

Epoch: 5| Step: 6
Training loss: 3.577451950806209
Validation loss: 2.9403408297565323

Epoch: 5| Step: 7
Training loss: 2.6223565369849826
Validation loss: 2.938555148981238

Epoch: 5| Step: 8
Training loss: 3.312619764933979
Validation loss: 2.940432376312502

Epoch: 5| Step: 9
Training loss: 3.4444934797043927
Validation loss: 2.9414892013504508

Epoch: 5| Step: 10
Training loss: 3.8305488231053584
Validation loss: 2.936813431349058

Epoch: 45| Step: 0
Training loss: 3.0188590778365154
Validation loss: 2.937450354406845

Epoch: 5| Step: 1
Training loss: 3.298603924302866
Validation loss: 2.938135685295293

Epoch: 5| Step: 2
Training loss: 3.252034357562748
Validation loss: 2.9410124763308683

Epoch: 5| Step: 3
Training loss: 4.257305374042549
Validation loss: 2.944545617831956

Epoch: 5| Step: 4
Training loss: 2.918214024215066
Validation loss: 2.944243382982586

Epoch: 5| Step: 5
Training loss: 2.699896587934577
Validation loss: 2.9441446536218

Epoch: 5| Step: 6
Training loss: 3.274442168040355
Validation loss: 2.949283434473544

Epoch: 5| Step: 7
Training loss: 3.677477000545153
Validation loss: 2.964205020017085

Epoch: 5| Step: 8
Training loss: 3.2217051449244263
Validation loss: 2.94696958373095

Epoch: 5| Step: 9
Training loss: 2.5560026837306493
Validation loss: 2.9309426879644467

Epoch: 5| Step: 10
Training loss: 2.8724297354050052
Validation loss: 2.929461011000531

Epoch: 46| Step: 0
Training loss: 3.057948096713681
Validation loss: 2.9306850847630335

Epoch: 5| Step: 1
Training loss: 2.984598041608066
Validation loss: 2.928762741874512

Epoch: 5| Step: 2
Training loss: 2.3324022365414763
Validation loss: 2.9280935771726657

Epoch: 5| Step: 3
Training loss: 4.01827120146044
Validation loss: 2.9265316906950605

Epoch: 5| Step: 4
Training loss: 2.995586009067295
Validation loss: 2.9282112857528397

Epoch: 5| Step: 5
Training loss: 3.0492524090687256
Validation loss: 2.925503892584849

Epoch: 5| Step: 6
Training loss: 3.4153437185383373
Validation loss: 2.925541321186004

Epoch: 5| Step: 7
Training loss: 3.6860158487477017
Validation loss: 2.926995406401041

Epoch: 5| Step: 8
Training loss: 2.971534467214498
Validation loss: 2.924228164820629

Epoch: 5| Step: 9
Training loss: 3.0485964875871026
Validation loss: 2.9246231184077267

Epoch: 5| Step: 10
Training loss: 3.5804594329040214
Validation loss: 2.9242485828518454

Epoch: 47| Step: 0
Training loss: 2.728750930066022
Validation loss: 2.928728048748537

Epoch: 5| Step: 1
Training loss: 3.4232956536982595
Validation loss: 2.926452580728543

Epoch: 5| Step: 2
Training loss: 3.6181607677532233
Validation loss: 2.9231584515971187

Epoch: 5| Step: 3
Training loss: 2.5472614018616273
Validation loss: 2.925401697586477

Epoch: 5| Step: 4
Training loss: 3.6229444792639454
Validation loss: 2.923140539479925

Epoch: 5| Step: 5
Training loss: 3.2958337667266395
Validation loss: 2.924077729331642

Epoch: 5| Step: 6
Training loss: 3.0818415632969596
Validation loss: 2.9169734430195087

Epoch: 5| Step: 7
Training loss: 3.2218740172805544
Validation loss: 2.922005067511742

Epoch: 5| Step: 8
Training loss: 2.934834508698033
Validation loss: 2.9190422488860017

Epoch: 5| Step: 9
Training loss: 3.2846142189025183
Validation loss: 2.9146265125589412

Epoch: 5| Step: 10
Training loss: 3.3831988459825295
Validation loss: 2.9109402204224333

Epoch: 48| Step: 0
Training loss: 3.235967124460757
Validation loss: 2.9141763741147395

Epoch: 5| Step: 1
Training loss: 2.8846780173520137
Validation loss: 2.913162644550585

Epoch: 5| Step: 2
Training loss: 3.260638212206825
Validation loss: 2.9122607663174995

Epoch: 5| Step: 3
Training loss: 3.408728441562612
Validation loss: 2.9110083252694854

Epoch: 5| Step: 4
Training loss: 2.937045610062666
Validation loss: 2.909917910221847

Epoch: 5| Step: 5
Training loss: 3.4646386878262816
Validation loss: 2.9113652992268966

Epoch: 5| Step: 6
Training loss: 2.8314927424439382
Validation loss: 2.906990481793242

Epoch: 5| Step: 7
Training loss: 2.7855575293846866
Validation loss: 2.9083868650890405

Epoch: 5| Step: 8
Training loss: 3.7633456220896413
Validation loss: 2.911002704821688

Epoch: 5| Step: 9
Training loss: 3.462191042560411
Validation loss: 2.921697692246807

Epoch: 5| Step: 10
Training loss: 2.9544905477370342
Validation loss: 2.9477130804084495

Epoch: 49| Step: 0
Training loss: 2.754059136658189
Validation loss: 2.9782430563962943

Epoch: 5| Step: 1
Training loss: 2.320073484703937
Validation loss: 2.9707140347018584

Epoch: 5| Step: 2
Training loss: 3.191694603806844
Validation loss: 2.9782069443322534

Epoch: 5| Step: 3
Training loss: 3.4994317002088025
Validation loss: 2.970430201135724

Epoch: 5| Step: 4
Training loss: 3.489268061881462
Validation loss: 2.9582429953241007

Epoch: 5| Step: 5
Training loss: 3.9264318733634678
Validation loss: 2.916701474546058

Epoch: 5| Step: 6
Training loss: 2.8127145473452178
Validation loss: 2.9044236782627

Epoch: 5| Step: 7
Training loss: 3.1671145942174674
Validation loss: 2.928795315434359

Epoch: 5| Step: 8
Training loss: 3.1529929096542664
Validation loss: 2.9698706644120376

Epoch: 5| Step: 9
Training loss: 3.8296286607608954
Validation loss: 2.9769456284325106

Epoch: 5| Step: 10
Training loss: 3.110524794037773
Validation loss: 2.9400699503439425

Epoch: 50| Step: 0
Training loss: 3.957360211600702
Validation loss: 2.91564618612621

Epoch: 5| Step: 1
Training loss: 2.6429430476333478
Validation loss: 2.901274757316912

Epoch: 5| Step: 2
Training loss: 3.071523956389214
Validation loss: 2.9003364169837442

Epoch: 5| Step: 3
Training loss: 3.315650880876179
Validation loss: 2.9284198344422254

Epoch: 5| Step: 4
Training loss: 3.141600500028962
Validation loss: 2.9148788568900343

Epoch: 5| Step: 5
Training loss: 3.215554734658845
Validation loss: 2.9064177598013203

Epoch: 5| Step: 6
Training loss: 3.0554050080944704
Validation loss: 2.904269992943311

Epoch: 5| Step: 7
Training loss: 2.787967926574288
Validation loss: 2.9054803674922765

Epoch: 5| Step: 8
Training loss: 3.269806297701334
Validation loss: 2.922180666927569

Epoch: 5| Step: 9
Training loss: 3.320680413899369
Validation loss: 2.9315241962244234

Epoch: 5| Step: 10
Training loss: 3.260196828692465
Validation loss: 2.9238382275830204

Epoch: 51| Step: 0
Training loss: 2.7712001318739934
Validation loss: 2.9165468205969334

Epoch: 5| Step: 1
Training loss: 3.6223962574932727
Validation loss: 2.9173026966220683

Epoch: 5| Step: 2
Training loss: 3.201709862701784
Validation loss: 2.9161176865108605

Epoch: 5| Step: 3
Training loss: 3.046889867501787
Validation loss: 2.9122309136930964

Epoch: 5| Step: 4
Training loss: 3.054906812829288
Validation loss: 2.902221968621592

Epoch: 5| Step: 5
Training loss: 2.7059145078553426
Validation loss: 2.8907221074132616

Epoch: 5| Step: 6
Training loss: 3.127122539670103
Validation loss: 2.8909451942292197

Epoch: 5| Step: 7
Training loss: 3.600786303373678
Validation loss: 2.8912711483635407

Epoch: 5| Step: 8
Training loss: 3.4749630109615945
Validation loss: 2.891321983219658

Epoch: 5| Step: 9
Training loss: 3.137218088805902
Validation loss: 2.8909173952265976

Epoch: 5| Step: 10
Training loss: 3.308809924128866
Validation loss: 2.8965930819993835

Epoch: 52| Step: 0
Training loss: 3.3885298905322885
Validation loss: 2.8938993471917867

Epoch: 5| Step: 1
Training loss: 3.1445970611319796
Validation loss: 2.891783129590465

Epoch: 5| Step: 2
Training loss: 3.448633924178263
Validation loss: 2.8891248052204888

Epoch: 5| Step: 3
Training loss: 3.2023420167738204
Validation loss: 2.888938348324142

Epoch: 5| Step: 4
Training loss: 2.4288126360895004
Validation loss: 2.8887333687729932

Epoch: 5| Step: 5
Training loss: 3.15807690011362
Validation loss: 2.888282070711051

Epoch: 5| Step: 6
Training loss: 3.659814385048484
Validation loss: 2.890050275850494

Epoch: 5| Step: 7
Training loss: 2.914229564633387
Validation loss: 2.8862503290924755

Epoch: 5| Step: 8
Training loss: 3.255121890128277
Validation loss: 2.8894010108104786

Epoch: 5| Step: 9
Training loss: 3.3982858207440727
Validation loss: 2.8858437837113224

Epoch: 5| Step: 10
Training loss: 2.863899029001447
Validation loss: 2.8882716520374876

Epoch: 53| Step: 0
Training loss: 3.0755996801663184
Validation loss: 2.8919016849281443

Epoch: 5| Step: 1
Training loss: 3.4267212155622713
Validation loss: 2.887607990829645

Epoch: 5| Step: 2
Training loss: 3.3377819099378114
Validation loss: 2.884266979495188

Epoch: 5| Step: 3
Training loss: 2.9427560087859974
Validation loss: 2.884369656014763

Epoch: 5| Step: 4
Training loss: 3.426269078944409
Validation loss: 2.888949202966769

Epoch: 5| Step: 5
Training loss: 2.8982535661188287
Validation loss: 2.88195207415834

Epoch: 5| Step: 6
Training loss: 3.757117700881079
Validation loss: 2.8922627065400897

Epoch: 5| Step: 7
Training loss: 2.8601866857247735
Validation loss: 2.8797526781387996

Epoch: 5| Step: 8
Training loss: 2.732517767008182
Validation loss: 2.8765064375007037

Epoch: 5| Step: 9
Training loss: 3.1774073868047186
Validation loss: 2.8799555596246513

Epoch: 5| Step: 10
Training loss: 3.1597806615397417
Validation loss: 2.8750680163712286

Epoch: 54| Step: 0
Training loss: 2.8055243558586187
Validation loss: 2.873809220980588

Epoch: 5| Step: 1
Training loss: 3.3661190028151533
Validation loss: 2.875467033313926

Epoch: 5| Step: 2
Training loss: 3.0394481424061137
Validation loss: 2.8746099443749484

Epoch: 5| Step: 3
Training loss: 3.397304582849454
Validation loss: 2.8723169659440924

Epoch: 5| Step: 4
Training loss: 3.716538998131701
Validation loss: 2.8796521374308335

Epoch: 5| Step: 5
Training loss: 2.957379218607476
Validation loss: 2.88312049703521

Epoch: 5| Step: 6
Training loss: 3.046749797107054
Validation loss: 2.8996202595068423

Epoch: 5| Step: 7
Training loss: 3.653644122202394
Validation loss: 2.9263475769404157

Epoch: 5| Step: 8
Training loss: 2.8305053809646648
Validation loss: 2.889029518245808

Epoch: 5| Step: 9
Training loss: 3.0295112578275245
Validation loss: 2.882206057973897

Epoch: 5| Step: 10
Training loss: 2.8432784475535042
Validation loss: 2.8751727083967284

Epoch: 55| Step: 0
Training loss: 2.6470931250400462
Validation loss: 2.8664019771763396

Epoch: 5| Step: 1
Training loss: 3.6942204158104617
Validation loss: 2.8693266073900534

Epoch: 5| Step: 2
Training loss: 3.3352847744949066
Validation loss: 2.8772728056527526

Epoch: 5| Step: 3
Training loss: 3.0722066457704966
Validation loss: 2.860746330412519

Epoch: 5| Step: 4
Training loss: 3.48535553003942
Validation loss: 2.858884187737194

Epoch: 5| Step: 5
Training loss: 2.320829391704433
Validation loss: 2.8573037076974224

Epoch: 5| Step: 6
Training loss: 3.296224954891136
Validation loss: 2.857198780841207

Epoch: 5| Step: 7
Training loss: 3.123341539902085
Validation loss: 2.8535505120297864

Epoch: 5| Step: 8
Training loss: 3.3044794256118455
Validation loss: 2.8567490906614825

Epoch: 5| Step: 9
Training loss: 2.437946767699958
Validation loss: 2.8580975080763578

Epoch: 5| Step: 10
Training loss: 3.7878353058602334
Validation loss: 2.853113092408577

Epoch: 56| Step: 0
Training loss: 3.1646346716936606
Validation loss: 2.8524661482231233

Epoch: 5| Step: 1
Training loss: 3.763661992802932
Validation loss: 2.850645771636714

Epoch: 5| Step: 2
Training loss: 3.3356230183295827
Validation loss: 2.849655186422521

Epoch: 5| Step: 3
Training loss: 3.1419066286060153
Validation loss: 2.8518172117329055

Epoch: 5| Step: 4
Training loss: 3.04298818089913
Validation loss: 2.852725276188392

Epoch: 5| Step: 5
Training loss: 3.5626271543062975
Validation loss: 2.8474822345752666

Epoch: 5| Step: 6
Training loss: 3.173638365721494
Validation loss: 2.849393439102595

Epoch: 5| Step: 7
Training loss: 1.9534978892088188
Validation loss: 2.849512993358347

Epoch: 5| Step: 8
Training loss: 3.152378540603402
Validation loss: 2.848737207138219

Epoch: 5| Step: 9
Training loss: 3.244025681381077
Validation loss: 2.8501589429424428

Epoch: 5| Step: 10
Training loss: 2.781276745614028
Validation loss: 2.850476227827966

Epoch: 57| Step: 0
Training loss: 3.0448058316065176
Validation loss: 2.852984545956947

Epoch: 5| Step: 1
Training loss: 3.2531061734434368
Validation loss: 2.85205075742978

Epoch: 5| Step: 2
Training loss: 3.2935298201857286
Validation loss: 2.849413785173992

Epoch: 5| Step: 3
Training loss: 2.4965358575422836
Validation loss: 2.8498273527697107

Epoch: 5| Step: 4
Training loss: 2.813258090105309
Validation loss: 2.8478715470502305

Epoch: 5| Step: 5
Training loss: 3.8329237152398616
Validation loss: 2.845033538293107

Epoch: 5| Step: 6
Training loss: 3.4043792346965125
Validation loss: 2.845724261397781

Epoch: 5| Step: 7
Training loss: 2.7650094936821805
Validation loss: 2.843221789136711

Epoch: 5| Step: 8
Training loss: 3.2489619431267185
Validation loss: 2.840695734762318

Epoch: 5| Step: 9
Training loss: 3.0271978921515967
Validation loss: 2.839853428259383

Epoch: 5| Step: 10
Training loss: 3.3684432305841905
Validation loss: 2.838184531938265

Epoch: 58| Step: 0
Training loss: 3.09387083491927
Validation loss: 2.8379691946669747

Epoch: 5| Step: 1
Training loss: 3.179873749248109
Validation loss: 2.8363230896333276

Epoch: 5| Step: 2
Training loss: 3.2244807217104925
Validation loss: 2.8311937699944276

Epoch: 5| Step: 3
Training loss: 3.4164015659358613
Validation loss: 2.830991061550541

Epoch: 5| Step: 4
Training loss: 2.5200015080159837
Validation loss: 2.828426011706617

Epoch: 5| Step: 5
Training loss: 3.351092823615573
Validation loss: 2.8261795581868787

Epoch: 5| Step: 6
Training loss: 3.2491522930564707
Validation loss: 2.8263844593511216

Epoch: 5| Step: 7
Training loss: 2.4159907568697925
Validation loss: 2.8188225490185985

Epoch: 5| Step: 8
Training loss: 3.263439998916156
Validation loss: 2.8235418711626568

Epoch: 5| Step: 9
Training loss: 3.0566136368117665
Validation loss: 2.8259427830680286

Epoch: 5| Step: 10
Training loss: 3.4707958614773555
Validation loss: 2.842292883821331

Epoch: 59| Step: 0
Training loss: 2.9490877842402847
Validation loss: 2.862888417515463

Epoch: 5| Step: 1
Training loss: 3.045641527168245
Validation loss: 2.859576540888556

Epoch: 5| Step: 2
Training loss: 3.1249642942296094
Validation loss: 2.85600678872409

Epoch: 5| Step: 3
Training loss: 3.9236483876906005
Validation loss: 2.8329448810671565

Epoch: 5| Step: 4
Training loss: 2.4687589814227944
Validation loss: 2.814371424796398

Epoch: 5| Step: 5
Training loss: 2.501617957125321
Validation loss: 2.817431313540175

Epoch: 5| Step: 6
Training loss: 3.280928096421676
Validation loss: 2.8281419570297555

Epoch: 5| Step: 7
Training loss: 2.9020258240342756
Validation loss: 2.8421472619076757

Epoch: 5| Step: 8
Training loss: 3.730019171821475
Validation loss: 2.855471996443957

Epoch: 5| Step: 9
Training loss: 2.9987982886220084
Validation loss: 2.843240996392566

Epoch: 5| Step: 10
Training loss: 3.3906152962400746
Validation loss: 2.8377911704022907

Epoch: 60| Step: 0
Training loss: 3.258385916543332
Validation loss: 2.8294638922260344

Epoch: 5| Step: 1
Training loss: 2.773688334552728
Validation loss: 2.8192330366743037

Epoch: 5| Step: 2
Training loss: 3.43509409546553
Validation loss: 2.82433613305564

Epoch: 5| Step: 3
Training loss: 3.5833788284843924
Validation loss: 2.8264935957919985

Epoch: 5| Step: 4
Training loss: 3.393776971137287
Validation loss: 2.8274329841385

Epoch: 5| Step: 5
Training loss: 3.0876852373780057
Validation loss: 2.8285574851168653

Epoch: 5| Step: 6
Training loss: 2.906374364673594
Validation loss: 2.823400902639883

Epoch: 5| Step: 7
Training loss: 3.111113555846692
Validation loss: 2.821386697251445

Epoch: 5| Step: 8
Training loss: 3.080839557663774
Validation loss: 2.8139975203652807

Epoch: 5| Step: 9
Training loss: 2.682160951460101
Validation loss: 2.81353606233802

Epoch: 5| Step: 10
Training loss: 3.029053669063313
Validation loss: 2.812589923328054

Epoch: 61| Step: 0
Training loss: 2.6777151428466897
Validation loss: 2.8072082286744098

Epoch: 5| Step: 1
Training loss: 3.259646697529105
Validation loss: 2.8057988392079363

Epoch: 5| Step: 2
Training loss: 3.1235801522987163
Validation loss: 2.804111516288563

Epoch: 5| Step: 3
Training loss: 2.6595531793919203
Validation loss: 2.8035841164317734

Epoch: 5| Step: 4
Training loss: 3.2286559326552164
Validation loss: 2.8042354630215596

Epoch: 5| Step: 5
Training loss: 2.892052869996751
Validation loss: 2.8017956635252905

Epoch: 5| Step: 6
Training loss: 2.9675692167621657
Validation loss: 2.8020111951787707

Epoch: 5| Step: 7
Training loss: 3.5176982276657633
Validation loss: 2.8011892380292562

Epoch: 5| Step: 8
Training loss: 3.301493370390352
Validation loss: 2.8068361192213174

Epoch: 5| Step: 9
Training loss: 3.199606847453525
Validation loss: 2.821402827482198

Epoch: 5| Step: 10
Training loss: 3.3739760929655858
Validation loss: 2.8371825109561915

Epoch: 62| Step: 0
Training loss: 3.2930518668150643
Validation loss: 2.7963761268393825

Epoch: 5| Step: 1
Training loss: 2.643834257474105
Validation loss: 2.8015534793196157

Epoch: 5| Step: 2
Training loss: 3.573362687782686
Validation loss: 2.805945472245892

Epoch: 5| Step: 3
Training loss: 2.968791118136303
Validation loss: 2.818057267098971

Epoch: 5| Step: 4
Training loss: 2.986708921775044
Validation loss: 2.819092315565592

Epoch: 5| Step: 5
Training loss: 2.741360357579321
Validation loss: 2.8226753149549046

Epoch: 5| Step: 6
Training loss: 3.189670197948322
Validation loss: 2.8497157615912987

Epoch: 5| Step: 7
Training loss: 2.9195576826598115
Validation loss: 2.8663232361414877

Epoch: 5| Step: 8
Training loss: 3.149820861566724
Validation loss: 2.858725442799395

Epoch: 5| Step: 9
Training loss: 3.7070223744872015
Validation loss: 2.8450795396348343

Epoch: 5| Step: 10
Training loss: 3.2930492603962795
Validation loss: 2.8255381896327685

Epoch: 63| Step: 0
Training loss: 3.610969752617888
Validation loss: 2.8014057936945447

Epoch: 5| Step: 1
Training loss: 2.792858969925104
Validation loss: 2.7923141069114314

Epoch: 5| Step: 2
Training loss: 3.2162556288455315
Validation loss: 2.7929344426985354

Epoch: 5| Step: 3
Training loss: 2.5950649559108783
Validation loss: 2.7976830408805387

Epoch: 5| Step: 4
Training loss: 3.0390475942054924
Validation loss: 2.8062006300729028

Epoch: 5| Step: 5
Training loss: 2.5315366041146654
Validation loss: 2.807733145396425

Epoch: 5| Step: 6
Training loss: 2.95556717259252
Validation loss: 2.812737855686405

Epoch: 5| Step: 7
Training loss: 3.258099806304183
Validation loss: 2.8195395038827518

Epoch: 5| Step: 8
Training loss: 3.2110064051304947
Validation loss: 2.8111629283945065

Epoch: 5| Step: 9
Training loss: 3.720361953272086
Validation loss: 2.797174405284652

Epoch: 5| Step: 10
Training loss: 3.205375810987012
Validation loss: 2.7961156853234828

Epoch: 64| Step: 0
Training loss: 2.5044964408704526
Validation loss: 2.786992323530259

Epoch: 5| Step: 1
Training loss: 3.4274825739956643
Validation loss: 2.7920378094070046

Epoch: 5| Step: 2
Training loss: 3.1102345874295034
Validation loss: 2.78507187423886

Epoch: 5| Step: 3
Training loss: 3.4807843922529247
Validation loss: 2.796387376531675

Epoch: 5| Step: 4
Training loss: 3.4829019075523555
Validation loss: 2.8008071107145724

Epoch: 5| Step: 5
Training loss: 2.6114999490614115
Validation loss: 2.802444188357712

Epoch: 5| Step: 6
Training loss: 3.26012501412554
Validation loss: 2.7908181407141393

Epoch: 5| Step: 7
Training loss: 2.8493101657085624
Validation loss: 2.7855465129763863

Epoch: 5| Step: 8
Training loss: 3.126400595556962
Validation loss: 2.778491691469357

Epoch: 5| Step: 9
Training loss: 2.8155739833600406
Validation loss: 2.7745077630603814

Epoch: 5| Step: 10
Training loss: 3.323904881076964
Validation loss: 2.7800127415760847

Epoch: 65| Step: 0
Training loss: 3.2218846732585447
Validation loss: 2.7824939325517075

Epoch: 5| Step: 1
Training loss: 3.428479375057594
Validation loss: 2.7812159638616825

Epoch: 5| Step: 2
Training loss: 3.01328166776718
Validation loss: 2.780105567368383

Epoch: 5| Step: 3
Training loss: 3.157783815460315
Validation loss: 2.7817469161362567

Epoch: 5| Step: 4
Training loss: 2.96175580556234
Validation loss: 2.7805391209461057

Epoch: 5| Step: 5
Training loss: 2.60294999247586
Validation loss: 2.7793890172387408

Epoch: 5| Step: 6
Training loss: 3.4142988110078485
Validation loss: 2.779601514309574

Epoch: 5| Step: 7
Training loss: 2.900197114493682
Validation loss: 2.7773745964758834

Epoch: 5| Step: 8
Training loss: 3.4376226229904443
Validation loss: 2.77865801038343

Epoch: 5| Step: 9
Training loss: 2.933608541438659
Validation loss: 2.7779667236985333

Epoch: 5| Step: 10
Training loss: 2.9759613791800277
Validation loss: 2.778279084599477

Epoch: 66| Step: 0
Training loss: 3.0913335437337204
Validation loss: 2.776564387586751

Epoch: 5| Step: 1
Training loss: 2.6889843057704312
Validation loss: 2.773836600349923

Epoch: 5| Step: 2
Training loss: 3.16840552389412
Validation loss: 2.7742318378843382

Epoch: 5| Step: 3
Training loss: 2.8462530166415654
Validation loss: 2.771261411751766

Epoch: 5| Step: 4
Training loss: 3.076164279504512
Validation loss: 2.770348454574134

Epoch: 5| Step: 5
Training loss: 2.9236627505210273
Validation loss: 2.7700426680783465

Epoch: 5| Step: 6
Training loss: 2.9947419181782826
Validation loss: 2.7727631269697253

Epoch: 5| Step: 7
Training loss: 2.9786587440000587
Validation loss: 2.775855972299632

Epoch: 5| Step: 8
Training loss: 2.8640327248115556
Validation loss: 2.7697645496664647

Epoch: 5| Step: 9
Training loss: 3.5833951959518915
Validation loss: 2.77753027743086

Epoch: 5| Step: 10
Training loss: 3.8086226711642297
Validation loss: 2.780910016275541

Epoch: 67| Step: 0
Training loss: 3.4269894912687726
Validation loss: 2.7702065560099167

Epoch: 5| Step: 1
Training loss: 3.1887469377132893
Validation loss: 2.761604005124235

Epoch: 5| Step: 2
Training loss: 3.1224131749392456
Validation loss: 2.7611236991762365

Epoch: 5| Step: 3
Training loss: 2.654870696142945
Validation loss: 2.7590701548874237

Epoch: 5| Step: 4
Training loss: 2.9803527569479367
Validation loss: 2.7589630020429095

Epoch: 5| Step: 5
Training loss: 2.596956591925294
Validation loss: 2.7570337730315297

Epoch: 5| Step: 6
Training loss: 3.115249681584653
Validation loss: 2.761410318236491

Epoch: 5| Step: 7
Training loss: 3.0138258236460644
Validation loss: 2.7573459633488184

Epoch: 5| Step: 8
Training loss: 3.206893267433598
Validation loss: 2.7572847303060297

Epoch: 5| Step: 9
Training loss: 3.1413036011852364
Validation loss: 2.759722647525225

Epoch: 5| Step: 10
Training loss: 3.438015430995004
Validation loss: 2.763403416733018

Epoch: 68| Step: 0
Training loss: 2.224972341129823
Validation loss: 2.7593509231947926

Epoch: 5| Step: 1
Training loss: 2.7989687621406585
Validation loss: 2.762146863340243

Epoch: 5| Step: 2
Training loss: 3.449628621996824
Validation loss: 2.756098476316347

Epoch: 5| Step: 3
Training loss: 3.203960030733848
Validation loss: 2.758141388655693

Epoch: 5| Step: 4
Training loss: 3.3512711120418546
Validation loss: 2.75329739087217

Epoch: 5| Step: 5
Training loss: 2.989267383499052
Validation loss: 2.756989342359303

Epoch: 5| Step: 6
Training loss: 3.405319506741352
Validation loss: 2.757603942780672

Epoch: 5| Step: 7
Training loss: 3.3395731855410014
Validation loss: 2.75937685909698

Epoch: 5| Step: 8
Training loss: 2.667157654463993
Validation loss: 2.7682401633945948

Epoch: 5| Step: 9
Training loss: 3.432107336780014
Validation loss: 2.7721625048403054

Epoch: 5| Step: 10
Training loss: 2.658723285578502
Validation loss: 2.785280396417282

Epoch: 69| Step: 0
Training loss: 2.6745121305985413
Validation loss: 2.7867399708000464

Epoch: 5| Step: 1
Training loss: 2.86688380490987
Validation loss: 2.7890797308289623

Epoch: 5| Step: 2
Training loss: 2.777304776504415
Validation loss: 2.7817188036977574

Epoch: 5| Step: 3
Training loss: 3.0915153987377004
Validation loss: 2.7544778973386213

Epoch: 5| Step: 4
Training loss: 3.7060422070359684
Validation loss: 2.7511510975535254

Epoch: 5| Step: 5
Training loss: 3.2595500017623995
Validation loss: 2.7493892701873968

Epoch: 5| Step: 6
Training loss: 3.2537016695516754
Validation loss: 2.751528232325186

Epoch: 5| Step: 7
Training loss: 2.9620552469545096
Validation loss: 2.751155155726391

Epoch: 5| Step: 8
Training loss: 3.031408089516815
Validation loss: 2.7581139204897673

Epoch: 5| Step: 9
Training loss: 2.850508487246487
Validation loss: 2.7594669109750587

Epoch: 5| Step: 10
Training loss: 3.3341519939923208
Validation loss: 2.7611945633671655

Epoch: 70| Step: 0
Training loss: 3.080199805875621
Validation loss: 2.7555684236755735

Epoch: 5| Step: 1
Training loss: 3.2244938830298278
Validation loss: 2.7476061612706277

Epoch: 5| Step: 2
Training loss: 3.153529590550722
Validation loss: 2.7845901963136264

Epoch: 5| Step: 3
Training loss: 2.648082698135723
Validation loss: 2.7980145967184242

Epoch: 5| Step: 4
Training loss: 3.081594457968366
Validation loss: 2.7530843529512765

Epoch: 5| Step: 5
Training loss: 3.0250917783323508
Validation loss: 2.746238442237378

Epoch: 5| Step: 6
Training loss: 2.980595617231474
Validation loss: 2.741595146512304

Epoch: 5| Step: 7
Training loss: 2.3672161037617965
Validation loss: 2.7511125739662026

Epoch: 5| Step: 8
Training loss: 3.121458411845707
Validation loss: 2.758838651245733

Epoch: 5| Step: 9
Training loss: 3.7269999569216585
Validation loss: 2.7697717756656335

Epoch: 5| Step: 10
Training loss: 3.394222618620266
Validation loss: 2.7419778880291377

Epoch: 71| Step: 0
Training loss: 3.5754051032325944
Validation loss: 2.7523647984316795

Epoch: 5| Step: 1
Training loss: 2.6805056554688043
Validation loss: 2.75481691450435

Epoch: 5| Step: 2
Training loss: 3.3540937206478962
Validation loss: 2.7455359534397292

Epoch: 5| Step: 3
Training loss: 2.6601005918082907
Validation loss: 2.745874413681204

Epoch: 5| Step: 4
Training loss: 2.9988227759717665
Validation loss: 2.739008983937259

Epoch: 5| Step: 5
Training loss: 2.9354815751843972
Validation loss: 2.737746740213841

Epoch: 5| Step: 6
Training loss: 2.63787201702978
Validation loss: 2.7348950047754905

Epoch: 5| Step: 7
Training loss: 3.375749575416229
Validation loss: 2.732506672803262

Epoch: 5| Step: 8
Training loss: 3.0750546706387176
Validation loss: 2.729972131211179

Epoch: 5| Step: 9
Training loss: 3.2219089450768483
Validation loss: 2.7278974660272377

Epoch: 5| Step: 10
Training loss: 3.1492269203119796
Validation loss: 2.7344620098093584

Epoch: 72| Step: 0
Training loss: 2.624459528914228
Validation loss: 2.7311355326168094

Epoch: 5| Step: 1
Training loss: 3.073139005904122
Validation loss: 2.7370394399604407

Epoch: 5| Step: 2
Training loss: 2.9744596487473767
Validation loss: 2.739979530999339

Epoch: 5| Step: 3
Training loss: 2.7418130907034906
Validation loss: 2.7458354500734043

Epoch: 5| Step: 4
Training loss: 3.2194901883775144
Validation loss: 2.7401047264296725

Epoch: 5| Step: 5
Training loss: 3.4920777169195216
Validation loss: 2.7360709654361757

Epoch: 5| Step: 6
Training loss: 3.1270973796558663
Validation loss: 2.7303656510583556

Epoch: 5| Step: 7
Training loss: 3.3270091303937153
Validation loss: 2.726051367984371

Epoch: 5| Step: 8
Training loss: 2.8774314218629806
Validation loss: 2.7211565977032803

Epoch: 5| Step: 9
Training loss: 3.078628266530242
Validation loss: 2.722247195873958

Epoch: 5| Step: 10
Training loss: 3.0022409334626348
Validation loss: 2.7239141098106527

Epoch: 73| Step: 0
Training loss: 2.4973086175152086
Validation loss: 2.7201473401404495

Epoch: 5| Step: 1
Training loss: 2.8908031511825083
Validation loss: 2.718295630691777

Epoch: 5| Step: 2
Training loss: 3.1499716379009
Validation loss: 2.720556922016498

Epoch: 5| Step: 3
Training loss: 3.1168555367372495
Validation loss: 2.72318452793512

Epoch: 5| Step: 4
Training loss: 3.1257735248709526
Validation loss: 2.7226123703585774

Epoch: 5| Step: 5
Training loss: 3.0850442486871112
Validation loss: 2.72977573224402

Epoch: 5| Step: 6
Training loss: 3.2892558931229927
Validation loss: 2.723063652562391

Epoch: 5| Step: 7
Training loss: 3.1988227049483178
Validation loss: 2.7234518826219705

Epoch: 5| Step: 8
Training loss: 3.0591309369220205
Validation loss: 2.720372062314181

Epoch: 5| Step: 9
Training loss: 2.974832828216564
Validation loss: 2.7234484797468372

Epoch: 5| Step: 10
Training loss: 3.119650419898134
Validation loss: 2.720984237137725

Epoch: 74| Step: 0
Training loss: 3.1844990385116683
Validation loss: 2.7180768566867606

Epoch: 5| Step: 1
Training loss: 3.2331708795170764
Validation loss: 2.7183810323046145

Epoch: 5| Step: 2
Training loss: 3.164002519203852
Validation loss: 2.7178970562367253

Epoch: 5| Step: 3
Training loss: 3.0812430298515547
Validation loss: 2.7326754640323143

Epoch: 5| Step: 4
Training loss: 3.5263878761768495
Validation loss: 2.745737607741552

Epoch: 5| Step: 5
Training loss: 3.215350680054594
Validation loss: 2.7473939720761416

Epoch: 5| Step: 6
Training loss: 2.795830302419218
Validation loss: 2.72418427256274

Epoch: 5| Step: 7
Training loss: 2.592018192733686
Validation loss: 2.7110385510087434

Epoch: 5| Step: 8
Training loss: 2.94043633629064
Validation loss: 2.712870480682415

Epoch: 5| Step: 9
Training loss: 2.891757392742594
Validation loss: 2.709125749951881

Epoch: 5| Step: 10
Training loss: 2.7491109451269775
Validation loss: 2.709091955542224

Epoch: 75| Step: 0
Training loss: 3.5044327322291746
Validation loss: 2.710469865799838

Epoch: 5| Step: 1
Training loss: 2.8886317623672855
Validation loss: 2.7097183015152075

Epoch: 5| Step: 2
Training loss: 3.1462141568578876
Validation loss: 2.7103678846131483

Epoch: 5| Step: 3
Training loss: 3.1569803733662685
Validation loss: 2.7093789457351645

Epoch: 5| Step: 4
Training loss: 2.847925160378378
Validation loss: 2.7155859119790122

Epoch: 5| Step: 5
Training loss: 3.061884604145225
Validation loss: 2.7140680342324

Epoch: 5| Step: 6
Training loss: 3.240422147399838
Validation loss: 2.719934139856826

Epoch: 5| Step: 7
Training loss: 2.8552747000369156
Validation loss: 2.7146841454807604

Epoch: 5| Step: 8
Training loss: 3.2751578314801804
Validation loss: 2.717483732929887

Epoch: 5| Step: 9
Training loss: 2.880735895129116
Validation loss: 2.718446739406306

Epoch: 5| Step: 10
Training loss: 2.444735718000103
Validation loss: 2.730137546565637

Epoch: 76| Step: 0
Training loss: 3.333746948011937
Validation loss: 2.7281252964214464

Epoch: 5| Step: 1
Training loss: 2.9561288885426276
Validation loss: 2.720007323159307

Epoch: 5| Step: 2
Training loss: 3.5712229696765654
Validation loss: 2.7188446571581966

Epoch: 5| Step: 3
Training loss: 3.1422286612813255
Validation loss: 2.717329997900836

Epoch: 5| Step: 4
Training loss: 2.8506463238186837
Validation loss: 2.718511246327585

Epoch: 5| Step: 5
Training loss: 2.9494633655280897
Validation loss: 2.711747900439511

Epoch: 5| Step: 6
Training loss: 3.161868693550367
Validation loss: 2.7135505146273413

Epoch: 5| Step: 7
Training loss: 2.859312296529015
Validation loss: 2.705027336525493

Epoch: 5| Step: 8
Training loss: 2.5288489928317475
Validation loss: 2.7002709067862676

Epoch: 5| Step: 9
Training loss: 2.9532170357062064
Validation loss: 2.7036937632371516

Epoch: 5| Step: 10
Training loss: 2.98698000033477
Validation loss: 2.703212412508449

Epoch: 77| Step: 0
Training loss: 2.9125995799055886
Validation loss: 2.7044664542473

Epoch: 5| Step: 1
Training loss: 3.153391837557895
Validation loss: 2.703417826941802

Epoch: 5| Step: 2
Training loss: 2.8600849875247163
Validation loss: 2.7019739620816257

Epoch: 5| Step: 3
Training loss: 3.504925259651713
Validation loss: 2.7061299077970444

Epoch: 5| Step: 4
Training loss: 3.154103068252706
Validation loss: 2.701817894683966

Epoch: 5| Step: 5
Training loss: 2.8894103101338198
Validation loss: 2.704904763584741

Epoch: 5| Step: 6
Training loss: 2.9131190022846933
Validation loss: 2.7012745269891707

Epoch: 5| Step: 7
Training loss: 3.1261095747435377
Validation loss: 2.703474247127299

Epoch: 5| Step: 8
Training loss: 3.3709474887701676
Validation loss: 2.704065841397212

Epoch: 5| Step: 9
Training loss: 2.2217292662737256
Validation loss: 2.698736511806849

Epoch: 5| Step: 10
Training loss: 3.0940788941931023
Validation loss: 2.699867299433431

Epoch: 78| Step: 0
Training loss: 2.9789548856425068
Validation loss: 2.6994815370408975

Epoch: 5| Step: 1
Training loss: 2.6539354001011697
Validation loss: 2.7009406415190846

Epoch: 5| Step: 2
Training loss: 2.991598763576333
Validation loss: 2.6991288251004444

Epoch: 5| Step: 3
Training loss: 2.9949363253389
Validation loss: 2.699000621446996

Epoch: 5| Step: 4
Training loss: 3.106333716509737
Validation loss: 2.700085726364145

Epoch: 5| Step: 5
Training loss: 3.096687078692693
Validation loss: 2.702321101057469

Epoch: 5| Step: 6
Training loss: 3.1588916865440155
Validation loss: 2.6972700094642255

Epoch: 5| Step: 7
Training loss: 3.2482562155366472
Validation loss: 2.7028978394470964

Epoch: 5| Step: 8
Training loss: 3.0973418991467443
Validation loss: 2.706786071691135

Epoch: 5| Step: 9
Training loss: 2.9713293816181645
Validation loss: 2.70126120231486

Epoch: 5| Step: 10
Training loss: 2.9236854207513776
Validation loss: 2.7103368676485426

Epoch: 79| Step: 0
Training loss: 2.7151626948440226
Validation loss: 2.703271953252167

Epoch: 5| Step: 1
Training loss: 3.3064805525526957
Validation loss: 2.7086107151424637

Epoch: 5| Step: 2
Training loss: 2.740592818903136
Validation loss: 2.69832017467041

Epoch: 5| Step: 3
Training loss: 3.009465543626703
Validation loss: 2.6971539874675745

Epoch: 5| Step: 4
Training loss: 3.084506627823153
Validation loss: 2.6873762813402444

Epoch: 5| Step: 5
Training loss: 3.1644641009117915
Validation loss: 2.6866988442405844

Epoch: 5| Step: 6
Training loss: 3.322514636234972
Validation loss: 2.687923637439074

Epoch: 5| Step: 7
Training loss: 2.77932449723844
Validation loss: 2.68495931817168

Epoch: 5| Step: 8
Training loss: 3.0860756372365725
Validation loss: 2.688004197684747

Epoch: 5| Step: 9
Training loss: 3.5120530356571433
Validation loss: 2.6877568573627815

Epoch: 5| Step: 10
Training loss: 2.2372451168206933
Validation loss: 2.6856918662747815

Epoch: 80| Step: 0
Training loss: 2.7485786579570632
Validation loss: 2.6864642050027476

Epoch: 5| Step: 1
Training loss: 2.6326388972519523
Validation loss: 2.69164612022926

Epoch: 5| Step: 2
Training loss: 2.360778795180817
Validation loss: 2.7062502218206252

Epoch: 5| Step: 3
Training loss: 3.007393626982059
Validation loss: 2.702922871577191

Epoch: 5| Step: 4
Training loss: 3.108732991097261
Validation loss: 2.718631960114825

Epoch: 5| Step: 5
Training loss: 2.9524981120957063
Validation loss: 2.710517443411639

Epoch: 5| Step: 6
Training loss: 3.2292862080422893
Validation loss: 2.688947910481125

Epoch: 5| Step: 7
Training loss: 3.257284656822503
Validation loss: 2.6808259401039654

Epoch: 5| Step: 8
Training loss: 3.345060715516345
Validation loss: 2.676971167615889

Epoch: 5| Step: 9
Training loss: 2.990081284862987
Validation loss: 2.6777510699442257

Epoch: 5| Step: 10
Training loss: 3.4838208497736893
Validation loss: 2.6743821420072775

Epoch: 81| Step: 0
Training loss: 3.0860808906559587
Validation loss: 2.676591543502882

Epoch: 5| Step: 1
Training loss: 3.3578185268257483
Validation loss: 2.6797729122685237

Epoch: 5| Step: 2
Training loss: 3.11270668538504
Validation loss: 2.6846319024941208

Epoch: 5| Step: 3
Training loss: 2.5427504766634623
Validation loss: 2.6827429498817508

Epoch: 5| Step: 4
Training loss: 2.383270919978494
Validation loss: 2.6801124091650115

Epoch: 5| Step: 5
Training loss: 2.4143001106136093
Validation loss: 2.679706777312372

Epoch: 5| Step: 6
Training loss: 2.915480199818244
Validation loss: 2.6751487243605867

Epoch: 5| Step: 7
Training loss: 3.0665029717030876
Validation loss: 2.6749332179666436

Epoch: 5| Step: 8
Training loss: 3.427962649316626
Validation loss: 2.6792715622748555

Epoch: 5| Step: 9
Training loss: 3.462600756119142
Validation loss: 2.675893699678973

Epoch: 5| Step: 10
Training loss: 3.238799823243781
Validation loss: 2.689369561572787

Epoch: 82| Step: 0
Training loss: 2.625318053822818
Validation loss: 2.688500283310514

Epoch: 5| Step: 1
Training loss: 3.2593772295672654
Validation loss: 2.7059330459814874

Epoch: 5| Step: 2
Training loss: 2.601942063327992
Validation loss: 2.706461341038444

Epoch: 5| Step: 3
Training loss: 3.4409438481825325
Validation loss: 2.702090236319676

Epoch: 5| Step: 4
Training loss: 3.4800853924852557
Validation loss: 2.7090910518160842

Epoch: 5| Step: 5
Training loss: 3.6071181073884198
Validation loss: 2.6954649789513514

Epoch: 5| Step: 6
Training loss: 2.68286869299042
Validation loss: 2.6789807238099415

Epoch: 5| Step: 7
Training loss: 3.1574244061117374
Validation loss: 2.680459511550354

Epoch: 5| Step: 8
Training loss: 2.7576698504072628
Validation loss: 2.677629615152172

Epoch: 5| Step: 9
Training loss: 3.0110804652038325
Validation loss: 2.681047360312736

Epoch: 5| Step: 10
Training loss: 2.0961414173918045
Validation loss: 2.6813684875756785

Epoch: 83| Step: 0
Training loss: 3.321893580358726
Validation loss: 2.6852380496613977

Epoch: 5| Step: 1
Training loss: 2.8260602632429324
Validation loss: 2.680955626780443

Epoch: 5| Step: 2
Training loss: 2.9845882958688628
Validation loss: 2.6809605074318656

Epoch: 5| Step: 3
Training loss: 3.142265233122132
Validation loss: 2.6790997604977203

Epoch: 5| Step: 4
Training loss: 3.269431783787937
Validation loss: 2.680723598162863

Epoch: 5| Step: 5
Training loss: 3.0731591770148365
Validation loss: 2.678961065190401

Epoch: 5| Step: 6
Training loss: 2.505308808805419
Validation loss: 2.6750911432608993

Epoch: 5| Step: 7
Training loss: 3.1850079537236957
Validation loss: 2.6721957031708006

Epoch: 5| Step: 8
Training loss: 2.300902902596129
Validation loss: 2.6703710693291

Epoch: 5| Step: 9
Training loss: 3.172258175410305
Validation loss: 2.6658330695666104

Epoch: 5| Step: 10
Training loss: 3.2029401027999294
Validation loss: 2.6764400908500243

Epoch: 84| Step: 0
Training loss: 3.4199860118557592
Validation loss: 2.6979627565327213

Epoch: 5| Step: 1
Training loss: 3.2315077304431847
Validation loss: 2.7381479436445852

Epoch: 5| Step: 2
Training loss: 3.101625994361494
Validation loss: 2.718379867605176

Epoch: 5| Step: 3
Training loss: 2.7820566272087004
Validation loss: 2.675568233089133

Epoch: 5| Step: 4
Training loss: 3.3835751420475835
Validation loss: 2.670112842901975

Epoch: 5| Step: 5
Training loss: 2.543028753132338
Validation loss: 2.6732989795210176

Epoch: 5| Step: 6
Training loss: 3.005288072891185
Validation loss: 2.679636056162804

Epoch: 5| Step: 7
Training loss: 2.292214264612669
Validation loss: 2.683978666791318

Epoch: 5| Step: 8
Training loss: 3.0886456545499223
Validation loss: 2.699716017770572

Epoch: 5| Step: 9
Training loss: 2.8468041420586325
Validation loss: 2.709722071686011

Epoch: 5| Step: 10
Training loss: 3.4506512234601163
Validation loss: 2.70474404084179

Epoch: 85| Step: 0
Training loss: 2.748665052127418
Validation loss: 2.6988601599528277

Epoch: 5| Step: 1
Training loss: 3.2636803490501896
Validation loss: 2.698912289826543

Epoch: 5| Step: 2
Training loss: 2.2822513211710627
Validation loss: 2.6990949796084047

Epoch: 5| Step: 3
Training loss: 3.322240507556801
Validation loss: 2.7021140596293924

Epoch: 5| Step: 4
Training loss: 3.2410182085287853
Validation loss: 2.700848418040885

Epoch: 5| Step: 5
Training loss: 2.622954343525677
Validation loss: 2.7099916929424857

Epoch: 5| Step: 6
Training loss: 3.0438345582092703
Validation loss: 2.7141501958948777

Epoch: 5| Step: 7
Training loss: 3.12565880506786
Validation loss: 2.7167244771481873

Epoch: 5| Step: 8
Training loss: 2.6268925883185146
Validation loss: 2.719103040487781

Epoch: 5| Step: 9
Training loss: 3.4004513440963824
Validation loss: 2.7098651479198708

Epoch: 5| Step: 10
Training loss: 3.4690848523976414
Validation loss: 2.6992441838071484

Epoch: 86| Step: 0
Training loss: 3.1529423973660538
Validation loss: 2.695966608692895

Epoch: 5| Step: 1
Training loss: 3.3275835196705885
Validation loss: 2.700255266304405

Epoch: 5| Step: 2
Training loss: 3.1094466158033267
Validation loss: 2.6972821363248007

Epoch: 5| Step: 3
Training loss: 3.458444631846144
Validation loss: 2.6933549508553534

Epoch: 5| Step: 4
Training loss: 3.0932200584827774
Validation loss: 2.6884260821335393

Epoch: 5| Step: 5
Training loss: 3.1709827991068393
Validation loss: 2.6911895220337576

Epoch: 5| Step: 6
Training loss: 2.7408270871199587
Validation loss: 2.689459068320429

Epoch: 5| Step: 7
Training loss: 2.7624559942684654
Validation loss: 2.6921057397062667

Epoch: 5| Step: 8
Training loss: 2.441328026090583
Validation loss: 2.691108080693502

Epoch: 5| Step: 9
Training loss: 3.1248043762012316
Validation loss: 2.6928834160652877

Epoch: 5| Step: 10
Training loss: 2.733089384574886
Validation loss: 2.701937981339823

Epoch: 87| Step: 0
Training loss: 3.0038741845452095
Validation loss: 2.7096392156517326

Epoch: 5| Step: 1
Training loss: 3.127801173747321
Validation loss: 2.709497704750303

Epoch: 5| Step: 2
Training loss: 3.0443588431205075
Validation loss: 2.6928714398056703

Epoch: 5| Step: 3
Training loss: 3.2023843048423903
Validation loss: 2.68454349917315

Epoch: 5| Step: 4
Training loss: 3.1542509187828696
Validation loss: 2.6823451701792758

Epoch: 5| Step: 5
Training loss: 2.829958495250216
Validation loss: 2.6807623462235117

Epoch: 5| Step: 6
Training loss: 3.1213995983004974
Validation loss: 2.6778775299526103

Epoch: 5| Step: 7
Training loss: 2.3154038420175516
Validation loss: 2.6764423877845336

Epoch: 5| Step: 8
Training loss: 3.185524571455873
Validation loss: 2.6817264798123572

Epoch: 5| Step: 9
Training loss: 3.0873575154527626
Validation loss: 2.6806773881831125

Epoch: 5| Step: 10
Training loss: 2.9427820967259937
Validation loss: 2.679441922648268

Epoch: 88| Step: 0
Training loss: 2.8559172522046974
Validation loss: 2.67985742640625

Epoch: 5| Step: 1
Training loss: 2.430788042363417
Validation loss: 2.6805600263639873

Epoch: 5| Step: 2
Training loss: 2.4550064549875956
Validation loss: 2.6835633769781424

Epoch: 5| Step: 3
Training loss: 3.176758262805455
Validation loss: 2.682373092152995

Epoch: 5| Step: 4
Training loss: 2.8758293282558247
Validation loss: 2.6791759815825062

Epoch: 5| Step: 5
Training loss: 3.422932500603324
Validation loss: 2.683227038266959

Epoch: 5| Step: 6
Training loss: 3.2963231786504053
Validation loss: 2.6806966870670546

Epoch: 5| Step: 7
Training loss: 3.2803613821848185
Validation loss: 2.677528657132608

Epoch: 5| Step: 8
Training loss: 3.2803613821848185
Validation loss: 2.677411277937712

Epoch: 5| Step: 9
Training loss: 3.006818968925407
Validation loss: 2.6768865412844796

Epoch: 5| Step: 10
Training loss: 2.9053797905953873
Validation loss: 2.675198564049483

Epoch: 89| Step: 0
Training loss: 2.9431652873342564
Validation loss: 2.6695993016771773

Epoch: 5| Step: 1
Training loss: 3.307722136750267
Validation loss: 2.6633737797509824

Epoch: 5| Step: 2
Training loss: 3.318899630461891
Validation loss: 2.659825456335912

Epoch: 5| Step: 3
Training loss: 3.4879277339588524
Validation loss: 2.652079531464032

Epoch: 5| Step: 4
Training loss: 3.2864324424598386
Validation loss: 2.6505831006689253

Epoch: 5| Step: 5
Training loss: 2.6476604931015904
Validation loss: 2.656756269452096

Epoch: 5| Step: 6
Training loss: 2.744449475919133
Validation loss: 2.6536479957469754

Epoch: 5| Step: 7
Training loss: 2.4823134403871934
Validation loss: 2.6536134856369

Epoch: 5| Step: 8
Training loss: 3.0182338360192706
Validation loss: 2.6427389169845403

Epoch: 5| Step: 9
Training loss: 2.587504854059504
Validation loss: 2.6457530455115186

Epoch: 5| Step: 10
Training loss: 2.8678107558718273
Validation loss: 2.647044435534783

Epoch: 90| Step: 0
Training loss: 2.4442541982812322
Validation loss: 2.6568988892981977

Epoch: 5| Step: 1
Training loss: 3.3657396217315956
Validation loss: 2.6803238382624417

Epoch: 5| Step: 2
Training loss: 1.9178918018948918
Validation loss: 2.6792696198840766

Epoch: 5| Step: 3
Training loss: 2.851655138157056
Validation loss: 2.7019574590286006

Epoch: 5| Step: 4
Training loss: 3.403251518090566
Validation loss: 2.6684489895292516

Epoch: 5| Step: 5
Training loss: 2.7658171506176314
Validation loss: 2.6639440963252112

Epoch: 5| Step: 6
Training loss: 3.142994760002213
Validation loss: 2.6432818896660164

Epoch: 5| Step: 7
Training loss: 3.475925618674136
Validation loss: 2.640593548280565

Epoch: 5| Step: 8
Training loss: 2.820205136947547
Validation loss: 2.6418619614796626

Epoch: 5| Step: 9
Training loss: 3.09202943988716
Validation loss: 2.641467343615004

Epoch: 5| Step: 10
Training loss: 3.1878471933404176
Validation loss: 2.6425739573242177

Epoch: 91| Step: 0
Training loss: 2.8453342929196133
Validation loss: 2.643454099078558

Epoch: 5| Step: 1
Training loss: 3.1043081742020204
Validation loss: 2.6397204572200677

Epoch: 5| Step: 2
Training loss: 2.432524469140804
Validation loss: 2.6474728093139617

Epoch: 5| Step: 3
Training loss: 2.6422251531172782
Validation loss: 2.6402485537821554

Epoch: 5| Step: 4
Training loss: 3.0849335787901295
Validation loss: 2.6411779050196453

Epoch: 5| Step: 5
Training loss: 3.2348944942479987
Validation loss: 2.638840231116728

Epoch: 5| Step: 6
Training loss: 3.23947081212011
Validation loss: 2.6444456010525665

Epoch: 5| Step: 7
Training loss: 3.3515629268192475
Validation loss: 2.6496612579983325

Epoch: 5| Step: 8
Training loss: 2.8945950026190213
Validation loss: 2.6462620148967337

Epoch: 5| Step: 9
Training loss: 2.8803761843196454
Validation loss: 2.646177581633687

Epoch: 5| Step: 10
Training loss: 2.9823363366192015
Validation loss: 2.6385850564869426

Epoch: 92| Step: 0
Training loss: 3.1012817563234223
Validation loss: 2.635726850793952

Epoch: 5| Step: 1
Training loss: 3.3984860471568403
Validation loss: 2.6362056236227653

Epoch: 5| Step: 2
Training loss: 3.5658874468624786
Validation loss: 2.6402465312204986

Epoch: 5| Step: 3
Training loss: 2.748191065147072
Validation loss: 2.639046633384001

Epoch: 5| Step: 4
Training loss: 3.017776907388708
Validation loss: 2.63552074493559

Epoch: 5| Step: 5
Training loss: 2.8631460202121444
Validation loss: 2.63837155792645

Epoch: 5| Step: 6
Training loss: 2.593027220983653
Validation loss: 2.6356634526818783

Epoch: 5| Step: 7
Training loss: 2.72893571725788
Validation loss: 2.6415940218033063

Epoch: 5| Step: 8
Training loss: 2.7798408624671467
Validation loss: 2.6402313109816635

Epoch: 5| Step: 9
Training loss: 2.9185702152141646
Validation loss: 2.651836860492315

Epoch: 5| Step: 10
Training loss: 2.8348391589199204
Validation loss: 2.638694209236431

Epoch: 93| Step: 0
Training loss: 2.7052236359498467
Validation loss: 2.6381878009148494

Epoch: 5| Step: 1
Training loss: 3.0464799673804506
Validation loss: 2.6355576421355345

Epoch: 5| Step: 2
Training loss: 3.0369979003858796
Validation loss: 2.636490399109215

Epoch: 5| Step: 3
Training loss: 3.2886072419114956
Validation loss: 2.6410425216138287

Epoch: 5| Step: 4
Training loss: 3.453663779641501
Validation loss: 2.641151720826427

Epoch: 5| Step: 5
Training loss: 2.5369311968322945
Validation loss: 2.6478288237651926

Epoch: 5| Step: 6
Training loss: 3.338707374749111
Validation loss: 2.666284923827134

Epoch: 5| Step: 7
Training loss: 2.7212243932904387
Validation loss: 2.668056762782955

Epoch: 5| Step: 8
Training loss: 2.66967781251786
Validation loss: 2.6717311808670297

Epoch: 5| Step: 9
Training loss: 2.9632044344982145
Validation loss: 2.673539441607763

Epoch: 5| Step: 10
Training loss: 2.796883183472665
Validation loss: 2.6464585048599414

Epoch: 94| Step: 0
Training loss: 2.413889264554354
Validation loss: 2.628366348066846

Epoch: 5| Step: 1
Training loss: 2.99769042440246
Validation loss: 2.6313792267627094

Epoch: 5| Step: 2
Training loss: 3.147265497732947
Validation loss: 2.634663793173661

Epoch: 5| Step: 3
Training loss: 3.193379533336604
Validation loss: 2.636759362008648

Epoch: 5| Step: 4
Training loss: 2.524722312538971
Validation loss: 2.6346895738165244

Epoch: 5| Step: 5
Training loss: 3.093090719240018
Validation loss: 2.632083404691192

Epoch: 5| Step: 6
Training loss: 2.6796023519350496
Validation loss: 2.63295905157303

Epoch: 5| Step: 7
Training loss: 3.146711231201681
Validation loss: 2.6483245979453667

Epoch: 5| Step: 8
Training loss: 3.309535301295706
Validation loss: 2.6698564312751367

Epoch: 5| Step: 9
Training loss: 3.2073118061566173
Validation loss: 2.6912125921231316

Epoch: 5| Step: 10
Training loss: 3.1748219597826837
Validation loss: 2.6912227305922993

Epoch: 95| Step: 0
Training loss: 2.5092696950439226
Validation loss: 2.688240481541166

Epoch: 5| Step: 1
Training loss: 3.0301703663887976
Validation loss: 2.670082483594145

Epoch: 5| Step: 2
Training loss: 3.167803476634425
Validation loss: 2.6504996078570806

Epoch: 5| Step: 3
Training loss: 2.899954262734526
Validation loss: 2.6404586810486217

Epoch: 5| Step: 4
Training loss: 2.8251931183559575
Validation loss: 2.6285657538002627

Epoch: 5| Step: 5
Training loss: 3.225703903383298
Validation loss: 2.623514304818693

Epoch: 5| Step: 6
Training loss: 3.2306522192742837
Validation loss: 2.621721764793842

Epoch: 5| Step: 7
Training loss: 2.874809922278932
Validation loss: 2.621701506676083

Epoch: 5| Step: 8
Training loss: 2.5575215429925695
Validation loss: 2.624117020579491

Epoch: 5| Step: 9
Training loss: 3.0358786883034727
Validation loss: 2.628907844408765

Epoch: 5| Step: 10
Training loss: 3.307256903678441
Validation loss: 2.626134714103559

Epoch: 96| Step: 0
Training loss: 2.8229336802590437
Validation loss: 2.6216743534926894

Epoch: 5| Step: 1
Training loss: 2.992511940839076
Validation loss: 2.627350892742253

Epoch: 5| Step: 2
Training loss: 2.933774818084636
Validation loss: 2.6421341665577316

Epoch: 5| Step: 3
Training loss: 3.4707799247183098
Validation loss: 2.673443003909925

Epoch: 5| Step: 4
Training loss: 2.6304472761237854
Validation loss: 2.679213487052736

Epoch: 5| Step: 5
Training loss: 2.7627731533417963
Validation loss: 2.698023309158747

Epoch: 5| Step: 6
Training loss: 3.1027943353335443
Validation loss: 2.6947561989750226

Epoch: 5| Step: 7
Training loss: 3.2561812673625607
Validation loss: 2.6515147497440243

Epoch: 5| Step: 8
Training loss: 2.2568115338698442
Validation loss: 2.6335023273460454

Epoch: 5| Step: 9
Training loss: 2.9463047612587228
Validation loss: 2.619175542829738

Epoch: 5| Step: 10
Training loss: 3.4570878018856117
Validation loss: 2.6151097804603496

Epoch: 97| Step: 0
Training loss: 3.0642169110084163
Validation loss: 2.625663348292672

Epoch: 5| Step: 1
Training loss: 2.9809958615535046
Validation loss: 2.6249611603128784

Epoch: 5| Step: 2
Training loss: 2.604622630574144
Validation loss: 2.6225149675034793

Epoch: 5| Step: 3
Training loss: 3.449726071747259
Validation loss: 2.6249347039933744

Epoch: 5| Step: 4
Training loss: 2.5571898357889284
Validation loss: 2.619427844916422

Epoch: 5| Step: 5
Training loss: 2.6124551833109693
Validation loss: 2.614110558687883

Epoch: 5| Step: 6
Training loss: 3.2338570442664074
Validation loss: 2.615728548047545

Epoch: 5| Step: 7
Training loss: 3.1319536282747045
Validation loss: 2.614422340732938

Epoch: 5| Step: 8
Training loss: 2.9739299356381887
Validation loss: 2.6228097654808837

Epoch: 5| Step: 9
Training loss: 2.6756491969582084
Validation loss: 2.6249866827076644

Epoch: 5| Step: 10
Training loss: 3.346173985401263
Validation loss: 2.633591913472003

Epoch: 98| Step: 0
Training loss: 2.559932818425334
Validation loss: 2.6301167725073444

Epoch: 5| Step: 1
Training loss: 2.5694763307626256
Validation loss: 2.6191271340291276

Epoch: 5| Step: 2
Training loss: 3.150375943229506
Validation loss: 2.617160349940611

Epoch: 5| Step: 3
Training loss: 3.0011885196055914
Validation loss: 2.6155545710005033

Epoch: 5| Step: 4
Training loss: 3.390116007347525
Validation loss: 2.609541034629339

Epoch: 5| Step: 5
Training loss: 2.8284714628833036
Validation loss: 2.610972523056861

Epoch: 5| Step: 6
Training loss: 2.732241773907277
Validation loss: 2.6134344028759235

Epoch: 5| Step: 7
Training loss: 2.3003304368532316
Validation loss: 2.621665859753335

Epoch: 5| Step: 8
Training loss: 3.141831503135042
Validation loss: 2.642134062736526

Epoch: 5| Step: 9
Training loss: 3.483573102836393
Validation loss: 2.6630035981741713

Epoch: 5| Step: 10
Training loss: 3.3205847774390818
Validation loss: 2.661163351939849

Epoch: 99| Step: 0
Training loss: 2.7662950124409567
Validation loss: 2.6357300012065425

Epoch: 5| Step: 1
Training loss: 2.7856903634074714
Validation loss: 2.618939387667842

Epoch: 5| Step: 2
Training loss: 2.6580838324513687
Validation loss: 2.6123403522493818

Epoch: 5| Step: 3
Training loss: 3.2402590980069474
Validation loss: 2.6029340252580573

Epoch: 5| Step: 4
Training loss: 3.556693716139989
Validation loss: 2.6017663229098864

Epoch: 5| Step: 5
Training loss: 2.5377500927582837
Validation loss: 2.6020388021999983

Epoch: 5| Step: 6
Training loss: 3.2096656080867465
Validation loss: 2.6117618700114313

Epoch: 5| Step: 7
Training loss: 2.618537122135881
Validation loss: 2.6111556524417945

Epoch: 5| Step: 8
Training loss: 3.0712424852390288
Validation loss: 2.613132959116164

Epoch: 5| Step: 9
Training loss: 2.7613025227529606
Validation loss: 2.613123088651266

Epoch: 5| Step: 10
Training loss: 3.2302882225952527
Validation loss: 2.6137441783695876

Epoch: 100| Step: 0
Training loss: 3.3893323271194915
Validation loss: 2.6131113796278114

Epoch: 5| Step: 1
Training loss: 2.5032156290894663
Validation loss: 2.61443287014025

Epoch: 5| Step: 2
Training loss: 2.856331628346707
Validation loss: 2.6127408058318506

Epoch: 5| Step: 3
Training loss: 2.8896340811045027
Validation loss: 2.613821117523717

Epoch: 5| Step: 4
Training loss: 3.223147453095271
Validation loss: 2.6168986744411304

Epoch: 5| Step: 5
Training loss: 2.62303160480477
Validation loss: 2.6277650488964936

Epoch: 5| Step: 6
Training loss: 2.638008672467163
Validation loss: 2.6204390184206683

Epoch: 5| Step: 7
Training loss: 3.442164360311465
Validation loss: 2.6284579419081155

Epoch: 5| Step: 8
Training loss: 2.938546501587509
Validation loss: 2.6171379935648815

Epoch: 5| Step: 9
Training loss: 3.3137492577240066
Validation loss: 2.6076379134444956

Epoch: 5| Step: 10
Training loss: 2.4260583003713116
Validation loss: 2.61100711024845

Epoch: 101| Step: 0
Training loss: 2.7581442830587077
Validation loss: 2.60904970450859

Epoch: 5| Step: 1
Training loss: 3.1555017774175247
Validation loss: 2.6079988388255475

Epoch: 5| Step: 2
Training loss: 2.9004067365924557
Validation loss: 2.6087435500583123

Epoch: 5| Step: 3
Training loss: 3.0528238762971474
Validation loss: 2.6083493539642593

Epoch: 5| Step: 4
Training loss: 3.1522827898864896
Validation loss: 2.5956969739218425

Epoch: 5| Step: 5
Training loss: 3.157298905227873
Validation loss: 2.594783509347353

Epoch: 5| Step: 6
Training loss: 2.8835722793031944
Validation loss: 2.59563817745187

Epoch: 5| Step: 7
Training loss: 2.6703149356909055
Validation loss: 2.5950571169860295

Epoch: 5| Step: 8
Training loss: 2.7611896704131165
Validation loss: 2.597532077572169

Epoch: 5| Step: 9
Training loss: 3.072368991129055
Validation loss: 2.5927414557361588

Epoch: 5| Step: 10
Training loss: 2.827816182341862
Validation loss: 2.5980851867770696

Epoch: 102| Step: 0
Training loss: 2.5566273828080472
Validation loss: 2.5992757718585

Epoch: 5| Step: 1
Training loss: 3.347542296776986
Validation loss: 2.5946831525088268

Epoch: 5| Step: 2
Training loss: 3.057840656507598
Validation loss: 2.6070093881668117

Epoch: 5| Step: 3
Training loss: 2.849062306926186
Validation loss: 2.606957769866765

Epoch: 5| Step: 4
Training loss: 3.098132487725311
Validation loss: 2.61733208986819

Epoch: 5| Step: 5
Training loss: 2.390768508094344
Validation loss: 2.6186634880858053

Epoch: 5| Step: 6
Training loss: 3.260744381035875
Validation loss: 2.618396661049681

Epoch: 5| Step: 7
Training loss: 2.681923247778787
Validation loss: 2.619334861633071

Epoch: 5| Step: 8
Training loss: 3.2277297894194703
Validation loss: 2.6245243424810494

Epoch: 5| Step: 9
Training loss: 3.0125967049806635
Validation loss: 2.6329019791227797

Epoch: 5| Step: 10
Training loss: 2.8585263853431764
Validation loss: 2.653561809237251

Epoch: 103| Step: 0
Training loss: 2.6115292547998648
Validation loss: 2.6590630476570705

Epoch: 5| Step: 1
Training loss: 3.0265275802527825
Validation loss: 2.629220655529313

Epoch: 5| Step: 2
Training loss: 3.3479265885046825
Validation loss: 2.6033241786178447

Epoch: 5| Step: 3
Training loss: 2.6590200005704805
Validation loss: 2.5965418047630036

Epoch: 5| Step: 4
Training loss: 2.807830154966319
Validation loss: 2.5889605263347457

Epoch: 5| Step: 5
Training loss: 3.002155483278034
Validation loss: 2.5929229540577112

Epoch: 5| Step: 6
Training loss: 3.0994656871429256
Validation loss: 2.598534395938724

Epoch: 5| Step: 7
Training loss: 2.8916756035247984
Validation loss: 2.593875939773164

Epoch: 5| Step: 8
Training loss: 3.115589774496048
Validation loss: 2.59207680131125

Epoch: 5| Step: 9
Training loss: 2.544595365152813
Validation loss: 2.590642549972457

Epoch: 5| Step: 10
Training loss: 3.268239995728241
Validation loss: 2.589023156995679

Epoch: 104| Step: 0
Training loss: 3.2528629897376375
Validation loss: 2.5891320475612147

Epoch: 5| Step: 1
Training loss: 2.5582242509613553
Validation loss: 2.5891221895646783

Epoch: 5| Step: 2
Training loss: 3.132503960463082
Validation loss: 2.592012342484828

Epoch: 5| Step: 3
Training loss: 2.860403407529888
Validation loss: 2.5908645639647623

Epoch: 5| Step: 4
Training loss: 3.137406707227741
Validation loss: 2.5878006723024325

Epoch: 5| Step: 5
Training loss: 2.5576515850887094
Validation loss: 2.586232831390218

Epoch: 5| Step: 6
Training loss: 2.8189025059485853
Validation loss: 2.58763145345499

Epoch: 5| Step: 7
Training loss: 2.6882940494373444
Validation loss: 2.5883176174338685

Epoch: 5| Step: 8
Training loss: 3.109877962618921
Validation loss: 2.5900192303992235

Epoch: 5| Step: 9
Training loss: 3.2156772205201607
Validation loss: 2.589297693122713

Epoch: 5| Step: 10
Training loss: 2.955016968189455
Validation loss: 2.5870439044711833

Epoch: 105| Step: 0
Training loss: 2.4545081060310276
Validation loss: 2.586180451455587

Epoch: 5| Step: 1
Training loss: 2.99705233402273
Validation loss: 2.586401325987039

Epoch: 5| Step: 2
Training loss: 2.6590179382958663
Validation loss: 2.5903503608455227

Epoch: 5| Step: 3
Training loss: 2.518884667518884
Validation loss: 2.5859086829696647

Epoch: 5| Step: 4
Training loss: 2.981398611143406
Validation loss: 2.585862653869964

Epoch: 5| Step: 5
Training loss: 3.3300958806344827
Validation loss: 2.5868006892265303

Epoch: 5| Step: 6
Training loss: 3.0860215573994902
Validation loss: 2.5836602376963187

Epoch: 5| Step: 7
Training loss: 3.2773466598988867
Validation loss: 2.588914292547542

Epoch: 5| Step: 8
Training loss: 2.941103409252387
Validation loss: 2.590113595690274

Epoch: 5| Step: 9
Training loss: 2.8676976885576666
Validation loss: 2.597293192513276

Epoch: 5| Step: 10
Training loss: 3.1298491430033786
Validation loss: 2.6173783035775924

Epoch: 106| Step: 0
Training loss: 3.6953872124698175
Validation loss: 2.6179074336298997

Epoch: 5| Step: 1
Training loss: 2.6334830768679534
Validation loss: 2.5932118895079475

Epoch: 5| Step: 2
Training loss: 2.759934686772541
Validation loss: 2.5828955868589505

Epoch: 5| Step: 3
Training loss: 2.4302200764027475
Validation loss: 2.577699429118509

Epoch: 5| Step: 4
Training loss: 2.341775596591975
Validation loss: 2.577200357408665

Epoch: 5| Step: 5
Training loss: 2.778931326293196
Validation loss: 2.5809337521257403

Epoch: 5| Step: 6
Training loss: 2.9231717908962853
Validation loss: 2.5874412007997862

Epoch: 5| Step: 7
Training loss: 3.282719019884764
Validation loss: 2.5887158353567012

Epoch: 5| Step: 8
Training loss: 3.2746112330660213
Validation loss: 2.5827582953496284

Epoch: 5| Step: 9
Training loss: 3.1058748567502614
Validation loss: 2.587353284497844

Epoch: 5| Step: 10
Training loss: 2.9226167930584714
Validation loss: 2.5777240808121324

Epoch: 107| Step: 0
Training loss: 2.747366077328248
Validation loss: 2.5762087206314157

Epoch: 5| Step: 1
Training loss: 2.5704092453950316
Validation loss: 2.6021893636715827

Epoch: 5| Step: 2
Training loss: 2.602925627951363
Validation loss: 2.6389099539790526

Epoch: 5| Step: 3
Training loss: 3.1262299215410994
Validation loss: 2.6784800218649893

Epoch: 5| Step: 4
Training loss: 2.982871270937104
Validation loss: 2.7566748862241894

Epoch: 5| Step: 5
Training loss: 3.07796760582686
Validation loss: 2.83500668540841

Epoch: 5| Step: 6
Training loss: 3.3298021845442713
Validation loss: 2.824823038604495

Epoch: 5| Step: 7
Training loss: 3.1799539740248606
Validation loss: 2.7141109799365966

Epoch: 5| Step: 8
Training loss: 2.8995000737179217
Validation loss: 2.5818059264859032

Epoch: 5| Step: 9
Training loss: 3.07907461631882
Validation loss: 2.5741750768325735

Epoch: 5| Step: 10
Training loss: 3.0136489323393554
Validation loss: 2.6237953965288723

Epoch: 108| Step: 0
Training loss: 3.1606642570569563
Validation loss: 2.6441364439250727

Epoch: 5| Step: 1
Training loss: 2.627863003874549
Validation loss: 2.6584815701464666

Epoch: 5| Step: 2
Training loss: 2.7335407837399517
Validation loss: 2.6417086972674246

Epoch: 5| Step: 3
Training loss: 3.1308820679640004
Validation loss: 2.654480238293966

Epoch: 5| Step: 4
Training loss: 3.1668604406666203
Validation loss: 2.6318397841719476

Epoch: 5| Step: 5
Training loss: 3.1400551350120476
Validation loss: 2.6197710602562583

Epoch: 5| Step: 6
Training loss: 2.75052724465623
Validation loss: 2.592216002498166

Epoch: 5| Step: 7
Training loss: 3.5043109502733993
Validation loss: 2.5826585522168433

Epoch: 5| Step: 8
Training loss: 2.743924452117037
Validation loss: 2.5868211621910295

Epoch: 5| Step: 9
Training loss: 3.0669921315294046
Validation loss: 2.6042374510630517

Epoch: 5| Step: 10
Training loss: 2.7836605298481656
Validation loss: 2.609778289744791

Epoch: 109| Step: 0
Training loss: 3.014712813381727
Validation loss: 2.6222320139525834

Epoch: 5| Step: 1
Training loss: 2.6173699614277175
Validation loss: 2.663726068480256

Epoch: 5| Step: 2
Training loss: 2.9273040434865485
Validation loss: 2.686601624572396

Epoch: 5| Step: 3
Training loss: 2.9720931653993414
Validation loss: 2.6878946886852852

Epoch: 5| Step: 4
Training loss: 2.9196364043144887
Validation loss: 2.6553640752129466

Epoch: 5| Step: 5
Training loss: 2.880963815638621
Validation loss: 2.5912898732219736

Epoch: 5| Step: 6
Training loss: 2.684650596175853
Validation loss: 2.5745440386541567

Epoch: 5| Step: 7
Training loss: 2.770847024142829
Validation loss: 2.577254684483853

Epoch: 5| Step: 8
Training loss: 3.4734462530289227
Validation loss: 2.5734454740749455

Epoch: 5| Step: 9
Training loss: 3.287197717033702
Validation loss: 2.580285369815824

Epoch: 5| Step: 10
Training loss: 2.840607971878968
Validation loss: 2.5793195316946878

Epoch: 110| Step: 0
Training loss: 3.1130004909378974
Validation loss: 2.5762464294888097

Epoch: 5| Step: 1
Training loss: 3.004195776034276
Validation loss: 2.5756164746699626

Epoch: 5| Step: 2
Training loss: 2.726256257705468
Validation loss: 2.5810925917474536

Epoch: 5| Step: 3
Training loss: 3.503077380276112
Validation loss: 2.577882305715621

Epoch: 5| Step: 4
Training loss: 2.8118471023589953
Validation loss: 2.5724654638828137

Epoch: 5| Step: 5
Training loss: 2.6981458726136998
Validation loss: 2.5749066293802545

Epoch: 5| Step: 6
Training loss: 2.817591318649357
Validation loss: 2.5707321026466596

Epoch: 5| Step: 7
Training loss: 3.034003982883321
Validation loss: 2.581624205671805

Epoch: 5| Step: 8
Training loss: 2.734496893209456
Validation loss: 2.5795432089554438

Epoch: 5| Step: 9
Training loss: 3.1335430102162314
Validation loss: 2.583293512244523

Epoch: 5| Step: 10
Training loss: 2.5926354093144495
Validation loss: 2.586955509894233

Epoch: 111| Step: 0
Training loss: 3.0883521568135053
Validation loss: 2.592292471997959

Epoch: 5| Step: 1
Training loss: 2.709133636389031
Validation loss: 2.6053185266287344

Epoch: 5| Step: 2
Training loss: 2.41749156378425
Validation loss: 2.6223455364111286

Epoch: 5| Step: 3
Training loss: 2.652468693842392
Validation loss: 2.628393988074639

Epoch: 5| Step: 4
Training loss: 2.831447777987476
Validation loss: 2.638365003968001

Epoch: 5| Step: 5
Training loss: 2.9790315575184696
Validation loss: 2.624972644591101

Epoch: 5| Step: 6
Training loss: 3.3732592013912166
Validation loss: 2.6124106018044344

Epoch: 5| Step: 7
Training loss: 3.4365961447089783
Validation loss: 2.599297432677121

Epoch: 5| Step: 8
Training loss: 2.384602959011257
Validation loss: 2.590248488198911

Epoch: 5| Step: 9
Training loss: 3.354312790872555
Validation loss: 2.5821177927136767

Epoch: 5| Step: 10
Training loss: 2.7906105169281403
Validation loss: 2.5785006988026913

Epoch: 112| Step: 0
Training loss: 3.122092611157466
Validation loss: 2.5769912568650186

Epoch: 5| Step: 1
Training loss: 3.1166609316958396
Validation loss: 2.563910835511202

Epoch: 5| Step: 2
Training loss: 2.6146892409639704
Validation loss: 2.5667880496901354

Epoch: 5| Step: 3
Training loss: 3.142075995805246
Validation loss: 2.5625534272145423

Epoch: 5| Step: 4
Training loss: 3.014289362523603
Validation loss: 2.559689679241065

Epoch: 5| Step: 5
Training loss: 2.7975027562623
Validation loss: 2.56101124633838

Epoch: 5| Step: 6
Training loss: 2.932569871153002
Validation loss: 2.5615424851598627

Epoch: 5| Step: 7
Training loss: 3.106001207301095
Validation loss: 2.567909269968272

Epoch: 5| Step: 8
Training loss: 2.347432511469614
Validation loss: 2.569181903070438

Epoch: 5| Step: 9
Training loss: 2.894266669862059
Validation loss: 2.5771856610989152

Epoch: 5| Step: 10
Training loss: 3.088302903276765
Validation loss: 2.575472515123325

Epoch: 113| Step: 0
Training loss: 2.8535045960387477
Validation loss: 2.5640789822747454

Epoch: 5| Step: 1
Training loss: 2.926348357505076
Validation loss: 2.56786812015523

Epoch: 5| Step: 2
Training loss: 3.1284161015899885
Validation loss: 2.564886915818909

Epoch: 5| Step: 3
Training loss: 2.4667839237214446
Validation loss: 2.560495072962763

Epoch: 5| Step: 4
Training loss: 2.9533755887397835
Validation loss: 2.5609893587960637

Epoch: 5| Step: 5
Training loss: 2.9021226020852704
Validation loss: 2.576536346033961

Epoch: 5| Step: 6
Training loss: 3.5638920256145887
Validation loss: 2.5871426035552543

Epoch: 5| Step: 7
Training loss: 2.7637008611554132
Validation loss: 2.5995168435770513

Epoch: 5| Step: 8
Training loss: 3.3080676672771037
Validation loss: 2.591822685396756

Epoch: 5| Step: 9
Training loss: 2.616271083435171
Validation loss: 2.5831120548753765

Epoch: 5| Step: 10
Training loss: 2.4799206225705066
Validation loss: 2.56553224287981

Epoch: 114| Step: 0
Training loss: 2.957253451546649
Validation loss: 2.5603035047529286

Epoch: 5| Step: 1
Training loss: 3.131486188619027
Validation loss: 2.558803046485916

Epoch: 5| Step: 2
Training loss: 2.882166679015112
Validation loss: 2.561053972804586

Epoch: 5| Step: 3
Training loss: 3.2117788136145067
Validation loss: 2.560459570155326

Epoch: 5| Step: 4
Training loss: 2.4900712262732694
Validation loss: 2.5625378335540385

Epoch: 5| Step: 5
Training loss: 2.80750288490154
Validation loss: 2.564287394167768

Epoch: 5| Step: 6
Training loss: 3.0623944322724785
Validation loss: 2.561143681749554

Epoch: 5| Step: 7
Training loss: 2.405263426028444
Validation loss: 2.566436411285064

Epoch: 5| Step: 8
Training loss: 2.7711866244380943
Validation loss: 2.5656055107713933

Epoch: 5| Step: 9
Training loss: 3.294831279782236
Validation loss: 2.5590000787140688

Epoch: 5| Step: 10
Training loss: 3.0940628664205105
Validation loss: 2.5577249995447517

Epoch: 115| Step: 0
Training loss: 3.044575141118542
Validation loss: 2.5580346623938968

Epoch: 5| Step: 1
Training loss: 3.0805645100866927
Validation loss: 2.5644180718696745

Epoch: 5| Step: 2
Training loss: 2.9799327443361205
Validation loss: 2.574482655487628

Epoch: 5| Step: 3
Training loss: 2.8977500737835045
Validation loss: 2.5877112851387425

Epoch: 5| Step: 4
Training loss: 2.5878813200009603
Validation loss: 2.626365257755798

Epoch: 5| Step: 5
Training loss: 2.673012207020502
Validation loss: 2.6204274682919175

Epoch: 5| Step: 6
Training loss: 3.0106903972495775
Validation loss: 2.6239696693658345

Epoch: 5| Step: 7
Training loss: 3.097710588514969
Validation loss: 2.6277990921457337

Epoch: 5| Step: 8
Training loss: 3.168996622995616
Validation loss: 2.608081251529017

Epoch: 5| Step: 9
Training loss: 2.52896702799151
Validation loss: 2.586370081196287

Epoch: 5| Step: 10
Training loss: 2.965541511220666
Validation loss: 2.5600599761812264

Epoch: 116| Step: 0
Training loss: 2.8775676374001184
Validation loss: 2.5461857538309993

Epoch: 5| Step: 1
Training loss: 3.117276527452834
Validation loss: 2.5438282263045067

Epoch: 5| Step: 2
Training loss: 2.5534655713863406
Validation loss: 2.5395269234535727

Epoch: 5| Step: 3
Training loss: 3.1627616562990744
Validation loss: 2.5423085141783472

Epoch: 5| Step: 4
Training loss: 3.226778554263809
Validation loss: 2.5437182611095532

Epoch: 5| Step: 5
Training loss: 3.0737507523283285
Validation loss: 2.544191008802967

Epoch: 5| Step: 6
Training loss: 2.9554126093849273
Validation loss: 2.5446973114844664

Epoch: 5| Step: 7
Training loss: 3.096323195490519
Validation loss: 2.539369065777518

Epoch: 5| Step: 8
Training loss: 2.643884396575163
Validation loss: 2.544876670535089

Epoch: 5| Step: 9
Training loss: 2.6248142540018855
Validation loss: 2.554742829633482

Epoch: 5| Step: 10
Training loss: 2.5965875937093705
Validation loss: 2.573039885196719

Epoch: 117| Step: 0
Training loss: 2.815560011373017
Validation loss: 2.5882538256840806

Epoch: 5| Step: 1
Training loss: 3.293142800578937
Validation loss: 2.5970893186310575

Epoch: 5| Step: 2
Training loss: 2.666622777418722
Validation loss: 2.6115375616156955

Epoch: 5| Step: 3
Training loss: 2.9614962651984182
Validation loss: 2.6238278762011262

Epoch: 5| Step: 4
Training loss: 2.4390452450930638
Validation loss: 2.6330091640882687

Epoch: 5| Step: 5
Training loss: 2.60544459204505
Validation loss: 2.620264738726273

Epoch: 5| Step: 6
Training loss: 3.451889438436641
Validation loss: 2.5901013679288263

Epoch: 5| Step: 7
Training loss: 3.0266889097709995
Validation loss: 2.582121260716086

Epoch: 5| Step: 8
Training loss: 2.8500959413675884
Validation loss: 2.560960187461561

Epoch: 5| Step: 9
Training loss: 3.3834306887696117
Validation loss: 2.5449888833949084

Epoch: 5| Step: 10
Training loss: 2.3149774013924023
Validation loss: 2.5408587265156966

Epoch: 118| Step: 0
Training loss: 2.450736760278911
Validation loss: 2.544027937943429

Epoch: 5| Step: 1
Training loss: 2.9118976477671357
Validation loss: 2.5514633276087686

Epoch: 5| Step: 2
Training loss: 3.2633654794742974
Validation loss: 2.5517806341800107

Epoch: 5| Step: 3
Training loss: 2.7978325595177087
Validation loss: 2.549877099283154

Epoch: 5| Step: 4
Training loss: 2.8091110156384267
Validation loss: 2.5498453144413626

Epoch: 5| Step: 5
Training loss: 2.6844553001747813
Validation loss: 2.546240785933578

Epoch: 5| Step: 6
Training loss: 3.1708456539628167
Validation loss: 2.549936208946498

Epoch: 5| Step: 7
Training loss: 2.865203420397719
Validation loss: 2.550462187708403

Epoch: 5| Step: 8
Training loss: 2.7222302841101746
Validation loss: 2.5460962398002747

Epoch: 5| Step: 9
Training loss: 3.4195624074895634
Validation loss: 2.5448978897563754

Epoch: 5| Step: 10
Training loss: 2.7932407913568347
Validation loss: 2.5447907995847006

Epoch: 119| Step: 0
Training loss: 2.445387866531512
Validation loss: 2.544888158593492

Epoch: 5| Step: 1
Training loss: 3.003762428997739
Validation loss: 2.555355076493059

Epoch: 5| Step: 2
Training loss: 3.334544978863601
Validation loss: 2.575431987847087

Epoch: 5| Step: 3
Training loss: 2.488510624300869
Validation loss: 2.577047435688114

Epoch: 5| Step: 4
Training loss: 2.968957833494007
Validation loss: 2.584814054829601

Epoch: 5| Step: 5
Training loss: 2.7511365449243628
Validation loss: 2.577581633394262

Epoch: 5| Step: 6
Training loss: 3.016409658229022
Validation loss: 2.568203962348042

Epoch: 5| Step: 7
Training loss: 3.4698439239228436
Validation loss: 2.5615913486853716

Epoch: 5| Step: 8
Training loss: 3.068226190368179
Validation loss: 2.547246945458152

Epoch: 5| Step: 9
Training loss: 2.381196121046821
Validation loss: 2.5424329616888186

Epoch: 5| Step: 10
Training loss: 2.847324514231432
Validation loss: 2.5430561774796696

Epoch: 120| Step: 0
Training loss: 2.779238798777223
Validation loss: 2.538165400364485

Epoch: 5| Step: 1
Training loss: 2.9562174434361177
Validation loss: 2.539545997796689

Epoch: 5| Step: 2
Training loss: 2.5850350917301053
Validation loss: 2.5374940746643726

Epoch: 5| Step: 3
Training loss: 3.1970605522294355
Validation loss: 2.5387982691490336

Epoch: 5| Step: 4
Training loss: 3.300434089778076
Validation loss: 2.536926184607237

Epoch: 5| Step: 5
Training loss: 3.051579994819522
Validation loss: 2.5355316879672984

Epoch: 5| Step: 6
Training loss: 2.6325038649774273
Validation loss: 2.5365253625011945

Epoch: 5| Step: 7
Training loss: 2.7574044160713043
Validation loss: 2.539308573849375

Epoch: 5| Step: 8
Training loss: 3.044044157692916
Validation loss: 2.5373755973267844

Epoch: 5| Step: 9
Training loss: 2.802463935803762
Validation loss: 2.5406821038662675

Epoch: 5| Step: 10
Training loss: 2.611237095663526
Validation loss: 2.5454304681105873

Epoch: 121| Step: 0
Training loss: 3.3244261626501928
Validation loss: 2.5488328140888923

Epoch: 5| Step: 1
Training loss: 2.783121058274722
Validation loss: 2.5473758092636567

Epoch: 5| Step: 2
Training loss: 3.1367836609391264
Validation loss: 2.544029719572863

Epoch: 5| Step: 3
Training loss: 2.9942046455362044
Validation loss: 2.5426812778540513

Epoch: 5| Step: 4
Training loss: 3.0599641226865564
Validation loss: 2.542500580169808

Epoch: 5| Step: 5
Training loss: 2.315036516663685
Validation loss: 2.5365168514670335

Epoch: 5| Step: 6
Training loss: 2.901266275382421
Validation loss: 2.53949188665656

Epoch: 5| Step: 7
Training loss: 3.278411073084572
Validation loss: 2.5397292737834767

Epoch: 5| Step: 8
Training loss: 2.2326972905007794
Validation loss: 2.541015114494563

Epoch: 5| Step: 9
Training loss: 2.8099759113731846
Validation loss: 2.5380782791491394

Epoch: 5| Step: 10
Training loss: 2.7269631340128413
Validation loss: 2.5376127197294873

Epoch: 122| Step: 0
Training loss: 2.924721702965074
Validation loss: 2.541735880323059

Epoch: 5| Step: 1
Training loss: 2.326890451696069
Validation loss: 2.540259068494815

Epoch: 5| Step: 2
Training loss: 2.886301467324285
Validation loss: 2.5430881943555703

Epoch: 5| Step: 3
Training loss: 2.8860718204816935
Validation loss: 2.5566310568563666

Epoch: 5| Step: 4
Training loss: 2.9831944871981957
Validation loss: 2.5671085921167625

Epoch: 5| Step: 5
Training loss: 3.1466622849881114
Validation loss: 2.576377117545544

Epoch: 5| Step: 6
Training loss: 2.7929130068464816
Validation loss: 2.571742542469155

Epoch: 5| Step: 7
Training loss: 2.9464873138781247
Validation loss: 2.550143415233222

Epoch: 5| Step: 8
Training loss: 3.0130332126654364
Validation loss: 2.5443620048999147

Epoch: 5| Step: 9
Training loss: 2.7384012280353596
Validation loss: 2.5415415767535094

Epoch: 5| Step: 10
Training loss: 3.0784976946605425
Validation loss: 2.541051455465796

Epoch: 123| Step: 0
Training loss: 3.0157669903626725
Validation loss: 2.5345936391456454

Epoch: 5| Step: 1
Training loss: 3.3795138656166968
Validation loss: 2.5375564003158373

Epoch: 5| Step: 2
Training loss: 3.2842376186627917
Validation loss: 2.534568786434777

Epoch: 5| Step: 3
Training loss: 3.003350770781854
Validation loss: 2.5295991597297953

Epoch: 5| Step: 4
Training loss: 2.6367489509265765
Validation loss: 2.528244610403623

Epoch: 5| Step: 5
Training loss: 2.8873113661413154
Validation loss: 2.5295634726075344

Epoch: 5| Step: 6
Training loss: 2.0880307328092673
Validation loss: 2.5295322017493023

Epoch: 5| Step: 7
Training loss: 2.629166974180015
Validation loss: 2.5275987304182226

Epoch: 5| Step: 8
Training loss: 2.7936258036681307
Validation loss: 2.523621262181296

Epoch: 5| Step: 9
Training loss: 3.113552335378611
Validation loss: 2.528517639561159

Epoch: 5| Step: 10
Training loss: 2.7777921633877716
Validation loss: 2.5374036263366686

Epoch: 124| Step: 0
Training loss: 3.4962077713599315
Validation loss: 2.5513039104196036

Epoch: 5| Step: 1
Training loss: 3.222647964004499
Validation loss: 2.5624543552850443

Epoch: 5| Step: 2
Training loss: 2.4887328883319983
Validation loss: 2.5665889823588146

Epoch: 5| Step: 3
Training loss: 2.606148924114016
Validation loss: 2.5718854598219143

Epoch: 5| Step: 4
Training loss: 2.852084511830263
Validation loss: 2.57908659174265

Epoch: 5| Step: 5
Training loss: 2.803111619183808
Validation loss: 2.5931438158250346

Epoch: 5| Step: 6
Training loss: 2.6427792220982345
Validation loss: 2.5891438947321825

Epoch: 5| Step: 7
Training loss: 3.0610115949728294
Validation loss: 2.596916203477809

Epoch: 5| Step: 8
Training loss: 2.8804606119676706
Validation loss: 2.5672538315304467

Epoch: 5| Step: 9
Training loss: 2.9893197044188917
Validation loss: 2.5494598854184947

Epoch: 5| Step: 10
Training loss: 2.483446535521492
Validation loss: 2.537790170192276

Epoch: 125| Step: 0
Training loss: 2.694557858294525
Validation loss: 2.5299922826979113

Epoch: 5| Step: 1
Training loss: 2.3511934212544894
Validation loss: 2.524003775823051

Epoch: 5| Step: 2
Training loss: 2.8301271548871423
Validation loss: 2.5222111530496845

Epoch: 5| Step: 3
Training loss: 3.1318736964710077
Validation loss: 2.5242850370187666

Epoch: 5| Step: 4
Training loss: 3.289772518838956
Validation loss: 2.5248586039396366

Epoch: 5| Step: 5
Training loss: 2.8980342450800576
Validation loss: 2.524448135630629

Epoch: 5| Step: 6
Training loss: 2.903053741073281
Validation loss: 2.526088188883885

Epoch: 5| Step: 7
Training loss: 2.9599232408520058
Validation loss: 2.5295129794303186

Epoch: 5| Step: 8
Training loss: 3.294819991385685
Validation loss: 2.5200481398745884

Epoch: 5| Step: 9
Training loss: 2.662791824466486
Validation loss: 2.524458817917347

Epoch: 5| Step: 10
Training loss: 2.6487715518897326
Validation loss: 2.522557720292802

Epoch: 126| Step: 0
Training loss: 2.5703980220028404
Validation loss: 2.521423500258852

Epoch: 5| Step: 1
Training loss: 3.118697563143378
Validation loss: 2.528719421115537

Epoch: 5| Step: 2
Training loss: 2.593652654452686
Validation loss: 2.552833804063774

Epoch: 5| Step: 3
Training loss: 2.7442080452127087
Validation loss: 2.5516622231482553

Epoch: 5| Step: 4
Training loss: 3.15360035484192
Validation loss: 2.575403269773751

Epoch: 5| Step: 5
Training loss: 2.6988611715935216
Validation loss: 2.579734962314809

Epoch: 5| Step: 6
Training loss: 3.048863940422641
Validation loss: 2.5961169322709283

Epoch: 5| Step: 7
Training loss: 2.9945581671313395
Validation loss: 2.603163293962757

Epoch: 5| Step: 8
Training loss: 3.140180869512059
Validation loss: 2.574573379198182

Epoch: 5| Step: 9
Training loss: 2.631230997121154
Validation loss: 2.5541826009960107

Epoch: 5| Step: 10
Training loss: 3.036688262103354
Validation loss: 2.53546050449031

Epoch: 127| Step: 0
Training loss: 3.266170182418923
Validation loss: 2.52987912244701

Epoch: 5| Step: 1
Training loss: 2.5811862226462865
Validation loss: 2.5171041061888317

Epoch: 5| Step: 2
Training loss: 2.7212625053093893
Validation loss: 2.5194480155366

Epoch: 5| Step: 3
Training loss: 2.880935843794438
Validation loss: 2.5168140698935932

Epoch: 5| Step: 4
Training loss: 2.973925125462218
Validation loss: 2.5206225442755263

Epoch: 5| Step: 5
Training loss: 3.0055785763701723
Validation loss: 2.522138477553788

Epoch: 5| Step: 6
Training loss: 3.2762404211225205
Validation loss: 2.5239327263308966

Epoch: 5| Step: 7
Training loss: 2.8276099478933685
Validation loss: 2.5216009513192676

Epoch: 5| Step: 8
Training loss: 2.629098961669234
Validation loss: 2.5228992425144776

Epoch: 5| Step: 9
Training loss: 2.978906064317379
Validation loss: 2.521138600803954

Epoch: 5| Step: 10
Training loss: 2.3722495164077753
Validation loss: 2.525388014042686

Epoch: 128| Step: 0
Training loss: 3.3897892497671465
Validation loss: 2.5278716893829802

Epoch: 5| Step: 1
Training loss: 2.516037711650796
Validation loss: 2.522488263287842

Epoch: 5| Step: 2
Training loss: 2.596455002296203
Validation loss: 2.5266046155343376

Epoch: 5| Step: 3
Training loss: 2.559279767734452
Validation loss: 2.526378489802242

Epoch: 5| Step: 4
Training loss: 2.7265093341879583
Validation loss: 2.5268827810025614

Epoch: 5| Step: 5
Training loss: 2.787902419803059
Validation loss: 2.532657569700071

Epoch: 5| Step: 6
Training loss: 3.0024583598607584
Validation loss: 2.540356439715415

Epoch: 5| Step: 7
Training loss: 2.8504656628767266
Validation loss: 2.5501937075219967

Epoch: 5| Step: 8
Training loss: 2.907242144157522
Validation loss: 2.558871256290378

Epoch: 5| Step: 9
Training loss: 3.2462838274486248
Validation loss: 2.55765418115219

Epoch: 5| Step: 10
Training loss: 2.8709004239758587
Validation loss: 2.5735916259400002

Epoch: 129| Step: 0
Training loss: 2.9542586154016384
Validation loss: 2.551888506955171

Epoch: 5| Step: 1
Training loss: 2.6888592853265156
Validation loss: 2.545618682131857

Epoch: 5| Step: 2
Training loss: 3.271751825588204
Validation loss: 2.538146227267192

Epoch: 5| Step: 3
Training loss: 3.0231479239960004
Validation loss: 2.5268840948402214

Epoch: 5| Step: 4
Training loss: 2.396672298210789
Validation loss: 2.519049623000191

Epoch: 5| Step: 5
Training loss: 2.850032866439037
Validation loss: 2.519843351444705

Epoch: 5| Step: 6
Training loss: 3.1382964502545287
Validation loss: 2.5188572212151454

Epoch: 5| Step: 7
Training loss: 3.018430047622866
Validation loss: 2.514704300454771

Epoch: 5| Step: 8
Training loss: 2.969389836477616
Validation loss: 2.515389956993839

Epoch: 5| Step: 9
Training loss: 2.666727919669794
Validation loss: 2.515583046897263

Epoch: 5| Step: 10
Training loss: 2.548394153818069
Validation loss: 2.515406111998795

Epoch: 130| Step: 0
Training loss: 3.002131340777794
Validation loss: 2.5159785463581943

Epoch: 5| Step: 1
Training loss: 2.4494821507211806
Validation loss: 2.515889892613544

Epoch: 5| Step: 2
Training loss: 3.0461218269817203
Validation loss: 2.514428275665688

Epoch: 5| Step: 3
Training loss: 2.586385451872547
Validation loss: 2.517146491233685

Epoch: 5| Step: 4
Training loss: 3.064882869504833
Validation loss: 2.5229981799192083

Epoch: 5| Step: 5
Training loss: 2.485349260190486
Validation loss: 2.530159321679778

Epoch: 5| Step: 6
Training loss: 3.192809077919385
Validation loss: 2.5427802047341457

Epoch: 5| Step: 7
Training loss: 2.938361832827965
Validation loss: 2.54891238747707

Epoch: 5| Step: 8
Training loss: 3.1089633688353047
Validation loss: 2.5555571155118293

Epoch: 5| Step: 9
Training loss: 2.9313943595557648
Validation loss: 2.545609566031026

Epoch: 5| Step: 10
Training loss: 2.694291692732044
Validation loss: 2.540919386858927

Epoch: 131| Step: 0
Training loss: 3.287729894918145
Validation loss: 2.5480088171846695

Epoch: 5| Step: 1
Training loss: 2.870488150947752
Validation loss: 2.5397375328029677

Epoch: 5| Step: 2
Training loss: 3.091817695513835
Validation loss: 2.5416082112896077

Epoch: 5| Step: 3
Training loss: 3.1060455746227067
Validation loss: 2.527556168694938

Epoch: 5| Step: 4
Training loss: 2.6258127679950674
Validation loss: 2.5200209915978347

Epoch: 5| Step: 5
Training loss: 3.1158479570601827
Validation loss: 2.5247377305516205

Epoch: 5| Step: 6
Training loss: 2.693296612955065
Validation loss: 2.51935100440109

Epoch: 5| Step: 7
Training loss: 2.287566649919938
Validation loss: 2.5182148513839233

Epoch: 5| Step: 8
Training loss: 2.548688371707428
Validation loss: 2.515862380012204

Epoch: 5| Step: 9
Training loss: 2.9703122495664185
Validation loss: 2.5132950280549426

Epoch: 5| Step: 10
Training loss: 2.7909282352975864
Validation loss: 2.516404087515903

Epoch: 132| Step: 0
Training loss: 2.3540000068839566
Validation loss: 2.518265191885502

Epoch: 5| Step: 1
Training loss: 2.421556513364537
Validation loss: 2.516859877184344

Epoch: 5| Step: 2
Training loss: 2.8088325324705794
Validation loss: 2.518588151807931

Epoch: 5| Step: 3
Training loss: 2.994797964780515
Validation loss: 2.524452687210361

Epoch: 5| Step: 4
Training loss: 3.1718611693433068
Validation loss: 2.5309066124295887

Epoch: 5| Step: 5
Training loss: 2.964287385267092
Validation loss: 2.5404975459253607

Epoch: 5| Step: 6
Training loss: 3.257080288575273
Validation loss: 2.541343391701067

Epoch: 5| Step: 7
Training loss: 2.8398788428991457
Validation loss: 2.550550404671722

Epoch: 5| Step: 8
Training loss: 2.0393690558442477
Validation loss: 2.536619705619394

Epoch: 5| Step: 9
Training loss: 3.3901783169910242
Validation loss: 2.5454111286648207

Epoch: 5| Step: 10
Training loss: 2.9553532343127764
Validation loss: 2.543650887656662

Epoch: 133| Step: 0
Training loss: 3.19721223277426
Validation loss: 2.533678548003813

Epoch: 5| Step: 1
Training loss: 2.8042286787124597
Validation loss: 2.530424008847418

Epoch: 5| Step: 2
Training loss: 3.163303312421133
Validation loss: 2.535767120549051

Epoch: 5| Step: 3
Training loss: 3.18853533516851
Validation loss: 2.5283178728872997

Epoch: 5| Step: 4
Training loss: 2.8990961442092846
Validation loss: 2.532718381929438

Epoch: 5| Step: 5
Training loss: 3.0837014124660507
Validation loss: 2.526603822071332

Epoch: 5| Step: 6
Training loss: 2.4976640278179354
Validation loss: 2.532299085144647

Epoch: 5| Step: 7
Training loss: 2.6199635827831393
Validation loss: 2.5195334600241934

Epoch: 5| Step: 8
Training loss: 2.6313670007784253
Validation loss: 2.526461080921823

Epoch: 5| Step: 9
Training loss: 2.7046402229042523
Validation loss: 2.516217742224602

Epoch: 5| Step: 10
Training loss: 2.497481508081537
Validation loss: 2.5218337777346944

Epoch: 134| Step: 0
Training loss: 2.888896528462147
Validation loss: 2.521232418469766

Epoch: 5| Step: 1
Training loss: 2.2420341625350226
Validation loss: 2.5213608553795495

Epoch: 5| Step: 2
Training loss: 3.133526271263765
Validation loss: 2.522081427347009

Epoch: 5| Step: 3
Training loss: 3.0379236436079315
Validation loss: 2.522707946296626

Epoch: 5| Step: 4
Training loss: 2.6425593587655904
Validation loss: 2.5136567011975335

Epoch: 5| Step: 5
Training loss: 3.498102218556474
Validation loss: 2.513145431871816

Epoch: 5| Step: 6
Training loss: 2.657403672949569
Validation loss: 2.5150352881836233

Epoch: 5| Step: 7
Training loss: 3.040561649489802
Validation loss: 2.5107101624923778

Epoch: 5| Step: 8
Training loss: 2.7287570461543944
Validation loss: 2.5097275679470323

Epoch: 5| Step: 9
Training loss: 2.654652822177078
Validation loss: 2.5038883877361644

Epoch: 5| Step: 10
Training loss: 2.7614986866166173
Validation loss: 2.5052346790207487

Epoch: 135| Step: 0
Training loss: 2.1934470942986204
Validation loss: 2.50197497568828

Epoch: 5| Step: 1
Training loss: 3.3581793498162402
Validation loss: 2.5010673930988547

Epoch: 5| Step: 2
Training loss: 3.0954609773197554
Validation loss: 2.504284178097656

Epoch: 5| Step: 3
Training loss: 2.7762673997741696
Validation loss: 2.5045825960566885

Epoch: 5| Step: 4
Training loss: 2.7980168744792455
Validation loss: 2.513299285663711

Epoch: 5| Step: 5
Training loss: 2.949255290026123
Validation loss: 2.5175484475960244

Epoch: 5| Step: 6
Training loss: 3.101020054501094
Validation loss: 2.5061246962809793

Epoch: 5| Step: 7
Training loss: 2.6954691523487018
Validation loss: 2.498322654304578

Epoch: 5| Step: 8
Training loss: 2.2866945485045442
Validation loss: 2.4991849319203108

Epoch: 5| Step: 9
Training loss: 2.8505493036250855
Validation loss: 2.501594681917844

Epoch: 5| Step: 10
Training loss: 3.2180370541200194
Validation loss: 2.500234687208194

Epoch: 136| Step: 0
Training loss: 3.1896017288750604
Validation loss: 2.503115018729174

Epoch: 5| Step: 1
Training loss: 2.7501381926059962
Validation loss: 2.502171658131366

Epoch: 5| Step: 2
Training loss: 3.055374419498002
Validation loss: 2.501492910804614

Epoch: 5| Step: 3
Training loss: 2.589337467747513
Validation loss: 2.5077636885739696

Epoch: 5| Step: 4
Training loss: 2.9989122962046
Validation loss: 2.503046587199174

Epoch: 5| Step: 5
Training loss: 3.4192816953735905
Validation loss: 2.507528023194575

Epoch: 5| Step: 6
Training loss: 2.4963656711664792
Validation loss: 2.5170295273097

Epoch: 5| Step: 7
Training loss: 2.541787900274228
Validation loss: 2.5341572100947167

Epoch: 5| Step: 8
Training loss: 2.6217199450214532
Validation loss: 2.5672238915530317

Epoch: 5| Step: 9
Training loss: 2.966433775972254
Validation loss: 2.579993845992791

Epoch: 5| Step: 10
Training loss: 2.642795821623619
Validation loss: 2.5808898300273517

Epoch: 137| Step: 0
Training loss: 2.720686299750559
Validation loss: 2.5853987143870807

Epoch: 5| Step: 1
Training loss: 2.512759454340669
Validation loss: 2.551554437763534

Epoch: 5| Step: 2
Training loss: 2.9917775961482254
Validation loss: 2.5240156717198223

Epoch: 5| Step: 3
Training loss: 3.051385133494321
Validation loss: 2.5210640944975973

Epoch: 5| Step: 4
Training loss: 3.390716973388951
Validation loss: 2.512952986616464

Epoch: 5| Step: 5
Training loss: 3.0566457730088437
Validation loss: 2.5141261899459715

Epoch: 5| Step: 6
Training loss: 2.7565685200622783
Validation loss: 2.5129536349347656

Epoch: 5| Step: 7
Training loss: 2.4058821756205666
Validation loss: 2.510500540949311

Epoch: 5| Step: 8
Training loss: 2.6916802298693256
Validation loss: 2.5173217538018413

Epoch: 5| Step: 9
Training loss: 2.8504393991754293
Validation loss: 2.5121734467332604

Epoch: 5| Step: 10
Training loss: 2.9006401802361137
Validation loss: 2.5046286352380367

Epoch: 138| Step: 0
Training loss: 2.8998212364609954
Validation loss: 2.504457047753131

Epoch: 5| Step: 1
Training loss: 3.103560335138535
Validation loss: 2.5008057536623456

Epoch: 5| Step: 2
Training loss: 2.4785256291661772
Validation loss: 2.5084066774847438

Epoch: 5| Step: 3
Training loss: 2.8869032536288755
Validation loss: 2.5148083219704933

Epoch: 5| Step: 4
Training loss: 2.871880705021452
Validation loss: 2.523927280982798

Epoch: 5| Step: 5
Training loss: 2.852932368415852
Validation loss: 2.5272905461702257

Epoch: 5| Step: 6
Training loss: 2.811943677346307
Validation loss: 2.519259707524357

Epoch: 5| Step: 7
Training loss: 2.9269793798556383
Validation loss: 2.509220562547162

Epoch: 5| Step: 8
Training loss: 2.8240558160447593
Validation loss: 2.500804925360518

Epoch: 5| Step: 9
Training loss: 3.0415352222485788
Validation loss: 2.4944210335078374

Epoch: 5| Step: 10
Training loss: 2.632803715994017
Validation loss: 2.498063902615006

Epoch: 139| Step: 0
Training loss: 3.049222227891624
Validation loss: 2.4951796523597376

Epoch: 5| Step: 1
Training loss: 2.7077146165769057
Validation loss: 2.495869169920033

Epoch: 5| Step: 2
Training loss: 2.894840445330011
Validation loss: 2.500040827181933

Epoch: 5| Step: 3
Training loss: 3.142513940699814
Validation loss: 2.5001587478934466

Epoch: 5| Step: 4
Training loss: 3.2892228402314423
Validation loss: 2.496651779238961

Epoch: 5| Step: 5
Training loss: 2.661538099871552
Validation loss: 2.5004527871476836

Epoch: 5| Step: 6
Training loss: 3.1089842277610216
Validation loss: 2.5070314051867735

Epoch: 5| Step: 7
Training loss: 2.355946658413046
Validation loss: 2.5241926297681463

Epoch: 5| Step: 8
Training loss: 2.6248839216452633
Validation loss: 2.5487158950879714

Epoch: 5| Step: 9
Training loss: 2.642973808894896
Validation loss: 2.700351381585972

Epoch: 5| Step: 10
Training loss: 3.2880019700353063
Validation loss: 2.9111753097939217

Epoch: 140| Step: 0
Training loss: 3.4100562711307028
Validation loss: 2.89992153495094

Epoch: 5| Step: 1
Training loss: 3.240479977930079
Validation loss: 2.838743685423554

Epoch: 5| Step: 2
Training loss: 2.7212242180615327
Validation loss: 2.6628380319332527

Epoch: 5| Step: 3
Training loss: 2.999831830715389
Validation loss: 2.5647678359424297

Epoch: 5| Step: 4
Training loss: 3.093628081414397
Validation loss: 2.5164053059662597

Epoch: 5| Step: 5
Training loss: 2.874801463030667
Validation loss: 2.509330960662981

Epoch: 5| Step: 6
Training loss: 2.557484533388088
Validation loss: 2.5070553354940275

Epoch: 5| Step: 7
Training loss: 2.5384820362632854
Validation loss: 2.5378538232475076

Epoch: 5| Step: 8
Training loss: 3.162437944971939
Validation loss: 2.5570268825765172

Epoch: 5| Step: 9
Training loss: 2.509533063155048
Validation loss: 2.5162476462221397

Epoch: 5| Step: 10
Training loss: 2.572273225418251
Validation loss: 2.5054387849236375

Epoch: 141| Step: 0
Training loss: 2.7591792278028833
Validation loss: 2.4986401602509405

Epoch: 5| Step: 1
Training loss: 3.0923484941528745
Validation loss: 2.4843097187261565

Epoch: 5| Step: 2
Training loss: 2.4242266650843636
Validation loss: 2.487595764186721

Epoch: 5| Step: 3
Training loss: 2.607377069781238
Validation loss: 2.4972693153026695

Epoch: 5| Step: 4
Training loss: 3.230807340837333
Validation loss: 2.5033975822686405

Epoch: 5| Step: 5
Training loss: 2.705518511789017
Validation loss: 2.517861963182639

Epoch: 5| Step: 6
Training loss: 2.9046516535262055
Validation loss: 2.5342513985894013

Epoch: 5| Step: 7
Training loss: 3.350247638716078
Validation loss: 2.5382380078464144

Epoch: 5| Step: 8
Training loss: 2.7291237242914135
Validation loss: 2.5557831141558887

Epoch: 5| Step: 9
Training loss: 2.857358794907793
Validation loss: 2.589088260580578

Epoch: 5| Step: 10
Training loss: 2.638955937476298
Validation loss: 2.59224576557421

Epoch: 142| Step: 0
Training loss: 2.8147775541129683
Validation loss: 2.5788622485958945

Epoch: 5| Step: 1
Training loss: 2.7660737616467506
Validation loss: 2.54141751431031

Epoch: 5| Step: 2
Training loss: 2.731980152432241
Validation loss: 2.5323534755120543

Epoch: 5| Step: 3
Training loss: 2.9468693754399364
Validation loss: 2.5252350683454114

Epoch: 5| Step: 4
Training loss: 2.766934876674074
Validation loss: 2.5028041300316266

Epoch: 5| Step: 5
Training loss: 3.0203002108478323
Validation loss: 2.492395591425521

Epoch: 5| Step: 6
Training loss: 2.831367446450794
Validation loss: 2.4917122581306512

Epoch: 5| Step: 7
Training loss: 3.1746053735785966
Validation loss: 2.4868894681435534

Epoch: 5| Step: 8
Training loss: 2.5995227962667586
Validation loss: 2.5017693370204577

Epoch: 5| Step: 9
Training loss: 2.925851981475632
Validation loss: 2.500729850141919

Epoch: 5| Step: 10
Training loss: 2.7012647280452624
Validation loss: 2.501388894124163

Epoch: 143| Step: 0
Training loss: 2.754272869407469
Validation loss: 2.511559745726238

Epoch: 5| Step: 1
Training loss: 2.909140841098899
Validation loss: 2.5076271111020794

Epoch: 5| Step: 2
Training loss: 2.9367262450231904
Validation loss: 2.5077786710881065

Epoch: 5| Step: 3
Training loss: 2.9306721977977723
Validation loss: 2.5034428997855254

Epoch: 5| Step: 4
Training loss: 3.0410463580254996
Validation loss: 2.5060080711124715

Epoch: 5| Step: 5
Training loss: 2.3369127362028728
Validation loss: 2.501441941706081

Epoch: 5| Step: 6
Training loss: 2.8594437054160307
Validation loss: 2.5036845486371835

Epoch: 5| Step: 7
Training loss: 2.502957978313826
Validation loss: 2.50218723251448

Epoch: 5| Step: 8
Training loss: 2.776722684327987
Validation loss: 2.494974527373857

Epoch: 5| Step: 9
Training loss: 3.301293472182917
Validation loss: 2.4923547727254673

Epoch: 5| Step: 10
Training loss: 2.726724002285059
Validation loss: 2.498801869242356

Epoch: 144| Step: 0
Training loss: 3.0937607890239587
Validation loss: 2.4967409189418848

Epoch: 5| Step: 1
Training loss: 2.850683625531521
Validation loss: 2.49495828220183

Epoch: 5| Step: 2
Training loss: 2.1681831872411195
Validation loss: 2.499186635758066

Epoch: 5| Step: 3
Training loss: 2.756467237150858
Validation loss: 2.5001146567109185

Epoch: 5| Step: 4
Training loss: 2.9954986180133716
Validation loss: 2.5072516224735835

Epoch: 5| Step: 5
Training loss: 3.105453702302379
Validation loss: 2.5096453495859503

Epoch: 5| Step: 6
Training loss: 2.7395474585056534
Validation loss: 2.5108387848813014

Epoch: 5| Step: 7
Training loss: 2.9556531630279603
Validation loss: 2.5068131729868526

Epoch: 5| Step: 8
Training loss: 2.766917126207574
Validation loss: 2.5014483307071793

Epoch: 5| Step: 9
Training loss: 2.7712632804142876
Validation loss: 2.502414776916241

Epoch: 5| Step: 10
Training loss: 2.8691728666712946
Validation loss: 2.5008610124610295

Epoch: 145| Step: 0
Training loss: 3.077225606974286
Validation loss: 2.5001215423243903

Epoch: 5| Step: 1
Training loss: 2.907553431773553
Validation loss: 2.4959448114355323

Epoch: 5| Step: 2
Training loss: 2.9577282747991553
Validation loss: 2.5045746223558525

Epoch: 5| Step: 3
Training loss: 2.3756044522114155
Validation loss: 2.5116924951206565

Epoch: 5| Step: 4
Training loss: 2.6095165282831716
Validation loss: 2.507794262785202

Epoch: 5| Step: 5
Training loss: 1.951953383944412
Validation loss: 2.514817231157508

Epoch: 5| Step: 6
Training loss: 2.492140336023888
Validation loss: 2.518180543239845

Epoch: 5| Step: 7
Training loss: 3.231202564592281
Validation loss: 2.5228818678371194

Epoch: 5| Step: 8
Training loss: 3.1867258964471534
Validation loss: 2.510885218834555

Epoch: 5| Step: 9
Training loss: 2.6844431325594886
Validation loss: 2.4990036455629183

Epoch: 5| Step: 10
Training loss: 3.465504132872806
Validation loss: 2.503196254353759

Epoch: 146| Step: 0
Training loss: 2.9841281329403655
Validation loss: 2.4957303380524283

Epoch: 5| Step: 1
Training loss: 2.101570895153422
Validation loss: 2.4906825548261056

Epoch: 5| Step: 2
Training loss: 2.5201301749985037
Validation loss: 2.4895277668858284

Epoch: 5| Step: 3
Training loss: 3.378301912628031
Validation loss: 2.490916337331102

Epoch: 5| Step: 4
Training loss: 2.5854711198464506
Validation loss: 2.49095634802573

Epoch: 5| Step: 5
Training loss: 2.5696567058237396
Validation loss: 2.487889067622403

Epoch: 5| Step: 6
Training loss: 3.0682095613092297
Validation loss: 2.486636516716302

Epoch: 5| Step: 7
Training loss: 3.0646291065925286
Validation loss: 2.493505600919287

Epoch: 5| Step: 8
Training loss: 3.1550880030526622
Validation loss: 2.498667244830699

Epoch: 5| Step: 9
Training loss: 2.7644175679333762
Validation loss: 2.500867931898081

Epoch: 5| Step: 10
Training loss: 2.63614170117903
Validation loss: 2.5118515512076223

Epoch: 147| Step: 0
Training loss: 2.712744206980696
Validation loss: 2.5152769709766774

Epoch: 5| Step: 1
Training loss: 3.0856761966604997
Validation loss: 2.515598709457208

Epoch: 5| Step: 2
Training loss: 3.182224770366754
Validation loss: 2.5111862039335264

Epoch: 5| Step: 3
Training loss: 2.802891998643685
Validation loss: 2.5177334888095286

Epoch: 5| Step: 4
Training loss: 2.95616098798175
Validation loss: 2.5066782496302973

Epoch: 5| Step: 5
Training loss: 2.9903498252941443
Validation loss: 2.500407302656028

Epoch: 5| Step: 6
Training loss: 2.5062853004461934
Validation loss: 2.5032122289458307

Epoch: 5| Step: 7
Training loss: 2.9644099585385817
Validation loss: 2.496119262065784

Epoch: 5| Step: 8
Training loss: 2.76432674992865
Validation loss: 2.4783162055744428

Epoch: 5| Step: 9
Training loss: 2.876112183771721
Validation loss: 2.484769072093714

Epoch: 5| Step: 10
Training loss: 1.8655460436804874
Validation loss: 2.488498018854881

Epoch: 148| Step: 0
Training loss: 2.864094159523087
Validation loss: 2.4853320247779043

Epoch: 5| Step: 1
Training loss: 2.8188849135632172
Validation loss: 2.481959205403575

Epoch: 5| Step: 2
Training loss: 2.915293579236439
Validation loss: 2.488557244116546

Epoch: 5| Step: 3
Training loss: 2.7725646458786444
Validation loss: 2.4829129910168275

Epoch: 5| Step: 4
Training loss: 2.7765074166848547
Validation loss: 2.50213908695825

Epoch: 5| Step: 5
Training loss: 2.4366416397931654
Validation loss: 2.5106834518695766

Epoch: 5| Step: 6
Training loss: 2.950894921547139
Validation loss: 2.5108864389420265

Epoch: 5| Step: 7
Training loss: 2.765396884626942
Validation loss: 2.5155828868979366

Epoch: 5| Step: 8
Training loss: 3.2466041723681953
Validation loss: 2.5008796626066214

Epoch: 5| Step: 9
Training loss: 2.6174974855777062
Validation loss: 2.4878980943316393

Epoch: 5| Step: 10
Training loss: 2.7554784304668076
Validation loss: 2.481785055822051

Epoch: 149| Step: 0
Training loss: 2.5657422093556836
Validation loss: 2.4900714476254566

Epoch: 5| Step: 1
Training loss: 3.3371662673110416
Validation loss: 2.487408251159456

Epoch: 5| Step: 2
Training loss: 2.641926100674154
Validation loss: 2.4797356999403335

Epoch: 5| Step: 3
Training loss: 2.624512854287545
Validation loss: 2.492086734509726

Epoch: 5| Step: 4
Training loss: 2.5006034122861442
Validation loss: 2.4838823214477745

Epoch: 5| Step: 5
Training loss: 3.1041493426016595
Validation loss: 2.49313218907541

Epoch: 5| Step: 6
Training loss: 2.770355231164776
Validation loss: 2.4855921245550694

Epoch: 5| Step: 7
Training loss: 2.7978936583329688
Validation loss: 2.489281362689463

Epoch: 5| Step: 8
Training loss: 2.8293909432493085
Validation loss: 2.5160418352158374

Epoch: 5| Step: 9
Training loss: 2.7456649944779965
Validation loss: 2.505647672754538

Epoch: 5| Step: 10
Training loss: 3.0541281419712183
Validation loss: 2.5273028262613217

Epoch: 150| Step: 0
Training loss: 3.112891734033637
Validation loss: 2.5158547151516824

Epoch: 5| Step: 1
Training loss: 3.0270703001500943
Validation loss: 2.5194396014793616

Epoch: 5| Step: 2
Training loss: 3.24833607260711
Validation loss: 2.5218213083586174

Epoch: 5| Step: 3
Training loss: 2.7561477088544586
Validation loss: 2.4990692467235625

Epoch: 5| Step: 4
Training loss: 2.489366998144837
Validation loss: 2.4858638589452844

Epoch: 5| Step: 5
Training loss: 2.838532408719612
Validation loss: 2.4869053619279446

Epoch: 5| Step: 6
Training loss: 2.534365396916532
Validation loss: 2.480699769529855

Epoch: 5| Step: 7
Training loss: 2.902555352733793
Validation loss: 2.481326276200295

Epoch: 5| Step: 8
Training loss: 2.321720813339798
Validation loss: 2.481041139050054

Epoch: 5| Step: 9
Training loss: 2.981637548052503
Validation loss: 2.4756031879522142

Epoch: 5| Step: 10
Training loss: 2.8122708545162176
Validation loss: 2.478331585407982

Epoch: 151| Step: 0
Training loss: 2.5633013332967236
Validation loss: 2.4794712791221585

Epoch: 5| Step: 1
Training loss: 3.4269008568569723
Validation loss: 2.482212019989189

Epoch: 5| Step: 2
Training loss: 2.811699647406629
Validation loss: 2.477565043973379

Epoch: 5| Step: 3
Training loss: 2.5641630405238804
Validation loss: 2.476304005800903

Epoch: 5| Step: 4
Training loss: 3.1256591101793036
Validation loss: 2.4731076744457674

Epoch: 5| Step: 5
Training loss: 2.5536594013681233
Validation loss: 2.47826446085747

Epoch: 5| Step: 6
Training loss: 2.680476214388197
Validation loss: 2.4812673918424317

Epoch: 5| Step: 7
Training loss: 2.59120954630107
Validation loss: 2.4789801906883024

Epoch: 5| Step: 8
Training loss: 2.291825641551022
Validation loss: 2.4811148571587305

Epoch: 5| Step: 9
Training loss: 3.2613137730437893
Validation loss: 2.4910623980606936

Epoch: 5| Step: 10
Training loss: 2.987334696134827
Validation loss: 2.5001366383118664

Epoch: 152| Step: 0
Training loss: 2.501790645186469
Validation loss: 2.505395310564836

Epoch: 5| Step: 1
Training loss: 2.559594996572362
Validation loss: 2.5056760280318318

Epoch: 5| Step: 2
Training loss: 2.9959654699762543
Validation loss: 2.5032351040400544

Epoch: 5| Step: 3
Training loss: 2.700972565574814
Validation loss: 2.507594510599549

Epoch: 5| Step: 4
Training loss: 2.7334532137687657
Validation loss: 2.509202971060845

Epoch: 5| Step: 5
Training loss: 2.8312488816955916
Validation loss: 2.499078371537471

Epoch: 5| Step: 6
Training loss: 2.881000724816223
Validation loss: 2.4917445046730102

Epoch: 5| Step: 7
Training loss: 2.849220798450902
Validation loss: 2.491414359648576

Epoch: 5| Step: 8
Training loss: 2.8512290446085413
Validation loss: 2.501109291408821

Epoch: 5| Step: 9
Training loss: 2.9563319640460923
Validation loss: 2.5006362771888306

Epoch: 5| Step: 10
Training loss: 3.2587679918595103
Validation loss: 2.5062801788577715

Epoch: 153| Step: 0
Training loss: 2.7270896423904105
Validation loss: 2.52276738362109

Epoch: 5| Step: 1
Training loss: 3.2004578441673748
Validation loss: 2.521454761873558

Epoch: 5| Step: 2
Training loss: 2.623671604273819
Validation loss: 2.527853944741184

Epoch: 5| Step: 3
Training loss: 2.8546654110008496
Validation loss: 2.516002988662339

Epoch: 5| Step: 4
Training loss: 2.2491049575773414
Validation loss: 2.518833274790918

Epoch: 5| Step: 5
Training loss: 3.0863951524766633
Validation loss: 2.509218703074243

Epoch: 5| Step: 6
Training loss: 2.8122265152948893
Validation loss: 2.502155409482431

Epoch: 5| Step: 7
Training loss: 2.9332572652606013
Validation loss: 2.4711382627546

Epoch: 5| Step: 8
Training loss: 2.9963022331105975
Validation loss: 2.478835347359586

Epoch: 5| Step: 9
Training loss: 2.9090801937816253
Validation loss: 2.499176025989673

Epoch: 5| Step: 10
Training loss: 2.759290520659012
Validation loss: 2.5132252732382065

Epoch: 154| Step: 0
Training loss: 2.7473397826251977
Validation loss: 2.5213523017988977

Epoch: 5| Step: 1
Training loss: 2.837959010435082
Validation loss: 2.5332662486756194

Epoch: 5| Step: 2
Training loss: 3.064553642690998
Validation loss: 2.5453600126802596

Epoch: 5| Step: 3
Training loss: 2.4575787587705715
Validation loss: 2.5537819064001104

Epoch: 5| Step: 4
Training loss: 3.0420464230718953
Validation loss: 2.5708465824200295

Epoch: 5| Step: 5
Training loss: 3.1279504199476817
Validation loss: 2.568405282090544

Epoch: 5| Step: 6
Training loss: 2.125649745564944
Validation loss: 2.596150389712468

Epoch: 5| Step: 7
Training loss: 2.794408211200356
Validation loss: 2.614743018551379

Epoch: 5| Step: 8
Training loss: 3.6891358190131043
Validation loss: 2.628072693319013

Epoch: 5| Step: 9
Training loss: 2.8194013904443356
Validation loss: 2.613778617071633

Epoch: 5| Step: 10
Training loss: 2.6773616383881356
Validation loss: 2.577087754519934

Epoch: 155| Step: 0
Training loss: 2.86177370943932
Validation loss: 2.555707088009555

Epoch: 5| Step: 1
Training loss: 2.9891550818471293
Validation loss: 2.5230717786539367

Epoch: 5| Step: 2
Training loss: 3.0618112529185293
Validation loss: 2.512294749108144

Epoch: 5| Step: 3
Training loss: 3.0063501543583295
Validation loss: 2.5092145212985164

Epoch: 5| Step: 4
Training loss: 2.454958673816919
Validation loss: 2.5053491115168294

Epoch: 5| Step: 5
Training loss: 2.6706177726163944
Validation loss: 2.5063160256654555

Epoch: 5| Step: 6
Training loss: 3.0040192700617525
Validation loss: 2.5165155203071428

Epoch: 5| Step: 7
Training loss: 2.9050825501890793
Validation loss: 2.5156688896543558

Epoch: 5| Step: 8
Training loss: 2.3008336836793775
Validation loss: 2.51365360278515

Epoch: 5| Step: 9
Training loss: 2.924001317828882
Validation loss: 2.5072437349704737

Epoch: 5| Step: 10
Training loss: 3.080017747208629
Validation loss: 2.504787934163195

Epoch: 156| Step: 0
Training loss: 2.8622875284691234
Validation loss: 2.509475754982227

Epoch: 5| Step: 1
Training loss: 3.185157962636742
Validation loss: 2.510868548737775

Epoch: 5| Step: 2
Training loss: 2.416981336781199
Validation loss: 2.514088369192679

Epoch: 5| Step: 3
Training loss: 2.734542579965261
Validation loss: 2.540401800300383

Epoch: 5| Step: 4
Training loss: 2.97616598536996
Validation loss: 2.5285334004436826

Epoch: 5| Step: 5
Training loss: 2.972516210718764
Validation loss: 2.5212550680431396

Epoch: 5| Step: 6
Training loss: 2.6277216471384652
Validation loss: 2.5241412790956788

Epoch: 5| Step: 7
Training loss: 2.1576769985825965
Validation loss: 2.5092480325230966

Epoch: 5| Step: 8
Training loss: 3.167020945222887
Validation loss: 2.5005308284997576

Epoch: 5| Step: 9
Training loss: 3.0073213250539133
Validation loss: 2.488046403833116

Epoch: 5| Step: 10
Training loss: 2.9004900879936337
Validation loss: 2.4821741384835097

Epoch: 157| Step: 0
Training loss: 2.771512763299377
Validation loss: 2.481349705365893

Epoch: 5| Step: 1
Training loss: 2.781826002503234
Validation loss: 2.4813799221229176

Epoch: 5| Step: 2
Training loss: 2.7726421236531253
Validation loss: 2.480920558144785

Epoch: 5| Step: 3
Training loss: 2.3287086523278857
Validation loss: 2.483926291023446

Epoch: 5| Step: 4
Training loss: 2.149114994385884
Validation loss: 2.48695161187094

Epoch: 5| Step: 5
Training loss: 2.8330340694879395
Validation loss: 2.4888731591062836

Epoch: 5| Step: 6
Training loss: 3.031138939150203
Validation loss: 2.488773024776019

Epoch: 5| Step: 7
Training loss: 3.225800726793193
Validation loss: 2.4962664299615223

Epoch: 5| Step: 8
Training loss: 3.16929694577412
Validation loss: 2.495923861133562

Epoch: 5| Step: 9
Training loss: 3.0758364152406275
Validation loss: 2.4968196369256246

Epoch: 5| Step: 10
Training loss: 2.5906799715511637
Validation loss: 2.494568237874418

Epoch: 158| Step: 0
Training loss: 3.1936880146737567
Validation loss: 2.4873114977763584

Epoch: 5| Step: 1
Training loss: 2.7683202681289596
Validation loss: 2.4734576154546515

Epoch: 5| Step: 2
Training loss: 3.126475024203029
Validation loss: 2.474641595775029

Epoch: 5| Step: 3
Training loss: 2.1865312883679957
Validation loss: 2.4637005237535305

Epoch: 5| Step: 4
Training loss: 2.8433482127305285
Validation loss: 2.4644262489625675

Epoch: 5| Step: 5
Training loss: 2.4386867666332126
Validation loss: 2.4718823015073985

Epoch: 5| Step: 6
Training loss: 2.581479843288522
Validation loss: 2.4715257872904166

Epoch: 5| Step: 7
Training loss: 2.781119011355369
Validation loss: 2.462967339708313

Epoch: 5| Step: 8
Training loss: 2.949551473884585
Validation loss: 2.467474274875086

Epoch: 5| Step: 9
Training loss: 2.6270437005179703
Validation loss: 2.467571241415055

Epoch: 5| Step: 10
Training loss: 3.1472907995339505
Validation loss: 2.47123087059755

Epoch: 159| Step: 0
Training loss: 2.7366232212566
Validation loss: 2.480564686666692

Epoch: 5| Step: 1
Training loss: 2.3679496117463166
Validation loss: 2.488791974094869

Epoch: 5| Step: 2
Training loss: 3.1922801956109743
Validation loss: 2.4994834509820443

Epoch: 5| Step: 3
Training loss: 2.6989351998656304
Validation loss: 2.5167978047485295

Epoch: 5| Step: 4
Training loss: 2.747400355523653
Validation loss: 2.501007061825547

Epoch: 5| Step: 5
Training loss: 2.8188427928867408
Validation loss: 2.501508786616571

Epoch: 5| Step: 6
Training loss: 2.8118236152276435
Validation loss: 2.482425856122961

Epoch: 5| Step: 7
Training loss: 2.5567383539858333
Validation loss: 2.46934356864377

Epoch: 5| Step: 8
Training loss: 2.93010885641838
Validation loss: 2.4653979684117946

Epoch: 5| Step: 9
Training loss: 3.0390912130612584
Validation loss: 2.4701198403152285

Epoch: 5| Step: 10
Training loss: 2.8440378902717294
Validation loss: 2.4683289527753103

Epoch: 160| Step: 0
Training loss: 3.3015138794929175
Validation loss: 2.477088991044149

Epoch: 5| Step: 1
Training loss: 2.539407090499051
Validation loss: 2.478631156075649

Epoch: 5| Step: 2
Training loss: 2.914979028642703
Validation loss: 2.4971491648546245

Epoch: 5| Step: 3
Training loss: 2.5641736403419926
Validation loss: 2.4949803924612106

Epoch: 5| Step: 4
Training loss: 2.852562130812236
Validation loss: 2.4822609982108097

Epoch: 5| Step: 5
Training loss: 3.2147991042901616
Validation loss: 2.487742475874579

Epoch: 5| Step: 6
Training loss: 2.462968260882338
Validation loss: 2.4896378437599247

Epoch: 5| Step: 7
Training loss: 3.1513916998194493
Validation loss: 2.486751783392153

Epoch: 5| Step: 8
Training loss: 2.681805454864633
Validation loss: 2.488881415898789

Epoch: 5| Step: 9
Training loss: 2.183940279902177
Validation loss: 2.4890067229593145

Epoch: 5| Step: 10
Training loss: 2.6537441326549063
Validation loss: 2.4885172298752143

Epoch: 161| Step: 0
Training loss: 3.04089676680454
Validation loss: 2.4834001640402956

Epoch: 5| Step: 1
Training loss: 3.1652192438492
Validation loss: 2.47450984142108

Epoch: 5| Step: 2
Training loss: 3.185179669928232
Validation loss: 2.478378421523281

Epoch: 5| Step: 3
Training loss: 2.519254542096923
Validation loss: 2.4692477888354367

Epoch: 5| Step: 4
Training loss: 2.5638099671580528
Validation loss: 2.469191681352731

Epoch: 5| Step: 5
Training loss: 2.819936204148081
Validation loss: 2.462513824194218

Epoch: 5| Step: 6
Training loss: 2.516602415144646
Validation loss: 2.464627616598977

Epoch: 5| Step: 7
Training loss: 2.7240651233131388
Validation loss: 2.459234583109726

Epoch: 5| Step: 8
Training loss: 2.3847598264031675
Validation loss: 2.4675849926909383

Epoch: 5| Step: 9
Training loss: 2.9686703319902437
Validation loss: 2.4629069026533275

Epoch: 5| Step: 10
Training loss: 2.52222756115894
Validation loss: 2.464740193059219

Epoch: 162| Step: 0
Training loss: 2.8533777599203556
Validation loss: 2.4660226168026047

Epoch: 5| Step: 1
Training loss: 3.1285683667341506
Validation loss: 2.4836882502867637

Epoch: 5| Step: 2
Training loss: 2.7052736948426435
Validation loss: 2.5096504316184576

Epoch: 5| Step: 3
Training loss: 2.8862993196327036
Validation loss: 2.5330405071179927

Epoch: 5| Step: 4
Training loss: 3.046347704523078
Validation loss: 2.5181585878184545

Epoch: 5| Step: 5
Training loss: 1.9866990424831443
Validation loss: 2.509419021687194

Epoch: 5| Step: 6
Training loss: 2.6652282670046255
Validation loss: 2.50069396016402

Epoch: 5| Step: 7
Training loss: 2.9335256434025743
Validation loss: 2.481619492121585

Epoch: 5| Step: 8
Training loss: 3.0220280005964804
Validation loss: 2.4732908910496243

Epoch: 5| Step: 9
Training loss: 2.5637988078708496
Validation loss: 2.463965407197078

Epoch: 5| Step: 10
Training loss: 2.7940004377316985
Validation loss: 2.4560211310476183

Epoch: 163| Step: 0
Training loss: 2.9416763161419026
Validation loss: 2.4589201138423427

Epoch: 5| Step: 1
Training loss: 2.5009206983828194
Validation loss: 2.457474397035987

Epoch: 5| Step: 2
Training loss: 2.9398742171388315
Validation loss: 2.4570305989248586

Epoch: 5| Step: 3
Training loss: 3.201615885209877
Validation loss: 2.4570325072840395

Epoch: 5| Step: 4
Training loss: 2.2984906178138345
Validation loss: 2.4564071382487556

Epoch: 5| Step: 5
Training loss: 2.707045341774289
Validation loss: 2.4566554622678765

Epoch: 5| Step: 6
Training loss: 2.5556056621264887
Validation loss: 2.451112537117663

Epoch: 5| Step: 7
Training loss: 2.878846953362368
Validation loss: 2.453866993102413

Epoch: 5| Step: 8
Training loss: 2.534806943084324
Validation loss: 2.45538487248663

Epoch: 5| Step: 9
Training loss: 3.1658916696219626
Validation loss: 2.4840757974459984

Epoch: 5| Step: 10
Training loss: 2.801779341723008
Validation loss: 2.520734717090089

Epoch: 164| Step: 0
Training loss: 2.9951772071240117
Validation loss: 2.563576127938751

Epoch: 5| Step: 1
Training loss: 2.5711148293905244
Validation loss: 2.578379853430919

Epoch: 5| Step: 2
Training loss: 3.4508408116180767
Validation loss: 2.5698382094657695

Epoch: 5| Step: 3
Training loss: 2.420931921662344
Validation loss: 2.5629189021567247

Epoch: 5| Step: 4
Training loss: 2.595320995668289
Validation loss: 2.556374317015232

Epoch: 5| Step: 5
Training loss: 3.1234578714474495
Validation loss: 2.5333505369497105

Epoch: 5| Step: 6
Training loss: 2.7688085476646096
Validation loss: 2.520247721315898

Epoch: 5| Step: 7
Training loss: 3.0592701287068373
Validation loss: 2.503898511680778

Epoch: 5| Step: 8
Training loss: 2.548484901908891
Validation loss: 2.469484874323127

Epoch: 5| Step: 9
Training loss: 2.561779106897275
Validation loss: 2.469336682339142

Epoch: 5| Step: 10
Training loss: 2.595562313212927
Validation loss: 2.451787900467422

Epoch: 165| Step: 0
Training loss: 2.1011961436815962
Validation loss: 2.4469145920244215

Epoch: 5| Step: 1
Training loss: 2.8978631203643275
Validation loss: 2.448438463036078

Epoch: 5| Step: 2
Training loss: 2.7234010922684333
Validation loss: 2.457057726909585

Epoch: 5| Step: 3
Training loss: 2.708094004302457
Validation loss: 2.456067363427656

Epoch: 5| Step: 4
Training loss: 2.9206488173281215
Validation loss: 2.45487038334544

Epoch: 5| Step: 5
Training loss: 2.3822282919205415
Validation loss: 2.455883222032355

Epoch: 5| Step: 6
Training loss: 3.134543989195659
Validation loss: 2.4558858494699995

Epoch: 5| Step: 7
Training loss: 3.23843261953971
Validation loss: 2.462265638092106

Epoch: 5| Step: 8
Training loss: 2.667412762775079
Validation loss: 2.471951514871539

Epoch: 5| Step: 9
Training loss: 3.1133906059252308
Validation loss: 2.4724715326711504

Epoch: 5| Step: 10
Training loss: 2.6852129586441116
Validation loss: 2.482016911352055

Epoch: 166| Step: 0
Training loss: 2.5151078539676672
Validation loss: 2.4771224235484

Epoch: 5| Step: 1
Training loss: 2.891858966453992
Validation loss: 2.463642976713

Epoch: 5| Step: 2
Training loss: 2.7285084598040314
Validation loss: 2.4575149834929833

Epoch: 5| Step: 3
Training loss: 2.9801764388623853
Validation loss: 2.44477827551878

Epoch: 5| Step: 4
Training loss: 2.614312166739767
Validation loss: 2.4608458070068795

Epoch: 5| Step: 5
Training loss: 2.963059603474948
Validation loss: 2.457734670338268

Epoch: 5| Step: 6
Training loss: 2.4536241157254572
Validation loss: 2.453705747589803

Epoch: 5| Step: 7
Training loss: 2.843230483001294
Validation loss: 2.4533075259903554

Epoch: 5| Step: 8
Training loss: 3.188057944140946
Validation loss: 2.45153092985082

Epoch: 5| Step: 9
Training loss: 2.158642312496626
Validation loss: 2.4490098036721895

Epoch: 5| Step: 10
Training loss: 3.1931297103001874
Validation loss: 2.455747137379224

Epoch: 167| Step: 0
Training loss: 2.741696827344794
Validation loss: 2.4780422613839677

Epoch: 5| Step: 1
Training loss: 2.702400419110299
Validation loss: 2.507023298157967

Epoch: 5| Step: 2
Training loss: 2.588876120581768
Validation loss: 2.513342563123357

Epoch: 5| Step: 3
Training loss: 2.532039754606687
Validation loss: 2.511979140512961

Epoch: 5| Step: 4
Training loss: 2.6425530431759614
Validation loss: 2.511067817913847

Epoch: 5| Step: 5
Training loss: 2.6406091091422743
Validation loss: 2.495286958685884

Epoch: 5| Step: 6
Training loss: 2.9892267065414404
Validation loss: 2.4696474221220255

Epoch: 5| Step: 7
Training loss: 2.4721764073311685
Validation loss: 2.453420187189946

Epoch: 5| Step: 8
Training loss: 2.73979286775313
Validation loss: 2.459724696468386

Epoch: 5| Step: 9
Training loss: 3.405754123255419
Validation loss: 2.452996125110634

Epoch: 5| Step: 10
Training loss: 3.1517428708223165
Validation loss: 2.4554341655274636

Epoch: 168| Step: 0
Training loss: 2.547550884034387
Validation loss: 2.456430055753444

Epoch: 5| Step: 1
Training loss: 2.6454148049126944
Validation loss: 2.4556905272580196

Epoch: 5| Step: 2
Training loss: 2.3951498853574145
Validation loss: 2.457311841066783

Epoch: 5| Step: 3
Training loss: 2.724014096877583
Validation loss: 2.460323315304984

Epoch: 5| Step: 4
Training loss: 2.7753280858101657
Validation loss: 2.4578424161357875

Epoch: 5| Step: 5
Training loss: 3.4229067287815464
Validation loss: 2.458797703664589

Epoch: 5| Step: 6
Training loss: 2.9709034387592674
Validation loss: 2.4621933287157076

Epoch: 5| Step: 7
Training loss: 2.821160017411553
Validation loss: 2.4608763328251873

Epoch: 5| Step: 8
Training loss: 2.62562553581917
Validation loss: 2.4718236599255796

Epoch: 5| Step: 9
Training loss: 2.6527049923998107
Validation loss: 2.472111362884302

Epoch: 5| Step: 10
Training loss: 2.68791098002779
Validation loss: 2.477835310054017

Epoch: 169| Step: 0
Training loss: 2.6647982210705927
Validation loss: 2.4783847313700074

Epoch: 5| Step: 1
Training loss: 2.6675803486843677
Validation loss: 2.474119891260078

Epoch: 5| Step: 2
Training loss: 2.813338599749995
Validation loss: 2.4726886330808577

Epoch: 5| Step: 3
Training loss: 2.332000067676524
Validation loss: 2.471397392695143

Epoch: 5| Step: 4
Training loss: 2.5017420421362084
Validation loss: 2.464314446192294

Epoch: 5| Step: 5
Training loss: 2.469967891777862
Validation loss: 2.464798980286026

Epoch: 5| Step: 6
Training loss: 2.9869392922269475
Validation loss: 2.460123316342431

Epoch: 5| Step: 7
Training loss: 3.4795692043469053
Validation loss: 2.445773373797351

Epoch: 5| Step: 8
Training loss: 2.561534141317466
Validation loss: 2.45029252235317

Epoch: 5| Step: 9
Training loss: 2.6992074438981737
Validation loss: 2.4541733028116632

Epoch: 5| Step: 10
Training loss: 3.03299670674604
Validation loss: 2.4443973623034783

Epoch: 170| Step: 0
Training loss: 2.451149795250405
Validation loss: 2.4586841492142892

Epoch: 5| Step: 1
Training loss: 2.9555570084545164
Validation loss: 2.4659778029958455

Epoch: 5| Step: 2
Training loss: 2.753188625470815
Validation loss: 2.4656985682377903

Epoch: 5| Step: 3
Training loss: 2.854750599030678
Validation loss: 2.4754307287665767

Epoch: 5| Step: 4
Training loss: 2.5458228623528134
Validation loss: 2.4714621354076214

Epoch: 5| Step: 5
Training loss: 2.7713171362068243
Validation loss: 2.468529083473642

Epoch: 5| Step: 6
Training loss: 3.0161748987579386
Validation loss: 2.4748465414524907

Epoch: 5| Step: 7
Training loss: 2.4499028906747657
Validation loss: 2.4632929319283177

Epoch: 5| Step: 8
Training loss: 2.6868611840697945
Validation loss: 2.459625365198839

Epoch: 5| Step: 9
Training loss: 2.9341903872200574
Validation loss: 2.4582319668046075

Epoch: 5| Step: 10
Training loss: 2.8467718145469827
Validation loss: 2.4426131740371098

Epoch: 171| Step: 0
Training loss: 2.132046181083779
Validation loss: 2.443081391456779

Epoch: 5| Step: 1
Training loss: 2.2965650284436983
Validation loss: 2.4391382305909945

Epoch: 5| Step: 2
Training loss: 2.5830354108579963
Validation loss: 2.438635924019935

Epoch: 5| Step: 3
Training loss: 2.7901842442046125
Validation loss: 2.442637351313331

Epoch: 5| Step: 4
Training loss: 3.1923202270459705
Validation loss: 2.446735211300454

Epoch: 5| Step: 5
Training loss: 2.80089446494722
Validation loss: 2.4374452000535185

Epoch: 5| Step: 6
Training loss: 3.091885862437411
Validation loss: 2.4455315968342264

Epoch: 5| Step: 7
Training loss: 2.8914600712596683
Validation loss: 2.447191776631623

Epoch: 5| Step: 8
Training loss: 2.7027555003679646
Validation loss: 2.4521831002410632

Epoch: 5| Step: 9
Training loss: 2.55490130075228
Validation loss: 2.4577073850154063

Epoch: 5| Step: 10
Training loss: 3.0809180276249375
Validation loss: 2.485625229192273

Epoch: 172| Step: 0
Training loss: 2.3040077370805108
Validation loss: 2.5029204292333063

Epoch: 5| Step: 1
Training loss: 2.510565746729678
Validation loss: 2.503868046551774

Epoch: 5| Step: 2
Training loss: 2.5618253610664072
Validation loss: 2.499752925640984

Epoch: 5| Step: 3
Training loss: 2.651479948396376
Validation loss: 2.516598548190029

Epoch: 5| Step: 4
Training loss: 3.300323129497207
Validation loss: 2.498400674975019

Epoch: 5| Step: 5
Training loss: 3.076021201667093
Validation loss: 2.4894878516566807

Epoch: 5| Step: 6
Training loss: 3.0235206139153403
Validation loss: 2.496833975621999

Epoch: 5| Step: 7
Training loss: 3.0522862042562244
Validation loss: 2.481190481453871

Epoch: 5| Step: 8
Training loss: 2.1668598260119913
Validation loss: 2.4559589713829455

Epoch: 5| Step: 9
Training loss: 2.680379083212694
Validation loss: 2.4438497632021186

Epoch: 5| Step: 10
Training loss: 2.732210010661406
Validation loss: 2.442488589470333

Epoch: 173| Step: 0
Training loss: 2.7144065450003114
Validation loss: 2.443978217237439

Epoch: 5| Step: 1
Training loss: 2.562899209537092
Validation loss: 2.4415637633999983

Epoch: 5| Step: 2
Training loss: 2.741668043358485
Validation loss: 2.441475303542923

Epoch: 5| Step: 3
Training loss: 3.0674170122058753
Validation loss: 2.449123297952241

Epoch: 5| Step: 4
Training loss: 2.7627879100611805
Validation loss: 2.4571683913768276

Epoch: 5| Step: 5
Training loss: 2.9966956060056735
Validation loss: 2.4596353784495566

Epoch: 5| Step: 6
Training loss: 2.8765612799596814
Validation loss: 2.4537869055476444

Epoch: 5| Step: 7
Training loss: 2.120675904652104
Validation loss: 2.4717359615000825

Epoch: 5| Step: 8
Training loss: 2.722823850708096
Validation loss: 2.4664523199794335

Epoch: 5| Step: 9
Training loss: 2.912904401871671
Validation loss: 2.4727425254916917

Epoch: 5| Step: 10
Training loss: 2.6279972766589217
Validation loss: 2.455131381709113

Epoch: 174| Step: 0
Training loss: 2.928423229814133
Validation loss: 2.45281700832809

Epoch: 5| Step: 1
Training loss: 2.714201267979552
Validation loss: 2.4538226426578267

Epoch: 5| Step: 2
Training loss: 2.846770307037481
Validation loss: 2.455212625150716

Epoch: 5| Step: 3
Training loss: 2.5030878071397065
Validation loss: 2.4526346277084534

Epoch: 5| Step: 4
Training loss: 3.0494597597533537
Validation loss: 2.4540052400301327

Epoch: 5| Step: 5
Training loss: 2.9162747982718713
Validation loss: 2.437846073754569

Epoch: 5| Step: 6
Training loss: 2.0379170090508616
Validation loss: 2.4473777394188403

Epoch: 5| Step: 7
Training loss: 2.6222710729707486
Validation loss: 2.4535826457398753

Epoch: 5| Step: 8
Training loss: 2.9450667301512787
Validation loss: 2.450036383712993

Epoch: 5| Step: 9
Training loss: 2.537087009440007
Validation loss: 2.443974423138412

Epoch: 5| Step: 10
Training loss: 3.005151458325451
Validation loss: 2.4544729293406546

Epoch: 175| Step: 0
Training loss: 2.4898852773075375
Validation loss: 2.4475758256135136

Epoch: 5| Step: 1
Training loss: 2.59937439507828
Validation loss: 2.456807326320329

Epoch: 5| Step: 2
Training loss: 2.818109132439059
Validation loss: 2.457066958703157

Epoch: 5| Step: 3
Training loss: 2.8374283500061206
Validation loss: 2.4512014973841816

Epoch: 5| Step: 4
Training loss: 2.857383493099192
Validation loss: 2.4426971490564893

Epoch: 5| Step: 5
Training loss: 2.673804049665626
Validation loss: 2.449937322537692

Epoch: 5| Step: 6
Training loss: 2.828152398245437
Validation loss: 2.4514882500809

Epoch: 5| Step: 7
Training loss: 2.70397979803834
Validation loss: 2.440400626643557

Epoch: 5| Step: 8
Training loss: 2.733378288628176
Validation loss: 2.448259964650185

Epoch: 5| Step: 9
Training loss: 3.194765375205557
Validation loss: 2.4537978829115894

Epoch: 5| Step: 10
Training loss: 2.159823897388561
Validation loss: 2.442894017031391

Testing loss: 2.729872503078691
