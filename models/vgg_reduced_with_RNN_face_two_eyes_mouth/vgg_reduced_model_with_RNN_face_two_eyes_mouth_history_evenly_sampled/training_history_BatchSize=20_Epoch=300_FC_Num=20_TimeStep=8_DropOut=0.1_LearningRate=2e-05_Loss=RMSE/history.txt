Epoch: 1| Step: 0
Training loss: 5.488473431354975
Validation loss: 5.82739982436068

Epoch: 5| Step: 1
Training loss: 6.431190732158271
Validation loss: 5.801240033442946

Epoch: 5| Step: 2
Training loss: 5.283388686667326
Validation loss: 5.775852195786153

Epoch: 5| Step: 3
Training loss: 6.044026968289288
Validation loss: 5.749064044295507

Epoch: 5| Step: 4
Training loss: 6.090441622451868
Validation loss: 5.718890910970902

Epoch: 5| Step: 5
Training loss: 4.072243142923552
Validation loss: 5.685752426178072

Epoch: 5| Step: 6
Training loss: 6.0863251666686216
Validation loss: 5.64840816557755

Epoch: 5| Step: 7
Training loss: 5.88420422873965
Validation loss: 5.60743871591669

Epoch: 5| Step: 8
Training loss: 6.018521966308302
Validation loss: 5.5626946848782515

Epoch: 5| Step: 9
Training loss: 6.040056035874494
Validation loss: 5.513161393353915

Epoch: 5| Step: 10
Training loss: 4.768670581641275
Validation loss: 5.461347093472368

Epoch: 2| Step: 0
Training loss: 4.43626107127167
Validation loss: 5.406980143832735

Epoch: 5| Step: 1
Training loss: 5.504245853167296
Validation loss: 5.351264732513352

Epoch: 5| Step: 2
Training loss: 4.46346584093935
Validation loss: 5.291841388608736

Epoch: 5| Step: 3
Training loss: 5.621631715863617
Validation loss: 5.23069103368166

Epoch: 5| Step: 4
Training loss: 5.942954679883436
Validation loss: 5.167498059553423

Epoch: 5| Step: 5
Training loss: 5.093647212764208
Validation loss: 5.101476387330206

Epoch: 5| Step: 6
Training loss: 5.56609613993629
Validation loss: 5.034760481712969

Epoch: 5| Step: 7
Training loss: 5.348669988430919
Validation loss: 4.967868583576625

Epoch: 5| Step: 8
Training loss: 4.250841842749541
Validation loss: 4.898232485579546

Epoch: 5| Step: 9
Training loss: 4.943299376426193
Validation loss: 4.830552610631422

Epoch: 5| Step: 10
Training loss: 5.239031641932125
Validation loss: 4.759938667500613

Epoch: 3| Step: 0
Training loss: 4.323559277428662
Validation loss: 4.688044953201806

Epoch: 5| Step: 1
Training loss: 3.6312503204082933
Validation loss: 4.6163404147239655

Epoch: 5| Step: 2
Training loss: 4.137851001798631
Validation loss: 4.5524431128088

Epoch: 5| Step: 3
Training loss: 3.874602635836651
Validation loss: 4.490360931664227

Epoch: 5| Step: 4
Training loss: 4.391454869374269
Validation loss: 4.437930786261068

Epoch: 5| Step: 5
Training loss: 4.761758004606449
Validation loss: 4.387430940242369

Epoch: 5| Step: 6
Training loss: 4.769371486178126
Validation loss: 4.337025611494461

Epoch: 5| Step: 7
Training loss: 4.513241676816079
Validation loss: 4.288231795356457

Epoch: 5| Step: 8
Training loss: 4.787645039963439
Validation loss: 4.247419801001361

Epoch: 5| Step: 9
Training loss: 4.649280016544627
Validation loss: 4.204052460290242

Epoch: 5| Step: 10
Training loss: 5.497498550310763
Validation loss: 4.162478454055164

Epoch: 4| Step: 0
Training loss: 4.5389477818711175
Validation loss: 4.12356230092634

Epoch: 5| Step: 1
Training loss: 4.637422529123591
Validation loss: 4.088847040053932

Epoch: 5| Step: 2
Training loss: 3.792459817169293
Validation loss: 4.054637904759605

Epoch: 5| Step: 3
Training loss: 3.635818910980356
Validation loss: 4.025724360327393

Epoch: 5| Step: 4
Training loss: 4.156899767113482
Validation loss: 3.995662426758399

Epoch: 5| Step: 5
Training loss: 4.432159433809224
Validation loss: 3.9641143776161245

Epoch: 5| Step: 6
Training loss: 3.37817925366391
Validation loss: 3.9348128121706885

Epoch: 5| Step: 7
Training loss: 3.355669968137301
Validation loss: 3.9072797990486086

Epoch: 5| Step: 8
Training loss: 4.769794378747091
Validation loss: 3.8799985771802437

Epoch: 5| Step: 9
Training loss: 3.9162220127580163
Validation loss: 3.8504821983576023

Epoch: 5| Step: 10
Training loss: 4.54366018424277
Validation loss: 3.8266373215413023

Epoch: 5| Step: 0
Training loss: 3.2427683849923747
Validation loss: 3.799942201715615

Epoch: 5| Step: 1
Training loss: 3.7332221769633267
Validation loss: 3.774674574775503

Epoch: 5| Step: 2
Training loss: 4.114425978086176
Validation loss: 3.75354884135603

Epoch: 5| Step: 3
Training loss: 3.9859369544877863
Validation loss: 3.7345229867953886

Epoch: 5| Step: 4
Training loss: 4.084312451328038
Validation loss: 3.7177560259824034

Epoch: 5| Step: 5
Training loss: 3.556983558340094
Validation loss: 3.7019252547907318

Epoch: 5| Step: 6
Training loss: 3.5589076886683086
Validation loss: 3.6844239695230168

Epoch: 5| Step: 7
Training loss: 3.9848052147868507
Validation loss: 3.6702690695289655

Epoch: 5| Step: 8
Training loss: 4.2842877602407645
Validation loss: 3.6656457317749243

Epoch: 5| Step: 9
Training loss: 3.9225262712871647
Validation loss: 3.650480244804161

Epoch: 5| Step: 10
Training loss: 4.233251443706661
Validation loss: 3.639766190616067

Epoch: 6| Step: 0
Training loss: 3.4323985305535816
Validation loss: 3.627526245641897

Epoch: 5| Step: 1
Training loss: 3.2845684891027824
Validation loss: 3.616551623313503

Epoch: 5| Step: 2
Training loss: 4.330728236886676
Validation loss: 3.6047980866069507

Epoch: 5| Step: 3
Training loss: 4.021603894229276
Validation loss: 3.5911437404798723

Epoch: 5| Step: 4
Training loss: 3.37070700680258
Validation loss: 3.57596096929206

Epoch: 5| Step: 5
Training loss: 4.338240608067553
Validation loss: 3.5520167845083988

Epoch: 5| Step: 6
Training loss: 3.6469636018870233
Validation loss: 3.5333293281698097

Epoch: 5| Step: 7
Training loss: 3.9299886599466887
Validation loss: 3.5144942282905642

Epoch: 5| Step: 8
Training loss: 3.809212314552239
Validation loss: 3.502306472650099

Epoch: 5| Step: 9
Training loss: 3.5465577105467045
Validation loss: 3.4839907198419344

Epoch: 5| Step: 10
Training loss: 3.3910773894001416
Validation loss: 3.473606714231816

Epoch: 7| Step: 0
Training loss: 3.33518040662369
Validation loss: 3.4692370468111706

Epoch: 5| Step: 1
Training loss: 3.7070549179302406
Validation loss: 3.451272354925641

Epoch: 5| Step: 2
Training loss: 3.2375581714014046
Validation loss: 3.4396097266450143

Epoch: 5| Step: 3
Training loss: 4.854773007398919
Validation loss: 3.4204958046099794

Epoch: 5| Step: 4
Training loss: 3.7936493157941715
Validation loss: 3.4040906718234445

Epoch: 5| Step: 5
Training loss: 3.3496285930115604
Validation loss: 3.390104401012007

Epoch: 5| Step: 6
Training loss: 3.9111574398413156
Validation loss: 3.3809180123431086

Epoch: 5| Step: 7
Training loss: 3.1739024931190998
Validation loss: 3.3709143942369866

Epoch: 5| Step: 8
Training loss: 3.364369923975597
Validation loss: 3.3616993972154807

Epoch: 5| Step: 9
Training loss: 3.5039680330917276
Validation loss: 3.3551848928483636

Epoch: 5| Step: 10
Training loss: 3.31749018376615
Validation loss: 3.353244053598432

Epoch: 8| Step: 0
Training loss: 3.9595305522901376
Validation loss: 3.3442020288976275

Epoch: 5| Step: 1
Training loss: 3.458947981175
Validation loss: 3.331083861293027

Epoch: 5| Step: 2
Training loss: 3.627629214508636
Validation loss: 3.325780057543272

Epoch: 5| Step: 3
Training loss: 3.2964853354772568
Validation loss: 3.322526804289357

Epoch: 5| Step: 4
Training loss: 3.4729367669585463
Validation loss: 3.308266096071673

Epoch: 5| Step: 5
Training loss: 3.7466340535555656
Validation loss: 3.2977482441567743

Epoch: 5| Step: 6
Training loss: 3.1518489255475264
Validation loss: 3.295154773791104

Epoch: 5| Step: 7
Training loss: 3.775347050762185
Validation loss: 3.291473726220624

Epoch: 5| Step: 8
Training loss: 3.074201688028415
Validation loss: 3.2817989298434145

Epoch: 5| Step: 9
Training loss: 4.160487717868797
Validation loss: 3.2724382925077378

Epoch: 5| Step: 10
Training loss: 3.037029145091829
Validation loss: 3.264112117874434

Epoch: 9| Step: 0
Training loss: 3.2630157998369165
Validation loss: 3.260475126453519

Epoch: 5| Step: 1
Training loss: 3.828502901069944
Validation loss: 3.252293669505621

Epoch: 5| Step: 2
Training loss: 2.8723892299452842
Validation loss: 3.2444128977073996

Epoch: 5| Step: 3
Training loss: 3.2524440085585784
Validation loss: 3.2470002541026304

Epoch: 5| Step: 4
Training loss: 3.853830656233965
Validation loss: 3.2431477612802557

Epoch: 5| Step: 5
Training loss: 3.5360479926740447
Validation loss: 3.227878216387629

Epoch: 5| Step: 6
Training loss: 3.8205078324695823
Validation loss: 3.2247765418746934

Epoch: 5| Step: 7
Training loss: 3.3377457660382186
Validation loss: 3.2206727993111786

Epoch: 5| Step: 8
Training loss: 3.201559735693048
Validation loss: 3.2169493303705408

Epoch: 5| Step: 9
Training loss: 3.8696886393753243
Validation loss: 3.2154716221766813

Epoch: 5| Step: 10
Training loss: 3.346885993148744
Validation loss: 3.2106549977778784

Epoch: 10| Step: 0
Training loss: 3.3575228531117225
Validation loss: 3.21526992240414

Epoch: 5| Step: 1
Training loss: 3.9250511895018594
Validation loss: 3.2136720496708313

Epoch: 5| Step: 2
Training loss: 2.94110843523659
Validation loss: 3.2158927720605743

Epoch: 5| Step: 3
Training loss: 3.8460470639591082
Validation loss: 3.2183221998062663

Epoch: 5| Step: 4
Training loss: 3.4830407295047054
Validation loss: 3.215437458421649

Epoch: 5| Step: 5
Training loss: 3.7886067853772505
Validation loss: 3.2084330119925495

Epoch: 5| Step: 6
Training loss: 3.572922034672003
Validation loss: 3.1960490667741683

Epoch: 5| Step: 7
Training loss: 3.459734498790915
Validation loss: 3.19445173973997

Epoch: 5| Step: 8
Training loss: 3.289311995297008
Validation loss: 3.193962982963797

Epoch: 5| Step: 9
Training loss: 3.221193737742164
Validation loss: 3.1881145598245624

Epoch: 5| Step: 10
Training loss: 3.0215662801499747
Validation loss: 3.1866300176997386

Epoch: 11| Step: 0
Training loss: 3.560617585351076
Validation loss: 3.1788778163806937

Epoch: 5| Step: 1
Training loss: 2.8404172714372278
Validation loss: 3.1765069727563473

Epoch: 5| Step: 2
Training loss: 3.4671547460534633
Validation loss: 3.17227353091264

Epoch: 5| Step: 3
Training loss: 3.622037532079018
Validation loss: 3.168540381361951

Epoch: 5| Step: 4
Training loss: 3.1450919652449962
Validation loss: 3.1666796338043084

Epoch: 5| Step: 5
Training loss: 2.8749134216540915
Validation loss: 3.1618155330533395

Epoch: 5| Step: 6
Training loss: 3.813913802358581
Validation loss: 3.1588070271814814

Epoch: 5| Step: 7
Training loss: 3.6392319269241877
Validation loss: 3.153922434733771

Epoch: 5| Step: 8
Training loss: 3.437629281127168
Validation loss: 3.152588237347202

Epoch: 5| Step: 9
Training loss: 3.4671892658657204
Validation loss: 3.1479185053153014

Epoch: 5| Step: 10
Training loss: 3.7407725930475255
Validation loss: 3.14654231718787

Epoch: 12| Step: 0
Training loss: 2.7812911469919754
Validation loss: 3.1429530970297037

Epoch: 5| Step: 1
Training loss: 3.3608850678096505
Validation loss: 3.1409660231345167

Epoch: 5| Step: 2
Training loss: 3.6299814657783767
Validation loss: 3.141007296210051

Epoch: 5| Step: 3
Training loss: 3.3027997768971664
Validation loss: 3.1384027045081737

Epoch: 5| Step: 4
Training loss: 3.962335283484056
Validation loss: 3.1384860175668927

Epoch: 5| Step: 5
Training loss: 3.032785400395332
Validation loss: 3.1339930254450934

Epoch: 5| Step: 6
Training loss: 3.3275339380793434
Validation loss: 3.1331280770902463

Epoch: 5| Step: 7
Training loss: 3.5407852123136148
Validation loss: 3.130722008391753

Epoch: 5| Step: 8
Training loss: 3.661563631210419
Validation loss: 3.1293983188789443

Epoch: 5| Step: 9
Training loss: 2.994154321050704
Validation loss: 3.127903139013246

Epoch: 5| Step: 10
Training loss: 3.7356934075604395
Validation loss: 3.125993794576915

Epoch: 13| Step: 0
Training loss: 4.077014289522147
Validation loss: 3.124296753212053

Epoch: 5| Step: 1
Training loss: 3.891502802228648
Validation loss: 3.12148456507911

Epoch: 5| Step: 2
Training loss: 3.4042412670712916
Validation loss: 3.118879272575271

Epoch: 5| Step: 3
Training loss: 3.6678577280355835
Validation loss: 3.1182536309924007

Epoch: 5| Step: 4
Training loss: 3.158975765008515
Validation loss: 3.1173940935474196

Epoch: 5| Step: 5
Training loss: 3.4195670091355517
Validation loss: 3.114611277199571

Epoch: 5| Step: 6
Training loss: 3.49404004689474
Validation loss: 3.1118438824478285

Epoch: 5| Step: 7
Training loss: 3.126485090236353
Validation loss: 3.109997189963708

Epoch: 5| Step: 8
Training loss: 2.2558500743855894
Validation loss: 3.108354022111084

Epoch: 5| Step: 9
Training loss: 2.9070148076958753
Validation loss: 3.1092277859315205

Epoch: 5| Step: 10
Training loss: 3.570773639573195
Validation loss: 3.11168586885546

Epoch: 14| Step: 0
Training loss: 3.1763028212729902
Validation loss: 3.1273258577860448

Epoch: 5| Step: 1
Training loss: 2.906851593428578
Validation loss: 3.1463708617305475

Epoch: 5| Step: 2
Training loss: 3.082976415097885
Validation loss: 3.144374596941978

Epoch: 5| Step: 3
Training loss: 2.911093992161911
Validation loss: 3.143068100761441

Epoch: 5| Step: 4
Training loss: 3.796737605619178
Validation loss: 3.138495513316479

Epoch: 5| Step: 5
Training loss: 3.866884038559157
Validation loss: 3.134138245201876

Epoch: 5| Step: 6
Training loss: 3.8077600750231664
Validation loss: 3.1313395261190866

Epoch: 5| Step: 7
Training loss: 3.4789402749115093
Validation loss: 3.1089811751233767

Epoch: 5| Step: 8
Training loss: 3.4841260607279203
Validation loss: 3.091153562309269

Epoch: 5| Step: 9
Training loss: 3.5220508765077465
Validation loss: 3.131828098822005

Epoch: 5| Step: 10
Training loss: 3.136213706130764
Validation loss: 3.092774156996548

Epoch: 15| Step: 0
Training loss: 3.0305675249555866
Validation loss: 3.0921112904600543

Epoch: 5| Step: 1
Training loss: 3.3066409134118304
Validation loss: 3.1227937010215068

Epoch: 5| Step: 2
Training loss: 3.9584310151478665
Validation loss: 3.1203347952474743

Epoch: 5| Step: 3
Training loss: 3.250605306743575
Validation loss: 3.1121832107719616

Epoch: 5| Step: 4
Training loss: 3.14370379252821
Validation loss: 3.126971878252035

Epoch: 5| Step: 5
Training loss: 3.076614241506406
Validation loss: 3.1399399556102185

Epoch: 5| Step: 6
Training loss: 3.6988526498487295
Validation loss: 3.1421164433001616

Epoch: 5| Step: 7
Training loss: 3.494204081880811
Validation loss: 3.136796284670265

Epoch: 5| Step: 8
Training loss: 3.2818569530251662
Validation loss: 3.1290275199244486

Epoch: 5| Step: 9
Training loss: 3.4776896160544277
Validation loss: 3.1168080101801663

Epoch: 5| Step: 10
Training loss: 3.5495139904184447
Validation loss: 3.105338190550838

Epoch: 16| Step: 0
Training loss: 2.7498344024736894
Validation loss: 3.092994722874891

Epoch: 5| Step: 1
Training loss: 4.29489256470217
Validation loss: 3.088024474119097

Epoch: 5| Step: 2
Training loss: 2.9484830027001876
Validation loss: 3.0837216699481567

Epoch: 5| Step: 3
Training loss: 3.743942709215473
Validation loss: 3.0767998710935998

Epoch: 5| Step: 4
Training loss: 3.159596548038137
Validation loss: 3.0728989595237093

Epoch: 5| Step: 5
Training loss: 3.8207216258274337
Validation loss: 3.0673890523867984

Epoch: 5| Step: 6
Training loss: 2.841789492043674
Validation loss: 3.0651804260680806

Epoch: 5| Step: 7
Training loss: 3.2496060352695753
Validation loss: 3.0653406813876005

Epoch: 5| Step: 8
Training loss: 3.446796815457555
Validation loss: 3.066207988227084

Epoch: 5| Step: 9
Training loss: 3.1238456119774396
Validation loss: 3.067020745276391

Epoch: 5| Step: 10
Training loss: 3.218793850201913
Validation loss: 3.0605914003400563

Epoch: 17| Step: 0
Training loss: 3.419481389617143
Validation loss: 3.0556046655038904

Epoch: 5| Step: 1
Training loss: 3.7689689256333936
Validation loss: 3.0545769220278456

Epoch: 5| Step: 2
Training loss: 3.1043734556270697
Validation loss: 3.053183455644493

Epoch: 5| Step: 3
Training loss: 3.3906695806851044
Validation loss: 3.050935557910144

Epoch: 5| Step: 4
Training loss: 3.872574816400345
Validation loss: 3.045386527962632

Epoch: 5| Step: 5
Training loss: 3.2416909446559004
Validation loss: 3.0470587604263546

Epoch: 5| Step: 6
Training loss: 2.938819264350577
Validation loss: 3.0457939794404223

Epoch: 5| Step: 7
Training loss: 3.311672179229198
Validation loss: 3.044763944905481

Epoch: 5| Step: 8
Training loss: 3.3162449234723383
Validation loss: 3.044657743689704

Epoch: 5| Step: 9
Training loss: 2.956623245774824
Validation loss: 3.0345268750443943

Epoch: 5| Step: 10
Training loss: 3.2163942475334717
Validation loss: 3.03239554759211

Epoch: 18| Step: 0
Training loss: 3.8491299822795537
Validation loss: 3.0319562689037465

Epoch: 5| Step: 1
Training loss: 2.846863101134574
Validation loss: 3.0313282178338308

Epoch: 5| Step: 2
Training loss: 3.2182049336066125
Validation loss: 3.02640008536084

Epoch: 5| Step: 3
Training loss: 3.4400226006763477
Validation loss: 3.0269236008120037

Epoch: 5| Step: 4
Training loss: 3.4146977931248297
Validation loss: 3.023014606394206

Epoch: 5| Step: 5
Training loss: 2.875631511824294
Validation loss: 3.0236589666978637

Epoch: 5| Step: 6
Training loss: 3.138369837092977
Validation loss: 3.021904410866961

Epoch: 5| Step: 7
Training loss: 2.9551028132746797
Validation loss: 3.022150520676151

Epoch: 5| Step: 8
Training loss: 3.2083316819488106
Validation loss: 3.018890109452171

Epoch: 5| Step: 9
Training loss: 3.4911625870777803
Validation loss: 3.021494268150903

Epoch: 5| Step: 10
Training loss: 3.924650145081916
Validation loss: 3.017882626577026

Epoch: 19| Step: 0
Training loss: 2.1653359312424008
Validation loss: 3.016993525864636

Epoch: 5| Step: 1
Training loss: 3.831537088462816
Validation loss: 3.0197919760000045

Epoch: 5| Step: 2
Training loss: 3.270383735095971
Validation loss: 3.014953182247891

Epoch: 5| Step: 3
Training loss: 2.997024172828289
Validation loss: 3.016381310596824

Epoch: 5| Step: 4
Training loss: 3.5962406981198405
Validation loss: 3.0129829601685194

Epoch: 5| Step: 5
Training loss: 3.925070870118044
Validation loss: 3.016780236902362

Epoch: 5| Step: 6
Training loss: 3.3611805876249723
Validation loss: 3.0115241016321908

Epoch: 5| Step: 7
Training loss: 3.112470150233764
Validation loss: 3.01119788149945

Epoch: 5| Step: 8
Training loss: 3.143866844356864
Validation loss: 3.0107835342508835

Epoch: 5| Step: 9
Training loss: 3.112707298147063
Validation loss: 3.0088436562971808

Epoch: 5| Step: 10
Training loss: 3.465459826895792
Validation loss: 3.009211189044544

Epoch: 20| Step: 0
Training loss: 2.925162195126597
Validation loss: 3.0059495163571004

Epoch: 5| Step: 1
Training loss: 3.166014118888445
Validation loss: 3.0027496058193917

Epoch: 5| Step: 2
Training loss: 2.9905816691895866
Validation loss: 3.0006965346461585

Epoch: 5| Step: 3
Training loss: 3.1876555760133596
Validation loss: 3.001837929665954

Epoch: 5| Step: 4
Training loss: 2.742712856298171
Validation loss: 3.004435718330638

Epoch: 5| Step: 5
Training loss: 3.4407090900064805
Validation loss: 3.007382799193611

Epoch: 5| Step: 6
Training loss: 3.89906724877392
Validation loss: 3.0100579635494937

Epoch: 5| Step: 7
Training loss: 2.45459096076474
Validation loss: 3.0018141552609747

Epoch: 5| Step: 8
Training loss: 3.3244284576002157
Validation loss: 2.9959350395016044

Epoch: 5| Step: 9
Training loss: 4.094539653534355
Validation loss: 2.993633040931433

Epoch: 5| Step: 10
Training loss: 3.669141555504979
Validation loss: 2.9983014165606674

Epoch: 21| Step: 0
Training loss: 3.4679326649589037
Validation loss: 2.9918333178272056

Epoch: 5| Step: 1
Training loss: 3.488857243091339
Validation loss: 2.9915677539429675

Epoch: 5| Step: 2
Training loss: 3.1958965336710548
Validation loss: 2.991541872059027

Epoch: 5| Step: 3
Training loss: 3.3265921774597977
Validation loss: 3.000076985140499

Epoch: 5| Step: 4
Training loss: 3.838208553744647
Validation loss: 2.9948907246019183

Epoch: 5| Step: 5
Training loss: 3.2253346173474564
Validation loss: 2.9942752110683446

Epoch: 5| Step: 6
Training loss: 3.056662620977167
Validation loss: 2.9886749100508907

Epoch: 5| Step: 7
Training loss: 3.441239698278913
Validation loss: 2.986159390091594

Epoch: 5| Step: 8
Training loss: 2.677224587203309
Validation loss: 2.9851663677692297

Epoch: 5| Step: 9
Training loss: 2.815360924194958
Validation loss: 2.983600112330885

Epoch: 5| Step: 10
Training loss: 3.3747797293661588
Validation loss: 2.9880213367688575

Epoch: 22| Step: 0
Training loss: 2.7741966390628297
Validation loss: 2.98616791334323

Epoch: 5| Step: 1
Training loss: 3.3399960845650205
Validation loss: 2.983274296694139

Epoch: 5| Step: 2
Training loss: 2.9511358434369734
Validation loss: 2.979661976223214

Epoch: 5| Step: 3
Training loss: 3.2277054136404164
Validation loss: 2.9790262168674095

Epoch: 5| Step: 4
Training loss: 3.894563328525736
Validation loss: 2.978700304578039

Epoch: 5| Step: 5
Training loss: 3.5227290961744675
Validation loss: 2.9773984228409893

Epoch: 5| Step: 6
Training loss: 2.635085847820621
Validation loss: 2.9757724969229926

Epoch: 5| Step: 7
Training loss: 3.590442628271163
Validation loss: 2.976408394858925

Epoch: 5| Step: 8
Training loss: 3.714010215330275
Validation loss: 2.9739777042286835

Epoch: 5| Step: 9
Training loss: 3.1446025200580237
Validation loss: 2.9754826710584577

Epoch: 5| Step: 10
Training loss: 2.7505028871744046
Validation loss: 2.977712370204608

Epoch: 23| Step: 0
Training loss: 2.6500864662603005
Validation loss: 2.9873828407930616

Epoch: 5| Step: 1
Training loss: 3.3772150470919375
Validation loss: 3.011453111970881

Epoch: 5| Step: 2
Training loss: 3.3869095234889715
Validation loss: 3.043147933503177

Epoch: 5| Step: 3
Training loss: 3.109115819816025
Validation loss: 2.984788151027851

Epoch: 5| Step: 4
Training loss: 3.020010491915029
Validation loss: 2.9732024451947416

Epoch: 5| Step: 5
Training loss: 3.1668492983973464
Validation loss: 2.97058482439293

Epoch: 5| Step: 6
Training loss: 3.7826093011709756
Validation loss: 2.9739528450720294

Epoch: 5| Step: 7
Training loss: 3.263212782360946
Validation loss: 2.9712628216098644

Epoch: 5| Step: 8
Training loss: 3.6236472400992223
Validation loss: 2.9699527957134757

Epoch: 5| Step: 9
Training loss: 3.122090014746638
Validation loss: 2.9677427879221256

Epoch: 5| Step: 10
Training loss: 3.242094548742877
Validation loss: 2.9686175642282184

Epoch: 24| Step: 0
Training loss: 3.3640266327954698
Validation loss: 2.967883749518838

Epoch: 5| Step: 1
Training loss: 2.53792342237735
Validation loss: 2.9637669978047905

Epoch: 5| Step: 2
Training loss: 3.6721837989334647
Validation loss: 2.961858974139633

Epoch: 5| Step: 3
Training loss: 3.522011614284829
Validation loss: 2.962165103784229

Epoch: 5| Step: 4
Training loss: 3.3400246375996914
Validation loss: 2.9639487006569696

Epoch: 5| Step: 5
Training loss: 3.243790342928993
Validation loss: 2.9594747573365368

Epoch: 5| Step: 6
Training loss: 3.6901353373946293
Validation loss: 2.9578918348277163

Epoch: 5| Step: 7
Training loss: 2.580850536111321
Validation loss: 2.9553170871756596

Epoch: 5| Step: 8
Training loss: 3.3672724666629064
Validation loss: 2.9518622117078412

Epoch: 5| Step: 9
Training loss: 3.0588709290314346
Validation loss: 2.953439737747251

Epoch: 5| Step: 10
Training loss: 3.109139591679556
Validation loss: 2.9569731125340133

Epoch: 25| Step: 0
Training loss: 2.8358813403745526
Validation loss: 2.9568967166156845

Epoch: 5| Step: 1
Training loss: 3.428098549475641
Validation loss: 2.956342361388996

Epoch: 5| Step: 2
Training loss: 3.81218680674383
Validation loss: 2.9523466444911852

Epoch: 5| Step: 3
Training loss: 2.9688903775404945
Validation loss: 2.9473424593085804

Epoch: 5| Step: 4
Training loss: 2.765883439052574
Validation loss: 2.9453120343285817

Epoch: 5| Step: 5
Training loss: 3.622414159922675
Validation loss: 2.9472050541492045

Epoch: 5| Step: 6
Training loss: 3.450142517463316
Validation loss: 2.9465028793311343

Epoch: 5| Step: 7
Training loss: 3.260954661157377
Validation loss: 2.9449493122479558

Epoch: 5| Step: 8
Training loss: 2.925675964498318
Validation loss: 2.945351116525349

Epoch: 5| Step: 9
Training loss: 2.8442167800287086
Validation loss: 2.946900239504333

Epoch: 5| Step: 10
Training loss: 3.5192446914852855
Validation loss: 2.9428027728179

Epoch: 26| Step: 0
Training loss: 3.1603628121709733
Validation loss: 2.9471534747841637

Epoch: 5| Step: 1
Training loss: 2.9784254917202486
Validation loss: 2.949692700778922

Epoch: 5| Step: 2
Training loss: 3.1616551412862655
Validation loss: 2.953657447885165

Epoch: 5| Step: 3
Training loss: 3.7064788696230164
Validation loss: 2.9509396114608237

Epoch: 5| Step: 4
Training loss: 3.1359409303746184
Validation loss: 2.946757082255194

Epoch: 5| Step: 5
Training loss: 3.135793889230423
Validation loss: 2.9461615411382827

Epoch: 5| Step: 6
Training loss: 3.7013638328354674
Validation loss: 2.944980853671548

Epoch: 5| Step: 7
Training loss: 3.2203704310522725
Validation loss: 2.93758154489495

Epoch: 5| Step: 8
Training loss: 3.660513454338018
Validation loss: 2.9387768457878836

Epoch: 5| Step: 9
Training loss: 2.8148791105287043
Validation loss: 2.9361764845072593

Epoch: 5| Step: 10
Training loss: 2.627783525669872
Validation loss: 2.936875291950065

Epoch: 27| Step: 0
Training loss: 2.9718417481689143
Validation loss: 2.9365831513896814

Epoch: 5| Step: 1
Training loss: 3.118122926100796
Validation loss: 2.9375423427471996

Epoch: 5| Step: 2
Training loss: 3.540139950071023
Validation loss: 2.9345787427279255

Epoch: 5| Step: 3
Training loss: 2.741755959661634
Validation loss: 2.9359608049447963

Epoch: 5| Step: 4
Training loss: 3.7633632341339642
Validation loss: 2.9357876976508996

Epoch: 5| Step: 5
Training loss: 3.351094958010372
Validation loss: 2.935778987964689

Epoch: 5| Step: 6
Training loss: 3.4007010802957107
Validation loss: 2.9342258422842247

Epoch: 5| Step: 7
Training loss: 2.9790626098671207
Validation loss: 2.9320451423030405

Epoch: 5| Step: 8
Training loss: 3.522790955222404
Validation loss: 2.9309765493043614

Epoch: 5| Step: 9
Training loss: 2.6362419997229987
Validation loss: 2.930956557752327

Epoch: 5| Step: 10
Training loss: 3.2524104349528424
Validation loss: 2.9387277809506576

Epoch: 28| Step: 0
Training loss: 3.386943734867643
Validation loss: 2.93245020003088

Epoch: 5| Step: 1
Training loss: 2.9974319274655827
Validation loss: 2.927126393712878

Epoch: 5| Step: 2
Training loss: 3.0755558038844972
Validation loss: 2.9239429602548066

Epoch: 5| Step: 3
Training loss: 2.8443508980521375
Validation loss: 2.92284996178736

Epoch: 5| Step: 4
Training loss: 3.862711217345713
Validation loss: 2.919745925495219

Epoch: 5| Step: 5
Training loss: 3.0096008532931036
Validation loss: 2.920393129257939

Epoch: 5| Step: 6
Training loss: 2.964649782130847
Validation loss: 2.917769945615015

Epoch: 5| Step: 7
Training loss: 3.509695792206642
Validation loss: 2.9171782072841457

Epoch: 5| Step: 8
Training loss: 3.2972692461810764
Validation loss: 2.9182045004196038

Epoch: 5| Step: 9
Training loss: 3.249816009008391
Validation loss: 2.9169146864485076

Epoch: 5| Step: 10
Training loss: 2.946325800701096
Validation loss: 2.912271550758109

Epoch: 29| Step: 0
Training loss: 3.276389309258403
Validation loss: 2.912711833637236

Epoch: 5| Step: 1
Training loss: 3.3036791839111013
Validation loss: 2.9124317906396517

Epoch: 5| Step: 2
Training loss: 3.9608142239199062
Validation loss: 2.912250067225619

Epoch: 5| Step: 3
Training loss: 3.1338870519698685
Validation loss: 2.910283019949642

Epoch: 5| Step: 4
Training loss: 2.9666326099398286
Validation loss: 2.9076774435717954

Epoch: 5| Step: 5
Training loss: 3.583168706143289
Validation loss: 2.9075330463943447

Epoch: 5| Step: 6
Training loss: 3.127379007781594
Validation loss: 2.9093507105386376

Epoch: 5| Step: 7
Training loss: 3.056914237454392
Validation loss: 2.9119890690408714

Epoch: 5| Step: 8
Training loss: 3.299203059750608
Validation loss: 2.9054483116645664

Epoch: 5| Step: 9
Training loss: 2.912672923443338
Validation loss: 2.902847892167102

Epoch: 5| Step: 10
Training loss: 2.2134751493146023
Validation loss: 2.904424811607659

Epoch: 30| Step: 0
Training loss: 3.186502337933899
Validation loss: 2.9097304377386553

Epoch: 5| Step: 1
Training loss: 2.615425723926548
Validation loss: 2.9117683719440377

Epoch: 5| Step: 2
Training loss: 3.6547431122853045
Validation loss: 2.9088360090020706

Epoch: 5| Step: 3
Training loss: 3.51379862498942
Validation loss: 2.9071191429084604

Epoch: 5| Step: 4
Training loss: 3.369842686136711
Validation loss: 2.903338870515388

Epoch: 5| Step: 5
Training loss: 3.539014129644958
Validation loss: 2.900492261415976

Epoch: 5| Step: 6
Training loss: 3.2736262811017864
Validation loss: 2.8978123109032508

Epoch: 5| Step: 7
Training loss: 2.9210605404178347
Validation loss: 2.8987627460824403

Epoch: 5| Step: 8
Training loss: 2.6259301672000865
Validation loss: 2.8960219296964578

Epoch: 5| Step: 9
Training loss: 3.4008766278370866
Validation loss: 2.899022211348371

Epoch: 5| Step: 10
Training loss: 2.828447355161126
Validation loss: 2.896946390734288

Epoch: 31| Step: 0
Training loss: 3.226284652458832
Validation loss: 2.8944197791811264

Epoch: 5| Step: 1
Training loss: 3.2233649197135046
Validation loss: 2.8963468398375567

Epoch: 5| Step: 2
Training loss: 3.0432012858439235
Validation loss: 2.898234952542792

Epoch: 5| Step: 3
Training loss: 3.031490355725294
Validation loss: 2.895585820994909

Epoch: 5| Step: 4
Training loss: 3.1770962740942053
Validation loss: 2.898078591307374

Epoch: 5| Step: 5
Training loss: 3.0622100692837604
Validation loss: 2.896165956304077

Epoch: 5| Step: 6
Training loss: 2.7655418081756302
Validation loss: 2.897645530390775

Epoch: 5| Step: 7
Training loss: 2.9671578404298637
Validation loss: 2.891723503903439

Epoch: 5| Step: 8
Training loss: 2.942538708324462
Validation loss: 2.891390883540699

Epoch: 5| Step: 9
Training loss: 3.7509314333965094
Validation loss: 2.8908110554556634

Epoch: 5| Step: 10
Training loss: 3.8153579505989645
Validation loss: 2.8890250734017036

Epoch: 32| Step: 0
Training loss: 3.667719920922938
Validation loss: 2.8884958236319838

Epoch: 5| Step: 1
Training loss: 3.395307410456235
Validation loss: 2.887302087582722

Epoch: 5| Step: 2
Training loss: 3.0242130359308907
Validation loss: 2.887165355463615

Epoch: 5| Step: 3
Training loss: 2.9444355354734113
Validation loss: 2.8861984065258657

Epoch: 5| Step: 4
Training loss: 3.0766712764265987
Validation loss: 2.8866792176830223

Epoch: 5| Step: 5
Training loss: 2.5457587106842827
Validation loss: 2.882215568189302

Epoch: 5| Step: 6
Training loss: 2.685518998434863
Validation loss: 2.8834942391949414

Epoch: 5| Step: 7
Training loss: 3.8942667757490788
Validation loss: 2.8804182302385057

Epoch: 5| Step: 8
Training loss: 3.5445222151172184
Validation loss: 2.881693492594608

Epoch: 5| Step: 9
Training loss: 3.5214813960227276
Validation loss: 2.882307224706137

Epoch: 5| Step: 10
Training loss: 2.139019886425539
Validation loss: 2.878391411902415

Epoch: 33| Step: 0
Training loss: 3.0061607680688938
Validation loss: 2.8821239016416547

Epoch: 5| Step: 1
Training loss: 3.715810303041709
Validation loss: 2.88818077774

Epoch: 5| Step: 2
Training loss: 2.890448487537262
Validation loss: 2.904356180770795

Epoch: 5| Step: 3
Training loss: 3.1458115903258754
Validation loss: 2.949109694853637

Epoch: 5| Step: 4
Training loss: 3.0426542342375242
Validation loss: 2.926245787247108

Epoch: 5| Step: 5
Training loss: 2.7533832892195584
Validation loss: 2.896592049141447

Epoch: 5| Step: 6
Training loss: 3.1591875362151343
Validation loss: 2.8806752033433467

Epoch: 5| Step: 7
Training loss: 3.4680939474965364
Validation loss: 2.875737844148954

Epoch: 5| Step: 8
Training loss: 3.1599442419130614
Validation loss: 2.879044107201512

Epoch: 5| Step: 9
Training loss: 3.2526055675266368
Validation loss: 2.8906096409525706

Epoch: 5| Step: 10
Training loss: 3.411436838951052
Validation loss: 2.897270121229396

Epoch: 34| Step: 0
Training loss: 3.668830550965026
Validation loss: 2.904002810400831

Epoch: 5| Step: 1
Training loss: 3.194144112294782
Validation loss: 2.899163260130469

Epoch: 5| Step: 2
Training loss: 3.4781549471296813
Validation loss: 2.8817963221881144

Epoch: 5| Step: 3
Training loss: 2.892594939497888
Validation loss: 2.8747685612585876

Epoch: 5| Step: 4
Training loss: 2.683112977341063
Validation loss: 2.8696815391128845

Epoch: 5| Step: 5
Training loss: 3.3572733137761595
Validation loss: 2.8718729619947965

Epoch: 5| Step: 6
Training loss: 3.8296485827307856
Validation loss: 2.8785213139033865

Epoch: 5| Step: 7
Training loss: 3.065862561275196
Validation loss: 2.8939585329555166

Epoch: 5| Step: 8
Training loss: 2.8477151914339043
Validation loss: 2.887004951060179

Epoch: 5| Step: 9
Training loss: 2.8973439253736193
Validation loss: 2.8947407758165657

Epoch: 5| Step: 10
Training loss: 2.9066517870052615
Validation loss: 2.8873763143287228

Epoch: 35| Step: 0
Training loss: 2.8392852275947367
Validation loss: 2.8806937977806855

Epoch: 5| Step: 1
Training loss: 3.4739898420941926
Validation loss: 2.868974039940194

Epoch: 5| Step: 2
Training loss: 3.4561149805333433
Validation loss: 2.8612773754828913

Epoch: 5| Step: 3
Training loss: 2.493743219581507
Validation loss: 2.8598178247398356

Epoch: 5| Step: 4
Training loss: 3.169603107287575
Validation loss: 2.861636606826682

Epoch: 5| Step: 5
Training loss: 3.4176270755563256
Validation loss: 2.859450456446366

Epoch: 5| Step: 6
Training loss: 3.4597429060924925
Validation loss: 2.860887032312813

Epoch: 5| Step: 7
Training loss: 2.942521531018975
Validation loss: 2.86525510605752

Epoch: 5| Step: 8
Training loss: 3.412576382519272
Validation loss: 2.8894969119170066

Epoch: 5| Step: 9
Training loss: 2.987252969783603
Validation loss: 2.9236886002165225

Epoch: 5| Step: 10
Training loss: 3.0664440371377966
Validation loss: 2.882220965480532

Epoch: 36| Step: 0
Training loss: 3.643903966565764
Validation loss: 2.8655688129810923

Epoch: 5| Step: 1
Training loss: 2.599907701027774
Validation loss: 2.861393194380249

Epoch: 5| Step: 2
Training loss: 3.4489975509480018
Validation loss: 2.8598891818641192

Epoch: 5| Step: 3
Training loss: 2.904499470174028
Validation loss: 2.8676170315068488

Epoch: 5| Step: 4
Training loss: 2.9532903392868435
Validation loss: 2.881495544037261

Epoch: 5| Step: 5
Training loss: 3.454745365591603
Validation loss: 2.867993098812639

Epoch: 5| Step: 6
Training loss: 3.0425087969236686
Validation loss: 2.8668768049040234

Epoch: 5| Step: 7
Training loss: 3.412046767098766
Validation loss: 2.859704164390893

Epoch: 5| Step: 8
Training loss: 2.715319606873998
Validation loss: 2.863906079253075

Epoch: 5| Step: 9
Training loss: 3.219793058107327
Validation loss: 2.863166402863706

Epoch: 5| Step: 10
Training loss: 3.2058358979088886
Validation loss: 2.8599958762774436

Epoch: 37| Step: 0
Training loss: 3.116941819990245
Validation loss: 2.8542179533899468

Epoch: 5| Step: 1
Training loss: 3.6566074555250347
Validation loss: 2.8500308731182926

Epoch: 5| Step: 2
Training loss: 3.0536597198495032
Validation loss: 2.849022898177025

Epoch: 5| Step: 3
Training loss: 2.665895877146988
Validation loss: 2.850161398502312

Epoch: 5| Step: 4
Training loss: 2.990275516638103
Validation loss: 2.8499422354997894

Epoch: 5| Step: 5
Training loss: 2.665837476877576
Validation loss: 2.854565303285488

Epoch: 5| Step: 6
Training loss: 3.3610043854666385
Validation loss: 2.863176547575139

Epoch: 5| Step: 7
Training loss: 3.80757798954721
Validation loss: 2.868987219232986

Epoch: 5| Step: 8
Training loss: 2.526789939141244
Validation loss: 2.869063550533086

Epoch: 5| Step: 9
Training loss: 3.237713403922203
Validation loss: 2.8620606824665034

Epoch: 5| Step: 10
Training loss: 3.4517257410062996
Validation loss: 2.8523495048715453

Epoch: 38| Step: 0
Training loss: 3.4829655691937242
Validation loss: 2.849726825007433

Epoch: 5| Step: 1
Training loss: 3.261324884995845
Validation loss: 2.845879708465371

Epoch: 5| Step: 2
Training loss: 3.1490770168486564
Validation loss: 2.8439609476843772

Epoch: 5| Step: 3
Training loss: 2.908115567541085
Validation loss: 2.840419834700095

Epoch: 5| Step: 4
Training loss: 2.8735571848268853
Validation loss: 2.842483172526559

Epoch: 5| Step: 5
Training loss: 3.1407232316630056
Validation loss: 2.8412261494660482

Epoch: 5| Step: 6
Training loss: 3.202629237072466
Validation loss: 2.842439589592678

Epoch: 5| Step: 7
Training loss: 2.8415500389471116
Validation loss: 2.840803838597976

Epoch: 5| Step: 8
Training loss: 3.146491952291466
Validation loss: 2.8391589680120077

Epoch: 5| Step: 9
Training loss: 3.3121588189382036
Validation loss: 2.841724352680673

Epoch: 5| Step: 10
Training loss: 3.3190618336185453
Validation loss: 2.8390592517319835

Epoch: 39| Step: 0
Training loss: 2.9818056240578605
Validation loss: 2.838558955994616

Epoch: 5| Step: 1
Training loss: 2.9195702586682675
Validation loss: 2.843440272806754

Epoch: 5| Step: 2
Training loss: 3.194298469046151
Validation loss: 2.8519438152207153

Epoch: 5| Step: 3
Training loss: 3.1952699691068474
Validation loss: 2.859329439344115

Epoch: 5| Step: 4
Training loss: 3.7344836614274084
Validation loss: 2.841916332067669

Epoch: 5| Step: 5
Training loss: 3.3570488971675156
Validation loss: 2.8331953107982293

Epoch: 5| Step: 6
Training loss: 2.9029574868416788
Validation loss: 2.833507096996174

Epoch: 5| Step: 7
Training loss: 3.1737134895162793
Validation loss: 2.832387989674585

Epoch: 5| Step: 8
Training loss: 2.674142689449304
Validation loss: 2.8397226195647494

Epoch: 5| Step: 9
Training loss: 2.998516033629079
Validation loss: 2.8650872204436024

Epoch: 5| Step: 10
Training loss: 3.5099903304355378
Validation loss: 2.8823256547427825

Epoch: 40| Step: 0
Training loss: 2.8561122602310283
Validation loss: 2.8468451772436

Epoch: 5| Step: 1
Training loss: 2.9102907700138543
Validation loss: 2.8338222160303546

Epoch: 5| Step: 2
Training loss: 3.1536074614244485
Validation loss: 2.839332833526691

Epoch: 5| Step: 3
Training loss: 3.674393070473045
Validation loss: 2.84848263489187

Epoch: 5| Step: 4
Training loss: 3.326564369183217
Validation loss: 2.8442347349049433

Epoch: 5| Step: 5
Training loss: 3.3449696250642607
Validation loss: 2.837937173020612

Epoch: 5| Step: 6
Training loss: 2.827058707017306
Validation loss: 2.841502297839049

Epoch: 5| Step: 7
Training loss: 2.885139497924728
Validation loss: 2.835543323155221

Epoch: 5| Step: 8
Training loss: 2.3450810022740285
Validation loss: 2.8397096123017804

Epoch: 5| Step: 9
Training loss: 3.9156929320754537
Validation loss: 2.8364371961209516

Epoch: 5| Step: 10
Training loss: 3.039548075111747
Validation loss: 2.8306974075705873

Epoch: 41| Step: 0
Training loss: 2.895877334662943
Validation loss: 2.829744815925994

Epoch: 5| Step: 1
Training loss: 3.319059678624136
Validation loss: 2.8299344735737972

Epoch: 5| Step: 2
Training loss: 3.2011994319379027
Validation loss: 2.8252339012080583

Epoch: 5| Step: 3
Training loss: 3.5364711276212937
Validation loss: 2.8221012556284686

Epoch: 5| Step: 4
Training loss: 3.4270809061492087
Validation loss: 2.8205469528453957

Epoch: 5| Step: 5
Training loss: 2.83955526657582
Validation loss: 2.821364368105875

Epoch: 5| Step: 6
Training loss: 3.1949080605330082
Validation loss: 2.8208885010316394

Epoch: 5| Step: 7
Training loss: 3.3993066136782053
Validation loss: 2.8211483467141867

Epoch: 5| Step: 8
Training loss: 3.017030852729352
Validation loss: 2.8245156361772334

Epoch: 5| Step: 9
Training loss: 2.3614381775558844
Validation loss: 2.821882300821181

Epoch: 5| Step: 10
Training loss: 3.1847657088456693
Validation loss: 2.823294461548068

Epoch: 42| Step: 0
Training loss: 3.3376980497768782
Validation loss: 2.821492342589913

Epoch: 5| Step: 1
Training loss: 3.3395641901455555
Validation loss: 2.8198703826902727

Epoch: 5| Step: 2
Training loss: 3.2874502548109295
Validation loss: 2.8161456308501895

Epoch: 5| Step: 3
Training loss: 3.3843173232583905
Validation loss: 2.8202146017134804

Epoch: 5| Step: 4
Training loss: 3.239571639813644
Validation loss: 2.8236234077114424

Epoch: 5| Step: 5
Training loss: 3.1290581865127596
Validation loss: 2.829491624521275

Epoch: 5| Step: 6
Training loss: 2.8273400329076317
Validation loss: 2.8279345927651356

Epoch: 5| Step: 7
Training loss: 2.8742757797286207
Validation loss: 2.8428278269257854

Epoch: 5| Step: 8
Training loss: 3.2005789709850494
Validation loss: 2.8733962937741335

Epoch: 5| Step: 9
Training loss: 2.751942728644308
Validation loss: 2.86202922416987

Epoch: 5| Step: 10
Training loss: 2.97235402639927
Validation loss: 2.8219338024239855

Epoch: 43| Step: 0
Training loss: 2.789577660947754
Validation loss: 2.8099508776892814

Epoch: 5| Step: 1
Training loss: 3.0703474435928975
Validation loss: 2.8084929494069066

Epoch: 5| Step: 2
Training loss: 4.094110138172437
Validation loss: 2.807232186377568

Epoch: 5| Step: 3
Training loss: 2.7351142973789164
Validation loss: 2.8081741554697572

Epoch: 5| Step: 4
Training loss: 3.268611436755263
Validation loss: 2.8120365212133978

Epoch: 5| Step: 5
Training loss: 3.5188132515841084
Validation loss: 2.8128220842034666

Epoch: 5| Step: 6
Training loss: 3.1297955148219523
Validation loss: 2.812242825689869

Epoch: 5| Step: 7
Training loss: 2.205650667477368
Validation loss: 2.8113911675004903

Epoch: 5| Step: 8
Training loss: 3.5567785798770175
Validation loss: 2.806560094030002

Epoch: 5| Step: 9
Training loss: 2.802320155992771
Validation loss: 2.810204164782772

Epoch: 5| Step: 10
Training loss: 2.6832700753505465
Validation loss: 2.8087049532379846

Epoch: 44| Step: 0
Training loss: 3.2610097879861244
Validation loss: 2.8122892913825708

Epoch: 5| Step: 1
Training loss: 3.002060500478822
Validation loss: 2.821056622421078

Epoch: 5| Step: 2
Training loss: 3.793269828059211
Validation loss: 2.8156734924958955

Epoch: 5| Step: 3
Training loss: 3.486330997241464
Validation loss: 2.8060381500439497

Epoch: 5| Step: 4
Training loss: 3.137208361198648
Validation loss: 2.8063207966432957

Epoch: 5| Step: 5
Training loss: 2.906308573470986
Validation loss: 2.8083035480590546

Epoch: 5| Step: 6
Training loss: 2.89637736600628
Validation loss: 2.8029371769840243

Epoch: 5| Step: 7
Training loss: 3.0783401646423822
Validation loss: 2.805244839454202

Epoch: 5| Step: 8
Training loss: 2.5965379186337394
Validation loss: 2.8084205721123054

Epoch: 5| Step: 9
Training loss: 3.3973128639315178
Validation loss: 2.816899831181194

Epoch: 5| Step: 10
Training loss: 2.3929882460997756
Validation loss: 2.798973350912505

Epoch: 45| Step: 0
Training loss: 3.1044567066527833
Validation loss: 2.7916928306777526

Epoch: 5| Step: 1
Training loss: 3.071437018246616
Validation loss: 2.7920742946431156

Epoch: 5| Step: 2
Training loss: 2.838661419970082
Validation loss: 2.796890058011169

Epoch: 5| Step: 3
Training loss: 2.870474030959791
Validation loss: 2.804339201208949

Epoch: 5| Step: 4
Training loss: 3.515214548522402
Validation loss: 2.8411476049001028

Epoch: 5| Step: 5
Training loss: 2.7416140399585607
Validation loss: 2.8240174527133712

Epoch: 5| Step: 6
Training loss: 3.8146953828120354
Validation loss: 2.8203501647283082

Epoch: 5| Step: 7
Training loss: 3.2808311558384284
Validation loss: 2.801999748024175

Epoch: 5| Step: 8
Training loss: 2.6287858093695973
Validation loss: 2.797932706045392

Epoch: 5| Step: 9
Training loss: 3.2787783078110757
Validation loss: 2.793562164933172

Epoch: 5| Step: 10
Training loss: 3.0516832803398617
Validation loss: 2.793038582267646

Epoch: 46| Step: 0
Training loss: 3.4080212388787188
Validation loss: 2.796792271153002

Epoch: 5| Step: 1
Training loss: 2.8994091287007535
Validation loss: 2.79253893102898

Epoch: 5| Step: 2
Training loss: 2.3494164696047712
Validation loss: 2.795544265873913

Epoch: 5| Step: 3
Training loss: 3.7663620350174516
Validation loss: 2.7936116475772943

Epoch: 5| Step: 4
Training loss: 3.072339192241413
Validation loss: 2.7953316637708427

Epoch: 5| Step: 5
Training loss: 3.0156822396810212
Validation loss: 2.7924255774575957

Epoch: 5| Step: 6
Training loss: 2.953355406799952
Validation loss: 2.7906486174460188

Epoch: 5| Step: 7
Training loss: 2.9101559222944444
Validation loss: 2.796171144588402

Epoch: 5| Step: 8
Training loss: 3.247204532000416
Validation loss: 2.787994162690474

Epoch: 5| Step: 9
Training loss: 3.2482926212093224
Validation loss: 2.7862022732300518

Epoch: 5| Step: 10
Training loss: 3.0749330963051746
Validation loss: 2.786946761609909

Epoch: 47| Step: 0
Training loss: 3.1100938435713337
Validation loss: 2.787880865257832

Epoch: 5| Step: 1
Training loss: 3.7305485102729867
Validation loss: 2.796355049244199

Epoch: 5| Step: 2
Training loss: 2.788675917218933
Validation loss: 2.7990379015869924

Epoch: 5| Step: 3
Training loss: 3.4538549972075896
Validation loss: 2.805462830170441

Epoch: 5| Step: 4
Training loss: 3.0367992770247407
Validation loss: 2.791356409421535

Epoch: 5| Step: 5
Training loss: 3.127756962576114
Validation loss: 2.786778462769796

Epoch: 5| Step: 6
Training loss: 2.609110104940642
Validation loss: 2.7823974051054297

Epoch: 5| Step: 7
Training loss: 3.2797857014500997
Validation loss: 2.7833496405207487

Epoch: 5| Step: 8
Training loss: 3.1964096013972902
Validation loss: 2.7841197495086636

Epoch: 5| Step: 9
Training loss: 2.8487891519491546
Validation loss: 2.7854269918093215

Epoch: 5| Step: 10
Training loss: 2.7409262514432653
Validation loss: 2.783838341327997

Epoch: 48| Step: 0
Training loss: 3.6633201123578414
Validation loss: 2.782537684181974

Epoch: 5| Step: 1
Training loss: 3.5289615203670675
Validation loss: 2.7787583940506044

Epoch: 5| Step: 2
Training loss: 2.659319551385165
Validation loss: 2.7784609109111194

Epoch: 5| Step: 3
Training loss: 3.0462537865816732
Validation loss: 2.7775385686634144

Epoch: 5| Step: 4
Training loss: 2.8192397003080405
Validation loss: 2.778854907675026

Epoch: 5| Step: 5
Training loss: 2.4375279742860894
Validation loss: 2.779699107232121

Epoch: 5| Step: 6
Training loss: 3.2208807845936263
Validation loss: 2.778497383436308

Epoch: 5| Step: 7
Training loss: 3.4804390200662763
Validation loss: 2.7768612734718623

Epoch: 5| Step: 8
Training loss: 2.882812169186126
Validation loss: 2.778756834881625

Epoch: 5| Step: 9
Training loss: 3.6009205806738245
Validation loss: 2.7749656163681182

Epoch: 5| Step: 10
Training loss: 2.2832996096754243
Validation loss: 2.775490090482579

Epoch: 49| Step: 0
Training loss: 3.473326267618423
Validation loss: 2.7748027246194056

Epoch: 5| Step: 1
Training loss: 2.8514479522690768
Validation loss: 2.772752041236376

Epoch: 5| Step: 2
Training loss: 3.2083670544193956
Validation loss: 2.7742310986120273

Epoch: 5| Step: 3
Training loss: 2.663497551672175
Validation loss: 2.773818487389265

Epoch: 5| Step: 4
Training loss: 3.0390229602585297
Validation loss: 2.7689855047026746

Epoch: 5| Step: 5
Training loss: 3.137998782933852
Validation loss: 2.766205642525679

Epoch: 5| Step: 6
Training loss: 2.9794817848986708
Validation loss: 2.772107942279212

Epoch: 5| Step: 7
Training loss: 3.1707154207366
Validation loss: 2.7747064460868414

Epoch: 5| Step: 8
Training loss: 3.4620750744908944
Validation loss: 2.7827355046069346

Epoch: 5| Step: 9
Training loss: 2.6289408031080383
Validation loss: 2.7650979639894766

Epoch: 5| Step: 10
Training loss: 3.17887114371628
Validation loss: 2.7603809585784744

Epoch: 50| Step: 0
Training loss: 2.424356186339666
Validation loss: 2.7578429700006035

Epoch: 5| Step: 1
Training loss: 2.684432030672601
Validation loss: 2.756925645554431

Epoch: 5| Step: 2
Training loss: 3.159129726952324
Validation loss: 2.755772696579978

Epoch: 5| Step: 3
Training loss: 2.9285614698021396
Validation loss: 2.759864747929055

Epoch: 5| Step: 4
Training loss: 3.008380628162974
Validation loss: 2.7603608692092134

Epoch: 5| Step: 5
Training loss: 3.255187809180089
Validation loss: 2.7649129585098655

Epoch: 5| Step: 6
Training loss: 3.1040749931026435
Validation loss: 2.7614193318720757

Epoch: 5| Step: 7
Training loss: 3.4406526846815626
Validation loss: 2.760240886259003

Epoch: 5| Step: 8
Training loss: 3.200008606899131
Validation loss: 2.7586549275573433

Epoch: 5| Step: 9
Training loss: 2.8818056576158293
Validation loss: 2.770247322885607

Epoch: 5| Step: 10
Training loss: 3.6818203910024674
Validation loss: 2.763519340644408

Epoch: 51| Step: 0
Training loss: 2.993058916892996
Validation loss: 2.75134549454818

Epoch: 5| Step: 1
Training loss: 3.1458208365960565
Validation loss: 2.7540595946407613

Epoch: 5| Step: 2
Training loss: 2.9676056915203946
Validation loss: 2.751374987929606

Epoch: 5| Step: 3
Training loss: 3.80275920277912
Validation loss: 2.7503911389974833

Epoch: 5| Step: 4
Training loss: 2.8275624764283225
Validation loss: 2.748840674968099

Epoch: 5| Step: 5
Training loss: 2.93262450439272
Validation loss: 2.7528350252380998

Epoch: 5| Step: 6
Training loss: 2.899627359060321
Validation loss: 2.753813863016374

Epoch: 5| Step: 7
Training loss: 3.201903170644698
Validation loss: 2.7541919633058796

Epoch: 5| Step: 8
Training loss: 2.8965492369886974
Validation loss: 2.7502446946717214

Epoch: 5| Step: 9
Training loss: 3.163171411945242
Validation loss: 2.748992256109089

Epoch: 5| Step: 10
Training loss: 2.7762733253072804
Validation loss: 2.7454529736735203

Epoch: 52| Step: 0
Training loss: 2.883578563103465
Validation loss: 2.7473398526103687

Epoch: 5| Step: 1
Training loss: 3.3775503624380887
Validation loss: 2.7515072695853897

Epoch: 5| Step: 2
Training loss: 2.769227693221837
Validation loss: 2.7508462990824363

Epoch: 5| Step: 3
Training loss: 3.1075707189564374
Validation loss: 2.75207839240897

Epoch: 5| Step: 4
Training loss: 3.0328778487352768
Validation loss: 2.750197475275164

Epoch: 5| Step: 5
Training loss: 3.681241430198137
Validation loss: 2.7495831297584883

Epoch: 5| Step: 6
Training loss: 2.9096744829832475
Validation loss: 2.7461044093563913

Epoch: 5| Step: 7
Training loss: 3.1407704485715153
Validation loss: 2.7493558037783123

Epoch: 5| Step: 8
Training loss: 3.054620376200649
Validation loss: 2.750578329143777

Epoch: 5| Step: 9
Training loss: 2.9136051095149966
Validation loss: 2.75901871100269

Epoch: 5| Step: 10
Training loss: 2.7677382676574775
Validation loss: 2.7540278531033007

Epoch: 53| Step: 0
Training loss: 3.4017632007747847
Validation loss: 2.7587641395534233

Epoch: 5| Step: 1
Training loss: 3.195016712031587
Validation loss: 2.7423945467010657

Epoch: 5| Step: 2
Training loss: 2.447325051964521
Validation loss: 2.7404201568756066

Epoch: 5| Step: 3
Training loss: 3.4761446926787265
Validation loss: 2.7417582850952797

Epoch: 5| Step: 4
Training loss: 3.672518020492186
Validation loss: 2.7408313186533295

Epoch: 5| Step: 5
Training loss: 2.6190428576900913
Validation loss: 2.7420877511502657

Epoch: 5| Step: 6
Training loss: 2.746496135809649
Validation loss: 2.738288073181393

Epoch: 5| Step: 7
Training loss: 3.041894686439067
Validation loss: 2.7357808323540143

Epoch: 5| Step: 8
Training loss: 2.8789291070369774
Validation loss: 2.7405307456805037

Epoch: 5| Step: 9
Training loss: 3.2406606732927576
Validation loss: 2.7335212201997474

Epoch: 5| Step: 10
Training loss: 2.7117573930145995
Validation loss: 2.7337409953017886

Epoch: 54| Step: 0
Training loss: 3.3933125756708673
Validation loss: 2.7320217149257338

Epoch: 5| Step: 1
Training loss: 3.0580706581450205
Validation loss: 2.735343597010743

Epoch: 5| Step: 2
Training loss: 2.7913420094599006
Validation loss: 2.744374882752258

Epoch: 5| Step: 3
Training loss: 3.1375407546842617
Validation loss: 2.7618237361593723

Epoch: 5| Step: 4
Training loss: 3.1594678131265423
Validation loss: 2.768795120226055

Epoch: 5| Step: 5
Training loss: 3.0791308313606525
Validation loss: 2.7575160269269214

Epoch: 5| Step: 6
Training loss: 3.1409082996641935
Validation loss: 2.7466622939474723

Epoch: 5| Step: 7
Training loss: 3.216834229632839
Validation loss: 2.7378679533274575

Epoch: 5| Step: 8
Training loss: 2.517545736857706
Validation loss: 2.7308538939471028

Epoch: 5| Step: 9
Training loss: 2.829731353301997
Validation loss: 2.727915960958702

Epoch: 5| Step: 10
Training loss: 3.2761475627302263
Validation loss: 2.728101393908994

Epoch: 55| Step: 0
Training loss: 3.5247739300030854
Validation loss: 2.727400085779351

Epoch: 5| Step: 1
Training loss: 2.6072461244022302
Validation loss: 2.726181126303569

Epoch: 5| Step: 2
Training loss: 3.088842642123074
Validation loss: 2.724586327997415

Epoch: 5| Step: 3
Training loss: 2.8514206942480333
Validation loss: 2.726599007643669

Epoch: 5| Step: 4
Training loss: 3.4879218553923668
Validation loss: 2.726932792789253

Epoch: 5| Step: 5
Training loss: 3.4282181705412365
Validation loss: 2.7279254320442647

Epoch: 5| Step: 6
Training loss: 3.1628002521785445
Validation loss: 2.7274452832695153

Epoch: 5| Step: 7
Training loss: 2.6179018782200445
Validation loss: 2.7266327110573365

Epoch: 5| Step: 8
Training loss: 2.7351584047964415
Validation loss: 2.7240794215359023

Epoch: 5| Step: 9
Training loss: 3.1037654404058332
Validation loss: 2.7232038513046706

Epoch: 5| Step: 10
Training loss: 2.7111205992854006
Validation loss: 2.7241980036405593

Epoch: 56| Step: 0
Training loss: 2.810793210408707
Validation loss: 2.720002953668302

Epoch: 5| Step: 1
Training loss: 3.320554477625596
Validation loss: 2.7225045039041014

Epoch: 5| Step: 2
Training loss: 3.2231702360004597
Validation loss: 2.72310726227034

Epoch: 5| Step: 3
Training loss: 3.047899123006842
Validation loss: 2.7270558637773497

Epoch: 5| Step: 4
Training loss: 3.1384228629538478
Validation loss: 2.729513200973282

Epoch: 5| Step: 5
Training loss: 3.364433419083414
Validation loss: 2.736639726505768

Epoch: 5| Step: 6
Training loss: 2.845484445687914
Validation loss: 2.7294141245004466

Epoch: 5| Step: 7
Training loss: 3.1777136672458357
Validation loss: 2.722671597961969

Epoch: 5| Step: 8
Training loss: 2.535485197806025
Validation loss: 2.7215862800268047

Epoch: 5| Step: 9
Training loss: 3.036873075363325
Validation loss: 2.7276523380742934

Epoch: 5| Step: 10
Training loss: 2.8755849160325564
Validation loss: 2.738215307307393

Epoch: 57| Step: 0
Training loss: 3.608151315117031
Validation loss: 2.739152844947513

Epoch: 5| Step: 1
Training loss: 3.1869455491086445
Validation loss: 2.7214198578771325

Epoch: 5| Step: 2
Training loss: 3.0364249191059667
Validation loss: 2.7178393592630656

Epoch: 5| Step: 3
Training loss: 3.2275752586378057
Validation loss: 2.7221062179765294

Epoch: 5| Step: 4
Training loss: 2.748488791259872
Validation loss: 2.7242346784821794

Epoch: 5| Step: 5
Training loss: 3.026375223095576
Validation loss: 2.7321815780583334

Epoch: 5| Step: 6
Training loss: 2.8650103626429972
Validation loss: 2.7315747094756633

Epoch: 5| Step: 7
Training loss: 3.0614024161187907
Validation loss: 2.7326394728733505

Epoch: 5| Step: 8
Training loss: 2.8601201655079143
Validation loss: 2.727633459765177

Epoch: 5| Step: 9
Training loss: 2.8431999596831363
Validation loss: 2.7240267926384534

Epoch: 5| Step: 10
Training loss: 3.1313934536964574
Validation loss: 2.720623183407856

Epoch: 58| Step: 0
Training loss: 3.30361019097052
Validation loss: 2.716290145782799

Epoch: 5| Step: 1
Training loss: 2.1091586531847715
Validation loss: 2.7160730295648468

Epoch: 5| Step: 2
Training loss: 2.9244367008177563
Validation loss: 2.713760036209752

Epoch: 5| Step: 3
Training loss: 3.3411171788775564
Validation loss: 2.7119416129169553

Epoch: 5| Step: 4
Training loss: 3.196326805985142
Validation loss: 2.713602853554057

Epoch: 5| Step: 5
Training loss: 2.6387957495152805
Validation loss: 2.7200635632354224

Epoch: 5| Step: 6
Training loss: 2.8020825202874535
Validation loss: 2.721684297317497

Epoch: 5| Step: 7
Training loss: 3.424384324920429
Validation loss: 2.7233785650182387

Epoch: 5| Step: 8
Training loss: 3.4147255818821733
Validation loss: 2.7137701348430268

Epoch: 5| Step: 9
Training loss: 2.853112706035688
Validation loss: 2.7079080949872503

Epoch: 5| Step: 10
Training loss: 3.2089423225048153
Validation loss: 2.711413719065454

Epoch: 59| Step: 0
Training loss: 2.8495936455400352
Validation loss: 2.7230380514687686

Epoch: 5| Step: 1
Training loss: 2.940080523783001
Validation loss: 2.739933113393738

Epoch: 5| Step: 2
Training loss: 3.3439704608433916
Validation loss: 2.77044193545277

Epoch: 5| Step: 3
Training loss: 2.921769247334219
Validation loss: 2.7202580180203095

Epoch: 5| Step: 4
Training loss: 2.9238677547727603
Validation loss: 2.71080459382887

Epoch: 5| Step: 5
Training loss: 2.3666526265690515
Validation loss: 2.7102114057397237

Epoch: 5| Step: 6
Training loss: 3.7521529057625913
Validation loss: 2.711761270014348

Epoch: 5| Step: 7
Training loss: 2.8754542448024862
Validation loss: 2.710616110642656

Epoch: 5| Step: 8
Training loss: 3.312180701647513
Validation loss: 2.710672291155384

Epoch: 5| Step: 9
Training loss: 2.99825617652956
Validation loss: 2.7100492627946062

Epoch: 5| Step: 10
Training loss: 2.971423421058802
Validation loss: 2.7065221752366933

Epoch: 60| Step: 0
Training loss: 2.8560007332979858
Validation loss: 2.7070629118790897

Epoch: 5| Step: 1
Training loss: 3.091200731920665
Validation loss: 2.7107057934879846

Epoch: 5| Step: 2
Training loss: 3.5619347107101524
Validation loss: 2.7103969981646365

Epoch: 5| Step: 3
Training loss: 2.5910324199654964
Validation loss: 2.7183805145556947

Epoch: 5| Step: 4
Training loss: 3.401606342977601
Validation loss: 2.7298627158511577

Epoch: 5| Step: 5
Training loss: 2.7115064568095395
Validation loss: 2.7130490263019182

Epoch: 5| Step: 6
Training loss: 3.3872568303627153
Validation loss: 2.7048387663753046

Epoch: 5| Step: 7
Training loss: 2.8346677517510552
Validation loss: 2.7020569601838718

Epoch: 5| Step: 8
Training loss: 3.1136815903789277
Validation loss: 2.698949090745329

Epoch: 5| Step: 9
Training loss: 2.950072795163729
Validation loss: 2.6988037050515743

Epoch: 5| Step: 10
Training loss: 2.634907780142823
Validation loss: 2.703234460081984

Epoch: 61| Step: 0
Training loss: 3.109102170083208
Validation loss: 2.6964844920924547

Epoch: 5| Step: 1
Training loss: 2.4505938452540383
Validation loss: 2.698595751568647

Epoch: 5| Step: 2
Training loss: 2.842805139541113
Validation loss: 2.7041917372715263

Epoch: 5| Step: 3
Training loss: 3.5324177119449787
Validation loss: 2.6951528374985827

Epoch: 5| Step: 4
Training loss: 2.5615860774663197
Validation loss: 2.6970456931061566

Epoch: 5| Step: 5
Training loss: 2.9782854035001662
Validation loss: 2.6960774072716767

Epoch: 5| Step: 6
Training loss: 3.1263790902288724
Validation loss: 2.6928696462181656

Epoch: 5| Step: 7
Training loss: 3.4835522967667765
Validation loss: 2.695336080753849

Epoch: 5| Step: 8
Training loss: 3.261113605213096
Validation loss: 2.6940575687250226

Epoch: 5| Step: 9
Training loss: 3.0293710135088756
Validation loss: 2.6945034644437245

Epoch: 5| Step: 10
Training loss: 2.6803849538781854
Validation loss: 2.6966962655742126

Epoch: 62| Step: 0
Training loss: 2.585406660931018
Validation loss: 2.6935353982803947

Epoch: 5| Step: 1
Training loss: 2.5202857019048603
Validation loss: 2.692933873804067

Epoch: 5| Step: 2
Training loss: 3.6406690079153465
Validation loss: 2.6912495240495597

Epoch: 5| Step: 3
Training loss: 2.7434009790558807
Validation loss: 2.6955338895880536

Epoch: 5| Step: 4
Training loss: 2.9933491735173776
Validation loss: 2.6998409039025235

Epoch: 5| Step: 5
Training loss: 2.6893261759707987
Validation loss: 2.7065443492953363

Epoch: 5| Step: 6
Training loss: 3.2744714383207585
Validation loss: 2.7187099932389835

Epoch: 5| Step: 7
Training loss: 3.419265100145533
Validation loss: 2.69442350384158

Epoch: 5| Step: 8
Training loss: 3.2849105035444097
Validation loss: 2.6900276074950513

Epoch: 5| Step: 9
Training loss: 3.2019389119751342
Validation loss: 2.688347484667667

Epoch: 5| Step: 10
Training loss: 2.597633120785188
Validation loss: 2.6904411110063093

Epoch: 63| Step: 0
Training loss: 3.2111354497700684
Validation loss: 2.692371690981794

Epoch: 5| Step: 1
Training loss: 3.2334640620700026
Validation loss: 2.694018775891565

Epoch: 5| Step: 2
Training loss: 2.9451658176961084
Validation loss: 2.692407889069738

Epoch: 5| Step: 3
Training loss: 3.2876573764278225
Validation loss: 2.6949600890551237

Epoch: 5| Step: 4
Training loss: 3.1324342418445084
Validation loss: 2.697796337659091

Epoch: 5| Step: 5
Training loss: 2.888041893779349
Validation loss: 2.6907321184429436

Epoch: 5| Step: 6
Training loss: 2.852218092713262
Validation loss: 2.69552723209186

Epoch: 5| Step: 7
Training loss: 2.9220891047892645
Validation loss: 2.7018754290051286

Epoch: 5| Step: 8
Training loss: 2.8866107182297083
Validation loss: 2.714873531328999

Epoch: 5| Step: 9
Training loss: 3.176124319617315
Validation loss: 2.720924180419071

Epoch: 5| Step: 10
Training loss: 2.688348680496949
Validation loss: 2.714202229509463

Epoch: 64| Step: 0
Training loss: 2.855264011876073
Validation loss: 2.704530068028044

Epoch: 5| Step: 1
Training loss: 2.8713662777225557
Validation loss: 2.710009242052901

Epoch: 5| Step: 2
Training loss: 3.0799990143712437
Validation loss: 2.6925166479895464

Epoch: 5| Step: 3
Training loss: 2.9450714255513604
Validation loss: 2.686136096620777

Epoch: 5| Step: 4
Training loss: 3.187488929878908
Validation loss: 2.6888647046204026

Epoch: 5| Step: 5
Training loss: 2.741842220989571
Validation loss: 2.688905932465858

Epoch: 5| Step: 6
Training loss: 2.9792407544578303
Validation loss: 2.68601067922656

Epoch: 5| Step: 7
Training loss: 3.027431009327108
Validation loss: 2.680722104384172

Epoch: 5| Step: 8
Training loss: 3.3610744702012005
Validation loss: 2.6828301874889564

Epoch: 5| Step: 9
Training loss: 2.9386545712429206
Validation loss: 2.682717817371557

Epoch: 5| Step: 10
Training loss: 3.0986363518830244
Validation loss: 2.6796828581172667

Epoch: 65| Step: 0
Training loss: 3.7031765061027757
Validation loss: 2.6799389379699066

Epoch: 5| Step: 1
Training loss: 2.8475299906637495
Validation loss: 2.6827769586667825

Epoch: 5| Step: 2
Training loss: 3.176945434245809
Validation loss: 2.70403483747142

Epoch: 5| Step: 3
Training loss: 2.8047489595187716
Validation loss: 2.70499497887021

Epoch: 5| Step: 4
Training loss: 2.810922646602554
Validation loss: 2.692777909859474

Epoch: 5| Step: 5
Training loss: 3.471630103592817
Validation loss: 2.6856901480752073

Epoch: 5| Step: 6
Training loss: 2.806184841835375
Validation loss: 2.678825047093818

Epoch: 5| Step: 7
Training loss: 2.3555966875495753
Validation loss: 2.6765912293443095

Epoch: 5| Step: 8
Training loss: 2.862471108103375
Validation loss: 2.6760203652952392

Epoch: 5| Step: 9
Training loss: 3.0156533037349695
Validation loss: 2.675876184546928

Epoch: 5| Step: 10
Training loss: 3.0776106506337886
Validation loss: 2.6762471336500404

Epoch: 66| Step: 0
Training loss: 2.7395345782642297
Validation loss: 2.677469324268823

Epoch: 5| Step: 1
Training loss: 2.8884995353002374
Validation loss: 2.6791162182349466

Epoch: 5| Step: 2
Training loss: 3.234165940461982
Validation loss: 2.681977439862874

Epoch: 5| Step: 3
Training loss: 3.2860345743581205
Validation loss: 2.6827138620854867

Epoch: 5| Step: 4
Training loss: 2.4535337459901387
Validation loss: 2.6857905100874166

Epoch: 5| Step: 5
Training loss: 2.980447311624241
Validation loss: 2.6836101582052065

Epoch: 5| Step: 6
Training loss: 2.993622517907714
Validation loss: 2.681313898826416

Epoch: 5| Step: 7
Training loss: 3.2618915443563656
Validation loss: 2.6808712075084538

Epoch: 5| Step: 8
Training loss: 2.977006053166231
Validation loss: 2.680448617923329

Epoch: 5| Step: 9
Training loss: 3.347876880902309
Validation loss: 2.6863639779060087

Epoch: 5| Step: 10
Training loss: 2.8741797230697617
Validation loss: 2.691401816929614

Epoch: 67| Step: 0
Training loss: 3.0975500331529338
Validation loss: 2.693325879627726

Epoch: 5| Step: 1
Training loss: 3.073713985820082
Validation loss: 2.7171213148815845

Epoch: 5| Step: 2
Training loss: 2.718479449962229
Validation loss: 2.7445783560050905

Epoch: 5| Step: 3
Training loss: 3.10044383286561
Validation loss: 2.777209712739127

Epoch: 5| Step: 4
Training loss: 2.8930403232605864
Validation loss: 2.7263983647039374

Epoch: 5| Step: 5
Training loss: 2.9750785432593223
Validation loss: 2.7143120145282995

Epoch: 5| Step: 6
Training loss: 2.7682805647194906
Validation loss: 2.6871240175893396

Epoch: 5| Step: 7
Training loss: 3.1206778582224417
Validation loss: 2.6804729549328243

Epoch: 5| Step: 8
Training loss: 3.570162513303691
Validation loss: 2.6839490966516695

Epoch: 5| Step: 9
Training loss: 3.4074324209182785
Validation loss: 2.700180340930696

Epoch: 5| Step: 10
Training loss: 2.384715536655343
Validation loss: 2.694354195629133

Epoch: 68| Step: 0
Training loss: 3.173380076547638
Validation loss: 2.6879537704410357

Epoch: 5| Step: 1
Training loss: 2.947624776203556
Validation loss: 2.6818551746683053

Epoch: 5| Step: 2
Training loss: 2.411980283425691
Validation loss: 2.670796352507552

Epoch: 5| Step: 3
Training loss: 3.261906601299023
Validation loss: 2.667824146599955

Epoch: 5| Step: 4
Training loss: 2.446318982944517
Validation loss: 2.664887966282299

Epoch: 5| Step: 5
Training loss: 3.263793723881137
Validation loss: 2.6642649535786447

Epoch: 5| Step: 6
Training loss: 2.840491807288905
Validation loss: 2.674770490131111

Epoch: 5| Step: 7
Training loss: 3.1779873588411425
Validation loss: 2.6955564212863905

Epoch: 5| Step: 8
Training loss: 3.3674443759869606
Validation loss: 2.701077739352467

Epoch: 5| Step: 9
Training loss: 3.2788463689768297
Validation loss: 2.681189000712528

Epoch: 5| Step: 10
Training loss: 2.7701561657233547
Validation loss: 2.6635028069666853

Epoch: 69| Step: 0
Training loss: 2.913715249815403
Validation loss: 2.658314189854175

Epoch: 5| Step: 1
Training loss: 2.997876846512049
Validation loss: 2.657082837176739

Epoch: 5| Step: 2
Training loss: 2.910112173271496
Validation loss: 2.656988182500001

Epoch: 5| Step: 3
Training loss: 2.9118627677901276
Validation loss: 2.659547781341511

Epoch: 5| Step: 4
Training loss: 2.6227736341418613
Validation loss: 2.662474343673429

Epoch: 5| Step: 5
Training loss: 2.9893777668067014
Validation loss: 2.6672439197156197

Epoch: 5| Step: 6
Training loss: 3.128049049636785
Validation loss: 2.664781298745441

Epoch: 5| Step: 7
Training loss: 3.5597516886232055
Validation loss: 2.6600151637161162

Epoch: 5| Step: 8
Training loss: 2.8188762019086635
Validation loss: 2.66833079010684

Epoch: 5| Step: 9
Training loss: 3.276332549183516
Validation loss: 2.6534276397968357

Epoch: 5| Step: 10
Training loss: 2.8232940384053027
Validation loss: 2.6579751615287885

Epoch: 70| Step: 0
Training loss: 2.9408558283661006
Validation loss: 2.655582793453312

Epoch: 5| Step: 1
Training loss: 2.8616450736361103
Validation loss: 2.692877966778565

Epoch: 5| Step: 2
Training loss: 3.4180778442411155
Validation loss: 2.726740621045793

Epoch: 5| Step: 3
Training loss: 3.1403356010748165
Validation loss: 2.726710928901591

Epoch: 5| Step: 4
Training loss: 2.8170614763403217
Validation loss: 2.6994367896999845

Epoch: 5| Step: 5
Training loss: 3.0874146607995057
Validation loss: 2.6852760012770442

Epoch: 5| Step: 6
Training loss: 3.105680791945225
Validation loss: 2.6734812150189144

Epoch: 5| Step: 7
Training loss: 3.030624482415789
Validation loss: 2.665376323784685

Epoch: 5| Step: 8
Training loss: 3.1342518988612156
Validation loss: 2.6588840056089853

Epoch: 5| Step: 9
Training loss: 2.65412081484711
Validation loss: 2.65848567913275

Epoch: 5| Step: 10
Training loss: 2.6702453819129968
Validation loss: 2.6597911887856

Epoch: 71| Step: 0
Training loss: 2.594462469212147
Validation loss: 2.6561745736055586

Epoch: 5| Step: 1
Training loss: 2.940182698600116
Validation loss: 2.6546961351508784

Epoch: 5| Step: 2
Training loss: 3.107731677232341
Validation loss: 2.65824657011468

Epoch: 5| Step: 3
Training loss: 3.265538410699738
Validation loss: 2.65932180430194

Epoch: 5| Step: 4
Training loss: 2.8069826898533727
Validation loss: 2.6593293323270757

Epoch: 5| Step: 5
Training loss: 3.0349617482120514
Validation loss: 2.6735347852149776

Epoch: 5| Step: 6
Training loss: 2.854827266084105
Validation loss: 2.6834501414427807

Epoch: 5| Step: 7
Training loss: 3.0845675361005838
Validation loss: 2.7126561858549314

Epoch: 5| Step: 8
Training loss: 3.269902544348399
Validation loss: 2.709036896778019

Epoch: 5| Step: 9
Training loss: 2.8682082851119213
Validation loss: 2.680868662868879

Epoch: 5| Step: 10
Training loss: 3.151475827070682
Validation loss: 2.651892513280647

Epoch: 72| Step: 0
Training loss: 3.0161426475445277
Validation loss: 2.648216399740555

Epoch: 5| Step: 1
Training loss: 3.436508313097224
Validation loss: 2.646154733143777

Epoch: 5| Step: 2
Training loss: 3.2052315088888244
Validation loss: 2.6500828676042714

Epoch: 5| Step: 3
Training loss: 2.9430408571228392
Validation loss: 2.654003250426403

Epoch: 5| Step: 4
Training loss: 2.7887027626020906
Validation loss: 2.654704600465489

Epoch: 5| Step: 5
Training loss: 3.4143049559931713
Validation loss: 2.6514502672061546

Epoch: 5| Step: 6
Training loss: 2.995175296703583
Validation loss: 2.6533065866136467

Epoch: 5| Step: 7
Training loss: 3.3720482528057762
Validation loss: 2.652168000004329

Epoch: 5| Step: 8
Training loss: 2.257160237747242
Validation loss: 2.6489946023412405

Epoch: 5| Step: 9
Training loss: 2.8746329363481857
Validation loss: 2.648381043766301

Epoch: 5| Step: 10
Training loss: 2.3234381895699214
Validation loss: 2.6432796870896165

Epoch: 73| Step: 0
Training loss: 3.1850667903969536
Validation loss: 2.640543845722611

Epoch: 5| Step: 1
Training loss: 3.1265611945001335
Validation loss: 2.646768774877019

Epoch: 5| Step: 2
Training loss: 2.5844070192726742
Validation loss: 2.6572179836570626

Epoch: 5| Step: 3
Training loss: 2.9313175803651856
Validation loss: 2.6658302538075027

Epoch: 5| Step: 4
Training loss: 2.660280109944571
Validation loss: 2.668929232937293

Epoch: 5| Step: 5
Training loss: 3.3644436235425457
Validation loss: 2.6448755521071172

Epoch: 5| Step: 6
Training loss: 2.9264725198268575
Validation loss: 2.6413194112603007

Epoch: 5| Step: 7
Training loss: 2.8685073517214286
Validation loss: 2.6376755706961568

Epoch: 5| Step: 8
Training loss: 3.3390071423395065
Validation loss: 2.6438757298355786

Epoch: 5| Step: 9
Training loss: 2.7587312459373043
Validation loss: 2.6401065910488657

Epoch: 5| Step: 10
Training loss: 3.00870268888722
Validation loss: 2.6372715407690777

Epoch: 74| Step: 0
Training loss: 2.6730520767636254
Validation loss: 2.6394396249505943

Epoch: 5| Step: 1
Training loss: 3.4020588139064865
Validation loss: 2.6422823705646485

Epoch: 5| Step: 2
Training loss: 2.6289916796924424
Validation loss: 2.640641459674461

Epoch: 5| Step: 3
Training loss: 2.8682436959599618
Validation loss: 2.6400694214408778

Epoch: 5| Step: 4
Training loss: 3.1963676818260245
Validation loss: 2.637384734215444

Epoch: 5| Step: 5
Training loss: 2.5761583630118543
Validation loss: 2.6348642664199793

Epoch: 5| Step: 6
Training loss: 2.9120353622804576
Validation loss: 2.6382149571060975

Epoch: 5| Step: 7
Training loss: 3.46401627044733
Validation loss: 2.645196551401304

Epoch: 5| Step: 8
Training loss: 3.0485023260922635
Validation loss: 2.643232490799735

Epoch: 5| Step: 9
Training loss: 3.0025989083571876
Validation loss: 2.6535426772319797

Epoch: 5| Step: 10
Training loss: 2.9408968500844965
Validation loss: 2.63974727521616

Epoch: 75| Step: 0
Training loss: 2.777464444184389
Validation loss: 2.63637256386941

Epoch: 5| Step: 1
Training loss: 2.9619251707568655
Validation loss: 2.6309749539118585

Epoch: 5| Step: 2
Training loss: 3.054075994529096
Validation loss: 2.6328299150499226

Epoch: 5| Step: 3
Training loss: 2.5736313006322873
Validation loss: 2.629468666217008

Epoch: 5| Step: 4
Training loss: 2.4303924421043486
Validation loss: 2.624788296274032

Epoch: 5| Step: 5
Training loss: 2.562964606616343
Validation loss: 2.629266618350795

Epoch: 5| Step: 6
Training loss: 3.4001940166990896
Validation loss: 2.6301678134879922

Epoch: 5| Step: 7
Training loss: 2.575112449635041
Validation loss: 2.6255444412782314

Epoch: 5| Step: 8
Training loss: 3.4021015628498383
Validation loss: 2.631085127814153

Epoch: 5| Step: 9
Training loss: 3.316164401057171
Validation loss: 2.6311871449092585

Epoch: 5| Step: 10
Training loss: 3.502665458436004
Validation loss: 2.637311770992043

Epoch: 76| Step: 0
Training loss: 3.254691625657491
Validation loss: 2.648665257411098

Epoch: 5| Step: 1
Training loss: 3.2935418369015594
Validation loss: 2.6378122421419965

Epoch: 5| Step: 2
Training loss: 2.9243023423464827
Validation loss: 2.630415338204176

Epoch: 5| Step: 3
Training loss: 3.0375192837829075
Validation loss: 2.631693231640965

Epoch: 5| Step: 4
Training loss: 2.3190394547343836
Validation loss: 2.6316710990612764

Epoch: 5| Step: 5
Training loss: 2.890628959034451
Validation loss: 2.6282088965021257

Epoch: 5| Step: 6
Training loss: 3.126614878157122
Validation loss: 2.627045712751328

Epoch: 5| Step: 7
Training loss: 3.0696076416389766
Validation loss: 2.6247447710628657

Epoch: 5| Step: 8
Training loss: 3.1949486560307743
Validation loss: 2.625384945631717

Epoch: 5| Step: 9
Training loss: 2.6945314021897158
Validation loss: 2.624311204420654

Epoch: 5| Step: 10
Training loss: 2.697318483313983
Validation loss: 2.625629215839284

Epoch: 77| Step: 0
Training loss: 2.587502366216932
Validation loss: 2.624979742766004

Epoch: 5| Step: 1
Training loss: 2.757633192592905
Validation loss: 2.634440701016857

Epoch: 5| Step: 2
Training loss: 3.2518688110785363
Validation loss: 2.6355389650110155

Epoch: 5| Step: 3
Training loss: 2.9982183252075476
Validation loss: 2.6345571270356953

Epoch: 5| Step: 4
Training loss: 2.885831910883081
Validation loss: 2.6275483149081698

Epoch: 5| Step: 5
Training loss: 3.071540877991589
Validation loss: 2.626520481202856

Epoch: 5| Step: 6
Training loss: 3.4702872229440898
Validation loss: 2.623751823579704

Epoch: 5| Step: 7
Training loss: 2.547050797649726
Validation loss: 2.6244691975214174

Epoch: 5| Step: 8
Training loss: 2.9309440664617843
Validation loss: 2.6245723459996997

Epoch: 5| Step: 9
Training loss: 3.089369938881178
Validation loss: 2.618784545988541

Epoch: 5| Step: 10
Training loss: 2.9600369737223255
Validation loss: 2.6251657426800517

Epoch: 78| Step: 0
Training loss: 3.114455629790555
Validation loss: 2.629570510092076

Epoch: 5| Step: 1
Training loss: 2.254905439538378
Validation loss: 2.633693429504337

Epoch: 5| Step: 2
Training loss: 2.760629398617944
Validation loss: 2.6465379598519285

Epoch: 5| Step: 3
Training loss: 2.417975652188755
Validation loss: 2.650130062815983

Epoch: 5| Step: 4
Training loss: 3.647468389174115
Validation loss: 2.640969059055668

Epoch: 5| Step: 5
Training loss: 3.263361826516729
Validation loss: 2.636203606711541

Epoch: 5| Step: 6
Training loss: 2.7438104505548884
Validation loss: 2.629747849276197

Epoch: 5| Step: 7
Training loss: 3.20081048476779
Validation loss: 2.6312151644991952

Epoch: 5| Step: 8
Training loss: 3.2261554747623165
Validation loss: 2.626063278499872

Epoch: 5| Step: 9
Training loss: 3.168602519017327
Validation loss: 2.615549791775746

Epoch: 5| Step: 10
Training loss: 2.5085167772333867
Validation loss: 2.6168100931323277

Epoch: 79| Step: 0
Training loss: 2.6663717067033446
Validation loss: 2.6158030090711115

Epoch: 5| Step: 1
Training loss: 3.4952035463188973
Validation loss: 2.6151294504781366

Epoch: 5| Step: 2
Training loss: 2.863868059965853
Validation loss: 2.6155578064797385

Epoch: 5| Step: 3
Training loss: 2.5875002469417434
Validation loss: 2.613965926946645

Epoch: 5| Step: 4
Training loss: 2.9710777392621783
Validation loss: 2.6151738768231074

Epoch: 5| Step: 5
Training loss: 3.650068878151011
Validation loss: 2.618075223388096

Epoch: 5| Step: 6
Training loss: 2.9015704802453195
Validation loss: 2.6157506351870854

Epoch: 5| Step: 7
Training loss: 2.6700256372142475
Validation loss: 2.611493289379012

Epoch: 5| Step: 8
Training loss: 3.1126303955707866
Validation loss: 2.613339962459081

Epoch: 5| Step: 9
Training loss: 2.2019351424558424
Validation loss: 2.611870934479105

Epoch: 5| Step: 10
Training loss: 3.2814511192083766
Validation loss: 2.6142689623306428

Epoch: 80| Step: 0
Training loss: 2.7200559789843655
Validation loss: 2.622318200726241

Epoch: 5| Step: 1
Training loss: 3.068270637690835
Validation loss: 2.6340494182140266

Epoch: 5| Step: 2
Training loss: 3.171386230092822
Validation loss: 2.6466473086412643

Epoch: 5| Step: 3
Training loss: 3.138809362508715
Validation loss: 2.665283079405208

Epoch: 5| Step: 4
Training loss: 3.244359476974233
Validation loss: 2.676555213884543

Epoch: 5| Step: 5
Training loss: 3.105867948005713
Validation loss: 2.637258482777369

Epoch: 5| Step: 6
Training loss: 2.954427926186847
Validation loss: 2.6277520168346884

Epoch: 5| Step: 7
Training loss: 3.1832324612864658
Validation loss: 2.619207504265379

Epoch: 5| Step: 8
Training loss: 2.5923533528566076
Validation loss: 2.6060572151206336

Epoch: 5| Step: 9
Training loss: 2.720098314612177
Validation loss: 2.608900013573172

Epoch: 5| Step: 10
Training loss: 2.558512492745953
Validation loss: 2.605481698697592

Epoch: 81| Step: 0
Training loss: 2.952500373136156
Validation loss: 2.610472936624234

Epoch: 5| Step: 1
Training loss: 2.7533250993631686
Validation loss: 2.6224465302599698

Epoch: 5| Step: 2
Training loss: 2.8240353008960044
Validation loss: 2.6276298920164525

Epoch: 5| Step: 3
Training loss: 2.612811720653719
Validation loss: 2.6439319506577674

Epoch: 5| Step: 4
Training loss: 3.1539119710012824
Validation loss: 2.6459893886390065

Epoch: 5| Step: 5
Training loss: 3.375675133889235
Validation loss: 2.657759549363056

Epoch: 5| Step: 6
Training loss: 3.182870981749402
Validation loss: 2.66030400700515

Epoch: 5| Step: 7
Training loss: 3.2309943328590482
Validation loss: 2.649117967062442

Epoch: 5| Step: 8
Training loss: 2.893103284641007
Validation loss: 2.638564631501249

Epoch: 5| Step: 9
Training loss: 2.7907776247260165
Validation loss: 2.625673293662887

Epoch: 5| Step: 10
Training loss: 2.8031238670729577
Validation loss: 2.6226890341318967

Epoch: 82| Step: 0
Training loss: 2.161274570482069
Validation loss: 2.619093070070653

Epoch: 5| Step: 1
Training loss: 2.9900626264666883
Validation loss: 2.615078268910933

Epoch: 5| Step: 2
Training loss: 2.543958058389375
Validation loss: 2.612125185592789

Epoch: 5| Step: 3
Training loss: 2.6805712074081973
Validation loss: 2.6135876026879874

Epoch: 5| Step: 4
Training loss: 2.8473598498651382
Validation loss: 2.60253712391367

Epoch: 5| Step: 5
Training loss: 2.8739547487969124
Validation loss: 2.599855598576284

Epoch: 5| Step: 6
Training loss: 3.1929021198814653
Validation loss: 2.6017987189215193

Epoch: 5| Step: 7
Training loss: 3.0879859016867472
Validation loss: 2.6040941749245397

Epoch: 5| Step: 8
Training loss: 3.1752234012374805
Validation loss: 2.6023662192448183

Epoch: 5| Step: 9
Training loss: 3.5579715524000455
Validation loss: 2.6095377700770492

Epoch: 5| Step: 10
Training loss: 3.173582472464469
Validation loss: 2.606260579303312

Epoch: 83| Step: 0
Training loss: 3.192422992013515
Validation loss: 2.6241822900394514

Epoch: 5| Step: 1
Training loss: 2.7167787969496477
Validation loss: 2.6208953701657456

Epoch: 5| Step: 2
Training loss: 3.1586260020015064
Validation loss: 2.624577195728462

Epoch: 5| Step: 3
Training loss: 2.975791851414399
Validation loss: 2.618780164236288

Epoch: 5| Step: 4
Training loss: 2.6857210525902833
Validation loss: 2.619635771801555

Epoch: 5| Step: 5
Training loss: 3.1534252556863756
Validation loss: 2.611953984693111

Epoch: 5| Step: 6
Training loss: 3.2145598461177327
Validation loss: 2.6022012735583697

Epoch: 5| Step: 7
Training loss: 2.6229438903543136
Validation loss: 2.595237342058511

Epoch: 5| Step: 8
Training loss: 3.08530838746537
Validation loss: 2.595735081137436

Epoch: 5| Step: 9
Training loss: 2.4723029343744276
Validation loss: 2.5890017449066485

Epoch: 5| Step: 10
Training loss: 3.0543134611552465
Validation loss: 2.589865744102698

Epoch: 84| Step: 0
Training loss: 3.0028167852251464
Validation loss: 2.5919548560404464

Epoch: 5| Step: 1
Training loss: 3.481512835731934
Validation loss: 2.587149759939691

Epoch: 5| Step: 2
Training loss: 3.2726452581166865
Validation loss: 2.5914612610503562

Epoch: 5| Step: 3
Training loss: 3.0036386040753307
Validation loss: 2.592431202757441

Epoch: 5| Step: 4
Training loss: 2.7243594475424975
Validation loss: 2.599109800521956

Epoch: 5| Step: 5
Training loss: 2.220564516651909
Validation loss: 2.605613788463563

Epoch: 5| Step: 6
Training loss: 3.087098340305946
Validation loss: 2.6130106514081164

Epoch: 5| Step: 7
Training loss: 3.0196986380269726
Validation loss: 2.6273094893435416

Epoch: 5| Step: 8
Training loss: 2.7647560608025854
Validation loss: 2.641714163794742

Epoch: 5| Step: 9
Training loss: 2.2410930660725223
Validation loss: 2.638229091897005

Epoch: 5| Step: 10
Training loss: 3.381479330976357
Validation loss: 2.672253075163177

Epoch: 85| Step: 0
Training loss: 3.147365491688095
Validation loss: 2.613921092669404

Epoch: 5| Step: 1
Training loss: 2.4242716098422954
Validation loss: 2.591973975800278

Epoch: 5| Step: 2
Training loss: 3.163093475021893
Validation loss: 2.5871644571213115

Epoch: 5| Step: 3
Training loss: 2.7997388615768584
Validation loss: 2.5890349363417005

Epoch: 5| Step: 4
Training loss: 2.8052226541585426
Validation loss: 2.592332507242268

Epoch: 5| Step: 5
Training loss: 2.883129071477351
Validation loss: 2.592151725153434

Epoch: 5| Step: 6
Training loss: 3.177406036164145
Validation loss: 2.6033110035261156

Epoch: 5| Step: 7
Training loss: 2.8524971044393648
Validation loss: 2.6097614340402684

Epoch: 5| Step: 8
Training loss: 3.4665721207955214
Validation loss: 2.6058528443797337

Epoch: 5| Step: 9
Training loss: 2.6350317411302497
Validation loss: 2.595824379646191

Epoch: 5| Step: 10
Training loss: 2.84546919615888
Validation loss: 2.59960641354845

Epoch: 86| Step: 0
Training loss: 2.757968282217062
Validation loss: 2.5952387872462572

Epoch: 5| Step: 1
Training loss: 2.949797193377142
Validation loss: 2.5966765084679695

Epoch: 5| Step: 2
Training loss: 3.105198033846914
Validation loss: 2.598424603968271

Epoch: 5| Step: 3
Training loss: 3.346067392057055
Validation loss: 2.601276064999858

Epoch: 5| Step: 4
Training loss: 2.8711985458659446
Validation loss: 2.598662493204144

Epoch: 5| Step: 5
Training loss: 3.06191357038771
Validation loss: 2.599582318469438

Epoch: 5| Step: 6
Training loss: 2.830460569289344
Validation loss: 2.604282525879537

Epoch: 5| Step: 7
Training loss: 2.990728196742317
Validation loss: 2.600112342852692

Epoch: 5| Step: 8
Training loss: 2.5413196097474082
Validation loss: 2.6018362293296566

Epoch: 5| Step: 9
Training loss: 2.670341899569361
Validation loss: 2.589295979274429

Epoch: 5| Step: 10
Training loss: 3.2606924669577024
Validation loss: 2.5879826657162184

Epoch: 87| Step: 0
Training loss: 2.9172749747844167
Validation loss: 2.5897587201843892

Epoch: 5| Step: 1
Training loss: 3.1234998535527487
Validation loss: 2.5926851987128985

Epoch: 5| Step: 2
Training loss: 2.9193620125888593
Validation loss: 2.5997843934580165

Epoch: 5| Step: 3
Training loss: 2.862720804152381
Validation loss: 2.6138295759453434

Epoch: 5| Step: 4
Training loss: 2.9779651771082443
Validation loss: 2.6009610620362396

Epoch: 5| Step: 5
Training loss: 3.521705624722508
Validation loss: 2.5973574156604373

Epoch: 5| Step: 6
Training loss: 2.8695052339167435
Validation loss: 2.583890030930264

Epoch: 5| Step: 7
Training loss: 2.8488643056543164
Validation loss: 2.579805388219387

Epoch: 5| Step: 8
Training loss: 3.04310492038272
Validation loss: 2.582880923946984

Epoch: 5| Step: 9
Training loss: 2.4952079622063974
Validation loss: 2.5902217010806514

Epoch: 5| Step: 10
Training loss: 2.636363998849539
Validation loss: 2.5851839015424947

Epoch: 88| Step: 0
Training loss: 3.4687994876115145
Validation loss: 2.5891865094441453

Epoch: 5| Step: 1
Training loss: 2.553975417261552
Validation loss: 2.5865100464323674

Epoch: 5| Step: 2
Training loss: 2.8542193851103743
Validation loss: 2.584851635173532

Epoch: 5| Step: 3
Training loss: 2.5313205473688027
Validation loss: 2.5901146131831205

Epoch: 5| Step: 4
Training loss: 2.9038913138361844
Validation loss: 2.604520811221883

Epoch: 5| Step: 5
Training loss: 3.0549731499074215
Validation loss: 2.608661542530204

Epoch: 5| Step: 6
Training loss: 2.8243477397497103
Validation loss: 2.662339923334567

Epoch: 5| Step: 7
Training loss: 3.184610440850363
Validation loss: 2.6675423365582973

Epoch: 5| Step: 8
Training loss: 2.694438848019935
Validation loss: 2.6057486863023662

Epoch: 5| Step: 9
Training loss: 3.206409984263182
Validation loss: 2.5849473782286827

Epoch: 5| Step: 10
Training loss: 2.964598312572418
Validation loss: 2.5760938302995364

Epoch: 89| Step: 0
Training loss: 2.4214960601667466
Validation loss: 2.578312626061834

Epoch: 5| Step: 1
Training loss: 3.0695386692810884
Validation loss: 2.576637675818934

Epoch: 5| Step: 2
Training loss: 2.999052215905149
Validation loss: 2.5842891900229006

Epoch: 5| Step: 3
Training loss: 2.552492744667136
Validation loss: 2.5884239615852356

Epoch: 5| Step: 4
Training loss: 3.0479080405192533
Validation loss: 2.598845530204157

Epoch: 5| Step: 5
Training loss: 3.1280879213801325
Validation loss: 2.600977505604792

Epoch: 5| Step: 6
Training loss: 2.4224209077912935
Validation loss: 2.604035043322892

Epoch: 5| Step: 7
Training loss: 2.584666789878991
Validation loss: 2.6043763034897744

Epoch: 5| Step: 8
Training loss: 3.3533769866599616
Validation loss: 2.6088950885170465

Epoch: 5| Step: 9
Training loss: 3.4450493882934046
Validation loss: 2.610728810087169

Epoch: 5| Step: 10
Training loss: 3.1325065482422016
Validation loss: 2.586898601809732

Epoch: 90| Step: 0
Training loss: 2.866658258056137
Validation loss: 2.5822734640036247

Epoch: 5| Step: 1
Training loss: 2.494551347746562
Validation loss: 2.5785413816629537

Epoch: 5| Step: 2
Training loss: 2.4378324428681992
Validation loss: 2.574901585540594

Epoch: 5| Step: 3
Training loss: 3.142812697604119
Validation loss: 2.5744229283867237

Epoch: 5| Step: 4
Training loss: 2.9373495185130234
Validation loss: 2.5745335298276393

Epoch: 5| Step: 5
Training loss: 2.849001384923564
Validation loss: 2.5794586262369665

Epoch: 5| Step: 6
Training loss: 3.1162352673074825
Validation loss: 2.5859572491587035

Epoch: 5| Step: 7
Training loss: 3.273057865534567
Validation loss: 2.590975935860142

Epoch: 5| Step: 8
Training loss: 2.650295629745638
Validation loss: 2.594309593628377

Epoch: 5| Step: 9
Training loss: 3.3874263178283037
Validation loss: 2.590764821217125

Epoch: 5| Step: 10
Training loss: 2.9455357474555584
Validation loss: 2.6095737211883496

Epoch: 91| Step: 0
Training loss: 2.746865566962214
Validation loss: 2.6074986143158347

Epoch: 5| Step: 1
Training loss: 3.285526939642736
Validation loss: 2.621515387122093

Epoch: 5| Step: 2
Training loss: 2.932362548260518
Validation loss: 2.6091354178584663

Epoch: 5| Step: 3
Training loss: 3.377659068057239
Validation loss: 2.5955849295019773

Epoch: 5| Step: 4
Training loss: 2.3095996298350667
Validation loss: 2.5904291754902524

Epoch: 5| Step: 5
Training loss: 3.5338570752432914
Validation loss: 2.583813443724645

Epoch: 5| Step: 6
Training loss: 2.492108095632078
Validation loss: 2.58241527438761

Epoch: 5| Step: 7
Training loss: 2.4765923435085746
Validation loss: 2.582925196297856

Epoch: 5| Step: 8
Training loss: 3.064952257789556
Validation loss: 2.5919658792702918

Epoch: 5| Step: 9
Training loss: 3.279939807711708
Validation loss: 2.6209974356673884

Epoch: 5| Step: 10
Training loss: 2.587577461152063
Validation loss: 2.6084167349846274

Epoch: 92| Step: 0
Training loss: 3.1704012448978602
Validation loss: 2.6125198246534924

Epoch: 5| Step: 1
Training loss: 3.4164953576537505
Validation loss: 2.608907443393841

Epoch: 5| Step: 2
Training loss: 3.097315265605557
Validation loss: 2.5827465886226637

Epoch: 5| Step: 3
Training loss: 2.8582457934024723
Validation loss: 2.5775692218577664

Epoch: 5| Step: 4
Training loss: 2.8049611247695583
Validation loss: 2.573688733170832

Epoch: 5| Step: 5
Training loss: 2.243920271424383
Validation loss: 2.5731453633052803

Epoch: 5| Step: 6
Training loss: 2.9964480035230685
Validation loss: 2.570499249184095

Epoch: 5| Step: 7
Training loss: 2.6894010872609537
Validation loss: 2.574292709759796

Epoch: 5| Step: 8
Training loss: 3.1158926432751985
Validation loss: 2.5694788959221895

Epoch: 5| Step: 9
Training loss: 2.764776153471107
Validation loss: 2.568312618635258

Epoch: 5| Step: 10
Training loss: 2.9697840445768677
Validation loss: 2.567487793109077

Epoch: 93| Step: 0
Training loss: 2.8160754894466096
Validation loss: 2.5643937811208826

Epoch: 5| Step: 1
Training loss: 2.960641972028304
Validation loss: 2.5659958738616226

Epoch: 5| Step: 2
Training loss: 2.9443880851518007
Validation loss: 2.569641809736963

Epoch: 5| Step: 3
Training loss: 2.9843745206662735
Validation loss: 2.5725711339565858

Epoch: 5| Step: 4
Training loss: 3.182738094368393
Validation loss: 2.575809902789073

Epoch: 5| Step: 5
Training loss: 2.736216333843514
Validation loss: 2.5791754468500385

Epoch: 5| Step: 6
Training loss: 3.1701071938282035
Validation loss: 2.583301901915552

Epoch: 5| Step: 7
Training loss: 2.7228753372554326
Validation loss: 2.621810148865333

Epoch: 5| Step: 8
Training loss: 3.1304630592700025
Validation loss: 2.667008938153276

Epoch: 5| Step: 9
Training loss: 2.7525213993636957
Validation loss: 2.6650473852988874

Epoch: 5| Step: 10
Training loss: 2.8775868595114904
Validation loss: 2.6285333716844423

Epoch: 94| Step: 0
Training loss: 2.940204106207123
Validation loss: 2.5689393738214163

Epoch: 5| Step: 1
Training loss: 3.2079089656099384
Validation loss: 2.5697470033332137

Epoch: 5| Step: 2
Training loss: 3.2801689183538354
Validation loss: 2.574283659348799

Epoch: 5| Step: 3
Training loss: 2.616075604089969
Validation loss: 2.5816419143865565

Epoch: 5| Step: 4
Training loss: 2.401863658043444
Validation loss: 2.5874152773393497

Epoch: 5| Step: 5
Training loss: 3.0374178714402515
Validation loss: 2.5845858167160034

Epoch: 5| Step: 6
Training loss: 3.0508845625612757
Validation loss: 2.5884492519722806

Epoch: 5| Step: 7
Training loss: 3.2730163448961753
Validation loss: 2.5935348686413775

Epoch: 5| Step: 8
Training loss: 3.0822789391223386
Validation loss: 2.590162224077041

Epoch: 5| Step: 9
Training loss: 3.095466985029515
Validation loss: 2.587173688399009

Epoch: 5| Step: 10
Training loss: 2.14483684870772
Validation loss: 2.5876613822039194

Epoch: 95| Step: 0
Training loss: 3.3220454462055864
Validation loss: 2.58056536164651

Epoch: 5| Step: 1
Training loss: 3.090426268325859
Validation loss: 2.578237533723571

Epoch: 5| Step: 2
Training loss: 3.211718684674121
Validation loss: 2.58295597458852

Epoch: 5| Step: 3
Training loss: 2.986584709127213
Validation loss: 2.5775937087006833

Epoch: 5| Step: 4
Training loss: 2.282610135048359
Validation loss: 2.570769918761925

Epoch: 5| Step: 5
Training loss: 3.087633038947978
Validation loss: 2.5670719813804035

Epoch: 5| Step: 6
Training loss: 2.832302990734438
Validation loss: 2.5630391982008955

Epoch: 5| Step: 7
Training loss: 2.883509109813415
Validation loss: 2.5675717956733846

Epoch: 5| Step: 8
Training loss: 2.852906127422914
Validation loss: 2.5762296718338673

Epoch: 5| Step: 9
Training loss: 2.9102689785213585
Validation loss: 2.5794480693525577

Epoch: 5| Step: 10
Training loss: 2.7664211872842723
Validation loss: 2.5853797730754238

Epoch: 96| Step: 0
Training loss: 2.6992241380474895
Validation loss: 2.577980078697601

Epoch: 5| Step: 1
Training loss: 2.7139176140623666
Validation loss: 2.5830980353186863

Epoch: 5| Step: 2
Training loss: 2.8549742472701367
Validation loss: 2.58519248341136

Epoch: 5| Step: 3
Training loss: 3.436307110580709
Validation loss: 2.582005346689949

Epoch: 5| Step: 4
Training loss: 3.460897131139778
Validation loss: 2.5768305805805767

Epoch: 5| Step: 5
Training loss: 3.4820555763344916
Validation loss: 2.5599975051662636

Epoch: 5| Step: 6
Training loss: 2.372516839758518
Validation loss: 2.563776523148924

Epoch: 5| Step: 7
Training loss: 2.7640021783900197
Validation loss: 2.5609411224570056

Epoch: 5| Step: 8
Training loss: 2.394074587814474
Validation loss: 2.5586693136439878

Epoch: 5| Step: 9
Training loss: 2.929966132583436
Validation loss: 2.5570638697302086

Epoch: 5| Step: 10
Training loss: 2.735848253364172
Validation loss: 2.5582304059580627

Epoch: 97| Step: 0
Training loss: 2.918942208669728
Validation loss: 2.552857699682566

Epoch: 5| Step: 1
Training loss: 2.8680920746094434
Validation loss: 2.5597332470153593

Epoch: 5| Step: 2
Training loss: 2.632846549065808
Validation loss: 2.559622689123952

Epoch: 5| Step: 3
Training loss: 3.0247470277039703
Validation loss: 2.562851330242902

Epoch: 5| Step: 4
Training loss: 2.7928772384483658
Validation loss: 2.5732572311133173

Epoch: 5| Step: 5
Training loss: 2.368344770006149
Validation loss: 2.5841177441813064

Epoch: 5| Step: 6
Training loss: 3.343917414672118
Validation loss: 2.578828044454764

Epoch: 5| Step: 7
Training loss: 3.2075881753220474
Validation loss: 2.5737022342184086

Epoch: 5| Step: 8
Training loss: 2.796088081347722
Validation loss: 2.5609809540902724

Epoch: 5| Step: 9
Training loss: 2.81648666965412
Validation loss: 2.5603360619263746

Epoch: 5| Step: 10
Training loss: 3.1673538232085856
Validation loss: 2.5527456529539547

Epoch: 98| Step: 0
Training loss: 2.732129641019198
Validation loss: 2.5555510684374196

Epoch: 5| Step: 1
Training loss: 2.0784444921889533
Validation loss: 2.5526012632591915

Epoch: 5| Step: 2
Training loss: 2.7255013485899746
Validation loss: 2.5590588935025997

Epoch: 5| Step: 3
Training loss: 3.0710414186229174
Validation loss: 2.5596206679554157

Epoch: 5| Step: 4
Training loss: 2.968645595923221
Validation loss: 2.5587806060425926

Epoch: 5| Step: 5
Training loss: 2.9479350346688324
Validation loss: 2.5595697566173583

Epoch: 5| Step: 6
Training loss: 2.7329095891911375
Validation loss: 2.5562103620626577

Epoch: 5| Step: 7
Training loss: 3.039612708016251
Validation loss: 2.556828497100072

Epoch: 5| Step: 8
Training loss: 3.050819855859686
Validation loss: 2.561212438796018

Epoch: 5| Step: 9
Training loss: 3.0707463935819073
Validation loss: 2.557931808417429

Epoch: 5| Step: 10
Training loss: 3.414004537059806
Validation loss: 2.564916982026309

Epoch: 99| Step: 0
Training loss: 2.682051525044887
Validation loss: 2.5775610800801534

Epoch: 5| Step: 1
Training loss: 2.658220525119851
Validation loss: 2.574529453146194

Epoch: 5| Step: 2
Training loss: 3.1111008344964945
Validation loss: 2.575079643227692

Epoch: 5| Step: 3
Training loss: 3.332272519748951
Validation loss: 2.5793754322049027

Epoch: 5| Step: 4
Training loss: 2.4769771000246714
Validation loss: 2.568185344420686

Epoch: 5| Step: 5
Training loss: 2.867746740366437
Validation loss: 2.5617893613227816

Epoch: 5| Step: 6
Training loss: 3.0972230471242614
Validation loss: 2.5588427270560468

Epoch: 5| Step: 7
Training loss: 3.072351608479721
Validation loss: 2.55966650692431

Epoch: 5| Step: 8
Training loss: 3.126034679784258
Validation loss: 2.5574754846432555

Epoch: 5| Step: 9
Training loss: 2.8674525832202704
Validation loss: 2.563160711328437

Epoch: 5| Step: 10
Training loss: 2.501981712731875
Validation loss: 2.563667306611598

Epoch: 100| Step: 0
Training loss: 2.77526649020311
Validation loss: 2.569736463416707

Epoch: 5| Step: 1
Training loss: 2.578816361638976
Validation loss: 2.5757322890365484

Epoch: 5| Step: 2
Training loss: 3.3301315348081277
Validation loss: 2.5823300044378965

Epoch: 5| Step: 3
Training loss: 2.5718147502530466
Validation loss: 2.581308317122829

Epoch: 5| Step: 4
Training loss: 2.681945738969628
Validation loss: 2.5753514320941018

Epoch: 5| Step: 5
Training loss: 2.7584813849446994
Validation loss: 2.5979831812727987

Epoch: 5| Step: 6
Training loss: 3.3146592785862135
Validation loss: 2.628687252912564

Epoch: 5| Step: 7
Training loss: 2.770925496416216
Validation loss: 2.6016501874113342

Epoch: 5| Step: 8
Training loss: 3.021355279138539
Validation loss: 2.5630404014829065

Epoch: 5| Step: 9
Training loss: 3.114997113319884
Validation loss: 2.550756177110171

Epoch: 5| Step: 10
Training loss: 3.0148268518026202
Validation loss: 2.5396130894868643

Epoch: 101| Step: 0
Training loss: 2.9076774127130003
Validation loss: 2.542221792094799

Epoch: 5| Step: 1
Training loss: 2.7335661645518416
Validation loss: 2.5407567089016885

Epoch: 5| Step: 2
Training loss: 2.7325147131744494
Validation loss: 2.539166195048017

Epoch: 5| Step: 3
Training loss: 3.0720526736035194
Validation loss: 2.5392969913916263

Epoch: 5| Step: 4
Training loss: 3.5024615215009467
Validation loss: 2.537509948259969

Epoch: 5| Step: 5
Training loss: 2.5515570169215906
Validation loss: 2.541858777458832

Epoch: 5| Step: 6
Training loss: 2.1729110332451342
Validation loss: 2.54281666515455

Epoch: 5| Step: 7
Training loss: 2.7077404155700693
Validation loss: 2.5522371575157954

Epoch: 5| Step: 8
Training loss: 2.944435211583023
Validation loss: 2.5603847542291107

Epoch: 5| Step: 9
Training loss: 3.1442376609839786
Validation loss: 2.5713258385177657

Epoch: 5| Step: 10
Training loss: 3.3001312518749994
Validation loss: 2.584090643505023

Epoch: 102| Step: 0
Training loss: 2.8127764248110623
Validation loss: 2.5743764504447504

Epoch: 5| Step: 1
Training loss: 3.009598952028456
Validation loss: 2.562806145933165

Epoch: 5| Step: 2
Training loss: 2.885856034926429
Validation loss: 2.5646485426186745

Epoch: 5| Step: 3
Training loss: 2.1127853516841837
Validation loss: 2.556018933091489

Epoch: 5| Step: 4
Training loss: 3.299499624058933
Validation loss: 2.554162465631576

Epoch: 5| Step: 5
Training loss: 2.8377402384555404
Validation loss: 2.5498173498070993

Epoch: 5| Step: 6
Training loss: 2.2964956787786313
Validation loss: 2.545362396678795

Epoch: 5| Step: 7
Training loss: 3.1456107425044464
Validation loss: 2.541243163003494

Epoch: 5| Step: 8
Training loss: 3.319452295511308
Validation loss: 2.5379368894370615

Epoch: 5| Step: 9
Training loss: 3.3966361347007976
Validation loss: 2.5375323050407763

Epoch: 5| Step: 10
Training loss: 2.2704401871649584
Validation loss: 2.5622640281494307

Epoch: 103| Step: 0
Training loss: 2.9415190777663303
Validation loss: 2.5870272573870254

Epoch: 5| Step: 1
Training loss: 2.5299394770684525
Validation loss: 2.6070418311284507

Epoch: 5| Step: 2
Training loss: 2.666673918555254
Validation loss: 2.6309586374146257

Epoch: 5| Step: 3
Training loss: 2.595107401277222
Validation loss: 2.652076836434098

Epoch: 5| Step: 4
Training loss: 3.375065273077571
Validation loss: 2.675315154897235

Epoch: 5| Step: 5
Training loss: 3.0469526232099406
Validation loss: 2.657066192794222

Epoch: 5| Step: 6
Training loss: 3.088303212078815
Validation loss: 2.6337827356136208

Epoch: 5| Step: 7
Training loss: 3.212722913080951
Validation loss: 2.6064219337445524

Epoch: 5| Step: 8
Training loss: 2.5887102549332517
Validation loss: 2.5856879235042065

Epoch: 5| Step: 9
Training loss: 2.9554122866975416
Validation loss: 2.5768116618477537

Epoch: 5| Step: 10
Training loss: 3.13796823966667
Validation loss: 2.5456285897616477

Epoch: 104| Step: 0
Training loss: 2.685055796720106
Validation loss: 2.5398593224634354

Epoch: 5| Step: 1
Training loss: 2.575081618413618
Validation loss: 2.5323466724774946

Epoch: 5| Step: 2
Training loss: 3.115912384583899
Validation loss: 2.534799891767292

Epoch: 5| Step: 3
Training loss: 3.091836665193263
Validation loss: 2.5409831239611327

Epoch: 5| Step: 4
Training loss: 2.8256814421729106
Validation loss: 2.549295020167

Epoch: 5| Step: 5
Training loss: 3.1376170467110107
Validation loss: 2.544810606141056

Epoch: 5| Step: 6
Training loss: 2.815290634844399
Validation loss: 2.554325996012634

Epoch: 5| Step: 7
Training loss: 2.9694646677823946
Validation loss: 2.5406067458948547

Epoch: 5| Step: 8
Training loss: 2.6572187564487053
Validation loss: 2.539584028954306

Epoch: 5| Step: 9
Training loss: 2.760284180730733
Validation loss: 2.5397861062361424

Epoch: 5| Step: 10
Training loss: 3.1871714703167715
Validation loss: 2.542453747555282

Epoch: 105| Step: 0
Training loss: 3.1698335739877237
Validation loss: 2.544663198690309

Epoch: 5| Step: 1
Training loss: 3.0085648029354317
Validation loss: 2.5448021268463195

Epoch: 5| Step: 2
Training loss: 2.6969608297647105
Validation loss: 2.5632896227200623

Epoch: 5| Step: 3
Training loss: 2.8091946994858046
Validation loss: 2.567266883102334

Epoch: 5| Step: 4
Training loss: 2.8739306907711684
Validation loss: 2.5656224697172956

Epoch: 5| Step: 5
Training loss: 2.8423857717787624
Validation loss: 2.5554584495053514

Epoch: 5| Step: 6
Training loss: 3.012729025084876
Validation loss: 2.5625437570953262

Epoch: 5| Step: 7
Training loss: 2.5957548367391774
Validation loss: 2.5565262260817647

Epoch: 5| Step: 8
Training loss: 2.987656631513593
Validation loss: 2.5432881062338373

Epoch: 5| Step: 9
Training loss: 2.860869803843911
Validation loss: 2.5403730732349388

Epoch: 5| Step: 10
Training loss: 2.8831432948761084
Validation loss: 2.545162321375096

Epoch: 106| Step: 0
Training loss: 3.227886380943612
Validation loss: 2.5361823687588934

Epoch: 5| Step: 1
Training loss: 2.7780757320399347
Validation loss: 2.533965508239407

Epoch: 5| Step: 2
Training loss: 2.684595001762152
Validation loss: 2.540427147945871

Epoch: 5| Step: 3
Training loss: 2.8362986437147075
Validation loss: 2.5428714001724884

Epoch: 5| Step: 4
Training loss: 2.8868390007937585
Validation loss: 2.536482870719339

Epoch: 5| Step: 5
Training loss: 2.8133484302435083
Validation loss: 2.5596697945185958

Epoch: 5| Step: 6
Training loss: 2.7788306868658066
Validation loss: 2.5610096306807777

Epoch: 5| Step: 7
Training loss: 3.4455290918756476
Validation loss: 2.5778885022846287

Epoch: 5| Step: 8
Training loss: 2.6269927862073397
Validation loss: 2.5772931787733953

Epoch: 5| Step: 9
Training loss: 2.3868964545840705
Validation loss: 2.612573385878592

Epoch: 5| Step: 10
Training loss: 3.2134606316652157
Validation loss: 2.6469567807397665

Epoch: 107| Step: 0
Training loss: 3.486898423680482
Validation loss: 2.601674940295762

Epoch: 5| Step: 1
Training loss: 2.931729594284143
Validation loss: 2.548277631186668

Epoch: 5| Step: 2
Training loss: 2.915809905147128
Validation loss: 2.5311148944318695

Epoch: 5| Step: 3
Training loss: 2.597676809129169
Validation loss: 2.5327927103908134

Epoch: 5| Step: 4
Training loss: 2.803972243379789
Validation loss: 2.5270676276974977

Epoch: 5| Step: 5
Training loss: 2.4771166641734954
Validation loss: 2.5285237431760823

Epoch: 5| Step: 6
Training loss: 2.284342616069567
Validation loss: 2.526640876121931

Epoch: 5| Step: 7
Training loss: 3.3099571400428887
Validation loss: 2.5293539215887804

Epoch: 5| Step: 8
Training loss: 2.832141195333519
Validation loss: 2.5340355004709716

Epoch: 5| Step: 9
Training loss: 2.9970658576661253
Validation loss: 2.5420628875457147

Epoch: 5| Step: 10
Training loss: 2.9576328325793035
Validation loss: 2.554502250349909

Epoch: 108| Step: 0
Training loss: 2.8898900102850646
Validation loss: 2.560929356039969

Epoch: 5| Step: 1
Training loss: 3.277989684185859
Validation loss: 2.577943188771944

Epoch: 5| Step: 2
Training loss: 2.0761955310123383
Validation loss: 2.606299439959194

Epoch: 5| Step: 3
Training loss: 3.0859940535759387
Validation loss: 2.61201824535688

Epoch: 5| Step: 4
Training loss: 3.3650810574295664
Validation loss: 2.6120193038815933

Epoch: 5| Step: 5
Training loss: 2.9251949603975884
Validation loss: 2.589964813742193

Epoch: 5| Step: 6
Training loss: 2.8164716863768318
Validation loss: 2.5468639094462735

Epoch: 5| Step: 7
Training loss: 3.0739652924225664
Validation loss: 2.5423859241399698

Epoch: 5| Step: 8
Training loss: 2.1366728894544296
Validation loss: 2.530877079161902

Epoch: 5| Step: 9
Training loss: 3.258656490785576
Validation loss: 2.5328248711752552

Epoch: 5| Step: 10
Training loss: 2.5808049000631454
Validation loss: 2.535104998031578

Epoch: 109| Step: 0
Training loss: 3.331555814465287
Validation loss: 2.5361422345814693

Epoch: 5| Step: 1
Training loss: 2.691193903060656
Validation loss: 2.536406946294467

Epoch: 5| Step: 2
Training loss: 2.2195055037995477
Validation loss: 2.5348429538504806

Epoch: 5| Step: 3
Training loss: 2.904523275000063
Validation loss: 2.533012044221147

Epoch: 5| Step: 4
Training loss: 3.0599778357806366
Validation loss: 2.5343438639323344

Epoch: 5| Step: 5
Training loss: 2.657309466733174
Validation loss: 2.5270869279632704

Epoch: 5| Step: 6
Training loss: 2.6875778009553035
Validation loss: 2.5284672649115443

Epoch: 5| Step: 7
Training loss: 3.331271837459938
Validation loss: 2.5265347238813463

Epoch: 5| Step: 8
Training loss: 3.334457605227142
Validation loss: 2.531005072736079

Epoch: 5| Step: 9
Training loss: 2.671735347198972
Validation loss: 2.5396081996525646

Epoch: 5| Step: 10
Training loss: 2.749670182303724
Validation loss: 2.5494876357690615

Epoch: 110| Step: 0
Training loss: 2.7594163245695684
Validation loss: 2.5869514765718664

Epoch: 5| Step: 1
Training loss: 2.7287739963848137
Validation loss: 2.6497924989680146

Epoch: 5| Step: 2
Training loss: 2.9090774072528838
Validation loss: 2.713432761578185

Epoch: 5| Step: 3
Training loss: 3.186644495430701
Validation loss: 2.760534494260882

Epoch: 5| Step: 4
Training loss: 3.0054862402418685
Validation loss: 2.748696018984162

Epoch: 5| Step: 5
Training loss: 2.8703942932535726
Validation loss: 2.7186464340178564

Epoch: 5| Step: 6
Training loss: 2.9522739374891245
Validation loss: 2.695442239148393

Epoch: 5| Step: 7
Training loss: 3.509352314197184
Validation loss: 2.6857283920739925

Epoch: 5| Step: 8
Training loss: 2.831102184622263
Validation loss: 2.6023752764139485

Epoch: 5| Step: 9
Training loss: 2.2904825330200236
Validation loss: 2.547973395958771

Epoch: 5| Step: 10
Training loss: 3.1206280452775297
Validation loss: 2.542246157548824

Epoch: 111| Step: 0
Training loss: 2.8035628845390104
Validation loss: 2.539865075827388

Epoch: 5| Step: 1
Training loss: 2.629603209932444
Validation loss: 2.5429858901521123

Epoch: 5| Step: 2
Training loss: 2.7406229190970754
Validation loss: 2.545194401402114

Epoch: 5| Step: 3
Training loss: 2.8946567770731755
Validation loss: 2.5579925559730112

Epoch: 5| Step: 4
Training loss: 3.247854992124144
Validation loss: 2.5475794400970133

Epoch: 5| Step: 5
Training loss: 2.7985471702909104
Validation loss: 2.5322671009250226

Epoch: 5| Step: 6
Training loss: 2.452024857032574
Validation loss: 2.5288262216993544

Epoch: 5| Step: 7
Training loss: 3.0986117300043117
Validation loss: 2.5220951802587313

Epoch: 5| Step: 8
Training loss: 3.1027105786514295
Validation loss: 2.535208780119351

Epoch: 5| Step: 9
Training loss: 3.252548099194421
Validation loss: 2.5684778162562685

Epoch: 5| Step: 10
Training loss: 2.979235952856532
Validation loss: 2.616489619665149

Epoch: 112| Step: 0
Training loss: 2.448645809151568
Validation loss: 2.619383984974447

Epoch: 5| Step: 1
Training loss: 2.858230445129612
Validation loss: 2.5974505806694377

Epoch: 5| Step: 2
Training loss: 3.085646835351883
Validation loss: 2.5931505987559653

Epoch: 5| Step: 3
Training loss: 3.0046223951279947
Validation loss: 2.578803924233268

Epoch: 5| Step: 4
Training loss: 2.4314502074665563
Validation loss: 2.572883253680599

Epoch: 5| Step: 5
Training loss: 2.8265624392685007
Validation loss: 2.561639787948442

Epoch: 5| Step: 6
Training loss: 2.596965038147952
Validation loss: 2.5580721029927327

Epoch: 5| Step: 7
Training loss: 2.922276270438687
Validation loss: 2.5377931684231783

Epoch: 5| Step: 8
Training loss: 3.4799718020381945
Validation loss: 2.537528063844572

Epoch: 5| Step: 9
Training loss: 3.1266440072556887
Validation loss: 2.5323263148948163

Epoch: 5| Step: 10
Training loss: 2.567746165359898
Validation loss: 2.5172153521696603

Epoch: 113| Step: 0
Training loss: 3.3864064496111173
Validation loss: 2.517107559879686

Epoch: 5| Step: 1
Training loss: 2.6437411910106454
Validation loss: 2.5147112531628726

Epoch: 5| Step: 2
Training loss: 2.7928922629386927
Validation loss: 2.516292208642305

Epoch: 5| Step: 3
Training loss: 2.997026559380453
Validation loss: 2.521311532975796

Epoch: 5| Step: 4
Training loss: 2.763820684625527
Validation loss: 2.5226550481459293

Epoch: 5| Step: 5
Training loss: 2.6317957151379097
Validation loss: 2.527621138350629

Epoch: 5| Step: 6
Training loss: 3.221306239485747
Validation loss: 2.5338669494893966

Epoch: 5| Step: 7
Training loss: 2.4239463562144223
Validation loss: 2.5343037825773127

Epoch: 5| Step: 8
Training loss: 3.038469977585347
Validation loss: 2.524621559032137

Epoch: 5| Step: 9
Training loss: 2.8619175014268223
Validation loss: 2.539230966587578

Epoch: 5| Step: 10
Training loss: 2.6876293417390467
Validation loss: 2.539212535025456

Epoch: 114| Step: 0
Training loss: 3.1873180861080135
Validation loss: 2.540093668637392

Epoch: 5| Step: 1
Training loss: 2.7105578065952196
Validation loss: 2.5379399097174202

Epoch: 5| Step: 2
Training loss: 2.4849709809602607
Validation loss: 2.5527014497175675

Epoch: 5| Step: 3
Training loss: 2.320714125890491
Validation loss: 2.540981298829934

Epoch: 5| Step: 4
Training loss: 3.4599734787117478
Validation loss: 2.558131725807254

Epoch: 5| Step: 5
Training loss: 3.017542570330587
Validation loss: 2.5661241937615964

Epoch: 5| Step: 6
Training loss: 3.0791686172031802
Validation loss: 2.5561875839429855

Epoch: 5| Step: 7
Training loss: 3.124519005951906
Validation loss: 2.52588487871584

Epoch: 5| Step: 8
Training loss: 2.2893204787768617
Validation loss: 2.514792286475695

Epoch: 5| Step: 9
Training loss: 3.064177695856137
Validation loss: 2.5104728436804233

Epoch: 5| Step: 10
Training loss: 2.6403167364100266
Validation loss: 2.5075460067531465

Epoch: 115| Step: 0
Training loss: 2.5515747705411
Validation loss: 2.5144353382309297

Epoch: 5| Step: 1
Training loss: 3.008338466086901
Validation loss: 2.5088819686331973

Epoch: 5| Step: 2
Training loss: 3.245474672558658
Validation loss: 2.5086793977714152

Epoch: 5| Step: 3
Training loss: 2.6377737689646157
Validation loss: 2.5069031928500096

Epoch: 5| Step: 4
Training loss: 2.863666919583763
Validation loss: 2.5075428414926106

Epoch: 5| Step: 5
Training loss: 2.970566685620072
Validation loss: 2.5074854622737224

Epoch: 5| Step: 6
Training loss: 3.2463778338198703
Validation loss: 2.5092997227094367

Epoch: 5| Step: 7
Training loss: 3.214493242255207
Validation loss: 2.513790435153323

Epoch: 5| Step: 8
Training loss: 2.575304002316174
Validation loss: 2.517019536643866

Epoch: 5| Step: 9
Training loss: 2.545147268834586
Validation loss: 2.518444481981173

Epoch: 5| Step: 10
Training loss: 2.542668150496121
Validation loss: 2.538612988029843

Epoch: 116| Step: 0
Training loss: 2.8970942507901647
Validation loss: 2.552543455680436

Epoch: 5| Step: 1
Training loss: 2.853118054150653
Validation loss: 2.561365149890629

Epoch: 5| Step: 2
Training loss: 2.7973318739100246
Validation loss: 2.5928098445179595

Epoch: 5| Step: 3
Training loss: 2.6241630854924916
Validation loss: 2.5875964834692757

Epoch: 5| Step: 4
Training loss: 3.1911854101414123
Validation loss: 2.5651868354731358

Epoch: 5| Step: 5
Training loss: 2.696150497418537
Validation loss: 2.568035659405791

Epoch: 5| Step: 6
Training loss: 2.9542658786945775
Validation loss: 2.56737019888122

Epoch: 5| Step: 7
Training loss: 2.6720084887615294
Validation loss: 2.543430668056391

Epoch: 5| Step: 8
Training loss: 2.95825943832162
Validation loss: 2.523513543388255

Epoch: 5| Step: 9
Training loss: 2.9394923819014798
Validation loss: 2.514655282297684

Epoch: 5| Step: 10
Training loss: 2.8968827429609303
Validation loss: 2.50584037468623

Epoch: 117| Step: 0
Training loss: 2.2714704150675393
Validation loss: 2.509510183153225

Epoch: 5| Step: 1
Training loss: 3.1674367737876605
Validation loss: 2.4975651143200954

Epoch: 5| Step: 2
Training loss: 3.08554159594513
Validation loss: 2.5035403420083293

Epoch: 5| Step: 3
Training loss: 3.030715423323815
Validation loss: 2.5107804864793497

Epoch: 5| Step: 4
Training loss: 2.8970489877674512
Validation loss: 2.531579587021897

Epoch: 5| Step: 5
Training loss: 2.9748661684339304
Validation loss: 2.550130756555749

Epoch: 5| Step: 6
Training loss: 2.816793597670053
Validation loss: 2.5714673115108284

Epoch: 5| Step: 7
Training loss: 2.850010614208065
Validation loss: 2.5763357208750666

Epoch: 5| Step: 8
Training loss: 2.6780214162800653
Validation loss: 2.5358115209132728

Epoch: 5| Step: 9
Training loss: 3.1302609219737945
Validation loss: 2.515524869656088

Epoch: 5| Step: 10
Training loss: 2.482251777493842
Validation loss: 2.5065296853258023

Epoch: 118| Step: 0
Training loss: 2.499105579595934
Validation loss: 2.498833597506981

Epoch: 5| Step: 1
Training loss: 3.098431522673335
Validation loss: 2.503175178346376

Epoch: 5| Step: 2
Training loss: 2.883080115987101
Validation loss: 2.5046272421708866

Epoch: 5| Step: 3
Training loss: 3.0885332610266274
Validation loss: 2.506026332578893

Epoch: 5| Step: 4
Training loss: 3.117841226583639
Validation loss: 2.5053524616901806

Epoch: 5| Step: 5
Training loss: 2.1521221953800986
Validation loss: 2.50657895647981

Epoch: 5| Step: 6
Training loss: 2.4632655197981825
Validation loss: 2.5065376037137495

Epoch: 5| Step: 7
Training loss: 3.1803709603111443
Validation loss: 2.5059273481283526

Epoch: 5| Step: 8
Training loss: 3.0739789430570923
Validation loss: 2.4994347758862347

Epoch: 5| Step: 9
Training loss: 2.9119051804772647
Validation loss: 2.5004793558678853

Epoch: 5| Step: 10
Training loss: 2.9619963270083467
Validation loss: 2.513888094282919

Epoch: 119| Step: 0
Training loss: 2.4214011436320435
Validation loss: 2.5429799512970535

Epoch: 5| Step: 1
Training loss: 2.8011773120687455
Validation loss: 2.55661797104337

Epoch: 5| Step: 2
Training loss: 3.4554525272782906
Validation loss: 2.5685220554023562

Epoch: 5| Step: 3
Training loss: 2.9966507335517907
Validation loss: 2.5587912501991874

Epoch: 5| Step: 4
Training loss: 2.7318632087810872
Validation loss: 2.542531981919683

Epoch: 5| Step: 5
Training loss: 2.9961876487689723
Validation loss: 2.5282609316987648

Epoch: 5| Step: 6
Training loss: 2.263220517413872
Validation loss: 2.525429067277943

Epoch: 5| Step: 7
Training loss: 3.0080605937150646
Validation loss: 2.516570365897961

Epoch: 5| Step: 8
Training loss: 3.037335137810756
Validation loss: 2.527131607639748

Epoch: 5| Step: 9
Training loss: 2.6658712830087654
Validation loss: 2.516626688400564

Epoch: 5| Step: 10
Training loss: 2.9120509182072922
Validation loss: 2.5222617659756783

Epoch: 120| Step: 0
Training loss: 2.7770823424085456
Validation loss: 2.517682381113918

Epoch: 5| Step: 1
Training loss: 2.869719424206735
Validation loss: 2.513996614027382

Epoch: 5| Step: 2
Training loss: 3.061771383998736
Validation loss: 2.5186869806855743

Epoch: 5| Step: 3
Training loss: 2.969662174830192
Validation loss: 2.510961771006677

Epoch: 5| Step: 4
Training loss: 2.814473964129564
Validation loss: 2.5085943071225607

Epoch: 5| Step: 5
Training loss: 2.479115995856314
Validation loss: 2.517646555621835

Epoch: 5| Step: 6
Training loss: 2.7762059967662185
Validation loss: 2.511374601803689

Epoch: 5| Step: 7
Training loss: 3.4019717725942877
Validation loss: 2.5107426674023134

Epoch: 5| Step: 8
Training loss: 2.5149511536543474
Validation loss: 2.5049971484947733

Epoch: 5| Step: 9
Training loss: 2.883434362975155
Validation loss: 2.5007114608085805

Epoch: 5| Step: 10
Training loss: 2.6797675740814975
Validation loss: 2.5039493447721823

Epoch: 121| Step: 0
Training loss: 2.6941188657063613
Validation loss: 2.506313090020925

Epoch: 5| Step: 1
Training loss: 2.7908525465991807
Validation loss: 2.5124637707876794

Epoch: 5| Step: 2
Training loss: 2.952399916668529
Validation loss: 2.5048655221524605

Epoch: 5| Step: 3
Training loss: 3.0447051317984157
Validation loss: 2.513029199852274

Epoch: 5| Step: 4
Training loss: 2.918466303432339
Validation loss: 2.514622259086385

Epoch: 5| Step: 5
Training loss: 2.589315461236868
Validation loss: 2.5134959739197296

Epoch: 5| Step: 6
Training loss: 2.73497255607937
Validation loss: 2.5136915708220693

Epoch: 5| Step: 7
Training loss: 3.141586687872775
Validation loss: 2.517729233608048

Epoch: 5| Step: 8
Training loss: 2.840405016481595
Validation loss: 2.504893681593095

Epoch: 5| Step: 9
Training loss: 3.3087044329184288
Validation loss: 2.5094202108377375

Epoch: 5| Step: 10
Training loss: 1.830002366882628
Validation loss: 2.508069580525927

Epoch: 122| Step: 0
Training loss: 2.618565711772637
Validation loss: 2.5050653916542656

Epoch: 5| Step: 1
Training loss: 2.559372179265034
Validation loss: 2.5094307946613874

Epoch: 5| Step: 2
Training loss: 2.7025174025858365
Validation loss: 2.518236105910034

Epoch: 5| Step: 3
Training loss: 2.7456681205199494
Validation loss: 2.5114382720862074

Epoch: 5| Step: 4
Training loss: 2.9781243339289656
Validation loss: 2.5154908010113397

Epoch: 5| Step: 5
Training loss: 3.0979477888304277
Validation loss: 2.5187426960538284

Epoch: 5| Step: 6
Training loss: 2.850181935175127
Validation loss: 2.5269485136440886

Epoch: 5| Step: 7
Training loss: 3.016218532203658
Validation loss: 2.5532325509403937

Epoch: 5| Step: 8
Training loss: 2.948377557497957
Validation loss: 2.535844344008029

Epoch: 5| Step: 9
Training loss: 2.7104373877337045
Validation loss: 2.5126005914287526

Epoch: 5| Step: 10
Training loss: 2.9811505379069816
Validation loss: 2.502894225459135

Epoch: 123| Step: 0
Training loss: 2.965416251132456
Validation loss: 2.4966890734796814

Epoch: 5| Step: 1
Training loss: 2.9442135002527925
Validation loss: 2.4983406784718127

Epoch: 5| Step: 2
Training loss: 2.798214213517079
Validation loss: 2.4978372437675223

Epoch: 5| Step: 3
Training loss: 2.9253196606845377
Validation loss: 2.5006598534947138

Epoch: 5| Step: 4
Training loss: 2.177266406768469
Validation loss: 2.5012930592166076

Epoch: 5| Step: 5
Training loss: 2.847854167826375
Validation loss: 2.499244360397351

Epoch: 5| Step: 6
Training loss: 2.7760736536374395
Validation loss: 2.498573351460022

Epoch: 5| Step: 7
Training loss: 2.990214122900475
Validation loss: 2.5154220640853393

Epoch: 5| Step: 8
Training loss: 3.1216608136297515
Validation loss: 2.520762887402775

Epoch: 5| Step: 9
Training loss: 2.452784617918372
Validation loss: 2.554396020480672

Epoch: 5| Step: 10
Training loss: 3.3153734519807316
Validation loss: 2.576142074493578

Epoch: 124| Step: 0
Training loss: 2.74171404541572
Validation loss: 2.59516590353834

Epoch: 5| Step: 1
Training loss: 2.276803163520347
Validation loss: 2.6035397338957167

Epoch: 5| Step: 2
Training loss: 2.979770163563145
Validation loss: 2.5752022641585044

Epoch: 5| Step: 3
Training loss: 2.7080898664543023
Validation loss: 2.5787379665081165

Epoch: 5| Step: 4
Training loss: 3.165278749650381
Validation loss: 2.5502213966085603

Epoch: 5| Step: 5
Training loss: 2.7180492331092823
Validation loss: 2.506304378194247

Epoch: 5| Step: 6
Training loss: 3.4443045112597375
Validation loss: 2.496983568543105

Epoch: 5| Step: 7
Training loss: 2.850461815343258
Validation loss: 2.497286547374105

Epoch: 5| Step: 8
Training loss: 2.789293124710826
Validation loss: 2.499321409645153

Epoch: 5| Step: 9
Training loss: 2.8594630493615516
Validation loss: 2.5061860142317167

Epoch: 5| Step: 10
Training loss: 2.777238073900456
Validation loss: 2.4999412468189846

Epoch: 125| Step: 0
Training loss: 2.843811202176665
Validation loss: 2.502462547343002

Epoch: 5| Step: 1
Training loss: 2.5626402095490137
Validation loss: 2.4994220003948118

Epoch: 5| Step: 2
Training loss: 2.4508235364724835
Validation loss: 2.496323407742883

Epoch: 5| Step: 3
Training loss: 2.8685038608513738
Validation loss: 2.4950557228777472

Epoch: 5| Step: 4
Training loss: 3.0625175942674607
Validation loss: 2.5088141593485247

Epoch: 5| Step: 5
Training loss: 2.811303710831491
Validation loss: 2.5224180776855567

Epoch: 5| Step: 6
Training loss: 3.098482154143525
Validation loss: 2.54718581179837

Epoch: 5| Step: 7
Training loss: 3.0987188337512217
Validation loss: 2.5498907525477112

Epoch: 5| Step: 8
Training loss: 2.7992374948677257
Validation loss: 2.571911435152078

Epoch: 5| Step: 9
Training loss: 2.792228120360002
Validation loss: 2.5904427040886433

Epoch: 5| Step: 10
Training loss: 2.8014768962898047
Validation loss: 2.5953259533980195

Epoch: 126| Step: 0
Training loss: 3.1448143493973206
Validation loss: 2.592409334254983

Epoch: 5| Step: 1
Training loss: 3.330763939185589
Validation loss: 2.577458747697646

Epoch: 5| Step: 2
Training loss: 2.544708079025666
Validation loss: 2.5636800894467417

Epoch: 5| Step: 3
Training loss: 2.7768398852621243
Validation loss: 2.5602578499167965

Epoch: 5| Step: 4
Training loss: 2.5248984250326147
Validation loss: 2.5592168779847784

Epoch: 5| Step: 5
Training loss: 3.3297914443133028
Validation loss: 2.5369840661087637

Epoch: 5| Step: 6
Training loss: 2.6672706416735887
Validation loss: 2.5317211981077263

Epoch: 5| Step: 7
Training loss: 2.6935776586786058
Validation loss: 2.5112675980392476

Epoch: 5| Step: 8
Training loss: 2.2436217927564988
Validation loss: 2.5084441475072334

Epoch: 5| Step: 9
Training loss: 2.59363482116137
Validation loss: 2.4994025613780093

Epoch: 5| Step: 10
Training loss: 3.2250655352417263
Validation loss: 2.4950615281800523

Epoch: 127| Step: 0
Training loss: 2.4711065513334733
Validation loss: 2.496472197411089

Epoch: 5| Step: 1
Training loss: 2.336309907246154
Validation loss: 2.5014024266937946

Epoch: 5| Step: 2
Training loss: 2.9182552008097615
Validation loss: 2.4992390038400023

Epoch: 5| Step: 3
Training loss: 2.636109141769004
Validation loss: 2.5002956113063144

Epoch: 5| Step: 4
Training loss: 3.391682683983425
Validation loss: 2.4954134460652755

Epoch: 5| Step: 5
Training loss: 3.125231009527942
Validation loss: 2.4952503113044417

Epoch: 5| Step: 6
Training loss: 2.7130177017011246
Validation loss: 2.5000727971050583

Epoch: 5| Step: 7
Training loss: 2.882760892576686
Validation loss: 2.504650805475023

Epoch: 5| Step: 8
Training loss: 2.7870198952546805
Validation loss: 2.523484522985461

Epoch: 5| Step: 9
Training loss: 2.7405733318960834
Validation loss: 2.538337248280169

Epoch: 5| Step: 10
Training loss: 2.996191945760866
Validation loss: 2.564192292396204

Epoch: 128| Step: 0
Training loss: 3.0884088205690565
Validation loss: 2.568475201189149

Epoch: 5| Step: 1
Training loss: 2.890556045946998
Validation loss: 2.604654568815016

Epoch: 5| Step: 2
Training loss: 2.6524300427788736
Validation loss: 2.597999676252878

Epoch: 5| Step: 3
Training loss: 2.7042830968712726
Validation loss: 2.575055520749108

Epoch: 5| Step: 4
Training loss: 2.7870769538945157
Validation loss: 2.522774328334305

Epoch: 5| Step: 5
Training loss: 2.6865019608488154
Validation loss: 2.5164025084196635

Epoch: 5| Step: 6
Training loss: 2.762801199670832
Validation loss: 2.5057561114896205

Epoch: 5| Step: 7
Training loss: 3.150275893466484
Validation loss: 2.50195187287037

Epoch: 5| Step: 8
Training loss: 3.081033175192332
Validation loss: 2.495865917950083

Epoch: 5| Step: 9
Training loss: 2.8907690063896876
Validation loss: 2.4939668870978227

Epoch: 5| Step: 10
Training loss: 2.37747324610598
Validation loss: 2.4932798222155075

Epoch: 129| Step: 0
Training loss: 3.1200771466523087
Validation loss: 2.507516686023062

Epoch: 5| Step: 1
Training loss: 2.4861739261394455
Validation loss: 2.4999917676236367

Epoch: 5| Step: 2
Training loss: 3.1803015413608082
Validation loss: 2.497551801150612

Epoch: 5| Step: 3
Training loss: 2.5712694050710807
Validation loss: 2.498400792977976

Epoch: 5| Step: 4
Training loss: 2.911131665915155
Validation loss: 2.503658578131152

Epoch: 5| Step: 5
Training loss: 3.0117203332721196
Validation loss: 2.5027241918103917

Epoch: 5| Step: 6
Training loss: 2.981416044269622
Validation loss: 2.505997792009929

Epoch: 5| Step: 7
Training loss: 2.894941581439724
Validation loss: 2.5249485906539197

Epoch: 5| Step: 8
Training loss: 2.9768649370630884
Validation loss: 2.5245425198225777

Epoch: 5| Step: 9
Training loss: 2.062856238840114
Validation loss: 2.529178506546728

Epoch: 5| Step: 10
Training loss: 2.7376975663192105
Validation loss: 2.532062450265724

Epoch: 130| Step: 0
Training loss: 3.0411670919046507
Validation loss: 2.517107759503076

Epoch: 5| Step: 1
Training loss: 2.410017259939602
Validation loss: 2.5198716950100164

Epoch: 5| Step: 2
Training loss: 2.93580513615692
Validation loss: 2.515622625526261

Epoch: 5| Step: 3
Training loss: 2.52115785595862
Validation loss: 2.526741867694203

Epoch: 5| Step: 4
Training loss: 2.9344952413442704
Validation loss: 2.51566838623413

Epoch: 5| Step: 5
Training loss: 2.590025836418044
Validation loss: 2.5260631124391453

Epoch: 5| Step: 6
Training loss: 2.4945135950454747
Validation loss: 2.517151381926545

Epoch: 5| Step: 7
Training loss: 2.9806498501254275
Validation loss: 2.5089108462894387

Epoch: 5| Step: 8
Training loss: 2.9809003644926184
Validation loss: 2.507774894799654

Epoch: 5| Step: 9
Training loss: 3.0444063015642158
Validation loss: 2.50393359500951

Epoch: 5| Step: 10
Training loss: 2.838878609260649
Validation loss: 2.504730937064919

Epoch: 131| Step: 0
Training loss: 2.547271604023471
Validation loss: 2.493902462375244

Epoch: 5| Step: 1
Training loss: 2.631316985593776
Validation loss: 2.4954350519810733

Epoch: 5| Step: 2
Training loss: 3.0974170260519274
Validation loss: 2.4883625413061674

Epoch: 5| Step: 3
Training loss: 2.390110932971861
Validation loss: 2.487798170132407

Epoch: 5| Step: 4
Training loss: 3.2165749617501698
Validation loss: 2.488430163041847

Epoch: 5| Step: 5
Training loss: 2.840358178561206
Validation loss: 2.4866999368845555

Epoch: 5| Step: 6
Training loss: 2.785734183551304
Validation loss: 2.4928437107535553

Epoch: 5| Step: 7
Training loss: 2.994792551234018
Validation loss: 2.5001218653273862

Epoch: 5| Step: 8
Training loss: 2.5172881321175966
Validation loss: 2.5124550058010047

Epoch: 5| Step: 9
Training loss: 2.6729992737546104
Validation loss: 2.5269307427362713

Epoch: 5| Step: 10
Training loss: 3.229085679217953
Validation loss: 2.531540759144017

Epoch: 132| Step: 0
Training loss: 2.719954475975544
Validation loss: 2.5395689938240573

Epoch: 5| Step: 1
Training loss: 2.7534017330691527
Validation loss: 2.534601271612961

Epoch: 5| Step: 2
Training loss: 3.203589875517017
Validation loss: 2.525521945970677

Epoch: 5| Step: 3
Training loss: 2.6048051483733734
Validation loss: 2.5198840936617506

Epoch: 5| Step: 4
Training loss: 2.4535569703581803
Validation loss: 2.5011987796089823

Epoch: 5| Step: 5
Training loss: 2.810910602332746
Validation loss: 2.5025087658740075

Epoch: 5| Step: 6
Training loss: 3.113747287842478
Validation loss: 2.5132076608200986

Epoch: 5| Step: 7
Training loss: 2.923678407677314
Validation loss: 2.5311668784428436

Epoch: 5| Step: 8
Training loss: 2.67778379031606
Validation loss: 2.5345260625876094

Epoch: 5| Step: 9
Training loss: 2.6656068146097605
Validation loss: 2.562793661839076

Epoch: 5| Step: 10
Training loss: 3.0151578709404814
Validation loss: 2.5562091726149716

Epoch: 133| Step: 0
Training loss: 2.624726326618136
Validation loss: 2.5518934817556054

Epoch: 5| Step: 1
Training loss: 2.729138662956554
Validation loss: 2.5507183175543897

Epoch: 5| Step: 2
Training loss: 2.8191409226911994
Validation loss: 2.5358106494531545

Epoch: 5| Step: 3
Training loss: 2.759072164677811
Validation loss: 2.5269360370422906

Epoch: 5| Step: 4
Training loss: 2.431908282520598
Validation loss: 2.5390046032787907

Epoch: 5| Step: 5
Training loss: 3.0857630426853953
Validation loss: 2.5385515939322993

Epoch: 5| Step: 6
Training loss: 2.79896578080881
Validation loss: 2.537522958841263

Epoch: 5| Step: 7
Training loss: 3.167255815278277
Validation loss: 2.555814590437001

Epoch: 5| Step: 8
Training loss: 2.8183307818087853
Validation loss: 2.546879786296841

Epoch: 5| Step: 9
Training loss: 2.8395467023009746
Validation loss: 2.500469402627214

Epoch: 5| Step: 10
Training loss: 2.8961327121316964
Validation loss: 2.5050567420085788

Epoch: 134| Step: 0
Training loss: 2.9258669750250084
Validation loss: 2.4956485707499194

Epoch: 5| Step: 1
Training loss: 2.7783920520175616
Validation loss: 2.4907927247606336

Epoch: 5| Step: 2
Training loss: 2.395193584001111
Validation loss: 2.5128849846979797

Epoch: 5| Step: 3
Training loss: 3.143487185950091
Validation loss: 2.5721547037784154

Epoch: 5| Step: 4
Training loss: 2.3717818290896413
Validation loss: 2.5349151134119103

Epoch: 5| Step: 5
Training loss: 3.01066521451232
Validation loss: 2.5273479220661192

Epoch: 5| Step: 6
Training loss: 2.7620745784405742
Validation loss: 2.5131688184020975

Epoch: 5| Step: 7
Training loss: 2.7717732338787
Validation loss: 2.5077433087966448

Epoch: 5| Step: 8
Training loss: 2.98211776292096
Validation loss: 2.506138067226729

Epoch: 5| Step: 9
Training loss: 3.1007798598313525
Validation loss: 2.5049070580864314

Epoch: 5| Step: 10
Training loss: 2.682802575103584
Validation loss: 2.5030892819746753

Epoch: 135| Step: 0
Training loss: 2.6993878059056953
Validation loss: 2.5253708742387686

Epoch: 5| Step: 1
Training loss: 2.706080854737476
Validation loss: 2.5261487127283515

Epoch: 5| Step: 2
Training loss: 2.8354306779599816
Validation loss: 2.557253122253306

Epoch: 5| Step: 3
Training loss: 2.4521177131189478
Validation loss: 2.5421059829101953

Epoch: 5| Step: 4
Training loss: 3.032866685905046
Validation loss: 2.5377648537893753

Epoch: 5| Step: 5
Training loss: 2.8878269159117984
Validation loss: 2.523734092013572

Epoch: 5| Step: 6
Training loss: 2.864392656858269
Validation loss: 2.514987054238335

Epoch: 5| Step: 7
Training loss: 2.822799980501529
Validation loss: 2.503083738024554

Epoch: 5| Step: 8
Training loss: 2.8808866855167348
Validation loss: 2.4989511648307126

Epoch: 5| Step: 9
Training loss: 2.6235700981614807
Validation loss: 2.497263136324703

Epoch: 5| Step: 10
Training loss: 3.1064758587090595
Validation loss: 2.508067533144814

Epoch: 136| Step: 0
Training loss: 2.8400600093895187
Validation loss: 2.4867455576621538

Epoch: 5| Step: 1
Training loss: 2.7456350363954556
Validation loss: 2.485742192904212

Epoch: 5| Step: 2
Training loss: 2.803208920382542
Validation loss: 2.4947756765197706

Epoch: 5| Step: 3
Training loss: 3.055718991696288
Validation loss: 2.501512743511993

Epoch: 5| Step: 4
Training loss: 2.558531409516058
Validation loss: 2.5104452267799386

Epoch: 5| Step: 5
Training loss: 3.029758833802357
Validation loss: 2.516671602678528

Epoch: 5| Step: 6
Training loss: 2.7140681853643858
Validation loss: 2.5220433975636767

Epoch: 5| Step: 7
Training loss: 3.0282349683636847
Validation loss: 2.529752429349131

Epoch: 5| Step: 8
Training loss: 2.438706612878037
Validation loss: 2.515682969074764

Epoch: 5| Step: 9
Training loss: 2.581350539791806
Validation loss: 2.505494564162373

Epoch: 5| Step: 10
Training loss: 2.90331407142787
Validation loss: 2.499912450139302

Epoch: 137| Step: 0
Training loss: 2.2713355346092765
Validation loss: 2.4917048718831656

Epoch: 5| Step: 1
Training loss: 2.7258472980206476
Validation loss: 2.501213889594003

Epoch: 5| Step: 2
Training loss: 2.857362800034414
Validation loss: 2.489392560611593

Epoch: 5| Step: 3
Training loss: 3.027985378073861
Validation loss: 2.490053408901983

Epoch: 5| Step: 4
Training loss: 2.897603945904156
Validation loss: 2.4878041345769466

Epoch: 5| Step: 5
Training loss: 2.5738099950214686
Validation loss: 2.482746220066184

Epoch: 5| Step: 6
Training loss: 2.692923639914009
Validation loss: 2.4833903741021937

Epoch: 5| Step: 7
Training loss: 2.9211901509818494
Validation loss: 2.4882344014370688

Epoch: 5| Step: 8
Training loss: 2.7214461364293667
Validation loss: 2.4944424558319884

Epoch: 5| Step: 9
Training loss: 3.1311782798243772
Validation loss: 2.507403490413571

Epoch: 5| Step: 10
Training loss: 2.9270306963729924
Validation loss: 2.5196370379799364

Epoch: 138| Step: 0
Training loss: 2.2565046172040906
Validation loss: 2.525404531449174

Epoch: 5| Step: 1
Training loss: 2.668725996780549
Validation loss: 2.5337540467703152

Epoch: 5| Step: 2
Training loss: 2.943623916290782
Validation loss: 2.5480843939002593

Epoch: 5| Step: 3
Training loss: 3.184582890097057
Validation loss: 2.5533565845018282

Epoch: 5| Step: 4
Training loss: 2.838021345599968
Validation loss: 2.525901844521885

Epoch: 5| Step: 5
Training loss: 2.832882583517119
Validation loss: 2.4884920895549003

Epoch: 5| Step: 6
Training loss: 2.616172297563666
Validation loss: 2.481468541150647

Epoch: 5| Step: 7
Training loss: 2.739959159184721
Validation loss: 2.4745063427805003

Epoch: 5| Step: 8
Training loss: 2.9298442340887254
Validation loss: 2.47937873194616

Epoch: 5| Step: 9
Training loss: 3.2035492406745925
Validation loss: 2.4864405097588786

Epoch: 5| Step: 10
Training loss: 2.588276799017075
Validation loss: 2.4861343984070254

Epoch: 139| Step: 0
Training loss: 2.7887659422770574
Validation loss: 2.4970114493178555

Epoch: 5| Step: 1
Training loss: 2.6528463659912034
Validation loss: 2.4913734363774083

Epoch: 5| Step: 2
Training loss: 2.9737503504582534
Validation loss: 2.4806277949425133

Epoch: 5| Step: 3
Training loss: 2.417810881704001
Validation loss: 2.4787050570422133

Epoch: 5| Step: 4
Training loss: 2.6553886363331154
Validation loss: 2.487127630261467

Epoch: 5| Step: 5
Training loss: 2.634208874877688
Validation loss: 2.5096810165539454

Epoch: 5| Step: 6
Training loss: 3.050063592216553
Validation loss: 2.5328911479865956

Epoch: 5| Step: 7
Training loss: 2.668764590507128
Validation loss: 2.55242401186385

Epoch: 5| Step: 8
Training loss: 3.231584017403175
Validation loss: 2.5811524773772163

Epoch: 5| Step: 9
Training loss: 2.9775212863830642
Validation loss: 2.596064943341507

Epoch: 5| Step: 10
Training loss: 2.8796539784890194
Validation loss: 2.579407854005366

Epoch: 140| Step: 0
Training loss: 2.760768527271987
Validation loss: 2.526201136868362

Epoch: 5| Step: 1
Training loss: 2.5665987311285843
Validation loss: 2.4987467988278262

Epoch: 5| Step: 2
Training loss: 2.9555550724242665
Validation loss: 2.4860458461891723

Epoch: 5| Step: 3
Training loss: 2.649983452799255
Validation loss: 2.485525597309535

Epoch: 5| Step: 4
Training loss: 2.4802751600759825
Validation loss: 2.4844156598461784

Epoch: 5| Step: 5
Training loss: 2.7831779398531555
Validation loss: 2.4940225667353153

Epoch: 5| Step: 6
Training loss: 3.0126668226975446
Validation loss: 2.5094832983481927

Epoch: 5| Step: 7
Training loss: 2.779025785048574
Validation loss: 2.506705021340054

Epoch: 5| Step: 8
Training loss: 2.72807685311426
Validation loss: 2.511653905880031

Epoch: 5| Step: 9
Training loss: 3.2300921846822592
Validation loss: 2.5039430281903856

Epoch: 5| Step: 10
Training loss: 2.7822353889108413
Validation loss: 2.507289836737396

Epoch: 141| Step: 0
Training loss: 2.9514358776066985
Validation loss: 2.5171875556483467

Epoch: 5| Step: 1
Training loss: 3.1320215306425023
Validation loss: 2.526085937910428

Epoch: 5| Step: 2
Training loss: 2.9037808009142667
Validation loss: 2.528859361526256

Epoch: 5| Step: 3
Training loss: 2.8231883932904673
Validation loss: 2.5397830921888334

Epoch: 5| Step: 4
Training loss: 2.352202977757612
Validation loss: 2.5294206055682404

Epoch: 5| Step: 5
Training loss: 2.7498260789840225
Validation loss: 2.5376612095745426

Epoch: 5| Step: 6
Training loss: 2.6731342226145394
Validation loss: 2.5427237567938876

Epoch: 5| Step: 7
Training loss: 2.440342444012535
Validation loss: 2.527877091753334

Epoch: 5| Step: 8
Training loss: 2.997309431901619
Validation loss: 2.525875211829529

Epoch: 5| Step: 9
Training loss: 2.924735071949059
Validation loss: 2.532474076512997

Epoch: 5| Step: 10
Training loss: 2.5710660531317844
Validation loss: 2.514693172003965

Epoch: 142| Step: 0
Training loss: 2.757709447215872
Validation loss: 2.511214420106958

Epoch: 5| Step: 1
Training loss: 2.7121152051126485
Validation loss: 2.5176398197655043

Epoch: 5| Step: 2
Training loss: 2.8978757905214017
Validation loss: 2.5110333692402342

Epoch: 5| Step: 3
Training loss: 2.8644664023838264
Validation loss: 2.5173121171727897

Epoch: 5| Step: 4
Training loss: 3.0699582271654005
Validation loss: 2.505761041295117

Epoch: 5| Step: 5
Training loss: 2.67567485959798
Validation loss: 2.4961968052311816

Epoch: 5| Step: 6
Training loss: 3.0038775180985313
Validation loss: 2.495389604447954

Epoch: 5| Step: 7
Training loss: 2.4454499714877254
Validation loss: 2.494114455411826

Epoch: 5| Step: 8
Training loss: 2.7040257358906343
Validation loss: 2.499465477108279

Epoch: 5| Step: 9
Training loss: 2.6795344628767404
Validation loss: 2.5035746644102357

Epoch: 5| Step: 10
Training loss: 2.6884875590040274
Validation loss: 2.4931749055616828

Epoch: 143| Step: 0
Training loss: 2.8812536144440792
Validation loss: 2.486945602086555

Epoch: 5| Step: 1
Training loss: 3.0832149036104672
Validation loss: 2.488183651180379

Epoch: 5| Step: 2
Training loss: 2.945788438626658
Validation loss: 2.4776025210108195

Epoch: 5| Step: 3
Training loss: 2.5953249458506047
Validation loss: 2.47775036761428

Epoch: 5| Step: 4
Training loss: 3.1278017835522096
Validation loss: 2.490950734875668

Epoch: 5| Step: 5
Training loss: 2.6456082966739296
Validation loss: 2.4992054137990873

Epoch: 5| Step: 6
Training loss: 2.6428981229189787
Validation loss: 2.5002343047488855

Epoch: 5| Step: 7
Training loss: 2.3865842890597055
Validation loss: 2.5089619916542234

Epoch: 5| Step: 8
Training loss: 2.4162041013160103
Validation loss: 2.505632734794482

Epoch: 5| Step: 9
Training loss: 2.930349371849895
Validation loss: 2.5259069628627477

Epoch: 5| Step: 10
Training loss: 2.923443052204024
Validation loss: 2.5243545847336017

Epoch: 144| Step: 0
Training loss: 2.9285168559608756
Validation loss: 2.5197705562771984

Epoch: 5| Step: 1
Training loss: 2.661831097461361
Validation loss: 2.5192860402529043

Epoch: 5| Step: 2
Training loss: 2.6741172795793884
Validation loss: 2.4911553298316966

Epoch: 5| Step: 3
Training loss: 2.487508273470361
Validation loss: 2.4939631721310342

Epoch: 5| Step: 4
Training loss: 2.8226828296464705
Validation loss: 2.4913599800168975

Epoch: 5| Step: 5
Training loss: 3.140782290643017
Validation loss: 2.4772674498193554

Epoch: 5| Step: 6
Training loss: 2.3928223528091825
Validation loss: 2.490327160092143

Epoch: 5| Step: 7
Training loss: 3.0937379779004104
Validation loss: 2.4896232185424516

Epoch: 5| Step: 8
Training loss: 2.8860780988397625
Validation loss: 2.4808510411212694

Epoch: 5| Step: 9
Training loss: 2.6378498731210995
Validation loss: 2.482408011760906

Epoch: 5| Step: 10
Training loss: 2.691155630991732
Validation loss: 2.489822351164427

Epoch: 145| Step: 0
Training loss: 2.6286191060795003
Validation loss: 2.5005327703008438

Epoch: 5| Step: 1
Training loss: 3.163414104570736
Validation loss: 2.5051811049127393

Epoch: 5| Step: 2
Training loss: 2.8603273900587523
Validation loss: 2.5089020791086054

Epoch: 5| Step: 3
Training loss: 3.215677368805301
Validation loss: 2.5161692293619984

Epoch: 5| Step: 4
Training loss: 2.2574330575338943
Validation loss: 2.5054154858635904

Epoch: 5| Step: 5
Training loss: 3.3228742702414307
Validation loss: 2.4896301815694692

Epoch: 5| Step: 6
Training loss: 2.7703123726282666
Validation loss: 2.4877788608149434

Epoch: 5| Step: 7
Training loss: 2.439092849259152
Validation loss: 2.490283001902088

Epoch: 5| Step: 8
Training loss: 2.6090755633475946
Validation loss: 2.498106477302143

Epoch: 5| Step: 9
Training loss: 2.490379897708803
Validation loss: 2.5035818774000775

Epoch: 5| Step: 10
Training loss: 2.6716526228959405
Validation loss: 2.5214512022966282

Epoch: 146| Step: 0
Training loss: 2.4849781767656363
Validation loss: 2.5192874282671305

Epoch: 5| Step: 1
Training loss: 3.034913199375986
Validation loss: 2.5140077710551187

Epoch: 5| Step: 2
Training loss: 2.9408159410872736
Validation loss: 2.503931469505771

Epoch: 5| Step: 3
Training loss: 2.581714143195426
Validation loss: 2.486535921151917

Epoch: 5| Step: 4
Training loss: 2.907842876392502
Validation loss: 2.4914993980526035

Epoch: 5| Step: 5
Training loss: 3.276796352061834
Validation loss: 2.485842524606635

Epoch: 5| Step: 6
Training loss: 2.2143859928470877
Validation loss: 2.4876730392192905

Epoch: 5| Step: 7
Training loss: 2.6798583218147933
Validation loss: 2.4934584546781386

Epoch: 5| Step: 8
Training loss: 2.8433961752967845
Validation loss: 2.5001965178908923

Epoch: 5| Step: 9
Training loss: 2.8753998519817823
Validation loss: 2.5173690967388365

Epoch: 5| Step: 10
Training loss: 2.636388506517923
Validation loss: 2.516849454981054

Epoch: 147| Step: 0
Training loss: 3.233379855919124
Validation loss: 2.5317018187454576

Epoch: 5| Step: 1
Training loss: 2.561798185679901
Validation loss: 2.524988977884777

Epoch: 5| Step: 2
Training loss: 2.3958427981866937
Validation loss: 2.513494729070244

Epoch: 5| Step: 3
Training loss: 3.076926060821847
Validation loss: 2.5136598138844692

Epoch: 5| Step: 4
Training loss: 2.588139544337661
Validation loss: 2.5232087454543106

Epoch: 5| Step: 5
Training loss: 2.7213954113233396
Validation loss: 2.5258822845086044

Epoch: 5| Step: 6
Training loss: 2.7750630517618267
Validation loss: 2.510502476060279

Epoch: 5| Step: 7
Training loss: 2.77558837014354
Validation loss: 2.5041824579333913

Epoch: 5| Step: 8
Training loss: 2.6093068370939014
Validation loss: 2.507566086026012

Epoch: 5| Step: 9
Training loss: 2.705206978824136
Validation loss: 2.509470862611003

Epoch: 5| Step: 10
Training loss: 2.857840537991646
Validation loss: 2.5066576651747776

Epoch: 148| Step: 0
Training loss: 3.053459213221798
Validation loss: 2.489643695676357

Epoch: 5| Step: 1
Training loss: 3.297433670221325
Validation loss: 2.4777264072525576

Epoch: 5| Step: 2
Training loss: 2.7923324607103064
Validation loss: 2.4782295541313273

Epoch: 5| Step: 3
Training loss: 2.8963732501967985
Validation loss: 2.4767974869357543

Epoch: 5| Step: 4
Training loss: 2.56047731911749
Validation loss: 2.4707897747772285

Epoch: 5| Step: 5
Training loss: 2.7348192998410705
Validation loss: 2.4760789332801347

Epoch: 5| Step: 6
Training loss: 2.94187957886501
Validation loss: 2.476072087450187

Epoch: 5| Step: 7
Training loss: 2.2684589419972094
Validation loss: 2.473571738502573

Epoch: 5| Step: 8
Training loss: 2.582519946690622
Validation loss: 2.4786604311606792

Epoch: 5| Step: 9
Training loss: 2.3465504509513244
Validation loss: 2.4940913671520377

Epoch: 5| Step: 10
Training loss: 2.830882377420517
Validation loss: 2.504519464941407

Epoch: 149| Step: 0
Training loss: 2.213996631016705
Validation loss: 2.508438428364806

Epoch: 5| Step: 1
Training loss: 2.692469947243438
Validation loss: 2.520242494845845

Epoch: 5| Step: 2
Training loss: 3.099311530664726
Validation loss: 2.551007201429498

Epoch: 5| Step: 3
Training loss: 2.7798772274323857
Validation loss: 2.5445087270549576

Epoch: 5| Step: 4
Training loss: 3.081380603800198
Validation loss: 2.5399660351502336

Epoch: 5| Step: 5
Training loss: 2.8436950007559214
Validation loss: 2.500089650956477

Epoch: 5| Step: 6
Training loss: 3.0005511731229144
Validation loss: 2.4981904474496983

Epoch: 5| Step: 7
Training loss: 2.6193640014155384
Validation loss: 2.484536117557951

Epoch: 5| Step: 8
Training loss: 2.9547815268577744
Validation loss: 2.4808275152753105

Epoch: 5| Step: 9
Training loss: 2.799671416076248
Validation loss: 2.47808614940206

Epoch: 5| Step: 10
Training loss: 2.131898118080802
Validation loss: 2.4787083439377295

Epoch: 150| Step: 0
Training loss: 2.8495173396934903
Validation loss: 2.4766387529177116

Epoch: 5| Step: 1
Training loss: 2.7261322468999722
Validation loss: 2.483378278440234

Epoch: 5| Step: 2
Training loss: 2.8089620590119235
Validation loss: 2.474367630179614

Epoch: 5| Step: 3
Training loss: 2.742512479908453
Validation loss: 2.479200411703322

Epoch: 5| Step: 4
Training loss: 3.046005516212563
Validation loss: 2.490106744296443

Epoch: 5| Step: 5
Training loss: 2.4697127577522946
Validation loss: 2.503414794685866

Epoch: 5| Step: 6
Training loss: 2.8204204506965405
Validation loss: 2.5041014365345213

Epoch: 5| Step: 7
Training loss: 2.565374204618675
Validation loss: 2.509885477912117

Epoch: 5| Step: 8
Training loss: 2.624952951645429
Validation loss: 2.518535986543911

Epoch: 5| Step: 9
Training loss: 2.8916289364627965
Validation loss: 2.5069175505689487

Epoch: 5| Step: 10
Training loss: 2.797762085447506
Validation loss: 2.512208207345403

Epoch: 151| Step: 0
Training loss: 2.8663776303742092
Validation loss: 2.5028673786740936

Epoch: 5| Step: 1
Training loss: 2.5241827558137135
Validation loss: 2.492925877536239

Epoch: 5| Step: 2
Training loss: 3.4153141197852066
Validation loss: 2.483987154811515

Epoch: 5| Step: 3
Training loss: 2.7041590482333118
Validation loss: 2.4797921498580915

Epoch: 5| Step: 4
Training loss: 2.774478512813968
Validation loss: 2.486145851645824

Epoch: 5| Step: 5
Training loss: 2.315127349382721
Validation loss: 2.4916945883053163

Epoch: 5| Step: 6
Training loss: 2.933631134810891
Validation loss: 2.4921855743274235

Epoch: 5| Step: 7
Training loss: 2.4586651680473564
Validation loss: 2.4947857336565957

Epoch: 5| Step: 8
Training loss: 2.575946234017573
Validation loss: 2.4947665976248463

Epoch: 5| Step: 9
Training loss: 3.2184886641102
Validation loss: 2.501463192194409

Epoch: 5| Step: 10
Training loss: 2.2448494557836347
Validation loss: 2.492999812882337

Epoch: 152| Step: 0
Training loss: 2.1735160720192357
Validation loss: 2.5036129982843764

Epoch: 5| Step: 1
Training loss: 2.5503948205208444
Validation loss: 2.507866780485849

Epoch: 5| Step: 2
Training loss: 2.0349927020117815
Validation loss: 2.5234554870100547

Epoch: 5| Step: 3
Training loss: 2.9056471332667915
Validation loss: 2.529989973386648

Epoch: 5| Step: 4
Training loss: 3.4261706836625736
Validation loss: 2.5289342818866043

Epoch: 5| Step: 5
Training loss: 2.324755694771981
Validation loss: 2.50435968214531

Epoch: 5| Step: 6
Training loss: 2.435980592240066
Validation loss: 2.4998656062437257

Epoch: 5| Step: 7
Training loss: 3.2125453960610315
Validation loss: 2.4761210225011054

Epoch: 5| Step: 8
Training loss: 2.8688351421146243
Validation loss: 2.4785466489545

Epoch: 5| Step: 9
Training loss: 2.868549906748161
Validation loss: 2.4759764384997913

Epoch: 5| Step: 10
Training loss: 3.239571934196476
Validation loss: 2.4606877010231774

Epoch: 153| Step: 0
Training loss: 2.420197921414858
Validation loss: 2.4663926013337343

Epoch: 5| Step: 1
Training loss: 2.910904305596935
Validation loss: 2.470583984117219

Epoch: 5| Step: 2
Training loss: 2.8631926518949498
Validation loss: 2.4711309820383587

Epoch: 5| Step: 3
Training loss: 3.1687919779447977
Validation loss: 2.4743720780632756

Epoch: 5| Step: 4
Training loss: 2.8896172493775696
Validation loss: 2.4722419675147815

Epoch: 5| Step: 5
Training loss: 2.246605113324833
Validation loss: 2.4745741100608454

Epoch: 5| Step: 6
Training loss: 2.455958970861023
Validation loss: 2.4818191409129233

Epoch: 5| Step: 7
Training loss: 3.0498592531842186
Validation loss: 2.4845881701819748

Epoch: 5| Step: 8
Training loss: 2.316444641103921
Validation loss: 2.4857768363409884

Epoch: 5| Step: 9
Training loss: 2.506302233220652
Validation loss: 2.4948486681957127

Epoch: 5| Step: 10
Training loss: 3.2135582691095554
Validation loss: 2.500774005313101

Epoch: 154| Step: 0
Training loss: 2.6858339690293396
Validation loss: 2.510674358001199

Epoch: 5| Step: 1
Training loss: 2.365196271820975
Validation loss: 2.5046237078096807

Epoch: 5| Step: 2
Training loss: 2.8845237883672823
Validation loss: 2.5068633456586435

Epoch: 5| Step: 3
Training loss: 3.0737586640510837
Validation loss: 2.5140476355336334

Epoch: 5| Step: 4
Training loss: 2.7474482575005523
Validation loss: 2.5075294739480567

Epoch: 5| Step: 5
Training loss: 2.915762970206133
Validation loss: 2.530158614443124

Epoch: 5| Step: 6
Training loss: 2.600045343150382
Validation loss: 2.512863772648326

Epoch: 5| Step: 7
Training loss: 3.0451771235823473
Validation loss: 2.512282436474955

Epoch: 5| Step: 8
Training loss: 2.6786723090657185
Validation loss: 2.5092409083602814

Epoch: 5| Step: 9
Training loss: 2.617734299660098
Validation loss: 2.522043553087172

Epoch: 5| Step: 10
Training loss: 2.575841921600008
Validation loss: 2.5282635701089733

Epoch: 155| Step: 0
Training loss: 2.679987676506746
Validation loss: 2.526268650957511

Epoch: 5| Step: 1
Training loss: 3.2625031219116707
Validation loss: 2.522920823387004

Epoch: 5| Step: 2
Training loss: 2.9249008748791216
Validation loss: 2.482759325570406

Epoch: 5| Step: 3
Training loss: 2.91529586913192
Validation loss: 2.477764433839823

Epoch: 5| Step: 4
Training loss: 2.446363424362545
Validation loss: 2.472239035998988

Epoch: 5| Step: 5
Training loss: 2.4036008445577015
Validation loss: 2.488267474011524

Epoch: 5| Step: 6
Training loss: 2.97244755216613
Validation loss: 2.509328549584131

Epoch: 5| Step: 7
Training loss: 3.2155105436991844
Validation loss: 2.4884136835231523

Epoch: 5| Step: 8
Training loss: 2.6010296250078464
Validation loss: 2.4834570597105676

Epoch: 5| Step: 9
Training loss: 2.7421438534297997
Validation loss: 2.4643410903606555

Epoch: 5| Step: 10
Training loss: 1.7780799766163553
Validation loss: 2.462078773005994

Epoch: 156| Step: 0
Training loss: 2.6759375310771083
Validation loss: 2.4595763406438396

Epoch: 5| Step: 1
Training loss: 2.8082727665317515
Validation loss: 2.4476201834617846

Epoch: 5| Step: 2
Training loss: 2.4396476087781798
Validation loss: 2.470982692689019

Epoch: 5| Step: 3
Training loss: 2.9853113113699643
Validation loss: 2.4605682090757246

Epoch: 5| Step: 4
Training loss: 2.009400804511177
Validation loss: 2.469087518704547

Epoch: 5| Step: 5
Training loss: 3.381247072341977
Validation loss: 2.4843092915059484

Epoch: 5| Step: 6
Training loss: 2.8144402487127382
Validation loss: 2.4642499016536727

Epoch: 5| Step: 7
Training loss: 2.7408198671212136
Validation loss: 2.4701783448754178

Epoch: 5| Step: 8
Training loss: 2.998406940918729
Validation loss: 2.4723176527191577

Epoch: 5| Step: 9
Training loss: 2.254410341904299
Validation loss: 2.4660122541954768

Epoch: 5| Step: 10
Training loss: 2.774080787521921
Validation loss: 2.4707135063244143

Epoch: 157| Step: 0
Training loss: 2.409274194887058
Validation loss: 2.4751556335121694

Epoch: 5| Step: 1
Training loss: 2.5946955049068077
Validation loss: 2.483694098674031

Epoch: 5| Step: 2
Training loss: 2.597476534255565
Validation loss: 2.483464165964657

Epoch: 5| Step: 3
Training loss: 2.6145417006218836
Validation loss: 2.500023802777258

Epoch: 5| Step: 4
Training loss: 2.645334862638744
Validation loss: 2.501259427064204

Epoch: 5| Step: 5
Training loss: 2.40900085552449
Validation loss: 2.4888129463191313

Epoch: 5| Step: 6
Training loss: 3.3062981181978928
Validation loss: 2.4891967449258248

Epoch: 5| Step: 7
Training loss: 2.8336170465875283
Validation loss: 2.4857160586593214

Epoch: 5| Step: 8
Training loss: 3.0534298544485345
Validation loss: 2.4830117510129233

Epoch: 5| Step: 9
Training loss: 2.771220780056401
Validation loss: 2.4782437769436956

Epoch: 5| Step: 10
Training loss: 2.7220102690447656
Validation loss: 2.4773990709692595

Epoch: 158| Step: 0
Training loss: 3.0854797796422284
Validation loss: 2.4690153156694414

Epoch: 5| Step: 1
Training loss: 2.7554775652137398
Validation loss: 2.4721491528138992

Epoch: 5| Step: 2
Training loss: 2.5131545167985943
Validation loss: 2.460980010686872

Epoch: 5| Step: 3
Training loss: 2.0394420051381155
Validation loss: 2.4707438801378276

Epoch: 5| Step: 4
Training loss: 3.203253171263774
Validation loss: 2.4734672089126337

Epoch: 5| Step: 5
Training loss: 2.841440793305458
Validation loss: 2.4856558137433167

Epoch: 5| Step: 6
Training loss: 2.6386834404816857
Validation loss: 2.5197824925071157

Epoch: 5| Step: 7
Training loss: 3.028266303482831
Validation loss: 2.5291635504535455

Epoch: 5| Step: 8
Training loss: 2.280079162294179
Validation loss: 2.554151316386876

Epoch: 5| Step: 9
Training loss: 2.5995418731844757
Validation loss: 2.5535006975611343

Epoch: 5| Step: 10
Training loss: 3.113542074384479
Validation loss: 2.520140144177392

Epoch: 159| Step: 0
Training loss: 3.1942286063728296
Validation loss: 2.492275343856483

Epoch: 5| Step: 1
Training loss: 2.663993588448447
Validation loss: 2.465491613318875

Epoch: 5| Step: 2
Training loss: 2.8927304410015244
Validation loss: 2.453676491869367

Epoch: 5| Step: 3
Training loss: 3.102742237406238
Validation loss: 2.4554285296410585

Epoch: 5| Step: 4
Training loss: 2.4010117226234637
Validation loss: 2.451394145532754

Epoch: 5| Step: 5
Training loss: 2.724292236247162
Validation loss: 2.448218713757113

Epoch: 5| Step: 6
Training loss: 2.6790560765280076
Validation loss: 2.445241593225923

Epoch: 5| Step: 7
Training loss: 2.5223486473264227
Validation loss: 2.448856573548915

Epoch: 5| Step: 8
Training loss: 2.2574947357961253
Validation loss: 2.4470628983220277

Epoch: 5| Step: 9
Training loss: 2.9386360731153567
Validation loss: 2.448931993270867

Epoch: 5| Step: 10
Training loss: 2.3478879893553444
Validation loss: 2.4601494213024546

Epoch: 160| Step: 0
Training loss: 2.4783403531530723
Validation loss: 2.4745331030592737

Epoch: 5| Step: 1
Training loss: 2.880058482424032
Validation loss: 2.48565584881003

Epoch: 5| Step: 2
Training loss: 2.6156865157136715
Validation loss: 2.494085981025606

Epoch: 5| Step: 3
Training loss: 2.4179778214440093
Validation loss: 2.4883811434678407

Epoch: 5| Step: 4
Training loss: 2.882388696299931
Validation loss: 2.4973082725905535

Epoch: 5| Step: 5
Training loss: 2.910167064262625
Validation loss: 2.4834176095141967

Epoch: 5| Step: 6
Training loss: 3.03333155942872
Validation loss: 2.4862939150929053

Epoch: 5| Step: 7
Training loss: 2.8475844134779087
Validation loss: 2.4728648155715898

Epoch: 5| Step: 8
Training loss: 2.597545925465015
Validation loss: 2.471296047142474

Epoch: 5| Step: 9
Training loss: 2.6190931072661026
Validation loss: 2.4824578318992265

Epoch: 5| Step: 10
Training loss: 2.5166942148616633
Validation loss: 2.4753644006878712

Epoch: 161| Step: 0
Training loss: 2.7911234274907644
Validation loss: 2.485171296144931

Epoch: 5| Step: 1
Training loss: 2.8014896619511713
Validation loss: 2.489074655750642

Epoch: 5| Step: 2
Training loss: 3.001953125
Validation loss: 2.510499208325851

Epoch: 5| Step: 3
Training loss: 3.113769646103671
Validation loss: 2.4972838618643003

Epoch: 5| Step: 4
Training loss: 2.7151510160819075
Validation loss: 2.501968816528825

Epoch: 5| Step: 5
Training loss: 2.4113029830909736
Validation loss: 2.51617418818056

Epoch: 5| Step: 6
Training loss: 1.7330786869479406
Validation loss: 2.504872997525128

Epoch: 5| Step: 7
Training loss: 2.7301273159759396
Validation loss: 2.5138818613121576

Epoch: 5| Step: 8
Training loss: 2.455862862165987
Validation loss: 2.5066172842963175

Epoch: 5| Step: 9
Training loss: 3.000214727982226
Validation loss: 2.4864454917800014

Epoch: 5| Step: 10
Training loss: 2.796743549689004
Validation loss: 2.497507111185538

Epoch: 162| Step: 0
Training loss: 2.8907902850760445
Validation loss: 2.4923232993685

Epoch: 5| Step: 1
Training loss: 1.942626385498731
Validation loss: 2.4911755370996853

Epoch: 5| Step: 2
Training loss: 2.8749963511568217
Validation loss: 2.5172612916823316

Epoch: 5| Step: 3
Training loss: 3.1796158166251796
Validation loss: 2.502773579878823

Epoch: 5| Step: 4
Training loss: 2.5440067920834064
Validation loss: 2.4971436970334926

Epoch: 5| Step: 5
Training loss: 2.6718305617535356
Validation loss: 2.5087859728930058

Epoch: 5| Step: 6
Training loss: 2.274873994125378
Validation loss: 2.5247995316298333

Epoch: 5| Step: 7
Training loss: 2.596695479925651
Validation loss: 2.529796636330422

Epoch: 5| Step: 8
Training loss: 2.92809934167195
Validation loss: 2.508782346802352

Epoch: 5| Step: 9
Training loss: 2.95125395422755
Validation loss: 2.4911805755129452

Epoch: 5| Step: 10
Training loss: 2.864216359069702
Validation loss: 2.4851962890188997

Epoch: 163| Step: 0
Training loss: 2.38991780510823
Validation loss: 2.4856688430561795

Epoch: 5| Step: 1
Training loss: 2.04936032433358
Validation loss: 2.475690819801504

Epoch: 5| Step: 2
Training loss: 3.140155814125679
Validation loss: 2.4748473691193746

Epoch: 5| Step: 3
Training loss: 2.695112403408139
Validation loss: 2.478028566069306

Epoch: 5| Step: 4
Training loss: 2.146274545981314
Validation loss: 2.4951896924567962

Epoch: 5| Step: 5
Training loss: 2.636640352567145
Validation loss: 2.4945590585383153

Epoch: 5| Step: 6
Training loss: 2.2166521067129197
Validation loss: 2.5068181329275916

Epoch: 5| Step: 7
Training loss: 3.3984950269017573
Validation loss: 2.5178775453851014

Epoch: 5| Step: 8
Training loss: 2.890374580052332
Validation loss: 2.554354742297181

Epoch: 5| Step: 9
Training loss: 3.138306782252763
Validation loss: 2.6120349829526384

Epoch: 5| Step: 10
Training loss: 3.1048463593585702
Validation loss: 2.64635327996836

Epoch: 164| Step: 0
Training loss: 3.1672267585809193
Validation loss: 2.644260744980086

Epoch: 5| Step: 1
Training loss: 2.698847302109054
Validation loss: 2.656007411816719

Epoch: 5| Step: 2
Training loss: 2.73938897510735
Validation loss: 2.625363970718718

Epoch: 5| Step: 3
Training loss: 3.083633992425684
Validation loss: 2.570298405641767

Epoch: 5| Step: 4
Training loss: 2.265021092398751
Validation loss: 2.5435124948160177

Epoch: 5| Step: 5
Training loss: 3.0719868605650604
Validation loss: 2.5237634610136657

Epoch: 5| Step: 6
Training loss: 2.2482637488039057
Validation loss: 2.490400162739155

Epoch: 5| Step: 7
Training loss: 2.2895105333587877
Validation loss: 2.4852816701581557

Epoch: 5| Step: 8
Training loss: 2.467516047494142
Validation loss: 2.508269120103301

Epoch: 5| Step: 9
Training loss: 3.396651717412943
Validation loss: 2.5653220463582196

Epoch: 5| Step: 10
Training loss: 3.0060590909427822
Validation loss: 2.601792093527535

Epoch: 165| Step: 0
Training loss: 2.7478043721014944
Validation loss: 2.5651052343902356

Epoch: 5| Step: 1
Training loss: 3.0967857802210186
Validation loss: 2.497329691705309

Epoch: 5| Step: 2
Training loss: 2.021714703250464
Validation loss: 2.4590098487978276

Epoch: 5| Step: 3
Training loss: 2.5663349019762722
Validation loss: 2.454223994858462

Epoch: 5| Step: 4
Training loss: 3.1131394185266696
Validation loss: 2.441403581777776

Epoch: 5| Step: 5
Training loss: 3.096648890673887
Validation loss: 2.4517107177925195

Epoch: 5| Step: 6
Training loss: 2.7234582581771294
Validation loss: 2.4509575096765674

Epoch: 5| Step: 7
Training loss: 2.825213540707701
Validation loss: 2.448088153251215

Epoch: 5| Step: 8
Training loss: 2.2477071523620555
Validation loss: 2.4546995181768865

Epoch: 5| Step: 9
Training loss: 2.8608686371145535
Validation loss: 2.4543004362511205

Epoch: 5| Step: 10
Training loss: 2.3472448105888275
Validation loss: 2.4611472430277073

Epoch: 166| Step: 0
Training loss: 2.1737756988427748
Validation loss: 2.480841470016445

Epoch: 5| Step: 1
Training loss: 2.431689060448836
Validation loss: 2.4905543078665073

Epoch: 5| Step: 2
Training loss: 3.0434584021660838
Validation loss: 2.481592852680645

Epoch: 5| Step: 3
Training loss: 3.183488752821857
Validation loss: 2.485155469670543

Epoch: 5| Step: 4
Training loss: 2.3252601149884193
Validation loss: 2.4706517292789063

Epoch: 5| Step: 5
Training loss: 2.431324496267897
Validation loss: 2.460775122792894

Epoch: 5| Step: 6
Training loss: 2.811240189578866
Validation loss: 2.4610406898575232

Epoch: 5| Step: 7
Training loss: 2.6718992711799654
Validation loss: 2.455292492875578

Epoch: 5| Step: 8
Training loss: 2.384275593816555
Validation loss: 2.4662592015326754

Epoch: 5| Step: 9
Training loss: 2.7485747545418757
Validation loss: 2.467641211506437

Epoch: 5| Step: 10
Training loss: 3.3156498741777254
Validation loss: 2.474822368070811

Epoch: 167| Step: 0
Training loss: 1.8101531653116587
Validation loss: 2.4805509019288903

Epoch: 5| Step: 1
Training loss: 3.1800493414067867
Validation loss: 2.488033456007063

Epoch: 5| Step: 2
Training loss: 2.8486227689872656
Validation loss: 2.4966707283151384

Epoch: 5| Step: 3
Training loss: 2.3348853762345185
Validation loss: 2.500295266793726

Epoch: 5| Step: 4
Training loss: 3.036992719071911
Validation loss: 2.5210047776870974

Epoch: 5| Step: 5
Training loss: 3.3375670408452067
Validation loss: 2.520188697583875

Epoch: 5| Step: 6
Training loss: 2.4015441059904727
Validation loss: 2.489737872260065

Epoch: 5| Step: 7
Training loss: 2.3665829128793936
Validation loss: 2.4970831867753196

Epoch: 5| Step: 8
Training loss: 2.5283504880634573
Validation loss: 2.5020533835062495

Epoch: 5| Step: 9
Training loss: 2.924326638206866
Validation loss: 2.471458106542197

Epoch: 5| Step: 10
Training loss: 2.767943708762505
Validation loss: 2.465647965496638

Epoch: 168| Step: 0
Training loss: 2.5152696631015323
Validation loss: 2.466189300860573

Epoch: 5| Step: 1
Training loss: 2.64029849590173
Validation loss: 2.458623939497027

Epoch: 5| Step: 2
Training loss: 2.419686688562568
Validation loss: 2.465629197021216

Epoch: 5| Step: 3
Training loss: 2.765177889959805
Validation loss: 2.4556367507666073

Epoch: 5| Step: 4
Training loss: 2.9765125180350798
Validation loss: 2.467005823704362

Epoch: 5| Step: 5
Training loss: 2.4322455086640624
Validation loss: 2.478269126739737

Epoch: 5| Step: 6
Training loss: 2.68897180398761
Validation loss: 2.4716944292628087

Epoch: 5| Step: 7
Training loss: 2.77308536496918
Validation loss: 2.4548706371122564

Epoch: 5| Step: 8
Training loss: 2.913099359883593
Validation loss: 2.4589119597479736

Epoch: 5| Step: 9
Training loss: 2.647473185027923
Validation loss: 2.449838376652414

Epoch: 5| Step: 10
Training loss: 3.012793283708879
Validation loss: 2.4625925119480283

Epoch: 169| Step: 0
Training loss: 3.002720235327545
Validation loss: 2.464605463921787

Epoch: 5| Step: 1
Training loss: 2.427689494349585
Validation loss: 2.472477906325393

Epoch: 5| Step: 2
Training loss: 2.882554453643965
Validation loss: 2.474149879246616

Epoch: 5| Step: 3
Training loss: 2.5590464883019948
Validation loss: 2.482398883502726

Epoch: 5| Step: 4
Training loss: 2.4300613361042975
Validation loss: 2.5014937440028535

Epoch: 5| Step: 5
Training loss: 2.544833154661558
Validation loss: 2.512031126589178

Epoch: 5| Step: 6
Training loss: 2.549971587826885
Validation loss: 2.5047264008229546

Epoch: 5| Step: 7
Training loss: 2.874027751228499
Validation loss: 2.492604564386884

Epoch: 5| Step: 8
Training loss: 2.9140863903385648
Validation loss: 2.497998843610465

Epoch: 5| Step: 9
Training loss: 2.6738637917635777
Validation loss: 2.4874577701780933

Epoch: 5| Step: 10
Training loss: 2.4710759661864024
Validation loss: 2.4919078236777192

Epoch: 170| Step: 0
Training loss: 2.426726177170561
Validation loss: 2.4730987772321997

Epoch: 5| Step: 1
Training loss: 2.300603629802927
Validation loss: 2.4705293379537547

Epoch: 5| Step: 2
Training loss: 3.0001908877359793
Validation loss: 2.46675702741297

Epoch: 5| Step: 3
Training loss: 3.093915222071734
Validation loss: 2.483721638344321

Epoch: 5| Step: 4
Training loss: 3.2188083680425374
Validation loss: 2.4868795574135043

Epoch: 5| Step: 5
Training loss: 2.439200370650421
Validation loss: 2.4767080745377554

Epoch: 5| Step: 6
Training loss: 2.4161706503100473
Validation loss: 2.4583212242294032

Epoch: 5| Step: 7
Training loss: 2.6767714401616343
Validation loss: 2.4468303363651493

Epoch: 5| Step: 8
Training loss: 2.070730951593944
Validation loss: 2.450316599793535

Epoch: 5| Step: 9
Training loss: 2.783241073617384
Validation loss: 2.4561287547418424

Epoch: 5| Step: 10
Training loss: 2.8657901695515737
Validation loss: 2.4885045626510918

Epoch: 171| Step: 0
Training loss: 2.6630320415911286
Validation loss: 2.47959541783428

Epoch: 5| Step: 1
Training loss: 2.4730693839613482
Validation loss: 2.465564247074412

Epoch: 5| Step: 2
Training loss: 2.433287869207249
Validation loss: 2.4636506718592006

Epoch: 5| Step: 3
Training loss: 2.623391794121238
Validation loss: 2.4614098515685625

Epoch: 5| Step: 4
Training loss: 2.4343776756732227
Validation loss: 2.4819355805722103

Epoch: 5| Step: 5
Training loss: 2.2267952780595217
Validation loss: 2.521501070484582

Epoch: 5| Step: 6
Training loss: 2.979689189908409
Validation loss: 2.540018040378439

Epoch: 5| Step: 7
Training loss: 3.669636275226205
Validation loss: 2.5679999274145633

Epoch: 5| Step: 8
Training loss: 2.7146127726045917
Validation loss: 2.5475460834004715

Epoch: 5| Step: 9
Training loss: 2.4181941455805847
Validation loss: 2.5187652479132767

Epoch: 5| Step: 10
Training loss: 2.3815586480786655
Validation loss: 2.4894406355042733

Epoch: 172| Step: 0
Training loss: 2.86215291813387
Validation loss: 2.5036553239912682

Epoch: 5| Step: 1
Training loss: 2.5718179949054867
Validation loss: 2.4876962560928324

Epoch: 5| Step: 2
Training loss: 2.6806926121259758
Validation loss: 2.4759415471456188

Epoch: 5| Step: 3
Training loss: 2.697201716324024
Validation loss: 2.457331860300381

Epoch: 5| Step: 4
Training loss: 2.1346782865396663
Validation loss: 2.4462750856673536

Epoch: 5| Step: 5
Training loss: 3.0121658329798335
Validation loss: 2.461564339456571

Epoch: 5| Step: 6
Training loss: 2.6685357894513086
Validation loss: 2.4504526135849654

Epoch: 5| Step: 7
Training loss: 2.4172987494978213
Validation loss: 2.458769829571031

Epoch: 5| Step: 8
Training loss: 2.821178863264049
Validation loss: 2.464527558186829

Epoch: 5| Step: 9
Training loss: 2.6281397071816954
Validation loss: 2.4492419619018917

Epoch: 5| Step: 10
Training loss: 2.996770551052706
Validation loss: 2.447068227660199

Epoch: 173| Step: 0
Training loss: 2.4781606433513086
Validation loss: 2.4497977090597054

Epoch: 5| Step: 1
Training loss: 2.5109280161746748
Validation loss: 2.436193424692784

Epoch: 5| Step: 2
Training loss: 2.0668750944965204
Validation loss: 2.4576494277335628

Epoch: 5| Step: 3
Training loss: 2.548425027242575
Validation loss: 2.473052847695764

Epoch: 5| Step: 4
Training loss: 2.868417418904492
Validation loss: 2.482428713646193

Epoch: 5| Step: 5
Training loss: 2.37212408514468
Validation loss: 2.5077344991980293

Epoch: 5| Step: 6
Training loss: 2.8742991712786585
Validation loss: 2.5056533839428563

Epoch: 5| Step: 7
Training loss: 3.1450634618521054
Validation loss: 2.5323141583767326

Epoch: 5| Step: 8
Training loss: 2.7402268924189537
Validation loss: 2.5039449361181823

Epoch: 5| Step: 9
Training loss: 2.3267859377890714
Validation loss: 2.48499357314001

Epoch: 5| Step: 10
Training loss: 2.9688341630750945
Validation loss: 2.4705337553910467

Epoch: 174| Step: 0
Training loss: 2.4883293494541636
Validation loss: 2.484442704471921

Epoch: 5| Step: 1
Training loss: 2.900778922345383
Validation loss: 2.510485765638609

Epoch: 5| Step: 2
Training loss: 2.4413757810598726
Validation loss: 2.4824775481788017

Epoch: 5| Step: 3
Training loss: 2.8704363219456246
Validation loss: 2.4588625737792618

Epoch: 5| Step: 4
Training loss: 2.115938050226769
Validation loss: 2.4538818784409786

Epoch: 5| Step: 5
Training loss: 2.1926153046965737
Validation loss: 2.4562465510829075

Epoch: 5| Step: 6
Training loss: 2.407638941604892
Validation loss: 2.467659328874843

Epoch: 5| Step: 7
Training loss: 2.9277700430928544
Validation loss: 2.4884531915337935

Epoch: 5| Step: 8
Training loss: 3.047368092862429
Validation loss: 2.5175211572931677

Epoch: 5| Step: 9
Training loss: 2.966229623755917
Validation loss: 2.4977563511437135

Epoch: 5| Step: 10
Training loss: 2.7749075418826687
Validation loss: 2.49411006843278

Epoch: 175| Step: 0
Training loss: 2.388413846543781
Validation loss: 2.4752735424719186

Epoch: 5| Step: 1
Training loss: 2.8063370892916857
Validation loss: 2.4567688376107353

Epoch: 5| Step: 2
Training loss: 2.790389314376643
Validation loss: 2.442597600788993

Epoch: 5| Step: 3
Training loss: 2.6368202020412896
Validation loss: 2.4387481865528415

Epoch: 5| Step: 4
Training loss: 2.677027146359594
Validation loss: 2.454457717529814

Epoch: 5| Step: 5
Training loss: 2.2166824378501846
Validation loss: 2.4462731846358845

Epoch: 5| Step: 6
Training loss: 2.232019209570583
Validation loss: 2.442067414044388

Epoch: 5| Step: 7
Training loss: 3.0207837506313844
Validation loss: 2.443849277507069

Epoch: 5| Step: 8
Training loss: 2.3113151814258055
Validation loss: 2.4516766438809205

Epoch: 5| Step: 9
Training loss: 2.6721010168305255
Validation loss: 2.444888662708161

Epoch: 5| Step: 10
Training loss: 3.0911634016729503
Validation loss: 2.456929788709024

Epoch: 176| Step: 0
Training loss: 2.441412402335998
Validation loss: 2.466759846966332

Epoch: 5| Step: 1
Training loss: 2.7122857426698492
Validation loss: 2.483704280161119

Epoch: 5| Step: 2
Training loss: 2.1460904704965613
Validation loss: 2.490639091545812

Epoch: 5| Step: 3
Training loss: 2.6468615498927286
Validation loss: 2.498102286673997

Epoch: 5| Step: 4
Training loss: 2.664467252261285
Validation loss: 2.503252116846183

Epoch: 5| Step: 5
Training loss: 2.684021406233313
Validation loss: 2.5080948368736826

Epoch: 5| Step: 6
Training loss: 2.188576896440818
Validation loss: 2.5090021651810623

Epoch: 5| Step: 7
Training loss: 3.188972880829809
Validation loss: 2.5169718866620663

Epoch: 5| Step: 8
Training loss: 1.9254203287945726
Validation loss: 2.497629437381951

Epoch: 5| Step: 9
Training loss: 2.5523032165055106
Validation loss: 2.4856360463517397

Epoch: 5| Step: 10
Training loss: 3.236914775491308
Validation loss: 2.477581107256282

Epoch: 177| Step: 0
Training loss: 2.2090737403176774
Validation loss: 2.4822120003658967

Epoch: 5| Step: 1
Training loss: 2.265461988175247
Validation loss: 2.4636742056419543

Epoch: 5| Step: 2
Training loss: 2.8414058875145836
Validation loss: 2.4641852805184894

Epoch: 5| Step: 3
Training loss: 2.5594030134184056
Validation loss: 2.456883960721863

Epoch: 5| Step: 4
Training loss: 3.207186770646749
Validation loss: 2.451238738476926

Epoch: 5| Step: 5
Training loss: 2.876162086811064
Validation loss: 2.451962218093376

Epoch: 5| Step: 6
Training loss: 2.6396277536590196
Validation loss: 2.455199338148595

Epoch: 5| Step: 7
Training loss: 2.429931628360325
Validation loss: 2.4554990033923945

Epoch: 5| Step: 8
Training loss: 2.736028814180799
Validation loss: 2.4433898475336155

Epoch: 5| Step: 9
Training loss: 2.2362292938382597
Validation loss: 2.454532639278157

Epoch: 5| Step: 10
Training loss: 2.4563279350671126
Validation loss: 2.454043115514703

Epoch: 178| Step: 0
Training loss: 2.59739355608989
Validation loss: 2.4500779168616105

Epoch: 5| Step: 1
Training loss: 2.649388145491557
Validation loss: 2.47254853904265

Epoch: 5| Step: 2
Training loss: 2.235254394765855
Validation loss: 2.4564768836525817

Epoch: 5| Step: 3
Training loss: 3.515477427458289
Validation loss: 2.471400712130758

Epoch: 5| Step: 4
Training loss: 2.537806743253133
Validation loss: 2.4705136428607295

Epoch: 5| Step: 5
Training loss: 2.8804412434906825
Validation loss: 2.479135704588272

Epoch: 5| Step: 6
Training loss: 2.0792481105145018
Validation loss: 2.494710416667691

Epoch: 5| Step: 7
Training loss: 1.9633033736015033
Validation loss: 2.525267364973564

Epoch: 5| Step: 8
Training loss: 2.8077499119443816
Validation loss: 2.516592281184575

Epoch: 5| Step: 9
Training loss: 2.2422795825086697
Validation loss: 2.510416779339202

Epoch: 5| Step: 10
Training loss: 2.5395808703124003
Validation loss: 2.5148410695381123

Epoch: 179| Step: 0
Training loss: 2.6515955817834467
Validation loss: 2.4740393215495895

Epoch: 5| Step: 1
Training loss: 2.7946081085342978
Validation loss: 2.4667472478092507

Epoch: 5| Step: 2
Training loss: 2.70749157271126
Validation loss: 2.451829302522436

Epoch: 5| Step: 3
Training loss: 2.6281601185669192
Validation loss: 2.4698430055230327

Epoch: 5| Step: 4
Training loss: 2.642021306618333
Validation loss: 2.471289663178535

Epoch: 5| Step: 5
Training loss: 2.236046332716942
Validation loss: 2.471596850703745

Epoch: 5| Step: 6
Training loss: 1.9551472684997968
Validation loss: 2.4766061668419117

Epoch: 5| Step: 7
Training loss: 3.0181346194994183
Validation loss: 2.478307930133529

Epoch: 5| Step: 8
Training loss: 2.9166765122020397
Validation loss: 2.467657066158998

Epoch: 5| Step: 9
Training loss: 2.4994417520944627
Validation loss: 2.4516778584243917

Epoch: 5| Step: 10
Training loss: 2.3817185188808376
Validation loss: 2.4296406443087113

Epoch: 180| Step: 0
Training loss: 2.389051430616064
Validation loss: 2.432128592663357

Epoch: 5| Step: 1
Training loss: 2.133151184690294
Validation loss: 2.4455699070303125

Epoch: 5| Step: 2
Training loss: 2.3098143370027255
Validation loss: 2.434799580066887

Epoch: 5| Step: 3
Training loss: 2.4002982510577224
Validation loss: 2.4451284749834308

Epoch: 5| Step: 4
Training loss: 2.6574780486412317
Validation loss: 2.4480447034443085

Epoch: 5| Step: 5
Training loss: 3.09458249383616
Validation loss: 2.471629924973915

Epoch: 5| Step: 6
Training loss: 2.547025711187405
Validation loss: 2.484527421205768

Epoch: 5| Step: 7
Training loss: 2.495183692239916
Validation loss: 2.5315997075717824

Epoch: 5| Step: 8
Training loss: 2.590973068433019
Validation loss: 2.5673497345708527

Epoch: 5| Step: 9
Training loss: 2.61349627831827
Validation loss: 2.565122307579531

Epoch: 5| Step: 10
Training loss: 2.974417326470318
Validation loss: 2.589800847153405

Epoch: 181| Step: 0
Training loss: 2.4825195485370117
Validation loss: 2.5943647452535528

Epoch: 5| Step: 1
Training loss: 2.5449843614918417
Validation loss: 2.5697942543499765

Epoch: 5| Step: 2
Training loss: 2.711995031228479
Validation loss: 2.544585681192441

Epoch: 5| Step: 3
Training loss: 1.9957249967071338
Validation loss: 2.5236907286370633

Epoch: 5| Step: 4
Training loss: 2.6235969972093405
Validation loss: 2.490544930512204

Epoch: 5| Step: 5
Training loss: 2.4546258307953503
Validation loss: 2.4699809727079747

Epoch: 5| Step: 6
Training loss: 2.608983724348156
Validation loss: 2.4579101093559816

Epoch: 5| Step: 7
Training loss: 2.7856337898976737
Validation loss: 2.471640158231691

Epoch: 5| Step: 8
Training loss: 2.7490720917375135
Validation loss: 2.4598343060987835

Epoch: 5| Step: 9
Training loss: 2.563820661429377
Validation loss: 2.454705278973696

Epoch: 5| Step: 10
Training loss: 2.3832838248955044
Validation loss: 2.4573279751901005

Epoch: 182| Step: 0
Training loss: 2.7858486946573255
Validation loss: 2.456665996873613

Epoch: 5| Step: 1
Training loss: 2.0492998276558683
Validation loss: 2.463970818588108

Epoch: 5| Step: 2
Training loss: 2.52520095101104
Validation loss: 2.4988761621581674

Epoch: 5| Step: 3
Training loss: 2.891994007795571
Validation loss: 2.521725608470232

Epoch: 5| Step: 4
Training loss: 2.1684391645465535
Validation loss: 2.5237838185929533

Epoch: 5| Step: 5
Training loss: 2.285826286483993
Validation loss: 2.5042481506952305

Epoch: 5| Step: 6
Training loss: 1.8553558636507124
Validation loss: 2.482291153268906

Epoch: 5| Step: 7
Training loss: 2.419414722665431
Validation loss: 2.4634522459521753

Epoch: 5| Step: 8
Training loss: 3.027041788115835
Validation loss: 2.489576494088503

Epoch: 5| Step: 9
Training loss: 2.719968150176776
Validation loss: 2.5651354359582874

Epoch: 5| Step: 10
Training loss: 3.3649997197642785
Validation loss: 2.607688746541381

Epoch: 183| Step: 0
Training loss: 2.89392775448966
Validation loss: 2.607660254922034

Epoch: 5| Step: 1
Training loss: 2.6786027052733585
Validation loss: 2.5227359502726645

Epoch: 5| Step: 2
Training loss: 2.434561890466279
Validation loss: 2.440308454040913

Epoch: 5| Step: 3
Training loss: 2.066023389109655
Validation loss: 2.4297782248723068

Epoch: 5| Step: 4
Training loss: 3.190435516380121
Validation loss: 2.4225281521710156

Epoch: 5| Step: 5
Training loss: 2.5795968218277046
Validation loss: 2.4401947021148476

Epoch: 5| Step: 6
Training loss: 2.6910136120528834
Validation loss: 2.4598748088048135

Epoch: 5| Step: 7
Training loss: 2.772148929035635
Validation loss: 2.444754168700698

Epoch: 5| Step: 8
Training loss: 2.596521298849135
Validation loss: 2.4411695323747904

Epoch: 5| Step: 9
Training loss: 2.2996787261484495
Validation loss: 2.444357973918875

Epoch: 5| Step: 10
Training loss: 2.349832398951385
Validation loss: 2.4487068976115576

Epoch: 184| Step: 0
Training loss: 2.164258046043045
Validation loss: 2.458082466993484

Epoch: 5| Step: 1
Training loss: 2.4360346179563197
Validation loss: 2.491261025119795

Epoch: 5| Step: 2
Training loss: 2.6065949575344542
Validation loss: 2.5157379989197475

Epoch: 5| Step: 3
Training loss: 2.70257977405851
Validation loss: 2.587281000080683

Epoch: 5| Step: 4
Training loss: 2.2562000892592478
Validation loss: 2.6528871311810214

Epoch: 5| Step: 5
Training loss: 3.0422152368567352
Validation loss: 2.6363797966608415

Epoch: 5| Step: 6
Training loss: 2.4209232552176885
Validation loss: 2.605389840269159

Epoch: 5| Step: 7
Training loss: 2.8253347215431526
Validation loss: 2.5812956186049596

Epoch: 5| Step: 8
Training loss: 2.860484257228494
Validation loss: 2.550082304766546

Epoch: 5| Step: 9
Training loss: 2.6460784037674085
Validation loss: 2.5186883832797986

Epoch: 5| Step: 10
Training loss: 2.2633939083609635
Validation loss: 2.4909386893052257

Epoch: 185| Step: 0
Training loss: 2.755662636658856
Validation loss: 2.4506252666242605

Epoch: 5| Step: 1
Training loss: 2.4103608129608367
Validation loss: 2.450392088092364

Epoch: 5| Step: 2
Training loss: 2.2518821897029313
Validation loss: 2.436567349483831

Epoch: 5| Step: 3
Training loss: 2.4052758164574106
Validation loss: 2.4342193476245892

Epoch: 5| Step: 4
Training loss: 3.1142484725185278
Validation loss: 2.431421330294219

Epoch: 5| Step: 5
Training loss: 1.784352060895405
Validation loss: 2.4448796276749145

Epoch: 5| Step: 6
Training loss: 2.430847872155614
Validation loss: 2.4433534835786763

Epoch: 5| Step: 7
Training loss: 2.296067699324829
Validation loss: 2.446618929037349

Epoch: 5| Step: 8
Training loss: 2.725937211442167
Validation loss: 2.45955521189021

Epoch: 5| Step: 9
Training loss: 2.8124231963797106
Validation loss: 2.4785113572882045

Epoch: 5| Step: 10
Training loss: 2.562168658164337
Validation loss: 2.498238308914384

Epoch: 186| Step: 0
Training loss: 2.7125293993784982
Validation loss: 2.487134891980444

Epoch: 5| Step: 1
Training loss: 2.621751046234443
Validation loss: 2.5016748376155546

Epoch: 5| Step: 2
Training loss: 2.572725317219335
Validation loss: 2.48320926541607

Epoch: 5| Step: 3
Training loss: 2.6297986810020455
Validation loss: 2.499866663545738

Epoch: 5| Step: 4
Training loss: 2.0403340200842566
Validation loss: 2.5054976158766524

Epoch: 5| Step: 5
Training loss: 2.578802401240932
Validation loss: 2.5122720748769454

Epoch: 5| Step: 6
Training loss: 2.7824332474124427
Validation loss: 2.50844661360233

Epoch: 5| Step: 7
Training loss: 2.409585795600535
Validation loss: 2.516098292835855

Epoch: 5| Step: 8
Training loss: 1.9012174620844313
Validation loss: 2.50707047358087

Epoch: 5| Step: 9
Training loss: 2.4603724239634146
Validation loss: 2.5186258988833456

Epoch: 5| Step: 10
Training loss: 2.3939112596501126
Validation loss: 2.5063657214117887

Epoch: 187| Step: 0
Training loss: 2.756335676249984
Validation loss: 2.510059326321191

Epoch: 5| Step: 1
Training loss: 2.70254960303082
Validation loss: 2.4936876611851395

Epoch: 5| Step: 2
Training loss: 2.737955680789417
Validation loss: 2.4843803019256474

Epoch: 5| Step: 3
Training loss: 2.009823871506237
Validation loss: 2.459411390621969

Epoch: 5| Step: 4
Training loss: 2.6848779351531724
Validation loss: 2.4496035162342027

Epoch: 5| Step: 5
Training loss: 2.1517920366792445
Validation loss: 2.4659973370795227

Epoch: 5| Step: 6
Training loss: 2.582298645855417
Validation loss: 2.4663370328195287

Epoch: 5| Step: 7
Training loss: 2.6474019504506217
Validation loss: 2.463603759710159

Epoch: 5| Step: 8
Training loss: 2.1440740490552166
Validation loss: 2.474467435222463

Epoch: 5| Step: 9
Training loss: 2.077160948665013
Validation loss: 2.4644925994047253

Epoch: 5| Step: 10
Training loss: 2.520420786830641
Validation loss: 2.458597336600854

Epoch: 188| Step: 0
Training loss: 2.9019694645311636
Validation loss: 2.4576129563505744

Epoch: 5| Step: 1
Training loss: 2.2204439386043644
Validation loss: 2.458074956225847

Epoch: 5| Step: 2
Training loss: 2.397638343105276
Validation loss: 2.4720857762405584

Epoch: 5| Step: 3
Training loss: 2.014035448317347
Validation loss: 2.486629758717259

Epoch: 5| Step: 4
Training loss: 2.3378426938095163
Validation loss: 2.4832878940975935

Epoch: 5| Step: 5
Training loss: 2.409745488953803
Validation loss: 2.4947015009291147

Epoch: 5| Step: 6
Training loss: 2.5176684686684707
Validation loss: 2.47493825126743

Epoch: 5| Step: 7
Training loss: 2.5213559662428273
Validation loss: 2.47442555564908

Epoch: 5| Step: 8
Training loss: 2.6287887116183435
Validation loss: 2.490968987344277

Epoch: 5| Step: 9
Training loss: 2.4066710661040416
Validation loss: 2.525071321038781

Epoch: 5| Step: 10
Training loss: 2.3360378282109995
Validation loss: 2.5276267948185267

Epoch: 189| Step: 0
Training loss: 2.626034759750473
Validation loss: 2.531934118297537

Epoch: 5| Step: 1
Training loss: 2.561433895987875
Validation loss: 2.543170820428713

Epoch: 5| Step: 2
Training loss: 2.667080151767042
Validation loss: 2.544305961842392

Epoch: 5| Step: 3
Training loss: 2.4441805526108307
Validation loss: 2.5527636232613427

Epoch: 5| Step: 4
Training loss: 2.542103609976387
Validation loss: 2.555173378816307

Epoch: 5| Step: 5
Training loss: 2.889115717940843
Validation loss: 2.5613193077913485

Epoch: 5| Step: 6
Training loss: 2.669740415377129
Validation loss: 2.5396577627951498

Epoch: 5| Step: 7
Training loss: 1.84002373659331
Validation loss: 2.550332974227497

Epoch: 5| Step: 8
Training loss: 1.673600064457077
Validation loss: 2.5576205463897397

Epoch: 5| Step: 9
Training loss: 2.548789492493383
Validation loss: 2.5664170483281943

Epoch: 5| Step: 10
Training loss: 2.1347415011788824
Validation loss: 2.541102861407047

Epoch: 190| Step: 0
Training loss: 2.7398517801054534
Validation loss: 2.4917962431323915

Epoch: 5| Step: 1
Training loss: 2.515471364891986
Validation loss: 2.482677902942787

Epoch: 5| Step: 2
Training loss: 2.2879221292195586
Validation loss: 2.4754126765616253

Epoch: 5| Step: 3
Training loss: 2.3944836560446476
Validation loss: 2.472370783825074

Epoch: 5| Step: 4
Training loss: 1.9018890025325088
Validation loss: 2.462177923042616

Epoch: 5| Step: 5
Training loss: 2.6927359387122096
Validation loss: 2.453946268400122

Epoch: 5| Step: 6
Training loss: 2.354236084131207
Validation loss: 2.4625629131133695

Epoch: 5| Step: 7
Training loss: 2.0575299346340707
Validation loss: 2.466587492856433

Epoch: 5| Step: 8
Training loss: 2.296627420589305
Validation loss: 2.485723486423328

Epoch: 5| Step: 9
Training loss: 2.659222992296812
Validation loss: 2.5063654851330166

Epoch: 5| Step: 10
Training loss: 2.7569551080667796
Validation loss: 2.5309656728665613

Epoch: 191| Step: 0
Training loss: 2.6037197390742297
Validation loss: 2.547343221304666

Epoch: 5| Step: 1
Training loss: 2.562159631965833
Validation loss: 2.5716515155267468

Epoch: 5| Step: 2
Training loss: 2.110261631876072
Validation loss: 2.6058461073017734

Epoch: 5| Step: 3
Training loss: 2.1284211612265285
Validation loss: 2.646573586586074

Epoch: 5| Step: 4
Training loss: 2.639172306791526
Validation loss: 2.6765567540481583

Epoch: 5| Step: 5
Training loss: 2.678190385872699
Validation loss: 2.665622019794046

Epoch: 5| Step: 6
Training loss: 2.316926894449286
Validation loss: 2.6278844085710724

Epoch: 5| Step: 7
Training loss: 2.951214530631507
Validation loss: 2.555817084549584

Epoch: 5| Step: 8
Training loss: 2.2876282452764096
Validation loss: 2.4860733778538098

Epoch: 5| Step: 9
Training loss: 2.0830634387351052
Validation loss: 2.4388127689911374

Epoch: 5| Step: 10
Training loss: 2.1887628452309706
Validation loss: 2.423214072035059

Epoch: 192| Step: 0
Training loss: 2.296216286384234
Validation loss: 2.3975620754445788

Epoch: 5| Step: 1
Training loss: 2.207913652763414
Validation loss: 2.3963435906139576

Epoch: 5| Step: 2
Training loss: 2.116514429740281
Validation loss: 2.3978628592703437

Epoch: 5| Step: 3
Training loss: 2.5009930545690615
Validation loss: 2.4216128109137602

Epoch: 5| Step: 4
Training loss: 2.5319403189786343
Validation loss: 2.4399399378996303

Epoch: 5| Step: 5
Training loss: 2.3910642731442593
Validation loss: 2.4472248298005037

Epoch: 5| Step: 6
Training loss: 2.467017326260119
Validation loss: 2.457076522253817

Epoch: 5| Step: 7
Training loss: 2.5291357747620817
Validation loss: 2.4634975896043327

Epoch: 5| Step: 8
Training loss: 2.9433488446954135
Validation loss: 2.453935645855229

Epoch: 5| Step: 9
Training loss: 2.5510180890598266
Validation loss: 2.473154955710597

Epoch: 5| Step: 10
Training loss: 2.2761731026159917
Validation loss: 2.4759155569192295

Epoch: 193| Step: 0
Training loss: 2.3801108130935797
Validation loss: 2.4767317968469427

Epoch: 5| Step: 1
Training loss: 2.606275899561716
Validation loss: 2.4916851823183084

Epoch: 5| Step: 2
Training loss: 1.8102864527725768
Validation loss: 2.5183004771786583

Epoch: 5| Step: 3
Training loss: 2.1291691888942323
Validation loss: 2.5562859199407764

Epoch: 5| Step: 4
Training loss: 2.3316861764756482
Validation loss: 2.6016054936688815

Epoch: 5| Step: 5
Training loss: 2.406261691771007
Validation loss: 2.601656844699104

Epoch: 5| Step: 6
Training loss: 2.93307470207405
Validation loss: 2.619597825348587

Epoch: 5| Step: 7
Training loss: 2.4126844701258543
Validation loss: 2.5958012123815406

Epoch: 5| Step: 8
Training loss: 2.628973723363314
Validation loss: 2.5307626137280157

Epoch: 5| Step: 9
Training loss: 2.016290244394366
Validation loss: 2.5188050910398494

Epoch: 5| Step: 10
Training loss: 2.333564803586007
Validation loss: 2.5174198548776987

Epoch: 194| Step: 0
Training loss: 2.7693342776394103
Validation loss: 2.5187902596098755

Epoch: 5| Step: 1
Training loss: 2.5022488969397765
Validation loss: 2.51233749896743

Epoch: 5| Step: 2
Training loss: 2.5553168125403105
Validation loss: 2.488551816137233

Epoch: 5| Step: 3
Training loss: 2.2237335972987795
Validation loss: 2.4657393759423347

Epoch: 5| Step: 4
Training loss: 2.0323672229897953
Validation loss: 2.4558440784111117

Epoch: 5| Step: 5
Training loss: 2.663777982223804
Validation loss: 2.4299510196577256

Epoch: 5| Step: 6
Training loss: 2.1729403291208156
Validation loss: 2.4453122525799995

Epoch: 5| Step: 7
Training loss: 2.197221462229798
Validation loss: 2.456628180090077

Epoch: 5| Step: 8
Training loss: 2.2555469379145587
Validation loss: 2.479929649338978

Epoch: 5| Step: 9
Training loss: 2.365282053510209
Validation loss: 2.5022619269372126

Epoch: 5| Step: 10
Training loss: 2.1077379443964412
Validation loss: 2.5064200915312016

Epoch: 195| Step: 0
Training loss: 2.370775179381604
Validation loss: 2.5293169539080593

Epoch: 5| Step: 1
Training loss: 2.1510445607853246
Validation loss: 2.5294649855780764

Epoch: 5| Step: 2
Training loss: 2.6256158197211135
Validation loss: 2.5619113505120827

Epoch: 5| Step: 3
Training loss: 1.5788651798424
Validation loss: 2.57008648823207

Epoch: 5| Step: 4
Training loss: 1.7794470781226148
Validation loss: 2.604100264820435

Epoch: 5| Step: 5
Training loss: 2.600395330304769
Validation loss: 2.638861289327087

Epoch: 5| Step: 6
Training loss: 2.6178098024151972
Validation loss: 2.5895125993219215

Epoch: 5| Step: 7
Training loss: 1.4487052069281765
Validation loss: 2.5525477874275233

Epoch: 5| Step: 8
Training loss: 2.423269842313937
Validation loss: 2.5395166901785315

Epoch: 5| Step: 9
Training loss: 2.792054353430858
Validation loss: 2.500475873058366

Epoch: 5| Step: 10
Training loss: 2.7056429386932117
Validation loss: 2.4591422647165726

Epoch: 196| Step: 0
Training loss: 2.4846477238893674
Validation loss: 2.4233990909995606

Epoch: 5| Step: 1
Training loss: 3.037732615413842
Validation loss: 2.4149179615143046

Epoch: 5| Step: 2
Training loss: 2.136488209897896
Validation loss: 2.4215776814728094

Epoch: 5| Step: 3
Training loss: 1.8367994517092934
Validation loss: 2.4043489875389565

Epoch: 5| Step: 4
Training loss: 2.1435970641098803
Validation loss: 2.413197570957714

Epoch: 5| Step: 5
Training loss: 2.0584635684347785
Validation loss: 2.409309216426392

Epoch: 5| Step: 6
Training loss: 2.512749301821113
Validation loss: 2.42506452397832

Epoch: 5| Step: 7
Training loss: 2.0787431758325887
Validation loss: 2.4503347301707366

Epoch: 5| Step: 8
Training loss: 1.9168357221710512
Validation loss: 2.465285359594886

Epoch: 5| Step: 9
Training loss: 2.6348138554529736
Validation loss: 2.4834185468455776

Epoch: 5| Step: 10
Training loss: 2.615979545017497
Validation loss: 2.496453411134079

Epoch: 197| Step: 0
Training loss: 2.200139396759519
Validation loss: 2.5359520899802845

Epoch: 5| Step: 1
Training loss: 2.040828480878954
Validation loss: 2.550615581643988

Epoch: 5| Step: 2
Training loss: 2.525591235295029
Validation loss: 2.5604167136190457

Epoch: 5| Step: 3
Training loss: 2.040179534940501
Validation loss: 2.579860738616055

Epoch: 5| Step: 4
Training loss: 2.2750261661575806
Validation loss: 2.578303407802349

Epoch: 5| Step: 5
Training loss: 2.4662441622108626
Validation loss: 2.585046223804971

Epoch: 5| Step: 6
Training loss: 2.3039205018408273
Validation loss: 2.6227014696735944

Epoch: 5| Step: 7
Training loss: 1.8902987994799414
Validation loss: 2.6532427022389578

Epoch: 5| Step: 8
Training loss: 2.8970973780274347
Validation loss: 2.615894385213085

Epoch: 5| Step: 9
Training loss: 2.455682963762212
Validation loss: 2.584380246005677

Epoch: 5| Step: 10
Training loss: 2.097116752594197
Validation loss: 2.5302172130917486

Epoch: 198| Step: 0
Training loss: 2.0036202090867277
Validation loss: 2.5029404841587275

Epoch: 5| Step: 1
Training loss: 2.1362525110469948
Validation loss: 2.4658167900938324

Epoch: 5| Step: 2
Training loss: 2.2886526111860492
Validation loss: 2.4401001567682647

Epoch: 5| Step: 3
Training loss: 2.2765091009429383
Validation loss: 2.4417074274495767

Epoch: 5| Step: 4
Training loss: 2.8049105499747
Validation loss: 2.4600102847444814

Epoch: 5| Step: 5
Training loss: 2.095172000643449
Validation loss: 2.491565040397792

Epoch: 5| Step: 6
Training loss: 2.291008548449216
Validation loss: 2.5246510756098957

Epoch: 5| Step: 7
Training loss: 2.2714750334005567
Validation loss: 2.5585371078662926

Epoch: 5| Step: 8
Training loss: 2.397256168858397
Validation loss: 2.6214850674168204

Epoch: 5| Step: 9
Training loss: 1.8755803799430184
Validation loss: 2.648764775891616

Epoch: 5| Step: 10
Training loss: 2.661822767495357
Validation loss: 2.6426024828768075

Epoch: 199| Step: 0
Training loss: 2.3994247939320457
Validation loss: 2.6257884359677726

Epoch: 5| Step: 1
Training loss: 1.852509590360911
Validation loss: 2.5760157722874224

Epoch: 5| Step: 2
Training loss: 2.079475365645307
Validation loss: 2.5366721468164726

Epoch: 5| Step: 3
Training loss: 2.3322297847205777
Validation loss: 2.5243043270765306

Epoch: 5| Step: 4
Training loss: 2.2868839872798215
Validation loss: 2.4818563574507437

Epoch: 5| Step: 5
Training loss: 1.8898446230119548
Validation loss: 2.468603809743288

Epoch: 5| Step: 6
Training loss: 2.6142676620098353
Validation loss: 2.4898789657167355

Epoch: 5| Step: 7
Training loss: 2.1090894717776623
Validation loss: 2.505823107315106

Epoch: 5| Step: 8
Training loss: 2.527872068674987
Validation loss: 2.5246306981143394

Epoch: 5| Step: 9
Training loss: 2.1908883147403966
Validation loss: 2.4994287699620465

Epoch: 5| Step: 10
Training loss: 2.53139222298894
Validation loss: 2.5093039717723444

Epoch: 200| Step: 0
Training loss: 1.8357210072240078
Validation loss: 2.49148107641342

Epoch: 5| Step: 1
Training loss: 2.1061187476853735
Validation loss: 2.471771339533026

Epoch: 5| Step: 2
Training loss: 1.6089493271913453
Validation loss: 2.477577477402183

Epoch: 5| Step: 3
Training loss: 2.592997430296249
Validation loss: 2.4733242816072276

Epoch: 5| Step: 4
Training loss: 2.18283346243905
Validation loss: 2.4827612048601715

Epoch: 5| Step: 5
Training loss: 2.1570943754769645
Validation loss: 2.4827257418028994

Epoch: 5| Step: 6
Training loss: 2.247445139485896
Validation loss: 2.493392415952582

Epoch: 5| Step: 7
Training loss: 1.9921921075505848
Validation loss: 2.4960111821705455

Epoch: 5| Step: 8
Training loss: 2.5699085045643697
Validation loss: 2.5106367905612097

Epoch: 5| Step: 9
Training loss: 2.5349137905893793
Validation loss: 2.496603003240486

Epoch: 5| Step: 10
Training loss: 2.5821791706045505
Validation loss: 2.503752882864992

Epoch: 201| Step: 0
Training loss: 2.0337943940572223
Validation loss: 2.5254594570635565

Epoch: 5| Step: 1
Training loss: 2.369090910764979
Validation loss: 2.505845338598604

Epoch: 5| Step: 2
Training loss: 2.516189227594964
Validation loss: 2.5311395359483635

Epoch: 5| Step: 3
Training loss: 2.1949151925146317
Validation loss: 2.5256927002234857

Epoch: 5| Step: 4
Training loss: 2.316433422321658
Validation loss: 2.552634548373171

Epoch: 5| Step: 5
Training loss: 2.055635066971872
Validation loss: 2.5364201176809624

Epoch: 5| Step: 6
Training loss: 1.9859121781722477
Validation loss: 2.5255356669507667

Epoch: 5| Step: 7
Training loss: 2.7029036061905556
Validation loss: 2.532181957536292

Epoch: 5| Step: 8
Training loss: 2.0878377538397572
Validation loss: 2.5427850138616686

Epoch: 5| Step: 9
Training loss: 2.0661776728124477
Validation loss: 2.551532098347776

Epoch: 5| Step: 10
Training loss: 2.067976760416401
Validation loss: 2.575962864635862

Epoch: 202| Step: 0
Training loss: 2.192784819246815
Validation loss: 2.5810104307410557

Epoch: 5| Step: 1
Training loss: 1.8072025229449518
Validation loss: 2.616455582117037

Epoch: 5| Step: 2
Training loss: 2.7396361390646375
Validation loss: 2.626034153505254

Epoch: 5| Step: 3
Training loss: 2.4568920975475703
Validation loss: 2.5924080635146796

Epoch: 5| Step: 4
Training loss: 2.161081512573183
Validation loss: 2.561835268062256

Epoch: 5| Step: 5
Training loss: 2.155040346374223
Validation loss: 2.5496002288853754

Epoch: 5| Step: 6
Training loss: 2.07189788575572
Validation loss: 2.5387044189980217

Epoch: 5| Step: 7
Training loss: 2.189883323418014
Validation loss: 2.50356065615935

Epoch: 5| Step: 8
Training loss: 2.3029867847641547
Validation loss: 2.4820633639344254

Epoch: 5| Step: 9
Training loss: 2.1434087542864195
Validation loss: 2.4837258578807835

Epoch: 5| Step: 10
Training loss: 1.7161936389089925
Validation loss: 2.4625086958953246

Epoch: 203| Step: 0
Training loss: 2.0831626695030527
Validation loss: 2.473058181151076

Epoch: 5| Step: 1
Training loss: 1.6785229571570497
Validation loss: 2.5112413343596733

Epoch: 5| Step: 2
Training loss: 1.82547195811742
Validation loss: 2.540217688758873

Epoch: 5| Step: 3
Training loss: 2.7165570238918963
Validation loss: 2.543867593239047

Epoch: 5| Step: 4
Training loss: 2.3657388314559253
Validation loss: 2.5832845152001047

Epoch: 5| Step: 5
Training loss: 2.582728951009204
Validation loss: 2.5868508951719735

Epoch: 5| Step: 6
Training loss: 2.2354501125065105
Validation loss: 2.6052794899625678

Epoch: 5| Step: 7
Training loss: 2.4489245565062783
Validation loss: 2.6316798352179593

Epoch: 5| Step: 8
Training loss: 1.459348579510658
Validation loss: 2.56939945959437

Epoch: 5| Step: 9
Training loss: 2.1570698381983915
Validation loss: 2.5395752243185354

Epoch: 5| Step: 10
Training loss: 2.3776140383417625
Validation loss: 2.510218979170454

Epoch: 204| Step: 0
Training loss: 2.5373053001536383
Validation loss: 2.47724368296557

Epoch: 5| Step: 1
Training loss: 2.31930571526362
Validation loss: 2.472195108472486

Epoch: 5| Step: 2
Training loss: 2.312212745764811
Validation loss: 2.4682686002639107

Epoch: 5| Step: 3
Training loss: 2.278245593569565
Validation loss: 2.467992893657637

Epoch: 5| Step: 4
Training loss: 1.9626716149974377
Validation loss: 2.4701993869158065

Epoch: 5| Step: 5
Training loss: 2.305068783013077
Validation loss: 2.4619932140522294

Epoch: 5| Step: 6
Training loss: 2.2991757450106576
Validation loss: 2.4793284332313705

Epoch: 5| Step: 7
Training loss: 2.013057167215522
Validation loss: 2.475519156881585

Epoch: 5| Step: 8
Training loss: 2.1533978160655405
Validation loss: 2.519665423037989

Epoch: 5| Step: 9
Training loss: 1.796730765483252
Validation loss: 2.5319712107804873

Epoch: 5| Step: 10
Training loss: 1.650964327985397
Validation loss: 2.5598234368923523

Epoch: 205| Step: 0
Training loss: 1.9070759219102766
Validation loss: 2.5836926225964114

Epoch: 5| Step: 1
Training loss: 1.898484531652022
Validation loss: 2.5864991367310792

Epoch: 5| Step: 2
Training loss: 1.8129851908597079
Validation loss: 2.6036618720942237

Epoch: 5| Step: 3
Training loss: 2.218061958335065
Validation loss: 2.5995598385346637

Epoch: 5| Step: 4
Training loss: 2.466024802009744
Validation loss: 2.5920359975856515

Epoch: 5| Step: 5
Training loss: 2.2569502401685066
Validation loss: 2.591717953572301

Epoch: 5| Step: 6
Training loss: 2.2770268267164053
Validation loss: 2.577877436759278

Epoch: 5| Step: 7
Training loss: 1.997578704963996
Validation loss: 2.5558788528057907

Epoch: 5| Step: 8
Training loss: 2.1008798844918526
Validation loss: 2.5460498166811463

Epoch: 5| Step: 9
Training loss: 2.4766407662428294
Validation loss: 2.5233647922627376

Epoch: 5| Step: 10
Training loss: 1.906878508467996
Validation loss: 2.5248651042665045

Epoch: 206| Step: 0
Training loss: 1.5791714664007166
Validation loss: 2.502681848307347

Epoch: 5| Step: 1
Training loss: 2.5073366278143516
Validation loss: 2.5060020957754494

Epoch: 5| Step: 2
Training loss: 2.5983686574509
Validation loss: 2.5026461302469594

Epoch: 5| Step: 3
Training loss: 1.6383935194062424
Validation loss: 2.516924487362697

Epoch: 5| Step: 4
Training loss: 1.9503480013852832
Validation loss: 2.521043954943947

Epoch: 5| Step: 5
Training loss: 2.1567561343393122
Validation loss: 2.5098375740015144

Epoch: 5| Step: 6
Training loss: 1.520683890886662
Validation loss: 2.5521223984809622

Epoch: 5| Step: 7
Training loss: 2.5099515259761978
Validation loss: 2.531332095936807

Epoch: 5| Step: 8
Training loss: 2.6285802857326765
Validation loss: 2.540511237992996

Epoch: 5| Step: 9
Training loss: 1.608479519197549
Validation loss: 2.5392938833768675

Epoch: 5| Step: 10
Training loss: 2.0373123082495757
Validation loss: 2.5484985968339853

Epoch: 207| Step: 0
Training loss: 2.126304786868848
Validation loss: 2.5498840767338216

Epoch: 5| Step: 1
Training loss: 2.1793024413466284
Validation loss: 2.5494619588870244

Epoch: 5| Step: 2
Training loss: 2.0668191479247215
Validation loss: 2.5180862311027674

Epoch: 5| Step: 3
Training loss: 2.134702634449214
Validation loss: 2.5114932015029363

Epoch: 5| Step: 4
Training loss: 1.9198928784250113
Validation loss: 2.5011793656759025

Epoch: 5| Step: 5
Training loss: 2.013318183391404
Validation loss: 2.5165906054303093

Epoch: 5| Step: 6
Training loss: 2.178291119626406
Validation loss: 2.5345742544364347

Epoch: 5| Step: 7
Training loss: 2.3906612019509224
Validation loss: 2.54942520132921

Epoch: 5| Step: 8
Training loss: 1.7582745432253315
Validation loss: 2.5428456605144287

Epoch: 5| Step: 9
Training loss: 2.0768319603096264
Validation loss: 2.562019026883113

Epoch: 5| Step: 10
Training loss: 2.0179770297812136
Validation loss: 2.556273977652256

Epoch: 208| Step: 0
Training loss: 1.994186714678412
Validation loss: 2.5462731181739127

Epoch: 5| Step: 1
Training loss: 2.13497379331563
Validation loss: 2.5507595460396724

Epoch: 5| Step: 2
Training loss: 1.6395770404441243
Validation loss: 2.5707552963839087

Epoch: 5| Step: 3
Training loss: 1.9935888410624851
Validation loss: 2.6226736870751015

Epoch: 5| Step: 4
Training loss: 2.10894364079017
Validation loss: 2.5952223191706247

Epoch: 5| Step: 5
Training loss: 2.606611696023018
Validation loss: 2.6029213022345976

Epoch: 5| Step: 6
Training loss: 1.752799179616864
Validation loss: 2.5326279809321064

Epoch: 5| Step: 7
Training loss: 2.2294813866840326
Validation loss: 2.470627856239917

Epoch: 5| Step: 8
Training loss: 2.0523907839377658
Validation loss: 2.4610367314336377

Epoch: 5| Step: 9
Training loss: 2.269971269770231
Validation loss: 2.429386595752081

Epoch: 5| Step: 10
Training loss: 1.98244683010386
Validation loss: 2.4298718804579393

Epoch: 209| Step: 0
Training loss: 1.8520484640688775
Validation loss: 2.4684152860417377

Epoch: 5| Step: 1
Training loss: 2.4572472409162907
Validation loss: 2.4726398239830414

Epoch: 5| Step: 2
Training loss: 1.9735130337888072
Validation loss: 2.4755101585614123

Epoch: 5| Step: 3
Training loss: 2.046131494034865
Validation loss: 2.522195418728323

Epoch: 5| Step: 4
Training loss: 2.3378163822275946
Validation loss: 2.5416134361880727

Epoch: 5| Step: 5
Training loss: 2.17923844063054
Validation loss: 2.5572906940911895

Epoch: 5| Step: 6
Training loss: 2.1753130808027885
Validation loss: 2.584145275129716

Epoch: 5| Step: 7
Training loss: 2.0854879173380594
Validation loss: 2.5910978856470925

Epoch: 5| Step: 8
Training loss: 2.042664018299753
Validation loss: 2.581113231161779

Epoch: 5| Step: 9
Training loss: 2.083464224200394
Validation loss: 2.5518267561360837

Epoch: 5| Step: 10
Training loss: 1.7644746797236117
Validation loss: 2.5059195935435685

Epoch: 210| Step: 0
Training loss: 2.049811666257772
Validation loss: 2.470731616209568

Epoch: 5| Step: 1
Training loss: 1.843252729179238
Validation loss: 2.4615886586570923

Epoch: 5| Step: 2
Training loss: 2.210782426443804
Validation loss: 2.4619911044045977

Epoch: 5| Step: 3
Training loss: 2.1683669265893206
Validation loss: 2.4766983839121908

Epoch: 5| Step: 4
Training loss: 1.921448016612743
Validation loss: 2.493641328506305

Epoch: 5| Step: 5
Training loss: 1.5704961261331072
Validation loss: 2.5265534468069744

Epoch: 5| Step: 6
Training loss: 2.446592440800187
Validation loss: 2.5769623193987794

Epoch: 5| Step: 7
Training loss: 2.2824338166751827
Validation loss: 2.612063212895045

Epoch: 5| Step: 8
Training loss: 2.186607941889543
Validation loss: 2.63860257917594

Epoch: 5| Step: 9
Training loss: 1.9654497004758753
Validation loss: 2.661891078418242

Epoch: 5| Step: 10
Training loss: 2.0638575854294237
Validation loss: 2.6864344398720994

Epoch: 211| Step: 0
Training loss: 1.7885680202467327
Validation loss: 2.6903026816372213

Epoch: 5| Step: 1
Training loss: 1.6783205369513916
Validation loss: 2.6745071346565457

Epoch: 5| Step: 2
Training loss: 2.1478981034530906
Validation loss: 2.6741875072504873

Epoch: 5| Step: 3
Training loss: 1.7831029790727937
Validation loss: 2.6465248933346808

Epoch: 5| Step: 4
Training loss: 2.1905539856200797
Validation loss: 2.630624014359623

Epoch: 5| Step: 5
Training loss: 2.0499129718822844
Validation loss: 2.6262572696280597

Epoch: 5| Step: 6
Training loss: 1.8016121823556208
Validation loss: 2.5796660281510753

Epoch: 5| Step: 7
Training loss: 2.0505534890264734
Validation loss: 2.5578910703765

Epoch: 5| Step: 8
Training loss: 2.0037044549954843
Validation loss: 2.526670807938322

Epoch: 5| Step: 9
Training loss: 2.587157177904658
Validation loss: 2.4816548222299697

Epoch: 5| Step: 10
Training loss: 2.0335078675244747
Validation loss: 2.4753271000073034

Epoch: 212| Step: 0
Training loss: 1.4443608630688152
Validation loss: 2.460176401312351

Epoch: 5| Step: 1
Training loss: 2.448771702123555
Validation loss: 2.457242367667444

Epoch: 5| Step: 2
Training loss: 1.927064108537886
Validation loss: 2.4504612781206876

Epoch: 5| Step: 3
Training loss: 2.181840605692795
Validation loss: 2.464298859241052

Epoch: 5| Step: 4
Training loss: 1.985750757737143
Validation loss: 2.453397616701316

Epoch: 5| Step: 5
Training loss: 1.7582224728075506
Validation loss: 2.4666924719581735

Epoch: 5| Step: 6
Training loss: 1.924732286242168
Validation loss: 2.4619272924365174

Epoch: 5| Step: 7
Training loss: 2.0477957947595535
Validation loss: 2.4821574862607774

Epoch: 5| Step: 8
Training loss: 2.007799794197699
Validation loss: 2.483946623154075

Epoch: 5| Step: 9
Training loss: 2.2627526326630436
Validation loss: 2.505315881729522

Epoch: 5| Step: 10
Training loss: 1.987093647616587
Validation loss: 2.5178673982299697

Epoch: 213| Step: 0
Training loss: 1.9855567236938816
Validation loss: 2.50526479495801

Epoch: 5| Step: 1
Training loss: 2.111657158464655
Validation loss: 2.5337399048668403

Epoch: 5| Step: 2
Training loss: 1.465533447659625
Validation loss: 2.5277178036892467

Epoch: 5| Step: 3
Training loss: 2.039268746304253
Validation loss: 2.538461915729018

Epoch: 5| Step: 4
Training loss: 1.9485695164794554
Validation loss: 2.5381257611580095

Epoch: 5| Step: 5
Training loss: 2.28494308651219
Validation loss: 2.5563734465478536

Epoch: 5| Step: 6
Training loss: 1.9126416596450677
Validation loss: 2.5683731436199535

Epoch: 5| Step: 7
Training loss: 2.3756129829004444
Validation loss: 2.579374503902355

Epoch: 5| Step: 8
Training loss: 1.8759688735160946
Validation loss: 2.5740367654468717

Epoch: 5| Step: 9
Training loss: 1.70099597814265
Validation loss: 2.5730355832157543

Epoch: 5| Step: 10
Training loss: 1.9326616603057925
Validation loss: 2.5554451650719687

Epoch: 214| Step: 0
Training loss: 1.8319148370321559
Validation loss: 2.5609422636584367

Epoch: 5| Step: 1
Training loss: 2.158945582486323
Validation loss: 2.5497663945472504

Epoch: 5| Step: 2
Training loss: 2.000215757176297
Validation loss: 2.543840184693821

Epoch: 5| Step: 3
Training loss: 1.9180780134912716
Validation loss: 2.5328298520419965

Epoch: 5| Step: 4
Training loss: 1.58277826451052
Validation loss: 2.526260877628466

Epoch: 5| Step: 5
Training loss: 1.7940469130566705
Validation loss: 2.528359025573509

Epoch: 5| Step: 6
Training loss: 1.5388061774726547
Validation loss: 2.5361044237317882

Epoch: 5| Step: 7
Training loss: 2.1265438306046422
Validation loss: 2.553524153227757

Epoch: 5| Step: 8
Training loss: 2.2017170621007165
Validation loss: 2.549117070219005

Epoch: 5| Step: 9
Training loss: 2.1194319986178223
Validation loss: 2.5319619493545753

Epoch: 5| Step: 10
Training loss: 2.2677751532753394
Validation loss: 2.492485709268146

Epoch: 215| Step: 0
Training loss: 2.2138137709976173
Validation loss: 2.4987988950175017

Epoch: 5| Step: 1
Training loss: 1.9665807853417232
Validation loss: 2.5040187222035315

Epoch: 5| Step: 2
Training loss: 1.5832703059183493
Validation loss: 2.5044996754924087

Epoch: 5| Step: 3
Training loss: 1.807512458557837
Validation loss: 2.504432055670127

Epoch: 5| Step: 4
Training loss: 1.5971351277290837
Validation loss: 2.5122093074150516

Epoch: 5| Step: 5
Training loss: 2.091259514239205
Validation loss: 2.5471456517148066

Epoch: 5| Step: 6
Training loss: 2.0071305478702297
Validation loss: 2.5756064942731496

Epoch: 5| Step: 7
Training loss: 2.3517214699173694
Validation loss: 2.6007117877498036

Epoch: 5| Step: 8
Training loss: 1.8697781008880892
Validation loss: 2.6132443315973135

Epoch: 5| Step: 9
Training loss: 2.1272789571577495
Validation loss: 2.648763483310661

Epoch: 5| Step: 10
Training loss: 1.5615974108152735
Validation loss: 2.617130482296981

Epoch: 216| Step: 0
Training loss: 2.211118980481038
Validation loss: 2.6502260177915846

Epoch: 5| Step: 1
Training loss: 1.708359121112488
Validation loss: 2.6003732428751944

Epoch: 5| Step: 2
Training loss: 1.5253774957421529
Validation loss: 2.5598541404253057

Epoch: 5| Step: 3
Training loss: 1.4393184604050093
Validation loss: 2.5504813581829477

Epoch: 5| Step: 4
Training loss: 1.7292421699799985
Validation loss: 2.50658097746217

Epoch: 5| Step: 5
Training loss: 2.03017725861204
Validation loss: 2.4930418570600485

Epoch: 5| Step: 6
Training loss: 2.2779253418220358
Validation loss: 2.44613207555967

Epoch: 5| Step: 7
Training loss: 2.1929034390184365
Validation loss: 2.4575192031691757

Epoch: 5| Step: 8
Training loss: 1.8743971809278088
Validation loss: 2.440679054165335

Epoch: 5| Step: 9
Training loss: 1.976749577169203
Validation loss: 2.47835985703353

Epoch: 5| Step: 10
Training loss: 2.1282840484473033
Validation loss: 2.4633804074605856

Epoch: 217| Step: 0
Training loss: 2.013040586097467
Validation loss: 2.4958093195386253

Epoch: 5| Step: 1
Training loss: 2.099476853557635
Validation loss: 2.4776259377923884

Epoch: 5| Step: 2
Training loss: 1.1070526960902884
Validation loss: 2.493669399830257

Epoch: 5| Step: 3
Training loss: 2.2239114606028787
Validation loss: 2.5015098749940243

Epoch: 5| Step: 4
Training loss: 1.9821843347910568
Validation loss: 2.5489822589400726

Epoch: 5| Step: 5
Training loss: 1.7565247290282435
Validation loss: 2.5560087869068084

Epoch: 5| Step: 6
Training loss: 1.3582140031521024
Validation loss: 2.549162274914599

Epoch: 5| Step: 7
Training loss: 1.672988235760613
Validation loss: 2.5609081905682163

Epoch: 5| Step: 8
Training loss: 1.9315624317662292
Validation loss: 2.6058520947232635

Epoch: 5| Step: 9
Training loss: 2.1341870248884347
Validation loss: 2.5943544338109374

Epoch: 5| Step: 10
Training loss: 2.388497696372126
Validation loss: 2.5735940276165628

Epoch: 218| Step: 0
Training loss: 1.5732305184138158
Validation loss: 2.5744473206803065

Epoch: 5| Step: 1
Training loss: 1.8280860701108348
Validation loss: 2.5567977472066485

Epoch: 5| Step: 2
Training loss: 1.6092201825091177
Validation loss: 2.523863216763574

Epoch: 5| Step: 3
Training loss: 1.672179221166806
Validation loss: 2.525095137236732

Epoch: 5| Step: 4
Training loss: 2.090185861126114
Validation loss: 2.5870939659749577

Epoch: 5| Step: 5
Training loss: 2.2765217732260257
Validation loss: 2.6062540527966958

Epoch: 5| Step: 6
Training loss: 1.9375004922189394
Validation loss: 2.6359466148959148

Epoch: 5| Step: 7
Training loss: 2.042540992316127
Validation loss: 2.6184214289205685

Epoch: 5| Step: 8
Training loss: 1.766299296215578
Validation loss: 2.5705087896423606

Epoch: 5| Step: 9
Training loss: 2.2364490193168765
Validation loss: 2.5408347220868674

Epoch: 5| Step: 10
Training loss: 1.6939710240593795
Validation loss: 2.499227982958976

Epoch: 219| Step: 0
Training loss: 2.0031891668221777
Validation loss: 2.4880324462262955

Epoch: 5| Step: 1
Training loss: 1.8378207672820541
Validation loss: 2.4655386205609124

Epoch: 5| Step: 2
Training loss: 1.9707121380995885
Validation loss: 2.4667437672586785

Epoch: 5| Step: 3
Training loss: 1.7804960696512584
Validation loss: 2.4419729569505484

Epoch: 5| Step: 4
Training loss: 1.819776267772812
Validation loss: 2.4360742061662335

Epoch: 5| Step: 5
Training loss: 1.9079191060941683
Validation loss: 2.442630145175032

Epoch: 5| Step: 6
Training loss: 1.9445914038874903
Validation loss: 2.45836524636766

Epoch: 5| Step: 7
Training loss: 1.9627629632382049
Validation loss: 2.4823472682976764

Epoch: 5| Step: 8
Training loss: 1.524056333396815
Validation loss: 2.4843644611250943

Epoch: 5| Step: 9
Training loss: 1.4794536724050282
Validation loss: 2.4948767475139797

Epoch: 5| Step: 10
Training loss: 2.382534223472831
Validation loss: 2.460576915090528

Epoch: 220| Step: 0
Training loss: 1.5685093334140405
Validation loss: 2.469143883968882

Epoch: 5| Step: 1
Training loss: 1.6777076585838482
Validation loss: 2.47267898994677

Epoch: 5| Step: 2
Training loss: 1.9807438706333627
Validation loss: 2.475393506759211

Epoch: 5| Step: 3
Training loss: 2.019505867715553
Validation loss: 2.514269745576347

Epoch: 5| Step: 4
Training loss: 1.9397610422816427
Validation loss: 2.5445900768606693

Epoch: 5| Step: 5
Training loss: 2.422775790141728
Validation loss: 2.5845417523472793

Epoch: 5| Step: 6
Training loss: 1.5511013056260836
Validation loss: 2.622681352061701

Epoch: 5| Step: 7
Training loss: 1.6661757540920374
Validation loss: 2.619265876386075

Epoch: 5| Step: 8
Training loss: 1.4460430876246704
Validation loss: 2.606915233243559

Epoch: 5| Step: 9
Training loss: 1.149690061764923
Validation loss: 2.5975902153292423

Epoch: 5| Step: 10
Training loss: 2.562756316228847
Validation loss: 2.5988318520019766

Epoch: 221| Step: 0
Training loss: 1.700808428230468
Validation loss: 2.5644876278329076

Epoch: 5| Step: 1
Training loss: 1.3466175886612568
Validation loss: 2.578634228325458

Epoch: 5| Step: 2
Training loss: 1.6502057756364719
Validation loss: 2.56434630662835

Epoch: 5| Step: 3
Training loss: 2.2804524320807285
Validation loss: 2.5616197602391626

Epoch: 5| Step: 4
Training loss: 1.845370857162285
Validation loss: 2.5662991023500465

Epoch: 5| Step: 5
Training loss: 2.4748311534276586
Validation loss: 2.5302700666239715

Epoch: 5| Step: 6
Training loss: 1.9238548935320428
Validation loss: 2.5374712404263766

Epoch: 5| Step: 7
Training loss: 1.2010952560675399
Validation loss: 2.5355685336962153

Epoch: 5| Step: 8
Training loss: 1.387802431292946
Validation loss: 2.5082131199567055

Epoch: 5| Step: 9
Training loss: 1.8841256275569498
Validation loss: 2.496623763011734

Epoch: 5| Step: 10
Training loss: 1.908466363903776
Validation loss: 2.500929245474739

Epoch: 222| Step: 0
Training loss: 1.8579545565900253
Validation loss: 2.494461185312572

Epoch: 5| Step: 1
Training loss: 1.7173256260558751
Validation loss: 2.4801089942449424

Epoch: 5| Step: 2
Training loss: 1.5080403368283026
Validation loss: 2.500121181381311

Epoch: 5| Step: 3
Training loss: 1.6679241522872685
Validation loss: 2.467954493692672

Epoch: 5| Step: 4
Training loss: 1.2821754741732312
Validation loss: 2.4854251867993273

Epoch: 5| Step: 5
Training loss: 2.1718295524836897
Validation loss: 2.4968383362532536

Epoch: 5| Step: 6
Training loss: 1.857185035792511
Validation loss: 2.500940209655425

Epoch: 5| Step: 7
Training loss: 1.6992069638599865
Validation loss: 2.5257372695676032

Epoch: 5| Step: 8
Training loss: 1.9404886022723005
Validation loss: 2.5542030212510918

Epoch: 5| Step: 9
Training loss: 1.951959246827565
Validation loss: 2.563905197099273

Epoch: 5| Step: 10
Training loss: 1.9563191045188524
Validation loss: 2.563635271744725

Epoch: 223| Step: 0
Training loss: 1.7083409782176584
Validation loss: 2.5752941401653815

Epoch: 5| Step: 1
Training loss: 1.87075751674212
Validation loss: 2.5674946667847993

Epoch: 5| Step: 2
Training loss: 1.8162021317182888
Validation loss: 2.57970943842465

Epoch: 5| Step: 3
Training loss: 1.8875362923271952
Validation loss: 2.581157567601609

Epoch: 5| Step: 4
Training loss: 1.7496115389599953
Validation loss: 2.5641331744358644

Epoch: 5| Step: 5
Training loss: 1.454723996074389
Validation loss: 2.543488263451626

Epoch: 5| Step: 6
Training loss: 2.059125625261045
Validation loss: 2.5374930964372515

Epoch: 5| Step: 7
Training loss: 1.6071740813476731
Validation loss: 2.4862087269967663

Epoch: 5| Step: 8
Training loss: 1.8033797905532352
Validation loss: 2.4761518103773597

Epoch: 5| Step: 9
Training loss: 1.7366009423869853
Validation loss: 2.460924161610198

Epoch: 5| Step: 10
Training loss: 1.7117924056752802
Validation loss: 2.442084161173722

Epoch: 224| Step: 0
Training loss: 1.976454780870024
Validation loss: 2.4116417691848486

Epoch: 5| Step: 1
Training loss: 1.4434711996283454
Validation loss: 2.4276814645106466

Epoch: 5| Step: 2
Training loss: 1.5968517712361179
Validation loss: 2.417335912634822

Epoch: 5| Step: 3
Training loss: 2.026590725622035
Validation loss: 2.4225428956664077

Epoch: 5| Step: 4
Training loss: 1.5674960561943025
Validation loss: 2.4173324654019472

Epoch: 5| Step: 5
Training loss: 1.8978156181873902
Validation loss: 2.421430100070066

Epoch: 5| Step: 6
Training loss: 1.7484550468375695
Validation loss: 2.4365584735084567

Epoch: 5| Step: 7
Training loss: 2.0791783925594114
Validation loss: 2.462433580604583

Epoch: 5| Step: 8
Training loss: 1.7842521798910385
Validation loss: 2.513241847118846

Epoch: 5| Step: 9
Training loss: 1.2035215640764994
Validation loss: 2.5752315369754353

Epoch: 5| Step: 10
Training loss: 1.9096748353878081
Validation loss: 2.6007691230203243

Epoch: 225| Step: 0
Training loss: 1.548897317156185
Validation loss: 2.6203522219582758

Epoch: 5| Step: 1
Training loss: 1.8607837245129353
Validation loss: 2.633836049376161

Epoch: 5| Step: 2
Training loss: 1.862752587516932
Validation loss: 2.611880617295992

Epoch: 5| Step: 3
Training loss: 1.7510286441510114
Validation loss: 2.5864896869717033

Epoch: 5| Step: 4
Training loss: 1.4666560241284194
Validation loss: 2.585845960516089

Epoch: 5| Step: 5
Training loss: 1.8146266956892958
Validation loss: 2.5453397581708597

Epoch: 5| Step: 6
Training loss: 1.912812490427422
Validation loss: 2.5235759311463886

Epoch: 5| Step: 7
Training loss: 1.660402382949152
Validation loss: 2.511534546678526

Epoch: 5| Step: 8
Training loss: 1.8864966473057991
Validation loss: 2.5095329037915564

Epoch: 5| Step: 9
Training loss: 1.6778484123651036
Validation loss: 2.4984668665755527

Epoch: 5| Step: 10
Training loss: 1.6610645636745835
Validation loss: 2.4967234931462308

Epoch: 226| Step: 0
Training loss: 1.5825714319387674
Validation loss: 2.5046145059596867

Epoch: 5| Step: 1
Training loss: 1.928091709832618
Validation loss: 2.491340189969325

Epoch: 5| Step: 2
Training loss: 1.5878774869968866
Validation loss: 2.5128963282557075

Epoch: 5| Step: 3
Training loss: 1.6438582033000178
Validation loss: 2.5055246826034367

Epoch: 5| Step: 4
Training loss: 1.8925271042126302
Validation loss: 2.496074100190895

Epoch: 5| Step: 5
Training loss: 1.7342630298658976
Validation loss: 2.4901188484561403

Epoch: 5| Step: 6
Training loss: 1.8179360787177614
Validation loss: 2.504487928471949

Epoch: 5| Step: 7
Training loss: 1.5955953946861658
Validation loss: 2.4789530854340303

Epoch: 5| Step: 8
Training loss: 2.1078714168789365
Validation loss: 2.5296436977439534

Epoch: 5| Step: 9
Training loss: 1.3805871503622955
Validation loss: 2.5244602802669878

Epoch: 5| Step: 10
Training loss: 1.5138841836994248
Validation loss: 2.552494518881624

Epoch: 227| Step: 0
Training loss: 1.7036287455186276
Validation loss: 2.53651309370649

Epoch: 5| Step: 1
Training loss: 1.8888030297581029
Validation loss: 2.5651521881357406

Epoch: 5| Step: 2
Training loss: 1.6688802403977827
Validation loss: 2.596780549649675

Epoch: 5| Step: 3
Training loss: 1.850981609148015
Validation loss: 2.5620569125674346

Epoch: 5| Step: 4
Training loss: 2.10215291518355
Validation loss: 2.5622482756423537

Epoch: 5| Step: 5
Training loss: 1.59662436293199
Validation loss: 2.5463265244210374

Epoch: 5| Step: 6
Training loss: 1.2771418700666992
Validation loss: 2.5364135453884966

Epoch: 5| Step: 7
Training loss: 1.3085405481256083
Validation loss: 2.537298681150514

Epoch: 5| Step: 8
Training loss: 1.5774509009989046
Validation loss: 2.5330218422625927

Epoch: 5| Step: 9
Training loss: 2.0464851066295338
Validation loss: 2.5043246324251816

Epoch: 5| Step: 10
Training loss: 1.4676348734391054
Validation loss: 2.5111494659781317

Epoch: 228| Step: 0
Training loss: 1.5342647691587374
Validation loss: 2.4735964682172895

Epoch: 5| Step: 1
Training loss: 1.7571527896161756
Validation loss: 2.4867604884602588

Epoch: 5| Step: 2
Training loss: 1.4740368268395714
Validation loss: 2.489557862757555

Epoch: 5| Step: 3
Training loss: 1.5734125917616728
Validation loss: 2.4849160063828135

Epoch: 5| Step: 4
Training loss: 1.9275079688910626
Validation loss: 2.4728063724976166

Epoch: 5| Step: 5
Training loss: 1.4284046859160138
Validation loss: 2.4786671250424144

Epoch: 5| Step: 6
Training loss: 1.7609572699722418
Validation loss: 2.5103621587774443

Epoch: 5| Step: 7
Training loss: 2.0819655187941404
Validation loss: 2.4958913768788884

Epoch: 5| Step: 8
Training loss: 2.0530105535697687
Validation loss: 2.4985741948662183

Epoch: 5| Step: 9
Training loss: 1.2681923716675583
Validation loss: 2.535678463076186

Epoch: 5| Step: 10
Training loss: 1.5607339415071633
Validation loss: 2.491840009277074

Epoch: 229| Step: 0
Training loss: 1.8349412528256623
Validation loss: 2.4717641006126088

Epoch: 5| Step: 1
Training loss: 2.064561564936686
Validation loss: 2.4565374757715572

Epoch: 5| Step: 2
Training loss: 1.45953023930294
Validation loss: 2.452997253824708

Epoch: 5| Step: 3
Training loss: 1.011823670827211
Validation loss: 2.4349391748925973

Epoch: 5| Step: 4
Training loss: 1.6250421078434873
Validation loss: 2.432973472902123

Epoch: 5| Step: 5
Training loss: 1.4335816925955398
Validation loss: 2.4429667276459557

Epoch: 5| Step: 6
Training loss: 2.01452535751642
Validation loss: 2.431396294980152

Epoch: 5| Step: 7
Training loss: 1.679467049259842
Validation loss: 2.4363028828917974

Epoch: 5| Step: 8
Training loss: 1.8530800953871487
Validation loss: 2.481180764939189

Epoch: 5| Step: 9
Training loss: 1.4732855709383554
Validation loss: 2.4945658947421254

Epoch: 5| Step: 10
Training loss: 1.8233169188914193
Validation loss: 2.5232461785487725

Epoch: 230| Step: 0
Training loss: 1.9109397482683332
Validation loss: 2.549750102323122

Epoch: 5| Step: 1
Training loss: 1.751799407645486
Validation loss: 2.59421538936772

Epoch: 5| Step: 2
Training loss: 1.6306509650002885
Validation loss: 2.6173821744358046

Epoch: 5| Step: 3
Training loss: 1.5235922710343843
Validation loss: 2.6346502522752533

Epoch: 5| Step: 4
Training loss: 1.9696056383695244
Validation loss: 2.6408391269719216

Epoch: 5| Step: 5
Training loss: 1.7990939164512207
Validation loss: 2.5998301095177108

Epoch: 5| Step: 6
Training loss: 1.932496038632694
Validation loss: 2.5833429309244593

Epoch: 5| Step: 7
Training loss: 1.5767485403910302
Validation loss: 2.504119891064812

Epoch: 5| Step: 8
Training loss: 1.5041930086289632
Validation loss: 2.4665624319910853

Epoch: 5| Step: 9
Training loss: 1.494558717163184
Validation loss: 2.438645545133354

Epoch: 5| Step: 10
Training loss: 1.0247084319224082
Validation loss: 2.417851794664305

Epoch: 231| Step: 0
Training loss: 1.6005052007360074
Validation loss: 2.4056632177869854

Epoch: 5| Step: 1
Training loss: 1.3759175187080288
Validation loss: 2.408224249738655

Epoch: 5| Step: 2
Training loss: 2.019197004685697
Validation loss: 2.4370841961888554

Epoch: 5| Step: 3
Training loss: 1.6551819722609378
Validation loss: 2.440430086685179

Epoch: 5| Step: 4
Training loss: 1.79820255498135
Validation loss: 2.4670088310630827

Epoch: 5| Step: 5
Training loss: 1.6846952795586034
Validation loss: 2.491367373460953

Epoch: 5| Step: 6
Training loss: 1.4961461787586503
Validation loss: 2.5172014391798654

Epoch: 5| Step: 7
Training loss: 1.424832966702311
Validation loss: 2.5516894024975847

Epoch: 5| Step: 8
Training loss: 1.622050249043399
Validation loss: 2.5324706599753664

Epoch: 5| Step: 9
Training loss: 1.8164276449932846
Validation loss: 2.5508367316993943

Epoch: 5| Step: 10
Training loss: 1.5978839590744631
Validation loss: 2.546949815182865

Epoch: 232| Step: 0
Training loss: 1.5718856447136231
Validation loss: 2.5425419751833225

Epoch: 5| Step: 1
Training loss: 1.8736029824672127
Validation loss: 2.5544130518400237

Epoch: 5| Step: 2
Training loss: 2.1764123299326377
Validation loss: 2.5736471079813423

Epoch: 5| Step: 3
Training loss: 1.2654754173516714
Validation loss: 2.5602836798699173

Epoch: 5| Step: 4
Training loss: 1.805678256666594
Validation loss: 2.5379986024453833

Epoch: 5| Step: 5
Training loss: 1.5935724944952432
Validation loss: 2.5110502128241823

Epoch: 5| Step: 6
Training loss: 1.982801098561555
Validation loss: 2.4963733393840988

Epoch: 5| Step: 7
Training loss: 1.1918335695472313
Validation loss: 2.4761988585486976

Epoch: 5| Step: 8
Training loss: 1.4586960840925949
Validation loss: 2.4682070372708345

Epoch: 5| Step: 9
Training loss: 1.4306404814876161
Validation loss: 2.447646024810985

Epoch: 5| Step: 10
Training loss: 1.4343284782228798
Validation loss: 2.481182777161831

Epoch: 233| Step: 0
Training loss: 1.5640643871497966
Validation loss: 2.4616813987245396

Epoch: 5| Step: 1
Training loss: 1.4568838090928946
Validation loss: 2.453426658403316

Epoch: 5| Step: 2
Training loss: 1.5855368873975206
Validation loss: 2.448546452476955

Epoch: 5| Step: 3
Training loss: 1.6664393110970408
Validation loss: 2.469099957444454

Epoch: 5| Step: 4
Training loss: 1.8250488745010713
Validation loss: 2.444374950772226

Epoch: 5| Step: 5
Training loss: 1.360023869837927
Validation loss: 2.4646059772520297

Epoch: 5| Step: 6
Training loss: 1.5824099240573306
Validation loss: 2.457776497405344

Epoch: 5| Step: 7
Training loss: 1.7620389862986716
Validation loss: 2.4663939120536824

Epoch: 5| Step: 8
Training loss: 1.6562430183695347
Validation loss: 2.485529413590116

Epoch: 5| Step: 9
Training loss: 1.8983645327010652
Validation loss: 2.498689346894283

Epoch: 5| Step: 10
Training loss: 1.2914946759476396
Validation loss: 2.4720116830939927

Epoch: 234| Step: 0
Training loss: 1.134548672078812
Validation loss: 2.478366480352984

Epoch: 5| Step: 1
Training loss: 1.5305779987189
Validation loss: 2.51269909567748

Epoch: 5| Step: 2
Training loss: 1.5498271476593997
Validation loss: 2.4784301648953617

Epoch: 5| Step: 3
Training loss: 1.8482029047708395
Validation loss: 2.4998393868566944

Epoch: 5| Step: 4
Training loss: 1.5658878981317217
Validation loss: 2.48870194191297

Epoch: 5| Step: 5
Training loss: 1.6192264695182768
Validation loss: 2.5054902119458204

Epoch: 5| Step: 6
Training loss: 1.6736046231233335
Validation loss: 2.5066239485207604

Epoch: 5| Step: 7
Training loss: 1.3883834088573064
Validation loss: 2.489802085549769

Epoch: 5| Step: 8
Training loss: 1.5381416625570052
Validation loss: 2.5126963133897418

Epoch: 5| Step: 9
Training loss: 1.9772206292618344
Validation loss: 2.512837565440132

Epoch: 5| Step: 10
Training loss: 1.7354342688331441
Validation loss: 2.514184207853912

Epoch: 235| Step: 0
Training loss: 1.637843653603323
Validation loss: 2.507245204293325

Epoch: 5| Step: 1
Training loss: 1.6260441579887208
Validation loss: 2.50207038487993

Epoch: 5| Step: 2
Training loss: 1.4925544647042674
Validation loss: 2.4935831970893094

Epoch: 5| Step: 3
Training loss: 1.5348909648727012
Validation loss: 2.493776174893097

Epoch: 5| Step: 4
Training loss: 1.379596526623294
Validation loss: 2.5077402475476958

Epoch: 5| Step: 5
Training loss: 1.896177791560924
Validation loss: 2.5152306089268306

Epoch: 5| Step: 6
Training loss: 1.3655167752817043
Validation loss: 2.508716012483416

Epoch: 5| Step: 7
Training loss: 1.5369651174167103
Validation loss: 2.511147592619981

Epoch: 5| Step: 8
Training loss: 1.5618925821292422
Validation loss: 2.5243084097170074

Epoch: 5| Step: 9
Training loss: 1.7695823139965887
Validation loss: 2.4881537159048825

Epoch: 5| Step: 10
Training loss: 1.5364463762583156
Validation loss: 2.5098629259365848

Epoch: 236| Step: 0
Training loss: 1.6326554510344804
Validation loss: 2.4831614797486106

Epoch: 5| Step: 1
Training loss: 1.4978000084340006
Validation loss: 2.476396020348096

Epoch: 5| Step: 2
Training loss: 1.7140191600400787
Validation loss: 2.4826804622679544

Epoch: 5| Step: 3
Training loss: 1.5251832789365134
Validation loss: 2.486083549596817

Epoch: 5| Step: 4
Training loss: 1.6262613682858995
Validation loss: 2.4749069479773724

Epoch: 5| Step: 5
Training loss: 1.8960529940719868
Validation loss: 2.479448144461431

Epoch: 5| Step: 6
Training loss: 1.3973384352971863
Validation loss: 2.490644460422896

Epoch: 5| Step: 7
Training loss: 1.626038879483376
Validation loss: 2.4774397004334725

Epoch: 5| Step: 8
Training loss: 0.7965946826442248
Validation loss: 2.4820483191522444

Epoch: 5| Step: 9
Training loss: 1.7123084998433735
Validation loss: 2.4973646065730017

Epoch: 5| Step: 10
Training loss: 1.577399285270768
Validation loss: 2.5035454722737414

Epoch: 237| Step: 0
Training loss: 1.655278478744167
Validation loss: 2.5027517238709436

Epoch: 5| Step: 1
Training loss: 1.4996065577455466
Validation loss: 2.5221759641410064

Epoch: 5| Step: 2
Training loss: 1.2570681531573513
Validation loss: 2.494099238687646

Epoch: 5| Step: 3
Training loss: 1.7093633787328482
Validation loss: 2.4974251028270436

Epoch: 5| Step: 4
Training loss: 1.2640545367354332
Validation loss: 2.500180262557833

Epoch: 5| Step: 5
Training loss: 1.3821901548128552
Validation loss: 2.5068526763416608

Epoch: 5| Step: 6
Training loss: 1.9308052069281432
Validation loss: 2.491521265307213

Epoch: 5| Step: 7
Training loss: 1.5112242370378381
Validation loss: 2.4723838810754177

Epoch: 5| Step: 8
Training loss: 1.7537791454587839
Validation loss: 2.481960731011267

Epoch: 5| Step: 9
Training loss: 1.4188752442588997
Validation loss: 2.482684637106615

Epoch: 5| Step: 10
Training loss: 1.6378029666791314
Validation loss: 2.5066168966743687

Epoch: 238| Step: 0
Training loss: 1.6184379424134876
Validation loss: 2.52100550986381

Epoch: 5| Step: 1
Training loss: 1.3721881204984647
Validation loss: 2.5301103820580018

Epoch: 5| Step: 2
Training loss: 1.4875754136915809
Validation loss: 2.5379235011677364

Epoch: 5| Step: 3
Training loss: 1.540083028858772
Validation loss: 2.535752159843185

Epoch: 5| Step: 4
Training loss: 1.730576832584203
Validation loss: 2.511515926658321

Epoch: 5| Step: 5
Training loss: 1.7081846622190702
Validation loss: 2.506899889233598

Epoch: 5| Step: 6
Training loss: 1.0237809398479836
Validation loss: 2.4774208583086708

Epoch: 5| Step: 7
Training loss: 1.3916812699897543
Validation loss: 2.499902013683735

Epoch: 5| Step: 8
Training loss: 1.6224388333210107
Validation loss: 2.496322070632078

Epoch: 5| Step: 9
Training loss: 1.7540524428171211
Validation loss: 2.4567124821733866

Epoch: 5| Step: 10
Training loss: 1.5842036649318934
Validation loss: 2.4695012050558676

Epoch: 239| Step: 0
Training loss: 1.4418636102974765
Validation loss: 2.4461981755039597

Epoch: 5| Step: 1
Training loss: 1.9236077041993649
Validation loss: 2.4456899079708188

Epoch: 5| Step: 2
Training loss: 1.3475669941853536
Validation loss: 2.4729203047858097

Epoch: 5| Step: 3
Training loss: 1.6279240489695017
Validation loss: 2.4566395293083083

Epoch: 5| Step: 4
Training loss: 1.0630955429526265
Validation loss: 2.4851826063077405

Epoch: 5| Step: 5
Training loss: 1.6455415716585213
Validation loss: 2.4889395587638417

Epoch: 5| Step: 6
Training loss: 1.8208346293406235
Validation loss: 2.5139788448722067

Epoch: 5| Step: 7
Training loss: 1.2330367644615197
Validation loss: 2.5092678233473866

Epoch: 5| Step: 8
Training loss: 1.645005690034342
Validation loss: 2.5013773887176947

Epoch: 5| Step: 9
Training loss: 1.5888548828848994
Validation loss: 2.5337975632099687

Epoch: 5| Step: 10
Training loss: 1.3989489595047557
Validation loss: 2.510015906457686

Epoch: 240| Step: 0
Training loss: 1.2980673031572751
Validation loss: 2.534808746365493

Epoch: 5| Step: 1
Training loss: 1.5705305868508288
Validation loss: 2.5240456834206193

Epoch: 5| Step: 2
Training loss: 1.3708119333716768
Validation loss: 2.5188861799219286

Epoch: 5| Step: 3
Training loss: 1.605179586613143
Validation loss: 2.521398808525128

Epoch: 5| Step: 4
Training loss: 1.8602479440262216
Validation loss: 2.499836843560496

Epoch: 5| Step: 5
Training loss: 1.4834199744363161
Validation loss: 2.515815403078453

Epoch: 5| Step: 6
Training loss: 1.4120791947765754
Validation loss: 2.5122198070351667

Epoch: 5| Step: 7
Training loss: 1.2796314064186725
Validation loss: 2.5094477818093477

Epoch: 5| Step: 8
Training loss: 1.644056528033816
Validation loss: 2.512598384489397

Epoch: 5| Step: 9
Training loss: 1.3684267367793188
Validation loss: 2.4990051279375542

Epoch: 5| Step: 10
Training loss: 1.8637300666546481
Validation loss: 2.501155828091445

Epoch: 241| Step: 0
Training loss: 1.1581315377097718
Validation loss: 2.4832727307857976

Epoch: 5| Step: 1
Training loss: 1.8119465870974283
Validation loss: 2.4817477638391248

Epoch: 5| Step: 2
Training loss: 1.4049429859526208
Validation loss: 2.4873969335955426

Epoch: 5| Step: 3
Training loss: 1.763897683863436
Validation loss: 2.457065349819386

Epoch: 5| Step: 4
Training loss: 1.5089740923660302
Validation loss: 2.4887459355285566

Epoch: 5| Step: 5
Training loss: 1.2364114308426462
Validation loss: 2.475547094546618

Epoch: 5| Step: 6
Training loss: 1.2585290798666493
Validation loss: 2.4930975265078543

Epoch: 5| Step: 7
Training loss: 1.564318323697525
Validation loss: 2.5249059903499234

Epoch: 5| Step: 8
Training loss: 1.3467853330428183
Validation loss: 2.51107612781224

Epoch: 5| Step: 9
Training loss: 1.7689451885023282
Validation loss: 2.5204374354519956

Epoch: 5| Step: 10
Training loss: 1.600814719196995
Validation loss: 2.495472488710821

Epoch: 242| Step: 0
Training loss: 0.8268416194853001
Validation loss: 2.511673211291703

Epoch: 5| Step: 1
Training loss: 1.7219069185431335
Validation loss: 2.490423394335777

Epoch: 5| Step: 2
Training loss: 1.5173385214948758
Validation loss: 2.493359754257167

Epoch: 5| Step: 3
Training loss: 1.5713496033531977
Validation loss: 2.4887793638934164

Epoch: 5| Step: 4
Training loss: 1.7903718779444198
Validation loss: 2.4869496254481027

Epoch: 5| Step: 5
Training loss: 1.7396439258126772
Validation loss: 2.493082090718319

Epoch: 5| Step: 6
Training loss: 1.0328052814825808
Validation loss: 2.45973538051897

Epoch: 5| Step: 7
Training loss: 1.294278774838354
Validation loss: 2.4486600174400825

Epoch: 5| Step: 8
Training loss: 1.864259602948983
Validation loss: 2.4683604288059433

Epoch: 5| Step: 9
Training loss: 1.6725118262039627
Validation loss: 2.4907003450524883

Epoch: 5| Step: 10
Training loss: 0.7248237477836282
Validation loss: 2.488932923924877

Epoch: 243| Step: 0
Training loss: 0.8670771760613475
Validation loss: 2.502336289241721

Epoch: 5| Step: 1
Training loss: 1.3599351627658136
Validation loss: 2.498442052626573

Epoch: 5| Step: 2
Training loss: 1.9578427518682624
Validation loss: 2.537181639854512

Epoch: 5| Step: 3
Training loss: 1.4849584135661011
Validation loss: 2.550455794837748

Epoch: 5| Step: 4
Training loss: 1.2197524618509807
Validation loss: 2.5313250481061225

Epoch: 5| Step: 5
Training loss: 1.4392436689059007
Validation loss: 2.5353249872718866

Epoch: 5| Step: 6
Training loss: 1.487896085945938
Validation loss: 2.5373520570435475

Epoch: 5| Step: 7
Training loss: 1.421483499474818
Validation loss: 2.5620454224435094

Epoch: 5| Step: 8
Training loss: 1.6571732592847532
Validation loss: 2.509925158642033

Epoch: 5| Step: 9
Training loss: 1.652318065975768
Validation loss: 2.5008842237651514

Epoch: 5| Step: 10
Training loss: 1.4048529148831737
Validation loss: 2.502389289079143

Epoch: 244| Step: 0
Training loss: 1.4522911058132146
Validation loss: 2.4874491262961245

Epoch: 5| Step: 1
Training loss: 1.6771332237768175
Validation loss: 2.4683515757585073

Epoch: 5| Step: 2
Training loss: 1.484654851934674
Validation loss: 2.4527146389584984

Epoch: 5| Step: 3
Training loss: 1.5776358875684517
Validation loss: 2.460144297453463

Epoch: 5| Step: 4
Training loss: 1.4396761303521657
Validation loss: 2.4615357874441353

Epoch: 5| Step: 5
Training loss: 1.7300836207736852
Validation loss: 2.463911081676585

Epoch: 5| Step: 6
Training loss: 1.3999461129580673
Validation loss: 2.4816741285787174

Epoch: 5| Step: 7
Training loss: 1.1353129184931081
Validation loss: 2.4618050151251047

Epoch: 5| Step: 8
Training loss: 1.2521397396506129
Validation loss: 2.468073284735282

Epoch: 5| Step: 9
Training loss: 1.5349131772714295
Validation loss: 2.471540195972068

Epoch: 5| Step: 10
Training loss: 1.2318940642036664
Validation loss: 2.488138872803784

Epoch: 245| Step: 0
Training loss: 1.2903368575129222
Validation loss: 2.4838597418671653

Epoch: 5| Step: 1
Training loss: 1.4149769729250299
Validation loss: 2.5037063104911947

Epoch: 5| Step: 2
Training loss: 1.619888335488562
Validation loss: 2.5057840174267874

Epoch: 5| Step: 3
Training loss: 1.160095470133611
Validation loss: 2.5171989918463518

Epoch: 5| Step: 4
Training loss: 1.2392629588736472
Validation loss: 2.51390951388335

Epoch: 5| Step: 5
Training loss: 1.6425204998345406
Validation loss: 2.5095675262939863

Epoch: 5| Step: 6
Training loss: 1.8889362580150428
Validation loss: 2.5025399707878884

Epoch: 5| Step: 7
Training loss: 1.1587043179557415
Validation loss: 2.5177967203171767

Epoch: 5| Step: 8
Training loss: 1.79472813271489
Validation loss: 2.4980030954755694

Epoch: 5| Step: 9
Training loss: 1.265174926981776
Validation loss: 2.4749491172077085

Epoch: 5| Step: 10
Training loss: 1.1681101531610398
Validation loss: 2.4693349215682843

Epoch: 246| Step: 0
Training loss: 1.037710127176387
Validation loss: 2.4838974851666524

Epoch: 5| Step: 1
Training loss: 1.2106210602798126
Validation loss: 2.4752635986969143

Epoch: 5| Step: 2
Training loss: 1.4174787867605418
Validation loss: 2.493645231061226

Epoch: 5| Step: 3
Training loss: 1.6338407938098534
Validation loss: 2.4832150818950214

Epoch: 5| Step: 4
Training loss: 1.5236776309395346
Validation loss: 2.468974434394182

Epoch: 5| Step: 5
Training loss: 1.4973626793770802
Validation loss: 2.46739215615202

Epoch: 5| Step: 6
Training loss: 1.5632214978497838
Validation loss: 2.4807816709593866

Epoch: 5| Step: 7
Training loss: 1.5627092602792356
Validation loss: 2.5117034031311043

Epoch: 5| Step: 8
Training loss: 1.4326344952516197
Validation loss: 2.4954046345456504

Epoch: 5| Step: 9
Training loss: 1.57669017263449
Validation loss: 2.4932165426859765

Epoch: 5| Step: 10
Training loss: 1.168074178881108
Validation loss: 2.48794818012275

Epoch: 247| Step: 0
Training loss: 1.3172914601996049
Validation loss: 2.4867703842011677

Epoch: 5| Step: 1
Training loss: 1.6445651016919345
Validation loss: 2.477522744393628

Epoch: 5| Step: 2
Training loss: 1.8218007041478343
Validation loss: 2.472302411754405

Epoch: 5| Step: 3
Training loss: 1.4364764674616306
Validation loss: 2.5010641417376944

Epoch: 5| Step: 4
Training loss: 1.227814927888811
Validation loss: 2.4973234656551857

Epoch: 5| Step: 5
Training loss: 1.2797532992744283
Validation loss: 2.4751448016226236

Epoch: 5| Step: 6
Training loss: 1.1570620391684887
Validation loss: 2.4915176516465287

Epoch: 5| Step: 7
Training loss: 1.5672643123526324
Validation loss: 2.4654575042247586

Epoch: 5| Step: 8
Training loss: 1.2399166631381764
Validation loss: 2.5002092325166516

Epoch: 5| Step: 9
Training loss: 1.3488122819267794
Validation loss: 2.4982858852158953

Epoch: 5| Step: 10
Training loss: 1.576388773122252
Validation loss: 2.5087174134990398

Epoch: 248| Step: 0
Training loss: 1.7371472034834683
Validation loss: 2.523973751435353

Epoch: 5| Step: 1
Training loss: 1.4968435136832328
Validation loss: 2.4810902116813307

Epoch: 5| Step: 2
Training loss: 1.1017996891139699
Validation loss: 2.5078541731736603

Epoch: 5| Step: 3
Training loss: 1.7614785176509398
Validation loss: 2.5117415088379107

Epoch: 5| Step: 4
Training loss: 1.2678800672918598
Validation loss: 2.5225585475496444

Epoch: 5| Step: 5
Training loss: 1.1937705672324779
Validation loss: 2.4972431887671482

Epoch: 5| Step: 6
Training loss: 1.4721708028838805
Validation loss: 2.523148605261173

Epoch: 5| Step: 7
Training loss: 1.4093998283009366
Validation loss: 2.5262654746523188

Epoch: 5| Step: 8
Training loss: 1.194534247864279
Validation loss: 2.5285583733076598

Epoch: 5| Step: 9
Training loss: 1.5046383351565926
Validation loss: 2.539582421873329

Epoch: 5| Step: 10
Training loss: 1.4111827379522501
Validation loss: 2.5395182326931827

Epoch: 249| Step: 0
Training loss: 1.3620282292570485
Validation loss: 2.5172997053438952

Epoch: 5| Step: 1
Training loss: 1.4942304596666
Validation loss: 2.469182232212657

Epoch: 5| Step: 2
Training loss: 1.1502385451822847
Validation loss: 2.477810646441642

Epoch: 5| Step: 3
Training loss: 1.230882024238838
Validation loss: 2.445382151404089

Epoch: 5| Step: 4
Training loss: 0.9563673558246901
Validation loss: 2.4417723920043644

Epoch: 5| Step: 5
Training loss: 1.4626291038717074
Validation loss: 2.4576979198853985

Epoch: 5| Step: 6
Training loss: 1.8759121265693943
Validation loss: 2.432642936352087

Epoch: 5| Step: 7
Training loss: 1.4004975388494056
Validation loss: 2.4475511503614156

Epoch: 5| Step: 8
Training loss: 1.5635692752414279
Validation loss: 2.4648905491039828

Epoch: 5| Step: 9
Training loss: 1.315012751760408
Validation loss: 2.4518019891227545

Epoch: 5| Step: 10
Training loss: 1.6652132452193122
Validation loss: 2.4874762801665065

Epoch: 250| Step: 0
Training loss: 1.4949805199109887
Validation loss: 2.522269027674048

Epoch: 5| Step: 1
Training loss: 1.5588692251952971
Validation loss: 2.533649897496077

Epoch: 5| Step: 2
Training loss: 1.3997223135895642
Validation loss: 2.5242834242600765

Epoch: 5| Step: 3
Training loss: 1.7173098686290564
Validation loss: 2.527114931093369

Epoch: 5| Step: 4
Training loss: 1.3069170786260151
Validation loss: 2.484981331565207

Epoch: 5| Step: 5
Training loss: 1.2287117660488136
Validation loss: 2.5190822838834053

Epoch: 5| Step: 6
Training loss: 1.1073819376961451
Validation loss: 2.4923674769540693

Epoch: 5| Step: 7
Training loss: 1.5627821095423116
Validation loss: 2.484632676183455

Epoch: 5| Step: 8
Training loss: 1.0881907187855673
Validation loss: 2.4652476661927207

Epoch: 5| Step: 9
Training loss: 1.6063242023116406
Validation loss: 2.458250834514819

Epoch: 5| Step: 10
Training loss: 1.3269946056190205
Validation loss: 2.4657910892684387

Epoch: 251| Step: 0
Training loss: 1.2615809409641312
Validation loss: 2.472427832207197

Epoch: 5| Step: 1
Training loss: 0.8729192311894901
Validation loss: 2.463465850592387

Epoch: 5| Step: 2
Training loss: 1.2614276183988324
Validation loss: 2.488032852199429

Epoch: 5| Step: 3
Training loss: 1.9335087921282026
Validation loss: 2.479252520513998

Epoch: 5| Step: 4
Training loss: 1.3222161287991891
Validation loss: 2.48805107352434

Epoch: 5| Step: 5
Training loss: 1.1432676663646866
Validation loss: 2.479934982477287

Epoch: 5| Step: 6
Training loss: 1.9821270803366164
Validation loss: 2.484826205182391

Epoch: 5| Step: 7
Training loss: 1.3609246377085304
Validation loss: 2.4913936686303364

Epoch: 5| Step: 8
Training loss: 1.2477705146572124
Validation loss: 2.4869037156508034

Epoch: 5| Step: 9
Training loss: 1.3186581873458798
Validation loss: 2.492568642781309

Epoch: 5| Step: 10
Training loss: 1.2867955475004156
Validation loss: 2.489192857024647

Epoch: 252| Step: 0
Training loss: 1.3830024890449728
Validation loss: 2.4960879234759363

Epoch: 5| Step: 1
Training loss: 1.634021512201613
Validation loss: 2.4855910075482184

Epoch: 5| Step: 2
Training loss: 1.4541046777900646
Validation loss: 2.4866279601894763

Epoch: 5| Step: 3
Training loss: 1.4447370053571817
Validation loss: 2.4947209663006027

Epoch: 5| Step: 4
Training loss: 1.21329858771204
Validation loss: 2.511901253786612

Epoch: 5| Step: 5
Training loss: 1.4410103768604452
Validation loss: 2.538081083106185

Epoch: 5| Step: 6
Training loss: 1.2538907059035804
Validation loss: 2.5279550774912423

Epoch: 5| Step: 7
Training loss: 1.4366242602227017
Validation loss: 2.512969557702188

Epoch: 5| Step: 8
Training loss: 1.380711915858006
Validation loss: 2.523781011956758

Epoch: 5| Step: 9
Training loss: 1.2454431443746241
Validation loss: 2.495095023996804

Epoch: 5| Step: 10
Training loss: 1.3441109726907425
Validation loss: 2.4902971394024793

Epoch: 253| Step: 0
Training loss: 1.2213267450026537
Validation loss: 2.503483117844256

Epoch: 5| Step: 1
Training loss: 1.6539014323384678
Validation loss: 2.4917988759130365

Epoch: 5| Step: 2
Training loss: 1.266814720552736
Validation loss: 2.5013451269723466

Epoch: 5| Step: 3
Training loss: 1.8484701738992615
Validation loss: 2.506752862390311

Epoch: 5| Step: 4
Training loss: 1.0476159277886015
Validation loss: 2.5129249251384977

Epoch: 5| Step: 5
Training loss: 1.468046141447601
Validation loss: 2.4881828403135815

Epoch: 5| Step: 6
Training loss: 1.118716600654771
Validation loss: 2.51076857586466

Epoch: 5| Step: 7
Training loss: 0.9666648389261878
Validation loss: 2.5101789670782284

Epoch: 5| Step: 8
Training loss: 1.7492454809588702
Validation loss: 2.5190728234349518

Epoch: 5| Step: 9
Training loss: 1.3408837466644103
Validation loss: 2.530042627996797

Epoch: 5| Step: 10
Training loss: 1.1529092726466337
Validation loss: 2.5404959661636837

Epoch: 254| Step: 0
Training loss: 1.4995694337232295
Validation loss: 2.516676785631325

Epoch: 5| Step: 1
Training loss: 1.606617240633562
Validation loss: 2.5305490864034144

Epoch: 5| Step: 2
Training loss: 1.4369451032331786
Validation loss: 2.4949337066826742

Epoch: 5| Step: 3
Training loss: 1.1910717103638748
Validation loss: 2.463447116484832

Epoch: 5| Step: 4
Training loss: 1.0205850234323064
Validation loss: 2.459654913395356

Epoch: 5| Step: 5
Training loss: 1.348031696597802
Validation loss: 2.4687593656429505

Epoch: 5| Step: 6
Training loss: 1.4027960427776918
Validation loss: 2.447935670784566

Epoch: 5| Step: 7
Training loss: 0.9467988742152855
Validation loss: 2.439251676548297

Epoch: 5| Step: 8
Training loss: 1.1834929269080494
Validation loss: 2.4518629017063778

Epoch: 5| Step: 9
Training loss: 1.5801856307341664
Validation loss: 2.4533851526869355

Epoch: 5| Step: 10
Training loss: 1.5991111790007522
Validation loss: 2.4592374209303802

Epoch: 255| Step: 0
Training loss: 1.3740337184366838
Validation loss: 2.477208872588807

Epoch: 5| Step: 1
Training loss: 1.541042777282774
Validation loss: 2.4766293270149538

Epoch: 5| Step: 2
Training loss: 1.6568723265152538
Validation loss: 2.508092690364883

Epoch: 5| Step: 3
Training loss: 0.6202188483583295
Validation loss: 2.481464157642799

Epoch: 5| Step: 4
Training loss: 1.3656166425575798
Validation loss: 2.4781320446184125

Epoch: 5| Step: 5
Training loss: 1.3577414157113519
Validation loss: 2.472675721993002

Epoch: 5| Step: 6
Training loss: 1.555960589235835
Validation loss: 2.485883749310135

Epoch: 5| Step: 7
Training loss: 1.262556193772446
Validation loss: 2.519371358967162

Epoch: 5| Step: 8
Training loss: 0.9124882501342116
Validation loss: 2.511171757301521

Epoch: 5| Step: 9
Training loss: 1.3643047349270114
Validation loss: 2.5014131838250604

Epoch: 5| Step: 10
Training loss: 1.4759285994113343
Validation loss: 2.511399155268045

Epoch: 256| Step: 0
Training loss: 1.2469585132595986
Validation loss: 2.506595136566159

Epoch: 5| Step: 1
Training loss: 1.1892819336217801
Validation loss: 2.5006982115473746

Epoch: 5| Step: 2
Training loss: 1.4685485377019958
Validation loss: 2.4852557899870797

Epoch: 5| Step: 3
Training loss: 1.314733013492345
Validation loss: 2.495211867961908

Epoch: 5| Step: 4
Training loss: 1.406220287432956
Validation loss: 2.4586254597729953

Epoch: 5| Step: 5
Training loss: 1.8610883240071814
Validation loss: 2.4718418710952617

Epoch: 5| Step: 6
Training loss: 1.0794909020836045
Validation loss: 2.492518477042107

Epoch: 5| Step: 7
Training loss: 1.5168192769217936
Validation loss: 2.4803029594151127

Epoch: 5| Step: 8
Training loss: 1.1605091521540347
Validation loss: 2.462096683489875

Epoch: 5| Step: 9
Training loss: 0.89664944726749
Validation loss: 2.4648014791281443

Epoch: 5| Step: 10
Training loss: 1.207090456599974
Validation loss: 2.4600009201825763

Epoch: 257| Step: 0
Training loss: 1.074978868143726
Validation loss: 2.483302287182763

Epoch: 5| Step: 1
Training loss: 1.6091872911334952
Validation loss: 2.483977434787522

Epoch: 5| Step: 2
Training loss: 1.1958199215623135
Validation loss: 2.483399392387905

Epoch: 5| Step: 3
Training loss: 1.1319544732573315
Validation loss: 2.4991754371836494

Epoch: 5| Step: 4
Training loss: 1.2389173348092457
Validation loss: 2.4857973595984664

Epoch: 5| Step: 5
Training loss: 0.9761997922620061
Validation loss: 2.480457727370456

Epoch: 5| Step: 6
Training loss: 1.2926385463635222
Validation loss: 2.4972060978564814

Epoch: 5| Step: 7
Training loss: 1.4753478367473691
Validation loss: 2.4972907573360716

Epoch: 5| Step: 8
Training loss: 1.6010455530037142
Validation loss: 2.49215707995995

Epoch: 5| Step: 9
Training loss: 1.3990340851673204
Validation loss: 2.4914924855236684

Epoch: 5| Step: 10
Training loss: 1.3748255965860314
Validation loss: 2.455983539719273

Epoch: 258| Step: 0
Training loss: 1.6677381012082808
Validation loss: 2.464864752294691

Epoch: 5| Step: 1
Training loss: 0.9411075482219083
Validation loss: 2.483493857375477

Epoch: 5| Step: 2
Training loss: 1.0450882538576038
Validation loss: 2.505755659279105

Epoch: 5| Step: 3
Training loss: 1.410016251057792
Validation loss: 2.4864345606022007

Epoch: 5| Step: 4
Training loss: 1.5452751594868863
Validation loss: 2.497123235716397

Epoch: 5| Step: 5
Training loss: 1.0391441255789693
Validation loss: 2.484902129202906

Epoch: 5| Step: 6
Training loss: 1.4870544343283192
Validation loss: 2.4716551605715313

Epoch: 5| Step: 7
Training loss: 1.3281652107883406
Validation loss: 2.4774859604835533

Epoch: 5| Step: 8
Training loss: 1.3181459607356505
Validation loss: 2.4798417713377487

Epoch: 5| Step: 9
Training loss: 1.4283965906374367
Validation loss: 2.4867188958151716

Epoch: 5| Step: 10
Training loss: 1.1043695167530596
Validation loss: 2.4951521374372394

Epoch: 259| Step: 0
Training loss: 1.6872187486027401
Validation loss: 2.4673795093120323

Epoch: 5| Step: 1
Training loss: 1.2149085122659522
Validation loss: 2.459742236380268

Epoch: 5| Step: 2
Training loss: 1.2862789734301043
Validation loss: 2.4538614121219084

Epoch: 5| Step: 3
Training loss: 1.2701011904255062
Validation loss: 2.437019058794965

Epoch: 5| Step: 4
Training loss: 1.4339076226086431
Validation loss: 2.4444217547600093

Epoch: 5| Step: 5
Training loss: 1.1240143696860834
Validation loss: 2.4441698047618954

Epoch: 5| Step: 6
Training loss: 1.3124714348727262
Validation loss: 2.449330328612769

Epoch: 5| Step: 7
Training loss: 1.7548058460575597
Validation loss: 2.4767896597794286

Epoch: 5| Step: 8
Training loss: 0.5220985367863143
Validation loss: 2.4878252696998273

Epoch: 5| Step: 9
Training loss: 1.354824693677994
Validation loss: 2.509132262626451

Epoch: 5| Step: 10
Training loss: 1.17821289260809
Validation loss: 2.515590058322711

Epoch: 260| Step: 0
Training loss: 1.5271564183390707
Validation loss: 2.532044574008827

Epoch: 5| Step: 1
Training loss: 1.434854062597998
Validation loss: 2.5543651810867996

Epoch: 5| Step: 2
Training loss: 1.30078317453053
Validation loss: 2.530334696082373

Epoch: 5| Step: 3
Training loss: 1.3240447253541547
Validation loss: 2.52894061055579

Epoch: 5| Step: 4
Training loss: 1.6582279270864895
Validation loss: 2.552939204203336

Epoch: 5| Step: 5
Training loss: 1.3694577795277434
Validation loss: 2.542537304741518

Epoch: 5| Step: 6
Training loss: 0.8994213853635288
Validation loss: 2.4940384268834714

Epoch: 5| Step: 7
Training loss: 0.9015895449385044
Validation loss: 2.4904401693737848

Epoch: 5| Step: 8
Training loss: 1.205668893492645
Validation loss: 2.4952240968464703

Epoch: 5| Step: 9
Training loss: 1.310800314671511
Validation loss: 2.4838476041095343

Epoch: 5| Step: 10
Training loss: 1.0975859269934607
Validation loss: 2.4509084037895277

Epoch: 261| Step: 0
Training loss: 1.386254934193779
Validation loss: 2.438923855572154

Epoch: 5| Step: 1
Training loss: 1.0048128776570937
Validation loss: 2.459348247657923

Epoch: 5| Step: 2
Training loss: 1.617351284118269
Validation loss: 2.434382978020788

Epoch: 5| Step: 3
Training loss: 1.4153145152772726
Validation loss: 2.4405324119755507

Epoch: 5| Step: 4
Training loss: 1.357675037515261
Validation loss: 2.476342578586104

Epoch: 5| Step: 5
Training loss: 1.588228121805722
Validation loss: 2.4502306850495814

Epoch: 5| Step: 6
Training loss: 1.056790438201178
Validation loss: 2.449907930254354

Epoch: 5| Step: 7
Training loss: 1.134612028721269
Validation loss: 2.495741418548476

Epoch: 5| Step: 8
Training loss: 1.15720585671745
Validation loss: 2.4373234873455303

Epoch: 5| Step: 9
Training loss: 1.2152349204120743
Validation loss: 2.4594089389435703

Epoch: 5| Step: 10
Training loss: 1.174780029646934
Validation loss: 2.4831099888005763

Epoch: 262| Step: 0
Training loss: 1.4379723643537596
Validation loss: 2.4714087617436094

Epoch: 5| Step: 1
Training loss: 1.3077226614773603
Validation loss: 2.5092822594859454

Epoch: 5| Step: 2
Training loss: 1.2502397784093862
Validation loss: 2.490900164495779

Epoch: 5| Step: 3
Training loss: 1.7054269615152777
Validation loss: 2.4996409496765026

Epoch: 5| Step: 4
Training loss: 0.8706147797279725
Validation loss: 2.4941047070158575

Epoch: 5| Step: 5
Training loss: 0.7655393980789877
Validation loss: 2.5109230689468545

Epoch: 5| Step: 6
Training loss: 1.318587219894735
Validation loss: 2.5159255006058916

Epoch: 5| Step: 7
Training loss: 1.7224098081188117
Validation loss: 2.5099130447942533

Epoch: 5| Step: 8
Training loss: 1.1406956480957016
Validation loss: 2.5069180117735144

Epoch: 5| Step: 9
Training loss: 1.2487533074412491
Validation loss: 2.4795235652450547

Epoch: 5| Step: 10
Training loss: 0.9411684107785969
Validation loss: 2.446879655582681

Epoch: 263| Step: 0
Training loss: 1.2947234725282275
Validation loss: 2.4504041692476233

Epoch: 5| Step: 1
Training loss: 1.0546381620946932
Validation loss: 2.47213011999807

Epoch: 5| Step: 2
Training loss: 1.1962210001365143
Validation loss: 2.4348131637046744

Epoch: 5| Step: 3
Training loss: 1.227234723003617
Validation loss: 2.4272295542374174

Epoch: 5| Step: 4
Training loss: 1.4247037813930221
Validation loss: 2.4392163838902436

Epoch: 5| Step: 5
Training loss: 1.7210233046235524
Validation loss: 2.4392876791577693

Epoch: 5| Step: 6
Training loss: 1.1069456553296324
Validation loss: 2.4531385072464675

Epoch: 5| Step: 7
Training loss: 1.4038564020391782
Validation loss: 2.437451339248584

Epoch: 5| Step: 8
Training loss: 1.5023977665704817
Validation loss: 2.44946003690113

Epoch: 5| Step: 9
Training loss: 1.044653514020543
Validation loss: 2.4504683362108497

Epoch: 5| Step: 10
Training loss: 0.7442446658475405
Validation loss: 2.489395781904549

Epoch: 264| Step: 0
Training loss: 1.3905919960477429
Validation loss: 2.461838942603461

Epoch: 5| Step: 1
Training loss: 1.2166102283050957
Validation loss: 2.4326289316997967

Epoch: 5| Step: 2
Training loss: 1.2133311578884813
Validation loss: 2.479680695106899

Epoch: 5| Step: 3
Training loss: 1.1918830292805835
Validation loss: 2.4713787871759916

Epoch: 5| Step: 4
Training loss: 1.6217538248119645
Validation loss: 2.431622604050971

Epoch: 5| Step: 5
Training loss: 1.221522088561991
Validation loss: 2.4677847546803453

Epoch: 5| Step: 6
Training loss: 1.4180220496719058
Validation loss: 2.447878589914354

Epoch: 5| Step: 7
Training loss: 0.6912962400343254
Validation loss: 2.466326404392987

Epoch: 5| Step: 8
Training loss: 1.2487785093243484
Validation loss: 2.4488764242650536

Epoch: 5| Step: 9
Training loss: 1.2498600881476527
Validation loss: 2.4531589106242104

Epoch: 5| Step: 10
Training loss: 1.296056742079441
Validation loss: 2.462837594369807

Epoch: 265| Step: 0
Training loss: 1.0206468697311306
Validation loss: 2.5010638885577547

Epoch: 5| Step: 1
Training loss: 1.3989910117181688
Validation loss: 2.49875204358379

Epoch: 5| Step: 2
Training loss: 1.1099477015022783
Validation loss: 2.4834615026701843

Epoch: 5| Step: 3
Training loss: 0.9855583283994513
Validation loss: 2.4904731385411636

Epoch: 5| Step: 4
Training loss: 1.424423700213993
Validation loss: 2.454656995851129

Epoch: 5| Step: 5
Training loss: 1.1637151827249297
Validation loss: 2.4843041359635416

Epoch: 5| Step: 6
Training loss: 0.719355162571567
Validation loss: 2.4730189237481652

Epoch: 5| Step: 7
Training loss: 1.530316438052513
Validation loss: 2.4738892837154145

Epoch: 5| Step: 8
Training loss: 1.7143253594310157
Validation loss: 2.4906418624477764

Epoch: 5| Step: 9
Training loss: 1.3615424755025662
Validation loss: 2.4917992041101944

Epoch: 5| Step: 10
Training loss: 0.9819336544512972
Validation loss: 2.499069091821993

Epoch: 266| Step: 0
Training loss: 1.148384767736
Validation loss: 2.479246487413552

Epoch: 5| Step: 1
Training loss: 1.2308245916363925
Validation loss: 2.504217194334814

Epoch: 5| Step: 2
Training loss: 1.4628684598621213
Validation loss: 2.482506985990522

Epoch: 5| Step: 3
Training loss: 1.3397981063141504
Validation loss: 2.498335518021846

Epoch: 5| Step: 4
Training loss: 1.0634565535415383
Validation loss: 2.49112469959838

Epoch: 5| Step: 5
Training loss: 1.2809943897860006
Validation loss: 2.4986194090247396

Epoch: 5| Step: 6
Training loss: 1.4949027716874117
Validation loss: 2.4709976575208903

Epoch: 5| Step: 7
Training loss: 1.1537233531846331
Validation loss: 2.453467724557487

Epoch: 5| Step: 8
Training loss: 1.0854403229012999
Validation loss: 2.4522405686072033

Epoch: 5| Step: 9
Training loss: 1.1992739189455275
Validation loss: 2.4404784695462918

Epoch: 5| Step: 10
Training loss: 1.1214292868142455
Validation loss: 2.426657439211737

Epoch: 267| Step: 0
Training loss: 1.0606402220839117
Validation loss: 2.4496034168116374

Epoch: 5| Step: 1
Training loss: 1.0567691181909071
Validation loss: 2.4454741291044004

Epoch: 5| Step: 2
Training loss: 1.0562313507058902
Validation loss: 2.4460792465116152

Epoch: 5| Step: 3
Training loss: 1.4931773951691787
Validation loss: 2.423889996522286

Epoch: 5| Step: 4
Training loss: 1.3926284588335207
Validation loss: 2.4479788732817434

Epoch: 5| Step: 5
Training loss: 0.9742263622338334
Validation loss: 2.4794680883612257

Epoch: 5| Step: 6
Training loss: 1.1977767973250806
Validation loss: 2.48164968286681

Epoch: 5| Step: 7
Training loss: 1.3121829331117083
Validation loss: 2.4989750986516106

Epoch: 5| Step: 8
Training loss: 1.6623799589028498
Validation loss: 2.4864508160978325

Epoch: 5| Step: 9
Training loss: 1.0666127546415112
Validation loss: 2.470063477601786

Epoch: 5| Step: 10
Training loss: 1.122007363249337
Validation loss: 2.4941896526657183

Epoch: 268| Step: 0
Training loss: 1.6963497100512304
Validation loss: 2.473364507436531

Epoch: 5| Step: 1
Training loss: 1.4198769584593223
Validation loss: 2.494030289441008

Epoch: 5| Step: 2
Training loss: 0.9618824290384653
Validation loss: 2.471989686814538

Epoch: 5| Step: 3
Training loss: 1.4127992920573524
Validation loss: 2.4785938895593755

Epoch: 5| Step: 4
Training loss: 1.05283311370208
Validation loss: 2.463964883849074

Epoch: 5| Step: 5
Training loss: 1.2916268475865513
Validation loss: 2.48217816028375

Epoch: 5| Step: 6
Training loss: 1.1426024866359847
Validation loss: 2.4615444275482097

Epoch: 5| Step: 7
Training loss: 0.9396268561039006
Validation loss: 2.447758279431423

Epoch: 5| Step: 8
Training loss: 1.4177143299537467
Validation loss: 2.449822365869715

Epoch: 5| Step: 9
Training loss: 1.015316079915065
Validation loss: 2.447264668583854

Epoch: 5| Step: 10
Training loss: 0.7893508912887852
Validation loss: 2.4429607534246047

Epoch: 269| Step: 0
Training loss: 1.5179599198238167
Validation loss: 2.4476343160071297

Epoch: 5| Step: 1
Training loss: 1.3057223573052428
Validation loss: 2.4482853249027214

Epoch: 5| Step: 2
Training loss: 0.9602727684295189
Validation loss: 2.4442260943525196

Epoch: 5| Step: 3
Training loss: 0.9749490149934511
Validation loss: 2.453586079134405

Epoch: 5| Step: 4
Training loss: 1.3668909241664917
Validation loss: 2.4548130647906263

Epoch: 5| Step: 5
Training loss: 0.9872719054623436
Validation loss: 2.498199624730844

Epoch: 5| Step: 6
Training loss: 1.2254581217588851
Validation loss: 2.491869810762702

Epoch: 5| Step: 7
Training loss: 1.1643051816163668
Validation loss: 2.509309707331783

Epoch: 5| Step: 8
Training loss: 1.362742626390679
Validation loss: 2.4868051287748103

Epoch: 5| Step: 9
Training loss: 1.21616117915642
Validation loss: 2.503512556472041

Epoch: 5| Step: 10
Training loss: 1.1430383521560035
Validation loss: 2.5008660221353676

Epoch: 270| Step: 0
Training loss: 1.3261774930989476
Validation loss: 2.4933499417331193

Epoch: 5| Step: 1
Training loss: 1.141975387311353
Validation loss: 2.483338870350469

Epoch: 5| Step: 2
Training loss: 0.977065117238498
Validation loss: 2.468516247213842

Epoch: 5| Step: 3
Training loss: 0.7945907615497105
Validation loss: 2.4759325400063035

Epoch: 5| Step: 4
Training loss: 1.3726797467708278
Validation loss: 2.480790732830464

Epoch: 5| Step: 5
Training loss: 1.0733478691960963
Validation loss: 2.432653691920894

Epoch: 5| Step: 6
Training loss: 1.5061704559216595
Validation loss: 2.457482343087907

Epoch: 5| Step: 7
Training loss: 1.6172890746425799
Validation loss: 2.4653989001159675

Epoch: 5| Step: 8
Training loss: 1.2257739405417123
Validation loss: 2.4639085780296557

Epoch: 5| Step: 9
Training loss: 1.0872423853428839
Validation loss: 2.4731910317898937

Epoch: 5| Step: 10
Training loss: 0.792842873791024
Validation loss: 2.457437370411144

Epoch: 271| Step: 0
Training loss: 1.4423710765115811
Validation loss: 2.42391727965054

Epoch: 5| Step: 1
Training loss: 1.3235372854759029
Validation loss: 2.470577674063113

Epoch: 5| Step: 2
Training loss: 1.1765107081388406
Validation loss: 2.4688411917510322

Epoch: 5| Step: 3
Training loss: 1.0494248381657294
Validation loss: 2.486486229119999

Epoch: 5| Step: 4
Training loss: 1.1997411130753668
Validation loss: 2.483534074358563

Epoch: 5| Step: 5
Training loss: 1.002019036041775
Validation loss: 2.4951899904123955

Epoch: 5| Step: 6
Training loss: 1.219872422426778
Validation loss: 2.507550490865399

Epoch: 5| Step: 7
Training loss: 1.2901109073336021
Validation loss: 2.5092217272712563

Epoch: 5| Step: 8
Training loss: 1.1233130628830292
Validation loss: 2.4916081613615004

Epoch: 5| Step: 9
Training loss: 1.3240249176849948
Validation loss: 2.502430118258209

Epoch: 5| Step: 10
Training loss: 0.9694517424241031
Validation loss: 2.4921776535431666

Epoch: 272| Step: 0
Training loss: 1.2870832101943892
Validation loss: 2.4868068246002526

Epoch: 5| Step: 1
Training loss: 1.375292746851239
Validation loss: 2.4827785273014853

Epoch: 5| Step: 2
Training loss: 1.3066639805461238
Validation loss: 2.460541863191167

Epoch: 5| Step: 3
Training loss: 0.9973301413526641
Validation loss: 2.4345573930167337

Epoch: 5| Step: 4
Training loss: 1.2474874039436419
Validation loss: 2.4415240825479176

Epoch: 5| Step: 5
Training loss: 1.5301751237264447
Validation loss: 2.4008378028252118

Epoch: 5| Step: 6
Training loss: 0.9692202626434384
Validation loss: 2.4146764669885292

Epoch: 5| Step: 7
Training loss: 0.986901477315997
Validation loss: 2.406245384643373

Epoch: 5| Step: 8
Training loss: 0.7429902403538335
Validation loss: 2.4282859112591164

Epoch: 5| Step: 9
Training loss: 1.42355256102372
Validation loss: 2.429692548800595

Epoch: 5| Step: 10
Training loss: 1.0290824768184756
Validation loss: 2.445201158470458

Epoch: 273| Step: 0
Training loss: 1.5057731633425897
Validation loss: 2.474070680374079

Epoch: 5| Step: 1
Training loss: 1.6893292155608282
Validation loss: 2.4926773645780584

Epoch: 5| Step: 2
Training loss: 0.9733261191632023
Validation loss: 2.491283261835538

Epoch: 5| Step: 3
Training loss: 1.176781871755476
Validation loss: 2.510286749486086

Epoch: 5| Step: 4
Training loss: 1.3648757136007919
Validation loss: 2.492188529699309

Epoch: 5| Step: 5
Training loss: 0.7952061175411362
Validation loss: 2.5113011237217315

Epoch: 5| Step: 6
Training loss: 0.9099982783542319
Validation loss: 2.4881444819938663

Epoch: 5| Step: 7
Training loss: 0.9437797668006828
Validation loss: 2.5089458482894216

Epoch: 5| Step: 8
Training loss: 0.9834190449833116
Validation loss: 2.4881910932148967

Epoch: 5| Step: 9
Training loss: 1.2132601213549847
Validation loss: 2.5033827834685662

Epoch: 5| Step: 10
Training loss: 1.1798641754633492
Validation loss: 2.4737519101787555

Epoch: 274| Step: 0
Training loss: 1.5385392747092932
Validation loss: 2.4844154225117485

Epoch: 5| Step: 1
Training loss: 1.5277227921657641
Validation loss: 2.4610816237539175

Epoch: 5| Step: 2
Training loss: 1.0460689345159224
Validation loss: 2.44499087479965

Epoch: 5| Step: 3
Training loss: 1.1883175695763908
Validation loss: 2.4495117098121

Epoch: 5| Step: 4
Training loss: 1.0386203025705218
Validation loss: 2.4104900657118518

Epoch: 5| Step: 5
Training loss: 0.6350137783042552
Validation loss: 2.396541457282774

Epoch: 5| Step: 6
Training loss: 0.9996124351010397
Validation loss: 2.413371703210782

Epoch: 5| Step: 7
Training loss: 1.051294704761303
Validation loss: 2.388456470574378

Epoch: 5| Step: 8
Training loss: 1.2006480990108577
Validation loss: 2.42651882064835

Epoch: 5| Step: 9
Training loss: 1.2489848783385487
Validation loss: 2.4528672413597943

Epoch: 5| Step: 10
Training loss: 1.2438757598019
Validation loss: 2.4568968577555017

Epoch: 275| Step: 0
Training loss: 0.972260482731574
Validation loss: 2.4774194483902274

Epoch: 5| Step: 1
Training loss: 1.234149236193237
Validation loss: 2.4904735966147564

Epoch: 5| Step: 2
Training loss: 1.2046358604594716
Validation loss: 2.51445076834271

Epoch: 5| Step: 3
Training loss: 1.3299112761453367
Validation loss: 2.503120048472681

Epoch: 5| Step: 4
Training loss: 0.939868383171979
Validation loss: 2.5036457776024412

Epoch: 5| Step: 5
Training loss: 1.3227825647504536
Validation loss: 2.5117542405509976

Epoch: 5| Step: 6
Training loss: 0.8144804952216828
Validation loss: 2.5049440513432715

Epoch: 5| Step: 7
Training loss: 1.439697079321306
Validation loss: 2.4970827535272613

Epoch: 5| Step: 8
Training loss: 1.2458208317379251
Validation loss: 2.463926000758343

Epoch: 5| Step: 9
Training loss: 1.0055597840589645
Validation loss: 2.4458362446071473

Epoch: 5| Step: 10
Training loss: 1.1954756980637247
Validation loss: 2.464028195665383

Epoch: 276| Step: 0
Training loss: 1.3353794114524635
Validation loss: 2.448006955072031

Epoch: 5| Step: 1
Training loss: 0.9818065680654234
Validation loss: 2.4314620880438422

Epoch: 5| Step: 2
Training loss: 1.1206138726877142
Validation loss: 2.434163136794706

Epoch: 5| Step: 3
Training loss: 1.1533805191901865
Validation loss: 2.4165686572281624

Epoch: 5| Step: 4
Training loss: 0.7421191535399435
Validation loss: 2.4308551385328236

Epoch: 5| Step: 5
Training loss: 0.9768426417033261
Validation loss: 2.4243855653544384

Epoch: 5| Step: 6
Training loss: 0.997997514134906
Validation loss: 2.4631430455975885

Epoch: 5| Step: 7
Training loss: 1.6287788322982488
Validation loss: 2.4712077500842855

Epoch: 5| Step: 8
Training loss: 1.096118324749293
Validation loss: 2.491120202384856

Epoch: 5| Step: 9
Training loss: 1.4081152942795372
Validation loss: 2.474564743633404

Epoch: 5| Step: 10
Training loss: 0.9274793414876763
Validation loss: 2.450274230538574

Epoch: 277| Step: 0
Training loss: 0.8193429939775468
Validation loss: 2.4614329005953626

Epoch: 5| Step: 1
Training loss: 0.8086644385947374
Validation loss: 2.465288775651214

Epoch: 5| Step: 2
Training loss: 0.5717479981694708
Validation loss: 2.461860982717551

Epoch: 5| Step: 3
Training loss: 0.8925503448904507
Validation loss: 2.4518747607470073

Epoch: 5| Step: 4
Training loss: 1.7249237154250168
Validation loss: 2.457534401245707

Epoch: 5| Step: 5
Training loss: 1.4489058082141366
Validation loss: 2.462645884102297

Epoch: 5| Step: 6
Training loss: 0.9577338617349748
Validation loss: 2.4527247149145723

Epoch: 5| Step: 7
Training loss: 0.8863686698157103
Validation loss: 2.44770710156527

Epoch: 5| Step: 8
Training loss: 1.6423942109155987
Validation loss: 2.430741694091381

Epoch: 5| Step: 9
Training loss: 1.0802287708925316
Validation loss: 2.441311157212248

Epoch: 5| Step: 10
Training loss: 1.1805403197308912
Validation loss: 2.444365447650397

Epoch: 278| Step: 0
Training loss: 1.0127010805118402
Validation loss: 2.4431242233356265

Epoch: 5| Step: 1
Training loss: 0.7421008812401919
Validation loss: 2.4287427818353167

Epoch: 5| Step: 2
Training loss: 1.1018305783721807
Validation loss: 2.443412524106491

Epoch: 5| Step: 3
Training loss: 1.177554089869022
Validation loss: 2.436634506405692

Epoch: 5| Step: 4
Training loss: 0.9567589197194069
Validation loss: 2.422435548226928

Epoch: 5| Step: 5
Training loss: 1.1349592191453068
Validation loss: 2.4477723226795427

Epoch: 5| Step: 6
Training loss: 1.0722389426324974
Validation loss: 2.474240257550772

Epoch: 5| Step: 7
Training loss: 1.0705997610596794
Validation loss: 2.4954321168914197

Epoch: 5| Step: 8
Training loss: 1.0282238573590312
Validation loss: 2.47155775887033

Epoch: 5| Step: 9
Training loss: 1.7623572704338706
Validation loss: 2.493329575237324

Epoch: 5| Step: 10
Training loss: 1.2196038018687523
Validation loss: 2.5144418573474585

Epoch: 279| Step: 0
Training loss: 0.9785767191623558
Validation loss: 2.4774183183852885

Epoch: 5| Step: 1
Training loss: 1.1944777622061062
Validation loss: 2.495715494815249

Epoch: 5| Step: 2
Training loss: 0.9879003099696089
Validation loss: 2.441069546884518

Epoch: 5| Step: 3
Training loss: 0.9966965889399394
Validation loss: 2.421688584726198

Epoch: 5| Step: 4
Training loss: 1.3273417238755505
Validation loss: 2.4384926067760166

Epoch: 5| Step: 5
Training loss: 0.8547445916280603
Validation loss: 2.4434157283764577

Epoch: 5| Step: 6
Training loss: 1.076273890816073
Validation loss: 2.4362323684208844

Epoch: 5| Step: 7
Training loss: 1.5418453714394713
Validation loss: 2.449709659556128

Epoch: 5| Step: 8
Training loss: 1.4292910500423632
Validation loss: 2.4741174614100685

Epoch: 5| Step: 9
Training loss: 0.9182410952174968
Validation loss: 2.474482486209005

Epoch: 5| Step: 10
Training loss: 0.9054840073439699
Validation loss: 2.4593166766103716

Epoch: 280| Step: 0
Training loss: 0.9356242488330585
Validation loss: 2.4986439452149747

Epoch: 5| Step: 1
Training loss: 1.2404742632175316
Validation loss: 2.4973957299964256

Epoch: 5| Step: 2
Training loss: 0.7899661413614688
Validation loss: 2.4842402728071256

Epoch: 5| Step: 3
Training loss: 1.2596049361543191
Validation loss: 2.534316848057987

Epoch: 5| Step: 4
Training loss: 1.4173007368883217
Validation loss: 2.5380347603487894

Epoch: 5| Step: 5
Training loss: 1.2618853574179423
Validation loss: 2.489120078513447

Epoch: 5| Step: 6
Training loss: 1.016822695614937
Validation loss: 2.4769167274260173

Epoch: 5| Step: 7
Training loss: 1.6373432579443865
Validation loss: 2.4693905326669587

Epoch: 5| Step: 8
Training loss: 0.6200222152913829
Validation loss: 2.4347677765164994

Epoch: 5| Step: 9
Training loss: 0.7899066450997341
Validation loss: 2.428523039135377

Epoch: 5| Step: 10
Training loss: 0.8600418278036827
Validation loss: 2.4349492970303883

Epoch: 281| Step: 0
Training loss: 1.2317625963555305
Validation loss: 2.4465523071008834

Epoch: 5| Step: 1
Training loss: 1.5023458733744501
Validation loss: 2.440556013218872

Epoch: 5| Step: 2
Training loss: 1.0147467116786384
Validation loss: 2.4535387211662614

Epoch: 5| Step: 3
Training loss: 1.2007358162697666
Validation loss: 2.4503491829011583

Epoch: 5| Step: 4
Training loss: 0.6203483571179379
Validation loss: 2.483811418583664

Epoch: 5| Step: 5
Training loss: 0.9575584983386021
Validation loss: 2.46726419378136

Epoch: 5| Step: 6
Training loss: 1.2880694176436627
Validation loss: 2.479338779474463

Epoch: 5| Step: 7
Training loss: 1.0998696921933993
Validation loss: 2.489150169015201

Epoch: 5| Step: 8
Training loss: 0.9511048530292762
Validation loss: 2.477614421370094

Epoch: 5| Step: 9
Training loss: 1.108273994081076
Validation loss: 2.4585060120162034

Epoch: 5| Step: 10
Training loss: 0.845539773225501
Validation loss: 2.441143316864576

Epoch: 282| Step: 0
Training loss: 1.3000260185425654
Validation loss: 2.476292246153035

Epoch: 5| Step: 1
Training loss: 1.022337927063467
Validation loss: 2.480247246209929

Epoch: 5| Step: 2
Training loss: 1.5541917786942954
Validation loss: 2.4603656469643336

Epoch: 5| Step: 3
Training loss: 0.7044138011044478
Validation loss: 2.439436775970538

Epoch: 5| Step: 4
Training loss: 0.9369239626884851
Validation loss: 2.4721482298758195

Epoch: 5| Step: 5
Training loss: 1.0276438343701133
Validation loss: 2.442299674816672

Epoch: 5| Step: 6
Training loss: 0.9608443610481302
Validation loss: 2.429898031357988

Epoch: 5| Step: 7
Training loss: 1.1873808349247543
Validation loss: 2.4454907637973475

Epoch: 5| Step: 8
Training loss: 1.0662086499370096
Validation loss: 2.445808487984833

Epoch: 5| Step: 9
Training loss: 0.9872063381212635
Validation loss: 2.445423279790408

Epoch: 5| Step: 10
Training loss: 0.9535417114840106
Validation loss: 2.4802199129323204

Epoch: 283| Step: 0
Training loss: 1.3715861161885148
Validation loss: 2.437811958537585

Epoch: 5| Step: 1
Training loss: 1.0935604476163823
Validation loss: 2.480141071214914

Epoch: 5| Step: 2
Training loss: 0.5652173422650727
Validation loss: 2.463232106331315

Epoch: 5| Step: 3
Training loss: 1.0681293804866816
Validation loss: 2.455232516363304

Epoch: 5| Step: 4
Training loss: 0.6049456890413868
Validation loss: 2.4789116937634765

Epoch: 5| Step: 5
Training loss: 0.5693818167101489
Validation loss: 2.438980619408325

Epoch: 5| Step: 6
Training loss: 1.071331791821051
Validation loss: 2.431380840732612

Epoch: 5| Step: 7
Training loss: 1.3428612808624678
Validation loss: 2.4350145866508153

Epoch: 5| Step: 8
Training loss: 0.9783742349469825
Validation loss: 2.424658132511855

Epoch: 5| Step: 9
Training loss: 1.506581728167062
Validation loss: 2.418576922346126

Epoch: 5| Step: 10
Training loss: 1.2169505308561588
Validation loss: 2.406742744936893

Epoch: 284| Step: 0
Training loss: 1.1462402083749332
Validation loss: 2.42156485676554

Epoch: 5| Step: 1
Training loss: 0.9263227464574932
Validation loss: 2.4203043014627

Epoch: 5| Step: 2
Training loss: 0.9274387249923401
Validation loss: 2.4231888969132402

Epoch: 5| Step: 3
Training loss: 0.7557476661007574
Validation loss: 2.4143550759357244

Epoch: 5| Step: 4
Training loss: 1.697972755051798
Validation loss: 2.4258773024040194

Epoch: 5| Step: 5
Training loss: 0.9670798764104718
Validation loss: 2.4398543391633747

Epoch: 5| Step: 6
Training loss: 0.9926150744818265
Validation loss: 2.42295342449595

Epoch: 5| Step: 7
Training loss: 1.091997541026606
Validation loss: 2.450694529048894

Epoch: 5| Step: 8
Training loss: 0.6893758757543319
Validation loss: 2.4785401455821914

Epoch: 5| Step: 9
Training loss: 1.0896937222599865
Validation loss: 2.4879457859322556

Epoch: 5| Step: 10
Training loss: 1.113062090801511
Validation loss: 2.4763803484619173

Epoch: 285| Step: 0
Training loss: 1.1167967853365979
Validation loss: 2.4823733920521156

Epoch: 5| Step: 1
Training loss: 1.152233674562542
Validation loss: 2.462558097231057

Epoch: 5| Step: 2
Training loss: 0.9975872437129583
Validation loss: 2.4678134058008085

Epoch: 5| Step: 3
Training loss: 0.9276848388296518
Validation loss: 2.4386105506742575

Epoch: 5| Step: 4
Training loss: 1.3592131507373184
Validation loss: 2.4305446750692274

Epoch: 5| Step: 5
Training loss: 0.9683290613006885
Validation loss: 2.408375160507518

Epoch: 5| Step: 6
Training loss: 0.6396406100427561
Validation loss: 2.4084567985717933

Epoch: 5| Step: 7
Training loss: 0.6614895960911606
Validation loss: 2.4107210831666497

Epoch: 5| Step: 8
Training loss: 1.1095221515900795
Validation loss: 2.4374570598243466

Epoch: 5| Step: 9
Training loss: 0.6274531856870932
Validation loss: 2.422934861743921

Epoch: 5| Step: 10
Training loss: 1.6771305227650037
Validation loss: 2.4654187507383987

Epoch: 286| Step: 0
Training loss: 1.024467474142328
Validation loss: 2.459962163064435

Epoch: 5| Step: 1
Training loss: 0.7684045278976773
Validation loss: 2.4671028055388566

Epoch: 5| Step: 2
Training loss: 1.1594557782845731
Validation loss: 2.477760581802327

Epoch: 5| Step: 3
Training loss: 0.9274209547162803
Validation loss: 2.506244047170787

Epoch: 5| Step: 4
Training loss: 0.9568187244094961
Validation loss: 2.480619047167267

Epoch: 5| Step: 5
Training loss: 1.0045901095587526
Validation loss: 2.5351165495847807

Epoch: 5| Step: 6
Training loss: 1.238946633615904
Validation loss: 2.5186659528749016

Epoch: 5| Step: 7
Training loss: 0.9936986813999735
Validation loss: 2.4975919477880564

Epoch: 5| Step: 8
Training loss: 1.3675694831198097
Validation loss: 2.4868172974564944

Epoch: 5| Step: 9
Training loss: 1.0952116872237727
Validation loss: 2.4499317645209393

Epoch: 5| Step: 10
Training loss: 0.9252829840531533
Validation loss: 2.429123390577895

Epoch: 287| Step: 0
Training loss: 0.9098687434116963
Validation loss: 2.395055787195058

Epoch: 5| Step: 1
Training loss: 1.014117310252094
Validation loss: 2.395380897300788

Epoch: 5| Step: 2
Training loss: 0.9344156390382103
Validation loss: 2.403890084558608

Epoch: 5| Step: 3
Training loss: 1.3228811975164718
Validation loss: 2.402052446470645

Epoch: 5| Step: 4
Training loss: 0.9214642789750794
Validation loss: 2.387252966684127

Epoch: 5| Step: 5
Training loss: 1.4752334991809646
Validation loss: 2.3779605252079614

Epoch: 5| Step: 6
Training loss: 0.9538479548956714
Validation loss: 2.4206192534746465

Epoch: 5| Step: 7
Training loss: 1.0201465606112452
Validation loss: 2.4226309690387775

Epoch: 5| Step: 8
Training loss: 0.9468430038434604
Validation loss: 2.4528262623536823

Epoch: 5| Step: 9
Training loss: 1.1363128776484621
Validation loss: 2.4146470616805438

Epoch: 5| Step: 10
Training loss: 0.655061030747737
Validation loss: 2.4696324927071083

Epoch: 288| Step: 0
Training loss: 0.940630359571022
Validation loss: 2.47149237969564

Epoch: 5| Step: 1
Training loss: 1.3718699027207901
Validation loss: 2.483394678851176

Epoch: 5| Step: 2
Training loss: 1.1497010526612634
Validation loss: 2.4824137061907434

Epoch: 5| Step: 3
Training loss: 1.1179385561701072
Validation loss: 2.4704024637496174

Epoch: 5| Step: 4
Training loss: 0.8942780781924373
Validation loss: 2.4948687469031228

Epoch: 5| Step: 5
Training loss: 1.2758395703190486
Validation loss: 2.4950501600497326

Epoch: 5| Step: 6
Training loss: 0.7728804692089203
Validation loss: 2.4995914012522453

Epoch: 5| Step: 7
Training loss: 0.5848228024016273
Validation loss: 2.5065830679907903

Epoch: 5| Step: 8
Training loss: 1.0602476143876474
Validation loss: 2.48064177767709

Epoch: 5| Step: 9
Training loss: 0.9926060972509559
Validation loss: 2.4842778937153622

Epoch: 5| Step: 10
Training loss: 0.9162992839387042
Validation loss: 2.4357814125746673

Epoch: 289| Step: 0
Training loss: 1.0973393536001221
Validation loss: 2.437180423217212

Epoch: 5| Step: 1
Training loss: 0.9876183861377167
Validation loss: 2.4326219783478624

Epoch: 5| Step: 2
Training loss: 1.1041471851477622
Validation loss: 2.4050072906392503

Epoch: 5| Step: 3
Training loss: 0.9106180550252169
Validation loss: 2.396933289101889

Epoch: 5| Step: 4
Training loss: 0.8237901630943247
Validation loss: 2.3976945500314395

Epoch: 5| Step: 5
Training loss: 0.9497567681083707
Validation loss: 2.405171467332662

Epoch: 5| Step: 6
Training loss: 1.5518342486042094
Validation loss: 2.3888220066027053

Epoch: 5| Step: 7
Training loss: 0.9383225964687972
Validation loss: 2.3947179074803535

Epoch: 5| Step: 8
Training loss: 1.1277175505664487
Validation loss: 2.4386768660519462

Epoch: 5| Step: 9
Training loss: 0.6320513633668057
Validation loss: 2.4086800993220376

Epoch: 5| Step: 10
Training loss: 0.9247801957719161
Validation loss: 2.430020739483187

Epoch: 290| Step: 0
Training loss: 0.40602732938243097
Validation loss: 2.446177836685484

Epoch: 5| Step: 1
Training loss: 0.7286374396785288
Validation loss: 2.4238924947033373

Epoch: 5| Step: 2
Training loss: 1.6019623792186142
Validation loss: 2.4522486999316984

Epoch: 5| Step: 3
Training loss: 1.1093741940777497
Validation loss: 2.4429146319020343

Epoch: 5| Step: 4
Training loss: 0.8696974438706383
Validation loss: 2.4237432582420264

Epoch: 5| Step: 5
Training loss: 0.42813093710353717
Validation loss: 2.428758138343282

Epoch: 5| Step: 6
Training loss: 1.4348892885625422
Validation loss: 2.43638025273646

Epoch: 5| Step: 7
Training loss: 1.02540724967922
Validation loss: 2.4358051635213034

Epoch: 5| Step: 8
Training loss: 0.8929995287032128
Validation loss: 2.4488605307238176

Epoch: 5| Step: 9
Training loss: 1.1870372774172724
Validation loss: 2.4444579628143015

Epoch: 5| Step: 10
Training loss: 0.9083763039483638
Validation loss: 2.4542842895370844

Epoch: 291| Step: 0
Training loss: 1.0336125217154624
Validation loss: 2.427869579003489

Epoch: 5| Step: 1
Training loss: 0.7868556141302232
Validation loss: 2.444707143520083

Epoch: 5| Step: 2
Training loss: 1.2114923498090837
Validation loss: 2.414797748885484

Epoch: 5| Step: 3
Training loss: 1.0189965259915807
Validation loss: 2.431030178890586

Epoch: 5| Step: 4
Training loss: 1.0855766080920974
Validation loss: 2.4260387210367247

Epoch: 5| Step: 5
Training loss: 1.4565743146612395
Validation loss: 2.4187998730780493

Epoch: 5| Step: 6
Training loss: 1.031606554756477
Validation loss: 2.439641664258696

Epoch: 5| Step: 7
Training loss: 0.4996998154039254
Validation loss: 2.4570899336988803

Epoch: 5| Step: 8
Training loss: 0.8867423436727236
Validation loss: 2.4316108286333793

Epoch: 5| Step: 9
Training loss: 0.9601220493417819
Validation loss: 2.4381302775157043

Epoch: 5| Step: 10
Training loss: 0.9079300336537995
Validation loss: 2.451887469785684

Epoch: 292| Step: 0
Training loss: 1.1544252895436233
Validation loss: 2.434057340853524

Epoch: 5| Step: 1
Training loss: 0.90633608968198
Validation loss: 2.4308131936248665

Epoch: 5| Step: 2
Training loss: 0.7973565535252765
Validation loss: 2.4286961084749144

Epoch: 5| Step: 3
Training loss: 0.9007724771461181
Validation loss: 2.41953627087231

Epoch: 5| Step: 4
Training loss: 1.259222957624408
Validation loss: 2.4130332465837134

Epoch: 5| Step: 5
Training loss: 1.5027500216227523
Validation loss: 2.443207591087235

Epoch: 5| Step: 6
Training loss: 0.9113773782291233
Validation loss: 2.4021602416129166

Epoch: 5| Step: 7
Training loss: 0.9100583723755465
Validation loss: 2.4316172007976733

Epoch: 5| Step: 8
Training loss: 0.7429656517052454
Validation loss: 2.4642728200843624

Epoch: 5| Step: 9
Training loss: 0.8938275363607763
Validation loss: 2.4344643699761055

Epoch: 5| Step: 10
Training loss: 1.0486559167065606
Validation loss: 2.46490050144354

Epoch: 293| Step: 0
Training loss: 0.6751442702081831
Validation loss: 2.445356163996138

Epoch: 5| Step: 1
Training loss: 0.883613560570014
Validation loss: 2.4681232508856326

Epoch: 5| Step: 2
Training loss: 0.9782377598516117
Validation loss: 2.4475073506001697

Epoch: 5| Step: 3
Training loss: 0.9770146048204866
Validation loss: 2.445634829258695

Epoch: 5| Step: 4
Training loss: 1.0341240685107282
Validation loss: 2.454594744197985

Epoch: 5| Step: 5
Training loss: 1.2360134598144177
Validation loss: 2.4603919348228667

Epoch: 5| Step: 6
Training loss: 1.6077243524972404
Validation loss: 2.4597388428459603

Epoch: 5| Step: 7
Training loss: 0.8363798165593862
Validation loss: 2.464045002140183

Epoch: 5| Step: 8
Training loss: 0.8233300430281012
Validation loss: 2.4536834952615068

Epoch: 5| Step: 9
Training loss: 0.9186104013173467
Validation loss: 2.452165811011534

Epoch: 5| Step: 10
Training loss: 0.6395316446854384
Validation loss: 2.458146286472786

Epoch: 294| Step: 0
Training loss: 0.8135314776327556
Validation loss: 2.433448618231156

Epoch: 5| Step: 1
Training loss: 0.7335110309996121
Validation loss: 2.477911033404289

Epoch: 5| Step: 2
Training loss: 1.0273546573654582
Validation loss: 2.4824137660885577

Epoch: 5| Step: 3
Training loss: 1.239688975643648
Validation loss: 2.525184253592596

Epoch: 5| Step: 4
Training loss: 1.2070282377433843
Validation loss: 2.5007646673057087

Epoch: 5| Step: 5
Training loss: 0.7308544425859083
Validation loss: 2.481977940255561

Epoch: 5| Step: 6
Training loss: 0.9373071154216999
Validation loss: 2.4706899996438905

Epoch: 5| Step: 7
Training loss: 0.6277543649297628
Validation loss: 2.4741264212758716

Epoch: 5| Step: 8
Training loss: 0.8251821302455777
Validation loss: 2.4395921645641243

Epoch: 5| Step: 9
Training loss: 0.8308041258728328
Validation loss: 2.443396355803959

Epoch: 5| Step: 10
Training loss: 1.6996624246786125
Validation loss: 2.432312431825633

Epoch: 295| Step: 0
Training loss: 1.076050628644484
Validation loss: 2.443966668136924

Epoch: 5| Step: 1
Training loss: 0.9783107824883799
Validation loss: 2.4410690811154323

Epoch: 5| Step: 2
Training loss: 0.9612571990855956
Validation loss: 2.417821916904987

Epoch: 5| Step: 3
Training loss: 0.8759892525492636
Validation loss: 2.4270571191850747

Epoch: 5| Step: 4
Training loss: 1.047883075051841
Validation loss: 2.424567352978966

Epoch: 5| Step: 5
Training loss: 1.0477712410239393
Validation loss: 2.4491652432997557

Epoch: 5| Step: 6
Training loss: 1.5196004425220895
Validation loss: 2.4397581813457236

Epoch: 5| Step: 7
Training loss: 0.8250149320927255
Validation loss: 2.4616515171211577

Epoch: 5| Step: 8
Training loss: 0.46626270328019354
Validation loss: 2.479597692401643

Epoch: 5| Step: 9
Training loss: 0.9718208555490043
Validation loss: 2.499678619811101

Epoch: 5| Step: 10
Training loss: 0.8858242817006865
Validation loss: 2.4824020467438617

Epoch: 296| Step: 0
Training loss: 0.7185785254889362
Validation loss: 2.5071481202834187

Epoch: 5| Step: 1
Training loss: 1.4801025742992908
Validation loss: 2.4833910358158917

Epoch: 5| Step: 2
Training loss: 0.9242798424696601
Validation loss: 2.4406794007907338

Epoch: 5| Step: 3
Training loss: 0.8114690108243563
Validation loss: 2.44717594809958

Epoch: 5| Step: 4
Training loss: 0.5487211944562128
Validation loss: 2.4270794075491335

Epoch: 5| Step: 5
Training loss: 0.7111360461322088
Validation loss: 2.4129251530858857

Epoch: 5| Step: 6
Training loss: 1.088029506728518
Validation loss: 2.440814335167666

Epoch: 5| Step: 7
Training loss: 1.0660069874504063
Validation loss: 2.440526038403214

Epoch: 5| Step: 8
Training loss: 0.988201635719834
Validation loss: 2.4585683810028955

Epoch: 5| Step: 9
Training loss: 0.850883913457772
Validation loss: 2.4748766314719033

Epoch: 5| Step: 10
Training loss: 1.3436825757521316
Validation loss: 2.482804343978661

Epoch: 297| Step: 0
Training loss: 0.9027804684395104
Validation loss: 2.4567244597229356

Epoch: 5| Step: 1
Training loss: 1.4748636796964472
Validation loss: 2.447474070804698

Epoch: 5| Step: 2
Training loss: 0.8730824439805909
Validation loss: 2.435990476417336

Epoch: 5| Step: 3
Training loss: 1.0860910101318044
Validation loss: 2.466321487755728

Epoch: 5| Step: 4
Training loss: 1.0474628676795568
Validation loss: 2.459339116681106

Epoch: 5| Step: 5
Training loss: 0.9897968597265173
Validation loss: 2.4537225020033735

Epoch: 5| Step: 6
Training loss: 1.093244108643481
Validation loss: 2.448469381218218

Epoch: 5| Step: 7
Training loss: 0.843072195131543
Validation loss: 2.4443491419650356

Epoch: 5| Step: 8
Training loss: 0.7045799672365759
Validation loss: 2.463332678402783

Epoch: 5| Step: 9
Training loss: 0.5867968297782375
Validation loss: 2.454230278017096

Epoch: 5| Step: 10
Training loss: 0.899295629269
Validation loss: 2.46171679316183

Epoch: 298| Step: 0
Training loss: 0.9357378929897964
Validation loss: 2.465533477757753

Epoch: 5| Step: 1
Training loss: 0.9689699969139569
Validation loss: 2.4345651548238925

Epoch: 5| Step: 2
Training loss: 1.6565208933278621
Validation loss: 2.4363373296542026

Epoch: 5| Step: 3
Training loss: 0.9102565726462261
Validation loss: 2.4387989390513884

Epoch: 5| Step: 4
Training loss: 0.9119371990929908
Validation loss: 2.4244890039774263

Epoch: 5| Step: 5
Training loss: 0.8041515602577223
Validation loss: 2.4198707091082303

Epoch: 5| Step: 6
Training loss: 0.9164684616006726
Validation loss: 2.39078686057846

Epoch: 5| Step: 7
Training loss: 0.8455558807251559
Validation loss: 2.425583567533774

Epoch: 5| Step: 8
Training loss: 0.9680027079071443
Validation loss: 2.4302699589758414

Epoch: 5| Step: 9
Training loss: 0.9634485079433104
Validation loss: 2.429278381446217

Epoch: 5| Step: 10
Training loss: 0.31140422632810694
Validation loss: 2.448015018774767

Epoch: 299| Step: 0
Training loss: 1.4121248236479897
Validation loss: 2.4313985429392035

Epoch: 5| Step: 1
Training loss: 0.9858951033531275
Validation loss: 2.4374459426056023

Epoch: 5| Step: 2
Training loss: 0.728113303684055
Validation loss: 2.4458419686310506

Epoch: 5| Step: 3
Training loss: 1.0051407404230348
Validation loss: 2.444092718214134

Epoch: 5| Step: 4
Training loss: 1.179051309790793
Validation loss: 2.426840240319251

Epoch: 5| Step: 5
Training loss: 0.8766400770378253
Validation loss: 2.4412963128389307

Epoch: 5| Step: 6
Training loss: 1.000873839527161
Validation loss: 2.429855652652431

Epoch: 5| Step: 7
Training loss: 0.4908441952937547
Validation loss: 2.4168337939913034

Epoch: 5| Step: 8
Training loss: 0.6477641780734146
Validation loss: 2.4469851800200333

Epoch: 5| Step: 9
Training loss: 1.0505944975918926
Validation loss: 2.4470772677081762

Epoch: 5| Step: 10
Training loss: 0.8956119056697452
Validation loss: 2.4483788641516506

Epoch: 300| Step: 0
Training loss: 0.619839463407841
Validation loss: 2.4612990601230678

Epoch: 5| Step: 1
Training loss: 1.1941771756544097
Validation loss: 2.4703936730206655

Epoch: 5| Step: 2
Training loss: 0.8912040099895294
Validation loss: 2.4691064031374452

Epoch: 5| Step: 3
Training loss: 0.8976621848392426
Validation loss: 2.4684535692702596

Epoch: 5| Step: 4
Training loss: 0.6830262798793981
Validation loss: 2.450092767671463

Epoch: 5| Step: 5
Training loss: 1.434702930072492
Validation loss: 2.4383315063511883

Epoch: 5| Step: 6
Training loss: 0.7849291952358893
Validation loss: 2.444244565681642

Epoch: 5| Step: 7
Training loss: 1.1712275941999772
Validation loss: 2.4222189382167256

Epoch: 5| Step: 8
Training loss: 1.0886504500696395
Validation loss: 2.4040111428175353

Epoch: 5| Step: 9
Training loss: 0.6287581227879422
Validation loss: 2.3775916420951146

Epoch: 5| Step: 10
Training loss: 0.6292151409279644
Validation loss: 2.4032915064153193

Testing loss: 2.3736946188240626
