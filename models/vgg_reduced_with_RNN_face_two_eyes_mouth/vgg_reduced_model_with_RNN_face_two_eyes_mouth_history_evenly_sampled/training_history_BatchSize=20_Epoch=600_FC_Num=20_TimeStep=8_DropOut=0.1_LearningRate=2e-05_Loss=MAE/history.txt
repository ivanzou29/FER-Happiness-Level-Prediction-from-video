Epoch: 1| Step: 0
Training loss: 4.589041709899902
Validation loss: 5.1180714279092765

Epoch: 5| Step: 1
Training loss: 4.4440507888793945
Validation loss: 5.094116800574846

Epoch: 5| Step: 2
Training loss: 4.201178550720215
Validation loss: 5.069738946935182

Epoch: 5| Step: 3
Training loss: 4.9924516677856445
Validation loss: 5.043060636007658

Epoch: 5| Step: 4
Training loss: 5.172228813171387
Validation loss: 5.012996222383233

Epoch: 5| Step: 5
Training loss: 4.04581356048584
Validation loss: 4.980026829627253

Epoch: 5| Step: 6
Training loss: 5.162674903869629
Validation loss: 4.943395419787335

Epoch: 5| Step: 7
Training loss: 4.769099235534668
Validation loss: 4.9033859981003625

Epoch: 5| Step: 8
Training loss: 6.135032653808594
Validation loss: 4.858847905230778

Epoch: 5| Step: 9
Training loss: 4.580574989318848
Validation loss: 4.8088118696725495

Epoch: 5| Step: 10
Training loss: 4.098395347595215
Validation loss: 4.754319954943913

Epoch: 2| Step: 0
Training loss: 3.854707717895508
Validation loss: 4.695246711854012

Epoch: 5| Step: 1
Training loss: 4.540563106536865
Validation loss: 4.632872248208651

Epoch: 5| Step: 2
Training loss: 4.092309474945068
Validation loss: 4.566511031120054

Epoch: 5| Step: 3
Training loss: 4.301184177398682
Validation loss: 4.495264443018103

Epoch: 5| Step: 4
Training loss: 5.082685947418213
Validation loss: 4.419934426584551

Epoch: 5| Step: 5
Training loss: 3.9706826210021973
Validation loss: 4.345315774281819

Epoch: 5| Step: 6
Training loss: 4.343222618103027
Validation loss: 4.2706719829190165

Epoch: 5| Step: 7
Training loss: 5.0320563316345215
Validation loss: 4.198535832025671

Epoch: 5| Step: 8
Training loss: 4.041659355163574
Validation loss: 4.129581113015452

Epoch: 5| Step: 9
Training loss: 2.6821837425231934
Validation loss: 4.058859502115557

Epoch: 5| Step: 10
Training loss: 3.7100276947021484
Validation loss: 3.992533519703855

Epoch: 3| Step: 0
Training loss: 4.0986151695251465
Validation loss: 3.9308281611370783

Epoch: 5| Step: 1
Training loss: 3.2399768829345703
Validation loss: 3.8732831478118896

Epoch: 5| Step: 2
Training loss: 3.270853042602539
Validation loss: 3.8188167951440297

Epoch: 5| Step: 3
Training loss: 3.335155963897705
Validation loss: 3.7680774709229827

Epoch: 5| Step: 4
Training loss: 3.0141749382019043
Validation loss: 3.721213161304433

Epoch: 5| Step: 5
Training loss: 4.961956977844238
Validation loss: 3.6798801165755077

Epoch: 5| Step: 6
Training loss: 3.287307024002075
Validation loss: 3.6389460025295133

Epoch: 5| Step: 7
Training loss: 2.8076999187469482
Validation loss: 3.6021745410016788

Epoch: 5| Step: 8
Training loss: 3.5058035850524902
Validation loss: 3.568758226210071

Epoch: 5| Step: 9
Training loss: 3.8595738410949707
Validation loss: 3.5405011741063928

Epoch: 5| Step: 10
Training loss: 4.1633100509643555
Validation loss: 3.508524020512899

Epoch: 4| Step: 0
Training loss: 3.1957499980926514
Validation loss: 3.4797967428802163

Epoch: 5| Step: 1
Training loss: 4.611111640930176
Validation loss: 3.4559612479261173

Epoch: 5| Step: 2
Training loss: 3.324737071990967
Validation loss: 3.428657249737811

Epoch: 5| Step: 3
Training loss: 3.0549683570861816
Validation loss: 3.3992548860529417

Epoch: 5| Step: 4
Training loss: 3.7351646423339844
Validation loss: 3.37894255627868

Epoch: 5| Step: 5
Training loss: 2.3395919799804688
Validation loss: 3.358486008900468

Epoch: 5| Step: 6
Training loss: 2.774935722351074
Validation loss: 3.386109462348364

Epoch: 5| Step: 7
Training loss: 3.556858777999878
Validation loss: 3.3730029085631013

Epoch: 5| Step: 8
Training loss: 3.236816883087158
Validation loss: 3.3526385240657355

Epoch: 5| Step: 9
Training loss: 2.7330691814422607
Validation loss: 3.31141596968456

Epoch: 5| Step: 10
Training loss: 4.301085948944092
Validation loss: 3.283712940831338

Epoch: 5| Step: 0
Training loss: 2.3342227935791016
Validation loss: 3.2638246987455632

Epoch: 5| Step: 1
Training loss: 3.5974769592285156
Validation loss: 3.2530752945971746

Epoch: 5| Step: 2
Training loss: 3.986860990524292
Validation loss: 3.2475815588428127

Epoch: 5| Step: 3
Training loss: 3.454145908355713
Validation loss: 3.2552927335103354

Epoch: 5| Step: 4
Training loss: 3.0072131156921387
Validation loss: 3.2423805267580095

Epoch: 5| Step: 5
Training loss: 2.8288064002990723
Validation loss: 3.230608845269808

Epoch: 5| Step: 6
Training loss: 2.7039692401885986
Validation loss: 3.224889193811724

Epoch: 5| Step: 7
Training loss: 3.0684421062469482
Validation loss: 3.2128158487299436

Epoch: 5| Step: 8
Training loss: 3.6601665019989014
Validation loss: 3.1987431459529425

Epoch: 5| Step: 9
Training loss: 3.3223495483398438
Validation loss: 3.1789545679605133

Epoch: 5| Step: 10
Training loss: 3.3879237174987793
Validation loss: 3.168508134862428

Epoch: 6| Step: 0
Training loss: 3.3506832122802734
Validation loss: 3.158469095025011

Epoch: 5| Step: 1
Training loss: 2.6307151317596436
Validation loss: 3.146427336559501

Epoch: 5| Step: 2
Training loss: 3.983341932296753
Validation loss: 3.1301441807900705

Epoch: 5| Step: 3
Training loss: 3.1944949626922607
Validation loss: 3.120258900427049

Epoch: 5| Step: 4
Training loss: 2.836944580078125
Validation loss: 3.113858489580052

Epoch: 5| Step: 5
Training loss: 3.272538423538208
Validation loss: 3.0977942277026433

Epoch: 5| Step: 6
Training loss: 2.548095941543579
Validation loss: 3.0846715281086583

Epoch: 5| Step: 7
Training loss: 3.316964626312256
Validation loss: 3.0766072350163616

Epoch: 5| Step: 8
Training loss: 3.1723551750183105
Validation loss: 3.078996930071103

Epoch: 5| Step: 9
Training loss: 3.057436943054199
Validation loss: 3.078599683700069

Epoch: 5| Step: 10
Training loss: 3.115466833114624
Validation loss: 3.065147087138186

Epoch: 7| Step: 0
Training loss: 3.0551674365997314
Validation loss: 3.049813880715319

Epoch: 5| Step: 1
Training loss: 3.059142827987671
Validation loss: 3.0377259254455566

Epoch: 5| Step: 2
Training loss: 1.775816559791565
Validation loss: 3.029401966320571

Epoch: 5| Step: 3
Training loss: 3.1305148601531982
Validation loss: 3.0287704211409374

Epoch: 5| Step: 4
Training loss: 3.5576679706573486
Validation loss: 3.0235726987161944

Epoch: 5| Step: 5
Training loss: 3.2887721061706543
Validation loss: 3.0207642175818004

Epoch: 5| Step: 6
Training loss: 2.4815711975097656
Validation loss: 3.013213788309405

Epoch: 5| Step: 7
Training loss: 3.320728302001953
Validation loss: 3.007618027348672

Epoch: 5| Step: 8
Training loss: 3.5567634105682373
Validation loss: 3.0020845038916475

Epoch: 5| Step: 9
Training loss: 3.889620542526245
Validation loss: 2.995895008887014

Epoch: 5| Step: 10
Training loss: 2.6512577533721924
Validation loss: 2.984038242729761

Epoch: 8| Step: 0
Training loss: 2.8360607624053955
Validation loss: 2.9765884542977936

Epoch: 5| Step: 1
Training loss: 2.9073758125305176
Validation loss: 2.973292386660012

Epoch: 5| Step: 2
Training loss: 3.515583038330078
Validation loss: 2.9657288674385316

Epoch: 5| Step: 3
Training loss: 3.0065736770629883
Validation loss: 2.9627983775190128

Epoch: 5| Step: 4
Training loss: 2.421259641647339
Validation loss: 2.9572655488086004

Epoch: 5| Step: 5
Training loss: 3.572650194168091
Validation loss: 2.95455006886554

Epoch: 5| Step: 6
Training loss: 2.6544249057769775
Validation loss: 2.949542366048341

Epoch: 5| Step: 7
Training loss: 3.277949571609497
Validation loss: 2.9430533660355436

Epoch: 5| Step: 8
Training loss: 2.9966044425964355
Validation loss: 2.9431024084809008

Epoch: 5| Step: 9
Training loss: 3.3479714393615723
Validation loss: 2.933705124803769

Epoch: 5| Step: 10
Training loss: 2.790262460708618
Validation loss: 2.9322786895177697

Epoch: 9| Step: 0
Training loss: 3.7302467823028564
Validation loss: 2.9534674921343402

Epoch: 5| Step: 1
Training loss: 2.8635663986206055
Validation loss: 2.921924647464547

Epoch: 5| Step: 2
Training loss: 4.411258697509766
Validation loss: 2.9188131824616463

Epoch: 5| Step: 3
Training loss: 3.4425601959228516
Validation loss: 2.915190209624588

Epoch: 5| Step: 4
Training loss: 2.060523748397827
Validation loss: 2.912605183098906

Epoch: 5| Step: 5
Training loss: 2.7664971351623535
Validation loss: 2.906728885507071

Epoch: 5| Step: 6
Training loss: 2.744870662689209
Validation loss: 2.904556248777656

Epoch: 5| Step: 7
Training loss: 1.8675975799560547
Validation loss: 2.9008689439424904

Epoch: 5| Step: 8
Training loss: 2.9371237754821777
Validation loss: 2.8958532271846646

Epoch: 5| Step: 9
Training loss: 2.77168345451355
Validation loss: 2.8942971511553695

Epoch: 5| Step: 10
Training loss: 3.5702502727508545
Validation loss: 2.923328732931486

Epoch: 10| Step: 0
Training loss: 2.6161084175109863
Validation loss: 2.8850931634185133

Epoch: 5| Step: 1
Training loss: 2.941204786300659
Validation loss: 2.884216829012799

Epoch: 5| Step: 2
Training loss: 2.8286890983581543
Validation loss: 2.8844651919539257

Epoch: 5| Step: 3
Training loss: 2.451939344406128
Validation loss: 2.88329041388727

Epoch: 5| Step: 4
Training loss: 3.4444401264190674
Validation loss: 2.8816664808539936

Epoch: 5| Step: 5
Training loss: 3.127709150314331
Validation loss: 2.877421804653701

Epoch: 5| Step: 6
Training loss: 3.2059435844421387
Validation loss: 2.8720166375560146

Epoch: 5| Step: 7
Training loss: 2.9563827514648438
Validation loss: 2.874851862589518

Epoch: 5| Step: 8
Training loss: 2.5279273986816406
Validation loss: 2.8685994763528146

Epoch: 5| Step: 9
Training loss: 3.1535983085632324
Validation loss: 2.870495693657988

Epoch: 5| Step: 10
Training loss: 3.6712605953216553
Validation loss: 2.863236411925285

Epoch: 11| Step: 0
Training loss: 3.131971597671509
Validation loss: 2.865843185814478

Epoch: 5| Step: 1
Training loss: 3.9668948650360107
Validation loss: 2.8569134281527613

Epoch: 5| Step: 2
Training loss: 2.8047895431518555
Validation loss: 2.8458161328428533

Epoch: 5| Step: 3
Training loss: 2.6410984992980957
Validation loss: 2.846505888046757

Epoch: 5| Step: 4
Training loss: 3.0195279121398926
Validation loss: 2.847803656772901

Epoch: 5| Step: 5
Training loss: 2.9626011848449707
Validation loss: 2.8397304550293954

Epoch: 5| Step: 6
Training loss: 3.3783462047576904
Validation loss: 2.841023357965613

Epoch: 5| Step: 7
Training loss: 2.6471848487854004
Validation loss: 2.841085674942181

Epoch: 5| Step: 8
Training loss: 2.9483377933502197
Validation loss: 2.8353906959615727

Epoch: 5| Step: 9
Training loss: 2.740320920944214
Validation loss: 2.8275527646464687

Epoch: 5| Step: 10
Training loss: 2.1628220081329346
Validation loss: 2.8209163783698954

Epoch: 12| Step: 0
Training loss: 2.7326858043670654
Validation loss: 2.8281832074606292

Epoch: 5| Step: 1
Training loss: 3.1567606925964355
Validation loss: 2.8319020399483303

Epoch: 5| Step: 2
Training loss: 2.6039280891418457
Validation loss: 2.8242488830320296

Epoch: 5| Step: 3
Training loss: 2.3997080326080322
Validation loss: 2.8144373791192168

Epoch: 5| Step: 4
Training loss: 3.1948719024658203
Validation loss: 2.805307649797009

Epoch: 5| Step: 5
Training loss: 2.769245147705078
Validation loss: 2.8006529884953655

Epoch: 5| Step: 6
Training loss: 3.6990742683410645
Validation loss: 2.7946061524011756

Epoch: 5| Step: 7
Training loss: 3.4732251167297363
Validation loss: 2.793561363732943

Epoch: 5| Step: 8
Training loss: 2.6167070865631104
Validation loss: 2.794385633160991

Epoch: 5| Step: 9
Training loss: 3.0296850204467773
Validation loss: 2.797464560436946

Epoch: 5| Step: 10
Training loss: 2.564023733139038
Validation loss: 2.796526026982133

Epoch: 13| Step: 0
Training loss: 2.4801459312438965
Validation loss: 2.7794887404288016

Epoch: 5| Step: 1
Training loss: 3.2998008728027344
Validation loss: 2.7811306343283704

Epoch: 5| Step: 2
Training loss: 3.0109095573425293
Validation loss: 2.7901716001572145

Epoch: 5| Step: 3
Training loss: 3.202702045440674
Validation loss: 2.7836312606770504

Epoch: 5| Step: 4
Training loss: 2.248373508453369
Validation loss: 2.7771300808075936

Epoch: 5| Step: 5
Training loss: 3.0272724628448486
Validation loss: 2.778211857682915

Epoch: 5| Step: 6
Training loss: 2.2103984355926514
Validation loss: 2.7744494099770822

Epoch: 5| Step: 7
Training loss: 3.188133716583252
Validation loss: 2.7677072940334195

Epoch: 5| Step: 8
Training loss: 3.066779613494873
Validation loss: 2.76226229821482

Epoch: 5| Step: 9
Training loss: 3.1438496112823486
Validation loss: 2.7576445482110463

Epoch: 5| Step: 10
Training loss: 3.2591845989227295
Validation loss: 2.768063396535894

Epoch: 14| Step: 0
Training loss: 2.0075631141662598
Validation loss: 2.774304936009069

Epoch: 5| Step: 1
Training loss: 2.7969672679901123
Validation loss: 2.7767558815658733

Epoch: 5| Step: 2
Training loss: 2.990204334259033
Validation loss: 2.772121467897969

Epoch: 5| Step: 3
Training loss: 2.0868136882781982
Validation loss: 2.767753762583579

Epoch: 5| Step: 4
Training loss: 2.839871644973755
Validation loss: 2.7603581438782396

Epoch: 5| Step: 5
Training loss: 3.294706344604492
Validation loss: 2.7653888271700953

Epoch: 5| Step: 6
Training loss: 2.9398295879364014
Validation loss: 2.7483944944156113

Epoch: 5| Step: 7
Training loss: 4.088879585266113
Validation loss: 2.746756466486121

Epoch: 5| Step: 8
Training loss: 3.210458278656006
Validation loss: 2.7439548712904736

Epoch: 5| Step: 9
Training loss: 3.0843443870544434
Validation loss: 2.739339264490271

Epoch: 5| Step: 10
Training loss: 2.5201804637908936
Validation loss: 2.740022982320478

Epoch: 15| Step: 0
Training loss: 3.1700024604797363
Validation loss: 2.7400258048888175

Epoch: 5| Step: 1
Training loss: 2.8611066341400146
Validation loss: 2.7366541662523822

Epoch: 5| Step: 2
Training loss: 3.0538277626037598
Validation loss: 2.7457092295410814

Epoch: 5| Step: 3
Training loss: 2.0482399463653564
Validation loss: 2.723055342192291

Epoch: 5| Step: 4
Training loss: 3.5401482582092285
Validation loss: 2.722927439597345

Epoch: 5| Step: 5
Training loss: 2.398627996444702
Validation loss: 2.718617808434271

Epoch: 5| Step: 6
Training loss: 2.767759323120117
Validation loss: 2.7165139157284974

Epoch: 5| Step: 7
Training loss: 3.3448405265808105
Validation loss: 2.714346326807494

Epoch: 5| Step: 8
Training loss: 2.5127129554748535
Validation loss: 2.7143668872053905

Epoch: 5| Step: 9
Training loss: 3.0167386531829834
Validation loss: 2.7134320505203737

Epoch: 5| Step: 10
Training loss: 3.0502982139587402
Validation loss: 2.7163777146288144

Epoch: 16| Step: 0
Training loss: 2.6915698051452637
Validation loss: 2.7140576454900924

Epoch: 5| Step: 1
Training loss: 2.7345097064971924
Validation loss: 2.7104144404011388

Epoch: 5| Step: 2
Training loss: 3.2036728858947754
Validation loss: 2.7105412124305643

Epoch: 5| Step: 3
Training loss: 2.9854557514190674
Validation loss: 2.701223842559322

Epoch: 5| Step: 4
Training loss: 2.5432307720184326
Validation loss: 2.699164036781557

Epoch: 5| Step: 5
Training loss: 3.034576177597046
Validation loss: 2.6957755934807563

Epoch: 5| Step: 6
Training loss: 2.9361939430236816
Validation loss: 2.6927885393942557

Epoch: 5| Step: 7
Training loss: 2.802623748779297
Validation loss: 2.6934127987072034

Epoch: 5| Step: 8
Training loss: 2.682068109512329
Validation loss: 2.6940731668985016

Epoch: 5| Step: 9
Training loss: 3.1987571716308594
Validation loss: 2.6898226173975135

Epoch: 5| Step: 10
Training loss: 2.6881771087646484
Validation loss: 2.6786357100291918

Epoch: 17| Step: 0
Training loss: 2.6278576850891113
Validation loss: 2.675371575099166

Epoch: 5| Step: 1
Training loss: 2.40063738822937
Validation loss: 2.6712974861104

Epoch: 5| Step: 2
Training loss: 3.6005935668945312
Validation loss: 2.665277173442225

Epoch: 5| Step: 3
Training loss: 2.898073196411133
Validation loss: 2.6666679843779533

Epoch: 5| Step: 4
Training loss: 2.5454564094543457
Validation loss: 2.6639454339140203

Epoch: 5| Step: 5
Training loss: 3.205300807952881
Validation loss: 2.658655135862289

Epoch: 5| Step: 6
Training loss: 2.5255589485168457
Validation loss: 2.653538388590659

Epoch: 5| Step: 7
Training loss: 3.2350432872772217
Validation loss: 2.653260789891725

Epoch: 5| Step: 8
Training loss: 2.9764599800109863
Validation loss: 2.6502786092860724

Epoch: 5| Step: 9
Training loss: 2.5374257564544678
Validation loss: 2.642489484561387

Epoch: 5| Step: 10
Training loss: 2.660884141921997
Validation loss: 2.6443424583763204

Epoch: 18| Step: 0
Training loss: 2.6182010173797607
Validation loss: 2.6389893511290192

Epoch: 5| Step: 1
Training loss: 3.6754863262176514
Validation loss: 2.6648414801525813

Epoch: 5| Step: 2
Training loss: 2.2028889656066895
Validation loss: 2.6580480273051927

Epoch: 5| Step: 3
Training loss: 2.399209499359131
Validation loss: 2.654984902310115

Epoch: 5| Step: 4
Training loss: 2.580699920654297
Validation loss: 2.693831302786386

Epoch: 5| Step: 5
Training loss: 3.4422059059143066
Validation loss: 2.659468602108699

Epoch: 5| Step: 6
Training loss: 2.702751874923706
Validation loss: 2.63996615973852

Epoch: 5| Step: 7
Training loss: 3.1544735431671143
Validation loss: 2.669927802137149

Epoch: 5| Step: 8
Training loss: 2.8764731884002686
Validation loss: 2.6716421573392806

Epoch: 5| Step: 9
Training loss: 2.5426762104034424
Validation loss: 2.6431815444782214

Epoch: 5| Step: 10
Training loss: 3.0356826782226562
Validation loss: 2.635492981121104

Epoch: 19| Step: 0
Training loss: 3.3250935077667236
Validation loss: 2.6333350519980154

Epoch: 5| Step: 1
Training loss: 2.7777891159057617
Validation loss: 2.625573653046803

Epoch: 5| Step: 2
Training loss: 2.546083450317383
Validation loss: 2.6264731038001274

Epoch: 5| Step: 3
Training loss: 3.409025192260742
Validation loss: 2.6111086183978665

Epoch: 5| Step: 4
Training loss: 2.615532636642456
Validation loss: 2.605534476618613

Epoch: 5| Step: 5
Training loss: 2.2809653282165527
Validation loss: 2.60465750386638

Epoch: 5| Step: 6
Training loss: 3.098784923553467
Validation loss: 2.6201486074796287

Epoch: 5| Step: 7
Training loss: 2.730679988861084
Validation loss: 2.598344495219569

Epoch: 5| Step: 8
Training loss: 2.5703046321868896
Validation loss: 2.60257787089194

Epoch: 5| Step: 9
Training loss: 2.0991568565368652
Validation loss: 2.635025429469283

Epoch: 5| Step: 10
Training loss: 3.595454454421997
Validation loss: 2.6870528036548245

Epoch: 20| Step: 0
Training loss: 3.023247480392456
Validation loss: 2.7007080662635063

Epoch: 5| Step: 1
Training loss: 2.3013532161712646
Validation loss: 2.6519510489638134

Epoch: 5| Step: 2
Training loss: 3.130413055419922
Validation loss: 2.616143777806272

Epoch: 5| Step: 3
Training loss: 3.53376841545105
Validation loss: 2.6017245297790854

Epoch: 5| Step: 4
Training loss: 2.993549108505249
Validation loss: 2.608165723021312

Epoch: 5| Step: 5
Training loss: 3.064145088195801
Validation loss: 2.6102753505911878

Epoch: 5| Step: 6
Training loss: 2.174788475036621
Validation loss: 2.602254008734098

Epoch: 5| Step: 7
Training loss: 2.5007472038269043
Validation loss: 2.6098969956879974

Epoch: 5| Step: 8
Training loss: 2.4494686126708984
Validation loss: 2.628086354142876

Epoch: 5| Step: 9
Training loss: 3.2567038536071777
Validation loss: 2.6300050109945317

Epoch: 5| Step: 10
Training loss: 2.5534965991973877
Validation loss: 2.6207349556748585

Epoch: 21| Step: 0
Training loss: 3.1149115562438965
Validation loss: 2.629059760801254

Epoch: 5| Step: 1
Training loss: 2.2946882247924805
Validation loss: 2.6334080734560565

Epoch: 5| Step: 2
Training loss: 3.3835175037384033
Validation loss: 2.627350648244222

Epoch: 5| Step: 3
Training loss: 2.8159704208374023
Validation loss: 2.616623757987894

Epoch: 5| Step: 4
Training loss: 3.0659358501434326
Validation loss: 2.5832456619508806

Epoch: 5| Step: 5
Training loss: 1.8715074062347412
Validation loss: 2.5651094067481255

Epoch: 5| Step: 6
Training loss: 2.6761183738708496
Validation loss: 2.5682284319272606

Epoch: 5| Step: 7
Training loss: 3.487759828567505
Validation loss: 2.583686569685577

Epoch: 5| Step: 8
Training loss: 3.008662223815918
Validation loss: 2.596710399914813

Epoch: 5| Step: 9
Training loss: 2.809087038040161
Validation loss: 2.620674648592549

Epoch: 5| Step: 10
Training loss: 2.266080379486084
Validation loss: 2.6206598410042385

Epoch: 22| Step: 0
Training loss: 3.226377010345459
Validation loss: 2.599467126272058

Epoch: 5| Step: 1
Training loss: 2.12658953666687
Validation loss: 2.5840649040796424

Epoch: 5| Step: 2
Training loss: 3.0280940532684326
Validation loss: 2.6038707148644233

Epoch: 5| Step: 3
Training loss: 2.215528964996338
Validation loss: 2.5636661283431517

Epoch: 5| Step: 4
Training loss: 2.0079360008239746
Validation loss: 2.5677166395289923

Epoch: 5| Step: 5
Training loss: 3.18367075920105
Validation loss: 2.5695918324173137

Epoch: 5| Step: 6
Training loss: 2.505039930343628
Validation loss: 2.5647360278714086

Epoch: 5| Step: 7
Training loss: 3.5948646068573
Validation loss: 2.554519453356343

Epoch: 5| Step: 8
Training loss: 2.6992335319519043
Validation loss: 2.5714582448364585

Epoch: 5| Step: 9
Training loss: 2.8981242179870605
Validation loss: 2.6015771537698726

Epoch: 5| Step: 10
Training loss: 3.3805694580078125
Validation loss: 2.6069977283477783

Epoch: 23| Step: 0
Training loss: 3.0338754653930664
Validation loss: 2.5723045231193624

Epoch: 5| Step: 1
Training loss: 2.3101210594177246
Validation loss: 2.547715466509583

Epoch: 5| Step: 2
Training loss: 3.0677742958068848
Validation loss: 2.5587397647160355

Epoch: 5| Step: 3
Training loss: 2.707947254180908
Validation loss: 2.5750605444754324

Epoch: 5| Step: 4
Training loss: 3.169314384460449
Validation loss: 2.572482483361357

Epoch: 5| Step: 5
Training loss: 2.336341381072998
Validation loss: 2.5597926544886764

Epoch: 5| Step: 6
Training loss: 2.2940735816955566
Validation loss: 2.5508330483590402

Epoch: 5| Step: 7
Training loss: 2.3365564346313477
Validation loss: 2.569013923727056

Epoch: 5| Step: 8
Training loss: 3.249703884124756
Validation loss: 2.5587630400093655

Epoch: 5| Step: 9
Training loss: 3.0671167373657227
Validation loss: 2.5470877283362934

Epoch: 5| Step: 10
Training loss: 2.9204142093658447
Validation loss: 2.550268283454321

Epoch: 24| Step: 0
Training loss: 3.026299238204956
Validation loss: 2.5571019623869207

Epoch: 5| Step: 1
Training loss: 1.8689801692962646
Validation loss: 2.5531346823579524

Epoch: 5| Step: 2
Training loss: 2.5666897296905518
Validation loss: 2.5472171229700886

Epoch: 5| Step: 3
Training loss: 2.903609037399292
Validation loss: 2.544280400840185

Epoch: 5| Step: 4
Training loss: 2.796400547027588
Validation loss: 2.5412980907706806

Epoch: 5| Step: 5
Training loss: 2.592130422592163
Validation loss: 2.540701884095387

Epoch: 5| Step: 6
Training loss: 2.809612989425659
Validation loss: 2.5419503642666723

Epoch: 5| Step: 7
Training loss: 2.984905958175659
Validation loss: 2.5398203839537916

Epoch: 5| Step: 8
Training loss: 2.711977481842041
Validation loss: 2.535810027071225

Epoch: 5| Step: 9
Training loss: 3.0086114406585693
Validation loss: 2.536234563396823

Epoch: 5| Step: 10
Training loss: 3.0849738121032715
Validation loss: 2.529230143434258

Epoch: 25| Step: 0
Training loss: 3.0756678581237793
Validation loss: 2.528868411176948

Epoch: 5| Step: 1
Training loss: 2.8311142921447754
Validation loss: 2.5237284732121292

Epoch: 5| Step: 2
Training loss: 2.937387228012085
Validation loss: 2.532969802938482

Epoch: 5| Step: 3
Training loss: 3.002002716064453
Validation loss: 2.517431171991492

Epoch: 5| Step: 4
Training loss: 2.7220253944396973
Validation loss: 2.5163035572216077

Epoch: 5| Step: 5
Training loss: 2.683635950088501
Validation loss: 2.5207446493128294

Epoch: 5| Step: 6
Training loss: 1.6267696619033813
Validation loss: 2.5170944762486283

Epoch: 5| Step: 7
Training loss: 4.171642780303955
Validation loss: 2.5146191145784114

Epoch: 5| Step: 8
Training loss: 2.4660274982452393
Validation loss: 2.5161820919282976

Epoch: 5| Step: 9
Training loss: 1.8438892364501953
Validation loss: 2.5220146640654533

Epoch: 5| Step: 10
Training loss: 2.751300573348999
Validation loss: 2.5309489926984234

Epoch: 26| Step: 0
Training loss: 3.2794883251190186
Validation loss: 2.5292475479905323

Epoch: 5| Step: 1
Training loss: 2.5895612239837646
Validation loss: 2.5168115733772196

Epoch: 5| Step: 2
Training loss: 2.7353456020355225
Validation loss: 2.5107542801928777

Epoch: 5| Step: 3
Training loss: 3.072547197341919
Validation loss: 2.5208964347839355

Epoch: 5| Step: 4
Training loss: 2.139007091522217
Validation loss: 2.5278784613455496

Epoch: 5| Step: 5
Training loss: 3.033900499343872
Validation loss: 2.533425654134443

Epoch: 5| Step: 6
Training loss: 2.850978374481201
Validation loss: 2.539007591944869

Epoch: 5| Step: 7
Training loss: 2.9487812519073486
Validation loss: 2.5342278249802126

Epoch: 5| Step: 8
Training loss: 2.3522143363952637
Validation loss: 2.515659293820781

Epoch: 5| Step: 9
Training loss: 2.8681883811950684
Validation loss: 2.509128587220305

Epoch: 5| Step: 10
Training loss: 2.325410842895508
Validation loss: 2.50311525406376

Epoch: 27| Step: 0
Training loss: 2.307300567626953
Validation loss: 2.4998237804699968

Epoch: 5| Step: 1
Training loss: 3.5382771492004395
Validation loss: 2.5028566416873725

Epoch: 5| Step: 2
Training loss: 3.2738678455352783
Validation loss: 2.501264320906772

Epoch: 5| Step: 3
Training loss: 2.6488094329833984
Validation loss: 2.513362917848813

Epoch: 5| Step: 4
Training loss: 2.4481282234191895
Validation loss: 2.5136479664874334

Epoch: 5| Step: 5
Training loss: 2.458343029022217
Validation loss: 2.520530880138438

Epoch: 5| Step: 6
Training loss: 3.2553551197052
Validation loss: 2.506064094522948

Epoch: 5| Step: 7
Training loss: 2.4442965984344482
Validation loss: 2.492617778880622

Epoch: 5| Step: 8
Training loss: 2.2747631072998047
Validation loss: 2.494476556777954

Epoch: 5| Step: 9
Training loss: 2.8721721172332764
Validation loss: 2.4870106891919206

Epoch: 5| Step: 10
Training loss: 2.3287644386291504
Validation loss: 2.491177628117223

Epoch: 28| Step: 0
Training loss: 2.1665825843811035
Validation loss: 2.484962668470157

Epoch: 5| Step: 1
Training loss: 2.952976703643799
Validation loss: 2.4870004935931136

Epoch: 5| Step: 2
Training loss: 2.3882365226745605
Validation loss: 2.501256065983926

Epoch: 5| Step: 3
Training loss: 2.033369302749634
Validation loss: 2.5090038161123953

Epoch: 5| Step: 4
Training loss: 3.3952178955078125
Validation loss: 2.4961648653912287

Epoch: 5| Step: 5
Training loss: 2.740097999572754
Validation loss: 2.490597632623488

Epoch: 5| Step: 6
Training loss: 2.688833713531494
Validation loss: 2.486706297884705

Epoch: 5| Step: 7
Training loss: 2.537715196609497
Validation loss: 2.4894829104023595

Epoch: 5| Step: 8
Training loss: 3.097592830657959
Validation loss: 2.493325969224335

Epoch: 5| Step: 9
Training loss: 2.563978672027588
Validation loss: 2.486099568746423

Epoch: 5| Step: 10
Training loss: 3.295780658721924
Validation loss: 2.4795263454478276

Epoch: 29| Step: 0
Training loss: 2.200587034225464
Validation loss: 2.487029601168889

Epoch: 5| Step: 1
Training loss: 2.4373252391815186
Validation loss: 2.497903057323989

Epoch: 5| Step: 2
Training loss: 2.709568500518799
Validation loss: 2.5197021089574343

Epoch: 5| Step: 3
Training loss: 3.0730719566345215
Validation loss: 2.53689254483869

Epoch: 5| Step: 4
Training loss: 2.7397513389587402
Validation loss: 2.5368210679741314

Epoch: 5| Step: 5
Training loss: 3.192206859588623
Validation loss: 2.5168913666919996

Epoch: 5| Step: 6
Training loss: 2.3807432651519775
Validation loss: 2.4985529197159635

Epoch: 5| Step: 7
Training loss: 3.5075466632843018
Validation loss: 2.4840627818979244

Epoch: 5| Step: 8
Training loss: 2.792273998260498
Validation loss: 2.47678461382466

Epoch: 5| Step: 9
Training loss: 3.0667622089385986
Validation loss: 2.47861550956644

Epoch: 5| Step: 10
Training loss: 1.7786545753479004
Validation loss: 2.5015371717432493

Epoch: 30| Step: 0
Training loss: 2.2765815258026123
Validation loss: 2.5536085405657367

Epoch: 5| Step: 1
Training loss: 2.656219005584717
Validation loss: 2.5535084021988737

Epoch: 5| Step: 2
Training loss: 3.0439658164978027
Validation loss: 2.53075312542659

Epoch: 5| Step: 3
Training loss: 2.2899441719055176
Validation loss: 2.5121035755321546

Epoch: 5| Step: 4
Training loss: 2.740673065185547
Validation loss: 2.492592442420221

Epoch: 5| Step: 5
Training loss: 3.2560417652130127
Validation loss: 2.484426834250009

Epoch: 5| Step: 6
Training loss: 2.776172637939453
Validation loss: 2.4771967241840978

Epoch: 5| Step: 7
Training loss: 2.11962890625
Validation loss: 2.4779140974885676

Epoch: 5| Step: 8
Training loss: 3.1863136291503906
Validation loss: 2.480369572998375

Epoch: 5| Step: 9
Training loss: 2.8969929218292236
Validation loss: 2.4811910762581775

Epoch: 5| Step: 10
Training loss: 2.7133655548095703
Validation loss: 2.4735955833106913

Epoch: 31| Step: 0
Training loss: 2.9246747493743896
Validation loss: 2.473621404299172

Epoch: 5| Step: 1
Training loss: 1.9400064945220947
Validation loss: 2.4828571991253923

Epoch: 5| Step: 2
Training loss: 2.155972480773926
Validation loss: 2.500236254866405

Epoch: 5| Step: 3
Training loss: 1.841253638267517
Validation loss: 2.5394951438391082

Epoch: 5| Step: 4
Training loss: 2.814565658569336
Validation loss: 2.5356869800116426

Epoch: 5| Step: 5
Training loss: 2.849578619003296
Validation loss: 2.496981202915151

Epoch: 5| Step: 6
Training loss: 2.9956367015838623
Validation loss: 2.4911901643199306

Epoch: 5| Step: 7
Training loss: 3.107456922531128
Validation loss: 2.471421818579397

Epoch: 5| Step: 8
Training loss: 2.571181058883667
Validation loss: 2.4630727844853557

Epoch: 5| Step: 9
Training loss: 3.596823215484619
Validation loss: 2.460948113472231

Epoch: 5| Step: 10
Training loss: 3.0549068450927734
Validation loss: 2.459799261503322

Epoch: 32| Step: 0
Training loss: 2.856776714324951
Validation loss: 2.4589634069832425

Epoch: 5| Step: 1
Training loss: 2.6360411643981934
Validation loss: 2.461083927462178

Epoch: 5| Step: 2
Training loss: 2.873380184173584
Validation loss: 2.4604041320021435

Epoch: 5| Step: 3
Training loss: 1.6204818487167358
Validation loss: 2.460456799435359

Epoch: 5| Step: 4
Training loss: 2.3876776695251465
Validation loss: 2.458147636023901

Epoch: 5| Step: 5
Training loss: 3.0775904655456543
Validation loss: 2.4572140760319208

Epoch: 5| Step: 6
Training loss: 2.063464403152466
Validation loss: 2.4776284028125066

Epoch: 5| Step: 7
Training loss: 3.000683307647705
Validation loss: 2.4991330433917303

Epoch: 5| Step: 8
Training loss: 2.953345775604248
Validation loss: 2.499110996082265

Epoch: 5| Step: 9
Training loss: 2.975421190261841
Validation loss: 2.4900436196275937

Epoch: 5| Step: 10
Training loss: 3.405778169631958
Validation loss: 2.485791067923269

Epoch: 33| Step: 0
Training loss: 2.6878437995910645
Validation loss: 2.4768250783284507

Epoch: 5| Step: 1
Training loss: 2.8961901664733887
Validation loss: 2.466516463987289

Epoch: 5| Step: 2
Training loss: 1.622036337852478
Validation loss: 2.459946393966675

Epoch: 5| Step: 3
Training loss: 2.761221408843994
Validation loss: 2.4597068422584125

Epoch: 5| Step: 4
Training loss: 2.675936222076416
Validation loss: 2.463440256734048

Epoch: 5| Step: 5
Training loss: 3.163639545440674
Validation loss: 2.4591937680398264

Epoch: 5| Step: 6
Training loss: 2.303389310836792
Validation loss: 2.46107994100099

Epoch: 5| Step: 7
Training loss: 3.1682848930358887
Validation loss: 2.448564044890865

Epoch: 5| Step: 8
Training loss: 2.597445249557495
Validation loss: 2.443115818885065

Epoch: 5| Step: 9
Training loss: 3.111764430999756
Validation loss: 2.441913156099217

Epoch: 5| Step: 10
Training loss: 2.5087947845458984
Validation loss: 2.4435162236613612

Epoch: 34| Step: 0
Training loss: 3.0043365955352783
Validation loss: 2.442585181164485

Epoch: 5| Step: 1
Training loss: 2.203166961669922
Validation loss: 2.4425673459165838

Epoch: 5| Step: 2
Training loss: 2.5715978145599365
Validation loss: 2.442035695557953

Epoch: 5| Step: 3
Training loss: 2.845590591430664
Validation loss: 2.4428375356940815

Epoch: 5| Step: 4
Training loss: 2.7732372283935547
Validation loss: 2.4421105372008456

Epoch: 5| Step: 5
Training loss: 3.354857921600342
Validation loss: 2.4508881415090253

Epoch: 5| Step: 6
Training loss: 2.771864414215088
Validation loss: 2.4546534271650415

Epoch: 5| Step: 7
Training loss: 2.464144468307495
Validation loss: 2.467111982325072

Epoch: 5| Step: 8
Training loss: 2.2544565200805664
Validation loss: 2.473775891847508

Epoch: 5| Step: 9
Training loss: 2.7617640495300293
Validation loss: 2.477071403175272

Epoch: 5| Step: 10
Training loss: 2.54105544090271
Validation loss: 2.45424408553749

Epoch: 35| Step: 0
Training loss: 3.108668327331543
Validation loss: 2.443373821114981

Epoch: 5| Step: 1
Training loss: 3.0935471057891846
Validation loss: 2.439242479621723

Epoch: 5| Step: 2
Training loss: 2.2199270725250244
Validation loss: 2.4355869805941017

Epoch: 5| Step: 3
Training loss: 3.022209644317627
Validation loss: 2.446133344404159

Epoch: 5| Step: 4
Training loss: 3.0838234424591064
Validation loss: 2.4506126373044905

Epoch: 5| Step: 5
Training loss: 2.297699213027954
Validation loss: 2.4557061426101194

Epoch: 5| Step: 6
Training loss: 2.2287936210632324
Validation loss: 2.4750343727809128

Epoch: 5| Step: 7
Training loss: 3.2688212394714355
Validation loss: 2.4863496647086194

Epoch: 5| Step: 8
Training loss: 2.341273307800293
Validation loss: 2.4829839506456928

Epoch: 5| Step: 9
Training loss: 2.03214430809021
Validation loss: 2.4527107490006315

Epoch: 5| Step: 10
Training loss: 2.764646530151367
Validation loss: 2.4355710039856615

Epoch: 36| Step: 0
Training loss: 2.9749679565429688
Validation loss: 2.4272618524489866

Epoch: 5| Step: 1
Training loss: 2.5328125953674316
Validation loss: 2.428296253245364

Epoch: 5| Step: 2
Training loss: 2.7540535926818848
Validation loss: 2.429641763369242

Epoch: 5| Step: 3
Training loss: 2.3327393531799316
Validation loss: 2.427052331227128

Epoch: 5| Step: 4
Training loss: 2.602304458618164
Validation loss: 2.455474679188062

Epoch: 5| Step: 5
Training loss: 3.249371290206909
Validation loss: 2.477037763082853

Epoch: 5| Step: 6
Training loss: 2.7690131664276123
Validation loss: 2.483257434701407

Epoch: 5| Step: 7
Training loss: 2.1583423614501953
Validation loss: 2.4684162524438675

Epoch: 5| Step: 8
Training loss: 3.0943408012390137
Validation loss: 2.4538207489957093

Epoch: 5| Step: 9
Training loss: 2.8234736919403076
Validation loss: 2.4499733499301377

Epoch: 5| Step: 10
Training loss: 2.1089179515838623
Validation loss: 2.443236840668545

Epoch: 37| Step: 0
Training loss: 2.4926023483276367
Validation loss: 2.443925908816758

Epoch: 5| Step: 1
Training loss: 2.268683433532715
Validation loss: 2.4386079029370378

Epoch: 5| Step: 2
Training loss: 3.109772205352783
Validation loss: 2.4300818904753654

Epoch: 5| Step: 3
Training loss: 2.3667032718658447
Validation loss: 2.435593787059989

Epoch: 5| Step: 4
Training loss: 2.8078339099884033
Validation loss: 2.4359587802681872

Epoch: 5| Step: 5
Training loss: 2.5453224182128906
Validation loss: 2.4380016890905236

Epoch: 5| Step: 6
Training loss: 2.552532196044922
Validation loss: 2.432813911027806

Epoch: 5| Step: 7
Training loss: 2.7154717445373535
Validation loss: 2.4314852555592856

Epoch: 5| Step: 8
Training loss: 2.819920301437378
Validation loss: 2.431324428127658

Epoch: 5| Step: 9
Training loss: 2.5893330574035645
Validation loss: 2.434957170999178

Epoch: 5| Step: 10
Training loss: 3.1861636638641357
Validation loss: 2.447763084083475

Epoch: 38| Step: 0
Training loss: 2.2477898597717285
Validation loss: 2.4556280361708773

Epoch: 5| Step: 1
Training loss: 2.254808187484741
Validation loss: 2.4819332938040457

Epoch: 5| Step: 2
Training loss: 2.4856739044189453
Validation loss: 2.4761980502836165

Epoch: 5| Step: 3
Training loss: 2.2408947944641113
Validation loss: 2.4825356980805755

Epoch: 5| Step: 4
Training loss: 2.9536542892456055
Validation loss: 2.4478868233260287

Epoch: 5| Step: 5
Training loss: 2.537997245788574
Validation loss: 2.429337219525409

Epoch: 5| Step: 6
Training loss: 3.259564161300659
Validation loss: 2.4186848927569646

Epoch: 5| Step: 7
Training loss: 2.8042101860046387
Validation loss: 2.4176708498308734

Epoch: 5| Step: 8
Training loss: 2.459911823272705
Validation loss: 2.4205567631670224

Epoch: 5| Step: 9
Training loss: 2.535881519317627
Validation loss: 2.4227360602348083

Epoch: 5| Step: 10
Training loss: 3.7227065563201904
Validation loss: 2.4199759216718775

Epoch: 39| Step: 0
Training loss: 2.3518712520599365
Validation loss: 2.4167095563744985

Epoch: 5| Step: 1
Training loss: 2.384899139404297
Validation loss: 2.4282786384705575

Epoch: 5| Step: 2
Training loss: 2.606581211090088
Validation loss: 2.4386067108441423

Epoch: 5| Step: 3
Training loss: 3.468292236328125
Validation loss: 2.4411348501841226

Epoch: 5| Step: 4
Training loss: 2.7964587211608887
Validation loss: 2.4327510505594234

Epoch: 5| Step: 5
Training loss: 2.6459193229675293
Validation loss: 2.4194364752820743

Epoch: 5| Step: 6
Training loss: 2.8074147701263428
Validation loss: 2.413515047360492

Epoch: 5| Step: 7
Training loss: 2.676321029663086
Validation loss: 2.41063448690599

Epoch: 5| Step: 8
Training loss: 2.623340129852295
Validation loss: 2.404190355731595

Epoch: 5| Step: 9
Training loss: 2.1218056678771973
Validation loss: 2.407005056258171

Epoch: 5| Step: 10
Training loss: 2.865689516067505
Validation loss: 2.405075578279393

Epoch: 40| Step: 0
Training loss: 2.6268410682678223
Validation loss: 2.405367928166543

Epoch: 5| Step: 1
Training loss: 2.602369785308838
Validation loss: 2.409205752034341

Epoch: 5| Step: 2
Training loss: 2.6134955883026123
Validation loss: 2.4133300678704375

Epoch: 5| Step: 3
Training loss: 2.7741212844848633
Validation loss: 2.4177138151661044

Epoch: 5| Step: 4
Training loss: 2.7065062522888184
Validation loss: 2.4246644204662693

Epoch: 5| Step: 5
Training loss: 2.662463903427124
Validation loss: 2.445122177882861

Epoch: 5| Step: 6
Training loss: 2.9949393272399902
Validation loss: 2.446701980406238

Epoch: 5| Step: 7
Training loss: 2.4664134979248047
Validation loss: 2.432089105729134

Epoch: 5| Step: 8
Training loss: 2.0287673473358154
Validation loss: 2.4267181683612127

Epoch: 5| Step: 9
Training loss: 3.0263750553131104
Validation loss: 2.4342307864978747

Epoch: 5| Step: 10
Training loss: 2.8896596431732178
Validation loss: 2.4410318841216383

Epoch: 41| Step: 0
Training loss: 2.600318431854248
Validation loss: 2.4198326115967124

Epoch: 5| Step: 1
Training loss: 2.660463809967041
Validation loss: 2.403994316695839

Epoch: 5| Step: 2
Training loss: 3.0848705768585205
Validation loss: 2.396479066982064

Epoch: 5| Step: 3
Training loss: 2.7478957176208496
Validation loss: 2.394015250667449

Epoch: 5| Step: 4
Training loss: 2.4901223182678223
Validation loss: 2.394951726800652

Epoch: 5| Step: 5
Training loss: 2.7356762886047363
Validation loss: 2.4015634982816634

Epoch: 5| Step: 6
Training loss: 2.7338919639587402
Validation loss: 2.3989169571989324

Epoch: 5| Step: 7
Training loss: 2.2229442596435547
Validation loss: 2.4069481126723753

Epoch: 5| Step: 8
Training loss: 2.4994473457336426
Validation loss: 2.4135783077568136

Epoch: 5| Step: 9
Training loss: 2.6921918392181396
Validation loss: 2.4264797344002673

Epoch: 5| Step: 10
Training loss: 2.592892646789551
Validation loss: 2.418704696880874

Epoch: 42| Step: 0
Training loss: 2.203118085861206
Validation loss: 2.408202020070886

Epoch: 5| Step: 1
Training loss: 2.455784320831299
Validation loss: 2.3916881238260577

Epoch: 5| Step: 2
Training loss: 2.831465482711792
Validation loss: 2.3920104401085966

Epoch: 5| Step: 3
Training loss: 2.7032010555267334
Validation loss: 2.389903676125311

Epoch: 5| Step: 4
Training loss: 2.4889302253723145
Validation loss: 2.3863056859662457

Epoch: 5| Step: 5
Training loss: 2.9288489818573
Validation loss: 2.382541113002326

Epoch: 5| Step: 6
Training loss: 3.2529659271240234
Validation loss: 2.378073307775682

Epoch: 5| Step: 7
Training loss: 3.0712552070617676
Validation loss: 2.3795571942483225

Epoch: 5| Step: 8
Training loss: 2.353151798248291
Validation loss: 2.3837285733992055

Epoch: 5| Step: 9
Training loss: 2.583524227142334
Validation loss: 2.3834180165362615

Epoch: 5| Step: 10
Training loss: 2.098238229751587
Validation loss: 2.3899553950114916

Epoch: 43| Step: 0
Training loss: 2.8944153785705566
Validation loss: 2.4003076181616834

Epoch: 5| Step: 1
Training loss: 2.4219861030578613
Validation loss: 2.4344085903577906

Epoch: 5| Step: 2
Training loss: 2.3230743408203125
Validation loss: 2.4351738011965187

Epoch: 5| Step: 3
Training loss: 2.3530569076538086
Validation loss: 2.4415916089088685

Epoch: 5| Step: 4
Training loss: 3.3519656658172607
Validation loss: 2.4488456531237532

Epoch: 5| Step: 5
Training loss: 2.4024624824523926
Validation loss: 2.425296180991716

Epoch: 5| Step: 6
Training loss: 2.617992877960205
Validation loss: 2.4115980696934525

Epoch: 5| Step: 7
Training loss: 2.882563829421997
Validation loss: 2.401912304662889

Epoch: 5| Step: 8
Training loss: 2.2869181632995605
Validation loss: 2.4025082639468613

Epoch: 5| Step: 9
Training loss: 2.8094582557678223
Validation loss: 2.4075547982287664

Epoch: 5| Step: 10
Training loss: 2.710139513015747
Validation loss: 2.412058650806386

Epoch: 44| Step: 0
Training loss: 2.377239465713501
Validation loss: 2.4191990642137426

Epoch: 5| Step: 1
Training loss: 2.5984559059143066
Validation loss: 2.4183699059230026

Epoch: 5| Step: 2
Training loss: 2.8298211097717285
Validation loss: 2.4249221535139185

Epoch: 5| Step: 3
Training loss: 2.4806697368621826
Validation loss: 2.4271696049679994

Epoch: 5| Step: 4
Training loss: 2.857732057571411
Validation loss: 2.4282957200081117

Epoch: 5| Step: 5
Training loss: 2.913571834564209
Validation loss: 2.431713475975939

Epoch: 5| Step: 6
Training loss: 3.061380386352539
Validation loss: 2.4283543171421176

Epoch: 5| Step: 7
Training loss: 2.252023220062256
Validation loss: 2.4369658859827186

Epoch: 5| Step: 8
Training loss: 2.0509097576141357
Validation loss: 2.4410497783332743

Epoch: 5| Step: 9
Training loss: 3.2100067138671875
Validation loss: 2.4606845353239324

Epoch: 5| Step: 10
Training loss: 2.503413438796997
Validation loss: 2.4834810738922446

Epoch: 45| Step: 0
Training loss: 2.3988475799560547
Validation loss: 2.474394295805244

Epoch: 5| Step: 1
Training loss: 3.6866588592529297
Validation loss: 2.4596920808156333

Epoch: 5| Step: 2
Training loss: 2.4866371154785156
Validation loss: 2.4428168906960437

Epoch: 5| Step: 3
Training loss: 2.70819354057312
Validation loss: 2.4223685956770376

Epoch: 5| Step: 4
Training loss: 2.307520627975464
Validation loss: 2.410579191741123

Epoch: 5| Step: 5
Training loss: 2.5140018463134766
Validation loss: 2.405618449693085

Epoch: 5| Step: 6
Training loss: 2.101440191268921
Validation loss: 2.409070973755211

Epoch: 5| Step: 7
Training loss: 2.314444065093994
Validation loss: 2.408100346083282

Epoch: 5| Step: 8
Training loss: 2.907588243484497
Validation loss: 2.3989010498087895

Epoch: 5| Step: 9
Training loss: 3.4902286529541016
Validation loss: 2.397875501263526

Epoch: 5| Step: 10
Training loss: 2.199054479598999
Validation loss: 2.391732551718271

Epoch: 46| Step: 0
Training loss: 2.1489131450653076
Validation loss: 2.3798563352195163

Epoch: 5| Step: 1
Training loss: 2.5711722373962402
Validation loss: 2.3731712782254784

Epoch: 5| Step: 2
Training loss: 3.016496181488037
Validation loss: 2.3707287401281376

Epoch: 5| Step: 3
Training loss: 2.9493327140808105
Validation loss: 2.3657566731975925

Epoch: 5| Step: 4
Training loss: 2.3977065086364746
Validation loss: 2.3679624424185803

Epoch: 5| Step: 5
Training loss: 2.2135186195373535
Validation loss: 2.3970147255928285

Epoch: 5| Step: 6
Training loss: 3.1603527069091797
Validation loss: 2.45857850966915

Epoch: 5| Step: 7
Training loss: 2.855299949645996
Validation loss: 2.4913850522810415

Epoch: 5| Step: 8
Training loss: 2.7055132389068604
Validation loss: 2.4662902996104252

Epoch: 5| Step: 9
Training loss: 1.865041732788086
Validation loss: 2.3986161216612785

Epoch: 5| Step: 10
Training loss: 3.3935036659240723
Validation loss: 2.369279871704758

Epoch: 47| Step: 0
Training loss: 1.665963888168335
Validation loss: 2.3844329362274497

Epoch: 5| Step: 1
Training loss: 3.193462610244751
Validation loss: 2.4201063904710995

Epoch: 5| Step: 2
Training loss: 2.738987445831299
Validation loss: 2.4492756935857956

Epoch: 5| Step: 3
Training loss: 2.618534803390503
Validation loss: 2.4506424319359565

Epoch: 5| Step: 4
Training loss: 2.8640570640563965
Validation loss: 2.4493144968504548

Epoch: 5| Step: 5
Training loss: 2.759702205657959
Validation loss: 2.4228231214707896

Epoch: 5| Step: 6
Training loss: 3.1143009662628174
Validation loss: 2.4032426470069477

Epoch: 5| Step: 7
Training loss: 2.682084321975708
Validation loss: 2.392308909405944

Epoch: 5| Step: 8
Training loss: 2.388601779937744
Validation loss: 2.3831951746376614

Epoch: 5| Step: 9
Training loss: 2.88938570022583
Validation loss: 2.383842993808049

Epoch: 5| Step: 10
Training loss: 2.604954242706299
Validation loss: 2.3892550468444824

Epoch: 48| Step: 0
Training loss: 2.5165011882781982
Validation loss: 2.4053768316904702

Epoch: 5| Step: 1
Training loss: 3.0384018421173096
Validation loss: 2.413437363921955

Epoch: 5| Step: 2
Training loss: 2.2173430919647217
Validation loss: 2.4231197808378484

Epoch: 5| Step: 3
Training loss: 2.161729335784912
Validation loss: 2.4346600245403986

Epoch: 5| Step: 4
Training loss: 2.6925363540649414
Validation loss: 2.440534640383977

Epoch: 5| Step: 5
Training loss: 2.595242738723755
Validation loss: 2.4314112919633106

Epoch: 5| Step: 6
Training loss: 2.8343639373779297
Validation loss: 2.4200809809469406

Epoch: 5| Step: 7
Training loss: 3.171368360519409
Validation loss: 2.4139598261925483

Epoch: 5| Step: 8
Training loss: 2.736645221710205
Validation loss: 2.4012695384281937

Epoch: 5| Step: 9
Training loss: 2.277552604675293
Validation loss: 2.386279905996015

Epoch: 5| Step: 10
Training loss: 2.809779644012451
Validation loss: 2.3848243246796312

Epoch: 49| Step: 0
Training loss: 3.17199444770813
Validation loss: 2.378471082256686

Epoch: 5| Step: 1
Training loss: 2.3511672019958496
Validation loss: 2.37926116553686

Epoch: 5| Step: 2
Training loss: 2.795900583267212
Validation loss: 2.372665415528

Epoch: 5| Step: 3
Training loss: 2.2247061729431152
Validation loss: 2.369283091637396

Epoch: 5| Step: 4
Training loss: 2.7667758464813232
Validation loss: 2.361049347026374

Epoch: 5| Step: 5
Training loss: 2.4276890754699707
Validation loss: 2.366883441966067

Epoch: 5| Step: 6
Training loss: 3.2929527759552
Validation loss: 2.3643174786721506

Epoch: 5| Step: 7
Training loss: 2.45967698097229
Validation loss: 2.3763704658836446

Epoch: 5| Step: 8
Training loss: 2.263239622116089
Validation loss: 2.391124076740716

Epoch: 5| Step: 9
Training loss: 2.3843092918395996
Validation loss: 2.416817388226909

Epoch: 5| Step: 10
Training loss: 2.852729558944702
Validation loss: 2.4273483253294423

Epoch: 50| Step: 0
Training loss: 1.9440736770629883
Validation loss: 2.417376609258754

Epoch: 5| Step: 1
Training loss: 3.3563437461853027
Validation loss: 2.4302794535954795

Epoch: 5| Step: 2
Training loss: 2.432245969772339
Validation loss: 2.4508636151590655

Epoch: 5| Step: 3
Training loss: 2.2732396125793457
Validation loss: 2.458955036696567

Epoch: 5| Step: 4
Training loss: 2.7096011638641357
Validation loss: 2.453109715574531

Epoch: 5| Step: 5
Training loss: 3.1268935203552246
Validation loss: 2.448888473613288

Epoch: 5| Step: 6
Training loss: 2.141580104827881
Validation loss: 2.4235042833512828

Epoch: 5| Step: 7
Training loss: 3.154568672180176
Validation loss: 2.3868102719706874

Epoch: 5| Step: 8
Training loss: 2.184121608734131
Validation loss: 2.365552694566788

Epoch: 5| Step: 9
Training loss: 2.899766445159912
Validation loss: 2.346960695840979

Epoch: 5| Step: 10
Training loss: 2.711660385131836
Validation loss: 2.3515783150990806

Epoch: 51| Step: 0
Training loss: 2.0193264484405518
Validation loss: 2.3578037113271733

Epoch: 5| Step: 1
Training loss: 2.7072255611419678
Validation loss: 2.361076419071485

Epoch: 5| Step: 2
Training loss: 2.8199682235717773
Validation loss: 2.367406577192327

Epoch: 5| Step: 3
Training loss: 2.632554531097412
Validation loss: 2.3711573616150887

Epoch: 5| Step: 4
Training loss: 2.614936113357544
Validation loss: 2.3622155317696194

Epoch: 5| Step: 5
Training loss: 2.956301212310791
Validation loss: 2.354812396469937

Epoch: 5| Step: 6
Training loss: 2.944499969482422
Validation loss: 2.3503525282747004

Epoch: 5| Step: 7
Training loss: 2.927804708480835
Validation loss: 2.3505183163509575

Epoch: 5| Step: 8
Training loss: 2.545170783996582
Validation loss: 2.34511766382443

Epoch: 5| Step: 9
Training loss: 2.9658942222595215
Validation loss: 2.343386201448338

Epoch: 5| Step: 10
Training loss: 1.761135220527649
Validation loss: 2.346756386500533

Epoch: 52| Step: 0
Training loss: 2.696767568588257
Validation loss: 2.353836344134423

Epoch: 5| Step: 1
Training loss: 3.052588701248169
Validation loss: 2.3739866620750836

Epoch: 5| Step: 2
Training loss: 2.8385586738586426
Validation loss: 2.400900876650246

Epoch: 5| Step: 3
Training loss: 2.3575329780578613
Validation loss: 2.4060983452745663

Epoch: 5| Step: 4
Training loss: 2.316863775253296
Validation loss: 2.4298687352929065

Epoch: 5| Step: 5
Training loss: 2.91532564163208
Validation loss: 2.4236581299894597

Epoch: 5| Step: 6
Training loss: 2.1774439811706543
Validation loss: 2.4025311367486113

Epoch: 5| Step: 7
Training loss: 2.3493902683258057
Validation loss: 2.3650134712137203

Epoch: 5| Step: 8
Training loss: 2.751767635345459
Validation loss: 2.3515970860758135

Epoch: 5| Step: 9
Training loss: 2.2059435844421387
Validation loss: 2.3409582017570414

Epoch: 5| Step: 10
Training loss: 3.1703073978424072
Validation loss: 2.3395797616692

Epoch: 53| Step: 0
Training loss: 2.89007306098938
Validation loss: 2.338744301949778

Epoch: 5| Step: 1
Training loss: 2.433166027069092
Validation loss: 2.345805706516389

Epoch: 5| Step: 2
Training loss: 2.8132970333099365
Validation loss: 2.3551043925746793

Epoch: 5| Step: 3
Training loss: 3.2284388542175293
Validation loss: 2.3605772320942213

Epoch: 5| Step: 4
Training loss: 2.399404525756836
Validation loss: 2.3620396147492113

Epoch: 5| Step: 5
Training loss: 1.255395770072937
Validation loss: 2.3622551887266097

Epoch: 5| Step: 6
Training loss: 3.1536169052124023
Validation loss: 2.3787581382259244

Epoch: 5| Step: 7
Training loss: 2.566455125808716
Validation loss: 2.3920993138385076

Epoch: 5| Step: 8
Training loss: 2.0239059925079346
Validation loss: 2.389153636911864

Epoch: 5| Step: 9
Training loss: 3.0734689235687256
Validation loss: 2.387249961976082

Epoch: 5| Step: 10
Training loss: 3.0831987857818604
Validation loss: 2.3805817122100503

Epoch: 54| Step: 0
Training loss: 2.701962471008301
Validation loss: 2.370455447063651

Epoch: 5| Step: 1
Training loss: 2.964059591293335
Validation loss: 2.3545731485530896

Epoch: 5| Step: 2
Training loss: 3.6746578216552734
Validation loss: 2.346605752104072

Epoch: 5| Step: 3
Training loss: 1.7992141246795654
Validation loss: 2.3451486146578224

Epoch: 5| Step: 4
Training loss: 2.6045517921447754
Validation loss: 2.337461881740119

Epoch: 5| Step: 5
Training loss: 2.015779972076416
Validation loss: 2.325937822300901

Epoch: 5| Step: 6
Training loss: 2.346045970916748
Validation loss: 2.3300394012082006

Epoch: 5| Step: 7
Training loss: 2.2836201190948486
Validation loss: 2.3154692303749824

Epoch: 5| Step: 8
Training loss: 2.810213565826416
Validation loss: 2.3157320560947543

Epoch: 5| Step: 9
Training loss: 2.57377290725708
Validation loss: 2.325411283841697

Epoch: 5| Step: 10
Training loss: 2.7100465297698975
Validation loss: 2.323158043687062

Epoch: 55| Step: 0
Training loss: 2.1789956092834473
Validation loss: 2.3239481679854856

Epoch: 5| Step: 1
Training loss: 2.1246306896209717
Validation loss: 2.3272789857720815

Epoch: 5| Step: 2
Training loss: 2.1591765880584717
Validation loss: 2.332098045656758

Epoch: 5| Step: 3
Training loss: 2.1043198108673096
Validation loss: 2.3408340356683217

Epoch: 5| Step: 4
Training loss: 3.3217360973358154
Validation loss: 2.3353324782463813

Epoch: 5| Step: 5
Training loss: 2.6491360664367676
Validation loss: 2.3474249865419123

Epoch: 5| Step: 6
Training loss: 2.8814029693603516
Validation loss: 2.3494358242198987

Epoch: 5| Step: 7
Training loss: 2.881221055984497
Validation loss: 2.3633989928871073

Epoch: 5| Step: 8
Training loss: 2.535804033279419
Validation loss: 2.3562569413133847

Epoch: 5| Step: 9
Training loss: 2.6515908241271973
Validation loss: 2.3600939781435075

Epoch: 5| Step: 10
Training loss: 3.1010327339172363
Validation loss: 2.3520610691398702

Epoch: 56| Step: 0
Training loss: 2.155045986175537
Validation loss: 2.3527421797475507

Epoch: 5| Step: 1
Training loss: 2.904745101928711
Validation loss: 2.3434192121669812

Epoch: 5| Step: 2
Training loss: 2.4885897636413574
Validation loss: 2.3417337197129444

Epoch: 5| Step: 3
Training loss: 2.863835096359253
Validation loss: 2.3522422339326594

Epoch: 5| Step: 4
Training loss: 2.1912777423858643
Validation loss: 2.3663969860281995

Epoch: 5| Step: 5
Training loss: 2.4220733642578125
Validation loss: 2.3786953931213706

Epoch: 5| Step: 6
Training loss: 2.846165895462036
Validation loss: 2.344605953462662

Epoch: 5| Step: 7
Training loss: 2.7006969451904297
Validation loss: 2.3224709405693957

Epoch: 5| Step: 8
Training loss: 2.6951489448547363
Validation loss: 2.3127799111027874

Epoch: 5| Step: 9
Training loss: 2.5638389587402344
Validation loss: 2.316231991655083

Epoch: 5| Step: 10
Training loss: 2.6581451892852783
Validation loss: 2.322530333713819

Epoch: 57| Step: 0
Training loss: 2.708036422729492
Validation loss: 2.3185793507483696

Epoch: 5| Step: 1
Training loss: 2.9253408908843994
Validation loss: 2.3215308573938187

Epoch: 5| Step: 2
Training loss: 2.496694564819336
Validation loss: 2.319113390420073

Epoch: 5| Step: 3
Training loss: 2.5271859169006348
Validation loss: 2.317180243871545

Epoch: 5| Step: 4
Training loss: 2.1297357082366943
Validation loss: 2.3164917063969437

Epoch: 5| Step: 5
Training loss: 2.6308000087738037
Validation loss: 2.3254056412686586

Epoch: 5| Step: 6
Training loss: 2.2704386711120605
Validation loss: 2.3268366167622228

Epoch: 5| Step: 7
Training loss: 2.168907642364502
Validation loss: 2.337951470446843

Epoch: 5| Step: 8
Training loss: 3.4767355918884277
Validation loss: 2.3464124023273425

Epoch: 5| Step: 9
Training loss: 2.6714465618133545
Validation loss: 2.344792191700269

Epoch: 5| Step: 10
Training loss: 2.7460007667541504
Validation loss: 2.323793386900297

Epoch: 58| Step: 0
Training loss: 2.49303936958313
Validation loss: 2.3141200824450423

Epoch: 5| Step: 1
Training loss: 1.9123332500457764
Validation loss: 2.30734210501435

Epoch: 5| Step: 2
Training loss: 2.6740126609802246
Validation loss: 2.3050437870846

Epoch: 5| Step: 3
Training loss: 2.9123711585998535
Validation loss: 2.307834374007358

Epoch: 5| Step: 4
Training loss: 2.6849827766418457
Validation loss: 2.3079129188291487

Epoch: 5| Step: 5
Training loss: 2.8737804889678955
Validation loss: 2.306551871761199

Epoch: 5| Step: 6
Training loss: 2.3252265453338623
Validation loss: 2.3065078181605183

Epoch: 5| Step: 7
Training loss: 2.776095151901245
Validation loss: 2.3039921637504333

Epoch: 5| Step: 8
Training loss: 2.8098113536834717
Validation loss: 2.304893857689314

Epoch: 5| Step: 9
Training loss: 2.3824312686920166
Validation loss: 2.2976328660083074

Epoch: 5| Step: 10
Training loss: 2.720350980758667
Validation loss: 2.301176009639617

Epoch: 59| Step: 0
Training loss: 1.965858817100525
Validation loss: 2.3089911373712684

Epoch: 5| Step: 1
Training loss: 3.2434182167053223
Validation loss: 2.3105917797293714

Epoch: 5| Step: 2
Training loss: 3.1005444526672363
Validation loss: 2.325814118949316

Epoch: 5| Step: 3
Training loss: 2.4828104972839355
Validation loss: 2.347483265784479

Epoch: 5| Step: 4
Training loss: 2.430854082107544
Validation loss: 2.3675414874989498

Epoch: 5| Step: 5
Training loss: 2.758368968963623
Validation loss: 2.3900329451407156

Epoch: 5| Step: 6
Training loss: 2.60304594039917
Validation loss: 2.400243887337305

Epoch: 5| Step: 7
Training loss: 2.6869401931762695
Validation loss: 2.3966807908909296

Epoch: 5| Step: 8
Training loss: 2.272325038909912
Validation loss: 2.3547666380482335

Epoch: 5| Step: 9
Training loss: 2.997788190841675
Validation loss: 2.3224401320180585

Epoch: 5| Step: 10
Training loss: 1.7237578630447388
Validation loss: 2.303778691958356

Epoch: 60| Step: 0
Training loss: 2.4819893836975098
Validation loss: 2.295261316401984

Epoch: 5| Step: 1
Training loss: 3.1537060737609863
Validation loss: 2.2964314696609334

Epoch: 5| Step: 2
Training loss: 2.8352291584014893
Validation loss: 2.302301776024603

Epoch: 5| Step: 3
Training loss: 2.626504898071289
Validation loss: 2.302323972025225

Epoch: 5| Step: 4
Training loss: 2.5673322677612305
Validation loss: 2.2929489792034192

Epoch: 5| Step: 5
Training loss: 2.5916130542755127
Validation loss: 2.2910653006645942

Epoch: 5| Step: 6
Training loss: 2.3644473552703857
Validation loss: 2.2957942511445735

Epoch: 5| Step: 7
Training loss: 2.4151062965393066
Validation loss: 2.304838806070307

Epoch: 5| Step: 8
Training loss: 2.600451707839966
Validation loss: 2.319621107911551

Epoch: 5| Step: 9
Training loss: 2.40516996383667
Validation loss: 2.3585711525332544

Epoch: 5| Step: 10
Training loss: 2.3863916397094727
Validation loss: 2.378324367666757

Epoch: 61| Step: 0
Training loss: 2.2316207885742188
Validation loss: 2.402564715313655

Epoch: 5| Step: 1
Training loss: 2.4079813957214355
Validation loss: 2.4285521789263655

Epoch: 5| Step: 2
Training loss: 2.9358787536621094
Validation loss: 2.4664004720667356

Epoch: 5| Step: 3
Training loss: 2.6991381645202637
Validation loss: 2.4787114717627086

Epoch: 5| Step: 4
Training loss: 3.4691758155822754
Validation loss: 2.438865601375539

Epoch: 5| Step: 5
Training loss: 2.306924343109131
Validation loss: 2.353378418953188

Epoch: 5| Step: 6
Training loss: 2.7771620750427246
Validation loss: 2.300886848921417

Epoch: 5| Step: 7
Training loss: 2.1937954425811768
Validation loss: 2.2884725345078336

Epoch: 5| Step: 8
Training loss: 3.0809550285339355
Validation loss: 2.2841988186682425

Epoch: 5| Step: 9
Training loss: 2.0110456943511963
Validation loss: 2.287728871068647

Epoch: 5| Step: 10
Training loss: 2.565458059310913
Validation loss: 2.3236161944686726

Epoch: 62| Step: 0
Training loss: 2.910210132598877
Validation loss: 2.3100840430105887

Epoch: 5| Step: 1
Training loss: 2.3085875511169434
Validation loss: 2.2932780378608295

Epoch: 5| Step: 2
Training loss: 3.171957492828369
Validation loss: 2.287156920279226

Epoch: 5| Step: 3
Training loss: 2.3276562690734863
Validation loss: 2.2831255441070883

Epoch: 5| Step: 4
Training loss: 2.6750311851501465
Validation loss: 2.270922778755106

Epoch: 5| Step: 5
Training loss: 2.241438150405884
Validation loss: 2.272270361582438

Epoch: 5| Step: 6
Training loss: 2.0383498668670654
Validation loss: 2.2803563097471833

Epoch: 5| Step: 7
Training loss: 2.7571768760681152
Validation loss: 2.2884083999100553

Epoch: 5| Step: 8
Training loss: 2.713146686553955
Validation loss: 2.31234142088121

Epoch: 5| Step: 9
Training loss: 2.5401642322540283
Validation loss: 2.3383902836871404

Epoch: 5| Step: 10
Training loss: 2.7464566230773926
Validation loss: 2.3618125736072497

Epoch: 63| Step: 0
Training loss: 2.866894006729126
Validation loss: 2.3894905787642284

Epoch: 5| Step: 1
Training loss: 3.6925086975097656
Validation loss: 2.38685211699496

Epoch: 5| Step: 2
Training loss: 3.4923298358917236
Validation loss: 2.3541946744406097

Epoch: 5| Step: 3
Training loss: 2.942610740661621
Validation loss: 2.3225671860479538

Epoch: 5| Step: 4
Training loss: 2.0116398334503174
Validation loss: 2.3002684090727117

Epoch: 5| Step: 5
Training loss: 1.9532177448272705
Validation loss: 2.2861157053260395

Epoch: 5| Step: 6
Training loss: 2.192408800125122
Validation loss: 2.2899707914680563

Epoch: 5| Step: 7
Training loss: 2.2380576133728027
Validation loss: 2.313676098341583

Epoch: 5| Step: 8
Training loss: 2.2394051551818848
Validation loss: 2.2984363161107546

Epoch: 5| Step: 9
Training loss: 2.364504814147949
Validation loss: 2.29777790141362

Epoch: 5| Step: 10
Training loss: 2.160764694213867
Validation loss: 2.3011026049173005

Epoch: 64| Step: 0
Training loss: 2.661773204803467
Validation loss: 2.310077323708483

Epoch: 5| Step: 1
Training loss: 2.5537831783294678
Validation loss: 2.2909228878636516

Epoch: 5| Step: 2
Training loss: 2.523829221725464
Validation loss: 2.277097091879896

Epoch: 5| Step: 3
Training loss: 2.671294689178467
Validation loss: 2.2750395036512807

Epoch: 5| Step: 4
Training loss: 2.5044097900390625
Validation loss: 2.2692664131041496

Epoch: 5| Step: 5
Training loss: 2.598844051361084
Validation loss: 2.273733546656947

Epoch: 5| Step: 6
Training loss: 2.3832180500030518
Validation loss: 2.272916870732461

Epoch: 5| Step: 7
Training loss: 2.8142731189727783
Validation loss: 2.2735960329732587

Epoch: 5| Step: 8
Training loss: 2.0923640727996826
Validation loss: 2.283019463221232

Epoch: 5| Step: 9
Training loss: 2.4518845081329346
Validation loss: 2.2851789843651558

Epoch: 5| Step: 10
Training loss: 2.911055088043213
Validation loss: 2.285652624663486

Epoch: 65| Step: 0
Training loss: 2.208948850631714
Validation loss: 2.290335965412919

Epoch: 5| Step: 1
Training loss: 2.7708582878112793
Validation loss: 2.2874268075471282

Epoch: 5| Step: 2
Training loss: 2.899137496948242
Validation loss: 2.277502618810182

Epoch: 5| Step: 3
Training loss: 2.5316004753112793
Validation loss: 2.2657841738834175

Epoch: 5| Step: 4
Training loss: 2.3840317726135254
Validation loss: 2.2699190032097603

Epoch: 5| Step: 5
Training loss: 2.691967010498047
Validation loss: 2.266406400229341

Epoch: 5| Step: 6
Training loss: 3.3276000022888184
Validation loss: 2.2651712894439697

Epoch: 5| Step: 7
Training loss: 2.611938714981079
Validation loss: 2.2644642758113083

Epoch: 5| Step: 8
Training loss: 2.1383118629455566
Validation loss: 2.275013815972113

Epoch: 5| Step: 9
Training loss: 2.2176895141601562
Validation loss: 2.2912208828874814

Epoch: 5| Step: 10
Training loss: 2.079512357711792
Validation loss: 2.3052085035590717

Epoch: 66| Step: 0
Training loss: 2.04082989692688
Validation loss: 2.3340807653242543

Epoch: 5| Step: 1
Training loss: 1.9631941318511963
Validation loss: 2.31935788226384

Epoch: 5| Step: 2
Training loss: 2.7896456718444824
Validation loss: 2.3349673696743545

Epoch: 5| Step: 3
Training loss: 2.6706197261810303
Validation loss: 2.3148832577531055

Epoch: 5| Step: 4
Training loss: 2.3438754081726074
Validation loss: 2.3008053841129428

Epoch: 5| Step: 5
Training loss: 2.9404778480529785
Validation loss: 2.2934787375952608

Epoch: 5| Step: 6
Training loss: 2.875488758087158
Validation loss: 2.2820054613133913

Epoch: 5| Step: 7
Training loss: 2.6707301139831543
Validation loss: 2.255438594407933

Epoch: 5| Step: 8
Training loss: 2.821746349334717
Validation loss: 2.250743455784295

Epoch: 5| Step: 9
Training loss: 2.2268331050872803
Validation loss: 2.2492985058856267

Epoch: 5| Step: 10
Training loss: 2.4878597259521484
Validation loss: 2.244216401089904

Epoch: 67| Step: 0
Training loss: 2.786752223968506
Validation loss: 2.2489600873762563

Epoch: 5| Step: 1
Training loss: 2.3560826778411865
Validation loss: 2.250474734972882

Epoch: 5| Step: 2
Training loss: 2.4098243713378906
Validation loss: 2.25740316349973

Epoch: 5| Step: 3
Training loss: 2.4028658866882324
Validation loss: 2.2474513669167795

Epoch: 5| Step: 4
Training loss: 1.9786536693572998
Validation loss: 2.246400733147898

Epoch: 5| Step: 5
Training loss: 2.9696130752563477
Validation loss: 2.2437997300137758

Epoch: 5| Step: 6
Training loss: 3.0694515705108643
Validation loss: 2.2537535390546246

Epoch: 5| Step: 7
Training loss: 3.1473517417907715
Validation loss: 2.2681851028114237

Epoch: 5| Step: 8
Training loss: 2.384347438812256
Validation loss: 2.2738917873751734

Epoch: 5| Step: 9
Training loss: 2.408041477203369
Validation loss: 2.295166705244331

Epoch: 5| Step: 10
Training loss: 1.9914355278015137
Validation loss: 2.306866850904239

Epoch: 68| Step: 0
Training loss: 1.9893401861190796
Validation loss: 2.321398692746316

Epoch: 5| Step: 1
Training loss: 2.4273526668548584
Validation loss: 2.3188007570082143

Epoch: 5| Step: 2
Training loss: 2.321617364883423
Validation loss: 2.297749537293629

Epoch: 5| Step: 3
Training loss: 2.618502378463745
Validation loss: 2.2714804321207027

Epoch: 5| Step: 4
Training loss: 2.6891963481903076
Validation loss: 2.249473866596017

Epoch: 5| Step: 5
Training loss: 2.427689790725708
Validation loss: 2.2417800477755967

Epoch: 5| Step: 6
Training loss: 2.847034215927124
Validation loss: 2.23979046780576

Epoch: 5| Step: 7
Training loss: 2.5948879718780518
Validation loss: 2.2324348700943815

Epoch: 5| Step: 8
Training loss: 2.4949586391448975
Validation loss: 2.2420767878973358

Epoch: 5| Step: 9
Training loss: 2.8035004138946533
Validation loss: 2.2385726821038032

Epoch: 5| Step: 10
Training loss: 2.777911901473999
Validation loss: 2.241273510840631

Epoch: 69| Step: 0
Training loss: 2.968799114227295
Validation loss: 2.241133428389026

Epoch: 5| Step: 1
Training loss: 3.2173283100128174
Validation loss: 2.241443910906392

Epoch: 5| Step: 2
Training loss: 2.811774730682373
Validation loss: 2.2507191473437893

Epoch: 5| Step: 3
Training loss: 2.025609254837036
Validation loss: 2.252050817653697

Epoch: 5| Step: 4
Training loss: 2.5192909240722656
Validation loss: 2.2516782591419835

Epoch: 5| Step: 5
Training loss: 2.2461891174316406
Validation loss: 2.24845270059442

Epoch: 5| Step: 6
Training loss: 2.4435949325561523
Validation loss: 2.2544233440071024

Epoch: 5| Step: 7
Training loss: 1.8840961456298828
Validation loss: 2.2566040203135502

Epoch: 5| Step: 8
Training loss: 2.3782806396484375
Validation loss: 2.264022450293264

Epoch: 5| Step: 9
Training loss: 2.5880746841430664
Validation loss: 2.271899938583374

Epoch: 5| Step: 10
Training loss: 2.775688886642456
Validation loss: 2.2855109578819683

Epoch: 70| Step: 0
Training loss: 2.3769659996032715
Validation loss: 2.2832051400215394

Epoch: 5| Step: 1
Training loss: 3.0417933464050293
Validation loss: 2.2778503407714186

Epoch: 5| Step: 2
Training loss: 2.6840004920959473
Validation loss: 2.2623972380033104

Epoch: 5| Step: 3
Training loss: 1.9974476099014282
Validation loss: 2.258930539572111

Epoch: 5| Step: 4
Training loss: 2.5103557109832764
Validation loss: 2.2646044723449217

Epoch: 5| Step: 5
Training loss: 2.8564257621765137
Validation loss: 2.242333637770786

Epoch: 5| Step: 6
Training loss: 2.699735641479492
Validation loss: 2.2357584417507215

Epoch: 5| Step: 7
Training loss: 2.5324959754943848
Validation loss: 2.230320697189659

Epoch: 5| Step: 8
Training loss: 3.0841355323791504
Validation loss: 2.216147868863998

Epoch: 5| Step: 9
Training loss: 1.9953590631484985
Validation loss: 2.2114471620129

Epoch: 5| Step: 10
Training loss: 1.9584238529205322
Validation loss: 2.2124083683054936

Epoch: 71| Step: 0
Training loss: 2.4340386390686035
Validation loss: 2.211788897873253

Epoch: 5| Step: 1
Training loss: 3.057622194290161
Validation loss: 2.215318610591273

Epoch: 5| Step: 2
Training loss: 2.6444852352142334
Validation loss: 2.210644652766566

Epoch: 5| Step: 3
Training loss: 1.789364218711853
Validation loss: 2.2228470053724063

Epoch: 5| Step: 4
Training loss: 1.888481855392456
Validation loss: 2.2451444261817524

Epoch: 5| Step: 5
Training loss: 3.0601375102996826
Validation loss: 2.2612393210011144

Epoch: 5| Step: 6
Training loss: 2.2441487312316895
Validation loss: 2.279197913344188

Epoch: 5| Step: 7
Training loss: 2.8292396068573
Validation loss: 2.300019318057645

Epoch: 5| Step: 8
Training loss: 2.4797611236572266
Validation loss: 2.3083028665152927

Epoch: 5| Step: 9
Training loss: 2.7364797592163086
Validation loss: 2.300178094576764

Epoch: 5| Step: 10
Training loss: 2.696226119995117
Validation loss: 2.2834553564748457

Epoch: 72| Step: 0
Training loss: 2.518669605255127
Validation loss: 2.245388138678766

Epoch: 5| Step: 1
Training loss: 2.3509297370910645
Validation loss: 2.230631105361446

Epoch: 5| Step: 2
Training loss: 2.6603708267211914
Validation loss: 2.2170440958392237

Epoch: 5| Step: 3
Training loss: 2.62105131149292
Validation loss: 2.2153733494461223

Epoch: 5| Step: 4
Training loss: 2.7244081497192383
Validation loss: 2.21021629148914

Epoch: 5| Step: 5
Training loss: 2.668863296508789
Validation loss: 2.2111696735505135

Epoch: 5| Step: 6
Training loss: 2.4622063636779785
Validation loss: 2.204728477744646

Epoch: 5| Step: 7
Training loss: 2.4137585163116455
Validation loss: 2.210637319472528

Epoch: 5| Step: 8
Training loss: 2.4241397380828857
Validation loss: 2.2191140984976165

Epoch: 5| Step: 9
Training loss: 2.361731767654419
Validation loss: 2.239204211901593

Epoch: 5| Step: 10
Training loss: 2.625519275665283
Validation loss: 2.2423867025683

Epoch: 73| Step: 0
Training loss: 2.45457124710083
Validation loss: 2.2238200659392984

Epoch: 5| Step: 1
Training loss: 2.2500500679016113
Validation loss: 2.2087069916468796

Epoch: 5| Step: 2
Training loss: 2.6720082759857178
Validation loss: 2.204892163635582

Epoch: 5| Step: 3
Training loss: 2.1576428413391113
Validation loss: 2.2073694531635573

Epoch: 5| Step: 4
Training loss: 2.22015643119812
Validation loss: 2.2072684905862294

Epoch: 5| Step: 5
Training loss: 2.494072437286377
Validation loss: 2.209699971701509

Epoch: 5| Step: 6
Training loss: 2.639252185821533
Validation loss: 2.2112965122345956

Epoch: 5| Step: 7
Training loss: 2.6916749477386475
Validation loss: 2.2147950767188944

Epoch: 5| Step: 8
Training loss: 2.9013545513153076
Validation loss: 2.225865279474566

Epoch: 5| Step: 9
Training loss: 2.7100887298583984
Validation loss: 2.230328731639411

Epoch: 5| Step: 10
Training loss: 2.4314234256744385
Validation loss: 2.2343698624641664

Epoch: 74| Step: 0
Training loss: 2.978816032409668
Validation loss: 2.248591120525073

Epoch: 5| Step: 1
Training loss: 3.1198792457580566
Validation loss: 2.2385074092495825

Epoch: 5| Step: 2
Training loss: 2.1816623210906982
Validation loss: 2.233426747783538

Epoch: 5| Step: 3
Training loss: 2.8771777153015137
Validation loss: 2.227277014845161

Epoch: 5| Step: 4
Training loss: 2.4394850730895996
Validation loss: 2.2225243506893033

Epoch: 5| Step: 5
Training loss: 2.0988588333129883
Validation loss: 2.227478728499464

Epoch: 5| Step: 6
Training loss: 2.3676178455352783
Validation loss: 2.2202950100744925

Epoch: 5| Step: 7
Training loss: 2.869811773300171
Validation loss: 2.2199550892717097

Epoch: 5| Step: 8
Training loss: 2.0352516174316406
Validation loss: 2.226785828990321

Epoch: 5| Step: 9
Training loss: 2.3345112800598145
Validation loss: 2.2226172185713247

Epoch: 5| Step: 10
Training loss: 2.2458553314208984
Validation loss: 2.2237880806769095

Epoch: 75| Step: 0
Training loss: 2.267256498336792
Validation loss: 2.2192081071997203

Epoch: 5| Step: 1
Training loss: 2.946230888366699
Validation loss: 2.230917881893855

Epoch: 5| Step: 2
Training loss: 2.2749667167663574
Validation loss: 2.2602941630988993

Epoch: 5| Step: 3
Training loss: 2.8456051349639893
Validation loss: 2.2583205289738153

Epoch: 5| Step: 4
Training loss: 3.0444066524505615
Validation loss: 2.2408527123030795

Epoch: 5| Step: 5
Training loss: 2.2914154529571533
Validation loss: 2.227355387903029

Epoch: 5| Step: 6
Training loss: 2.1396872997283936
Validation loss: 2.2274508066074823

Epoch: 5| Step: 7
Training loss: 2.5945181846618652
Validation loss: 2.210774867765365

Epoch: 5| Step: 8
Training loss: 2.297010898590088
Validation loss: 2.2095321814219155

Epoch: 5| Step: 9
Training loss: 2.27455997467041
Validation loss: 2.2181527768411944

Epoch: 5| Step: 10
Training loss: 2.512712240219116
Validation loss: 2.208128727892394

Epoch: 76| Step: 0
Training loss: 2.434199333190918
Validation loss: 2.2074444434976064

Epoch: 5| Step: 1
Training loss: 2.036628246307373
Validation loss: 2.2123384655162854

Epoch: 5| Step: 2
Training loss: 2.365957260131836
Validation loss: 2.2038773926355506

Epoch: 5| Step: 3
Training loss: 2.681875705718994
Validation loss: 2.206551403127691

Epoch: 5| Step: 4
Training loss: 3.0838534832000732
Validation loss: 2.2017559133550173

Epoch: 5| Step: 5
Training loss: 2.3323235511779785
Validation loss: 2.202165760019774

Epoch: 5| Step: 6
Training loss: 2.8192384243011475
Validation loss: 2.203837021704643

Epoch: 5| Step: 7
Training loss: 2.1204679012298584
Validation loss: 2.20082821512735

Epoch: 5| Step: 8
Training loss: 2.855276584625244
Validation loss: 2.201177740609774

Epoch: 5| Step: 9
Training loss: 2.4865920543670654
Validation loss: 2.203456522316061

Epoch: 5| Step: 10
Training loss: 2.0880022048950195
Validation loss: 2.2043332566497145

Epoch: 77| Step: 0
Training loss: 2.6064789295196533
Validation loss: 2.2141290967182448

Epoch: 5| Step: 1
Training loss: 2.7605175971984863
Validation loss: 2.2288049856821694

Epoch: 5| Step: 2
Training loss: 2.580613374710083
Validation loss: 2.24443418236189

Epoch: 5| Step: 3
Training loss: 2.3423011302948
Validation loss: 2.2428033172443347

Epoch: 5| Step: 4
Training loss: 2.102344274520874
Validation loss: 2.2103872683740433

Epoch: 5| Step: 5
Training loss: 2.2487494945526123
Validation loss: 2.1930351846961567

Epoch: 5| Step: 6
Training loss: 3.2602596282958984
Validation loss: 2.197181749087508

Epoch: 5| Step: 7
Training loss: 3.2181429862976074
Validation loss: 2.191906236833142

Epoch: 5| Step: 8
Training loss: 2.189542531967163
Validation loss: 2.1861191462445

Epoch: 5| Step: 9
Training loss: 2.342491865158081
Validation loss: 2.1897219034933273

Epoch: 5| Step: 10
Training loss: 1.6126741170883179
Validation loss: 2.197998217357102

Epoch: 78| Step: 0
Training loss: 2.771390438079834
Validation loss: 2.1975088145143244

Epoch: 5| Step: 1
Training loss: 2.759589672088623
Validation loss: 2.200567768466088

Epoch: 5| Step: 2
Training loss: 2.649460554122925
Validation loss: 2.198341146592171

Epoch: 5| Step: 3
Training loss: 2.601982593536377
Validation loss: 2.2000346465777327

Epoch: 5| Step: 4
Training loss: 2.142160654067993
Validation loss: 2.1978420852332987

Epoch: 5| Step: 5
Training loss: 2.3127877712249756
Validation loss: 2.2117055718616774

Epoch: 5| Step: 6
Training loss: 1.879743218421936
Validation loss: 2.2294221949833695

Epoch: 5| Step: 7
Training loss: 2.8039097785949707
Validation loss: 2.2457133262388167

Epoch: 5| Step: 8
Training loss: 2.057516574859619
Validation loss: 2.236991115795669

Epoch: 5| Step: 9
Training loss: 2.605644464492798
Validation loss: 2.2315530469340663

Epoch: 5| Step: 10
Training loss: 2.754537582397461
Validation loss: 2.2306250295331402

Epoch: 79| Step: 0
Training loss: 2.6282577514648438
Validation loss: 2.2224891903579875

Epoch: 5| Step: 1
Training loss: 2.9925625324249268
Validation loss: 2.1988803404633717

Epoch: 5| Step: 2
Training loss: 2.0583863258361816
Validation loss: 2.1904725848987536

Epoch: 5| Step: 3
Training loss: 2.7296276092529297
Validation loss: 2.184488647727556

Epoch: 5| Step: 4
Training loss: 2.1107020378112793
Validation loss: 2.185275921257593

Epoch: 5| Step: 5
Training loss: 3.012800693511963
Validation loss: 2.187671522940359

Epoch: 5| Step: 6
Training loss: 2.5647168159484863
Validation loss: 2.1843407974448255

Epoch: 5| Step: 7
Training loss: 2.2068979740142822
Validation loss: 2.1870005976769233

Epoch: 5| Step: 8
Training loss: 2.1685802936553955
Validation loss: 2.1799384765727545

Epoch: 5| Step: 9
Training loss: 2.7573649883270264
Validation loss: 2.1807033477290982

Epoch: 5| Step: 10
Training loss: 1.888138771057129
Validation loss: 2.1751831103396673

Epoch: 80| Step: 0
Training loss: 3.0025393962860107
Validation loss: 2.1900596669925156

Epoch: 5| Step: 1
Training loss: 2.5195155143737793
Validation loss: 2.1975509505118094

Epoch: 5| Step: 2
Training loss: 1.9192121028900146
Validation loss: 2.2184718578092513

Epoch: 5| Step: 3
Training loss: 1.6128612756729126
Validation loss: 2.2497314201888217

Epoch: 5| Step: 4
Training loss: 2.7249350547790527
Validation loss: 2.2848693773310673

Epoch: 5| Step: 5
Training loss: 3.0273075103759766
Validation loss: 2.2934769533013784

Epoch: 5| Step: 6
Training loss: 2.6090831756591797
Validation loss: 2.260397793144308

Epoch: 5| Step: 7
Training loss: 2.6043269634246826
Validation loss: 2.211659210984425

Epoch: 5| Step: 8
Training loss: 2.448652982711792
Validation loss: 2.2064137176800798

Epoch: 5| Step: 9
Training loss: 2.298072338104248
Validation loss: 2.184417893809657

Epoch: 5| Step: 10
Training loss: 2.4375014305114746
Validation loss: 2.187651095851775

Epoch: 81| Step: 0
Training loss: 2.5653316974639893
Validation loss: 2.1848729733497865

Epoch: 5| Step: 1
Training loss: 3.056030511856079
Validation loss: 2.192924843039564

Epoch: 5| Step: 2
Training loss: 2.023686647415161
Validation loss: 2.199588426979639

Epoch: 5| Step: 3
Training loss: 2.6992383003234863
Validation loss: 2.1840657226500975

Epoch: 5| Step: 4
Training loss: 2.8102238178253174
Validation loss: 2.1583304738485687

Epoch: 5| Step: 5
Training loss: 2.4698173999786377
Validation loss: 2.1653334325359714

Epoch: 5| Step: 6
Training loss: 2.4525959491729736
Validation loss: 2.1836570103963218

Epoch: 5| Step: 7
Training loss: 1.934815764427185
Validation loss: 2.2053317895499607

Epoch: 5| Step: 8
Training loss: 2.085844039916992
Validation loss: 2.233168243080057

Epoch: 5| Step: 9
Training loss: 2.8434243202209473
Validation loss: 2.261970776383595

Epoch: 5| Step: 10
Training loss: 2.2817325592041016
Validation loss: 2.283048604124336

Epoch: 82| Step: 0
Training loss: 2.2802319526672363
Validation loss: 2.2699224064427037

Epoch: 5| Step: 1
Training loss: 2.4638702869415283
Validation loss: 2.2192994420246412

Epoch: 5| Step: 2
Training loss: 2.6767563819885254
Validation loss: 2.1824237415867467

Epoch: 5| Step: 3
Training loss: 2.6001152992248535
Validation loss: 2.1657995075307865

Epoch: 5| Step: 4
Training loss: 2.982898712158203
Validation loss: 2.153136889139811

Epoch: 5| Step: 5
Training loss: 2.540480375289917
Validation loss: 2.1529598671902894

Epoch: 5| Step: 6
Training loss: 2.42482328414917
Validation loss: 2.153746892047185

Epoch: 5| Step: 7
Training loss: 2.280073881149292
Validation loss: 2.161683682472475

Epoch: 5| Step: 8
Training loss: 2.2811055183410645
Validation loss: 2.1612513039701726

Epoch: 5| Step: 9
Training loss: 2.570664644241333
Validation loss: 2.1692884955354916

Epoch: 5| Step: 10
Training loss: 2.1962528228759766
Validation loss: 2.1865444657623128

Epoch: 83| Step: 0
Training loss: 2.10375714302063
Validation loss: 2.198369176157059

Epoch: 5| Step: 1
Training loss: 2.664921522140503
Validation loss: 2.2034112945679696

Epoch: 5| Step: 2
Training loss: 1.9389501810073853
Validation loss: 2.2051542574359524

Epoch: 5| Step: 3
Training loss: 3.0395517349243164
Validation loss: 2.2003115146390853

Epoch: 5| Step: 4
Training loss: 2.503877639770508
Validation loss: 2.1835067656732376

Epoch: 5| Step: 5
Training loss: 2.7056281566619873
Validation loss: 2.178517265986371

Epoch: 5| Step: 6
Training loss: 2.3802342414855957
Validation loss: 2.1792919392226846

Epoch: 5| Step: 7
Training loss: 2.388522148132324
Validation loss: 2.1859095340133994

Epoch: 5| Step: 8
Training loss: 2.0006861686706543
Validation loss: 2.1952227674504763

Epoch: 5| Step: 9
Training loss: 2.806337594985962
Validation loss: 2.1987512573119132

Epoch: 5| Step: 10
Training loss: 2.45137882232666
Validation loss: 2.21322391879174

Epoch: 84| Step: 0
Training loss: 2.5441696643829346
Validation loss: 2.2108551174081783

Epoch: 5| Step: 1
Training loss: 2.898040294647217
Validation loss: 2.2132641807679208

Epoch: 5| Step: 2
Training loss: 2.731637954711914
Validation loss: 2.199342317478631

Epoch: 5| Step: 3
Training loss: 2.6434857845306396
Validation loss: 2.2081200179233345

Epoch: 5| Step: 4
Training loss: 2.0633950233459473
Validation loss: 2.206730756708371

Epoch: 5| Step: 5
Training loss: 2.1055986881256104
Validation loss: 2.2082123294953377

Epoch: 5| Step: 6
Training loss: 2.367326498031616
Validation loss: 2.1996763265261086

Epoch: 5| Step: 7
Training loss: 2.528860092163086
Validation loss: 2.191962121635355

Epoch: 5| Step: 8
Training loss: 2.478609561920166
Validation loss: 2.191352863465586

Epoch: 5| Step: 9
Training loss: 2.5438551902770996
Validation loss: 2.189666235318748

Epoch: 5| Step: 10
Training loss: 1.9149876832962036
Validation loss: 2.1871396879996023

Epoch: 85| Step: 0
Training loss: 2.7149462699890137
Validation loss: 2.19335481556513

Epoch: 5| Step: 1
Training loss: 2.5903618335723877
Validation loss: 2.1846051164852676

Epoch: 5| Step: 2
Training loss: 2.796821117401123
Validation loss: 2.1868345045274302

Epoch: 5| Step: 3
Training loss: 2.0883493423461914
Validation loss: 2.1738965934322727

Epoch: 5| Step: 4
Training loss: 2.7236504554748535
Validation loss: 2.1702928081635506

Epoch: 5| Step: 5
Training loss: 2.730933666229248
Validation loss: 2.167884408786733

Epoch: 5| Step: 6
Training loss: 1.859829306602478
Validation loss: 2.175759800018803

Epoch: 5| Step: 7
Training loss: 2.3557851314544678
Validation loss: 2.172707675605692

Epoch: 5| Step: 8
Training loss: 2.4499382972717285
Validation loss: 2.1769076188405356

Epoch: 5| Step: 9
Training loss: 2.0833728313446045
Validation loss: 2.181417585701071

Epoch: 5| Step: 10
Training loss: 2.6055102348327637
Validation loss: 2.2018739151698288

Epoch: 86| Step: 0
Training loss: 2.3093409538269043
Validation loss: 2.2215527206338863

Epoch: 5| Step: 1
Training loss: 2.237865447998047
Validation loss: 2.2196706571886615

Epoch: 5| Step: 2
Training loss: 1.8084619045257568
Validation loss: 2.2380064777148667

Epoch: 5| Step: 3
Training loss: 2.2899158000946045
Validation loss: 2.2100162262557657

Epoch: 5| Step: 4
Training loss: 2.4199764728546143
Validation loss: 2.202979382648263

Epoch: 5| Step: 5
Training loss: 2.2443630695343018
Validation loss: 2.1880017044723674

Epoch: 5| Step: 6
Training loss: 2.538670539855957
Validation loss: 2.192862528626637

Epoch: 5| Step: 7
Training loss: 2.7426929473876953
Validation loss: 2.195286172692494

Epoch: 5| Step: 8
Training loss: 3.251818895339966
Validation loss: 2.178833464140533

Epoch: 5| Step: 9
Training loss: 2.512164354324341
Validation loss: 2.1628986840607016

Epoch: 5| Step: 10
Training loss: 2.5193793773651123
Validation loss: 2.1588716301866757

Epoch: 87| Step: 0
Training loss: 2.3400063514709473
Validation loss: 2.1542003552118936

Epoch: 5| Step: 1
Training loss: 2.8292832374572754
Validation loss: 2.152873895501578

Epoch: 5| Step: 2
Training loss: 2.5472512245178223
Validation loss: 2.152534379754015

Epoch: 5| Step: 3
Training loss: 2.5941014289855957
Validation loss: 2.17292796668186

Epoch: 5| Step: 4
Training loss: 2.3233466148376465
Validation loss: 2.187573074012674

Epoch: 5| Step: 5
Training loss: 2.1506173610687256
Validation loss: 2.2176057638660556

Epoch: 5| Step: 6
Training loss: 2.1237716674804688
Validation loss: 2.2087666116734987

Epoch: 5| Step: 7
Training loss: 2.1245603561401367
Validation loss: 2.2160268855351273

Epoch: 5| Step: 8
Training loss: 2.3790524005889893
Validation loss: 2.1896532556062103

Epoch: 5| Step: 9
Training loss: 3.038867473602295
Validation loss: 2.1577943037914973

Epoch: 5| Step: 10
Training loss: 2.313308000564575
Validation loss: 2.1353481572161437

Epoch: 88| Step: 0
Training loss: 1.8992042541503906
Validation loss: 2.123102354746993

Epoch: 5| Step: 1
Training loss: 2.5044124126434326
Validation loss: 2.113292027545232

Epoch: 5| Step: 2
Training loss: 2.742220401763916
Validation loss: 2.1270461044003888

Epoch: 5| Step: 3
Training loss: 2.5843379497528076
Validation loss: 2.1305374971000095

Epoch: 5| Step: 4
Training loss: 2.577411651611328
Validation loss: 2.13584622516427

Epoch: 5| Step: 5
Training loss: 1.9809436798095703
Validation loss: 2.1242163642760246

Epoch: 5| Step: 6
Training loss: 2.8812479972839355
Validation loss: 2.124522122003699

Epoch: 5| Step: 7
Training loss: 2.1327295303344727
Validation loss: 2.1157410708806847

Epoch: 5| Step: 8
Training loss: 2.639650821685791
Validation loss: 2.121218417280464

Epoch: 5| Step: 9
Training loss: 2.661738872528076
Validation loss: 2.110460086535382

Epoch: 5| Step: 10
Training loss: 2.5480756759643555
Validation loss: 2.126121178750069

Epoch: 89| Step: 0
Training loss: 2.4773643016815186
Validation loss: 2.157865766556032

Epoch: 5| Step: 1
Training loss: 2.4906868934631348
Validation loss: 2.1991871608200895

Epoch: 5| Step: 2
Training loss: 2.713697910308838
Validation loss: 2.2437214261742047

Epoch: 5| Step: 3
Training loss: 2.297438383102417
Validation loss: 2.2752580206881285

Epoch: 5| Step: 4
Training loss: 2.9652810096740723
Validation loss: 2.228773461875095

Epoch: 5| Step: 5
Training loss: 2.146358013153076
Validation loss: 2.1751407295145015

Epoch: 5| Step: 6
Training loss: 2.3227524757385254
Validation loss: 2.1746211795396704

Epoch: 5| Step: 7
Training loss: 2.1702167987823486
Validation loss: 2.1549894502086024

Epoch: 5| Step: 8
Training loss: 2.5087578296661377
Validation loss: 2.139269369904713

Epoch: 5| Step: 9
Training loss: 2.1022307872772217
Validation loss: 2.1254543437752673

Epoch: 5| Step: 10
Training loss: 2.428905487060547
Validation loss: 2.117378257936047

Epoch: 90| Step: 0
Training loss: 2.284851551055908
Validation loss: 2.126602863752714

Epoch: 5| Step: 1
Training loss: 2.2225494384765625
Validation loss: 2.128714252543706

Epoch: 5| Step: 2
Training loss: 2.1956863403320312
Validation loss: 2.128536860148112

Epoch: 5| Step: 3
Training loss: 3.4120166301727295
Validation loss: 2.114147086297312

Epoch: 5| Step: 4
Training loss: 3.116154193878174
Validation loss: 2.1073477024673135

Epoch: 5| Step: 5
Training loss: 2.6270713806152344
Validation loss: 2.1027849464006323

Epoch: 5| Step: 6
Training loss: 1.9800125360488892
Validation loss: 2.1133354966358473

Epoch: 5| Step: 7
Training loss: 2.2265987396240234
Validation loss: 2.112421412621775

Epoch: 5| Step: 8
Training loss: 2.2667040824890137
Validation loss: 2.123982416686191

Epoch: 5| Step: 9
Training loss: 2.5206751823425293
Validation loss: 2.1469014331858647

Epoch: 5| Step: 10
Training loss: 1.8205270767211914
Validation loss: 2.2011910869229223

Epoch: 91| Step: 0
Training loss: 2.5711185932159424
Validation loss: 2.3182237814831477

Epoch: 5| Step: 1
Training loss: 1.9632478952407837
Validation loss: 2.404513435979043

Epoch: 5| Step: 2
Training loss: 2.6981637477874756
Validation loss: 2.4208620235484135

Epoch: 5| Step: 3
Training loss: 1.8885619640350342
Validation loss: 2.3572379517298874

Epoch: 5| Step: 4
Training loss: 2.7302041053771973
Validation loss: 2.2328629519349787

Epoch: 5| Step: 5
Training loss: 2.428741455078125
Validation loss: 2.1672423731896187

Epoch: 5| Step: 6
Training loss: 2.7379109859466553
Validation loss: 2.1361233034441547

Epoch: 5| Step: 7
Training loss: 1.935530662536621
Validation loss: 2.1169807975010206

Epoch: 5| Step: 8
Training loss: 3.054819107055664
Validation loss: 2.1225681202386015

Epoch: 5| Step: 9
Training loss: 2.466576099395752
Validation loss: 2.1295053766619776

Epoch: 5| Step: 10
Training loss: 2.977151393890381
Validation loss: 2.1618187324975127

Epoch: 92| Step: 0
Training loss: 2.591813564300537
Validation loss: 2.190295926986202

Epoch: 5| Step: 1
Training loss: 3.003192901611328
Validation loss: 2.212559376993487

Epoch: 5| Step: 2
Training loss: 2.7198641300201416
Validation loss: 2.171976914969824

Epoch: 5| Step: 3
Training loss: 1.7915804386138916
Validation loss: 2.1660836819679505

Epoch: 5| Step: 4
Training loss: 1.9254939556121826
Validation loss: 2.211432715897919

Epoch: 5| Step: 5
Training loss: 2.1219682693481445
Validation loss: 2.250373932623094

Epoch: 5| Step: 6
Training loss: 2.21610689163208
Validation loss: 2.280267923108993

Epoch: 5| Step: 7
Training loss: 2.572068452835083
Validation loss: 2.2471819923770044

Epoch: 5| Step: 8
Training loss: 2.632410764694214
Validation loss: 2.2455546932835735

Epoch: 5| Step: 9
Training loss: 2.942772150039673
Validation loss: 2.2279867228641304

Epoch: 5| Step: 10
Training loss: 2.6629233360290527
Validation loss: 2.2157915381975073

Epoch: 93| Step: 0
Training loss: 2.448853015899658
Validation loss: 2.184765431188768

Epoch: 5| Step: 1
Training loss: 1.9025284051895142
Validation loss: 2.175012698737524

Epoch: 5| Step: 2
Training loss: 2.6176352500915527
Validation loss: 2.164180865851782

Epoch: 5| Step: 3
Training loss: 2.566788673400879
Validation loss: 2.154740934730858

Epoch: 5| Step: 4
Training loss: 3.0076117515563965
Validation loss: 2.1336605638586064

Epoch: 5| Step: 5
Training loss: 2.209339141845703
Validation loss: 2.13008487737307

Epoch: 5| Step: 6
Training loss: 2.474228620529175
Validation loss: 2.117520205436214

Epoch: 5| Step: 7
Training loss: 2.228614330291748
Validation loss: 2.1014790176063456

Epoch: 5| Step: 8
Training loss: 2.975928544998169
Validation loss: 2.1014767334025395

Epoch: 5| Step: 9
Training loss: 2.0075247287750244
Validation loss: 2.0999208906645417

Epoch: 5| Step: 10
Training loss: 2.019369125366211
Validation loss: 2.10194133686763

Epoch: 94| Step: 0
Training loss: 2.2709615230560303
Validation loss: 2.098202751528832

Epoch: 5| Step: 1
Training loss: 2.437533140182495
Validation loss: 2.0979026876470095

Epoch: 5| Step: 2
Training loss: 1.7442958354949951
Validation loss: 2.117889150496452

Epoch: 5| Step: 3
Training loss: 2.1977744102478027
Validation loss: 2.1517560802480227

Epoch: 5| Step: 4
Training loss: 2.3668136596679688
Validation loss: 2.1452665175161054

Epoch: 5| Step: 5
Training loss: 2.956568479537964
Validation loss: 2.146087508047781

Epoch: 5| Step: 6
Training loss: 2.660374879837036
Validation loss: 2.137791592587707

Epoch: 5| Step: 7
Training loss: 2.344040632247925
Validation loss: 2.11679748822284

Epoch: 5| Step: 8
Training loss: 2.901310920715332
Validation loss: 2.1069638754731868

Epoch: 5| Step: 9
Training loss: 2.4373364448547363
Validation loss: 2.1065572307955835

Epoch: 5| Step: 10
Training loss: 2.031405448913574
Validation loss: 2.111914211703885

Epoch: 95| Step: 0
Training loss: 2.287501811981201
Validation loss: 2.1160062359225367

Epoch: 5| Step: 1
Training loss: 2.7660670280456543
Validation loss: 2.1287474273353495

Epoch: 5| Step: 2
Training loss: 2.0706424713134766
Validation loss: 2.149857988921545

Epoch: 5| Step: 3
Training loss: 2.5346226692199707
Validation loss: 2.212446948533417

Epoch: 5| Step: 4
Training loss: 2.6063389778137207
Validation loss: 2.2307666245327202

Epoch: 5| Step: 5
Training loss: 2.030639886856079
Validation loss: 2.2574708077215377

Epoch: 5| Step: 6
Training loss: 2.4650189876556396
Validation loss: 2.2240614070687243

Epoch: 5| Step: 7
Training loss: 2.3297715187072754
Validation loss: 2.2081630973405737

Epoch: 5| Step: 8
Training loss: 2.830573320388794
Validation loss: 2.2026723687366774

Epoch: 5| Step: 9
Training loss: 2.321110963821411
Validation loss: 2.168295773126746

Epoch: 5| Step: 10
Training loss: 1.9489250183105469
Validation loss: 2.1514907857423187

Epoch: 96| Step: 0
Training loss: 2.3497581481933594
Validation loss: 2.12595094532095

Epoch: 5| Step: 1
Training loss: 2.6005795001983643
Validation loss: 2.136793105832992

Epoch: 5| Step: 2
Training loss: 2.2807397842407227
Validation loss: 2.169272950900498

Epoch: 5| Step: 3
Training loss: 2.849832773208618
Validation loss: 2.183025044779624

Epoch: 5| Step: 4
Training loss: 2.823885202407837
Validation loss: 2.1517705584085114

Epoch: 5| Step: 5
Training loss: 2.2563869953155518
Validation loss: 2.161873291897517

Epoch: 5| Step: 6
Training loss: 2.8825504779815674
Validation loss: 2.1681842752682265

Epoch: 5| Step: 7
Training loss: 1.9678971767425537
Validation loss: 2.177451196537223

Epoch: 5| Step: 8
Training loss: 2.5461935997009277
Validation loss: 2.1861412858450286

Epoch: 5| Step: 9
Training loss: 2.257676124572754
Validation loss: 2.170576621127385

Epoch: 5| Step: 10
Training loss: 1.482092261314392
Validation loss: 2.182048004160645

Epoch: 97| Step: 0
Training loss: 2.2795157432556152
Validation loss: 2.190958733199745

Epoch: 5| Step: 1
Training loss: 2.3254549503326416
Validation loss: 2.1945407852049796

Epoch: 5| Step: 2
Training loss: 2.6319468021392822
Validation loss: 2.2060159457627164

Epoch: 5| Step: 3
Training loss: 2.5998599529266357
Validation loss: 2.2215091746340514

Epoch: 5| Step: 4
Training loss: 2.3570077419281006
Validation loss: 2.2122423956471104

Epoch: 5| Step: 5
Training loss: 1.9114017486572266
Validation loss: 2.1817909722687094

Epoch: 5| Step: 6
Training loss: 1.6752655506134033
Validation loss: 2.1440800184844644

Epoch: 5| Step: 7
Training loss: 3.0271553993225098
Validation loss: 2.1177005396094373

Epoch: 5| Step: 8
Training loss: 2.666328191757202
Validation loss: 2.1039721247970418

Epoch: 5| Step: 9
Training loss: 2.5121524333953857
Validation loss: 2.0852228005727134

Epoch: 5| Step: 10
Training loss: 2.1508939266204834
Validation loss: 2.081399019046496

Epoch: 98| Step: 0
Training loss: 2.350428581237793
Validation loss: 2.0909337228344334

Epoch: 5| Step: 1
Training loss: 2.6321969032287598
Validation loss: 2.0975829811506372

Epoch: 5| Step: 2
Training loss: 1.6241188049316406
Validation loss: 2.095475991566976

Epoch: 5| Step: 3
Training loss: 3.0595836639404297
Validation loss: 2.0835746911264237

Epoch: 5| Step: 4
Training loss: 3.0219311714172363
Validation loss: 2.0883360908877466

Epoch: 5| Step: 5
Training loss: 2.765625238418579
Validation loss: 2.096915950057327

Epoch: 5| Step: 6
Training loss: 1.7845081090927124
Validation loss: 2.1424021823431856

Epoch: 5| Step: 7
Training loss: 2.611405849456787
Validation loss: 2.236782632848268

Epoch: 5| Step: 8
Training loss: 2.0128798484802246
Validation loss: 2.330682857062227

Epoch: 5| Step: 9
Training loss: 1.7134368419647217
Validation loss: 2.3445169797507663

Epoch: 5| Step: 10
Training loss: 3.1643030643463135
Validation loss: 2.333896936908845

Epoch: 99| Step: 0
Training loss: 2.157139778137207
Validation loss: 2.2709662478457213

Epoch: 5| Step: 1
Training loss: 3.100432872772217
Validation loss: 2.1697726044603574

Epoch: 5| Step: 2
Training loss: 2.6642396450042725
Validation loss: 2.1088271166688655

Epoch: 5| Step: 3
Training loss: 2.6049060821533203
Validation loss: 2.100079144200971

Epoch: 5| Step: 4
Training loss: 2.6784369945526123
Validation loss: 2.1188589821579638

Epoch: 5| Step: 5
Training loss: 2.310720920562744
Validation loss: 2.1353861131975727

Epoch: 5| Step: 6
Training loss: 2.6517443656921387
Validation loss: 2.173317632367534

Epoch: 5| Step: 7
Training loss: 2.010305404663086
Validation loss: 2.2106027962059103

Epoch: 5| Step: 8
Training loss: 2.102273464202881
Validation loss: 2.2544658876234487

Epoch: 5| Step: 9
Training loss: 2.027249813079834
Validation loss: 2.2717240318175285

Epoch: 5| Step: 10
Training loss: 2.1894328594207764
Validation loss: 2.244774587692753

Epoch: 100| Step: 0
Training loss: 2.7149932384490967
Validation loss: 2.2540795469796784

Epoch: 5| Step: 1
Training loss: 2.502392530441284
Validation loss: 2.2075733677033456

Epoch: 5| Step: 2
Training loss: 2.809885263442993
Validation loss: 2.1820917206425823

Epoch: 5| Step: 3
Training loss: 2.9461703300476074
Validation loss: 2.180409144329768

Epoch: 5| Step: 4
Training loss: 2.200441837310791
Validation loss: 2.1754953476690475

Epoch: 5| Step: 5
Training loss: 1.8089134693145752
Validation loss: 2.1807441672971173

Epoch: 5| Step: 6
Training loss: 1.6081386804580688
Validation loss: 2.170428760590092

Epoch: 5| Step: 7
Training loss: 2.3929286003112793
Validation loss: 2.1585767320407334

Epoch: 5| Step: 8
Training loss: 2.708521604537964
Validation loss: 2.1673749364832395

Epoch: 5| Step: 9
Training loss: 2.2371163368225098
Validation loss: 2.1666359824519

Epoch: 5| Step: 10
Training loss: 1.8676657676696777
Validation loss: 2.1623802031240156

Epoch: 101| Step: 0
Training loss: 2.836369037628174
Validation loss: 2.162470648365636

Epoch: 5| Step: 1
Training loss: 1.9634653329849243
Validation loss: 2.1649155693669475

Epoch: 5| Step: 2
Training loss: 2.5613086223602295
Validation loss: 2.1622312735485774

Epoch: 5| Step: 3
Training loss: 2.7733120918273926
Validation loss: 2.156224996812882

Epoch: 5| Step: 4
Training loss: 2.396826982498169
Validation loss: 2.136042453909433

Epoch: 5| Step: 5
Training loss: 2.5923843383789062
Validation loss: 2.119468810737774

Epoch: 5| Step: 6
Training loss: 2.2164011001586914
Validation loss: 2.11178756272921

Epoch: 5| Step: 7
Training loss: 2.774925708770752
Validation loss: 2.116269738443436

Epoch: 5| Step: 8
Training loss: 1.974714994430542
Validation loss: 2.1247707592543734

Epoch: 5| Step: 9
Training loss: 1.4095349311828613
Validation loss: 2.138222787969856

Epoch: 5| Step: 10
Training loss: 2.1779637336730957
Validation loss: 2.171490970478263

Epoch: 102| Step: 0
Training loss: 2.5113420486450195
Validation loss: 2.1841377237791657

Epoch: 5| Step: 1
Training loss: 1.5454344749450684
Validation loss: 2.1750950364656347

Epoch: 5| Step: 2
Training loss: 2.6537246704101562
Validation loss: 2.144613589009931

Epoch: 5| Step: 3
Training loss: 2.271069288253784
Validation loss: 2.120757233711981

Epoch: 5| Step: 4
Training loss: 3.1973280906677246
Validation loss: 2.1034289995829263

Epoch: 5| Step: 5
Training loss: 1.9298515319824219
Validation loss: 2.086379620336717

Epoch: 5| Step: 6
Training loss: 2.457075595855713
Validation loss: 2.0862010755846576

Epoch: 5| Step: 7
Training loss: 2.6523284912109375
Validation loss: 2.082898066889855

Epoch: 5| Step: 8
Training loss: 2.339507579803467
Validation loss: 2.080015133785945

Epoch: 5| Step: 9
Training loss: 1.9768654108047485
Validation loss: 2.0986257509518693

Epoch: 5| Step: 10
Training loss: 2.2576258182525635
Validation loss: 2.1240009825716735

Epoch: 103| Step: 0
Training loss: 2.446465492248535
Validation loss: 2.144828987377946

Epoch: 5| Step: 1
Training loss: 2.5749881267547607
Validation loss: 2.2096275975627284

Epoch: 5| Step: 2
Training loss: 1.9989362955093384
Validation loss: 2.2279769682115123

Epoch: 5| Step: 3
Training loss: 2.5228865146636963
Validation loss: 2.224631894019342

Epoch: 5| Step: 4
Training loss: 2.5248255729675293
Validation loss: 2.2041935177259546

Epoch: 5| Step: 5
Training loss: 1.9512813091278076
Validation loss: 2.1543406773638982

Epoch: 5| Step: 6
Training loss: 2.9284183979034424
Validation loss: 2.1451788845882622

Epoch: 5| Step: 7
Training loss: 2.0503907203674316
Validation loss: 2.1500658296769664

Epoch: 5| Step: 8
Training loss: 2.195455312728882
Validation loss: 2.1580235368462017

Epoch: 5| Step: 9
Training loss: 2.3597562313079834
Validation loss: 2.182909345114103

Epoch: 5| Step: 10
Training loss: 2.4640040397644043
Validation loss: 2.200667768396357

Epoch: 104| Step: 0
Training loss: 1.924933671951294
Validation loss: 2.1780225256437897

Epoch: 5| Step: 1
Training loss: 1.750125527381897
Validation loss: 2.144996827648532

Epoch: 5| Step: 2
Training loss: 2.576937437057495
Validation loss: 2.1242339764871905

Epoch: 5| Step: 3
Training loss: 2.5015201568603516
Validation loss: 2.1055033565849386

Epoch: 5| Step: 4
Training loss: 2.4671082496643066
Validation loss: 2.106835429386426

Epoch: 5| Step: 5
Training loss: 2.258532762527466
Validation loss: 2.092543545589652

Epoch: 5| Step: 6
Training loss: 2.573505401611328
Validation loss: 2.1034413435125865

Epoch: 5| Step: 7
Training loss: 2.6697545051574707
Validation loss: 2.1310106451793382

Epoch: 5| Step: 8
Training loss: 2.165149211883545
Validation loss: 2.145008708841057

Epoch: 5| Step: 9
Training loss: 2.1546521186828613
Validation loss: 2.1351249499987532

Epoch: 5| Step: 10
Training loss: 2.2557573318481445
Validation loss: 2.1365483242978334

Epoch: 105| Step: 0
Training loss: 2.580374240875244
Validation loss: 2.1322795960210983

Epoch: 5| Step: 1
Training loss: 2.1597180366516113
Validation loss: 2.115032370372485

Epoch: 5| Step: 2
Training loss: 2.6093804836273193
Validation loss: 2.1165128266939552

Epoch: 5| Step: 3
Training loss: 2.3179931640625
Validation loss: 2.100622982107183

Epoch: 5| Step: 4
Training loss: 2.4830455780029297
Validation loss: 2.145076121053388

Epoch: 5| Step: 5
Training loss: 1.8488876819610596
Validation loss: 2.171487036571708

Epoch: 5| Step: 6
Training loss: 2.7598676681518555
Validation loss: 2.2030915880715973

Epoch: 5| Step: 7
Training loss: 2.1844475269317627
Validation loss: 2.1946096817652383

Epoch: 5| Step: 8
Training loss: 2.3781838417053223
Validation loss: 2.1925978583674275

Epoch: 5| Step: 9
Training loss: 1.8304866552352905
Validation loss: 2.173675734509704

Epoch: 5| Step: 10
Training loss: 1.9108424186706543
Validation loss: 2.1452287550895446

Epoch: 106| Step: 0
Training loss: 1.916632056236267
Validation loss: 2.1262442347823933

Epoch: 5| Step: 1
Training loss: 2.4807865619659424
Validation loss: 2.118030135349561

Epoch: 5| Step: 2
Training loss: 2.3785033226013184
Validation loss: 2.105313995833038

Epoch: 5| Step: 3
Training loss: 2.0264525413513184
Validation loss: 2.1132467972334994

Epoch: 5| Step: 4
Training loss: 2.2600173950195312
Validation loss: 2.129555768864129

Epoch: 5| Step: 5
Training loss: 3.0117287635803223
Validation loss: 2.167726041168295

Epoch: 5| Step: 6
Training loss: 2.0747246742248535
Validation loss: 2.1749882749331895

Epoch: 5| Step: 7
Training loss: 2.7499136924743652
Validation loss: 2.1372452551318752

Epoch: 5| Step: 8
Training loss: 1.8323808908462524
Validation loss: 2.1326997177575224

Epoch: 5| Step: 9
Training loss: 1.8958399295806885
Validation loss: 2.119869342414282

Epoch: 5| Step: 10
Training loss: 2.2730772495269775
Validation loss: 2.112421712567729

Epoch: 107| Step: 0
Training loss: 2.1225972175598145
Validation loss: 2.1043460112746044

Epoch: 5| Step: 1
Training loss: 2.1496288776397705
Validation loss: 2.123398880804739

Epoch: 5| Step: 2
Training loss: 2.172708034515381
Validation loss: 2.1299111291926396

Epoch: 5| Step: 3
Training loss: 2.607513904571533
Validation loss: 2.171586872428976

Epoch: 5| Step: 4
Training loss: 2.1949305534362793
Validation loss: 2.2134151663831485

Epoch: 5| Step: 5
Training loss: 2.505176067352295
Validation loss: 2.2345898382125364

Epoch: 5| Step: 6
Training loss: 2.5535759925842285
Validation loss: 2.233895017254737

Epoch: 5| Step: 7
Training loss: 2.3793253898620605
Validation loss: 2.20761509736379

Epoch: 5| Step: 8
Training loss: 2.2521162033081055
Validation loss: 2.164108399421938

Epoch: 5| Step: 9
Training loss: 2.1571145057678223
Validation loss: 2.1328631575389574

Epoch: 5| Step: 10
Training loss: 1.5838022232055664
Validation loss: 2.1008470430169055

Epoch: 108| Step: 0
Training loss: 2.3759078979492188
Validation loss: 2.0909642660489647

Epoch: 5| Step: 1
Training loss: 2.4126944541931152
Validation loss: 2.085924643342213

Epoch: 5| Step: 2
Training loss: 2.017587184906006
Validation loss: 2.0902598750206733

Epoch: 5| Step: 3
Training loss: 2.4352800846099854
Validation loss: 2.127423988875522

Epoch: 5| Step: 4
Training loss: 1.8193285465240479
Validation loss: 2.1790274497001403

Epoch: 5| Step: 5
Training loss: 2.286370277404785
Validation loss: 2.1923080439208658

Epoch: 5| Step: 6
Training loss: 2.7998573780059814
Validation loss: 2.159724170161832

Epoch: 5| Step: 7
Training loss: 1.940218210220337
Validation loss: 2.126496655966646

Epoch: 5| Step: 8
Training loss: 2.286869525909424
Validation loss: 2.106047494437105

Epoch: 5| Step: 9
Training loss: 1.758959174156189
Validation loss: 2.1059854312609603

Epoch: 5| Step: 10
Training loss: 2.624763011932373
Validation loss: 2.0940307160859466

Epoch: 109| Step: 0
Training loss: 1.9321937561035156
Validation loss: 2.1075675615700344

Epoch: 5| Step: 1
Training loss: 2.8293354511260986
Validation loss: 2.160112952673307

Epoch: 5| Step: 2
Training loss: 2.0130841732025146
Validation loss: 2.185612909255489

Epoch: 5| Step: 3
Training loss: 2.153505802154541
Validation loss: 2.1714294238757064

Epoch: 5| Step: 4
Training loss: 2.076873779296875
Validation loss: 2.152382594282909

Epoch: 5| Step: 5
Training loss: 1.8184953927993774
Validation loss: 2.126851720194663

Epoch: 5| Step: 6
Training loss: 3.0179450511932373
Validation loss: 2.129175314339258

Epoch: 5| Step: 7
Training loss: 2.07413649559021
Validation loss: 2.1294422149658203

Epoch: 5| Step: 8
Training loss: 1.7859516143798828
Validation loss: 2.124087390079293

Epoch: 5| Step: 9
Training loss: 2.5215091705322266
Validation loss: 2.101005527280992

Epoch: 5| Step: 10
Training loss: 2.013026714324951
Validation loss: 2.104297689212266

Epoch: 110| Step: 0
Training loss: 1.8801122903823853
Validation loss: 2.102946901834139

Epoch: 5| Step: 1
Training loss: 2.584700584411621
Validation loss: 2.133066174804523

Epoch: 5| Step: 2
Training loss: 1.8956317901611328
Validation loss: 2.162441881754065

Epoch: 5| Step: 3
Training loss: 1.9207347631454468
Validation loss: 2.1877597903692596

Epoch: 5| Step: 4
Training loss: 1.9726505279541016
Validation loss: 2.207677266931021

Epoch: 5| Step: 5
Training loss: 2.2435812950134277
Validation loss: 2.240247534167382

Epoch: 5| Step: 6
Training loss: 2.581799268722534
Validation loss: 2.218914193491782

Epoch: 5| Step: 7
Training loss: 2.7882213592529297
Validation loss: 2.1819720550249984

Epoch: 5| Step: 8
Training loss: 2.4943041801452637
Validation loss: 2.1232592444266043

Epoch: 5| Step: 9
Training loss: 2.1839449405670166
Validation loss: 2.0910503031105123

Epoch: 5| Step: 10
Training loss: 1.5655924081802368
Validation loss: 2.089974528999739

Epoch: 111| Step: 0
Training loss: 2.950535535812378
Validation loss: 2.074055851146739

Epoch: 5| Step: 1
Training loss: 1.7232364416122437
Validation loss: 2.0832761231289116

Epoch: 5| Step: 2
Training loss: 1.6840133666992188
Validation loss: 2.0739011867071993

Epoch: 5| Step: 3
Training loss: 2.646395206451416
Validation loss: 2.1099462419427852

Epoch: 5| Step: 4
Training loss: 1.8792879581451416
Validation loss: 2.1219950183745353

Epoch: 5| Step: 5
Training loss: 2.176304340362549
Validation loss: 2.146739508516045

Epoch: 5| Step: 6
Training loss: 1.9635257720947266
Validation loss: 2.1853106842246106

Epoch: 5| Step: 7
Training loss: 2.69301700592041
Validation loss: 2.19736490326543

Epoch: 5| Step: 8
Training loss: 1.8794047832489014
Validation loss: 2.206300590627937

Epoch: 5| Step: 9
Training loss: 2.3404037952423096
Validation loss: 2.1971127448543424

Epoch: 5| Step: 10
Training loss: 2.322626829147339
Validation loss: 2.159427609494937

Epoch: 112| Step: 0
Training loss: 2.2054429054260254
Validation loss: 2.1675945738310456

Epoch: 5| Step: 1
Training loss: 1.9532581567764282
Validation loss: 2.140600417249946

Epoch: 5| Step: 2
Training loss: 1.867456078529358
Validation loss: 2.132051811423353

Epoch: 5| Step: 3
Training loss: 2.32934832572937
Validation loss: 2.1278594040101573

Epoch: 5| Step: 4
Training loss: 1.8371412754058838
Validation loss: 2.097779300905043

Epoch: 5| Step: 5
Training loss: 2.303910970687866
Validation loss: 2.0957685760272446

Epoch: 5| Step: 6
Training loss: 2.421273946762085
Validation loss: 2.1055328256340435

Epoch: 5| Step: 7
Training loss: 1.824196219444275
Validation loss: 2.121765552028533

Epoch: 5| Step: 8
Training loss: 2.458392858505249
Validation loss: 2.157195455284529

Epoch: 5| Step: 9
Training loss: 2.297396183013916
Validation loss: 2.189978189365838

Epoch: 5| Step: 10
Training loss: 2.5695817470550537
Validation loss: 2.209246253454557

Epoch: 113| Step: 0
Training loss: 2.0958471298217773
Validation loss: 2.158423957004342

Epoch: 5| Step: 1
Training loss: 1.9470418691635132
Validation loss: 2.129097932128496

Epoch: 5| Step: 2
Training loss: 2.709815502166748
Validation loss: 2.1004997209836076

Epoch: 5| Step: 3
Training loss: 1.67255437374115
Validation loss: 2.0943447902638423

Epoch: 5| Step: 4
Training loss: 2.2255587577819824
Validation loss: 2.087703086996591

Epoch: 5| Step: 5
Training loss: 2.3266780376434326
Validation loss: 2.10435438412492

Epoch: 5| Step: 6
Training loss: 2.037682056427002
Validation loss: 2.1314842547139814

Epoch: 5| Step: 7
Training loss: 2.2501609325408936
Validation loss: 2.1517892191486974

Epoch: 5| Step: 8
Training loss: 1.8969770669937134
Validation loss: 2.1502566440131075

Epoch: 5| Step: 9
Training loss: 2.231656074523926
Validation loss: 2.179107114832888

Epoch: 5| Step: 10
Training loss: 2.4218673706054688
Validation loss: 2.1811215582714287

Epoch: 114| Step: 0
Training loss: 1.8396708965301514
Validation loss: 2.1797412313440794

Epoch: 5| Step: 1
Training loss: 2.0371947288513184
Validation loss: 2.127237291746242

Epoch: 5| Step: 2
Training loss: 2.423788070678711
Validation loss: 2.074704090754191

Epoch: 5| Step: 3
Training loss: 1.4521684646606445
Validation loss: 2.052653463937903

Epoch: 5| Step: 4
Training loss: 2.0091352462768555
Validation loss: 2.0564349159117667

Epoch: 5| Step: 5
Training loss: 2.4359874725341797
Validation loss: 2.0501978884461107

Epoch: 5| Step: 6
Training loss: 2.1283018589019775
Validation loss: 2.0591404771292083

Epoch: 5| Step: 7
Training loss: 3.1923935413360596
Validation loss: 2.0686673169494956

Epoch: 5| Step: 8
Training loss: 2.3937792778015137
Validation loss: 2.0798289686120968

Epoch: 5| Step: 9
Training loss: 2.1334898471832275
Validation loss: 2.110807908478604

Epoch: 5| Step: 10
Training loss: 1.7285349369049072
Validation loss: 2.1092436928902902

Epoch: 115| Step: 0
Training loss: 2.8437352180480957
Validation loss: 2.1238883387657905

Epoch: 5| Step: 1
Training loss: 1.9444446563720703
Validation loss: 2.125331614607124

Epoch: 5| Step: 2
Training loss: 2.065004348754883
Validation loss: 2.1255073598636094

Epoch: 5| Step: 3
Training loss: 2.04300594329834
Validation loss: 2.12095820519232

Epoch: 5| Step: 4
Training loss: 2.712185859680176
Validation loss: 2.103936513264974

Epoch: 5| Step: 5
Training loss: 2.46562123298645
Validation loss: 2.10378957563831

Epoch: 5| Step: 6
Training loss: 1.46430242061615
Validation loss: 2.089915055100636

Epoch: 5| Step: 7
Training loss: 1.0555871725082397
Validation loss: 2.0989643783979517

Epoch: 5| Step: 8
Training loss: 2.0172269344329834
Validation loss: 2.1216907462766095

Epoch: 5| Step: 9
Training loss: 2.8336405754089355
Validation loss: 2.110306737243488

Epoch: 5| Step: 10
Training loss: 2.0374817848205566
Validation loss: 2.158401402094031

Epoch: 116| Step: 0
Training loss: 2.3010315895080566
Validation loss: 2.175484347087081

Epoch: 5| Step: 1
Training loss: 1.4204715490341187
Validation loss: 2.1766882942568873

Epoch: 5| Step: 2
Training loss: 1.8595974445343018
Validation loss: 2.1774096347952403

Epoch: 5| Step: 3
Training loss: 2.134690046310425
Validation loss: 2.1560388713754635

Epoch: 5| Step: 4
Training loss: 2.3278093338012695
Validation loss: 2.118341258777085

Epoch: 5| Step: 5
Training loss: 2.2133166790008545
Validation loss: 2.0993465223620014

Epoch: 5| Step: 6
Training loss: 1.7766401767730713
Validation loss: 2.0559833101046983

Epoch: 5| Step: 7
Training loss: 2.695453643798828
Validation loss: 2.0448721454989527

Epoch: 5| Step: 8
Training loss: 2.0345287322998047
Validation loss: 2.0320025938813404

Epoch: 5| Step: 9
Training loss: 2.425313949584961
Validation loss: 2.0387001396507345

Epoch: 5| Step: 10
Training loss: 2.13224196434021
Validation loss: 2.048238656854117

Epoch: 117| Step: 0
Training loss: 1.9859699010849
Validation loss: 2.0750269787285918

Epoch: 5| Step: 1
Training loss: 2.054422378540039
Validation loss: 2.080582854568317

Epoch: 5| Step: 2
Training loss: 0.9626005291938782
Validation loss: 2.129295833649174

Epoch: 5| Step: 3
Training loss: 2.085528612136841
Validation loss: 2.131128239375289

Epoch: 5| Step: 4
Training loss: 1.9239575862884521
Validation loss: 2.134157306404524

Epoch: 5| Step: 5
Training loss: 2.4785475730895996
Validation loss: 2.117653073803071

Epoch: 5| Step: 6
Training loss: 2.352396011352539
Validation loss: 2.1034606349083687

Epoch: 5| Step: 7
Training loss: 2.13926362991333
Validation loss: 2.1102411208614225

Epoch: 5| Step: 8
Training loss: 2.7963802814483643
Validation loss: 2.1022993941460886

Epoch: 5| Step: 9
Training loss: 2.224994659423828
Validation loss: 2.078270596842612

Epoch: 5| Step: 10
Training loss: 1.9200035333633423
Validation loss: 2.082916813512002

Epoch: 118| Step: 0
Training loss: 2.3736109733581543
Validation loss: 2.062144484571231

Epoch: 5| Step: 1
Training loss: 1.4831840991973877
Validation loss: 2.05546131185306

Epoch: 5| Step: 2
Training loss: 2.5420784950256348
Validation loss: 2.070766327201679

Epoch: 5| Step: 3
Training loss: 2.4229180812835693
Validation loss: 2.1126173080936557

Epoch: 5| Step: 4
Training loss: 1.9331767559051514
Validation loss: 2.139741407927646

Epoch: 5| Step: 5
Training loss: 2.419471025466919
Validation loss: 2.127483690938642

Epoch: 5| Step: 6
Training loss: 1.8698921203613281
Validation loss: 2.087868090598814

Epoch: 5| Step: 7
Training loss: 2.1872191429138184
Validation loss: 2.075201142218805

Epoch: 5| Step: 8
Training loss: 1.7042251825332642
Validation loss: 2.0777542924368255

Epoch: 5| Step: 9
Training loss: 1.8777391910552979
Validation loss: 2.069254377836822

Epoch: 5| Step: 10
Training loss: 2.5512259006500244
Validation loss: 2.0621420132216586

Epoch: 119| Step: 0
Training loss: 2.051270008087158
Validation loss: 2.0547463714435534

Epoch: 5| Step: 1
Training loss: 2.282503366470337
Validation loss: 2.086900880259852

Epoch: 5| Step: 2
Training loss: 2.3251793384552
Validation loss: 2.0972833325785976

Epoch: 5| Step: 3
Training loss: 2.006674289703369
Validation loss: 2.1093614447501396

Epoch: 5| Step: 4
Training loss: 2.131896734237671
Validation loss: 2.12924450443637

Epoch: 5| Step: 5
Training loss: 2.580059766769409
Validation loss: 2.134009386903496

Epoch: 5| Step: 6
Training loss: 1.8231481313705444
Validation loss: 2.1132759637730096

Epoch: 5| Step: 7
Training loss: 1.97494375705719
Validation loss: 2.1164750463219097

Epoch: 5| Step: 8
Training loss: 1.3221569061279297
Validation loss: 2.1442027963617796

Epoch: 5| Step: 9
Training loss: 1.6981029510498047
Validation loss: 2.13211424632739

Epoch: 5| Step: 10
Training loss: 2.8652255535125732
Validation loss: 2.0933329828323854

Epoch: 120| Step: 0
Training loss: 2.2003636360168457
Validation loss: 2.0894959780477707

Epoch: 5| Step: 1
Training loss: 1.9242830276489258
Validation loss: 2.062595186694976

Epoch: 5| Step: 2
Training loss: 1.5912554264068604
Validation loss: 2.054238744961318

Epoch: 5| Step: 3
Training loss: 2.1547837257385254
Validation loss: 2.0359854313635055

Epoch: 5| Step: 4
Training loss: 2.256190061569214
Validation loss: 2.046551545461019

Epoch: 5| Step: 5
Training loss: 1.887787103652954
Validation loss: 2.038026358491631

Epoch: 5| Step: 6
Training loss: 2.0443053245544434
Validation loss: 2.049350256560951

Epoch: 5| Step: 7
Training loss: 2.482534885406494
Validation loss: 2.0794231135358094

Epoch: 5| Step: 8
Training loss: 2.2197346687316895
Validation loss: 2.1140836708007322

Epoch: 5| Step: 9
Training loss: 1.5980817079544067
Validation loss: 2.1285686249374063

Epoch: 5| Step: 10
Training loss: 2.363772392272949
Validation loss: 2.1277151748698246

Epoch: 121| Step: 0
Training loss: 2.13511323928833
Validation loss: 2.12900012282915

Epoch: 5| Step: 1
Training loss: 2.13565993309021
Validation loss: 2.1457576238980858

Epoch: 5| Step: 2
Training loss: 1.353140950202942
Validation loss: 2.1461123010163665

Epoch: 5| Step: 3
Training loss: 2.2175052165985107
Validation loss: 2.1085700091495307

Epoch: 5| Step: 4
Training loss: 1.9961761236190796
Validation loss: 2.091184610961586

Epoch: 5| Step: 5
Training loss: 1.9195142984390259
Validation loss: 2.095000704129537

Epoch: 5| Step: 6
Training loss: 2.675955057144165
Validation loss: 2.09309450785319

Epoch: 5| Step: 7
Training loss: 2.120154857635498
Validation loss: 2.081110321065431

Epoch: 5| Step: 8
Training loss: 2.3264553546905518
Validation loss: 2.073460546872949

Epoch: 5| Step: 9
Training loss: 1.9564988613128662
Validation loss: 2.079329252243042

Epoch: 5| Step: 10
Training loss: 1.5921114683151245
Validation loss: 2.0735948213966946

Epoch: 122| Step: 0
Training loss: 2.917076826095581
Validation loss: 2.0973654690609185

Epoch: 5| Step: 1
Training loss: 1.79228937625885
Validation loss: 2.0893474214820453

Epoch: 5| Step: 2
Training loss: 2.2764739990234375
Validation loss: 2.1137949753833074

Epoch: 5| Step: 3
Training loss: 2.0361788272857666
Validation loss: 2.1210386676173054

Epoch: 5| Step: 4
Training loss: 1.7099952697753906
Validation loss: 2.1047146230615597

Epoch: 5| Step: 5
Training loss: 2.605182409286499
Validation loss: 2.084678953693759

Epoch: 5| Step: 6
Training loss: 1.6811058521270752
Validation loss: 2.0712288451451126

Epoch: 5| Step: 7
Training loss: 1.9013183116912842
Validation loss: 2.0525142608150357

Epoch: 5| Step: 8
Training loss: 2.0215163230895996
Validation loss: 2.073188139546302

Epoch: 5| Step: 9
Training loss: 1.9151487350463867
Validation loss: 2.0812973463407127

Epoch: 5| Step: 10
Training loss: 1.251461148262024
Validation loss: 2.0879197120666504

Epoch: 123| Step: 0
Training loss: 2.0533432960510254
Validation loss: 2.124434260911839

Epoch: 5| Step: 1
Training loss: 1.699620246887207
Validation loss: 2.115668084031792

Epoch: 5| Step: 2
Training loss: 1.7947123050689697
Validation loss: 2.118242194575648

Epoch: 5| Step: 3
Training loss: 2.09938383102417
Validation loss: 2.1063595587207424

Epoch: 5| Step: 4
Training loss: 1.8337419033050537
Validation loss: 2.078114176309237

Epoch: 5| Step: 5
Training loss: 1.7450950145721436
Validation loss: 2.0654076324996127

Epoch: 5| Step: 6
Training loss: 2.0861313343048096
Validation loss: 2.043281234720702

Epoch: 5| Step: 7
Training loss: 2.4717142581939697
Validation loss: 2.0405950238627772

Epoch: 5| Step: 8
Training loss: 1.9116203784942627
Validation loss: 2.0368465787620953

Epoch: 5| Step: 9
Training loss: 2.7542545795440674
Validation loss: 2.0458673943755445

Epoch: 5| Step: 10
Training loss: 1.7364985942840576
Validation loss: 2.075323453513525

Epoch: 124| Step: 0
Training loss: 1.6652599573135376
Validation loss: 2.0977259758980042

Epoch: 5| Step: 1
Training loss: 1.8980419635772705
Validation loss: 2.0773970619324715

Epoch: 5| Step: 2
Training loss: 2.5568766593933105
Validation loss: 2.0602399764522428

Epoch: 5| Step: 3
Training loss: 1.7209808826446533
Validation loss: 2.0567392559461695

Epoch: 5| Step: 4
Training loss: 2.115123748779297
Validation loss: 2.0533288947997557

Epoch: 5| Step: 5
Training loss: 1.7514997720718384
Validation loss: 2.0782017823188537

Epoch: 5| Step: 6
Training loss: 1.9513791799545288
Validation loss: 2.0949855337860765

Epoch: 5| Step: 7
Training loss: 1.5797356367111206
Validation loss: 2.152659687944638

Epoch: 5| Step: 8
Training loss: 2.125103235244751
Validation loss: 2.2293786874381443

Epoch: 5| Step: 9
Training loss: 2.536940574645996
Validation loss: 2.2514793065286454

Epoch: 5| Step: 10
Training loss: 2.6550896167755127
Validation loss: 2.2684235700996975

Epoch: 125| Step: 0
Training loss: 1.7262948751449585
Validation loss: 2.2524227621734783

Epoch: 5| Step: 1
Training loss: 2.315814733505249
Validation loss: 2.1883065418530534

Epoch: 5| Step: 2
Training loss: 2.2413864135742188
Validation loss: 2.122161465306436

Epoch: 5| Step: 3
Training loss: 2.6833443641662598
Validation loss: 2.0580651683192097

Epoch: 5| Step: 4
Training loss: 1.8540042638778687
Validation loss: 2.0291896840577484

Epoch: 5| Step: 5
Training loss: 2.2445571422576904
Validation loss: 2.0383710297205115

Epoch: 5| Step: 6
Training loss: 1.9517953395843506
Validation loss: 2.009989002699493

Epoch: 5| Step: 7
Training loss: 2.082765817642212
Validation loss: 2.0187432086595924

Epoch: 5| Step: 8
Training loss: 2.090885639190674
Validation loss: 2.0187147560939995

Epoch: 5| Step: 9
Training loss: 1.708997368812561
Validation loss: 2.023977284790367

Epoch: 5| Step: 10
Training loss: 2.015756607055664
Validation loss: 2.045711140478811

Epoch: 126| Step: 0
Training loss: 2.091076135635376
Validation loss: 2.097412009393015

Epoch: 5| Step: 1
Training loss: 2.544752359390259
Validation loss: 2.1364245940280218

Epoch: 5| Step: 2
Training loss: 2.0898444652557373
Validation loss: 2.158731614389727

Epoch: 5| Step: 3
Training loss: 2.146777391433716
Validation loss: 2.177268671733077

Epoch: 5| Step: 4
Training loss: 1.7785342931747437
Validation loss: 2.1394108828677925

Epoch: 5| Step: 5
Training loss: 2.3484034538269043
Validation loss: 2.1094308130202757

Epoch: 5| Step: 6
Training loss: 1.5864083766937256
Validation loss: 2.0824407351914274

Epoch: 5| Step: 7
Training loss: 1.7580302953720093
Validation loss: 2.0423847142086236

Epoch: 5| Step: 8
Training loss: 1.8582684993743896
Validation loss: 2.0379555712464037

Epoch: 5| Step: 9
Training loss: 1.7696411609649658
Validation loss: 2.0372157763409358

Epoch: 5| Step: 10
Training loss: 2.674173355102539
Validation loss: 2.059865818228773

Epoch: 127| Step: 0
Training loss: 2.5327892303466797
Validation loss: 2.0559959975622033

Epoch: 5| Step: 1
Training loss: 2.209979295730591
Validation loss: 2.0655296566665813

Epoch: 5| Step: 2
Training loss: 1.827897071838379
Validation loss: 2.0703285560813

Epoch: 5| Step: 3
Training loss: 2.271165370941162
Validation loss: 2.0809632168021253

Epoch: 5| Step: 4
Training loss: 2.4350943565368652
Validation loss: 2.096954922522268

Epoch: 5| Step: 5
Training loss: 2.779277801513672
Validation loss: 2.110518478578137

Epoch: 5| Step: 6
Training loss: 1.7745387554168701
Validation loss: 2.103022006250197

Epoch: 5| Step: 7
Training loss: 1.2695392370224
Validation loss: 2.088084679777904

Epoch: 5| Step: 8
Training loss: 2.079436779022217
Validation loss: 2.074928213191289

Epoch: 5| Step: 9
Training loss: 1.7046905755996704
Validation loss: 2.068031061080194

Epoch: 5| Step: 10
Training loss: 1.0070419311523438
Validation loss: 2.0681073434891237

Epoch: 128| Step: 0
Training loss: 2.1232008934020996
Validation loss: 2.0434821164736183

Epoch: 5| Step: 1
Training loss: 2.308335065841675
Validation loss: 2.0343213901724866

Epoch: 5| Step: 2
Training loss: 2.2677600383758545
Validation loss: 2.0228884912306264

Epoch: 5| Step: 3
Training loss: 1.9367777109146118
Validation loss: 2.0102208609222085

Epoch: 5| Step: 4
Training loss: 2.1951961517333984
Validation loss: 2.0265553779499506

Epoch: 5| Step: 5
Training loss: 1.8755699396133423
Validation loss: 2.0172023286101637

Epoch: 5| Step: 6
Training loss: 1.7103900909423828
Validation loss: 2.0694279798897366

Epoch: 5| Step: 7
Training loss: 1.5901767015457153
Validation loss: 2.1340251174024356

Epoch: 5| Step: 8
Training loss: 2.0368411540985107
Validation loss: 2.174172527046614

Epoch: 5| Step: 9
Training loss: 1.7433078289031982
Validation loss: 2.187480306112638

Epoch: 5| Step: 10
Training loss: 2.575071334838867
Validation loss: 2.1651332788569952

Epoch: 129| Step: 0
Training loss: 1.5468738079071045
Validation loss: 2.1176327274691675

Epoch: 5| Step: 1
Training loss: 2.068821668624878
Validation loss: 2.074244104405885

Epoch: 5| Step: 2
Training loss: 2.543976068496704
Validation loss: 2.050760169183054

Epoch: 5| Step: 3
Training loss: 1.8432585000991821
Validation loss: 2.0530758160416798

Epoch: 5| Step: 4
Training loss: 1.6817528009414673
Validation loss: 2.057671252117362

Epoch: 5| Step: 5
Training loss: 2.5047824382781982
Validation loss: 2.0400816291891117

Epoch: 5| Step: 6
Training loss: 1.5661208629608154
Validation loss: 2.0418097139686666

Epoch: 5| Step: 7
Training loss: 2.10929799079895
Validation loss: 2.07166669061107

Epoch: 5| Step: 8
Training loss: 1.9896104335784912
Validation loss: 2.1027426027482554

Epoch: 5| Step: 9
Training loss: 2.3450093269348145
Validation loss: 2.1200656493504844

Epoch: 5| Step: 10
Training loss: 1.7219526767730713
Validation loss: 2.1051561370972665

Epoch: 130| Step: 0
Training loss: 1.993666410446167
Validation loss: 2.091220227620935

Epoch: 5| Step: 1
Training loss: 1.9032037258148193
Validation loss: 2.0695471020155054

Epoch: 5| Step: 2
Training loss: 2.828122854232788
Validation loss: 2.0480190092517483

Epoch: 5| Step: 3
Training loss: 1.7821826934814453
Validation loss: 2.034100542786301

Epoch: 5| Step: 4
Training loss: 1.4790185689926147
Validation loss: 2.04655264013557

Epoch: 5| Step: 5
Training loss: 2.0484321117401123
Validation loss: 2.046849094411378

Epoch: 5| Step: 6
Training loss: 2.075120210647583
Validation loss: 2.0518689719579553

Epoch: 5| Step: 7
Training loss: 1.4554330110549927
Validation loss: 2.0456581269541094

Epoch: 5| Step: 8
Training loss: 2.555830478668213
Validation loss: 2.0643373612434632

Epoch: 5| Step: 9
Training loss: 1.9877971410751343
Validation loss: 2.113748336351046

Epoch: 5| Step: 10
Training loss: 1.6637953519821167
Validation loss: 2.1298454705105034

Epoch: 131| Step: 0
Training loss: 1.629338026046753
Validation loss: 2.133449295515655

Epoch: 5| Step: 1
Training loss: 2.221290111541748
Validation loss: 2.1149962922578216

Epoch: 5| Step: 2
Training loss: 1.785146713256836
Validation loss: 2.0848856113290273

Epoch: 5| Step: 3
Training loss: 2.6126205921173096
Validation loss: 2.0516674236584733

Epoch: 5| Step: 4
Training loss: 1.802166223526001
Validation loss: 2.044673574868069

Epoch: 5| Step: 5
Training loss: 2.279822587966919
Validation loss: 2.020629208575013

Epoch: 5| Step: 6
Training loss: 2.090355396270752
Validation loss: 2.035233241255565

Epoch: 5| Step: 7
Training loss: 1.8350059986114502
Validation loss: 2.0104167307576826

Epoch: 5| Step: 8
Training loss: 1.8754081726074219
Validation loss: 2.0110582408084663

Epoch: 5| Step: 9
Training loss: 2.039973497390747
Validation loss: 2.0226262679664035

Epoch: 5| Step: 10
Training loss: 1.641889214515686
Validation loss: 2.038298585081613

Epoch: 132| Step: 0
Training loss: 2.5653738975524902
Validation loss: 2.0938343335223455

Epoch: 5| Step: 1
Training loss: 1.8515806198120117
Validation loss: 2.1298751061962498

Epoch: 5| Step: 2
Training loss: 2.2749640941619873
Validation loss: 2.14387119841832

Epoch: 5| Step: 3
Training loss: 1.691014289855957
Validation loss: 2.1309320388301725

Epoch: 5| Step: 4
Training loss: 1.669597864151001
Validation loss: 2.082146465137441

Epoch: 5| Step: 5
Training loss: 1.5294575691223145
Validation loss: 2.0495038840078537

Epoch: 5| Step: 6
Training loss: 1.6022911071777344
Validation loss: 2.0259439099219536

Epoch: 5| Step: 7
Training loss: 2.1078007221221924
Validation loss: 2.0380988761942875

Epoch: 5| Step: 8
Training loss: 1.6619030237197876
Validation loss: 2.0325492838377595

Epoch: 5| Step: 9
Training loss: 2.7844457626342773
Validation loss: 2.0449990944195817

Epoch: 5| Step: 10
Training loss: 2.0499608516693115
Validation loss: 2.067210228212418

Epoch: 133| Step: 0
Training loss: 1.5697898864746094
Validation loss: 2.0996605850035146

Epoch: 5| Step: 1
Training loss: 1.6362968683242798
Validation loss: 2.137511346929817

Epoch: 5| Step: 2
Training loss: 1.8482329845428467
Validation loss: 2.1778852734514462

Epoch: 5| Step: 3
Training loss: 1.930169701576233
Validation loss: 2.1853729730011313

Epoch: 5| Step: 4
Training loss: 2.4485273361206055
Validation loss: 2.1357242138155046

Epoch: 5| Step: 5
Training loss: 2.866171360015869
Validation loss: 2.0981146340729087

Epoch: 5| Step: 6
Training loss: 1.8099911212921143
Validation loss: 2.054600897655692

Epoch: 5| Step: 7
Training loss: 1.7371257543563843
Validation loss: 2.0214077990542174

Epoch: 5| Step: 8
Training loss: 2.0169758796691895
Validation loss: 2.016538184176209

Epoch: 5| Step: 9
Training loss: 1.7807207107543945
Validation loss: 2.0189930085212953

Epoch: 5| Step: 10
Training loss: 2.15537691116333
Validation loss: 2.0063475844680623

Epoch: 134| Step: 0
Training loss: 1.8980060815811157
Validation loss: 2.011823546501898

Epoch: 5| Step: 1
Training loss: 1.6079849004745483
Validation loss: 2.0132372481848604

Epoch: 5| Step: 2
Training loss: 1.889409065246582
Validation loss: 2.0458710603816535

Epoch: 5| Step: 3
Training loss: 2.008375883102417
Validation loss: 2.0993435100842546

Epoch: 5| Step: 4
Training loss: 2.523928165435791
Validation loss: 2.1607691113666823

Epoch: 5| Step: 5
Training loss: 2.200533628463745
Validation loss: 2.2153005523066365

Epoch: 5| Step: 6
Training loss: 2.489881992340088
Validation loss: 2.254826029141744

Epoch: 5| Step: 7
Training loss: 1.9650834798812866
Validation loss: 2.215656767609299

Epoch: 5| Step: 8
Training loss: 2.0030035972595215
Validation loss: 2.148223397552326

Epoch: 5| Step: 9
Training loss: 2.0935561656951904
Validation loss: 2.1490889659491916

Epoch: 5| Step: 10
Training loss: 1.7131179571151733
Validation loss: 2.166088463157736

Epoch: 135| Step: 0
Training loss: 2.3580245971679688
Validation loss: 2.1470364806472615

Epoch: 5| Step: 1
Training loss: 1.6747229099273682
Validation loss: 2.122165256930936

Epoch: 5| Step: 2
Training loss: 2.1086249351501465
Validation loss: 2.0632306247629146

Epoch: 5| Step: 3
Training loss: 2.3493025302886963
Validation loss: 2.0157018630735335

Epoch: 5| Step: 4
Training loss: 1.9643819332122803
Validation loss: 1.9925812944289176

Epoch: 5| Step: 5
Training loss: 1.8658885955810547
Validation loss: 1.9909515585950626

Epoch: 5| Step: 6
Training loss: 1.8224380016326904
Validation loss: 1.9757250970409763

Epoch: 5| Step: 7
Training loss: 2.2903289794921875
Validation loss: 1.9949411269157165

Epoch: 5| Step: 8
Training loss: 1.8312747478485107
Validation loss: 2.0271597267479025

Epoch: 5| Step: 9
Training loss: 2.0851147174835205
Validation loss: 2.09311508106929

Epoch: 5| Step: 10
Training loss: 1.991093635559082
Validation loss: 2.1509020636158604

Epoch: 136| Step: 0
Training loss: 1.5833131074905396
Validation loss: 2.166166836215604

Epoch: 5| Step: 1
Training loss: 2.2964866161346436
Validation loss: 2.1299722297217256

Epoch: 5| Step: 2
Training loss: 1.8958097696304321
Validation loss: 2.130602705863214

Epoch: 5| Step: 3
Training loss: 2.295879364013672
Validation loss: 2.1112511439989974

Epoch: 5| Step: 4
Training loss: 1.5901081562042236
Validation loss: 2.111743715501601

Epoch: 5| Step: 5
Training loss: 1.957720160484314
Validation loss: 2.111683625046925

Epoch: 5| Step: 6
Training loss: 1.7382490634918213
Validation loss: 2.095835014056134

Epoch: 5| Step: 7
Training loss: 2.2411396503448486
Validation loss: 2.077574622246527

Epoch: 5| Step: 8
Training loss: 1.7824041843414307
Validation loss: 2.0527168050889046

Epoch: 5| Step: 9
Training loss: 1.7104383707046509
Validation loss: 2.032559656327771

Epoch: 5| Step: 10
Training loss: 2.2900638580322266
Validation loss: 2.045933190212455

Epoch: 137| Step: 0
Training loss: 1.4754747152328491
Validation loss: 2.0265960924087034

Epoch: 5| Step: 1
Training loss: 2.1239285469055176
Validation loss: 2.026707926104146

Epoch: 5| Step: 2
Training loss: 1.8696705102920532
Validation loss: 2.0315416397586947

Epoch: 5| Step: 3
Training loss: 2.1928954124450684
Validation loss: 2.037326432043506

Epoch: 5| Step: 4
Training loss: 1.371110200881958
Validation loss: 2.0407140665156867

Epoch: 5| Step: 5
Training loss: 1.7440135478973389
Validation loss: 2.059294085348806

Epoch: 5| Step: 6
Training loss: 2.5820467472076416
Validation loss: 2.08109531094951

Epoch: 5| Step: 7
Training loss: 2.0437915325164795
Validation loss: 2.0747658334752566

Epoch: 5| Step: 8
Training loss: 1.6962594985961914
Validation loss: 2.063425667824284

Epoch: 5| Step: 9
Training loss: 1.8664629459381104
Validation loss: 2.061880862841042

Epoch: 5| Step: 10
Training loss: 2.1275627613067627
Validation loss: 2.0405249646914903

Epoch: 138| Step: 0
Training loss: 2.13008189201355
Validation loss: 2.0539426137042303

Epoch: 5| Step: 1
Training loss: 1.4045168161392212
Validation loss: 2.0537445981015443

Epoch: 5| Step: 2
Training loss: 1.4542393684387207
Validation loss: 2.0802186842887633

Epoch: 5| Step: 3
Training loss: 2.134580135345459
Validation loss: 2.0808401056515273

Epoch: 5| Step: 4
Training loss: 2.3559324741363525
Validation loss: 2.096259965691515

Epoch: 5| Step: 5
Training loss: 1.9099193811416626
Validation loss: 2.114116232882264

Epoch: 5| Step: 6
Training loss: 1.9070675373077393
Validation loss: 2.1236957939722205

Epoch: 5| Step: 7
Training loss: 1.9577096700668335
Validation loss: 2.1168373759074877

Epoch: 5| Step: 8
Training loss: 2.7335212230682373
Validation loss: 2.0815604027881416

Epoch: 5| Step: 9
Training loss: 1.548304557800293
Validation loss: 2.0377727272689983

Epoch: 5| Step: 10
Training loss: 1.4003173112869263
Validation loss: 2.026074976049444

Epoch: 139| Step: 0
Training loss: 1.4018669128417969
Validation loss: 2.008223536194012

Epoch: 5| Step: 1
Training loss: 1.9649488925933838
Validation loss: 2.0029025359820296

Epoch: 5| Step: 2
Training loss: 1.7084996700286865
Validation loss: 2.013170571737392

Epoch: 5| Step: 3
Training loss: 2.2744550704956055
Validation loss: 2.022337149548274

Epoch: 5| Step: 4
Training loss: 2.3609566688537598
Validation loss: 2.054833681352677

Epoch: 5| Step: 5
Training loss: 1.6872764825820923
Validation loss: 2.0565881113852225

Epoch: 5| Step: 6
Training loss: 1.3252067565917969
Validation loss: 2.0843238625475156

Epoch: 5| Step: 7
Training loss: 2.338667392730713
Validation loss: 2.113211154937744

Epoch: 5| Step: 8
Training loss: 1.8995879888534546
Validation loss: 2.142466360522855

Epoch: 5| Step: 9
Training loss: 1.9044862985610962
Validation loss: 2.148544111559468

Epoch: 5| Step: 10
Training loss: 2.2073869705200195
Validation loss: 2.1256672387482016

Epoch: 140| Step: 0
Training loss: 2.2328619956970215
Validation loss: 2.113038429649927

Epoch: 5| Step: 1
Training loss: 1.6865705251693726
Validation loss: 2.105062800069009

Epoch: 5| Step: 2
Training loss: 1.9285579919815063
Validation loss: 2.116720579003775

Epoch: 5| Step: 3
Training loss: 2.358328342437744
Validation loss: 2.0838859773451284

Epoch: 5| Step: 4
Training loss: 2.127870559692383
Validation loss: 2.040885991947625

Epoch: 5| Step: 5
Training loss: 1.7716783285140991
Validation loss: 2.0294733906304963

Epoch: 5| Step: 6
Training loss: 1.4852638244628906
Validation loss: 2.0237048902819232

Epoch: 5| Step: 7
Training loss: 1.6430352926254272
Validation loss: 2.0197971008157216

Epoch: 5| Step: 8
Training loss: 1.4618675708770752
Validation loss: 2.022331945357784

Epoch: 5| Step: 9
Training loss: 2.1673178672790527
Validation loss: 2.0219700874820834

Epoch: 5| Step: 10
Training loss: 1.7768735885620117
Validation loss: 2.0240480002536567

Epoch: 141| Step: 0
Training loss: 1.281923532485962
Validation loss: 2.026071471552695

Epoch: 5| Step: 1
Training loss: 2.0056967735290527
Validation loss: 2.0562047099554412

Epoch: 5| Step: 2
Training loss: 1.7036283016204834
Validation loss: 2.0488443682270665

Epoch: 5| Step: 3
Training loss: 2.0040242671966553
Validation loss: 2.0650734875791814

Epoch: 5| Step: 4
Training loss: 2.2913601398468018
Validation loss: 2.0662174583763204

Epoch: 5| Step: 5
Training loss: 1.8502776622772217
Validation loss: 2.073231727846207

Epoch: 5| Step: 6
Training loss: 1.9170582294464111
Validation loss: 2.061300088000554

Epoch: 5| Step: 7
Training loss: 1.1779406070709229
Validation loss: 2.0501970526992634

Epoch: 5| Step: 8
Training loss: 2.1600141525268555
Validation loss: 2.037442816201077

Epoch: 5| Step: 9
Training loss: 2.184795379638672
Validation loss: 2.0180772184043803

Epoch: 5| Step: 10
Training loss: 2.1202290058135986
Validation loss: 2.029327943760862

Epoch: 142| Step: 0
Training loss: 2.32159686088562
Validation loss: 2.034361413730088

Epoch: 5| Step: 1
Training loss: 1.9752165079116821
Validation loss: 2.0290448896346556

Epoch: 5| Step: 2
Training loss: 2.022028684616089
Validation loss: 2.053899927805829

Epoch: 5| Step: 3
Training loss: 1.7619659900665283
Validation loss: 2.0431474511341383

Epoch: 5| Step: 4
Training loss: 1.6776580810546875
Validation loss: 2.073801504668369

Epoch: 5| Step: 5
Training loss: 1.828431487083435
Validation loss: 2.105008940542898

Epoch: 5| Step: 6
Training loss: 2.1029887199401855
Validation loss: 2.1178743429081415

Epoch: 5| Step: 7
Training loss: 1.759697675704956
Validation loss: 2.0982381195150395

Epoch: 5| Step: 8
Training loss: 1.6305615901947021
Validation loss: 2.1040911725772324

Epoch: 5| Step: 9
Training loss: 1.742958426475525
Validation loss: 2.0878075527888473

Epoch: 5| Step: 10
Training loss: 1.8719886541366577
Validation loss: 2.063279967154226

Epoch: 143| Step: 0
Training loss: 2.6541380882263184
Validation loss: 2.022082669760591

Epoch: 5| Step: 1
Training loss: 1.5434342622756958
Validation loss: 1.9939766750540784

Epoch: 5| Step: 2
Training loss: 1.8882554769515991
Validation loss: 2.0059558396698325

Epoch: 5| Step: 3
Training loss: 1.7728134393692017
Validation loss: 2.017418087169688

Epoch: 5| Step: 4
Training loss: 2.051978588104248
Validation loss: 2.049440460820352

Epoch: 5| Step: 5
Training loss: 1.4504201412200928
Validation loss: 2.0851159236764394

Epoch: 5| Step: 6
Training loss: 1.7814865112304688
Validation loss: 2.0938050952008975

Epoch: 5| Step: 7
Training loss: 1.8600791692733765
Validation loss: 2.058489002207274

Epoch: 5| Step: 8
Training loss: 1.3911453485488892
Validation loss: 2.0382158961347354

Epoch: 5| Step: 9
Training loss: 2.0338892936706543
Validation loss: 2.0147914553201325

Epoch: 5| Step: 10
Training loss: 2.1058669090270996
Validation loss: 1.9965108761223413

Epoch: 144| Step: 0
Training loss: 1.400943398475647
Validation loss: 1.9876209228269515

Epoch: 5| Step: 1
Training loss: 1.5243580341339111
Validation loss: 1.9667588472366333

Epoch: 5| Step: 2
Training loss: 2.1103947162628174
Validation loss: 1.9576851655078191

Epoch: 5| Step: 3
Training loss: 1.841052770614624
Validation loss: 1.975947577466247

Epoch: 5| Step: 4
Training loss: 1.9029045104980469
Validation loss: 1.9808542548969228

Epoch: 5| Step: 5
Training loss: 2.0914223194122314
Validation loss: 1.9811932079253658

Epoch: 5| Step: 6
Training loss: 2.283897638320923
Validation loss: 1.973908652541458

Epoch: 5| Step: 7
Training loss: 2.250169038772583
Validation loss: 1.9764384018477572

Epoch: 5| Step: 8
Training loss: 1.9775216579437256
Validation loss: 1.999154217781559

Epoch: 5| Step: 9
Training loss: 1.6563358306884766
Validation loss: 2.0042082763487294

Epoch: 5| Step: 10
Training loss: 1.3497536182403564
Validation loss: 2.039675627985308

Epoch: 145| Step: 0
Training loss: 2.243309259414673
Validation loss: 2.052046042616649

Epoch: 5| Step: 1
Training loss: 1.4785215854644775
Validation loss: 2.0564153373882337

Epoch: 5| Step: 2
Training loss: 2.12404465675354
Validation loss: 2.071264846350557

Epoch: 5| Step: 3
Training loss: 1.4047152996063232
Validation loss: 2.0702474168551865

Epoch: 5| Step: 4
Training loss: 2.1034083366394043
Validation loss: 2.0651176193709015

Epoch: 5| Step: 5
Training loss: 1.9269487857818604
Validation loss: 2.070882240931193

Epoch: 5| Step: 6
Training loss: 1.7222387790679932
Validation loss: 2.071471430922067

Epoch: 5| Step: 7
Training loss: 1.524036169052124
Validation loss: 2.048218939893989

Epoch: 5| Step: 8
Training loss: 1.8573211431503296
Validation loss: 2.042815628872123

Epoch: 5| Step: 9
Training loss: 1.4355533123016357
Validation loss: 2.0223941482523435

Epoch: 5| Step: 10
Training loss: 2.4025719165802
Validation loss: 2.0185426024980444

Epoch: 146| Step: 0
Training loss: 1.8252277374267578
Validation loss: 2.0050121866246706

Epoch: 5| Step: 1
Training loss: 1.3353841304779053
Validation loss: 1.986019540858525

Epoch: 5| Step: 2
Training loss: 1.9051389694213867
Validation loss: 2.004317710476537

Epoch: 5| Step: 3
Training loss: 1.6657607555389404
Validation loss: 2.0189038450999925

Epoch: 5| Step: 4
Training loss: 1.9748328924179077
Validation loss: 2.042172693437146

Epoch: 5| Step: 5
Training loss: 2.1027958393096924
Validation loss: 2.0400745073954263

Epoch: 5| Step: 6
Training loss: 1.792618751525879
Validation loss: 2.038369923509577

Epoch: 5| Step: 7
Training loss: 1.6347284317016602
Validation loss: 2.02695664282768

Epoch: 5| Step: 8
Training loss: 1.9103145599365234
Validation loss: 2.0053608827693488

Epoch: 5| Step: 9
Training loss: 1.3705388307571411
Validation loss: 2.020649548499815

Epoch: 5| Step: 10
Training loss: 2.7085485458374023
Validation loss: 2.030542009620256

Epoch: 147| Step: 0
Training loss: 1.7520275115966797
Validation loss: 2.0261837923398582

Epoch: 5| Step: 1
Training loss: 2.202538013458252
Validation loss: 2.042020341401459

Epoch: 5| Step: 2
Training loss: 1.8500322103500366
Validation loss: 2.0396998928439234

Epoch: 5| Step: 3
Training loss: 2.1398067474365234
Validation loss: 2.0607076742315806

Epoch: 5| Step: 4
Training loss: 1.5299972295761108
Validation loss: 2.0677158755640828

Epoch: 5| Step: 5
Training loss: 2.0188028812408447
Validation loss: 2.0668305940525507

Epoch: 5| Step: 6
Training loss: 2.3787670135498047
Validation loss: 2.1057650773755965

Epoch: 5| Step: 7
Training loss: 1.0870145559310913
Validation loss: 2.068038599465483

Epoch: 5| Step: 8
Training loss: 1.1768527030944824
Validation loss: 2.0275605955431537

Epoch: 5| Step: 9
Training loss: 1.5956329107284546
Validation loss: 2.016196853371077

Epoch: 5| Step: 10
Training loss: 2.1113317012786865
Validation loss: 2.0166449162267868

Epoch: 148| Step: 0
Training loss: 1.858994722366333
Validation loss: 2.0193917930767102

Epoch: 5| Step: 1
Training loss: 1.3841549158096313
Validation loss: 2.030672037473289

Epoch: 5| Step: 2
Training loss: 2.1824307441711426
Validation loss: 2.031867115728317

Epoch: 5| Step: 3
Training loss: 2.051424264907837
Validation loss: 2.044238959589312

Epoch: 5| Step: 4
Training loss: 2.018361806869507
Validation loss: 2.057663595804604

Epoch: 5| Step: 5
Training loss: 2.120591640472412
Validation loss: 2.037317996383995

Epoch: 5| Step: 6
Training loss: 1.268812894821167
Validation loss: 2.0082945618578183

Epoch: 5| Step: 7
Training loss: 1.4953172206878662
Validation loss: 1.9985361458152853

Epoch: 5| Step: 8
Training loss: 1.9652687311172485
Validation loss: 2.0086232410964144

Epoch: 5| Step: 9
Training loss: 1.5554825067520142
Validation loss: 2.03461169427441

Epoch: 5| Step: 10
Training loss: 2.0969502925872803
Validation loss: 2.062765549587947

Epoch: 149| Step: 0
Training loss: 1.877436876296997
Validation loss: 2.096677734005836

Epoch: 5| Step: 1
Training loss: 1.2954999208450317
Validation loss: 2.0993913168548257

Epoch: 5| Step: 2
Training loss: 2.211282968521118
Validation loss: 2.118264199585043

Epoch: 5| Step: 3
Training loss: 1.8637765645980835
Validation loss: 2.0843727588653564

Epoch: 5| Step: 4
Training loss: 2.0783653259277344
Validation loss: 2.051848965306436

Epoch: 5| Step: 5
Training loss: 1.239875316619873
Validation loss: 2.0345911774584042

Epoch: 5| Step: 6
Training loss: 2.5279734134674072
Validation loss: 2.004301978695777

Epoch: 5| Step: 7
Training loss: 1.5960391759872437
Validation loss: 1.9926592034678305

Epoch: 5| Step: 8
Training loss: 1.464569091796875
Validation loss: 1.995309345183834

Epoch: 5| Step: 9
Training loss: 1.518602728843689
Validation loss: 2.0084486161508868

Epoch: 5| Step: 10
Training loss: 2.148911714553833
Validation loss: 2.0069522242392264

Epoch: 150| Step: 0
Training loss: 2.3325793743133545
Validation loss: 2.029066301161243

Epoch: 5| Step: 1
Training loss: 1.9131824970245361
Validation loss: 2.032166641245606

Epoch: 5| Step: 2
Training loss: 1.719961166381836
Validation loss: 2.019335728819652

Epoch: 5| Step: 3
Training loss: 1.9818189144134521
Validation loss: 2.042710352969426

Epoch: 5| Step: 4
Training loss: 2.048649549484253
Validation loss: 2.071533167234031

Epoch: 5| Step: 5
Training loss: 1.9508987665176392
Validation loss: 2.10155031629788

Epoch: 5| Step: 6
Training loss: 1.5808892250061035
Validation loss: 2.1045755135115756

Epoch: 5| Step: 7
Training loss: 1.8831926584243774
Validation loss: 2.1291722405341362

Epoch: 5| Step: 8
Training loss: 1.4085947275161743
Validation loss: 2.1283760686074533

Epoch: 5| Step: 9
Training loss: 1.2917535305023193
Validation loss: 2.121514852328967

Epoch: 5| Step: 10
Training loss: 1.3328351974487305
Validation loss: 2.113005235630979

Epoch: 151| Step: 0
Training loss: 1.7022502422332764
Validation loss: 2.0876733103106098

Epoch: 5| Step: 1
Training loss: 2.286296844482422
Validation loss: 2.051045725422521

Epoch: 5| Step: 2
Training loss: 1.4782888889312744
Validation loss: 2.039481548852818

Epoch: 5| Step: 3
Training loss: 1.8426374197006226
Validation loss: 2.034218770201488

Epoch: 5| Step: 4
Training loss: 2.0056231021881104
Validation loss: 2.0499393619516844

Epoch: 5| Step: 5
Training loss: 2.030228614807129
Validation loss: 2.04797097175352

Epoch: 5| Step: 6
Training loss: 1.7134281396865845
Validation loss: 2.0399225078603274

Epoch: 5| Step: 7
Training loss: 1.906121015548706
Validation loss: 2.087077092098933

Epoch: 5| Step: 8
Training loss: 1.2945241928100586
Validation loss: 2.119380215162872

Epoch: 5| Step: 9
Training loss: 1.327041745185852
Validation loss: 2.161023942373132

Epoch: 5| Step: 10
Training loss: 1.7665796279907227
Validation loss: 2.172987384180869

Epoch: 152| Step: 0
Training loss: 1.7699270248413086
Validation loss: 2.2123016644549627

Epoch: 5| Step: 1
Training loss: 2.0397000312805176
Validation loss: 2.206332883527202

Epoch: 5| Step: 2
Training loss: 1.6351028680801392
Validation loss: 2.152584775801628

Epoch: 5| Step: 3
Training loss: 1.685140609741211
Validation loss: 2.121494790559174

Epoch: 5| Step: 4
Training loss: 1.8419373035430908
Validation loss: 2.0565999554049585

Epoch: 5| Step: 5
Training loss: 1.97531259059906
Validation loss: 2.0116723045226066

Epoch: 5| Step: 6
Training loss: 1.407170295715332
Validation loss: 1.9929167685970184

Epoch: 5| Step: 7
Training loss: 2.168083906173706
Validation loss: 1.9852897351787937

Epoch: 5| Step: 8
Training loss: 1.2891199588775635
Validation loss: 1.9706616273490332

Epoch: 5| Step: 9
Training loss: 1.5319793224334717
Validation loss: 1.9858506033497472

Epoch: 5| Step: 10
Training loss: 2.1403417587280273
Validation loss: 2.0356584954005417

Epoch: 153| Step: 0
Training loss: 1.8142122030258179
Validation loss: 2.0799615024238505

Epoch: 5| Step: 1
Training loss: 1.6444225311279297
Validation loss: 2.135317538374214

Epoch: 5| Step: 2
Training loss: 1.8243030309677124
Validation loss: 2.1553224491816696

Epoch: 5| Step: 3
Training loss: 1.4807218313217163
Validation loss: 2.138379934013531

Epoch: 5| Step: 4
Training loss: 1.1769685745239258
Validation loss: 2.1120654318922307

Epoch: 5| Step: 5
Training loss: 2.523080348968506
Validation loss: 2.0561729490116076

Epoch: 5| Step: 6
Training loss: 1.7485439777374268
Validation loss: 2.0435981532578826

Epoch: 5| Step: 7
Training loss: 1.5126397609710693
Validation loss: 2.0147190145266953

Epoch: 5| Step: 8
Training loss: 1.9359220266342163
Validation loss: 2.033129524159175

Epoch: 5| Step: 9
Training loss: 2.0143659114837646
Validation loss: 2.0018759927442

Epoch: 5| Step: 10
Training loss: 1.979723334312439
Validation loss: 2.011042760264489

Epoch: 154| Step: 0
Training loss: 1.9435116052627563
Validation loss: 1.986225103819242

Epoch: 5| Step: 1
Training loss: 1.2754106521606445
Validation loss: 1.9979741342606083

Epoch: 5| Step: 2
Training loss: 1.9172780513763428
Validation loss: 2.0017916002581195

Epoch: 5| Step: 3
Training loss: 1.58719801902771
Validation loss: 2.0558269305895736

Epoch: 5| Step: 4
Training loss: 2.0297627449035645
Validation loss: 2.0957346244524886

Epoch: 5| Step: 5
Training loss: 1.6352345943450928
Validation loss: 2.0833795314194052

Epoch: 5| Step: 6
Training loss: 1.6709169149398804
Validation loss: 2.1071817746726413

Epoch: 5| Step: 7
Training loss: 1.5586960315704346
Validation loss: 2.1235945916944936

Epoch: 5| Step: 8
Training loss: 1.6799507141113281
Validation loss: 2.152395094594648

Epoch: 5| Step: 9
Training loss: 2.092012405395508
Validation loss: 2.1291981973955707

Epoch: 5| Step: 10
Training loss: 2.02339243888855
Validation loss: 2.1115900906183387

Epoch: 155| Step: 0
Training loss: 1.5778757333755493
Validation loss: 2.0332055784040883

Epoch: 5| Step: 1
Training loss: 1.0033113956451416
Validation loss: 2.022806993094824

Epoch: 5| Step: 2
Training loss: 2.1545193195343018
Validation loss: 2.0010007363493725

Epoch: 5| Step: 3
Training loss: 1.9662621021270752
Validation loss: 1.9973513951865576

Epoch: 5| Step: 4
Training loss: 1.956652283668518
Validation loss: 2.0123464010095082

Epoch: 5| Step: 5
Training loss: 2.1074349880218506
Validation loss: 2.0151130973651843

Epoch: 5| Step: 6
Training loss: 1.682021141052246
Validation loss: 2.0281016416447137

Epoch: 5| Step: 7
Training loss: 1.9293098449707031
Validation loss: 2.04423677280385

Epoch: 5| Step: 8
Training loss: 1.0097734928131104
Validation loss: 2.0625811507624965

Epoch: 5| Step: 9
Training loss: 2.067662477493286
Validation loss: 2.0464968514698807

Epoch: 5| Step: 10
Training loss: 1.414209008216858
Validation loss: 2.0701541285361014

Epoch: 156| Step: 0
Training loss: 1.6889845132827759
Validation loss: 2.058413722181833

Epoch: 5| Step: 1
Training loss: 2.1538257598876953
Validation loss: 2.0351723676086753

Epoch: 5| Step: 2
Training loss: 1.381172776222229
Validation loss: 2.0510720591391287

Epoch: 5| Step: 3
Training loss: 1.8107820749282837
Validation loss: 2.0310177110856578

Epoch: 5| Step: 4
Training loss: 1.508675217628479
Validation loss: 2.056347826475738

Epoch: 5| Step: 5
Training loss: 1.6692588329315186
Validation loss: 2.0694842953835764

Epoch: 5| Step: 6
Training loss: 1.454760193824768
Validation loss: 2.072072685405772

Epoch: 5| Step: 7
Training loss: 1.5870949029922485
Validation loss: 2.06617691439967

Epoch: 5| Step: 8
Training loss: 1.7297570705413818
Validation loss: 2.075622402211671

Epoch: 5| Step: 9
Training loss: 1.8690345287322998
Validation loss: 2.0568140860526793

Epoch: 5| Step: 10
Training loss: 1.6920899152755737
Validation loss: 2.014331812499672

Epoch: 157| Step: 0
Training loss: 1.444785475730896
Validation loss: 1.993090775705153

Epoch: 5| Step: 1
Training loss: 1.5922771692276
Validation loss: 1.9742543133356238

Epoch: 5| Step: 2
Training loss: 2.129021406173706
Validation loss: 1.9946978297284854

Epoch: 5| Step: 3
Training loss: 2.3852381706237793
Validation loss: 2.0456611738410047

Epoch: 5| Step: 4
Training loss: 1.0923839807510376
Validation loss: 2.079245046902728

Epoch: 5| Step: 5
Training loss: 1.7877269983291626
Validation loss: 2.124207722243442

Epoch: 5| Step: 6
Training loss: 1.1050751209259033
Validation loss: 2.1235499151291384

Epoch: 5| Step: 7
Training loss: 1.5137752294540405
Validation loss: 2.105781983303767

Epoch: 5| Step: 8
Training loss: 2.179360866546631
Validation loss: 2.1280678959303003

Epoch: 5| Step: 9
Training loss: 1.6468921899795532
Validation loss: 2.0915704068317207

Epoch: 5| Step: 10
Training loss: 1.6099066734313965
Validation loss: 2.0813612655926774

Epoch: 158| Step: 0
Training loss: 1.4394787549972534
Validation loss: 2.075518149201588

Epoch: 5| Step: 1
Training loss: 1.5428857803344727
Validation loss: 2.0416251228701685

Epoch: 5| Step: 2
Training loss: 1.890089988708496
Validation loss: 2.0047567172717025

Epoch: 5| Step: 3
Training loss: 2.359189987182617
Validation loss: 1.9808086451663767

Epoch: 5| Step: 4
Training loss: 1.4814598560333252
Validation loss: 1.9806595733088832

Epoch: 5| Step: 5
Training loss: 1.5818426609039307
Validation loss: 1.983659085407052

Epoch: 5| Step: 6
Training loss: 1.8408753871917725
Validation loss: 2.044765741594376

Epoch: 5| Step: 7
Training loss: 1.336053729057312
Validation loss: 2.060584766890413

Epoch: 5| Step: 8
Training loss: 1.6453726291656494
Validation loss: 2.1115849300097396

Epoch: 5| Step: 9
Training loss: 1.697787880897522
Validation loss: 2.1311142957338722

Epoch: 5| Step: 10
Training loss: 1.6955381631851196
Validation loss: 2.1624465783437095

Epoch: 159| Step: 0
Training loss: 2.0719642639160156
Validation loss: 2.1861676375071206

Epoch: 5| Step: 1
Training loss: 1.350124716758728
Validation loss: 2.2107393767244075

Epoch: 5| Step: 2
Training loss: 1.8831853866577148
Validation loss: 2.1854956637146654

Epoch: 5| Step: 3
Training loss: 1.952990174293518
Validation loss: 2.176343479464131

Epoch: 5| Step: 4
Training loss: 1.5163613557815552
Validation loss: 2.1620384826455066

Epoch: 5| Step: 5
Training loss: 1.6733944416046143
Validation loss: 2.1306807482114403

Epoch: 5| Step: 6
Training loss: 1.699352502822876
Validation loss: 2.071461549369238

Epoch: 5| Step: 7
Training loss: 1.6008732318878174
Validation loss: 2.0419670010125763

Epoch: 5| Step: 8
Training loss: 1.690138578414917
Validation loss: 1.9921099780708231

Epoch: 5| Step: 9
Training loss: 1.5455715656280518
Validation loss: 1.9789383321680047

Epoch: 5| Step: 10
Training loss: 1.377838134765625
Validation loss: 1.9571993376619072

Epoch: 160| Step: 0
Training loss: 1.643608808517456
Validation loss: 1.9465630259565128

Epoch: 5| Step: 1
Training loss: 1.5993810892105103
Validation loss: 1.977254803462695

Epoch: 5| Step: 2
Training loss: 1.3898788690567017
Validation loss: 2.005784558993514

Epoch: 5| Step: 3
Training loss: 1.777722954750061
Validation loss: 2.048790318991548

Epoch: 5| Step: 4
Training loss: 1.9993171691894531
Validation loss: 2.0977871853818177

Epoch: 5| Step: 5
Training loss: 1.5672963857650757
Validation loss: 2.1450922796803136

Epoch: 5| Step: 6
Training loss: 1.601680040359497
Validation loss: 2.162231127421061

Epoch: 5| Step: 7
Training loss: 2.086177349090576
Validation loss: 2.1391291925984044

Epoch: 5| Step: 8
Training loss: 1.5733245611190796
Validation loss: 2.117829704797396

Epoch: 5| Step: 9
Training loss: 1.5369147062301636
Validation loss: 2.0808791678438903

Epoch: 5| Step: 10
Training loss: 1.6725702285766602
Validation loss: 2.0322215146915887

Epoch: 161| Step: 0
Training loss: 1.367595911026001
Validation loss: 2.0360327741151214

Epoch: 5| Step: 1
Training loss: 1.2604949474334717
Validation loss: 2.0275364229756017

Epoch: 5| Step: 2
Training loss: 1.9362285137176514
Validation loss: 2.049416829180974

Epoch: 5| Step: 3
Training loss: 1.4451295137405396
Validation loss: 2.073455801574133

Epoch: 5| Step: 4
Training loss: 2.2344508171081543
Validation loss: 2.088152954655309

Epoch: 5| Step: 5
Training loss: 1.1898932456970215
Validation loss: 2.1251607966679398

Epoch: 5| Step: 6
Training loss: 1.560185432434082
Validation loss: 2.1323298805503437

Epoch: 5| Step: 7
Training loss: 1.912024736404419
Validation loss: 2.1423336587926394

Epoch: 5| Step: 8
Training loss: 1.4619511365890503
Validation loss: 2.1462007056000414

Epoch: 5| Step: 9
Training loss: 1.8875137567520142
Validation loss: 2.1328391823717343

Epoch: 5| Step: 10
Training loss: 1.526273488998413
Validation loss: 2.1040633955309467

Epoch: 162| Step: 0
Training loss: 2.193002939224243
Validation loss: 2.086063628555626

Epoch: 5| Step: 1
Training loss: 1.589964747428894
Validation loss: 2.0329659702957317

Epoch: 5| Step: 2
Training loss: 0.8604773283004761
Validation loss: 2.0438246021988573

Epoch: 5| Step: 3
Training loss: 1.7123889923095703
Validation loss: 2.044819558820417

Epoch: 5| Step: 4
Training loss: 1.9117555618286133
Validation loss: 2.0321006005810154

Epoch: 5| Step: 5
Training loss: 1.7641279697418213
Validation loss: 2.0484438762869885

Epoch: 5| Step: 6
Training loss: 1.4387743473052979
Validation loss: 2.0495309509256834

Epoch: 5| Step: 7
Training loss: 1.6448808908462524
Validation loss: 2.0512589075232066

Epoch: 5| Step: 8
Training loss: 1.204049825668335
Validation loss: 2.057972873410871

Epoch: 5| Step: 9
Training loss: 1.3252233266830444
Validation loss: 2.0747024756605907

Epoch: 5| Step: 10
Training loss: 1.9932924509048462
Validation loss: 2.071949230727329

Epoch: 163| Step: 0
Training loss: 1.4972960948944092
Validation loss: 2.087038423425408

Epoch: 5| Step: 1
Training loss: 2.315295696258545
Validation loss: 2.064464625491891

Epoch: 5| Step: 2
Training loss: 1.8562967777252197
Validation loss: 2.078007380167643

Epoch: 5| Step: 3
Training loss: 0.9994456171989441
Validation loss: 2.032954554403982

Epoch: 5| Step: 4
Training loss: 1.1431660652160645
Validation loss: 2.061127319130846

Epoch: 5| Step: 5
Training loss: 1.1946965456008911
Validation loss: 2.0731522460137644

Epoch: 5| Step: 6
Training loss: 1.6475814580917358
Validation loss: 2.1334483649141047

Epoch: 5| Step: 7
Training loss: 2.4275853633880615
Validation loss: 2.159638202318581

Epoch: 5| Step: 8
Training loss: 1.0080819129943848
Validation loss: 2.1824185207325923

Epoch: 5| Step: 9
Training loss: 2.2887516021728516
Validation loss: 2.170667213778342

Epoch: 5| Step: 10
Training loss: 1.0265682935714722
Validation loss: 2.1671006141170377

Epoch: 164| Step: 0
Training loss: 1.8322073221206665
Validation loss: 2.1437318043042253

Epoch: 5| Step: 1
Training loss: 1.5491447448730469
Validation loss: 2.074273755473475

Epoch: 5| Step: 2
Training loss: 1.2092303037643433
Validation loss: 2.011944974622419

Epoch: 5| Step: 3
Training loss: 1.3329095840454102
Validation loss: 1.9955066532217047

Epoch: 5| Step: 4
Training loss: 1.9271433353424072
Validation loss: 1.9966764847437541

Epoch: 5| Step: 5
Training loss: 1.3185850381851196
Validation loss: 2.001512009610412

Epoch: 5| Step: 6
Training loss: 1.6335418224334717
Validation loss: 2.00320339715609

Epoch: 5| Step: 7
Training loss: 1.1183292865753174
Validation loss: 2.0139091143044094

Epoch: 5| Step: 8
Training loss: 2.1853432655334473
Validation loss: 2.0352472848789667

Epoch: 5| Step: 9
Training loss: 1.656842589378357
Validation loss: 2.069749673207601

Epoch: 5| Step: 10
Training loss: 1.6567515134811401
Validation loss: 2.125915919580767

Epoch: 165| Step: 0
Training loss: 1.7379159927368164
Validation loss: 2.1434392057439333

Epoch: 5| Step: 1
Training loss: 1.3579423427581787
Validation loss: 2.1627685408438406

Epoch: 5| Step: 2
Training loss: 1.8266788721084595
Validation loss: 2.1241750435162614

Epoch: 5| Step: 3
Training loss: 1.2517896890640259
Validation loss: 2.0792335656381424

Epoch: 5| Step: 4
Training loss: 1.3561866283416748
Validation loss: 2.020065902381815

Epoch: 5| Step: 5
Training loss: 1.7676661014556885
Validation loss: 2.016189612368102

Epoch: 5| Step: 6
Training loss: 1.2154583930969238
Validation loss: 1.9749385951667704

Epoch: 5| Step: 7
Training loss: 1.4184573888778687
Validation loss: 1.995605517459172

Epoch: 5| Step: 8
Training loss: 1.8538169860839844
Validation loss: 2.010132538375034

Epoch: 5| Step: 9
Training loss: 2.0864663124084473
Validation loss: 2.039468173057802

Epoch: 5| Step: 10
Training loss: 1.5886704921722412
Validation loss: 2.0515814006969495

Epoch: 166| Step: 0
Training loss: 1.2668335437774658
Validation loss: 2.0894737371834378

Epoch: 5| Step: 1
Training loss: 1.4389554262161255
Validation loss: 2.1255213317050727

Epoch: 5| Step: 2
Training loss: 1.5647070407867432
Validation loss: 2.1081849580170005

Epoch: 5| Step: 3
Training loss: 2.6324734687805176
Validation loss: 2.107307126445155

Epoch: 5| Step: 4
Training loss: 1.0794012546539307
Validation loss: 2.1199161929468953

Epoch: 5| Step: 5
Training loss: 1.155390977859497
Validation loss: 2.115592897579234

Epoch: 5| Step: 6
Training loss: 1.4434382915496826
Validation loss: 2.0906292751271236

Epoch: 5| Step: 7
Training loss: 1.6993224620819092
Validation loss: 2.0220924449223343

Epoch: 5| Step: 8
Training loss: 1.8187410831451416
Validation loss: 2.00700633500212

Epoch: 5| Step: 9
Training loss: 1.5753027200698853
Validation loss: 1.9931833103138914

Epoch: 5| Step: 10
Training loss: 1.919849157333374
Validation loss: 2.001765119132175

Epoch: 167| Step: 0
Training loss: 1.4007470607757568
Validation loss: 2.0223614964433896

Epoch: 5| Step: 1
Training loss: 1.8457410335540771
Validation loss: 2.005220223498601

Epoch: 5| Step: 2
Training loss: 1.5178817510604858
Validation loss: 2.0140059250657276

Epoch: 5| Step: 3
Training loss: 1.7136147022247314
Validation loss: 2.0320297671902563

Epoch: 5| Step: 4
Training loss: 1.7247718572616577
Validation loss: 2.081537195431289

Epoch: 5| Step: 5
Training loss: 1.5657978057861328
Validation loss: 2.1212090984467538

Epoch: 5| Step: 6
Training loss: 1.7978441715240479
Validation loss: 2.1274800326234553

Epoch: 5| Step: 7
Training loss: 1.1027657985687256
Validation loss: 2.0876459101194977

Epoch: 5| Step: 8
Training loss: 1.7352893352508545
Validation loss: 2.06160415885269

Epoch: 5| Step: 9
Training loss: 1.3713610172271729
Validation loss: 2.022419556494682

Epoch: 5| Step: 10
Training loss: 1.5680891275405884
Validation loss: 2.0578358916826147

Epoch: 168| Step: 0
Training loss: 1.7666676044464111
Validation loss: 2.018338869976741

Epoch: 5| Step: 1
Training loss: 1.484976053237915
Validation loss: 2.007717970878847

Epoch: 5| Step: 2
Training loss: 1.7050142288208008
Validation loss: 2.0244867263301725

Epoch: 5| Step: 3
Training loss: 1.6737655401229858
Validation loss: 2.052406016216483

Epoch: 5| Step: 4
Training loss: 1.603796362876892
Validation loss: 2.03648014478786

Epoch: 5| Step: 5
Training loss: 1.7749332189559937
Validation loss: 2.0653603512753724

Epoch: 5| Step: 6
Training loss: 1.5111030340194702
Validation loss: 2.086005549277029

Epoch: 5| Step: 7
Training loss: 1.5387601852416992
Validation loss: 2.0599884627967753

Epoch: 5| Step: 8
Training loss: 1.0285005569458008
Validation loss: 2.0396868362221667

Epoch: 5| Step: 9
Training loss: 1.3506101369857788
Validation loss: 2.018516263654155

Epoch: 5| Step: 10
Training loss: 1.3817541599273682
Validation loss: 1.9879261357809908

Epoch: 169| Step: 0
Training loss: 1.4644310474395752
Validation loss: 2.011771022632558

Epoch: 5| Step: 1
Training loss: 1.9130862951278687
Validation loss: 2.0441672327697917

Epoch: 5| Step: 2
Training loss: 1.5307631492614746
Validation loss: 2.066138275208012

Epoch: 5| Step: 3
Training loss: 1.8297220468521118
Validation loss: 2.0757243030814716

Epoch: 5| Step: 4
Training loss: 1.615869164466858
Validation loss: 2.1143516468745407

Epoch: 5| Step: 5
Training loss: 1.0094165802001953
Validation loss: 2.1265167523455877

Epoch: 5| Step: 6
Training loss: 1.2949440479278564
Validation loss: 2.156981473327965

Epoch: 5| Step: 7
Training loss: 1.4598959684371948
Validation loss: 2.127739624310565

Epoch: 5| Step: 8
Training loss: 1.2805497646331787
Validation loss: 2.1048512330619236

Epoch: 5| Step: 9
Training loss: 1.7914848327636719
Validation loss: 2.0545167999882854

Epoch: 5| Step: 10
Training loss: 1.13058340549469
Validation loss: 2.0325326919555664

Epoch: 170| Step: 0
Training loss: 0.9960623979568481
Validation loss: 2.0148328478618334

Epoch: 5| Step: 1
Training loss: 1.6111419200897217
Validation loss: 1.9759256096296414

Epoch: 5| Step: 2
Training loss: 2.18056321144104
Validation loss: 1.9725498973682363

Epoch: 5| Step: 3
Training loss: 1.1598026752471924
Validation loss: 2.031291337423427

Epoch: 5| Step: 4
Training loss: 1.4244247674942017
Validation loss: 2.084842628048312

Epoch: 5| Step: 5
Training loss: 1.435401201248169
Validation loss: 2.0823075130421627

Epoch: 5| Step: 6
Training loss: 1.9654890298843384
Validation loss: 2.18952525302928

Epoch: 5| Step: 7
Training loss: 1.9880539178848267
Validation loss: 2.2270603308113675

Epoch: 5| Step: 8
Training loss: 1.756036400794983
Validation loss: 2.197733768852808

Epoch: 5| Step: 9
Training loss: 1.0523215532302856
Validation loss: 2.116694373469199

Epoch: 5| Step: 10
Training loss: 0.9485307335853577
Validation loss: 2.0364635016328547

Epoch: 171| Step: 0
Training loss: 1.5478465557098389
Validation loss: 1.998616110893988

Epoch: 5| Step: 1
Training loss: 1.642168641090393
Validation loss: 1.9803766345465055

Epoch: 5| Step: 2
Training loss: 1.3316640853881836
Validation loss: 1.9790218645526516

Epoch: 5| Step: 3
Training loss: 1.8768644332885742
Validation loss: 1.9569731373940744

Epoch: 5| Step: 4
Training loss: 1.3584966659545898
Validation loss: 2.022741069075882

Epoch: 5| Step: 5
Training loss: 1.1046308279037476
Validation loss: 2.0645890389719317

Epoch: 5| Step: 6
Training loss: 1.5462583303451538
Validation loss: 2.100945367608019

Epoch: 5| Step: 7
Training loss: 1.527803659439087
Validation loss: 2.1041912135257514

Epoch: 5| Step: 8
Training loss: 1.5584042072296143
Validation loss: 2.1153885651660222

Epoch: 5| Step: 9
Training loss: 1.279769778251648
Validation loss: 2.1426722336840887

Epoch: 5| Step: 10
Training loss: 1.4888207912445068
Validation loss: 2.1452300112734557

Epoch: 172| Step: 0
Training loss: 1.1307936906814575
Validation loss: 2.1012444470518377

Epoch: 5| Step: 1
Training loss: 1.3568159341812134
Validation loss: 2.090578576569916

Epoch: 5| Step: 2
Training loss: 0.9221063852310181
Validation loss: 2.0784523564000286

Epoch: 5| Step: 3
Training loss: 1.7145553827285767
Validation loss: 2.1094019412994385

Epoch: 5| Step: 4
Training loss: 2.089576005935669
Validation loss: 2.070829737570978

Epoch: 5| Step: 5
Training loss: 1.8552663326263428
Validation loss: 2.035663253517561

Epoch: 5| Step: 6
Training loss: 1.2398239374160767
Validation loss: 2.0034641937542985

Epoch: 5| Step: 7
Training loss: 1.1690785884857178
Validation loss: 1.9901253254182878

Epoch: 5| Step: 8
Training loss: 1.5582239627838135
Validation loss: 1.9876918485087733

Epoch: 5| Step: 9
Training loss: 1.6703386306762695
Validation loss: 1.9839303365317724

Epoch: 5| Step: 10
Training loss: 1.9108299016952515
Validation loss: 2.0693129813799294

Epoch: 173| Step: 0
Training loss: 1.4555635452270508
Validation loss: 2.1471246263032318

Epoch: 5| Step: 1
Training loss: 1.3896182775497437
Validation loss: 2.1432337248197166

Epoch: 5| Step: 2
Training loss: 1.0631604194641113
Validation loss: 2.145966793901177

Epoch: 5| Step: 3
Training loss: 1.588323712348938
Validation loss: 2.152901919939185

Epoch: 5| Step: 4
Training loss: 1.5414807796478271
Validation loss: 2.092254482289796

Epoch: 5| Step: 5
Training loss: 1.6174957752227783
Validation loss: 2.048907187677199

Epoch: 5| Step: 6
Training loss: 1.2575393915176392
Validation loss: 2.0166966325493267

Epoch: 5| Step: 7
Training loss: 1.8944084644317627
Validation loss: 1.988231485889804

Epoch: 5| Step: 8
Training loss: 1.75048828125
Validation loss: 1.99618516173414

Epoch: 5| Step: 9
Training loss: 1.448891520500183
Validation loss: 1.9934551856851066

Epoch: 5| Step: 10
Training loss: 1.7590187788009644
Validation loss: 2.0008547408606416

Epoch: 174| Step: 0
Training loss: 1.1672624349594116
Validation loss: 2.039406507245956

Epoch: 5| Step: 1
Training loss: 1.4035894870758057
Validation loss: 2.0812592634590725

Epoch: 5| Step: 2
Training loss: 1.370710015296936
Validation loss: 2.128420211935556

Epoch: 5| Step: 3
Training loss: 1.777111291885376
Validation loss: 2.1429502733292116

Epoch: 5| Step: 4
Training loss: 1.5150848627090454
Validation loss: 2.1009199298838133

Epoch: 5| Step: 5
Training loss: 1.4340397119522095
Validation loss: 2.061413247098205

Epoch: 5| Step: 6
Training loss: 1.2862827777862549
Validation loss: 2.019208264607255

Epoch: 5| Step: 7
Training loss: 1.233010172843933
Validation loss: 2.0130761695164505

Epoch: 5| Step: 8
Training loss: 2.1360652446746826
Validation loss: 2.027012930121473

Epoch: 5| Step: 9
Training loss: 0.8203523755073547
Validation loss: 2.0391872595715266

Epoch: 5| Step: 10
Training loss: 1.9651471376419067
Validation loss: 2.0755484360520557

Epoch: 175| Step: 0
Training loss: 1.005365014076233
Validation loss: 2.0421970557141047

Epoch: 5| Step: 1
Training loss: 2.136277675628662
Validation loss: 2.0403708322073824

Epoch: 5| Step: 2
Training loss: 1.6275440454483032
Validation loss: 2.034606989993844

Epoch: 5| Step: 3
Training loss: 1.4089624881744385
Validation loss: 2.034237943669801

Epoch: 5| Step: 4
Training loss: 1.24225652217865
Validation loss: 2.0407408514330463

Epoch: 5| Step: 5
Training loss: 1.6455771923065186
Validation loss: 2.074432202564773

Epoch: 5| Step: 6
Training loss: 1.4006288051605225
Validation loss: 2.0909051536231913

Epoch: 5| Step: 7
Training loss: 1.2361520528793335
Validation loss: 2.095181970186131

Epoch: 5| Step: 8
Training loss: 1.0943286418914795
Validation loss: 2.1074197830692416

Epoch: 5| Step: 9
Training loss: 1.723263144493103
Validation loss: 2.149542336822838

Epoch: 5| Step: 10
Training loss: 1.3321242332458496
Validation loss: 2.165803993901899

Epoch: 176| Step: 0
Training loss: 1.3198875188827515
Validation loss: 2.107049931762039

Epoch: 5| Step: 1
Training loss: 2.0118720531463623
Validation loss: 2.0638236627783826

Epoch: 5| Step: 2
Training loss: 1.0666916370391846
Validation loss: 2.037587963124757

Epoch: 5| Step: 3
Training loss: 1.5769927501678467
Validation loss: 2.0751526586471067

Epoch: 5| Step: 4
Training loss: 1.6380460262298584
Validation loss: 2.05069274158888

Epoch: 5| Step: 5
Training loss: 1.0962212085723877
Validation loss: 2.0133210587245163

Epoch: 5| Step: 6
Training loss: 1.466432809829712
Validation loss: 2.0160341672999884

Epoch: 5| Step: 7
Training loss: 1.3467800617218018
Validation loss: 2.0436450768542547

Epoch: 5| Step: 8
Training loss: 1.5811188220977783
Validation loss: 2.0513941318758073

Epoch: 5| Step: 9
Training loss: 1.5430457592010498
Validation loss: 2.0870342023911013

Epoch: 5| Step: 10
Training loss: 0.922751247882843
Validation loss: 2.0957816262398996

Epoch: 177| Step: 0
Training loss: 1.1779321432113647
Validation loss: 2.1462014336739816

Epoch: 5| Step: 1
Training loss: 1.7995563745498657
Validation loss: 2.1758493684953257

Epoch: 5| Step: 2
Training loss: 1.0511000156402588
Validation loss: 2.185649715444093

Epoch: 5| Step: 3
Training loss: 1.4545865058898926
Validation loss: 2.1087788112701906

Epoch: 5| Step: 4
Training loss: 1.7935991287231445
Validation loss: 2.042624931181631

Epoch: 5| Step: 5
Training loss: 1.3302842378616333
Validation loss: 2.00909831190622

Epoch: 5| Step: 6
Training loss: 1.0311119556427002
Validation loss: 1.9780563013527983

Epoch: 5| Step: 7
Training loss: 1.1003965139389038
Validation loss: 1.9625215325304257

Epoch: 5| Step: 8
Training loss: 1.5847957134246826
Validation loss: 2.007620016733805

Epoch: 5| Step: 9
Training loss: 2.057642698287964
Validation loss: 2.048070958865586

Epoch: 5| Step: 10
Training loss: 1.624909520149231
Validation loss: 2.099929021250817

Epoch: 178| Step: 0
Training loss: 1.4051802158355713
Validation loss: 2.1877647715230144

Epoch: 5| Step: 1
Training loss: 1.525048017501831
Validation loss: 2.177869096879036

Epoch: 5| Step: 2
Training loss: 1.204441785812378
Validation loss: 2.199898230132236

Epoch: 5| Step: 3
Training loss: 1.5393197536468506
Validation loss: 2.200464899821948

Epoch: 5| Step: 4
Training loss: 1.2987079620361328
Validation loss: 2.1901322282770628

Epoch: 5| Step: 5
Training loss: 1.0597060918807983
Validation loss: 2.180437080321773

Epoch: 5| Step: 6
Training loss: 1.8721034526824951
Validation loss: 2.1343380789602957

Epoch: 5| Step: 7
Training loss: 1.048848032951355
Validation loss: 2.1081476339729885

Epoch: 5| Step: 8
Training loss: 1.6869834661483765
Validation loss: 2.07688340064018

Epoch: 5| Step: 9
Training loss: 1.3001015186309814
Validation loss: 2.053478503739962

Epoch: 5| Step: 10
Training loss: 1.3914376497268677
Validation loss: 2.0676706273068666

Epoch: 179| Step: 0
Training loss: 1.6297193765640259
Validation loss: 2.0645272654871785

Epoch: 5| Step: 1
Training loss: 1.1262454986572266
Validation loss: 2.0530103047688804

Epoch: 5| Step: 2
Training loss: 1.3259937763214111
Validation loss: 2.0859775838031562

Epoch: 5| Step: 3
Training loss: 1.817847490310669
Validation loss: 2.11393597690008

Epoch: 5| Step: 4
Training loss: 1.3091304302215576
Validation loss: 2.1346679297826623

Epoch: 5| Step: 5
Training loss: 1.3883529901504517
Validation loss: 2.1304666534546883

Epoch: 5| Step: 6
Training loss: 1.592847228050232
Validation loss: 2.1543487374500563

Epoch: 5| Step: 7
Training loss: 1.125748872756958
Validation loss: 2.1277060175454743

Epoch: 5| Step: 8
Training loss: 0.9501329660415649
Validation loss: 2.0759323425190424

Epoch: 5| Step: 9
Training loss: 1.272520899772644
Validation loss: 2.074464754391742

Epoch: 5| Step: 10
Training loss: 1.3488845825195312
Validation loss: 2.0090709886243268

Epoch: 180| Step: 0
Training loss: 1.4105911254882812
Validation loss: 2.0161456959221953

Epoch: 5| Step: 1
Training loss: 1.3982164859771729
Validation loss: 2.034819628602715

Epoch: 5| Step: 2
Training loss: 1.3214102983474731
Validation loss: 2.044181695548437

Epoch: 5| Step: 3
Training loss: 1.7247587442398071
Validation loss: 2.0564813383163942

Epoch: 5| Step: 4
Training loss: 1.218364953994751
Validation loss: 2.127261350231786

Epoch: 5| Step: 5
Training loss: 0.9764959216117859
Validation loss: 2.1449699068582184

Epoch: 5| Step: 6
Training loss: 1.722111463546753
Validation loss: 2.1719337330069592

Epoch: 5| Step: 7
Training loss: 1.363561749458313
Validation loss: 2.1723939244465162

Epoch: 5| Step: 8
Training loss: 1.4424678087234497
Validation loss: 2.1484767621563328

Epoch: 5| Step: 9
Training loss: 1.5020250082015991
Validation loss: 2.0753244687152166

Epoch: 5| Step: 10
Training loss: 0.9751715660095215
Validation loss: 2.035334652470004

Epoch: 181| Step: 0
Training loss: 1.4060440063476562
Validation loss: 1.9709273397281606

Epoch: 5| Step: 1
Training loss: 1.3416210412979126
Validation loss: 1.9620979562882455

Epoch: 5| Step: 2
Training loss: 1.341668725013733
Validation loss: 1.9534131916620399

Epoch: 5| Step: 3
Training loss: 0.9262346029281616
Validation loss: 1.9840354816887968

Epoch: 5| Step: 4
Training loss: 1.6781526803970337
Validation loss: 2.023724639287559

Epoch: 5| Step: 5
Training loss: 1.669704794883728
Validation loss: 2.0501459465231946

Epoch: 5| Step: 6
Training loss: 1.6261098384857178
Validation loss: 2.0761212302792456

Epoch: 5| Step: 7
Training loss: 1.619783639907837
Validation loss: 2.1301723731461393

Epoch: 5| Step: 8
Training loss: 1.3268240690231323
Validation loss: 2.120292648192375

Epoch: 5| Step: 9
Training loss: 1.1447064876556396
Validation loss: 2.1182842075183825

Epoch: 5| Step: 10
Training loss: 0.7440446019172668
Validation loss: 2.0915741882016583

Epoch: 182| Step: 0
Training loss: 0.8938053846359253
Validation loss: 2.122996081588089

Epoch: 5| Step: 1
Training loss: 1.1002140045166016
Validation loss: 2.1472312865718717

Epoch: 5| Step: 2
Training loss: 1.6201359033584595
Validation loss: 2.1281654373292

Epoch: 5| Step: 3
Training loss: 1.0901015996932983
Validation loss: 2.133541145632344

Epoch: 5| Step: 4
Training loss: 1.5388914346694946
Validation loss: 2.113633696750928

Epoch: 5| Step: 5
Training loss: 1.3112680912017822
Validation loss: 2.0763045946756997

Epoch: 5| Step: 6
Training loss: 1.51915442943573
Validation loss: 2.042882083564676

Epoch: 5| Step: 7
Training loss: 1.0116316080093384
Validation loss: 2.042588008347378

Epoch: 5| Step: 8
Training loss: 1.3003519773483276
Validation loss: 2.039502820660991

Epoch: 5| Step: 9
Training loss: 1.570058822631836
Validation loss: 2.0373718430919032

Epoch: 5| Step: 10
Training loss: 1.6401197910308838
Validation loss: 2.036437255080028

Epoch: 183| Step: 0
Training loss: 1.1076838970184326
Validation loss: 2.021877449045899

Epoch: 5| Step: 1
Training loss: 1.8058010339736938
Validation loss: 2.004355581857825

Epoch: 5| Step: 2
Training loss: 1.5641359090805054
Validation loss: 1.9872698988965762

Epoch: 5| Step: 3
Training loss: 1.265108346939087
Validation loss: 1.9895831333693637

Epoch: 5| Step: 4
Training loss: 1.118208408355713
Validation loss: 1.9922411493075791

Epoch: 5| Step: 5
Training loss: 1.3434113264083862
Validation loss: 2.001541781169112

Epoch: 5| Step: 6
Training loss: 1.221099615097046
Validation loss: 2.0382182957023702

Epoch: 5| Step: 7
Training loss: 1.1433055400848389
Validation loss: 2.053913265146235

Epoch: 5| Step: 8
Training loss: 1.609000563621521
Validation loss: 2.078154710031325

Epoch: 5| Step: 9
Training loss: 1.0817245244979858
Validation loss: 2.0935810355729956

Epoch: 5| Step: 10
Training loss: 1.3776943683624268
Validation loss: 2.1116417300316597

Epoch: 184| Step: 0
Training loss: 1.2474857568740845
Validation loss: 2.0978952453982447

Epoch: 5| Step: 1
Training loss: 1.2071244716644287
Validation loss: 2.0441122337054183

Epoch: 5| Step: 2
Training loss: 1.4563932418823242
Validation loss: 2.0509980288884972

Epoch: 5| Step: 3
Training loss: 1.0707358121871948
Validation loss: 1.994120382493542

Epoch: 5| Step: 4
Training loss: 1.3760660886764526
Validation loss: 1.987930231196906

Epoch: 5| Step: 5
Training loss: 1.631421685218811
Validation loss: 2.004313092077932

Epoch: 5| Step: 6
Training loss: 1.4614697694778442
Validation loss: 2.0280117168221423

Epoch: 5| Step: 7
Training loss: 1.2346041202545166
Validation loss: 2.0959792342237247

Epoch: 5| Step: 8
Training loss: 1.0425280332565308
Validation loss: 2.121029387238205

Epoch: 5| Step: 9
Training loss: 0.9955604672431946
Validation loss: 2.1216698667054534

Epoch: 5| Step: 10
Training loss: 2.046950101852417
Validation loss: 2.1360064937222387

Epoch: 185| Step: 0
Training loss: 0.9799873232841492
Validation loss: 2.0956790959963234

Epoch: 5| Step: 1
Training loss: 1.610647439956665
Validation loss: 2.0942986754960913

Epoch: 5| Step: 2
Training loss: 1.2175886631011963
Validation loss: 2.074344224827264

Epoch: 5| Step: 3
Training loss: 1.4403520822525024
Validation loss: 2.106536416597264

Epoch: 5| Step: 4
Training loss: 1.7402479648590088
Validation loss: 2.0656116290759017

Epoch: 5| Step: 5
Training loss: 1.332634687423706
Validation loss: 2.096759029614028

Epoch: 5| Step: 6
Training loss: 0.7856854200363159
Validation loss: 2.0321779712553947

Epoch: 5| Step: 7
Training loss: 1.4737184047698975
Validation loss: 2.0170444262925016

Epoch: 5| Step: 8
Training loss: 1.2780354022979736
Validation loss: 2.059802509123279

Epoch: 5| Step: 9
Training loss: 0.7453117966651917
Validation loss: 2.057393329117888

Epoch: 5| Step: 10
Training loss: 1.2519421577453613
Validation loss: 2.0895132467310917

Epoch: 186| Step: 0
Training loss: 1.6911571025848389
Validation loss: 2.0760195332188762

Epoch: 5| Step: 1
Training loss: 1.2766796350479126
Validation loss: 2.114144927711897

Epoch: 5| Step: 2
Training loss: 1.4353948831558228
Validation loss: 2.103547188543504

Epoch: 5| Step: 3
Training loss: 0.9074895977973938
Validation loss: 2.12065270767417

Epoch: 5| Step: 4
Training loss: 1.2082871198654175
Validation loss: 2.0959983871829126

Epoch: 5| Step: 5
Training loss: 1.4150421619415283
Validation loss: 2.0601578527881252

Epoch: 5| Step: 6
Training loss: 1.5595380067825317
Validation loss: 2.045101192689711

Epoch: 5| Step: 7
Training loss: 1.4099732637405396
Validation loss: 2.011340243842012

Epoch: 5| Step: 8
Training loss: 1.1842074394226074
Validation loss: 2.043509275682511

Epoch: 5| Step: 9
Training loss: 0.9099957346916199
Validation loss: 2.0424434600337857

Epoch: 5| Step: 10
Training loss: 0.7425097227096558
Validation loss: 2.0468774098221973

Epoch: 187| Step: 0
Training loss: 0.686191737651825
Validation loss: 2.0594101105966875

Epoch: 5| Step: 1
Training loss: 1.7900617122650146
Validation loss: 2.0764861619600685

Epoch: 5| Step: 2
Training loss: 1.3076390027999878
Validation loss: 2.1048740161362516

Epoch: 5| Step: 3
Training loss: 1.3044012784957886
Validation loss: 2.1328443070893646

Epoch: 5| Step: 4
Training loss: 1.3299033641815186
Validation loss: 2.13510347566297

Epoch: 5| Step: 5
Training loss: 1.4316999912261963
Validation loss: 2.125129097251482

Epoch: 5| Step: 6
Training loss: 1.1770182847976685
Validation loss: 2.042344134341004

Epoch: 5| Step: 7
Training loss: 1.3405427932739258
Validation loss: 2.0168177158601823

Epoch: 5| Step: 8
Training loss: 1.1490122079849243
Validation loss: 2.0004740889354418

Epoch: 5| Step: 9
Training loss: 1.423034429550171
Validation loss: 1.990062262422295

Epoch: 5| Step: 10
Training loss: 0.9474581480026245
Validation loss: 2.002016980160949

Epoch: 188| Step: 0
Training loss: 0.6573970913887024
Validation loss: 2.0580211301003732

Epoch: 5| Step: 1
Training loss: 1.4703994989395142
Validation loss: 2.1335205326798143

Epoch: 5| Step: 2
Training loss: 1.339280366897583
Validation loss: 2.1485346414709605

Epoch: 5| Step: 3
Training loss: 1.135888695716858
Validation loss: 2.15691513399924

Epoch: 5| Step: 4
Training loss: 1.3760744333267212
Validation loss: 2.1622153584675123

Epoch: 5| Step: 5
Training loss: 1.151197075843811
Validation loss: 2.1091422368121404

Epoch: 5| Step: 6
Training loss: 0.946708083152771
Validation loss: 2.0838110139293056

Epoch: 5| Step: 7
Training loss: 1.3543920516967773
Validation loss: 2.042297617081673

Epoch: 5| Step: 8
Training loss: 1.0095587968826294
Validation loss: 2.0333127847281833

Epoch: 5| Step: 9
Training loss: 1.686100721359253
Validation loss: 2.0234740908427904

Epoch: 5| Step: 10
Training loss: 1.446819543838501
Validation loss: 2.033117922403479

Epoch: 189| Step: 0
Training loss: 1.5874958038330078
Validation loss: 2.056979333200762

Epoch: 5| Step: 1
Training loss: 1.759560227394104
Validation loss: 2.050135494560324

Epoch: 5| Step: 2
Training loss: 1.2660826444625854
Validation loss: 2.1264029549014185

Epoch: 5| Step: 3
Training loss: 0.7549662590026855
Validation loss: 2.134927947034118

Epoch: 5| Step: 4
Training loss: 0.9161667823791504
Validation loss: 2.1372040522995817

Epoch: 5| Step: 5
Training loss: 1.403930425643921
Validation loss: 2.104791215671006

Epoch: 5| Step: 6
Training loss: 1.4651882648468018
Validation loss: 2.0518327554066977

Epoch: 5| Step: 7
Training loss: 1.2418692111968994
Validation loss: 2.0173535359803068

Epoch: 5| Step: 8
Training loss: 1.122549295425415
Validation loss: 1.999102242531315

Epoch: 5| Step: 9
Training loss: 1.0782908201217651
Validation loss: 1.994594104828373

Epoch: 5| Step: 10
Training loss: 0.718380331993103
Validation loss: 2.0336057216890397

Epoch: 190| Step: 0
Training loss: 1.154179334640503
Validation loss: 2.0699034249910744

Epoch: 5| Step: 1
Training loss: 1.8020093441009521
Validation loss: 2.164759166779057

Epoch: 5| Step: 2
Training loss: 0.8173868060112
Validation loss: 2.1849764341949136

Epoch: 5| Step: 3
Training loss: 1.4991085529327393
Validation loss: 2.1683709582974835

Epoch: 5| Step: 4
Training loss: 0.9571069478988647
Validation loss: 2.0652498750276465

Epoch: 5| Step: 5
Training loss: 1.2260334491729736
Validation loss: 1.9888674392495105

Epoch: 5| Step: 6
Training loss: 1.6141910552978516
Validation loss: 1.9713744399368123

Epoch: 5| Step: 7
Training loss: 1.2260128259658813
Validation loss: 1.9718509348489905

Epoch: 5| Step: 8
Training loss: 1.3139235973358154
Validation loss: 2.0075767758072063

Epoch: 5| Step: 9
Training loss: 0.9390760660171509
Validation loss: 2.0305311397839616

Epoch: 5| Step: 10
Training loss: 1.144474744796753
Validation loss: 2.04640333883224

Epoch: 191| Step: 0
Training loss: 0.6943098306655884
Validation loss: 2.0972505231057443

Epoch: 5| Step: 1
Training loss: 1.1965343952178955
Validation loss: 2.155842947703536

Epoch: 5| Step: 2
Training loss: 1.3938376903533936
Validation loss: 2.242342428494525

Epoch: 5| Step: 3
Training loss: 1.2852060794830322
Validation loss: 2.231783072153727

Epoch: 5| Step: 4
Training loss: 1.3372074365615845
Validation loss: 2.18280614191486

Epoch: 5| Step: 5
Training loss: 1.3524558544158936
Validation loss: 2.103996020491405

Epoch: 5| Step: 6
Training loss: 1.1342045068740845
Validation loss: 2.050138076146444

Epoch: 5| Step: 7
Training loss: 1.446372628211975
Validation loss: 1.9965699782935522

Epoch: 5| Step: 8
Training loss: 1.7307798862457275
Validation loss: 1.9707320197936027

Epoch: 5| Step: 9
Training loss: 1.0432603359222412
Validation loss: 1.9609382972922376

Epoch: 5| Step: 10
Training loss: 1.1776450872421265
Validation loss: 1.9688172084029003

Epoch: 192| Step: 0
Training loss: 1.303640365600586
Validation loss: 2.0064314001349994

Epoch: 5| Step: 1
Training loss: 1.2818619012832642
Validation loss: 2.0005454504361717

Epoch: 5| Step: 2
Training loss: 1.1882184743881226
Validation loss: 2.005714439576672

Epoch: 5| Step: 3
Training loss: 0.8495515584945679
Validation loss: 2.034400716904671

Epoch: 5| Step: 4
Training loss: 1.4316579103469849
Validation loss: 2.0903179466083484

Epoch: 5| Step: 5
Training loss: 1.2411001920700073
Validation loss: 2.1202838920777842

Epoch: 5| Step: 6
Training loss: 1.0657286643981934
Validation loss: 2.064069476178897

Epoch: 5| Step: 7
Training loss: 1.2963659763336182
Validation loss: 2.0459990014312086

Epoch: 5| Step: 8
Training loss: 1.2532703876495361
Validation loss: 2.0465039219907535

Epoch: 5| Step: 9
Training loss: 1.2152811288833618
Validation loss: 2.0139690496588267

Epoch: 5| Step: 10
Training loss: 0.8398398160934448
Validation loss: 2.043777995212104

Epoch: 193| Step: 0
Training loss: 1.4642001390457153
Validation loss: 2.014570188778703

Epoch: 5| Step: 1
Training loss: 1.8679399490356445
Validation loss: 2.0436792937658166

Epoch: 5| Step: 2
Training loss: 1.1801789999008179
Validation loss: 2.04007375624872

Epoch: 5| Step: 3
Training loss: 1.1261526346206665
Validation loss: 2.0232545432224067

Epoch: 5| Step: 4
Training loss: 0.8359028100967407
Validation loss: 2.048131985049094

Epoch: 5| Step: 5
Training loss: 0.8772013783454895
Validation loss: 2.039029677708944

Epoch: 5| Step: 6
Training loss: 0.8659766316413879
Validation loss: 2.0198162730022142

Epoch: 5| Step: 7
Training loss: 1.6624763011932373
Validation loss: 2.0440198734242427

Epoch: 5| Step: 8
Training loss: 1.1162469387054443
Validation loss: 2.0847794317430064

Epoch: 5| Step: 9
Training loss: 0.6913763880729675
Validation loss: 2.1085758773229455

Epoch: 5| Step: 10
Training loss: 1.0455851554870605
Validation loss: 2.1235456466674805

Epoch: 194| Step: 0
Training loss: 1.0207656621932983
Validation loss: 2.0731897507944415

Epoch: 5| Step: 1
Training loss: 1.176867127418518
Validation loss: 2.0615398191636607

Epoch: 5| Step: 2
Training loss: 1.1782047748565674
Validation loss: 2.0506373092692387

Epoch: 5| Step: 3
Training loss: 0.8484252691268921
Validation loss: 1.999511746950047

Epoch: 5| Step: 4
Training loss: 1.2660951614379883
Validation loss: 1.9932868890864874

Epoch: 5| Step: 5
Training loss: 1.092940092086792
Validation loss: 1.9690326926528767

Epoch: 5| Step: 6
Training loss: 0.7873739004135132
Validation loss: 1.9773764405199277

Epoch: 5| Step: 7
Training loss: 1.349722981452942
Validation loss: 1.982842291555097

Epoch: 5| Step: 8
Training loss: 1.5993951559066772
Validation loss: 2.023163014842618

Epoch: 5| Step: 9
Training loss: 1.1244761943817139
Validation loss: 2.0412661977993545

Epoch: 5| Step: 10
Training loss: 1.4333884716033936
Validation loss: 2.0666551436147382

Epoch: 195| Step: 0
Training loss: 1.5268083810806274
Validation loss: 2.065383493259389

Epoch: 5| Step: 1
Training loss: 0.8755990862846375
Validation loss: 2.083197162997338

Epoch: 5| Step: 2
Training loss: 1.104923129081726
Validation loss: 2.0978480513377855

Epoch: 5| Step: 3
Training loss: 1.133591651916504
Validation loss: 2.0238563206888016

Epoch: 5| Step: 4
Training loss: 1.3059247732162476
Validation loss: 2.0066133570927445

Epoch: 5| Step: 5
Training loss: 1.1132522821426392
Validation loss: 1.9805228120537215

Epoch: 5| Step: 6
Training loss: 1.175055742263794
Validation loss: 1.9586330088236

Epoch: 5| Step: 7
Training loss: 1.2921507358551025
Validation loss: 1.9435940327182892

Epoch: 5| Step: 8
Training loss: 1.588213324546814
Validation loss: 1.9473073303058583

Epoch: 5| Step: 9
Training loss: 0.43714213371276855
Validation loss: 1.9815285782660208

Epoch: 5| Step: 10
Training loss: 1.2662267684936523
Validation loss: 1.9930362739870626

Epoch: 196| Step: 0
Training loss: 0.9923856854438782
Validation loss: 2.0275149217215915

Epoch: 5| Step: 1
Training loss: 1.7859758138656616
Validation loss: 2.0619682214593373

Epoch: 5| Step: 2
Training loss: 1.2791478633880615
Validation loss: 2.090265917521651

Epoch: 5| Step: 3
Training loss: 1.226291298866272
Validation loss: 2.0641670009141326

Epoch: 5| Step: 4
Training loss: 0.5503911972045898
Validation loss: 2.04099678608679

Epoch: 5| Step: 5
Training loss: 1.0515941381454468
Validation loss: 2.0301275919842463

Epoch: 5| Step: 6
Training loss: 0.6400198340415955
Validation loss: 2.031737745449107

Epoch: 5| Step: 7
Training loss: 0.9890614748001099
Validation loss: 2.0818517246553974

Epoch: 5| Step: 8
Training loss: 1.302185297012329
Validation loss: 2.0694371987414617

Epoch: 5| Step: 9
Training loss: 1.3083473443984985
Validation loss: 2.0746692060142435

Epoch: 5| Step: 10
Training loss: 1.1585125923156738
Validation loss: 2.059278926541728

Epoch: 197| Step: 0
Training loss: 1.0737711191177368
Validation loss: 2.075316867520732

Epoch: 5| Step: 1
Training loss: 1.0032224655151367
Validation loss: 2.0658172933004235

Epoch: 5| Step: 2
Training loss: 0.7438070178031921
Validation loss: 2.034943945946232

Epoch: 5| Step: 3
Training loss: 0.8940718770027161
Validation loss: 2.0217589588575464

Epoch: 5| Step: 4
Training loss: 1.286698341369629
Validation loss: 1.9978555376811693

Epoch: 5| Step: 5
Training loss: 1.0905061960220337
Validation loss: 1.98581850400535

Epoch: 5| Step: 6
Training loss: 1.2651078701019287
Validation loss: 2.005781909470917

Epoch: 5| Step: 7
Training loss: 1.0875554084777832
Validation loss: 1.9968169248232277

Epoch: 5| Step: 8
Training loss: 1.4505876302719116
Validation loss: 2.0023833346623245

Epoch: 5| Step: 9
Training loss: 0.9078599214553833
Validation loss: 2.0210957604069866

Epoch: 5| Step: 10
Training loss: 1.2969235181808472
Validation loss: 2.030103188689037

Epoch: 198| Step: 0
Training loss: 1.1045023202896118
Validation loss: 2.0004111207941526

Epoch: 5| Step: 1
Training loss: 0.7363334894180298
Validation loss: 2.0098352022068475

Epoch: 5| Step: 2
Training loss: 0.9728201031684875
Validation loss: 2.060021695270333

Epoch: 5| Step: 3
Training loss: 1.3247566223144531
Validation loss: 2.082805952718181

Epoch: 5| Step: 4
Training loss: 0.870958685874939
Validation loss: 2.1251674672608734

Epoch: 5| Step: 5
Training loss: 1.6397082805633545
Validation loss: 2.076748719779394

Epoch: 5| Step: 6
Training loss: 0.8556499481201172
Validation loss: 2.025770728306104

Epoch: 5| Step: 7
Training loss: 1.1474034786224365
Validation loss: 1.9434183054072882

Epoch: 5| Step: 8
Training loss: 0.6886641979217529
Validation loss: 1.963192045047719

Epoch: 5| Step: 9
Training loss: 1.1542394161224365
Validation loss: 1.9514272879528742

Epoch: 5| Step: 10
Training loss: 1.6479644775390625
Validation loss: 1.9697634712342293

Epoch: 199| Step: 0
Training loss: 1.4180629253387451
Validation loss: 1.9847321138587048

Epoch: 5| Step: 1
Training loss: 1.0197060108184814
Validation loss: 1.941712970374733

Epoch: 5| Step: 2
Training loss: 1.3325389623641968
Validation loss: 1.932334206437552

Epoch: 5| Step: 3
Training loss: 1.1568834781646729
Validation loss: 1.9609494581017444

Epoch: 5| Step: 4
Training loss: 0.6844199299812317
Validation loss: 1.9732450336538336

Epoch: 5| Step: 5
Training loss: 1.1397958993911743
Validation loss: 2.0103903714046685

Epoch: 5| Step: 6
Training loss: 1.067669153213501
Validation loss: 2.035803823060887

Epoch: 5| Step: 7
Training loss: 1.0153491497039795
Validation loss: 2.0911237193692114

Epoch: 5| Step: 8
Training loss: 0.9234284162521362
Validation loss: 2.099229863894883

Epoch: 5| Step: 9
Training loss: 1.1251245737075806
Validation loss: 2.072869477733489

Epoch: 5| Step: 10
Training loss: 0.9650128483772278
Validation loss: 2.0100698496705744

Epoch: 200| Step: 0
Training loss: 0.7812511324882507
Validation loss: 1.9732112435884372

Epoch: 5| Step: 1
Training loss: 1.149039387702942
Validation loss: 1.9541183953644128

Epoch: 5| Step: 2
Training loss: 0.7791133522987366
Validation loss: 1.9520955457482287

Epoch: 5| Step: 3
Training loss: 1.4624888896942139
Validation loss: 1.9521246212784962

Epoch: 5| Step: 4
Training loss: 1.087339997291565
Validation loss: 1.987861192354592

Epoch: 5| Step: 5
Training loss: 1.429734468460083
Validation loss: 2.020130375380157

Epoch: 5| Step: 6
Training loss: 0.986676812171936
Validation loss: 2.011397647601302

Epoch: 5| Step: 7
Training loss: 0.9497528076171875
Validation loss: 2.0651376683224916

Epoch: 5| Step: 8
Training loss: 1.354910135269165
Validation loss: 2.0906499995980212

Epoch: 5| Step: 9
Training loss: 1.3732995986938477
Validation loss: 2.1213359320035545

Epoch: 5| Step: 10
Training loss: 0.4131228029727936
Validation loss: 2.1618818339481147

Epoch: 201| Step: 0
Training loss: 1.2200008630752563
Validation loss: 2.171586903192664

Epoch: 5| Step: 1
Training loss: 1.3354015350341797
Validation loss: 2.141293587223176

Epoch: 5| Step: 2
Training loss: 0.46978408098220825
Validation loss: 2.080682844244024

Epoch: 5| Step: 3
Training loss: 0.9787899851799011
Validation loss: 2.000666532465207

Epoch: 5| Step: 4
Training loss: 1.258610486984253
Validation loss: 1.966674748287406

Epoch: 5| Step: 5
Training loss: 0.820094108581543
Validation loss: 1.9394508228507092

Epoch: 5| Step: 6
Training loss: 1.2723371982574463
Validation loss: 1.9230060859393048

Epoch: 5| Step: 7
Training loss: 1.2502514123916626
Validation loss: 1.94602237209197

Epoch: 5| Step: 8
Training loss: 1.102738618850708
Validation loss: 1.9806844213957429

Epoch: 5| Step: 9
Training loss: 1.080268144607544
Validation loss: 1.9944331389601513

Epoch: 5| Step: 10
Training loss: 0.8899804949760437
Validation loss: 2.023399140245171

Epoch: 202| Step: 0
Training loss: 1.0747089385986328
Validation loss: 2.040920412668618

Epoch: 5| Step: 1
Training loss: 1.4118014574050903
Validation loss: 2.0601220079647597

Epoch: 5| Step: 2
Training loss: 1.3244032859802246
Validation loss: 2.0469713031604724

Epoch: 5| Step: 3
Training loss: 1.0110008716583252
Validation loss: 2.0327558248273787

Epoch: 5| Step: 4
Training loss: 0.8625245094299316
Validation loss: 2.00424974964511

Epoch: 5| Step: 5
Training loss: 0.9023378491401672
Validation loss: 1.9762378649045063

Epoch: 5| Step: 6
Training loss: 1.3322597742080688
Validation loss: 1.9395428319131174

Epoch: 5| Step: 7
Training loss: 0.6649397015571594
Validation loss: 1.9849943525047713

Epoch: 5| Step: 8
Training loss: 0.798303484916687
Validation loss: 1.9824221223913214

Epoch: 5| Step: 9
Training loss: 0.9735231399536133
Validation loss: 1.9990637443398918

Epoch: 5| Step: 10
Training loss: 1.2331891059875488
Validation loss: 2.0641076590425227

Epoch: 203| Step: 0
Training loss: 0.720798134803772
Validation loss: 2.1095869669350247

Epoch: 5| Step: 1
Training loss: 0.7698245048522949
Validation loss: 2.1712433599656626

Epoch: 5| Step: 2
Training loss: 0.5561347603797913
Validation loss: 2.15208875748419

Epoch: 5| Step: 3
Training loss: 1.2657701969146729
Validation loss: 2.0797727095183505

Epoch: 5| Step: 4
Training loss: 0.8941830396652222
Validation loss: 2.0198852041716218

Epoch: 5| Step: 5
Training loss: 0.7418094873428345
Validation loss: 2.0059696320564515

Epoch: 5| Step: 6
Training loss: 1.0044835805892944
Validation loss: 1.9685136169515631

Epoch: 5| Step: 7
Training loss: 1.2034348249435425
Validation loss: 1.9528144559552592

Epoch: 5| Step: 8
Training loss: 1.1792024374008179
Validation loss: 1.968742327023578

Epoch: 5| Step: 9
Training loss: 1.1647186279296875
Validation loss: 1.9929322914410663

Epoch: 5| Step: 10
Training loss: 1.6809545755386353
Validation loss: 1.9745253568054528

Epoch: 204| Step: 0
Training loss: 1.3009828329086304
Validation loss: 1.9839253681962208

Epoch: 5| Step: 1
Training loss: 1.1255817413330078
Validation loss: 1.9695481382390505

Epoch: 5| Step: 2
Training loss: 0.7930466532707214
Validation loss: 2.0016180340961744

Epoch: 5| Step: 3
Training loss: 1.111288070678711
Validation loss: 2.022060812160533

Epoch: 5| Step: 4
Training loss: 0.8177277445793152
Validation loss: 1.998870554790702

Epoch: 5| Step: 5
Training loss: 1.0893083810806274
Validation loss: 2.050073590329898

Epoch: 5| Step: 6
Training loss: 0.7201805114746094
Validation loss: 2.0825085281043925

Epoch: 5| Step: 7
Training loss: 1.0533559322357178
Validation loss: 2.082074167907879

Epoch: 5| Step: 8
Training loss: 0.8928385972976685
Validation loss: 2.0480437150565525

Epoch: 5| Step: 9
Training loss: 1.3697999715805054
Validation loss: 2.059142297314059

Epoch: 5| Step: 10
Training loss: 0.8420746326446533
Validation loss: 2.052914216954221

Epoch: 205| Step: 0
Training loss: 1.0915964841842651
Validation loss: 2.0202641307666735

Epoch: 5| Step: 1
Training loss: 1.113416075706482
Validation loss: 1.9874771025873

Epoch: 5| Step: 2
Training loss: 0.9032249450683594
Validation loss: 1.9524119771936888

Epoch: 5| Step: 3
Training loss: 0.9613730311393738
Validation loss: 1.9177610258902273

Epoch: 5| Step: 4
Training loss: 0.9078156352043152
Validation loss: 1.933534929829259

Epoch: 5| Step: 5
Training loss: 1.3431406021118164
Validation loss: 1.9609934206931823

Epoch: 5| Step: 6
Training loss: 0.8950017690658569
Validation loss: 1.9710288278518184

Epoch: 5| Step: 7
Training loss: 1.2690188884735107
Validation loss: 1.998266666166244

Epoch: 5| Step: 8
Training loss: 0.9412554502487183
Validation loss: 2.0655853594503095

Epoch: 5| Step: 9
Training loss: 1.1040838956832886
Validation loss: 2.0900317186950357

Epoch: 5| Step: 10
Training loss: 1.1217340230941772
Validation loss: 2.0851135151360625

Epoch: 206| Step: 0
Training loss: 1.3033692836761475
Validation loss: 2.077046626357622

Epoch: 5| Step: 1
Training loss: 0.8361383676528931
Validation loss: 2.028046024742947

Epoch: 5| Step: 2
Training loss: 0.7407106161117554
Validation loss: 2.024579789048882

Epoch: 5| Step: 3
Training loss: 1.0536969900131226
Validation loss: 1.947027543539642

Epoch: 5| Step: 4
Training loss: 1.2693802118301392
Validation loss: 1.9409762877289967

Epoch: 5| Step: 5
Training loss: 1.1763635873794556
Validation loss: 1.9251016404039116

Epoch: 5| Step: 6
Training loss: 0.629204273223877
Validation loss: 1.9083340603818175

Epoch: 5| Step: 7
Training loss: 1.1168662309646606
Validation loss: 1.9312435914111394

Epoch: 5| Step: 8
Training loss: 0.6535583734512329
Validation loss: 1.9293736975680116

Epoch: 5| Step: 9
Training loss: 0.9290655851364136
Validation loss: 2.0164585446798675

Epoch: 5| Step: 10
Training loss: 1.61415433883667
Validation loss: 2.0210912830086163

Epoch: 207| Step: 0
Training loss: 1.349556803703308
Validation loss: 2.057790695980031

Epoch: 5| Step: 1
Training loss: 1.3757165670394897
Validation loss: 2.1480437196711057

Epoch: 5| Step: 2
Training loss: 0.8717073202133179
Validation loss: 2.1174040045789493

Epoch: 5| Step: 3
Training loss: 1.1351326704025269
Validation loss: 2.0787400173884567

Epoch: 5| Step: 4
Training loss: 1.1856319904327393
Validation loss: 2.043727710682859

Epoch: 5| Step: 5
Training loss: 0.7531408071517944
Validation loss: 1.9511732042476695

Epoch: 5| Step: 6
Training loss: 1.2806756496429443
Validation loss: 1.9445087179060905

Epoch: 5| Step: 7
Training loss: 1.24355149269104
Validation loss: 1.9116468019382928

Epoch: 5| Step: 8
Training loss: 0.5717337727546692
Validation loss: 1.9215978499381774

Epoch: 5| Step: 9
Training loss: 1.0650250911712646
Validation loss: 1.9182092374370945

Epoch: 5| Step: 10
Training loss: 0.41965585947036743
Validation loss: 1.9663964407418364

Epoch: 208| Step: 0
Training loss: 0.957751452922821
Validation loss: 2.0078922035873576

Epoch: 5| Step: 1
Training loss: 0.9774625897407532
Validation loss: 2.043584474953272

Epoch: 5| Step: 2
Training loss: 1.3516826629638672
Validation loss: 2.0713992157290058

Epoch: 5| Step: 3
Training loss: 0.7786663770675659
Validation loss: 2.0517605222681516

Epoch: 5| Step: 4
Training loss: 0.9967754483222961
Validation loss: 2.0612454504095097

Epoch: 5| Step: 5
Training loss: 0.8309694528579712
Validation loss: 2.0529897110436552

Epoch: 5| Step: 6
Training loss: 0.8524256944656372
Validation loss: 2.022415525169783

Epoch: 5| Step: 7
Training loss: 1.3559746742248535
Validation loss: 1.9892099903475853

Epoch: 5| Step: 8
Training loss: 1.2227296829223633
Validation loss: 1.9590850530132171

Epoch: 5| Step: 9
Training loss: 0.6330398321151733
Validation loss: 1.9422354698181152

Epoch: 5| Step: 10
Training loss: 0.7618354558944702
Validation loss: 1.8870288018257386

Epoch: 209| Step: 0
Training loss: 1.0923868417739868
Validation loss: 1.9009897478165165

Epoch: 5| Step: 1
Training loss: 1.3283329010009766
Validation loss: 1.9071539883972497

Epoch: 5| Step: 2
Training loss: 0.8478549122810364
Validation loss: 1.9688304701159078

Epoch: 5| Step: 3
Training loss: 0.5588509440422058
Validation loss: 1.9834571320523497

Epoch: 5| Step: 4
Training loss: 0.9560171365737915
Validation loss: 2.0002543208419636

Epoch: 5| Step: 5
Training loss: 1.3840317726135254
Validation loss: 2.067917705864035

Epoch: 5| Step: 6
Training loss: 0.9688836336135864
Validation loss: 2.0964999762914514

Epoch: 5| Step: 7
Training loss: 0.9871547818183899
Validation loss: 2.1025837775199645

Epoch: 5| Step: 8
Training loss: 0.7963653802871704
Validation loss: 2.0917716436488654

Epoch: 5| Step: 9
Training loss: 0.6960595846176147
Validation loss: 2.01126362944162

Epoch: 5| Step: 10
Training loss: 1.0086052417755127
Validation loss: 1.9555747662821124

Epoch: 210| Step: 0
Training loss: 0.7505382299423218
Validation loss: 1.8843592366864603

Epoch: 5| Step: 1
Training loss: 1.0710108280181885
Validation loss: 1.9418565073320944

Epoch: 5| Step: 2
Training loss: 1.1606262922286987
Validation loss: 1.9606559058671356

Epoch: 5| Step: 3
Training loss: 1.1630637645721436
Validation loss: 1.937973335225095

Epoch: 5| Step: 4
Training loss: 0.9523946046829224
Validation loss: 1.9540349732163131

Epoch: 5| Step: 5
Training loss: 0.9146913290023804
Validation loss: 1.916057009850779

Epoch: 5| Step: 6
Training loss: 1.2497918605804443
Validation loss: 1.917146034138177

Epoch: 5| Step: 7
Training loss: 0.7122151851654053
Validation loss: 1.9118620567424323

Epoch: 5| Step: 8
Training loss: 0.7247260212898254
Validation loss: 1.9713392398690666

Epoch: 5| Step: 9
Training loss: 1.3005845546722412
Validation loss: 2.0150648816939323

Epoch: 5| Step: 10
Training loss: 0.9366788268089294
Validation loss: 2.0321181948466966

Epoch: 211| Step: 0
Training loss: 1.170270323753357
Validation loss: 2.056251000332576

Epoch: 5| Step: 1
Training loss: 0.8446565866470337
Validation loss: 2.0396560750981814

Epoch: 5| Step: 2
Training loss: 0.48190516233444214
Validation loss: 1.9630443024378952

Epoch: 5| Step: 3
Training loss: 0.8492868542671204
Validation loss: 1.9292464487014278

Epoch: 5| Step: 4
Training loss: 1.5875027179718018
Validation loss: 1.93115565212824

Epoch: 5| Step: 5
Training loss: 1.23135507106781
Validation loss: 1.9255837496890817

Epoch: 5| Step: 6
Training loss: 1.0313631296157837
Validation loss: 1.9404919173127861

Epoch: 5| Step: 7
Training loss: 0.8654535412788391
Validation loss: 1.8972423909812846

Epoch: 5| Step: 8
Training loss: 0.9808835983276367
Validation loss: 1.935149101800816

Epoch: 5| Step: 9
Training loss: 0.8448652029037476
Validation loss: 1.9729918984956638

Epoch: 5| Step: 10
Training loss: 0.7949262261390686
Validation loss: 2.021329418305428

Epoch: 212| Step: 0
Training loss: 1.079755187034607
Validation loss: 2.014408657627721

Epoch: 5| Step: 1
Training loss: 1.049688696861267
Validation loss: 2.016665154887784

Epoch: 5| Step: 2
Training loss: 0.6858901381492615
Validation loss: 1.964822776855961

Epoch: 5| Step: 3
Training loss: 0.967973530292511
Validation loss: 1.9450448687358568

Epoch: 5| Step: 4
Training loss: 0.9568923711776733
Validation loss: 1.8818730923437303

Epoch: 5| Step: 5
Training loss: 0.9954071044921875
Validation loss: 1.8395174998109058

Epoch: 5| Step: 6
Training loss: 0.718859851360321
Validation loss: 1.8400440882611018

Epoch: 5| Step: 7
Training loss: 0.8815194368362427
Validation loss: 1.839457417047152

Epoch: 5| Step: 8
Training loss: 1.19310462474823
Validation loss: 1.9029930009636828

Epoch: 5| Step: 9
Training loss: 1.4263246059417725
Validation loss: 1.9746157174469323

Epoch: 5| Step: 10
Training loss: 1.2135721445083618
Validation loss: 2.0327403353106592

Epoch: 213| Step: 0
Training loss: 1.0669610500335693
Validation loss: 2.0318075431290494

Epoch: 5| Step: 1
Training loss: 1.0951083898544312
Validation loss: 2.0565739036888204

Epoch: 5| Step: 2
Training loss: 1.1712480783462524
Validation loss: 2.01858074690706

Epoch: 5| Step: 3
Training loss: 0.9345905184745789
Validation loss: 2.0265443004587644

Epoch: 5| Step: 4
Training loss: 0.6799296736717224
Validation loss: 1.9890812212421047

Epoch: 5| Step: 5
Training loss: 1.116787314414978
Validation loss: 1.9149748715021278

Epoch: 5| Step: 6
Training loss: 0.9998143911361694
Validation loss: 1.881252299072922

Epoch: 5| Step: 7
Training loss: 1.0850764513015747
Validation loss: 1.8770487308502197

Epoch: 5| Step: 8
Training loss: 1.0211713314056396
Validation loss: 1.9064557552337646

Epoch: 5| Step: 9
Training loss: 0.6366823315620422
Validation loss: 1.901384626665423

Epoch: 5| Step: 10
Training loss: 0.9437574744224548
Validation loss: 1.9149895867993754

Epoch: 214| Step: 0
Training loss: 1.1323862075805664
Validation loss: 1.9544908820941884

Epoch: 5| Step: 1
Training loss: 1.4365252256393433
Validation loss: 2.0209759896801365

Epoch: 5| Step: 2
Training loss: 1.383862853050232
Validation loss: 2.0164707681184173

Epoch: 5| Step: 3
Training loss: 0.8774884939193726
Validation loss: 1.9947814018495622

Epoch: 5| Step: 4
Training loss: 0.8952862024307251
Validation loss: 2.0242323516517557

Epoch: 5| Step: 5
Training loss: 0.9406042098999023
Validation loss: 1.9992768636313818

Epoch: 5| Step: 6
Training loss: 0.8508065342903137
Validation loss: 1.961704013168171

Epoch: 5| Step: 7
Training loss: 0.8762186169624329
Validation loss: 1.9806911330069266

Epoch: 5| Step: 8
Training loss: 0.7473989725112915
Validation loss: 1.978464703406057

Epoch: 5| Step: 9
Training loss: 0.7809370756149292
Validation loss: 2.0054914771869616

Epoch: 5| Step: 10
Training loss: 0.8203277587890625
Validation loss: 2.0199384048420894

Epoch: 215| Step: 0
Training loss: 0.9264548420906067
Validation loss: 1.9750722608258646

Epoch: 5| Step: 1
Training loss: 1.1204391717910767
Validation loss: 1.9597277026022635

Epoch: 5| Step: 2
Training loss: 1.4625422954559326
Validation loss: 1.9546378671482045

Epoch: 5| Step: 3
Training loss: 0.7765199542045593
Validation loss: 2.005862771823842

Epoch: 5| Step: 4
Training loss: 0.6389133334159851
Validation loss: 2.0209024644667104

Epoch: 5| Step: 5
Training loss: 1.068805456161499
Validation loss: 2.058866067599225

Epoch: 5| Step: 6
Training loss: 1.0455114841461182
Validation loss: 2.052327117612285

Epoch: 5| Step: 7
Training loss: 1.0984402894973755
Validation loss: 2.0005895783824306

Epoch: 5| Step: 8
Training loss: 0.5983540415763855
Validation loss: 1.9627909301429667

Epoch: 5| Step: 9
Training loss: 1.2125461101531982
Validation loss: 1.9193085778144099

Epoch: 5| Step: 10
Training loss: 0.4067174196243286
Validation loss: 1.8898377982519006

Epoch: 216| Step: 0
Training loss: 0.8922966718673706
Validation loss: 1.903643472220308

Epoch: 5| Step: 1
Training loss: 0.7775797843933105
Validation loss: 1.9233273152382142

Epoch: 5| Step: 2
Training loss: 0.9980930089950562
Validation loss: 1.9444451870456818

Epoch: 5| Step: 3
Training loss: 1.0106313228607178
Validation loss: 1.9216235324900637

Epoch: 5| Step: 4
Training loss: 0.8584555387496948
Validation loss: 1.985957512291529

Epoch: 5| Step: 5
Training loss: 1.5237922668457031
Validation loss: 1.9632232676270187

Epoch: 5| Step: 6
Training loss: 0.5728126764297485
Validation loss: 1.9920003055244364

Epoch: 5| Step: 7
Training loss: 0.7347173690795898
Validation loss: 2.0118370632971487

Epoch: 5| Step: 8
Training loss: 1.1420446634292603
Validation loss: 2.016871565131731

Epoch: 5| Step: 9
Training loss: 0.935315728187561
Validation loss: 1.9884941385638328

Epoch: 5| Step: 10
Training loss: 0.600511908531189
Validation loss: 1.9779395313673123

Epoch: 217| Step: 0
Training loss: 1.3096998929977417
Validation loss: 1.9314864091975714

Epoch: 5| Step: 1
Training loss: 0.6440209150314331
Validation loss: 1.9209826415584934

Epoch: 5| Step: 2
Training loss: 0.8617660403251648
Validation loss: 1.8965056583445559

Epoch: 5| Step: 3
Training loss: 1.0447356700897217
Validation loss: 1.8906645287749588

Epoch: 5| Step: 4
Training loss: 0.7905654907226562
Validation loss: 1.8931675713549379

Epoch: 5| Step: 5
Training loss: 1.1419315338134766
Validation loss: 1.8813257345589258

Epoch: 5| Step: 6
Training loss: 0.5647867918014526
Validation loss: 1.927861390575286

Epoch: 5| Step: 7
Training loss: 0.7438660860061646
Validation loss: 1.9668864434765232

Epoch: 5| Step: 8
Training loss: 0.7623870372772217
Validation loss: 2.0326419825194986

Epoch: 5| Step: 9
Training loss: 1.246931552886963
Validation loss: 2.0228709738741637

Epoch: 5| Step: 10
Training loss: 1.0430370569229126
Validation loss: 2.033803642437022

Epoch: 218| Step: 0
Training loss: 0.9298681020736694
Validation loss: 2.032089106498226

Epoch: 5| Step: 1
Training loss: 1.301276445388794
Validation loss: 1.992637090785529

Epoch: 5| Step: 2
Training loss: 0.8181066513061523
Validation loss: 1.9881781942100936

Epoch: 5| Step: 3
Training loss: 1.0386159420013428
Validation loss: 1.9515501042847991

Epoch: 5| Step: 4
Training loss: 0.634209394454956
Validation loss: 1.9462004092431837

Epoch: 5| Step: 5
Training loss: 0.9140788912773132
Validation loss: 1.9407018897353963

Epoch: 5| Step: 6
Training loss: 0.8968172073364258
Validation loss: 1.935242606747535

Epoch: 5| Step: 7
Training loss: 0.9965766072273254
Validation loss: 1.9611797473763908

Epoch: 5| Step: 8
Training loss: 0.9512316584587097
Validation loss: 1.965181707054056

Epoch: 5| Step: 9
Training loss: 0.6624585390090942
Validation loss: 1.92705169288061

Epoch: 5| Step: 10
Training loss: 0.49718984961509705
Validation loss: 1.9224132337877828

Epoch: 219| Step: 0
Training loss: 0.9495153427124023
Validation loss: 1.9438246847480856

Epoch: 5| Step: 1
Training loss: 0.8716924786567688
Validation loss: 1.9514237014196252

Epoch: 5| Step: 2
Training loss: 1.112007975578308
Validation loss: 1.979643080824165

Epoch: 5| Step: 3
Training loss: 0.5028687119483948
Validation loss: 1.9889314520743586

Epoch: 5| Step: 4
Training loss: 0.6458135843276978
Validation loss: 2.0623015588329685

Epoch: 5| Step: 5
Training loss: 0.8707295656204224
Validation loss: 2.116702328446091

Epoch: 5| Step: 6
Training loss: 0.8432113528251648
Validation loss: 2.102998641229445

Epoch: 5| Step: 7
Training loss: 0.6880677938461304
Validation loss: 2.00914986800122

Epoch: 5| Step: 8
Training loss: 0.8462053537368774
Validation loss: 1.937643507475494

Epoch: 5| Step: 9
Training loss: 1.2711374759674072
Validation loss: 1.8524171806150866

Epoch: 5| Step: 10
Training loss: 1.3551772832870483
Validation loss: 1.8443529311046805

Epoch: 220| Step: 0
Training loss: 0.7992725372314453
Validation loss: 1.8392492391729867

Epoch: 5| Step: 1
Training loss: 0.8586422801017761
Validation loss: 1.8120843787347116

Epoch: 5| Step: 2
Training loss: 1.2055398225784302
Validation loss: 1.841133721413151

Epoch: 5| Step: 3
Training loss: 0.7434090375900269
Validation loss: 1.8970253108650126

Epoch: 5| Step: 4
Training loss: 0.7305126190185547
Validation loss: 1.9331548406231789

Epoch: 5| Step: 5
Training loss: 0.9277036786079407
Validation loss: 2.0146401902680755

Epoch: 5| Step: 6
Training loss: 1.1414175033569336
Validation loss: 2.0807836414665304

Epoch: 5| Step: 7
Training loss: 1.084365725517273
Validation loss: 2.0874926069731354

Epoch: 5| Step: 8
Training loss: 0.5049052834510803
Validation loss: 2.081922725964618

Epoch: 5| Step: 9
Training loss: 1.1922028064727783
Validation loss: 2.033169754089848

Epoch: 5| Step: 10
Training loss: 1.109937071800232
Validation loss: 1.9603329679017425

Epoch: 221| Step: 0
Training loss: 0.6917495727539062
Validation loss: 1.9176673645614295

Epoch: 5| Step: 1
Training loss: 1.2566769123077393
Validation loss: 1.8879478259753155

Epoch: 5| Step: 2
Training loss: 1.280347466468811
Validation loss: 1.889395498460339

Epoch: 5| Step: 3
Training loss: 0.5325523614883423
Validation loss: 1.8831510108004335

Epoch: 5| Step: 4
Training loss: 0.9225185513496399
Validation loss: 1.8858735048642723

Epoch: 5| Step: 5
Training loss: 0.8308441042900085
Validation loss: 1.8225001981181483

Epoch: 5| Step: 6
Training loss: 0.7658834457397461
Validation loss: 1.8869509184232323

Epoch: 5| Step: 7
Training loss: 1.029131293296814
Validation loss: 1.9164765470771379

Epoch: 5| Step: 8
Training loss: 1.0843641757965088
Validation loss: 1.9224335903762488

Epoch: 5| Step: 9
Training loss: 0.7127605676651001
Validation loss: 1.96147019632401

Epoch: 5| Step: 10
Training loss: 1.2419780492782593
Validation loss: 1.993873485954859

Epoch: 222| Step: 0
Training loss: 1.1692346334457397
Validation loss: 2.0171818707578923

Epoch: 5| Step: 1
Training loss: 1.1175661087036133
Validation loss: 2.0308997143981276

Epoch: 5| Step: 2
Training loss: 0.9888625144958496
Validation loss: 1.9579828682766165

Epoch: 5| Step: 3
Training loss: 0.8542943000793457
Validation loss: 1.8841194375868766

Epoch: 5| Step: 4
Training loss: 1.2707631587982178
Validation loss: 1.849329771534089

Epoch: 5| Step: 5
Training loss: 0.5264378786087036
Validation loss: 1.8357284722789642

Epoch: 5| Step: 6
Training loss: 0.8258188366889954
Validation loss: 1.849556290975181

Epoch: 5| Step: 7
Training loss: 0.7660263180732727
Validation loss: 1.8535933545840684

Epoch: 5| Step: 8
Training loss: 1.011344313621521
Validation loss: 1.8711692889531453

Epoch: 5| Step: 9
Training loss: 0.899127185344696
Validation loss: 1.8967093165202806

Epoch: 5| Step: 10
Training loss: 0.7628293037414551
Validation loss: 1.917205402928014

Epoch: 223| Step: 0
Training loss: 0.8944723010063171
Validation loss: 1.9300552375854985

Epoch: 5| Step: 1
Training loss: 0.6842816472053528
Validation loss: 1.914974953538628

Epoch: 5| Step: 2
Training loss: 1.1660970449447632
Validation loss: 1.8817971893536147

Epoch: 5| Step: 3
Training loss: 1.1785924434661865
Validation loss: 1.903794950054538

Epoch: 5| Step: 4
Training loss: 0.728595495223999
Validation loss: 1.9078860436716387

Epoch: 5| Step: 5
Training loss: 0.8125432729721069
Validation loss: 1.8952865305767264

Epoch: 5| Step: 6
Training loss: 1.0771602392196655
Validation loss: 1.892385939116119

Epoch: 5| Step: 7
Training loss: 0.6419277787208557
Validation loss: 1.932521899541219

Epoch: 5| Step: 8
Training loss: 0.9861078262329102
Validation loss: 1.9210706077596194

Epoch: 5| Step: 9
Training loss: 0.7493039965629578
Validation loss: 1.923182951506748

Epoch: 5| Step: 10
Training loss: 0.5967534780502319
Validation loss: 1.917735275401864

Epoch: 224| Step: 0
Training loss: 0.5277003645896912
Validation loss: 1.8427442965968963

Epoch: 5| Step: 1
Training loss: 1.1349279880523682
Validation loss: 1.8669522500807239

Epoch: 5| Step: 2
Training loss: 1.0234618186950684
Validation loss: 1.809223057121359

Epoch: 5| Step: 3
Training loss: 0.6636342406272888
Validation loss: 1.8580669254385016

Epoch: 5| Step: 4
Training loss: 0.8167634010314941
Validation loss: 1.8566327389850412

Epoch: 5| Step: 5
Training loss: 0.7793478965759277
Validation loss: 1.8547580908703547

Epoch: 5| Step: 6
Training loss: 0.6706699132919312
Validation loss: 1.9186820496794998

Epoch: 5| Step: 7
Training loss: 1.2378273010253906
Validation loss: 1.9085758398937922

Epoch: 5| Step: 8
Training loss: 0.7274181246757507
Validation loss: 1.9089921533420522

Epoch: 5| Step: 9
Training loss: 0.8947221636772156
Validation loss: 1.9043372754127748

Epoch: 5| Step: 10
Training loss: 0.5813770294189453
Validation loss: 1.9058575053368845

Epoch: 225| Step: 0
Training loss: 0.9543158411979675
Validation loss: 1.9063629706700642

Epoch: 5| Step: 1
Training loss: 0.8462842106819153
Validation loss: 1.8940826282706311

Epoch: 5| Step: 2
Training loss: 0.7220312356948853
Validation loss: 1.8516686334404895

Epoch: 5| Step: 3
Training loss: 0.6437368988990784
Validation loss: 1.8828049500783284

Epoch: 5| Step: 4
Training loss: 0.5616632103919983
Validation loss: 1.8472390149229316

Epoch: 5| Step: 5
Training loss: 0.955891489982605
Validation loss: 1.8659063654561197

Epoch: 5| Step: 6
Training loss: 1.0413497686386108
Validation loss: 1.8403654034419725

Epoch: 5| Step: 7
Training loss: 0.6669923067092896
Validation loss: 1.8483435594907371

Epoch: 5| Step: 8
Training loss: 1.0373244285583496
Validation loss: 1.8779513964089014

Epoch: 5| Step: 9
Training loss: 0.5843173265457153
Validation loss: 1.8723831253667031

Epoch: 5| Step: 10
Training loss: 0.9444390535354614
Validation loss: 1.9346912804470267

Epoch: 226| Step: 0
Training loss: 0.7168970704078674
Validation loss: 1.9040427323310607

Epoch: 5| Step: 1
Training loss: 0.3735920190811157
Validation loss: 1.9284279538739113

Epoch: 5| Step: 2
Training loss: 0.9636263847351074
Validation loss: 1.901699560944752

Epoch: 5| Step: 3
Training loss: 0.788235068321228
Validation loss: 1.9732919367410804

Epoch: 5| Step: 4
Training loss: 0.8085777163505554
Validation loss: 1.9788287826763686

Epoch: 5| Step: 5
Training loss: 1.0051393508911133
Validation loss: 1.9273172527231195

Epoch: 5| Step: 6
Training loss: 1.0644348859786987
Validation loss: 1.9372928655275734

Epoch: 5| Step: 7
Training loss: 0.9713315963745117
Validation loss: 1.8783313638420516

Epoch: 5| Step: 8
Training loss: 0.8404079675674438
Validation loss: 1.8399742662265737

Epoch: 5| Step: 9
Training loss: 0.7488505244255066
Validation loss: 1.8702798017891504

Epoch: 5| Step: 10
Training loss: 0.669804036617279
Validation loss: 1.8498825193733297

Epoch: 227| Step: 0
Training loss: 0.5322281122207642
Validation loss: 1.8313415435052687

Epoch: 5| Step: 1
Training loss: 0.8529464602470398
Validation loss: 1.8582034469932638

Epoch: 5| Step: 2
Training loss: 0.9203839302062988
Validation loss: 1.8801470520675823

Epoch: 5| Step: 3
Training loss: 0.9987720251083374
Validation loss: 1.9032407050491662

Epoch: 5| Step: 4
Training loss: 0.7544426918029785
Validation loss: 1.9240436771864533

Epoch: 5| Step: 5
Training loss: 0.9738060235977173
Validation loss: 1.9494102206281436

Epoch: 5| Step: 6
Training loss: 0.9294502139091492
Validation loss: 1.9985409270050705

Epoch: 5| Step: 7
Training loss: 0.7924004793167114
Validation loss: 1.9786425252114572

Epoch: 5| Step: 8
Training loss: 0.6425794363021851
Validation loss: 1.9727771282196045

Epoch: 5| Step: 9
Training loss: 1.0257834196090698
Validation loss: 1.94216178694079

Epoch: 5| Step: 10
Training loss: 0.7361359000205994
Validation loss: 1.9297966341818533

Epoch: 228| Step: 0
Training loss: 0.4599824845790863
Validation loss: 1.896929323032338

Epoch: 5| Step: 1
Training loss: 1.3006043434143066
Validation loss: 1.882310910891461

Epoch: 5| Step: 2
Training loss: 1.0640851259231567
Validation loss: 1.8826563973580637

Epoch: 5| Step: 3
Training loss: 0.7007492780685425
Validation loss: 1.871323803419708

Epoch: 5| Step: 4
Training loss: 0.7407907247543335
Validation loss: 1.8680221713999265

Epoch: 5| Step: 5
Training loss: 0.7347406148910522
Validation loss: 1.885139399959195

Epoch: 5| Step: 6
Training loss: 0.7472981214523315
Validation loss: 1.8577128687212545

Epoch: 5| Step: 7
Training loss: 1.0814476013183594
Validation loss: 1.8706925786951536

Epoch: 5| Step: 8
Training loss: 0.6484235525131226
Validation loss: 1.8767885187620759

Epoch: 5| Step: 9
Training loss: 0.9611479043960571
Validation loss: 1.8813878746442898

Epoch: 5| Step: 10
Training loss: 0.5767144560813904
Validation loss: 1.900426431368756

Epoch: 229| Step: 0
Training loss: 0.8675199747085571
Validation loss: 1.9231722765071417

Epoch: 5| Step: 1
Training loss: 0.6568759083747864
Validation loss: 1.8990669788852814

Epoch: 5| Step: 2
Training loss: 0.5279895067214966
Validation loss: 1.9031250169200282

Epoch: 5| Step: 3
Training loss: 0.9495555758476257
Validation loss: 1.9322192617641982

Epoch: 5| Step: 4
Training loss: 0.7963191866874695
Validation loss: 1.8971123003190564

Epoch: 5| Step: 5
Training loss: 0.7598341703414917
Validation loss: 1.8703710238138835

Epoch: 5| Step: 6
Training loss: 1.3164055347442627
Validation loss: 1.8566400312608289

Epoch: 5| Step: 7
Training loss: 0.6401562690734863
Validation loss: 1.80837683908401

Epoch: 5| Step: 8
Training loss: 1.0074808597564697
Validation loss: 1.8136660309248074

Epoch: 5| Step: 9
Training loss: 0.6939448118209839
Validation loss: 1.828554904589089

Epoch: 5| Step: 10
Training loss: 0.6403086185455322
Validation loss: 1.882056256776215

Epoch: 230| Step: 0
Training loss: 0.9503439664840698
Validation loss: 1.8939965681363178

Epoch: 5| Step: 1
Training loss: 0.8765274286270142
Validation loss: 1.9217739079588203

Epoch: 5| Step: 2
Training loss: 0.8609092831611633
Validation loss: 1.9214646316343738

Epoch: 5| Step: 3
Training loss: 1.1190197467803955
Validation loss: 1.9571662359340216

Epoch: 5| Step: 4
Training loss: 0.5121064186096191
Validation loss: 2.0420136349175566

Epoch: 5| Step: 5
Training loss: 0.7392732501029968
Validation loss: 2.0261808364622054

Epoch: 5| Step: 6
Training loss: 0.9554246068000793
Validation loss: 1.959231065165612

Epoch: 5| Step: 7
Training loss: 0.9715116620063782
Validation loss: 1.908188141802306

Epoch: 5| Step: 8
Training loss: 0.49444159865379333
Validation loss: 1.8205599233668337

Epoch: 5| Step: 9
Training loss: 1.1189002990722656
Validation loss: 1.8503118304796116

Epoch: 5| Step: 10
Training loss: 0.7638400197029114
Validation loss: 1.8204686795511553

Epoch: 231| Step: 0
Training loss: 0.8550108075141907
Validation loss: 1.8767539070498558

Epoch: 5| Step: 1
Training loss: 1.116996169090271
Validation loss: 1.9220543061533282

Epoch: 5| Step: 2
Training loss: 0.9490949511528015
Validation loss: 1.963639360602184

Epoch: 5| Step: 3
Training loss: 0.44491347670555115
Validation loss: 1.9375587970979753

Epoch: 5| Step: 4
Training loss: 0.5411803126335144
Validation loss: 1.9962192081635999

Epoch: 5| Step: 5
Training loss: 0.7694755792617798
Validation loss: 1.922177424994848

Epoch: 5| Step: 6
Training loss: 0.7947531938552856
Validation loss: 1.8754852458994875

Epoch: 5| Step: 7
Training loss: 0.8969645500183105
Validation loss: 1.8522799438045872

Epoch: 5| Step: 8
Training loss: 0.7996889352798462
Validation loss: 1.8394547303517659

Epoch: 5| Step: 9
Training loss: 0.823667049407959
Validation loss: 1.7623900098185385

Epoch: 5| Step: 10
Training loss: 1.1033774614334106
Validation loss: 1.7656687946729763

Epoch: 232| Step: 0
Training loss: 0.7562931776046753
Validation loss: 1.7832765104950115

Epoch: 5| Step: 1
Training loss: 0.8615385293960571
Validation loss: 1.787732643465842

Epoch: 5| Step: 2
Training loss: 0.9558144807815552
Validation loss: 1.7765988944679179

Epoch: 5| Step: 3
Training loss: 0.8051173090934753
Validation loss: 1.8307156396168534

Epoch: 5| Step: 4
Training loss: 0.48133915662765503
Validation loss: 1.8501963769235918

Epoch: 5| Step: 5
Training loss: 0.9144339561462402
Validation loss: 1.8474654984730545

Epoch: 5| Step: 6
Training loss: 0.7533721327781677
Validation loss: 1.9005672149760748

Epoch: 5| Step: 7
Training loss: 0.606046736240387
Validation loss: 1.9029345743117794

Epoch: 5| Step: 8
Training loss: 0.8157171010971069
Validation loss: 1.9503525585256598

Epoch: 5| Step: 9
Training loss: 0.8839314579963684
Validation loss: 1.9668515587365756

Epoch: 5| Step: 10
Training loss: 0.9712677001953125
Validation loss: 1.9406784683145502

Epoch: 233| Step: 0
Training loss: 0.5107483863830566
Validation loss: 1.903459692514071

Epoch: 5| Step: 1
Training loss: 0.7084419131278992
Validation loss: 1.8494714472883491

Epoch: 5| Step: 2
Training loss: 0.9996097683906555
Validation loss: 1.8364223023896575

Epoch: 5| Step: 3
Training loss: 1.0448520183563232
Validation loss: 1.8141737778981526

Epoch: 5| Step: 4
Training loss: 0.680952250957489
Validation loss: 1.8328367817786433

Epoch: 5| Step: 5
Training loss: 0.8522504568099976
Validation loss: 1.847918612982637

Epoch: 5| Step: 6
Training loss: 0.3983443081378937
Validation loss: 1.8572204010460966

Epoch: 5| Step: 7
Training loss: 0.7267725467681885
Validation loss: 1.908462987151197

Epoch: 5| Step: 8
Training loss: 1.085423231124878
Validation loss: 1.974973722170758

Epoch: 5| Step: 9
Training loss: 0.8671640157699585
Validation loss: 1.9654937777467953

Epoch: 5| Step: 10
Training loss: 0.6068001985549927
Validation loss: 1.9060637335623465

Epoch: 234| Step: 0
Training loss: 0.608462929725647
Validation loss: 1.8709125775162891

Epoch: 5| Step: 1
Training loss: 0.8493639230728149
Validation loss: 1.873512343693805

Epoch: 5| Step: 2
Training loss: 0.9392088651657104
Validation loss: 1.8017367688558434

Epoch: 5| Step: 3
Training loss: 0.711086630821228
Validation loss: 1.8153480073457122

Epoch: 5| Step: 4
Training loss: 0.7793611288070679
Validation loss: 1.804186523601573

Epoch: 5| Step: 5
Training loss: 0.623437762260437
Validation loss: 1.8701546486987863

Epoch: 5| Step: 6
Training loss: 1.041911244392395
Validation loss: 1.8317941106775755

Epoch: 5| Step: 7
Training loss: 0.6133230924606323
Validation loss: 1.8680450672744422

Epoch: 5| Step: 8
Training loss: 0.7322889566421509
Validation loss: 1.9032509621753488

Epoch: 5| Step: 9
Training loss: 0.9442022442817688
Validation loss: 1.9175452250306324

Epoch: 5| Step: 10
Training loss: 0.4497513473033905
Validation loss: 1.9306905026076941

Epoch: 235| Step: 0
Training loss: 0.4085536003112793
Validation loss: 1.9180090478671494

Epoch: 5| Step: 1
Training loss: 0.5615575909614563
Validation loss: 1.8184821810773624

Epoch: 5| Step: 2
Training loss: 0.6843447685241699
Validation loss: 1.8067641591513028

Epoch: 5| Step: 3
Training loss: 0.5833331346511841
Validation loss: 1.7365759662402573

Epoch: 5| Step: 4
Training loss: 0.648607611656189
Validation loss: 1.759918814064354

Epoch: 5| Step: 5
Training loss: 0.6995182037353516
Validation loss: 1.7582693587067306

Epoch: 5| Step: 6
Training loss: 0.9278303384780884
Validation loss: 1.8060482458401752

Epoch: 5| Step: 7
Training loss: 1.166388750076294
Validation loss: 1.8582802459757815

Epoch: 5| Step: 8
Training loss: 0.7570189237594604
Validation loss: 1.8289192620144095

Epoch: 5| Step: 9
Training loss: 0.8844504356384277
Validation loss: 1.8610836485380768

Epoch: 5| Step: 10
Training loss: 1.081247091293335
Validation loss: 1.8523056584019815

Epoch: 236| Step: 0
Training loss: 0.7738878130912781
Validation loss: 1.8752280076344807

Epoch: 5| Step: 1
Training loss: 0.8214093446731567
Validation loss: 1.8525038919141215

Epoch: 5| Step: 2
Training loss: 1.0329384803771973
Validation loss: 1.7862620725426623

Epoch: 5| Step: 3
Training loss: 0.7518705725669861
Validation loss: 1.7540938879853936

Epoch: 5| Step: 4
Training loss: 0.42220354080200195
Validation loss: 1.8048408633919173

Epoch: 5| Step: 5
Training loss: 0.5088045001029968
Validation loss: 1.8075898949817946

Epoch: 5| Step: 6
Training loss: 0.9297193288803101
Validation loss: 1.8179950483383671

Epoch: 5| Step: 7
Training loss: 0.5835052132606506
Validation loss: 1.8169040667113436

Epoch: 5| Step: 8
Training loss: 0.724723756313324
Validation loss: 1.8909205646925076

Epoch: 5| Step: 9
Training loss: 0.6443839073181152
Validation loss: 1.9086446736448555

Epoch: 5| Step: 10
Training loss: 0.7079516053199768
Validation loss: 1.840562569197788

Epoch: 237| Step: 0
Training loss: 0.7807599902153015
Validation loss: 1.8834724349360312

Epoch: 5| Step: 1
Training loss: 0.7621970176696777
Validation loss: 1.8193885023875902

Epoch: 5| Step: 2
Training loss: 0.8402138948440552
Validation loss: 1.8458972002870293

Epoch: 5| Step: 3
Training loss: 0.5550820231437683
Validation loss: 1.8149767421906995

Epoch: 5| Step: 4
Training loss: 0.49479180574417114
Validation loss: 1.7802610602430118

Epoch: 5| Step: 5
Training loss: 0.6083815693855286
Validation loss: 1.800166186466012

Epoch: 5| Step: 6
Training loss: 0.8392568826675415
Validation loss: 1.8309722433808029

Epoch: 5| Step: 7
Training loss: 0.9250518083572388
Validation loss: 1.8309867548686203

Epoch: 5| Step: 8
Training loss: 0.7797967791557312
Validation loss: 1.8547601635738085

Epoch: 5| Step: 9
Training loss: 0.5108562707901001
Validation loss: 1.8599783220598776

Epoch: 5| Step: 10
Training loss: 0.9317125678062439
Validation loss: 1.8637418862312072

Epoch: 238| Step: 0
Training loss: 0.5922359228134155
Validation loss: 1.8582176931442753

Epoch: 5| Step: 1
Training loss: 0.7493466138839722
Validation loss: 1.8582136272102274

Epoch: 5| Step: 2
Training loss: 0.6523948311805725
Validation loss: 1.846133993517968

Epoch: 5| Step: 3
Training loss: 0.793808102607727
Validation loss: 1.854647454395089

Epoch: 5| Step: 4
Training loss: 0.8240995407104492
Validation loss: 1.8753856241062123

Epoch: 5| Step: 5
Training loss: 0.5246647000312805
Validation loss: 1.8834742756300076

Epoch: 5| Step: 6
Training loss: 0.5803708434104919
Validation loss: 1.8750246506865307

Epoch: 5| Step: 7
Training loss: 0.5421684980392456
Validation loss: 1.877240474506091

Epoch: 5| Step: 8
Training loss: 0.8507382273674011
Validation loss: 1.8557594591571438

Epoch: 5| Step: 9
Training loss: 1.2369945049285889
Validation loss: 1.8651295804208325

Epoch: 5| Step: 10
Training loss: 0.4255770146846771
Validation loss: 1.8490671573146698

Epoch: 239| Step: 0
Training loss: 0.46024125814437866
Validation loss: 1.887592956583987

Epoch: 5| Step: 1
Training loss: 0.8834344148635864
Validation loss: 1.8457227048053537

Epoch: 5| Step: 2
Training loss: 0.4552420675754547
Validation loss: 1.8281819987040695

Epoch: 5| Step: 3
Training loss: 0.6453452110290527
Validation loss: 1.8058461617398005

Epoch: 5| Step: 4
Training loss: 0.5298609137535095
Validation loss: 1.8152289993019515

Epoch: 5| Step: 5
Training loss: 0.6561446785926819
Validation loss: 1.8479547321155507

Epoch: 5| Step: 6
Training loss: 0.8783639669418335
Validation loss: 1.8209902291656823

Epoch: 5| Step: 7
Training loss: 0.8600915670394897
Validation loss: 1.8274927203373244

Epoch: 5| Step: 8
Training loss: 0.6020325422286987
Validation loss: 1.8373199175762873

Epoch: 5| Step: 9
Training loss: 0.8655665516853333
Validation loss: 1.7932606153590704

Epoch: 5| Step: 10
Training loss: 0.787854790687561
Validation loss: 1.8300439106520785

Epoch: 240| Step: 0
Training loss: 1.1350576877593994
Validation loss: 1.824522259414837

Epoch: 5| Step: 1
Training loss: 0.6623890399932861
Validation loss: 1.8129323964477868

Epoch: 5| Step: 2
Training loss: 0.8589500188827515
Validation loss: 1.8440253914043467

Epoch: 5| Step: 3
Training loss: 0.5531683564186096
Validation loss: 1.855648999573082

Epoch: 5| Step: 4
Training loss: 0.76374751329422
Validation loss: 1.77777527224633

Epoch: 5| Step: 5
Training loss: 0.716943621635437
Validation loss: 1.791904995518346

Epoch: 5| Step: 6
Training loss: 0.5710195302963257
Validation loss: 1.7822268496277511

Epoch: 5| Step: 7
Training loss: 0.8748142123222351
Validation loss: 1.7975480184760144

Epoch: 5| Step: 8
Training loss: 0.38280782103538513
Validation loss: 1.832715649758616

Epoch: 5| Step: 9
Training loss: 0.4576500952243805
Validation loss: 1.8323949344696537

Epoch: 5| Step: 10
Training loss: 0.6042523384094238
Validation loss: 1.868304188533496

Epoch: 241| Step: 0
Training loss: 0.3714798390865326
Validation loss: 1.8845604542763001

Epoch: 5| Step: 1
Training loss: 0.8233038187026978
Validation loss: 1.8994011161147908

Epoch: 5| Step: 2
Training loss: 0.5380995869636536
Validation loss: 1.8958667683345016

Epoch: 5| Step: 3
Training loss: 0.8835102319717407
Validation loss: 1.8824857281100364

Epoch: 5| Step: 4
Training loss: 0.9839822053909302
Validation loss: 1.8657335491590603

Epoch: 5| Step: 5
Training loss: 1.001573920249939
Validation loss: 1.7931944247215026

Epoch: 5| Step: 6
Training loss: 0.2844603359699249
Validation loss: 1.786043232487094

Epoch: 5| Step: 7
Training loss: 0.8616605997085571
Validation loss: 1.7428225573673044

Epoch: 5| Step: 8
Training loss: 0.5881723761558533
Validation loss: 1.7703714050272459

Epoch: 5| Step: 9
Training loss: 0.6938760876655579
Validation loss: 1.791370132917999

Epoch: 5| Step: 10
Training loss: 0.6787145137786865
Validation loss: 1.7951985482246644

Epoch: 242| Step: 0
Training loss: 0.5117388963699341
Validation loss: 1.8956016673836658

Epoch: 5| Step: 1
Training loss: 0.8746881484985352
Validation loss: 1.9071549395079255

Epoch: 5| Step: 2
Training loss: 1.0271494388580322
Validation loss: 1.9046646343764437

Epoch: 5| Step: 3
Training loss: 0.5048321485519409
Validation loss: 1.8549591572053972

Epoch: 5| Step: 4
Training loss: 0.6051973104476929
Validation loss: 1.890890241951071

Epoch: 5| Step: 5
Training loss: 0.7060977816581726
Validation loss: 1.8600876844057472

Epoch: 5| Step: 6
Training loss: 0.7278989553451538
Validation loss: 1.8821995771059425

Epoch: 5| Step: 7
Training loss: 0.6495320200920105
Validation loss: 1.9091756702751241

Epoch: 5| Step: 8
Training loss: 0.8468796610832214
Validation loss: 1.8942162541932956

Epoch: 5| Step: 9
Training loss: 0.4055348038673401
Validation loss: 1.921614387983917

Epoch: 5| Step: 10
Training loss: 0.686886727809906
Validation loss: 1.8866447505130564

Epoch: 243| Step: 0
Training loss: 0.7143398523330688
Validation loss: 1.887073040008545

Epoch: 5| Step: 1
Training loss: 0.6798206567764282
Validation loss: 1.9379298533162763

Epoch: 5| Step: 2
Training loss: 0.8906911611557007
Validation loss: 1.888783993259553

Epoch: 5| Step: 3
Training loss: 0.5681083798408508
Validation loss: 1.902427763067266

Epoch: 5| Step: 4
Training loss: 0.5551570057868958
Validation loss: 1.8938070445932367

Epoch: 5| Step: 5
Training loss: 0.8160880208015442
Validation loss: 1.8519811386703162

Epoch: 5| Step: 6
Training loss: 0.6786786913871765
Validation loss: 1.8480251578874485

Epoch: 5| Step: 7
Training loss: 0.435293585062027
Validation loss: 1.7971632442166727

Epoch: 5| Step: 8
Training loss: 0.711138904094696
Validation loss: 1.8062218120021205

Epoch: 5| Step: 9
Training loss: 0.8637911081314087
Validation loss: 1.8392871310633998

Epoch: 5| Step: 10
Training loss: 0.552884578704834
Validation loss: 1.7985474422413816

Epoch: 244| Step: 0
Training loss: 0.5799359083175659
Validation loss: 1.7850525738090597

Epoch: 5| Step: 1
Training loss: 0.6287499666213989
Validation loss: 1.7977136758065992

Epoch: 5| Step: 2
Training loss: 0.7821369171142578
Validation loss: 1.8358624853113645

Epoch: 5| Step: 3
Training loss: 0.4785660207271576
Validation loss: 1.8785862563758768

Epoch: 5| Step: 4
Training loss: 0.5112423896789551
Validation loss: 1.8767004115607149

Epoch: 5| Step: 5
Training loss: 0.7060034871101379
Validation loss: 1.8626109630830827

Epoch: 5| Step: 6
Training loss: 0.7558757066726685
Validation loss: 1.8751505523599603

Epoch: 5| Step: 7
Training loss: 0.7013963460922241
Validation loss: 1.827637618587863

Epoch: 5| Step: 8
Training loss: 0.9538876414299011
Validation loss: 1.8200048528691775

Epoch: 5| Step: 9
Training loss: 0.674635648727417
Validation loss: 1.8311682413983088

Epoch: 5| Step: 10
Training loss: 0.8232653141021729
Validation loss: 1.796412479492926

Epoch: 245| Step: 0
Training loss: 0.622397780418396
Validation loss: 1.8166239851264543

Epoch: 5| Step: 1
Training loss: 0.4236142039299011
Validation loss: 1.7809395585008847

Epoch: 5| Step: 2
Training loss: 0.8416712880134583
Validation loss: 1.791361456276268

Epoch: 5| Step: 3
Training loss: 0.950247585773468
Validation loss: 1.814546943992697

Epoch: 5| Step: 4
Training loss: 0.7975403070449829
Validation loss: 1.8254469133192492

Epoch: 5| Step: 5
Training loss: 0.6311579346656799
Validation loss: 1.8394877000521588

Epoch: 5| Step: 6
Training loss: 0.8929435610771179
Validation loss: 1.8429569608421736

Epoch: 5| Step: 7
Training loss: 0.6648042798042297
Validation loss: 1.8762295681943175

Epoch: 5| Step: 8
Training loss: 0.6829037070274353
Validation loss: 1.8796470447253155

Epoch: 5| Step: 9
Training loss: 0.5341668725013733
Validation loss: 1.8773593671860234

Epoch: 5| Step: 10
Training loss: 0.2506007254123688
Validation loss: 1.870436627377746

Epoch: 246| Step: 0
Training loss: 0.7258515954017639
Validation loss: 1.911011319006643

Epoch: 5| Step: 1
Training loss: 0.5886899828910828
Validation loss: 1.8713071282191942

Epoch: 5| Step: 2
Training loss: 0.48378342390060425
Validation loss: 1.8430196418557117

Epoch: 5| Step: 3
Training loss: 0.8752061724662781
Validation loss: 1.8243355135763846

Epoch: 5| Step: 4
Training loss: 0.603696346282959
Validation loss: 1.8238056769935034

Epoch: 5| Step: 5
Training loss: 0.8555645942687988
Validation loss: 1.8172176486702376

Epoch: 5| Step: 6
Training loss: 0.8347102999687195
Validation loss: 1.833402927203845

Epoch: 5| Step: 7
Training loss: 0.9673995971679688
Validation loss: 1.8307115698373446

Epoch: 5| Step: 8
Training loss: 0.693699061870575
Validation loss: 1.8609690191925212

Epoch: 5| Step: 9
Training loss: 0.5666316747665405
Validation loss: 1.894632726587275

Epoch: 5| Step: 10
Training loss: 0.4760178327560425
Validation loss: 1.836991197319441

Epoch: 247| Step: 0
Training loss: 0.6226118206977844
Validation loss: 1.8038037361637238

Epoch: 5| Step: 1
Training loss: 0.37452930212020874
Validation loss: 1.8016044837172314

Epoch: 5| Step: 2
Training loss: 0.5818305015563965
Validation loss: 1.7653830307786182

Epoch: 5| Step: 3
Training loss: 0.7543265223503113
Validation loss: 1.771208356785518

Epoch: 5| Step: 4
Training loss: 0.6750544309616089
Validation loss: 1.791363295688424

Epoch: 5| Step: 5
Training loss: 0.6217683553695679
Validation loss: 1.7783873029934463

Epoch: 5| Step: 6
Training loss: 0.7046482563018799
Validation loss: 1.8194208811688166

Epoch: 5| Step: 7
Training loss: 0.7194755673408508
Validation loss: 1.8572134125617243

Epoch: 5| Step: 8
Training loss: 0.7848881483078003
Validation loss: 1.9006350912073606

Epoch: 5| Step: 9
Training loss: 0.7005144357681274
Validation loss: 1.939993437900338

Epoch: 5| Step: 10
Training loss: 0.9673863649368286
Validation loss: 1.9328124830799718

Epoch: 248| Step: 0
Training loss: 0.7165816426277161
Validation loss: 1.8959502814918436

Epoch: 5| Step: 1
Training loss: 0.8696708679199219
Validation loss: 1.8783868192344584

Epoch: 5| Step: 2
Training loss: 0.685190737247467
Validation loss: 1.8083134928057272

Epoch: 5| Step: 3
Training loss: 0.7011627554893494
Validation loss: 1.7863768659612185

Epoch: 5| Step: 4
Training loss: 0.6613624691963196
Validation loss: 1.780630015557812

Epoch: 5| Step: 5
Training loss: 0.4835132658481598
Validation loss: 1.8068249558889737

Epoch: 5| Step: 6
Training loss: 0.5546838641166687
Validation loss: 1.8298274188913324

Epoch: 5| Step: 7
Training loss: 0.8732684850692749
Validation loss: 1.8418830966436734

Epoch: 5| Step: 8
Training loss: 0.5794183015823364
Validation loss: 1.8668887679294874

Epoch: 5| Step: 9
Training loss: 0.49170631170272827
Validation loss: 1.8964170281605055

Epoch: 5| Step: 10
Training loss: 0.3852442502975464
Validation loss: 1.8865937084280036

Epoch: 249| Step: 0
Training loss: 0.7142167687416077
Validation loss: 1.92916230745213

Epoch: 5| Step: 1
Training loss: 0.796704888343811
Validation loss: 1.8953502947284329

Epoch: 5| Step: 2
Training loss: 0.5919255018234253
Validation loss: 1.8337296542300974

Epoch: 5| Step: 3
Training loss: 0.6618632078170776
Validation loss: 1.8618347349987234

Epoch: 5| Step: 4
Training loss: 0.5342161059379578
Validation loss: 1.820345696582589

Epoch: 5| Step: 5
Training loss: 0.39483001828193665
Validation loss: 1.848957436059111

Epoch: 5| Step: 6
Training loss: 0.7029280066490173
Validation loss: 1.8199980630669543

Epoch: 5| Step: 7
Training loss: 0.8604637384414673
Validation loss: 1.8452474314679381

Epoch: 5| Step: 8
Training loss: 0.5819827914237976
Validation loss: 1.862015708800285

Epoch: 5| Step: 9
Training loss: 0.8237683176994324
Validation loss: 1.905155994558847

Epoch: 5| Step: 10
Training loss: 0.7254016995429993
Validation loss: 1.859590127903928

Epoch: 250| Step: 0
Training loss: 0.584588885307312
Validation loss: 1.8507662345004339

Epoch: 5| Step: 1
Training loss: 0.6578208208084106
Validation loss: 1.8099819883223502

Epoch: 5| Step: 2
Training loss: 0.6299342513084412
Validation loss: 1.802319718945411

Epoch: 5| Step: 3
Training loss: 0.6012126207351685
Validation loss: 1.8370306081669305

Epoch: 5| Step: 4
Training loss: 0.628174364566803
Validation loss: 1.8291108877428117

Epoch: 5| Step: 5
Training loss: 0.627145528793335
Validation loss: 1.7981792034641388

Epoch: 5| Step: 6
Training loss: 0.870631217956543
Validation loss: 1.818058063907008

Epoch: 5| Step: 7
Training loss: 0.5510416030883789
Validation loss: 1.8729282604750765

Epoch: 5| Step: 8
Training loss: 0.6682003736495972
Validation loss: 1.8702774586216095

Epoch: 5| Step: 9
Training loss: 1.3032214641571045
Validation loss: 1.919003193096448

Epoch: 5| Step: 10
Training loss: 0.5686964988708496
Validation loss: 1.9533649695816862

Epoch: 251| Step: 0
Training loss: 0.4428647458553314
Validation loss: 1.94648991861651

Epoch: 5| Step: 1
Training loss: 0.8391982913017273
Validation loss: 1.9695525156554354

Epoch: 5| Step: 2
Training loss: 0.8392900228500366
Validation loss: 1.8920965220338555

Epoch: 5| Step: 3
Training loss: 0.4337906837463379
Validation loss: 1.8089021021319973

Epoch: 5| Step: 4
Training loss: 0.6999643445014954
Validation loss: 1.783186005007836

Epoch: 5| Step: 5
Training loss: 0.7004040479660034
Validation loss: 1.7552960380431144

Epoch: 5| Step: 6
Training loss: 0.6598151922225952
Validation loss: 1.7644676713533298

Epoch: 5| Step: 7
Training loss: 0.6702046990394592
Validation loss: 1.770567686327042

Epoch: 5| Step: 8
Training loss: 0.7600570321083069
Validation loss: 1.804018799976636

Epoch: 5| Step: 9
Training loss: 0.6023619771003723
Validation loss: 1.844687573371395

Epoch: 5| Step: 10
Training loss: 0.8401389122009277
Validation loss: 1.8452541828155518

Epoch: 252| Step: 0
Training loss: 0.7713698744773865
Validation loss: 1.8559885230115665

Epoch: 5| Step: 1
Training loss: 0.3953522741794586
Validation loss: 1.8643903642572381

Epoch: 5| Step: 2
Training loss: 0.7047250866889954
Validation loss: 1.8760609857497677

Epoch: 5| Step: 3
Training loss: 0.6374141573905945
Validation loss: 1.8738626921048729

Epoch: 5| Step: 4
Training loss: 0.5269529223442078
Validation loss: 1.8292080356228737

Epoch: 5| Step: 5
Training loss: 0.7232807874679565
Validation loss: 1.789707959339183

Epoch: 5| Step: 6
Training loss: 0.5257067084312439
Validation loss: 1.7809422169962237

Epoch: 5| Step: 7
Training loss: 1.0143474340438843
Validation loss: 1.7563284417634368

Epoch: 5| Step: 8
Training loss: 0.5871855020523071
Validation loss: 1.7231877901220833

Epoch: 5| Step: 9
Training loss: 0.579988956451416
Validation loss: 1.7317906156662972

Epoch: 5| Step: 10
Training loss: 0.38897109031677246
Validation loss: 1.7491013619207567

Epoch: 253| Step: 0
Training loss: 0.7912319302558899
Validation loss: 1.747926918409204

Epoch: 5| Step: 1
Training loss: 0.5487690567970276
Validation loss: 1.7960486924776466

Epoch: 5| Step: 2
Training loss: 0.2875848412513733
Validation loss: 1.8089653509919361

Epoch: 5| Step: 3
Training loss: 0.7388249635696411
Validation loss: 1.8458078984291322

Epoch: 5| Step: 4
Training loss: 0.7822321057319641
Validation loss: 1.838815805732563

Epoch: 5| Step: 5
Training loss: 0.6318801045417786
Validation loss: 1.8584662432311683

Epoch: 5| Step: 6
Training loss: 0.746431827545166
Validation loss: 1.8627035605010165

Epoch: 5| Step: 7
Training loss: 0.4874412417411804
Validation loss: 1.8604977746163645

Epoch: 5| Step: 8
Training loss: 0.42224007844924927
Validation loss: 1.8401925615085069

Epoch: 5| Step: 9
Training loss: 0.48986220359802246
Validation loss: 1.8628042718415618

Epoch: 5| Step: 10
Training loss: 0.8137858510017395
Validation loss: 1.8108117042049285

Epoch: 254| Step: 0
Training loss: 0.6342635154724121
Validation loss: 1.7934324331181024

Epoch: 5| Step: 1
Training loss: 0.5370445251464844
Validation loss: 1.8105636706916235

Epoch: 5| Step: 2
Training loss: 0.4803951382637024
Validation loss: 1.8214856117002425

Epoch: 5| Step: 3
Training loss: 0.7392787933349609
Validation loss: 1.836592713991801

Epoch: 5| Step: 4
Training loss: 0.7536002993583679
Validation loss: 1.8321660205882082

Epoch: 5| Step: 5
Training loss: 0.2639749050140381
Validation loss: 1.8740693548674225

Epoch: 5| Step: 6
Training loss: 0.8686580657958984
Validation loss: 1.8566487989118021

Epoch: 5| Step: 7
Training loss: 0.6695870161056519
Validation loss: 1.8122978646268126

Epoch: 5| Step: 8
Training loss: 0.6671223640441895
Validation loss: 1.791898742798836

Epoch: 5| Step: 9
Training loss: 0.3935213088989258
Validation loss: 1.7584987378889514

Epoch: 5| Step: 10
Training loss: 0.7224256992340088
Validation loss: 1.7239522062322146

Epoch: 255| Step: 0
Training loss: 0.6238588094711304
Validation loss: 1.7382945117130075

Epoch: 5| Step: 1
Training loss: 0.7987926602363586
Validation loss: 1.738609270382953

Epoch: 5| Step: 2
Training loss: 0.6340232491493225
Validation loss: 1.805065829266784

Epoch: 5| Step: 3
Training loss: 0.2584518790245056
Validation loss: 1.7998473003346434

Epoch: 5| Step: 4
Training loss: 0.6231725215911865
Validation loss: 1.860820657463484

Epoch: 5| Step: 5
Training loss: 0.8392732739448547
Validation loss: 1.9168712554439422

Epoch: 5| Step: 6
Training loss: 0.592463493347168
Validation loss: 1.9711526875854821

Epoch: 5| Step: 7
Training loss: 0.7443901896476746
Validation loss: 1.9544107862698135

Epoch: 5| Step: 8
Training loss: 0.5131096839904785
Validation loss: 1.8619040135414369

Epoch: 5| Step: 9
Training loss: 0.47988319396972656
Validation loss: 1.8180467979882353

Epoch: 5| Step: 10
Training loss: 0.7732855081558228
Validation loss: 1.791180549129363

Epoch: 256| Step: 0
Training loss: 1.10440993309021
Validation loss: 1.805982715340071

Epoch: 5| Step: 1
Training loss: 0.4330597519874573
Validation loss: 1.748656972762077

Epoch: 5| Step: 2
Training loss: 0.43274563550949097
Validation loss: 1.7476654873099378

Epoch: 5| Step: 3
Training loss: 0.3541090786457062
Validation loss: 1.7778596301232614

Epoch: 5| Step: 4
Training loss: 0.7218305468559265
Validation loss: 1.811734934006968

Epoch: 5| Step: 5
Training loss: 0.7311619520187378
Validation loss: 1.8352059843719646

Epoch: 5| Step: 6
Training loss: 0.7254053354263306
Validation loss: 1.8072069139890774

Epoch: 5| Step: 7
Training loss: 0.46745771169662476
Validation loss: 1.8039069624357327

Epoch: 5| Step: 8
Training loss: 0.3213454782962799
Validation loss: 1.8105455598523539

Epoch: 5| Step: 9
Training loss: 0.9779735803604126
Validation loss: 1.870089525817543

Epoch: 5| Step: 10
Training loss: 0.804352879524231
Validation loss: 1.8956192283220188

Epoch: 257| Step: 0
Training loss: 0.7548373937606812
Validation loss: 1.8903619012525004

Epoch: 5| Step: 1
Training loss: 0.5303696393966675
Validation loss: 1.8651741191905031

Epoch: 5| Step: 2
Training loss: 0.6629747748374939
Validation loss: 1.8074659211661226

Epoch: 5| Step: 3
Training loss: 0.48808541893959045
Validation loss: 1.7627156344793176

Epoch: 5| Step: 4
Training loss: 0.7471802830696106
Validation loss: 1.7245909142237839

Epoch: 5| Step: 5
Training loss: 0.6954389810562134
Validation loss: 1.686005215491018

Epoch: 5| Step: 6
Training loss: 0.6436518430709839
Validation loss: 1.6991544308200959

Epoch: 5| Step: 7
Training loss: 0.7179484367370605
Validation loss: 1.68539983354589

Epoch: 5| Step: 8
Training loss: 0.5523473620414734
Validation loss: 1.7316881328500726

Epoch: 5| Step: 9
Training loss: 0.4803397059440613
Validation loss: 1.7531067222677252

Epoch: 5| Step: 10
Training loss: 0.39622047543525696
Validation loss: 1.7605328277875019

Epoch: 258| Step: 0
Training loss: 0.34847956895828247
Validation loss: 1.7934589398804532

Epoch: 5| Step: 1
Training loss: 0.8468601107597351
Validation loss: 1.8174339122669672

Epoch: 5| Step: 2
Training loss: 0.706386148929596
Validation loss: 1.7965295776244132

Epoch: 5| Step: 3
Training loss: 0.6044341325759888
Validation loss: 1.7953091949544928

Epoch: 5| Step: 4
Training loss: 0.43552151322364807
Validation loss: 1.7979533069877214

Epoch: 5| Step: 5
Training loss: 0.42845815420150757
Validation loss: 1.7684549734156618

Epoch: 5| Step: 6
Training loss: 0.29875433444976807
Validation loss: 1.7295352374353716

Epoch: 5| Step: 7
Training loss: 0.5737262964248657
Validation loss: 1.730497573011665

Epoch: 5| Step: 8
Training loss: 0.8660684823989868
Validation loss: 1.734133066669587

Epoch: 5| Step: 9
Training loss: 0.742668867111206
Validation loss: 1.7267825949576594

Epoch: 5| Step: 10
Training loss: 0.4355069398880005
Validation loss: 1.7124862593989219

Epoch: 259| Step: 0
Training loss: 0.6554031372070312
Validation loss: 1.7209156136358938

Epoch: 5| Step: 1
Training loss: 0.6964789628982544
Validation loss: 1.7394689359972555

Epoch: 5| Step: 2
Training loss: 0.558303952217102
Validation loss: 1.7976717820731543

Epoch: 5| Step: 3
Training loss: 0.4371646046638489
Validation loss: 1.8039621678731774

Epoch: 5| Step: 4
Training loss: 0.6128109693527222
Validation loss: 1.8000047937516244

Epoch: 5| Step: 5
Training loss: 0.4540823996067047
Validation loss: 1.7868364382815618

Epoch: 5| Step: 6
Training loss: 0.8986976742744446
Validation loss: 1.773975767115111

Epoch: 5| Step: 7
Training loss: 0.4340801239013672
Validation loss: 1.7881576861104658

Epoch: 5| Step: 8
Training loss: 0.4276720881462097
Validation loss: 1.7595366790730467

Epoch: 5| Step: 9
Training loss: 0.5702691078186035
Validation loss: 1.8098596244729974

Epoch: 5| Step: 10
Training loss: 0.3531962037086487
Validation loss: 1.7824108523707236

Epoch: 260| Step: 0
Training loss: 0.7905750274658203
Validation loss: 1.7734306768704486

Epoch: 5| Step: 1
Training loss: 0.6542642116546631
Validation loss: 1.7761240018311368

Epoch: 5| Step: 2
Training loss: 0.6406825184822083
Validation loss: 1.7832049990213046

Epoch: 5| Step: 3
Training loss: 0.5186793804168701
Validation loss: 1.7622099384184806

Epoch: 5| Step: 4
Training loss: 0.5937677621841431
Validation loss: 1.7702713858696721

Epoch: 5| Step: 5
Training loss: 0.42784708738327026
Validation loss: 1.8198916489078152

Epoch: 5| Step: 6
Training loss: 0.5795871615409851
Validation loss: 1.8415744394384406

Epoch: 5| Step: 7
Training loss: 0.8209924697875977
Validation loss: 1.8414376845923803

Epoch: 5| Step: 8
Training loss: 0.351767897605896
Validation loss: 1.8448769789870068

Epoch: 5| Step: 9
Training loss: 0.27062803506851196
Validation loss: 1.8315818668693624

Epoch: 5| Step: 10
Training loss: 0.46983298659324646
Validation loss: 1.8414330149209628

Epoch: 261| Step: 0
Training loss: 0.4170112609863281
Validation loss: 1.783470437090884

Epoch: 5| Step: 1
Training loss: 0.4374517500400543
Validation loss: 1.7849082036684918

Epoch: 5| Step: 2
Training loss: 0.7001605033874512
Validation loss: 1.7956857168546287

Epoch: 5| Step: 3
Training loss: 0.6749778389930725
Validation loss: 1.7740161175368934

Epoch: 5| Step: 4
Training loss: 0.5953386425971985
Validation loss: 1.7965445441584433

Epoch: 5| Step: 5
Training loss: 0.5843936204910278
Validation loss: 1.7813029545609669

Epoch: 5| Step: 6
Training loss: 0.5501077175140381
Validation loss: 1.8359831635669996

Epoch: 5| Step: 7
Training loss: 0.6314923167228699
Validation loss: 1.8376831046996578

Epoch: 5| Step: 8
Training loss: 0.4193599820137024
Validation loss: 1.7983944390409736

Epoch: 5| Step: 9
Training loss: 0.637985110282898
Validation loss: 1.7972472470293763

Epoch: 5| Step: 10
Training loss: 0.5282981991767883
Validation loss: 1.7775464545014084

Epoch: 262| Step: 0
Training loss: 0.39586570858955383
Validation loss: 1.7414825411253079

Epoch: 5| Step: 1
Training loss: 0.5426384210586548
Validation loss: 1.78849486894505

Epoch: 5| Step: 2
Training loss: 0.3420071601867676
Validation loss: 1.7943453109392555

Epoch: 5| Step: 3
Training loss: 0.5994312763214111
Validation loss: 1.7957706323233984

Epoch: 5| Step: 4
Training loss: 0.544776439666748
Validation loss: 1.7992738344336068

Epoch: 5| Step: 5
Training loss: 0.5787070989608765
Validation loss: 1.776519331880795

Epoch: 5| Step: 6
Training loss: 0.4231250286102295
Validation loss: 1.7452580300710534

Epoch: 5| Step: 7
Training loss: 0.7192130088806152
Validation loss: 1.7534494964025353

Epoch: 5| Step: 8
Training loss: 0.594807505607605
Validation loss: 1.7456959992326715

Epoch: 5| Step: 9
Training loss: 0.5083827376365662
Validation loss: 1.7372811942972162

Epoch: 5| Step: 10
Training loss: 0.8224950432777405
Validation loss: 1.7559490460221485

Epoch: 263| Step: 0
Training loss: 0.25094297528266907
Validation loss: 1.782552731934414

Epoch: 5| Step: 1
Training loss: 0.892289936542511
Validation loss: 1.793880465210125

Epoch: 5| Step: 2
Training loss: 0.6778386235237122
Validation loss: 1.791116949050657

Epoch: 5| Step: 3
Training loss: 0.8590288162231445
Validation loss: 1.8210815998815721

Epoch: 5| Step: 4
Training loss: 0.5344256162643433
Validation loss: 1.8272900158359158

Epoch: 5| Step: 5
Training loss: 0.6085705757141113
Validation loss: 1.8389803491612917

Epoch: 5| Step: 6
Training loss: 0.5301221609115601
Validation loss: 1.8112185014191495

Epoch: 5| Step: 7
Training loss: 0.43327227234840393
Validation loss: 1.8164217600258448

Epoch: 5| Step: 8
Training loss: 0.4127127230167389
Validation loss: 1.8221955607014317

Epoch: 5| Step: 9
Training loss: 0.474980890750885
Validation loss: 1.7999315005476757

Epoch: 5| Step: 10
Training loss: 0.33981528878211975
Validation loss: 1.786390140492429

Epoch: 264| Step: 0
Training loss: 0.25821688771247864
Validation loss: 1.8342940230523386

Epoch: 5| Step: 1
Training loss: 0.7153981924057007
Validation loss: 1.835252897713774

Epoch: 5| Step: 2
Training loss: 0.4516848921775818
Validation loss: 1.8341051647740025

Epoch: 5| Step: 3
Training loss: 0.5528864860534668
Validation loss: 1.8194831955817439

Epoch: 5| Step: 4
Training loss: 0.61506587266922
Validation loss: 1.812372076895929

Epoch: 5| Step: 5
Training loss: 0.31319698691368103
Validation loss: 1.793108522251088

Epoch: 5| Step: 6
Training loss: 0.7772318124771118
Validation loss: 1.7436112755088395

Epoch: 5| Step: 7
Training loss: 0.7489639520645142
Validation loss: 1.757442557683555

Epoch: 5| Step: 8
Training loss: 0.5986127853393555
Validation loss: 1.7591801458789456

Epoch: 5| Step: 9
Training loss: 0.5025513768196106
Validation loss: 1.7482515983684088

Epoch: 5| Step: 10
Training loss: 0.3857971429824829
Validation loss: 1.76632934488276

Epoch: 265| Step: 0
Training loss: 0.43852367997169495
Validation loss: 1.7527319269795572

Epoch: 5| Step: 1
Training loss: 0.48632678389549255
Validation loss: 1.730157268944607

Epoch: 5| Step: 2
Training loss: 0.6609736084938049
Validation loss: 1.7680513499885477

Epoch: 5| Step: 3
Training loss: 0.7218023538589478
Validation loss: 1.7460171830269597

Epoch: 5| Step: 4
Training loss: 0.6221932768821716
Validation loss: 1.8110895977225354

Epoch: 5| Step: 5
Training loss: 0.47548380494117737
Validation loss: 1.7883115224940802

Epoch: 5| Step: 6
Training loss: 0.5675418972969055
Validation loss: 1.8347030185884046

Epoch: 5| Step: 7
Training loss: 0.37797003984451294
Validation loss: 1.8120417979455763

Epoch: 5| Step: 8
Training loss: 0.47879916429519653
Validation loss: 1.8078406651814778

Epoch: 5| Step: 9
Training loss: 0.29887861013412476
Validation loss: 1.7791377805894422

Epoch: 5| Step: 10
Training loss: 0.6731236577033997
Validation loss: 1.788997906510548

Epoch: 266| Step: 0
Training loss: 0.4735194742679596
Validation loss: 1.7824161334704327

Epoch: 5| Step: 1
Training loss: 0.5720672607421875
Validation loss: 1.7715261251695695

Epoch: 5| Step: 2
Training loss: 0.4720337986946106
Validation loss: 1.765855635366132

Epoch: 5| Step: 3
Training loss: 0.4249497354030609
Validation loss: 1.7442933590181413

Epoch: 5| Step: 4
Training loss: 0.8437259793281555
Validation loss: 1.7428535235825406

Epoch: 5| Step: 5
Training loss: 0.5765084028244019
Validation loss: 1.7667366138068579

Epoch: 5| Step: 6
Training loss: 0.2488839328289032
Validation loss: 1.7388730664407053

Epoch: 5| Step: 7
Training loss: 0.6774286031723022
Validation loss: 1.7424578897414669

Epoch: 5| Step: 8
Training loss: 0.42279690504074097
Validation loss: 1.7612090367142872

Epoch: 5| Step: 9
Training loss: 0.2684462070465088
Validation loss: 1.7630946533654326

Epoch: 5| Step: 10
Training loss: 0.572995662689209
Validation loss: 1.7826873576769264

Epoch: 267| Step: 0
Training loss: 0.28590765595436096
Validation loss: 1.822698986658486

Epoch: 5| Step: 1
Training loss: 0.4541739523410797
Validation loss: 1.8696474875173261

Epoch: 5| Step: 2
Training loss: 0.7037405967712402
Validation loss: 1.8572434430481286

Epoch: 5| Step: 3
Training loss: 0.48919540643692017
Validation loss: 1.842104543921768

Epoch: 5| Step: 4
Training loss: 0.19376632571220398
Validation loss: 1.8368425164171445

Epoch: 5| Step: 5
Training loss: 0.5539140105247498
Validation loss: 1.795613940044116

Epoch: 5| Step: 6
Training loss: 0.5802806615829468
Validation loss: 1.7466987179171654

Epoch: 5| Step: 7
Training loss: 0.6956743001937866
Validation loss: 1.700055722267397

Epoch: 5| Step: 8
Training loss: 0.5125308036804199
Validation loss: 1.7060372701255224

Epoch: 5| Step: 9
Training loss: 0.6134393811225891
Validation loss: 1.7094223986389816

Epoch: 5| Step: 10
Training loss: 0.839898943901062
Validation loss: 1.7420588347219652

Epoch: 268| Step: 0
Training loss: 0.20140235126018524
Validation loss: 1.6869334700287029

Epoch: 5| Step: 1
Training loss: 0.4820583760738373
Validation loss: 1.7174559626528012

Epoch: 5| Step: 2
Training loss: 0.522689700126648
Validation loss: 1.7563176488363614

Epoch: 5| Step: 3
Training loss: 0.8333874940872192
Validation loss: 1.7926763642218806

Epoch: 5| Step: 4
Training loss: 0.43755966424942017
Validation loss: 1.8511277655119538

Epoch: 5| Step: 5
Training loss: 0.8972278833389282
Validation loss: 1.8914481875717

Epoch: 5| Step: 6
Training loss: 0.5708561539649963
Validation loss: 1.8400929268970285

Epoch: 5| Step: 7
Training loss: 0.5303562879562378
Validation loss: 1.8358640542594336

Epoch: 5| Step: 8
Training loss: 0.6034501791000366
Validation loss: 1.7657681639476488

Epoch: 5| Step: 9
Training loss: 0.48536938428878784
Validation loss: 1.7492073069336593

Epoch: 5| Step: 10
Training loss: 0.43642574548721313
Validation loss: 1.73951123094046

Epoch: 269| Step: 0
Training loss: 0.301219642162323
Validation loss: 1.7201410365361038

Epoch: 5| Step: 1
Training loss: 0.695574164390564
Validation loss: 1.6793781019026233

Epoch: 5| Step: 2
Training loss: 0.6043146252632141
Validation loss: 1.7027949556227653

Epoch: 5| Step: 3
Training loss: 0.5856307148933411
Validation loss: 1.6737332279964159

Epoch: 5| Step: 4
Training loss: 0.5770716667175293
Validation loss: 1.6860991921476138

Epoch: 5| Step: 5
Training loss: 0.3906159996986389
Validation loss: 1.6816117635337255

Epoch: 5| Step: 6
Training loss: 0.6698523759841919
Validation loss: 1.7462777117247223

Epoch: 5| Step: 7
Training loss: 0.5230833888053894
Validation loss: 1.770614089504365

Epoch: 5| Step: 8
Training loss: 0.6416643261909485
Validation loss: 1.824779668161946

Epoch: 5| Step: 9
Training loss: 0.5593905448913574
Validation loss: 1.8065122506951774

Epoch: 5| Step: 10
Training loss: 0.7477970719337463
Validation loss: 1.8927779697602796

Epoch: 270| Step: 0
Training loss: 0.8198844790458679
Validation loss: 1.885453986865218

Epoch: 5| Step: 1
Training loss: 0.5183595418930054
Validation loss: 1.8326568449697187

Epoch: 5| Step: 2
Training loss: 0.3517821431159973
Validation loss: 1.7445009882732103

Epoch: 5| Step: 3
Training loss: 0.47581785917282104
Validation loss: 1.6772731273405013

Epoch: 5| Step: 4
Training loss: 0.44509705901145935
Validation loss: 1.6966573217863679

Epoch: 5| Step: 5
Training loss: 0.6517348289489746
Validation loss: 1.6743168625780331

Epoch: 5| Step: 6
Training loss: 0.7116284370422363
Validation loss: 1.6693277012917302

Epoch: 5| Step: 7
Training loss: 0.701003909111023
Validation loss: 1.7093956355125672

Epoch: 5| Step: 8
Training loss: 0.42195987701416016
Validation loss: 1.7312537290716683

Epoch: 5| Step: 9
Training loss: 0.5163493156433105
Validation loss: 1.7548499414997716

Epoch: 5| Step: 10
Training loss: 0.6006009578704834
Validation loss: 1.8275763629585184

Epoch: 271| Step: 0
Training loss: 0.4975353181362152
Validation loss: 1.8179775796910769

Epoch: 5| Step: 1
Training loss: 0.4624706208705902
Validation loss: 1.8372103693664714

Epoch: 5| Step: 2
Training loss: 0.6209046244621277
Validation loss: 1.8413269135259813

Epoch: 5| Step: 3
Training loss: 0.4540085196495056
Validation loss: 1.8504223721001738

Epoch: 5| Step: 4
Training loss: 0.5173324942588806
Validation loss: 1.7967898025307605

Epoch: 5| Step: 5
Training loss: 0.687551736831665
Validation loss: 1.746658048322124

Epoch: 5| Step: 6
Training loss: 0.6975563168525696
Validation loss: 1.7324329281366

Epoch: 5| Step: 7
Training loss: 0.4738695025444031
Validation loss: 1.6688479236377183

Epoch: 5| Step: 8
Training loss: 0.5331482887268066
Validation loss: 1.6766252120335896

Epoch: 5| Step: 9
Training loss: 0.4393281936645508
Validation loss: 1.6993654004989132

Epoch: 5| Step: 10
Training loss: 0.3634796440601349
Validation loss: 1.7361505595586633

Epoch: 272| Step: 0
Training loss: 0.5540401339530945
Validation loss: 1.7997046080968713

Epoch: 5| Step: 1
Training loss: 0.6141372323036194
Validation loss: 1.7951109819514777

Epoch: 5| Step: 2
Training loss: 0.5409097671508789
Validation loss: 1.814224482864462

Epoch: 5| Step: 3
Training loss: 0.5061864852905273
Validation loss: 1.8136177062988281

Epoch: 5| Step: 4
Training loss: 0.37366583943367004
Validation loss: 1.8040215622994207

Epoch: 5| Step: 5
Training loss: 0.3956541419029236
Validation loss: 1.8232275068119008

Epoch: 5| Step: 6
Training loss: 0.3937016725540161
Validation loss: 1.8134796388687626

Epoch: 5| Step: 7
Training loss: 0.38757938146591187
Validation loss: 1.8423215176469536

Epoch: 5| Step: 8
Training loss: 0.6749431490898132
Validation loss: 1.810857734372539

Epoch: 5| Step: 9
Training loss: 0.8695583343505859
Validation loss: 1.7808383267412904

Epoch: 5| Step: 10
Training loss: 0.40685009956359863
Validation loss: 1.760348944253819

Epoch: 273| Step: 0
Training loss: 0.38650041818618774
Validation loss: 1.7356058961601668

Epoch: 5| Step: 1
Training loss: 0.5541186332702637
Validation loss: 1.7378780841827393

Epoch: 5| Step: 2
Training loss: 0.4414900839328766
Validation loss: 1.719292845777286

Epoch: 5| Step: 3
Training loss: 0.6901932954788208
Validation loss: 1.7225377200752177

Epoch: 5| Step: 4
Training loss: 0.6996698379516602
Validation loss: 1.7204879137777513

Epoch: 5| Step: 5
Training loss: 0.5183389782905579
Validation loss: 1.7559406988082393

Epoch: 5| Step: 6
Training loss: 0.3725081980228424
Validation loss: 1.7887038556478356

Epoch: 5| Step: 7
Training loss: 0.7948123216629028
Validation loss: 1.789734673756425

Epoch: 5| Step: 8
Training loss: 0.4190328121185303
Validation loss: 1.7786796631351594

Epoch: 5| Step: 9
Training loss: 0.4477943778038025
Validation loss: 1.7839925571154522

Epoch: 5| Step: 10
Training loss: 0.5699037313461304
Validation loss: 1.7922192171055784

Epoch: 274| Step: 0
Training loss: 0.6951297521591187
Validation loss: 1.7649660033564414

Epoch: 5| Step: 1
Training loss: 0.34894901514053345
Validation loss: 1.725736746224024

Epoch: 5| Step: 2
Training loss: 0.644886314868927
Validation loss: 1.7579149635889197

Epoch: 5| Step: 3
Training loss: 0.3440394103527069
Validation loss: 1.7395268012118597

Epoch: 5| Step: 4
Training loss: 0.47763633728027344
Validation loss: 1.7304351547712922

Epoch: 5| Step: 5
Training loss: 0.5275477170944214
Validation loss: 1.7322499777681084

Epoch: 5| Step: 6
Training loss: 0.5918422341346741
Validation loss: 1.7547615522979407

Epoch: 5| Step: 7
Training loss: 0.6045664548873901
Validation loss: 1.7375472450769076

Epoch: 5| Step: 8
Training loss: 0.45088881254196167
Validation loss: 1.7796050758772

Epoch: 5| Step: 9
Training loss: 0.3597841262817383
Validation loss: 1.799842208944341

Epoch: 5| Step: 10
Training loss: 0.47403785586357117
Validation loss: 1.7183675586536367

Epoch: 275| Step: 0
Training loss: 0.44865888357162476
Validation loss: 1.7100518377878333

Epoch: 5| Step: 1
Training loss: 0.4528200626373291
Validation loss: 1.6949551579772786

Epoch: 5| Step: 2
Training loss: 0.4231688380241394
Validation loss: 1.7034233065061672

Epoch: 5| Step: 3
Training loss: 0.4665680527687073
Validation loss: 1.7508435582601896

Epoch: 5| Step: 4
Training loss: 0.3695193827152252
Validation loss: 1.7543242554510794

Epoch: 5| Step: 5
Training loss: 0.5360147953033447
Validation loss: 1.742291997837764

Epoch: 5| Step: 6
Training loss: 0.4707353711128235
Validation loss: 1.7800128267657371

Epoch: 5| Step: 7
Training loss: 0.4561764597892761
Validation loss: 1.763746832006721

Epoch: 5| Step: 8
Training loss: 0.6504735946655273
Validation loss: 1.754195326118059

Epoch: 5| Step: 9
Training loss: 0.21504929661750793
Validation loss: 1.7914620740439302

Epoch: 5| Step: 10
Training loss: 0.7112938165664673
Validation loss: 1.7559360291368218

Epoch: 276| Step: 0
Training loss: 0.4440120756626129
Validation loss: 1.7563900229751424

Epoch: 5| Step: 1
Training loss: 0.5032504200935364
Validation loss: 1.729677402844993

Epoch: 5| Step: 2
Training loss: 0.6354378461837769
Validation loss: 1.7559338128694923

Epoch: 5| Step: 3
Training loss: 0.5306991338729858
Validation loss: 1.7258252943715742

Epoch: 5| Step: 4
Training loss: 0.33266448974609375
Validation loss: 1.7362947951080978

Epoch: 5| Step: 5
Training loss: 0.4075520634651184
Validation loss: 1.749629323200513

Epoch: 5| Step: 6
Training loss: 0.5939788222312927
Validation loss: 1.765647295982607

Epoch: 5| Step: 7
Training loss: 0.37393680214881897
Validation loss: 1.7506010968198058

Epoch: 5| Step: 8
Training loss: 0.6168463826179504
Validation loss: 1.7570418465522029

Epoch: 5| Step: 9
Training loss: 0.36187800765037537
Validation loss: 1.7609624657579648

Epoch: 5| Step: 10
Training loss: 0.43339431285858154
Validation loss: 1.745820156989559

Epoch: 277| Step: 0
Training loss: 0.5934553742408752
Validation loss: 1.7579869749725505

Epoch: 5| Step: 1
Training loss: 0.502012312412262
Validation loss: 1.7690487113050235

Epoch: 5| Step: 2
Training loss: 0.39027702808380127
Validation loss: 1.7574030788995887

Epoch: 5| Step: 3
Training loss: 0.43169736862182617
Validation loss: 1.7377397911522978

Epoch: 5| Step: 4
Training loss: 0.4978993535041809
Validation loss: 1.770340814385363

Epoch: 5| Step: 5
Training loss: 0.4668664038181305
Validation loss: 1.7669204024858371

Epoch: 5| Step: 6
Training loss: 0.3330285847187042
Validation loss: 1.7257208260156776

Epoch: 5| Step: 7
Training loss: 0.6557555198669434
Validation loss: 1.745287085092196

Epoch: 5| Step: 8
Training loss: 0.20902836322784424
Validation loss: 1.7587121314899896

Epoch: 5| Step: 9
Training loss: 0.39426857233047485
Validation loss: 1.744179356482721

Epoch: 5| Step: 10
Training loss: 0.39249271154403687
Validation loss: 1.7151923525717951

Epoch: 278| Step: 0
Training loss: 0.5636034607887268
Validation loss: 1.737516176316046

Epoch: 5| Step: 1
Training loss: 0.24791006743907928
Validation loss: 1.711408325420913

Epoch: 5| Step: 2
Training loss: 0.43982377648353577
Validation loss: 1.7182198903893913

Epoch: 5| Step: 3
Training loss: 0.4700332581996918
Validation loss: 1.7104306631190802

Epoch: 5| Step: 4
Training loss: 0.38760319352149963
Validation loss: 1.714038968727153

Epoch: 5| Step: 5
Training loss: 0.35694628953933716
Validation loss: 1.7304061946048532

Epoch: 5| Step: 6
Training loss: 0.5000971555709839
Validation loss: 1.6997885691222323

Epoch: 5| Step: 7
Training loss: 0.4856688380241394
Validation loss: 1.7387452510095411

Epoch: 5| Step: 8
Training loss: 0.3441794812679291
Validation loss: 1.7673243861044607

Epoch: 5| Step: 9
Training loss: 0.7354274988174438
Validation loss: 1.7750142979365524

Epoch: 5| Step: 10
Training loss: 0.32660627365112305
Validation loss: 1.8228279736734205

Epoch: 279| Step: 0
Training loss: 0.4989137649536133
Validation loss: 1.8285479058501541

Epoch: 5| Step: 1
Training loss: 0.5983991622924805
Validation loss: 1.8085569784205446

Epoch: 5| Step: 2
Training loss: 0.2784068286418915
Validation loss: 1.8097620766649964

Epoch: 5| Step: 3
Training loss: 0.2824748456478119
Validation loss: 1.7587546712608748

Epoch: 5| Step: 4
Training loss: 0.4972810745239258
Validation loss: 1.7203757685999717

Epoch: 5| Step: 5
Training loss: 0.4928972125053406
Validation loss: 1.7204153819750714

Epoch: 5| Step: 6
Training loss: 0.5141561627388
Validation loss: 1.6919329576594855

Epoch: 5| Step: 7
Training loss: 0.5370832681655884
Validation loss: 1.693033520893384

Epoch: 5| Step: 8
Training loss: 0.4126442074775696
Validation loss: 1.6989290457899853

Epoch: 5| Step: 9
Training loss: 0.48273858428001404
Validation loss: 1.6892254967843332

Epoch: 5| Step: 10
Training loss: 0.3113866150379181
Validation loss: 1.74045136667067

Epoch: 280| Step: 0
Training loss: 0.4174744486808777
Validation loss: 1.747161412751803

Epoch: 5| Step: 1
Training loss: 0.3874935805797577
Validation loss: 1.7872964284753288

Epoch: 5| Step: 2
Training loss: 0.4485490918159485
Validation loss: 1.7632539285126554

Epoch: 5| Step: 3
Training loss: 0.7372955679893494
Validation loss: 1.7833429562148226

Epoch: 5| Step: 4
Training loss: 0.5046614408493042
Validation loss: 1.7410739570535638

Epoch: 5| Step: 5
Training loss: 0.2656621038913727
Validation loss: 1.7966093350482244

Epoch: 5| Step: 6
Training loss: 0.3640345633029938
Validation loss: 1.7395728211249075

Epoch: 5| Step: 7
Training loss: 0.42675819993019104
Validation loss: 1.714662959498744

Epoch: 5| Step: 8
Training loss: 0.3858848214149475
Validation loss: 1.686266819636027

Epoch: 5| Step: 9
Training loss: 0.19215404987335205
Validation loss: 1.6595495785436323

Epoch: 5| Step: 10
Training loss: 0.6517958045005798
Validation loss: 1.68419732457848

Epoch: 281| Step: 0
Training loss: 0.19922463595867157
Validation loss: 1.706053828680387

Epoch: 5| Step: 1
Training loss: 0.34367281198501587
Validation loss: 1.731040664898452

Epoch: 5| Step: 2
Training loss: 0.4878174662590027
Validation loss: 1.7204756070208806

Epoch: 5| Step: 3
Training loss: 0.3382640480995178
Validation loss: 1.6995412265100787

Epoch: 5| Step: 4
Training loss: 0.29151207208633423
Validation loss: 1.703763263199919

Epoch: 5| Step: 5
Training loss: 0.45515871047973633
Validation loss: 1.7265872301593903

Epoch: 5| Step: 6
Training loss: 0.39881303906440735
Validation loss: 1.7155923228110037

Epoch: 5| Step: 7
Training loss: 0.5874314904212952
Validation loss: 1.710866888364156

Epoch: 5| Step: 8
Training loss: 0.6178313493728638
Validation loss: 1.668489138285319

Epoch: 5| Step: 9
Training loss: 0.5229922533035278
Validation loss: 1.6790077455582157

Epoch: 5| Step: 10
Training loss: 0.37211304903030396
Validation loss: 1.711227002964225

Epoch: 282| Step: 0
Training loss: 0.37040048837661743
Validation loss: 1.7168990360793246

Epoch: 5| Step: 1
Training loss: 0.40873509645462036
Validation loss: 1.6981401276844803

Epoch: 5| Step: 2
Training loss: 0.29300886392593384
Validation loss: 1.7537472055804344

Epoch: 5| Step: 3
Training loss: 0.2695193886756897
Validation loss: 1.7655733746867026

Epoch: 5| Step: 4
Training loss: 0.45873183012008667
Validation loss: 1.744816186607525

Epoch: 5| Step: 5
Training loss: 0.41378289461135864
Validation loss: 1.7212642905532674

Epoch: 5| Step: 6
Training loss: 0.5927414298057556
Validation loss: 1.7457727065650366

Epoch: 5| Step: 7
Training loss: 0.5763396620750427
Validation loss: 1.7394067010571879

Epoch: 5| Step: 8
Training loss: 0.38449424505233765
Validation loss: 1.767840980201639

Epoch: 5| Step: 9
Training loss: 0.467170387506485
Validation loss: 1.7502617784725722

Epoch: 5| Step: 10
Training loss: 0.45125919580459595
Validation loss: 1.7524062049004339

Epoch: 283| Step: 0
Training loss: 0.26171115040779114
Validation loss: 1.7751623328014086

Epoch: 5| Step: 1
Training loss: 0.47239407896995544
Validation loss: 1.7474635903553297

Epoch: 5| Step: 2
Training loss: 0.35306814312934875
Validation loss: 1.7936238704189178

Epoch: 5| Step: 3
Training loss: 0.46971622109413147
Validation loss: 1.7884127991173857

Epoch: 5| Step: 4
Training loss: 0.4992225766181946
Validation loss: 1.8243576736860379

Epoch: 5| Step: 5
Training loss: 0.3243837058544159
Validation loss: 1.8368552474565403

Epoch: 5| Step: 6
Training loss: 0.5757227540016174
Validation loss: 1.7952314551158617

Epoch: 5| Step: 7
Training loss: 0.5572683215141296
Validation loss: 1.748119269647906

Epoch: 5| Step: 8
Training loss: 0.40549811720848083
Validation loss: 1.6974738874743063

Epoch: 5| Step: 9
Training loss: 0.5069786906242371
Validation loss: 1.6537436028962493

Epoch: 5| Step: 10
Training loss: 0.5214831829071045
Validation loss: 1.637273738461156

Epoch: 284| Step: 0
Training loss: 0.6638072729110718
Validation loss: 1.6772889578214256

Epoch: 5| Step: 1
Training loss: 0.15373504161834717
Validation loss: 1.6891700990738407

Epoch: 5| Step: 2
Training loss: 0.47815021872520447
Validation loss: 1.7252382334842478

Epoch: 5| Step: 3
Training loss: 0.4954739212989807
Validation loss: 1.808444966552078

Epoch: 5| Step: 4
Training loss: 0.5124493837356567
Validation loss: 1.8417512204057427

Epoch: 5| Step: 5
Training loss: 0.4779295325279236
Validation loss: 1.813603025610729

Epoch: 5| Step: 6
Training loss: 0.2826376259326935
Validation loss: 1.8363770438778786

Epoch: 5| Step: 7
Training loss: 0.29527905583381653
Validation loss: 1.7459865718759515

Epoch: 5| Step: 8
Training loss: 0.674704909324646
Validation loss: 1.7725571445239487

Epoch: 5| Step: 9
Training loss: 0.32190993428230286
Validation loss: 1.747433372723159

Epoch: 5| Step: 10
Training loss: 0.6699649095535278
Validation loss: 1.7190308077360994

Epoch: 285| Step: 0
Training loss: 0.6461149454116821
Validation loss: 1.6858403810890772

Epoch: 5| Step: 1
Training loss: 0.5837255716323853
Validation loss: 1.717485027928506

Epoch: 5| Step: 2
Training loss: 0.3665347993373871
Validation loss: 1.7139771625559816

Epoch: 5| Step: 3
Training loss: 0.5318439602851868
Validation loss: 1.7377443364871445

Epoch: 5| Step: 4
Training loss: 0.33922189474105835
Validation loss: 1.7511689996206632

Epoch: 5| Step: 5
Training loss: 0.1952381730079651
Validation loss: 1.7286609065148137

Epoch: 5| Step: 6
Training loss: 0.4520687460899353
Validation loss: 1.735979687783026

Epoch: 5| Step: 7
Training loss: 0.3372308611869812
Validation loss: 1.720032791937551

Epoch: 5| Step: 8
Training loss: 0.26274433732032776
Validation loss: 1.7221261057802426

Epoch: 5| Step: 9
Training loss: 0.5730969309806824
Validation loss: 1.7233105385175316

Epoch: 5| Step: 10
Training loss: 0.44455254077911377
Validation loss: 1.7182634466437883

Epoch: 286| Step: 0
Training loss: 0.6369483470916748
Validation loss: 1.6823501599732267

Epoch: 5| Step: 1
Training loss: 0.3863774836063385
Validation loss: 1.6706220744758524

Epoch: 5| Step: 2
Training loss: 0.4511604309082031
Validation loss: 1.6788921266473749

Epoch: 5| Step: 3
Training loss: 0.42495474219322205
Validation loss: 1.6930769540930306

Epoch: 5| Step: 4
Training loss: 0.32705268263816833
Validation loss: 1.7008359201492802

Epoch: 5| Step: 5
Training loss: 0.23911893367767334
Validation loss: 1.7531942013771302

Epoch: 5| Step: 6
Training loss: 0.598069965839386
Validation loss: 1.7676631366052935

Epoch: 5| Step: 7
Training loss: 0.3419899642467499
Validation loss: 1.7589928616759598

Epoch: 5| Step: 8
Training loss: 0.40160447359085083
Validation loss: 1.7481627323294198

Epoch: 5| Step: 9
Training loss: 0.3698664605617523
Validation loss: 1.7137807441014115

Epoch: 5| Step: 10
Training loss: 0.45505014061927795
Validation loss: 1.6934946749799995

Epoch: 287| Step: 0
Training loss: 0.37343090772628784
Validation loss: 1.6595141246754637

Epoch: 5| Step: 1
Training loss: 0.32166606187820435
Validation loss: 1.6398969478504632

Epoch: 5| Step: 2
Training loss: 0.5685548186302185
Validation loss: 1.6515571660892938

Epoch: 5| Step: 3
Training loss: 0.24122171103954315
Validation loss: 1.66162920254533

Epoch: 5| Step: 4
Training loss: 0.5431585311889648
Validation loss: 1.653535996713946

Epoch: 5| Step: 5
Training loss: 0.5060644745826721
Validation loss: 1.6432307215147122

Epoch: 5| Step: 6
Training loss: 0.46840566396713257
Validation loss: 1.6911615633195447

Epoch: 5| Step: 7
Training loss: 0.3061971664428711
Validation loss: 1.6955406601710985

Epoch: 5| Step: 8
Training loss: 0.4831019937992096
Validation loss: 1.7526110487599527

Epoch: 5| Step: 9
Training loss: 0.5072884559631348
Validation loss: 1.8340010386641308

Epoch: 5| Step: 10
Training loss: 0.4018292725086212
Validation loss: 1.8166449736523371

Epoch: 288| Step: 0
Training loss: 0.562423050403595
Validation loss: 1.8340540726979573

Epoch: 5| Step: 1
Training loss: 0.18449687957763672
Validation loss: 1.8519177283010175

Epoch: 5| Step: 2
Training loss: 0.5274044275283813
Validation loss: 1.78532172659392

Epoch: 5| Step: 3
Training loss: 0.5492687821388245
Validation loss: 1.8137447552014423

Epoch: 5| Step: 4
Training loss: 0.39327946305274963
Validation loss: 1.7529078145180979

Epoch: 5| Step: 5
Training loss: 0.44401365518569946
Validation loss: 1.7417529552213606

Epoch: 5| Step: 6
Training loss: 0.2522764801979065
Validation loss: 1.724726342385815

Epoch: 5| Step: 7
Training loss: 0.394441694021225
Validation loss: 1.7328215581114574

Epoch: 5| Step: 8
Training loss: 0.5676247477531433
Validation loss: 1.7533435398532498

Epoch: 5| Step: 9
Training loss: 0.2144867479801178
Validation loss: 1.7209411654421078

Epoch: 5| Step: 10
Training loss: 0.28313159942626953
Validation loss: 1.7316426730925036

Epoch: 289| Step: 0
Training loss: 0.4067024290561676
Validation loss: 1.7294985914743075

Epoch: 5| Step: 1
Training loss: 0.544612467288971
Validation loss: 1.7616957977253904

Epoch: 5| Step: 2
Training loss: 0.23898057639598846
Validation loss: 1.777416782994424

Epoch: 5| Step: 3
Training loss: 0.28243035078048706
Validation loss: 1.759919374219833

Epoch: 5| Step: 4
Training loss: 0.6725267767906189
Validation loss: 1.7400166437190066

Epoch: 5| Step: 5
Training loss: 0.3161117434501648
Validation loss: 1.6914788920392272

Epoch: 5| Step: 6
Training loss: 0.5247706770896912
Validation loss: 1.6663473357436478

Epoch: 5| Step: 7
Training loss: 0.24103736877441406
Validation loss: 1.6575102626636464

Epoch: 5| Step: 8
Training loss: 0.554228663444519
Validation loss: 1.6557107676741898

Epoch: 5| Step: 9
Training loss: 0.2979423403739929
Validation loss: 1.65331906144337

Epoch: 5| Step: 10
Training loss: 0.5626898407936096
Validation loss: 1.6530992395134383

Epoch: 290| Step: 0
Training loss: 0.5460716485977173
Validation loss: 1.6918051294101182

Epoch: 5| Step: 1
Training loss: 0.3459163308143616
Validation loss: 1.694056717298364

Epoch: 5| Step: 2
Training loss: 0.3971416652202606
Validation loss: 1.7369993156002415

Epoch: 5| Step: 3
Training loss: 0.3736501634120941
Validation loss: 1.7412225930921492

Epoch: 5| Step: 4
Training loss: 0.2997872829437256
Validation loss: 1.7336594430349206

Epoch: 5| Step: 5
Training loss: 0.24341300129890442
Validation loss: 1.7323303094474218

Epoch: 5| Step: 6
Training loss: 0.4227568507194519
Validation loss: 1.7546231592855146

Epoch: 5| Step: 7
Training loss: 0.4563640058040619
Validation loss: 1.7373658828837897

Epoch: 5| Step: 8
Training loss: 0.7364106178283691
Validation loss: 1.6888098562917402

Epoch: 5| Step: 9
Training loss: 0.3482017517089844
Validation loss: 1.6769799429883239

Epoch: 5| Step: 10
Training loss: 0.3901705741882324
Validation loss: 1.6180701524980607

Epoch: 291| Step: 0
Training loss: 0.4004362225532532
Validation loss: 1.6442162964933662

Epoch: 5| Step: 1
Training loss: 0.5062369108200073
Validation loss: 1.6453521764406593

Epoch: 5| Step: 2
Training loss: 0.41024842858314514
Validation loss: 1.6624832717321252

Epoch: 5| Step: 3
Training loss: 0.3047424852848053
Validation loss: 1.714922942141051

Epoch: 5| Step: 4
Training loss: 0.2544533610343933
Validation loss: 1.74290632688871

Epoch: 5| Step: 5
Training loss: 0.23860327899456024
Validation loss: 1.7784867594319005

Epoch: 5| Step: 6
Training loss: 0.4245898723602295
Validation loss: 1.7832491359403055

Epoch: 5| Step: 7
Training loss: 0.38245755434036255
Validation loss: 1.7399836253094416

Epoch: 5| Step: 8
Training loss: 0.41091465950012207
Validation loss: 1.7058555477408952

Epoch: 5| Step: 9
Training loss: 0.38348740339279175
Validation loss: 1.638536951875174

Epoch: 5| Step: 10
Training loss: 0.5493950843811035
Validation loss: 1.6387016786042081

Epoch: 292| Step: 0
Training loss: 0.3089717626571655
Validation loss: 1.603777370145244

Epoch: 5| Step: 1
Training loss: 0.21075968444347382
Validation loss: 1.613921485921388

Epoch: 5| Step: 2
Training loss: 0.4413580000400543
Validation loss: 1.595163381227883

Epoch: 5| Step: 3
Training loss: 0.39734184741973877
Validation loss: 1.6141499768021286

Epoch: 5| Step: 4
Training loss: 0.5247930288314819
Validation loss: 1.6014020865963352

Epoch: 5| Step: 5
Training loss: 0.4029407501220703
Validation loss: 1.6699724953661683

Epoch: 5| Step: 6
Training loss: 0.40583792328834534
Validation loss: 1.6988148791815645

Epoch: 5| Step: 7
Training loss: 0.5365309715270996
Validation loss: 1.6977661348158313

Epoch: 5| Step: 8
Training loss: 0.42386946082115173
Validation loss: 1.7172125924018122

Epoch: 5| Step: 9
Training loss: 0.33888331055641174
Validation loss: 1.791282848645282

Epoch: 5| Step: 10
Training loss: 0.7524204850196838
Validation loss: 1.7931075339676232

Epoch: 293| Step: 0
Training loss: 0.3683181405067444
Validation loss: 1.7526878631243141

Epoch: 5| Step: 1
Training loss: 0.5001225471496582
Validation loss: 1.7432905884199246

Epoch: 5| Step: 2
Training loss: 0.37591683864593506
Validation loss: 1.6995971420759797

Epoch: 5| Step: 3
Training loss: 0.27186864614486694
Validation loss: 1.6578238446225402

Epoch: 5| Step: 4
Training loss: 0.24390120804309845
Validation loss: 1.6399623283775904

Epoch: 5| Step: 5
Training loss: 0.4652818739414215
Validation loss: 1.6381582713896228

Epoch: 5| Step: 6
Training loss: 0.45402970910072327
Validation loss: 1.6466899892335296

Epoch: 5| Step: 7
Training loss: 0.5035271644592285
Validation loss: 1.6201966321596535

Epoch: 5| Step: 8
Training loss: 0.25690004229545593
Validation loss: 1.6186623086211502

Epoch: 5| Step: 9
Training loss: 0.5031112432479858
Validation loss: 1.701149550817346

Epoch: 5| Step: 10
Training loss: 0.41435056924819946
Validation loss: 1.6848492801830333

Epoch: 294| Step: 0
Training loss: 0.4923950135707855
Validation loss: 1.7425625388340285

Epoch: 5| Step: 1
Training loss: 0.36081963777542114
Validation loss: 1.8191874373343684

Epoch: 5| Step: 2
Training loss: 0.3708323836326599
Validation loss: 1.8134431146806287

Epoch: 5| Step: 3
Training loss: 0.28090402483940125
Validation loss: 1.7672097259952175

Epoch: 5| Step: 4
Training loss: 0.6272328495979309
Validation loss: 1.7484053975792342

Epoch: 5| Step: 5
Training loss: 0.33690938353538513
Validation loss: 1.7136015020390993

Epoch: 5| Step: 6
Training loss: 0.5857089161872864
Validation loss: 1.6768845935021677

Epoch: 5| Step: 7
Training loss: 0.3032354414463043
Validation loss: 1.6323764208824403

Epoch: 5| Step: 8
Training loss: 0.3137330114841461
Validation loss: 1.6013777191920946

Epoch: 5| Step: 9
Training loss: 0.38794854283332825
Validation loss: 1.5948399561707691

Epoch: 5| Step: 10
Training loss: 0.27588126063346863
Validation loss: 1.5987431182656238

Epoch: 295| Step: 0
Training loss: 0.4914669394493103
Validation loss: 1.6586080058928458

Epoch: 5| Step: 1
Training loss: 0.28880995512008667
Validation loss: 1.680607767515285

Epoch: 5| Step: 2
Training loss: 0.34878483414649963
Validation loss: 1.7478149629408313

Epoch: 5| Step: 3
Training loss: 0.2729984521865845
Validation loss: 1.7701908926809988

Epoch: 5| Step: 4
Training loss: 0.5923131704330444
Validation loss: 1.7710981522836993

Epoch: 5| Step: 5
Training loss: 0.2888878583908081
Validation loss: 1.765746763957444

Epoch: 5| Step: 6
Training loss: 0.6962765455245972
Validation loss: 1.7811325852588942

Epoch: 5| Step: 7
Training loss: 0.2679165303707123
Validation loss: 1.7745286880000946

Epoch: 5| Step: 8
Training loss: 0.42791658639907837
Validation loss: 1.7542253386589788

Epoch: 5| Step: 9
Training loss: 0.42513900995254517
Validation loss: 1.6758234398339384

Epoch: 5| Step: 10
Training loss: 0.3204194903373718
Validation loss: 1.6603537631291214

Epoch: 296| Step: 0
Training loss: 0.3247387707233429
Validation loss: 1.617309243448319

Epoch: 5| Step: 1
Training loss: 0.48136216402053833
Validation loss: 1.6166942863054172

Epoch: 5| Step: 2
Training loss: 0.47314539551734924
Validation loss: 1.6039294504350232

Epoch: 5| Step: 3
Training loss: 0.46401315927505493
Validation loss: 1.5951476276561778

Epoch: 5| Step: 4
Training loss: 0.47772979736328125
Validation loss: 1.63704082914578

Epoch: 5| Step: 5
Training loss: 0.4005366265773773
Validation loss: 1.6474123872736448

Epoch: 5| Step: 6
Training loss: 0.3279019892215729
Validation loss: 1.6893652292989916

Epoch: 5| Step: 7
Training loss: 0.3615809977054596
Validation loss: 1.7210491472674954

Epoch: 5| Step: 8
Training loss: 0.2559756338596344
Validation loss: 1.7603701212072884

Epoch: 5| Step: 9
Training loss: 0.517943799495697
Validation loss: 1.7798604375572615

Epoch: 5| Step: 10
Training loss: 0.38978588581085205
Validation loss: 1.7739005409261233

Epoch: 297| Step: 0
Training loss: 0.7024352550506592
Validation loss: 1.752363093437687

Epoch: 5| Step: 1
Training loss: 0.21975967288017273
Validation loss: 1.7418213146989063

Epoch: 5| Step: 2
Training loss: 0.38352274894714355
Validation loss: 1.6876137205349502

Epoch: 5| Step: 3
Training loss: 0.45018690824508667
Validation loss: 1.6834754969484063

Epoch: 5| Step: 4
Training loss: 0.34081125259399414
Validation loss: 1.6727914169270506

Epoch: 5| Step: 5
Training loss: 0.33488893508911133
Validation loss: 1.6292585057597007

Epoch: 5| Step: 6
Training loss: 0.34706804156303406
Validation loss: 1.6633621467057096

Epoch: 5| Step: 7
Training loss: 0.28866106271743774
Validation loss: 1.6293210393639022

Epoch: 5| Step: 8
Training loss: 0.3174479007720947
Validation loss: 1.6667017423978416

Epoch: 5| Step: 9
Training loss: 0.48748379945755005
Validation loss: 1.6226485352362356

Epoch: 5| Step: 10
Training loss: 0.3641587495803833
Validation loss: 1.648461143175761

Epoch: 298| Step: 0
Training loss: 0.4383793771266937
Validation loss: 1.7090463651123868

Epoch: 5| Step: 1
Training loss: 0.48762351274490356
Validation loss: 1.69803612847482

Epoch: 5| Step: 2
Training loss: 0.4106479585170746
Validation loss: 1.746350912637608

Epoch: 5| Step: 3
Training loss: 0.39007511734962463
Validation loss: 1.7729812950216315

Epoch: 5| Step: 4
Training loss: 0.55036461353302
Validation loss: 1.775706644340228

Epoch: 5| Step: 5
Training loss: 0.3997949957847595
Validation loss: 1.7006725098497124

Epoch: 5| Step: 6
Training loss: 0.2815776765346527
Validation loss: 1.6889883036254554

Epoch: 5| Step: 7
Training loss: 0.38167038559913635
Validation loss: 1.5983504172294372

Epoch: 5| Step: 8
Training loss: 0.1983197182416916
Validation loss: 1.622369844426391

Epoch: 5| Step: 9
Training loss: 0.32667434215545654
Validation loss: 1.629056570350483

Epoch: 5| Step: 10
Training loss: 0.27837052941322327
Validation loss: 1.6255208664042975

Epoch: 299| Step: 0
Training loss: 0.4248020648956299
Validation loss: 1.6522863705952961

Epoch: 5| Step: 1
Training loss: 0.3514748215675354
Validation loss: 1.663925475971673

Epoch: 5| Step: 2
Training loss: 0.3890749216079712
Validation loss: 1.65288039945787

Epoch: 5| Step: 3
Training loss: 0.294093519449234
Validation loss: 1.657020454765648

Epoch: 5| Step: 4
Training loss: 0.5120692253112793
Validation loss: 1.6916314722389303

Epoch: 5| Step: 5
Training loss: 0.3263089060783386
Validation loss: 1.7204356821634437

Epoch: 5| Step: 6
Training loss: 0.3954905569553375
Validation loss: 1.7020318238965926

Epoch: 5| Step: 7
Training loss: 0.2265511453151703
Validation loss: 1.6739814896737375

Epoch: 5| Step: 8
Training loss: 0.3481345772743225
Validation loss: 1.6495944235914497

Epoch: 5| Step: 9
Training loss: 0.3700941801071167
Validation loss: 1.6844826398357269

Epoch: 5| Step: 10
Training loss: 0.20765790343284607
Validation loss: 1.6804912385120188

Epoch: 300| Step: 0
Training loss: 0.3678474426269531
Validation loss: 1.6742510116228493

Epoch: 5| Step: 1
Training loss: 0.45604443550109863
Validation loss: 1.665584921836853

Epoch: 5| Step: 2
Training loss: 0.3836769461631775
Validation loss: 1.7136696820618005

Epoch: 5| Step: 3
Training loss: 0.159652978181839
Validation loss: 1.7001319200761857

Epoch: 5| Step: 4
Training loss: 0.35103994607925415
Validation loss: 1.6973258103093793

Epoch: 5| Step: 5
Training loss: 0.35279303789138794
Validation loss: 1.741226109125281

Epoch: 5| Step: 6
Training loss: 0.42114096879959106
Validation loss: 1.7255443232033842

Epoch: 5| Step: 7
Training loss: 0.3645060062408447
Validation loss: 1.7082905230983612

Epoch: 5| Step: 8
Training loss: 0.11082810163497925
Validation loss: 1.6541533162516933

Epoch: 5| Step: 9
Training loss: 0.3327490985393524
Validation loss: 1.6819429013036913

Epoch: 5| Step: 10
Training loss: 0.5895905494689941
Validation loss: 1.6564193553822015

Epoch: 301| Step: 0
Training loss: 0.3730132281780243
Validation loss: 1.6602085739053705

Epoch: 5| Step: 1
Training loss: 0.4292968809604645
Validation loss: 1.6323977042269964

Epoch: 5| Step: 2
Training loss: 0.2574903964996338
Validation loss: 1.6254526671542917

Epoch: 5| Step: 3
Training loss: 0.4875851571559906
Validation loss: 1.6748827042118195

Epoch: 5| Step: 4
Training loss: 0.19667784869670868
Validation loss: 1.737612598685808

Epoch: 5| Step: 5
Training loss: 0.2640377879142761
Validation loss: 1.7258559555135748

Epoch: 5| Step: 6
Training loss: 0.4365984797477722
Validation loss: 1.7386748137012604

Epoch: 5| Step: 7
Training loss: 0.4137760102748871
Validation loss: 1.7739852179763138

Epoch: 5| Step: 8
Training loss: 0.3950135111808777
Validation loss: 1.6904883564159434

Epoch: 5| Step: 9
Training loss: 0.2812741696834564
Validation loss: 1.7329759008140975

Epoch: 5| Step: 10
Training loss: 0.22616101801395416
Validation loss: 1.7251273406449186

Epoch: 302| Step: 0
Training loss: 0.4578360617160797
Validation loss: 1.7131081024805705

Epoch: 5| Step: 1
Training loss: 0.4419892430305481
Validation loss: 1.718170004506265

Epoch: 5| Step: 2
Training loss: 0.3183723986148834
Validation loss: 1.7129404506375712

Epoch: 5| Step: 3
Training loss: 0.25210174918174744
Validation loss: 1.6412865654114754

Epoch: 5| Step: 4
Training loss: 0.2391590178012848
Validation loss: 1.6496880208292315

Epoch: 5| Step: 5
Training loss: 0.5628089904785156
Validation loss: 1.6610331612248574

Epoch: 5| Step: 6
Training loss: 0.30071666836738586
Validation loss: 1.6633720269767187

Epoch: 5| Step: 7
Training loss: 0.31633779406547546
Validation loss: 1.6661386887232463

Epoch: 5| Step: 8
Training loss: 0.2675878405570984
Validation loss: 1.727017612867458

Epoch: 5| Step: 9
Training loss: 0.30063456296920776
Validation loss: 1.7365839353171728

Epoch: 5| Step: 10
Training loss: 0.47076770663261414
Validation loss: 1.7498288372511506

Epoch: 303| Step: 0
Training loss: 0.2125699520111084
Validation loss: 1.7337528326178109

Epoch: 5| Step: 1
Training loss: 0.21621468663215637
Validation loss: 1.7322995149961082

Epoch: 5| Step: 2
Training loss: 0.5978454947471619
Validation loss: 1.7093527611865793

Epoch: 5| Step: 3
Training loss: 0.264137327671051
Validation loss: 1.719925791986527

Epoch: 5| Step: 4
Training loss: 0.2607651352882385
Validation loss: 1.7143757420201455

Epoch: 5| Step: 5
Training loss: 0.3311852812767029
Validation loss: 1.663041539089654

Epoch: 5| Step: 6
Training loss: 0.4575828015804291
Validation loss: 1.6487135400054276

Epoch: 5| Step: 7
Training loss: 0.3467399477958679
Validation loss: 1.6694836385788456

Epoch: 5| Step: 8
Training loss: 0.370428204536438
Validation loss: 1.629192804777494

Epoch: 5| Step: 9
Training loss: 0.4011845588684082
Validation loss: 1.614091642441288

Epoch: 5| Step: 10
Training loss: 0.3405897617340088
Validation loss: 1.580903164802059

Epoch: 304| Step: 0
Training loss: 0.21184463798999786
Validation loss: 1.597009272985561

Epoch: 5| Step: 1
Training loss: 0.22892741858959198
Validation loss: 1.6122721754094607

Epoch: 5| Step: 2
Training loss: 0.1516267955303192
Validation loss: 1.6674412078754877

Epoch: 5| Step: 3
Training loss: 0.3231768310070038
Validation loss: 1.6500494608315088

Epoch: 5| Step: 4
Training loss: 0.3657785654067993
Validation loss: 1.6462258574783162

Epoch: 5| Step: 5
Training loss: 0.3619736433029175
Validation loss: 1.6359900774494294

Epoch: 5| Step: 6
Training loss: 0.6544264554977417
Validation loss: 1.6362647164252497

Epoch: 5| Step: 7
Training loss: 0.25604718923568726
Validation loss: 1.635391302006219

Epoch: 5| Step: 8
Training loss: 0.3567647337913513
Validation loss: 1.634493544537534

Epoch: 5| Step: 9
Training loss: 0.3098374903202057
Validation loss: 1.6437152175493137

Epoch: 5| Step: 10
Training loss: 0.5190773010253906
Validation loss: 1.6540283682525798

Epoch: 305| Step: 0
Training loss: 0.40799230337142944
Validation loss: 1.6691632578449864

Epoch: 5| Step: 1
Training loss: 0.2608078420162201
Validation loss: 1.66263787592611

Epoch: 5| Step: 2
Training loss: 0.5068556070327759
Validation loss: 1.6946219500674997

Epoch: 5| Step: 3
Training loss: 0.45198744535446167
Validation loss: 1.660600091821404

Epoch: 5| Step: 4
Training loss: 0.24477402865886688
Validation loss: 1.678293138421992

Epoch: 5| Step: 5
Training loss: 0.3096811771392822
Validation loss: 1.6551127100503573

Epoch: 5| Step: 6
Training loss: 0.2512056231498718
Validation loss: 1.631295395153825

Epoch: 5| Step: 7
Training loss: 0.2435436248779297
Validation loss: 1.6479169809690086

Epoch: 5| Step: 8
Training loss: 0.4387282431125641
Validation loss: 1.617447608260698

Epoch: 5| Step: 9
Training loss: 0.3006848096847534
Validation loss: 1.5906586557306268

Epoch: 5| Step: 10
Training loss: 0.23942695558071136
Validation loss: 1.6314368196713027

Epoch: 306| Step: 0
Training loss: 0.3497971296310425
Validation loss: 1.655759330718748

Epoch: 5| Step: 1
Training loss: 0.2090417891740799
Validation loss: 1.6675116246746433

Epoch: 5| Step: 2
Training loss: 0.46032780408859253
Validation loss: 1.7138485190688924

Epoch: 5| Step: 3
Training loss: 0.4067186713218689
Validation loss: 1.7152263272193171

Epoch: 5| Step: 4
Training loss: 0.2988002896308899
Validation loss: 1.7222926642305108

Epoch: 5| Step: 5
Training loss: 0.33406883478164673
Validation loss: 1.7177549741601432

Epoch: 5| Step: 6
Training loss: 0.2854614853858948
Validation loss: 1.6906702954282042

Epoch: 5| Step: 7
Training loss: 0.3791993260383606
Validation loss: 1.6744733805297523

Epoch: 5| Step: 8
Training loss: 0.3107798099517822
Validation loss: 1.6641306505408338

Epoch: 5| Step: 9
Training loss: 0.3673081696033478
Validation loss: 1.650251470586305

Epoch: 5| Step: 10
Training loss: 0.34561219811439514
Validation loss: 1.6340711373154835

Epoch: 307| Step: 0
Training loss: 0.3078140616416931
Validation loss: 1.6481147760986

Epoch: 5| Step: 1
Training loss: 0.23636069893836975
Validation loss: 1.6586037656312347

Epoch: 5| Step: 2
Training loss: 0.27164116501808167
Validation loss: 1.629878838857015

Epoch: 5| Step: 3
Training loss: 0.3077281415462494
Validation loss: 1.646378699169364

Epoch: 5| Step: 4
Training loss: 0.5738805532455444
Validation loss: 1.6751042207082112

Epoch: 5| Step: 5
Training loss: 0.24654307961463928
Validation loss: 1.694730193384232

Epoch: 5| Step: 6
Training loss: 0.3303189277648926
Validation loss: 1.7042366650796705

Epoch: 5| Step: 7
Training loss: 0.3326082229614258
Validation loss: 1.747506821027366

Epoch: 5| Step: 8
Training loss: 0.4200104773044586
Validation loss: 1.718843848474564

Epoch: 5| Step: 9
Training loss: 0.4311901926994324
Validation loss: 1.76591452347335

Epoch: 5| Step: 10
Training loss: 0.19726184010505676
Validation loss: 1.7375277473080544

Epoch: 308| Step: 0
Training loss: 0.38027364015579224
Validation loss: 1.7242101751348025

Epoch: 5| Step: 1
Training loss: 0.2737123370170593
Validation loss: 1.6692993679354269

Epoch: 5| Step: 2
Training loss: 0.21897724270820618
Validation loss: 1.695966359107725

Epoch: 5| Step: 3
Training loss: 0.3011164665222168
Validation loss: 1.691157046184745

Epoch: 5| Step: 4
Training loss: 0.2747401297092438
Validation loss: 1.6629690944507558

Epoch: 5| Step: 5
Training loss: 0.3772038519382477
Validation loss: 1.6686931489616312

Epoch: 5| Step: 6
Training loss: 0.3378182351589203
Validation loss: 1.6662939312637493

Epoch: 5| Step: 7
Training loss: 0.269591748714447
Validation loss: 1.6512893848521735

Epoch: 5| Step: 8
Training loss: 0.3023338317871094
Validation loss: 1.6717101758526218

Epoch: 5| Step: 9
Training loss: 0.2283007800579071
Validation loss: 1.6485501361149613

Epoch: 5| Step: 10
Training loss: 0.5062556862831116
Validation loss: 1.6681402485857728

Epoch: 309| Step: 0
Training loss: 0.36315804719924927
Validation loss: 1.6715918048735587

Epoch: 5| Step: 1
Training loss: 0.506734311580658
Validation loss: 1.6744829736730105

Epoch: 5| Step: 2
Training loss: 0.3027699291706085
Validation loss: 1.6790179116751558

Epoch: 5| Step: 3
Training loss: 0.3909614682197571
Validation loss: 1.673176916696692

Epoch: 5| Step: 4
Training loss: 0.14905551075935364
Validation loss: 1.6616047454136673

Epoch: 5| Step: 5
Training loss: 0.16182470321655273
Validation loss: 1.6512525671271867

Epoch: 5| Step: 6
Training loss: 0.11583395302295685
Validation loss: 1.64334911172108

Epoch: 5| Step: 7
Training loss: 0.3591517210006714
Validation loss: 1.6505264710354548

Epoch: 5| Step: 8
Training loss: 0.41668105125427246
Validation loss: 1.686161671915362

Epoch: 5| Step: 9
Training loss: 0.2985089421272278
Validation loss: 1.6380085945129395

Epoch: 5| Step: 10
Training loss: 0.238753542304039
Validation loss: 1.6804232110259354

Epoch: 310| Step: 0
Training loss: 0.23101063072681427
Validation loss: 1.6864920790477465

Epoch: 5| Step: 1
Training loss: 0.4241233766078949
Validation loss: 1.6795379833508564

Epoch: 5| Step: 2
Training loss: 0.3119431138038635
Validation loss: 1.69690502074457

Epoch: 5| Step: 3
Training loss: 0.4464941918849945
Validation loss: 1.7647683351270613

Epoch: 5| Step: 4
Training loss: 0.2573447823524475
Validation loss: 1.7476458472590293

Epoch: 5| Step: 5
Training loss: 0.3430876135826111
Validation loss: 1.7154690732238114

Epoch: 5| Step: 6
Training loss: 0.1948324739933014
Validation loss: 1.7444472505200295

Epoch: 5| Step: 7
Training loss: 0.11209523677825928
Validation loss: 1.6996895702936317

Epoch: 5| Step: 8
Training loss: 0.3581181764602661
Validation loss: 1.673133559124444

Epoch: 5| Step: 9
Training loss: 0.23956935107707977
Validation loss: 1.6279193073190668

Epoch: 5| Step: 10
Training loss: 0.4431949555873871
Validation loss: 1.6104357293857041

Epoch: 311| Step: 0
Training loss: 0.3281603157520294
Validation loss: 1.6349761909054172

Epoch: 5| Step: 1
Training loss: 0.3142525255680084
Validation loss: 1.6570372619936544

Epoch: 5| Step: 2
Training loss: 0.26827457547187805
Validation loss: 1.6373216131682038

Epoch: 5| Step: 3
Training loss: 0.2992319166660309
Validation loss: 1.6149378438149729

Epoch: 5| Step: 4
Training loss: 0.29594501852989197
Validation loss: 1.673110459440498

Epoch: 5| Step: 5
Training loss: 0.32268041372299194
Validation loss: 1.6826208483788274

Epoch: 5| Step: 6
Training loss: 0.38770437240600586
Validation loss: 1.6657504291944607

Epoch: 5| Step: 7
Training loss: 0.3125901520252228
Validation loss: 1.6544867715527933

Epoch: 5| Step: 8
Training loss: 0.22054603695869446
Validation loss: 1.6671093279315579

Epoch: 5| Step: 9
Training loss: 0.1877875179052353
Validation loss: 1.6630293579511746

Epoch: 5| Step: 10
Training loss: 0.3274264633655548
Validation loss: 1.700776123231457

Epoch: 312| Step: 0
Training loss: 0.1983807533979416
Validation loss: 1.692038679635653

Epoch: 5| Step: 1
Training loss: 0.24583816528320312
Validation loss: 1.7092194082916423

Epoch: 5| Step: 2
Training loss: 0.3238198757171631
Validation loss: 1.6735875452718427

Epoch: 5| Step: 3
Training loss: 0.44561076164245605
Validation loss: 1.6766979489275204

Epoch: 5| Step: 4
Training loss: 0.2639208436012268
Validation loss: 1.649486477657031

Epoch: 5| Step: 5
Training loss: 0.45844364166259766
Validation loss: 1.6411748880981116

Epoch: 5| Step: 6
Training loss: 0.26327967643737793
Validation loss: 1.644667161408291

Epoch: 5| Step: 7
Training loss: 0.20537802577018738
Validation loss: 1.6561302074822046

Epoch: 5| Step: 8
Training loss: 0.524902880191803
Validation loss: 1.6539680816793954

Epoch: 5| Step: 9
Training loss: 0.24207787215709686
Validation loss: 1.6653417720589587

Epoch: 5| Step: 10
Training loss: 0.4383983612060547
Validation loss: 1.7342656325268488

Epoch: 313| Step: 0
Training loss: 0.6111046671867371
Validation loss: 1.7045533528891943

Epoch: 5| Step: 1
Training loss: 0.2297540009021759
Validation loss: 1.6611842455402497

Epoch: 5| Step: 2
Training loss: 0.28146737813949585
Validation loss: 1.6740972431757117

Epoch: 5| Step: 3
Training loss: 0.5670297741889954
Validation loss: 1.6327751118649718

Epoch: 5| Step: 4
Training loss: 0.23724094033241272
Validation loss: 1.6356655269540765

Epoch: 5| Step: 5
Training loss: 0.2958904802799225
Validation loss: 1.6442966768818517

Epoch: 5| Step: 6
Training loss: 0.2714292109012604
Validation loss: 1.6454642921365716

Epoch: 5| Step: 7
Training loss: 0.38791486620903015
Validation loss: 1.6549300096368278

Epoch: 5| Step: 8
Training loss: 0.3297896981239319
Validation loss: 1.6692839553279262

Epoch: 5| Step: 9
Training loss: 0.5192750692367554
Validation loss: 1.6949209679839432

Epoch: 5| Step: 10
Training loss: 0.11795853078365326
Validation loss: 1.6951236237761795

Epoch: 314| Step: 0
Training loss: 0.31893548369407654
Validation loss: 1.7556200668375979

Epoch: 5| Step: 1
Training loss: 0.33713650703430176
Validation loss: 1.8045001901606077

Epoch: 5| Step: 2
Training loss: 0.47365251183509827
Validation loss: 1.8215344951998802

Epoch: 5| Step: 3
Training loss: 0.2652658522129059
Validation loss: 1.8283550713651924

Epoch: 5| Step: 4
Training loss: 0.3924686014652252
Validation loss: 1.8297503750811341

Epoch: 5| Step: 5
Training loss: 0.24995434284210205
Validation loss: 1.7700329698542112

Epoch: 5| Step: 6
Training loss: 0.46076449751853943
Validation loss: 1.6889711913242136

Epoch: 5| Step: 7
Training loss: 0.24587580561637878
Validation loss: 1.6200095376660746

Epoch: 5| Step: 8
Training loss: 0.3992795944213867
Validation loss: 1.6364099979400635

Epoch: 5| Step: 9
Training loss: 0.3842484951019287
Validation loss: 1.6312895244167698

Epoch: 5| Step: 10
Training loss: 0.5347077250480652
Validation loss: 1.654719393740418

Epoch: 315| Step: 0
Training loss: 0.3838309943675995
Validation loss: 1.5860199928283691

Epoch: 5| Step: 1
Training loss: 0.3096545338630676
Validation loss: 1.630698924423546

Epoch: 5| Step: 2
Training loss: 0.4465896189212799
Validation loss: 1.632674478715466

Epoch: 5| Step: 3
Training loss: 0.2784726619720459
Validation loss: 1.6667087180640108

Epoch: 5| Step: 4
Training loss: 0.5165413618087769
Validation loss: 1.7677374424472931

Epoch: 5| Step: 5
Training loss: 0.4400502145290375
Validation loss: 1.780683308519343

Epoch: 5| Step: 6
Training loss: 0.29532843828201294
Validation loss: 1.7798396413044264

Epoch: 5| Step: 7
Training loss: 0.39884400367736816
Validation loss: 1.813456102084088

Epoch: 5| Step: 8
Training loss: 0.30137741565704346
Validation loss: 1.8087695414020168

Epoch: 5| Step: 9
Training loss: 0.14773806929588318
Validation loss: 1.7628899364061252

Epoch: 5| Step: 10
Training loss: 0.3185870945453644
Validation loss: 1.774641607397346

Epoch: 316| Step: 0
Training loss: 0.2584936022758484
Validation loss: 1.7273957716521395

Epoch: 5| Step: 1
Training loss: 0.2829812169075012
Validation loss: 1.7553422348473662

Epoch: 5| Step: 2
Training loss: 0.27352839708328247
Validation loss: 1.7056406390282415

Epoch: 5| Step: 3
Training loss: 0.38828667998313904
Validation loss: 1.6748368945173038

Epoch: 5| Step: 4
Training loss: 0.25081995129585266
Validation loss: 1.639362895360557

Epoch: 5| Step: 5
Training loss: 0.46891021728515625
Validation loss: 1.629273703021388

Epoch: 5| Step: 6
Training loss: 0.3596545159816742
Validation loss: 1.651282992414249

Epoch: 5| Step: 7
Training loss: 0.3061308264732361
Validation loss: 1.6512520249171923

Epoch: 5| Step: 8
Training loss: 0.28850728273391724
Validation loss: 1.6689088626574444

Epoch: 5| Step: 9
Training loss: 0.2724657356739044
Validation loss: 1.7130424296984108

Epoch: 5| Step: 10
Training loss: 0.45783814787864685
Validation loss: 1.7393099261868386

Epoch: 317| Step: 0
Training loss: 0.304105281829834
Validation loss: 1.7175866583342194

Epoch: 5| Step: 1
Training loss: 0.2550038993358612
Validation loss: 1.7543292289139123

Epoch: 5| Step: 2
Training loss: 0.2720066010951996
Validation loss: 1.7527122689831642

Epoch: 5| Step: 3
Training loss: 0.3586931824684143
Validation loss: 1.7484810775326145

Epoch: 5| Step: 4
Training loss: 0.3636954426765442
Validation loss: 1.7581595887419998

Epoch: 5| Step: 5
Training loss: 0.21193091571331024
Validation loss: 1.7574669020150298

Epoch: 5| Step: 6
Training loss: 0.5678719878196716
Validation loss: 1.7026939956090783

Epoch: 5| Step: 7
Training loss: 0.22617311775684357
Validation loss: 1.6495912600589056

Epoch: 5| Step: 8
Training loss: 0.20428769290447235
Validation loss: 1.6271673466569634

Epoch: 5| Step: 9
Training loss: 0.3100490868091583
Validation loss: 1.6258239887093986

Epoch: 5| Step: 10
Training loss: 0.20235668122768402
Validation loss: 1.6021552380695139

Epoch: 318| Step: 0
Training loss: 0.2631768584251404
Validation loss: 1.6437230911306155

Epoch: 5| Step: 1
Training loss: 0.24836115539073944
Validation loss: 1.642959217871389

Epoch: 5| Step: 2
Training loss: 0.17812572419643402
Validation loss: 1.7139464270684026

Epoch: 5| Step: 3
Training loss: 0.16921444237232208
Validation loss: 1.729769947708294

Epoch: 5| Step: 4
Training loss: 0.527237057685852
Validation loss: 1.7549229668032738

Epoch: 5| Step: 5
Training loss: 0.2762686610221863
Validation loss: 1.7755020690220658

Epoch: 5| Step: 6
Training loss: 0.5380445718765259
Validation loss: 1.773016865535449

Epoch: 5| Step: 7
Training loss: 0.5084028244018555
Validation loss: 1.7402066825538554

Epoch: 5| Step: 8
Training loss: 0.23876428604125977
Validation loss: 1.6966775437837005

Epoch: 5| Step: 9
Training loss: 0.3057038187980652
Validation loss: 1.6647934298361502

Epoch: 5| Step: 10
Training loss: 0.39484500885009766
Validation loss: 1.6133549623591925

Epoch: 319| Step: 0
Training loss: 0.2834092974662781
Validation loss: 1.5937456225836149

Epoch: 5| Step: 1
Training loss: 0.2182711362838745
Validation loss: 1.6163538412381244

Epoch: 5| Step: 2
Training loss: 0.33366286754608154
Validation loss: 1.6014524493166196

Epoch: 5| Step: 3
Training loss: 0.26868966221809387
Validation loss: 1.6102623003785328

Epoch: 5| Step: 4
Training loss: 0.33851271867752075
Validation loss: 1.6300005643598494

Epoch: 5| Step: 5
Training loss: 0.3582722842693329
Validation loss: 1.6275354059793616

Epoch: 5| Step: 6
Training loss: 0.376590371131897
Validation loss: 1.6696657185913415

Epoch: 5| Step: 7
Training loss: 0.3809638023376465
Validation loss: 1.7735482262026878

Epoch: 5| Step: 8
Training loss: 0.29894015192985535
Validation loss: 1.8100885691181305

Epoch: 5| Step: 9
Training loss: 0.16359026730060577
Validation loss: 1.7953322292656027

Epoch: 5| Step: 10
Training loss: 0.34700682759284973
Validation loss: 1.809407708465412

Epoch: 320| Step: 0
Training loss: 0.14279761910438538
Validation loss: 1.7997227125270392

Epoch: 5| Step: 1
Training loss: 0.23090510070323944
Validation loss: 1.770326598998039

Epoch: 5| Step: 2
Training loss: 0.524770975112915
Validation loss: 1.7469815643884803

Epoch: 5| Step: 3
Training loss: 0.2112809121608734
Validation loss: 1.710789131861861

Epoch: 5| Step: 4
Training loss: 0.2634998857975006
Validation loss: 1.6710766412878548

Epoch: 5| Step: 5
Training loss: 0.27878233790397644
Validation loss: 1.6356874409542288

Epoch: 5| Step: 6
Training loss: 0.4382149577140808
Validation loss: 1.6634771721337431

Epoch: 5| Step: 7
Training loss: 0.32655787467956543
Validation loss: 1.6536176050862958

Epoch: 5| Step: 8
Training loss: 0.21451222896575928
Validation loss: 1.6852622442348029

Epoch: 5| Step: 9
Training loss: 0.373666375875473
Validation loss: 1.6881026632042342

Epoch: 5| Step: 10
Training loss: 0.3180069029331207
Validation loss: 1.736032288561585

Epoch: 321| Step: 0
Training loss: 0.19906029105186462
Validation loss: 1.6817148372691164

Epoch: 5| Step: 1
Training loss: 0.1855522096157074
Validation loss: 1.7300969528895553

Epoch: 5| Step: 2
Training loss: 0.3819931149482727
Validation loss: 1.7554295409110285

Epoch: 5| Step: 3
Training loss: 0.2576788365840912
Validation loss: 1.6987361279867028

Epoch: 5| Step: 4
Training loss: 0.25307202339172363
Validation loss: 1.7047921342234458

Epoch: 5| Step: 5
Training loss: 0.35661011934280396
Validation loss: 1.7080250170923048

Epoch: 5| Step: 6
Training loss: 0.42264002561569214
Validation loss: 1.7481465057660175

Epoch: 5| Step: 7
Training loss: 0.3081813156604767
Validation loss: 1.727895668757859

Epoch: 5| Step: 8
Training loss: 0.2178349792957306
Validation loss: 1.6956266780053415

Epoch: 5| Step: 9
Training loss: 0.2794415056705475
Validation loss: 1.682222527842368

Epoch: 5| Step: 10
Training loss: 0.17672084271907806
Validation loss: 1.6617382226451751

Epoch: 322| Step: 0
Training loss: 0.20236821472644806
Validation loss: 1.617529703724769

Epoch: 5| Step: 1
Training loss: 0.17742720246315002
Validation loss: 1.653840103457051

Epoch: 5| Step: 2
Training loss: 0.1462874859571457
Validation loss: 1.6604159288508917

Epoch: 5| Step: 3
Training loss: 0.46143394708633423
Validation loss: 1.6278337073582474

Epoch: 5| Step: 4
Training loss: 0.23591092228889465
Validation loss: 1.6886830893895959

Epoch: 5| Step: 5
Training loss: 0.447753369808197
Validation loss: 1.6094091566660071

Epoch: 5| Step: 6
Training loss: 0.35187849402427673
Validation loss: 1.6306292177528463

Epoch: 5| Step: 7
Training loss: 0.30517998337745667
Validation loss: 1.6743634195737942

Epoch: 5| Step: 8
Training loss: 0.35598936676979065
Validation loss: 1.6809823461758193

Epoch: 5| Step: 9
Training loss: 0.3171321153640747
Validation loss: 1.7346878256849063

Epoch: 5| Step: 10
Training loss: 0.40970465540885925
Validation loss: 1.697258992861676

Epoch: 323| Step: 0
Training loss: 0.4481712877750397
Validation loss: 1.7258380305382512

Epoch: 5| Step: 1
Training loss: 0.35914137959480286
Validation loss: 1.7130175354660198

Epoch: 5| Step: 2
Training loss: 0.21069416403770447
Validation loss: 1.6627593886467718

Epoch: 5| Step: 3
Training loss: 0.1895410120487213
Validation loss: 1.6912277975390035

Epoch: 5| Step: 4
Training loss: 0.28977710008621216
Validation loss: 1.6778310088701145

Epoch: 5| Step: 5
Training loss: 0.1656283736228943
Validation loss: 1.6995084901009836

Epoch: 5| Step: 6
Training loss: 0.4366609454154968
Validation loss: 1.7141464987108785

Epoch: 5| Step: 7
Training loss: 0.3372669517993927
Validation loss: 1.667505778292174

Epoch: 5| Step: 8
Training loss: 0.32049599289894104
Validation loss: 1.6650776388824626

Epoch: 5| Step: 9
Training loss: 0.3190644383430481
Validation loss: 1.6421896449981197

Epoch: 5| Step: 10
Training loss: 0.2633327841758728
Validation loss: 1.6454553411852928

Epoch: 324| Step: 0
Training loss: 0.3120303750038147
Validation loss: 1.6810002865329865

Epoch: 5| Step: 1
Training loss: 0.21766996383666992
Validation loss: 1.690654461101819

Epoch: 5| Step: 2
Training loss: 0.5048756003379822
Validation loss: 1.7466095788504488

Epoch: 5| Step: 3
Training loss: 0.2582382261753082
Validation loss: 1.7814693092018046

Epoch: 5| Step: 4
Training loss: 0.32873326539993286
Validation loss: 1.7629608518333846

Epoch: 5| Step: 5
Training loss: 0.29190120100975037
Validation loss: 1.7692186922155402

Epoch: 5| Step: 6
Training loss: 0.3024722635746002
Validation loss: 1.7103693228895946

Epoch: 5| Step: 7
Training loss: 0.20999202132225037
Validation loss: 1.6535938298830422

Epoch: 5| Step: 8
Training loss: 0.2386704683303833
Validation loss: 1.6465034023407967

Epoch: 5| Step: 9
Training loss: 0.3308009207248688
Validation loss: 1.640292884201132

Epoch: 5| Step: 10
Training loss: 0.2923746705055237
Validation loss: 1.6335078285586448

Epoch: 325| Step: 0
Training loss: 0.2201795130968094
Validation loss: 1.7212466309147496

Epoch: 5| Step: 1
Training loss: 0.457078754901886
Validation loss: 1.6942956306601082

Epoch: 5| Step: 2
Training loss: 0.23336243629455566
Validation loss: 1.7786298746703773

Epoch: 5| Step: 3
Training loss: 0.33022528886795044
Validation loss: 1.790727448719804

Epoch: 5| Step: 4
Training loss: 0.3638390600681305
Validation loss: 1.7570267825998285

Epoch: 5| Step: 5
Training loss: 0.44440919160842896
Validation loss: 1.7542053012437717

Epoch: 5| Step: 6
Training loss: 0.1968597173690796
Validation loss: 1.7241684185561312

Epoch: 5| Step: 7
Training loss: 0.23627547919750214
Validation loss: 1.714669587791607

Epoch: 5| Step: 8
Training loss: 0.2835284173488617
Validation loss: 1.6660039835078742

Epoch: 5| Step: 9
Training loss: 0.21297602355480194
Validation loss: 1.6130977625487952

Epoch: 5| Step: 10
Training loss: 0.40228280425071716
Validation loss: 1.6397701027572795

Epoch: 326| Step: 0
Training loss: 0.34462106227874756
Validation loss: 1.606747454212558

Epoch: 5| Step: 1
Training loss: 0.2421281337738037
Validation loss: 1.5550883482861262

Epoch: 5| Step: 2
Training loss: 0.27994540333747864
Validation loss: 1.5723111424394833

Epoch: 5| Step: 3
Training loss: 0.2564545273780823
Validation loss: 1.5891791300107074

Epoch: 5| Step: 4
Training loss: 0.3482546806335449
Validation loss: 1.6382222008961502

Epoch: 5| Step: 5
Training loss: 0.272081583738327
Validation loss: 1.6542429001100603

Epoch: 5| Step: 6
Training loss: 0.18376681208610535
Validation loss: 1.644018223208766

Epoch: 5| Step: 7
Training loss: 0.3303191363811493
Validation loss: 1.6174460649490356

Epoch: 5| Step: 8
Training loss: 0.37014418840408325
Validation loss: 1.635754628848004

Epoch: 5| Step: 9
Training loss: 0.18597057461738586
Validation loss: 1.6181111258845176

Epoch: 5| Step: 10
Training loss: 0.40915629267692566
Validation loss: 1.6048706872488863

Epoch: 327| Step: 0
Training loss: 0.408499151468277
Validation loss: 1.645101160131475

Epoch: 5| Step: 1
Training loss: 0.1880471408367157
Validation loss: 1.6435272270633328

Epoch: 5| Step: 2
Training loss: 0.28124287724494934
Validation loss: 1.6709258082092449

Epoch: 5| Step: 3
Training loss: 0.42054319381713867
Validation loss: 1.6422070123816048

Epoch: 5| Step: 4
Training loss: 0.2861558198928833
Validation loss: 1.675954516215991

Epoch: 5| Step: 5
Training loss: 0.19117429852485657
Validation loss: 1.6155595510236678

Epoch: 5| Step: 6
Training loss: 0.20623886585235596
Validation loss: 1.6433901248439666

Epoch: 5| Step: 7
Training loss: 0.2226148098707199
Validation loss: 1.6140966671769337

Epoch: 5| Step: 8
Training loss: 0.23531179130077362
Validation loss: 1.591669108278008

Epoch: 5| Step: 9
Training loss: 0.2519415318965912
Validation loss: 1.6013057936904251

Epoch: 5| Step: 10
Training loss: 0.16278232634067535
Validation loss: 1.6294489740043558

Epoch: 328| Step: 0
Training loss: 0.2306973934173584
Validation loss: 1.6557656693202194

Epoch: 5| Step: 1
Training loss: 0.29500967264175415
Validation loss: 1.6459209983066847

Epoch: 5| Step: 2
Training loss: 0.20663094520568848
Validation loss: 1.689944505050618

Epoch: 5| Step: 3
Training loss: 0.18995317816734314
Validation loss: 1.7016737717454151

Epoch: 5| Step: 4
Training loss: 0.25046175718307495
Validation loss: 1.7264644907366844

Epoch: 5| Step: 5
Training loss: 0.3081585466861725
Validation loss: 1.737937053044637

Epoch: 5| Step: 6
Training loss: 0.3856196999549866
Validation loss: 1.7514233755809006

Epoch: 5| Step: 7
Training loss: 0.40272173285484314
Validation loss: 1.7797966016236173

Epoch: 5| Step: 8
Training loss: 0.5205572843551636
Validation loss: 1.7280602916594474

Epoch: 5| Step: 9
Training loss: 0.2138018161058426
Validation loss: 1.690865876854107

Epoch: 5| Step: 10
Training loss: 0.21424496173858643
Validation loss: 1.6358367909667313

Epoch: 329| Step: 0
Training loss: 0.5097159743309021
Validation loss: 1.5993386109670003

Epoch: 5| Step: 1
Training loss: 0.24860505759716034
Validation loss: 1.6019176001189857

Epoch: 5| Step: 2
Training loss: 0.3458382487297058
Validation loss: 1.6264051647596462

Epoch: 5| Step: 3
Training loss: 0.1989327222108841
Validation loss: 1.6624287302776048

Epoch: 5| Step: 4
Training loss: 0.3103618025779724
Validation loss: 1.6696453914847424

Epoch: 5| Step: 5
Training loss: 0.16728028655052185
Validation loss: 1.6345107965571906

Epoch: 5| Step: 6
Training loss: 0.29861074686050415
Validation loss: 1.617746139085421

Epoch: 5| Step: 7
Training loss: 0.32994934916496277
Validation loss: 1.6681199650610647

Epoch: 5| Step: 8
Training loss: 0.18452608585357666
Validation loss: 1.7283357612548336

Epoch: 5| Step: 9
Training loss: 0.31937175989151
Validation loss: 1.7376877941111082

Epoch: 5| Step: 10
Training loss: 0.30716636776924133
Validation loss: 1.7640163116557623

Epoch: 330| Step: 0
Training loss: 0.21234333515167236
Validation loss: 1.7683265593744093

Epoch: 5| Step: 1
Training loss: 0.2896326184272766
Validation loss: 1.7295150756835938

Epoch: 5| Step: 2
Training loss: 0.39032500982284546
Validation loss: 1.685159142299365

Epoch: 5| Step: 3
Training loss: 0.1785670965909958
Validation loss: 1.6687649629449333

Epoch: 5| Step: 4
Training loss: 0.381780743598938
Validation loss: 1.6329972526078582

Epoch: 5| Step: 5
Training loss: 0.22322607040405273
Validation loss: 1.6340424091585222

Epoch: 5| Step: 6
Training loss: 0.2785821557044983
Validation loss: 1.5918951778001682

Epoch: 5| Step: 7
Training loss: 0.29553061723709106
Validation loss: 1.5807779335206555

Epoch: 5| Step: 8
Training loss: 0.2347695380449295
Validation loss: 1.6055850034118981

Epoch: 5| Step: 9
Training loss: 0.22079196572303772
Validation loss: 1.6200671503620763

Epoch: 5| Step: 10
Training loss: 0.29543933272361755
Validation loss: 1.623909044009383

Epoch: 331| Step: 0
Training loss: 0.27050161361694336
Validation loss: 1.6681418611157326

Epoch: 5| Step: 1
Training loss: 0.26216134428977966
Validation loss: 1.6348810516377932

Epoch: 5| Step: 2
Training loss: 0.32843995094299316
Validation loss: 1.6759825996173325

Epoch: 5| Step: 3
Training loss: 0.24380715191364288
Validation loss: 1.6667152399657874

Epoch: 5| Step: 4
Training loss: 0.1412758082151413
Validation loss: 1.653516984754993

Epoch: 5| Step: 5
Training loss: 0.19750156998634338
Validation loss: 1.6284027304700626

Epoch: 5| Step: 6
Training loss: 0.36422497034072876
Validation loss: 1.6355437130056403

Epoch: 5| Step: 7
Training loss: 0.2602381110191345
Validation loss: 1.6393326251737532

Epoch: 5| Step: 8
Training loss: 0.3310471177101135
Validation loss: 1.635978434034573

Epoch: 5| Step: 9
Training loss: 0.3040076196193695
Validation loss: 1.6249228472350745

Epoch: 5| Step: 10
Training loss: 0.1769157350063324
Validation loss: 1.6099449088496547

Epoch: 332| Step: 0
Training loss: 0.18547090888023376
Validation loss: 1.6089482089524627

Epoch: 5| Step: 1
Training loss: 0.34183287620544434
Validation loss: 1.6395987669626872

Epoch: 5| Step: 2
Training loss: 0.1458893120288849
Validation loss: 1.6033362188646871

Epoch: 5| Step: 3
Training loss: 0.24568255245685577
Validation loss: 1.6036126305980067

Epoch: 5| Step: 4
Training loss: 0.4270245134830475
Validation loss: 1.65641878497216

Epoch: 5| Step: 5
Training loss: 0.1799326390028
Validation loss: 1.6183094068240094

Epoch: 5| Step: 6
Training loss: 0.21931993961334229
Validation loss: 1.6737861607664375

Epoch: 5| Step: 7
Training loss: 0.2595537304878235
Validation loss: 1.7023266707697222

Epoch: 5| Step: 8
Training loss: 0.32636314630508423
Validation loss: 1.6914091879321682

Epoch: 5| Step: 9
Training loss: 0.3066882789134979
Validation loss: 1.6862169375983618

Epoch: 5| Step: 10
Training loss: 0.32717233896255493
Validation loss: 1.660123017526442

Epoch: 333| Step: 0
Training loss: 0.27208051085472107
Validation loss: 1.6481291863226122

Epoch: 5| Step: 1
Training loss: 0.28376567363739014
Validation loss: 1.6063153500198035

Epoch: 5| Step: 2
Training loss: 0.159693643450737
Validation loss: 1.5764734809116652

Epoch: 5| Step: 3
Training loss: 0.37388089299201965
Validation loss: 1.5886874288640997

Epoch: 5| Step: 4
Training loss: 0.29476994276046753
Validation loss: 1.5746793708493632

Epoch: 5| Step: 5
Training loss: 0.19556479156017303
Validation loss: 1.6169527243542414

Epoch: 5| Step: 6
Training loss: 0.28678449988365173
Validation loss: 1.6148734310621857

Epoch: 5| Step: 7
Training loss: 0.23273082077503204
Validation loss: 1.6476878504599295

Epoch: 5| Step: 8
Training loss: 0.3826781213283539
Validation loss: 1.7108647720788115

Epoch: 5| Step: 9
Training loss: 0.16143539547920227
Validation loss: 1.6929022060927523

Epoch: 5| Step: 10
Training loss: 0.21000665426254272
Validation loss: 1.7445977503253567

Epoch: 334| Step: 0
Training loss: 0.2107085883617401
Validation loss: 1.7692248975076983

Epoch: 5| Step: 1
Training loss: 0.22173568606376648
Validation loss: 1.7513503105409685

Epoch: 5| Step: 2
Training loss: 0.2698957026004791
Validation loss: 1.7281307738314393

Epoch: 5| Step: 3
Training loss: 0.20788104832172394
Validation loss: 1.6925074003076042

Epoch: 5| Step: 4
Training loss: 0.2141437977552414
Validation loss: 1.6754362570342196

Epoch: 5| Step: 5
Training loss: 0.28447845578193665
Validation loss: 1.6452183966995568

Epoch: 5| Step: 6
Training loss: 0.272014319896698
Validation loss: 1.6816568554088633

Epoch: 5| Step: 7
Training loss: 0.4696221351623535
Validation loss: 1.6483298450387933

Epoch: 5| Step: 8
Training loss: 0.2769162058830261
Validation loss: 1.6665129982015139

Epoch: 5| Step: 9
Training loss: 0.14205439388751984
Validation loss: 1.671107974103702

Epoch: 5| Step: 10
Training loss: 0.345567524433136
Validation loss: 1.6781324096905288

Epoch: 335| Step: 0
Training loss: 0.3080267906188965
Validation loss: 1.6816942473893524

Epoch: 5| Step: 1
Training loss: 0.2270619422197342
Validation loss: 1.6586661146533104

Epoch: 5| Step: 2
Training loss: 0.1676575243473053
Validation loss: 1.6872020882944907

Epoch: 5| Step: 3
Training loss: 0.3274318277835846
Validation loss: 1.6550354790943924

Epoch: 5| Step: 4
Training loss: 0.31383779644966125
Validation loss: 1.6559245740213702

Epoch: 5| Step: 5
Training loss: 0.24836936593055725
Validation loss: 1.6474611618185555

Epoch: 5| Step: 6
Training loss: 0.3648565709590912
Validation loss: 1.633085407236571

Epoch: 5| Step: 7
Training loss: 0.3092777132987976
Validation loss: 1.6231168188074583

Epoch: 5| Step: 8
Training loss: 0.1848139613866806
Validation loss: 1.607144017373362

Epoch: 5| Step: 9
Training loss: 0.2867359519004822
Validation loss: 1.6010163214898878

Epoch: 5| Step: 10
Training loss: 0.19685976207256317
Validation loss: 1.5635363709542058

Epoch: 336| Step: 0
Training loss: 0.19566261768341064
Validation loss: 1.6221090773100495

Epoch: 5| Step: 1
Training loss: 0.3398975431919098
Validation loss: 1.6142513059800672

Epoch: 5| Step: 2
Training loss: 0.30118364095687866
Validation loss: 1.6948091035248132

Epoch: 5| Step: 3
Training loss: 0.38085901737213135
Validation loss: 1.7110818765496696

Epoch: 5| Step: 4
Training loss: 0.3731843829154968
Validation loss: 1.750120544946322

Epoch: 5| Step: 5
Training loss: 0.39133164286613464
Validation loss: 1.7680260366009128

Epoch: 5| Step: 6
Training loss: 0.2713142931461334
Validation loss: 1.736140352423473

Epoch: 5| Step: 7
Training loss: 0.2451440840959549
Validation loss: 1.7060168879006499

Epoch: 5| Step: 8
Training loss: 0.20246663689613342
Validation loss: 1.7002014357556579

Epoch: 5| Step: 9
Training loss: 0.14585331082344055
Validation loss: 1.6445159425017655

Epoch: 5| Step: 10
Training loss: 0.12756145000457764
Validation loss: 1.5828973785523446

Epoch: 337| Step: 0
Training loss: 0.20152850449085236
Validation loss: 1.617058504012323

Epoch: 5| Step: 1
Training loss: 0.2241860330104828
Validation loss: 1.6188966356297976

Epoch: 5| Step: 2
Training loss: 0.329839289188385
Validation loss: 1.594919943040417

Epoch: 5| Step: 3
Training loss: 0.2892575263977051
Validation loss: 1.5802659091129099

Epoch: 5| Step: 4
Training loss: 0.25827354192733765
Validation loss: 1.539752015503504

Epoch: 5| Step: 5
Training loss: 0.18911945819854736
Validation loss: 1.5898145014239895

Epoch: 5| Step: 6
Training loss: 0.23996968567371368
Validation loss: 1.5884665571233278

Epoch: 5| Step: 7
Training loss: 0.23536750674247742
Validation loss: 1.5746039511055074

Epoch: 5| Step: 8
Training loss: 0.20242004096508026
Validation loss: 1.6102314302998204

Epoch: 5| Step: 9
Training loss: 0.25667479634284973
Validation loss: 1.5986638671608382

Epoch: 5| Step: 10
Training loss: 0.45654329657554626
Validation loss: 1.6169133481159006

Epoch: 338| Step: 0
Training loss: 0.3203533887863159
Validation loss: 1.6147172758656163

Epoch: 5| Step: 1
Training loss: 0.3006366193294525
Validation loss: 1.6053106169546805

Epoch: 5| Step: 2
Training loss: 0.16317163407802582
Validation loss: 1.6640412025554205

Epoch: 5| Step: 3
Training loss: 0.23067279160022736
Validation loss: 1.6535624291307183

Epoch: 5| Step: 4
Training loss: 0.21612128615379333
Validation loss: 1.6819305484012892

Epoch: 5| Step: 5
Training loss: 0.2787448763847351
Validation loss: 1.6959722221538585

Epoch: 5| Step: 6
Training loss: 0.2895866334438324
Validation loss: 1.6602841564404067

Epoch: 5| Step: 7
Training loss: 0.21471205353736877
Validation loss: 1.638075449133432

Epoch: 5| Step: 8
Training loss: 0.19293168187141418
Validation loss: 1.631787638510427

Epoch: 5| Step: 9
Training loss: 0.14530645310878754
Validation loss: 1.6470067449795303

Epoch: 5| Step: 10
Training loss: 0.25606098771095276
Validation loss: 1.6559513615023704

Epoch: 339| Step: 0
Training loss: 0.17876502871513367
Validation loss: 1.5746218030170729

Epoch: 5| Step: 1
Training loss: 0.21172185242176056
Validation loss: 1.6056733618500412

Epoch: 5| Step: 2
Training loss: 0.2824253439903259
Validation loss: 1.5931114637723534

Epoch: 5| Step: 3
Training loss: 0.1591300070285797
Validation loss: 1.60379256227965

Epoch: 5| Step: 4
Training loss: 0.24846847355365753
Validation loss: 1.5965786941589848

Epoch: 5| Step: 5
Training loss: 0.3075435757637024
Validation loss: 1.5683013072577856

Epoch: 5| Step: 6
Training loss: 0.275668203830719
Validation loss: 1.562718451664012

Epoch: 5| Step: 7
Training loss: 0.23353461921215057
Validation loss: 1.573174944487951

Epoch: 5| Step: 8
Training loss: 0.23591962456703186
Validation loss: 1.594588900125155

Epoch: 5| Step: 9
Training loss: 0.2090100795030594
Validation loss: 1.6357306575262418

Epoch: 5| Step: 10
Training loss: 0.19217747449874878
Validation loss: 1.6509891389518656

Epoch: 340| Step: 0
Training loss: 0.20533442497253418
Validation loss: 1.6853716488807433

Epoch: 5| Step: 1
Training loss: 0.29011303186416626
Validation loss: 1.6957923391813874

Epoch: 5| Step: 2
Training loss: 0.23908421397209167
Validation loss: 1.6513525439846901

Epoch: 5| Step: 3
Training loss: 0.4395190179347992
Validation loss: 1.6836721499760945

Epoch: 5| Step: 4
Training loss: 0.20265407860279083
Validation loss: 1.6445477944548412

Epoch: 5| Step: 5
Training loss: 0.24789080023765564
Validation loss: 1.600401625517876

Epoch: 5| Step: 6
Training loss: 0.24544870853424072
Validation loss: 1.5826286205681421

Epoch: 5| Step: 7
Training loss: 0.24848933517932892
Validation loss: 1.5597358839486235

Epoch: 5| Step: 8
Training loss: 0.14926782250404358
Validation loss: 1.5685496061078963

Epoch: 5| Step: 9
Training loss: 0.21957314014434814
Validation loss: 1.5876370796593287

Epoch: 5| Step: 10
Training loss: 0.30493927001953125
Validation loss: 1.5834961886047034

Epoch: 341| Step: 0
Training loss: 0.21933837234973907
Validation loss: 1.5736456404450119

Epoch: 5| Step: 1
Training loss: 0.15531429648399353
Validation loss: 1.60710516155407

Epoch: 5| Step: 2
Training loss: 0.37779098749160767
Validation loss: 1.5885559487086471

Epoch: 5| Step: 3
Training loss: 0.3153928816318512
Validation loss: 1.612374633871099

Epoch: 5| Step: 4
Training loss: 0.1719583421945572
Validation loss: 1.6214134795691377

Epoch: 5| Step: 5
Training loss: 0.2213170975446701
Validation loss: 1.5984306386722031

Epoch: 5| Step: 6
Training loss: 0.2581174373626709
Validation loss: 1.6009180609897902

Epoch: 5| Step: 7
Training loss: 0.29262667894363403
Validation loss: 1.5904677234670168

Epoch: 5| Step: 8
Training loss: 0.24922367930412292
Validation loss: 1.6092996225562146

Epoch: 5| Step: 9
Training loss: 0.20256416499614716
Validation loss: 1.5998746502783991

Epoch: 5| Step: 10
Training loss: 0.19684824347496033
Validation loss: 1.5868244658234298

Epoch: 342| Step: 0
Training loss: 0.19977691769599915
Validation loss: 1.6391106241492814

Epoch: 5| Step: 1
Training loss: 0.2057780921459198
Validation loss: 1.6430997592146679

Epoch: 5| Step: 2
Training loss: 0.2581290006637573
Validation loss: 1.6943503772058794

Epoch: 5| Step: 3
Training loss: 0.30246469378471375
Validation loss: 1.6370391653430076

Epoch: 5| Step: 4
Training loss: 0.17467114329338074
Validation loss: 1.6198295303570327

Epoch: 5| Step: 5
Training loss: 0.27324697375297546
Validation loss: 1.6341978414084322

Epoch: 5| Step: 6
Training loss: 0.21228861808776855
Validation loss: 1.6099773478764359

Epoch: 5| Step: 7
Training loss: 0.2905632555484772
Validation loss: 1.6099799640717045

Epoch: 5| Step: 8
Training loss: 0.20989832282066345
Validation loss: 1.6094675615269651

Epoch: 5| Step: 9
Training loss: 0.30509153008461
Validation loss: 1.5853953053874354

Epoch: 5| Step: 10
Training loss: 0.29344460368156433
Validation loss: 1.592289686203003

Epoch: 343| Step: 0
Training loss: 0.2181154191493988
Validation loss: 1.6031398529647498

Epoch: 5| Step: 1
Training loss: 0.24299128353595734
Validation loss: 1.612828718718662

Epoch: 5| Step: 2
Training loss: 0.2093333750963211
Validation loss: 1.6510164788974229

Epoch: 5| Step: 3
Training loss: 0.2344350814819336
Validation loss: 1.6067700924411896

Epoch: 5| Step: 4
Training loss: 0.24289003014564514
Validation loss: 1.6581474901527486

Epoch: 5| Step: 5
Training loss: 0.3973214030265808
Validation loss: 1.6612125750510924

Epoch: 5| Step: 6
Training loss: 0.25014036893844604
Validation loss: 1.6536606255398

Epoch: 5| Step: 7
Training loss: 0.2272484302520752
Validation loss: 1.6792370183493501

Epoch: 5| Step: 8
Training loss: 0.14000903069972992
Validation loss: 1.6806591198008547

Epoch: 5| Step: 9
Training loss: 0.35075169801712036
Validation loss: 1.6725675700813212

Epoch: 5| Step: 10
Training loss: 0.20712897181510925
Validation loss: 1.6326744171880907

Epoch: 344| Step: 0
Training loss: 0.2636684775352478
Validation loss: 1.6163651853479364

Epoch: 5| Step: 1
Training loss: 0.17448510229587555
Validation loss: 1.599406893535327

Epoch: 5| Step: 2
Training loss: 0.21160602569580078
Validation loss: 1.5884289638970488

Epoch: 5| Step: 3
Training loss: 0.2633717656135559
Validation loss: 1.6313980638339955

Epoch: 5| Step: 4
Training loss: 0.3339914381504059
Validation loss: 1.5770935089357438

Epoch: 5| Step: 5
Training loss: 0.3724457621574402
Validation loss: 1.5758257399323166

Epoch: 5| Step: 6
Training loss: 0.21620504558086395
Validation loss: 1.5660718333336614

Epoch: 5| Step: 7
Training loss: 0.22589531540870667
Validation loss: 1.6158642897041895

Epoch: 5| Step: 8
Training loss: 0.14805558323860168
Validation loss: 1.595233214798794

Epoch: 5| Step: 9
Training loss: 0.2190423309803009
Validation loss: 1.6026022382961806

Epoch: 5| Step: 10
Training loss: 0.26694732904434204
Validation loss: 1.6129762408553914

Epoch: 345| Step: 0
Training loss: 0.22885584831237793
Validation loss: 1.6045874805860623

Epoch: 5| Step: 1
Training loss: 0.23660340905189514
Validation loss: 1.6150326446820331

Epoch: 5| Step: 2
Training loss: 0.2735896706581116
Validation loss: 1.6422526362121745

Epoch: 5| Step: 3
Training loss: 0.3191831707954407
Validation loss: 1.623074880210302

Epoch: 5| Step: 4
Training loss: 0.22317108511924744
Validation loss: 1.614113074477001

Epoch: 5| Step: 5
Training loss: 0.23515014350414276
Validation loss: 1.6206269956404162

Epoch: 5| Step: 6
Training loss: 0.29308420419692993
Validation loss: 1.656163937302046

Epoch: 5| Step: 7
Training loss: 0.19827374815940857
Validation loss: 1.6476367263383762

Epoch: 5| Step: 8
Training loss: 0.2309490144252777
Validation loss: 1.6875503716930267

Epoch: 5| Step: 9
Training loss: 0.28524547815322876
Validation loss: 1.6228395187726585

Epoch: 5| Step: 10
Training loss: 0.13939201831817627
Validation loss: 1.6788835845967776

Epoch: 346| Step: 0
Training loss: 0.15443404018878937
Validation loss: 1.6325720471720542

Epoch: 5| Step: 1
Training loss: 0.2992691099643707
Validation loss: 1.6308308416797268

Epoch: 5| Step: 2
Training loss: 0.3389851450920105
Validation loss: 1.6402193705240886

Epoch: 5| Step: 3
Training loss: 0.21216145157814026
Validation loss: 1.606951250824877

Epoch: 5| Step: 4
Training loss: 0.23399069905281067
Validation loss: 1.606288153638122

Epoch: 5| Step: 5
Training loss: 0.22852683067321777
Validation loss: 1.615039780575742

Epoch: 5| Step: 6
Training loss: 0.16187922656536102
Validation loss: 1.5707794158689437

Epoch: 5| Step: 7
Training loss: 0.14337722957134247
Validation loss: 1.5977760796905847

Epoch: 5| Step: 8
Training loss: 0.20136108994483948
Validation loss: 1.6041578746611072

Epoch: 5| Step: 9
Training loss: 0.23010511696338654
Validation loss: 1.6312546422404628

Epoch: 5| Step: 10
Training loss: 0.15974119305610657
Validation loss: 1.630568265914917

Epoch: 347| Step: 0
Training loss: 0.10578689724206924
Validation loss: 1.6570661465326946

Epoch: 5| Step: 1
Training loss: 0.16890016198158264
Validation loss: 1.6560554542849142

Epoch: 5| Step: 2
Training loss: 0.15119105577468872
Validation loss: 1.6868740512478737

Epoch: 5| Step: 3
Training loss: 0.3545683026313782
Validation loss: 1.6527581189268379

Epoch: 5| Step: 4
Training loss: 0.198080912232399
Validation loss: 1.6353779441566878

Epoch: 5| Step: 5
Training loss: 0.23984107375144958
Validation loss: 1.636900016056594

Epoch: 5| Step: 6
Training loss: 0.2067013531923294
Validation loss: 1.6202470846073602

Epoch: 5| Step: 7
Training loss: 0.17373187839984894
Validation loss: 1.6180719214100991

Epoch: 5| Step: 8
Training loss: 0.3486289381980896
Validation loss: 1.625701735096593

Epoch: 5| Step: 9
Training loss: 0.25022056698799133
Validation loss: 1.6079219336150794

Epoch: 5| Step: 10
Training loss: 0.17596139013767242
Validation loss: 1.5628428074621386

Epoch: 348| Step: 0
Training loss: 0.28912094235420227
Validation loss: 1.6032646163817375

Epoch: 5| Step: 1
Training loss: 0.2909582257270813
Validation loss: 1.630724363429572

Epoch: 5| Step: 2
Training loss: 0.22708070278167725
Validation loss: 1.6261464536830943

Epoch: 5| Step: 3
Training loss: 0.2156144678592682
Validation loss: 1.6269388634671447

Epoch: 5| Step: 4
Training loss: 0.1859009563922882
Validation loss: 1.6927526048434678

Epoch: 5| Step: 5
Training loss: 0.25070902705192566
Validation loss: 1.6976511286151024

Epoch: 5| Step: 6
Training loss: 0.24182458221912384
Validation loss: 1.6722820728055892

Epoch: 5| Step: 7
Training loss: 0.2442551553249359
Validation loss: 1.6903562789322228

Epoch: 5| Step: 8
Training loss: 0.2515885829925537
Validation loss: 1.6301305447855303

Epoch: 5| Step: 9
Training loss: 0.24745729565620422
Validation loss: 1.6186544664444462

Epoch: 5| Step: 10
Training loss: 0.1676258146762848
Validation loss: 1.603161802855871

Epoch: 349| Step: 0
Training loss: 0.2106730043888092
Validation loss: 1.5950286952398156

Epoch: 5| Step: 1
Training loss: 0.3460668921470642
Validation loss: 1.5719312160245833

Epoch: 5| Step: 2
Training loss: 0.16750462353229523
Validation loss: 1.6003088925474434

Epoch: 5| Step: 3
Training loss: 0.2496829330921173
Validation loss: 1.603164965106595

Epoch: 5| Step: 4
Training loss: 0.2337314635515213
Validation loss: 1.646351796324535

Epoch: 5| Step: 5
Training loss: 0.3574497699737549
Validation loss: 1.6728056374416556

Epoch: 5| Step: 6
Training loss: 0.15360622107982635
Validation loss: 1.671180650752078

Epoch: 5| Step: 7
Training loss: 0.26194897294044495
Validation loss: 1.7243289088690152

Epoch: 5| Step: 8
Training loss: 0.3452863097190857
Validation loss: 1.7166550441454815

Epoch: 5| Step: 9
Training loss: 0.17442013323307037
Validation loss: 1.705716747109608

Epoch: 5| Step: 10
Training loss: 0.20753157138824463
Validation loss: 1.6608969242342058

Epoch: 350| Step: 0
Training loss: 0.19848397374153137
Validation loss: 1.7037168407952914

Epoch: 5| Step: 1
Training loss: 0.278455525636673
Validation loss: 1.7130658524010771

Epoch: 5| Step: 2
Training loss: 0.3368544578552246
Validation loss: 1.706902301439675

Epoch: 5| Step: 3
Training loss: 0.1725546419620514
Validation loss: 1.6668594357787923

Epoch: 5| Step: 4
Training loss: 0.27409738302230835
Validation loss: 1.6340263030862296

Epoch: 5| Step: 5
Training loss: 0.2353760302066803
Validation loss: 1.6318308076550883

Epoch: 5| Step: 6
Training loss: 0.36610493063926697
Validation loss: 1.5909585978395195

Epoch: 5| Step: 7
Training loss: 0.2358575314283371
Validation loss: 1.613416903762407

Epoch: 5| Step: 8
Training loss: 0.2874695360660553
Validation loss: 1.5997296071821643

Epoch: 5| Step: 9
Training loss: 0.15438656508922577
Validation loss: 1.5948205327474942

Epoch: 5| Step: 10
Training loss: 0.2327130287885666
Validation loss: 1.599548578262329

Epoch: 351| Step: 0
Training loss: 0.18103285133838654
Validation loss: 1.5857101435302405

Epoch: 5| Step: 1
Training loss: 0.28367123007774353
Validation loss: 1.5967224938895113

Epoch: 5| Step: 2
Training loss: 0.2830328047275543
Validation loss: 1.6470770194966307

Epoch: 5| Step: 3
Training loss: 0.2698896825313568
Validation loss: 1.6177006806096723

Epoch: 5| Step: 4
Training loss: 0.2180405557155609
Validation loss: 1.618685835151262

Epoch: 5| Step: 5
Training loss: 0.22244206070899963
Validation loss: 1.5925943761743524

Epoch: 5| Step: 6
Training loss: 0.13906103372573853
Validation loss: 1.6180189245490617

Epoch: 5| Step: 7
Training loss: 0.22207674384117126
Validation loss: 1.6560526112074494

Epoch: 5| Step: 8
Training loss: 0.2627762258052826
Validation loss: 1.639709314992351

Epoch: 5| Step: 9
Training loss: 0.466087281703949
Validation loss: 1.6511819542095225

Epoch: 5| Step: 10
Training loss: 0.1930769681930542
Validation loss: 1.6287971722182406

Epoch: 352| Step: 0
Training loss: 0.2749482989311218
Validation loss: 1.5960806979927966

Epoch: 5| Step: 1
Training loss: 0.28217774629592896
Validation loss: 1.5522164042278002

Epoch: 5| Step: 2
Training loss: 0.1867372989654541
Validation loss: 1.6183797928594774

Epoch: 5| Step: 3
Training loss: 0.23659725487232208
Validation loss: 1.6210618390831897

Epoch: 5| Step: 4
Training loss: 0.17559517920017242
Validation loss: 1.6298813678885018

Epoch: 5| Step: 5
Training loss: 0.28011608123779297
Validation loss: 1.6191495592876146

Epoch: 5| Step: 6
Training loss: 0.23212930560112
Validation loss: 1.6572774059029036

Epoch: 5| Step: 7
Training loss: 0.21449287235736847
Validation loss: 1.63891799219193

Epoch: 5| Step: 8
Training loss: 0.22155825793743134
Validation loss: 1.631544122131922

Epoch: 5| Step: 9
Training loss: 0.18315628170967102
Validation loss: 1.6588590260474914

Epoch: 5| Step: 10
Training loss: 0.3257954716682434
Validation loss: 1.660380817228748

Epoch: 353| Step: 0
Training loss: 0.18780377507209778
Validation loss: 1.6303003577775852

Epoch: 5| Step: 1
Training loss: 0.262416273355484
Validation loss: 1.613894329276136

Epoch: 5| Step: 2
Training loss: 0.22784848511219025
Validation loss: 1.5879320611235916

Epoch: 5| Step: 3
Training loss: 0.22879727184772491
Validation loss: 1.5963158774119552

Epoch: 5| Step: 4
Training loss: 0.1591542661190033
Validation loss: 1.637004057566325

Epoch: 5| Step: 5
Training loss: 0.35814565420150757
Validation loss: 1.6377711962628108

Epoch: 5| Step: 6
Training loss: 0.24219122529029846
Validation loss: 1.5828106236714188

Epoch: 5| Step: 7
Training loss: 0.1914389580488205
Validation loss: 1.5800732925374021

Epoch: 5| Step: 8
Training loss: 0.2393055409193039
Validation loss: 1.631135981570008

Epoch: 5| Step: 9
Training loss: 0.24368388950824738
Validation loss: 1.6285744828562583

Epoch: 5| Step: 10
Training loss: 0.1996806412935257
Validation loss: 1.665098068534687

Epoch: 354| Step: 0
Training loss: 0.18548454344272614
Validation loss: 1.6913172429607761

Epoch: 5| Step: 1
Training loss: 0.23966917395591736
Validation loss: 1.7345244525581278

Epoch: 5| Step: 2
Training loss: 0.18675890564918518
Validation loss: 1.7191116912390596

Epoch: 5| Step: 3
Training loss: 0.352081298828125
Validation loss: 1.683026586809466

Epoch: 5| Step: 4
Training loss: 0.25648069381713867
Validation loss: 1.6996599397351664

Epoch: 5| Step: 5
Training loss: 0.2192685902118683
Validation loss: 1.6605996649752381

Epoch: 5| Step: 6
Training loss: 0.2317645102739334
Validation loss: 1.6160696834646247

Epoch: 5| Step: 7
Training loss: 0.1945486068725586
Validation loss: 1.6394845003722816

Epoch: 5| Step: 8
Training loss: 0.25733157992362976
Validation loss: 1.664366461897409

Epoch: 5| Step: 9
Training loss: 0.24560098350048065
Validation loss: 1.6429868846811273

Epoch: 5| Step: 10
Training loss: 0.21836726367473602
Validation loss: 1.6412486184027888

Epoch: 355| Step: 0
Training loss: 0.10871841013431549
Validation loss: 1.6651120108942832

Epoch: 5| Step: 1
Training loss: 0.22198224067687988
Validation loss: 1.640602461753353

Epoch: 5| Step: 2
Training loss: 0.23646271228790283
Validation loss: 1.5981405396615305

Epoch: 5| Step: 3
Training loss: 0.15580888092517853
Validation loss: 1.6149348110281012

Epoch: 5| Step: 4
Training loss: 0.3529181480407715
Validation loss: 1.6104590841518935

Epoch: 5| Step: 5
Training loss: 0.20562982559204102
Validation loss: 1.6254784753245692

Epoch: 5| Step: 6
Training loss: 0.20803360641002655
Validation loss: 1.6014065614310644

Epoch: 5| Step: 7
Training loss: 0.39070257544517517
Validation loss: 1.6296468114340177

Epoch: 5| Step: 8
Training loss: 0.12558767199516296
Validation loss: 1.6398928575618292

Epoch: 5| Step: 9
Training loss: 0.23987717926502228
Validation loss: 1.6166495328308434

Epoch: 5| Step: 10
Training loss: 0.20724540948867798
Validation loss: 1.68886992239183

Epoch: 356| Step: 0
Training loss: 0.34476393461227417
Validation loss: 1.6379305355010494

Epoch: 5| Step: 1
Training loss: 0.31841012835502625
Validation loss: 1.681898582366205

Epoch: 5| Step: 2
Training loss: 0.22066250443458557
Validation loss: 1.6828440889235465

Epoch: 5| Step: 3
Training loss: 0.229771226644516
Validation loss: 1.6609445143771429

Epoch: 5| Step: 4
Training loss: 0.1741226464509964
Validation loss: 1.655225505111038

Epoch: 5| Step: 5
Training loss: 0.13214841485023499
Validation loss: 1.6015293662266066

Epoch: 5| Step: 6
Training loss: 0.1809341162443161
Validation loss: 1.612482072204672

Epoch: 5| Step: 7
Training loss: 0.1289805769920349
Validation loss: 1.5985364183302848

Epoch: 5| Step: 8
Training loss: 0.238732248544693
Validation loss: 1.5759801339077693

Epoch: 5| Step: 9
Training loss: 0.22041574120521545
Validation loss: 1.5811933445674118

Epoch: 5| Step: 10
Training loss: 0.3005492687225342
Validation loss: 1.5675991965878395

Epoch: 357| Step: 0
Training loss: 0.2470347136259079
Validation loss: 1.5299814619043821

Epoch: 5| Step: 1
Training loss: 0.1784537136554718
Validation loss: 1.5543007491737284

Epoch: 5| Step: 2
Training loss: 0.21276316046714783
Validation loss: 1.5411789955631379

Epoch: 5| Step: 3
Training loss: 0.310890257358551
Validation loss: 1.5792555770566385

Epoch: 5| Step: 4
Training loss: 0.2213340550661087
Validation loss: 1.591824230327401

Epoch: 5| Step: 5
Training loss: 0.3040217459201813
Validation loss: 1.6116802782140753

Epoch: 5| Step: 6
Training loss: 0.16597604751586914
Validation loss: 1.5857311205197406

Epoch: 5| Step: 7
Training loss: 0.20499424636363983
Validation loss: 1.6037692805772186

Epoch: 5| Step: 8
Training loss: 0.2033977061510086
Validation loss: 1.6227582449554114

Epoch: 5| Step: 9
Training loss: 0.20284628868103027
Validation loss: 1.6386085466672016

Epoch: 5| Step: 10
Training loss: 0.3546258211135864
Validation loss: 1.65956409259509

Epoch: 358| Step: 0
Training loss: 0.19473564624786377
Validation loss: 1.6310824399353356

Epoch: 5| Step: 1
Training loss: 0.22370584309101105
Validation loss: 1.6684735077683643

Epoch: 5| Step: 2
Training loss: 0.25832730531692505
Validation loss: 1.6438381620632705

Epoch: 5| Step: 3
Training loss: 0.27426618337631226
Validation loss: 1.6163042886282808

Epoch: 5| Step: 4
Training loss: 0.21615223586559296
Validation loss: 1.6263430554379699

Epoch: 5| Step: 5
Training loss: 0.23794850707054138
Validation loss: 1.6479049267307404

Epoch: 5| Step: 6
Training loss: 0.20060808956623077
Validation loss: 1.6150469677422636

Epoch: 5| Step: 7
Training loss: 0.27691957354545593
Validation loss: 1.5953046160359536

Epoch: 5| Step: 8
Training loss: 0.24786758422851562
Validation loss: 1.6062688032786052

Epoch: 5| Step: 9
Training loss: 0.19913902878761292
Validation loss: 1.6174948112938994

Epoch: 5| Step: 10
Training loss: 0.18595527112483978
Validation loss: 1.617660076387467

Epoch: 359| Step: 0
Training loss: 0.14502108097076416
Validation loss: 1.6257752936373475

Epoch: 5| Step: 1
Training loss: 0.1722361147403717
Validation loss: 1.6833859246264222

Epoch: 5| Step: 2
Training loss: 0.2523205280303955
Validation loss: 1.6698911125941942

Epoch: 5| Step: 3
Training loss: 0.24883727729320526
Validation loss: 1.6694000895305345

Epoch: 5| Step: 4
Training loss: 0.25020939111709595
Validation loss: 1.6678637214886245

Epoch: 5| Step: 5
Training loss: 0.28602370619773865
Validation loss: 1.6575112317198066

Epoch: 5| Step: 6
Training loss: 0.3143172860145569
Validation loss: 1.6400791316904046

Epoch: 5| Step: 7
Training loss: 0.22429995238780975
Validation loss: 1.5888933507345055

Epoch: 5| Step: 8
Training loss: 0.14989891648292542
Validation loss: 1.5711688546724216

Epoch: 5| Step: 9
Training loss: 0.26307064294815063
Validation loss: 1.4935949489634524

Epoch: 5| Step: 10
Training loss: 0.24794135987758636
Validation loss: 1.5226963617468392

Epoch: 360| Step: 0
Training loss: 0.2364603579044342
Validation loss: 1.5185047413713189

Epoch: 5| Step: 1
Training loss: 0.3863435685634613
Validation loss: 1.5326389971599783

Epoch: 5| Step: 2
Training loss: 0.17371277511119843
Validation loss: 1.546170416698661

Epoch: 5| Step: 3
Training loss: 0.1968868225812912
Validation loss: 1.5595109360192412

Epoch: 5| Step: 4
Training loss: 0.15194189548492432
Validation loss: 1.5878166793495097

Epoch: 5| Step: 5
Training loss: 0.22018423676490784
Validation loss: 1.6093581671355872

Epoch: 5| Step: 6
Training loss: 0.17410621047019958
Validation loss: 1.674256092758589

Epoch: 5| Step: 7
Training loss: 0.22166724503040314
Validation loss: 1.6779857399643108

Epoch: 5| Step: 8
Training loss: 0.3095543384552002
Validation loss: 1.6899290841112855

Epoch: 5| Step: 9
Training loss: 0.22074279189109802
Validation loss: 1.6975078646854689

Epoch: 5| Step: 10
Training loss: 0.17796482145786285
Validation loss: 1.6918233889405445

Epoch: 361| Step: 0
Training loss: 0.16977961361408234
Validation loss: 1.6556755291518344

Epoch: 5| Step: 1
Training loss: 0.341539204120636
Validation loss: 1.6127116462235809

Epoch: 5| Step: 2
Training loss: 0.18574543297290802
Validation loss: 1.5714937115228305

Epoch: 5| Step: 3
Training loss: 0.2032613754272461
Validation loss: 1.5915529138298445

Epoch: 5| Step: 4
Training loss: 0.1652948409318924
Validation loss: 1.5588816699161325

Epoch: 5| Step: 5
Training loss: 0.1370038390159607
Validation loss: 1.564198088902299

Epoch: 5| Step: 6
Training loss: 0.19772851467132568
Validation loss: 1.5707487444723807

Epoch: 5| Step: 7
Training loss: 0.16150066256523132
Validation loss: 1.5598133058958157

Epoch: 5| Step: 8
Training loss: 0.28757888078689575
Validation loss: 1.5181819341515983

Epoch: 5| Step: 9
Training loss: 0.24721558392047882
Validation loss: 1.5643329210178827

Epoch: 5| Step: 10
Training loss: 0.26497912406921387
Validation loss: 1.537313070348514

Epoch: 362| Step: 0
Training loss: 0.25748270750045776
Validation loss: 1.5728075196666103

Epoch: 5| Step: 1
Training loss: 0.1564742475748062
Validation loss: 1.595611156955842

Epoch: 5| Step: 2
Training loss: 0.20571133494377136
Validation loss: 1.626041058571108

Epoch: 5| Step: 3
Training loss: 0.1678156852722168
Validation loss: 1.643289069975576

Epoch: 5| Step: 4
Training loss: 0.14920400083065033
Validation loss: 1.7015803578079387

Epoch: 5| Step: 5
Training loss: 0.3059268891811371
Validation loss: 1.675028399754596

Epoch: 5| Step: 6
Training loss: 0.1849672943353653
Validation loss: 1.6661476986382597

Epoch: 5| Step: 7
Training loss: 0.13524417579174042
Validation loss: 1.611107172504548

Epoch: 5| Step: 8
Training loss: 0.1896437108516693
Validation loss: 1.5678763979224748

Epoch: 5| Step: 9
Training loss: 0.3287193775177002
Validation loss: 1.5796336640593827

Epoch: 5| Step: 10
Training loss: 0.18156497180461884
Validation loss: 1.5714182071788336

Epoch: 363| Step: 0
Training loss: 0.12320506572723389
Validation loss: 1.544481251829414

Epoch: 5| Step: 1
Training loss: 0.1480712592601776
Validation loss: 1.5374175412680513

Epoch: 5| Step: 2
Training loss: 0.16962596774101257
Validation loss: 1.5477339490767448

Epoch: 5| Step: 3
Training loss: 0.17050375044345856
Validation loss: 1.544733501249744

Epoch: 5| Step: 4
Training loss: 0.19497182965278625
Validation loss: 1.6169006209219656

Epoch: 5| Step: 5
Training loss: 0.31157711148262024
Validation loss: 1.6123966247804704

Epoch: 5| Step: 6
Training loss: 0.35435619950294495
Validation loss: 1.6126717226479643

Epoch: 5| Step: 7
Training loss: 0.29476866126060486
Validation loss: 1.6296076864324591

Epoch: 5| Step: 8
Training loss: 0.16156703233718872
Validation loss: 1.6618404670428204

Epoch: 5| Step: 9
Training loss: 0.15597863495349884
Validation loss: 1.6113799836045952

Epoch: 5| Step: 10
Training loss: 0.17162489891052246
Validation loss: 1.5869934020503875

Epoch: 364| Step: 0
Training loss: 0.12540242075920105
Validation loss: 1.591458453926989

Epoch: 5| Step: 1
Training loss: 0.19415566325187683
Validation loss: 1.5698338067659767

Epoch: 5| Step: 2
Training loss: 0.17407558858394623
Validation loss: 1.548248056442507

Epoch: 5| Step: 3
Training loss: 0.19769147038459778
Validation loss: 1.5566070771986438

Epoch: 5| Step: 4
Training loss: 0.191175177693367
Validation loss: 1.547029185038741

Epoch: 5| Step: 5
Training loss: 0.14391843974590302
Validation loss: 1.5669562432073778

Epoch: 5| Step: 6
Training loss: 0.27464374899864197
Validation loss: 1.5310063285212363

Epoch: 5| Step: 7
Training loss: 0.2716811001300812
Validation loss: 1.6022734872756466

Epoch: 5| Step: 8
Training loss: 0.2785011827945709
Validation loss: 1.584155612094428

Epoch: 5| Step: 9
Training loss: 0.19089409708976746
Validation loss: 1.5948484046484834

Epoch: 5| Step: 10
Training loss: 0.13513974845409393
Validation loss: 1.6305002525288572

Epoch: 365| Step: 0
Training loss: 0.21528418362140656
Validation loss: 1.6445820370028097

Epoch: 5| Step: 1
Training loss: 0.19836418330669403
Validation loss: 1.6170963805208924

Epoch: 5| Step: 2
Training loss: 0.26086628437042236
Validation loss: 1.6027242034994147

Epoch: 5| Step: 3
Training loss: 0.1659582406282425
Validation loss: 1.6025891765471427

Epoch: 5| Step: 4
Training loss: 0.136039137840271
Validation loss: 1.621765559719455

Epoch: 5| Step: 5
Training loss: 0.21293583512306213
Validation loss: 1.5901752825706237

Epoch: 5| Step: 6
Training loss: 0.14888668060302734
Validation loss: 1.5807327211544078

Epoch: 5| Step: 7
Training loss: 0.13390019536018372
Validation loss: 1.6047417386885612

Epoch: 5| Step: 8
Training loss: 0.13031557202339172
Validation loss: 1.5698415592152586

Epoch: 5| Step: 9
Training loss: 0.2075786143541336
Validation loss: 1.5680976836912093

Epoch: 5| Step: 10
Training loss: 0.39457687735557556
Validation loss: 1.5362183919516943

Epoch: 366| Step: 0
Training loss: 0.2823551297187805
Validation loss: 1.550141049969581

Epoch: 5| Step: 1
Training loss: 0.25098925828933716
Validation loss: 1.5549737945679696

Epoch: 5| Step: 2
Training loss: 0.16605551540851593
Validation loss: 1.5589949136139245

Epoch: 5| Step: 3
Training loss: 0.15883804857730865
Validation loss: 1.6014194552616408

Epoch: 5| Step: 4
Training loss: 0.13110485672950745
Validation loss: 1.6011457071509412

Epoch: 5| Step: 5
Training loss: 0.11632498353719711
Validation loss: 1.6308070139218402

Epoch: 5| Step: 6
Training loss: 0.20361709594726562
Validation loss: 1.6514843458770423

Epoch: 5| Step: 7
Training loss: 0.20993609726428986
Validation loss: 1.6764330325588104

Epoch: 5| Step: 8
Training loss: 0.36505916714668274
Validation loss: 1.6663033834067724

Epoch: 5| Step: 9
Training loss: 0.15114325284957886
Validation loss: 1.6577305973217051

Epoch: 5| Step: 10
Training loss: 0.19785736501216888
Validation loss: 1.6364035811475528

Epoch: 367| Step: 0
Training loss: 0.29220542311668396
Validation loss: 1.6239315771287488

Epoch: 5| Step: 1
Training loss: 0.18310700356960297
Validation loss: 1.6131492609618812

Epoch: 5| Step: 2
Training loss: 0.14898589253425598
Validation loss: 1.5429769440363812

Epoch: 5| Step: 3
Training loss: 0.21836626529693604
Validation loss: 1.5377020630785214

Epoch: 5| Step: 4
Training loss: 0.12697750329971313
Validation loss: 1.6069362471180577

Epoch: 5| Step: 5
Training loss: 0.23668289184570312
Validation loss: 1.5506342226459133

Epoch: 5| Step: 6
Training loss: 0.24247154593467712
Validation loss: 1.5587244418359572

Epoch: 5| Step: 7
Training loss: 0.1440465748310089
Validation loss: 1.5999223096396333

Epoch: 5| Step: 8
Training loss: 0.12801451981067657
Validation loss: 1.5806200581212198

Epoch: 5| Step: 9
Training loss: 0.2614927589893341
Validation loss: 1.5937417091861847

Epoch: 5| Step: 10
Training loss: 0.1481562852859497
Validation loss: 1.6013518764126686

Epoch: 368| Step: 0
Training loss: 0.1879454404115677
Validation loss: 1.5924512775995399

Epoch: 5| Step: 1
Training loss: 0.24122481048107147
Validation loss: 1.5926762319380237

Epoch: 5| Step: 2
Training loss: 0.2385074645280838
Validation loss: 1.588720037091163

Epoch: 5| Step: 3
Training loss: 0.20831015706062317
Validation loss: 1.535640949203122

Epoch: 5| Step: 4
Training loss: 0.111797034740448
Validation loss: 1.577009662505119

Epoch: 5| Step: 5
Training loss: 0.2526702880859375
Validation loss: 1.5431349636406027

Epoch: 5| Step: 6
Training loss: 0.1310362070798874
Validation loss: 1.5635868003291469

Epoch: 5| Step: 7
Training loss: 0.1871793568134308
Validation loss: 1.5860246291724585

Epoch: 5| Step: 8
Training loss: 0.15016862750053406
Validation loss: 1.5686820437831264

Epoch: 5| Step: 9
Training loss: 0.24344055354595184
Validation loss: 1.5763111114501953

Epoch: 5| Step: 10
Training loss: 0.1484665870666504
Validation loss: 1.5751123787254415

Epoch: 369| Step: 0
Training loss: 0.20069722831249237
Validation loss: 1.6030314558295793

Epoch: 5| Step: 1
Training loss: 0.15534670650959015
Validation loss: 1.564200326960574

Epoch: 5| Step: 2
Training loss: 0.18568173050880432
Validation loss: 1.5607036313702982

Epoch: 5| Step: 3
Training loss: 0.2002030313014984
Validation loss: 1.5812071305449291

Epoch: 5| Step: 4
Training loss: 0.1087116003036499
Validation loss: 1.5420695030561058

Epoch: 5| Step: 5
Training loss: 0.2928890585899353
Validation loss: 1.5483727647412209

Epoch: 5| Step: 6
Training loss: 0.1501835286617279
Validation loss: 1.5738070818685717

Epoch: 5| Step: 7
Training loss: 0.14976590871810913
Validation loss: 1.5299791789823962

Epoch: 5| Step: 8
Training loss: 0.2782946527004242
Validation loss: 1.5914516923248128

Epoch: 5| Step: 9
Training loss: 0.09176158159971237
Validation loss: 1.5965142583334317

Epoch: 5| Step: 10
Training loss: 0.13705775141716003
Validation loss: 1.6066953302711569

Epoch: 370| Step: 0
Training loss: 0.22991767525672913
Validation loss: 1.6048405266577197

Epoch: 5| Step: 1
Training loss: 0.11229107528924942
Validation loss: 1.5973692171035274

Epoch: 5| Step: 2
Training loss: 0.17681053280830383
Validation loss: 1.603118165846794

Epoch: 5| Step: 3
Training loss: 0.09440300613641739
Validation loss: 1.560040388056027

Epoch: 5| Step: 4
Training loss: 0.19426488876342773
Validation loss: 1.5193571493189821

Epoch: 5| Step: 5
Training loss: 0.20958742499351501
Validation loss: 1.527557776820275

Epoch: 5| Step: 6
Training loss: 0.12875080108642578
Validation loss: 1.5319273343650244

Epoch: 5| Step: 7
Training loss: 0.195237398147583
Validation loss: 1.5234201159528507

Epoch: 5| Step: 8
Training loss: 0.15546968579292297
Validation loss: 1.5404270015737063

Epoch: 5| Step: 9
Training loss: 0.2804902195930481
Validation loss: 1.5507442726883838

Epoch: 5| Step: 10
Training loss: 0.14597319066524506
Validation loss: 1.5525741692512267

Epoch: 371| Step: 0
Training loss: 0.18690483272075653
Validation loss: 1.5384883444796327

Epoch: 5| Step: 1
Training loss: 0.18080434203147888
Validation loss: 1.5385666803647113

Epoch: 5| Step: 2
Training loss: 0.16955943405628204
Validation loss: 1.5769948241531209

Epoch: 5| Step: 3
Training loss: 0.12062746286392212
Validation loss: 1.5458751955339987

Epoch: 5| Step: 4
Training loss: 0.13834720849990845
Validation loss: 1.6031952904116722

Epoch: 5| Step: 5
Training loss: 0.4053977429866791
Validation loss: 1.620448330397247

Epoch: 5| Step: 6
Training loss: 0.22472529113292694
Validation loss: 1.605076628346597

Epoch: 5| Step: 7
Training loss: 0.19244512915611267
Validation loss: 1.6137965904769076

Epoch: 5| Step: 8
Training loss: 0.1686285436153412
Validation loss: 1.610244583058101

Epoch: 5| Step: 9
Training loss: 0.11879195272922516
Validation loss: 1.5836151774211595

Epoch: 5| Step: 10
Training loss: 0.22810518741607666
Validation loss: 1.611245289925606

Epoch: 372| Step: 0
Training loss: 0.09573664516210556
Validation loss: 1.5851804229520983

Epoch: 5| Step: 1
Training loss: 0.11387423425912857
Validation loss: 1.5806041186855686

Epoch: 5| Step: 2
Training loss: 0.22483757138252258
Validation loss: 1.5588908400586856

Epoch: 5| Step: 3
Training loss: 0.22365093231201172
Validation loss: 1.5468268676470684

Epoch: 5| Step: 4
Training loss: 0.2572922110557556
Validation loss: 1.5242941738456808

Epoch: 5| Step: 5
Training loss: 0.17926986515522003
Validation loss: 1.560131698526362

Epoch: 5| Step: 6
Training loss: 0.1917133629322052
Validation loss: 1.5466391719797605

Epoch: 5| Step: 7
Training loss: 0.2545850872993469
Validation loss: 1.5772861934477282

Epoch: 5| Step: 8
Training loss: 0.24099735915660858
Validation loss: 1.6020368414540445

Epoch: 5| Step: 9
Training loss: 0.1453399807214737
Validation loss: 1.5819320653074531

Epoch: 5| Step: 10
Training loss: 0.13752956688404083
Validation loss: 1.614132858091785

Epoch: 373| Step: 0
Training loss: 0.16303779184818268
Validation loss: 1.5904106824628768

Epoch: 5| Step: 1
Training loss: 0.10934116691350937
Validation loss: 1.5871082916054675

Epoch: 5| Step: 2
Training loss: 0.16660729050636292
Validation loss: 1.605064974036268

Epoch: 5| Step: 3
Training loss: 0.13619491457939148
Validation loss: 1.593839773567774

Epoch: 5| Step: 4
Training loss: 0.11546885967254639
Validation loss: 1.6306246583179762

Epoch: 5| Step: 5
Training loss: 0.3081953227519989
Validation loss: 1.6324266977207635

Epoch: 5| Step: 6
Training loss: 0.22718434035778046
Validation loss: 1.6273581238203152

Epoch: 5| Step: 7
Training loss: 0.13598546385765076
Validation loss: 1.6090754706372496

Epoch: 5| Step: 8
Training loss: 0.12279708683490753
Validation loss: 1.5775093327286422

Epoch: 5| Step: 9
Training loss: 0.09299175441265106
Validation loss: 1.575609553244806

Epoch: 5| Step: 10
Training loss: 0.26706138253211975
Validation loss: 1.5391127345382527

Epoch: 374| Step: 0
Training loss: 0.31408190727233887
Validation loss: 1.528490463892619

Epoch: 5| Step: 1
Training loss: 0.24321675300598145
Validation loss: 1.5194045702616374

Epoch: 5| Step: 2
Training loss: 0.2159782201051712
Validation loss: 1.5197817048718851

Epoch: 5| Step: 3
Training loss: 0.23759238421916962
Validation loss: 1.4945036890686199

Epoch: 5| Step: 4
Training loss: 0.18594709038734436
Validation loss: 1.528714814493733

Epoch: 5| Step: 5
Training loss: 0.18076461553573608
Validation loss: 1.530643383661906

Epoch: 5| Step: 6
Training loss: 0.20050878822803497
Validation loss: 1.5503756282150105

Epoch: 5| Step: 7
Training loss: 0.20181012153625488
Validation loss: 1.5937930537808327

Epoch: 5| Step: 8
Training loss: 0.1156425029039383
Validation loss: 1.6399900785056494

Epoch: 5| Step: 9
Training loss: 0.1246500238776207
Validation loss: 1.6350622702670354

Epoch: 5| Step: 10
Training loss: 0.14615803956985474
Validation loss: 1.6219880119446786

Epoch: 375| Step: 0
Training loss: 0.17952798306941986
Validation loss: 1.5923408974883377

Epoch: 5| Step: 1
Training loss: 0.3878048062324524
Validation loss: 1.5737184645027242

Epoch: 5| Step: 2
Training loss: 0.21360249817371368
Validation loss: 1.5548683469013502

Epoch: 5| Step: 3
Training loss: 0.2269398421049118
Validation loss: 1.529507266577854

Epoch: 5| Step: 4
Training loss: 0.2349996566772461
Validation loss: 1.509968755065754

Epoch: 5| Step: 5
Training loss: 0.14175698161125183
Validation loss: 1.5179563568484398

Epoch: 5| Step: 6
Training loss: 0.1965625286102295
Validation loss: 1.4913620660381932

Epoch: 5| Step: 7
Training loss: 0.14650174975395203
Validation loss: 1.510250238962071

Epoch: 5| Step: 8
Training loss: 0.18170233070850372
Validation loss: 1.535341767854588

Epoch: 5| Step: 9
Training loss: 0.11964006721973419
Validation loss: 1.5801724515935427

Epoch: 5| Step: 10
Training loss: 0.22119690477848053
Validation loss: 1.5951543738765102

Epoch: 376| Step: 0
Training loss: 0.13761742413043976
Validation loss: 1.6197963119834982

Epoch: 5| Step: 1
Training loss: 0.1905021369457245
Validation loss: 1.6137902685391006

Epoch: 5| Step: 2
Training loss: 0.16806170344352722
Validation loss: 1.6139722485696115

Epoch: 5| Step: 3
Training loss: 0.18299880623817444
Validation loss: 1.6400860201927923

Epoch: 5| Step: 4
Training loss: 0.2706231474876404
Validation loss: 1.6066509126335062

Epoch: 5| Step: 5
Training loss: 0.08414910733699799
Validation loss: 1.6116097409238097

Epoch: 5| Step: 6
Training loss: 0.1464831829071045
Validation loss: 1.5811939918866722

Epoch: 5| Step: 7
Training loss: 0.19727034866809845
Validation loss: 1.5883565929628187

Epoch: 5| Step: 8
Training loss: 0.21802811324596405
Validation loss: 1.5769796422732774

Epoch: 5| Step: 9
Training loss: 0.2766854166984558
Validation loss: 1.5396930030597153

Epoch: 5| Step: 10
Training loss: 0.17320561408996582
Validation loss: 1.5311918463758243

Epoch: 377| Step: 0
Training loss: 0.12705084681510925
Validation loss: 1.5372358778471589

Epoch: 5| Step: 1
Training loss: 0.17559507489204407
Validation loss: 1.5514922052301385

Epoch: 5| Step: 2
Training loss: 0.16022947430610657
Validation loss: 1.5535852998815558

Epoch: 5| Step: 3
Training loss: 0.14570152759552002
Validation loss: 1.5367781744208386

Epoch: 5| Step: 4
Training loss: 0.15182426571846008
Validation loss: 1.5390861444575812

Epoch: 5| Step: 5
Training loss: 0.16997526586055756
Validation loss: 1.5447467257899623

Epoch: 5| Step: 6
Training loss: 0.2500258684158325
Validation loss: 1.5637778915384764

Epoch: 5| Step: 7
Training loss: 0.11076221615076065
Validation loss: 1.5992363716966362

Epoch: 5| Step: 8
Training loss: 0.12190184742212296
Validation loss: 1.583429407047969

Epoch: 5| Step: 9
Training loss: 0.2005610167980194
Validation loss: 1.6002555149857716

Epoch: 5| Step: 10
Training loss: 0.22346197068691254
Validation loss: 1.5553529518906788

Epoch: 378| Step: 0
Training loss: 0.3035457730293274
Validation loss: 1.6132310859618648

Epoch: 5| Step: 1
Training loss: 0.1466210037469864
Validation loss: 1.585996821362485

Epoch: 5| Step: 2
Training loss: 0.10966978967189789
Validation loss: 1.5615655504247195

Epoch: 5| Step: 3
Training loss: 0.18843840062618256
Validation loss: 1.5534813827083958

Epoch: 5| Step: 4
Training loss: 0.1592516154050827
Validation loss: 1.594284825427558

Epoch: 5| Step: 5
Training loss: 0.22921474277973175
Validation loss: 1.5742136355369323

Epoch: 5| Step: 6
Training loss: 0.17828187346458435
Validation loss: 1.567600486099079

Epoch: 5| Step: 7
Training loss: 0.16784445941448212
Validation loss: 1.5824061427065121

Epoch: 5| Step: 8
Training loss: 0.18031525611877441
Validation loss: 1.5667838390155504

Epoch: 5| Step: 9
Training loss: 0.1337517648935318
Validation loss: 1.5729629455074188

Epoch: 5| Step: 10
Training loss: 0.2083965390920639
Validation loss: 1.556325763784429

Epoch: 379| Step: 0
Training loss: 0.10948606580495834
Validation loss: 1.548992267218969

Epoch: 5| Step: 1
Training loss: 0.18531310558319092
Validation loss: 1.5706608346713486

Epoch: 5| Step: 2
Training loss: 0.16945138573646545
Validation loss: 1.537970467280316

Epoch: 5| Step: 3
Training loss: 0.17095895111560822
Validation loss: 1.5805363988363614

Epoch: 5| Step: 4
Training loss: 0.1488063633441925
Validation loss: 1.5463043470536508

Epoch: 5| Step: 5
Training loss: 0.17550323903560638
Validation loss: 1.5626039722914338

Epoch: 5| Step: 6
Training loss: 0.170172318816185
Validation loss: 1.5588985053441857

Epoch: 5| Step: 7
Training loss: 0.18343761563301086
Validation loss: 1.5917458918786818

Epoch: 5| Step: 8
Training loss: 0.17793890833854675
Validation loss: 1.5991689338478992

Epoch: 5| Step: 9
Training loss: 0.13556614518165588
Validation loss: 1.57913839304319

Epoch: 5| Step: 10
Training loss: 0.3422999083995819
Validation loss: 1.5927647506037066

Epoch: 380| Step: 0
Training loss: 0.20854201912879944
Validation loss: 1.5627031364748556

Epoch: 5| Step: 1
Training loss: 0.22036579251289368
Validation loss: 1.592972295258635

Epoch: 5| Step: 2
Training loss: 0.15698440372943878
Validation loss: 1.5737224458366312

Epoch: 5| Step: 3
Training loss: 0.14533475041389465
Validation loss: 1.564012905602814

Epoch: 5| Step: 4
Training loss: 0.36162373423576355
Validation loss: 1.5526478675103956

Epoch: 5| Step: 5
Training loss: 0.09738542884588242
Validation loss: 1.5493812766126407

Epoch: 5| Step: 6
Training loss: 0.11250783503055573
Validation loss: 1.5327630094302598

Epoch: 5| Step: 7
Training loss: 0.12284723669290543
Validation loss: 1.51329118205655

Epoch: 5| Step: 8
Training loss: 0.15429671108722687
Validation loss: 1.5523230080963464

Epoch: 5| Step: 9
Training loss: 0.14120149612426758
Validation loss: 1.5250045612294187

Epoch: 5| Step: 10
Training loss: 0.17081785202026367
Validation loss: 1.572087130238933

Epoch: 381| Step: 0
Training loss: 0.11818893998861313
Validation loss: 1.5571656175839004

Epoch: 5| Step: 1
Training loss: 0.12268905341625214
Validation loss: 1.5515752210411975

Epoch: 5| Step: 2
Training loss: 0.10730979591608047
Validation loss: 1.6027283976154942

Epoch: 5| Step: 3
Training loss: 0.347283273935318
Validation loss: 1.5849988921996085

Epoch: 5| Step: 4
Training loss: 0.14268562197685242
Validation loss: 1.5809791511104954

Epoch: 5| Step: 5
Training loss: 0.10969855636358261
Validation loss: 1.5807539762989167

Epoch: 5| Step: 6
Training loss: 0.21786901354789734
Validation loss: 1.5769290872799453

Epoch: 5| Step: 7
Training loss: 0.21354837715625763
Validation loss: 1.5571344514046945

Epoch: 5| Step: 8
Training loss: 0.1747984141111374
Validation loss: 1.5491345685015443

Epoch: 5| Step: 9
Training loss: 0.12405622005462646
Validation loss: 1.5621783823095343

Epoch: 5| Step: 10
Training loss: 0.17428910732269287
Validation loss: 1.5865784601498676

Epoch: 382| Step: 0
Training loss: 0.2543107867240906
Validation loss: 1.5686685026332896

Epoch: 5| Step: 1
Training loss: 0.18012090027332306
Validation loss: 1.5414893665621359

Epoch: 5| Step: 2
Training loss: 0.11743001639842987
Validation loss: 1.5438569463709348

Epoch: 5| Step: 3
Training loss: 0.15339617431163788
Validation loss: 1.5365274683121712

Epoch: 5| Step: 4
Training loss: 0.1871650665998459
Validation loss: 1.5031576784708167

Epoch: 5| Step: 5
Training loss: 0.2917299270629883
Validation loss: 1.5236501206633866

Epoch: 5| Step: 6
Training loss: 0.14947167038917542
Validation loss: 1.5424561103185017

Epoch: 5| Step: 7
Training loss: 0.16380465030670166
Validation loss: 1.5455682841680383

Epoch: 5| Step: 8
Training loss: 0.1793743222951889
Validation loss: 1.5041774729246735

Epoch: 5| Step: 9
Training loss: 0.1967851221561432
Validation loss: 1.524718133352136

Epoch: 5| Step: 10
Training loss: 0.17481902241706848
Validation loss: 1.5254559504088534

Epoch: 383| Step: 0
Training loss: 0.35320258140563965
Validation loss: 1.577371383226046

Epoch: 5| Step: 1
Training loss: 0.10808897018432617
Validation loss: 1.6061065145718154

Epoch: 5| Step: 2
Training loss: 0.08203668147325516
Validation loss: 1.5870463745568388

Epoch: 5| Step: 3
Training loss: 0.113883376121521
Validation loss: 1.5987344762330413

Epoch: 5| Step: 4
Training loss: 0.1190471425652504
Validation loss: 1.6003997992443781

Epoch: 5| Step: 5
Training loss: 0.19125895202159882
Validation loss: 1.5512145911493609

Epoch: 5| Step: 6
Training loss: 0.23041746020317078
Validation loss: 1.5783702122267855

Epoch: 5| Step: 7
Training loss: 0.28181880712509155
Validation loss: 1.5496962474238487

Epoch: 5| Step: 8
Training loss: 0.10818664729595184
Validation loss: 1.5508532037017166

Epoch: 5| Step: 9
Training loss: 0.14711631834506989
Validation loss: 1.5421581345219766

Epoch: 5| Step: 10
Training loss: 0.17614763975143433
Validation loss: 1.5486331524387482

Epoch: 384| Step: 0
Training loss: 0.1781608760356903
Validation loss: 1.4667795806802728

Epoch: 5| Step: 1
Training loss: 0.1820223182439804
Validation loss: 1.5256673469338367

Epoch: 5| Step: 2
Training loss: 0.13920339941978455
Validation loss: 1.5217232409343924

Epoch: 5| Step: 3
Training loss: 0.18441568315029144
Validation loss: 1.5372512058545185

Epoch: 5| Step: 4
Training loss: 0.16620710492134094
Validation loss: 1.549695207226661

Epoch: 5| Step: 5
Training loss: 0.15153363347053528
Validation loss: 1.5618830137355353

Epoch: 5| Step: 6
Training loss: 0.27024340629577637
Validation loss: 1.6032375815094158

Epoch: 5| Step: 7
Training loss: 0.142952099442482
Validation loss: 1.6000798633021693

Epoch: 5| Step: 8
Training loss: 0.1564185619354248
Validation loss: 1.6037857340228172

Epoch: 5| Step: 9
Training loss: 0.1769700050354004
Validation loss: 1.6143168095619447

Epoch: 5| Step: 10
Training loss: 0.21433435380458832
Validation loss: 1.5891001544972903

Epoch: 385| Step: 0
Training loss: 0.17514893412590027
Validation loss: 1.5795520274869856

Epoch: 5| Step: 1
Training loss: 0.23676621913909912
Validation loss: 1.5227619037833264

Epoch: 5| Step: 2
Training loss: 0.1818922460079193
Validation loss: 1.529663824266003

Epoch: 5| Step: 3
Training loss: 0.12797820568084717
Validation loss: 1.53446146621499

Epoch: 5| Step: 4
Training loss: 0.19231602549552917
Validation loss: 1.5116752463002359

Epoch: 5| Step: 5
Training loss: 0.1402965486049652
Validation loss: 1.5376952937854234

Epoch: 5| Step: 6
Training loss: 0.20405730605125427
Validation loss: 1.493908638595253

Epoch: 5| Step: 7
Training loss: 0.2412707805633545
Validation loss: 1.518233564592177

Epoch: 5| Step: 8
Training loss: 0.12073899805545807
Validation loss: 1.5460461621643395

Epoch: 5| Step: 9
Training loss: 0.159628227353096
Validation loss: 1.5798396064389137

Epoch: 5| Step: 10
Training loss: 0.17040449380874634
Validation loss: 1.561834385318141

Epoch: 386| Step: 0
Training loss: 0.13124068081378937
Validation loss: 1.5638189905433244

Epoch: 5| Step: 1
Training loss: 0.13000771403312683
Validation loss: 1.5683843192233835

Epoch: 5| Step: 2
Training loss: 0.17898742854595184
Validation loss: 1.5752069796285322

Epoch: 5| Step: 3
Training loss: 0.15211975574493408
Validation loss: 1.5865870111732072

Epoch: 5| Step: 4
Training loss: 0.22275233268737793
Validation loss: 1.613284400714341

Epoch: 5| Step: 5
Training loss: 0.1074807196855545
Validation loss: 1.5247495148771553

Epoch: 5| Step: 6
Training loss: 0.18659411370754242
Validation loss: 1.5545914480763097

Epoch: 5| Step: 7
Training loss: 0.23009303212165833
Validation loss: 1.5667537258517357

Epoch: 5| Step: 8
Training loss: 0.13441292941570282
Validation loss: 1.5696928488310946

Epoch: 5| Step: 9
Training loss: 0.2800396978855133
Validation loss: 1.556536106653111

Epoch: 5| Step: 10
Training loss: 0.10656863451004028
Validation loss: 1.5410175067122265

Epoch: 387| Step: 0
Training loss: 0.22733235359191895
Validation loss: 1.5558651467805267

Epoch: 5| Step: 1
Training loss: 0.26418620347976685
Validation loss: 1.5766243357812204

Epoch: 5| Step: 2
Training loss: 0.10927212238311768
Validation loss: 1.5771334248204385

Epoch: 5| Step: 3
Training loss: 0.15640641748905182
Validation loss: 1.5728516014673377

Epoch: 5| Step: 4
Training loss: 0.13642989099025726
Validation loss: 1.6090183693875548

Epoch: 5| Step: 5
Training loss: 0.10823722928762436
Validation loss: 1.6204659169720066

Epoch: 5| Step: 6
Training loss: 0.2577705979347229
Validation loss: 1.6427188957891157

Epoch: 5| Step: 7
Training loss: 0.12524929642677307
Validation loss: 1.6097368489029587

Epoch: 5| Step: 8
Training loss: 0.13503733277320862
Validation loss: 1.6127087852006317

Epoch: 5| Step: 9
Training loss: 0.13620655238628387
Validation loss: 1.5940962042859805

Epoch: 5| Step: 10
Training loss: 0.1293521523475647
Validation loss: 1.5532354731713571

Epoch: 388| Step: 0
Training loss: 0.19582998752593994
Validation loss: 1.5776952697384743

Epoch: 5| Step: 1
Training loss: 0.2655408978462219
Validation loss: 1.582156362072114

Epoch: 5| Step: 2
Training loss: 0.16680112481117249
Validation loss: 1.6235496972196846

Epoch: 5| Step: 3
Training loss: 0.1569490134716034
Validation loss: 1.5920379930926907

Epoch: 5| Step: 4
Training loss: 0.200653076171875
Validation loss: 1.6039639134560861

Epoch: 5| Step: 5
Training loss: 0.11987797915935516
Validation loss: 1.5893553790225778

Epoch: 5| Step: 6
Training loss: 0.13915066421031952
Validation loss: 1.5861493182438675

Epoch: 5| Step: 7
Training loss: 0.13959211111068726
Validation loss: 1.5710634608422556

Epoch: 5| Step: 8
Training loss: 0.09567193686962128
Validation loss: 1.5808900325529036

Epoch: 5| Step: 9
Training loss: 0.17394192516803741
Validation loss: 1.5761239631201631

Epoch: 5| Step: 10
Training loss: 0.10454853624105453
Validation loss: 1.5838779121316888

Epoch: 389| Step: 0
Training loss: 0.10641465336084366
Validation loss: 1.5520417075003348

Epoch: 5| Step: 1
Training loss: 0.1106889471411705
Validation loss: 1.584915545678908

Epoch: 5| Step: 2
Training loss: 0.32713577151298523
Validation loss: 1.622480192492085

Epoch: 5| Step: 3
Training loss: 0.10989222675561905
Validation loss: 1.5821604062152166

Epoch: 5| Step: 4
Training loss: 0.11954975128173828
Validation loss: 1.6106037555202362

Epoch: 5| Step: 5
Training loss: 0.16795478761196136
Validation loss: 1.6538887562290314

Epoch: 5| Step: 6
Training loss: 0.2243552953004837
Validation loss: 1.631838951059567

Epoch: 5| Step: 7
Training loss: 0.14233538508415222
Validation loss: 1.6397598315310735

Epoch: 5| Step: 8
Training loss: 0.13874007761478424
Validation loss: 1.6780768684161607

Epoch: 5| Step: 9
Training loss: 0.15746799111366272
Validation loss: 1.6214630706335909

Epoch: 5| Step: 10
Training loss: 0.18616339564323425
Validation loss: 1.6094560507805116

Epoch: 390| Step: 0
Training loss: 0.13247103989124298
Validation loss: 1.6073525105753252

Epoch: 5| Step: 1
Training loss: 0.07935337722301483
Validation loss: 1.5811818863755913

Epoch: 5| Step: 2
Training loss: 0.13927260041236877
Validation loss: 1.5811614836415937

Epoch: 5| Step: 3
Training loss: 0.18769145011901855
Validation loss: 1.5426887235333842

Epoch: 5| Step: 4
Training loss: 0.15108728408813477
Validation loss: 1.5592330514743764

Epoch: 5| Step: 5
Training loss: 0.14893625676631927
Validation loss: 1.5242666249634118

Epoch: 5| Step: 6
Training loss: 0.18143436312675476
Validation loss: 1.5594285572728803

Epoch: 5| Step: 7
Training loss: 0.18629395961761475
Validation loss: 1.5063201868405907

Epoch: 5| Step: 8
Training loss: 0.2734913229942322
Validation loss: 1.5841912954084334

Epoch: 5| Step: 9
Training loss: 0.14573624730110168
Validation loss: 1.5419306293610604

Epoch: 5| Step: 10
Training loss: 0.1546388864517212
Validation loss: 1.5819428582345285

Epoch: 391| Step: 0
Training loss: 0.13142737746238708
Validation loss: 1.5652421187329035

Epoch: 5| Step: 1
Training loss: 0.10680171102285385
Validation loss: 1.627494668447843

Epoch: 5| Step: 2
Training loss: 0.14494559168815613
Validation loss: 1.5976025660832722

Epoch: 5| Step: 3
Training loss: 0.20119519531726837
Validation loss: 1.5895368809341102

Epoch: 5| Step: 4
Training loss: 0.1838449090719223
Validation loss: 1.5656938270855976

Epoch: 5| Step: 5
Training loss: 0.13839837908744812
Validation loss: 1.5867988601807625

Epoch: 5| Step: 6
Training loss: 0.20586416125297546
Validation loss: 1.5580329843746719

Epoch: 5| Step: 7
Training loss: 0.14732682704925537
Validation loss: 1.5710826343105686

Epoch: 5| Step: 8
Training loss: 0.31677496433258057
Validation loss: 1.549497721015766

Epoch: 5| Step: 9
Training loss: 0.10471775382757187
Validation loss: 1.5446378466903523

Epoch: 5| Step: 10
Training loss: 0.12280206382274628
Validation loss: 1.5320650858263816

Epoch: 392| Step: 0
Training loss: 0.15746064484119415
Validation loss: 1.5542265445955339

Epoch: 5| Step: 1
Training loss: 0.20811843872070312
Validation loss: 1.5803564210091867

Epoch: 5| Step: 2
Training loss: 0.21331992745399475
Validation loss: 1.622116296522079

Epoch: 5| Step: 3
Training loss: 0.2332375943660736
Validation loss: 1.5765655233014015

Epoch: 5| Step: 4
Training loss: 0.16072364151477814
Validation loss: 1.6111778366950251

Epoch: 5| Step: 5
Training loss: 0.14722025394439697
Validation loss: 1.617278193914762

Epoch: 5| Step: 6
Training loss: 0.1974402815103531
Validation loss: 1.6226261456807454

Epoch: 5| Step: 7
Training loss: 0.1313564032316208
Validation loss: 1.6058805655407649

Epoch: 5| Step: 8
Training loss: 0.12075354903936386
Validation loss: 1.6072607117314492

Epoch: 5| Step: 9
Training loss: 0.192155659198761
Validation loss: 1.5831438956722137

Epoch: 5| Step: 10
Training loss: 0.30101579427719116
Validation loss: 1.5939737699365104

Epoch: 393| Step: 0
Training loss: 0.14924830198287964
Validation loss: 1.5522248078418035

Epoch: 5| Step: 1
Training loss: 0.18671166896820068
Validation loss: 1.528795639673869

Epoch: 5| Step: 2
Training loss: 0.12938004732131958
Validation loss: 1.5539399680270944

Epoch: 5| Step: 3
Training loss: 0.24471943080425262
Validation loss: 1.5710759534630725

Epoch: 5| Step: 4
Training loss: 0.15048669278621674
Validation loss: 1.6000455822995914

Epoch: 5| Step: 5
Training loss: 0.11289771646261215
Validation loss: 1.5657826495426956

Epoch: 5| Step: 6
Training loss: 0.14445622265338898
Validation loss: 1.608549125732914

Epoch: 5| Step: 7
Training loss: 0.15447251498699188
Validation loss: 1.5906727826723488

Epoch: 5| Step: 8
Training loss: 0.21924209594726562
Validation loss: 1.6406661105412308

Epoch: 5| Step: 9
Training loss: 0.24606242775917053
Validation loss: 1.657254272891629

Epoch: 5| Step: 10
Training loss: 0.22584883868694305
Validation loss: 1.5821180369264336

Epoch: 394| Step: 0
Training loss: 0.18061630427837372
Validation loss: 1.567755409466323

Epoch: 5| Step: 1
Training loss: 0.17586317658424377
Validation loss: 1.5607955327597998

Epoch: 5| Step: 2
Training loss: 0.1018139123916626
Validation loss: 1.5081170822984429

Epoch: 5| Step: 3
Training loss: 0.10404741764068604
Validation loss: 1.527477857887104

Epoch: 5| Step: 4
Training loss: 0.15819229185581207
Validation loss: 1.5253974814568796

Epoch: 5| Step: 5
Training loss: 0.14476701617240906
Validation loss: 1.4968998444977628

Epoch: 5| Step: 6
Training loss: 0.16147898137569427
Validation loss: 1.5105978494049401

Epoch: 5| Step: 7
Training loss: 0.18410232663154602
Validation loss: 1.5304691035260436

Epoch: 5| Step: 8
Training loss: 0.24147728085517883
Validation loss: 1.5617487174208446

Epoch: 5| Step: 9
Training loss: 0.16348405182361603
Validation loss: 1.590814510981242

Epoch: 5| Step: 10
Training loss: 0.13322250545024872
Validation loss: 1.632008647405973

Epoch: 395| Step: 0
Training loss: 0.17261716723442078
Validation loss: 1.667150302599835

Epoch: 5| Step: 1
Training loss: 0.19819703698158264
Validation loss: 1.6798854579207718

Epoch: 5| Step: 2
Training loss: 0.2943461537361145
Validation loss: 1.6805824002911967

Epoch: 5| Step: 3
Training loss: 0.27797654271125793
Validation loss: 1.6240151197679582

Epoch: 5| Step: 4
Training loss: 0.09482933580875397
Validation loss: 1.5896123622053413

Epoch: 5| Step: 5
Training loss: 0.11162164062261581
Validation loss: 1.561159037774609

Epoch: 5| Step: 6
Training loss: 0.08831256628036499
Validation loss: 1.5532070090693813

Epoch: 5| Step: 7
Training loss: 0.1738874316215515
Validation loss: 1.543624831784156

Epoch: 5| Step: 8
Training loss: 0.13506349921226501
Validation loss: 1.5740197127865208

Epoch: 5| Step: 9
Training loss: 0.1917162388563156
Validation loss: 1.5681971042386946

Epoch: 5| Step: 10
Training loss: 0.1565362811088562
Validation loss: 1.5968984711554743

Epoch: 396| Step: 0
Training loss: 0.1970415860414505
Validation loss: 1.5988103984504618

Epoch: 5| Step: 1
Training loss: 0.20571443438529968
Validation loss: 1.6364160891502135

Epoch: 5| Step: 2
Training loss: 0.1780948042869568
Validation loss: 1.655674075567594

Epoch: 5| Step: 3
Training loss: 0.3378809094429016
Validation loss: 1.6275138137161091

Epoch: 5| Step: 4
Training loss: 0.17579218745231628
Validation loss: 1.5968509335671701

Epoch: 5| Step: 5
Training loss: 0.1252526342868805
Validation loss: 1.607730911624047

Epoch: 5| Step: 6
Training loss: 0.12594689428806305
Validation loss: 1.5937385020717498

Epoch: 5| Step: 7
Training loss: 0.13924963772296906
Validation loss: 1.5767456434106315

Epoch: 5| Step: 8
Training loss: 0.11635122448205948
Validation loss: 1.5931969150420158

Epoch: 5| Step: 9
Training loss: 0.18041959404945374
Validation loss: 1.5849318735061153

Epoch: 5| Step: 10
Training loss: 0.127914696931839
Validation loss: 1.5553349871789255

Epoch: 397| Step: 0
Training loss: 0.11074856668710709
Validation loss: 1.5620539008930165

Epoch: 5| Step: 1
Training loss: 0.16253340244293213
Validation loss: 1.563395707837997

Epoch: 5| Step: 2
Training loss: 0.0749596357345581
Validation loss: 1.5622103701355636

Epoch: 5| Step: 3
Training loss: 0.24596218764781952
Validation loss: 1.5614407370167394

Epoch: 5| Step: 4
Training loss: 0.08785530924797058
Validation loss: 1.5568851476074548

Epoch: 5| Step: 5
Training loss: 0.13201987743377686
Validation loss: 1.576870579873362

Epoch: 5| Step: 6
Training loss: 0.10410650074481964
Validation loss: 1.613487740998627

Epoch: 5| Step: 7
Training loss: 0.22854885458946228
Validation loss: 1.5765091155164985

Epoch: 5| Step: 8
Training loss: 0.227460578083992
Validation loss: 1.5788167727890836

Epoch: 5| Step: 9
Training loss: 0.14526806771755219
Validation loss: 1.6056598251865757

Epoch: 5| Step: 10
Training loss: 0.15157397091388702
Validation loss: 1.589094247869266

Epoch: 398| Step: 0
Training loss: 0.1540623903274536
Validation loss: 1.5493868256127963

Epoch: 5| Step: 1
Training loss: 0.23989315330982208
Validation loss: 1.5745483252309984

Epoch: 5| Step: 2
Training loss: 0.15034165978431702
Validation loss: 1.5747284222674627

Epoch: 5| Step: 3
Training loss: 0.17829529941082
Validation loss: 1.5397153515969553

Epoch: 5| Step: 4
Training loss: 0.14358505606651306
Validation loss: 1.4972900049660796

Epoch: 5| Step: 5
Training loss: 0.1509322226047516
Validation loss: 1.4844301259645851

Epoch: 5| Step: 6
Training loss: 0.13379505276679993
Validation loss: 1.535087175266717

Epoch: 5| Step: 7
Training loss: 0.221536323428154
Validation loss: 1.5000413079415598

Epoch: 5| Step: 8
Training loss: 0.13641750812530518
Validation loss: 1.4806627970869823

Epoch: 5| Step: 9
Training loss: 0.13948890566825867
Validation loss: 1.4486202398935955

Epoch: 5| Step: 10
Training loss: 0.2521305978298187
Validation loss: 1.452200852414613

Epoch: 399| Step: 0
Training loss: 0.15506894886493683
Validation loss: 1.4908419398851291

Epoch: 5| Step: 1
Training loss: 0.221602201461792
Validation loss: 1.4948733147754465

Epoch: 5| Step: 2
Training loss: 0.1699424684047699
Validation loss: 1.4923242343369352

Epoch: 5| Step: 3
Training loss: 0.14126047492027283
Validation loss: 1.5263822642705773

Epoch: 5| Step: 4
Training loss: 0.1684754192829132
Validation loss: 1.4962135207268499

Epoch: 5| Step: 5
Training loss: 0.17623372375965118
Validation loss: 1.5293637962751492

Epoch: 5| Step: 6
Training loss: 0.10594866424798965
Validation loss: 1.513220614002597

Epoch: 5| Step: 7
Training loss: 0.13565337657928467
Validation loss: 1.5017366332392539

Epoch: 5| Step: 8
Training loss: 0.11529576778411865
Validation loss: 1.5334836052310081

Epoch: 5| Step: 9
Training loss: 0.23633241653442383
Validation loss: 1.5314486231855167

Epoch: 5| Step: 10
Training loss: 0.1936105191707611
Validation loss: 1.481788130216701

Epoch: 400| Step: 0
Training loss: 0.2122783660888672
Validation loss: 1.4626694892042427

Epoch: 5| Step: 1
Training loss: 0.24526090919971466
Validation loss: 1.4478870034217834

Epoch: 5| Step: 2
Training loss: 0.12669682502746582
Validation loss: 1.4844818653598908

Epoch: 5| Step: 3
Training loss: 0.18024799227714539
Validation loss: 1.4821364533516668

Epoch: 5| Step: 4
Training loss: 0.2246168553829193
Validation loss: 1.453128175068927

Epoch: 5| Step: 5
Training loss: 0.13769152760505676
Validation loss: 1.5013321740652925

Epoch: 5| Step: 6
Training loss: 0.15205544233322144
Validation loss: 1.4899693227583362

Epoch: 5| Step: 7
Training loss: 0.1563383787870407
Validation loss: 1.5274602443941179

Epoch: 5| Step: 8
Training loss: 0.10896116495132446
Validation loss: 1.5653643774729904

Epoch: 5| Step: 9
Training loss: 0.17782941460609436
Validation loss: 1.5957614785881453

Epoch: 5| Step: 10
Training loss: 0.19239594042301178
Validation loss: 1.6219268588609592

Epoch: 401| Step: 0
Training loss: 0.19425727427005768
Validation loss: 1.5710126187211724

Epoch: 5| Step: 1
Training loss: 0.08289475739002228
Validation loss: 1.5783879295472176

Epoch: 5| Step: 2
Training loss: 0.13018114864826202
Validation loss: 1.5740153225519324

Epoch: 5| Step: 3
Training loss: 0.10441067069768906
Validation loss: 1.5556988741761895

Epoch: 5| Step: 4
Training loss: 0.14289389550685883
Validation loss: 1.545067871770551

Epoch: 5| Step: 5
Training loss: 0.16061006486415863
Validation loss: 1.516779722705964

Epoch: 5| Step: 6
Training loss: 0.17679060995578766
Validation loss: 1.5381764391417145

Epoch: 5| Step: 7
Training loss: 0.18180492520332336
Validation loss: 1.4978109021340646

Epoch: 5| Step: 8
Training loss: 0.2825683653354645
Validation loss: 1.5073831773573352

Epoch: 5| Step: 9
Training loss: 0.14382275938987732
Validation loss: 1.518715085521821

Epoch: 5| Step: 10
Training loss: 0.23443076014518738
Validation loss: 1.5240366394801805

Epoch: 402| Step: 0
Training loss: 0.16079704463481903
Validation loss: 1.5195578913534842

Epoch: 5| Step: 1
Training loss: 0.1862347573041916
Validation loss: 1.5343437630643126

Epoch: 5| Step: 2
Training loss: 0.12606430053710938
Validation loss: 1.5151253361855783

Epoch: 5| Step: 3
Training loss: 0.232737734913826
Validation loss: 1.565492949178142

Epoch: 5| Step: 4
Training loss: 0.18486414849758148
Validation loss: 1.5552518444676553

Epoch: 5| Step: 5
Training loss: 0.11265580356121063
Validation loss: 1.5772678711081063

Epoch: 5| Step: 6
Training loss: 0.1463233381509781
Validation loss: 1.5737158867620653

Epoch: 5| Step: 7
Training loss: 0.1103958860039711
Validation loss: 1.581243109959428

Epoch: 5| Step: 8
Training loss: 0.13281577825546265
Validation loss: 1.5935470942528016

Epoch: 5| Step: 9
Training loss: 0.13124284148216248
Validation loss: 1.5697479530047345

Epoch: 5| Step: 10
Training loss: 0.14641231298446655
Validation loss: 1.5460139436106528

Epoch: 403| Step: 0
Training loss: 0.18279704451560974
Validation loss: 1.514147900765942

Epoch: 5| Step: 1
Training loss: 0.2081209421157837
Validation loss: 1.483836636748365

Epoch: 5| Step: 2
Training loss: 0.16057661175727844
Validation loss: 1.49260365322072

Epoch: 5| Step: 3
Training loss: 0.21367022395133972
Validation loss: 1.5076398567486835

Epoch: 5| Step: 4
Training loss: 0.17281027138233185
Validation loss: 1.5500410538847729

Epoch: 5| Step: 5
Training loss: 0.12032146751880646
Validation loss: 1.524608298014569

Epoch: 5| Step: 6
Training loss: 0.1163436621427536
Validation loss: 1.592935137851264

Epoch: 5| Step: 7
Training loss: 0.16344021260738373
Validation loss: 1.6120161420555525

Epoch: 5| Step: 8
Training loss: 0.1826009452342987
Validation loss: 1.6436645369375906

Epoch: 5| Step: 9
Training loss: 0.24434277415275574
Validation loss: 1.6049229829542098

Epoch: 5| Step: 10
Training loss: 0.09850567579269409
Validation loss: 1.6145045975203156

Epoch: 404| Step: 0
Training loss: 0.1576758474111557
Validation loss: 1.6029028149061306

Epoch: 5| Step: 1
Training loss: 0.204813152551651
Validation loss: 1.5679909311315066

Epoch: 5| Step: 2
Training loss: 0.1518741101026535
Validation loss: 1.6047363088976951

Epoch: 5| Step: 3
Training loss: 0.17472270131111145
Validation loss: 1.556329083699052

Epoch: 5| Step: 4
Training loss: 0.200764462351799
Validation loss: 1.5586085293882637

Epoch: 5| Step: 5
Training loss: 0.20313136279582977
Validation loss: 1.557465676338442

Epoch: 5| Step: 6
Training loss: 0.20881855487823486
Validation loss: 1.536395401083013

Epoch: 5| Step: 7
Training loss: 0.1699335128068924
Validation loss: 1.5060803672318817

Epoch: 5| Step: 8
Training loss: 0.19083309173583984
Validation loss: 1.5144471737646288

Epoch: 5| Step: 9
Training loss: 0.22366483509540558
Validation loss: 1.5223028506002119

Epoch: 5| Step: 10
Training loss: 0.2706328332424164
Validation loss: 1.544495181370807

Epoch: 405| Step: 0
Training loss: 0.22456903755664825
Validation loss: 1.5058165955287155

Epoch: 5| Step: 1
Training loss: 0.14749078452587128
Validation loss: 1.5513114634380545

Epoch: 5| Step: 2
Training loss: 0.11400546878576279
Validation loss: 1.5640734100854525

Epoch: 5| Step: 3
Training loss: 0.193869948387146
Validation loss: 1.5590667250335857

Epoch: 5| Step: 4
Training loss: 0.2148309201002121
Validation loss: 1.5358710929911623

Epoch: 5| Step: 5
Training loss: 0.11878374963998795
Validation loss: 1.5335930316678938

Epoch: 5| Step: 6
Training loss: 0.25852954387664795
Validation loss: 1.5569597841590963

Epoch: 5| Step: 7
Training loss: 0.12834230065345764
Validation loss: 1.5464568932851155

Epoch: 5| Step: 8
Training loss: 0.2004958689212799
Validation loss: 1.5375088568656676

Epoch: 5| Step: 9
Training loss: 0.15061937272548676
Validation loss: 1.527910594017275

Epoch: 5| Step: 10
Training loss: 0.22532235085964203
Validation loss: 1.5132701153396277

Epoch: 406| Step: 0
Training loss: 0.15806499123573303
Validation loss: 1.5408175619699622

Epoch: 5| Step: 1
Training loss: 0.16480818390846252
Validation loss: 1.518768718165736

Epoch: 5| Step: 2
Training loss: 0.13312216103076935
Validation loss: 1.5721172773709862

Epoch: 5| Step: 3
Training loss: 0.20248791575431824
Validation loss: 1.5870904358484412

Epoch: 5| Step: 4
Training loss: 0.2126975804567337
Validation loss: 1.5998587980065295

Epoch: 5| Step: 5
Training loss: 0.1656298041343689
Validation loss: 1.6317207249262

Epoch: 5| Step: 6
Training loss: 0.16332221031188965
Validation loss: 1.649199817770271

Epoch: 5| Step: 7
Training loss: 0.24322982132434845
Validation loss: 1.6675743620882753

Epoch: 5| Step: 8
Training loss: 0.135577991604805
Validation loss: 1.6327001958765008

Epoch: 5| Step: 9
Training loss: 0.1331649124622345
Validation loss: 1.6373929233961209

Epoch: 5| Step: 10
Training loss: 0.3204861879348755
Validation loss: 1.5640377447169314

Epoch: 407| Step: 0
Training loss: 0.21755731105804443
Validation loss: 1.5741400846870996

Epoch: 5| Step: 1
Training loss: 0.2150927037000656
Validation loss: 1.5145813880428192

Epoch: 5| Step: 2
Training loss: 0.3318677246570587
Validation loss: 1.5143253495616298

Epoch: 5| Step: 3
Training loss: 0.207040935754776
Validation loss: 1.5026751705395278

Epoch: 5| Step: 4
Training loss: 0.08341825008392334
Validation loss: 1.4953136969638128

Epoch: 5| Step: 5
Training loss: 0.20706979930400848
Validation loss: 1.5017032366926952

Epoch: 5| Step: 6
Training loss: 0.16491977870464325
Validation loss: 1.5158278531925653

Epoch: 5| Step: 7
Training loss: 0.15209713578224182
Validation loss: 1.5481372597397014

Epoch: 5| Step: 8
Training loss: 0.22754673659801483
Validation loss: 1.5825530995604813

Epoch: 5| Step: 9
Training loss: 0.16629162430763245
Validation loss: 1.6337151271040722

Epoch: 5| Step: 10
Training loss: 0.13485445082187653
Validation loss: 1.6062055198095178

Epoch: 408| Step: 0
Training loss: 0.12671026587486267
Validation loss: 1.683232448434317

Epoch: 5| Step: 1
Training loss: 0.22948011755943298
Validation loss: 1.6742704606825305

Epoch: 5| Step: 2
Training loss: 0.27903515100479126
Validation loss: 1.6776973496201217

Epoch: 5| Step: 3
Training loss: 0.19819505512714386
Validation loss: 1.6299688162342194

Epoch: 5| Step: 4
Training loss: 0.15571275353431702
Validation loss: 1.5727522232199227

Epoch: 5| Step: 5
Training loss: 0.12546691298484802
Validation loss: 1.4961611801578152

Epoch: 5| Step: 6
Training loss: 0.1296357810497284
Validation loss: 1.4848190148671467

Epoch: 5| Step: 7
Training loss: 0.2488335818052292
Validation loss: 1.4234132926951173

Epoch: 5| Step: 8
Training loss: 0.32739630341529846
Validation loss: 1.4219457385360554

Epoch: 5| Step: 9
Training loss: 0.13166189193725586
Validation loss: 1.4073360107278312

Epoch: 5| Step: 10
Training loss: 0.1916971057653427
Validation loss: 1.4756285221345964

Epoch: 409| Step: 0
Training loss: 0.19583502411842346
Validation loss: 1.4724640295069704

Epoch: 5| Step: 1
Training loss: 0.21894288063049316
Validation loss: 1.5167737430141819

Epoch: 5| Step: 2
Training loss: 0.13965661823749542
Validation loss: 1.5459363114449285

Epoch: 5| Step: 3
Training loss: 0.15986593067646027
Validation loss: 1.5755656278261574

Epoch: 5| Step: 4
Training loss: 0.14572188258171082
Validation loss: 1.633559206480621

Epoch: 5| Step: 5
Training loss: 0.1499055176973343
Validation loss: 1.6378232253495084

Epoch: 5| Step: 6
Training loss: 0.21682365238666534
Validation loss: 1.6292037169138591

Epoch: 5| Step: 7
Training loss: 0.14660857617855072
Validation loss: 1.6088747875664824

Epoch: 5| Step: 8
Training loss: 0.14814481139183044
Validation loss: 1.5485335601273404

Epoch: 5| Step: 9
Training loss: 0.1478312611579895
Validation loss: 1.5736675364996797

Epoch: 5| Step: 10
Training loss: 0.1482374519109726
Validation loss: 1.5648691192750008

Epoch: 410| Step: 0
Training loss: 0.12557077407836914
Validation loss: 1.5498061513388028

Epoch: 5| Step: 1
Training loss: 0.18499693274497986
Validation loss: 1.5147474478649836

Epoch: 5| Step: 2
Training loss: 0.16065192222595215
Validation loss: 1.4912694256792787

Epoch: 5| Step: 3
Training loss: 0.23486705124378204
Validation loss: 1.503279096336775

Epoch: 5| Step: 4
Training loss: 0.09487426280975342
Validation loss: 1.5463562998720395

Epoch: 5| Step: 5
Training loss: 0.2140309363603592
Validation loss: 1.5315593968155563

Epoch: 5| Step: 6
Training loss: 0.08572074770927429
Validation loss: 1.535435022846345

Epoch: 5| Step: 7
Training loss: 0.15213674306869507
Validation loss: 1.5752655101078812

Epoch: 5| Step: 8
Training loss: 0.10784001648426056
Validation loss: 1.5879532752498504

Epoch: 5| Step: 9
Training loss: 0.16985993087291718
Validation loss: 1.5887828398776311

Epoch: 5| Step: 10
Training loss: 0.28491267561912537
Validation loss: 1.5814367314820648

Epoch: 411| Step: 0
Training loss: 0.17811527848243713
Validation loss: 1.5650936557400612

Epoch: 5| Step: 1
Training loss: 0.14034786820411682
Validation loss: 1.5919945265657158

Epoch: 5| Step: 2
Training loss: 0.0853143259882927
Validation loss: 1.5918856782297934

Epoch: 5| Step: 3
Training loss: 0.19801083207130432
Validation loss: 1.581122402221926

Epoch: 5| Step: 4
Training loss: 0.09978697448968887
Validation loss: 1.592176668105587

Epoch: 5| Step: 5
Training loss: 0.102485790848732
Validation loss: 1.5659583166081419

Epoch: 5| Step: 6
Training loss: 0.1007237657904625
Validation loss: 1.5455787143399637

Epoch: 5| Step: 7
Training loss: 0.12898369133472443
Validation loss: 1.5462142882808563

Epoch: 5| Step: 8
Training loss: 0.12617631256580353
Validation loss: 1.569745486141533

Epoch: 5| Step: 9
Training loss: 0.16164982318878174
Validation loss: 1.5635882231496996

Epoch: 5| Step: 10
Training loss: 0.31058502197265625
Validation loss: 1.5704505353845575

Epoch: 412| Step: 0
Training loss: 0.0996956005692482
Validation loss: 1.5494889008101596

Epoch: 5| Step: 1
Training loss: 0.1170182004570961
Validation loss: 1.5277155778741325

Epoch: 5| Step: 2
Training loss: 0.1851424276828766
Validation loss: 1.5837322460707797

Epoch: 5| Step: 3
Training loss: 0.11845438182353973
Validation loss: 1.5676728294741722

Epoch: 5| Step: 4
Training loss: 0.16706904768943787
Validation loss: 1.5435476700464885

Epoch: 5| Step: 5
Training loss: 0.18882033228874207
Validation loss: 1.5730919299587127

Epoch: 5| Step: 6
Training loss: 0.16448864340782166
Validation loss: 1.5736299227642756

Epoch: 5| Step: 7
Training loss: 0.1699988842010498
Validation loss: 1.5494422528051561

Epoch: 5| Step: 8
Training loss: 0.1299794614315033
Validation loss: 1.5571906323074012

Epoch: 5| Step: 9
Training loss: 0.1226857528090477
Validation loss: 1.558084499451422

Epoch: 5| Step: 10
Training loss: 0.28592801094055176
Validation loss: 1.5169103837782336

Epoch: 413| Step: 0
Training loss: 0.14910954236984253
Validation loss: 1.546174148077606

Epoch: 5| Step: 1
Training loss: 0.19917640089988708
Validation loss: 1.5327460073655652

Epoch: 5| Step: 2
Training loss: 0.3055376410484314
Validation loss: 1.539991395447844

Epoch: 5| Step: 3
Training loss: 0.11760696023702621
Validation loss: 1.5380897483518046

Epoch: 5| Step: 4
Training loss: 0.1601373255252838
Validation loss: 1.5483093236082344

Epoch: 5| Step: 5
Training loss: 0.16263777017593384
Validation loss: 1.5847177172219882

Epoch: 5| Step: 6
Training loss: 0.12959977984428406
Validation loss: 1.5749267583252282

Epoch: 5| Step: 7
Training loss: 0.09274893254041672
Validation loss: 1.6015705139406267

Epoch: 5| Step: 8
Training loss: 0.1424589604139328
Validation loss: 1.6118128145894697

Epoch: 5| Step: 9
Training loss: 0.21233972907066345
Validation loss: 1.603439123399796

Epoch: 5| Step: 10
Training loss: 0.12973511219024658
Validation loss: 1.5791306880212599

Epoch: 414| Step: 0
Training loss: 0.09707753360271454
Validation loss: 1.5910446874557003

Epoch: 5| Step: 1
Training loss: 0.12728925049304962
Validation loss: 1.5559363198536698

Epoch: 5| Step: 2
Training loss: 0.09487991780042648
Validation loss: 1.5744823332755797

Epoch: 5| Step: 3
Training loss: 0.13480551540851593
Validation loss: 1.5492979429101432

Epoch: 5| Step: 4
Training loss: 0.3042815029621124
Validation loss: 1.5665728167821003

Epoch: 5| Step: 5
Training loss: 0.10263248533010483
Validation loss: 1.532859456154608

Epoch: 5| Step: 6
Training loss: 0.13909657299518585
Validation loss: 1.5211537589309037

Epoch: 5| Step: 7
Training loss: 0.15168976783752441
Validation loss: 1.5571047285551667

Epoch: 5| Step: 8
Training loss: 0.10397849977016449
Validation loss: 1.550280063383041

Epoch: 5| Step: 9
Training loss: 0.18718774616718292
Validation loss: 1.5752739380764704

Epoch: 5| Step: 10
Training loss: 0.16803397238254547
Validation loss: 1.572771882498136

Epoch: 415| Step: 0
Training loss: 0.13474971055984497
Validation loss: 1.548873169447786

Epoch: 5| Step: 1
Training loss: 0.10656486451625824
Validation loss: 1.576595840915557

Epoch: 5| Step: 2
Training loss: 0.0987580269575119
Validation loss: 1.5704851355603946

Epoch: 5| Step: 3
Training loss: 0.1633530557155609
Validation loss: 1.5436984967159968

Epoch: 5| Step: 4
Training loss: 0.13055825233459473
Validation loss: 1.552583332984678

Epoch: 5| Step: 5
Training loss: 0.11247420310974121
Validation loss: 1.5327869820338424

Epoch: 5| Step: 6
Training loss: 0.23690755665302277
Validation loss: 1.5057547092437744

Epoch: 5| Step: 7
Training loss: 0.15916089713573456
Validation loss: 1.5100828530967876

Epoch: 5| Step: 8
Training loss: 0.1410493552684784
Validation loss: 1.520149580893978

Epoch: 5| Step: 9
Training loss: 0.1838107407093048
Validation loss: 1.5448411100654191

Epoch: 5| Step: 10
Training loss: 0.10034019500017166
Validation loss: 1.5276515535129014

Epoch: 416| Step: 0
Training loss: 0.11800800263881683
Validation loss: 1.4768405281087404

Epoch: 5| Step: 1
Training loss: 0.10859385877847672
Validation loss: 1.518403980039781

Epoch: 5| Step: 2
Training loss: 0.10340330749750137
Validation loss: 1.5484662594333771

Epoch: 5| Step: 3
Training loss: 0.21072883903980255
Validation loss: 1.6099730486510901

Epoch: 5| Step: 4
Training loss: 0.121773362159729
Validation loss: 1.5737920473980647

Epoch: 5| Step: 5
Training loss: 0.151212677359581
Validation loss: 1.566293784367141

Epoch: 5| Step: 6
Training loss: 0.19965389370918274
Validation loss: 1.6005809255825576

Epoch: 5| Step: 7
Training loss: 0.10548214614391327
Validation loss: 1.556966886725477

Epoch: 5| Step: 8
Training loss: 0.19929830729961395
Validation loss: 1.5692036856887162

Epoch: 5| Step: 9
Training loss: 0.0938805490732193
Validation loss: 1.5299780355986727

Epoch: 5| Step: 10
Training loss: 0.18852770328521729
Validation loss: 1.5172179514361965

Epoch: 417| Step: 0
Training loss: 0.15470324456691742
Validation loss: 1.5093273347423923

Epoch: 5| Step: 1
Training loss: 0.0941987857222557
Validation loss: 1.47671942428876

Epoch: 5| Step: 2
Training loss: 0.19359596073627472
Validation loss: 1.488240034349503

Epoch: 5| Step: 3
Training loss: 0.17528843879699707
Validation loss: 1.4814056529793689

Epoch: 5| Step: 4
Training loss: 0.13774383068084717
Validation loss: 1.5147422872563845

Epoch: 5| Step: 5
Training loss: 0.0894356220960617
Validation loss: 1.4964052938645886

Epoch: 5| Step: 6
Training loss: 0.08742524683475494
Validation loss: 1.5075525955487323

Epoch: 5| Step: 7
Training loss: 0.24094276130199432
Validation loss: 1.5229453066343903

Epoch: 5| Step: 8
Training loss: 0.14000678062438965
Validation loss: 1.6004704941985428

Epoch: 5| Step: 9
Training loss: 0.1501809060573578
Validation loss: 1.5861044750418714

Epoch: 5| Step: 10
Training loss: 0.09340769797563553
Validation loss: 1.6048364472645584

Epoch: 418| Step: 0
Training loss: 0.1344544142484665
Validation loss: 1.5900199669663624

Epoch: 5| Step: 1
Training loss: 0.07277500629425049
Validation loss: 1.5416557750394266

Epoch: 5| Step: 2
Training loss: 0.18893693387508392
Validation loss: 1.5622637887154855

Epoch: 5| Step: 3
Training loss: 0.10597074031829834
Validation loss: 1.5492393932034891

Epoch: 5| Step: 4
Training loss: 0.10001544654369354
Validation loss: 1.5350577017312408

Epoch: 5| Step: 5
Training loss: 0.14015008509159088
Validation loss: 1.544015694690007

Epoch: 5| Step: 6
Training loss: 0.2587626874446869
Validation loss: 1.565888161300331

Epoch: 5| Step: 7
Training loss: 0.1185867041349411
Validation loss: 1.550064758587909

Epoch: 5| Step: 8
Training loss: 0.10014869272708893
Validation loss: 1.5506999543918076

Epoch: 5| Step: 9
Training loss: 0.13462361693382263
Validation loss: 1.5272891790636125

Epoch: 5| Step: 10
Training loss: 0.1379864662885666
Validation loss: 1.5767869936522616

Epoch: 419| Step: 0
Training loss: 0.1407642513513565
Validation loss: 1.616642221327751

Epoch: 5| Step: 1
Training loss: 0.1861940175294876
Validation loss: 1.6006730461633334

Epoch: 5| Step: 2
Training loss: 0.18165482580661774
Validation loss: 1.6017176605040027

Epoch: 5| Step: 3
Training loss: 0.17739291489124298
Validation loss: 1.5705790442805136

Epoch: 5| Step: 4
Training loss: 0.11210417747497559
Validation loss: 1.5844316117225155

Epoch: 5| Step: 5
Training loss: 0.3119390904903412
Validation loss: 1.5605969288015877

Epoch: 5| Step: 6
Training loss: 0.19394339621067047
Validation loss: 1.5516863792173323

Epoch: 5| Step: 7
Training loss: 0.15855498611927032
Validation loss: 1.5370537721982567

Epoch: 5| Step: 8
Training loss: 0.0683397427201271
Validation loss: 1.5266538095730606

Epoch: 5| Step: 9
Training loss: 0.15600351989269257
Validation loss: 1.498918342974878

Epoch: 5| Step: 10
Training loss: 0.12178631126880646
Validation loss: 1.539644697661041

Epoch: 420| Step: 0
Training loss: 0.18726518750190735
Validation loss: 1.5074230996511315

Epoch: 5| Step: 1
Training loss: 0.09399034827947617
Validation loss: 1.507566762226884

Epoch: 5| Step: 2
Training loss: 0.1027056947350502
Validation loss: 1.519647620698457

Epoch: 5| Step: 3
Training loss: 0.1319362372159958
Validation loss: 1.4942776426192252

Epoch: 5| Step: 4
Training loss: 0.1862061768770218
Validation loss: 1.53436125991165

Epoch: 5| Step: 5
Training loss: 0.16161952912807465
Validation loss: 1.5397560750284502

Epoch: 5| Step: 6
Training loss: 0.12447978556156158
Validation loss: 1.5328364090252948

Epoch: 5| Step: 7
Training loss: 0.08313453942537308
Validation loss: 1.546538104293167

Epoch: 5| Step: 8
Training loss: 0.22519588470458984
Validation loss: 1.5589097033264816

Epoch: 5| Step: 9
Training loss: 0.10837902128696442
Validation loss: 1.543433145810199

Epoch: 5| Step: 10
Training loss: 0.13199153542518616
Validation loss: 1.5387713755330732

Epoch: 421| Step: 0
Training loss: 0.11212842166423798
Validation loss: 1.5454165711197803

Epoch: 5| Step: 1
Training loss: 0.25030994415283203
Validation loss: 1.537823889845161

Epoch: 5| Step: 2
Training loss: 0.11496806144714355
Validation loss: 1.565415479803598

Epoch: 5| Step: 3
Training loss: 0.16453415155410767
Validation loss: 1.5063443722263459

Epoch: 5| Step: 4
Training loss: 0.11234889179468155
Validation loss: 1.5170829962658625

Epoch: 5| Step: 5
Training loss: 0.12950678169727325
Validation loss: 1.517599178898719

Epoch: 5| Step: 6
Training loss: 0.1352681815624237
Validation loss: 1.4956450257250058

Epoch: 5| Step: 7
Training loss: 0.10244808346033096
Validation loss: 1.5170003553872466

Epoch: 5| Step: 8
Training loss: 0.12637418508529663
Validation loss: 1.5048730258018739

Epoch: 5| Step: 9
Training loss: 0.15247096121311188
Validation loss: 1.485995807955342

Epoch: 5| Step: 10
Training loss: 0.13241659104824066
Validation loss: 1.5012523519095553

Epoch: 422| Step: 0
Training loss: 0.27655288577079773
Validation loss: 1.493942004378124

Epoch: 5| Step: 1
Training loss: 0.1167709082365036
Validation loss: 1.5209762370714577

Epoch: 5| Step: 2
Training loss: 0.08737069368362427
Validation loss: 1.5349242020678777

Epoch: 5| Step: 3
Training loss: 0.08977074921131134
Validation loss: 1.561385464924638

Epoch: 5| Step: 4
Training loss: 0.09980478882789612
Validation loss: 1.543355462371662

Epoch: 5| Step: 5
Training loss: 0.10952617973089218
Validation loss: 1.5718457724458428

Epoch: 5| Step: 6
Training loss: 0.08328308165073395
Validation loss: 1.5200516011125298

Epoch: 5| Step: 7
Training loss: 0.19510069489479065
Validation loss: 1.54471872057966

Epoch: 5| Step: 8
Training loss: 0.15273872017860413
Validation loss: 1.5204568024604552

Epoch: 5| Step: 9
Training loss: 0.1342204362154007
Validation loss: 1.5230438670804423

Epoch: 5| Step: 10
Training loss: 0.0901079922914505
Validation loss: 1.5309992913276917

Epoch: 423| Step: 0
Training loss: 0.07162388414144516
Validation loss: 1.5608008433413763

Epoch: 5| Step: 1
Training loss: 0.17780908942222595
Validation loss: 1.5188701921893704

Epoch: 5| Step: 2
Training loss: 0.14681768417358398
Validation loss: 1.5430915714592062

Epoch: 5| Step: 3
Training loss: 0.13075199723243713
Validation loss: 1.5330649204151605

Epoch: 5| Step: 4
Training loss: 0.1332910805940628
Validation loss: 1.5478238392901678

Epoch: 5| Step: 5
Training loss: 0.10334068536758423
Validation loss: 1.5667163582258328

Epoch: 5| Step: 6
Training loss: 0.12652376294136047
Validation loss: 1.5503216289704846

Epoch: 5| Step: 7
Training loss: 0.1637926548719406
Validation loss: 1.533945357927712

Epoch: 5| Step: 8
Training loss: 0.18307174742221832
Validation loss: 1.5438851489815661

Epoch: 5| Step: 9
Training loss: 0.1698402613401413
Validation loss: 1.584627906481425

Epoch: 5| Step: 10
Training loss: 0.12662525475025177
Validation loss: 1.5661791345124603

Epoch: 424| Step: 0
Training loss: 0.1877145618200302
Validation loss: 1.525782609498629

Epoch: 5| Step: 1
Training loss: 0.12280213832855225
Validation loss: 1.555080198472546

Epoch: 5| Step: 2
Training loss: 0.08626249432563782
Validation loss: 1.5546996490929716

Epoch: 5| Step: 3
Training loss: 0.11197181791067123
Validation loss: 1.5381619379084597

Epoch: 5| Step: 4
Training loss: 0.1776028424501419
Validation loss: 1.5321939683729602

Epoch: 5| Step: 5
Training loss: 0.15160419046878815
Validation loss: 1.52654049088878

Epoch: 5| Step: 6
Training loss: 0.1295280009508133
Validation loss: 1.5087323932237522

Epoch: 5| Step: 7
Training loss: 0.12539616227149963
Validation loss: 1.4748818605176863

Epoch: 5| Step: 8
Training loss: 0.13249480724334717
Validation loss: 1.5261595338903449

Epoch: 5| Step: 9
Training loss: 0.2621251046657562
Validation loss: 1.5137823038203742

Epoch: 5| Step: 10
Training loss: 0.16051144897937775
Validation loss: 1.4851499789504594

Epoch: 425| Step: 0
Training loss: 0.12706434726715088
Validation loss: 1.4960692492864465

Epoch: 5| Step: 1
Training loss: 0.10788550227880478
Validation loss: 1.4766171645092707

Epoch: 5| Step: 2
Training loss: 0.20098046958446503
Validation loss: 1.4594165843020204

Epoch: 5| Step: 3
Training loss: 0.1384095847606659
Validation loss: 1.4362681918246771

Epoch: 5| Step: 4
Training loss: 0.12132147699594498
Validation loss: 1.4607763213496054

Epoch: 5| Step: 5
Training loss: 0.11469242721796036
Validation loss: 1.473551474591737

Epoch: 5| Step: 6
Training loss: 0.1595015972852707
Validation loss: 1.4542962915153914

Epoch: 5| Step: 7
Training loss: 0.17492781579494476
Validation loss: 1.486164495509158

Epoch: 5| Step: 8
Training loss: 0.07492570579051971
Validation loss: 1.5324870386431295

Epoch: 5| Step: 9
Training loss: 0.11491362750530243
Validation loss: 1.522797833206833

Epoch: 5| Step: 10
Training loss: 0.10988493263721466
Validation loss: 1.5763056739684074

Epoch: 426| Step: 0
Training loss: 0.1475014090538025
Validation loss: 1.523480607617286

Epoch: 5| Step: 1
Training loss: 0.11485636234283447
Validation loss: 1.5379521193042878

Epoch: 5| Step: 2
Training loss: 0.09954904019832611
Validation loss: 1.5429207451881901

Epoch: 5| Step: 3
Training loss: 0.14705947041511536
Validation loss: 1.4941632427195066

Epoch: 5| Step: 4
Training loss: 0.07486873865127563
Validation loss: 1.479375091932153

Epoch: 5| Step: 5
Training loss: 0.10444221645593643
Validation loss: 1.4514864478059994

Epoch: 5| Step: 6
Training loss: 0.20365285873413086
Validation loss: 1.4466603250913723

Epoch: 5| Step: 7
Training loss: 0.13212215900421143
Validation loss: 1.4331948769989835

Epoch: 5| Step: 8
Training loss: 0.23288877308368683
Validation loss: 1.4478290978298392

Epoch: 5| Step: 9
Training loss: 0.20729920268058777
Validation loss: 1.4303548989757415

Epoch: 5| Step: 10
Training loss: 0.13593845069408417
Validation loss: 1.5119034192895378

Epoch: 427| Step: 0
Training loss: 0.14638212323188782
Validation loss: 1.5319924764735724

Epoch: 5| Step: 1
Training loss: 0.14694781601428986
Validation loss: 1.5305643158574258

Epoch: 5| Step: 2
Training loss: 0.13608285784721375
Validation loss: 1.5904266693258797

Epoch: 5| Step: 3
Training loss: 0.14342816174030304
Validation loss: 1.5700120977176133

Epoch: 5| Step: 4
Training loss: 0.11688625812530518
Validation loss: 1.5952856386861494

Epoch: 5| Step: 5
Training loss: 0.25689536333084106
Validation loss: 1.5887571521984634

Epoch: 5| Step: 6
Training loss: 0.18622954189777374
Validation loss: 1.6212589753571378

Epoch: 5| Step: 7
Training loss: 0.19205144047737122
Validation loss: 1.6269011523133965

Epoch: 5| Step: 8
Training loss: 0.12211539596319199
Validation loss: 1.6274946248659523

Epoch: 5| Step: 9
Training loss: 0.13372577726840973
Validation loss: 1.5861671227280811

Epoch: 5| Step: 10
Training loss: 0.06577359139919281
Validation loss: 1.5103607203370781

Epoch: 428| Step: 0
Training loss: 0.1182449460029602
Validation loss: 1.5262701819019933

Epoch: 5| Step: 1
Training loss: 0.15210595726966858
Validation loss: 1.523934418155301

Epoch: 5| Step: 2
Training loss: 0.1283584088087082
Validation loss: 1.5146434076370732

Epoch: 5| Step: 3
Training loss: 0.16434772312641144
Validation loss: 1.5113914628182687

Epoch: 5| Step: 4
Training loss: 0.13602301478385925
Validation loss: 1.5239012779728058

Epoch: 5| Step: 5
Training loss: 0.21215800940990448
Validation loss: 1.499352119302237

Epoch: 5| Step: 6
Training loss: 0.0898459404706955
Validation loss: 1.539268974334963

Epoch: 5| Step: 7
Training loss: 0.10294077545404434
Validation loss: 1.524259139132756

Epoch: 5| Step: 8
Training loss: 0.1267787367105484
Validation loss: 1.5509154283872215

Epoch: 5| Step: 9
Training loss: 0.07241684198379517
Validation loss: 1.5311771092876312

Epoch: 5| Step: 10
Training loss: 0.11986160278320312
Validation loss: 1.543476209845594

Epoch: 429| Step: 0
Training loss: 0.12487871944904327
Validation loss: 1.5471170243396555

Epoch: 5| Step: 1
Training loss: 0.14033924043178558
Validation loss: 1.5652431711073844

Epoch: 5| Step: 2
Training loss: 0.10464129596948624
Validation loss: 1.5184176096352198

Epoch: 5| Step: 3
Training loss: 0.1192002072930336
Validation loss: 1.532237563081967

Epoch: 5| Step: 4
Training loss: 0.1293300986289978
Validation loss: 1.5282567207531264

Epoch: 5| Step: 5
Training loss: 0.11023181676864624
Validation loss: 1.5421213680698025

Epoch: 5| Step: 6
Training loss: 0.1840541809797287
Validation loss: 1.5499764257861721

Epoch: 5| Step: 7
Training loss: 0.10881590843200684
Validation loss: 1.5336016006367181

Epoch: 5| Step: 8
Training loss: 0.11318731307983398
Validation loss: 1.5496732957901493

Epoch: 5| Step: 9
Training loss: 0.1125909835100174
Validation loss: 1.5511012000422324

Epoch: 5| Step: 10
Training loss: 0.27363160252571106
Validation loss: 1.5937886776462677

Epoch: 430| Step: 0
Training loss: 0.1296718567609787
Validation loss: 1.5736499255703342

Epoch: 5| Step: 1
Training loss: 0.122319795191288
Validation loss: 1.5744955629430792

Epoch: 5| Step: 2
Training loss: 0.1438053846359253
Validation loss: 1.5936714859418972

Epoch: 5| Step: 3
Training loss: 0.08229198306798935
Validation loss: 1.615861677354382

Epoch: 5| Step: 4
Training loss: 0.14494065940380096
Validation loss: 1.5682921845425841

Epoch: 5| Step: 5
Training loss: 0.13255664706230164
Validation loss: 1.578020005456863

Epoch: 5| Step: 6
Training loss: 0.24844665825366974
Validation loss: 1.5423020649981756

Epoch: 5| Step: 7
Training loss: 0.08131898939609528
Validation loss: 1.5770839862926032

Epoch: 5| Step: 8
Training loss: 0.13746817409992218
Validation loss: 1.5349878341920915

Epoch: 5| Step: 9
Training loss: 0.12519006431102753
Validation loss: 1.545737308840598

Epoch: 5| Step: 10
Training loss: 0.10932906717061996
Validation loss: 1.5203504331650273

Epoch: 431| Step: 0
Training loss: 0.10738629102706909
Validation loss: 1.5198690442628757

Epoch: 5| Step: 1
Training loss: 0.2732507586479187
Validation loss: 1.5216507245135564

Epoch: 5| Step: 2
Training loss: 0.1119987741112709
Validation loss: 1.4856758245857813

Epoch: 5| Step: 3
Training loss: 0.08576905727386475
Validation loss: 1.50142817407526

Epoch: 5| Step: 4
Training loss: 0.10104440152645111
Validation loss: 1.527113901671543

Epoch: 5| Step: 5
Training loss: 0.1312071681022644
Validation loss: 1.5185880968647618

Epoch: 5| Step: 6
Training loss: 0.08782555907964706
Validation loss: 1.5011067018714002

Epoch: 5| Step: 7
Training loss: 0.1606726199388504
Validation loss: 1.529400634509261

Epoch: 5| Step: 8
Training loss: 0.143042653799057
Validation loss: 1.5400129236200804

Epoch: 5| Step: 9
Training loss: 0.13340510427951813
Validation loss: 1.5489526423074866

Epoch: 5| Step: 10
Training loss: 0.06844472885131836
Validation loss: 1.5393047050763202

Epoch: 432| Step: 0
Training loss: 0.1851482093334198
Validation loss: 1.5386434114107521

Epoch: 5| Step: 1
Training loss: 0.08643260598182678
Validation loss: 1.5563686829741283

Epoch: 5| Step: 2
Training loss: 0.12871208786964417
Validation loss: 1.5293033904926752

Epoch: 5| Step: 3
Training loss: 0.09319201111793518
Validation loss: 1.4992272353941394

Epoch: 5| Step: 4
Training loss: 0.08561287075281143
Validation loss: 1.5494966827413088

Epoch: 5| Step: 5
Training loss: 0.14215600490570068
Validation loss: 1.5231635147525417

Epoch: 5| Step: 6
Training loss: 0.13690727949142456
Validation loss: 1.5370283537013556

Epoch: 5| Step: 7
Training loss: 0.2238617241382599
Validation loss: 1.535834934121819

Epoch: 5| Step: 8
Training loss: 0.12674225866794586
Validation loss: 1.5053034014599298

Epoch: 5| Step: 9
Training loss: 0.10476791858673096
Validation loss: 1.5004912358458324

Epoch: 5| Step: 10
Training loss: 0.10497208684682846
Validation loss: 1.520581260804207

Epoch: 433| Step: 0
Training loss: 0.13676926493644714
Validation loss: 1.5088611636110532

Epoch: 5| Step: 1
Training loss: 0.11924449354410172
Validation loss: 1.4995799987546858

Epoch: 5| Step: 2
Training loss: 0.09988000243902206
Validation loss: 1.5178557236989338

Epoch: 5| Step: 3
Training loss: 0.2396228015422821
Validation loss: 1.5349212231174592

Epoch: 5| Step: 4
Training loss: 0.1388475000858307
Validation loss: 1.5162424637425331

Epoch: 5| Step: 5
Training loss: 0.09759119153022766
Validation loss: 1.5356783225972166

Epoch: 5| Step: 6
Training loss: 0.09068746864795685
Validation loss: 1.533278356316269

Epoch: 5| Step: 7
Training loss: 0.1113908514380455
Validation loss: 1.5337031784877981

Epoch: 5| Step: 8
Training loss: 0.11916796118021011
Validation loss: 1.541139151460381

Epoch: 5| Step: 9
Training loss: 0.11195727437734604
Validation loss: 1.5120662047017006

Epoch: 5| Step: 10
Training loss: 0.13924448192119598
Validation loss: 1.5365715783129457

Epoch: 434| Step: 0
Training loss: 0.1314765214920044
Validation loss: 1.5726182960694837

Epoch: 5| Step: 1
Training loss: 0.10107846558094025
Validation loss: 1.4997156794353197

Epoch: 5| Step: 2
Training loss: 0.07402323931455612
Validation loss: 1.5072117197898127

Epoch: 5| Step: 3
Training loss: 0.15193764865398407
Validation loss: 1.5070131542862102

Epoch: 5| Step: 4
Training loss: 0.0772356167435646
Validation loss: 1.51657122629945

Epoch: 5| Step: 5
Training loss: 0.06262912601232529
Validation loss: 1.5305985596872145

Epoch: 5| Step: 6
Training loss: 0.06798503547906876
Validation loss: 1.5185843161357346

Epoch: 5| Step: 7
Training loss: 0.14983731508255005
Validation loss: 1.5200420348874983

Epoch: 5| Step: 8
Training loss: 0.09254143387079239
Validation loss: 1.540295962364443

Epoch: 5| Step: 9
Training loss: 0.10390367358922958
Validation loss: 1.5363385805519678

Epoch: 5| Step: 10
Training loss: 0.26456406712532043
Validation loss: 1.5720195193444528

Epoch: 435| Step: 0
Training loss: 0.1105373278260231
Validation loss: 1.571285545185048

Epoch: 5| Step: 1
Training loss: 0.11246795952320099
Validation loss: 1.6212156690577024

Epoch: 5| Step: 2
Training loss: 0.1721649020910263
Validation loss: 1.5870300877478816

Epoch: 5| Step: 3
Training loss: 0.07342888414859772
Validation loss: 1.568318328549785

Epoch: 5| Step: 4
Training loss: 0.07321573793888092
Validation loss: 1.5381995272892777

Epoch: 5| Step: 5
Training loss: 0.13049724698066711
Validation loss: 1.5456313138367028

Epoch: 5| Step: 6
Training loss: 0.12220640480518341
Validation loss: 1.5419904493516492

Epoch: 5| Step: 7
Training loss: 0.23638220131397247
Validation loss: 1.54158414307461

Epoch: 5| Step: 8
Training loss: 0.07541509717702866
Validation loss: 1.5368262606282388

Epoch: 5| Step: 9
Training loss: 0.08932540565729141
Validation loss: 1.5398539638006559

Epoch: 5| Step: 10
Training loss: 0.1456487774848938
Validation loss: 1.4931269679018246

Epoch: 436| Step: 0
Training loss: 0.08593468368053436
Validation loss: 1.540360652631329

Epoch: 5| Step: 1
Training loss: 0.09630612283945084
Validation loss: 1.5532837657518284

Epoch: 5| Step: 2
Training loss: 0.13719382882118225
Validation loss: 1.5815056139423

Epoch: 5| Step: 3
Training loss: 0.0960172787308693
Validation loss: 1.5267941464659989

Epoch: 5| Step: 4
Training loss: 0.12514294683933258
Validation loss: 1.5351436343244327

Epoch: 5| Step: 5
Training loss: 0.09699597209692001
Validation loss: 1.5334239518770607

Epoch: 5| Step: 6
Training loss: 0.09359072148799896
Validation loss: 1.5276793690137966

Epoch: 5| Step: 7
Training loss: 0.1195300966501236
Validation loss: 1.5287383506374974

Epoch: 5| Step: 8
Training loss: 0.23886170983314514
Validation loss: 1.4923459124821488

Epoch: 5| Step: 9
Training loss: 0.13609522581100464
Validation loss: 1.5112328888267599

Epoch: 5| Step: 10
Training loss: 0.11619459092617035
Validation loss: 1.4725426089379094

Epoch: 437| Step: 0
Training loss: 0.14322881400585175
Validation loss: 1.5098205420278734

Epoch: 5| Step: 1
Training loss: 0.06399904191493988
Validation loss: 1.4958136761060326

Epoch: 5| Step: 2
Training loss: 0.1560601145029068
Validation loss: 1.5124421504236036

Epoch: 5| Step: 3
Training loss: 0.09584047645330429
Validation loss: 1.5080661068680465

Epoch: 5| Step: 4
Training loss: 0.0751027837395668
Validation loss: 1.5517791266082435

Epoch: 5| Step: 5
Training loss: 0.08312224596738815
Validation loss: 1.5457488003597464

Epoch: 5| Step: 6
Training loss: 0.13115987181663513
Validation loss: 1.5449154505165674

Epoch: 5| Step: 7
Training loss: 0.2705775797367096
Validation loss: 1.5507698110354844

Epoch: 5| Step: 8
Training loss: 0.11708478629589081
Validation loss: 1.555737821004724

Epoch: 5| Step: 9
Training loss: 0.12802007794380188
Validation loss: 1.5678739650275118

Epoch: 5| Step: 10
Training loss: 0.15636727213859558
Validation loss: 1.5432771059774584

Epoch: 438| Step: 0
Training loss: 0.11561016738414764
Validation loss: 1.4888826877840105

Epoch: 5| Step: 1
Training loss: 0.08545886725187302
Validation loss: 1.486360348680968

Epoch: 5| Step: 2
Training loss: 0.1138233169913292
Validation loss: 1.4909878212918517

Epoch: 5| Step: 3
Training loss: 0.15572893619537354
Validation loss: 1.4924129875757361

Epoch: 5| Step: 4
Training loss: 0.13590529561042786
Validation loss: 1.4991755306079824

Epoch: 5| Step: 5
Training loss: 0.07822636514902115
Validation loss: 1.4804584204509694

Epoch: 5| Step: 6
Training loss: 0.13228905200958252
Validation loss: 1.4983545657127135

Epoch: 5| Step: 7
Training loss: 0.11624413728713989
Validation loss: 1.5395299516698366

Epoch: 5| Step: 8
Training loss: 0.20500218868255615
Validation loss: 1.5169971719864876

Epoch: 5| Step: 9
Training loss: 0.08455471694469452
Validation loss: 1.5561936222096926

Epoch: 5| Step: 10
Training loss: 0.10397106409072876
Validation loss: 1.5700475810676493

Epoch: 439| Step: 0
Training loss: 0.07710637152194977
Validation loss: 1.5751636643563547

Epoch: 5| Step: 1
Training loss: 0.20814304053783417
Validation loss: 1.5640517562948248

Epoch: 5| Step: 2
Training loss: 0.07129040360450745
Validation loss: 1.5516230073026431

Epoch: 5| Step: 3
Training loss: 0.1195911392569542
Validation loss: 1.547593394915263

Epoch: 5| Step: 4
Training loss: 0.12137472629547119
Validation loss: 1.5560704815772273

Epoch: 5| Step: 5
Training loss: 0.13269147276878357
Validation loss: 1.5590187061217524

Epoch: 5| Step: 6
Training loss: 0.10607685148715973
Validation loss: 1.5377583670359787

Epoch: 5| Step: 7
Training loss: 0.22923369705677032
Validation loss: 1.5255999449760682

Epoch: 5| Step: 8
Training loss: 0.08196940273046494
Validation loss: 1.5426884453783754

Epoch: 5| Step: 9
Training loss: 0.09174454212188721
Validation loss: 1.540498068255763

Epoch: 5| Step: 10
Training loss: 0.10079411417245865
Validation loss: 1.5259982155215355

Epoch: 440| Step: 0
Training loss: 0.08584453165531158
Validation loss: 1.531375685045796

Epoch: 5| Step: 1
Training loss: 0.10763230174779892
Validation loss: 1.496675169596108

Epoch: 5| Step: 2
Training loss: 0.11642563343048096
Validation loss: 1.5110923180016138

Epoch: 5| Step: 3
Training loss: 0.22069501876831055
Validation loss: 1.49432373046875

Epoch: 5| Step: 4
Training loss: 0.11962057650089264
Validation loss: 1.4636250054964455

Epoch: 5| Step: 5
Training loss: 0.21082735061645508
Validation loss: 1.4592074809535858

Epoch: 5| Step: 6
Training loss: 0.1740204244852066
Validation loss: 1.4510422137475782

Epoch: 5| Step: 7
Training loss: 0.12640665471553802
Validation loss: 1.4914788635828162

Epoch: 5| Step: 8
Training loss: 0.10528428852558136
Validation loss: 1.4938594871951687

Epoch: 5| Step: 9
Training loss: 0.13751980662345886
Validation loss: 1.52803292710294

Epoch: 5| Step: 10
Training loss: 0.11418649554252625
Validation loss: 1.515063073045464

Epoch: 441| Step: 0
Training loss: 0.10769853740930557
Validation loss: 1.5126421656659854

Epoch: 5| Step: 1
Training loss: 0.09059345722198486
Validation loss: 1.4941678418908069

Epoch: 5| Step: 2
Training loss: 0.10753490775823593
Validation loss: 1.5203434036624046

Epoch: 5| Step: 3
Training loss: 0.10900537669658661
Validation loss: 1.5223758528309483

Epoch: 5| Step: 4
Training loss: 0.09269475191831589
Validation loss: 1.520765450692946

Epoch: 5| Step: 5
Training loss: 0.20579960942268372
Validation loss: 1.526400957056271

Epoch: 5| Step: 6
Training loss: 0.12311617285013199
Validation loss: 1.529773332739389

Epoch: 5| Step: 7
Training loss: 0.05953570455312729
Validation loss: 1.5090888072085638

Epoch: 5| Step: 8
Training loss: 0.1830657571554184
Validation loss: 1.497374826861966

Epoch: 5| Step: 9
Training loss: 0.06854071468114853
Validation loss: 1.5271735255436232

Epoch: 5| Step: 10
Training loss: 0.07525952905416489
Validation loss: 1.506848713403107

Epoch: 442| Step: 0
Training loss: 0.09318328648805618
Validation loss: 1.4872497166356733

Epoch: 5| Step: 1
Training loss: 0.1418190747499466
Validation loss: 1.5140440976747902

Epoch: 5| Step: 2
Training loss: 0.06725994497537613
Validation loss: 1.5077935470047819

Epoch: 5| Step: 3
Training loss: 0.07816906273365021
Validation loss: 1.525262608323046

Epoch: 5| Step: 4
Training loss: 0.10157519578933716
Validation loss: 1.5159540240482619

Epoch: 5| Step: 5
Training loss: 0.10683612525463104
Validation loss: 1.4825933902494368

Epoch: 5| Step: 6
Training loss: 0.1412842571735382
Validation loss: 1.4792931977138724

Epoch: 5| Step: 7
Training loss: 0.11367203295230865
Validation loss: 1.4814695863313572

Epoch: 5| Step: 8
Training loss: 0.08047349750995636
Validation loss: 1.490698295254861

Epoch: 5| Step: 9
Training loss: 0.20976440608501434
Validation loss: 1.5044901114638134

Epoch: 5| Step: 10
Training loss: 0.10114103555679321
Validation loss: 1.5212651580892584

Epoch: 443| Step: 0
Training loss: 0.09664203226566315
Validation loss: 1.4881466127211047

Epoch: 5| Step: 1
Training loss: 0.09337206184864044
Validation loss: 1.4706549689333925

Epoch: 5| Step: 2
Training loss: 0.20355498790740967
Validation loss: 1.4783767384867514

Epoch: 5| Step: 3
Training loss: 0.16206958889961243
Validation loss: 1.4991249038327126

Epoch: 5| Step: 4
Training loss: 0.11261968314647675
Validation loss: 1.486018152647121

Epoch: 5| Step: 5
Training loss: 0.12416557967662811
Validation loss: 1.5109924693261423

Epoch: 5| Step: 6
Training loss: 0.10186803340911865
Validation loss: 1.5387378828499907

Epoch: 5| Step: 7
Training loss: 0.12339989840984344
Validation loss: 1.560364345709483

Epoch: 5| Step: 8
Training loss: 0.15484528243541718
Validation loss: 1.5491484621519684

Epoch: 5| Step: 9
Training loss: 0.13648036122322083
Validation loss: 1.57667713908739

Epoch: 5| Step: 10
Training loss: 0.12277145683765411
Validation loss: 1.5656863104912542

Epoch: 444| Step: 0
Training loss: 0.056942641735076904
Validation loss: 1.5733130106361963

Epoch: 5| Step: 1
Training loss: 0.08060600608587265
Validation loss: 1.5513605366470993

Epoch: 5| Step: 2
Training loss: 0.10689885914325714
Validation loss: 1.5583479968450402

Epoch: 5| Step: 3
Training loss: 0.06276006996631622
Validation loss: 1.5635185639063518

Epoch: 5| Step: 4
Training loss: 0.12266410887241364
Validation loss: 1.5449373260621102

Epoch: 5| Step: 5
Training loss: 0.11723650991916656
Validation loss: 1.507020963135586

Epoch: 5| Step: 6
Training loss: 0.1773562729358673
Validation loss: 1.4773428196548133

Epoch: 5| Step: 7
Training loss: 0.23195099830627441
Validation loss: 1.517747845700992

Epoch: 5| Step: 8
Training loss: 0.13344329595565796
Validation loss: 1.5143054813467047

Epoch: 5| Step: 9
Training loss: 0.12237532436847687
Validation loss: 1.4866413115173258

Epoch: 5| Step: 10
Training loss: 0.13604098558425903
Validation loss: 1.5073021534950501

Epoch: 445| Step: 0
Training loss: 0.09446197003126144
Validation loss: 1.5544370887100056

Epoch: 5| Step: 1
Training loss: 0.10522685199975967
Validation loss: 1.5322818512557654

Epoch: 5| Step: 2
Training loss: 0.2180175483226776
Validation loss: 1.5648609104976858

Epoch: 5| Step: 3
Training loss: 0.08663663268089294
Validation loss: 1.5735794882620535

Epoch: 5| Step: 4
Training loss: 0.09192883223295212
Validation loss: 1.591407032423122

Epoch: 5| Step: 5
Training loss: 0.07269872725009918
Validation loss: 1.597587578399207

Epoch: 5| Step: 6
Training loss: 0.18442890048027039
Validation loss: 1.5777050666911627

Epoch: 5| Step: 7
Training loss: 0.11785630881786346
Validation loss: 1.5905948736334359

Epoch: 5| Step: 8
Training loss: 0.18420788645744324
Validation loss: 1.559721767261464

Epoch: 5| Step: 9
Training loss: 0.10729663074016571
Validation loss: 1.558804968351959

Epoch: 5| Step: 10
Training loss: 0.07051333039999008
Validation loss: 1.5498355056649895

Epoch: 446| Step: 0
Training loss: 0.1177465170621872
Validation loss: 1.5584476763202297

Epoch: 5| Step: 1
Training loss: 0.09650231897830963
Validation loss: 1.5324967984230287

Epoch: 5| Step: 2
Training loss: 0.1271657943725586
Validation loss: 1.5108439332695418

Epoch: 5| Step: 3
Training loss: 0.08072838932275772
Validation loss: 1.5311057375323387

Epoch: 5| Step: 4
Training loss: 0.10662417113780975
Validation loss: 1.5216742189981605

Epoch: 5| Step: 5
Training loss: 0.23938031494617462
Validation loss: 1.534017021938037

Epoch: 5| Step: 6
Training loss: 0.10244765132665634
Validation loss: 1.5099182269906486

Epoch: 5| Step: 7
Training loss: 0.12234129011631012
Validation loss: 1.5515893941284509

Epoch: 5| Step: 8
Training loss: 0.09107744693756104
Validation loss: 1.519431548733865

Epoch: 5| Step: 9
Training loss: 0.10779251158237457
Validation loss: 1.525977893542218

Epoch: 5| Step: 10
Training loss: 0.1677929162979126
Validation loss: 1.5280958080804476

Epoch: 447| Step: 0
Training loss: 0.08750604093074799
Validation loss: 1.5752300677760955

Epoch: 5| Step: 1
Training loss: 0.06745541840791702
Validation loss: 1.546463199841079

Epoch: 5| Step: 2
Training loss: 0.13181182742118835
Validation loss: 1.5834154281564938

Epoch: 5| Step: 3
Training loss: 0.07678861916065216
Validation loss: 1.5603799909673712

Epoch: 5| Step: 4
Training loss: 0.08572961390018463
Validation loss: 1.5905350267246205

Epoch: 5| Step: 5
Training loss: 0.22301003336906433
Validation loss: 1.5698809123808337

Epoch: 5| Step: 6
Training loss: 0.12833961844444275
Validation loss: 1.542096625092209

Epoch: 5| Step: 7
Training loss: 0.0801645815372467
Validation loss: 1.5762920360411368

Epoch: 5| Step: 8
Training loss: 0.08952567726373672
Validation loss: 1.5618036434214602

Epoch: 5| Step: 9
Training loss: 0.137765571475029
Validation loss: 1.5470039152329969

Epoch: 5| Step: 10
Training loss: 0.07911068201065063
Validation loss: 1.5274312214184833

Epoch: 448| Step: 0
Training loss: 0.055553071200847626
Validation loss: 1.537352656805387

Epoch: 5| Step: 1
Training loss: 0.09522004425525665
Validation loss: 1.5242330412710867

Epoch: 5| Step: 2
Training loss: 0.18068258464336395
Validation loss: 1.551885949668064

Epoch: 5| Step: 3
Training loss: 0.1897476613521576
Validation loss: 1.556996504465739

Epoch: 5| Step: 4
Training loss: 0.11154584586620331
Validation loss: 1.5378073953813123

Epoch: 5| Step: 5
Training loss: 0.07891257852315903
Validation loss: 1.527202929860802

Epoch: 5| Step: 6
Training loss: 0.18222172558307648
Validation loss: 1.4772029487035607

Epoch: 5| Step: 7
Training loss: 0.10077546536922455
Validation loss: 1.502135531876677

Epoch: 5| Step: 8
Training loss: 0.12701070308685303
Validation loss: 1.4907353142256379

Epoch: 5| Step: 9
Training loss: 0.11832060664892197
Validation loss: 1.5297276909633348

Epoch: 5| Step: 10
Training loss: 0.13015852868556976
Validation loss: 1.5298027094974314

Epoch: 449| Step: 0
Training loss: 0.1461370438337326
Validation loss: 1.5419552377475205

Epoch: 5| Step: 1
Training loss: 0.11415489763021469
Validation loss: 1.5187816568600234

Epoch: 5| Step: 2
Training loss: 0.11193616688251495
Validation loss: 1.4923086474018712

Epoch: 5| Step: 3
Training loss: 0.1214185357093811
Validation loss: 1.5069008950264222

Epoch: 5| Step: 4
Training loss: 0.0874737799167633
Validation loss: 1.4899858890041229

Epoch: 5| Step: 5
Training loss: 0.21369504928588867
Validation loss: 1.4436194358333465

Epoch: 5| Step: 6
Training loss: 0.11811988055706024
Validation loss: 1.4864096321085447

Epoch: 5| Step: 7
Training loss: 0.06231581047177315
Validation loss: 1.4881878975898988

Epoch: 5| Step: 8
Training loss: 0.12772783637046814
Validation loss: 1.440972108994761

Epoch: 5| Step: 9
Training loss: 0.11720360815525055
Validation loss: 1.4860262947697793

Epoch: 5| Step: 10
Training loss: 0.08052361756563187
Validation loss: 1.4775834070738925

Epoch: 450| Step: 0
Training loss: 0.11144840717315674
Validation loss: 1.454887834928369

Epoch: 5| Step: 1
Training loss: 0.10322161018848419
Validation loss: 1.4732979728329567

Epoch: 5| Step: 2
Training loss: 0.09300891309976578
Validation loss: 1.4952392821670861

Epoch: 5| Step: 3
Training loss: 0.13884052634239197
Validation loss: 1.5070676611315819

Epoch: 5| Step: 4
Training loss: 0.12082157284021378
Validation loss: 1.5053089549464564

Epoch: 5| Step: 5
Training loss: 0.10890273004770279
Validation loss: 1.5008357994018062

Epoch: 5| Step: 6
Training loss: 0.132487490773201
Validation loss: 1.50796797198634

Epoch: 5| Step: 7
Training loss: 0.09834323823451996
Validation loss: 1.5215846107852073

Epoch: 5| Step: 8
Training loss: 0.2309013307094574
Validation loss: 1.526337391586714

Epoch: 5| Step: 9
Training loss: 0.14309599995613098
Validation loss: 1.5315264501879293

Epoch: 5| Step: 10
Training loss: 0.09849423915147781
Validation loss: 1.5141508271617274

Epoch: 451| Step: 0
Training loss: 0.09626725316047668
Validation loss: 1.539863077543115

Epoch: 5| Step: 1
Training loss: 0.13803336024284363
Validation loss: 1.528785326147592

Epoch: 5| Step: 2
Training loss: 0.09023342281579971
Validation loss: 1.5066060725078787

Epoch: 5| Step: 3
Training loss: 0.07912285625934601
Validation loss: 1.475997728686179

Epoch: 5| Step: 4
Training loss: 0.12387808412313461
Validation loss: 1.4940942846318728

Epoch: 5| Step: 5
Training loss: 0.22248753905296326
Validation loss: 1.5265845188530542

Epoch: 5| Step: 6
Training loss: 0.18418961763381958
Validation loss: 1.525145834492099

Epoch: 5| Step: 7
Training loss: 0.09253295511007309
Validation loss: 1.4795666189603909

Epoch: 5| Step: 8
Training loss: 0.08432215452194214
Validation loss: 1.4827360171143726

Epoch: 5| Step: 9
Training loss: 0.10666688531637192
Validation loss: 1.4946637243352912

Epoch: 5| Step: 10
Training loss: 0.08989690989255905
Validation loss: 1.486414764517097

Epoch: 452| Step: 0
Training loss: 0.08786475658416748
Validation loss: 1.4986517942079933

Epoch: 5| Step: 1
Training loss: 0.08200720697641373
Validation loss: 1.4862984720096792

Epoch: 5| Step: 2
Training loss: 0.12230479717254639
Validation loss: 1.530648495561333

Epoch: 5| Step: 3
Training loss: 0.09745224565267563
Validation loss: 1.507506553844739

Epoch: 5| Step: 4
Training loss: 0.15024900436401367
Validation loss: 1.5183946637697117

Epoch: 5| Step: 5
Training loss: 0.15481793880462646
Validation loss: 1.4890528455857308

Epoch: 5| Step: 6
Training loss: 0.09185577183961868
Validation loss: 1.4746386447260458

Epoch: 5| Step: 7
Training loss: 0.10244350135326385
Validation loss: 1.5072528816038562

Epoch: 5| Step: 8
Training loss: 0.1169828325510025
Validation loss: 1.5056714486050349

Epoch: 5| Step: 9
Training loss: 0.1107155904173851
Validation loss: 1.5118419662598641

Epoch: 5| Step: 10
Training loss: 0.21300804615020752
Validation loss: 1.5250631199088147

Epoch: 453| Step: 0
Training loss: 0.07775349915027618
Validation loss: 1.54478661347461

Epoch: 5| Step: 1
Training loss: 0.1883372962474823
Validation loss: 1.5374964244904057

Epoch: 5| Step: 2
Training loss: 0.14513923227787018
Validation loss: 1.5361943091115644

Epoch: 5| Step: 3
Training loss: 0.08577683568000793
Validation loss: 1.5051310664863997

Epoch: 5| Step: 4
Training loss: 0.09711284935474396
Validation loss: 1.5450108602482786

Epoch: 5| Step: 5
Training loss: 0.11303137242794037
Validation loss: 1.537066969179338

Epoch: 5| Step: 6
Training loss: 0.11776532977819443
Validation loss: 1.5282847656998584

Epoch: 5| Step: 7
Training loss: 0.08252622932195663
Validation loss: 1.5085706441633162

Epoch: 5| Step: 8
Training loss: 0.08065368980169296
Validation loss: 1.5024472481460982

Epoch: 5| Step: 9
Training loss: 0.1550993025302887
Validation loss: 1.492413209330651

Epoch: 5| Step: 10
Training loss: 0.0885959342122078
Validation loss: 1.5151885081362981

Epoch: 454| Step: 0
Training loss: 0.08058527857065201
Validation loss: 1.5231115997478526

Epoch: 5| Step: 1
Training loss: 0.15792211890220642
Validation loss: 1.5498438317288634

Epoch: 5| Step: 2
Training loss: 0.11694172769784927
Validation loss: 1.5051577527035949

Epoch: 5| Step: 3
Training loss: 0.09770624339580536
Validation loss: 1.5455496888006888

Epoch: 5| Step: 4
Training loss: 0.08644945174455643
Validation loss: 1.5205986525422783

Epoch: 5| Step: 5
Training loss: 0.1531176120042801
Validation loss: 1.4992929504763695

Epoch: 5| Step: 6
Training loss: 0.10251691192388535
Validation loss: 1.5406393825366933

Epoch: 5| Step: 7
Training loss: 0.1813877820968628
Validation loss: 1.5056238212893087

Epoch: 5| Step: 8
Training loss: 0.08025628328323364
Validation loss: 1.5496637898106729

Epoch: 5| Step: 9
Training loss: 0.11357690393924713
Validation loss: 1.5804938193290465

Epoch: 5| Step: 10
Training loss: 0.09005121886730194
Validation loss: 1.5794561178453508

Epoch: 455| Step: 0
Training loss: 0.10195914655923843
Validation loss: 1.5805389752952002

Epoch: 5| Step: 1
Training loss: 0.08150873333215714
Validation loss: 1.5428346895402478

Epoch: 5| Step: 2
Training loss: 0.09287730604410172
Validation loss: 1.502615051884805

Epoch: 5| Step: 3
Training loss: 0.0752612054347992
Validation loss: 1.534969993816909

Epoch: 5| Step: 4
Training loss: 0.10874523222446442
Validation loss: 1.5347918207927416

Epoch: 5| Step: 5
Training loss: 0.20084314048290253
Validation loss: 1.5119128188779276

Epoch: 5| Step: 6
Training loss: 0.118660107254982
Validation loss: 1.4888413477969427

Epoch: 5| Step: 7
Training loss: 0.14552529156208038
Validation loss: 1.4835159060775593

Epoch: 5| Step: 8
Training loss: 0.1218881607055664
Validation loss: 1.5149286049668507

Epoch: 5| Step: 9
Training loss: 0.067780040204525
Validation loss: 1.5343655181187454

Epoch: 5| Step: 10
Training loss: 0.10650420188903809
Validation loss: 1.5069874691706833

Epoch: 456| Step: 0
Training loss: 0.1025838628411293
Validation loss: 1.56009421425481

Epoch: 5| Step: 1
Training loss: 0.10712222009897232
Validation loss: 1.547850408861714

Epoch: 5| Step: 2
Training loss: 0.12677940726280212
Validation loss: 1.5564883588462748

Epoch: 5| Step: 3
Training loss: 0.18909773230552673
Validation loss: 1.535803287259994

Epoch: 5| Step: 4
Training loss: 0.09706650674343109
Validation loss: 1.5406163238709973

Epoch: 5| Step: 5
Training loss: 0.10531550645828247
Validation loss: 1.5342195431391399

Epoch: 5| Step: 6
Training loss: 0.11218615621328354
Validation loss: 1.5350863779744794

Epoch: 5| Step: 7
Training loss: 0.06725934147834778
Validation loss: 1.5437587679073375

Epoch: 5| Step: 8
Training loss: 0.10889671742916107
Validation loss: 1.5645271449960687

Epoch: 5| Step: 9
Training loss: 0.17376454174518585
Validation loss: 1.5357104565507622

Epoch: 5| Step: 10
Training loss: 0.11209423094987869
Validation loss: 1.5301650083193215

Epoch: 457| Step: 0
Training loss: 0.08285505324602127
Validation loss: 1.5206462978034891

Epoch: 5| Step: 1
Training loss: 0.12063517421483994
Validation loss: 1.5160923414332892

Epoch: 5| Step: 2
Training loss: 0.17977243661880493
Validation loss: 1.512855084993506

Epoch: 5| Step: 3
Training loss: 0.07292371988296509
Validation loss: 1.5012143029961535

Epoch: 5| Step: 4
Training loss: 0.08526702970266342
Validation loss: 1.4521210808907785

Epoch: 5| Step: 5
Training loss: 0.09201810508966446
Validation loss: 1.483316348445031

Epoch: 5| Step: 6
Training loss: 0.061141692101955414
Validation loss: 1.4873425217084988

Epoch: 5| Step: 7
Training loss: 0.11291928589344025
Validation loss: 1.4812425028893255

Epoch: 5| Step: 8
Training loss: 0.09191125631332397
Validation loss: 1.4870897698146042

Epoch: 5| Step: 9
Training loss: 0.11991526186466217
Validation loss: 1.4740215962932957

Epoch: 5| Step: 10
Training loss: 0.16490046679973602
Validation loss: 1.4812673330307007

Epoch: 458| Step: 0
Training loss: 0.09991228580474854
Validation loss: 1.478494680056008

Epoch: 5| Step: 1
Training loss: 0.05265520140528679
Validation loss: 1.4780648626307005

Epoch: 5| Step: 2
Training loss: 0.09324415028095245
Validation loss: 1.5432844392714962

Epoch: 5| Step: 3
Training loss: 0.07243514060974121
Validation loss: 1.5486695689539756

Epoch: 5| Step: 4
Training loss: 0.0935240164399147
Validation loss: 1.5578414650373562

Epoch: 5| Step: 5
Training loss: 0.10943058878183365
Validation loss: 1.5447203267005183

Epoch: 5| Step: 6
Training loss: 0.1305592954158783
Validation loss: 1.546167500557438

Epoch: 5| Step: 7
Training loss: 0.218189999461174
Validation loss: 1.5443006484739241

Epoch: 5| Step: 8
Training loss: 0.113865926861763
Validation loss: 1.5105792694194342

Epoch: 5| Step: 9
Training loss: 0.06802406907081604
Validation loss: 1.5187356882197882

Epoch: 5| Step: 10
Training loss: 0.08669295161962509
Validation loss: 1.481351702444015

Epoch: 459| Step: 0
Training loss: 0.0678299218416214
Validation loss: 1.4839623987033803

Epoch: 5| Step: 1
Training loss: 0.10487780719995499
Validation loss: 1.492895544216197

Epoch: 5| Step: 2
Training loss: 0.10388138145208359
Validation loss: 1.4902192187565628

Epoch: 5| Step: 3
Training loss: 0.07345811277627945
Validation loss: 1.4981634040032663

Epoch: 5| Step: 4
Training loss: 0.10053201019763947
Validation loss: 1.505329978081488

Epoch: 5| Step: 5
Training loss: 0.07992292195558548
Validation loss: 1.485937512049111

Epoch: 5| Step: 6
Training loss: 0.23188230395317078
Validation loss: 1.5335441981592486

Epoch: 5| Step: 7
Training loss: 0.10143314301967621
Validation loss: 1.4952073597138928

Epoch: 5| Step: 8
Training loss: 0.08229805529117584
Validation loss: 1.5172875824794974

Epoch: 5| Step: 9
Training loss: 0.12308084964752197
Validation loss: 1.5275952316099597

Epoch: 5| Step: 10
Training loss: 0.06147157400846481
Validation loss: 1.5080779662696264

Epoch: 460| Step: 0
Training loss: 0.06581757962703705
Validation loss: 1.5145560592733405

Epoch: 5| Step: 1
Training loss: 0.06884665042161942
Validation loss: 1.5209467141858992

Epoch: 5| Step: 2
Training loss: 0.07745778560638428
Validation loss: 1.5068336289416078

Epoch: 5| Step: 3
Training loss: 0.12837131321430206
Validation loss: 1.5457112289244128

Epoch: 5| Step: 4
Training loss: 0.16739051043987274
Validation loss: 1.5131385281521788

Epoch: 5| Step: 5
Training loss: 0.1932838261127472
Validation loss: 1.5127038853142851

Epoch: 5| Step: 6
Training loss: 0.1031045913696289
Validation loss: 1.4961453599314536

Epoch: 5| Step: 7
Training loss: 0.09487475454807281
Validation loss: 1.5121821921358827

Epoch: 5| Step: 8
Training loss: 0.1276055872440338
Validation loss: 1.504156727944651

Epoch: 5| Step: 9
Training loss: 0.07178682833909988
Validation loss: 1.5023435738778883

Epoch: 5| Step: 10
Training loss: 0.061626825481653214
Validation loss: 1.5215326791168542

Epoch: 461| Step: 0
Training loss: 0.06573629379272461
Validation loss: 1.518420010484675

Epoch: 5| Step: 1
Training loss: 0.10785945504903793
Validation loss: 1.5551064501526535

Epoch: 5| Step: 2
Training loss: 0.08606087416410446
Validation loss: 1.5474659460847096

Epoch: 5| Step: 3
Training loss: 0.09845127910375595
Validation loss: 1.5339027989295222

Epoch: 5| Step: 4
Training loss: 0.0901937261223793
Validation loss: 1.5429742746455695

Epoch: 5| Step: 5
Training loss: 0.081398144364357
Validation loss: 1.5394542371073077

Epoch: 5| Step: 6
Training loss: 0.10953755676746368
Validation loss: 1.5346611174204017

Epoch: 5| Step: 7
Training loss: 0.1346842646598816
Validation loss: 1.5244351279351018

Epoch: 5| Step: 8
Training loss: 0.09424541890621185
Validation loss: 1.5391779894469886

Epoch: 5| Step: 9
Training loss: 0.17840702831745148
Validation loss: 1.5231504863308323

Epoch: 5| Step: 10
Training loss: 0.11390472203493118
Validation loss: 1.4963489732434672

Epoch: 462| Step: 0
Training loss: 0.07349434494972229
Validation loss: 1.494500034598894

Epoch: 5| Step: 1
Training loss: 0.10372237861156464
Validation loss: 1.526624705201836

Epoch: 5| Step: 2
Training loss: 0.09821741282939911
Validation loss: 1.493963785068963

Epoch: 5| Step: 3
Training loss: 0.10927796363830566
Validation loss: 1.485877412621693

Epoch: 5| Step: 4
Training loss: 0.08931173384189606
Validation loss: 1.4818541772903935

Epoch: 5| Step: 5
Training loss: 0.06129201129078865
Validation loss: 1.4936261753882132

Epoch: 5| Step: 6
Training loss: 0.0725364089012146
Validation loss: 1.5126515972998835

Epoch: 5| Step: 7
Training loss: 0.1917324811220169
Validation loss: 1.4977376243119598

Epoch: 5| Step: 8
Training loss: 0.11883672326803207
Validation loss: 1.513106660176349

Epoch: 5| Step: 9
Training loss: 0.07640998065471649
Validation loss: 1.505001155279016

Epoch: 5| Step: 10
Training loss: 0.08442985266447067
Validation loss: 1.5034729755052956

Epoch: 463| Step: 0
Training loss: 0.0964488536119461
Validation loss: 1.5249299874869726

Epoch: 5| Step: 1
Training loss: 0.05238109081983566
Validation loss: 1.5180799294543523

Epoch: 5| Step: 2
Training loss: 0.18492934107780457
Validation loss: 1.5164972184806742

Epoch: 5| Step: 3
Training loss: 0.10266349464654922
Validation loss: 1.5470857222874959

Epoch: 5| Step: 4
Training loss: 0.1530415266752243
Validation loss: 1.5082409830503567

Epoch: 5| Step: 5
Training loss: 0.1064915657043457
Validation loss: 1.5108614044804727

Epoch: 5| Step: 6
Training loss: 0.07794225215911865
Validation loss: 1.5396359582101145

Epoch: 5| Step: 7
Training loss: 0.07210974395275116
Validation loss: 1.5332652407307779

Epoch: 5| Step: 8
Training loss: 0.15047958493232727
Validation loss: 1.5721621615912325

Epoch: 5| Step: 9
Training loss: 0.10170567035675049
Validation loss: 1.5888227301259195

Epoch: 5| Step: 10
Training loss: 0.11794954538345337
Validation loss: 1.5581475944929226

Epoch: 464| Step: 0
Training loss: 0.2030472755432129
Validation loss: 1.5492879908571962

Epoch: 5| Step: 1
Training loss: 0.057399503886699677
Validation loss: 1.523461716149443

Epoch: 5| Step: 2
Training loss: 0.0824698656797409
Validation loss: 1.538469672203064

Epoch: 5| Step: 3
Training loss: 0.09203797578811646
Validation loss: 1.5293202938572052

Epoch: 5| Step: 4
Training loss: 0.10745032131671906
Validation loss: 1.4883744614098662

Epoch: 5| Step: 5
Training loss: 0.12276814132928848
Validation loss: 1.5127120594824515

Epoch: 5| Step: 6
Training loss: 0.09375359117984772
Validation loss: 1.5071007461958035

Epoch: 5| Step: 7
Training loss: 0.09963221848011017
Validation loss: 1.5217930142597487

Epoch: 5| Step: 8
Training loss: 0.09227751195430756
Validation loss: 1.4808909675126434

Epoch: 5| Step: 9
Training loss: 0.11203376203775406
Validation loss: 1.533047829904864

Epoch: 5| Step: 10
Training loss: 0.10917942970991135
Validation loss: 1.4704409299358245

Epoch: 465| Step: 0
Training loss: 0.09637635201215744
Validation loss: 1.4806967717345043

Epoch: 5| Step: 1
Training loss: 0.12029256671667099
Validation loss: 1.5051790911664245

Epoch: 5| Step: 2
Training loss: 0.08052416145801544
Validation loss: 1.4813647577839513

Epoch: 5| Step: 3
Training loss: 0.09820142388343811
Validation loss: 1.49189918656503

Epoch: 5| Step: 4
Training loss: 0.15628941357135773
Validation loss: 1.5355077059038225

Epoch: 5| Step: 5
Training loss: 0.2386844903230667
Validation loss: 1.5205241480181295

Epoch: 5| Step: 6
Training loss: 0.10199781507253647
Validation loss: 1.5080505519784906

Epoch: 5| Step: 7
Training loss: 0.12613126635551453
Validation loss: 1.5205053565322713

Epoch: 5| Step: 8
Training loss: 0.07120707631111145
Validation loss: 1.498682878350699

Epoch: 5| Step: 9
Training loss: 0.08347586542367935
Validation loss: 1.4937436311475691

Epoch: 5| Step: 10
Training loss: 0.13984787464141846
Validation loss: 1.5258340540752615

Epoch: 466| Step: 0
Training loss: 0.15050221979618073
Validation loss: 1.506622245234828

Epoch: 5| Step: 1
Training loss: 0.15605409443378448
Validation loss: 1.5112316531519736

Epoch: 5| Step: 2
Training loss: 0.11323799937963486
Validation loss: 1.5241384506225586

Epoch: 5| Step: 3
Training loss: 0.13092878460884094
Validation loss: 1.5069458228285595

Epoch: 5| Step: 4
Training loss: 0.2616710066795349
Validation loss: 1.4971802196195048

Epoch: 5| Step: 5
Training loss: 0.08278100192546844
Validation loss: 1.518790610374943

Epoch: 5| Step: 6
Training loss: 0.07473140954971313
Validation loss: 1.5179965944700344

Epoch: 5| Step: 7
Training loss: 0.0919901579618454
Validation loss: 1.5405497204872869

Epoch: 5| Step: 8
Training loss: 0.11743389070034027
Validation loss: 1.5397859478509555

Epoch: 5| Step: 9
Training loss: 0.07336671650409698
Validation loss: 1.5223209934849893

Epoch: 5| Step: 10
Training loss: 0.06781885772943497
Validation loss: 1.4931138446254115

Epoch: 467| Step: 0
Training loss: 0.14288823306560516
Validation loss: 1.489869713142354

Epoch: 5| Step: 1
Training loss: 0.09588433802127838
Validation loss: 1.4625497607774631

Epoch: 5| Step: 2
Training loss: 0.1301668882369995
Validation loss: 1.4801146830281904

Epoch: 5| Step: 3
Training loss: 0.09946532547473907
Validation loss: 1.4973868375183434

Epoch: 5| Step: 4
Training loss: 0.08266445249319077
Validation loss: 1.5071447344236477

Epoch: 5| Step: 5
Training loss: 0.12101934105157852
Validation loss: 1.5207220559479089

Epoch: 5| Step: 6
Training loss: 0.10261745750904083
Validation loss: 1.53251471442561

Epoch: 5| Step: 7
Training loss: 0.10736110061407089
Validation loss: 1.5590183683620986

Epoch: 5| Step: 8
Training loss: 0.08720433712005615
Validation loss: 1.5521258115768433

Epoch: 5| Step: 9
Training loss: 0.22051115334033966
Validation loss: 1.5547173894861692

Epoch: 5| Step: 10
Training loss: 0.10798385739326477
Validation loss: 1.5449333985646565

Epoch: 468| Step: 0
Training loss: 0.13695701956748962
Validation loss: 1.5532571308074459

Epoch: 5| Step: 1
Training loss: 0.1399880051612854
Validation loss: 1.4766789713213522

Epoch: 5| Step: 2
Training loss: 0.07798534631729126
Validation loss: 1.4495104025768977

Epoch: 5| Step: 3
Training loss: 0.14961044490337372
Validation loss: 1.4048958427162581

Epoch: 5| Step: 4
Training loss: 0.19946661591529846
Validation loss: 1.4180622280284922

Epoch: 5| Step: 5
Training loss: 0.1774328500032425
Validation loss: 1.3990301291147869

Epoch: 5| Step: 6
Training loss: 0.13640788197517395
Validation loss: 1.4251444339752197

Epoch: 5| Step: 7
Training loss: 0.1314917802810669
Validation loss: 1.4338260850598734

Epoch: 5| Step: 8
Training loss: 0.09540949761867523
Validation loss: 1.4486877751606766

Epoch: 5| Step: 9
Training loss: 0.21977272629737854
Validation loss: 1.4592313176842147

Epoch: 5| Step: 10
Training loss: 0.07684996724128723
Validation loss: 1.44868294782536

Epoch: 469| Step: 0
Training loss: 0.09787873178720474
Validation loss: 1.448446531449595

Epoch: 5| Step: 1
Training loss: 0.07732702791690826
Validation loss: 1.4784283779000724

Epoch: 5| Step: 2
Training loss: 0.11689631640911102
Validation loss: 1.4613974632755402

Epoch: 5| Step: 3
Training loss: 0.23809079825878143
Validation loss: 1.4732960167751517

Epoch: 5| Step: 4
Training loss: 0.0763736218214035
Validation loss: 1.4920336847664208

Epoch: 5| Step: 5
Training loss: 0.11911825835704803
Validation loss: 1.4853073781536472

Epoch: 5| Step: 6
Training loss: 0.11554823070764542
Validation loss: 1.4739502309471049

Epoch: 5| Step: 7
Training loss: 0.13702616095542908
Validation loss: 1.4698285947563827

Epoch: 5| Step: 8
Training loss: 0.10501866042613983
Validation loss: 1.4132106188804872

Epoch: 5| Step: 9
Training loss: 0.12125711143016815
Validation loss: 1.4259059576578037

Epoch: 5| Step: 10
Training loss: 0.10530108213424683
Validation loss: 1.4479548533757527

Epoch: 470| Step: 0
Training loss: 0.1407305747270584
Validation loss: 1.438669623867158

Epoch: 5| Step: 1
Training loss: 0.07777351886034012
Validation loss: 1.4357787075863089

Epoch: 5| Step: 2
Training loss: 0.08907538652420044
Validation loss: 1.4850263185398553

Epoch: 5| Step: 3
Training loss: 0.0895984023809433
Validation loss: 1.4410232920800485

Epoch: 5| Step: 4
Training loss: 0.05565686151385307
Validation loss: 1.4888016004716196

Epoch: 5| Step: 5
Training loss: 0.11731972545385361
Validation loss: 1.5039163597168461

Epoch: 5| Step: 6
Training loss: 0.09134194999933243
Validation loss: 1.5299576597829019

Epoch: 5| Step: 7
Training loss: 0.1151890754699707
Validation loss: 1.521536789914613

Epoch: 5| Step: 8
Training loss: 0.22976665198802948
Validation loss: 1.5108596240320513

Epoch: 5| Step: 9
Training loss: 0.11968717724084854
Validation loss: 1.5504262152538504

Epoch: 5| Step: 10
Training loss: 0.1645316779613495
Validation loss: 1.5316078457781064

Epoch: 471| Step: 0
Training loss: 0.0855356827378273
Validation loss: 1.5279792252407278

Epoch: 5| Step: 1
Training loss: 0.0645628422498703
Validation loss: 1.5114141574469946

Epoch: 5| Step: 2
Training loss: 0.08170098811388016
Validation loss: 1.4693616180009739

Epoch: 5| Step: 3
Training loss: 0.22338683903217316
Validation loss: 1.4541569063740392

Epoch: 5| Step: 4
Training loss: 0.09357313066720963
Validation loss: 1.4357830298844205

Epoch: 5| Step: 5
Training loss: 0.13804981112480164
Validation loss: 1.433087016946526

Epoch: 5| Step: 6
Training loss: 0.08296659588813782
Validation loss: 1.4763632673089222

Epoch: 5| Step: 7
Training loss: 0.12306322902441025
Validation loss: 1.4676524310983636

Epoch: 5| Step: 8
Training loss: 0.08754194527864456
Validation loss: 1.4637074688429474

Epoch: 5| Step: 9
Training loss: 0.10684683173894882
Validation loss: 1.5046224735116447

Epoch: 5| Step: 10
Training loss: 0.09398257732391357
Validation loss: 1.521754531450169

Epoch: 472| Step: 0
Training loss: 0.09680891036987305
Validation loss: 1.5269101563320364

Epoch: 5| Step: 1
Training loss: 0.1933133602142334
Validation loss: 1.5265370267693714

Epoch: 5| Step: 2
Training loss: 0.05250055715441704
Validation loss: 1.5139776981005104

Epoch: 5| Step: 3
Training loss: 0.1512060910463333
Validation loss: 1.5738629564162223

Epoch: 5| Step: 4
Training loss: 0.10677085071802139
Validation loss: 1.5641363782267417

Epoch: 5| Step: 5
Training loss: 0.13007722795009613
Validation loss: 1.53695821954358

Epoch: 5| Step: 6
Training loss: 0.07757055014371872
Validation loss: 1.5448485907687937

Epoch: 5| Step: 7
Training loss: 0.048787690699100494
Validation loss: 1.5067846416145243

Epoch: 5| Step: 8
Training loss: 0.07833906263113022
Validation loss: 1.4877807683842157

Epoch: 5| Step: 9
Training loss: 0.11666449159383774
Validation loss: 1.4873111324925576

Epoch: 5| Step: 10
Training loss: 0.21782487630844116
Validation loss: 1.4767719686672252

Epoch: 473| Step: 0
Training loss: 0.11499392986297607
Validation loss: 1.496752929943864

Epoch: 5| Step: 1
Training loss: 0.10532112419605255
Validation loss: 1.4633581484517744

Epoch: 5| Step: 2
Training loss: 0.06498265266418457
Validation loss: 1.4835330568334109

Epoch: 5| Step: 3
Training loss: 0.11461331695318222
Validation loss: 1.501381665147761

Epoch: 5| Step: 4
Training loss: 0.10394151508808136
Validation loss: 1.4920085886473298

Epoch: 5| Step: 5
Training loss: 0.10308686643838882
Validation loss: 1.4577928371326898

Epoch: 5| Step: 6
Training loss: 0.08637143671512604
Validation loss: 1.5174639276278916

Epoch: 5| Step: 7
Training loss: 0.2452435940504074
Validation loss: 1.5320700310891675

Epoch: 5| Step: 8
Training loss: 0.11284531652927399
Validation loss: 1.489204825252615

Epoch: 5| Step: 9
Training loss: 0.0944487676024437
Validation loss: 1.5052593126091907

Epoch: 5| Step: 10
Training loss: 0.0585775226354599
Validation loss: 1.493935925986177

Epoch: 474| Step: 0
Training loss: 0.05223260074853897
Validation loss: 1.4710993971875919

Epoch: 5| Step: 1
Training loss: 0.08279742300510406
Validation loss: 1.530718759823871

Epoch: 5| Step: 2
Training loss: 0.07351157069206238
Validation loss: 1.5025896603061306

Epoch: 5| Step: 3
Training loss: 0.13133938610553741
Validation loss: 1.5254351746651433

Epoch: 5| Step: 4
Training loss: 0.08997674286365509
Validation loss: 1.5085291375396073

Epoch: 5| Step: 5
Training loss: 0.07780246436595917
Validation loss: 1.4721642899256882

Epoch: 5| Step: 6
Training loss: 0.10207177698612213
Validation loss: 1.5004072650786369

Epoch: 5| Step: 7
Training loss: 0.12569613754749298
Validation loss: 1.5037075575961862

Epoch: 5| Step: 8
Training loss: 0.08484892547130585
Validation loss: 1.4961662664208362

Epoch: 5| Step: 9
Training loss: 0.09017534554004669
Validation loss: 1.4917279161432737

Epoch: 5| Step: 10
Training loss: 0.1857673078775406
Validation loss: 1.4986945967520438

Epoch: 475| Step: 0
Training loss: 0.1032315269112587
Validation loss: 1.5298275140024

Epoch: 5| Step: 1
Training loss: 0.20548799633979797
Validation loss: 1.522071728142359

Epoch: 5| Step: 2
Training loss: 0.09455308318138123
Validation loss: 1.514191524956816

Epoch: 5| Step: 3
Training loss: 0.08409176021814346
Validation loss: 1.514749861532642

Epoch: 5| Step: 4
Training loss: 0.08622142672538757
Validation loss: 1.5216046917823054

Epoch: 5| Step: 5
Training loss: 0.06290938705205917
Validation loss: 1.463772209741736

Epoch: 5| Step: 6
Training loss: 0.11004622280597687
Validation loss: 1.4509780035224011

Epoch: 5| Step: 7
Training loss: 0.10476698726415634
Validation loss: 1.4741305035929526

Epoch: 5| Step: 8
Training loss: 0.13133928179740906
Validation loss: 1.4948763706350838

Epoch: 5| Step: 9
Training loss: 0.08719061315059662
Validation loss: 1.4648401403939852

Epoch: 5| Step: 10
Training loss: 0.08841758966445923
Validation loss: 1.4640704598478091

Epoch: 476| Step: 0
Training loss: 0.18399815261363983
Validation loss: 1.4694908395890267

Epoch: 5| Step: 1
Training loss: 0.13301317393779755
Validation loss: 1.4634658187948248

Epoch: 5| Step: 2
Training loss: 0.09789873659610748
Validation loss: 1.4896825103349582

Epoch: 5| Step: 3
Training loss: 0.059089530259370804
Validation loss: 1.4554208517074585

Epoch: 5| Step: 4
Training loss: 0.10170452296733856
Validation loss: 1.4966366598683019

Epoch: 5| Step: 5
Training loss: 0.11550712585449219
Validation loss: 1.4858212676099551

Epoch: 5| Step: 6
Training loss: 0.12375948578119278
Validation loss: 1.5236480960281946

Epoch: 5| Step: 7
Training loss: 0.11408668756484985
Validation loss: 1.535126910414747

Epoch: 5| Step: 8
Training loss: 0.08427351713180542
Validation loss: 1.5090428462592504

Epoch: 5| Step: 9
Training loss: 0.06596752256155014
Validation loss: 1.5362913095822899

Epoch: 5| Step: 10
Training loss: 0.07452696561813354
Validation loss: 1.494644106075328

Epoch: 477| Step: 0
Training loss: 0.08582477271556854
Validation loss: 1.518872441784028

Epoch: 5| Step: 1
Training loss: 0.05889498069882393
Validation loss: 1.5036265965430968

Epoch: 5| Step: 2
Training loss: 0.08946062624454498
Validation loss: 1.4548263498531875

Epoch: 5| Step: 3
Training loss: 0.08323057740926743
Validation loss: 1.4714590554596276

Epoch: 5| Step: 4
Training loss: 0.16804631054401398
Validation loss: 1.4493741123907027

Epoch: 5| Step: 5
Training loss: 0.15079444646835327
Validation loss: 1.467411498869619

Epoch: 5| Step: 6
Training loss: 0.056991733610630035
Validation loss: 1.4568539204136017

Epoch: 5| Step: 7
Training loss: 0.1417723447084427
Validation loss: 1.4677330037598968

Epoch: 5| Step: 8
Training loss: 0.0925479307770729
Validation loss: 1.511501367374133

Epoch: 5| Step: 9
Training loss: 0.09254332631826401
Validation loss: 1.475786397534032

Epoch: 5| Step: 10
Training loss: 0.1908659189939499
Validation loss: 1.5336042334956508

Epoch: 478| Step: 0
Training loss: 0.07457886636257172
Validation loss: 1.5300061754001084

Epoch: 5| Step: 1
Training loss: 0.11505398899316788
Validation loss: 1.5700461544016355

Epoch: 5| Step: 2
Training loss: 0.22761264443397522
Validation loss: 1.5587795396004953

Epoch: 5| Step: 3
Training loss: 0.11821675300598145
Validation loss: 1.5534506177389493

Epoch: 5| Step: 4
Training loss: 0.08614891022443771
Validation loss: 1.5700296509650447

Epoch: 5| Step: 5
Training loss: 0.0925336703658104
Validation loss: 1.5226268896492579

Epoch: 5| Step: 6
Training loss: 0.11706371605396271
Validation loss: 1.4936600423628283

Epoch: 5| Step: 7
Training loss: 0.10701236873865128
Validation loss: 1.4976921376361643

Epoch: 5| Step: 8
Training loss: 0.11927028745412827
Validation loss: 1.4799975951512654

Epoch: 5| Step: 9
Training loss: 0.12199197709560394
Validation loss: 1.434528886630971

Epoch: 5| Step: 10
Training loss: 0.14818528294563293
Validation loss: 1.4857450710829867

Epoch: 479| Step: 0
Training loss: 0.10024379193782806
Validation loss: 1.4501402942083215

Epoch: 5| Step: 1
Training loss: 0.12059459835290909
Validation loss: 1.4492096221575173

Epoch: 5| Step: 2
Training loss: 0.04617846757173538
Validation loss: 1.4719347114204078

Epoch: 5| Step: 3
Training loss: 0.10129012912511826
Validation loss: 1.4915404435127013

Epoch: 5| Step: 4
Training loss: 0.10121651738882065
Validation loss: 1.5157645786962202

Epoch: 5| Step: 5
Training loss: 0.09836474061012268
Validation loss: 1.5562532794091009

Epoch: 5| Step: 6
Training loss: 0.09090468287467957
Validation loss: 1.5743693561964138

Epoch: 5| Step: 7
Training loss: 0.19821122288703918
Validation loss: 1.5794989370530652

Epoch: 5| Step: 8
Training loss: 0.08672774583101273
Validation loss: 1.5375086671562606

Epoch: 5| Step: 9
Training loss: 0.08923516422510147
Validation loss: 1.5472372437036166

Epoch: 5| Step: 10
Training loss: 0.10025344043970108
Validation loss: 1.5557664209796536

Epoch: 480| Step: 0
Training loss: 0.07715360820293427
Validation loss: 1.5500694474866312

Epoch: 5| Step: 1
Training loss: 0.06328843533992767
Validation loss: 1.4947178594527706

Epoch: 5| Step: 2
Training loss: 0.11099262535572052
Validation loss: 1.4939981929717525

Epoch: 5| Step: 3
Training loss: 0.1070457473397255
Validation loss: 1.4648194518140567

Epoch: 5| Step: 4
Training loss: 0.09360351413488388
Validation loss: 1.4818428152350969

Epoch: 5| Step: 5
Training loss: 0.154983252286911
Validation loss: 1.4598485551854616

Epoch: 5| Step: 6
Training loss: 0.11868925392627716
Validation loss: 1.473850413035321

Epoch: 5| Step: 7
Training loss: 0.12315718084573746
Validation loss: 1.5052671137676443

Epoch: 5| Step: 8
Training loss: 0.10823361575603485
Validation loss: 1.5013552916947233

Epoch: 5| Step: 9
Training loss: 0.09892910718917847
Validation loss: 1.51138134156504

Epoch: 5| Step: 10
Training loss: 0.07950439304113388
Validation loss: 1.5351836886457217

Epoch: 481| Step: 0
Training loss: 0.27310723066329956
Validation loss: 1.5381440988150976

Epoch: 5| Step: 1
Training loss: 0.10167224705219269
Validation loss: 1.5475489913776357

Epoch: 5| Step: 2
Training loss: 0.08986331522464752
Validation loss: 1.5401221308656918

Epoch: 5| Step: 3
Training loss: 0.12179724872112274
Validation loss: 1.527457925581163

Epoch: 5| Step: 4
Training loss: 0.09947752952575684
Validation loss: 1.564980701733661

Epoch: 5| Step: 5
Training loss: 0.10273358970880508
Validation loss: 1.564909678633495

Epoch: 5| Step: 6
Training loss: 0.08497428894042969
Validation loss: 1.5238517368993452

Epoch: 5| Step: 7
Training loss: 0.11974632740020752
Validation loss: 1.5325498119477303

Epoch: 5| Step: 8
Training loss: 0.09263554960489273
Validation loss: 1.4924530700970722

Epoch: 5| Step: 9
Training loss: 0.1016886830329895
Validation loss: 1.5055836426314486

Epoch: 5| Step: 10
Training loss: 0.0531889870762825
Validation loss: 1.5017224396428754

Epoch: 482| Step: 0
Training loss: 0.05645621940493584
Validation loss: 1.5149854870252712

Epoch: 5| Step: 1
Training loss: 0.06274092942476273
Validation loss: 1.518840596240054

Epoch: 5| Step: 2
Training loss: 0.12120924144983292
Validation loss: 1.542421603715548

Epoch: 5| Step: 3
Training loss: 0.07659956812858582
Validation loss: 1.5426210908479587

Epoch: 5| Step: 4
Training loss: 0.11550672352313995
Validation loss: 1.5435890228517595

Epoch: 5| Step: 5
Training loss: 0.1457679271697998
Validation loss: 1.5560736630552559

Epoch: 5| Step: 6
Training loss: 0.07812932133674622
Validation loss: 1.5510958266514603

Epoch: 5| Step: 7
Training loss: 0.10748811066150665
Validation loss: 1.5761307247223393

Epoch: 5| Step: 8
Training loss: 0.22776365280151367
Validation loss: 1.547648883634998

Epoch: 5| Step: 9
Training loss: 0.10049746185541153
Validation loss: 1.5953124505217358

Epoch: 5| Step: 10
Training loss: 0.1489517241716385
Validation loss: 1.5517036978916456

Epoch: 483| Step: 0
Training loss: 0.22886185348033905
Validation loss: 1.5406753119602

Epoch: 5| Step: 1
Training loss: 0.10738897323608398
Validation loss: 1.5470335073368524

Epoch: 5| Step: 2
Training loss: 0.06021355465054512
Validation loss: 1.5861524010217318

Epoch: 5| Step: 3
Training loss: 0.10747289657592773
Validation loss: 1.5621736203470538

Epoch: 5| Step: 4
Training loss: 0.08203716576099396
Validation loss: 1.5617677409161803

Epoch: 5| Step: 5
Training loss: 0.08282368630170822
Validation loss: 1.5745410778189217

Epoch: 5| Step: 6
Training loss: 0.09976927191019058
Validation loss: 1.5202487470001302

Epoch: 5| Step: 7
Training loss: 0.07009367644786835
Validation loss: 1.5231932875930623

Epoch: 5| Step: 8
Training loss: 0.08524803072214127
Validation loss: 1.5221779551557315

Epoch: 5| Step: 9
Training loss: 0.09694640338420868
Validation loss: 1.5426768359317575

Epoch: 5| Step: 10
Training loss: 0.11928757280111313
Validation loss: 1.5391318118700417

Epoch: 484| Step: 0
Training loss: 0.08867809921503067
Validation loss: 1.5263760897421068

Epoch: 5| Step: 1
Training loss: 0.08285795897245407
Validation loss: 1.540894817280513

Epoch: 5| Step: 2
Training loss: 0.06504344940185547
Validation loss: 1.5637784324666506

Epoch: 5| Step: 3
Training loss: 0.1308688223361969
Validation loss: 1.5516940278391684

Epoch: 5| Step: 4
Training loss: 0.08148252218961716
Validation loss: 1.5791536454231507

Epoch: 5| Step: 5
Training loss: 0.07368762791156769
Validation loss: 1.5268223580493723

Epoch: 5| Step: 6
Training loss: 0.06956242024898529
Validation loss: 1.5344779106878466

Epoch: 5| Step: 7
Training loss: 0.06515928357839584
Validation loss: 1.4913577623264764

Epoch: 5| Step: 8
Training loss: 0.17261233925819397
Validation loss: 1.491745646281909

Epoch: 5| Step: 9
Training loss: 0.07210426032543182
Validation loss: 1.5034176598313034

Epoch: 5| Step: 10
Training loss: 0.12587948143482208
Validation loss: 1.4779592303819553

Epoch: 485| Step: 0
Training loss: 0.1092018336057663
Validation loss: 1.5058829989484561

Epoch: 5| Step: 1
Training loss: 0.06370113044977188
Validation loss: 1.5417709658222813

Epoch: 5| Step: 2
Training loss: 0.11152388155460358
Validation loss: 1.5041965553837437

Epoch: 5| Step: 3
Training loss: 0.061220426112413406
Validation loss: 1.526298152503147

Epoch: 5| Step: 4
Training loss: 0.11496078968048096
Validation loss: 1.5325122123123498

Epoch: 5| Step: 5
Training loss: 0.09033436328172684
Validation loss: 1.5842770043239798

Epoch: 5| Step: 6
Training loss: 0.10902967303991318
Validation loss: 1.585056471568282

Epoch: 5| Step: 7
Training loss: 0.12440948188304901
Validation loss: 1.5514236816795923

Epoch: 5| Step: 8
Training loss: 0.18738257884979248
Validation loss: 1.5365915016461444

Epoch: 5| Step: 9
Training loss: 0.09105551242828369
Validation loss: 1.5265502980960313

Epoch: 5| Step: 10
Training loss: 0.15029123425483704
Validation loss: 1.530237929795378

Epoch: 486| Step: 0
Training loss: 0.10113541781902313
Validation loss: 1.5186655572665635

Epoch: 5| Step: 1
Training loss: 0.09155839681625366
Validation loss: 1.5187011944350375

Epoch: 5| Step: 2
Training loss: 0.18652474880218506
Validation loss: 1.5060020416013655

Epoch: 5| Step: 3
Training loss: 0.07556873559951782
Validation loss: 1.5048649195701844

Epoch: 5| Step: 4
Training loss: 0.0553579218685627
Validation loss: 1.4971537705390685

Epoch: 5| Step: 5
Training loss: 0.14614048600196838
Validation loss: 1.4722696171011975

Epoch: 5| Step: 6
Training loss: 0.09024056792259216
Validation loss: 1.520820060083943

Epoch: 5| Step: 7
Training loss: 0.1204758882522583
Validation loss: 1.5404771047253762

Epoch: 5| Step: 8
Training loss: 0.07506541907787323
Validation loss: 1.4833561707568426

Epoch: 5| Step: 9
Training loss: 0.07104859501123428
Validation loss: 1.5077735236895982

Epoch: 5| Step: 10
Training loss: 0.08682936429977417
Validation loss: 1.5361916839435537

Epoch: 487| Step: 0
Training loss: 0.06841730326414108
Validation loss: 1.554447732945924

Epoch: 5| Step: 1
Training loss: 0.19954581558704376
Validation loss: 1.5788808714958928

Epoch: 5| Step: 2
Training loss: 0.0669446513056755
Validation loss: 1.5813209408073015

Epoch: 5| Step: 3
Training loss: 0.09735158830881119
Validation loss: 1.5581204404113114

Epoch: 5| Step: 4
Training loss: 0.12310197204351425
Validation loss: 1.573620080947876

Epoch: 5| Step: 5
Training loss: 0.10021207481622696
Validation loss: 1.5650301979434105

Epoch: 5| Step: 6
Training loss: 0.1181594505906105
Validation loss: 1.5776696256411973

Epoch: 5| Step: 7
Training loss: 0.0721617192029953
Validation loss: 1.5926784456417125

Epoch: 5| Step: 8
Training loss: 0.09035839140415192
Validation loss: 1.511749070177796

Epoch: 5| Step: 9
Training loss: 0.09246020019054413
Validation loss: 1.5185561705661077

Epoch: 5| Step: 10
Training loss: 0.0741785392165184
Validation loss: 1.4745513995488484

Epoch: 488| Step: 0
Training loss: 0.09670078009366989
Validation loss: 1.4892045887567664

Epoch: 5| Step: 1
Training loss: 0.12263782322406769
Validation loss: 1.5001065897685226

Epoch: 5| Step: 2
Training loss: 0.12330882251262665
Validation loss: 1.4898980022758566

Epoch: 5| Step: 3
Training loss: 0.08934032171964645
Validation loss: 1.516908945575837

Epoch: 5| Step: 4
Training loss: 0.08319902420043945
Validation loss: 1.4797945727584183

Epoch: 5| Step: 5
Training loss: 0.19893299043178558
Validation loss: 1.5098592081377584

Epoch: 5| Step: 6
Training loss: 0.09111767262220383
Validation loss: 1.505109437050358

Epoch: 5| Step: 7
Training loss: 0.08480991423130035
Validation loss: 1.5529627389805292

Epoch: 5| Step: 8
Training loss: 0.090190589427948
Validation loss: 1.543775790481157

Epoch: 5| Step: 9
Training loss: 0.08389510214328766
Validation loss: 1.4955902073972969

Epoch: 5| Step: 10
Training loss: 0.09853025525808334
Validation loss: 1.5547725244234967

Epoch: 489| Step: 0
Training loss: 0.12284256517887115
Validation loss: 1.4957548264534242

Epoch: 5| Step: 1
Training loss: 0.10159386694431305
Validation loss: 1.496096746895903

Epoch: 5| Step: 2
Training loss: 0.06668253242969513
Validation loss: 1.4800576074149019

Epoch: 5| Step: 3
Training loss: 0.0938216894865036
Validation loss: 1.4609577732701455

Epoch: 5| Step: 4
Training loss: 0.11718934774398804
Validation loss: 1.4580181003898702

Epoch: 5| Step: 5
Training loss: 0.19943253695964813
Validation loss: 1.4871214576946792

Epoch: 5| Step: 6
Training loss: 0.08184029161930084
Validation loss: 1.47397857071251

Epoch: 5| Step: 7
Training loss: 0.10409992933273315
Validation loss: 1.4920384242970457

Epoch: 5| Step: 8
Training loss: 0.04591113328933716
Validation loss: 1.507250721736621

Epoch: 5| Step: 9
Training loss: 0.07848967611789703
Validation loss: 1.5200464763948995

Epoch: 5| Step: 10
Training loss: 0.08206484466791153
Validation loss: 1.5570747134506062

Epoch: 490| Step: 0
Training loss: 0.10751976072788239
Validation loss: 1.5363641067217755

Epoch: 5| Step: 1
Training loss: 0.06524673849344254
Validation loss: 1.5510121135301487

Epoch: 5| Step: 2
Training loss: 0.0976184755563736
Validation loss: 1.531069053116665

Epoch: 5| Step: 3
Training loss: 0.07395017892122269
Validation loss: 1.5383532072908135

Epoch: 5| Step: 4
Training loss: 0.09254375845193863
Validation loss: 1.5382931309361612

Epoch: 5| Step: 5
Training loss: 0.08317993581295013
Validation loss: 1.5151459376017253

Epoch: 5| Step: 6
Training loss: 0.17369261384010315
Validation loss: 1.5144396251247776

Epoch: 5| Step: 7
Training loss: 0.08383224904537201
Validation loss: 1.492539475041051

Epoch: 5| Step: 8
Training loss: 0.06383182108402252
Validation loss: 1.516770039835284

Epoch: 5| Step: 9
Training loss: 0.08965082466602325
Validation loss: 1.4991231477388771

Epoch: 5| Step: 10
Training loss: 0.05265863612294197
Validation loss: 1.5074877456952167

Epoch: 491| Step: 0
Training loss: 0.08779056370258331
Validation loss: 1.5388582662869525

Epoch: 5| Step: 1
Training loss: 0.061157792806625366
Validation loss: 1.5242861381141088

Epoch: 5| Step: 2
Training loss: 0.18720336258411407
Validation loss: 1.4928204859456708

Epoch: 5| Step: 3
Training loss: 0.04908544942736626
Validation loss: 1.5400870512890559

Epoch: 5| Step: 4
Training loss: 0.0568249449133873
Validation loss: 1.5487977548312115

Epoch: 5| Step: 5
Training loss: 0.13374245166778564
Validation loss: 1.535368093880274

Epoch: 5| Step: 6
Training loss: 0.07654444873332977
Validation loss: 1.5515538364328363

Epoch: 5| Step: 7
Training loss: 0.07884293049573898
Validation loss: 1.5250558019966207

Epoch: 5| Step: 8
Training loss: 0.052229225635528564
Validation loss: 1.5100513196760608

Epoch: 5| Step: 9
Training loss: 0.07041807472705841
Validation loss: 1.4972592323057112

Epoch: 5| Step: 10
Training loss: 0.08370613306760788
Validation loss: 1.5106279952551729

Epoch: 492| Step: 0
Training loss: 0.047117091715335846
Validation loss: 1.4994927913911882

Epoch: 5| Step: 1
Training loss: 0.10210633277893066
Validation loss: 1.4767710931839482

Epoch: 5| Step: 2
Training loss: 0.07003118097782135
Validation loss: 1.485583257931535

Epoch: 5| Step: 3
Training loss: 0.08780983835458755
Validation loss: 1.5113677222241637

Epoch: 5| Step: 4
Training loss: 0.0656551867723465
Validation loss: 1.5121386551087903

Epoch: 5| Step: 5
Training loss: 0.09623023867607117
Validation loss: 1.5060600490980252

Epoch: 5| Step: 6
Training loss: 0.17141327261924744
Validation loss: 1.5127992040367537

Epoch: 5| Step: 7
Training loss: 0.09334292262792587
Validation loss: 1.4829794617109402

Epoch: 5| Step: 8
Training loss: 0.1254623830318451
Validation loss: 1.5129335490606164

Epoch: 5| Step: 9
Training loss: 0.09265550225973129
Validation loss: 1.5130397389011998

Epoch: 5| Step: 10
Training loss: 0.07552651315927505
Validation loss: 1.539029566190576

Epoch: 493| Step: 0
Training loss: 0.09602553397417068
Validation loss: 1.5077007483410578

Epoch: 5| Step: 1
Training loss: 0.057680655270814896
Validation loss: 1.5091931999370616

Epoch: 5| Step: 2
Training loss: 0.10253331810235977
Validation loss: 1.541947809598779

Epoch: 5| Step: 3
Training loss: 0.20641636848449707
Validation loss: 1.5184097315675469

Epoch: 5| Step: 4
Training loss: 0.06912985444068909
Validation loss: 1.5197225937279322

Epoch: 5| Step: 5
Training loss: 0.09963057190179825
Validation loss: 1.514150816907165

Epoch: 5| Step: 6
Training loss: 0.07227341830730438
Validation loss: 1.4937909905628493

Epoch: 5| Step: 7
Training loss: 0.08372997492551804
Validation loss: 1.5135100272393995

Epoch: 5| Step: 8
Training loss: 0.056326162070035934
Validation loss: 1.4824324577085433

Epoch: 5| Step: 9
Training loss: 0.15493175387382507
Validation loss: 1.5284581889388382

Epoch: 5| Step: 10
Training loss: 0.09390703588724136
Validation loss: 1.5338377125801579

Epoch: 494| Step: 0
Training loss: 0.056601859629154205
Validation loss: 1.547383346865254

Epoch: 5| Step: 1
Training loss: 0.06541629135608673
Validation loss: 1.5081892103277228

Epoch: 5| Step: 2
Training loss: 0.1336662769317627
Validation loss: 1.5473039855239212

Epoch: 5| Step: 3
Training loss: 0.12781766057014465
Validation loss: 1.5567167215449835

Epoch: 5| Step: 4
Training loss: 0.12168164551258087
Validation loss: 1.5048577426582255

Epoch: 5| Step: 5
Training loss: 0.08891736716032028
Validation loss: 1.5150670172065817

Epoch: 5| Step: 6
Training loss: 0.06555722653865814
Validation loss: 1.5500869263884842

Epoch: 5| Step: 7
Training loss: 0.05592211335897446
Validation loss: 1.5440147243520266

Epoch: 5| Step: 8
Training loss: 0.15834924578666687
Validation loss: 1.5505809399389452

Epoch: 5| Step: 9
Training loss: 0.09922850131988525
Validation loss: 1.5826825275216052

Epoch: 5| Step: 10
Training loss: 0.09128770977258682
Validation loss: 1.5789571064774708

Epoch: 495| Step: 0
Training loss: 0.08395399153232574
Validation loss: 1.5787925066486481

Epoch: 5| Step: 1
Training loss: 0.16431814432144165
Validation loss: 1.5599142146366898

Epoch: 5| Step: 2
Training loss: 0.08009862154722214
Validation loss: 1.56318284362875

Epoch: 5| Step: 3
Training loss: 0.0525452196598053
Validation loss: 1.5154627202659525

Epoch: 5| Step: 4
Training loss: 0.20014062523841858
Validation loss: 1.5143813561367732

Epoch: 5| Step: 5
Training loss: 0.1014193519949913
Validation loss: 1.511755851007277

Epoch: 5| Step: 6
Training loss: 0.10262956470251083
Validation loss: 1.4868441550962386

Epoch: 5| Step: 7
Training loss: 0.09393145143985748
Validation loss: 1.5071606277137675

Epoch: 5| Step: 8
Training loss: 0.09238797426223755
Validation loss: 1.4807752960471696

Epoch: 5| Step: 9
Training loss: 0.09238214790821075
Validation loss: 1.5054434909615466

Epoch: 5| Step: 10
Training loss: 0.09851394593715668
Validation loss: 1.5451221658337502

Epoch: 496| Step: 0
Training loss: 0.07586564868688583
Validation loss: 1.5303242975665676

Epoch: 5| Step: 1
Training loss: 0.07470101863145828
Validation loss: 1.5304661976393832

Epoch: 5| Step: 2
Training loss: 0.12404751777648926
Validation loss: 1.5542912162760252

Epoch: 5| Step: 3
Training loss: 0.09508457034826279
Validation loss: 1.5262652571483324

Epoch: 5| Step: 4
Training loss: 0.10858681052923203
Validation loss: 1.5568566027507986

Epoch: 5| Step: 5
Training loss: 0.13399922847747803
Validation loss: 1.5468063880038518

Epoch: 5| Step: 6
Training loss: 0.12165051698684692
Validation loss: 1.570025674758419

Epoch: 5| Step: 7
Training loss: 0.10310952365398407
Validation loss: 1.575414207673842

Epoch: 5| Step: 8
Training loss: 0.05852827429771423
Validation loss: 1.583280360826882

Epoch: 5| Step: 9
Training loss: 0.0914153903722763
Validation loss: 1.5626516662618166

Epoch: 5| Step: 10
Training loss: 0.21947263181209564
Validation loss: 1.5692187957866217

Epoch: 497| Step: 0
Training loss: 0.11592386662960052
Validation loss: 1.5491355029485558

Epoch: 5| Step: 1
Training loss: 0.09051254391670227
Validation loss: 1.5540617050663117

Epoch: 5| Step: 2
Training loss: 0.09211034327745438
Validation loss: 1.5439273548382584

Epoch: 5| Step: 3
Training loss: 0.14980340003967285
Validation loss: 1.5357098566588534

Epoch: 5| Step: 4
Training loss: 0.05058603733778
Validation loss: 1.528928595204507

Epoch: 5| Step: 5
Training loss: 0.11100051552057266
Validation loss: 1.5364213976808774

Epoch: 5| Step: 6
Training loss: 0.08454964309930801
Validation loss: 1.5313581394892868

Epoch: 5| Step: 7
Training loss: 0.1376948058605194
Validation loss: 1.5272938628350534

Epoch: 5| Step: 8
Training loss: 0.11803428828716278
Validation loss: 1.5058243249052314

Epoch: 5| Step: 9
Training loss: 0.10130205005407333
Validation loss: 1.522936362092213

Epoch: 5| Step: 10
Training loss: 0.09655147045850754
Validation loss: 1.4914729300365652

Epoch: 498| Step: 0
Training loss: 0.08269830048084259
Validation loss: 1.5089987734312653

Epoch: 5| Step: 1
Training loss: 0.12199926376342773
Validation loss: 1.5090789359102967

Epoch: 5| Step: 2
Training loss: 0.07543744146823883
Validation loss: 1.4986411166447464

Epoch: 5| Step: 3
Training loss: 0.07758218050003052
Validation loss: 1.5171309273730043

Epoch: 5| Step: 4
Training loss: 0.07456444948911667
Validation loss: 1.5236335031447872

Epoch: 5| Step: 5
Training loss: 0.09823878109455109
Validation loss: 1.5255652608410004

Epoch: 5| Step: 6
Training loss: 0.12791094183921814
Validation loss: 1.5438023869709303

Epoch: 5| Step: 7
Training loss: 0.11311507225036621
Validation loss: 1.5332025712536228

Epoch: 5| Step: 8
Training loss: 0.09978418052196503
Validation loss: 1.5118602616812593

Epoch: 5| Step: 9
Training loss: 0.21839919686317444
Validation loss: 1.5389140088071105

Epoch: 5| Step: 10
Training loss: 0.0907742977142334
Validation loss: 1.5249741026150283

Epoch: 499| Step: 0
Training loss: 0.11164458096027374
Validation loss: 1.5189613655049314

Epoch: 5| Step: 1
Training loss: 0.0861416906118393
Validation loss: 1.4677596553679435

Epoch: 5| Step: 2
Training loss: 0.11969677358865738
Validation loss: 1.4397425728459512

Epoch: 5| Step: 3
Training loss: 0.05633770674467087
Validation loss: 1.4284086727326917

Epoch: 5| Step: 4
Training loss: 0.2041560709476471
Validation loss: 1.434314609855734

Epoch: 5| Step: 5
Training loss: 0.07775913923978806
Validation loss: 1.4171335004991101

Epoch: 5| Step: 6
Training loss: 0.14542211592197418
Validation loss: 1.4346718275418846

Epoch: 5| Step: 7
Training loss: 0.10794713348150253
Validation loss: 1.4505365561413508

Epoch: 5| Step: 8
Training loss: 0.10227993875741959
Validation loss: 1.4251795802065121

Epoch: 5| Step: 9
Training loss: 0.12626159191131592
Validation loss: 1.4590922286433559

Epoch: 5| Step: 10
Training loss: 0.06993797421455383
Validation loss: 1.472555350231868

Epoch: 500| Step: 0
Training loss: 0.07536637037992477
Validation loss: 1.4949319772822882

Epoch: 5| Step: 1
Training loss: 0.06610669195652008
Validation loss: 1.5311226767878379

Epoch: 5| Step: 2
Training loss: 0.07435733079910278
Validation loss: 1.5342278480529785

Epoch: 5| Step: 3
Training loss: 0.07869154959917068
Validation loss: 1.5589569601961362

Epoch: 5| Step: 4
Training loss: 0.18635477125644684
Validation loss: 1.5665554385031424

Epoch: 5| Step: 5
Training loss: 0.08129115402698517
Validation loss: 1.5928147185233332

Epoch: 5| Step: 6
Training loss: 0.09393280744552612
Validation loss: 1.5828762810717347

Epoch: 5| Step: 7
Training loss: 0.15149855613708496
Validation loss: 1.5364915619614303

Epoch: 5| Step: 8
Training loss: 0.06892342865467072
Validation loss: 1.54426376024882

Epoch: 5| Step: 9
Training loss: 0.09832490980625153
Validation loss: 1.5357434954694522

Epoch: 5| Step: 10
Training loss: 0.055932506918907166
Validation loss: 1.5160626166610307

Epoch: 501| Step: 0
Training loss: 0.048937153071165085
Validation loss: 1.52529227477248

Epoch: 5| Step: 1
Training loss: 0.11070388555526733
Validation loss: 1.4927231560471237

Epoch: 5| Step: 2
Training loss: 0.10300542414188385
Validation loss: 1.4807086759997952

Epoch: 5| Step: 3
Training loss: 0.1060015931725502
Validation loss: 1.446424006133951

Epoch: 5| Step: 4
Training loss: 0.21035702526569366
Validation loss: 1.4525185528621878

Epoch: 5| Step: 5
Training loss: 0.11095404624938965
Validation loss: 1.4745255131875314

Epoch: 5| Step: 6
Training loss: 0.09160131961107254
Validation loss: 1.4985925254001413

Epoch: 5| Step: 7
Training loss: 0.06861188262701035
Validation loss: 1.512264649073283

Epoch: 5| Step: 8
Training loss: 0.1149393692612648
Validation loss: 1.5071713603952879

Epoch: 5| Step: 9
Training loss: 0.09809631109237671
Validation loss: 1.521996800617505

Epoch: 5| Step: 10
Training loss: 0.08650816231966019
Validation loss: 1.535048924466615

Epoch: 502| Step: 0
Training loss: 0.05002053454518318
Validation loss: 1.5588795677308114

Epoch: 5| Step: 1
Training loss: 0.08667843043804169
Validation loss: 1.533727627928539

Epoch: 5| Step: 2
Training loss: 0.18683183193206787
Validation loss: 1.5379034742232291

Epoch: 5| Step: 3
Training loss: 0.05458386614918709
Validation loss: 1.5603678098288916

Epoch: 5| Step: 4
Training loss: 0.07267102599143982
Validation loss: 1.551157694990917

Epoch: 5| Step: 5
Training loss: 0.1270013004541397
Validation loss: 1.5264838985217515

Epoch: 5| Step: 6
Training loss: 0.05643707513809204
Validation loss: 1.5085282889745568

Epoch: 5| Step: 7
Training loss: 0.08581308275461197
Validation loss: 1.5158238334040488

Epoch: 5| Step: 8
Training loss: 0.08347177505493164
Validation loss: 1.5166092854674145

Epoch: 5| Step: 9
Training loss: 0.07110126316547394
Validation loss: 1.514150583615867

Epoch: 5| Step: 10
Training loss: 0.11507286876440048
Validation loss: 1.4970124754854428

Epoch: 503| Step: 0
Training loss: 0.11983473598957062
Validation loss: 1.4953751666571504

Epoch: 5| Step: 1
Training loss: 0.05281441658735275
Validation loss: 1.5132343474254812

Epoch: 5| Step: 2
Training loss: 0.12158310413360596
Validation loss: 1.5194366785787767

Epoch: 5| Step: 3
Training loss: 0.08759528398513794
Validation loss: 1.4864897388283924

Epoch: 5| Step: 4
Training loss: 0.04774894192814827
Validation loss: 1.5405373688667052

Epoch: 5| Step: 5
Training loss: 0.06895728409290314
Validation loss: 1.538577978328992

Epoch: 5| Step: 6
Training loss: 0.08860873430967331
Validation loss: 1.528198172969203

Epoch: 5| Step: 7
Training loss: 0.1338927447795868
Validation loss: 1.5360454282452982

Epoch: 5| Step: 8
Training loss: 0.07353673875331879
Validation loss: 1.5297305301953388

Epoch: 5| Step: 9
Training loss: 0.10534504801034927
Validation loss: 1.5230640826686737

Epoch: 5| Step: 10
Training loss: 0.15807488560676575
Validation loss: 1.5172414587390037

Epoch: 504| Step: 0
Training loss: 0.11581705510616302
Validation loss: 1.5643122042379072

Epoch: 5| Step: 1
Training loss: 0.08221544325351715
Validation loss: 1.5415695585230345

Epoch: 5| Step: 2
Training loss: 0.08198070526123047
Validation loss: 1.5222826157846758

Epoch: 5| Step: 3
Training loss: 0.09100145101547241
Validation loss: 1.5219732740873932

Epoch: 5| Step: 4
Training loss: 0.07450292259454727
Validation loss: 1.537240615455053

Epoch: 5| Step: 5
Training loss: 0.027299288660287857
Validation loss: 1.537142042190798

Epoch: 5| Step: 6
Training loss: 0.06531079858541489
Validation loss: 1.523394278941616

Epoch: 5| Step: 7
Training loss: 0.1616654098033905
Validation loss: 1.5289994144952426

Epoch: 5| Step: 8
Training loss: 0.08539363741874695
Validation loss: 1.5561164258628764

Epoch: 5| Step: 9
Training loss: 0.06546294689178467
Validation loss: 1.5216745465032515

Epoch: 5| Step: 10
Training loss: 0.08227133750915527
Validation loss: 1.5228065598395564

Epoch: 505| Step: 0
Training loss: 0.10985100269317627
Validation loss: 1.494041988926549

Epoch: 5| Step: 1
Training loss: 0.08909152448177338
Validation loss: 1.5334060448472218

Epoch: 5| Step: 2
Training loss: 0.10669668018817902
Validation loss: 1.5219297691058087

Epoch: 5| Step: 3
Training loss: 0.0936276763677597
Validation loss: 1.5257892890643048

Epoch: 5| Step: 4
Training loss: 0.08772917091846466
Validation loss: 1.505218575077672

Epoch: 5| Step: 5
Training loss: 0.09273733198642731
Validation loss: 1.4790549585896153

Epoch: 5| Step: 6
Training loss: 0.08466386049985886
Validation loss: 1.4872286922188216

Epoch: 5| Step: 7
Training loss: 0.15006723999977112
Validation loss: 1.4949647034368208

Epoch: 5| Step: 8
Training loss: 0.09119845926761627
Validation loss: 1.4604493405229302

Epoch: 5| Step: 9
Training loss: 0.10815439373254776
Validation loss: 1.5026755358583184

Epoch: 5| Step: 10
Training loss: 0.07578812539577484
Validation loss: 1.4903842967043641

Epoch: 506| Step: 0
Training loss: 0.1232287734746933
Validation loss: 1.503704902946308

Epoch: 5| Step: 1
Training loss: 0.103701151907444
Validation loss: 1.4711706817791026

Epoch: 5| Step: 2
Training loss: 0.08980692923069
Validation loss: 1.475631989458556

Epoch: 5| Step: 3
Training loss: 0.05764347314834595
Validation loss: 1.5066501504631453

Epoch: 5| Step: 4
Training loss: 0.07521585375070572
Validation loss: 1.512572592304599

Epoch: 5| Step: 5
Training loss: 0.06146440654993057
Validation loss: 1.5080574930355113

Epoch: 5| Step: 6
Training loss: 0.05822262167930603
Validation loss: 1.4885122173575944

Epoch: 5| Step: 7
Training loss: 0.15627239644527435
Validation loss: 1.5059212535940192

Epoch: 5| Step: 8
Training loss: 0.07311905175447464
Validation loss: 1.4968338140877344

Epoch: 5| Step: 9
Training loss: 0.08363090455532074
Validation loss: 1.4735337226621565

Epoch: 5| Step: 10
Training loss: 0.08249205350875854
Validation loss: 1.4787042474233976

Epoch: 507| Step: 0
Training loss: 0.09194742143154144
Validation loss: 1.4831000784391999

Epoch: 5| Step: 1
Training loss: 0.06779006868600845
Validation loss: 1.498911751213894

Epoch: 5| Step: 2
Training loss: 0.048848897218704224
Validation loss: 1.5124183316384592

Epoch: 5| Step: 3
Training loss: 0.07138873636722565
Validation loss: 1.5157555251993158

Epoch: 5| Step: 4
Training loss: 0.2355443686246872
Validation loss: 1.5167441598830684

Epoch: 5| Step: 5
Training loss: 0.0662146657705307
Validation loss: 1.501203876669689

Epoch: 5| Step: 6
Training loss: 0.06400223076343536
Validation loss: 1.5081652761787496

Epoch: 5| Step: 7
Training loss: 0.10201003402471542
Validation loss: 1.5470756356434157

Epoch: 5| Step: 8
Training loss: 0.11046423763036728
Validation loss: 1.561753531937958

Epoch: 5| Step: 9
Training loss: 0.06491825729608536
Validation loss: 1.5084148619764595

Epoch: 5| Step: 10
Training loss: 0.08565732836723328
Validation loss: 1.520217469943467

Epoch: 508| Step: 0
Training loss: 0.09314055740833282
Validation loss: 1.4890735303201983

Epoch: 5| Step: 1
Training loss: 0.12509965896606445
Validation loss: 1.4972545690433954

Epoch: 5| Step: 2
Training loss: 0.12087909877300262
Validation loss: 1.4894466259146248

Epoch: 5| Step: 3
Training loss: 0.19825181365013123
Validation loss: 1.5093126399542696

Epoch: 5| Step: 4
Training loss: 0.10675303637981415
Validation loss: 1.4969005430898359

Epoch: 5| Step: 5
Training loss: 0.0946495458483696
Validation loss: 1.497202496374807

Epoch: 5| Step: 6
Training loss: 0.0993066281080246
Validation loss: 1.5168391088003754

Epoch: 5| Step: 7
Training loss: 0.07444576919078827
Validation loss: 1.5082961564422936

Epoch: 5| Step: 8
Training loss: 0.11147814989089966
Validation loss: 1.5419310805618123

Epoch: 5| Step: 9
Training loss: 0.057857055217027664
Validation loss: 1.5266866325050272

Epoch: 5| Step: 10
Training loss: 0.03178480267524719
Validation loss: 1.5352825605741112

Epoch: 509| Step: 0
Training loss: 0.09671135246753693
Validation loss: 1.5488929876717188

Epoch: 5| Step: 1
Training loss: 0.05328719690442085
Validation loss: 1.5238379688673123

Epoch: 5| Step: 2
Training loss: 0.06014365702867508
Validation loss: 1.5041329706868818

Epoch: 5| Step: 3
Training loss: 0.07167492806911469
Validation loss: 1.514957295951023

Epoch: 5| Step: 4
Training loss: 0.12478804588317871
Validation loss: 1.5009201188241281

Epoch: 5| Step: 5
Training loss: 0.08177921175956726
Validation loss: 1.5223274077138593

Epoch: 5| Step: 6
Training loss: 0.10349329560995102
Validation loss: 1.5019421910726896

Epoch: 5| Step: 7
Training loss: 0.08704736083745956
Validation loss: 1.523229128570967

Epoch: 5| Step: 8
Training loss: 0.06779554486274719
Validation loss: 1.5351007151347336

Epoch: 5| Step: 9
Training loss: 0.15475969016551971
Validation loss: 1.5591325477887226

Epoch: 5| Step: 10
Training loss: 0.1194448173046112
Validation loss: 1.5487583465473627

Epoch: 510| Step: 0
Training loss: 0.05236297845840454
Validation loss: 1.517451799044045

Epoch: 5| Step: 1
Training loss: 0.14047999680042267
Validation loss: 1.5248228311538696

Epoch: 5| Step: 2
Training loss: 0.07950346171855927
Validation loss: 1.4973045702903502

Epoch: 5| Step: 3
Training loss: 0.08836770057678223
Validation loss: 1.480855954590664

Epoch: 5| Step: 4
Training loss: 0.08992767333984375
Validation loss: 1.4712992470751527

Epoch: 5| Step: 5
Training loss: 0.05649673938751221
Validation loss: 1.4624917007261706

Epoch: 5| Step: 6
Training loss: 0.09689883887767792
Validation loss: 1.4695327775452727

Epoch: 5| Step: 7
Training loss: 0.16239115595817566
Validation loss: 1.456461614178073

Epoch: 5| Step: 8
Training loss: 0.0932423546910286
Validation loss: 1.4418076853598318

Epoch: 5| Step: 9
Training loss: 0.0626223087310791
Validation loss: 1.4452735480441843

Epoch: 5| Step: 10
Training loss: 0.08985379338264465
Validation loss: 1.465809509959272

Epoch: 511| Step: 0
Training loss: 0.08828915655612946
Validation loss: 1.4653230623532367

Epoch: 5| Step: 1
Training loss: 0.08308152854442596
Validation loss: 1.4788212007091892

Epoch: 5| Step: 2
Training loss: 0.07863743603229523
Validation loss: 1.4439483111904514

Epoch: 5| Step: 3
Training loss: 0.08582130819559097
Validation loss: 1.4395963440659225

Epoch: 5| Step: 4
Training loss: 0.08036893606185913
Validation loss: 1.4974487430305892

Epoch: 5| Step: 5
Training loss: 0.1040663942694664
Validation loss: 1.478682328295964

Epoch: 5| Step: 6
Training loss: 0.18446698784828186
Validation loss: 1.4784673901014431

Epoch: 5| Step: 7
Training loss: 0.08472182601690292
Validation loss: 1.521714086173683

Epoch: 5| Step: 8
Training loss: 0.10231389105319977
Validation loss: 1.5057437977483195

Epoch: 5| Step: 9
Training loss: 0.10286177694797516
Validation loss: 1.4989507916153118

Epoch: 5| Step: 10
Training loss: 0.14510226249694824
Validation loss: 1.5047526116012244

Epoch: 512| Step: 0
Training loss: 0.07825622707605362
Validation loss: 1.4697316013356692

Epoch: 5| Step: 1
Training loss: 0.08144916594028473
Validation loss: 1.4667069937593193

Epoch: 5| Step: 2
Training loss: 0.10700021684169769
Validation loss: 1.4424155181454075

Epoch: 5| Step: 3
Training loss: 0.08255220949649811
Validation loss: 1.4746417255811795

Epoch: 5| Step: 4
Training loss: 0.13922937214374542
Validation loss: 1.4799067576726277

Epoch: 5| Step: 5
Training loss: 0.05433577299118042
Validation loss: 1.4561270981706598

Epoch: 5| Step: 6
Training loss: 0.15710607171058655
Validation loss: 1.4782471490162674

Epoch: 5| Step: 7
Training loss: 0.04567411541938782
Validation loss: 1.4789704251033005

Epoch: 5| Step: 8
Training loss: 0.12667040526866913
Validation loss: 1.4836353717311737

Epoch: 5| Step: 9
Training loss: 0.11676798015832901
Validation loss: 1.502121365198525

Epoch: 5| Step: 10
Training loss: 0.09953366965055466
Validation loss: 1.4736027333044237

Epoch: 513| Step: 0
Training loss: 0.10085465013980865
Validation loss: 1.513392307425058

Epoch: 5| Step: 1
Training loss: 0.11739371716976166
Validation loss: 1.5367928781817037

Epoch: 5| Step: 2
Training loss: 0.0972231850028038
Validation loss: 1.5095268603294127

Epoch: 5| Step: 3
Training loss: 0.11390648782253265
Validation loss: 1.5327669446186354

Epoch: 5| Step: 4
Training loss: 0.1150016188621521
Validation loss: 1.5214589347121537

Epoch: 5| Step: 5
Training loss: 0.14216668903827667
Validation loss: 1.5060589646780362

Epoch: 5| Step: 6
Training loss: 0.09855382144451141
Validation loss: 1.4798296779714606

Epoch: 5| Step: 7
Training loss: 0.08333880454301834
Validation loss: 1.4629851259211057

Epoch: 5| Step: 8
Training loss: 0.10208561271429062
Validation loss: 1.4431068217882546

Epoch: 5| Step: 9
Training loss: 0.22342562675476074
Validation loss: 1.4780351727880456

Epoch: 5| Step: 10
Training loss: 0.1335649937391281
Validation loss: 1.492329348800003

Epoch: 514| Step: 0
Training loss: 0.09107811748981476
Validation loss: 1.4418227826395342

Epoch: 5| Step: 1
Training loss: 0.10475430637598038
Validation loss: 1.4714446067810059

Epoch: 5| Step: 2
Training loss: 0.10865302383899689
Validation loss: 1.482956495336307

Epoch: 5| Step: 3
Training loss: 0.1219693273305893
Validation loss: 1.4819945750697967

Epoch: 5| Step: 4
Training loss: 0.08194364607334137
Validation loss: 1.4606898471873293

Epoch: 5| Step: 5
Training loss: 0.09526710212230682
Validation loss: 1.4855973464186474

Epoch: 5| Step: 6
Training loss: 0.19298899173736572
Validation loss: 1.4577362998839347

Epoch: 5| Step: 7
Training loss: 0.07207794487476349
Validation loss: 1.5093700642226844

Epoch: 5| Step: 8
Training loss: 0.16894972324371338
Validation loss: 1.4988025478137437

Epoch: 5| Step: 9
Training loss: 0.09416091442108154
Validation loss: 1.497134727816428

Epoch: 5| Step: 10
Training loss: 0.0960506945848465
Validation loss: 1.4670405375060214

Epoch: 515| Step: 0
Training loss: 0.1299094557762146
Validation loss: 1.477928679476502

Epoch: 5| Step: 1
Training loss: 0.08173660188913345
Validation loss: 1.481743130632626

Epoch: 5| Step: 2
Training loss: 0.10034780204296112
Validation loss: 1.4856865329127158

Epoch: 5| Step: 3
Training loss: 0.07936891168355942
Validation loss: 1.4802597004880187

Epoch: 5| Step: 4
Training loss: 0.1170593872666359
Validation loss: 1.4589482763762116

Epoch: 5| Step: 5
Training loss: 0.1914852112531662
Validation loss: 1.4768479293392551

Epoch: 5| Step: 6
Training loss: 0.06900434195995331
Validation loss: 1.4553054583969938

Epoch: 5| Step: 7
Training loss: 0.09384136646986008
Validation loss: 1.447081442802183

Epoch: 5| Step: 8
Training loss: 0.09460632503032684
Validation loss: 1.4328266766763502

Epoch: 5| Step: 9
Training loss: 0.07593517005443573
Validation loss: 1.4601653442587903

Epoch: 5| Step: 10
Training loss: 0.05392187461256981
Validation loss: 1.4748994945197977

Epoch: 516| Step: 0
Training loss: 0.11262623220682144
Validation loss: 1.4731784635974514

Epoch: 5| Step: 1
Training loss: 0.09526307880878448
Validation loss: 1.4831165472666423

Epoch: 5| Step: 2
Training loss: 0.08262049406766891
Validation loss: 1.4830267378078994

Epoch: 5| Step: 3
Training loss: 0.05458848550915718
Validation loss: 1.4959954459180114

Epoch: 5| Step: 4
Training loss: 0.05508707836270332
Validation loss: 1.504781980668345

Epoch: 5| Step: 5
Training loss: 0.14573808014392853
Validation loss: 1.4999521022201867

Epoch: 5| Step: 6
Training loss: 0.10908619314432144
Validation loss: 1.5130028263215096

Epoch: 5| Step: 7
Training loss: 0.1267250031232834
Validation loss: 1.5240023495048605

Epoch: 5| Step: 8
Training loss: 0.09632423520088196
Validation loss: 1.553411796528806

Epoch: 5| Step: 9
Training loss: 0.08091114461421967
Validation loss: 1.5526887434785084

Epoch: 5| Step: 10
Training loss: 0.18143810331821442
Validation loss: 1.5244710445404053

Epoch: 517| Step: 0
Training loss: 0.15469315648078918
Validation loss: 1.506488505230155

Epoch: 5| Step: 1
Training loss: 0.06552368402481079
Validation loss: 1.5014798154113114

Epoch: 5| Step: 2
Training loss: 0.08302624523639679
Validation loss: 1.4819008663136473

Epoch: 5| Step: 3
Training loss: 0.09179918467998505
Validation loss: 1.4968108105403122

Epoch: 5| Step: 4
Training loss: 0.0821031853556633
Validation loss: 1.4852732522513277

Epoch: 5| Step: 5
Training loss: 0.08699846267700195
Validation loss: 1.4900306783696657

Epoch: 5| Step: 6
Training loss: 0.06115422397851944
Validation loss: 1.485016772823949

Epoch: 5| Step: 7
Training loss: 0.1185217872262001
Validation loss: 1.4651113376822522

Epoch: 5| Step: 8
Training loss: 0.07408208400011063
Validation loss: 1.4580924087955105

Epoch: 5| Step: 9
Training loss: 0.06590558588504791
Validation loss: 1.5080352598620999

Epoch: 5| Step: 10
Training loss: 0.06455272436141968
Validation loss: 1.5190710995786934

Epoch: 518| Step: 0
Training loss: 0.08841755241155624
Validation loss: 1.5062071443885885

Epoch: 5| Step: 1
Training loss: 0.11948053538799286
Validation loss: 1.5491267352975824

Epoch: 5| Step: 2
Training loss: 0.1124129518866539
Validation loss: 1.5192171335220337

Epoch: 5| Step: 3
Training loss: 0.06409747898578644
Validation loss: 1.5425160379819973

Epoch: 5| Step: 4
Training loss: 0.06318219751119614
Validation loss: 1.5501973398270146

Epoch: 5| Step: 5
Training loss: 0.06863360106945038
Validation loss: 1.5219290923046809

Epoch: 5| Step: 6
Training loss: 0.16459199786186218
Validation loss: 1.525477687517802

Epoch: 5| Step: 7
Training loss: 0.08898116648197174
Validation loss: 1.484827454372119

Epoch: 5| Step: 8
Training loss: 0.12345745414495468
Validation loss: 1.472615308659051

Epoch: 5| Step: 9
Training loss: 0.07717527449131012
Validation loss: 1.4828106062386626

Epoch: 5| Step: 10
Training loss: 0.0872403085231781
Validation loss: 1.4650130361639044

Epoch: 519| Step: 0
Training loss: 0.08140833675861359
Validation loss: 1.4591432258646975

Epoch: 5| Step: 1
Training loss: 0.09204848855733871
Validation loss: 1.498127459197916

Epoch: 5| Step: 2
Training loss: 0.09337397664785385
Validation loss: 1.4826234630359116

Epoch: 5| Step: 3
Training loss: 0.08181343972682953
Validation loss: 1.488245269944591

Epoch: 5| Step: 4
Training loss: 0.064817413687706
Validation loss: 1.4763222740542503

Epoch: 5| Step: 5
Training loss: 0.0991043895483017
Validation loss: 1.4936770303274995

Epoch: 5| Step: 6
Training loss: 0.0970020741224289
Validation loss: 1.5246830999210317

Epoch: 5| Step: 7
Training loss: 0.07501231133937836
Validation loss: 1.48800370770116

Epoch: 5| Step: 8
Training loss: 0.11321850121021271
Validation loss: 1.503725089052672

Epoch: 5| Step: 9
Training loss: 0.14238134026527405
Validation loss: 1.5250367938831288

Epoch: 5| Step: 10
Training loss: 0.22141128778457642
Validation loss: 1.490143943858403

Epoch: 520| Step: 0
Training loss: 0.2238602638244629
Validation loss: 1.5164681596140708

Epoch: 5| Step: 1
Training loss: 0.07368545234203339
Validation loss: 1.4736264931258334

Epoch: 5| Step: 2
Training loss: 0.08723819255828857
Validation loss: 1.477826355605997

Epoch: 5| Step: 3
Training loss: 0.09703569114208221
Validation loss: 1.4548445017107072

Epoch: 5| Step: 4
Training loss: 0.09695619344711304
Validation loss: 1.4427732665051696

Epoch: 5| Step: 5
Training loss: 0.10863576829433441
Validation loss: 1.454881937273087

Epoch: 5| Step: 6
Training loss: 0.11998362839221954
Validation loss: 1.457948887219993

Epoch: 5| Step: 7
Training loss: 0.0951247587800026
Validation loss: 1.44262473429403

Epoch: 5| Step: 8
Training loss: 0.09612762928009033
Validation loss: 1.4536099356989707

Epoch: 5| Step: 9
Training loss: 0.09372153133153915
Validation loss: 1.455418308575948

Epoch: 5| Step: 10
Training loss: 0.07619914412498474
Validation loss: 1.4282417040999218

Epoch: 521| Step: 0
Training loss: 0.07568135112524033
Validation loss: 1.4434669684338313

Epoch: 5| Step: 1
Training loss: 0.11700092256069183
Validation loss: 1.4485176032589329

Epoch: 5| Step: 2
Training loss: 0.08335823565721512
Validation loss: 1.4930664057372718

Epoch: 5| Step: 3
Training loss: 0.12166553735733032
Validation loss: 1.490014515256369

Epoch: 5| Step: 4
Training loss: 0.08285737037658691
Validation loss: 1.462528947860964

Epoch: 5| Step: 5
Training loss: 0.12588810920715332
Validation loss: 1.466372759111466

Epoch: 5| Step: 6
Training loss: 0.15902504324913025
Validation loss: 1.4810215343711197

Epoch: 5| Step: 7
Training loss: 0.07811528444290161
Validation loss: 1.4604856634652743

Epoch: 5| Step: 8
Training loss: 0.08843295276165009
Validation loss: 1.4874128141710836

Epoch: 5| Step: 9
Training loss: 0.08461499214172363
Validation loss: 1.4536438321554532

Epoch: 5| Step: 10
Training loss: 0.07641381025314331
Validation loss: 1.484076698621114

Epoch: 522| Step: 0
Training loss: 0.08267682790756226
Validation loss: 1.4591608226940196

Epoch: 5| Step: 1
Training loss: 0.0706314668059349
Validation loss: 1.466008738804889

Epoch: 5| Step: 2
Training loss: 0.161957785487175
Validation loss: 1.4812803832433556

Epoch: 5| Step: 3
Training loss: 0.09264529496431351
Validation loss: 1.4888174162116101

Epoch: 5| Step: 4
Training loss: 0.0952187031507492
Validation loss: 1.4892576086905696

Epoch: 5| Step: 5
Training loss: 0.05935478210449219
Validation loss: 1.4736861086660815

Epoch: 5| Step: 6
Training loss: 0.08119960129261017
Validation loss: 1.4735869117962417

Epoch: 5| Step: 7
Training loss: 0.09099928289651871
Validation loss: 1.4913285445141535

Epoch: 5| Step: 8
Training loss: 0.05187095329165459
Validation loss: 1.4896246425567135

Epoch: 5| Step: 9
Training loss: 0.10362613201141357
Validation loss: 1.467052173870866

Epoch: 5| Step: 10
Training loss: 0.06872493028640747
Validation loss: 1.4855121245948217

Epoch: 523| Step: 0
Training loss: 0.0772305577993393
Validation loss: 1.5161681611050841

Epoch: 5| Step: 1
Training loss: 0.059623949229717255
Validation loss: 1.4881095834957656

Epoch: 5| Step: 2
Training loss: 0.05689932778477669
Validation loss: 1.4908546004244076

Epoch: 5| Step: 3
Training loss: 0.08090177923440933
Validation loss: 1.5128993167672107

Epoch: 5| Step: 4
Training loss: 0.10267166793346405
Validation loss: 1.5200492194903794

Epoch: 5| Step: 5
Training loss: 0.07270680367946625
Validation loss: 1.503701365122231

Epoch: 5| Step: 6
Training loss: 0.11403410136699677
Validation loss: 1.5120791632642028

Epoch: 5| Step: 7
Training loss: 0.053687650710344315
Validation loss: 1.4941815125044955

Epoch: 5| Step: 8
Training loss: 0.18006043136119843
Validation loss: 1.4903731922949515

Epoch: 5| Step: 9
Training loss: 0.0763358324766159
Validation loss: 1.524674811670857

Epoch: 5| Step: 10
Training loss: 0.06659003347158432
Validation loss: 1.5016665394588182

Epoch: 524| Step: 0
Training loss: 0.06958118826150894
Validation loss: 1.5116545897658153

Epoch: 5| Step: 1
Training loss: 0.0464106984436512
Validation loss: 1.5274260749099076

Epoch: 5| Step: 2
Training loss: 0.07949879765510559
Validation loss: 1.5009623958218483

Epoch: 5| Step: 3
Training loss: 0.09898736327886581
Validation loss: 1.5314257689701614

Epoch: 5| Step: 4
Training loss: 0.06264837831258774
Validation loss: 1.5073711692645986

Epoch: 5| Step: 5
Training loss: 0.20932678878307343
Validation loss: 1.5114732609000257

Epoch: 5| Step: 6
Training loss: 0.08243437111377716
Validation loss: 1.4888604456378567

Epoch: 5| Step: 7
Training loss: 0.0643577128648758
Validation loss: 1.5200254942781182

Epoch: 5| Step: 8
Training loss: 0.05986855551600456
Validation loss: 1.4867977147461267

Epoch: 5| Step: 9
Training loss: 0.05611767619848251
Validation loss: 1.4742039326698548

Epoch: 5| Step: 10
Training loss: 0.07822643220424652
Validation loss: 1.476133906713096

Epoch: 525| Step: 0
Training loss: 0.06691890954971313
Validation loss: 1.5031266109917754

Epoch: 5| Step: 1
Training loss: 0.08680710941553116
Validation loss: 1.4646778593781173

Epoch: 5| Step: 2
Training loss: 0.05262332409620285
Validation loss: 1.4385267265381352

Epoch: 5| Step: 3
Training loss: 0.07246579229831696
Validation loss: 1.4497541727558259

Epoch: 5| Step: 4
Training loss: 0.09892360866069794
Validation loss: 1.4237362505287252

Epoch: 5| Step: 5
Training loss: 0.07905970513820648
Validation loss: 1.4505284063277706

Epoch: 5| Step: 6
Training loss: 0.14152589440345764
Validation loss: 1.4535798411215506

Epoch: 5| Step: 7
Training loss: 0.06725486367940903
Validation loss: 1.4614760837247294

Epoch: 5| Step: 8
Training loss: 0.08904567360877991
Validation loss: 1.4541572550291657

Epoch: 5| Step: 9
Training loss: 0.23820047080516815
Validation loss: 1.4766178989923129

Epoch: 5| Step: 10
Training loss: 0.07981203496456146
Validation loss: 1.484796816302884

Epoch: 526| Step: 0
Training loss: 0.07870693504810333
Validation loss: 1.4559462044828682

Epoch: 5| Step: 1
Training loss: 0.07872337102890015
Validation loss: 1.4648477005702194

Epoch: 5| Step: 2
Training loss: 0.11207637935876846
Validation loss: 1.468999445438385

Epoch: 5| Step: 3
Training loss: 0.07033593952655792
Validation loss: 1.4784484678699124

Epoch: 5| Step: 4
Training loss: 0.06048083305358887
Validation loss: 1.4600987447205411

Epoch: 5| Step: 5
Training loss: 0.1553899347782135
Validation loss: 1.4912263295983756

Epoch: 5| Step: 6
Training loss: 0.07049482315778732
Validation loss: 1.4772355255260263

Epoch: 5| Step: 7
Training loss: 0.09279020875692368
Validation loss: 1.4752176666772494

Epoch: 5| Step: 8
Training loss: 0.08612215518951416
Validation loss: 1.4926071795084144

Epoch: 5| Step: 9
Training loss: 0.084266796708107
Validation loss: 1.5100540948170487

Epoch: 5| Step: 10
Training loss: 0.06103650853037834
Validation loss: 1.4741547569151847

Epoch: 527| Step: 0
Training loss: 0.07832031697034836
Validation loss: 1.5028169603757962

Epoch: 5| Step: 1
Training loss: 0.046763308346271515
Validation loss: 1.4902201724308792

Epoch: 5| Step: 2
Training loss: 0.053527552634477615
Validation loss: 1.507143073184516

Epoch: 5| Step: 3
Training loss: 0.060402870178222656
Validation loss: 1.4685325596922187

Epoch: 5| Step: 4
Training loss: 0.19053111970424652
Validation loss: 1.4708296906563543

Epoch: 5| Step: 5
Training loss: 0.05733518674969673
Validation loss: 1.4855049681919876

Epoch: 5| Step: 6
Training loss: 0.07763393223285675
Validation loss: 1.4636356433232625

Epoch: 5| Step: 7
Training loss: 0.08237709850072861
Validation loss: 1.4889218397037958

Epoch: 5| Step: 8
Training loss: 0.07053835690021515
Validation loss: 1.4768831319706415

Epoch: 5| Step: 9
Training loss: 0.07817687839269638
Validation loss: 1.4928333208125124

Epoch: 5| Step: 10
Training loss: 0.058258820325136185
Validation loss: 1.5047675704443326

Epoch: 528| Step: 0
Training loss: 0.05526607111096382
Validation loss: 1.5128860896633518

Epoch: 5| Step: 1
Training loss: 0.0718512088060379
Validation loss: 1.506554825331575

Epoch: 5| Step: 2
Training loss: 0.17680624127388
Validation loss: 1.503993417627068

Epoch: 5| Step: 3
Training loss: 0.0641692653298378
Validation loss: 1.5161636837067143

Epoch: 5| Step: 4
Training loss: 0.07220884412527084
Validation loss: 1.5267942131206553

Epoch: 5| Step: 5
Training loss: 0.08431784808635712
Validation loss: 1.5144540430397115

Epoch: 5| Step: 6
Training loss: 0.07421557605266571
Validation loss: 1.494201321114776

Epoch: 5| Step: 7
Training loss: 0.07647798955440521
Validation loss: 1.5030902906130719

Epoch: 5| Step: 8
Training loss: 0.07209289073944092
Validation loss: 1.4993955576291649

Epoch: 5| Step: 9
Training loss: 0.09514113515615463
Validation loss: 1.4880380797129806

Epoch: 5| Step: 10
Training loss: 0.08094042539596558
Validation loss: 1.4908588163314327

Epoch: 529| Step: 0
Training loss: 0.05902016907930374
Validation loss: 1.517545469345585

Epoch: 5| Step: 1
Training loss: 0.07604088634252548
Validation loss: 1.502445678557119

Epoch: 5| Step: 2
Training loss: 0.05784810706973076
Validation loss: 1.5098574981894544

Epoch: 5| Step: 3
Training loss: 0.0683147981762886
Validation loss: 1.5026992046704857

Epoch: 5| Step: 4
Training loss: 0.08889565616846085
Validation loss: 1.4811277709981447

Epoch: 5| Step: 5
Training loss: 0.09516562521457672
Validation loss: 1.4656449735805552

Epoch: 5| Step: 6
Training loss: 0.16985970735549927
Validation loss: 1.5038287588345107

Epoch: 5| Step: 7
Training loss: 0.06718973815441132
Validation loss: 1.4953096105206398

Epoch: 5| Step: 8
Training loss: 0.08650285005569458
Validation loss: 1.4685601547200193

Epoch: 5| Step: 9
Training loss: 0.1252356320619583
Validation loss: 1.466958592014928

Epoch: 5| Step: 10
Training loss: 0.11866653710603714
Validation loss: 1.4351963009885562

Epoch: 530| Step: 0
Training loss: 0.1592053771018982
Validation loss: 1.4541867843238256

Epoch: 5| Step: 1
Training loss: 0.08252977579832077
Validation loss: 1.4886724948883057

Epoch: 5| Step: 2
Training loss: 0.07762783765792847
Validation loss: 1.4583448306206734

Epoch: 5| Step: 3
Training loss: 0.09182654321193695
Validation loss: 1.4904887842875656

Epoch: 5| Step: 4
Training loss: 0.07727253437042236
Validation loss: 1.5058960953066427

Epoch: 5| Step: 5
Training loss: 0.08496886491775513
Validation loss: 1.515219694824629

Epoch: 5| Step: 6
Training loss: 0.07373438775539398
Validation loss: 1.480855509799014

Epoch: 5| Step: 7
Training loss: 0.11302895843982697
Validation loss: 1.513968047275338

Epoch: 5| Step: 8
Training loss: 0.08119988441467285
Validation loss: 1.5488385154354958

Epoch: 5| Step: 9
Training loss: 0.08457523584365845
Validation loss: 1.4836799893327939

Epoch: 5| Step: 10
Training loss: 0.0770721361041069
Validation loss: 1.5153356982815651

Epoch: 531| Step: 0
Training loss: 0.04429548233747482
Validation loss: 1.5286055008570354

Epoch: 5| Step: 1
Training loss: 0.09781480580568314
Validation loss: 1.4791969868444628

Epoch: 5| Step: 2
Training loss: 0.09361062943935394
Validation loss: 1.5140051611008183

Epoch: 5| Step: 3
Training loss: 0.06218906119465828
Validation loss: 1.5010025475614814

Epoch: 5| Step: 4
Training loss: 0.16583707928657532
Validation loss: 1.5241304700092604

Epoch: 5| Step: 5
Training loss: 0.06692729145288467
Validation loss: 1.4672234558290052

Epoch: 5| Step: 6
Training loss: 0.16514810919761658
Validation loss: 1.483351589531027

Epoch: 5| Step: 7
Training loss: 0.13286034762859344
Validation loss: 1.4811983569975822

Epoch: 5| Step: 8
Training loss: 0.08221779018640518
Validation loss: 1.481446821202514

Epoch: 5| Step: 9
Training loss: 0.1258944720029831
Validation loss: 1.4736837648576306

Epoch: 5| Step: 10
Training loss: 0.09920158237218857
Validation loss: 1.4761256146174606

Epoch: 532| Step: 0
Training loss: 0.05315510183572769
Validation loss: 1.4818281281378962

Epoch: 5| Step: 1
Training loss: 0.1395757496356964
Validation loss: 1.5083428313655238

Epoch: 5| Step: 2
Training loss: 0.0757877379655838
Validation loss: 1.5171529016187113

Epoch: 5| Step: 3
Training loss: 0.08815421164035797
Validation loss: 1.5029795567194622

Epoch: 5| Step: 4
Training loss: 0.06710701435804367
Validation loss: 1.5237645167176441

Epoch: 5| Step: 5
Training loss: 0.07302536070346832
Validation loss: 1.5648832366030703

Epoch: 5| Step: 6
Training loss: 0.10800745338201523
Validation loss: 1.519529200369312

Epoch: 5| Step: 7
Training loss: 0.06632071733474731
Validation loss: 1.5115881619914886

Epoch: 5| Step: 8
Training loss: 0.07188926637172699
Validation loss: 1.5178455447637906

Epoch: 5| Step: 9
Training loss: 0.15919049084186554
Validation loss: 1.5059674644982943

Epoch: 5| Step: 10
Training loss: 0.11592300981283188
Validation loss: 1.4926855102662118

Epoch: 533| Step: 0
Training loss: 0.047473665326833725
Validation loss: 1.4681995273918234

Epoch: 5| Step: 1
Training loss: 0.08100970834493637
Validation loss: 1.4834926051478232

Epoch: 5| Step: 2
Training loss: 0.086690254509449
Validation loss: 1.4132821393269364

Epoch: 5| Step: 3
Training loss: 0.09168259054422379
Validation loss: 1.4561980353888644

Epoch: 5| Step: 4
Training loss: 0.0933523029088974
Validation loss: 1.435094000190817

Epoch: 5| Step: 5
Training loss: 0.07631795108318329
Validation loss: 1.4506114189342787

Epoch: 5| Step: 6
Training loss: 0.10241588205099106
Validation loss: 1.4565962860661168

Epoch: 5| Step: 7
Training loss: 0.06879822909832001
Validation loss: 1.4791750561806463

Epoch: 5| Step: 8
Training loss: 0.07348315417766571
Validation loss: 1.51898790431279

Epoch: 5| Step: 9
Training loss: 0.1502530872821808
Validation loss: 1.5297189502305881

Epoch: 5| Step: 10
Training loss: 0.06371364742517471
Validation loss: 1.5283561163051154

Epoch: 534| Step: 0
Training loss: 0.06895996630191803
Validation loss: 1.5296149382027246

Epoch: 5| Step: 1
Training loss: 0.15888270735740662
Validation loss: 1.5230827357179375

Epoch: 5| Step: 2
Training loss: 0.07775188982486725
Validation loss: 1.4693691461317

Epoch: 5| Step: 3
Training loss: 0.05657771974802017
Validation loss: 1.4971304273092618

Epoch: 5| Step: 4
Training loss: 0.09567584097385406
Validation loss: 1.4616486000758346

Epoch: 5| Step: 5
Training loss: 0.04374198243021965
Validation loss: 1.4772622482751006

Epoch: 5| Step: 6
Training loss: 0.04963596537709236
Validation loss: 1.4526488524611278

Epoch: 5| Step: 7
Training loss: 0.10908587276935577
Validation loss: 1.4629680033653014

Epoch: 5| Step: 8
Training loss: 0.1066407784819603
Validation loss: 1.4867250163068053

Epoch: 5| Step: 9
Training loss: 0.06244579702615738
Validation loss: 1.5099300351194156

Epoch: 5| Step: 10
Training loss: 0.05547433719038963
Validation loss: 1.4803648725632699

Epoch: 535| Step: 0
Training loss: 0.06499681621789932
Validation loss: 1.5221693541413994

Epoch: 5| Step: 1
Training loss: 0.07424944639205933
Validation loss: 1.5299780580305284

Epoch: 5| Step: 2
Training loss: 0.06189708784222603
Validation loss: 1.4988393706660117

Epoch: 5| Step: 3
Training loss: 0.08419043570756912
Validation loss: 1.5084526551667081

Epoch: 5| Step: 4
Training loss: 0.11789105087518692
Validation loss: 1.4755733365653663

Epoch: 5| Step: 5
Training loss: 0.1625160276889801
Validation loss: 1.477787426722947

Epoch: 5| Step: 6
Training loss: 0.10950805991888046
Validation loss: 1.4339613876035135

Epoch: 5| Step: 7
Training loss: 0.07321935892105103
Validation loss: 1.478233056683694

Epoch: 5| Step: 8
Training loss: 0.11257284879684448
Validation loss: 1.4902407328287761

Epoch: 5| Step: 9
Training loss: 0.06763333827257156
Validation loss: 1.466492832347911

Epoch: 5| Step: 10
Training loss: 0.093830406665802
Validation loss: 1.4527898578233616

Epoch: 536| Step: 0
Training loss: 0.07604239135980606
Validation loss: 1.415346598753365

Epoch: 5| Step: 1
Training loss: 0.09154228121042252
Validation loss: 1.4220589091700893

Epoch: 5| Step: 2
Training loss: 0.10673101246356964
Validation loss: 1.4423989903542302

Epoch: 5| Step: 3
Training loss: 0.0832301527261734
Validation loss: 1.4557134002767584

Epoch: 5| Step: 4
Training loss: 0.06329233199357986
Validation loss: 1.4176736211264005

Epoch: 5| Step: 5
Training loss: 0.06378538906574249
Validation loss: 1.457145671049754

Epoch: 5| Step: 6
Training loss: 0.14530423283576965
Validation loss: 1.4764542630923692

Epoch: 5| Step: 7
Training loss: 0.05302729457616806
Validation loss: 1.4671624937365133

Epoch: 5| Step: 8
Training loss: 0.1351132094860077
Validation loss: 1.5141413711732434

Epoch: 5| Step: 9
Training loss: 0.05733559653162956
Validation loss: 1.5182217397997457

Epoch: 5| Step: 10
Training loss: 0.10494531691074371
Validation loss: 1.5146289307584044

Epoch: 537| Step: 0
Training loss: 0.09773234277963638
Validation loss: 1.4859598759681947

Epoch: 5| Step: 1
Training loss: 0.12411042302846909
Validation loss: 1.530165433883667

Epoch: 5| Step: 2
Training loss: 0.09673762321472168
Validation loss: 1.5010434196841331

Epoch: 5| Step: 3
Training loss: 0.20036537945270538
Validation loss: 1.5212009094094718

Epoch: 5| Step: 4
Training loss: 0.08005895465612411
Validation loss: 1.4946866650735178

Epoch: 5| Step: 5
Training loss: 0.08276702463626862
Validation loss: 1.4937766700662591

Epoch: 5| Step: 6
Training loss: 0.09205359220504761
Validation loss: 1.5149287318670621

Epoch: 5| Step: 7
Training loss: 0.04910632222890854
Validation loss: 1.5146810072724537

Epoch: 5| Step: 8
Training loss: 0.08356938511133194
Validation loss: 1.4780069820342525

Epoch: 5| Step: 9
Training loss: 0.08959326893091202
Validation loss: 1.481360843104701

Epoch: 5| Step: 10
Training loss: 0.07097401469945908
Validation loss: 1.5114984127783007

Epoch: 538| Step: 0
Training loss: 0.14423558115959167
Validation loss: 1.5040699769091863

Epoch: 5| Step: 1
Training loss: 0.06170957162976265
Validation loss: 1.480145133951659

Epoch: 5| Step: 2
Training loss: 0.07505621761083603
Validation loss: 1.521922024347449

Epoch: 5| Step: 3
Training loss: 0.047965433448553085
Validation loss: 1.4904058780721439

Epoch: 5| Step: 4
Training loss: 0.07653598487377167
Validation loss: 1.4808087028482908

Epoch: 5| Step: 5
Training loss: 0.0517486110329628
Validation loss: 1.4953201816928001

Epoch: 5| Step: 6
Training loss: 0.09896739572286606
Validation loss: 1.471348847112348

Epoch: 5| Step: 7
Training loss: 0.14838315546512604
Validation loss: 1.4560409707407798

Epoch: 5| Step: 8
Training loss: 0.08364267647266388
Validation loss: 1.4470896003066853

Epoch: 5| Step: 9
Training loss: 0.06792552769184113
Validation loss: 1.4504796792102117

Epoch: 5| Step: 10
Training loss: 0.057606395334005356
Validation loss: 1.4647250983022875

Epoch: 539| Step: 0
Training loss: 0.0949389636516571
Validation loss: 1.4400336101490965

Epoch: 5| Step: 1
Training loss: 0.09487419575452805
Validation loss: 1.4612736125146188

Epoch: 5| Step: 2
Training loss: 0.06478031724691391
Validation loss: 1.4545299571047547

Epoch: 5| Step: 3
Training loss: 0.09718979895114899
Validation loss: 1.4479443475764284

Epoch: 5| Step: 4
Training loss: 0.04936591908335686
Validation loss: 1.4423970150691208

Epoch: 5| Step: 5
Training loss: 0.07068119198083878
Validation loss: 1.4733458949673561

Epoch: 5| Step: 6
Training loss: 0.08032456785440445
Validation loss: 1.4521873266466203

Epoch: 5| Step: 7
Training loss: 0.14411136507987976
Validation loss: 1.473354685691095

Epoch: 5| Step: 8
Training loss: 0.062071990221738815
Validation loss: 1.480416351749051

Epoch: 5| Step: 9
Training loss: 0.11233341693878174
Validation loss: 1.4934018017143331

Epoch: 5| Step: 10
Training loss: 0.09451940655708313
Validation loss: 1.49533659924743

Epoch: 540| Step: 0
Training loss: 0.05530395358800888
Validation loss: 1.4628205722378147

Epoch: 5| Step: 1
Training loss: 0.07735203951597214
Validation loss: 1.4660119484829646

Epoch: 5| Step: 2
Training loss: 0.06681651622056961
Validation loss: 1.4797515907595236

Epoch: 5| Step: 3
Training loss: 0.06437182426452637
Validation loss: 1.4405579989956272

Epoch: 5| Step: 4
Training loss: 0.10657574981451035
Validation loss: 1.4774771326331682

Epoch: 5| Step: 5
Training loss: 0.1155669242143631
Validation loss: 1.4402792466584073

Epoch: 5| Step: 6
Training loss: 0.20104432106018066
Validation loss: 1.46970493947306

Epoch: 5| Step: 7
Training loss: 0.1007893830537796
Validation loss: 1.462710279290394

Epoch: 5| Step: 8
Training loss: 0.1004633903503418
Validation loss: 1.4739130684124526

Epoch: 5| Step: 9
Training loss: 0.07246650755405426
Validation loss: 1.431113572530849

Epoch: 5| Step: 10
Training loss: 0.0936601385474205
Validation loss: 1.4391614198684692

Epoch: 541| Step: 0
Training loss: 0.06841136515140533
Validation loss: 1.4413645126486336

Epoch: 5| Step: 1
Training loss: 0.12467537820339203
Validation loss: 1.4952017748227684

Epoch: 5| Step: 2
Training loss: 0.11548186838626862
Validation loss: 1.4777118634152155

Epoch: 5| Step: 3
Training loss: 0.08177048712968826
Validation loss: 1.4288290835195971

Epoch: 5| Step: 4
Training loss: 0.17917725443840027
Validation loss: 1.4697034397432882

Epoch: 5| Step: 5
Training loss: 0.06924731284379959
Validation loss: 1.4703218821556336

Epoch: 5| Step: 6
Training loss: 0.08752655982971191
Validation loss: 1.468634892535466

Epoch: 5| Step: 7
Training loss: 0.11785055696964264
Validation loss: 1.5228422444353822

Epoch: 5| Step: 8
Training loss: 0.1035698652267456
Validation loss: 1.4788580620160667

Epoch: 5| Step: 9
Training loss: 0.06488923728466034
Validation loss: 1.4740522843535229

Epoch: 5| Step: 10
Training loss: 0.06527803093194962
Validation loss: 1.4809368028435657

Epoch: 542| Step: 0
Training loss: 0.0970277413725853
Validation loss: 1.4903021089492305

Epoch: 5| Step: 1
Training loss: 0.09749560058116913
Validation loss: 1.4486787870366087

Epoch: 5| Step: 2
Training loss: 0.037926506251096725
Validation loss: 1.4041489760080974

Epoch: 5| Step: 3
Training loss: 0.0964590534567833
Validation loss: 1.407200469765612

Epoch: 5| Step: 4
Training loss: 0.17237690091133118
Validation loss: 1.3801948562745125

Epoch: 5| Step: 5
Training loss: 0.0994258001446724
Validation loss: 1.4189819328246578

Epoch: 5| Step: 6
Training loss: 0.06743727624416351
Validation loss: 1.4365856673127861

Epoch: 5| Step: 7
Training loss: 0.0817483514547348
Validation loss: 1.4455742861634941

Epoch: 5| Step: 8
Training loss: 0.058925170451402664
Validation loss: 1.4718282274020615

Epoch: 5| Step: 9
Training loss: 0.06618649512529373
Validation loss: 1.4809728194308538

Epoch: 5| Step: 10
Training loss: 0.11740563809871674
Validation loss: 1.507336203769971

Epoch: 543| Step: 0
Training loss: 0.0774414911866188
Validation loss: 1.5485680616030129

Epoch: 5| Step: 1
Training loss: 0.09380634874105453
Validation loss: 1.5688762395612654

Epoch: 5| Step: 2
Training loss: 0.06352345645427704
Validation loss: 1.557404787309708

Epoch: 5| Step: 3
Training loss: 0.0967787653207779
Validation loss: 1.5799935504954348

Epoch: 5| Step: 4
Training loss: 0.09186158329248428
Validation loss: 1.5703058345343477

Epoch: 5| Step: 5
Training loss: 0.14799848198890686
Validation loss: 1.535969558582511

Epoch: 5| Step: 6
Training loss: 0.13626530766487122
Validation loss: 1.5264530386976016

Epoch: 5| Step: 7
Training loss: 0.10169746726751328
Validation loss: 1.5219232651495165

Epoch: 5| Step: 8
Training loss: 0.1158999353647232
Validation loss: 1.4890395364453715

Epoch: 5| Step: 9
Training loss: 0.08647339046001434
Validation loss: 1.4919750280277704

Epoch: 5| Step: 10
Training loss: 0.12427251785993576
Validation loss: 1.4478681766858665

Epoch: 544| Step: 0
Training loss: 0.12792949378490448
Validation loss: 1.4485950034151795

Epoch: 5| Step: 1
Training loss: 0.127298042178154
Validation loss: 1.4529538705784788

Epoch: 5| Step: 2
Training loss: 0.07798396050930023
Validation loss: 1.4834872368843324

Epoch: 5| Step: 3
Training loss: 0.0926244929432869
Validation loss: 1.4708593788967337

Epoch: 5| Step: 4
Training loss: 0.1007477417588234
Validation loss: 1.4915533898979105

Epoch: 5| Step: 5
Training loss: 0.18472173810005188
Validation loss: 1.4883838738164594

Epoch: 5| Step: 6
Training loss: 0.09055555611848831
Validation loss: 1.4805572379019953

Epoch: 5| Step: 7
Training loss: 0.05470560863614082
Validation loss: 1.5171911165278444

Epoch: 5| Step: 8
Training loss: 0.10562069714069366
Validation loss: 1.5207425266183832

Epoch: 5| Step: 9
Training loss: 0.06413793563842773
Validation loss: 1.528651866861569

Epoch: 5| Step: 10
Training loss: 0.054230064153671265
Validation loss: 1.5357327006196464

Epoch: 545| Step: 0
Training loss: 0.10304264724254608
Validation loss: 1.4977936180689002

Epoch: 5| Step: 1
Training loss: 0.05573943257331848
Validation loss: 1.4793955472207838

Epoch: 5| Step: 2
Training loss: 0.09002230316400528
Validation loss: 1.4731441941312564

Epoch: 5| Step: 3
Training loss: 0.08531980961561203
Validation loss: 1.4535614059817406

Epoch: 5| Step: 4
Training loss: 0.06441786140203476
Validation loss: 1.4401307900746663

Epoch: 5| Step: 5
Training loss: 0.0947866439819336
Validation loss: 1.4414623181025188

Epoch: 5| Step: 6
Training loss: 0.05664936453104019
Validation loss: 1.466899364225326

Epoch: 5| Step: 7
Training loss: 0.0864541083574295
Validation loss: 1.487764737939322

Epoch: 5| Step: 8
Training loss: 0.08946719020605087
Validation loss: 1.4981115594986947

Epoch: 5| Step: 9
Training loss: 0.1661897450685501
Validation loss: 1.529626916813594

Epoch: 5| Step: 10
Training loss: 0.06716523319482803
Validation loss: 1.5227552524176977

Epoch: 546| Step: 0
Training loss: 0.05846557766199112
Validation loss: 1.4907579319451445

Epoch: 5| Step: 1
Training loss: 0.0893123671412468
Validation loss: 1.506211410286606

Epoch: 5| Step: 2
Training loss: 0.06364879757165909
Validation loss: 1.5211721697161276

Epoch: 5| Step: 3
Training loss: 0.09021847695112228
Validation loss: 1.5091589907164216

Epoch: 5| Step: 4
Training loss: 0.06830748170614243
Validation loss: 1.492833576535666

Epoch: 5| Step: 5
Training loss: 0.060025930404663086
Validation loss: 1.4900222055373653

Epoch: 5| Step: 6
Training loss: 0.17279568314552307
Validation loss: 1.4827202891790738

Epoch: 5| Step: 7
Training loss: 0.10936892032623291
Validation loss: 1.4889197618730607

Epoch: 5| Step: 8
Training loss: 0.09108749032020569
Validation loss: 1.475263217444061

Epoch: 5| Step: 9
Training loss: 0.06657780706882477
Validation loss: 1.4831429361015238

Epoch: 5| Step: 10
Training loss: 0.08152473717927933
Validation loss: 1.450233087744764

Epoch: 547| Step: 0
Training loss: 0.05519484356045723
Validation loss: 1.4757121519375873

Epoch: 5| Step: 1
Training loss: 0.05565398931503296
Validation loss: 1.5145893609651955

Epoch: 5| Step: 2
Training loss: 0.06468963623046875
Validation loss: 1.47641114265688

Epoch: 5| Step: 3
Training loss: 0.061054527759552
Validation loss: 1.5051940820550407

Epoch: 5| Step: 4
Training loss: 0.11186299473047256
Validation loss: 1.4792483058027042

Epoch: 5| Step: 5
Training loss: 0.08368577808141708
Validation loss: 1.5020593238133255

Epoch: 5| Step: 6
Training loss: 0.0746401697397232
Validation loss: 1.5091816738087644

Epoch: 5| Step: 7
Training loss: 0.0523490384221077
Validation loss: 1.491879363213816

Epoch: 5| Step: 8
Training loss: 0.14175090193748474
Validation loss: 1.532495101292928

Epoch: 5| Step: 9
Training loss: 0.09464108198881149
Validation loss: 1.5001624604707122

Epoch: 5| Step: 10
Training loss: 0.12660662829875946
Validation loss: 1.5137987188113633

Epoch: 548| Step: 0
Training loss: 0.06223822385072708
Validation loss: 1.5294869535712785

Epoch: 5| Step: 1
Training loss: 0.040840066969394684
Validation loss: 1.4780558950157576

Epoch: 5| Step: 2
Training loss: 0.07035445421934128
Validation loss: 1.4960994130821639

Epoch: 5| Step: 3
Training loss: 0.2100880891084671
Validation loss: 1.4822370929102744

Epoch: 5| Step: 4
Training loss: 0.08579547703266144
Validation loss: 1.4451329144098426

Epoch: 5| Step: 5
Training loss: 0.046104785054922104
Validation loss: 1.453412514860912

Epoch: 5| Step: 6
Training loss: 0.04649457708001137
Validation loss: 1.443468475854525

Epoch: 5| Step: 7
Training loss: 0.057644497603178024
Validation loss: 1.4120903893183636

Epoch: 5| Step: 8
Training loss: 0.10968303680419922
Validation loss: 1.4229946713293753

Epoch: 5| Step: 9
Training loss: 0.06453323364257812
Validation loss: 1.4230307045803274

Epoch: 5| Step: 10
Training loss: 0.09223125129938126
Validation loss: 1.4395387775154525

Epoch: 549| Step: 0
Training loss: 0.04645143821835518
Validation loss: 1.4568713672699467

Epoch: 5| Step: 1
Training loss: 0.10253908485174179
Validation loss: 1.4609087923521638

Epoch: 5| Step: 2
Training loss: 0.07243935018777847
Validation loss: 1.4499365411778933

Epoch: 5| Step: 3
Training loss: 0.1570623219013214
Validation loss: 1.4520144859949748

Epoch: 5| Step: 4
Training loss: 0.05033745616674423
Validation loss: 1.4844114139515867

Epoch: 5| Step: 5
Training loss: 0.056016940623521805
Validation loss: 1.5163213501694381

Epoch: 5| Step: 6
Training loss: 0.06514017283916473
Validation loss: 1.504989021567888

Epoch: 5| Step: 7
Training loss: 0.06009485200047493
Validation loss: 1.498996026413415

Epoch: 5| Step: 8
Training loss: 0.05842430517077446
Validation loss: 1.4612118685117332

Epoch: 5| Step: 9
Training loss: 0.039333585649728775
Validation loss: 1.482543150583903

Epoch: 5| Step: 10
Training loss: 0.11121970415115356
Validation loss: 1.4546687884997296

Epoch: 550| Step: 0
Training loss: 0.09455247223377228
Validation loss: 1.4315762917200725

Epoch: 5| Step: 1
Training loss: 0.07452736794948578
Validation loss: 1.4442928202690617

Epoch: 5| Step: 2
Training loss: 0.07452777028083801
Validation loss: 1.4767212816464004

Epoch: 5| Step: 3
Training loss: 0.06763976067304611
Validation loss: 1.4624732527681576

Epoch: 5| Step: 4
Training loss: 0.07315797358751297
Validation loss: 1.4685926315605

Epoch: 5| Step: 5
Training loss: 0.09140747785568237
Validation loss: 1.4508457094110467

Epoch: 5| Step: 6
Training loss: 0.06982521712779999
Validation loss: 1.4496528474233483

Epoch: 5| Step: 7
Training loss: 0.06047794967889786
Validation loss: 1.4445014756212953

Epoch: 5| Step: 8
Training loss: 0.1835736185312271
Validation loss: 1.4514863760240617

Epoch: 5| Step: 9
Training loss: 0.08932171761989594
Validation loss: 1.4505686170311385

Epoch: 5| Step: 10
Training loss: 0.04755093902349472
Validation loss: 1.435575630075188

Epoch: 551| Step: 0
Training loss: 0.042423851788043976
Validation loss: 1.455342588886138

Epoch: 5| Step: 1
Training loss: 0.05556158348917961
Validation loss: 1.4573344312688357

Epoch: 5| Step: 2
Training loss: 0.04697147011756897
Validation loss: 1.4435609668813727

Epoch: 5| Step: 3
Training loss: 0.05154925584793091
Validation loss: 1.4469482796166533

Epoch: 5| Step: 4
Training loss: 0.08096721023321152
Validation loss: 1.4814743931575487

Epoch: 5| Step: 5
Training loss: 0.06443361192941666
Validation loss: 1.4906827890744774

Epoch: 5| Step: 6
Training loss: 0.0686303973197937
Validation loss: 1.470826054132113

Epoch: 5| Step: 7
Training loss: 0.06999845802783966
Validation loss: 1.4988958681783369

Epoch: 5| Step: 8
Training loss: 0.1382806897163391
Validation loss: 1.4740983311847975

Epoch: 5| Step: 9
Training loss: 0.04843622073531151
Validation loss: 1.484300583921453

Epoch: 5| Step: 10
Training loss: 0.16430982947349548
Validation loss: 1.4720733781014719

Epoch: 552| Step: 0
Training loss: 0.06446949392557144
Validation loss: 1.4916720595411075

Epoch: 5| Step: 1
Training loss: 0.08956707268953323
Validation loss: 1.4929311249845771

Epoch: 5| Step: 2
Training loss: 0.08390907943248749
Validation loss: 1.4841482498312508

Epoch: 5| Step: 3
Training loss: 0.07423602789640427
Validation loss: 1.489983061949412

Epoch: 5| Step: 4
Training loss: 0.03963496536016464
Validation loss: 1.507840644928717

Epoch: 5| Step: 5
Training loss: 0.15281574428081512
Validation loss: 1.5003716663647724

Epoch: 5| Step: 6
Training loss: 0.07833780348300934
Validation loss: 1.4827360017325288

Epoch: 5| Step: 7
Training loss: 0.07881873846054077
Validation loss: 1.5032260443574639

Epoch: 5| Step: 8
Training loss: 0.09441075474023819
Validation loss: 1.5070916183533207

Epoch: 5| Step: 9
Training loss: 0.04049369692802429
Validation loss: 1.4528649558303177

Epoch: 5| Step: 10
Training loss: 0.051160603761672974
Validation loss: 1.501538981673538

Epoch: 553| Step: 0
Training loss: 0.05804389715194702
Validation loss: 1.4970297364778415

Epoch: 5| Step: 1
Training loss: 0.06522754579782486
Validation loss: 1.4974218004493303

Epoch: 5| Step: 2
Training loss: 0.062346916645765305
Validation loss: 1.4649189274798158

Epoch: 5| Step: 3
Training loss: 0.07901778072118759
Validation loss: 1.444703628939967

Epoch: 5| Step: 4
Training loss: 0.1557057499885559
Validation loss: 1.4660225299096876

Epoch: 5| Step: 5
Training loss: 0.07586503028869629
Validation loss: 1.4450155765779558

Epoch: 5| Step: 6
Training loss: 0.0873483270406723
Validation loss: 1.4354139322875648

Epoch: 5| Step: 7
Training loss: 0.06004735082387924
Validation loss: 1.4736382756181943

Epoch: 5| Step: 8
Training loss: 0.08910150825977325
Validation loss: 1.4779332760841615

Epoch: 5| Step: 9
Training loss: 0.08597972244024277
Validation loss: 1.4991564866035216

Epoch: 5| Step: 10
Training loss: 0.060301557183265686
Validation loss: 1.484411593406431

Epoch: 554| Step: 0
Training loss: 0.09681214392185211
Validation loss: 1.5249979893366497

Epoch: 5| Step: 1
Training loss: 0.04215861111879349
Validation loss: 1.4934849764711113

Epoch: 5| Step: 2
Training loss: 0.08205094933509827
Validation loss: 1.4641362967029694

Epoch: 5| Step: 3
Training loss: 0.04979962483048439
Validation loss: 1.4532196739668488

Epoch: 5| Step: 4
Training loss: 0.08653144538402557
Validation loss: 1.4829727411270142

Epoch: 5| Step: 5
Training loss: 0.05701983720064163
Validation loss: 1.4257378924277522

Epoch: 5| Step: 6
Training loss: 0.07716084271669388
Validation loss: 1.4485596841381443

Epoch: 5| Step: 7
Training loss: 0.08134765923023224
Validation loss: 1.4147542779163649

Epoch: 5| Step: 8
Training loss: 0.07255031168460846
Validation loss: 1.453829837101762

Epoch: 5| Step: 9
Training loss: 0.1995345950126648
Validation loss: 1.4611020959833616

Epoch: 5| Step: 10
Training loss: 0.06410245597362518
Validation loss: 1.4398565869177542

Epoch: 555| Step: 0
Training loss: 0.07818982750177383
Validation loss: 1.4712835127307522

Epoch: 5| Step: 1
Training loss: 0.11308789253234863
Validation loss: 1.4993232834723689

Epoch: 5| Step: 2
Training loss: 0.03951338678598404
Validation loss: 1.5174052830665343

Epoch: 5| Step: 3
Training loss: 0.0951773151755333
Validation loss: 1.5103321408712735

Epoch: 5| Step: 4
Training loss: 0.08656831830739975
Validation loss: 1.4769540820070493

Epoch: 5| Step: 5
Training loss: 0.06535542756319046
Validation loss: 1.4957939745277486

Epoch: 5| Step: 6
Training loss: 0.05468561500310898
Validation loss: 1.4998148410551009

Epoch: 5| Step: 7
Training loss: 0.06170736998319626
Validation loss: 1.5118305503681142

Epoch: 5| Step: 8
Training loss: 0.14691884815692902
Validation loss: 1.5283353790160148

Epoch: 5| Step: 9
Training loss: 0.07143174856901169
Validation loss: 1.4987973872051443

Epoch: 5| Step: 10
Training loss: 0.061100561171770096
Validation loss: 1.468025016528304

Epoch: 556| Step: 0
Training loss: 0.06959189474582672
Validation loss: 1.4808396229179956

Epoch: 5| Step: 1
Training loss: 0.058265604078769684
Validation loss: 1.4604808399754186

Epoch: 5| Step: 2
Training loss: 0.06591810286045074
Validation loss: 1.4693361847631392

Epoch: 5| Step: 3
Training loss: 0.07848155498504639
Validation loss: 1.5074267066935056

Epoch: 5| Step: 4
Training loss: 0.08092799037694931
Validation loss: 1.5070541584363548

Epoch: 5| Step: 5
Training loss: 0.07501860707998276
Validation loss: 1.497446462672244

Epoch: 5| Step: 6
Training loss: 0.05789268761873245
Validation loss: 1.5079339447841849

Epoch: 5| Step: 7
Training loss: 0.13652370870113373
Validation loss: 1.5220503050793883

Epoch: 5| Step: 8
Training loss: 0.11167510598897934
Validation loss: 1.5086838250519128

Epoch: 5| Step: 9
Training loss: 0.07923083007335663
Validation loss: 1.5043872723015406

Epoch: 5| Step: 10
Training loss: 0.06484019756317139
Validation loss: 1.5145981042615828

Epoch: 557| Step: 0
Training loss: 0.07824864238500595
Validation loss: 1.5190257654395154

Epoch: 5| Step: 1
Training loss: 0.07123091071844101
Validation loss: 1.489287296930949

Epoch: 5| Step: 2
Training loss: 0.0686466172337532
Validation loss: 1.4953492149229972

Epoch: 5| Step: 3
Training loss: 0.06959281116724014
Validation loss: 1.500823707990749

Epoch: 5| Step: 4
Training loss: 0.10382888466119766
Validation loss: 1.47220274197158

Epoch: 5| Step: 5
Training loss: 0.06532011181116104
Validation loss: 1.488373133444017

Epoch: 5| Step: 6
Training loss: 0.06846103072166443
Validation loss: 1.4649311701456706

Epoch: 5| Step: 7
Training loss: 0.065370574593544
Validation loss: 1.4819395311417118

Epoch: 5| Step: 8
Training loss: 0.05761796981096268
Validation loss: 1.4599090186498498

Epoch: 5| Step: 9
Training loss: 0.15774491429328918
Validation loss: 1.4397458337968396

Epoch: 5| Step: 10
Training loss: 0.06068529933691025
Validation loss: 1.4682914903087

Epoch: 558| Step: 0
Training loss: 0.06515615433454514
Validation loss: 1.4409433052104006

Epoch: 5| Step: 1
Training loss: 0.0530073344707489
Validation loss: 1.453634827367721

Epoch: 5| Step: 2
Training loss: 0.07827432453632355
Validation loss: 1.4537675778071086

Epoch: 5| Step: 3
Training loss: 0.06031613424420357
Validation loss: 1.45787061414411

Epoch: 5| Step: 4
Training loss: 0.06353506445884705
Validation loss: 1.4398751438304942

Epoch: 5| Step: 5
Training loss: 0.05112748593091965
Validation loss: 1.4662679940141656

Epoch: 5| Step: 6
Training loss: 0.06408869475126266
Validation loss: 1.4310253102292296

Epoch: 5| Step: 7
Training loss: 0.06311442703008652
Validation loss: 1.4394497307397986

Epoch: 5| Step: 8
Training loss: 0.17094461619853973
Validation loss: 1.4763921268524662

Epoch: 5| Step: 9
Training loss: 0.061194080859422684
Validation loss: 1.4561608863133255

Epoch: 5| Step: 10
Training loss: 0.05959881842136383
Validation loss: 1.466261246512013

Epoch: 559| Step: 0
Training loss: 0.05905402451753616
Validation loss: 1.4728236685517013

Epoch: 5| Step: 1
Training loss: 0.07075940072536469
Validation loss: 1.4703141207336097

Epoch: 5| Step: 2
Training loss: 0.06834195554256439
Validation loss: 1.4684133811663556

Epoch: 5| Step: 3
Training loss: 0.07204057276248932
Validation loss: 1.4508434521254672

Epoch: 5| Step: 4
Training loss: 0.06786924600601196
Validation loss: 1.4574192736738472

Epoch: 5| Step: 5
Training loss: 0.06160982698202133
Validation loss: 1.4368703660144602

Epoch: 5| Step: 6
Training loss: 0.08805801719427109
Validation loss: 1.4504951853905954

Epoch: 5| Step: 7
Training loss: 0.16835106909275055
Validation loss: 1.4530917380445747

Epoch: 5| Step: 8
Training loss: 0.08792345970869064
Validation loss: 1.4454759981042595

Epoch: 5| Step: 9
Training loss: 0.09416303783655167
Validation loss: 1.4526229776361936

Epoch: 5| Step: 10
Training loss: 0.06638497114181519
Validation loss: 1.4959497432554922

Epoch: 560| Step: 0
Training loss: 0.06895574182271957
Validation loss: 1.4813294038977673

Epoch: 5| Step: 1
Training loss: 0.06808115541934967
Validation loss: 1.519186718489534

Epoch: 5| Step: 2
Training loss: 0.04999282956123352
Validation loss: 1.4914687032340674

Epoch: 5| Step: 3
Training loss: 0.052706051617860794
Validation loss: 1.4827235257753761

Epoch: 5| Step: 4
Training loss: 0.0636981874704361
Validation loss: 1.5194397229020313

Epoch: 5| Step: 5
Training loss: 0.1609996259212494
Validation loss: 1.5118055446173555

Epoch: 5| Step: 6
Training loss: 0.08069472014904022
Validation loss: 1.50846613607099

Epoch: 5| Step: 7
Training loss: 0.0748351514339447
Validation loss: 1.5079348574402511

Epoch: 5| Step: 8
Training loss: 0.07510150223970413
Validation loss: 1.4718060108923143

Epoch: 5| Step: 9
Training loss: 0.04546787217259407
Validation loss: 1.4874960645552604

Epoch: 5| Step: 10
Training loss: 0.03980610892176628
Validation loss: 1.5016017742054437

Epoch: 561| Step: 0
Training loss: 0.05732610076665878
Validation loss: 1.5142211811516875

Epoch: 5| Step: 1
Training loss: 0.07113226503133774
Validation loss: 1.4932441429425312

Epoch: 5| Step: 2
Training loss: 0.053647637367248535
Validation loss: 1.4978711425617177

Epoch: 5| Step: 3
Training loss: 0.0832325890660286
Validation loss: 1.5133245786031086

Epoch: 5| Step: 4
Training loss: 0.0437309667468071
Validation loss: 1.4966228867089877

Epoch: 5| Step: 5
Training loss: 0.09347623586654663
Validation loss: 1.5121744666048276

Epoch: 5| Step: 6
Training loss: 0.06699984520673752
Validation loss: 1.524885626249416

Epoch: 5| Step: 7
Training loss: 0.059301674365997314
Validation loss: 1.494877576828003

Epoch: 5| Step: 8
Training loss: 0.1529705673456192
Validation loss: 1.5110735226702947

Epoch: 5| Step: 9
Training loss: 0.08150635659694672
Validation loss: 1.5193011247983543

Epoch: 5| Step: 10
Training loss: 0.09849971532821655
Validation loss: 1.486629520693133

Epoch: 562| Step: 0
Training loss: 0.07535910606384277
Validation loss: 1.5175974304958055

Epoch: 5| Step: 1
Training loss: 0.15007451176643372
Validation loss: 1.4824047639805784

Epoch: 5| Step: 2
Training loss: 0.09865497797727585
Validation loss: 1.436505134387683

Epoch: 5| Step: 3
Training loss: 0.09077465534210205
Validation loss: 1.4290213097808182

Epoch: 5| Step: 4
Training loss: 0.0709156021475792
Validation loss: 1.4265404708923832

Epoch: 5| Step: 5
Training loss: 0.08537047356367111
Validation loss: 1.4739682866681008

Epoch: 5| Step: 6
Training loss: 0.08338063210248947
Validation loss: 1.4922883331134755

Epoch: 5| Step: 7
Training loss: 0.09313931316137314
Validation loss: 1.483128232340659

Epoch: 5| Step: 8
Training loss: 0.0598735585808754
Validation loss: 1.501650647450519

Epoch: 5| Step: 9
Training loss: 0.07347755879163742
Validation loss: 1.5240860523716095

Epoch: 5| Step: 10
Training loss: 0.1114526242017746
Validation loss: 1.516058720568175

Epoch: 563| Step: 0
Training loss: 0.07416947931051254
Validation loss: 1.5189901680074713

Epoch: 5| Step: 1
Training loss: 0.07305203378200531
Validation loss: 1.5287441720244705

Epoch: 5| Step: 2
Training loss: 0.09978991746902466
Validation loss: 1.4823477345128213

Epoch: 5| Step: 3
Training loss: 0.04616980999708176
Validation loss: 1.4811332430890811

Epoch: 5| Step: 4
Training loss: 0.16442808508872986
Validation loss: 1.471234433112606

Epoch: 5| Step: 5
Training loss: 0.057145856320858
Validation loss: 1.444060863987092

Epoch: 5| Step: 6
Training loss: 0.08738334476947784
Validation loss: 1.4138147138780164

Epoch: 5| Step: 7
Training loss: 0.09322135895490646
Validation loss: 1.4095366142129386

Epoch: 5| Step: 8
Training loss: 0.10190092027187347
Validation loss: 1.4553905148659982

Epoch: 5| Step: 9
Training loss: 0.054311782121658325
Validation loss: 1.4457856788430163

Epoch: 5| Step: 10
Training loss: 0.07923521846532822
Validation loss: 1.4710743683640675

Epoch: 564| Step: 0
Training loss: 0.06038845330476761
Validation loss: 1.4645367860794067

Epoch: 5| Step: 1
Training loss: 0.14388692378997803
Validation loss: 1.4766241997800849

Epoch: 5| Step: 2
Training loss: 0.09257015585899353
Validation loss: 1.5200426802840283

Epoch: 5| Step: 3
Training loss: 0.07260875403881073
Validation loss: 1.5154012018634426

Epoch: 5| Step: 4
Training loss: 0.1516156941652298
Validation loss: 1.5305549329327

Epoch: 5| Step: 5
Training loss: 0.07650623470544815
Validation loss: 1.5262992420504171

Epoch: 5| Step: 6
Training loss: 0.0862400084733963
Validation loss: 1.5218620864293908

Epoch: 5| Step: 7
Training loss: 0.056423407047986984
Validation loss: 1.5464074201481317

Epoch: 5| Step: 8
Training loss: 0.12418632209300995
Validation loss: 1.5323213172215286

Epoch: 5| Step: 9
Training loss: 0.10063309967517853
Validation loss: 1.5043562355861868

Epoch: 5| Step: 10
Training loss: 0.05996900424361229
Validation loss: 1.5008688261432033

Epoch: 565| Step: 0
Training loss: 0.10240095853805542
Validation loss: 1.5107553530764837

Epoch: 5| Step: 1
Training loss: 0.12038986384868622
Validation loss: 1.4891554206930182

Epoch: 5| Step: 2
Training loss: 0.05738319829106331
Validation loss: 1.4975832470001713

Epoch: 5| Step: 3
Training loss: 0.10976141691207886
Validation loss: 1.5355636214697233

Epoch: 5| Step: 4
Training loss: 0.14882615208625793
Validation loss: 1.4896628613113074

Epoch: 5| Step: 5
Training loss: 0.07815742492675781
Validation loss: 1.5186153611829203

Epoch: 5| Step: 6
Training loss: 0.06604000180959702
Validation loss: 1.5111262183035574

Epoch: 5| Step: 7
Training loss: 0.09545427560806274
Validation loss: 1.5025640790180494

Epoch: 5| Step: 8
Training loss: 0.08667586743831635
Validation loss: 1.4833657395455144

Epoch: 5| Step: 9
Training loss: 0.10700465738773346
Validation loss: 1.5169448134719685

Epoch: 5| Step: 10
Training loss: 0.07910210639238358
Validation loss: 1.544792482929845

Epoch: 566| Step: 0
Training loss: 0.09984685480594635
Validation loss: 1.5427739402299285

Epoch: 5| Step: 1
Training loss: 0.09711272269487381
Validation loss: 1.5314301675365818

Epoch: 5| Step: 2
Training loss: 0.09898839890956879
Validation loss: 1.531996811589887

Epoch: 5| Step: 3
Training loss: 0.0770380049943924
Validation loss: 1.529842730491392

Epoch: 5| Step: 4
Training loss: 0.1432855874300003
Validation loss: 1.506250895479674

Epoch: 5| Step: 5
Training loss: 0.05783732607960701
Validation loss: 1.482087242987848

Epoch: 5| Step: 6
Training loss: 0.06064373254776001
Validation loss: 1.4931681777841301

Epoch: 5| Step: 7
Training loss: 0.0703287273645401
Validation loss: 1.4778658395172448

Epoch: 5| Step: 8
Training loss: 0.08422522246837616
Validation loss: 1.495980724211662

Epoch: 5| Step: 9
Training loss: 0.07023762166500092
Validation loss: 1.482520648228225

Epoch: 5| Step: 10
Training loss: 0.11365501582622528
Validation loss: 1.501143825951443

Epoch: 567| Step: 0
Training loss: 0.09063007682561874
Validation loss: 1.4840523901806082

Epoch: 5| Step: 1
Training loss: 0.08626723289489746
Validation loss: 1.5065463230174074

Epoch: 5| Step: 2
Training loss: 0.062032300978899
Validation loss: 1.4806598899185017

Epoch: 5| Step: 3
Training loss: 0.06559557467699051
Validation loss: 1.4917662899981263

Epoch: 5| Step: 4
Training loss: 0.07908504456281662
Validation loss: 1.491950047913418

Epoch: 5| Step: 5
Training loss: 0.06307712942361832
Validation loss: 1.4704202246922318

Epoch: 5| Step: 6
Training loss: 0.054953597486019135
Validation loss: 1.4740012614957747

Epoch: 5| Step: 7
Training loss: 0.06569752097129822
Validation loss: 1.5067466856330953

Epoch: 5| Step: 8
Training loss: 0.05690420791506767
Validation loss: 1.4864472445621286

Epoch: 5| Step: 9
Training loss: 0.20542283356189728
Validation loss: 1.490984555213682

Epoch: 5| Step: 10
Training loss: 0.059585969895124435
Validation loss: 1.5137534103085917

Epoch: 568| Step: 0
Training loss: 0.05912787839770317
Validation loss: 1.5312039890596945

Epoch: 5| Step: 1
Training loss: 0.06658443063497543
Validation loss: 1.5100834344023017

Epoch: 5| Step: 2
Training loss: 0.11200054734945297
Validation loss: 1.5250875514040712

Epoch: 5| Step: 3
Training loss: 0.07913602888584137
Validation loss: 1.5292788154335433

Epoch: 5| Step: 4
Training loss: 0.08502240478992462
Validation loss: 1.5035372216214415

Epoch: 5| Step: 5
Training loss: 0.05368178337812424
Validation loss: 1.5098967206093572

Epoch: 5| Step: 6
Training loss: 0.04987425357103348
Validation loss: 1.5032199557109545

Epoch: 5| Step: 7
Training loss: 0.08193089067935944
Validation loss: 1.5300224096544328

Epoch: 5| Step: 8
Training loss: 0.07887299358844757
Validation loss: 1.5323558148517404

Epoch: 5| Step: 9
Training loss: 0.15072481334209442
Validation loss: 1.5415782274738434

Epoch: 5| Step: 10
Training loss: 0.07743891328573227
Validation loss: 1.5624380932059339

Epoch: 569| Step: 0
Training loss: 0.15694069862365723
Validation loss: 1.5118241540847286

Epoch: 5| Step: 1
Training loss: 0.0633394867181778
Validation loss: 1.5298591788097093

Epoch: 5| Step: 2
Training loss: 0.05473555251955986
Validation loss: 1.4972965063587311

Epoch: 5| Step: 3
Training loss: 0.06292041391134262
Validation loss: 1.5056544708949264

Epoch: 5| Step: 4
Training loss: 0.08085528761148453
Validation loss: 1.4751630867681196

Epoch: 5| Step: 5
Training loss: 0.0740625411272049
Validation loss: 1.4536926977096065

Epoch: 5| Step: 6
Training loss: 0.08526957035064697
Validation loss: 1.4632771425349738

Epoch: 5| Step: 7
Training loss: 0.04258427768945694
Validation loss: 1.4625922633755593

Epoch: 5| Step: 8
Training loss: 0.10669825971126556
Validation loss: 1.468720091286526

Epoch: 5| Step: 9
Training loss: 0.05123100429773331
Validation loss: 1.4417313965418006

Epoch: 5| Step: 10
Training loss: 0.07947403192520142
Validation loss: 1.4013747169125466

Epoch: 570| Step: 0
Training loss: 0.05786997079849243
Validation loss: 1.4135320250706007

Epoch: 5| Step: 1
Training loss: 0.06939826905727386
Validation loss: 1.4099140423600391

Epoch: 5| Step: 2
Training loss: 0.08429203182458878
Validation loss: 1.407154235788571

Epoch: 5| Step: 3
Training loss: 0.06816982477903366
Validation loss: 1.4165294144743232

Epoch: 5| Step: 4
Training loss: 0.0630020946264267
Validation loss: 1.4348398306036507

Epoch: 5| Step: 5
Training loss: 0.05461934208869934
Validation loss: 1.4118551400399977

Epoch: 5| Step: 6
Training loss: 0.16070762276649475
Validation loss: 1.456924053930467

Epoch: 5| Step: 7
Training loss: 0.05832244083285332
Validation loss: 1.4260147425436205

Epoch: 5| Step: 8
Training loss: 0.11729345470666885
Validation loss: 1.479681496979088

Epoch: 5| Step: 9
Training loss: 0.05914611741900444
Validation loss: 1.4561062717950473

Epoch: 5| Step: 10
Training loss: 0.052264921367168427
Validation loss: 1.4681135249394242

Epoch: 571| Step: 0
Training loss: 0.06703747808933258
Validation loss: 1.5154510595465218

Epoch: 5| Step: 1
Training loss: 0.040082305669784546
Validation loss: 1.4676428366732854

Epoch: 5| Step: 2
Training loss: 0.06173587590456009
Validation loss: 1.501418887927968

Epoch: 5| Step: 3
Training loss: 0.08679504692554474
Validation loss: 1.521972797250235

Epoch: 5| Step: 4
Training loss: 0.06763040274381638
Validation loss: 1.5016527560449415

Epoch: 5| Step: 5
Training loss: 0.09216324985027313
Validation loss: 1.5043133638238395

Epoch: 5| Step: 6
Training loss: 0.056354451924562454
Validation loss: 1.5123675164356027

Epoch: 5| Step: 7
Training loss: 0.08910774439573288
Validation loss: 1.505410171324207

Epoch: 5| Step: 8
Training loss: 0.15517541766166687
Validation loss: 1.5170096274345153

Epoch: 5| Step: 9
Training loss: 0.06539218127727509
Validation loss: 1.5142180112100416

Epoch: 5| Step: 10
Training loss: 0.041469674557447433
Validation loss: 1.5050672766982869

Epoch: 572| Step: 0
Training loss: 0.05404524877667427
Validation loss: 1.5039938784414721

Epoch: 5| Step: 1
Training loss: 0.06433318555355072
Validation loss: 1.5066896279652913

Epoch: 5| Step: 2
Training loss: 0.0799613669514656
Validation loss: 1.4973605781473138

Epoch: 5| Step: 3
Training loss: 0.054814111441373825
Validation loss: 1.4834852398082774

Epoch: 5| Step: 4
Training loss: 0.06634695827960968
Validation loss: 1.4911778396175754

Epoch: 5| Step: 5
Training loss: 0.10879160463809967
Validation loss: 1.4967034523205092

Epoch: 5| Step: 6
Training loss: 0.05903736501932144
Validation loss: 1.4956183984715452

Epoch: 5| Step: 7
Training loss: 0.03249729424715042
Validation loss: 1.4909771873104958

Epoch: 5| Step: 8
Training loss: 0.1505163013935089
Validation loss: 1.4914814938781082

Epoch: 5| Step: 9
Training loss: 0.06808002293109894
Validation loss: 1.466159551374374

Epoch: 5| Step: 10
Training loss: 0.06482753902673721
Validation loss: 1.4654354331313924

Epoch: 573| Step: 0
Training loss: 0.21426033973693848
Validation loss: 1.4721753981805616

Epoch: 5| Step: 1
Training loss: 0.07086790353059769
Validation loss: 1.4533803155345302

Epoch: 5| Step: 2
Training loss: 0.07983538508415222
Validation loss: 1.476230962302095

Epoch: 5| Step: 3
Training loss: 0.08589403331279755
Validation loss: 1.4479840070970598

Epoch: 5| Step: 4
Training loss: 0.07975400239229202
Validation loss: 1.4944594662676576

Epoch: 5| Step: 5
Training loss: 0.051760513335466385
Validation loss: 1.5005634728298392

Epoch: 5| Step: 6
Training loss: 0.07072939723730087
Validation loss: 1.4846109651750135

Epoch: 5| Step: 7
Training loss: 0.06817831099033356
Validation loss: 1.488740518528928

Epoch: 5| Step: 8
Training loss: 0.05495382472872734
Validation loss: 1.5445934264890608

Epoch: 5| Step: 9
Training loss: 0.08121953904628754
Validation loss: 1.507259976479315

Epoch: 5| Step: 10
Training loss: 0.07244568318128586
Validation loss: 1.5063074199102258

Epoch: 574| Step: 0
Training loss: 0.054142214357852936
Validation loss: 1.4925930333393875

Epoch: 5| Step: 1
Training loss: 0.047326087951660156
Validation loss: 1.502591577909326

Epoch: 5| Step: 2
Training loss: 0.05125995725393295
Validation loss: 1.5011398907630675

Epoch: 5| Step: 3
Training loss: 0.05360638350248337
Validation loss: 1.500314998370345

Epoch: 5| Step: 4
Training loss: 0.07689885795116425
Validation loss: 1.4978259455773137

Epoch: 5| Step: 5
Training loss: 0.0462757907807827
Validation loss: 1.475645060180336

Epoch: 5| Step: 6
Training loss: 0.0952586680650711
Validation loss: 1.4412750761996034

Epoch: 5| Step: 7
Training loss: 0.1455899029970169
Validation loss: 1.451623502598014

Epoch: 5| Step: 8
Training loss: 0.05554727464914322
Validation loss: 1.5006689999693184

Epoch: 5| Step: 9
Training loss: 0.07634707540273666
Validation loss: 1.5131013649766163

Epoch: 5| Step: 10
Training loss: 0.12381803244352341
Validation loss: 1.5281583416846491

Epoch: 575| Step: 0
Training loss: 0.09214364737272263
Validation loss: 1.5070606444471626

Epoch: 5| Step: 1
Training loss: 0.07565856724977493
Validation loss: 1.5242495312485644

Epoch: 5| Step: 2
Training loss: 0.06891737878322601
Validation loss: 1.485435297412257

Epoch: 5| Step: 3
Training loss: 0.08877982199192047
Validation loss: 1.4692963823195426

Epoch: 5| Step: 4
Training loss: 0.07547182589769363
Validation loss: 1.4458248384537236

Epoch: 5| Step: 5
Training loss: 0.04902193695306778
Validation loss: 1.4523044529781546

Epoch: 5| Step: 6
Training loss: 0.10196483135223389
Validation loss: 1.504619759898032

Epoch: 5| Step: 7
Training loss: 0.08410284668207169
Validation loss: 1.474111988980283

Epoch: 5| Step: 8
Training loss: 0.11732210218906403
Validation loss: 1.4662653707688855

Epoch: 5| Step: 9
Training loss: 0.15498225390911102
Validation loss: 1.4686208437847834

Epoch: 5| Step: 10
Training loss: 0.08324209600687027
Validation loss: 1.4771702058853642

Epoch: 576| Step: 0
Training loss: 0.14170905947685242
Validation loss: 1.509218790197885

Epoch: 5| Step: 1
Training loss: 0.07276028394699097
Validation loss: 1.5454985146881433

Epoch: 5| Step: 2
Training loss: 0.0979885533452034
Validation loss: 1.6067408413015387

Epoch: 5| Step: 3
Training loss: 0.0989246517419815
Validation loss: 1.6009926924141504

Epoch: 5| Step: 4
Training loss: 0.113522969186306
Validation loss: 1.5852552280631116

Epoch: 5| Step: 5
Training loss: 0.05414693430066109
Validation loss: 1.5737641075605988

Epoch: 5| Step: 6
Training loss: 0.10734443366527557
Validation loss: 1.539715438760737

Epoch: 5| Step: 7
Training loss: 0.10741573572158813
Validation loss: 1.504763028954947

Epoch: 5| Step: 8
Training loss: 0.10999419540166855
Validation loss: 1.4967525312977452

Epoch: 5| Step: 9
Training loss: 0.07244428992271423
Validation loss: 1.4547710751974454

Epoch: 5| Step: 10
Training loss: 0.108939029276371
Validation loss: 1.4279301736944465

Epoch: 577| Step: 0
Training loss: 0.0950109213590622
Validation loss: 1.4735508516270628

Epoch: 5| Step: 1
Training loss: 0.055076420307159424
Validation loss: 1.4632185018190773

Epoch: 5| Step: 2
Training loss: 0.08623292297124863
Validation loss: 1.4772821293082288

Epoch: 5| Step: 3
Training loss: 0.12183346599340439
Validation loss: 1.477876854199235

Epoch: 5| Step: 4
Training loss: 0.1429212987422943
Validation loss: 1.4836737058495963

Epoch: 5| Step: 5
Training loss: 0.12688222527503967
Validation loss: 1.489367123573057

Epoch: 5| Step: 6
Training loss: 0.061082273721694946
Validation loss: 1.5060069791732296

Epoch: 5| Step: 7
Training loss: 0.1109689325094223
Validation loss: 1.5182753609072777

Epoch: 5| Step: 8
Training loss: 0.10903970152139664
Validation loss: 1.5469189920733053

Epoch: 5| Step: 9
Training loss: 0.06470324099063873
Validation loss: 1.564118739097349

Epoch: 5| Step: 10
Training loss: 0.09456262737512589
Validation loss: 1.505769270722584

Epoch: 578| Step: 0
Training loss: 0.05850701779127121
Validation loss: 1.5020746864298338

Epoch: 5| Step: 1
Training loss: 0.07001713663339615
Validation loss: 1.4888969941805767

Epoch: 5| Step: 2
Training loss: 0.08954570442438126
Validation loss: 1.5128858384265695

Epoch: 5| Step: 3
Training loss: 0.07057739794254303
Validation loss: 1.487627685710948

Epoch: 5| Step: 4
Training loss: 0.08966901898384094
Validation loss: 1.4886367051832137

Epoch: 5| Step: 5
Training loss: 0.15696890652179718
Validation loss: 1.489512692215622

Epoch: 5| Step: 6
Training loss: 0.0851636752486229
Validation loss: 1.4608963266495736

Epoch: 5| Step: 7
Training loss: 0.07888589054346085
Validation loss: 1.4817832464812903

Epoch: 5| Step: 8
Training loss: 0.08064129948616028
Validation loss: 1.510552324274535

Epoch: 5| Step: 9
Training loss: 0.06359270215034485
Validation loss: 1.5269191188196982

Epoch: 5| Step: 10
Training loss: 0.10626426339149475
Validation loss: 1.5344835353154007

Epoch: 579| Step: 0
Training loss: 0.0584038607776165
Validation loss: 1.5218154666244343

Epoch: 5| Step: 1
Training loss: 0.056271087378263474
Validation loss: 1.5255293570539004

Epoch: 5| Step: 2
Training loss: 0.13839809596538544
Validation loss: 1.5124467918949742

Epoch: 5| Step: 3
Training loss: 0.09606398642063141
Validation loss: 1.5023917536581717

Epoch: 5| Step: 4
Training loss: 0.10225246846675873
Validation loss: 1.5049496690432231

Epoch: 5| Step: 5
Training loss: 0.10813052952289581
Validation loss: 1.503164017072288

Epoch: 5| Step: 6
Training loss: 0.09625311195850372
Validation loss: 1.4984720983812887

Epoch: 5| Step: 7
Training loss: 0.0756579041481018
Validation loss: 1.4762237136081984

Epoch: 5| Step: 8
Training loss: 0.0830458402633667
Validation loss: 1.4659319923770042

Epoch: 5| Step: 9
Training loss: 0.08790914714336395
Validation loss: 1.4490001631039444

Epoch: 5| Step: 10
Training loss: 0.061862848699092865
Validation loss: 1.4651878187733312

Epoch: 580| Step: 0
Training loss: 0.1268129199743271
Validation loss: 1.4456459963193504

Epoch: 5| Step: 1
Training loss: 0.06084059923887253
Validation loss: 1.4256094630046556

Epoch: 5| Step: 2
Training loss: 0.0717843621969223
Validation loss: 1.4464435603028984

Epoch: 5| Step: 3
Training loss: 0.10575523227453232
Validation loss: 1.4595216397316224

Epoch: 5| Step: 4
Training loss: 0.10268620401620865
Validation loss: 1.4531935081687024

Epoch: 5| Step: 5
Training loss: 0.06454475969076157
Validation loss: 1.4508495971720705

Epoch: 5| Step: 6
Training loss: 0.08032853901386261
Validation loss: 1.4933409633175019

Epoch: 5| Step: 7
Training loss: 0.05573171377182007
Validation loss: 1.4877688384825183

Epoch: 5| Step: 8
Training loss: 0.073332779109478
Validation loss: 1.474012613937419

Epoch: 5| Step: 9
Training loss: 0.19105535745620728
Validation loss: 1.4953288455163278

Epoch: 5| Step: 10
Training loss: 0.04844670370221138
Validation loss: 1.469875915076143

Epoch: 581| Step: 0
Training loss: 0.0686996728181839
Validation loss: 1.4686709706501295

Epoch: 5| Step: 1
Training loss: 0.13549470901489258
Validation loss: 1.453590436648297

Epoch: 5| Step: 2
Training loss: 0.060418762266635895
Validation loss: 1.4601055165772796

Epoch: 5| Step: 3
Training loss: 0.09063426405191422
Validation loss: 1.4901921672205771

Epoch: 5| Step: 4
Training loss: 0.07712648063898087
Validation loss: 1.4828222631126322

Epoch: 5| Step: 5
Training loss: 0.06007592752575874
Validation loss: 1.4964601942287978

Epoch: 5| Step: 6
Training loss: 0.07869435101747513
Validation loss: 1.476227121968423

Epoch: 5| Step: 7
Training loss: 0.07624165713787079
Validation loss: 1.4956964491516032

Epoch: 5| Step: 8
Training loss: 0.10838770866394043
Validation loss: 1.470610595518543

Epoch: 5| Step: 9
Training loss: 0.09549194574356079
Validation loss: 1.5086965304549023

Epoch: 5| Step: 10
Training loss: 0.05816088244318962
Validation loss: 1.5197854503508537

Epoch: 582| Step: 0
Training loss: 0.05832044407725334
Validation loss: 1.510187174684258

Epoch: 5| Step: 1
Training loss: 0.07527869939804077
Validation loss: 1.54683421632295

Epoch: 5| Step: 2
Training loss: 0.07337427139282227
Validation loss: 1.5240086599062848

Epoch: 5| Step: 3
Training loss: 0.08568446338176727
Validation loss: 1.4840253822265133

Epoch: 5| Step: 4
Training loss: 0.08448819816112518
Validation loss: 1.5187672479178316

Epoch: 5| Step: 5
Training loss: 0.18222814798355103
Validation loss: 1.525784824484138

Epoch: 5| Step: 6
Training loss: 0.10275980085134506
Validation loss: 1.4856658212600216

Epoch: 5| Step: 7
Training loss: 0.07637394964694977
Validation loss: 1.473912921003116

Epoch: 5| Step: 8
Training loss: 0.08172665536403656
Validation loss: 1.4675411569174899

Epoch: 5| Step: 9
Training loss: 0.05744742229580879
Validation loss: 1.4687019881381784

Epoch: 5| Step: 10
Training loss: 0.10848676413297653
Validation loss: 1.4882298528507192

Epoch: 583| Step: 0
Training loss: 0.0909571573138237
Validation loss: 1.4656681899101502

Epoch: 5| Step: 1
Training loss: 0.14105696976184845
Validation loss: 1.470540105655629

Epoch: 5| Step: 2
Training loss: 0.07689756155014038
Validation loss: 1.4547982805518693

Epoch: 5| Step: 3
Training loss: 0.05404387041926384
Validation loss: 1.4402703521072224

Epoch: 5| Step: 4
Training loss: 0.07305536419153214
Validation loss: 1.454908590162954

Epoch: 5| Step: 5
Training loss: 0.07016211003065109
Validation loss: 1.4747206370035808

Epoch: 5| Step: 6
Training loss: 0.0691002830862999
Validation loss: 1.450461765771271

Epoch: 5| Step: 7
Training loss: 0.07755261659622192
Validation loss: 1.4631188646439584

Epoch: 5| Step: 8
Training loss: 0.0852084532380104
Validation loss: 1.4836158316622499

Epoch: 5| Step: 9
Training loss: 0.07446615397930145
Validation loss: 1.4725293651703866

Epoch: 5| Step: 10
Training loss: 0.09972544759511948
Validation loss: 1.4797078640230241

Epoch: 584| Step: 0
Training loss: 0.0845048576593399
Validation loss: 1.4693872274891022

Epoch: 5| Step: 1
Training loss: 0.0835658609867096
Validation loss: 1.4416728981079594

Epoch: 5| Step: 2
Training loss: 0.07281576097011566
Validation loss: 1.4521921885910856

Epoch: 5| Step: 3
Training loss: 0.046569980680942535
Validation loss: 1.420330464199025

Epoch: 5| Step: 4
Training loss: 0.07754442095756531
Validation loss: 1.4427316951495346

Epoch: 5| Step: 5
Training loss: 0.07061152905225754
Validation loss: 1.4565580134750695

Epoch: 5| Step: 6
Training loss: 0.10589244216680527
Validation loss: 1.4522364549739386

Epoch: 5| Step: 7
Training loss: 0.0933128148317337
Validation loss: 1.4635075189734017

Epoch: 5| Step: 8
Training loss: 0.1855829805135727
Validation loss: 1.4937705096378122

Epoch: 5| Step: 9
Training loss: 0.08810243755578995
Validation loss: 1.4951312234324794

Epoch: 5| Step: 10
Training loss: 0.051421571522951126
Validation loss: 1.500110101956193

Epoch: 585| Step: 0
Training loss: 0.19966275990009308
Validation loss: 1.5177247357624832

Epoch: 5| Step: 1
Training loss: 0.07160825282335281
Validation loss: 1.470050851504008

Epoch: 5| Step: 2
Training loss: 0.08709178119897842
Validation loss: 1.4725645421653666

Epoch: 5| Step: 3
Training loss: 0.050805818289518356
Validation loss: 1.4669170174547421

Epoch: 5| Step: 4
Training loss: 0.07825830578804016
Validation loss: 1.4595587240752352

Epoch: 5| Step: 5
Training loss: 0.04082120582461357
Validation loss: 1.4804248604723202

Epoch: 5| Step: 6
Training loss: 0.07506964355707169
Validation loss: 1.4892524198819233

Epoch: 5| Step: 7
Training loss: 0.07446104288101196
Validation loss: 1.457091586564177

Epoch: 5| Step: 8
Training loss: 0.12029097229242325
Validation loss: 1.488721465551725

Epoch: 5| Step: 9
Training loss: 0.059751175343990326
Validation loss: 1.4699438848803121

Epoch: 5| Step: 10
Training loss: 0.05339692160487175
Validation loss: 1.4600515532237228

Epoch: 586| Step: 0
Training loss: 0.04740133509039879
Validation loss: 1.4868397738343926

Epoch: 5| Step: 1
Training loss: 0.05569876357913017
Validation loss: 1.473080115933572

Epoch: 5| Step: 2
Training loss: 0.14106900990009308
Validation loss: 1.4783698358843405

Epoch: 5| Step: 3
Training loss: 0.07546542584896088
Validation loss: 1.4469537722167147

Epoch: 5| Step: 4
Training loss: 0.09591151773929596
Validation loss: 1.4517602420622302

Epoch: 5| Step: 5
Training loss: 0.09362424910068512
Validation loss: 1.4707178146608415

Epoch: 5| Step: 6
Training loss: 0.07907810062170029
Validation loss: 1.492512531177972

Epoch: 5| Step: 7
Training loss: 0.08891948312520981
Validation loss: 1.4663121059376707

Epoch: 5| Step: 8
Training loss: 0.07641420513391495
Validation loss: 1.458797489443133

Epoch: 5| Step: 9
Training loss: 0.04168787598609924
Validation loss: 1.4840664312403689

Epoch: 5| Step: 10
Training loss: 0.048491645604372025
Validation loss: 1.5143826533389348

Epoch: 587| Step: 0
Training loss: 0.08662570267915726
Validation loss: 1.5117318425127255

Epoch: 5| Step: 1
Training loss: 0.07789447903633118
Validation loss: 1.5118559829650386

Epoch: 5| Step: 2
Training loss: 0.16801850497722626
Validation loss: 1.50668034374073

Epoch: 5| Step: 3
Training loss: 0.07184701412916183
Validation loss: 1.498220887235416

Epoch: 5| Step: 4
Training loss: 0.06387335807085037
Validation loss: 1.4950658211144068

Epoch: 5| Step: 5
Training loss: 0.041721779853105545
Validation loss: 1.5453158296564573

Epoch: 5| Step: 6
Training loss: 0.08505537360906601
Validation loss: 1.5104748561818113

Epoch: 5| Step: 7
Training loss: 0.0846291035413742
Validation loss: 1.5683965106164255

Epoch: 5| Step: 8
Training loss: 0.06808365881443024
Validation loss: 1.5437563068123275

Epoch: 5| Step: 9
Training loss: 0.0736231654882431
Validation loss: 1.4932685411104591

Epoch: 5| Step: 10
Training loss: 0.10487610101699829
Validation loss: 1.4768764165139967

Epoch: 588| Step: 0
Training loss: 0.08740223944187164
Validation loss: 1.5177285812234367

Epoch: 5| Step: 1
Training loss: 0.08687102049589157
Validation loss: 1.4791873123056145

Epoch: 5| Step: 2
Training loss: 0.09529919922351837
Validation loss: 1.4644255715031778

Epoch: 5| Step: 3
Training loss: 0.06788717210292816
Validation loss: 1.435940928997532

Epoch: 5| Step: 4
Training loss: 0.1700122207403183
Validation loss: 1.4614572037932694

Epoch: 5| Step: 5
Training loss: 0.06470923125743866
Validation loss: 1.4416702267944173

Epoch: 5| Step: 6
Training loss: 0.07649610936641693
Validation loss: 1.436809419303812

Epoch: 5| Step: 7
Training loss: 0.06305167078971863
Validation loss: 1.4735276352974676

Epoch: 5| Step: 8
Training loss: 0.10219557583332062
Validation loss: 1.474693174003273

Epoch: 5| Step: 9
Training loss: 0.08700200170278549
Validation loss: 1.4870403710231985

Epoch: 5| Step: 10
Training loss: 0.09911701083183289
Validation loss: 1.5545459588368733

Epoch: 589| Step: 0
Training loss: 0.06297514587640762
Validation loss: 1.52990113535235

Epoch: 5| Step: 1
Training loss: 0.1137792319059372
Validation loss: 1.511444059751367

Epoch: 5| Step: 2
Training loss: 0.15899424254894257
Validation loss: 1.5004140330899147

Epoch: 5| Step: 3
Training loss: 0.04872041940689087
Validation loss: 1.505583063248665

Epoch: 5| Step: 4
Training loss: 0.07028773427009583
Validation loss: 1.5377537460737332

Epoch: 5| Step: 5
Training loss: 0.09477376192808151
Validation loss: 1.5224712503853666

Epoch: 5| Step: 6
Training loss: 0.09018536657094955
Validation loss: 1.5028980496109172

Epoch: 5| Step: 7
Training loss: 0.0964098647236824
Validation loss: 1.489691444622573

Epoch: 5| Step: 8
Training loss: 0.07417480647563934
Validation loss: 1.470814077443974

Epoch: 5| Step: 9
Training loss: 0.07578208297491074
Validation loss: 1.4705634283763107

Epoch: 5| Step: 10
Training loss: 0.07177500426769257
Validation loss: 1.4566371287069013

Epoch: 590| Step: 0
Training loss: 0.10353841632604599
Validation loss: 1.4614120888453659

Epoch: 5| Step: 1
Training loss: 0.11153928935527802
Validation loss: 1.4419580839013542

Epoch: 5| Step: 2
Training loss: 0.07243531942367554
Validation loss: 1.4471083123196837

Epoch: 5| Step: 3
Training loss: 0.08888832479715347
Validation loss: 1.4551973842805432

Epoch: 5| Step: 4
Training loss: 0.0794321745634079
Validation loss: 1.4837890401963265

Epoch: 5| Step: 5
Training loss: 0.09951458871364594
Validation loss: 1.493541491928921

Epoch: 5| Step: 6
Training loss: 0.10274761915206909
Validation loss: 1.5042993791641728

Epoch: 5| Step: 7
Training loss: 0.07393722236156464
Validation loss: 1.5461873726178241

Epoch: 5| Step: 8
Training loss: 0.09115619957447052
Validation loss: 1.5380464894797212

Epoch: 5| Step: 9
Training loss: 0.08549553155899048
Validation loss: 1.5332518700630433

Epoch: 5| Step: 10
Training loss: 0.19971993565559387
Validation loss: 1.5045867543066702

Epoch: 591| Step: 0
Training loss: 0.061997514218091965
Validation loss: 1.441675002216011

Epoch: 5| Step: 1
Training loss: 0.06658248603343964
Validation loss: 1.4025221652882074

Epoch: 5| Step: 2
Training loss: 0.08626286685466766
Validation loss: 1.4038383371086531

Epoch: 5| Step: 3
Training loss: 0.10367168486118317
Validation loss: 1.3588567728637366

Epoch: 5| Step: 4
Training loss: 0.178996279835701
Validation loss: 1.3687519258068455

Epoch: 5| Step: 5
Training loss: 0.08915461599826813
Validation loss: 1.3879881610152542

Epoch: 5| Step: 6
Training loss: 0.08561155945062637
Validation loss: 1.3950873972267233

Epoch: 5| Step: 7
Training loss: 0.08313541114330292
Validation loss: 1.448580332981643

Epoch: 5| Step: 8
Training loss: 0.10206592082977295
Validation loss: 1.4733613691022318

Epoch: 5| Step: 9
Training loss: 0.06446520239114761
Validation loss: 1.4847277620787263

Epoch: 5| Step: 10
Training loss: 0.09103087335824966
Validation loss: 1.4936894921846287

Epoch: 592| Step: 0
Training loss: 0.07057821750640869
Validation loss: 1.4825937145499772

Epoch: 5| Step: 1
Training loss: 0.08212457597255707
Validation loss: 1.4923274337604482

Epoch: 5| Step: 2
Training loss: 0.09108266979455948
Validation loss: 1.4778746430591871

Epoch: 5| Step: 3
Training loss: 0.08531641960144043
Validation loss: 1.4453447018900225

Epoch: 5| Step: 4
Training loss: 0.06743629276752472
Validation loss: 1.4498127083624563

Epoch: 5| Step: 5
Training loss: 0.07960382848978043
Validation loss: 1.4075396951808725

Epoch: 5| Step: 6
Training loss: 0.050794728100299835
Validation loss: 1.4031712803789365

Epoch: 5| Step: 7
Training loss: 0.09077674150466919
Validation loss: 1.4211560180110316

Epoch: 5| Step: 8
Training loss: 0.05048632621765137
Validation loss: 1.3899826285659627

Epoch: 5| Step: 9
Training loss: 0.15346014499664307
Validation loss: 1.4427281156662972

Epoch: 5| Step: 10
Training loss: 0.052627209573984146
Validation loss: 1.451828190075454

Epoch: 593| Step: 0
Training loss: 0.07379434257745743
Validation loss: 1.4583810676810562

Epoch: 5| Step: 1
Training loss: 0.03889608755707741
Validation loss: 1.4803844023776311

Epoch: 5| Step: 2
Training loss: 0.06368477642536163
Validation loss: 1.4673296661787136

Epoch: 5| Step: 3
Training loss: 0.04582444578409195
Validation loss: 1.516714894643394

Epoch: 5| Step: 4
Training loss: 0.09842514991760254
Validation loss: 1.4976665114843717

Epoch: 5| Step: 5
Training loss: 0.06069467216730118
Validation loss: 1.5058736974193203

Epoch: 5| Step: 6
Training loss: 0.07214745134115219
Validation loss: 1.468916622541284

Epoch: 5| Step: 7
Training loss: 0.09048370271921158
Validation loss: 1.4835434421416251

Epoch: 5| Step: 8
Training loss: 0.0651516318321228
Validation loss: 1.4581895259118849

Epoch: 5| Step: 9
Training loss: 0.14229288697242737
Validation loss: 1.4429115582537908

Epoch: 5| Step: 10
Training loss: 0.041026562452316284
Validation loss: 1.4428635938193208

Epoch: 594| Step: 0
Training loss: 0.05556485801935196
Validation loss: 1.455891837355911

Epoch: 5| Step: 1
Training loss: 0.06492029130458832
Validation loss: 1.4574813688955

Epoch: 5| Step: 2
Training loss: 0.05109412595629692
Validation loss: 1.4799715639442526

Epoch: 5| Step: 3
Training loss: 0.08199314773082733
Validation loss: 1.4767833781498734

Epoch: 5| Step: 4
Training loss: 0.05965358763933182
Validation loss: 1.4878487253701815

Epoch: 5| Step: 5
Training loss: 0.07221324741840363
Validation loss: 1.494226009615006

Epoch: 5| Step: 6
Training loss: 0.06787681579589844
Validation loss: 1.5017080717189337

Epoch: 5| Step: 7
Training loss: 0.05837070941925049
Validation loss: 1.4929742582382695

Epoch: 5| Step: 8
Training loss: 0.07008703798055649
Validation loss: 1.4962063412512503

Epoch: 5| Step: 9
Training loss: 0.14388632774353027
Validation loss: 1.5023231378165625

Epoch: 5| Step: 10
Training loss: 0.062451522797346115
Validation loss: 1.5086118841683993

Epoch: 595| Step: 0
Training loss: 0.0379151813685894
Validation loss: 1.49269022351952

Epoch: 5| Step: 1
Training loss: 0.03223472461104393
Validation loss: 1.5104246652254494

Epoch: 5| Step: 2
Training loss: 0.04474315419793129
Validation loss: 1.4835911002210391

Epoch: 5| Step: 3
Training loss: 0.08198554813861847
Validation loss: 1.5313586701628983

Epoch: 5| Step: 4
Training loss: 0.05846273899078369
Validation loss: 1.5171580417181856

Epoch: 5| Step: 5
Training loss: 0.06609601527452469
Validation loss: 1.4980052337851575

Epoch: 5| Step: 6
Training loss: 0.20256826281547546
Validation loss: 1.5236683981392973

Epoch: 5| Step: 7
Training loss: 0.06176324933767319
Validation loss: 1.4956272827681674

Epoch: 5| Step: 8
Training loss: 0.08273342251777649
Validation loss: 1.453632225272476

Epoch: 5| Step: 9
Training loss: 0.07956240326166153
Validation loss: 1.494403668629226

Epoch: 5| Step: 10
Training loss: 0.06304190307855606
Validation loss: 1.4748062183780055

Epoch: 596| Step: 0
Training loss: 0.059907495975494385
Validation loss: 1.4689770911329536

Epoch: 5| Step: 1
Training loss: 0.058643948286771774
Validation loss: 1.4868763146861907

Epoch: 5| Step: 2
Training loss: 0.06843049079179764
Validation loss: 1.4658344509781047

Epoch: 5| Step: 3
Training loss: 0.06432639062404633
Validation loss: 1.4685095535811556

Epoch: 5| Step: 4
Training loss: 0.14352110028266907
Validation loss: 1.4862419072017874

Epoch: 5| Step: 5
Training loss: 0.09146866947412491
Validation loss: 1.503026068851512

Epoch: 5| Step: 6
Training loss: 0.08407825231552124
Validation loss: 1.4851130516298356

Epoch: 5| Step: 7
Training loss: 0.04986361786723137
Validation loss: 1.520101898459978

Epoch: 5| Step: 8
Training loss: 0.09009154140949249
Validation loss: 1.4746896246428132

Epoch: 5| Step: 9
Training loss: 0.05978964641690254
Validation loss: 1.4944511728902017

Epoch: 5| Step: 10
Training loss: 0.06355944275856018
Validation loss: 1.4468484501684866

Epoch: 597| Step: 0
Training loss: 0.08253206312656403
Validation loss: 1.4834264452739427

Epoch: 5| Step: 1
Training loss: 0.06032703444361687
Validation loss: 1.4855041773088518

Epoch: 5| Step: 2
Training loss: 0.0867772325873375
Validation loss: 1.4838543604778986

Epoch: 5| Step: 3
Training loss: 0.05012793466448784
Validation loss: 1.4883426671387048

Epoch: 5| Step: 4
Training loss: 0.07830512523651123
Validation loss: 1.4809392959840837

Epoch: 5| Step: 5
Training loss: 0.06329735368490219
Validation loss: 1.4667139463527228

Epoch: 5| Step: 6
Training loss: 0.05995083600282669
Validation loss: 1.4533503388845792

Epoch: 5| Step: 7
Training loss: 0.14491212368011475
Validation loss: 1.4522458814805554

Epoch: 5| Step: 8
Training loss: 0.07003698498010635
Validation loss: 1.4501685891100156

Epoch: 5| Step: 9
Training loss: 0.07136552035808563
Validation loss: 1.448525769095267

Epoch: 5| Step: 10
Training loss: 0.09217756986618042
Validation loss: 1.4401841484090334

Epoch: 598| Step: 0
Training loss: 0.07423753291368484
Validation loss: 1.4591275389476488

Epoch: 5| Step: 1
Training loss: 0.050831519067287445
Validation loss: 1.4567250795261835

Epoch: 5| Step: 2
Training loss: 0.05936546251177788
Validation loss: 1.4556170804526216

Epoch: 5| Step: 3
Training loss: 0.06450019776821136
Validation loss: 1.452519008549311

Epoch: 5| Step: 4
Training loss: 0.05708625167608261
Validation loss: 1.4589900252639607

Epoch: 5| Step: 5
Training loss: 0.07493887841701508
Validation loss: 1.5005619449000205

Epoch: 5| Step: 6
Training loss: 0.04204676300287247
Validation loss: 1.4913026376437115

Epoch: 5| Step: 7
Training loss: 0.08629719913005829
Validation loss: 1.4806303369101657

Epoch: 5| Step: 8
Training loss: 0.08051947504281998
Validation loss: 1.4995588756376697

Epoch: 5| Step: 9
Training loss: 0.11938150972127914
Validation loss: 1.5230063751179685

Epoch: 5| Step: 10
Training loss: 0.0782003104686737
Validation loss: 1.4873816069736276

Epoch: 599| Step: 0
Training loss: 0.05525099113583565
Validation loss: 1.4865002593686503

Epoch: 5| Step: 1
Training loss: 0.07441546767950058
Validation loss: 1.4656536438131844

Epoch: 5| Step: 2
Training loss: 0.06716571748256683
Validation loss: 1.4587229259552494

Epoch: 5| Step: 3
Training loss: 0.058672595769166946
Validation loss: 1.4995527805820588

Epoch: 5| Step: 4
Training loss: 0.08748506009578705
Validation loss: 1.4488688989352154

Epoch: 5| Step: 5
Training loss: 0.05679553002119064
Validation loss: 1.4642175320656068

Epoch: 5| Step: 6
Training loss: 0.10175836086273193
Validation loss: 1.4552812807021602

Epoch: 5| Step: 7
Training loss: 0.07103902846574783
Validation loss: 1.4518519114422541

Epoch: 5| Step: 8
Training loss: 0.06205790117383003
Validation loss: 1.472479579269245

Epoch: 5| Step: 9
Training loss: 0.18074142932891846
Validation loss: 1.4258869796670892

Epoch: 5| Step: 10
Training loss: 0.04308612272143364
Validation loss: 1.4153319956153951

Epoch: 600| Step: 0
Training loss: 0.07161351293325424
Validation loss: 1.4341370239052722

Epoch: 5| Step: 1
Training loss: 0.09307391941547394
Validation loss: 1.4376198181542017

Epoch: 5| Step: 2
Training loss: 0.04966890066862106
Validation loss: 1.4403444951580417

Epoch: 5| Step: 3
Training loss: 0.1032678484916687
Validation loss: 1.457788714798548

Epoch: 5| Step: 4
Training loss: 0.06714968383312225
Validation loss: 1.4657111693454046

Epoch: 5| Step: 5
Training loss: 0.14850009977817535
Validation loss: 1.4527204869895853

Epoch: 5| Step: 6
Training loss: 0.07418011128902435
Validation loss: 1.4481168216274631

Epoch: 5| Step: 7
Training loss: 0.07155533879995346
Validation loss: 1.4636817132273028

Epoch: 5| Step: 8
Training loss: 0.06888328492641449
Validation loss: 1.4649119556591075

Epoch: 5| Step: 9
Training loss: 0.05065352842211723
Validation loss: 1.4592969443208428

Epoch: 5| Step: 10
Training loss: 0.048346146941185
Validation loss: 1.4707794804726877

Testing loss: 2.0200079679489136
