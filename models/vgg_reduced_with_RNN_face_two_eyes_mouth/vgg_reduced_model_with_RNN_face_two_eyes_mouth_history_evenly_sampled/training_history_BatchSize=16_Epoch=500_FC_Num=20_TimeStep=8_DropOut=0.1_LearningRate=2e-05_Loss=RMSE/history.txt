Epoch: 1| Step: 0
Training loss: 5.957625162504293
Validation loss: 5.7519032350032555

Epoch: 6| Step: 1
Training loss: 5.6568812234111165
Validation loss: 5.724722771103611

Epoch: 6| Step: 2
Training loss: 6.440376009655954
Validation loss: 5.698901547465858

Epoch: 6| Step: 3
Training loss: 5.615633307839831
Validation loss: 5.6724581550725075

Epoch: 6| Step: 4
Training loss: 5.12663559284557
Validation loss: 5.64291030574511

Epoch: 6| Step: 5
Training loss: 6.438257857961691
Validation loss: 5.6105235177369615

Epoch: 6| Step: 6
Training loss: 5.931937091290609
Validation loss: 5.572699871413986

Epoch: 6| Step: 7
Training loss: 4.476840291882595
Validation loss: 5.529805564836372

Epoch: 6| Step: 8
Training loss: 5.50577467426646
Validation loss: 5.482843584025807

Epoch: 6| Step: 9
Training loss: 5.210554986780552
Validation loss: 5.43195070503472

Epoch: 6| Step: 10
Training loss: 5.350931261243114
Validation loss: 5.3776035437454075

Epoch: 6| Step: 11
Training loss: 5.625110709902271
Validation loss: 5.318160174716249

Epoch: 6| Step: 12
Training loss: 5.771313515343176
Validation loss: 5.255248755301561

Epoch: 6| Step: 13
Training loss: 3.6916036240222936
Validation loss: 5.190391561919008

Epoch: 2| Step: 0
Training loss: 5.226798059375473
Validation loss: 5.125067291498298

Epoch: 6| Step: 1
Training loss: 4.711743742873836
Validation loss: 5.056134365056537

Epoch: 6| Step: 2
Training loss: 5.652075475773293
Validation loss: 4.9869455493235275

Epoch: 6| Step: 3
Training loss: 4.537055564952108
Validation loss: 4.913270330307451

Epoch: 6| Step: 4
Training loss: 3.904122956043803
Validation loss: 4.8388271777608605

Epoch: 6| Step: 5
Training loss: 4.901098182776672
Validation loss: 4.7620082181980985

Epoch: 6| Step: 6
Training loss: 4.713284794954535
Validation loss: 4.69131004239835

Epoch: 6| Step: 7
Training loss: 5.019003042490345
Validation loss: 4.627706102428077

Epoch: 6| Step: 8
Training loss: 3.9723287951941875
Validation loss: 4.568819116541765

Epoch: 6| Step: 9
Training loss: 3.128834012801428
Validation loss: 4.5142960095608515

Epoch: 6| Step: 10
Training loss: 4.528222486711552
Validation loss: 4.462904935302108

Epoch: 6| Step: 11
Training loss: 5.51989684409352
Validation loss: 4.409954963148849

Epoch: 6| Step: 12
Training loss: 5.588134845622146
Validation loss: 4.3584675901000285

Epoch: 6| Step: 13
Training loss: 4.764680762629895
Validation loss: 4.316798611634639

Epoch: 3| Step: 0
Training loss: 5.652596658507013
Validation loss: 4.281783450726077

Epoch: 6| Step: 1
Training loss: 4.202911031162123
Validation loss: 4.245949508212906

Epoch: 6| Step: 2
Training loss: 4.986185827141143
Validation loss: 4.21301970899602

Epoch: 6| Step: 3
Training loss: 4.0488008018856165
Validation loss: 4.179528508705018

Epoch: 6| Step: 4
Training loss: 3.697190563570465
Validation loss: 4.1487129616979015

Epoch: 6| Step: 5
Training loss: 4.799469783426745
Validation loss: 4.112458906838946

Epoch: 6| Step: 6
Training loss: 4.26309251890069
Validation loss: 4.075250438768119

Epoch: 6| Step: 7
Training loss: 4.764876109831295
Validation loss: 4.039705983037245

Epoch: 6| Step: 8
Training loss: 2.462153155690941
Validation loss: 4.002434516499113

Epoch: 6| Step: 9
Training loss: 3.406729008302648
Validation loss: 3.9676192532116072

Epoch: 6| Step: 10
Training loss: 3.572174054406586
Validation loss: 3.9345269126103903

Epoch: 6| Step: 11
Training loss: 3.0002795724936298
Validation loss: 3.8958207444391237

Epoch: 6| Step: 12
Training loss: 4.2991981468421
Validation loss: 3.8666065849124296

Epoch: 6| Step: 13
Training loss: 5.282696226838037
Validation loss: 3.8369180794258892

Epoch: 4| Step: 0
Training loss: 3.732217588478274
Validation loss: 3.8073790485648944

Epoch: 6| Step: 1
Training loss: 4.879500048307772
Validation loss: 3.7743319444495196

Epoch: 6| Step: 2
Training loss: 4.154266113396922
Validation loss: 3.746291931255569

Epoch: 6| Step: 3
Training loss: 3.274513522991753
Validation loss: 3.733601027953988

Epoch: 6| Step: 4
Training loss: 3.310738725082624
Validation loss: 3.698496210745572

Epoch: 6| Step: 5
Training loss: 3.9206077686468115
Validation loss: 3.683285509529469

Epoch: 6| Step: 6
Training loss: 4.442754938284397
Validation loss: 3.6657919558203225

Epoch: 6| Step: 7
Training loss: 3.223091234848045
Validation loss: 3.6508192312028522

Epoch: 6| Step: 8
Training loss: 4.226052301042601
Validation loss: 3.636522679064787

Epoch: 6| Step: 9
Training loss: 3.1549389826319714
Validation loss: 3.619892441497735

Epoch: 6| Step: 10
Training loss: 4.12544386816437
Validation loss: 3.6053686850567526

Epoch: 6| Step: 11
Training loss: 3.4169409727067155
Validation loss: 3.5940890187509242

Epoch: 6| Step: 12
Training loss: 4.306489155499587
Validation loss: 3.5765852111291156

Epoch: 6| Step: 13
Training loss: 3.0484319376931412
Validation loss: 3.560073155463445

Epoch: 5| Step: 0
Training loss: 4.030320171198939
Validation loss: 3.5409844052002226

Epoch: 6| Step: 1
Training loss: 3.312449184963644
Validation loss: 3.528606471092775

Epoch: 6| Step: 2
Training loss: 4.020330262543349
Validation loss: 3.5179409450293284

Epoch: 6| Step: 3
Training loss: 4.140899994553428
Validation loss: 3.5006293655331

Epoch: 6| Step: 4
Training loss: 4.262791401587376
Validation loss: 3.48135083020621

Epoch: 6| Step: 5
Training loss: 3.3889243084110996
Validation loss: 3.4639199746599996

Epoch: 6| Step: 6
Training loss: 4.243551860335564
Validation loss: 3.4575473936574146

Epoch: 6| Step: 7
Training loss: 4.14133732264667
Validation loss: 3.4471220409367067

Epoch: 6| Step: 8
Training loss: 3.7415414144937738
Validation loss: 3.424068438492898

Epoch: 6| Step: 9
Training loss: 3.55721774752861
Validation loss: 3.4368988913614515

Epoch: 6| Step: 10
Training loss: 2.349204569990408
Validation loss: 3.413743545209453

Epoch: 6| Step: 11
Training loss: 3.7008046795918936
Validation loss: 3.4166095562795618

Epoch: 6| Step: 12
Training loss: 2.8062795726687724
Validation loss: 3.405362351765941

Epoch: 6| Step: 13
Training loss: 2.921230469468219
Validation loss: 3.392002263583351

Epoch: 6| Step: 0
Training loss: 3.394413953714597
Validation loss: 3.373528014068015

Epoch: 6| Step: 1
Training loss: 2.344094009584309
Validation loss: 3.3613588885945163

Epoch: 6| Step: 2
Training loss: 3.7245253907023277
Validation loss: 3.3530932368457336

Epoch: 6| Step: 3
Training loss: 3.902601201115575
Validation loss: 3.3462369692491087

Epoch: 6| Step: 4
Training loss: 3.8485759429872797
Validation loss: 3.323478752772035

Epoch: 6| Step: 5
Training loss: 3.2756418894940285
Validation loss: 3.3093840326479165

Epoch: 6| Step: 6
Training loss: 3.226213265423813
Validation loss: 3.295361330252705

Epoch: 6| Step: 7
Training loss: 2.960497337779501
Validation loss: 3.28515466116428

Epoch: 6| Step: 8
Training loss: 4.199337298471973
Validation loss: 3.2731784126050254

Epoch: 6| Step: 9
Training loss: 3.9285132168507086
Validation loss: 3.2632000725985932

Epoch: 6| Step: 10
Training loss: 3.8708811373405596
Validation loss: 3.25925074941138

Epoch: 6| Step: 11
Training loss: 3.8490322382967586
Validation loss: 3.2428233545519234

Epoch: 6| Step: 12
Training loss: 3.149583025990879
Validation loss: 3.244188765893628

Epoch: 6| Step: 13
Training loss: 3.4481986277250787
Validation loss: 3.2880385024692163

Epoch: 7| Step: 0
Training loss: 2.6524866708893384
Validation loss: 3.2175707426506626

Epoch: 6| Step: 1
Training loss: 3.4418266117593777
Validation loss: 3.217606497978871

Epoch: 6| Step: 2
Training loss: 3.7790619375458268
Validation loss: 3.2209792986639836

Epoch: 6| Step: 3
Training loss: 2.6840844739875416
Validation loss: 3.2143975888022744

Epoch: 6| Step: 4
Training loss: 3.519626357881853
Validation loss: 3.2129939448449183

Epoch: 6| Step: 5
Training loss: 3.653453442091172
Validation loss: 3.2136129150427353

Epoch: 6| Step: 6
Training loss: 3.876804300906149
Validation loss: 3.2002181498581384

Epoch: 6| Step: 7
Training loss: 4.347046404050093
Validation loss: 3.184753542506881

Epoch: 6| Step: 8
Training loss: 3.6328403266743403
Validation loss: 3.1714411985008946

Epoch: 6| Step: 9
Training loss: 3.0589417007542465
Validation loss: 3.167079233734172

Epoch: 6| Step: 10
Training loss: 3.2138355848206928
Validation loss: 3.169585636712092

Epoch: 6| Step: 11
Training loss: 2.887897586285232
Validation loss: 3.1666615269678067

Epoch: 6| Step: 12
Training loss: 3.128078012942406
Validation loss: 3.15160145083608

Epoch: 6| Step: 13
Training loss: 4.3553570788655005
Validation loss: 3.136303040338737

Epoch: 8| Step: 0
Training loss: 3.0882559650060597
Validation loss: 3.1229134023018132

Epoch: 6| Step: 1
Training loss: 2.5061518319327156
Validation loss: 3.124428300143477

Epoch: 6| Step: 2
Training loss: 2.9817963489401373
Validation loss: 3.13289132278753

Epoch: 6| Step: 3
Training loss: 3.3190220378294653
Validation loss: 3.1269673871232264

Epoch: 6| Step: 4
Training loss: 3.320926528701471
Validation loss: 3.100696361262357

Epoch: 6| Step: 5
Training loss: 2.7794732408465515
Validation loss: 3.100986094770165

Epoch: 6| Step: 6
Training loss: 4.395731389941229
Validation loss: 3.0868342201507066

Epoch: 6| Step: 7
Training loss: 3.9122261414644743
Validation loss: 3.0797889151233693

Epoch: 6| Step: 8
Training loss: 3.861089781070281
Validation loss: 3.080480944590328

Epoch: 6| Step: 9
Training loss: 3.6168022856943276
Validation loss: 3.1043965849897126

Epoch: 6| Step: 10
Training loss: 3.851578965838599
Validation loss: 3.064040847173617

Epoch: 6| Step: 11
Training loss: 2.5475341318406444
Validation loss: 3.0624827270824326

Epoch: 6| Step: 12
Training loss: 3.3567403708595633
Validation loss: 3.0667764198205925

Epoch: 6| Step: 13
Training loss: 2.877817514833357
Validation loss: 3.065491883028639

Epoch: 9| Step: 0
Training loss: 3.66707722937341
Validation loss: 3.0568675082572594

Epoch: 6| Step: 1
Training loss: 3.4633434879520038
Validation loss: 3.0462971743374596

Epoch: 6| Step: 2
Training loss: 3.2984947817629457
Validation loss: 3.0430461527178023

Epoch: 6| Step: 3
Training loss: 3.0065114563876416
Validation loss: 3.0344961942668602

Epoch: 6| Step: 4
Training loss: 3.055956798757401
Validation loss: 3.0324798852813593

Epoch: 6| Step: 5
Training loss: 3.41867919513809
Validation loss: 3.026709849519498

Epoch: 6| Step: 6
Training loss: 3.3707382704285918
Validation loss: 3.018999766318843

Epoch: 6| Step: 7
Training loss: 3.435137682602766
Validation loss: 3.0136523792789784

Epoch: 6| Step: 8
Training loss: 3.6519063595886605
Validation loss: 3.007597496169453

Epoch: 6| Step: 9
Training loss: 3.7301470073540224
Validation loss: 3.002441787921825

Epoch: 6| Step: 10
Training loss: 2.809119163465363
Validation loss: 2.9967726503698904

Epoch: 6| Step: 11
Training loss: 3.3248409491336774
Validation loss: 2.9917525027163783

Epoch: 6| Step: 12
Training loss: 3.2157832426499917
Validation loss: 2.986556541936692

Epoch: 6| Step: 13
Training loss: 2.4180714919735955
Validation loss: 2.9808633815864507

Epoch: 10| Step: 0
Training loss: 3.06279099308088
Validation loss: 2.9806360971821455

Epoch: 6| Step: 1
Training loss: 3.4180294358451917
Validation loss: 2.9753457443177234

Epoch: 6| Step: 2
Training loss: 3.8870364878762143
Validation loss: 2.9756286377439825

Epoch: 6| Step: 3
Training loss: 2.8731580721810728
Validation loss: 2.9709059446667867

Epoch: 6| Step: 4
Training loss: 2.507451206694774
Validation loss: 2.9675708788778037

Epoch: 6| Step: 5
Training loss: 2.960257499938541
Validation loss: 2.9639781526152817

Epoch: 6| Step: 6
Training loss: 3.656738770248415
Validation loss: 2.962617184780788

Epoch: 6| Step: 7
Training loss: 3.120444983514627
Validation loss: 2.959396168494628

Epoch: 6| Step: 8
Training loss: 3.7176424829592634
Validation loss: 2.95658323478117

Epoch: 6| Step: 9
Training loss: 3.2411901939397225
Validation loss: 2.954362021489611

Epoch: 6| Step: 10
Training loss: 3.5324603681777638
Validation loss: 2.9499507524520747

Epoch: 6| Step: 11
Training loss: 2.9755205548486234
Validation loss: 2.9489248312792897

Epoch: 6| Step: 12
Training loss: 2.6789302367624175
Validation loss: 2.9472303372420754

Epoch: 6| Step: 13
Training loss: 4.1410796293751915
Validation loss: 2.9437202098356177

Epoch: 11| Step: 0
Training loss: 3.461082162696875
Validation loss: 2.9415040193236996

Epoch: 6| Step: 1
Training loss: 3.070487679878419
Validation loss: 2.9391441203783204

Epoch: 6| Step: 2
Training loss: 3.507999542619073
Validation loss: 2.9357947534034188

Epoch: 6| Step: 3
Training loss: 3.446993393995984
Validation loss: 2.935635125080061

Epoch: 6| Step: 4
Training loss: 2.494274449473609
Validation loss: 2.9334382107892525

Epoch: 6| Step: 5
Training loss: 3.4290873843205922
Validation loss: 2.9301914539116884

Epoch: 6| Step: 6
Training loss: 3.0094108793312366
Validation loss: 2.928775413157518

Epoch: 6| Step: 7
Training loss: 3.285539856421213
Validation loss: 2.9247408816353513

Epoch: 6| Step: 8
Training loss: 3.1806057440635302
Validation loss: 2.9200204567354917

Epoch: 6| Step: 9
Training loss: 3.364478913725107
Validation loss: 2.9184455954739565

Epoch: 6| Step: 10
Training loss: 3.3756951922990672
Validation loss: 2.9159080808026077

Epoch: 6| Step: 11
Training loss: 2.7064356293126193
Validation loss: 2.912415478855868

Epoch: 6| Step: 12
Training loss: 3.281591197848221
Validation loss: 2.909683694604882

Epoch: 6| Step: 13
Training loss: 3.801805348445749
Validation loss: 2.9106180764296297

Epoch: 12| Step: 0
Training loss: 3.901231395282281
Validation loss: 2.911225071471424

Epoch: 6| Step: 1
Training loss: 2.6810783135637637
Validation loss: 2.902043544038723

Epoch: 6| Step: 2
Training loss: 3.005598566292448
Validation loss: 2.9182382108788585

Epoch: 6| Step: 3
Training loss: 2.7733529951089415
Validation loss: 2.940919282859212

Epoch: 6| Step: 4
Training loss: 3.0944025141464166
Validation loss: 2.9747726997480193

Epoch: 6| Step: 5
Training loss: 2.9436043154552545
Validation loss: 2.9502162003691397

Epoch: 6| Step: 6
Training loss: 3.054870756071967
Validation loss: 2.916804413831522

Epoch: 6| Step: 7
Training loss: 3.100487510740892
Validation loss: 2.905748770215584

Epoch: 6| Step: 8
Training loss: 3.571441138109169
Validation loss: 2.901754161028059

Epoch: 6| Step: 9
Training loss: 3.6173195866305883
Validation loss: 2.900675008678711

Epoch: 6| Step: 10
Training loss: 3.6091718079812116
Validation loss: 2.8977710561468117

Epoch: 6| Step: 11
Training loss: 3.0811427471072736
Validation loss: 2.8949625248266666

Epoch: 6| Step: 12
Training loss: 3.4349177978985628
Validation loss: 2.897135067430811

Epoch: 6| Step: 13
Training loss: 2.9938297396494953
Validation loss: 2.896792862723256

Epoch: 13| Step: 0
Training loss: 3.2008635190298342
Validation loss: 2.8930901646983087

Epoch: 6| Step: 1
Training loss: 2.91508928060806
Validation loss: 2.8895412161613936

Epoch: 6| Step: 2
Training loss: 3.16481562940713
Validation loss: 2.882029823342876

Epoch: 6| Step: 3
Training loss: 3.6347522438126876
Validation loss: 2.8829997736876076

Epoch: 6| Step: 4
Training loss: 3.089444179234978
Validation loss: 2.880115968543916

Epoch: 6| Step: 5
Training loss: 3.265598424775988
Validation loss: 2.877715961313519

Epoch: 6| Step: 6
Training loss: 2.9023642866555557
Validation loss: 2.878810956961268

Epoch: 6| Step: 7
Training loss: 3.0364453341084223
Validation loss: 2.8700296668692147

Epoch: 6| Step: 8
Training loss: 3.3246179289467417
Validation loss: 2.8679878874896096

Epoch: 6| Step: 9
Training loss: 2.847977733910777
Validation loss: 2.8669090371600765

Epoch: 6| Step: 10
Training loss: 3.6622942661659765
Validation loss: 2.8631414966836095

Epoch: 6| Step: 11
Training loss: 3.1584205340288984
Validation loss: 2.860595706149645

Epoch: 6| Step: 12
Training loss: 3.426140621739937
Validation loss: 2.859962131885759

Epoch: 6| Step: 13
Training loss: 2.9533985152561093
Validation loss: 2.8567931319187507

Epoch: 14| Step: 0
Training loss: 3.0365937313473155
Validation loss: 2.8551100634436226

Epoch: 6| Step: 1
Training loss: 3.0070162425133753
Validation loss: 2.8545891437350472

Epoch: 6| Step: 2
Training loss: 3.3321434440372797
Validation loss: 2.8532871354952527

Epoch: 6| Step: 3
Training loss: 2.359913543475316
Validation loss: 2.850997094236097

Epoch: 6| Step: 4
Training loss: 3.276177254414625
Validation loss: 2.8492843466293083

Epoch: 6| Step: 5
Training loss: 3.1587362034160114
Validation loss: 2.8478217343066157

Epoch: 6| Step: 6
Training loss: 3.161318495714669
Validation loss: 2.845303559710317

Epoch: 6| Step: 7
Training loss: 3.141940168892836
Validation loss: 2.8441260178368633

Epoch: 6| Step: 8
Training loss: 2.6538199585054496
Validation loss: 2.8422598573829165

Epoch: 6| Step: 9
Training loss: 3.38800073842983
Validation loss: 2.842620280838064

Epoch: 6| Step: 10
Training loss: 3.575771840678848
Validation loss: 2.838796773064535

Epoch: 6| Step: 11
Training loss: 3.3427596006962386
Validation loss: 2.8368838679369914

Epoch: 6| Step: 12
Training loss: 3.2722304128369113
Validation loss: 2.8365514552774758

Epoch: 6| Step: 13
Training loss: 3.930700577276046
Validation loss: 2.834542216243717

Epoch: 15| Step: 0
Training loss: 3.966628341062238
Validation loss: 2.835317605132697

Epoch: 6| Step: 1
Training loss: 2.64236835061573
Validation loss: 2.8328248882174973

Epoch: 6| Step: 2
Training loss: 3.5251633842967234
Validation loss: 2.8325584396744437

Epoch: 6| Step: 3
Training loss: 3.7566355172608774
Validation loss: 2.831610015897042

Epoch: 6| Step: 4
Training loss: 3.36513348658985
Validation loss: 2.829892203914718

Epoch: 6| Step: 5
Training loss: 2.9340163331620563
Validation loss: 2.8286713773933307

Epoch: 6| Step: 6
Training loss: 3.194903732306126
Validation loss: 2.827153627982867

Epoch: 6| Step: 7
Training loss: 2.805057171869635
Validation loss: 2.8257380431202455

Epoch: 6| Step: 8
Training loss: 3.078573746090814
Validation loss: 2.8243971650157604

Epoch: 6| Step: 9
Training loss: 3.2531310917836667
Validation loss: 2.824191926319811

Epoch: 6| Step: 10
Training loss: 2.9957025265068187
Validation loss: 2.8224568670061196

Epoch: 6| Step: 11
Training loss: 2.387241137786245
Validation loss: 2.8244598330707165

Epoch: 6| Step: 12
Training loss: 2.959360633823284
Validation loss: 2.8251234883332255

Epoch: 6| Step: 13
Training loss: 3.1287893590154607
Validation loss: 2.8278273885508454

Epoch: 16| Step: 0
Training loss: 3.2813719227255334
Validation loss: 2.82630703254352

Epoch: 6| Step: 1
Training loss: 3.0783458959642913
Validation loss: 2.822871582254871

Epoch: 6| Step: 2
Training loss: 3.466624115413778
Validation loss: 2.8211413449995724

Epoch: 6| Step: 3
Training loss: 2.9108656460242375
Validation loss: 2.81875470521683

Epoch: 6| Step: 4
Training loss: 3.441004405986933
Validation loss: 2.8147984336469496

Epoch: 6| Step: 5
Training loss: 3.4212774164274156
Validation loss: 2.814471052963992

Epoch: 6| Step: 6
Training loss: 2.9472365027139724
Validation loss: 2.8134715581836036

Epoch: 6| Step: 7
Training loss: 2.880457135583955
Validation loss: 2.8118851767876007

Epoch: 6| Step: 8
Training loss: 2.897736251191562
Validation loss: 2.813658979793847

Epoch: 6| Step: 9
Training loss: 3.4248098390234283
Validation loss: 2.810870921361047

Epoch: 6| Step: 10
Training loss: 3.2336857010531808
Validation loss: 2.8092693720140867

Epoch: 6| Step: 11
Training loss: 2.9584441544814646
Validation loss: 2.807457197441599

Epoch: 6| Step: 12
Training loss: 2.849552648135252
Validation loss: 2.806254064768616

Epoch: 6| Step: 13
Training loss: 3.463928170496803
Validation loss: 2.804699414690925

Epoch: 17| Step: 0
Training loss: 2.773330385530568
Validation loss: 2.806111992064964

Epoch: 6| Step: 1
Training loss: 3.07298104601302
Validation loss: 2.8037405210032134

Epoch: 6| Step: 2
Training loss: 3.125065612104177
Validation loss: 2.802549030180629

Epoch: 6| Step: 3
Training loss: 2.679139106177625
Validation loss: 2.803828752126081

Epoch: 6| Step: 4
Training loss: 3.2650817711303906
Validation loss: 2.8001369593893837

Epoch: 6| Step: 5
Training loss: 2.9650026462279375
Validation loss: 2.8033623820334928

Epoch: 6| Step: 6
Training loss: 3.73147508718656
Validation loss: 2.803499100566619

Epoch: 6| Step: 7
Training loss: 3.557672676619141
Validation loss: 2.8021261188537134

Epoch: 6| Step: 8
Training loss: 3.3663544299177928
Validation loss: 2.7965685333418286

Epoch: 6| Step: 9
Training loss: 2.873410988250282
Validation loss: 2.795312137406899

Epoch: 6| Step: 10
Training loss: 3.2847759375952994
Validation loss: 2.795094094290838

Epoch: 6| Step: 11
Training loss: 3.208924045100114
Validation loss: 2.796167457056809

Epoch: 6| Step: 12
Training loss: 2.9677790610036388
Validation loss: 2.7957598769104046

Epoch: 6| Step: 13
Training loss: 2.9616104206790115
Validation loss: 2.794481800923228

Epoch: 18| Step: 0
Training loss: 3.4852028449201145
Validation loss: 2.7944458654546276

Epoch: 6| Step: 1
Training loss: 3.1698595982214295
Validation loss: 2.7904842653980317

Epoch: 6| Step: 2
Training loss: 2.733106744104666
Validation loss: 2.792098845882924

Epoch: 6| Step: 3
Training loss: 2.817000962533133
Validation loss: 2.790881048368491

Epoch: 6| Step: 4
Training loss: 3.2127384973007955
Validation loss: 2.790033083505758

Epoch: 6| Step: 5
Training loss: 3.435540490418314
Validation loss: 2.7879285406723633

Epoch: 6| Step: 6
Training loss: 2.898205030634853
Validation loss: 2.787350554405399

Epoch: 6| Step: 7
Training loss: 3.849264143932976
Validation loss: 2.786416203055084

Epoch: 6| Step: 8
Training loss: 2.902726693644375
Validation loss: 2.785939813179893

Epoch: 6| Step: 9
Training loss: 2.9393648761669824
Validation loss: 2.786595121163325

Epoch: 6| Step: 10
Training loss: 3.31417027234815
Validation loss: 2.788259393643724

Epoch: 6| Step: 11
Training loss: 3.294555137136992
Validation loss: 2.781909152459448

Epoch: 6| Step: 12
Training loss: 2.653372249158142
Validation loss: 2.7845974252696744

Epoch: 6| Step: 13
Training loss: 2.9098898132017963
Validation loss: 2.7842972531349526

Epoch: 19| Step: 0
Training loss: 2.556870767071898
Validation loss: 2.7844567150366566

Epoch: 6| Step: 1
Training loss: 3.2270622697655424
Validation loss: 2.784497801752899

Epoch: 6| Step: 2
Training loss: 3.6326851771202713
Validation loss: 2.7828905355993974

Epoch: 6| Step: 3
Training loss: 3.802501136433509
Validation loss: 2.7773665327465142

Epoch: 6| Step: 4
Training loss: 2.940850477664994
Validation loss: 2.7753225748598407

Epoch: 6| Step: 5
Training loss: 3.421306824217467
Validation loss: 2.7722492880804266

Epoch: 6| Step: 6
Training loss: 3.270051866872471
Validation loss: 2.7758016929126392

Epoch: 6| Step: 7
Training loss: 3.1412498649600176
Validation loss: 2.773125368446477

Epoch: 6| Step: 8
Training loss: 2.8034323431334767
Validation loss: 2.7715585465663786

Epoch: 6| Step: 9
Training loss: 2.8121901447424866
Validation loss: 2.772224518048628

Epoch: 6| Step: 10
Training loss: 3.4064025844730805
Validation loss: 2.7677609673773715

Epoch: 6| Step: 11
Training loss: 3.085931782777536
Validation loss: 2.7691891683711183

Epoch: 6| Step: 12
Training loss: 2.516760717828221
Validation loss: 2.770740125964946

Epoch: 6| Step: 13
Training loss: 2.7351557897519965
Validation loss: 2.7752789265643263

Epoch: 20| Step: 0
Training loss: 3.938624145860267
Validation loss: 2.816232380957334

Epoch: 6| Step: 1
Training loss: 2.8360400641103887
Validation loss: 2.769124967119098

Epoch: 6| Step: 2
Training loss: 2.7466331158443746
Validation loss: 2.7633702888908704

Epoch: 6| Step: 3
Training loss: 3.2347007992802452
Validation loss: 2.769613494478024

Epoch: 6| Step: 4
Training loss: 3.0462746053084686
Validation loss: 2.777400746206421

Epoch: 6| Step: 5
Training loss: 3.17143945569364
Validation loss: 2.775602908177479

Epoch: 6| Step: 6
Training loss: 3.244727185600073
Validation loss: 2.772273540034858

Epoch: 6| Step: 7
Training loss: 3.1360168051658643
Validation loss: 2.7725320075342443

Epoch: 6| Step: 8
Training loss: 3.2424100133075355
Validation loss: 2.767633305777901

Epoch: 6| Step: 9
Training loss: 2.8787566809963896
Validation loss: 2.766611766628776

Epoch: 6| Step: 10
Training loss: 3.4405922592781164
Validation loss: 2.761848294547313

Epoch: 6| Step: 11
Training loss: 2.6123954058430217
Validation loss: 2.7626664540601396

Epoch: 6| Step: 12
Training loss: 2.765245314575232
Validation loss: 2.7792634172813675

Epoch: 6| Step: 13
Training loss: 3.302378323412141
Validation loss: 2.8166411199234576

Epoch: 21| Step: 0
Training loss: 3.1983774124561606
Validation loss: 2.8292282872235126

Epoch: 6| Step: 1
Training loss: 3.4850698556562265
Validation loss: 2.814094131784894

Epoch: 6| Step: 2
Training loss: 3.4593363000760604
Validation loss: 2.769020001327849

Epoch: 6| Step: 3
Training loss: 3.2545401332418433
Validation loss: 2.758994921888738

Epoch: 6| Step: 4
Training loss: 2.8914546291506156
Validation loss: 2.791090635090852

Epoch: 6| Step: 5
Training loss: 3.3236721858068456
Validation loss: 2.787639130285269

Epoch: 6| Step: 6
Training loss: 2.2393045532831697
Validation loss: 2.790660422125506

Epoch: 6| Step: 7
Training loss: 3.2813148128829575
Validation loss: 2.789904803564955

Epoch: 6| Step: 8
Training loss: 2.94074184011287
Validation loss: 2.783957188484422

Epoch: 6| Step: 9
Training loss: 3.8147736320481105
Validation loss: 2.774157881030514

Epoch: 6| Step: 10
Training loss: 2.8923413928701702
Validation loss: 2.767618485042831

Epoch: 6| Step: 11
Training loss: 2.315543054116578
Validation loss: 2.7658050369127074

Epoch: 6| Step: 12
Training loss: 3.2474623823446596
Validation loss: 2.780669886136967

Epoch: 6| Step: 13
Training loss: 3.151791738136182
Validation loss: 2.8036545035919893

Epoch: 22| Step: 0
Training loss: 3.3041146144799693
Validation loss: 2.8009543364042466

Epoch: 6| Step: 1
Training loss: 2.867191158780874
Validation loss: 2.798162442089262

Epoch: 6| Step: 2
Training loss: 3.236391774796541
Validation loss: 2.78903410649418

Epoch: 6| Step: 3
Training loss: 2.9970348327465746
Validation loss: 2.7793798202163336

Epoch: 6| Step: 4
Training loss: 3.194414903439655
Validation loss: 2.759092916630357

Epoch: 6| Step: 5
Training loss: 2.8706084172064505
Validation loss: 2.747503002794041

Epoch: 6| Step: 6
Training loss: 3.3975843038197744
Validation loss: 2.7495542521101415

Epoch: 6| Step: 7
Training loss: 3.2694685370516274
Validation loss: 2.8169918473547964

Epoch: 6| Step: 8
Training loss: 3.3066579296652927
Validation loss: 2.804806314671547

Epoch: 6| Step: 9
Training loss: 3.4877092633649553
Validation loss: 2.789650927796894

Epoch: 6| Step: 10
Training loss: 2.69997332524439
Validation loss: 2.7361617375047658

Epoch: 6| Step: 11
Training loss: 3.1008147676385907
Validation loss: 2.740757285519028

Epoch: 6| Step: 12
Training loss: 3.005032927067727
Validation loss: 2.747610122977529

Epoch: 6| Step: 13
Training loss: 2.6606986099322687
Validation loss: 2.7510706503792015

Epoch: 23| Step: 0
Training loss: 2.648997379864743
Validation loss: 2.7595467278407573

Epoch: 6| Step: 1
Training loss: 2.947006426537234
Validation loss: 2.7640069504266656

Epoch: 6| Step: 2
Training loss: 2.677839882272484
Validation loss: 2.7724071991704817

Epoch: 6| Step: 3
Training loss: 3.0456587491356486
Validation loss: 2.776095957368401

Epoch: 6| Step: 4
Training loss: 3.086610358557458
Validation loss: 2.7862756684012324

Epoch: 6| Step: 5
Training loss: 3.1125377116542263
Validation loss: 2.8115255584234076

Epoch: 6| Step: 6
Training loss: 3.6113038296911264
Validation loss: 2.808088800641079

Epoch: 6| Step: 7
Training loss: 3.4762341290673695
Validation loss: 2.7714780294492

Epoch: 6| Step: 8
Training loss: 2.957320044259202
Validation loss: 2.754784973235516

Epoch: 6| Step: 9
Training loss: 3.1281807542952134
Validation loss: 2.738974772945395

Epoch: 6| Step: 10
Training loss: 3.2285475270656128
Validation loss: 2.7332038304973976

Epoch: 6| Step: 11
Training loss: 3.135088086997305
Validation loss: 2.7400169648547306

Epoch: 6| Step: 12
Training loss: 2.91943600289717
Validation loss: 2.753580391516475

Epoch: 6| Step: 13
Training loss: 3.3761950602293105
Validation loss: 2.7823698078452477

Epoch: 24| Step: 0
Training loss: 2.132948874560583
Validation loss: 2.734799694826424

Epoch: 6| Step: 1
Training loss: 3.0161674683618926
Validation loss: 2.7298249577442646

Epoch: 6| Step: 2
Training loss: 2.676544748794117
Validation loss: 2.736892782351643

Epoch: 6| Step: 3
Training loss: 2.7159122258077923
Validation loss: 2.7664666507793796

Epoch: 6| Step: 4
Training loss: 2.949714103681411
Validation loss: 2.837985514293926

Epoch: 6| Step: 5
Training loss: 3.0361046996828884
Validation loss: 2.8712624969125464

Epoch: 6| Step: 6
Training loss: 3.805306824833962
Validation loss: 2.7610615113885704

Epoch: 6| Step: 7
Training loss: 3.2266652088582344
Validation loss: 2.7297966946997403

Epoch: 6| Step: 8
Training loss: 3.3443035487521597
Validation loss: 2.7276438087339456

Epoch: 6| Step: 9
Training loss: 3.3573443285656235
Validation loss: 2.7651308319331087

Epoch: 6| Step: 10
Training loss: 3.3960774963846445
Validation loss: 2.824980771958259

Epoch: 6| Step: 11
Training loss: 3.1679234436784176
Validation loss: 2.836586229204208

Epoch: 6| Step: 12
Training loss: 3.764901625929911
Validation loss: 2.8006060356072564

Epoch: 6| Step: 13
Training loss: 3.0786278018714857
Validation loss: 2.7843721072312895

Epoch: 25| Step: 0
Training loss: 2.9930968334619545
Validation loss: 2.765996647650589

Epoch: 6| Step: 1
Training loss: 3.0014848213530083
Validation loss: 2.7666143575003783

Epoch: 6| Step: 2
Training loss: 3.7759811642063847
Validation loss: 2.7590412659633268

Epoch: 6| Step: 3
Training loss: 3.276124857142939
Validation loss: 2.74785381481822

Epoch: 6| Step: 4
Training loss: 3.415379320472319
Validation loss: 2.7367178794153117

Epoch: 6| Step: 5
Training loss: 3.0095124432163467
Validation loss: 2.7360356158066246

Epoch: 6| Step: 6
Training loss: 2.6270328098393
Validation loss: 2.748919036828948

Epoch: 6| Step: 7
Training loss: 3.135671780537432
Validation loss: 2.7598675847907104

Epoch: 6| Step: 8
Training loss: 2.3658713531216113
Validation loss: 2.793578489778413

Epoch: 6| Step: 9
Training loss: 2.8140951083770602
Validation loss: 2.7986245873889617

Epoch: 6| Step: 10
Training loss: 2.713191170244726
Validation loss: 2.7540244377408474

Epoch: 6| Step: 11
Training loss: 3.632928005556219
Validation loss: 2.7277428085318647

Epoch: 6| Step: 12
Training loss: 3.4988675328963725
Validation loss: 2.7136033315908654

Epoch: 6| Step: 13
Training loss: 2.419248374831984
Validation loss: 2.710234868214623

Epoch: 26| Step: 0
Training loss: 3.079691686680627
Validation loss: 2.712783905757876

Epoch: 6| Step: 1
Training loss: 2.8884604107753837
Validation loss: 2.7115301141886268

Epoch: 6| Step: 2
Training loss: 2.8563000764359385
Validation loss: 2.711198883586148

Epoch: 6| Step: 3
Training loss: 3.4851084394837613
Validation loss: 2.7062357687706795

Epoch: 6| Step: 4
Training loss: 3.1832022022447735
Validation loss: 2.708340697755732

Epoch: 6| Step: 5
Training loss: 3.0407336820368274
Validation loss: 2.7064205463883684

Epoch: 6| Step: 6
Training loss: 2.4497925300725303
Validation loss: 2.7028789371518904

Epoch: 6| Step: 7
Training loss: 3.4835962357547476
Validation loss: 2.7072113928462143

Epoch: 6| Step: 8
Training loss: 2.7307008309027676
Validation loss: 2.7043438236538306

Epoch: 6| Step: 9
Training loss: 2.960284239034979
Validation loss: 2.7098940332031125

Epoch: 6| Step: 10
Training loss: 3.4423968029414285
Validation loss: 2.7205399922067985

Epoch: 6| Step: 11
Training loss: 3.176466001141629
Validation loss: 2.7254899441098663

Epoch: 6| Step: 12
Training loss: 2.999712930295926
Validation loss: 2.7068230127549566

Epoch: 6| Step: 13
Training loss: 3.174245014687594
Validation loss: 2.7025362609280497

Epoch: 27| Step: 0
Training loss: 2.808236514572329
Validation loss: 2.7036786185549144

Epoch: 6| Step: 1
Training loss: 2.6147583577414304
Validation loss: 2.706726694438078

Epoch: 6| Step: 2
Training loss: 3.817367947935692
Validation loss: 2.708396186446365

Epoch: 6| Step: 3
Training loss: 3.1092975549302473
Validation loss: 2.7032650255663246

Epoch: 6| Step: 4
Training loss: 3.160682662670203
Validation loss: 2.6958412259368254

Epoch: 6| Step: 5
Training loss: 2.4366371388174826
Validation loss: 2.6944262592731123

Epoch: 6| Step: 6
Training loss: 2.9291192482754393
Validation loss: 2.693108604574162

Epoch: 6| Step: 7
Training loss: 3.1153885088730524
Validation loss: 2.694513586724824

Epoch: 6| Step: 8
Training loss: 3.1122115342389725
Validation loss: 2.693498720415227

Epoch: 6| Step: 9
Training loss: 2.954216972177428
Validation loss: 2.709256624553777

Epoch: 6| Step: 10
Training loss: 3.4179210376134135
Validation loss: 2.700622956007326

Epoch: 6| Step: 11
Training loss: 3.2137619924006238
Validation loss: 2.6960154834848105

Epoch: 6| Step: 12
Training loss: 2.667864907786511
Validation loss: 2.695933073443361

Epoch: 6| Step: 13
Training loss: 3.4398049689607846
Validation loss: 2.723921409442479

Epoch: 28| Step: 0
Training loss: 3.216515811947123
Validation loss: 2.7249612584012652

Epoch: 6| Step: 1
Training loss: 3.1189287337037457
Validation loss: 2.722762103981747

Epoch: 6| Step: 2
Training loss: 2.980339477455363
Validation loss: 2.7206272974823884

Epoch: 6| Step: 3
Training loss: 2.4225268071347776
Validation loss: 2.707989477916164

Epoch: 6| Step: 4
Training loss: 2.6622096803370088
Validation loss: 2.7004957061562775

Epoch: 6| Step: 5
Training loss: 3.040216300446963
Validation loss: 2.6933880308693614

Epoch: 6| Step: 6
Training loss: 3.0526429966230153
Validation loss: 2.6886670248995155

Epoch: 6| Step: 7
Training loss: 2.546907764060248
Validation loss: 2.6941136644238872

Epoch: 6| Step: 8
Training loss: 2.8162065453696505
Validation loss: 2.6869783021522435

Epoch: 6| Step: 9
Training loss: 3.1712860913717065
Validation loss: 2.687338671333781

Epoch: 6| Step: 10
Training loss: 3.3626233386707822
Validation loss: 2.688938495171397

Epoch: 6| Step: 11
Training loss: 3.4461490368089023
Validation loss: 2.6859568873073845

Epoch: 6| Step: 12
Training loss: 3.090617896709244
Validation loss: 2.68587864137789

Epoch: 6| Step: 13
Training loss: 3.732999157140858
Validation loss: 2.683432664168361

Epoch: 29| Step: 0
Training loss: 2.703782811911496
Validation loss: 2.685009633609919

Epoch: 6| Step: 1
Training loss: 3.192090786343151
Validation loss: 2.6842063835857344

Epoch: 6| Step: 2
Training loss: 3.3308927820426564
Validation loss: 2.6839246880029464

Epoch: 6| Step: 3
Training loss: 2.9716995845332907
Validation loss: 2.681335105341797

Epoch: 6| Step: 4
Training loss: 2.7001477201106425
Validation loss: 2.6815067849353458

Epoch: 6| Step: 5
Training loss: 3.02660966402171
Validation loss: 2.6815943744179096

Epoch: 6| Step: 6
Training loss: 3.2915479099403395
Validation loss: 2.6850517570380625

Epoch: 6| Step: 7
Training loss: 3.9472273306142807
Validation loss: 2.680012367809558

Epoch: 6| Step: 8
Training loss: 2.5899832157195033
Validation loss: 2.6772974298234953

Epoch: 6| Step: 9
Training loss: 2.5767182182231427
Validation loss: 2.6782320393545933

Epoch: 6| Step: 10
Training loss: 3.1771376975155814
Validation loss: 2.681890431656425

Epoch: 6| Step: 11
Training loss: 3.0437089169214695
Validation loss: 2.677083368127024

Epoch: 6| Step: 12
Training loss: 2.8883952020562766
Validation loss: 2.6768883149348794

Epoch: 6| Step: 13
Training loss: 2.411729592761401
Validation loss: 2.6782702338268147

Epoch: 30| Step: 0
Training loss: 2.9733526589602346
Validation loss: 2.678938797751489

Epoch: 6| Step: 1
Training loss: 2.947327104436641
Validation loss: 2.6739291853470366

Epoch: 6| Step: 2
Training loss: 2.6404988636837152
Validation loss: 2.674142666441042

Epoch: 6| Step: 3
Training loss: 2.8781200562143683
Validation loss: 2.6750977663243956

Epoch: 6| Step: 4
Training loss: 3.35844074831591
Validation loss: 2.6743615139920336

Epoch: 6| Step: 5
Training loss: 2.5568481081357555
Validation loss: 2.673243640999146

Epoch: 6| Step: 6
Training loss: 3.0058157498154108
Validation loss: 2.6738907141022774

Epoch: 6| Step: 7
Training loss: 3.1546309444805147
Validation loss: 2.673953191483802

Epoch: 6| Step: 8
Training loss: 3.3533193967414587
Validation loss: 2.67262701440063

Epoch: 6| Step: 9
Training loss: 2.9319307817768925
Validation loss: 2.675516407261656

Epoch: 6| Step: 10
Training loss: 3.347787291411322
Validation loss: 2.671657792100434

Epoch: 6| Step: 11
Training loss: 2.91512412197927
Validation loss: 2.674832071916375

Epoch: 6| Step: 12
Training loss: 3.1549005928641383
Validation loss: 2.672823434592741

Epoch: 6| Step: 13
Training loss: 2.961625394202639
Validation loss: 2.6729159027999576

Epoch: 31| Step: 0
Training loss: 2.4030820130867556
Validation loss: 2.6736287371100556

Epoch: 6| Step: 1
Training loss: 3.3566849694862637
Validation loss: 2.6784819772709896

Epoch: 6| Step: 2
Training loss: 2.753219973498875
Validation loss: 2.6813007617936204

Epoch: 6| Step: 3
Training loss: 2.9221509507371524
Validation loss: 2.6852377422427196

Epoch: 6| Step: 4
Training loss: 3.3795073751771803
Validation loss: 2.6778845376759612

Epoch: 6| Step: 5
Training loss: 2.766289927405184
Validation loss: 2.668087022151573

Epoch: 6| Step: 6
Training loss: 3.4155295425855146
Validation loss: 2.672607490339918

Epoch: 6| Step: 7
Training loss: 3.1040511824527206
Validation loss: 2.6710881627398186

Epoch: 6| Step: 8
Training loss: 2.4446870534126726
Validation loss: 2.67519565656814

Epoch: 6| Step: 9
Training loss: 3.555200963087664
Validation loss: 2.66930877122348

Epoch: 6| Step: 10
Training loss: 2.933534908593474
Validation loss: 2.6703952687362293

Epoch: 6| Step: 11
Training loss: 2.7203345230499436
Validation loss: 2.6719607848149414

Epoch: 6| Step: 12
Training loss: 3.08430410688221
Validation loss: 2.6701400925351204

Epoch: 6| Step: 13
Training loss: 3.267139868295563
Validation loss: 2.6684637980743147

Epoch: 32| Step: 0
Training loss: 3.0213720082531808
Validation loss: 2.669641201557185

Epoch: 6| Step: 1
Training loss: 3.2437243392605555
Validation loss: 2.6654937895732544

Epoch: 6| Step: 2
Training loss: 2.3508477122685076
Validation loss: 2.66896253500661

Epoch: 6| Step: 3
Training loss: 3.522221052876254
Validation loss: 2.6726101378086073

Epoch: 6| Step: 4
Training loss: 2.7080909229267727
Validation loss: 2.668671185928468

Epoch: 6| Step: 5
Training loss: 2.441732888305609
Validation loss: 2.6709175526860527

Epoch: 6| Step: 6
Training loss: 3.095055506983452
Validation loss: 2.675090243381668

Epoch: 6| Step: 7
Training loss: 2.823774838416429
Validation loss: 2.6833899153492315

Epoch: 6| Step: 8
Training loss: 2.732896415944443
Validation loss: 2.7002199766240955

Epoch: 6| Step: 9
Training loss: 3.2372765541292634
Validation loss: 2.7152920916756424

Epoch: 6| Step: 10
Training loss: 3.2927340133101652
Validation loss: 2.7402860583264252

Epoch: 6| Step: 11
Training loss: 3.524128442248639
Validation loss: 2.7202967533191273

Epoch: 6| Step: 12
Training loss: 2.82695041944694
Validation loss: 2.695868911606024

Epoch: 6| Step: 13
Training loss: 3.5058752883082436
Validation loss: 2.679385300673778

Epoch: 33| Step: 0
Training loss: 3.2662390902687766
Validation loss: 2.6594531527022665

Epoch: 6| Step: 1
Training loss: 3.073919531330515
Validation loss: 2.657270428782211

Epoch: 6| Step: 2
Training loss: 3.3271310960896034
Validation loss: 2.664641618596682

Epoch: 6| Step: 3
Training loss: 2.433947591024608
Validation loss: 2.669394783525651

Epoch: 6| Step: 4
Training loss: 3.435615161522888
Validation loss: 2.6785700054330945

Epoch: 6| Step: 5
Training loss: 2.8733253577432185
Validation loss: 2.6755018408882543

Epoch: 6| Step: 6
Training loss: 2.354277504081272
Validation loss: 2.6720919292828476

Epoch: 6| Step: 7
Training loss: 3.070907418656968
Validation loss: 2.6884941996043445

Epoch: 6| Step: 8
Training loss: 3.1668176782305166
Validation loss: 2.6932834477507126

Epoch: 6| Step: 9
Training loss: 2.876096765049589
Validation loss: 2.69773884273257

Epoch: 6| Step: 10
Training loss: 3.418172705968373
Validation loss: 2.711942388075613

Epoch: 6| Step: 11
Training loss: 2.9392649441425376
Validation loss: 2.7298083934474997

Epoch: 6| Step: 12
Training loss: 3.265423052078461
Validation loss: 2.7481890511305687

Epoch: 6| Step: 13
Training loss: 2.662618027341039
Validation loss: 2.7203187934221367

Epoch: 34| Step: 0
Training loss: 2.6716486070878855
Validation loss: 2.7357366037786233

Epoch: 6| Step: 1
Training loss: 3.2752702266650036
Validation loss: 2.763521199235448

Epoch: 6| Step: 2
Training loss: 3.4373388079216656
Validation loss: 2.791859870020321

Epoch: 6| Step: 3
Training loss: 3.666258586947624
Validation loss: 2.77218200190996

Epoch: 6| Step: 4
Training loss: 2.2488569959172455
Validation loss: 2.8033709900937307

Epoch: 6| Step: 5
Training loss: 3.590600665535401
Validation loss: 2.7982023609973603

Epoch: 6| Step: 6
Training loss: 2.9036610875206565
Validation loss: 2.7415958440900163

Epoch: 6| Step: 7
Training loss: 2.8552329491815196
Validation loss: 2.745896164457219

Epoch: 6| Step: 8
Training loss: 2.712858635183062
Validation loss: 2.730877271069548

Epoch: 6| Step: 9
Training loss: 2.823408546151521
Validation loss: 2.7093621088274737

Epoch: 6| Step: 10
Training loss: 3.537535078865523
Validation loss: 2.695623804120973

Epoch: 6| Step: 11
Training loss: 2.8888181245728073
Validation loss: 2.696810121789291

Epoch: 6| Step: 12
Training loss: 3.3463578081915175
Validation loss: 2.6854009288757967

Epoch: 6| Step: 13
Training loss: 2.7603570799724184
Validation loss: 2.7004964124519324

Epoch: 35| Step: 0
Training loss: 3.1022015352874077
Validation loss: 2.7131909264656215

Epoch: 6| Step: 1
Training loss: 2.595948356255796
Validation loss: 2.7194676303716916

Epoch: 6| Step: 2
Training loss: 2.768630641319235
Validation loss: 2.740458137580234

Epoch: 6| Step: 3
Training loss: 2.3642906870520086
Validation loss: 2.755540410721428

Epoch: 6| Step: 4
Training loss: 3.623488801804382
Validation loss: 2.77830247606396

Epoch: 6| Step: 5
Training loss: 2.750498293034437
Validation loss: 2.7668254377405246

Epoch: 6| Step: 6
Training loss: 2.9357833716279123
Validation loss: 2.7534568180761525

Epoch: 6| Step: 7
Training loss: 3.4396415281927655
Validation loss: 2.720854541909665

Epoch: 6| Step: 8
Training loss: 3.4944800035628036
Validation loss: 2.698555047013815

Epoch: 6| Step: 9
Training loss: 3.267359806663657
Validation loss: 2.6720646040918714

Epoch: 6| Step: 10
Training loss: 2.9537243108806717
Validation loss: 2.6631588482089685

Epoch: 6| Step: 11
Training loss: 3.0091495861271924
Validation loss: 2.6542324059630666

Epoch: 6| Step: 12
Training loss: 2.6653576161129373
Validation loss: 2.6495560606413138

Epoch: 6| Step: 13
Training loss: 3.4539368654631586
Validation loss: 2.6539196517309254

Epoch: 36| Step: 0
Training loss: 3.126289711890262
Validation loss: 2.6528856101319462

Epoch: 6| Step: 1
Training loss: 3.0291394623833945
Validation loss: 2.6499572820890758

Epoch: 6| Step: 2
Training loss: 3.20937426306132
Validation loss: 2.6492605568448275

Epoch: 6| Step: 3
Training loss: 2.687923841544231
Validation loss: 2.646761087146429

Epoch: 6| Step: 4
Training loss: 3.2279247890252205
Validation loss: 2.649578491806352

Epoch: 6| Step: 5
Training loss: 2.6529448646886964
Validation loss: 2.6506766164982305

Epoch: 6| Step: 6
Training loss: 3.3169898069016366
Validation loss: 2.64940426430596

Epoch: 6| Step: 7
Training loss: 3.1813617019678158
Validation loss: 2.649646615279583

Epoch: 6| Step: 8
Training loss: 2.3494961299860306
Validation loss: 2.6507375471688213

Epoch: 6| Step: 9
Training loss: 2.753336789388389
Validation loss: 2.6569457280058875

Epoch: 6| Step: 10
Training loss: 3.0510697661868775
Validation loss: 2.6573845078264697

Epoch: 6| Step: 11
Training loss: 3.195395620146352
Validation loss: 2.6600447666855525

Epoch: 6| Step: 12
Training loss: 2.7474025250153007
Validation loss: 2.67831761960042

Epoch: 6| Step: 13
Training loss: 3.480626574704483
Validation loss: 2.6956782495448355

Epoch: 37| Step: 0
Training loss: 3.3078776804070547
Validation loss: 2.6728667619589634

Epoch: 6| Step: 1
Training loss: 3.1971440743636763
Validation loss: 2.650359961428696

Epoch: 6| Step: 2
Training loss: 2.3334040858123024
Validation loss: 2.6379196493711508

Epoch: 6| Step: 3
Training loss: 2.48026987314813
Validation loss: 2.63597921132552

Epoch: 6| Step: 4
Training loss: 2.628674977348026
Validation loss: 2.633987113613711

Epoch: 6| Step: 5
Training loss: 3.0058768248965553
Validation loss: 2.6354649127663863

Epoch: 6| Step: 6
Training loss: 3.3773937919627866
Validation loss: 2.634556208445942

Epoch: 6| Step: 7
Training loss: 2.4300094342146727
Validation loss: 2.6306389500724525

Epoch: 6| Step: 8
Training loss: 3.918554960078867
Validation loss: 2.6305945627097778

Epoch: 6| Step: 9
Training loss: 3.24322257926733
Validation loss: 2.628428899043198

Epoch: 6| Step: 10
Training loss: 2.7912858067431103
Validation loss: 2.6301751481412357

Epoch: 6| Step: 11
Training loss: 2.9509999536289997
Validation loss: 2.6316056217737183

Epoch: 6| Step: 12
Training loss: 2.8648296088500866
Validation loss: 2.6304008105619885

Epoch: 6| Step: 13
Training loss: 3.1042239975382078
Validation loss: 2.6281877314803643

Epoch: 38| Step: 0
Training loss: 3.05987825862085
Validation loss: 2.628949662431117

Epoch: 6| Step: 1
Training loss: 2.9185102539928027
Validation loss: 2.6275930552097915

Epoch: 6| Step: 2
Training loss: 3.018512983475256
Validation loss: 2.6276559085049103

Epoch: 6| Step: 3
Training loss: 3.0989491865947385
Validation loss: 2.6276246664430416

Epoch: 6| Step: 4
Training loss: 3.1897459906014625
Validation loss: 2.6256617304333814

Epoch: 6| Step: 5
Training loss: 3.072021940331788
Validation loss: 2.625245076510778

Epoch: 6| Step: 6
Training loss: 3.199644104717052
Validation loss: 2.6261281110580392

Epoch: 6| Step: 7
Training loss: 3.031005849542514
Validation loss: 2.6240059346932405

Epoch: 6| Step: 8
Training loss: 2.9746016804726483
Validation loss: 2.6270394330558027

Epoch: 6| Step: 9
Training loss: 2.420675460561322
Validation loss: 2.6266490124237794

Epoch: 6| Step: 10
Training loss: 2.503685428207623
Validation loss: 2.625815259569439

Epoch: 6| Step: 11
Training loss: 2.8440640454277095
Validation loss: 2.632662119148685

Epoch: 6| Step: 12
Training loss: 3.45035009957415
Validation loss: 2.633948267265893

Epoch: 6| Step: 13
Training loss: 2.720544770747192
Validation loss: 2.644084835848736

Epoch: 39| Step: 0
Training loss: 2.6497209078093915
Validation loss: 2.646704852805427

Epoch: 6| Step: 1
Training loss: 3.5707083384575222
Validation loss: 2.6508206843259843

Epoch: 6| Step: 2
Training loss: 2.69624431922537
Validation loss: 2.6609000717853784

Epoch: 6| Step: 3
Training loss: 3.1383862463376255
Validation loss: 2.680843085329728

Epoch: 6| Step: 4
Training loss: 3.012658433982145
Validation loss: 2.6839295594344863

Epoch: 6| Step: 5
Training loss: 2.960971318758879
Validation loss: 2.6677070063725896

Epoch: 6| Step: 6
Training loss: 2.8755424651166197
Validation loss: 2.6612356535167954

Epoch: 6| Step: 7
Training loss: 3.519124099602877
Validation loss: 2.654239955183951

Epoch: 6| Step: 8
Training loss: 2.8101687624337
Validation loss: 2.647081252491728

Epoch: 6| Step: 9
Training loss: 2.1808697082067017
Validation loss: 2.638268590394238

Epoch: 6| Step: 10
Training loss: 3.1498066312990063
Validation loss: 2.637207002086867

Epoch: 6| Step: 11
Training loss: 3.0694790162622736
Validation loss: 2.6324288586622053

Epoch: 6| Step: 12
Training loss: 2.960636012850269
Validation loss: 2.6307505871136585

Epoch: 6| Step: 13
Training loss: 2.9712820398178366
Validation loss: 2.631126041136264

Epoch: 40| Step: 0
Training loss: 3.619501613641351
Validation loss: 2.632874642524206

Epoch: 6| Step: 1
Training loss: 3.33903056278048
Validation loss: 2.6363570402366134

Epoch: 6| Step: 2
Training loss: 3.056896298961576
Validation loss: 2.6394685214081313

Epoch: 6| Step: 3
Training loss: 2.9550477887983524
Validation loss: 2.6295941295548357

Epoch: 6| Step: 4
Training loss: 3.243879423701679
Validation loss: 2.6207226419500036

Epoch: 6| Step: 5
Training loss: 3.137622517781085
Validation loss: 2.623435126793885

Epoch: 6| Step: 6
Training loss: 3.0551496775619897
Validation loss: 2.6239615240334397

Epoch: 6| Step: 7
Training loss: 2.8776057500820493
Validation loss: 2.6222886411269832

Epoch: 6| Step: 8
Training loss: 2.2919393435003177
Validation loss: 2.623809221592234

Epoch: 6| Step: 9
Training loss: 2.9312564158420256
Validation loss: 2.6212650297698565

Epoch: 6| Step: 10
Training loss: 2.9269005298661854
Validation loss: 2.618687494724226

Epoch: 6| Step: 11
Training loss: 3.254102025548028
Validation loss: 2.617930498296405

Epoch: 6| Step: 12
Training loss: 2.6144135763271072
Validation loss: 2.615798970245872

Epoch: 6| Step: 13
Training loss: 1.5500944908627432
Validation loss: 2.6131007919176956

Epoch: 41| Step: 0
Training loss: 3.3475914395801194
Validation loss: 2.6126175318745433

Epoch: 6| Step: 1
Training loss: 3.5307364301339046
Validation loss: 2.611433744152594

Epoch: 6| Step: 2
Training loss: 2.6967175346012384
Validation loss: 2.6109318457496

Epoch: 6| Step: 3
Training loss: 1.8170988341698642
Validation loss: 2.6125398870587793

Epoch: 6| Step: 4
Training loss: 2.7662147712101866
Validation loss: 2.6111022054810844

Epoch: 6| Step: 5
Training loss: 3.2384268770501037
Validation loss: 2.611868311818419

Epoch: 6| Step: 6
Training loss: 3.1954984354329596
Validation loss: 2.6265263668358907

Epoch: 6| Step: 7
Training loss: 3.033203596617397
Validation loss: 2.63369683738012

Epoch: 6| Step: 8
Training loss: 3.463020335187038
Validation loss: 2.650435201216069

Epoch: 6| Step: 9
Training loss: 3.48698102036024
Validation loss: 2.664980619405053

Epoch: 6| Step: 10
Training loss: 2.4163959176119825
Validation loss: 2.683245246825817

Epoch: 6| Step: 11
Training loss: 2.628360413883719
Validation loss: 2.67274521086679

Epoch: 6| Step: 12
Training loss: 2.9015303815913858
Validation loss: 2.686799304542241

Epoch: 6| Step: 13
Training loss: 2.252741203476353
Validation loss: 2.6832526876684346

Epoch: 42| Step: 0
Training loss: 2.404739896861533
Validation loss: 2.6421055311563255

Epoch: 6| Step: 1
Training loss: 2.6362506818340896
Validation loss: 2.6253973049328554

Epoch: 6| Step: 2
Training loss: 3.7505589386510008
Validation loss: 2.604162645562462

Epoch: 6| Step: 3
Training loss: 3.0684310156837897
Validation loss: 2.6042753053380086

Epoch: 6| Step: 4
Training loss: 2.841029783979653
Validation loss: 2.609066241539327

Epoch: 6| Step: 5
Training loss: 3.0186690546718267
Validation loss: 2.6108244270408014

Epoch: 6| Step: 6
Training loss: 2.8713528263211847
Validation loss: 2.6126760374904374

Epoch: 6| Step: 7
Training loss: 2.8197876502634247
Validation loss: 2.6090316256703856

Epoch: 6| Step: 8
Training loss: 2.5247094695387453
Validation loss: 2.612408015994833

Epoch: 6| Step: 9
Training loss: 3.4347467667300453
Validation loss: 2.62059467310951

Epoch: 6| Step: 10
Training loss: 2.6593695778348807
Validation loss: 2.6260806865679354

Epoch: 6| Step: 11
Training loss: 3.272828257091264
Validation loss: 2.6203725521433943

Epoch: 6| Step: 12
Training loss: 3.059692808950605
Validation loss: 2.6216851588662125

Epoch: 6| Step: 13
Training loss: 3.07979526805394
Validation loss: 2.6141792641749038

Epoch: 43| Step: 0
Training loss: 3.1560489099481432
Validation loss: 2.607024679440848

Epoch: 6| Step: 1
Training loss: 2.4559201395178656
Validation loss: 2.606007014225359

Epoch: 6| Step: 2
Training loss: 3.279351257273167
Validation loss: 2.605991389391635

Epoch: 6| Step: 3
Training loss: 3.140739780435209
Validation loss: 2.6065678564749892

Epoch: 6| Step: 4
Training loss: 2.980870930945855
Validation loss: 2.614364858717197

Epoch: 6| Step: 5
Training loss: 2.996547778963948
Validation loss: 2.6228530178462943

Epoch: 6| Step: 6
Training loss: 2.8129212805687027
Validation loss: 2.6274127624422365

Epoch: 6| Step: 7
Training loss: 2.957946716261995
Validation loss: 2.6397453658972796

Epoch: 6| Step: 8
Training loss: 3.2468478248494326
Validation loss: 2.612659046426503

Epoch: 6| Step: 9
Training loss: 2.7415557742278205
Validation loss: 2.6060838739005994

Epoch: 6| Step: 10
Training loss: 2.955802228699604
Validation loss: 2.609335966053452

Epoch: 6| Step: 11
Training loss: 3.1020141580186014
Validation loss: 2.602365800569172

Epoch: 6| Step: 12
Training loss: 2.833457850543767
Validation loss: 2.6012898821209

Epoch: 6| Step: 13
Training loss: 2.824165312075485
Validation loss: 2.6007571227882305

Epoch: 44| Step: 0
Training loss: 3.177054850132738
Validation loss: 2.6016184763755907

Epoch: 6| Step: 1
Training loss: 2.560926652178968
Validation loss: 2.601094911516342

Epoch: 6| Step: 2
Training loss: 3.2600925434761523
Validation loss: 2.5977541688950807

Epoch: 6| Step: 3
Training loss: 3.1447198846759266
Validation loss: 2.5979857390080854

Epoch: 6| Step: 4
Training loss: 3.1025761021848655
Validation loss: 2.5988211429828225

Epoch: 6| Step: 5
Training loss: 3.198604911444457
Validation loss: 2.5983001831150503

Epoch: 6| Step: 6
Training loss: 2.931473088671375
Validation loss: 2.597687311670669

Epoch: 6| Step: 7
Training loss: 2.7214177515124485
Validation loss: 2.5982710064081536

Epoch: 6| Step: 8
Training loss: 3.271447644383356
Validation loss: 2.5993961467958298

Epoch: 6| Step: 9
Training loss: 3.0845918063227264
Validation loss: 2.5979292077344858

Epoch: 6| Step: 10
Training loss: 2.5300032759633924
Validation loss: 2.5976494472530858

Epoch: 6| Step: 11
Training loss: 2.109058045486989
Validation loss: 2.596941306522163

Epoch: 6| Step: 12
Training loss: 2.7765116243096766
Validation loss: 2.599214678343078

Epoch: 6| Step: 13
Training loss: 3.5411630758651325
Validation loss: 2.6111677727725624

Epoch: 45| Step: 0
Training loss: 2.2095733855664568
Validation loss: 2.6003524201449175

Epoch: 6| Step: 1
Training loss: 3.3271391218775515
Validation loss: 2.5958362950336573

Epoch: 6| Step: 2
Training loss: 2.2848799579232035
Validation loss: 2.592440475603417

Epoch: 6| Step: 3
Training loss: 2.9384841893491087
Validation loss: 2.592782696268121

Epoch: 6| Step: 4
Training loss: 3.1482512085278502
Validation loss: 2.59160118972572

Epoch: 6| Step: 5
Training loss: 2.419739304522156
Validation loss: 2.5966160686024717

Epoch: 6| Step: 6
Training loss: 3.361619208597738
Validation loss: 2.5962063104665267

Epoch: 6| Step: 7
Training loss: 3.0936784832327335
Validation loss: 2.598068538407106

Epoch: 6| Step: 8
Training loss: 3.174428428805629
Validation loss: 2.6003524792978365

Epoch: 6| Step: 9
Training loss: 3.151066215146284
Validation loss: 2.597617138649823

Epoch: 6| Step: 10
Training loss: 2.780198487804746
Validation loss: 2.5975710293322707

Epoch: 6| Step: 11
Training loss: 2.882540392762218
Validation loss: 2.5965550843020853

Epoch: 6| Step: 12
Training loss: 3.783386005477484
Validation loss: 2.599233917303824

Epoch: 6| Step: 13
Training loss: 1.8129815086856738
Validation loss: 2.599388522126983

Epoch: 46| Step: 0
Training loss: 2.5500075845044607
Validation loss: 2.595716235992224

Epoch: 6| Step: 1
Training loss: 3.5861576985088397
Validation loss: 2.602570469761467

Epoch: 6| Step: 2
Training loss: 2.5846492635642675
Validation loss: 2.602199357379586

Epoch: 6| Step: 3
Training loss: 2.826849128019433
Validation loss: 2.607304051454676

Epoch: 6| Step: 4
Training loss: 2.2155563580596467
Validation loss: 2.603231844233192

Epoch: 6| Step: 5
Training loss: 3.5565776117598897
Validation loss: 2.6029991876736274

Epoch: 6| Step: 6
Training loss: 3.037044688820784
Validation loss: 2.606457510798046

Epoch: 6| Step: 7
Training loss: 2.264472826308876
Validation loss: 2.6111625329086428

Epoch: 6| Step: 8
Training loss: 1.8761943827702066
Validation loss: 2.6185164497210294

Epoch: 6| Step: 9
Training loss: 2.9674183318317806
Validation loss: 2.631430617363505

Epoch: 6| Step: 10
Training loss: 3.042421343122835
Validation loss: 2.6358717435062022

Epoch: 6| Step: 11
Training loss: 3.138515086314145
Validation loss: 2.6324498133162404

Epoch: 6| Step: 12
Training loss: 3.5615487418126985
Validation loss: 2.634542812957702

Epoch: 6| Step: 13
Training loss: 3.890219548558452
Validation loss: 2.6198000973305873

Epoch: 47| Step: 0
Training loss: 2.8027915390511926
Validation loss: 2.5925476938754044

Epoch: 6| Step: 1
Training loss: 2.6144529717965552
Validation loss: 2.589925012127325

Epoch: 6| Step: 2
Training loss: 3.163328636683149
Validation loss: 2.5919377350763755

Epoch: 6| Step: 3
Training loss: 2.86025570506629
Validation loss: 2.596275798821038

Epoch: 6| Step: 4
Training loss: 3.27506654395137
Validation loss: 2.605318141391623

Epoch: 6| Step: 5
Training loss: 3.143986208101651
Validation loss: 2.621058291408481

Epoch: 6| Step: 6
Training loss: 1.9685374553935604
Validation loss: 2.6175089056401

Epoch: 6| Step: 7
Training loss: 3.268483640128268
Validation loss: 2.608817024349718

Epoch: 6| Step: 8
Training loss: 3.1121107172062343
Validation loss: 2.6085165447812173

Epoch: 6| Step: 9
Training loss: 2.846546181742872
Validation loss: 2.599764787795549

Epoch: 6| Step: 10
Training loss: 2.811058777190904
Validation loss: 2.592828127429049

Epoch: 6| Step: 11
Training loss: 3.6405639643321135
Validation loss: 2.59008741985654

Epoch: 6| Step: 12
Training loss: 2.8315665028148786
Validation loss: 2.588207358389589

Epoch: 6| Step: 13
Training loss: 3.1209496762057363
Validation loss: 2.585372438262613

Epoch: 48| Step: 0
Training loss: 3.421067791492062
Validation loss: 2.583136882186224

Epoch: 6| Step: 1
Training loss: 3.753194973791197
Validation loss: 2.590417934922941

Epoch: 6| Step: 2
Training loss: 2.0138510061040704
Validation loss: 2.591248926511212

Epoch: 6| Step: 3
Training loss: 3.032647980478205
Validation loss: 2.5982943928903754

Epoch: 6| Step: 4
Training loss: 3.133042629094385
Validation loss: 2.6058462588075146

Epoch: 6| Step: 5
Training loss: 2.748942952307578
Validation loss: 2.6199188315725004

Epoch: 6| Step: 6
Training loss: 2.582835016077465
Validation loss: 2.6154377195882343

Epoch: 6| Step: 7
Training loss: 3.8052426663588657
Validation loss: 2.6197140195178164

Epoch: 6| Step: 8
Training loss: 3.4369087404328145
Validation loss: 2.6244667828150177

Epoch: 6| Step: 9
Training loss: 2.393858872768897
Validation loss: 2.606176874509994

Epoch: 6| Step: 10
Training loss: 2.4449862423999247
Validation loss: 2.6006748831379434

Epoch: 6| Step: 11
Training loss: 2.6141113422616895
Validation loss: 2.5947467358052614

Epoch: 6| Step: 12
Training loss: 2.741831003692171
Validation loss: 2.5834962847705345

Epoch: 6| Step: 13
Training loss: 2.4054730634907737
Validation loss: 2.583524477261894

Epoch: 49| Step: 0
Training loss: 3.086634303747893
Validation loss: 2.583221012502614

Epoch: 6| Step: 1
Training loss: 2.564843664480133
Validation loss: 2.582168879005854

Epoch: 6| Step: 2
Training loss: 2.0690636664984887
Validation loss: 2.584995689254413

Epoch: 6| Step: 3
Training loss: 3.2871817605202147
Validation loss: 2.5878971849398242

Epoch: 6| Step: 4
Training loss: 3.3806040825587216
Validation loss: 2.588623575102424

Epoch: 6| Step: 5
Training loss: 3.3178602789673817
Validation loss: 2.581883581069606

Epoch: 6| Step: 6
Training loss: 2.908279530666062
Validation loss: 2.5803748343956143

Epoch: 6| Step: 7
Training loss: 2.6862275415815704
Validation loss: 2.5822915236802526

Epoch: 6| Step: 8
Training loss: 2.3534730772865653
Validation loss: 2.5886752153429082

Epoch: 6| Step: 9
Training loss: 3.0935006089309334
Validation loss: 2.5853368992777743

Epoch: 6| Step: 10
Training loss: 2.8374774209355125
Validation loss: 2.591877740585014

Epoch: 6| Step: 11
Training loss: 2.8355008043917995
Validation loss: 2.5948212980155336

Epoch: 6| Step: 12
Training loss: 3.401661433269307
Validation loss: 2.603740534875259

Epoch: 6| Step: 13
Training loss: 3.047405803122756
Validation loss: 2.5936076835237585

Epoch: 50| Step: 0
Training loss: 1.7640696739138757
Validation loss: 2.5886873626922817

Epoch: 6| Step: 1
Training loss: 2.929742512504332
Validation loss: 2.5844834951507

Epoch: 6| Step: 2
Training loss: 2.790789414162097
Validation loss: 2.5810556310902966

Epoch: 6| Step: 3
Training loss: 2.5615911965637665
Validation loss: 2.581671789436938

Epoch: 6| Step: 4
Training loss: 2.9468349094030306
Validation loss: 2.577364420389764

Epoch: 6| Step: 5
Training loss: 2.947978222387406
Validation loss: 2.580983160364832

Epoch: 6| Step: 6
Training loss: 3.4110415293844705
Validation loss: 2.5874787687477148

Epoch: 6| Step: 7
Training loss: 2.3799553422985587
Validation loss: 2.584566106673109

Epoch: 6| Step: 8
Training loss: 3.370068090186772
Validation loss: 2.585772596915259

Epoch: 6| Step: 9
Training loss: 2.821516208080928
Validation loss: 2.5803873496714336

Epoch: 6| Step: 10
Training loss: 3.058029648950825
Validation loss: 2.582651801288528

Epoch: 6| Step: 11
Training loss: 3.4556218437005164
Validation loss: 2.5809391298445328

Epoch: 6| Step: 12
Training loss: 3.4703335283476187
Validation loss: 2.5655407331011584

Epoch: 6| Step: 13
Training loss: 2.617328423648815
Validation loss: 2.564587850761545

Epoch: 51| Step: 0
Training loss: 3.3796747116573527
Validation loss: 2.564574301731844

Epoch: 6| Step: 1
Training loss: 3.1698732871834667
Validation loss: 2.5608590116794123

Epoch: 6| Step: 2
Training loss: 2.536631291711334
Validation loss: 2.5629685146439067

Epoch: 6| Step: 3
Training loss: 3.1619433429523256
Validation loss: 2.5615455917004546

Epoch: 6| Step: 4
Training loss: 3.0048940792870513
Validation loss: 2.5626845514693666

Epoch: 6| Step: 5
Training loss: 2.2274187549712243
Validation loss: 2.5627330090831775

Epoch: 6| Step: 6
Training loss: 2.9114787329071135
Validation loss: 2.5648615440275235

Epoch: 6| Step: 7
Training loss: 3.1783855500221874
Validation loss: 2.563880338544095

Epoch: 6| Step: 8
Training loss: 2.7880411281425452
Validation loss: 2.560962051409759

Epoch: 6| Step: 9
Training loss: 3.2013014650211074
Validation loss: 2.560495476457816

Epoch: 6| Step: 10
Training loss: 2.8459075456347454
Validation loss: 2.5672246604781734

Epoch: 6| Step: 11
Training loss: 2.643110200556836
Validation loss: 2.57283454681932

Epoch: 6| Step: 12
Training loss: 2.8246264658049363
Validation loss: 2.5812344113890533

Epoch: 6| Step: 13
Training loss: 3.162914830921176
Validation loss: 2.587062475867138

Epoch: 52| Step: 0
Training loss: 2.6092310882903473
Validation loss: 2.6016811846466457

Epoch: 6| Step: 1
Training loss: 2.893332373388925
Validation loss: 2.6007539231112786

Epoch: 6| Step: 2
Training loss: 2.808529063873919
Validation loss: 2.6028473207280647

Epoch: 6| Step: 3
Training loss: 2.700029132827132
Validation loss: 2.6059874721013765

Epoch: 6| Step: 4
Training loss: 3.3667583855954883
Validation loss: 2.587893879215658

Epoch: 6| Step: 5
Training loss: 3.139197181558073
Validation loss: 2.575976423926794

Epoch: 6| Step: 6
Training loss: 3.0640265883345394
Validation loss: 2.5558185936545277

Epoch: 6| Step: 7
Training loss: 3.2849315516570914
Validation loss: 2.5591432248326207

Epoch: 6| Step: 8
Training loss: 2.2935986669027595
Validation loss: 2.5558540265205103

Epoch: 6| Step: 9
Training loss: 3.128983666918349
Validation loss: 2.555278253052454

Epoch: 6| Step: 10
Training loss: 3.1853379041283145
Validation loss: 2.5560512078411444

Epoch: 6| Step: 11
Training loss: 2.937452599974953
Validation loss: 2.562808564719362

Epoch: 6| Step: 12
Training loss: 2.9227807584140435
Validation loss: 2.555806206830595

Epoch: 6| Step: 13
Training loss: 2.429938594685901
Validation loss: 2.561468816809303

Epoch: 53| Step: 0
Training loss: 3.121740548691503
Validation loss: 2.5607713730910517

Epoch: 6| Step: 1
Training loss: 2.717117082276737
Validation loss: 2.5685704118709

Epoch: 6| Step: 2
Training loss: 3.2304449853172894
Validation loss: 2.5733806003685444

Epoch: 6| Step: 3
Training loss: 2.415801671761396
Validation loss: 2.585360560918516

Epoch: 6| Step: 4
Training loss: 2.7942386754517994
Validation loss: 2.5811363564461742

Epoch: 6| Step: 5
Training loss: 2.772049333493944
Validation loss: 2.5752733276878823

Epoch: 6| Step: 6
Training loss: 3.0762109372519872
Validation loss: 2.5754316653304676

Epoch: 6| Step: 7
Training loss: 2.5751611492507798
Validation loss: 2.5719711079416485

Epoch: 6| Step: 8
Training loss: 3.2784388534663824
Validation loss: 2.5684380370047464

Epoch: 6| Step: 9
Training loss: 2.6975778099342036
Validation loss: 2.5575105687749833

Epoch: 6| Step: 10
Training loss: 3.3714421203885987
Validation loss: 2.554864707747223

Epoch: 6| Step: 11
Training loss: 3.476861765121623
Validation loss: 2.5562556780026395

Epoch: 6| Step: 12
Training loss: 2.598015644193773
Validation loss: 2.556777388784966

Epoch: 6| Step: 13
Training loss: 2.3530154381280823
Validation loss: 2.5584345266019013

Epoch: 54| Step: 0
Training loss: 2.1872733952453443
Validation loss: 2.5542590860311574

Epoch: 6| Step: 1
Training loss: 3.023980616795014
Validation loss: 2.553308906799255

Epoch: 6| Step: 2
Training loss: 3.1630794552168062
Validation loss: 2.5568816558029117

Epoch: 6| Step: 3
Training loss: 3.076640899263751
Validation loss: 2.5558647059351163

Epoch: 6| Step: 4
Training loss: 3.1253997547048256
Validation loss: 2.5612811199285446

Epoch: 6| Step: 5
Training loss: 2.76627182804947
Validation loss: 2.5592063372743086

Epoch: 6| Step: 6
Training loss: 2.7048897687976927
Validation loss: 2.5634122655787035

Epoch: 6| Step: 7
Training loss: 2.6689022547866883
Validation loss: 2.565983546157549

Epoch: 6| Step: 8
Training loss: 2.913661734914568
Validation loss: 2.570899072342648

Epoch: 6| Step: 9
Training loss: 2.6028663644153225
Validation loss: 2.562461058378021

Epoch: 6| Step: 10
Training loss: 3.497608321327788
Validation loss: 2.560593174455357

Epoch: 6| Step: 11
Training loss: 3.3998713132402876
Validation loss: 2.5514566961004888

Epoch: 6| Step: 12
Training loss: 2.6972895793141145
Validation loss: 2.54685962238774

Epoch: 6| Step: 13
Training loss: 2.676279553424379
Validation loss: 2.552574220667622

Epoch: 55| Step: 0
Training loss: 2.725243804244314
Validation loss: 2.5516537922416336

Epoch: 6| Step: 1
Training loss: 2.6728245347384396
Validation loss: 2.5539539803523272

Epoch: 6| Step: 2
Training loss: 3.2763431735800284
Validation loss: 2.54958834074952

Epoch: 6| Step: 3
Training loss: 2.8894451310915006
Validation loss: 2.550718929639601

Epoch: 6| Step: 4
Training loss: 2.805341893947555
Validation loss: 2.5490097198086668

Epoch: 6| Step: 5
Training loss: 2.7226611538244936
Validation loss: 2.549849911172919

Epoch: 6| Step: 6
Training loss: 3.1396554237869396
Validation loss: 2.5510365790318557

Epoch: 6| Step: 7
Training loss: 3.7295277312393718
Validation loss: 2.5542816495020624

Epoch: 6| Step: 8
Training loss: 3.177907534560717
Validation loss: 2.55102042053822

Epoch: 6| Step: 9
Training loss: 2.543838844341167
Validation loss: 2.5523019488993484

Epoch: 6| Step: 10
Training loss: 3.061616108296414
Validation loss: 2.556548929987284

Epoch: 6| Step: 11
Training loss: 2.68465823365712
Validation loss: 2.5535681785798925

Epoch: 6| Step: 12
Training loss: 2.578066461071913
Validation loss: 2.5544267330477397

Epoch: 6| Step: 13
Training loss: 2.3788402028303217
Validation loss: 2.565427247201815

Epoch: 56| Step: 0
Training loss: 3.1939213716100374
Validation loss: 2.5688198221328853

Epoch: 6| Step: 1
Training loss: 2.570016768582629
Validation loss: 2.5663226098652374

Epoch: 6| Step: 2
Training loss: 2.450604741723702
Validation loss: 2.5628863707918725

Epoch: 6| Step: 3
Training loss: 2.5833030719420296
Validation loss: 2.577059121549169

Epoch: 6| Step: 4
Training loss: 3.2397607752705206
Validation loss: 2.585539017767795

Epoch: 6| Step: 5
Training loss: 2.8047884867134267
Validation loss: 2.559946068554877

Epoch: 6| Step: 6
Training loss: 2.3369187555453292
Validation loss: 2.5458654127326485

Epoch: 6| Step: 7
Training loss: 2.993825120720078
Validation loss: 2.541834935778195

Epoch: 6| Step: 8
Training loss: 3.198391277536442
Validation loss: 2.5382945717029055

Epoch: 6| Step: 9
Training loss: 3.35432217318434
Validation loss: 2.5420035277365938

Epoch: 6| Step: 10
Training loss: 2.785095299780139
Validation loss: 2.5397969400209988

Epoch: 6| Step: 11
Training loss: 3.1292524777230644
Validation loss: 2.5408670091059316

Epoch: 6| Step: 12
Training loss: 3.085221683197604
Validation loss: 2.5401023866977064

Epoch: 6| Step: 13
Training loss: 2.6969341320216516
Validation loss: 2.543844577619111

Epoch: 57| Step: 0
Training loss: 2.909848682100526
Validation loss: 2.550671751409603

Epoch: 6| Step: 1
Training loss: 3.0422324782202437
Validation loss: 2.5576313196655316

Epoch: 6| Step: 2
Training loss: 2.5375430211521532
Validation loss: 2.580281043898693

Epoch: 6| Step: 3
Training loss: 2.3640567232352585
Validation loss: 2.60406538801242

Epoch: 6| Step: 4
Training loss: 3.098510162686494
Validation loss: 2.644940643702176

Epoch: 6| Step: 5
Training loss: 2.6338561392146795
Validation loss: 2.6708790447807895

Epoch: 6| Step: 6
Training loss: 3.2535137841985127
Validation loss: 2.612315810337716

Epoch: 6| Step: 7
Training loss: 2.661720387396996
Validation loss: 2.5516210047270174

Epoch: 6| Step: 8
Training loss: 3.3934171228862304
Validation loss: 2.537884859745493

Epoch: 6| Step: 9
Training loss: 3.130048412399534
Validation loss: 2.540414837446075

Epoch: 6| Step: 10
Training loss: 2.999991893757359
Validation loss: 2.5414790994260312

Epoch: 6| Step: 11
Training loss: 2.665529356265841
Validation loss: 2.5479115572968296

Epoch: 6| Step: 12
Training loss: 3.2222650093950196
Validation loss: 2.5564234377712762

Epoch: 6| Step: 13
Training loss: 2.378898933787754
Validation loss: 2.5616660312962947

Epoch: 58| Step: 0
Training loss: 3.349022816718975
Validation loss: 2.583778548074488

Epoch: 6| Step: 1
Training loss: 2.9102340790242898
Validation loss: 2.757691581589973

Epoch: 6| Step: 2
Training loss: 3.0023800627601704
Validation loss: 2.7080606940194

Epoch: 6| Step: 3
Training loss: 3.2777095040432593
Validation loss: 2.6409384423795443

Epoch: 6| Step: 4
Training loss: 2.850114846843501
Validation loss: 2.6157784741652232

Epoch: 6| Step: 5
Training loss: 2.8608724706520845
Validation loss: 2.607492128268934

Epoch: 6| Step: 6
Training loss: 2.7669267769607675
Validation loss: 2.597023365298043

Epoch: 6| Step: 7
Training loss: 3.337848482262122
Validation loss: 2.5911494498625185

Epoch: 6| Step: 8
Training loss: 2.858036415834452
Validation loss: 2.567929317509379

Epoch: 6| Step: 9
Training loss: 2.533523198173803
Validation loss: 2.587149841194565

Epoch: 6| Step: 10
Training loss: 3.3449359822669056
Validation loss: 2.607657445166096

Epoch: 6| Step: 11
Training loss: 3.003588755165435
Validation loss: 2.622038552174441

Epoch: 6| Step: 12
Training loss: 2.7540755848869702
Validation loss: 2.6373910864822028

Epoch: 6| Step: 13
Training loss: 2.4053140776991953
Validation loss: 2.6580453971016795

Epoch: 59| Step: 0
Training loss: 2.089206833800084
Validation loss: 2.663192999268241

Epoch: 6| Step: 1
Training loss: 3.1813297763856805
Validation loss: 2.673426627758656

Epoch: 6| Step: 2
Training loss: 3.4124584488906637
Validation loss: 2.6306174625387007

Epoch: 6| Step: 3
Training loss: 2.5965746470621855
Validation loss: 2.605248086822523

Epoch: 6| Step: 4
Training loss: 2.452870932864886
Validation loss: 2.5809054747159244

Epoch: 6| Step: 5
Training loss: 3.3057729683408223
Validation loss: 2.579178353733641

Epoch: 6| Step: 6
Training loss: 3.066484622804186
Validation loss: 2.578153540589086

Epoch: 6| Step: 7
Training loss: 2.3920297920770306
Validation loss: 2.5784962645021414

Epoch: 6| Step: 8
Training loss: 3.385378104748327
Validation loss: 2.5756828149085673

Epoch: 6| Step: 9
Training loss: 3.4968641401979634
Validation loss: 2.5732088999550653

Epoch: 6| Step: 10
Training loss: 2.9308288792270907
Validation loss: 2.5532751756373826

Epoch: 6| Step: 11
Training loss: 3.234609991557769
Validation loss: 2.553626772122334

Epoch: 6| Step: 12
Training loss: 2.592295135231664
Validation loss: 2.559752821775618

Epoch: 6| Step: 13
Training loss: 2.5838910905603583
Validation loss: 2.5912037713968035

Epoch: 60| Step: 0
Training loss: 2.8173575097704777
Validation loss: 2.5900254880039273

Epoch: 6| Step: 1
Training loss: 2.8263503771591685
Validation loss: 2.5856970242219566

Epoch: 6| Step: 2
Training loss: 2.4654353621238565
Validation loss: 2.6042764393630335

Epoch: 6| Step: 3
Training loss: 3.3426477629841305
Validation loss: 2.6157741138392985

Epoch: 6| Step: 4
Training loss: 2.823825497506645
Validation loss: 2.585562186755738

Epoch: 6| Step: 5
Training loss: 2.9029850822378185
Validation loss: 2.5821121612953184

Epoch: 6| Step: 6
Training loss: 2.6516033144739244
Validation loss: 2.5608617856877904

Epoch: 6| Step: 7
Training loss: 2.9809026039897137
Validation loss: 2.556648834402597

Epoch: 6| Step: 8
Training loss: 3.2272559799267775
Validation loss: 2.5500403233958604

Epoch: 6| Step: 9
Training loss: 3.2834831268169777
Validation loss: 2.539693709827822

Epoch: 6| Step: 10
Training loss: 2.5265878198377627
Validation loss: 2.532811096563092

Epoch: 6| Step: 11
Training loss: 3.080890168695954
Validation loss: 2.530029299281552

Epoch: 6| Step: 12
Training loss: 2.9508220432442203
Validation loss: 2.527140952706621

Epoch: 6| Step: 13
Training loss: 2.3448819288123657
Validation loss: 2.531031190081098

Epoch: 61| Step: 0
Training loss: 2.8666727295153476
Validation loss: 2.5286823975229

Epoch: 6| Step: 1
Training loss: 2.6971587561139914
Validation loss: 2.5354545591306468

Epoch: 6| Step: 2
Training loss: 2.8905334458157363
Validation loss: 2.5568590601303613

Epoch: 6| Step: 3
Training loss: 2.077396580661653
Validation loss: 2.617615328235878

Epoch: 6| Step: 4
Training loss: 3.0030995886895595
Validation loss: 2.654217804882168

Epoch: 6| Step: 5
Training loss: 2.427210584805518
Validation loss: 2.6531058449008222

Epoch: 6| Step: 6
Training loss: 3.516377957562254
Validation loss: 2.5920567634944667

Epoch: 6| Step: 7
Training loss: 3.3554009640544655
Validation loss: 2.550145995315708

Epoch: 6| Step: 8
Training loss: 3.0117770138657343
Validation loss: 2.531658954366258

Epoch: 6| Step: 9
Training loss: 2.829346956586383
Validation loss: 2.5289323933186325

Epoch: 6| Step: 10
Training loss: 2.772460421528219
Validation loss: 2.5331941838279466

Epoch: 6| Step: 11
Training loss: 2.7389886788464683
Validation loss: 2.5352548289062398

Epoch: 6| Step: 12
Training loss: 2.8583145259612857
Validation loss: 2.5336752276961665

Epoch: 6| Step: 13
Training loss: 3.793803161550276
Validation loss: 2.5379119108736217

Epoch: 62| Step: 0
Training loss: 3.373404372928549
Validation loss: 2.5358303977577794

Epoch: 6| Step: 1
Training loss: 2.587279279942197
Validation loss: 2.534805516033651

Epoch: 6| Step: 2
Training loss: 2.3765179651866677
Validation loss: 2.534111867223148

Epoch: 6| Step: 3
Training loss: 3.112966026133019
Validation loss: 2.5348768726399116

Epoch: 6| Step: 4
Training loss: 3.366285871618453
Validation loss: 2.5304858655674645

Epoch: 6| Step: 5
Training loss: 2.974415723341926
Validation loss: 2.52869357390153

Epoch: 6| Step: 6
Training loss: 2.9040643820863776
Validation loss: 2.5312268281273806

Epoch: 6| Step: 7
Training loss: 2.595836489590297
Validation loss: 2.5328258722077845

Epoch: 6| Step: 8
Training loss: 2.774360266824898
Validation loss: 2.527061368394368

Epoch: 6| Step: 9
Training loss: 2.9426672108345353
Validation loss: 2.531760640899548

Epoch: 6| Step: 10
Training loss: 2.8120957825845276
Validation loss: 2.5477399295390497

Epoch: 6| Step: 11
Training loss: 3.3553698417465614
Validation loss: 2.564637566910329

Epoch: 6| Step: 12
Training loss: 2.2171461729213093
Validation loss: 2.5661127548176927

Epoch: 6| Step: 13
Training loss: 3.008072799714759
Validation loss: 2.561505033735082

Epoch: 63| Step: 0
Training loss: 2.341831082944481
Validation loss: 2.580178666379669

Epoch: 6| Step: 1
Training loss: 3.0483873575330587
Validation loss: 2.5762886007795833

Epoch: 6| Step: 2
Training loss: 3.4024425540421883
Validation loss: 2.586526410402444

Epoch: 6| Step: 3
Training loss: 2.7170796140955265
Validation loss: 2.567541875379422

Epoch: 6| Step: 4
Training loss: 2.1153576815831205
Validation loss: 2.550392198974502

Epoch: 6| Step: 5
Training loss: 2.8922482443458044
Validation loss: 2.5466674885230125

Epoch: 6| Step: 6
Training loss: 2.990659956294284
Validation loss: 2.5428594785623058

Epoch: 6| Step: 7
Training loss: 3.0824192513611948
Validation loss: 2.549713449465511

Epoch: 6| Step: 8
Training loss: 3.4221028291289444
Validation loss: 2.5556738068001303

Epoch: 6| Step: 9
Training loss: 3.316740237111745
Validation loss: 2.5328353986977614

Epoch: 6| Step: 10
Training loss: 2.17116935848156
Validation loss: 2.5214922789597716

Epoch: 6| Step: 11
Training loss: 2.805104854208311
Validation loss: 2.5215962878413043

Epoch: 6| Step: 12
Training loss: 3.2722054942174275
Validation loss: 2.519398101623308

Epoch: 6| Step: 13
Training loss: 2.45108744563259
Validation loss: 2.5278553660817433

Epoch: 64| Step: 0
Training loss: 2.6242938227134798
Validation loss: 2.531702343280259

Epoch: 6| Step: 1
Training loss: 2.312237286465405
Validation loss: 2.529979810973421

Epoch: 6| Step: 2
Training loss: 2.7799918082686013
Validation loss: 2.527663224318713

Epoch: 6| Step: 3
Training loss: 3.0634135226718366
Validation loss: 2.526700251367957

Epoch: 6| Step: 4
Training loss: 3.1178164504898795
Validation loss: 2.5323913504654394

Epoch: 6| Step: 5
Training loss: 3.2242971970424743
Validation loss: 2.542085248658054

Epoch: 6| Step: 6
Training loss: 2.695756339418701
Validation loss: 2.537510769631921

Epoch: 6| Step: 7
Training loss: 2.487962160356292
Validation loss: 2.530519798182897

Epoch: 6| Step: 8
Training loss: 2.779581490993866
Validation loss: 2.527490709489641

Epoch: 6| Step: 9
Training loss: 2.874885059215191
Validation loss: 2.523359732263079

Epoch: 6| Step: 10
Training loss: 3.243277272376683
Validation loss: 2.5247695441208986

Epoch: 6| Step: 11
Training loss: 3.005064821480367
Validation loss: 2.5232810853259315

Epoch: 6| Step: 12
Training loss: 3.2369212572232686
Validation loss: 2.5211956286213173

Epoch: 6| Step: 13
Training loss: 3.0488171769702537
Validation loss: 2.5260411818901045

Epoch: 65| Step: 0
Training loss: 3.2914751858286553
Validation loss: 2.5307037582462337

Epoch: 6| Step: 1
Training loss: 3.277041251916163
Validation loss: 2.5571537717886748

Epoch: 6| Step: 2
Training loss: 2.552558501765972
Validation loss: 2.558591836231765

Epoch: 6| Step: 3
Training loss: 2.9879762980122364
Validation loss: 2.5676352036576073

Epoch: 6| Step: 4
Training loss: 2.495642297361422
Validation loss: 2.577697624016902

Epoch: 6| Step: 5
Training loss: 3.282338134540006
Validation loss: 2.609850336119063

Epoch: 6| Step: 6
Training loss: 2.5334353961797036
Validation loss: 2.6391874826261583

Epoch: 6| Step: 7
Training loss: 2.6613057211601023
Validation loss: 2.569863882273484

Epoch: 6| Step: 8
Training loss: 2.8874844373143245
Validation loss: 2.528877685058721

Epoch: 6| Step: 9
Training loss: 3.285540001553267
Validation loss: 2.517717736687681

Epoch: 6| Step: 10
Training loss: 2.73748462968805
Validation loss: 2.5116433477555984

Epoch: 6| Step: 11
Training loss: 2.952724046079715
Validation loss: 2.508585418245754

Epoch: 6| Step: 12
Training loss: 2.9238000739719867
Validation loss: 2.5120504893135513

Epoch: 6| Step: 13
Training loss: 1.5161277487735643
Validation loss: 2.5158248492818776

Epoch: 66| Step: 0
Training loss: 3.2820991507273325
Validation loss: 2.5164973869130294

Epoch: 6| Step: 1
Training loss: 3.3094160010776035
Validation loss: 2.5161083299530858

Epoch: 6| Step: 2
Training loss: 2.882803898826938
Validation loss: 2.514938396331454

Epoch: 6| Step: 3
Training loss: 2.858159374878705
Validation loss: 2.51843445112073

Epoch: 6| Step: 4
Training loss: 3.554464010402288
Validation loss: 2.52863399098616

Epoch: 6| Step: 5
Training loss: 3.002866964538034
Validation loss: 2.5309375148226856

Epoch: 6| Step: 6
Training loss: 2.2158817502982715
Validation loss: 2.5382258816616763

Epoch: 6| Step: 7
Training loss: 2.946602698130904
Validation loss: 2.5535131608266477

Epoch: 6| Step: 8
Training loss: 3.1171078014463025
Validation loss: 2.5845728773987684

Epoch: 6| Step: 9
Training loss: 2.233622711089952
Validation loss: 2.5780606437996028

Epoch: 6| Step: 10
Training loss: 2.7130428351153797
Validation loss: 2.577796885821588

Epoch: 6| Step: 11
Training loss: 2.2277496920638824
Validation loss: 2.5973298994041927

Epoch: 6| Step: 12
Training loss: 2.8930871323756526
Validation loss: 2.60366683363435

Epoch: 6| Step: 13
Training loss: 2.7133213961789346
Validation loss: 2.56106368858921

Epoch: 67| Step: 0
Training loss: 3.22125857475303
Validation loss: 2.521801065060371

Epoch: 6| Step: 1
Training loss: 2.670965385644036
Validation loss: 2.507214872877922

Epoch: 6| Step: 2
Training loss: 2.894512140414315
Validation loss: 2.5064418562275574

Epoch: 6| Step: 3
Training loss: 2.9721796403094514
Validation loss: 2.5146056453681007

Epoch: 6| Step: 4
Training loss: 3.2096666480267197
Validation loss: 2.521973820675658

Epoch: 6| Step: 5
Training loss: 2.5943152489670465
Validation loss: 2.5303598203653235

Epoch: 6| Step: 6
Training loss: 2.414639499681398
Validation loss: 2.5532892093408517

Epoch: 6| Step: 7
Training loss: 3.4496577880973165
Validation loss: 2.5455054556688728

Epoch: 6| Step: 8
Training loss: 3.050775779494535
Validation loss: 2.541274136418357

Epoch: 6| Step: 9
Training loss: 2.4654302367824985
Validation loss: 2.533039490989073

Epoch: 6| Step: 10
Training loss: 3.112934471354837
Validation loss: 2.5260536152123945

Epoch: 6| Step: 11
Training loss: 2.2711899386974177
Validation loss: 2.5124623596166864

Epoch: 6| Step: 12
Training loss: 2.988046195565506
Validation loss: 2.5068638733453366

Epoch: 6| Step: 13
Training loss: 3.436862955885652
Validation loss: 2.510078963676041

Epoch: 68| Step: 0
Training loss: 2.721835172692481
Validation loss: 2.532558204893808

Epoch: 6| Step: 1
Training loss: 2.6846848758635398
Validation loss: 2.5702360568034135

Epoch: 6| Step: 2
Training loss: 2.77646851732076
Validation loss: 2.6439921049639614

Epoch: 6| Step: 3
Training loss: 2.934919481878899
Validation loss: 2.651420572147164

Epoch: 6| Step: 4
Training loss: 3.168235607643401
Validation loss: 2.6439275824626627

Epoch: 6| Step: 5
Training loss: 3.0647683598417848
Validation loss: 2.5576875989695953

Epoch: 6| Step: 6
Training loss: 2.8681098639329274
Validation loss: 2.51815746184204

Epoch: 6| Step: 7
Training loss: 2.7114927399355406
Validation loss: 2.5043662848152137

Epoch: 6| Step: 8
Training loss: 2.8442566808015375
Validation loss: 2.502689382444579

Epoch: 6| Step: 9
Training loss: 3.1469789823079357
Validation loss: 2.4999313421973617

Epoch: 6| Step: 10
Training loss: 3.0600451537148006
Validation loss: 2.5059773451864795

Epoch: 6| Step: 11
Training loss: 3.1547027421255267
Validation loss: 2.5085195457612723

Epoch: 6| Step: 12
Training loss: 2.6641972751030476
Validation loss: 2.5090015439405864

Epoch: 6| Step: 13
Training loss: 2.6884131543614536
Validation loss: 2.5106754893757937

Epoch: 69| Step: 0
Training loss: 2.813848214725289
Validation loss: 2.5091460425801118

Epoch: 6| Step: 1
Training loss: 2.4673081062317004
Validation loss: 2.509150281686099

Epoch: 6| Step: 2
Training loss: 2.498252830336567
Validation loss: 2.5165836833818687

Epoch: 6| Step: 3
Training loss: 3.4394863978373578
Validation loss: 2.5209648717008206

Epoch: 6| Step: 4
Training loss: 2.3172294093307917
Validation loss: 2.540657580128088

Epoch: 6| Step: 5
Training loss: 3.295968459904324
Validation loss: 2.5413370243128517

Epoch: 6| Step: 6
Training loss: 2.722331001634169
Validation loss: 2.5421513294210953

Epoch: 6| Step: 7
Training loss: 2.964003130891822
Validation loss: 2.528850735480971

Epoch: 6| Step: 8
Training loss: 2.889707677504038
Validation loss: 2.5282061338718287

Epoch: 6| Step: 9
Training loss: 3.182589319838103
Validation loss: 2.5171110767118914

Epoch: 6| Step: 10
Training loss: 2.086935311880002
Validation loss: 2.5129192906673037

Epoch: 6| Step: 11
Training loss: 3.4467767557926434
Validation loss: 2.511926948222825

Epoch: 6| Step: 12
Training loss: 3.299070088539599
Validation loss: 2.503781495099482

Epoch: 6| Step: 13
Training loss: 2.249781174085229
Validation loss: 2.5187892071979245

Epoch: 70| Step: 0
Training loss: 3.170019349240718
Validation loss: 2.525581802273334

Epoch: 6| Step: 1
Training loss: 3.014592759953128
Validation loss: 2.551393497966537

Epoch: 6| Step: 2
Training loss: 2.5372192265058278
Validation loss: 2.5684701407272765

Epoch: 6| Step: 3
Training loss: 2.9849359274781597
Validation loss: 2.5543704712214668

Epoch: 6| Step: 4
Training loss: 3.158808813479725
Validation loss: 2.55592594093929

Epoch: 6| Step: 5
Training loss: 3.4595321660923375
Validation loss: 2.556438402857522

Epoch: 6| Step: 6
Training loss: 2.776020663088319
Validation loss: 2.540094250986183

Epoch: 6| Step: 7
Training loss: 2.5672887390940566
Validation loss: 2.526839650224336

Epoch: 6| Step: 8
Training loss: 2.512969137394657
Validation loss: 2.523857464505145

Epoch: 6| Step: 9
Training loss: 2.426757517762809
Validation loss: 2.5108790866368973

Epoch: 6| Step: 10
Training loss: 2.8862198539206982
Validation loss: 2.49784294920812

Epoch: 6| Step: 11
Training loss: 3.1687295284776194
Validation loss: 2.4934145945899475

Epoch: 6| Step: 12
Training loss: 2.8856157768949826
Validation loss: 2.4947728136143095

Epoch: 6| Step: 13
Training loss: 2.1037345921025277
Validation loss: 2.496040288846385

Epoch: 71| Step: 0
Training loss: 3.004448771006512
Validation loss: 2.492410149974615

Epoch: 6| Step: 1
Training loss: 2.879041733264713
Validation loss: 2.495745194554987

Epoch: 6| Step: 2
Training loss: 3.1309538010168025
Validation loss: 2.497719612721361

Epoch: 6| Step: 3
Training loss: 2.692836165698799
Validation loss: 2.519745900234224

Epoch: 6| Step: 4
Training loss: 2.8114679774292917
Validation loss: 2.5636327767382907

Epoch: 6| Step: 5
Training loss: 2.9129970535698186
Validation loss: 2.630829749120332

Epoch: 6| Step: 6
Training loss: 2.551659051828548
Validation loss: 2.693981011198677

Epoch: 6| Step: 7
Training loss: 3.2790773010356116
Validation loss: 2.660367398030623

Epoch: 6| Step: 8
Training loss: 3.3226644645497885
Validation loss: 2.5844845143641093

Epoch: 6| Step: 9
Training loss: 2.9559499963394806
Validation loss: 2.5021680895645684

Epoch: 6| Step: 10
Training loss: 2.5864856519317723
Validation loss: 2.493249201630423

Epoch: 6| Step: 11
Training loss: 3.446395461617318
Validation loss: 2.5038155797240393

Epoch: 6| Step: 12
Training loss: 2.2215996293954676
Validation loss: 2.519037659890392

Epoch: 6| Step: 13
Training loss: 2.6327336240097394
Validation loss: 2.531158046553673

Epoch: 72| Step: 0
Training loss: 3.114215705804637
Validation loss: 2.540481636757074

Epoch: 6| Step: 1
Training loss: 3.1279409684076938
Validation loss: 2.545008548392055

Epoch: 6| Step: 2
Training loss: 3.1863736425199876
Validation loss: 2.5315230999690015

Epoch: 6| Step: 3
Training loss: 2.4493816996855338
Validation loss: 2.512757753584802

Epoch: 6| Step: 4
Training loss: 2.8023920468203642
Validation loss: 2.5071633615964606

Epoch: 6| Step: 5
Training loss: 2.4676473545340936
Validation loss: 2.5286281471820544

Epoch: 6| Step: 6
Training loss: 2.7859448871953205
Validation loss: 2.5547346682943637

Epoch: 6| Step: 7
Training loss: 2.6538817675485675
Validation loss: 2.603023751438266

Epoch: 6| Step: 8
Training loss: 2.9461344980898208
Validation loss: 2.6645842241508007

Epoch: 6| Step: 9
Training loss: 3.726759803395189
Validation loss: 2.6934626664321746

Epoch: 6| Step: 10
Training loss: 2.855577625959564
Validation loss: 2.691625113055218

Epoch: 6| Step: 11
Training loss: 2.7104372997705646
Validation loss: 2.696099830782922

Epoch: 6| Step: 12
Training loss: 2.8489958617105686
Validation loss: 2.6926808582647355

Epoch: 6| Step: 13
Training loss: 3.1481370048907498
Validation loss: 2.6322366566675206

Epoch: 73| Step: 0
Training loss: 2.7323734478207244
Validation loss: 2.6002680686849473

Epoch: 6| Step: 1
Training loss: 2.843454701947757
Validation loss: 2.5616304376337395

Epoch: 6| Step: 2
Training loss: 3.212500866841596
Validation loss: 2.5486523443269733

Epoch: 6| Step: 3
Training loss: 3.077777668677128
Validation loss: 2.533588217187269

Epoch: 6| Step: 4
Training loss: 2.528886515788146
Validation loss: 2.5333858377955862

Epoch: 6| Step: 5
Training loss: 3.0144274611775237
Validation loss: 2.523372471393523

Epoch: 6| Step: 6
Training loss: 2.8567838341073157
Validation loss: 2.529618566348441

Epoch: 6| Step: 7
Training loss: 3.0988957930379653
Validation loss: 2.5282398729900746

Epoch: 6| Step: 8
Training loss: 2.713650711611822
Validation loss: 2.52907671619362

Epoch: 6| Step: 9
Training loss: 3.2250606560732407
Validation loss: 2.5282895484667764

Epoch: 6| Step: 10
Training loss: 2.320920408614078
Validation loss: 2.5324502284779804

Epoch: 6| Step: 11
Training loss: 2.8116779397566254
Validation loss: 2.535765639445129

Epoch: 6| Step: 12
Training loss: 2.961777862224575
Validation loss: 2.5290125523102516

Epoch: 6| Step: 13
Training loss: 2.50160852183814
Validation loss: 2.5431805339696947

Epoch: 74| Step: 0
Training loss: 2.693556061244302
Validation loss: 2.5612878791406564

Epoch: 6| Step: 1
Training loss: 3.491390128705578
Validation loss: 2.5600200180599657

Epoch: 6| Step: 2
Training loss: 3.3268871602264904
Validation loss: 2.580328899822639

Epoch: 6| Step: 3
Training loss: 2.742218278239399
Validation loss: 2.5762145530318095

Epoch: 6| Step: 4
Training loss: 2.17906699697254
Validation loss: 2.5762350892254524

Epoch: 6| Step: 5
Training loss: 2.8508012147320914
Validation loss: 2.5606070909604677

Epoch: 6| Step: 6
Training loss: 2.8343938824782757
Validation loss: 2.5591406583289027

Epoch: 6| Step: 7
Training loss: 2.882380755589107
Validation loss: 2.5443517155027866

Epoch: 6| Step: 8
Training loss: 2.9147977745092675
Validation loss: 2.5324131622455366

Epoch: 6| Step: 9
Training loss: 3.019753273996972
Validation loss: 2.5164977536571267

Epoch: 6| Step: 10
Training loss: 2.5813244012265635
Validation loss: 2.5097027223260873

Epoch: 6| Step: 11
Training loss: 2.8766048761879857
Validation loss: 2.50442923451251

Epoch: 6| Step: 12
Training loss: 2.808165112974537
Validation loss: 2.5007826185150455

Epoch: 6| Step: 13
Training loss: 2.4542999369559526
Validation loss: 2.505814634207975

Epoch: 75| Step: 0
Training loss: 2.738085947948989
Validation loss: 2.5050396094407126

Epoch: 6| Step: 1
Training loss: 2.8966730304585195
Validation loss: 2.5082025003317705

Epoch: 6| Step: 2
Training loss: 3.088031145502069
Validation loss: 2.513164286169511

Epoch: 6| Step: 3
Training loss: 2.515330232208683
Validation loss: 2.517485698652772

Epoch: 6| Step: 4
Training loss: 2.703328560457669
Validation loss: 2.5181115641307885

Epoch: 6| Step: 5
Training loss: 2.46945952830543
Validation loss: 2.5264943075807405

Epoch: 6| Step: 6
Training loss: 2.413185034229645
Validation loss: 2.5536811931191314

Epoch: 6| Step: 7
Training loss: 2.4161484480592414
Validation loss: 2.573799258587894

Epoch: 6| Step: 8
Training loss: 3.1453216507120523
Validation loss: 2.5825417669080495

Epoch: 6| Step: 9
Training loss: 3.0040516514305957
Validation loss: 2.5769925386893666

Epoch: 6| Step: 10
Training loss: 3.3252510951176384
Validation loss: 2.55929269869799

Epoch: 6| Step: 11
Training loss: 3.150105756165087
Validation loss: 2.5438821041185937

Epoch: 6| Step: 12
Training loss: 2.5791353962306522
Validation loss: 2.5238594584468195

Epoch: 6| Step: 13
Training loss: 3.407145391247936
Validation loss: 2.513190743969155

Epoch: 76| Step: 0
Training loss: 3.0370484569855196
Validation loss: 2.5056196445664085

Epoch: 6| Step: 1
Training loss: 3.020394620060212
Validation loss: 2.5020979804875094

Epoch: 6| Step: 2
Training loss: 3.206356149444425
Validation loss: 2.5041429093840755

Epoch: 6| Step: 3
Training loss: 2.5667265484582784
Validation loss: 2.4983444413145715

Epoch: 6| Step: 4
Training loss: 2.2275155152744897
Validation loss: 2.5051359866697567

Epoch: 6| Step: 5
Training loss: 2.731700875714148
Validation loss: 2.501710709422595

Epoch: 6| Step: 6
Training loss: 2.642038181626796
Validation loss: 2.501430313559222

Epoch: 6| Step: 7
Training loss: 2.838319224936484
Validation loss: 2.5020808245862223

Epoch: 6| Step: 8
Training loss: 2.795634586037213
Validation loss: 2.4986661675270874

Epoch: 6| Step: 9
Training loss: 2.410189388795424
Validation loss: 2.498169998297761

Epoch: 6| Step: 10
Training loss: 2.862242214805697
Validation loss: 2.4957663014633136

Epoch: 6| Step: 11
Training loss: 3.232963069545554
Validation loss: 2.50499876445959

Epoch: 6| Step: 12
Training loss: 2.922127942239256
Validation loss: 2.495253061674682

Epoch: 6| Step: 13
Training loss: 2.9119543063697364
Validation loss: 2.5007061607024554

Epoch: 77| Step: 0
Training loss: 2.7373510241796972
Validation loss: 2.544033820943573

Epoch: 6| Step: 1
Training loss: 3.0056191906760827
Validation loss: 2.6014101884964247

Epoch: 6| Step: 2
Training loss: 3.7364103125762007
Validation loss: 2.6674086319798245

Epoch: 6| Step: 3
Training loss: 3.2247267851315895
Validation loss: 2.6418301392365198

Epoch: 6| Step: 4
Training loss: 2.3694998648829197
Validation loss: 2.6314491687448647

Epoch: 6| Step: 5
Training loss: 2.440191983190142
Validation loss: 2.614236005961142

Epoch: 6| Step: 6
Training loss: 2.6656809614239556
Validation loss: 2.5833352539129457

Epoch: 6| Step: 7
Training loss: 2.1404180496307394
Validation loss: 2.5614525830052437

Epoch: 6| Step: 8
Training loss: 2.6514794988010477
Validation loss: 2.5530488696352776

Epoch: 6| Step: 9
Training loss: 2.8217429974035544
Validation loss: 2.530279430495135

Epoch: 6| Step: 10
Training loss: 2.442985036397383
Validation loss: 2.4935548394953106

Epoch: 6| Step: 11
Training loss: 3.026589182675521
Validation loss: 2.4996248384183897

Epoch: 6| Step: 12
Training loss: 3.1153952434463568
Validation loss: 2.502291018789554

Epoch: 6| Step: 13
Training loss: 2.914352443476067
Validation loss: 2.5048348507841767

Epoch: 78| Step: 0
Training loss: 3.3324714182080886
Validation loss: 2.509890907761007

Epoch: 6| Step: 1
Training loss: 3.3364040218287414
Validation loss: 2.5120938536002626

Epoch: 6| Step: 2
Training loss: 2.361454634515608
Validation loss: 2.5130305280736986

Epoch: 6| Step: 3
Training loss: 3.162596110817227
Validation loss: 2.5125744646318946

Epoch: 6| Step: 4
Training loss: 2.842256090742664
Validation loss: 2.505320063873023

Epoch: 6| Step: 5
Training loss: 2.543290500238523
Validation loss: 2.4979856928527457

Epoch: 6| Step: 6
Training loss: 2.8399965436672616
Validation loss: 2.488274251774416

Epoch: 6| Step: 7
Training loss: 2.8783013007128955
Validation loss: 2.484773909927287

Epoch: 6| Step: 8
Training loss: 3.0793182074216676
Validation loss: 2.4913034690948903

Epoch: 6| Step: 9
Training loss: 2.655095556375074
Validation loss: 2.499842668525386

Epoch: 6| Step: 10
Training loss: 3.142688585690739
Validation loss: 2.51541387912436

Epoch: 6| Step: 11
Training loss: 2.809812490920143
Validation loss: 2.521256268896995

Epoch: 6| Step: 12
Training loss: 2.332464896670829
Validation loss: 2.544487394767852

Epoch: 6| Step: 13
Training loss: 1.4283222287672603
Validation loss: 2.5376610327829656

Epoch: 79| Step: 0
Training loss: 2.5285112611664315
Validation loss: 2.544251896518028

Epoch: 6| Step: 1
Training loss: 2.4377458888521835
Validation loss: 2.558808295385214

Epoch: 6| Step: 2
Training loss: 2.451223717859375
Validation loss: 2.60190909763173

Epoch: 6| Step: 3
Training loss: 2.6184799419259086
Validation loss: 2.601012572648427

Epoch: 6| Step: 4
Training loss: 3.0090426220852837
Validation loss: 2.5911952598946

Epoch: 6| Step: 5
Training loss: 3.140377964913174
Validation loss: 2.5627407828235915

Epoch: 6| Step: 6
Training loss: 3.0872881673816246
Validation loss: 2.5257366219931487

Epoch: 6| Step: 7
Training loss: 2.7508694401401126
Validation loss: 2.475986770793801

Epoch: 6| Step: 8
Training loss: 3.272408772152114
Validation loss: 2.4836705047958585

Epoch: 6| Step: 9
Training loss: 2.6856524304539797
Validation loss: 2.4874279694257324

Epoch: 6| Step: 10
Training loss: 2.944071622153515
Validation loss: 2.490099589049763

Epoch: 6| Step: 11
Training loss: 2.839280357252964
Validation loss: 2.4935704111519725

Epoch: 6| Step: 12
Training loss: 3.0421578694347007
Validation loss: 2.495825643912943

Epoch: 6| Step: 13
Training loss: 3.067531733888914
Validation loss: 2.495718716164742

Epoch: 80| Step: 0
Training loss: 2.755404709930836
Validation loss: 2.485270410991335

Epoch: 6| Step: 1
Training loss: 2.9842505304234295
Validation loss: 2.485788363419577

Epoch: 6| Step: 2
Training loss: 2.6624627553994364
Validation loss: 2.4920023899778307

Epoch: 6| Step: 3
Training loss: 2.408561290085462
Validation loss: 2.5211095815356392

Epoch: 6| Step: 4
Training loss: 3.1161838531512585
Validation loss: 2.544686508637007

Epoch: 6| Step: 5
Training loss: 2.304250281290139
Validation loss: 2.5692084435662053

Epoch: 6| Step: 6
Training loss: 2.5161052742965215
Validation loss: 2.5907559599569425

Epoch: 6| Step: 7
Training loss: 2.8920522104829263
Validation loss: 2.594799202658401

Epoch: 6| Step: 8
Training loss: 3.2310598586785373
Validation loss: 2.573144651942567

Epoch: 6| Step: 9
Training loss: 2.6416599570428816
Validation loss: 2.550290827098537

Epoch: 6| Step: 10
Training loss: 3.3787260327210626
Validation loss: 2.5351484068433794

Epoch: 6| Step: 11
Training loss: 2.8361579241881185
Validation loss: 2.5123553991197136

Epoch: 6| Step: 12
Training loss: 2.835639202308528
Validation loss: 2.4888495267704496

Epoch: 6| Step: 13
Training loss: 2.4281386562832368
Validation loss: 2.4789741274517003

Epoch: 81| Step: 0
Training loss: 2.4446267820998293
Validation loss: 2.4833440733195125

Epoch: 6| Step: 1
Training loss: 2.139140707387763
Validation loss: 2.4756703432382894

Epoch: 6| Step: 2
Training loss: 2.316887070670944
Validation loss: 2.483907988867284

Epoch: 6| Step: 3
Training loss: 2.7437731731018418
Validation loss: 2.482343982089495

Epoch: 6| Step: 4
Training loss: 2.8460358874805407
Validation loss: 2.4815375966489643

Epoch: 6| Step: 5
Training loss: 3.1903980021192138
Validation loss: 2.474757223277937

Epoch: 6| Step: 6
Training loss: 2.967184517343156
Validation loss: 2.4770785722724997

Epoch: 6| Step: 7
Training loss: 3.197040118803678
Validation loss: 2.470594159447612

Epoch: 6| Step: 8
Training loss: 2.8475155893758126
Validation loss: 2.4771370822096666

Epoch: 6| Step: 9
Training loss: 2.869892227063326
Validation loss: 2.473674966141485

Epoch: 6| Step: 10
Training loss: 2.2966418504781445
Validation loss: 2.4759221463956953

Epoch: 6| Step: 11
Training loss: 3.1957503114449644
Validation loss: 2.4743816374116223

Epoch: 6| Step: 12
Training loss: 3.1032170799707783
Validation loss: 2.475320432306441

Epoch: 6| Step: 13
Training loss: 2.7388744718401314
Validation loss: 2.4885163562756207

Epoch: 82| Step: 0
Training loss: 2.6367853000860726
Validation loss: 2.490157217543146

Epoch: 6| Step: 1
Training loss: 1.8952290616455725
Validation loss: 2.4980065006570307

Epoch: 6| Step: 2
Training loss: 2.4563730689513816
Validation loss: 2.5105249068999878

Epoch: 6| Step: 3
Training loss: 2.966681472512778
Validation loss: 2.5211440867483508

Epoch: 6| Step: 4
Training loss: 2.167949394620806
Validation loss: 2.5202685253667974

Epoch: 6| Step: 5
Training loss: 2.9205619595248837
Validation loss: 2.508463455137639

Epoch: 6| Step: 6
Training loss: 2.769496384846438
Validation loss: 2.499407547307404

Epoch: 6| Step: 7
Training loss: 3.1048091931771906
Validation loss: 2.4909286670662847

Epoch: 6| Step: 8
Training loss: 3.1374608132396262
Validation loss: 2.482030483437602

Epoch: 6| Step: 9
Training loss: 2.917973979245649
Validation loss: 2.479467952914057

Epoch: 6| Step: 10
Training loss: 3.1685852128318346
Validation loss: 2.475364916447451

Epoch: 6| Step: 11
Training loss: 3.1521598072108135
Validation loss: 2.476386230671732

Epoch: 6| Step: 12
Training loss: 2.935148231103466
Validation loss: 2.4800902235672915

Epoch: 6| Step: 13
Training loss: 2.658062036317044
Validation loss: 2.477584588103393

Epoch: 83| Step: 0
Training loss: 2.6431280608485324
Validation loss: 2.475852731323804

Epoch: 6| Step: 1
Training loss: 3.0905100493465967
Validation loss: 2.480397875652349

Epoch: 6| Step: 2
Training loss: 2.681641691892541
Validation loss: 2.484147906396465

Epoch: 6| Step: 3
Training loss: 2.545899467629011
Validation loss: 2.490927314709329

Epoch: 6| Step: 4
Training loss: 2.9949414201971627
Validation loss: 2.5007916376394874

Epoch: 6| Step: 5
Training loss: 2.2708297402823017
Validation loss: 2.5233286181981676

Epoch: 6| Step: 6
Training loss: 2.38371384879806
Validation loss: 2.54158700595919

Epoch: 6| Step: 7
Training loss: 2.184063419064028
Validation loss: 2.5329733557058054

Epoch: 6| Step: 8
Training loss: 3.100656833589073
Validation loss: 2.5277034657396547

Epoch: 6| Step: 9
Training loss: 3.1392842177931977
Validation loss: 2.539479905772119

Epoch: 6| Step: 10
Training loss: 3.4963404733560264
Validation loss: 2.525814034384285

Epoch: 6| Step: 11
Training loss: 2.400203092247238
Validation loss: 2.5108964111287317

Epoch: 6| Step: 12
Training loss: 3.0101265068970795
Validation loss: 2.4937945588270525

Epoch: 6| Step: 13
Training loss: 2.877079253270937
Validation loss: 2.4824024226560235

Epoch: 84| Step: 0
Training loss: 3.2860389276614552
Validation loss: 2.4802726390965413

Epoch: 6| Step: 1
Training loss: 2.84560325515385
Validation loss: 2.4791929633618532

Epoch: 6| Step: 2
Training loss: 2.6784747079007967
Validation loss: 2.4832375909414006

Epoch: 6| Step: 3
Training loss: 2.620069687477096
Validation loss: 2.486326971719913

Epoch: 6| Step: 4
Training loss: 2.462987040266851
Validation loss: 2.482112286217156

Epoch: 6| Step: 5
Training loss: 3.011761814705078
Validation loss: 2.479871664287645

Epoch: 6| Step: 6
Training loss: 3.115364172452709
Validation loss: 2.4780736357630846

Epoch: 6| Step: 7
Training loss: 2.8513021271860346
Validation loss: 2.4921314182915633

Epoch: 6| Step: 8
Training loss: 2.5034005878961927
Validation loss: 2.5230818235924466

Epoch: 6| Step: 9
Training loss: 3.151548755712237
Validation loss: 2.5737519097739576

Epoch: 6| Step: 10
Training loss: 2.7933955366663668
Validation loss: 2.6080394773426474

Epoch: 6| Step: 11
Training loss: 2.956606472854842
Validation loss: 2.6079583087889495

Epoch: 6| Step: 12
Training loss: 2.40219716190853
Validation loss: 2.5556286259971

Epoch: 6| Step: 13
Training loss: 2.6286842286447762
Validation loss: 2.513246032394044

Epoch: 85| Step: 0
Training loss: 2.7204704541181357
Validation loss: 2.4864029535354275

Epoch: 6| Step: 1
Training loss: 2.4463756066278157
Validation loss: 2.4754505735089

Epoch: 6| Step: 2
Training loss: 2.4392771966686158
Validation loss: 2.4799720939382066

Epoch: 6| Step: 3
Training loss: 3.0757892867243237
Validation loss: 2.476303778041725

Epoch: 6| Step: 4
Training loss: 2.9776485994733832
Validation loss: 2.4770677405121124

Epoch: 6| Step: 5
Training loss: 2.9840934580672056
Validation loss: 2.4812782925745336

Epoch: 6| Step: 6
Training loss: 2.7442523539865715
Validation loss: 2.487296829505289

Epoch: 6| Step: 7
Training loss: 2.929611652664019
Validation loss: 2.4872189119802264

Epoch: 6| Step: 8
Training loss: 2.7805001608909063
Validation loss: 2.479174349131736

Epoch: 6| Step: 9
Training loss: 2.7472283527737433
Validation loss: 2.4863590050740463

Epoch: 6| Step: 10
Training loss: 2.664986458577577
Validation loss: 2.4793554464926415

Epoch: 6| Step: 11
Training loss: 3.3066974416449195
Validation loss: 2.4731231063654784

Epoch: 6| Step: 12
Training loss: 3.159416498804018
Validation loss: 2.481388684262745

Epoch: 6| Step: 13
Training loss: 1.79165787657718
Validation loss: 2.4986232412171883

Epoch: 86| Step: 0
Training loss: 2.6616274088825054
Validation loss: 2.5472607577462596

Epoch: 6| Step: 1
Training loss: 3.227235442176967
Validation loss: 2.623189082731774

Epoch: 6| Step: 2
Training loss: 2.545516137207768
Validation loss: 2.630400959678809

Epoch: 6| Step: 3
Training loss: 3.4462889241375008
Validation loss: 2.653696260747307

Epoch: 6| Step: 4
Training loss: 3.1217619332276163
Validation loss: 2.6393695741799377

Epoch: 6| Step: 5
Training loss: 2.992877930348854
Validation loss: 2.575549531515448

Epoch: 6| Step: 6
Training loss: 2.633290504960363
Validation loss: 2.546213568056899

Epoch: 6| Step: 7
Training loss: 2.686661700424766
Validation loss: 2.5188922554780375

Epoch: 6| Step: 8
Training loss: 2.660224543967786
Validation loss: 2.4993226820686947

Epoch: 6| Step: 9
Training loss: 2.5049412532778184
Validation loss: 2.4954906033209645

Epoch: 6| Step: 10
Training loss: 2.6765201634289437
Validation loss: 2.489293983736169

Epoch: 6| Step: 11
Training loss: 2.0999890645060324
Validation loss: 2.489916013393491

Epoch: 6| Step: 12
Training loss: 3.0706215428713937
Validation loss: 2.4934071599205936

Epoch: 6| Step: 13
Training loss: 2.1573070202005877
Validation loss: 2.494827154821999

Epoch: 87| Step: 0
Training loss: 2.441858258938136
Validation loss: 2.5016879505345897

Epoch: 6| Step: 1
Training loss: 2.8101912453078843
Validation loss: 2.508725924830973

Epoch: 6| Step: 2
Training loss: 2.399156990610344
Validation loss: 2.5100047122800127

Epoch: 6| Step: 3
Training loss: 2.8289577880816896
Validation loss: 2.5247858147723217

Epoch: 6| Step: 4
Training loss: 2.321751209517084
Validation loss: 2.5239665611712314

Epoch: 6| Step: 5
Training loss: 3.103434499805027
Validation loss: 2.519486025478846

Epoch: 6| Step: 6
Training loss: 2.642757570386694
Validation loss: 2.524832959875213

Epoch: 6| Step: 7
Training loss: 2.952027939568603
Validation loss: 2.5294603234230917

Epoch: 6| Step: 8
Training loss: 3.184204492318508
Validation loss: 2.5096127630425062

Epoch: 6| Step: 9
Training loss: 3.029262244926173
Validation loss: 2.5097199701550834

Epoch: 6| Step: 10
Training loss: 3.1051760745535013
Validation loss: 2.495023187247676

Epoch: 6| Step: 11
Training loss: 2.3484803338627382
Validation loss: 2.4819561025398107

Epoch: 6| Step: 12
Training loss: 3.0542560087271178
Validation loss: 2.4699451611227605

Epoch: 6| Step: 13
Training loss: 2.4139337104096197
Validation loss: 2.459387956771122

Epoch: 88| Step: 0
Training loss: 2.6213535231274876
Validation loss: 2.4703677603723695

Epoch: 6| Step: 1
Training loss: 3.219335262088141
Validation loss: 2.4794054261954663

Epoch: 6| Step: 2
Training loss: 3.283600464876848
Validation loss: 2.5083664606935003

Epoch: 6| Step: 3
Training loss: 2.482924895866402
Validation loss: 2.529782993183598

Epoch: 6| Step: 4
Training loss: 2.5008734131037382
Validation loss: 2.543661129495987

Epoch: 6| Step: 5
Training loss: 3.1582843531800604
Validation loss: 2.5762137111608054

Epoch: 6| Step: 6
Training loss: 2.3321940047372607
Validation loss: 2.5945105259904047

Epoch: 6| Step: 7
Training loss: 2.6990460617979966
Validation loss: 2.6234141011117975

Epoch: 6| Step: 8
Training loss: 2.0724047183600285
Validation loss: 2.6074340254684225

Epoch: 6| Step: 9
Training loss: 3.0561792970057855
Validation loss: 2.576190206329748

Epoch: 6| Step: 10
Training loss: 2.973136792836148
Validation loss: 2.5576685586853958

Epoch: 6| Step: 11
Training loss: 3.160115207551775
Validation loss: 2.527775215525656

Epoch: 6| Step: 12
Training loss: 2.4252897738333346
Validation loss: 2.502054533635967

Epoch: 6| Step: 13
Training loss: 3.1462614429191524
Validation loss: 2.4827426256434273

Epoch: 89| Step: 0
Training loss: 2.6475387443610843
Validation loss: 2.4719251731181213

Epoch: 6| Step: 1
Training loss: 2.549964481929178
Validation loss: 2.4652307249280887

Epoch: 6| Step: 2
Training loss: 2.5590912080515436
Validation loss: 2.4695542119745744

Epoch: 6| Step: 3
Training loss: 2.9818801437842084
Validation loss: 2.4700333715021743

Epoch: 6| Step: 4
Training loss: 2.9069088424913994
Validation loss: 2.470557956207543

Epoch: 6| Step: 5
Training loss: 2.5514711437234436
Validation loss: 2.469109775490734

Epoch: 6| Step: 6
Training loss: 2.7655212038034573
Validation loss: 2.462088470152358

Epoch: 6| Step: 7
Training loss: 3.06454212844778
Validation loss: 2.4617984867914817

Epoch: 6| Step: 8
Training loss: 3.1559756320259202
Validation loss: 2.463120015696166

Epoch: 6| Step: 9
Training loss: 3.1540109983166578
Validation loss: 2.468503445159128

Epoch: 6| Step: 10
Training loss: 2.3355038856011787
Validation loss: 2.4732589626046146

Epoch: 6| Step: 11
Training loss: 3.02786789817341
Validation loss: 2.4727325217738465

Epoch: 6| Step: 12
Training loss: 1.8023376358914027
Validation loss: 2.4771426956136047

Epoch: 6| Step: 13
Training loss: 3.295084100787445
Validation loss: 2.48941399119383

Epoch: 90| Step: 0
Training loss: 2.8023707775368485
Validation loss: 2.485794872064926

Epoch: 6| Step: 1
Training loss: 2.6858719618581235
Validation loss: 2.4898476937619853

Epoch: 6| Step: 2
Training loss: 3.0415781783379177
Validation loss: 2.4897260936889456

Epoch: 6| Step: 3
Training loss: 2.8651876101223688
Validation loss: 2.490777844894074

Epoch: 6| Step: 4
Training loss: 2.130338134790456
Validation loss: 2.4914001348492447

Epoch: 6| Step: 5
Training loss: 2.690950972497094
Validation loss: 2.483497743875704

Epoch: 6| Step: 6
Training loss: 3.297561646319792
Validation loss: 2.488609155975029

Epoch: 6| Step: 7
Training loss: 2.5956459928931688
Validation loss: 2.4902248337828494

Epoch: 6| Step: 8
Training loss: 2.7459586532158307
Validation loss: 2.4772371239112587

Epoch: 6| Step: 9
Training loss: 2.779920710386607
Validation loss: 2.4723594036466183

Epoch: 6| Step: 10
Training loss: 3.0804778270892452
Validation loss: 2.462790788524049

Epoch: 6| Step: 11
Training loss: 2.3711796199828825
Validation loss: 2.4658366664627223

Epoch: 6| Step: 12
Training loss: 2.663477858663155
Validation loss: 2.4608146744909165

Epoch: 6| Step: 13
Training loss: 2.81235452911551
Validation loss: 2.463870228863995

Epoch: 91| Step: 0
Training loss: 2.7619901575000143
Validation loss: 2.4650679212495903

Epoch: 6| Step: 1
Training loss: 2.7212048551979025
Validation loss: 2.4660500565015124

Epoch: 6| Step: 2
Training loss: 2.759228912668335
Validation loss: 2.4643138355327077

Epoch: 6| Step: 3
Training loss: 2.2582536418221983
Validation loss: 2.4636801109045647

Epoch: 6| Step: 4
Training loss: 3.1321302322652738
Validation loss: 2.467880191330831

Epoch: 6| Step: 5
Training loss: 3.222864280690847
Validation loss: 2.4667839808809844

Epoch: 6| Step: 6
Training loss: 2.778541703613293
Validation loss: 2.467829268696519

Epoch: 6| Step: 7
Training loss: 3.233333991401317
Validation loss: 2.482759332798446

Epoch: 6| Step: 8
Training loss: 2.162813452786711
Validation loss: 2.492714520818133

Epoch: 6| Step: 9
Training loss: 2.635377443848492
Validation loss: 2.5026222484362615

Epoch: 6| Step: 10
Training loss: 2.271084646148334
Validation loss: 2.522923970370462

Epoch: 6| Step: 11
Training loss: 2.722437320264427
Validation loss: 2.4996544424804097

Epoch: 6| Step: 12
Training loss: 2.5401185641813804
Validation loss: 2.481870881758482

Epoch: 6| Step: 13
Training loss: 3.444088257725396
Validation loss: 2.4811351544660107

Epoch: 92| Step: 0
Training loss: 3.0045760540223134
Validation loss: 2.4712818922310493

Epoch: 6| Step: 1
Training loss: 3.1655363441396998
Validation loss: 2.4719514329412857

Epoch: 6| Step: 2
Training loss: 2.4868189468835196
Validation loss: 2.469453959725052

Epoch: 6| Step: 3
Training loss: 2.6973894603236817
Validation loss: 2.463239892266402

Epoch: 6| Step: 4
Training loss: 2.846352863689565
Validation loss: 2.466888885111037

Epoch: 6| Step: 5
Training loss: 2.3929047528961753
Validation loss: 2.475174707797192

Epoch: 6| Step: 6
Training loss: 3.1848818928664824
Validation loss: 2.473110026505848

Epoch: 6| Step: 7
Training loss: 2.370922302382414
Validation loss: 2.477758176215841

Epoch: 6| Step: 8
Training loss: 2.7197272638015253
Validation loss: 2.47793147179421

Epoch: 6| Step: 9
Training loss: 2.521266984026569
Validation loss: 2.47059684906496

Epoch: 6| Step: 10
Training loss: 2.968379268587108
Validation loss: 2.479397175069573

Epoch: 6| Step: 11
Training loss: 2.744817271586696
Validation loss: 2.468681314763445

Epoch: 6| Step: 12
Training loss: 2.5255188286169497
Validation loss: 2.472850367955999

Epoch: 6| Step: 13
Training loss: 2.6727059840013276
Validation loss: 2.4800749228635586

Epoch: 93| Step: 0
Training loss: 1.9527491703835063
Validation loss: 2.489389004620635

Epoch: 6| Step: 1
Training loss: 2.976822969349156
Validation loss: 2.501582217213246

Epoch: 6| Step: 2
Training loss: 2.785716552873185
Validation loss: 2.4979284060964893

Epoch: 6| Step: 3
Training loss: 3.353491310382515
Validation loss: 2.515626351308947

Epoch: 6| Step: 4
Training loss: 2.6263788325843844
Validation loss: 2.520698357303097

Epoch: 6| Step: 5
Training loss: 2.389103823117932
Validation loss: 2.5297299409816745

Epoch: 6| Step: 6
Training loss: 2.8798083026983807
Validation loss: 2.524522938106798

Epoch: 6| Step: 7
Training loss: 3.1222923755871905
Validation loss: 2.53009323067503

Epoch: 6| Step: 8
Training loss: 2.6445373805551173
Validation loss: 2.5223708427267053

Epoch: 6| Step: 9
Training loss: 2.7942798871512564
Validation loss: 2.501539179020245

Epoch: 6| Step: 10
Training loss: 2.7591527000387903
Validation loss: 2.4890439865228915

Epoch: 6| Step: 11
Training loss: 2.3753276398182157
Validation loss: 2.4809673267852115

Epoch: 6| Step: 12
Training loss: 2.8374564146483903
Validation loss: 2.4871131273752987

Epoch: 6| Step: 13
Training loss: 2.654957265994885
Validation loss: 2.493506009085705

Epoch: 94| Step: 0
Training loss: 2.9414347815681294
Validation loss: 2.4858759110589

Epoch: 6| Step: 1
Training loss: 2.4839254488361715
Validation loss: 2.4964897071126697

Epoch: 6| Step: 2
Training loss: 2.495825142653266
Validation loss: 2.5023804304095867

Epoch: 6| Step: 3
Training loss: 3.305803403636346
Validation loss: 2.4948696018373338

Epoch: 6| Step: 4
Training loss: 2.249380132272371
Validation loss: 2.502817710261468

Epoch: 6| Step: 5
Training loss: 3.1924893095095883
Validation loss: 2.5123075167939963

Epoch: 6| Step: 6
Training loss: 2.2260156863500455
Validation loss: 2.5117940479167573

Epoch: 6| Step: 7
Training loss: 2.498034276624799
Validation loss: 2.5117233603705373

Epoch: 6| Step: 8
Training loss: 1.8970580564150323
Validation loss: 2.5149035603044645

Epoch: 6| Step: 9
Training loss: 3.1743488154614767
Validation loss: 2.4955103717549902

Epoch: 6| Step: 10
Training loss: 3.4361758369332933
Validation loss: 2.486954393066414

Epoch: 6| Step: 11
Training loss: 2.6443904236298863
Validation loss: 2.4814309757972364

Epoch: 6| Step: 12
Training loss: 2.7273727131346237
Validation loss: 2.482477071073948

Epoch: 6| Step: 13
Training loss: 2.435208833265638
Validation loss: 2.4832593936432845

Epoch: 95| Step: 0
Training loss: 2.4186689259743925
Validation loss: 2.4845523627740804

Epoch: 6| Step: 1
Training loss: 3.198383972286581
Validation loss: 2.4865557432497924

Epoch: 6| Step: 2
Training loss: 2.8336389227233165
Validation loss: 2.495905777400624

Epoch: 6| Step: 3
Training loss: 3.0130417585951386
Validation loss: 2.510972142095595

Epoch: 6| Step: 4
Training loss: 2.7556016397297167
Validation loss: 2.5455851723448033

Epoch: 6| Step: 5
Training loss: 2.6084073950964686
Validation loss: 2.5580315856640934

Epoch: 6| Step: 6
Training loss: 2.8543809313761552
Validation loss: 2.550916277751868

Epoch: 6| Step: 7
Training loss: 2.2935380635068787
Validation loss: 2.539157736785129

Epoch: 6| Step: 8
Training loss: 2.6204392913732897
Validation loss: 2.5298360462997094

Epoch: 6| Step: 9
Training loss: 2.6449882980116666
Validation loss: 2.5320198997881054

Epoch: 6| Step: 10
Training loss: 2.5366273441182616
Validation loss: 2.5185056730292392

Epoch: 6| Step: 11
Training loss: 3.2747666020981976
Validation loss: 2.4849027368663354

Epoch: 6| Step: 12
Training loss: 2.362275014992954
Validation loss: 2.4771830902205036

Epoch: 6| Step: 13
Training loss: 2.5337029333876107
Validation loss: 2.473776214234709

Epoch: 96| Step: 0
Training loss: 3.13446503621151
Validation loss: 2.4601298345323226

Epoch: 6| Step: 1
Training loss: 2.300200461898265
Validation loss: 2.464205735998587

Epoch: 6| Step: 2
Training loss: 2.7200521222898715
Validation loss: 2.4646980967157006

Epoch: 6| Step: 3
Training loss: 3.2345911221007286
Validation loss: 2.4683048298121646

Epoch: 6| Step: 4
Training loss: 2.9378868010690944
Validation loss: 2.467525072888524

Epoch: 6| Step: 5
Training loss: 2.16448860242649
Validation loss: 2.4676068973302567

Epoch: 6| Step: 6
Training loss: 2.908621200116406
Validation loss: 2.469935930756382

Epoch: 6| Step: 7
Training loss: 3.236092963506616
Validation loss: 2.4932266071402522

Epoch: 6| Step: 8
Training loss: 2.3882620109704114
Validation loss: 2.504388795182231

Epoch: 6| Step: 9
Training loss: 2.4926422565234563
Validation loss: 2.5253436598406105

Epoch: 6| Step: 10
Training loss: 2.3910702558763046
Validation loss: 2.554861698443924

Epoch: 6| Step: 11
Training loss: 2.2871971471869443
Validation loss: 2.5905975703324096

Epoch: 6| Step: 12
Training loss: 2.7998252098840206
Validation loss: 2.582833271141481

Epoch: 6| Step: 13
Training loss: 3.4186794740979525
Validation loss: 2.5617950304103148

Epoch: 97| Step: 0
Training loss: 2.78329563990975
Validation loss: 2.5302739329484876

Epoch: 6| Step: 1
Training loss: 2.3317551952658784
Validation loss: 2.5063126368880306

Epoch: 6| Step: 2
Training loss: 3.134580346452178
Validation loss: 2.4878697961068497

Epoch: 6| Step: 3
Training loss: 2.7421970638966946
Validation loss: 2.479794949421322

Epoch: 6| Step: 4
Training loss: 2.6168134279662865
Validation loss: 2.470134568554403

Epoch: 6| Step: 5
Training loss: 2.6720191961272763
Validation loss: 2.471276517078

Epoch: 6| Step: 6
Training loss: 2.7596438975664475
Validation loss: 2.473012681069129

Epoch: 6| Step: 7
Training loss: 3.3747253306200946
Validation loss: 2.4655376909891182

Epoch: 6| Step: 8
Training loss: 2.965334242303741
Validation loss: 2.4716724540158057

Epoch: 6| Step: 9
Training loss: 2.4785125467868987
Validation loss: 2.466472341939202

Epoch: 6| Step: 10
Training loss: 3.125984342041632
Validation loss: 2.4780587033172172

Epoch: 6| Step: 11
Training loss: 2.03798860647444
Validation loss: 2.4900430515826026

Epoch: 6| Step: 12
Training loss: 2.479740642706477
Validation loss: 2.4940426150887878

Epoch: 6| Step: 13
Training loss: 2.40510660724339
Validation loss: 2.5089077941286786

Epoch: 98| Step: 0
Training loss: 2.6488944140567945
Validation loss: 2.5117202054776433

Epoch: 6| Step: 1
Training loss: 2.8728566680537098
Validation loss: 2.5357705538760444

Epoch: 6| Step: 2
Training loss: 2.6175223520630735
Validation loss: 2.5172967631586207

Epoch: 6| Step: 3
Training loss: 2.1844064909448253
Validation loss: 2.5247918857779656

Epoch: 6| Step: 4
Training loss: 2.2812119572223915
Validation loss: 2.528679770701776

Epoch: 6| Step: 5
Training loss: 2.856706885726471
Validation loss: 2.5351338141187227

Epoch: 6| Step: 6
Training loss: 2.7082127666535603
Validation loss: 2.5303644058898445

Epoch: 6| Step: 7
Training loss: 3.109914454911922
Validation loss: 2.52927038904461

Epoch: 6| Step: 8
Training loss: 2.751000569123376
Validation loss: 2.5169206728495865

Epoch: 6| Step: 9
Training loss: 2.3539111806144946
Validation loss: 2.519326810308119

Epoch: 6| Step: 10
Training loss: 3.263369716899954
Validation loss: 2.5493351222565446

Epoch: 6| Step: 11
Training loss: 3.100536263135549
Validation loss: 2.5342690579734195

Epoch: 6| Step: 12
Training loss: 2.6890082451923427
Validation loss: 2.536486400105236

Epoch: 6| Step: 13
Training loss: 2.712531684655276
Validation loss: 2.5177577338511634

Epoch: 99| Step: 0
Training loss: 2.7403135498963627
Validation loss: 2.5177912728987546

Epoch: 6| Step: 1
Training loss: 2.2508164090260925
Validation loss: 2.5387901514737274

Epoch: 6| Step: 2
Training loss: 2.1186834589318932
Validation loss: 2.5439055990917576

Epoch: 6| Step: 3
Training loss: 3.191375470800934
Validation loss: 2.5570443104782745

Epoch: 6| Step: 4
Training loss: 3.6066487903351736
Validation loss: 2.561142493592028

Epoch: 6| Step: 5
Training loss: 2.2579422751752714
Validation loss: 2.538874908660928

Epoch: 6| Step: 6
Training loss: 2.923043246982581
Validation loss: 2.5202539497322882

Epoch: 6| Step: 7
Training loss: 2.662673185205225
Validation loss: 2.5216280528485755

Epoch: 6| Step: 8
Training loss: 2.4946768355305884
Validation loss: 2.518499437235473

Epoch: 6| Step: 9
Training loss: 2.418744826988977
Validation loss: 2.5127058060082055

Epoch: 6| Step: 10
Training loss: 3.015824859795565
Validation loss: 2.5168989233937533

Epoch: 6| Step: 11
Training loss: 2.9791898570903204
Validation loss: 2.525055630937222

Epoch: 6| Step: 12
Training loss: 2.875015424604088
Validation loss: 2.518592638654201

Epoch: 6| Step: 13
Training loss: 2.5065978724427502
Validation loss: 2.5473323114258597

Epoch: 100| Step: 0
Training loss: 2.6960472100705957
Validation loss: 2.540962473367567

Epoch: 6| Step: 1
Training loss: 2.924672465448288
Validation loss: 2.565994835815075

Epoch: 6| Step: 2
Training loss: 2.5203715024830298
Validation loss: 2.563475981462748

Epoch: 6| Step: 3
Training loss: 2.8474512850619202
Validation loss: 2.567394373598058

Epoch: 6| Step: 4
Training loss: 2.6638439457982366
Validation loss: 2.556500948809695

Epoch: 6| Step: 5
Training loss: 2.9603660656127717
Validation loss: 2.520558024822147

Epoch: 6| Step: 6
Training loss: 2.36237049050559
Validation loss: 2.4920150579394162

Epoch: 6| Step: 7
Training loss: 2.454350256623928
Validation loss: 2.477393059742932

Epoch: 6| Step: 8
Training loss: 3.2925363349502725
Validation loss: 2.4728768517310904

Epoch: 6| Step: 9
Training loss: 2.7822508993319595
Validation loss: 2.4764917084757725

Epoch: 6| Step: 10
Training loss: 2.9517321657495135
Validation loss: 2.475536258674193

Epoch: 6| Step: 11
Training loss: 2.8598462326221603
Validation loss: 2.4769719561308547

Epoch: 6| Step: 12
Training loss: 2.8912907014283458
Validation loss: 2.4796667441719586

Epoch: 6| Step: 13
Training loss: 1.4970144123308629
Validation loss: 2.4910176554803853

Epoch: 101| Step: 0
Training loss: 2.8776027673686264
Validation loss: 2.504134082512241

Epoch: 6| Step: 1
Training loss: 2.7734816856625475
Validation loss: 2.521499528131862

Epoch: 6| Step: 2
Training loss: 2.4596001760698925
Validation loss: 2.5214749682998683

Epoch: 6| Step: 3
Training loss: 2.5789358077829863
Validation loss: 2.5308046423901214

Epoch: 6| Step: 4
Training loss: 3.1246960301382467
Validation loss: 2.540884322850911

Epoch: 6| Step: 5
Training loss: 2.8554351846415575
Validation loss: 2.5511151410758544

Epoch: 6| Step: 6
Training loss: 3.039268663175075
Validation loss: 2.540053880879203

Epoch: 6| Step: 7
Training loss: 2.6010459409980857
Validation loss: 2.5358109224163328

Epoch: 6| Step: 8
Training loss: 2.897167822267267
Validation loss: 2.5259196556537753

Epoch: 6| Step: 9
Training loss: 2.3953654841406364
Validation loss: 2.5319998666144787

Epoch: 6| Step: 10
Training loss: 2.8046002812757354
Validation loss: 2.5188979880334563

Epoch: 6| Step: 11
Training loss: 2.8715217115673077
Validation loss: 2.5162163769693913

Epoch: 6| Step: 12
Training loss: 2.1849651363568086
Validation loss: 2.51643413701911

Epoch: 6| Step: 13
Training loss: 2.2941483902633353
Validation loss: 2.509579708209818

Epoch: 102| Step: 0
Training loss: 2.7876049689128335
Validation loss: 2.51451993963402

Epoch: 6| Step: 1
Training loss: 2.674396239978864
Validation loss: 2.524568081537173

Epoch: 6| Step: 2
Training loss: 2.702929803933853
Validation loss: 2.532317969949517

Epoch: 6| Step: 3
Training loss: 2.150922080742191
Validation loss: 2.5339299918778293

Epoch: 6| Step: 4
Training loss: 2.517256782094495
Validation loss: 2.5186041173304754

Epoch: 6| Step: 5
Training loss: 3.006782652682297
Validation loss: 2.5212715789709157

Epoch: 6| Step: 6
Training loss: 2.4487053973510897
Validation loss: 2.519268998347281

Epoch: 6| Step: 7
Training loss: 2.6315627032330737
Validation loss: 2.51736446513819

Epoch: 6| Step: 8
Training loss: 2.410021414918845
Validation loss: 2.5281653843097334

Epoch: 6| Step: 9
Training loss: 2.941262291048878
Validation loss: 2.5305324597319308

Epoch: 6| Step: 10
Training loss: 3.1638096084314746
Validation loss: 2.5276866408325334

Epoch: 6| Step: 11
Training loss: 2.6960720595286207
Validation loss: 2.5056325833681297

Epoch: 6| Step: 12
Training loss: 2.9632322734282273
Validation loss: 2.5158307055025873

Epoch: 6| Step: 13
Training loss: 2.834316157999332
Validation loss: 2.5207273538458796

Epoch: 103| Step: 0
Training loss: 2.15902111725509
Validation loss: 2.528902889709725

Epoch: 6| Step: 1
Training loss: 2.859538923057007
Validation loss: 2.5263086639425514

Epoch: 6| Step: 2
Training loss: 2.6648536916797294
Validation loss: 2.5178137304417185

Epoch: 6| Step: 3
Training loss: 2.314696737739399
Validation loss: 2.530937812621544

Epoch: 6| Step: 4
Training loss: 2.823713793005295
Validation loss: 2.529043242673121

Epoch: 6| Step: 5
Training loss: 3.10859355979242
Validation loss: 2.5270592892269566

Epoch: 6| Step: 6
Training loss: 1.8770290204600706
Validation loss: 2.5210313514979035

Epoch: 6| Step: 7
Training loss: 2.6139178904718223
Validation loss: 2.516634491487496

Epoch: 6| Step: 8
Training loss: 2.6006078486391533
Validation loss: 2.512426697440191

Epoch: 6| Step: 9
Training loss: 3.2687621311524264
Validation loss: 2.523084966310797

Epoch: 6| Step: 10
Training loss: 2.937127921706305
Validation loss: 2.522078425685278

Epoch: 6| Step: 11
Training loss: 2.8535956672445204
Validation loss: 2.524291359063519

Epoch: 6| Step: 12
Training loss: 2.9903678440677615
Validation loss: 2.5237966845877673

Epoch: 6| Step: 13
Training loss: 2.192124628102115
Validation loss: 2.52374993863881

Epoch: 104| Step: 0
Training loss: 2.3798375303447505
Validation loss: 2.530379993166366

Epoch: 6| Step: 1
Training loss: 2.896638131771151
Validation loss: 2.550418057476204

Epoch: 6| Step: 2
Training loss: 3.1124931304733274
Validation loss: 2.555787005078557

Epoch: 6| Step: 3
Training loss: 2.520612428512267
Validation loss: 2.569958696358645

Epoch: 6| Step: 4
Training loss: 2.9161596856682754
Validation loss: 2.5581663319374774

Epoch: 6| Step: 5
Training loss: 2.2154400273468267
Validation loss: 2.5268621724310134

Epoch: 6| Step: 6
Training loss: 3.0005745337607945
Validation loss: 2.484823309147472

Epoch: 6| Step: 7
Training loss: 2.8420993919200375
Validation loss: 2.4885723845003542

Epoch: 6| Step: 8
Training loss: 2.137452831082487
Validation loss: 2.4830125258831974

Epoch: 6| Step: 9
Training loss: 2.0615625273857905
Validation loss: 2.466473654695565

Epoch: 6| Step: 10
Training loss: 2.8857307859863597
Validation loss: 2.4813748834394165

Epoch: 6| Step: 11
Training loss: 3.0672502073076
Validation loss: 2.50069065500833

Epoch: 6| Step: 12
Training loss: 2.9663159481004513
Validation loss: 2.5183547392755945

Epoch: 6| Step: 13
Training loss: 2.6190283834485886
Validation loss: 2.558940471122818

Epoch: 105| Step: 0
Training loss: 3.103177896684571
Validation loss: 2.634406051693105

Epoch: 6| Step: 1
Training loss: 2.4092505436479352
Validation loss: 2.6261486601028547

Epoch: 6| Step: 2
Training loss: 2.583514504591482
Validation loss: 2.630830316743725

Epoch: 6| Step: 3
Training loss: 2.91364798780889
Validation loss: 2.6149745763320316

Epoch: 6| Step: 4
Training loss: 2.5863763258233123
Validation loss: 2.6104791633672257

Epoch: 6| Step: 5
Training loss: 2.778502575304569
Validation loss: 2.6127476252144413

Epoch: 6| Step: 6
Training loss: 2.168716988875712
Validation loss: 2.5964789802682096

Epoch: 6| Step: 7
Training loss: 2.634180907569275
Validation loss: 2.570319237456942

Epoch: 6| Step: 8
Training loss: 2.731766770138308
Validation loss: 2.5274205177542606

Epoch: 6| Step: 9
Training loss: 2.5295543878321687
Validation loss: 2.4949991230411652

Epoch: 6| Step: 10
Training loss: 2.64051403286511
Validation loss: 2.4777450566751082

Epoch: 6| Step: 11
Training loss: 3.211701313881763
Validation loss: 2.4653082091260425

Epoch: 6| Step: 12
Training loss: 3.208948563545992
Validation loss: 2.4574103780641994

Epoch: 6| Step: 13
Training loss: 2.5560662984711833
Validation loss: 2.4463553269213483

Epoch: 106| Step: 0
Training loss: 2.2580287526194724
Validation loss: 2.4479145756077436

Epoch: 6| Step: 1
Training loss: 2.170512478693918
Validation loss: 2.4542791461314204

Epoch: 6| Step: 2
Training loss: 2.3731833085137155
Validation loss: 2.461832937119787

Epoch: 6| Step: 3
Training loss: 2.9856360202942875
Validation loss: 2.4572472325699084

Epoch: 6| Step: 4
Training loss: 2.3904169528165977
Validation loss: 2.468500458315037

Epoch: 6| Step: 5
Training loss: 2.4393792366462135
Validation loss: 2.4889308716172303

Epoch: 6| Step: 6
Training loss: 2.688730889486998
Validation loss: 2.5163179692918196

Epoch: 6| Step: 7
Training loss: 2.3385903085069177
Validation loss: 2.5324078930566105

Epoch: 6| Step: 8
Training loss: 2.819016515477068
Validation loss: 2.541206193751807

Epoch: 6| Step: 9
Training loss: 3.061555054910502
Validation loss: 2.5423052479982964

Epoch: 6| Step: 10
Training loss: 3.3316395429836883
Validation loss: 2.5447205218863376

Epoch: 6| Step: 11
Training loss: 3.4635885517513123
Validation loss: 2.5419979259514487

Epoch: 6| Step: 12
Training loss: 2.461933430977957
Validation loss: 2.538690744955831

Epoch: 6| Step: 13
Training loss: 2.6893882328091756
Validation loss: 2.5302873697987

Epoch: 107| Step: 0
Training loss: 2.4846086692083373
Validation loss: 2.514163725639823

Epoch: 6| Step: 1
Training loss: 3.3866646838244945
Validation loss: 2.4972789825648216

Epoch: 6| Step: 2
Training loss: 2.596868823029187
Validation loss: 2.486250317349664

Epoch: 6| Step: 3
Training loss: 2.562035867480173
Validation loss: 2.4564731151198926

Epoch: 6| Step: 4
Training loss: 2.711234744263391
Validation loss: 2.4547698227855173

Epoch: 6| Step: 5
Training loss: 2.5824843108742916
Validation loss: 2.458419501781235

Epoch: 6| Step: 6
Training loss: 2.900078404123074
Validation loss: 2.4546604099881852

Epoch: 6| Step: 7
Training loss: 2.4160094079914454
Validation loss: 2.4495489033347355

Epoch: 6| Step: 8
Training loss: 3.0356231291091493
Validation loss: 2.4602506789574243

Epoch: 6| Step: 9
Training loss: 3.1363462842177308
Validation loss: 2.4705723860987647

Epoch: 6| Step: 10
Training loss: 2.7895915066687396
Validation loss: 2.4923204213026238

Epoch: 6| Step: 11
Training loss: 2.348947382617357
Validation loss: 2.513338061804507

Epoch: 6| Step: 12
Training loss: 2.0749976927962748
Validation loss: 2.53177654461995

Epoch: 6| Step: 13
Training loss: 1.8680818083981339
Validation loss: 2.5570463437090325

Epoch: 108| Step: 0
Training loss: 2.519758631182305
Validation loss: 2.5768696244025837

Epoch: 6| Step: 1
Training loss: 2.7887616676486595
Validation loss: 2.6061027385116056

Epoch: 6| Step: 2
Training loss: 2.240185418629196
Validation loss: 2.6052342247638984

Epoch: 6| Step: 3
Training loss: 2.865112551730216
Validation loss: 2.602239677621435

Epoch: 6| Step: 4
Training loss: 3.1165608706001957
Validation loss: 2.6006306152478706

Epoch: 6| Step: 5
Training loss: 2.228883303401478
Validation loss: 2.5555276173301995

Epoch: 6| Step: 6
Training loss: 3.053533077397516
Validation loss: 2.5229226727610325

Epoch: 6| Step: 7
Training loss: 2.647151668640675
Validation loss: 2.502420191729182

Epoch: 6| Step: 8
Training loss: 2.3608628186091236
Validation loss: 2.4854108230272782

Epoch: 6| Step: 9
Training loss: 2.0144446413676316
Validation loss: 2.4779545564709653

Epoch: 6| Step: 10
Training loss: 2.913844368878077
Validation loss: 2.492996726845078

Epoch: 6| Step: 11
Training loss: 2.8930551572170544
Validation loss: 2.489933146032978

Epoch: 6| Step: 12
Training loss: 2.148048726365644
Validation loss: 2.4936417130048745

Epoch: 6| Step: 13
Training loss: 3.569213430908953
Validation loss: 2.4842156985833403

Epoch: 109| Step: 0
Training loss: 2.5146701493298123
Validation loss: 2.4817908508473456

Epoch: 6| Step: 1
Training loss: 2.334758346109722
Validation loss: 2.484462547397846

Epoch: 6| Step: 2
Training loss: 2.894510493030332
Validation loss: 2.4673679419475514

Epoch: 6| Step: 3
Training loss: 2.778191245354459
Validation loss: 2.451357538466931

Epoch: 6| Step: 4
Training loss: 2.825032772448007
Validation loss: 2.4806685327430946

Epoch: 6| Step: 5
Training loss: 2.0694110563288657
Validation loss: 2.5092523266272395

Epoch: 6| Step: 6
Training loss: 2.3940894262235934
Validation loss: 2.547077693557507

Epoch: 6| Step: 7
Training loss: 2.856430288422027
Validation loss: 2.589326074919016

Epoch: 6| Step: 8
Training loss: 2.7694985370291216
Validation loss: 2.6078329183478752

Epoch: 6| Step: 9
Training loss: 2.8818367648147745
Validation loss: 2.596146543977687

Epoch: 6| Step: 10
Training loss: 2.4974751120120553
Validation loss: 2.5740825623213563

Epoch: 6| Step: 11
Training loss: 2.8496903636109363
Validation loss: 2.554216538978707

Epoch: 6| Step: 12
Training loss: 2.948918975348245
Validation loss: 2.5344230668236336

Epoch: 6| Step: 13
Training loss: 2.8609158059364885
Validation loss: 2.525764082861293

Epoch: 110| Step: 0
Training loss: 2.571722136876007
Validation loss: 2.5043363331223003

Epoch: 6| Step: 1
Training loss: 2.3279590931605116
Validation loss: 2.516580073110933

Epoch: 6| Step: 2
Training loss: 2.649568389436112
Validation loss: 2.5379117482414384

Epoch: 6| Step: 3
Training loss: 2.3176331125690104
Validation loss: 2.552345352501047

Epoch: 6| Step: 4
Training loss: 2.997255182266687
Validation loss: 2.5627935658073473

Epoch: 6| Step: 5
Training loss: 3.1197658191728896
Validation loss: 2.5200674120081414

Epoch: 6| Step: 6
Training loss: 2.5885949439559894
Validation loss: 2.4972638651964663

Epoch: 6| Step: 7
Training loss: 2.157561746290566
Validation loss: 2.4830811012029463

Epoch: 6| Step: 8
Training loss: 2.9412001984705003
Validation loss: 2.4781993760303225

Epoch: 6| Step: 9
Training loss: 2.2822983305668547
Validation loss: 2.478716481519329

Epoch: 6| Step: 10
Training loss: 2.7140991067915734
Validation loss: 2.481536838364054

Epoch: 6| Step: 11
Training loss: 2.9955925354371375
Validation loss: 2.491818385564288

Epoch: 6| Step: 12
Training loss: 2.617916540833666
Validation loss: 2.5053892774876116

Epoch: 6| Step: 13
Training loss: 2.639763415023889
Validation loss: 2.5064875135053235

Epoch: 111| Step: 0
Training loss: 2.262020321573434
Validation loss: 2.516584509546414

Epoch: 6| Step: 1
Training loss: 2.582366413749381
Validation loss: 2.5314869746327995

Epoch: 6| Step: 2
Training loss: 2.384411884787508
Validation loss: 2.530214012360267

Epoch: 6| Step: 3
Training loss: 2.566039455452405
Validation loss: 2.5325801630274762

Epoch: 6| Step: 4
Training loss: 2.812981458356701
Validation loss: 2.533555964905242

Epoch: 6| Step: 5
Training loss: 2.6714057733424115
Validation loss: 2.5454712615518336

Epoch: 6| Step: 6
Training loss: 2.516637562800325
Validation loss: 2.556853948603791

Epoch: 6| Step: 7
Training loss: 2.672228427288476
Validation loss: 2.547718780275776

Epoch: 6| Step: 8
Training loss: 2.1078788820393966
Validation loss: 2.5513929955663994

Epoch: 6| Step: 9
Training loss: 2.872606027105508
Validation loss: 2.5529507081987703

Epoch: 6| Step: 10
Training loss: 2.79161796717133
Validation loss: 2.5474346086375776

Epoch: 6| Step: 11
Training loss: 2.357470014913407
Validation loss: 2.549145902900092

Epoch: 6| Step: 12
Training loss: 3.1638796906583613
Validation loss: 2.52212597817388

Epoch: 6| Step: 13
Training loss: 2.9089100467206115
Validation loss: 2.515588183175959

Epoch: 112| Step: 0
Training loss: 1.943289689391299
Validation loss: 2.485181437538284

Epoch: 6| Step: 1
Training loss: 2.8340170166323144
Validation loss: 2.4759353511815925

Epoch: 6| Step: 2
Training loss: 2.7685152458059115
Validation loss: 2.478429606329654

Epoch: 6| Step: 3
Training loss: 2.9307720974130858
Validation loss: 2.4841400621520924

Epoch: 6| Step: 4
Training loss: 2.8882892141111123
Validation loss: 2.4939240104524654

Epoch: 6| Step: 5
Training loss: 2.4371152720905074
Validation loss: 2.5268940170824963

Epoch: 6| Step: 6
Training loss: 2.3667435938014174
Validation loss: 2.540687328651195

Epoch: 6| Step: 7
Training loss: 3.058567870360659
Validation loss: 2.5439869767495336

Epoch: 6| Step: 8
Training loss: 2.1374443537735703
Validation loss: 2.5620040373577972

Epoch: 6| Step: 9
Training loss: 2.1050760047945807
Validation loss: 2.5868978942289775

Epoch: 6| Step: 10
Training loss: 2.5729540205700867
Validation loss: 2.588460064317295

Epoch: 6| Step: 11
Training loss: 2.912515756458016
Validation loss: 2.5918977194508406

Epoch: 6| Step: 12
Training loss: 2.2525720730003913
Validation loss: 2.5681752872299026

Epoch: 6| Step: 13
Training loss: 3.513840150222881
Validation loss: 2.5516121652679686

Epoch: 113| Step: 0
Training loss: 2.266205601454547
Validation loss: 2.534812635097018

Epoch: 6| Step: 1
Training loss: 2.1830848824271207
Validation loss: 2.524267081309734

Epoch: 6| Step: 2
Training loss: 2.8557741599347923
Validation loss: 2.5148203204906325

Epoch: 6| Step: 3
Training loss: 2.484176147947887
Validation loss: 2.5162815100249305

Epoch: 6| Step: 4
Training loss: 2.7557870489047467
Validation loss: 2.5151280176102264

Epoch: 6| Step: 5
Training loss: 2.3765106416219623
Validation loss: 2.527464875067995

Epoch: 6| Step: 6
Training loss: 3.307174720598892
Validation loss: 2.5215829002464445

Epoch: 6| Step: 7
Training loss: 3.219496260862257
Validation loss: 2.512830810571574

Epoch: 6| Step: 8
Training loss: 2.6464514923868143
Validation loss: 2.5362933166828987

Epoch: 6| Step: 9
Training loss: 2.539531018972929
Validation loss: 2.5421091737110255

Epoch: 6| Step: 10
Training loss: 2.301115002088799
Validation loss: 2.551499184679299

Epoch: 6| Step: 11
Training loss: 2.7417416984548604
Validation loss: 2.5564790427080575

Epoch: 6| Step: 12
Training loss: 2.1151153446425983
Validation loss: 2.551393348251306

Epoch: 6| Step: 13
Training loss: 1.9645476525775716
Validation loss: 2.5703717471249776

Epoch: 114| Step: 0
Training loss: 3.267982763396697
Validation loss: 2.5892410583015675

Epoch: 6| Step: 1
Training loss: 2.5210859839405777
Validation loss: 2.5637795749853427

Epoch: 6| Step: 2
Training loss: 2.5895949944755063
Validation loss: 2.524130987507116

Epoch: 6| Step: 3
Training loss: 2.5741442841799618
Validation loss: 2.508115891983328

Epoch: 6| Step: 4
Training loss: 3.08590829569844
Validation loss: 2.500636565268702

Epoch: 6| Step: 5
Training loss: 2.404151298522313
Validation loss: 2.502569518852978

Epoch: 6| Step: 6
Training loss: 3.1884261637000764
Validation loss: 2.510010554503056

Epoch: 6| Step: 7
Training loss: 1.941944009458927
Validation loss: 2.5235500190600506

Epoch: 6| Step: 8
Training loss: 2.4454243302291547
Validation loss: 2.5347489016253495

Epoch: 6| Step: 9
Training loss: 2.6185285633941042
Validation loss: 2.5444649016204006

Epoch: 6| Step: 10
Training loss: 2.0288412043295194
Validation loss: 2.5446618471853917

Epoch: 6| Step: 11
Training loss: 2.3893303450937546
Validation loss: 2.58560434442121

Epoch: 6| Step: 12
Training loss: 2.5692374813364665
Validation loss: 2.586291338129392

Epoch: 6| Step: 13
Training loss: 2.4638980556615215
Validation loss: 2.592785828658907

Epoch: 115| Step: 0
Training loss: 3.0212642143145563
Validation loss: 2.6450971748941376

Epoch: 6| Step: 1
Training loss: 2.7154431456681167
Validation loss: 2.674446982283845

Epoch: 6| Step: 2
Training loss: 2.1918767468195584
Validation loss: 2.696838751448668

Epoch: 6| Step: 3
Training loss: 2.25593821730459
Validation loss: 2.6753845442929305

Epoch: 6| Step: 4
Training loss: 2.2938595654671636
Validation loss: 2.622613382501564

Epoch: 6| Step: 5
Training loss: 2.895646800521704
Validation loss: 2.5908208151706447

Epoch: 6| Step: 6
Training loss: 2.5594513598778006
Validation loss: 2.5359574417766604

Epoch: 6| Step: 7
Training loss: 2.845255694170554
Validation loss: 2.51272860181771

Epoch: 6| Step: 8
Training loss: 2.2784241196079003
Validation loss: 2.5365364032539373

Epoch: 6| Step: 9
Training loss: 2.3311476575053174
Validation loss: 2.5535332189864715

Epoch: 6| Step: 10
Training loss: 2.5678656622072475
Validation loss: 2.5457756890557213

Epoch: 6| Step: 11
Training loss: 2.728267803146985
Validation loss: 2.5588047266558456

Epoch: 6| Step: 12
Training loss: 2.9330514541206965
Validation loss: 2.5553529827252506

Epoch: 6| Step: 13
Training loss: 2.874834802276621
Validation loss: 2.554611916923093

Epoch: 116| Step: 0
Training loss: 2.2976672823737387
Validation loss: 2.5757164666156664

Epoch: 6| Step: 1
Training loss: 2.550856397844998
Validation loss: 2.5778442070800547

Epoch: 6| Step: 2
Training loss: 2.120745944737743
Validation loss: 2.570913692905751

Epoch: 6| Step: 3
Training loss: 2.2864065548212205
Validation loss: 2.5622505368694704

Epoch: 6| Step: 4
Training loss: 2.4816687857484534
Validation loss: 2.5616884924982886

Epoch: 6| Step: 5
Training loss: 3.358626881178905
Validation loss: 2.5482283584387653

Epoch: 6| Step: 6
Training loss: 2.8519606220902864
Validation loss: 2.5320617465980524

Epoch: 6| Step: 7
Training loss: 2.9819409095645684
Validation loss: 2.536939723655314

Epoch: 6| Step: 8
Training loss: 2.5932232425272406
Validation loss: 2.5426438828539184

Epoch: 6| Step: 9
Training loss: 2.0742807037813935
Validation loss: 2.542513448249073

Epoch: 6| Step: 10
Training loss: 3.032566846345068
Validation loss: 2.5435741068154507

Epoch: 6| Step: 11
Training loss: 1.9163376346065875
Validation loss: 2.545676831250699

Epoch: 6| Step: 12
Training loss: 2.1992996228053108
Validation loss: 2.5636609911695225

Epoch: 6| Step: 13
Training loss: 2.8145585050318407
Validation loss: 2.5954203341615982

Epoch: 117| Step: 0
Training loss: 2.541850932794994
Validation loss: 2.622695958630399

Epoch: 6| Step: 1
Training loss: 3.019265936759298
Validation loss: 2.679828715776295

Epoch: 6| Step: 2
Training loss: 2.4888091433139787
Validation loss: 2.692047339499846

Epoch: 6| Step: 3
Training loss: 2.9313486501527657
Validation loss: 2.69524248414769

Epoch: 6| Step: 4
Training loss: 2.6645146766468844
Validation loss: 2.6720748132940915

Epoch: 6| Step: 5
Training loss: 2.4262433433539665
Validation loss: 2.6388735437369806

Epoch: 6| Step: 6
Training loss: 2.091843833360642
Validation loss: 2.5957649046013604

Epoch: 6| Step: 7
Training loss: 2.7684720143079553
Validation loss: 2.567240328526025

Epoch: 6| Step: 8
Training loss: 2.3722605717299112
Validation loss: 2.5608029512392716

Epoch: 6| Step: 9
Training loss: 2.4160172039202603
Validation loss: 2.540007770223814

Epoch: 6| Step: 10
Training loss: 1.8592176611230555
Validation loss: 2.5409954216186006

Epoch: 6| Step: 11
Training loss: 2.9192199067373465
Validation loss: 2.5547145362776353

Epoch: 6| Step: 12
Training loss: 2.5779552057013206
Validation loss: 2.5536074696520865

Epoch: 6| Step: 13
Training loss: 2.5864631602600343
Validation loss: 2.5445711068230605

Epoch: 118| Step: 0
Training loss: 2.419160466025782
Validation loss: 2.531807160974991

Epoch: 6| Step: 1
Training loss: 2.549947839091259
Validation loss: 2.5116023539673917

Epoch: 6| Step: 2
Training loss: 2.4417294707917
Validation loss: 2.5027672372823306

Epoch: 6| Step: 3
Training loss: 2.6245779878988142
Validation loss: 2.5055731662352385

Epoch: 6| Step: 4
Training loss: 2.377665178756359
Validation loss: 2.5338759135811606

Epoch: 6| Step: 5
Training loss: 2.547459915489665
Validation loss: 2.546806473939061

Epoch: 6| Step: 6
Training loss: 2.7780414032346488
Validation loss: 2.5526806398362787

Epoch: 6| Step: 7
Training loss: 2.5787977785759173
Validation loss: 2.5957833948386497

Epoch: 6| Step: 8
Training loss: 2.165976659013235
Validation loss: 2.6046949553798675

Epoch: 6| Step: 9
Training loss: 2.3065146234967906
Validation loss: 2.615440786618577

Epoch: 6| Step: 10
Training loss: 2.7538044362828336
Validation loss: 2.61031019294206

Epoch: 6| Step: 11
Training loss: 2.6187781211781624
Validation loss: 2.6123855433861505

Epoch: 6| Step: 12
Training loss: 2.6554270647620415
Validation loss: 2.6081667205027825

Epoch: 6| Step: 13
Training loss: 3.0230930339139777
Validation loss: 2.60359557323471

Epoch: 119| Step: 0
Training loss: 2.708179753179431
Validation loss: 2.586645055504999

Epoch: 6| Step: 1
Training loss: 2.679344221987892
Validation loss: 2.5847687843244915

Epoch: 6| Step: 2
Training loss: 2.70007884652195
Validation loss: 2.578990996919952

Epoch: 6| Step: 3
Training loss: 1.7224309172708518
Validation loss: 2.569672664324412

Epoch: 6| Step: 4
Training loss: 2.916562559903785
Validation loss: 2.605756473386906

Epoch: 6| Step: 5
Training loss: 2.207173948822917
Validation loss: 2.598441899244304

Epoch: 6| Step: 6
Training loss: 2.839097125567091
Validation loss: 2.604159194115203

Epoch: 6| Step: 7
Training loss: 2.007614422835313
Validation loss: 2.587182120977908

Epoch: 6| Step: 8
Training loss: 2.406509880795416
Validation loss: 2.5691989920758735

Epoch: 6| Step: 9
Training loss: 2.6983648293698854
Validation loss: 2.5893484229142216

Epoch: 6| Step: 10
Training loss: 2.592334223038763
Validation loss: 2.6062732319251225

Epoch: 6| Step: 11
Training loss: 2.4262717422226543
Validation loss: 2.613321492456269

Epoch: 6| Step: 12
Training loss: 2.7368793463296783
Validation loss: 2.6340926368762685

Epoch: 6| Step: 13
Training loss: 2.607053443510147
Validation loss: 2.6272890664709165

Epoch: 120| Step: 0
Training loss: 2.7199631538419884
Validation loss: 2.6155052463541772

Epoch: 6| Step: 1
Training loss: 3.234607632881659
Validation loss: 2.6152638849372396

Epoch: 6| Step: 2
Training loss: 1.6952352901754955
Validation loss: 2.612282834234289

Epoch: 6| Step: 3
Training loss: 2.338396392138762
Validation loss: 2.602693976293907

Epoch: 6| Step: 4
Training loss: 2.418467826056693
Validation loss: 2.58404725921184

Epoch: 6| Step: 5
Training loss: 2.6043620125300495
Validation loss: 2.581835540477813

Epoch: 6| Step: 6
Training loss: 2.3081444627451027
Validation loss: 2.5944138077910623

Epoch: 6| Step: 7
Training loss: 1.8966922979963852
Validation loss: 2.598745687340361

Epoch: 6| Step: 8
Training loss: 2.362844076784388
Validation loss: 2.602944867060834

Epoch: 6| Step: 9
Training loss: 2.266193818344372
Validation loss: 2.620016693397714

Epoch: 6| Step: 10
Training loss: 2.6583467174260864
Validation loss: 2.617706960382117

Epoch: 6| Step: 11
Training loss: 2.591644535603944
Validation loss: 2.6161479973844357

Epoch: 6| Step: 12
Training loss: 2.754950229451369
Validation loss: 2.5807111996999534

Epoch: 6| Step: 13
Training loss: 3.4420600469251235
Validation loss: 2.548675245113836

Epoch: 121| Step: 0
Training loss: 2.1041176163901856
Validation loss: 2.530963658187616

Epoch: 6| Step: 1
Training loss: 2.7691571799509993
Validation loss: 2.5338937152021046

Epoch: 6| Step: 2
Training loss: 2.6088201424016164
Validation loss: 2.536254076795958

Epoch: 6| Step: 3
Training loss: 2.4196308198025136
Validation loss: 2.539571435751696

Epoch: 6| Step: 4
Training loss: 2.9065927282897706
Validation loss: 2.5422984897451757

Epoch: 6| Step: 5
Training loss: 2.4197254116552274
Validation loss: 2.5575659245416626

Epoch: 6| Step: 6
Training loss: 2.4813254971873286
Validation loss: 2.5881965113114602

Epoch: 6| Step: 7
Training loss: 2.5790985118959147
Validation loss: 2.6073553964429053

Epoch: 6| Step: 8
Training loss: 1.9744780031719182
Validation loss: 2.6499658104294412

Epoch: 6| Step: 9
Training loss: 2.387398131429205
Validation loss: 2.691228083208507

Epoch: 6| Step: 10
Training loss: 2.9867374995324383
Validation loss: 2.704039301027134

Epoch: 6| Step: 11
Training loss: 2.319074203981886
Validation loss: 2.716800511732833

Epoch: 6| Step: 12
Training loss: 2.5756140300884613
Validation loss: 2.713875581601068

Epoch: 6| Step: 13
Training loss: 3.1889226394031036
Validation loss: 2.671570553357851

Epoch: 122| Step: 0
Training loss: 2.5029372126971836
Validation loss: 2.601574498487984

Epoch: 6| Step: 1
Training loss: 2.684679813864665
Validation loss: 2.558838874843654

Epoch: 6| Step: 2
Training loss: 2.447849408030599
Validation loss: 2.526301648777472

Epoch: 6| Step: 3
Training loss: 1.9912624230868357
Validation loss: 2.511472684582805

Epoch: 6| Step: 4
Training loss: 2.0849940991947093
Validation loss: 2.4961478467727365

Epoch: 6| Step: 5
Training loss: 3.1961359954182953
Validation loss: 2.5263031739914994

Epoch: 6| Step: 6
Training loss: 2.0015548384294233
Validation loss: 2.4965535146669375

Epoch: 6| Step: 7
Training loss: 2.6388401116218825
Validation loss: 2.500302061680567

Epoch: 6| Step: 8
Training loss: 2.530804159201226
Validation loss: 2.5502085523437716

Epoch: 6| Step: 9
Training loss: 2.495354914677974
Validation loss: 2.581473514321112

Epoch: 6| Step: 10
Training loss: 2.8835793899182707
Validation loss: 2.6028872477979963

Epoch: 6| Step: 11
Training loss: 2.572573516655295
Validation loss: 2.641508091278289

Epoch: 6| Step: 12
Training loss: 2.7942628223390864
Validation loss: 2.631918342133256

Epoch: 6| Step: 13
Training loss: 3.0236034101361753
Validation loss: 2.6427846932015706

Epoch: 123| Step: 0
Training loss: 2.2922848879064355
Validation loss: 2.5985634108520053

Epoch: 6| Step: 1
Training loss: 2.492322194635958
Validation loss: 2.5806586232526425

Epoch: 6| Step: 2
Training loss: 2.6038274213439765
Validation loss: 2.5712090100804486

Epoch: 6| Step: 3
Training loss: 2.981846562163802
Validation loss: 2.5310868818744137

Epoch: 6| Step: 4
Training loss: 2.19269750838579
Validation loss: 2.5242122069369706

Epoch: 6| Step: 5
Training loss: 1.8688490110979372
Validation loss: 2.525704777974268

Epoch: 6| Step: 6
Training loss: 2.4660885141889075
Validation loss: 2.5392357935428214

Epoch: 6| Step: 7
Training loss: 2.3587039220501014
Validation loss: 2.5435755894198953

Epoch: 6| Step: 8
Training loss: 2.591074839375001
Validation loss: 2.553276569271827

Epoch: 6| Step: 9
Training loss: 2.5927172523632236
Validation loss: 2.545801796857203

Epoch: 6| Step: 10
Training loss: 2.723879130411231
Validation loss: 2.564917497769487

Epoch: 6| Step: 11
Training loss: 1.8945472952566356
Validation loss: 2.6032609515533154

Epoch: 6| Step: 12
Training loss: 2.8131161332769357
Validation loss: 2.616404179573302

Epoch: 6| Step: 13
Training loss: 3.0937617137956903
Validation loss: 2.6596030905965278

Epoch: 124| Step: 0
Training loss: 2.603258467935696
Validation loss: 2.682568567457031

Epoch: 6| Step: 1
Training loss: 3.220814459491683
Validation loss: 2.7124761286343366

Epoch: 6| Step: 2
Training loss: 3.1613779241065627
Validation loss: 2.691035370885737

Epoch: 6| Step: 3
Training loss: 2.1513006933380416
Validation loss: 2.6465823965707616

Epoch: 6| Step: 4
Training loss: 2.2047694136273854
Validation loss: 2.6257281433724464

Epoch: 6| Step: 5
Training loss: 2.434436927565977
Validation loss: 2.6249280158904624

Epoch: 6| Step: 6
Training loss: 2.7085309078825515
Validation loss: 2.6190564557887823

Epoch: 6| Step: 7
Training loss: 2.1746734593252395
Validation loss: 2.6229095964270415

Epoch: 6| Step: 8
Training loss: 2.4086090018117092
Validation loss: 2.625215276435214

Epoch: 6| Step: 9
Training loss: 2.3576785424302513
Validation loss: 2.6310929539124968

Epoch: 6| Step: 10
Training loss: 2.773364944583516
Validation loss: 2.645659860497605

Epoch: 6| Step: 11
Training loss: 2.5047395602007834
Validation loss: 2.641842193558578

Epoch: 6| Step: 12
Training loss: 2.010086968091981
Validation loss: 2.639623389995666

Epoch: 6| Step: 13
Training loss: 3.101186888120622
Validation loss: 2.6323551260140743

Epoch: 125| Step: 0
Training loss: 2.1674195839859096
Validation loss: 2.6261614697396003

Epoch: 6| Step: 1
Training loss: 2.556215628320596
Validation loss: 2.6283534789485907

Epoch: 6| Step: 2
Training loss: 2.2715022183977798
Validation loss: 2.6266942941045466

Epoch: 6| Step: 3
Training loss: 2.557423098126712
Validation loss: 2.614434455725291

Epoch: 6| Step: 4
Training loss: 2.4889794632159075
Validation loss: 2.5872060174293967

Epoch: 6| Step: 5
Training loss: 2.4713883606957294
Validation loss: 2.574084360994576

Epoch: 6| Step: 6
Training loss: 2.865055965389586
Validation loss: 2.5781783818410924

Epoch: 6| Step: 7
Training loss: 2.9597429669104343
Validation loss: 2.565790074670699

Epoch: 6| Step: 8
Training loss: 2.134435574075533
Validation loss: 2.5782722886001137

Epoch: 6| Step: 9
Training loss: 2.8712319269470923
Validation loss: 2.578386245671842

Epoch: 6| Step: 10
Training loss: 2.6637610659286657
Validation loss: 2.589946149325693

Epoch: 6| Step: 11
Training loss: 2.1535802705895497
Validation loss: 2.5803949639208383

Epoch: 6| Step: 12
Training loss: 2.907023337234763
Validation loss: 2.603309813933865

Epoch: 6| Step: 13
Training loss: 1.8473474353365376
Validation loss: 2.6086116050124364

Epoch: 126| Step: 0
Training loss: 2.8014299181550535
Validation loss: 2.6142574888894297

Epoch: 6| Step: 1
Training loss: 2.6826888200870265
Validation loss: 2.595095982903763

Epoch: 6| Step: 2
Training loss: 3.004677940032081
Validation loss: 2.561684948797407

Epoch: 6| Step: 3
Training loss: 2.4146475962484883
Validation loss: 2.5396255764900344

Epoch: 6| Step: 4
Training loss: 1.7849708644508673
Validation loss: 2.511651027509441

Epoch: 6| Step: 5
Training loss: 2.8027929851504627
Validation loss: 2.499092522883359

Epoch: 6| Step: 6
Training loss: 2.2374517424936324
Validation loss: 2.4794146730073066

Epoch: 6| Step: 7
Training loss: 2.61001971840261
Validation loss: 2.4901014267661603

Epoch: 6| Step: 8
Training loss: 2.109838703191575
Validation loss: 2.490037135742481

Epoch: 6| Step: 9
Training loss: 2.147607039425177
Validation loss: 2.50422879418519

Epoch: 6| Step: 10
Training loss: 2.807490486271569
Validation loss: 2.509855815776282

Epoch: 6| Step: 11
Training loss: 1.9704375527589069
Validation loss: 2.527840150140771

Epoch: 6| Step: 12
Training loss: 3.1908974586300483
Validation loss: 2.551150020252065

Epoch: 6| Step: 13
Training loss: 1.7263673697975495
Validation loss: 2.5856135440875745

Epoch: 127| Step: 0
Training loss: 2.2538381265430707
Validation loss: 2.6440921648619518

Epoch: 6| Step: 1
Training loss: 2.1365258166366794
Validation loss: 2.704899966892105

Epoch: 6| Step: 2
Training loss: 2.5686948375858383
Validation loss: 2.7190676248897363

Epoch: 6| Step: 3
Training loss: 3.011386877791423
Validation loss: 2.6844440808733756

Epoch: 6| Step: 4
Training loss: 2.4435950149600183
Validation loss: 2.6356698392499363

Epoch: 6| Step: 5
Training loss: 2.354527932413498
Validation loss: 2.555514875976648

Epoch: 6| Step: 6
Training loss: 2.4720264373958134
Validation loss: 2.499620013943532

Epoch: 6| Step: 7
Training loss: 2.021199170324539
Validation loss: 2.4858183632753765

Epoch: 6| Step: 8
Training loss: 2.6827682713643672
Validation loss: 2.479525715807479

Epoch: 6| Step: 9
Training loss: 2.620234477929377
Validation loss: 2.496829173990382

Epoch: 6| Step: 10
Training loss: 3.0318159381285716
Validation loss: 2.546911981584542

Epoch: 6| Step: 11
Training loss: 2.466796681697835
Validation loss: 2.5633717536497933

Epoch: 6| Step: 12
Training loss: 2.404643228283225
Validation loss: 2.5702972566255027

Epoch: 6| Step: 13
Training loss: 2.9165704075505716
Validation loss: 2.5658234145007177

Epoch: 128| Step: 0
Training loss: 2.2824062395841533
Validation loss: 2.5819170864255154

Epoch: 6| Step: 1
Training loss: 3.232664973864745
Validation loss: 2.615031909657352

Epoch: 6| Step: 2
Training loss: 2.4499463912392634
Validation loss: 2.6271398087999978

Epoch: 6| Step: 3
Training loss: 1.9843583594397936
Validation loss: 2.6850537315277054

Epoch: 6| Step: 4
Training loss: 2.9026218861198125
Validation loss: 2.730519303733141

Epoch: 6| Step: 5
Training loss: 2.521486171541527
Validation loss: 2.7472336559934973

Epoch: 6| Step: 6
Training loss: 2.408993234829966
Validation loss: 2.762645352196536

Epoch: 6| Step: 7
Training loss: 2.426542841333661
Validation loss: 2.7489927168009536

Epoch: 6| Step: 8
Training loss: 2.749761744495195
Validation loss: 2.6688838676846505

Epoch: 6| Step: 9
Training loss: 2.2301090304487827
Validation loss: 2.6235989212116038

Epoch: 6| Step: 10
Training loss: 2.000155204472888
Validation loss: 2.566026566480324

Epoch: 6| Step: 11
Training loss: 2.3704847279531216
Validation loss: 2.5347514675414433

Epoch: 6| Step: 12
Training loss: 2.1361511704031955
Validation loss: 2.5050942693014253

Epoch: 6| Step: 13
Training loss: 2.9856997440685418
Validation loss: 2.477469811731638

Epoch: 129| Step: 0
Training loss: 2.212545719859701
Validation loss: 2.478153457750279

Epoch: 6| Step: 1
Training loss: 2.7439910087660575
Validation loss: 2.478844381182736

Epoch: 6| Step: 2
Training loss: 2.9108941493182394
Validation loss: 2.4728745709818507

Epoch: 6| Step: 3
Training loss: 2.567958136137082
Validation loss: 2.4794937435758633

Epoch: 6| Step: 4
Training loss: 2.8663092575236235
Validation loss: 2.5325358953079053

Epoch: 6| Step: 5
Training loss: 2.156259287938556
Validation loss: 2.600556555759646

Epoch: 6| Step: 6
Training loss: 2.3449293094220396
Validation loss: 2.625597466342418

Epoch: 6| Step: 7
Training loss: 2.027869948233126
Validation loss: 2.6357311781117927

Epoch: 6| Step: 8
Training loss: 2.470864175364928
Validation loss: 2.650358323822861

Epoch: 6| Step: 9
Training loss: 2.6656586907640207
Validation loss: 2.6339785739290322

Epoch: 6| Step: 10
Training loss: 2.369945166231148
Validation loss: 2.6421558680109363

Epoch: 6| Step: 11
Training loss: 2.577656651351351
Validation loss: 2.6326988304977768

Epoch: 6| Step: 12
Training loss: 1.9124079189697496
Validation loss: 2.6167855265218183

Epoch: 6| Step: 13
Training loss: 2.3132484874318435
Validation loss: 2.6159132016161677

Epoch: 130| Step: 0
Training loss: 2.4443808051215705
Validation loss: 2.6063733765924995

Epoch: 6| Step: 1
Training loss: 2.748675113922519
Validation loss: 2.5678708576396128

Epoch: 6| Step: 2
Training loss: 2.327413975225025
Validation loss: 2.5620894874840636

Epoch: 6| Step: 3
Training loss: 2.526991570534514
Validation loss: 2.5522971958728546

Epoch: 6| Step: 4
Training loss: 1.7292849795145842
Validation loss: 2.545157499616089

Epoch: 6| Step: 5
Training loss: 2.6212029015089438
Validation loss: 2.5275374785541467

Epoch: 6| Step: 6
Training loss: 2.2453420956969974
Validation loss: 2.51892842404571

Epoch: 6| Step: 7
Training loss: 2.550506343310929
Validation loss: 2.5384598898309196

Epoch: 6| Step: 8
Training loss: 2.1126432742678265
Validation loss: 2.5585281966108617

Epoch: 6| Step: 9
Training loss: 2.681711038997246
Validation loss: 2.594723192363041

Epoch: 6| Step: 10
Training loss: 2.7429933586526953
Validation loss: 2.582089278071238

Epoch: 6| Step: 11
Training loss: 2.252239490309635
Validation loss: 2.5913276752429666

Epoch: 6| Step: 12
Training loss: 2.5927905410805927
Validation loss: 2.5725730722039257

Epoch: 6| Step: 13
Training loss: 2.056937490630804
Validation loss: 2.548733346626149

Epoch: 131| Step: 0
Training loss: 1.8860279026819364
Validation loss: 2.536181490350414

Epoch: 6| Step: 1
Training loss: 2.5599987569448315
Validation loss: 2.5047308705361586

Epoch: 6| Step: 2
Training loss: 2.8695198571913436
Validation loss: 2.528751473524348

Epoch: 6| Step: 3
Training loss: 2.1075467699320867
Validation loss: 2.498865814733443

Epoch: 6| Step: 4
Training loss: 2.523599719806389
Validation loss: 2.5106066767750637

Epoch: 6| Step: 5
Training loss: 2.543150817635044
Validation loss: 2.509293921741054

Epoch: 6| Step: 6
Training loss: 2.4934457693740946
Validation loss: 2.512203346827822

Epoch: 6| Step: 7
Training loss: 2.358413601465225
Validation loss: 2.5279928854951508

Epoch: 6| Step: 8
Training loss: 2.3911020638169846
Validation loss: 2.5409911993185985

Epoch: 6| Step: 9
Training loss: 2.436255797706622
Validation loss: 2.5667124324112245

Epoch: 6| Step: 10
Training loss: 2.339410451976605
Validation loss: 2.570723457545906

Epoch: 6| Step: 11
Training loss: 2.0140367504808836
Validation loss: 2.6007645650283897

Epoch: 6| Step: 12
Training loss: 2.547199813631425
Validation loss: 2.604609981745321

Epoch: 6| Step: 13
Training loss: 2.6084174495048424
Validation loss: 2.604174823050903

Epoch: 132| Step: 0
Training loss: 1.6897648341869163
Validation loss: 2.6432152276990286

Epoch: 6| Step: 1
Training loss: 2.649869008695454
Validation loss: 2.6741600970600987

Epoch: 6| Step: 2
Training loss: 2.3443455257408794
Validation loss: 2.6720527542302888

Epoch: 6| Step: 3
Training loss: 2.3129550383040973
Validation loss: 2.6803405161213063

Epoch: 6| Step: 4
Training loss: 2.5302601515414893
Validation loss: 2.673849686190725

Epoch: 6| Step: 5
Training loss: 2.6085463253073375
Validation loss: 2.628909710889724

Epoch: 6| Step: 6
Training loss: 2.6181731688110936
Validation loss: 2.5990204264954517

Epoch: 6| Step: 7
Training loss: 2.289065832975389
Validation loss: 2.575546374180293

Epoch: 6| Step: 8
Training loss: 2.3950611915814757
Validation loss: 2.5364661272942493

Epoch: 6| Step: 9
Training loss: 2.451140457499104
Validation loss: 2.512138676455622

Epoch: 6| Step: 10
Training loss: 2.231548308618644
Validation loss: 2.5043895813523744

Epoch: 6| Step: 11
Training loss: 2.715843839793812
Validation loss: 2.4754703569906993

Epoch: 6| Step: 12
Training loss: 2.52302250239815
Validation loss: 2.4827408495980876

Epoch: 6| Step: 13
Training loss: 1.81099065878706
Validation loss: 2.5068720432710676

Epoch: 133| Step: 0
Training loss: 2.0695195820912593
Validation loss: 2.5326032850644156

Epoch: 6| Step: 1
Training loss: 2.734785997292799
Validation loss: 2.554844304320437

Epoch: 6| Step: 2
Training loss: 2.4370367147867817
Validation loss: 2.5822538365827925

Epoch: 6| Step: 3
Training loss: 2.682130550743056
Validation loss: 2.629844989532576

Epoch: 6| Step: 4
Training loss: 1.8163073441024116
Validation loss: 2.648764200981108

Epoch: 6| Step: 5
Training loss: 2.676561495217905
Validation loss: 2.673238573638375

Epoch: 6| Step: 6
Training loss: 2.0090765035749127
Validation loss: 2.647717047000195

Epoch: 6| Step: 7
Training loss: 2.573186965726256
Validation loss: 2.6435456375887294

Epoch: 6| Step: 8
Training loss: 2.2006379286330207
Validation loss: 2.611110403691655

Epoch: 6| Step: 9
Training loss: 1.8206823407148804
Validation loss: 2.574623117604345

Epoch: 6| Step: 10
Training loss: 2.9227985411683544
Validation loss: 2.5583846518336513

Epoch: 6| Step: 11
Training loss: 2.8536407840129647
Validation loss: 2.522757810982423

Epoch: 6| Step: 12
Training loss: 1.5592006945231238
Validation loss: 2.5219199231127676

Epoch: 6| Step: 13
Training loss: 2.0614700057470463
Validation loss: 2.5171319341859784

Epoch: 134| Step: 0
Training loss: 2.69802127669692
Validation loss: 2.4903076047865196

Epoch: 6| Step: 1
Training loss: 2.754444345701044
Validation loss: 2.4937276747048065

Epoch: 6| Step: 2
Training loss: 2.0364364141535036
Validation loss: 2.500449457066679

Epoch: 6| Step: 3
Training loss: 2.061096523069914
Validation loss: 2.502511938526237

Epoch: 6| Step: 4
Training loss: 2.3580613679285345
Validation loss: 2.5205824735728277

Epoch: 6| Step: 5
Training loss: 2.459656978665471
Validation loss: 2.5375377110907413

Epoch: 6| Step: 6
Training loss: 2.7106790996603505
Validation loss: 2.5473529561720665

Epoch: 6| Step: 7
Training loss: 2.0668175329496448
Validation loss: 2.5558076743147735

Epoch: 6| Step: 8
Training loss: 2.0134682168472158
Validation loss: 2.5523401766914424

Epoch: 6| Step: 9
Training loss: 2.1619452851012406
Validation loss: 2.5876511034925698

Epoch: 6| Step: 10
Training loss: 2.5187487429480813
Validation loss: 2.5642800610072993

Epoch: 6| Step: 11
Training loss: 2.3990241212447123
Validation loss: 2.5735787488910273

Epoch: 6| Step: 12
Training loss: 1.9724797840315338
Validation loss: 2.561127926355584

Epoch: 6| Step: 13
Training loss: 2.388192329086585
Validation loss: 2.5319939698288416

Epoch: 135| Step: 0
Training loss: 2.1718347120321884
Validation loss: 2.524669343880879

Epoch: 6| Step: 1
Training loss: 1.9931504857948001
Validation loss: 2.527314227845432

Epoch: 6| Step: 2
Training loss: 2.4633128494766905
Validation loss: 2.523588726074233

Epoch: 6| Step: 3
Training loss: 2.1023163418381325
Validation loss: 2.5128797571971746

Epoch: 6| Step: 4
Training loss: 2.3711396013379735
Validation loss: 2.5146875649424865

Epoch: 6| Step: 5
Training loss: 2.239210218946084
Validation loss: 2.551013801947874

Epoch: 6| Step: 6
Training loss: 2.519826283295307
Validation loss: 2.5847584226985068

Epoch: 6| Step: 7
Training loss: 2.4773294603025278
Validation loss: 2.613219958082808

Epoch: 6| Step: 8
Training loss: 1.9443338529229786
Validation loss: 2.638251008155494

Epoch: 6| Step: 9
Training loss: 2.7811593887484727
Validation loss: 2.636064582961662

Epoch: 6| Step: 10
Training loss: 2.0352145898697875
Validation loss: 2.584956910983028

Epoch: 6| Step: 11
Training loss: 1.98935195482852
Validation loss: 2.536594864673951

Epoch: 6| Step: 12
Training loss: 2.540674443250633
Validation loss: 2.4929461753450584

Epoch: 6| Step: 13
Training loss: 3.285803405666705
Validation loss: 2.4780824799412264

Epoch: 136| Step: 0
Training loss: 2.5735611719688105
Validation loss: 2.4612805959596735

Epoch: 6| Step: 1
Training loss: 2.612337726134533
Validation loss: 2.4704619137224673

Epoch: 6| Step: 2
Training loss: 1.759510491745572
Validation loss: 2.463336152325117

Epoch: 6| Step: 3
Training loss: 2.416286986768997
Validation loss: 2.4801598849214286

Epoch: 6| Step: 4
Training loss: 1.9391289293097775
Validation loss: 2.5119466138417126

Epoch: 6| Step: 5
Training loss: 2.113057179303336
Validation loss: 2.511557041793867

Epoch: 6| Step: 6
Training loss: 2.295229159946231
Validation loss: 2.5321462197453655

Epoch: 6| Step: 7
Training loss: 2.1589999147797676
Validation loss: 2.5459194095556072

Epoch: 6| Step: 8
Training loss: 2.4457622272958264
Validation loss: 2.5732686831295304

Epoch: 6| Step: 9
Training loss: 2.4600415733360084
Validation loss: 2.5824873564861464

Epoch: 6| Step: 10
Training loss: 2.261019003874706
Validation loss: 2.576886961878503

Epoch: 6| Step: 11
Training loss: 2.1818849705097043
Validation loss: 2.609175586700978

Epoch: 6| Step: 12
Training loss: 2.546201932937503
Validation loss: 2.604510056692569

Epoch: 6| Step: 13
Training loss: 2.2458252854164695
Validation loss: 2.5974267468846675

Epoch: 137| Step: 0
Training loss: 2.500395171404631
Validation loss: 2.603280745566221

Epoch: 6| Step: 1
Training loss: 1.86845846294224
Validation loss: 2.564189391018895

Epoch: 6| Step: 2
Training loss: 2.0850334351417916
Validation loss: 2.5220277933242015

Epoch: 6| Step: 3
Training loss: 2.7241380290660397
Validation loss: 2.521745700898804

Epoch: 6| Step: 4
Training loss: 2.016088151578825
Validation loss: 2.53103135214251

Epoch: 6| Step: 5
Training loss: 2.604620891376127
Validation loss: 2.5007158997669623

Epoch: 6| Step: 6
Training loss: 2.253272749332788
Validation loss: 2.510068279940459

Epoch: 6| Step: 7
Training loss: 2.6403887942155677
Validation loss: 2.5131316646666453

Epoch: 6| Step: 8
Training loss: 2.2108096028461204
Validation loss: 2.5099922209078507

Epoch: 6| Step: 9
Training loss: 1.9699549544940351
Validation loss: 2.533374217633946

Epoch: 6| Step: 10
Training loss: 2.1676943493645147
Validation loss: 2.5365550280984803

Epoch: 6| Step: 11
Training loss: 2.047705329036136
Validation loss: 2.524594258365666

Epoch: 6| Step: 12
Training loss: 2.8041417007884224
Validation loss: 2.526688026181876

Epoch: 6| Step: 13
Training loss: 1.3965733213041713
Validation loss: 2.5160875791293393

Epoch: 138| Step: 0
Training loss: 1.617484908468368
Validation loss: 2.478887376972335

Epoch: 6| Step: 1
Training loss: 2.613363906169
Validation loss: 2.471253015752862

Epoch: 6| Step: 2
Training loss: 1.9237362912329712
Validation loss: 2.496159727529052

Epoch: 6| Step: 3
Training loss: 1.9978702649829705
Validation loss: 2.527287825593482

Epoch: 6| Step: 4
Training loss: 2.437784227281352
Validation loss: 2.532362019773616

Epoch: 6| Step: 5
Training loss: 2.49709971995785
Validation loss: 2.5570387992919015

Epoch: 6| Step: 6
Training loss: 1.7876446698739545
Validation loss: 2.5584344183821317

Epoch: 6| Step: 7
Training loss: 2.65328616673833
Validation loss: 2.5747284785792006

Epoch: 6| Step: 8
Training loss: 2.212604015944125
Validation loss: 2.5353296679663173

Epoch: 6| Step: 9
Training loss: 2.6897421067284513
Validation loss: 2.489895321249797

Epoch: 6| Step: 10
Training loss: 1.8206065844918267
Validation loss: 2.4612282378926085

Epoch: 6| Step: 11
Training loss: 2.378691464704709
Validation loss: 2.440318820743538

Epoch: 6| Step: 12
Training loss: 2.726740440530267
Validation loss: 2.434614895721309

Epoch: 6| Step: 13
Training loss: 1.2269977356222161
Validation loss: 2.4424889820214077

Epoch: 139| Step: 0
Training loss: 2.5597251196150497
Validation loss: 2.4481982702547356

Epoch: 6| Step: 1
Training loss: 1.6168832538808415
Validation loss: 2.4544603289983447

Epoch: 6| Step: 2
Training loss: 2.2436498465539696
Validation loss: 2.5071392042947354

Epoch: 6| Step: 3
Training loss: 1.9431584086572184
Validation loss: 2.5496656694514517

Epoch: 6| Step: 4
Training loss: 1.952677683151355
Validation loss: 2.602876915946833

Epoch: 6| Step: 5
Training loss: 2.242176866672304
Validation loss: 2.5845673495281227

Epoch: 6| Step: 6
Training loss: 2.765442923031838
Validation loss: 2.5775520709832835

Epoch: 6| Step: 7
Training loss: 2.437723589692575
Validation loss: 2.5597302284127608

Epoch: 6| Step: 8
Training loss: 2.461988533464344
Validation loss: 2.5319168891535555

Epoch: 6| Step: 9
Training loss: 2.924696432157683
Validation loss: 2.509153059732149

Epoch: 6| Step: 10
Training loss: 2.2054043064843722
Validation loss: 2.474044763753233

Epoch: 6| Step: 11
Training loss: 1.9906937927144719
Validation loss: 2.465205453723341

Epoch: 6| Step: 12
Training loss: 2.0657865752539664
Validation loss: 2.441914704698328

Epoch: 6| Step: 13
Training loss: 2.195802898545927
Validation loss: 2.4349592264550237

Epoch: 140| Step: 0
Training loss: 2.359264446977898
Validation loss: 2.4317413576738116

Epoch: 6| Step: 1
Training loss: 2.3368875364144337
Validation loss: 2.438685849427729

Epoch: 6| Step: 2
Training loss: 2.1907201770779836
Validation loss: 2.424301292320191

Epoch: 6| Step: 3
Training loss: 2.4252665736968404
Validation loss: 2.439731165731568

Epoch: 6| Step: 4
Training loss: 2.331730144237462
Validation loss: 2.452582299348912

Epoch: 6| Step: 5
Training loss: 2.042935606357585
Validation loss: 2.5052396390166978

Epoch: 6| Step: 6
Training loss: 1.779607517498187
Validation loss: 2.5234615693436115

Epoch: 6| Step: 7
Training loss: 2.1146008219880508
Validation loss: 2.5790107848589523

Epoch: 6| Step: 8
Training loss: 2.1752769118550197
Validation loss: 2.5533435250806638

Epoch: 6| Step: 9
Training loss: 2.3966805549541053
Validation loss: 2.4845715681888825

Epoch: 6| Step: 10
Training loss: 2.374835460384088
Validation loss: 2.47304584628721

Epoch: 6| Step: 11
Training loss: 1.8977398630554163
Validation loss: 2.4730553698151323

Epoch: 6| Step: 12
Training loss: 2.087118436010827
Validation loss: 2.47261049575981

Epoch: 6| Step: 13
Training loss: 2.5520438885397727
Validation loss: 2.445965687497762

Epoch: 141| Step: 0
Training loss: 2.1454425814005535
Validation loss: 2.4521229290143594

Epoch: 6| Step: 1
Training loss: 2.0507616023984423
Validation loss: 2.449353190919418

Epoch: 6| Step: 2
Training loss: 2.3496452956652614
Validation loss: 2.4537548131666056

Epoch: 6| Step: 3
Training loss: 1.7388121062210737
Validation loss: 2.466673393401087

Epoch: 6| Step: 4
Training loss: 2.469711502771404
Validation loss: 2.4652826641827166

Epoch: 6| Step: 5
Training loss: 2.538363410369088
Validation loss: 2.4724845381434055

Epoch: 6| Step: 6
Training loss: 1.6300668949606052
Validation loss: 2.4966355480610334

Epoch: 6| Step: 7
Training loss: 2.03122511628388
Validation loss: 2.519045019932001

Epoch: 6| Step: 8
Training loss: 1.8006587783309265
Validation loss: 2.525560271545936

Epoch: 6| Step: 9
Training loss: 2.5871942238110366
Validation loss: 2.5332176433316738

Epoch: 6| Step: 10
Training loss: 2.3682927236312423
Validation loss: 2.5215059720488266

Epoch: 6| Step: 11
Training loss: 1.805122356124663
Validation loss: 2.51842898574064

Epoch: 6| Step: 12
Training loss: 2.1025429179452577
Validation loss: 2.4925621919359453

Epoch: 6| Step: 13
Training loss: 3.052935241612167
Validation loss: 2.4834538926517884

Epoch: 142| Step: 0
Training loss: 1.6108872798932048
Validation loss: 2.4748489581561457

Epoch: 6| Step: 1
Training loss: 2.612993848931379
Validation loss: 2.455011459028779

Epoch: 6| Step: 2
Training loss: 2.5812866245285453
Validation loss: 2.451434375653461

Epoch: 6| Step: 3
Training loss: 2.199029456981725
Validation loss: 2.439734956972323

Epoch: 6| Step: 4
Training loss: 1.9928082265773666
Validation loss: 2.4435185460698783

Epoch: 6| Step: 5
Training loss: 2.8094531191614265
Validation loss: 2.453725018916806

Epoch: 6| Step: 6
Training loss: 1.7279638066916587
Validation loss: 2.487282659490905

Epoch: 6| Step: 7
Training loss: 2.053154783453828
Validation loss: 2.5132280937025935

Epoch: 6| Step: 8
Training loss: 2.0806323535407656
Validation loss: 2.5220065077294955

Epoch: 6| Step: 9
Training loss: 2.0377402275149703
Validation loss: 2.5327992642440247

Epoch: 6| Step: 10
Training loss: 1.775600106247093
Validation loss: 2.4940691688355385

Epoch: 6| Step: 11
Training loss: 2.475582566719845
Validation loss: 2.4827118327611117

Epoch: 6| Step: 12
Training loss: 1.8152033935162097
Validation loss: 2.4609163006352706

Epoch: 6| Step: 13
Training loss: 2.3131774734774915
Validation loss: 2.436926027151973

Epoch: 143| Step: 0
Training loss: 2.275758587468693
Validation loss: 2.4482728631342585

Epoch: 6| Step: 1
Training loss: 1.8902752765629938
Validation loss: 2.447072909548064

Epoch: 6| Step: 2
Training loss: 1.4975516683233656
Validation loss: 2.453803790002311

Epoch: 6| Step: 3
Training loss: 2.3277630620636436
Validation loss: 2.461212258497421

Epoch: 6| Step: 4
Training loss: 2.2138381101283007
Validation loss: 2.4481901945896927

Epoch: 6| Step: 5
Training loss: 2.534974548693618
Validation loss: 2.4450151868903367

Epoch: 6| Step: 6
Training loss: 1.9909261861900913
Validation loss: 2.4618953363691474

Epoch: 6| Step: 7
Training loss: 2.5778884316770414
Validation loss: 2.46784286790596

Epoch: 6| Step: 8
Training loss: 2.3431768097927828
Validation loss: 2.4852045755639036

Epoch: 6| Step: 9
Training loss: 1.695380284233158
Validation loss: 2.5165847000430093

Epoch: 6| Step: 10
Training loss: 2.4316113083385855
Validation loss: 2.566582873377246

Epoch: 6| Step: 11
Training loss: 1.8352129866143039
Validation loss: 2.5904121542952443

Epoch: 6| Step: 12
Training loss: 2.2776222124191015
Validation loss: 2.602870842887249

Epoch: 6| Step: 13
Training loss: 2.3474358631346592
Validation loss: 2.5261775020963677

Epoch: 144| Step: 0
Training loss: 1.8102843455372937
Validation loss: 2.467722340210497

Epoch: 6| Step: 1
Training loss: 2.1327134553038487
Validation loss: 2.4194576667652683

Epoch: 6| Step: 2
Training loss: 2.0253694362139005
Validation loss: 2.4208791674828904

Epoch: 6| Step: 3
Training loss: 2.240813468976519
Validation loss: 2.441306315158969

Epoch: 6| Step: 4
Training loss: 2.324512520825099
Validation loss: 2.4802733285159375

Epoch: 6| Step: 5
Training loss: 2.0147085546047494
Validation loss: 2.4804884800228413

Epoch: 6| Step: 6
Training loss: 2.5571702564473457
Validation loss: 2.5168712659793075

Epoch: 6| Step: 7
Training loss: 2.384401985705694
Validation loss: 2.533292321457141

Epoch: 6| Step: 8
Training loss: 2.0922416833836937
Validation loss: 2.5601312797799887

Epoch: 6| Step: 9
Training loss: 2.3148447469966
Validation loss: 2.568032346083904

Epoch: 6| Step: 10
Training loss: 2.3393657113211117
Validation loss: 2.6247466649222053

Epoch: 6| Step: 11
Training loss: 2.0064557311675864
Validation loss: 2.6231115065047685

Epoch: 6| Step: 12
Training loss: 2.5926921479723957
Validation loss: 2.61989544583999

Epoch: 6| Step: 13
Training loss: 2.3528068013248244
Validation loss: 2.5438676849463726

Epoch: 145| Step: 0
Training loss: 1.9923658702508813
Validation loss: 2.4856271681983864

Epoch: 6| Step: 1
Training loss: 1.929822168014113
Validation loss: 2.450259525214245

Epoch: 6| Step: 2
Training loss: 2.187048620247817
Validation loss: 2.4035824032608746

Epoch: 6| Step: 3
Training loss: 1.7959167579102249
Validation loss: 2.3778654320062134

Epoch: 6| Step: 4
Training loss: 2.6273155898287377
Validation loss: 2.3657891980404004

Epoch: 6| Step: 5
Training loss: 2.2150771137531637
Validation loss: 2.3929879911271468

Epoch: 6| Step: 6
Training loss: 2.4832295590251343
Validation loss: 2.393679226043484

Epoch: 6| Step: 7
Training loss: 2.362960516232896
Validation loss: 2.3917196187191645

Epoch: 6| Step: 8
Training loss: 1.8551738303858445
Validation loss: 2.4012917642457414

Epoch: 6| Step: 9
Training loss: 1.573395847651888
Validation loss: 2.436030021144444

Epoch: 6| Step: 10
Training loss: 2.4060075315704808
Validation loss: 2.477220102163266

Epoch: 6| Step: 11
Training loss: 2.190590555352865
Validation loss: 2.476231174594865

Epoch: 6| Step: 12
Training loss: 2.4892529277671276
Validation loss: 2.4889236872396148

Epoch: 6| Step: 13
Training loss: 1.868068598906948
Validation loss: 2.4847715028766997

Epoch: 146| Step: 0
Training loss: 1.870395410623296
Validation loss: 2.484775072697996

Epoch: 6| Step: 1
Training loss: 2.394562315000368
Validation loss: 2.474295449638877

Epoch: 6| Step: 2
Training loss: 1.8730303273350113
Validation loss: 2.478887971631537

Epoch: 6| Step: 3
Training loss: 2.339674598043806
Validation loss: 2.4422582466233376

Epoch: 6| Step: 4
Training loss: 2.2770024300664065
Validation loss: 2.4317633121366358

Epoch: 6| Step: 5
Training loss: 1.776576352296101
Validation loss: 2.436523004005284

Epoch: 6| Step: 6
Training loss: 1.6322861694684807
Validation loss: 2.4446644001976057

Epoch: 6| Step: 7
Training loss: 1.7473485478817394
Validation loss: 2.4295183068843684

Epoch: 6| Step: 8
Training loss: 2.414452876159033
Validation loss: 2.454757928646335

Epoch: 6| Step: 9
Training loss: 2.131210228333544
Validation loss: 2.4318357757435978

Epoch: 6| Step: 10
Training loss: 2.4388415239562797
Validation loss: 2.4521854467577864

Epoch: 6| Step: 11
Training loss: 2.6053137325628493
Validation loss: 2.428046227253496

Epoch: 6| Step: 12
Training loss: 1.8862127095373198
Validation loss: 2.4546918336121637

Epoch: 6| Step: 13
Training loss: 1.9936602963922636
Validation loss: 2.444510829522233

Epoch: 147| Step: 0
Training loss: 1.8051782246357213
Validation loss: 2.463283862927497

Epoch: 6| Step: 1
Training loss: 2.0486393669751664
Validation loss: 2.4595060254165673

Epoch: 6| Step: 2
Training loss: 2.2346876232481656
Validation loss: 2.445100196046779

Epoch: 6| Step: 3
Training loss: 1.962412488407624
Validation loss: 2.4399706653766193

Epoch: 6| Step: 4
Training loss: 2.6167414498627273
Validation loss: 2.4162820372758786

Epoch: 6| Step: 5
Training loss: 2.0895655937113733
Validation loss: 2.4016254190472406

Epoch: 6| Step: 6
Training loss: 2.1247074823439966
Validation loss: 2.389073902928296

Epoch: 6| Step: 7
Training loss: 1.4408588145208983
Validation loss: 2.3792658018759054

Epoch: 6| Step: 8
Training loss: 2.1287957119023693
Validation loss: 2.3686269799779414

Epoch: 6| Step: 9
Training loss: 1.6846723531142227
Validation loss: 2.368635498997325

Epoch: 6| Step: 10
Training loss: 2.5651421300463775
Validation loss: 2.3774894335614087

Epoch: 6| Step: 11
Training loss: 2.383547009935356
Validation loss: 2.382780290907418

Epoch: 6| Step: 12
Training loss: 1.0070924774331387
Validation loss: 2.381244059171924

Epoch: 6| Step: 13
Training loss: 2.5874083793009666
Validation loss: 2.4151147140288924

Epoch: 148| Step: 0
Training loss: 2.0086039011345247
Validation loss: 2.428287854877246

Epoch: 6| Step: 1
Training loss: 1.9012555842471204
Validation loss: 2.4378074386903394

Epoch: 6| Step: 2
Training loss: 1.9321490198283382
Validation loss: 2.4794657867923005

Epoch: 6| Step: 3
Training loss: 2.2502078913967916
Validation loss: 2.5126570544405804

Epoch: 6| Step: 4
Training loss: 1.3552164947866077
Validation loss: 2.4904003150917

Epoch: 6| Step: 5
Training loss: 1.9814867040711237
Validation loss: 2.489799941804235

Epoch: 6| Step: 6
Training loss: 1.9849645985249866
Validation loss: 2.4792580277928034

Epoch: 6| Step: 7
Training loss: 1.7188965474855202
Validation loss: 2.4539630932554286

Epoch: 6| Step: 8
Training loss: 2.443804291026963
Validation loss: 2.4446097755346137

Epoch: 6| Step: 9
Training loss: 2.534244414515388
Validation loss: 2.4181551138431256

Epoch: 6| Step: 10
Training loss: 2.139292727021528
Validation loss: 2.381416844058884

Epoch: 6| Step: 11
Training loss: 2.4867512596850467
Validation loss: 2.4092487293870892

Epoch: 6| Step: 12
Training loss: 2.030700609297099
Validation loss: 2.3867510359109527

Epoch: 6| Step: 13
Training loss: 2.0054431992416344
Validation loss: 2.386046118109002

Epoch: 149| Step: 0
Training loss: 1.9773670112269555
Validation loss: 2.3994973163839863

Epoch: 6| Step: 1
Training loss: 2.190814313993415
Validation loss: 2.3939813212156573

Epoch: 6| Step: 2
Training loss: 2.1402862726343184
Validation loss: 2.4136316334602794

Epoch: 6| Step: 3
Training loss: 1.8243678683448337
Validation loss: 2.4314112662217346

Epoch: 6| Step: 4
Training loss: 1.955520625537004
Validation loss: 2.4582821413288913

Epoch: 6| Step: 5
Training loss: 2.184283043668095
Validation loss: 2.4606849239995157

Epoch: 6| Step: 6
Training loss: 2.0294500739212733
Validation loss: 2.5019079772360104

Epoch: 6| Step: 7
Training loss: 1.509423694654397
Validation loss: 2.506376676130395

Epoch: 6| Step: 8
Training loss: 1.6867567474198615
Validation loss: 2.4960007540531035

Epoch: 6| Step: 9
Training loss: 1.9146876968426025
Validation loss: 2.476034524089964

Epoch: 6| Step: 10
Training loss: 2.1982862213076384
Validation loss: 2.476163754980494

Epoch: 6| Step: 11
Training loss: 1.980676403106894
Validation loss: 2.45290925228268

Epoch: 6| Step: 12
Training loss: 2.1493000310506027
Validation loss: 2.4421197010717943

Epoch: 6| Step: 13
Training loss: 3.056414260038597
Validation loss: 2.4366786951956323

Epoch: 150| Step: 0
Training loss: 1.776589302659308
Validation loss: 2.4518619063055427

Epoch: 6| Step: 1
Training loss: 1.684428421900215
Validation loss: 2.4493248953426443

Epoch: 6| Step: 2
Training loss: 2.350275340081314
Validation loss: 2.460378690378612

Epoch: 6| Step: 3
Training loss: 1.9147861903180126
Validation loss: 2.4792455386814494

Epoch: 6| Step: 4
Training loss: 1.7251214965935104
Validation loss: 2.451947432452273

Epoch: 6| Step: 5
Training loss: 2.0782939870862913
Validation loss: 2.419737197235873

Epoch: 6| Step: 6
Training loss: 2.3845386693934154
Validation loss: 2.4210481278096085

Epoch: 6| Step: 7
Training loss: 2.014837303314013
Validation loss: 2.413200067459637

Epoch: 6| Step: 8
Training loss: 2.1265260041613674
Validation loss: 2.4344193327529666

Epoch: 6| Step: 9
Training loss: 2.361332769523451
Validation loss: 2.4479708492554924

Epoch: 6| Step: 10
Training loss: 1.760809483990222
Validation loss: 2.4594611939798794

Epoch: 6| Step: 11
Training loss: 2.3617864752373907
Validation loss: 2.4283000697583983

Epoch: 6| Step: 12
Training loss: 1.7382438741373294
Validation loss: 2.4228790752896234

Epoch: 6| Step: 13
Training loss: 1.8187655969324588
Validation loss: 2.4215704433662832

Epoch: 151| Step: 0
Training loss: 2.1227719463201846
Validation loss: 2.4444293898068845

Epoch: 6| Step: 1
Training loss: 2.318964814057749
Validation loss: 2.4575196006216156

Epoch: 6| Step: 2
Training loss: 1.6853320713134057
Validation loss: 2.459855874344346

Epoch: 6| Step: 3
Training loss: 2.177223152404225
Validation loss: 2.4433506218012155

Epoch: 6| Step: 4
Training loss: 1.933020181068025
Validation loss: 2.4632955223218937

Epoch: 6| Step: 5
Training loss: 2.715235224978737
Validation loss: 2.4389196951723666

Epoch: 6| Step: 6
Training loss: 1.4147081113156057
Validation loss: 2.418167720218607

Epoch: 6| Step: 7
Training loss: 1.9063069069294647
Validation loss: 2.3995781101264924

Epoch: 6| Step: 8
Training loss: 2.3262877927863834
Validation loss: 2.3810803741706885

Epoch: 6| Step: 9
Training loss: 1.7952762955350858
Validation loss: 2.4042331205314285

Epoch: 6| Step: 10
Training loss: 2.2182351173117443
Validation loss: 2.384781351231042

Epoch: 6| Step: 11
Training loss: 1.7415321383318694
Validation loss: 2.412120228504216

Epoch: 6| Step: 12
Training loss: 1.6070172714938433
Validation loss: 2.4113640022702287

Epoch: 6| Step: 13
Training loss: 1.511420484192073
Validation loss: 2.430402301541039

Epoch: 152| Step: 0
Training loss: 1.7263124725064474
Validation loss: 2.4419041851931014

Epoch: 6| Step: 1
Training loss: 1.4468015680979067
Validation loss: 2.4422738692715966

Epoch: 6| Step: 2
Training loss: 2.0187488567715173
Validation loss: 2.451683964594008

Epoch: 6| Step: 3
Training loss: 2.413776565950803
Validation loss: 2.4314912588955457

Epoch: 6| Step: 4
Training loss: 1.7251643392813556
Validation loss: 2.4374473151694116

Epoch: 6| Step: 5
Training loss: 2.0178539165176854
Validation loss: 2.440485470369582

Epoch: 6| Step: 6
Training loss: 2.05472521149001
Validation loss: 2.429929241890723

Epoch: 6| Step: 7
Training loss: 2.323655414431294
Validation loss: 2.408007694283331

Epoch: 6| Step: 8
Training loss: 1.8211479398241062
Validation loss: 2.3928788024942174

Epoch: 6| Step: 9
Training loss: 1.88539914567369
Validation loss: 2.399071627261293

Epoch: 6| Step: 10
Training loss: 2.2813193950810673
Validation loss: 2.3943792177542305

Epoch: 6| Step: 11
Training loss: 2.045981175609215
Validation loss: 2.4223894269567943

Epoch: 6| Step: 12
Training loss: 2.2064063343712363
Validation loss: 2.431839747964963

Epoch: 6| Step: 13
Training loss: 1.8053814103027843
Validation loss: 2.437890160663637

Epoch: 153| Step: 0
Training loss: 2.4157033732384416
Validation loss: 2.4626814218680444

Epoch: 6| Step: 1
Training loss: 1.7924073780342982
Validation loss: 2.475552189104163

Epoch: 6| Step: 2
Training loss: 1.633998750226256
Validation loss: 2.475222023631993

Epoch: 6| Step: 3
Training loss: 1.8979644814032894
Validation loss: 2.480834212610143

Epoch: 6| Step: 4
Training loss: 1.801851628866803
Validation loss: 2.4838408622613914

Epoch: 6| Step: 5
Training loss: 1.718861524258192
Validation loss: 2.4430237165547886

Epoch: 6| Step: 6
Training loss: 2.2037380799367647
Validation loss: 2.4311480946543007

Epoch: 6| Step: 7
Training loss: 2.0935835131598424
Validation loss: 2.437986049356688

Epoch: 6| Step: 8
Training loss: 2.2371022046631857
Validation loss: 2.432133863021729

Epoch: 6| Step: 9
Training loss: 2.0675629405320466
Validation loss: 2.4488191412892477

Epoch: 6| Step: 10
Training loss: 2.0837540646738226
Validation loss: 2.4308412902123133

Epoch: 6| Step: 11
Training loss: 1.7778648199522036
Validation loss: 2.4180037723078818

Epoch: 6| Step: 12
Training loss: 1.7511202768641565
Validation loss: 2.400594950602634

Epoch: 6| Step: 13
Training loss: 2.23037243850596
Validation loss: 2.4057051307151633

Epoch: 154| Step: 0
Training loss: 2.302837909833179
Validation loss: 2.425873273920713

Epoch: 6| Step: 1
Training loss: 2.2662022348578916
Validation loss: 2.4260002810021173

Epoch: 6| Step: 2
Training loss: 1.20642370841056
Validation loss: 2.446784266828464

Epoch: 6| Step: 3
Training loss: 2.044204717324213
Validation loss: 2.496397384182133

Epoch: 6| Step: 4
Training loss: 1.822152709733493
Validation loss: 2.4533737325095184

Epoch: 6| Step: 5
Training loss: 1.8986674353985533
Validation loss: 2.447604103703748

Epoch: 6| Step: 6
Training loss: 2.3260427290188974
Validation loss: 2.444101987440775

Epoch: 6| Step: 7
Training loss: 2.072531378385401
Validation loss: 2.450198003583466

Epoch: 6| Step: 8
Training loss: 2.259131445624809
Validation loss: 2.453254821155506

Epoch: 6| Step: 9
Training loss: 1.0930671740286995
Validation loss: 2.4805608131403716

Epoch: 6| Step: 10
Training loss: 2.2810297820518843
Validation loss: 2.4773321146667584

Epoch: 6| Step: 11
Training loss: 1.9903172708754544
Validation loss: 2.496233626658724

Epoch: 6| Step: 12
Training loss: 1.468427582110813
Validation loss: 2.489540339314183

Epoch: 6| Step: 13
Training loss: 1.8192310968517555
Validation loss: 2.453242560190814

Epoch: 155| Step: 0
Training loss: 2.424690431321933
Validation loss: 2.4249474457066644

Epoch: 6| Step: 1
Training loss: 2.10293908395667
Validation loss: 2.3911336644106753

Epoch: 6| Step: 2
Training loss: 1.8257631221813142
Validation loss: 2.3712459562051156

Epoch: 6| Step: 3
Training loss: 1.9296871293411209
Validation loss: 2.360503414406998

Epoch: 6| Step: 4
Training loss: 1.9284627015886144
Validation loss: 2.3415261895361565

Epoch: 6| Step: 5
Training loss: 1.7194145305142476
Validation loss: 2.336870579527783

Epoch: 6| Step: 6
Training loss: 2.056961947388169
Validation loss: 2.3295990596066427

Epoch: 6| Step: 7
Training loss: 2.050410122668774
Validation loss: 2.342823303124477

Epoch: 6| Step: 8
Training loss: 2.0953003566540827
Validation loss: 2.3623880885596154

Epoch: 6| Step: 9
Training loss: 1.5902816581771277
Validation loss: 2.3952441831809494

Epoch: 6| Step: 10
Training loss: 1.6913594510341494
Validation loss: 2.425365552740144

Epoch: 6| Step: 11
Training loss: 2.21511004964617
Validation loss: 2.5000751094405094

Epoch: 6| Step: 12
Training loss: 2.266893649890919
Validation loss: 2.539341209897353

Epoch: 6| Step: 13
Training loss: 2.0200428416175273
Validation loss: 2.5688162024429966

Epoch: 156| Step: 0
Training loss: 2.112004428497642
Validation loss: 2.519281597381112

Epoch: 6| Step: 1
Training loss: 2.312080345222915
Validation loss: 2.4862767615003727

Epoch: 6| Step: 2
Training loss: 1.5801437609494062
Validation loss: 2.4438174307020883

Epoch: 6| Step: 3
Training loss: 1.538798353115675
Validation loss: 2.4029455808201385

Epoch: 6| Step: 4
Training loss: 1.919991912030033
Validation loss: 2.386545059384927

Epoch: 6| Step: 5
Training loss: 1.7816776632261622
Validation loss: 2.403303445656341

Epoch: 6| Step: 6
Training loss: 1.842864777727671
Validation loss: 2.427884944730214

Epoch: 6| Step: 7
Training loss: 2.0371613390723704
Validation loss: 2.424693737516694

Epoch: 6| Step: 8
Training loss: 2.128131242426429
Validation loss: 2.435770969199656

Epoch: 6| Step: 9
Training loss: 2.2500162124049696
Validation loss: 2.413655647506991

Epoch: 6| Step: 10
Training loss: 2.3376749269035013
Validation loss: 2.3878895176452146

Epoch: 6| Step: 11
Training loss: 1.4524762746215936
Validation loss: 2.4307814212358037

Epoch: 6| Step: 12
Training loss: 1.9186395221925834
Validation loss: 2.4534108936074133

Epoch: 6| Step: 13
Training loss: 1.9309890620170262
Validation loss: 2.4920226767912617

Epoch: 157| Step: 0
Training loss: 2.128449725277115
Validation loss: 2.5376378497442262

Epoch: 6| Step: 1
Training loss: 1.9928605681710756
Validation loss: 2.524254008498242

Epoch: 6| Step: 2
Training loss: 1.8176189353258774
Validation loss: 2.4999795092491546

Epoch: 6| Step: 3
Training loss: 2.361248358932418
Validation loss: 2.508759339372611

Epoch: 6| Step: 4
Training loss: 1.5687946176453134
Validation loss: 2.457143363818696

Epoch: 6| Step: 5
Training loss: 2.0264643707870453
Validation loss: 2.4710736734003813

Epoch: 6| Step: 6
Training loss: 2.1169157522427544
Validation loss: 2.456714864539567

Epoch: 6| Step: 7
Training loss: 1.7758921973313466
Validation loss: 2.4238466079315386

Epoch: 6| Step: 8
Training loss: 2.056011976941918
Validation loss: 2.43778275395095

Epoch: 6| Step: 9
Training loss: 2.0533758698223163
Validation loss: 2.4240515654694916

Epoch: 6| Step: 10
Training loss: 2.2797490237786433
Validation loss: 2.4136934301927004

Epoch: 6| Step: 11
Training loss: 1.6141916435697499
Validation loss: 2.4148350423419256

Epoch: 6| Step: 12
Training loss: 1.4440770823228037
Validation loss: 2.453632225747526

Epoch: 6| Step: 13
Training loss: 1.798809569156465
Validation loss: 2.497554429916994

Epoch: 158| Step: 0
Training loss: 2.221229993980188
Validation loss: 2.5037679313601733

Epoch: 6| Step: 1
Training loss: 1.7215135032175188
Validation loss: 2.5009986574810696

Epoch: 6| Step: 2
Training loss: 1.3130798875339393
Validation loss: 2.5123336111623944

Epoch: 6| Step: 3
Training loss: 1.8522994108134367
Validation loss: 2.489074388991684

Epoch: 6| Step: 4
Training loss: 1.8107905383377505
Validation loss: 2.4753584269827376

Epoch: 6| Step: 5
Training loss: 2.1045747745178516
Validation loss: 2.4719804464520574

Epoch: 6| Step: 6
Training loss: 2.226823543839509
Validation loss: 2.4615999334530914

Epoch: 6| Step: 7
Training loss: 1.9206702945829
Validation loss: 2.407453580371816

Epoch: 6| Step: 8
Training loss: 1.985490740594765
Validation loss: 2.391587286431435

Epoch: 6| Step: 9
Training loss: 1.7587361261597347
Validation loss: 2.3857684250664564

Epoch: 6| Step: 10
Training loss: 1.0764780041847823
Validation loss: 2.358106044140836

Epoch: 6| Step: 11
Training loss: 1.7231852785234305
Validation loss: 2.3636324279965226

Epoch: 6| Step: 12
Training loss: 2.0860554522479777
Validation loss: 2.3619599253658143

Epoch: 6| Step: 13
Training loss: 2.5170025578191444
Validation loss: 2.395992257374439

Epoch: 159| Step: 0
Training loss: 1.3671260710948618
Validation loss: 2.408733104711246

Epoch: 6| Step: 1
Training loss: 1.5707355897209951
Validation loss: 2.4740058556716527

Epoch: 6| Step: 2
Training loss: 1.8188441825679917
Validation loss: 2.536209839844995

Epoch: 6| Step: 3
Training loss: 2.028228272804919
Validation loss: 2.5532914865346563

Epoch: 6| Step: 4
Training loss: 1.5771808632744457
Validation loss: 2.5765322182941324

Epoch: 6| Step: 5
Training loss: 2.22710200683454
Validation loss: 2.547158336801846

Epoch: 6| Step: 6
Training loss: 2.578750072188938
Validation loss: 2.517978006734275

Epoch: 6| Step: 7
Training loss: 2.023948811030766
Validation loss: 2.4804467046919294

Epoch: 6| Step: 8
Training loss: 1.5290929431796603
Validation loss: 2.468448410211032

Epoch: 6| Step: 9
Training loss: 2.145135512973144
Validation loss: 2.39792491003072

Epoch: 6| Step: 10
Training loss: 1.684323110825101
Validation loss: 2.3894947502661643

Epoch: 6| Step: 11
Training loss: 1.9453426496628217
Validation loss: 2.3684759595525224

Epoch: 6| Step: 12
Training loss: 2.238219681403977
Validation loss: 2.364994334451906

Epoch: 6| Step: 13
Training loss: 1.8985251575216684
Validation loss: 2.339375246466302

Epoch: 160| Step: 0
Training loss: 1.7536696378495038
Validation loss: 2.3768059772976895

Epoch: 6| Step: 1
Training loss: 2.2084524254505724
Validation loss: 2.4249205431338927

Epoch: 6| Step: 2
Training loss: 1.803168379924588
Validation loss: 2.429357146362275

Epoch: 6| Step: 3
Training loss: 2.1108927599883285
Validation loss: 2.444607345191667

Epoch: 6| Step: 4
Training loss: 1.6984959961644939
Validation loss: 2.454460224288981

Epoch: 6| Step: 5
Training loss: 1.5671419998516327
Validation loss: 2.474273468481503

Epoch: 6| Step: 6
Training loss: 2.4936031518210697
Validation loss: 2.4815367443532383

Epoch: 6| Step: 7
Training loss: 2.0061580506166394
Validation loss: 2.4723792066787764

Epoch: 6| Step: 8
Training loss: 2.3648418223609795
Validation loss: 2.4840544570389054

Epoch: 6| Step: 9
Training loss: 2.1036577522057924
Validation loss: 2.4609913096264

Epoch: 6| Step: 10
Training loss: 1.5532565024752638
Validation loss: 2.4087821657461324

Epoch: 6| Step: 11
Training loss: 1.2575161033797537
Validation loss: 2.4021219130606712

Epoch: 6| Step: 12
Training loss: 1.7194429561229887
Validation loss: 2.374475562628985

Epoch: 6| Step: 13
Training loss: 1.351255216561975
Validation loss: 2.378976409166886

Epoch: 161| Step: 0
Training loss: 2.177208588083133
Validation loss: 2.3472155626126514

Epoch: 6| Step: 1
Training loss: 2.1137060841894164
Validation loss: 2.3528647514922634

Epoch: 6| Step: 2
Training loss: 1.953023495897567
Validation loss: 2.3330917877947552

Epoch: 6| Step: 3
Training loss: 2.2541686753165933
Validation loss: 2.332408420304667

Epoch: 6| Step: 4
Training loss: 1.5835940330441132
Validation loss: 2.339068546208302

Epoch: 6| Step: 5
Training loss: 1.7061830416665535
Validation loss: 2.351369789454582

Epoch: 6| Step: 6
Training loss: 1.5703312507382918
Validation loss: 2.361168781262271

Epoch: 6| Step: 7
Training loss: 2.1808101265177497
Validation loss: 2.382069059093334

Epoch: 6| Step: 8
Training loss: 2.1259709552205566
Validation loss: 2.4037957462298083

Epoch: 6| Step: 9
Training loss: 1.789333539529742
Validation loss: 2.410877068870311

Epoch: 6| Step: 10
Training loss: 1.6678895596504337
Validation loss: 2.41869498972495

Epoch: 6| Step: 11
Training loss: 1.4230452532029942
Validation loss: 2.4178425106872847

Epoch: 6| Step: 12
Training loss: 1.674318755808172
Validation loss: 2.3899463170350757

Epoch: 6| Step: 13
Training loss: 0.9394646086754276
Validation loss: 2.41914610991207

Epoch: 162| Step: 0
Training loss: 2.030674075129206
Validation loss: 2.42169276096655

Epoch: 6| Step: 1
Training loss: 1.5914841046248114
Validation loss: 2.3867881451571353

Epoch: 6| Step: 2
Training loss: 2.312596705708627
Validation loss: 2.372135452301975

Epoch: 6| Step: 3
Training loss: 1.8871340719038954
Validation loss: 2.376382002532419

Epoch: 6| Step: 4
Training loss: 2.3208696614771767
Validation loss: 2.3939642033118096

Epoch: 6| Step: 5
Training loss: 2.1424307898578787
Validation loss: 2.392325933783711

Epoch: 6| Step: 6
Training loss: 2.0923187146338815
Validation loss: 2.4346833037220943

Epoch: 6| Step: 7
Training loss: 1.308890829952904
Validation loss: 2.427683816229772

Epoch: 6| Step: 8
Training loss: 1.629848143869979
Validation loss: 2.4548956178728294

Epoch: 6| Step: 9
Training loss: 1.933118727162319
Validation loss: 2.4545733046658196

Epoch: 6| Step: 10
Training loss: 1.5846181558772805
Validation loss: 2.4431710470864427

Epoch: 6| Step: 11
Training loss: 1.759770841093303
Validation loss: 2.4367372435819545

Epoch: 6| Step: 12
Training loss: 2.0334423265272363
Validation loss: 2.388315903168575

Epoch: 6| Step: 13
Training loss: 0.7147977637002477
Validation loss: 2.3547033434540476

Epoch: 163| Step: 0
Training loss: 2.281786398336412
Validation loss: 2.31582048900197

Epoch: 6| Step: 1
Training loss: 1.879926947533857
Validation loss: 2.3151521758851965

Epoch: 6| Step: 2
Training loss: 2.1972406682610472
Validation loss: 2.323933257577913

Epoch: 6| Step: 3
Training loss: 1.6199172565145084
Validation loss: 2.319858661737405

Epoch: 6| Step: 4
Training loss: 1.9990334559470497
Validation loss: 2.3473912219273396

Epoch: 6| Step: 5
Training loss: 1.7098201778738817
Validation loss: 2.3590722887127074

Epoch: 6| Step: 6
Training loss: 1.4641489237515601
Validation loss: 2.321564873190953

Epoch: 6| Step: 7
Training loss: 1.6863926680537598
Validation loss: 2.330407879320853

Epoch: 6| Step: 8
Training loss: 1.8403171974934476
Validation loss: 2.356820897003632

Epoch: 6| Step: 9
Training loss: 1.9860776670199545
Validation loss: 2.399641085520922

Epoch: 6| Step: 10
Training loss: 2.075840432813284
Validation loss: 2.43048915821177

Epoch: 6| Step: 11
Training loss: 1.6129405698759964
Validation loss: 2.4633087490017904

Epoch: 6| Step: 12
Training loss: 1.4204109955093773
Validation loss: 2.5123279825080136

Epoch: 6| Step: 13
Training loss: 1.4184196322791303
Validation loss: 2.5356806509387333

Epoch: 164| Step: 0
Training loss: 1.947255217774032
Validation loss: 2.5250655258450303

Epoch: 6| Step: 1
Training loss: 1.5125296534634292
Validation loss: 2.5101971941165826

Epoch: 6| Step: 2
Training loss: 1.6872085743503102
Validation loss: 2.4650002909533306

Epoch: 6| Step: 3
Training loss: 2.19419359900779
Validation loss: 2.453057581268586

Epoch: 6| Step: 4
Training loss: 1.8251510296343538
Validation loss: 2.415835576756366

Epoch: 6| Step: 5
Training loss: 1.9375380235447988
Validation loss: 2.370384802699678

Epoch: 6| Step: 6
Training loss: 1.9602017789245885
Validation loss: 2.336080668237238

Epoch: 6| Step: 7
Training loss: 1.60744983375309
Validation loss: 2.3225556162029055

Epoch: 6| Step: 8
Training loss: 1.5807711633909258
Validation loss: 2.2933246456333083

Epoch: 6| Step: 9
Training loss: 1.7720414771398838
Validation loss: 2.3182059258658154

Epoch: 6| Step: 10
Training loss: 1.880377053028729
Validation loss: 2.2935121278178476

Epoch: 6| Step: 11
Training loss: 1.8215890754911577
Validation loss: 2.3245336065463276

Epoch: 6| Step: 12
Training loss: 0.9923071000712157
Validation loss: 2.3748899967600936

Epoch: 6| Step: 13
Training loss: 2.4659436850324594
Validation loss: 2.400810264893478

Epoch: 165| Step: 0
Training loss: 1.963381334904305
Validation loss: 2.4270841132080934

Epoch: 6| Step: 1
Training loss: 1.257649808040864
Validation loss: 2.458467154165484

Epoch: 6| Step: 2
Training loss: 2.0805232614960056
Validation loss: 2.4419014912686063

Epoch: 6| Step: 3
Training loss: 1.765769682501094
Validation loss: 2.4377950085413924

Epoch: 6| Step: 4
Training loss: 1.9645852739871308
Validation loss: 2.4009264380314392

Epoch: 6| Step: 5
Training loss: 1.6776210404686076
Validation loss: 2.416652130603744

Epoch: 6| Step: 6
Training loss: 2.1669767842512497
Validation loss: 2.385215781089761

Epoch: 6| Step: 7
Training loss: 2.051749213526126
Validation loss: 2.3593312029680806

Epoch: 6| Step: 8
Training loss: 1.7499474108832338
Validation loss: 2.3675706893656034

Epoch: 6| Step: 9
Training loss: 1.4415841341741764
Validation loss: 2.371074438502149

Epoch: 6| Step: 10
Training loss: 1.792689016955892
Validation loss: 2.367399063763263

Epoch: 6| Step: 11
Training loss: 1.4056842089607664
Validation loss: 2.366129589479883

Epoch: 6| Step: 12
Training loss: 1.5653151519624982
Validation loss: 2.368785854484596

Epoch: 6| Step: 13
Training loss: 1.942546854816467
Validation loss: 2.3741129031814427

Epoch: 166| Step: 0
Training loss: 1.7900037663169748
Validation loss: 2.394691030894619

Epoch: 6| Step: 1
Training loss: 1.8271724468959685
Validation loss: 2.3767231312513966

Epoch: 6| Step: 2
Training loss: 1.851149758478284
Validation loss: 2.412797200614449

Epoch: 6| Step: 3
Training loss: 2.2477702642593775
Validation loss: 2.401325292271487

Epoch: 6| Step: 4
Training loss: 1.5399703238464164
Validation loss: 2.436046411980444

Epoch: 6| Step: 5
Training loss: 1.9563992330649087
Validation loss: 2.445938166075501

Epoch: 6| Step: 6
Training loss: 1.721091253735104
Validation loss: 2.4384600355552757

Epoch: 6| Step: 7
Training loss: 1.7933673623317827
Validation loss: 2.4472612357486714

Epoch: 6| Step: 8
Training loss: 1.6801150465356047
Validation loss: 2.446315563453724

Epoch: 6| Step: 9
Training loss: 1.2040078528106957
Validation loss: 2.4373426278771535

Epoch: 6| Step: 10
Training loss: 1.6805729860745227
Validation loss: 2.429410024577709

Epoch: 6| Step: 11
Training loss: 1.6658476088527456
Validation loss: 2.4163126687992276

Epoch: 6| Step: 12
Training loss: 1.3700304826422058
Validation loss: 2.41749702512052

Epoch: 6| Step: 13
Training loss: 1.5074712337450582
Validation loss: 2.406876691104212

Epoch: 167| Step: 0
Training loss: 1.6914216144383714
Validation loss: 2.3704153086598057

Epoch: 6| Step: 1
Training loss: 1.7218705718992589
Validation loss: 2.378263558210617

Epoch: 6| Step: 2
Training loss: 1.968492400255714
Validation loss: 2.381275469764039

Epoch: 6| Step: 3
Training loss: 2.116253974311463
Validation loss: 2.350415204855762

Epoch: 6| Step: 4
Training loss: 1.438575176683842
Validation loss: 2.3664481528225303

Epoch: 6| Step: 5
Training loss: 1.7411296010342412
Validation loss: 2.373272959255919

Epoch: 6| Step: 6
Training loss: 1.9424962259498961
Validation loss: 2.3850679559602144

Epoch: 6| Step: 7
Training loss: 1.9381743457346945
Validation loss: 2.3840541800472845

Epoch: 6| Step: 8
Training loss: 1.58100318942632
Validation loss: 2.386119794966069

Epoch: 6| Step: 9
Training loss: 1.3791797572011197
Validation loss: 2.413330861426142

Epoch: 6| Step: 10
Training loss: 1.4374548863505139
Validation loss: 2.388572717577162

Epoch: 6| Step: 11
Training loss: 1.2530928495853797
Validation loss: 2.3947328056000092

Epoch: 6| Step: 12
Training loss: 2.0923417322973643
Validation loss: 2.4052517677755785

Epoch: 6| Step: 13
Training loss: 1.8686091545382937
Validation loss: 2.3992045837531846

Epoch: 168| Step: 0
Training loss: 1.5004694521933235
Validation loss: 2.4081866436576562

Epoch: 6| Step: 1
Training loss: 1.4763216498394887
Validation loss: 2.4053333333251365

Epoch: 6| Step: 2
Training loss: 1.8010989754955862
Validation loss: 2.425055090013448

Epoch: 6| Step: 3
Training loss: 1.4452275431639736
Validation loss: 2.4270234021132024

Epoch: 6| Step: 4
Training loss: 1.611339148281423
Validation loss: 2.4153028196285575

Epoch: 6| Step: 5
Training loss: 2.1603596541540555
Validation loss: 2.415049256367854

Epoch: 6| Step: 6
Training loss: 1.7191921705732467
Validation loss: 2.3904647312305722

Epoch: 6| Step: 7
Training loss: 1.8855706111661805
Validation loss: 2.3681277645379457

Epoch: 6| Step: 8
Training loss: 1.8025837976920869
Validation loss: 2.337665809232963

Epoch: 6| Step: 9
Training loss: 1.7943367985160392
Validation loss: 2.3106254356450635

Epoch: 6| Step: 10
Training loss: 1.576171950632162
Validation loss: 2.331469233624251

Epoch: 6| Step: 11
Training loss: 1.75679196720962
Validation loss: 2.305914250453544

Epoch: 6| Step: 12
Training loss: 1.5999955862699666
Validation loss: 2.322192113612499

Epoch: 6| Step: 13
Training loss: 2.165792276546887
Validation loss: 2.345228482231553

Epoch: 169| Step: 0
Training loss: 1.5268961452998349
Validation loss: 2.3415564714934267

Epoch: 6| Step: 1
Training loss: 1.5058184468487545
Validation loss: 2.3156599645117297

Epoch: 6| Step: 2
Training loss: 1.3506156824329825
Validation loss: 2.3459762932359114

Epoch: 6| Step: 3
Training loss: 1.77521066624384
Validation loss: 2.370941571868412

Epoch: 6| Step: 4
Training loss: 2.3533725805855217
Validation loss: 2.3856058215446314

Epoch: 6| Step: 5
Training loss: 1.9221150318142053
Validation loss: 2.3968804340188914

Epoch: 6| Step: 6
Training loss: 1.8309823553421647
Validation loss: 2.4267065012792894

Epoch: 6| Step: 7
Training loss: 1.1043050187481596
Validation loss: 2.4201661060612816

Epoch: 6| Step: 8
Training loss: 1.2842564084882835
Validation loss: 2.4190355775941237

Epoch: 6| Step: 9
Training loss: 2.0986700751403378
Validation loss: 2.4300645231651203

Epoch: 6| Step: 10
Training loss: 1.5377230164590436
Validation loss: 2.4328225895307583

Epoch: 6| Step: 11
Training loss: 1.8702730995304917
Validation loss: 2.436432251450885

Epoch: 6| Step: 12
Training loss: 1.9908315793914968
Validation loss: 2.4062358214939876

Epoch: 6| Step: 13
Training loss: 0.9462479620827181
Validation loss: 2.419552153604658

Epoch: 170| Step: 0
Training loss: 1.6001397489075557
Validation loss: 2.4016810437776424

Epoch: 6| Step: 1
Training loss: 1.5624151588294448
Validation loss: 2.403773016941091

Epoch: 6| Step: 2
Training loss: 1.531901863077389
Validation loss: 2.4014090964096217

Epoch: 6| Step: 3
Training loss: 1.6715102466311402
Validation loss: 2.4062562102616023

Epoch: 6| Step: 4
Training loss: 1.573442973152953
Validation loss: 2.3856083415477523

Epoch: 6| Step: 5
Training loss: 2.120470043111987
Validation loss: 2.367549227878552

Epoch: 6| Step: 6
Training loss: 1.2795051230491645
Validation loss: 2.36794697659532

Epoch: 6| Step: 7
Training loss: 1.622626331624724
Validation loss: 2.3689097244863584

Epoch: 6| Step: 8
Training loss: 1.6017234163157719
Validation loss: 2.375439342541906

Epoch: 6| Step: 9
Training loss: 1.1723590105607344
Validation loss: 2.352923880765888

Epoch: 6| Step: 10
Training loss: 1.5655406358111879
Validation loss: 2.3616419485188676

Epoch: 6| Step: 11
Training loss: 1.8994099830250215
Validation loss: 2.406379222130195

Epoch: 6| Step: 12
Training loss: 1.657141967124888
Validation loss: 2.437441756544155

Epoch: 6| Step: 13
Training loss: 2.0880996984817464
Validation loss: 2.4165591603922274

Epoch: 171| Step: 0
Training loss: 1.8414453876982733
Validation loss: 2.3853988396028205

Epoch: 6| Step: 1
Training loss: 1.8492598238574867
Validation loss: 2.377308422324057

Epoch: 6| Step: 2
Training loss: 1.8210125015181595
Validation loss: 2.392524013782167

Epoch: 6| Step: 3
Training loss: 1.74628394539675
Validation loss: 2.380913270553652

Epoch: 6| Step: 4
Training loss: 1.8332354201555485
Validation loss: 2.3657016889483096

Epoch: 6| Step: 5
Training loss: 1.7603456682262908
Validation loss: 2.364635975605756

Epoch: 6| Step: 6
Training loss: 0.9839486303799414
Validation loss: 2.3485588689217654

Epoch: 6| Step: 7
Training loss: 1.7395159847295916
Validation loss: 2.3779925354556566

Epoch: 6| Step: 8
Training loss: 1.4610466737805086
Validation loss: 2.3648192195119475

Epoch: 6| Step: 9
Training loss: 1.136173392756939
Validation loss: 2.3924833577724938

Epoch: 6| Step: 10
Training loss: 1.841925866311648
Validation loss: 2.3821492579790458

Epoch: 6| Step: 11
Training loss: 1.1755170049958545
Validation loss: 2.3668602345900607

Epoch: 6| Step: 12
Training loss: 1.7180673804253548
Validation loss: 2.400727508245505

Epoch: 6| Step: 13
Training loss: 1.7314694096867285
Validation loss: 2.3900599875310102

Epoch: 172| Step: 0
Training loss: 1.5538458151210466
Validation loss: 2.420711161211807

Epoch: 6| Step: 1
Training loss: 1.6554894050436542
Validation loss: 2.444370159886157

Epoch: 6| Step: 2
Training loss: 1.7872410459946462
Validation loss: 2.463957354076329

Epoch: 6| Step: 3
Training loss: 1.252164302160748
Validation loss: 2.4473342408597265

Epoch: 6| Step: 4
Training loss: 1.2699031813204003
Validation loss: 2.4670860650971265

Epoch: 6| Step: 5
Training loss: 0.9683649774645536
Validation loss: 2.440418758204625

Epoch: 6| Step: 6
Training loss: 1.494983550016299
Validation loss: 2.4473605838441252

Epoch: 6| Step: 7
Training loss: 1.9164028884603175
Validation loss: 2.429849469999885

Epoch: 6| Step: 8
Training loss: 1.4092011744182196
Validation loss: 2.3994837977873553

Epoch: 6| Step: 9
Training loss: 1.3455356886832335
Validation loss: 2.395007131112366

Epoch: 6| Step: 10
Training loss: 1.874618555051659
Validation loss: 2.39057034912526

Epoch: 6| Step: 11
Training loss: 2.2052225719407272
Validation loss: 2.40204895969414

Epoch: 6| Step: 12
Training loss: 1.5471001663477173
Validation loss: 2.4151194955441326

Epoch: 6| Step: 13
Training loss: 1.820437578480057
Validation loss: 2.3766818117757027

Epoch: 173| Step: 0
Training loss: 1.665121538463185
Validation loss: 2.3778770304668844

Epoch: 6| Step: 1
Training loss: 1.8447791637798967
Validation loss: 2.362243218266485

Epoch: 6| Step: 2
Training loss: 1.3512999880540382
Validation loss: 2.365220493651787

Epoch: 6| Step: 3
Training loss: 1.8176590731557956
Validation loss: 2.3360828021519637

Epoch: 6| Step: 4
Training loss: 0.97426163273876
Validation loss: 2.3644058728697996

Epoch: 6| Step: 5
Training loss: 2.4456839477391603
Validation loss: 2.387558646314778

Epoch: 6| Step: 6
Training loss: 1.9023012630410125
Validation loss: 2.3918971859554388

Epoch: 6| Step: 7
Training loss: 1.6192816844276814
Validation loss: 2.395197056139751

Epoch: 6| Step: 8
Training loss: 1.3261862572857825
Validation loss: 2.418876828241685

Epoch: 6| Step: 9
Training loss: 1.0817616812046869
Validation loss: 2.4139988664480545

Epoch: 6| Step: 10
Training loss: 1.7814117492050199
Validation loss: 2.3977918611981455

Epoch: 6| Step: 11
Training loss: 1.2908170838848827
Validation loss: 2.382057965347288

Epoch: 6| Step: 12
Training loss: 1.1930822871752194
Validation loss: 2.356560773546712

Epoch: 6| Step: 13
Training loss: 1.2433831081108757
Validation loss: 2.3847619334218155

Epoch: 174| Step: 0
Training loss: 1.433952432191984
Validation loss: 2.3761289662565472

Epoch: 6| Step: 1
Training loss: 1.7213541589718664
Validation loss: 2.390862242076686

Epoch: 6| Step: 2
Training loss: 1.6630800597646427
Validation loss: 2.369991089548959

Epoch: 6| Step: 3
Training loss: 1.2396977262313162
Validation loss: 2.3640658584081904

Epoch: 6| Step: 4
Training loss: 1.6530030290283955
Validation loss: 2.3688445576687847

Epoch: 6| Step: 5
Training loss: 2.0858284568145398
Validation loss: 2.381702715377448

Epoch: 6| Step: 6
Training loss: 1.0977085956296369
Validation loss: 2.405667802823345

Epoch: 6| Step: 7
Training loss: 1.6253977802231883
Validation loss: 2.426193609400241

Epoch: 6| Step: 8
Training loss: 1.8259170109586589
Validation loss: 2.427740348675449

Epoch: 6| Step: 9
Training loss: 1.4030047375768284
Validation loss: 2.4478984726487365

Epoch: 6| Step: 10
Training loss: 1.7431076425349483
Validation loss: 2.420993060302981

Epoch: 6| Step: 11
Training loss: 1.1918688266956343
Validation loss: 2.3696617755272897

Epoch: 6| Step: 12
Training loss: 1.5010444660500395
Validation loss: 2.3499094607668356

Epoch: 6| Step: 13
Training loss: 1.4228545786472837
Validation loss: 2.3278577901321964

Epoch: 175| Step: 0
Training loss: 1.2881358197020178
Validation loss: 2.34175238027845

Epoch: 6| Step: 1
Training loss: 1.6865231547661894
Validation loss: 2.35339751670799

Epoch: 6| Step: 2
Training loss: 1.521492131694565
Validation loss: 2.3817861890241447

Epoch: 6| Step: 3
Training loss: 1.7318697870039084
Validation loss: 2.3954031363206276

Epoch: 6| Step: 4
Training loss: 1.2418272827687762
Validation loss: 2.3882689246777216

Epoch: 6| Step: 5
Training loss: 1.4918540062643797
Validation loss: 2.4021092640986663

Epoch: 6| Step: 6
Training loss: 1.51829906409596
Validation loss: 2.3961244303740807

Epoch: 6| Step: 7
Training loss: 1.5701655228946754
Validation loss: 2.414056658144539

Epoch: 6| Step: 8
Training loss: 1.8305697925665532
Validation loss: 2.4029042710961708

Epoch: 6| Step: 9
Training loss: 1.8228627950791683
Validation loss: 2.411256636656136

Epoch: 6| Step: 10
Training loss: 1.0488063021472689
Validation loss: 2.4140453301507536

Epoch: 6| Step: 11
Training loss: 1.3990242009718006
Validation loss: 2.4354000169476184

Epoch: 6| Step: 12
Training loss: 1.4057387800289594
Validation loss: 2.4586620368289087

Epoch: 6| Step: 13
Training loss: 2.1601122115269704
Validation loss: 2.4941610146808815

Epoch: 176| Step: 0
Training loss: 1.3564860459343606
Validation loss: 2.477959593832742

Epoch: 6| Step: 1
Training loss: 1.485774615131856
Validation loss: 2.4286301460037527

Epoch: 6| Step: 2
Training loss: 1.9587220827412481
Validation loss: 2.4166046858814227

Epoch: 6| Step: 3
Training loss: 1.2446679834611898
Validation loss: 2.3941804314078494

Epoch: 6| Step: 4
Training loss: 1.6210897790331635
Validation loss: 2.3825584379731404

Epoch: 6| Step: 5
Training loss: 1.1914815910156253
Validation loss: 2.3731734522562378

Epoch: 6| Step: 6
Training loss: 1.8491328913712968
Validation loss: 2.3720723594600934

Epoch: 6| Step: 7
Training loss: 1.70738946224561
Validation loss: 2.362408542680412

Epoch: 6| Step: 8
Training loss: 0.9963216782634041
Validation loss: 2.3524135523648546

Epoch: 6| Step: 9
Training loss: 2.1600752361758007
Validation loss: 2.3490738375221927

Epoch: 6| Step: 10
Training loss: 0.9925702175409393
Validation loss: 2.3809190402941423

Epoch: 6| Step: 11
Training loss: 1.657657241382315
Validation loss: 2.389559427949215

Epoch: 6| Step: 12
Training loss: 1.2446901554019003
Validation loss: 2.4111510259298012

Epoch: 6| Step: 13
Training loss: 1.6024395285874413
Validation loss: 2.4016477502202576

Epoch: 177| Step: 0
Training loss: 1.1674315068577001
Validation loss: 2.391800455995734

Epoch: 6| Step: 1
Training loss: 2.038834950111555
Validation loss: 2.396450065712661

Epoch: 6| Step: 2
Training loss: 1.1731194564208725
Validation loss: 2.3811287765086635

Epoch: 6| Step: 3
Training loss: 1.2648289378608362
Validation loss: 2.3969762038873386

Epoch: 6| Step: 4
Training loss: 0.9905253026234762
Validation loss: 2.4056622112624355

Epoch: 6| Step: 5
Training loss: 1.7632665495794226
Validation loss: 2.436925788348477

Epoch: 6| Step: 6
Training loss: 1.6511807147498547
Validation loss: 2.437920842469299

Epoch: 6| Step: 7
Training loss: 1.3921552660771475
Validation loss: 2.448224833266398

Epoch: 6| Step: 8
Training loss: 1.3845168564150192
Validation loss: 2.46642242549716

Epoch: 6| Step: 9
Training loss: 1.5707512237918062
Validation loss: 2.425443018331277

Epoch: 6| Step: 10
Training loss: 1.6695853981872895
Validation loss: 2.447024497305422

Epoch: 6| Step: 11
Training loss: 1.5481552836875467
Validation loss: 2.4816549802845875

Epoch: 6| Step: 12
Training loss: 1.6094563287721892
Validation loss: 2.4431763481882447

Epoch: 6| Step: 13
Training loss: 1.7617278849498128
Validation loss: 2.4271076308035076

Epoch: 178| Step: 0
Training loss: 1.4283223956893738
Validation loss: 2.4224715510037136

Epoch: 6| Step: 1
Training loss: 1.4077530351923457
Validation loss: 2.404485303924751

Epoch: 6| Step: 2
Training loss: 1.6017183553642909
Validation loss: 2.3995870780193034

Epoch: 6| Step: 3
Training loss: 0.844136502786763
Validation loss: 2.3902436231757256

Epoch: 6| Step: 4
Training loss: 1.9301231602917606
Validation loss: 2.379420877059728

Epoch: 6| Step: 5
Training loss: 1.8096207736741252
Validation loss: 2.4003762634296812

Epoch: 6| Step: 6
Training loss: 1.4999272010939542
Validation loss: 2.404428725832699

Epoch: 6| Step: 7
Training loss: 1.4075124372132681
Validation loss: 2.4016147177303635

Epoch: 6| Step: 8
Training loss: 1.2910516823308351
Validation loss: 2.4110397730068875

Epoch: 6| Step: 9
Training loss: 1.0988817534800588
Validation loss: 2.415375882143239

Epoch: 6| Step: 10
Training loss: 1.3497092269417013
Validation loss: 2.4331123190433153

Epoch: 6| Step: 11
Training loss: 1.4645054947999738
Validation loss: 2.42518823301387

Epoch: 6| Step: 12
Training loss: 1.8898889038696762
Validation loss: 2.431222872697797

Epoch: 6| Step: 13
Training loss: 1.4671971654929068
Validation loss: 2.4310208629861747

Epoch: 179| Step: 0
Training loss: 1.6062181491885195
Validation loss: 2.4117864003196385

Epoch: 6| Step: 1
Training loss: 1.444242008809807
Validation loss: 2.419762153998722

Epoch: 6| Step: 2
Training loss: 1.848306876022724
Validation loss: 2.41515462232735

Epoch: 6| Step: 3
Training loss: 1.4010972882920945
Validation loss: 2.4362658712305474

Epoch: 6| Step: 4
Training loss: 1.4109915586742192
Validation loss: 2.4294799393160824

Epoch: 6| Step: 5
Training loss: 1.9818697757225028
Validation loss: 2.424497639700561

Epoch: 6| Step: 6
Training loss: 1.4619090883505474
Validation loss: 2.445959256287504

Epoch: 6| Step: 7
Training loss: 1.0451942160245247
Validation loss: 2.4549748996365146

Epoch: 6| Step: 8
Training loss: 1.3639217500726903
Validation loss: 2.4271674604824716

Epoch: 6| Step: 9
Training loss: 1.206002497605605
Validation loss: 2.457770212360135

Epoch: 6| Step: 10
Training loss: 1.3505451143815668
Validation loss: 2.426327271579766

Epoch: 6| Step: 11
Training loss: 1.2481209937400495
Validation loss: 2.408608749557042

Epoch: 6| Step: 12
Training loss: 1.3769988789633494
Validation loss: 2.4038683725029113

Epoch: 6| Step: 13
Training loss: 1.5722156587799947
Validation loss: 2.3929872235308123

Epoch: 180| Step: 0
Training loss: 1.7305668443556876
Validation loss: 2.355750773788307

Epoch: 6| Step: 1
Training loss: 1.5066432866811545
Validation loss: 2.372892036350854

Epoch: 6| Step: 2
Training loss: 2.0431222073923037
Validation loss: 2.3760680790792676

Epoch: 6| Step: 3
Training loss: 1.2456930347319861
Validation loss: 2.3684581886270095

Epoch: 6| Step: 4
Training loss: 1.1352931780841757
Validation loss: 2.3737334353705193

Epoch: 6| Step: 5
Training loss: 1.1610321950991025
Validation loss: 2.3719284638060727

Epoch: 6| Step: 6
Training loss: 1.0395703329574302
Validation loss: 2.3971309413285393

Epoch: 6| Step: 7
Training loss: 1.6805929892638325
Validation loss: 2.4087969603836634

Epoch: 6| Step: 8
Training loss: 1.368633922026956
Validation loss: 2.409796307056876

Epoch: 6| Step: 9
Training loss: 1.1797602548963935
Validation loss: 2.4267670000424433

Epoch: 6| Step: 10
Training loss: 1.579795406591506
Validation loss: 2.4478284210308456

Epoch: 6| Step: 11
Training loss: 1.345405357425934
Validation loss: 2.455356033531634

Epoch: 6| Step: 12
Training loss: 1.3930793705446305
Validation loss: 2.46882748018186

Epoch: 6| Step: 13
Training loss: 1.3829546494347487
Validation loss: 2.478147048002783

Epoch: 181| Step: 0
Training loss: 1.3507283453567318
Validation loss: 2.4884577625914654

Epoch: 6| Step: 1
Training loss: 1.2815071871284711
Validation loss: 2.4824553781966574

Epoch: 6| Step: 2
Training loss: 1.5720577126215005
Validation loss: 2.4773539652022496

Epoch: 6| Step: 3
Training loss: 1.5044024553000495
Validation loss: 2.442262301614478

Epoch: 6| Step: 4
Training loss: 1.702874821477871
Validation loss: 2.400668473020831

Epoch: 6| Step: 5
Training loss: 1.2030591079701352
Validation loss: 2.39569565286901

Epoch: 6| Step: 6
Training loss: 1.342059025150047
Validation loss: 2.3869163093471837

Epoch: 6| Step: 7
Training loss: 1.132308111039215
Validation loss: 2.3593019124954884

Epoch: 6| Step: 8
Training loss: 1.5046003052986643
Validation loss: 2.3819866274945154

Epoch: 6| Step: 9
Training loss: 1.226456558608999
Validation loss: 2.3764189888987097

Epoch: 6| Step: 10
Training loss: 1.5803186259529094
Validation loss: 2.40228824626394

Epoch: 6| Step: 11
Training loss: 1.4226626216404286
Validation loss: 2.410616886801495

Epoch: 6| Step: 12
Training loss: 0.8916917402241906
Validation loss: 2.4185569588851163

Epoch: 6| Step: 13
Training loss: 2.2590315012903255
Validation loss: 2.428606604094476

Epoch: 182| Step: 0
Training loss: 1.5357778130505564
Validation loss: 2.4486589453563443

Epoch: 6| Step: 1
Training loss: 1.4472367956916916
Validation loss: 2.4345699376264003

Epoch: 6| Step: 2
Training loss: 1.3606648081053907
Validation loss: 2.4540373521188177

Epoch: 6| Step: 3
Training loss: 1.2316324211353102
Validation loss: 2.474900318507099

Epoch: 6| Step: 4
Training loss: 1.356659819392765
Validation loss: 2.456318022095989

Epoch: 6| Step: 5
Training loss: 1.400406798797378
Validation loss: 2.440806226669492

Epoch: 6| Step: 6
Training loss: 1.5214638469912507
Validation loss: 2.413750394923935

Epoch: 6| Step: 7
Training loss: 1.3621996767322884
Validation loss: 2.4305929572708873

Epoch: 6| Step: 8
Training loss: 1.4427571569598052
Validation loss: 2.398080615205951

Epoch: 6| Step: 9
Training loss: 1.129573004738812
Validation loss: 2.38714064294758

Epoch: 6| Step: 10
Training loss: 1.6507848866860897
Validation loss: 2.3716276780341694

Epoch: 6| Step: 11
Training loss: 1.310362756021463
Validation loss: 2.35305895232555

Epoch: 6| Step: 12
Training loss: 1.4291533425973242
Validation loss: 2.358801990759482

Epoch: 6| Step: 13
Training loss: 1.8074050853073915
Validation loss: 2.342430796831398

Epoch: 183| Step: 0
Training loss: 1.7478096742434945
Validation loss: 2.391572777665039

Epoch: 6| Step: 1
Training loss: 0.9786177104152712
Validation loss: 2.4137523364391833

Epoch: 6| Step: 2
Training loss: 0.9866057958760156
Validation loss: 2.4345720015365138

Epoch: 6| Step: 3
Training loss: 1.5476455310679493
Validation loss: 2.457536287306992

Epoch: 6| Step: 4
Training loss: 1.387515459747791
Validation loss: 2.4737573613053745

Epoch: 6| Step: 5
Training loss: 1.2761574932650661
Validation loss: 2.479405546136442

Epoch: 6| Step: 6
Training loss: 1.199514247013028
Validation loss: 2.450540299532411

Epoch: 6| Step: 7
Training loss: 1.5963907989563688
Validation loss: 2.4544216481154035

Epoch: 6| Step: 8
Training loss: 1.5492037573784831
Validation loss: 2.4635616272977483

Epoch: 6| Step: 9
Training loss: 1.4715508883689092
Validation loss: 2.4178954307873015

Epoch: 6| Step: 10
Training loss: 1.2535586246617536
Validation loss: 2.442372021051802

Epoch: 6| Step: 11
Training loss: 1.7707756332272029
Validation loss: 2.430293346057191

Epoch: 6| Step: 12
Training loss: 1.4358039470077955
Validation loss: 2.409678689093108

Epoch: 6| Step: 13
Training loss: 1.4132371464348414
Validation loss: 2.4145933691157375

Epoch: 184| Step: 0
Training loss: 1.4956270690215003
Validation loss: 2.4258572592595833

Epoch: 6| Step: 1
Training loss: 1.757548265730438
Validation loss: 2.4499414506244364

Epoch: 6| Step: 2
Training loss: 1.593499182618012
Validation loss: 2.457212498854016

Epoch: 6| Step: 3
Training loss: 1.4185475410828696
Validation loss: 2.4469594500802296

Epoch: 6| Step: 4
Training loss: 1.7483050448756774
Validation loss: 2.4536664480319055

Epoch: 6| Step: 5
Training loss: 1.179581037353164
Validation loss: 2.416679973869758

Epoch: 6| Step: 6
Training loss: 1.1938310306070108
Validation loss: 2.4110680830049045

Epoch: 6| Step: 7
Training loss: 1.044739038746282
Validation loss: 2.423810664714097

Epoch: 6| Step: 8
Training loss: 0.7289033732301258
Validation loss: 2.4318754507541582

Epoch: 6| Step: 9
Training loss: 1.3096850044155715
Validation loss: 2.411480641842696

Epoch: 6| Step: 10
Training loss: 1.1975076004615366
Validation loss: 2.433641265919871

Epoch: 6| Step: 11
Training loss: 1.5472675942724072
Validation loss: 2.445585776881157

Epoch: 6| Step: 12
Training loss: 1.5766162269594388
Validation loss: 2.4677361072662074

Epoch: 6| Step: 13
Training loss: 1.4236493619830108
Validation loss: 2.4794052338763035

Epoch: 185| Step: 0
Training loss: 1.241520060561148
Validation loss: 2.4692119624637074

Epoch: 6| Step: 1
Training loss: 1.3372871318660418
Validation loss: 2.4420395521221336

Epoch: 6| Step: 2
Training loss: 1.3113905440978175
Validation loss: 2.455288206724733

Epoch: 6| Step: 3
Training loss: 1.3140151043666828
Validation loss: 2.455604983753988

Epoch: 6| Step: 4
Training loss: 1.4219668012893678
Validation loss: 2.4763446563376403

Epoch: 6| Step: 5
Training loss: 1.2202973446655894
Validation loss: 2.4686963288535084

Epoch: 6| Step: 6
Training loss: 1.2897133773451857
Validation loss: 2.476834250019054

Epoch: 6| Step: 7
Training loss: 1.9132653892672773
Validation loss: 2.462785067459408

Epoch: 6| Step: 8
Training loss: 1.488505669441741
Validation loss: 2.4696770637293164

Epoch: 6| Step: 9
Training loss: 1.6270316701478378
Validation loss: 2.4157320371561735

Epoch: 6| Step: 10
Training loss: 1.4318774184927128
Validation loss: 2.4303609500762624

Epoch: 6| Step: 11
Training loss: 0.994014049933475
Validation loss: 2.435138724013781

Epoch: 6| Step: 12
Training loss: 1.026499005680931
Validation loss: 2.4342954957075733

Epoch: 6| Step: 13
Training loss: 1.5789160681432972
Validation loss: 2.3979064472668123

Epoch: 186| Step: 0
Training loss: 1.500928035390933
Validation loss: 2.4038179132650086

Epoch: 6| Step: 1
Training loss: 1.3863898088625435
Validation loss: 2.382467275081269

Epoch: 6| Step: 2
Training loss: 0.9503403932190316
Validation loss: 2.380914031813486

Epoch: 6| Step: 3
Training loss: 1.4053499096282487
Validation loss: 2.4317126958638347

Epoch: 6| Step: 4
Training loss: 1.2054417091051284
Validation loss: 2.411828527316586

Epoch: 6| Step: 5
Training loss: 1.1292327092037515
Validation loss: 2.432293183199614

Epoch: 6| Step: 6
Training loss: 2.179365018007279
Validation loss: 2.4579153651101695

Epoch: 6| Step: 7
Training loss: 1.1794935155369293
Validation loss: 2.4332276337215815

Epoch: 6| Step: 8
Training loss: 0.9790776327250076
Validation loss: 2.478533667016922

Epoch: 6| Step: 9
Training loss: 1.6775592894672111
Validation loss: 2.4417301763433503

Epoch: 6| Step: 10
Training loss: 1.170562925144053
Validation loss: 2.454435254764454

Epoch: 6| Step: 11
Training loss: 1.538293404286552
Validation loss: 2.4610274582799128

Epoch: 6| Step: 12
Training loss: 0.8366741606641422
Validation loss: 2.435052923864786

Epoch: 6| Step: 13
Training loss: 1.1386150784338196
Validation loss: 2.43820241941355

Epoch: 187| Step: 0
Training loss: 1.4695317237443581
Validation loss: 2.4167601815172555

Epoch: 6| Step: 1
Training loss: 1.1145589356411154
Validation loss: 2.3814663844127266

Epoch: 6| Step: 2
Training loss: 1.095036975636935
Validation loss: 2.394819498474242

Epoch: 6| Step: 3
Training loss: 0.7995655787651778
Validation loss: 2.383256505801695

Epoch: 6| Step: 4
Training loss: 1.5356583490038116
Validation loss: 2.397512349073149

Epoch: 6| Step: 5
Training loss: 1.5592482490474673
Validation loss: 2.38567549462044

Epoch: 6| Step: 6
Training loss: 1.248779273009836
Validation loss: 2.3867258370838047

Epoch: 6| Step: 7
Training loss: 1.2684667261651696
Validation loss: 2.3983647017891183

Epoch: 6| Step: 8
Training loss: 1.3871137029719425
Validation loss: 2.4082072713992697

Epoch: 6| Step: 9
Training loss: 1.4132660366776792
Validation loss: 2.3987516658593586

Epoch: 6| Step: 10
Training loss: 1.6553618730985087
Validation loss: 2.4222030221680444

Epoch: 6| Step: 11
Training loss: 0.8903404584399833
Validation loss: 2.418757807615236

Epoch: 6| Step: 12
Training loss: 1.313967656217958
Validation loss: 2.4413827273312374

Epoch: 6| Step: 13
Training loss: 1.614678246774474
Validation loss: 2.474531796650525

Epoch: 188| Step: 0
Training loss: 1.428525191648733
Validation loss: 2.4474704402922693

Epoch: 6| Step: 1
Training loss: 1.6985056816951578
Validation loss: 2.4830679199633763

Epoch: 6| Step: 2
Training loss: 1.042377947516665
Validation loss: 2.4651117667465225

Epoch: 6| Step: 3
Training loss: 0.9726889118394396
Validation loss: 2.4959661898680294

Epoch: 6| Step: 4
Training loss: 1.1727337043490407
Validation loss: 2.4426810788717135

Epoch: 6| Step: 5
Training loss: 1.1016004839902325
Validation loss: 2.4487205642825254

Epoch: 6| Step: 6
Training loss: 1.3958452376052568
Validation loss: 2.430587518504315

Epoch: 6| Step: 7
Training loss: 1.3817848223071443
Validation loss: 2.430176088759113

Epoch: 6| Step: 8
Training loss: 1.3501370801912345
Validation loss: 2.3798133193994095

Epoch: 6| Step: 9
Training loss: 1.1560502266350674
Validation loss: 2.3968382352155024

Epoch: 6| Step: 10
Training loss: 1.4167021672157745
Validation loss: 2.355595322797152

Epoch: 6| Step: 11
Training loss: 1.369278012509955
Validation loss: 2.3497863511394

Epoch: 6| Step: 12
Training loss: 1.536875221032138
Validation loss: 2.3471814080207776

Epoch: 6| Step: 13
Training loss: 0.6374623689577562
Validation loss: 2.327039442554488

Epoch: 189| Step: 0
Training loss: 1.2117081681655837
Validation loss: 2.337702715071661

Epoch: 6| Step: 1
Training loss: 1.135401483603404
Validation loss: 2.3420357498215774

Epoch: 6| Step: 2
Training loss: 0.9596137256146352
Validation loss: 2.3571544820147903

Epoch: 6| Step: 3
Training loss: 1.0315910122319014
Validation loss: 2.3816239519385736

Epoch: 6| Step: 4
Training loss: 0.9888586234939253
Validation loss: 2.4184904501022024

Epoch: 6| Step: 5
Training loss: 1.1899048396938536
Validation loss: 2.4397382753539354

Epoch: 6| Step: 6
Training loss: 1.5366937834084136
Validation loss: 2.498641125730248

Epoch: 6| Step: 7
Training loss: 1.1490611245087707
Validation loss: 2.519891783908315

Epoch: 6| Step: 8
Training loss: 1.3125454122770575
Validation loss: 2.51336086921963

Epoch: 6| Step: 9
Training loss: 1.8100374527739298
Validation loss: 2.537009616654358

Epoch: 6| Step: 10
Training loss: 1.2882341439892382
Validation loss: 2.5120024031878483

Epoch: 6| Step: 11
Training loss: 1.70445213756016
Validation loss: 2.4951498811590365

Epoch: 6| Step: 12
Training loss: 1.1721342181567094
Validation loss: 2.4906150117427006

Epoch: 6| Step: 13
Training loss: 1.7333136395411561
Validation loss: 2.457743108929051

Epoch: 190| Step: 0
Training loss: 1.1185208879855781
Validation loss: 2.4109613624124338

Epoch: 6| Step: 1
Training loss: 1.1494253671717343
Validation loss: 2.3899186589692194

Epoch: 6| Step: 2
Training loss: 1.0534387047692004
Validation loss: 2.367944325743054

Epoch: 6| Step: 3
Training loss: 1.4028283772087373
Validation loss: 2.3765896678310003

Epoch: 6| Step: 4
Training loss: 1.1527487350288157
Validation loss: 2.373008075131734

Epoch: 6| Step: 5
Training loss: 1.3348523021103877
Validation loss: 2.3615315526444145

Epoch: 6| Step: 6
Training loss: 1.492572355321631
Validation loss: 2.3967136244288536

Epoch: 6| Step: 7
Training loss: 1.5282408282296325
Validation loss: 2.3727715566873626

Epoch: 6| Step: 8
Training loss: 1.6028562205200028
Validation loss: 2.4237366786886168

Epoch: 6| Step: 9
Training loss: 0.9223472226281235
Validation loss: 2.448495406257973

Epoch: 6| Step: 10
Training loss: 0.9612802033956112
Validation loss: 2.4379121133839887

Epoch: 6| Step: 11
Training loss: 1.5017400821150633
Validation loss: 2.448314445047076

Epoch: 6| Step: 12
Training loss: 1.291072319044022
Validation loss: 2.489335300609863

Epoch: 6| Step: 13
Training loss: 1.3785501079618916
Validation loss: 2.4963090240079566

Epoch: 191| Step: 0
Training loss: 0.9882753997750202
Validation loss: 2.517313354024098

Epoch: 6| Step: 1
Training loss: 0.9793360272840717
Validation loss: 2.5127951852514943

Epoch: 6| Step: 2
Training loss: 1.4954027617027634
Validation loss: 2.503848767989781

Epoch: 6| Step: 3
Training loss: 1.8815221519940215
Validation loss: 2.4938203164612602

Epoch: 6| Step: 4
Training loss: 1.1293875120532797
Validation loss: 2.4469892334640364

Epoch: 6| Step: 5
Training loss: 1.0556976002492366
Validation loss: 2.426587257211154

Epoch: 6| Step: 6
Training loss: 1.2629660473244464
Validation loss: 2.4183388449202106

Epoch: 6| Step: 7
Training loss: 1.3134476101885766
Validation loss: 2.3992251920177328

Epoch: 6| Step: 8
Training loss: 1.469039076906656
Validation loss: 2.3915857203250184

Epoch: 6| Step: 9
Training loss: 1.280328698496899
Validation loss: 2.387095675136304

Epoch: 6| Step: 10
Training loss: 1.0680450032714266
Validation loss: 2.3677710211228864

Epoch: 6| Step: 11
Training loss: 1.5263794491520053
Validation loss: 2.4260047974854677

Epoch: 6| Step: 12
Training loss: 1.1430319903511827
Validation loss: 2.4103105098492006

Epoch: 6| Step: 13
Training loss: 0.6709190931846865
Validation loss: 2.4418065096331643

Epoch: 192| Step: 0
Training loss: 1.4309749955419246
Validation loss: 2.432694442723094

Epoch: 6| Step: 1
Training loss: 1.405628321242151
Validation loss: 2.4674813232619357

Epoch: 6| Step: 2
Training loss: 0.7220659061345934
Validation loss: 2.497923435688242

Epoch: 6| Step: 3
Training loss: 1.8449360540209825
Validation loss: 2.5112413384431367

Epoch: 6| Step: 4
Training loss: 1.2821649215536284
Validation loss: 2.4970526169363874

Epoch: 6| Step: 5
Training loss: 1.357332866138073
Validation loss: 2.490633855438475

Epoch: 6| Step: 6
Training loss: 1.3210266709851477
Validation loss: 2.501949317376366

Epoch: 6| Step: 7
Training loss: 0.747365536668286
Validation loss: 2.457525053328781

Epoch: 6| Step: 8
Training loss: 1.5542221523058606
Validation loss: 2.4285603767561317

Epoch: 6| Step: 9
Training loss: 1.1253433233487364
Validation loss: 2.424150280032129

Epoch: 6| Step: 10
Training loss: 0.8718662685380932
Validation loss: 2.4299066568256187

Epoch: 6| Step: 11
Training loss: 1.0572928004266582
Validation loss: 2.4129655804785504

Epoch: 6| Step: 12
Training loss: 0.9640065626736197
Validation loss: 2.3971844288081248

Epoch: 6| Step: 13
Training loss: 1.1576498681879914
Validation loss: 2.4137677229985055

Epoch: 193| Step: 0
Training loss: 0.9893747243682034
Validation loss: 2.427182806361012

Epoch: 6| Step: 1
Training loss: 0.9760085403916868
Validation loss: 2.4099317291748066

Epoch: 6| Step: 2
Training loss: 0.947449216060444
Validation loss: 2.4247801048390594

Epoch: 6| Step: 3
Training loss: 1.2253896852489075
Validation loss: 2.417098415903757

Epoch: 6| Step: 4
Training loss: 1.0813932775924509
Validation loss: 2.416666158888965

Epoch: 6| Step: 5
Training loss: 1.3097017522358174
Validation loss: 2.432030751656539

Epoch: 6| Step: 6
Training loss: 1.3335830732743927
Validation loss: 2.451096778356268

Epoch: 6| Step: 7
Training loss: 1.6066980412428598
Validation loss: 2.483599821942601

Epoch: 6| Step: 8
Training loss: 1.3844116791630132
Validation loss: 2.4589558733085783

Epoch: 6| Step: 9
Training loss: 1.0035596909876583
Validation loss: 2.4629599650993192

Epoch: 6| Step: 10
Training loss: 0.9904475537529634
Validation loss: 2.4423504988927127

Epoch: 6| Step: 11
Training loss: 1.2004591897734989
Validation loss: 2.430471433559852

Epoch: 6| Step: 12
Training loss: 1.7502433743862966
Validation loss: 2.437221463856524

Epoch: 6| Step: 13
Training loss: 1.3042552940227574
Validation loss: 2.4286980427925005

Epoch: 194| Step: 0
Training loss: 1.2950175208302017
Validation loss: 2.440635637894559

Epoch: 6| Step: 1
Training loss: 0.7475319626522785
Validation loss: 2.4059732118395663

Epoch: 6| Step: 2
Training loss: 1.2036999901418106
Validation loss: 2.4233979051272603

Epoch: 6| Step: 3
Training loss: 1.1126526245692387
Validation loss: 2.442859263936667

Epoch: 6| Step: 4
Training loss: 1.5525730649061087
Validation loss: 2.4324699354620325

Epoch: 6| Step: 5
Training loss: 1.3748905398408573
Validation loss: 2.4186949748859687

Epoch: 6| Step: 6
Training loss: 1.7057835538701294
Validation loss: 2.4186764038298896

Epoch: 6| Step: 7
Training loss: 1.1444589637608968
Validation loss: 2.387213869349148

Epoch: 6| Step: 8
Training loss: 1.3287592551482341
Validation loss: 2.3972225325888754

Epoch: 6| Step: 9
Training loss: 1.1856272134473667
Validation loss: 2.3773215626113777

Epoch: 6| Step: 10
Training loss: 1.188433129951814
Validation loss: 2.4044393357257703

Epoch: 6| Step: 11
Training loss: 1.3563861216077808
Validation loss: 2.4186741853841722

Epoch: 6| Step: 12
Training loss: 0.7288529992967668
Validation loss: 2.429415039131697

Epoch: 6| Step: 13
Training loss: 1.1085295343383352
Validation loss: 2.4591638697850238

Epoch: 195| Step: 0
Training loss: 1.2224979968532386
Validation loss: 2.4554158180491092

Epoch: 6| Step: 1
Training loss: 0.9635249093462951
Validation loss: 2.46737378693851

Epoch: 6| Step: 2
Training loss: 1.644323340387072
Validation loss: 2.4565571037075933

Epoch: 6| Step: 3
Training loss: 1.6386232789464379
Validation loss: 2.4341856565640225

Epoch: 6| Step: 4
Training loss: 1.2930151248233142
Validation loss: 2.398378563398933

Epoch: 6| Step: 5
Training loss: 1.1471957805337814
Validation loss: 2.4258787280120657

Epoch: 6| Step: 6
Training loss: 0.815294850788211
Validation loss: 2.4113979515869053

Epoch: 6| Step: 7
Training loss: 1.5372911512990324
Validation loss: 2.434287626673669

Epoch: 6| Step: 8
Training loss: 1.0399647860800967
Validation loss: 2.410250679740748

Epoch: 6| Step: 9
Training loss: 1.0504139538348731
Validation loss: 2.413744128003694

Epoch: 6| Step: 10
Training loss: 0.7731379689984548
Validation loss: 2.4100510303736926

Epoch: 6| Step: 11
Training loss: 1.01423350157564
Validation loss: 2.4290572988131864

Epoch: 6| Step: 12
Training loss: 1.1512904639075865
Validation loss: 2.447064761024992

Epoch: 6| Step: 13
Training loss: 1.1602857112899954
Validation loss: 2.4450450264610835

Epoch: 196| Step: 0
Training loss: 1.2124797721040692
Validation loss: 2.4870061095408875

Epoch: 6| Step: 1
Training loss: 0.8419805268869704
Validation loss: 2.4737251507763234

Epoch: 6| Step: 2
Training loss: 1.069528167029118
Validation loss: 2.489054207924187

Epoch: 6| Step: 3
Training loss: 1.6174772436082983
Validation loss: 2.4635270642997686

Epoch: 6| Step: 4
Training loss: 0.9726153139132874
Validation loss: 2.454024105763393

Epoch: 6| Step: 5
Training loss: 1.2227897205565856
Validation loss: 2.4174930834155615

Epoch: 6| Step: 6
Training loss: 1.4646949794245439
Validation loss: 2.3926386590013045

Epoch: 6| Step: 7
Training loss: 1.4680473594873824
Validation loss: 2.4176488432093626

Epoch: 6| Step: 8
Training loss: 0.8823100322686988
Validation loss: 2.394285480121351

Epoch: 6| Step: 9
Training loss: 1.1983886231324221
Validation loss: 2.402885742302032

Epoch: 6| Step: 10
Training loss: 0.813911312656545
Validation loss: 2.3891893988224044

Epoch: 6| Step: 11
Training loss: 1.3342414485377885
Validation loss: 2.3603854276846867

Epoch: 6| Step: 12
Training loss: 1.1111423759565204
Validation loss: 2.3710315517315808

Epoch: 6| Step: 13
Training loss: 0.8404004757906599
Validation loss: 2.3648737239905304

Epoch: 197| Step: 0
Training loss: 1.1325356506900448
Validation loss: 2.361268097132247

Epoch: 6| Step: 1
Training loss: 1.1180410259137277
Validation loss: 2.404093973579227

Epoch: 6| Step: 2
Training loss: 1.069209846482925
Validation loss: 2.430119082339632

Epoch: 6| Step: 3
Training loss: 1.664868799716595
Validation loss: 2.4292639901474806

Epoch: 6| Step: 4
Training loss: 1.122809290426133
Validation loss: 2.455204555850654

Epoch: 6| Step: 5
Training loss: 0.6037034912045076
Validation loss: 2.447775686197533

Epoch: 6| Step: 6
Training loss: 0.9636430566728679
Validation loss: 2.4331272660287317

Epoch: 6| Step: 7
Training loss: 1.2022261296197223
Validation loss: 2.4149181533957824

Epoch: 6| Step: 8
Training loss: 1.1234396604217427
Validation loss: 2.4169960525927605

Epoch: 6| Step: 9
Training loss: 1.3753632152440445
Validation loss: 2.4322341842237414

Epoch: 6| Step: 10
Training loss: 1.0803348725871045
Validation loss: 2.3813698971379447

Epoch: 6| Step: 11
Training loss: 0.7704567934654587
Validation loss: 2.4006771079327858

Epoch: 6| Step: 12
Training loss: 1.283552705708735
Validation loss: 2.3794450650629067

Epoch: 6| Step: 13
Training loss: 1.284716267042133
Validation loss: 2.3841108900302017

Epoch: 198| Step: 0
Training loss: 1.4849258203956306
Validation loss: 2.3807794524750947

Epoch: 6| Step: 1
Training loss: 1.5081486302598262
Validation loss: 2.3774172533954636

Epoch: 6| Step: 2
Training loss: 0.915311302634902
Validation loss: 2.3943122022573853

Epoch: 6| Step: 3
Training loss: 1.059001492172357
Validation loss: 2.392243942418243

Epoch: 6| Step: 4
Training loss: 0.7496628400810396
Validation loss: 2.393162291791063

Epoch: 6| Step: 5
Training loss: 1.3337421336920738
Validation loss: 2.415017561078746

Epoch: 6| Step: 6
Training loss: 1.0093271864204574
Validation loss: 2.4401822830758904

Epoch: 6| Step: 7
Training loss: 0.6168677068895665
Validation loss: 2.436703003948995

Epoch: 6| Step: 8
Training loss: 1.1657526943430072
Validation loss: 2.4332936122139803

Epoch: 6| Step: 9
Training loss: 1.0740511676810929
Validation loss: 2.449753819700599

Epoch: 6| Step: 10
Training loss: 1.1569493730360434
Validation loss: 2.432568034921517

Epoch: 6| Step: 11
Training loss: 1.5365605810594476
Validation loss: 2.4289021724579536

Epoch: 6| Step: 12
Training loss: 0.5592242863677609
Validation loss: 2.407094629016083

Epoch: 6| Step: 13
Training loss: 1.3108681115938599
Validation loss: 2.3741833233136624

Epoch: 199| Step: 0
Training loss: 0.8387414484966748
Validation loss: 2.3649672268483704

Epoch: 6| Step: 1
Training loss: 1.1426962245321626
Validation loss: 2.373372977323639

Epoch: 6| Step: 2
Training loss: 0.7560077294933435
Validation loss: 2.3601533751742405

Epoch: 6| Step: 3
Training loss: 1.087884488593555
Validation loss: 2.395612607171643

Epoch: 6| Step: 4
Training loss: 1.0991058009611918
Validation loss: 2.392386012313841

Epoch: 6| Step: 5
Training loss: 1.0438948388026257
Validation loss: 2.3994536699430373

Epoch: 6| Step: 6
Training loss: 1.0109661351766432
Validation loss: 2.4051466224477887

Epoch: 6| Step: 7
Training loss: 1.6872750591542982
Validation loss: 2.4303943376255597

Epoch: 6| Step: 8
Training loss: 1.0152320688595031
Validation loss: 2.425032342209428

Epoch: 6| Step: 9
Training loss: 1.339363078653076
Validation loss: 2.411985898603313

Epoch: 6| Step: 10
Training loss: 1.0959461507028885
Validation loss: 2.408915100302546

Epoch: 6| Step: 11
Training loss: 1.0994851836680337
Validation loss: 2.4136478736905205

Epoch: 6| Step: 12
Training loss: 1.3068492591690888
Validation loss: 2.427523011790803

Epoch: 6| Step: 13
Training loss: 0.7895921119530731
Validation loss: 2.4369855305728074

Epoch: 200| Step: 0
Training loss: 0.8874844509428226
Validation loss: 2.4015822227960304

Epoch: 6| Step: 1
Training loss: 1.1273382047964906
Validation loss: 2.415213080560513

Epoch: 6| Step: 2
Training loss: 1.1588685567012402
Validation loss: 2.4267061431501795

Epoch: 6| Step: 3
Training loss: 1.1351073074028983
Validation loss: 2.439591548767097

Epoch: 6| Step: 4
Training loss: 0.9362354332945554
Validation loss: 2.4378293374719937

Epoch: 6| Step: 5
Training loss: 0.9831478401921242
Validation loss: 2.4421648980890116

Epoch: 6| Step: 6
Training loss: 1.7316050361678146
Validation loss: 2.4641595002544157

Epoch: 6| Step: 7
Training loss: 1.0153045148644089
Validation loss: 2.4660108393136566

Epoch: 6| Step: 8
Training loss: 0.9528758239222096
Validation loss: 2.4538086220212008

Epoch: 6| Step: 9
Training loss: 1.1808441251980855
Validation loss: 2.446270901090618

Epoch: 6| Step: 10
Training loss: 0.8601136934180059
Validation loss: 2.4358172617697034

Epoch: 6| Step: 11
Training loss: 0.845447633839488
Validation loss: 2.424311595287778

Epoch: 6| Step: 12
Training loss: 1.2817160991384122
Validation loss: 2.412434862181874

Epoch: 6| Step: 13
Training loss: 1.3596418710713847
Validation loss: 2.42718441128778

Epoch: 201| Step: 0
Training loss: 1.2867273623393092
Validation loss: 2.38765808528739

Epoch: 6| Step: 1
Training loss: 0.9077420284474884
Validation loss: 2.414336888800523

Epoch: 6| Step: 2
Training loss: 0.9220329731219038
Validation loss: 2.402680747780118

Epoch: 6| Step: 3
Training loss: 1.857928955945457
Validation loss: 2.408080632141474

Epoch: 6| Step: 4
Training loss: 1.2032827298698048
Validation loss: 2.4077985016256718

Epoch: 6| Step: 5
Training loss: 1.089681633817802
Validation loss: 2.4222617601027325

Epoch: 6| Step: 6
Training loss: 1.3143509120792736
Validation loss: 2.433529615836899

Epoch: 6| Step: 7
Training loss: 0.9491548869937347
Validation loss: 2.432945714946163

Epoch: 6| Step: 8
Training loss: 0.6897206422338144
Validation loss: 2.448970090632574

Epoch: 6| Step: 9
Training loss: 1.2568822702494435
Validation loss: 2.434011964849642

Epoch: 6| Step: 10
Training loss: 0.41174795926624236
Validation loss: 2.445035346648671

Epoch: 6| Step: 11
Training loss: 1.0505222724648742
Validation loss: 2.4248448555153588

Epoch: 6| Step: 12
Training loss: 1.0574979847016306
Validation loss: 2.411130244746204

Epoch: 6| Step: 13
Training loss: 0.6362944985737757
Validation loss: 2.433647867679258

Epoch: 202| Step: 0
Training loss: 0.9083235137886977
Validation loss: 2.4182690416675

Epoch: 6| Step: 1
Training loss: 1.6362905738876588
Validation loss: 2.4295837234573097

Epoch: 6| Step: 2
Training loss: 0.5667984492505517
Validation loss: 2.3972944490174783

Epoch: 6| Step: 3
Training loss: 0.8348789107871782
Validation loss: 2.4329580724019886

Epoch: 6| Step: 4
Training loss: 0.6859260227920254
Validation loss: 2.4319651363152954

Epoch: 6| Step: 5
Training loss: 0.971191774486167
Validation loss: 2.4318496584603095

Epoch: 6| Step: 6
Training loss: 0.8761195785827138
Validation loss: 2.4200150804415044

Epoch: 6| Step: 7
Training loss: 1.8562672392690052
Validation loss: 2.4134187154212845

Epoch: 6| Step: 8
Training loss: 1.2134234107469575
Validation loss: 2.4155187720066977

Epoch: 6| Step: 9
Training loss: 0.7373977299271713
Validation loss: 2.4259642608482404

Epoch: 6| Step: 10
Training loss: 1.2178842452844643
Validation loss: 2.3827234276756473

Epoch: 6| Step: 11
Training loss: 1.010912953569606
Validation loss: 2.4087533978396114

Epoch: 6| Step: 12
Training loss: 1.0034671520792915
Validation loss: 2.4076557312255846

Epoch: 6| Step: 13
Training loss: 1.0040931379272384
Validation loss: 2.435462775543457

Epoch: 203| Step: 0
Training loss: 0.7512776697556749
Validation loss: 2.4303169892441243

Epoch: 6| Step: 1
Training loss: 1.3337895933958208
Validation loss: 2.41346271212312

Epoch: 6| Step: 2
Training loss: 0.9170173422193777
Validation loss: 2.416301288784313

Epoch: 6| Step: 3
Training loss: 1.425097994195593
Validation loss: 2.4512044313121337

Epoch: 6| Step: 4
Training loss: 0.9755847155741847
Validation loss: 2.4562397094701374

Epoch: 6| Step: 5
Training loss: 0.9925570963523966
Validation loss: 2.449467960807446

Epoch: 6| Step: 6
Training loss: 1.2213888210865063
Validation loss: 2.438769974920488

Epoch: 6| Step: 7
Training loss: 1.4524198892795361
Validation loss: 2.4759157143047927

Epoch: 6| Step: 8
Training loss: 0.8048434800755013
Validation loss: 2.4592973088936416

Epoch: 6| Step: 9
Training loss: 1.2417869641873598
Validation loss: 2.4671256330419533

Epoch: 6| Step: 10
Training loss: 0.8472582326507632
Validation loss: 2.4472131645509574

Epoch: 6| Step: 11
Training loss: 0.8794781667873927
Validation loss: 2.4368452707865655

Epoch: 6| Step: 12
Training loss: 1.0064279671374892
Validation loss: 2.4394519595428266

Epoch: 6| Step: 13
Training loss: 1.4374480030772951
Validation loss: 2.410925389787129

Epoch: 204| Step: 0
Training loss: 0.9338848027432342
Validation loss: 2.435398087426754

Epoch: 6| Step: 1
Training loss: 0.7359625923430746
Validation loss: 2.4081000652562596

Epoch: 6| Step: 2
Training loss: 0.8283228008194211
Validation loss: 2.428341337021269

Epoch: 6| Step: 3
Training loss: 0.8466948933539404
Validation loss: 2.400513240069843

Epoch: 6| Step: 4
Training loss: 1.213686916625214
Validation loss: 2.42806378167015

Epoch: 6| Step: 5
Training loss: 1.106490239496358
Validation loss: 2.42585137896525

Epoch: 6| Step: 6
Training loss: 1.5838412256620578
Validation loss: 2.46956276692987

Epoch: 6| Step: 7
Training loss: 0.6091772394354316
Validation loss: 2.450932692744647

Epoch: 6| Step: 8
Training loss: 0.96429090839077
Validation loss: 2.4703168080696356

Epoch: 6| Step: 9
Training loss: 0.7874418933563274
Validation loss: 2.4546983787573518

Epoch: 6| Step: 10
Training loss: 1.10968905019907
Validation loss: 2.483523277979337

Epoch: 6| Step: 11
Training loss: 1.042994695333595
Validation loss: 2.4688325190327274

Epoch: 6| Step: 12
Training loss: 1.5006898247485254
Validation loss: 2.5029356425170337

Epoch: 6| Step: 13
Training loss: 1.4116965042497924
Validation loss: 2.467563104480151

Epoch: 205| Step: 0
Training loss: 1.1133797049906409
Validation loss: 2.4669845185307953

Epoch: 6| Step: 1
Training loss: 0.9556122516906949
Validation loss: 2.4726969708727475

Epoch: 6| Step: 2
Training loss: 0.8365638026675148
Validation loss: 2.460234388418859

Epoch: 6| Step: 3
Training loss: 1.1849874216530796
Validation loss: 2.4734536520272683

Epoch: 6| Step: 4
Training loss: 0.8718599789873944
Validation loss: 2.4417707935162505

Epoch: 6| Step: 5
Training loss: 0.7371120984502715
Validation loss: 2.45831834494094

Epoch: 6| Step: 6
Training loss: 0.8634991608125798
Validation loss: 2.4287352573906884

Epoch: 6| Step: 7
Training loss: 1.1375479279366503
Validation loss: 2.416423299145698

Epoch: 6| Step: 8
Training loss: 1.2355700152699876
Validation loss: 2.433175681366665

Epoch: 6| Step: 9
Training loss: 1.1244959231752656
Validation loss: 2.4214465346797356

Epoch: 6| Step: 10
Training loss: 0.9430328499057081
Validation loss: 2.3945835001230824

Epoch: 6| Step: 11
Training loss: 1.4135050227963535
Validation loss: 2.398540638239264

Epoch: 6| Step: 12
Training loss: 1.0725909852957327
Validation loss: 2.4061557009240415

Epoch: 6| Step: 13
Training loss: 1.0764379155195238
Validation loss: 2.4268397226980145

Epoch: 206| Step: 0
Training loss: 1.1238835410946642
Validation loss: 2.428126512385173

Epoch: 6| Step: 1
Training loss: 1.0855092912765667
Validation loss: 2.4300412430717953

Epoch: 6| Step: 2
Training loss: 1.6149006029372035
Validation loss: 2.4539290307696167

Epoch: 6| Step: 3
Training loss: 1.1339790914414405
Validation loss: 2.4376414047382293

Epoch: 6| Step: 4
Training loss: 0.9457975041889536
Validation loss: 2.435156280993321

Epoch: 6| Step: 5
Training loss: 1.1892476522932922
Validation loss: 2.425831293598462

Epoch: 6| Step: 6
Training loss: 1.1492028832393797
Validation loss: 2.4302557265073013

Epoch: 6| Step: 7
Training loss: 1.118244711287111
Validation loss: 2.403782989293667

Epoch: 6| Step: 8
Training loss: 0.7385383440883633
Validation loss: 2.418911959812536

Epoch: 6| Step: 9
Training loss: 0.7302962318733762
Validation loss: 2.4054477709026574

Epoch: 6| Step: 10
Training loss: 0.6716493183179951
Validation loss: 2.4205523019846047

Epoch: 6| Step: 11
Training loss: 1.1878066419915134
Validation loss: 2.419055765750494

Epoch: 6| Step: 12
Training loss: 0.7312208577405324
Validation loss: 2.4103281753537513

Epoch: 6| Step: 13
Training loss: 0.8426973346107188
Validation loss: 2.428234466573964

Epoch: 207| Step: 0
Training loss: 1.0661087459542171
Validation loss: 2.4516114769641635

Epoch: 6| Step: 1
Training loss: 0.7636211407679908
Validation loss: 2.430266654037827

Epoch: 6| Step: 2
Training loss: 1.0411819983507087
Validation loss: 2.4590701345532

Epoch: 6| Step: 3
Training loss: 1.5216288467392447
Validation loss: 2.463112786217345

Epoch: 6| Step: 4
Training loss: 1.010692945377334
Validation loss: 2.43976875528703

Epoch: 6| Step: 5
Training loss: 0.8229799769388814
Validation loss: 2.428803649444575

Epoch: 6| Step: 6
Training loss: 1.2758675073639292
Validation loss: 2.423801117984114

Epoch: 6| Step: 7
Training loss: 1.3000172613905285
Validation loss: 2.414188487785542

Epoch: 6| Step: 8
Training loss: 0.4706043440501968
Validation loss: 2.415246844154972

Epoch: 6| Step: 9
Training loss: 1.0552816907131743
Validation loss: 2.399561496893644

Epoch: 6| Step: 10
Training loss: 1.0039487599675498
Validation loss: 2.400990681775039

Epoch: 6| Step: 11
Training loss: 0.8056599194969234
Validation loss: 2.390202623770285

Epoch: 6| Step: 12
Training loss: 0.9948011501053289
Validation loss: 2.4187780971897843

Epoch: 6| Step: 13
Training loss: 1.045531136266671
Validation loss: 2.4317431351229297

Epoch: 208| Step: 0
Training loss: 0.7677251854491455
Validation loss: 2.4247423022175565

Epoch: 6| Step: 1
Training loss: 0.8092791467413848
Validation loss: 2.425660520972144

Epoch: 6| Step: 2
Training loss: 1.4140621206377901
Validation loss: 2.4263357417435083

Epoch: 6| Step: 3
Training loss: 0.8904874260371836
Validation loss: 2.42370997581006

Epoch: 6| Step: 4
Training loss: 0.7286616120301275
Validation loss: 2.406216964633412

Epoch: 6| Step: 5
Training loss: 1.1109619610074604
Validation loss: 2.4333872104613268

Epoch: 6| Step: 6
Training loss: 1.0250644710082926
Validation loss: 2.4063120912409666

Epoch: 6| Step: 7
Training loss: 1.2662485729333757
Validation loss: 2.4375340780395467

Epoch: 6| Step: 8
Training loss: 1.5925711965889733
Validation loss: 2.4437080588884275

Epoch: 6| Step: 9
Training loss: 0.7443806819234491
Validation loss: 2.4443626274364014

Epoch: 6| Step: 10
Training loss: 0.784618971979706
Validation loss: 2.4394479272038376

Epoch: 6| Step: 11
Training loss: 0.9543502624043689
Validation loss: 2.4446627642754195

Epoch: 6| Step: 12
Training loss: 0.8247772783137468
Validation loss: 2.401083576809226

Epoch: 6| Step: 13
Training loss: 1.035392878135694
Validation loss: 2.4269548040844278

Epoch: 209| Step: 0
Training loss: 0.9611991588109432
Validation loss: 2.4030088989694707

Epoch: 6| Step: 1
Training loss: 0.8533777260843657
Validation loss: 2.379591379462556

Epoch: 6| Step: 2
Training loss: 1.1382391550714983
Validation loss: 2.39483063961781

Epoch: 6| Step: 3
Training loss: 1.2180587568909176
Validation loss: 2.3919348680799133

Epoch: 6| Step: 4
Training loss: 1.1576533178538702
Validation loss: 2.3971778993442134

Epoch: 6| Step: 5
Training loss: 0.7930990027577604
Validation loss: 2.414824323126537

Epoch: 6| Step: 6
Training loss: 0.9309453068944012
Validation loss: 2.3812784422077846

Epoch: 6| Step: 7
Training loss: 1.3660872037316882
Validation loss: 2.39573696490166

Epoch: 6| Step: 8
Training loss: 0.8917308099498344
Validation loss: 2.4130475317619227

Epoch: 6| Step: 9
Training loss: 0.7468989555954255
Validation loss: 2.411153316155194

Epoch: 6| Step: 10
Training loss: 0.5293419737799286
Validation loss: 2.3851386620833606

Epoch: 6| Step: 11
Training loss: 1.360924856694352
Validation loss: 2.3957486726659387

Epoch: 6| Step: 12
Training loss: 0.9214718793965365
Validation loss: 2.4029259363852624

Epoch: 6| Step: 13
Training loss: 0.6880181700669133
Validation loss: 2.392958373407427

Epoch: 210| Step: 0
Training loss: 0.9781374933584458
Validation loss: 2.399573653945227

Epoch: 6| Step: 1
Training loss: 0.5868601337861539
Validation loss: 2.453068931330208

Epoch: 6| Step: 2
Training loss: 0.6369095030957436
Validation loss: 2.4139191320468765

Epoch: 6| Step: 3
Training loss: 1.0484829979474457
Validation loss: 2.4332780667663543

Epoch: 6| Step: 4
Training loss: 1.390163602257506
Validation loss: 2.4315486538204403

Epoch: 6| Step: 5
Training loss: 1.4800172786735022
Validation loss: 2.4005463266963445

Epoch: 6| Step: 6
Training loss: 1.048122175527917
Validation loss: 2.3987160380950883

Epoch: 6| Step: 7
Training loss: 0.8888783979955792
Validation loss: 2.385879257521381

Epoch: 6| Step: 8
Training loss: 1.113054754406432
Validation loss: 2.3852637142014554

Epoch: 6| Step: 9
Training loss: 0.5714282265730226
Validation loss: 2.3499686136726496

Epoch: 6| Step: 10
Training loss: 1.0204307709593128
Validation loss: 2.3504932051826843

Epoch: 6| Step: 11
Training loss: 0.9914655086041001
Validation loss: 2.376175484290394

Epoch: 6| Step: 12
Training loss: 1.1388083322200775
Validation loss: 2.3715582705769425

Epoch: 6| Step: 13
Training loss: 1.0033127035721674
Validation loss: 2.396934912946029

Epoch: 211| Step: 0
Training loss: 1.291406061688252
Validation loss: 2.3923759785235976

Epoch: 6| Step: 1
Training loss: 1.101407412169719
Validation loss: 2.4093713469363434

Epoch: 6| Step: 2
Training loss: 0.9162608389844332
Validation loss: 2.418451552470984

Epoch: 6| Step: 3
Training loss: 0.8829939664157183
Validation loss: 2.408761980886381

Epoch: 6| Step: 4
Training loss: 1.386648686747871
Validation loss: 2.452606083584895

Epoch: 6| Step: 5
Training loss: 1.2550995754542427
Validation loss: 2.471732331359585

Epoch: 6| Step: 6
Training loss: 1.0998261747867677
Validation loss: 2.497528154446317

Epoch: 6| Step: 7
Training loss: 0.6686390865009509
Validation loss: 2.488081649893616

Epoch: 6| Step: 8
Training loss: 1.210196532926698
Validation loss: 2.4512016323015406

Epoch: 6| Step: 9
Training loss: 0.9610196210305049
Validation loss: 2.447682915189446

Epoch: 6| Step: 10
Training loss: 0.8333988680502059
Validation loss: 2.4257922177665163

Epoch: 6| Step: 11
Training loss: 1.140455102678168
Validation loss: 2.4347674253642366

Epoch: 6| Step: 12
Training loss: 0.9536020929683209
Validation loss: 2.4207472722389247

Epoch: 6| Step: 13
Training loss: 0.8072704599527907
Validation loss: 2.4170402482799056

Epoch: 212| Step: 0
Training loss: 1.1535889185980346
Validation loss: 2.406919649612131

Epoch: 6| Step: 1
Training loss: 0.7678893722537933
Validation loss: 2.343336331084005

Epoch: 6| Step: 2
Training loss: 0.9420534813554955
Validation loss: 2.3317344892935896

Epoch: 6| Step: 3
Training loss: 0.8787830859883674
Validation loss: 2.3540002410312413

Epoch: 6| Step: 4
Training loss: 0.6224831449379264
Validation loss: 2.3384375943813307

Epoch: 6| Step: 5
Training loss: 1.2153515505727106
Validation loss: 2.350409432767974

Epoch: 6| Step: 6
Training loss: 0.9357348673292718
Validation loss: 2.3639516944055203

Epoch: 6| Step: 7
Training loss: 0.7690975690562947
Validation loss: 2.397844660374469

Epoch: 6| Step: 8
Training loss: 1.459885815374992
Validation loss: 2.44562063798729

Epoch: 6| Step: 9
Training loss: 1.0949512969033517
Validation loss: 2.467479164280013

Epoch: 6| Step: 10
Training loss: 1.1839059348758572
Validation loss: 2.485280151746696

Epoch: 6| Step: 11
Training loss: 1.0016432612049488
Validation loss: 2.492167145606759

Epoch: 6| Step: 12
Training loss: 0.9149839858962362
Validation loss: 2.447045964212715

Epoch: 6| Step: 13
Training loss: 0.8481802309700304
Validation loss: 2.4389959608583216

Epoch: 213| Step: 0
Training loss: 0.8527338214056408
Validation loss: 2.430666247853826

Epoch: 6| Step: 1
Training loss: 1.3342235791951795
Validation loss: 2.397311277935216

Epoch: 6| Step: 2
Training loss: 0.9289977135317026
Validation loss: 2.398427517713733

Epoch: 6| Step: 3
Training loss: 0.846208980529689
Validation loss: 2.3960222206363144

Epoch: 6| Step: 4
Training loss: 0.6846465369001361
Validation loss: 2.373934098576329

Epoch: 6| Step: 5
Training loss: 0.9692601122187194
Validation loss: 2.3569681927427193

Epoch: 6| Step: 6
Training loss: 0.8290968177039585
Validation loss: 2.3609740221285747

Epoch: 6| Step: 7
Training loss: 0.8081723649378763
Validation loss: 2.3724115943747606

Epoch: 6| Step: 8
Training loss: 0.8541993778447106
Validation loss: 2.376873713958974

Epoch: 6| Step: 9
Training loss: 1.1049545224355144
Validation loss: 2.371514667195746

Epoch: 6| Step: 10
Training loss: 0.44846753873801715
Validation loss: 2.371808253515667

Epoch: 6| Step: 11
Training loss: 1.0965326062810778
Validation loss: 2.385897012585937

Epoch: 6| Step: 12
Training loss: 0.6139418087838865
Validation loss: 2.3917981204431764

Epoch: 6| Step: 13
Training loss: 1.8281913810480908
Validation loss: 2.430520717138734

Epoch: 214| Step: 0
Training loss: 0.8765746661479195
Validation loss: 2.4284707211641523

Epoch: 6| Step: 1
Training loss: 1.2273252994503032
Validation loss: 2.4234211771039456

Epoch: 6| Step: 2
Training loss: 0.6510055888034217
Validation loss: 2.449989569790177

Epoch: 6| Step: 3
Training loss: 1.0501248035737225
Validation loss: 2.4157099592838445

Epoch: 6| Step: 4
Training loss: 1.0269963942764413
Validation loss: 2.409301725458438

Epoch: 6| Step: 5
Training loss: 0.6054895458956993
Validation loss: 2.3945570079842873

Epoch: 6| Step: 6
Training loss: 1.3498334464011
Validation loss: 2.3936369568808575

Epoch: 6| Step: 7
Training loss: 0.7111901473621215
Validation loss: 2.404428343061086

Epoch: 6| Step: 8
Training loss: 1.0600582563838132
Validation loss: 2.4000209017410845

Epoch: 6| Step: 9
Training loss: 0.5278440292363984
Validation loss: 2.392507276559651

Epoch: 6| Step: 10
Training loss: 1.13830529097891
Validation loss: 2.3764307152420376

Epoch: 6| Step: 11
Training loss: 0.9017720578898357
Validation loss: 2.3724210642407497

Epoch: 6| Step: 12
Training loss: 1.0379681668444294
Validation loss: 2.332954550320865

Epoch: 6| Step: 13
Training loss: 0.8428208215152052
Validation loss: 2.4027631442748865

Epoch: 215| Step: 0
Training loss: 0.8334109190745306
Validation loss: 2.3927854137517746

Epoch: 6| Step: 1
Training loss: 0.7422525477765544
Validation loss: 2.347804423718571

Epoch: 6| Step: 2
Training loss: 1.1199092123155991
Validation loss: 2.3572663118067725

Epoch: 6| Step: 3
Training loss: 0.9189750188227844
Validation loss: 2.3684030782102323

Epoch: 6| Step: 4
Training loss: 0.9580026484514552
Validation loss: 2.3792174446065313

Epoch: 6| Step: 5
Training loss: 0.9845179196708329
Validation loss: 2.4037321811095116

Epoch: 6| Step: 6
Training loss: 0.690785727634168
Validation loss: 2.398330005191444

Epoch: 6| Step: 7
Training loss: 1.0187386541378365
Validation loss: 2.4104348803742734

Epoch: 6| Step: 8
Training loss: 1.1912760178725843
Validation loss: 2.393779452807338

Epoch: 6| Step: 9
Training loss: 0.8997387957350969
Validation loss: 2.39188391486394

Epoch: 6| Step: 10
Training loss: 0.9019636534369203
Validation loss: 2.3900507581022286

Epoch: 6| Step: 11
Training loss: 0.46496873665894284
Validation loss: 2.4017462674969745

Epoch: 6| Step: 12
Training loss: 0.6033714146828606
Validation loss: 2.413470458387124

Epoch: 6| Step: 13
Training loss: 1.63326676907785
Validation loss: 2.418998391818585

Epoch: 216| Step: 0
Training loss: 0.9712963479077765
Validation loss: 2.3993822856832283

Epoch: 6| Step: 1
Training loss: 0.8879541873627155
Validation loss: 2.3803269065119155

Epoch: 6| Step: 2
Training loss: 0.9358369381586917
Validation loss: 2.376432285941956

Epoch: 6| Step: 3
Training loss: 0.8056771572089247
Validation loss: 2.3853893981512777

Epoch: 6| Step: 4
Training loss: 1.3703896217001086
Validation loss: 2.3809961425404356

Epoch: 6| Step: 5
Training loss: 0.8797649003935353
Validation loss: 2.361668884784963

Epoch: 6| Step: 6
Training loss: 0.9804727014712767
Validation loss: 2.3668133087156606

Epoch: 6| Step: 7
Training loss: 0.9999069528206168
Validation loss: 2.34789869533418

Epoch: 6| Step: 8
Training loss: 0.7677202942398248
Validation loss: 2.406291011508219

Epoch: 6| Step: 9
Training loss: 0.9123951302975817
Validation loss: 2.416912270761178

Epoch: 6| Step: 10
Training loss: 0.9381844247476998
Validation loss: 2.4401877881817464

Epoch: 6| Step: 11
Training loss: 1.127636152111878
Validation loss: 2.4419421339375935

Epoch: 6| Step: 12
Training loss: 0.754079492458927
Validation loss: 2.452080409054456

Epoch: 6| Step: 13
Training loss: 0.8484421703568366
Validation loss: 2.450720076461892

Epoch: 217| Step: 0
Training loss: 1.037333548648374
Validation loss: 2.4335213945745875

Epoch: 6| Step: 1
Training loss: 0.7739259737899011
Validation loss: 2.419060218896299

Epoch: 6| Step: 2
Training loss: 0.8431899013099128
Validation loss: 2.4019710592833983

Epoch: 6| Step: 3
Training loss: 0.7818476107867312
Validation loss: 2.3833220196842717

Epoch: 6| Step: 4
Training loss: 0.6984117422111957
Validation loss: 2.3891885318245807

Epoch: 6| Step: 5
Training loss: 1.4117006419993794
Validation loss: 2.3952386432784345

Epoch: 6| Step: 6
Training loss: 0.8981597471052633
Validation loss: 2.383775007431636

Epoch: 6| Step: 7
Training loss: 0.9460860941141648
Validation loss: 2.399193933613926

Epoch: 6| Step: 8
Training loss: 1.010034993764647
Validation loss: 2.3910590827368217

Epoch: 6| Step: 9
Training loss: 0.8346533493202397
Validation loss: 2.369316820677191

Epoch: 6| Step: 10
Training loss: 1.0250992424534622
Validation loss: 2.383021390739964

Epoch: 6| Step: 11
Training loss: 0.7814503984922203
Validation loss: 2.365668608597748

Epoch: 6| Step: 12
Training loss: 0.9308814068170764
Validation loss: 2.3985137547878868

Epoch: 6| Step: 13
Training loss: 0.554676915457304
Validation loss: 2.3967246834970326

Epoch: 218| Step: 0
Training loss: 1.022630096404196
Validation loss: 2.406357051522702

Epoch: 6| Step: 1
Training loss: 0.7519568108802724
Validation loss: 2.424019536824207

Epoch: 6| Step: 2
Training loss: 1.3014527383342807
Validation loss: 2.409058988998683

Epoch: 6| Step: 3
Training loss: 0.9055788909568189
Validation loss: 2.4044347083638327

Epoch: 6| Step: 4
Training loss: 0.7770604523127284
Validation loss: 2.4096347195841674

Epoch: 6| Step: 5
Training loss: 0.615329771366156
Validation loss: 2.3684654504983564

Epoch: 6| Step: 6
Training loss: 1.0840130226542468
Validation loss: 2.3903489746722983

Epoch: 6| Step: 7
Training loss: 0.5821501335237594
Validation loss: 2.3907894834227035

Epoch: 6| Step: 8
Training loss: 0.7701323045044567
Validation loss: 2.3864515178557655

Epoch: 6| Step: 9
Training loss: 0.9454717580772338
Validation loss: 2.392805875879739

Epoch: 6| Step: 10
Training loss: 0.7799341946744359
Validation loss: 2.3969784140723718

Epoch: 6| Step: 11
Training loss: 1.1629649370800585
Validation loss: 2.3998235740641483

Epoch: 6| Step: 12
Training loss: 0.7477932094025898
Validation loss: 2.384462468701312

Epoch: 6| Step: 13
Training loss: 1.2335583846644043
Validation loss: 2.415860738305911

Epoch: 219| Step: 0
Training loss: 0.8709218492802387
Validation loss: 2.393204053814222

Epoch: 6| Step: 1
Training loss: 0.6320814926113953
Validation loss: 2.4193426165904395

Epoch: 6| Step: 2
Training loss: 1.2585132139783022
Validation loss: 2.3871663893942077

Epoch: 6| Step: 3
Training loss: 0.8437415228523804
Validation loss: 2.3865096538349793

Epoch: 6| Step: 4
Training loss: 0.774499337695376
Validation loss: 2.373146614163965

Epoch: 6| Step: 5
Training loss: 0.8062407677883331
Validation loss: 2.379970185794638

Epoch: 6| Step: 6
Training loss: 1.342139942894278
Validation loss: 2.389804776857578

Epoch: 6| Step: 7
Training loss: 0.9012677271100834
Validation loss: 2.4191950869372243

Epoch: 6| Step: 8
Training loss: 1.0116366202109968
Validation loss: 2.392466879579937

Epoch: 6| Step: 9
Training loss: 0.7486788318800033
Validation loss: 2.42224986085925

Epoch: 6| Step: 10
Training loss: 0.7384640502676825
Validation loss: 2.3946158234543273

Epoch: 6| Step: 11
Training loss: 0.7436720206149031
Validation loss: 2.416148954707861

Epoch: 6| Step: 12
Training loss: 0.9675614849533968
Validation loss: 2.4321504598326666

Epoch: 6| Step: 13
Training loss: 1.074064763910007
Validation loss: 2.409307914553165

Epoch: 220| Step: 0
Training loss: 0.8880670857992683
Validation loss: 2.3750092182941214

Epoch: 6| Step: 1
Training loss: 0.9272233378674918
Validation loss: 2.365984735364774

Epoch: 6| Step: 2
Training loss: 1.1244649674457161
Validation loss: 2.370330841343701

Epoch: 6| Step: 3
Training loss: 0.7471441893108529
Validation loss: 2.3507403101963646

Epoch: 6| Step: 4
Training loss: 0.920686149197901
Validation loss: 2.3712045818301197

Epoch: 6| Step: 5
Training loss: 0.5904851293702109
Validation loss: 2.387915203411609

Epoch: 6| Step: 6
Training loss: 0.9176254279755723
Validation loss: 2.4105986448757686

Epoch: 6| Step: 7
Training loss: 0.7801201470469679
Validation loss: 2.4353072550548647

Epoch: 6| Step: 8
Training loss: 1.4977037019331225
Validation loss: 2.4449076852944938

Epoch: 6| Step: 9
Training loss: 0.6524878245712207
Validation loss: 2.428947752631302

Epoch: 6| Step: 10
Training loss: 0.8306831578316363
Validation loss: 2.4547700880505863

Epoch: 6| Step: 11
Training loss: 0.7438175972104464
Validation loss: 2.483393569114442

Epoch: 6| Step: 12
Training loss: 0.7481080670141451
Validation loss: 2.45440144637964

Epoch: 6| Step: 13
Training loss: 1.1631809967680742
Validation loss: 2.4610427534438712

Epoch: 221| Step: 0
Training loss: 0.9637199065164603
Validation loss: 2.472357037392456

Epoch: 6| Step: 1
Training loss: 0.830208729959646
Validation loss: 2.456552664789695

Epoch: 6| Step: 2
Training loss: 1.5108248805745765
Validation loss: 2.4346938491615453

Epoch: 6| Step: 3
Training loss: 0.9075640655266592
Validation loss: 2.3933054988507445

Epoch: 6| Step: 4
Training loss: 0.8735489393738631
Validation loss: 2.3611178796354686

Epoch: 6| Step: 5
Training loss: 1.2398900312452306
Validation loss: 2.385796655622107

Epoch: 6| Step: 6
Training loss: 0.8259998620428012
Validation loss: 2.370107112977207

Epoch: 6| Step: 7
Training loss: 0.6079461389639419
Validation loss: 2.375470737076779

Epoch: 6| Step: 8
Training loss: 0.9895092116587801
Validation loss: 2.3751600197562324

Epoch: 6| Step: 9
Training loss: 0.904263951009126
Validation loss: 2.392529151185913

Epoch: 6| Step: 10
Training loss: 0.8693889134690262
Validation loss: 2.3777418069912635

Epoch: 6| Step: 11
Training loss: 0.6795941431233227
Validation loss: 2.3980711488508626

Epoch: 6| Step: 12
Training loss: 0.6414705372048294
Validation loss: 2.393817707171872

Epoch: 6| Step: 13
Training loss: 0.7644477668617312
Validation loss: 2.400655333713569

Epoch: 222| Step: 0
Training loss: 0.9439167405928273
Validation loss: 2.405197905444747

Epoch: 6| Step: 1
Training loss: 0.7106086892811834
Validation loss: 2.4123324625146028

Epoch: 6| Step: 2
Training loss: 0.9312203216943996
Validation loss: 2.4046222149465635

Epoch: 6| Step: 3
Training loss: 1.173265166650589
Validation loss: 2.400706593050408

Epoch: 6| Step: 4
Training loss: 0.7644304571362966
Validation loss: 2.378982520900122

Epoch: 6| Step: 5
Training loss: 0.8163611294630092
Validation loss: 2.3595712437923466

Epoch: 6| Step: 6
Training loss: 0.9762912831387853
Validation loss: 2.316348741284364

Epoch: 6| Step: 7
Training loss: 1.0432460573415805
Validation loss: 2.3215973584570073

Epoch: 6| Step: 8
Training loss: 0.9261260537373092
Validation loss: 2.3104636281578523

Epoch: 6| Step: 9
Training loss: 0.8434971677826444
Validation loss: 2.302504752641233

Epoch: 6| Step: 10
Training loss: 0.9836249445785408
Validation loss: 2.329344799958071

Epoch: 6| Step: 11
Training loss: 0.8708853023177568
Validation loss: 2.3457056463402775

Epoch: 6| Step: 12
Training loss: 0.7455497875794312
Validation loss: 2.340354353013417

Epoch: 6| Step: 13
Training loss: 0.7515668000476933
Validation loss: 2.36653844002742

Epoch: 223| Step: 0
Training loss: 0.5770120733954897
Validation loss: 2.401698405560269

Epoch: 6| Step: 1
Training loss: 1.1094257719215042
Validation loss: 2.438089904101874

Epoch: 6| Step: 2
Training loss: 0.6666382147757614
Validation loss: 2.4252258111917824

Epoch: 6| Step: 3
Training loss: 0.86434149902695
Validation loss: 2.441881075717703

Epoch: 6| Step: 4
Training loss: 0.731393565243336
Validation loss: 2.449799161560103

Epoch: 6| Step: 5
Training loss: 0.8237010903085762
Validation loss: 2.477063713519367

Epoch: 6| Step: 6
Training loss: 0.8882217776503903
Validation loss: 2.4159746459283746

Epoch: 6| Step: 7
Training loss: 0.7310448481034933
Validation loss: 2.40824550123677

Epoch: 6| Step: 8
Training loss: 0.6997049655071892
Validation loss: 2.3448728320586993

Epoch: 6| Step: 9
Training loss: 0.7284454230062167
Validation loss: 2.3351561711307824

Epoch: 6| Step: 10
Training loss: 1.0977899327443918
Validation loss: 2.334886403387847

Epoch: 6| Step: 11
Training loss: 0.9055864272449293
Validation loss: 2.319233165698428

Epoch: 6| Step: 12
Training loss: 1.2912043492684744
Validation loss: 2.3322356171905567

Epoch: 6| Step: 13
Training loss: 1.0752919887281545
Validation loss: 2.3185510220363317

Epoch: 224| Step: 0
Training loss: 0.3971158153094995
Validation loss: 2.333115561675612

Epoch: 6| Step: 1
Training loss: 0.9492866272067498
Validation loss: 2.3041808547392915

Epoch: 6| Step: 2
Training loss: 0.7398287988136902
Validation loss: 2.325238322519727

Epoch: 6| Step: 3
Training loss: 1.0117883842394177
Validation loss: 2.3327785748416283

Epoch: 6| Step: 4
Training loss: 0.7647064303918316
Validation loss: 2.3320954492050254

Epoch: 6| Step: 5
Training loss: 0.6681031655150803
Validation loss: 2.379366650865015

Epoch: 6| Step: 6
Training loss: 0.9661526161360189
Validation loss: 2.3511687986796543

Epoch: 6| Step: 7
Training loss: 0.9790094770239728
Validation loss: 2.3608285921499332

Epoch: 6| Step: 8
Training loss: 0.7430386932535452
Validation loss: 2.39957344347566

Epoch: 6| Step: 9
Training loss: 0.7101181255048787
Validation loss: 2.398108924248832

Epoch: 6| Step: 10
Training loss: 1.398517414558774
Validation loss: 2.4170862409319906

Epoch: 6| Step: 11
Training loss: 0.9529924769589957
Validation loss: 2.4071031152020144

Epoch: 6| Step: 12
Training loss: 0.6288367523272629
Validation loss: 2.4151743010426077

Epoch: 6| Step: 13
Training loss: 0.4016866224952136
Validation loss: 2.380875937835884

Epoch: 225| Step: 0
Training loss: 0.9510992441509069
Validation loss: 2.3843807434512603

Epoch: 6| Step: 1
Training loss: 0.8787204800418521
Validation loss: 2.4025880596163502

Epoch: 6| Step: 2
Training loss: 1.1540822508934936
Validation loss: 2.364498378855084

Epoch: 6| Step: 3
Training loss: 0.7601334728188424
Validation loss: 2.3572758745983298

Epoch: 6| Step: 4
Training loss: 0.6699846421801724
Validation loss: 2.3658141029823314

Epoch: 6| Step: 5
Training loss: 0.5119522959532036
Validation loss: 2.346174198087656

Epoch: 6| Step: 6
Training loss: 1.2415880400236468
Validation loss: 2.368689556337147

Epoch: 6| Step: 7
Training loss: 0.7060808781030724
Validation loss: 2.349029800407963

Epoch: 6| Step: 8
Training loss: 0.7805301783370655
Validation loss: 2.335862655173179

Epoch: 6| Step: 9
Training loss: 0.8970402342747251
Validation loss: 2.372038986441034

Epoch: 6| Step: 10
Training loss: 0.7778282764102324
Validation loss: 2.356727822064884

Epoch: 6| Step: 11
Training loss: 0.717277594332374
Validation loss: 2.3584129959955074

Epoch: 6| Step: 12
Training loss: 0.43388561357678956
Validation loss: 2.3790580986222762

Epoch: 6| Step: 13
Training loss: 1.2189306956611152
Validation loss: 2.377183578557579

Epoch: 226| Step: 0
Training loss: 0.820626625588195
Validation loss: 2.400098730862824

Epoch: 6| Step: 1
Training loss: 0.8464893096230763
Validation loss: 2.3599675920297254

Epoch: 6| Step: 2
Training loss: 1.1668609673055224
Validation loss: 2.3453006561512137

Epoch: 6| Step: 3
Training loss: 0.6021448264568986
Validation loss: 2.3808013675558994

Epoch: 6| Step: 4
Training loss: 0.6669329593215388
Validation loss: 2.3574071842356434

Epoch: 6| Step: 5
Training loss: 1.1058736538142042
Validation loss: 2.3926107786527355

Epoch: 6| Step: 6
Training loss: 0.7184924203158305
Validation loss: 2.3771907803430805

Epoch: 6| Step: 7
Training loss: 0.6957004836223479
Validation loss: 2.3903749321613774

Epoch: 6| Step: 8
Training loss: 0.30653745288388845
Validation loss: 2.4020892414197914

Epoch: 6| Step: 9
Training loss: 0.8044858513175311
Validation loss: 2.372659841818366

Epoch: 6| Step: 10
Training loss: 0.9290757610915645
Validation loss: 2.4045229407062454

Epoch: 6| Step: 11
Training loss: 0.7589667663259292
Validation loss: 2.4279361286244674

Epoch: 6| Step: 12
Training loss: 0.751432203708067
Validation loss: 2.4076781587306924

Epoch: 6| Step: 13
Training loss: 0.7284050824362482
Validation loss: 2.4076346589977167

Epoch: 227| Step: 0
Training loss: 0.7066097583851113
Validation loss: 2.3779517528241865

Epoch: 6| Step: 1
Training loss: 1.0564835690810725
Validation loss: 2.39683775496834

Epoch: 6| Step: 2
Training loss: 0.5245430217714002
Validation loss: 2.376234149487184

Epoch: 6| Step: 3
Training loss: 1.083493893291479
Validation loss: 2.3839908230198805

Epoch: 6| Step: 4
Training loss: 0.6343399733471329
Validation loss: 2.3947794097327093

Epoch: 6| Step: 5
Training loss: 0.32738804938521604
Validation loss: 2.3748475950398316

Epoch: 6| Step: 6
Training loss: 0.6548901501479724
Validation loss: 2.372716698801734

Epoch: 6| Step: 7
Training loss: 0.608045742127472
Validation loss: 2.3977409832635184

Epoch: 6| Step: 8
Training loss: 0.6725836720228455
Validation loss: 2.3923957342325815

Epoch: 6| Step: 9
Training loss: 0.8120942202902224
Validation loss: 2.3883458070926107

Epoch: 6| Step: 10
Training loss: 1.2119550797916312
Validation loss: 2.370795121576952

Epoch: 6| Step: 11
Training loss: 0.6474214199428678
Validation loss: 2.3815850964303396

Epoch: 6| Step: 12
Training loss: 0.8625511085184263
Validation loss: 2.3727227483253146

Epoch: 6| Step: 13
Training loss: 0.746471369384023
Validation loss: 2.3644003219727265

Epoch: 228| Step: 0
Training loss: 0.9893440593091349
Validation loss: 2.384813297875573

Epoch: 6| Step: 1
Training loss: 0.7749701063481981
Validation loss: 2.3772204715709684

Epoch: 6| Step: 2
Training loss: 0.5357805773045813
Validation loss: 2.3862701660955006

Epoch: 6| Step: 3
Training loss: 0.7173913470684135
Validation loss: 2.375578330090644

Epoch: 6| Step: 4
Training loss: 0.7591971891724997
Validation loss: 2.3802246608745414

Epoch: 6| Step: 5
Training loss: 1.2669857857079192
Validation loss: 2.377785416395535

Epoch: 6| Step: 6
Training loss: 0.6625612005719945
Validation loss: 2.408005816272785

Epoch: 6| Step: 7
Training loss: 0.9022710201132845
Validation loss: 2.376475493806755

Epoch: 6| Step: 8
Training loss: 0.7868143669443831
Validation loss: 2.3876594217814247

Epoch: 6| Step: 9
Training loss: 0.7002633033845207
Validation loss: 2.385880787616872

Epoch: 6| Step: 10
Training loss: 0.5944146902990151
Validation loss: 2.3614664367959124

Epoch: 6| Step: 11
Training loss: 0.6106765248201876
Validation loss: 2.373135962671452

Epoch: 6| Step: 12
Training loss: 0.7589431665123071
Validation loss: 2.377479517517991

Epoch: 6| Step: 13
Training loss: 0.8525359513093825
Validation loss: 2.351923510838669

Epoch: 229| Step: 0
Training loss: 0.8075777018810639
Validation loss: 2.371373201479984

Epoch: 6| Step: 1
Training loss: 0.7171871775375007
Validation loss: 2.3887876060445126

Epoch: 6| Step: 2
Training loss: 0.7381274754468994
Validation loss: 2.3932574284758616

Epoch: 6| Step: 3
Training loss: 0.6381520713720529
Validation loss: 2.4128106504620064

Epoch: 6| Step: 4
Training loss: 0.707496784863395
Validation loss: 2.3879670126673695

Epoch: 6| Step: 5
Training loss: 0.4159838167307237
Validation loss: 2.3814668979015834

Epoch: 6| Step: 6
Training loss: 0.6393596434030837
Validation loss: 2.392863796943879

Epoch: 6| Step: 7
Training loss: 1.012838267110693
Validation loss: 2.397544745726877

Epoch: 6| Step: 8
Training loss: 0.6879290629039604
Validation loss: 2.388584648282861

Epoch: 6| Step: 9
Training loss: 1.232487116082809
Validation loss: 2.404373004733299

Epoch: 6| Step: 10
Training loss: 0.9409905936655775
Validation loss: 2.397694143731344

Epoch: 6| Step: 11
Training loss: 0.585145364005636
Validation loss: 2.395613722257159

Epoch: 6| Step: 12
Training loss: 0.705258481108235
Validation loss: 2.3887653435340166

Epoch: 6| Step: 13
Training loss: 0.4167038503585682
Validation loss: 2.3931259878769486

Epoch: 230| Step: 0
Training loss: 0.5173624417019772
Validation loss: 2.414978346366961

Epoch: 6| Step: 1
Training loss: 0.7107209934430176
Validation loss: 2.4039884992786478

Epoch: 6| Step: 2
Training loss: 1.0414205196745132
Validation loss: 2.414138178414555

Epoch: 6| Step: 3
Training loss: 1.0378663484823138
Validation loss: 2.4271879628248163

Epoch: 6| Step: 4
Training loss: 0.5948748223676614
Validation loss: 2.3855734207300507

Epoch: 6| Step: 5
Training loss: 0.6897879157794377
Validation loss: 2.4095881820036706

Epoch: 6| Step: 6
Training loss: 0.7084201637977205
Validation loss: 2.3846685928602573

Epoch: 6| Step: 7
Training loss: 0.7878878319633579
Validation loss: 2.3880142144904886

Epoch: 6| Step: 8
Training loss: 0.5124554754315482
Validation loss: 2.3671660664458285

Epoch: 6| Step: 9
Training loss: 0.6943490715233263
Validation loss: 2.375237859398323

Epoch: 6| Step: 10
Training loss: 0.761164184581579
Validation loss: 2.3523825563066745

Epoch: 6| Step: 11
Training loss: 0.7824431654061267
Validation loss: 2.3567055803256767

Epoch: 6| Step: 12
Training loss: 0.7382261063907177
Validation loss: 2.4153414389346084

Epoch: 6| Step: 13
Training loss: 1.0530930511427916
Validation loss: 2.382000896527494

Epoch: 231| Step: 0
Training loss: 0.9865681875437707
Validation loss: 2.4162427624498455

Epoch: 6| Step: 1
Training loss: 0.7511030668502562
Validation loss: 2.433309014277936

Epoch: 6| Step: 2
Training loss: 0.8840462831942796
Validation loss: 2.404134457769243

Epoch: 6| Step: 3
Training loss: 0.8170371652178553
Validation loss: 2.4180494121369107

Epoch: 6| Step: 4
Training loss: 0.35495093641258363
Validation loss: 2.415602445099804

Epoch: 6| Step: 5
Training loss: 0.7170553962530536
Validation loss: 2.3788515217299704

Epoch: 6| Step: 6
Training loss: 0.4568710535455633
Validation loss: 2.4000736230407145

Epoch: 6| Step: 7
Training loss: 0.773539180044432
Validation loss: 2.381744683448053

Epoch: 6| Step: 8
Training loss: 0.7648050627699478
Validation loss: 2.3674995950081996

Epoch: 6| Step: 9
Training loss: 0.5850273183818182
Validation loss: 2.3667651719953646

Epoch: 6| Step: 10
Training loss: 1.0623131194974984
Validation loss: 2.379717480957814

Epoch: 6| Step: 11
Training loss: 0.6839401675261786
Validation loss: 2.394064724403093

Epoch: 6| Step: 12
Training loss: 0.8389312755186417
Validation loss: 2.400729888504041

Epoch: 6| Step: 13
Training loss: 0.42868752730631293
Validation loss: 2.4377128754227932

Epoch: 232| Step: 0
Training loss: 0.45161902987907643
Validation loss: 2.450416298991906

Epoch: 6| Step: 1
Training loss: 1.1724383208231652
Validation loss: 2.4544360402231233

Epoch: 6| Step: 2
Training loss: 0.4147267681350191
Validation loss: 2.4385620266743637

Epoch: 6| Step: 3
Training loss: 0.6585791218537014
Validation loss: 2.4425804355183023

Epoch: 6| Step: 4
Training loss: 0.6601432257276029
Validation loss: 2.4752730396395513

Epoch: 6| Step: 5
Training loss: 0.5815359991186049
Validation loss: 2.4513592467879133

Epoch: 6| Step: 6
Training loss: 0.7072249932154512
Validation loss: 2.4597304955237442

Epoch: 6| Step: 7
Training loss: 0.9981233153212536
Validation loss: 2.449379626274824

Epoch: 6| Step: 8
Training loss: 0.8167401228845488
Validation loss: 2.4396718995084052

Epoch: 6| Step: 9
Training loss: 0.6694929345650524
Validation loss: 2.432487780452996

Epoch: 6| Step: 10
Training loss: 0.7045708519589391
Validation loss: 2.426949818249418

Epoch: 6| Step: 11
Training loss: 0.6147326891394368
Validation loss: 2.4535002647724813

Epoch: 6| Step: 12
Training loss: 0.6724172444459472
Validation loss: 2.4168731451317407

Epoch: 6| Step: 13
Training loss: 0.8642111900383777
Validation loss: 2.4115029811524287

Epoch: 233| Step: 0
Training loss: 1.0507155614124417
Validation loss: 2.381727141767124

Epoch: 6| Step: 1
Training loss: 0.5785091000536062
Validation loss: 2.3966249235398926

Epoch: 6| Step: 2
Training loss: 0.8526966346990156
Validation loss: 2.385976700295852

Epoch: 6| Step: 3
Training loss: 0.8303950523770223
Validation loss: 2.368237234815536

Epoch: 6| Step: 4
Training loss: 0.44956363209974726
Validation loss: 2.3735470561537464

Epoch: 6| Step: 5
Training loss: 0.8186322396890666
Validation loss: 2.3918592052715866

Epoch: 6| Step: 6
Training loss: 0.6421629425328284
Validation loss: 2.389989351379381

Epoch: 6| Step: 7
Training loss: 0.4669321414852962
Validation loss: 2.410279738228545

Epoch: 6| Step: 8
Training loss: 0.7600048639744159
Validation loss: 2.417590834105234

Epoch: 6| Step: 9
Training loss: 0.6429089561275283
Validation loss: 2.4118705084882834

Epoch: 6| Step: 10
Training loss: 0.8606344877120377
Validation loss: 2.4401035460959215

Epoch: 6| Step: 11
Training loss: 0.7726471070152693
Validation loss: 2.4210843862896834

Epoch: 6| Step: 12
Training loss: 0.6610333636948937
Validation loss: 2.4153761910058815

Epoch: 6| Step: 13
Training loss: 0.4772054368840523
Validation loss: 2.428339634149547

Epoch: 234| Step: 0
Training loss: 0.7627147325297486
Validation loss: 2.4042823661580415

Epoch: 6| Step: 1
Training loss: 0.6653539105559071
Validation loss: 2.4180034643109876

Epoch: 6| Step: 2
Training loss: 0.7013654733805265
Validation loss: 2.408091167391787

Epoch: 6| Step: 3
Training loss: 0.7463829718224592
Validation loss: 2.3936602981104547

Epoch: 6| Step: 4
Training loss: 0.6844722443561836
Validation loss: 2.417646693276086

Epoch: 6| Step: 5
Training loss: 0.5389857030150772
Validation loss: 2.4290267625715036

Epoch: 6| Step: 6
Training loss: 1.1024608871545913
Validation loss: 2.3822030307238182

Epoch: 6| Step: 7
Training loss: 0.6610811965605227
Validation loss: 2.408886505858837

Epoch: 6| Step: 8
Training loss: 0.5818069332969884
Validation loss: 2.406748486309365

Epoch: 6| Step: 9
Training loss: 0.7283745595872738
Validation loss: 2.393042449932029

Epoch: 6| Step: 10
Training loss: 0.8520686194183956
Validation loss: 2.4316290115031016

Epoch: 6| Step: 11
Training loss: 0.5595312987037004
Validation loss: 2.413391650874317

Epoch: 6| Step: 12
Training loss: 0.479015851819703
Validation loss: 2.4049708089608344

Epoch: 6| Step: 13
Training loss: 0.8203397837143316
Validation loss: 2.413083538620067

Epoch: 235| Step: 0
Training loss: 0.7152290764887925
Validation loss: 2.4299059383455384

Epoch: 6| Step: 1
Training loss: 0.8041557480922392
Validation loss: 2.472905465624966

Epoch: 6| Step: 2
Training loss: 0.5575714894290482
Validation loss: 2.4871726319624523

Epoch: 6| Step: 3
Training loss: 0.5112143207029142
Validation loss: 2.477036669055883

Epoch: 6| Step: 4
Training loss: 0.5588696738654599
Validation loss: 2.4792803183943155

Epoch: 6| Step: 5
Training loss: 0.4877980091647899
Validation loss: 2.4606623331524102

Epoch: 6| Step: 6
Training loss: 0.7873736900879482
Validation loss: 2.4775465437518966

Epoch: 6| Step: 7
Training loss: 0.56753737532429
Validation loss: 2.4885383857264474

Epoch: 6| Step: 8
Training loss: 0.7112170497723616
Validation loss: 2.458345881062127

Epoch: 6| Step: 9
Training loss: 0.9239483809481666
Validation loss: 2.4247442243586534

Epoch: 6| Step: 10
Training loss: 0.7930459797650927
Validation loss: 2.4207022196832977

Epoch: 6| Step: 11
Training loss: 1.1360114345075802
Validation loss: 2.400722260776224

Epoch: 6| Step: 12
Training loss: 0.5081339478965899
Validation loss: 2.404536852641746

Epoch: 6| Step: 13
Training loss: 0.8649555730160211
Validation loss: 2.3569799446137365

Epoch: 236| Step: 0
Training loss: 0.6001362923956344
Validation loss: 2.370016057424033

Epoch: 6| Step: 1
Training loss: 0.750054277999108
Validation loss: 2.3465718444747674

Epoch: 6| Step: 2
Training loss: 0.8561123034170294
Validation loss: 2.376676817017726

Epoch: 6| Step: 3
Training loss: 0.7078374828788554
Validation loss: 2.3759428084045533

Epoch: 6| Step: 4
Training loss: 0.8986958671258316
Validation loss: 2.3916160952101557

Epoch: 6| Step: 5
Training loss: 0.6825527002437811
Validation loss: 2.3779842612597477

Epoch: 6| Step: 6
Training loss: 0.663223499529315
Validation loss: 2.3746594776965457

Epoch: 6| Step: 7
Training loss: 1.1897542537862456
Validation loss: 2.361304304031492

Epoch: 6| Step: 8
Training loss: 0.6199675852623642
Validation loss: 2.3572068814447347

Epoch: 6| Step: 9
Training loss: 0.5108341987544451
Validation loss: 2.3642030563479404

Epoch: 6| Step: 10
Training loss: 0.28491271083477376
Validation loss: 2.3636328021900472

Epoch: 6| Step: 11
Training loss: 0.6654522434327217
Validation loss: 2.4082001442721093

Epoch: 6| Step: 12
Training loss: 0.713363239970112
Validation loss: 2.4048265983675634

Epoch: 6| Step: 13
Training loss: 0.45572477247753657
Validation loss: 2.434598223572776

Epoch: 237| Step: 0
Training loss: 0.6975353157509792
Validation loss: 2.400038462462255

Epoch: 6| Step: 1
Training loss: 1.2008530604594974
Validation loss: 2.4338118324869153

Epoch: 6| Step: 2
Training loss: 0.5440810083947346
Validation loss: 2.435168894105321

Epoch: 6| Step: 3
Training loss: 0.5643856443835569
Validation loss: 2.441834005705495

Epoch: 6| Step: 4
Training loss: 0.7402859068474511
Validation loss: 2.4228953434735563

Epoch: 6| Step: 5
Training loss: 0.708849008631573
Validation loss: 2.4001524170978352

Epoch: 6| Step: 6
Training loss: 0.7745475124908962
Validation loss: 2.3843596278800527

Epoch: 6| Step: 7
Training loss: 0.9217502380259046
Validation loss: 2.4054110438476672

Epoch: 6| Step: 8
Training loss: 0.5889252844345896
Validation loss: 2.3476184828760625

Epoch: 6| Step: 9
Training loss: 0.7859752426034001
Validation loss: 2.3642601758006276

Epoch: 6| Step: 10
Training loss: 0.7837449480347202
Validation loss: 2.3397328153957955

Epoch: 6| Step: 11
Training loss: 0.3985825442926369
Validation loss: 2.3762379071780138

Epoch: 6| Step: 12
Training loss: 0.26797763209178016
Validation loss: 2.38052815546681

Epoch: 6| Step: 13
Training loss: 0.62235460716774
Validation loss: 2.3651522568666965

Epoch: 238| Step: 0
Training loss: 0.8658775195380696
Validation loss: 2.3527795522127284

Epoch: 6| Step: 1
Training loss: 0.7327277193459635
Validation loss: 2.4061963358108707

Epoch: 6| Step: 2
Training loss: 0.3476795124457845
Validation loss: 2.3866557279496408

Epoch: 6| Step: 3
Training loss: 0.4916078393571053
Validation loss: 2.384529702155387

Epoch: 6| Step: 4
Training loss: 1.0526164312590347
Validation loss: 2.3954589783122686

Epoch: 6| Step: 5
Training loss: 0.5528049221780946
Validation loss: 2.3595365433539124

Epoch: 6| Step: 6
Training loss: 1.0148271214251248
Validation loss: 2.390335583444918

Epoch: 6| Step: 7
Training loss: 0.6167128947260077
Validation loss: 2.386514877769752

Epoch: 6| Step: 8
Training loss: 0.6040606953869746
Validation loss: 2.344680456508475

Epoch: 6| Step: 9
Training loss: 0.4210979581774778
Validation loss: 2.3672331064399073

Epoch: 6| Step: 10
Training loss: 0.5522311180775751
Validation loss: 2.3748323449380497

Epoch: 6| Step: 11
Training loss: 0.8613451482427037
Validation loss: 2.3763709901176573

Epoch: 6| Step: 12
Training loss: 0.6438612027090607
Validation loss: 2.3791918201028115

Epoch: 6| Step: 13
Training loss: 0.44419823493508076
Validation loss: 2.394501011128278

Epoch: 239| Step: 0
Training loss: 0.7236451676893122
Validation loss: 2.374135832201504

Epoch: 6| Step: 1
Training loss: 0.5949208610861662
Validation loss: 2.3810120831679225

Epoch: 6| Step: 2
Training loss: 0.6282551398137242
Validation loss: 2.370749531754607

Epoch: 6| Step: 3
Training loss: 0.6880758648063925
Validation loss: 2.3562195780362822

Epoch: 6| Step: 4
Training loss: 0.4019285114785787
Validation loss: 2.4012987858996944

Epoch: 6| Step: 5
Training loss: 0.5134334518542358
Validation loss: 2.3785133971629935

Epoch: 6| Step: 6
Training loss: 0.5698230158279131
Validation loss: 2.3643369370578706

Epoch: 6| Step: 7
Training loss: 0.6945341017914486
Validation loss: 2.355936344835257

Epoch: 6| Step: 8
Training loss: 0.8514527766381874
Validation loss: 2.3707720456236934

Epoch: 6| Step: 9
Training loss: 0.8060480855602546
Validation loss: 2.351293742878617

Epoch: 6| Step: 10
Training loss: 0.5891457779601696
Validation loss: 2.3857989282790615

Epoch: 6| Step: 11
Training loss: 0.6099473270750765
Validation loss: 2.3516126087777702

Epoch: 6| Step: 12
Training loss: 0.6486684319038262
Validation loss: 2.3742799439163442

Epoch: 6| Step: 13
Training loss: 1.1644512781783094
Validation loss: 2.3628631040173946

Epoch: 240| Step: 0
Training loss: 0.6458866087156528
Validation loss: 2.390472217417338

Epoch: 6| Step: 1
Training loss: 0.7238346698627727
Validation loss: 2.4049727069299625

Epoch: 6| Step: 2
Training loss: 0.5901946482994548
Validation loss: 2.3628080095748487

Epoch: 6| Step: 3
Training loss: 0.7196612179620427
Validation loss: 2.393018809407703

Epoch: 6| Step: 4
Training loss: 0.6951533789134912
Validation loss: 2.373289771633681

Epoch: 6| Step: 5
Training loss: 0.7298888081954326
Validation loss: 2.4024171682111137

Epoch: 6| Step: 6
Training loss: 0.6032548112467933
Validation loss: 2.4321621657049115

Epoch: 6| Step: 7
Training loss: 0.6537067086088987
Validation loss: 2.4307953542694674

Epoch: 6| Step: 8
Training loss: 0.42490422628271063
Validation loss: 2.45954324708361

Epoch: 6| Step: 9
Training loss: 0.643058852120233
Validation loss: 2.4280016860207323

Epoch: 6| Step: 10
Training loss: 0.8576123280258305
Validation loss: 2.41962775143856

Epoch: 6| Step: 11
Training loss: 0.6551634330910702
Validation loss: 2.419686852783947

Epoch: 6| Step: 12
Training loss: 0.6425265027676917
Validation loss: 2.4569306338892845

Epoch: 6| Step: 13
Training loss: 0.7486154571679133
Validation loss: 2.441792366455611

Epoch: 241| Step: 0
Training loss: 1.0353850489700618
Validation loss: 2.431043358872881

Epoch: 6| Step: 1
Training loss: 0.2878215028760929
Validation loss: 2.4330685575436037

Epoch: 6| Step: 2
Training loss: 1.0324639198150751
Validation loss: 2.4357001235714955

Epoch: 6| Step: 3
Training loss: 0.5298124104182824
Validation loss: 2.3787996610491757

Epoch: 6| Step: 4
Training loss: 0.7123956085158613
Validation loss: 2.409379699814383

Epoch: 6| Step: 5
Training loss: 0.5317038672934512
Validation loss: 2.3880998837206944

Epoch: 6| Step: 6
Training loss: 0.41526422115228867
Validation loss: 2.3695545408296654

Epoch: 6| Step: 7
Training loss: 0.6416691899766065
Validation loss: 2.3873673232772528

Epoch: 6| Step: 8
Training loss: 0.841814895047573
Validation loss: 2.379500072730571

Epoch: 6| Step: 9
Training loss: 0.8055794966271469
Validation loss: 2.4015452348680677

Epoch: 6| Step: 10
Training loss: 0.4329937228404162
Validation loss: 2.371979005907833

Epoch: 6| Step: 11
Training loss: 0.41355404134663676
Validation loss: 2.3899027702396274

Epoch: 6| Step: 12
Training loss: 0.26580787422178875
Validation loss: 2.3923892425991875

Epoch: 6| Step: 13
Training loss: 0.8005038641622514
Validation loss: 2.415098562744527

Epoch: 242| Step: 0
Training loss: 0.5723031458092829
Validation loss: 2.4351638008625502

Epoch: 6| Step: 1
Training loss: 1.1489267150641658
Validation loss: 2.4421981253150173

Epoch: 6| Step: 2
Training loss: 0.4672641251155199
Validation loss: 2.436520290452869

Epoch: 6| Step: 3
Training loss: 0.6022775042133414
Validation loss: 2.4094486841004503

Epoch: 6| Step: 4
Training loss: 0.7765534951131183
Validation loss: 2.4178107979391315

Epoch: 6| Step: 5
Training loss: 0.46938746340543935
Validation loss: 2.4136980419287504

Epoch: 6| Step: 6
Training loss: 0.5152245035447783
Validation loss: 2.3842997906318346

Epoch: 6| Step: 7
Training loss: 0.6111168054353923
Validation loss: 2.3943117482715883

Epoch: 6| Step: 8
Training loss: 0.5980998119842509
Validation loss: 2.410121069513585

Epoch: 6| Step: 9
Training loss: 0.5553142606399266
Validation loss: 2.406662944832523

Epoch: 6| Step: 10
Training loss: 0.5162596697975445
Validation loss: 2.411949485277867

Epoch: 6| Step: 11
Training loss: 0.5851600320894991
Validation loss: 2.3812053045879242

Epoch: 6| Step: 12
Training loss: 0.5848629571694346
Validation loss: 2.3947524262495334

Epoch: 6| Step: 13
Training loss: 0.8762508715572186
Validation loss: 2.428745323051969

Epoch: 243| Step: 0
Training loss: 0.7607485338761678
Validation loss: 2.3906046118320288

Epoch: 6| Step: 1
Training loss: 0.927383838484444
Validation loss: 2.4064485393174526

Epoch: 6| Step: 2
Training loss: 0.5642264944055818
Validation loss: 2.419323283847681

Epoch: 6| Step: 3
Training loss: 0.6216162397226469
Validation loss: 2.4093500295559434

Epoch: 6| Step: 4
Training loss: 0.5287175122103442
Validation loss: 2.4059809180185887

Epoch: 6| Step: 5
Training loss: 0.5004032118537185
Validation loss: 2.421872283796414

Epoch: 6| Step: 6
Training loss: 0.8754736095418187
Validation loss: 2.3863294114136253

Epoch: 6| Step: 7
Training loss: 0.4691015832364004
Validation loss: 2.41428698125132

Epoch: 6| Step: 8
Training loss: 0.5726685391261509
Validation loss: 2.4030766678111384

Epoch: 6| Step: 9
Training loss: 0.7716663001233323
Validation loss: 2.3875410099090613

Epoch: 6| Step: 10
Training loss: 0.305898168449493
Validation loss: 2.420490708960539

Epoch: 6| Step: 11
Training loss: 0.3725274349196815
Validation loss: 2.3993589685979244

Epoch: 6| Step: 12
Training loss: 0.32738839074969434
Validation loss: 2.380260940228541

Epoch: 6| Step: 13
Training loss: 1.1345659037547218
Validation loss: 2.392025496528151

Epoch: 244| Step: 0
Training loss: 0.713915696694217
Validation loss: 2.375698766151808

Epoch: 6| Step: 1
Training loss: 0.9572047485032923
Validation loss: 2.3733507115890657

Epoch: 6| Step: 2
Training loss: 0.5259004692962664
Validation loss: 2.3444940645195262

Epoch: 6| Step: 3
Training loss: 0.2840500893310503
Validation loss: 2.3522020437223774

Epoch: 6| Step: 4
Training loss: 0.6694790458135009
Validation loss: 2.4024692382905566

Epoch: 6| Step: 5
Training loss: 0.6013903681223206
Validation loss: 2.366592214872894

Epoch: 6| Step: 6
Training loss: 0.5911974751326288
Validation loss: 2.429499465065163

Epoch: 6| Step: 7
Training loss: 0.9679534467545035
Validation loss: 2.4381545949288697

Epoch: 6| Step: 8
Training loss: 0.4841025724625947
Validation loss: 2.4411054995788315

Epoch: 6| Step: 9
Training loss: 0.5429189645460464
Validation loss: 2.4669146911506115

Epoch: 6| Step: 10
Training loss: 0.333008103356556
Validation loss: 2.471712104119115

Epoch: 6| Step: 11
Training loss: 0.917149084479187
Validation loss: 2.4315133273765395

Epoch: 6| Step: 12
Training loss: 0.4318710161072281
Validation loss: 2.4375379447413112

Epoch: 6| Step: 13
Training loss: 0.8091580545718138
Validation loss: 2.419763341652824

Epoch: 245| Step: 0
Training loss: 0.4977493743959612
Validation loss: 2.4335927055157938

Epoch: 6| Step: 1
Training loss: 0.5243428499825762
Validation loss: 2.4369627552717565

Epoch: 6| Step: 2
Training loss: 0.6399650896505016
Validation loss: 2.4014000568553158

Epoch: 6| Step: 3
Training loss: 0.460603010721591
Validation loss: 2.40012691463034

Epoch: 6| Step: 4
Training loss: 0.5459220758277954
Validation loss: 2.419419418331017

Epoch: 6| Step: 5
Training loss: 0.4443348308172173
Validation loss: 2.4538105307966354

Epoch: 6| Step: 6
Training loss: 0.6557050894957
Validation loss: 2.4172245996858437

Epoch: 6| Step: 7
Training loss: 1.0413997435312852
Validation loss: 2.4530506257309055

Epoch: 6| Step: 8
Training loss: 0.5014967866435225
Validation loss: 2.4355928207960758

Epoch: 6| Step: 9
Training loss: 0.5270700097441873
Validation loss: 2.4311242280854817

Epoch: 6| Step: 10
Training loss: 0.6328679284204175
Validation loss: 2.47170688288782

Epoch: 6| Step: 11
Training loss: 0.9273527304030535
Validation loss: 2.43754671092537

Epoch: 6| Step: 12
Training loss: 0.5643195023819941
Validation loss: 2.430512961929033

Epoch: 6| Step: 13
Training loss: 0.8924997241022448
Validation loss: 2.394657725798573

Epoch: 246| Step: 0
Training loss: 0.5651832531085339
Validation loss: 2.4113400081936827

Epoch: 6| Step: 1
Training loss: 0.5920645231318894
Validation loss: 2.3861274790430973

Epoch: 6| Step: 2
Training loss: 0.42379486375372327
Validation loss: 2.390437248074871

Epoch: 6| Step: 3
Training loss: 0.9982692523019793
Validation loss: 2.358290493338815

Epoch: 6| Step: 4
Training loss: 0.3508377021274398
Validation loss: 2.3886208457393785

Epoch: 6| Step: 5
Training loss: 0.635715466478332
Validation loss: 2.413723096714332

Epoch: 6| Step: 6
Training loss: 0.5655447887219341
Validation loss: 2.384125510874804

Epoch: 6| Step: 7
Training loss: 0.7352829048760361
Validation loss: 2.421945008408263

Epoch: 6| Step: 8
Training loss: 0.6124373540176419
Validation loss: 2.4533437329998575

Epoch: 6| Step: 9
Training loss: 0.7087422948078688
Validation loss: 2.450856725807312

Epoch: 6| Step: 10
Training loss: 0.29852706104567317
Validation loss: 2.4257958828368147

Epoch: 6| Step: 11
Training loss: 0.8659240178655929
Validation loss: 2.4479120160654086

Epoch: 6| Step: 12
Training loss: 0.6549994952076139
Validation loss: 2.4482822631313548

Epoch: 6| Step: 13
Training loss: 0.1312277860235265
Validation loss: 2.4516486574538527

Epoch: 247| Step: 0
Training loss: 0.4665716417953869
Validation loss: 2.4563892822971227

Epoch: 6| Step: 1
Training loss: 0.4379466705799337
Validation loss: 2.4255079846323446

Epoch: 6| Step: 2
Training loss: 0.780363800965681
Validation loss: 2.4295930427618675

Epoch: 6| Step: 3
Training loss: 0.6886213434454309
Validation loss: 2.423007759723242

Epoch: 6| Step: 4
Training loss: 0.5748417906171747
Validation loss: 2.438949835310852

Epoch: 6| Step: 5
Training loss: 0.5400658268013214
Validation loss: 2.4263251430720474

Epoch: 6| Step: 6
Training loss: 0.31123562375537317
Validation loss: 2.4005205171056536

Epoch: 6| Step: 7
Training loss: 0.6621848544418537
Validation loss: 2.3888987512934214

Epoch: 6| Step: 8
Training loss: 0.8409588530178065
Validation loss: 2.432178336486045

Epoch: 6| Step: 9
Training loss: 0.6681262717310736
Validation loss: 2.4074654334824626

Epoch: 6| Step: 10
Training loss: 0.5743304812142256
Validation loss: 2.433736934375986

Epoch: 6| Step: 11
Training loss: 0.9188313753070401
Validation loss: 2.38683956696999

Epoch: 6| Step: 12
Training loss: 0.24121116143961407
Validation loss: 2.3908098484343117

Epoch: 6| Step: 13
Training loss: 0.3650071360269357
Validation loss: 2.406768991099247

Epoch: 248| Step: 0
Training loss: 0.8794812843278885
Validation loss: 2.3976434797083237

Epoch: 6| Step: 1
Training loss: 0.5845059518405
Validation loss: 2.4072608332120695

Epoch: 6| Step: 2
Training loss: 0.49617868732622417
Validation loss: 2.4174685221116246

Epoch: 6| Step: 3
Training loss: 0.5608959905200542
Validation loss: 2.4199972229289677

Epoch: 6| Step: 4
Training loss: 0.6184988938015642
Validation loss: 2.4450514359604973

Epoch: 6| Step: 5
Training loss: 0.5863947038253268
Validation loss: 2.472593383062447

Epoch: 6| Step: 6
Training loss: 0.573114228142168
Validation loss: 2.426656182036704

Epoch: 6| Step: 7
Training loss: 0.6419849846798225
Validation loss: 2.4405324986371117

Epoch: 6| Step: 8
Training loss: 0.5581839598882048
Validation loss: 2.425707498461368

Epoch: 6| Step: 9
Training loss: 0.3488566857891797
Validation loss: 2.4410439725119897

Epoch: 6| Step: 10
Training loss: 0.20400599017067247
Validation loss: 2.4360642276154034

Epoch: 6| Step: 11
Training loss: 0.470908693876715
Validation loss: 2.42871558933126

Epoch: 6| Step: 12
Training loss: 0.7761843676010486
Validation loss: 2.42993957005429

Epoch: 6| Step: 13
Training loss: 1.1032924190053681
Validation loss: 2.4158100408742613

Epoch: 249| Step: 0
Training loss: 0.954191955220186
Validation loss: 2.3833306507526046

Epoch: 6| Step: 1
Training loss: 0.7176355761526264
Validation loss: 2.396238467367475

Epoch: 6| Step: 2
Training loss: 0.6449751048125952
Validation loss: 2.3760550206033146

Epoch: 6| Step: 3
Training loss: 0.3479938689348123
Validation loss: 2.3807130825335663

Epoch: 6| Step: 4
Training loss: 0.5357240045892043
Validation loss: 2.3723476000634736

Epoch: 6| Step: 5
Training loss: 0.802827815722363
Validation loss: 2.3680817390479265

Epoch: 6| Step: 6
Training loss: 0.5600586469628626
Validation loss: 2.344512421670072

Epoch: 6| Step: 7
Training loss: 0.6874409346783864
Validation loss: 2.411894734051762

Epoch: 6| Step: 8
Training loss: 0.7208903413254395
Validation loss: 2.4137496498617335

Epoch: 6| Step: 9
Training loss: 0.6159330246141981
Validation loss: 2.4395337135944266

Epoch: 6| Step: 10
Training loss: 0.24472169011190845
Validation loss: 2.45460644617127

Epoch: 6| Step: 11
Training loss: 0.640660261718908
Validation loss: 2.4537786832013766

Epoch: 6| Step: 12
Training loss: 0.3281815797979757
Validation loss: 2.421927155598984

Epoch: 6| Step: 13
Training loss: 0.5156523668367102
Validation loss: 2.4360807287193422

Epoch: 250| Step: 0
Training loss: 0.5741178722391783
Validation loss: 2.413742660710383

Epoch: 6| Step: 1
Training loss: 0.644137545474749
Validation loss: 2.4140142270104366

Epoch: 6| Step: 2
Training loss: 0.6007527437627637
Validation loss: 2.3969434113042274

Epoch: 6| Step: 3
Training loss: 0.5919557867938084
Validation loss: 2.343590517804945

Epoch: 6| Step: 4
Training loss: 0.5551279226860514
Validation loss: 2.374288667240946

Epoch: 6| Step: 5
Training loss: 0.4501361435673708
Validation loss: 2.375666079680712

Epoch: 6| Step: 6
Training loss: 0.6371303702239061
Validation loss: 2.36405418920534

Epoch: 6| Step: 7
Training loss: 1.057611100874106
Validation loss: 2.3845097616687805

Epoch: 6| Step: 8
Training loss: 0.6088552214453191
Validation loss: 2.3750423131864036

Epoch: 6| Step: 9
Training loss: 0.6773529738487853
Validation loss: 2.403667903983645

Epoch: 6| Step: 10
Training loss: 0.5673610663391286
Validation loss: 2.3931601118256314

Epoch: 6| Step: 11
Training loss: 0.6907391967259978
Validation loss: 2.391305274266862

Epoch: 6| Step: 12
Training loss: 0.30192815423239994
Validation loss: 2.4020107019418666

Epoch: 6| Step: 13
Training loss: 0.4997092534161768
Validation loss: 2.3744039240868395

Epoch: 251| Step: 0
Training loss: 0.4560370431627603
Validation loss: 2.384598077064769

Epoch: 6| Step: 1
Training loss: 0.842667238123867
Validation loss: 2.3963314364323804

Epoch: 6| Step: 2
Training loss: 0.5756275774207383
Validation loss: 2.4177909922373764

Epoch: 6| Step: 3
Training loss: 0.8475841016872505
Validation loss: 2.397676587224623

Epoch: 6| Step: 4
Training loss: 0.6714526556755178
Validation loss: 2.4041161165375415

Epoch: 6| Step: 5
Training loss: 0.2871849064507498
Validation loss: 2.4128386724635136

Epoch: 6| Step: 6
Training loss: 0.5651716523079466
Validation loss: 2.37994534604584

Epoch: 6| Step: 7
Training loss: 0.5913732290182968
Validation loss: 2.3907631551259003

Epoch: 6| Step: 8
Training loss: 0.586215525469566
Validation loss: 2.420928991022416

Epoch: 6| Step: 9
Training loss: 0.5705042999901232
Validation loss: 2.4231614564096384

Epoch: 6| Step: 10
Training loss: 0.46627740406162954
Validation loss: 2.4102520773641767

Epoch: 6| Step: 11
Training loss: 0.7317759195786779
Validation loss: 2.4081607456222702

Epoch: 6| Step: 12
Training loss: 0.6259069537947751
Validation loss: 2.3863982990192403

Epoch: 6| Step: 13
Training loss: 0.2586576740050099
Validation loss: 2.3962089561565882

Epoch: 252| Step: 0
Training loss: 0.574766274301863
Validation loss: 2.4071192594278306

Epoch: 6| Step: 1
Training loss: 0.7741825869031638
Validation loss: 2.4018689158272926

Epoch: 6| Step: 2
Training loss: 0.33105496881973784
Validation loss: 2.4239971177369535

Epoch: 6| Step: 3
Training loss: 0.8915348424943749
Validation loss: 2.419806877619805

Epoch: 6| Step: 4
Training loss: 0.6185495099934161
Validation loss: 2.3974056607690817

Epoch: 6| Step: 5
Training loss: 0.43446811803126856
Validation loss: 2.454835952271166

Epoch: 6| Step: 6
Training loss: 0.47763522375446493
Validation loss: 2.418805152870739

Epoch: 6| Step: 7
Training loss: 0.5523594369778473
Validation loss: 2.4025770926266143

Epoch: 6| Step: 8
Training loss: 0.6208678500503184
Validation loss: 2.414166837554043

Epoch: 6| Step: 9
Training loss: 0.5016880151677816
Validation loss: 2.4112835481464625

Epoch: 6| Step: 10
Training loss: 0.6157859630544706
Validation loss: 2.372759726904925

Epoch: 6| Step: 11
Training loss: 0.7106261357522308
Validation loss: 2.422126074779

Epoch: 6| Step: 12
Training loss: 0.5499481501848089
Validation loss: 2.4043287723924087

Epoch: 6| Step: 13
Training loss: 0.4865066782707636
Validation loss: 2.3696047570695584

Epoch: 253| Step: 0
Training loss: 0.5276952066858389
Validation loss: 2.4127056735715273

Epoch: 6| Step: 1
Training loss: 0.6066639086989009
Validation loss: 2.4123156395545022

Epoch: 6| Step: 2
Training loss: 0.34043263244230554
Validation loss: 2.3886603826178736

Epoch: 6| Step: 3
Training loss: 0.2836559096171787
Validation loss: 2.3907365777603453

Epoch: 6| Step: 4
Training loss: 0.642858473080061
Validation loss: 2.3840083991235725

Epoch: 6| Step: 5
Training loss: 0.5800714717188022
Validation loss: 2.3645189854843958

Epoch: 6| Step: 6
Training loss: 0.458342066233697
Validation loss: 2.349028271410034

Epoch: 6| Step: 7
Training loss: 0.30136027893731476
Validation loss: 2.3661590457127253

Epoch: 6| Step: 8
Training loss: 0.5774033656332394
Validation loss: 2.367327649932441

Epoch: 6| Step: 9
Training loss: 0.5327566324516609
Validation loss: 2.3660875037127918

Epoch: 6| Step: 10
Training loss: 0.6713775745115917
Validation loss: 2.3826242916902864

Epoch: 6| Step: 11
Training loss: 0.8765986688397079
Validation loss: 2.361047537798515

Epoch: 6| Step: 12
Training loss: 0.6321084143989986
Validation loss: 2.3785533154573173

Epoch: 6| Step: 13
Training loss: 1.099881506086326
Validation loss: 2.3825492252154556

Epoch: 254| Step: 0
Training loss: 0.30191465579367105
Validation loss: 2.4029229213722436

Epoch: 6| Step: 1
Training loss: 0.5350795050397296
Validation loss: 2.3829919148718677

Epoch: 6| Step: 2
Training loss: 0.3626790130847593
Validation loss: 2.3882495397865418

Epoch: 6| Step: 3
Training loss: 0.4209241217545434
Validation loss: 2.349187417457071

Epoch: 6| Step: 4
Training loss: 0.3979843217778482
Validation loss: 2.3601377640002146

Epoch: 6| Step: 5
Training loss: 1.1068143708884632
Validation loss: 2.364648565907075

Epoch: 6| Step: 6
Training loss: 0.787420850136763
Validation loss: 2.3906262251853283

Epoch: 6| Step: 7
Training loss: 0.55552829900742
Validation loss: 2.3988283808908135

Epoch: 6| Step: 8
Training loss: 0.6027352185345407
Validation loss: 2.39746021410838

Epoch: 6| Step: 9
Training loss: 0.7157726402073006
Validation loss: 2.4039940243495344

Epoch: 6| Step: 10
Training loss: 0.6672395886852048
Validation loss: 2.3906902572686963

Epoch: 6| Step: 11
Training loss: 0.5693756142036148
Validation loss: 2.3983967988616923

Epoch: 6| Step: 12
Training loss: 0.39968530822821047
Validation loss: 2.3693017924980135

Epoch: 6| Step: 13
Training loss: 0.6716419081782719
Validation loss: 2.377712915286768

Epoch: 255| Step: 0
Training loss: 0.38144898381104736
Validation loss: 2.3586240172364508

Epoch: 6| Step: 1
Training loss: 0.7350030202219666
Validation loss: 2.391863524699089

Epoch: 6| Step: 2
Training loss: 0.651143116993889
Validation loss: 2.407143843259469

Epoch: 6| Step: 3
Training loss: 0.5168894955079688
Validation loss: 2.3944546435455942

Epoch: 6| Step: 4
Training loss: 0.8250669481105403
Validation loss: 2.4315214977034687

Epoch: 6| Step: 5
Training loss: 0.5453446365112283
Validation loss: 2.4598184468820827

Epoch: 6| Step: 6
Training loss: 0.5620220060757546
Validation loss: 2.449186931668444

Epoch: 6| Step: 7
Training loss: 0.6085543363881005
Validation loss: 2.44763410967025

Epoch: 6| Step: 8
Training loss: 0.4062460569043635
Validation loss: 2.4593933360172042

Epoch: 6| Step: 9
Training loss: 0.5583303937787158
Validation loss: 2.4362082054514733

Epoch: 6| Step: 10
Training loss: 0.622449247443766
Validation loss: 2.430403332365145

Epoch: 6| Step: 11
Training loss: 0.24928763343468133
Validation loss: 2.414715243884742

Epoch: 6| Step: 12
Training loss: 0.6068712541600135
Validation loss: 2.439448465269785

Epoch: 6| Step: 13
Training loss: 0.6346508685330933
Validation loss: 2.4472224507666516

Epoch: 256| Step: 0
Training loss: 0.4231804852471183
Validation loss: 2.429412757679756

Epoch: 6| Step: 1
Training loss: 0.6361399635238606
Validation loss: 2.4491291953825427

Epoch: 6| Step: 2
Training loss: 0.5494972846733809
Validation loss: 2.45122855182669

Epoch: 6| Step: 3
Training loss: 0.5609796959777746
Validation loss: 2.4447209678258006

Epoch: 6| Step: 4
Training loss: 0.5934892382975757
Validation loss: 2.4576461384909423

Epoch: 6| Step: 5
Training loss: 0.5235051638012423
Validation loss: 2.4472410272825837

Epoch: 6| Step: 6
Training loss: 0.5569372357271629
Validation loss: 2.446678183104541

Epoch: 6| Step: 7
Training loss: 0.6845295849056929
Validation loss: 2.460565472550946

Epoch: 6| Step: 8
Training loss: 0.6120160409626527
Validation loss: 2.485280687110625

Epoch: 6| Step: 9
Training loss: 0.4083793113896592
Validation loss: 2.402835991137439

Epoch: 6| Step: 10
Training loss: 0.8408435282232513
Validation loss: 2.4162629288482615

Epoch: 6| Step: 11
Training loss: 0.31395525643288663
Validation loss: 2.3814885321522534

Epoch: 6| Step: 12
Training loss: 0.6558482893369862
Validation loss: 2.364636665130581

Epoch: 6| Step: 13
Training loss: 0.4283241838870798
Validation loss: 2.397083220118825

Epoch: 257| Step: 0
Training loss: 0.47612119785231866
Validation loss: 2.3587621436036437

Epoch: 6| Step: 1
Training loss: 0.44242954638871385
Validation loss: 2.3592184506918823

Epoch: 6| Step: 2
Training loss: 0.523338564732194
Validation loss: 2.3497471928242146

Epoch: 6| Step: 3
Training loss: 0.7156222330897783
Validation loss: 2.3845643514754475

Epoch: 6| Step: 4
Training loss: 0.4923766847355519
Validation loss: 2.397987771686355

Epoch: 6| Step: 5
Training loss: 0.5796155787268484
Validation loss: 2.3997621247033534

Epoch: 6| Step: 6
Training loss: 0.8510210258069474
Validation loss: 2.4158400825298934

Epoch: 6| Step: 7
Training loss: 0.6912296306651052
Validation loss: 2.4467837670472923

Epoch: 6| Step: 8
Training loss: 0.5459477329004797
Validation loss: 2.394586205527269

Epoch: 6| Step: 9
Training loss: 0.5169049185381775
Validation loss: 2.4005061904871114

Epoch: 6| Step: 10
Training loss: 0.5555372579528352
Validation loss: 2.4216425916164996

Epoch: 6| Step: 11
Training loss: 0.3757259574071291
Validation loss: 2.4256990440706323

Epoch: 6| Step: 12
Training loss: 0.5531807434958943
Validation loss: 2.420975931134664

Epoch: 6| Step: 13
Training loss: 0.24036238136536556
Validation loss: 2.4459016633960573

Epoch: 258| Step: 0
Training loss: 0.4644851744095655
Validation loss: 2.4077357252179348

Epoch: 6| Step: 1
Training loss: 0.5554413307172023
Validation loss: 2.4238610849395914

Epoch: 6| Step: 2
Training loss: 0.9264740102368156
Validation loss: 2.4684371511175063

Epoch: 6| Step: 3
Training loss: 0.43888725299402903
Validation loss: 2.439677925392079

Epoch: 6| Step: 4
Training loss: 0.6880127988389984
Validation loss: 2.4349463943163756

Epoch: 6| Step: 5
Training loss: 0.48824661132019387
Validation loss: 2.4454487470369917

Epoch: 6| Step: 6
Training loss: 0.546115129349755
Validation loss: 2.464705930026795

Epoch: 6| Step: 7
Training loss: 0.45337903366839727
Validation loss: 2.4788243267747103

Epoch: 6| Step: 8
Training loss: 0.382740695213621
Validation loss: 2.4588376635573663

Epoch: 6| Step: 9
Training loss: 0.5376040590824857
Validation loss: 2.408726486285501

Epoch: 6| Step: 10
Training loss: 0.3143183022291795
Validation loss: 2.415956214192024

Epoch: 6| Step: 11
Training loss: 0.7010297285842354
Validation loss: 2.4108386162467745

Epoch: 6| Step: 12
Training loss: 0.6079749628169671
Validation loss: 2.4125848486264343

Epoch: 6| Step: 13
Training loss: 0.42811452616110457
Validation loss: 2.4315983552104967

Epoch: 259| Step: 0
Training loss: 0.7008172841413562
Validation loss: 2.370310751935106

Epoch: 6| Step: 1
Training loss: 0.4704485952975238
Validation loss: 2.3760580729462264

Epoch: 6| Step: 2
Training loss: 0.5753706970700365
Validation loss: 2.3785198021779843

Epoch: 6| Step: 3
Training loss: 0.4195989742350154
Validation loss: 2.3677805631432904

Epoch: 6| Step: 4
Training loss: 0.6409925243950491
Validation loss: 2.376565124993966

Epoch: 6| Step: 5
Training loss: 0.4259203412412391
Validation loss: 2.3884449020212033

Epoch: 6| Step: 6
Training loss: 0.5354813194079753
Validation loss: 2.3846437762511323

Epoch: 6| Step: 7
Training loss: 0.5094685766938959
Validation loss: 2.4017328896485304

Epoch: 6| Step: 8
Training loss: 0.5046754333659769
Validation loss: 2.4251281716249475

Epoch: 6| Step: 9
Training loss: 0.7676619855191674
Validation loss: 2.434497732314562

Epoch: 6| Step: 10
Training loss: 0.45208360771604494
Validation loss: 2.4449645629042034

Epoch: 6| Step: 11
Training loss: 0.7572079242717858
Validation loss: 2.430672841872864

Epoch: 6| Step: 12
Training loss: 0.42470547624708144
Validation loss: 2.442280091850693

Epoch: 6| Step: 13
Training loss: 0.44475150325300233
Validation loss: 2.4465220803878127

Epoch: 260| Step: 0
Training loss: 0.4412691190267963
Validation loss: 2.4222729872282582

Epoch: 6| Step: 1
Training loss: 0.5674020891969316
Validation loss: 2.411465012787324

Epoch: 6| Step: 2
Training loss: 0.4831567950229915
Validation loss: 2.426620748448987

Epoch: 6| Step: 3
Training loss: 0.7239422876423175
Validation loss: 2.384491065211275

Epoch: 6| Step: 4
Training loss: 0.5888872285535587
Validation loss: 2.4053515600269013

Epoch: 6| Step: 5
Training loss: 0.2086157176419514
Validation loss: 2.405729461522064

Epoch: 6| Step: 6
Training loss: 0.3453568917648467
Validation loss: 2.3978013414857986

Epoch: 6| Step: 7
Training loss: 0.8305338965887386
Validation loss: 2.4111962165444343

Epoch: 6| Step: 8
Training loss: 0.43739639485992315
Validation loss: 2.389407444150832

Epoch: 6| Step: 9
Training loss: 0.5826163199530501
Validation loss: 2.3978328281313788

Epoch: 6| Step: 10
Training loss: 0.5596790041723329
Validation loss: 2.447405152997226

Epoch: 6| Step: 11
Training loss: 0.6428439857067462
Validation loss: 2.4259703973946776

Epoch: 6| Step: 12
Training loss: 0.4379536286491724
Validation loss: 2.4741532250382696

Epoch: 6| Step: 13
Training loss: 0.5027944438530225
Validation loss: 2.4342828859686545

Epoch: 261| Step: 0
Training loss: 0.677765243662784
Validation loss: 2.4361783649794786

Epoch: 6| Step: 1
Training loss: 0.3621110630098934
Validation loss: 2.455004823346336

Epoch: 6| Step: 2
Training loss: 0.4938489331950628
Validation loss: 2.443203286358889

Epoch: 6| Step: 3
Training loss: 0.8402934090462632
Validation loss: 2.420258337657163

Epoch: 6| Step: 4
Training loss: 0.5121656315657863
Validation loss: 2.3725630623122904

Epoch: 6| Step: 5
Training loss: 0.3025592789812426
Validation loss: 2.3894251751443685

Epoch: 6| Step: 6
Training loss: 0.40115020158532744
Validation loss: 2.3617120544660644

Epoch: 6| Step: 7
Training loss: 0.3420517978970034
Validation loss: 2.395281852251736

Epoch: 6| Step: 8
Training loss: 0.5769283953140336
Validation loss: 2.3785033495809578

Epoch: 6| Step: 9
Training loss: 0.5037549405293481
Validation loss: 2.3964343529391554

Epoch: 6| Step: 10
Training loss: 0.7332393712477464
Validation loss: 2.4353503668261025

Epoch: 6| Step: 11
Training loss: 0.5781319849777965
Validation loss: 2.435102213944788

Epoch: 6| Step: 12
Training loss: 0.5017587307587117
Validation loss: 2.454424208703045

Epoch: 6| Step: 13
Training loss: 0.798260587438661
Validation loss: 2.476859124151181

Epoch: 262| Step: 0
Training loss: 0.3790819606204087
Validation loss: 2.462839374879302

Epoch: 6| Step: 1
Training loss: 0.7179791836815836
Validation loss: 2.4457000925328396

Epoch: 6| Step: 2
Training loss: 0.6441716202310619
Validation loss: 2.431679615285212

Epoch: 6| Step: 3
Training loss: 0.6500402199699513
Validation loss: 2.422094440872473

Epoch: 6| Step: 4
Training loss: 0.4701405245634945
Validation loss: 2.442683927265099

Epoch: 6| Step: 5
Training loss: 0.4764747851586194
Validation loss: 2.4053998302100283

Epoch: 6| Step: 6
Training loss: 0.24959445634175761
Validation loss: 2.425661170955423

Epoch: 6| Step: 7
Training loss: 0.3555455177329839
Validation loss: 2.4450227854831454

Epoch: 6| Step: 8
Training loss: 0.386449604587054
Validation loss: 2.455259543094396

Epoch: 6| Step: 9
Training loss: 0.7889825006098777
Validation loss: 2.4543873496663964

Epoch: 6| Step: 10
Training loss: 0.7125262021383305
Validation loss: 2.452764037923083

Epoch: 6| Step: 11
Training loss: 0.4959413489593197
Validation loss: 2.456802211153444

Epoch: 6| Step: 12
Training loss: 0.41001897058560816
Validation loss: 2.484015313562057

Epoch: 6| Step: 13
Training loss: 0.5888397817734585
Validation loss: 2.4466550265134748

Epoch: 263| Step: 0
Training loss: 0.4850059522184884
Validation loss: 2.3936124255050104

Epoch: 6| Step: 1
Training loss: 0.5677017392350084
Validation loss: 2.401375596777029

Epoch: 6| Step: 2
Training loss: 0.4132427341851692
Validation loss: 2.399040208167887

Epoch: 6| Step: 3
Training loss: 0.4582087029445224
Validation loss: 2.3965702097173547

Epoch: 6| Step: 4
Training loss: 0.3453233540240222
Validation loss: 2.39151394095484

Epoch: 6| Step: 5
Training loss: 0.42768298672161226
Validation loss: 2.395081078205582

Epoch: 6| Step: 6
Training loss: 0.7917442451077589
Validation loss: 2.3931021732942632

Epoch: 6| Step: 7
Training loss: 0.4389397907851825
Validation loss: 2.424735935246451

Epoch: 6| Step: 8
Training loss: 0.40143259819514815
Validation loss: 2.368580471717862

Epoch: 6| Step: 9
Training loss: 0.4604332800783512
Validation loss: 2.434541998850612

Epoch: 6| Step: 10
Training loss: 0.44547071490595364
Validation loss: 2.4227619982806377

Epoch: 6| Step: 11
Training loss: 0.5033211083011753
Validation loss: 2.4479492736892876

Epoch: 6| Step: 12
Training loss: 0.8533600200513388
Validation loss: 2.460440961882047

Epoch: 6| Step: 13
Training loss: 0.6262423803433177
Validation loss: 2.4598861977583937

Epoch: 264| Step: 0
Training loss: 0.7800867957949896
Validation loss: 2.4339173383830905

Epoch: 6| Step: 1
Training loss: 0.5085893118059671
Validation loss: 2.4666752350593795

Epoch: 6| Step: 2
Training loss: 0.5821817702678452
Validation loss: 2.482843570048495

Epoch: 6| Step: 3
Training loss: 0.2896307694852828
Validation loss: 2.4753070119245884

Epoch: 6| Step: 4
Training loss: 0.3971533182414004
Validation loss: 2.430206301999026

Epoch: 6| Step: 5
Training loss: 0.6451245900259801
Validation loss: 2.4202602744814077

Epoch: 6| Step: 6
Training loss: 0.43784163964154815
Validation loss: 2.3986374704639726

Epoch: 6| Step: 7
Training loss: 0.5915296095839898
Validation loss: 2.415326098488255

Epoch: 6| Step: 8
Training loss: 0.567555701593254
Validation loss: 2.41689485597782

Epoch: 6| Step: 9
Training loss: 0.6739335129740287
Validation loss: 2.4152219346733594

Epoch: 6| Step: 10
Training loss: 0.3607766763323711
Validation loss: 2.425009746424096

Epoch: 6| Step: 11
Training loss: 0.4059887192549532
Validation loss: 2.417254171963244

Epoch: 6| Step: 12
Training loss: 0.6934193330012167
Validation loss: 2.429616812524572

Epoch: 6| Step: 13
Training loss: 0.22797188911603708
Validation loss: 2.4131839158432524

Epoch: 265| Step: 0
Training loss: 0.6289036910674357
Validation loss: 2.432998665847009

Epoch: 6| Step: 1
Training loss: 0.5058897738362526
Validation loss: 2.442757536721439

Epoch: 6| Step: 2
Training loss: 0.43407847828907486
Validation loss: 2.434194474841339

Epoch: 6| Step: 3
Training loss: 0.2377455270428678
Validation loss: 2.406360561354258

Epoch: 6| Step: 4
Training loss: 0.7669563007240415
Validation loss: 2.422935873260976

Epoch: 6| Step: 5
Training loss: 0.5732117211013281
Validation loss: 2.4333633389886677

Epoch: 6| Step: 6
Training loss: 0.5518996334950453
Validation loss: 2.4262900237458638

Epoch: 6| Step: 7
Training loss: 0.33731155167637716
Validation loss: 2.4059006909280596

Epoch: 6| Step: 8
Training loss: 0.43500592975849933
Validation loss: 2.4499326623431945

Epoch: 6| Step: 9
Training loss: 0.767312156665362
Validation loss: 2.408943421434968

Epoch: 6| Step: 10
Training loss: 0.5444339769302183
Validation loss: 2.4190819159424324

Epoch: 6| Step: 11
Training loss: 0.4960417832918229
Validation loss: 2.436077672655975

Epoch: 6| Step: 12
Training loss: 0.3658179246913132
Validation loss: 2.432637084316279

Epoch: 6| Step: 13
Training loss: 0.541789908938466
Validation loss: 2.4395813439578973

Epoch: 266| Step: 0
Training loss: 0.4657883863084767
Validation loss: 2.4464523456448295

Epoch: 6| Step: 1
Training loss: 0.6859793100670771
Validation loss: 2.412737308914818

Epoch: 6| Step: 2
Training loss: 0.28251158369840756
Validation loss: 2.3761510925376177

Epoch: 6| Step: 3
Training loss: 0.488045597431971
Validation loss: 2.384985903187927

Epoch: 6| Step: 4
Training loss: 0.5655350924530664
Validation loss: 2.3994376983781263

Epoch: 6| Step: 5
Training loss: 0.45907776876652395
Validation loss: 2.3960630787341284

Epoch: 6| Step: 6
Training loss: 0.5028263615510644
Validation loss: 2.449441625834518

Epoch: 6| Step: 7
Training loss: 0.6598527650897033
Validation loss: 2.4242966288461782

Epoch: 6| Step: 8
Training loss: 0.5410146334532318
Validation loss: 2.4380804895184705

Epoch: 6| Step: 9
Training loss: 0.5929174106974792
Validation loss: 2.4300273837831248

Epoch: 6| Step: 10
Training loss: 0.636304334332759
Validation loss: 2.421951459986977

Epoch: 6| Step: 11
Training loss: 0.35898984089240277
Validation loss: 2.4371171271437304

Epoch: 6| Step: 12
Training loss: 0.3827957227494854
Validation loss: 2.481411237771229

Epoch: 6| Step: 13
Training loss: 0.5498534429963571
Validation loss: 2.455934668462055

Epoch: 267| Step: 0
Training loss: 0.8521532931594948
Validation loss: 2.4871872365448002

Epoch: 6| Step: 1
Training loss: 0.4637195231661767
Validation loss: 2.4720262973926603

Epoch: 6| Step: 2
Training loss: 0.560315207215815
Validation loss: 2.4832023184534413

Epoch: 6| Step: 3
Training loss: 0.27667237001356365
Validation loss: 2.4444451810637426

Epoch: 6| Step: 4
Training loss: 0.45732374694265515
Validation loss: 2.451352189171305

Epoch: 6| Step: 5
Training loss: 0.374663659101652
Validation loss: 2.411570956718819

Epoch: 6| Step: 6
Training loss: 0.71203687573961
Validation loss: 2.4073535182410843

Epoch: 6| Step: 7
Training loss: 0.37591782148168745
Validation loss: 2.3586653449144452

Epoch: 6| Step: 8
Training loss: 0.4577600911318286
Validation loss: 2.3592211542712156

Epoch: 6| Step: 9
Training loss: 0.6401550849008235
Validation loss: 2.3528430567118925

Epoch: 6| Step: 10
Training loss: 0.5271362461575679
Validation loss: 2.4147730824008145

Epoch: 6| Step: 11
Training loss: 0.19240083948867243
Validation loss: 2.379820003153071

Epoch: 6| Step: 12
Training loss: 0.5182372305033409
Validation loss: 2.4338637101701472

Epoch: 6| Step: 13
Training loss: 0.5324888650419476
Validation loss: 2.4110417124517243

Epoch: 268| Step: 0
Training loss: 0.26792409207766055
Validation loss: 2.435729868861118

Epoch: 6| Step: 1
Training loss: 0.4719332532735824
Validation loss: 2.426595201398673

Epoch: 6| Step: 2
Training loss: 0.3971690950548885
Validation loss: 2.4365964886754354

Epoch: 6| Step: 3
Training loss: 0.9144401748176956
Validation loss: 2.450431258648176

Epoch: 6| Step: 4
Training loss: 0.29819686135521417
Validation loss: 2.4343475389533085

Epoch: 6| Step: 5
Training loss: 0.32942767639508846
Validation loss: 2.4428168136136983

Epoch: 6| Step: 6
Training loss: 0.5098180049717344
Validation loss: 2.418513346357842

Epoch: 6| Step: 7
Training loss: 0.37797768852321784
Validation loss: 2.424928516568709

Epoch: 6| Step: 8
Training loss: 0.49429855536917905
Validation loss: 2.4227860276432116

Epoch: 6| Step: 9
Training loss: 0.6580636983290464
Validation loss: 2.4105527592233225

Epoch: 6| Step: 10
Training loss: 0.304303979362245
Validation loss: 2.401794130614679

Epoch: 6| Step: 11
Training loss: 0.4892530916941814
Validation loss: 2.3851448166049294

Epoch: 6| Step: 12
Training loss: 0.5069508211033837
Validation loss: 2.3531193263357233

Epoch: 6| Step: 13
Training loss: 0.6529881155953838
Validation loss: 2.377509281698497

Epoch: 269| Step: 0
Training loss: 0.7409287067408006
Validation loss: 2.313934438354674

Epoch: 6| Step: 1
Training loss: 0.28859194267049876
Validation loss: 2.377888374435508

Epoch: 6| Step: 2
Training loss: 0.4813470333913379
Validation loss: 2.3540268917407814

Epoch: 6| Step: 3
Training loss: 0.5074385806909794
Validation loss: 2.350204758809839

Epoch: 6| Step: 4
Training loss: 0.29102980815964885
Validation loss: 2.3831852242645097

Epoch: 6| Step: 5
Training loss: 0.4655244795573305
Validation loss: 2.3610767946719307

Epoch: 6| Step: 6
Training loss: 0.6667182773242435
Validation loss: 2.385269985551392

Epoch: 6| Step: 7
Training loss: 0.3559115868798902
Validation loss: 2.406926006196204

Epoch: 6| Step: 8
Training loss: 0.6759512803167226
Validation loss: 2.4002211536355342

Epoch: 6| Step: 9
Training loss: 0.4337932711847521
Validation loss: 2.4259955806380313

Epoch: 6| Step: 10
Training loss: 0.6034771064391886
Validation loss: 2.4667238867668395

Epoch: 6| Step: 11
Training loss: 0.38985565717779797
Validation loss: 2.448161123231572

Epoch: 6| Step: 12
Training loss: 0.4461091094036781
Validation loss: 2.475503256271556

Epoch: 6| Step: 13
Training loss: 0.3534879726322443
Validation loss: 2.481246584696222

Epoch: 270| Step: 0
Training loss: 0.49014874200539826
Validation loss: 2.49631410648952

Epoch: 6| Step: 1
Training loss: 0.23450711023779816
Validation loss: 2.4680789467993547

Epoch: 6| Step: 2
Training loss: 0.3507116405857905
Validation loss: 2.4750343215135433

Epoch: 6| Step: 3
Training loss: 0.4782343913829947
Validation loss: 2.4507400229670746

Epoch: 6| Step: 4
Training loss: 0.5181723296724208
Validation loss: 2.439684670013778

Epoch: 6| Step: 5
Training loss: 0.2842254339672664
Validation loss: 2.414663487248488

Epoch: 6| Step: 6
Training loss: 0.5658132935188381
Validation loss: 2.3779793614128972

Epoch: 6| Step: 7
Training loss: 0.36252877022587543
Validation loss: 2.389402950761853

Epoch: 6| Step: 8
Training loss: 0.18023037794002522
Validation loss: 2.3872772095667605

Epoch: 6| Step: 9
Training loss: 0.7186377064432037
Validation loss: 2.4090078089482296

Epoch: 6| Step: 10
Training loss: 0.6337682076947936
Validation loss: 2.35475916425417

Epoch: 6| Step: 11
Training loss: 0.4509626621831727
Validation loss: 2.385899315233202

Epoch: 6| Step: 12
Training loss: 0.5767909458046311
Validation loss: 2.417956158490924

Epoch: 6| Step: 13
Training loss: 0.7867286461792043
Validation loss: 2.378091314733545

Epoch: 271| Step: 0
Training loss: 0.7606517654762549
Validation loss: 2.4113585743539194

Epoch: 6| Step: 1
Training loss: 0.5610412916042218
Validation loss: 2.428935833369268

Epoch: 6| Step: 2
Training loss: 0.5203968667029836
Validation loss: 2.438925030741905

Epoch: 6| Step: 3
Training loss: 0.5066758272269389
Validation loss: 2.413413959217074

Epoch: 6| Step: 4
Training loss: 0.3001867835397488
Validation loss: 2.4173846845407954

Epoch: 6| Step: 5
Training loss: 0.2691152098328302
Validation loss: 2.433372780777501

Epoch: 6| Step: 6
Training loss: 0.5036110715760285
Validation loss: 2.401269923002032

Epoch: 6| Step: 7
Training loss: 0.48758609879508724
Validation loss: 2.455959994350889

Epoch: 6| Step: 8
Training loss: 0.431710595721104
Validation loss: 2.4421688283161735

Epoch: 6| Step: 9
Training loss: 0.4657501071831523
Validation loss: 2.4060149209158057

Epoch: 6| Step: 10
Training loss: 0.571716409591384
Validation loss: 2.4259647226484695

Epoch: 6| Step: 11
Training loss: 0.3753102529110686
Validation loss: 2.3992792252956883

Epoch: 6| Step: 12
Training loss: 0.36213492968939054
Validation loss: 2.3933295717023295

Epoch: 6| Step: 13
Training loss: 0.2568407529662341
Validation loss: 2.416280905203895

Epoch: 272| Step: 0
Training loss: 0.2522679070268787
Validation loss: 2.4064629317637687

Epoch: 6| Step: 1
Training loss: 0.2982498257901114
Validation loss: 2.3995842682113655

Epoch: 6| Step: 2
Training loss: 0.4048262737452252
Validation loss: 2.4075773903736626

Epoch: 6| Step: 3
Training loss: 0.5473430810173404
Validation loss: 2.4257659132211744

Epoch: 6| Step: 4
Training loss: 0.38528898633011743
Validation loss: 2.446340163140945

Epoch: 6| Step: 5
Training loss: 0.3256322771676009
Validation loss: 2.429163667646763

Epoch: 6| Step: 6
Training loss: 0.3539804595548868
Validation loss: 2.4408250200684902

Epoch: 6| Step: 7
Training loss: 0.5968265883300646
Validation loss: 2.4359311486511417

Epoch: 6| Step: 8
Training loss: 0.7798208134189625
Validation loss: 2.454093304645627

Epoch: 6| Step: 9
Training loss: 0.4109135856487125
Validation loss: 2.4378377576820562

Epoch: 6| Step: 10
Training loss: 0.6689430403844853
Validation loss: 2.4388218501516508

Epoch: 6| Step: 11
Training loss: 0.2879920547874556
Validation loss: 2.427213441583983

Epoch: 6| Step: 12
Training loss: 0.42735280475403475
Validation loss: 2.4614012359889843

Epoch: 6| Step: 13
Training loss: 0.5504432073725842
Validation loss: 2.44300774506104

Epoch: 273| Step: 0
Training loss: 0.4505218182444602
Validation loss: 2.466035959842654

Epoch: 6| Step: 1
Training loss: 0.3919643519563181
Validation loss: 2.43826212615222

Epoch: 6| Step: 2
Training loss: 0.14948840566874821
Validation loss: 2.425998135828091

Epoch: 6| Step: 3
Training loss: 0.7348548457779968
Validation loss: 2.3838947804358006

Epoch: 6| Step: 4
Training loss: 0.2288114800720907
Validation loss: 2.4262276470698607

Epoch: 6| Step: 5
Training loss: 0.39968165455257715
Validation loss: 2.3788219672508957

Epoch: 6| Step: 6
Training loss: 0.513534527536204
Validation loss: 2.3777733549536864

Epoch: 6| Step: 7
Training loss: 0.5618337818510984
Validation loss: 2.356583120543586

Epoch: 6| Step: 8
Training loss: 0.5620028099858637
Validation loss: 2.3941165638800603

Epoch: 6| Step: 9
Training loss: 0.5305816709982585
Validation loss: 2.3856625736265555

Epoch: 6| Step: 10
Training loss: 0.42783605333782976
Validation loss: 2.42648474585873

Epoch: 6| Step: 11
Training loss: 0.38644684759930403
Validation loss: 2.387346847287323

Epoch: 6| Step: 12
Training loss: 0.37448971520830676
Validation loss: 2.4555160164969387

Epoch: 6| Step: 13
Training loss: 0.6197509404968167
Validation loss: 2.4318504029845096

Epoch: 274| Step: 0
Training loss: 0.4996902579302421
Validation loss: 2.439890761573625

Epoch: 6| Step: 1
Training loss: 0.7228675327222074
Validation loss: 2.4766774069213495

Epoch: 6| Step: 2
Training loss: 0.40896719283452193
Validation loss: 2.507259767618629

Epoch: 6| Step: 3
Training loss: 0.18201860457607974
Validation loss: 2.4719822717115814

Epoch: 6| Step: 4
Training loss: 0.523768562270194
Validation loss: 2.4483624045730212

Epoch: 6| Step: 5
Training loss: 0.48969397072573156
Validation loss: 2.4579500693374974

Epoch: 6| Step: 6
Training loss: 0.5252406817467106
Validation loss: 2.400366790641673

Epoch: 6| Step: 7
Training loss: 0.17050043900704567
Validation loss: 2.406509558543947

Epoch: 6| Step: 8
Training loss: 0.33331515093725067
Validation loss: 2.393536380872816

Epoch: 6| Step: 9
Training loss: 0.20233615507504993
Validation loss: 2.3879273252796316

Epoch: 6| Step: 10
Training loss: 0.6358980846140426
Validation loss: 2.384405847180371

Epoch: 6| Step: 11
Training loss: 0.2990224368566393
Validation loss: 2.3701178429806733

Epoch: 6| Step: 12
Training loss: 0.48084693849225035
Validation loss: 2.380953513085115

Epoch: 6| Step: 13
Training loss: 0.8038698505135246
Validation loss: 2.3734868836664145

Epoch: 275| Step: 0
Training loss: 0.46541206496185616
Validation loss: 2.423019707088482

Epoch: 6| Step: 1
Training loss: 0.5494472229216296
Validation loss: 2.3823034341512184

Epoch: 6| Step: 2
Training loss: 0.4857718568705397
Validation loss: 2.4250124744423847

Epoch: 6| Step: 3
Training loss: 0.3353476113657062
Validation loss: 2.394462498143223

Epoch: 6| Step: 4
Training loss: 0.3789685384932694
Validation loss: 2.4030745037739107

Epoch: 6| Step: 5
Training loss: 0.3596385528442441
Validation loss: 2.421264471981469

Epoch: 6| Step: 6
Training loss: 0.5525996175345644
Validation loss: 2.441803390917844

Epoch: 6| Step: 7
Training loss: 0.32502224185836376
Validation loss: 2.4395452847319494

Epoch: 6| Step: 8
Training loss: 0.46816786540511596
Validation loss: 2.4151512712296497

Epoch: 6| Step: 9
Training loss: 0.5160409809960667
Validation loss: 2.431958089354703

Epoch: 6| Step: 10
Training loss: 0.3781194678603354
Validation loss: 2.4248769425077796

Epoch: 6| Step: 11
Training loss: 0.7013234264262707
Validation loss: 2.413399207754246

Epoch: 6| Step: 12
Training loss: 0.23766989528951754
Validation loss: 2.4123974290708627

Epoch: 6| Step: 13
Training loss: 0.5889222987562286
Validation loss: 2.4195635469374315

Epoch: 276| Step: 0
Training loss: 0.4456326020168846
Validation loss: 2.403815957326993

Epoch: 6| Step: 1
Training loss: 0.2600798892886364
Validation loss: 2.3877261872825164

Epoch: 6| Step: 2
Training loss: 0.3727651201119949
Validation loss: 2.3744941716799857

Epoch: 6| Step: 3
Training loss: 0.3165450556958068
Validation loss: 2.405489215992171

Epoch: 6| Step: 4
Training loss: 0.48022858114301875
Validation loss: 2.3817304928011085

Epoch: 6| Step: 5
Training loss: 0.7487188761997725
Validation loss: 2.406577218154944

Epoch: 6| Step: 6
Training loss: 0.46188862510788375
Validation loss: 2.401342890427607

Epoch: 6| Step: 7
Training loss: 0.40824183595346736
Validation loss: 2.3794535615120385

Epoch: 6| Step: 8
Training loss: 0.6047459872247881
Validation loss: 2.387482085652278

Epoch: 6| Step: 9
Training loss: 0.3741992308238681
Validation loss: 2.4118766771732725

Epoch: 6| Step: 10
Training loss: 0.4811236097900968
Validation loss: 2.378473568738219

Epoch: 6| Step: 11
Training loss: 0.2548847417648788
Validation loss: 2.4025694921041643

Epoch: 6| Step: 12
Training loss: 0.3040591387352203
Validation loss: 2.3950755828817525

Epoch: 6| Step: 13
Training loss: 0.5304854445154965
Validation loss: 2.392824948244679

Epoch: 277| Step: 0
Training loss: 0.43373399476855384
Validation loss: 2.398089239124467

Epoch: 6| Step: 1
Training loss: 0.6654438685727515
Validation loss: 2.3973883156182043

Epoch: 6| Step: 2
Training loss: 0.5577743495856498
Validation loss: 2.3762136638720657

Epoch: 6| Step: 3
Training loss: 0.5568327990295958
Validation loss: 2.394151015828467

Epoch: 6| Step: 4
Training loss: 0.15595406880010487
Validation loss: 2.3846717008310128

Epoch: 6| Step: 5
Training loss: 0.5020787419574846
Validation loss: 2.425192367286766

Epoch: 6| Step: 6
Training loss: 0.23627788230313312
Validation loss: 2.406281699973413

Epoch: 6| Step: 7
Training loss: 0.46181837062534875
Validation loss: 2.4147657376387213

Epoch: 6| Step: 8
Training loss: 0.3905548414168349
Validation loss: 2.403663972663892

Epoch: 6| Step: 9
Training loss: 0.4220228642488903
Validation loss: 2.433131301467251

Epoch: 6| Step: 10
Training loss: 0.3015473752354903
Validation loss: 2.413822660085122

Epoch: 6| Step: 11
Training loss: 0.5006501024598703
Validation loss: 2.4265467128719886

Epoch: 6| Step: 12
Training loss: 0.4645202857660124
Validation loss: 2.4326735115085256

Epoch: 6| Step: 13
Training loss: 0.170815622154969
Validation loss: 2.4287156326089767

Epoch: 278| Step: 0
Training loss: 0.320412503890506
Validation loss: 2.4014300786132865

Epoch: 6| Step: 1
Training loss: 0.6487177048070218
Validation loss: 2.4309992287326567

Epoch: 6| Step: 2
Training loss: 0.5669442351349843
Validation loss: 2.4430861261067904

Epoch: 6| Step: 3
Training loss: 0.21403603007252897
Validation loss: 2.4084046274896163

Epoch: 6| Step: 4
Training loss: 0.3545326020713905
Validation loss: 2.415477972362846

Epoch: 6| Step: 5
Training loss: 0.463735686284361
Validation loss: 2.4464093173904526

Epoch: 6| Step: 6
Training loss: 0.2678452710518059
Validation loss: 2.439222858102807

Epoch: 6| Step: 7
Training loss: 0.43547488588432043
Validation loss: 2.4207505033330783

Epoch: 6| Step: 8
Training loss: 0.5539696037099546
Validation loss: 2.4398330679889346

Epoch: 6| Step: 9
Training loss: 0.4295242346186896
Validation loss: 2.4198247121700835

Epoch: 6| Step: 10
Training loss: 0.40426101156936023
Validation loss: 2.4405360005494368

Epoch: 6| Step: 11
Training loss: 0.20521858491479963
Validation loss: 2.412953566332675

Epoch: 6| Step: 12
Training loss: 0.5954340592876833
Validation loss: 2.405389441974809

Epoch: 6| Step: 13
Training loss: 0.4810149646857969
Validation loss: 2.3819433032678194

Epoch: 279| Step: 0
Training loss: 0.5882184201513055
Validation loss: 2.3998087828611565

Epoch: 6| Step: 1
Training loss: 0.23354861483643968
Validation loss: 2.391324652880233

Epoch: 6| Step: 2
Training loss: 0.24747703457739834
Validation loss: 2.3953103195940506

Epoch: 6| Step: 3
Training loss: 0.33273032028977223
Validation loss: 2.418096998143008

Epoch: 6| Step: 4
Training loss: 0.4103237173518379
Validation loss: 2.4064782956851207

Epoch: 6| Step: 5
Training loss: 0.37374943589643184
Validation loss: 2.4444309566665767

Epoch: 6| Step: 6
Training loss: 0.5648290840661454
Validation loss: 2.392149381112231

Epoch: 6| Step: 7
Training loss: 0.28778967413749396
Validation loss: 2.4251413094210816

Epoch: 6| Step: 8
Training loss: 0.474576187543293
Validation loss: 2.425135602607132

Epoch: 6| Step: 9
Training loss: 0.599962633678066
Validation loss: 2.4239997569982283

Epoch: 6| Step: 10
Training loss: 0.4731709696308795
Validation loss: 2.4091832134375104

Epoch: 6| Step: 11
Training loss: 0.5070645619692185
Validation loss: 2.3828882800794196

Epoch: 6| Step: 12
Training loss: 0.30940055404473543
Validation loss: 2.401613974774324

Epoch: 6| Step: 13
Training loss: 0.5091907577569633
Validation loss: 2.3856515497841593

Epoch: 280| Step: 0
Training loss: 0.3484952425474651
Validation loss: 2.4094132065319

Epoch: 6| Step: 1
Training loss: 0.5945891674168094
Validation loss: 2.404089631338778

Epoch: 6| Step: 2
Training loss: 0.5752864694171548
Validation loss: 2.403105243907984

Epoch: 6| Step: 3
Training loss: 0.41201947574044945
Validation loss: 2.407772157550208

Epoch: 6| Step: 4
Training loss: 0.43528876760929364
Validation loss: 2.404923601760073

Epoch: 6| Step: 5
Training loss: 0.42368672908493926
Validation loss: 2.3999863353719664

Epoch: 6| Step: 6
Training loss: 0.28183346732068915
Validation loss: 2.407776189700396

Epoch: 6| Step: 7
Training loss: 0.2790548970296365
Validation loss: 2.4033936155453275

Epoch: 6| Step: 8
Training loss: 0.5855448869769427
Validation loss: 2.372124094871307

Epoch: 6| Step: 9
Training loss: 0.3581491377653303
Validation loss: 2.3720221943791127

Epoch: 6| Step: 10
Training loss: 0.47393438432432244
Validation loss: 2.3928487923708173

Epoch: 6| Step: 11
Training loss: 0.1843351349325103
Validation loss: 2.394968131460888

Epoch: 6| Step: 12
Training loss: 0.5057510495648735
Validation loss: 2.4268772615713847

Epoch: 6| Step: 13
Training loss: 0.6367148182753417
Validation loss: 2.3890401900883433

Epoch: 281| Step: 0
Training loss: 0.5959094081232644
Validation loss: 2.40114692163839

Epoch: 6| Step: 1
Training loss: 0.3059656526122214
Validation loss: 2.419082118356141

Epoch: 6| Step: 2
Training loss: 0.47624233309764635
Validation loss: 2.429153014825934

Epoch: 6| Step: 3
Training loss: 0.48797426873517813
Validation loss: 2.424350754201941

Epoch: 6| Step: 4
Training loss: 0.30597860708908664
Validation loss: 2.416417287944799

Epoch: 6| Step: 5
Training loss: 0.4501664158614325
Validation loss: 2.4084545041856016

Epoch: 6| Step: 6
Training loss: 0.27148783290499606
Validation loss: 2.3810369308994352

Epoch: 6| Step: 7
Training loss: 0.6874559561753089
Validation loss: 2.4246669442044997

Epoch: 6| Step: 8
Training loss: 0.23344627592399217
Validation loss: 2.4148245598691553

Epoch: 6| Step: 9
Training loss: 0.44944898261620203
Validation loss: 2.399882626333847

Epoch: 6| Step: 10
Training loss: 0.2521154930287364
Validation loss: 2.369562997009554

Epoch: 6| Step: 11
Training loss: 0.5220438210173483
Validation loss: 2.408090950214497

Epoch: 6| Step: 12
Training loss: 0.4895681436360231
Validation loss: 2.3775921326992826

Epoch: 6| Step: 13
Training loss: 0.33000342522635306
Validation loss: 2.3708916618363123

Epoch: 282| Step: 0
Training loss: 0.4002667491298576
Validation loss: 2.3903679384781626

Epoch: 6| Step: 1
Training loss: 0.15104080205428733
Validation loss: 2.4140449467800145

Epoch: 6| Step: 2
Training loss: 0.27656281358086865
Validation loss: 2.4251343853420315

Epoch: 6| Step: 3
Training loss: 0.788576297343913
Validation loss: 2.4152562845876577

Epoch: 6| Step: 4
Training loss: 0.2776609943523379
Validation loss: 2.4245463013778403

Epoch: 6| Step: 5
Training loss: 0.38613608807036465
Validation loss: 2.410261699032847

Epoch: 6| Step: 6
Training loss: 0.433013665448363
Validation loss: 2.399413235523854

Epoch: 6| Step: 7
Training loss: 0.4320469492979518
Validation loss: 2.393900227208297

Epoch: 6| Step: 8
Training loss: 0.43595501033932704
Validation loss: 2.4101751717708386

Epoch: 6| Step: 9
Training loss: 0.15940464248998354
Validation loss: 2.392694043182308

Epoch: 6| Step: 10
Training loss: 0.5203489594386908
Validation loss: 2.3788556557067415

Epoch: 6| Step: 11
Training loss: 0.573371573668098
Validation loss: 2.410043798070885

Epoch: 6| Step: 12
Training loss: 0.46018150532299656
Validation loss: 2.4095956550582094

Epoch: 6| Step: 13
Training loss: 0.46802547410364603
Validation loss: 2.424470518805723

Epoch: 283| Step: 0
Training loss: 0.5543432107474744
Validation loss: 2.405424031948948

Epoch: 6| Step: 1
Training loss: 0.4119367554347805
Validation loss: 2.421964778023413

Epoch: 6| Step: 2
Training loss: 0.3774682315507359
Validation loss: 2.4526217113978093

Epoch: 6| Step: 3
Training loss: 0.39488053676180784
Validation loss: 2.430128260866474

Epoch: 6| Step: 4
Training loss: 0.36422909375414947
Validation loss: 2.4598248053803378

Epoch: 6| Step: 5
Training loss: 0.42791138213304736
Validation loss: 2.4533909071655615

Epoch: 6| Step: 6
Training loss: 0.1840074625937951
Validation loss: 2.424283494932381

Epoch: 6| Step: 7
Training loss: 0.3481211393611387
Validation loss: 2.4531300455008447

Epoch: 6| Step: 8
Training loss: 0.6047036782399657
Validation loss: 2.4503421040661433

Epoch: 6| Step: 9
Training loss: 0.4511742364730796
Validation loss: 2.4226307663924778

Epoch: 6| Step: 10
Training loss: 0.24321409269969013
Validation loss: 2.4201520906482985

Epoch: 6| Step: 11
Training loss: 0.6748523612509685
Validation loss: 2.4077597214067556

Epoch: 6| Step: 12
Training loss: 0.42062453985543324
Validation loss: 2.395501169841853

Epoch: 6| Step: 13
Training loss: 0.5325786301044018
Validation loss: 2.3784715962696703

Epoch: 284| Step: 0
Training loss: 0.593068459512117
Validation loss: 2.3817340844003536

Epoch: 6| Step: 1
Training loss: 0.4520569414208161
Validation loss: 2.4028709048672905

Epoch: 6| Step: 2
Training loss: 0.44507428540392757
Validation loss: 2.42002722266966

Epoch: 6| Step: 3
Training loss: 0.4879718410554056
Validation loss: 2.4290374075027126

Epoch: 6| Step: 4
Training loss: 0.3395627273946387
Validation loss: 2.422935061719606

Epoch: 6| Step: 5
Training loss: 0.33016921372243957
Validation loss: 2.4482477632269437

Epoch: 6| Step: 6
Training loss: 0.4865204917055901
Validation loss: 2.4160604466222093

Epoch: 6| Step: 7
Training loss: 0.30347644548122954
Validation loss: 2.4362065596416858

Epoch: 6| Step: 8
Training loss: 0.508548203639495
Validation loss: 2.461861632905731

Epoch: 6| Step: 9
Training loss: 0.4176790534750423
Validation loss: 2.4482210520313745

Epoch: 6| Step: 10
Training loss: 0.3912720851941471
Validation loss: 2.44357195294932

Epoch: 6| Step: 11
Training loss: 0.5692674913043604
Validation loss: 2.4756588239320725

Epoch: 6| Step: 12
Training loss: 0.34103288552210065
Validation loss: 2.437056252574773

Epoch: 6| Step: 13
Training loss: 0.5479854753267904
Validation loss: 2.4285667379231772

Epoch: 285| Step: 0
Training loss: 0.23068300083850632
Validation loss: 2.4487521991819214

Epoch: 6| Step: 1
Training loss: 0.6223980625596819
Validation loss: 2.420605783998904

Epoch: 6| Step: 2
Training loss: 0.5791024888338396
Validation loss: 2.4481785543596506

Epoch: 6| Step: 3
Training loss: 0.19754186494365794
Validation loss: 2.4289691281028243

Epoch: 6| Step: 4
Training loss: 0.5844695458452899
Validation loss: 2.4197872334002395

Epoch: 6| Step: 5
Training loss: 0.3433742420159005
Validation loss: 2.3935512708162254

Epoch: 6| Step: 6
Training loss: 0.2402548742464755
Validation loss: 2.400162502225702

Epoch: 6| Step: 7
Training loss: 0.47941571653346976
Validation loss: 2.3298648252872702

Epoch: 6| Step: 8
Training loss: 0.48121394542537754
Validation loss: 2.396551543164992

Epoch: 6| Step: 9
Training loss: 0.3112958237991617
Validation loss: 2.416170645137504

Epoch: 6| Step: 10
Training loss: 0.3767238769751965
Validation loss: 2.4182236153600405

Epoch: 6| Step: 11
Training loss: 0.43077193312727413
Validation loss: 2.424869608790856

Epoch: 6| Step: 12
Training loss: 0.5299839191876232
Validation loss: 2.4239725747433454

Epoch: 6| Step: 13
Training loss: 0.37796126832531424
Validation loss: 2.4254780378834613

Epoch: 286| Step: 0
Training loss: 0.48633478918450296
Validation loss: 2.4345038510367094

Epoch: 6| Step: 1
Training loss: 0.41098324191138075
Validation loss: 2.4481711341553356

Epoch: 6| Step: 2
Training loss: 0.4180434686061811
Validation loss: 2.4680720860504493

Epoch: 6| Step: 3
Training loss: 0.5595922282722239
Validation loss: 2.470934218731201

Epoch: 6| Step: 4
Training loss: 0.2611050598872733
Validation loss: 2.450420784073625

Epoch: 6| Step: 5
Training loss: 0.16605494538446222
Validation loss: 2.43617070828289

Epoch: 6| Step: 6
Training loss: 0.4739840905732697
Validation loss: 2.4645582859715613

Epoch: 6| Step: 7
Training loss: 0.44790260899093276
Validation loss: 2.4268462700703344

Epoch: 6| Step: 8
Training loss: 0.5569239915732052
Validation loss: 2.4567116337875

Epoch: 6| Step: 9
Training loss: 0.3882258362248096
Validation loss: 2.416570245997856

Epoch: 6| Step: 10
Training loss: 0.42509951828790443
Validation loss: 2.4278617028693334

Epoch: 6| Step: 11
Training loss: 0.4828601961742692
Validation loss: 2.4412017471473395

Epoch: 6| Step: 12
Training loss: 0.2863767970248136
Validation loss: 2.434904981043984

Epoch: 6| Step: 13
Training loss: 0.7858479427936187
Validation loss: 2.4387017603972656

Epoch: 287| Step: 0
Training loss: 0.42668032433709296
Validation loss: 2.3878350983363217

Epoch: 6| Step: 1
Training loss: 0.31032966118771294
Validation loss: 2.3996905423649

Epoch: 6| Step: 2
Training loss: 0.5812969311871873
Validation loss: 2.394512812727423

Epoch: 6| Step: 3
Training loss: 0.46244679673366423
Validation loss: 2.388096475335274

Epoch: 6| Step: 4
Training loss: 0.4659260563817089
Validation loss: 2.3594430121681

Epoch: 6| Step: 5
Training loss: 0.4094454646435701
Validation loss: 2.410738715886676

Epoch: 6| Step: 6
Training loss: 0.42010940977280786
Validation loss: 2.3930659889869808

Epoch: 6| Step: 7
Training loss: 0.6602150478926412
Validation loss: 2.453748434759791

Epoch: 6| Step: 8
Training loss: 0.5814710391615572
Validation loss: 2.408515716872789

Epoch: 6| Step: 9
Training loss: 0.4826474917016353
Validation loss: 2.4198429735369804

Epoch: 6| Step: 10
Training loss: 0.3270561885301306
Validation loss: 2.394821698874276

Epoch: 6| Step: 11
Training loss: 0.19847586441142506
Validation loss: 2.3602627287053446

Epoch: 6| Step: 12
Training loss: 0.3833911959196952
Validation loss: 2.3600898381805244

Epoch: 6| Step: 13
Training loss: 0.18786055944913801
Validation loss: 2.330598599398523

Epoch: 288| Step: 0
Training loss: 0.37543631046412174
Validation loss: 2.359667769154436

Epoch: 6| Step: 1
Training loss: 0.5551405117940236
Validation loss: 2.402564764039952

Epoch: 6| Step: 2
Training loss: 0.38007751809803886
Validation loss: 2.3773129803601813

Epoch: 6| Step: 3
Training loss: 0.6603152518118023
Validation loss: 2.381200571784998

Epoch: 6| Step: 4
Training loss: 0.38841802847464674
Validation loss: 2.428784527645007

Epoch: 6| Step: 5
Training loss: 0.3823848398606722
Validation loss: 2.3990075191362235

Epoch: 6| Step: 6
Training loss: 0.2883545738364148
Validation loss: 2.372690380655554

Epoch: 6| Step: 7
Training loss: 0.35541018328431007
Validation loss: 2.3914833214310245

Epoch: 6| Step: 8
Training loss: 0.41198287396344335
Validation loss: 2.4278529619038336

Epoch: 6| Step: 9
Training loss: 0.44382502767794524
Validation loss: 2.4198119735217083

Epoch: 6| Step: 10
Training loss: 0.5132827154919564
Validation loss: 2.4215722420435974

Epoch: 6| Step: 11
Training loss: 0.41474830765174836
Validation loss: 2.4058951009739737

Epoch: 6| Step: 12
Training loss: 0.4611481977042688
Validation loss: 2.430206067282299

Epoch: 6| Step: 13
Training loss: 0.4143861009943366
Validation loss: 2.403295208999782

Epoch: 289| Step: 0
Training loss: 0.48282938128344016
Validation loss: 2.371389604627665

Epoch: 6| Step: 1
Training loss: 0.5309748217401853
Validation loss: 2.3984787968721832

Epoch: 6| Step: 2
Training loss: 0.3562492772145217
Validation loss: 2.365190263745341

Epoch: 6| Step: 3
Training loss: 0.2966083784964318
Validation loss: 2.4085026672094143

Epoch: 6| Step: 4
Training loss: 0.37745599360733406
Validation loss: 2.413251320604507

Epoch: 6| Step: 5
Training loss: 0.36676577435187624
Validation loss: 2.405901608911081

Epoch: 6| Step: 6
Training loss: 0.295920229572016
Validation loss: 2.416715337866433

Epoch: 6| Step: 7
Training loss: 0.351442380093472
Validation loss: 2.447706129611158

Epoch: 6| Step: 8
Training loss: 0.21718037682797153
Validation loss: 2.4323816676500867

Epoch: 6| Step: 9
Training loss: 0.7837657097028382
Validation loss: 2.460624903891644

Epoch: 6| Step: 10
Training loss: 0.2798118245728235
Validation loss: 2.4611080539640895

Epoch: 6| Step: 11
Training loss: 0.5749512755440459
Validation loss: 2.461054890129978

Epoch: 6| Step: 12
Training loss: 0.3398108959760024
Validation loss: 2.466276872722565

Epoch: 6| Step: 13
Training loss: 0.22634240673909023
Validation loss: 2.4499553066092283

Epoch: 290| Step: 0
Training loss: 0.375711540846586
Validation loss: 2.4394189071977945

Epoch: 6| Step: 1
Training loss: 0.5103253328259769
Validation loss: 2.440140658190324

Epoch: 6| Step: 2
Training loss: 0.39753210756796986
Validation loss: 2.4298987324322447

Epoch: 6| Step: 3
Training loss: 0.3977059773528048
Validation loss: 2.4451086237210107

Epoch: 6| Step: 4
Training loss: 0.44481229295038355
Validation loss: 2.3966656405957747

Epoch: 6| Step: 5
Training loss: 0.3775486960171195
Validation loss: 2.389824938395938

Epoch: 6| Step: 6
Training loss: 0.48028109537777786
Validation loss: 2.3939961923287334

Epoch: 6| Step: 7
Training loss: 0.40242462826740266
Validation loss: 2.407475814357098

Epoch: 6| Step: 8
Training loss: 0.543576099825216
Validation loss: 2.3968440045914834

Epoch: 6| Step: 9
Training loss: 0.21759694050601913
Validation loss: 2.4305794481391305

Epoch: 6| Step: 10
Training loss: 0.5193507806063465
Validation loss: 2.450234188533798

Epoch: 6| Step: 11
Training loss: 0.2945991923439624
Validation loss: 2.45413028979716

Epoch: 6| Step: 12
Training loss: 0.3339910896920155
Validation loss: 2.446434644431741

Epoch: 6| Step: 13
Training loss: 0.35445336583789144
Validation loss: 2.434570493618685

Epoch: 291| Step: 0
Training loss: 0.22049323372504304
Validation loss: 2.421143302779266

Epoch: 6| Step: 1
Training loss: 0.5100516324460191
Validation loss: 2.464019804610051

Epoch: 6| Step: 2
Training loss: 0.3076712787845765
Validation loss: 2.4653107495673643

Epoch: 6| Step: 3
Training loss: 0.6299576825734148
Validation loss: 2.4404962108088584

Epoch: 6| Step: 4
Training loss: 0.42283350176927526
Validation loss: 2.419962070564979

Epoch: 6| Step: 5
Training loss: 0.3459227882399734
Validation loss: 2.4115438507047458

Epoch: 6| Step: 6
Training loss: 0.42065698907292876
Validation loss: 2.436953194841772

Epoch: 6| Step: 7
Training loss: 0.42653653760996596
Validation loss: 2.4072445222031185

Epoch: 6| Step: 8
Training loss: 0.3411350163596403
Validation loss: 2.3988255744690203

Epoch: 6| Step: 9
Training loss: 0.5235432759918158
Validation loss: 2.402999527775189

Epoch: 6| Step: 10
Training loss: 0.36380836228359054
Validation loss: 2.414944848658204

Epoch: 6| Step: 11
Training loss: 0.4190505280231808
Validation loss: 2.4248263759638475

Epoch: 6| Step: 12
Training loss: 0.3148621570327383
Validation loss: 2.435220879734439

Epoch: 6| Step: 13
Training loss: 0.1806705267497193
Validation loss: 2.4449377977518405

Epoch: 292| Step: 0
Training loss: 0.4767295357063242
Validation loss: 2.449959896128582

Epoch: 6| Step: 1
Training loss: 0.32824577651898473
Validation loss: 2.4423560704881813

Epoch: 6| Step: 2
Training loss: 0.2587513014396704
Validation loss: 2.438756512135322

Epoch: 6| Step: 3
Training loss: 0.2409654364117497
Validation loss: 2.447987803147955

Epoch: 6| Step: 4
Training loss: 0.3786377496219394
Validation loss: 2.444222680324613

Epoch: 6| Step: 5
Training loss: 0.5162063846683242
Validation loss: 2.4592087686686455

Epoch: 6| Step: 6
Training loss: 0.13197229186320078
Validation loss: 2.4588232377835912

Epoch: 6| Step: 7
Training loss: 0.4136774323894326
Validation loss: 2.4615178791279915

Epoch: 6| Step: 8
Training loss: 0.4240310113020478
Validation loss: 2.4328491418090374

Epoch: 6| Step: 9
Training loss: 0.4590775577835999
Validation loss: 2.4383375854883518

Epoch: 6| Step: 10
Training loss: 0.5544158915304964
Validation loss: 2.4151482895236684

Epoch: 6| Step: 11
Training loss: 0.4808252144276298
Validation loss: 2.43741397400854

Epoch: 6| Step: 12
Training loss: 0.2843508647276366
Validation loss: 2.391628363932419

Epoch: 6| Step: 13
Training loss: 0.5921194877923597
Validation loss: 2.39550808111685

Epoch: 293| Step: 0
Training loss: 0.5457529273275729
Validation loss: 2.370741770800229

Epoch: 6| Step: 1
Training loss: 0.36581662120677744
Validation loss: 2.3946050319296157

Epoch: 6| Step: 2
Training loss: 0.1996152429035466
Validation loss: 2.386796134273041

Epoch: 6| Step: 3
Training loss: 0.3766410207597971
Validation loss: 2.3953766832136285

Epoch: 6| Step: 4
Training loss: 0.5068202962648533
Validation loss: 2.382858221596162

Epoch: 6| Step: 5
Training loss: 0.33349650705515776
Validation loss: 2.3702167860339074

Epoch: 6| Step: 6
Training loss: 0.5270067621734624
Validation loss: 2.3755450181964517

Epoch: 6| Step: 7
Training loss: 0.29806345922244154
Validation loss: 2.3987671411572764

Epoch: 6| Step: 8
Training loss: 0.557534286830293
Validation loss: 2.40917348158206

Epoch: 6| Step: 9
Training loss: 0.3095890123754318
Validation loss: 2.4228913936214425

Epoch: 6| Step: 10
Training loss: 0.24440995428587314
Validation loss: 2.447418782942812

Epoch: 6| Step: 11
Training loss: 0.3563291804677114
Validation loss: 2.4690178606030107

Epoch: 6| Step: 12
Training loss: 0.29679862093932835
Validation loss: 2.4794977935042786

Epoch: 6| Step: 13
Training loss: 0.5250611814544327
Validation loss: 2.4787741155797214

Epoch: 294| Step: 0
Training loss: 0.2941655446068074
Validation loss: 2.4508967921592992

Epoch: 6| Step: 1
Training loss: 0.3449770527961938
Validation loss: 2.4278305592083176

Epoch: 6| Step: 2
Training loss: 0.13403582961213736
Validation loss: 2.457908476513213

Epoch: 6| Step: 3
Training loss: 0.3155015916625498
Validation loss: 2.4340985052425728

Epoch: 6| Step: 4
Training loss: 0.370917047291868
Validation loss: 2.4531706933826056

Epoch: 6| Step: 5
Training loss: 0.6889853903601514
Validation loss: 2.4138563963976787

Epoch: 6| Step: 6
Training loss: 0.30413141612455263
Validation loss: 2.4067855961228912

Epoch: 6| Step: 7
Training loss: 0.29937601662704094
Validation loss: 2.4007216219275582

Epoch: 6| Step: 8
Training loss: 0.28330676057035664
Validation loss: 2.3679947260725425

Epoch: 6| Step: 9
Training loss: 0.6309178564406166
Validation loss: 2.3836704731507496

Epoch: 6| Step: 10
Training loss: 0.18373020660748277
Validation loss: 2.372127596454359

Epoch: 6| Step: 11
Training loss: 0.3635376261438306
Validation loss: 2.3599110460054593

Epoch: 6| Step: 12
Training loss: 0.43081786854115
Validation loss: 2.400412364240395

Epoch: 6| Step: 13
Training loss: 0.4850478267684302
Validation loss: 2.4145345338208224

Epoch: 295| Step: 0
Training loss: 0.35494862745535255
Validation loss: 2.4105917545328026

Epoch: 6| Step: 1
Training loss: 0.16699988921848494
Validation loss: 2.407897097832316

Epoch: 6| Step: 2
Training loss: 0.3363900352500145
Validation loss: 2.408776853341165

Epoch: 6| Step: 3
Training loss: 0.5526488005373594
Validation loss: 2.4290308787015364

Epoch: 6| Step: 4
Training loss: 0.6133075635573952
Validation loss: 2.431943493595462

Epoch: 6| Step: 5
Training loss: 0.516801676363854
Validation loss: 2.426478772261732

Epoch: 6| Step: 6
Training loss: 0.3272571667716263
Validation loss: 2.421931562977199

Epoch: 6| Step: 7
Training loss: 0.39258757622572593
Validation loss: 2.3930137807210334

Epoch: 6| Step: 8
Training loss: 0.3844801720118842
Validation loss: 2.384315797339625

Epoch: 6| Step: 9
Training loss: 0.4201924893663024
Validation loss: 2.3893054291031914

Epoch: 6| Step: 10
Training loss: 0.32128272006838837
Validation loss: 2.389778189370017

Epoch: 6| Step: 11
Training loss: 0.3858220271286497
Validation loss: 2.4255698957447067

Epoch: 6| Step: 12
Training loss: 0.20981589341906595
Validation loss: 2.399891859612576

Epoch: 6| Step: 13
Training loss: 0.18064251333027925
Validation loss: 2.3868317305183737

Epoch: 296| Step: 0
Training loss: 0.23724037837465117
Validation loss: 2.4195174403223336

Epoch: 6| Step: 1
Training loss: 0.24504779882195474
Validation loss: 2.3880797666617872

Epoch: 6| Step: 2
Training loss: 0.4560872133733411
Validation loss: 2.380947948545441

Epoch: 6| Step: 3
Training loss: 0.26913630533281446
Validation loss: 2.4124012165098403

Epoch: 6| Step: 4
Training loss: 0.702612138839146
Validation loss: 2.373605948323078

Epoch: 6| Step: 5
Training loss: 0.5507106600497697
Validation loss: 2.393955245410932

Epoch: 6| Step: 6
Training loss: 0.43788109938293507
Validation loss: 2.411080714739024

Epoch: 6| Step: 7
Training loss: 0.32334637763479357
Validation loss: 2.398933058025154

Epoch: 6| Step: 8
Training loss: 0.18793923865345952
Validation loss: 2.417893698292899

Epoch: 6| Step: 9
Training loss: 0.34018278201586527
Validation loss: 2.399226747260545

Epoch: 6| Step: 10
Training loss: 0.19548984105820585
Validation loss: 2.414205157524446

Epoch: 6| Step: 11
Training loss: 0.29303853793223
Validation loss: 2.4035486011376848

Epoch: 6| Step: 12
Training loss: 0.3798999733468729
Validation loss: 2.409401467276898

Epoch: 6| Step: 13
Training loss: 0.2310066734336712
Validation loss: 2.3760391848256637

Epoch: 297| Step: 0
Training loss: 0.3872213854059317
Validation loss: 2.406548026542109

Epoch: 6| Step: 1
Training loss: 0.3411942100682659
Validation loss: 2.3855048502443745

Epoch: 6| Step: 2
Training loss: 0.4369313086157124
Validation loss: 2.3744341095690813

Epoch: 6| Step: 3
Training loss: 0.45542035311922563
Validation loss: 2.3889552239380447

Epoch: 6| Step: 4
Training loss: 0.45542460664433865
Validation loss: 2.419528615548802

Epoch: 6| Step: 5
Training loss: 0.4972032620265059
Validation loss: 2.4186857270033135

Epoch: 6| Step: 6
Training loss: 0.2213700606679844
Validation loss: 2.4045067241400004

Epoch: 6| Step: 7
Training loss: 0.21251829643581424
Validation loss: 2.443640163708018

Epoch: 6| Step: 8
Training loss: 0.2904266439354069
Validation loss: 2.4210342472182975

Epoch: 6| Step: 9
Training loss: 0.4815612251071776
Validation loss: 2.419860011139838

Epoch: 6| Step: 10
Training loss: 0.3381330249066769
Validation loss: 2.420392812708503

Epoch: 6| Step: 11
Training loss: 0.28949505428922284
Validation loss: 2.42138645882712

Epoch: 6| Step: 12
Training loss: 0.2364823807379292
Validation loss: 2.4075109190266186

Epoch: 6| Step: 13
Training loss: 0.5888001006772251
Validation loss: 2.407491302259848

Epoch: 298| Step: 0
Training loss: 0.6296477596341551
Validation loss: 2.412167193898175

Epoch: 6| Step: 1
Training loss: 0.4969408357537307
Validation loss: 2.3775761314034636

Epoch: 6| Step: 2
Training loss: 0.3785981370811051
Validation loss: 2.365945541207782

Epoch: 6| Step: 3
Training loss: 0.3530709330766646
Validation loss: 2.3957037385521516

Epoch: 6| Step: 4
Training loss: 0.3615171402063836
Validation loss: 2.3564524025100244

Epoch: 6| Step: 5
Training loss: 0.3760910058169061
Validation loss: 2.3681604381415564

Epoch: 6| Step: 6
Training loss: 0.16854851491506398
Validation loss: 2.3649254919460185

Epoch: 6| Step: 7
Training loss: 0.5454394709154916
Validation loss: 2.3984833897638436

Epoch: 6| Step: 8
Training loss: 0.1846421722517727
Validation loss: 2.427617226163009

Epoch: 6| Step: 9
Training loss: 0.26890459327253896
Validation loss: 2.420596030285121

Epoch: 6| Step: 10
Training loss: 0.34627716982107065
Validation loss: 2.3944083799914626

Epoch: 6| Step: 11
Training loss: 0.3314698128757391
Validation loss: 2.381264309878744

Epoch: 6| Step: 12
Training loss: 0.30436862251524877
Validation loss: 2.402284228380125

Epoch: 6| Step: 13
Training loss: 0.21364142638567923
Validation loss: 2.3997895595557734

Epoch: 299| Step: 0
Training loss: 0.3122765099539718
Validation loss: 2.405031030508574

Epoch: 6| Step: 1
Training loss: 0.3583133606926152
Validation loss: 2.415291118552157

Epoch: 6| Step: 2
Training loss: 0.2884618085163026
Validation loss: 2.40053054301789

Epoch: 6| Step: 3
Training loss: 0.6407165229363104
Validation loss: 2.431322790213436

Epoch: 6| Step: 4
Training loss: 0.22104869221647974
Validation loss: 2.4593374576844185

Epoch: 6| Step: 5
Training loss: 0.42592802055372886
Validation loss: 2.409000383022975

Epoch: 6| Step: 6
Training loss: 0.29137650458161385
Validation loss: 2.457326891239063

Epoch: 6| Step: 7
Training loss: 0.38620311384590345
Validation loss: 2.409089434086846

Epoch: 6| Step: 8
Training loss: 0.4275192695312591
Validation loss: 2.420828267510598

Epoch: 6| Step: 9
Training loss: 0.44837185183106615
Validation loss: 2.4280953172178705

Epoch: 6| Step: 10
Training loss: 0.40734830358467367
Validation loss: 2.4314754014332802

Epoch: 6| Step: 11
Training loss: 0.2997208394150884
Validation loss: 2.442952368711997

Epoch: 6| Step: 12
Training loss: 0.28437305701294185
Validation loss: 2.4424180562546303

Epoch: 6| Step: 13
Training loss: 0.343210392854822
Validation loss: 2.4545092267385806

Epoch: 300| Step: 0
Training loss: 0.30771199536495825
Validation loss: 2.455962167112512

Epoch: 6| Step: 1
Training loss: 0.13456905929136917
Validation loss: 2.459448888905303

Epoch: 6| Step: 2
Training loss: 0.31262842162211013
Validation loss: 2.4511849234099317

Epoch: 6| Step: 3
Training loss: 0.17089958190534799
Validation loss: 2.425158904949808

Epoch: 6| Step: 4
Training loss: 0.530865333641581
Validation loss: 2.415926106067385

Epoch: 6| Step: 5
Training loss: 0.2884974111204497
Validation loss: 2.4232928986476714

Epoch: 6| Step: 6
Training loss: 0.41829884052872834
Validation loss: 2.428496001990412

Epoch: 6| Step: 7
Training loss: 0.2039936273084343
Validation loss: 2.400523572247332

Epoch: 6| Step: 8
Training loss: 0.34937233587760813
Validation loss: 2.3860044405873464

Epoch: 6| Step: 9
Training loss: 0.5543933142009827
Validation loss: 2.407066823447636

Epoch: 6| Step: 10
Training loss: 0.5327772458850264
Validation loss: 2.375973758218995

Epoch: 6| Step: 11
Training loss: 0.3546713804371538
Validation loss: 2.383557693956721

Epoch: 6| Step: 12
Training loss: 0.36274080170971407
Validation loss: 2.3959345349895385

Epoch: 6| Step: 13
Training loss: 0.4857035383394841
Validation loss: 2.4137330762839224

Epoch: 301| Step: 0
Training loss: 0.23425657141291364
Validation loss: 2.4205241902901595

Epoch: 6| Step: 1
Training loss: 0.21637961468163897
Validation loss: 2.3946856235317058

Epoch: 6| Step: 2
Training loss: 0.3949240438248936
Validation loss: 2.4307542510103834

Epoch: 6| Step: 3
Training loss: 0.4944298843705754
Validation loss: 2.451635347999221

Epoch: 6| Step: 4
Training loss: 0.5018078783121535
Validation loss: 2.432163161789769

Epoch: 6| Step: 5
Training loss: 0.42107230222078224
Validation loss: 2.4360499721712063

Epoch: 6| Step: 6
Training loss: 0.256592522791626
Validation loss: 2.3887187540733907

Epoch: 6| Step: 7
Training loss: 0.5812565044326268
Validation loss: 2.372714212647278

Epoch: 6| Step: 8
Training loss: 0.5525343570124565
Validation loss: 2.388338927688277

Epoch: 6| Step: 9
Training loss: 0.3671816764532067
Validation loss: 2.4131957894098686

Epoch: 6| Step: 10
Training loss: 0.3232774513578263
Validation loss: 2.438014044353951

Epoch: 6| Step: 11
Training loss: 0.17349004550926864
Validation loss: 2.4500057427157147

Epoch: 6| Step: 12
Training loss: 0.6011942937982436
Validation loss: 2.453572418667687

Epoch: 6| Step: 13
Training loss: 0.5292646391226526
Validation loss: 2.450261065327768

Epoch: 302| Step: 0
Training loss: 0.3721675995920233
Validation loss: 2.460076890282858

Epoch: 6| Step: 1
Training loss: 0.37975693605453636
Validation loss: 2.42909143777769

Epoch: 6| Step: 2
Training loss: 0.30756232362775854
Validation loss: 2.408244141570189

Epoch: 6| Step: 3
Training loss: 0.29742781717082545
Validation loss: 2.4312888051587827

Epoch: 6| Step: 4
Training loss: 0.6737895567540146
Validation loss: 2.418003896884928

Epoch: 6| Step: 5
Training loss: 0.42844412110580504
Validation loss: 2.4174396963814946

Epoch: 6| Step: 6
Training loss: 0.32745612179949857
Validation loss: 2.440494750670738

Epoch: 6| Step: 7
Training loss: 0.24977044653034627
Validation loss: 2.432549409586582

Epoch: 6| Step: 8
Training loss: 0.3487117047631006
Validation loss: 2.474544619317818

Epoch: 6| Step: 9
Training loss: 0.5020090213037228
Validation loss: 2.489100069817511

Epoch: 6| Step: 10
Training loss: 0.43356305950250223
Validation loss: 2.491220037585582

Epoch: 6| Step: 11
Training loss: 0.362580577346409
Validation loss: 2.489792816565663

Epoch: 6| Step: 12
Training loss: 0.48073595261941837
Validation loss: 2.483803236797947

Epoch: 6| Step: 13
Training loss: 0.2625338402007213
Validation loss: 2.4918651045035265

Epoch: 303| Step: 0
Training loss: 0.4752350595755587
Validation loss: 2.4723302483754805

Epoch: 6| Step: 1
Training loss: 0.44502389490073824
Validation loss: 2.4957180546379534

Epoch: 6| Step: 2
Training loss: 0.2718817731956312
Validation loss: 2.4436659600702635

Epoch: 6| Step: 3
Training loss: 0.6182302767950651
Validation loss: 2.4432078271781497

Epoch: 6| Step: 4
Training loss: 0.3243776070117007
Validation loss: 2.410149895154453

Epoch: 6| Step: 5
Training loss: 0.2534961028730604
Validation loss: 2.3994949178082248

Epoch: 6| Step: 6
Training loss: 0.40928298993631723
Validation loss: 2.4103449903815424

Epoch: 6| Step: 7
Training loss: 0.3225142011546804
Validation loss: 2.3840317862328226

Epoch: 6| Step: 8
Training loss: 0.44940747153013566
Validation loss: 2.392189313525731

Epoch: 6| Step: 9
Training loss: 0.37225275247579726
Validation loss: 2.429448836449085

Epoch: 6| Step: 10
Training loss: 0.22108290918684342
Validation loss: 2.405875634065283

Epoch: 6| Step: 11
Training loss: 0.4466499855831515
Validation loss: 2.423705965936855

Epoch: 6| Step: 12
Training loss: 0.21336897209314817
Validation loss: 2.3948827906136803

Epoch: 6| Step: 13
Training loss: 0.3663683743614742
Validation loss: 2.440470618347779

Epoch: 304| Step: 0
Training loss: 0.46184724804375415
Validation loss: 2.4478497504987367

Epoch: 6| Step: 1
Training loss: 0.30818883671777214
Validation loss: 2.474599905107852

Epoch: 6| Step: 2
Training loss: 0.3791528076566451
Validation loss: 2.4418035011569654

Epoch: 6| Step: 3
Training loss: 0.3361528061501249
Validation loss: 2.478664282834022

Epoch: 6| Step: 4
Training loss: 0.5196957148615485
Validation loss: 2.459575716821318

Epoch: 6| Step: 5
Training loss: 0.1801274966332293
Validation loss: 2.4544857163175866

Epoch: 6| Step: 6
Training loss: 0.29356529536468584
Validation loss: 2.4601239228318117

Epoch: 6| Step: 7
Training loss: 0.2680053085434801
Validation loss: 2.4666233646224898

Epoch: 6| Step: 8
Training loss: 0.2701455455135309
Validation loss: 2.4110662945671666

Epoch: 6| Step: 9
Training loss: 0.34978988718387144
Validation loss: 2.4331533582340934

Epoch: 6| Step: 10
Training loss: 0.4949249255440869
Validation loss: 2.42083400857059

Epoch: 6| Step: 11
Training loss: 0.37307615315050063
Validation loss: 2.3947797330273795

Epoch: 6| Step: 12
Training loss: 0.5697472527702621
Validation loss: 2.424779281492035

Epoch: 6| Step: 13
Training loss: 0.36954526572231716
Validation loss: 2.427998144648825

Epoch: 305| Step: 0
Training loss: 0.45047225212458586
Validation loss: 2.4370480242743873

Epoch: 6| Step: 1
Training loss: 0.27802618446550575
Validation loss: 2.453644149374685

Epoch: 6| Step: 2
Training loss: 0.21688545410728532
Validation loss: 2.445065917823363

Epoch: 6| Step: 3
Training loss: 0.4053206083123455
Validation loss: 2.441036064319645

Epoch: 6| Step: 4
Training loss: 0.5193583839044618
Validation loss: 2.463292333504344

Epoch: 6| Step: 5
Training loss: 0.2737546443980696
Validation loss: 2.4614826536783916

Epoch: 6| Step: 6
Training loss: 0.5749488911512619
Validation loss: 2.451360524236833

Epoch: 6| Step: 7
Training loss: 0.43110556256880567
Validation loss: 2.4460548213244957

Epoch: 6| Step: 8
Training loss: 0.2287123395842618
Validation loss: 2.4439583521738255

Epoch: 6| Step: 9
Training loss: 0.18579470496706527
Validation loss: 2.441842244125504

Epoch: 6| Step: 10
Training loss: 0.4480020382570834
Validation loss: 2.4138910137292893

Epoch: 6| Step: 11
Training loss: 0.36219395181670966
Validation loss: 2.455270137984649

Epoch: 6| Step: 12
Training loss: 0.416087542841041
Validation loss: 2.4457693974769117

Epoch: 6| Step: 13
Training loss: 0.1313856062963215
Validation loss: 2.4531133434739014

Epoch: 306| Step: 0
Training loss: 0.2877924830779193
Validation loss: 2.4161689600813543

Epoch: 6| Step: 1
Training loss: 0.2823263473720789
Validation loss: 2.400516512282394

Epoch: 6| Step: 2
Training loss: 0.6584596219033199
Validation loss: 2.4119191496318972

Epoch: 6| Step: 3
Training loss: 0.27419223168113965
Validation loss: 2.4159081594368232

Epoch: 6| Step: 4
Training loss: 0.1992218166938059
Validation loss: 2.380651276654757

Epoch: 6| Step: 5
Training loss: 0.25124819413290533
Validation loss: 2.3972830803146348

Epoch: 6| Step: 6
Training loss: 0.5144305120667163
Validation loss: 2.3747307981587973

Epoch: 6| Step: 7
Training loss: 0.22851402738615878
Validation loss: 2.3872040667252326

Epoch: 6| Step: 8
Training loss: 0.36344321547365926
Validation loss: 2.4228449482526666

Epoch: 6| Step: 9
Training loss: 0.45322344795721764
Validation loss: 2.407582837995286

Epoch: 6| Step: 10
Training loss: 0.390882083218682
Validation loss: 2.399214328797551

Epoch: 6| Step: 11
Training loss: 0.22652430047905092
Validation loss: 2.417147653965346

Epoch: 6| Step: 12
Training loss: 0.2986056054085802
Validation loss: 2.4063820921864565

Epoch: 6| Step: 13
Training loss: 0.09645457985326283
Validation loss: 2.39892449832102

Epoch: 307| Step: 0
Training loss: 0.23194183334973503
Validation loss: 2.443715563194906

Epoch: 6| Step: 1
Training loss: 0.47078694590488407
Validation loss: 2.444751922011581

Epoch: 6| Step: 2
Training loss: 0.41665639467293375
Validation loss: 2.447721958380462

Epoch: 6| Step: 3
Training loss: 0.2723769738772237
Validation loss: 2.434825226871754

Epoch: 6| Step: 4
Training loss: 0.14858021902176682
Validation loss: 2.4499043703198478

Epoch: 6| Step: 5
Training loss: 0.42809680929440685
Validation loss: 2.452230099670162

Epoch: 6| Step: 6
Training loss: 0.21481872759669055
Validation loss: 2.4612626316237614

Epoch: 6| Step: 7
Training loss: 0.29846352418804567
Validation loss: 2.4480701025791065

Epoch: 6| Step: 8
Training loss: 0.2856048425994836
Validation loss: 2.447547923224772

Epoch: 6| Step: 9
Training loss: 0.39595409692725003
Validation loss: 2.469671943038619

Epoch: 6| Step: 10
Training loss: 0.23204235538403975
Validation loss: 2.399638922391716

Epoch: 6| Step: 11
Training loss: 0.6054925237110603
Validation loss: 2.408181727550107

Epoch: 6| Step: 12
Training loss: 0.3091781490863593
Validation loss: 2.4060655498406534

Epoch: 6| Step: 13
Training loss: 0.17660468935123197
Validation loss: 2.3839799468368503

Epoch: 308| Step: 0
Training loss: 0.5137931767532934
Validation loss: 2.3780921383441

Epoch: 6| Step: 1
Training loss: 0.40150742505667425
Validation loss: 2.4061715206862493

Epoch: 6| Step: 2
Training loss: 0.43477516061037264
Validation loss: 2.4097054564959297

Epoch: 6| Step: 3
Training loss: 0.35788842274459376
Validation loss: 2.397096647712272

Epoch: 6| Step: 4
Training loss: 0.31158938053760504
Validation loss: 2.3736706560915746

Epoch: 6| Step: 5
Training loss: 0.19299899339166335
Validation loss: 2.3722814481009458

Epoch: 6| Step: 6
Training loss: 0.22011703552132533
Validation loss: 2.403766432318146

Epoch: 6| Step: 7
Training loss: 0.18259678690988304
Validation loss: 2.4378569115272835

Epoch: 6| Step: 8
Training loss: 0.3807422751358791
Validation loss: 2.3965602340945225

Epoch: 6| Step: 9
Training loss: 0.4932083261095679
Validation loss: 2.4412289313127116

Epoch: 6| Step: 10
Training loss: 0.2899912142861493
Validation loss: 2.4056963049823588

Epoch: 6| Step: 11
Training loss: 0.3044358461335473
Validation loss: 2.414233233955336

Epoch: 6| Step: 12
Training loss: 0.3260184286853087
Validation loss: 2.423801314715247

Epoch: 6| Step: 13
Training loss: 0.41546460046665035
Validation loss: 2.4381676993347363

Epoch: 309| Step: 0
Training loss: 0.31299369676400945
Validation loss: 2.4321100996760414

Epoch: 6| Step: 1
Training loss: 0.12758361073442415
Validation loss: 2.423968227923349

Epoch: 6| Step: 2
Training loss: 0.32070196711415994
Validation loss: 2.42093000496599

Epoch: 6| Step: 3
Training loss: 0.368048247478714
Validation loss: 2.3995625001011285

Epoch: 6| Step: 4
Training loss: 0.536045644097732
Validation loss: 2.388901726056338

Epoch: 6| Step: 5
Training loss: 0.5049380598701388
Validation loss: 2.380965762994372

Epoch: 6| Step: 6
Training loss: 0.37442572649645656
Validation loss: 2.390524379310511

Epoch: 6| Step: 7
Training loss: 0.45133163463990345
Validation loss: 2.383824053011896

Epoch: 6| Step: 8
Training loss: 0.186642633669213
Validation loss: 2.39252568964102

Epoch: 6| Step: 9
Training loss: 0.3068028525053568
Validation loss: 2.3758741787416593

Epoch: 6| Step: 10
Training loss: 0.31157472242143874
Validation loss: 2.411528913457754

Epoch: 6| Step: 11
Training loss: 0.40778352992612954
Validation loss: 2.4181044512625096

Epoch: 6| Step: 12
Training loss: 0.28800733108097404
Validation loss: 2.4406654264962633

Epoch: 6| Step: 13
Training loss: 0.09128055550011666
Validation loss: 2.440649078760018

Epoch: 310| Step: 0
Training loss: 0.3771553682928093
Validation loss: 2.4453840017586472

Epoch: 6| Step: 1
Training loss: 0.4077287865727386
Validation loss: 2.425389537810672

Epoch: 6| Step: 2
Training loss: 0.47643687984581823
Validation loss: 2.4644342001664614

Epoch: 6| Step: 3
Training loss: 0.17910096595856173
Validation loss: 2.425526771845623

Epoch: 6| Step: 4
Training loss: 0.5021417463784896
Validation loss: 2.426293287609837

Epoch: 6| Step: 5
Training loss: 0.17348218634289123
Validation loss: 2.4009989759871786

Epoch: 6| Step: 6
Training loss: 0.312656006019417
Validation loss: 2.3783841237286727

Epoch: 6| Step: 7
Training loss: 0.373732849863091
Validation loss: 2.37710593851653

Epoch: 6| Step: 8
Training loss: 0.36998800876878485
Validation loss: 2.376295048052456

Epoch: 6| Step: 9
Training loss: 0.20472457018623227
Validation loss: 2.372597983369376

Epoch: 6| Step: 10
Training loss: 0.44734754187029124
Validation loss: 2.414920018865119

Epoch: 6| Step: 11
Training loss: 0.29610020773898704
Validation loss: 2.3883642662108455

Epoch: 6| Step: 12
Training loss: 0.2841171772690126
Validation loss: 2.400165124437455

Epoch: 6| Step: 13
Training loss: 0.3350938360969556
Validation loss: 2.439655875597796

Epoch: 311| Step: 0
Training loss: 0.40812883202942996
Validation loss: 2.433032259546677

Epoch: 6| Step: 1
Training loss: 0.5100801747076843
Validation loss: 2.4360885061938933

Epoch: 6| Step: 2
Training loss: 0.24985789939459435
Validation loss: 2.388833807818759

Epoch: 6| Step: 3
Training loss: 0.37270665257762436
Validation loss: 2.4030298413335687

Epoch: 6| Step: 4
Training loss: 0.24868198247197337
Validation loss: 2.3715879836772227

Epoch: 6| Step: 5
Training loss: 0.47418881845045835
Validation loss: 2.353973218102739

Epoch: 6| Step: 6
Training loss: 0.5152193554589911
Validation loss: 2.3474799356104694

Epoch: 6| Step: 7
Training loss: 0.3580312693102188
Validation loss: 2.3770615104743493

Epoch: 6| Step: 8
Training loss: 0.22142721074236685
Validation loss: 2.340496134646008

Epoch: 6| Step: 9
Training loss: 0.28796695903235636
Validation loss: 2.40304583289709

Epoch: 6| Step: 10
Training loss: 0.3969323394684997
Validation loss: 2.4167175029489774

Epoch: 6| Step: 11
Training loss: 0.21897878773774768
Validation loss: 2.4293919902481242

Epoch: 6| Step: 12
Training loss: 0.26956502730425064
Validation loss: 2.4410650320187703

Epoch: 6| Step: 13
Training loss: 0.1388172207308298
Validation loss: 2.4321417340171747

Epoch: 312| Step: 0
Training loss: 0.4156805847400329
Validation loss: 2.4612354947807353

Epoch: 6| Step: 1
Training loss: 0.2948590015819167
Validation loss: 2.447675015878325

Epoch: 6| Step: 2
Training loss: 0.3310674029133602
Validation loss: 2.4554871477608207

Epoch: 6| Step: 3
Training loss: 0.5004397485043401
Validation loss: 2.489653369122519

Epoch: 6| Step: 4
Training loss: 0.3894813389635513
Validation loss: 2.4686132392890174

Epoch: 6| Step: 5
Training loss: 0.2587138804504926
Validation loss: 2.4728532728292314

Epoch: 6| Step: 6
Training loss: 0.3786394812231703
Validation loss: 2.4762610852490226

Epoch: 6| Step: 7
Training loss: 0.283655528756116
Validation loss: 2.4391920444809023

Epoch: 6| Step: 8
Training loss: 0.11032412196256654
Validation loss: 2.4069504854917683

Epoch: 6| Step: 9
Training loss: 0.29933417860228967
Validation loss: 2.3948692133195015

Epoch: 6| Step: 10
Training loss: 0.27266802830655357
Validation loss: 2.4239898318591155

Epoch: 6| Step: 11
Training loss: 0.07132459434344782
Validation loss: 2.4205805362083557

Epoch: 6| Step: 12
Training loss: 0.5292672293268226
Validation loss: 2.4072591681438458

Epoch: 6| Step: 13
Training loss: 0.2381695031959736
Validation loss: 2.4320894272184437

Epoch: 313| Step: 0
Training loss: 0.37610873586722304
Validation loss: 2.421830334683206

Epoch: 6| Step: 1
Training loss: 0.37534447583795405
Validation loss: 2.4257512569530064

Epoch: 6| Step: 2
Training loss: 0.4040375767195583
Validation loss: 2.414897874650569

Epoch: 6| Step: 3
Training loss: 0.42606660922221745
Validation loss: 2.4331927509915867

Epoch: 6| Step: 4
Training loss: 0.2710525316459704
Validation loss: 2.4137200080950336

Epoch: 6| Step: 5
Training loss: 0.2729821364423598
Validation loss: 2.4267690785117773

Epoch: 6| Step: 6
Training loss: 0.2664860345838544
Validation loss: 2.4276441038678773

Epoch: 6| Step: 7
Training loss: 0.4521289928366491
Validation loss: 2.4310464916555534

Epoch: 6| Step: 8
Training loss: 0.2898475708414034
Validation loss: 2.425337490493165

Epoch: 6| Step: 9
Training loss: 0.24141985228403873
Validation loss: 2.42179600153127

Epoch: 6| Step: 10
Training loss: 0.4012045797743645
Validation loss: 2.427313274624452

Epoch: 6| Step: 11
Training loss: 0.36094649497709747
Validation loss: 2.4051984628973764

Epoch: 6| Step: 12
Training loss: 0.2854859784235597
Validation loss: 2.4413758955186236

Epoch: 6| Step: 13
Training loss: 0.0913831946648806
Validation loss: 2.421541357859324

Epoch: 314| Step: 0
Training loss: 0.22322366592588752
Validation loss: 2.4360251228151

Epoch: 6| Step: 1
Training loss: 0.27838040422590427
Validation loss: 2.433338583881424

Epoch: 6| Step: 2
Training loss: 0.33548888481420297
Validation loss: 2.421410170454953

Epoch: 6| Step: 3
Training loss: 0.22822111665453695
Validation loss: 2.425232162077832

Epoch: 6| Step: 4
Training loss: 0.25843914054525186
Validation loss: 2.433334926484458

Epoch: 6| Step: 5
Training loss: 0.5772343037562415
Validation loss: 2.415435330575112

Epoch: 6| Step: 6
Training loss: 0.3386976384061988
Validation loss: 2.4281387787565993

Epoch: 6| Step: 7
Training loss: 0.3812179637956803
Validation loss: 2.4510729156731097

Epoch: 6| Step: 8
Training loss: 0.39216962598823535
Validation loss: 2.423939223540946

Epoch: 6| Step: 9
Training loss: 0.3700182538427038
Validation loss: 2.42417206952872

Epoch: 6| Step: 10
Training loss: 0.3621008780427963
Validation loss: 2.429999410714529

Epoch: 6| Step: 11
Training loss: 0.2008848642848198
Validation loss: 2.4300634228331077

Epoch: 6| Step: 12
Training loss: 0.27438058343476474
Validation loss: 2.4293610139432373

Epoch: 6| Step: 13
Training loss: 0.24948905349179745
Validation loss: 2.418521002774966

Epoch: 315| Step: 0
Training loss: 0.13329220838542005
Validation loss: 2.3727321418575262

Epoch: 6| Step: 1
Training loss: 0.4678207405399125
Validation loss: 2.3895962833069695

Epoch: 6| Step: 2
Training loss: 0.47177795902844566
Validation loss: 2.4134296323483655

Epoch: 6| Step: 3
Training loss: 0.5215756054346528
Validation loss: 2.4266597021251552

Epoch: 6| Step: 4
Training loss: 0.2694913724065028
Validation loss: 2.4216526306510953

Epoch: 6| Step: 5
Training loss: 0.3090537903525653
Validation loss: 2.410013842128726

Epoch: 6| Step: 6
Training loss: 0.2511160793001688
Validation loss: 2.4396971215336665

Epoch: 6| Step: 7
Training loss: 0.18844701110345052
Validation loss: 2.427365453840701

Epoch: 6| Step: 8
Training loss: 0.28862285688223316
Validation loss: 2.452880803851141

Epoch: 6| Step: 9
Training loss: 0.2518355516632234
Validation loss: 2.4513600619917826

Epoch: 6| Step: 10
Training loss: 0.4468618511052785
Validation loss: 2.46389682477146

Epoch: 6| Step: 11
Training loss: 0.3073125875215714
Validation loss: 2.439676924231602

Epoch: 6| Step: 12
Training loss: 0.11334594161915149
Validation loss: 2.4322921940190163

Epoch: 6| Step: 13
Training loss: 0.18240212204892428
Validation loss: 2.4250124527704826

Epoch: 316| Step: 0
Training loss: 0.2500364753816956
Validation loss: 2.4561312629268426

Epoch: 6| Step: 1
Training loss: 0.4008906893560802
Validation loss: 2.400896135555044

Epoch: 6| Step: 2
Training loss: 0.22926966653590788
Validation loss: 2.4227339952915248

Epoch: 6| Step: 3
Training loss: 0.24926736889567921
Validation loss: 2.4475588243516686

Epoch: 6| Step: 4
Training loss: 0.3324549944255334
Validation loss: 2.384368972879296

Epoch: 6| Step: 5
Training loss: 0.47428669576288923
Validation loss: 2.414152380596234

Epoch: 6| Step: 6
Training loss: 0.1571783264281732
Validation loss: 2.397982409175354

Epoch: 6| Step: 7
Training loss: 0.40383798476138216
Validation loss: 2.39109855571148

Epoch: 6| Step: 8
Training loss: 0.23073256474325543
Validation loss: 2.365804658142032

Epoch: 6| Step: 9
Training loss: 0.3551198903313382
Validation loss: 2.3837786424637657

Epoch: 6| Step: 10
Training loss: 0.3537804681105339
Validation loss: 2.365487485315867

Epoch: 6| Step: 11
Training loss: 0.3867318892895913
Validation loss: 2.3739387816114044

Epoch: 6| Step: 12
Training loss: 0.3700260060102036
Validation loss: 2.361632486992935

Epoch: 6| Step: 13
Training loss: 0.3154198140113722
Validation loss: 2.401643641598897

Epoch: 317| Step: 0
Training loss: 0.19789335255751772
Validation loss: 2.42450014254245

Epoch: 6| Step: 1
Training loss: 0.4860327256295022
Validation loss: 2.424227542816373

Epoch: 6| Step: 2
Training loss: 0.2839060511402028
Validation loss: 2.4648161762209138

Epoch: 6| Step: 3
Training loss: 0.2862894456246397
Validation loss: 2.437402480577636

Epoch: 6| Step: 4
Training loss: 0.33173056058122247
Validation loss: 2.488702621786506

Epoch: 6| Step: 5
Training loss: 0.2416213478492225
Validation loss: 2.473239766780042

Epoch: 6| Step: 6
Training loss: 0.25164982186452683
Validation loss: 2.457366195373592

Epoch: 6| Step: 7
Training loss: 0.18532416379352187
Validation loss: 2.40104637032535

Epoch: 6| Step: 8
Training loss: 0.2245842961117898
Validation loss: 2.417637378290315

Epoch: 6| Step: 9
Training loss: 0.45330862731205024
Validation loss: 2.424145606749709

Epoch: 6| Step: 10
Training loss: 0.4402022863707815
Validation loss: 2.445827959894732

Epoch: 6| Step: 11
Training loss: 0.30455657395692404
Validation loss: 2.382089780088012

Epoch: 6| Step: 12
Training loss: 0.3780842546310674
Validation loss: 2.376293567344969

Epoch: 6| Step: 13
Training loss: 0.39798623129376676
Validation loss: 2.4079237700557905

Epoch: 318| Step: 0
Training loss: 0.30678851212152447
Validation loss: 2.378265958526547

Epoch: 6| Step: 1
Training loss: 0.48580871175577006
Validation loss: 2.404110625870674

Epoch: 6| Step: 2
Training loss: 0.3949277226499037
Validation loss: 2.41380057643148

Epoch: 6| Step: 3
Training loss: 0.13499516827272617
Validation loss: 2.404718444608483

Epoch: 6| Step: 4
Training loss: 0.2069849556319901
Validation loss: 2.4028438404760615

Epoch: 6| Step: 5
Training loss: 0.367039346228078
Validation loss: 2.409755244031812

Epoch: 6| Step: 6
Training loss: 0.3221298856679286
Validation loss: 2.404473073616472

Epoch: 6| Step: 7
Training loss: 0.13310817455471824
Validation loss: 2.4014400620297067

Epoch: 6| Step: 8
Training loss: 0.35430861414731435
Validation loss: 2.4133807712201327

Epoch: 6| Step: 9
Training loss: 0.3419825894039923
Validation loss: 2.433314455390093

Epoch: 6| Step: 10
Training loss: 0.3112751799666479
Validation loss: 2.407450286174247

Epoch: 6| Step: 11
Training loss: 0.3844742809568478
Validation loss: 2.437896281912922

Epoch: 6| Step: 12
Training loss: 0.19025127171355807
Validation loss: 2.415003863973823

Epoch: 6| Step: 13
Training loss: 0.11456751217494152
Validation loss: 2.424857318217079

Epoch: 319| Step: 0
Training loss: 0.31983290798817615
Validation loss: 2.435190539741879

Epoch: 6| Step: 1
Training loss: 0.5021445951904577
Validation loss: 2.442172851963657

Epoch: 6| Step: 2
Training loss: 0.33286487050890406
Validation loss: 2.4254636874538424

Epoch: 6| Step: 3
Training loss: 0.19197847505577004
Validation loss: 2.4412594440908597

Epoch: 6| Step: 4
Training loss: 0.33626832862448847
Validation loss: 2.404431153605549

Epoch: 6| Step: 5
Training loss: 0.1986221937043738
Validation loss: 2.3958186208443553

Epoch: 6| Step: 6
Training loss: 0.364038989736425
Validation loss: 2.4100679733861

Epoch: 6| Step: 7
Training loss: 0.17783263917051306
Validation loss: 2.414649062461052

Epoch: 6| Step: 8
Training loss: 0.2743394689211788
Validation loss: 2.3959148790803453

Epoch: 6| Step: 9
Training loss: 0.20645324525776937
Validation loss: 2.4006804770991357

Epoch: 6| Step: 10
Training loss: 0.3116809243601855
Validation loss: 2.391681401005591

Epoch: 6| Step: 11
Training loss: 0.5356575504414268
Validation loss: 2.3715117138635686

Epoch: 6| Step: 12
Training loss: 0.2385708737226684
Validation loss: 2.3873490642394346

Epoch: 6| Step: 13
Training loss: 0.11723622262895152
Validation loss: 2.3868624532140115

Epoch: 320| Step: 0
Training loss: 0.2333230251919033
Validation loss: 2.3709074016997733

Epoch: 6| Step: 1
Training loss: 0.38743453780332765
Validation loss: 2.3970768762024623

Epoch: 6| Step: 2
Training loss: 0.35001388249794346
Validation loss: 2.3937630638593514

Epoch: 6| Step: 3
Training loss: 0.19533903895317653
Validation loss: 2.412727128654971

Epoch: 6| Step: 4
Training loss: 0.42142319328014505
Validation loss: 2.4323395530260963

Epoch: 6| Step: 5
Training loss: 0.4268203270558003
Validation loss: 2.4300658281603518

Epoch: 6| Step: 6
Training loss: 0.1916723250939444
Validation loss: 2.4485058974453646

Epoch: 6| Step: 7
Training loss: 0.18852340037202575
Validation loss: 2.440058455360433

Epoch: 6| Step: 8
Training loss: 0.3269482127997623
Validation loss: 2.4489359880100894

Epoch: 6| Step: 9
Training loss: 0.14619841319934043
Validation loss: 2.4163272714463613

Epoch: 6| Step: 10
Training loss: 0.25442350958374216
Validation loss: 2.417073094354283

Epoch: 6| Step: 11
Training loss: 0.524206848691645
Validation loss: 2.4145819172937366

Epoch: 6| Step: 12
Training loss: 0.18354133101124837
Validation loss: 2.419924673906325

Epoch: 6| Step: 13
Training loss: 0.30557419062031854
Validation loss: 2.3895117896822993

Epoch: 321| Step: 0
Training loss: 0.3395498144636854
Validation loss: 2.4163695086568318

Epoch: 6| Step: 1
Training loss: 0.5379142141052328
Validation loss: 2.409654261982722

Epoch: 6| Step: 2
Training loss: 0.1724154093644519
Validation loss: 2.42575344884645

Epoch: 6| Step: 3
Training loss: 0.351311784991582
Validation loss: 2.3826383051281437

Epoch: 6| Step: 4
Training loss: 0.3691741282280929
Validation loss: 2.3994252181025573

Epoch: 6| Step: 5
Training loss: 0.23592529960060318
Validation loss: 2.451175164301934

Epoch: 6| Step: 6
Training loss: 0.2035896873068768
Validation loss: 2.4435851982622987

Epoch: 6| Step: 7
Training loss: 0.3706113591184666
Validation loss: 2.422089037003142

Epoch: 6| Step: 8
Training loss: 0.1748621595728696
Validation loss: 2.4274415571256047

Epoch: 6| Step: 9
Training loss: 0.4346908744993665
Validation loss: 2.421162028564418

Epoch: 6| Step: 10
Training loss: 0.3746228109263326
Validation loss: 2.3953774529874363

Epoch: 6| Step: 11
Training loss: 0.22927590587856286
Validation loss: 2.413557675833026

Epoch: 6| Step: 12
Training loss: 0.1797208962296584
Validation loss: 2.401375850859081

Epoch: 6| Step: 13
Training loss: 0.291498730484143
Validation loss: 2.383158704385318

Epoch: 322| Step: 0
Training loss: 0.2754079529200914
Validation loss: 2.3866894798416753

Epoch: 6| Step: 1
Training loss: 0.280358384713641
Validation loss: 2.3802469774171042

Epoch: 6| Step: 2
Training loss: 0.22764120142518954
Validation loss: 2.3810784598485464

Epoch: 6| Step: 3
Training loss: 0.3419784717434622
Validation loss: 2.369378546227297

Epoch: 6| Step: 4
Training loss: 0.2551672798664724
Validation loss: 2.356419298932334

Epoch: 6| Step: 5
Training loss: 0.226445776369871
Validation loss: 2.3394075633168225

Epoch: 6| Step: 6
Training loss: 0.3591238056166983
Validation loss: 2.3682208585467

Epoch: 6| Step: 7
Training loss: 0.298533849491832
Validation loss: 2.3544381504477068

Epoch: 6| Step: 8
Training loss: 0.46710887362128983
Validation loss: 2.355071146338204

Epoch: 6| Step: 9
Training loss: 0.49238895653020215
Validation loss: 2.3772651187926006

Epoch: 6| Step: 10
Training loss: 0.24709766221486287
Validation loss: 2.3937607398603875

Epoch: 6| Step: 11
Training loss: 0.3002816298910456
Validation loss: 2.3900390942929146

Epoch: 6| Step: 12
Training loss: 0.3352390280449324
Validation loss: 2.417402417125153

Epoch: 6| Step: 13
Training loss: 0.11708734126276232
Validation loss: 2.3872694701270607

Epoch: 323| Step: 0
Training loss: 0.4365178903658227
Validation loss: 2.410859800835408

Epoch: 6| Step: 1
Training loss: 0.1850567820115594
Validation loss: 2.428318349735852

Epoch: 6| Step: 2
Training loss: 0.48694588212554607
Validation loss: 2.4106208780351883

Epoch: 6| Step: 3
Training loss: 0.3849378287599959
Validation loss: 2.4340594051982833

Epoch: 6| Step: 4
Training loss: 0.18639071470948074
Validation loss: 2.4355994398959897

Epoch: 6| Step: 5
Training loss: 0.334402503014453
Validation loss: 2.4037210838905296

Epoch: 6| Step: 6
Training loss: 0.19967998144236426
Validation loss: 2.3977610144541335

Epoch: 6| Step: 7
Training loss: 0.31397893942223426
Validation loss: 2.43267158825578

Epoch: 6| Step: 8
Training loss: 0.33020218092344306
Validation loss: 2.402333987770018

Epoch: 6| Step: 9
Training loss: 0.25419737924737507
Validation loss: 2.3509220091441465

Epoch: 6| Step: 10
Training loss: 0.330880560979167
Validation loss: 2.4010023884791165

Epoch: 6| Step: 11
Training loss: 0.2486853305101736
Validation loss: 2.434401626711942

Epoch: 6| Step: 12
Training loss: 0.21798049594308927
Validation loss: 2.420721757987029

Epoch: 6| Step: 13
Training loss: 0.19041651166670298
Validation loss: 2.376111505035763

Epoch: 324| Step: 0
Training loss: 0.16978775957991035
Validation loss: 2.411708264867385

Epoch: 6| Step: 1
Training loss: 0.12529593692394606
Validation loss: 2.3948753856535783

Epoch: 6| Step: 2
Training loss: 0.30804401637276396
Validation loss: 2.386693303779992

Epoch: 6| Step: 3
Training loss: 0.28897562525761017
Validation loss: 2.3926491127758958

Epoch: 6| Step: 4
Training loss: 0.162257861877813
Validation loss: 2.409787089918946

Epoch: 6| Step: 5
Training loss: 0.33818735753431617
Validation loss: 2.3620528999584915

Epoch: 6| Step: 6
Training loss: 0.3418503855643526
Validation loss: 2.368323497388805

Epoch: 6| Step: 7
Training loss: 0.38879913853600906
Validation loss: 2.3748502203748605

Epoch: 6| Step: 8
Training loss: 0.34033069582968584
Validation loss: 2.3911116553285616

Epoch: 6| Step: 9
Training loss: 0.4907654700889441
Validation loss: 2.3711189181781855

Epoch: 6| Step: 10
Training loss: 0.21989312534541178
Validation loss: 2.394782980958831

Epoch: 6| Step: 11
Training loss: 0.20794820155223415
Validation loss: 2.407250902423554

Epoch: 6| Step: 12
Training loss: 0.3531779156763061
Validation loss: 2.4165969533769727

Epoch: 6| Step: 13
Training loss: 0.21032150712642309
Validation loss: 2.4238897426849477

Epoch: 325| Step: 0
Training loss: 0.34886138432803526
Validation loss: 2.422977153588889

Epoch: 6| Step: 1
Training loss: 0.15120847441338295
Validation loss: 2.4505820155833105

Epoch: 6| Step: 2
Training loss: 0.24472130954764446
Validation loss: 2.4511394482082185

Epoch: 6| Step: 3
Training loss: 0.6019419674640729
Validation loss: 2.455157918786309

Epoch: 6| Step: 4
Training loss: 0.15948604870898364
Validation loss: 2.4370895986295347

Epoch: 6| Step: 5
Training loss: 0.28862468968767524
Validation loss: 2.4185419144328555

Epoch: 6| Step: 6
Training loss: 0.24585195045909705
Validation loss: 2.4158695518430995

Epoch: 6| Step: 7
Training loss: 0.2596962915119026
Validation loss: 2.4053786273767437

Epoch: 6| Step: 8
Training loss: 0.31869856194978763
Validation loss: 2.423223295230312

Epoch: 6| Step: 9
Training loss: 0.1519064373085046
Validation loss: 2.371557094455007

Epoch: 6| Step: 10
Training loss: 0.39595368295790334
Validation loss: 2.3405061167382044

Epoch: 6| Step: 11
Training loss: 0.2940640510696546
Validation loss: 2.3876968553896574

Epoch: 6| Step: 12
Training loss: 0.15837363485186018
Validation loss: 2.365105495466102

Epoch: 6| Step: 13
Training loss: 0.29885578650807515
Validation loss: 2.379485978322042

Epoch: 326| Step: 0
Training loss: 0.4959408381733744
Validation loss: 2.358712711675199

Epoch: 6| Step: 1
Training loss: 0.3392231854922368
Validation loss: 2.3690773236274074

Epoch: 6| Step: 2
Training loss: 0.2517158218772308
Validation loss: 2.3674318814300763

Epoch: 6| Step: 3
Training loss: 0.15356023203471808
Validation loss: 2.414636859744494

Epoch: 6| Step: 4
Training loss: 0.44398405792960693
Validation loss: 2.366462373632509

Epoch: 6| Step: 5
Training loss: 0.13310626443245863
Validation loss: 2.381843884028533

Epoch: 6| Step: 6
Training loss: 0.3637876160497755
Validation loss: 2.3850034961437045

Epoch: 6| Step: 7
Training loss: 0.33487974022404127
Validation loss: 2.3912895930843177

Epoch: 6| Step: 8
Training loss: 0.1700198997918637
Validation loss: 2.377161517965941

Epoch: 6| Step: 9
Training loss: 0.1800713999189632
Validation loss: 2.378572491865945

Epoch: 6| Step: 10
Training loss: 0.24820109701844031
Validation loss: 2.4079524158565864

Epoch: 6| Step: 11
Training loss: 0.27027635277527856
Validation loss: 2.409403420808662

Epoch: 6| Step: 12
Training loss: 0.3247113794021311
Validation loss: 2.3986551401757232

Epoch: 6| Step: 13
Training loss: 0.2944028468233443
Validation loss: 2.382639591446569

Epoch: 327| Step: 0
Training loss: 0.4645060426485297
Validation loss: 2.363050310713801

Epoch: 6| Step: 1
Training loss: 0.49860286719851626
Validation loss: 2.3817560326756366

Epoch: 6| Step: 2
Training loss: 0.14328768936172334
Validation loss: 2.4160583615932403

Epoch: 6| Step: 3
Training loss: 0.11760224224906023
Validation loss: 2.354463180902491

Epoch: 6| Step: 4
Training loss: 0.27641937517969223
Validation loss: 2.3715079870601192

Epoch: 6| Step: 5
Training loss: 0.13101893987766988
Validation loss: 2.387171018011834

Epoch: 6| Step: 6
Training loss: 0.2606485891758774
Validation loss: 2.4173372690435184

Epoch: 6| Step: 7
Training loss: 0.31915036330195684
Validation loss: 2.410638758213091

Epoch: 6| Step: 8
Training loss: 0.34555074059577173
Validation loss: 2.419236538124249

Epoch: 6| Step: 9
Training loss: 0.1533418445896347
Validation loss: 2.4385900423926876

Epoch: 6| Step: 10
Training loss: 0.39964824796941906
Validation loss: 2.443117814026844

Epoch: 6| Step: 11
Training loss: 0.3367940827291327
Validation loss: 2.431928572013353

Epoch: 6| Step: 12
Training loss: 0.22040012118743812
Validation loss: 2.431979593852651

Epoch: 6| Step: 13
Training loss: 0.15485028722726876
Validation loss: 2.4144467039689648

Epoch: 328| Step: 0
Training loss: 0.38822464635885584
Validation loss: 2.432305016972539

Epoch: 6| Step: 1
Training loss: 0.3737636091950497
Validation loss: 2.392939691536315

Epoch: 6| Step: 2
Training loss: 0.2779993984486912
Validation loss: 2.4213813408287583

Epoch: 6| Step: 3
Training loss: 0.27007465593153135
Validation loss: 2.3756369517604026

Epoch: 6| Step: 4
Training loss: 0.2610435886926262
Validation loss: 2.3912450083057455

Epoch: 6| Step: 5
Training loss: 0.38126848207294906
Validation loss: 2.3751401088127033

Epoch: 6| Step: 6
Training loss: 0.26445976091226664
Validation loss: 2.395785830875277

Epoch: 6| Step: 7
Training loss: 0.23252971936062908
Validation loss: 2.4110082004543916

Epoch: 6| Step: 8
Training loss: 0.30801168909820303
Validation loss: 2.4489038519489683

Epoch: 6| Step: 9
Training loss: 0.14799114929859666
Validation loss: 2.4348357685378237

Epoch: 6| Step: 10
Training loss: 0.3199663152325437
Validation loss: 2.436242247367491

Epoch: 6| Step: 11
Training loss: 0.49735553105501035
Validation loss: 2.4468116975334695

Epoch: 6| Step: 12
Training loss: 0.19679475995934148
Validation loss: 2.4242531153460862

Epoch: 6| Step: 13
Training loss: 0.30306943993814883
Validation loss: 2.3961433570304584

Epoch: 329| Step: 0
Training loss: 0.32357455220138803
Validation loss: 2.4237213866184275

Epoch: 6| Step: 1
Training loss: 0.25794690414525967
Validation loss: 2.387555529217054

Epoch: 6| Step: 2
Training loss: 0.26853758323993804
Validation loss: 2.422692712407698

Epoch: 6| Step: 3
Training loss: 0.3147668162361454
Validation loss: 2.365662524779845

Epoch: 6| Step: 4
Training loss: 0.5202191037046049
Validation loss: 2.430423064559032

Epoch: 6| Step: 5
Training loss: 0.33054539939138067
Validation loss: 2.4402250523789824

Epoch: 6| Step: 6
Training loss: 0.36031750773963944
Validation loss: 2.420141688672188

Epoch: 6| Step: 7
Training loss: 0.17980006051020087
Validation loss: 2.446030669704904

Epoch: 6| Step: 8
Training loss: 0.21328276644157146
Validation loss: 2.4157983841719446

Epoch: 6| Step: 9
Training loss: 0.214296510969375
Validation loss: 2.433193112380413

Epoch: 6| Step: 10
Training loss: 0.13392534762998393
Validation loss: 2.443424248944227

Epoch: 6| Step: 11
Training loss: 0.3104372610817396
Validation loss: 2.4280637130407157

Epoch: 6| Step: 12
Training loss: 0.4281956001877521
Validation loss: 2.459582903017872

Epoch: 6| Step: 13
Training loss: 0.21532263702868504
Validation loss: 2.4293230902784995

Epoch: 330| Step: 0
Training loss: 0.342694580484337
Validation loss: 2.435505711407231

Epoch: 6| Step: 1
Training loss: 0.2754127547659098
Validation loss: 2.3631898560458744

Epoch: 6| Step: 2
Training loss: 0.40280465697709367
Validation loss: 2.38229137190918

Epoch: 6| Step: 3
Training loss: 0.20664291128180984
Validation loss: 2.392014329994113

Epoch: 6| Step: 4
Training loss: 0.4108521869710315
Validation loss: 2.3592957725986894

Epoch: 6| Step: 5
Training loss: 0.2989878757292794
Validation loss: 2.3544347706408333

Epoch: 6| Step: 6
Training loss: 0.29141157211884466
Validation loss: 2.33888128773361

Epoch: 6| Step: 7
Training loss: 0.3502752579826454
Validation loss: 2.3538961629903046

Epoch: 6| Step: 8
Training loss: 0.3188232950014374
Validation loss: 2.3643935496329527

Epoch: 6| Step: 9
Training loss: 0.23302043647175263
Validation loss: 2.4187095284378297

Epoch: 6| Step: 10
Training loss: 0.27078037783509246
Validation loss: 2.417601537873185

Epoch: 6| Step: 11
Training loss: 0.2208070088537053
Validation loss: 2.452665948198863

Epoch: 6| Step: 12
Training loss: 0.32253794868224256
Validation loss: 2.480614153174286

Epoch: 6| Step: 13
Training loss: 0.13982500238328205
Validation loss: 2.4724460679595204

Epoch: 331| Step: 0
Training loss: 0.23420597180252342
Validation loss: 2.474921808284817

Epoch: 6| Step: 1
Training loss: 0.28808614439876046
Validation loss: 2.4456291686934764

Epoch: 6| Step: 2
Training loss: 0.2272909063687241
Validation loss: 2.4109800683908063

Epoch: 6| Step: 3
Training loss: 0.31308431833173356
Validation loss: 2.4501317918182055

Epoch: 6| Step: 4
Training loss: 0.36993381517227886
Validation loss: 2.4519002404472916

Epoch: 6| Step: 5
Training loss: 0.35910117041546613
Validation loss: 2.4384805317886498

Epoch: 6| Step: 6
Training loss: 0.2011047269734391
Validation loss: 2.4081975393258204

Epoch: 6| Step: 7
Training loss: 0.4585389593559506
Validation loss: 2.4540551295974113

Epoch: 6| Step: 8
Training loss: 0.21260522382985175
Validation loss: 2.4299110721500847

Epoch: 6| Step: 9
Training loss: 0.4034648202263468
Validation loss: 2.437517994324404

Epoch: 6| Step: 10
Training loss: 0.3323874526350593
Validation loss: 2.4586050736073584

Epoch: 6| Step: 11
Training loss: 0.17904762695617993
Validation loss: 2.412685098103295

Epoch: 6| Step: 12
Training loss: 0.3319915298938354
Validation loss: 2.410413079435441

Epoch: 6| Step: 13
Training loss: 0.19741320990690409
Validation loss: 2.416413675488071

Epoch: 332| Step: 0
Training loss: 0.3839614519822956
Validation loss: 2.4292446809578165

Epoch: 6| Step: 1
Training loss: 0.33451758312689434
Validation loss: 2.431189892483978

Epoch: 6| Step: 2
Training loss: 0.2499402466532684
Validation loss: 2.4427986967036808

Epoch: 6| Step: 3
Training loss: 0.1942847294648489
Validation loss: 2.4159128518370028

Epoch: 6| Step: 4
Training loss: 0.33114869125003343
Validation loss: 2.4284154313712984

Epoch: 6| Step: 5
Training loss: 0.22597086049422288
Validation loss: 2.392230081698

Epoch: 6| Step: 6
Training loss: 0.3959131494996299
Validation loss: 2.4130263047597538

Epoch: 6| Step: 7
Training loss: 0.17354324120196135
Validation loss: 2.410462296652147

Epoch: 6| Step: 8
Training loss: 0.37213124254402574
Validation loss: 2.3800635727440134

Epoch: 6| Step: 9
Training loss: 0.13170965999357298
Validation loss: 2.4039740824202958

Epoch: 6| Step: 10
Training loss: 0.2885253400119873
Validation loss: 2.420230075841432

Epoch: 6| Step: 11
Training loss: 0.4079625639196267
Validation loss: 2.4290042432589414

Epoch: 6| Step: 12
Training loss: 0.2698407262335617
Validation loss: 2.404055773964129

Epoch: 6| Step: 13
Training loss: 0.3277887028801442
Validation loss: 2.4259828247254838

Epoch: 333| Step: 0
Training loss: 0.27271873829232796
Validation loss: 2.4304995309337087

Epoch: 6| Step: 1
Training loss: 0.4664056806704626
Validation loss: 2.4489098336557182

Epoch: 6| Step: 2
Training loss: 0.39335326158760103
Validation loss: 2.435179852226295

Epoch: 6| Step: 3
Training loss: 0.2146149891277668
Validation loss: 2.451602513763394

Epoch: 6| Step: 4
Training loss: 0.19154473569313096
Validation loss: 2.4108009095153573

Epoch: 6| Step: 5
Training loss: 0.28038886481301517
Validation loss: 2.4170931870053716

Epoch: 6| Step: 6
Training loss: 0.36785402068481093
Validation loss: 2.379725282124709

Epoch: 6| Step: 7
Training loss: 0.3196468065041453
Validation loss: 2.3902101145319317

Epoch: 6| Step: 8
Training loss: 0.27538729726525835
Validation loss: 2.3935186203544987

Epoch: 6| Step: 9
Training loss: 0.20462960742197864
Validation loss: 2.3505250943267484

Epoch: 6| Step: 10
Training loss: 0.37433635082299677
Validation loss: 2.414709532071323

Epoch: 6| Step: 11
Training loss: 0.11070281645867122
Validation loss: 2.3995052525008638

Epoch: 6| Step: 12
Training loss: 0.336838688919348
Validation loss: 2.429872041880855

Epoch: 6| Step: 13
Training loss: 0.29876613597308466
Validation loss: 2.44871836363329

Epoch: 334| Step: 0
Training loss: 0.4732562741187643
Validation loss: 2.4278789439566735

Epoch: 6| Step: 1
Training loss: 0.18158292366621778
Validation loss: 2.430424686332714

Epoch: 6| Step: 2
Training loss: 0.3642415715501146
Validation loss: 2.443537735121334

Epoch: 6| Step: 3
Training loss: 0.45761706636747157
Validation loss: 2.457202706302919

Epoch: 6| Step: 4
Training loss: 0.20601991839197192
Validation loss: 2.473344156206863

Epoch: 6| Step: 5
Training loss: 0.20220198359785213
Validation loss: 2.467296454369537

Epoch: 6| Step: 6
Training loss: 0.31924474504846334
Validation loss: 2.4309248482467423

Epoch: 6| Step: 7
Training loss: 0.1752359302773168
Validation loss: 2.484164414213591

Epoch: 6| Step: 8
Training loss: 0.19808510255270906
Validation loss: 2.4506295755761993

Epoch: 6| Step: 9
Training loss: 0.3844838538754455
Validation loss: 2.414012704127187

Epoch: 6| Step: 10
Training loss: 0.253556230346706
Validation loss: 2.39953302549806

Epoch: 6| Step: 11
Training loss: 0.21251832272971552
Validation loss: 2.4189717081712754

Epoch: 6| Step: 12
Training loss: 0.09305329025246964
Validation loss: 2.41043774560155

Epoch: 6| Step: 13
Training loss: 0.27018310669312623
Validation loss: 2.3970710539125277

Epoch: 335| Step: 0
Training loss: 0.21641940686274957
Validation loss: 2.4118771273213744

Epoch: 6| Step: 1
Training loss: 0.43463970873225605
Validation loss: 2.4124876655256076

Epoch: 6| Step: 2
Training loss: 0.42837853894804734
Validation loss: 2.4037547646718043

Epoch: 6| Step: 3
Training loss: 0.30250667499633677
Validation loss: 2.3927244270334147

Epoch: 6| Step: 4
Training loss: 0.3029095788770999
Validation loss: 2.3740436612503486

Epoch: 6| Step: 5
Training loss: 0.21487913707258977
Validation loss: 2.4096147195409676

Epoch: 6| Step: 6
Training loss: 0.24568869543840055
Validation loss: 2.3949555945768624

Epoch: 6| Step: 7
Training loss: 0.16779183896350122
Validation loss: 2.389528605284671

Epoch: 6| Step: 8
Training loss: 0.3139192301837327
Validation loss: 2.4412096842072106

Epoch: 6| Step: 9
Training loss: 0.17605687890171193
Validation loss: 2.4145044966257942

Epoch: 6| Step: 10
Training loss: 0.09612603071798621
Validation loss: 2.413379043982883

Epoch: 6| Step: 11
Training loss: 0.305117242920792
Validation loss: 2.405707175697412

Epoch: 6| Step: 12
Training loss: 0.3888731775440366
Validation loss: 2.442050419049727

Epoch: 6| Step: 13
Training loss: 0.09627486737523717
Validation loss: 2.4463325696880167

Epoch: 336| Step: 0
Training loss: 0.32750380843255905
Validation loss: 2.439652087386615

Epoch: 6| Step: 1
Training loss: 0.17506283074933002
Validation loss: 2.451313053724984

Epoch: 6| Step: 2
Training loss: 0.42809118777777494
Validation loss: 2.439091874397877

Epoch: 6| Step: 3
Training loss: 0.22326820335418437
Validation loss: 2.4486053761682656

Epoch: 6| Step: 4
Training loss: 0.28120894927212065
Validation loss: 2.4542766433655454

Epoch: 6| Step: 5
Training loss: 0.29218532082056137
Validation loss: 2.4517316020241484

Epoch: 6| Step: 6
Training loss: 0.33750878516878446
Validation loss: 2.4535008676745824

Epoch: 6| Step: 7
Training loss: 0.3324539299110852
Validation loss: 2.419655990623324

Epoch: 6| Step: 8
Training loss: 0.10038270603666821
Validation loss: 2.391719245168342

Epoch: 6| Step: 9
Training loss: 0.2433659890930837
Validation loss: 2.414415179153259

Epoch: 6| Step: 10
Training loss: 0.2268632996644836
Validation loss: 2.3891632449649944

Epoch: 6| Step: 11
Training loss: 0.19145721613364652
Validation loss: 2.3766110606246094

Epoch: 6| Step: 12
Training loss: 0.43417453531150446
Validation loss: 2.3487745782094835

Epoch: 6| Step: 13
Training loss: 0.2994314846835172
Validation loss: 2.359881900695321

Epoch: 337| Step: 0
Training loss: 0.3219309600776043
Validation loss: 2.360561002949039

Epoch: 6| Step: 1
Training loss: 0.268869070356594
Validation loss: 2.351623044883299

Epoch: 6| Step: 2
Training loss: 0.3416966209520014
Validation loss: 2.383313760763848

Epoch: 6| Step: 3
Training loss: 0.21716715147899204
Validation loss: 2.376092866573056

Epoch: 6| Step: 4
Training loss: 0.27505711049158943
Validation loss: 2.38539420485965

Epoch: 6| Step: 5
Training loss: 0.21439984151250316
Validation loss: 2.374329617525391

Epoch: 6| Step: 6
Training loss: 0.19638424553587128
Validation loss: 2.4102319946927624

Epoch: 6| Step: 7
Training loss: 0.1464403594963412
Validation loss: 2.4337422070449914

Epoch: 6| Step: 8
Training loss: 0.337017507843286
Validation loss: 2.432802800136607

Epoch: 6| Step: 9
Training loss: 0.22528633435306586
Validation loss: 2.4408932437852346

Epoch: 6| Step: 10
Training loss: 0.46881900915161673
Validation loss: 2.4413058756878154

Epoch: 6| Step: 11
Training loss: 0.17145112177962146
Validation loss: 2.4731063735036867

Epoch: 6| Step: 12
Training loss: 0.26091770451090657
Validation loss: 2.4692118638306746

Epoch: 6| Step: 13
Training loss: 0.442868738473099
Validation loss: 2.439375842108419

Epoch: 338| Step: 0
Training loss: 0.3248537348854452
Validation loss: 2.450854744648122

Epoch: 6| Step: 1
Training loss: 0.23735960179797022
Validation loss: 2.4352584515330475

Epoch: 6| Step: 2
Training loss: 0.2487927284395885
Validation loss: 2.4465887492524563

Epoch: 6| Step: 3
Training loss: 0.22542364714902854
Validation loss: 2.422225282169208

Epoch: 6| Step: 4
Training loss: 0.3111789915749329
Validation loss: 2.4218447341642073

Epoch: 6| Step: 5
Training loss: 0.15921629151345157
Validation loss: 2.4025423992418014

Epoch: 6| Step: 6
Training loss: 0.25977050088307485
Validation loss: 2.397937558613767

Epoch: 6| Step: 7
Training loss: 0.3482937272422329
Validation loss: 2.3840866321554697

Epoch: 6| Step: 8
Training loss: 0.24661858165014702
Validation loss: 2.367869559877054

Epoch: 6| Step: 9
Training loss: 0.22788515088944877
Validation loss: 2.3805061258699864

Epoch: 6| Step: 10
Training loss: 0.306518518226831
Validation loss: 2.3616675289691273

Epoch: 6| Step: 11
Training loss: 0.46161046444619347
Validation loss: 2.3376904314677556

Epoch: 6| Step: 12
Training loss: 0.14672030205357664
Validation loss: 2.3637064867907105

Epoch: 6| Step: 13
Training loss: 0.3018444517131215
Validation loss: 2.3701599383054015

Epoch: 339| Step: 0
Training loss: 0.38270645229740496
Validation loss: 2.335899767569382

Epoch: 6| Step: 1
Training loss: 0.3182539267930756
Validation loss: 2.3313199996830978

Epoch: 6| Step: 2
Training loss: 0.16972880521111258
Validation loss: 2.3426819498669014

Epoch: 6| Step: 3
Training loss: 0.11956819044521304
Validation loss: 2.3595245037970605

Epoch: 6| Step: 4
Training loss: 0.24260485742917506
Validation loss: 2.3445052550940924

Epoch: 6| Step: 5
Training loss: 0.38530354729961724
Validation loss: 2.3960771013098072

Epoch: 6| Step: 6
Training loss: 0.3664968773004954
Validation loss: 2.389289702874521

Epoch: 6| Step: 7
Training loss: 0.26044850472694586
Validation loss: 2.4068849320139827

Epoch: 6| Step: 8
Training loss: 0.18335455673186973
Validation loss: 2.447384362260801

Epoch: 6| Step: 9
Training loss: 0.16291004678036275
Validation loss: 2.4540965879426033

Epoch: 6| Step: 10
Training loss: 0.24921968992050053
Validation loss: 2.4520844206199155

Epoch: 6| Step: 11
Training loss: 0.1739404294133618
Validation loss: 2.447564957556225

Epoch: 6| Step: 12
Training loss: 0.4588248117549088
Validation loss: 2.4242359166810177

Epoch: 6| Step: 13
Training loss: 0.14992761554233508
Validation loss: 2.4660633650873502

Epoch: 340| Step: 0
Training loss: 0.16325963643865085
Validation loss: 2.438336333809758

Epoch: 6| Step: 1
Training loss: 0.410861852521983
Validation loss: 2.4193113341231287

Epoch: 6| Step: 2
Training loss: 0.15134549139258813
Validation loss: 2.442910712319528

Epoch: 6| Step: 3
Training loss: 0.43716997232810123
Validation loss: 2.4420135637865252

Epoch: 6| Step: 4
Training loss: 0.2752813162879894
Validation loss: 2.410887556809707

Epoch: 6| Step: 5
Training loss: 0.23641803701985403
Validation loss: 2.439488296533075

Epoch: 6| Step: 6
Training loss: 0.234923801039985
Validation loss: 2.456290843149885

Epoch: 6| Step: 7
Training loss: 0.13470134031164196
Validation loss: 2.4409199028348074

Epoch: 6| Step: 8
Training loss: 0.3031323677819303
Validation loss: 2.4379985100776604

Epoch: 6| Step: 9
Training loss: 0.25416598606539625
Validation loss: 2.4667224364376894

Epoch: 6| Step: 10
Training loss: 0.37452659925518256
Validation loss: 2.433903290505092

Epoch: 6| Step: 11
Training loss: 0.25222633393708427
Validation loss: 2.432155856103946

Epoch: 6| Step: 12
Training loss: 0.19591580672388395
Validation loss: 2.413804373351637

Epoch: 6| Step: 13
Training loss: 0.19872477005419648
Validation loss: 2.415856235754427

Epoch: 341| Step: 0
Training loss: 0.26308259459186306
Validation loss: 2.4218749576585803

Epoch: 6| Step: 1
Training loss: 0.5265229513105385
Validation loss: 2.4160467617961694

Epoch: 6| Step: 2
Training loss: 0.25737271222936114
Validation loss: 2.382839867219352

Epoch: 6| Step: 3
Training loss: 0.3245029008593159
Validation loss: 2.382701972483878

Epoch: 6| Step: 4
Training loss: 0.20566379840540436
Validation loss: 2.414521687630334

Epoch: 6| Step: 5
Training loss: 0.43063811139657987
Validation loss: 2.3698043575891368

Epoch: 6| Step: 6
Training loss: 0.21240899963473697
Validation loss: 2.3948140459052905

Epoch: 6| Step: 7
Training loss: 0.1281325210131636
Validation loss: 2.3865681654406488

Epoch: 6| Step: 8
Training loss: 0.26021764620742344
Validation loss: 2.393964462463972

Epoch: 6| Step: 9
Training loss: 0.3209586372026569
Validation loss: 2.355060767694389

Epoch: 6| Step: 10
Training loss: 0.2257756843012895
Validation loss: 2.412420128111117

Epoch: 6| Step: 11
Training loss: 0.21452821622455176
Validation loss: 2.3971458656253657

Epoch: 6| Step: 12
Training loss: 0.22824768105495674
Validation loss: 2.433848469615659

Epoch: 6| Step: 13
Training loss: 0.2612293849459118
Validation loss: 2.417146681920005

Epoch: 342| Step: 0
Training loss: 0.20476078730708114
Validation loss: 2.409871966256496

Epoch: 6| Step: 1
Training loss: 0.2000611483704928
Validation loss: 2.434235520010559

Epoch: 6| Step: 2
Training loss: 0.2330935254211612
Validation loss: 2.46466972662816

Epoch: 6| Step: 3
Training loss: 0.4314533189727465
Validation loss: 2.4462997456267117

Epoch: 6| Step: 4
Training loss: 0.29222281543464385
Validation loss: 2.441619160743096

Epoch: 6| Step: 5
Training loss: 0.2929889163388083
Validation loss: 2.4055591002086594

Epoch: 6| Step: 6
Training loss: 0.19079843667087634
Validation loss: 2.410634316097173

Epoch: 6| Step: 7
Training loss: 0.28835071099059545
Validation loss: 2.406207327856545

Epoch: 6| Step: 8
Training loss: 0.4015881192536364
Validation loss: 2.4052185076569415

Epoch: 6| Step: 9
Training loss: 0.12264884042530927
Validation loss: 2.4018644606940978

Epoch: 6| Step: 10
Training loss: 0.261254582228014
Validation loss: 2.4148205851379894

Epoch: 6| Step: 11
Training loss: 0.22803109306830868
Validation loss: 2.4043099432257113

Epoch: 6| Step: 12
Training loss: 0.38289789298397636
Validation loss: 2.4183969993310166

Epoch: 6| Step: 13
Training loss: 0.2334219789004923
Validation loss: 2.3881856387072355

Epoch: 343| Step: 0
Training loss: 0.32559110137377667
Validation loss: 2.3842491220860365

Epoch: 6| Step: 1
Training loss: 0.23396860493038588
Validation loss: 2.401843008909276

Epoch: 6| Step: 2
Training loss: 0.19624581501076352
Validation loss: 2.3840611513896643

Epoch: 6| Step: 3
Training loss: 0.2119662576551666
Validation loss: 2.411195829531026

Epoch: 6| Step: 4
Training loss: 0.1834573035784893
Validation loss: 2.4062471729353048

Epoch: 6| Step: 5
Training loss: 0.22136194084577657
Validation loss: 2.372935094225866

Epoch: 6| Step: 6
Training loss: 0.3315406091350472
Validation loss: 2.40564321563016

Epoch: 6| Step: 7
Training loss: 0.268535197157624
Validation loss: 2.400182624289703

Epoch: 6| Step: 8
Training loss: 0.2914696550294885
Validation loss: 2.3813583641339098

Epoch: 6| Step: 9
Training loss: 0.25668349292693526
Validation loss: 2.404321366136041

Epoch: 6| Step: 10
Training loss: 0.4208763453091317
Validation loss: 2.3888305346277696

Epoch: 6| Step: 11
Training loss: 0.3375465316837816
Validation loss: 2.3950351403785506

Epoch: 6| Step: 12
Training loss: 0.15691302413349958
Validation loss: 2.4046697073846333

Epoch: 6| Step: 13
Training loss: 0.20692639124578774
Validation loss: 2.3906851378963894

Epoch: 344| Step: 0
Training loss: 0.14878375676139957
Validation loss: 2.399031963285936

Epoch: 6| Step: 1
Training loss: 0.22858141090742662
Validation loss: 2.418717888284029

Epoch: 6| Step: 2
Training loss: 0.1299686291788782
Validation loss: 2.428319066574208

Epoch: 6| Step: 3
Training loss: 0.49350646568012746
Validation loss: 2.408375238745986

Epoch: 6| Step: 4
Training loss: 0.3808380903507575
Validation loss: 2.4254824295609083

Epoch: 6| Step: 5
Training loss: 0.23628745241352864
Validation loss: 2.3948356093593457

Epoch: 6| Step: 6
Training loss: 0.20639380802308172
Validation loss: 2.408213442548198

Epoch: 6| Step: 7
Training loss: 0.2609627608675319
Validation loss: 2.421069644501338

Epoch: 6| Step: 8
Training loss: 0.16070755415113447
Validation loss: 2.417296138448337

Epoch: 6| Step: 9
Training loss: 0.16332809378611712
Validation loss: 2.405552603600692

Epoch: 6| Step: 10
Training loss: 0.2843163676129867
Validation loss: 2.4280493937307925

Epoch: 6| Step: 11
Training loss: 0.16563855151751739
Validation loss: 2.4360677562090784

Epoch: 6| Step: 12
Training loss: 0.30070910889124397
Validation loss: 2.408477130750859

Epoch: 6| Step: 13
Training loss: 0.1686111519169937
Validation loss: 2.4571637871515883

Epoch: 345| Step: 0
Training loss: 0.13216754041184908
Validation loss: 2.4426056503381495

Epoch: 6| Step: 1
Training loss: 0.25324975753972157
Validation loss: 2.4592715743363462

Epoch: 6| Step: 2
Training loss: 0.2067485174312735
Validation loss: 2.4340889946495894

Epoch: 6| Step: 3
Training loss: 0.3155651569288602
Validation loss: 2.47855917985756

Epoch: 6| Step: 4
Training loss: 0.20526426133281211
Validation loss: 2.484274210697358

Epoch: 6| Step: 5
Training loss: 0.22088650874436308
Validation loss: 2.443874159026256

Epoch: 6| Step: 6
Training loss: 0.31291364473203526
Validation loss: 2.4156723243452203

Epoch: 6| Step: 7
Training loss: 0.21986260335315694
Validation loss: 2.4201743763985992

Epoch: 6| Step: 8
Training loss: 0.20175683980524503
Validation loss: 2.4082883413853895

Epoch: 6| Step: 9
Training loss: 0.28590382601792097
Validation loss: 2.423078177122578

Epoch: 6| Step: 10
Training loss: 0.29784490859306934
Validation loss: 2.424098832184979

Epoch: 6| Step: 11
Training loss: 0.43368506973471865
Validation loss: 2.4171112727940387

Epoch: 6| Step: 12
Training loss: 0.1791810590393386
Validation loss: 2.433058341180521

Epoch: 6| Step: 13
Training loss: 0.1609233245810248
Validation loss: 2.4368514425279244

Epoch: 346| Step: 0
Training loss: 0.2323670603122664
Validation loss: 2.4068246364905286

Epoch: 6| Step: 1
Training loss: 0.2983916966505493
Validation loss: 2.4372333510126976

Epoch: 6| Step: 2
Training loss: 0.22862802496244267
Validation loss: 2.3850008465133428

Epoch: 6| Step: 3
Training loss: 0.3081196390269806
Validation loss: 2.403245134021963

Epoch: 6| Step: 4
Training loss: 0.18957362324786844
Validation loss: 2.373842737857502

Epoch: 6| Step: 5
Training loss: 0.22015933333133622
Validation loss: 2.4134269345237196

Epoch: 6| Step: 6
Training loss: 0.12137112459783508
Validation loss: 2.4154228924934213

Epoch: 6| Step: 7
Training loss: 0.4432976129340234
Validation loss: 2.3872097885070978

Epoch: 6| Step: 8
Training loss: 0.30942240650439756
Validation loss: 2.3891830733793236

Epoch: 6| Step: 9
Training loss: 0.1932240985880923
Validation loss: 2.3891461655067636

Epoch: 6| Step: 10
Training loss: 0.3028999860063325
Validation loss: 2.404375255033489

Epoch: 6| Step: 11
Training loss: 0.15869559649290552
Validation loss: 2.380044329448775

Epoch: 6| Step: 12
Training loss: 0.2587513734255843
Validation loss: 2.3835918193692667

Epoch: 6| Step: 13
Training loss: 0.10325397857119702
Validation loss: 2.390606252709513

Epoch: 347| Step: 0
Training loss: 0.4379815108542528
Validation loss: 2.4165695059158843

Epoch: 6| Step: 1
Training loss: 0.1835688310310045
Validation loss: 2.38855074714906

Epoch: 6| Step: 2
Training loss: 0.1824965460986074
Validation loss: 2.433072615206436

Epoch: 6| Step: 3
Training loss: 0.22052297582262792
Validation loss: 2.4068605798683596

Epoch: 6| Step: 4
Training loss: 0.19409598100098926
Validation loss: 2.425123834276078

Epoch: 6| Step: 5
Training loss: 0.15089106587913106
Validation loss: 2.438110323008064

Epoch: 6| Step: 6
Training loss: 0.22416357497975006
Validation loss: 2.4163567984750993

Epoch: 6| Step: 7
Training loss: 0.18386695702957545
Validation loss: 2.4508277645314833

Epoch: 6| Step: 8
Training loss: 0.17445864070367656
Validation loss: 2.4127963378496182

Epoch: 6| Step: 9
Training loss: 0.5181043720625621
Validation loss: 2.4261921681274377

Epoch: 6| Step: 10
Training loss: 0.12487302977494039
Validation loss: 2.427470548175312

Epoch: 6| Step: 11
Training loss: 0.13142266666499097
Validation loss: 2.441922590098127

Epoch: 6| Step: 12
Training loss: 0.31861316183987454
Validation loss: 2.4283823248783523

Epoch: 6| Step: 13
Training loss: 0.13303975689360853
Validation loss: 2.413022672352634

Epoch: 348| Step: 0
Training loss: 0.12890170551728022
Validation loss: 2.4369492036036324

Epoch: 6| Step: 1
Training loss: 0.2273424633553398
Validation loss: 2.42990245883107

Epoch: 6| Step: 2
Training loss: 0.45373712497761787
Validation loss: 2.463547705794448

Epoch: 6| Step: 3
Training loss: 0.15983711988695215
Validation loss: 2.4509185896783983

Epoch: 6| Step: 4
Training loss: 0.20684392119390627
Validation loss: 2.4372328913476173

Epoch: 6| Step: 5
Training loss: 0.27461301982951464
Validation loss: 2.443714218018258

Epoch: 6| Step: 6
Training loss: 0.22994191358829963
Validation loss: 2.452253883663127

Epoch: 6| Step: 7
Training loss: 0.19493846364041492
Validation loss: 2.4394094446717056

Epoch: 6| Step: 8
Training loss: 0.3759338751005353
Validation loss: 2.449602159900755

Epoch: 6| Step: 9
Training loss: 0.17677102645461848
Validation loss: 2.4247981547029847

Epoch: 6| Step: 10
Training loss: 0.2541234921046158
Validation loss: 2.4560668582288927

Epoch: 6| Step: 11
Training loss: 0.1740110431457389
Validation loss: 2.4730371318175592

Epoch: 6| Step: 12
Training loss: 0.34199831884651355
Validation loss: 2.4705840909967995

Epoch: 6| Step: 13
Training loss: 0.17839848454263668
Validation loss: 2.4784571020943873

Epoch: 349| Step: 0
Training loss: 0.1765389536457897
Validation loss: 2.4496036983344696

Epoch: 6| Step: 1
Training loss: 0.480742027906951
Validation loss: 2.4403479419286924

Epoch: 6| Step: 2
Training loss: 0.17019195577845359
Validation loss: 2.443787234678095

Epoch: 6| Step: 3
Training loss: 0.19929717894934337
Validation loss: 2.44503997371283

Epoch: 6| Step: 4
Training loss: 0.1959736790786132
Validation loss: 2.4077476882056086

Epoch: 6| Step: 5
Training loss: 0.16899338628098512
Validation loss: 2.3982210421370405

Epoch: 6| Step: 6
Training loss: 0.22735366308091898
Validation loss: 2.385916127821829

Epoch: 6| Step: 7
Training loss: 0.18616405036801684
Validation loss: 2.40357449233847

Epoch: 6| Step: 8
Training loss: 0.313827508342233
Validation loss: 2.396856131573439

Epoch: 6| Step: 9
Training loss: 0.17721149537761724
Validation loss: 2.3988372254796784

Epoch: 6| Step: 10
Training loss: 0.35099612283942694
Validation loss: 2.3989317534597157

Epoch: 6| Step: 11
Training loss: 0.1665914870119
Validation loss: 2.4042754619785733

Epoch: 6| Step: 12
Training loss: 0.32831090247598693
Validation loss: 2.3994954803252053

Epoch: 6| Step: 13
Training loss: 0.22009744496394196
Validation loss: 2.4167244352310933

Epoch: 350| Step: 0
Training loss: 0.22350735872750568
Validation loss: 2.435427427979072

Epoch: 6| Step: 1
Training loss: 0.421845382074615
Validation loss: 2.4108288671475564

Epoch: 6| Step: 2
Training loss: 0.39767358513540413
Validation loss: 2.4163309620131344

Epoch: 6| Step: 3
Training loss: 0.1898302081266419
Validation loss: 2.426646453434358

Epoch: 6| Step: 4
Training loss: 0.22717831219193532
Validation loss: 2.4324284631636446

Epoch: 6| Step: 5
Training loss: 0.2251771467943201
Validation loss: 2.3999156719820722

Epoch: 6| Step: 6
Training loss: 0.3080363127996818
Validation loss: 2.437408300399239

Epoch: 6| Step: 7
Training loss: 0.1419471273063203
Validation loss: 2.416399947042319

Epoch: 6| Step: 8
Training loss: 0.08994667750184056
Validation loss: 2.403405848146679

Epoch: 6| Step: 9
Training loss: 0.2715465968340382
Validation loss: 2.4010940349230467

Epoch: 6| Step: 10
Training loss: 0.2924372875198991
Validation loss: 2.4120286034986025

Epoch: 6| Step: 11
Training loss: 0.16988431581212285
Validation loss: 2.4153501190388402

Epoch: 6| Step: 12
Training loss: 0.16678276091633337
Validation loss: 2.4241936547275222

Epoch: 6| Step: 13
Training loss: 0.1862990742554958
Validation loss: 2.4162326553148548

Epoch: 351| Step: 0
Training loss: 0.21109627117229815
Validation loss: 2.4329683719022706

Epoch: 6| Step: 1
Training loss: 0.3008832387045825
Validation loss: 2.431777201592384

Epoch: 6| Step: 2
Training loss: 0.4026735306074787
Validation loss: 2.4180131039060258

Epoch: 6| Step: 3
Training loss: 0.19270700162135318
Validation loss: 2.4136726860340283

Epoch: 6| Step: 4
Training loss: 0.2598073395241117
Validation loss: 2.4174511792056226

Epoch: 6| Step: 5
Training loss: 0.2172816329841854
Validation loss: 2.3831701523002495

Epoch: 6| Step: 6
Training loss: 0.2397477330542184
Validation loss: 2.3990978761332955

Epoch: 6| Step: 7
Training loss: 0.2954449215443635
Validation loss: 2.405547977314539

Epoch: 6| Step: 8
Training loss: 0.1381517380299277
Validation loss: 2.396745134990755

Epoch: 6| Step: 9
Training loss: 0.29775985806910804
Validation loss: 2.3870018176800354

Epoch: 6| Step: 10
Training loss: 0.13670087424991442
Validation loss: 2.4017650548530556

Epoch: 6| Step: 11
Training loss: 0.28702022180360354
Validation loss: 2.374292811321785

Epoch: 6| Step: 12
Training loss: 0.1635825083895284
Validation loss: 2.3737444632615756

Epoch: 6| Step: 13
Training loss: 0.23938472262425578
Validation loss: 2.4142219333373545

Epoch: 352| Step: 0
Training loss: 0.29136994572939917
Validation loss: 2.3951977143898815

Epoch: 6| Step: 1
Training loss: 0.1934038361574256
Validation loss: 2.4041255207016703

Epoch: 6| Step: 2
Training loss: 0.2678334625880205
Validation loss: 2.4116828548335603

Epoch: 6| Step: 3
Training loss: 0.18672391094273735
Validation loss: 2.4298452655761555

Epoch: 6| Step: 4
Training loss: 0.15296112190569416
Validation loss: 2.4271069231136404

Epoch: 6| Step: 5
Training loss: 0.20903716802011243
Validation loss: 2.462297220263135

Epoch: 6| Step: 6
Training loss: 0.15753404393184492
Validation loss: 2.4426600254262936

Epoch: 6| Step: 7
Training loss: 0.2513666053652599
Validation loss: 2.4522629134807032

Epoch: 6| Step: 8
Training loss: 0.33074054047658885
Validation loss: 2.470589942387358

Epoch: 6| Step: 9
Training loss: 0.3168715364315792
Validation loss: 2.4569971330128904

Epoch: 6| Step: 10
Training loss: 0.44978128124696265
Validation loss: 2.462145224713079

Epoch: 6| Step: 11
Training loss: 0.25592411474361915
Validation loss: 2.409072371391316

Epoch: 6| Step: 12
Training loss: 0.16181069170036097
Validation loss: 2.4508547598153974

Epoch: 6| Step: 13
Training loss: 0.26124258993673316
Validation loss: 2.396831386603777

Epoch: 353| Step: 0
Training loss: 0.24417037782571951
Validation loss: 2.4126356382695637

Epoch: 6| Step: 1
Training loss: 0.16628023825367935
Validation loss: 2.3868105646667077

Epoch: 6| Step: 2
Training loss: 0.2378681463511107
Validation loss: 2.3894066888157397

Epoch: 6| Step: 3
Training loss: 0.1352815565360005
Validation loss: 2.362958416354959

Epoch: 6| Step: 4
Training loss: 0.2837840731576662
Validation loss: 2.3662607295767897

Epoch: 6| Step: 5
Training loss: 0.4402609965171171
Validation loss: 2.349595306414103

Epoch: 6| Step: 6
Training loss: 0.2692648635487805
Validation loss: 2.3460690713239916

Epoch: 6| Step: 7
Training loss: 0.3680288537054249
Validation loss: 2.400393456826231

Epoch: 6| Step: 8
Training loss: 0.18956290338462625
Validation loss: 2.3836883247918332

Epoch: 6| Step: 9
Training loss: 0.18381047139350312
Validation loss: 2.4314415342289077

Epoch: 6| Step: 10
Training loss: 0.3662377716405608
Validation loss: 2.4234507874858795

Epoch: 6| Step: 11
Training loss: 0.2719521095281029
Validation loss: 2.4607002733842793

Epoch: 6| Step: 12
Training loss: 0.24162240397207763
Validation loss: 2.47854090478391

Epoch: 6| Step: 13
Training loss: 0.09856831925411536
Validation loss: 2.4609596981955746

Epoch: 354| Step: 0
Training loss: 0.3363912977199232
Validation loss: 2.4487790283803537

Epoch: 6| Step: 1
Training loss: 0.23038956526457263
Validation loss: 2.484814573563201

Epoch: 6| Step: 2
Training loss: 0.31532828056158085
Validation loss: 2.4581889361616462

Epoch: 6| Step: 3
Training loss: 0.16652399652267785
Validation loss: 2.4368378155462302

Epoch: 6| Step: 4
Training loss: 0.1974657761823309
Validation loss: 2.465813713702511

Epoch: 6| Step: 5
Training loss: 0.35031343670940135
Validation loss: 2.418758612608912

Epoch: 6| Step: 6
Training loss: 0.25353207527476773
Validation loss: 2.440959927491036

Epoch: 6| Step: 7
Training loss: 0.45520125921180815
Validation loss: 2.4241613196874994

Epoch: 6| Step: 8
Training loss: 0.21629533231913006
Validation loss: 2.4419940580495956

Epoch: 6| Step: 9
Training loss: 0.14427826623555873
Validation loss: 2.453507586313623

Epoch: 6| Step: 10
Training loss: 0.11702634538831837
Validation loss: 2.4677443308948996

Epoch: 6| Step: 11
Training loss: 0.23705815825746926
Validation loss: 2.441577383955014

Epoch: 6| Step: 12
Training loss: 0.295623021633311
Validation loss: 2.47139273199255

Epoch: 6| Step: 13
Training loss: 0.35031587192433694
Validation loss: 2.454275986336852

Epoch: 355| Step: 0
Training loss: 0.1662567071171219
Validation loss: 2.4362435059095806

Epoch: 6| Step: 1
Training loss: 0.12057979403120826
Validation loss: 2.424916628296781

Epoch: 6| Step: 2
Training loss: 0.3522286567570731
Validation loss: 2.413276833101914

Epoch: 6| Step: 3
Training loss: 0.1579664602972122
Validation loss: 2.4475095497196513

Epoch: 6| Step: 4
Training loss: 0.24468790892253825
Validation loss: 2.4208371736268948

Epoch: 6| Step: 5
Training loss: 0.288368991225351
Validation loss: 2.377075582589796

Epoch: 6| Step: 6
Training loss: 0.1664488189496228
Validation loss: 2.404505015583507

Epoch: 6| Step: 7
Training loss: 0.12665645708669077
Validation loss: 2.394883642169243

Epoch: 6| Step: 8
Training loss: 0.23750390218992382
Validation loss: 2.4309410847336252

Epoch: 6| Step: 9
Training loss: 0.29804827338574336
Validation loss: 2.423062878780519

Epoch: 6| Step: 10
Training loss: 0.4696226580056021
Validation loss: 2.4155295868427893

Epoch: 6| Step: 11
Training loss: 0.13937186483526282
Validation loss: 2.41629783424

Epoch: 6| Step: 12
Training loss: 0.17746062733620793
Validation loss: 2.429090023553673

Epoch: 6| Step: 13
Training loss: 0.29677912770243814
Validation loss: 2.4240279817375026

Epoch: 356| Step: 0
Training loss: 0.21258815661800157
Validation loss: 2.4447309288696606

Epoch: 6| Step: 1
Training loss: 0.1158555470951273
Validation loss: 2.4235611332467832

Epoch: 6| Step: 2
Training loss: 0.33889770370407823
Validation loss: 2.4386058283602

Epoch: 6| Step: 3
Training loss: 0.2637593018441814
Validation loss: 2.441304164532355

Epoch: 6| Step: 4
Training loss: 0.3746417838070464
Validation loss: 2.4373248215866656

Epoch: 6| Step: 5
Training loss: 0.33571412178335563
Validation loss: 2.4222706207306373

Epoch: 6| Step: 6
Training loss: 0.1986000326559956
Validation loss: 2.445031892334584

Epoch: 6| Step: 7
Training loss: 0.23470446159592215
Validation loss: 2.4428008197778244

Epoch: 6| Step: 8
Training loss: 0.2828040501085667
Validation loss: 2.4428839299115683

Epoch: 6| Step: 9
Training loss: 0.4428724900868199
Validation loss: 2.461379535468437

Epoch: 6| Step: 10
Training loss: 0.21018408516540993
Validation loss: 2.4374561184913284

Epoch: 6| Step: 11
Training loss: 0.2821224112867272
Validation loss: 2.492289387765021

Epoch: 6| Step: 12
Training loss: 0.1537239386696221
Validation loss: 2.458613138524407

Epoch: 6| Step: 13
Training loss: 0.20546363744430735
Validation loss: 2.4310234824947132

Epoch: 357| Step: 0
Training loss: 0.2203682409614226
Validation loss: 2.4023331767390697

Epoch: 6| Step: 1
Training loss: 0.18159389920311428
Validation loss: 2.393139315819694

Epoch: 6| Step: 2
Training loss: 0.1621807297541219
Validation loss: 2.40416180353943

Epoch: 6| Step: 3
Training loss: 0.15159954571973555
Validation loss: 2.39207638564017

Epoch: 6| Step: 4
Training loss: 0.08966310626260691
Validation loss: 2.382303491185495

Epoch: 6| Step: 5
Training loss: 0.22315142597924117
Validation loss: 2.3593049821662437

Epoch: 6| Step: 6
Training loss: 0.21822897987691553
Validation loss: 2.3911594230778928

Epoch: 6| Step: 7
Training loss: 0.3660463293788532
Validation loss: 2.4036826629069314

Epoch: 6| Step: 8
Training loss: 0.24331261413663652
Validation loss: 2.3553143514297497

Epoch: 6| Step: 9
Training loss: 0.14547245184821353
Validation loss: 2.3711409982286176

Epoch: 6| Step: 10
Training loss: 0.22365783984472137
Validation loss: 2.367515589692208

Epoch: 6| Step: 11
Training loss: 0.4383218403072195
Validation loss: 2.4038285621144513

Epoch: 6| Step: 12
Training loss: 0.28123124377969594
Validation loss: 2.382481047334093

Epoch: 6| Step: 13
Training loss: 0.42833876041704816
Validation loss: 2.376180805387906

Epoch: 358| Step: 0
Training loss: 0.15489998778736566
Validation loss: 2.3726322793807753

Epoch: 6| Step: 1
Training loss: 0.23726546194895548
Validation loss: 2.3885241219553497

Epoch: 6| Step: 2
Training loss: 0.19868637458072147
Validation loss: 2.4094469311685405

Epoch: 6| Step: 3
Training loss: 0.2581942650548859
Validation loss: 2.4099542142181245

Epoch: 6| Step: 4
Training loss: 0.28065178087051074
Validation loss: 2.4199842743755466

Epoch: 6| Step: 5
Training loss: 0.08485010196203951
Validation loss: 2.452561926714109

Epoch: 6| Step: 6
Training loss: 0.20098349630630397
Validation loss: 2.430796605085175

Epoch: 6| Step: 7
Training loss: 0.1467999619184251
Validation loss: 2.4389465631571836

Epoch: 6| Step: 8
Training loss: 0.3074734185328957
Validation loss: 2.4304552129218706

Epoch: 6| Step: 9
Training loss: 0.23060791210767945
Validation loss: 2.422485912808672

Epoch: 6| Step: 10
Training loss: 0.4858207047109607
Validation loss: 2.423740128447849

Epoch: 6| Step: 11
Training loss: 0.30267995529806896
Validation loss: 2.417941472378449

Epoch: 6| Step: 12
Training loss: 0.20994618386175198
Validation loss: 2.4093922411803703

Epoch: 6| Step: 13
Training loss: 0.15979772072811915
Validation loss: 2.3904447616952678

Epoch: 359| Step: 0
Training loss: 0.1944721166517605
Validation loss: 2.4170594550357842

Epoch: 6| Step: 1
Training loss: 0.1465406945362373
Validation loss: 2.4092833868534314

Epoch: 6| Step: 2
Training loss: 0.11491570618888289
Validation loss: 2.3832729675375073

Epoch: 6| Step: 3
Training loss: 0.15690195444772798
Validation loss: 2.3804431558097194

Epoch: 6| Step: 4
Training loss: 0.19997144137570055
Validation loss: 2.3773912978477556

Epoch: 6| Step: 5
Training loss: 0.40197468469036685
Validation loss: 2.3662016242566533

Epoch: 6| Step: 6
Training loss: 0.3154710323294636
Validation loss: 2.3772483776655617

Epoch: 6| Step: 7
Training loss: 0.34437995322069814
Validation loss: 2.3526623331935244

Epoch: 6| Step: 8
Training loss: 0.14270996504103714
Validation loss: 2.3771407230071273

Epoch: 6| Step: 9
Training loss: 0.2096956040284533
Validation loss: 2.385536482802522

Epoch: 6| Step: 10
Training loss: 0.1247813055137207
Validation loss: 2.4031113321467785

Epoch: 6| Step: 11
Training loss: 0.32715772928735537
Validation loss: 2.374786609698225

Epoch: 6| Step: 12
Training loss: 0.33598916077940827
Validation loss: 2.436430171228996

Epoch: 6| Step: 13
Training loss: 0.0737088500153347
Validation loss: 2.428363214541026

Epoch: 360| Step: 0
Training loss: 0.21509108611384176
Validation loss: 2.4108742078869323

Epoch: 6| Step: 1
Training loss: 0.23881454667514948
Validation loss: 2.4337777976570023

Epoch: 6| Step: 2
Training loss: 0.17475301628859102
Validation loss: 2.4182491750513284

Epoch: 6| Step: 3
Training loss: 0.2437223437098484
Validation loss: 2.4392598784973107

Epoch: 6| Step: 4
Training loss: 0.1347716993538584
Validation loss: 2.424819078833436

Epoch: 6| Step: 5
Training loss: 0.11412428936131222
Validation loss: 2.4099310792042616

Epoch: 6| Step: 6
Training loss: 0.2886034181025635
Validation loss: 2.4177494356811717

Epoch: 6| Step: 7
Training loss: 0.4816022853024415
Validation loss: 2.389901391824067

Epoch: 6| Step: 8
Training loss: 0.2922986441373292
Validation loss: 2.4223563402344523

Epoch: 6| Step: 9
Training loss: 0.20892147650683182
Validation loss: 2.4007170474671398

Epoch: 6| Step: 10
Training loss: 0.15915244401762368
Validation loss: 2.386258579154221

Epoch: 6| Step: 11
Training loss: 0.1791823376596188
Validation loss: 2.409294618593873

Epoch: 6| Step: 12
Training loss: 0.3318463203193406
Validation loss: 2.405533900177622

Epoch: 6| Step: 13
Training loss: 0.06941186750093932
Validation loss: 2.3982039758751506

Epoch: 361| Step: 0
Training loss: 0.14530260862504876
Validation loss: 2.388500727447505

Epoch: 6| Step: 1
Training loss: 0.10771636477630299
Validation loss: 2.385659867774163

Epoch: 6| Step: 2
Training loss: 0.41578395643360483
Validation loss: 2.4139111126885076

Epoch: 6| Step: 3
Training loss: 0.15846394596555025
Validation loss: 2.4222461396215924

Epoch: 6| Step: 4
Training loss: 0.2012165908745032
Validation loss: 2.394037848248038

Epoch: 6| Step: 5
Training loss: 0.20982727409324908
Validation loss: 2.3956029197106123

Epoch: 6| Step: 6
Training loss: 0.2275740224152213
Validation loss: 2.4266802335837347

Epoch: 6| Step: 7
Training loss: 0.24011167633796707
Validation loss: 2.4035430126462685

Epoch: 6| Step: 8
Training loss: 0.1591556800103294
Validation loss: 2.409803395420478

Epoch: 6| Step: 9
Training loss: 0.16167841929021057
Validation loss: 2.402696177498871

Epoch: 6| Step: 10
Training loss: 0.13405032300444195
Validation loss: 2.394367798805899

Epoch: 6| Step: 11
Training loss: 0.27114038148797737
Validation loss: 2.4153665111682097

Epoch: 6| Step: 12
Training loss: 0.31751945488565064
Validation loss: 2.38369522460861

Epoch: 6| Step: 13
Training loss: 0.37412927788386263
Validation loss: 2.3879977290771084

Epoch: 362| Step: 0
Training loss: 0.23816080645186982
Validation loss: 2.3984819542857334

Epoch: 6| Step: 1
Training loss: 0.26687635854692426
Validation loss: 2.390503173229028

Epoch: 6| Step: 2
Training loss: 0.15244654097575505
Validation loss: 2.3958344647234098

Epoch: 6| Step: 3
Training loss: 0.21259435984938846
Validation loss: 2.426905793515552

Epoch: 6| Step: 4
Training loss: 0.14890104619967465
Validation loss: 2.422474697252699

Epoch: 6| Step: 5
Training loss: 0.2135747974947818
Validation loss: 2.4626667614827373

Epoch: 6| Step: 6
Training loss: 0.28397123156832094
Validation loss: 2.4558691787114975

Epoch: 6| Step: 7
Training loss: 0.4064531735233335
Validation loss: 2.447317920385958

Epoch: 6| Step: 8
Training loss: 0.17615393232167922
Validation loss: 2.4391509429302523

Epoch: 6| Step: 9
Training loss: 0.23645264521379797
Validation loss: 2.4434828733381693

Epoch: 6| Step: 10
Training loss: 0.09721571741122725
Validation loss: 2.4069094511366256

Epoch: 6| Step: 11
Training loss: 0.10559370444884705
Validation loss: 2.4352297563741807

Epoch: 6| Step: 12
Training loss: 0.4063755721642917
Validation loss: 2.4167956631454284

Epoch: 6| Step: 13
Training loss: 0.23743538730501787
Validation loss: 2.4159208592451185

Epoch: 363| Step: 0
Training loss: 0.30051663140720614
Validation loss: 2.3898359242145983

Epoch: 6| Step: 1
Training loss: 0.2187710990267215
Validation loss: 2.3732837559616953

Epoch: 6| Step: 2
Training loss: 0.15089041780179285
Validation loss: 2.365135196414375

Epoch: 6| Step: 3
Training loss: 0.2049089369650779
Validation loss: 2.353666024348305

Epoch: 6| Step: 4
Training loss: 0.3921581698085002
Validation loss: 2.3571848149767685

Epoch: 6| Step: 5
Training loss: 0.232693953703044
Validation loss: 2.346775633626821

Epoch: 6| Step: 6
Training loss: 0.3358059448100791
Validation loss: 2.3420647855482803

Epoch: 6| Step: 7
Training loss: 0.19900462854396378
Validation loss: 2.35694715571941

Epoch: 6| Step: 8
Training loss: 0.446969196422039
Validation loss: 2.3683968206495036

Epoch: 6| Step: 9
Training loss: 0.24382680942091264
Validation loss: 2.400165825117585

Epoch: 6| Step: 10
Training loss: 0.24820066925697484
Validation loss: 2.4026486596549534

Epoch: 6| Step: 11
Training loss: 0.2016898034126477
Validation loss: 2.3915770643795433

Epoch: 6| Step: 12
Training loss: 0.38346099420898394
Validation loss: 2.4233500957948837

Epoch: 6| Step: 13
Training loss: 0.18709686771074296
Validation loss: 2.4330848524275037

Epoch: 364| Step: 0
Training loss: 0.2209732883366577
Validation loss: 2.4871519989397894

Epoch: 6| Step: 1
Training loss: 0.1871969237208285
Validation loss: 2.479002046345947

Epoch: 6| Step: 2
Training loss: 0.29143376361137857
Validation loss: 2.509586141871986

Epoch: 6| Step: 3
Training loss: 0.27765609721886375
Validation loss: 2.4846117058192423

Epoch: 6| Step: 4
Training loss: 0.2330646921905347
Validation loss: 2.438651472107189

Epoch: 6| Step: 5
Training loss: 0.1845440013236398
Validation loss: 2.5000130396677216

Epoch: 6| Step: 6
Training loss: 0.21244488871004005
Validation loss: 2.4576250672056887

Epoch: 6| Step: 7
Training loss: 0.1931772433914779
Validation loss: 2.491966239536836

Epoch: 6| Step: 8
Training loss: 0.330945157186736
Validation loss: 2.472482735028918

Epoch: 6| Step: 9
Training loss: 0.43346922177364783
Validation loss: 2.4673276206916728

Epoch: 6| Step: 10
Training loss: 0.18420840916232614
Validation loss: 2.4661534628026907

Epoch: 6| Step: 11
Training loss: 0.32913308601066504
Validation loss: 2.4614034294650797

Epoch: 6| Step: 12
Training loss: 0.3189233336669254
Validation loss: 2.4431933636819534

Epoch: 6| Step: 13
Training loss: 0.20278942375093614
Validation loss: 2.414794605904651

Epoch: 365| Step: 0
Training loss: 0.20625593653718333
Validation loss: 2.402176980947191

Epoch: 6| Step: 1
Training loss: 0.11835700432445925
Validation loss: 2.4242800496475603

Epoch: 6| Step: 2
Training loss: 0.27817305299779144
Validation loss: 2.4103424999630865

Epoch: 6| Step: 3
Training loss: 0.19234212454783797
Validation loss: 2.4028004644775804

Epoch: 6| Step: 4
Training loss: 0.3277840773276587
Validation loss: 2.403412553224212

Epoch: 6| Step: 5
Training loss: 0.26052249983160847
Validation loss: 2.403370772584959

Epoch: 6| Step: 6
Training loss: 0.21743102588648044
Validation loss: 2.410364055850863

Epoch: 6| Step: 7
Training loss: 0.4829806902127431
Validation loss: 2.4119055141180943

Epoch: 6| Step: 8
Training loss: 0.21373770987999383
Validation loss: 2.4281985619129833

Epoch: 6| Step: 9
Training loss: 0.11060711294437778
Validation loss: 2.4019907307390085

Epoch: 6| Step: 10
Training loss: 0.24056303601243642
Validation loss: 2.4320333922137363

Epoch: 6| Step: 11
Training loss: 0.2287672483346102
Validation loss: 2.4421858844210207

Epoch: 6| Step: 12
Training loss: 0.46462882707285585
Validation loss: 2.4684842341634536

Epoch: 6| Step: 13
Training loss: 0.10974780477672354
Validation loss: 2.449561668396627

Epoch: 366| Step: 0
Training loss: 0.13009073350988853
Validation loss: 2.4825473676646266

Epoch: 6| Step: 1
Training loss: 0.20056829365629664
Validation loss: 2.480985110210545

Epoch: 6| Step: 2
Training loss: 0.40631093888627606
Validation loss: 2.4413385554291

Epoch: 6| Step: 3
Training loss: 0.2241987953876586
Validation loss: 2.4345829318068217

Epoch: 6| Step: 4
Training loss: 0.22776724053125466
Validation loss: 2.4253597946601206

Epoch: 6| Step: 5
Training loss: 0.18992149817469758
Validation loss: 2.4278997507281095

Epoch: 6| Step: 6
Training loss: 0.24037366411132477
Validation loss: 2.401235957540997

Epoch: 6| Step: 7
Training loss: 0.3355316882532538
Validation loss: 2.3747497722538133

Epoch: 6| Step: 8
Training loss: 0.2409595615958789
Validation loss: 2.388954962096239

Epoch: 6| Step: 9
Training loss: 0.2929980581246886
Validation loss: 2.406250598759837

Epoch: 6| Step: 10
Training loss: 0.39980779887946855
Validation loss: 2.3676584592193475

Epoch: 6| Step: 11
Training loss: 0.28397200556161195
Validation loss: 2.4087210699869144

Epoch: 6| Step: 12
Training loss: 0.1478223477000651
Validation loss: 2.3911153510415666

Epoch: 6| Step: 13
Training loss: 0.25756454103360493
Validation loss: 2.3583490022963267

Epoch: 367| Step: 0
Training loss: 0.3009419816813387
Validation loss: 2.3998605709012097

Epoch: 6| Step: 1
Training loss: 0.17745923134892355
Validation loss: 2.412496093954267

Epoch: 6| Step: 2
Training loss: 0.2531518292042833
Validation loss: 2.3891844607934636

Epoch: 6| Step: 3
Training loss: 0.24360693009537987
Validation loss: 2.3879165158743842

Epoch: 6| Step: 4
Training loss: 0.21892361903528826
Validation loss: 2.4073897135592413

Epoch: 6| Step: 5
Training loss: 0.2995945445621483
Validation loss: 2.3934184190861405

Epoch: 6| Step: 6
Training loss: 0.22836971515341006
Validation loss: 2.4104314759182826

Epoch: 6| Step: 7
Training loss: 0.2935981855316249
Validation loss: 2.41887662051156

Epoch: 6| Step: 8
Training loss: 0.1868080643796989
Validation loss: 2.4057586811830673

Epoch: 6| Step: 9
Training loss: 0.4503221312531312
Validation loss: 2.418201720847237

Epoch: 6| Step: 10
Training loss: 0.12230066309265279
Validation loss: 2.4565255095726606

Epoch: 6| Step: 11
Training loss: 0.22936829814423054
Validation loss: 2.4662130749725315

Epoch: 6| Step: 12
Training loss: 0.3209004936686398
Validation loss: 2.444574800910245

Epoch: 6| Step: 13
Training loss: 0.1358692205984472
Validation loss: 2.486687410921246

Epoch: 368| Step: 0
Training loss: 0.19051625167179215
Validation loss: 2.466596393809208

Epoch: 6| Step: 1
Training loss: 0.2009436970670255
Validation loss: 2.4574157652904636

Epoch: 6| Step: 2
Training loss: 0.4293483088941489
Validation loss: 2.474020766985418

Epoch: 6| Step: 3
Training loss: 0.1899753138228218
Validation loss: 2.433568364640417

Epoch: 6| Step: 4
Training loss: 0.159088278191738
Validation loss: 2.425804508623433

Epoch: 6| Step: 5
Training loss: 0.22155716320653385
Validation loss: 2.3965890510209196

Epoch: 6| Step: 6
Training loss: 0.18305846564684827
Validation loss: 2.394424746321097

Epoch: 6| Step: 7
Training loss: 0.1289651476082175
Validation loss: 2.3580481988625586

Epoch: 6| Step: 8
Training loss: 0.23517983847391716
Validation loss: 2.3812290298278826

Epoch: 6| Step: 9
Training loss: 0.42854597876120515
Validation loss: 2.3796460621679905

Epoch: 6| Step: 10
Training loss: 0.16165206935040627
Validation loss: 2.4062495674438686

Epoch: 6| Step: 11
Training loss: 0.22016421495193222
Validation loss: 2.4045769498258096

Epoch: 6| Step: 12
Training loss: 0.3480445750424893
Validation loss: 2.410595602237168

Epoch: 6| Step: 13
Training loss: 0.3396438471092918
Validation loss: 2.422090715691488

Epoch: 369| Step: 0
Training loss: 0.30921492047514276
Validation loss: 2.4272230343040757

Epoch: 6| Step: 1
Training loss: 0.21747062568332562
Validation loss: 2.462364759261229

Epoch: 6| Step: 2
Training loss: 0.3050580827721067
Validation loss: 2.4690243802311405

Epoch: 6| Step: 3
Training loss: 0.13709087138287412
Validation loss: 2.4783551680478038

Epoch: 6| Step: 4
Training loss: 0.13713055308529
Validation loss: 2.4519710132151724

Epoch: 6| Step: 5
Training loss: 0.13438078623888977
Validation loss: 2.473189671807023

Epoch: 6| Step: 6
Training loss: 0.2241047373269671
Validation loss: 2.443059809437438

Epoch: 6| Step: 7
Training loss: 0.4034424382150586
Validation loss: 2.428873207995495

Epoch: 6| Step: 8
Training loss: 0.15523961736526873
Validation loss: 2.395802399131093

Epoch: 6| Step: 9
Training loss: 0.202813716937677
Validation loss: 2.4062256275781047

Epoch: 6| Step: 10
Training loss: 0.21698822993009542
Validation loss: 2.3831947637327073

Epoch: 6| Step: 11
Training loss: 0.35880512166306905
Validation loss: 2.422630301840321

Epoch: 6| Step: 12
Training loss: 0.2119730502534159
Validation loss: 2.415548715929887

Epoch: 6| Step: 13
Training loss: 0.22048756529277608
Validation loss: 2.392456624853457

Epoch: 370| Step: 0
Training loss: 0.22888860667068814
Validation loss: 2.409785363297429

Epoch: 6| Step: 1
Training loss: 0.17718916890537445
Validation loss: 2.41260432037404

Epoch: 6| Step: 2
Training loss: 0.44447399970800905
Validation loss: 2.4029124605493344

Epoch: 6| Step: 3
Training loss: 0.22214114687476563
Validation loss: 2.42261261863329

Epoch: 6| Step: 4
Training loss: 0.19455056343568103
Validation loss: 2.4470384934297607

Epoch: 6| Step: 5
Training loss: 0.24558469559355636
Validation loss: 2.451131392692391

Epoch: 6| Step: 6
Training loss: 0.11069069292502512
Validation loss: 2.403861567382366

Epoch: 6| Step: 7
Training loss: 0.33607247324712114
Validation loss: 2.456695514399995

Epoch: 6| Step: 8
Training loss: 0.17665317768338468
Validation loss: 2.4327484144337164

Epoch: 6| Step: 9
Training loss: 0.15364687455896708
Validation loss: 2.437430779142339

Epoch: 6| Step: 10
Training loss: 0.1703452940524294
Validation loss: 2.4613456834200655

Epoch: 6| Step: 11
Training loss: 0.11459258342021168
Validation loss: 2.429044744203625

Epoch: 6| Step: 12
Training loss: 0.2897728234263718
Validation loss: 2.4291847261963335

Epoch: 6| Step: 13
Training loss: 0.1974078694769751
Validation loss: 2.407181121637567

Epoch: 371| Step: 0
Training loss: 0.2543036358897032
Validation loss: 2.402685920817502

Epoch: 6| Step: 1
Training loss: 0.16595743505880642
Validation loss: 2.3989520771354558

Epoch: 6| Step: 2
Training loss: 0.1367333881171245
Validation loss: 2.421418295202041

Epoch: 6| Step: 3
Training loss: 0.15469090934810975
Validation loss: 2.4214953317802537

Epoch: 6| Step: 4
Training loss: 0.12612532179047561
Validation loss: 2.412926466288228

Epoch: 6| Step: 5
Training loss: 0.2235633875600224
Validation loss: 2.4197683179277663

Epoch: 6| Step: 6
Training loss: 0.14745408478028674
Validation loss: 2.412665908058957

Epoch: 6| Step: 7
Training loss: 0.2609912097499345
Validation loss: 2.4412543110483105

Epoch: 6| Step: 8
Training loss: 0.2741409109771272
Validation loss: 2.4117643190144213

Epoch: 6| Step: 9
Training loss: 0.15753662149102193
Validation loss: 2.4494664139155837

Epoch: 6| Step: 10
Training loss: 0.18329864484449415
Validation loss: 2.4446388099497036

Epoch: 6| Step: 11
Training loss: 0.3980184670326132
Validation loss: 2.440590587451773

Epoch: 6| Step: 12
Training loss: 0.3043754642647526
Validation loss: 2.4264462336495027

Epoch: 6| Step: 13
Training loss: 0.20372218597459063
Validation loss: 2.4314614965468255

Epoch: 372| Step: 0
Training loss: 0.18682106598517986
Validation loss: 2.4645726885786017

Epoch: 6| Step: 1
Training loss: 0.2066581350886919
Validation loss: 2.424591679010714

Epoch: 6| Step: 2
Training loss: 0.17495371151016942
Validation loss: 2.4254495948413366

Epoch: 6| Step: 3
Training loss: 0.18349903788496263
Validation loss: 2.4028628144952164

Epoch: 6| Step: 4
Training loss: 0.27822476804982227
Validation loss: 2.4007353666136435

Epoch: 6| Step: 5
Training loss: 0.18574442135082292
Validation loss: 2.3715841991610724

Epoch: 6| Step: 6
Training loss: 0.2866036118954948
Validation loss: 2.3552413017325087

Epoch: 6| Step: 7
Training loss: 0.2430569746150114
Validation loss: 2.379021583249528

Epoch: 6| Step: 8
Training loss: 0.13006687745734347
Validation loss: 2.365674618709584

Epoch: 6| Step: 9
Training loss: 0.39801298227414844
Validation loss: 2.365365893127934

Epoch: 6| Step: 10
Training loss: 0.16671766057324394
Validation loss: 2.3684661724628855

Epoch: 6| Step: 11
Training loss: 0.11460259981808703
Validation loss: 2.384820800190269

Epoch: 6| Step: 12
Training loss: 0.14455646861927898
Validation loss: 2.3736240857282103

Epoch: 6| Step: 13
Training loss: 0.39718862291803103
Validation loss: 2.4175865627647504

Epoch: 373| Step: 0
Training loss: 0.1853293700041705
Validation loss: 2.4014752781483364

Epoch: 6| Step: 1
Training loss: 0.4458867436202735
Validation loss: 2.406187952970553

Epoch: 6| Step: 2
Training loss: 0.20310380715072834
Validation loss: 2.384596678381495

Epoch: 6| Step: 3
Training loss: 0.27378843131355224
Validation loss: 2.4085528175523216

Epoch: 6| Step: 4
Training loss: 0.18777911947980838
Validation loss: 2.429687559087382

Epoch: 6| Step: 5
Training loss: 0.2679540541153
Validation loss: 2.439623502752983

Epoch: 6| Step: 6
Training loss: 0.25232394232233935
Validation loss: 2.4583176983780546

Epoch: 6| Step: 7
Training loss: 0.15784333371636375
Validation loss: 2.4438031811457757

Epoch: 6| Step: 8
Training loss: 0.2576072771944059
Validation loss: 2.431411806066177

Epoch: 6| Step: 9
Training loss: 0.23318670556877058
Validation loss: 2.4416880638971046

Epoch: 6| Step: 10
Training loss: 0.11372650544435768
Validation loss: 2.4376273152200647

Epoch: 6| Step: 11
Training loss: 0.28180257503285333
Validation loss: 2.4311245064756526

Epoch: 6| Step: 12
Training loss: 0.19479001732160264
Validation loss: 2.4312623489293608

Epoch: 6| Step: 13
Training loss: 0.17762204697360237
Validation loss: 2.42522765472633

Epoch: 374| Step: 0
Training loss: 0.2538678653753187
Validation loss: 2.46049025782232

Epoch: 6| Step: 1
Training loss: 0.1928798238975531
Validation loss: 2.4448111536937884

Epoch: 6| Step: 2
Training loss: 0.22865243223714352
Validation loss: 2.4664310287341045

Epoch: 6| Step: 3
Training loss: 0.23210054512395453
Validation loss: 2.4428746906945262

Epoch: 6| Step: 4
Training loss: 0.4021130798714654
Validation loss: 2.4014339874352135

Epoch: 6| Step: 5
Training loss: 0.1502325788084064
Validation loss: 2.400993001979133

Epoch: 6| Step: 6
Training loss: 0.2784767112993733
Validation loss: 2.397943198121936

Epoch: 6| Step: 7
Training loss: 0.22443356474887088
Validation loss: 2.40543097706127

Epoch: 6| Step: 8
Training loss: 0.16841620351314643
Validation loss: 2.3920071964174867

Epoch: 6| Step: 9
Training loss: 0.26573403308519156
Validation loss: 2.3960036054529263

Epoch: 6| Step: 10
Training loss: 0.2884799396624558
Validation loss: 2.392423869976837

Epoch: 6| Step: 11
Training loss: 0.11296659375213051
Validation loss: 2.4057770538489023

Epoch: 6| Step: 12
Training loss: 0.181615417536169
Validation loss: 2.488287746973259

Epoch: 6| Step: 13
Training loss: 0.4319327561199804
Validation loss: 2.4915287642537782

Epoch: 375| Step: 0
Training loss: 0.19132482976789988
Validation loss: 2.5021521313592756

Epoch: 6| Step: 1
Training loss: 0.2679328377239979
Validation loss: 2.4871473146760836

Epoch: 6| Step: 2
Training loss: 0.23049357652298985
Validation loss: 2.489893602817034

Epoch: 6| Step: 3
Training loss: 0.23894891845616406
Validation loss: 2.449636492906615

Epoch: 6| Step: 4
Training loss: 0.3355280021538002
Validation loss: 2.450131405723273

Epoch: 6| Step: 5
Training loss: 0.28911551427556725
Validation loss: 2.4062070295366893

Epoch: 6| Step: 6
Training loss: 0.2604687289013136
Validation loss: 2.4119750588435176

Epoch: 6| Step: 7
Training loss: 0.1976821298204514
Validation loss: 2.3975310193724044

Epoch: 6| Step: 8
Training loss: 0.1916077973481957
Validation loss: 2.4300343403393625

Epoch: 6| Step: 9
Training loss: 0.40480424309102164
Validation loss: 2.444248832653146

Epoch: 6| Step: 10
Training loss: 0.16976262994468722
Validation loss: 2.42077829734247

Epoch: 6| Step: 11
Training loss: 0.27836977870448487
Validation loss: 2.427020652060537

Epoch: 6| Step: 12
Training loss: 0.20611148431118095
Validation loss: 2.4527082129018245

Epoch: 6| Step: 13
Training loss: 0.22624388027871864
Validation loss: 2.4463524524123526

Epoch: 376| Step: 0
Training loss: 0.1759194890148551
Validation loss: 2.4335532470707837

Epoch: 6| Step: 1
Training loss: 0.15953241946569824
Validation loss: 2.461357368139687

Epoch: 6| Step: 2
Training loss: 0.3049685331434325
Validation loss: 2.4759822789587855

Epoch: 6| Step: 3
Training loss: 0.16953922903384
Validation loss: 2.4378601630600216

Epoch: 6| Step: 4
Training loss: 0.4434857461449348
Validation loss: 2.475361921312005

Epoch: 6| Step: 5
Training loss: 0.2121680710651917
Validation loss: 2.423175269272438

Epoch: 6| Step: 6
Training loss: 0.3090164693568278
Validation loss: 2.3924865873906374

Epoch: 6| Step: 7
Training loss: 0.2207902297578329
Validation loss: 2.401689021780523

Epoch: 6| Step: 8
Training loss: 0.2664490427679705
Validation loss: 2.388712359770452

Epoch: 6| Step: 9
Training loss: 0.19945893114472002
Validation loss: 2.3806605279861563

Epoch: 6| Step: 10
Training loss: 0.2886078196938999
Validation loss: 2.4160258985742282

Epoch: 6| Step: 11
Training loss: 0.2090723351729653
Validation loss: 2.3835353508691246

Epoch: 6| Step: 12
Training loss: 0.29968343761821253
Validation loss: 2.3660146376471034

Epoch: 6| Step: 13
Training loss: 0.1752208784622826
Validation loss: 2.3857673161248996

Epoch: 377| Step: 0
Training loss: 0.17236417818781655
Validation loss: 2.401860214220805

Epoch: 6| Step: 1
Training loss: 0.4556247718768602
Validation loss: 2.421903447974167

Epoch: 6| Step: 2
Training loss: 0.18531155973585095
Validation loss: 2.460414438544584

Epoch: 6| Step: 3
Training loss: 0.24663808959682437
Validation loss: 2.4373774585784607

Epoch: 6| Step: 4
Training loss: 0.15665368147014594
Validation loss: 2.4575047800878043

Epoch: 6| Step: 5
Training loss: 0.36856674312085214
Validation loss: 2.477225450448826

Epoch: 6| Step: 6
Training loss: 0.2487289632355531
Validation loss: 2.4227565837315406

Epoch: 6| Step: 7
Training loss: 0.21025523474557523
Validation loss: 2.4434048481106596

Epoch: 6| Step: 8
Training loss: 0.1900557637104413
Validation loss: 2.405038395939012

Epoch: 6| Step: 9
Training loss: 0.11106062004111499
Validation loss: 2.409615202561229

Epoch: 6| Step: 10
Training loss: 0.2584339224165286
Validation loss: 2.4367981355886714

Epoch: 6| Step: 11
Training loss: 0.21229297847797968
Validation loss: 2.415462784556023

Epoch: 6| Step: 12
Training loss: 0.28332328877923135
Validation loss: 2.413079395287728

Epoch: 6| Step: 13
Training loss: 0.11083616763165183
Validation loss: 2.4114453924393477

Epoch: 378| Step: 0
Training loss: 0.08925574632085435
Validation loss: 2.40000165529946

Epoch: 6| Step: 1
Training loss: 0.43286535580692787
Validation loss: 2.407372355549953

Epoch: 6| Step: 2
Training loss: 0.3894490661715685
Validation loss: 2.468821335417813

Epoch: 6| Step: 3
Training loss: 0.36210567221451
Validation loss: 2.438470996758987

Epoch: 6| Step: 4
Training loss: 0.2148820322782259
Validation loss: 2.391635527312842

Epoch: 6| Step: 5
Training loss: 0.23482974758776773
Validation loss: 2.351273133736179

Epoch: 6| Step: 6
Training loss: 0.2697080916613785
Validation loss: 2.3441616951923145

Epoch: 6| Step: 7
Training loss: 0.4270552726769371
Validation loss: 2.35946100528208

Epoch: 6| Step: 8
Training loss: 0.35259521121772336
Validation loss: 2.3663471438294215

Epoch: 6| Step: 9
Training loss: 0.19006542677665864
Validation loss: 2.365529142839605

Epoch: 6| Step: 10
Training loss: 0.1956400794472608
Validation loss: 2.389603158018684

Epoch: 6| Step: 11
Training loss: 0.26250027929018693
Validation loss: 2.4299509436964706

Epoch: 6| Step: 12
Training loss: 0.4634246964335483
Validation loss: 2.4050630418126224

Epoch: 6| Step: 13
Training loss: 0.17008982502930842
Validation loss: 2.36059291355993

Epoch: 379| Step: 0
Training loss: 0.2692933622241236
Validation loss: 2.365973854424557

Epoch: 6| Step: 1
Training loss: 0.3187590354685983
Validation loss: 2.3289658280027576

Epoch: 6| Step: 2
Training loss: 0.2676570664508613
Validation loss: 2.354697418567616

Epoch: 6| Step: 3
Training loss: 0.6079653550177975
Validation loss: 2.3868365080072884

Epoch: 6| Step: 4
Training loss: 0.3427061792014154
Validation loss: 2.3675222042112485

Epoch: 6| Step: 5
Training loss: 0.4078813955055195
Validation loss: 2.366403075095931

Epoch: 6| Step: 6
Training loss: 0.4416033886918544
Validation loss: 2.3746015940998197

Epoch: 6| Step: 7
Training loss: 0.3318863945421948
Validation loss: 2.3990141584973346

Epoch: 6| Step: 8
Training loss: 0.32364265551243426
Validation loss: 2.397794261477519

Epoch: 6| Step: 9
Training loss: 0.2545050675593985
Validation loss: 2.401550489612821

Epoch: 6| Step: 10
Training loss: 0.31167239033233834
Validation loss: 2.3950428397384225

Epoch: 6| Step: 11
Training loss: 0.32935900481037805
Validation loss: 2.4313163998795186

Epoch: 6| Step: 12
Training loss: 0.20772048196462228
Validation loss: 2.406260021217083

Epoch: 6| Step: 13
Training loss: 0.2398301422036295
Validation loss: 2.400402235840116

Epoch: 380| Step: 0
Training loss: 0.1671268466752569
Validation loss: 2.3871665110163516

Epoch: 6| Step: 1
Training loss: 0.32780185182149
Validation loss: 2.359215420027925

Epoch: 6| Step: 2
Training loss: 0.3452731869616065
Validation loss: 2.3574960190619314

Epoch: 6| Step: 3
Training loss: 0.24405708409551047
Validation loss: 2.3958186772893804

Epoch: 6| Step: 4
Training loss: 0.31471944868388807
Validation loss: 2.399116075139887

Epoch: 6| Step: 5
Training loss: 0.32396413388021833
Validation loss: 2.4141324142631464

Epoch: 6| Step: 6
Training loss: 0.5037889565864588
Validation loss: 2.4657908834112314

Epoch: 6| Step: 7
Training loss: 0.3197091630921338
Validation loss: 2.446505720964067

Epoch: 6| Step: 8
Training loss: 0.2160324848900707
Validation loss: 2.4778672167768803

Epoch: 6| Step: 9
Training loss: 0.28712416630226567
Validation loss: 2.4573411797410074

Epoch: 6| Step: 10
Training loss: 0.14431989526448288
Validation loss: 2.454290977828532

Epoch: 6| Step: 11
Training loss: 0.24045237287755358
Validation loss: 2.4346732657691

Epoch: 6| Step: 12
Training loss: 0.3636761231794037
Validation loss: 2.4287101869995

Epoch: 6| Step: 13
Training loss: 0.2895470115583486
Validation loss: 2.4372320866705524

Epoch: 381| Step: 0
Training loss: 0.2610405061903537
Validation loss: 2.4124557458328675

Epoch: 6| Step: 1
Training loss: 0.35137883793089547
Validation loss: 2.456143660817409

Epoch: 6| Step: 2
Training loss: 0.3284540116345471
Validation loss: 2.4396350114656933

Epoch: 6| Step: 3
Training loss: 0.32002264957811977
Validation loss: 2.4782941214644096

Epoch: 6| Step: 4
Training loss: 0.5259529139616711
Validation loss: 2.503210132529667

Epoch: 6| Step: 5
Training loss: 0.30803216464206895
Validation loss: 2.5266262631788927

Epoch: 6| Step: 6
Training loss: 0.26053759945854416
Validation loss: 2.5230321349982585

Epoch: 6| Step: 7
Training loss: 0.33179417168270703
Validation loss: 2.490794987044244

Epoch: 6| Step: 8
Training loss: 0.36353678586173727
Validation loss: 2.4943982790242156

Epoch: 6| Step: 9
Training loss: 0.42143118436975463
Validation loss: 2.498691107499612

Epoch: 6| Step: 10
Training loss: 0.2450596031240537
Validation loss: 2.3997975222142527

Epoch: 6| Step: 11
Training loss: 0.29403951155734187
Validation loss: 2.351380719712622

Epoch: 6| Step: 12
Training loss: 0.3881233600452809
Validation loss: 2.32337224443763

Epoch: 6| Step: 13
Training loss: 0.20172656538322029
Validation loss: 2.362840597248158

Epoch: 382| Step: 0
Training loss: 0.3623589117802139
Validation loss: 2.3557991105397895

Epoch: 6| Step: 1
Training loss: 0.35034968669660127
Validation loss: 2.3982744411675414

Epoch: 6| Step: 2
Training loss: 0.21463613014932625
Validation loss: 2.445876740137552

Epoch: 6| Step: 3
Training loss: 0.26535580121084223
Validation loss: 2.469214829049401

Epoch: 6| Step: 4
Training loss: 0.2566925925211055
Validation loss: 2.5239998765325287

Epoch: 6| Step: 5
Training loss: 0.3790734502243809
Validation loss: 2.5050197596265273

Epoch: 6| Step: 6
Training loss: 0.35073054739477605
Validation loss: 2.4750663420286774

Epoch: 6| Step: 7
Training loss: 0.3072340259263863
Validation loss: 2.4461441950470695

Epoch: 6| Step: 8
Training loss: 0.22432131332191735
Validation loss: 2.462857796649284

Epoch: 6| Step: 9
Training loss: 0.4574809999637527
Validation loss: 2.450253743502259

Epoch: 6| Step: 10
Training loss: 0.3165345226287761
Validation loss: 2.4098440358204054

Epoch: 6| Step: 11
Training loss: 0.3158931221248862
Validation loss: 2.412586590777516

Epoch: 6| Step: 12
Training loss: 0.3628705482144133
Validation loss: 2.4187051978623804

Epoch: 6| Step: 13
Training loss: 0.28941484833995657
Validation loss: 2.3987601323986683

Epoch: 383| Step: 0
Training loss: 0.2871082980596365
Validation loss: 2.4155577646230366

Epoch: 6| Step: 1
Training loss: 0.22016862270007076
Validation loss: 2.45195987084025

Epoch: 6| Step: 2
Training loss: 0.2676712208317283
Validation loss: 2.4884401989493288

Epoch: 6| Step: 3
Training loss: 0.37578409396104584
Validation loss: 2.499493293274496

Epoch: 6| Step: 4
Training loss: 0.5428726330766368
Validation loss: 2.487097322534607

Epoch: 6| Step: 5
Training loss: 0.2298703993279355
Validation loss: 2.487126217084167

Epoch: 6| Step: 6
Training loss: 0.21520591035299333
Validation loss: 2.4604445430394852

Epoch: 6| Step: 7
Training loss: 0.28301075946334475
Validation loss: 2.475267318425362

Epoch: 6| Step: 8
Training loss: 0.22045001986538768
Validation loss: 2.4464435830783224

Epoch: 6| Step: 9
Training loss: 0.2981325168981516
Validation loss: 2.406015858567231

Epoch: 6| Step: 10
Training loss: 0.29801616185480495
Validation loss: 2.4088609056231625

Epoch: 6| Step: 11
Training loss: 0.27747768875161155
Validation loss: 2.4141894928791245

Epoch: 6| Step: 12
Training loss: 0.2643451430774117
Validation loss: 2.367186944426012

Epoch: 6| Step: 13
Training loss: 0.26532497010507167
Validation loss: 2.416829178692112

Epoch: 384| Step: 0
Training loss: 0.31542046359249026
Validation loss: 2.395234081090593

Epoch: 6| Step: 1
Training loss: 0.23835171767556748
Validation loss: 2.4136085360852197

Epoch: 6| Step: 2
Training loss: 0.23068698959686856
Validation loss: 2.4206974878507483

Epoch: 6| Step: 3
Training loss: 0.24952829832171738
Validation loss: 2.4293217300091645

Epoch: 6| Step: 4
Training loss: 0.4618263887265055
Validation loss: 2.4336782142630633

Epoch: 6| Step: 5
Training loss: 0.28281099203139765
Validation loss: 2.4018665334954767

Epoch: 6| Step: 6
Training loss: 0.1980739687833913
Validation loss: 2.3966378814364284

Epoch: 6| Step: 7
Training loss: 0.23647844247273297
Validation loss: 2.3971344900684497

Epoch: 6| Step: 8
Training loss: 0.19393463489531837
Validation loss: 2.3646953021932227

Epoch: 6| Step: 9
Training loss: 0.20575043512010974
Validation loss: 2.3493399503218555

Epoch: 6| Step: 10
Training loss: 0.2103935221101815
Validation loss: 2.397509735187572

Epoch: 6| Step: 11
Training loss: 0.19126984543152759
Validation loss: 2.396701867895638

Epoch: 6| Step: 12
Training loss: 0.3343139606093761
Validation loss: 2.3586425013617274

Epoch: 6| Step: 13
Training loss: 0.2168300019119967
Validation loss: 2.401041827180595

Epoch: 385| Step: 0
Training loss: 0.219322723574898
Validation loss: 2.3838303991275978

Epoch: 6| Step: 1
Training loss: 0.4079556056943704
Validation loss: 2.39804090009477

Epoch: 6| Step: 2
Training loss: 0.1546789882225431
Validation loss: 2.414898516914739

Epoch: 6| Step: 3
Training loss: 0.17765145935336357
Validation loss: 2.400804800836509

Epoch: 6| Step: 4
Training loss: 0.30487030609696575
Validation loss: 2.4373101412125977

Epoch: 6| Step: 5
Training loss: 0.1370836497351967
Validation loss: 2.414069271585899

Epoch: 6| Step: 6
Training loss: 0.15972786692709173
Validation loss: 2.4200602739679615

Epoch: 6| Step: 7
Training loss: 0.14667186182838252
Validation loss: 2.4300725198104187

Epoch: 6| Step: 8
Training loss: 0.3175713082082812
Validation loss: 2.4062357980548494

Epoch: 6| Step: 9
Training loss: 0.10738524332552726
Validation loss: 2.4288192520290663

Epoch: 6| Step: 10
Training loss: 0.18631631026007706
Validation loss: 2.4062059297482596

Epoch: 6| Step: 11
Training loss: 0.2744241624378546
Validation loss: 2.4140558266267877

Epoch: 6| Step: 12
Training loss: 0.2704598559895658
Validation loss: 2.402785042363662

Epoch: 6| Step: 13
Training loss: 0.26027003769684387
Validation loss: 2.399860549536297

Epoch: 386| Step: 0
Training loss: 0.12597717610291076
Validation loss: 2.3926415423254404

Epoch: 6| Step: 1
Training loss: 0.29617135835007324
Validation loss: 2.4199260606456177

Epoch: 6| Step: 2
Training loss: 0.19024079564595692
Validation loss: 2.4274019458848155

Epoch: 6| Step: 3
Training loss: 0.24962142503334162
Validation loss: 2.4471817166551806

Epoch: 6| Step: 4
Training loss: 0.18621759155112835
Validation loss: 2.4411363111017024

Epoch: 6| Step: 5
Training loss: 0.2447298264342906
Validation loss: 2.4428667579949486

Epoch: 6| Step: 6
Training loss: 0.10329210242390066
Validation loss: 2.4166307114276835

Epoch: 6| Step: 7
Training loss: 0.14048879040217857
Validation loss: 2.41262191701587

Epoch: 6| Step: 8
Training loss: 0.2564326554114358
Validation loss: 2.4074383222411706

Epoch: 6| Step: 9
Training loss: 0.17395708037018442
Validation loss: 2.408149412249912

Epoch: 6| Step: 10
Training loss: 0.2839598182019943
Validation loss: 2.4066712844746836

Epoch: 6| Step: 11
Training loss: 0.20506101264402582
Validation loss: 2.3988001396523253

Epoch: 6| Step: 12
Training loss: 0.4243653053052758
Validation loss: 2.3891508079939388

Epoch: 6| Step: 13
Training loss: 0.18123206469160674
Validation loss: 2.3976255523384817

Epoch: 387| Step: 0
Training loss: 0.18041983928343
Validation loss: 2.40733537937817

Epoch: 6| Step: 1
Training loss: 0.17475664554833728
Validation loss: 2.3885945976473155

Epoch: 6| Step: 2
Training loss: 0.2385275380907641
Validation loss: 2.4042273859478467

Epoch: 6| Step: 3
Training loss: 0.15054869086017217
Validation loss: 2.408436666336147

Epoch: 6| Step: 4
Training loss: 0.19792986917797942
Validation loss: 2.426390335103833

Epoch: 6| Step: 5
Training loss: 0.38605297461491284
Validation loss: 2.398132676818455

Epoch: 6| Step: 6
Training loss: 0.1438740402441551
Validation loss: 2.382245660418491

Epoch: 6| Step: 7
Training loss: 0.13726359521649328
Validation loss: 2.390808550963493

Epoch: 6| Step: 8
Training loss: 0.2018106559392723
Validation loss: 2.3909299364967684

Epoch: 6| Step: 9
Training loss: 0.21715411403021084
Validation loss: 2.387004343458872

Epoch: 6| Step: 10
Training loss: 0.1897022830883812
Validation loss: 2.3773752499095218

Epoch: 6| Step: 11
Training loss: 0.14779337616132457
Validation loss: 2.400333440939837

Epoch: 6| Step: 12
Training loss: 0.3940907086615059
Validation loss: 2.3836234592998364

Epoch: 6| Step: 13
Training loss: 0.26021312229452065
Validation loss: 2.385368735374638

Epoch: 388| Step: 0
Training loss: 0.15784954660700648
Validation loss: 2.3651678148903836

Epoch: 6| Step: 1
Training loss: 0.40177914901697964
Validation loss: 2.386054194589124

Epoch: 6| Step: 2
Training loss: 0.1560551023895516
Validation loss: 2.4078925409962655

Epoch: 6| Step: 3
Training loss: 0.2263012234518193
Validation loss: 2.3978834769278965

Epoch: 6| Step: 4
Training loss: 0.1548714502503537
Validation loss: 2.399993824438128

Epoch: 6| Step: 5
Training loss: 0.1083665405632544
Validation loss: 2.420967887499712

Epoch: 6| Step: 6
Training loss: 0.26979474995052855
Validation loss: 2.4206656854174717

Epoch: 6| Step: 7
Training loss: 0.30037009636586687
Validation loss: 2.4355537631616557

Epoch: 6| Step: 8
Training loss: 0.11708616007529626
Validation loss: 2.4378144582261454

Epoch: 6| Step: 9
Training loss: 0.28677077016380564
Validation loss: 2.454803224027403

Epoch: 6| Step: 10
Training loss: 0.138554859489289
Validation loss: 2.4250813081839

Epoch: 6| Step: 11
Training loss: 0.1258498153039534
Validation loss: 2.427717631312342

Epoch: 6| Step: 12
Training loss: 0.14000087893159033
Validation loss: 2.4135057021138953

Epoch: 6| Step: 13
Training loss: 0.16518372622937538
Validation loss: 2.3738722260845733

Epoch: 389| Step: 0
Training loss: 0.2456184671955242
Validation loss: 2.411274095349596

Epoch: 6| Step: 1
Training loss: 0.26468192307453015
Validation loss: 2.367399933055717

Epoch: 6| Step: 2
Training loss: 0.16550168539036142
Validation loss: 2.389686436156177

Epoch: 6| Step: 3
Training loss: 0.23337689703337358
Validation loss: 2.3533724073792563

Epoch: 6| Step: 4
Training loss: 0.22825402993773727
Validation loss: 2.399800854157684

Epoch: 6| Step: 5
Training loss: 0.2519218662003831
Validation loss: 2.3712141440897643

Epoch: 6| Step: 6
Training loss: 0.18951166369380268
Validation loss: 2.3847837312804883

Epoch: 6| Step: 7
Training loss: 0.16936900092160231
Validation loss: 2.4205246149997364

Epoch: 6| Step: 8
Training loss: 0.37353014973794585
Validation loss: 2.414615992303333

Epoch: 6| Step: 9
Training loss: 0.16288227224546267
Validation loss: 2.424270649642065

Epoch: 6| Step: 10
Training loss: 0.15295399805112656
Validation loss: 2.419533345429051

Epoch: 6| Step: 11
Training loss: 0.14978969951588295
Validation loss: 2.410564875732386

Epoch: 6| Step: 12
Training loss: 0.14685400422161635
Validation loss: 2.3947856615159457

Epoch: 6| Step: 13
Training loss: 0.15754154001903647
Validation loss: 2.4072924346787

Epoch: 390| Step: 0
Training loss: 0.2151822804237045
Validation loss: 2.413297276049344

Epoch: 6| Step: 1
Training loss: 0.15972787275777472
Validation loss: 2.387223465743911

Epoch: 6| Step: 2
Training loss: 0.17954371753492748
Validation loss: 2.404395941596337

Epoch: 6| Step: 3
Training loss: 0.2127438310363072
Validation loss: 2.428334743005467

Epoch: 6| Step: 4
Training loss: 0.21192942620763078
Validation loss: 2.402060896039364

Epoch: 6| Step: 5
Training loss: 0.19585410364739242
Validation loss: 2.4308342943073584

Epoch: 6| Step: 6
Training loss: 0.4512076260492505
Validation loss: 2.397642930122262

Epoch: 6| Step: 7
Training loss: 0.10922986431764242
Validation loss: 2.403839573519072

Epoch: 6| Step: 8
Training loss: 0.280756225532199
Validation loss: 2.424969912038821

Epoch: 6| Step: 9
Training loss: 0.16132569184211834
Validation loss: 2.38623138140799

Epoch: 6| Step: 10
Training loss: 0.16250391712419304
Validation loss: 2.375085367159227

Epoch: 6| Step: 11
Training loss: 0.16096760921855344
Validation loss: 2.379786104817844

Epoch: 6| Step: 12
Training loss: 0.2727496214085162
Validation loss: 2.3825663379759443

Epoch: 6| Step: 13
Training loss: 0.0996438181923142
Validation loss: 2.3764133198867756

Epoch: 391| Step: 0
Training loss: 0.4197457054888642
Validation loss: 2.41049141214683

Epoch: 6| Step: 1
Training loss: 0.17096891857174468
Validation loss: 2.419099220663672

Epoch: 6| Step: 2
Training loss: 0.2082546900293209
Validation loss: 2.421729570852647

Epoch: 6| Step: 3
Training loss: 0.17114888504749218
Validation loss: 2.4043689103650783

Epoch: 6| Step: 4
Training loss: 0.18599974928603144
Validation loss: 2.40030190165282

Epoch: 6| Step: 5
Training loss: 0.16662998963159048
Validation loss: 2.406531985545245

Epoch: 6| Step: 6
Training loss: 0.20965255446111677
Validation loss: 2.3965277893657406

Epoch: 6| Step: 7
Training loss: 0.16729241426113997
Validation loss: 2.413087110379312

Epoch: 6| Step: 8
Training loss: 0.18467351258588932
Validation loss: 2.402612195247033

Epoch: 6| Step: 9
Training loss: 0.22304652125502558
Validation loss: 2.4081965727165096

Epoch: 6| Step: 10
Training loss: 0.2722194928091348
Validation loss: 2.4050397893962874

Epoch: 6| Step: 11
Training loss: 0.28968587879027663
Validation loss: 2.4217368296554893

Epoch: 6| Step: 12
Training loss: 0.1626933162974319
Validation loss: 2.4150164825526477

Epoch: 6| Step: 13
Training loss: 0.1489616726009729
Validation loss: 2.4280298721583

Epoch: 392| Step: 0
Training loss: 0.1566359759470842
Validation loss: 2.4240808746748934

Epoch: 6| Step: 1
Training loss: 0.18993545365996412
Validation loss: 2.405597399572716

Epoch: 6| Step: 2
Training loss: 0.16696925312518326
Validation loss: 2.426046381178942

Epoch: 6| Step: 3
Training loss: 0.1432805850472199
Validation loss: 2.430293519583103

Epoch: 6| Step: 4
Training loss: 0.4584698654326606
Validation loss: 2.4190216965823286

Epoch: 6| Step: 5
Training loss: 0.22757204987274185
Validation loss: 2.408091682655474

Epoch: 6| Step: 6
Training loss: 0.13135583844987772
Validation loss: 2.4079790150715277

Epoch: 6| Step: 7
Training loss: 0.12843041305295275
Validation loss: 2.3953045561565047

Epoch: 6| Step: 8
Training loss: 0.11286705440904976
Validation loss: 2.4078758232963207

Epoch: 6| Step: 9
Training loss: 0.20238356806045799
Validation loss: 2.40416852037096

Epoch: 6| Step: 10
Training loss: 0.30358795914401043
Validation loss: 2.3679562261356217

Epoch: 6| Step: 11
Training loss: 0.28899425267985746
Validation loss: 2.3913503692884266

Epoch: 6| Step: 12
Training loss: 0.20806426415020662
Validation loss: 2.3823011495506923

Epoch: 6| Step: 13
Training loss: 0.09626028818718348
Validation loss: 2.413097829874869

Epoch: 393| Step: 0
Training loss: 0.26077893173257005
Validation loss: 2.3783003237137135

Epoch: 6| Step: 1
Training loss: 0.18436927544063647
Validation loss: 2.427209754625435

Epoch: 6| Step: 2
Training loss: 0.1348723182716546
Validation loss: 2.3893399340609864

Epoch: 6| Step: 3
Training loss: 0.14514530392120376
Validation loss: 2.3741001017507983

Epoch: 6| Step: 4
Training loss: 0.28437341071303057
Validation loss: 2.4162333237494003

Epoch: 6| Step: 5
Training loss: 0.18975723084706103
Validation loss: 2.4010425201308436

Epoch: 6| Step: 6
Training loss: 0.16365545732190748
Validation loss: 2.374734079988533

Epoch: 6| Step: 7
Training loss: 0.15068701235242532
Validation loss: 2.4172340721657593

Epoch: 6| Step: 8
Training loss: 0.24300163083353393
Validation loss: 2.4089693190376127

Epoch: 6| Step: 9
Training loss: 0.3702519757670786
Validation loss: 2.4170493327545204

Epoch: 6| Step: 10
Training loss: 0.11143061036486866
Validation loss: 2.404754232371547

Epoch: 6| Step: 11
Training loss: 0.20413468744611932
Validation loss: 2.4073845327922716

Epoch: 6| Step: 12
Training loss: 0.09521622289979242
Validation loss: 2.4036544056434908

Epoch: 6| Step: 13
Training loss: 0.17009574391473486
Validation loss: 2.4028433849014474

Epoch: 394| Step: 0
Training loss: 0.16247192309898836
Validation loss: 2.464793925388501

Epoch: 6| Step: 1
Training loss: 0.12081207308962683
Validation loss: 2.4314314343912993

Epoch: 6| Step: 2
Training loss: 0.30688993681781984
Validation loss: 2.397888663789231

Epoch: 6| Step: 3
Training loss: 0.12129057378027024
Validation loss: 2.4137930909053797

Epoch: 6| Step: 4
Training loss: 0.13053363853937797
Validation loss: 2.39184546450989

Epoch: 6| Step: 5
Training loss: 0.18117560060000706
Validation loss: 2.385867973036829

Epoch: 6| Step: 6
Training loss: 0.29044378024543943
Validation loss: 2.398316442602357

Epoch: 6| Step: 7
Training loss: 0.18805293172885357
Validation loss: 2.379911966013287

Epoch: 6| Step: 8
Training loss: 0.19055140591185074
Validation loss: 2.377485098801975

Epoch: 6| Step: 9
Training loss: 0.37002779804659197
Validation loss: 2.420794714138019

Epoch: 6| Step: 10
Training loss: 0.11692482596372825
Validation loss: 2.3841818739992187

Epoch: 6| Step: 11
Training loss: 0.20253851475728937
Validation loss: 2.400934932138071

Epoch: 6| Step: 12
Training loss: 0.2053094739705458
Validation loss: 2.4235389024402396

Epoch: 6| Step: 13
Training loss: 0.3108632018109481
Validation loss: 2.383862698347062

Epoch: 395| Step: 0
Training loss: 0.21041686656835396
Validation loss: 2.3916809122196483

Epoch: 6| Step: 1
Training loss: 0.22802092320553846
Validation loss: 2.4240538091350836

Epoch: 6| Step: 2
Training loss: 0.11742944378294914
Validation loss: 2.381922223132283

Epoch: 6| Step: 3
Training loss: 0.25405471569302657
Validation loss: 2.3764268564508093

Epoch: 6| Step: 4
Training loss: 0.1777689344740665
Validation loss: 2.368175268963896

Epoch: 6| Step: 5
Training loss: 0.1360338083653653
Validation loss: 2.3806699246572793

Epoch: 6| Step: 6
Training loss: 0.12155707995680437
Validation loss: 2.371788979181203

Epoch: 6| Step: 7
Training loss: 0.24530283671984832
Validation loss: 2.3522460563238905

Epoch: 6| Step: 8
Training loss: 0.14465591492720187
Validation loss: 2.394661444944134

Epoch: 6| Step: 9
Training loss: 0.2551083790711835
Validation loss: 2.3586020194603856

Epoch: 6| Step: 10
Training loss: 0.18522428276727895
Validation loss: 2.351443395247837

Epoch: 6| Step: 11
Training loss: 0.3716437229671308
Validation loss: 2.376660039925833

Epoch: 6| Step: 12
Training loss: 0.2607295858359743
Validation loss: 2.3873295196604363

Epoch: 6| Step: 13
Training loss: 0.2862416083342693
Validation loss: 2.3504552535053422

Epoch: 396| Step: 0
Training loss: 0.12417488913251759
Validation loss: 2.357170992265039

Epoch: 6| Step: 1
Training loss: 0.14468010119312028
Validation loss: 2.385022755052083

Epoch: 6| Step: 2
Training loss: 0.4164444768081609
Validation loss: 2.3793534962824587

Epoch: 6| Step: 3
Training loss: 0.14550897098566523
Validation loss: 2.364036222646565

Epoch: 6| Step: 4
Training loss: 0.20424683433937016
Validation loss: 2.3882675708131567

Epoch: 6| Step: 5
Training loss: 0.2452224034488969
Validation loss: 2.3774104728459906

Epoch: 6| Step: 6
Training loss: 0.16651599873682235
Validation loss: 2.3875768683163408

Epoch: 6| Step: 7
Training loss: 0.19574408530839907
Validation loss: 2.4263086802247784

Epoch: 6| Step: 8
Training loss: 0.13324371625548326
Validation loss: 2.3826798026692493

Epoch: 6| Step: 9
Training loss: 0.2187189948724694
Validation loss: 2.3983525674702246

Epoch: 6| Step: 10
Training loss: 0.17089342382433595
Validation loss: 2.43590444105512

Epoch: 6| Step: 11
Training loss: 0.1709769804167003
Validation loss: 2.433459889612615

Epoch: 6| Step: 12
Training loss: 0.22562916659367568
Validation loss: 2.433865751506089

Epoch: 6| Step: 13
Training loss: 0.32543796501763816
Validation loss: 2.4459672586138645

Epoch: 397| Step: 0
Training loss: 0.2653042315035995
Validation loss: 2.448800622808277

Epoch: 6| Step: 1
Training loss: 0.1587048686259337
Validation loss: 2.407039895699678

Epoch: 6| Step: 2
Training loss: 0.12067763297008371
Validation loss: 2.428705929408939

Epoch: 6| Step: 3
Training loss: 0.19105478053148212
Validation loss: 2.4081758224591927

Epoch: 6| Step: 4
Training loss: 0.14629917517266242
Validation loss: 2.415673163796569

Epoch: 6| Step: 5
Training loss: 0.17684741409976448
Validation loss: 2.4331486442939405

Epoch: 6| Step: 6
Training loss: 0.20924729893876914
Validation loss: 2.415032618197548

Epoch: 6| Step: 7
Training loss: 0.4021507837450339
Validation loss: 2.409513879493802

Epoch: 6| Step: 8
Training loss: 0.25468832027560645
Validation loss: 2.4018603588475798

Epoch: 6| Step: 9
Training loss: 0.16497388376556935
Validation loss: 2.4046576485925892

Epoch: 6| Step: 10
Training loss: 0.2603202291579929
Validation loss: 2.4008038536750855

Epoch: 6| Step: 11
Training loss: 0.144956999118504
Validation loss: 2.3965246935615423

Epoch: 6| Step: 12
Training loss: 0.2233745466258652
Validation loss: 2.3828045577776424

Epoch: 6| Step: 13
Training loss: 0.16349297968603752
Validation loss: 2.4081875655597735

Epoch: 398| Step: 0
Training loss: 0.1454262280725128
Validation loss: 2.379631638423545

Epoch: 6| Step: 1
Training loss: 0.2622514967625673
Validation loss: 2.3999584479819682

Epoch: 6| Step: 2
Training loss: 0.12842389372294744
Validation loss: 2.399075543665936

Epoch: 6| Step: 3
Training loss: 0.12724170164899806
Validation loss: 2.370910840743037

Epoch: 6| Step: 4
Training loss: 0.19175541423790662
Validation loss: 2.3843972775258258

Epoch: 6| Step: 5
Training loss: 0.15105080919438865
Validation loss: 2.3931053013787413

Epoch: 6| Step: 6
Training loss: 0.14822131023733287
Validation loss: 2.393220683595455

Epoch: 6| Step: 7
Training loss: 0.06929876445895174
Validation loss: 2.384700977480222

Epoch: 6| Step: 8
Training loss: 0.2014890133906973
Validation loss: 2.3819718858943584

Epoch: 6| Step: 9
Training loss: 0.1597862738623968
Validation loss: 2.38238436656762

Epoch: 6| Step: 10
Training loss: 0.25199611799716576
Validation loss: 2.3860972797902855

Epoch: 6| Step: 11
Training loss: 0.14142230295772534
Validation loss: 2.4097564658739596

Epoch: 6| Step: 12
Training loss: 0.32581401083907113
Validation loss: 2.389616735730781

Epoch: 6| Step: 13
Training loss: 0.4588320865002167
Validation loss: 2.3798719186202892

Epoch: 399| Step: 0
Training loss: 0.18057632377791002
Validation loss: 2.400354947868551

Epoch: 6| Step: 1
Training loss: 0.16681671962567912
Validation loss: 2.406168576330384

Epoch: 6| Step: 2
Training loss: 0.1272802832482682
Validation loss: 2.382315858982231

Epoch: 6| Step: 3
Training loss: 0.390366640482091
Validation loss: 2.398831601966464

Epoch: 6| Step: 4
Training loss: 0.1962326974743158
Validation loss: 2.375538756785931

Epoch: 6| Step: 5
Training loss: 0.1588396407088722
Validation loss: 2.3847096218331965

Epoch: 6| Step: 6
Training loss: 0.16901017195375787
Validation loss: 2.3670131343374883

Epoch: 6| Step: 7
Training loss: 0.10705668623989764
Validation loss: 2.3802731764694944

Epoch: 6| Step: 8
Training loss: 0.19153826890129014
Validation loss: 2.410781507742517

Epoch: 6| Step: 9
Training loss: 0.255426506609551
Validation loss: 2.3883992422903435

Epoch: 6| Step: 10
Training loss: 0.24371851479315632
Validation loss: 2.3744748047033015

Epoch: 6| Step: 11
Training loss: 0.19094216273931267
Validation loss: 2.36378672845105

Epoch: 6| Step: 12
Training loss: 0.16174403352323796
Validation loss: 2.3785605642916026

Epoch: 6| Step: 13
Training loss: 0.17170668618621648
Validation loss: 2.3822333735066388

Epoch: 400| Step: 0
Training loss: 0.10703662368065317
Validation loss: 2.3953318036619367

Epoch: 6| Step: 1
Training loss: 0.16169327452315696
Validation loss: 2.3962632216694546

Epoch: 6| Step: 2
Training loss: 0.3705980302669801
Validation loss: 2.394182001170884

Epoch: 6| Step: 3
Training loss: 0.18775997417537135
Validation loss: 2.4560810079301643

Epoch: 6| Step: 4
Training loss: 0.26111390552536007
Validation loss: 2.411670091250445

Epoch: 6| Step: 5
Training loss: 0.17603252253587973
Validation loss: 2.417110225960207

Epoch: 6| Step: 6
Training loss: 0.1787215057750229
Validation loss: 2.437306169491985

Epoch: 6| Step: 7
Training loss: 0.14506713650963862
Validation loss: 2.4249233278129934

Epoch: 6| Step: 8
Training loss: 0.27820886087008134
Validation loss: 2.41818083646181

Epoch: 6| Step: 9
Training loss: 0.10698574135878473
Validation loss: 2.424728589208535

Epoch: 6| Step: 10
Training loss: 0.11625793051843451
Validation loss: 2.393344249237136

Epoch: 6| Step: 11
Training loss: 0.16810118089935663
Validation loss: 2.399951209833676

Epoch: 6| Step: 12
Training loss: 0.2312677402393161
Validation loss: 2.394616198159173

Epoch: 6| Step: 13
Training loss: 0.2180914331912443
Validation loss: 2.3860552668668555

Epoch: 401| Step: 0
Training loss: 0.14102605744127558
Validation loss: 2.3764346721956158

Epoch: 6| Step: 1
Training loss: 0.11256804064363608
Validation loss: 2.4166206096281577

Epoch: 6| Step: 2
Training loss: 0.2524265602217743
Validation loss: 2.390788506558319

Epoch: 6| Step: 3
Training loss: 0.29225766670508735
Validation loss: 2.400486188077819

Epoch: 6| Step: 4
Training loss: 0.2067019795155287
Validation loss: 2.384585604995335

Epoch: 6| Step: 5
Training loss: 0.19289504276746325
Validation loss: 2.4206376486456107

Epoch: 6| Step: 6
Training loss: 0.1372186038203928
Validation loss: 2.403600874422035

Epoch: 6| Step: 7
Training loss: 0.1358858418692558
Validation loss: 2.425695377268714

Epoch: 6| Step: 8
Training loss: 0.17873211511089823
Validation loss: 2.4339338308696825

Epoch: 6| Step: 9
Training loss: 0.25056153057402797
Validation loss: 2.4171363203060174

Epoch: 6| Step: 10
Training loss: 0.1797241194355239
Validation loss: 2.43594569736379

Epoch: 6| Step: 11
Training loss: 0.37149106891108524
Validation loss: 2.4120376271346617

Epoch: 6| Step: 12
Training loss: 0.2598514271770171
Validation loss: 2.41068326825186

Epoch: 6| Step: 13
Training loss: 0.14454467814158187
Validation loss: 2.3707691443527565

Epoch: 402| Step: 0
Training loss: 0.14850556544710472
Validation loss: 2.374470908993862

Epoch: 6| Step: 1
Training loss: 0.13791842680160388
Validation loss: 2.391072955606043

Epoch: 6| Step: 2
Training loss: 0.20166353680083976
Validation loss: 2.3872984915542266

Epoch: 6| Step: 3
Training loss: 0.3378434782266163
Validation loss: 2.399181215787623

Epoch: 6| Step: 4
Training loss: 0.16039428234807998
Validation loss: 2.3715468990316357

Epoch: 6| Step: 5
Training loss: 0.2643229182326343
Validation loss: 2.3923127154365975

Epoch: 6| Step: 6
Training loss: 0.14464981783075131
Validation loss: 2.410170477772961

Epoch: 6| Step: 7
Training loss: 0.12540536954234652
Validation loss: 2.402679421508955

Epoch: 6| Step: 8
Training loss: 0.21853115851707078
Validation loss: 2.4193520309746424

Epoch: 6| Step: 9
Training loss: 0.1064894348532068
Validation loss: 2.3905960500552594

Epoch: 6| Step: 10
Training loss: 0.14674915543041864
Validation loss: 2.417488226530557

Epoch: 6| Step: 11
Training loss: 0.19855953053795672
Validation loss: 2.4244281247988266

Epoch: 6| Step: 12
Training loss: 0.2588042920507704
Validation loss: 2.4391365625842254

Epoch: 6| Step: 13
Training loss: 0.299140193776507
Validation loss: 2.430931722085746

Epoch: 403| Step: 0
Training loss: 0.21116708694319336
Validation loss: 2.463520453115728

Epoch: 6| Step: 1
Training loss: 0.19844226418430597
Validation loss: 2.4480804123283595

Epoch: 6| Step: 2
Training loss: 0.1476559833241633
Validation loss: 2.475146098386042

Epoch: 6| Step: 3
Training loss: 0.29048662942213954
Validation loss: 2.452450042497107

Epoch: 6| Step: 4
Training loss: 0.13370335750508353
Validation loss: 2.445311517134383

Epoch: 6| Step: 5
Training loss: 0.11517785189330977
Validation loss: 2.421274419409589

Epoch: 6| Step: 6
Training loss: 0.22074020546863923
Validation loss: 2.4302879883726294

Epoch: 6| Step: 7
Training loss: 0.15968079471694188
Validation loss: 2.4241998613222795

Epoch: 6| Step: 8
Training loss: 0.23336956212655835
Validation loss: 2.4085956727240547

Epoch: 6| Step: 9
Training loss: 0.18246333122929095
Validation loss: 2.404224886526699

Epoch: 6| Step: 10
Training loss: 0.1839680609789789
Validation loss: 2.3953511566569796

Epoch: 6| Step: 11
Training loss: 0.21013855629216904
Validation loss: 2.3852970075187816

Epoch: 6| Step: 12
Training loss: 0.3699132110644556
Validation loss: 2.3854369575385137

Epoch: 6| Step: 13
Training loss: 0.06373642767621164
Validation loss: 2.391441883924607

Epoch: 404| Step: 0
Training loss: 0.1202046417134193
Validation loss: 2.3834869995534995

Epoch: 6| Step: 1
Training loss: 0.14432316699075712
Validation loss: 2.3690482272395355

Epoch: 6| Step: 2
Training loss: 0.15180705976259634
Validation loss: 2.3672291238171814

Epoch: 6| Step: 3
Training loss: 0.1559998834984754
Validation loss: 2.3965775687918365

Epoch: 6| Step: 4
Training loss: 0.3609491577577732
Validation loss: 2.3829840291896573

Epoch: 6| Step: 5
Training loss: 0.21252580759466932
Validation loss: 2.4270551851441176

Epoch: 6| Step: 6
Training loss: 0.2390619449359708
Validation loss: 2.385290261191186

Epoch: 6| Step: 7
Training loss: 0.15420482400632105
Validation loss: 2.4093341476683916

Epoch: 6| Step: 8
Training loss: 0.29007859394129076
Validation loss: 2.4235930478914276

Epoch: 6| Step: 9
Training loss: 0.18045896280675527
Validation loss: 2.3971336203295452

Epoch: 6| Step: 10
Training loss: 0.13483297351373413
Validation loss: 2.422022361651871

Epoch: 6| Step: 11
Training loss: 0.2103061145221206
Validation loss: 2.3825705020910966

Epoch: 6| Step: 12
Training loss: 0.14812293099515658
Validation loss: 2.4009323315885664

Epoch: 6| Step: 13
Training loss: 0.09738695685163343
Validation loss: 2.402998315833005

Epoch: 405| Step: 0
Training loss: 0.10431907253289799
Validation loss: 2.381050849510319

Epoch: 6| Step: 1
Training loss: 0.32902875825088995
Validation loss: 2.361684736048868

Epoch: 6| Step: 2
Training loss: 0.20653174980843064
Validation loss: 2.3830026234359165

Epoch: 6| Step: 3
Training loss: 0.10159785773956068
Validation loss: 2.3829191913250716

Epoch: 6| Step: 4
Training loss: 0.14709282078438338
Validation loss: 2.379558470657699

Epoch: 6| Step: 5
Training loss: 0.20110080908157785
Validation loss: 2.416746907728435

Epoch: 6| Step: 6
Training loss: 0.2094353240209438
Validation loss: 2.4145346983926186

Epoch: 6| Step: 7
Training loss: 0.19606309666358893
Validation loss: 2.4032954666124042

Epoch: 6| Step: 8
Training loss: 0.13898205653889503
Validation loss: 2.4207551937600176

Epoch: 6| Step: 9
Training loss: 0.24415059641502151
Validation loss: 2.3984047380856413

Epoch: 6| Step: 10
Training loss: 0.1341257869954231
Validation loss: 2.382389130377317

Epoch: 6| Step: 11
Training loss: 0.13586235901910113
Validation loss: 2.391559703084748

Epoch: 6| Step: 12
Training loss: 0.2024570449846467
Validation loss: 2.4428012259218033

Epoch: 6| Step: 13
Training loss: 0.09806259967654227
Validation loss: 2.4091799184126192

Epoch: 406| Step: 0
Training loss: 0.14954589189097267
Validation loss: 2.407143351223192

Epoch: 6| Step: 1
Training loss: 0.16701766148846905
Validation loss: 2.4592790819706662

Epoch: 6| Step: 2
Training loss: 0.13982730694219375
Validation loss: 2.4280937936637614

Epoch: 6| Step: 3
Training loss: 0.059041537445113604
Validation loss: 2.451926955736904

Epoch: 6| Step: 4
Training loss: 0.12947035673075835
Validation loss: 2.4568604829382865

Epoch: 6| Step: 5
Training loss: 0.42177146064910753
Validation loss: 2.448684903470734

Epoch: 6| Step: 6
Training loss: 0.1533646124724219
Validation loss: 2.4362828739564533

Epoch: 6| Step: 7
Training loss: 0.10238595157950192
Validation loss: 2.419056722191949

Epoch: 6| Step: 8
Training loss: 0.14871875569038356
Validation loss: 2.457638226870391

Epoch: 6| Step: 9
Training loss: 0.2500534596504951
Validation loss: 2.4376437862867917

Epoch: 6| Step: 10
Training loss: 0.13001799181542126
Validation loss: 2.4495198219372973

Epoch: 6| Step: 11
Training loss: 0.11208696822635561
Validation loss: 2.4582086896156885

Epoch: 6| Step: 12
Training loss: 0.21080102744327117
Validation loss: 2.4531266686845523

Epoch: 6| Step: 13
Training loss: 0.16809940246968555
Validation loss: 2.4567394994061273

Epoch: 407| Step: 0
Training loss: 0.1275934868514846
Validation loss: 2.4629259687510805

Epoch: 6| Step: 1
Training loss: 0.21816048205109087
Validation loss: 2.4269809415230794

Epoch: 6| Step: 2
Training loss: 0.18159808409295677
Validation loss: 2.475176117440681

Epoch: 6| Step: 3
Training loss: 0.2499175531813198
Validation loss: 2.4345760072019647

Epoch: 6| Step: 4
Training loss: 0.0874488483079802
Validation loss: 2.434569343725411

Epoch: 6| Step: 5
Training loss: 0.13987289742976694
Validation loss: 2.374181861265448

Epoch: 6| Step: 6
Training loss: 0.15254715032297717
Validation loss: 2.4003929409780653

Epoch: 6| Step: 7
Training loss: 0.32505013831070684
Validation loss: 2.429684340933226

Epoch: 6| Step: 8
Training loss: 0.17127462128296814
Validation loss: 2.4178216375132995

Epoch: 6| Step: 9
Training loss: 0.12842049976944125
Validation loss: 2.3892648189178654

Epoch: 6| Step: 10
Training loss: 0.1935432022644269
Validation loss: 2.385595747416012

Epoch: 6| Step: 11
Training loss: 0.15235000988741457
Validation loss: 2.4127898872914595

Epoch: 6| Step: 12
Training loss: 0.21187751208703792
Validation loss: 2.415949578944741

Epoch: 6| Step: 13
Training loss: 0.12497591740362494
Validation loss: 2.4026903368162134

Epoch: 408| Step: 0
Training loss: 0.21370593397544257
Validation loss: 2.4052735083784693

Epoch: 6| Step: 1
Training loss: 0.08320505605614824
Validation loss: 2.4196583088218797

Epoch: 6| Step: 2
Training loss: 0.17704131642379764
Validation loss: 2.405771952993941

Epoch: 6| Step: 3
Training loss: 0.3053598321949216
Validation loss: 2.412079656214527

Epoch: 6| Step: 4
Training loss: 0.16469285983388332
Validation loss: 2.3882412528216688

Epoch: 6| Step: 5
Training loss: 0.15399242496206064
Validation loss: 2.4145322489260814

Epoch: 6| Step: 6
Training loss: 0.2526269522284304
Validation loss: 2.4033261601853013

Epoch: 6| Step: 7
Training loss: 0.09601003714396053
Validation loss: 2.4167521853762945

Epoch: 6| Step: 8
Training loss: 0.15476742952807376
Validation loss: 2.3889479181116484

Epoch: 6| Step: 9
Training loss: 0.1263627336003126
Validation loss: 2.3699475060118464

Epoch: 6| Step: 10
Training loss: 0.08444188500170834
Validation loss: 2.4072919048671415

Epoch: 6| Step: 11
Training loss: 0.2036632412513407
Validation loss: 2.430810202654876

Epoch: 6| Step: 12
Training loss: 0.12921815763658318
Validation loss: 2.387063018533277

Epoch: 6| Step: 13
Training loss: 0.2761670793389426
Validation loss: 2.404651642095412

Epoch: 409| Step: 0
Training loss: 0.23942948235540862
Validation loss: 2.4198379617923456

Epoch: 6| Step: 1
Training loss: 0.08319112227730352
Validation loss: 2.411624118086225

Epoch: 6| Step: 2
Training loss: 0.17774677233374367
Validation loss: 2.409142077178794

Epoch: 6| Step: 3
Training loss: 0.12182570172603302
Validation loss: 2.405851641461694

Epoch: 6| Step: 4
Training loss: 0.13330589536141899
Validation loss: 2.4023578981199187

Epoch: 6| Step: 5
Training loss: 0.11755580246630408
Validation loss: 2.4103229296409467

Epoch: 6| Step: 6
Training loss: 0.20522083584867024
Validation loss: 2.4036759223201707

Epoch: 6| Step: 7
Training loss: 0.14737974546361854
Validation loss: 2.3757762126244217

Epoch: 6| Step: 8
Training loss: 0.09881670493836905
Validation loss: 2.4126377262564893

Epoch: 6| Step: 9
Training loss: 0.07160580176640766
Validation loss: 2.3824347148304374

Epoch: 6| Step: 10
Training loss: 0.21914270607407244
Validation loss: 2.3990114174789197

Epoch: 6| Step: 11
Training loss: 0.32013287974188703
Validation loss: 2.3979100547294463

Epoch: 6| Step: 12
Training loss: 0.16228240327225116
Validation loss: 2.3713332531299565

Epoch: 6| Step: 13
Training loss: 0.19220508557011173
Validation loss: 2.3882084524749296

Epoch: 410| Step: 0
Training loss: 0.22563689345821974
Validation loss: 2.372390613248719

Epoch: 6| Step: 1
Training loss: 0.161171532804835
Validation loss: 2.4050304900723254

Epoch: 6| Step: 2
Training loss: 0.1550208862906801
Validation loss: 2.3906230075309653

Epoch: 6| Step: 3
Training loss: 0.38816583940702554
Validation loss: 2.388905505674008

Epoch: 6| Step: 4
Training loss: 0.10125230221426856
Validation loss: 2.3993046769377484

Epoch: 6| Step: 5
Training loss: 0.19898193907547873
Validation loss: 2.4147176135401724

Epoch: 6| Step: 6
Training loss: 0.1882446027839454
Validation loss: 2.422121137217789

Epoch: 6| Step: 7
Training loss: 0.17729587749033507
Validation loss: 2.4361433961155594

Epoch: 6| Step: 8
Training loss: 0.07860699918773914
Validation loss: 2.401291608908631

Epoch: 6| Step: 9
Training loss: 0.11543161677831486
Validation loss: 2.377121240357939

Epoch: 6| Step: 10
Training loss: 0.14171401852928667
Validation loss: 2.3921033542978956

Epoch: 6| Step: 11
Training loss: 0.14643679799877515
Validation loss: 2.358570470496923

Epoch: 6| Step: 12
Training loss: 0.13644477094951787
Validation loss: 2.357535333031648

Epoch: 6| Step: 13
Training loss: 0.19170054368714098
Validation loss: 2.3822917700749824

Epoch: 411| Step: 0
Training loss: 0.21372069824441856
Validation loss: 2.372967275167898

Epoch: 6| Step: 1
Training loss: 0.10514953661286867
Validation loss: 2.4117465622488785

Epoch: 6| Step: 2
Training loss: 0.18113280651099922
Validation loss: 2.392226369488995

Epoch: 6| Step: 3
Training loss: 0.11454270375839089
Validation loss: 2.4003453633872995

Epoch: 6| Step: 4
Training loss: 0.2290256465523601
Validation loss: 2.4030607866022957

Epoch: 6| Step: 5
Training loss: 0.132283405048489
Validation loss: 2.4365820059252608

Epoch: 6| Step: 6
Training loss: 0.35123001907235846
Validation loss: 2.4199838924753285

Epoch: 6| Step: 7
Training loss: 0.09187577286220042
Validation loss: 2.416775850715703

Epoch: 6| Step: 8
Training loss: 0.11390724360918286
Validation loss: 2.4203378468050074

Epoch: 6| Step: 9
Training loss: 0.1565162059921292
Validation loss: 2.390842516587343

Epoch: 6| Step: 10
Training loss: 0.15967804763200497
Validation loss: 2.41784585487407

Epoch: 6| Step: 11
Training loss: 0.26767890313216197
Validation loss: 2.3945284085644234

Epoch: 6| Step: 12
Training loss: 0.25345937578025696
Validation loss: 2.390979267947926

Epoch: 6| Step: 13
Training loss: 0.11187935186025458
Validation loss: 2.3943069728497393

Epoch: 412| Step: 0
Training loss: 0.12486192408635206
Validation loss: 2.387416825523207

Epoch: 6| Step: 1
Training loss: 0.10912376739192528
Validation loss: 2.401045215054103

Epoch: 6| Step: 2
Training loss: 0.32161983171677444
Validation loss: 2.3828091980958166

Epoch: 6| Step: 3
Training loss: 0.16421860125940557
Validation loss: 2.3707758054838783

Epoch: 6| Step: 4
Training loss: 0.18774666059015693
Validation loss: 2.386090004429312

Epoch: 6| Step: 5
Training loss: 0.19493249164787493
Validation loss: 2.3999890368221464

Epoch: 6| Step: 6
Training loss: 0.1270671918915621
Validation loss: 2.4093851516071605

Epoch: 6| Step: 7
Training loss: 0.1289914023312094
Validation loss: 2.427953465268878

Epoch: 6| Step: 8
Training loss: 0.3471040626649972
Validation loss: 2.430145041219032

Epoch: 6| Step: 9
Training loss: 0.16053005534145798
Validation loss: 2.431392788075531

Epoch: 6| Step: 10
Training loss: 0.1061463532428843
Validation loss: 2.4261260609688113

Epoch: 6| Step: 11
Training loss: 0.2668887118540137
Validation loss: 2.4411886726804624

Epoch: 6| Step: 12
Training loss: 0.21703348050162546
Validation loss: 2.4560081970568

Epoch: 6| Step: 13
Training loss: 0.14620861163723908
Validation loss: 2.431623275634981

Epoch: 413| Step: 0
Training loss: 0.08734906026908451
Validation loss: 2.448516068723797

Epoch: 6| Step: 1
Training loss: 0.1676283869916759
Validation loss: 2.4530275177997094

Epoch: 6| Step: 2
Training loss: 0.2723641172268342
Validation loss: 2.4016271814241303

Epoch: 6| Step: 3
Training loss: 0.16624941912707336
Validation loss: 2.4309593796526885

Epoch: 6| Step: 4
Training loss: 0.3800373694591626
Validation loss: 2.3804264284175294

Epoch: 6| Step: 5
Training loss: 0.12796306902580146
Validation loss: 2.382396765150718

Epoch: 6| Step: 6
Training loss: 0.12903201586033408
Validation loss: 2.405963803442977

Epoch: 6| Step: 7
Training loss: 0.12621850430548967
Validation loss: 2.3783996399298633

Epoch: 6| Step: 8
Training loss: 0.1805422913791945
Validation loss: 2.3952524780264866

Epoch: 6| Step: 9
Training loss: 0.1596598025225575
Validation loss: 2.407819979672955

Epoch: 6| Step: 10
Training loss: 0.29788252872776777
Validation loss: 2.4085670228654776

Epoch: 6| Step: 11
Training loss: 0.21471318699283273
Validation loss: 2.4168800196883806

Epoch: 6| Step: 12
Training loss: 0.16796286705715394
Validation loss: 2.4389181499993393

Epoch: 6| Step: 13
Training loss: 0.16819217150114268
Validation loss: 2.439643355038294

Epoch: 414| Step: 0
Training loss: 0.15025342528894609
Validation loss: 2.4245121237915974

Epoch: 6| Step: 1
Training loss: 0.17549280766851896
Validation loss: 2.4017089031600807

Epoch: 6| Step: 2
Training loss: 0.1607935368038764
Validation loss: 2.409896616685156

Epoch: 6| Step: 3
Training loss: 0.07453252007044067
Validation loss: 2.424071785882042

Epoch: 6| Step: 4
Training loss: 0.17134358876826208
Validation loss: 2.3866878901127073

Epoch: 6| Step: 5
Training loss: 0.13475664772318943
Validation loss: 2.389623110984991

Epoch: 6| Step: 6
Training loss: 0.30076319157279235
Validation loss: 2.3860712263423864

Epoch: 6| Step: 7
Training loss: 0.16454535908354387
Validation loss: 2.392747222704209

Epoch: 6| Step: 8
Training loss: 0.1562424359874923
Validation loss: 2.382593298071584

Epoch: 6| Step: 9
Training loss: 0.2357745030716331
Validation loss: 2.386679103618635

Epoch: 6| Step: 10
Training loss: 0.21330658060081933
Validation loss: 2.4084257161324527

Epoch: 6| Step: 11
Training loss: 0.35840190916952547
Validation loss: 2.4174324408480206

Epoch: 6| Step: 12
Training loss: 0.22790654023221427
Validation loss: 2.4312296196859196

Epoch: 6| Step: 13
Training loss: 0.18907562478277634
Validation loss: 2.411986450235617

Epoch: 415| Step: 0
Training loss: 0.14546820722411088
Validation loss: 2.4339414946030433

Epoch: 6| Step: 1
Training loss: 0.22598108964636826
Validation loss: 2.409090656266679

Epoch: 6| Step: 2
Training loss: 0.170545933799925
Validation loss: 2.405872333977622

Epoch: 6| Step: 3
Training loss: 0.25580124522302017
Validation loss: 2.4036375646087107

Epoch: 6| Step: 4
Training loss: 0.3611142118129308
Validation loss: 2.4247164863827897

Epoch: 6| Step: 5
Training loss: 0.17894806269156335
Validation loss: 2.416615442815869

Epoch: 6| Step: 6
Training loss: 0.1660792845799391
Validation loss: 2.423630601351857

Epoch: 6| Step: 7
Training loss: 0.22479560429362463
Validation loss: 2.410923904296501

Epoch: 6| Step: 8
Training loss: 0.13620666241206816
Validation loss: 2.4108039128150187

Epoch: 6| Step: 9
Training loss: 0.13635926669743637
Validation loss: 2.410714964164729

Epoch: 6| Step: 10
Training loss: 0.164607437296191
Validation loss: 2.414573692036317

Epoch: 6| Step: 11
Training loss: 0.2029765118207986
Validation loss: 2.4233775457991458

Epoch: 6| Step: 12
Training loss: 0.31278366089310095
Validation loss: 2.395464176577018

Epoch: 6| Step: 13
Training loss: 0.18201138997920668
Validation loss: 2.417324807871677

Epoch: 416| Step: 0
Training loss: 0.14594713876615992
Validation loss: 2.428400574677276

Epoch: 6| Step: 1
Training loss: 0.15230810530908223
Validation loss: 2.4189440730430865

Epoch: 6| Step: 2
Training loss: 0.1678148163115264
Validation loss: 2.3981591144912717

Epoch: 6| Step: 3
Training loss: 0.13821530062584306
Validation loss: 2.406769728203246

Epoch: 6| Step: 4
Training loss: 0.14894595400404226
Validation loss: 2.3994374164451084

Epoch: 6| Step: 5
Training loss: 0.12729441910071196
Validation loss: 2.389932545967054

Epoch: 6| Step: 6
Training loss: 0.22312707644920224
Validation loss: 2.4056973269446247

Epoch: 6| Step: 7
Training loss: 0.16398025903720403
Validation loss: 2.413965848979181

Epoch: 6| Step: 8
Training loss: 0.12039407358175085
Validation loss: 2.3965521384644513

Epoch: 6| Step: 9
Training loss: 0.15199779697205176
Validation loss: 2.4199246855595997

Epoch: 6| Step: 10
Training loss: 0.18790610362671634
Validation loss: 2.429946426107573

Epoch: 6| Step: 11
Training loss: 0.3822342144293269
Validation loss: 2.4368446821742618

Epoch: 6| Step: 12
Training loss: 0.21509743365140568
Validation loss: 2.4227542409856166

Epoch: 6| Step: 13
Training loss: 0.19776330619417662
Validation loss: 2.40779985435702

Epoch: 417| Step: 0
Training loss: 0.10302120570117754
Validation loss: 2.4091052175578986

Epoch: 6| Step: 1
Training loss: 0.370949526417501
Validation loss: 2.4270371797931736

Epoch: 6| Step: 2
Training loss: 0.15075853478096135
Validation loss: 2.3961815404894673

Epoch: 6| Step: 3
Training loss: 0.15670083094697887
Validation loss: 2.400980115368536

Epoch: 6| Step: 4
Training loss: 0.16095043611849583
Validation loss: 2.3886526058027098

Epoch: 6| Step: 5
Training loss: 0.2013370243425222
Validation loss: 2.3931339113781207

Epoch: 6| Step: 6
Training loss: 0.13103374564025222
Validation loss: 2.4133691500551624

Epoch: 6| Step: 7
Training loss: 0.11982513215976767
Validation loss: 2.401351902973761

Epoch: 6| Step: 8
Training loss: 0.2525342405350082
Validation loss: 2.4093391726170013

Epoch: 6| Step: 9
Training loss: 0.2296690563659842
Validation loss: 2.401960887825715

Epoch: 6| Step: 10
Training loss: 0.208082517005359
Validation loss: 2.3890895321240584

Epoch: 6| Step: 11
Training loss: 0.21715354791272953
Validation loss: 2.410622302030902

Epoch: 6| Step: 12
Training loss: 0.20258409667122987
Validation loss: 2.4181968839380588

Epoch: 6| Step: 13
Training loss: 0.10921775208919149
Validation loss: 2.43995879891111

Epoch: 418| Step: 0
Training loss: 0.2433812270908321
Validation loss: 2.449909117944463

Epoch: 6| Step: 1
Training loss: 0.20487045490827827
Validation loss: 2.476061955856325

Epoch: 6| Step: 2
Training loss: 0.1702298081736494
Validation loss: 2.4252641403545563

Epoch: 6| Step: 3
Training loss: 0.20443189619355753
Validation loss: 2.4567200007587515

Epoch: 6| Step: 4
Training loss: 0.13425337837672865
Validation loss: 2.4078362133188813

Epoch: 6| Step: 5
Training loss: 0.3436252194123246
Validation loss: 2.444865126882694

Epoch: 6| Step: 6
Training loss: 0.22914085278920798
Validation loss: 2.4081287675117267

Epoch: 6| Step: 7
Training loss: 0.1942439796221779
Validation loss: 2.3835888766988598

Epoch: 6| Step: 8
Training loss: 0.12012294429847056
Validation loss: 2.35310025517742

Epoch: 6| Step: 9
Training loss: 0.11219686224718252
Validation loss: 2.3552179492977405

Epoch: 6| Step: 10
Training loss: 0.1918963463772644
Validation loss: 2.340948373278894

Epoch: 6| Step: 11
Training loss: 0.15031025956242808
Validation loss: 2.3466634229819867

Epoch: 6| Step: 12
Training loss: 0.20901153958327356
Validation loss: 2.3653097883063676

Epoch: 6| Step: 13
Training loss: 0.194259206681318
Validation loss: 2.371470939774962

Epoch: 419| Step: 0
Training loss: 0.17466558750614852
Validation loss: 2.3752970965729836

Epoch: 6| Step: 1
Training loss: 0.18622404306465207
Validation loss: 2.384673498313461

Epoch: 6| Step: 2
Training loss: 0.26079913028333607
Validation loss: 2.434622479389319

Epoch: 6| Step: 3
Training loss: 0.19920139611149454
Validation loss: 2.4515885290551744

Epoch: 6| Step: 4
Training loss: 0.3064447980381651
Validation loss: 2.4990679418570627

Epoch: 6| Step: 5
Training loss: 0.21491845306035182
Validation loss: 2.4406001357340252

Epoch: 6| Step: 6
Training loss: 0.08983534276022145
Validation loss: 2.432337221618133

Epoch: 6| Step: 7
Training loss: 0.20093060812395677
Validation loss: 2.3909735525061717

Epoch: 6| Step: 8
Training loss: 0.2750125210252387
Validation loss: 2.366298403924619

Epoch: 6| Step: 9
Training loss: 0.1209079177911003
Validation loss: 2.373724110061191

Epoch: 6| Step: 10
Training loss: 0.21900119153497705
Validation loss: 2.377191228971105

Epoch: 6| Step: 11
Training loss: 0.3266245846846079
Validation loss: 2.3859514648171514

Epoch: 6| Step: 12
Training loss: 0.2326483944987926
Validation loss: 2.445841009561875

Epoch: 6| Step: 13
Training loss: 0.19290817483732353
Validation loss: 2.4517647837719077

Epoch: 420| Step: 0
Training loss: 0.3183631311674803
Validation loss: 2.4344223361379975

Epoch: 6| Step: 1
Training loss: 0.15702527352722084
Validation loss: 2.485662771382193

Epoch: 6| Step: 2
Training loss: 0.19783698326689786
Validation loss: 2.4509965843815538

Epoch: 6| Step: 3
Training loss: 0.22768183146207752
Validation loss: 2.465328731719926

Epoch: 6| Step: 4
Training loss: 0.35474225096408285
Validation loss: 2.487710385622049

Epoch: 6| Step: 5
Training loss: 0.2864046075319102
Validation loss: 2.4463792702029945

Epoch: 6| Step: 6
Training loss: 0.31549590038818986
Validation loss: 2.4132993039751884

Epoch: 6| Step: 7
Training loss: 0.43688175250771183
Validation loss: 2.417689258948216

Epoch: 6| Step: 8
Training loss: 0.30820174609747286
Validation loss: 2.429409958756343

Epoch: 6| Step: 9
Training loss: 0.396023938649958
Validation loss: 2.4428597277902626

Epoch: 6| Step: 10
Training loss: 0.5121087779166017
Validation loss: 2.50060925699471

Epoch: 6| Step: 11
Training loss: 0.5429295038543661
Validation loss: 2.50137260656899

Epoch: 6| Step: 12
Training loss: 0.2665180592537301
Validation loss: 2.476884875735846

Epoch: 6| Step: 13
Training loss: 0.2560641364850001
Validation loss: 2.486190320482435

Epoch: 421| Step: 0
Training loss: 0.3141072189225937
Validation loss: 2.4543535834473382

Epoch: 6| Step: 1
Training loss: 0.23290436615534568
Validation loss: 2.4523598187103057

Epoch: 6| Step: 2
Training loss: 0.29016968325741893
Validation loss: 2.4393279954380334

Epoch: 6| Step: 3
Training loss: 0.2156659001108188
Validation loss: 2.4228589814187127

Epoch: 6| Step: 4
Training loss: 0.21739147885331117
Validation loss: 2.3840491518074263

Epoch: 6| Step: 5
Training loss: 0.3437751522398986
Validation loss: 2.386461855321337

Epoch: 6| Step: 6
Training loss: 0.300108379913506
Validation loss: 2.3552451767295834

Epoch: 6| Step: 7
Training loss: 0.22021830317112379
Validation loss: 2.346775559342955

Epoch: 6| Step: 8
Training loss: 0.2216319146123836
Validation loss: 2.307810030972178

Epoch: 6| Step: 9
Training loss: 0.2990564583474048
Validation loss: 2.3016809885775045

Epoch: 6| Step: 10
Training loss: 0.2818915679021031
Validation loss: 2.2804455880582926

Epoch: 6| Step: 11
Training loss: 0.4688272094717623
Validation loss: 2.300607649758991

Epoch: 6| Step: 12
Training loss: 0.3162036765326985
Validation loss: 2.3226975320557335

Epoch: 6| Step: 13
Training loss: 0.13460998946817332
Validation loss: 2.3294821048256793

Epoch: 422| Step: 0
Training loss: 0.2881609027115838
Validation loss: 2.379906013399883

Epoch: 6| Step: 1
Training loss: 0.2321943243058393
Validation loss: 2.380418141142277

Epoch: 6| Step: 2
Training loss: 0.18345231837933648
Validation loss: 2.4022769961723225

Epoch: 6| Step: 3
Training loss: 0.27134714843597046
Validation loss: 2.4320051839574357

Epoch: 6| Step: 4
Training loss: 0.23625030497374858
Validation loss: 2.4545587546079837

Epoch: 6| Step: 5
Training loss: 0.2769924544802632
Validation loss: 2.4673380305051973

Epoch: 6| Step: 6
Training loss: 0.18198034860030252
Validation loss: 2.450511157714919

Epoch: 6| Step: 7
Training loss: 0.5143563529304479
Validation loss: 2.480064844318449

Epoch: 6| Step: 8
Training loss: 0.28805903939576744
Validation loss: 2.5103782195068334

Epoch: 6| Step: 9
Training loss: 0.2143744805666133
Validation loss: 2.524592559489812

Epoch: 6| Step: 10
Training loss: 0.3350409920899175
Validation loss: 2.491112549899429

Epoch: 6| Step: 11
Training loss: 0.3490759226780465
Validation loss: 2.4817429335354766

Epoch: 6| Step: 12
Training loss: 0.27736404505873585
Validation loss: 2.476797446050778

Epoch: 6| Step: 13
Training loss: 0.4314431131288724
Validation loss: 2.445972565184675

Epoch: 423| Step: 0
Training loss: 0.3310620692507588
Validation loss: 2.4930541814247533

Epoch: 6| Step: 1
Training loss: 0.23412451869744047
Validation loss: 2.4466058625627496

Epoch: 6| Step: 2
Training loss: 0.23424209164131884
Validation loss: 2.4242301998044047

Epoch: 6| Step: 3
Training loss: 0.41023342678038216
Validation loss: 2.4133330221090397

Epoch: 6| Step: 4
Training loss: 0.4337462595192958
Validation loss: 2.4082238255211497

Epoch: 6| Step: 5
Training loss: 0.37801953413358047
Validation loss: 2.3742267103184265

Epoch: 6| Step: 6
Training loss: 0.1793951787298372
Validation loss: 2.358311153124792

Epoch: 6| Step: 7
Training loss: 0.17572117944673266
Validation loss: 2.3596525615068358

Epoch: 6| Step: 8
Training loss: 0.4191890443278893
Validation loss: 2.3825276135084854

Epoch: 6| Step: 9
Training loss: 0.5233143049423343
Validation loss: 2.4022265301870873

Epoch: 6| Step: 10
Training loss: 0.5490943832997353
Validation loss: 2.437563255631485

Epoch: 6| Step: 11
Training loss: 0.24891676768598964
Validation loss: 2.412793611425724

Epoch: 6| Step: 12
Training loss: 0.2707640333034768
Validation loss: 2.3622841261266334

Epoch: 6| Step: 13
Training loss: 0.29134971847566404
Validation loss: 2.3992284237801806

Epoch: 424| Step: 0
Training loss: 0.15384168117611394
Validation loss: 2.4141674858532296

Epoch: 6| Step: 1
Training loss: 0.4077044822609754
Validation loss: 2.455801335803709

Epoch: 6| Step: 2
Training loss: 0.3118233866019292
Validation loss: 2.449315892897248

Epoch: 6| Step: 3
Training loss: 0.357459686447187
Validation loss: 2.455017253031584

Epoch: 6| Step: 4
Training loss: 0.2391231313498827
Validation loss: 2.435482961477857

Epoch: 6| Step: 5
Training loss: 0.23149542125258368
Validation loss: 2.4196579549471067

Epoch: 6| Step: 6
Training loss: 0.23478578490466714
Validation loss: 2.3805901266145315

Epoch: 6| Step: 7
Training loss: 0.24075084312336886
Validation loss: 2.393224077452419

Epoch: 6| Step: 8
Training loss: 0.2435456005808802
Validation loss: 2.3671253258046483

Epoch: 6| Step: 9
Training loss: 0.4401816200254684
Validation loss: 2.377255500531304

Epoch: 6| Step: 10
Training loss: 0.4553566272850217
Validation loss: 2.384061905192393

Epoch: 6| Step: 11
Training loss: 0.3037322548992885
Validation loss: 2.349273061016584

Epoch: 6| Step: 12
Training loss: 0.314660673181805
Validation loss: 2.388217592949336

Epoch: 6| Step: 13
Training loss: 0.3979057054191619
Validation loss: 2.3803517848205344

Epoch: 425| Step: 0
Training loss: 0.30935248524207193
Validation loss: 2.3316526893947898

Epoch: 6| Step: 1
Training loss: 0.23769077243402895
Validation loss: 2.3712256902141746

Epoch: 6| Step: 2
Training loss: 0.40475922099961453
Validation loss: 2.3973537656948327

Epoch: 6| Step: 3
Training loss: 0.20214259558450856
Validation loss: 2.4117110095262024

Epoch: 6| Step: 4
Training loss: 0.33539960735883234
Validation loss: 2.4433127500184155

Epoch: 6| Step: 5
Training loss: 0.4338478684015897
Validation loss: 2.4616907745977534

Epoch: 6| Step: 6
Training loss: 0.4325892006667182
Validation loss: 2.4628160199677187

Epoch: 6| Step: 7
Training loss: 0.24442003664406783
Validation loss: 2.4713137632303113

Epoch: 6| Step: 8
Training loss: 0.3392573152932678
Validation loss: 2.450694376320131

Epoch: 6| Step: 9
Training loss: 0.17471807880985687
Validation loss: 2.4740231782783755

Epoch: 6| Step: 10
Training loss: 0.2643923769982375
Validation loss: 2.468620277154465

Epoch: 6| Step: 11
Training loss: 0.29694583951126546
Validation loss: 2.4297887683881823

Epoch: 6| Step: 12
Training loss: 0.2961704527212742
Validation loss: 2.4297316020002735

Epoch: 6| Step: 13
Training loss: 0.22432029199286255
Validation loss: 2.417895607853673

Epoch: 426| Step: 0
Training loss: 0.259591137213581
Validation loss: 2.4165468309992786

Epoch: 6| Step: 1
Training loss: 0.3184532775938435
Validation loss: 2.3838065126516734

Epoch: 6| Step: 2
Training loss: 0.2670854501868482
Validation loss: 2.350143805410544

Epoch: 6| Step: 3
Training loss: 0.3059291725856725
Validation loss: 2.3584944536471544

Epoch: 6| Step: 4
Training loss: 0.42225252143509057
Validation loss: 2.2985936422683557

Epoch: 6| Step: 5
Training loss: 0.2458141039881591
Validation loss: 2.3289768620301987

Epoch: 6| Step: 6
Training loss: 0.26727472632689125
Validation loss: 2.3099805626284264

Epoch: 6| Step: 7
Training loss: 0.24386885202949718
Validation loss: 2.3254576458126612

Epoch: 6| Step: 8
Training loss: 0.24246181058288585
Validation loss: 2.3064625862809125

Epoch: 6| Step: 9
Training loss: 0.22549881842350178
Validation loss: 2.3009859694553665

Epoch: 6| Step: 10
Training loss: 0.26225875543228655
Validation loss: 2.339642759063386

Epoch: 6| Step: 11
Training loss: 0.19564255483306314
Validation loss: 2.3449255496638335

Epoch: 6| Step: 12
Training loss: 0.22827414444786157
Validation loss: 2.3535667357036933

Epoch: 6| Step: 13
Training loss: 0.20846124934108207
Validation loss: 2.3468229301237185

Epoch: 427| Step: 0
Training loss: 0.36120669412250134
Validation loss: 2.4026793180106916

Epoch: 6| Step: 1
Training loss: 0.147648426888121
Validation loss: 2.402382401553029

Epoch: 6| Step: 2
Training loss: 0.16692990262472102
Validation loss: 2.448184589149371

Epoch: 6| Step: 3
Training loss: 0.18401021593696393
Validation loss: 2.425339388908044

Epoch: 6| Step: 4
Training loss: 0.17658937975421096
Validation loss: 2.4591885947908914

Epoch: 6| Step: 5
Training loss: 0.250954415498245
Validation loss: 2.4641569482224814

Epoch: 6| Step: 6
Training loss: 0.30671712807893536
Validation loss: 2.437733176021543

Epoch: 6| Step: 7
Training loss: 0.20347852387034965
Validation loss: 2.4323428667413456

Epoch: 6| Step: 8
Training loss: 0.2189474662109946
Validation loss: 2.4227384141643977

Epoch: 6| Step: 9
Training loss: 0.2053605904571129
Validation loss: 2.3933160434397385

Epoch: 6| Step: 10
Training loss: 0.21570255121958187
Validation loss: 2.3913948138111425

Epoch: 6| Step: 11
Training loss: 0.20456526069165207
Validation loss: 2.393911525768859

Epoch: 6| Step: 12
Training loss: 0.2492491652724389
Validation loss: 2.3455034026333084

Epoch: 6| Step: 13
Training loss: 0.2533715119161775
Validation loss: 2.4095201379991678

Epoch: 428| Step: 0
Training loss: 0.24868234199501418
Validation loss: 2.3407457081322818

Epoch: 6| Step: 1
Training loss: 0.24767854331487177
Validation loss: 2.380158653520793

Epoch: 6| Step: 2
Training loss: 0.17455873821895448
Validation loss: 2.3746550968145015

Epoch: 6| Step: 3
Training loss: 0.22677305730524402
Validation loss: 2.394389239937755

Epoch: 6| Step: 4
Training loss: 0.3449709299009837
Validation loss: 2.3795836128705012

Epoch: 6| Step: 5
Training loss: 0.17517662437730286
Validation loss: 2.439696811021411

Epoch: 6| Step: 6
Training loss: 0.1880522185748293
Validation loss: 2.430192395653156

Epoch: 6| Step: 7
Training loss: 0.24781587312189773
Validation loss: 2.436546167455916

Epoch: 6| Step: 8
Training loss: 0.21782203097951838
Validation loss: 2.4381317947981564

Epoch: 6| Step: 9
Training loss: 0.26940669070270734
Validation loss: 2.4685744398007223

Epoch: 6| Step: 10
Training loss: 0.260371655706867
Validation loss: 2.4673184052101216

Epoch: 6| Step: 11
Training loss: 0.26134715103660483
Validation loss: 2.442484917960168

Epoch: 6| Step: 12
Training loss: 0.15016479380551437
Validation loss: 2.4273819021278435

Epoch: 6| Step: 13
Training loss: 0.11053263316395873
Validation loss: 2.459504649527852

Epoch: 429| Step: 0
Training loss: 0.1821200903019324
Validation loss: 2.4267654893876296

Epoch: 6| Step: 1
Training loss: 0.2705724480594007
Validation loss: 2.435455601860969

Epoch: 6| Step: 2
Training loss: 0.17860704539380504
Validation loss: 2.4531455806247435

Epoch: 6| Step: 3
Training loss: 0.2551553810744899
Validation loss: 2.4140259130365402

Epoch: 6| Step: 4
Training loss: 0.1676300537462654
Validation loss: 2.4337413927867937

Epoch: 6| Step: 5
Training loss: 0.1861159382043099
Validation loss: 2.4312109229381815

Epoch: 6| Step: 6
Training loss: 0.15936111572037528
Validation loss: 2.440298629374918

Epoch: 6| Step: 7
Training loss: 0.20758052154064954
Validation loss: 2.4511632349397776

Epoch: 6| Step: 8
Training loss: 0.24204697685296195
Validation loss: 2.4351305818781293

Epoch: 6| Step: 9
Training loss: 0.1772996595585433
Validation loss: 2.459372964034596

Epoch: 6| Step: 10
Training loss: 0.20040141405653172
Validation loss: 2.4339171140305735

Epoch: 6| Step: 11
Training loss: 0.218880291011567
Validation loss: 2.415743383771146

Epoch: 6| Step: 12
Training loss: 0.13506835300935652
Validation loss: 2.426590924250077

Epoch: 6| Step: 13
Training loss: 0.4692547147256911
Validation loss: 2.390380881226822

Epoch: 430| Step: 0
Training loss: 0.11648253351133696
Validation loss: 2.3961783562397008

Epoch: 6| Step: 1
Training loss: 0.2149258196741572
Validation loss: 2.3563980568261242

Epoch: 6| Step: 2
Training loss: 0.14593230164722537
Validation loss: 2.3800445957715928

Epoch: 6| Step: 3
Training loss: 0.21565496575106222
Validation loss: 2.363131810298104

Epoch: 6| Step: 4
Training loss: 0.32228499845590247
Validation loss: 2.395282154607984

Epoch: 6| Step: 5
Training loss: 0.12055170351149513
Validation loss: 2.348637334770519

Epoch: 6| Step: 6
Training loss: 0.17358924761168718
Validation loss: 2.3369295781458437

Epoch: 6| Step: 7
Training loss: 0.17546718939803088
Validation loss: 2.386428011583621

Epoch: 6| Step: 8
Training loss: 0.14673917861759544
Validation loss: 2.3847949348959743

Epoch: 6| Step: 9
Training loss: 0.18518494894644008
Validation loss: 2.3751514118852066

Epoch: 6| Step: 10
Training loss: 0.2265917496051697
Validation loss: 2.3966957590964904

Epoch: 6| Step: 11
Training loss: 0.11290743828012786
Validation loss: 2.3806415186202834

Epoch: 6| Step: 12
Training loss: 0.19542144597891636
Validation loss: 2.412842538897231

Epoch: 6| Step: 13
Training loss: 0.14677824424929345
Validation loss: 2.3877380309561604

Epoch: 431| Step: 0
Training loss: 0.13948457614341053
Validation loss: 2.3828397069137974

Epoch: 6| Step: 1
Training loss: 0.10203689042605239
Validation loss: 2.429173618609872

Epoch: 6| Step: 2
Training loss: 0.15753986111567855
Validation loss: 2.391596947012834

Epoch: 6| Step: 3
Training loss: 0.14621770108819573
Validation loss: 2.425025800511252

Epoch: 6| Step: 4
Training loss: 0.17472223649617055
Validation loss: 2.4260722098082543

Epoch: 6| Step: 5
Training loss: 0.3840858534936266
Validation loss: 2.414802422741496

Epoch: 6| Step: 6
Training loss: 0.22267471203473285
Validation loss: 2.4135018808241924

Epoch: 6| Step: 7
Training loss: 0.11245450931289074
Validation loss: 2.3998168936776394

Epoch: 6| Step: 8
Training loss: 0.15328586701683072
Validation loss: 2.387986996481501

Epoch: 6| Step: 9
Training loss: 0.11110534462601467
Validation loss: 2.3970598103504455

Epoch: 6| Step: 10
Training loss: 0.13664858243617356
Validation loss: 2.3611897166142803

Epoch: 6| Step: 11
Training loss: 0.18521566443707488
Validation loss: 2.378321610574839

Epoch: 6| Step: 12
Training loss: 0.23582468714691782
Validation loss: 2.3713273595237863

Epoch: 6| Step: 13
Training loss: 0.10878150715094825
Validation loss: 2.382582959961138

Epoch: 432| Step: 0
Training loss: 0.08861870663105964
Validation loss: 2.397433651637139

Epoch: 6| Step: 1
Training loss: 0.09349104263402883
Validation loss: 2.3682564151923953

Epoch: 6| Step: 2
Training loss: 0.13710703209290817
Validation loss: 2.3593906020955435

Epoch: 6| Step: 3
Training loss: 0.28396216650680156
Validation loss: 2.366726341719981

Epoch: 6| Step: 4
Training loss: 0.12621310301575536
Validation loss: 2.3684404381340842

Epoch: 6| Step: 5
Training loss: 0.13921866274572992
Validation loss: 2.3980414784541364

Epoch: 6| Step: 6
Training loss: 0.1272523581308807
Validation loss: 2.3767082577682936

Epoch: 6| Step: 7
Training loss: 0.3377486244776491
Validation loss: 2.396695120511615

Epoch: 6| Step: 8
Training loss: 0.16492323789480665
Validation loss: 2.378895397448787

Epoch: 6| Step: 9
Training loss: 0.1182496178859763
Validation loss: 2.401175766796678

Epoch: 6| Step: 10
Training loss: 0.13852146211686925
Validation loss: 2.3914995314376513

Epoch: 6| Step: 11
Training loss: 0.15144423093057813
Validation loss: 2.3925540236932763

Epoch: 6| Step: 12
Training loss: 0.21216532318845324
Validation loss: 2.4039454830589184

Epoch: 6| Step: 13
Training loss: 0.30643193621158393
Validation loss: 2.380363143920244

Epoch: 433| Step: 0
Training loss: 0.12349388880754453
Validation loss: 2.398484227749179

Epoch: 6| Step: 1
Training loss: 0.14645018496462614
Validation loss: 2.376532139763921

Epoch: 6| Step: 2
Training loss: 0.11270272579304871
Validation loss: 2.3859461348874507

Epoch: 6| Step: 3
Training loss: 0.23752106899368788
Validation loss: 2.42129767262072

Epoch: 6| Step: 4
Training loss: 0.20735204782102543
Validation loss: 2.4042759012875714

Epoch: 6| Step: 5
Training loss: 0.12422947777302873
Validation loss: 2.386075455252441

Epoch: 6| Step: 6
Training loss: 0.14549798100175115
Validation loss: 2.3833826301198417

Epoch: 6| Step: 7
Training loss: 0.16491084789743085
Validation loss: 2.390738570134729

Epoch: 6| Step: 8
Training loss: 0.3158081547762629
Validation loss: 2.403664832307339

Epoch: 6| Step: 9
Training loss: 0.08052476616045756
Validation loss: 2.4067453397406933

Epoch: 6| Step: 10
Training loss: 0.2678118054304163
Validation loss: 2.389488768953826

Epoch: 6| Step: 11
Training loss: 0.1389442039812304
Validation loss: 2.4037795439547804

Epoch: 6| Step: 12
Training loss: 0.16869563467651916
Validation loss: 2.411962701234721

Epoch: 6| Step: 13
Training loss: 0.2510579938182645
Validation loss: 2.3927413770217814

Epoch: 434| Step: 0
Training loss: 0.13621434762381987
Validation loss: 2.40006839764116

Epoch: 6| Step: 1
Training loss: 0.17467606996732957
Validation loss: 2.417266793112517

Epoch: 6| Step: 2
Training loss: 0.0831727045038622
Validation loss: 2.3971226251770026

Epoch: 6| Step: 3
Training loss: 0.23302269861676686
Validation loss: 2.389727082355901

Epoch: 6| Step: 4
Training loss: 0.30945052949259444
Validation loss: 2.394545058857819

Epoch: 6| Step: 5
Training loss: 0.21049526445482863
Validation loss: 2.4105297097178013

Epoch: 6| Step: 6
Training loss: 0.17303709536402262
Validation loss: 2.398589812627814

Epoch: 6| Step: 7
Training loss: 0.12937326796381235
Validation loss: 2.389672047266897

Epoch: 6| Step: 8
Training loss: 0.12039393047273096
Validation loss: 2.3893678895917376

Epoch: 6| Step: 9
Training loss: 0.09294584216457284
Validation loss: 2.388074987366016

Epoch: 6| Step: 10
Training loss: 0.1562608119084907
Validation loss: 2.3795523404725465

Epoch: 6| Step: 11
Training loss: 0.22017420628503037
Validation loss: 2.364859540241807

Epoch: 6| Step: 12
Training loss: 0.18855792843957594
Validation loss: 2.392584626835855

Epoch: 6| Step: 13
Training loss: 0.11860390447534773
Validation loss: 2.3913055610448977

Epoch: 435| Step: 0
Training loss: 0.08532279880772307
Validation loss: 2.367477026196398

Epoch: 6| Step: 1
Training loss: 0.11950504352289161
Validation loss: 2.3998531722203755

Epoch: 6| Step: 2
Training loss: 0.16905363832648232
Validation loss: 2.37791044337737

Epoch: 6| Step: 3
Training loss: 0.10677812326557373
Validation loss: 2.3706646010709624

Epoch: 6| Step: 4
Training loss: 0.2131116227457183
Validation loss: 2.3922129576928115

Epoch: 6| Step: 5
Training loss: 0.16878945542836907
Validation loss: 2.370280934134561

Epoch: 6| Step: 6
Training loss: 0.1536894806326642
Validation loss: 2.3904027640508145

Epoch: 6| Step: 7
Training loss: 0.24715761293369953
Validation loss: 2.42005885234769

Epoch: 6| Step: 8
Training loss: 0.08714057840332706
Validation loss: 2.374722213561673

Epoch: 6| Step: 9
Training loss: 0.10371235830335948
Validation loss: 2.388282135618341

Epoch: 6| Step: 10
Training loss: 0.13702664446947974
Validation loss: 2.4030540922783383

Epoch: 6| Step: 11
Training loss: 0.30728560242353486
Validation loss: 2.4077904123721763

Epoch: 6| Step: 12
Training loss: 0.23249183531494497
Validation loss: 2.385635378488371

Epoch: 6| Step: 13
Training loss: 0.10977757395668707
Validation loss: 2.3838582477397847

Epoch: 436| Step: 0
Training loss: 0.2994632080912404
Validation loss: 2.376176127310921

Epoch: 6| Step: 1
Training loss: 0.25956239135688475
Validation loss: 2.3762986875142595

Epoch: 6| Step: 2
Training loss: 0.13892777431715012
Validation loss: 2.3787448484194833

Epoch: 6| Step: 3
Training loss: 0.09203329483959939
Validation loss: 2.409974609822997

Epoch: 6| Step: 4
Training loss: 0.14784469311376472
Validation loss: 2.371654069587295

Epoch: 6| Step: 5
Training loss: 0.182818918441518
Validation loss: 2.391382708447712

Epoch: 6| Step: 6
Training loss: 0.14140785384981006
Validation loss: 2.3479843599689123

Epoch: 6| Step: 7
Training loss: 0.20264948609357775
Validation loss: 2.3800513736638043

Epoch: 6| Step: 8
Training loss: 0.1624536879275564
Validation loss: 2.3796492526494544

Epoch: 6| Step: 9
Training loss: 0.11187363288752684
Validation loss: 2.3957892443723

Epoch: 6| Step: 10
Training loss: 0.16211471204130198
Validation loss: 2.3668961014112395

Epoch: 6| Step: 11
Training loss: 0.17908720626617922
Validation loss: 2.381674452979588

Epoch: 6| Step: 12
Training loss: 0.1477992238540557
Validation loss: 2.3906337880769226

Epoch: 6| Step: 13
Training loss: 0.11786438639218808
Validation loss: 2.381606138645388

Epoch: 437| Step: 0
Training loss: 0.09591144155059732
Validation loss: 2.3976767967914783

Epoch: 6| Step: 1
Training loss: 0.12500468632734882
Validation loss: 2.394920346013629

Epoch: 6| Step: 2
Training loss: 0.12722497590633156
Validation loss: 2.37997237461003

Epoch: 6| Step: 3
Training loss: 0.17517199366423183
Validation loss: 2.386376005624635

Epoch: 6| Step: 4
Training loss: 0.1320537463327674
Validation loss: 2.381697879152929

Epoch: 6| Step: 5
Training loss: 0.22563599365534187
Validation loss: 2.358789659439263

Epoch: 6| Step: 6
Training loss: 0.31358797701932667
Validation loss: 2.3758210515428844

Epoch: 6| Step: 7
Training loss: 0.16239225456016992
Validation loss: 2.390257516865872

Epoch: 6| Step: 8
Training loss: 0.16287149961974276
Validation loss: 2.364036163544926

Epoch: 6| Step: 9
Training loss: 0.1589150247054781
Validation loss: 2.377765903718624

Epoch: 6| Step: 10
Training loss: 0.1313794108298236
Validation loss: 2.3640492732283516

Epoch: 6| Step: 11
Training loss: 0.2026375828000686
Validation loss: 2.408247371342594

Epoch: 6| Step: 12
Training loss: 0.107484643110941
Validation loss: 2.3648076188003575

Epoch: 6| Step: 13
Training loss: 0.34306309082444614
Validation loss: 2.3801109843540282

Epoch: 438| Step: 0
Training loss: 0.1459505080178467
Validation loss: 2.407239514713977

Epoch: 6| Step: 1
Training loss: 0.1579997615861452
Validation loss: 2.4152546351151223

Epoch: 6| Step: 2
Training loss: 0.1283103143521661
Validation loss: 2.400105114056927

Epoch: 6| Step: 3
Training loss: 0.1700606930078401
Validation loss: 2.361318425537975

Epoch: 6| Step: 4
Training loss: 0.2207328810086028
Validation loss: 2.3580082693874753

Epoch: 6| Step: 5
Training loss: 0.2082722733345351
Validation loss: 2.3804995124280635

Epoch: 6| Step: 6
Training loss: 0.21202415032753472
Validation loss: 2.4055798858259947

Epoch: 6| Step: 7
Training loss: 0.1980378643596928
Validation loss: 2.3772074043273834

Epoch: 6| Step: 8
Training loss: 0.24971951456087763
Validation loss: 2.3594014275574375

Epoch: 6| Step: 9
Training loss: 0.35593002907646526
Validation loss: 2.347004875545021

Epoch: 6| Step: 10
Training loss: 0.28712325808636496
Validation loss: 2.380612406886188

Epoch: 6| Step: 11
Training loss: 0.2735234670378342
Validation loss: 2.4038162794063176

Epoch: 6| Step: 12
Training loss: 0.16493241967157227
Validation loss: 2.387960094596853

Epoch: 6| Step: 13
Training loss: 0.33258024717285156
Validation loss: 2.415828836120459

Epoch: 439| Step: 0
Training loss: 0.16664859492454695
Validation loss: 2.3881636165458016

Epoch: 6| Step: 1
Training loss: 0.3147572415111945
Validation loss: 2.386559773274035

Epoch: 6| Step: 2
Training loss: 0.2861850157107353
Validation loss: 2.4406158330708783

Epoch: 6| Step: 3
Training loss: 0.3049319216113785
Validation loss: 2.4443091990264407

Epoch: 6| Step: 4
Training loss: 0.255840126070641
Validation loss: 2.4475964424243983

Epoch: 6| Step: 5
Training loss: 0.26040624915585003
Validation loss: 2.4306924666730083

Epoch: 6| Step: 6
Training loss: 0.17655626155162243
Validation loss: 2.4080107912941213

Epoch: 6| Step: 7
Training loss: 0.23589964714567646
Validation loss: 2.3801821522365474

Epoch: 6| Step: 8
Training loss: 0.233868823232899
Validation loss: 2.380664014859737

Epoch: 6| Step: 9
Training loss: 0.17076344199141733
Validation loss: 2.3515901120701885

Epoch: 6| Step: 10
Training loss: 0.22294851830164006
Validation loss: 2.381605931970147

Epoch: 6| Step: 11
Training loss: 0.3561156956671318
Validation loss: 2.3778745449909566

Epoch: 6| Step: 12
Training loss: 0.22226978526051713
Validation loss: 2.37622346814033

Epoch: 6| Step: 13
Training loss: 0.22469361425577497
Validation loss: 2.3781234838442535

Epoch: 440| Step: 0
Training loss: 0.20330694193122
Validation loss: 2.3934430161814815

Epoch: 6| Step: 1
Training loss: 0.2459789265589752
Validation loss: 2.402722481734597

Epoch: 6| Step: 2
Training loss: 0.22127603760220554
Validation loss: 2.425142084282438

Epoch: 6| Step: 3
Training loss: 0.32758919929837743
Validation loss: 2.422550746763323

Epoch: 6| Step: 4
Training loss: 0.1417951510195848
Validation loss: 2.4365168130189323

Epoch: 6| Step: 5
Training loss: 0.2779741644372192
Validation loss: 2.4470082203391526

Epoch: 6| Step: 6
Training loss: 0.2761064114606132
Validation loss: 2.43234082834325

Epoch: 6| Step: 7
Training loss: 0.19649786779591233
Validation loss: 2.4081859538276658

Epoch: 6| Step: 8
Training loss: 0.13237501063450383
Validation loss: 2.4106066906742267

Epoch: 6| Step: 9
Training loss: 0.12706225912922228
Validation loss: 2.4081461434893137

Epoch: 6| Step: 10
Training loss: 0.22607788511397056
Validation loss: 2.409943579670867

Epoch: 6| Step: 11
Training loss: 0.4466468829012998
Validation loss: 2.3970476180899754

Epoch: 6| Step: 12
Training loss: 0.26085960230513244
Validation loss: 2.4550401182459516

Epoch: 6| Step: 13
Training loss: 0.13413981243591724
Validation loss: 2.484976874816444

Epoch: 441| Step: 0
Training loss: 0.20165125201428008
Validation loss: 2.4924435909093643

Epoch: 6| Step: 1
Training loss: 0.2019385109341582
Validation loss: 2.516303744677856

Epoch: 6| Step: 2
Training loss: 0.34125645011353417
Validation loss: 2.5637453701109294

Epoch: 6| Step: 3
Training loss: 0.8724336113033154
Validation loss: 2.5850370007975747

Epoch: 6| Step: 4
Training loss: 0.19897093974280977
Validation loss: 2.4193770457516726

Epoch: 6| Step: 5
Training loss: 0.7342515395255179
Validation loss: 2.5078467209987294

Epoch: 6| Step: 6
Training loss: 1.167980895728811
Validation loss: 2.5084390129525143

Epoch: 6| Step: 7
Training loss: 0.6127110156696972
Validation loss: 2.5202946593731745

Epoch: 6| Step: 8
Training loss: 0.8303661609634592
Validation loss: 2.476332428946666

Epoch: 6| Step: 9
Training loss: 0.47557296578578284
Validation loss: 2.4470311538425964

Epoch: 6| Step: 10
Training loss: 0.4675791422514976
Validation loss: 2.4352860210111547

Epoch: 6| Step: 11
Training loss: 0.5371056573912536
Validation loss: 2.4669695148062996

Epoch: 6| Step: 12
Training loss: 0.5708448198884513
Validation loss: 2.5098787763837755

Epoch: 6| Step: 13
Training loss: 0.34711547111259794
Validation loss: 2.5785189061994256

Epoch: 442| Step: 0
Training loss: 1.0632484268402869
Validation loss: 2.604942721660532

Epoch: 6| Step: 1
Training loss: 0.735515763591659
Validation loss: 2.526459836879626

Epoch: 6| Step: 2
Training loss: 0.5201781984501588
Validation loss: 2.4280457056659763

Epoch: 6| Step: 3
Training loss: 0.8623120144525211
Validation loss: 2.3374538698503686

Epoch: 6| Step: 4
Training loss: 0.5110150222996381
Validation loss: 2.314365590052666

Epoch: 6| Step: 5
Training loss: 0.5063185798441028
Validation loss: 2.316066117468634

Epoch: 6| Step: 6
Training loss: 0.48288405051798866
Validation loss: 2.324511819398165

Epoch: 6| Step: 7
Training loss: 0.4874940248269918
Validation loss: 2.405659294523485

Epoch: 6| Step: 8
Training loss: 0.4828830630394309
Validation loss: 2.433859587466849

Epoch: 6| Step: 9
Training loss: 0.7359756718999624
Validation loss: 2.5235332985271945

Epoch: 6| Step: 10
Training loss: 0.6516186916354036
Validation loss: 2.5663686153234453

Epoch: 6| Step: 11
Training loss: 0.9291790445355764
Validation loss: 2.5904540830993583

Epoch: 6| Step: 12
Training loss: 1.1288607367082397
Validation loss: 2.5795265174405944

Epoch: 6| Step: 13
Training loss: 0.7284558146370163
Validation loss: 2.5571061009724314

Epoch: 443| Step: 0
Training loss: 0.8672814189468268
Validation loss: 2.546113686135731

Epoch: 6| Step: 1
Training loss: 0.7730056250516821
Validation loss: 2.5477879408746342

Epoch: 6| Step: 2
Training loss: 1.1066719759005612
Validation loss: 2.516632029341138

Epoch: 6| Step: 3
Training loss: 1.2196291173732703
Validation loss: 2.432743600124204

Epoch: 6| Step: 4
Training loss: 0.5017344670193614
Validation loss: 2.401261177053844

Epoch: 6| Step: 5
Training loss: 0.8052493605991633
Validation loss: 2.4836665819228725

Epoch: 6| Step: 6
Training loss: 0.7453728033657483
Validation loss: 2.5264306529554363

Epoch: 6| Step: 7
Training loss: 0.8569404101847841
Validation loss: 2.5934160306393124

Epoch: 6| Step: 8
Training loss: 0.5722259924382731
Validation loss: 2.5615185334452666

Epoch: 6| Step: 9
Training loss: 0.46069819493831304
Validation loss: 2.5675408100004495

Epoch: 6| Step: 10
Training loss: 0.5006048597077832
Validation loss: 2.553750305681715

Epoch: 6| Step: 11
Training loss: 0.5729128461768183
Validation loss: 2.5477366989999424

Epoch: 6| Step: 12
Training loss: 0.8774175964419622
Validation loss: 2.5274569715282618

Epoch: 6| Step: 13
Training loss: 0.9883851912650772
Validation loss: 2.5074604415868973

Epoch: 444| Step: 0
Training loss: 0.610236170732764
Validation loss: 2.475683588717332

Epoch: 6| Step: 1
Training loss: 0.33147545465590234
Validation loss: 2.472167531394793

Epoch: 6| Step: 2
Training loss: 0.4755051561872263
Validation loss: 2.4819269396657995

Epoch: 6| Step: 3
Training loss: 0.5747315070191668
Validation loss: 2.494618108045822

Epoch: 6| Step: 4
Training loss: 0.6374253173166642
Validation loss: 2.5128241046555564

Epoch: 6| Step: 5
Training loss: 0.6338509880577596
Validation loss: 2.497849324835262

Epoch: 6| Step: 6
Training loss: 0.5934556432183301
Validation loss: 2.489742332842606

Epoch: 6| Step: 7
Training loss: 0.3651732327287183
Validation loss: 2.4550933298341437

Epoch: 6| Step: 8
Training loss: 0.4348733595411166
Validation loss: 2.48579040646157

Epoch: 6| Step: 9
Training loss: 0.8863021611411686
Validation loss: 2.490017007778816

Epoch: 6| Step: 10
Training loss: 0.32014227042109766
Validation loss: 2.4294969504900896

Epoch: 6| Step: 11
Training loss: 0.5960222733867229
Validation loss: 2.398232096926429

Epoch: 6| Step: 12
Training loss: 0.7557026308756696
Validation loss: 2.351473862933006

Epoch: 6| Step: 13
Training loss: 0.4625683076780252
Validation loss: 2.3521160967249344

Epoch: 445| Step: 0
Training loss: 0.5648882287796356
Validation loss: 2.3730608445257744

Epoch: 6| Step: 1
Training loss: 0.6309639103025454
Validation loss: 2.3716930656366797

Epoch: 6| Step: 2
Training loss: 0.46318291236397835
Validation loss: 2.4081625048132254

Epoch: 6| Step: 3
Training loss: 0.6332807809793621
Validation loss: 2.4240159790585634

Epoch: 6| Step: 4
Training loss: 0.49953707484290755
Validation loss: 2.4633221972850707

Epoch: 6| Step: 5
Training loss: 0.4616617558088438
Validation loss: 2.4756098611048705

Epoch: 6| Step: 6
Training loss: 0.5580381284389047
Validation loss: 2.4819822092369503

Epoch: 6| Step: 7
Training loss: 0.39804982042954257
Validation loss: 2.4712601519134885

Epoch: 6| Step: 8
Training loss: 0.3895215662101797
Validation loss: 2.4663171480096233

Epoch: 6| Step: 9
Training loss: 0.59577608756073
Validation loss: 2.4585080245491717

Epoch: 6| Step: 10
Training loss: 0.40907909094472533
Validation loss: 2.465335122280707

Epoch: 6| Step: 11
Training loss: 0.39634843196387887
Validation loss: 2.464298168473528

Epoch: 6| Step: 12
Training loss: 0.3457668051824719
Validation loss: 2.4807274809202156

Epoch: 6| Step: 13
Training loss: 0.24589323018614936
Validation loss: 2.4649541954371386

Epoch: 446| Step: 0
Training loss: 0.2753907196910506
Validation loss: 2.471236640577497

Epoch: 6| Step: 1
Training loss: 0.4039661695059011
Validation loss: 2.468000655224843

Epoch: 6| Step: 2
Training loss: 0.3821647184667216
Validation loss: 2.472640415997541

Epoch: 6| Step: 3
Training loss: 0.3078848022901536
Validation loss: 2.469894494881467

Epoch: 6| Step: 4
Training loss: 0.3759592027495944
Validation loss: 2.5073435927729295

Epoch: 6| Step: 5
Training loss: 0.3511428553691565
Validation loss: 2.4758775506013952

Epoch: 6| Step: 6
Training loss: 0.19082276294895792
Validation loss: 2.468674022647196

Epoch: 6| Step: 7
Training loss: 0.24153004129664823
Validation loss: 2.4844628817234775

Epoch: 6| Step: 8
Training loss: 0.4430495704780101
Validation loss: 2.477875308494038

Epoch: 6| Step: 9
Training loss: 0.38816658798491055
Validation loss: 2.4432968646167272

Epoch: 6| Step: 10
Training loss: 0.3772305470817394
Validation loss: 2.477656662475992

Epoch: 6| Step: 11
Training loss: 0.28800890911084437
Validation loss: 2.467221017257459

Epoch: 6| Step: 12
Training loss: 0.26697994112003404
Validation loss: 2.4388927417484596

Epoch: 6| Step: 13
Training loss: 0.2603303321143569
Validation loss: 2.4670146872965386

Epoch: 447| Step: 0
Training loss: 0.29539864257569703
Validation loss: 2.4498578594362646

Epoch: 6| Step: 1
Training loss: 0.24198054115527962
Validation loss: 2.4489222869486236

Epoch: 6| Step: 2
Training loss: 0.18652483555135008
Validation loss: 2.4690788998046913

Epoch: 6| Step: 3
Training loss: 0.3202020524504523
Validation loss: 2.470637898571296

Epoch: 6| Step: 4
Training loss: 0.36381049213599165
Validation loss: 2.4648240486801947

Epoch: 6| Step: 5
Training loss: 0.30003666057700484
Validation loss: 2.460404292488794

Epoch: 6| Step: 6
Training loss: 0.4039714258907561
Validation loss: 2.468442339020476

Epoch: 6| Step: 7
Training loss: 0.24369917058380922
Validation loss: 2.4756155691007526

Epoch: 6| Step: 8
Training loss: 0.30250598537025
Validation loss: 2.491883961893978

Epoch: 6| Step: 9
Training loss: 0.25539425805029214
Validation loss: 2.4794367725979796

Epoch: 6| Step: 10
Training loss: 0.31090687931666944
Validation loss: 2.4885458050664258

Epoch: 6| Step: 11
Training loss: 0.4022493159013885
Validation loss: 2.492957769023896

Epoch: 6| Step: 12
Training loss: 0.23568636083871336
Validation loss: 2.5014687781681406

Epoch: 6| Step: 13
Training loss: 0.2799886126842331
Validation loss: 2.4814672817839956

Epoch: 448| Step: 0
Training loss: 0.31558158925344026
Validation loss: 2.4788042525541676

Epoch: 6| Step: 1
Training loss: 0.35149817408064393
Validation loss: 2.478239257389867

Epoch: 6| Step: 2
Training loss: 0.2207548874101237
Validation loss: 2.485166630326725

Epoch: 6| Step: 3
Training loss: 0.31342878601496826
Validation loss: 2.488328573663893

Epoch: 6| Step: 4
Training loss: 0.1725904680313352
Validation loss: 2.473370981402825

Epoch: 6| Step: 5
Training loss: 0.19649503349077452
Validation loss: 2.500776307261372

Epoch: 6| Step: 6
Training loss: 0.28859198139600867
Validation loss: 2.4919554416255396

Epoch: 6| Step: 7
Training loss: 0.23908912784654276
Validation loss: 2.488550691702384

Epoch: 6| Step: 8
Training loss: 0.34454623036244053
Validation loss: 2.5180270039871853

Epoch: 6| Step: 9
Training loss: 0.20963580662629877
Validation loss: 2.476015215182853

Epoch: 6| Step: 10
Training loss: 0.3267928853111757
Validation loss: 2.5057159207055806

Epoch: 6| Step: 11
Training loss: 0.20927920000229433
Validation loss: 2.476657330308488

Epoch: 6| Step: 12
Training loss: 0.2845646194590214
Validation loss: 2.4883509746394012

Epoch: 6| Step: 13
Training loss: 0.2724766880528067
Validation loss: 2.4911753477473546

Epoch: 449| Step: 0
Training loss: 0.2897063765193413
Validation loss: 2.481466036363762

Epoch: 6| Step: 1
Training loss: 0.2616496777840673
Validation loss: 2.489442832079273

Epoch: 6| Step: 2
Training loss: 0.218023575618051
Validation loss: 2.50126303382518

Epoch: 6| Step: 3
Training loss: 0.20036762544289075
Validation loss: 2.482756141100325

Epoch: 6| Step: 4
Training loss: 0.2218059146808593
Validation loss: 2.5013997292046906

Epoch: 6| Step: 5
Training loss: 0.26808324875581746
Validation loss: 2.487944216595037

Epoch: 6| Step: 6
Training loss: 0.30427910259484575
Validation loss: 2.5020381730550403

Epoch: 6| Step: 7
Training loss: 0.3063509477919468
Validation loss: 2.4740565061061464

Epoch: 6| Step: 8
Training loss: 0.27995557404920396
Validation loss: 2.444067400469822

Epoch: 6| Step: 9
Training loss: 0.23205797574548867
Validation loss: 2.458181465871017

Epoch: 6| Step: 10
Training loss: 0.2026292914442664
Validation loss: 2.429051364788046

Epoch: 6| Step: 11
Training loss: 0.30154861062434574
Validation loss: 2.465252007821505

Epoch: 6| Step: 12
Training loss: 0.22817065618176818
Validation loss: 2.4562521527370227

Epoch: 6| Step: 13
Training loss: 0.26056646647994824
Validation loss: 2.450508102124647

Epoch: 450| Step: 0
Training loss: 0.22572969422207598
Validation loss: 2.437828935757736

Epoch: 6| Step: 1
Training loss: 0.23308242568894158
Validation loss: 2.4266570166319665

Epoch: 6| Step: 2
Training loss: 0.2727986229101435
Validation loss: 2.462879297821576

Epoch: 6| Step: 3
Training loss: 0.15368220873919983
Validation loss: 2.4419345509548505

Epoch: 6| Step: 4
Training loss: 0.18660469681804792
Validation loss: 2.449316733378087

Epoch: 6| Step: 5
Training loss: 0.17734334710365274
Validation loss: 2.454869614734675

Epoch: 6| Step: 6
Training loss: 0.1263625124931801
Validation loss: 2.497841710413257

Epoch: 6| Step: 7
Training loss: 0.2135521296907417
Validation loss: 2.476359615683141

Epoch: 6| Step: 8
Training loss: 0.20801861157390486
Validation loss: 2.450584953129797

Epoch: 6| Step: 9
Training loss: 0.2880111467941161
Validation loss: 2.462410685138252

Epoch: 6| Step: 10
Training loss: 0.1604938031857902
Validation loss: 2.454614230484026

Epoch: 6| Step: 11
Training loss: 0.16618362789621316
Validation loss: 2.4750331728110386

Epoch: 6| Step: 12
Training loss: 0.2330031299360374
Validation loss: 2.4264905810366475

Epoch: 6| Step: 13
Training loss: 0.4389975835792321
Validation loss: 2.442897486961597

Epoch: 451| Step: 0
Training loss: 0.33982285621694835
Validation loss: 2.48750919277063

Epoch: 6| Step: 1
Training loss: 0.14617563135814202
Validation loss: 2.461261719185737

Epoch: 6| Step: 2
Training loss: 0.15178143821831874
Validation loss: 2.444360132871031

Epoch: 6| Step: 3
Training loss: 0.13564441095927696
Validation loss: 2.4317479034453147

Epoch: 6| Step: 4
Training loss: 0.20150042065808424
Validation loss: 2.447108361279132

Epoch: 6| Step: 5
Training loss: 0.22870195568244744
Validation loss: 2.4575399916189418

Epoch: 6| Step: 6
Training loss: 0.24324502324867603
Validation loss: 2.4661016240127984

Epoch: 6| Step: 7
Training loss: 0.22794718017398713
Validation loss: 2.4410401344688517

Epoch: 6| Step: 8
Training loss: 0.19710858392122016
Validation loss: 2.4509389592371775

Epoch: 6| Step: 9
Training loss: 0.19808956904948083
Validation loss: 2.4642984124268397

Epoch: 6| Step: 10
Training loss: 0.17717003569744552
Validation loss: 2.460349040424339

Epoch: 6| Step: 11
Training loss: 0.14374533469466388
Validation loss: 2.4672340109217905

Epoch: 6| Step: 12
Training loss: 0.17581433938437616
Validation loss: 2.490358913974185

Epoch: 6| Step: 13
Training loss: 0.24498135576054894
Validation loss: 2.4970877286888276

Epoch: 452| Step: 0
Training loss: 0.1718559471320539
Validation loss: 2.4734629677298776

Epoch: 6| Step: 1
Training loss: 0.17913257908542826
Validation loss: 2.5299601629174444

Epoch: 6| Step: 2
Training loss: 0.2552425141054115
Validation loss: 2.5251507924337084

Epoch: 6| Step: 3
Training loss: 0.17143653080548424
Validation loss: 2.505518940425827

Epoch: 6| Step: 4
Training loss: 0.22091426708326498
Validation loss: 2.4788312529118977

Epoch: 6| Step: 5
Training loss: 0.19548954568713728
Validation loss: 2.5195608379117664

Epoch: 6| Step: 6
Training loss: 0.24284291029095115
Validation loss: 2.4939632204441406

Epoch: 6| Step: 7
Training loss: 0.20403248471251495
Validation loss: 2.516109090045806

Epoch: 6| Step: 8
Training loss: 0.3423578617734007
Validation loss: 2.4705219734653316

Epoch: 6| Step: 9
Training loss: 0.28049599719718904
Validation loss: 2.474198474120533

Epoch: 6| Step: 10
Training loss: 0.20024948317631333
Validation loss: 2.4528975257515584

Epoch: 6| Step: 11
Training loss: 0.15402959658918866
Validation loss: 2.468959165523193

Epoch: 6| Step: 12
Training loss: 0.22865339348502292
Validation loss: 2.425683002894246

Epoch: 6| Step: 13
Training loss: 0.10579491443927326
Validation loss: 2.4154251744229254

Epoch: 453| Step: 0
Training loss: 0.19175747352083683
Validation loss: 2.4485898033395688

Epoch: 6| Step: 1
Training loss: 0.15862659010980704
Validation loss: 2.4340411951946677

Epoch: 6| Step: 2
Training loss: 0.1136046922233052
Validation loss: 2.420125313791284

Epoch: 6| Step: 3
Training loss: 0.13528213481829607
Validation loss: 2.4105334660588382

Epoch: 6| Step: 4
Training loss: 0.23433127790175207
Validation loss: 2.4072556138290255

Epoch: 6| Step: 5
Training loss: 0.17186996062433718
Validation loss: 2.408677519374526

Epoch: 6| Step: 6
Training loss: 0.2603818997381398
Validation loss: 2.432400377531902

Epoch: 6| Step: 7
Training loss: 0.19811312227716435
Validation loss: 2.4252732627329014

Epoch: 6| Step: 8
Training loss: 0.18061743469630573
Validation loss: 2.43337627798066

Epoch: 6| Step: 9
Training loss: 0.2146370760659049
Validation loss: 2.422084881556495

Epoch: 6| Step: 10
Training loss: 0.22135158238117855
Validation loss: 2.429534678339704

Epoch: 6| Step: 11
Training loss: 0.2925191863198624
Validation loss: 2.415875290095921

Epoch: 6| Step: 12
Training loss: 0.16069441603455456
Validation loss: 2.4343897978653444

Epoch: 6| Step: 13
Training loss: 0.2387776441697487
Validation loss: 2.461912933708736

Epoch: 454| Step: 0
Training loss: 0.1296592308165177
Validation loss: 2.4478406995576885

Epoch: 6| Step: 1
Training loss: 0.20421620849685726
Validation loss: 2.4537575071373783

Epoch: 6| Step: 2
Training loss: 0.24095878858312744
Validation loss: 2.467123375032237

Epoch: 6| Step: 3
Training loss: 0.12110269421185911
Validation loss: 2.4733239291917015

Epoch: 6| Step: 4
Training loss: 0.18773195700927764
Validation loss: 2.469712803425698

Epoch: 6| Step: 5
Training loss: 0.1924158639158661
Validation loss: 2.446354361241798

Epoch: 6| Step: 6
Training loss: 0.23020557960025503
Validation loss: 2.4742132050205785

Epoch: 6| Step: 7
Training loss: 0.15080407518362232
Validation loss: 2.4595874516416956

Epoch: 6| Step: 8
Training loss: 0.19093643645506994
Validation loss: 2.4469354391370386

Epoch: 6| Step: 9
Training loss: 0.24833972794398443
Validation loss: 2.466984746630765

Epoch: 6| Step: 10
Training loss: 0.14570789533890535
Validation loss: 2.466571021228094

Epoch: 6| Step: 11
Training loss: 0.28325965580218304
Validation loss: 2.439533795562536

Epoch: 6| Step: 12
Training loss: 0.17036691024001316
Validation loss: 2.4697387426682402

Epoch: 6| Step: 13
Training loss: 0.218167892873226
Validation loss: 2.4538166567333835

Epoch: 455| Step: 0
Training loss: 0.2864476187465023
Validation loss: 2.453728203451147

Epoch: 6| Step: 1
Training loss: 0.30443680059469724
Validation loss: 2.4765931260806515

Epoch: 6| Step: 2
Training loss: 0.1628284820649365
Validation loss: 2.4329874165639405

Epoch: 6| Step: 3
Training loss: 0.25316941377916874
Validation loss: 2.479862676591872

Epoch: 6| Step: 4
Training loss: 0.18815817153955583
Validation loss: 2.4874977447784814

Epoch: 6| Step: 5
Training loss: 0.19816334100731411
Validation loss: 2.453353270311032

Epoch: 6| Step: 6
Training loss: 0.167737796492698
Validation loss: 2.463193491122459

Epoch: 6| Step: 7
Training loss: 0.11963866447042047
Validation loss: 2.47576947498757

Epoch: 6| Step: 8
Training loss: 0.12393735541485786
Validation loss: 2.481753667416039

Epoch: 6| Step: 9
Training loss: 0.16403490924441888
Validation loss: 2.457587397139013

Epoch: 6| Step: 10
Training loss: 0.16340206823434975
Validation loss: 2.470830199319145

Epoch: 6| Step: 11
Training loss: 0.14983932587036292
Validation loss: 2.4509722191808856

Epoch: 6| Step: 12
Training loss: 0.16500796640194873
Validation loss: 2.4426408651639107

Epoch: 6| Step: 13
Training loss: 0.1473571462599196
Validation loss: 2.4566592148676305

Epoch: 456| Step: 0
Training loss: 0.1557978585150682
Validation loss: 2.4456674978017796

Epoch: 6| Step: 1
Training loss: 0.15394590999600571
Validation loss: 2.450693221439312

Epoch: 6| Step: 2
Training loss: 0.14181307419021388
Validation loss: 2.4576980575754503

Epoch: 6| Step: 3
Training loss: 0.16408355895626364
Validation loss: 2.444133188089518

Epoch: 6| Step: 4
Training loss: 0.16890722187161394
Validation loss: 2.4576445372882323

Epoch: 6| Step: 5
Training loss: 0.17677806506390661
Validation loss: 2.475651179573243

Epoch: 6| Step: 6
Training loss: 0.2357602666387144
Validation loss: 2.469817878044055

Epoch: 6| Step: 7
Training loss: 0.199331681648825
Validation loss: 2.485846107328011

Epoch: 6| Step: 8
Training loss: 0.15645128636378422
Validation loss: 2.4479931200001697

Epoch: 6| Step: 9
Training loss: 0.30731544833643554
Validation loss: 2.4488509298526937

Epoch: 6| Step: 10
Training loss: 0.13831218222656153
Validation loss: 2.449841250472186

Epoch: 6| Step: 11
Training loss: 0.23842904713347599
Validation loss: 2.438378841107058

Epoch: 6| Step: 12
Training loss: 0.1382640496564165
Validation loss: 2.44387072877158

Epoch: 6| Step: 13
Training loss: 0.19837869914379164
Validation loss: 2.460175596845284

Epoch: 457| Step: 0
Training loss: 0.11730910190961133
Validation loss: 2.439875965297717

Epoch: 6| Step: 1
Training loss: 0.2834331761948298
Validation loss: 2.4583470104484317

Epoch: 6| Step: 2
Training loss: 0.20555997281189772
Validation loss: 2.4941730703854517

Epoch: 6| Step: 3
Training loss: 0.15419066672983373
Validation loss: 2.486892571037187

Epoch: 6| Step: 4
Training loss: 0.26876013093527595
Validation loss: 2.4794948726349477

Epoch: 6| Step: 5
Training loss: 0.14250510449218237
Validation loss: 2.4606912815610653

Epoch: 6| Step: 6
Training loss: 0.16115488999292021
Validation loss: 2.463974177161298

Epoch: 6| Step: 7
Training loss: 0.20778380676316674
Validation loss: 2.473364233800695

Epoch: 6| Step: 8
Training loss: 0.14623281495087237
Validation loss: 2.4850016055445776

Epoch: 6| Step: 9
Training loss: 0.15907767016461302
Validation loss: 2.419155410610649

Epoch: 6| Step: 10
Training loss: 0.18866293591791627
Validation loss: 2.4299235589818577

Epoch: 6| Step: 11
Training loss: 0.13828955587668992
Validation loss: 2.452137384796393

Epoch: 6| Step: 12
Training loss: 0.14339726438486722
Validation loss: 2.4566151955516906

Epoch: 6| Step: 13
Training loss: 0.20241219824654974
Validation loss: 2.451360722939429

Epoch: 458| Step: 0
Training loss: 0.13584456253905686
Validation loss: 2.441880825850292

Epoch: 6| Step: 1
Training loss: 0.1882718214468019
Validation loss: 2.442312112479771

Epoch: 6| Step: 2
Training loss: 0.12242455010330484
Validation loss: 2.4066144366015663

Epoch: 6| Step: 3
Training loss: 0.19744980589206743
Validation loss: 2.4310494633531

Epoch: 6| Step: 4
Training loss: 0.176102847386418
Validation loss: 2.429758003941557

Epoch: 6| Step: 5
Training loss: 0.13016562397185516
Validation loss: 2.397445296580347

Epoch: 6| Step: 6
Training loss: 0.16513904951132508
Validation loss: 2.422832670951273

Epoch: 6| Step: 7
Training loss: 0.14672307593089431
Validation loss: 2.4165553412787824

Epoch: 6| Step: 8
Training loss: 0.20148571311266725
Validation loss: 2.4174959519424055

Epoch: 6| Step: 9
Training loss: 0.3051362523227534
Validation loss: 2.4258356571593955

Epoch: 6| Step: 10
Training loss: 0.2164343819081055
Validation loss: 2.4355208126472654

Epoch: 6| Step: 11
Training loss: 0.2093015385329249
Validation loss: 2.441068995523133

Epoch: 6| Step: 12
Training loss: 0.18718390841851576
Validation loss: 2.4472804326417203

Epoch: 6| Step: 13
Training loss: 0.21475954139449577
Validation loss: 2.427161822334371

Epoch: 459| Step: 0
Training loss: 0.14412724244142447
Validation loss: 2.4497144494183356

Epoch: 6| Step: 1
Training loss: 0.15121018666007316
Validation loss: 2.438516207786724

Epoch: 6| Step: 2
Training loss: 0.1222314724434322
Validation loss: 2.4209142985882046

Epoch: 6| Step: 3
Training loss: 0.18633060573629898
Validation loss: 2.4153374894662436

Epoch: 6| Step: 4
Training loss: 0.1313238583245533
Validation loss: 2.442279268892424

Epoch: 6| Step: 5
Training loss: 0.12067277474285903
Validation loss: 2.440562560559134

Epoch: 6| Step: 6
Training loss: 0.11573873078292009
Validation loss: 2.457998579025208

Epoch: 6| Step: 7
Training loss: 0.19935187398488005
Validation loss: 2.436589239420035

Epoch: 6| Step: 8
Training loss: 0.25346472571593626
Validation loss: 2.476273911385074

Epoch: 6| Step: 9
Training loss: 0.12371145642782731
Validation loss: 2.465190618040052

Epoch: 6| Step: 10
Training loss: 0.23834322295450105
Validation loss: 2.4487253982183423

Epoch: 6| Step: 11
Training loss: 0.2289639501140141
Validation loss: 2.448995957516697

Epoch: 6| Step: 12
Training loss: 0.2728010809475984
Validation loss: 2.4719089439609387

Epoch: 6| Step: 13
Training loss: 0.15315556026599983
Validation loss: 2.480638187439236

Epoch: 460| Step: 0
Training loss: 0.16605059311547468
Validation loss: 2.442763204465774

Epoch: 6| Step: 1
Training loss: 0.15008134126567899
Validation loss: 2.462883638420825

Epoch: 6| Step: 2
Training loss: 0.18291594806224407
Validation loss: 2.4364648024306503

Epoch: 6| Step: 3
Training loss: 0.1767121039877029
Validation loss: 2.439585562076978

Epoch: 6| Step: 4
Training loss: 0.13218557829846564
Validation loss: 2.420111059797996

Epoch: 6| Step: 5
Training loss: 0.13695127604531776
Validation loss: 2.421337719353017

Epoch: 6| Step: 6
Training loss: 0.1740848649054449
Validation loss: 2.426982821751509

Epoch: 6| Step: 7
Training loss: 0.17847193176981457
Validation loss: 2.407379386623704

Epoch: 6| Step: 8
Training loss: 0.16989944573059965
Validation loss: 2.4100953736272848

Epoch: 6| Step: 9
Training loss: 0.11303289088375695
Validation loss: 2.4098156688892387

Epoch: 6| Step: 10
Training loss: 0.18151491183311352
Validation loss: 2.3759979457081912

Epoch: 6| Step: 11
Training loss: 0.24172939536011984
Validation loss: 2.4021533606828336

Epoch: 6| Step: 12
Training loss: 0.1277337794625401
Validation loss: 2.4386808670774167

Epoch: 6| Step: 13
Training loss: 0.12307694990975633
Validation loss: 2.4377999963828856

Epoch: 461| Step: 0
Training loss: 0.09346334023541186
Validation loss: 2.4245188572043683

Epoch: 6| Step: 1
Training loss: 0.11191912268471484
Validation loss: 2.4339780397253206

Epoch: 6| Step: 2
Training loss: 0.1988572412242836
Validation loss: 2.449968459859901

Epoch: 6| Step: 3
Training loss: 0.23134485309878378
Validation loss: 2.4664831713787576

Epoch: 6| Step: 4
Training loss: 0.1986456837792743
Validation loss: 2.454765864693092

Epoch: 6| Step: 5
Training loss: 0.15078453396398267
Validation loss: 2.430832143380246

Epoch: 6| Step: 6
Training loss: 0.12585229436988496
Validation loss: 2.4468919573363803

Epoch: 6| Step: 7
Training loss: 0.19064227244810636
Validation loss: 2.4363154932244786

Epoch: 6| Step: 8
Training loss: 0.2027069705382823
Validation loss: 2.4015410945801268

Epoch: 6| Step: 9
Training loss: 0.09066147399126134
Validation loss: 2.398744047872167

Epoch: 6| Step: 10
Training loss: 0.15495848953548286
Validation loss: 2.4220789521472788

Epoch: 6| Step: 11
Training loss: 0.20431858370449985
Validation loss: 2.413143547085779

Epoch: 6| Step: 12
Training loss: 0.17722323561890702
Validation loss: 2.4083980863989214

Epoch: 6| Step: 13
Training loss: 0.13738946562865378
Validation loss: 2.4144796755764806

Epoch: 462| Step: 0
Training loss: 0.1727732896038736
Validation loss: 2.3936267077027127

Epoch: 6| Step: 1
Training loss: 0.17299114668971943
Validation loss: 2.427175082207005

Epoch: 6| Step: 2
Training loss: 0.11075612406019847
Validation loss: 2.4344222613693405

Epoch: 6| Step: 3
Training loss: 0.1803574202166479
Validation loss: 2.431212892688614

Epoch: 6| Step: 4
Training loss: 0.13681605827074908
Validation loss: 2.441211546125563

Epoch: 6| Step: 5
Training loss: 0.22370732827569775
Validation loss: 2.424255446068571

Epoch: 6| Step: 6
Training loss: 0.15826839701744186
Validation loss: 2.4380022356631335

Epoch: 6| Step: 7
Training loss: 0.130645634331012
Validation loss: 2.4572529856984877

Epoch: 6| Step: 8
Training loss: 0.11280462691924117
Validation loss: 2.4345271500589862

Epoch: 6| Step: 9
Training loss: 0.16915413183679287
Validation loss: 2.4463331093835587

Epoch: 6| Step: 10
Training loss: 0.1335616232071633
Validation loss: 2.454377819507038

Epoch: 6| Step: 11
Training loss: 0.2279206706456085
Validation loss: 2.4116115035494334

Epoch: 6| Step: 12
Training loss: 0.1404252620631077
Validation loss: 2.43961423805269

Epoch: 6| Step: 13
Training loss: 0.07461149364978431
Validation loss: 2.435054404110904

Epoch: 463| Step: 0
Training loss: 0.1056289074953736
Validation loss: 2.4106685170945754

Epoch: 6| Step: 1
Training loss: 0.14479101524503799
Validation loss: 2.405625998477569

Epoch: 6| Step: 2
Training loss: 0.18979732471669358
Validation loss: 2.4188518369077885

Epoch: 6| Step: 3
Training loss: 0.19786355075498135
Validation loss: 2.403249362580421

Epoch: 6| Step: 4
Training loss: 0.25256527604595475
Validation loss: 2.38947914303283

Epoch: 6| Step: 5
Training loss: 0.13261138892102495
Validation loss: 2.3997898733622005

Epoch: 6| Step: 6
Training loss: 0.12653030998689158
Validation loss: 2.3965029046136532

Epoch: 6| Step: 7
Training loss: 0.175776958413188
Validation loss: 2.386478850863914

Epoch: 6| Step: 8
Training loss: 0.09207749086702485
Validation loss: 2.416691987524171

Epoch: 6| Step: 9
Training loss: 0.11278003767127753
Validation loss: 2.421817693386278

Epoch: 6| Step: 10
Training loss: 0.09628551256085328
Validation loss: 2.42144044701603

Epoch: 6| Step: 11
Training loss: 0.16341170023460772
Validation loss: 2.400520935208817

Epoch: 6| Step: 12
Training loss: 0.13108832699331227
Validation loss: 2.397201293254728

Epoch: 6| Step: 13
Training loss: 0.11146027267705912
Validation loss: 2.3749726449873125

Epoch: 464| Step: 0
Training loss: 0.2294345052747609
Validation loss: 2.414335182156812

Epoch: 6| Step: 1
Training loss: 0.10385325987977011
Validation loss: 2.3970257617036097

Epoch: 6| Step: 2
Training loss: 0.12267972272065777
Validation loss: 2.3937420749610765

Epoch: 6| Step: 3
Training loss: 0.16663140368443968
Validation loss: 2.4183708973866125

Epoch: 6| Step: 4
Training loss: 0.2368922633168589
Validation loss: 2.4338905707699525

Epoch: 6| Step: 5
Training loss: 0.1894636642828001
Validation loss: 2.4439210811749184

Epoch: 6| Step: 6
Training loss: 0.1801180036166847
Validation loss: 2.435130499761805

Epoch: 6| Step: 7
Training loss: 0.2053580689483398
Validation loss: 2.462195977532189

Epoch: 6| Step: 8
Training loss: 0.14424722058818365
Validation loss: 2.426478846218629

Epoch: 6| Step: 9
Training loss: 0.1201043160838212
Validation loss: 2.447504283665771

Epoch: 6| Step: 10
Training loss: 0.10728029110549699
Validation loss: 2.4457331407042453

Epoch: 6| Step: 11
Training loss: 0.1651953741358987
Validation loss: 2.4519813619759554

Epoch: 6| Step: 12
Training loss: 0.2191709232294699
Validation loss: 2.4532500998605813

Epoch: 6| Step: 13
Training loss: 0.177641477515854
Validation loss: 2.449328422625912

Epoch: 465| Step: 0
Training loss: 0.24336597378572533
Validation loss: 2.4283981856473633

Epoch: 6| Step: 1
Training loss: 0.1523406260732548
Validation loss: 2.443655582388768

Epoch: 6| Step: 2
Training loss: 0.11654260333249901
Validation loss: 2.431128581091777

Epoch: 6| Step: 3
Training loss: 0.15396348934504556
Validation loss: 2.456518197287204

Epoch: 6| Step: 4
Training loss: 0.22784692786709068
Validation loss: 2.4223389021482005

Epoch: 6| Step: 5
Training loss: 0.14445608994250578
Validation loss: 2.4164929008353044

Epoch: 6| Step: 6
Training loss: 0.10852831714796224
Validation loss: 2.402696358886304

Epoch: 6| Step: 7
Training loss: 0.13197775383363425
Validation loss: 2.4164831376816407

Epoch: 6| Step: 8
Training loss: 0.19940602158373597
Validation loss: 2.4419399429272777

Epoch: 6| Step: 9
Training loss: 0.2002634537263574
Validation loss: 2.431999750984397

Epoch: 6| Step: 10
Training loss: 0.10621109400909891
Validation loss: 2.446133626656185

Epoch: 6| Step: 11
Training loss: 0.12912023008257073
Validation loss: 2.4007464917828467

Epoch: 6| Step: 12
Training loss: 0.13716878391845466
Validation loss: 2.419545289818908

Epoch: 6| Step: 13
Training loss: 0.14455005162609924
Validation loss: 2.4501694771112934

Epoch: 466| Step: 0
Training loss: 0.20672182135632236
Validation loss: 2.413120300290262

Epoch: 6| Step: 1
Training loss: 0.19210310028675712
Validation loss: 2.4142464490912805

Epoch: 6| Step: 2
Training loss: 0.10425180343542
Validation loss: 2.425193681906902

Epoch: 6| Step: 3
Training loss: 0.23488221121970695
Validation loss: 2.4397830562517075

Epoch: 6| Step: 4
Training loss: 0.18192119873545004
Validation loss: 2.4570864019071994

Epoch: 6| Step: 5
Training loss: 0.1392340213093478
Validation loss: 2.423659172309868

Epoch: 6| Step: 6
Training loss: 0.12308672607808478
Validation loss: 2.442246929771909

Epoch: 6| Step: 7
Training loss: 0.1653699886509915
Validation loss: 2.42616351472787

Epoch: 6| Step: 8
Training loss: 0.11094965515571999
Validation loss: 2.457204623918278

Epoch: 6| Step: 9
Training loss: 0.16413748253815044
Validation loss: 2.433188388507948

Epoch: 6| Step: 10
Training loss: 0.08651464010683564
Validation loss: 2.4341292606449976

Epoch: 6| Step: 11
Training loss: 0.11725790769735953
Validation loss: 2.4265168280702656

Epoch: 6| Step: 12
Training loss: 0.08791471786885274
Validation loss: 2.4042648918813088

Epoch: 6| Step: 13
Training loss: 0.12518865534896328
Validation loss: 2.413554687378486

Epoch: 467| Step: 0
Training loss: 0.1194045473649753
Validation loss: 2.4187273427267675

Epoch: 6| Step: 1
Training loss: 0.09239671413033343
Validation loss: 2.4349470844614243

Epoch: 6| Step: 2
Training loss: 0.14303104106745296
Validation loss: 2.416102435963841

Epoch: 6| Step: 3
Training loss: 0.16092292525210497
Validation loss: 2.386106646455837

Epoch: 6| Step: 4
Training loss: 0.12433616379295703
Validation loss: 2.405608033617941

Epoch: 6| Step: 5
Training loss: 0.1531165646156399
Validation loss: 2.425172546285834

Epoch: 6| Step: 6
Training loss: 0.20081813043085212
Validation loss: 2.450446430590368

Epoch: 6| Step: 7
Training loss: 0.09926122709824094
Validation loss: 2.456934729357414

Epoch: 6| Step: 8
Training loss: 0.1734226995888984
Validation loss: 2.4483071153058544

Epoch: 6| Step: 9
Training loss: 0.2323000452358105
Validation loss: 2.4342160354106377

Epoch: 6| Step: 10
Training loss: 0.219212511412964
Validation loss: 2.416927944807477

Epoch: 6| Step: 11
Training loss: 0.1243505107489808
Validation loss: 2.4395744902869785

Epoch: 6| Step: 12
Training loss: 0.22208902821983634
Validation loss: 2.44055599693716

Epoch: 6| Step: 13
Training loss: 0.13758562331856652
Validation loss: 2.4445253145877603

Epoch: 468| Step: 0
Training loss: 0.18074751292690103
Validation loss: 2.434909010377642

Epoch: 6| Step: 1
Training loss: 0.17825289953021636
Validation loss: 2.4333954837996594

Epoch: 6| Step: 2
Training loss: 0.2165641222586153
Validation loss: 2.411584484098348

Epoch: 6| Step: 3
Training loss: 0.15477005918024808
Validation loss: 2.4063970736328075

Epoch: 6| Step: 4
Training loss: 0.12568656307290466
Validation loss: 2.410091947417498

Epoch: 6| Step: 5
Training loss: 0.14632502471604913
Validation loss: 2.4203186835423027

Epoch: 6| Step: 6
Training loss: 0.10964981108818575
Validation loss: 2.3824820781784726

Epoch: 6| Step: 7
Training loss: 0.12143446688292582
Validation loss: 2.414908414130916

Epoch: 6| Step: 8
Training loss: 0.2042679177179426
Validation loss: 2.4149111731996102

Epoch: 6| Step: 9
Training loss: 0.11609708995558406
Validation loss: 2.399997810906263

Epoch: 6| Step: 10
Training loss: 0.16162908597702416
Validation loss: 2.397879475718841

Epoch: 6| Step: 11
Training loss: 0.18833975694118937
Validation loss: 2.394241520236358

Epoch: 6| Step: 12
Training loss: 0.22338552003731935
Validation loss: 2.412451410141649

Epoch: 6| Step: 13
Training loss: 0.09959573278317649
Validation loss: 2.4037880781050944

Epoch: 469| Step: 0
Training loss: 0.13876278006488704
Validation loss: 2.417424117915427

Epoch: 6| Step: 1
Training loss: 0.09524618268842917
Validation loss: 2.406100575996537

Epoch: 6| Step: 2
Training loss: 0.16148299110974912
Validation loss: 2.4111334592226523

Epoch: 6| Step: 3
Training loss: 0.08647087774081823
Validation loss: 2.4184727000548656

Epoch: 6| Step: 4
Training loss: 0.16725504415436693
Validation loss: 2.4280445695761728

Epoch: 6| Step: 5
Training loss: 0.08723184268923896
Validation loss: 2.4564749472056704

Epoch: 6| Step: 6
Training loss: 0.11732629662711089
Validation loss: 2.4219828179078196

Epoch: 6| Step: 7
Training loss: 0.19614076468721725
Validation loss: 2.456733426672278

Epoch: 6| Step: 8
Training loss: 0.16022832923245087
Validation loss: 2.4546103389834957

Epoch: 6| Step: 9
Training loss: 0.20507449192280408
Validation loss: 2.419177208535762

Epoch: 6| Step: 10
Training loss: 0.13196644151752043
Validation loss: 2.4437204406014708

Epoch: 6| Step: 11
Training loss: 0.217366149894383
Validation loss: 2.4443712369973065

Epoch: 6| Step: 12
Training loss: 0.12816204925183639
Validation loss: 2.45199361251862

Epoch: 6| Step: 13
Training loss: 0.10577092769047679
Validation loss: 2.450406492881913

Epoch: 470| Step: 0
Training loss: 0.08676113647867358
Validation loss: 2.4347551802793754

Epoch: 6| Step: 1
Training loss: 0.1458452778988146
Validation loss: 2.39542436430765

Epoch: 6| Step: 2
Training loss: 0.09312808363724667
Validation loss: 2.399933682656884

Epoch: 6| Step: 3
Training loss: 0.0872132397371459
Validation loss: 2.4119386841501367

Epoch: 6| Step: 4
Training loss: 0.2014605663620259
Validation loss: 2.4333882850592614

Epoch: 6| Step: 5
Training loss: 0.13630443192225888
Validation loss: 2.401470287986368

Epoch: 6| Step: 6
Training loss: 0.1983641075720585
Validation loss: 2.437061717404793

Epoch: 6| Step: 7
Training loss: 0.20754230149949413
Validation loss: 2.3855438372268924

Epoch: 6| Step: 8
Training loss: 0.20445798024879827
Validation loss: 2.39306474523208

Epoch: 6| Step: 9
Training loss: 0.10894349674915202
Validation loss: 2.4119686778335407

Epoch: 6| Step: 10
Training loss: 0.18068419679362333
Validation loss: 2.4034659937088114

Epoch: 6| Step: 11
Training loss: 0.10020444802321368
Validation loss: 2.4110811698204664

Epoch: 6| Step: 12
Training loss: 0.1114697016246804
Validation loss: 2.4265858658267416

Epoch: 6| Step: 13
Training loss: 0.06716339696425953
Validation loss: 2.418697255848266

Epoch: 471| Step: 0
Training loss: 0.12921990901468752
Validation loss: 2.4480709419168427

Epoch: 6| Step: 1
Training loss: 0.1348838149673413
Validation loss: 2.4620715342222095

Epoch: 6| Step: 2
Training loss: 0.13574165920456646
Validation loss: 2.437196328236543

Epoch: 6| Step: 3
Training loss: 0.20704714696058935
Validation loss: 2.457681310444732

Epoch: 6| Step: 4
Training loss: 0.05351023020317953
Validation loss: 2.4574998478877994

Epoch: 6| Step: 5
Training loss: 0.15340401861044795
Validation loss: 2.4478143079342427

Epoch: 6| Step: 6
Training loss: 0.17555001732662628
Validation loss: 2.4774504746889465

Epoch: 6| Step: 7
Training loss: 0.16787823744525987
Validation loss: 2.478340247901007

Epoch: 6| Step: 8
Training loss: 0.24554083032356092
Validation loss: 2.4547736837470984

Epoch: 6| Step: 9
Training loss: 0.05825009099217499
Validation loss: 2.45083099166426

Epoch: 6| Step: 10
Training loss: 0.14246941694206872
Validation loss: 2.4786911140615784

Epoch: 6| Step: 11
Training loss: 0.09938742181377624
Validation loss: 2.446535646093971

Epoch: 6| Step: 12
Training loss: 0.13034843219294173
Validation loss: 2.4491553787967097

Epoch: 6| Step: 13
Training loss: 0.10011720699022857
Validation loss: 2.4344182122745726

Epoch: 472| Step: 0
Training loss: 0.12821878280657822
Validation loss: 2.412685124667481

Epoch: 6| Step: 1
Training loss: 0.10545367557033165
Validation loss: 2.431642170580354

Epoch: 6| Step: 2
Training loss: 0.1979347250044975
Validation loss: 2.4410169485481026

Epoch: 6| Step: 3
Training loss: 0.129697567192826
Validation loss: 2.426428471540583

Epoch: 6| Step: 4
Training loss: 0.09445587297769578
Validation loss: 2.4358302387714392

Epoch: 6| Step: 5
Training loss: 0.11581074303628817
Validation loss: 2.4317268092408413

Epoch: 6| Step: 6
Training loss: 0.1988310126074331
Validation loss: 2.429463476742173

Epoch: 6| Step: 7
Training loss: 0.11660295769960587
Validation loss: 2.4135335662762656

Epoch: 6| Step: 8
Training loss: 0.20647877626770583
Validation loss: 2.406134251171933

Epoch: 6| Step: 9
Training loss: 0.14773046102034326
Validation loss: 2.4517242715196477

Epoch: 6| Step: 10
Training loss: 0.04832079300067162
Validation loss: 2.4299680243688693

Epoch: 6| Step: 11
Training loss: 0.19716214780259084
Validation loss: 2.4498204330576923

Epoch: 6| Step: 12
Training loss: 0.11939477000999696
Validation loss: 2.4070873484240876

Epoch: 6| Step: 13
Training loss: 0.08491526669669637
Validation loss: 2.428451623134804

Epoch: 473| Step: 0
Training loss: 0.20124206429585878
Validation loss: 2.4189269436729033

Epoch: 6| Step: 1
Training loss: 0.10501144750527637
Validation loss: 2.4390845715971965

Epoch: 6| Step: 2
Training loss: 0.20742575826799403
Validation loss: 2.41291490774566

Epoch: 6| Step: 3
Training loss: 0.08028337876514469
Validation loss: 2.455076743497114

Epoch: 6| Step: 4
Training loss: 0.10258832384006225
Validation loss: 2.439181478549783

Epoch: 6| Step: 5
Training loss: 0.12232283222789829
Validation loss: 2.4470674207172203

Epoch: 6| Step: 6
Training loss: 0.0817481133029291
Validation loss: 2.4410533389082527

Epoch: 6| Step: 7
Training loss: 0.07368142979252344
Validation loss: 2.44227623738049

Epoch: 6| Step: 8
Training loss: 0.14351927391816804
Validation loss: 2.421665551757906

Epoch: 6| Step: 9
Training loss: 0.07084022935731332
Validation loss: 2.432143444503994

Epoch: 6| Step: 10
Training loss: 0.10431635403270233
Validation loss: 2.421681568202746

Epoch: 6| Step: 11
Training loss: 0.14427407039586762
Validation loss: 2.4554592460047555

Epoch: 6| Step: 12
Training loss: 0.18747941539940216
Validation loss: 2.4491966578764264

Epoch: 6| Step: 13
Training loss: 0.21327115967744742
Validation loss: 2.4251058304425768

Epoch: 474| Step: 0
Training loss: 0.10691354729162757
Validation loss: 2.429829299250337

Epoch: 6| Step: 1
Training loss: 0.22461842228456294
Validation loss: 2.4510057328402315

Epoch: 6| Step: 2
Training loss: 0.09435332890245536
Validation loss: 2.4357706102982926

Epoch: 6| Step: 3
Training loss: 0.1187115117492544
Validation loss: 2.447835689890566

Epoch: 6| Step: 4
Training loss: 0.0867029637496612
Validation loss: 2.4684360793147633

Epoch: 6| Step: 5
Training loss: 0.11344325057604875
Validation loss: 2.454482458086252

Epoch: 6| Step: 6
Training loss: 0.09294343230978344
Validation loss: 2.4454816476473913

Epoch: 6| Step: 7
Training loss: 0.15951596178409172
Validation loss: 2.4437562572578635

Epoch: 6| Step: 8
Training loss: 0.11112979321660682
Validation loss: 2.447893051909776

Epoch: 6| Step: 9
Training loss: 0.11070804490118365
Validation loss: 2.4598607267827144

Epoch: 6| Step: 10
Training loss: 0.19029616541048547
Validation loss: 2.433027356762569

Epoch: 6| Step: 11
Training loss: 0.11049105680694044
Validation loss: 2.435723156967871

Epoch: 6| Step: 12
Training loss: 0.09959886532859141
Validation loss: 2.4778403874913577

Epoch: 6| Step: 13
Training loss: 0.11524778223438054
Validation loss: 2.4523957543279624

Epoch: 475| Step: 0
Training loss: 0.21177062880535416
Validation loss: 2.4251620440125414

Epoch: 6| Step: 1
Training loss: 0.13363015699382513
Validation loss: 2.454809060817227

Epoch: 6| Step: 2
Training loss: 0.17248304599049874
Validation loss: 2.42766014053406

Epoch: 6| Step: 3
Training loss: 0.10468428325692898
Validation loss: 2.4256407196500884

Epoch: 6| Step: 4
Training loss: 0.07485231596401563
Validation loss: 2.428634690319662

Epoch: 6| Step: 5
Training loss: 0.10482525551519406
Validation loss: 2.435030084163756

Epoch: 6| Step: 6
Training loss: 0.06935490093680922
Validation loss: 2.4096552354546197

Epoch: 6| Step: 7
Training loss: 0.19768779261709404
Validation loss: 2.4297933706770753

Epoch: 6| Step: 8
Training loss: 0.11560699461239159
Validation loss: 2.4062698575454853

Epoch: 6| Step: 9
Training loss: 0.11619192657123356
Validation loss: 2.392238554171918

Epoch: 6| Step: 10
Training loss: 0.16308573191738304
Validation loss: 2.419368708581032

Epoch: 6| Step: 11
Training loss: 0.20282545377510586
Validation loss: 2.420835542782841

Epoch: 6| Step: 12
Training loss: 0.23489473255235058
Validation loss: 2.4272410266581965

Epoch: 6| Step: 13
Training loss: 0.11730870098700923
Validation loss: 2.438583206961359

Epoch: 476| Step: 0
Training loss: 0.0906057489435625
Validation loss: 2.4639886726607254

Epoch: 6| Step: 1
Training loss: 0.1454510610112117
Validation loss: 2.4659631694851094

Epoch: 6| Step: 2
Training loss: 0.19087333840481968
Validation loss: 2.4631737209211746

Epoch: 6| Step: 3
Training loss: 0.1406803816778593
Validation loss: 2.498038508930626

Epoch: 6| Step: 4
Training loss: 0.11644642475854888
Validation loss: 2.482684437813215

Epoch: 6| Step: 5
Training loss: 0.15947260555866882
Validation loss: 2.495671510035762

Epoch: 6| Step: 6
Training loss: 0.2046181015128814
Validation loss: 2.4837616431427754

Epoch: 6| Step: 7
Training loss: 0.11510370410492532
Validation loss: 2.483299200192019

Epoch: 6| Step: 8
Training loss: 0.2180923812026319
Validation loss: 2.4235572225605844

Epoch: 6| Step: 9
Training loss: 0.2349530958355886
Validation loss: 2.43197158450353

Epoch: 6| Step: 10
Training loss: 0.1557904638475398
Validation loss: 2.402288221719119

Epoch: 6| Step: 11
Training loss: 0.21163926128005825
Validation loss: 2.4000152083653377

Epoch: 6| Step: 12
Training loss: 0.11835570597233765
Validation loss: 2.4107481665291366

Epoch: 6| Step: 13
Training loss: 0.17036837527437038
Validation loss: 2.375629494364017

Epoch: 477| Step: 0
Training loss: 0.1658489456437511
Validation loss: 2.4039391217929365

Epoch: 6| Step: 1
Training loss: 0.2149960498252872
Validation loss: 2.3968239860594416

Epoch: 6| Step: 2
Training loss: 0.18534689717506264
Validation loss: 2.40106058694958

Epoch: 6| Step: 3
Training loss: 0.1324434130659629
Validation loss: 2.3838684743916225

Epoch: 6| Step: 4
Training loss: 0.1129323626451774
Validation loss: 2.4140230318905025

Epoch: 6| Step: 5
Training loss: 0.24761291901014118
Validation loss: 2.4217047243467635

Epoch: 6| Step: 6
Training loss: 0.11256358945616926
Validation loss: 2.39985904971891

Epoch: 6| Step: 7
Training loss: 0.10280852560866298
Validation loss: 2.467577089560711

Epoch: 6| Step: 8
Training loss: 0.12545185822191646
Validation loss: 2.4577141174502803

Epoch: 6| Step: 9
Training loss: 0.18762144486987592
Validation loss: 2.444386553005024

Epoch: 6| Step: 10
Training loss: 0.1458872194586207
Validation loss: 2.470468412417417

Epoch: 6| Step: 11
Training loss: 0.15142052233797104
Validation loss: 2.4688294056419555

Epoch: 6| Step: 12
Training loss: 0.11425335378179727
Validation loss: 2.4746861708504597

Epoch: 6| Step: 13
Training loss: 0.1381846990642217
Validation loss: 2.499794139897671

Epoch: 478| Step: 0
Training loss: 0.14534515531791845
Validation loss: 2.4939337914212163

Epoch: 6| Step: 1
Training loss: 0.23264494377215078
Validation loss: 2.4735956183674013

Epoch: 6| Step: 2
Training loss: 0.09678464067128328
Validation loss: 2.4764985148438123

Epoch: 6| Step: 3
Training loss: 0.115300478806157
Validation loss: 2.481435480239687

Epoch: 6| Step: 4
Training loss: 0.07005439512817796
Validation loss: 2.4848976609635156

Epoch: 6| Step: 5
Training loss: 0.2209811527125427
Validation loss: 2.4514184526822103

Epoch: 6| Step: 6
Training loss: 0.09527975950579776
Validation loss: 2.4863912011821365

Epoch: 6| Step: 7
Training loss: 0.18758972325944806
Validation loss: 2.4939390400027546

Epoch: 6| Step: 8
Training loss: 0.12025648274464347
Validation loss: 2.476389377782826

Epoch: 6| Step: 9
Training loss: 0.10061953733407364
Validation loss: 2.4964553971831656

Epoch: 6| Step: 10
Training loss: 0.12294049432780103
Validation loss: 2.495665242868351

Epoch: 6| Step: 11
Training loss: 0.12259453554239673
Validation loss: 2.471085351025019

Epoch: 6| Step: 12
Training loss: 0.0880295873507976
Validation loss: 2.4815660838195233

Epoch: 6| Step: 13
Training loss: 0.09088692734436528
Validation loss: 2.483649730684674

Epoch: 479| Step: 0
Training loss: 0.14693864954908864
Validation loss: 2.465507801013928

Epoch: 6| Step: 1
Training loss: 0.0693186583949856
Validation loss: 2.4492809891375265

Epoch: 6| Step: 2
Training loss: 0.17308474830213752
Validation loss: 2.4366313616062625

Epoch: 6| Step: 3
Training loss: 0.15392720326731357
Validation loss: 2.436228815862759

Epoch: 6| Step: 4
Training loss: 0.1409647004275849
Validation loss: 2.4251213743626088

Epoch: 6| Step: 5
Training loss: 0.086600816067037
Validation loss: 2.4191727471275652

Epoch: 6| Step: 6
Training loss: 0.21569401078966277
Validation loss: 2.4273933727724626

Epoch: 6| Step: 7
Training loss: 0.12615203465224387
Validation loss: 2.4254457844419077

Epoch: 6| Step: 8
Training loss: 0.10073864557489612
Validation loss: 2.4356082488443445

Epoch: 6| Step: 9
Training loss: 0.1278607859957291
Validation loss: 2.438346437113928

Epoch: 6| Step: 10
Training loss: 0.06009304988850498
Validation loss: 2.415953331103448

Epoch: 6| Step: 11
Training loss: 0.15658279978328116
Validation loss: 2.4501122505251214

Epoch: 6| Step: 12
Training loss: 0.19526966578944002
Validation loss: 2.443397266519755

Epoch: 6| Step: 13
Training loss: 0.07573664866789177
Validation loss: 2.4371866551192007

Epoch: 480| Step: 0
Training loss: 0.09245148560077984
Validation loss: 2.4194339291145277

Epoch: 6| Step: 1
Training loss: 0.20687451817781977
Validation loss: 2.438956726475246

Epoch: 6| Step: 2
Training loss: 0.09017399547148006
Validation loss: 2.4350693902361717

Epoch: 6| Step: 3
Training loss: 0.10421525497524112
Validation loss: 2.4569211782881277

Epoch: 6| Step: 4
Training loss: 0.11886958262437099
Validation loss: 2.4442681835232194

Epoch: 6| Step: 5
Training loss: 0.06700636571874696
Validation loss: 2.4477688952693315

Epoch: 6| Step: 6
Training loss: 0.11303251187097649
Validation loss: 2.4644213384168854

Epoch: 6| Step: 7
Training loss: 0.13411585026361747
Validation loss: 2.4652987627793084

Epoch: 6| Step: 8
Training loss: 0.10137391003788278
Validation loss: 2.438597092790979

Epoch: 6| Step: 9
Training loss: 0.1445755053115588
Validation loss: 2.448400421273312

Epoch: 6| Step: 10
Training loss: 0.05900392808254006
Validation loss: 2.4376553627145894

Epoch: 6| Step: 11
Training loss: 0.2320859067615534
Validation loss: 2.4606757297419923

Epoch: 6| Step: 12
Training loss: 0.17592594760958313
Validation loss: 2.42418124466292

Epoch: 6| Step: 13
Training loss: 0.09435923626278846
Validation loss: 2.434337608086776

Epoch: 481| Step: 0
Training loss: 0.1628760969420739
Validation loss: 2.420443895540526

Epoch: 6| Step: 1
Training loss: 0.09351806959304834
Validation loss: 2.425131965081035

Epoch: 6| Step: 2
Training loss: 0.11834343387404396
Validation loss: 2.400736628819581

Epoch: 6| Step: 3
Training loss: 0.08235803579281249
Validation loss: 2.430261806857602

Epoch: 6| Step: 4
Training loss: 0.0863746017386147
Validation loss: 2.403016900301785

Epoch: 6| Step: 5
Training loss: 0.15821459811016642
Validation loss: 2.4399427369581765

Epoch: 6| Step: 6
Training loss: 0.1743262258803859
Validation loss: 2.4354675544779503

Epoch: 6| Step: 7
Training loss: 0.18278696460565902
Validation loss: 2.4636894375486453

Epoch: 6| Step: 8
Training loss: 0.12105734724044537
Validation loss: 2.436829608601087

Epoch: 6| Step: 9
Training loss: 0.16559403687880778
Validation loss: 2.4371542358009157

Epoch: 6| Step: 10
Training loss: 0.0792659916659657
Validation loss: 2.4514663833781887

Epoch: 6| Step: 11
Training loss: 0.11626300927403246
Validation loss: 2.442239875739108

Epoch: 6| Step: 12
Training loss: 0.0596992239123088
Validation loss: 2.4421913860601556

Epoch: 6| Step: 13
Training loss: 0.10027209643249951
Validation loss: 2.4646699845867976

Epoch: 482| Step: 0
Training loss: 0.11440615927221914
Validation loss: 2.4466751654254555

Epoch: 6| Step: 1
Training loss: 0.09716218902420834
Validation loss: 2.4445141991009582

Epoch: 6| Step: 2
Training loss: 0.09878614989271248
Validation loss: 2.448051538637736

Epoch: 6| Step: 3
Training loss: 0.177674818016411
Validation loss: 2.439300802699849

Epoch: 6| Step: 4
Training loss: 0.2198904740053774
Validation loss: 2.448681575227436

Epoch: 6| Step: 5
Training loss: 0.12100913183057171
Validation loss: 2.4202580066438406

Epoch: 6| Step: 6
Training loss: 0.08779228855162341
Validation loss: 2.438785717675498

Epoch: 6| Step: 7
Training loss: 0.19528765520386204
Validation loss: 2.4148827718390047

Epoch: 6| Step: 8
Training loss: 0.07459910394462652
Validation loss: 2.4155681884611466

Epoch: 6| Step: 9
Training loss: 0.09831041105849674
Validation loss: 2.431712838187998

Epoch: 6| Step: 10
Training loss: 0.1354027146402376
Validation loss: 2.410574719487064

Epoch: 6| Step: 11
Training loss: 0.09948601283071337
Validation loss: 2.412088367187506

Epoch: 6| Step: 12
Training loss: 0.08791212242858441
Validation loss: 2.399251375632914

Epoch: 6| Step: 13
Training loss: 0.07964500317879718
Validation loss: 2.3872812806286894

Epoch: 483| Step: 0
Training loss: 0.11514196084653464
Validation loss: 2.407862629625167

Epoch: 6| Step: 1
Training loss: 0.08584094041421085
Validation loss: 2.414949083269829

Epoch: 6| Step: 2
Training loss: 0.18211381046845612
Validation loss: 2.402540346230503

Epoch: 6| Step: 3
Training loss: 0.1329445182784191
Validation loss: 2.4040063866629815

Epoch: 6| Step: 4
Training loss: 0.12823370125492364
Validation loss: 2.3944962189536603

Epoch: 6| Step: 5
Training loss: 0.13308963891411316
Validation loss: 2.4192802838490683

Epoch: 6| Step: 6
Training loss: 0.12100427921615868
Validation loss: 2.4061462290473465

Epoch: 6| Step: 7
Training loss: 0.07704207174104567
Validation loss: 2.4106124738910024

Epoch: 6| Step: 8
Training loss: 0.10170256145266657
Validation loss: 2.4308447145968315

Epoch: 6| Step: 9
Training loss: 0.12333044422544481
Validation loss: 2.438945805295075

Epoch: 6| Step: 10
Training loss: 0.11974701403362378
Validation loss: 2.44660365739181

Epoch: 6| Step: 11
Training loss: 0.23603659374097627
Validation loss: 2.428830041418334

Epoch: 6| Step: 12
Training loss: 0.17579312284427376
Validation loss: 2.435883865787367

Epoch: 6| Step: 13
Training loss: 0.11949315445762182
Validation loss: 2.4400058504629913

Epoch: 484| Step: 0
Training loss: 0.08196305380734194
Validation loss: 2.418913984091074

Epoch: 6| Step: 1
Training loss: 0.11641714089925526
Validation loss: 2.390456517900637

Epoch: 6| Step: 2
Training loss: 0.08995581458674201
Validation loss: 2.4202919106468417

Epoch: 6| Step: 3
Training loss: 0.09467827165755144
Validation loss: 2.4462238170350967

Epoch: 6| Step: 4
Training loss: 0.06246630684329083
Validation loss: 2.4202461579259493

Epoch: 6| Step: 5
Training loss: 0.12877202993636305
Validation loss: 2.44911814161443

Epoch: 6| Step: 6
Training loss: 0.19275884138231678
Validation loss: 2.4097799472511117

Epoch: 6| Step: 7
Training loss: 0.17641421902330623
Validation loss: 2.4297957293203774

Epoch: 6| Step: 8
Training loss: 0.11332084522825597
Validation loss: 2.4257387597406406

Epoch: 6| Step: 9
Training loss: 0.19017357843664326
Validation loss: 2.4313394373735546

Epoch: 6| Step: 10
Training loss: 0.17017007655985958
Validation loss: 2.4293309616746908

Epoch: 6| Step: 11
Training loss: 0.07850724823234853
Validation loss: 2.434355221393316

Epoch: 6| Step: 12
Training loss: 0.08745267686768245
Validation loss: 2.444180194944324

Epoch: 6| Step: 13
Training loss: 0.08304505915015761
Validation loss: 2.4323736269519536

Epoch: 485| Step: 0
Training loss: 0.16086044411213643
Validation loss: 2.4537006463308497

Epoch: 6| Step: 1
Training loss: 0.09459975199975629
Validation loss: 2.420664579754079

Epoch: 6| Step: 2
Training loss: 0.11416974300729106
Validation loss: 2.4124401989431825

Epoch: 6| Step: 3
Training loss: 0.22406500486412925
Validation loss: 2.4282529101594643

Epoch: 6| Step: 4
Training loss: 0.12576525361362542
Validation loss: 2.4344246634429236

Epoch: 6| Step: 5
Training loss: 0.08195251989641254
Validation loss: 2.3979979535821365

Epoch: 6| Step: 6
Training loss: 0.17017882201771448
Validation loss: 2.4291764986720845

Epoch: 6| Step: 7
Training loss: 0.1801109817716493
Validation loss: 2.4139126377599034

Epoch: 6| Step: 8
Training loss: 0.07463449185196178
Validation loss: 2.416896967863764

Epoch: 6| Step: 9
Training loss: 0.09559318494738868
Validation loss: 2.443335167095768

Epoch: 6| Step: 10
Training loss: 0.1385217243256669
Validation loss: 2.417551397087386

Epoch: 6| Step: 11
Training loss: 0.1140121851952808
Validation loss: 2.4408859387593975

Epoch: 6| Step: 12
Training loss: 0.09324468087553045
Validation loss: 2.4387070995973046

Epoch: 6| Step: 13
Training loss: 0.11313807137326812
Validation loss: 2.437803018212737

Epoch: 486| Step: 0
Training loss: 0.086203342763485
Validation loss: 2.4190334977789463

Epoch: 6| Step: 1
Training loss: 0.1744717138511139
Validation loss: 2.416637921896094

Epoch: 6| Step: 2
Training loss: 0.12151039648267063
Validation loss: 2.420931989435005

Epoch: 6| Step: 3
Training loss: 0.14586376329674716
Validation loss: 2.4033991206503096

Epoch: 6| Step: 4
Training loss: 0.09582917514967654
Validation loss: 2.4212531274165703

Epoch: 6| Step: 5
Training loss: 0.082749182634048
Validation loss: 2.4187066647950046

Epoch: 6| Step: 6
Training loss: 0.16913736045100902
Validation loss: 2.4229789469897316

Epoch: 6| Step: 7
Training loss: 0.22186118942583766
Validation loss: 2.4149380397183537

Epoch: 6| Step: 8
Training loss: 0.12293411568132105
Validation loss: 2.4229979971627618

Epoch: 6| Step: 9
Training loss: 0.09359665090812952
Validation loss: 2.4201153415131844

Epoch: 6| Step: 10
Training loss: 0.09724720642623978
Validation loss: 2.4048353516036443

Epoch: 6| Step: 11
Training loss: 0.13690015474607473
Validation loss: 2.4226167218514725

Epoch: 6| Step: 12
Training loss: 0.09839301182567459
Validation loss: 2.4494297356511305

Epoch: 6| Step: 13
Training loss: 0.12701907279006375
Validation loss: 2.432196252129295

Epoch: 487| Step: 0
Training loss: 0.11563432517337088
Validation loss: 2.4141368154297376

Epoch: 6| Step: 1
Training loss: 0.12413732301030858
Validation loss: 2.411217107733745

Epoch: 6| Step: 2
Training loss: 0.10902276115112013
Validation loss: 2.4542758891926906

Epoch: 6| Step: 3
Training loss: 0.08009128346144778
Validation loss: 2.4372874993732547

Epoch: 6| Step: 4
Training loss: 0.09559860165864682
Validation loss: 2.420679978507211

Epoch: 6| Step: 5
Training loss: 0.11150125794064611
Validation loss: 2.4195646520444147

Epoch: 6| Step: 6
Training loss: 0.10322077613208237
Validation loss: 2.4564160583485166

Epoch: 6| Step: 7
Training loss: 0.17169306619395586
Validation loss: 2.442147054526215

Epoch: 6| Step: 8
Training loss: 0.21706772115388392
Validation loss: 2.4421706737571935

Epoch: 6| Step: 9
Training loss: 0.24790947780818337
Validation loss: 2.4177450744916755

Epoch: 6| Step: 10
Training loss: 0.10177200057389514
Validation loss: 2.442109254883381

Epoch: 6| Step: 11
Training loss: 0.10272277541726123
Validation loss: 2.4273691123110215

Epoch: 6| Step: 12
Training loss: 0.09883113788641076
Validation loss: 2.4290252227149116

Epoch: 6| Step: 13
Training loss: 0.13212652324098004
Validation loss: 2.393643221822677

Epoch: 488| Step: 0
Training loss: 0.13202646404824167
Validation loss: 2.416103952224602

Epoch: 6| Step: 1
Training loss: 0.11297563731038475
Validation loss: 2.461483736840879

Epoch: 6| Step: 2
Training loss: 0.088804081109397
Validation loss: 2.4458788521547135

Epoch: 6| Step: 3
Training loss: 0.15950534716749312
Validation loss: 2.4321358009296303

Epoch: 6| Step: 4
Training loss: 0.12130799491291076
Validation loss: 2.4619053174781396

Epoch: 6| Step: 5
Training loss: 0.11533703514568533
Validation loss: 2.429570210824278

Epoch: 6| Step: 6
Training loss: 0.12004864683287284
Validation loss: 2.4541172988327205

Epoch: 6| Step: 7
Training loss: 0.22104696479731364
Validation loss: 2.4714321915693236

Epoch: 6| Step: 8
Training loss: 0.09300026019025368
Validation loss: 2.4558607973587914

Epoch: 6| Step: 9
Training loss: 0.18527828653365172
Validation loss: 2.4679658599035603

Epoch: 6| Step: 10
Training loss: 0.08168181003401481
Validation loss: 2.451962067600015

Epoch: 6| Step: 11
Training loss: 0.10999708293032584
Validation loss: 2.4362845323419835

Epoch: 6| Step: 12
Training loss: 0.17870939493816415
Validation loss: 2.4277789063535256

Epoch: 6| Step: 13
Training loss: 0.07371494306588265
Validation loss: 2.449339732924886

Epoch: 489| Step: 0
Training loss: 0.11478917550876065
Validation loss: 2.4438201288087438

Epoch: 6| Step: 1
Training loss: 0.1953327931352161
Validation loss: 2.433619082950137

Epoch: 6| Step: 2
Training loss: 0.12142149349629366
Validation loss: 2.435619698640221

Epoch: 6| Step: 3
Training loss: 0.07715009132254382
Validation loss: 2.4030555026219242

Epoch: 6| Step: 4
Training loss: 0.17712134182436046
Validation loss: 2.419921133427002

Epoch: 6| Step: 5
Training loss: 0.11530713435226818
Validation loss: 2.3752989478289352

Epoch: 6| Step: 6
Training loss: 0.1714516269549212
Validation loss: 2.405843411930767

Epoch: 6| Step: 7
Training loss: 0.10007253657304194
Validation loss: 2.385352068317138

Epoch: 6| Step: 8
Training loss: 0.106243335641093
Validation loss: 2.4347973436712285

Epoch: 6| Step: 9
Training loss: 0.12312168541672938
Validation loss: 2.390808142420883

Epoch: 6| Step: 10
Training loss: 0.12936819276316025
Validation loss: 2.417108721997536

Epoch: 6| Step: 11
Training loss: 0.14479140117561462
Validation loss: 2.438001679401933

Epoch: 6| Step: 12
Training loss: 0.1468504971498394
Validation loss: 2.4218074549671322

Epoch: 6| Step: 13
Training loss: 0.11656329886569236
Validation loss: 2.4276629167906143

Epoch: 490| Step: 0
Training loss: 0.1465506594415624
Validation loss: 2.4522030479138883

Epoch: 6| Step: 1
Training loss: 0.18899748764184782
Validation loss: 2.4615061295562737

Epoch: 6| Step: 2
Training loss: 0.07915814165854985
Validation loss: 2.432265029075911

Epoch: 6| Step: 3
Training loss: 0.12111613235968748
Validation loss: 2.439947569109124

Epoch: 6| Step: 4
Training loss: 0.1265775921735861
Validation loss: 2.429082329738438

Epoch: 6| Step: 5
Training loss: 0.15051617274169354
Validation loss: 2.4241462835777727

Epoch: 6| Step: 6
Training loss: 0.1140920708484947
Validation loss: 2.428658271013111

Epoch: 6| Step: 7
Training loss: 0.11527088766790783
Validation loss: 2.4249111619979846

Epoch: 6| Step: 8
Training loss: 0.1340036272725197
Validation loss: 2.4340093980604833

Epoch: 6| Step: 9
Training loss: 0.24554621624471357
Validation loss: 2.4160085941234644

Epoch: 6| Step: 10
Training loss: 0.11703522245721563
Validation loss: 2.4042775156408234

Epoch: 6| Step: 11
Training loss: 0.11881293508213213
Validation loss: 2.430892486736171

Epoch: 6| Step: 12
Training loss: 0.12573971773479123
Validation loss: 2.421343353592991

Epoch: 6| Step: 13
Training loss: 0.09224906094391024
Validation loss: 2.3777194017052614

Epoch: 491| Step: 0
Training loss: 0.11734011963842629
Validation loss: 2.3963823057806346

Epoch: 6| Step: 1
Training loss: 0.2231143371721609
Validation loss: 2.431839406931881

Epoch: 6| Step: 2
Training loss: 0.1417648163592353
Validation loss: 2.410529390662517

Epoch: 6| Step: 3
Training loss: 0.15917710144188987
Validation loss: 2.4220060547914497

Epoch: 6| Step: 4
Training loss: 0.12410063856415525
Validation loss: 2.418965698004205

Epoch: 6| Step: 5
Training loss: 0.08310600531614411
Validation loss: 2.4119332251087062

Epoch: 6| Step: 6
Training loss: 0.09467813886189141
Validation loss: 2.426468071467306

Epoch: 6| Step: 7
Training loss: 0.11342507719293103
Validation loss: 2.4242030708943543

Epoch: 6| Step: 8
Training loss: 0.2014774020890227
Validation loss: 2.418621904519674

Epoch: 6| Step: 9
Training loss: 0.12355910133223066
Validation loss: 2.422473896139571

Epoch: 6| Step: 10
Training loss: 0.10874946137135949
Validation loss: 2.4276546006836113

Epoch: 6| Step: 11
Training loss: 0.1530500569190487
Validation loss: 2.4570297360413527

Epoch: 6| Step: 12
Training loss: 0.11103449127615474
Validation loss: 2.4211057872421557

Epoch: 6| Step: 13
Training loss: 0.12186816071002443
Validation loss: 2.428803575558468

Epoch: 492| Step: 0
Training loss: 0.10404570728992402
Validation loss: 2.3866836257669344

Epoch: 6| Step: 1
Training loss: 0.10524289355105954
Validation loss: 2.3764594806772688

Epoch: 6| Step: 2
Training loss: 0.17560494906620436
Validation loss: 2.403317662796248

Epoch: 6| Step: 3
Training loss: 0.19357380392480272
Validation loss: 2.3918637583552425

Epoch: 6| Step: 4
Training loss: 0.17346067918073482
Validation loss: 2.3989566456107436

Epoch: 6| Step: 5
Training loss: 0.16486587127397304
Validation loss: 2.386684030718989

Epoch: 6| Step: 6
Training loss: 0.07144641493691851
Validation loss: 2.399987153605122

Epoch: 6| Step: 7
Training loss: 0.17895576508144284
Validation loss: 2.385546449178539

Epoch: 6| Step: 8
Training loss: 0.12508475142539596
Validation loss: 2.38713232045188

Epoch: 6| Step: 9
Training loss: 0.12171319986845203
Validation loss: 2.415741742059763

Epoch: 6| Step: 10
Training loss: 0.13726626166433237
Validation loss: 2.4157943240246333

Epoch: 6| Step: 11
Training loss: 0.12874318414998304
Validation loss: 2.4561443497032465

Epoch: 6| Step: 12
Training loss: 0.09324625895719942
Validation loss: 2.4331845528242275

Epoch: 6| Step: 13
Training loss: 0.05732139534958843
Validation loss: 2.465492755029011

Epoch: 493| Step: 0
Training loss: 0.11680933015174916
Validation loss: 2.4673907399834634

Epoch: 6| Step: 1
Training loss: 0.21465066556320864
Validation loss: 2.4822207244532795

Epoch: 6| Step: 2
Training loss: 0.1613670322987224
Validation loss: 2.460281070446224

Epoch: 6| Step: 3
Training loss: 0.09005040782026476
Validation loss: 2.443639919266014

Epoch: 6| Step: 4
Training loss: 0.07668324748406984
Validation loss: 2.4363847089407615

Epoch: 6| Step: 5
Training loss: 0.1178801333193572
Validation loss: 2.449537532253261

Epoch: 6| Step: 6
Training loss: 0.11962553914839526
Validation loss: 2.4258501987831496

Epoch: 6| Step: 7
Training loss: 0.08738364653685973
Validation loss: 2.4457267183163993

Epoch: 6| Step: 8
Training loss: 0.12738309819839572
Validation loss: 2.4507740283086514

Epoch: 6| Step: 9
Training loss: 0.08398807872323588
Validation loss: 2.4155946234228094

Epoch: 6| Step: 10
Training loss: 0.07797683733123574
Validation loss: 2.4436342320483733

Epoch: 6| Step: 11
Training loss: 0.22777855020985885
Validation loss: 2.432826457398277

Epoch: 6| Step: 12
Training loss: 0.09527324450490125
Validation loss: 2.411806035830833

Epoch: 6| Step: 13
Training loss: 0.12834817563524314
Validation loss: 2.4025518869268927

Epoch: 494| Step: 0
Training loss: 0.09593383073779432
Validation loss: 2.4181440838732744

Epoch: 6| Step: 1
Training loss: 0.1367791995879018
Validation loss: 2.409123613386416

Epoch: 6| Step: 2
Training loss: 0.12110977682067413
Validation loss: 2.40688766087048

Epoch: 6| Step: 3
Training loss: 0.21172084877691214
Validation loss: 2.4114546824405276

Epoch: 6| Step: 4
Training loss: 0.16056241890685105
Validation loss: 2.429115249387094

Epoch: 6| Step: 5
Training loss: 0.1728021475638337
Validation loss: 2.4274518689429683

Epoch: 6| Step: 6
Training loss: 0.07715189298303297
Validation loss: 2.4366411474007186

Epoch: 6| Step: 7
Training loss: 0.08393081354328434
Validation loss: 2.428481227074804

Epoch: 6| Step: 8
Training loss: 0.08894259533691883
Validation loss: 2.427725130927386

Epoch: 6| Step: 9
Training loss: 0.09357613096789452
Validation loss: 2.4245897905838922

Epoch: 6| Step: 10
Training loss: 0.09220697229630344
Validation loss: 2.4337388610003474

Epoch: 6| Step: 11
Training loss: 0.06321821089899854
Validation loss: 2.425485338844658

Epoch: 6| Step: 12
Training loss: 0.1251255388476938
Validation loss: 2.439000525802684

Epoch: 6| Step: 13
Training loss: 0.12831951762378516
Validation loss: 2.4681309279084322

Epoch: 495| Step: 0
Training loss: 0.09941521589588125
Validation loss: 2.449451775958166

Epoch: 6| Step: 1
Training loss: 0.11885214102063947
Validation loss: 2.4183052601878186

Epoch: 6| Step: 2
Training loss: 0.15463105361524815
Validation loss: 2.4533509202089823

Epoch: 6| Step: 3
Training loss: 0.18656223952053166
Validation loss: 2.4371727407417114

Epoch: 6| Step: 4
Training loss: 0.11164175161136268
Validation loss: 2.4422420591323903

Epoch: 6| Step: 5
Training loss: 0.11947404218627221
Validation loss: 2.4235383576686766

Epoch: 6| Step: 6
Training loss: 0.17398364364545676
Validation loss: 2.4521512887486243

Epoch: 6| Step: 7
Training loss: 0.09986873594651964
Validation loss: 2.4688781086133846

Epoch: 6| Step: 8
Training loss: 0.10899550729726497
Validation loss: 2.4470071925812684

Epoch: 6| Step: 9
Training loss: 0.05709091781926575
Validation loss: 2.424987402036331

Epoch: 6| Step: 10
Training loss: 0.09882143604877235
Validation loss: 2.4226197430431387

Epoch: 6| Step: 11
Training loss: 0.06574159621359829
Validation loss: 2.404210986114918

Epoch: 6| Step: 12
Training loss: 0.15012188841789667
Validation loss: 2.4368532651690846

Epoch: 6| Step: 13
Training loss: 0.13862122698775403
Validation loss: 2.4336054631512303

Epoch: 496| Step: 0
Training loss: 0.0755914742760787
Validation loss: 2.3981658641702635

Epoch: 6| Step: 1
Training loss: 0.1292741107205021
Validation loss: 2.412289386787997

Epoch: 6| Step: 2
Training loss: 0.09861418104299566
Validation loss: 2.3863450843673393

Epoch: 6| Step: 3
Training loss: 0.1049056740393579
Validation loss: 2.40219055695788

Epoch: 6| Step: 4
Training loss: 0.11674288008746804
Validation loss: 2.3739187400138975

Epoch: 6| Step: 5
Training loss: 0.09720168175826986
Validation loss: 2.392591522962816

Epoch: 6| Step: 6
Training loss: 0.1622313190169808
Validation loss: 2.40366514694103

Epoch: 6| Step: 7
Training loss: 0.1476183171467536
Validation loss: 2.394051554206572

Epoch: 6| Step: 8
Training loss: 0.11069455476375387
Validation loss: 2.4005808502944865

Epoch: 6| Step: 9
Training loss: 0.11764617800821124
Validation loss: 2.395242903631574

Epoch: 6| Step: 10
Training loss: 0.2417092369392373
Validation loss: 2.411406038306803

Epoch: 6| Step: 11
Training loss: 0.09737686724366046
Validation loss: 2.4139889049691527

Epoch: 6| Step: 12
Training loss: 0.09141806297915162
Validation loss: 2.4203878959727336

Epoch: 6| Step: 13
Training loss: 0.09507668081109857
Validation loss: 2.4325302982617627

Epoch: 497| Step: 0
Training loss: 0.17006421978118427
Validation loss: 2.452243307626694

Epoch: 6| Step: 1
Training loss: 0.0944307368259573
Validation loss: 2.462081654664934

Epoch: 6| Step: 2
Training loss: 0.08995361970033595
Validation loss: 2.4794307118996097

Epoch: 6| Step: 3
Training loss: 0.1475875576128863
Validation loss: 2.4905096091704815

Epoch: 6| Step: 4
Training loss: 0.13983491304916268
Validation loss: 2.479125809395301

Epoch: 6| Step: 5
Training loss: 0.15144781610929975
Validation loss: 2.471700514505756

Epoch: 6| Step: 6
Training loss: 0.11304276948603673
Validation loss: 2.4725426238555106

Epoch: 6| Step: 7
Training loss: 0.1490335668518535
Validation loss: 2.450578703516346

Epoch: 6| Step: 8
Training loss: 0.2104398809428015
Validation loss: 2.4509733237237605

Epoch: 6| Step: 9
Training loss: 0.08318034641549127
Validation loss: 2.4372414735012526

Epoch: 6| Step: 10
Training loss: 0.11725890447863102
Validation loss: 2.447283603039871

Epoch: 6| Step: 11
Training loss: 0.09915921460062029
Validation loss: 2.404598285532615

Epoch: 6| Step: 12
Training loss: 0.16889714783766768
Validation loss: 2.3949359268866837

Epoch: 6| Step: 13
Training loss: 0.13966875662065983
Validation loss: 2.3842743465513805

Epoch: 498| Step: 0
Training loss: 0.10224723614889747
Validation loss: 2.3778115175041896

Epoch: 6| Step: 1
Training loss: 0.1005102076209864
Validation loss: 2.3950686205859193

Epoch: 6| Step: 2
Training loss: 0.14028287038421736
Validation loss: 2.376874450626754

Epoch: 6| Step: 3
Training loss: 0.1516713194168367
Validation loss: 2.376137741054164

Epoch: 6| Step: 4
Training loss: 0.11181155864752171
Validation loss: 2.3765067484407285

Epoch: 6| Step: 5
Training loss: 0.12991966355782023
Validation loss: 2.388298726410293

Epoch: 6| Step: 6
Training loss: 0.16664607447330834
Validation loss: 2.3833270387016396

Epoch: 6| Step: 7
Training loss: 0.1380335529032512
Validation loss: 2.4103711404176678

Epoch: 6| Step: 8
Training loss: 0.2087709638496643
Validation loss: 2.4115238319449093

Epoch: 6| Step: 9
Training loss: 0.18561487457646736
Validation loss: 2.4322140311429474

Epoch: 6| Step: 10
Training loss: 0.14495291930062051
Validation loss: 2.433837699840137

Epoch: 6| Step: 11
Training loss: 0.18722714996086548
Validation loss: 2.4560293443208496

Epoch: 6| Step: 12
Training loss: 0.07584877753854502
Validation loss: 2.460502881725284

Epoch: 6| Step: 13
Training loss: 0.154138205828778
Validation loss: 2.4724517288231516

Epoch: 499| Step: 0
Training loss: 0.10926278352254408
Validation loss: 2.4506019883192756

Epoch: 6| Step: 1
Training loss: 0.22373063226075277
Validation loss: 2.4912869252302596

Epoch: 6| Step: 2
Training loss: 0.12845099136980445
Validation loss: 2.471914065203117

Epoch: 6| Step: 3
Training loss: 0.10140681254873016
Validation loss: 2.4699732869044597

Epoch: 6| Step: 4
Training loss: 0.08915635108139774
Validation loss: 2.457272741068754

Epoch: 6| Step: 5
Training loss: 0.060855012169255256
Validation loss: 2.4498124370389642

Epoch: 6| Step: 6
Training loss: 0.08586865615317607
Validation loss: 2.433105571480835

Epoch: 6| Step: 7
Training loss: 0.0826551998113176
Validation loss: 2.455882342043672

Epoch: 6| Step: 8
Training loss: 0.14260107012545478
Validation loss: 2.4408990883678205

Epoch: 6| Step: 9
Training loss: 0.07619253208587137
Validation loss: 2.4378097690733065

Epoch: 6| Step: 10
Training loss: 0.09893454299190017
Validation loss: 2.405380191963369

Epoch: 6| Step: 11
Training loss: 0.10332967142505102
Validation loss: 2.3893891207699647

Epoch: 6| Step: 12
Training loss: 0.18745570851763746
Validation loss: 2.4160076200281804

Epoch: 6| Step: 13
Training loss: 0.07634334033332273
Validation loss: 2.42252667591169

Epoch: 500| Step: 0
Training loss: 0.10457180234455503
Validation loss: 2.3976993657515346

Epoch: 6| Step: 1
Training loss: 0.15312503722248794
Validation loss: 2.424979234273938

Epoch: 6| Step: 2
Training loss: 0.07578071085256328
Validation loss: 2.426745898856172

Epoch: 6| Step: 3
Training loss: 0.081028554909077
Validation loss: 2.4080089228676687

Epoch: 6| Step: 4
Training loss: 0.07887200613355178
Validation loss: 2.396829017448047

Epoch: 6| Step: 5
Training loss: 0.09121499389515844
Validation loss: 2.4088033056280276

Epoch: 6| Step: 6
Training loss: 0.14418961124172514
Validation loss: 2.408036239011606

Epoch: 6| Step: 7
Training loss: 0.09521786611601851
Validation loss: 2.410146091812263

Epoch: 6| Step: 8
Training loss: 0.21464839202908145
Validation loss: 2.402959386132583

Epoch: 6| Step: 9
Training loss: 0.1109492480410906
Validation loss: 2.412437337156876

Epoch: 6| Step: 10
Training loss: 0.15334125545844537
Validation loss: 2.391224323760935

Epoch: 6| Step: 11
Training loss: 0.10147950100518988
Validation loss: 2.413352746483736

Epoch: 6| Step: 12
Training loss: 0.08558110549497791
Validation loss: 2.4255185556946146

Epoch: 6| Step: 13
Training loss: 0.09544461720246067
Validation loss: 2.416535462695831

Testing loss: 2.4161970931986683
