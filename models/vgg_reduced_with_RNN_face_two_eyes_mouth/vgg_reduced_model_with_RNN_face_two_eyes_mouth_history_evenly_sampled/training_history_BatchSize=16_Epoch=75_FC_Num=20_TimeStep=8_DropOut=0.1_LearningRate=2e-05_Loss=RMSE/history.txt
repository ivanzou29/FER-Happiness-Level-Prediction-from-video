Epoch: 1| Step: 0
Training loss: 4.387164180760756
Validation loss: 5.724423752639075

Epoch: 6| Step: 1
Training loss: 4.3763469257533485
Validation loss: 5.694696103122712

Epoch: 6| Step: 2
Training loss: 5.03684506382929
Validation loss: 5.661354410020108

Epoch: 6| Step: 3
Training loss: 6.1588203757221365
Validation loss: 5.626483963041907

Epoch: 6| Step: 4
Training loss: 7.204529333684601
Validation loss: 5.585850195041452

Epoch: 6| Step: 5
Training loss: 3.819757901054523
Validation loss: 5.5407506423294075

Epoch: 6| Step: 6
Training loss: 5.268563285587285
Validation loss: 5.490937443552388

Epoch: 6| Step: 7
Training loss: 5.7975929000800495
Validation loss: 5.4339538484619645

Epoch: 6| Step: 8
Training loss: 6.269206937678913
Validation loss: 5.370599668746157

Epoch: 6| Step: 9
Training loss: 6.63002946067467
Validation loss: 5.301891575912498

Epoch: 6| Step: 10
Training loss: 4.092583410010786
Validation loss: 5.226153844642373

Epoch: 6| Step: 11
Training loss: 4.555021663074086
Validation loss: 5.148615024424043

Epoch: 6| Step: 12
Training loss: 5.877302002875793
Validation loss: 5.067583627549901

Epoch: 6| Step: 13
Training loss: 5.833365449362856
Validation loss: 4.985003887626775

Epoch: 2| Step: 0
Training loss: 5.449797656301461
Validation loss: 4.9003866281303745

Epoch: 6| Step: 1
Training loss: 3.9550684799265112
Validation loss: 4.816557667438487

Epoch: 6| Step: 2
Training loss: 4.271644229976349
Validation loss: 4.73417866065295

Epoch: 6| Step: 3
Training loss: 4.698741809363912
Validation loss: 4.656331139448254

Epoch: 6| Step: 4
Training loss: 4.555228304286713
Validation loss: 4.58231779838223

Epoch: 6| Step: 5
Training loss: 3.7677645481434454
Validation loss: 4.512222792741436

Epoch: 6| Step: 6
Training loss: 4.190689466465596
Validation loss: 4.447421157432192

Epoch: 6| Step: 7
Training loss: 5.158842787392275
Validation loss: 4.385517418023402

Epoch: 6| Step: 8
Training loss: 5.267705579891118
Validation loss: 4.327300516835686

Epoch: 6| Step: 9
Training loss: 4.058337382497993
Validation loss: 4.271793682294428

Epoch: 6| Step: 10
Training loss: 5.3941610486886145
Validation loss: 4.22665967134509

Epoch: 6| Step: 11
Training loss: 3.9970744878810955
Validation loss: 4.180918586283929

Epoch: 6| Step: 12
Training loss: 3.6553565343797336
Validation loss: 4.139091617955925

Epoch: 6| Step: 13
Training loss: 5.170273823966669
Validation loss: 4.103705750981358

Epoch: 3| Step: 0
Training loss: 3.082753376072362
Validation loss: 4.069649948901844

Epoch: 6| Step: 1
Training loss: 3.1490358300010453
Validation loss: 4.037978987945196

Epoch: 6| Step: 2
Training loss: 3.8569539619291437
Validation loss: 4.008091136802456

Epoch: 6| Step: 3
Training loss: 5.281077365198036
Validation loss: 3.9846284853661107

Epoch: 6| Step: 4
Training loss: 3.9209209360733706
Validation loss: 3.9567994483905076

Epoch: 6| Step: 5
Training loss: 4.521604176328638
Validation loss: 3.9360766998600156

Epoch: 6| Step: 6
Training loss: 4.226428468733188
Validation loss: 3.908301880447527

Epoch: 6| Step: 7
Training loss: 3.876925820511533
Validation loss: 3.8827068738455703

Epoch: 6| Step: 8
Training loss: 3.5878760057711143
Validation loss: 3.8577436447054363

Epoch: 6| Step: 9
Training loss: 3.4059351504340776
Validation loss: 3.828215085062695

Epoch: 6| Step: 10
Training loss: 4.156870171878657
Validation loss: 3.7942572426142056

Epoch: 6| Step: 11
Training loss: 4.263202580248137
Validation loss: 3.7672726636360756

Epoch: 6| Step: 12
Training loss: 4.932229621386857
Validation loss: 3.750328276563761

Epoch: 6| Step: 13
Training loss: 3.7827614529871
Validation loss: 3.731686901206634

Epoch: 4| Step: 0
Training loss: 3.8731502917357914
Validation loss: 3.714520075594957

Epoch: 6| Step: 1
Training loss: 4.059399169661976
Validation loss: 3.6976242391184777

Epoch: 6| Step: 2
Training loss: 3.339361430359589
Validation loss: 3.68329884385782

Epoch: 6| Step: 3
Training loss: 4.0052151061928
Validation loss: 3.666000315916865

Epoch: 6| Step: 4
Training loss: 3.8356421331675965
Validation loss: 3.6448995680652416

Epoch: 6| Step: 5
Training loss: 4.23813251287112
Validation loss: 3.6269633768532623

Epoch: 6| Step: 6
Training loss: 4.248802914044446
Validation loss: 3.613129869708354

Epoch: 6| Step: 7
Training loss: 3.541366669159946
Validation loss: 3.5972492575291044

Epoch: 6| Step: 8
Training loss: 4.21508629978657
Validation loss: 3.5864604651094183

Epoch: 6| Step: 9
Training loss: 3.6257610179925988
Validation loss: 3.5693185445524116

Epoch: 6| Step: 10
Training loss: 3.1309839558222285
Validation loss: 3.5549211293905914

Epoch: 6| Step: 11
Training loss: 3.597493618448521
Validation loss: 3.541703278402396

Epoch: 6| Step: 12
Training loss: 3.846339648233785
Validation loss: 3.528576822706812

Epoch: 6| Step: 13
Training loss: 3.501867885796835
Validation loss: 3.5187246774123557

Epoch: 5| Step: 0
Training loss: 3.610550858164118
Validation loss: 3.511776027253174

Epoch: 6| Step: 1
Training loss: 3.5459118850440405
Validation loss: 3.4971958462063313

Epoch: 6| Step: 2
Training loss: 3.320939594963449
Validation loss: 3.474589945160853

Epoch: 6| Step: 3
Training loss: 3.86535650506585
Validation loss: 3.4593004405714436

Epoch: 6| Step: 4
Training loss: 3.50878702403051
Validation loss: 3.4385820462613075

Epoch: 6| Step: 5
Training loss: 3.372623878731896
Validation loss: 3.4254188289297947

Epoch: 6| Step: 6
Training loss: 4.1520961569233785
Validation loss: 3.412800194591104

Epoch: 6| Step: 7
Training loss: 4.3454746692056565
Validation loss: 3.3994394166566764

Epoch: 6| Step: 8
Training loss: 3.6613714100199966
Validation loss: 3.382777852758159

Epoch: 6| Step: 9
Training loss: 3.402827231811169
Validation loss: 3.366907892770537

Epoch: 6| Step: 10
Training loss: 3.2209617645069195
Validation loss: 3.355808189364284

Epoch: 6| Step: 11
Training loss: 3.8853622446348153
Validation loss: 3.341207214231052

Epoch: 6| Step: 12
Training loss: 3.630083268947111
Validation loss: 3.331539668724032

Epoch: 6| Step: 13
Training loss: 2.7109803298073363
Validation loss: 3.3169957936376826

Epoch: 6| Step: 0
Training loss: 2.6868751154258685
Validation loss: 3.308007586701754

Epoch: 6| Step: 1
Training loss: 3.5035619322010785
Validation loss: 3.2951754935045736

Epoch: 6| Step: 2
Training loss: 3.957720832952895
Validation loss: 3.2816334333879458

Epoch: 6| Step: 3
Training loss: 3.7933276524247024
Validation loss: 3.2667570880340344

Epoch: 6| Step: 4
Training loss: 3.8370406978736455
Validation loss: 3.2502102842998637

Epoch: 6| Step: 5
Training loss: 4.145142591943484
Validation loss: 3.237336141057069

Epoch: 6| Step: 6
Training loss: 3.1399310659629176
Validation loss: 3.2217978895092876

Epoch: 6| Step: 7
Training loss: 3.7611416921745024
Validation loss: 3.2092146273677606

Epoch: 6| Step: 8
Training loss: 2.7614778794026535
Validation loss: 3.1972667090643094

Epoch: 6| Step: 9
Training loss: 3.616503393352261
Validation loss: 3.1880513984455536

Epoch: 6| Step: 10
Training loss: 3.232310202706571
Validation loss: 3.1768175847456153

Epoch: 6| Step: 11
Training loss: 3.237090366915805
Validation loss: 3.168482249187547

Epoch: 6| Step: 12
Training loss: 3.191936621608002
Validation loss: 3.15739019319107

Epoch: 6| Step: 13
Training loss: 3.5905495365934508
Validation loss: 3.150900466888987

Epoch: 7| Step: 0
Training loss: 2.5873982432531437
Validation loss: 3.142129429076079

Epoch: 6| Step: 1
Training loss: 4.362103445835274
Validation loss: 3.133207497418662

Epoch: 6| Step: 2
Training loss: 2.745942156366525
Validation loss: 3.1229752509268796

Epoch: 6| Step: 3
Training loss: 3.1558311864380393
Validation loss: 3.112743325706427

Epoch: 6| Step: 4
Training loss: 3.8797347153100095
Validation loss: 3.101435262704292

Epoch: 6| Step: 5
Training loss: 3.747366552744399
Validation loss: 3.0951614184901817

Epoch: 6| Step: 6
Training loss: 3.6037626683187494
Validation loss: 3.0879394110623704

Epoch: 6| Step: 7
Training loss: 3.3141414965648237
Validation loss: 3.0794327454769745

Epoch: 6| Step: 8
Training loss: 3.009116150368525
Validation loss: 3.070217755356286

Epoch: 6| Step: 9
Training loss: 3.3401312810258377
Validation loss: 3.0719749327188803

Epoch: 6| Step: 10
Training loss: 3.0298874142317436
Validation loss: 3.0581569636087895

Epoch: 6| Step: 11
Training loss: 3.2353206118350535
Validation loss: 3.0529908488514317

Epoch: 6| Step: 12
Training loss: 3.229732406444275
Validation loss: 3.047417949115815

Epoch: 6| Step: 13
Training loss: 3.7177140532015196
Validation loss: 3.0405131124983655

Epoch: 8| Step: 0
Training loss: 3.2707604726139556
Validation loss: 3.0306618850156557

Epoch: 6| Step: 1
Training loss: 3.174091936151287
Validation loss: 3.02912747330017

Epoch: 6| Step: 2
Training loss: 3.815806721476986
Validation loss: 3.0435877869099954

Epoch: 6| Step: 3
Training loss: 3.3486565928088985
Validation loss: 3.0331693542991136

Epoch: 6| Step: 4
Training loss: 2.7438092340492632
Validation loss: 3.0270612839872224

Epoch: 6| Step: 5
Training loss: 3.658607049201418
Validation loss: 3.018650367455001

Epoch: 6| Step: 6
Training loss: 2.994669310793073
Validation loss: 3.0140577567980684

Epoch: 6| Step: 7
Training loss: 3.73249124555334
Validation loss: 3.001335134073554

Epoch: 6| Step: 8
Training loss: 3.6334768692735473
Validation loss: 2.9962895787379358

Epoch: 6| Step: 9
Training loss: 3.58670295075377
Validation loss: 2.9883338112350293

Epoch: 6| Step: 10
Training loss: 3.631169823501701
Validation loss: 2.9790413248784153

Epoch: 6| Step: 11
Training loss: 2.934328030503847
Validation loss: 2.9686035793705057

Epoch: 6| Step: 12
Training loss: 2.5992949630254683
Validation loss: 2.958627902496971

Epoch: 6| Step: 13
Training loss: 2.412057482203696
Validation loss: 2.9533013541115385

Epoch: 9| Step: 0
Training loss: 3.822268369553818
Validation loss: 2.9466628672365056

Epoch: 6| Step: 1
Training loss: 3.3137465236880135
Validation loss: 2.9432061854051024

Epoch: 6| Step: 2
Training loss: 2.5871103629159746
Validation loss: 2.9391492753153523

Epoch: 6| Step: 3
Training loss: 3.8683394748869637
Validation loss: 2.9687651240379695

Epoch: 6| Step: 4
Training loss: 3.644320597392215
Validation loss: 2.9319575090266006

Epoch: 6| Step: 5
Training loss: 2.704873109615964
Validation loss: 2.95649213283405

Epoch: 6| Step: 6
Training loss: 2.786316190047208
Validation loss: 2.9992189591278926

Epoch: 6| Step: 7
Training loss: 2.976699625696401
Validation loss: 2.936929155510035

Epoch: 6| Step: 8
Training loss: 3.0450014271599692
Validation loss: 2.9214744159471313

Epoch: 6| Step: 9
Training loss: 3.875851937441212
Validation loss: 2.92412829764121

Epoch: 6| Step: 10
Training loss: 3.2585002072685283
Validation loss: 2.9349437309031443

Epoch: 6| Step: 11
Training loss: 3.0864904753270612
Validation loss: 2.9340152514408486

Epoch: 6| Step: 12
Training loss: 2.2432084899143088
Validation loss: 2.9330248950445053

Epoch: 6| Step: 13
Training loss: 4.2133476423270055
Validation loss: 2.9153250475543016

Epoch: 10| Step: 0
Training loss: 3.0178597031854135
Validation loss: 2.900080668904858

Epoch: 6| Step: 1
Training loss: 4.069613288672025
Validation loss: 2.893760051101653

Epoch: 6| Step: 2
Training loss: 2.8408337406222683
Validation loss: 2.898943382689407

Epoch: 6| Step: 3
Training loss: 4.040257290116177
Validation loss: 2.904518785903191

Epoch: 6| Step: 4
Training loss: 3.0564916409877885
Validation loss: 2.898118770450367

Epoch: 6| Step: 5
Training loss: 3.0140272265991004
Validation loss: 2.8901354338854253

Epoch: 6| Step: 6
Training loss: 3.433157796600655
Validation loss: 2.8811507414565525

Epoch: 6| Step: 7
Training loss: 3.2919083196729275
Validation loss: 2.877369995715613

Epoch: 6| Step: 8
Training loss: 2.5740062759073927
Validation loss: 2.871848281292761

Epoch: 6| Step: 9
Training loss: 2.4429050087123314
Validation loss: 2.8694438757453433

Epoch: 6| Step: 10
Training loss: 3.288830094270157
Validation loss: 2.8704029208945134

Epoch: 6| Step: 11
Training loss: 3.4538534785538255
Validation loss: 2.8667036557321173

Epoch: 6| Step: 12
Training loss: 2.5016550307878993
Validation loss: 2.8588789974725684

Epoch: 6| Step: 13
Training loss: 3.6211709155242144
Validation loss: 2.853150254047627

Epoch: 11| Step: 0
Training loss: 2.881545700820226
Validation loss: 2.852775438256121

Epoch: 6| Step: 1
Training loss: 2.751458388205049
Validation loss: 2.850118646273141

Epoch: 6| Step: 2
Training loss: 3.3765492592145527
Validation loss: 2.850534475108811

Epoch: 6| Step: 3
Training loss: 2.7803466701476585
Validation loss: 2.8475600480309464

Epoch: 6| Step: 4
Training loss: 3.2402053840908462
Validation loss: 2.842307459492501

Epoch: 6| Step: 5
Training loss: 3.323258975264312
Validation loss: 2.8415183716224184

Epoch: 6| Step: 6
Training loss: 3.0086838289979116
Validation loss: 2.8380041056908283

Epoch: 6| Step: 7
Training loss: 3.3673822120961128
Validation loss: 2.832525072561989

Epoch: 6| Step: 8
Training loss: 3.148382370989121
Validation loss: 2.8309097453570167

Epoch: 6| Step: 9
Training loss: 3.4170435410723803
Validation loss: 2.8285312536431517

Epoch: 6| Step: 10
Training loss: 3.39420196727138
Validation loss: 2.8272191420477535

Epoch: 6| Step: 11
Training loss: 3.0447214193959544
Validation loss: 2.8232769945978493

Epoch: 6| Step: 12
Training loss: 3.2220246776959423
Validation loss: 2.8226233309786384

Epoch: 6| Step: 13
Training loss: 3.5172362301745586
Validation loss: 2.8216932167407207

Epoch: 12| Step: 0
Training loss: 3.007608619814977
Validation loss: 2.821766171205434

Epoch: 6| Step: 1
Training loss: 3.519993217201634
Validation loss: 2.8253638336415405

Epoch: 6| Step: 2
Training loss: 3.566370551274304
Validation loss: 2.826443600389409

Epoch: 6| Step: 3
Training loss: 3.0223825275067555
Validation loss: 2.816260973606199

Epoch: 6| Step: 4
Training loss: 2.5870615196035405
Validation loss: 2.8132038452622004

Epoch: 6| Step: 5
Training loss: 3.2847377587655098
Validation loss: 2.810052208950975

Epoch: 6| Step: 6
Training loss: 2.701742535356757
Validation loss: 2.8093096103627997

Epoch: 6| Step: 7
Training loss: 3.253385247952391
Validation loss: 2.810173120357674

Epoch: 6| Step: 8
Training loss: 3.0638435686282848
Validation loss: 2.8097164220666957

Epoch: 6| Step: 9
Training loss: 3.048029441250764
Validation loss: 2.808932675616841

Epoch: 6| Step: 10
Training loss: 3.664454587605307
Validation loss: 2.799759036490806

Epoch: 6| Step: 11
Training loss: 2.666093337494886
Validation loss: 2.800052284742861

Epoch: 6| Step: 12
Training loss: 3.591884360977435
Validation loss: 2.80277958423611

Epoch: 6| Step: 13
Training loss: 2.7996372669140452
Validation loss: 2.8023233231251368

Epoch: 13| Step: 0
Training loss: 3.1718626726784773
Validation loss: 2.8054561173648263

Epoch: 6| Step: 1
Training loss: 2.8746939786499417
Validation loss: 2.795964533552842

Epoch: 6| Step: 2
Training loss: 3.398663112123211
Validation loss: 2.7979522791750755

Epoch: 6| Step: 3
Training loss: 3.0005432272862653
Validation loss: 2.794896582648408

Epoch: 6| Step: 4
Training loss: 3.244439576927726
Validation loss: 2.790139776350997

Epoch: 6| Step: 5
Training loss: 3.4472650717067546
Validation loss: 2.7866489474391725

Epoch: 6| Step: 6
Training loss: 3.2032241433780007
Validation loss: 2.7847670978039276

Epoch: 6| Step: 7
Training loss: 3.355942502844389
Validation loss: 2.783724162867792

Epoch: 6| Step: 8
Training loss: 3.34004819366954
Validation loss: 2.7815592788453176

Epoch: 6| Step: 9
Training loss: 2.9332736840107603
Validation loss: 2.7874563630827707

Epoch: 6| Step: 10
Training loss: 3.022950283488445
Validation loss: 2.78430970072123

Epoch: 6| Step: 11
Training loss: 3.1873001335163402
Validation loss: 2.7807606728312404

Epoch: 6| Step: 12
Training loss: 2.9631448937122213
Validation loss: 2.7753418954683258

Epoch: 6| Step: 13
Training loss: 2.347574495996178
Validation loss: 2.7787301628081487

Epoch: 14| Step: 0
Training loss: 3.6320089784670864
Validation loss: 2.8224059980537346

Epoch: 6| Step: 1
Training loss: 3.3008412011475
Validation loss: 2.859269914243206

Epoch: 6| Step: 2
Training loss: 3.026955935341159
Validation loss: 2.829807241439476

Epoch: 6| Step: 3
Training loss: 3.401952149446553
Validation loss: 2.8144365605236783

Epoch: 6| Step: 4
Training loss: 3.139152827085957
Validation loss: 2.795628485125512

Epoch: 6| Step: 5
Training loss: 3.4060876090160934
Validation loss: 2.783213130096028

Epoch: 6| Step: 6
Training loss: 2.5975547369145255
Validation loss: 2.779458940731668

Epoch: 6| Step: 7
Training loss: 3.5675024414054146
Validation loss: 2.786323656506312

Epoch: 6| Step: 8
Training loss: 2.4795069955125957
Validation loss: 2.7862627263031703

Epoch: 6| Step: 9
Training loss: 2.76199749480071
Validation loss: 2.789426043692691

Epoch: 6| Step: 10
Training loss: 3.5191875124786742
Validation loss: 2.782363049460059

Epoch: 6| Step: 11
Training loss: 2.9269163326169143
Validation loss: 2.784043215933435

Epoch: 6| Step: 12
Training loss: 2.809510570815133
Validation loss: 2.8044621542763237

Epoch: 6| Step: 13
Training loss: 3.1689927107876708
Validation loss: 2.7947577540699204

Epoch: 15| Step: 0
Training loss: 3.727115486110104
Validation loss: 2.7756339420993514

Epoch: 6| Step: 1
Training loss: 3.1602778653012598
Validation loss: 2.7698958022313467

Epoch: 6| Step: 2
Training loss: 3.458473999349251
Validation loss: 2.76725749319422

Epoch: 6| Step: 3
Training loss: 2.7750493912983796
Validation loss: 2.762991626019882

Epoch: 6| Step: 4
Training loss: 3.0408981780768576
Validation loss: 2.761595145264013

Epoch: 6| Step: 5
Training loss: 3.0350140669620815
Validation loss: 2.7623780349788993

Epoch: 6| Step: 6
Training loss: 2.662770693634024
Validation loss: 2.7662075118232234

Epoch: 6| Step: 7
Training loss: 2.577979251325284
Validation loss: 2.7713219067483137

Epoch: 6| Step: 8
Training loss: 3.6189489174890297
Validation loss: 2.7943812105381913

Epoch: 6| Step: 9
Training loss: 3.425837760989861
Validation loss: 2.761682015969092

Epoch: 6| Step: 10
Training loss: 2.422508501445391
Validation loss: 2.7549948539929257

Epoch: 6| Step: 11
Training loss: 3.2763575819531323
Validation loss: 2.7536375332565672

Epoch: 6| Step: 12
Training loss: 3.014334130592442
Validation loss: 2.75633081512958

Epoch: 6| Step: 13
Training loss: 3.2499997065617356
Validation loss: 2.7595384680193984

Epoch: 16| Step: 0
Training loss: 3.2301479858416724
Validation loss: 2.763516000557892

Epoch: 6| Step: 1
Training loss: 3.3373977359720386
Validation loss: 2.7565453942974085

Epoch: 6| Step: 2
Training loss: 2.9315916663446075
Validation loss: 2.749159083065844

Epoch: 6| Step: 3
Training loss: 3.1780019130520976
Validation loss: 2.745469970228498

Epoch: 6| Step: 4
Training loss: 2.7069928495427518
Validation loss: 2.744277976705629

Epoch: 6| Step: 5
Training loss: 3.1569917015085034
Validation loss: 2.7420662010927135

Epoch: 6| Step: 6
Training loss: 3.0951517955919945
Validation loss: 2.746082902022569

Epoch: 6| Step: 7
Training loss: 3.103643915250804
Validation loss: 2.7522795794677353

Epoch: 6| Step: 8
Training loss: 3.3609054982441027
Validation loss: 2.7539950602359764

Epoch: 6| Step: 9
Training loss: 3.1556589309642162
Validation loss: 2.746325128460898

Epoch: 6| Step: 10
Training loss: 2.836099246958511
Validation loss: 2.7422215035679813

Epoch: 6| Step: 11
Training loss: 3.2882561861924193
Validation loss: 2.733202474204377

Epoch: 6| Step: 12
Training loss: 3.006635638779645
Validation loss: 2.7314537595774273

Epoch: 6| Step: 13
Training loss: 3.049173280580709
Validation loss: 2.7287688357920548

Epoch: 17| Step: 0
Training loss: 3.1950328303457702
Validation loss: 2.7268259791060725

Epoch: 6| Step: 1
Training loss: 2.8596192969517
Validation loss: 2.728102368394352

Epoch: 6| Step: 2
Training loss: 3.302190319618544
Validation loss: 2.7280759960853884

Epoch: 6| Step: 3
Training loss: 3.2464304174465632
Validation loss: 2.7261232322603517

Epoch: 6| Step: 4
Training loss: 2.583899856303883
Validation loss: 2.7214328766065785

Epoch: 6| Step: 5
Training loss: 3.3600273031306163
Validation loss: 2.7229298657615066

Epoch: 6| Step: 6
Training loss: 2.560289499483797
Validation loss: 2.7224928839442777

Epoch: 6| Step: 7
Training loss: 3.4062178024030154
Validation loss: 2.7235919371319532

Epoch: 6| Step: 8
Training loss: 3.453951499381977
Validation loss: 2.7208639782158133

Epoch: 6| Step: 9
Training loss: 2.8992872611945173
Validation loss: 2.719083166589059

Epoch: 6| Step: 10
Training loss: 3.003871168469969
Validation loss: 2.7167483061267834

Epoch: 6| Step: 11
Training loss: 3.031359483767014
Validation loss: 2.715482120528262

Epoch: 6| Step: 12
Training loss: 2.9170747380665136
Validation loss: 2.714262658808572

Epoch: 6| Step: 13
Training loss: 3.2390169750497826
Validation loss: 2.7108958733671904

Epoch: 18| Step: 0
Training loss: 3.142616058367235
Validation loss: 2.708816550211038

Epoch: 6| Step: 1
Training loss: 3.2673965832339524
Validation loss: 2.7099842034837507

Epoch: 6| Step: 2
Training loss: 3.387949648360232
Validation loss: 2.7123602533084155

Epoch: 6| Step: 3
Training loss: 2.62467155218247
Validation loss: 2.712075101424741

Epoch: 6| Step: 4
Training loss: 3.034274922065128
Validation loss: 2.723941119103619

Epoch: 6| Step: 5
Training loss: 3.202356013590738
Validation loss: 2.715849633797578

Epoch: 6| Step: 6
Training loss: 2.6226689115371498
Validation loss: 2.7053416553387857

Epoch: 6| Step: 7
Training loss: 2.797254142423367
Validation loss: 2.70742774065905

Epoch: 6| Step: 8
Training loss: 2.2644222881908247
Validation loss: 2.727464956186629

Epoch: 6| Step: 9
Training loss: 3.2847155480634016
Validation loss: 2.7400692398461217

Epoch: 6| Step: 10
Training loss: 3.0013527998980005
Validation loss: 2.730627437546123

Epoch: 6| Step: 11
Training loss: 3.4568483465915896
Validation loss: 2.7077608991271496

Epoch: 6| Step: 12
Training loss: 3.400290218757414
Validation loss: 2.698172847209316

Epoch: 6| Step: 13
Training loss: 3.1588562129119677
Validation loss: 2.7127845067918397

Epoch: 19| Step: 0
Training loss: 2.627308874610563
Validation loss: 2.7059660300218296

Epoch: 6| Step: 1
Training loss: 2.3243268669049773
Validation loss: 2.7042552020421966

Epoch: 6| Step: 2
Training loss: 3.2016681614610345
Validation loss: 2.703741192700205

Epoch: 6| Step: 3
Training loss: 2.893014281241924
Validation loss: 2.7001492743509834

Epoch: 6| Step: 4
Training loss: 3.3574061102105883
Validation loss: 2.6993930103217143

Epoch: 6| Step: 5
Training loss: 3.352180050595995
Validation loss: 2.6982159337919387

Epoch: 6| Step: 6
Training loss: 3.513620305173253
Validation loss: 2.695166892454848

Epoch: 6| Step: 7
Training loss: 2.6442371469700867
Validation loss: 2.6939820874783416

Epoch: 6| Step: 8
Training loss: 2.87627581608413
Validation loss: 2.695405246731472

Epoch: 6| Step: 9
Training loss: 3.4348672668487703
Validation loss: 2.6967100529575254

Epoch: 6| Step: 10
Training loss: 2.7973172141896523
Validation loss: 2.7022608136059407

Epoch: 6| Step: 11
Training loss: 3.3887467345837967
Validation loss: 2.74834234910854

Epoch: 6| Step: 12
Training loss: 3.358586276414981
Validation loss: 2.792935839745316

Epoch: 6| Step: 13
Training loss: 2.7133844858482536
Validation loss: 2.719717423883618

Epoch: 20| Step: 0
Training loss: 3.241620191095476
Validation loss: 2.695090453953089

Epoch: 6| Step: 1
Training loss: 2.8109955896691052
Validation loss: 2.6930043637822743

Epoch: 6| Step: 2
Training loss: 2.494301213506735
Validation loss: 2.6924416253333474

Epoch: 6| Step: 3
Training loss: 3.040167678675854
Validation loss: 2.692910923180434

Epoch: 6| Step: 4
Training loss: 2.9030291029219994
Validation loss: 2.6948240413287823

Epoch: 6| Step: 5
Training loss: 3.0456708044548884
Validation loss: 2.707509242181509

Epoch: 6| Step: 6
Training loss: 3.6739729711278666
Validation loss: 2.701208351871322

Epoch: 6| Step: 7
Training loss: 2.7163594577325885
Validation loss: 2.6927297046295906

Epoch: 6| Step: 8
Training loss: 3.079762444438266
Validation loss: 2.6858607856996617

Epoch: 6| Step: 9
Training loss: 3.035022079663977
Validation loss: 2.6835677618572196

Epoch: 6| Step: 10
Training loss: 3.5050682429092834
Validation loss: 2.685480580575313

Epoch: 6| Step: 11
Training loss: 2.8139494657716844
Validation loss: 2.687105871568089

Epoch: 6| Step: 12
Training loss: 3.7192586342594116
Validation loss: 2.6878126725175755

Epoch: 6| Step: 13
Training loss: 1.402806027865505
Validation loss: 2.6936929372423255

Epoch: 21| Step: 0
Training loss: 2.9029939521308683
Validation loss: 2.717334474524877

Epoch: 6| Step: 1
Training loss: 2.6439908037473
Validation loss: 2.7222773576563015

Epoch: 6| Step: 2
Training loss: 2.8894880378556067
Validation loss: 2.7006480177665844

Epoch: 6| Step: 3
Training loss: 3.2451611222292978
Validation loss: 2.692900557827195

Epoch: 6| Step: 4
Training loss: 3.263931930654991
Validation loss: 2.684741450046282

Epoch: 6| Step: 5
Training loss: 2.651215573185804
Validation loss: 2.6832400235101277

Epoch: 6| Step: 6
Training loss: 2.7240512071073244
Validation loss: 2.679609390546346

Epoch: 6| Step: 7
Training loss: 3.1807160834420283
Validation loss: 2.6811790375264017

Epoch: 6| Step: 8
Training loss: 3.6832572969439323
Validation loss: 2.6820493495279747

Epoch: 6| Step: 9
Training loss: 2.985703097913723
Validation loss: 2.679488846632451

Epoch: 6| Step: 10
Training loss: 3.4137809165915107
Validation loss: 2.6792535429581594

Epoch: 6| Step: 11
Training loss: 3.097375922007835
Validation loss: 2.6794069903256283

Epoch: 6| Step: 12
Training loss: 2.743010307829455
Validation loss: 2.679287209472954

Epoch: 6| Step: 13
Training loss: 2.940960732569814
Validation loss: 2.6783070924788746

Epoch: 22| Step: 0
Training loss: 2.7877337712679404
Validation loss: 2.675541820132922

Epoch: 6| Step: 1
Training loss: 2.9179792084819267
Validation loss: 2.67767272209505

Epoch: 6| Step: 2
Training loss: 2.440382988686351
Validation loss: 2.679458396462608

Epoch: 6| Step: 3
Training loss: 2.7980446527502343
Validation loss: 2.687797602406474

Epoch: 6| Step: 4
Training loss: 3.147777100016251
Validation loss: 2.7338119785058628

Epoch: 6| Step: 5
Training loss: 3.369847214175623
Validation loss: 2.7515913720753913

Epoch: 6| Step: 6
Training loss: 3.375626541191022
Validation loss: 2.776992795292556

Epoch: 6| Step: 7
Training loss: 3.445487296931723
Validation loss: 2.77593219180059

Epoch: 6| Step: 8
Training loss: 3.405436567420054
Validation loss: 2.750486962840257

Epoch: 6| Step: 9
Training loss: 3.030722188714838
Validation loss: 2.7412345573637817

Epoch: 6| Step: 10
Training loss: 2.7015531523208
Validation loss: 2.7419627248000795

Epoch: 6| Step: 11
Training loss: 2.9984969506425543
Validation loss: 2.7529888262474373

Epoch: 6| Step: 12
Training loss: 2.9686473627919865
Validation loss: 2.750001713443644

Epoch: 6| Step: 13
Training loss: 3.6731267865007697
Validation loss: 2.7399537857460126

Epoch: 23| Step: 0
Training loss: 3.5315424705175693
Validation loss: 2.732411092837633

Epoch: 6| Step: 1
Training loss: 3.200609959643557
Validation loss: 2.7318588957900034

Epoch: 6| Step: 2
Training loss: 2.885562071367102
Validation loss: 2.7245707113641195

Epoch: 6| Step: 3
Training loss: 3.634122222742926
Validation loss: 2.7219941959164764

Epoch: 6| Step: 4
Training loss: 3.145385626119556
Validation loss: 2.720904020202079

Epoch: 6| Step: 5
Training loss: 2.385611369309175
Validation loss: 2.7209478350590963

Epoch: 6| Step: 6
Training loss: 2.97528401149128
Validation loss: 2.7197687562106454

Epoch: 6| Step: 7
Training loss: 2.8408973554889005
Validation loss: 2.7208885897196273

Epoch: 6| Step: 8
Training loss: 2.9261029503337963
Validation loss: 2.729671003015697

Epoch: 6| Step: 9
Training loss: 2.4989900456322243
Validation loss: 2.7186571679858265

Epoch: 6| Step: 10
Training loss: 2.891953611474079
Validation loss: 2.7195221140832375

Epoch: 6| Step: 11
Training loss: 3.5507130296320524
Validation loss: 2.7202435244192964

Epoch: 6| Step: 12
Training loss: 2.9029124795018295
Validation loss: 2.7158485576883313

Epoch: 6| Step: 13
Training loss: 3.296029655952738
Validation loss: 2.716903414911217

Epoch: 24| Step: 0
Training loss: 3.045282192089194
Validation loss: 2.7123508204987434

Epoch: 6| Step: 1
Training loss: 3.2014959891593673
Validation loss: 2.708723975911851

Epoch: 6| Step: 2
Training loss: 3.156933700991526
Validation loss: 2.7041862349304084

Epoch: 6| Step: 3
Training loss: 3.288561277640183
Validation loss: 2.7059140369869903

Epoch: 6| Step: 4
Training loss: 2.9760539904588383
Validation loss: 2.7027963541304607

Epoch: 6| Step: 5
Training loss: 2.990743343359575
Validation loss: 2.7025387946520287

Epoch: 6| Step: 6
Training loss: 3.7783996936527395
Validation loss: 2.702245669431133

Epoch: 6| Step: 7
Training loss: 2.8096966653733126
Validation loss: 2.698749991436894

Epoch: 6| Step: 8
Training loss: 2.110960865809108
Validation loss: 2.6992857811802415

Epoch: 6| Step: 9
Training loss: 2.8666818781012964
Validation loss: 2.703847691432261

Epoch: 6| Step: 10
Training loss: 2.9432553663400087
Validation loss: 2.7030730367276727

Epoch: 6| Step: 11
Training loss: 3.4064535377656413
Validation loss: 2.701292816990639

Epoch: 6| Step: 12
Training loss: 2.6396897143750606
Validation loss: 2.6994515925496665

Epoch: 6| Step: 13
Training loss: 3.246899813427803
Validation loss: 2.699372300865209

Epoch: 25| Step: 0
Training loss: 2.9040944298873335
Validation loss: 2.698047207336292

Epoch: 6| Step: 1
Training loss: 2.9482132365980838
Validation loss: 2.6963335031570885

Epoch: 6| Step: 2
Training loss: 3.415104408064409
Validation loss: 2.6975208340034476

Epoch: 6| Step: 3
Training loss: 2.8086372128069623
Validation loss: 2.6952825757720067

Epoch: 6| Step: 4
Training loss: 3.2188590318305144
Validation loss: 2.696026004219881

Epoch: 6| Step: 5
Training loss: 2.662487828759684
Validation loss: 2.697788914123104

Epoch: 6| Step: 6
Training loss: 3.7389500895594736
Validation loss: 2.699086581331969

Epoch: 6| Step: 7
Training loss: 3.193561699200302
Validation loss: 2.695292641862452

Epoch: 6| Step: 8
Training loss: 3.3633949535258747
Validation loss: 2.692770280175242

Epoch: 6| Step: 9
Training loss: 2.8030871232449606
Validation loss: 2.6950014871523975

Epoch: 6| Step: 10
Training loss: 2.5760330498275272
Validation loss: 2.6899029066871547

Epoch: 6| Step: 11
Training loss: 3.003589390188598
Validation loss: 2.687972413362009

Epoch: 6| Step: 12
Training loss: 2.7090407890270956
Validation loss: 2.6942057578016336

Epoch: 6| Step: 13
Training loss: 2.8846512386343495
Validation loss: 2.696326052299257

Epoch: 26| Step: 0
Training loss: 3.230851027392946
Validation loss: 2.709205152664484

Epoch: 6| Step: 1
Training loss: 2.856623258346209
Validation loss: 2.7147979602624632

Epoch: 6| Step: 2
Training loss: 3.2640523089536932
Validation loss: 2.737119314204478

Epoch: 6| Step: 3
Training loss: 3.6246656066301752
Validation loss: 2.6942728223553636

Epoch: 6| Step: 4
Training loss: 2.73501875792492
Validation loss: 2.6892583750931407

Epoch: 6| Step: 5
Training loss: 2.906469193262973
Validation loss: 2.685158944519366

Epoch: 6| Step: 6
Training loss: 3.0451555144086804
Validation loss: 2.6856869875396763

Epoch: 6| Step: 7
Training loss: 2.9519783498492185
Validation loss: 2.6882565638472893

Epoch: 6| Step: 8
Training loss: 2.6353041633646894
Validation loss: 2.6842511842583336

Epoch: 6| Step: 9
Training loss: 3.2362158507795664
Validation loss: 2.6902880733487518

Epoch: 6| Step: 10
Training loss: 3.766054374306342
Validation loss: 2.6871410701581917

Epoch: 6| Step: 11
Training loss: 2.6809055240465907
Validation loss: 2.6649453291748997

Epoch: 6| Step: 12
Training loss: 2.5526664742368177
Validation loss: 2.6544775630854502

Epoch: 6| Step: 13
Training loss: 2.5613593377251664
Validation loss: 2.6513488547716166

Epoch: 27| Step: 0
Training loss: 3.15272551804604
Validation loss: 2.6855994818970736

Epoch: 6| Step: 1
Training loss: 3.091840829253657
Validation loss: 2.6657995899213365

Epoch: 6| Step: 2
Training loss: 2.165012192548642
Validation loss: 2.64284520634122

Epoch: 6| Step: 3
Training loss: 3.0772319601981963
Validation loss: 2.6599295266270384

Epoch: 6| Step: 4
Training loss: 3.25362135795147
Validation loss: 2.6759107816604577

Epoch: 6| Step: 5
Training loss: 2.417700929861856
Validation loss: 2.659710612568424

Epoch: 6| Step: 6
Training loss: 3.4326380244744525
Validation loss: 2.650630865348335

Epoch: 6| Step: 7
Training loss: 3.3694935843195353
Validation loss: 2.6433072274065212

Epoch: 6| Step: 8
Training loss: 2.7484336206735165
Validation loss: 2.640562028225658

Epoch: 6| Step: 9
Training loss: 3.2180243109240556
Validation loss: 2.6373645886316757

Epoch: 6| Step: 10
Training loss: 2.825252359646996
Validation loss: 2.6390972092644716

Epoch: 6| Step: 11
Training loss: 2.813007902273286
Validation loss: 2.6382689149464547

Epoch: 6| Step: 12
Training loss: 3.4174786199920884
Validation loss: 2.638521392814203

Epoch: 6| Step: 13
Training loss: 3.0096300058672987
Validation loss: 2.6358354556667996

Epoch: 28| Step: 0
Training loss: 3.40573984227965
Validation loss: 2.6323769567806097

Epoch: 6| Step: 1
Training loss: 3.2096826927721764
Validation loss: 2.6312541106295253

Epoch: 6| Step: 2
Training loss: 3.1491766504508174
Validation loss: 2.6322524227614306

Epoch: 6| Step: 3
Training loss: 3.347184315981689
Validation loss: 2.6321471023327363

Epoch: 6| Step: 4
Training loss: 2.5745180734550837
Validation loss: 2.6291638227287835

Epoch: 6| Step: 5
Training loss: 2.7081240255220704
Validation loss: 2.6353312130793514

Epoch: 6| Step: 6
Training loss: 2.8357690177870993
Validation loss: 2.6672576921012476

Epoch: 6| Step: 7
Training loss: 2.6335183847168415
Validation loss: 2.6404173938633755

Epoch: 6| Step: 8
Training loss: 3.145138510123802
Validation loss: 2.637937074437448

Epoch: 6| Step: 9
Training loss: 3.3036031183910053
Validation loss: 2.636755636269395

Epoch: 6| Step: 10
Training loss: 3.4202316727722657
Validation loss: 2.6325389356857585

Epoch: 6| Step: 11
Training loss: 2.5440692073357334
Validation loss: 2.6319843931390885

Epoch: 6| Step: 12
Training loss: 2.641020795966318
Validation loss: 2.6395592249555158

Epoch: 6| Step: 13
Training loss: 2.735145591054772
Validation loss: 2.645732349318957

Epoch: 29| Step: 0
Training loss: 3.101357710296701
Validation loss: 2.6369976194903266

Epoch: 6| Step: 1
Training loss: 2.5972935014577856
Validation loss: 2.6386894456903796

Epoch: 6| Step: 2
Training loss: 3.2900118148730706
Validation loss: 2.6546341364729362

Epoch: 6| Step: 3
Training loss: 2.7512693076732284
Validation loss: 2.680809126602452

Epoch: 6| Step: 4
Training loss: 3.0476164086932154
Validation loss: 2.6828373733898196

Epoch: 6| Step: 5
Training loss: 3.3384702836537077
Validation loss: 2.6607555900637156

Epoch: 6| Step: 6
Training loss: 2.7067841916650472
Validation loss: 2.65551708709762

Epoch: 6| Step: 7
Training loss: 3.4594389898348616
Validation loss: 2.639892148284961

Epoch: 6| Step: 8
Training loss: 2.8387643895861663
Validation loss: 2.642472096547308

Epoch: 6| Step: 9
Training loss: 2.8668438864051446
Validation loss: 2.641073446245428

Epoch: 6| Step: 10
Training loss: 2.157363161983421
Validation loss: 2.647986865899187

Epoch: 6| Step: 11
Training loss: 3.1847788845662586
Validation loss: 2.6585259335547766

Epoch: 6| Step: 12
Training loss: 3.785098426778732
Validation loss: 2.6580650946729696

Epoch: 6| Step: 13
Training loss: 2.4544501157669867
Validation loss: 2.6465052512998746

Epoch: 30| Step: 0
Training loss: 2.8705182179848143
Validation loss: 2.6485372274032772

Epoch: 6| Step: 1
Training loss: 3.1542669430661885
Validation loss: 2.6676672345303345

Epoch: 6| Step: 2
Training loss: 3.2985621469890223
Validation loss: 2.6995426310920543

Epoch: 6| Step: 3
Training loss: 2.964078098189717
Validation loss: 2.658080812695825

Epoch: 6| Step: 4
Training loss: 2.9707076193670803
Validation loss: 2.634616129213978

Epoch: 6| Step: 5
Training loss: 2.4461670378747766
Validation loss: 2.6313332891519283

Epoch: 6| Step: 6
Training loss: 2.7311603941720173
Validation loss: 2.6256062685986223

Epoch: 6| Step: 7
Training loss: 2.842227402417981
Validation loss: 2.623725513355968

Epoch: 6| Step: 8
Training loss: 3.3371368324912196
Validation loss: 2.632874062196543

Epoch: 6| Step: 9
Training loss: 2.526612826136894
Validation loss: 2.6312478984617527

Epoch: 6| Step: 10
Training loss: 3.3679321598550986
Validation loss: 2.63631407506259

Epoch: 6| Step: 11
Training loss: 3.010117002221912
Validation loss: 2.631386699306216

Epoch: 6| Step: 12
Training loss: 3.030352272731767
Validation loss: 2.6287231586341604

Epoch: 6| Step: 13
Training loss: 3.5121958645054825
Validation loss: 2.6253299163992527

Epoch: 31| Step: 0
Training loss: 3.8764585395720403
Validation loss: 2.6238538277975683

Epoch: 6| Step: 1
Training loss: 2.988879893059726
Validation loss: 2.622546495270451

Epoch: 6| Step: 2
Training loss: 3.0439454691510224
Validation loss: 2.618273966705067

Epoch: 6| Step: 3
Training loss: 3.5782446695497407
Validation loss: 2.627235076334985

Epoch: 6| Step: 4
Training loss: 2.191443023101111
Validation loss: 2.629785510841165

Epoch: 6| Step: 5
Training loss: 3.012274110801259
Validation loss: 2.6319990698330287

Epoch: 6| Step: 6
Training loss: 2.4759679616171018
Validation loss: 2.6227851954425434

Epoch: 6| Step: 7
Training loss: 3.0827561602928055
Validation loss: 2.624520529043258

Epoch: 6| Step: 8
Training loss: 2.6782295553836617
Validation loss: 2.6247337370341657

Epoch: 6| Step: 9
Training loss: 3.4091522731460064
Validation loss: 2.659663408076935

Epoch: 6| Step: 10
Training loss: 2.5338976164670317
Validation loss: 2.6467453464556447

Epoch: 6| Step: 11
Training loss: 2.618811533348379
Validation loss: 2.673158485238373

Epoch: 6| Step: 12
Training loss: 2.8331655190829403
Validation loss: 2.6757717792585

Epoch: 6| Step: 13
Training loss: 3.0996753707234617
Validation loss: 2.679895735466309

Epoch: 32| Step: 0
Training loss: 2.750430333539339
Validation loss: 2.654918150004257

Epoch: 6| Step: 1
Training loss: 3.306067933692522
Validation loss: 2.63238936408597

Epoch: 6| Step: 2
Training loss: 2.970166641338384
Validation loss: 2.615132101238222

Epoch: 6| Step: 3
Training loss: 2.9819319546852587
Validation loss: 2.6108445024739626

Epoch: 6| Step: 4
Training loss: 3.4258387353090978
Validation loss: 2.6137692061077433

Epoch: 6| Step: 5
Training loss: 2.8219692615805836
Validation loss: 2.614626584841071

Epoch: 6| Step: 6
Training loss: 2.8893941372240324
Validation loss: 2.61746426231527

Epoch: 6| Step: 7
Training loss: 3.261392140739704
Validation loss: 2.6110023443008763

Epoch: 6| Step: 8
Training loss: 2.97017290247852
Validation loss: 2.616774801824948

Epoch: 6| Step: 9
Training loss: 2.7423692083337166
Validation loss: 2.615930437616624

Epoch: 6| Step: 10
Training loss: 2.9132280152035634
Validation loss: 2.615747059858725

Epoch: 6| Step: 11
Training loss: 2.840496843424559
Validation loss: 2.6156842281536665

Epoch: 6| Step: 12
Training loss: 2.865954391201774
Validation loss: 2.6121070455990947

Epoch: 6| Step: 13
Training loss: 2.988079547931351
Validation loss: 2.6096412267927995

Epoch: 33| Step: 0
Training loss: 2.961674017380963
Validation loss: 2.612502859068602

Epoch: 6| Step: 1
Training loss: 2.7502112740941453
Validation loss: 2.612548838305775

Epoch: 6| Step: 2
Training loss: 2.457278386288071
Validation loss: 2.6091803658107837

Epoch: 6| Step: 3
Training loss: 2.9238362793181216
Validation loss: 2.6097545174626076

Epoch: 6| Step: 4
Training loss: 3.4497324300750236
Validation loss: 2.616934974081695

Epoch: 6| Step: 5
Training loss: 3.114787083386134
Validation loss: 2.6135422959901975

Epoch: 6| Step: 6
Training loss: 3.1088422002491223
Validation loss: 2.6194648875662216

Epoch: 6| Step: 7
Training loss: 2.5830673470513843
Validation loss: 2.6284025702876663

Epoch: 6| Step: 8
Training loss: 3.5327947158062156
Validation loss: 2.6402187123443888

Epoch: 6| Step: 9
Training loss: 2.4128614481019866
Validation loss: 2.6450941684194245

Epoch: 6| Step: 10
Training loss: 3.0406700138786484
Validation loss: 2.6550491987120624

Epoch: 6| Step: 11
Training loss: 2.738776103756711
Validation loss: 2.6574214931292883

Epoch: 6| Step: 12
Training loss: 3.1991773143874975
Validation loss: 2.6454546622466744

Epoch: 6| Step: 13
Training loss: 3.342017464684009
Validation loss: 2.6407358129678773

Epoch: 34| Step: 0
Training loss: 2.8150493511799857
Validation loss: 2.610398549932811

Epoch: 6| Step: 1
Training loss: 3.3436460389705336
Validation loss: 2.6046584659642287

Epoch: 6| Step: 2
Training loss: 3.2075221700043377
Validation loss: 2.6071715832050364

Epoch: 6| Step: 3
Training loss: 2.6845521062439666
Validation loss: 2.6064885521698455

Epoch: 6| Step: 4
Training loss: 2.697219660406689
Validation loss: 2.6137252355168714

Epoch: 6| Step: 5
Training loss: 2.9705271972890577
Validation loss: 2.6090883428273908

Epoch: 6| Step: 6
Training loss: 2.5527368033294686
Validation loss: 2.6042651591390067

Epoch: 6| Step: 7
Training loss: 3.3535193219439434
Validation loss: 2.6003819264397854

Epoch: 6| Step: 8
Training loss: 2.7768913147331373
Validation loss: 2.5943514861241215

Epoch: 6| Step: 9
Training loss: 2.690140868260018
Validation loss: 2.5972756201233897

Epoch: 6| Step: 10
Training loss: 3.5969481459934642
Validation loss: 2.5994321858992997

Epoch: 6| Step: 11
Training loss: 2.8542618190376667
Validation loss: 2.595707239537722

Epoch: 6| Step: 12
Training loss: 2.883591461387435
Validation loss: 2.596194852984196

Epoch: 6| Step: 13
Training loss: 3.026852751261585
Validation loss: 2.594100323594653

Epoch: 35| Step: 0
Training loss: 2.6278733467518185
Validation loss: 2.5992696627688336

Epoch: 6| Step: 1
Training loss: 2.317079391581322
Validation loss: 2.5999558445042066

Epoch: 6| Step: 2
Training loss: 3.198947173016002
Validation loss: 2.6034583827102544

Epoch: 6| Step: 3
Training loss: 3.1001692941030834
Validation loss: 2.6013727754220137

Epoch: 6| Step: 4
Training loss: 3.179955773435898
Validation loss: 2.5961407701805572

Epoch: 6| Step: 5
Training loss: 3.2253448183702305
Validation loss: 2.5962228848699316

Epoch: 6| Step: 6
Training loss: 3.0344820390673535
Validation loss: 2.5907876198979887

Epoch: 6| Step: 7
Training loss: 3.188958526217234
Validation loss: 2.5917003967962264

Epoch: 6| Step: 8
Training loss: 2.640704543140216
Validation loss: 2.585547512195106

Epoch: 6| Step: 9
Training loss: 3.230810735421943
Validation loss: 2.59006486147194

Epoch: 6| Step: 10
Training loss: 2.870852588723712
Validation loss: 2.595595603476489

Epoch: 6| Step: 11
Training loss: 3.2860604038735004
Validation loss: 2.615504645509697

Epoch: 6| Step: 12
Training loss: 2.656521233566954
Validation loss: 2.625055097674612

Epoch: 6| Step: 13
Training loss: 2.571153311907425
Validation loss: 2.627774497539905

Epoch: 36| Step: 0
Training loss: 2.5689487723784956
Validation loss: 2.6126206748282734

Epoch: 6| Step: 1
Training loss: 2.9967061079723174
Validation loss: 2.595498079230332

Epoch: 6| Step: 2
Training loss: 2.6544482235007596
Validation loss: 2.5852497929843854

Epoch: 6| Step: 3
Training loss: 2.7214720680699913
Validation loss: 2.579586139293901

Epoch: 6| Step: 4
Training loss: 2.4957705961652126
Validation loss: 2.580578891290366

Epoch: 6| Step: 5
Training loss: 3.467318127626732
Validation loss: 2.580846421728164

Epoch: 6| Step: 6
Training loss: 3.256382763402089
Validation loss: 2.5872852211529973

Epoch: 6| Step: 7
Training loss: 2.8287895644215517
Validation loss: 2.5893068375880874

Epoch: 6| Step: 8
Training loss: 3.4444656542326673
Validation loss: 2.589064646870064

Epoch: 6| Step: 9
Training loss: 3.2761311157500166
Validation loss: 2.5826919596718496

Epoch: 6| Step: 10
Training loss: 3.2550199326990406
Validation loss: 2.585325972726629

Epoch: 6| Step: 11
Training loss: 2.3826815209583008
Validation loss: 2.579108454923576

Epoch: 6| Step: 12
Training loss: 2.36680312860207
Validation loss: 2.5769602163263077

Epoch: 6| Step: 13
Training loss: 3.342217352592469
Validation loss: 2.581168144310887

Epoch: 37| Step: 0
Training loss: 2.2446165318922833
Validation loss: 2.583066982811489

Epoch: 6| Step: 1
Training loss: 2.8240556471964062
Validation loss: 2.58008068061271

Epoch: 6| Step: 2
Training loss: 3.1788529934175576
Validation loss: 2.5798861208972155

Epoch: 6| Step: 3
Training loss: 3.1583613519423896
Validation loss: 2.5832146793655384

Epoch: 6| Step: 4
Training loss: 2.287149508781356
Validation loss: 2.579506362255194

Epoch: 6| Step: 5
Training loss: 3.2573918132719157
Validation loss: 2.5773000382344926

Epoch: 6| Step: 6
Training loss: 2.71901578809806
Validation loss: 2.5774443293723754

Epoch: 6| Step: 7
Training loss: 3.520633097415323
Validation loss: 2.578753923487485

Epoch: 6| Step: 8
Training loss: 3.5636194712197793
Validation loss: 2.578109360812456

Epoch: 6| Step: 9
Training loss: 3.032704584401923
Validation loss: 2.5901624418243743

Epoch: 6| Step: 10
Training loss: 2.7741196344234598
Validation loss: 2.6157965671369947

Epoch: 6| Step: 11
Training loss: 2.5576414243315155
Validation loss: 2.6240174729786303

Epoch: 6| Step: 12
Training loss: 3.043275398992633
Validation loss: 2.627530239438537

Epoch: 6| Step: 13
Training loss: 2.2720769107722467
Validation loss: 2.6217442111570137

Epoch: 38| Step: 0
Training loss: 3.4304516751258185
Validation loss: 2.624733406901407

Epoch: 6| Step: 1
Training loss: 3.170081622880953
Validation loss: 2.582897690061388

Epoch: 6| Step: 2
Training loss: 3.0792452714838365
Validation loss: 2.5749340756200305

Epoch: 6| Step: 3
Training loss: 2.8557143829777507
Validation loss: 2.576682701155933

Epoch: 6| Step: 4
Training loss: 3.4792179553121425
Validation loss: 2.5734351694649997

Epoch: 6| Step: 5
Training loss: 3.3026439940878536
Validation loss: 2.577530726717751

Epoch: 6| Step: 6
Training loss: 3.046071107892253
Validation loss: 2.5822326413820074

Epoch: 6| Step: 7
Training loss: 2.9655509979694528
Validation loss: 2.580859606207083

Epoch: 6| Step: 8
Training loss: 2.658175141063208
Validation loss: 2.5831152803749626

Epoch: 6| Step: 9
Training loss: 2.8183469395353256
Validation loss: 2.5856903694677733

Epoch: 6| Step: 10
Training loss: 2.7941626497902132
Validation loss: 2.584742502788081

Epoch: 6| Step: 11
Training loss: 2.0787072764196597
Validation loss: 2.585324270128014

Epoch: 6| Step: 12
Training loss: 2.3832654178608466
Validation loss: 2.5828291023476693

Epoch: 6| Step: 13
Training loss: 3.079178528167082
Validation loss: 2.592288796078247

Epoch: 39| Step: 0
Training loss: 3.0113751602606675
Validation loss: 2.5988585197932386

Epoch: 6| Step: 1
Training loss: 2.60490811791806
Validation loss: 2.6169471225049623

Epoch: 6| Step: 2
Training loss: 2.5803893347036495
Validation loss: 2.6948210789159477

Epoch: 6| Step: 3
Training loss: 3.2502875567648095
Validation loss: 2.7306201286145626

Epoch: 6| Step: 4
Training loss: 3.661786444095041
Validation loss: 2.7428897547083264

Epoch: 6| Step: 5
Training loss: 2.712739636783283
Validation loss: 2.7076807988741547

Epoch: 6| Step: 6
Training loss: 3.3695633509712346
Validation loss: 2.6443462215306033

Epoch: 6| Step: 7
Training loss: 2.800733238670605
Validation loss: 2.6230745221933476

Epoch: 6| Step: 8
Training loss: 3.0943764716976814
Validation loss: 2.612347324787394

Epoch: 6| Step: 9
Training loss: 2.325527303643248
Validation loss: 2.6165389835621546

Epoch: 6| Step: 10
Training loss: 3.2126890728004183
Validation loss: 2.621299655239836

Epoch: 6| Step: 11
Training loss: 2.766533050604433
Validation loss: 2.6291947310671375

Epoch: 6| Step: 12
Training loss: 2.880216427194399
Validation loss: 2.648815300746421

Epoch: 6| Step: 13
Training loss: 3.366829341949196
Validation loss: 2.6590569583043533

Epoch: 40| Step: 0
Training loss: 2.5343004848377255
Validation loss: 2.6367727579034193

Epoch: 6| Step: 1
Training loss: 2.8696109186335383
Validation loss: 2.64295580885225

Epoch: 6| Step: 2
Training loss: 3.3961524735404853
Validation loss: 2.6314648226498303

Epoch: 6| Step: 3
Training loss: 2.830448608158306
Validation loss: 2.6338803733518237

Epoch: 6| Step: 4
Training loss: 2.727578047799171
Validation loss: 2.6368687108888835

Epoch: 6| Step: 5
Training loss: 2.6622526671816886
Validation loss: 2.647658219611159

Epoch: 6| Step: 6
Training loss: 3.116051641425612
Validation loss: 2.650962449491127

Epoch: 6| Step: 7
Training loss: 2.9509041322023206
Validation loss: 2.658058146577036

Epoch: 6| Step: 8
Training loss: 2.956245670759003
Validation loss: 2.6674181122319265

Epoch: 6| Step: 9
Training loss: 3.250799520890886
Validation loss: 2.679361787166764

Epoch: 6| Step: 10
Training loss: 3.2879258318794147
Validation loss: 2.6781609873042664

Epoch: 6| Step: 11
Training loss: 3.0856537893712783
Validation loss: 2.679285769433163

Epoch: 6| Step: 12
Training loss: 3.267409133873522
Validation loss: 2.6662199821701775

Epoch: 6| Step: 13
Training loss: 2.7776231584961293
Validation loss: 2.6611324155938343

Epoch: 41| Step: 0
Training loss: 3.21614888097127
Validation loss: 2.6583300269517123

Epoch: 6| Step: 1
Training loss: 2.5395974872080993
Validation loss: 2.6544796201954868

Epoch: 6| Step: 2
Training loss: 3.4167725306291628
Validation loss: 2.6532516978177774

Epoch: 6| Step: 3
Training loss: 2.483215829343583
Validation loss: 2.6489807882316105

Epoch: 6| Step: 4
Training loss: 2.881623640678733
Validation loss: 2.6517451808814974

Epoch: 6| Step: 5
Training loss: 3.3024893590277773
Validation loss: 2.6511427324192387

Epoch: 6| Step: 6
Training loss: 2.6921977303654288
Validation loss: 2.644621849704443

Epoch: 6| Step: 7
Training loss: 2.8419106372203697
Validation loss: 2.620231475214282

Epoch: 6| Step: 8
Training loss: 2.80569618384632
Validation loss: 2.612301195778869

Epoch: 6| Step: 9
Training loss: 2.801433918135615
Validation loss: 2.6050441151339934

Epoch: 6| Step: 10
Training loss: 3.0326861882425984
Validation loss: 2.6070835790169724

Epoch: 6| Step: 11
Training loss: 3.21345988972799
Validation loss: 2.6038946190935093

Epoch: 6| Step: 12
Training loss: 3.245924227955411
Validation loss: 2.603504636886103

Epoch: 6| Step: 13
Training loss: 2.9109472236737086
Validation loss: 2.603117096751103

Epoch: 42| Step: 0
Training loss: 2.824844565377444
Validation loss: 2.602282046353341

Epoch: 6| Step: 1
Training loss: 2.7085645332444104
Validation loss: 2.59904603002343

Epoch: 6| Step: 2
Training loss: 2.771115902902756
Validation loss: 2.600349401372492

Epoch: 6| Step: 3
Training loss: 3.1555383465376754
Validation loss: 2.5974194747139827

Epoch: 6| Step: 4
Training loss: 2.8101635022635865
Validation loss: 2.5979748567743166

Epoch: 6| Step: 5
Training loss: 2.969079410949284
Validation loss: 2.6087014926423246

Epoch: 6| Step: 6
Training loss: 2.5564804085231314
Validation loss: 2.61574423722762

Epoch: 6| Step: 7
Training loss: 3.0023910213007894
Validation loss: 2.6214978969078664

Epoch: 6| Step: 8
Training loss: 2.961334604493472
Validation loss: 2.6257201455550403

Epoch: 6| Step: 9
Training loss: 2.4790288635764837
Validation loss: 2.6274571801400772

Epoch: 6| Step: 10
Training loss: 3.526479283518473
Validation loss: 2.628233729923349

Epoch: 6| Step: 11
Training loss: 2.878316541960362
Validation loss: 2.624734802639917

Epoch: 6| Step: 12
Training loss: 3.299205950369589
Validation loss: 2.6099717237298443

Epoch: 6| Step: 13
Training loss: 3.512372084491065
Validation loss: 2.593774213503669

Epoch: 43| Step: 0
Training loss: 2.8975274232976997
Validation loss: 2.5914809878987204

Epoch: 6| Step: 1
Training loss: 2.654839803313206
Validation loss: 2.5894742500514774

Epoch: 6| Step: 2
Training loss: 3.4476327154936883
Validation loss: 2.5896059356831116

Epoch: 6| Step: 3
Training loss: 2.9911482876335773
Validation loss: 2.5886978036629076

Epoch: 6| Step: 4
Training loss: 3.5261295970657027
Validation loss: 2.5862802867485635

Epoch: 6| Step: 5
Training loss: 3.345096210185218
Validation loss: 2.5847998332479247

Epoch: 6| Step: 6
Training loss: 2.928530044794931
Validation loss: 2.575928934995347

Epoch: 6| Step: 7
Training loss: 2.870211054255711
Validation loss: 2.5768741669579045

Epoch: 6| Step: 8
Training loss: 2.8500181431778415
Validation loss: 2.5751316098251604

Epoch: 6| Step: 9
Training loss: 2.946278380822533
Validation loss: 2.5738840342560914

Epoch: 6| Step: 10
Training loss: 3.3705639826257743
Validation loss: 2.5743312802072196

Epoch: 6| Step: 11
Training loss: 2.2697055244176547
Validation loss: 2.5713585701868222

Epoch: 6| Step: 12
Training loss: 1.8479418543920003
Validation loss: 2.563248099698473

Epoch: 6| Step: 13
Training loss: 2.810932570363547
Validation loss: 2.56451058514533

Epoch: 44| Step: 0
Training loss: 3.082100561641413
Validation loss: 2.561779291030973

Epoch: 6| Step: 1
Training loss: 2.930913805847024
Validation loss: 2.5573065127239274

Epoch: 6| Step: 2
Training loss: 2.77009230339419
Validation loss: 2.5640486467822114

Epoch: 6| Step: 3
Training loss: 2.6581356760362698
Validation loss: 2.568989515693809

Epoch: 6| Step: 4
Training loss: 2.6756356526879848
Validation loss: 2.5772849466002152

Epoch: 6| Step: 5
Training loss: 3.739264571153137
Validation loss: 2.5830377233621076

Epoch: 6| Step: 6
Training loss: 2.3445310181436803
Validation loss: 2.556573458722885

Epoch: 6| Step: 7
Training loss: 2.6863777123895005
Validation loss: 2.545546811888972

Epoch: 6| Step: 8
Training loss: 3.0023983269723145
Validation loss: 2.540291717056634

Epoch: 6| Step: 9
Training loss: 3.052295733841361
Validation loss: 2.5416584697277185

Epoch: 6| Step: 10
Training loss: 3.204246064299084
Validation loss: 2.540832357046594

Epoch: 6| Step: 11
Training loss: 2.8064803234982536
Validation loss: 2.543411802262117

Epoch: 6| Step: 12
Training loss: 3.0849239954558456
Validation loss: 2.5528881545981736

Epoch: 6| Step: 13
Training loss: 2.537190753903201
Validation loss: 2.552011385303835

Epoch: 45| Step: 0
Training loss: 2.5653680707591375
Validation loss: 2.5530374323562692

Epoch: 6| Step: 1
Training loss: 2.8305843892956655
Validation loss: 2.55467525922167

Epoch: 6| Step: 2
Training loss: 3.3732960956262183
Validation loss: 2.551273813410417

Epoch: 6| Step: 3
Training loss: 2.5883807945280557
Validation loss: 2.5460369201572037

Epoch: 6| Step: 4
Training loss: 2.165432382800253
Validation loss: 2.546539019748315

Epoch: 6| Step: 5
Training loss: 3.3149724406251844
Validation loss: 2.5440014632667065

Epoch: 6| Step: 6
Training loss: 2.8665893928699404
Validation loss: 2.5470137103822417

Epoch: 6| Step: 7
Training loss: 3.3986817721568334
Validation loss: 2.5442102723779647

Epoch: 6| Step: 8
Training loss: 2.928412482969255
Validation loss: 2.5455253825541053

Epoch: 6| Step: 9
Training loss: 2.794698113121979
Validation loss: 2.545095121125627

Epoch: 6| Step: 10
Training loss: 3.0504780128985907
Validation loss: 2.544640826481657

Epoch: 6| Step: 11
Training loss: 3.2498218781003803
Validation loss: 2.543914122692703

Epoch: 6| Step: 12
Training loss: 2.6262990371214876
Validation loss: 2.5468322178573954

Epoch: 6| Step: 13
Training loss: 2.5851469646712495
Validation loss: 2.5589767213274484

Epoch: 46| Step: 0
Training loss: 2.5205745932043406
Validation loss: 2.554593502002649

Epoch: 6| Step: 1
Training loss: 3.1612041607931336
Validation loss: 2.549380210459228

Epoch: 6| Step: 2
Training loss: 3.2587624315288837
Validation loss: 2.550156578502254

Epoch: 6| Step: 3
Training loss: 3.0544361684289356
Validation loss: 2.5660955963062286

Epoch: 6| Step: 4
Training loss: 2.6279103630316523
Validation loss: 2.579805158666795

Epoch: 6| Step: 5
Training loss: 3.546294177388295
Validation loss: 2.584305837880553

Epoch: 6| Step: 6
Training loss: 2.502758316442329
Validation loss: 2.5822509803189804

Epoch: 6| Step: 7
Training loss: 2.355610351355013
Validation loss: 2.5695770325541694

Epoch: 6| Step: 8
Training loss: 2.6742146381922725
Validation loss: 2.564577210670771

Epoch: 6| Step: 9
Training loss: 3.216835119023572
Validation loss: 2.556070697464339

Epoch: 6| Step: 10
Training loss: 2.697719041417809
Validation loss: 2.550995323870237

Epoch: 6| Step: 11
Training loss: 2.8307449260835655
Validation loss: 2.550404755835362

Epoch: 6| Step: 12
Training loss: 3.1902724531770774
Validation loss: 2.555026250655857

Epoch: 6| Step: 13
Training loss: 2.5713170648043207
Validation loss: 2.550892573991188

Epoch: 47| Step: 0
Training loss: 2.9113658874429382
Validation loss: 2.5467860759141585

Epoch: 6| Step: 1
Training loss: 2.3185057107815186
Validation loss: 2.5447733018684677

Epoch: 6| Step: 2
Training loss: 2.6468819970552993
Validation loss: 2.5400442482360517

Epoch: 6| Step: 3
Training loss: 3.273682214152408
Validation loss: 2.5468688779558932

Epoch: 6| Step: 4
Training loss: 2.6563805043193693
Validation loss: 2.5425388494568124

Epoch: 6| Step: 5
Training loss: 2.5554395962635015
Validation loss: 2.545713511008718

Epoch: 6| Step: 6
Training loss: 2.818263019862979
Validation loss: 2.5475012711773948

Epoch: 6| Step: 7
Training loss: 3.3016473299782843
Validation loss: 2.562447255990139

Epoch: 6| Step: 8
Training loss: 3.5754656508434435
Validation loss: 2.5433467461001924

Epoch: 6| Step: 9
Training loss: 3.5413707085910255
Validation loss: 2.543308876039457

Epoch: 6| Step: 10
Training loss: 2.594965270881304
Validation loss: 2.542353601958466

Epoch: 6| Step: 11
Training loss: 2.4510094334246895
Validation loss: 2.5464265580686214

Epoch: 6| Step: 12
Training loss: 2.8129109400304464
Validation loss: 2.545578487253662

Epoch: 6| Step: 13
Training loss: 2.837934815285246
Validation loss: 2.5522290755532113

Epoch: 48| Step: 0
Training loss: 2.8572418093576037
Validation loss: 2.548754089157779

Epoch: 6| Step: 1
Training loss: 3.1154553947849313
Validation loss: 2.5388445996857323

Epoch: 6| Step: 2
Training loss: 2.4656314709557927
Validation loss: 2.5552754749891378

Epoch: 6| Step: 3
Training loss: 3.6488907264997055
Validation loss: 2.558425329909237

Epoch: 6| Step: 4
Training loss: 2.9616025313726704
Validation loss: 2.565927868436796

Epoch: 6| Step: 5
Training loss: 2.9830459910986566
Validation loss: 2.5879088089300795

Epoch: 6| Step: 6
Training loss: 3.053624897602649
Validation loss: 2.623883071766666

Epoch: 6| Step: 7
Training loss: 2.9388986058145643
Validation loss: 2.619903758420816

Epoch: 6| Step: 8
Training loss: 3.1960522977443584
Validation loss: 2.5835657855381533

Epoch: 6| Step: 9
Training loss: 3.193881061649277
Validation loss: 2.5567087982403165

Epoch: 6| Step: 10
Training loss: 2.5197015749114673
Validation loss: 2.5543029471641665

Epoch: 6| Step: 11
Training loss: 2.375160412641388
Validation loss: 2.543929085785942

Epoch: 6| Step: 12
Training loss: 2.7107828849212785
Validation loss: 2.543073530757085

Epoch: 6| Step: 13
Training loss: 2.381265106553747
Validation loss: 2.543859636860137

Epoch: 49| Step: 0
Training loss: 2.399362590705041
Validation loss: 2.545665347758473

Epoch: 6| Step: 1
Training loss: 3.156303027623466
Validation loss: 2.5455779706136195

Epoch: 6| Step: 2
Training loss: 2.7016139575476834
Validation loss: 2.542219577591995

Epoch: 6| Step: 3
Training loss: 2.7879422713642175
Validation loss: 2.5470267207300403

Epoch: 6| Step: 4
Training loss: 2.969704725441746
Validation loss: 2.5421317310661187

Epoch: 6| Step: 5
Training loss: 3.0448097467728537
Validation loss: 2.540837852936711

Epoch: 6| Step: 6
Training loss: 2.2859314215078
Validation loss: 2.542263252152276

Epoch: 6| Step: 7
Training loss: 3.061085276909117
Validation loss: 2.5415589635721583

Epoch: 6| Step: 8
Training loss: 3.035490236108616
Validation loss: 2.5460547213304685

Epoch: 6| Step: 9
Training loss: 3.611260916382111
Validation loss: 2.539539642053713

Epoch: 6| Step: 10
Training loss: 2.846841661611875
Validation loss: 2.542612331749628

Epoch: 6| Step: 11
Training loss: 2.4883897119954197
Validation loss: 2.5479525927391413

Epoch: 6| Step: 12
Training loss: 2.934107993168652
Validation loss: 2.5516750234245995

Epoch: 6| Step: 13
Training loss: 3.359769576209745
Validation loss: 2.564192614326909

Epoch: 50| Step: 0
Training loss: 2.68805263071533
Validation loss: 2.5635672727006376

Epoch: 6| Step: 1
Training loss: 2.738353080732483
Validation loss: 2.568939576402697

Epoch: 6| Step: 2
Training loss: 3.1884133021576697
Validation loss: 2.567205940580647

Epoch: 6| Step: 3
Training loss: 2.8251360700127197
Validation loss: 2.568729348315857

Epoch: 6| Step: 4
Training loss: 2.810544923910242
Validation loss: 2.569635015632142

Epoch: 6| Step: 5
Training loss: 2.9594423248141477
Validation loss: 2.5692223892405512

Epoch: 6| Step: 6
Training loss: 3.10731322975533
Validation loss: 2.556394010759041

Epoch: 6| Step: 7
Training loss: 2.8103622789448366
Validation loss: 2.562670904343484

Epoch: 6| Step: 8
Training loss: 3.065476508632155
Validation loss: 2.557566789591307

Epoch: 6| Step: 9
Training loss: 2.5902946160263203
Validation loss: 2.533307127690203

Epoch: 6| Step: 10
Training loss: 3.2076538819694482
Validation loss: 2.531683334393687

Epoch: 6| Step: 11
Training loss: 2.281086641498242
Validation loss: 2.531494523804813

Epoch: 6| Step: 12
Training loss: 3.404859766600146
Validation loss: 2.534785293496396

Epoch: 6| Step: 13
Training loss: 2.57553784577267
Validation loss: 2.5332747281273726

Epoch: 51| Step: 0
Training loss: 3.0162210616594156
Validation loss: 2.531799666908019

Epoch: 6| Step: 1
Training loss: 3.219842817841648
Validation loss: 2.536507122514486

Epoch: 6| Step: 2
Training loss: 3.0744414775971785
Validation loss: 2.5368641767031526

Epoch: 6| Step: 3
Training loss: 2.9139535182997554
Validation loss: 2.541712994676936

Epoch: 6| Step: 4
Training loss: 2.788637273092603
Validation loss: 2.59841001191453

Epoch: 6| Step: 5
Training loss: 2.9002801430977776
Validation loss: 2.602489364098093

Epoch: 6| Step: 6
Training loss: 3.1228543354012333
Validation loss: 2.5752718603456266

Epoch: 6| Step: 7
Training loss: 2.5379488806359825
Validation loss: 2.5574056176721807

Epoch: 6| Step: 8
Training loss: 3.068426198249918
Validation loss: 2.5553606605343213

Epoch: 6| Step: 9
Training loss: 2.945919065473426
Validation loss: 2.540006044817614

Epoch: 6| Step: 10
Training loss: 2.980400114656558
Validation loss: 2.546983486179898

Epoch: 6| Step: 11
Training loss: 2.6567552871314066
Validation loss: 2.5340133991477867

Epoch: 6| Step: 12
Training loss: 2.695984510597989
Validation loss: 2.5308320725786864

Epoch: 6| Step: 13
Training loss: 2.82101981045793
Validation loss: 2.5430760620635358

Epoch: 52| Step: 0
Training loss: 2.865031832639661
Validation loss: 2.561797300043254

Epoch: 6| Step: 1
Training loss: 2.897067093061398
Validation loss: 2.565531544395099

Epoch: 6| Step: 2
Training loss: 3.1285456569876753
Validation loss: 2.566133582648804

Epoch: 6| Step: 3
Training loss: 2.7626449995694777
Validation loss: 2.5663812068937846

Epoch: 6| Step: 4
Training loss: 3.1735291325512307
Validation loss: 2.559246644175806

Epoch: 6| Step: 5
Training loss: 2.4965600188650403
Validation loss: 2.5702842184466315

Epoch: 6| Step: 6
Training loss: 3.2523833119178316
Validation loss: 2.5612937224966807

Epoch: 6| Step: 7
Training loss: 3.19773642231869
Validation loss: 2.5581159127784696

Epoch: 6| Step: 8
Training loss: 2.6527955874055484
Validation loss: 2.5509508993587535

Epoch: 6| Step: 9
Training loss: 2.572924553451085
Validation loss: 2.54172880183187

Epoch: 6| Step: 10
Training loss: 3.0659544788124142
Validation loss: 2.5360685299432615

Epoch: 6| Step: 11
Training loss: 2.96128356038597
Validation loss: 2.5323909880477533

Epoch: 6| Step: 12
Training loss: 2.5549164182425463
Validation loss: 2.5318596618561826

Epoch: 6| Step: 13
Training loss: 2.696480053109766
Validation loss: 2.5372615402508067

Epoch: 53| Step: 0
Training loss: 3.4815807685341937
Validation loss: 2.5594654097984426

Epoch: 6| Step: 1
Training loss: 2.6865537885076716
Validation loss: 2.5601986611325005

Epoch: 6| Step: 2
Training loss: 2.740837786601195
Validation loss: 2.566670281570546

Epoch: 6| Step: 3
Training loss: 2.817597749600224
Validation loss: 2.5863127221049624

Epoch: 6| Step: 4
Training loss: 2.7305925638617152
Validation loss: 2.573628348136644

Epoch: 6| Step: 5
Training loss: 3.156928414433083
Validation loss: 2.5438178752885587

Epoch: 6| Step: 6
Training loss: 2.6814343511343623
Validation loss: 2.5492331894290485

Epoch: 6| Step: 7
Training loss: 3.1715367329439976
Validation loss: 2.5271404038928584

Epoch: 6| Step: 8
Training loss: 2.7484567820451127
Validation loss: 2.5212348079966476

Epoch: 6| Step: 9
Training loss: 2.549541177797518
Validation loss: 2.517816189396103

Epoch: 6| Step: 10
Training loss: 3.2891278838049076
Validation loss: 2.5236984621386505

Epoch: 6| Step: 11
Training loss: 2.1407314747413424
Validation loss: 2.5265470746150407

Epoch: 6| Step: 12
Training loss: 3.185689374495179
Validation loss: 2.5295631604582756

Epoch: 6| Step: 13
Training loss: 3.0741621349118975
Validation loss: 2.523579618774168

Epoch: 54| Step: 0
Training loss: 2.8939219874772872
Validation loss: 2.521573692167016

Epoch: 6| Step: 1
Training loss: 2.9818155388069703
Validation loss: 2.516339512877915

Epoch: 6| Step: 2
Training loss: 2.3345640093210003
Validation loss: 2.5240747583120284

Epoch: 6| Step: 3
Training loss: 3.1679952411037884
Validation loss: 2.533616407494705

Epoch: 6| Step: 4
Training loss: 2.5005051102581257
Validation loss: 2.5806235826202846

Epoch: 6| Step: 5
Training loss: 3.2647581273170623
Validation loss: 2.6225808565074376

Epoch: 6| Step: 6
Training loss: 2.6530445279879062
Validation loss: 2.6069511929860822

Epoch: 6| Step: 7
Training loss: 3.077793781255743
Validation loss: 2.5687173885276082

Epoch: 6| Step: 8
Training loss: 2.6222889842767763
Validation loss: 2.5582306660068483

Epoch: 6| Step: 9
Training loss: 3.163050360154195
Validation loss: 2.5492923954784295

Epoch: 6| Step: 10
Training loss: 2.7725637859577894
Validation loss: 2.5341916094777397

Epoch: 6| Step: 11
Training loss: 3.1745329746174624
Validation loss: 2.5277826439386453

Epoch: 6| Step: 12
Training loss: 3.211366499483724
Validation loss: 2.523844914724008

Epoch: 6| Step: 13
Training loss: 2.5524392223688146
Validation loss: 2.5243483867461634

Epoch: 55| Step: 0
Training loss: 3.2946532659480674
Validation loss: 2.522379946260312

Epoch: 6| Step: 1
Training loss: 2.290276111298615
Validation loss: 2.5247997590758025

Epoch: 6| Step: 2
Training loss: 2.6587062474476726
Validation loss: 2.519086608037396

Epoch: 6| Step: 3
Training loss: 2.7813706103972535
Validation loss: 2.5181815226064037

Epoch: 6| Step: 4
Training loss: 2.389060512065372
Validation loss: 2.520152018638701

Epoch: 6| Step: 5
Training loss: 3.2719259846530533
Validation loss: 2.514001190647985

Epoch: 6| Step: 6
Training loss: 2.5687248173057067
Validation loss: 2.5153587718639936

Epoch: 6| Step: 7
Training loss: 3.1636507496362216
Validation loss: 2.5158704004760573

Epoch: 6| Step: 8
Training loss: 3.3435326621467
Validation loss: 2.520591604415544

Epoch: 6| Step: 9
Training loss: 3.4064364600986545
Validation loss: 2.5171203999090808

Epoch: 6| Step: 10
Training loss: 2.657084255480555
Validation loss: 2.5229423095747223

Epoch: 6| Step: 11
Training loss: 3.161915142274277
Validation loss: 2.5387043957721063

Epoch: 6| Step: 12
Training loss: 2.598661070637413
Validation loss: 2.5357655767635787

Epoch: 6| Step: 13
Training loss: 1.9057458930173354
Validation loss: 2.5482501000543634

Epoch: 56| Step: 0
Training loss: 2.5631910183228896
Validation loss: 2.5714618611447495

Epoch: 6| Step: 1
Training loss: 2.983453898062652
Validation loss: 2.5921742782340136

Epoch: 6| Step: 2
Training loss: 3.4663699120883855
Validation loss: 2.6007097137398834

Epoch: 6| Step: 3
Training loss: 2.695677270946335
Validation loss: 2.558366907893566

Epoch: 6| Step: 4
Training loss: 2.5269221288761656
Validation loss: 2.5504503840040424

Epoch: 6| Step: 5
Training loss: 2.8070767142831357
Validation loss: 2.5211677742989225

Epoch: 6| Step: 6
Training loss: 3.1729656279992766
Validation loss: 2.5183276465480224

Epoch: 6| Step: 7
Training loss: 2.2872019422450163
Validation loss: 2.5134392798603433

Epoch: 6| Step: 8
Training loss: 3.169449503659902
Validation loss: 2.5091241623855556

Epoch: 6| Step: 9
Training loss: 2.423655095713855
Validation loss: 2.5112073974853732

Epoch: 6| Step: 10
Training loss: 2.729663473633842
Validation loss: 2.513841575062945

Epoch: 6| Step: 11
Training loss: 3.2315614413724574
Validation loss: 2.5087754961999837

Epoch: 6| Step: 12
Training loss: 2.9584451215514282
Validation loss: 2.5095693119571294

Epoch: 6| Step: 13
Training loss: 3.4568050332059017
Validation loss: 2.5105389457302003

Epoch: 57| Step: 0
Training loss: 3.0192015000251153
Validation loss: 2.511472330374946

Epoch: 6| Step: 1
Training loss: 2.936111771475113
Validation loss: 2.5122209326114318

Epoch: 6| Step: 2
Training loss: 3.3184465977261786
Validation loss: 2.5084574089996154

Epoch: 6| Step: 3
Training loss: 2.9856986261193112
Validation loss: 2.5064901748349158

Epoch: 6| Step: 4
Training loss: 2.9667817668517555
Validation loss: 2.5125763170298723

Epoch: 6| Step: 5
Training loss: 2.9502169707083192
Validation loss: 2.5132406638567413

Epoch: 6| Step: 6
Training loss: 3.6198728410506322
Validation loss: 2.5335776381521202

Epoch: 6| Step: 7
Training loss: 2.2001464404872286
Validation loss: 2.5432811036311946

Epoch: 6| Step: 8
Training loss: 2.723117696223906
Validation loss: 2.5492288409874826

Epoch: 6| Step: 9
Training loss: 3.0562871076519325
Validation loss: 2.545747280933926

Epoch: 6| Step: 10
Training loss: 2.952945441383087
Validation loss: 2.56300640229711

Epoch: 6| Step: 11
Training loss: 2.2405632063725602
Validation loss: 2.5714497361074744

Epoch: 6| Step: 12
Training loss: 1.9020858057123713
Validation loss: 2.586963659762793

Epoch: 6| Step: 13
Training loss: 2.741258860659423
Validation loss: 2.56887770055085

Epoch: 58| Step: 0
Training loss: 2.6671345916130766
Validation loss: 2.589121314264658

Epoch: 6| Step: 1
Training loss: 3.162990510919685
Validation loss: 2.5688042375701774

Epoch: 6| Step: 2
Training loss: 2.395040884126909
Validation loss: 2.5486223095531253

Epoch: 6| Step: 3
Training loss: 3.1379425587791223
Validation loss: 2.5260158076145167

Epoch: 6| Step: 4
Training loss: 2.793167469984723
Validation loss: 2.5153081550822707

Epoch: 6| Step: 5
Training loss: 2.7749459476189857
Validation loss: 2.5061477831365884

Epoch: 6| Step: 6
Training loss: 3.2624079724190564
Validation loss: 2.5017452495772274

Epoch: 6| Step: 7
Training loss: 2.729012162200676
Validation loss: 2.5006807805221336

Epoch: 6| Step: 8
Training loss: 2.838812261626805
Validation loss: 2.5010392664299026

Epoch: 6| Step: 9
Training loss: 2.9360669475479266
Validation loss: 2.495171842796628

Epoch: 6| Step: 10
Training loss: 3.086941712595638
Validation loss: 2.499059468414947

Epoch: 6| Step: 11
Training loss: 2.5050252000222635
Validation loss: 2.4958149407643613

Epoch: 6| Step: 12
Training loss: 2.526750497895129
Validation loss: 2.4972957916241167

Epoch: 6| Step: 13
Training loss: 3.416984372758283
Validation loss: 2.5053968014366674

Epoch: 59| Step: 0
Training loss: 2.898700712442128
Validation loss: 2.5145750530433615

Epoch: 6| Step: 1
Training loss: 2.1470142435952604
Validation loss: 2.52865706293093

Epoch: 6| Step: 2
Training loss: 3.0481575638402587
Validation loss: 2.545546663844087

Epoch: 6| Step: 3
Training loss: 2.6307891405864865
Validation loss: 2.535871005951697

Epoch: 6| Step: 4
Training loss: 2.8238881446580066
Validation loss: 2.520717638195295

Epoch: 6| Step: 5
Training loss: 2.696788881060668
Validation loss: 2.502176885462919

Epoch: 6| Step: 6
Training loss: 2.7194027171983306
Validation loss: 2.5005494867467704

Epoch: 6| Step: 7
Training loss: 2.692494564068619
Validation loss: 2.4956338523509545

Epoch: 6| Step: 8
Training loss: 3.2961801094917407
Validation loss: 2.49671278973941

Epoch: 6| Step: 9
Training loss: 3.6159258427991245
Validation loss: 2.4945383329694844

Epoch: 6| Step: 10
Training loss: 2.311696505786017
Validation loss: 2.5027242143458728

Epoch: 6| Step: 11
Training loss: 3.166228130158121
Validation loss: 2.5255134222170907

Epoch: 6| Step: 12
Training loss: 3.301591870691354
Validation loss: 2.581961824095827

Epoch: 6| Step: 13
Training loss: 2.3705370279287457
Validation loss: 2.5637518333387344

Epoch: 60| Step: 0
Training loss: 3.3347305866182277
Validation loss: 2.5101349467079612

Epoch: 6| Step: 1
Training loss: 2.1930220523739576
Validation loss: 2.494422842346771

Epoch: 6| Step: 2
Training loss: 2.5552287330440357
Validation loss: 2.4936332314050116

Epoch: 6| Step: 3
Training loss: 2.9229019726587584
Validation loss: 2.496902960388007

Epoch: 6| Step: 4
Training loss: 2.8880293455878463
Validation loss: 2.500261779123298

Epoch: 6| Step: 5
Training loss: 3.106148277167556
Validation loss: 2.5005725328062827

Epoch: 6| Step: 6
Training loss: 2.3498852600331457
Validation loss: 2.5026818493317045

Epoch: 6| Step: 7
Training loss: 3.2011805144979513
Validation loss: 2.506764317557503

Epoch: 6| Step: 8
Training loss: 2.8415121139007704
Validation loss: 2.5076979437612303

Epoch: 6| Step: 9
Training loss: 3.0110533853826014
Validation loss: 2.5056886698352536

Epoch: 6| Step: 10
Training loss: 3.312964352863569
Validation loss: 2.4996996822250854

Epoch: 6| Step: 11
Training loss: 2.7298452295719975
Validation loss: 2.4952123595842584

Epoch: 6| Step: 12
Training loss: 2.652961220870165
Validation loss: 2.4945982832125733

Epoch: 6| Step: 13
Training loss: 3.0176449666444123
Validation loss: 2.5001592554620107

Epoch: 61| Step: 0
Training loss: 2.2590078601675083
Validation loss: 2.5033706144083987

Epoch: 6| Step: 1
Training loss: 2.63866184551781
Validation loss: 2.5135475252422843

Epoch: 6| Step: 2
Training loss: 3.503421881803128
Validation loss: 2.529119074939426

Epoch: 6| Step: 3
Training loss: 2.532313464902714
Validation loss: 2.5336291760020315

Epoch: 6| Step: 4
Training loss: 3.0799245463455174
Validation loss: 2.537902768100349

Epoch: 6| Step: 5
Training loss: 2.2239661354327125
Validation loss: 2.553376861763925

Epoch: 6| Step: 6
Training loss: 2.9810772795796776
Validation loss: 2.5401094374247624

Epoch: 6| Step: 7
Training loss: 3.0406999663063132
Validation loss: 2.5536021342657547

Epoch: 6| Step: 8
Training loss: 2.7972455338692934
Validation loss: 2.532802040643445

Epoch: 6| Step: 9
Training loss: 2.9018118821525727
Validation loss: 2.5137601256024724

Epoch: 6| Step: 10
Training loss: 3.0496835137931537
Validation loss: 2.5091427250583314

Epoch: 6| Step: 11
Training loss: 2.462697589518338
Validation loss: 2.497203578570108

Epoch: 6| Step: 12
Training loss: 2.991727868377693
Validation loss: 2.493938967146911

Epoch: 6| Step: 13
Training loss: 3.4174920147437655
Validation loss: 2.4941024302603614

Epoch: 62| Step: 0
Training loss: 2.513807410177854
Validation loss: 2.4882806101924864

Epoch: 6| Step: 1
Training loss: 2.299449178832073
Validation loss: 2.496378615827112

Epoch: 6| Step: 2
Training loss: 2.8834393241085254
Validation loss: 2.4889438394950796

Epoch: 6| Step: 3
Training loss: 2.872527344576012
Validation loss: 2.4868268074191553

Epoch: 6| Step: 4
Training loss: 2.8394024491625958
Validation loss: 2.494714087361312

Epoch: 6| Step: 5
Training loss: 2.742049080596551
Validation loss: 2.4933813250176526

Epoch: 6| Step: 6
Training loss: 2.7649665522837346
Validation loss: 2.501655033862233

Epoch: 6| Step: 7
Training loss: 2.9182079783962935
Validation loss: 2.510954251480984

Epoch: 6| Step: 8
Training loss: 3.262285487112719
Validation loss: 2.510825190856856

Epoch: 6| Step: 9
Training loss: 2.9377871433896843
Validation loss: 2.523585307665959

Epoch: 6| Step: 10
Training loss: 2.2706949267656924
Validation loss: 2.5095074688399306

Epoch: 6| Step: 11
Training loss: 3.505612641474444
Validation loss: 2.502512550621256

Epoch: 6| Step: 12
Training loss: 2.9626041442335302
Validation loss: 2.5052604377374315

Epoch: 6| Step: 13
Training loss: 2.86501302559706
Validation loss: 2.5090282346632944

Epoch: 63| Step: 0
Training loss: 2.3362840886534983
Validation loss: 2.5041235070147585

Epoch: 6| Step: 1
Training loss: 2.5577381829317005
Validation loss: 2.503967808614057

Epoch: 6| Step: 2
Training loss: 3.4412455180257093
Validation loss: 2.501297564787853

Epoch: 6| Step: 3
Training loss: 2.90552388626387
Validation loss: 2.4978068145309016

Epoch: 6| Step: 4
Training loss: 2.963822622451201
Validation loss: 2.5047190908236945

Epoch: 6| Step: 5
Training loss: 3.197229533146169
Validation loss: 2.5138024252741573

Epoch: 6| Step: 6
Training loss: 2.912382812761964
Validation loss: 2.5041198050682034

Epoch: 6| Step: 7
Training loss: 2.494625035550065
Validation loss: 2.50704350739404

Epoch: 6| Step: 8
Training loss: 2.868646983040204
Validation loss: 2.5131564865891876

Epoch: 6| Step: 9
Training loss: 2.6696395892229416
Validation loss: 2.512386176634411

Epoch: 6| Step: 10
Training loss: 2.790047180569875
Validation loss: 2.517657056495701

Epoch: 6| Step: 11
Training loss: 3.068693787473637
Validation loss: 2.509868583611882

Epoch: 6| Step: 12
Training loss: 2.218961678736625
Validation loss: 2.5191245338776884

Epoch: 6| Step: 13
Training loss: 3.2075093850335223
Validation loss: 2.515069784993835

Epoch: 64| Step: 0
Training loss: 2.496509403968181
Validation loss: 2.5008821428240964

Epoch: 6| Step: 1
Training loss: 3.026664332782445
Validation loss: 2.4967502453017905

Epoch: 6| Step: 2
Training loss: 2.803718760873794
Validation loss: 2.4935765345101935

Epoch: 6| Step: 3
Training loss: 3.0657651972234983
Validation loss: 2.486731394815764

Epoch: 6| Step: 4
Training loss: 2.3603489362444017
Validation loss: 2.4880353070990076

Epoch: 6| Step: 5
Training loss: 2.872570006046194
Validation loss: 2.4907773544549583

Epoch: 6| Step: 6
Training loss: 2.7475663600748823
Validation loss: 2.4936373483257843

Epoch: 6| Step: 7
Training loss: 3.0611173661620596
Validation loss: 2.496760357118902

Epoch: 6| Step: 8
Training loss: 3.160846045505645
Validation loss: 2.4895700159247434

Epoch: 6| Step: 9
Training loss: 3.301629710201635
Validation loss: 2.490317822030792

Epoch: 6| Step: 10
Training loss: 2.7511017933035338
Validation loss: 2.5004441758854012

Epoch: 6| Step: 11
Training loss: 2.2256202176221302
Validation loss: 2.505838610919449

Epoch: 6| Step: 12
Training loss: 2.989039425878007
Validation loss: 2.501008718295038

Epoch: 6| Step: 13
Training loss: 2.629023783126751
Validation loss: 2.49981037056489

Epoch: 65| Step: 0
Training loss: 3.6893631705550547
Validation loss: 2.5159723511725174

Epoch: 6| Step: 1
Training loss: 2.7804646615504502
Validation loss: 2.510811968417569

Epoch: 6| Step: 2
Training loss: 2.591079164091407
Validation loss: 2.5194882762436825

Epoch: 6| Step: 3
Training loss: 3.166671619076788
Validation loss: 2.5037139705614573

Epoch: 6| Step: 4
Training loss: 3.069890971282453
Validation loss: 2.5065432065052993

Epoch: 6| Step: 5
Training loss: 2.5252372063740487
Validation loss: 2.4948761001498116

Epoch: 6| Step: 6
Training loss: 2.4627943995749293
Validation loss: 2.4921804340499105

Epoch: 6| Step: 7
Training loss: 2.881967808476819
Validation loss: 2.482507770828827

Epoch: 6| Step: 8
Training loss: 3.1132351478216873
Validation loss: 2.4813427284010934

Epoch: 6| Step: 9
Training loss: 2.5700306839354328
Validation loss: 2.480976898437825

Epoch: 6| Step: 10
Training loss: 2.9843099696878377
Validation loss: 2.4836367361967677

Epoch: 6| Step: 11
Training loss: 2.7176055253218347
Validation loss: 2.4830099328286916

Epoch: 6| Step: 12
Training loss: 2.240701109632322
Validation loss: 2.4935994558460672

Epoch: 6| Step: 13
Training loss: 2.448880356283183
Validation loss: 2.491368681331654

Epoch: 66| Step: 0
Training loss: 2.709778287763678
Validation loss: 2.4896129685852584

Epoch: 6| Step: 1
Training loss: 2.826630677033079
Validation loss: 2.48818097439165

Epoch: 6| Step: 2
Training loss: 3.0210947033288997
Validation loss: 2.487023701349843

Epoch: 6| Step: 3
Training loss: 2.9045308268351437
Validation loss: 2.4869744726281797

Epoch: 6| Step: 4
Training loss: 2.427349179706572
Validation loss: 2.48607928868926

Epoch: 6| Step: 5
Training loss: 2.8079981908602196
Validation loss: 2.4899422065158197

Epoch: 6| Step: 6
Training loss: 2.8885101004818967
Validation loss: 2.488015985711607

Epoch: 6| Step: 7
Training loss: 2.7814538430939684
Validation loss: 2.481585915655939

Epoch: 6| Step: 8
Training loss: 2.7852166852774225
Validation loss: 2.484126527392502

Epoch: 6| Step: 9
Training loss: 3.036186524532933
Validation loss: 2.484221326951358

Epoch: 6| Step: 10
Training loss: 2.380422825960292
Validation loss: 2.484136857779912

Epoch: 6| Step: 11
Training loss: 3.2342190175061183
Validation loss: 2.489858558473523

Epoch: 6| Step: 12
Training loss: 2.6821315285492595
Validation loss: 2.494753599384888

Epoch: 6| Step: 13
Training loss: 3.2130200391869326
Validation loss: 2.507238146014308

Epoch: 67| Step: 0
Training loss: 2.39422505896273
Validation loss: 2.51529754808595

Epoch: 6| Step: 1
Training loss: 3.040941613582345
Validation loss: 2.5423575073839535

Epoch: 6| Step: 2
Training loss: 2.8374471718327894
Validation loss: 2.5526305492010164

Epoch: 6| Step: 3
Training loss: 2.472209486291586
Validation loss: 2.5290208442999456

Epoch: 6| Step: 4
Training loss: 3.0051368603507025
Validation loss: 2.503410037934372

Epoch: 6| Step: 5
Training loss: 2.8791439211913503
Validation loss: 2.487775528195835

Epoch: 6| Step: 6
Training loss: 2.352852603703823
Validation loss: 2.48469954357454

Epoch: 6| Step: 7
Training loss: 3.297522024872101
Validation loss: 2.4828219154801134

Epoch: 6| Step: 8
Training loss: 3.331208569124104
Validation loss: 2.4791180268174124

Epoch: 6| Step: 9
Training loss: 2.1979870777392416
Validation loss: 2.482344938415769

Epoch: 6| Step: 10
Training loss: 2.2231032956071686
Validation loss: 2.4824034801668557

Epoch: 6| Step: 11
Training loss: 2.821959292144555
Validation loss: 2.4787621147782217

Epoch: 6| Step: 12
Training loss: 3.4989159131277607
Validation loss: 2.4811971106491977

Epoch: 6| Step: 13
Training loss: 3.007926482976229
Validation loss: 2.48256576659491

Epoch: 68| Step: 0
Training loss: 2.6833528857575133
Validation loss: 2.4871898644122368

Epoch: 6| Step: 1
Training loss: 2.4014515778558043
Validation loss: 2.492056211395874

Epoch: 6| Step: 2
Training loss: 2.8919499840216822
Validation loss: 2.492350670658065

Epoch: 6| Step: 3
Training loss: 3.2588213998152082
Validation loss: 2.489908262482762

Epoch: 6| Step: 4
Training loss: 2.6742127659446817
Validation loss: 2.501105060199281

Epoch: 6| Step: 5
Training loss: 2.7929506528041315
Validation loss: 2.4888932427586994

Epoch: 6| Step: 6
Training loss: 2.62019953703169
Validation loss: 2.4841631562136337

Epoch: 6| Step: 7
Training loss: 2.982736826956384
Validation loss: 2.48503795014851

Epoch: 6| Step: 8
Training loss: 2.5632099935805894
Validation loss: 2.477182307834804

Epoch: 6| Step: 9
Training loss: 2.8610724741807307
Validation loss: 2.4823429131930617

Epoch: 6| Step: 10
Training loss: 2.8329517631154033
Validation loss: 2.490006808862076

Epoch: 6| Step: 11
Training loss: 2.9987671226149373
Validation loss: 2.486432731001674

Epoch: 6| Step: 12
Training loss: 2.999496099750255
Validation loss: 2.4944923480447283

Epoch: 6| Step: 13
Training loss: 3.0037138521366473
Validation loss: 2.5016368655099797

Epoch: 69| Step: 0
Training loss: 3.037942478933737
Validation loss: 2.4887109697942926

Epoch: 6| Step: 1
Training loss: 2.4332786588753623
Validation loss: 2.4890008958099785

Epoch: 6| Step: 2
Training loss: 2.2655034525922213
Validation loss: 2.4772174807954026

Epoch: 6| Step: 3
Training loss: 2.6473033355778335
Validation loss: 2.474566804229763

Epoch: 6| Step: 4
Training loss: 2.8169475569605074
Validation loss: 2.477278476295395

Epoch: 6| Step: 5
Training loss: 2.530639480620992
Validation loss: 2.4748233355907088

Epoch: 6| Step: 6
Training loss: 2.8453760214370862
Validation loss: 2.4791180040673484

Epoch: 6| Step: 7
Training loss: 3.170647444687892
Validation loss: 2.4813669012842254

Epoch: 6| Step: 8
Training loss: 2.951973019308624
Validation loss: 2.4856866619465063

Epoch: 6| Step: 9
Training loss: 2.7722049177042103
Validation loss: 2.481384456619376

Epoch: 6| Step: 10
Training loss: 3.2157394996773534
Validation loss: 2.4822315223667295

Epoch: 6| Step: 11
Training loss: 3.062035973096513
Validation loss: 2.5009650685224343

Epoch: 6| Step: 12
Training loss: 3.0486929922807318
Validation loss: 2.5206218282606407

Epoch: 6| Step: 13
Training loss: 2.449573253912146
Validation loss: 2.544606448466725

Epoch: 70| Step: 0
Training loss: 2.3018901853244365
Validation loss: 2.5068667081254374

Epoch: 6| Step: 1
Training loss: 3.394644609145397
Validation loss: 2.485689587916345

Epoch: 6| Step: 2
Training loss: 2.832320836487417
Validation loss: 2.4810430351406483

Epoch: 6| Step: 3
Training loss: 2.8920607841509196
Validation loss: 2.473484177716733

Epoch: 6| Step: 4
Training loss: 2.5934461852315613
Validation loss: 2.4752005224783935

Epoch: 6| Step: 5
Training loss: 3.1776935595872957
Validation loss: 2.476010749543077

Epoch: 6| Step: 6
Training loss: 2.6965424758109298
Validation loss: 2.4797722530189086

Epoch: 6| Step: 7
Training loss: 2.2977165704544302
Validation loss: 2.4879984060707785

Epoch: 6| Step: 8
Training loss: 2.5225510117785817
Validation loss: 2.4894080882762775

Epoch: 6| Step: 9
Training loss: 2.8817977152984584
Validation loss: 2.4910466383450456

Epoch: 6| Step: 10
Training loss: 3.0554544798191756
Validation loss: 2.501989676252635

Epoch: 6| Step: 11
Training loss: 2.450527881662176
Validation loss: 2.5152223203985646

Epoch: 6| Step: 12
Training loss: 2.9262000727641175
Validation loss: 2.5628893296607123

Epoch: 6| Step: 13
Training loss: 3.7559680496498147
Validation loss: 2.5853009453065403

Epoch: 71| Step: 0
Training loss: 2.8118259893870183
Validation loss: 2.534162120563388

Epoch: 6| Step: 1
Training loss: 2.802232523258982
Validation loss: 2.4935453572484545

Epoch: 6| Step: 2
Training loss: 2.6673407199429677
Validation loss: 2.475523415253489

Epoch: 6| Step: 3
Training loss: 3.15182214744441
Validation loss: 2.4734818146114854

Epoch: 6| Step: 4
Training loss: 3.029973813437936
Validation loss: 2.4779553830997347

Epoch: 6| Step: 5
Training loss: 2.917688317975313
Validation loss: 2.4839498690549555

Epoch: 6| Step: 6
Training loss: 2.125392428795067
Validation loss: 2.478591600624762

Epoch: 6| Step: 7
Training loss: 2.7897286781544337
Validation loss: 2.478547220940147

Epoch: 6| Step: 8
Training loss: 2.628881128426358
Validation loss: 2.4821957579070104

Epoch: 6| Step: 9
Training loss: 2.8459232954678386
Validation loss: 2.47065153731598

Epoch: 6| Step: 10
Training loss: 2.911502808223774
Validation loss: 2.4799104017727256

Epoch: 6| Step: 11
Training loss: 3.0114847332274346
Validation loss: 2.492367420381257

Epoch: 6| Step: 12
Training loss: 3.0749079744788577
Validation loss: 2.5023781570857206

Epoch: 6| Step: 13
Training loss: 2.7928576894166555
Validation loss: 2.551991755182035

Epoch: 72| Step: 0
Training loss: 3.4967686859414875
Validation loss: 2.6215814753147524

Epoch: 6| Step: 1
Training loss: 2.317845841232648
Validation loss: 2.6362758508480404

Epoch: 6| Step: 2
Training loss: 2.9532664431652913
Validation loss: 2.652086267576908

Epoch: 6| Step: 3
Training loss: 2.6851183962158496
Validation loss: 2.583008947922134

Epoch: 6| Step: 4
Training loss: 2.772670414109972
Validation loss: 2.5164038562547737

Epoch: 6| Step: 5
Training loss: 3.1310754845388784
Validation loss: 2.4904059500704934

Epoch: 6| Step: 6
Training loss: 2.3478841306050584
Validation loss: 2.473147444588736

Epoch: 6| Step: 7
Training loss: 2.8590826500030286
Validation loss: 2.4710658374509196

Epoch: 6| Step: 8
Training loss: 3.536308513870564
Validation loss: 2.4704495394336146

Epoch: 6| Step: 9
Training loss: 2.48136921555397
Validation loss: 2.4737778733933906

Epoch: 6| Step: 10
Training loss: 2.8111786175422155
Validation loss: 2.47297545687636

Epoch: 6| Step: 11
Training loss: 2.970780491370117
Validation loss: 2.4702583451874487

Epoch: 6| Step: 12
Training loss: 2.5638396320270194
Validation loss: 2.4678041326600297

Epoch: 6| Step: 13
Training loss: 2.2550218488899274
Validation loss: 2.466295865992071

Epoch: 73| Step: 0
Training loss: 2.645689131844639
Validation loss: 2.4654559028960583

Epoch: 6| Step: 1
Training loss: 3.0173075829369513
Validation loss: 2.4691233323460087

Epoch: 6| Step: 2
Training loss: 2.9925066825008115
Validation loss: 2.472768508635259

Epoch: 6| Step: 3
Training loss: 2.645817273509228
Validation loss: 2.4813072357722006

Epoch: 6| Step: 4
Training loss: 3.310384110582143
Validation loss: 2.491935472670596

Epoch: 6| Step: 5
Training loss: 2.5496037381020593
Validation loss: 2.4920763907846344

Epoch: 6| Step: 6
Training loss: 3.2059043177404463
Validation loss: 2.493534286527979

Epoch: 6| Step: 7
Training loss: 2.4302228233623775
Validation loss: 2.4961583893035346

Epoch: 6| Step: 8
Training loss: 2.4314786435757645
Validation loss: 2.4978422492429124

Epoch: 6| Step: 9
Training loss: 1.9014722014327885
Validation loss: 2.485919573634877

Epoch: 6| Step: 10
Training loss: 2.50011272176296
Validation loss: 2.485209166007042

Epoch: 6| Step: 11
Training loss: 3.1009782293663246
Validation loss: 2.4768889925489663

Epoch: 6| Step: 12
Training loss: 3.1462568962133743
Validation loss: 2.47459481946763

Epoch: 6| Step: 13
Training loss: 3.41567501160636
Validation loss: 2.478990658345859

Epoch: 74| Step: 0
Training loss: 2.202401766193872
Validation loss: 2.4765734473197702

Epoch: 6| Step: 1
Training loss: 3.4981454295423493
Validation loss: 2.489103263680468

Epoch: 6| Step: 2
Training loss: 2.501740040813898
Validation loss: 2.4979160282939814

Epoch: 6| Step: 3
Training loss: 3.1034016189137312
Validation loss: 2.5007501850728944

Epoch: 6| Step: 4
Training loss: 2.4742605780970597
Validation loss: 2.501382615659315

Epoch: 6| Step: 5
Training loss: 2.958451246320525
Validation loss: 2.5191963794263703

Epoch: 6| Step: 6
Training loss: 2.7060982994218876
Validation loss: 2.527255227135183

Epoch: 6| Step: 7
Training loss: 3.043397454557365
Validation loss: 2.5297457196462525

Epoch: 6| Step: 8
Training loss: 2.49323473126808
Validation loss: 2.541592130033742

Epoch: 6| Step: 9
Training loss: 2.7865716833904677
Validation loss: 2.548259669485534

Epoch: 6| Step: 10
Training loss: 2.6012499738965453
Validation loss: 2.5156071567431244

Epoch: 6| Step: 11
Training loss: 3.4979928937417766
Validation loss: 2.493913269331816

Epoch: 6| Step: 12
Training loss: 2.2859355934328067
Validation loss: 2.4838866274083946

Epoch: 6| Step: 13
Training loss: 2.7669399605245695
Validation loss: 2.475423783794125

Epoch: 75| Step: 0
Training loss: 2.6101919026182063
Validation loss: 2.4768789760797225

Epoch: 6| Step: 1
Training loss: 3.180412041222509
Validation loss: 2.4798256275890074

Epoch: 6| Step: 2
Training loss: 2.9446970653327975
Validation loss: 2.4803516967843042

Epoch: 6| Step: 3
Training loss: 3.2050598255590486
Validation loss: 2.4905298299124614

Epoch: 6| Step: 4
Training loss: 2.832785123260398
Validation loss: 2.49766257749266

Epoch: 6| Step: 5
Training loss: 2.7946993074761664
Validation loss: 2.5045562673937294

Epoch: 6| Step: 6
Training loss: 1.7177769767720432
Validation loss: 2.5235220220860834

Epoch: 6| Step: 7
Training loss: 2.50178559432521
Validation loss: 2.5396316473520137

Epoch: 6| Step: 8
Training loss: 3.1697097679152555
Validation loss: 2.560885345116702

Epoch: 6| Step: 9
Training loss: 3.0823033820665873
Validation loss: 2.5902086790661216

Epoch: 6| Step: 10
Training loss: 3.10703653551419
Validation loss: 2.556633448394262

Epoch: 6| Step: 11
Training loss: 2.882142689536575
Validation loss: 2.538574558572649

Epoch: 6| Step: 12
Training loss: 2.725309329893309
Validation loss: 2.5187401016152

Epoch: 6| Step: 13
Training loss: 2.6901181797033127
Validation loss: 2.5130206163829105

Testing loss: 2.773040477530781
