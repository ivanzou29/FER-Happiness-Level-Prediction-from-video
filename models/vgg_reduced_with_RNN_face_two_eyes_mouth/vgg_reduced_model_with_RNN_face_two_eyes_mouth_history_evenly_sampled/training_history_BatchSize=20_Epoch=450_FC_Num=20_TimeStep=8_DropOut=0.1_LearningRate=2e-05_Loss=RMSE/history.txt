Epoch: 1| Step: 0
Training loss: 6.349727426521022
Validation loss: 5.8601841539191275

Epoch: 5| Step: 1
Training loss: 6.180727556480823
Validation loss: 5.8374839706430945

Epoch: 5| Step: 2
Training loss: 5.7553722329485275
Validation loss: 5.818643707499064

Epoch: 5| Step: 3
Training loss: 5.841060243802363
Validation loss: 5.799052104359311

Epoch: 5| Step: 4
Training loss: 5.176375813432565
Validation loss: 5.777627183094326

Epoch: 5| Step: 5
Training loss: 5.227519450942804
Validation loss: 5.753345555943288

Epoch: 5| Step: 6
Training loss: 4.584567695629605
Validation loss: 5.726840734189395

Epoch: 5| Step: 7
Training loss: 5.382698046792097
Validation loss: 5.695807043616917

Epoch: 5| Step: 8
Training loss: 6.780205008859113
Validation loss: 5.661768893421116

Epoch: 5| Step: 9
Training loss: 5.573689896130528
Validation loss: 5.625496738244834

Epoch: 5| Step: 10
Training loss: 6.424167493030955
Validation loss: 5.584417954385094

Epoch: 2| Step: 0
Training loss: 5.4505406242797445
Validation loss: 5.539405877253824

Epoch: 5| Step: 1
Training loss: 5.141492590695883
Validation loss: 5.49225830066098

Epoch: 5| Step: 2
Training loss: 5.799275109604217
Validation loss: 5.441865114920425

Epoch: 5| Step: 3
Training loss: 4.927672637903494
Validation loss: 5.390507233296179

Epoch: 5| Step: 4
Training loss: 6.466527584717029
Validation loss: 5.340149232466652

Epoch: 5| Step: 5
Training loss: 5.571437385049074
Validation loss: 5.288865407089214

Epoch: 5| Step: 6
Training loss: 5.475410285800651
Validation loss: 5.239212449987572

Epoch: 5| Step: 7
Training loss: 3.6571813196050007
Validation loss: 5.191089756497086

Epoch: 5| Step: 8
Training loss: 4.469691037417542
Validation loss: 5.145914134998329

Epoch: 5| Step: 9
Training loss: 5.707954932523447
Validation loss: 5.097247848020869

Epoch: 5| Step: 10
Training loss: 5.64110108794152
Validation loss: 5.039400174832759

Epoch: 3| Step: 0
Training loss: 5.110529124715983
Validation loss: 4.978626261883282

Epoch: 5| Step: 1
Training loss: 5.147231474473111
Validation loss: 4.912246564468852

Epoch: 5| Step: 2
Training loss: 3.5162388244516407
Validation loss: 4.8468591360719016

Epoch: 5| Step: 3
Training loss: 5.250878033556961
Validation loss: 4.788697947500677

Epoch: 5| Step: 4
Training loss: 4.7748384058906295
Validation loss: 4.734337877119692

Epoch: 5| Step: 5
Training loss: 5.51541422584393
Validation loss: 4.681878535620919

Epoch: 5| Step: 6
Training loss: 4.059650067061469
Validation loss: 4.629736749856808

Epoch: 5| Step: 7
Training loss: 4.849965297928768
Validation loss: 4.577275706250597

Epoch: 5| Step: 8
Training loss: 4.640410036188082
Validation loss: 4.531983849291319

Epoch: 5| Step: 9
Training loss: 4.117104574740081
Validation loss: 4.490860377410997

Epoch: 5| Step: 10
Training loss: 5.327404879683465
Validation loss: 4.4628686884218

Epoch: 4| Step: 0
Training loss: 5.229407113716269
Validation loss: 4.43673089546486

Epoch: 5| Step: 1
Training loss: 4.695871634046482
Validation loss: 4.395818128949777

Epoch: 5| Step: 2
Training loss: 4.662509474348409
Validation loss: 4.3642036252653424

Epoch: 5| Step: 3
Training loss: 4.826148755193003
Validation loss: 4.340565524937078

Epoch: 5| Step: 4
Training loss: 4.2546455574560005
Validation loss: 4.319199463406065

Epoch: 5| Step: 5
Training loss: 4.22660108397072
Validation loss: 4.296788738499815

Epoch: 5| Step: 6
Training loss: 3.779107992494142
Validation loss: 4.276127064511772

Epoch: 5| Step: 7
Training loss: 4.251545793247448
Validation loss: 4.253917757091415

Epoch: 5| Step: 8
Training loss: 3.4305621793599776
Validation loss: 4.235470335613965

Epoch: 5| Step: 9
Training loss: 4.19090383172387
Validation loss: 4.212011706905672

Epoch: 5| Step: 10
Training loss: 4.990200166529031
Validation loss: 4.190696436702199

Epoch: 5| Step: 0
Training loss: 5.431897664495239
Validation loss: 4.1599402103177985

Epoch: 5| Step: 1
Training loss: 4.045944990718475
Validation loss: 4.135051035518417

Epoch: 5| Step: 2
Training loss: 4.722771352117818
Validation loss: 4.112847154441396

Epoch: 5| Step: 3
Training loss: 4.34317012731032
Validation loss: 4.087696260114171

Epoch: 5| Step: 4
Training loss: 3.7638858562111612
Validation loss: 4.062527103507199

Epoch: 5| Step: 5
Training loss: 4.589446458869318
Validation loss: 4.040083401388814

Epoch: 5| Step: 6
Training loss: 4.488015215951622
Validation loss: 4.017282535777937

Epoch: 5| Step: 7
Training loss: 4.243819286471854
Validation loss: 4.001586607088165

Epoch: 5| Step: 8
Training loss: 3.1320396478416193
Validation loss: 3.9812290538241273

Epoch: 5| Step: 9
Training loss: 2.9627724952761136
Validation loss: 3.960040933427074

Epoch: 5| Step: 10
Training loss: 3.851322065977317
Validation loss: 3.9399396087463976

Epoch: 6| Step: 0
Training loss: 3.9160067360793755
Validation loss: 3.916506232277118

Epoch: 5| Step: 1
Training loss: 4.198084421647485
Validation loss: 3.8974733864727944

Epoch: 5| Step: 2
Training loss: 3.960059074192423
Validation loss: 3.8757952093494143

Epoch: 5| Step: 3
Training loss: 4.344971848584319
Validation loss: 3.8620084523139364

Epoch: 5| Step: 4
Training loss: 4.768999749639388
Validation loss: 3.838378895229704

Epoch: 5| Step: 5
Training loss: 3.7085834947423777
Validation loss: 3.819711587214023

Epoch: 5| Step: 6
Training loss: 4.229071529928174
Validation loss: 3.795192961540634

Epoch: 5| Step: 7
Training loss: 3.303626789822159
Validation loss: 3.770845522759157

Epoch: 5| Step: 8
Training loss: 3.267692386068227
Validation loss: 3.744637428023799

Epoch: 5| Step: 9
Training loss: 4.7129865400258515
Validation loss: 3.7217833454064575

Epoch: 5| Step: 10
Training loss: 2.8248126617701006
Validation loss: 3.6971064653898433

Epoch: 7| Step: 0
Training loss: 3.6817296024974135
Validation loss: 3.676664293970984

Epoch: 5| Step: 1
Training loss: 4.062841547766876
Validation loss: 3.6608811924582008

Epoch: 5| Step: 2
Training loss: 3.643801633491906
Validation loss: 3.6464401757330664

Epoch: 5| Step: 3
Training loss: 4.075758441015222
Validation loss: 3.6310776965566136

Epoch: 5| Step: 4
Training loss: 3.8995384236602337
Validation loss: 3.619122182191452

Epoch: 5| Step: 5
Training loss: 3.5425033179505183
Validation loss: 3.6116728872343513

Epoch: 5| Step: 6
Training loss: 2.693572967447352
Validation loss: 3.6019748370469435

Epoch: 5| Step: 7
Training loss: 4.3284956019413245
Validation loss: 3.591704095025356

Epoch: 5| Step: 8
Training loss: 4.483061807533554
Validation loss: 3.583448574638861

Epoch: 5| Step: 9
Training loss: 4.06874894993266
Validation loss: 3.5696562726292704

Epoch: 5| Step: 10
Training loss: 2.9179877059708916
Validation loss: 3.5579779867657613

Epoch: 8| Step: 0
Training loss: 3.6651888094324776
Validation loss: 3.555529212394753

Epoch: 5| Step: 1
Training loss: 3.759507397788098
Validation loss: 3.548646311926543

Epoch: 5| Step: 2
Training loss: 3.764257412207147
Validation loss: 3.5425143222193802

Epoch: 5| Step: 3
Training loss: 3.968363945875099
Validation loss: 3.531759858518997

Epoch: 5| Step: 4
Training loss: 4.90400401418002
Validation loss: 3.520682993139749

Epoch: 5| Step: 5
Training loss: 3.5403554546111775
Validation loss: 3.520841160286358

Epoch: 5| Step: 6
Training loss: 3.8757626183001825
Validation loss: 3.5079826640574194

Epoch: 5| Step: 7
Training loss: 3.7100683860953825
Validation loss: 3.506929323812322

Epoch: 5| Step: 8
Training loss: 3.200303933491885
Validation loss: 3.5027934000601753

Epoch: 5| Step: 9
Training loss: 2.722214606873463
Validation loss: 3.5028512243233774

Epoch: 5| Step: 10
Training loss: 3.5559979716532255
Validation loss: 3.5087624366342545

Epoch: 9| Step: 0
Training loss: 3.294078924849064
Validation loss: 3.4896149801779255

Epoch: 5| Step: 1
Training loss: 3.214766769136425
Validation loss: 3.4847684263159233

Epoch: 5| Step: 2
Training loss: 3.4810920611018337
Validation loss: 3.486889927457284

Epoch: 5| Step: 3
Training loss: 3.6360662512120325
Validation loss: 3.4824419884697866

Epoch: 5| Step: 4
Training loss: 3.210828496191911
Validation loss: 3.478548244144128

Epoch: 5| Step: 5
Training loss: 4.456078978436148
Validation loss: 3.4804011917799

Epoch: 5| Step: 6
Training loss: 4.274607161826623
Validation loss: 3.479989903798048

Epoch: 5| Step: 7
Training loss: 3.1070004698351212
Validation loss: 3.475210338201546

Epoch: 5| Step: 8
Training loss: 4.38457248321837
Validation loss: 3.469157849677457

Epoch: 5| Step: 9
Training loss: 3.40748727707926
Validation loss: 3.4680800873304927

Epoch: 5| Step: 10
Training loss: 3.8781116666726
Validation loss: 3.4643524373178756

Epoch: 10| Step: 0
Training loss: 3.1446662068283437
Validation loss: 3.460349730971788

Epoch: 5| Step: 1
Training loss: 3.220738065494218
Validation loss: 3.4547821747162044

Epoch: 5| Step: 2
Training loss: 3.849834062047071
Validation loss: 3.4551494356397825

Epoch: 5| Step: 3
Training loss: 3.373421193764145
Validation loss: 3.5264168799591262

Epoch: 5| Step: 4
Training loss: 4.508284043320561
Validation loss: 3.4624289007525455

Epoch: 5| Step: 5
Training loss: 3.257223025628439
Validation loss: 3.455828084825943

Epoch: 5| Step: 6
Training loss: 4.420884955006225
Validation loss: 3.475007127902226

Epoch: 5| Step: 7
Training loss: 2.817537247310873
Validation loss: 3.496689926153467

Epoch: 5| Step: 8
Training loss: 3.7451129858597683
Validation loss: 3.4797802765268453

Epoch: 5| Step: 9
Training loss: 3.5914377486229503
Validation loss: 3.458502119808097

Epoch: 5| Step: 10
Training loss: 4.271186082120012
Validation loss: 3.4416884991122845

Epoch: 11| Step: 0
Training loss: 4.485754990327933
Validation loss: 3.430812944331835

Epoch: 5| Step: 1
Training loss: 3.493192592095894
Validation loss: 3.4315357660894623

Epoch: 5| Step: 2
Training loss: 4.20598292416867
Validation loss: 3.470095519002736

Epoch: 5| Step: 3
Training loss: 3.2681762366802474
Validation loss: 3.412005663509357

Epoch: 5| Step: 4
Training loss: 3.251491204524562
Validation loss: 3.41349527316586

Epoch: 5| Step: 5
Training loss: 4.157754955445457
Validation loss: 3.418253750358696

Epoch: 5| Step: 6
Training loss: 3.398011069016505
Validation loss: 3.4058340871826496

Epoch: 5| Step: 7
Training loss: 3.285531293618683
Validation loss: 3.3981501677406416

Epoch: 5| Step: 8
Training loss: 3.752578230518275
Validation loss: 3.391320194497804

Epoch: 5| Step: 9
Training loss: 3.297635826801318
Validation loss: 3.386805585326658

Epoch: 5| Step: 10
Training loss: 3.1371135154471648
Validation loss: 3.38385694646672

Epoch: 12| Step: 0
Training loss: 3.8903314563976688
Validation loss: 3.3839694646916425

Epoch: 5| Step: 1
Training loss: 3.348800125458884
Validation loss: 3.382753319525649

Epoch: 5| Step: 2
Training loss: 4.0061859935104875
Validation loss: 3.3796107261319963

Epoch: 5| Step: 3
Training loss: 3.497385138151849
Validation loss: 3.3743730856835716

Epoch: 5| Step: 4
Training loss: 4.009841732412158
Validation loss: 3.3753787610182595

Epoch: 5| Step: 5
Training loss: 3.1437131966774365
Validation loss: 3.3837805967960906

Epoch: 5| Step: 6
Training loss: 3.0624137399163933
Validation loss: 3.3839745783788064

Epoch: 5| Step: 7
Training loss: 3.437740525587213
Validation loss: 3.3773242235030208

Epoch: 5| Step: 8
Training loss: 2.9602703862802286
Validation loss: 3.369095106561962

Epoch: 5| Step: 9
Training loss: 4.294468431185088
Validation loss: 3.369500069701151

Epoch: 5| Step: 10
Training loss: 3.804880877521196
Validation loss: 3.3694158302869504

Epoch: 13| Step: 0
Training loss: 3.8832467218217106
Validation loss: 3.365309678236949

Epoch: 5| Step: 1
Training loss: 3.7214505944150815
Validation loss: 3.362284340289571

Epoch: 5| Step: 2
Training loss: 3.562513117180484
Validation loss: 3.3602089169518

Epoch: 5| Step: 3
Training loss: 3.6220693909661135
Validation loss: 3.3578321519331187

Epoch: 5| Step: 4
Training loss: 3.420980955060296
Validation loss: 3.3563256295905357

Epoch: 5| Step: 5
Training loss: 3.849706237286596
Validation loss: 3.3561572587923925

Epoch: 5| Step: 6
Training loss: 3.532005431805038
Validation loss: 3.3522366506111463

Epoch: 5| Step: 7
Training loss: 3.700229204656407
Validation loss: 3.3485402283044166

Epoch: 5| Step: 8
Training loss: 3.368368910712178
Validation loss: 3.3447656975859283

Epoch: 5| Step: 9
Training loss: 3.5266027337560777
Validation loss: 3.3411281098215477

Epoch: 5| Step: 10
Training loss: 3.1639583617604092
Validation loss: 3.339245443647235

Epoch: 14| Step: 0
Training loss: 3.6025783736249726
Validation loss: 3.337375674471363

Epoch: 5| Step: 1
Training loss: 3.1794373509941165
Validation loss: 3.3358401337411747

Epoch: 5| Step: 2
Training loss: 2.9326934448855724
Validation loss: 3.3339458261764636

Epoch: 5| Step: 3
Training loss: 3.7899805588840096
Validation loss: 3.335243900926688

Epoch: 5| Step: 4
Training loss: 3.363379216733403
Validation loss: 3.3341082953908043

Epoch: 5| Step: 5
Training loss: 3.444411386994365
Validation loss: 3.3329287857759113

Epoch: 5| Step: 6
Training loss: 3.1623017863402323
Validation loss: 3.332820784222427

Epoch: 5| Step: 7
Training loss: 3.808257196668387
Validation loss: 3.329215706452224

Epoch: 5| Step: 8
Training loss: 3.5338035060743627
Validation loss: 3.3291525453520103

Epoch: 5| Step: 9
Training loss: 4.090793619549163
Validation loss: 3.328562810404599

Epoch: 5| Step: 10
Training loss: 4.255438074316873
Validation loss: 3.326747245723461

Epoch: 15| Step: 0
Training loss: 3.739411728232422
Validation loss: 3.32469572515765

Epoch: 5| Step: 1
Training loss: 3.609945673229983
Validation loss: 3.323666059916098

Epoch: 5| Step: 2
Training loss: 4.450211706376156
Validation loss: 3.3213820095915225

Epoch: 5| Step: 3
Training loss: 3.094100469909713
Validation loss: 3.319742865344855

Epoch: 5| Step: 4
Training loss: 3.505096675611573
Validation loss: 3.3189982939090803

Epoch: 5| Step: 5
Training loss: 3.5169688729217645
Validation loss: 3.316235960657353

Epoch: 5| Step: 6
Training loss: 3.2895163904730613
Validation loss: 3.315574989491818

Epoch: 5| Step: 7
Training loss: 3.328518696454398
Validation loss: 3.315279887930943

Epoch: 5| Step: 8
Training loss: 3.4204753643521024
Validation loss: 3.3132241096707773

Epoch: 5| Step: 9
Training loss: 3.298065549116932
Validation loss: 3.3117029365298034

Epoch: 5| Step: 10
Training loss: 3.7535749561147536
Validation loss: 3.3111620488111613

Epoch: 16| Step: 0
Training loss: 4.004122278852011
Validation loss: 3.3095686548248895

Epoch: 5| Step: 1
Training loss: 3.0876100281172136
Validation loss: 3.3117487653996234

Epoch: 5| Step: 2
Training loss: 3.21482995587677
Validation loss: 3.309119474835621

Epoch: 5| Step: 3
Training loss: 3.1836072301286693
Validation loss: 3.3093974675133944

Epoch: 5| Step: 4
Training loss: 3.9962357452014245
Validation loss: 3.3089352661125195

Epoch: 5| Step: 5
Training loss: 3.538126773372193
Validation loss: 3.3095164407324034

Epoch: 5| Step: 6
Training loss: 3.275055187430113
Validation loss: 3.3115443149130788

Epoch: 5| Step: 7
Training loss: 3.7958691681483465
Validation loss: 3.313074190258567

Epoch: 5| Step: 8
Training loss: 3.9917578419338184
Validation loss: 3.3123126403610144

Epoch: 5| Step: 9
Training loss: 3.6211274607384456
Validation loss: 3.3110470532995797

Epoch: 5| Step: 10
Training loss: 3.144052030642419
Validation loss: 3.306408550763385

Epoch: 17| Step: 0
Training loss: 3.196319346833692
Validation loss: 3.304541273975781

Epoch: 5| Step: 1
Training loss: 4.022200014487465
Validation loss: 3.3028076832838753

Epoch: 5| Step: 2
Training loss: 4.011443458330775
Validation loss: 3.300490213218363

Epoch: 5| Step: 3
Training loss: 3.492510684631213
Validation loss: 3.2987995619914803

Epoch: 5| Step: 4
Training loss: 3.458250083074525
Validation loss: 3.2971482052180154

Epoch: 5| Step: 5
Training loss: 3.7240529437373455
Validation loss: 3.296151375760784

Epoch: 5| Step: 6
Training loss: 2.891852370866759
Validation loss: 3.2955479655482436

Epoch: 5| Step: 7
Training loss: 3.359102175967392
Validation loss: 3.2940659730673056

Epoch: 5| Step: 8
Training loss: 3.1176905787750826
Validation loss: 3.2933121526497953

Epoch: 5| Step: 9
Training loss: 3.8279164782972126
Validation loss: 3.2925605702438663

Epoch: 5| Step: 10
Training loss: 3.7003722441780638
Validation loss: 3.2909709080361162

Epoch: 18| Step: 0
Training loss: 3.583050531864099
Validation loss: 3.2906867069497663

Epoch: 5| Step: 1
Training loss: 3.5696876696994235
Validation loss: 3.2887409604395472

Epoch: 5| Step: 2
Training loss: 3.5782088224096174
Validation loss: 3.2886124539926125

Epoch: 5| Step: 3
Training loss: 3.600372581275308
Validation loss: 3.28767456423443

Epoch: 5| Step: 4
Training loss: 3.3748881003585
Validation loss: 3.285351187132634

Epoch: 5| Step: 5
Training loss: 3.673895876319058
Validation loss: 3.284111994468267

Epoch: 5| Step: 6
Training loss: 3.3683618325436067
Validation loss: 3.284424383385161

Epoch: 5| Step: 7
Training loss: 2.8464726420202986
Validation loss: 3.2828870815691595

Epoch: 5| Step: 8
Training loss: 3.6850373401587477
Validation loss: 3.28131083301694

Epoch: 5| Step: 9
Training loss: 3.740524272789464
Validation loss: 3.2800404824945844

Epoch: 5| Step: 10
Training loss: 3.780334235658082
Validation loss: 3.2793318838285708

Epoch: 19| Step: 0
Training loss: 3.2609014343694676
Validation loss: 3.278789346501151

Epoch: 5| Step: 1
Training loss: 3.6020744439819388
Validation loss: 3.2770673666654524

Epoch: 5| Step: 2
Training loss: 3.5597601276122095
Validation loss: 3.276686075513386

Epoch: 5| Step: 3
Training loss: 3.5768590295072817
Validation loss: 3.276881473496194

Epoch: 5| Step: 4
Training loss: 3.8989788283511704
Validation loss: 3.2736664266945996

Epoch: 5| Step: 5
Training loss: 3.2609096231626187
Validation loss: 3.2734247014977633

Epoch: 5| Step: 6
Training loss: 3.822329372991334
Validation loss: 3.2720454671248924

Epoch: 5| Step: 7
Training loss: 3.4893219048042385
Validation loss: 3.2712514132143045

Epoch: 5| Step: 8
Training loss: 3.5636119780210387
Validation loss: 3.270094138559663

Epoch: 5| Step: 9
Training loss: 3.329867627602995
Validation loss: 3.268236759250347

Epoch: 5| Step: 10
Training loss: 3.2901255867128802
Validation loss: 3.267855166551783

Epoch: 20| Step: 0
Training loss: 3.4120926051390987
Validation loss: 3.2661435629661835

Epoch: 5| Step: 1
Training loss: 3.1806756061254293
Validation loss: 3.264667310699401

Epoch: 5| Step: 2
Training loss: 3.9850489626069843
Validation loss: 3.2644799590888516

Epoch: 5| Step: 3
Training loss: 3.598372960640293
Validation loss: 3.263088586267836

Epoch: 5| Step: 4
Training loss: 4.177953513712682
Validation loss: 3.261464945327071

Epoch: 5| Step: 5
Training loss: 3.390580700000419
Validation loss: 3.2613177788848597

Epoch: 5| Step: 6
Training loss: 3.6477508879064326
Validation loss: 3.2597433872816466

Epoch: 5| Step: 7
Training loss: 3.4289682107621644
Validation loss: 3.2597348290699397

Epoch: 5| Step: 8
Training loss: 3.006746811767776
Validation loss: 3.2572015064602393

Epoch: 5| Step: 9
Training loss: 3.7053734757659273
Validation loss: 3.2568475999946354

Epoch: 5| Step: 10
Training loss: 2.783519119260074
Validation loss: 3.256365696997012

Epoch: 21| Step: 0
Training loss: 2.9641059289142664
Validation loss: 3.2549924706863314

Epoch: 5| Step: 1
Training loss: 3.797501877262538
Validation loss: 3.2555930260865886

Epoch: 5| Step: 2
Training loss: 3.3670654274747185
Validation loss: 3.254385069996819

Epoch: 5| Step: 3
Training loss: 4.086957348374416
Validation loss: 3.252748997471365

Epoch: 5| Step: 4
Training loss: 3.7579975042979434
Validation loss: 3.252060348337967

Epoch: 5| Step: 5
Training loss: 3.471256209887512
Validation loss: 3.2501438762159176

Epoch: 5| Step: 6
Training loss: 3.5921263634389433
Validation loss: 3.249128928562411

Epoch: 5| Step: 7
Training loss: 3.334514233900708
Validation loss: 3.252981942976444

Epoch: 5| Step: 8
Training loss: 3.155846145022321
Validation loss: 3.2783499360225723

Epoch: 5| Step: 9
Training loss: 3.9072818461394485
Validation loss: 3.245977434966638

Epoch: 5| Step: 10
Training loss: 2.7977086535001074
Validation loss: 3.245950608847421

Epoch: 22| Step: 0
Training loss: 4.2136142694594145
Validation loss: 3.248242071608088

Epoch: 5| Step: 1
Training loss: 3.728749399265058
Validation loss: 3.2608145199434113

Epoch: 5| Step: 2
Training loss: 3.245194036151828
Validation loss: 3.2908124790229865

Epoch: 5| Step: 3
Training loss: 3.5164517257112764
Validation loss: 3.2929754577178363

Epoch: 5| Step: 4
Training loss: 3.758806442176955
Validation loss: 3.2601976417734617

Epoch: 5| Step: 5
Training loss: 3.5930232100932833
Validation loss: 3.2494158097502615

Epoch: 5| Step: 6
Training loss: 3.2187590367458854
Validation loss: 3.249352987866425

Epoch: 5| Step: 7
Training loss: 3.0260990069543556
Validation loss: 3.247660515058472

Epoch: 5| Step: 8
Training loss: 4.175617039933687
Validation loss: 3.2470449560413464

Epoch: 5| Step: 9
Training loss: 2.3178757739215707
Validation loss: 3.2420435268965084

Epoch: 5| Step: 10
Training loss: 3.3551286696023155
Validation loss: 3.2414863699094227

Epoch: 23| Step: 0
Training loss: 3.2121008183391897
Validation loss: 3.2410735075551855

Epoch: 5| Step: 1
Training loss: 2.9313182310447417
Validation loss: 3.2433101627332563

Epoch: 5| Step: 2
Training loss: 3.7763142805238132
Validation loss: 3.250267633062738

Epoch: 5| Step: 3
Training loss: 3.401597932167537
Validation loss: 3.250652556145876

Epoch: 5| Step: 4
Training loss: 3.268934990806806
Validation loss: 3.2508802018709777

Epoch: 5| Step: 5
Training loss: 3.285586298351266
Validation loss: 3.2438647414594346

Epoch: 5| Step: 6
Training loss: 4.256846803116151
Validation loss: 3.239640120294878

Epoch: 5| Step: 7
Training loss: 3.715381539263472
Validation loss: 3.236822991538044

Epoch: 5| Step: 8
Training loss: 3.161117124710069
Validation loss: 3.2333791724675778

Epoch: 5| Step: 9
Training loss: 3.533500291970342
Validation loss: 3.23063810143457

Epoch: 5| Step: 10
Training loss: 3.7341244665404782
Validation loss: 3.2309914653203236

Epoch: 24| Step: 0
Training loss: 3.4798347760582757
Validation loss: 3.227939478645457

Epoch: 5| Step: 1
Training loss: 3.1492658334788115
Validation loss: 3.2304268882981266

Epoch: 5| Step: 2
Training loss: 3.8092499935427795
Validation loss: 3.2270880342702952

Epoch: 5| Step: 3
Training loss: 2.817886281108895
Validation loss: 3.2250836408827466

Epoch: 5| Step: 4
Training loss: 3.2355197226050425
Validation loss: 3.223340313682638

Epoch: 5| Step: 5
Training loss: 3.5827646617465625
Validation loss: 3.223189078464459

Epoch: 5| Step: 6
Training loss: 4.383651897810961
Validation loss: 3.222417078773042

Epoch: 5| Step: 7
Training loss: 3.2174872726983064
Validation loss: 3.2202239205690724

Epoch: 5| Step: 8
Training loss: 3.716980072173322
Validation loss: 3.2203757265062745

Epoch: 5| Step: 9
Training loss: 3.456525414308175
Validation loss: 3.218756738136567

Epoch: 5| Step: 10
Training loss: 3.1416571140565686
Validation loss: 3.21816601121307

Epoch: 25| Step: 0
Training loss: 2.8605536027782588
Validation loss: 3.2169396717256706

Epoch: 5| Step: 1
Training loss: 3.294663831265242
Validation loss: 3.2165877106880383

Epoch: 5| Step: 2
Training loss: 2.899493166601526
Validation loss: 3.2151257609772106

Epoch: 5| Step: 3
Training loss: 3.712936088046884
Validation loss: 3.215375336064759

Epoch: 5| Step: 4
Training loss: 4.093954066657605
Validation loss: 3.2133598399184913

Epoch: 5| Step: 5
Training loss: 3.7864516869040203
Validation loss: 3.2122169697776934

Epoch: 5| Step: 6
Training loss: 3.0831951076007504
Validation loss: 3.2111783325683128

Epoch: 5| Step: 7
Training loss: 3.298278220707193
Validation loss: 3.2098243651605824

Epoch: 5| Step: 8
Training loss: 3.523243427218239
Validation loss: 3.2080643925628403

Epoch: 5| Step: 9
Training loss: 3.2723200308648623
Validation loss: 3.207529251430359

Epoch: 5| Step: 10
Training loss: 4.1870791095615285
Validation loss: 3.206662814804212

Epoch: 26| Step: 0
Training loss: 3.6130603289726424
Validation loss: 3.2053609475791496

Epoch: 5| Step: 1
Training loss: 3.591479438333072
Validation loss: 3.2039233981712

Epoch: 5| Step: 2
Training loss: 4.028157548795111
Validation loss: 3.2032864101508585

Epoch: 5| Step: 3
Training loss: 2.700036461901832
Validation loss: 3.2021580847177122

Epoch: 5| Step: 4
Training loss: 3.255270279358506
Validation loss: 3.20064091916685

Epoch: 5| Step: 5
Training loss: 3.191077823618785
Validation loss: 3.200438284725766

Epoch: 5| Step: 6
Training loss: 3.1360043368893433
Validation loss: 3.2005672444293234

Epoch: 5| Step: 7
Training loss: 3.7244017152553077
Validation loss: 3.1993345277508447

Epoch: 5| Step: 8
Training loss: 3.7727999257156455
Validation loss: 3.198893044306962

Epoch: 5| Step: 9
Training loss: 3.483885863316731
Validation loss: 3.1968651631749583

Epoch: 5| Step: 10
Training loss: 3.3825457954548983
Validation loss: 3.1956934764581377

Epoch: 27| Step: 0
Training loss: 2.987568050870397
Validation loss: 3.195465087456582

Epoch: 5| Step: 1
Training loss: 4.00414442889138
Validation loss: 3.1937588588380703

Epoch: 5| Step: 2
Training loss: 3.4574326104404847
Validation loss: 3.1940532952823952

Epoch: 5| Step: 3
Training loss: 3.364974921304511
Validation loss: 3.1917963527936073

Epoch: 5| Step: 4
Training loss: 2.9904241321036995
Validation loss: 3.192448237858387

Epoch: 5| Step: 5
Training loss: 3.4019047730947847
Validation loss: 3.190658841090195

Epoch: 5| Step: 6
Training loss: 3.9177275228736166
Validation loss: 3.189361400342913

Epoch: 5| Step: 7
Training loss: 3.7719966435827086
Validation loss: 3.189678915215817

Epoch: 5| Step: 8
Training loss: 3.5676946412355117
Validation loss: 3.1881431398850797

Epoch: 5| Step: 9
Training loss: 3.7476379584939012
Validation loss: 3.186750883336065

Epoch: 5| Step: 10
Training loss: 2.2598781969786432
Validation loss: 3.186015157033722

Epoch: 28| Step: 0
Training loss: 4.146019757295044
Validation loss: 3.185944733720134

Epoch: 5| Step: 1
Training loss: 2.881241698677202
Validation loss: 3.18478594411553

Epoch: 5| Step: 2
Training loss: 3.2591844043982166
Validation loss: 3.1847798247671104

Epoch: 5| Step: 3
Training loss: 3.0098890394371884
Validation loss: 3.1826974768360214

Epoch: 5| Step: 4
Training loss: 3.2221119923938586
Validation loss: 3.1840331502544887

Epoch: 5| Step: 5
Training loss: 3.6701774406673975
Validation loss: 3.1884097731845067

Epoch: 5| Step: 6
Training loss: 3.78431703379784
Validation loss: 3.1925527083067298

Epoch: 5| Step: 7
Training loss: 3.939426858915597
Validation loss: 3.1815328381912593

Epoch: 5| Step: 8
Training loss: 3.606389119391965
Validation loss: 3.197578261291429

Epoch: 5| Step: 9
Training loss: 3.400904249109182
Validation loss: 3.2873288304721546

Epoch: 5| Step: 10
Training loss: 2.7128772666607763
Validation loss: 3.212969008847709

Epoch: 29| Step: 0
Training loss: 3.766333042549788
Validation loss: 3.2106266149174076

Epoch: 5| Step: 1
Training loss: 3.8645111378852133
Validation loss: 3.1969309202086107

Epoch: 5| Step: 2
Training loss: 3.0378876992037793
Validation loss: 3.2130146135217243

Epoch: 5| Step: 3
Training loss: 3.7359978250174555
Validation loss: 3.275198831841959

Epoch: 5| Step: 4
Training loss: 3.40108062737403
Validation loss: 3.290407349296606

Epoch: 5| Step: 5
Training loss: 3.787225336873725
Validation loss: 3.3032651177301173

Epoch: 5| Step: 6
Training loss: 3.446333199853732
Validation loss: 3.3114241085091503

Epoch: 5| Step: 7
Training loss: 3.0343200238607246
Validation loss: 3.2966268391891296

Epoch: 5| Step: 8
Training loss: 3.59853621499423
Validation loss: 3.2781649257719705

Epoch: 5| Step: 9
Training loss: 3.8451602488683796
Validation loss: 3.269794725333036

Epoch: 5| Step: 10
Training loss: 2.89231353105964
Validation loss: 3.265851175826945

Epoch: 30| Step: 0
Training loss: 3.024858165600012
Validation loss: 3.268199946638082

Epoch: 5| Step: 1
Training loss: 3.6766138542534725
Validation loss: 3.267347888241879

Epoch: 5| Step: 2
Training loss: 3.601952653716689
Validation loss: 3.2567324278812793

Epoch: 5| Step: 3
Training loss: 3.814092584887492
Validation loss: 3.2557052439111067

Epoch: 5| Step: 4
Training loss: 3.686706457584402
Validation loss: 3.2581748679227585

Epoch: 5| Step: 5
Training loss: 3.5893521143472458
Validation loss: 3.2491043109210067

Epoch: 5| Step: 6
Training loss: 3.735407858031667
Validation loss: 3.24461113920648

Epoch: 5| Step: 7
Training loss: 3.0391089428488587
Validation loss: 3.2424128470281275

Epoch: 5| Step: 8
Training loss: 3.7188094959788964
Validation loss: 3.242722294339735

Epoch: 5| Step: 9
Training loss: 2.9972784095033127
Validation loss: 3.2405399371112913

Epoch: 5| Step: 10
Training loss: 3.516804137111726
Validation loss: 3.2404617035687435

Epoch: 31| Step: 0
Training loss: 3.3734726452112045
Validation loss: 3.2389564906124435

Epoch: 5| Step: 1
Training loss: 3.619195697857419
Validation loss: 3.238330429568403

Epoch: 5| Step: 2
Training loss: 3.4011019379599636
Validation loss: 3.236501535118947

Epoch: 5| Step: 3
Training loss: 3.7150538692958435
Validation loss: 3.2346071969702272

Epoch: 5| Step: 4
Training loss: 3.949054537263476
Validation loss: 3.2330412744092025

Epoch: 5| Step: 5
Training loss: 3.901181281748697
Validation loss: 3.2316516826723354

Epoch: 5| Step: 6
Training loss: 2.76640679467968
Validation loss: 3.2308653759996373

Epoch: 5| Step: 7
Training loss: 3.920420950844913
Validation loss: 3.2283274554775323

Epoch: 5| Step: 8
Training loss: 2.7297256615541814
Validation loss: 3.2271211928979002

Epoch: 5| Step: 9
Training loss: 3.5173114715785614
Validation loss: 3.2261121092338603

Epoch: 5| Step: 10
Training loss: 3.166624788375472
Validation loss: 3.2248013563602487

Epoch: 32| Step: 0
Training loss: 3.619330082652366
Validation loss: 3.223686500357202

Epoch: 5| Step: 1
Training loss: 3.55175714123069
Validation loss: 3.22261762638756

Epoch: 5| Step: 2
Training loss: 3.3068544754663187
Validation loss: 3.221974447200816

Epoch: 5| Step: 3
Training loss: 3.0890525837007314
Validation loss: 3.22066645362984

Epoch: 5| Step: 4
Training loss: 3.746792502366008
Validation loss: 3.218787860816941

Epoch: 5| Step: 5
Training loss: 3.4100059310100805
Validation loss: 3.220083386425489

Epoch: 5| Step: 6
Training loss: 3.687247962743667
Validation loss: 3.2174164155587195

Epoch: 5| Step: 7
Training loss: 3.0814847473727687
Validation loss: 3.2156616919986574

Epoch: 5| Step: 8
Training loss: 3.182904389992725
Validation loss: 3.214562804875023

Epoch: 5| Step: 9
Training loss: 3.4892866473497195
Validation loss: 3.215029913837865

Epoch: 5| Step: 10
Training loss: 4.038112978861997
Validation loss: 3.2143101331385844

Epoch: 33| Step: 0
Training loss: 3.5462218367998215
Validation loss: 3.2119272274232085

Epoch: 5| Step: 1
Training loss: 2.646183821725047
Validation loss: 3.2109153137406614

Epoch: 5| Step: 2
Training loss: 2.715681251496391
Validation loss: 3.210648239444395

Epoch: 5| Step: 3
Training loss: 3.3313517084394233
Validation loss: 3.209127675935311

Epoch: 5| Step: 4
Training loss: 3.9595371758081077
Validation loss: 3.2080981985183175

Epoch: 5| Step: 5
Training loss: 3.2640398914947473
Validation loss: 3.2073783337464836

Epoch: 5| Step: 6
Training loss: 3.831935931934431
Validation loss: 3.2062856092084537

Epoch: 5| Step: 7
Training loss: 3.4137024154894573
Validation loss: 3.206421347250551

Epoch: 5| Step: 8
Training loss: 4.167028920003028
Validation loss: 3.203146052497693

Epoch: 5| Step: 9
Training loss: 3.4163564835837614
Validation loss: 3.201821430067519

Epoch: 5| Step: 10
Training loss: 3.5402617117482853
Validation loss: 3.2001305005550984

Epoch: 34| Step: 0
Training loss: 3.615520579314719
Validation loss: 3.197904981120366

Epoch: 5| Step: 1
Training loss: 4.308377493085397
Validation loss: 3.1921444762517197

Epoch: 5| Step: 2
Training loss: 3.5450624380275957
Validation loss: 3.1847819047995154

Epoch: 5| Step: 3
Training loss: 3.0100797752885344
Validation loss: 3.1308621541067607

Epoch: 5| Step: 4
Training loss: 2.5811065079751114
Validation loss: 3.1185284059834415

Epoch: 5| Step: 5
Training loss: 3.412934070968603
Validation loss: 3.116066233991048

Epoch: 5| Step: 6
Training loss: 3.1394964059711024
Validation loss: 3.116176379863239

Epoch: 5| Step: 7
Training loss: 3.2061434782005027
Validation loss: 3.115994006006605

Epoch: 5| Step: 8
Training loss: 3.0410074712880415
Validation loss: 3.113313917854116

Epoch: 5| Step: 9
Training loss: 3.4891983654938064
Validation loss: 3.1121418025591225

Epoch: 5| Step: 10
Training loss: 3.9718169129308754
Validation loss: 3.1100523077987527

Epoch: 35| Step: 0
Training loss: 3.2730626731534085
Validation loss: 3.1083374238069097

Epoch: 5| Step: 1
Training loss: 3.744335346600939
Validation loss: 3.104943959338411

Epoch: 5| Step: 2
Training loss: 3.150083201687103
Validation loss: 3.1030092252873285

Epoch: 5| Step: 3
Training loss: 3.008743736472938
Validation loss: 3.0995593723417154

Epoch: 5| Step: 4
Training loss: 3.885666103725475
Validation loss: 3.0964443969468136

Epoch: 5| Step: 5
Training loss: 3.8132133441889637
Validation loss: 3.0948720517065866

Epoch: 5| Step: 6
Training loss: 2.8119352833394315
Validation loss: 3.0970186591860016

Epoch: 5| Step: 7
Training loss: 3.1579478012612436
Validation loss: 3.099144518333017

Epoch: 5| Step: 8
Training loss: 3.1825316359991995
Validation loss: 3.1056501140946904

Epoch: 5| Step: 9
Training loss: 3.4223906942764466
Validation loss: 3.1251995277284967

Epoch: 5| Step: 10
Training loss: 3.5669094704191773
Validation loss: 3.101576994596558

Epoch: 36| Step: 0
Training loss: 3.438833359568028
Validation loss: 3.0956091674032242

Epoch: 5| Step: 1
Training loss: 3.186636863978802
Validation loss: 3.091618036683115

Epoch: 5| Step: 2
Training loss: 3.3815213529958084
Validation loss: 3.090194375888069

Epoch: 5| Step: 3
Training loss: 3.37786376394728
Validation loss: 3.089426459497721

Epoch: 5| Step: 4
Training loss: 4.230755487166269
Validation loss: 3.0873641284906284

Epoch: 5| Step: 5
Training loss: 3.008205477321425
Validation loss: 3.085141205403986

Epoch: 5| Step: 6
Training loss: 3.615583356586161
Validation loss: 3.0840212235599678

Epoch: 5| Step: 7
Training loss: 3.732913573259146
Validation loss: 3.0840785687128793

Epoch: 5| Step: 8
Training loss: 2.547978916691817
Validation loss: 3.0833119685711337

Epoch: 5| Step: 9
Training loss: 2.685505237603358
Validation loss: 3.0822022305349517

Epoch: 5| Step: 10
Training loss: 3.5195240693860574
Validation loss: 3.080945311324096

Epoch: 37| Step: 0
Training loss: 3.4832655162384922
Validation loss: 3.0817805096377393

Epoch: 5| Step: 1
Training loss: 3.9239501326539163
Validation loss: 3.080386096578191

Epoch: 5| Step: 2
Training loss: 3.3726696870389032
Validation loss: 3.0793638350048753

Epoch: 5| Step: 3
Training loss: 3.506707848015778
Validation loss: 3.078326241866219

Epoch: 5| Step: 4
Training loss: 2.4020162219564614
Validation loss: 3.076751364175389

Epoch: 5| Step: 5
Training loss: 3.9647352682973254
Validation loss: 3.0762755923895373

Epoch: 5| Step: 6
Training loss: 3.391388556648012
Validation loss: 3.075816456722182

Epoch: 5| Step: 7
Training loss: 3.255123208522395
Validation loss: 3.07674310685792

Epoch: 5| Step: 8
Training loss: 3.210876464263645
Validation loss: 3.0761506960716467

Epoch: 5| Step: 9
Training loss: 2.9320966656871312
Validation loss: 3.0753277551679954

Epoch: 5| Step: 10
Training loss: 3.1342348594181164
Validation loss: 3.083545293952875

Epoch: 38| Step: 0
Training loss: 3.386122566379708
Validation loss: 3.09180679274612

Epoch: 5| Step: 1
Training loss: 3.114427611541835
Validation loss: 3.084074281953106

Epoch: 5| Step: 2
Training loss: 3.3400062209202743
Validation loss: 3.0759114673124457

Epoch: 5| Step: 3
Training loss: 3.620238498397353
Validation loss: 3.0730197008371043

Epoch: 5| Step: 4
Training loss: 3.6339435088365146
Validation loss: 3.0685353965732785

Epoch: 5| Step: 5
Training loss: 3.3291525530525905
Validation loss: 3.0670880239773446

Epoch: 5| Step: 6
Training loss: 3.0555860363759684
Validation loss: 3.0771857361542536

Epoch: 5| Step: 7
Training loss: 3.733707639685713
Validation loss: 3.0651296785878053

Epoch: 5| Step: 8
Training loss: 3.6683874571737523
Validation loss: 3.066166066145905

Epoch: 5| Step: 9
Training loss: 2.284259952930545
Validation loss: 3.070080382620946

Epoch: 5| Step: 10
Training loss: 3.4013019985947337
Validation loss: 3.0730153452590256

Epoch: 39| Step: 0
Training loss: 3.463016342058433
Validation loss: 3.0795751653338708

Epoch: 5| Step: 1
Training loss: 3.496662319557632
Validation loss: 3.0783526116409026

Epoch: 5| Step: 2
Training loss: 3.403439823717615
Validation loss: 3.068917594356363

Epoch: 5| Step: 3
Training loss: 2.6208888057625854
Validation loss: 3.066164805297409

Epoch: 5| Step: 4
Training loss: 3.3069050880841258
Validation loss: 3.062101606515543

Epoch: 5| Step: 5
Training loss: 3.859499539362058
Validation loss: 3.0635059471692503

Epoch: 5| Step: 6
Training loss: 3.101774347790996
Validation loss: 3.060754253734067

Epoch: 5| Step: 7
Training loss: 3.5720205415859128
Validation loss: 3.057300408642531

Epoch: 5| Step: 8
Training loss: 3.0999533372874137
Validation loss: 3.0560934968905213

Epoch: 5| Step: 9
Training loss: 3.23032232134886
Validation loss: 3.0542412761281375

Epoch: 5| Step: 10
Training loss: 3.524346684725863
Validation loss: 3.054711342945051

Epoch: 40| Step: 0
Training loss: 3.1334909669981164
Validation loss: 3.0574270392682754

Epoch: 5| Step: 1
Training loss: 3.0060187998353203
Validation loss: 3.0714415087754645

Epoch: 5| Step: 2
Training loss: 3.564455265410316
Validation loss: 3.086004813225844

Epoch: 5| Step: 3
Training loss: 3.659941545863899
Validation loss: 3.0944938954430685

Epoch: 5| Step: 4
Training loss: 3.4350507854055707
Validation loss: 3.087588319033784

Epoch: 5| Step: 5
Training loss: 3.1245524276654377
Validation loss: 3.070495960697685

Epoch: 5| Step: 6
Training loss: 3.815508921464206
Validation loss: 3.0512941835322938

Epoch: 5| Step: 7
Training loss: 2.9221168458776448
Validation loss: 3.051260801262086

Epoch: 5| Step: 8
Training loss: 3.6173157638318103
Validation loss: 3.0482987065893075

Epoch: 5| Step: 9
Training loss: 2.9058079537181394
Validation loss: 3.0497504268203537

Epoch: 5| Step: 10
Training loss: 3.3901003945937656
Validation loss: 3.0549682390829

Epoch: 41| Step: 0
Training loss: 2.812903311740155
Validation loss: 3.052687857273075

Epoch: 5| Step: 1
Training loss: 3.36901013107792
Validation loss: 3.0478430603419535

Epoch: 5| Step: 2
Training loss: 3.1930103916246417
Validation loss: 3.045750900999632

Epoch: 5| Step: 3
Training loss: 3.486615200671871
Validation loss: 3.0434929953759657

Epoch: 5| Step: 4
Training loss: 3.290247905168518
Validation loss: 3.0413961139889145

Epoch: 5| Step: 5
Training loss: 3.226351751875647
Validation loss: 3.0411144541412227

Epoch: 5| Step: 6
Training loss: 3.4082238314199076
Validation loss: 3.0413629745763164

Epoch: 5| Step: 7
Training loss: 3.8406431466179054
Validation loss: 3.0409390878283156

Epoch: 5| Step: 8
Training loss: 3.193438813041001
Validation loss: 3.0373015700459733

Epoch: 5| Step: 9
Training loss: 3.3672850698686405
Validation loss: 3.0371618154436772

Epoch: 5| Step: 10
Training loss: 3.3641764549306368
Validation loss: 3.036423941411338

Epoch: 42| Step: 0
Training loss: 3.499589214741644
Validation loss: 3.0370234894305135

Epoch: 5| Step: 1
Training loss: 3.003647811745237
Validation loss: 3.037378394692538

Epoch: 5| Step: 2
Training loss: 3.057518937059274
Validation loss: 3.0369738466223946

Epoch: 5| Step: 3
Training loss: 2.600515893959098
Validation loss: 3.037230245121659

Epoch: 5| Step: 4
Training loss: 4.559103969077092
Validation loss: 3.0377789047471406

Epoch: 5| Step: 5
Training loss: 3.4415520107823334
Validation loss: 3.0353544454030392

Epoch: 5| Step: 6
Training loss: 4.202709078151979
Validation loss: 3.0372726256749476

Epoch: 5| Step: 7
Training loss: 3.377744618331149
Validation loss: 3.0352084167417437

Epoch: 5| Step: 8
Training loss: 2.1537769897328474
Validation loss: 3.0312238158657716

Epoch: 5| Step: 9
Training loss: 2.7395830529119736
Validation loss: 3.0318503783756543

Epoch: 5| Step: 10
Training loss: 3.1075865236176483
Validation loss: 3.0331824718049236

Epoch: 43| Step: 0
Training loss: 3.808387038661207
Validation loss: 3.0340064856817595

Epoch: 5| Step: 1
Training loss: 3.331541501687443
Validation loss: 3.032483983749238

Epoch: 5| Step: 2
Training loss: 3.1972280417384846
Validation loss: 3.029422164518662

Epoch: 5| Step: 3
Training loss: 3.424477480270299
Validation loss: 3.0274915755293157

Epoch: 5| Step: 4
Training loss: 2.9208992537507217
Validation loss: 3.0340000047646063

Epoch: 5| Step: 5
Training loss: 3.539817746314635
Validation loss: 3.032696344099523

Epoch: 5| Step: 6
Training loss: 2.8283383620904363
Validation loss: 3.032137605622746

Epoch: 5| Step: 7
Training loss: 2.585690581642858
Validation loss: 3.028834320964375

Epoch: 5| Step: 8
Training loss: 3.104232446029049
Validation loss: 3.0284197303234843

Epoch: 5| Step: 9
Training loss: 3.794001744070341
Validation loss: 3.0247957676788784

Epoch: 5| Step: 10
Training loss: 3.635292568475149
Validation loss: 3.024779627898669

Epoch: 44| Step: 0
Training loss: 2.7187013292888937
Validation loss: 3.0246708179537887

Epoch: 5| Step: 1
Training loss: 3.52271068714522
Validation loss: 3.0226284813419007

Epoch: 5| Step: 2
Training loss: 2.8958987404734446
Validation loss: 3.022533182617342

Epoch: 5| Step: 3
Training loss: 2.693220393610967
Validation loss: 3.0240759233139305

Epoch: 5| Step: 4
Training loss: 3.1264849377209383
Validation loss: 3.0245453519568555

Epoch: 5| Step: 5
Training loss: 3.355691282911176
Validation loss: 3.02799055278781

Epoch: 5| Step: 6
Training loss: 3.810670507508734
Validation loss: 3.034541748976401

Epoch: 5| Step: 7
Training loss: 3.4594617327919464
Validation loss: 3.022069753669832

Epoch: 5| Step: 8
Training loss: 3.0951152833042195
Validation loss: 3.018900974093838

Epoch: 5| Step: 9
Training loss: 3.2744431874077513
Validation loss: 3.019234812208671

Epoch: 5| Step: 10
Training loss: 4.142246835600927
Validation loss: 3.0165882505147454

Epoch: 45| Step: 0
Training loss: 3.6050825480455586
Validation loss: 3.013189805918035

Epoch: 5| Step: 1
Training loss: 2.9366788325092035
Validation loss: 3.0164619571010034

Epoch: 5| Step: 2
Training loss: 2.2910683862410894
Validation loss: 3.018170537533743

Epoch: 5| Step: 3
Training loss: 3.4692526788164475
Validation loss: 3.020708802187826

Epoch: 5| Step: 4
Training loss: 2.5229435014964494
Validation loss: 3.0224629375465657

Epoch: 5| Step: 5
Training loss: 3.6243777563167168
Validation loss: 3.0176994613941868

Epoch: 5| Step: 6
Training loss: 3.619508991135961
Validation loss: 3.0109545929694104

Epoch: 5| Step: 7
Training loss: 3.0276779679423433
Validation loss: 3.009749676338071

Epoch: 5| Step: 8
Training loss: 3.0509722426410586
Validation loss: 3.0097085266282715

Epoch: 5| Step: 9
Training loss: 3.9885330344892362
Validation loss: 3.010747957244209

Epoch: 5| Step: 10
Training loss: 3.784013479212813
Validation loss: 3.0095424604101284

Epoch: 46| Step: 0
Training loss: 3.676113069092534
Validation loss: 3.009230298650648

Epoch: 5| Step: 1
Training loss: 2.756062327805475
Validation loss: 3.006821733082214

Epoch: 5| Step: 2
Training loss: 3.1775702098229854
Validation loss: 3.005490281691469

Epoch: 5| Step: 3
Training loss: 3.291759554039281
Validation loss: 3.007720027887668

Epoch: 5| Step: 4
Training loss: 3.5202595320304955
Validation loss: 3.006607630444101

Epoch: 5| Step: 5
Training loss: 2.856928711767855
Validation loss: 3.011110559568216

Epoch: 5| Step: 6
Training loss: 3.4036988670383326
Validation loss: 3.00892538580943

Epoch: 5| Step: 7
Training loss: 3.0224775027312614
Validation loss: 3.0074836626845887

Epoch: 5| Step: 8
Training loss: 3.391558259423386
Validation loss: 3.004346808960128

Epoch: 5| Step: 9
Training loss: 3.7862005692608767
Validation loss: 3.0009602715498382

Epoch: 5| Step: 10
Training loss: 3.0673423941741724
Validation loss: 2.9967233220156193

Epoch: 47| Step: 0
Training loss: 3.8795722320554042
Validation loss: 2.9948006612777283

Epoch: 5| Step: 1
Training loss: 3.551624093148886
Validation loss: 2.9934642613169187

Epoch: 5| Step: 2
Training loss: 3.2467642595426383
Validation loss: 2.9935375102503787

Epoch: 5| Step: 3
Training loss: 2.972898776653936
Validation loss: 3.001857353517387

Epoch: 5| Step: 4
Training loss: 3.6615757423702515
Validation loss: 2.9947493811890604

Epoch: 5| Step: 5
Training loss: 3.048080284192704
Validation loss: 2.995417456746643

Epoch: 5| Step: 6
Training loss: 3.452253965413238
Validation loss: 3.0005115496750006

Epoch: 5| Step: 7
Training loss: 2.7143444452887104
Validation loss: 3.002139830639251

Epoch: 5| Step: 8
Training loss: 3.0525020967393526
Validation loss: 2.999390287207659

Epoch: 5| Step: 9
Training loss: 3.025921730032715
Validation loss: 2.996321686002778

Epoch: 5| Step: 10
Training loss: 3.268701883403177
Validation loss: 2.993064120299864

Epoch: 48| Step: 0
Training loss: 2.913119329656923
Validation loss: 2.9908199444655827

Epoch: 5| Step: 1
Training loss: 3.1062052303288596
Validation loss: 2.9892358711263065

Epoch: 5| Step: 2
Training loss: 2.9260477064393338
Validation loss: 2.988086272582542

Epoch: 5| Step: 3
Training loss: 3.0382587380039934
Validation loss: 2.9875816552018812

Epoch: 5| Step: 4
Training loss: 3.578476801073372
Validation loss: 2.984836069646983

Epoch: 5| Step: 5
Training loss: 3.7347751546689683
Validation loss: 2.9855791147605384

Epoch: 5| Step: 6
Training loss: 3.050646516411041
Validation loss: 2.9854476968889405

Epoch: 5| Step: 7
Training loss: 2.8180779986122113
Validation loss: 2.9828975752701457

Epoch: 5| Step: 8
Training loss: 3.1121718513286103
Validation loss: 2.98330496286842

Epoch: 5| Step: 9
Training loss: 3.5812987532301315
Validation loss: 2.9839467129659263

Epoch: 5| Step: 10
Training loss: 3.979209992870243
Validation loss: 2.9851726335179833

Epoch: 49| Step: 0
Training loss: 3.495079942042747
Validation loss: 2.979701445879895

Epoch: 5| Step: 1
Training loss: 4.08459473933098
Validation loss: 2.9829887061384204

Epoch: 5| Step: 2
Training loss: 2.9309142939239345
Validation loss: 2.979049269547927

Epoch: 5| Step: 3
Training loss: 3.971860132557245
Validation loss: 2.9759912902815064

Epoch: 5| Step: 4
Training loss: 2.78129346149219
Validation loss: 2.9750733592363545

Epoch: 5| Step: 5
Training loss: 3.0739404729317594
Validation loss: 2.975120659664312

Epoch: 5| Step: 6
Training loss: 3.2586867808248248
Validation loss: 2.975139060199653

Epoch: 5| Step: 7
Training loss: 2.9922741909765516
Validation loss: 2.9743814385968177

Epoch: 5| Step: 8
Training loss: 2.8624431221321074
Validation loss: 2.9782301376380276

Epoch: 5| Step: 9
Training loss: 3.2960409402063866
Validation loss: 2.9786630645576526

Epoch: 5| Step: 10
Training loss: 2.7171261201915793
Validation loss: 2.9825706841023423

Epoch: 50| Step: 0
Training loss: 3.981873448781286
Validation loss: 2.989013086395791

Epoch: 5| Step: 1
Training loss: 3.533164526547734
Validation loss: 2.9811128580962705

Epoch: 5| Step: 2
Training loss: 3.2283465092484813
Validation loss: 2.9772178783859524

Epoch: 5| Step: 3
Training loss: 3.2133800562816095
Validation loss: 2.9710615354657786

Epoch: 5| Step: 4
Training loss: 2.9967239294072505
Validation loss: 2.968976329213531

Epoch: 5| Step: 5
Training loss: 2.91010021181365
Validation loss: 2.966663612326358

Epoch: 5| Step: 6
Training loss: 1.9130494219891185
Validation loss: 2.9640445778117153

Epoch: 5| Step: 7
Training loss: 3.5048100253221475
Validation loss: 2.9612699079595166

Epoch: 5| Step: 8
Training loss: 3.5019005656087856
Validation loss: 2.9634906911402776

Epoch: 5| Step: 9
Training loss: 3.354305825199862
Validation loss: 2.9612563351170387

Epoch: 5| Step: 10
Training loss: 3.304085462485528
Validation loss: 2.9606157825549744

Epoch: 51| Step: 0
Training loss: 3.425989055529214
Validation loss: 2.959639814657145

Epoch: 5| Step: 1
Training loss: 2.590323609420216
Validation loss: 2.960465174515408

Epoch: 5| Step: 2
Training loss: 3.1840358684570584
Validation loss: 2.96016168372559

Epoch: 5| Step: 3
Training loss: 3.863735808658362
Validation loss: 2.961258686431621

Epoch: 5| Step: 4
Training loss: 2.9283462098876525
Validation loss: 2.9610021830176763

Epoch: 5| Step: 5
Training loss: 3.59333639667312
Validation loss: 2.9621559818031926

Epoch: 5| Step: 6
Training loss: 3.14295485889571
Validation loss: 2.9589429351765046

Epoch: 5| Step: 7
Training loss: 3.3730686454313368
Validation loss: 2.955535678223302

Epoch: 5| Step: 8
Training loss: 3.2124619774850425
Validation loss: 2.957098380020512

Epoch: 5| Step: 9
Training loss: 3.1914911153802046
Validation loss: 2.9566548196020883

Epoch: 5| Step: 10
Training loss: 3.006775357663528
Validation loss: 2.956426877682731

Epoch: 52| Step: 0
Training loss: 2.9495338524238432
Validation loss: 2.9540415527193136

Epoch: 5| Step: 1
Training loss: 3.719278506381611
Validation loss: 2.955110107458748

Epoch: 5| Step: 2
Training loss: 2.489485277189447
Validation loss: 2.956200180842799

Epoch: 5| Step: 3
Training loss: 2.762723877409546
Validation loss: 2.9547015169201565

Epoch: 5| Step: 4
Training loss: 3.6725145148294924
Validation loss: 2.952319572999755

Epoch: 5| Step: 5
Training loss: 3.0944721650625135
Validation loss: 2.955018399655355

Epoch: 5| Step: 6
Training loss: 3.188901107120773
Validation loss: 2.9537051068889895

Epoch: 5| Step: 7
Training loss: 3.322966396872477
Validation loss: 2.9489922492820213

Epoch: 5| Step: 8
Training loss: 3.1301151373895864
Validation loss: 2.950947194804877

Epoch: 5| Step: 9
Training loss: 3.320433419213622
Validation loss: 2.948396013636885

Epoch: 5| Step: 10
Training loss: 3.8497109440875357
Validation loss: 2.9474067230983403

Epoch: 53| Step: 0
Training loss: 2.502731642848858
Validation loss: 2.9464646546426763

Epoch: 5| Step: 1
Training loss: 3.171898301513471
Validation loss: 2.9449934786773757

Epoch: 5| Step: 2
Training loss: 3.037467322154149
Validation loss: 2.946282094528409

Epoch: 5| Step: 3
Training loss: 2.7014883742745095
Validation loss: 2.944887532455606

Epoch: 5| Step: 4
Training loss: 3.007919507786042
Validation loss: 2.9415157066620137

Epoch: 5| Step: 5
Training loss: 3.3114472641729384
Validation loss: 2.946770830629194

Epoch: 5| Step: 6
Training loss: 3.168043105150065
Validation loss: 2.9433619409394787

Epoch: 5| Step: 7
Training loss: 3.639119635166612
Validation loss: 2.9498179767334762

Epoch: 5| Step: 8
Training loss: 3.664483735489688
Validation loss: 2.956248124919041

Epoch: 5| Step: 9
Training loss: 3.505315558884592
Validation loss: 2.9562511392838466

Epoch: 5| Step: 10
Training loss: 3.728215200990938
Validation loss: 2.947945004198759

Epoch: 54| Step: 0
Training loss: 3.0464389586826606
Validation loss: 2.937645589362004

Epoch: 5| Step: 1
Training loss: 3.5014039357348072
Validation loss: 2.9369756945901226

Epoch: 5| Step: 2
Training loss: 2.9701021026631627
Validation loss: 2.936675335378231

Epoch: 5| Step: 3
Training loss: 3.086583168954712
Validation loss: 2.937783178967929

Epoch: 5| Step: 4
Training loss: 3.5235047598295512
Validation loss: 2.9355035969611074

Epoch: 5| Step: 5
Training loss: 3.377614880350965
Validation loss: 2.9359758097391495

Epoch: 5| Step: 6
Training loss: 3.439955233349162
Validation loss: 2.935579910361526

Epoch: 5| Step: 7
Training loss: 3.0545368596467974
Validation loss: 2.9345941057732405

Epoch: 5| Step: 8
Training loss: 3.3222455310606325
Validation loss: 2.9346476076103594

Epoch: 5| Step: 9
Training loss: 2.7684645219279194
Validation loss: 2.933695706817514

Epoch: 5| Step: 10
Training loss: 3.4057168805852207
Validation loss: 2.9332887182823453

Epoch: 55| Step: 0
Training loss: 2.796769038915683
Validation loss: 2.934345138701723

Epoch: 5| Step: 1
Training loss: 3.423384242163685
Validation loss: 2.9318161841940302

Epoch: 5| Step: 2
Training loss: 3.2972556522698966
Validation loss: 2.9316180600113095

Epoch: 5| Step: 3
Training loss: 3.916528104130225
Validation loss: 2.9315162005891406

Epoch: 5| Step: 4
Training loss: 2.794148826720409
Validation loss: 2.9317741207609744

Epoch: 5| Step: 5
Training loss: 3.532148398836233
Validation loss: 2.931346287964922

Epoch: 5| Step: 6
Training loss: 3.0075854723573787
Validation loss: 2.9308915589002678

Epoch: 5| Step: 7
Training loss: 3.1789183940078924
Validation loss: 2.929109724053178

Epoch: 5| Step: 8
Training loss: 2.7120911180161102
Validation loss: 2.9280590056984086

Epoch: 5| Step: 9
Training loss: 3.0181121847386603
Validation loss: 2.926895426931115

Epoch: 5| Step: 10
Training loss: 3.668352100948823
Validation loss: 2.9251075942902798

Epoch: 56| Step: 0
Training loss: 3.7331547359481014
Validation loss: 2.9265179742609386

Epoch: 5| Step: 1
Training loss: 2.8931329518322415
Validation loss: 2.925215648620992

Epoch: 5| Step: 2
Training loss: 3.1197792694066253
Validation loss: 2.9243320296618314

Epoch: 5| Step: 3
Training loss: 3.020351520568474
Validation loss: 2.9240430774993684

Epoch: 5| Step: 4
Training loss: 3.231687894623241
Validation loss: 2.9245396395800376

Epoch: 5| Step: 5
Training loss: 3.315573795653082
Validation loss: 2.9257183364186488

Epoch: 5| Step: 6
Training loss: 2.8605717723679236
Validation loss: 2.922471208532936

Epoch: 5| Step: 7
Training loss: 3.0481065657501927
Validation loss: 2.931816811153575

Epoch: 5| Step: 8
Training loss: 3.5784211015413003
Validation loss: 2.9330597881984013

Epoch: 5| Step: 9
Training loss: 3.1515275732931562
Validation loss: 2.9313018555653314

Epoch: 5| Step: 10
Training loss: 3.3373791619188484
Validation loss: 2.9272393865365745

Epoch: 57| Step: 0
Training loss: 3.279482701610291
Validation loss: 2.9246497134594933

Epoch: 5| Step: 1
Training loss: 3.241506629138001
Validation loss: 2.9237765102691617

Epoch: 5| Step: 2
Training loss: 3.0316237386383853
Validation loss: 2.922779229148256

Epoch: 5| Step: 3
Training loss: 3.050716541107117
Validation loss: 2.9157852288325268

Epoch: 5| Step: 4
Training loss: 2.9306084164577144
Validation loss: 2.9115515517214394

Epoch: 5| Step: 5
Training loss: 2.7168413675533163
Validation loss: 2.9103640307969343

Epoch: 5| Step: 6
Training loss: 3.446174634815749
Validation loss: 2.911410061423613

Epoch: 5| Step: 7
Training loss: 3.270552718320405
Validation loss: 2.911784130036741

Epoch: 5| Step: 8
Training loss: 2.883947298983709
Validation loss: 2.913764855496218

Epoch: 5| Step: 9
Training loss: 3.743324568940045
Validation loss: 2.913384120380031

Epoch: 5| Step: 10
Training loss: 3.641101724085269
Validation loss: 2.9130562843031074

Epoch: 58| Step: 0
Training loss: 2.8773044804118397
Validation loss: 2.912171611592783

Epoch: 5| Step: 1
Training loss: 3.6680897783131123
Validation loss: 2.9124184928149193

Epoch: 5| Step: 2
Training loss: 3.441958501110125
Validation loss: 2.912409098829456

Epoch: 5| Step: 3
Training loss: 3.229047137273454
Validation loss: 2.913069728824527

Epoch: 5| Step: 4
Training loss: 2.7306950684103533
Validation loss: 2.912184685184142

Epoch: 5| Step: 5
Training loss: 3.4712711828929623
Validation loss: 2.9113801798234316

Epoch: 5| Step: 6
Training loss: 2.7901239165266434
Validation loss: 2.9104609984310073

Epoch: 5| Step: 7
Training loss: 2.4756911035354374
Validation loss: 2.9077615457971535

Epoch: 5| Step: 8
Training loss: 3.4095490604377914
Validation loss: 2.9051133781415497

Epoch: 5| Step: 9
Training loss: 3.0126087343212027
Validation loss: 2.906432078278348

Epoch: 5| Step: 10
Training loss: 4.03997119591142
Validation loss: 2.9052126097349937

Epoch: 59| Step: 0
Training loss: 3.027164498221395
Validation loss: 2.904152834973753

Epoch: 5| Step: 1
Training loss: 3.024777453094206
Validation loss: 2.9019868394669412

Epoch: 5| Step: 2
Training loss: 3.403982825355819
Validation loss: 2.898603834292751

Epoch: 5| Step: 3
Training loss: 3.7499539690371484
Validation loss: 2.8977483981604713

Epoch: 5| Step: 4
Training loss: 3.214657598508272
Validation loss: 2.900365009611145

Epoch: 5| Step: 5
Training loss: 2.555996713937668
Validation loss: 2.8977736960724734

Epoch: 5| Step: 6
Training loss: 3.1458479689369208
Validation loss: 2.900430993969362

Epoch: 5| Step: 7
Training loss: 3.528698564911959
Validation loss: 2.903906687386717

Epoch: 5| Step: 8
Training loss: 2.7109604540465986
Validation loss: 2.911052561038103

Epoch: 5| Step: 9
Training loss: 3.4716295541826767
Validation loss: 2.9227899874963486

Epoch: 5| Step: 10
Training loss: 3.1808561010014773
Validation loss: 2.9213865858023276

Epoch: 60| Step: 0
Training loss: 3.016124940849347
Validation loss: 2.9188215133100295

Epoch: 5| Step: 1
Training loss: 3.077490416820985
Validation loss: 2.9030651867038957

Epoch: 5| Step: 2
Training loss: 3.4848117982242552
Validation loss: 2.893529824934624

Epoch: 5| Step: 3
Training loss: 2.9879202830393337
Validation loss: 2.891564328937633

Epoch: 5| Step: 4
Training loss: 4.081799952328639
Validation loss: 2.8934295432207815

Epoch: 5| Step: 5
Training loss: 2.6522066645527085
Validation loss: 2.8903765597417395

Epoch: 5| Step: 6
Training loss: 3.570615659568318
Validation loss: 2.890137989421515

Epoch: 5| Step: 7
Training loss: 3.1933980490299576
Validation loss: 2.8890219862320494

Epoch: 5| Step: 8
Training loss: 3.153065803206553
Validation loss: 2.887072436863215

Epoch: 5| Step: 9
Training loss: 2.5672416546636083
Validation loss: 2.8871108911397956

Epoch: 5| Step: 10
Training loss: 3.064938411373895
Validation loss: 2.887068442760605

Epoch: 61| Step: 0
Training loss: 3.1993631742526762
Validation loss: 2.8850098939176707

Epoch: 5| Step: 1
Training loss: 3.591467489102576
Validation loss: 2.8842564467680805

Epoch: 5| Step: 2
Training loss: 2.9151929856242136
Validation loss: 2.8845773203694045

Epoch: 5| Step: 3
Training loss: 2.8964035424176973
Validation loss: 2.8842316604873663

Epoch: 5| Step: 4
Training loss: 3.315893630094469
Validation loss: 2.8834482754652053

Epoch: 5| Step: 5
Training loss: 2.9346250709845334
Validation loss: 2.8834810879778376

Epoch: 5| Step: 6
Training loss: 3.172990875144459
Validation loss: 2.883648818400917

Epoch: 5| Step: 7
Training loss: 3.430537854834094
Validation loss: 2.8859272705677133

Epoch: 5| Step: 8
Training loss: 3.4386169006258926
Validation loss: 2.8860289286621965

Epoch: 5| Step: 9
Training loss: 3.1015944779522777
Validation loss: 2.8866637745863377

Epoch: 5| Step: 10
Training loss: 2.9132445468365424
Validation loss: 2.8864560152076804

Epoch: 62| Step: 0
Training loss: 3.5747925011231665
Validation loss: 2.886522244690482

Epoch: 5| Step: 1
Training loss: 3.643172653810636
Validation loss: 2.897616291609742

Epoch: 5| Step: 2
Training loss: 3.4257598145530923
Validation loss: 2.9250459703693448

Epoch: 5| Step: 3
Training loss: 2.8523911199760734
Validation loss: 2.9399033704979334

Epoch: 5| Step: 4
Training loss: 3.0675760358295445
Validation loss: 2.8813877693031587

Epoch: 5| Step: 5
Training loss: 3.1344811616454105
Validation loss: 2.877196954102076

Epoch: 5| Step: 6
Training loss: 3.6527851348016394
Validation loss: 2.877396140121496

Epoch: 5| Step: 7
Training loss: 2.734616339795933
Validation loss: 2.930543590967636

Epoch: 5| Step: 8
Training loss: 2.6201099988545162
Validation loss: 2.8839755225202213

Epoch: 5| Step: 9
Training loss: 3.81611312005983
Validation loss: 2.892392965849936

Epoch: 5| Step: 10
Training loss: 1.9473116610029646
Validation loss: 2.898668936291917

Epoch: 63| Step: 0
Training loss: 3.5967431913430596
Validation loss: 2.907706941785175

Epoch: 5| Step: 1
Training loss: 2.57077671485352
Validation loss: 2.8917954035154736

Epoch: 5| Step: 2
Training loss: 2.9843356943787613
Validation loss: 2.883846321353011

Epoch: 5| Step: 3
Training loss: 3.5158335984121365
Validation loss: 2.873351839626606

Epoch: 5| Step: 4
Training loss: 2.8630189450217096
Validation loss: 2.87066326160592

Epoch: 5| Step: 5
Training loss: 3.5838947004278574
Validation loss: 2.8681598525747685

Epoch: 5| Step: 6
Training loss: 3.4361085329600347
Validation loss: 2.8784372595510166

Epoch: 5| Step: 7
Training loss: 3.216719496166335
Validation loss: 2.886582593284894

Epoch: 5| Step: 8
Training loss: 3.155436949299323
Validation loss: 2.904763517177344

Epoch: 5| Step: 9
Training loss: 3.000581843855015
Validation loss: 2.8899838539992757

Epoch: 5| Step: 10
Training loss: 2.992404700779878
Validation loss: 2.8730713330383746

Epoch: 64| Step: 0
Training loss: 2.584825443741894
Validation loss: 2.863026561561683

Epoch: 5| Step: 1
Training loss: 3.0315705749259467
Validation loss: 2.860250389119638

Epoch: 5| Step: 2
Training loss: 3.584252054887986
Validation loss: 2.8598679457712923

Epoch: 5| Step: 3
Training loss: 3.9462019418201346
Validation loss: 2.8598355472037924

Epoch: 5| Step: 4
Training loss: 3.616013799944851
Validation loss: 2.8597406890582655

Epoch: 5| Step: 5
Training loss: 2.7475619345740085
Validation loss: 2.8588551425795234

Epoch: 5| Step: 6
Training loss: 3.2054232656183768
Validation loss: 2.859429328268299

Epoch: 5| Step: 7
Training loss: 2.838849886804438
Validation loss: 2.8612550440483044

Epoch: 5| Step: 8
Training loss: 2.6700650157942065
Validation loss: 2.860137783019972

Epoch: 5| Step: 9
Training loss: 3.3361030198068895
Validation loss: 2.858786419431487

Epoch: 5| Step: 10
Training loss: 2.9557736744939627
Validation loss: 2.8619656866718852

Epoch: 65| Step: 0
Training loss: 3.81675970027983
Validation loss: 2.8565504492170755

Epoch: 5| Step: 1
Training loss: 2.8350912886089037
Validation loss: 2.8553373170947807

Epoch: 5| Step: 2
Training loss: 2.813738995076795
Validation loss: 2.8539912052591765

Epoch: 5| Step: 3
Training loss: 2.947573009360042
Validation loss: 2.8531392452388133

Epoch: 5| Step: 4
Training loss: 2.5747819900814424
Validation loss: 2.854769410820089

Epoch: 5| Step: 5
Training loss: 3.6168191611022262
Validation loss: 2.852919903030769

Epoch: 5| Step: 6
Training loss: 3.481744705745079
Validation loss: 2.851567402407143

Epoch: 5| Step: 7
Training loss: 3.451632354015647
Validation loss: 2.852691606655728

Epoch: 5| Step: 8
Training loss: 2.71426222905776
Validation loss: 2.854342804975228

Epoch: 5| Step: 9
Training loss: 3.228595527264807
Validation loss: 2.8547981167899055

Epoch: 5| Step: 10
Training loss: 2.997418405473808
Validation loss: 2.8526018591349036

Epoch: 66| Step: 0
Training loss: 3.308336628512672
Validation loss: 2.8503626320884115

Epoch: 5| Step: 1
Training loss: 3.033271980363837
Validation loss: 2.8485291754253836

Epoch: 5| Step: 2
Training loss: 2.8586127927718756
Validation loss: 2.8518820801147866

Epoch: 5| Step: 3
Training loss: 2.8271442209057502
Validation loss: 2.8479873629247936

Epoch: 5| Step: 4
Training loss: 3.118081483305984
Validation loss: 2.8530314731187705

Epoch: 5| Step: 5
Training loss: 3.7419564767138334
Validation loss: 2.8491758537335716

Epoch: 5| Step: 6
Training loss: 2.9245544224627262
Validation loss: 2.844570589179234

Epoch: 5| Step: 7
Training loss: 3.0981772755484953
Validation loss: 2.8436375302414607

Epoch: 5| Step: 8
Training loss: 2.9882510913000204
Validation loss: 2.8442189306538954

Epoch: 5| Step: 9
Training loss: 3.307898438228828
Validation loss: 2.842367420095145

Epoch: 5| Step: 10
Training loss: 3.3931532192830978
Validation loss: 2.8439503999956943

Epoch: 67| Step: 0
Training loss: 3.073664187443126
Validation loss: 2.845513940852532

Epoch: 5| Step: 1
Training loss: 3.0973733048779426
Validation loss: 2.8464268937595882

Epoch: 5| Step: 2
Training loss: 2.971041628119348
Validation loss: 2.8457138112335194

Epoch: 5| Step: 3
Training loss: 3.3008748599891806
Validation loss: 2.8456359337792545

Epoch: 5| Step: 4
Training loss: 3.2955167603075943
Validation loss: 2.8462122017020617

Epoch: 5| Step: 5
Training loss: 2.60549629345566
Validation loss: 2.8432541497985326

Epoch: 5| Step: 6
Training loss: 3.2008034829877547
Validation loss: 2.8419562994171716

Epoch: 5| Step: 7
Training loss: 3.184770200574721
Validation loss: 2.8414150687319077

Epoch: 5| Step: 8
Training loss: 3.3153979023237046
Validation loss: 2.842439380348249

Epoch: 5| Step: 9
Training loss: 3.3209193494147646
Validation loss: 2.839934195888906

Epoch: 5| Step: 10
Training loss: 3.2724596260908294
Validation loss: 2.8434745207097794

Epoch: 68| Step: 0
Training loss: 3.3666837452622116
Validation loss: 2.846291334270096

Epoch: 5| Step: 1
Training loss: 3.2791060936910292
Validation loss: 2.8452422688971537

Epoch: 5| Step: 2
Training loss: 3.3947479916330723
Validation loss: 2.8489059356738

Epoch: 5| Step: 3
Training loss: 3.698203248573722
Validation loss: 2.844161188597525

Epoch: 5| Step: 4
Training loss: 3.022534297120631
Validation loss: 2.835377562556891

Epoch: 5| Step: 5
Training loss: 2.9762680428705837
Validation loss: 2.833686566516991

Epoch: 5| Step: 6
Training loss: 3.1915045621523492
Validation loss: 2.8341189378994893

Epoch: 5| Step: 7
Training loss: 2.595453461293184
Validation loss: 2.8339555613278584

Epoch: 5| Step: 8
Training loss: 3.07449638150347
Validation loss: 2.8335585863547657

Epoch: 5| Step: 9
Training loss: 2.6920935828619923
Validation loss: 2.83149654784813

Epoch: 5| Step: 10
Training loss: 3.182115831943852
Validation loss: 2.8309058884509737

Epoch: 69| Step: 0
Training loss: 3.3043114558690885
Validation loss: 2.8301151941586564

Epoch: 5| Step: 1
Training loss: 3.141904352102984
Validation loss: 2.8315756109122123

Epoch: 5| Step: 2
Training loss: 3.32838589357592
Validation loss: 2.8331018532169296

Epoch: 5| Step: 3
Training loss: 3.048736629542788
Validation loss: 2.8294365275195617

Epoch: 5| Step: 4
Training loss: 3.209639163785634
Validation loss: 2.826622208735942

Epoch: 5| Step: 5
Training loss: 2.8110209496639227
Validation loss: 2.8256310241241462

Epoch: 5| Step: 6
Training loss: 2.5442095891999257
Validation loss: 2.828343728046069

Epoch: 5| Step: 7
Training loss: 3.608623079526363
Validation loss: 2.8328674037057557

Epoch: 5| Step: 8
Training loss: 3.063397178800922
Validation loss: 2.835118725329579

Epoch: 5| Step: 9
Training loss: 3.1818240623915193
Validation loss: 2.8290702506058247

Epoch: 5| Step: 10
Training loss: 3.167857816096766
Validation loss: 2.825472926937839

Epoch: 70| Step: 0
Training loss: 2.6780945071751243
Validation loss: 2.8253262811199242

Epoch: 5| Step: 1
Training loss: 2.9487166829994234
Validation loss: 2.8235035389827328

Epoch: 5| Step: 2
Training loss: 2.801696883051325
Validation loss: 2.824951977166896

Epoch: 5| Step: 3
Training loss: 3.4708776049101187
Validation loss: 2.822083490598257

Epoch: 5| Step: 4
Training loss: 3.1213409364138687
Validation loss: 2.8222500619800903

Epoch: 5| Step: 5
Training loss: 2.918116309176911
Validation loss: 2.8218940775009536

Epoch: 5| Step: 6
Training loss: 3.2712857040888186
Validation loss: 2.821335995279502

Epoch: 5| Step: 7
Training loss: 2.9191777636721556
Validation loss: 2.8219848016208533

Epoch: 5| Step: 8
Training loss: 3.5384453578566264
Validation loss: 2.822109120679252

Epoch: 5| Step: 9
Training loss: 2.805633555378216
Validation loss: 2.82176756578853

Epoch: 5| Step: 10
Training loss: 3.900869952277635
Validation loss: 2.8199626692121598

Epoch: 71| Step: 0
Training loss: 2.8522720917200517
Validation loss: 2.820497537368999

Epoch: 5| Step: 1
Training loss: 2.8458909579503318
Validation loss: 2.819516865511946

Epoch: 5| Step: 2
Training loss: 3.323426848243391
Validation loss: 2.8190751636004525

Epoch: 5| Step: 3
Training loss: 3.5866344830039276
Validation loss: 2.818057227981048

Epoch: 5| Step: 4
Training loss: 2.5058711728823986
Validation loss: 2.815200998123926

Epoch: 5| Step: 5
Training loss: 3.215287948456825
Validation loss: 2.81802918756808

Epoch: 5| Step: 6
Training loss: 3.104358249017763
Validation loss: 2.815571963822638

Epoch: 5| Step: 7
Training loss: 3.3620010402843494
Validation loss: 2.8155821962519565

Epoch: 5| Step: 8
Training loss: 3.390267911468892
Validation loss: 2.812161538963892

Epoch: 5| Step: 9
Training loss: 3.0709679755650012
Validation loss: 2.8166211451185434

Epoch: 5| Step: 10
Training loss: 3.0165693158482028
Validation loss: 2.8141540084654704

Epoch: 72| Step: 0
Training loss: 3.4141648755120446
Validation loss: 2.8188135952509517

Epoch: 5| Step: 1
Training loss: 3.7859102645694165
Validation loss: 2.8182887256220988

Epoch: 5| Step: 2
Training loss: 3.1299822953671037
Validation loss: 2.8244958981360764

Epoch: 5| Step: 3
Training loss: 2.9593553165800333
Validation loss: 2.8264184268465717

Epoch: 5| Step: 4
Training loss: 2.654630458998075
Validation loss: 2.835704217469493

Epoch: 5| Step: 5
Training loss: 2.749521387239372
Validation loss: 2.811729249430668

Epoch: 5| Step: 6
Training loss: 3.394606963653245
Validation loss: 2.8081777268137103

Epoch: 5| Step: 7
Training loss: 2.5932611211547276
Validation loss: 2.804256186099906

Epoch: 5| Step: 8
Training loss: 3.1402668155608366
Validation loss: 2.8102373143400654

Epoch: 5| Step: 9
Training loss: 2.8925979067520746
Validation loss: 2.8115866687795408

Epoch: 5| Step: 10
Training loss: 3.4682931685119387
Validation loss: 2.8251064891384257

Epoch: 73| Step: 0
Training loss: 3.512756805263468
Validation loss: 2.827521476013774

Epoch: 5| Step: 1
Training loss: 3.1939031575426235
Validation loss: 2.8482374709424354

Epoch: 5| Step: 2
Training loss: 3.1721415290286132
Validation loss: 2.8545893835215757

Epoch: 5| Step: 3
Training loss: 2.9326173500978143
Validation loss: 2.8373189637374403

Epoch: 5| Step: 4
Training loss: 2.4280618706036403
Validation loss: 2.821740210029452

Epoch: 5| Step: 5
Training loss: 3.250608093886666
Validation loss: 2.8118266868643342

Epoch: 5| Step: 6
Training loss: 3.249131746954842
Validation loss: 2.808586075298056

Epoch: 5| Step: 7
Training loss: 3.3441169038351686
Validation loss: 2.808891971417595

Epoch: 5| Step: 8
Training loss: 3.3975102003560544
Validation loss: 2.8083116772325667

Epoch: 5| Step: 9
Training loss: 3.330912537506731
Validation loss: 2.8064293467414307

Epoch: 5| Step: 10
Training loss: 2.387464940477765
Validation loss: 2.806509811126548

Epoch: 74| Step: 0
Training loss: 2.632816122261974
Validation loss: 2.803424972536239

Epoch: 5| Step: 1
Training loss: 3.0966130119852067
Validation loss: 2.8027153914036904

Epoch: 5| Step: 2
Training loss: 3.1636894853909325
Validation loss: 2.807749439892966

Epoch: 5| Step: 3
Training loss: 2.2175978772088554
Validation loss: 2.8275575732013585

Epoch: 5| Step: 4
Training loss: 3.440104243672919
Validation loss: 2.8754521995626012

Epoch: 5| Step: 5
Training loss: 3.1007300347913596
Validation loss: 2.882942008936606

Epoch: 5| Step: 6
Training loss: 3.6060001068538368
Validation loss: 2.85457069358311

Epoch: 5| Step: 7
Training loss: 3.4985726034392433
Validation loss: 2.8298758113427347

Epoch: 5| Step: 8
Training loss: 2.586285801045573
Validation loss: 2.801814557278923

Epoch: 5| Step: 9
Training loss: 3.4829835037686316
Validation loss: 2.79630416935954

Epoch: 5| Step: 10
Training loss: 3.25401630192608
Validation loss: 2.7933976511631182

Epoch: 75| Step: 0
Training loss: 2.7233478647386766
Validation loss: 2.7959395009512247

Epoch: 5| Step: 1
Training loss: 2.25245447855856
Validation loss: 2.794616988492045

Epoch: 5| Step: 2
Training loss: 2.8963760489478823
Validation loss: 2.7982117297784095

Epoch: 5| Step: 3
Training loss: 2.8756888849648448
Validation loss: 2.7958702216153863

Epoch: 5| Step: 4
Training loss: 3.025989175276673
Validation loss: 2.7972933676936864

Epoch: 5| Step: 5
Training loss: 3.5249626428234357
Validation loss: 2.794830427399831

Epoch: 5| Step: 6
Training loss: 3.810087472507257
Validation loss: 2.7932218414446344

Epoch: 5| Step: 7
Training loss: 3.1466895616097172
Validation loss: 2.7933376003010273

Epoch: 5| Step: 8
Training loss: 3.381352133627451
Validation loss: 2.7934107657795315

Epoch: 5| Step: 9
Training loss: 2.6105013489338873
Validation loss: 2.79114492025576

Epoch: 5| Step: 10
Training loss: 3.733637653163744
Validation loss: 2.7904902241327267

Epoch: 76| Step: 0
Training loss: 3.740021335520551
Validation loss: 2.791162455106524

Epoch: 5| Step: 1
Training loss: 3.499183150747206
Validation loss: 2.7920713821588907

Epoch: 5| Step: 2
Training loss: 2.632657190830195
Validation loss: 2.7914157250183234

Epoch: 5| Step: 3
Training loss: 3.3630098771725248
Validation loss: 2.7959102007586663

Epoch: 5| Step: 4
Training loss: 2.9505114419130565
Validation loss: 2.795303008365382

Epoch: 5| Step: 5
Training loss: 2.917254870004076
Validation loss: 2.7905171476063795

Epoch: 5| Step: 6
Training loss: 2.7668856748586554
Validation loss: 2.786474674342928

Epoch: 5| Step: 7
Training loss: 3.4039322553319358
Validation loss: 2.7858253113407576

Epoch: 5| Step: 8
Training loss: 1.969598314897977
Validation loss: 2.7849601701091022

Epoch: 5| Step: 9
Training loss: 3.1778770747672955
Validation loss: 2.788247435365494

Epoch: 5| Step: 10
Training loss: 3.4238626638303535
Validation loss: 2.788223491071581

Epoch: 77| Step: 0
Training loss: 3.5169974805764856
Validation loss: 2.7850102400717116

Epoch: 5| Step: 1
Training loss: 3.375990263161019
Validation loss: 2.7790085933568247

Epoch: 5| Step: 2
Training loss: 3.235931906333815
Validation loss: 2.7802881880097536

Epoch: 5| Step: 3
Training loss: 3.685010813434527
Validation loss: 2.7792936428868384

Epoch: 5| Step: 4
Training loss: 3.4651681088047996
Validation loss: 2.7830553913612572

Epoch: 5| Step: 5
Training loss: 2.840344580310618
Validation loss: 2.782407237116068

Epoch: 5| Step: 6
Training loss: 3.0092145550224862
Validation loss: 2.7843250725249673

Epoch: 5| Step: 7
Training loss: 2.8085110669440083
Validation loss: 2.784229955652734

Epoch: 5| Step: 8
Training loss: 2.614435371579169
Validation loss: 2.782779612648602

Epoch: 5| Step: 9
Training loss: 2.8675691522110505
Validation loss: 2.7838674978346463

Epoch: 5| Step: 10
Training loss: 2.4451624425116987
Validation loss: 2.783155615501291

Epoch: 78| Step: 0
Training loss: 3.4381495468963723
Validation loss: 2.7807973207786896

Epoch: 5| Step: 1
Training loss: 3.617971644259329
Validation loss: 2.7820360428626403

Epoch: 5| Step: 2
Training loss: 2.768666981298495
Validation loss: 2.7793427569498776

Epoch: 5| Step: 3
Training loss: 3.57591892516634
Validation loss: 2.779877987336303

Epoch: 5| Step: 4
Training loss: 2.899625385686802
Validation loss: 2.7806098886238932

Epoch: 5| Step: 5
Training loss: 2.7996923652314556
Validation loss: 2.778291815670666

Epoch: 5| Step: 6
Training loss: 2.9675345090869745
Validation loss: 2.774128321209691

Epoch: 5| Step: 7
Training loss: 3.410680147284063
Validation loss: 2.77863842220598

Epoch: 5| Step: 8
Training loss: 3.127136873163459
Validation loss: 2.771630551748007

Epoch: 5| Step: 9
Training loss: 2.7089707333662023
Validation loss: 2.7730154887736678

Epoch: 5| Step: 10
Training loss: 2.4494299789920233
Validation loss: 2.782811232593359

Epoch: 79| Step: 0
Training loss: 3.0239285802127567
Validation loss: 2.7867296214273005

Epoch: 5| Step: 1
Training loss: 2.957137031628417
Validation loss: 2.783284426647487

Epoch: 5| Step: 2
Training loss: 2.7923299845933123
Validation loss: 2.7887438667385718

Epoch: 5| Step: 3
Training loss: 3.3097300914422374
Validation loss: 2.7940718407144494

Epoch: 5| Step: 4
Training loss: 2.835502654226235
Validation loss: 2.791654187907535

Epoch: 5| Step: 5
Training loss: 3.132290537438265
Validation loss: 2.7860007955343313

Epoch: 5| Step: 6
Training loss: 3.0449810695216346
Validation loss: 2.7885880046402467

Epoch: 5| Step: 7
Training loss: 3.2375787909504696
Validation loss: 2.7756718898335744

Epoch: 5| Step: 8
Training loss: 2.902196210394454
Validation loss: 2.766620182319449

Epoch: 5| Step: 9
Training loss: 3.6157438557046486
Validation loss: 2.762587088316175

Epoch: 5| Step: 10
Training loss: 3.0455131421604906
Validation loss: 2.7613478894846213

Epoch: 80| Step: 0
Training loss: 2.4346431716684993
Validation loss: 2.763855994255138

Epoch: 5| Step: 1
Training loss: 3.444583461034402
Validation loss: 2.769251911001379

Epoch: 5| Step: 2
Training loss: 3.0357591577627545
Validation loss: 2.7723328847836743

Epoch: 5| Step: 3
Training loss: 3.510958681607153
Validation loss: 2.7758623078425653

Epoch: 5| Step: 4
Training loss: 3.8064416996830435
Validation loss: 2.774438952048877

Epoch: 5| Step: 5
Training loss: 3.1787338888860357
Validation loss: 2.7766320481320186

Epoch: 5| Step: 6
Training loss: 3.083181807085335
Validation loss: 2.777062692343873

Epoch: 5| Step: 7
Training loss: 2.950892982458174
Validation loss: 2.778276325131874

Epoch: 5| Step: 8
Training loss: 2.3308256729576553
Validation loss: 2.7769506577324043

Epoch: 5| Step: 9
Training loss: 2.8892172194830597
Validation loss: 2.776574035277466

Epoch: 5| Step: 10
Training loss: 3.155850677912651
Validation loss: 2.774191745938476

Epoch: 81| Step: 0
Training loss: 2.829407290608742
Validation loss: 2.770065903277067

Epoch: 5| Step: 1
Training loss: 3.369967346485992
Validation loss: 2.768305560347782

Epoch: 5| Step: 2
Training loss: 3.021513097289953
Validation loss: 2.76820408175144

Epoch: 5| Step: 3
Training loss: 3.0208925087931573
Validation loss: 2.7675949523313714

Epoch: 5| Step: 4
Training loss: 2.359500098543515
Validation loss: 2.7666147170345865

Epoch: 5| Step: 5
Training loss: 3.1422813185272935
Validation loss: 2.7647361302592675

Epoch: 5| Step: 6
Training loss: 3.698521194832536
Validation loss: 2.764867906187581

Epoch: 5| Step: 7
Training loss: 3.078961718547703
Validation loss: 2.764744730620673

Epoch: 5| Step: 8
Training loss: 2.7601350940592155
Validation loss: 2.760864601004127

Epoch: 5| Step: 9
Training loss: 3.585957977967809
Validation loss: 2.7583501812740954

Epoch: 5| Step: 10
Training loss: 2.907802372278843
Validation loss: 2.7569228103149936

Epoch: 82| Step: 0
Training loss: 3.6410570665940987
Validation loss: 2.753764498450165

Epoch: 5| Step: 1
Training loss: 3.039008211175609
Validation loss: 2.753406972258174

Epoch: 5| Step: 2
Training loss: 2.7185498744928296
Validation loss: 2.7549415687355987

Epoch: 5| Step: 3
Training loss: 2.9687581915491426
Validation loss: 2.7541453775292335

Epoch: 5| Step: 4
Training loss: 2.9831089709714647
Validation loss: 2.752078219144584

Epoch: 5| Step: 5
Training loss: 3.6041273140642365
Validation loss: 2.758458699011207

Epoch: 5| Step: 6
Training loss: 2.6297204399199106
Validation loss: 2.7645327533559936

Epoch: 5| Step: 7
Training loss: 2.3185829369751527
Validation loss: 2.756274906280586

Epoch: 5| Step: 8
Training loss: 3.428763923463772
Validation loss: 2.7599211000510673

Epoch: 5| Step: 9
Training loss: 3.05395686394806
Validation loss: 2.7593776841066324

Epoch: 5| Step: 10
Training loss: 3.2079006415222566
Validation loss: 2.7560018634266847

Epoch: 83| Step: 0
Training loss: 2.7688601263116146
Validation loss: 2.7582205644479094

Epoch: 5| Step: 1
Training loss: 2.3248453273392244
Validation loss: 2.7567051111984644

Epoch: 5| Step: 2
Training loss: 3.1554324158146576
Validation loss: 2.7550270710574996

Epoch: 5| Step: 3
Training loss: 3.269098068582042
Validation loss: 2.7482050055710023

Epoch: 5| Step: 4
Training loss: 2.634937639891955
Validation loss: 2.7442779944549867

Epoch: 5| Step: 5
Training loss: 2.7474994561539337
Validation loss: 2.7436456997636176

Epoch: 5| Step: 6
Training loss: 3.334443161901425
Validation loss: 2.7448365136469204

Epoch: 5| Step: 7
Training loss: 3.482768967340585
Validation loss: 2.7438420066344684

Epoch: 5| Step: 8
Training loss: 3.1356431915138727
Validation loss: 2.7417745238043265

Epoch: 5| Step: 9
Training loss: 3.66763723416994
Validation loss: 2.7418504144403655

Epoch: 5| Step: 10
Training loss: 3.048054784607833
Validation loss: 2.743088882975581

Epoch: 84| Step: 0
Training loss: 3.5430898761337297
Validation loss: 2.7419362857173204

Epoch: 5| Step: 1
Training loss: 3.416511547630175
Validation loss: 2.7395452275818033

Epoch: 5| Step: 2
Training loss: 2.745494532968569
Validation loss: 2.740962132854489

Epoch: 5| Step: 3
Training loss: 2.805692444872539
Validation loss: 2.739807111032896

Epoch: 5| Step: 4
Training loss: 2.6476034015638854
Validation loss: 2.74247396864944

Epoch: 5| Step: 5
Training loss: 3.597907804129589
Validation loss: 2.740140348213818

Epoch: 5| Step: 6
Training loss: 2.4845103101050046
Validation loss: 2.7404591151554616

Epoch: 5| Step: 7
Training loss: 3.119808615169861
Validation loss: 2.7404367379501777

Epoch: 5| Step: 8
Training loss: 3.1791792329779
Validation loss: 2.74027228437176

Epoch: 5| Step: 9
Training loss: 2.6485671290178887
Validation loss: 2.7445096689118484

Epoch: 5| Step: 10
Training loss: 3.3481563163462016
Validation loss: 2.7504535079232952

Epoch: 85| Step: 0
Training loss: 2.474438258685175
Validation loss: 2.766790119678007

Epoch: 5| Step: 1
Training loss: 3.2114492041133995
Validation loss: 2.7895080756475226

Epoch: 5| Step: 2
Training loss: 3.7379159140969684
Validation loss: 2.7759676853803463

Epoch: 5| Step: 3
Training loss: 2.5664840988359225
Validation loss: 2.7478852237060982

Epoch: 5| Step: 4
Training loss: 2.655366369138505
Validation loss: 2.7383209315049677

Epoch: 5| Step: 5
Training loss: 2.7548966595052566
Validation loss: 2.7369406134549834

Epoch: 5| Step: 6
Training loss: 3.5978436581718585
Validation loss: 2.7377865596244493

Epoch: 5| Step: 7
Training loss: 3.0440250468282573
Validation loss: 2.7455346088412678

Epoch: 5| Step: 8
Training loss: 3.3289017464876545
Validation loss: 2.745472642680212

Epoch: 5| Step: 9
Training loss: 3.279436754852447
Validation loss: 2.745912245188014

Epoch: 5| Step: 10
Training loss: 2.8366148588990807
Validation loss: 2.7479177079142834

Epoch: 86| Step: 0
Training loss: 3.4728869263936057
Validation loss: 2.7506551213921995

Epoch: 5| Step: 1
Training loss: 2.8777129600062596
Validation loss: 2.7507775606709517

Epoch: 5| Step: 2
Training loss: 2.954984210854834
Validation loss: 2.7507084710444416

Epoch: 5| Step: 3
Training loss: 2.7973889779022447
Validation loss: 2.747809530531226

Epoch: 5| Step: 4
Training loss: 2.729345000364
Validation loss: 2.7470585239491774

Epoch: 5| Step: 5
Training loss: 3.1167053002667635
Validation loss: 2.745086768629063

Epoch: 5| Step: 6
Training loss: 3.6938533039138086
Validation loss: 2.7410058758711178

Epoch: 5| Step: 7
Training loss: 3.1955891608338622
Validation loss: 2.741238374904225

Epoch: 5| Step: 8
Training loss: 2.8590127684237028
Validation loss: 2.7385072391791656

Epoch: 5| Step: 9
Training loss: 3.0537290508536987
Validation loss: 2.739758534613319

Epoch: 5| Step: 10
Training loss: 2.9352024914427086
Validation loss: 2.7396937522375686

Epoch: 87| Step: 0
Training loss: 3.7195309371964136
Validation loss: 2.738449457810402

Epoch: 5| Step: 1
Training loss: 2.4457108535729786
Validation loss: 2.7368802746013037

Epoch: 5| Step: 2
Training loss: 2.8966513011365342
Validation loss: 2.7342894228715053

Epoch: 5| Step: 3
Training loss: 2.785478784576571
Validation loss: 2.733948905783232

Epoch: 5| Step: 4
Training loss: 3.193677712535028
Validation loss: 2.731174435603552

Epoch: 5| Step: 5
Training loss: 3.4889559205480576
Validation loss: 2.729935607636054

Epoch: 5| Step: 6
Training loss: 3.0770413577747138
Validation loss: 2.725472968281884

Epoch: 5| Step: 7
Training loss: 3.012381909853561
Validation loss: 2.7337798358919274

Epoch: 5| Step: 8
Training loss: 3.2660176164347026
Validation loss: 2.744829410669325

Epoch: 5| Step: 9
Training loss: 2.6811193972348573
Validation loss: 2.7494559015451063

Epoch: 5| Step: 10
Training loss: 2.8781336416638723
Validation loss: 2.7636013470598435

Epoch: 88| Step: 0
Training loss: 3.1853084135819927
Validation loss: 2.7573869724284847

Epoch: 5| Step: 1
Training loss: 3.056480252382326
Validation loss: 2.7391527045588138

Epoch: 5| Step: 2
Training loss: 2.730096401426877
Validation loss: 2.735705231586876

Epoch: 5| Step: 3
Training loss: 2.593228758866635
Validation loss: 2.7348306649482583

Epoch: 5| Step: 4
Training loss: 3.4318134783230865
Validation loss: 2.7359428989802708

Epoch: 5| Step: 5
Training loss: 2.5406172936429385
Validation loss: 2.736204847068958

Epoch: 5| Step: 6
Training loss: 3.2991686611903415
Validation loss: 2.730150031683097

Epoch: 5| Step: 7
Training loss: 3.2681514330531987
Validation loss: 2.7242911088930275

Epoch: 5| Step: 8
Training loss: 3.069805850870073
Validation loss: 2.720251226893381

Epoch: 5| Step: 9
Training loss: 3.3166768353432534
Validation loss: 2.7210669323784904

Epoch: 5| Step: 10
Training loss: 3.0823890855423186
Validation loss: 2.725764605789589

Epoch: 89| Step: 0
Training loss: 3.021645500360059
Validation loss: 2.7260070031816683

Epoch: 5| Step: 1
Training loss: 3.0595190370843013
Validation loss: 2.729432780099767

Epoch: 5| Step: 2
Training loss: 3.2392161530238672
Validation loss: 2.7320460710863603

Epoch: 5| Step: 3
Training loss: 3.15825762964138
Validation loss: 2.7325901263888754

Epoch: 5| Step: 4
Training loss: 2.696455295830908
Validation loss: 2.7362128625190936

Epoch: 5| Step: 5
Training loss: 2.6750610273298374
Validation loss: 2.739006349169756

Epoch: 5| Step: 6
Training loss: 2.8136106205587676
Validation loss: 2.7426885789726145

Epoch: 5| Step: 7
Training loss: 2.981422921529907
Validation loss: 2.73809193738523

Epoch: 5| Step: 8
Training loss: 3.401438543385535
Validation loss: 2.739358264279703

Epoch: 5| Step: 9
Training loss: 3.462505596720996
Validation loss: 2.7353103130299297

Epoch: 5| Step: 10
Training loss: 3.0021162516165516
Validation loss: 2.7304937772381246

Epoch: 90| Step: 0
Training loss: 3.364700142138789
Validation loss: 2.7257933752546384

Epoch: 5| Step: 1
Training loss: 2.7178507227434223
Validation loss: 2.7227442340785277

Epoch: 5| Step: 2
Training loss: 3.3076892683871644
Validation loss: 2.7203973030645865

Epoch: 5| Step: 3
Training loss: 2.919198345245118
Validation loss: 2.7219478521089937

Epoch: 5| Step: 4
Training loss: 3.1289976871002807
Validation loss: 2.727221269889641

Epoch: 5| Step: 5
Training loss: 2.6344366751948267
Validation loss: 2.7175938881882273

Epoch: 5| Step: 6
Training loss: 3.018200816870785
Validation loss: 2.724139832180926

Epoch: 5| Step: 7
Training loss: 3.6112110042612247
Validation loss: 2.728114561178354

Epoch: 5| Step: 8
Training loss: 2.939788900568751
Validation loss: 2.7268029799833466

Epoch: 5| Step: 9
Training loss: 2.971154293433477
Validation loss: 2.724177431936221

Epoch: 5| Step: 10
Training loss: 2.9008573317162925
Validation loss: 2.715060118490421

Epoch: 91| Step: 0
Training loss: 3.0561067450090236
Validation loss: 2.7186635679867965

Epoch: 5| Step: 1
Training loss: 2.5209899937734885
Validation loss: 2.7222877731310904

Epoch: 5| Step: 2
Training loss: 2.477642894669666
Validation loss: 2.7142522578753105

Epoch: 5| Step: 3
Training loss: 2.556605840785861
Validation loss: 2.7089764370254015

Epoch: 5| Step: 4
Training loss: 2.9750474493265866
Validation loss: 2.7014904477806154

Epoch: 5| Step: 5
Training loss: 3.035768110936088
Validation loss: 2.6985786212835214

Epoch: 5| Step: 6
Training loss: 3.543366970238732
Validation loss: 2.6886419544401132

Epoch: 5| Step: 7
Training loss: 3.4838483609157658
Validation loss: 2.6860368441642586

Epoch: 5| Step: 8
Training loss: 3.1054708996651366
Validation loss: 2.6877093699794434

Epoch: 5| Step: 9
Training loss: 3.2031375047393107
Validation loss: 2.689158274063842

Epoch: 5| Step: 10
Training loss: 3.2615722623355325
Validation loss: 2.6873477750546506

Epoch: 92| Step: 0
Training loss: 3.054650191837787
Validation loss: 2.6842732977964103

Epoch: 5| Step: 1
Training loss: 2.711161051830452
Validation loss: 2.687367847395738

Epoch: 5| Step: 2
Training loss: 2.843099666473368
Validation loss: 2.687188462641824

Epoch: 5| Step: 3
Training loss: 3.250727058661202
Validation loss: 2.6857716697064737

Epoch: 5| Step: 4
Training loss: 2.508578935007396
Validation loss: 2.6999263356869037

Epoch: 5| Step: 5
Training loss: 3.484182309694414
Validation loss: 2.7073633048645243

Epoch: 5| Step: 6
Training loss: 2.6766666033575763
Validation loss: 2.710656407099327

Epoch: 5| Step: 7
Training loss: 3.274170713770899
Validation loss: 2.6886302081538798

Epoch: 5| Step: 8
Training loss: 2.976633626733854
Validation loss: 2.684154879270678

Epoch: 5| Step: 9
Training loss: 3.1321419547639406
Validation loss: 2.686487074239648

Epoch: 5| Step: 10
Training loss: 3.4160164625320584
Validation loss: 2.6956647231708155

Epoch: 93| Step: 0
Training loss: 3.4907584114500643
Validation loss: 2.6936987836501016

Epoch: 5| Step: 1
Training loss: 2.6209915982620777
Validation loss: 2.6900148827889443

Epoch: 5| Step: 2
Training loss: 2.953903015021949
Validation loss: 2.6869565161900946

Epoch: 5| Step: 3
Training loss: 2.6992795194859696
Validation loss: 2.688210275460181

Epoch: 5| Step: 4
Training loss: 3.6605070713424586
Validation loss: 2.6867464644633747

Epoch: 5| Step: 5
Training loss: 3.3795240245404807
Validation loss: 2.688474128997713

Epoch: 5| Step: 6
Training loss: 3.321836736535861
Validation loss: 2.689335014629762

Epoch: 5| Step: 7
Training loss: 2.6072230802611776
Validation loss: 2.690394528123526

Epoch: 5| Step: 8
Training loss: 2.9238623729832875
Validation loss: 2.7074745839290766

Epoch: 5| Step: 9
Training loss: 3.0330305081074194
Validation loss: 2.78367175725166

Epoch: 5| Step: 10
Training loss: 2.4532011955722326
Validation loss: 2.7725527632282416

Epoch: 94| Step: 0
Training loss: 3.4129546089719436
Validation loss: 2.8043544330554555

Epoch: 5| Step: 1
Training loss: 3.2023117893966524
Validation loss: 2.8016622708595973

Epoch: 5| Step: 2
Training loss: 3.1050137552395882
Validation loss: 2.7832666358401026

Epoch: 5| Step: 3
Training loss: 3.2525470729649752
Validation loss: 2.7755595321484696

Epoch: 5| Step: 4
Training loss: 2.9818449630295873
Validation loss: 2.753790176029486

Epoch: 5| Step: 5
Training loss: 2.957057695761862
Validation loss: 2.7527428248839336

Epoch: 5| Step: 6
Training loss: 3.1987450403828723
Validation loss: 2.7620358373328657

Epoch: 5| Step: 7
Training loss: 2.649700212615729
Validation loss: 2.7607135454405194

Epoch: 5| Step: 8
Training loss: 3.219091008464403
Validation loss: 2.759797089679394

Epoch: 5| Step: 9
Training loss: 2.9174364618150688
Validation loss: 2.7762269660068886

Epoch: 5| Step: 10
Training loss: 2.8696315233764866
Validation loss: 2.7390764864715917

Epoch: 95| Step: 0
Training loss: 2.6289553134642
Validation loss: 2.7330214124236027

Epoch: 5| Step: 1
Training loss: 3.023996069910634
Validation loss: 2.7347297721918884

Epoch: 5| Step: 2
Training loss: 3.7017064979147256
Validation loss: 2.737536806945546

Epoch: 5| Step: 3
Training loss: 2.8275238578457675
Validation loss: 2.737328548983789

Epoch: 5| Step: 4
Training loss: 2.9123964021127944
Validation loss: 2.7387251070936536

Epoch: 5| Step: 5
Training loss: 3.1678856628284278
Validation loss: 2.7478727230751727

Epoch: 5| Step: 6
Training loss: 2.5180564171528403
Validation loss: 2.7402652836997867

Epoch: 5| Step: 7
Training loss: 3.174574731896157
Validation loss: 2.740858828137708

Epoch: 5| Step: 8
Training loss: 3.720432702197037
Validation loss: 2.7448453752978654

Epoch: 5| Step: 9
Training loss: 3.0580032967449253
Validation loss: 2.7396824484767968

Epoch: 5| Step: 10
Training loss: 2.6960794877918914
Validation loss: 2.7443478783919666

Epoch: 96| Step: 0
Training loss: 3.2887790584984082
Validation loss: 2.736435899984063

Epoch: 5| Step: 1
Training loss: 3.101123692294009
Validation loss: 2.7460232467165087

Epoch: 5| Step: 2
Training loss: 3.349168611671305
Validation loss: 2.7440570443567243

Epoch: 5| Step: 3
Training loss: 2.493658223769869
Validation loss: 2.7411994089947926

Epoch: 5| Step: 4
Training loss: 3.739973779270238
Validation loss: 2.741025835863208

Epoch: 5| Step: 5
Training loss: 2.5657519663387176
Validation loss: 2.7300458783635415

Epoch: 5| Step: 6
Training loss: 3.488707034790564
Validation loss: 2.733393571696584

Epoch: 5| Step: 7
Training loss: 2.3796338501741765
Validation loss: 2.7288834788835206

Epoch: 5| Step: 8
Training loss: 2.9817960291079775
Validation loss: 2.7269526536655393

Epoch: 5| Step: 9
Training loss: 3.114928992917882
Validation loss: 2.7258659263042633

Epoch: 5| Step: 10
Training loss: 2.809406528996118
Validation loss: 2.725464245877395

Epoch: 97| Step: 0
Training loss: 3.2738540857758416
Validation loss: 2.724400740487859

Epoch: 5| Step: 1
Training loss: 2.888949181669276
Validation loss: 2.7218217273300183

Epoch: 5| Step: 2
Training loss: 3.028696301937135
Validation loss: 2.7247035717390937

Epoch: 5| Step: 3
Training loss: 2.6113556066534933
Validation loss: 2.7247862256061244

Epoch: 5| Step: 4
Training loss: 3.2581874713949293
Validation loss: 2.7246764053471813

Epoch: 5| Step: 5
Training loss: 3.195422033097427
Validation loss: 2.7228113828405878

Epoch: 5| Step: 6
Training loss: 2.8097300982924045
Validation loss: 2.721996686099134

Epoch: 5| Step: 7
Training loss: 2.679577616671305
Validation loss: 2.7226136650728288

Epoch: 5| Step: 8
Training loss: 3.057110930022716
Validation loss: 2.7231935871349457

Epoch: 5| Step: 9
Training loss: 3.076361911292774
Validation loss: 2.7220923162427173

Epoch: 5| Step: 10
Training loss: 3.664907004307166
Validation loss: 2.7204391942396757

Epoch: 98| Step: 0
Training loss: 2.7866832511657798
Validation loss: 2.7172676017679263

Epoch: 5| Step: 1
Training loss: 3.032496559788953
Validation loss: 2.7184943433857014

Epoch: 5| Step: 2
Training loss: 2.916229342417308
Validation loss: 2.71620464161986

Epoch: 5| Step: 3
Training loss: 2.4929169451316877
Validation loss: 2.715111807497473

Epoch: 5| Step: 4
Training loss: 3.17822726975055
Validation loss: 2.7134452252994428

Epoch: 5| Step: 5
Training loss: 3.4814306571833895
Validation loss: 2.7120898778301665

Epoch: 5| Step: 6
Training loss: 2.9300844457649964
Validation loss: 2.7092329558386252

Epoch: 5| Step: 7
Training loss: 2.7854577285224154
Validation loss: 2.6674000224516106

Epoch: 5| Step: 8
Training loss: 2.8422258924981345
Validation loss: 2.6584861053637727

Epoch: 5| Step: 9
Training loss: 3.4763996900518612
Validation loss: 2.6734934823874754

Epoch: 5| Step: 10
Training loss: 3.3385366994232664
Validation loss: 2.6576614229974176

Epoch: 99| Step: 0
Training loss: 2.9078309055998295
Validation loss: 2.6546277134430127

Epoch: 5| Step: 1
Training loss: 3.096743281976692
Validation loss: 2.656808099380143

Epoch: 5| Step: 2
Training loss: 2.752165028824803
Validation loss: 2.6510501623465816

Epoch: 5| Step: 3
Training loss: 3.152774823860058
Validation loss: 2.6504164451523726

Epoch: 5| Step: 4
Training loss: 2.953607106088044
Validation loss: 2.6492957734464193

Epoch: 5| Step: 5
Training loss: 2.7431715370692933
Validation loss: 2.6499788227345706

Epoch: 5| Step: 6
Training loss: 2.965037705180096
Validation loss: 2.653192500358496

Epoch: 5| Step: 7
Training loss: 2.6737981645509183
Validation loss: 2.6532499315561577

Epoch: 5| Step: 8
Training loss: 2.704405905589074
Validation loss: 2.6528725642495514

Epoch: 5| Step: 9
Training loss: 3.257324767709536
Validation loss: 2.6573727680832326

Epoch: 5| Step: 10
Training loss: 3.726387707591635
Validation loss: 2.6571343819035214

Epoch: 100| Step: 0
Training loss: 2.8346381455377503
Validation loss: 2.6618393840614067

Epoch: 5| Step: 1
Training loss: 2.642417164120435
Validation loss: 2.6771931718890345

Epoch: 5| Step: 2
Training loss: 3.1310707634891553
Validation loss: 2.6933405038022786

Epoch: 5| Step: 3
Training loss: 2.792110369897291
Validation loss: 2.6878850145511497

Epoch: 5| Step: 4
Training loss: 3.0725710572110985
Validation loss: 2.6671279218617006

Epoch: 5| Step: 5
Training loss: 2.841602562622255
Validation loss: 2.6653626782583584

Epoch: 5| Step: 6
Training loss: 3.0359727701365737
Validation loss: 2.649080981959108

Epoch: 5| Step: 7
Training loss: 2.6628591554921797
Validation loss: 2.6521291241658664

Epoch: 5| Step: 8
Training loss: 3.559762672700205
Validation loss: 2.6492270196921135

Epoch: 5| Step: 9
Training loss: 2.8708323249390655
Validation loss: 2.6445849820289102

Epoch: 5| Step: 10
Training loss: 3.4541645125201006
Validation loss: 2.6440681251572418

Epoch: 101| Step: 0
Training loss: 3.377091783861667
Validation loss: 2.643124018190706

Epoch: 5| Step: 1
Training loss: 2.832147088148186
Validation loss: 2.645403303747303

Epoch: 5| Step: 2
Training loss: 2.588801155413781
Validation loss: 2.6425367797355834

Epoch: 5| Step: 3
Training loss: 2.9591732355157867
Validation loss: 2.644520039694527

Epoch: 5| Step: 4
Training loss: 2.4498992899222856
Validation loss: 2.6445957403241045

Epoch: 5| Step: 5
Training loss: 2.6569017396100425
Validation loss: 2.6431042170314503

Epoch: 5| Step: 6
Training loss: 2.9077166066456663
Validation loss: 2.6413289443871064

Epoch: 5| Step: 7
Training loss: 3.3248089670932335
Validation loss: 2.647120858113727

Epoch: 5| Step: 8
Training loss: 3.0296881673260287
Validation loss: 2.6613301311161868

Epoch: 5| Step: 9
Training loss: 3.1496434327812586
Validation loss: 2.6581962004111435

Epoch: 5| Step: 10
Training loss: 3.500018119765108
Validation loss: 2.693038110660788

Epoch: 102| Step: 0
Training loss: 3.446100745997206
Validation loss: 2.6521917236714234

Epoch: 5| Step: 1
Training loss: 3.2074506627106745
Validation loss: 2.6436543314526544

Epoch: 5| Step: 2
Training loss: 2.43482325372623
Validation loss: 2.6387803207743623

Epoch: 5| Step: 3
Training loss: 2.314430049990457
Validation loss: 2.6380241659729475

Epoch: 5| Step: 4
Training loss: 3.3998003452247216
Validation loss: 2.6373378961036877

Epoch: 5| Step: 5
Training loss: 2.628617201356232
Validation loss: 2.6347231529810036

Epoch: 5| Step: 6
Training loss: 2.964524162668836
Validation loss: 2.6323794216902776

Epoch: 5| Step: 7
Training loss: 2.7956030313510047
Validation loss: 2.6363176200672394

Epoch: 5| Step: 8
Training loss: 3.157600038564105
Validation loss: 2.636314781535574

Epoch: 5| Step: 9
Training loss: 2.9380108003671004
Validation loss: 2.633652754643088

Epoch: 5| Step: 10
Training loss: 3.2892231301705315
Validation loss: 2.6359531262390345

Epoch: 103| Step: 0
Training loss: 2.8137167947539288
Validation loss: 2.635157462028818

Epoch: 5| Step: 1
Training loss: 3.1737378292443843
Validation loss: 2.631816081608872

Epoch: 5| Step: 2
Training loss: 3.0535530657044823
Validation loss: 2.6349584685449665

Epoch: 5| Step: 3
Training loss: 3.3232760499119625
Validation loss: 2.6319798911529895

Epoch: 5| Step: 4
Training loss: 2.8402462009041556
Validation loss: 2.630164490712768

Epoch: 5| Step: 5
Training loss: 2.7221149360725403
Validation loss: 2.6409819666836882

Epoch: 5| Step: 6
Training loss: 2.0803020804466463
Validation loss: 2.6497119428145335

Epoch: 5| Step: 7
Training loss: 2.917549399355676
Validation loss: 2.6632541547245916

Epoch: 5| Step: 8
Training loss: 2.729520925189727
Validation loss: 2.682720701410731

Epoch: 5| Step: 9
Training loss: 3.3318214484615933
Validation loss: 2.716086291013491

Epoch: 5| Step: 10
Training loss: 3.774166818591959
Validation loss: 2.729367609868527

Epoch: 104| Step: 0
Training loss: 3.14040332220609
Validation loss: 2.681390159273441

Epoch: 5| Step: 1
Training loss: 3.033991409712055
Validation loss: 2.6505426230925817

Epoch: 5| Step: 2
Training loss: 3.023863138997238
Validation loss: 2.6279360050650697

Epoch: 5| Step: 3
Training loss: 3.161088162431808
Validation loss: 2.628707545942243

Epoch: 5| Step: 4
Training loss: 2.9315296942495057
Validation loss: 2.6317729580404934

Epoch: 5| Step: 5
Training loss: 3.4170888934497015
Validation loss: 2.63495873415593

Epoch: 5| Step: 6
Training loss: 2.99472249269069
Validation loss: 2.6430370015858498

Epoch: 5| Step: 7
Training loss: 2.6205553846440295
Validation loss: 2.645080043176237

Epoch: 5| Step: 8
Training loss: 2.77271779352947
Validation loss: 2.6388710173746697

Epoch: 5| Step: 9
Training loss: 3.1139175741156397
Validation loss: 2.6390577911686792

Epoch: 5| Step: 10
Training loss: 2.4619396288587216
Validation loss: 2.6472970235585955

Epoch: 105| Step: 0
Training loss: 2.9786856380781717
Validation loss: 2.649639380001212

Epoch: 5| Step: 1
Training loss: 3.1227819582078253
Validation loss: 2.650652415027527

Epoch: 5| Step: 2
Training loss: 3.2585998608265045
Validation loss: 2.638955683925176

Epoch: 5| Step: 3
Training loss: 2.9532867871729014
Validation loss: 2.6325759808234093

Epoch: 5| Step: 4
Training loss: 3.2262015891332
Validation loss: 2.631253969355484

Epoch: 5| Step: 5
Training loss: 3.294645739948047
Validation loss: 2.6320543716364697

Epoch: 5| Step: 6
Training loss: 3.245852244513433
Validation loss: 2.626253404041658

Epoch: 5| Step: 7
Training loss: 2.551852365020141
Validation loss: 2.6269739398649343

Epoch: 5| Step: 8
Training loss: 2.4384976815014583
Validation loss: 2.621908802496726

Epoch: 5| Step: 9
Training loss: 2.3882006151477597
Validation loss: 2.6222117773747398

Epoch: 5| Step: 10
Training loss: 3.1820023941616062
Validation loss: 2.630786457852945

Epoch: 106| Step: 0
Training loss: 2.9748020522996503
Validation loss: 2.6406065693922205

Epoch: 5| Step: 1
Training loss: 3.294615925240548
Validation loss: 2.654999996579495

Epoch: 5| Step: 2
Training loss: 3.2859224022533415
Validation loss: 2.6439437558992176

Epoch: 5| Step: 3
Training loss: 2.5161039476982183
Validation loss: 2.6330250579727252

Epoch: 5| Step: 4
Training loss: 2.8369639827255875
Validation loss: 2.6277506856251565

Epoch: 5| Step: 5
Training loss: 2.747245362607232
Validation loss: 2.6188760344394755

Epoch: 5| Step: 6
Training loss: 2.7659017133482586
Validation loss: 2.621229856145915

Epoch: 5| Step: 7
Training loss: 3.001072532939087
Validation loss: 2.6253561568372437

Epoch: 5| Step: 8
Training loss: 3.244118430321805
Validation loss: 2.626806618973476

Epoch: 5| Step: 9
Training loss: 3.0391574246602753
Validation loss: 2.6262030259499287

Epoch: 5| Step: 10
Training loss: 2.9086574304634993
Validation loss: 2.6237704194831855

Epoch: 107| Step: 0
Training loss: 3.445784832675735
Validation loss: 2.6258012659120387

Epoch: 5| Step: 1
Training loss: 2.7751663192532843
Validation loss: 2.628669984013881

Epoch: 5| Step: 2
Training loss: 3.300676513454805
Validation loss: 2.624169645612724

Epoch: 5| Step: 3
Training loss: 3.079459738474233
Validation loss: 2.6248373663896722

Epoch: 5| Step: 4
Training loss: 2.578612957639986
Validation loss: 2.621438721714215

Epoch: 5| Step: 5
Training loss: 3.5023719379721125
Validation loss: 2.6247485871050165

Epoch: 5| Step: 6
Training loss: 2.3863184416813783
Validation loss: 2.623271097377225

Epoch: 5| Step: 7
Training loss: 2.9118845473552804
Validation loss: 2.6228084654846224

Epoch: 5| Step: 8
Training loss: 3.207195096587241
Validation loss: 2.620552576974858

Epoch: 5| Step: 9
Training loss: 2.3824845885732016
Validation loss: 2.621155016245296

Epoch: 5| Step: 10
Training loss: 2.9554293890804315
Validation loss: 2.626724435586816

Epoch: 108| Step: 0
Training loss: 2.9852630731896816
Validation loss: 2.631321993390404

Epoch: 5| Step: 1
Training loss: 3.2326058234574586
Validation loss: 2.6372984342152384

Epoch: 5| Step: 2
Training loss: 2.831503351930672
Validation loss: 2.6483307574721886

Epoch: 5| Step: 3
Training loss: 2.214716078427308
Validation loss: 2.638692244748361

Epoch: 5| Step: 4
Training loss: 3.2753674774170887
Validation loss: 2.623408017938938

Epoch: 5| Step: 5
Training loss: 3.085162642533419
Validation loss: 2.617481855878106

Epoch: 5| Step: 6
Training loss: 2.9429097784628673
Validation loss: 2.6156837126193015

Epoch: 5| Step: 7
Training loss: 3.0479665512692637
Validation loss: 2.614131609184197

Epoch: 5| Step: 8
Training loss: 3.1164012863949724
Validation loss: 2.615986586254961

Epoch: 5| Step: 9
Training loss: 3.060791629043594
Validation loss: 2.6145295665157513

Epoch: 5| Step: 10
Training loss: 2.648402751143259
Validation loss: 2.616873296525917

Epoch: 109| Step: 0
Training loss: 2.3166521273186462
Validation loss: 2.617438056374961

Epoch: 5| Step: 1
Training loss: 2.6152846977514645
Validation loss: 2.6105090108701257

Epoch: 5| Step: 2
Training loss: 3.5110180318005924
Validation loss: 2.6126542000869626

Epoch: 5| Step: 3
Training loss: 2.808526092690608
Validation loss: 2.609425306065533

Epoch: 5| Step: 4
Training loss: 3.078876384289224
Validation loss: 2.612993576672677

Epoch: 5| Step: 5
Training loss: 2.705826131914677
Validation loss: 2.6118472057821505

Epoch: 5| Step: 6
Training loss: 2.540452406535223
Validation loss: 2.613220111123093

Epoch: 5| Step: 7
Training loss: 3.3343513523682593
Validation loss: 2.6159091580609646

Epoch: 5| Step: 8
Training loss: 3.2757597995586147
Validation loss: 2.612351553443535

Epoch: 5| Step: 9
Training loss: 3.301270795104495
Validation loss: 2.6161624983411946

Epoch: 5| Step: 10
Training loss: 2.8203594172160136
Validation loss: 2.6164500020685595

Epoch: 110| Step: 0
Training loss: 2.9896739631410965
Validation loss: 2.6228559247049605

Epoch: 5| Step: 1
Training loss: 3.2557214113878565
Validation loss: 2.629477310244909

Epoch: 5| Step: 2
Training loss: 2.8902950614067393
Validation loss: 2.6261869053031344

Epoch: 5| Step: 3
Training loss: 2.638720756885541
Validation loss: 2.628437342642849

Epoch: 5| Step: 4
Training loss: 2.7701893873232177
Validation loss: 2.6332871062942393

Epoch: 5| Step: 5
Training loss: 3.037512376548136
Validation loss: 2.6221516239851637

Epoch: 5| Step: 6
Training loss: 3.1931743603227125
Validation loss: 2.6157466599861703

Epoch: 5| Step: 7
Training loss: 3.267710334761816
Validation loss: 2.6074201612661625

Epoch: 5| Step: 8
Training loss: 2.880540236560385
Validation loss: 2.6128433228236756

Epoch: 5| Step: 9
Training loss: 2.865837090983307
Validation loss: 2.618480910212921

Epoch: 5| Step: 10
Training loss: 2.743685669025342
Validation loss: 2.6293801885798618

Epoch: 111| Step: 0
Training loss: 2.954422115872633
Validation loss: 2.637457125821257

Epoch: 5| Step: 1
Training loss: 3.4209819307627845
Validation loss: 2.632457067598045

Epoch: 5| Step: 2
Training loss: 3.3364077377333885
Validation loss: 2.627325601150906

Epoch: 5| Step: 3
Training loss: 3.1102899326704248
Validation loss: 2.6217938594242236

Epoch: 5| Step: 4
Training loss: 2.8262489798677706
Validation loss: 2.6183854152212653

Epoch: 5| Step: 5
Training loss: 2.970479361128048
Validation loss: 2.6180473657467984

Epoch: 5| Step: 6
Training loss: 2.566187461689324
Validation loss: 2.6187322199868377

Epoch: 5| Step: 7
Training loss: 3.2291045808463634
Validation loss: 2.6168259737224835

Epoch: 5| Step: 8
Training loss: 2.412915892651666
Validation loss: 2.6123723933857366

Epoch: 5| Step: 9
Training loss: 2.8948163961585305
Validation loss: 2.6211789179084244

Epoch: 5| Step: 10
Training loss: 2.8968643073056435
Validation loss: 2.6515309697193277

Epoch: 112| Step: 0
Training loss: 2.9219551279433356
Validation loss: 2.7113082153289576

Epoch: 5| Step: 1
Training loss: 2.915983247162009
Validation loss: 2.6653792511146532

Epoch: 5| Step: 2
Training loss: 3.0753187371031694
Validation loss: 2.651709716441334

Epoch: 5| Step: 3
Training loss: 3.287344658376134
Validation loss: 2.641874695897837

Epoch: 5| Step: 4
Training loss: 2.6747276737954624
Validation loss: 2.62354770846106

Epoch: 5| Step: 5
Training loss: 2.5905904254515817
Validation loss: 2.6177644816328365

Epoch: 5| Step: 6
Training loss: 3.1453868389109223
Validation loss: 2.6122712161480868

Epoch: 5| Step: 7
Training loss: 2.7600526869623976
Validation loss: 2.6162154891591274

Epoch: 5| Step: 8
Training loss: 2.8045565008741504
Validation loss: 2.616100850590833

Epoch: 5| Step: 9
Training loss: 3.0405379687690743
Validation loss: 2.617019870797459

Epoch: 5| Step: 10
Training loss: 3.514783427917859
Validation loss: 2.6137720161593943

Epoch: 113| Step: 0
Training loss: 3.030632821401619
Validation loss: 2.6109456147179086

Epoch: 5| Step: 1
Training loss: 2.9818695896014047
Validation loss: 2.6129494846147927

Epoch: 5| Step: 2
Training loss: 3.2517073621473025
Validation loss: 2.6171998069154254

Epoch: 5| Step: 3
Training loss: 2.6744063137474012
Validation loss: 2.6166136811582588

Epoch: 5| Step: 4
Training loss: 2.883470082944902
Validation loss: 2.615660358609995

Epoch: 5| Step: 5
Training loss: 2.894960358765004
Validation loss: 2.6113405881370113

Epoch: 5| Step: 6
Training loss: 2.9267553686488794
Validation loss: 2.6136441788010796

Epoch: 5| Step: 7
Training loss: 2.738321127172637
Validation loss: 2.607723940600458

Epoch: 5| Step: 8
Training loss: 3.0823507203820824
Validation loss: 2.619205927442504

Epoch: 5| Step: 9
Training loss: 2.894074727040717
Validation loss: 2.6358315097839786

Epoch: 5| Step: 10
Training loss: 3.2088756020442006
Validation loss: 2.6548657414563026

Epoch: 114| Step: 0
Training loss: 2.7636675615580297
Validation loss: 2.6594060785994524

Epoch: 5| Step: 1
Training loss: 3.395111350479292
Validation loss: 2.660127937740003

Epoch: 5| Step: 2
Training loss: 1.9129902853233032
Validation loss: 2.6306556320505146

Epoch: 5| Step: 3
Training loss: 2.3828106989619218
Validation loss: 2.619049842728586

Epoch: 5| Step: 4
Training loss: 3.0312882253851887
Validation loss: 2.609526203135162

Epoch: 5| Step: 5
Training loss: 2.9664244527913826
Validation loss: 2.5994619689190133

Epoch: 5| Step: 6
Training loss: 3.4650661392835453
Validation loss: 2.5958971411711316

Epoch: 5| Step: 7
Training loss: 2.8889884646282136
Validation loss: 2.5945660468389744

Epoch: 5| Step: 8
Training loss: 2.5216326326475875
Validation loss: 2.598358632236551

Epoch: 5| Step: 9
Training loss: 3.5440407070293443
Validation loss: 2.597640228530485

Epoch: 5| Step: 10
Training loss: 3.2267778153887905
Validation loss: 2.598416256218551

Epoch: 115| Step: 0
Training loss: 2.845149272361477
Validation loss: 2.6028302310300475

Epoch: 5| Step: 1
Training loss: 3.084456694505657
Validation loss: 2.5972667425814366

Epoch: 5| Step: 2
Training loss: 2.7195978706087827
Validation loss: 2.5979777559447856

Epoch: 5| Step: 3
Training loss: 3.097693040203578
Validation loss: 2.6007350413884844

Epoch: 5| Step: 4
Training loss: 3.3976666858869824
Validation loss: 2.596439539176098

Epoch: 5| Step: 5
Training loss: 3.0009632153746466
Validation loss: 2.59214377159523

Epoch: 5| Step: 6
Training loss: 2.88192131513228
Validation loss: 2.589342688412495

Epoch: 5| Step: 7
Training loss: 3.144617077147812
Validation loss: 2.589243263281767

Epoch: 5| Step: 8
Training loss: 3.1861105489762673
Validation loss: 2.59400722702364

Epoch: 5| Step: 9
Training loss: 1.9544764611404506
Validation loss: 2.595248144891525

Epoch: 5| Step: 10
Training loss: 2.8818627423778813
Validation loss: 2.613319342126659

Epoch: 116| Step: 0
Training loss: 2.7817549515007562
Validation loss: 2.6194462043326743

Epoch: 5| Step: 1
Training loss: 2.5553553463652583
Validation loss: 2.640065180860098

Epoch: 5| Step: 2
Training loss: 2.8966348394204497
Validation loss: 2.6575413382584205

Epoch: 5| Step: 3
Training loss: 2.957292310914635
Validation loss: 2.6594679255451648

Epoch: 5| Step: 4
Training loss: 3.2395507385642124
Validation loss: 2.6000760203386695

Epoch: 5| Step: 5
Training loss: 3.2359086238469725
Validation loss: 2.58044004887773

Epoch: 5| Step: 6
Training loss: 2.9516560771399645
Validation loss: 2.5852138506932345

Epoch: 5| Step: 7
Training loss: 3.1518342505700403
Validation loss: 2.5951791209686035

Epoch: 5| Step: 8
Training loss: 2.5777605203712235
Validation loss: 2.6027207847656153

Epoch: 5| Step: 9
Training loss: 3.0635811590567403
Validation loss: 2.6161935039353525

Epoch: 5| Step: 10
Training loss: 3.1345471837832144
Validation loss: 2.6237507204453068

Epoch: 117| Step: 0
Training loss: 2.7889528226257747
Validation loss: 2.6246948982906333

Epoch: 5| Step: 1
Training loss: 3.453096001274589
Validation loss: 2.6348929493830986

Epoch: 5| Step: 2
Training loss: 2.758021878947558
Validation loss: 2.6375007182663985

Epoch: 5| Step: 3
Training loss: 3.0839481943531575
Validation loss: 2.634525778033146

Epoch: 5| Step: 4
Training loss: 3.149071414257658
Validation loss: 2.632371273163428

Epoch: 5| Step: 5
Training loss: 2.564012964712802
Validation loss: 2.619749692999247

Epoch: 5| Step: 6
Training loss: 2.7930698189755074
Validation loss: 2.6100031451769468

Epoch: 5| Step: 7
Training loss: 2.657659627833898
Validation loss: 2.6038396033538604

Epoch: 5| Step: 8
Training loss: 3.2016791825560373
Validation loss: 2.5993772019526276

Epoch: 5| Step: 9
Training loss: 2.8362243339147275
Validation loss: 2.5985420438317024

Epoch: 5| Step: 10
Training loss: 3.4435758127790557
Validation loss: 2.594896848014158

Epoch: 118| Step: 0
Training loss: 2.9765032264234454
Validation loss: 2.5935683727361667

Epoch: 5| Step: 1
Training loss: 2.586890007762596
Validation loss: 2.5969646659856105

Epoch: 5| Step: 2
Training loss: 2.892826705853231
Validation loss: 2.594245015367896

Epoch: 5| Step: 3
Training loss: 3.029576104857257
Validation loss: 2.6059665112520696

Epoch: 5| Step: 4
Training loss: 2.8741520170120665
Validation loss: 2.6073939045205496

Epoch: 5| Step: 5
Training loss: 2.834229682805799
Validation loss: 2.6133554599738535

Epoch: 5| Step: 6
Training loss: 2.751404663619265
Validation loss: 2.615421620805584

Epoch: 5| Step: 7
Training loss: 2.761313747293565
Validation loss: 2.6083660880744266

Epoch: 5| Step: 8
Training loss: 3.3208182634101844
Validation loss: 2.6308411702641203

Epoch: 5| Step: 9
Training loss: 3.081001293366584
Validation loss: 2.5935561395166133

Epoch: 5| Step: 10
Training loss: 3.4214015964180775
Validation loss: 2.5832857249302696

Epoch: 119| Step: 0
Training loss: 2.2277290366916684
Validation loss: 2.5745910886145302

Epoch: 5| Step: 1
Training loss: 2.9729906813869715
Validation loss: 2.5752304279892173

Epoch: 5| Step: 2
Training loss: 2.984968675611985
Validation loss: 2.574646778134872

Epoch: 5| Step: 3
Training loss: 3.2265499382605802
Validation loss: 2.5757204866763295

Epoch: 5| Step: 4
Training loss: 3.3927817802377134
Validation loss: 2.577331066722994

Epoch: 5| Step: 5
Training loss: 3.0195969430111345
Validation loss: 2.5769850491851165

Epoch: 5| Step: 6
Training loss: 2.9105363635983186
Validation loss: 2.581960511476194

Epoch: 5| Step: 7
Training loss: 2.702373422204472
Validation loss: 2.582159265467915

Epoch: 5| Step: 8
Training loss: 2.839094438304978
Validation loss: 2.57941997343829

Epoch: 5| Step: 9
Training loss: 2.8505131711228975
Validation loss: 2.5763034763463994

Epoch: 5| Step: 10
Training loss: 3.119442079006652
Validation loss: 2.580344970657627

Epoch: 120| Step: 0
Training loss: 2.94140316987098
Validation loss: 2.5808012415552306

Epoch: 5| Step: 1
Training loss: 2.981510725156566
Validation loss: 2.5832818476388875

Epoch: 5| Step: 2
Training loss: 3.3818386164893375
Validation loss: 2.583891950765368

Epoch: 5| Step: 3
Training loss: 3.0802160605904634
Validation loss: 2.5820307644828753

Epoch: 5| Step: 4
Training loss: 2.537509478471464
Validation loss: 2.5847912550344923

Epoch: 5| Step: 5
Training loss: 3.1103987805481865
Validation loss: 2.582388566839313

Epoch: 5| Step: 6
Training loss: 2.9082519855071114
Validation loss: 2.586215683449846

Epoch: 5| Step: 7
Training loss: 2.656785439772252
Validation loss: 2.585328288139953

Epoch: 5| Step: 8
Training loss: 2.4506850044047295
Validation loss: 2.579916264702294

Epoch: 5| Step: 9
Training loss: 2.996399626355803
Validation loss: 2.5804033302302973

Epoch: 5| Step: 10
Training loss: 3.1519322841748103
Validation loss: 2.576977442767208

Epoch: 121| Step: 0
Training loss: 3.113175566254374
Validation loss: 2.5686991919974442

Epoch: 5| Step: 1
Training loss: 2.54917588474103
Validation loss: 2.568119631072199

Epoch: 5| Step: 2
Training loss: 2.3139729319566125
Validation loss: 2.5679208586461493

Epoch: 5| Step: 3
Training loss: 2.9699426764919132
Validation loss: 2.565124844112271

Epoch: 5| Step: 4
Training loss: 3.0586305423633195
Validation loss: 2.5663086494320515

Epoch: 5| Step: 5
Training loss: 2.7063956347036493
Validation loss: 2.567342101602938

Epoch: 5| Step: 6
Training loss: 3.6558152942952984
Validation loss: 2.5662370479487397

Epoch: 5| Step: 7
Training loss: 2.718149228421116
Validation loss: 2.5641460599278596

Epoch: 5| Step: 8
Training loss: 3.3530884583429432
Validation loss: 2.5638223613094433

Epoch: 5| Step: 9
Training loss: 2.5657293858358394
Validation loss: 2.563668008604199

Epoch: 5| Step: 10
Training loss: 3.032723294911043
Validation loss: 2.5639049611236144

Epoch: 122| Step: 0
Training loss: 2.948524241745792
Validation loss: 2.563318983572008

Epoch: 5| Step: 1
Training loss: 3.0785218578440583
Validation loss: 2.5691407277395824

Epoch: 5| Step: 2
Training loss: 2.842713051681731
Validation loss: 2.571794078082486

Epoch: 5| Step: 3
Training loss: 2.9351626897948884
Validation loss: 2.5830174913621837

Epoch: 5| Step: 4
Training loss: 2.8355139213735527
Validation loss: 2.60327312735101

Epoch: 5| Step: 5
Training loss: 3.1576248045212605
Validation loss: 2.62750371092979

Epoch: 5| Step: 6
Training loss: 3.091989035306886
Validation loss: 2.6114690084886427

Epoch: 5| Step: 7
Training loss: 2.726179997849788
Validation loss: 2.584406005484512

Epoch: 5| Step: 8
Training loss: 3.083979118009294
Validation loss: 2.5732372479950705

Epoch: 5| Step: 9
Training loss: 2.647839684096411
Validation loss: 2.567046174791756

Epoch: 5| Step: 10
Training loss: 2.9327908368293727
Validation loss: 2.5665428559920525

Epoch: 123| Step: 0
Training loss: 2.6966439759282568
Validation loss: 2.5643117009203977

Epoch: 5| Step: 1
Training loss: 2.9496424894781508
Validation loss: 2.564005052849669

Epoch: 5| Step: 2
Training loss: 3.0499017793442893
Validation loss: 2.563833910464757

Epoch: 5| Step: 3
Training loss: 2.8778640744768595
Validation loss: 2.562604521373782

Epoch: 5| Step: 4
Training loss: 3.028584989995489
Validation loss: 2.5641542552990337

Epoch: 5| Step: 5
Training loss: 3.2746308912234494
Validation loss: 2.5653042919413016

Epoch: 5| Step: 6
Training loss: 2.497179156554291
Validation loss: 2.563792841232038

Epoch: 5| Step: 7
Training loss: 3.0984775373264215
Validation loss: 2.561012702831814

Epoch: 5| Step: 8
Training loss: 2.9224967091120067
Validation loss: 2.5638264930132344

Epoch: 5| Step: 9
Training loss: 2.8923852458271044
Validation loss: 2.562356804289021

Epoch: 5| Step: 10
Training loss: 2.8804081346814145
Validation loss: 2.5657282087945745

Epoch: 124| Step: 0
Training loss: 2.8079822283071034
Validation loss: 2.567014259988715

Epoch: 5| Step: 1
Training loss: 2.8227798785374287
Validation loss: 2.570578409181933

Epoch: 5| Step: 2
Training loss: 2.837992614467654
Validation loss: 2.5675885289594724

Epoch: 5| Step: 3
Training loss: 2.7951741934390206
Validation loss: 2.567881814536399

Epoch: 5| Step: 4
Training loss: 2.84131392212778
Validation loss: 2.569452011007091

Epoch: 5| Step: 5
Training loss: 3.06741965489455
Validation loss: 2.5730557798717193

Epoch: 5| Step: 6
Training loss: 3.064428228468019
Validation loss: 2.5665551340630155

Epoch: 5| Step: 7
Training loss: 2.970586911147305
Validation loss: 2.566777014214777

Epoch: 5| Step: 8
Training loss: 3.143195016460007
Validation loss: 2.565857681095854

Epoch: 5| Step: 9
Training loss: 2.9143488439032073
Validation loss: 2.5642863344349

Epoch: 5| Step: 10
Training loss: 2.804781091345175
Validation loss: 2.5634268288346385

Epoch: 125| Step: 0
Training loss: 3.379077144115865
Validation loss: 2.561766832955453

Epoch: 5| Step: 1
Training loss: 2.567053308305674
Validation loss: 2.5623996123692314

Epoch: 5| Step: 2
Training loss: 2.9815022487807825
Validation loss: 2.5602356565360322

Epoch: 5| Step: 3
Training loss: 2.7893886856266468
Validation loss: 2.558159287886193

Epoch: 5| Step: 4
Training loss: 2.7439374855305125
Validation loss: 2.5601757377528114

Epoch: 5| Step: 5
Training loss: 3.3456374215947107
Validation loss: 2.561790159899331

Epoch: 5| Step: 6
Training loss: 2.2487377228754264
Validation loss: 2.5615955300243813

Epoch: 5| Step: 7
Training loss: 3.3707517094547312
Validation loss: 2.564982026817635

Epoch: 5| Step: 8
Training loss: 2.9516334601899654
Validation loss: 2.5619333242401283

Epoch: 5| Step: 9
Training loss: 3.0149540129992842
Validation loss: 2.558705194972698

Epoch: 5| Step: 10
Training loss: 2.354583219511207
Validation loss: 2.55417474399716

Epoch: 126| Step: 0
Training loss: 3.141296922156423
Validation loss: 2.5558373859236077

Epoch: 5| Step: 1
Training loss: 2.870899095229617
Validation loss: 2.5549172149536767

Epoch: 5| Step: 2
Training loss: 3.358032384092617
Validation loss: 2.554018261430957

Epoch: 5| Step: 3
Training loss: 2.9425469728413733
Validation loss: 2.5536166149270865

Epoch: 5| Step: 4
Training loss: 3.1095212969077495
Validation loss: 2.5539502492517374

Epoch: 5| Step: 5
Training loss: 2.5804913382677728
Validation loss: 2.556818672976463

Epoch: 5| Step: 6
Training loss: 2.685864771667738
Validation loss: 2.5541675935852726

Epoch: 5| Step: 7
Training loss: 2.9517882212835165
Validation loss: 2.552766158014538

Epoch: 5| Step: 8
Training loss: 2.6993016894084136
Validation loss: 2.5548356099737624

Epoch: 5| Step: 9
Training loss: 2.836778584329632
Validation loss: 2.554163628932211

Epoch: 5| Step: 10
Training loss: 2.7894162934033444
Validation loss: 2.5494394161110265

Epoch: 127| Step: 0
Training loss: 2.7109721508614917
Validation loss: 2.5521694032387456

Epoch: 5| Step: 1
Training loss: 2.805393310824343
Validation loss: 2.550507441939293

Epoch: 5| Step: 2
Training loss: 2.9304523741128023
Validation loss: 2.553776293810207

Epoch: 5| Step: 3
Training loss: 2.525330013955072
Validation loss: 2.555304089197623

Epoch: 5| Step: 4
Training loss: 2.8372347468276145
Validation loss: 2.559474763515136

Epoch: 5| Step: 5
Training loss: 2.581247646524682
Validation loss: 2.5643718874593096

Epoch: 5| Step: 6
Training loss: 2.919489248625409
Validation loss: 2.5810466997460044

Epoch: 5| Step: 7
Training loss: 3.1793068697817155
Validation loss: 2.5554874182992795

Epoch: 5| Step: 8
Training loss: 3.2465583477972264
Validation loss: 2.5513921022987107

Epoch: 5| Step: 9
Training loss: 3.1991884931127976
Validation loss: 2.5557101093577628

Epoch: 5| Step: 10
Training loss: 3.119613124385362
Validation loss: 2.5602969622280742

Epoch: 128| Step: 0
Training loss: 2.6934270926324357
Validation loss: 2.5711898585480277

Epoch: 5| Step: 1
Training loss: 3.2135416501795904
Validation loss: 2.5746544083656464

Epoch: 5| Step: 2
Training loss: 2.407746382293819
Validation loss: 2.5823761605367177

Epoch: 5| Step: 3
Training loss: 3.067208077142594
Validation loss: 2.576337541856962

Epoch: 5| Step: 4
Training loss: 3.4470700303044675
Validation loss: 2.5622629165522914

Epoch: 5| Step: 5
Training loss: 3.115859434745066
Validation loss: 2.5544999933034194

Epoch: 5| Step: 6
Training loss: 2.866703002906398
Validation loss: 2.555723805690267

Epoch: 5| Step: 7
Training loss: 2.7838917733564497
Validation loss: 2.5526042461019673

Epoch: 5| Step: 8
Training loss: 2.386326834159548
Validation loss: 2.549582020095808

Epoch: 5| Step: 9
Training loss: 2.750385777550852
Validation loss: 2.5512912715678966

Epoch: 5| Step: 10
Training loss: 3.3539363395004065
Validation loss: 2.5556498382027186

Epoch: 129| Step: 0
Training loss: 2.9270644181659655
Validation loss: 2.5626326260784507

Epoch: 5| Step: 1
Training loss: 2.368940453434346
Validation loss: 2.565893193138952

Epoch: 5| Step: 2
Training loss: 3.1366479088941617
Validation loss: 2.5757930308225747

Epoch: 5| Step: 3
Training loss: 2.5563591670297297
Validation loss: 2.5835132780992085

Epoch: 5| Step: 4
Training loss: 3.050669180830117
Validation loss: 2.591674658381149

Epoch: 5| Step: 5
Training loss: 2.687235708326628
Validation loss: 2.595570050854478

Epoch: 5| Step: 6
Training loss: 3.190701541113316
Validation loss: 2.609730501343764

Epoch: 5| Step: 7
Training loss: 3.1329911863590856
Validation loss: 2.591063575883888

Epoch: 5| Step: 8
Training loss: 3.089243216816851
Validation loss: 2.5725327902410124

Epoch: 5| Step: 9
Training loss: 3.0776201018039626
Validation loss: 2.553328816961891

Epoch: 5| Step: 10
Training loss: 2.8063951144685926
Validation loss: 2.546808683446855

Epoch: 130| Step: 0
Training loss: 2.5202304550032095
Validation loss: 2.546854624668929

Epoch: 5| Step: 1
Training loss: 2.5094898354369515
Validation loss: 2.550259531942271

Epoch: 5| Step: 2
Training loss: 3.133998579734573
Validation loss: 2.563157300187588

Epoch: 5| Step: 3
Training loss: 3.3363237001090256
Validation loss: 2.583555968816964

Epoch: 5| Step: 4
Training loss: 3.0035249346527912
Validation loss: 2.5578308486077392

Epoch: 5| Step: 5
Training loss: 3.0093246820190545
Validation loss: 2.5531080876123604

Epoch: 5| Step: 6
Training loss: 3.2776754618335033
Validation loss: 2.55146914423116

Epoch: 5| Step: 7
Training loss: 3.132172707084396
Validation loss: 2.5482972617506334

Epoch: 5| Step: 8
Training loss: 2.8498451391610224
Validation loss: 2.54609434181059

Epoch: 5| Step: 9
Training loss: 2.645342703757815
Validation loss: 2.5417678422188428

Epoch: 5| Step: 10
Training loss: 2.5708802126706742
Validation loss: 2.548092715381731

Epoch: 131| Step: 0
Training loss: 2.8774612506342057
Validation loss: 2.550623848632635

Epoch: 5| Step: 1
Training loss: 2.6175068674662363
Validation loss: 2.5603666521751856

Epoch: 5| Step: 2
Training loss: 2.845995509012074
Validation loss: 2.569292649302205

Epoch: 5| Step: 3
Training loss: 2.7954845701749425
Validation loss: 2.5805323950743357

Epoch: 5| Step: 4
Training loss: 3.157180799960258
Validation loss: 2.5908847059925053

Epoch: 5| Step: 5
Training loss: 3.3312684021060384
Validation loss: 2.592914856536126

Epoch: 5| Step: 6
Training loss: 2.4645091462974604
Validation loss: 2.5808221892490897

Epoch: 5| Step: 7
Training loss: 2.5000795351728193
Validation loss: 2.5641060155099082

Epoch: 5| Step: 8
Training loss: 3.1591042180900577
Validation loss: 2.5517029797563775

Epoch: 5| Step: 9
Training loss: 2.955225928846616
Validation loss: 2.5485411216523937

Epoch: 5| Step: 10
Training loss: 3.0910910537523626
Validation loss: 2.5500233543174247

Epoch: 132| Step: 0
Training loss: 2.3960967430491578
Validation loss: 2.5486278218392875

Epoch: 5| Step: 1
Training loss: 3.3207579549533177
Validation loss: 2.558380511341458

Epoch: 5| Step: 2
Training loss: 3.1057313052335385
Validation loss: 2.558514347455324

Epoch: 5| Step: 3
Training loss: 3.262920519156275
Validation loss: 2.5617399951988657

Epoch: 5| Step: 4
Training loss: 3.024387259729475
Validation loss: 2.564861905855181

Epoch: 5| Step: 5
Training loss: 3.2401840454386894
Validation loss: 2.5665647061630152

Epoch: 5| Step: 6
Training loss: 2.4305917706894773
Validation loss: 2.5605574947938012

Epoch: 5| Step: 7
Training loss: 2.733127767307181
Validation loss: 2.559075015264743

Epoch: 5| Step: 8
Training loss: 3.416012274869712
Validation loss: 2.5566184684057625

Epoch: 5| Step: 9
Training loss: 2.2101145584311146
Validation loss: 2.5520865471530656

Epoch: 5| Step: 10
Training loss: 2.6513672774228807
Validation loss: 2.549543549842143

Epoch: 133| Step: 0
Training loss: 2.9513983951988956
Validation loss: 2.5472606128202795

Epoch: 5| Step: 1
Training loss: 2.861420113709043
Validation loss: 2.5445010900502294

Epoch: 5| Step: 2
Training loss: 2.7695750675582143
Validation loss: 2.5509686019233597

Epoch: 5| Step: 3
Training loss: 2.728410242294283
Validation loss: 2.562644640274215

Epoch: 5| Step: 4
Training loss: 2.5026464759724876
Validation loss: 2.5642667302975974

Epoch: 5| Step: 5
Training loss: 3.026803127131026
Validation loss: 2.5774165627290153

Epoch: 5| Step: 6
Training loss: 3.3840256557348787
Validation loss: 2.574173286190007

Epoch: 5| Step: 7
Training loss: 2.7646825876555594
Validation loss: 2.5749711450524533

Epoch: 5| Step: 8
Training loss: 2.910280283902494
Validation loss: 2.573384578252401

Epoch: 5| Step: 9
Training loss: 2.525553757782096
Validation loss: 2.58121855913106

Epoch: 5| Step: 10
Training loss: 3.4338902333511756
Validation loss: 2.580065718517566

Epoch: 134| Step: 0
Training loss: 2.736491403330273
Validation loss: 2.5616198973472386

Epoch: 5| Step: 1
Training loss: 2.8409039015289075
Validation loss: 2.560676655331864

Epoch: 5| Step: 2
Training loss: 2.82710348828149
Validation loss: 2.5494714312581808

Epoch: 5| Step: 3
Training loss: 3.1332952645877294
Validation loss: 2.5577981092038264

Epoch: 5| Step: 4
Training loss: 2.446104366312348
Validation loss: 2.55413268435267

Epoch: 5| Step: 5
Training loss: 3.1283051369367976
Validation loss: 2.55558747004424

Epoch: 5| Step: 6
Training loss: 3.1756264436534956
Validation loss: 2.5568829672602034

Epoch: 5| Step: 7
Training loss: 2.7507928225602387
Validation loss: 2.5596081042238215

Epoch: 5| Step: 8
Training loss: 3.033605859552028
Validation loss: 2.5587404496013963

Epoch: 5| Step: 9
Training loss: 2.882200098507547
Validation loss: 2.5564047280310755

Epoch: 5| Step: 10
Training loss: 2.9122605057509765
Validation loss: 2.5637466445585466

Epoch: 135| Step: 0
Training loss: 3.149338661888109
Validation loss: 2.5625143823587706

Epoch: 5| Step: 1
Training loss: 2.9806573690623357
Validation loss: 2.5692318166970405

Epoch: 5| Step: 2
Training loss: 2.9255370991880425
Validation loss: 2.568698374610176

Epoch: 5| Step: 3
Training loss: 2.656336345391184
Validation loss: 2.564568384879906

Epoch: 5| Step: 4
Training loss: 3.09582111121769
Validation loss: 2.5686732879801846

Epoch: 5| Step: 5
Training loss: 2.9477928504058437
Validation loss: 2.5631455269408883

Epoch: 5| Step: 6
Training loss: 2.5929848335137393
Validation loss: 2.5667853829627236

Epoch: 5| Step: 7
Training loss: 2.677206330992906
Validation loss: 2.5682086190547904

Epoch: 5| Step: 8
Training loss: 2.6053722998569353
Validation loss: 2.5739520266808347

Epoch: 5| Step: 9
Training loss: 3.3296714377765446
Validation loss: 2.5764750769993587

Epoch: 5| Step: 10
Training loss: 3.0095972092014738
Validation loss: 2.5794525874896976

Epoch: 136| Step: 0
Training loss: 2.628819003648382
Validation loss: 2.5855983036675845

Epoch: 5| Step: 1
Training loss: 3.268293686593384
Validation loss: 2.593211027451509

Epoch: 5| Step: 2
Training loss: 2.5203141762904666
Validation loss: 2.597916000348626

Epoch: 5| Step: 3
Training loss: 2.623004245482662
Validation loss: 2.594691122983843

Epoch: 5| Step: 4
Training loss: 2.8860037489858112
Validation loss: 2.5971636507176594

Epoch: 5| Step: 5
Training loss: 3.0272999618809004
Validation loss: 2.600969897399429

Epoch: 5| Step: 6
Training loss: 2.6160188257665764
Validation loss: 2.5957609155835324

Epoch: 5| Step: 7
Training loss: 2.9583719456978015
Validation loss: 2.589853635936231

Epoch: 5| Step: 8
Training loss: 3.272778283068456
Validation loss: 2.5918911182029363

Epoch: 5| Step: 9
Training loss: 2.8578160106038784
Validation loss: 2.581585891156306

Epoch: 5| Step: 10
Training loss: 3.28490890678553
Validation loss: 2.5815578502865377

Epoch: 137| Step: 0
Training loss: 3.1386946634012487
Validation loss: 2.563375829073996

Epoch: 5| Step: 1
Training loss: 2.237876549262168
Validation loss: 2.552356545793745

Epoch: 5| Step: 2
Training loss: 2.859279276595307
Validation loss: 2.550663498647443

Epoch: 5| Step: 3
Training loss: 2.899009463076034
Validation loss: 2.5470796723410927

Epoch: 5| Step: 4
Training loss: 2.790970948103975
Validation loss: 2.537305481011518

Epoch: 5| Step: 5
Training loss: 2.992486764469053
Validation loss: 2.5320046749551026

Epoch: 5| Step: 6
Training loss: 3.0931417464525386
Validation loss: 2.535796996201878

Epoch: 5| Step: 7
Training loss: 2.343370941026737
Validation loss: 2.53274585516027

Epoch: 5| Step: 8
Training loss: 3.226760821216668
Validation loss: 2.5298795505852825

Epoch: 5| Step: 9
Training loss: 3.152523749411031
Validation loss: 2.534037912322094

Epoch: 5| Step: 10
Training loss: 2.9012034911537175
Validation loss: 2.524563523057136

Epoch: 138| Step: 0
Training loss: 2.9322264389091925
Validation loss: 2.5304151014200227

Epoch: 5| Step: 1
Training loss: 2.8895581725404176
Validation loss: 2.53133379130226

Epoch: 5| Step: 2
Training loss: 3.0395410156093123
Validation loss: 2.5279422438159593

Epoch: 5| Step: 3
Training loss: 2.6546254295021496
Validation loss: 2.532955717651775

Epoch: 5| Step: 4
Training loss: 3.1534899739507822
Validation loss: 2.537313892404263

Epoch: 5| Step: 5
Training loss: 2.478563529198702
Validation loss: 2.532539629613646

Epoch: 5| Step: 6
Training loss: 2.373053505970674
Validation loss: 2.538472360793629

Epoch: 5| Step: 7
Training loss: 2.917853540804181
Validation loss: 2.5410918061933367

Epoch: 5| Step: 8
Training loss: 3.0645427508404115
Validation loss: 2.5369420296719754

Epoch: 5| Step: 9
Training loss: 2.9118422981255065
Validation loss: 2.543591173344447

Epoch: 5| Step: 10
Training loss: 3.2603081308322976
Validation loss: 2.54002141497131

Epoch: 139| Step: 0
Training loss: 3.005907917188451
Validation loss: 2.5410001725805125

Epoch: 5| Step: 1
Training loss: 2.7459480605134536
Validation loss: 2.546125973109153

Epoch: 5| Step: 2
Training loss: 2.8415270490458093
Validation loss: 2.544622269886735

Epoch: 5| Step: 3
Training loss: 3.313963656680298
Validation loss: 2.547721695378781

Epoch: 5| Step: 4
Training loss: 2.5385830000960112
Validation loss: 2.5467813437986746

Epoch: 5| Step: 5
Training loss: 2.493186248310023
Validation loss: 2.5386994425882676

Epoch: 5| Step: 6
Training loss: 2.8508104142515984
Validation loss: 2.53122523093249

Epoch: 5| Step: 7
Training loss: 3.081669814041316
Validation loss: 2.529149861825681

Epoch: 5| Step: 8
Training loss: 2.8619929768324863
Validation loss: 2.5255330104643985

Epoch: 5| Step: 9
Training loss: 3.242226032809426
Validation loss: 2.523061386174958

Epoch: 5| Step: 10
Training loss: 2.5936020958336017
Validation loss: 2.526541763766364

Epoch: 140| Step: 0
Training loss: 2.9925461994833897
Validation loss: 2.5245594083338476

Epoch: 5| Step: 1
Training loss: 2.894507198259553
Validation loss: 2.5237488628998985

Epoch: 5| Step: 2
Training loss: 2.7792212126801332
Validation loss: 2.52160827744578

Epoch: 5| Step: 3
Training loss: 3.0238308120910746
Validation loss: 2.5275535660602912

Epoch: 5| Step: 4
Training loss: 2.868947333569477
Validation loss: 2.5268610330854986

Epoch: 5| Step: 5
Training loss: 2.949117858373606
Validation loss: 2.5244844992942044

Epoch: 5| Step: 6
Training loss: 2.480450775802249
Validation loss: 2.5255491259650498

Epoch: 5| Step: 7
Training loss: 2.237750298336496
Validation loss: 2.5269181762606046

Epoch: 5| Step: 8
Training loss: 3.2055070161220542
Validation loss: 2.5262374133953838

Epoch: 5| Step: 9
Training loss: 3.15694653973946
Validation loss: 2.530473833937894

Epoch: 5| Step: 10
Training loss: 2.9573053714174415
Validation loss: 2.528440245054384

Epoch: 141| Step: 0
Training loss: 3.1732047164187573
Validation loss: 2.5318330948725976

Epoch: 5| Step: 1
Training loss: 2.750704761710386
Validation loss: 2.5255479565897776

Epoch: 5| Step: 2
Training loss: 3.2066868772550534
Validation loss: 2.5241737298765035

Epoch: 5| Step: 3
Training loss: 2.5205880248036747
Validation loss: 2.5201523660317195

Epoch: 5| Step: 4
Training loss: 3.2810567163124715
Validation loss: 2.5251547559376766

Epoch: 5| Step: 5
Training loss: 2.513462724854335
Validation loss: 2.5213638695883662

Epoch: 5| Step: 6
Training loss: 3.0415726912800114
Validation loss: 2.5216650028639553

Epoch: 5| Step: 7
Training loss: 2.3252479133920603
Validation loss: 2.516743616039974

Epoch: 5| Step: 8
Training loss: 2.943268813149339
Validation loss: 2.5126683556651503

Epoch: 5| Step: 9
Training loss: 2.781794719716101
Validation loss: 2.522597597016085

Epoch: 5| Step: 10
Training loss: 2.9254709239630334
Validation loss: 2.5154518399557886

Epoch: 142| Step: 0
Training loss: 2.220299408113672
Validation loss: 2.515353200938928

Epoch: 5| Step: 1
Training loss: 2.7880985079346656
Validation loss: 2.5165085868461485

Epoch: 5| Step: 2
Training loss: 2.799360055681297
Validation loss: 2.51608129964325

Epoch: 5| Step: 3
Training loss: 2.9152420561125862
Validation loss: 2.51522119922319

Epoch: 5| Step: 4
Training loss: 2.882498540555348
Validation loss: 2.5126167980382177

Epoch: 5| Step: 5
Training loss: 3.2807733098679934
Validation loss: 2.514411981832956

Epoch: 5| Step: 6
Training loss: 3.1504290697243538
Validation loss: 2.51412493572143

Epoch: 5| Step: 7
Training loss: 2.659104642113804
Validation loss: 2.5144324650834964

Epoch: 5| Step: 8
Training loss: 2.5229592829747736
Validation loss: 2.5151913808710775

Epoch: 5| Step: 9
Training loss: 2.7508794938723016
Validation loss: 2.5124526262906137

Epoch: 5| Step: 10
Training loss: 3.4774019406587113
Validation loss: 2.507065820909221

Epoch: 143| Step: 0
Training loss: 2.8784838590449358
Validation loss: 2.5153070777714346

Epoch: 5| Step: 1
Training loss: 2.700427523073531
Validation loss: 2.5172707049626166

Epoch: 5| Step: 2
Training loss: 2.870930154512193
Validation loss: 2.526146623168768

Epoch: 5| Step: 3
Training loss: 2.629562953418071
Validation loss: 2.5315752021810565

Epoch: 5| Step: 4
Training loss: 2.9971676807863936
Validation loss: 2.5326394445835816

Epoch: 5| Step: 5
Training loss: 3.03484233867756
Validation loss: 2.5410277862988004

Epoch: 5| Step: 6
Training loss: 2.8266909846873247
Validation loss: 2.5447081102563054

Epoch: 5| Step: 7
Training loss: 2.6750335762554904
Validation loss: 2.5431146094868513

Epoch: 5| Step: 8
Training loss: 3.1255138737650254
Validation loss: 2.5396591437132745

Epoch: 5| Step: 9
Training loss: 2.734249177490178
Validation loss: 2.5297275169160702

Epoch: 5| Step: 10
Training loss: 3.1058185116518535
Validation loss: 2.5247572039844077

Epoch: 144| Step: 0
Training loss: 2.7427491919669578
Validation loss: 2.526594561264095

Epoch: 5| Step: 1
Training loss: 3.175113021160594
Validation loss: 2.512801349501494

Epoch: 5| Step: 2
Training loss: 3.2594199480155934
Validation loss: 2.514893123877518

Epoch: 5| Step: 3
Training loss: 2.647018907906764
Validation loss: 2.5136094229662387

Epoch: 5| Step: 4
Training loss: 2.85556994466294
Validation loss: 2.513403334728752

Epoch: 5| Step: 5
Training loss: 2.1972916665123474
Validation loss: 2.512463789154325

Epoch: 5| Step: 6
Training loss: 3.424263177401157
Validation loss: 2.518298850407312

Epoch: 5| Step: 7
Training loss: 2.6389134746097778
Validation loss: 2.522677367880145

Epoch: 5| Step: 8
Training loss: 3.3714143991749745
Validation loss: 2.5217957584490036

Epoch: 5| Step: 9
Training loss: 2.4739776503494753
Validation loss: 2.5182906727604615

Epoch: 5| Step: 10
Training loss: 2.2794608847376234
Validation loss: 2.512743972012495

Epoch: 145| Step: 0
Training loss: 3.1166502219461574
Validation loss: 2.5142186092775476

Epoch: 5| Step: 1
Training loss: 2.6242752891325742
Validation loss: 2.5113404217321555

Epoch: 5| Step: 2
Training loss: 2.5135794906415683
Validation loss: 2.503605791528071

Epoch: 5| Step: 3
Training loss: 2.656771709594303
Validation loss: 2.506514800693411

Epoch: 5| Step: 4
Training loss: 3.0493096430194213
Validation loss: 2.5038271978172553

Epoch: 5| Step: 5
Training loss: 2.797972991065877
Validation loss: 2.50187059837781

Epoch: 5| Step: 6
Training loss: 2.930064428877469
Validation loss: 2.4994115403516886

Epoch: 5| Step: 7
Training loss: 3.299752376398028
Validation loss: 2.5118996616537

Epoch: 5| Step: 8
Training loss: 3.027184503120049
Validation loss: 2.517672311578089

Epoch: 5| Step: 9
Training loss: 2.4479575187574962
Validation loss: 2.5247587209928364

Epoch: 5| Step: 10
Training loss: 2.937457145215989
Validation loss: 2.533039507182366

Epoch: 146| Step: 0
Training loss: 3.0960992698033056
Validation loss: 2.5290979519132293

Epoch: 5| Step: 1
Training loss: 2.7913899260800856
Validation loss: 2.521243348248893

Epoch: 5| Step: 2
Training loss: 2.9514546186320954
Validation loss: 2.519006908687465

Epoch: 5| Step: 3
Training loss: 3.0611376164883666
Validation loss: 2.5132994519285927

Epoch: 5| Step: 4
Training loss: 2.737812257837904
Validation loss: 2.5150097738169976

Epoch: 5| Step: 5
Training loss: 2.6260582743423075
Validation loss: 2.5200384714531987

Epoch: 5| Step: 6
Training loss: 3.0191247427087426
Validation loss: 2.5135011914693877

Epoch: 5| Step: 7
Training loss: 2.5711088019561874
Validation loss: 2.5113831868156096

Epoch: 5| Step: 8
Training loss: 2.76329890993195
Validation loss: 2.510483667126927

Epoch: 5| Step: 9
Training loss: 3.1228793769087795
Validation loss: 2.520397210758465

Epoch: 5| Step: 10
Training loss: 2.5518312498402267
Validation loss: 2.5246682989968168

Epoch: 147| Step: 0
Training loss: 2.1787178316438998
Validation loss: 2.5226193918515465

Epoch: 5| Step: 1
Training loss: 2.9026591770050376
Validation loss: 2.5220835670325834

Epoch: 5| Step: 2
Training loss: 2.764088521762669
Validation loss: 2.521674802295697

Epoch: 5| Step: 3
Training loss: 3.0210820764316586
Validation loss: 2.5171281485046326

Epoch: 5| Step: 4
Training loss: 3.023057386372894
Validation loss: 2.5061636120714113

Epoch: 5| Step: 5
Training loss: 2.7863094301932243
Validation loss: 2.4973819047114563

Epoch: 5| Step: 6
Training loss: 2.6086404645997816
Validation loss: 2.497301768288142

Epoch: 5| Step: 7
Training loss: 3.0336313234056074
Validation loss: 2.4962004203341586

Epoch: 5| Step: 8
Training loss: 2.6538372076855508
Validation loss: 2.4988819996215836

Epoch: 5| Step: 9
Training loss: 3.0850035980549855
Validation loss: 2.4957956410841837

Epoch: 5| Step: 10
Training loss: 3.260558217706325
Validation loss: 2.4957988952000676

Epoch: 148| Step: 0
Training loss: 3.309134158843607
Validation loss: 2.4979344849036202

Epoch: 5| Step: 1
Training loss: 2.7978697984244274
Validation loss: 2.4967200759468904

Epoch: 5| Step: 2
Training loss: 3.0873063926380753
Validation loss: 2.4953348296087783

Epoch: 5| Step: 3
Training loss: 2.7282581030327604
Validation loss: 2.4994954902461153

Epoch: 5| Step: 4
Training loss: 2.670581883949068
Validation loss: 2.500871998467932

Epoch: 5| Step: 5
Training loss: 2.170307499417723
Validation loss: 2.5037462458119757

Epoch: 5| Step: 6
Training loss: 2.9433666651887984
Validation loss: 2.5062238089841578

Epoch: 5| Step: 7
Training loss: 2.796922225127228
Validation loss: 2.5129979905272974

Epoch: 5| Step: 8
Training loss: 2.885004631580886
Validation loss: 2.517286320359032

Epoch: 5| Step: 9
Training loss: 2.8847540543310606
Validation loss: 2.531257306301967

Epoch: 5| Step: 10
Training loss: 3.0105011256072824
Validation loss: 2.5312346844480107

Epoch: 149| Step: 0
Training loss: 2.921698253814095
Validation loss: 2.524686222404914

Epoch: 5| Step: 1
Training loss: 2.878606441626984
Validation loss: 2.5136164276580537

Epoch: 5| Step: 2
Training loss: 2.630257382580763
Validation loss: 2.4998195316437077

Epoch: 5| Step: 3
Training loss: 2.706316524683486
Validation loss: 2.491946069543793

Epoch: 5| Step: 4
Training loss: 2.8436859459003436
Validation loss: 2.492505180630057

Epoch: 5| Step: 5
Training loss: 2.079017160833817
Validation loss: 2.4977572635930434

Epoch: 5| Step: 6
Training loss: 2.5643845118272557
Validation loss: 2.4889666706240083

Epoch: 5| Step: 7
Training loss: 3.1017263835205613
Validation loss: 2.4936948020242413

Epoch: 5| Step: 8
Training loss: 3.532258691449123
Validation loss: 2.4929643751549055

Epoch: 5| Step: 9
Training loss: 2.8769090368100105
Validation loss: 2.492675221248377

Epoch: 5| Step: 10
Training loss: 3.0074721106602014
Validation loss: 2.503013268463115

Epoch: 150| Step: 0
Training loss: 2.980478029249153
Validation loss: 2.5067963817249344

Epoch: 5| Step: 1
Training loss: 2.9402686524423505
Validation loss: 2.503474657810016

Epoch: 5| Step: 2
Training loss: 3.045035095263153
Validation loss: 2.5006771431911874

Epoch: 5| Step: 3
Training loss: 2.591576826331287
Validation loss: 2.493674701527709

Epoch: 5| Step: 4
Training loss: 2.809362653762455
Validation loss: 2.493860857262575

Epoch: 5| Step: 5
Training loss: 2.7782929377221244
Validation loss: 2.4925430984877694

Epoch: 5| Step: 6
Training loss: 2.7323339201355035
Validation loss: 2.49303066584656

Epoch: 5| Step: 7
Training loss: 3.0461158784902502
Validation loss: 2.4971870840598176

Epoch: 5| Step: 8
Training loss: 2.9699887552273254
Validation loss: 2.5099022781288682

Epoch: 5| Step: 9
Training loss: 2.6022388392441895
Validation loss: 2.515174207256035

Epoch: 5| Step: 10
Training loss: 2.758998885826115
Validation loss: 2.5091697177267713

Epoch: 151| Step: 0
Training loss: 2.7381228674606244
Validation loss: 2.507086889773574

Epoch: 5| Step: 1
Training loss: 2.751809478541159
Validation loss: 2.5185692760222813

Epoch: 5| Step: 2
Training loss: 2.9580734210390744
Validation loss: 2.5168810759267517

Epoch: 5| Step: 3
Training loss: 2.835024515950873
Validation loss: 2.511451733153053

Epoch: 5| Step: 4
Training loss: 3.1479818994178634
Validation loss: 2.497631006792225

Epoch: 5| Step: 5
Training loss: 2.755782290542457
Validation loss: 2.490429656679856

Epoch: 5| Step: 6
Training loss: 2.452033802484005
Validation loss: 2.4858756300343683

Epoch: 5| Step: 7
Training loss: 2.6165251391905473
Validation loss: 2.48629307680095

Epoch: 5| Step: 8
Training loss: 2.7848581633413936
Validation loss: 2.485549887319676

Epoch: 5| Step: 9
Training loss: 2.4265659310144065
Validation loss: 2.4837845131335494

Epoch: 5| Step: 10
Training loss: 3.739865404858838
Validation loss: 2.4885069846342747

Epoch: 152| Step: 0
Training loss: 3.419318371936446
Validation loss: 2.4916692614057414

Epoch: 5| Step: 1
Training loss: 2.686950183782836
Validation loss: 2.4872272835208653

Epoch: 5| Step: 2
Training loss: 2.729717276748679
Validation loss: 2.4927542486265652

Epoch: 5| Step: 3
Training loss: 2.9465352158836287
Validation loss: 2.489929559925946

Epoch: 5| Step: 4
Training loss: 2.438424350850224
Validation loss: 2.4909271129878325

Epoch: 5| Step: 5
Training loss: 2.9545675316899436
Validation loss: 2.495048514522962

Epoch: 5| Step: 6
Training loss: 2.6167812658431773
Validation loss: 2.495315042318583

Epoch: 5| Step: 7
Training loss: 2.7630904485841365
Validation loss: 2.496003924706639

Epoch: 5| Step: 8
Training loss: 2.8993273908715462
Validation loss: 2.4979257818289033

Epoch: 5| Step: 9
Training loss: 2.9393767185356214
Validation loss: 2.5026780515238167

Epoch: 5| Step: 10
Training loss: 2.6552817880121085
Validation loss: 2.5117455976089844

Epoch: 153| Step: 0
Training loss: 2.485429743828042
Validation loss: 2.5249801335243136

Epoch: 5| Step: 1
Training loss: 2.323431622229031
Validation loss: 2.527632169313414

Epoch: 5| Step: 2
Training loss: 3.066190714459315
Validation loss: 2.5180997543676584

Epoch: 5| Step: 3
Training loss: 3.0121172333353754
Validation loss: 2.5034795450026834

Epoch: 5| Step: 4
Training loss: 2.875710772682141
Validation loss: 2.487634908004837

Epoch: 5| Step: 5
Training loss: 3.0016821277932606
Validation loss: 2.485329915342516

Epoch: 5| Step: 6
Training loss: 2.646345094063236
Validation loss: 2.4825153279828616

Epoch: 5| Step: 7
Training loss: 2.6073573186647865
Validation loss: 2.4824314110955354

Epoch: 5| Step: 8
Training loss: 3.0395960792934886
Validation loss: 2.48481416087392

Epoch: 5| Step: 9
Training loss: 2.942337435864013
Validation loss: 2.4881195321287417

Epoch: 5| Step: 10
Training loss: 3.2964104058385546
Validation loss: 2.4854245039663287

Epoch: 154| Step: 0
Training loss: 2.736301201436737
Validation loss: 2.4897001989649703

Epoch: 5| Step: 1
Training loss: 2.8379689236660672
Validation loss: 2.483625338481297

Epoch: 5| Step: 2
Training loss: 3.024520482921438
Validation loss: 2.496606726601389

Epoch: 5| Step: 3
Training loss: 2.956740331008079
Validation loss: 2.5091212182766367

Epoch: 5| Step: 4
Training loss: 2.168030004237414
Validation loss: 2.5165842039368727

Epoch: 5| Step: 5
Training loss: 2.980349077094475
Validation loss: 2.52268782393139

Epoch: 5| Step: 6
Training loss: 2.6573241810670543
Validation loss: 2.518570462888295

Epoch: 5| Step: 7
Training loss: 2.592285662097921
Validation loss: 2.5111936819292504

Epoch: 5| Step: 8
Training loss: 3.3204829632253534
Validation loss: 2.5011271458452478

Epoch: 5| Step: 9
Training loss: 2.4309827289917147
Validation loss: 2.4954860328178268

Epoch: 5| Step: 10
Training loss: 3.368632491120023
Validation loss: 2.5012094535693365

Epoch: 155| Step: 0
Training loss: 2.5678879453864485
Validation loss: 2.4965031337697376

Epoch: 5| Step: 1
Training loss: 2.7529255304376203
Validation loss: 2.504589846063284

Epoch: 5| Step: 2
Training loss: 3.1940509572225024
Validation loss: 2.522121805601374

Epoch: 5| Step: 3
Training loss: 3.0336157621871513
Validation loss: 2.496874754978831

Epoch: 5| Step: 4
Training loss: 2.651722359095417
Validation loss: 2.4877357621003684

Epoch: 5| Step: 5
Training loss: 2.203818678713437
Validation loss: 2.483483572314257

Epoch: 5| Step: 6
Training loss: 2.753561574590671
Validation loss: 2.4798019710593606

Epoch: 5| Step: 7
Training loss: 2.7411189157269793
Validation loss: 2.479858066947828

Epoch: 5| Step: 8
Training loss: 2.990472287032889
Validation loss: 2.479751143338017

Epoch: 5| Step: 9
Training loss: 3.1523797507044367
Validation loss: 2.478543185490672

Epoch: 5| Step: 10
Training loss: 3.0417757058304082
Validation loss: 2.4804148714587857

Epoch: 156| Step: 0
Training loss: 3.003946569442511
Validation loss: 2.479950253032016

Epoch: 5| Step: 1
Training loss: 2.7082941101363995
Validation loss: 2.4790123525857104

Epoch: 5| Step: 2
Training loss: 2.7664926320992564
Validation loss: 2.481663551375166

Epoch: 5| Step: 3
Training loss: 2.72082510494684
Validation loss: 2.481888514098069

Epoch: 5| Step: 4
Training loss: 3.291462437213273
Validation loss: 2.481871293904229

Epoch: 5| Step: 5
Training loss: 2.0355959836386877
Validation loss: 2.484086004201292

Epoch: 5| Step: 6
Training loss: 3.187466789521384
Validation loss: 2.483107818628899

Epoch: 5| Step: 7
Training loss: 2.660435330039937
Validation loss: 2.493622235096352

Epoch: 5| Step: 8
Training loss: 2.8367091618667137
Validation loss: 2.5112955437953945

Epoch: 5| Step: 9
Training loss: 2.83250400149003
Validation loss: 2.5619596066087102

Epoch: 5| Step: 10
Training loss: 2.9629934616196967
Validation loss: 2.583010425756664

Epoch: 157| Step: 0
Training loss: 3.2782734767282937
Validation loss: 2.5969888208891416

Epoch: 5| Step: 1
Training loss: 2.929480461434379
Validation loss: 2.5481678771194325

Epoch: 5| Step: 2
Training loss: 2.808334317381674
Validation loss: 2.5287702094371345

Epoch: 5| Step: 3
Training loss: 3.0216680666932025
Validation loss: 2.516339152223542

Epoch: 5| Step: 4
Training loss: 2.719875322036938
Validation loss: 2.498170304107559

Epoch: 5| Step: 5
Training loss: 2.6927861412115566
Validation loss: 2.4938470082691806

Epoch: 5| Step: 6
Training loss: 2.732967690303022
Validation loss: 2.4852855940921694

Epoch: 5| Step: 7
Training loss: 2.89819532344052
Validation loss: 2.4878990887102774

Epoch: 5| Step: 8
Training loss: 2.8470451630740765
Validation loss: 2.489459691989376

Epoch: 5| Step: 9
Training loss: 2.688584042530112
Validation loss: 2.4938028496973983

Epoch: 5| Step: 10
Training loss: 2.5057844000621294
Validation loss: 2.483225065063735

Epoch: 158| Step: 0
Training loss: 2.9157675492580255
Validation loss: 2.479118551102925

Epoch: 5| Step: 1
Training loss: 2.324837430787332
Validation loss: 2.479093636560548

Epoch: 5| Step: 2
Training loss: 2.2860138156169683
Validation loss: 2.4804472028581106

Epoch: 5| Step: 3
Training loss: 2.50935197679497
Validation loss: 2.480206343342723

Epoch: 5| Step: 4
Training loss: 2.921137752441297
Validation loss: 2.4833613596929527

Epoch: 5| Step: 5
Training loss: 3.136342939426651
Validation loss: 2.4837424490121323

Epoch: 5| Step: 6
Training loss: 3.2900705129377608
Validation loss: 2.4877830714089546

Epoch: 5| Step: 7
Training loss: 2.657716413641485
Validation loss: 2.501289897317473

Epoch: 5| Step: 8
Training loss: 2.722868770147952
Validation loss: 2.520475590162077

Epoch: 5| Step: 9
Training loss: 3.5575115681377736
Validation loss: 2.5276262177113007

Epoch: 5| Step: 10
Training loss: 2.4205502732510418
Validation loss: 2.5323648816898525

Epoch: 159| Step: 0
Training loss: 3.1991132222751273
Validation loss: 2.5199422872568897

Epoch: 5| Step: 1
Training loss: 3.165010889405234
Validation loss: 2.510475503848739

Epoch: 5| Step: 2
Training loss: 2.875193216216714
Validation loss: 2.493520286643269

Epoch: 5| Step: 3
Training loss: 2.9963256268750342
Validation loss: 2.484145297499099

Epoch: 5| Step: 4
Training loss: 2.5429831883830705
Validation loss: 2.489373521119763

Epoch: 5| Step: 5
Training loss: 2.5053123299207387
Validation loss: 2.496693904644943

Epoch: 5| Step: 6
Training loss: 2.8139644624788263
Validation loss: 2.5152543613410505

Epoch: 5| Step: 7
Training loss: 3.484145905357486
Validation loss: 2.5282417012352676

Epoch: 5| Step: 8
Training loss: 2.3178649735113797
Validation loss: 2.5070752509964884

Epoch: 5| Step: 9
Training loss: 2.7717677288092273
Validation loss: 2.491409269229501

Epoch: 5| Step: 10
Training loss: 2.5581687050037374
Validation loss: 2.4939943256670354

Epoch: 160| Step: 0
Training loss: 2.301069309614851
Validation loss: 2.5109757369471923

Epoch: 5| Step: 1
Training loss: 2.588995470964663
Validation loss: 2.5153627722004885

Epoch: 5| Step: 2
Training loss: 2.5755815386327794
Validation loss: 2.5248158061495176

Epoch: 5| Step: 3
Training loss: 2.744581432844745
Validation loss: 2.5384048869886424

Epoch: 5| Step: 4
Training loss: 2.825162062595992
Validation loss: 2.554726479834963

Epoch: 5| Step: 5
Training loss: 2.654420020339408
Validation loss: 2.5606183542635415

Epoch: 5| Step: 6
Training loss: 3.0328339832926634
Validation loss: 2.5721840332051262

Epoch: 5| Step: 7
Training loss: 3.2873004171033102
Validation loss: 2.558201768362197

Epoch: 5| Step: 8
Training loss: 3.0181316176748965
Validation loss: 2.519425185892353

Epoch: 5| Step: 9
Training loss: 2.9793519893883573
Validation loss: 2.4877759197839646

Epoch: 5| Step: 10
Training loss: 3.291938593452795
Validation loss: 2.4826342453126635

Epoch: 161| Step: 0
Training loss: 3.141083944768668
Validation loss: 2.4729515513262146

Epoch: 5| Step: 1
Training loss: 2.889995774526708
Validation loss: 2.477639934364024

Epoch: 5| Step: 2
Training loss: 2.7689116178923037
Validation loss: 2.4834332209906247

Epoch: 5| Step: 3
Training loss: 2.452879097635011
Validation loss: 2.516943691234879

Epoch: 5| Step: 4
Training loss: 3.0246715146617897
Validation loss: 2.6094938559011562

Epoch: 5| Step: 5
Training loss: 2.743420880505577
Validation loss: 2.6711026063378074

Epoch: 5| Step: 6
Training loss: 2.7186829131169334
Validation loss: 2.607285316476628

Epoch: 5| Step: 7
Training loss: 2.8467910770981257
Validation loss: 2.5821092279291102

Epoch: 5| Step: 8
Training loss: 3.1061201839837227
Validation loss: 2.547126118962707

Epoch: 5| Step: 9
Training loss: 2.8508736392370975
Validation loss: 2.54070395344577

Epoch: 5| Step: 10
Training loss: 3.444403496023718
Validation loss: 2.523713711685109

Epoch: 162| Step: 0
Training loss: 3.426933277559219
Validation loss: 2.542397125988127

Epoch: 5| Step: 1
Training loss: 2.7639516304686067
Validation loss: 2.5555324285515026

Epoch: 5| Step: 2
Training loss: 3.1245438815078694
Validation loss: 2.539073065269582

Epoch: 5| Step: 3
Training loss: 3.03417402990702
Validation loss: 2.5289924132044765

Epoch: 5| Step: 4
Training loss: 2.7643865193785273
Validation loss: 2.5262195537631937

Epoch: 5| Step: 5
Training loss: 3.1280955432339494
Validation loss: 2.532638443477366

Epoch: 5| Step: 6
Training loss: 2.727210025355565
Validation loss: 2.538495138308318

Epoch: 5| Step: 7
Training loss: 2.815160383191917
Validation loss: 2.532009697934998

Epoch: 5| Step: 8
Training loss: 2.079157981268325
Validation loss: 2.533503829559767

Epoch: 5| Step: 9
Training loss: 2.961295476123857
Validation loss: 2.5307817885686306

Epoch: 5| Step: 10
Training loss: 2.284910531160136
Validation loss: 2.5210798674030115

Epoch: 163| Step: 0
Training loss: 3.0256624930804312
Validation loss: 2.5124113987725276

Epoch: 5| Step: 1
Training loss: 2.851805125326651
Validation loss: 2.508199708967648

Epoch: 5| Step: 2
Training loss: 2.857566052839005
Validation loss: 2.4963591695428646

Epoch: 5| Step: 3
Training loss: 2.7787494348138466
Validation loss: 2.491005619495976

Epoch: 5| Step: 4
Training loss: 2.833830415840833
Validation loss: 2.4966305853473068

Epoch: 5| Step: 5
Training loss: 3.0463312690923496
Validation loss: 2.4842375608104876

Epoch: 5| Step: 6
Training loss: 3.322480622544339
Validation loss: 2.47617965393748

Epoch: 5| Step: 7
Training loss: 2.4758747481617895
Validation loss: 2.475123312745239

Epoch: 5| Step: 8
Training loss: 2.5231135960610116
Validation loss: 2.4763888767298803

Epoch: 5| Step: 9
Training loss: 2.6017982903012116
Validation loss: 2.4754407091529043

Epoch: 5| Step: 10
Training loss: 2.749852783424118
Validation loss: 2.470816040960776

Epoch: 164| Step: 0
Training loss: 2.07240126702484
Validation loss: 2.4760137128319517

Epoch: 5| Step: 1
Training loss: 2.3803791566369856
Validation loss: 2.4755509350124054

Epoch: 5| Step: 2
Training loss: 3.11994632259069
Validation loss: 2.4871418630045636

Epoch: 5| Step: 3
Training loss: 2.8180257133139217
Validation loss: 2.489330237349803

Epoch: 5| Step: 4
Training loss: 2.082413572095563
Validation loss: 2.4893093508426327

Epoch: 5| Step: 5
Training loss: 3.005137019024722
Validation loss: 2.493385251627586

Epoch: 5| Step: 6
Training loss: 3.9232380842532186
Validation loss: 2.4999643251478334

Epoch: 5| Step: 7
Training loss: 2.6836292869735834
Validation loss: 2.5089030692497936

Epoch: 5| Step: 8
Training loss: 2.680021126222611
Validation loss: 2.5049481051553055

Epoch: 5| Step: 9
Training loss: 3.094971386803412
Validation loss: 2.511749078060396

Epoch: 5| Step: 10
Training loss: 2.654135367200459
Validation loss: 2.50702201277019

Epoch: 165| Step: 0
Training loss: 3.1242934381896714
Validation loss: 2.5249327271835655

Epoch: 5| Step: 1
Training loss: 2.54789535584249
Validation loss: 2.519504414127969

Epoch: 5| Step: 2
Training loss: 3.2464102947626503
Validation loss: 2.5236029329903595

Epoch: 5| Step: 3
Training loss: 2.75131055641344
Validation loss: 2.5247269184567216

Epoch: 5| Step: 4
Training loss: 2.6204090844439585
Validation loss: 2.519406374378667

Epoch: 5| Step: 5
Training loss: 3.1439196258346835
Validation loss: 2.5156073187790953

Epoch: 5| Step: 6
Training loss: 2.68674520494504
Validation loss: 2.4997498387106725

Epoch: 5| Step: 7
Training loss: 3.062624403314714
Validation loss: 2.4904329450861686

Epoch: 5| Step: 8
Training loss: 2.675406548097189
Validation loss: 2.47752923232831

Epoch: 5| Step: 9
Training loss: 2.519122991087588
Validation loss: 2.473738739336749

Epoch: 5| Step: 10
Training loss: 2.5599100003217523
Validation loss: 2.473428813091529

Epoch: 166| Step: 0
Training loss: 2.7047887544063647
Validation loss: 2.475483079520051

Epoch: 5| Step: 1
Training loss: 3.0997484412722787
Validation loss: 2.479957013726865

Epoch: 5| Step: 2
Training loss: 2.8716185213445233
Validation loss: 2.478599958897678

Epoch: 5| Step: 3
Training loss: 2.43421186064552
Validation loss: 2.47035345485517

Epoch: 5| Step: 4
Training loss: 2.7142645128755807
Validation loss: 2.4682878435775097

Epoch: 5| Step: 5
Training loss: 2.681120197559861
Validation loss: 2.473981564234073

Epoch: 5| Step: 6
Training loss: 2.854875870927372
Validation loss: 2.474037097827748

Epoch: 5| Step: 7
Training loss: 2.8832028339232343
Validation loss: 2.493547851443739

Epoch: 5| Step: 8
Training loss: 3.0033574390467157
Validation loss: 2.5063306373502363

Epoch: 5| Step: 9
Training loss: 2.9777869562067694
Validation loss: 2.5031357675081916

Epoch: 5| Step: 10
Training loss: 2.963236296373364
Validation loss: 2.49716650555026

Epoch: 167| Step: 0
Training loss: 2.3820535420406563
Validation loss: 2.490124689976481

Epoch: 5| Step: 1
Training loss: 3.1016974816148744
Validation loss: 2.4880977699545537

Epoch: 5| Step: 2
Training loss: 2.7685560653656185
Validation loss: 2.47349621189883

Epoch: 5| Step: 3
Training loss: 2.819101512162424
Validation loss: 2.4686645071404096

Epoch: 5| Step: 4
Training loss: 2.7081644347907456
Validation loss: 2.471941655220174

Epoch: 5| Step: 5
Training loss: 2.9988000377250508
Validation loss: 2.4689277033559467

Epoch: 5| Step: 6
Training loss: 2.9895457266503547
Validation loss: 2.471198108433337

Epoch: 5| Step: 7
Training loss: 2.501340125431906
Validation loss: 2.473688796450281

Epoch: 5| Step: 8
Training loss: 3.07518182232473
Validation loss: 2.484423179208313

Epoch: 5| Step: 9
Training loss: 2.906361075298836
Validation loss: 2.4928479035370965

Epoch: 5| Step: 10
Training loss: 2.5796072658027756
Validation loss: 2.499123670949484

Epoch: 168| Step: 0
Training loss: 2.7954546342667865
Validation loss: 2.505724966066933

Epoch: 5| Step: 1
Training loss: 2.513863936336129
Validation loss: 2.5074757157631073

Epoch: 5| Step: 2
Training loss: 2.662723775423452
Validation loss: 2.517497460380033

Epoch: 5| Step: 3
Training loss: 2.704184175815726
Validation loss: 2.525411660771445

Epoch: 5| Step: 4
Training loss: 2.9126221725314587
Validation loss: 2.534393372225141

Epoch: 5| Step: 5
Training loss: 3.0544979885467485
Validation loss: 2.5118067324142763

Epoch: 5| Step: 6
Training loss: 2.943988856771361
Validation loss: 2.4949122495297997

Epoch: 5| Step: 7
Training loss: 2.5835200416610014
Validation loss: 2.4755345582348016

Epoch: 5| Step: 8
Training loss: 2.8678371930272557
Validation loss: 2.459482299567149

Epoch: 5| Step: 9
Training loss: 2.6314996451425285
Validation loss: 2.470636971955737

Epoch: 5| Step: 10
Training loss: 3.247637990790549
Validation loss: 2.468622442407838

Epoch: 169| Step: 0
Training loss: 3.113246328811362
Validation loss: 2.472068138278358

Epoch: 5| Step: 1
Training loss: 2.5166494996283237
Validation loss: 2.480255795291149

Epoch: 5| Step: 2
Training loss: 2.42067802136713
Validation loss: 2.4760639391070507

Epoch: 5| Step: 3
Training loss: 2.9816652148779683
Validation loss: 2.467920367737488

Epoch: 5| Step: 4
Training loss: 2.667903245872983
Validation loss: 2.4627422360827502

Epoch: 5| Step: 5
Training loss: 2.8589480555573235
Validation loss: 2.4596493200118945

Epoch: 5| Step: 6
Training loss: 2.8164406191015803
Validation loss: 2.477750704914922

Epoch: 5| Step: 7
Training loss: 2.943270109224101
Validation loss: 2.499655519358094

Epoch: 5| Step: 8
Training loss: 3.41925059668699
Validation loss: 2.5383519841826363

Epoch: 5| Step: 9
Training loss: 3.0296485052407673
Validation loss: 2.583066131264068

Epoch: 5| Step: 10
Training loss: 2.0243610645649563
Validation loss: 2.6043829508560155

Epoch: 170| Step: 0
Training loss: 2.8619128362150175
Validation loss: 2.606951666978337

Epoch: 5| Step: 1
Training loss: 2.6604525363289384
Validation loss: 2.607019814760373

Epoch: 5| Step: 2
Training loss: 2.2179443616020014
Validation loss: 2.5961065774255894

Epoch: 5| Step: 3
Training loss: 3.267437883412698
Validation loss: 2.585500037437835

Epoch: 5| Step: 4
Training loss: 2.6376855504724945
Validation loss: 2.5283188604947195

Epoch: 5| Step: 5
Training loss: 3.3903123562025415
Validation loss: 2.4982700309961157

Epoch: 5| Step: 6
Training loss: 2.3998321553984714
Validation loss: 2.4812900683696535

Epoch: 5| Step: 7
Training loss: 3.0110063514300416
Validation loss: 2.4738727575936275

Epoch: 5| Step: 8
Training loss: 2.690783247242813
Validation loss: 2.468702923061189

Epoch: 5| Step: 9
Training loss: 2.7940306452147095
Validation loss: 2.464813481335761

Epoch: 5| Step: 10
Training loss: 3.0598366503030983
Validation loss: 2.4581303058155872

Epoch: 171| Step: 0
Training loss: 2.6025088310275093
Validation loss: 2.45482904511185

Epoch: 5| Step: 1
Training loss: 2.9330615336755463
Validation loss: 2.457451436066767

Epoch: 5| Step: 2
Training loss: 2.468558098782901
Validation loss: 2.452667778947523

Epoch: 5| Step: 3
Training loss: 2.762558265865581
Validation loss: 2.4506974005570883

Epoch: 5| Step: 4
Training loss: 2.6916476336614283
Validation loss: 2.4586328995187228

Epoch: 5| Step: 5
Training loss: 3.132465752416693
Validation loss: 2.4514869742671612

Epoch: 5| Step: 6
Training loss: 2.98989852324812
Validation loss: 2.4552160729724437

Epoch: 5| Step: 7
Training loss: 2.6124327326971373
Validation loss: 2.4545590240736246

Epoch: 5| Step: 8
Training loss: 3.0323231164176483
Validation loss: 2.4578893026545967

Epoch: 5| Step: 9
Training loss: 2.871406631548582
Validation loss: 2.4631063602274277

Epoch: 5| Step: 10
Training loss: 2.6353605261893156
Validation loss: 2.474464053076287

Epoch: 172| Step: 0
Training loss: 2.6417087836372857
Validation loss: 2.4800464071939348

Epoch: 5| Step: 1
Training loss: 3.169400908601782
Validation loss: 2.491548998332193

Epoch: 5| Step: 2
Training loss: 2.8623458354364915
Validation loss: 2.4953180237780597

Epoch: 5| Step: 3
Training loss: 2.8571643726356206
Validation loss: 2.4869146622909257

Epoch: 5| Step: 4
Training loss: 2.3661902816821807
Validation loss: 2.4664927919639372

Epoch: 5| Step: 5
Training loss: 2.499149082330158
Validation loss: 2.4628934354478926

Epoch: 5| Step: 6
Training loss: 2.749913127567393
Validation loss: 2.4596875505055507

Epoch: 5| Step: 7
Training loss: 3.0015612354504264
Validation loss: 2.4507304127218115

Epoch: 5| Step: 8
Training loss: 2.94482401634523
Validation loss: 2.447821650147932

Epoch: 5| Step: 9
Training loss: 3.02211273110337
Validation loss: 2.453457234734002

Epoch: 5| Step: 10
Training loss: 2.736974559505419
Validation loss: 2.455790644033099

Epoch: 173| Step: 0
Training loss: 2.3561680706158774
Validation loss: 2.4562651804213003

Epoch: 5| Step: 1
Training loss: 3.157259033866812
Validation loss: 2.4522699501814844

Epoch: 5| Step: 2
Training loss: 2.440525524735102
Validation loss: 2.4554914278221665

Epoch: 5| Step: 3
Training loss: 3.2986082610179346
Validation loss: 2.459997853192222

Epoch: 5| Step: 4
Training loss: 3.072102963748619
Validation loss: 2.4664207302079544

Epoch: 5| Step: 5
Training loss: 2.2165591746872306
Validation loss: 2.483576385101143

Epoch: 5| Step: 6
Training loss: 2.653281134694196
Validation loss: 2.4914842816295937

Epoch: 5| Step: 7
Training loss: 2.6462040038294123
Validation loss: 2.49001100745208

Epoch: 5| Step: 8
Training loss: 3.2709033415929527
Validation loss: 2.480938153838365

Epoch: 5| Step: 9
Training loss: 2.754797046060586
Validation loss: 2.4943171135087123

Epoch: 5| Step: 10
Training loss: 2.637950377858712
Validation loss: 2.4909871882208168

Epoch: 174| Step: 0
Training loss: 2.8366424272923334
Validation loss: 2.4859670402246583

Epoch: 5| Step: 1
Training loss: 2.84261257354676
Validation loss: 2.4854820727307305

Epoch: 5| Step: 2
Training loss: 2.945896566342723
Validation loss: 2.497440406043727

Epoch: 5| Step: 3
Training loss: 3.042366800769961
Validation loss: 2.494891251509988

Epoch: 5| Step: 4
Training loss: 2.628738375287512
Validation loss: 2.4943160178815753

Epoch: 5| Step: 5
Training loss: 2.7008878237194374
Validation loss: 2.4781277027960322

Epoch: 5| Step: 6
Training loss: 2.6167842725173283
Validation loss: 2.478811597607251

Epoch: 5| Step: 7
Training loss: 2.857724573316763
Validation loss: 2.4735074355268765

Epoch: 5| Step: 8
Training loss: 2.393176443842686
Validation loss: 2.47423064636744

Epoch: 5| Step: 9
Training loss: 2.8906187315176965
Validation loss: 2.4749982474428505

Epoch: 5| Step: 10
Training loss: 2.8685379382107015
Validation loss: 2.4728862950472603

Epoch: 175| Step: 0
Training loss: 3.1667941887593454
Validation loss: 2.474058969174691

Epoch: 5| Step: 1
Training loss: 2.7056799484245886
Validation loss: 2.4704229595899005

Epoch: 5| Step: 2
Training loss: 2.9969729410502204
Validation loss: 2.476544077173162

Epoch: 5| Step: 3
Training loss: 2.544455847883514
Validation loss: 2.470375273719278

Epoch: 5| Step: 4
Training loss: 2.644042653148065
Validation loss: 2.4823242564869834

Epoch: 5| Step: 5
Training loss: 2.7848005455546954
Validation loss: 2.4939401277004136

Epoch: 5| Step: 6
Training loss: 2.56913735098193
Validation loss: 2.4842168595513847

Epoch: 5| Step: 7
Training loss: 2.757677804396984
Validation loss: 2.482901412385912

Epoch: 5| Step: 8
Training loss: 2.2679118223861026
Validation loss: 2.4818722488632217

Epoch: 5| Step: 9
Training loss: 3.149087767738603
Validation loss: 2.48143455352364

Epoch: 5| Step: 10
Training loss: 3.035469186328918
Validation loss: 2.483794698894674

Epoch: 176| Step: 0
Training loss: 2.717915023092868
Validation loss: 2.4827759417468642

Epoch: 5| Step: 1
Training loss: 2.7720181984021948
Validation loss: 2.465438434827961

Epoch: 5| Step: 2
Training loss: 2.763289332789193
Validation loss: 2.4634478720126465

Epoch: 5| Step: 3
Training loss: 3.1498184393980355
Validation loss: 2.453300338654103

Epoch: 5| Step: 4
Training loss: 2.694409647669928
Validation loss: 2.453203767361415

Epoch: 5| Step: 5
Training loss: 2.3451292938507056
Validation loss: 2.451189002331136

Epoch: 5| Step: 6
Training loss: 2.920260876015082
Validation loss: 2.454596509798171

Epoch: 5| Step: 7
Training loss: 2.725296032425738
Validation loss: 2.4576454541985764

Epoch: 5| Step: 8
Training loss: 3.2677034763295625
Validation loss: 2.458030126848292

Epoch: 5| Step: 9
Training loss: 2.6026690538302923
Validation loss: 2.4678960205557905

Epoch: 5| Step: 10
Training loss: 2.5493640555455235
Validation loss: 2.4498128796932157

Epoch: 177| Step: 0
Training loss: 2.4609854557269455
Validation loss: 2.444688662053515

Epoch: 5| Step: 1
Training loss: 3.0271049552997646
Validation loss: 2.4603817449115937

Epoch: 5| Step: 2
Training loss: 2.9346008603859284
Validation loss: 2.4703794620889337

Epoch: 5| Step: 3
Training loss: 3.0102514905834794
Validation loss: 2.490747387052287

Epoch: 5| Step: 4
Training loss: 3.0536945416992687
Validation loss: 2.524165045161768

Epoch: 5| Step: 5
Training loss: 2.5932607534037224
Validation loss: 2.532954377612123

Epoch: 5| Step: 6
Training loss: 2.665558604657891
Validation loss: 2.5351394452285856

Epoch: 5| Step: 7
Training loss: 2.938483377983123
Validation loss: 2.530784606687644

Epoch: 5| Step: 8
Training loss: 2.857310065417564
Validation loss: 2.516097613232622

Epoch: 5| Step: 9
Training loss: 2.6619290845669474
Validation loss: 2.507013478269474

Epoch: 5| Step: 10
Training loss: 2.5818109230764925
Validation loss: 2.483950258149943

Epoch: 178| Step: 0
Training loss: 2.6297721173730517
Validation loss: 2.4770295246978487

Epoch: 5| Step: 1
Training loss: 2.8779603395360374
Validation loss: 2.4719865309909212

Epoch: 5| Step: 2
Training loss: 2.7913466217906686
Validation loss: 2.4691535647892593

Epoch: 5| Step: 3
Training loss: 2.324469647369164
Validation loss: 2.465259321498885

Epoch: 5| Step: 4
Training loss: 2.843820591983117
Validation loss: 2.4651718211239797

Epoch: 5| Step: 5
Training loss: 3.201575523189868
Validation loss: 2.461305773619793

Epoch: 5| Step: 6
Training loss: 2.610885639691513
Validation loss: 2.4550881473990205

Epoch: 5| Step: 7
Training loss: 2.9871375594287914
Validation loss: 2.4483838806913214

Epoch: 5| Step: 8
Training loss: 2.9260941504912417
Validation loss: 2.4509728415322827

Epoch: 5| Step: 9
Training loss: 2.649904997940098
Validation loss: 2.4528914084934206

Epoch: 5| Step: 10
Training loss: 2.4879670476233833
Validation loss: 2.450210379181199

Epoch: 179| Step: 0
Training loss: 2.612122146075498
Validation loss: 2.4530311411326946

Epoch: 5| Step: 1
Training loss: 3.1976694680431668
Validation loss: 2.455712465961901

Epoch: 5| Step: 2
Training loss: 2.9826947819944
Validation loss: 2.462667843083414

Epoch: 5| Step: 3
Training loss: 2.835330950814556
Validation loss: 2.471179943352861

Epoch: 5| Step: 4
Training loss: 2.7593428820493755
Validation loss: 2.4661924573456835

Epoch: 5| Step: 5
Training loss: 3.0120230396093746
Validation loss: 2.4827946797289244

Epoch: 5| Step: 6
Training loss: 2.3240904187588423
Validation loss: 2.4969158129383024

Epoch: 5| Step: 7
Training loss: 2.3759452544947153
Validation loss: 2.5149301180531887

Epoch: 5| Step: 8
Training loss: 2.823784970307179
Validation loss: 2.5075639912051075

Epoch: 5| Step: 9
Training loss: 2.9830114634974874
Validation loss: 2.4879347706684922

Epoch: 5| Step: 10
Training loss: 2.5457674204217113
Validation loss: 2.456814739223817

Epoch: 180| Step: 0
Training loss: 2.849106491299876
Validation loss: 2.4470382283742182

Epoch: 5| Step: 1
Training loss: 2.576209171421407
Validation loss: 2.445672508896507

Epoch: 5| Step: 2
Training loss: 3.028194972313414
Validation loss: 2.4461144244312636

Epoch: 5| Step: 3
Training loss: 3.1729339185025713
Validation loss: 2.44558558190244

Epoch: 5| Step: 4
Training loss: 2.600597030610259
Validation loss: 2.46469662387153

Epoch: 5| Step: 5
Training loss: 2.7306277511209123
Validation loss: 2.4672406495616244

Epoch: 5| Step: 6
Training loss: 3.0908675203740805
Validation loss: 2.464022035291405

Epoch: 5| Step: 7
Training loss: 2.430076641553859
Validation loss: 2.4568950985039297

Epoch: 5| Step: 8
Training loss: 2.5524476290868257
Validation loss: 2.4550276197565606

Epoch: 5| Step: 9
Training loss: 2.663517602586307
Validation loss: 2.4415683140934212

Epoch: 5| Step: 10
Training loss: 3.041335013785338
Validation loss: 2.439606597393786

Epoch: 181| Step: 0
Training loss: 2.900881330806616
Validation loss: 2.45666139066325

Epoch: 5| Step: 1
Training loss: 3.20923771847827
Validation loss: 2.4632557148842174

Epoch: 5| Step: 2
Training loss: 2.9395180121575764
Validation loss: 2.4917248833262122

Epoch: 5| Step: 3
Training loss: 2.662053936767992
Validation loss: 2.5158990389583757

Epoch: 5| Step: 4
Training loss: 2.5317636604471674
Validation loss: 2.522436126847019

Epoch: 5| Step: 5
Training loss: 2.3004850705347812
Validation loss: 2.527773114126144

Epoch: 5| Step: 6
Training loss: 2.7555088872016924
Validation loss: 2.5542073311135067

Epoch: 5| Step: 7
Training loss: 3.1552161610303577
Validation loss: 2.5734009679058483

Epoch: 5| Step: 8
Training loss: 2.7771341107918666
Validation loss: 2.575665747024657

Epoch: 5| Step: 9
Training loss: 2.3464180573893314
Validation loss: 2.543783946719204

Epoch: 5| Step: 10
Training loss: 3.1126611874678476
Validation loss: 2.5181037554401637

Epoch: 182| Step: 0
Training loss: 2.435221560853459
Validation loss: 2.513602679351075

Epoch: 5| Step: 1
Training loss: 2.4766954452499257
Validation loss: 2.5011918129137287

Epoch: 5| Step: 2
Training loss: 3.1880836700410824
Validation loss: 2.526942524416233

Epoch: 5| Step: 3
Training loss: 3.206866205501151
Validation loss: 2.498624385230662

Epoch: 5| Step: 4
Training loss: 3.0818372310009803
Validation loss: 2.497677770454918

Epoch: 5| Step: 5
Training loss: 2.323994909454916
Validation loss: 2.4745557149066535

Epoch: 5| Step: 6
Training loss: 2.737587834172776
Validation loss: 2.467613736516407

Epoch: 5| Step: 7
Training loss: 2.7791255595204465
Validation loss: 2.469144887976792

Epoch: 5| Step: 8
Training loss: 2.8114779840672806
Validation loss: 2.4562163382519313

Epoch: 5| Step: 9
Training loss: 3.087300060145912
Validation loss: 2.4467834852000037

Epoch: 5| Step: 10
Training loss: 2.4856885400544373
Validation loss: 2.4464201926774254

Epoch: 183| Step: 0
Training loss: 3.009919298173716
Validation loss: 2.446867886010657

Epoch: 5| Step: 1
Training loss: 2.716875065570319
Validation loss: 2.4514571001666523

Epoch: 5| Step: 2
Training loss: 2.6978939354919618
Validation loss: 2.442771050394752

Epoch: 5| Step: 3
Training loss: 3.0550764767928045
Validation loss: 2.450407054696807

Epoch: 5| Step: 4
Training loss: 2.4026571426047596
Validation loss: 2.4521163728129034

Epoch: 5| Step: 5
Training loss: 3.2996090223877372
Validation loss: 2.454500302842443

Epoch: 5| Step: 6
Training loss: 2.7210582712222395
Validation loss: 2.4653011961217564

Epoch: 5| Step: 7
Training loss: 2.9025910016759604
Validation loss: 2.4718195880892315

Epoch: 5| Step: 8
Training loss: 2.565840613798901
Validation loss: 2.477576532687288

Epoch: 5| Step: 9
Training loss: 2.737872867360643
Validation loss: 2.458549330120992

Epoch: 5| Step: 10
Training loss: 2.170390548016741
Validation loss: 2.4637677995271217

Epoch: 184| Step: 0
Training loss: 2.404934907694552
Validation loss: 2.4508207341502897

Epoch: 5| Step: 1
Training loss: 3.1492252547571433
Validation loss: 2.4533503966866093

Epoch: 5| Step: 2
Training loss: 2.701939846710452
Validation loss: 2.4513081582206016

Epoch: 5| Step: 3
Training loss: 2.9660203129593037
Validation loss: 2.442365756720733

Epoch: 5| Step: 4
Training loss: 2.8768752243568985
Validation loss: 2.4440168942636458

Epoch: 5| Step: 5
Training loss: 3.177095373579047
Validation loss: 2.442321852420011

Epoch: 5| Step: 6
Training loss: 2.4636409381976265
Validation loss: 2.44564673107846

Epoch: 5| Step: 7
Training loss: 2.727711170528852
Validation loss: 2.455316433579068

Epoch: 5| Step: 8
Training loss: 2.2661863486624427
Validation loss: 2.449674353262972

Epoch: 5| Step: 9
Training loss: 2.7476965186774978
Validation loss: 2.4574826268377437

Epoch: 5| Step: 10
Training loss: 2.7411794521370467
Validation loss: 2.4627376755892247

Epoch: 185| Step: 0
Training loss: 2.786021736142382
Validation loss: 2.466579920161608

Epoch: 5| Step: 1
Training loss: 2.8361535528604285
Validation loss: 2.4768680502934823

Epoch: 5| Step: 2
Training loss: 2.558595520484836
Validation loss: 2.469645909669067

Epoch: 5| Step: 3
Training loss: 3.0701050045184988
Validation loss: 2.4635031867380794

Epoch: 5| Step: 4
Training loss: 1.6880316426669546
Validation loss: 2.458850601431803

Epoch: 5| Step: 5
Training loss: 2.895999181009672
Validation loss: 2.4500412210693017

Epoch: 5| Step: 6
Training loss: 3.172977800755069
Validation loss: 2.4545308689319922

Epoch: 5| Step: 7
Training loss: 2.120745045361256
Validation loss: 2.454715355113711

Epoch: 5| Step: 8
Training loss: 2.7123832255598734
Validation loss: 2.4547056716598608

Epoch: 5| Step: 9
Training loss: 2.911882091021496
Validation loss: 2.4569561957593335

Epoch: 5| Step: 10
Training loss: 3.2273295601445344
Validation loss: 2.442837278014761

Epoch: 186| Step: 0
Training loss: 2.9207919964515865
Validation loss: 2.439188668600992

Epoch: 5| Step: 1
Training loss: 2.796753609010225
Validation loss: 2.4396691116980884

Epoch: 5| Step: 2
Training loss: 3.4120921858915203
Validation loss: 2.439150827316056

Epoch: 5| Step: 3
Training loss: 2.6720054550001002
Validation loss: 2.4343022694594265

Epoch: 5| Step: 4
Training loss: 2.751946627282295
Validation loss: 2.440732669176736

Epoch: 5| Step: 5
Training loss: 2.679971752160218
Validation loss: 2.442514180729505

Epoch: 5| Step: 6
Training loss: 2.293739722122324
Validation loss: 2.439368488661585

Epoch: 5| Step: 7
Training loss: 2.516511654237728
Validation loss: 2.4423800918125655

Epoch: 5| Step: 8
Training loss: 2.720096473946408
Validation loss: 2.4520879794804165

Epoch: 5| Step: 9
Training loss: 2.3154710808589134
Validation loss: 2.452295064065716

Epoch: 5| Step: 10
Training loss: 2.99102681010789
Validation loss: 2.4562846195349097

Epoch: 187| Step: 0
Training loss: 2.210997563816697
Validation loss: 2.465105591400899

Epoch: 5| Step: 1
Training loss: 3.0496911752410707
Validation loss: 2.4550289187920913

Epoch: 5| Step: 2
Training loss: 2.7329404719179076
Validation loss: 2.4421487572179728

Epoch: 5| Step: 3
Training loss: 2.840275245008347
Validation loss: 2.4515415638610882

Epoch: 5| Step: 4
Training loss: 2.259815845244684
Validation loss: 2.4493276690227916

Epoch: 5| Step: 5
Training loss: 2.6662452682689204
Validation loss: 2.4399730672414

Epoch: 5| Step: 6
Training loss: 3.09163015160671
Validation loss: 2.4379797916322006

Epoch: 5| Step: 7
Training loss: 3.0554654040668203
Validation loss: 2.4418288192767044

Epoch: 5| Step: 8
Training loss: 3.0038900585755113
Validation loss: 2.451125695663333

Epoch: 5| Step: 9
Training loss: 2.580702724122437
Validation loss: 2.451591420430335

Epoch: 5| Step: 10
Training loss: 2.418978133766282
Validation loss: 2.4451593569092784

Epoch: 188| Step: 0
Training loss: 2.5991648946766035
Validation loss: 2.456972503338033

Epoch: 5| Step: 1
Training loss: 3.056395694559792
Validation loss: 2.456890312206356

Epoch: 5| Step: 2
Training loss: 3.000748540952786
Validation loss: 2.4516410846256256

Epoch: 5| Step: 3
Training loss: 2.704920001865434
Validation loss: 2.4617728616910606

Epoch: 5| Step: 4
Training loss: 2.699671485130091
Validation loss: 2.477202305163178

Epoch: 5| Step: 5
Training loss: 2.3566030425026745
Validation loss: 2.468740285405435

Epoch: 5| Step: 6
Training loss: 2.400952043053591
Validation loss: 2.471562141277354

Epoch: 5| Step: 7
Training loss: 2.7184850629431585
Validation loss: 2.4741511050357836

Epoch: 5| Step: 8
Training loss: 2.8191081933852704
Validation loss: 2.473118674894393

Epoch: 5| Step: 9
Training loss: 2.7830304222733226
Validation loss: 2.4687734166368247

Epoch: 5| Step: 10
Training loss: 2.697533264803546
Validation loss: 2.4672842798084362

Epoch: 189| Step: 0
Training loss: 2.7938726069708215
Validation loss: 2.464284074277015

Epoch: 5| Step: 1
Training loss: 2.5259841020979357
Validation loss: 2.4660345896763824

Epoch: 5| Step: 2
Training loss: 2.745226531834866
Validation loss: 2.472813571562961

Epoch: 5| Step: 3
Training loss: 2.5269643035891445
Validation loss: 2.4804837423512134

Epoch: 5| Step: 4
Training loss: 2.413680061737613
Validation loss: 2.475686014959156

Epoch: 5| Step: 5
Training loss: 2.8341926692707133
Validation loss: 2.4703456477541508

Epoch: 5| Step: 6
Training loss: 2.3678789293552307
Validation loss: 2.462450553606238

Epoch: 5| Step: 7
Training loss: 3.260538328458234
Validation loss: 2.468082900160918

Epoch: 5| Step: 8
Training loss: 2.730978376556467
Validation loss: 2.470147363193329

Epoch: 5| Step: 9
Training loss: 3.2010643261944254
Validation loss: 2.456593352570015

Epoch: 5| Step: 10
Training loss: 2.556285113627453
Validation loss: 2.452449220860849

Epoch: 190| Step: 0
Training loss: 3.1938219394532026
Validation loss: 2.455376716048862

Epoch: 5| Step: 1
Training loss: 2.652779230202837
Validation loss: 2.446284723895129

Epoch: 5| Step: 2
Training loss: 2.873615429064104
Validation loss: 2.444329748472416

Epoch: 5| Step: 3
Training loss: 2.6669240668364527
Validation loss: 2.439679510540103

Epoch: 5| Step: 4
Training loss: 3.1508452719443993
Validation loss: 2.432371208097334

Epoch: 5| Step: 5
Training loss: 2.866354174178595
Validation loss: 2.4326309466716656

Epoch: 5| Step: 6
Training loss: 2.1739984464455593
Validation loss: 2.434734754294167

Epoch: 5| Step: 7
Training loss: 2.9675333842944136
Validation loss: 2.447578601275767

Epoch: 5| Step: 8
Training loss: 2.606602640788452
Validation loss: 2.4454603436511113

Epoch: 5| Step: 9
Training loss: 2.3631888379400934
Validation loss: 2.44447739881276

Epoch: 5| Step: 10
Training loss: 2.2850969877465164
Validation loss: 2.458442125230014

Epoch: 191| Step: 0
Training loss: 2.840103662237676
Validation loss: 2.4734015661556694

Epoch: 5| Step: 1
Training loss: 2.573732923587214
Validation loss: 2.471741118364789

Epoch: 5| Step: 2
Training loss: 2.172607517896145
Validation loss: 2.4667964281186276

Epoch: 5| Step: 3
Training loss: 2.4420903338470987
Validation loss: 2.4702308671340862

Epoch: 5| Step: 4
Training loss: 3.117034831885662
Validation loss: 2.4578512820036544

Epoch: 5| Step: 5
Training loss: 2.5775557380813825
Validation loss: 2.4581420480576104

Epoch: 5| Step: 6
Training loss: 2.6545780080720816
Validation loss: 2.444044161451007

Epoch: 5| Step: 7
Training loss: 3.068357199334843
Validation loss: 2.4438392142615664

Epoch: 5| Step: 8
Training loss: 3.0371608717499097
Validation loss: 2.438327503701063

Epoch: 5| Step: 9
Training loss: 2.7258291050609826
Validation loss: 2.4389669580735895

Epoch: 5| Step: 10
Training loss: 2.604432135720329
Validation loss: 2.4353378146569638

Epoch: 192| Step: 0
Training loss: 2.6494818234803725
Validation loss: 2.442054030325398

Epoch: 5| Step: 1
Training loss: 2.8958870496273192
Validation loss: 2.4445929544707043

Epoch: 5| Step: 2
Training loss: 2.452167688656511
Validation loss: 2.4653867952132273

Epoch: 5| Step: 3
Training loss: 3.0144458105797614
Validation loss: 2.461739287375984

Epoch: 5| Step: 4
Training loss: 2.1959516470472282
Validation loss: 2.4633828031514238

Epoch: 5| Step: 5
Training loss: 3.2132102923229953
Validation loss: 2.45876840322304

Epoch: 5| Step: 6
Training loss: 2.698821859812121
Validation loss: 2.4633280877807047

Epoch: 5| Step: 7
Training loss: 3.0413611968471455
Validation loss: 2.467183601772054

Epoch: 5| Step: 8
Training loss: 2.532814860828201
Validation loss: 2.4523832298172543

Epoch: 5| Step: 9
Training loss: 2.691669334985062
Validation loss: 2.4485088134011423

Epoch: 5| Step: 10
Training loss: 2.2723125807691336
Validation loss: 2.449617571404655

Epoch: 193| Step: 0
Training loss: 2.8540521491992963
Validation loss: 2.4369830836846185

Epoch: 5| Step: 1
Training loss: 2.262001454765196
Validation loss: 2.442698827226036

Epoch: 5| Step: 2
Training loss: 2.868705991852073
Validation loss: 2.46411887238282

Epoch: 5| Step: 3
Training loss: 2.8162015504559554
Validation loss: 2.448277006592924

Epoch: 5| Step: 4
Training loss: 2.7601908081551745
Validation loss: 2.446082717687691

Epoch: 5| Step: 5
Training loss: 2.9438145721545528
Validation loss: 2.4602239050430943

Epoch: 5| Step: 6
Training loss: 2.7084811732704908
Validation loss: 2.4747192359461945

Epoch: 5| Step: 7
Training loss: 2.3101271750381738
Validation loss: 2.4671512648923195

Epoch: 5| Step: 8
Training loss: 3.114791676028847
Validation loss: 2.472866933566695

Epoch: 5| Step: 9
Training loss: 2.37529742737615
Validation loss: 2.463605647368559

Epoch: 5| Step: 10
Training loss: 2.850079210753336
Validation loss: 2.4680053296044506

Epoch: 194| Step: 0
Training loss: 2.5222668840801896
Validation loss: 2.464149573532387

Epoch: 5| Step: 1
Training loss: 2.3119380371211924
Validation loss: 2.451034803929011

Epoch: 5| Step: 2
Training loss: 2.7144615288490574
Validation loss: 2.4507487126382776

Epoch: 5| Step: 3
Training loss: 2.903949606476594
Validation loss: 2.4271615075778716

Epoch: 5| Step: 4
Training loss: 2.855995056660966
Validation loss: 2.440517360653988

Epoch: 5| Step: 5
Training loss: 2.214884655017994
Validation loss: 2.4401915944719113

Epoch: 5| Step: 6
Training loss: 2.7120673823467514
Validation loss: 2.444570373793211

Epoch: 5| Step: 7
Training loss: 2.506951395191291
Validation loss: 2.448530042710957

Epoch: 5| Step: 8
Training loss: 2.9456799831880063
Validation loss: 2.4400680892511084

Epoch: 5| Step: 9
Training loss: 3.1213571296489846
Validation loss: 2.452192298636495

Epoch: 5| Step: 10
Training loss: 3.1678256038964108
Validation loss: 2.470947330339891

Epoch: 195| Step: 0
Training loss: 2.5777118698643
Validation loss: 2.487475052698822

Epoch: 5| Step: 1
Training loss: 2.4215963880191276
Validation loss: 2.4871355774361437

Epoch: 5| Step: 2
Training loss: 2.8523443117039298
Validation loss: 2.4838761298101084

Epoch: 5| Step: 3
Training loss: 2.6400610869015932
Validation loss: 2.4944671379363017

Epoch: 5| Step: 4
Training loss: 2.809270572949244
Validation loss: 2.4792620429491183

Epoch: 5| Step: 5
Training loss: 2.838580620641304
Validation loss: 2.4979943279842787

Epoch: 5| Step: 6
Training loss: 3.049217067349571
Validation loss: 2.4785080028988116

Epoch: 5| Step: 7
Training loss: 2.495899843615106
Validation loss: 2.486109161292166

Epoch: 5| Step: 8
Training loss: 2.519281419299739
Validation loss: 2.484000503527438

Epoch: 5| Step: 9
Training loss: 3.265945637854958
Validation loss: 2.5014974949287607

Epoch: 5| Step: 10
Training loss: 2.319730846314033
Validation loss: 2.4990717230956903

Epoch: 196| Step: 0
Training loss: 2.4891526449562265
Validation loss: 2.4760044657437184

Epoch: 5| Step: 1
Training loss: 2.2950359429763236
Validation loss: 2.466600763204912

Epoch: 5| Step: 2
Training loss: 2.663956805059424
Validation loss: 2.454486829201829

Epoch: 5| Step: 3
Training loss: 2.9762827824401707
Validation loss: 2.4565377554561367

Epoch: 5| Step: 4
Training loss: 3.052757180117154
Validation loss: 2.4504511865804903

Epoch: 5| Step: 5
Training loss: 2.7957729960344104
Validation loss: 2.4671868229675806

Epoch: 5| Step: 6
Training loss: 2.056625554535833
Validation loss: 2.490509280803382

Epoch: 5| Step: 7
Training loss: 2.8344404824966634
Validation loss: 2.4773399587362466

Epoch: 5| Step: 8
Training loss: 2.599404663004739
Validation loss: 2.4657855706258496

Epoch: 5| Step: 9
Training loss: 3.2905481747954117
Validation loss: 2.457345112820199

Epoch: 5| Step: 10
Training loss: 2.6306996909477594
Validation loss: 2.4592711041963056

Epoch: 197| Step: 0
Training loss: 2.941593807568126
Validation loss: 2.4498596802492685

Epoch: 5| Step: 1
Training loss: 2.678611606114924
Validation loss: 2.4452412315209333

Epoch: 5| Step: 2
Training loss: 2.7225301486220954
Validation loss: 2.4455587008974993

Epoch: 5| Step: 3
Training loss: 2.9981278299839578
Validation loss: 2.4568042136037644

Epoch: 5| Step: 4
Training loss: 2.82311551190214
Validation loss: 2.4621351123408544

Epoch: 5| Step: 5
Training loss: 1.6087989146421955
Validation loss: 2.474160303097928

Epoch: 5| Step: 6
Training loss: 2.9906304593569555
Validation loss: 2.482153345651675

Epoch: 5| Step: 7
Training loss: 2.714195206932967
Validation loss: 2.476357633186838

Epoch: 5| Step: 8
Training loss: 2.9514124511576054
Validation loss: 2.4672414236701306

Epoch: 5| Step: 9
Training loss: 2.5095665997508823
Validation loss: 2.457276313280747

Epoch: 5| Step: 10
Training loss: 2.5976366085371154
Validation loss: 2.459540849737541

Epoch: 198| Step: 0
Training loss: 2.6259795586457897
Validation loss: 2.459252348037234

Epoch: 5| Step: 1
Training loss: 2.99201921034577
Validation loss: 2.4556161523928086

Epoch: 5| Step: 2
Training loss: 2.0165112343571443
Validation loss: 2.443029217356517

Epoch: 5| Step: 3
Training loss: 2.790178604561942
Validation loss: 2.4440269609733183

Epoch: 5| Step: 4
Training loss: 2.891981641634635
Validation loss: 2.4311533882281506

Epoch: 5| Step: 5
Training loss: 3.0600367390540186
Validation loss: 2.4320503064694052

Epoch: 5| Step: 6
Training loss: 2.241875497197398
Validation loss: 2.438217507631411

Epoch: 5| Step: 7
Training loss: 2.5947577116061717
Validation loss: 2.43614449896311

Epoch: 5| Step: 8
Training loss: 2.848918535604303
Validation loss: 2.4311119886406587

Epoch: 5| Step: 9
Training loss: 2.6012941514190646
Validation loss: 2.4320947493119744

Epoch: 5| Step: 10
Training loss: 2.7945107638168323
Validation loss: 2.433471592346506

Epoch: 199| Step: 0
Training loss: 3.0958907302183887
Validation loss: 2.4371214415702473

Epoch: 5| Step: 1
Training loss: 2.192891044585401
Validation loss: 2.440172893900091

Epoch: 5| Step: 2
Training loss: 2.6396982948260432
Validation loss: 2.4456167720098816

Epoch: 5| Step: 3
Training loss: 3.371835143072043
Validation loss: 2.449777364545397

Epoch: 5| Step: 4
Training loss: 2.7661518521830897
Validation loss: 2.451550560747807

Epoch: 5| Step: 5
Training loss: 2.777008851968231
Validation loss: 2.4644233429984146

Epoch: 5| Step: 6
Training loss: 2.959073972447134
Validation loss: 2.4655403632471358

Epoch: 5| Step: 7
Training loss: 2.0409285969409314
Validation loss: 2.4723542563669216

Epoch: 5| Step: 8
Training loss: 2.794436195981555
Validation loss: 2.4634589488979683

Epoch: 5| Step: 9
Training loss: 1.846212004087853
Validation loss: 2.453051387596035

Epoch: 5| Step: 10
Training loss: 2.7890300161142285
Validation loss: 2.444347271948628

Epoch: 200| Step: 0
Training loss: 2.624726780796075
Validation loss: 2.444954668346149

Epoch: 5| Step: 1
Training loss: 2.6774766882870895
Validation loss: 2.442310654476968

Epoch: 5| Step: 2
Training loss: 2.6793854212308
Validation loss: 2.4393769823793816

Epoch: 5| Step: 3
Training loss: 2.4932981306368687
Validation loss: 2.4288775808682974

Epoch: 5| Step: 4
Training loss: 2.5279664771476935
Validation loss: 2.4261685761451077

Epoch: 5| Step: 5
Training loss: 2.9614173681480866
Validation loss: 2.4393485332478284

Epoch: 5| Step: 6
Training loss: 2.4448122725548207
Validation loss: 2.45550964214299

Epoch: 5| Step: 7
Training loss: 2.6782192289318316
Validation loss: 2.451521079049832

Epoch: 5| Step: 8
Training loss: 3.1434421335473077
Validation loss: 2.455389134454727

Epoch: 5| Step: 9
Training loss: 2.6511507342872576
Validation loss: 2.45868568092259

Epoch: 5| Step: 10
Training loss: 2.523677944384718
Validation loss: 2.4611570480084137

Epoch: 201| Step: 0
Training loss: 2.3384498176010697
Validation loss: 2.4565396224542497

Epoch: 5| Step: 1
Training loss: 2.3167714028959283
Validation loss: 2.4582598157109246

Epoch: 5| Step: 2
Training loss: 2.4307711720574936
Validation loss: 2.453928378871396

Epoch: 5| Step: 3
Training loss: 2.4733367031859332
Validation loss: 2.453254746960813

Epoch: 5| Step: 4
Training loss: 2.732857593755405
Validation loss: 2.4417182365340837

Epoch: 5| Step: 5
Training loss: 2.9249580967175772
Validation loss: 2.4435602477048546

Epoch: 5| Step: 6
Training loss: 2.385299335464899
Validation loss: 2.434738503300271

Epoch: 5| Step: 7
Training loss: 2.879593869289692
Validation loss: 2.444138338686113

Epoch: 5| Step: 8
Training loss: 2.4947946717012552
Validation loss: 2.451438908023715

Epoch: 5| Step: 9
Training loss: 3.080484018812812
Validation loss: 2.455348927367324

Epoch: 5| Step: 10
Training loss: 3.2467723371266515
Validation loss: 2.447965355369048

Epoch: 202| Step: 0
Training loss: 3.0382585810597655
Validation loss: 2.459765481339063

Epoch: 5| Step: 1
Training loss: 2.6222407962209493
Validation loss: 2.475664647795133

Epoch: 5| Step: 2
Training loss: 2.4750881680283956
Validation loss: 2.4602401633481885

Epoch: 5| Step: 3
Training loss: 2.3397877070317836
Validation loss: 2.457073542386471

Epoch: 5| Step: 4
Training loss: 2.4463834032457523
Validation loss: 2.4591289864368244

Epoch: 5| Step: 5
Training loss: 2.7165434202855794
Validation loss: 2.456933823659572

Epoch: 5| Step: 6
Training loss: 2.61468240213336
Validation loss: 2.465437373159734

Epoch: 5| Step: 7
Training loss: 2.52444466253214
Validation loss: 2.460035028338312

Epoch: 5| Step: 8
Training loss: 2.9390478722929783
Validation loss: 2.4687120739230446

Epoch: 5| Step: 9
Training loss: 2.615238933260124
Validation loss: 2.4700649648898487

Epoch: 5| Step: 10
Training loss: 3.0437546622301306
Validation loss: 2.4718475151927155

Epoch: 203| Step: 0
Training loss: 2.925374918327694
Validation loss: 2.4829035775754122

Epoch: 5| Step: 1
Training loss: 2.291034565072499
Validation loss: 2.4927613376325444

Epoch: 5| Step: 2
Training loss: 2.5952829633728083
Validation loss: 2.4738671595682886

Epoch: 5| Step: 3
Training loss: 2.81891248619532
Validation loss: 2.460357558095513

Epoch: 5| Step: 4
Training loss: 2.950131145083784
Validation loss: 2.459488677696689

Epoch: 5| Step: 5
Training loss: 2.5739544051132786
Validation loss: 2.4499889095190155

Epoch: 5| Step: 6
Training loss: 2.878556580963301
Validation loss: 2.4509548173350666

Epoch: 5| Step: 7
Training loss: 2.756494482706417
Validation loss: 2.446229532816128

Epoch: 5| Step: 8
Training loss: 2.445867993327459
Validation loss: 2.4527716396854866

Epoch: 5| Step: 9
Training loss: 2.308413942309011
Validation loss: 2.4438636490044274

Epoch: 5| Step: 10
Training loss: 2.63165321069635
Validation loss: 2.4721892629551565

Epoch: 204| Step: 0
Training loss: 2.4071881335675
Validation loss: 2.4879502682753922

Epoch: 5| Step: 1
Training loss: 2.642232371828466
Validation loss: 2.47631034474454

Epoch: 5| Step: 2
Training loss: 2.6975875319879457
Validation loss: 2.4784069067334102

Epoch: 5| Step: 3
Training loss: 3.1737259598941208
Validation loss: 2.4647782499397426

Epoch: 5| Step: 4
Training loss: 2.7970768520038245
Validation loss: 2.472967984602599

Epoch: 5| Step: 5
Training loss: 2.470061521188699
Validation loss: 2.469696538450541

Epoch: 5| Step: 6
Training loss: 3.0836636821663794
Validation loss: 2.4762943524168097

Epoch: 5| Step: 7
Training loss: 2.237205260060165
Validation loss: 2.4847311171105297

Epoch: 5| Step: 8
Training loss: 2.5257712517684108
Validation loss: 2.4960017441766356

Epoch: 5| Step: 9
Training loss: 2.152002214033555
Validation loss: 2.4831970078182857

Epoch: 5| Step: 10
Training loss: 3.185198083583663
Validation loss: 2.4763656987793827

Epoch: 205| Step: 0
Training loss: 2.366908494477137
Validation loss: 2.475561465842454

Epoch: 5| Step: 1
Training loss: 2.528598479833601
Validation loss: 2.470674593513208

Epoch: 5| Step: 2
Training loss: 2.719472767136135
Validation loss: 2.461273342329298

Epoch: 5| Step: 3
Training loss: 2.8082159687575774
Validation loss: 2.458561340431444

Epoch: 5| Step: 4
Training loss: 2.589330654036173
Validation loss: 2.4563507729475114

Epoch: 5| Step: 5
Training loss: 2.4537883274779215
Validation loss: 2.4456212428319013

Epoch: 5| Step: 6
Training loss: 2.8264175234465454
Validation loss: 2.444659724708118

Epoch: 5| Step: 7
Training loss: 2.850061141579631
Validation loss: 2.4347536814249535

Epoch: 5| Step: 8
Training loss: 3.0669087963990203
Validation loss: 2.424035288652517

Epoch: 5| Step: 9
Training loss: 1.9665328969020015
Validation loss: 2.4451672129732884

Epoch: 5| Step: 10
Training loss: 2.8043851981711927
Validation loss: 2.4473412487832906

Epoch: 206| Step: 0
Training loss: 3.0919361384361546
Validation loss: 2.448826311418193

Epoch: 5| Step: 1
Training loss: 2.0929591265176293
Validation loss: 2.440250836517066

Epoch: 5| Step: 2
Training loss: 2.1373042502198447
Validation loss: 2.440421760509211

Epoch: 5| Step: 3
Training loss: 2.894598791490159
Validation loss: 2.446313655117985

Epoch: 5| Step: 4
Training loss: 2.3000944242583063
Validation loss: 2.42843477354647

Epoch: 5| Step: 5
Training loss: 2.8519320313860055
Validation loss: 2.4272648384650966

Epoch: 5| Step: 6
Training loss: 2.965369297335507
Validation loss: 2.424421869089527

Epoch: 5| Step: 7
Training loss: 2.6951967076293637
Validation loss: 2.4248791943960804

Epoch: 5| Step: 8
Training loss: 3.0539300081817604
Validation loss: 2.4261887398178303

Epoch: 5| Step: 9
Training loss: 2.1903589367335474
Validation loss: 2.427601801451654

Epoch: 5| Step: 10
Training loss: 2.656611518941609
Validation loss: 2.4308293591422756

Epoch: 207| Step: 0
Training loss: 2.75484732923134
Validation loss: 2.4246469238318227

Epoch: 5| Step: 1
Training loss: 3.0310997679931013
Validation loss: 2.429316660387339

Epoch: 5| Step: 2
Training loss: 2.501981712731875
Validation loss: 2.4261065260336743

Epoch: 5| Step: 3
Training loss: 2.503379540234968
Validation loss: 2.431658373812117

Epoch: 5| Step: 4
Training loss: 2.4638011922022574
Validation loss: 2.4412274516601054

Epoch: 5| Step: 5
Training loss: 2.701857958953225
Validation loss: 2.438317783552773

Epoch: 5| Step: 6
Training loss: 2.123275056734933
Validation loss: 2.454056344008394

Epoch: 5| Step: 7
Training loss: 2.563481026781827
Validation loss: 2.4510367577481857

Epoch: 5| Step: 8
Training loss: 3.0698647208960286
Validation loss: 2.4702910637746442

Epoch: 5| Step: 9
Training loss: 2.2743031534921583
Validation loss: 2.4556268678908504

Epoch: 5| Step: 10
Training loss: 2.742685821552857
Validation loss: 2.464562950236877

Epoch: 208| Step: 0
Training loss: 2.8563414778136065
Validation loss: 2.447629803824094

Epoch: 5| Step: 1
Training loss: 2.6302220309564945
Validation loss: 2.448654270688855

Epoch: 5| Step: 2
Training loss: 2.7668166529740126
Validation loss: 2.4909402701352894

Epoch: 5| Step: 3
Training loss: 2.6355900361906035
Validation loss: 2.5235522570572266

Epoch: 5| Step: 4
Training loss: 2.4183930993751757
Validation loss: 2.5372638570893353

Epoch: 5| Step: 5
Training loss: 2.6199769598552045
Validation loss: 2.489509851915286

Epoch: 5| Step: 6
Training loss: 2.8146478716615646
Validation loss: 2.441163555855535

Epoch: 5| Step: 7
Training loss: 2.7552368412574118
Validation loss: 2.4336923055760797

Epoch: 5| Step: 8
Training loss: 2.585956400545779
Validation loss: 2.431244749067814

Epoch: 5| Step: 9
Training loss: 2.3441806651851373
Validation loss: 2.473660734678194

Epoch: 5| Step: 10
Training loss: 2.694145945327636
Validation loss: 2.5003384704552274

Epoch: 209| Step: 0
Training loss: 2.4649294492208558
Validation loss: 2.508315307273873

Epoch: 5| Step: 1
Training loss: 2.8312943545608196
Validation loss: 2.51737038600874

Epoch: 5| Step: 2
Training loss: 2.363924906698192
Validation loss: 2.4910056040585924

Epoch: 5| Step: 3
Training loss: 2.7253158911198496
Validation loss: 2.488859903477296

Epoch: 5| Step: 4
Training loss: 2.501275404801575
Validation loss: 2.4441247654430462

Epoch: 5| Step: 5
Training loss: 2.5898197224740898
Validation loss: 2.4599875735881036

Epoch: 5| Step: 6
Training loss: 2.2545858908827747
Validation loss: 2.4965018527208698

Epoch: 5| Step: 7
Training loss: 3.1274178878531202
Validation loss: 2.5251497660232394

Epoch: 5| Step: 8
Training loss: 3.156724950728331
Validation loss: 2.5197319706943633

Epoch: 5| Step: 9
Training loss: 2.879034777066542
Validation loss: 2.501721480599538

Epoch: 5| Step: 10
Training loss: 2.642172907107146
Validation loss: 2.4874172662151848

Epoch: 210| Step: 0
Training loss: 2.1418195301327803
Validation loss: 2.463711626557496

Epoch: 5| Step: 1
Training loss: 3.081283111084851
Validation loss: 2.4725831900387134

Epoch: 5| Step: 2
Training loss: 2.0914309739941057
Validation loss: 2.4765823874311206

Epoch: 5| Step: 3
Training loss: 2.825802265455056
Validation loss: 2.4815223234651764

Epoch: 5| Step: 4
Training loss: 2.6563486417518436
Validation loss: 2.4941869134569985

Epoch: 5| Step: 5
Training loss: 2.3304522870230717
Validation loss: 2.522177094422077

Epoch: 5| Step: 6
Training loss: 2.9649296322170993
Validation loss: 2.5589408257730066

Epoch: 5| Step: 7
Training loss: 2.627617121734793
Validation loss: 2.5724932281594115

Epoch: 5| Step: 8
Training loss: 2.383595022315602
Validation loss: 2.555842234677736

Epoch: 5| Step: 9
Training loss: 3.096366315496474
Validation loss: 2.505712545440219

Epoch: 5| Step: 10
Training loss: 2.6407659368881893
Validation loss: 2.4549218661427834

Epoch: 211| Step: 0
Training loss: 2.753415674112916
Validation loss: 2.445714655460411

Epoch: 5| Step: 1
Training loss: 2.4104112586046202
Validation loss: 2.473823160430484

Epoch: 5| Step: 2
Training loss: 2.6248643930921083
Validation loss: 2.4886116623286325

Epoch: 5| Step: 3
Training loss: 2.3857341927055975
Validation loss: 2.4851258208071494

Epoch: 5| Step: 4
Training loss: 2.937599180454564
Validation loss: 2.463474194623541

Epoch: 5| Step: 5
Training loss: 2.451059820645911
Validation loss: 2.4508829744463836

Epoch: 5| Step: 6
Training loss: 2.278844322642154
Validation loss: 2.438356056215444

Epoch: 5| Step: 7
Training loss: 3.071160662806891
Validation loss: 2.428202552753679

Epoch: 5| Step: 8
Training loss: 2.7875352626332073
Validation loss: 2.4206960570732394

Epoch: 5| Step: 9
Training loss: 2.5235337749811193
Validation loss: 2.402068287920124

Epoch: 5| Step: 10
Training loss: 3.1580334147738407
Validation loss: 2.4029065563788996

Epoch: 212| Step: 0
Training loss: 2.7900140245146665
Validation loss: 2.4187780526743707

Epoch: 5| Step: 1
Training loss: 2.6473142329269614
Validation loss: 2.423832394860566

Epoch: 5| Step: 2
Training loss: 2.883131717696386
Validation loss: 2.4327324149979717

Epoch: 5| Step: 3
Training loss: 2.302830766079203
Validation loss: 2.445041358265449

Epoch: 5| Step: 4
Training loss: 2.7161799593592386
Validation loss: 2.4602986178536583

Epoch: 5| Step: 5
Training loss: 2.139979801260911
Validation loss: 2.511328698543408

Epoch: 5| Step: 6
Training loss: 3.2283298187420537
Validation loss: 2.5216387142946877

Epoch: 5| Step: 7
Training loss: 2.1184151669034224
Validation loss: 2.531679722365063

Epoch: 5| Step: 8
Training loss: 2.680448996666504
Validation loss: 2.4879590824962516

Epoch: 5| Step: 9
Training loss: 2.9749711556198357
Validation loss: 2.481100592941737

Epoch: 5| Step: 10
Training loss: 2.3288510617714087
Validation loss: 2.4562503304004175

Epoch: 213| Step: 0
Training loss: 2.3309049458345816
Validation loss: 2.4293362127755977

Epoch: 5| Step: 1
Training loss: 2.485852551882047
Validation loss: 2.418103099524903

Epoch: 5| Step: 2
Training loss: 2.52067570679557
Validation loss: 2.407924797460693

Epoch: 5| Step: 3
Training loss: 2.659884759658182
Validation loss: 2.4259509911871735

Epoch: 5| Step: 4
Training loss: 2.777417918313474
Validation loss: 2.442155133378658

Epoch: 5| Step: 5
Training loss: 2.7105506818881793
Validation loss: 2.4612948396360372

Epoch: 5| Step: 6
Training loss: 2.9163030851906293
Validation loss: 2.4501992089200475

Epoch: 5| Step: 7
Training loss: 2.1950246819083863
Validation loss: 2.4608039065741543

Epoch: 5| Step: 8
Training loss: 2.5498284375689195
Validation loss: 2.451610640407116

Epoch: 5| Step: 9
Training loss: 2.7924899884678833
Validation loss: 2.430442882295537

Epoch: 5| Step: 10
Training loss: 3.0025731813277283
Validation loss: 2.4337323448114265

Epoch: 214| Step: 0
Training loss: 2.9884270925399465
Validation loss: 2.4216864907809232

Epoch: 5| Step: 1
Training loss: 2.785432649355913
Validation loss: 2.437470451956284

Epoch: 5| Step: 2
Training loss: 2.242393882902895
Validation loss: 2.425607468009795

Epoch: 5| Step: 3
Training loss: 2.599408882142257
Validation loss: 2.4391665592047347

Epoch: 5| Step: 4
Training loss: 2.6384573622672853
Validation loss: 2.441844797431632

Epoch: 5| Step: 5
Training loss: 2.6382449106069563
Validation loss: 2.455663127352881

Epoch: 5| Step: 6
Training loss: 1.2323314313150726
Validation loss: 2.454581051745269

Epoch: 5| Step: 7
Training loss: 2.649894201218027
Validation loss: 2.4765501939767947

Epoch: 5| Step: 8
Training loss: 2.9509416208881762
Validation loss: 2.455452080627696

Epoch: 5| Step: 9
Training loss: 2.9243574561554664
Validation loss: 2.464075914372262

Epoch: 5| Step: 10
Training loss: 2.54170694996747
Validation loss: 2.4707130093084775

Epoch: 215| Step: 0
Training loss: 2.73785266433548
Validation loss: 2.460226392380564

Epoch: 5| Step: 1
Training loss: 2.5658039100333507
Validation loss: 2.448525615939704

Epoch: 5| Step: 2
Training loss: 2.63270527878852
Validation loss: 2.459322284301811

Epoch: 5| Step: 3
Training loss: 2.6363554075465436
Validation loss: 2.4695245460542563

Epoch: 5| Step: 4
Training loss: 2.351770943056214
Validation loss: 2.46731632089653

Epoch: 5| Step: 5
Training loss: 2.2331323969772146
Validation loss: 2.500539367184558

Epoch: 5| Step: 6
Training loss: 3.1247477620369586
Validation loss: 2.5274949157994127

Epoch: 5| Step: 7
Training loss: 2.886616830226752
Validation loss: 2.527497662525044

Epoch: 5| Step: 8
Training loss: 2.6511733066773613
Validation loss: 2.5011918293132105

Epoch: 5| Step: 9
Training loss: 2.5000982265248997
Validation loss: 2.493441815099322

Epoch: 5| Step: 10
Training loss: 2.2796983013982244
Validation loss: 2.479644630735069

Epoch: 216| Step: 0
Training loss: 1.8812427862795793
Validation loss: 2.4775552051094336

Epoch: 5| Step: 1
Training loss: 2.993598784448406
Validation loss: 2.489923625283268

Epoch: 5| Step: 2
Training loss: 2.8989321551350047
Validation loss: 2.481471705577731

Epoch: 5| Step: 3
Training loss: 2.756419924387528
Validation loss: 2.458430236344261

Epoch: 5| Step: 4
Training loss: 2.864988393177535
Validation loss: 2.4424181334025956

Epoch: 5| Step: 5
Training loss: 2.2473017089747627
Validation loss: 2.4322426775589254

Epoch: 5| Step: 6
Training loss: 2.5431987230701485
Validation loss: 2.4296431313011393

Epoch: 5| Step: 7
Training loss: 2.397631979005637
Validation loss: 2.430721904103484

Epoch: 5| Step: 8
Training loss: 2.299286491181617
Validation loss: 2.4434211894752145

Epoch: 5| Step: 9
Training loss: 2.8690899350419268
Validation loss: 2.4441154060971106

Epoch: 5| Step: 10
Training loss: 2.7071358796744036
Validation loss: 2.446735107570215

Epoch: 217| Step: 0
Training loss: 3.0695765732011178
Validation loss: 2.4396119519524007

Epoch: 5| Step: 1
Training loss: 1.845042858401335
Validation loss: 2.45654491349206

Epoch: 5| Step: 2
Training loss: 3.3988079000734306
Validation loss: 2.4796498579975688

Epoch: 5| Step: 3
Training loss: 2.7148760677033272
Validation loss: 2.474042722410162

Epoch: 5| Step: 4
Training loss: 2.7750424321685054
Validation loss: 2.463093887056288

Epoch: 5| Step: 5
Training loss: 2.0351083350810484
Validation loss: 2.449103728723857

Epoch: 5| Step: 6
Training loss: 2.4934214822551333
Validation loss: 2.4543967377354665

Epoch: 5| Step: 7
Training loss: 2.0322235122063845
Validation loss: 2.448900943791546

Epoch: 5| Step: 8
Training loss: 2.4802490137046544
Validation loss: 2.46024392037947

Epoch: 5| Step: 9
Training loss: 2.093137053542971
Validation loss: 2.4633278473738263

Epoch: 5| Step: 10
Training loss: 2.8298985099791523
Validation loss: 2.469862446758777

Epoch: 218| Step: 0
Training loss: 2.638776956381688
Validation loss: 2.486845862285309

Epoch: 5| Step: 1
Training loss: 3.155689454110802
Validation loss: 2.502940879519789

Epoch: 5| Step: 2
Training loss: 2.103689599170225
Validation loss: 2.49166388547685

Epoch: 5| Step: 3
Training loss: 2.2733806589892738
Validation loss: 2.4741918437880925

Epoch: 5| Step: 4
Training loss: 2.521058558551497
Validation loss: 2.481798622977673

Epoch: 5| Step: 5
Training loss: 2.7523555204219385
Validation loss: 2.4845376694429424

Epoch: 5| Step: 6
Training loss: 2.628937175506484
Validation loss: 2.4885013350535057

Epoch: 5| Step: 7
Training loss: 2.8975384492602347
Validation loss: 2.489605541098448

Epoch: 5| Step: 8
Training loss: 2.5978421940615606
Validation loss: 2.484930572644189

Epoch: 5| Step: 9
Training loss: 2.13886383449308
Validation loss: 2.4778908141822615

Epoch: 5| Step: 10
Training loss: 2.482464517606799
Validation loss: 2.4836379913667286

Epoch: 219| Step: 0
Training loss: 2.5770338118988034
Validation loss: 2.4831356910463915

Epoch: 5| Step: 1
Training loss: 1.948563826931292
Validation loss: 2.4907123938341704

Epoch: 5| Step: 2
Training loss: 2.585957967901909
Validation loss: 2.479232945068549

Epoch: 5| Step: 3
Training loss: 2.1785860731182094
Validation loss: 2.4621685448596007

Epoch: 5| Step: 4
Training loss: 2.4177210469851884
Validation loss: 2.4655848574772206

Epoch: 5| Step: 5
Training loss: 2.603171003102336
Validation loss: 2.4720955150214765

Epoch: 5| Step: 6
Training loss: 2.40822738053605
Validation loss: 2.487366433323779

Epoch: 5| Step: 7
Training loss: 2.5971028362267936
Validation loss: 2.4890708335761316

Epoch: 5| Step: 8
Training loss: 2.689820995118227
Validation loss: 2.4624166262258727

Epoch: 5| Step: 9
Training loss: 2.5223729394796264
Validation loss: 2.4583654632749035

Epoch: 5| Step: 10
Training loss: 3.379613054913231
Validation loss: 2.4543043595794907

Epoch: 220| Step: 0
Training loss: 2.3452402082124357
Validation loss: 2.473031990613335

Epoch: 5| Step: 1
Training loss: 2.97646445766191
Validation loss: 2.499072744829291

Epoch: 5| Step: 2
Training loss: 2.8425736561863664
Validation loss: 2.52873677443905

Epoch: 5| Step: 3
Training loss: 2.1775171556464867
Validation loss: 2.534359805054725

Epoch: 5| Step: 4
Training loss: 2.1386163573701644
Validation loss: 2.5027868406883544

Epoch: 5| Step: 5
Training loss: 2.928440652645516
Validation loss: 2.4738814851820936

Epoch: 5| Step: 6
Training loss: 2.880525834770074
Validation loss: 2.461509775298728

Epoch: 5| Step: 7
Training loss: 2.8382155671461637
Validation loss: 2.4433838344765606

Epoch: 5| Step: 8
Training loss: 2.380040191343089
Validation loss: 2.4545739731037024

Epoch: 5| Step: 9
Training loss: 1.999663443858089
Validation loss: 2.4464667657723576

Epoch: 5| Step: 10
Training loss: 2.4060722384496653
Validation loss: 2.44267063298501

Epoch: 221| Step: 0
Training loss: 3.0036227287161017
Validation loss: 2.4343960200617034

Epoch: 5| Step: 1
Training loss: 2.029449486524183
Validation loss: 2.43111975274821

Epoch: 5| Step: 2
Training loss: 2.699742135343869
Validation loss: 2.4211607981836587

Epoch: 5| Step: 3
Training loss: 2.3115723269940753
Validation loss: 2.437148607081699

Epoch: 5| Step: 4
Training loss: 2.3460823152805235
Validation loss: 2.414819768746083

Epoch: 5| Step: 5
Training loss: 2.9532441614723473
Validation loss: 2.424740033285566

Epoch: 5| Step: 6
Training loss: 2.470468912595705
Validation loss: 2.4116314152783476

Epoch: 5| Step: 7
Training loss: 2.191884687286455
Validation loss: 2.4013336237611345

Epoch: 5| Step: 8
Training loss: 2.731717196732858
Validation loss: 2.3871893219050806

Epoch: 5| Step: 9
Training loss: 2.415742752343823
Validation loss: 2.3911405754436728

Epoch: 5| Step: 10
Training loss: 2.3706873839316653
Validation loss: 2.3985129328455557

Epoch: 222| Step: 0
Training loss: 2.0334481889564855
Validation loss: 2.4133112664721725

Epoch: 5| Step: 1
Training loss: 2.397536018268093
Validation loss: 2.447009256477908

Epoch: 5| Step: 2
Training loss: 2.1727610365622754
Validation loss: 2.4720383345236736

Epoch: 5| Step: 3
Training loss: 2.1950616116229633
Validation loss: 2.495044170799721

Epoch: 5| Step: 4
Training loss: 2.365986837432699
Validation loss: 2.4940210156126534

Epoch: 5| Step: 5
Training loss: 2.4105876122350307
Validation loss: 2.493780780398417

Epoch: 5| Step: 6
Training loss: 2.7364001812592855
Validation loss: 2.4911422180715004

Epoch: 5| Step: 7
Training loss: 3.16241457375204
Validation loss: 2.477658714292675

Epoch: 5| Step: 8
Training loss: 2.865276312959952
Validation loss: 2.497212122985425

Epoch: 5| Step: 9
Training loss: 2.6964088753203757
Validation loss: 2.497656038188265

Epoch: 5| Step: 10
Training loss: 2.2691597560628374
Validation loss: 2.490745040325584

Epoch: 223| Step: 0
Training loss: 2.5747610629435114
Validation loss: 2.4876105023192787

Epoch: 5| Step: 1
Training loss: 2.6520383768598914
Validation loss: 2.4705550060906836

Epoch: 5| Step: 2
Training loss: 2.8146150901089033
Validation loss: 2.45795952124133

Epoch: 5| Step: 3
Training loss: 2.78615249428949
Validation loss: 2.431280312445532

Epoch: 5| Step: 4
Training loss: 2.6332201543058416
Validation loss: 2.4402421073619234

Epoch: 5| Step: 5
Training loss: 2.6153024745789573
Validation loss: 2.431629471700371

Epoch: 5| Step: 6
Training loss: 2.0653930949403305
Validation loss: 2.4431368257421386

Epoch: 5| Step: 7
Training loss: 2.2924044952966205
Validation loss: 2.453596425262575

Epoch: 5| Step: 8
Training loss: 2.6797000450975026
Validation loss: 2.4341219182051628

Epoch: 5| Step: 9
Training loss: 2.3083400941972383
Validation loss: 2.4177851254602682

Epoch: 5| Step: 10
Training loss: 1.7708589065799538
Validation loss: 2.396411342012629

Epoch: 224| Step: 0
Training loss: 2.562017627997878
Validation loss: 2.3841916449629914

Epoch: 5| Step: 1
Training loss: 2.8538628483773767
Validation loss: 2.3961128517658756

Epoch: 5| Step: 2
Training loss: 2.3700528067327236
Validation loss: 2.407950227987812

Epoch: 5| Step: 3
Training loss: 2.1741699608041536
Validation loss: 2.4196200646188237

Epoch: 5| Step: 4
Training loss: 2.3636220134619608
Validation loss: 2.4374709694235044

Epoch: 5| Step: 5
Training loss: 2.6264421043964745
Validation loss: 2.443150599122235

Epoch: 5| Step: 6
Training loss: 3.115054057771215
Validation loss: 2.4578703648934583

Epoch: 5| Step: 7
Training loss: 1.8518986779050084
Validation loss: 2.459294875865239

Epoch: 5| Step: 8
Training loss: 2.372760921878776
Validation loss: 2.4894344010515934

Epoch: 5| Step: 9
Training loss: 2.427215594397624
Validation loss: 2.535285722285786

Epoch: 5| Step: 10
Training loss: 2.7108709233708437
Validation loss: 2.528979620272999

Epoch: 225| Step: 0
Training loss: 2.6629830687812266
Validation loss: 2.491731885750021

Epoch: 5| Step: 1
Training loss: 2.7868796817306474
Validation loss: 2.4686331274121387

Epoch: 5| Step: 2
Training loss: 1.9499565364199793
Validation loss: 2.450578476504644

Epoch: 5| Step: 3
Training loss: 2.6922015384035736
Validation loss: 2.4629751441751933

Epoch: 5| Step: 4
Training loss: 2.4920488755467884
Validation loss: 2.464176537314684

Epoch: 5| Step: 5
Training loss: 2.634193397860211
Validation loss: 2.4644326106559142

Epoch: 5| Step: 6
Training loss: 2.052867010388473
Validation loss: 2.4577165001494077

Epoch: 5| Step: 7
Training loss: 2.299079615498267
Validation loss: 2.4464348341032442

Epoch: 5| Step: 8
Training loss: 1.9502805214625512
Validation loss: 2.431411414362653

Epoch: 5| Step: 9
Training loss: 2.685268273901106
Validation loss: 2.423817209691832

Epoch: 5| Step: 10
Training loss: 2.3035758748228097
Validation loss: 2.4166474794199675

Epoch: 226| Step: 0
Training loss: 2.6172968144148445
Validation loss: 2.402087275536134

Epoch: 5| Step: 1
Training loss: 2.4035195055353245
Validation loss: 2.390956458101795

Epoch: 5| Step: 2
Training loss: 2.2670111263559085
Validation loss: 2.38065842272184

Epoch: 5| Step: 3
Training loss: 2.133640226502562
Validation loss: 2.3866137055217433

Epoch: 5| Step: 4
Training loss: 2.5468502862585454
Validation loss: 2.376081648899294

Epoch: 5| Step: 5
Training loss: 2.3850471399155073
Validation loss: 2.375080835880561

Epoch: 5| Step: 6
Training loss: 2.536565309706031
Validation loss: 2.407590599450542

Epoch: 5| Step: 7
Training loss: 2.2216803313872693
Validation loss: 2.421372003683066

Epoch: 5| Step: 8
Training loss: 2.6586634722906966
Validation loss: 2.44639907395347

Epoch: 5| Step: 9
Training loss: 1.9548656184263271
Validation loss: 2.4558798920616556

Epoch: 5| Step: 10
Training loss: 2.8210984928552887
Validation loss: 2.5004310595195225

Epoch: 227| Step: 0
Training loss: 2.696615153112617
Validation loss: 2.51437733682341

Epoch: 5| Step: 1
Training loss: 2.4889179654731453
Validation loss: 2.494875148626936

Epoch: 5| Step: 2
Training loss: 2.4415849543971584
Validation loss: 2.4704598512588194

Epoch: 5| Step: 3
Training loss: 2.2996230521426333
Validation loss: 2.4789592645480267

Epoch: 5| Step: 4
Training loss: 1.8819189206778084
Validation loss: 2.4567458684820265

Epoch: 5| Step: 5
Training loss: 2.459630031522581
Validation loss: 2.4826676878169622

Epoch: 5| Step: 6
Training loss: 1.8368367691448644
Validation loss: 2.472292720451178

Epoch: 5| Step: 7
Training loss: 2.3475930813178976
Validation loss: 2.4505490171117223

Epoch: 5| Step: 8
Training loss: 2.774862949320598
Validation loss: 2.425486714477521

Epoch: 5| Step: 9
Training loss: 2.827259837642214
Validation loss: 2.4306675620183564

Epoch: 5| Step: 10
Training loss: 2.0645632971578256
Validation loss: 2.410325231289252

Epoch: 228| Step: 0
Training loss: 2.2115351539765697
Validation loss: 2.4049276322902378

Epoch: 5| Step: 1
Training loss: 2.6699542006661434
Validation loss: 2.3860000847661893

Epoch: 5| Step: 2
Training loss: 2.567109405016985
Validation loss: 2.4344894901014125

Epoch: 5| Step: 3
Training loss: 2.615770189637759
Validation loss: 2.4977085502386793

Epoch: 5| Step: 4
Training loss: 2.1067052830202937
Validation loss: 2.430761856215103

Epoch: 5| Step: 5
Training loss: 2.7025578956860317
Validation loss: 2.407718948932169

Epoch: 5| Step: 6
Training loss: 2.391623494182821
Validation loss: 2.3762317090887506

Epoch: 5| Step: 7
Training loss: 2.4511345241178146
Validation loss: 2.373943212478701

Epoch: 5| Step: 8
Training loss: 2.5887110838274334
Validation loss: 2.37261054276556

Epoch: 5| Step: 9
Training loss: 2.480794858146144
Validation loss: 2.388954999655516

Epoch: 5| Step: 10
Training loss: 1.5798653552472277
Validation loss: 2.414655228825362

Epoch: 229| Step: 0
Training loss: 2.635092633698365
Validation loss: 2.4509545558409793

Epoch: 5| Step: 1
Training loss: 2.681837370587839
Validation loss: 2.477611185794198

Epoch: 5| Step: 2
Training loss: 2.31789130585181
Validation loss: 2.503509552002933

Epoch: 5| Step: 3
Training loss: 2.4288220596814445
Validation loss: 2.4825378588639135

Epoch: 5| Step: 4
Training loss: 1.7657702225908805
Validation loss: 2.4806619073024745

Epoch: 5| Step: 5
Training loss: 2.8713101467663398
Validation loss: 2.4531403527956064

Epoch: 5| Step: 6
Training loss: 1.9264136585616347
Validation loss: 2.4515414917059966

Epoch: 5| Step: 7
Training loss: 2.7176901845349173
Validation loss: 2.426461047897987

Epoch: 5| Step: 8
Training loss: 2.3457781345339375
Validation loss: 2.4241463861595096

Epoch: 5| Step: 9
Training loss: 2.188097626929746
Validation loss: 2.428665269491706

Epoch: 5| Step: 10
Training loss: 2.3105942373830763
Validation loss: 2.4152380755797083

Epoch: 230| Step: 0
Training loss: 2.3542086392152175
Validation loss: 2.450693950562501

Epoch: 5| Step: 1
Training loss: 2.250765882053629
Validation loss: 2.4891525883103487

Epoch: 5| Step: 2
Training loss: 2.105404203483594
Validation loss: 2.527960938570028

Epoch: 5| Step: 3
Training loss: 2.4674736296723947
Validation loss: 2.5195802903066973

Epoch: 5| Step: 4
Training loss: 2.859553097040676
Validation loss: 2.4881154117449507

Epoch: 5| Step: 5
Training loss: 2.471995767182365
Validation loss: 2.439145521669575

Epoch: 5| Step: 6
Training loss: 2.1155271882248767
Validation loss: 2.408258284832859

Epoch: 5| Step: 7
Training loss: 2.093926948927266
Validation loss: 2.3958051732473984

Epoch: 5| Step: 8
Training loss: 2.828689097424405
Validation loss: 2.39953500202148

Epoch: 5| Step: 9
Training loss: 2.0919775221439445
Validation loss: 2.406144898826357

Epoch: 5| Step: 10
Training loss: 2.5862613717184537
Validation loss: 2.3865584213939397

Epoch: 231| Step: 0
Training loss: 2.206970213999767
Validation loss: 2.3835942210416534

Epoch: 5| Step: 1
Training loss: 2.2906640605016113
Validation loss: 2.37273920102821

Epoch: 5| Step: 2
Training loss: 2.4477757731263194
Validation loss: 2.3905279097069436

Epoch: 5| Step: 3
Training loss: 2.5241867228689636
Validation loss: 2.3883874351702463

Epoch: 5| Step: 4
Training loss: 2.1531000764287365
Validation loss: 2.4010514569289247

Epoch: 5| Step: 5
Training loss: 2.531305194771011
Validation loss: 2.398665404206494

Epoch: 5| Step: 6
Training loss: 2.4298917923684646
Validation loss: 2.4309690722762283

Epoch: 5| Step: 7
Training loss: 2.123171861438528
Validation loss: 2.475172949107863

Epoch: 5| Step: 8
Training loss: 2.5200236467735477
Validation loss: 2.473094107296622

Epoch: 5| Step: 9
Training loss: 2.286267654242328
Validation loss: 2.4525826484731437

Epoch: 5| Step: 10
Training loss: 2.011696943146371
Validation loss: 2.4370672400790814

Epoch: 232| Step: 0
Training loss: 2.2978054938539616
Validation loss: 2.4216830333324366

Epoch: 5| Step: 1
Training loss: 2.038592638857648
Validation loss: 2.4106363132956226

Epoch: 5| Step: 2
Training loss: 2.3450582286380706
Validation loss: 2.3825908566546676

Epoch: 5| Step: 3
Training loss: 2.512181169767883
Validation loss: 2.413744697820943

Epoch: 5| Step: 4
Training loss: 2.3532078458632846
Validation loss: 2.4245859788332234

Epoch: 5| Step: 5
Training loss: 2.585682098591787
Validation loss: 2.474381608919608

Epoch: 5| Step: 6
Training loss: 2.300523209147788
Validation loss: 2.53744184721482

Epoch: 5| Step: 7
Training loss: 2.262202235907798
Validation loss: 2.5841636917627238

Epoch: 5| Step: 8
Training loss: 2.520762912828021
Validation loss: 2.5773720455590587

Epoch: 5| Step: 9
Training loss: 2.6951829962094673
Validation loss: 2.5200813864889824

Epoch: 5| Step: 10
Training loss: 1.788136538295326
Validation loss: 2.472935876789755

Epoch: 233| Step: 0
Training loss: 2.159867279425726
Validation loss: 2.460190365860029

Epoch: 5| Step: 1
Training loss: 2.2776688986499862
Validation loss: 2.4985915851818663

Epoch: 5| Step: 2
Training loss: 2.510661755597374
Validation loss: 2.50817302373779

Epoch: 5| Step: 3
Training loss: 2.4287557011103997
Validation loss: 2.498386728012418

Epoch: 5| Step: 4
Training loss: 2.5368048857411782
Validation loss: 2.4641282119315844

Epoch: 5| Step: 5
Training loss: 2.68548597232079
Validation loss: 2.4098444687951663

Epoch: 5| Step: 6
Training loss: 2.4490952164009063
Validation loss: 2.3366459925684606

Epoch: 5| Step: 7
Training loss: 2.277582538838477
Validation loss: 2.334711145605873

Epoch: 5| Step: 8
Training loss: 2.48412758416937
Validation loss: 2.3286432736977036

Epoch: 5| Step: 9
Training loss: 2.3697846017809066
Validation loss: 2.351064771942626

Epoch: 5| Step: 10
Training loss: 2.8551212208896
Validation loss: 2.3913706780656763

Epoch: 234| Step: 0
Training loss: 2.4886662112069633
Validation loss: 2.461286972553901

Epoch: 5| Step: 1
Training loss: 2.8163828008895098
Validation loss: 2.506708732252619

Epoch: 5| Step: 2
Training loss: 2.682199174094903
Validation loss: 2.5319489699361655

Epoch: 5| Step: 3
Training loss: 2.139405731684765
Validation loss: 2.4861377115713816

Epoch: 5| Step: 4
Training loss: 2.050991781418216
Validation loss: 2.4577902591522185

Epoch: 5| Step: 5
Training loss: 2.293277648186888
Validation loss: 2.458251893550971

Epoch: 5| Step: 6
Training loss: 2.312094781787343
Validation loss: 2.491544920661571

Epoch: 5| Step: 7
Training loss: 2.750293889380971
Validation loss: 2.5305556004790186

Epoch: 5| Step: 8
Training loss: 2.4866770509225193
Validation loss: 2.526498185771544

Epoch: 5| Step: 9
Training loss: 2.054401102158438
Validation loss: 2.4728705599681993

Epoch: 5| Step: 10
Training loss: 2.5498617246947877
Validation loss: 2.4444835098593662

Epoch: 235| Step: 0
Training loss: 2.473937848993457
Validation loss: 2.4761368083628694

Epoch: 5| Step: 1
Training loss: 1.842043329215951
Validation loss: 2.4832250103474074

Epoch: 5| Step: 2
Training loss: 2.205541381288598
Validation loss: 2.4850195344464274

Epoch: 5| Step: 3
Training loss: 3.022781655792994
Validation loss: 2.486390851907523

Epoch: 5| Step: 4
Training loss: 2.1474777019795264
Validation loss: 2.4464240594810502

Epoch: 5| Step: 5
Training loss: 2.7824180807580214
Validation loss: 2.4274999792652956

Epoch: 5| Step: 6
Training loss: 2.439218062352521
Validation loss: 2.558901060564794

Epoch: 5| Step: 7
Training loss: 2.9020304247617177
Validation loss: 2.5692769798005943

Epoch: 5| Step: 8
Training loss: 2.365016029416497
Validation loss: 2.553353724025424

Epoch: 5| Step: 9
Training loss: 2.557424869421981
Validation loss: 2.535235791545149

Epoch: 5| Step: 10
Training loss: 1.8852282969195926
Validation loss: 2.5069022131679

Epoch: 236| Step: 0
Training loss: 2.761522083752939
Validation loss: 2.4688361067090443

Epoch: 5| Step: 1
Training loss: 2.3841455951689743
Validation loss: 2.4335050583677806

Epoch: 5| Step: 2
Training loss: 2.450013927497981
Validation loss: 2.4043558637848355

Epoch: 5| Step: 3
Training loss: 2.4778354393826567
Validation loss: 2.391161706183768

Epoch: 5| Step: 4
Training loss: 2.0009503490840324
Validation loss: 2.403481599714664

Epoch: 5| Step: 5
Training loss: 2.2222134060154977
Validation loss: 2.3886368803740123

Epoch: 5| Step: 6
Training loss: 2.2736345448260837
Validation loss: 2.395868992551254

Epoch: 5| Step: 7
Training loss: 2.212995992981825
Validation loss: 2.4105176844949416

Epoch: 5| Step: 8
Training loss: 2.288824804678425
Validation loss: 2.4697256163390273

Epoch: 5| Step: 9
Training loss: 2.0436182102093143
Validation loss: 2.4729102437325152

Epoch: 5| Step: 10
Training loss: 2.457890443723969
Validation loss: 2.500791235787852

Epoch: 237| Step: 0
Training loss: 2.1566421594460556
Validation loss: 2.508767108682829

Epoch: 5| Step: 1
Training loss: 2.6479883403867124
Validation loss: 2.50457922949983

Epoch: 5| Step: 2
Training loss: 2.5774785936504534
Validation loss: 2.5099197319314497

Epoch: 5| Step: 3
Training loss: 2.266609556750228
Validation loss: 2.4900674591648904

Epoch: 5| Step: 4
Training loss: 1.9687293520858895
Validation loss: 2.4627967739759233

Epoch: 5| Step: 5
Training loss: 2.323469999864641
Validation loss: 2.4245384990377996

Epoch: 5| Step: 6
Training loss: 2.2654030526726032
Validation loss: 2.4109007371169873

Epoch: 5| Step: 7
Training loss: 2.2783250215942012
Validation loss: 2.416061205826967

Epoch: 5| Step: 8
Training loss: 2.2815718750342415
Validation loss: 2.4018523920874113

Epoch: 5| Step: 9
Training loss: 2.142839163750201
Validation loss: 2.403286891244072

Epoch: 5| Step: 10
Training loss: 2.1340200059162133
Validation loss: 2.414727013575141

Epoch: 238| Step: 0
Training loss: 2.618465919836641
Validation loss: 2.4282055902224795

Epoch: 5| Step: 1
Training loss: 2.568426025454107
Validation loss: 2.4369280817026624

Epoch: 5| Step: 2
Training loss: 2.166049086756862
Validation loss: 2.45162661023186

Epoch: 5| Step: 3
Training loss: 2.1644526932045904
Validation loss: 2.446649422795063

Epoch: 5| Step: 4
Training loss: 2.189180763856562
Validation loss: 2.432932416451722

Epoch: 5| Step: 5
Training loss: 2.2756157890537825
Validation loss: 2.4170401740342045

Epoch: 5| Step: 6
Training loss: 2.0187270077556403
Validation loss: 2.402093571267536

Epoch: 5| Step: 7
Training loss: 2.58572552783151
Validation loss: 2.3939030576095464

Epoch: 5| Step: 8
Training loss: 1.800351569492246
Validation loss: 2.3961584340541564

Epoch: 5| Step: 9
Training loss: 2.0444647889345906
Validation loss: 2.3779495168691587

Epoch: 5| Step: 10
Training loss: 2.4546883819209406
Validation loss: 2.3899510925886625

Epoch: 239| Step: 0
Training loss: 1.8663275745618904
Validation loss: 2.394264700314546

Epoch: 5| Step: 1
Training loss: 2.39159907025059
Validation loss: 2.418358524491634

Epoch: 5| Step: 2
Training loss: 1.522830000819285
Validation loss: 2.440105890045431

Epoch: 5| Step: 3
Training loss: 2.8066521779076767
Validation loss: 2.4546235821753175

Epoch: 5| Step: 4
Training loss: 1.9431105564644424
Validation loss: 2.458935206300101

Epoch: 5| Step: 5
Training loss: 2.591839005933475
Validation loss: 2.44899299712794

Epoch: 5| Step: 6
Training loss: 2.2968653464601028
Validation loss: 2.435849253690394

Epoch: 5| Step: 7
Training loss: 2.572283421066002
Validation loss: 2.396021272654266

Epoch: 5| Step: 8
Training loss: 2.066071164053078
Validation loss: 2.3735368330950513

Epoch: 5| Step: 9
Training loss: 2.1153269119662155
Validation loss: 2.366803164346547

Epoch: 5| Step: 10
Training loss: 2.4360442093531667
Validation loss: 2.3550369617097666

Epoch: 240| Step: 0
Training loss: 2.3404482154650808
Validation loss: 2.3754499761515264

Epoch: 5| Step: 1
Training loss: 1.7589520638870089
Validation loss: 2.402094651326936

Epoch: 5| Step: 2
Training loss: 2.213697133308068
Validation loss: 2.419509365349382

Epoch: 5| Step: 3
Training loss: 2.3446358596054844
Validation loss: 2.407283111043189

Epoch: 5| Step: 4
Training loss: 2.1715168829219222
Validation loss: 2.4175911204162674

Epoch: 5| Step: 5
Training loss: 1.8286829691953035
Validation loss: 2.4092811102795086

Epoch: 5| Step: 6
Training loss: 2.1011712940369156
Validation loss: 2.4359155216330715

Epoch: 5| Step: 7
Training loss: 2.4764968430152208
Validation loss: 2.4732526179133814

Epoch: 5| Step: 8
Training loss: 1.9958083812876715
Validation loss: 2.5064609286927464

Epoch: 5| Step: 9
Training loss: 2.6503091235972
Validation loss: 2.532468780118473

Epoch: 5| Step: 10
Training loss: 2.4054038801921105
Validation loss: 2.5387522770607927

Epoch: 241| Step: 0
Training loss: 1.9274018995205413
Validation loss: 2.5218399666537166

Epoch: 5| Step: 1
Training loss: 2.4044156699810233
Validation loss: 2.4865157947459573

Epoch: 5| Step: 2
Training loss: 2.2337480212236467
Validation loss: 2.4712028908794927

Epoch: 5| Step: 3
Training loss: 2.3243249179730237
Validation loss: 2.441645628385516

Epoch: 5| Step: 4
Training loss: 2.123249679466591
Validation loss: 2.4067669065423516

Epoch: 5| Step: 5
Training loss: 2.019912064026285
Validation loss: 2.40936747706029

Epoch: 5| Step: 6
Training loss: 1.837730927780545
Validation loss: 2.4131438987287592

Epoch: 5| Step: 7
Training loss: 2.6099940496501106
Validation loss: 2.4177670881859616

Epoch: 5| Step: 8
Training loss: 2.193549592082943
Validation loss: 2.4128756407987617

Epoch: 5| Step: 9
Training loss: 2.381146458254502
Validation loss: 2.409581295154842

Epoch: 5| Step: 10
Training loss: 2.4734721351844526
Validation loss: 2.435166273792212

Epoch: 242| Step: 0
Training loss: 1.6979177120026099
Validation loss: 2.534282580869291

Epoch: 5| Step: 1
Training loss: 2.4432194438722705
Validation loss: 2.652846549602177

Epoch: 5| Step: 2
Training loss: 3.0011972581454565
Validation loss: 2.665880006140413

Epoch: 5| Step: 3
Training loss: 2.41002082135082
Validation loss: 2.6146903400775874

Epoch: 5| Step: 4
Training loss: 2.5292800019043855
Validation loss: 2.5060284624437976

Epoch: 5| Step: 5
Training loss: 2.3776823255903135
Validation loss: 2.466785973149927

Epoch: 5| Step: 6
Training loss: 2.49087145266862
Validation loss: 2.4512297744361256

Epoch: 5| Step: 7
Training loss: 2.309418455135758
Validation loss: 2.42867754158663

Epoch: 5| Step: 8
Training loss: 1.9938318385245861
Validation loss: 2.4241358863145672

Epoch: 5| Step: 9
Training loss: 1.9326034938641319
Validation loss: 2.406860493592114

Epoch: 5| Step: 10
Training loss: 1.6584630611930424
Validation loss: 2.411791515294022

Epoch: 243| Step: 0
Training loss: 2.1820604540232624
Validation loss: 2.406590151493249

Epoch: 5| Step: 1
Training loss: 2.7019009326870096
Validation loss: 2.424644217077439

Epoch: 5| Step: 2
Training loss: 2.3042174813690077
Validation loss: 2.4495021261456373

Epoch: 5| Step: 3
Training loss: 2.1239192682789296
Validation loss: 2.46104666498215

Epoch: 5| Step: 4
Training loss: 2.2660029655093714
Validation loss: 2.4515250978049514

Epoch: 5| Step: 5
Training loss: 2.0363710844922402
Validation loss: 2.4411947279000925

Epoch: 5| Step: 6
Training loss: 2.3325299060535705
Validation loss: 2.440891633430783

Epoch: 5| Step: 7
Training loss: 1.520154653511695
Validation loss: 2.443927046230335

Epoch: 5| Step: 8
Training loss: 2.3042746998556876
Validation loss: 2.4598974011523147

Epoch: 5| Step: 9
Training loss: 2.145455138819161
Validation loss: 2.4706132616857643

Epoch: 5| Step: 10
Training loss: 1.4897230478490298
Validation loss: 2.451396484961269

Epoch: 244| Step: 0
Training loss: 1.7190863540289774
Validation loss: 2.437570501464333

Epoch: 5| Step: 1
Training loss: 1.860686152449214
Validation loss: 2.427976161419645

Epoch: 5| Step: 2
Training loss: 2.282936517896385
Validation loss: 2.4067964949381544

Epoch: 5| Step: 3
Training loss: 2.4697388225958545
Validation loss: 2.401090537145485

Epoch: 5| Step: 4
Training loss: 2.505165676036635
Validation loss: 2.3894294324515593

Epoch: 5| Step: 5
Training loss: 1.8955166171388762
Validation loss: 2.362129264633887

Epoch: 5| Step: 6
Training loss: 2.1707502787316475
Validation loss: 2.3555361980028007

Epoch: 5| Step: 7
Training loss: 2.4119822603778496
Validation loss: 2.361918144108478

Epoch: 5| Step: 8
Training loss: 1.7105016283809757
Validation loss: 2.388056529769064

Epoch: 5| Step: 9
Training loss: 2.27959633031129
Validation loss: 2.4148514177969904

Epoch: 5| Step: 10
Training loss: 1.985499506446702
Validation loss: 2.436735962675159

Epoch: 245| Step: 0
Training loss: 1.7592072103657048
Validation loss: 2.488632849826511

Epoch: 5| Step: 1
Training loss: 2.1016039082017794
Validation loss: 2.472408345819083

Epoch: 5| Step: 2
Training loss: 2.00472440618734
Validation loss: 2.488914814633392

Epoch: 5| Step: 3
Training loss: 1.945013122808517
Validation loss: 2.473876521382883

Epoch: 5| Step: 4
Training loss: 2.42979484885192
Validation loss: 2.460542145025328

Epoch: 5| Step: 5
Training loss: 2.228683799663343
Validation loss: 2.441461993231231

Epoch: 5| Step: 6
Training loss: 2.1558640728992797
Validation loss: 2.43793857500354

Epoch: 5| Step: 7
Training loss: 1.814087402803676
Validation loss: 2.420783677662423

Epoch: 5| Step: 8
Training loss: 2.279018826429098
Validation loss: 2.430138826599724

Epoch: 5| Step: 9
Training loss: 2.194438176474761
Validation loss: 2.4140998934870868

Epoch: 5| Step: 10
Training loss: 2.3979785989628817
Validation loss: 2.4074378201486875

Epoch: 246| Step: 0
Training loss: 1.5462048552822136
Validation loss: 2.402119882102057

Epoch: 5| Step: 1
Training loss: 1.7489791344804262
Validation loss: 2.400045907036989

Epoch: 5| Step: 2
Training loss: 2.2266595116612646
Validation loss: 2.3942474559467395

Epoch: 5| Step: 3
Training loss: 1.8164905815646852
Validation loss: 2.4056709433417542

Epoch: 5| Step: 4
Training loss: 2.125158864983043
Validation loss: 2.4147340810948394

Epoch: 5| Step: 5
Training loss: 2.2340832499784944
Validation loss: 2.432735787191435

Epoch: 5| Step: 6
Training loss: 2.6658112723592504
Validation loss: 2.4292680546928276

Epoch: 5| Step: 7
Training loss: 1.8090610106530107
Validation loss: 2.4272233955255293

Epoch: 5| Step: 8
Training loss: 1.9114560812400696
Validation loss: 2.4285215622976937

Epoch: 5| Step: 9
Training loss: 2.3905365372789587
Validation loss: 2.4102829546369917

Epoch: 5| Step: 10
Training loss: 2.089933076179459
Validation loss: 2.4288078883923427

Epoch: 247| Step: 0
Training loss: 2.207896375311525
Validation loss: 2.4404698241924954

Epoch: 5| Step: 1
Training loss: 2.0872325520308763
Validation loss: 2.4225766269479068

Epoch: 5| Step: 2
Training loss: 1.910158434283484
Validation loss: 2.4203416546539187

Epoch: 5| Step: 3
Training loss: 1.8772423369550597
Validation loss: 2.4266300157449696

Epoch: 5| Step: 4
Training loss: 1.6855601004107084
Validation loss: 2.4228478421864925

Epoch: 5| Step: 5
Training loss: 2.005510725199539
Validation loss: 2.406817448815707

Epoch: 5| Step: 6
Training loss: 2.116536057815506
Validation loss: 2.3994487375455895

Epoch: 5| Step: 7
Training loss: 2.345729144839034
Validation loss: 2.388718695045832

Epoch: 5| Step: 8
Training loss: 2.3107933757788066
Validation loss: 2.376528832370124

Epoch: 5| Step: 9
Training loss: 2.3482003240051124
Validation loss: 2.354409645152522

Epoch: 5| Step: 10
Training loss: 1.6980686548774304
Validation loss: 2.36013998315684

Epoch: 248| Step: 0
Training loss: 2.172593032372599
Validation loss: 2.359244207375102

Epoch: 5| Step: 1
Training loss: 2.1006355368461445
Validation loss: 2.3872727314980073

Epoch: 5| Step: 2
Training loss: 1.5690828129909007
Validation loss: 2.402011993361731

Epoch: 5| Step: 3
Training loss: 1.8789241417173737
Validation loss: 2.423064548330065

Epoch: 5| Step: 4
Training loss: 2.4610926019141446
Validation loss: 2.4384451803962492

Epoch: 5| Step: 5
Training loss: 2.286199035076478
Validation loss: 2.4036289936605857

Epoch: 5| Step: 6
Training loss: 1.5137167647073555
Validation loss: 2.4245541713641843

Epoch: 5| Step: 7
Training loss: 2.087104385258634
Validation loss: 2.4151679502454493

Epoch: 5| Step: 8
Training loss: 1.8572120588111183
Validation loss: 2.41572968016933

Epoch: 5| Step: 9
Training loss: 1.7600927186515267
Validation loss: 2.4356047964224503

Epoch: 5| Step: 10
Training loss: 2.3685275776090884
Validation loss: 2.431975400490476

Epoch: 249| Step: 0
Training loss: 1.714530759849746
Validation loss: 2.4039183881080746

Epoch: 5| Step: 1
Training loss: 2.312049100064092
Validation loss: 2.355248905864007

Epoch: 5| Step: 2
Training loss: 2.125857685008952
Validation loss: 2.3537591277807

Epoch: 5| Step: 3
Training loss: 2.08638115783152
Validation loss: 2.345373425755346

Epoch: 5| Step: 4
Training loss: 1.4414523977940448
Validation loss: 2.3573894157811814

Epoch: 5| Step: 5
Training loss: 1.8785023721127108
Validation loss: 2.3661735954634313

Epoch: 5| Step: 6
Training loss: 1.9369041387994812
Validation loss: 2.384854384557184

Epoch: 5| Step: 7
Training loss: 2.1932561073892165
Validation loss: 2.389451155543815

Epoch: 5| Step: 8
Training loss: 2.128799183804292
Validation loss: 2.4385290263966684

Epoch: 5| Step: 9
Training loss: 2.1793999157491344
Validation loss: 2.457243237257729

Epoch: 5| Step: 10
Training loss: 2.139684651571957
Validation loss: 2.4793694860342668

Epoch: 250| Step: 0
Training loss: 2.2089057996082513
Validation loss: 2.4793982286923164

Epoch: 5| Step: 1
Training loss: 2.5163472720284106
Validation loss: 2.4542551671060444

Epoch: 5| Step: 2
Training loss: 1.9135630676147086
Validation loss: 2.4181891491038465

Epoch: 5| Step: 3
Training loss: 1.7535569962592144
Validation loss: 2.4047970720846163

Epoch: 5| Step: 4
Training loss: 1.6803139161694038
Validation loss: 2.38745648649877

Epoch: 5| Step: 5
Training loss: 2.2815808618023756
Validation loss: 2.383367004374683

Epoch: 5| Step: 6
Training loss: 2.1625269320359934
Validation loss: 2.3608402037264753

Epoch: 5| Step: 7
Training loss: 1.5803386911911423
Validation loss: 2.367450555592887

Epoch: 5| Step: 8
Training loss: 2.120575506080778
Validation loss: 2.34650259395362

Epoch: 5| Step: 9
Training loss: 1.4675075064212066
Validation loss: 2.3451582486424525

Epoch: 5| Step: 10
Training loss: 1.9367590071790135
Validation loss: 2.3408200704632205

Epoch: 251| Step: 0
Training loss: 2.183690268579066
Validation loss: 2.3351345731168753

Epoch: 5| Step: 1
Training loss: 2.424286361769394
Validation loss: 2.3784839128538744

Epoch: 5| Step: 2
Training loss: 2.0063178885789106
Validation loss: 2.3952136477339874

Epoch: 5| Step: 3
Training loss: 1.5949141794393238
Validation loss: 2.419826433747076

Epoch: 5| Step: 4
Training loss: 1.43279940766621
Validation loss: 2.41495953547822

Epoch: 5| Step: 5
Training loss: 1.9738278979149013
Validation loss: 2.4213815695190277

Epoch: 5| Step: 6
Training loss: 1.7727257733016353
Validation loss: 2.4462003207798952

Epoch: 5| Step: 7
Training loss: 1.7957800804910393
Validation loss: 2.4308325272673525

Epoch: 5| Step: 8
Training loss: 2.1830868482382195
Validation loss: 2.4212260932666885

Epoch: 5| Step: 9
Training loss: 1.9366224824370368
Validation loss: 2.400601274275865

Epoch: 5| Step: 10
Training loss: 2.104393396028077
Validation loss: 2.371170526271655

Epoch: 252| Step: 0
Training loss: 2.2400053351202507
Validation loss: 2.337572697071698

Epoch: 5| Step: 1
Training loss: 1.7729441086662105
Validation loss: 2.3201166902229824

Epoch: 5| Step: 2
Training loss: 2.595268540351712
Validation loss: 2.324848199908703

Epoch: 5| Step: 3
Training loss: 1.9214431153373484
Validation loss: 2.316819423671531

Epoch: 5| Step: 4
Training loss: 1.9319682986025988
Validation loss: 2.318042448894028

Epoch: 5| Step: 5
Training loss: 1.8802496217824411
Validation loss: 2.3285440801544475

Epoch: 5| Step: 6
Training loss: 1.6214921209030386
Validation loss: 2.3217914666140675

Epoch: 5| Step: 7
Training loss: 1.8608435593475106
Validation loss: 2.3376926697401808

Epoch: 5| Step: 8
Training loss: 2.0757255756347557
Validation loss: 2.360971697343443

Epoch: 5| Step: 9
Training loss: 1.8889245196640758
Validation loss: 2.3931905470699775

Epoch: 5| Step: 10
Training loss: 1.415817267895747
Validation loss: 2.435191360884753

Epoch: 253| Step: 0
Training loss: 1.6933499416277755
Validation loss: 2.4722272632371274

Epoch: 5| Step: 1
Training loss: 2.1897769521758974
Validation loss: 2.5097496226602463

Epoch: 5| Step: 2
Training loss: 2.235239248591435
Validation loss: 2.501673280989858

Epoch: 5| Step: 3
Training loss: 1.7261706982185823
Validation loss: 2.4648538034161027

Epoch: 5| Step: 4
Training loss: 1.794088375594003
Validation loss: 2.421886399341845

Epoch: 5| Step: 5
Training loss: 2.33690141163521
Validation loss: 2.3967717120450986

Epoch: 5| Step: 6
Training loss: 1.9604671567711407
Validation loss: 2.3818091787183175

Epoch: 5| Step: 7
Training loss: 2.040459749736664
Validation loss: 2.3588648723169103

Epoch: 5| Step: 8
Training loss: 1.447621413757188
Validation loss: 2.3626145845895565

Epoch: 5| Step: 9
Training loss: 1.6558614311016515
Validation loss: 2.348139462688701

Epoch: 5| Step: 10
Training loss: 2.229169744566697
Validation loss: 2.3510834310816664

Epoch: 254| Step: 0
Training loss: 1.9694671535692179
Validation loss: 2.3499372264460825

Epoch: 5| Step: 1
Training loss: 2.0075512430342104
Validation loss: 2.3577457575945466

Epoch: 5| Step: 2
Training loss: 1.2567877059965342
Validation loss: 2.373703328459472

Epoch: 5| Step: 3
Training loss: 2.295258037214435
Validation loss: 2.3894257512975243

Epoch: 5| Step: 4
Training loss: 1.544537869074082
Validation loss: 2.379224242634051

Epoch: 5| Step: 5
Training loss: 1.9037585627362652
Validation loss: 2.381585338630005

Epoch: 5| Step: 6
Training loss: 2.0043706820482803
Validation loss: 2.3804218749968293

Epoch: 5| Step: 7
Training loss: 2.0433315443660667
Validation loss: 2.40217852734203

Epoch: 5| Step: 8
Training loss: 1.87478318550313
Validation loss: 2.386333958933519

Epoch: 5| Step: 9
Training loss: 1.9340267428706026
Validation loss: 2.407620332119986

Epoch: 5| Step: 10
Training loss: 2.0775969558658267
Validation loss: 2.398655900614351

Epoch: 255| Step: 0
Training loss: 1.988066056453147
Validation loss: 2.4065355244169413

Epoch: 5| Step: 1
Training loss: 1.5772497941744252
Validation loss: 2.4056566122288263

Epoch: 5| Step: 2
Training loss: 2.0269229283107957
Validation loss: 2.4107094300383896

Epoch: 5| Step: 3
Training loss: 2.1648854367645383
Validation loss: 2.392220157098625

Epoch: 5| Step: 4
Training loss: 1.7551450708536378
Validation loss: 2.4148549848181786

Epoch: 5| Step: 5
Training loss: 1.4623113689878828
Validation loss: 2.41262164871055

Epoch: 5| Step: 6
Training loss: 2.159618124407142
Validation loss: 2.446066942242732

Epoch: 5| Step: 7
Training loss: 2.2209795643065107
Validation loss: 2.4228584433719598

Epoch: 5| Step: 8
Training loss: 2.012427344106519
Validation loss: 2.3889689137173904

Epoch: 5| Step: 9
Training loss: 1.8355792406227922
Validation loss: 2.3766657779235563

Epoch: 5| Step: 10
Training loss: 1.4825704748890338
Validation loss: 2.380127598713209

Epoch: 256| Step: 0
Training loss: 2.087909352260494
Validation loss: 2.362731032092736

Epoch: 5| Step: 1
Training loss: 2.2975597788076865
Validation loss: 2.3703950312410402

Epoch: 5| Step: 2
Training loss: 2.0565979637075817
Validation loss: 2.3652523023799943

Epoch: 5| Step: 3
Training loss: 1.5779755776549702
Validation loss: 2.393224392655335

Epoch: 5| Step: 4
Training loss: 1.9504307589001133
Validation loss: 2.4262754446067594

Epoch: 5| Step: 5
Training loss: 1.9265843200685466
Validation loss: 2.4416237806315317

Epoch: 5| Step: 6
Training loss: 1.5368105296124217
Validation loss: 2.4418198637370905

Epoch: 5| Step: 7
Training loss: 1.9319122709728813
Validation loss: 2.4438000182963378

Epoch: 5| Step: 8
Training loss: 2.124758313964492
Validation loss: 2.45997024176982

Epoch: 5| Step: 9
Training loss: 1.4284271354691511
Validation loss: 2.431607403219167

Epoch: 5| Step: 10
Training loss: 1.747955626764715
Validation loss: 2.4243166425944196

Epoch: 257| Step: 0
Training loss: 1.5462970617313145
Validation loss: 2.4026559795719993

Epoch: 5| Step: 1
Training loss: 1.6148600761573793
Validation loss: 2.358922704089506

Epoch: 5| Step: 2
Training loss: 2.0059828678437817
Validation loss: 2.3467149330928

Epoch: 5| Step: 3
Training loss: 1.9474064843933208
Validation loss: 2.334656134611514

Epoch: 5| Step: 4
Training loss: 2.074398629242738
Validation loss: 2.34933417068178

Epoch: 5| Step: 5
Training loss: 2.1148604663967503
Validation loss: 2.3741273242802277

Epoch: 5| Step: 6
Training loss: 1.6136938865118888
Validation loss: 2.4263794418877254

Epoch: 5| Step: 7
Training loss: 2.041384956491151
Validation loss: 2.472708288327925

Epoch: 5| Step: 8
Training loss: 1.9020809172175905
Validation loss: 2.4731078434126963

Epoch: 5| Step: 9
Training loss: 1.900019234007806
Validation loss: 2.449886505690913

Epoch: 5| Step: 10
Training loss: 1.9656794384330178
Validation loss: 2.411209545078197

Epoch: 258| Step: 0
Training loss: 2.323258709778628
Validation loss: 2.3679258812072965

Epoch: 5| Step: 1
Training loss: 1.590899742396247
Validation loss: 2.367470920224887

Epoch: 5| Step: 2
Training loss: 2.0673339146024117
Validation loss: 2.370546781054403

Epoch: 5| Step: 3
Training loss: 1.8611393739758995
Validation loss: 2.3681909884516403

Epoch: 5| Step: 4
Training loss: 2.0780464100138936
Validation loss: 2.3608850608179317

Epoch: 5| Step: 5
Training loss: 1.8849729433824602
Validation loss: 2.346608427253834

Epoch: 5| Step: 6
Training loss: 1.7542335527705584
Validation loss: 2.331673419182678

Epoch: 5| Step: 7
Training loss: 1.8908235429914106
Validation loss: 2.334655072767321

Epoch: 5| Step: 8
Training loss: 1.5596267221815368
Validation loss: 2.371702395148633

Epoch: 5| Step: 9
Training loss: 1.6618335104960622
Validation loss: 2.4179384744984453

Epoch: 5| Step: 10
Training loss: 2.1178800569239886
Validation loss: 2.4051530999003554

Epoch: 259| Step: 0
Training loss: 1.790974490692778
Validation loss: 2.4118402829261534

Epoch: 5| Step: 1
Training loss: 1.8090042735903877
Validation loss: 2.4131151403254325

Epoch: 5| Step: 2
Training loss: 1.95191093858802
Validation loss: 2.40523949020354

Epoch: 5| Step: 3
Training loss: 1.6749188531606096
Validation loss: 2.392120414785551

Epoch: 5| Step: 4
Training loss: 1.6441109090645107
Validation loss: 2.400451747488858

Epoch: 5| Step: 5
Training loss: 2.1599810841403206
Validation loss: 2.377684800080759

Epoch: 5| Step: 6
Training loss: 1.6662173221757803
Validation loss: 2.4059932733196803

Epoch: 5| Step: 7
Training loss: 2.0569801448815124
Validation loss: 2.3903437403479577

Epoch: 5| Step: 8
Training loss: 1.623644116409473
Validation loss: 2.381872515205887

Epoch: 5| Step: 9
Training loss: 1.816235999875807
Validation loss: 2.4049709017007252

Epoch: 5| Step: 10
Training loss: 1.8354336960428672
Validation loss: 2.4186696827704584

Epoch: 260| Step: 0
Training loss: 1.6451303292448949
Validation loss: 2.4298854684317304

Epoch: 5| Step: 1
Training loss: 1.8379825970362333
Validation loss: 2.421121622618093

Epoch: 5| Step: 2
Training loss: 1.7268901531315377
Validation loss: 2.3691371557935677

Epoch: 5| Step: 3
Training loss: 2.0785612637922526
Validation loss: 2.3497820252803825

Epoch: 5| Step: 4
Training loss: 1.5824728267078323
Validation loss: 2.3367298239523038

Epoch: 5| Step: 5
Training loss: 2.0260363058168016
Validation loss: 2.3241155400001774

Epoch: 5| Step: 6
Training loss: 1.7939486350421736
Validation loss: 2.319184891467587

Epoch: 5| Step: 7
Training loss: 2.072138718612039
Validation loss: 2.3305111307652693

Epoch: 5| Step: 8
Training loss: 1.690764836364838
Validation loss: 2.3328501223719726

Epoch: 5| Step: 9
Training loss: 1.7915840203792417
Validation loss: 2.341560128271788

Epoch: 5| Step: 10
Training loss: 1.3668716501788836
Validation loss: 2.3419119121162795

Epoch: 261| Step: 0
Training loss: 2.029548049376758
Validation loss: 2.369712188552672

Epoch: 5| Step: 1
Training loss: 1.7265347439705496
Validation loss: 2.3899169212116083

Epoch: 5| Step: 2
Training loss: 1.707140886290804
Validation loss: 2.4037670914211575

Epoch: 5| Step: 3
Training loss: 1.196984013704837
Validation loss: 2.4336604896624316

Epoch: 5| Step: 4
Training loss: 1.8738698732434345
Validation loss: 2.4194534045482925

Epoch: 5| Step: 5
Training loss: 1.9552777442812297
Validation loss: 2.423081707169949

Epoch: 5| Step: 6
Training loss: 1.8024705753755328
Validation loss: 2.432224225755734

Epoch: 5| Step: 7
Training loss: 1.2800921814478226
Validation loss: 2.4405044737035158

Epoch: 5| Step: 8
Training loss: 2.115506000637415
Validation loss: 2.450517723441838

Epoch: 5| Step: 9
Training loss: 1.9539558779558066
Validation loss: 2.408204307709223

Epoch: 5| Step: 10
Training loss: 1.6554222917721235
Validation loss: 2.39783649851718

Epoch: 262| Step: 0
Training loss: 1.7679505013920256
Validation loss: 2.3574755239498755

Epoch: 5| Step: 1
Training loss: 2.017407361140757
Validation loss: 2.3348062835221968

Epoch: 5| Step: 2
Training loss: 1.4610075908309643
Validation loss: 2.3088064293390334

Epoch: 5| Step: 3
Training loss: 1.7222552535605018
Validation loss: 2.2925921276499253

Epoch: 5| Step: 4
Training loss: 1.7052798157353015
Validation loss: 2.2934331251617435

Epoch: 5| Step: 5
Training loss: 1.6425898094532765
Validation loss: 2.2877232142820554

Epoch: 5| Step: 6
Training loss: 1.5738893074268185
Validation loss: 2.300088806765196

Epoch: 5| Step: 7
Training loss: 1.8447571929117286
Validation loss: 2.288894258514186

Epoch: 5| Step: 8
Training loss: 1.9249794550208055
Validation loss: 2.2992694788720702

Epoch: 5| Step: 9
Training loss: 1.5533428415463144
Validation loss: 2.317671928566906

Epoch: 5| Step: 10
Training loss: 2.1722701557114235
Validation loss: 2.343502733319894

Epoch: 263| Step: 0
Training loss: 1.988483051483924
Validation loss: 2.359385183369827

Epoch: 5| Step: 1
Training loss: 1.7341790303356748
Validation loss: 2.3881194708391087

Epoch: 5| Step: 2
Training loss: 1.691614151438623
Validation loss: 2.4008126568160084

Epoch: 5| Step: 3
Training loss: 1.771761064045151
Validation loss: 2.4281446062643317

Epoch: 5| Step: 4
Training loss: 1.4648780106670536
Validation loss: 2.433845707788189

Epoch: 5| Step: 5
Training loss: 1.766976236115583
Validation loss: 2.438219566351041

Epoch: 5| Step: 6
Training loss: 1.6700550762391397
Validation loss: 2.416899181576482

Epoch: 5| Step: 7
Training loss: 2.106085805407455
Validation loss: 2.392030988677534

Epoch: 5| Step: 8
Training loss: 1.7310333364263837
Validation loss: 2.376370144334476

Epoch: 5| Step: 9
Training loss: 1.7488577384563104
Validation loss: 2.3562736378829916

Epoch: 5| Step: 10
Training loss: 1.4316263861683203
Validation loss: 2.342686681696125

Epoch: 264| Step: 0
Training loss: 1.9831444236268216
Validation loss: 2.325148050175087

Epoch: 5| Step: 1
Training loss: 2.103843273830897
Validation loss: 2.3364671553968397

Epoch: 5| Step: 2
Training loss: 1.2897113900806159
Validation loss: 2.326473495184849

Epoch: 5| Step: 3
Training loss: 0.9891871947740385
Validation loss: 2.348192568221688

Epoch: 5| Step: 4
Training loss: 1.5845414956396089
Validation loss: 2.3470023938311293

Epoch: 5| Step: 5
Training loss: 1.7570252414598935
Validation loss: 2.361757531632493

Epoch: 5| Step: 6
Training loss: 1.593520952109131
Validation loss: 2.403075319888746

Epoch: 5| Step: 7
Training loss: 1.5392327383937476
Validation loss: 2.421634886843594

Epoch: 5| Step: 8
Training loss: 1.8649456020327402
Validation loss: 2.437400974673854

Epoch: 5| Step: 9
Training loss: 1.9722639543598404
Validation loss: 2.3908074003958064

Epoch: 5| Step: 10
Training loss: 2.1055026078200108
Validation loss: 2.369043660065424

Epoch: 265| Step: 0
Training loss: 2.114605331932857
Validation loss: 2.3671462572116004

Epoch: 5| Step: 1
Training loss: 1.8134919444773738
Validation loss: 2.369005116574363

Epoch: 5| Step: 2
Training loss: 1.5832559248757525
Validation loss: 2.3339768740371745

Epoch: 5| Step: 3
Training loss: 1.3666774125180694
Validation loss: 2.3421984825108564

Epoch: 5| Step: 4
Training loss: 1.8961658465648075
Validation loss: 2.336436049831334

Epoch: 5| Step: 5
Training loss: 1.2409048115621246
Validation loss: 2.32792025101613

Epoch: 5| Step: 6
Training loss: 1.5608927280240745
Validation loss: 2.314724265158545

Epoch: 5| Step: 7
Training loss: 1.6209998413829503
Validation loss: 2.3158152406530226

Epoch: 5| Step: 8
Training loss: 2.203207352634425
Validation loss: 2.3118601908610317

Epoch: 5| Step: 9
Training loss: 1.3892668188675448
Validation loss: 2.326952443875227

Epoch: 5| Step: 10
Training loss: 1.738180984862887
Validation loss: 2.3448983423475998

Epoch: 266| Step: 0
Training loss: 1.7710313648869147
Validation loss: 2.3666245717030305

Epoch: 5| Step: 1
Training loss: 1.926473249485831
Validation loss: 2.3987365100167515

Epoch: 5| Step: 2
Training loss: 1.5242539785469917
Validation loss: 2.4179233927995796

Epoch: 5| Step: 3
Training loss: 2.0096310940305036
Validation loss: 2.42614188576768

Epoch: 5| Step: 4
Training loss: 1.4119037990326317
Validation loss: 2.4202958679189135

Epoch: 5| Step: 5
Training loss: 1.6079805128805096
Validation loss: 2.4189186515834034

Epoch: 5| Step: 6
Training loss: 1.5531417600161077
Validation loss: 2.4058656762474397

Epoch: 5| Step: 7
Training loss: 1.9085379456127536
Validation loss: 2.3673328198154655

Epoch: 5| Step: 8
Training loss: 1.65255642146804
Validation loss: 2.3814943440966383

Epoch: 5| Step: 9
Training loss: 1.8117770364522434
Validation loss: 2.349652385463772

Epoch: 5| Step: 10
Training loss: 1.3243068789523458
Validation loss: 2.344575047907996

Epoch: 267| Step: 0
Training loss: 1.7883129298719211
Validation loss: 2.3559516399920555

Epoch: 5| Step: 1
Training loss: 1.9481455078612082
Validation loss: 2.3649580550487648

Epoch: 5| Step: 2
Training loss: 1.4194155371389778
Validation loss: 2.3950302540070556

Epoch: 5| Step: 3
Training loss: 1.1865006307285977
Validation loss: 2.3988647336952864

Epoch: 5| Step: 4
Training loss: 1.7156277126714665
Validation loss: 2.433671072189427

Epoch: 5| Step: 5
Training loss: 1.9479955837426854
Validation loss: 2.402119068330717

Epoch: 5| Step: 6
Training loss: 1.90712949131731
Validation loss: 2.3718253756774867

Epoch: 5| Step: 7
Training loss: 1.1914629813273314
Validation loss: 2.3481902417000153

Epoch: 5| Step: 8
Training loss: 1.6136872378790525
Validation loss: 2.342973857604998

Epoch: 5| Step: 9
Training loss: 1.5953911951515267
Validation loss: 2.3588417068235805

Epoch: 5| Step: 10
Training loss: 2.0853771357135233
Validation loss: 2.3618299863130807

Epoch: 268| Step: 0
Training loss: 1.6914235173636858
Validation loss: 2.3769934318804764

Epoch: 5| Step: 1
Training loss: 1.423182630280914
Validation loss: 2.3901808849837187

Epoch: 5| Step: 2
Training loss: 1.476166364220909
Validation loss: 2.408818791913225

Epoch: 5| Step: 3
Training loss: 1.2300010640054457
Validation loss: 2.4226365796361335

Epoch: 5| Step: 4
Training loss: 1.7101993449058523
Validation loss: 2.445922399131384

Epoch: 5| Step: 5
Training loss: 1.6257656934398081
Validation loss: 2.495682413082159

Epoch: 5| Step: 6
Training loss: 1.4718368233753205
Validation loss: 2.4785400757645832

Epoch: 5| Step: 7
Training loss: 2.0541790815472156
Validation loss: 2.471988029566884

Epoch: 5| Step: 8
Training loss: 2.0481016254691835
Validation loss: 2.4288639935889433

Epoch: 5| Step: 9
Training loss: 1.7187320361499092
Validation loss: 2.395714341606534

Epoch: 5| Step: 10
Training loss: 1.7533970286883154
Validation loss: 2.368853596457619

Epoch: 269| Step: 0
Training loss: 1.3637056755743928
Validation loss: 2.3283599384804465

Epoch: 5| Step: 1
Training loss: 1.2760649179429264
Validation loss: 2.3246044257744356

Epoch: 5| Step: 2
Training loss: 1.6661238104161833
Validation loss: 2.3065437284803214

Epoch: 5| Step: 3
Training loss: 1.793650179753826
Validation loss: 2.3181673184226654

Epoch: 5| Step: 4
Training loss: 1.5967983190112927
Validation loss: 2.320222710003607

Epoch: 5| Step: 5
Training loss: 1.827238601588476
Validation loss: 2.3102638033019565

Epoch: 5| Step: 6
Training loss: 1.7368217599017854
Validation loss: 2.330634125580754

Epoch: 5| Step: 7
Training loss: 1.8408278245039034
Validation loss: 2.358833846915087

Epoch: 5| Step: 8
Training loss: 1.4801732072771956
Validation loss: 2.363995858051619

Epoch: 5| Step: 9
Training loss: 1.8559745661291827
Validation loss: 2.3677625368886295

Epoch: 5| Step: 10
Training loss: 1.749969345914209
Validation loss: 2.4052942458367377

Epoch: 270| Step: 0
Training loss: 1.4335848524768593
Validation loss: 2.4177132830593644

Epoch: 5| Step: 1
Training loss: 1.6160361204076343
Validation loss: 2.41751596472703

Epoch: 5| Step: 2
Training loss: 1.3921633152086605
Validation loss: 2.458088506149234

Epoch: 5| Step: 3
Training loss: 1.6834397389361808
Validation loss: 2.4466944764116962

Epoch: 5| Step: 4
Training loss: 1.1231527527366523
Validation loss: 2.4334442003705594

Epoch: 5| Step: 5
Training loss: 1.78998019074289
Validation loss: 2.4210787159744487

Epoch: 5| Step: 6
Training loss: 1.8010281540419104
Validation loss: 2.4297793221681965

Epoch: 5| Step: 7
Training loss: 1.7753082356991794
Validation loss: 2.4026797778843836

Epoch: 5| Step: 8
Training loss: 1.3832744107087556
Validation loss: 2.375427969610085

Epoch: 5| Step: 9
Training loss: 1.9888918675353597
Validation loss: 2.375992531409164

Epoch: 5| Step: 10
Training loss: 1.8087015140469953
Validation loss: 2.3514262301540576

Epoch: 271| Step: 0
Training loss: 1.508506970746982
Validation loss: 2.349755778655569

Epoch: 5| Step: 1
Training loss: 1.576095938478238
Validation loss: 2.338597450730198

Epoch: 5| Step: 2
Training loss: 1.6953264227088871
Validation loss: 2.3415641386781374

Epoch: 5| Step: 3
Training loss: 1.5797314917893872
Validation loss: 2.3280632746986574

Epoch: 5| Step: 4
Training loss: 1.6161011073662275
Validation loss: 2.341483504433128

Epoch: 5| Step: 5
Training loss: 1.4710384964252594
Validation loss: 2.3652387549727947

Epoch: 5| Step: 6
Training loss: 1.4353664155015882
Validation loss: 2.3650225669177702

Epoch: 5| Step: 7
Training loss: 1.9026396284358686
Validation loss: 2.3701057414369724

Epoch: 5| Step: 8
Training loss: 1.4312075679436098
Validation loss: 2.3876989587428454

Epoch: 5| Step: 9
Training loss: 1.7093081445539098
Validation loss: 2.3659366029160163

Epoch: 5| Step: 10
Training loss: 1.8619513734108126
Validation loss: 2.399267957889338

Epoch: 272| Step: 0
Training loss: 1.9008789689627206
Validation loss: 2.3989745454008555

Epoch: 5| Step: 1
Training loss: 1.7374960508233068
Validation loss: 2.3873623739626577

Epoch: 5| Step: 2
Training loss: 1.6495409702695039
Validation loss: 2.3806376268101315

Epoch: 5| Step: 3
Training loss: 1.5355165170460048
Validation loss: 2.3835789411261317

Epoch: 5| Step: 4
Training loss: 1.6037286763249092
Validation loss: 2.367750549986701

Epoch: 5| Step: 5
Training loss: 1.513923712669163
Validation loss: 2.3603305241338495

Epoch: 5| Step: 6
Training loss: 1.7288419426267543
Validation loss: 2.368454440241419

Epoch: 5| Step: 7
Training loss: 1.4553665592112979
Validation loss: 2.356449725128049

Epoch: 5| Step: 8
Training loss: 1.689073747143983
Validation loss: 2.3703827245402014

Epoch: 5| Step: 9
Training loss: 1.4619337143019917
Validation loss: 2.370804564918925

Epoch: 5| Step: 10
Training loss: 1.1878871788469156
Validation loss: 2.3623260750886534

Epoch: 273| Step: 0
Training loss: 1.5324686611636567
Validation loss: 2.388867007380543

Epoch: 5| Step: 1
Training loss: 1.9548964744728483
Validation loss: 2.3780444450016702

Epoch: 5| Step: 2
Training loss: 1.5390989037870269
Validation loss: 2.371107772658912

Epoch: 5| Step: 3
Training loss: 1.4463725558540437
Validation loss: 2.358946224162436

Epoch: 5| Step: 4
Training loss: 1.6606101459015425
Validation loss: 2.3485665383525522

Epoch: 5| Step: 5
Training loss: 1.859152195508109
Validation loss: 2.341037698515804

Epoch: 5| Step: 6
Training loss: 1.1504186034240962
Validation loss: 2.351831570868383

Epoch: 5| Step: 7
Training loss: 1.5583247284813144
Validation loss: 2.3648112526337144

Epoch: 5| Step: 8
Training loss: 1.389286382803194
Validation loss: 2.368338107449875

Epoch: 5| Step: 9
Training loss: 1.973056322074029
Validation loss: 2.386885881635143

Epoch: 5| Step: 10
Training loss: 1.245444197254185
Validation loss: 2.372863298434854

Epoch: 274| Step: 0
Training loss: 1.4393241752102284
Validation loss: 2.3796675573010577

Epoch: 5| Step: 1
Training loss: 1.3838346335176663
Validation loss: 2.362056239560521

Epoch: 5| Step: 2
Training loss: 1.2973445823507799
Validation loss: 2.3579905609103644

Epoch: 5| Step: 3
Training loss: 1.3922323731320192
Validation loss: 2.324131312612351

Epoch: 5| Step: 4
Training loss: 1.479841597689124
Validation loss: 2.334160105259237

Epoch: 5| Step: 5
Training loss: 2.094400219516437
Validation loss: 2.365730119951198

Epoch: 5| Step: 6
Training loss: 1.4357847678365276
Validation loss: 2.381679881810045

Epoch: 5| Step: 7
Training loss: 1.5617666430855903
Validation loss: 2.404922996806867

Epoch: 5| Step: 8
Training loss: 1.811182529832946
Validation loss: 2.4334128869010074

Epoch: 5| Step: 9
Training loss: 1.7254336710373466
Validation loss: 2.4554335482220853

Epoch: 5| Step: 10
Training loss: 1.62555259698816
Validation loss: 2.4334166374168684

Epoch: 275| Step: 0
Training loss: 1.6708749650190515
Validation loss: 2.4301905242374415

Epoch: 5| Step: 1
Training loss: 1.551876114020253
Validation loss: 2.4027508758591773

Epoch: 5| Step: 2
Training loss: 2.00855926994484
Validation loss: 2.388279837952023

Epoch: 5| Step: 3
Training loss: 1.5092171564754293
Validation loss: 2.3751975205672697

Epoch: 5| Step: 4
Training loss: 1.5938111835778117
Validation loss: 2.3499161079336988

Epoch: 5| Step: 5
Training loss: 1.5628207831114616
Validation loss: 2.3218033926684902

Epoch: 5| Step: 6
Training loss: 1.9550082473385797
Validation loss: 2.337747997486397

Epoch: 5| Step: 7
Training loss: 1.177611286063637
Validation loss: 2.3403569337909818

Epoch: 5| Step: 8
Training loss: 1.2296268549970382
Validation loss: 2.3494548788923115

Epoch: 5| Step: 9
Training loss: 1.4495210152425388
Validation loss: 2.3742099099742977

Epoch: 5| Step: 10
Training loss: 1.312743028211415
Validation loss: 2.383103611197905

Epoch: 276| Step: 0
Training loss: 1.3343789451237056
Validation loss: 2.3606286670934424

Epoch: 5| Step: 1
Training loss: 1.7468695570531678
Validation loss: 2.3570398402310477

Epoch: 5| Step: 2
Training loss: 1.8281857081057558
Validation loss: 2.3834535938295147

Epoch: 5| Step: 3
Training loss: 1.5112209239652135
Validation loss: 2.366263135838655

Epoch: 5| Step: 4
Training loss: 1.5576659383289788
Validation loss: 2.3735747937418017

Epoch: 5| Step: 5
Training loss: 1.4688024308606313
Validation loss: 2.3884401835638687

Epoch: 5| Step: 6
Training loss: 1.3495913558176615
Validation loss: 2.3936884184553517

Epoch: 5| Step: 7
Training loss: 1.3186459378229067
Validation loss: 2.4127625867148543

Epoch: 5| Step: 8
Training loss: 1.3523593824553
Validation loss: 2.390240227500097

Epoch: 5| Step: 9
Training loss: 1.8375996958357443
Validation loss: 2.3900946379284966

Epoch: 5| Step: 10
Training loss: 1.5793465145366694
Validation loss: 2.370211094616439

Epoch: 277| Step: 0
Training loss: 1.7974832583352094
Validation loss: 2.3610899305589985

Epoch: 5| Step: 1
Training loss: 1.460025441457569
Validation loss: 2.345890101205267

Epoch: 5| Step: 2
Training loss: 1.1375359288504514
Validation loss: 2.3322597823235043

Epoch: 5| Step: 3
Training loss: 1.195945621938366
Validation loss: 2.351375467874573

Epoch: 5| Step: 4
Training loss: 1.4811654980213003
Validation loss: 2.3382774247771154

Epoch: 5| Step: 5
Training loss: 1.3420252265577373
Validation loss: 2.35385645006654

Epoch: 5| Step: 6
Training loss: 1.4838977247195908
Validation loss: 2.361564560677828

Epoch: 5| Step: 7
Training loss: 1.989881190294852
Validation loss: 2.351604779215356

Epoch: 5| Step: 8
Training loss: 1.3197929217727262
Validation loss: 2.3576017954531525

Epoch: 5| Step: 9
Training loss: 1.621690534564357
Validation loss: 2.3546803623890447

Epoch: 5| Step: 10
Training loss: 1.8587084946042018
Validation loss: 2.32724776323332

Epoch: 278| Step: 0
Training loss: 1.3155964247982337
Validation loss: 2.33186115313695

Epoch: 5| Step: 1
Training loss: 1.5131713039493662
Validation loss: 2.3239371417562147

Epoch: 5| Step: 2
Training loss: 1.225690738407016
Validation loss: 2.3164851840927354

Epoch: 5| Step: 3
Training loss: 1.8447385174680448
Validation loss: 2.307556313461374

Epoch: 5| Step: 4
Training loss: 1.6072895649146106
Validation loss: 2.3213082138885928

Epoch: 5| Step: 5
Training loss: 1.4677570314182071
Validation loss: 2.3728558501480976

Epoch: 5| Step: 6
Training loss: 1.2853212569495163
Validation loss: 2.3828666811303267

Epoch: 5| Step: 7
Training loss: 2.074747194263672
Validation loss: 2.420945514278693

Epoch: 5| Step: 8
Training loss: 1.1640923515434924
Validation loss: 2.3938440382853283

Epoch: 5| Step: 9
Training loss: 1.550457899076225
Validation loss: 2.3794481615405267

Epoch: 5| Step: 10
Training loss: 1.6976819334444113
Validation loss: 2.337342749428028

Epoch: 279| Step: 0
Training loss: 1.4044958406076467
Validation loss: 2.316148633869965

Epoch: 5| Step: 1
Training loss: 1.9188085764539202
Validation loss: 2.30343996004484

Epoch: 5| Step: 2
Training loss: 1.4585014882098097
Validation loss: 2.2976328760447804

Epoch: 5| Step: 3
Training loss: 1.456454001614737
Validation loss: 2.2932209568608446

Epoch: 5| Step: 4
Training loss: 1.5913261232349931
Validation loss: 2.3055419194592117

Epoch: 5| Step: 5
Training loss: 1.3866560800924639
Validation loss: 2.3224329828137154

Epoch: 5| Step: 6
Training loss: 1.7810472071804617
Validation loss: 2.3481216142784773

Epoch: 5| Step: 7
Training loss: 1.2093777363275529
Validation loss: 2.3590788524657436

Epoch: 5| Step: 8
Training loss: 1.4807273618741017
Validation loss: 2.3872449565453406

Epoch: 5| Step: 9
Training loss: 1.2433271638207521
Validation loss: 2.3991194037554227

Epoch: 5| Step: 10
Training loss: 1.827395888779775
Validation loss: 2.4063052227159627

Epoch: 280| Step: 0
Training loss: 2.0554567934773758
Validation loss: 2.382828743709644

Epoch: 5| Step: 1
Training loss: 1.8853998411773165
Validation loss: 2.352704231967918

Epoch: 5| Step: 2
Training loss: 1.6859698952716953
Validation loss: 2.343805978851681

Epoch: 5| Step: 3
Training loss: 1.5081731335341149
Validation loss: 2.331614615768675

Epoch: 5| Step: 4
Training loss: 1.4505431506245274
Validation loss: 2.342872343732754

Epoch: 5| Step: 5
Training loss: 1.3302773481890378
Validation loss: 2.345208729281372

Epoch: 5| Step: 6
Training loss: 1.4447123338205727
Validation loss: 2.336084096546704

Epoch: 5| Step: 7
Training loss: 1.1014719175065435
Validation loss: 2.328422780059328

Epoch: 5| Step: 8
Training loss: 1.1906959792879408
Validation loss: 2.333737926263748

Epoch: 5| Step: 9
Training loss: 1.460858021578485
Validation loss: 2.3461961971084357

Epoch: 5| Step: 10
Training loss: 1.0910121438271025
Validation loss: 2.3405666595578776

Epoch: 281| Step: 0
Training loss: 1.0107538637233182
Validation loss: 2.346820976387403

Epoch: 5| Step: 1
Training loss: 1.2661534842549373
Validation loss: 2.334990185267736

Epoch: 5| Step: 2
Training loss: 1.4365372958574818
Validation loss: 2.355103117999535

Epoch: 5| Step: 3
Training loss: 1.5876635099293264
Validation loss: 2.3320810364174838

Epoch: 5| Step: 4
Training loss: 1.3190660631266795
Validation loss: 2.3273659725711906

Epoch: 5| Step: 5
Training loss: 1.4300218201686459
Validation loss: 2.3370388648984624

Epoch: 5| Step: 6
Training loss: 1.8753182459004079
Validation loss: 2.334598550554104

Epoch: 5| Step: 7
Training loss: 1.4534515506161199
Validation loss: 2.3529288104535837

Epoch: 5| Step: 8
Training loss: 1.7074982377541694
Validation loss: 2.370213863532764

Epoch: 5| Step: 9
Training loss: 1.3300623507691636
Validation loss: 2.3865526212449435

Epoch: 5| Step: 10
Training loss: 1.820060221335973
Validation loss: 2.4277734449153994

Epoch: 282| Step: 0
Training loss: 1.5534330127860754
Validation loss: 2.4215856267440072

Epoch: 5| Step: 1
Training loss: 1.4116607839888888
Validation loss: 2.425339541119418

Epoch: 5| Step: 2
Training loss: 1.8504498192642544
Validation loss: 2.4343924369168044

Epoch: 5| Step: 3
Training loss: 1.4427615361325075
Validation loss: 2.399609611918944

Epoch: 5| Step: 4
Training loss: 1.0750177914233936
Validation loss: 2.36700955641343

Epoch: 5| Step: 5
Training loss: 1.7184638045192069
Validation loss: 2.346166861756811

Epoch: 5| Step: 6
Training loss: 1.6281451818932313
Validation loss: 2.3416818366115684

Epoch: 5| Step: 7
Training loss: 1.4005414596898083
Validation loss: 2.332175595694496

Epoch: 5| Step: 8
Training loss: 1.4216224529968378
Validation loss: 2.3412521746784294

Epoch: 5| Step: 9
Training loss: 1.3264386410172877
Validation loss: 2.349348491264931

Epoch: 5| Step: 10
Training loss: 1.2190970391350895
Validation loss: 2.3610525770208532

Epoch: 283| Step: 0
Training loss: 1.3899550806650118
Validation loss: 2.370995768012462

Epoch: 5| Step: 1
Training loss: 1.15943428977862
Validation loss: 2.3823442369843706

Epoch: 5| Step: 2
Training loss: 1.2682736315233474
Validation loss: 2.3882130898074796

Epoch: 5| Step: 3
Training loss: 1.2400070823190306
Validation loss: 2.3986387423241786

Epoch: 5| Step: 4
Training loss: 1.5515921752181667
Validation loss: 2.4165896695876317

Epoch: 5| Step: 5
Training loss: 1.8427124336790788
Validation loss: 2.4017002794297646

Epoch: 5| Step: 6
Training loss: 1.4305112373046678
Validation loss: 2.3937467251349376

Epoch: 5| Step: 7
Training loss: 1.3978975415046697
Validation loss: 2.392164234678306

Epoch: 5| Step: 8
Training loss: 1.5702463012710055
Validation loss: 2.386610582893148

Epoch: 5| Step: 9
Training loss: 1.243820987765039
Validation loss: 2.3518226383439016

Epoch: 5| Step: 10
Training loss: 1.774568776685036
Validation loss: 2.3575940608112007

Epoch: 284| Step: 0
Training loss: 1.4885524392544591
Validation loss: 2.3385283189793635

Epoch: 5| Step: 1
Training loss: 1.206780071110684
Validation loss: 2.3468729587649446

Epoch: 5| Step: 2
Training loss: 1.0401841613132847
Validation loss: 2.330041212820957

Epoch: 5| Step: 3
Training loss: 1.6167587227846323
Validation loss: 2.3266887023666927

Epoch: 5| Step: 4
Training loss: 1.5321174033226328
Validation loss: 2.3456158452831497

Epoch: 5| Step: 5
Training loss: 1.6397794451924723
Validation loss: 2.344905696859819

Epoch: 5| Step: 6
Training loss: 1.2095563333677717
Validation loss: 2.3577941137926035

Epoch: 5| Step: 7
Training loss: 1.5245208800560281
Validation loss: 2.379295528625896

Epoch: 5| Step: 8
Training loss: 1.4977652273790527
Validation loss: 2.3847423133511256

Epoch: 5| Step: 9
Training loss: 1.5337110710644346
Validation loss: 2.4015948905460234

Epoch: 5| Step: 10
Training loss: 1.4294284940316393
Validation loss: 2.3957704888047013

Epoch: 285| Step: 0
Training loss: 1.8616865519477888
Validation loss: 2.4254409868181357

Epoch: 5| Step: 1
Training loss: 1.4936471560519997
Validation loss: 2.406154107009043

Epoch: 5| Step: 2
Training loss: 1.2392045198228834
Validation loss: 2.368111279255325

Epoch: 5| Step: 3
Training loss: 1.5231593733999482
Validation loss: 2.3640450504629196

Epoch: 5| Step: 4
Training loss: 1.5437911920032565
Validation loss: 2.344154223514584

Epoch: 5| Step: 5
Training loss: 1.5405178257184178
Validation loss: 2.3398527561934555

Epoch: 5| Step: 6
Training loss: 1.0540185573001055
Validation loss: 2.336062290920252

Epoch: 5| Step: 7
Training loss: 1.513292858293919
Validation loss: 2.337881767508448

Epoch: 5| Step: 8
Training loss: 1.134817887118785
Validation loss: 2.326106671393034

Epoch: 5| Step: 9
Training loss: 1.2922108898329232
Validation loss: 2.354029048592927

Epoch: 5| Step: 10
Training loss: 1.3756698363994526
Validation loss: 2.357059030152514

Epoch: 286| Step: 0
Training loss: 1.4200936361790928
Validation loss: 2.365379748695054

Epoch: 5| Step: 1
Training loss: 1.526359221278396
Validation loss: 2.3742258734893933

Epoch: 5| Step: 2
Training loss: 0.9076147326934302
Validation loss: 2.3901686683595944

Epoch: 5| Step: 3
Training loss: 1.4088735479219272
Validation loss: 2.3837393730687224

Epoch: 5| Step: 4
Training loss: 1.7388083355330213
Validation loss: 2.416604534180723

Epoch: 5| Step: 5
Training loss: 1.1956863317397677
Validation loss: 2.3820683875292685

Epoch: 5| Step: 6
Training loss: 1.3045436300114515
Validation loss: 2.329655871484681

Epoch: 5| Step: 7
Training loss: 1.6148078844344276
Validation loss: 2.3190897190421196

Epoch: 5| Step: 8
Training loss: 1.1570280395710546
Validation loss: 2.314499092675349

Epoch: 5| Step: 9
Training loss: 1.3744971482908905
Validation loss: 2.2960123988985823

Epoch: 5| Step: 10
Training loss: 1.750047206241968
Validation loss: 2.2816833891299573

Epoch: 287| Step: 0
Training loss: 1.4199014738314746
Validation loss: 2.2875609926972595

Epoch: 5| Step: 1
Training loss: 1.4052403958421158
Validation loss: 2.308930988387024

Epoch: 5| Step: 2
Training loss: 0.9700163286348835
Validation loss: 2.3329301520016816

Epoch: 5| Step: 3
Training loss: 1.5096750565341572
Validation loss: 2.3402013245761695

Epoch: 5| Step: 4
Training loss: 1.276041609575958
Validation loss: 2.3424302673979143

Epoch: 5| Step: 5
Training loss: 1.4911868749849293
Validation loss: 2.389533453018419

Epoch: 5| Step: 6
Training loss: 1.5232138445100798
Validation loss: 2.3839189063767936

Epoch: 5| Step: 7
Training loss: 1.5317587493900624
Validation loss: 2.3995482842166327

Epoch: 5| Step: 8
Training loss: 1.1083588580488415
Validation loss: 2.401134727175982

Epoch: 5| Step: 9
Training loss: 1.6689294554267902
Validation loss: 2.352659427024755

Epoch: 5| Step: 10
Training loss: 1.4609837652214348
Validation loss: 2.345817544343002

Epoch: 288| Step: 0
Training loss: 1.191563130040156
Validation loss: 2.3526659994069354

Epoch: 5| Step: 1
Training loss: 1.487101971242364
Validation loss: 2.321817492738984

Epoch: 5| Step: 2
Training loss: 1.3381330952584334
Validation loss: 2.3316876376831517

Epoch: 5| Step: 3
Training loss: 1.0408100547864885
Validation loss: 2.3383439839640747

Epoch: 5| Step: 4
Training loss: 1.3982897206227962
Validation loss: 2.352746955941311

Epoch: 5| Step: 5
Training loss: 1.6217405200985202
Validation loss: 2.358392711039598

Epoch: 5| Step: 6
Training loss: 1.2673560654817007
Validation loss: 2.3641947794348503

Epoch: 5| Step: 7
Training loss: 1.42557898353922
Validation loss: 2.3714605358812504

Epoch: 5| Step: 8
Training loss: 1.5999273373078282
Validation loss: 2.3892021204770666

Epoch: 5| Step: 9
Training loss: 1.6184618071067456
Validation loss: 2.3809973861393257

Epoch: 5| Step: 10
Training loss: 1.1911320605341476
Validation loss: 2.3836817454529706

Epoch: 289| Step: 0
Training loss: 1.3302227283357084
Validation loss: 2.372084111613902

Epoch: 5| Step: 1
Training loss: 1.567798404915377
Validation loss: 2.380006521269813

Epoch: 5| Step: 2
Training loss: 1.259538875547759
Validation loss: 2.3474437546542464

Epoch: 5| Step: 3
Training loss: 1.3223836330568692
Validation loss: 2.354083177256907

Epoch: 5| Step: 4
Training loss: 1.5032715089579711
Validation loss: 2.362377154699458

Epoch: 5| Step: 5
Training loss: 1.4649212219096859
Validation loss: 2.3522961347377285

Epoch: 5| Step: 6
Training loss: 1.1635831319489187
Validation loss: 2.3478392183907806

Epoch: 5| Step: 7
Training loss: 1.4934547994521266
Validation loss: 2.3708344648023907

Epoch: 5| Step: 8
Training loss: 1.5338393913900217
Validation loss: 2.3762751806031175

Epoch: 5| Step: 9
Training loss: 1.4380738315489792
Validation loss: 2.3832925330126966

Epoch: 5| Step: 10
Training loss: 1.0109047579290429
Validation loss: 2.3853737199930194

Epoch: 290| Step: 0
Training loss: 1.2601152748025517
Validation loss: 2.4030185133671527

Epoch: 5| Step: 1
Training loss: 1.2180762751832526
Validation loss: 2.411574330863653

Epoch: 5| Step: 2
Training loss: 1.1364690237594344
Validation loss: 2.399111131896865

Epoch: 5| Step: 3
Training loss: 1.4499643058329736
Validation loss: 2.3810519068143012

Epoch: 5| Step: 4
Training loss: 1.738114252533892
Validation loss: 2.3834586577448857

Epoch: 5| Step: 5
Training loss: 1.347734797303351
Validation loss: 2.359397768007072

Epoch: 5| Step: 6
Training loss: 1.2928773784333427
Validation loss: 2.3351568001961547

Epoch: 5| Step: 7
Training loss: 1.60487603525841
Validation loss: 2.345728795111928

Epoch: 5| Step: 8
Training loss: 1.5787990377003278
Validation loss: 2.3257401479888427

Epoch: 5| Step: 9
Training loss: 1.003680727077764
Validation loss: 2.3266415392442643

Epoch: 5| Step: 10
Training loss: 1.1670320256667701
Validation loss: 2.334367826726175

Epoch: 291| Step: 0
Training loss: 1.2562213571803673
Validation loss: 2.3344427776824492

Epoch: 5| Step: 1
Training loss: 1.0940788864481978
Validation loss: 2.364927902005514

Epoch: 5| Step: 2
Training loss: 1.4727503091335539
Validation loss: 2.3461670660904352

Epoch: 5| Step: 3
Training loss: 1.1382912053476
Validation loss: 2.3414037148764195

Epoch: 5| Step: 4
Training loss: 1.1730813492959642
Validation loss: 2.3718067813563453

Epoch: 5| Step: 5
Training loss: 1.3231879078898343
Validation loss: 2.3477083034251356

Epoch: 5| Step: 6
Training loss: 1.5283649279629992
Validation loss: 2.3532533746223327

Epoch: 5| Step: 7
Training loss: 1.6619554531310816
Validation loss: 2.342631421345249

Epoch: 5| Step: 8
Training loss: 1.5389991398660836
Validation loss: 2.3435982395930712

Epoch: 5| Step: 9
Training loss: 1.4171488259284282
Validation loss: 2.320443118319696

Epoch: 5| Step: 10
Training loss: 1.0468783022700365
Validation loss: 2.3683568556513754

Epoch: 292| Step: 0
Training loss: 1.592941378236208
Validation loss: 2.3782126395200005

Epoch: 5| Step: 1
Training loss: 1.6422049045094145
Validation loss: 2.3957822477682327

Epoch: 5| Step: 2
Training loss: 1.1561847359048765
Validation loss: 2.431991853439663

Epoch: 5| Step: 3
Training loss: 1.2562394820195282
Validation loss: 2.442772276187693

Epoch: 5| Step: 4
Training loss: 1.3619455171686714
Validation loss: 2.4324908684283417

Epoch: 5| Step: 5
Training loss: 1.4211389501931981
Validation loss: 2.3885428996753064

Epoch: 5| Step: 6
Training loss: 0.7837305742499914
Validation loss: 2.362509868189081

Epoch: 5| Step: 7
Training loss: 1.2147367375088118
Validation loss: 2.317949264040059

Epoch: 5| Step: 8
Training loss: 1.1743083358772841
Validation loss: 2.298041857545665

Epoch: 5| Step: 9
Training loss: 1.4678420649136292
Validation loss: 2.276702069718014

Epoch: 5| Step: 10
Training loss: 1.5393372885839225
Validation loss: 2.2797227287987716

Epoch: 293| Step: 0
Training loss: 1.062422805674642
Validation loss: 2.289463946390849

Epoch: 5| Step: 1
Training loss: 1.0697790333943837
Validation loss: 2.3007042630972774

Epoch: 5| Step: 2
Training loss: 1.3746693820544218
Validation loss: 2.2987151686279446

Epoch: 5| Step: 3
Training loss: 1.1605938429751148
Validation loss: 2.3019015039424526

Epoch: 5| Step: 4
Training loss: 1.2317591606807556
Validation loss: 2.3380501209955797

Epoch: 5| Step: 5
Training loss: 1.5045079996663961
Validation loss: 2.397373043552945

Epoch: 5| Step: 6
Training loss: 1.6042304913923495
Validation loss: 2.4608823937729283

Epoch: 5| Step: 7
Training loss: 1.6278103222304225
Validation loss: 2.467453734281477

Epoch: 5| Step: 8
Training loss: 1.5140656777300325
Validation loss: 2.457738617391012

Epoch: 5| Step: 9
Training loss: 1.1276710378832944
Validation loss: 2.4271795183438574

Epoch: 5| Step: 10
Training loss: 1.3205315222020073
Validation loss: 2.3946382756651707

Epoch: 294| Step: 0
Training loss: 1.5062829991441655
Validation loss: 2.359819975086038

Epoch: 5| Step: 1
Training loss: 1.1379556644498678
Validation loss: 2.346183189268518

Epoch: 5| Step: 2
Training loss: 1.3456392536037411
Validation loss: 2.31710612451414

Epoch: 5| Step: 3
Training loss: 1.601213668422981
Validation loss: 2.3228575095033666

Epoch: 5| Step: 4
Training loss: 1.089316018149814
Validation loss: 2.3132472617151474

Epoch: 5| Step: 5
Training loss: 1.1648444807023457
Validation loss: 2.3043778573177427

Epoch: 5| Step: 6
Training loss: 1.5748991525243603
Validation loss: 2.296288835798187

Epoch: 5| Step: 7
Training loss: 1.326498539149878
Validation loss: 2.3122648115658664

Epoch: 5| Step: 8
Training loss: 1.0760685201262574
Validation loss: 2.354995813114564

Epoch: 5| Step: 9
Training loss: 1.3792626457969122
Validation loss: 2.383451952464662

Epoch: 5| Step: 10
Training loss: 1.0484831116443614
Validation loss: 2.3812156303771275

Epoch: 295| Step: 0
Training loss: 1.2311059664214417
Validation loss: 2.4049363243970956

Epoch: 5| Step: 1
Training loss: 1.4459379750109391
Validation loss: 2.375329790819782

Epoch: 5| Step: 2
Training loss: 1.282219217806697
Validation loss: 2.3942256757204614

Epoch: 5| Step: 3
Training loss: 1.1995158371128316
Validation loss: 2.4085315370998934

Epoch: 5| Step: 4
Training loss: 1.6371450665605731
Validation loss: 2.3878905735315903

Epoch: 5| Step: 5
Training loss: 1.6320342623115376
Validation loss: 2.3715462109754553

Epoch: 5| Step: 6
Training loss: 1.3864264381612956
Validation loss: 2.3576419438504685

Epoch: 5| Step: 7
Training loss: 0.9240517537147167
Validation loss: 2.342243413134581

Epoch: 5| Step: 8
Training loss: 1.0594279813318055
Validation loss: 2.3005073883418485

Epoch: 5| Step: 9
Training loss: 1.049206258851412
Validation loss: 2.2907646279563565

Epoch: 5| Step: 10
Training loss: 1.3775398465328346
Validation loss: 2.2799340302951907

Epoch: 296| Step: 0
Training loss: 1.0602546977897247
Validation loss: 2.2821594091077215

Epoch: 5| Step: 1
Training loss: 1.3581336481176263
Validation loss: 2.2934107821084115

Epoch: 5| Step: 2
Training loss: 1.2581196285612581
Validation loss: 2.2916157111788946

Epoch: 5| Step: 3
Training loss: 1.1657795371531425
Validation loss: 2.3106399972416694

Epoch: 5| Step: 4
Training loss: 1.0513543477019356
Validation loss: 2.3562237076554378

Epoch: 5| Step: 5
Training loss: 0.9979052657801445
Validation loss: 2.373398452940182

Epoch: 5| Step: 6
Training loss: 1.4696835736549356
Validation loss: 2.4116458384492803

Epoch: 5| Step: 7
Training loss: 1.421626981126912
Validation loss: 2.478518101221071

Epoch: 5| Step: 8
Training loss: 1.4579511504970657
Validation loss: 2.447381257462151

Epoch: 5| Step: 9
Training loss: 1.3776015033467826
Validation loss: 2.4296223415699654

Epoch: 5| Step: 10
Training loss: 1.6852215113623485
Validation loss: 2.39855561896311

Epoch: 297| Step: 0
Training loss: 1.2645488920764036
Validation loss: 2.3750965733477103

Epoch: 5| Step: 1
Training loss: 1.2944684047327846
Validation loss: 2.3383680125174044

Epoch: 5| Step: 2
Training loss: 1.3545955956775364
Validation loss: 2.3174631835067654

Epoch: 5| Step: 3
Training loss: 1.638463731170515
Validation loss: 2.281864784100945

Epoch: 5| Step: 4
Training loss: 1.3506317020587137
Validation loss: 2.280850355086515

Epoch: 5| Step: 5
Training loss: 1.1208651638592768
Validation loss: 2.313784845170595

Epoch: 5| Step: 6
Training loss: 0.8765586186559359
Validation loss: 2.306859248234035

Epoch: 5| Step: 7
Training loss: 1.2430869630697228
Validation loss: 2.3408620563513614

Epoch: 5| Step: 8
Training loss: 1.3785895829590122
Validation loss: 2.384221828031161

Epoch: 5| Step: 9
Training loss: 1.607394434902102
Validation loss: 2.4128686347721735

Epoch: 5| Step: 10
Training loss: 0.8884562471808922
Validation loss: 2.4132353454115587

Epoch: 298| Step: 0
Training loss: 0.8444133199810359
Validation loss: 2.4653968193788196

Epoch: 5| Step: 1
Training loss: 1.7868546101066258
Validation loss: 2.4470999740158517

Epoch: 5| Step: 2
Training loss: 0.9983172563671088
Validation loss: 2.3992294281954623

Epoch: 5| Step: 3
Training loss: 1.1899892416235318
Validation loss: 2.3766983729826614

Epoch: 5| Step: 4
Training loss: 1.1502074013151016
Validation loss: 2.3553939848556573

Epoch: 5| Step: 5
Training loss: 1.4798987103932761
Validation loss: 2.3513713668099867

Epoch: 5| Step: 6
Training loss: 1.511007136542018
Validation loss: 2.3540268225864387

Epoch: 5| Step: 7
Training loss: 1.5970255532558253
Validation loss: 2.3638406184944096

Epoch: 5| Step: 8
Training loss: 0.8883775831608745
Validation loss: 2.3412679197169406

Epoch: 5| Step: 9
Training loss: 1.171198026303937
Validation loss: 2.3354970613020565

Epoch: 5| Step: 10
Training loss: 1.1361055588269182
Validation loss: 2.3271157146553363

Epoch: 299| Step: 0
Training loss: 1.25551988631663
Validation loss: 2.336167999395751

Epoch: 5| Step: 1
Training loss: 1.4552226359657312
Validation loss: 2.342753829087143

Epoch: 5| Step: 2
Training loss: 1.2004598848948262
Validation loss: 2.319222734176732

Epoch: 5| Step: 3
Training loss: 1.387224905562862
Validation loss: 2.3375136302370514

Epoch: 5| Step: 4
Training loss: 1.2496898743248468
Validation loss: 2.3173572377132508

Epoch: 5| Step: 5
Training loss: 1.5170204581362945
Validation loss: 2.3295430904196626

Epoch: 5| Step: 6
Training loss: 1.2401921783237528
Validation loss: 2.3328710997659323

Epoch: 5| Step: 7
Training loss: 1.2017787981735157
Validation loss: 2.341360055784607

Epoch: 5| Step: 8
Training loss: 0.8616241845874589
Validation loss: 2.3698079231801743

Epoch: 5| Step: 9
Training loss: 1.1325825951206396
Validation loss: 2.370131369530241

Epoch: 5| Step: 10
Training loss: 1.1711510011244035
Validation loss: 2.388370242825636

Epoch: 300| Step: 0
Training loss: 1.4946494837892528
Validation loss: 2.4094107082342577

Epoch: 5| Step: 1
Training loss: 1.133485896463242
Validation loss: 2.3892702015312364

Epoch: 5| Step: 2
Training loss: 0.9461235161405669
Validation loss: 2.4046544406516075

Epoch: 5| Step: 3
Training loss: 1.3438568959855128
Validation loss: 2.39861188776119

Epoch: 5| Step: 4
Training loss: 1.260794664350102
Validation loss: 2.401980318154176

Epoch: 5| Step: 5
Training loss: 1.4981885939983142
Validation loss: 2.4062129863379433

Epoch: 5| Step: 6
Training loss: 1.4079546874595759
Validation loss: 2.40330567935721

Epoch: 5| Step: 7
Training loss: 0.9321190587238469
Validation loss: 2.3507506738350665

Epoch: 5| Step: 8
Training loss: 1.2169832971597416
Validation loss: 2.3402462962821744

Epoch: 5| Step: 9
Training loss: 1.1411272798135803
Validation loss: 2.336627055760399

Epoch: 5| Step: 10
Training loss: 1.2631538190012563
Validation loss: 2.301894136768005

Epoch: 301| Step: 0
Training loss: 1.2078147740114427
Validation loss: 2.2773983667985647

Epoch: 5| Step: 1
Training loss: 1.3470886804435431
Validation loss: 2.3128320144664114

Epoch: 5| Step: 2
Training loss: 1.1784562007094967
Validation loss: 2.2814256794579615

Epoch: 5| Step: 3
Training loss: 1.3483017412185319
Validation loss: 2.293514231477735

Epoch: 5| Step: 4
Training loss: 0.9686475515030727
Validation loss: 2.3043826678007555

Epoch: 5| Step: 5
Training loss: 1.4369131631914493
Validation loss: 2.321664945744607

Epoch: 5| Step: 6
Training loss: 1.3137570220004648
Validation loss: 2.3717077392529555

Epoch: 5| Step: 7
Training loss: 1.0982343027237855
Validation loss: 2.416762872703878

Epoch: 5| Step: 8
Training loss: 1.1551423824782845
Validation loss: 2.375371372330044

Epoch: 5| Step: 9
Training loss: 0.9075816992037261
Validation loss: 2.375430475588162

Epoch: 5| Step: 10
Training loss: 1.5476654807310855
Validation loss: 2.381475478639241

Epoch: 302| Step: 0
Training loss: 1.2564934869393265
Validation loss: 2.3899859060001574

Epoch: 5| Step: 1
Training loss: 1.513266074636739
Validation loss: 2.365880000716365

Epoch: 5| Step: 2
Training loss: 1.009402772503653
Validation loss: 2.367048969599403

Epoch: 5| Step: 3
Training loss: 1.345180105325056
Validation loss: 2.3714998021251854

Epoch: 5| Step: 4
Training loss: 1.140928828912539
Validation loss: 2.3593429881624832

Epoch: 5| Step: 5
Training loss: 1.2726258107403754
Validation loss: 2.334181157646342

Epoch: 5| Step: 6
Training loss: 1.1327394659242493
Validation loss: 2.3773962490494074

Epoch: 5| Step: 7
Training loss: 1.3629739846834528
Validation loss: 2.3610258416573324

Epoch: 5| Step: 8
Training loss: 1.4849067137217107
Validation loss: 2.3195377223475635

Epoch: 5| Step: 9
Training loss: 1.0654995036130739
Validation loss: 2.3246964120048426

Epoch: 5| Step: 10
Training loss: 0.6412553244921833
Validation loss: 2.3092127003004768

Epoch: 303| Step: 0
Training loss: 1.0817179863329336
Validation loss: 2.316342036526497

Epoch: 5| Step: 1
Training loss: 1.1859499703255503
Validation loss: 2.3214161151667643

Epoch: 5| Step: 2
Training loss: 1.2068051123274668
Validation loss: 2.3444541595280177

Epoch: 5| Step: 3
Training loss: 1.2464976836916337
Validation loss: 2.3544101405872775

Epoch: 5| Step: 4
Training loss: 1.1528605708427333
Validation loss: 2.381677673035867

Epoch: 5| Step: 5
Training loss: 1.1063577157720794
Validation loss: 2.369162022295065

Epoch: 5| Step: 6
Training loss: 1.1420474654119173
Validation loss: 2.3466225678246264

Epoch: 5| Step: 7
Training loss: 1.0064572825683298
Validation loss: 2.3622571496675966

Epoch: 5| Step: 8
Training loss: 1.122552487562911
Validation loss: 2.3410765967883664

Epoch: 5| Step: 9
Training loss: 1.6593021843805202
Validation loss: 2.327181578495423

Epoch: 5| Step: 10
Training loss: 1.2319971673734724
Validation loss: 2.342597392524575

Epoch: 304| Step: 0
Training loss: 1.2763373934034554
Validation loss: 2.3432181090466377

Epoch: 5| Step: 1
Training loss: 0.7939141937200794
Validation loss: 2.3553727052035915

Epoch: 5| Step: 2
Training loss: 1.0062406835657856
Validation loss: 2.346803905021436

Epoch: 5| Step: 3
Training loss: 1.1020939404001806
Validation loss: 2.304213501644634

Epoch: 5| Step: 4
Training loss: 1.243451129525135
Validation loss: 2.31389766251511

Epoch: 5| Step: 5
Training loss: 1.5366861034468728
Validation loss: 2.32997172514936

Epoch: 5| Step: 6
Training loss: 0.9921184425651564
Validation loss: 2.3096071489189685

Epoch: 5| Step: 7
Training loss: 1.0344907528743759
Validation loss: 2.3163069585284064

Epoch: 5| Step: 8
Training loss: 1.2746266622537172
Validation loss: 2.3438476935914587

Epoch: 5| Step: 9
Training loss: 1.1901635865361848
Validation loss: 2.3318569391452977

Epoch: 5| Step: 10
Training loss: 1.354992433787262
Validation loss: 2.3739596021881972

Epoch: 305| Step: 0
Training loss: 1.3641371349353208
Validation loss: 2.3524659794771146

Epoch: 5| Step: 1
Training loss: 1.141729160092753
Validation loss: 2.371335059641911

Epoch: 5| Step: 2
Training loss: 1.3782882818603346
Validation loss: 2.350804404147006

Epoch: 5| Step: 3
Training loss: 1.0838659823261074
Validation loss: 2.3123455955000027

Epoch: 5| Step: 4
Training loss: 1.2403326521255384
Validation loss: 2.331239410295402

Epoch: 5| Step: 5
Training loss: 0.7726574055939799
Validation loss: 2.3121020953918805

Epoch: 5| Step: 6
Training loss: 1.3169434580414459
Validation loss: 2.3135491186124835

Epoch: 5| Step: 7
Training loss: 0.8750351490045462
Validation loss: 2.2935953639868476

Epoch: 5| Step: 8
Training loss: 1.3664164957716927
Validation loss: 2.3214546906666147

Epoch: 5| Step: 9
Training loss: 0.9559250959057364
Validation loss: 2.296932139106941

Epoch: 5| Step: 10
Training loss: 1.179092004297151
Validation loss: 2.321138279968233

Epoch: 306| Step: 0
Training loss: 0.9869827968292444
Validation loss: 2.3292313038253116

Epoch: 5| Step: 1
Training loss: 1.2339847768775065
Validation loss: 2.3213159150966014

Epoch: 5| Step: 2
Training loss: 1.0978772358385678
Validation loss: 2.349129326100942

Epoch: 5| Step: 3
Training loss: 1.1042860734301327
Validation loss: 2.342603995872569

Epoch: 5| Step: 4
Training loss: 1.295685647887434
Validation loss: 2.354725570899526

Epoch: 5| Step: 5
Training loss: 1.023534406194566
Validation loss: 2.359731799743698

Epoch: 5| Step: 6
Training loss: 1.0297518164499908
Validation loss: 2.3668740611006243

Epoch: 5| Step: 7
Training loss: 0.7407573774796286
Validation loss: 2.337618326365451

Epoch: 5| Step: 8
Training loss: 1.1306815790007971
Validation loss: 2.3306522773071707

Epoch: 5| Step: 9
Training loss: 1.6736984291707009
Validation loss: 2.319136542168152

Epoch: 5| Step: 10
Training loss: 1.100104266340272
Validation loss: 2.3169329723534156

Epoch: 307| Step: 0
Training loss: 1.2261284710219242
Validation loss: 2.293368669757175

Epoch: 5| Step: 1
Training loss: 1.0411331081837225
Validation loss: 2.3013117460486616

Epoch: 5| Step: 2
Training loss: 1.311626552411092
Validation loss: 2.3139967632241105

Epoch: 5| Step: 3
Training loss: 1.21907713974428
Validation loss: 2.3536232304643283

Epoch: 5| Step: 4
Training loss: 0.8116535032041757
Validation loss: 2.3728952445565388

Epoch: 5| Step: 5
Training loss: 1.0736182736652318
Validation loss: 2.381552458454563

Epoch: 5| Step: 6
Training loss: 1.0841408556466277
Validation loss: 2.3722518776905837

Epoch: 5| Step: 7
Training loss: 0.9729119389900392
Validation loss: 2.4024802719316445

Epoch: 5| Step: 8
Training loss: 1.0610081914572937
Validation loss: 2.391868416468111

Epoch: 5| Step: 9
Training loss: 1.0141223061063955
Validation loss: 2.3720649076090248

Epoch: 5| Step: 10
Training loss: 1.586366792652342
Validation loss: 2.3535362044299157

Epoch: 308| Step: 0
Training loss: 1.135972082564007
Validation loss: 2.346920701160854

Epoch: 5| Step: 1
Training loss: 1.1759873523226667
Validation loss: 2.3372332805450644

Epoch: 5| Step: 2
Training loss: 0.9289725944882724
Validation loss: 2.3413931587664565

Epoch: 5| Step: 3
Training loss: 0.9915258048427213
Validation loss: 2.342549845461897

Epoch: 5| Step: 4
Training loss: 1.5633380168500313
Validation loss: 2.3306436090009655

Epoch: 5| Step: 5
Training loss: 0.7510900126507669
Validation loss: 2.325905446241852

Epoch: 5| Step: 6
Training loss: 1.0556360570984618
Validation loss: 2.333172489004676

Epoch: 5| Step: 7
Training loss: 0.8890479329663932
Validation loss: 2.3215200194104417

Epoch: 5| Step: 8
Training loss: 1.084349039959796
Validation loss: 2.3420636548189204

Epoch: 5| Step: 9
Training loss: 1.2946877476468448
Validation loss: 2.3354442258211017

Epoch: 5| Step: 10
Training loss: 1.23564850024122
Validation loss: 2.330600352785673

Epoch: 309| Step: 0
Training loss: 1.0286912095246186
Validation loss: 2.343886632730886

Epoch: 5| Step: 1
Training loss: 1.2950793784715895
Validation loss: 2.3399380054382903

Epoch: 5| Step: 2
Training loss: 1.1631228347421998
Validation loss: 2.3516870384665065

Epoch: 5| Step: 3
Training loss: 1.2206544912186958
Validation loss: 2.3528412196578716

Epoch: 5| Step: 4
Training loss: 1.0459847151987076
Validation loss: 2.36686577105292

Epoch: 5| Step: 5
Training loss: 1.2210750898130112
Validation loss: 2.3706210872316062

Epoch: 5| Step: 6
Training loss: 1.1104846830930526
Validation loss: 2.379627028538247

Epoch: 5| Step: 7
Training loss: 1.5342465100223057
Validation loss: 2.3609960037763784

Epoch: 5| Step: 8
Training loss: 0.7835052364176815
Validation loss: 2.3386531393722776

Epoch: 5| Step: 9
Training loss: 0.6121438041698127
Validation loss: 2.3010256550915127

Epoch: 5| Step: 10
Training loss: 0.996127976970171
Validation loss: 2.3131957854604854

Epoch: 310| Step: 0
Training loss: 1.225189558271374
Validation loss: 2.3211063206417384

Epoch: 5| Step: 1
Training loss: 1.2527638397700795
Validation loss: 2.317797328507317

Epoch: 5| Step: 2
Training loss: 1.386028193072853
Validation loss: 2.301881585231307

Epoch: 5| Step: 3
Training loss: 0.8925557206762339
Validation loss: 2.3330511581374918

Epoch: 5| Step: 4
Training loss: 1.119340755550124
Validation loss: 2.3306088678045107

Epoch: 5| Step: 5
Training loss: 1.038285215670186
Validation loss: 2.313893439629476

Epoch: 5| Step: 6
Training loss: 0.8908697093272884
Validation loss: 2.3299932840986277

Epoch: 5| Step: 7
Training loss: 1.4368131904200487
Validation loss: 2.3294446252298235

Epoch: 5| Step: 8
Training loss: 0.9834278636420255
Validation loss: 2.350899779541791

Epoch: 5| Step: 9
Training loss: 1.0484703775131574
Validation loss: 2.3713798101037797

Epoch: 5| Step: 10
Training loss: 0.7017320185995038
Validation loss: 2.3484645250147325

Epoch: 311| Step: 0
Training loss: 0.9918003077708661
Validation loss: 2.353617889956071

Epoch: 5| Step: 1
Training loss: 0.9148400414943048
Validation loss: 2.3297976024203204

Epoch: 5| Step: 2
Training loss: 1.2657793209982766
Validation loss: 2.351232536402707

Epoch: 5| Step: 3
Training loss: 1.1005603208497008
Validation loss: 2.3266088340625446

Epoch: 5| Step: 4
Training loss: 1.089430973543121
Validation loss: 2.338264036842439

Epoch: 5| Step: 5
Training loss: 1.1370131907641527
Validation loss: 2.331842084021888

Epoch: 5| Step: 6
Training loss: 0.9514350918567269
Validation loss: 2.3150654303497156

Epoch: 5| Step: 7
Training loss: 1.250629933894165
Validation loss: 2.313477661768066

Epoch: 5| Step: 8
Training loss: 0.9904027490971332
Validation loss: 2.324940997982826

Epoch: 5| Step: 9
Training loss: 1.263248331352323
Validation loss: 2.3208345215661956

Epoch: 5| Step: 10
Training loss: 1.0041492924961324
Validation loss: 2.322203901821177

Epoch: 312| Step: 0
Training loss: 1.2746062736695625
Validation loss: 2.309361167050472

Epoch: 5| Step: 1
Training loss: 0.9190968176781559
Validation loss: 2.3197865825641033

Epoch: 5| Step: 2
Training loss: 0.8789820659574235
Validation loss: 2.3220270398377196

Epoch: 5| Step: 3
Training loss: 1.0917475216651567
Validation loss: 2.299094091882444

Epoch: 5| Step: 4
Training loss: 1.3001944561554797
Validation loss: 2.2834669020948057

Epoch: 5| Step: 5
Training loss: 0.4204901288004479
Validation loss: 2.3005813519315574

Epoch: 5| Step: 6
Training loss: 1.2278174036966465
Validation loss: 2.3172567053122726

Epoch: 5| Step: 7
Training loss: 1.1009460780653866
Validation loss: 2.3079943454398975

Epoch: 5| Step: 8
Training loss: 0.81659437138535
Validation loss: 2.2965708398603564

Epoch: 5| Step: 9
Training loss: 1.1901010837417616
Validation loss: 2.297481295841023

Epoch: 5| Step: 10
Training loss: 1.412275755644874
Validation loss: 2.2870364811501886

Epoch: 313| Step: 0
Training loss: 1.1207412537729797
Validation loss: 2.2980081178135925

Epoch: 5| Step: 1
Training loss: 0.6807940015633931
Validation loss: 2.268392037650427

Epoch: 5| Step: 2
Training loss: 1.156872555953236
Validation loss: 2.2807848258439862

Epoch: 5| Step: 3
Training loss: 0.811190025981083
Validation loss: 2.265718585306737

Epoch: 5| Step: 4
Training loss: 1.1864101026119045
Validation loss: 2.2893687959600917

Epoch: 5| Step: 5
Training loss: 1.1535321331037842
Validation loss: 2.2853034083660204

Epoch: 5| Step: 6
Training loss: 1.0549561335045048
Validation loss: 2.2878572283342646

Epoch: 5| Step: 7
Training loss: 1.2492776213915597
Validation loss: 2.315285886716489

Epoch: 5| Step: 8
Training loss: 1.0846438489618984
Validation loss: 2.327781678359651

Epoch: 5| Step: 9
Training loss: 1.0795809548304063
Validation loss: 2.3256863872952596

Epoch: 5| Step: 10
Training loss: 1.0983224387972002
Validation loss: 2.318787660241236

Epoch: 314| Step: 0
Training loss: 0.8751233899445388
Validation loss: 2.3422149137563357

Epoch: 5| Step: 1
Training loss: 1.1091663003104562
Validation loss: 2.3081083749263382

Epoch: 5| Step: 2
Training loss: 1.2160038453342472
Validation loss: 2.2937897350071372

Epoch: 5| Step: 3
Training loss: 0.7733265190262758
Validation loss: 2.276617557999103

Epoch: 5| Step: 4
Training loss: 1.0106569115974
Validation loss: 2.283776102130215

Epoch: 5| Step: 5
Training loss: 1.0769824732786177
Validation loss: 2.268713923269455

Epoch: 5| Step: 6
Training loss: 1.1151706122828051
Validation loss: 2.289774428035129

Epoch: 5| Step: 7
Training loss: 1.1116132052109078
Validation loss: 2.269118635258795

Epoch: 5| Step: 8
Training loss: 1.0968054464083947
Validation loss: 2.3012795500902765

Epoch: 5| Step: 9
Training loss: 1.069700748451829
Validation loss: 2.307403425821428

Epoch: 5| Step: 10
Training loss: 1.2027561563648652
Validation loss: 2.324556097109776

Epoch: 315| Step: 0
Training loss: 1.0127395723211445
Validation loss: 2.325647577466747

Epoch: 5| Step: 1
Training loss: 0.7407162187632262
Validation loss: 2.3203837176380326

Epoch: 5| Step: 2
Training loss: 1.1931803517518382
Validation loss: 2.3279675726896407

Epoch: 5| Step: 3
Training loss: 0.9856746812973418
Validation loss: 2.3258831955084656

Epoch: 5| Step: 4
Training loss: 1.3283426443050457
Validation loss: 2.344706582273168

Epoch: 5| Step: 5
Training loss: 1.3670297150162338
Validation loss: 2.317262301654044

Epoch: 5| Step: 6
Training loss: 1.1643159833562433
Validation loss: 2.304541701788428

Epoch: 5| Step: 7
Training loss: 0.8656004740411409
Validation loss: 2.29993111011011

Epoch: 5| Step: 8
Training loss: 0.7345163331082248
Validation loss: 2.2993964716441155

Epoch: 5| Step: 9
Training loss: 0.963371110547209
Validation loss: 2.2708968053660588

Epoch: 5| Step: 10
Training loss: 1.0312367062723298
Validation loss: 2.28096466595006

Epoch: 316| Step: 0
Training loss: 1.0475300120422089
Validation loss: 2.2943777645349845

Epoch: 5| Step: 1
Training loss: 1.091825863584719
Validation loss: 2.2943266454099436

Epoch: 5| Step: 2
Training loss: 0.9203936102313343
Validation loss: 2.2852525422750714

Epoch: 5| Step: 3
Training loss: 0.9260606947589896
Validation loss: 2.2961823735687013

Epoch: 5| Step: 4
Training loss: 1.4532506744839941
Validation loss: 2.2992748497268702

Epoch: 5| Step: 5
Training loss: 0.5962804529422543
Validation loss: 2.2944955081083185

Epoch: 5| Step: 6
Training loss: 0.9795600357973901
Validation loss: 2.3262522371461904

Epoch: 5| Step: 7
Training loss: 1.181006748645309
Validation loss: 2.2826649504126713

Epoch: 5| Step: 8
Training loss: 0.6791496779846538
Validation loss: 2.3164416430150165

Epoch: 5| Step: 9
Training loss: 1.1052371480039667
Validation loss: 2.2895755351796505

Epoch: 5| Step: 10
Training loss: 1.2846653241224917
Validation loss: 2.2754855724165957

Epoch: 317| Step: 0
Training loss: 1.4675424359764189
Validation loss: 2.283694576431448

Epoch: 5| Step: 1
Training loss: 1.1394817423242871
Validation loss: 2.2762616681661485

Epoch: 5| Step: 2
Training loss: 0.7244835510413764
Validation loss: 2.316876005069291

Epoch: 5| Step: 3
Training loss: 1.0610704341523705
Validation loss: 2.3418717452807045

Epoch: 5| Step: 4
Training loss: 0.9666099907165957
Validation loss: 2.326979755253492

Epoch: 5| Step: 5
Training loss: 1.0368860151500243
Validation loss: 2.3224657628059098

Epoch: 5| Step: 6
Training loss: 1.0375767461128342
Validation loss: 2.3158393989005357

Epoch: 5| Step: 7
Training loss: 0.974395850877901
Validation loss: 2.263388467087851

Epoch: 5| Step: 8
Training loss: 0.9161211941203177
Validation loss: 2.2556500916712716

Epoch: 5| Step: 9
Training loss: 1.0269182143402593
Validation loss: 2.235113531153057

Epoch: 5| Step: 10
Training loss: 1.1216526565602603
Validation loss: 2.228986904412489

Epoch: 318| Step: 0
Training loss: 0.8638452612077737
Validation loss: 2.267896005816649

Epoch: 5| Step: 1
Training loss: 1.0242524724161868
Validation loss: 2.268264580539607

Epoch: 5| Step: 2
Training loss: 0.8180556723855984
Validation loss: 2.301323177517691

Epoch: 5| Step: 3
Training loss: 0.8631626582787042
Validation loss: 2.29311089598212

Epoch: 5| Step: 4
Training loss: 1.1777023386986862
Validation loss: 2.311102206605378

Epoch: 5| Step: 5
Training loss: 1.127225317388047
Validation loss: 2.3276186828341996

Epoch: 5| Step: 6
Training loss: 1.009321044802556
Validation loss: 2.3495301374518927

Epoch: 5| Step: 7
Training loss: 1.091827555926527
Validation loss: 2.33345427250975

Epoch: 5| Step: 8
Training loss: 1.3368857515178285
Validation loss: 2.3282245307211684

Epoch: 5| Step: 9
Training loss: 1.2137026809598654
Validation loss: 2.3555823053700617

Epoch: 5| Step: 10
Training loss: 0.6906591355185973
Validation loss: 2.3571538860100496

Epoch: 319| Step: 0
Training loss: 1.0108925527872088
Validation loss: 2.363024188679868

Epoch: 5| Step: 1
Training loss: 0.8115190673416665
Validation loss: 2.3390342299086653

Epoch: 5| Step: 2
Training loss: 1.113987962709109
Validation loss: 2.3154781618104963

Epoch: 5| Step: 3
Training loss: 0.9913355857008602
Validation loss: 2.3468719472352277

Epoch: 5| Step: 4
Training loss: 0.8727644222360572
Validation loss: 2.3288744298138186

Epoch: 5| Step: 5
Training loss: 0.7360176220992187
Validation loss: 2.335151759983498

Epoch: 5| Step: 6
Training loss: 1.083535701239228
Validation loss: 2.315716530510375

Epoch: 5| Step: 7
Training loss: 1.2173490541949958
Validation loss: 2.281186665818782

Epoch: 5| Step: 8
Training loss: 1.3693309874711066
Validation loss: 2.2931602786417313

Epoch: 5| Step: 9
Training loss: 1.0606472466675259
Validation loss: 2.309433430629603

Epoch: 5| Step: 10
Training loss: 0.8722873601328067
Validation loss: 2.2818744112227702

Epoch: 320| Step: 0
Training loss: 0.7673633847747152
Validation loss: 2.3131501243723434

Epoch: 5| Step: 1
Training loss: 1.070898633418047
Validation loss: 2.2945055727278025

Epoch: 5| Step: 2
Training loss: 1.360241493213922
Validation loss: 2.297780771126733

Epoch: 5| Step: 3
Training loss: 0.9809298399996503
Validation loss: 2.287911131383141

Epoch: 5| Step: 4
Training loss: 1.018086487642924
Validation loss: 2.289047763621215

Epoch: 5| Step: 5
Training loss: 1.0336527720328057
Validation loss: 2.281985678547082

Epoch: 5| Step: 6
Training loss: 0.8366333391636591
Validation loss: 2.274858104252225

Epoch: 5| Step: 7
Training loss: 0.954682125694519
Validation loss: 2.263484615084915

Epoch: 5| Step: 8
Training loss: 0.933963207737319
Validation loss: 2.2701426013691695

Epoch: 5| Step: 9
Training loss: 0.9157590527098745
Validation loss: 2.264484310440795

Epoch: 5| Step: 10
Training loss: 1.152485156677384
Validation loss: 2.2592577306471537

Epoch: 321| Step: 0
Training loss: 1.0104447521488151
Validation loss: 2.269919086564794

Epoch: 5| Step: 1
Training loss: 0.8888084893489883
Validation loss: 2.286566316606135

Epoch: 5| Step: 2
Training loss: 0.7123511794753574
Validation loss: 2.3035654302691175

Epoch: 5| Step: 3
Training loss: 0.6105769115242359
Validation loss: 2.322139749998563

Epoch: 5| Step: 4
Training loss: 0.8452378682527039
Validation loss: 2.306275105300133

Epoch: 5| Step: 5
Training loss: 1.1695097386809692
Validation loss: 2.3218968313669213

Epoch: 5| Step: 6
Training loss: 1.1216930422485234
Validation loss: 2.310834562078549

Epoch: 5| Step: 7
Training loss: 1.2582107292639513
Validation loss: 2.2581513324432176

Epoch: 5| Step: 8
Training loss: 1.152224104537538
Validation loss: 2.2984987353773576

Epoch: 5| Step: 9
Training loss: 0.9074334277280961
Validation loss: 2.272500788487053

Epoch: 5| Step: 10
Training loss: 1.1151363510103167
Validation loss: 2.2983503014541387

Epoch: 322| Step: 0
Training loss: 1.1472075746713146
Validation loss: 2.3122305620244687

Epoch: 5| Step: 1
Training loss: 1.1391077270738683
Validation loss: 2.3345998232605765

Epoch: 5| Step: 2
Training loss: 1.0121940762858856
Validation loss: 2.3143522809061188

Epoch: 5| Step: 3
Training loss: 1.0232315438640456
Validation loss: 2.3596351880472892

Epoch: 5| Step: 4
Training loss: 0.7472463363016519
Validation loss: 2.3236346947559547

Epoch: 5| Step: 5
Training loss: 0.8466703948992648
Validation loss: 2.330562690971549

Epoch: 5| Step: 6
Training loss: 1.0458080491331638
Validation loss: 2.3235015178872045

Epoch: 5| Step: 7
Training loss: 0.9406690758298721
Validation loss: 2.327329380883957

Epoch: 5| Step: 8
Training loss: 0.8789650452339405
Validation loss: 2.3329966469930987

Epoch: 5| Step: 9
Training loss: 1.0814510401111983
Validation loss: 2.3163511008941042

Epoch: 5| Step: 10
Training loss: 0.7308953411441808
Validation loss: 2.3108786042974168

Epoch: 323| Step: 0
Training loss: 0.8252859212574234
Validation loss: 2.2843611389990266

Epoch: 5| Step: 1
Training loss: 0.8994082306746328
Validation loss: 2.299260729603432

Epoch: 5| Step: 2
Training loss: 1.2147741757797947
Validation loss: 2.2693738638002863

Epoch: 5| Step: 3
Training loss: 0.7157428694358857
Validation loss: 2.257994211768078

Epoch: 5| Step: 4
Training loss: 0.9912421160525117
Validation loss: 2.267129092018448

Epoch: 5| Step: 5
Training loss: 1.2207237791221426
Validation loss: 2.2577603866342937

Epoch: 5| Step: 6
Training loss: 0.8523272658728744
Validation loss: 2.2528504827292157

Epoch: 5| Step: 7
Training loss: 0.7809935339539117
Validation loss: 2.2589867404644344

Epoch: 5| Step: 8
Training loss: 0.839032335644891
Validation loss: 2.24292720115376

Epoch: 5| Step: 9
Training loss: 1.072376905548754
Validation loss: 2.296598767050906

Epoch: 5| Step: 10
Training loss: 1.0850347704963355
Validation loss: 2.283565342505753

Epoch: 324| Step: 0
Training loss: 1.0762322438333773
Validation loss: 2.289040207242448

Epoch: 5| Step: 1
Training loss: 0.6618608666658956
Validation loss: 2.2900476835579093

Epoch: 5| Step: 2
Training loss: 1.0507629846736737
Validation loss: 2.283052045961571

Epoch: 5| Step: 3
Training loss: 1.0570387451627918
Validation loss: 2.2824741590273243

Epoch: 5| Step: 4
Training loss: 0.7450874692657514
Validation loss: 2.285622103086321

Epoch: 5| Step: 5
Training loss: 1.0746409748163959
Validation loss: 2.2694739191760314

Epoch: 5| Step: 6
Training loss: 1.003328090085833
Validation loss: 2.2720202455961798

Epoch: 5| Step: 7
Training loss: 1.0010092529913397
Validation loss: 2.286902202646678

Epoch: 5| Step: 8
Training loss: 0.8303156972758248
Validation loss: 2.2848023701447904

Epoch: 5| Step: 9
Training loss: 0.9796330207144921
Validation loss: 2.2994090144477792

Epoch: 5| Step: 10
Training loss: 0.9348516568909988
Validation loss: 2.3126643487453062

Epoch: 325| Step: 0
Training loss: 0.5251491232663387
Validation loss: 2.3238473919720546

Epoch: 5| Step: 1
Training loss: 1.2314309853696697
Validation loss: 2.3621109933827475

Epoch: 5| Step: 2
Training loss: 0.9904230303005568
Validation loss: 2.3588700074939863

Epoch: 5| Step: 3
Training loss: 0.8852367704556183
Validation loss: 2.3265196705362254

Epoch: 5| Step: 4
Training loss: 0.8734598910988056
Validation loss: 2.3267797512030723

Epoch: 5| Step: 5
Training loss: 1.2357987992770574
Validation loss: 2.292943123722477

Epoch: 5| Step: 6
Training loss: 0.6402578232051521
Validation loss: 2.2908797254433644

Epoch: 5| Step: 7
Training loss: 1.151687383414797
Validation loss: 2.2880893312806263

Epoch: 5| Step: 8
Training loss: 0.9688972238219568
Validation loss: 2.2677811797767093

Epoch: 5| Step: 9
Training loss: 0.6711623604177451
Validation loss: 2.2565926629843056

Epoch: 5| Step: 10
Training loss: 0.9621606191291666
Validation loss: 2.2586654594438405

Epoch: 326| Step: 0
Training loss: 0.5219961219987016
Validation loss: 2.2781963748684237

Epoch: 5| Step: 1
Training loss: 1.0811722302996156
Validation loss: 2.2745535900141576

Epoch: 5| Step: 2
Training loss: 1.1558358249669538
Validation loss: 2.316780768225903

Epoch: 5| Step: 3
Training loss: 1.0954912222158448
Validation loss: 2.3254990491873477

Epoch: 5| Step: 4
Training loss: 0.9884950308590428
Validation loss: 2.3208287952081434

Epoch: 5| Step: 5
Training loss: 0.7137613909558987
Validation loss: 2.3057281775290024

Epoch: 5| Step: 6
Training loss: 0.9763738221051651
Validation loss: 2.316601141711713

Epoch: 5| Step: 7
Training loss: 0.6330668091463032
Validation loss: 2.298748555605769

Epoch: 5| Step: 8
Training loss: 1.0487673722329875
Validation loss: 2.2930219411790396

Epoch: 5| Step: 9
Training loss: 0.907261612690376
Validation loss: 2.2832798475583966

Epoch: 5| Step: 10
Training loss: 0.8845217202270766
Validation loss: 2.2882371457664936

Epoch: 327| Step: 0
Training loss: 0.937726565640517
Validation loss: 2.3077481100134127

Epoch: 5| Step: 1
Training loss: 0.8959905722965092
Validation loss: 2.3176392914924224

Epoch: 5| Step: 2
Training loss: 0.9177221413366321
Validation loss: 2.2747567473518386

Epoch: 5| Step: 3
Training loss: 1.1707810445673594
Validation loss: 2.2734468067540967

Epoch: 5| Step: 4
Training loss: 0.7784099455450945
Validation loss: 2.271697253622737

Epoch: 5| Step: 5
Training loss: 0.9404557997899968
Validation loss: 2.244290766336208

Epoch: 5| Step: 6
Training loss: 0.8600710737445423
Validation loss: 2.2713904962167866

Epoch: 5| Step: 7
Training loss: 0.5243381608701166
Validation loss: 2.2596860835052217

Epoch: 5| Step: 8
Training loss: 0.9198163208874027
Validation loss: 2.2757065189452423

Epoch: 5| Step: 9
Training loss: 1.2004804404435638
Validation loss: 2.2971088205861983

Epoch: 5| Step: 10
Training loss: 0.750568174677602
Validation loss: 2.314165704424107

Epoch: 328| Step: 0
Training loss: 0.7845023929445181
Validation loss: 2.321802169259746

Epoch: 5| Step: 1
Training loss: 0.9949457172462078
Validation loss: 2.344015809439775

Epoch: 5| Step: 2
Training loss: 1.0307168449345159
Validation loss: 2.347913594088353

Epoch: 5| Step: 3
Training loss: 0.7768649442947222
Validation loss: 2.332849752032295

Epoch: 5| Step: 4
Training loss: 0.9993210812469284
Validation loss: 2.3285474133172315

Epoch: 5| Step: 5
Training loss: 1.0852767251288984
Validation loss: 2.309291282465282

Epoch: 5| Step: 6
Training loss: 0.6040535415324563
Validation loss: 2.3043363653723965

Epoch: 5| Step: 7
Training loss: 0.7622933983363934
Validation loss: 2.2885201492839045

Epoch: 5| Step: 8
Training loss: 0.8604423137349203
Validation loss: 2.284988911849702

Epoch: 5| Step: 9
Training loss: 1.0086100180308988
Validation loss: 2.2758518647749253

Epoch: 5| Step: 10
Training loss: 0.8670034814740495
Validation loss: 2.295777481177212

Epoch: 329| Step: 0
Training loss: 1.124817886447319
Validation loss: 2.300279550875899

Epoch: 5| Step: 1
Training loss: 1.023527825715717
Validation loss: 2.2857860655407496

Epoch: 5| Step: 2
Training loss: 0.8605303540680723
Validation loss: 2.3115614660785724

Epoch: 5| Step: 3
Training loss: 0.8231659081213479
Validation loss: 2.308302387936226

Epoch: 5| Step: 4
Training loss: 1.0851807736398857
Validation loss: 2.3310925723147387

Epoch: 5| Step: 5
Training loss: 0.6271895441194
Validation loss: 2.3544271693242074

Epoch: 5| Step: 6
Training loss: 0.8521337430510205
Validation loss: 2.3801794358455495

Epoch: 5| Step: 7
Training loss: 0.8957381789364095
Validation loss: 2.3490301681967525

Epoch: 5| Step: 8
Training loss: 0.7623019602260335
Validation loss: 2.318418503003906

Epoch: 5| Step: 9
Training loss: 0.6500161728314136
Validation loss: 2.3023353304730723

Epoch: 5| Step: 10
Training loss: 1.0563251355776888
Validation loss: 2.3092503561724205

Epoch: 330| Step: 0
Training loss: 0.8222290900805609
Validation loss: 2.270235159164353

Epoch: 5| Step: 1
Training loss: 0.7840240818188478
Validation loss: 2.2683775399416457

Epoch: 5| Step: 2
Training loss: 1.1876032433050214
Validation loss: 2.296564858767079

Epoch: 5| Step: 3
Training loss: 0.893468066743709
Validation loss: 2.2851165625000007

Epoch: 5| Step: 4
Training loss: 0.6914091379568703
Validation loss: 2.2665544390567476

Epoch: 5| Step: 5
Training loss: 0.7210644485620564
Validation loss: 2.2495021930225083

Epoch: 5| Step: 6
Training loss: 0.8683490363023376
Validation loss: 2.265593558868758

Epoch: 5| Step: 7
Training loss: 0.8560109967434504
Validation loss: 2.2460267090567574

Epoch: 5| Step: 8
Training loss: 0.7865139813135341
Validation loss: 2.282332985475613

Epoch: 5| Step: 9
Training loss: 0.9620854723644859
Validation loss: 2.269930485543779

Epoch: 5| Step: 10
Training loss: 1.1257453674485398
Validation loss: 2.282351758349687

Epoch: 331| Step: 0
Training loss: 0.7702448290954974
Validation loss: 2.293276846098018

Epoch: 5| Step: 1
Training loss: 0.7789877371600216
Validation loss: 2.2658703912636335

Epoch: 5| Step: 2
Training loss: 0.7648095439864051
Validation loss: 2.2647728561785105

Epoch: 5| Step: 3
Training loss: 0.7788104305425049
Validation loss: 2.2792626294597795

Epoch: 5| Step: 4
Training loss: 1.0731323297035895
Validation loss: 2.2544511578634205

Epoch: 5| Step: 5
Training loss: 1.0108482120946238
Validation loss: 2.279118824517206

Epoch: 5| Step: 6
Training loss: 1.0468088385328727
Validation loss: 2.262617746916377

Epoch: 5| Step: 7
Training loss: 0.6153907940341184
Validation loss: 2.264410298807774

Epoch: 5| Step: 8
Training loss: 1.0033540505797638
Validation loss: 2.294343941309768

Epoch: 5| Step: 9
Training loss: 0.8411200473167358
Validation loss: 2.2842815942713814

Epoch: 5| Step: 10
Training loss: 0.836258942309638
Validation loss: 2.2760439918464703

Epoch: 332| Step: 0
Training loss: 0.9186960463998002
Validation loss: 2.3210428170730397

Epoch: 5| Step: 1
Training loss: 0.8370741843455745
Validation loss: 2.265200979846257

Epoch: 5| Step: 2
Training loss: 0.8239408630242272
Validation loss: 2.2763350264307327

Epoch: 5| Step: 3
Training loss: 0.731386189942532
Validation loss: 2.278315274827399

Epoch: 5| Step: 4
Training loss: 0.9642840472464306
Validation loss: 2.306213215384713

Epoch: 5| Step: 5
Training loss: 1.180542995660328
Validation loss: 2.2566176642740197

Epoch: 5| Step: 6
Training loss: 0.7845786707924095
Validation loss: 2.2811251887263975

Epoch: 5| Step: 7
Training loss: 0.6794093428830384
Validation loss: 2.272544122328484

Epoch: 5| Step: 8
Training loss: 0.8463381526116683
Validation loss: 2.3016481052615654

Epoch: 5| Step: 9
Training loss: 0.7849993572718424
Validation loss: 2.2930081864373784

Epoch: 5| Step: 10
Training loss: 0.9393444989824312
Validation loss: 2.304748654479696

Epoch: 333| Step: 0
Training loss: 0.8548972254325348
Validation loss: 2.3097750554295535

Epoch: 5| Step: 1
Training loss: 0.7485741333291226
Validation loss: 2.302634751170204

Epoch: 5| Step: 2
Training loss: 0.7638101672058966
Validation loss: 2.2982421778399527

Epoch: 5| Step: 3
Training loss: 0.8121711358846936
Validation loss: 2.327609233899193

Epoch: 5| Step: 4
Training loss: 0.9779414702494744
Validation loss: 2.293963082885209

Epoch: 5| Step: 5
Training loss: 0.5943691889963175
Validation loss: 2.3310985115570406

Epoch: 5| Step: 6
Training loss: 1.1615053289966946
Validation loss: 2.2873641091578993

Epoch: 5| Step: 7
Training loss: 0.901586371623108
Validation loss: 2.3210698511726746

Epoch: 5| Step: 8
Training loss: 0.9391484708357525
Validation loss: 2.291632464275767

Epoch: 5| Step: 9
Training loss: 0.8212163759196743
Validation loss: 2.2956282978488636

Epoch: 5| Step: 10
Training loss: 0.7671752338244605
Validation loss: 2.3059638303061676

Epoch: 334| Step: 0
Training loss: 0.9455762763118216
Validation loss: 2.275640921566657

Epoch: 5| Step: 1
Training loss: 1.0043345921666051
Validation loss: 2.290253910388981

Epoch: 5| Step: 2
Training loss: 0.7774983161343804
Validation loss: 2.2877437022639784

Epoch: 5| Step: 3
Training loss: 0.5334058662604029
Validation loss: 2.2844861917772628

Epoch: 5| Step: 4
Training loss: 0.9469374255259073
Validation loss: 2.2976238159363445

Epoch: 5| Step: 5
Training loss: 0.7871272082710519
Validation loss: 2.317676085943352

Epoch: 5| Step: 6
Training loss: 0.584415672029245
Validation loss: 2.3253769469657013

Epoch: 5| Step: 7
Training loss: 0.897608830964919
Validation loss: 2.308975874653917

Epoch: 5| Step: 8
Training loss: 0.9002963531857553
Validation loss: 2.3167498138596603

Epoch: 5| Step: 9
Training loss: 0.8743587937397164
Validation loss: 2.294958174642496

Epoch: 5| Step: 10
Training loss: 0.9725212708233311
Validation loss: 2.277372510717835

Epoch: 335| Step: 0
Training loss: 0.8765064962791558
Validation loss: 2.29281607876367

Epoch: 5| Step: 1
Training loss: 0.72996070860588
Validation loss: 2.2970347569010725

Epoch: 5| Step: 2
Training loss: 0.9709308441592066
Validation loss: 2.288371228306864

Epoch: 5| Step: 3
Training loss: 0.6813584757543564
Validation loss: 2.3097986186821524

Epoch: 5| Step: 4
Training loss: 0.7859574211128929
Validation loss: 2.304256958371664

Epoch: 5| Step: 5
Training loss: 0.9200513550170354
Validation loss: 2.3091523290594718

Epoch: 5| Step: 6
Training loss: 0.8305018521563267
Validation loss: 2.29592937318258

Epoch: 5| Step: 7
Training loss: 0.8921529479275849
Validation loss: 2.2443774707986757

Epoch: 5| Step: 8
Training loss: 0.9290108021127632
Validation loss: 2.2643653986269054

Epoch: 5| Step: 9
Training loss: 0.8658122249253941
Validation loss: 2.2343951407305807

Epoch: 5| Step: 10
Training loss: 0.7396556030925597
Validation loss: 2.240156744667511

Epoch: 336| Step: 0
Training loss: 0.6525922290616405
Validation loss: 2.2455961593449483

Epoch: 5| Step: 1
Training loss: 0.8354435825213519
Validation loss: 2.240976574953864

Epoch: 5| Step: 2
Training loss: 0.869210675449092
Validation loss: 2.2725005515830374

Epoch: 5| Step: 3
Training loss: 0.842115833014578
Validation loss: 2.296445162183685

Epoch: 5| Step: 4
Training loss: 1.032237187297495
Validation loss: 2.3201685245134565

Epoch: 5| Step: 5
Training loss: 0.8445314038582661
Validation loss: 2.3369480775405824

Epoch: 5| Step: 6
Training loss: 0.7160428938431075
Validation loss: 2.300434793105772

Epoch: 5| Step: 7
Training loss: 0.9112890177093146
Validation loss: 2.2881830285618228

Epoch: 5| Step: 8
Training loss: 1.101259771643595
Validation loss: 2.2781880262971885

Epoch: 5| Step: 9
Training loss: 0.6256024794664785
Validation loss: 2.2317923660398784

Epoch: 5| Step: 10
Training loss: 0.8460307202589556
Validation loss: 2.2571277291776486

Epoch: 337| Step: 0
Training loss: 0.5731476895948424
Validation loss: 2.259029357575439

Epoch: 5| Step: 1
Training loss: 0.8388075002412279
Validation loss: 2.292785925139086

Epoch: 5| Step: 2
Training loss: 0.662106426761331
Validation loss: 2.310063906782086

Epoch: 5| Step: 3
Training loss: 0.8101950375901469
Validation loss: 2.3137510203343985

Epoch: 5| Step: 4
Training loss: 0.7379255295631744
Validation loss: 2.3725725980264314

Epoch: 5| Step: 5
Training loss: 0.932175137076272
Validation loss: 2.357912467201283

Epoch: 5| Step: 6
Training loss: 0.957975863391584
Validation loss: 2.363823758974648

Epoch: 5| Step: 7
Training loss: 0.9196959459057634
Validation loss: 2.3388196150258613

Epoch: 5| Step: 8
Training loss: 1.119324940254851
Validation loss: 2.2809101367950744

Epoch: 5| Step: 9
Training loss: 0.6192639104800011
Validation loss: 2.2583763729038955

Epoch: 5| Step: 10
Training loss: 0.8554832422431132
Validation loss: 2.250223663110552

Epoch: 338| Step: 0
Training loss: 0.853179865599435
Validation loss: 2.239162784668017

Epoch: 5| Step: 1
Training loss: 0.8458116563045663
Validation loss: 2.2206920586309353

Epoch: 5| Step: 2
Training loss: 0.7342819804265762
Validation loss: 2.2312989002960073

Epoch: 5| Step: 3
Training loss: 0.8746176633659337
Validation loss: 2.2506944799185016

Epoch: 5| Step: 4
Training loss: 0.7827752673646795
Validation loss: 2.259719757834996

Epoch: 5| Step: 5
Training loss: 1.2166161073778874
Validation loss: 2.2661284071675807

Epoch: 5| Step: 6
Training loss: 0.7177253551337841
Validation loss: 2.2881349602787826

Epoch: 5| Step: 7
Training loss: 0.7361326084556712
Validation loss: 2.304907331763584

Epoch: 5| Step: 8
Training loss: 0.6143491643710417
Validation loss: 2.317255924799363

Epoch: 5| Step: 9
Training loss: 0.8133213953082709
Validation loss: 2.320771833524628

Epoch: 5| Step: 10
Training loss: 0.7320520713556423
Validation loss: 2.308056314218665

Epoch: 339| Step: 0
Training loss: 1.024101857048074
Validation loss: 2.281503819735169

Epoch: 5| Step: 1
Training loss: 0.5837248158383005
Validation loss: 2.30609293904012

Epoch: 5| Step: 2
Training loss: 0.7811988050853069
Validation loss: 2.278396429848466

Epoch: 5| Step: 3
Training loss: 0.6214091621697098
Validation loss: 2.2838032018809944

Epoch: 5| Step: 4
Training loss: 0.9052787048120764
Validation loss: 2.27187153510057

Epoch: 5| Step: 5
Training loss: 0.8110541537251448
Validation loss: 2.308030320634533

Epoch: 5| Step: 6
Training loss: 0.8820837608363996
Validation loss: 2.258714415925067

Epoch: 5| Step: 7
Training loss: 0.8210305477248662
Validation loss: 2.2499420171077835

Epoch: 5| Step: 8
Training loss: 0.8624460314023157
Validation loss: 2.2586215528643234

Epoch: 5| Step: 9
Training loss: 0.7905153929836135
Validation loss: 2.260786071038167

Epoch: 5| Step: 10
Training loss: 0.8218722093193918
Validation loss: 2.247227419491316

Epoch: 340| Step: 0
Training loss: 0.8593383781259377
Validation loss: 2.2609055090082264

Epoch: 5| Step: 1
Training loss: 1.0130393346095632
Validation loss: 2.251051513500311

Epoch: 5| Step: 2
Training loss: 1.0078221401965959
Validation loss: 2.253321396334382

Epoch: 5| Step: 3
Training loss: 0.7082709303650482
Validation loss: 2.2483159688359016

Epoch: 5| Step: 4
Training loss: 0.7844424062998983
Validation loss: 2.2773467928063433

Epoch: 5| Step: 5
Training loss: 0.5821375909729254
Validation loss: 2.286326305322335

Epoch: 5| Step: 6
Training loss: 0.7346695248487067
Validation loss: 2.2856808307374075

Epoch: 5| Step: 7
Training loss: 0.6761502487805577
Validation loss: 2.2756233438201217

Epoch: 5| Step: 8
Training loss: 0.9163459231137496
Validation loss: 2.3158803886364465

Epoch: 5| Step: 9
Training loss: 0.8063535017661211
Validation loss: 2.29205139115291

Epoch: 5| Step: 10
Training loss: 0.6352938522927087
Validation loss: 2.2778552637277327

Epoch: 341| Step: 0
Training loss: 0.9123820320064321
Validation loss: 2.273567118486074

Epoch: 5| Step: 1
Training loss: 0.9479557001370382
Validation loss: 2.2840433452909603

Epoch: 5| Step: 2
Training loss: 0.801860918856501
Validation loss: 2.296570998373628

Epoch: 5| Step: 3
Training loss: 0.791040227060027
Validation loss: 2.283864526627759

Epoch: 5| Step: 4
Training loss: 0.6506761720232082
Validation loss: 2.2773369596753654

Epoch: 5| Step: 5
Training loss: 1.0068326222969184
Validation loss: 2.2640161942984394

Epoch: 5| Step: 6
Training loss: 0.5540629887457691
Validation loss: 2.2466236449982286

Epoch: 5| Step: 7
Training loss: 0.7141652039639403
Validation loss: 2.220317995965322

Epoch: 5| Step: 8
Training loss: 0.7780989998759417
Validation loss: 2.2349880939788767

Epoch: 5| Step: 9
Training loss: 0.7691381389525433
Validation loss: 2.209897617030025

Epoch: 5| Step: 10
Training loss: 0.7842443684165066
Validation loss: 2.2309300140913995

Epoch: 342| Step: 0
Training loss: 0.9158120651020196
Validation loss: 2.2366443390947777

Epoch: 5| Step: 1
Training loss: 0.6833402763184555
Validation loss: 2.238615155742443

Epoch: 5| Step: 2
Training loss: 0.9579612106203266
Validation loss: 2.2387896467600057

Epoch: 5| Step: 3
Training loss: 0.6109096325618673
Validation loss: 2.238468981727586

Epoch: 5| Step: 4
Training loss: 0.7446941009497863
Validation loss: 2.272091393902708

Epoch: 5| Step: 5
Training loss: 0.8288607657678314
Validation loss: 2.2925825964140305

Epoch: 5| Step: 6
Training loss: 0.867913844091325
Validation loss: 2.2941702568004323

Epoch: 5| Step: 7
Training loss: 0.8298731292712718
Validation loss: 2.3635686363539485

Epoch: 5| Step: 8
Training loss: 0.5741925395770576
Validation loss: 2.3552652036142496

Epoch: 5| Step: 9
Training loss: 0.8538999761436451
Validation loss: 2.328971068732006

Epoch: 5| Step: 10
Training loss: 0.8010990163631112
Validation loss: 2.3386681458070893

Epoch: 343| Step: 0
Training loss: 0.7528814753077082
Validation loss: 2.334038462719877

Epoch: 5| Step: 1
Training loss: 1.031689983488567
Validation loss: 2.3407735419869047

Epoch: 5| Step: 2
Training loss: 0.6817208491556889
Validation loss: 2.294021938410431

Epoch: 5| Step: 3
Training loss: 0.6977181982749924
Validation loss: 2.2551259838560354

Epoch: 5| Step: 4
Training loss: 0.7729502983350799
Validation loss: 2.244452631602867

Epoch: 5| Step: 5
Training loss: 0.8028235467170798
Validation loss: 2.22339609235098

Epoch: 5| Step: 6
Training loss: 0.6236626144537829
Validation loss: 2.206423015817847

Epoch: 5| Step: 7
Training loss: 0.8370372632572439
Validation loss: 2.189402675996059

Epoch: 5| Step: 8
Training loss: 0.688393575658418
Validation loss: 2.199097444541688

Epoch: 5| Step: 9
Training loss: 0.8613285056046317
Validation loss: 2.237052658321465

Epoch: 5| Step: 10
Training loss: 0.9561517216163492
Validation loss: 2.2429445256536074

Epoch: 344| Step: 0
Training loss: 0.981582616814243
Validation loss: 2.267266617583035

Epoch: 5| Step: 1
Training loss: 0.7038310215048099
Validation loss: 2.279896551400091

Epoch: 5| Step: 2
Training loss: 0.9835660123057574
Validation loss: 2.272246386728831

Epoch: 5| Step: 3
Training loss: 0.618517083343024
Validation loss: 2.268654260886867

Epoch: 5| Step: 4
Training loss: 0.7416188922953988
Validation loss: 2.272544434528142

Epoch: 5| Step: 5
Training loss: 0.8086484070517077
Validation loss: 2.3060006743079877

Epoch: 5| Step: 6
Training loss: 0.8535831520725653
Validation loss: 2.3068086840898503

Epoch: 5| Step: 7
Training loss: 0.6983826182605195
Validation loss: 2.2948481121789284

Epoch: 5| Step: 8
Training loss: 0.5826488265047733
Validation loss: 2.3058238236227404

Epoch: 5| Step: 9
Training loss: 0.8774027871626964
Validation loss: 2.279984757551096

Epoch: 5| Step: 10
Training loss: 0.695293533409406
Validation loss: 2.299100647343511

Epoch: 345| Step: 0
Training loss: 0.4715294450584652
Validation loss: 2.3218603831474693

Epoch: 5| Step: 1
Training loss: 0.7027378287874584
Validation loss: 2.3325354531116678

Epoch: 5| Step: 2
Training loss: 0.8114906056507292
Validation loss: 2.3247370095821376

Epoch: 5| Step: 3
Training loss: 0.7929009093781788
Validation loss: 2.3033072761543507

Epoch: 5| Step: 4
Training loss: 0.9194977708035487
Validation loss: 2.318400928361182

Epoch: 5| Step: 5
Training loss: 0.6411447742452377
Validation loss: 2.297163082961511

Epoch: 5| Step: 6
Training loss: 0.6647479614751632
Validation loss: 2.272440834061721

Epoch: 5| Step: 7
Training loss: 0.832431535740845
Validation loss: 2.271395687508926

Epoch: 5| Step: 8
Training loss: 0.8018658619788893
Validation loss: 2.226732888760757

Epoch: 5| Step: 9
Training loss: 1.051295158332555
Validation loss: 2.2461054844703554

Epoch: 5| Step: 10
Training loss: 0.7223974228346174
Validation loss: 2.202889206334432

Epoch: 346| Step: 0
Training loss: 0.980441362826773
Validation loss: 2.229054513624161

Epoch: 5| Step: 1
Training loss: 0.8828437597091073
Validation loss: 2.238528527854613

Epoch: 5| Step: 2
Training loss: 0.6402254719606842
Validation loss: 2.2457925899391964

Epoch: 5| Step: 3
Training loss: 0.8019345050476675
Validation loss: 2.241538225155342

Epoch: 5| Step: 4
Training loss: 0.6374862819018439
Validation loss: 2.260030869387377

Epoch: 5| Step: 5
Training loss: 0.6025459128412376
Validation loss: 2.272310653789501

Epoch: 5| Step: 6
Training loss: 0.615175977084902
Validation loss: 2.2750772287746224

Epoch: 5| Step: 7
Training loss: 0.8790603502601892
Validation loss: 2.3142472627966395

Epoch: 5| Step: 8
Training loss: 0.6944570958786473
Validation loss: 2.2757840431144167

Epoch: 5| Step: 9
Training loss: 0.7827740109664908
Validation loss: 2.277614742510842

Epoch: 5| Step: 10
Training loss: 0.7900223889377365
Validation loss: 2.2849814026338464

Epoch: 347| Step: 0
Training loss: 0.8498249701199212
Validation loss: 2.286447032824204

Epoch: 5| Step: 1
Training loss: 0.9236292877097743
Validation loss: 2.2751741566438612

Epoch: 5| Step: 2
Training loss: 0.8936182551885142
Validation loss: 2.2986327903726598

Epoch: 5| Step: 3
Training loss: 0.5754960574057294
Validation loss: 2.3144831403339596

Epoch: 5| Step: 4
Training loss: 0.5824308623676496
Validation loss: 2.2942736115847997

Epoch: 5| Step: 5
Training loss: 0.5131209287121822
Validation loss: 2.25304175332862

Epoch: 5| Step: 6
Training loss: 0.841698837767038
Validation loss: 2.2561015593186107

Epoch: 5| Step: 7
Training loss: 0.5980774884701288
Validation loss: 2.2762379559665233

Epoch: 5| Step: 8
Training loss: 0.6729867741190689
Validation loss: 2.2485999356843065

Epoch: 5| Step: 9
Training loss: 0.8582178127610262
Validation loss: 2.265613941452766

Epoch: 5| Step: 10
Training loss: 0.8202526252330193
Validation loss: 2.2538143058235303

Epoch: 348| Step: 0
Training loss: 0.6463815428668807
Validation loss: 2.259784232531736

Epoch: 5| Step: 1
Training loss: 0.6133820517729134
Validation loss: 2.2649377792639016

Epoch: 5| Step: 2
Training loss: 0.6415405476675102
Validation loss: 2.24551013128685

Epoch: 5| Step: 3
Training loss: 0.9710894915241095
Validation loss: 2.2565763944450894

Epoch: 5| Step: 4
Training loss: 0.8608583652799566
Validation loss: 2.241477631838976

Epoch: 5| Step: 5
Training loss: 0.6304770335583311
Validation loss: 2.275708252666793

Epoch: 5| Step: 6
Training loss: 0.9847834511716772
Validation loss: 2.262478867978686

Epoch: 5| Step: 7
Training loss: 0.6356890725069565
Validation loss: 2.268804778884088

Epoch: 5| Step: 8
Training loss: 0.827760940276685
Validation loss: 2.2566382807287475

Epoch: 5| Step: 9
Training loss: 0.6001497995615406
Validation loss: 2.283469109315348

Epoch: 5| Step: 10
Training loss: 0.6375502323480793
Validation loss: 2.249627240840664

Epoch: 349| Step: 0
Training loss: 0.6679641545009363
Validation loss: 2.2564868597129286

Epoch: 5| Step: 1
Training loss: 0.6145002071824124
Validation loss: 2.2689305368032264

Epoch: 5| Step: 2
Training loss: 0.7572240215944682
Validation loss: 2.2494300293547687

Epoch: 5| Step: 3
Training loss: 0.6478409148414537
Validation loss: 2.260018076278526

Epoch: 5| Step: 4
Training loss: 0.7765150013449129
Validation loss: 2.2538141158664415

Epoch: 5| Step: 5
Training loss: 1.0500625932292806
Validation loss: 2.2641011783678797

Epoch: 5| Step: 6
Training loss: 0.6670756029550404
Validation loss: 2.281678902693684

Epoch: 5| Step: 7
Training loss: 0.638472756426679
Validation loss: 2.2691522882358415

Epoch: 5| Step: 8
Training loss: 0.8352466830473471
Validation loss: 2.248292152893447

Epoch: 5| Step: 9
Training loss: 0.7523028464601561
Validation loss: 2.220298957805058

Epoch: 5| Step: 10
Training loss: 0.6875067407104185
Validation loss: 2.21136193147762

Epoch: 350| Step: 0
Training loss: 0.8388764954873222
Validation loss: 2.2100715838797242

Epoch: 5| Step: 1
Training loss: 0.6922869488163816
Validation loss: 2.205235374281365

Epoch: 5| Step: 2
Training loss: 0.49662605023027007
Validation loss: 2.232472484415705

Epoch: 5| Step: 3
Training loss: 0.8325721164775426
Validation loss: 2.2945766852466005

Epoch: 5| Step: 4
Training loss: 0.8211481470151815
Validation loss: 2.355809002488703

Epoch: 5| Step: 5
Training loss: 0.8140336015078555
Validation loss: 2.4262030104086585

Epoch: 5| Step: 6
Training loss: 0.9245643182500813
Validation loss: 2.4647658569973085

Epoch: 5| Step: 7
Training loss: 0.6290664705699792
Validation loss: 2.430924314621729

Epoch: 5| Step: 8
Training loss: 0.5316320335932856
Validation loss: 2.354731736321982

Epoch: 5| Step: 9
Training loss: 0.8697637831431057
Validation loss: 2.2740754909442753

Epoch: 5| Step: 10
Training loss: 0.9340601119377517
Validation loss: 2.2821079969139926

Epoch: 351| Step: 0
Training loss: 0.8517159489956673
Validation loss: 2.28318306449627

Epoch: 5| Step: 1
Training loss: 0.782191967526585
Validation loss: 2.2500708425300626

Epoch: 5| Step: 2
Training loss: 0.8847303572945605
Validation loss: 2.2894293613506016

Epoch: 5| Step: 3
Training loss: 0.565379244278827
Validation loss: 2.2747118141606606

Epoch: 5| Step: 4
Training loss: 0.4621472727696652
Validation loss: 2.2567870277385724

Epoch: 5| Step: 5
Training loss: 0.7732912175724502
Validation loss: 2.29446039555884

Epoch: 5| Step: 6
Training loss: 0.9227400132028725
Validation loss: 2.2991332052618314

Epoch: 5| Step: 7
Training loss: 0.7976592075991745
Validation loss: 2.307277201530772

Epoch: 5| Step: 8
Training loss: 0.7076343472174577
Validation loss: 2.255995898924784

Epoch: 5| Step: 9
Training loss: 0.8482377127947252
Validation loss: 2.304211575753743

Epoch: 5| Step: 10
Training loss: 0.8069702657163808
Validation loss: 2.2758543249474035

Epoch: 352| Step: 0
Training loss: 0.4302209490511142
Validation loss: 2.3055330394326243

Epoch: 5| Step: 1
Training loss: 0.8174392881218563
Validation loss: 2.292527700040281

Epoch: 5| Step: 2
Training loss: 0.520995464521205
Validation loss: 2.311280724813998

Epoch: 5| Step: 3
Training loss: 0.9347194445019116
Validation loss: 2.3109085018731985

Epoch: 5| Step: 4
Training loss: 0.9996470782260404
Validation loss: 2.321906786044541

Epoch: 5| Step: 5
Training loss: 0.7713894169952571
Validation loss: 2.3269760050533725

Epoch: 5| Step: 6
Training loss: 0.6521888366232218
Validation loss: 2.310694024517689

Epoch: 5| Step: 7
Training loss: 0.4506996292452137
Validation loss: 2.2933083520497135

Epoch: 5| Step: 8
Training loss: 0.8339282693684411
Validation loss: 2.2907782934905825

Epoch: 5| Step: 9
Training loss: 0.7837546064615628
Validation loss: 2.2979895152332563

Epoch: 5| Step: 10
Training loss: 0.5765623418296039
Validation loss: 2.272249637187686

Epoch: 353| Step: 0
Training loss: 0.6008193144130582
Validation loss: 2.3001218784439263

Epoch: 5| Step: 1
Training loss: 0.9451723546582514
Validation loss: 2.243967222983444

Epoch: 5| Step: 2
Training loss: 0.4685146694736555
Validation loss: 2.2275112534993013

Epoch: 5| Step: 3
Training loss: 1.0471129645149668
Validation loss: 2.2269812808425535

Epoch: 5| Step: 4
Training loss: 0.6591085437953628
Validation loss: 2.239927144046885

Epoch: 5| Step: 5
Training loss: 0.7464045331686462
Validation loss: 2.242824952475677

Epoch: 5| Step: 6
Training loss: 0.5923230944478255
Validation loss: 2.23446735053833

Epoch: 5| Step: 7
Training loss: 0.7695197477304038
Validation loss: 2.2660846938328594

Epoch: 5| Step: 8
Training loss: 0.7711274299107156
Validation loss: 2.227273282046394

Epoch: 5| Step: 9
Training loss: 0.44487778040721004
Validation loss: 2.2506192046348046

Epoch: 5| Step: 10
Training loss: 0.711853862043374
Validation loss: 2.2492361891541828

Epoch: 354| Step: 0
Training loss: 0.7142996880322485
Validation loss: 2.234364801061318

Epoch: 5| Step: 1
Training loss: 0.8716004270861535
Validation loss: 2.262752189953283

Epoch: 5| Step: 2
Training loss: 0.6728188959394419
Validation loss: 2.270370060957094

Epoch: 5| Step: 3
Training loss: 0.6081400853919603
Validation loss: 2.278347817523366

Epoch: 5| Step: 4
Training loss: 0.5210888966759001
Validation loss: 2.3121515536451973

Epoch: 5| Step: 5
Training loss: 0.8303268239570004
Validation loss: 2.2699036510385233

Epoch: 5| Step: 6
Training loss: 0.9356003907253825
Validation loss: 2.2977182195087775

Epoch: 5| Step: 7
Training loss: 0.6454589871453377
Validation loss: 2.2786800345155553

Epoch: 5| Step: 8
Training loss: 0.48166798361539925
Validation loss: 2.2537299985643444

Epoch: 5| Step: 9
Training loss: 0.8488545890716863
Validation loss: 2.2689342959422527

Epoch: 5| Step: 10
Training loss: 0.590627086978838
Validation loss: 2.2270189791356074

Epoch: 355| Step: 0
Training loss: 0.5898179054913981
Validation loss: 2.229788394403255

Epoch: 5| Step: 1
Training loss: 0.9246620140676008
Validation loss: 2.218387642919333

Epoch: 5| Step: 2
Training loss: 0.7519590699592511
Validation loss: 2.2005360382849877

Epoch: 5| Step: 3
Training loss: 0.7522354982955372
Validation loss: 2.217213727521068

Epoch: 5| Step: 4
Training loss: 0.8365308848104536
Validation loss: 2.1937891276026322

Epoch: 5| Step: 5
Training loss: 0.6321718717294244
Validation loss: 2.2134706809854423

Epoch: 5| Step: 6
Training loss: 0.7157119731441497
Validation loss: 2.1946286516648756

Epoch: 5| Step: 7
Training loss: 0.8223335799817459
Validation loss: 2.220519112031171

Epoch: 5| Step: 8
Training loss: 0.5463392358078584
Validation loss: 2.2395368849298745

Epoch: 5| Step: 9
Training loss: 0.514985583946156
Validation loss: 2.269360311689193

Epoch: 5| Step: 10
Training loss: 0.6819008491714456
Validation loss: 2.2820382778407495

Epoch: 356| Step: 0
Training loss: 0.7090790320226475
Validation loss: 2.292622236299359

Epoch: 5| Step: 1
Training loss: 0.6863150354916425
Validation loss: 2.3053821710494407

Epoch: 5| Step: 2
Training loss: 0.8353395551701989
Validation loss: 2.314264708911769

Epoch: 5| Step: 3
Training loss: 0.6906618755731629
Validation loss: 2.3173575264517123

Epoch: 5| Step: 4
Training loss: 0.45358893880418016
Validation loss: 2.293202144403441

Epoch: 5| Step: 5
Training loss: 0.46129870405707674
Validation loss: 2.268611012080152

Epoch: 5| Step: 6
Training loss: 0.6588202054364135
Validation loss: 2.2626151261890217

Epoch: 5| Step: 7
Training loss: 0.8351571549641744
Validation loss: 2.2480427211410454

Epoch: 5| Step: 8
Training loss: 0.7637678315348967
Validation loss: 2.2320653955757117

Epoch: 5| Step: 9
Training loss: 0.6053712335627309
Validation loss: 2.2223004616616433

Epoch: 5| Step: 10
Training loss: 0.9030657105305299
Validation loss: 2.2409962285073544

Epoch: 357| Step: 0
Training loss: 0.5642539600255325
Validation loss: 2.223588622309177

Epoch: 5| Step: 1
Training loss: 0.5262756834309401
Validation loss: 2.2530001096320764

Epoch: 5| Step: 2
Training loss: 0.5044864005873032
Validation loss: 2.257914453455537

Epoch: 5| Step: 3
Training loss: 0.7194827946719216
Validation loss: 2.254434039199077

Epoch: 5| Step: 4
Training loss: 0.5049605761615472
Validation loss: 2.247590006006887

Epoch: 5| Step: 5
Training loss: 0.7943757826878544
Validation loss: 2.269921858104236

Epoch: 5| Step: 6
Training loss: 0.6119648356822621
Validation loss: 2.283389624454242

Epoch: 5| Step: 7
Training loss: 0.6645899529162299
Validation loss: 2.264016985805362

Epoch: 5| Step: 8
Training loss: 0.8517241018403922
Validation loss: 2.271247348109207

Epoch: 5| Step: 9
Training loss: 0.7833965947260995
Validation loss: 2.2809878648351862

Epoch: 5| Step: 10
Training loss: 0.9155999320182259
Validation loss: 2.266524701796994

Epoch: 358| Step: 0
Training loss: 0.4397335598807294
Validation loss: 2.240585693404992

Epoch: 5| Step: 1
Training loss: 0.5721469274331529
Validation loss: 2.277245537104889

Epoch: 5| Step: 2
Training loss: 0.8868319401358783
Validation loss: 2.2678885338283066

Epoch: 5| Step: 3
Training loss: 0.6526897677709379
Validation loss: 2.220977928685825

Epoch: 5| Step: 4
Training loss: 0.6834619013472966
Validation loss: 2.2326462042022004

Epoch: 5| Step: 5
Training loss: 0.6561514689636531
Validation loss: 2.2134925476839884

Epoch: 5| Step: 6
Training loss: 0.8352059345079283
Validation loss: 2.2216819445663827

Epoch: 5| Step: 7
Training loss: 0.5308133181816397
Validation loss: 2.243015915617032

Epoch: 5| Step: 8
Training loss: 0.7412294327711397
Validation loss: 2.231073358955201

Epoch: 5| Step: 9
Training loss: 0.7375604249155532
Validation loss: 2.271159706207923

Epoch: 5| Step: 10
Training loss: 0.6554082285569663
Validation loss: 2.2656273337957904

Epoch: 359| Step: 0
Training loss: 0.6196828687901653
Validation loss: 2.2654720097740957

Epoch: 5| Step: 1
Training loss: 0.7061080384839977
Validation loss: 2.243668522610687

Epoch: 5| Step: 2
Training loss: 0.887459533735967
Validation loss: 2.2395048211185

Epoch: 5| Step: 3
Training loss: 0.5370993041048032
Validation loss: 2.232108238408821

Epoch: 5| Step: 4
Training loss: 0.7507358755637021
Validation loss: 2.2174709098899927

Epoch: 5| Step: 5
Training loss: 0.48708450143748533
Validation loss: 2.2253888493820977

Epoch: 5| Step: 6
Training loss: 0.7006255122445758
Validation loss: 2.2402094180272614

Epoch: 5| Step: 7
Training loss: 0.19775824836390865
Validation loss: 2.2188397761566194

Epoch: 5| Step: 8
Training loss: 0.8253815390018603
Validation loss: 2.213142367305017

Epoch: 5| Step: 9
Training loss: 0.6417976671934899
Validation loss: 2.212215659834668

Epoch: 5| Step: 10
Training loss: 0.7660350090970736
Validation loss: 2.194519608624664

Epoch: 360| Step: 0
Training loss: 0.5565039215875114
Validation loss: 2.222134631000474

Epoch: 5| Step: 1
Training loss: 0.8646375608481777
Validation loss: 2.243701197623367

Epoch: 5| Step: 2
Training loss: 0.6913886202703581
Validation loss: 2.235733663817551

Epoch: 5| Step: 3
Training loss: 0.5566354048634753
Validation loss: 2.239427550140261

Epoch: 5| Step: 4
Training loss: 0.7620709118700669
Validation loss: 2.2367746295286874

Epoch: 5| Step: 5
Training loss: 0.5619527485895401
Validation loss: 2.25486453175182

Epoch: 5| Step: 6
Training loss: 0.3483607194750092
Validation loss: 2.2196261235863344

Epoch: 5| Step: 7
Training loss: 0.47103351062370624
Validation loss: 2.2620415138196885

Epoch: 5| Step: 8
Training loss: 0.777120356832583
Validation loss: 2.2613104927266177

Epoch: 5| Step: 9
Training loss: 0.8582765321239041
Validation loss: 2.2309107183010237

Epoch: 5| Step: 10
Training loss: 0.6112789341449918
Validation loss: 2.237715828837486

Epoch: 361| Step: 0
Training loss: 0.6878427604732993
Validation loss: 2.237852993960965

Epoch: 5| Step: 1
Training loss: 0.5776545698385488
Validation loss: 2.261601636250638

Epoch: 5| Step: 2
Training loss: 0.7215793730892938
Validation loss: 2.2589632691044104

Epoch: 5| Step: 3
Training loss: 0.7296665294827744
Validation loss: 2.2480832558622055

Epoch: 5| Step: 4
Training loss: 0.8422373882514598
Validation loss: 2.267398532428241

Epoch: 5| Step: 5
Training loss: 0.7150378354605696
Validation loss: 2.2735992713507174

Epoch: 5| Step: 6
Training loss: 0.4989705962928591
Validation loss: 2.2446530597215664

Epoch: 5| Step: 7
Training loss: 0.4625648124491671
Validation loss: 2.2554132398347044

Epoch: 5| Step: 8
Training loss: 0.4705936098712206
Validation loss: 2.2317209128466264

Epoch: 5| Step: 9
Training loss: 0.8313841474893322
Validation loss: 2.223519133593633

Epoch: 5| Step: 10
Training loss: 0.601222102971346
Validation loss: 2.2311643294533794

Epoch: 362| Step: 0
Training loss: 0.8015047851962231
Validation loss: 2.246488532584878

Epoch: 5| Step: 1
Training loss: 0.7851849071530017
Validation loss: 2.202824238314939

Epoch: 5| Step: 2
Training loss: 0.6350113378473784
Validation loss: 2.2210795674683825

Epoch: 5| Step: 3
Training loss: 0.6835862077569415
Validation loss: 2.2441174627420866

Epoch: 5| Step: 4
Training loss: 0.4658851338515926
Validation loss: 2.2517338752305904

Epoch: 5| Step: 5
Training loss: 0.6181341227291197
Validation loss: 2.2659694049182666

Epoch: 5| Step: 6
Training loss: 0.7326370126741399
Validation loss: 2.2867182688686274

Epoch: 5| Step: 7
Training loss: 0.4525213989709257
Validation loss: 2.2695859768638114

Epoch: 5| Step: 8
Training loss: 0.758233454872482
Validation loss: 2.2437512604139216

Epoch: 5| Step: 9
Training loss: 0.5760997145126475
Validation loss: 2.253107153019518

Epoch: 5| Step: 10
Training loss: 0.6284060414093064
Validation loss: 2.252541006211524

Epoch: 363| Step: 0
Training loss: 0.442727331614032
Validation loss: 2.248412214646363

Epoch: 5| Step: 1
Training loss: 0.7761192453680689
Validation loss: 2.249069181413805

Epoch: 5| Step: 2
Training loss: 0.8215021861599271
Validation loss: 2.2380198799074815

Epoch: 5| Step: 3
Training loss: 0.4738181469299888
Validation loss: 2.230212507274529

Epoch: 5| Step: 4
Training loss: 0.7146902701287071
Validation loss: 2.25420583307645

Epoch: 5| Step: 5
Training loss: 0.5984084687524271
Validation loss: 2.2480729828398998

Epoch: 5| Step: 6
Training loss: 0.7782621086690775
Validation loss: 2.2291824536535536

Epoch: 5| Step: 7
Training loss: 0.6610039228966401
Validation loss: 2.319065715149387

Epoch: 5| Step: 8
Training loss: 0.5770078381298562
Validation loss: 2.244967278436355

Epoch: 5| Step: 9
Training loss: 0.9583256589886315
Validation loss: 2.226128052181652

Epoch: 5| Step: 10
Training loss: 0.28028545287425466
Validation loss: 2.210449874606987

Epoch: 364| Step: 0
Training loss: 0.7793030702731892
Validation loss: 2.2195495939440417

Epoch: 5| Step: 1
Training loss: 0.7167821565618909
Validation loss: 2.2356403174918773

Epoch: 5| Step: 2
Training loss: 0.6364151868747625
Validation loss: 2.2174727388555024

Epoch: 5| Step: 3
Training loss: 0.5806238195778927
Validation loss: 2.22094237297247

Epoch: 5| Step: 4
Training loss: 0.5623325787510733
Validation loss: 2.238874231495087

Epoch: 5| Step: 5
Training loss: 0.712545149192496
Validation loss: 2.247344978017687

Epoch: 5| Step: 6
Training loss: 0.3494809090485134
Validation loss: 2.2317000058963674

Epoch: 5| Step: 7
Training loss: 0.766207726263026
Validation loss: 2.2225697054301214

Epoch: 5| Step: 8
Training loss: 0.5155619091391718
Validation loss: 2.2236804446084855

Epoch: 5| Step: 9
Training loss: 0.8279042219568322
Validation loss: 2.236823940200167

Epoch: 5| Step: 10
Training loss: 0.5985426967181344
Validation loss: 2.222568155182133

Epoch: 365| Step: 0
Training loss: 0.2572868797819632
Validation loss: 2.237262741711681

Epoch: 5| Step: 1
Training loss: 0.49850128985384445
Validation loss: 2.252353503802917

Epoch: 5| Step: 2
Training loss: 0.2842441760953679
Validation loss: 2.258338706520947

Epoch: 5| Step: 3
Training loss: 0.6493925392198113
Validation loss: 2.2640837080514693

Epoch: 5| Step: 4
Training loss: 0.562193548648138
Validation loss: 2.2473353350203245

Epoch: 5| Step: 5
Training loss: 0.7300925280444789
Validation loss: 2.284676693671946

Epoch: 5| Step: 6
Training loss: 0.911723641429028
Validation loss: 2.272865430076338

Epoch: 5| Step: 7
Training loss: 0.9338693571087435
Validation loss: 2.259380907289756

Epoch: 5| Step: 8
Training loss: 0.6672991246062645
Validation loss: 2.261015528643152

Epoch: 5| Step: 9
Training loss: 0.6258282656872918
Validation loss: 2.248477197151984

Epoch: 5| Step: 10
Training loss: 0.5739412740213392
Validation loss: 2.2775473940444795

Epoch: 366| Step: 0
Training loss: 0.7068357039169512
Validation loss: 2.2780315665111988

Epoch: 5| Step: 1
Training loss: 0.4742666506259913
Validation loss: 2.264149906352563

Epoch: 5| Step: 2
Training loss: 0.8032467731229361
Validation loss: 2.2968627871323384

Epoch: 5| Step: 3
Training loss: 0.7700064107083076
Validation loss: 2.2631844948592716

Epoch: 5| Step: 4
Training loss: 0.62102141049006
Validation loss: 2.2776606787101366

Epoch: 5| Step: 5
Training loss: 0.5966038882094643
Validation loss: 2.274208413163286

Epoch: 5| Step: 6
Training loss: 0.28543847631860075
Validation loss: 2.251741888678673

Epoch: 5| Step: 7
Training loss: 0.7799738952352075
Validation loss: 2.2134905694979015

Epoch: 5| Step: 8
Training loss: 0.2774236590823036
Validation loss: 2.2558495811701182

Epoch: 5| Step: 9
Training loss: 0.5583962578212257
Validation loss: 2.236512636320894

Epoch: 5| Step: 10
Training loss: 0.7905930885840825
Validation loss: 2.2543533122670274

Epoch: 367| Step: 0
Training loss: 0.7689277102369582
Validation loss: 2.2663397980013467

Epoch: 5| Step: 1
Training loss: 0.5699946419146156
Validation loss: 2.2511527231722592

Epoch: 5| Step: 2
Training loss: 0.7280555069795751
Validation loss: 2.283922259501459

Epoch: 5| Step: 3
Training loss: 0.5021448325907255
Validation loss: 2.274135234869581

Epoch: 5| Step: 4
Training loss: 0.46273508154605664
Validation loss: 2.2757745510354033

Epoch: 5| Step: 5
Training loss: 0.5465376221985867
Validation loss: 2.2830648402557725

Epoch: 5| Step: 6
Training loss: 0.6798729040776703
Validation loss: 2.257044717871349

Epoch: 5| Step: 7
Training loss: 0.6545607760561574
Validation loss: 2.2376291936296693

Epoch: 5| Step: 8
Training loss: 0.8504552029020088
Validation loss: 2.239299371741015

Epoch: 5| Step: 9
Training loss: 0.3543015064412046
Validation loss: 2.2390514788699765

Epoch: 5| Step: 10
Training loss: 0.5565481811857675
Validation loss: 2.2028842172774166

Epoch: 368| Step: 0
Training loss: 0.3836913239169985
Validation loss: 2.221517986266921

Epoch: 5| Step: 1
Training loss: 0.32790678579347926
Validation loss: 2.2126511100592907

Epoch: 5| Step: 2
Training loss: 0.37391131042550374
Validation loss: 2.1996765423782194

Epoch: 5| Step: 3
Training loss: 0.5409759892566626
Validation loss: 2.217165964868919

Epoch: 5| Step: 4
Training loss: 0.43291912349239997
Validation loss: 2.2164571522282546

Epoch: 5| Step: 5
Training loss: 0.5392461546812515
Validation loss: 2.249503642084451

Epoch: 5| Step: 6
Training loss: 0.7324057208504995
Validation loss: 2.251657458850396

Epoch: 5| Step: 7
Training loss: 0.8257590270142348
Validation loss: 2.251495661793167

Epoch: 5| Step: 8
Training loss: 0.8229854450375674
Validation loss: 2.287313797180242

Epoch: 5| Step: 9
Training loss: 0.8515294969795391
Validation loss: 2.246680685990179

Epoch: 5| Step: 10
Training loss: 0.5956174194718161
Validation loss: 2.2624665901166154

Epoch: 369| Step: 0
Training loss: 0.5168225513403012
Validation loss: 2.2604519931222975

Epoch: 5| Step: 1
Training loss: 0.6893752705218147
Validation loss: 2.243992385788295

Epoch: 5| Step: 2
Training loss: 0.47745989121755694
Validation loss: 2.236938070395609

Epoch: 5| Step: 3
Training loss: 0.5358878098743779
Validation loss: 2.233812482355604

Epoch: 5| Step: 4
Training loss: 0.5020346668078457
Validation loss: 2.217679208034327

Epoch: 5| Step: 5
Training loss: 0.5106762757814498
Validation loss: 2.210831092909808

Epoch: 5| Step: 6
Training loss: 0.8780025668334805
Validation loss: 2.2343145618028024

Epoch: 5| Step: 7
Training loss: 0.5262137562736661
Validation loss: 2.2187869398042426

Epoch: 5| Step: 8
Training loss: 0.5922278166561964
Validation loss: 2.2451309173493454

Epoch: 5| Step: 9
Training loss: 0.7314760738978604
Validation loss: 2.2610687926415993

Epoch: 5| Step: 10
Training loss: 0.64221788877439
Validation loss: 2.2712786940446748

Epoch: 370| Step: 0
Training loss: 0.8877205252345465
Validation loss: 2.252689557742355

Epoch: 5| Step: 1
Training loss: 0.35063177462610123
Validation loss: 2.2604821346263515

Epoch: 5| Step: 2
Training loss: 0.7165813069926189
Validation loss: 2.2420471280096796

Epoch: 5| Step: 3
Training loss: 0.4313373795041467
Validation loss: 2.202456311515451

Epoch: 5| Step: 4
Training loss: 0.6247716963543245
Validation loss: 2.198331009915365

Epoch: 5| Step: 5
Training loss: 0.44030900473253093
Validation loss: 2.2165369820097993

Epoch: 5| Step: 6
Training loss: 0.48885330259727827
Validation loss: 2.2135199186835908

Epoch: 5| Step: 7
Training loss: 0.7340919273717267
Validation loss: 2.1973876277546367

Epoch: 5| Step: 8
Training loss: 0.7894043889921353
Validation loss: 2.211317000167554

Epoch: 5| Step: 9
Training loss: 0.5579505632011551
Validation loss: 2.235767450087262

Epoch: 5| Step: 10
Training loss: 0.46104442843256277
Validation loss: 2.240176833416231

Epoch: 371| Step: 0
Training loss: 0.5061295130484419
Validation loss: 2.2438610386144195

Epoch: 5| Step: 1
Training loss: 0.5887713251483597
Validation loss: 2.223123365479904

Epoch: 5| Step: 2
Training loss: 0.7263856077717802
Validation loss: 2.2358795373827065

Epoch: 5| Step: 3
Training loss: 0.42872464933604043
Validation loss: 2.2510272578526305

Epoch: 5| Step: 4
Training loss: 0.45355822143807495
Validation loss: 2.2293248506194288

Epoch: 5| Step: 5
Training loss: 0.7024681838219251
Validation loss: 2.2624990622002317

Epoch: 5| Step: 6
Training loss: 0.842228188177645
Validation loss: 2.2499798041181327

Epoch: 5| Step: 7
Training loss: 0.6986379928759398
Validation loss: 2.2705788489996777

Epoch: 5| Step: 8
Training loss: 0.44701348406446906
Validation loss: 2.249992596193663

Epoch: 5| Step: 9
Training loss: 0.13711877611322518
Validation loss: 2.2451643372604493

Epoch: 5| Step: 10
Training loss: 0.8278607720672021
Validation loss: 2.268762366867022

Epoch: 372| Step: 0
Training loss: 0.5312936989258201
Validation loss: 2.305568984092604

Epoch: 5| Step: 1
Training loss: 0.7165542732495188
Validation loss: 2.3275372019937612

Epoch: 5| Step: 2
Training loss: 0.6681905456307996
Validation loss: 2.2703206963631795

Epoch: 5| Step: 3
Training loss: 0.359648372500569
Validation loss: 2.250633042449546

Epoch: 5| Step: 4
Training loss: 0.5311085288226869
Validation loss: 2.2814768078487435

Epoch: 5| Step: 5
Training loss: 0.7108404910795668
Validation loss: 2.264537131716339

Epoch: 5| Step: 6
Training loss: 0.4624594438659072
Validation loss: 2.256159151541355

Epoch: 5| Step: 7
Training loss: 0.7660847276237639
Validation loss: 2.227924996667103

Epoch: 5| Step: 8
Training loss: 0.5089510844564534
Validation loss: 2.2427432841461266

Epoch: 5| Step: 9
Training loss: 0.6020660522207248
Validation loss: 2.2513468902844695

Epoch: 5| Step: 10
Training loss: 0.5561416263234241
Validation loss: 2.275302407504597

Epoch: 373| Step: 0
Training loss: 0.6575090954517714
Validation loss: 2.2813210380080804

Epoch: 5| Step: 1
Training loss: 0.545935614178113
Validation loss: 2.2675652291929107

Epoch: 5| Step: 2
Training loss: 0.6193575313656833
Validation loss: 2.300705684924712

Epoch: 5| Step: 3
Training loss: 0.44632226666025016
Validation loss: 2.303500027478292

Epoch: 5| Step: 4
Training loss: 0.6285512644998335
Validation loss: 2.317103892909124

Epoch: 5| Step: 5
Training loss: 0.7084244968615929
Validation loss: 2.2876852937181043

Epoch: 5| Step: 6
Training loss: 0.5014054691335958
Validation loss: 2.2816652944571736

Epoch: 5| Step: 7
Training loss: 0.6192089247712171
Validation loss: 2.2624730811712803

Epoch: 5| Step: 8
Training loss: 0.7957629129366983
Validation loss: 2.2688266642550228

Epoch: 5| Step: 9
Training loss: 0.4384362896816218
Validation loss: 2.253922489471945

Epoch: 5| Step: 10
Training loss: 0.3597574893723232
Validation loss: 2.2328746200443366

Epoch: 374| Step: 0
Training loss: 0.5517725039526381
Validation loss: 2.2290046785610684

Epoch: 5| Step: 1
Training loss: 0.6770406024849451
Validation loss: 2.2310353649111923

Epoch: 5| Step: 2
Training loss: 0.7003947549880085
Validation loss: 2.2550126050749544

Epoch: 5| Step: 3
Training loss: 0.544579100729798
Validation loss: 2.2574303206298447

Epoch: 5| Step: 4
Training loss: 0.505968177906764
Validation loss: 2.229569241116415

Epoch: 5| Step: 5
Training loss: 0.5703471970128203
Validation loss: 2.254271143839703

Epoch: 5| Step: 6
Training loss: 0.5755107901777143
Validation loss: 2.296652927061407

Epoch: 5| Step: 7
Training loss: 0.5266034050965753
Validation loss: 2.2836819748219113

Epoch: 5| Step: 8
Training loss: 0.7724165680653718
Validation loss: 2.253444514360829

Epoch: 5| Step: 9
Training loss: 0.42782224336149655
Validation loss: 2.2934833621432014

Epoch: 5| Step: 10
Training loss: 0.4588221648881546
Validation loss: 2.2654722960725078

Epoch: 375| Step: 0
Training loss: 0.5793889894000223
Validation loss: 2.2733642788480695

Epoch: 5| Step: 1
Training loss: 0.5740421828161751
Validation loss: 2.270177698182634

Epoch: 5| Step: 2
Training loss: 0.6752343583341467
Validation loss: 2.2725081629582644

Epoch: 5| Step: 3
Training loss: 0.5042492785696865
Validation loss: 2.2858753184701674

Epoch: 5| Step: 4
Training loss: 0.26259194080946635
Validation loss: 2.2770018772572884

Epoch: 5| Step: 5
Training loss: 0.6104467455078952
Validation loss: 2.285305741697244

Epoch: 5| Step: 6
Training loss: 0.6340400422219107
Validation loss: 2.30231591158182

Epoch: 5| Step: 7
Training loss: 0.554555742975637
Validation loss: 2.299596848406156

Epoch: 5| Step: 8
Training loss: 0.4529965646184042
Validation loss: 2.2801130121680524

Epoch: 5| Step: 9
Training loss: 0.8405319233243612
Validation loss: 2.2445771366773966

Epoch: 5| Step: 10
Training loss: 0.5019819496279763
Validation loss: 2.2674643863477484

Epoch: 376| Step: 0
Training loss: 0.5803162314069562
Validation loss: 2.2189254922428043

Epoch: 5| Step: 1
Training loss: 0.6278943278796919
Validation loss: 2.201501385790088

Epoch: 5| Step: 2
Training loss: 0.6059393745696339
Validation loss: 2.2373298046365298

Epoch: 5| Step: 3
Training loss: 0.4227205915006965
Validation loss: 2.2122511663353777

Epoch: 5| Step: 4
Training loss: 0.5896729480947228
Validation loss: 2.2424989963943136

Epoch: 5| Step: 5
Training loss: 0.6172415311316581
Validation loss: 2.2389227247446897

Epoch: 5| Step: 6
Training loss: 0.5771361218992557
Validation loss: 2.228171846422278

Epoch: 5| Step: 7
Training loss: 0.6296723006617226
Validation loss: 2.255323242891592

Epoch: 5| Step: 8
Training loss: 0.5791702101162246
Validation loss: 2.2447691830331205

Epoch: 5| Step: 9
Training loss: 0.5379750159943222
Validation loss: 2.2597711033582355

Epoch: 5| Step: 10
Training loss: 0.49199554696626513
Validation loss: 2.2615788659317264

Epoch: 377| Step: 0
Training loss: 0.3384927995576607
Validation loss: 2.241671445604122

Epoch: 5| Step: 1
Training loss: 0.4504861946975544
Validation loss: 2.250792036945323

Epoch: 5| Step: 2
Training loss: 0.696648546383244
Validation loss: 2.242584947911482

Epoch: 5| Step: 3
Training loss: 0.8123731514140325
Validation loss: 2.2513046823088967

Epoch: 5| Step: 4
Training loss: 0.4866180628054988
Validation loss: 2.2554397227476533

Epoch: 5| Step: 5
Training loss: 0.5029734175845597
Validation loss: 2.2679225526538858

Epoch: 5| Step: 6
Training loss: 0.8831859237703265
Validation loss: 2.263309046117682

Epoch: 5| Step: 7
Training loss: 0.27732820870281455
Validation loss: 2.269702915262763

Epoch: 5| Step: 8
Training loss: 0.47948269339366745
Validation loss: 2.2619583456654984

Epoch: 5| Step: 9
Training loss: 0.334674679522191
Validation loss: 2.2605917047995523

Epoch: 5| Step: 10
Training loss: 0.5653889695760421
Validation loss: 2.2602676995404596

Epoch: 378| Step: 0
Training loss: 0.46714732849004764
Validation loss: 2.2559114464816363

Epoch: 5| Step: 1
Training loss: 0.32729361430138443
Validation loss: 2.2322123145153614

Epoch: 5| Step: 2
Training loss: 0.6452490306611967
Validation loss: 2.287705392065089

Epoch: 5| Step: 3
Training loss: 0.6154586867482803
Validation loss: 2.286528399279669

Epoch: 5| Step: 4
Training loss: 0.6951166370000587
Validation loss: 2.28340977857488

Epoch: 5| Step: 5
Training loss: 0.23842341450174753
Validation loss: 2.2858361829123135

Epoch: 5| Step: 6
Training loss: 0.6676072151716435
Validation loss: 2.24328596035594

Epoch: 5| Step: 7
Training loss: 0.5964240292824055
Validation loss: 2.2618946248845946

Epoch: 5| Step: 8
Training loss: 0.7164863932635933
Validation loss: 2.2430405687745214

Epoch: 5| Step: 9
Training loss: 0.3602219635432986
Validation loss: 2.244194086458079

Epoch: 5| Step: 10
Training loss: 0.6135256092148561
Validation loss: 2.2388305264984143

Epoch: 379| Step: 0
Training loss: 0.43467049461904417
Validation loss: 2.2392265415275983

Epoch: 5| Step: 1
Training loss: 0.6461927787785786
Validation loss: 2.225866804115404

Epoch: 5| Step: 2
Training loss: 0.4965985050675916
Validation loss: 2.2443398296263237

Epoch: 5| Step: 3
Training loss: 0.33881691111733253
Validation loss: 2.2305520182233107

Epoch: 5| Step: 4
Training loss: 0.5154658852341789
Validation loss: 2.257966052346239

Epoch: 5| Step: 5
Training loss: 0.3586596542666154
Validation loss: 2.313561146991969

Epoch: 5| Step: 6
Training loss: 0.5094581641427822
Validation loss: 2.3286694076454926

Epoch: 5| Step: 7
Training loss: 0.5923187170874749
Validation loss: 2.308767181140145

Epoch: 5| Step: 8
Training loss: 0.7010707516656896
Validation loss: 2.29644776328185

Epoch: 5| Step: 9
Training loss: 0.7823925437514424
Validation loss: 2.2911648300585052

Epoch: 5| Step: 10
Training loss: 0.674878173006713
Validation loss: 2.2595913520492155

Epoch: 380| Step: 0
Training loss: 0.507056539225187
Validation loss: 2.2731914978478938

Epoch: 5| Step: 1
Training loss: 0.8324727422816908
Validation loss: 2.2809626653568893

Epoch: 5| Step: 2
Training loss: 0.704329624356122
Validation loss: 2.298354216039806

Epoch: 5| Step: 3
Training loss: 0.5504723622888159
Validation loss: 2.295015130243934

Epoch: 5| Step: 4
Training loss: 0.6312289970982997
Validation loss: 2.291699955345155

Epoch: 5| Step: 5
Training loss: 0.3971075788236286
Validation loss: 2.286338101850094

Epoch: 5| Step: 6
Training loss: 0.15690903557532926
Validation loss: 2.2578630645752393

Epoch: 5| Step: 7
Training loss: 0.4841891208974608
Validation loss: 2.2527250641694168

Epoch: 5| Step: 8
Training loss: 0.40298695677339613
Validation loss: 2.2300685748215727

Epoch: 5| Step: 9
Training loss: 0.48378024965282257
Validation loss: 2.2219720776468805

Epoch: 5| Step: 10
Training loss: 0.6840426905426984
Validation loss: 2.252376279175287

Epoch: 381| Step: 0
Training loss: 0.30190675880382145
Validation loss: 2.23235260956799

Epoch: 5| Step: 1
Training loss: 0.5319991439565067
Validation loss: 2.2368566796666673

Epoch: 5| Step: 2
Training loss: 0.5664754364903585
Validation loss: 2.2437285471697943

Epoch: 5| Step: 3
Training loss: 0.35919300944528804
Validation loss: 2.2731479507890007

Epoch: 5| Step: 4
Training loss: 0.5100584979260812
Validation loss: 2.274732722498233

Epoch: 5| Step: 5
Training loss: 0.6443662952534441
Validation loss: 2.222480052258339

Epoch: 5| Step: 6
Training loss: 0.7283951810623969
Validation loss: 2.274938207240375

Epoch: 5| Step: 7
Training loss: 0.41185658733559555
Validation loss: 2.2507994352744918

Epoch: 5| Step: 8
Training loss: 0.48546543742689713
Validation loss: 2.245060152459837

Epoch: 5| Step: 9
Training loss: 0.6481935662738018
Validation loss: 2.2304590745568107

Epoch: 5| Step: 10
Training loss: 0.6834873007590144
Validation loss: 2.2545021617063417

Epoch: 382| Step: 0
Training loss: 0.5585308439673429
Validation loss: 2.27287326468763

Epoch: 5| Step: 1
Training loss: 0.28790342077341025
Validation loss: 2.2617584819542413

Epoch: 5| Step: 2
Training loss: 0.6632266225436998
Validation loss: 2.288220955442009

Epoch: 5| Step: 3
Training loss: 0.48203404084175183
Validation loss: 2.3167076045547845

Epoch: 5| Step: 4
Training loss: 0.6171360235838769
Validation loss: 2.263744128255467

Epoch: 5| Step: 5
Training loss: 0.547576644923762
Validation loss: 2.2685949512079646

Epoch: 5| Step: 6
Training loss: 0.39006756108696566
Validation loss: 2.251121153932361

Epoch: 5| Step: 7
Training loss: 0.6693018499131387
Validation loss: 2.258244164889876

Epoch: 5| Step: 8
Training loss: 0.5570489289419576
Validation loss: 2.2478281343786057

Epoch: 5| Step: 9
Training loss: 0.7024482012891661
Validation loss: 2.2479219023531893

Epoch: 5| Step: 10
Training loss: 0.36014265502293996
Validation loss: 2.2664950308821883

Epoch: 383| Step: 0
Training loss: 0.2902684444593031
Validation loss: 2.2480277369647768

Epoch: 5| Step: 1
Training loss: 0.5712303457489231
Validation loss: 2.2766592116712707

Epoch: 5| Step: 2
Training loss: 0.6745131838749335
Validation loss: 2.2340896278492894

Epoch: 5| Step: 3
Training loss: 0.5561325431427059
Validation loss: 2.274045314854571

Epoch: 5| Step: 4
Training loss: 0.571546030532045
Validation loss: 2.2933231828989116

Epoch: 5| Step: 5
Training loss: 0.5555760426187647
Validation loss: 2.276884342037174

Epoch: 5| Step: 6
Training loss: 0.5454286249460909
Validation loss: 2.2621633016364875

Epoch: 5| Step: 7
Training loss: 0.6788534769457929
Validation loss: 2.2820623684539365

Epoch: 5| Step: 8
Training loss: 0.4149601042196085
Validation loss: 2.2644674634800843

Epoch: 5| Step: 9
Training loss: 0.3271878574591636
Validation loss: 2.2670361360097626

Epoch: 5| Step: 10
Training loss: 0.5901737931855539
Validation loss: 2.2647308537103847

Epoch: 384| Step: 0
Training loss: 0.5466004090987712
Validation loss: 2.2529305762107983

Epoch: 5| Step: 1
Training loss: 0.4173844254872666
Validation loss: 2.2553809163695995

Epoch: 5| Step: 2
Training loss: 0.6611368243998704
Validation loss: 2.2445829262211863

Epoch: 5| Step: 3
Training loss: 0.2994240945129513
Validation loss: 2.2367287688492095

Epoch: 5| Step: 4
Training loss: 0.5943948857523823
Validation loss: 2.236332382582843

Epoch: 5| Step: 5
Training loss: 0.603347483301292
Validation loss: 2.214573212691739

Epoch: 5| Step: 6
Training loss: 0.14309642593970784
Validation loss: 2.2373077939275583

Epoch: 5| Step: 7
Training loss: 0.527815826477807
Validation loss: 2.2418081991704026

Epoch: 5| Step: 8
Training loss: 0.5528668356113013
Validation loss: 2.259348981276283

Epoch: 5| Step: 9
Training loss: 0.4251250889359392
Validation loss: 2.2531941869519323

Epoch: 5| Step: 10
Training loss: 0.8711640881250332
Validation loss: 2.2569988612915792

Epoch: 385| Step: 0
Training loss: 0.5673866468815413
Validation loss: 2.2620737817754786

Epoch: 5| Step: 1
Training loss: 0.36700207512708016
Validation loss: 2.2692315532768377

Epoch: 5| Step: 2
Training loss: 0.3910060549850125
Validation loss: 2.268729118292427

Epoch: 5| Step: 3
Training loss: 0.7870216036719077
Validation loss: 2.26235525744339

Epoch: 5| Step: 4
Training loss: 0.5157099856073588
Validation loss: 2.2711100839136233

Epoch: 5| Step: 5
Training loss: 0.46917573351198755
Validation loss: 2.2764905445301635

Epoch: 5| Step: 6
Training loss: 0.3830131277506291
Validation loss: 2.2901069100536575

Epoch: 5| Step: 7
Training loss: 0.36744157644632996
Validation loss: 2.270687239313525

Epoch: 5| Step: 8
Training loss: 0.7407801888037263
Validation loss: 2.2664949517049364

Epoch: 5| Step: 9
Training loss: 0.4822590510694136
Validation loss: 2.300137717505315

Epoch: 5| Step: 10
Training loss: 0.5647744976554631
Validation loss: 2.28049820432527

Epoch: 386| Step: 0
Training loss: 0.5047100369172135
Validation loss: 2.2779226475461534

Epoch: 5| Step: 1
Training loss: 0.47599629082256373
Validation loss: 2.236426128169691

Epoch: 5| Step: 2
Training loss: 0.4019205404555391
Validation loss: 2.262792139132858

Epoch: 5| Step: 3
Training loss: 0.5025527578623395
Validation loss: 2.2503349654184026

Epoch: 5| Step: 4
Training loss: 0.5215983177032137
Validation loss: 2.2252107763978666

Epoch: 5| Step: 5
Training loss: 0.527667927882474
Validation loss: 2.220344167756889

Epoch: 5| Step: 6
Training loss: 0.5668858569366229
Validation loss: 2.2026948621660196

Epoch: 5| Step: 7
Training loss: 0.39699739235999293
Validation loss: 2.2113137447735047

Epoch: 5| Step: 8
Training loss: 0.7465783188342746
Validation loss: 2.25721870474539

Epoch: 5| Step: 9
Training loss: 0.5445856951035078
Validation loss: 2.2199762570243107

Epoch: 5| Step: 10
Training loss: 0.4968030169665677
Validation loss: 2.275470519966071

Epoch: 387| Step: 0
Training loss: 0.527482417206812
Validation loss: 2.263942790170387

Epoch: 5| Step: 1
Training loss: 0.4112999546877843
Validation loss: 2.25411086732637

Epoch: 5| Step: 2
Training loss: 0.3935366264344956
Validation loss: 2.273514340120576

Epoch: 5| Step: 3
Training loss: 0.2066576303504889
Validation loss: 2.2685149672188873

Epoch: 5| Step: 4
Training loss: 0.6231107290426323
Validation loss: 2.2871865454549605

Epoch: 5| Step: 5
Training loss: 0.5498297026721424
Validation loss: 2.309007203589769

Epoch: 5| Step: 6
Training loss: 0.6184508515661673
Validation loss: 2.3028532893685614

Epoch: 5| Step: 7
Training loss: 0.687525705377153
Validation loss: 2.2914343704070017

Epoch: 5| Step: 8
Training loss: 0.3145332234411208
Validation loss: 2.301111196366945

Epoch: 5| Step: 9
Training loss: 0.44575184347698976
Validation loss: 2.3250758267988325

Epoch: 5| Step: 10
Training loss: 0.6955790490999229
Validation loss: 2.33304055709296

Epoch: 388| Step: 0
Training loss: 0.3736744739299329
Validation loss: 2.2831154973885437

Epoch: 5| Step: 1
Training loss: 0.5536165779353411
Validation loss: 2.3154511310706525

Epoch: 5| Step: 2
Training loss: 0.41393191599661344
Validation loss: 2.302171119623839

Epoch: 5| Step: 3
Training loss: 0.4444778886354553
Validation loss: 2.2839447907870283

Epoch: 5| Step: 4
Training loss: 0.661366093329192
Validation loss: 2.307825461241881

Epoch: 5| Step: 5
Training loss: 0.6253034093635449
Validation loss: 2.280893794429027

Epoch: 5| Step: 6
Training loss: 0.5544256747544294
Validation loss: 2.259578703945493

Epoch: 5| Step: 7
Training loss: 0.2929559450530086
Validation loss: 2.2690100389503636

Epoch: 5| Step: 8
Training loss: 0.5116648754850632
Validation loss: 2.2507888369368962

Epoch: 5| Step: 9
Training loss: 0.627923659893431
Validation loss: 2.2783042182391005

Epoch: 5| Step: 10
Training loss: 0.42150044591773755
Validation loss: 2.271103639556189

Epoch: 389| Step: 0
Training loss: 0.6501425421749614
Validation loss: 2.2684476593729315

Epoch: 5| Step: 1
Training loss: 0.3722675631653806
Validation loss: 2.254872283380161

Epoch: 5| Step: 2
Training loss: 0.5270268653757358
Validation loss: 2.2370882994817047

Epoch: 5| Step: 3
Training loss: 0.5401288970121606
Validation loss: 2.24754827840723

Epoch: 5| Step: 4
Training loss: 0.3925879937445062
Validation loss: 2.2545718189266686

Epoch: 5| Step: 5
Training loss: 0.37229942416516204
Validation loss: 2.282581591947869

Epoch: 5| Step: 6
Training loss: 0.5979262097579611
Validation loss: 2.3236077070466155

Epoch: 5| Step: 7
Training loss: 0.6079341286218389
Validation loss: 2.2441176495216264

Epoch: 5| Step: 8
Training loss: 0.46332754769017687
Validation loss: 2.2828946502888052

Epoch: 5| Step: 9
Training loss: 0.34138060152618666
Validation loss: 2.236598045336958

Epoch: 5| Step: 10
Training loss: 0.6068005343086565
Validation loss: 2.2221368904889682

Epoch: 390| Step: 0
Training loss: 0.555240570287143
Validation loss: 2.2406391052451085

Epoch: 5| Step: 1
Training loss: 0.40291495654516746
Validation loss: 2.2266286567051994

Epoch: 5| Step: 2
Training loss: 0.6313040851802247
Validation loss: 2.243286453476671

Epoch: 5| Step: 3
Training loss: 0.419250270584101
Validation loss: 2.2419655594158856

Epoch: 5| Step: 4
Training loss: 0.23298638973576322
Validation loss: 2.2344523608016305

Epoch: 5| Step: 5
Training loss: 0.3291312976840238
Validation loss: 2.245066444906794

Epoch: 5| Step: 6
Training loss: 0.5131173277082701
Validation loss: 2.2720667817782965

Epoch: 5| Step: 7
Training loss: 0.6926614606864819
Validation loss: 2.2463554229184637

Epoch: 5| Step: 8
Training loss: 0.47132526927344015
Validation loss: 2.233067477663988

Epoch: 5| Step: 9
Training loss: 0.5434176284201612
Validation loss: 2.251150501917577

Epoch: 5| Step: 10
Training loss: 0.5592240998448429
Validation loss: 2.2605345526899723

Epoch: 391| Step: 0
Training loss: 0.5884022814907418
Validation loss: 2.267953470349381

Epoch: 5| Step: 1
Training loss: 0.3855579177527265
Validation loss: 2.293225203840067

Epoch: 5| Step: 2
Training loss: 0.36514815674522505
Validation loss: 2.277780377036945

Epoch: 5| Step: 3
Training loss: 0.6164893293779895
Validation loss: 2.275339176758756

Epoch: 5| Step: 4
Training loss: 0.5348671459415677
Validation loss: 2.2542991322066652

Epoch: 5| Step: 5
Training loss: 0.3838713657178545
Validation loss: 2.2664494695721884

Epoch: 5| Step: 6
Training loss: 0.6704444737552216
Validation loss: 2.2058857249142285

Epoch: 5| Step: 7
Training loss: 0.5244452611071394
Validation loss: 2.227496775141917

Epoch: 5| Step: 8
Training loss: 0.5367404294806463
Validation loss: 2.2094340256222713

Epoch: 5| Step: 9
Training loss: 0.4684669593775287
Validation loss: 2.215830267059202

Epoch: 5| Step: 10
Training loss: 0.22369777785279507
Validation loss: 2.2203073329530136

Epoch: 392| Step: 0
Training loss: 0.5985137920702618
Validation loss: 2.2542469796976365

Epoch: 5| Step: 1
Training loss: 0.4207373928327766
Validation loss: 2.256643109479086

Epoch: 5| Step: 2
Training loss: 0.40351065146085235
Validation loss: 2.2256430960845863

Epoch: 5| Step: 3
Training loss: 0.45927604984958537
Validation loss: 2.2823413469662697

Epoch: 5| Step: 4
Training loss: 0.36466868854635753
Validation loss: 2.2627153767616246

Epoch: 5| Step: 5
Training loss: 0.5185718713129459
Validation loss: 2.2742107928231796

Epoch: 5| Step: 6
Training loss: 0.7040771395485768
Validation loss: 2.2830671629615775

Epoch: 5| Step: 7
Training loss: 0.4382672904336309
Validation loss: 2.2870051124282056

Epoch: 5| Step: 8
Training loss: 0.47722629531811656
Validation loss: 2.305151981123741

Epoch: 5| Step: 9
Training loss: 0.3716538468888387
Validation loss: 2.2728592512492485

Epoch: 5| Step: 10
Training loss: 0.5452740532730641
Validation loss: 2.259486945210899

Epoch: 393| Step: 0
Training loss: 0.4407794350333509
Validation loss: 2.275035684741353

Epoch: 5| Step: 1
Training loss: 0.3535632738911098
Validation loss: 2.2527498459298116

Epoch: 5| Step: 2
Training loss: 0.4985906586869492
Validation loss: 2.2719883310385764

Epoch: 5| Step: 3
Training loss: 0.4711852868824222
Validation loss: 2.246159302342098

Epoch: 5| Step: 4
Training loss: 0.5238176644893022
Validation loss: 2.2463444053176262

Epoch: 5| Step: 5
Training loss: 0.44313953007279355
Validation loss: 2.2412824393016333

Epoch: 5| Step: 6
Training loss: 0.33072167360523297
Validation loss: 2.2315153901735005

Epoch: 5| Step: 7
Training loss: 0.5408779203152265
Validation loss: 2.276341476249827

Epoch: 5| Step: 8
Training loss: 0.7688171636503389
Validation loss: 2.2579955662544378

Epoch: 5| Step: 9
Training loss: 0.44142073210868427
Validation loss: 2.2547198165326217

Epoch: 5| Step: 10
Training loss: 0.3370800217704329
Validation loss: 2.2775194200982463

Epoch: 394| Step: 0
Training loss: 0.4651060566395645
Validation loss: 2.2571691638356874

Epoch: 5| Step: 1
Training loss: 0.5167112180001121
Validation loss: 2.293547770172978

Epoch: 5| Step: 2
Training loss: 0.5573309917182114
Validation loss: 2.292164124522312

Epoch: 5| Step: 3
Training loss: 0.48367867101627904
Validation loss: 2.280926157595147

Epoch: 5| Step: 4
Training loss: 0.5489362019729078
Validation loss: 2.2792743022674866

Epoch: 5| Step: 5
Training loss: 0.5176646610109802
Validation loss: 2.2693146842038407

Epoch: 5| Step: 6
Training loss: 0.36693883145623085
Validation loss: 2.2886858425179692

Epoch: 5| Step: 7
Training loss: 0.41930514445998457
Validation loss: 2.3024170774267514

Epoch: 5| Step: 8
Training loss: 0.5298339258766441
Validation loss: 2.2809075545067152

Epoch: 5| Step: 9
Training loss: 0.3522502847099101
Validation loss: 2.2924043387318855

Epoch: 5| Step: 10
Training loss: 0.5083742409281413
Validation loss: 2.2955551473895497

Epoch: 395| Step: 0
Training loss: 0.4398355473080433
Validation loss: 2.2700059287845926

Epoch: 5| Step: 1
Training loss: 0.6455306425688687
Validation loss: 2.3045211451083056

Epoch: 5| Step: 2
Training loss: 0.45535199679343924
Validation loss: 2.25822040994642

Epoch: 5| Step: 3
Training loss: 0.34739520956018693
Validation loss: 2.275398764696297

Epoch: 5| Step: 4
Training loss: 0.26247596801014683
Validation loss: 2.2624114049184523

Epoch: 5| Step: 5
Training loss: 0.5268192084334826
Validation loss: 2.225604022173241

Epoch: 5| Step: 6
Training loss: 0.6254362967670082
Validation loss: 2.2446576607068596

Epoch: 5| Step: 7
Training loss: 0.494741775272776
Validation loss: 2.2282589373481607

Epoch: 5| Step: 8
Training loss: 0.5525779098279489
Validation loss: 2.2400637663415117

Epoch: 5| Step: 9
Training loss: 0.1773540178763083
Validation loss: 2.234163019674918

Epoch: 5| Step: 10
Training loss: 0.47628618265609585
Validation loss: 2.243551541889712

Epoch: 396| Step: 0
Training loss: 0.29338753332729717
Validation loss: 2.265499972782268

Epoch: 5| Step: 1
Training loss: 0.4498955976387402
Validation loss: 2.2686603020033234

Epoch: 5| Step: 2
Training loss: 0.31088120080218884
Validation loss: 2.280076090527615

Epoch: 5| Step: 3
Training loss: 0.582446340741676
Validation loss: 2.2727024457643825

Epoch: 5| Step: 4
Training loss: 0.5708589940208834
Validation loss: 2.3184021906083427

Epoch: 5| Step: 5
Training loss: 0.32162868093051394
Validation loss: 2.3396163343173217

Epoch: 5| Step: 6
Training loss: 0.6054811045709033
Validation loss: 2.3226055373019547

Epoch: 5| Step: 7
Training loss: 0.5319980795850726
Validation loss: 2.326835053079068

Epoch: 5| Step: 8
Training loss: 0.2504125558708272
Validation loss: 2.290508351915396

Epoch: 5| Step: 9
Training loss: 0.48116456796901724
Validation loss: 2.2754123067564413

Epoch: 5| Step: 10
Training loss: 0.6467480309127954
Validation loss: 2.2806346190846924

Epoch: 397| Step: 0
Training loss: 0.15420767463174745
Validation loss: 2.239245202384662

Epoch: 5| Step: 1
Training loss: 0.277822886552807
Validation loss: 2.262715278191233

Epoch: 5| Step: 2
Training loss: 0.2974349563483455
Validation loss: 2.2456756804793243

Epoch: 5| Step: 3
Training loss: 0.49948212507032774
Validation loss: 2.2619837557267943

Epoch: 5| Step: 4
Training loss: 0.5462217243741486
Validation loss: 2.25472407690782

Epoch: 5| Step: 5
Training loss: 0.4467206408262848
Validation loss: 2.227968518613677

Epoch: 5| Step: 6
Training loss: 0.6975515511306908
Validation loss: 2.225865939727352

Epoch: 5| Step: 7
Training loss: 0.29713210467076046
Validation loss: 2.2541883776204914

Epoch: 5| Step: 8
Training loss: 0.5491173141813451
Validation loss: 2.2835725448442425

Epoch: 5| Step: 9
Training loss: 0.4874473164285667
Validation loss: 2.29923872304423

Epoch: 5| Step: 10
Training loss: 0.6315412821879178
Validation loss: 2.277287334080433

Epoch: 398| Step: 0
Training loss: 0.4549129824954171
Validation loss: 2.272083105830897

Epoch: 5| Step: 1
Training loss: 0.524645876661999
Validation loss: 2.2758302767600194

Epoch: 5| Step: 2
Training loss: 0.6618740147339257
Validation loss: 2.304817663500369

Epoch: 5| Step: 3
Training loss: 0.4081275541450529
Validation loss: 2.284967077499208

Epoch: 5| Step: 4
Training loss: 0.35635475157900015
Validation loss: 2.2655881590883586

Epoch: 5| Step: 5
Training loss: 0.5538441869403278
Validation loss: 2.294424425476261

Epoch: 5| Step: 6
Training loss: 0.5218584526316785
Validation loss: 2.284271953165219

Epoch: 5| Step: 7
Training loss: 0.32537742762002553
Validation loss: 2.276510408940232

Epoch: 5| Step: 8
Training loss: 0.3352555183529673
Validation loss: 2.3059515443944103

Epoch: 5| Step: 9
Training loss: 0.4338529516556462
Validation loss: 2.2827401827979164

Epoch: 5| Step: 10
Training loss: 0.402746369472789
Validation loss: 2.2870744147135507

Epoch: 399| Step: 0
Training loss: 0.34834837864289997
Validation loss: 2.2879360733692575

Epoch: 5| Step: 1
Training loss: 0.6436638978208468
Validation loss: 2.2711302544423067

Epoch: 5| Step: 2
Training loss: 0.4486642151447241
Validation loss: 2.25817590323775

Epoch: 5| Step: 3
Training loss: 0.3350693552261963
Validation loss: 2.2687693472656276

Epoch: 5| Step: 4
Training loss: 0.46417868344670976
Validation loss: 2.2736274835222137

Epoch: 5| Step: 5
Training loss: 0.47063287234466245
Validation loss: 2.308232557370641

Epoch: 5| Step: 6
Training loss: 0.40612912213695357
Validation loss: 2.2815164356227275

Epoch: 5| Step: 7
Training loss: 0.3292858841443163
Validation loss: 2.328880299307883

Epoch: 5| Step: 8
Training loss: 0.5234087181718662
Validation loss: 2.3190458863802546

Epoch: 5| Step: 9
Training loss: 0.40903821880411595
Validation loss: 2.290908904846853

Epoch: 5| Step: 10
Training loss: 0.5225050577804129
Validation loss: 2.300227680769926

Epoch: 400| Step: 0
Training loss: 0.43676322819701013
Validation loss: 2.2764766299366785

Epoch: 5| Step: 1
Training loss: 0.3890841420600239
Validation loss: 2.2700869731803346

Epoch: 5| Step: 2
Training loss: 0.42499711512540167
Validation loss: 2.2525066480997955

Epoch: 5| Step: 3
Training loss: 0.3239464018097432
Validation loss: 2.2334058176879483

Epoch: 5| Step: 4
Training loss: 0.6446556433657668
Validation loss: 2.2381042153895954

Epoch: 5| Step: 5
Training loss: 0.4717412556968399
Validation loss: 2.235079025577703

Epoch: 5| Step: 6
Training loss: 0.42968392804135
Validation loss: 2.2468866516173547

Epoch: 5| Step: 7
Training loss: 0.6388060169329535
Validation loss: 2.273208357969623

Epoch: 5| Step: 8
Training loss: 0.4501191279561416
Validation loss: 2.3022100484912777

Epoch: 5| Step: 9
Training loss: 0.4214966808428239
Validation loss: 2.3063541671510084

Epoch: 5| Step: 10
Training loss: 0.3487923414751448
Validation loss: 2.337425771625611

Epoch: 401| Step: 0
Training loss: 0.5077463547102905
Validation loss: 2.3117002508310054

Epoch: 5| Step: 1
Training loss: 0.4870888455614465
Validation loss: 2.3004862724055255

Epoch: 5| Step: 2
Training loss: 0.4754148328223648
Validation loss: 2.317345102368243

Epoch: 5| Step: 3
Training loss: 0.4763792655011136
Validation loss: 2.308943623736782

Epoch: 5| Step: 4
Training loss: 0.38498393028336086
Validation loss: 2.3095160999242967

Epoch: 5| Step: 5
Training loss: 0.5155194781440974
Validation loss: 2.3158932473173586

Epoch: 5| Step: 6
Training loss: 0.3929932520301627
Validation loss: 2.296921789906396

Epoch: 5| Step: 7
Training loss: 0.5233123117171153
Validation loss: 2.295699691061478

Epoch: 5| Step: 8
Training loss: 0.3368763778177087
Validation loss: 2.273446262947292

Epoch: 5| Step: 9
Training loss: 0.3784515759711325
Validation loss: 2.270212883664359

Epoch: 5| Step: 10
Training loss: 0.45356287024258024
Validation loss: 2.270928300638739

Epoch: 402| Step: 0
Training loss: 0.44935128288658943
Validation loss: 2.273901284247477

Epoch: 5| Step: 1
Training loss: 0.594938919915269
Validation loss: 2.2652565865557954

Epoch: 5| Step: 2
Training loss: 0.48132367560966727
Validation loss: 2.2455374114224544

Epoch: 5| Step: 3
Training loss: 0.5146033250989653
Validation loss: 2.2131238657210295

Epoch: 5| Step: 4
Training loss: 0.348319225166269
Validation loss: 2.245930597872238

Epoch: 5| Step: 5
Training loss: 0.3595416056017386
Validation loss: 2.2277718392111936

Epoch: 5| Step: 6
Training loss: 0.45178481572544854
Validation loss: 2.2421581141615112

Epoch: 5| Step: 7
Training loss: 0.578163506540016
Validation loss: 2.2682196911014327

Epoch: 5| Step: 8
Training loss: 0.2953925639817575
Validation loss: 2.2796269294261298

Epoch: 5| Step: 9
Training loss: 0.4137043573668259
Validation loss: 2.3154513840631883

Epoch: 5| Step: 10
Training loss: 0.3985063082053324
Validation loss: 2.2859112974701237

Epoch: 403| Step: 0
Training loss: 0.3202057986364932
Validation loss: 2.316105852423265

Epoch: 5| Step: 1
Training loss: 0.1613930075273201
Validation loss: 2.28306363202112

Epoch: 5| Step: 2
Training loss: 0.3766406251266027
Validation loss: 2.265006253932595

Epoch: 5| Step: 3
Training loss: 0.4118918979518454
Validation loss: 2.3072937403558718

Epoch: 5| Step: 4
Training loss: 0.6887943481318659
Validation loss: 2.2901998984891625

Epoch: 5| Step: 5
Training loss: 0.4815073805101758
Validation loss: 2.271406637772514

Epoch: 5| Step: 6
Training loss: 0.27151659218615387
Validation loss: 2.26705976352388

Epoch: 5| Step: 7
Training loss: 0.3843007256302744
Validation loss: 2.2530988332310375

Epoch: 5| Step: 8
Training loss: 0.42816186036193643
Validation loss: 2.261449303979801

Epoch: 5| Step: 9
Training loss: 0.5116399456817082
Validation loss: 2.2579094179419554

Epoch: 5| Step: 10
Training loss: 0.5942452022052287
Validation loss: 2.2550694423981086

Epoch: 404| Step: 0
Training loss: 0.34548845468724115
Validation loss: 2.2634557062153755

Epoch: 5| Step: 1
Training loss: 0.5477474066038733
Validation loss: 2.247991964755227

Epoch: 5| Step: 2
Training loss: 0.5949111927498623
Validation loss: 2.2454534441716265

Epoch: 5| Step: 3
Training loss: 0.3776215472551255
Validation loss: 2.283921456933259

Epoch: 5| Step: 4
Training loss: 0.3466797197368768
Validation loss: 2.2486554529951004

Epoch: 5| Step: 5
Training loss: 0.47921261532553733
Validation loss: 2.24629750287521

Epoch: 5| Step: 6
Training loss: 0.4673405119217164
Validation loss: 2.290995325177379

Epoch: 5| Step: 7
Training loss: 0.4594619863246198
Validation loss: 2.3118162205708934

Epoch: 5| Step: 8
Training loss: 0.41225994667883437
Validation loss: 2.266170625257866

Epoch: 5| Step: 9
Training loss: 0.4492157314033261
Validation loss: 2.2960232225478125

Epoch: 5| Step: 10
Training loss: 0.14802968320446214
Validation loss: 2.2783633522462376

Epoch: 405| Step: 0
Training loss: 0.3709324737246858
Validation loss: 2.2981072126437425

Epoch: 5| Step: 1
Training loss: 0.451562192448178
Validation loss: 2.2694266446974365

Epoch: 5| Step: 2
Training loss: 0.26201423646653477
Validation loss: 2.2708300575156706

Epoch: 5| Step: 3
Training loss: 0.3837364102420712
Validation loss: 2.2961108647320128

Epoch: 5| Step: 4
Training loss: 0.44228658408492305
Validation loss: 2.2726397972481642

Epoch: 5| Step: 5
Training loss: 0.4244758999782687
Validation loss: 2.2639233143050355

Epoch: 5| Step: 6
Training loss: 0.42433026009123714
Validation loss: 2.273169532135831

Epoch: 5| Step: 7
Training loss: 0.1374707792400722
Validation loss: 2.2404568372162346

Epoch: 5| Step: 8
Training loss: 0.5072012523730427
Validation loss: 2.2431693562587625

Epoch: 5| Step: 9
Training loss: 0.651348085137637
Validation loss: 2.2349380155569425

Epoch: 5| Step: 10
Training loss: 0.4865075205646034
Validation loss: 2.2465158407801566

Epoch: 406| Step: 0
Training loss: 0.3699411461713773
Validation loss: 2.243087767900083

Epoch: 5| Step: 1
Training loss: 0.3588561375881748
Validation loss: 2.222872504419085

Epoch: 5| Step: 2
Training loss: 0.5271082599560817
Validation loss: 2.2480588809491815

Epoch: 5| Step: 3
Training loss: 0.5550936434332873
Validation loss: 2.2453896003813743

Epoch: 5| Step: 4
Training loss: 0.4163979756748104
Validation loss: 2.2650657294502508

Epoch: 5| Step: 5
Training loss: 0.3826852898503524
Validation loss: 2.247285462156739

Epoch: 5| Step: 6
Training loss: 0.3503118522154836
Validation loss: 2.2559381996904415

Epoch: 5| Step: 7
Training loss: 0.3541561246686764
Validation loss: 2.256371164475828

Epoch: 5| Step: 8
Training loss: 0.3753902074075176
Validation loss: 2.279893020047036

Epoch: 5| Step: 9
Training loss: 0.6296794474349532
Validation loss: 2.2510917309702965

Epoch: 5| Step: 10
Training loss: 0.30833079808498803
Validation loss: 2.282627550050353

Epoch: 407| Step: 0
Training loss: 0.3224308052979933
Validation loss: 2.2775973128172255

Epoch: 5| Step: 1
Training loss: 0.388428885256191
Validation loss: 2.266413707600488

Epoch: 5| Step: 2
Training loss: 0.582499885067908
Validation loss: 2.289280830993375

Epoch: 5| Step: 3
Training loss: 0.4246402641508489
Validation loss: 2.2715446086023876

Epoch: 5| Step: 4
Training loss: 0.434987705676317
Validation loss: 2.2997453557081755

Epoch: 5| Step: 5
Training loss: 0.25170042983576524
Validation loss: 2.2904039004460968

Epoch: 5| Step: 6
Training loss: 0.3765466306832742
Validation loss: 2.2812039894209817

Epoch: 5| Step: 7
Training loss: 0.3901252983627474
Validation loss: 2.2766197864991495

Epoch: 5| Step: 8
Training loss: 0.49079139949161843
Validation loss: 2.263081705485961

Epoch: 5| Step: 9
Training loss: 0.3794595277311651
Validation loss: 2.296419192345475

Epoch: 5| Step: 10
Training loss: 0.5323931512060384
Validation loss: 2.2978479923579855

Epoch: 408| Step: 0
Training loss: 0.3512769387052473
Validation loss: 2.268925927979552

Epoch: 5| Step: 1
Training loss: 0.24877648169484826
Validation loss: 2.243394548867266

Epoch: 5| Step: 2
Training loss: 0.2899803076421373
Validation loss: 2.2873156050435597

Epoch: 5| Step: 3
Training loss: 0.3681408093138985
Validation loss: 2.258531009520025

Epoch: 5| Step: 4
Training loss: 0.40809529536689537
Validation loss: 2.3072013658607355

Epoch: 5| Step: 5
Training loss: 0.4396926227263026
Validation loss: 2.2890656761823007

Epoch: 5| Step: 6
Training loss: 0.49782374750662806
Validation loss: 2.280224752761707

Epoch: 5| Step: 7
Training loss: 0.2902312877999122
Validation loss: 2.3277013789285266

Epoch: 5| Step: 8
Training loss: 0.6536352427765765
Validation loss: 2.2945170730210447

Epoch: 5| Step: 9
Training loss: 0.41406967948591256
Validation loss: 2.2768078841973005

Epoch: 5| Step: 10
Training loss: 0.49840380276703383
Validation loss: 2.3052674134176954

Epoch: 409| Step: 0
Training loss: 0.41624770160991315
Validation loss: 2.29885380109632

Epoch: 5| Step: 1
Training loss: 0.541780805177556
Validation loss: 2.2998119242575

Epoch: 5| Step: 2
Training loss: 0.31411804685399913
Validation loss: 2.293521484730211

Epoch: 5| Step: 3
Training loss: 0.3155054290821258
Validation loss: 2.316700294423492

Epoch: 5| Step: 4
Training loss: 0.41043682492640526
Validation loss: 2.301634506492531

Epoch: 5| Step: 5
Training loss: 0.5613148708278571
Validation loss: 2.3434593452518104

Epoch: 5| Step: 6
Training loss: 0.34321587420567057
Validation loss: 2.2887439107795693

Epoch: 5| Step: 7
Training loss: 0.4961717949700355
Validation loss: 2.286191996320537

Epoch: 5| Step: 8
Training loss: 0.30724173749052236
Validation loss: 2.296050678797643

Epoch: 5| Step: 9
Training loss: 0.4369403972712471
Validation loss: 2.285549110205411

Epoch: 5| Step: 10
Training loss: 0.3244627643295054
Validation loss: 2.267760788975221

Epoch: 410| Step: 0
Training loss: 0.34718884969976005
Validation loss: 2.2637334784064205

Epoch: 5| Step: 1
Training loss: 0.42897696268253044
Validation loss: 2.2529524593234638

Epoch: 5| Step: 2
Training loss: 0.47141368939753886
Validation loss: 2.2584667408277808

Epoch: 5| Step: 3
Training loss: 0.6428540457734179
Validation loss: 2.2492203130640642

Epoch: 5| Step: 4
Training loss: 0.526146837302895
Validation loss: 2.2696509766432373

Epoch: 5| Step: 5
Training loss: 0.41690069619841447
Validation loss: 2.251780559127787

Epoch: 5| Step: 6
Training loss: 0.14016848878572913
Validation loss: 2.221896498489729

Epoch: 5| Step: 7
Training loss: 0.4211424719768888
Validation loss: 2.2266792754642237

Epoch: 5| Step: 8
Training loss: 0.44105870566101596
Validation loss: 2.258521764176203

Epoch: 5| Step: 9
Training loss: 0.22764465436027628
Validation loss: 2.2654345360549684

Epoch: 5| Step: 10
Training loss: 0.3380698682292727
Validation loss: 2.2564218726932275

Epoch: 411| Step: 0
Training loss: 0.4701701744149999
Validation loss: 2.2567596813854736

Epoch: 5| Step: 1
Training loss: 0.6847244720366139
Validation loss: 2.2443329360201094

Epoch: 5| Step: 2
Training loss: 0.21196489559438894
Validation loss: 2.243129993343412

Epoch: 5| Step: 3
Training loss: 0.2993978666440402
Validation loss: 2.2539517679973207

Epoch: 5| Step: 4
Training loss: 0.270410706205074
Validation loss: 2.2743633366774

Epoch: 5| Step: 5
Training loss: 0.5053461778183879
Validation loss: 2.247115007223689

Epoch: 5| Step: 6
Training loss: 0.43998823011977095
Validation loss: 2.220374039154087

Epoch: 5| Step: 7
Training loss: 0.2479468917587242
Validation loss: 2.2485473995898198

Epoch: 5| Step: 8
Training loss: 0.6346084869727947
Validation loss: 2.252621680869782

Epoch: 5| Step: 9
Training loss: 0.2723400025320561
Validation loss: 2.2888752766500544

Epoch: 5| Step: 10
Training loss: 0.305492023644841
Validation loss: 2.272579584776686

Epoch: 412| Step: 0
Training loss: 0.37057334147482796
Validation loss: 2.3305214188071517

Epoch: 5| Step: 1
Training loss: 0.37548990832151136
Validation loss: 2.321725213566644

Epoch: 5| Step: 2
Training loss: 0.49701535983499645
Validation loss: 2.311468576715623

Epoch: 5| Step: 3
Training loss: 0.3833051742010407
Validation loss: 2.3079257035505103

Epoch: 5| Step: 4
Training loss: 0.3544766551416509
Validation loss: 2.247123334335683

Epoch: 5| Step: 5
Training loss: 0.26805277305080144
Validation loss: 2.2315707943005187

Epoch: 5| Step: 6
Training loss: 0.4351545200279269
Validation loss: 2.2277030362437884

Epoch: 5| Step: 7
Training loss: 0.4842493140295051
Validation loss: 2.2061507416892483

Epoch: 5| Step: 8
Training loss: 0.5551168902053235
Validation loss: 2.2343826391340635

Epoch: 5| Step: 9
Training loss: 0.4484886040627217
Validation loss: 2.228298537650039

Epoch: 5| Step: 10
Training loss: 0.42481357959780186
Validation loss: 2.2260996514673397

Epoch: 413| Step: 0
Training loss: 0.3996377332661581
Validation loss: 2.2056879812470402

Epoch: 5| Step: 1
Training loss: 0.5169620518103165
Validation loss: 2.224325822073937

Epoch: 5| Step: 2
Training loss: 0.24449868457631463
Validation loss: 2.2326788326947273

Epoch: 5| Step: 3
Training loss: 0.20736529733483142
Validation loss: 2.221989066529647

Epoch: 5| Step: 4
Training loss: 0.4459091004789753
Validation loss: 2.2340241889742414

Epoch: 5| Step: 5
Training loss: 0.4142498276375761
Validation loss: 2.2366363323038008

Epoch: 5| Step: 6
Training loss: 0.5591219558786462
Validation loss: 2.266390450026027

Epoch: 5| Step: 7
Training loss: 0.4619351920523244
Validation loss: 2.227701948737531

Epoch: 5| Step: 8
Training loss: 0.35757588888198005
Validation loss: 2.281243279458852

Epoch: 5| Step: 9
Training loss: 0.39115429304839794
Validation loss: 2.2675600613527327

Epoch: 5| Step: 10
Training loss: 0.38246273099182476
Validation loss: 2.2584745538753026

Epoch: 414| Step: 0
Training loss: 0.39472784677303174
Validation loss: 2.262507342889401

Epoch: 5| Step: 1
Training loss: 0.2825012322415847
Validation loss: 2.301751922849512

Epoch: 5| Step: 2
Training loss: 0.3543503953240107
Validation loss: 2.288425075558349

Epoch: 5| Step: 3
Training loss: 0.43581083022946165
Validation loss: 2.323824521116784

Epoch: 5| Step: 4
Training loss: 0.37142459777524733
Validation loss: 2.315680534125655

Epoch: 5| Step: 5
Training loss: 0.2409943600613961
Validation loss: 2.328976764062707

Epoch: 5| Step: 6
Training loss: 0.45919721822240817
Validation loss: 2.329557632259118

Epoch: 5| Step: 7
Training loss: 0.605116563318576
Validation loss: 2.287019911290693

Epoch: 5| Step: 8
Training loss: 0.4490342798039888
Validation loss: 2.288954252938255

Epoch: 5| Step: 9
Training loss: 0.3388080820211807
Validation loss: 2.3111183109580824

Epoch: 5| Step: 10
Training loss: 0.4341376905082967
Validation loss: 2.298778522840912

Epoch: 415| Step: 0
Training loss: 0.4566969015329163
Validation loss: 2.3267689028773866

Epoch: 5| Step: 1
Training loss: 0.3379027965315908
Validation loss: 2.2891246408255825

Epoch: 5| Step: 2
Training loss: 0.4637532947659734
Validation loss: 2.2944926545214486

Epoch: 5| Step: 3
Training loss: 0.48631513340767346
Validation loss: 2.291404676051024

Epoch: 5| Step: 4
Training loss: 0.30766481303343396
Validation loss: 2.3291243369594334

Epoch: 5| Step: 5
Training loss: 0.32536538290641337
Validation loss: 2.2860888626607645

Epoch: 5| Step: 6
Training loss: 0.23014996998513454
Validation loss: 2.3075607573627464

Epoch: 5| Step: 7
Training loss: 0.4793015079538639
Validation loss: 2.3094171163781607

Epoch: 5| Step: 8
Training loss: 0.43140157924335626
Validation loss: 2.2950761805393665

Epoch: 5| Step: 9
Training loss: 0.3949830518176961
Validation loss: 2.3078315470083046

Epoch: 5| Step: 10
Training loss: 0.38375809716867826
Validation loss: 2.294847095591607

Epoch: 416| Step: 0
Training loss: 0.55090103470142
Validation loss: 2.3169607597792052

Epoch: 5| Step: 1
Training loss: 0.46766801573956873
Validation loss: 2.3426730027002307

Epoch: 5| Step: 2
Training loss: 0.23989674638123598
Validation loss: 2.310191868647734

Epoch: 5| Step: 3
Training loss: 0.17560958957599612
Validation loss: 2.2924607382489923

Epoch: 5| Step: 4
Training loss: 0.21486713975684543
Validation loss: 2.268609062745527

Epoch: 5| Step: 5
Training loss: 0.4613177783655302
Validation loss: 2.2795340495144076

Epoch: 5| Step: 6
Training loss: 0.3797411617772419
Validation loss: 2.289617445214627

Epoch: 5| Step: 7
Training loss: 0.4573807154640044
Validation loss: 2.269094454111087

Epoch: 5| Step: 8
Training loss: 0.20645247837647604
Validation loss: 2.2796928945429467

Epoch: 5| Step: 9
Training loss: 0.5187479582137405
Validation loss: 2.2726551972703843

Epoch: 5| Step: 10
Training loss: 0.5025805400243035
Validation loss: 2.281654508595414

Epoch: 417| Step: 0
Training loss: 0.3224740250425227
Validation loss: 2.2992619059120356

Epoch: 5| Step: 1
Training loss: 0.41698596958643547
Validation loss: 2.2995444233147047

Epoch: 5| Step: 2
Training loss: 0.5273673723369494
Validation loss: 2.2957117437271006

Epoch: 5| Step: 3
Training loss: 0.5371000809298866
Validation loss: 2.3025414410047578

Epoch: 5| Step: 4
Training loss: 0.5022213586527415
Validation loss: 2.2739963440174074

Epoch: 5| Step: 5
Training loss: 0.3286989165639299
Validation loss: 2.318805867112423

Epoch: 5| Step: 6
Training loss: 0.3052699073592275
Validation loss: 2.2887521928440124

Epoch: 5| Step: 7
Training loss: 0.34095016235697895
Validation loss: 2.2665586296817817

Epoch: 5| Step: 8
Training loss: 0.31098844216326416
Validation loss: 2.2450987610058584

Epoch: 5| Step: 9
Training loss: 0.4329629209766885
Validation loss: 2.2759006909287227

Epoch: 5| Step: 10
Training loss: 0.3357709205497781
Validation loss: 2.275202091818961

Epoch: 418| Step: 0
Training loss: 0.49635179071434804
Validation loss: 2.2748250078820704

Epoch: 5| Step: 1
Training loss: 0.34583720608155266
Validation loss: 2.2629589169245388

Epoch: 5| Step: 2
Training loss: 0.5308866941539636
Validation loss: 2.2881730515322998

Epoch: 5| Step: 3
Training loss: 0.31592349912823187
Validation loss: 2.2939882591313943

Epoch: 5| Step: 4
Training loss: 0.4167774013556967
Validation loss: 2.283061971258877

Epoch: 5| Step: 5
Training loss: 0.4223939035593425
Validation loss: 2.2768690426803526

Epoch: 5| Step: 6
Training loss: 0.5511155973667586
Validation loss: 2.2732879084269477

Epoch: 5| Step: 7
Training loss: 0.28368692837725
Validation loss: 2.285104681694727

Epoch: 5| Step: 8
Training loss: 0.370439414315308
Validation loss: 2.261687558345659

Epoch: 5| Step: 9
Training loss: 0.17286596938617055
Validation loss: 2.2727169203965274

Epoch: 5| Step: 10
Training loss: 0.19382477632495163
Validation loss: 2.280833762765748

Epoch: 419| Step: 0
Training loss: 0.4455561389658991
Validation loss: 2.2811939683821514

Epoch: 5| Step: 1
Training loss: 0.2584819626989897
Validation loss: 2.2732772666374097

Epoch: 5| Step: 2
Training loss: 0.2274754480328808
Validation loss: 2.286808469702112

Epoch: 5| Step: 3
Training loss: 0.37677950640880303
Validation loss: 2.3053038910048547

Epoch: 5| Step: 4
Training loss: 0.39263277954439046
Validation loss: 2.332354328857904

Epoch: 5| Step: 5
Training loss: 0.47608007182900375
Validation loss: 2.2820888735077562

Epoch: 5| Step: 6
Training loss: 0.38849754833002637
Validation loss: 2.270571233415179

Epoch: 5| Step: 7
Training loss: 0.21976885070765928
Validation loss: 2.2924904594634836

Epoch: 5| Step: 8
Training loss: 0.527615343021313
Validation loss: 2.2764244877433844

Epoch: 5| Step: 9
Training loss: 0.32208777635371283
Validation loss: 2.252305183056124

Epoch: 5| Step: 10
Training loss: 0.5737650889238883
Validation loss: 2.2439107916521395

Epoch: 420| Step: 0
Training loss: 0.4077821778757456
Validation loss: 2.2440277433636426

Epoch: 5| Step: 1
Training loss: 0.12464955871828506
Validation loss: 2.2514070728020927

Epoch: 5| Step: 2
Training loss: 0.437471593207066
Validation loss: 2.2423742821854185

Epoch: 5| Step: 3
Training loss: 0.3633016149903933
Validation loss: 2.2468363717263613

Epoch: 5| Step: 4
Training loss: 0.34129495006790883
Validation loss: 2.272203539131431

Epoch: 5| Step: 5
Training loss: 0.4418591395584246
Validation loss: 2.239117099989403

Epoch: 5| Step: 6
Training loss: 0.5188992894460209
Validation loss: 2.2811455595253802

Epoch: 5| Step: 7
Training loss: 0.4536338119870298
Validation loss: 2.2831471895972824

Epoch: 5| Step: 8
Training loss: 0.29777995014737646
Validation loss: 2.2668486722347265

Epoch: 5| Step: 9
Training loss: 0.4327622250164008
Validation loss: 2.293121587152045

Epoch: 5| Step: 10
Training loss: 0.37351465106606546
Validation loss: 2.278621998933287

Epoch: 421| Step: 0
Training loss: 0.21061889110388282
Validation loss: 2.3328086769311094

Epoch: 5| Step: 1
Training loss: 0.4070360941241708
Validation loss: 2.2800952018630927

Epoch: 5| Step: 2
Training loss: 0.16451876637338764
Validation loss: 2.323638385254782

Epoch: 5| Step: 3
Training loss: 0.35700541346449927
Validation loss: 2.320509415705746

Epoch: 5| Step: 4
Training loss: 0.2845423373764996
Validation loss: 2.3209758280095354

Epoch: 5| Step: 5
Training loss: 0.19453702519741306
Validation loss: 2.2624368376530586

Epoch: 5| Step: 6
Training loss: 0.37195232853586857
Validation loss: 2.2490081845723973

Epoch: 5| Step: 7
Training loss: 0.5824315275624303
Validation loss: 2.2633231832497267

Epoch: 5| Step: 8
Training loss: 0.5060970086996532
Validation loss: 2.2331802474872324

Epoch: 5| Step: 9
Training loss: 0.45752951367866046
Validation loss: 2.2565751015910624

Epoch: 5| Step: 10
Training loss: 0.5119219660376263
Validation loss: 2.2527155281312576

Epoch: 422| Step: 0
Training loss: 0.5501943938302146
Validation loss: 2.259362572445875

Epoch: 5| Step: 1
Training loss: 0.2905629240415699
Validation loss: 2.2573027170281423

Epoch: 5| Step: 2
Training loss: 0.4547840199488066
Validation loss: 2.2512502967817105

Epoch: 5| Step: 3
Training loss: 0.35175408335418845
Validation loss: 2.2555993842885114

Epoch: 5| Step: 4
Training loss: 0.26244881562350725
Validation loss: 2.2772825080144004

Epoch: 5| Step: 5
Training loss: 0.36330450660342256
Validation loss: 2.223091036105418

Epoch: 5| Step: 6
Training loss: 0.4143718427649999
Validation loss: 2.255568245537636

Epoch: 5| Step: 7
Training loss: 0.23384968378801319
Validation loss: 2.264537028130878

Epoch: 5| Step: 8
Training loss: 0.4016305286954193
Validation loss: 2.276484488156369

Epoch: 5| Step: 9
Training loss: 0.32717756454845487
Validation loss: 2.2496162495200203

Epoch: 5| Step: 10
Training loss: 0.4750711525780381
Validation loss: 2.2384121460750213

Epoch: 423| Step: 0
Training loss: 0.3491501162543411
Validation loss: 2.2567032007398646

Epoch: 5| Step: 1
Training loss: 0.3644716591328473
Validation loss: 2.2506587717366333

Epoch: 5| Step: 2
Training loss: 0.3487292244578403
Validation loss: 2.2550793572779924

Epoch: 5| Step: 3
Training loss: 0.3864593599242416
Validation loss: 2.245491395195927

Epoch: 5| Step: 4
Training loss: 0.4173087318950728
Validation loss: 2.2526249380231054

Epoch: 5| Step: 5
Training loss: 0.4482830419600987
Validation loss: 2.2502729781258552

Epoch: 5| Step: 6
Training loss: 0.25318712955505196
Validation loss: 2.2496677487211483

Epoch: 5| Step: 7
Training loss: 0.3944744031383646
Validation loss: 2.246722726948924

Epoch: 5| Step: 8
Training loss: 0.4530458052257966
Validation loss: 2.246998472904558

Epoch: 5| Step: 9
Training loss: 0.3468111890230821
Validation loss: 2.2448141017291685

Epoch: 5| Step: 10
Training loss: 0.3444497182828582
Validation loss: 2.275919914485571

Epoch: 424| Step: 0
Training loss: 0.27948517220767793
Validation loss: 2.250738602643632

Epoch: 5| Step: 1
Training loss: 0.3312106932405115
Validation loss: 2.2602493540260116

Epoch: 5| Step: 2
Training loss: 0.4177208994483853
Validation loss: 2.2561627876516077

Epoch: 5| Step: 3
Training loss: 0.3980200768791118
Validation loss: 2.2535500520703824

Epoch: 5| Step: 4
Training loss: 0.45221492204383146
Validation loss: 2.2480667928893805

Epoch: 5| Step: 5
Training loss: 0.41147427185993557
Validation loss: 2.2769274742303462

Epoch: 5| Step: 6
Training loss: 0.1960788664165806
Validation loss: 2.292265445943511

Epoch: 5| Step: 7
Training loss: 0.5489994202595135
Validation loss: 2.2715541615252963

Epoch: 5| Step: 8
Training loss: 0.29017296984788854
Validation loss: 2.2623727949324217

Epoch: 5| Step: 9
Training loss: 0.1881063709667149
Validation loss: 2.2870790093836413

Epoch: 5| Step: 10
Training loss: 0.4449252737181734
Validation loss: 2.281960267085138

Epoch: 425| Step: 0
Training loss: 0.28080417477908737
Validation loss: 2.289376289525406

Epoch: 5| Step: 1
Training loss: 0.26390038937192656
Validation loss: 2.272844849711926

Epoch: 5| Step: 2
Training loss: 0.45915710770141277
Validation loss: 2.294705722450239

Epoch: 5| Step: 3
Training loss: 0.49486091196155685
Validation loss: 2.2647401603033264

Epoch: 5| Step: 4
Training loss: 0.3773363171905703
Validation loss: 2.316626339739439

Epoch: 5| Step: 5
Training loss: 0.31978010499455295
Validation loss: 2.318920615314952

Epoch: 5| Step: 6
Training loss: 0.3343289254432963
Validation loss: 2.2753107666637464

Epoch: 5| Step: 7
Training loss: 0.44337651559911057
Validation loss: 2.266795464882173

Epoch: 5| Step: 8
Training loss: 0.17679846280371508
Validation loss: 2.2822670573511736

Epoch: 5| Step: 9
Training loss: 0.49499297982352974
Validation loss: 2.3190729045148806

Epoch: 5| Step: 10
Training loss: 0.24889102482133466
Validation loss: 2.283211926818807

Epoch: 426| Step: 0
Training loss: 0.22276181512595394
Validation loss: 2.2675396821298315

Epoch: 5| Step: 1
Training loss: 0.4934168856846386
Validation loss: 2.2647232778902286

Epoch: 5| Step: 2
Training loss: 0.37665510503078536
Validation loss: 2.257899254345216

Epoch: 5| Step: 3
Training loss: 0.3952217480372412
Validation loss: 2.272848734346112

Epoch: 5| Step: 4
Training loss: 0.326640722954039
Validation loss: 2.28547515873559

Epoch: 5| Step: 5
Training loss: 0.17688938112733887
Validation loss: 2.286705527527733

Epoch: 5| Step: 6
Training loss: 0.4823688678732266
Validation loss: 2.3069192649755252

Epoch: 5| Step: 7
Training loss: 0.3659678351633766
Validation loss: 2.289932252053998

Epoch: 5| Step: 8
Training loss: 0.4326234046368748
Validation loss: 2.3178750135256743

Epoch: 5| Step: 9
Training loss: 0.2275153299160381
Validation loss: 2.2892371879619695

Epoch: 5| Step: 10
Training loss: 0.3788332131379039
Validation loss: 2.3049390363239883

Epoch: 427| Step: 0
Training loss: 0.19935543382834392
Validation loss: 2.281739641303469

Epoch: 5| Step: 1
Training loss: 0.30180900411107786
Validation loss: 2.28069648427476

Epoch: 5| Step: 2
Training loss: 0.3924350382871494
Validation loss: 2.283976192560693

Epoch: 5| Step: 3
Training loss: 0.3910161539506717
Validation loss: 2.263272422368283

Epoch: 5| Step: 4
Training loss: 0.40223609076516575
Validation loss: 2.2492757378435915

Epoch: 5| Step: 5
Training loss: 0.4411948381368408
Validation loss: 2.2526625810188614

Epoch: 5| Step: 6
Training loss: 0.2117624047799468
Validation loss: 2.2297667024600814

Epoch: 5| Step: 7
Training loss: 0.27736098276247934
Validation loss: 2.2798603892089515

Epoch: 5| Step: 8
Training loss: 0.30717129558848355
Validation loss: 2.2492229300222344

Epoch: 5| Step: 9
Training loss: 0.44776159381818953
Validation loss: 2.2527263652075935

Epoch: 5| Step: 10
Training loss: 0.5163912426128421
Validation loss: 2.2643050629252524

Epoch: 428| Step: 0
Training loss: 0.2735775997377526
Validation loss: 2.246169426041325

Epoch: 5| Step: 1
Training loss: 0.35335015275835036
Validation loss: 2.252436603775155

Epoch: 5| Step: 2
Training loss: 0.38126132979521243
Validation loss: 2.2728677806881477

Epoch: 5| Step: 3
Training loss: 0.26800101339002713
Validation loss: 2.2242057591378943

Epoch: 5| Step: 4
Training loss: 0.3002418040285309
Validation loss: 2.2692549014840173

Epoch: 5| Step: 5
Training loss: 0.40661005423748237
Validation loss: 2.2548698423818547

Epoch: 5| Step: 6
Training loss: 0.5416007888298685
Validation loss: 2.251865169908329

Epoch: 5| Step: 7
Training loss: 0.3627647912646437
Validation loss: 2.244847217442824

Epoch: 5| Step: 8
Training loss: 0.18454021632337392
Validation loss: 2.299837774411417

Epoch: 5| Step: 9
Training loss: 0.42426254931531904
Validation loss: 2.2927891872911044

Epoch: 5| Step: 10
Training loss: 0.35113073963092817
Validation loss: 2.2854958956966707

Epoch: 429| Step: 0
Training loss: 0.4725689452697574
Validation loss: 2.2875224059861425

Epoch: 5| Step: 1
Training loss: 0.3701159394175238
Validation loss: 2.314642317113494

Epoch: 5| Step: 2
Training loss: 0.292071928025181
Validation loss: 2.3041263965846146

Epoch: 5| Step: 3
Training loss: 0.5778910704896331
Validation loss: 2.3022793560308834

Epoch: 5| Step: 4
Training loss: 0.26604808043622813
Validation loss: 2.2818440512163574

Epoch: 5| Step: 5
Training loss: 0.37043350109955964
Validation loss: 2.2301093868118675

Epoch: 5| Step: 6
Training loss: 0.44909344459689476
Validation loss: 2.2669820464625654

Epoch: 5| Step: 7
Training loss: 0.35470318360460734
Validation loss: 2.3082837206046576

Epoch: 5| Step: 8
Training loss: 0.13540114640892664
Validation loss: 2.317294703416219

Epoch: 5| Step: 9
Training loss: 0.3085120612078946
Validation loss: 2.382559366025767

Epoch: 5| Step: 10
Training loss: 0.5167192638707266
Validation loss: 2.3966353345220015

Epoch: 430| Step: 0
Training loss: 0.5852810552147508
Validation loss: 2.3736777535122746

Epoch: 5| Step: 1
Training loss: 0.26706396950429706
Validation loss: 2.326619274339469

Epoch: 5| Step: 2
Training loss: 0.531925725344693
Validation loss: 2.2726732514413133

Epoch: 5| Step: 3
Training loss: 0.374370961302815
Validation loss: 2.2375290539201975

Epoch: 5| Step: 4
Training loss: 0.37237058122643973
Validation loss: 2.2600572119830993

Epoch: 5| Step: 5
Training loss: 0.5051256551306426
Validation loss: 2.2177076362426082

Epoch: 5| Step: 6
Training loss: 0.4146685214036959
Validation loss: 2.222128100563957

Epoch: 5| Step: 7
Training loss: 0.5383247911535308
Validation loss: 2.2050115147154346

Epoch: 5| Step: 8
Training loss: 0.4865433703014283
Validation loss: 2.241242256850979

Epoch: 5| Step: 9
Training loss: 0.38162893162191197
Validation loss: 2.256944000732109

Epoch: 5| Step: 10
Training loss: 0.31036300734104727
Validation loss: 2.2658871613233593

Epoch: 431| Step: 0
Training loss: 0.3380240138491554
Validation loss: 2.276962364568341

Epoch: 5| Step: 1
Training loss: 0.6610432596565173
Validation loss: 2.287309375026221

Epoch: 5| Step: 2
Training loss: 0.2979201691205987
Validation loss: 2.2510777835137374

Epoch: 5| Step: 3
Training loss: 0.5626993885574557
Validation loss: 2.3002598699968364

Epoch: 5| Step: 4
Training loss: 0.3849463062805809
Validation loss: 2.2490618560440425

Epoch: 5| Step: 5
Training loss: 0.1547565915197589
Validation loss: 2.2565882186855153

Epoch: 5| Step: 6
Training loss: 0.3644141099659695
Validation loss: 2.299196211221009

Epoch: 5| Step: 7
Training loss: 0.4325606436191471
Validation loss: 2.2683044656938303

Epoch: 5| Step: 8
Training loss: 0.42712449441443917
Validation loss: 2.3107274991379367

Epoch: 5| Step: 9
Training loss: 0.436514510846446
Validation loss: 2.2764954195727833

Epoch: 5| Step: 10
Training loss: 0.2856843839052748
Validation loss: 2.299892903715188

Epoch: 432| Step: 0
Training loss: 0.41244944782874476
Validation loss: 2.332794908143026

Epoch: 5| Step: 1
Training loss: 0.38218702093236284
Validation loss: 2.320518937741362

Epoch: 5| Step: 2
Training loss: 0.46163478739816566
Validation loss: 2.3134912075445833

Epoch: 5| Step: 3
Training loss: 0.3223349756700662
Validation loss: 2.358478728228483

Epoch: 5| Step: 4
Training loss: 0.5911103096481896
Validation loss: 2.3641418153968434

Epoch: 5| Step: 5
Training loss: 0.35431311421888684
Validation loss: 2.327590106819978

Epoch: 5| Step: 6
Training loss: 0.2627449130628426
Validation loss: 2.3438669614423238

Epoch: 5| Step: 7
Training loss: 0.44793890372974904
Validation loss: 2.3397605665230636

Epoch: 5| Step: 8
Training loss: 0.2928866080524799
Validation loss: 2.3065486978311265

Epoch: 5| Step: 9
Training loss: 0.4173598801306782
Validation loss: 2.3042311600197842

Epoch: 5| Step: 10
Training loss: 0.29863550797437927
Validation loss: 2.295972231338955

Epoch: 433| Step: 0
Training loss: 0.47670060642440726
Validation loss: 2.293011903867719

Epoch: 5| Step: 1
Training loss: 0.40734828529423106
Validation loss: 2.273699903552065

Epoch: 5| Step: 2
Training loss: 0.38880283698868917
Validation loss: 2.2812718238522742

Epoch: 5| Step: 3
Training loss: 0.49919931555992975
Validation loss: 2.2503760432631505

Epoch: 5| Step: 4
Training loss: 0.48107586472145186
Validation loss: 2.272890022273328

Epoch: 5| Step: 5
Training loss: 0.38546089829271285
Validation loss: 2.267042304698659

Epoch: 5| Step: 6
Training loss: 0.35085413882812644
Validation loss: 2.278118387848477

Epoch: 5| Step: 7
Training loss: 0.27695121656871363
Validation loss: 2.267970277850885

Epoch: 5| Step: 8
Training loss: 0.44546539626503173
Validation loss: 2.252602374571491

Epoch: 5| Step: 9
Training loss: 0.2444532909984031
Validation loss: 2.2902737528084867

Epoch: 5| Step: 10
Training loss: 0.3904391037157103
Validation loss: 2.2872007530087837

Epoch: 434| Step: 0
Training loss: 0.4786784303819276
Validation loss: 2.3283553548049185

Epoch: 5| Step: 1
Training loss: 0.3724707103581324
Validation loss: 2.283468110116079

Epoch: 5| Step: 2
Training loss: 0.3945993421355737
Validation loss: 2.287427634861875

Epoch: 5| Step: 3
Training loss: 0.36594051294690816
Validation loss: 2.3024084481248095

Epoch: 5| Step: 4
Training loss: 0.42263240288606113
Validation loss: 2.288002442636856

Epoch: 5| Step: 5
Training loss: 0.3772342207005755
Validation loss: 2.2833319005683994

Epoch: 5| Step: 6
Training loss: 0.4068552057517092
Validation loss: 2.278776255073121

Epoch: 5| Step: 7
Training loss: 0.32904366909388905
Validation loss: 2.308225119884709

Epoch: 5| Step: 8
Training loss: 0.34893054163515036
Validation loss: 2.270800121102507

Epoch: 5| Step: 9
Training loss: 0.3190197794052814
Validation loss: 2.2795419050667247

Epoch: 5| Step: 10
Training loss: 0.2708052229353664
Validation loss: 2.271147859061994

Epoch: 435| Step: 0
Training loss: 0.36873808615237136
Validation loss: 2.273706509678335

Epoch: 5| Step: 1
Training loss: 0.1375910452126991
Validation loss: 2.2586862558345153

Epoch: 5| Step: 2
Training loss: 0.2818514168679174
Validation loss: 2.2473172677995743

Epoch: 5| Step: 3
Training loss: 0.3075653516904258
Validation loss: 2.2652537357463713

Epoch: 5| Step: 4
Training loss: 0.45274165808387745
Validation loss: 2.259161718224994

Epoch: 5| Step: 5
Training loss: 0.42225777956637744
Validation loss: 2.248361798407597

Epoch: 5| Step: 6
Training loss: 0.5187668016309553
Validation loss: 2.239504523487254

Epoch: 5| Step: 7
Training loss: 0.2435964776400868
Validation loss: 2.2616390928556602

Epoch: 5| Step: 8
Training loss: 0.22377813190354237
Validation loss: 2.303217221695014

Epoch: 5| Step: 9
Training loss: 0.546479954405132
Validation loss: 2.323815930491138

Epoch: 5| Step: 10
Training loss: 0.4704898810225845
Validation loss: 2.3357489379410885

Epoch: 436| Step: 0
Training loss: 0.36994044127393066
Validation loss: 2.3337090324558862

Epoch: 5| Step: 1
Training loss: 0.23089655271821538
Validation loss: 2.292222423415902

Epoch: 5| Step: 2
Training loss: 0.5328712967903447
Validation loss: 2.270643853099071

Epoch: 5| Step: 3
Training loss: 0.5659862934565837
Validation loss: 2.296450078591644

Epoch: 5| Step: 4
Training loss: 0.4804767359868502
Validation loss: 2.267896997181482

Epoch: 5| Step: 5
Training loss: 0.24903089474750711
Validation loss: 2.2763825397821313

Epoch: 5| Step: 6
Training loss: 0.4158363134943727
Validation loss: 2.299575574163857

Epoch: 5| Step: 7
Training loss: 0.27622229886011307
Validation loss: 2.3696879969470563

Epoch: 5| Step: 8
Training loss: 0.6236553270509277
Validation loss: 2.3544456275998615

Epoch: 5| Step: 9
Training loss: 0.49646419301045336
Validation loss: 2.3570529154111504

Epoch: 5| Step: 10
Training loss: 0.43659100446983884
Validation loss: 2.293353265182719

Epoch: 437| Step: 0
Training loss: 0.3849708281029816
Validation loss: 2.3081857834988075

Epoch: 5| Step: 1
Training loss: 0.2694631849950996
Validation loss: 2.311206046538878

Epoch: 5| Step: 2
Training loss: 0.4292803656169143
Validation loss: 2.2993772236032837

Epoch: 5| Step: 3
Training loss: 0.4092206547515458
Validation loss: 2.2732695428085576

Epoch: 5| Step: 4
Training loss: 0.3486027530993423
Validation loss: 2.2822895760529263

Epoch: 5| Step: 5
Training loss: 0.6745257981331649
Validation loss: 2.3034528525580065

Epoch: 5| Step: 6
Training loss: 0.567938160236521
Validation loss: 2.2949131996411465

Epoch: 5| Step: 7
Training loss: 0.43993832399768296
Validation loss: 2.310684034293211

Epoch: 5| Step: 8
Training loss: 0.27377226636638446
Validation loss: 2.3067676665184984

Epoch: 5| Step: 9
Training loss: 0.48231755414437527
Validation loss: 2.3322231937701186

Epoch: 5| Step: 10
Training loss: 0.3704919050518977
Validation loss: 2.3369878391976227

Epoch: 438| Step: 0
Training loss: 0.4510535378101603
Validation loss: 2.3266233989246166

Epoch: 5| Step: 1
Training loss: 0.4594382294457179
Validation loss: 2.2926259744833133

Epoch: 5| Step: 2
Training loss: 0.4420366090440915
Validation loss: 2.255383520496141

Epoch: 5| Step: 3
Training loss: 0.4996342513368632
Validation loss: 2.248999741329744

Epoch: 5| Step: 4
Training loss: 0.2698699371230502
Validation loss: 2.2539390143154616

Epoch: 5| Step: 5
Training loss: 0.22205279372604592
Validation loss: 2.237425672275402

Epoch: 5| Step: 6
Training loss: 0.5284889502042366
Validation loss: 2.2338140798874098

Epoch: 5| Step: 7
Training loss: 0.4423191117324403
Validation loss: 2.2254727494489943

Epoch: 5| Step: 8
Training loss: 0.4546282103642538
Validation loss: 2.2296167627876584

Epoch: 5| Step: 9
Training loss: 0.330083361702635
Validation loss: 2.232447785464608

Epoch: 5| Step: 10
Training loss: 0.3383412636080403
Validation loss: 2.2427990544486516

Epoch: 439| Step: 0
Training loss: 0.4686515704762843
Validation loss: 2.2374339987829877

Epoch: 5| Step: 1
Training loss: 0.3782161642158127
Validation loss: 2.226338309727644

Epoch: 5| Step: 2
Training loss: 0.3230077117834881
Validation loss: 2.261990698109371

Epoch: 5| Step: 3
Training loss: 0.2805738932071675
Validation loss: 2.301791534022972

Epoch: 5| Step: 4
Training loss: 0.24412551070158434
Validation loss: 2.288422664188436

Epoch: 5| Step: 5
Training loss: 0.3138717228503037
Validation loss: 2.2535809727047376

Epoch: 5| Step: 6
Training loss: 0.42041510070657845
Validation loss: 2.2881311615383493

Epoch: 5| Step: 7
Training loss: 0.27862267383102424
Validation loss: 2.275650789626791

Epoch: 5| Step: 8
Training loss: 0.3475340510570099
Validation loss: 2.2657216788015595

Epoch: 5| Step: 9
Training loss: 0.521630598848573
Validation loss: 2.2526123293310807

Epoch: 5| Step: 10
Training loss: 0.31684096813852475
Validation loss: 2.2370671802633466

Epoch: 440| Step: 0
Training loss: 0.2889510532709805
Validation loss: 2.2422938442233273

Epoch: 5| Step: 1
Training loss: 0.43111145586000554
Validation loss: 2.208408001732288

Epoch: 5| Step: 2
Training loss: 0.47862963194161223
Validation loss: 2.2404386596018875

Epoch: 5| Step: 3
Training loss: 0.4020594731434414
Validation loss: 2.2702134753919134

Epoch: 5| Step: 4
Training loss: 0.27675188067640605
Validation loss: 2.2613242829733378

Epoch: 5| Step: 5
Training loss: 0.4776822365033224
Validation loss: 2.231176315942639

Epoch: 5| Step: 6
Training loss: 0.2649538312136464
Validation loss: 2.2526366885458295

Epoch: 5| Step: 7
Training loss: 0.2562222128432988
Validation loss: 2.2777175142096486

Epoch: 5| Step: 8
Training loss: 0.33108941180207613
Validation loss: 2.2786898224740617

Epoch: 5| Step: 9
Training loss: 0.17199419505177735
Validation loss: 2.2680403900923847

Epoch: 5| Step: 10
Training loss: 0.2552887180135876
Validation loss: 2.2761409714673673

Epoch: 441| Step: 0
Training loss: 0.2981055130777637
Validation loss: 2.3142786798883717

Epoch: 5| Step: 1
Training loss: 0.3313660409393315
Validation loss: 2.2707169175447763

Epoch: 5| Step: 2
Training loss: 0.365917423880105
Validation loss: 2.2774728726352667

Epoch: 5| Step: 3
Training loss: 0.19279840765635323
Validation loss: 2.2921866832809177

Epoch: 5| Step: 4
Training loss: 0.5290436085968818
Validation loss: 2.292139788327484

Epoch: 5| Step: 5
Training loss: 0.4365395835262889
Validation loss: 2.2906808927443487

Epoch: 5| Step: 6
Training loss: 0.41816956161453783
Validation loss: 2.2499491105881915

Epoch: 5| Step: 7
Training loss: 0.36498480445114406
Validation loss: 2.2507077201300727

Epoch: 5| Step: 8
Training loss: 0.2799972608977265
Validation loss: 2.2666660653872963

Epoch: 5| Step: 9
Training loss: 0.19748464077970046
Validation loss: 2.268181929350689

Epoch: 5| Step: 10
Training loss: 0.24455115325658147
Validation loss: 2.252040038469064

Epoch: 442| Step: 0
Training loss: 0.33240938532997527
Validation loss: 2.255200839011857

Epoch: 5| Step: 1
Training loss: 0.3188443497724387
Validation loss: 2.2310293500379155

Epoch: 5| Step: 2
Training loss: 0.3623443951915608
Validation loss: 2.269211196973439

Epoch: 5| Step: 3
Training loss: 0.3461163093671652
Validation loss: 2.2500555448614956

Epoch: 5| Step: 4
Training loss: 0.3514729703709336
Validation loss: 2.260762041167265

Epoch: 5| Step: 5
Training loss: 0.33761405651190346
Validation loss: 2.256667536515144

Epoch: 5| Step: 6
Training loss: 0.2323396040258574
Validation loss: 2.281119649267144

Epoch: 5| Step: 7
Training loss: 0.3968695099518486
Validation loss: 2.2889916664057526

Epoch: 5| Step: 8
Training loss: 0.3931888744940842
Validation loss: 2.2746218526963444

Epoch: 5| Step: 9
Training loss: 0.45062653912983763
Validation loss: 2.2817541282663196

Epoch: 5| Step: 10
Training loss: 0.15811683514967276
Validation loss: 2.2798176019206187

Epoch: 443| Step: 0
Training loss: 0.4513885671255807
Validation loss: 2.3098349964092497

Epoch: 5| Step: 1
Training loss: 0.3001715686072353
Validation loss: 2.290289662215715

Epoch: 5| Step: 2
Training loss: 0.3609545658255047
Validation loss: 2.33619531524399

Epoch: 5| Step: 3
Training loss: 0.1977458245780621
Validation loss: 2.2833355506680815

Epoch: 5| Step: 4
Training loss: 0.351841476801715
Validation loss: 2.309370422558563

Epoch: 5| Step: 5
Training loss: 0.3274719460680233
Validation loss: 2.313593206113064

Epoch: 5| Step: 6
Training loss: 0.21975081415915235
Validation loss: 2.3176044289191546

Epoch: 5| Step: 7
Training loss: 0.4784410535355252
Validation loss: 2.277050342682412

Epoch: 5| Step: 8
Training loss: 0.11232025619068155
Validation loss: 2.3264705463841415

Epoch: 5| Step: 9
Training loss: 0.31796284419393284
Validation loss: 2.331822341908954

Epoch: 5| Step: 10
Training loss: 0.3636158048713588
Validation loss: 2.348497246221245

Epoch: 444| Step: 0
Training loss: 0.24293292600243033
Validation loss: 2.3614575732851195

Epoch: 5| Step: 1
Training loss: 0.5150210282282542
Validation loss: 2.326421175456014

Epoch: 5| Step: 2
Training loss: 0.307063958558808
Validation loss: 2.3527550421251715

Epoch: 5| Step: 3
Training loss: 0.2682827213982394
Validation loss: 2.291492028914217

Epoch: 5| Step: 4
Training loss: 0.16573990196542002
Validation loss: 2.290400024879342

Epoch: 5| Step: 5
Training loss: 0.3850038826734277
Validation loss: 2.3086266132272226

Epoch: 5| Step: 6
Training loss: 0.17055251397470875
Validation loss: 2.2922027125028777

Epoch: 5| Step: 7
Training loss: 0.33859845809937517
Validation loss: 2.2912248411138236

Epoch: 5| Step: 8
Training loss: 0.4884157224499689
Validation loss: 2.270272029119668

Epoch: 5| Step: 9
Training loss: 0.22842196640032653
Validation loss: 2.2743799908553397

Epoch: 5| Step: 10
Training loss: 0.2602430130215786
Validation loss: 2.2862696972888377

Epoch: 445| Step: 0
Training loss: 0.3328009939219575
Validation loss: 2.2546980699604346

Epoch: 5| Step: 1
Training loss: 0.1446840664021559
Validation loss: 2.2123764957463323

Epoch: 5| Step: 2
Training loss: 0.28146565964032394
Validation loss: 2.2492021435854235

Epoch: 5| Step: 3
Training loss: 0.22324440889096017
Validation loss: 2.2289087581244087

Epoch: 5| Step: 4
Training loss: 0.257457069109778
Validation loss: 2.260523168138786

Epoch: 5| Step: 5
Training loss: 0.3836036408930302
Validation loss: 2.2360738613041127

Epoch: 5| Step: 6
Training loss: 0.5310252499602558
Validation loss: 2.243825661559852

Epoch: 5| Step: 7
Training loss: 0.34814595440203183
Validation loss: 2.26310555836517

Epoch: 5| Step: 8
Training loss: 0.28561090776833675
Validation loss: 2.256286850495018

Epoch: 5| Step: 9
Training loss: 0.32533029956474696
Validation loss: 2.2368814454034824

Epoch: 5| Step: 10
Training loss: 0.2989346557416479
Validation loss: 2.2459912085968274

Epoch: 446| Step: 0
Training loss: 0.27582483352480464
Validation loss: 2.2427575223367473

Epoch: 5| Step: 1
Training loss: 0.32301237113486236
Validation loss: 2.2761526017160656

Epoch: 5| Step: 2
Training loss: 0.34416863568868805
Validation loss: 2.2880964532736865

Epoch: 5| Step: 3
Training loss: 0.44156734936340003
Validation loss: 2.28215422938174

Epoch: 5| Step: 4
Training loss: 0.3603184589181077
Validation loss: 2.2473193713526363

Epoch: 5| Step: 5
Training loss: 0.42736152179593456
Validation loss: 2.279694253005296

Epoch: 5| Step: 6
Training loss: 0.28118409603235084
Validation loss: 2.2884418357693366

Epoch: 5| Step: 7
Training loss: 0.25899583724995795
Validation loss: 2.275687616901192

Epoch: 5| Step: 8
Training loss: 0.25873985542461103
Validation loss: 2.265881278847787

Epoch: 5| Step: 9
Training loss: 0.19790533413984565
Validation loss: 2.274531363569126

Epoch: 5| Step: 10
Training loss: 0.393408168278068
Validation loss: 2.256112442911452

Epoch: 447| Step: 0
Training loss: 0.46189251258696423
Validation loss: 2.2810929469518113

Epoch: 5| Step: 1
Training loss: 0.14349567731550505
Validation loss: 2.270039655566633

Epoch: 5| Step: 2
Training loss: 0.37259070981689124
Validation loss: 2.2872386939353246

Epoch: 5| Step: 3
Training loss: 0.29063768615516533
Validation loss: 2.276353671955245

Epoch: 5| Step: 4
Training loss: 0.21503784775282572
Validation loss: 2.2594098651755545

Epoch: 5| Step: 5
Training loss: 0.1457291142702406
Validation loss: 2.274604926411095

Epoch: 5| Step: 6
Training loss: 0.3254709192790656
Validation loss: 2.274446964217468

Epoch: 5| Step: 7
Training loss: 0.2618779794072844
Validation loss: 2.284048132939887

Epoch: 5| Step: 8
Training loss: 0.44172987425661003
Validation loss: 2.2877164256295135

Epoch: 5| Step: 9
Training loss: 0.43946066955871815
Validation loss: 2.2791644351377873

Epoch: 5| Step: 10
Training loss: 0.28195737256840564
Validation loss: 2.2892239219818777

Epoch: 448| Step: 0
Training loss: 0.2840903492401849
Validation loss: 2.313110712143824

Epoch: 5| Step: 1
Training loss: 0.13242534700416267
Validation loss: 2.3003104777905734

Epoch: 5| Step: 2
Training loss: 0.2669828434211101
Validation loss: 2.3177105282234693

Epoch: 5| Step: 3
Training loss: 0.4444351253261006
Validation loss: 2.2917868156670065

Epoch: 5| Step: 4
Training loss: 0.2751789496967265
Validation loss: 2.3148536931901034

Epoch: 5| Step: 5
Training loss: 0.4769388651297789
Validation loss: 2.3081874284055806

Epoch: 5| Step: 6
Training loss: 0.37248991286937944
Validation loss: 2.2756215697591045

Epoch: 5| Step: 7
Training loss: 0.3724014930917451
Validation loss: 2.297658214590637

Epoch: 5| Step: 8
Training loss: 0.3186879480960656
Validation loss: 2.277487695165291

Epoch: 5| Step: 9
Training loss: 0.25030287634819587
Validation loss: 2.254395719028759

Epoch: 5| Step: 10
Training loss: 0.27657857298616734
Validation loss: 2.255497498384482

Epoch: 449| Step: 0
Training loss: 0.6191048356070239
Validation loss: 2.2547745333733005

Epoch: 5| Step: 1
Training loss: 0.14871396494800626
Validation loss: 2.260488685249614

Epoch: 5| Step: 2
Training loss: 0.3137462323559086
Validation loss: 2.2499924224352195

Epoch: 5| Step: 3
Training loss: 0.20654179638108283
Validation loss: 2.2450109770159994

Epoch: 5| Step: 4
Training loss: 0.24252035740074707
Validation loss: 2.260750451944705

Epoch: 5| Step: 5
Training loss: 0.26436746469314787
Validation loss: 2.235299252347466

Epoch: 5| Step: 6
Training loss: 0.29267605465560226
Validation loss: 2.2324168899312955

Epoch: 5| Step: 7
Training loss: 0.2545418925721184
Validation loss: 2.272433659054153

Epoch: 5| Step: 8
Training loss: 0.3171639847142567
Validation loss: 2.267133869589479

Epoch: 5| Step: 9
Training loss: 0.33251379515059837
Validation loss: 2.2815569790341543

Epoch: 5| Step: 10
Training loss: 0.35326078091575636
Validation loss: 2.28833300815568

Epoch: 450| Step: 0
Training loss: 0.44718947449467494
Validation loss: 2.2994672132764435

Epoch: 5| Step: 1
Training loss: 0.3628618013331801
Validation loss: 2.270675811391898

Epoch: 5| Step: 2
Training loss: 0.20707110255316816
Validation loss: 2.3059474197998204

Epoch: 5| Step: 3
Training loss: 0.44427052110643883
Validation loss: 2.302451754089672

Epoch: 5| Step: 4
Training loss: 0.30791852209532733
Validation loss: 2.2838037199291423

Epoch: 5| Step: 5
Training loss: 0.17236930577283183
Validation loss: 2.2870092919227436

Epoch: 5| Step: 6
Training loss: 0.30041614270307865
Validation loss: 2.3078768801033154

Epoch: 5| Step: 7
Training loss: 0.15564976079663853
Validation loss: 2.3015173013541865

Epoch: 5| Step: 8
Training loss: 0.2934399947364067
Validation loss: 2.279888088737511

Epoch: 5| Step: 9
Training loss: 0.3286654018655999
Validation loss: 2.285788197620671

Epoch: 5| Step: 10
Training loss: 0.24052997174145752
Validation loss: 2.2959790022805535

Testing loss: 2.5221367505959034
