Epoch: 1| Step: 0
Training loss: 6.542722709926226
Validation loss: 5.772435765854437

Epoch: 5| Step: 1
Training loss: 5.037655372211355
Validation loss: 5.746053667417289

Epoch: 5| Step: 2
Training loss: 5.833803575726239
Validation loss: 5.7239529647547425

Epoch: 5| Step: 3
Training loss: 6.021290833230018
Validation loss: 5.70253186818463

Epoch: 5| Step: 4
Training loss: 5.919570675824724
Validation loss: 5.679996235921474

Epoch: 5| Step: 5
Training loss: 5.021262355007691
Validation loss: 5.6538548283945

Epoch: 5| Step: 6
Training loss: 6.6287710145678
Validation loss: 5.625451554526073

Epoch: 5| Step: 7
Training loss: 5.171366041327808
Validation loss: 5.594130057153563

Epoch: 5| Step: 8
Training loss: 5.722209613543367
Validation loss: 5.559029296827787

Epoch: 5| Step: 9
Training loss: 4.521136131635097
Validation loss: 5.523096789469096

Epoch: 5| Step: 10
Training loss: 5.745302354576982
Validation loss: 5.481509209455917

Epoch: 2| Step: 0
Training loss: 5.479121025485207
Validation loss: 5.437488677065268

Epoch: 5| Step: 1
Training loss: 6.2153715992055485
Validation loss: 5.390304917838588

Epoch: 5| Step: 2
Training loss: 5.179896653959722
Validation loss: 5.340209722750919

Epoch: 5| Step: 3
Training loss: 4.7205611031206764
Validation loss: 5.286619829780066

Epoch: 5| Step: 4
Training loss: 5.929259997250099
Validation loss: 5.232433234057316

Epoch: 5| Step: 5
Training loss: 4.6611560347014755
Validation loss: 5.175389149960108

Epoch: 5| Step: 6
Training loss: 5.156527240120097
Validation loss: 5.115425843292769

Epoch: 5| Step: 7
Training loss: 5.0000888816562945
Validation loss: 5.052574161104752

Epoch: 5| Step: 8
Training loss: 5.467388223308731
Validation loss: 4.988322436393083

Epoch: 5| Step: 9
Training loss: 4.929091234616166
Validation loss: 4.920454272786086

Epoch: 5| Step: 10
Training loss: 4.427863605028539
Validation loss: 4.856266572907389

Epoch: 3| Step: 0
Training loss: 5.156210604430468
Validation loss: 4.794066631267608

Epoch: 5| Step: 1
Training loss: 4.279560953242125
Validation loss: 4.733906886875057

Epoch: 5| Step: 2
Training loss: 5.513010069761969
Validation loss: 4.679939901563619

Epoch: 5| Step: 3
Training loss: 4.470273698453699
Validation loss: 4.634558757586615

Epoch: 5| Step: 4
Training loss: 4.554179927228426
Validation loss: 4.595171272895494

Epoch: 5| Step: 5
Training loss: 4.518636893601952
Validation loss: 4.558537271421128

Epoch: 5| Step: 6
Training loss: 4.233037420628757
Validation loss: 4.52512791022866

Epoch: 5| Step: 7
Training loss: 5.17989573340622
Validation loss: 4.495292452686872

Epoch: 5| Step: 8
Training loss: 3.694838382557182
Validation loss: 4.468250843696429

Epoch: 5| Step: 9
Training loss: 4.868647814010091
Validation loss: 4.439540224748609

Epoch: 5| Step: 10
Training loss: 4.698294861902029
Validation loss: 4.414883986149072

Epoch: 4| Step: 0
Training loss: 4.490331223129114
Validation loss: 4.392956020881282

Epoch: 5| Step: 1
Training loss: 4.103420802985839
Validation loss: 4.36983146719267

Epoch: 5| Step: 2
Training loss: 4.614135766408441
Validation loss: 4.348777115939116

Epoch: 5| Step: 3
Training loss: 4.950855011741915
Validation loss: 4.320855481644401

Epoch: 5| Step: 4
Training loss: 4.955667607267039
Validation loss: 4.295421346547489

Epoch: 5| Step: 5
Training loss: 5.266655614495249
Validation loss: 4.2733124175523

Epoch: 5| Step: 6
Training loss: 3.304261669382214
Validation loss: 4.248946210642205

Epoch: 5| Step: 7
Training loss: 3.7440684136962545
Validation loss: 4.22881539279813

Epoch: 5| Step: 8
Training loss: 4.521161654924643
Validation loss: 4.209566262043953

Epoch: 5| Step: 9
Training loss: 4.260859583781211
Validation loss: 4.1894065056730785

Epoch: 5| Step: 10
Training loss: 3.8440536751229897
Validation loss: 4.16529891586685

Epoch: 5| Step: 0
Training loss: 5.051965938921447
Validation loss: 4.15269801032504

Epoch: 5| Step: 1
Training loss: 3.4094058475095372
Validation loss: 4.125060328703998

Epoch: 5| Step: 2
Training loss: 3.458741466537884
Validation loss: 4.115413865546727

Epoch: 5| Step: 3
Training loss: 4.489884132640411
Validation loss: 4.096549654825919

Epoch: 5| Step: 4
Training loss: 5.079800279551053
Validation loss: 4.066023840110609

Epoch: 5| Step: 5
Training loss: 4.388817900608006
Validation loss: 4.051461308886679

Epoch: 5| Step: 6
Training loss: 4.776030040908469
Validation loss: 4.031024132560334

Epoch: 5| Step: 7
Training loss: 4.649782335662925
Validation loss: 4.011919962676107

Epoch: 5| Step: 8
Training loss: 3.90345016847576
Validation loss: 4.021095109660327

Epoch: 5| Step: 9
Training loss: 3.468538157549722
Validation loss: 3.9894870894349115

Epoch: 5| Step: 10
Training loss: 2.840373287652172
Validation loss: 3.9857396426286176

Epoch: 6| Step: 0
Training loss: 4.211969648985449
Validation loss: 3.981283670470644

Epoch: 5| Step: 1
Training loss: 4.859942927398259
Validation loss: 3.965418177913014

Epoch: 5| Step: 2
Training loss: 4.143236481160393
Validation loss: 3.953951005048803

Epoch: 5| Step: 3
Training loss: 3.544612213145064
Validation loss: 3.944308175226905

Epoch: 5| Step: 4
Training loss: 4.2096173936682435
Validation loss: 3.9302543023098706

Epoch: 5| Step: 5
Training loss: 4.017613256409354
Validation loss: 3.915278598315363

Epoch: 5| Step: 6
Training loss: 4.598706121502369
Validation loss: 3.9035791860707225

Epoch: 5| Step: 7
Training loss: 3.2801878163598657
Validation loss: 3.893051601169848

Epoch: 5| Step: 8
Training loss: 4.782802952903633
Validation loss: 3.8839906955165384

Epoch: 5| Step: 9
Training loss: 3.2457110641883737
Validation loss: 3.8722501134647462

Epoch: 5| Step: 10
Training loss: 3.538692766627534
Validation loss: 3.8677457016912156

Epoch: 7| Step: 0
Training loss: 3.9650107963963417
Validation loss: 3.859478073666747

Epoch: 5| Step: 1
Training loss: 5.00893938118293
Validation loss: 3.8485820207259125

Epoch: 5| Step: 2
Training loss: 4.368977352224207
Validation loss: 3.839392862271668

Epoch: 5| Step: 3
Training loss: 4.234946799996868
Validation loss: 3.8317621675215396

Epoch: 5| Step: 4
Training loss: 3.9039761448272046
Validation loss: 3.8224503092233895

Epoch: 5| Step: 5
Training loss: 3.1746402206227256
Validation loss: 3.816511319761327

Epoch: 5| Step: 6
Training loss: 4.101406712071148
Validation loss: 3.808825963936828

Epoch: 5| Step: 7
Training loss: 4.10012088690461
Validation loss: 3.8016037747973126

Epoch: 5| Step: 8
Training loss: 3.0830505000806205
Validation loss: 3.7964708403561858

Epoch: 5| Step: 9
Training loss: 4.195810753699382
Validation loss: 3.794103872037403

Epoch: 5| Step: 10
Training loss: 3.292734302940081
Validation loss: 3.78234792017908

Epoch: 8| Step: 0
Training loss: 4.006681107819271
Validation loss: 3.7720507787418525

Epoch: 5| Step: 1
Training loss: 4.561360046949295
Validation loss: 3.7671957700867784

Epoch: 5| Step: 2
Training loss: 3.901347509532664
Validation loss: 3.760509788531171

Epoch: 5| Step: 3
Training loss: 4.564527296345911
Validation loss: 3.7492750622481066

Epoch: 5| Step: 4
Training loss: 3.644611844299125
Validation loss: 3.753943712408387

Epoch: 5| Step: 5
Training loss: 3.6787423055803594
Validation loss: 3.7347823003396927

Epoch: 5| Step: 6
Training loss: 3.496542858068951
Validation loss: 3.7258962036127174

Epoch: 5| Step: 7
Training loss: 3.34953620319131
Validation loss: 3.721969187290637

Epoch: 5| Step: 8
Training loss: 3.9256290539139207
Validation loss: 3.7155489933778916

Epoch: 5| Step: 9
Training loss: 4.2565853485329885
Validation loss: 3.7088868250174962

Epoch: 5| Step: 10
Training loss: 3.4614324969187393
Validation loss: 3.70211651986203

Epoch: 9| Step: 0
Training loss: 3.8608326495146863
Validation loss: 3.6929132582962896

Epoch: 5| Step: 1
Training loss: 3.9602983248690307
Validation loss: 3.6886147742764903

Epoch: 5| Step: 2
Training loss: 3.2496528440077075
Validation loss: 3.6845113309804063

Epoch: 5| Step: 3
Training loss: 4.303513603975199
Validation loss: 3.679278544653904

Epoch: 5| Step: 4
Training loss: 3.1552288556410177
Validation loss: 3.6760222163444647

Epoch: 5| Step: 5
Training loss: 3.7903009966495587
Validation loss: 3.666332074856238

Epoch: 5| Step: 6
Training loss: 4.090705962869759
Validation loss: 3.6584315341163944

Epoch: 5| Step: 7
Training loss: 4.517735182905405
Validation loss: 3.6509088334639808

Epoch: 5| Step: 8
Training loss: 3.781810120010453
Validation loss: 3.6425458120647987

Epoch: 5| Step: 9
Training loss: 4.109704762270914
Validation loss: 3.6367622750815536

Epoch: 5| Step: 10
Training loss: 3.2258662102916884
Validation loss: 3.630367631774934

Epoch: 10| Step: 0
Training loss: 4.605549508277309
Validation loss: 3.6225791063775623

Epoch: 5| Step: 1
Training loss: 3.2611329060796836
Validation loss: 3.617217999731073

Epoch: 5| Step: 2
Training loss: 4.00257718985738
Validation loss: 3.6116692969588238

Epoch: 5| Step: 3
Training loss: 2.89973063040032
Validation loss: 3.6085956898616685

Epoch: 5| Step: 4
Training loss: 4.128215807855203
Validation loss: 3.6075254333357725

Epoch: 5| Step: 5
Training loss: 4.3026904893075155
Validation loss: 3.5995814110832476

Epoch: 5| Step: 6
Training loss: 3.494362923729706
Validation loss: 3.5885983059340703

Epoch: 5| Step: 7
Training loss: 3.5601351735887268
Validation loss: 3.585114363881116

Epoch: 5| Step: 8
Training loss: 3.820883366968886
Validation loss: 3.59777533260499

Epoch: 5| Step: 9
Training loss: 3.6058090231240305
Validation loss: 3.568027174483759

Epoch: 5| Step: 10
Training loss: 3.803023520802925
Validation loss: 3.5602061067011994

Epoch: 11| Step: 0
Training loss: 4.033915976273885
Validation loss: 3.5626583888118484

Epoch: 5| Step: 1
Training loss: 4.130505211620324
Validation loss: 3.5582870070776678

Epoch: 5| Step: 2
Training loss: 3.756430008775305
Validation loss: 3.5818258268599164

Epoch: 5| Step: 3
Training loss: 3.9599476918705725
Validation loss: 3.582718816283093

Epoch: 5| Step: 4
Training loss: 3.8290822603361367
Validation loss: 3.5688190831446813

Epoch: 5| Step: 5
Training loss: 3.3966856902852913
Validation loss: 3.564902390236514

Epoch: 5| Step: 6
Training loss: 2.9966882864313993
Validation loss: 3.568662490721489

Epoch: 5| Step: 7
Training loss: 3.718228600117197
Validation loss: 3.5803216758795706

Epoch: 5| Step: 8
Training loss: 3.5071715043257288
Validation loss: 3.5687448156342247

Epoch: 5| Step: 9
Training loss: 4.109437891257695
Validation loss: 3.5507113863431163

Epoch: 5| Step: 10
Training loss: 3.916942884296105
Validation loss: 3.526187887819638

Epoch: 12| Step: 0
Training loss: 4.474436309944309
Validation loss: 3.5140913340081017

Epoch: 5| Step: 1
Training loss: 3.8066068034188874
Validation loss: 3.5090083729805874

Epoch: 5| Step: 2
Training loss: 3.7009381625583875
Validation loss: 3.5028903251276606

Epoch: 5| Step: 3
Training loss: 3.487218816763406
Validation loss: 3.5038489436062723

Epoch: 5| Step: 4
Training loss: 3.2132545149173475
Validation loss: 3.5006938047430354

Epoch: 5| Step: 5
Training loss: 3.0509441102696813
Validation loss: 3.4954025849354275

Epoch: 5| Step: 6
Training loss: 3.9315351082617993
Validation loss: 3.4882343200290777

Epoch: 5| Step: 7
Training loss: 4.132954182206331
Validation loss: 3.478190711014062

Epoch: 5| Step: 8
Training loss: 3.7158958958722135
Validation loss: 3.470959523681077

Epoch: 5| Step: 9
Training loss: 3.8603642852133504
Validation loss: 3.455238539223743

Epoch: 5| Step: 10
Training loss: 3.019439656397035
Validation loss: 3.451504760556934

Epoch: 13| Step: 0
Training loss: 3.711776991804552
Validation loss: 3.447215884772248

Epoch: 5| Step: 1
Training loss: 3.8315952064606034
Validation loss: 3.446650690361563

Epoch: 5| Step: 2
Training loss: 3.4715897217158096
Validation loss: 3.436199717179306

Epoch: 5| Step: 3
Training loss: 3.800852132922344
Validation loss: 3.431102194717192

Epoch: 5| Step: 4
Training loss: 3.496307468808038
Validation loss: 3.4253296179950077

Epoch: 5| Step: 5
Training loss: 2.7792202690327534
Validation loss: 3.4203654771351473

Epoch: 5| Step: 6
Training loss: 3.787654025027321
Validation loss: 3.415760735541902

Epoch: 5| Step: 7
Training loss: 3.90825632069619
Validation loss: 3.416645262076148

Epoch: 5| Step: 8
Training loss: 4.104884257572484
Validation loss: 3.4214110674994074

Epoch: 5| Step: 9
Training loss: 3.8947185750617033
Validation loss: 3.413080615052209

Epoch: 5| Step: 10
Training loss: 3.0782695290962105
Validation loss: 3.426194301421755

Epoch: 14| Step: 0
Training loss: 3.643900825951513
Validation loss: 3.455008210830046

Epoch: 5| Step: 1
Training loss: 3.1531169184268335
Validation loss: 3.4349312306258226

Epoch: 5| Step: 2
Training loss: 3.8301545660239076
Validation loss: 3.410483826967933

Epoch: 5| Step: 3
Training loss: 3.9200296505954966
Validation loss: 3.3990590437209134

Epoch: 5| Step: 4
Training loss: 3.886361846639494
Validation loss: 3.3923492803131605

Epoch: 5| Step: 5
Training loss: 3.7048482627530666
Validation loss: 3.393659588347817

Epoch: 5| Step: 6
Training loss: 2.6885056499289166
Validation loss: 3.395533784727264

Epoch: 5| Step: 7
Training loss: 4.327029092908207
Validation loss: 3.3988228241537968

Epoch: 5| Step: 8
Training loss: 3.598677863947986
Validation loss: 3.3917947445710337

Epoch: 5| Step: 9
Training loss: 3.743260494575421
Validation loss: 3.386040436457926

Epoch: 5| Step: 10
Training loss: 3.119757718435956
Validation loss: 3.374630979647263

Epoch: 15| Step: 0
Training loss: 3.300561949538178
Validation loss: 3.3695221521645573

Epoch: 5| Step: 1
Training loss: 3.3087646728466984
Validation loss: 3.364341245324803

Epoch: 5| Step: 2
Training loss: 3.8449493025871395
Validation loss: 3.3630286344072235

Epoch: 5| Step: 3
Training loss: 3.8846339169399395
Validation loss: 3.359022944232998

Epoch: 5| Step: 4
Training loss: 3.1754142671189007
Validation loss: 3.3552238364183253

Epoch: 5| Step: 5
Training loss: 3.541469134637742
Validation loss: 3.3509503439507844

Epoch: 5| Step: 6
Training loss: 3.877275967548329
Validation loss: 3.3476611557216907

Epoch: 5| Step: 7
Training loss: 3.9808757899554856
Validation loss: 3.3437937198019854

Epoch: 5| Step: 8
Training loss: 2.46407029096863
Validation loss: 3.338028069454268

Epoch: 5| Step: 9
Training loss: 4.374331177951039
Validation loss: 3.3379900250689105

Epoch: 5| Step: 10
Training loss: 3.3228883333502988
Validation loss: 3.3335716505893767

Epoch: 16| Step: 0
Training loss: 3.2244802780695787
Validation loss: 3.3321963006579467

Epoch: 5| Step: 1
Training loss: 3.7079456998270905
Validation loss: 3.3285226414403666

Epoch: 5| Step: 2
Training loss: 2.7294673802539946
Validation loss: 3.324214906332277

Epoch: 5| Step: 3
Training loss: 4.167367164220223
Validation loss: 3.3215157053355715

Epoch: 5| Step: 4
Training loss: 3.8340415853156427
Validation loss: 3.320920945842441

Epoch: 5| Step: 5
Training loss: 3.157013904549371
Validation loss: 3.316144483517599

Epoch: 5| Step: 6
Training loss: 3.293021168862888
Validation loss: 3.312752014281729

Epoch: 5| Step: 7
Training loss: 3.7778923322724753
Validation loss: 3.3108042352292304

Epoch: 5| Step: 8
Training loss: 4.080538331588312
Validation loss: 3.3084317604607887

Epoch: 5| Step: 9
Training loss: 3.6071079284832956
Validation loss: 3.3058667316661157

Epoch: 5| Step: 10
Training loss: 3.2577008198502257
Validation loss: 3.3033355831103273

Epoch: 17| Step: 0
Training loss: 2.538495091347704
Validation loss: 3.300123454047235

Epoch: 5| Step: 1
Training loss: 2.8591820490204745
Validation loss: 3.300493011054156

Epoch: 5| Step: 2
Training loss: 3.5614830037806247
Validation loss: 3.2990271281817147

Epoch: 5| Step: 3
Training loss: 3.9025845839958038
Validation loss: 3.2967601111282474

Epoch: 5| Step: 4
Training loss: 4.332486925848303
Validation loss: 3.294167822412785

Epoch: 5| Step: 5
Training loss: 3.7187548725512984
Validation loss: 3.290868470526813

Epoch: 5| Step: 6
Training loss: 3.474612943101737
Validation loss: 3.288120717088743

Epoch: 5| Step: 7
Training loss: 4.072230730890669
Validation loss: 3.2838917822359193

Epoch: 5| Step: 8
Training loss: 4.00269441455302
Validation loss: 3.280122619342051

Epoch: 5| Step: 9
Training loss: 2.9503351182841357
Validation loss: 3.2772675394540123

Epoch: 5| Step: 10
Training loss: 2.9058356861410926
Validation loss: 3.2752458556036017

Epoch: 18| Step: 0
Training loss: 3.786161527409165
Validation loss: 3.275149485753749

Epoch: 5| Step: 1
Training loss: 3.5977958130248635
Validation loss: 3.272461243025359

Epoch: 5| Step: 2
Training loss: 3.0193967011985996
Validation loss: 3.2688328556270063

Epoch: 5| Step: 3
Training loss: 3.7158615049868535
Validation loss: 3.2658768133009164

Epoch: 5| Step: 4
Training loss: 3.9691077844541156
Validation loss: 3.2641007468024763

Epoch: 5| Step: 5
Training loss: 3.5061739554633107
Validation loss: 3.2633108111622073

Epoch: 5| Step: 6
Training loss: 3.4443709628836516
Validation loss: 3.2618234610837193

Epoch: 5| Step: 7
Training loss: 3.0166573610390577
Validation loss: 3.260719583773763

Epoch: 5| Step: 8
Training loss: 3.747801326880415
Validation loss: 3.259184547557525

Epoch: 5| Step: 9
Training loss: 3.483938010144944
Validation loss: 3.2566620735312988

Epoch: 5| Step: 10
Training loss: 3.200361594989554
Validation loss: 3.255044984455781

Epoch: 19| Step: 0
Training loss: 2.928332043211263
Validation loss: 3.252460903217033

Epoch: 5| Step: 1
Training loss: 3.703978492468397
Validation loss: 3.2501438241565968

Epoch: 5| Step: 2
Training loss: 3.4866731873616015
Validation loss: 3.2486502240107753

Epoch: 5| Step: 3
Training loss: 3.53864991602015
Validation loss: 3.2467537373341453

Epoch: 5| Step: 4
Training loss: 3.088611844291028
Validation loss: 3.2448762129354995

Epoch: 5| Step: 5
Training loss: 3.4158658430480897
Validation loss: 3.2435642095412103

Epoch: 5| Step: 6
Training loss: 3.579192422959924
Validation loss: 3.242238331393921

Epoch: 5| Step: 7
Training loss: 4.122359384298092
Validation loss: 3.2420265020393937

Epoch: 5| Step: 8
Training loss: 3.5106500987574596
Validation loss: 3.2399073217412924

Epoch: 5| Step: 9
Training loss: 2.723903200796304
Validation loss: 3.240079586080087

Epoch: 5| Step: 10
Training loss: 4.225446571359883
Validation loss: 3.2424165283310913

Epoch: 20| Step: 0
Training loss: 3.6391569787844205
Validation loss: 3.245298223453071

Epoch: 5| Step: 1
Training loss: 3.5386666251237413
Validation loss: 3.244572261780451

Epoch: 5| Step: 2
Training loss: 3.684929808694777
Validation loss: 3.243686006030041

Epoch: 5| Step: 3
Training loss: 3.539410100375849
Validation loss: 3.236806006544482

Epoch: 5| Step: 4
Training loss: 2.990991736938531
Validation loss: 3.233419231047229

Epoch: 5| Step: 5
Training loss: 3.146698805300065
Validation loss: 3.2313011749474714

Epoch: 5| Step: 6
Training loss: 3.6654423634851687
Validation loss: 3.2288712616817064

Epoch: 5| Step: 7
Training loss: 3.602135205194139
Validation loss: 3.2259855915903826

Epoch: 5| Step: 8
Training loss: 3.4579355554968396
Validation loss: 3.2241344072165568

Epoch: 5| Step: 9
Training loss: 3.9508016038505755
Validation loss: 3.2219936324302396

Epoch: 5| Step: 10
Training loss: 2.943765492003672
Validation loss: 3.219084215280353

Epoch: 21| Step: 0
Training loss: 4.117485136967638
Validation loss: 3.2192436753226903

Epoch: 5| Step: 1
Training loss: 3.1561762735046335
Validation loss: 3.216441832913017

Epoch: 5| Step: 2
Training loss: 3.287175668012814
Validation loss: 3.2152262984281252

Epoch: 5| Step: 3
Training loss: 3.449596276364767
Validation loss: 3.2145050073312538

Epoch: 5| Step: 4
Training loss: 3.5947826726213794
Validation loss: 3.2143932900085246

Epoch: 5| Step: 5
Training loss: 3.783200604187338
Validation loss: 3.2103115376137232

Epoch: 5| Step: 6
Training loss: 3.2708508598360213
Validation loss: 3.208588301701103

Epoch: 5| Step: 7
Training loss: 3.1783655966401603
Validation loss: 3.20652522573119

Epoch: 5| Step: 8
Training loss: 3.5481258656949413
Validation loss: 3.2052456098624544

Epoch: 5| Step: 9
Training loss: 3.8988308450108238
Validation loss: 3.2041493080375494

Epoch: 5| Step: 10
Training loss: 2.4828556621201563
Validation loss: 3.2021624639845427

Epoch: 22| Step: 0
Training loss: 3.109797463399618
Validation loss: 3.2014368105997386

Epoch: 5| Step: 1
Training loss: 3.302016601530008
Validation loss: 3.1999540394897212

Epoch: 5| Step: 2
Training loss: 3.0007062716404134
Validation loss: 3.1986629369825854

Epoch: 5| Step: 3
Training loss: 3.7393252709620843
Validation loss: 3.1978204527048164

Epoch: 5| Step: 4
Training loss: 3.5804086918614244
Validation loss: 3.1969327742165885

Epoch: 5| Step: 5
Training loss: 3.880824725798392
Validation loss: 3.1946178766091893

Epoch: 5| Step: 6
Training loss: 3.197724791164314
Validation loss: 3.19319571767199

Epoch: 5| Step: 7
Training loss: 3.337165695763614
Validation loss: 3.192244317227611

Epoch: 5| Step: 8
Training loss: 3.8534745428309365
Validation loss: 3.191169110116608

Epoch: 5| Step: 9
Training loss: 3.1574532509768836
Validation loss: 3.1893819705786752

Epoch: 5| Step: 10
Training loss: 3.7752692473941276
Validation loss: 3.188471833173908

Epoch: 23| Step: 0
Training loss: 3.3748160418073216
Validation loss: 3.1870401353531226

Epoch: 5| Step: 1
Training loss: 3.8768387400474897
Validation loss: 3.186220377490669

Epoch: 5| Step: 2
Training loss: 3.1828657382713033
Validation loss: 3.1853440481589717

Epoch: 5| Step: 3
Training loss: 3.765757704806377
Validation loss: 3.1848811217333264

Epoch: 5| Step: 4
Training loss: 3.0394658701116763
Validation loss: 3.1828597151071523

Epoch: 5| Step: 5
Training loss: 3.5162214663283873
Validation loss: 3.1814145237668847

Epoch: 5| Step: 6
Training loss: 3.669460200595903
Validation loss: 3.181082548168268

Epoch: 5| Step: 7
Training loss: 3.6860133908339545
Validation loss: 3.1792883494337185

Epoch: 5| Step: 8
Training loss: 3.5882224654738115
Validation loss: 3.178344947847106

Epoch: 5| Step: 9
Training loss: 3.2925248938613625
Validation loss: 3.177137014875917

Epoch: 5| Step: 10
Training loss: 2.612725761916551
Validation loss: 3.1751896344326895

Epoch: 24| Step: 0
Training loss: 3.507874486158895
Validation loss: 3.1747708419513967

Epoch: 5| Step: 1
Training loss: 3.3098892864139535
Validation loss: 3.1732360095673626

Epoch: 5| Step: 2
Training loss: 3.975593853621448
Validation loss: 3.17169550390788

Epoch: 5| Step: 3
Training loss: 3.817074267237787
Validation loss: 3.171562930732903

Epoch: 5| Step: 4
Training loss: 4.045027498922723
Validation loss: 3.1694994163941206

Epoch: 5| Step: 5
Training loss: 2.8464900639030737
Validation loss: 3.1690118009576462

Epoch: 5| Step: 6
Training loss: 3.136461677325664
Validation loss: 3.167275626583587

Epoch: 5| Step: 7
Training loss: 3.4968365950942757
Validation loss: 3.165508512375409

Epoch: 5| Step: 8
Training loss: 3.0749523252187445
Validation loss: 3.1648224661730358

Epoch: 5| Step: 9
Training loss: 3.2759766847668104
Validation loss: 3.1633970552641175

Epoch: 5| Step: 10
Training loss: 3.027077546259649
Validation loss: 3.1621824751120817

Epoch: 25| Step: 0
Training loss: 2.9873495407203996
Validation loss: 3.161033717950541

Epoch: 5| Step: 1
Training loss: 3.071789102527267
Validation loss: 3.1605170829176776

Epoch: 5| Step: 2
Training loss: 3.7525906832803755
Validation loss: 3.1589598279119557

Epoch: 5| Step: 3
Training loss: 3.577289333791877
Validation loss: 3.1576259330466767

Epoch: 5| Step: 4
Training loss: 3.3267337953856977
Validation loss: 3.156935307258989

Epoch: 5| Step: 5
Training loss: 3.8704839663048407
Validation loss: 3.1556608132822075

Epoch: 5| Step: 6
Training loss: 3.8880101497815933
Validation loss: 3.1543784085762243

Epoch: 5| Step: 7
Training loss: 3.143118708117444
Validation loss: 3.153976320821318

Epoch: 5| Step: 8
Training loss: 3.4947617705308143
Validation loss: 3.1522436976316435

Epoch: 5| Step: 9
Training loss: 3.031778191236043
Validation loss: 3.151320939623796

Epoch: 5| Step: 10
Training loss: 3.3743784296788837
Validation loss: 3.150144590115207

Epoch: 26| Step: 0
Training loss: 2.954247639725094
Validation loss: 3.148563614649256

Epoch: 5| Step: 1
Training loss: 3.17718242219752
Validation loss: 3.1476976433301087

Epoch: 5| Step: 2
Training loss: 2.9113270702127267
Validation loss: 3.1463000554309146

Epoch: 5| Step: 3
Training loss: 2.958863833147019
Validation loss: 3.1448855788022225

Epoch: 5| Step: 4
Training loss: 3.8760571422163737
Validation loss: 3.142757887578761

Epoch: 5| Step: 5
Training loss: 2.5768672765171496
Validation loss: 3.141103111513034

Epoch: 5| Step: 6
Training loss: 3.6067125152757433
Validation loss: 3.138960860512581

Epoch: 5| Step: 7
Training loss: 3.536257813526959
Validation loss: 3.137236274055297

Epoch: 5| Step: 8
Training loss: 4.117694743866052
Validation loss: 3.1350513038651044

Epoch: 5| Step: 9
Training loss: 4.0523380830341615
Validation loss: 3.1337953975827446

Epoch: 5| Step: 10
Training loss: 3.3853551458001863
Validation loss: 3.1313825274401057

Epoch: 27| Step: 0
Training loss: 3.6749965953162373
Validation loss: 3.129613338256082

Epoch: 5| Step: 1
Training loss: 4.008376172974211
Validation loss: 3.1260667305130423

Epoch: 5| Step: 2
Training loss: 3.2752122824788463
Validation loss: 3.1249712690447775

Epoch: 5| Step: 3
Training loss: 3.2021700296142255
Validation loss: 3.122686498593266

Epoch: 5| Step: 4
Training loss: 3.1834959424680362
Validation loss: 3.1215276931253553

Epoch: 5| Step: 5
Training loss: 2.9283297635098102
Validation loss: 3.1206056885066635

Epoch: 5| Step: 6
Training loss: 3.2796955604690434
Validation loss: 3.1201060722148335

Epoch: 5| Step: 7
Training loss: 3.599865031361392
Validation loss: 3.1187123858240478

Epoch: 5| Step: 8
Training loss: 3.6670725482206614
Validation loss: 3.1173669224380927

Epoch: 5| Step: 9
Training loss: 3.277620469824697
Validation loss: 3.116353701083867

Epoch: 5| Step: 10
Training loss: 3.0862310728633755
Validation loss: 3.114571496459009

Epoch: 28| Step: 0
Training loss: 4.142759068272484
Validation loss: 3.1143053269376537

Epoch: 5| Step: 1
Training loss: 3.3216166728676217
Validation loss: 3.11238055203635

Epoch: 5| Step: 2
Training loss: 3.1466910769706513
Validation loss: 3.1115668940672863

Epoch: 5| Step: 3
Training loss: 3.674249538687647
Validation loss: 3.110321632967992

Epoch: 5| Step: 4
Training loss: 3.561029498797868
Validation loss: 3.109491704007089

Epoch: 5| Step: 5
Training loss: 2.51025062951121
Validation loss: 3.1091556093440045

Epoch: 5| Step: 6
Training loss: 3.3575244153371337
Validation loss: 3.1072678624267285

Epoch: 5| Step: 7
Training loss: 3.3096528683178614
Validation loss: 3.1060420469840953

Epoch: 5| Step: 8
Training loss: 3.3723454809173354
Validation loss: 3.104413664337766

Epoch: 5| Step: 9
Training loss: 3.7866854103278174
Validation loss: 3.103731102676361

Epoch: 5| Step: 10
Training loss: 2.651316740283195
Validation loss: 3.1024090342203645

Epoch: 29| Step: 0
Training loss: 3.5888539009107796
Validation loss: 3.1018291365079596

Epoch: 5| Step: 1
Training loss: 3.1816676017502745
Validation loss: 3.10015564467253

Epoch: 5| Step: 2
Training loss: 3.689035645467562
Validation loss: 3.0996146451815827

Epoch: 5| Step: 3
Training loss: 3.157076736798409
Validation loss: 3.098348836230237

Epoch: 5| Step: 4
Training loss: 3.1153353970689044
Validation loss: 3.097078530057969

Epoch: 5| Step: 5
Training loss: 3.2612973974664867
Validation loss: 3.0961647094058113

Epoch: 5| Step: 6
Training loss: 3.760063401357291
Validation loss: 3.0950253790085345

Epoch: 5| Step: 7
Training loss: 3.4130441643992313
Validation loss: 3.094062568964682

Epoch: 5| Step: 8
Training loss: 2.9916202814301416
Validation loss: 3.093275643504872

Epoch: 5| Step: 9
Training loss: 3.302993376246806
Validation loss: 3.091825388537993

Epoch: 5| Step: 10
Training loss: 3.6360233678706826
Validation loss: 3.090857948802816

Epoch: 30| Step: 0
Training loss: 3.0507049746386747
Validation loss: 3.0899782512560616

Epoch: 5| Step: 1
Training loss: 3.727694869189371
Validation loss: 3.0890838429936665

Epoch: 5| Step: 2
Training loss: 3.4807365819629523
Validation loss: 3.0881070601096985

Epoch: 5| Step: 3
Training loss: 3.797572946959095
Validation loss: 3.0870794544502838

Epoch: 5| Step: 4
Training loss: 2.8407739849909337
Validation loss: 3.086192547793581

Epoch: 5| Step: 5
Training loss: 3.971322254823972
Validation loss: 3.085401515435068

Epoch: 5| Step: 6
Training loss: 3.1666913449848337
Validation loss: 3.083527152885408

Epoch: 5| Step: 7
Training loss: 3.0204844481597166
Validation loss: 3.082138039086267

Epoch: 5| Step: 8
Training loss: 3.270020953003368
Validation loss: 3.081419817998109

Epoch: 5| Step: 9
Training loss: 3.1795012398417577
Validation loss: 3.080096226454069

Epoch: 5| Step: 10
Training loss: 3.357075600689552
Validation loss: 3.0790304981404293

Epoch: 31| Step: 0
Training loss: 3.418500795644099
Validation loss: 3.0773991637387588

Epoch: 5| Step: 1
Training loss: 3.446519843416964
Validation loss: 3.076224559587353

Epoch: 5| Step: 2
Training loss: 3.6774716843086095
Validation loss: 3.0745974480224603

Epoch: 5| Step: 3
Training loss: 3.330680331820861
Validation loss: 3.0736270045292335

Epoch: 5| Step: 4
Training loss: 2.714499999314212
Validation loss: 3.073195875083165

Epoch: 5| Step: 5
Training loss: 3.5733351985964483
Validation loss: 3.0710679795037006

Epoch: 5| Step: 6
Training loss: 3.672362210030508
Validation loss: 3.068317729626891

Epoch: 5| Step: 7
Training loss: 3.39183156567865
Validation loss: 3.066075981062106

Epoch: 5| Step: 8
Training loss: 2.9246321944126947
Validation loss: 3.06293682995208

Epoch: 5| Step: 9
Training loss: 3.4780788586512914
Validation loss: 3.0595122783918547

Epoch: 5| Step: 10
Training loss: 3.121853885063729
Validation loss: 3.059265875061894

Epoch: 32| Step: 0
Training loss: 3.112891887215047
Validation loss: 3.0749572741600475

Epoch: 5| Step: 1
Training loss: 3.15600131726449
Validation loss: 3.0595290485690563

Epoch: 5| Step: 2
Training loss: 3.570025743450448
Validation loss: 3.0625137980060093

Epoch: 5| Step: 3
Training loss: 3.594176955361296
Validation loss: 3.0663665578716186

Epoch: 5| Step: 4
Training loss: 3.1698350782845073
Validation loss: 3.059537208223311

Epoch: 5| Step: 5
Training loss: 3.7131949856347126
Validation loss: 3.0549003695382937

Epoch: 5| Step: 6
Training loss: 3.858756567946647
Validation loss: 3.05159345491552

Epoch: 5| Step: 7
Training loss: 3.2328229488242664
Validation loss: 3.0459868064938673

Epoch: 5| Step: 8
Training loss: 3.3926953442076697
Validation loss: 3.0472177788593884

Epoch: 5| Step: 9
Training loss: 2.567842450356625
Validation loss: 3.0507948564742766

Epoch: 5| Step: 10
Training loss: 3.2434601641402576
Validation loss: 3.0542320413577437

Epoch: 33| Step: 0
Training loss: 2.8062952050728978
Validation loss: 3.051102146467402

Epoch: 5| Step: 1
Training loss: 3.454334720316685
Validation loss: 3.0466235086222255

Epoch: 5| Step: 2
Training loss: 3.377137390369272
Validation loss: 3.037006741858219

Epoch: 5| Step: 3
Training loss: 3.0927103781166054
Validation loss: 3.0350591037145427

Epoch: 5| Step: 4
Training loss: 2.97122859884538
Validation loss: 3.0365400256730224

Epoch: 5| Step: 5
Training loss: 3.7080988577675558
Validation loss: 3.0361275874907916

Epoch: 5| Step: 6
Training loss: 3.8349496225880317
Validation loss: 3.031193614181988

Epoch: 5| Step: 7
Training loss: 3.4038402187622263
Validation loss: 3.03219668701085

Epoch: 5| Step: 8
Training loss: 3.5773555811236304
Validation loss: 3.037718103119558

Epoch: 5| Step: 9
Training loss: 2.9939949015113365
Validation loss: 3.0601446550726967

Epoch: 5| Step: 10
Training loss: 3.243622170577428
Validation loss: 3.0356762843426144

Epoch: 34| Step: 0
Training loss: 3.2311593255135267
Validation loss: 3.032510201808018

Epoch: 5| Step: 1
Training loss: 3.2669345110122983
Validation loss: 3.0276876037703

Epoch: 5| Step: 2
Training loss: 2.854760286920141
Validation loss: 3.025133640812288

Epoch: 5| Step: 3
Training loss: 3.3630481599325024
Validation loss: 3.024561276847328

Epoch: 5| Step: 4
Training loss: 3.7044580048229823
Validation loss: 3.0251208053517598

Epoch: 5| Step: 5
Training loss: 3.08289057327765
Validation loss: 3.023561326368047

Epoch: 5| Step: 6
Training loss: 3.8565427449549357
Validation loss: 3.0234040781026397

Epoch: 5| Step: 7
Training loss: 2.244030344671207
Validation loss: 3.023163118488174

Epoch: 5| Step: 8
Training loss: 3.223877165742728
Validation loss: 3.0210135711999335

Epoch: 5| Step: 9
Training loss: 3.3448128125284518
Validation loss: 3.0205920000320083

Epoch: 5| Step: 10
Training loss: 4.105192311250901
Validation loss: 3.020041905578062

Epoch: 35| Step: 0
Training loss: 2.9185881870024177
Validation loss: 3.019421899414281

Epoch: 5| Step: 1
Training loss: 3.2688379863034944
Validation loss: 3.0184338780949154

Epoch: 5| Step: 2
Training loss: 3.5491715445077814
Validation loss: 3.0170157106267363

Epoch: 5| Step: 3
Training loss: 3.232579124290665
Validation loss: 3.0165668461742268

Epoch: 5| Step: 4
Training loss: 3.228890897399156
Validation loss: 3.014507042481969

Epoch: 5| Step: 5
Training loss: 3.3331998003598065
Validation loss: 3.014232606699286

Epoch: 5| Step: 6
Training loss: 3.6657008430719547
Validation loss: 3.013067460902713

Epoch: 5| Step: 7
Training loss: 3.436569365324312
Validation loss: 3.012504449506716

Epoch: 5| Step: 8
Training loss: 3.140416987728146
Validation loss: 3.0123259368009623

Epoch: 5| Step: 9
Training loss: 3.0767039780370875
Validation loss: 3.011012217730112

Epoch: 5| Step: 10
Training loss: 3.5508598092330623
Validation loss: 3.010449506635378

Epoch: 36| Step: 0
Training loss: 3.090965636394014
Validation loss: 3.009168211368816

Epoch: 5| Step: 1
Training loss: 3.7028608912031857
Validation loss: 3.0089439596144247

Epoch: 5| Step: 2
Training loss: 3.428406912966497
Validation loss: 3.0077274817096233

Epoch: 5| Step: 3
Training loss: 2.889666754176909
Validation loss: 3.006814069830635

Epoch: 5| Step: 4
Training loss: 3.698658756782125
Validation loss: 3.005932361119378

Epoch: 5| Step: 5
Training loss: 2.8410222311898994
Validation loss: 3.00524927964702

Epoch: 5| Step: 6
Training loss: 3.0517142184386317
Validation loss: 3.004098306989513

Epoch: 5| Step: 7
Training loss: 3.2228453424637724
Validation loss: 3.003131262904051

Epoch: 5| Step: 8
Training loss: 3.4764851422222125
Validation loss: 3.0020925460238783

Epoch: 5| Step: 9
Training loss: 3.1498789930564692
Validation loss: 3.001434603558347

Epoch: 5| Step: 10
Training loss: 3.700910719059791
Validation loss: 3.001035594456018

Epoch: 37| Step: 0
Training loss: 3.1965204394656817
Validation loss: 2.9996748905331723

Epoch: 5| Step: 1
Training loss: 3.1602564396200754
Validation loss: 2.998913089511626

Epoch: 5| Step: 2
Training loss: 3.9415359400119963
Validation loss: 2.997772871897898

Epoch: 5| Step: 3
Training loss: 2.9312447033409303
Validation loss: 2.9971810824495475

Epoch: 5| Step: 4
Training loss: 2.7590210079486974
Validation loss: 2.9963363748376772

Epoch: 5| Step: 5
Training loss: 2.8164504387678555
Validation loss: 2.995406246747249

Epoch: 5| Step: 6
Training loss: 3.034594706036908
Validation loss: 2.9947851396929153

Epoch: 5| Step: 7
Training loss: 3.9211243902826936
Validation loss: 2.993491550781352

Epoch: 5| Step: 8
Training loss: 3.871701959741152
Validation loss: 2.992894822067074

Epoch: 5| Step: 9
Training loss: 3.1158122994494373
Validation loss: 2.993079307343962

Epoch: 5| Step: 10
Training loss: 3.2164102587189616
Validation loss: 2.9919048492726916

Epoch: 38| Step: 0
Training loss: 2.7228234128931446
Validation loss: 2.990409705705714

Epoch: 5| Step: 1
Training loss: 3.393426818634121
Validation loss: 2.9885927125266143

Epoch: 5| Step: 2
Training loss: 3.7601093085612685
Validation loss: 2.988333426903441

Epoch: 5| Step: 3
Training loss: 2.772576856726002
Validation loss: 2.9863641337094524

Epoch: 5| Step: 4
Training loss: 3.79074279652443
Validation loss: 2.9846780454854502

Epoch: 5| Step: 5
Training loss: 3.5863693741841396
Validation loss: 2.9831054715516

Epoch: 5| Step: 6
Training loss: 2.9576516955595182
Validation loss: 2.9821427328249244

Epoch: 5| Step: 7
Training loss: 2.7486522146112278
Validation loss: 2.981531103441612

Epoch: 5| Step: 8
Training loss: 3.761925617364854
Validation loss: 2.978818516116368

Epoch: 5| Step: 9
Training loss: 3.065442909486856
Validation loss: 2.9779349466467906

Epoch: 5| Step: 10
Training loss: 3.3469445485814813
Validation loss: 2.9791141823493223

Epoch: 39| Step: 0
Training loss: 3.4171558743213897
Validation loss: 2.9755206427294953

Epoch: 5| Step: 1
Training loss: 3.4763508592971504
Validation loss: 2.979320654377034

Epoch: 5| Step: 2
Training loss: 3.6083655328760216
Validation loss: 2.9759842686683924

Epoch: 5| Step: 3
Training loss: 3.946675221996657
Validation loss: 2.9762929722705795

Epoch: 5| Step: 4
Training loss: 3.088240061417007
Validation loss: 2.9753826631170464

Epoch: 5| Step: 5
Training loss: 3.6157951558924077
Validation loss: 2.9737212573624876

Epoch: 5| Step: 6
Training loss: 3.216169934304729
Validation loss: 2.971972302978429

Epoch: 5| Step: 7
Training loss: 2.9252215309697527
Validation loss: 2.9680362484589695

Epoch: 5| Step: 8
Training loss: 3.393122443245448
Validation loss: 2.9675592388654572

Epoch: 5| Step: 9
Training loss: 2.346632037431071
Validation loss: 2.9695799690167357

Epoch: 5| Step: 10
Training loss: 2.632377158375442
Validation loss: 2.9694168119143995

Epoch: 40| Step: 0
Training loss: 3.5745734700602934
Validation loss: 2.9729956914058846

Epoch: 5| Step: 1
Training loss: 3.3273966534025825
Validation loss: 2.970331404878056

Epoch: 5| Step: 2
Training loss: 2.8620159689446423
Validation loss: 2.9672436643090485

Epoch: 5| Step: 3
Training loss: 3.2390967654795584
Validation loss: 2.967600677585133

Epoch: 5| Step: 4
Training loss: 3.4475325786332034
Validation loss: 2.966014891401497

Epoch: 5| Step: 5
Training loss: 3.383614883233544
Validation loss: 2.9616916895254173

Epoch: 5| Step: 6
Training loss: 3.3969255964762617
Validation loss: 2.9600224823695167

Epoch: 5| Step: 7
Training loss: 3.420100618633485
Validation loss: 2.957155364610585

Epoch: 5| Step: 8
Training loss: 2.9749714761857216
Validation loss: 2.9592939952019734

Epoch: 5| Step: 9
Training loss: 3.113929365176512
Validation loss: 2.963821949498432

Epoch: 5| Step: 10
Training loss: 3.1504106042066415
Validation loss: 2.9564713799201523

Epoch: 41| Step: 0
Training loss: 2.9809163608635294
Validation loss: 2.9605302679168277

Epoch: 5| Step: 1
Training loss: 3.568733250032523
Validation loss: 2.962685671373512

Epoch: 5| Step: 2
Training loss: 3.6627577551018295
Validation loss: 2.967915147406495

Epoch: 5| Step: 3
Training loss: 2.33559800554763
Validation loss: 2.965884723068108

Epoch: 5| Step: 4
Training loss: 2.631985316522564
Validation loss: 2.968600988615271

Epoch: 5| Step: 5
Training loss: 3.5679870645091865
Validation loss: 2.959241975076168

Epoch: 5| Step: 6
Training loss: 3.7972420723008766
Validation loss: 2.9514976662542893

Epoch: 5| Step: 7
Training loss: 2.8287172487717
Validation loss: 2.9496002804527968

Epoch: 5| Step: 8
Training loss: 3.048075747472346
Validation loss: 2.9510448165654406

Epoch: 5| Step: 9
Training loss: 3.715882036896999
Validation loss: 2.9530368628357286

Epoch: 5| Step: 10
Training loss: 3.463804689138738
Validation loss: 2.953744979811847

Epoch: 42| Step: 0
Training loss: 3.7797841154746825
Validation loss: 2.9523286732721976

Epoch: 5| Step: 1
Training loss: 2.686062716793594
Validation loss: 2.9509250945455254

Epoch: 5| Step: 2
Training loss: 3.857461678987673
Validation loss: 2.950872668860895

Epoch: 5| Step: 3
Training loss: 2.4940001971712014
Validation loss: 2.9475394708832523

Epoch: 5| Step: 4
Training loss: 2.7599119672695425
Validation loss: 2.948196109745794

Epoch: 5| Step: 5
Training loss: 3.1649574050327103
Validation loss: 2.947812706904865

Epoch: 5| Step: 6
Training loss: 3.0404495172937693
Validation loss: 2.9485990687516916

Epoch: 5| Step: 7
Training loss: 3.0653971767251007
Validation loss: 2.9455971698723014

Epoch: 5| Step: 8
Training loss: 3.7231304110900276
Validation loss: 2.9449980749564815

Epoch: 5| Step: 9
Training loss: 3.3752267549422266
Validation loss: 2.944020806438667

Epoch: 5| Step: 10
Training loss: 3.604239505333157
Validation loss: 2.944519400988851

Epoch: 43| Step: 0
Training loss: 3.1598094848954044
Validation loss: 2.943295410440211

Epoch: 5| Step: 1
Training loss: 3.304290098279639
Validation loss: 2.939993675012505

Epoch: 5| Step: 2
Training loss: 4.015337625751949
Validation loss: 2.9446814729223303

Epoch: 5| Step: 3
Training loss: 3.297887854451256
Validation loss: 2.9375578683264294

Epoch: 5| Step: 4
Training loss: 2.725616553314704
Validation loss: 2.939395632386168

Epoch: 5| Step: 5
Training loss: 2.9695218337746985
Validation loss: 2.946171511448562

Epoch: 5| Step: 6
Training loss: 3.6216457238420543
Validation loss: 2.9619605604125954

Epoch: 5| Step: 7
Training loss: 3.078236069587559
Validation loss: 2.9551433752336

Epoch: 5| Step: 8
Training loss: 2.993227944618048
Validation loss: 2.946313224040082

Epoch: 5| Step: 9
Training loss: 3.0821726564716907
Validation loss: 2.9390983457109137

Epoch: 5| Step: 10
Training loss: 3.3088594980715813
Validation loss: 2.936921025323482

Epoch: 44| Step: 0
Training loss: 2.95196688109844
Validation loss: 2.9397024042217406

Epoch: 5| Step: 1
Training loss: 3.721569627201983
Validation loss: 2.940765126651182

Epoch: 5| Step: 2
Training loss: 3.5760545362371894
Validation loss: 2.949814994034483

Epoch: 5| Step: 3
Training loss: 3.2328761954137755
Validation loss: 2.933623328433329

Epoch: 5| Step: 4
Training loss: 2.961022207210996
Validation loss: 2.9389238260313753

Epoch: 5| Step: 5
Training loss: 3.403107059315873
Validation loss: 2.9960318645332227

Epoch: 5| Step: 6
Training loss: 3.1836223577606524
Validation loss: 2.9463277532372607

Epoch: 5| Step: 7
Training loss: 3.254837836988622
Validation loss: 2.944502219566346

Epoch: 5| Step: 8
Training loss: 2.7054480124198457
Validation loss: 2.9338109789795754

Epoch: 5| Step: 9
Training loss: 3.1815114331697205
Validation loss: 2.9352191386253446

Epoch: 5| Step: 10
Training loss: 3.4719920086307234
Validation loss: 2.947316904923305

Epoch: 45| Step: 0
Training loss: 2.945530729025716
Validation loss: 2.952264076360959

Epoch: 5| Step: 1
Training loss: 2.9869293944855144
Validation loss: 2.970471245094728

Epoch: 5| Step: 2
Training loss: 3.229943524507633
Validation loss: 2.978740233652574

Epoch: 5| Step: 3
Training loss: 3.5967654638241027
Validation loss: 2.9346537453559005

Epoch: 5| Step: 4
Training loss: 3.6625752307859822
Validation loss: 2.9286717216566265

Epoch: 5| Step: 5
Training loss: 3.287797770775836
Validation loss: 2.9325194261173912

Epoch: 5| Step: 6
Training loss: 3.2434250273750935
Validation loss: 2.9350220049425397

Epoch: 5| Step: 7
Training loss: 2.9617691683773213
Validation loss: 2.935046670632809

Epoch: 5| Step: 8
Training loss: 3.1564344597726612
Validation loss: 2.9330915413855982

Epoch: 5| Step: 9
Training loss: 2.840362039780987
Validation loss: 2.923692500449242

Epoch: 5| Step: 10
Training loss: 3.5871230349383953
Validation loss: 2.922365781847565

Epoch: 46| Step: 0
Training loss: 3.5628439753928554
Validation loss: 2.920435001970358

Epoch: 5| Step: 1
Training loss: 3.2626783592608035
Validation loss: 2.919606887894073

Epoch: 5| Step: 2
Training loss: 3.8266462934485563
Validation loss: 2.9197635915164613

Epoch: 5| Step: 3
Training loss: 3.580734966851363
Validation loss: 2.9236123490955506

Epoch: 5| Step: 4
Training loss: 2.7200994540713146
Validation loss: 2.9206452184931577

Epoch: 5| Step: 5
Training loss: 3.1754581150949948
Validation loss: 2.925058396573956

Epoch: 5| Step: 6
Training loss: 3.3980482558157616
Validation loss: 2.9250776606801634

Epoch: 5| Step: 7
Training loss: 2.60588598842466
Validation loss: 2.9098219975845656

Epoch: 5| Step: 8
Training loss: 3.478847207271473
Validation loss: 2.908518182749802

Epoch: 5| Step: 9
Training loss: 2.7361942887505295
Validation loss: 2.9069634182818436

Epoch: 5| Step: 10
Training loss: 2.8636755782355676
Validation loss: 2.9088832954273722

Epoch: 47| Step: 0
Training loss: 3.1948817925831157
Validation loss: 2.910432384312669

Epoch: 5| Step: 1
Training loss: 2.934021858846399
Validation loss: 2.8980582259721275

Epoch: 5| Step: 2
Training loss: 2.8555093284886057
Validation loss: 2.8966943631273043

Epoch: 5| Step: 3
Training loss: 3.587667874651804
Validation loss: 2.893442663396647

Epoch: 5| Step: 4
Training loss: 2.8921663041371137
Validation loss: 2.8930180482572885

Epoch: 5| Step: 5
Training loss: 3.7928820049137095
Validation loss: 2.892323936946345

Epoch: 5| Step: 6
Training loss: 2.7731522534320634
Validation loss: 2.896785322575349

Epoch: 5| Step: 7
Training loss: 3.1226700298357453
Validation loss: 2.8988382561993506

Epoch: 5| Step: 8
Training loss: 3.8943516298614322
Validation loss: 2.9060856083177353

Epoch: 5| Step: 9
Training loss: 3.155132435771256
Validation loss: 2.8979467926248836

Epoch: 5| Step: 10
Training loss: 2.7986993220972867
Validation loss: 2.891533502378693

Epoch: 48| Step: 0
Training loss: 3.2975704670882466
Validation loss: 2.8906433681357866

Epoch: 5| Step: 1
Training loss: 3.147514567686127
Validation loss: 2.892679541385744

Epoch: 5| Step: 2
Training loss: 3.4156121898526077
Validation loss: 2.8996059003194565

Epoch: 5| Step: 3
Training loss: 3.5193280194167684
Validation loss: 2.917291947476955

Epoch: 5| Step: 4
Training loss: 2.8662546911588027
Validation loss: 2.935616256864082

Epoch: 5| Step: 5
Training loss: 3.4152039599076005
Validation loss: 2.9583887103413686

Epoch: 5| Step: 6
Training loss: 2.790441690300181
Validation loss: 2.903934369106993

Epoch: 5| Step: 7
Training loss: 3.095235756813815
Validation loss: 2.8870431726965453

Epoch: 5| Step: 8
Training loss: 2.8654778395943916
Validation loss: 2.890941716264767

Epoch: 5| Step: 9
Training loss: 3.069559951457743
Validation loss: 2.891571877823708

Epoch: 5| Step: 10
Training loss: 3.7364235849344873
Validation loss: 2.8940763215233436

Epoch: 49| Step: 0
Training loss: 3.4458448902629764
Validation loss: 2.892855135204808

Epoch: 5| Step: 1
Training loss: 2.4695019120160504
Validation loss: 2.889295484772925

Epoch: 5| Step: 2
Training loss: 3.288149165470935
Validation loss: 2.8888646577818555

Epoch: 5| Step: 3
Training loss: 3.24669420401653
Validation loss: 2.890158759166769

Epoch: 5| Step: 4
Training loss: 3.33657309130061
Validation loss: 2.8854085648845227

Epoch: 5| Step: 5
Training loss: 3.5458753076049527
Validation loss: 2.8840152821253344

Epoch: 5| Step: 6
Training loss: 3.493389016816613
Validation loss: 2.8827963878973804

Epoch: 5| Step: 7
Training loss: 3.4188263433046475
Validation loss: 2.88462765641359

Epoch: 5| Step: 8
Training loss: 2.397636056008913
Validation loss: 2.885576380500879

Epoch: 5| Step: 9
Training loss: 3.269284183186676
Validation loss: 2.8894540789256364

Epoch: 5| Step: 10
Training loss: 2.8726042011640605
Validation loss: 2.8917748919800887

Epoch: 50| Step: 0
Training loss: 2.7086997346742794
Validation loss: 2.8928847278424894

Epoch: 5| Step: 1
Training loss: 3.2119237123125792
Validation loss: 2.905445971654704

Epoch: 5| Step: 2
Training loss: 3.0102762015724434
Validation loss: 2.9022830472131

Epoch: 5| Step: 3
Training loss: 2.7787931070145895
Validation loss: 2.896469365655944

Epoch: 5| Step: 4
Training loss: 3.1783598956508587
Validation loss: 2.8884583534437036

Epoch: 5| Step: 5
Training loss: 2.7751991372354263
Validation loss: 2.8831592183127976

Epoch: 5| Step: 6
Training loss: 3.003173738812519
Validation loss: 2.881808383334398

Epoch: 5| Step: 7
Training loss: 3.292587746947695
Validation loss: 2.8808272908188104

Epoch: 5| Step: 8
Training loss: 3.5613232727118147
Validation loss: 2.880080248811053

Epoch: 5| Step: 9
Training loss: 3.8787496329629167
Validation loss: 2.885730736236786

Epoch: 5| Step: 10
Training loss: 3.374975133733627
Validation loss: 2.8872686667666563

Epoch: 51| Step: 0
Training loss: 2.6680748221673527
Validation loss: 2.876587135834323

Epoch: 5| Step: 1
Training loss: 3.582221206071182
Validation loss: 2.8764788287181564

Epoch: 5| Step: 2
Training loss: 2.7555476498319504
Validation loss: 2.888348688798967

Epoch: 5| Step: 3
Training loss: 3.277054056633808
Validation loss: 2.901740651268149

Epoch: 5| Step: 4
Training loss: 3.653814825317501
Validation loss: 2.87511959781289

Epoch: 5| Step: 5
Training loss: 2.8955382784548145
Validation loss: 2.8752568457012595

Epoch: 5| Step: 6
Training loss: 3.239534400169693
Validation loss: 2.8762221589887513

Epoch: 5| Step: 7
Training loss: 3.284706402436528
Validation loss: 2.8763137212773437

Epoch: 5| Step: 8
Training loss: 3.3890820345704733
Validation loss: 2.8780096653790936

Epoch: 5| Step: 9
Training loss: 2.8542750168628124
Validation loss: 2.877295003859432

Epoch: 5| Step: 10
Training loss: 3.1477437734093145
Validation loss: 2.8796998630120507

Epoch: 52| Step: 0
Training loss: 3.263835069650034
Validation loss: 2.881478195010646

Epoch: 5| Step: 1
Training loss: 3.427197640936972
Validation loss: 2.883557353889089

Epoch: 5| Step: 2
Training loss: 3.0793651270800066
Validation loss: 2.891729859531663

Epoch: 5| Step: 3
Training loss: 3.459558767729001
Validation loss: 2.87677688403553

Epoch: 5| Step: 4
Training loss: 2.7881280097526173
Validation loss: 2.878805988742215

Epoch: 5| Step: 5
Training loss: 3.023429141168597
Validation loss: 2.8836871049682595

Epoch: 5| Step: 6
Training loss: 2.7784327264714084
Validation loss: 2.8801313764306764

Epoch: 5| Step: 7
Training loss: 2.896258005156668
Validation loss: 2.884088213014927

Epoch: 5| Step: 8
Training loss: 3.1723665504855596
Validation loss: 2.8711131690342935

Epoch: 5| Step: 9
Training loss: 2.9863139140337966
Validation loss: 2.871492059471798

Epoch: 5| Step: 10
Training loss: 3.908672466625335
Validation loss: 2.874218130420324

Epoch: 53| Step: 0
Training loss: 3.4386995476724334
Validation loss: 2.8740247202015823

Epoch: 5| Step: 1
Training loss: 3.6972644642678447
Validation loss: 2.8704289001188243

Epoch: 5| Step: 2
Training loss: 2.905643687016851
Validation loss: 2.866807165182277

Epoch: 5| Step: 3
Training loss: 3.6201758018504724
Validation loss: 2.865059124017747

Epoch: 5| Step: 4
Training loss: 3.138507033970565
Validation loss: 2.865691887183422

Epoch: 5| Step: 5
Training loss: 2.6866979067416277
Validation loss: 2.8651826227542507

Epoch: 5| Step: 6
Training loss: 3.2118744237349586
Validation loss: 2.8630875880656284

Epoch: 5| Step: 7
Training loss: 3.1604409673096443
Validation loss: 2.859545652346059

Epoch: 5| Step: 8
Training loss: 3.4459553159981566
Validation loss: 2.860601914955388

Epoch: 5| Step: 9
Training loss: 2.531915082800217
Validation loss: 2.8573157071421345

Epoch: 5| Step: 10
Training loss: 2.6397914135055496
Validation loss: 2.8620238882280242

Epoch: 54| Step: 0
Training loss: 2.859998291121819
Validation loss: 2.868543130660281

Epoch: 5| Step: 1
Training loss: 2.9616014043271917
Validation loss: 2.8754590529827633

Epoch: 5| Step: 2
Training loss: 2.781001562102317
Validation loss: 2.8635998535356197

Epoch: 5| Step: 3
Training loss: 3.193326225458675
Validation loss: 2.8607817458038496

Epoch: 5| Step: 4
Training loss: 2.8896842456699057
Validation loss: 2.86044887938085

Epoch: 5| Step: 5
Training loss: 3.861319357167903
Validation loss: 2.8640417216052487

Epoch: 5| Step: 6
Training loss: 3.163185732834497
Validation loss: 2.8677001273114824

Epoch: 5| Step: 7
Training loss: 2.9411374560741734
Validation loss: 2.8609217219225305

Epoch: 5| Step: 8
Training loss: 2.8792446149845414
Validation loss: 2.8548387335467966

Epoch: 5| Step: 9
Training loss: 3.8269661531210057
Validation loss: 2.8570001715601685

Epoch: 5| Step: 10
Training loss: 3.104309249436611
Validation loss: 2.854589039558122

Epoch: 55| Step: 0
Training loss: 3.348920585613388
Validation loss: 2.8519212300191175

Epoch: 5| Step: 1
Training loss: 3.6724134983706747
Validation loss: 2.850024540537725

Epoch: 5| Step: 2
Training loss: 2.854547479846371
Validation loss: 2.8476527245664287

Epoch: 5| Step: 3
Training loss: 3.002424214317445
Validation loss: 2.8487698678118645

Epoch: 5| Step: 4
Training loss: 3.1022301250813746
Validation loss: 2.852623275136869

Epoch: 5| Step: 5
Training loss: 3.6184943126946347
Validation loss: 2.8518092946706464

Epoch: 5| Step: 6
Training loss: 3.1457708154659807
Validation loss: 2.8491540456041093

Epoch: 5| Step: 7
Training loss: 2.530092045161307
Validation loss: 2.8490169493845645

Epoch: 5| Step: 8
Training loss: 3.041995792784782
Validation loss: 2.844878401842332

Epoch: 5| Step: 9
Training loss: 3.320859760736077
Validation loss: 2.8453626345729672

Epoch: 5| Step: 10
Training loss: 2.7390862559078832
Validation loss: 2.844985023917744

Epoch: 56| Step: 0
Training loss: 2.60345335282804
Validation loss: 2.8439491722389443

Epoch: 5| Step: 1
Training loss: 2.827522255753437
Validation loss: 2.84241514035918

Epoch: 5| Step: 2
Training loss: 3.205500173356595
Validation loss: 2.84199846271085

Epoch: 5| Step: 3
Training loss: 3.1417114504211745
Validation loss: 2.843950471209175

Epoch: 5| Step: 4
Training loss: 3.524012753371544
Validation loss: 2.8457934279053654

Epoch: 5| Step: 5
Training loss: 3.1776294843341115
Validation loss: 2.8453935563498485

Epoch: 5| Step: 6
Training loss: 2.42924441501611
Validation loss: 2.8381037118063865

Epoch: 5| Step: 7
Training loss: 3.4000453609357772
Validation loss: 2.837419952785686

Epoch: 5| Step: 8
Training loss: 3.202237783234333
Validation loss: 2.834841563090089

Epoch: 5| Step: 9
Training loss: 3.122177069696883
Validation loss: 2.833352436915737

Epoch: 5| Step: 10
Training loss: 3.7859422558523574
Validation loss: 2.8316425246519104

Epoch: 57| Step: 0
Training loss: 3.368924075921167
Validation loss: 2.8306286619432592

Epoch: 5| Step: 1
Training loss: 2.835940190253545
Validation loss: 2.830138960667196

Epoch: 5| Step: 2
Training loss: 3.022667286473858
Validation loss: 2.830931221317938

Epoch: 5| Step: 3
Training loss: 2.9070426926340236
Validation loss: 2.831864284392693

Epoch: 5| Step: 4
Training loss: 2.902209354538925
Validation loss: 2.829692387432402

Epoch: 5| Step: 5
Training loss: 3.126690674251089
Validation loss: 2.8300997440546736

Epoch: 5| Step: 6
Training loss: 3.054119554878814
Validation loss: 2.8281196825794104

Epoch: 5| Step: 7
Training loss: 3.279312869879843
Validation loss: 2.826270457682624

Epoch: 5| Step: 8
Training loss: 3.830209094681957
Validation loss: 2.8267129253076098

Epoch: 5| Step: 9
Training loss: 3.0180366636846423
Validation loss: 2.8225360642998245

Epoch: 5| Step: 10
Training loss: 2.966191202988362
Validation loss: 2.8260488177971936

Epoch: 58| Step: 0
Training loss: 2.802960472424316
Validation loss: 2.8344589750442295

Epoch: 5| Step: 1
Training loss: 3.653058476817253
Validation loss: 2.8590052183060917

Epoch: 5| Step: 2
Training loss: 3.3974140599309792
Validation loss: 2.827475025808772

Epoch: 5| Step: 3
Training loss: 3.221536855777808
Validation loss: 2.82112104310948

Epoch: 5| Step: 4
Training loss: 2.792100806189896
Validation loss: 2.8186715453110684

Epoch: 5| Step: 5
Training loss: 3.6588962466534105
Validation loss: 2.845547470081265

Epoch: 5| Step: 6
Training loss: 2.5776002292033873
Validation loss: 2.838246505367163

Epoch: 5| Step: 7
Training loss: 2.935783534050368
Validation loss: 2.827192423910793

Epoch: 5| Step: 8
Training loss: 3.2459024861860994
Validation loss: 2.8199016558245833

Epoch: 5| Step: 9
Training loss: 3.0783533311768134
Validation loss: 2.818136946452618

Epoch: 5| Step: 10
Training loss: 2.935160902769469
Validation loss: 2.8176199366319867

Epoch: 59| Step: 0
Training loss: 3.2532738555359537
Validation loss: 2.829563295226616

Epoch: 5| Step: 1
Training loss: 3.490063868596786
Validation loss: 2.8432259999207403

Epoch: 5| Step: 2
Training loss: 3.6338985009386975
Validation loss: 2.861033958459161

Epoch: 5| Step: 3
Training loss: 2.9983584363253013
Validation loss: 2.831446238778348

Epoch: 5| Step: 4
Training loss: 3.5153217100079925
Validation loss: 2.819608981760846

Epoch: 5| Step: 5
Training loss: 2.7158199613448173
Validation loss: 2.8328641892747903

Epoch: 5| Step: 6
Training loss: 2.434744818317161
Validation loss: 2.8478027271867665

Epoch: 5| Step: 7
Training loss: 3.3881278269139714
Validation loss: 2.853717748590981

Epoch: 5| Step: 8
Training loss: 2.6361104984191175
Validation loss: 2.843496200196362

Epoch: 5| Step: 9
Training loss: 3.1058215822557584
Validation loss: 2.8401694200692416

Epoch: 5| Step: 10
Training loss: 3.356732415846798
Validation loss: 2.831876465864237

Epoch: 60| Step: 0
Training loss: 3.559996411182438
Validation loss: 2.821156920496799

Epoch: 5| Step: 1
Training loss: 3.1559034100583885
Validation loss: 2.815859697793023

Epoch: 5| Step: 2
Training loss: 3.3956122921264056
Validation loss: 2.8073427431316564

Epoch: 5| Step: 3
Training loss: 3.014421766512739
Validation loss: 2.805643638563714

Epoch: 5| Step: 4
Training loss: 3.0993263004797837
Validation loss: 2.807542587908531

Epoch: 5| Step: 5
Training loss: 2.7272510260383256
Validation loss: 2.8063577749266453

Epoch: 5| Step: 6
Training loss: 3.42317836795791
Validation loss: 2.8067572151133673

Epoch: 5| Step: 7
Training loss: 3.1656229574605486
Validation loss: 2.8059341101222133

Epoch: 5| Step: 8
Training loss: 2.715869034841408
Validation loss: 2.8175867456411265

Epoch: 5| Step: 9
Training loss: 3.2149288866119075
Validation loss: 2.819811439266793

Epoch: 5| Step: 10
Training loss: 2.7366099787643843
Validation loss: 2.8220738140784243

Epoch: 61| Step: 0
Training loss: 3.5611095726683004
Validation loss: 2.8189615584108245

Epoch: 5| Step: 1
Training loss: 3.3440568729656657
Validation loss: 2.813873952615611

Epoch: 5| Step: 2
Training loss: 2.8930452679211935
Validation loss: 2.8009179494506484

Epoch: 5| Step: 3
Training loss: 3.2559563268220986
Validation loss: 2.797538018320965

Epoch: 5| Step: 4
Training loss: 3.408142823830802
Validation loss: 2.793906259526713

Epoch: 5| Step: 5
Training loss: 3.294511716376316
Validation loss: 2.8030603269083865

Epoch: 5| Step: 6
Training loss: 2.5539532927541617
Validation loss: 2.7965214250829034

Epoch: 5| Step: 7
Training loss: 2.6262567327413997
Validation loss: 2.7945725856690475

Epoch: 5| Step: 8
Training loss: 3.099985178019868
Validation loss: 2.7959054941774415

Epoch: 5| Step: 9
Training loss: 2.918727873038284
Validation loss: 2.7941526811489124

Epoch: 5| Step: 10
Training loss: 3.303709494161671
Validation loss: 2.799025883112851

Epoch: 62| Step: 0
Training loss: 2.6187005523164797
Validation loss: 2.7997712056487787

Epoch: 5| Step: 1
Training loss: 2.826711986631286
Validation loss: 2.796103174770035

Epoch: 5| Step: 2
Training loss: 2.716220950986432
Validation loss: 2.7973035011046083

Epoch: 5| Step: 3
Training loss: 3.382599081659133
Validation loss: 2.798946573811372

Epoch: 5| Step: 4
Training loss: 3.4222049641139627
Validation loss: 2.7982359449911924

Epoch: 5| Step: 5
Training loss: 3.483554897532274
Validation loss: 2.792390398650526

Epoch: 5| Step: 6
Training loss: 3.4310644770150516
Validation loss: 2.7913623203735023

Epoch: 5| Step: 7
Training loss: 3.4523517554165077
Validation loss: 2.7904293297847755

Epoch: 5| Step: 8
Training loss: 2.721944926750932
Validation loss: 2.7931377561403936

Epoch: 5| Step: 9
Training loss: 2.988276462925087
Validation loss: 2.797869805754692

Epoch: 5| Step: 10
Training loss: 3.0010552139973927
Validation loss: 2.8201693747172083

Epoch: 63| Step: 0
Training loss: 3.0557188356488334
Validation loss: 2.8019478182615756

Epoch: 5| Step: 1
Training loss: 3.528829504584249
Validation loss: 2.796027901223677

Epoch: 5| Step: 2
Training loss: 3.4961686280825712
Validation loss: 2.78282158179887

Epoch: 5| Step: 3
Training loss: 2.597233099639835
Validation loss: 2.781931461010974

Epoch: 5| Step: 4
Training loss: 2.120862073522464
Validation loss: 2.7831014858498713

Epoch: 5| Step: 5
Training loss: 3.606001296962985
Validation loss: 2.7819637384258717

Epoch: 5| Step: 6
Training loss: 2.958805494283619
Validation loss: 2.780942252078082

Epoch: 5| Step: 7
Training loss: 2.8389454592322845
Validation loss: 2.7825330673841657

Epoch: 5| Step: 8
Training loss: 2.827627401677471
Validation loss: 2.783442043720906

Epoch: 5| Step: 9
Training loss: 3.630140802894611
Validation loss: 2.783020551011567

Epoch: 5| Step: 10
Training loss: 3.1127218512096526
Validation loss: 2.781769096966749

Epoch: 64| Step: 0
Training loss: 2.699613550575106
Validation loss: 2.779831798818367

Epoch: 5| Step: 1
Training loss: 3.2190770844126466
Validation loss: 2.7780084231887914

Epoch: 5| Step: 2
Training loss: 3.3323205998889627
Validation loss: 2.7789097289174087

Epoch: 5| Step: 3
Training loss: 2.669615565423396
Validation loss: 2.7796737944200007

Epoch: 5| Step: 4
Training loss: 2.6431838960325575
Validation loss: 2.7774431566137485

Epoch: 5| Step: 5
Training loss: 3.086457413926354
Validation loss: 2.777598174725295

Epoch: 5| Step: 6
Training loss: 3.520051195899419
Validation loss: 2.7779760333721066

Epoch: 5| Step: 7
Training loss: 3.4120716426970668
Validation loss: 2.7820967016498623

Epoch: 5| Step: 8
Training loss: 2.98654814683675
Validation loss: 2.785573982129895

Epoch: 5| Step: 9
Training loss: 3.113468561795755
Validation loss: 2.7798246349366798

Epoch: 5| Step: 10
Training loss: 3.273357818289222
Validation loss: 2.7779553523439757

Epoch: 65| Step: 0
Training loss: 3.2136524908821924
Validation loss: 2.778165822834401

Epoch: 5| Step: 1
Training loss: 3.228554173289605
Validation loss: 2.778079082766996

Epoch: 5| Step: 2
Training loss: 3.1778805258915606
Validation loss: 2.7726254647227515

Epoch: 5| Step: 3
Training loss: 2.821565386747125
Validation loss: 2.774046167151381

Epoch: 5| Step: 4
Training loss: 3.1361379881492604
Validation loss: 2.7717657920432743

Epoch: 5| Step: 5
Training loss: 2.8526654344440012
Validation loss: 2.7741937004169444

Epoch: 5| Step: 6
Training loss: 2.9622490627710047
Validation loss: 2.7748742853061654

Epoch: 5| Step: 7
Training loss: 3.4175199203078077
Validation loss: 2.777424652733698

Epoch: 5| Step: 8
Training loss: 2.858625970509262
Validation loss: 2.7773798476716736

Epoch: 5| Step: 9
Training loss: 3.204068375275781
Validation loss: 2.786408276817983

Epoch: 5| Step: 10
Training loss: 3.021685109686251
Validation loss: 2.7923716477007434

Epoch: 66| Step: 0
Training loss: 3.3898490334263247
Validation loss: 2.7954298878143655

Epoch: 5| Step: 1
Training loss: 2.8501690529995356
Validation loss: 2.776464702053157

Epoch: 5| Step: 2
Training loss: 3.2119372220014846
Validation loss: 2.769280193507854

Epoch: 5| Step: 3
Training loss: 2.9019965763821114
Validation loss: 2.764340868652266

Epoch: 5| Step: 4
Training loss: 2.4126679673301616
Validation loss: 2.7625299154686846

Epoch: 5| Step: 5
Training loss: 2.9778300312385677
Validation loss: 2.7622788750896397

Epoch: 5| Step: 6
Training loss: 3.3330591724818843
Validation loss: 2.7615184557847825

Epoch: 5| Step: 7
Training loss: 3.0961339223615236
Validation loss: 2.762374070322174

Epoch: 5| Step: 8
Training loss: 3.233633500025597
Validation loss: 2.7594370525658785

Epoch: 5| Step: 9
Training loss: 3.080175655855174
Validation loss: 2.7587986097316723

Epoch: 5| Step: 10
Training loss: 3.3876674427723605
Validation loss: 2.7583937377705166

Epoch: 67| Step: 0
Training loss: 2.5987895128439837
Validation loss: 2.7598941372657104

Epoch: 5| Step: 1
Training loss: 3.0754044801740803
Validation loss: 2.7594241425291837

Epoch: 5| Step: 2
Training loss: 3.3267026915603184
Validation loss: 2.7590716731480738

Epoch: 5| Step: 3
Training loss: 3.4367788772196737
Validation loss: 2.7552731671488075

Epoch: 5| Step: 4
Training loss: 2.716711398109427
Validation loss: 2.759497090503688

Epoch: 5| Step: 5
Training loss: 2.848863970898333
Validation loss: 2.756427466247638

Epoch: 5| Step: 6
Training loss: 3.249174453349019
Validation loss: 2.7563643414790486

Epoch: 5| Step: 7
Training loss: 2.918975533832762
Validation loss: 2.758186925423943

Epoch: 5| Step: 8
Training loss: 3.5467299377084798
Validation loss: 2.758349859697917

Epoch: 5| Step: 9
Training loss: 3.4583030301034148
Validation loss: 2.7560140006860236

Epoch: 5| Step: 10
Training loss: 2.3566037506956845
Validation loss: 2.758672782297942

Epoch: 68| Step: 0
Training loss: 3.6130584813085256
Validation loss: 2.760780754078098

Epoch: 5| Step: 1
Training loss: 3.171632503767206
Validation loss: 2.773310492572762

Epoch: 5| Step: 2
Training loss: 3.3939504883840805
Validation loss: 2.7608095068702783

Epoch: 5| Step: 3
Training loss: 3.1309422263678894
Validation loss: 2.757467359909477

Epoch: 5| Step: 4
Training loss: 3.148856691231607
Validation loss: 2.7575093229096415

Epoch: 5| Step: 5
Training loss: 3.1945708890206252
Validation loss: 2.756799763321606

Epoch: 5| Step: 6
Training loss: 3.128457255062458
Validation loss: 2.7615046819021964

Epoch: 5| Step: 7
Training loss: 2.3973947053605955
Validation loss: 2.756340434587034

Epoch: 5| Step: 8
Training loss: 2.863500735000881
Validation loss: 2.7618040471493037

Epoch: 5| Step: 9
Training loss: 3.054675792466775
Validation loss: 2.759127363189015

Epoch: 5| Step: 10
Training loss: 2.4768733362023356
Validation loss: 2.7586947750757114

Epoch: 69| Step: 0
Training loss: 2.7847806829804433
Validation loss: 2.7582700407284206

Epoch: 5| Step: 1
Training loss: 3.5723059366745447
Validation loss: 2.74931185233083

Epoch: 5| Step: 2
Training loss: 3.0174616621437504
Validation loss: 2.750678921120324

Epoch: 5| Step: 3
Training loss: 2.904452188285785
Validation loss: 2.750870147481204

Epoch: 5| Step: 4
Training loss: 2.9438079309938887
Validation loss: 2.753140642723866

Epoch: 5| Step: 5
Training loss: 3.351193280990396
Validation loss: 2.7547954872890297

Epoch: 5| Step: 6
Training loss: 2.6868912650603427
Validation loss: 2.7595907178709265

Epoch: 5| Step: 7
Training loss: 2.9586660887500025
Validation loss: 2.7594178175553674

Epoch: 5| Step: 8
Training loss: 2.9528483912183834
Validation loss: 2.7615773901819547

Epoch: 5| Step: 9
Training loss: 3.3167712905969893
Validation loss: 2.7569567781328512

Epoch: 5| Step: 10
Training loss: 3.221409708015572
Validation loss: 2.756763512412981

Epoch: 70| Step: 0
Training loss: 3.3058632637081287
Validation loss: 2.755827496978139

Epoch: 5| Step: 1
Training loss: 2.7880633618832067
Validation loss: 2.7550321703677128

Epoch: 5| Step: 2
Training loss: 2.474640687234069
Validation loss: 2.756409494655751

Epoch: 5| Step: 3
Training loss: 2.890904428533913
Validation loss: 2.7566859389631335

Epoch: 5| Step: 4
Training loss: 2.842921209606119
Validation loss: 2.764176456728478

Epoch: 5| Step: 5
Training loss: 3.370654805803355
Validation loss: 2.766337528238118

Epoch: 5| Step: 6
Training loss: 2.850533244791768
Validation loss: 2.7675357347888014

Epoch: 5| Step: 7
Training loss: 3.388575905971744
Validation loss: 2.7683102045775185

Epoch: 5| Step: 8
Training loss: 2.8642436617980653
Validation loss: 2.7706332125591695

Epoch: 5| Step: 9
Training loss: 3.1706355637687
Validation loss: 2.7689716772310518

Epoch: 5| Step: 10
Training loss: 3.7473206166805664
Validation loss: 2.7667077569866723

Epoch: 71| Step: 0
Training loss: 2.689006826565874
Validation loss: 2.7476661255627546

Epoch: 5| Step: 1
Training loss: 3.083048953439468
Validation loss: 2.746094301733335

Epoch: 5| Step: 2
Training loss: 3.4089873627629568
Validation loss: 2.7484542412155224

Epoch: 5| Step: 3
Training loss: 3.15336083852481
Validation loss: 2.749353843764796

Epoch: 5| Step: 4
Training loss: 3.1811049392693027
Validation loss: 2.7495121462546845

Epoch: 5| Step: 5
Training loss: 3.0214266139638966
Validation loss: 2.7475562121099606

Epoch: 5| Step: 6
Training loss: 2.5534301836886812
Validation loss: 2.747548019812297

Epoch: 5| Step: 7
Training loss: 2.9451081789416405
Validation loss: 2.745412223346088

Epoch: 5| Step: 8
Training loss: 2.798672231843433
Validation loss: 2.7435548650777437

Epoch: 5| Step: 9
Training loss: 3.947582475647415
Validation loss: 2.740796741296991

Epoch: 5| Step: 10
Training loss: 2.5827612602380565
Validation loss: 2.740852200295617

Epoch: 72| Step: 0
Training loss: 2.7974761657790412
Validation loss: 2.738033297085337

Epoch: 5| Step: 1
Training loss: 3.1507102771032662
Validation loss: 2.736939454780176

Epoch: 5| Step: 2
Training loss: 3.1524031963202948
Validation loss: 2.737319224692173

Epoch: 5| Step: 3
Training loss: 3.1327263494427924
Validation loss: 2.736660151133698

Epoch: 5| Step: 4
Training loss: 3.0669540401929343
Validation loss: 2.736951790848123

Epoch: 5| Step: 5
Training loss: 2.380009537846022
Validation loss: 2.735312949483131

Epoch: 5| Step: 6
Training loss: 3.1682179984408476
Validation loss: 2.7367152705448006

Epoch: 5| Step: 7
Training loss: 3.0021565950990268
Validation loss: 2.7389322835546666

Epoch: 5| Step: 8
Training loss: 2.966271580594695
Validation loss: 2.737638012032112

Epoch: 5| Step: 9
Training loss: 3.214397264997231
Validation loss: 2.744743407609513

Epoch: 5| Step: 10
Training loss: 3.527905796428198
Validation loss: 2.7459368198432923

Epoch: 73| Step: 0
Training loss: 3.3802841640405155
Validation loss: 2.746215137998611

Epoch: 5| Step: 1
Training loss: 3.227273710253147
Validation loss: 2.742175746551652

Epoch: 5| Step: 2
Training loss: 2.8290199844770982
Validation loss: 2.7422095371124304

Epoch: 5| Step: 3
Training loss: 3.097059541163791
Validation loss: 2.7512900383453656

Epoch: 5| Step: 4
Training loss: 2.953745297473808
Validation loss: 2.749837451989639

Epoch: 5| Step: 5
Training loss: 3.2186785940008815
Validation loss: 2.742463908407688

Epoch: 5| Step: 6
Training loss: 3.1289124982869105
Validation loss: 2.7380891097962032

Epoch: 5| Step: 7
Training loss: 2.9532990580938607
Validation loss: 2.7323816912446475

Epoch: 5| Step: 8
Training loss: 2.9241035652762757
Validation loss: 2.7311910901740237

Epoch: 5| Step: 9
Training loss: 2.901346643786659
Validation loss: 2.727854923449788

Epoch: 5| Step: 10
Training loss: 2.9141639507725747
Validation loss: 2.722697901154494

Epoch: 74| Step: 0
Training loss: 2.9850150016267127
Validation loss: 2.7214908873833084

Epoch: 5| Step: 1
Training loss: 3.493551307992649
Validation loss: 2.7232825197080235

Epoch: 5| Step: 2
Training loss: 3.188494807566482
Validation loss: 2.7214422892410592

Epoch: 5| Step: 3
Training loss: 3.0560299784403258
Validation loss: 2.7215624095720186

Epoch: 5| Step: 4
Training loss: 2.6521196453268585
Validation loss: 2.7246027810216193

Epoch: 5| Step: 5
Training loss: 3.418728012767433
Validation loss: 2.7250723814234687

Epoch: 5| Step: 6
Training loss: 2.9234043953355124
Validation loss: 2.740498690288471

Epoch: 5| Step: 7
Training loss: 2.8442218095687206
Validation loss: 2.730314476648338

Epoch: 5| Step: 8
Training loss: 2.8310236960402686
Validation loss: 2.7370538005993614

Epoch: 5| Step: 9
Training loss: 2.6458353858599373
Validation loss: 2.731464069669309

Epoch: 5| Step: 10
Training loss: 3.2959788763332303
Validation loss: 2.730719066510591

Epoch: 75| Step: 0
Training loss: 2.7366984931529337
Validation loss: 2.7240411390593633

Epoch: 5| Step: 1
Training loss: 2.6409032550903078
Validation loss: 2.720130337096322

Epoch: 5| Step: 2
Training loss: 2.9587476377554305
Validation loss: 2.71827324692429

Epoch: 5| Step: 3
Training loss: 2.9259973504764347
Validation loss: 2.7152494988865365

Epoch: 5| Step: 4
Training loss: 3.3317085279767595
Validation loss: 2.7140522503393494

Epoch: 5| Step: 5
Training loss: 2.8670817259525436
Validation loss: 2.7109641317069104

Epoch: 5| Step: 6
Training loss: 3.470356337310357
Validation loss: 2.71379776749676

Epoch: 5| Step: 7
Training loss: 3.280155108203652
Validation loss: 2.7110692573471855

Epoch: 5| Step: 8
Training loss: 3.235154062697356
Validation loss: 2.7052928874403137

Epoch: 5| Step: 9
Training loss: 2.9943836409655704
Validation loss: 2.706170875453397

Epoch: 5| Step: 10
Training loss: 2.811771637593259
Validation loss: 2.706039737927414

Epoch: 76| Step: 0
Training loss: 3.6652939278640013
Validation loss: 2.7065727916877687

Epoch: 5| Step: 1
Training loss: 2.831774301382391
Validation loss: 2.703415197315383

Epoch: 5| Step: 2
Training loss: 3.1338403399805257
Validation loss: 2.7042607857710337

Epoch: 5| Step: 3
Training loss: 2.7188364650964183
Validation loss: 2.703359424546129

Epoch: 5| Step: 4
Training loss: 2.935968202569473
Validation loss: 2.703378671511458

Epoch: 5| Step: 5
Training loss: 2.609846152525059
Validation loss: 2.704961527118881

Epoch: 5| Step: 6
Training loss: 3.6173844417734977
Validation loss: 2.700497842130475

Epoch: 5| Step: 7
Training loss: 3.2130615930954995
Validation loss: 2.702802634235472

Epoch: 5| Step: 8
Training loss: 2.810865138990102
Validation loss: 2.7036263321485765

Epoch: 5| Step: 9
Training loss: 2.2756879751391383
Validation loss: 2.710563153187048

Epoch: 5| Step: 10
Training loss: 3.277285696977274
Validation loss: 2.7179347036817543

Epoch: 77| Step: 0
Training loss: 3.153573894021466
Validation loss: 2.72659841999746

Epoch: 5| Step: 1
Training loss: 3.602620728565748
Validation loss: 2.7338759343941312

Epoch: 5| Step: 2
Training loss: 2.6256340714270476
Validation loss: 2.715526187135111

Epoch: 5| Step: 3
Training loss: 3.1091820738475513
Validation loss: 2.704333649057516

Epoch: 5| Step: 4
Training loss: 2.970822383937124
Validation loss: 2.6984710434192003

Epoch: 5| Step: 5
Training loss: 3.506013064615266
Validation loss: 2.7002408286370283

Epoch: 5| Step: 6
Training loss: 3.043087213876685
Validation loss: 2.7006066853417883

Epoch: 5| Step: 7
Training loss: 3.042466480882325
Validation loss: 2.6986571943621143

Epoch: 5| Step: 8
Training loss: 3.0054929037687796
Validation loss: 2.6978666255210944

Epoch: 5| Step: 9
Training loss: 2.482646892922992
Validation loss: 2.699875393327537

Epoch: 5| Step: 10
Training loss: 2.6049659621345143
Validation loss: 2.6971114114552748

Epoch: 78| Step: 0
Training loss: 3.0653823989861624
Validation loss: 2.701859517902812

Epoch: 5| Step: 1
Training loss: 3.2885343077686726
Validation loss: 2.6994131412503033

Epoch: 5| Step: 2
Training loss: 2.702329838395187
Validation loss: 2.702554895269336

Epoch: 5| Step: 3
Training loss: 2.8237259515326785
Validation loss: 2.699318660297844

Epoch: 5| Step: 4
Training loss: 2.7160439013442956
Validation loss: 2.7053762869021623

Epoch: 5| Step: 5
Training loss: 2.966318198608421
Validation loss: 2.710557468945249

Epoch: 5| Step: 6
Training loss: 3.214690676413445
Validation loss: 2.7143452962639265

Epoch: 5| Step: 7
Training loss: 3.4155440618448067
Validation loss: 2.7082238874889395

Epoch: 5| Step: 8
Training loss: 3.0149276006049712
Validation loss: 2.704215014970504

Epoch: 5| Step: 9
Training loss: 3.087106681203747
Validation loss: 2.6972148937689044

Epoch: 5| Step: 10
Training loss: 2.8140508826236807
Validation loss: 2.705404230818369

Epoch: 79| Step: 0
Training loss: 2.955249486418624
Validation loss: 2.7020924175227177

Epoch: 5| Step: 1
Training loss: 3.282597582979776
Validation loss: 2.6977300496629506

Epoch: 5| Step: 2
Training loss: 2.765262644677549
Validation loss: 2.7178218890102146

Epoch: 5| Step: 3
Training loss: 3.576132940291877
Validation loss: 2.7371093841414442

Epoch: 5| Step: 4
Training loss: 2.7670356902704505
Validation loss: 2.7012227245762155

Epoch: 5| Step: 5
Training loss: 2.211864910463818
Validation loss: 2.6834575836279546

Epoch: 5| Step: 6
Training loss: 3.5278086139469336
Validation loss: 2.68416176840972

Epoch: 5| Step: 7
Training loss: 2.7236102278666534
Validation loss: 2.6825220280111646

Epoch: 5| Step: 8
Training loss: 2.8346805361566636
Validation loss: 2.689247179642911

Epoch: 5| Step: 9
Training loss: 3.5010054370322528
Validation loss: 2.692930075369412

Epoch: 5| Step: 10
Training loss: 2.8114666205942798
Validation loss: 2.694533314550375

Epoch: 80| Step: 0
Training loss: 2.396617086726243
Validation loss: 2.695876230118978

Epoch: 5| Step: 1
Training loss: 3.0003955898137056
Validation loss: 2.699275663498348

Epoch: 5| Step: 2
Training loss: 3.145926181526168
Validation loss: 2.696997068918751

Epoch: 5| Step: 3
Training loss: 3.142520920616318
Validation loss: 2.6922027210939943

Epoch: 5| Step: 4
Training loss: 3.416653485776706
Validation loss: 2.6904116552510278

Epoch: 5| Step: 5
Training loss: 2.806229191556387
Validation loss: 2.6876175080403857

Epoch: 5| Step: 6
Training loss: 2.5726888043486715
Validation loss: 2.6884401598602294

Epoch: 5| Step: 7
Training loss: 3.490210466351029
Validation loss: 2.6884530159843583

Epoch: 5| Step: 8
Training loss: 2.7840490936083255
Validation loss: 2.689358392323261

Epoch: 5| Step: 9
Training loss: 3.0918722908620415
Validation loss: 2.6890532385255423

Epoch: 5| Step: 10
Training loss: 3.3789710242617192
Validation loss: 2.687031513579251

Epoch: 81| Step: 0
Training loss: 3.4523221977132623
Validation loss: 2.686958709678296

Epoch: 5| Step: 1
Training loss: 2.312987405085463
Validation loss: 2.6823856275575984

Epoch: 5| Step: 2
Training loss: 2.7563862773395904
Validation loss: 2.6807915709068895

Epoch: 5| Step: 3
Training loss: 2.821906909783331
Validation loss: 2.685902487261578

Epoch: 5| Step: 4
Training loss: 2.881269502056593
Validation loss: 2.679994727498223

Epoch: 5| Step: 5
Training loss: 2.7299184176373417
Validation loss: 2.6784362617449315

Epoch: 5| Step: 6
Training loss: 3.225973819113231
Validation loss: 2.6799768632285876

Epoch: 5| Step: 7
Training loss: 3.0668792554173976
Validation loss: 2.681588473895608

Epoch: 5| Step: 8
Training loss: 3.204321363374821
Validation loss: 2.683882537333515

Epoch: 5| Step: 9
Training loss: 3.058013276305236
Validation loss: 2.687505977210924

Epoch: 5| Step: 10
Training loss: 3.4763161561247538
Validation loss: 2.7191374298431947

Epoch: 82| Step: 0
Training loss: 3.4938326039384404
Validation loss: 2.736039710454051

Epoch: 5| Step: 1
Training loss: 2.9694481279782305
Validation loss: 2.760422567096951

Epoch: 5| Step: 2
Training loss: 3.396188978672627
Validation loss: 2.6883741894877073

Epoch: 5| Step: 3
Training loss: 2.611038682713167
Validation loss: 2.6731353801746613

Epoch: 5| Step: 4
Training loss: 2.433465210289126
Validation loss: 2.674235054521396

Epoch: 5| Step: 5
Training loss: 3.052232619313663
Validation loss: 2.6728708517083897

Epoch: 5| Step: 6
Training loss: 3.056838271115971
Validation loss: 2.674518526962689

Epoch: 5| Step: 7
Training loss: 2.6718695568006963
Validation loss: 2.6751200015277483

Epoch: 5| Step: 8
Training loss: 3.097431189116794
Validation loss: 2.6738137872104875

Epoch: 5| Step: 9
Training loss: 3.311466847653086
Validation loss: 2.673330067558504

Epoch: 5| Step: 10
Training loss: 2.81907199619099
Validation loss: 2.677251181773699

Epoch: 83| Step: 0
Training loss: 3.056552795513314
Validation loss: 2.675725454059042

Epoch: 5| Step: 1
Training loss: 2.607777180555366
Validation loss: 2.673567040349258

Epoch: 5| Step: 2
Training loss: 2.7070284316363393
Validation loss: 2.6750802977314088

Epoch: 5| Step: 3
Training loss: 2.9343239679256063
Validation loss: 2.6745955955737877

Epoch: 5| Step: 4
Training loss: 3.1480900499389173
Validation loss: 2.671235749809588

Epoch: 5| Step: 5
Training loss: 3.067598108838352
Validation loss: 2.670844665647154

Epoch: 5| Step: 6
Training loss: 3.1345654385067876
Validation loss: 2.669022550683543

Epoch: 5| Step: 7
Training loss: 3.1555434843139913
Validation loss: 2.666441329797838

Epoch: 5| Step: 8
Training loss: 3.4529864943676865
Validation loss: 2.66381396736978

Epoch: 5| Step: 9
Training loss: 2.8400052744856734
Validation loss: 2.6648414259056534

Epoch: 5| Step: 10
Training loss: 2.8606032771626975
Validation loss: 2.666455024606357

Epoch: 84| Step: 0
Training loss: 2.676427699055494
Validation loss: 2.6755746733994865

Epoch: 5| Step: 1
Training loss: 2.8754039978122665
Validation loss: 2.682700377373443

Epoch: 5| Step: 2
Training loss: 2.9888222996204536
Validation loss: 2.682183901355004

Epoch: 5| Step: 3
Training loss: 3.4066616824487506
Validation loss: 2.6911652133491937

Epoch: 5| Step: 4
Training loss: 2.9983100899825086
Validation loss: 2.6832474223285474

Epoch: 5| Step: 5
Training loss: 2.431334008184949
Validation loss: 2.674562423072693

Epoch: 5| Step: 6
Training loss: 3.0176019858987853
Validation loss: 2.6656988695654826

Epoch: 5| Step: 7
Training loss: 3.400698275948351
Validation loss: 2.6631644930741873

Epoch: 5| Step: 8
Training loss: 3.0711178099612417
Validation loss: 2.6646081749730643

Epoch: 5| Step: 9
Training loss: 3.2935109987354685
Validation loss: 2.6623276045730746

Epoch: 5| Step: 10
Training loss: 2.6419659883214366
Validation loss: 2.662569937547392

Epoch: 85| Step: 0
Training loss: 3.374484976572973
Validation loss: 2.662887894084493

Epoch: 5| Step: 1
Training loss: 2.5476161135939717
Validation loss: 2.661307892441511

Epoch: 5| Step: 2
Training loss: 3.217532325706732
Validation loss: 2.6600905438545297

Epoch: 5| Step: 3
Training loss: 3.0935727463623888
Validation loss: 2.659693642451146

Epoch: 5| Step: 4
Training loss: 3.042328557847433
Validation loss: 2.6627028404614297

Epoch: 5| Step: 5
Training loss: 2.8615530921587258
Validation loss: 2.660521548271397

Epoch: 5| Step: 6
Training loss: 2.798761339049649
Validation loss: 2.6656184026799536

Epoch: 5| Step: 7
Training loss: 2.4633397563322346
Validation loss: 2.6753508114187396

Epoch: 5| Step: 8
Training loss: 3.156999706704504
Validation loss: 2.689340291882524

Epoch: 5| Step: 9
Training loss: 3.061077488204757
Validation loss: 2.6751277179683615

Epoch: 5| Step: 10
Training loss: 3.314995023973968
Validation loss: 2.67473202811162

Epoch: 86| Step: 0
Training loss: 2.5939825482277734
Validation loss: 2.673774416859683

Epoch: 5| Step: 1
Training loss: 2.7663847316194836
Validation loss: 2.71150207740156

Epoch: 5| Step: 2
Training loss: 2.6967868476685015
Validation loss: 2.7713587285398655

Epoch: 5| Step: 3
Training loss: 2.7647975394986384
Validation loss: 2.7644560062659855

Epoch: 5| Step: 4
Training loss: 3.1841841261450847
Validation loss: 2.8362342947876584

Epoch: 5| Step: 5
Training loss: 3.152713267095351
Validation loss: 2.7877935740825768

Epoch: 5| Step: 6
Training loss: 3.2054902066938156
Validation loss: 2.719558664391059

Epoch: 5| Step: 7
Training loss: 3.6615403203706762
Validation loss: 2.681948157366014

Epoch: 5| Step: 8
Training loss: 3.3091490008278828
Validation loss: 2.673022767462838

Epoch: 5| Step: 9
Training loss: 2.511525575319634
Validation loss: 2.6648226663772756

Epoch: 5| Step: 10
Training loss: 3.306606592227403
Validation loss: 2.6567896285769104

Epoch: 87| Step: 0
Training loss: 2.684642869864556
Validation loss: 2.6628763576723338

Epoch: 5| Step: 1
Training loss: 2.4563163845419504
Validation loss: 2.6714795125810027

Epoch: 5| Step: 2
Training loss: 3.242292802318569
Validation loss: 2.6781788857027022

Epoch: 5| Step: 3
Training loss: 2.9325407655293896
Validation loss: 2.6765769657400464

Epoch: 5| Step: 4
Training loss: 3.104432284535312
Validation loss: 2.661923541094378

Epoch: 5| Step: 5
Training loss: 3.208568135046206
Validation loss: 2.660393768915325

Epoch: 5| Step: 6
Training loss: 2.3424628219992587
Validation loss: 2.6573273135927344

Epoch: 5| Step: 7
Training loss: 3.3408843979073364
Validation loss: 2.657214352208681

Epoch: 5| Step: 8
Training loss: 3.521845354227905
Validation loss: 2.6555987288966

Epoch: 5| Step: 9
Training loss: 3.3211315625787896
Validation loss: 2.650888867750198

Epoch: 5| Step: 10
Training loss: 2.6422517720170604
Validation loss: 2.651256597453014

Epoch: 88| Step: 0
Training loss: 2.99300809519215
Validation loss: 2.649904823799768

Epoch: 5| Step: 1
Training loss: 3.147524717929247
Validation loss: 2.646383633471036

Epoch: 5| Step: 2
Training loss: 3.1975161687876112
Validation loss: 2.646352496253806

Epoch: 5| Step: 3
Training loss: 3.117528452188932
Validation loss: 2.6456866686763663

Epoch: 5| Step: 4
Training loss: 2.5814404987672166
Validation loss: 2.6430971161240464

Epoch: 5| Step: 5
Training loss: 2.9929032627509944
Validation loss: 2.6417437001205317

Epoch: 5| Step: 6
Training loss: 2.5509306088426573
Validation loss: 2.646138010334532

Epoch: 5| Step: 7
Training loss: 3.2236887254693594
Validation loss: 2.6500038052525965

Epoch: 5| Step: 8
Training loss: 3.1283058990700923
Validation loss: 2.654404796379781

Epoch: 5| Step: 9
Training loss: 2.99680714774066
Validation loss: 2.6683910255917818

Epoch: 5| Step: 10
Training loss: 2.760307847283285
Validation loss: 2.663668268365502

Epoch: 89| Step: 0
Training loss: 2.859474722368815
Validation loss: 2.660161901236734

Epoch: 5| Step: 1
Training loss: 3.816335905865589
Validation loss: 2.662646705952824

Epoch: 5| Step: 2
Training loss: 3.1876706844332303
Validation loss: 2.662477133132433

Epoch: 5| Step: 3
Training loss: 2.972129745074669
Validation loss: 2.651876783713826

Epoch: 5| Step: 4
Training loss: 2.5363546633569447
Validation loss: 2.645171899521644

Epoch: 5| Step: 5
Training loss: 2.786495961918584
Validation loss: 2.6401875597101894

Epoch: 5| Step: 6
Training loss: 3.2344350026042843
Validation loss: 2.6397744571244406

Epoch: 5| Step: 7
Training loss: 3.0200406492415444
Validation loss: 2.6395821752133797

Epoch: 5| Step: 8
Training loss: 2.763094849213822
Validation loss: 2.6388619295422364

Epoch: 5| Step: 9
Training loss: 2.4455873377586057
Validation loss: 2.6386003629775665

Epoch: 5| Step: 10
Training loss: 2.8785584031290052
Validation loss: 2.639475345553096

Epoch: 90| Step: 0
Training loss: 2.9993892683805425
Validation loss: 2.639270683465526

Epoch: 5| Step: 1
Training loss: 2.589834359958939
Validation loss: 2.6392592526606

Epoch: 5| Step: 2
Training loss: 3.1142255052318424
Validation loss: 2.636200430121857

Epoch: 5| Step: 3
Training loss: 2.9550494024339415
Validation loss: 2.6406494943349577

Epoch: 5| Step: 4
Training loss: 3.1584969255928512
Validation loss: 2.6386901495842747

Epoch: 5| Step: 5
Training loss: 3.0559923746003888
Validation loss: 2.6420735847357246

Epoch: 5| Step: 6
Training loss: 3.3982498994107564
Validation loss: 2.638874261668378

Epoch: 5| Step: 7
Training loss: 2.328697390246177
Validation loss: 2.642422742693831

Epoch: 5| Step: 8
Training loss: 3.3718374057544245
Validation loss: 2.6431437289989685

Epoch: 5| Step: 9
Training loss: 2.60119131378596
Validation loss: 2.6377285793211964

Epoch: 5| Step: 10
Training loss: 2.980784068295488
Validation loss: 2.6365900154240896

Epoch: 91| Step: 0
Training loss: 3.389412799492887
Validation loss: 2.6393446444725033

Epoch: 5| Step: 1
Training loss: 2.9707169291058304
Validation loss: 2.643334848903965

Epoch: 5| Step: 2
Training loss: 2.5591256789918004
Validation loss: 2.6445816696129367

Epoch: 5| Step: 3
Training loss: 2.9914457432632293
Validation loss: 2.6445335804657004

Epoch: 5| Step: 4
Training loss: 2.727716327483526
Validation loss: 2.6482628934680394

Epoch: 5| Step: 5
Training loss: 3.1744981263960743
Validation loss: 2.6405032958044177

Epoch: 5| Step: 6
Training loss: 3.1628016090563618
Validation loss: 2.6476338240064297

Epoch: 5| Step: 7
Training loss: 3.3447743210550187
Validation loss: 2.647040097656786

Epoch: 5| Step: 8
Training loss: 2.442886465338031
Validation loss: 2.65253146800043

Epoch: 5| Step: 9
Training loss: 2.5345663315955678
Validation loss: 2.673473377796978

Epoch: 5| Step: 10
Training loss: 3.2840400096672413
Validation loss: 2.661604306780652

Epoch: 92| Step: 0
Training loss: 2.5735619131007406
Validation loss: 2.655410431240665

Epoch: 5| Step: 1
Training loss: 3.360944656229669
Validation loss: 2.6435758972596

Epoch: 5| Step: 2
Training loss: 3.060883075722931
Validation loss: 2.627438544956789

Epoch: 5| Step: 3
Training loss: 2.7534317798271504
Validation loss: 2.6224853680869544

Epoch: 5| Step: 4
Training loss: 3.4150432513557383
Validation loss: 2.621875845357155

Epoch: 5| Step: 5
Training loss: 3.1485377596280646
Validation loss: 2.623066267550678

Epoch: 5| Step: 6
Training loss: 3.0690893789671336
Validation loss: 2.6228436091417837

Epoch: 5| Step: 7
Training loss: 2.513104615601977
Validation loss: 2.6226946663975936

Epoch: 5| Step: 8
Training loss: 3.0737388071397027
Validation loss: 2.6236894131930324

Epoch: 5| Step: 9
Training loss: 2.657036429279308
Validation loss: 2.622974858791844

Epoch: 5| Step: 10
Training loss: 2.99700285287797
Validation loss: 2.625651991036082

Epoch: 93| Step: 0
Training loss: 2.8393191518125627
Validation loss: 2.6254150308638087

Epoch: 5| Step: 1
Training loss: 2.753203866545614
Validation loss: 2.6276415139042264

Epoch: 5| Step: 2
Training loss: 2.694610415805734
Validation loss: 2.6366740887079048

Epoch: 5| Step: 3
Training loss: 2.8168163662316643
Validation loss: 2.6526390272693434

Epoch: 5| Step: 4
Training loss: 3.2223839847109894
Validation loss: 2.6808737024195435

Epoch: 5| Step: 5
Training loss: 2.942324633043713
Validation loss: 2.6571673677269905

Epoch: 5| Step: 6
Training loss: 3.034218190283144
Validation loss: 2.649196142337513

Epoch: 5| Step: 7
Training loss: 3.4537016098050963
Validation loss: 2.6385539146845005

Epoch: 5| Step: 8
Training loss: 3.211358035873657
Validation loss: 2.624928136995281

Epoch: 5| Step: 9
Training loss: 2.4543553079621883
Validation loss: 2.6217998720282027

Epoch: 5| Step: 10
Training loss: 3.232781206424784
Validation loss: 2.6196285906426433

Epoch: 94| Step: 0
Training loss: 2.9249693453233903
Validation loss: 2.6179750279121645

Epoch: 5| Step: 1
Training loss: 2.9026194219475263
Validation loss: 2.618100734574127

Epoch: 5| Step: 2
Training loss: 3.1700219063949584
Validation loss: 2.6204011286032394

Epoch: 5| Step: 3
Training loss: 3.1764418324351147
Validation loss: 2.6168224351317138

Epoch: 5| Step: 4
Training loss: 3.1812368456375566
Validation loss: 2.617956306627053

Epoch: 5| Step: 5
Training loss: 2.9795790878121267
Validation loss: 2.6219431945794023

Epoch: 5| Step: 6
Training loss: 2.910222773463661
Validation loss: 2.6316441110898823

Epoch: 5| Step: 7
Training loss: 2.7125435504845163
Validation loss: 2.6349974858275758

Epoch: 5| Step: 8
Training loss: 3.1182662129955907
Validation loss: 2.6284129861442063

Epoch: 5| Step: 9
Training loss: 2.7291144640251837
Validation loss: 2.6226766200360196

Epoch: 5| Step: 10
Training loss: 2.7570662312762453
Validation loss: 2.618417672192921

Epoch: 95| Step: 0
Training loss: 3.159075992067495
Validation loss: 2.613539657350371

Epoch: 5| Step: 1
Training loss: 3.1874175715540725
Validation loss: 2.6144020525301763

Epoch: 5| Step: 2
Training loss: 3.0228228276885853
Validation loss: 2.615310859592567

Epoch: 5| Step: 3
Training loss: 2.447685966713109
Validation loss: 2.613714319749666

Epoch: 5| Step: 4
Training loss: 3.213516128084087
Validation loss: 2.6130011523217904

Epoch: 5| Step: 5
Training loss: 2.961891845861288
Validation loss: 2.612335508262687

Epoch: 5| Step: 6
Training loss: 2.9430601376692915
Validation loss: 2.6081462548743115

Epoch: 5| Step: 7
Training loss: 3.1205388078298073
Validation loss: 2.6101000911118875

Epoch: 5| Step: 8
Training loss: 3.032102327366378
Validation loss: 2.610844333092744

Epoch: 5| Step: 9
Training loss: 2.5952135116559374
Validation loss: 2.607322467726264

Epoch: 5| Step: 10
Training loss: 2.7462037499917056
Validation loss: 2.6091869989727368

Epoch: 96| Step: 0
Training loss: 2.4590555412532393
Validation loss: 2.607050795352797

Epoch: 5| Step: 1
Training loss: 3.046999571772346
Validation loss: 2.6070760810648115

Epoch: 5| Step: 2
Training loss: 2.849100131470122
Validation loss: 2.6051062370950944

Epoch: 5| Step: 3
Training loss: 2.9085708703333095
Validation loss: 2.6052903377490098

Epoch: 5| Step: 4
Training loss: 3.069018530507854
Validation loss: 2.608602087941687

Epoch: 5| Step: 5
Training loss: 3.127404318000714
Validation loss: 2.615514778493248

Epoch: 5| Step: 6
Training loss: 3.1435170688375074
Validation loss: 2.6135183686283265

Epoch: 5| Step: 7
Training loss: 2.9629442163598445
Validation loss: 2.6181870514682837

Epoch: 5| Step: 8
Training loss: 3.1662936409202835
Validation loss: 2.6217552303882137

Epoch: 5| Step: 9
Training loss: 3.1969533125755976
Validation loss: 2.620424628200792

Epoch: 5| Step: 10
Training loss: 2.293933567944339
Validation loss: 2.631202266444194

Epoch: 97| Step: 0
Training loss: 2.7838008198683517
Validation loss: 2.627257107723078

Epoch: 5| Step: 1
Training loss: 2.726795612852203
Validation loss: 2.625114562449429

Epoch: 5| Step: 2
Training loss: 2.7679800577602958
Validation loss: 2.639281511018655

Epoch: 5| Step: 3
Training loss: 2.3188436977652302
Validation loss: 2.6378989121288656

Epoch: 5| Step: 4
Training loss: 3.1429307359278287
Validation loss: 2.638448988628063

Epoch: 5| Step: 5
Training loss: 3.1468220014001576
Validation loss: 2.613596383596036

Epoch: 5| Step: 6
Training loss: 2.9200466371757234
Validation loss: 2.6057908159722056

Epoch: 5| Step: 7
Training loss: 3.4539349326767925
Validation loss: 2.604283750465644

Epoch: 5| Step: 8
Training loss: 3.2078887499309565
Validation loss: 2.6090556541178755

Epoch: 5| Step: 9
Training loss: 2.612304778767522
Validation loss: 2.6149863054433027

Epoch: 5| Step: 10
Training loss: 3.271095767497736
Validation loss: 2.6205086722683073

Epoch: 98| Step: 0
Training loss: 3.261944754988154
Validation loss: 2.6216738498927468

Epoch: 5| Step: 1
Training loss: 3.0328714025988885
Validation loss: 2.6360642124293325

Epoch: 5| Step: 2
Training loss: 3.175869235500885
Validation loss: 2.6406897760028465

Epoch: 5| Step: 3
Training loss: 3.0597677693724132
Validation loss: 2.6355034546669174

Epoch: 5| Step: 4
Training loss: 2.533970536437808
Validation loss: 2.621852105517265

Epoch: 5| Step: 5
Training loss: 2.973589997382655
Validation loss: 2.616869817758351

Epoch: 5| Step: 6
Training loss: 2.804436377543787
Validation loss: 2.614205891613503

Epoch: 5| Step: 7
Training loss: 2.688051388975923
Validation loss: 2.6146262151926503

Epoch: 5| Step: 8
Training loss: 2.7041445887467157
Validation loss: 2.6283917096235596

Epoch: 5| Step: 9
Training loss: 3.2602635226779886
Validation loss: 2.631289253529573

Epoch: 5| Step: 10
Training loss: 2.865943576488931
Validation loss: 2.632507669772117

Epoch: 99| Step: 0
Training loss: 2.557950889837758
Validation loss: 2.629358937435832

Epoch: 5| Step: 1
Training loss: 2.6309604186412208
Validation loss: 2.628303129405349

Epoch: 5| Step: 2
Training loss: 2.8956996603285963
Validation loss: 2.621365508288546

Epoch: 5| Step: 3
Training loss: 2.774091616580133
Validation loss: 2.611660699060957

Epoch: 5| Step: 4
Training loss: 2.8320489290935256
Validation loss: 2.6094095052081263

Epoch: 5| Step: 5
Training loss: 3.456703230818658
Validation loss: 2.6008472227344632

Epoch: 5| Step: 6
Training loss: 2.6723866112316417
Validation loss: 2.598781889354743

Epoch: 5| Step: 7
Training loss: 3.6085354707995534
Validation loss: 2.602083094409404

Epoch: 5| Step: 8
Training loss: 2.9702958750171744
Validation loss: 2.5976956173528034

Epoch: 5| Step: 9
Training loss: 2.5678415218782358
Validation loss: 2.5972624054657403

Epoch: 5| Step: 10
Training loss: 3.34123306378583
Validation loss: 2.5957628888592725

Epoch: 100| Step: 0
Training loss: 3.103267633362044
Validation loss: 2.595397544567309

Epoch: 5| Step: 1
Training loss: 2.328796597074475
Validation loss: 2.5924343128283867

Epoch: 5| Step: 2
Training loss: 2.6591842600894857
Validation loss: 2.5967757664767883

Epoch: 5| Step: 3
Training loss: 2.8351572187584457
Validation loss: 2.5938655364477654

Epoch: 5| Step: 4
Training loss: 3.224239963603129
Validation loss: 2.5948738453620397

Epoch: 5| Step: 5
Training loss: 3.104928522684773
Validation loss: 2.594245158657323

Epoch: 5| Step: 6
Training loss: 3.2967377403576905
Validation loss: 2.593705975677449

Epoch: 5| Step: 7
Training loss: 3.085256303375707
Validation loss: 2.5971499340447286

Epoch: 5| Step: 8
Training loss: 2.374585768062559
Validation loss: 2.6156928677496225

Epoch: 5| Step: 9
Training loss: 2.8992093027752976
Validation loss: 2.6381745501934697

Epoch: 5| Step: 10
Training loss: 3.267747399231701
Validation loss: 2.6887495718327443

Epoch: 101| Step: 0
Training loss: 3.2443403702711877
Validation loss: 2.7273611355352085

Epoch: 5| Step: 1
Training loss: 2.8253144688404785
Validation loss: 2.724446363185728

Epoch: 5| Step: 2
Training loss: 2.7071232855758316
Validation loss: 2.674179629917252

Epoch: 5| Step: 3
Training loss: 2.564419190530191
Validation loss: 2.645521850182876

Epoch: 5| Step: 4
Training loss: 2.780085287638307
Validation loss: 2.6610025470299385

Epoch: 5| Step: 5
Training loss: 3.1348844226418864
Validation loss: 2.65489447628917

Epoch: 5| Step: 6
Training loss: 3.1703582294112143
Validation loss: 2.6508630995870877

Epoch: 5| Step: 7
Training loss: 3.3993132065888334
Validation loss: 2.6393596182547308

Epoch: 5| Step: 8
Training loss: 2.605025086382777
Validation loss: 2.637274349108582

Epoch: 5| Step: 9
Training loss: 2.9829300982641835
Validation loss: 2.62862317348317

Epoch: 5| Step: 10
Training loss: 3.1398326576494475
Validation loss: 2.6277451115132795

Epoch: 102| Step: 0
Training loss: 2.8942424511692004
Validation loss: 2.6274712713302426

Epoch: 5| Step: 1
Training loss: 2.5294931225144976
Validation loss: 2.62832121126436

Epoch: 5| Step: 2
Training loss: 3.0749562020012697
Validation loss: 2.62065575830828

Epoch: 5| Step: 3
Training loss: 2.861684731404409
Validation loss: 2.6184396573442617

Epoch: 5| Step: 4
Training loss: 2.9638123257381306
Validation loss: 2.6177501310633775

Epoch: 5| Step: 5
Training loss: 2.961696557656403
Validation loss: 2.61881138748738

Epoch: 5| Step: 6
Training loss: 2.519772445607504
Validation loss: 2.6193733585123393

Epoch: 5| Step: 7
Training loss: 3.040632847367106
Validation loss: 2.6145051794885688

Epoch: 5| Step: 8
Training loss: 3.454116471818968
Validation loss: 2.5887729778044353

Epoch: 5| Step: 9
Training loss: 3.0152155939202463
Validation loss: 2.5847660825893177

Epoch: 5| Step: 10
Training loss: 3.189626246354056
Validation loss: 2.5809422487971028

Epoch: 103| Step: 0
Training loss: 2.9080353862073416
Validation loss: 2.5787677857287075

Epoch: 5| Step: 1
Training loss: 2.604847709612022
Validation loss: 2.5826596004405658

Epoch: 5| Step: 2
Training loss: 2.5678268518751293
Validation loss: 2.5832323315260606

Epoch: 5| Step: 3
Training loss: 2.9823216269681794
Validation loss: 2.579768355457896

Epoch: 5| Step: 4
Training loss: 3.0824608642370825
Validation loss: 2.585815282058199

Epoch: 5| Step: 5
Training loss: 3.708988231879906
Validation loss: 2.5931424624003134

Epoch: 5| Step: 6
Training loss: 2.869007001015334
Validation loss: 2.581337421381625

Epoch: 5| Step: 7
Training loss: 2.7178684427732884
Validation loss: 2.581074276363807

Epoch: 5| Step: 8
Training loss: 3.19842303281642
Validation loss: 2.5785567154916986

Epoch: 5| Step: 9
Training loss: 2.8088194606529493
Validation loss: 2.5740856955575038

Epoch: 5| Step: 10
Training loss: 2.621469939704705
Validation loss: 2.5747856760598578

Epoch: 104| Step: 0
Training loss: 3.0581185274973657
Validation loss: 2.5784753168030132

Epoch: 5| Step: 1
Training loss: 2.621751773743781
Validation loss: 2.5775778131656994

Epoch: 5| Step: 2
Training loss: 3.026615020658618
Validation loss: 2.5830752268280395

Epoch: 5| Step: 3
Training loss: 2.742043689749779
Validation loss: 2.589977172806081

Epoch: 5| Step: 4
Training loss: 2.8037037093635058
Validation loss: 2.5995462967332577

Epoch: 5| Step: 5
Training loss: 2.425159417644285
Validation loss: 2.596564034376917

Epoch: 5| Step: 6
Training loss: 3.0886833239915226
Validation loss: 2.599330836852293

Epoch: 5| Step: 7
Training loss: 2.5441157834857857
Validation loss: 2.596798201406492

Epoch: 5| Step: 8
Training loss: 3.2286131025438722
Validation loss: 2.6092399634438666

Epoch: 5| Step: 9
Training loss: 3.563489676085764
Validation loss: 2.598789347116195

Epoch: 5| Step: 10
Training loss: 2.916977311802963
Validation loss: 2.580959551962329

Epoch: 105| Step: 0
Training loss: 2.5772820221631036
Validation loss: 2.5789973846639738

Epoch: 5| Step: 1
Training loss: 3.0928021144470943
Validation loss: 2.5784004464521195

Epoch: 5| Step: 2
Training loss: 2.4965110274808024
Validation loss: 2.5789440923423284

Epoch: 5| Step: 3
Training loss: 2.6676472013520356
Validation loss: 2.574727550094763

Epoch: 5| Step: 4
Training loss: 2.888993416223785
Validation loss: 2.577679604757021

Epoch: 5| Step: 5
Training loss: 3.3325169199280062
Validation loss: 2.578161535318037

Epoch: 5| Step: 6
Training loss: 2.7051724303845757
Validation loss: 2.576756042993284

Epoch: 5| Step: 7
Training loss: 2.4346538457452827
Validation loss: 2.5834300717418976

Epoch: 5| Step: 8
Training loss: 2.8749135875154845
Validation loss: 2.5945230896749343

Epoch: 5| Step: 9
Training loss: 3.290315439239415
Validation loss: 2.61561411160687

Epoch: 5| Step: 10
Training loss: 3.757735983214289
Validation loss: 2.6399053117250655

Epoch: 106| Step: 0
Training loss: 3.4695951789613124
Validation loss: 2.624332864721129

Epoch: 5| Step: 1
Training loss: 2.5021312212483875
Validation loss: 2.590544733373767

Epoch: 5| Step: 2
Training loss: 2.9877771288929895
Validation loss: 2.579823652987844

Epoch: 5| Step: 3
Training loss: 2.6546477029117646
Validation loss: 2.5802185776019324

Epoch: 5| Step: 4
Training loss: 2.849794775283032
Validation loss: 2.578126578083469

Epoch: 5| Step: 5
Training loss: 3.044632149762622
Validation loss: 2.57528086149167

Epoch: 5| Step: 6
Training loss: 2.695228464779184
Validation loss: 2.5758449651130304

Epoch: 5| Step: 7
Training loss: 3.11148459788781
Validation loss: 2.5772412368613193

Epoch: 5| Step: 8
Training loss: 2.998178723943182
Validation loss: 2.5788656175902807

Epoch: 5| Step: 9
Training loss: 2.957842898124468
Validation loss: 2.5800237341648664

Epoch: 5| Step: 10
Training loss: 2.6937936234980095
Validation loss: 2.5784695461885723

Epoch: 107| Step: 0
Training loss: 2.5995842454528266
Validation loss: 2.5720861435559734

Epoch: 5| Step: 1
Training loss: 2.9094660202850555
Validation loss: 2.5751779019127636

Epoch: 5| Step: 2
Training loss: 2.94033287291838
Validation loss: 2.5754482957875626

Epoch: 5| Step: 3
Training loss: 3.0375015447165246
Validation loss: 2.578291692779789

Epoch: 5| Step: 4
Training loss: 2.988238804334988
Validation loss: 2.5763522270835897

Epoch: 5| Step: 5
Training loss: 2.6923374729815004
Validation loss: 2.5722243126563975

Epoch: 5| Step: 6
Training loss: 3.4794665605199264
Validation loss: 2.5734293755942637

Epoch: 5| Step: 7
Training loss: 2.921440214559609
Validation loss: 2.58251940716378

Epoch: 5| Step: 8
Training loss: 2.5722443993227806
Validation loss: 2.5847855054633175

Epoch: 5| Step: 9
Training loss: 2.740950520060143
Validation loss: 2.5840716658186493

Epoch: 5| Step: 10
Training loss: 3.18248638716526
Validation loss: 2.5768644361698354

Epoch: 108| Step: 0
Training loss: 3.2176965267268995
Validation loss: 2.573240144152096

Epoch: 5| Step: 1
Training loss: 2.439617020146107
Validation loss: 2.573980960142343

Epoch: 5| Step: 2
Training loss: 2.940907551308235
Validation loss: 2.573379388970687

Epoch: 5| Step: 3
Training loss: 2.812486267056316
Validation loss: 2.5713070737016785

Epoch: 5| Step: 4
Training loss: 2.270760234624487
Validation loss: 2.5726713548758338

Epoch: 5| Step: 5
Training loss: 3.0124688111269626
Validation loss: 2.5763977021958273

Epoch: 5| Step: 6
Training loss: 2.7606206758554666
Validation loss: 2.5777067549338755

Epoch: 5| Step: 7
Training loss: 2.9393877497401997
Validation loss: 2.579036615363624

Epoch: 5| Step: 8
Training loss: 2.9282439477428577
Validation loss: 2.581250710479695

Epoch: 5| Step: 9
Training loss: 3.4876007065537897
Validation loss: 2.582566125700563

Epoch: 5| Step: 10
Training loss: 3.115017013380881
Validation loss: 2.577548418799031

Epoch: 109| Step: 0
Training loss: 3.041059842826406
Validation loss: 2.583406320970514

Epoch: 5| Step: 1
Training loss: 3.3286287168324264
Validation loss: 2.5766930196417066

Epoch: 5| Step: 2
Training loss: 2.957122357878573
Validation loss: 2.5729576145112296

Epoch: 5| Step: 3
Training loss: 2.726570632179178
Validation loss: 2.56949408029736

Epoch: 5| Step: 4
Training loss: 2.837486999750815
Validation loss: 2.5754312631800587

Epoch: 5| Step: 5
Training loss: 2.7075985620933003
Validation loss: 2.57512967300581

Epoch: 5| Step: 6
Training loss: 2.8057330634571183
Validation loss: 2.5691660303299706

Epoch: 5| Step: 7
Training loss: 3.069456646081331
Validation loss: 2.569039815253391

Epoch: 5| Step: 8
Training loss: 3.175397298390315
Validation loss: 2.5716391800430647

Epoch: 5| Step: 9
Training loss: 2.781272802366586
Validation loss: 2.576380552478075

Epoch: 5| Step: 10
Training loss: 2.4632765537922547
Validation loss: 2.5893692222572873

Epoch: 110| Step: 0
Training loss: 2.6137098294513876
Validation loss: 2.6124990987366465

Epoch: 5| Step: 1
Training loss: 2.7529431979093806
Validation loss: 2.666174747262412

Epoch: 5| Step: 2
Training loss: 3.0197471156567217
Validation loss: 2.713716835551681

Epoch: 5| Step: 3
Training loss: 3.334007830724462
Validation loss: 2.6485500468471788

Epoch: 5| Step: 4
Training loss: 2.9796479020990714
Validation loss: 2.6025647609455977

Epoch: 5| Step: 5
Training loss: 2.8729570842847774
Validation loss: 2.5812678725332425

Epoch: 5| Step: 6
Training loss: 3.034813114049534
Validation loss: 2.570616187666713

Epoch: 5| Step: 7
Training loss: 2.7889211923401027
Validation loss: 2.569032747129537

Epoch: 5| Step: 8
Training loss: 2.6708870115157795
Validation loss: 2.5827138087107744

Epoch: 5| Step: 9
Training loss: 2.9175918928121063
Validation loss: 2.6051452999749967

Epoch: 5| Step: 10
Training loss: 3.2228918001037177
Validation loss: 2.625632348099621

Epoch: 111| Step: 0
Training loss: 3.0045311405563355
Validation loss: 2.6197302152250774

Epoch: 5| Step: 1
Training loss: 2.9562958340791523
Validation loss: 2.6023080842553146

Epoch: 5| Step: 2
Training loss: 3.4069599496666836
Validation loss: 2.578272422833987

Epoch: 5| Step: 3
Training loss: 2.334002966387775
Validation loss: 2.5777746057538007

Epoch: 5| Step: 4
Training loss: 2.997210159096784
Validation loss: 2.5931050605400694

Epoch: 5| Step: 5
Training loss: 3.2926556674824794
Validation loss: 2.6128900343861883

Epoch: 5| Step: 6
Training loss: 2.723915017089319
Validation loss: 2.6002632100963243

Epoch: 5| Step: 7
Training loss: 2.721444033853081
Validation loss: 2.572254428644033

Epoch: 5| Step: 8
Training loss: 2.959741355833752
Validation loss: 2.577602333742838

Epoch: 5| Step: 9
Training loss: 2.9312316893959345
Validation loss: 2.586510375001289

Epoch: 5| Step: 10
Training loss: 2.8494673047068395
Validation loss: 2.6015989407031306

Epoch: 112| Step: 0
Training loss: 3.1204715724506538
Validation loss: 2.6421110308230977

Epoch: 5| Step: 1
Training loss: 2.858196244877345
Validation loss: 2.6448596344458237

Epoch: 5| Step: 2
Training loss: 2.8798309869976526
Validation loss: 2.6280872416344794

Epoch: 5| Step: 3
Training loss: 2.9315890638682784
Validation loss: 2.621156362052235

Epoch: 5| Step: 4
Training loss: 2.767982383390827
Validation loss: 2.593732170343182

Epoch: 5| Step: 5
Training loss: 3.074401772466462
Validation loss: 2.5854503169078678

Epoch: 5| Step: 6
Training loss: 2.9273639874742488
Validation loss: 2.5776941878558035

Epoch: 5| Step: 7
Training loss: 3.1666832137093803
Validation loss: 2.563216300632294

Epoch: 5| Step: 8
Training loss: 3.017794446382602
Validation loss: 2.5576212670820095

Epoch: 5| Step: 9
Training loss: 2.5448716598557026
Validation loss: 2.554978560964651

Epoch: 5| Step: 10
Training loss: 2.870806911957791
Validation loss: 2.5535175622102133

Epoch: 113| Step: 0
Training loss: 2.8603557301416376
Validation loss: 2.5580966852705074

Epoch: 5| Step: 1
Training loss: 2.691367980950713
Validation loss: 2.555168629124506

Epoch: 5| Step: 2
Training loss: 3.1743584292543163
Validation loss: 2.5647351071239615

Epoch: 5| Step: 3
Training loss: 2.962274979041047
Validation loss: 2.568749500734992

Epoch: 5| Step: 4
Training loss: 3.4936293797834557
Validation loss: 2.576415276682264

Epoch: 5| Step: 5
Training loss: 3.1669613215906463
Validation loss: 2.572033008051818

Epoch: 5| Step: 6
Training loss: 2.545767701380487
Validation loss: 2.572914519767236

Epoch: 5| Step: 7
Training loss: 2.9903954301214433
Validation loss: 2.5730027700059943

Epoch: 5| Step: 8
Training loss: 2.6478336512300356
Validation loss: 2.5602225631121582

Epoch: 5| Step: 9
Training loss: 2.5324601471336265
Validation loss: 2.5607902821846382

Epoch: 5| Step: 10
Training loss: 2.7306799636376753
Validation loss: 2.5609769699537837

Epoch: 114| Step: 0
Training loss: 2.7136010708350193
Validation loss: 2.56102109241807

Epoch: 5| Step: 1
Training loss: 3.2823252051619454
Validation loss: 2.562770494080245

Epoch: 5| Step: 2
Training loss: 2.6816877456826025
Validation loss: 2.5618371673991036

Epoch: 5| Step: 3
Training loss: 2.850673756515969
Validation loss: 2.566412793932159

Epoch: 5| Step: 4
Training loss: 3.099468764040492
Validation loss: 2.5666815482311325

Epoch: 5| Step: 5
Training loss: 2.8511325459786625
Validation loss: 2.568306212302166

Epoch: 5| Step: 6
Training loss: 2.757738668950186
Validation loss: 2.566020715918653

Epoch: 5| Step: 7
Training loss: 2.769910520079233
Validation loss: 2.57003207247403

Epoch: 5| Step: 8
Training loss: 3.347236455638235
Validation loss: 2.567121841159926

Epoch: 5| Step: 9
Training loss: 2.7348257510731666
Validation loss: 2.565870907623386

Epoch: 5| Step: 10
Training loss: 2.662534392945136
Validation loss: 2.5781685953192595

Epoch: 115| Step: 0
Training loss: 2.795657612205074
Validation loss: 2.5617829747028753

Epoch: 5| Step: 1
Training loss: 2.8105521344526014
Validation loss: 2.5567686944943153

Epoch: 5| Step: 2
Training loss: 3.560302324209351
Validation loss: 2.551843587644514

Epoch: 5| Step: 3
Training loss: 3.0245365639038986
Validation loss: 2.5503779372327005

Epoch: 5| Step: 4
Training loss: 2.7913376533627328
Validation loss: 2.550743046082041

Epoch: 5| Step: 5
Training loss: 2.5840786709811727
Validation loss: 2.5579390795989023

Epoch: 5| Step: 6
Training loss: 2.9666830798205845
Validation loss: 2.5562585312201795

Epoch: 5| Step: 7
Training loss: 2.979436493149573
Validation loss: 2.554553058959421

Epoch: 5| Step: 8
Training loss: 2.9912018509595093
Validation loss: 2.547950129665328

Epoch: 5| Step: 9
Training loss: 3.0693298786430017
Validation loss: 2.5521068234562816

Epoch: 5| Step: 10
Training loss: 2.2425064763854885
Validation loss: 2.553979113192972

Epoch: 116| Step: 0
Training loss: 3.075406185708204
Validation loss: 2.564853236970219

Epoch: 5| Step: 1
Training loss: 3.3428516072331056
Validation loss: 2.5834416751458216

Epoch: 5| Step: 2
Training loss: 2.3631087311126917
Validation loss: 2.577989091270917

Epoch: 5| Step: 3
Training loss: 2.9905320809816387
Validation loss: 2.585699822148354

Epoch: 5| Step: 4
Training loss: 2.698396637590057
Validation loss: 2.5770412858419376

Epoch: 5| Step: 5
Training loss: 2.490092099183191
Validation loss: 2.5626276035987194

Epoch: 5| Step: 6
Training loss: 3.345163919854422
Validation loss: 2.5636617476634043

Epoch: 5| Step: 7
Training loss: 2.8010602782796648
Validation loss: 2.5620197233235453

Epoch: 5| Step: 8
Training loss: 2.9077018474861744
Validation loss: 2.5540849157448955

Epoch: 5| Step: 9
Training loss: 2.9057800569309804
Validation loss: 2.5601031841660804

Epoch: 5| Step: 10
Training loss: 2.6724301480905615
Validation loss: 2.562438862069011

Epoch: 117| Step: 0
Training loss: 3.077589269190882
Validation loss: 2.560457048024527

Epoch: 5| Step: 1
Training loss: 2.8834120377693546
Validation loss: 2.5696244912190322

Epoch: 5| Step: 2
Training loss: 2.8890048048613917
Validation loss: 2.56222783345833

Epoch: 5| Step: 3
Training loss: 2.4664592496767836
Validation loss: 2.5838671570022207

Epoch: 5| Step: 4
Training loss: 3.3207384262658675
Validation loss: 2.5688059700800268

Epoch: 5| Step: 5
Training loss: 3.1568195093595155
Validation loss: 2.564077046604987

Epoch: 5| Step: 6
Training loss: 2.4443411070722902
Validation loss: 2.558937998588495

Epoch: 5| Step: 7
Training loss: 2.96658455024255
Validation loss: 2.545958538738383

Epoch: 5| Step: 8
Training loss: 2.5035542971248583
Validation loss: 2.5423681265211404

Epoch: 5| Step: 9
Training loss: 2.946660793120225
Validation loss: 2.544275751824018

Epoch: 5| Step: 10
Training loss: 2.884674711350938
Validation loss: 2.5423090667764714

Epoch: 118| Step: 0
Training loss: 3.2256091466675607
Validation loss: 2.542981652002678

Epoch: 5| Step: 1
Training loss: 2.6043707093729185
Validation loss: 2.5424974140597705

Epoch: 5| Step: 2
Training loss: 3.169628682095245
Validation loss: 2.5449938464991395

Epoch: 5| Step: 3
Training loss: 3.1184934399713016
Validation loss: 2.5400194316983398

Epoch: 5| Step: 4
Training loss: 2.998852510341944
Validation loss: 2.5409502693811166

Epoch: 5| Step: 5
Training loss: 2.9617472726489438
Validation loss: 2.539181152802347

Epoch: 5| Step: 6
Training loss: 2.750090424178086
Validation loss: 2.5377988224224213

Epoch: 5| Step: 7
Training loss: 2.679444060097431
Validation loss: 2.53789591226146

Epoch: 5| Step: 8
Training loss: 2.828772202091516
Validation loss: 2.5434236436713804

Epoch: 5| Step: 9
Training loss: 2.6037663469978063
Validation loss: 2.5467464893481204

Epoch: 5| Step: 10
Training loss: 2.6663974586339654
Validation loss: 2.5518208067127914

Epoch: 119| Step: 0
Training loss: 2.8377190660785714
Validation loss: 2.5669487373759106

Epoch: 5| Step: 1
Training loss: 3.026284151763002
Validation loss: 2.5783897385788754

Epoch: 5| Step: 2
Training loss: 3.212607587504503
Validation loss: 2.6073671647448258

Epoch: 5| Step: 3
Training loss: 2.058412837090254
Validation loss: 2.6843378523549837

Epoch: 5| Step: 4
Training loss: 3.606187478090432
Validation loss: 2.826259353242768

Epoch: 5| Step: 5
Training loss: 3.4730744769773993
Validation loss: 2.7261950024853743

Epoch: 5| Step: 6
Training loss: 2.8916187124829142
Validation loss: 2.6223102037515154

Epoch: 5| Step: 7
Training loss: 2.3927739277341655
Validation loss: 2.5474801793070507

Epoch: 5| Step: 8
Training loss: 2.6870547968249805
Validation loss: 2.5506998775391074

Epoch: 5| Step: 9
Training loss: 2.6243456978739412
Validation loss: 2.5735136544074466

Epoch: 5| Step: 10
Training loss: 3.56310896102542
Validation loss: 2.611326375541899

Epoch: 120| Step: 0
Training loss: 2.7702577227293848
Validation loss: 2.6198572076284794

Epoch: 5| Step: 1
Training loss: 3.1579061261189185
Validation loss: 2.600678304707802

Epoch: 5| Step: 2
Training loss: 3.0220221624666244
Validation loss: 2.5911681629953685

Epoch: 5| Step: 3
Training loss: 2.7232838677622393
Validation loss: 2.590951597259515

Epoch: 5| Step: 4
Training loss: 3.1899461522834165
Validation loss: 2.5922571574383557

Epoch: 5| Step: 5
Training loss: 3.039409392105615
Validation loss: 2.595862191678047

Epoch: 5| Step: 6
Training loss: 3.0019597963694573
Validation loss: 2.596789119849277

Epoch: 5| Step: 7
Training loss: 2.937374355794491
Validation loss: 2.58814650481186

Epoch: 5| Step: 8
Training loss: 2.836163808657062
Validation loss: 2.5764562949597227

Epoch: 5| Step: 9
Training loss: 3.0606338108863693
Validation loss: 2.5673403061945774

Epoch: 5| Step: 10
Training loss: 2.8863650713120363
Validation loss: 2.56242841364975

Epoch: 121| Step: 0
Training loss: 3.371503643696386
Validation loss: 2.5703981536558187

Epoch: 5| Step: 1
Training loss: 2.8196785761224707
Validation loss: 2.5705153540475028

Epoch: 5| Step: 2
Training loss: 2.7161478327264983
Validation loss: 2.5555670758989835

Epoch: 5| Step: 3
Training loss: 2.4905185193282917
Validation loss: 2.571466068305974

Epoch: 5| Step: 4
Training loss: 3.1779810569971643
Validation loss: 2.579290761488133

Epoch: 5| Step: 5
Training loss: 2.9035142717649545
Validation loss: 2.6304590034901847

Epoch: 5| Step: 6
Training loss: 3.2041018601417113
Validation loss: 2.6774965770673473

Epoch: 5| Step: 7
Training loss: 2.6786442719500165
Validation loss: 2.7797603048865684

Epoch: 5| Step: 8
Training loss: 3.14878597176885
Validation loss: 2.786603021109307

Epoch: 5| Step: 9
Training loss: 2.643831011024713
Validation loss: 2.7068182185145027

Epoch: 5| Step: 10
Training loss: 2.954605135281554
Validation loss: 2.6811799420551923

Epoch: 122| Step: 0
Training loss: 2.485073543204852
Validation loss: 2.594524170652892

Epoch: 5| Step: 1
Training loss: 3.654474202129598
Validation loss: 2.558849624956335

Epoch: 5| Step: 2
Training loss: 3.1936129128135815
Validation loss: 2.56038878534555

Epoch: 5| Step: 3
Training loss: 2.4100858161811214
Validation loss: 2.557652331833108

Epoch: 5| Step: 4
Training loss: 3.0962106186445593
Validation loss: 2.5614063871611417

Epoch: 5| Step: 5
Training loss: 2.9828058881171806
Validation loss: 2.5614686076320874

Epoch: 5| Step: 6
Training loss: 2.661553149142517
Validation loss: 2.5657152433195782

Epoch: 5| Step: 7
Training loss: 2.899157658279983
Validation loss: 2.5698194856619905

Epoch: 5| Step: 8
Training loss: 2.477163825453122
Validation loss: 2.5717937202206103

Epoch: 5| Step: 9
Training loss: 2.786359230251865
Validation loss: 2.5802783881356857

Epoch: 5| Step: 10
Training loss: 3.349456481113327
Validation loss: 2.578054514269756

Epoch: 123| Step: 0
Training loss: 2.949233301392082
Validation loss: 2.559971377904279

Epoch: 5| Step: 1
Training loss: 3.0094281501869578
Validation loss: 2.5531683053055367

Epoch: 5| Step: 2
Training loss: 3.097827728643499
Validation loss: 2.5560405181730563

Epoch: 5| Step: 3
Training loss: 3.2633030863974932
Validation loss: 2.563990895822978

Epoch: 5| Step: 4
Training loss: 2.702166436965711
Validation loss: 2.568362032107844

Epoch: 5| Step: 5
Training loss: 3.3729849557323375
Validation loss: 2.568538780002545

Epoch: 5| Step: 6
Training loss: 3.2083351003138314
Validation loss: 2.573942902364124

Epoch: 5| Step: 7
Training loss: 2.159545812185794
Validation loss: 2.570507754415589

Epoch: 5| Step: 8
Training loss: 2.9609239723882936
Validation loss: 2.6013395413518263

Epoch: 5| Step: 9
Training loss: 2.2854810174200852
Validation loss: 2.613041153818092

Epoch: 5| Step: 10
Training loss: 2.7446241719765476
Validation loss: 2.6289382023522707

Epoch: 124| Step: 0
Training loss: 3.056915485345628
Validation loss: 2.631805925180826

Epoch: 5| Step: 1
Training loss: 2.6561810652819773
Validation loss: 2.6515964983375846

Epoch: 5| Step: 2
Training loss: 2.8655495603525885
Validation loss: 2.658038340931832

Epoch: 5| Step: 3
Training loss: 2.374608860935131
Validation loss: 2.6308074899038347

Epoch: 5| Step: 4
Training loss: 2.5448031745449535
Validation loss: 2.6182135554086545

Epoch: 5| Step: 5
Training loss: 2.722629629084347
Validation loss: 2.5980613647344817

Epoch: 5| Step: 6
Training loss: 3.0225229383281325
Validation loss: 2.5909772439124543

Epoch: 5| Step: 7
Training loss: 3.4720341712043594
Validation loss: 2.5845576715104395

Epoch: 5| Step: 8
Training loss: 3.4111290382082613
Validation loss: 2.5839988887849494

Epoch: 5| Step: 9
Training loss: 2.972664430784982
Validation loss: 2.5854511785772356

Epoch: 5| Step: 10
Training loss: 2.7669558151847697
Validation loss: 2.586777145810782

Epoch: 125| Step: 0
Training loss: 3.136171133996655
Validation loss: 2.5830916606925998

Epoch: 5| Step: 1
Training loss: 2.641643530887732
Validation loss: 2.578391373174222

Epoch: 5| Step: 2
Training loss: 2.6577888070586093
Validation loss: 2.5764032923721625

Epoch: 5| Step: 3
Training loss: 3.045879494821267
Validation loss: 2.5808524115208784

Epoch: 5| Step: 4
Training loss: 3.0843340993718322
Validation loss: 2.5820818604397635

Epoch: 5| Step: 5
Training loss: 2.6565623380245658
Validation loss: 2.579632575049129

Epoch: 5| Step: 6
Training loss: 2.519062229237402
Validation loss: 2.5788804365404783

Epoch: 5| Step: 7
Training loss: 2.3019788439298026
Validation loss: 2.586146896257055

Epoch: 5| Step: 8
Training loss: 3.449075663483491
Validation loss: 2.587108377095084

Epoch: 5| Step: 9
Training loss: 2.69704481100805
Validation loss: 2.5953418301204967

Epoch: 5| Step: 10
Training loss: 3.593387087866353
Validation loss: 2.602749136416156

Epoch: 126| Step: 0
Training loss: 3.1394675480064054
Validation loss: 2.606940551738939

Epoch: 5| Step: 1
Training loss: 2.73850814162307
Validation loss: 2.61736830416054

Epoch: 5| Step: 2
Training loss: 2.989457201982961
Validation loss: 2.6308527974550024

Epoch: 5| Step: 3
Training loss: 2.893210909168082
Validation loss: 2.6428002654129505

Epoch: 5| Step: 4
Training loss: 2.6479290049275717
Validation loss: 2.6480859839058106

Epoch: 5| Step: 5
Training loss: 3.0798102862897467
Validation loss: 2.6298006297123284

Epoch: 5| Step: 6
Training loss: 2.6162307129070173
Validation loss: 2.5883265742025428

Epoch: 5| Step: 7
Training loss: 2.9795557225997884
Validation loss: 2.5718899374177835

Epoch: 5| Step: 8
Training loss: 2.432764784700869
Validation loss: 2.5710630179212766

Epoch: 5| Step: 9
Training loss: 3.3518352264201177
Validation loss: 2.5761642253804173

Epoch: 5| Step: 10
Training loss: 3.0128410811068154
Validation loss: 2.579194440683351

Epoch: 127| Step: 0
Training loss: 2.8262467865417378
Validation loss: 2.585772610795431

Epoch: 5| Step: 1
Training loss: 3.096466105207393
Validation loss: 2.5884594987922624

Epoch: 5| Step: 2
Training loss: 2.881126344886276
Validation loss: 2.5836593903134357

Epoch: 5| Step: 3
Training loss: 2.77730168607167
Validation loss: 2.579742831898128

Epoch: 5| Step: 4
Training loss: 2.7000611863444246
Validation loss: 2.5761700339982734

Epoch: 5| Step: 5
Training loss: 3.0353606362670824
Validation loss: 2.5917820794554687

Epoch: 5| Step: 6
Training loss: 2.796846101920585
Validation loss: 2.5815226788574366

Epoch: 5| Step: 7
Training loss: 3.3511046339164126
Validation loss: 2.5877471134872447

Epoch: 5| Step: 8
Training loss: 2.704665346016333
Validation loss: 2.5928131044245353

Epoch: 5| Step: 9
Training loss: 2.578856116000835
Validation loss: 2.587383135216861

Epoch: 5| Step: 10
Training loss: 3.2133365773808524
Validation loss: 2.5846472173319994

Epoch: 128| Step: 0
Training loss: 2.6656724646077796
Validation loss: 2.595151459121649

Epoch: 5| Step: 1
Training loss: 3.141219049704286
Validation loss: 2.5812742268340774

Epoch: 5| Step: 2
Training loss: 2.678034058209707
Validation loss: 2.5817179826248116

Epoch: 5| Step: 3
Training loss: 2.7778573936073014
Validation loss: 2.5799604726607543

Epoch: 5| Step: 4
Training loss: 2.6232596486498663
Validation loss: 2.5858553283581243

Epoch: 5| Step: 5
Training loss: 3.0094091363953366
Validation loss: 2.5734139673810863

Epoch: 5| Step: 6
Training loss: 2.7219810141098186
Validation loss: 2.560750862553324

Epoch: 5| Step: 7
Training loss: 2.9865677851532086
Validation loss: 2.5570701568514855

Epoch: 5| Step: 8
Training loss: 2.782049942703673
Validation loss: 2.5427628716355386

Epoch: 5| Step: 9
Training loss: 3.0301325989970938
Validation loss: 2.5476812287818538

Epoch: 5| Step: 10
Training loss: 3.188399094579585
Validation loss: 2.536662661012

Epoch: 129| Step: 0
Training loss: 3.058368153248268
Validation loss: 2.53076691691161

Epoch: 5| Step: 1
Training loss: 2.7909194363782706
Validation loss: 2.5271900451878873

Epoch: 5| Step: 2
Training loss: 2.5426796838213463
Validation loss: 2.5301678318084893

Epoch: 5| Step: 3
Training loss: 2.941133402901771
Validation loss: 2.529718142894696

Epoch: 5| Step: 4
Training loss: 3.3344654703782033
Validation loss: 2.523041603970897

Epoch: 5| Step: 5
Training loss: 2.9938536305499683
Validation loss: 2.5248550237774543

Epoch: 5| Step: 6
Training loss: 2.9161847034245456
Validation loss: 2.5193613297619373

Epoch: 5| Step: 7
Training loss: 2.8946427749791113
Validation loss: 2.51968067664417

Epoch: 5| Step: 8
Training loss: 2.9238506308627805
Validation loss: 2.521182726982412

Epoch: 5| Step: 9
Training loss: 2.060832187371013
Validation loss: 2.5191706797582643

Epoch: 5| Step: 10
Training loss: 2.8122847580668857
Validation loss: 2.5147386040328734

Epoch: 130| Step: 0
Training loss: 2.5449668429450023
Validation loss: 2.511794769510023

Epoch: 5| Step: 1
Training loss: 2.8555499064005754
Validation loss: 2.5126680505995833

Epoch: 5| Step: 2
Training loss: 2.882899833534858
Validation loss: 2.5160102709720933

Epoch: 5| Step: 3
Training loss: 3.2557474813931218
Validation loss: 2.5219577372210478

Epoch: 5| Step: 4
Training loss: 2.624834146255554
Validation loss: 2.529368336334346

Epoch: 5| Step: 5
Training loss: 3.114538764422092
Validation loss: 2.5466966725763465

Epoch: 5| Step: 6
Training loss: 2.729459868156152
Validation loss: 2.5396646078212695

Epoch: 5| Step: 7
Training loss: 2.892936483435539
Validation loss: 2.538886474363853

Epoch: 5| Step: 8
Training loss: 2.5914936592602977
Validation loss: 2.534482274929069

Epoch: 5| Step: 9
Training loss: 2.6525396125848504
Validation loss: 2.532149364375327

Epoch: 5| Step: 10
Training loss: 3.166666198195038
Validation loss: 2.529977009184153

Epoch: 131| Step: 0
Training loss: 2.733492289162285
Validation loss: 2.5264144461707017

Epoch: 5| Step: 1
Training loss: 2.7457806556599857
Validation loss: 2.530182080814538

Epoch: 5| Step: 2
Training loss: 2.7750999089031967
Validation loss: 2.535405305131925

Epoch: 5| Step: 3
Training loss: 3.152870105917013
Validation loss: 2.5370293475422767

Epoch: 5| Step: 4
Training loss: 3.032603954473769
Validation loss: 2.5294050508938932

Epoch: 5| Step: 5
Training loss: 2.3322646441192605
Validation loss: 2.5291118557163985

Epoch: 5| Step: 6
Training loss: 3.440851692956964
Validation loss: 2.525824483540633

Epoch: 5| Step: 7
Training loss: 2.9207002450730584
Validation loss: 2.5308139475570197

Epoch: 5| Step: 8
Training loss: 2.9216871558205573
Validation loss: 2.5244147581440384

Epoch: 5| Step: 9
Training loss: 2.1669666620567405
Validation loss: 2.5217868978063605

Epoch: 5| Step: 10
Training loss: 2.9389133705540864
Validation loss: 2.52339682226712

Epoch: 132| Step: 0
Training loss: 3.0497235407372187
Validation loss: 2.528276170964028

Epoch: 5| Step: 1
Training loss: 2.9955242466194396
Validation loss: 2.528940008405343

Epoch: 5| Step: 2
Training loss: 2.9044265769416047
Validation loss: 2.5366985120325767

Epoch: 5| Step: 3
Training loss: 3.0862024893643785
Validation loss: 2.5419117600757737

Epoch: 5| Step: 4
Training loss: 2.452100989559869
Validation loss: 2.551124707799322

Epoch: 5| Step: 5
Training loss: 2.8108005051364446
Validation loss: 2.5305262302739324

Epoch: 5| Step: 6
Training loss: 3.0623628235281406
Validation loss: 2.5291753328822972

Epoch: 5| Step: 7
Training loss: 2.5848306090528133
Validation loss: 2.5264461259922593

Epoch: 5| Step: 8
Training loss: 2.789894385987943
Validation loss: 2.519546114715635

Epoch: 5| Step: 9
Training loss: 2.701222273769478
Validation loss: 2.514865183439077

Epoch: 5| Step: 10
Training loss: 2.8297766820460346
Validation loss: 2.5146937082422807

Epoch: 133| Step: 0
Training loss: 2.6553077372853604
Validation loss: 2.512062139737678

Epoch: 5| Step: 1
Training loss: 3.02281888404471
Validation loss: 2.5125392351396556

Epoch: 5| Step: 2
Training loss: 2.873314736727243
Validation loss: 2.515143082646618

Epoch: 5| Step: 3
Training loss: 2.9232546563111006
Validation loss: 2.516242937163346

Epoch: 5| Step: 4
Training loss: 2.5760097264645263
Validation loss: 2.5210620088587876

Epoch: 5| Step: 5
Training loss: 3.1165685206444715
Validation loss: 2.515882435709318

Epoch: 5| Step: 6
Training loss: 3.00975865407207
Validation loss: 2.522385399014233

Epoch: 5| Step: 7
Training loss: 3.1092434189142417
Validation loss: 2.518507196857004

Epoch: 5| Step: 8
Training loss: 2.3915276911251127
Validation loss: 2.5165558085737807

Epoch: 5| Step: 9
Training loss: 2.2563918769166795
Validation loss: 2.5166199966739757

Epoch: 5| Step: 10
Training loss: 3.2006166638811604
Validation loss: 2.513796515376547

Epoch: 134| Step: 0
Training loss: 2.8290599310342985
Validation loss: 2.5176696172652826

Epoch: 5| Step: 1
Training loss: 2.4583152727228743
Validation loss: 2.5191226939273803

Epoch: 5| Step: 2
Training loss: 3.2089353384681543
Validation loss: 2.5143270291093067

Epoch: 5| Step: 3
Training loss: 2.864788995931627
Validation loss: 2.5075164130469774

Epoch: 5| Step: 4
Training loss: 2.4222345885078753
Validation loss: 2.5087538978776958

Epoch: 5| Step: 5
Training loss: 2.5977130625542517
Validation loss: 2.5103921294635407

Epoch: 5| Step: 6
Training loss: 3.046829614545789
Validation loss: 2.517243652507756

Epoch: 5| Step: 7
Training loss: 3.0084730339547194
Validation loss: 2.5233893971982666

Epoch: 5| Step: 8
Training loss: 2.73766934990164
Validation loss: 2.5153318140164966

Epoch: 5| Step: 9
Training loss: 3.291025477544599
Validation loss: 2.5110738414316107

Epoch: 5| Step: 10
Training loss: 2.514928970243954
Validation loss: 2.51106513182864

Epoch: 135| Step: 0
Training loss: 2.5288470129618004
Validation loss: 2.5058630037857337

Epoch: 5| Step: 1
Training loss: 2.554934148518388
Validation loss: 2.502134000940005

Epoch: 5| Step: 2
Training loss: 2.4860420631845908
Validation loss: 2.503816989625068

Epoch: 5| Step: 3
Training loss: 2.9861274087939202
Validation loss: 2.513354436039907

Epoch: 5| Step: 4
Training loss: 2.862114266471697
Validation loss: 2.518736421151581

Epoch: 5| Step: 5
Training loss: 2.6960361559676214
Validation loss: 2.520614363996755

Epoch: 5| Step: 6
Training loss: 3.072720968620642
Validation loss: 2.5260065355174217

Epoch: 5| Step: 7
Training loss: 3.0898860344965406
Validation loss: 2.5273991802001516

Epoch: 5| Step: 8
Training loss: 2.830075597663209
Validation loss: 2.5312990289940713

Epoch: 5| Step: 9
Training loss: 3.2687167630958407
Validation loss: 2.514873712701387

Epoch: 5| Step: 10
Training loss: 2.759243342713778
Validation loss: 2.5023304987675554

Epoch: 136| Step: 0
Training loss: 2.7719703769724866
Validation loss: 2.507994746280456

Epoch: 5| Step: 1
Training loss: 3.0694291491772288
Validation loss: 2.505719665311119

Epoch: 5| Step: 2
Training loss: 2.7064421482016754
Validation loss: 2.511057679994545

Epoch: 5| Step: 3
Training loss: 2.9333495992151737
Validation loss: 2.5084440156686787

Epoch: 5| Step: 4
Training loss: 3.283655937598871
Validation loss: 2.50630169007254

Epoch: 5| Step: 5
Training loss: 2.6622404876461667
Validation loss: 2.5231970946802353

Epoch: 5| Step: 6
Training loss: 2.5377154254138308
Validation loss: 2.5378729616832576

Epoch: 5| Step: 7
Training loss: 2.9138496055254133
Validation loss: 2.5637149066744818

Epoch: 5| Step: 8
Training loss: 2.9570983314716113
Validation loss: 2.531282713109117

Epoch: 5| Step: 9
Training loss: 2.561473175498113
Validation loss: 2.522619138802453

Epoch: 5| Step: 10
Training loss: 2.733649980610484
Validation loss: 2.5152739183870616

Epoch: 137| Step: 0
Training loss: 2.9051582172530552
Validation loss: 2.508530650501331

Epoch: 5| Step: 1
Training loss: 2.6830258053033758
Validation loss: 2.505512608871896

Epoch: 5| Step: 2
Training loss: 2.8626158645035695
Validation loss: 2.5047718253065687

Epoch: 5| Step: 3
Training loss: 2.6868515119393357
Validation loss: 2.5086022189935413

Epoch: 5| Step: 4
Training loss: 2.7822748074912793
Validation loss: 2.504210963910252

Epoch: 5| Step: 5
Training loss: 2.6791268254269736
Validation loss: 2.5068138090870176

Epoch: 5| Step: 6
Training loss: 2.8700037126151603
Validation loss: 2.5022363115247916

Epoch: 5| Step: 7
Training loss: 3.1005565635911756
Validation loss: 2.502840342106971

Epoch: 5| Step: 8
Training loss: 3.001640824780875
Validation loss: 2.5042465025108123

Epoch: 5| Step: 9
Training loss: 2.682733433957489
Validation loss: 2.5100872865508217

Epoch: 5| Step: 10
Training loss: 2.750010403700136
Validation loss: 2.5201685601898673

Epoch: 138| Step: 0
Training loss: 2.417323702801252
Validation loss: 2.527910214613028

Epoch: 5| Step: 1
Training loss: 3.253268432386738
Validation loss: 2.5231432923394657

Epoch: 5| Step: 2
Training loss: 2.805852026639671
Validation loss: 2.529179054918237

Epoch: 5| Step: 3
Training loss: 3.0952074105275353
Validation loss: 2.5255936298335073

Epoch: 5| Step: 4
Training loss: 3.159914212571371
Validation loss: 2.5240696200049584

Epoch: 5| Step: 5
Training loss: 2.5342783767211827
Validation loss: 2.512767990750601

Epoch: 5| Step: 6
Training loss: 2.827054658958466
Validation loss: 2.5194525527460327

Epoch: 5| Step: 7
Training loss: 2.7258305045237297
Validation loss: 2.514529449836842

Epoch: 5| Step: 8
Training loss: 2.591164920806869
Validation loss: 2.5128484582778206

Epoch: 5| Step: 9
Training loss: 2.832403497895407
Validation loss: 2.5037246153682142

Epoch: 5| Step: 10
Training loss: 2.625633344993415
Validation loss: 2.5032798038861053

Epoch: 139| Step: 0
Training loss: 3.1158479570601827
Validation loss: 2.4966216261505356

Epoch: 5| Step: 1
Training loss: 2.6385400429976795
Validation loss: 2.503564511508146

Epoch: 5| Step: 2
Training loss: 2.738754862750989
Validation loss: 2.5132298818651746

Epoch: 5| Step: 3
Training loss: 2.7683056270247146
Validation loss: 2.52216121250358

Epoch: 5| Step: 4
Training loss: 1.882273996675184
Validation loss: 2.530991671095989

Epoch: 5| Step: 5
Training loss: 3.5010205552065123
Validation loss: 2.532582345468494

Epoch: 5| Step: 6
Training loss: 3.2085733365212272
Validation loss: 2.519447226942515

Epoch: 5| Step: 7
Training loss: 2.947821481918098
Validation loss: 2.501400596255077

Epoch: 5| Step: 8
Training loss: 2.5865567206419233
Validation loss: 2.5000007506338653

Epoch: 5| Step: 9
Training loss: 2.7981735709931472
Validation loss: 2.5035435696735435

Epoch: 5| Step: 10
Training loss: 2.6137316305718175
Validation loss: 2.5092797584538755

Epoch: 140| Step: 0
Training loss: 2.8593898418437385
Validation loss: 2.5065081489636896

Epoch: 5| Step: 1
Training loss: 3.1758136817993443
Validation loss: 2.5070012434915223

Epoch: 5| Step: 2
Training loss: 2.9122999654683905
Validation loss: 2.509165454132569

Epoch: 5| Step: 3
Training loss: 2.882988156805413
Validation loss: 2.5102269043037166

Epoch: 5| Step: 4
Training loss: 3.372289346120816
Validation loss: 2.503364878554679

Epoch: 5| Step: 5
Training loss: 2.6438282154678756
Validation loss: 2.5017619763667387

Epoch: 5| Step: 6
Training loss: 2.101446439239746
Validation loss: 2.5027853923073544

Epoch: 5| Step: 7
Training loss: 2.4145619884882725
Validation loss: 2.5041822194011334

Epoch: 5| Step: 8
Training loss: 2.9022014680593857
Validation loss: 2.5154920137892276

Epoch: 5| Step: 9
Training loss: 2.742540646497855
Validation loss: 2.5369819551583688

Epoch: 5| Step: 10
Training loss: 2.9817301429515286
Validation loss: 2.5568361434065316

Epoch: 141| Step: 0
Training loss: 2.7237738309170467
Validation loss: 2.567334462620963

Epoch: 5| Step: 1
Training loss: 3.12667649121832
Validation loss: 2.561546860737215

Epoch: 5| Step: 2
Training loss: 2.8135581675025247
Validation loss: 2.541416164609971

Epoch: 5| Step: 3
Training loss: 3.0335869973004614
Validation loss: 2.5323364628295786

Epoch: 5| Step: 4
Training loss: 2.8739149285071726
Validation loss: 2.518424460938501

Epoch: 5| Step: 5
Training loss: 3.104860181378647
Validation loss: 2.5069744907954425

Epoch: 5| Step: 6
Training loss: 2.813260802046627
Validation loss: 2.50269884438738

Epoch: 5| Step: 7
Training loss: 2.8190368980003786
Validation loss: 2.503258577012202

Epoch: 5| Step: 8
Training loss: 2.5133072500452234
Validation loss: 2.499980166571915

Epoch: 5| Step: 9
Training loss: 2.334772336100391
Validation loss: 2.5000827944797073

Epoch: 5| Step: 10
Training loss: 2.7178356343100907
Validation loss: 2.5022330463143883

Epoch: 142| Step: 0
Training loss: 2.744457989460634
Validation loss: 2.504739412814497

Epoch: 5| Step: 1
Training loss: 2.4423575295135302
Validation loss: 2.5041721744083323

Epoch: 5| Step: 2
Training loss: 2.773285939548307
Validation loss: 2.5087344943815313

Epoch: 5| Step: 3
Training loss: 2.898500508654334
Validation loss: 2.5087083421389322

Epoch: 5| Step: 4
Training loss: 3.286703464335593
Validation loss: 2.524122929305157

Epoch: 5| Step: 5
Training loss: 2.7805464636973403
Validation loss: 2.5168397294537552

Epoch: 5| Step: 6
Training loss: 3.252500012666789
Validation loss: 2.5240407827256135

Epoch: 5| Step: 7
Training loss: 3.038686380916896
Validation loss: 2.5157945428416646

Epoch: 5| Step: 8
Training loss: 2.6815853238220835
Validation loss: 2.5023058255831625

Epoch: 5| Step: 9
Training loss: 2.5533810696069628
Validation loss: 2.5009332637664343

Epoch: 5| Step: 10
Training loss: 2.191062097843798
Validation loss: 2.497621056570692

Epoch: 143| Step: 0
Training loss: 3.1783805991947225
Validation loss: 2.5079203871777094

Epoch: 5| Step: 1
Training loss: 2.178183853908623
Validation loss: 2.503624364396663

Epoch: 5| Step: 2
Training loss: 3.021817031825078
Validation loss: 2.5078243725191225

Epoch: 5| Step: 3
Training loss: 2.6263806481526015
Validation loss: 2.5117503191820787

Epoch: 5| Step: 4
Training loss: 3.2916168659804907
Validation loss: 2.5124774824715073

Epoch: 5| Step: 5
Training loss: 2.851819672157565
Validation loss: 2.5233646810149875

Epoch: 5| Step: 6
Training loss: 3.076128781940225
Validation loss: 2.516865928602162

Epoch: 5| Step: 7
Training loss: 2.5628083206401304
Validation loss: 2.515550701348843

Epoch: 5| Step: 8
Training loss: 2.8574998053603218
Validation loss: 2.5118541925653384

Epoch: 5| Step: 9
Training loss: 2.4521998708079202
Validation loss: 2.514847150279392

Epoch: 5| Step: 10
Training loss: 2.512764767792496
Validation loss: 2.505977666411693

Epoch: 144| Step: 0
Training loss: 2.623012426040774
Validation loss: 2.4959981986287287

Epoch: 5| Step: 1
Training loss: 2.5994352057369046
Validation loss: 2.494162875101196

Epoch: 5| Step: 2
Training loss: 2.927628996863149
Validation loss: 2.5037650746411604

Epoch: 5| Step: 3
Training loss: 3.2519152939804004
Validation loss: 2.4994806621887142

Epoch: 5| Step: 4
Training loss: 2.389352796542703
Validation loss: 2.4995534764702687

Epoch: 5| Step: 5
Training loss: 2.995123396482397
Validation loss: 2.5016923057793017

Epoch: 5| Step: 6
Training loss: 3.1446944105574097
Validation loss: 2.5061132811542515

Epoch: 5| Step: 7
Training loss: 2.4608160079757817
Validation loss: 2.509093084314051

Epoch: 5| Step: 8
Training loss: 2.489348130441476
Validation loss: 2.511546375063594

Epoch: 5| Step: 9
Training loss: 2.822575979097087
Validation loss: 2.4997549347075343

Epoch: 5| Step: 10
Training loss: 2.9476731450263727
Validation loss: 2.5030251934485683

Epoch: 145| Step: 0
Training loss: 2.704962926952557
Validation loss: 2.5031395190460555

Epoch: 5| Step: 1
Training loss: 2.4166358638861185
Validation loss: 2.499370200290236

Epoch: 5| Step: 2
Training loss: 2.568465569335002
Validation loss: 2.4957360185205317

Epoch: 5| Step: 3
Training loss: 2.5095958607771753
Validation loss: 2.491235196774546

Epoch: 5| Step: 4
Training loss: 3.1609602425285566
Validation loss: 2.4929159548113216

Epoch: 5| Step: 5
Training loss: 3.1039516365963404
Validation loss: 2.5033496238438753

Epoch: 5| Step: 6
Training loss: 2.7822855189655518
Validation loss: 2.5089240996950295

Epoch: 5| Step: 7
Training loss: 2.944128957277116
Validation loss: 2.5127650504008905

Epoch: 5| Step: 8
Training loss: 2.463231159236877
Validation loss: 2.5108406043553293

Epoch: 5| Step: 9
Training loss: 2.9276167812232865
Validation loss: 2.5111736337043253

Epoch: 5| Step: 10
Training loss: 3.0267776058327938
Validation loss: 2.4978119493879456

Epoch: 146| Step: 0
Training loss: 2.3669257192362587
Validation loss: 2.5095843695008373

Epoch: 5| Step: 1
Training loss: 3.0444661326072873
Validation loss: 2.5138632469506446

Epoch: 5| Step: 2
Training loss: 2.684456632392084
Validation loss: 2.509451780331065

Epoch: 5| Step: 3
Training loss: 3.044654389109065
Validation loss: 2.5134222992896125

Epoch: 5| Step: 4
Training loss: 2.7301381447182496
Validation loss: 2.511526989058485

Epoch: 5| Step: 5
Training loss: 2.6671820579611842
Validation loss: 2.5155119603346

Epoch: 5| Step: 6
Training loss: 2.7303942668835606
Validation loss: 2.5193746263873114

Epoch: 5| Step: 7
Training loss: 2.4734493869826
Validation loss: 2.508727681458377

Epoch: 5| Step: 8
Training loss: 2.590551219299092
Validation loss: 2.5030558152973104

Epoch: 5| Step: 9
Training loss: 2.8709985834036496
Validation loss: 2.4892127990611357

Epoch: 5| Step: 10
Training loss: 3.3307891355141037
Validation loss: 2.489105430684798

Epoch: 147| Step: 0
Training loss: 2.879195759060877
Validation loss: 2.4932931324902508

Epoch: 5| Step: 1
Training loss: 2.844651802356125
Validation loss: 2.4938528914280123

Epoch: 5| Step: 2
Training loss: 2.459172563570563
Validation loss: 2.493029230307316

Epoch: 5| Step: 3
Training loss: 2.630718451154434
Validation loss: 2.494867010317105

Epoch: 5| Step: 4
Training loss: 2.99346896387504
Validation loss: 2.4994496549871195

Epoch: 5| Step: 5
Training loss: 3.121711984832611
Validation loss: 2.504308517005465

Epoch: 5| Step: 6
Training loss: 2.7556138392235603
Validation loss: 2.4994786221316008

Epoch: 5| Step: 7
Training loss: 2.571218406323659
Validation loss: 2.5153608061760355

Epoch: 5| Step: 8
Training loss: 2.462262671792915
Validation loss: 2.522193599314031

Epoch: 5| Step: 9
Training loss: 2.901047510840912
Validation loss: 2.524974439652626

Epoch: 5| Step: 10
Training loss: 2.8835165513173653
Validation loss: 2.534770713346437

Epoch: 148| Step: 0
Training loss: 3.2615248936591006
Validation loss: 2.5607682545988952

Epoch: 5| Step: 1
Training loss: 2.3041507419176144
Validation loss: 2.568082191210854

Epoch: 5| Step: 2
Training loss: 2.9126532780339636
Validation loss: 2.57071941271776

Epoch: 5| Step: 3
Training loss: 2.587023550202858
Validation loss: 2.5715084695269272

Epoch: 5| Step: 4
Training loss: 3.2235424326072297
Validation loss: 2.579723082865499

Epoch: 5| Step: 5
Training loss: 2.749091258321926
Validation loss: 2.5488802204741687

Epoch: 5| Step: 6
Training loss: 2.8583145259612857
Validation loss: 2.508746450419139

Epoch: 5| Step: 7
Training loss: 2.7362616433583806
Validation loss: 2.4946319763946883

Epoch: 5| Step: 8
Training loss: 2.8188142891803296
Validation loss: 2.501747451744415

Epoch: 5| Step: 9
Training loss: 2.511259947738578
Validation loss: 2.5001985214741143

Epoch: 5| Step: 10
Training loss: 2.775611906203283
Validation loss: 2.503774252991305

Epoch: 149| Step: 0
Training loss: 2.868023077591286
Validation loss: 2.5074501740614896

Epoch: 5| Step: 1
Training loss: 2.6606421566016425
Validation loss: 2.500340952234855

Epoch: 5| Step: 2
Training loss: 3.1488445766612156
Validation loss: 2.5037329972513436

Epoch: 5| Step: 3
Training loss: 2.6797845672732445
Validation loss: 2.5017700425476628

Epoch: 5| Step: 4
Training loss: 2.9895827307794653
Validation loss: 2.506148083881144

Epoch: 5| Step: 5
Training loss: 2.783059892147715
Validation loss: 2.502873749184484

Epoch: 5| Step: 6
Training loss: 2.8839754069598476
Validation loss: 2.5153052686627957

Epoch: 5| Step: 7
Training loss: 2.6047814419195436
Validation loss: 2.5164273143789475

Epoch: 5| Step: 8
Training loss: 2.815632072211221
Validation loss: 2.5171659964049478

Epoch: 5| Step: 9
Training loss: 2.938325319616418
Validation loss: 2.541710844283025

Epoch: 5| Step: 10
Training loss: 2.5143213151913164
Validation loss: 2.551265904244959

Epoch: 150| Step: 0
Training loss: 2.7707986662185076
Validation loss: 2.582618420611976

Epoch: 5| Step: 1
Training loss: 2.808277520852374
Validation loss: 2.610428518170782

Epoch: 5| Step: 2
Training loss: 2.8117099923996185
Validation loss: 2.628539190390519

Epoch: 5| Step: 3
Training loss: 2.688280391498973
Validation loss: 2.594171022615126

Epoch: 5| Step: 4
Training loss: 2.7639367074413443
Validation loss: 2.583940949236826

Epoch: 5| Step: 5
Training loss: 2.4283942310217603
Validation loss: 2.5595303206925992

Epoch: 5| Step: 6
Training loss: 2.9805007472889256
Validation loss: 2.545961410544368

Epoch: 5| Step: 7
Training loss: 2.996673647229215
Validation loss: 2.5443695375344157

Epoch: 5| Step: 8
Training loss: 2.774033259488746
Validation loss: 2.5362321342973098

Epoch: 5| Step: 9
Training loss: 3.113355685963192
Validation loss: 2.513028019550464

Epoch: 5| Step: 10
Training loss: 3.0304115944979935
Validation loss: 2.5090275500797428

Epoch: 151| Step: 0
Training loss: 2.9245465962400226
Validation loss: 2.4966474100672005

Epoch: 5| Step: 1
Training loss: 3.078586292072915
Validation loss: 2.498677528439798

Epoch: 5| Step: 2
Training loss: 2.626072074313602
Validation loss: 2.4953653341934063

Epoch: 5| Step: 3
Training loss: 3.278985540936913
Validation loss: 2.50055157924219

Epoch: 5| Step: 4
Training loss: 2.3811219268559514
Validation loss: 2.498079902843464

Epoch: 5| Step: 5
Training loss: 2.873473384066821
Validation loss: 2.502956069121579

Epoch: 5| Step: 6
Training loss: 2.5462512791311567
Validation loss: 2.5080235953095977

Epoch: 5| Step: 7
Training loss: 2.6177359390675354
Validation loss: 2.507811547251927

Epoch: 5| Step: 8
Training loss: 2.5637529612895618
Validation loss: 2.5017962719302282

Epoch: 5| Step: 9
Training loss: 2.8567285850458677
Validation loss: 2.5045728756104246

Epoch: 5| Step: 10
Training loss: 2.7861871510156346
Validation loss: 2.5041874752954962

Epoch: 152| Step: 0
Training loss: 2.905333671907099
Validation loss: 2.496640385490887

Epoch: 5| Step: 1
Training loss: 2.322722445409835
Validation loss: 2.4988377002173396

Epoch: 5| Step: 2
Training loss: 3.3135256349059246
Validation loss: 2.494935954936072

Epoch: 5| Step: 3
Training loss: 2.9461239777043318
Validation loss: 2.498847507093851

Epoch: 5| Step: 4
Training loss: 3.1246218643291774
Validation loss: 2.508768905134404

Epoch: 5| Step: 5
Training loss: 2.76886339838035
Validation loss: 2.5026594690714816

Epoch: 5| Step: 6
Training loss: 2.781574187511871
Validation loss: 2.506351803428996

Epoch: 5| Step: 7
Training loss: 3.0067847143148283
Validation loss: 2.5150149627428338

Epoch: 5| Step: 8
Training loss: 2.27105294195202
Validation loss: 2.491003476786198

Epoch: 5| Step: 9
Training loss: 2.357181666413894
Validation loss: 2.481482412221031

Epoch: 5| Step: 10
Training loss: 2.6046467961527413
Validation loss: 2.4871374874342624

Epoch: 153| Step: 0
Training loss: 2.107653558279566
Validation loss: 2.4904149074370108

Epoch: 5| Step: 1
Training loss: 2.838513258112333
Validation loss: 2.495591234453667

Epoch: 5| Step: 2
Training loss: 2.04406953699335
Validation loss: 2.518919177765546

Epoch: 5| Step: 3
Training loss: 2.608164706482111
Validation loss: 2.5243795258174413

Epoch: 5| Step: 4
Training loss: 2.7863275705238304
Validation loss: 2.5117383856083926

Epoch: 5| Step: 5
Training loss: 3.207856196474259
Validation loss: 2.5065980667665815

Epoch: 5| Step: 6
Training loss: 2.609290207267522
Validation loss: 2.5105218025801186

Epoch: 5| Step: 7
Training loss: 2.9956280322729083
Validation loss: 2.508074995907354

Epoch: 5| Step: 8
Training loss: 3.3351003413854543
Validation loss: 2.5109995081694714

Epoch: 5| Step: 9
Training loss: 2.8606937890077946
Validation loss: 2.5118761357310984

Epoch: 5| Step: 10
Training loss: 2.7945126407847245
Validation loss: 2.4983423941728407

Epoch: 154| Step: 0
Training loss: 2.2401417827012655
Validation loss: 2.4934061759639374

Epoch: 5| Step: 1
Training loss: 2.645932433507702
Validation loss: 2.5033099494859905

Epoch: 5| Step: 2
Training loss: 2.9207413866170278
Validation loss: 2.487743434247624

Epoch: 5| Step: 3
Training loss: 2.6493462097950635
Validation loss: 2.4980256118696245

Epoch: 5| Step: 4
Training loss: 2.6455409772053717
Validation loss: 2.4932857324181157

Epoch: 5| Step: 5
Training loss: 2.853032483108177
Validation loss: 2.4877339710705106

Epoch: 5| Step: 6
Training loss: 3.0047969613690597
Validation loss: 2.491677001694087

Epoch: 5| Step: 7
Training loss: 2.6578814713433796
Validation loss: 2.4951424609073154

Epoch: 5| Step: 8
Training loss: 3.03246762704198
Validation loss: 2.503513188290751

Epoch: 5| Step: 9
Training loss: 2.7721121186650635
Validation loss: 2.4930092776658865

Epoch: 5| Step: 10
Training loss: 2.9288840044000493
Validation loss: 2.5042349979486174

Epoch: 155| Step: 0
Training loss: 2.3932706865950593
Validation loss: 2.519775508008491

Epoch: 5| Step: 1
Training loss: 2.834588520793513
Validation loss: 2.52862295831067

Epoch: 5| Step: 2
Training loss: 2.863053254213481
Validation loss: 2.5330306474116013

Epoch: 5| Step: 3
Training loss: 2.757077040687941
Validation loss: 2.521966322801857

Epoch: 5| Step: 4
Training loss: 2.8920255000466235
Validation loss: 2.506135583515784

Epoch: 5| Step: 5
Training loss: 2.4844730765698957
Validation loss: 2.4981559977104424

Epoch: 5| Step: 6
Training loss: 2.331224158095241
Validation loss: 2.497444242098303

Epoch: 5| Step: 7
Training loss: 2.73980261404953
Validation loss: 2.494105896786808

Epoch: 5| Step: 8
Training loss: 2.9281392393305388
Validation loss: 2.495829220007491

Epoch: 5| Step: 9
Training loss: 2.7852724112620915
Validation loss: 2.4883711459564997

Epoch: 5| Step: 10
Training loss: 3.4616860985857167
Validation loss: 2.4866139652379626

Epoch: 156| Step: 0
Training loss: 2.7277151038002483
Validation loss: 2.4905517674407496

Epoch: 5| Step: 1
Training loss: 2.8173537016476984
Validation loss: 2.4897043702702217

Epoch: 5| Step: 2
Training loss: 2.7060364495787885
Validation loss: 2.489189375931817

Epoch: 5| Step: 3
Training loss: 2.52266376549767
Validation loss: 2.494411235950069

Epoch: 5| Step: 4
Training loss: 2.7625498944087687
Validation loss: 2.5009609959535424

Epoch: 5| Step: 5
Training loss: 2.9616450367747547
Validation loss: 2.495645740690416

Epoch: 5| Step: 6
Training loss: 2.683878299114322
Validation loss: 2.514897455234416

Epoch: 5| Step: 7
Training loss: 2.600465193726961
Validation loss: 2.5302803839018435

Epoch: 5| Step: 8
Training loss: 2.6983329324170247
Validation loss: 2.53872014592365

Epoch: 5| Step: 9
Training loss: 3.046838535188446
Validation loss: 2.5456919783438448

Epoch: 5| Step: 10
Training loss: 2.9106628386675757
Validation loss: 2.545621726531657

Epoch: 157| Step: 0
Training loss: 2.8147598512434624
Validation loss: 2.5292771598100443

Epoch: 5| Step: 1
Training loss: 2.8760798540980113
Validation loss: 2.504824563796621

Epoch: 5| Step: 2
Training loss: 2.5979687495594983
Validation loss: 2.5052343484904447

Epoch: 5| Step: 3
Training loss: 2.7807770230455717
Validation loss: 2.5076978517534743

Epoch: 5| Step: 4
Training loss: 2.813269192098526
Validation loss: 2.5133391037488466

Epoch: 5| Step: 5
Training loss: 2.450001082128169
Validation loss: 2.5215071636328044

Epoch: 5| Step: 6
Training loss: 2.834696180153502
Validation loss: 2.5288072418818874

Epoch: 5| Step: 7
Training loss: 2.8540431272032376
Validation loss: 2.544796895398513

Epoch: 5| Step: 8
Training loss: 3.279402439765281
Validation loss: 2.5275270740082245

Epoch: 5| Step: 9
Training loss: 2.6353050680744436
Validation loss: 2.5313028258910104

Epoch: 5| Step: 10
Training loss: 2.8202017553676906
Validation loss: 2.5213340476235873

Epoch: 158| Step: 0
Training loss: 2.2137119960699922
Validation loss: 2.526710094177507

Epoch: 5| Step: 1
Training loss: 2.972539150021928
Validation loss: 2.526712592161007

Epoch: 5| Step: 2
Training loss: 3.097683342409897
Validation loss: 2.531651709981577

Epoch: 5| Step: 3
Training loss: 2.175853570527203
Validation loss: 2.5348793575187716

Epoch: 5| Step: 4
Training loss: 2.395478153161784
Validation loss: 2.566722109797354

Epoch: 5| Step: 5
Training loss: 3.4939600736348986
Validation loss: 2.5568333359533675

Epoch: 5| Step: 6
Training loss: 2.9470522166876005
Validation loss: 2.5333620327498845

Epoch: 5| Step: 7
Training loss: 2.519714348815692
Validation loss: 2.5036235974417003

Epoch: 5| Step: 8
Training loss: 2.7732731300324107
Validation loss: 2.4952079293287768

Epoch: 5| Step: 9
Training loss: 2.944001166447118
Validation loss: 2.492744051653115

Epoch: 5| Step: 10
Training loss: 2.611764875592912
Validation loss: 2.4954860882926284

Epoch: 159| Step: 0
Training loss: 2.1778042221842564
Validation loss: 2.496259327288648

Epoch: 5| Step: 1
Training loss: 2.636357758853304
Validation loss: 2.5161585261462367

Epoch: 5| Step: 2
Training loss: 2.655353978441288
Validation loss: 2.534535441079449

Epoch: 5| Step: 3
Training loss: 2.595829968478337
Validation loss: 2.537084469126742

Epoch: 5| Step: 4
Training loss: 2.635600620127165
Validation loss: 2.5332428230179955

Epoch: 5| Step: 5
Training loss: 3.044565900605918
Validation loss: 2.51192890060549

Epoch: 5| Step: 6
Training loss: 3.4099602047564224
Validation loss: 2.4955510679575923

Epoch: 5| Step: 7
Training loss: 2.294689150433919
Validation loss: 2.4985180861867593

Epoch: 5| Step: 8
Training loss: 2.9405482283167266
Validation loss: 2.499267653389902

Epoch: 5| Step: 9
Training loss: 2.7816484144498435
Validation loss: 2.499781873888019

Epoch: 5| Step: 10
Training loss: 3.0173613140153446
Validation loss: 2.503841554744907

Epoch: 160| Step: 0
Training loss: 2.2944070441477074
Validation loss: 2.4971862083601715

Epoch: 5| Step: 1
Training loss: 2.4210053882310443
Validation loss: 2.497868156035609

Epoch: 5| Step: 2
Training loss: 2.6568370394798033
Validation loss: 2.495236479269482

Epoch: 5| Step: 3
Training loss: 2.8858580177155435
Validation loss: 2.501658123565505

Epoch: 5| Step: 4
Training loss: 3.050950361930183
Validation loss: 2.5034869425916213

Epoch: 5| Step: 5
Training loss: 2.709736406801987
Validation loss: 2.5123525042057713

Epoch: 5| Step: 6
Training loss: 3.108371131673971
Validation loss: 2.5105072500083994

Epoch: 5| Step: 7
Training loss: 2.4596867364982318
Validation loss: 2.5016263542652806

Epoch: 5| Step: 8
Training loss: 2.555285742471376
Validation loss: 2.514745092799367

Epoch: 5| Step: 9
Training loss: 2.8861945764268224
Validation loss: 2.506431423434617

Epoch: 5| Step: 10
Training loss: 3.0116000022187968
Validation loss: 2.5019518585251825

Epoch: 161| Step: 0
Training loss: 2.71584120615165
Validation loss: 2.4971771228298967

Epoch: 5| Step: 1
Training loss: 2.7702237273664934
Validation loss: 2.4929656647058343

Epoch: 5| Step: 2
Training loss: 2.912129679045582
Validation loss: 2.4853607366458528

Epoch: 5| Step: 3
Training loss: 3.072747349788909
Validation loss: 2.4910736994860616

Epoch: 5| Step: 4
Training loss: 2.4093332724909873
Validation loss: 2.488947053128707

Epoch: 5| Step: 5
Training loss: 2.3210500450474973
Validation loss: 2.4970408051086865

Epoch: 5| Step: 6
Training loss: 2.8931072402840825
Validation loss: 2.492786428211763

Epoch: 5| Step: 7
Training loss: 2.59867758499104
Validation loss: 2.503134324449951

Epoch: 5| Step: 8
Training loss: 2.836876579733016
Validation loss: 2.5137453011210984

Epoch: 5| Step: 9
Training loss: 2.9868345660745352
Validation loss: 2.5538659040451233

Epoch: 5| Step: 10
Training loss: 2.5629443271884735
Validation loss: 2.622622756841648

Epoch: 162| Step: 0
Training loss: 2.6129345400144244
Validation loss: 2.6904106499619784

Epoch: 5| Step: 1
Training loss: 2.951493554347524
Validation loss: 2.6498768344628454

Epoch: 5| Step: 2
Training loss: 2.590040104529756
Validation loss: 2.6252462532337826

Epoch: 5| Step: 3
Training loss: 2.655323719756531
Validation loss: 2.607682798728954

Epoch: 5| Step: 4
Training loss: 2.835936491154263
Validation loss: 2.5968235889241993

Epoch: 5| Step: 5
Training loss: 2.464105994421832
Validation loss: 2.5895205441315143

Epoch: 5| Step: 6
Training loss: 3.177251609139692
Validation loss: 2.568319296456887

Epoch: 5| Step: 7
Training loss: 2.6617439450212754
Validation loss: 2.5571094683033024

Epoch: 5| Step: 8
Training loss: 2.206152709026103
Validation loss: 2.513153198843591

Epoch: 5| Step: 9
Training loss: 3.2612893558582434
Validation loss: 2.5089699033875252

Epoch: 5| Step: 10
Training loss: 2.5421867047046622
Validation loss: 2.5012532610180487

Epoch: 163| Step: 0
Training loss: 2.587529640212272
Validation loss: 2.4909033879558717

Epoch: 5| Step: 1
Training loss: 2.9873896047713298
Validation loss: 2.4957833107404244

Epoch: 5| Step: 2
Training loss: 3.143198809072842
Validation loss: 2.503166564159613

Epoch: 5| Step: 3
Training loss: 2.929023036627858
Validation loss: 2.49962363537738

Epoch: 5| Step: 4
Training loss: 2.803801245116911
Validation loss: 2.49357973754694

Epoch: 5| Step: 5
Training loss: 2.5566528413275265
Validation loss: 2.4858439570770274

Epoch: 5| Step: 6
Training loss: 2.6944562795931875
Validation loss: 2.4808406298820733

Epoch: 5| Step: 7
Training loss: 2.4497235278402343
Validation loss: 2.4871770538543663

Epoch: 5| Step: 8
Training loss: 2.694236828210693
Validation loss: 2.5073868902104928

Epoch: 5| Step: 9
Training loss: 2.8905176091221136
Validation loss: 2.524879136467699

Epoch: 5| Step: 10
Training loss: 2.4787219527557918
Validation loss: 2.5264315372909794

Epoch: 164| Step: 0
Training loss: 2.853366061970661
Validation loss: 2.5452984942711336

Epoch: 5| Step: 1
Training loss: 3.0252399443996847
Validation loss: 2.558303245641943

Epoch: 5| Step: 2
Training loss: 2.768503275398961
Validation loss: 2.537420917238239

Epoch: 5| Step: 3
Training loss: 2.977512478357875
Validation loss: 2.514741864219608

Epoch: 5| Step: 4
Training loss: 1.9415475344913848
Validation loss: 2.499491313741925

Epoch: 5| Step: 5
Training loss: 2.9833266728786803
Validation loss: 2.489078968178161

Epoch: 5| Step: 6
Training loss: 2.60533505487076
Validation loss: 2.48747200618531

Epoch: 5| Step: 7
Training loss: 2.682438008782211
Validation loss: 2.4908254298947106

Epoch: 5| Step: 8
Training loss: 2.537265928399792
Validation loss: 2.490728726396825

Epoch: 5| Step: 9
Training loss: 2.610201767470618
Validation loss: 2.4976152510589844

Epoch: 5| Step: 10
Training loss: 3.056022644947695
Validation loss: 2.4910844240349017

Epoch: 165| Step: 0
Training loss: 2.738817801809308
Validation loss: 2.4965506281283756

Epoch: 5| Step: 1
Training loss: 2.8394665998915034
Validation loss: 2.504661542513721

Epoch: 5| Step: 2
Training loss: 2.992363110361597
Validation loss: 2.5108605327168774

Epoch: 5| Step: 3
Training loss: 3.0437333562814968
Validation loss: 2.520897480992488

Epoch: 5| Step: 4
Training loss: 2.7174169846026186
Validation loss: 2.511186815445549

Epoch: 5| Step: 5
Training loss: 2.7903995674896342
Validation loss: 2.4940505186432396

Epoch: 5| Step: 6
Training loss: 2.479334870944769
Validation loss: 2.4877279250470767

Epoch: 5| Step: 7
Training loss: 2.820963945468733
Validation loss: 2.487187277774356

Epoch: 5| Step: 8
Training loss: 2.402493604002506
Validation loss: 2.487057800200936

Epoch: 5| Step: 9
Training loss: 2.214005461330277
Validation loss: 2.494807606016611

Epoch: 5| Step: 10
Training loss: 2.7599735600131092
Validation loss: 2.494618279666468

Epoch: 166| Step: 0
Training loss: 2.7434101910985778
Validation loss: 2.4951161600367704

Epoch: 5| Step: 1
Training loss: 2.359363075883051
Validation loss: 2.5023339697752633

Epoch: 5| Step: 2
Training loss: 2.738193744561836
Validation loss: 2.499358870220508

Epoch: 5| Step: 3
Training loss: 2.724031776814241
Validation loss: 2.496919540966356

Epoch: 5| Step: 4
Training loss: 2.1419545520694654
Validation loss: 2.4957002837439957

Epoch: 5| Step: 5
Training loss: 2.9143494983713305
Validation loss: 2.4876499153935914

Epoch: 5| Step: 6
Training loss: 2.6683667445985004
Validation loss: 2.484356786798258

Epoch: 5| Step: 7
Training loss: 3.0206487840426077
Validation loss: 2.488185082302964

Epoch: 5| Step: 8
Training loss: 2.9386008614454915
Validation loss: 2.4918517974034433

Epoch: 5| Step: 9
Training loss: 2.8224325480480927
Validation loss: 2.495041371906984

Epoch: 5| Step: 10
Training loss: 2.629921250995548
Validation loss: 2.4963040236740097

Epoch: 167| Step: 0
Training loss: 3.0019145260713835
Validation loss: 2.4861061966310256

Epoch: 5| Step: 1
Training loss: 2.522605451755837
Validation loss: 2.4800091862367806

Epoch: 5| Step: 2
Training loss: 2.4462276610931903
Validation loss: 2.47277908138043

Epoch: 5| Step: 3
Training loss: 2.475930695914997
Validation loss: 2.4817507584987055

Epoch: 5| Step: 4
Training loss: 3.046712391744625
Validation loss: 2.4876577253832277

Epoch: 5| Step: 5
Training loss: 2.6047773230156044
Validation loss: 2.4898112278521003

Epoch: 5| Step: 6
Training loss: 2.6459937059553953
Validation loss: 2.4937626975730836

Epoch: 5| Step: 7
Training loss: 2.770734130307275
Validation loss: 2.4938883155018097

Epoch: 5| Step: 8
Training loss: 2.27893032078263
Validation loss: 2.504443976970893

Epoch: 5| Step: 9
Training loss: 2.580485425127775
Validation loss: 2.5057943516297683

Epoch: 5| Step: 10
Training loss: 3.1698484664944333
Validation loss: 2.496233577362556

Epoch: 168| Step: 0
Training loss: 2.466944746718462
Validation loss: 2.4962023316123387

Epoch: 5| Step: 1
Training loss: 3.086037935964481
Validation loss: 2.524990525213168

Epoch: 5| Step: 2
Training loss: 2.9746010392611373
Validation loss: 2.528079674335988

Epoch: 5| Step: 3
Training loss: 2.4423346867447173
Validation loss: 2.5408473281986956

Epoch: 5| Step: 4
Training loss: 2.8423710089062104
Validation loss: 2.5444353796293573

Epoch: 5| Step: 5
Training loss: 2.515741381115172
Validation loss: 2.5397523801954236

Epoch: 5| Step: 6
Training loss: 2.5807402322161757
Validation loss: 2.53620394779364

Epoch: 5| Step: 7
Training loss: 2.76561189637609
Validation loss: 2.5210855568511548

Epoch: 5| Step: 8
Training loss: 2.3925050809959743
Validation loss: 2.521956677998657

Epoch: 5| Step: 9
Training loss: 3.0534990345110256
Validation loss: 2.5212016645482493

Epoch: 5| Step: 10
Training loss: 2.37006759434492
Validation loss: 2.511923055700008

Epoch: 169| Step: 0
Training loss: 2.467810922993889
Validation loss: 2.5108213027522064

Epoch: 5| Step: 1
Training loss: 2.723944076199295
Validation loss: 2.4991518673902795

Epoch: 5| Step: 2
Training loss: 2.2133964101964776
Validation loss: 2.4911013952998253

Epoch: 5| Step: 3
Training loss: 2.6537902213744213
Validation loss: 2.479460008045812

Epoch: 5| Step: 4
Training loss: 2.596895447798558
Validation loss: 2.476298994058869

Epoch: 5| Step: 5
Training loss: 2.6563052900955215
Validation loss: 2.484368018116463

Epoch: 5| Step: 6
Training loss: 2.8810551774031854
Validation loss: 2.498396526397972

Epoch: 5| Step: 7
Training loss: 3.055883929400104
Validation loss: 2.5044280706305204

Epoch: 5| Step: 8
Training loss: 2.622702910480069
Validation loss: 2.5198681627005963

Epoch: 5| Step: 9
Training loss: 3.184524643426369
Validation loss: 2.4992513017482505

Epoch: 5| Step: 10
Training loss: 2.3307835293757604
Validation loss: 2.49050297388207

Epoch: 170| Step: 0
Training loss: 2.3201358612334104
Validation loss: 2.493258653128509

Epoch: 5| Step: 1
Training loss: 1.8377202245868631
Validation loss: 2.493394397242615

Epoch: 5| Step: 2
Training loss: 2.1959869326218335
Validation loss: 2.481216926836794

Epoch: 5| Step: 3
Training loss: 2.9374524376447857
Validation loss: 2.4961445746250437

Epoch: 5| Step: 4
Training loss: 2.8820472259781855
Validation loss: 2.5037328979303908

Epoch: 5| Step: 5
Training loss: 2.5059028556304193
Validation loss: 2.519595332792211

Epoch: 5| Step: 6
Training loss: 2.4503832030826245
Validation loss: 2.5103535937619883

Epoch: 5| Step: 7
Training loss: 3.2707167359646028
Validation loss: 2.5137999042634505

Epoch: 5| Step: 8
Training loss: 2.3676094711436515
Validation loss: 2.5266430271659854

Epoch: 5| Step: 9
Training loss: 3.1495806036392846
Validation loss: 2.536664319969177

Epoch: 5| Step: 10
Training loss: 3.023113065754803
Validation loss: 2.5431196493338994

Epoch: 171| Step: 0
Training loss: 3.0700848133412206
Validation loss: 2.5518176571897797

Epoch: 5| Step: 1
Training loss: 1.4550274936136536
Validation loss: 2.545692083077105

Epoch: 5| Step: 2
Training loss: 2.701894138117508
Validation loss: 2.5400573568575564

Epoch: 5| Step: 3
Training loss: 2.8504248453004433
Validation loss: 2.5545055902531937

Epoch: 5| Step: 4
Training loss: 3.0157975063495557
Validation loss: 2.5693300096622416

Epoch: 5| Step: 5
Training loss: 2.4467213627507562
Validation loss: 2.5985857277466216

Epoch: 5| Step: 6
Training loss: 2.5932481579003133
Validation loss: 2.6086257881744674

Epoch: 5| Step: 7
Training loss: 2.1709689439039677
Validation loss: 2.5942617110033925

Epoch: 5| Step: 8
Training loss: 2.792917104390291
Validation loss: 2.5585655573437904

Epoch: 5| Step: 9
Training loss: 2.6617377645240534
Validation loss: 2.5525697965663774

Epoch: 5| Step: 10
Training loss: 3.0500296669439595
Validation loss: 2.5316091931064713

Epoch: 172| Step: 0
Training loss: 2.457897330806932
Validation loss: 2.494729639450684

Epoch: 5| Step: 1
Training loss: 2.18197424377429
Validation loss: 2.5009706827727802

Epoch: 5| Step: 2
Training loss: 2.6538623625388973
Validation loss: 2.499786061187742

Epoch: 5| Step: 3
Training loss: 2.9651567095406253
Validation loss: 2.5094745862896968

Epoch: 5| Step: 4
Training loss: 2.866666408657092
Validation loss: 2.533649977937115

Epoch: 5| Step: 5
Training loss: 2.322858037051905
Validation loss: 2.5409216973353694

Epoch: 5| Step: 6
Training loss: 3.2210908544186445
Validation loss: 2.527016004722151

Epoch: 5| Step: 7
Training loss: 1.7711043954469576
Validation loss: 2.528349297676749

Epoch: 5| Step: 8
Training loss: 3.226270907251897
Validation loss: 2.542924973636055

Epoch: 5| Step: 9
Training loss: 2.5136094637624034
Validation loss: 2.5449437234361394

Epoch: 5| Step: 10
Training loss: 2.69702500935049
Validation loss: 2.5623780608458477

Epoch: 173| Step: 0
Training loss: 2.7499644537275634
Validation loss: 2.535689569188857

Epoch: 5| Step: 1
Training loss: 2.4391712425961423
Validation loss: 2.520568773432654

Epoch: 5| Step: 2
Training loss: 2.0454109139075642
Validation loss: 2.4977825215772103

Epoch: 5| Step: 3
Training loss: 2.880918630216873
Validation loss: 2.4823600505940364

Epoch: 5| Step: 4
Training loss: 2.571760054067214
Validation loss: 2.464289889651303

Epoch: 5| Step: 5
Training loss: 2.5016473111245303
Validation loss: 2.4641689790584067

Epoch: 5| Step: 6
Training loss: 2.7603136343291284
Validation loss: 2.459318433608479

Epoch: 5| Step: 7
Training loss: 2.3328814977316137
Validation loss: 2.454913765602602

Epoch: 5| Step: 8
Training loss: 2.7496180702632347
Validation loss: 2.472480123154594

Epoch: 5| Step: 9
Training loss: 3.306998524728082
Validation loss: 2.492897142763125

Epoch: 5| Step: 10
Training loss: 2.5923155529361916
Validation loss: 2.572354929991095

Epoch: 174| Step: 0
Training loss: 2.6015207098276405
Validation loss: 2.583711894783017

Epoch: 5| Step: 1
Training loss: 2.712033712503878
Validation loss: 2.5165538974730444

Epoch: 5| Step: 2
Training loss: 2.503163148586924
Validation loss: 2.5062463374460564

Epoch: 5| Step: 3
Training loss: 2.2176259376864063
Validation loss: 2.5083116370653347

Epoch: 5| Step: 4
Training loss: 3.0333941240472195
Validation loss: 2.525005668472138

Epoch: 5| Step: 5
Training loss: 2.6174245243066503
Validation loss: 2.542198075839245

Epoch: 5| Step: 6
Training loss: 2.7019484941951064
Validation loss: 2.547372048400382

Epoch: 5| Step: 7
Training loss: 2.446616120851422
Validation loss: 2.567088241565133

Epoch: 5| Step: 8
Training loss: 2.6122510216450197
Validation loss: 2.5746177117569697

Epoch: 5| Step: 9
Training loss: 3.0120681579801394
Validation loss: 2.5993986567873426

Epoch: 5| Step: 10
Training loss: 2.3682049368250913
Validation loss: 2.630297989090384

Epoch: 175| Step: 0
Training loss: 2.752774572857085
Validation loss: 2.620231629801849

Epoch: 5| Step: 1
Training loss: 2.64218761550118
Validation loss: 2.6380408197138285

Epoch: 5| Step: 2
Training loss: 2.565678091115529
Validation loss: 2.614135986960042

Epoch: 5| Step: 3
Training loss: 2.7481364091224676
Validation loss: 2.592911757917391

Epoch: 5| Step: 4
Training loss: 2.5911533272537413
Validation loss: 2.559736834981469

Epoch: 5| Step: 5
Training loss: 2.713129130590775
Validation loss: 2.522324610050692

Epoch: 5| Step: 6
Training loss: 2.8599729485999745
Validation loss: 2.518029953464121

Epoch: 5| Step: 7
Training loss: 2.6044390014664613
Validation loss: 2.506723865785009

Epoch: 5| Step: 8
Training loss: 2.703538455103359
Validation loss: 2.496498154362474

Epoch: 5| Step: 9
Training loss: 2.2690531084176015
Validation loss: 2.4957964915921536

Epoch: 5| Step: 10
Training loss: 2.7552034393632447
Validation loss: 2.479845397877505

Epoch: 176| Step: 0
Training loss: 2.5801229422500866
Validation loss: 2.485271800467086

Epoch: 5| Step: 1
Training loss: 2.882993614896279
Validation loss: 2.4872258580315108

Epoch: 5| Step: 2
Training loss: 2.528476278563785
Validation loss: 2.49749011467494

Epoch: 5| Step: 3
Training loss: 2.613272491577251
Validation loss: 2.549888788010318

Epoch: 5| Step: 4
Training loss: 3.2365115567830034
Validation loss: 2.6071452482408524

Epoch: 5| Step: 5
Training loss: 2.73519466648837
Validation loss: 2.5913769347721614

Epoch: 5| Step: 6
Training loss: 2.24035239802583
Validation loss: 2.579862826405801

Epoch: 5| Step: 7
Training loss: 2.5968766268691788
Validation loss: 2.5800244227642386

Epoch: 5| Step: 8
Training loss: 2.4621360161254
Validation loss: 2.5780976275062693

Epoch: 5| Step: 9
Training loss: 2.3458374899719523
Validation loss: 2.5576430130488026

Epoch: 5| Step: 10
Training loss: 2.3229148990185315
Validation loss: 2.525458847992378

Epoch: 177| Step: 0
Training loss: 2.4092992313014396
Validation loss: 2.494971057430436

Epoch: 5| Step: 1
Training loss: 2.4850970484551462
Validation loss: 2.493609804562269

Epoch: 5| Step: 2
Training loss: 2.296963644587808
Validation loss: 2.4976325864657953

Epoch: 5| Step: 3
Training loss: 2.708696830026995
Validation loss: 2.4961211621085595

Epoch: 5| Step: 4
Training loss: 2.9492375051142057
Validation loss: 2.485035721825898

Epoch: 5| Step: 5
Training loss: 2.4769155930516766
Validation loss: 2.4975780578964053

Epoch: 5| Step: 6
Training loss: 2.573214576761262
Validation loss: 2.4961443034864357

Epoch: 5| Step: 7
Training loss: 2.7487719134489
Validation loss: 2.523335676171695

Epoch: 5| Step: 8
Training loss: 2.200963901554786
Validation loss: 2.5492135540044076

Epoch: 5| Step: 9
Training loss: 2.590927058557634
Validation loss: 2.546715237209028

Epoch: 5| Step: 10
Training loss: 2.9100907081545584
Validation loss: 2.549605752128823

Epoch: 178| Step: 0
Training loss: 2.3109672209174206
Validation loss: 2.5660527849452346

Epoch: 5| Step: 1
Training loss: 2.605555131158024
Validation loss: 2.574837990098709

Epoch: 5| Step: 2
Training loss: 2.0129033128814897
Validation loss: 2.5458282185739383

Epoch: 5| Step: 3
Training loss: 2.9108525409678156
Validation loss: 2.5131731578311753

Epoch: 5| Step: 4
Training loss: 2.7234769046841394
Validation loss: 2.5036399123355206

Epoch: 5| Step: 5
Training loss: 2.4140561791988446
Validation loss: 2.478531227013255

Epoch: 5| Step: 6
Training loss: 3.0665169665521734
Validation loss: 2.4792266487551338

Epoch: 5| Step: 7
Training loss: 2.4620810137759475
Validation loss: 2.4755220979758032

Epoch: 5| Step: 8
Training loss: 2.5710023458641507
Validation loss: 2.4736007900103747

Epoch: 5| Step: 9
Training loss: 2.4214516546577443
Validation loss: 2.4941489424722487

Epoch: 5| Step: 10
Training loss: 2.7898720813809277
Validation loss: 2.4981865355759

Epoch: 179| Step: 0
Training loss: 2.007993697365524
Validation loss: 2.50369543214769

Epoch: 5| Step: 1
Training loss: 2.303951960718492
Validation loss: 2.542730027952934

Epoch: 5| Step: 2
Training loss: 2.170200827837874
Validation loss: 2.5677508378728664

Epoch: 5| Step: 3
Training loss: 2.4677577861716773
Validation loss: 2.5899734856816288

Epoch: 5| Step: 4
Training loss: 3.423022352194126
Validation loss: 2.603228624947734

Epoch: 5| Step: 5
Training loss: 2.7050257708719787
Validation loss: 2.560777115511618

Epoch: 5| Step: 6
Training loss: 1.9889970551397542
Validation loss: 2.546129680434732

Epoch: 5| Step: 7
Training loss: 2.7015938363759244
Validation loss: 2.549725692949999

Epoch: 5| Step: 8
Training loss: 3.0892263921811294
Validation loss: 2.520715368187585

Epoch: 5| Step: 9
Training loss: 2.6200284654949195
Validation loss: 2.510746347331045

Epoch: 5| Step: 10
Training loss: 2.2525854091561572
Validation loss: 2.506301471176658

Epoch: 180| Step: 0
Training loss: 2.293736915655003
Validation loss: 2.5113761524162186

Epoch: 5| Step: 1
Training loss: 3.1188359311789378
Validation loss: 2.5299469837387996

Epoch: 5| Step: 2
Training loss: 2.795790222184272
Validation loss: 2.5137624681807225

Epoch: 5| Step: 3
Training loss: 2.464583442109708
Validation loss: 2.5222875281651542

Epoch: 5| Step: 4
Training loss: 2.757630166572305
Validation loss: 2.5094928695229943

Epoch: 5| Step: 5
Training loss: 1.5719679272221454
Validation loss: 2.4887973119341362

Epoch: 5| Step: 6
Training loss: 2.505395883583627
Validation loss: 2.5027604542099615

Epoch: 5| Step: 7
Training loss: 2.766370855932901
Validation loss: 2.4908737498739835

Epoch: 5| Step: 8
Training loss: 2.1940673337773675
Validation loss: 2.5114674327061106

Epoch: 5| Step: 9
Training loss: 2.8298009469489243
Validation loss: 2.5158757674778007

Epoch: 5| Step: 10
Training loss: 2.5443948476678346
Validation loss: 2.4965282360335506

Epoch: 181| Step: 0
Training loss: 2.732314548743231
Validation loss: 2.494548029827569

Epoch: 5| Step: 1
Training loss: 2.6163402495512926
Validation loss: 2.5025572782272376

Epoch: 5| Step: 2
Training loss: 2.2087149620191524
Validation loss: 2.5227182579176763

Epoch: 5| Step: 3
Training loss: 1.856781184170742
Validation loss: 2.518053826079531

Epoch: 5| Step: 4
Training loss: 2.9348434448079552
Validation loss: 2.5261129139395715

Epoch: 5| Step: 5
Training loss: 2.883904640473016
Validation loss: 2.529713242041153

Epoch: 5| Step: 6
Training loss: 2.4784211605939346
Validation loss: 2.513477119560223

Epoch: 5| Step: 7
Training loss: 2.701741123416791
Validation loss: 2.5052649075211466

Epoch: 5| Step: 8
Training loss: 2.587977869254625
Validation loss: 2.49445699112976

Epoch: 5| Step: 9
Training loss: 1.5440051497289529
Validation loss: 2.4901319038336767

Epoch: 5| Step: 10
Training loss: 2.728471148052626
Validation loss: 2.4861288795501535

Epoch: 182| Step: 0
Training loss: 3.0560604044451862
Validation loss: 2.498502449941376

Epoch: 5| Step: 1
Training loss: 2.210129553160663
Validation loss: 2.5164875571325847

Epoch: 5| Step: 2
Training loss: 2.1587339827181324
Validation loss: 2.5402219991374335

Epoch: 5| Step: 3
Training loss: 2.5864111705653254
Validation loss: 2.532986931063644

Epoch: 5| Step: 4
Training loss: 2.3220890321313115
Validation loss: 2.4816529162764316

Epoch: 5| Step: 5
Training loss: 2.674940169191162
Validation loss: 2.4708802604220526

Epoch: 5| Step: 6
Training loss: 2.347322411690616
Validation loss: 2.4702026420593377

Epoch: 5| Step: 7
Training loss: 2.496727709191616
Validation loss: 2.524613692286773

Epoch: 5| Step: 8
Training loss: 2.8761181522871286
Validation loss: 2.5763907776441006

Epoch: 5| Step: 9
Training loss: 2.5183631732451097
Validation loss: 2.6120907358873025

Epoch: 5| Step: 10
Training loss: 2.215274506516335
Validation loss: 2.646263247182165

Epoch: 183| Step: 0
Training loss: 2.2628158517472112
Validation loss: 2.6300159109014785

Epoch: 5| Step: 1
Training loss: 1.8897729640412728
Validation loss: 2.589093362927755

Epoch: 5| Step: 2
Training loss: 2.4323519604634343
Validation loss: 2.5559504816715934

Epoch: 5| Step: 3
Training loss: 2.876818206379004
Validation loss: 2.532481603002598

Epoch: 5| Step: 4
Training loss: 2.3782148186343
Validation loss: 2.5415710486372185

Epoch: 5| Step: 5
Training loss: 2.66658433151294
Validation loss: 2.5621717539399835

Epoch: 5| Step: 6
Training loss: 2.898525020789467
Validation loss: 2.5951088623433156

Epoch: 5| Step: 7
Training loss: 2.695034819963677
Validation loss: 2.5851477659492197

Epoch: 5| Step: 8
Training loss: 2.517887022542627
Validation loss: 2.573871827998907

Epoch: 5| Step: 9
Training loss: 2.6363886873854776
Validation loss: 2.5323032196877855

Epoch: 5| Step: 10
Training loss: 1.9573279972436775
Validation loss: 2.5001621491135535

Epoch: 184| Step: 0
Training loss: 2.6756153361540944
Validation loss: 2.4743424367514883

Epoch: 5| Step: 1
Training loss: 2.74904876209472
Validation loss: 2.4494927627511185

Epoch: 5| Step: 2
Training loss: 2.1003817392976796
Validation loss: 2.4717667687321008

Epoch: 5| Step: 3
Training loss: 2.7778894073520566
Validation loss: 2.467076893656119

Epoch: 5| Step: 4
Training loss: 2.6485613678629267
Validation loss: 2.4697107969092498

Epoch: 5| Step: 5
Training loss: 2.218211578803384
Validation loss: 2.484153850709344

Epoch: 5| Step: 6
Training loss: 2.4246760751735565
Validation loss: 2.494989914464873

Epoch: 5| Step: 7
Training loss: 2.312800826017588
Validation loss: 2.5413830775613433

Epoch: 5| Step: 8
Training loss: 2.325283082525522
Validation loss: 2.5371456254011373

Epoch: 5| Step: 9
Training loss: 2.770689814777745
Validation loss: 2.5568050366533295

Epoch: 5| Step: 10
Training loss: 2.113571175309255
Validation loss: 2.577005184297568

Epoch: 185| Step: 0
Training loss: 1.833877121589291
Validation loss: 2.5966117116412124

Epoch: 5| Step: 1
Training loss: 2.0270214963957796
Validation loss: 2.6159508839964674

Epoch: 5| Step: 2
Training loss: 3.1542527328567656
Validation loss: 2.623924776418853

Epoch: 5| Step: 3
Training loss: 2.160406115465385
Validation loss: 2.6128990109246484

Epoch: 5| Step: 4
Training loss: 2.768560543424142
Validation loss: 2.5967064386041825

Epoch: 5| Step: 5
Training loss: 2.5403044025612598
Validation loss: 2.5751864972165257

Epoch: 5| Step: 6
Training loss: 2.418348932651902
Validation loss: 2.568132241010074

Epoch: 5| Step: 7
Training loss: 2.5990389478230265
Validation loss: 2.5545155406903715

Epoch: 5| Step: 8
Training loss: 2.6528824945877894
Validation loss: 2.538232685098795

Epoch: 5| Step: 9
Training loss: 2.577276471691705
Validation loss: 2.5290684852073073

Epoch: 5| Step: 10
Training loss: 2.1006620952823205
Validation loss: 2.54441849306978

Epoch: 186| Step: 0
Training loss: 2.383946283477739
Validation loss: 2.5342933946830826

Epoch: 5| Step: 1
Training loss: 2.2469573110643117
Validation loss: 2.54760496588889

Epoch: 5| Step: 2
Training loss: 2.5917381849162218
Validation loss: 2.5680889215415945

Epoch: 5| Step: 3
Training loss: 2.642936642750865
Validation loss: 2.575953643441275

Epoch: 5| Step: 4
Training loss: 2.816203328307608
Validation loss: 2.5940431759527645

Epoch: 5| Step: 5
Training loss: 2.5864180841488027
Validation loss: 2.5992134020530413

Epoch: 5| Step: 6
Training loss: 2.3166508923366314
Validation loss: 2.5872047471060906

Epoch: 5| Step: 7
Training loss: 2.590566680951214
Validation loss: 2.585813356711094

Epoch: 5| Step: 8
Training loss: 1.9490912325014793
Validation loss: 2.578424438707716

Epoch: 5| Step: 9
Training loss: 2.12985292437334
Validation loss: 2.5583576012317124

Epoch: 5| Step: 10
Training loss: 2.447938721469519
Validation loss: 2.565513022989348

Epoch: 187| Step: 0
Training loss: 2.252265002051342
Validation loss: 2.5470004785306823

Epoch: 5| Step: 1
Training loss: 2.065500792954532
Validation loss: 2.577850612085817

Epoch: 5| Step: 2
Training loss: 2.535208162267034
Validation loss: 2.581757614357857

Epoch: 5| Step: 3
Training loss: 2.5797023687274976
Validation loss: 2.59643779350935

Epoch: 5| Step: 4
Training loss: 2.33648613958413
Validation loss: 2.5828143050604466

Epoch: 5| Step: 5
Training loss: 2.470901999931973
Validation loss: 2.602211166732501

Epoch: 5| Step: 6
Training loss: 2.15073873558939
Validation loss: 2.5639194025939425

Epoch: 5| Step: 7
Training loss: 2.867979683435643
Validation loss: 2.601838254160965

Epoch: 5| Step: 8
Training loss: 2.686311858376026
Validation loss: 2.556259245276233

Epoch: 5| Step: 9
Training loss: 2.2354724029769266
Validation loss: 2.5258900590027555

Epoch: 5| Step: 10
Training loss: 2.1798578011218006
Validation loss: 2.498744414471123

Epoch: 188| Step: 0
Training loss: 2.3514555339628145
Validation loss: 2.5060666605781026

Epoch: 5| Step: 1
Training loss: 1.5136746314239016
Validation loss: 2.5109793358775327

Epoch: 5| Step: 2
Training loss: 2.662767738885613
Validation loss: 2.5386218273084262

Epoch: 5| Step: 3
Training loss: 2.5554241086721996
Validation loss: 2.592157260586093

Epoch: 5| Step: 4
Training loss: 2.459303443575393
Validation loss: 2.633380532481005

Epoch: 5| Step: 5
Training loss: 1.862180372628779
Validation loss: 2.666669437640299

Epoch: 5| Step: 6
Training loss: 2.5875117647207633
Validation loss: 2.6910876104196073

Epoch: 5| Step: 7
Training loss: 2.738155606988448
Validation loss: 2.65391031742308

Epoch: 5| Step: 8
Training loss: 2.0984338778807508
Validation loss: 2.5982692738119595

Epoch: 5| Step: 9
Training loss: 2.749516357894883
Validation loss: 2.551840672227044

Epoch: 5| Step: 10
Training loss: 2.503434206644115
Validation loss: 2.5131155797095888

Epoch: 189| Step: 0
Training loss: 2.3894023885511753
Validation loss: 2.4842428310386833

Epoch: 5| Step: 1
Training loss: 2.530708631856265
Validation loss: 2.4680794443457326

Epoch: 5| Step: 2
Training loss: 2.408491403568726
Validation loss: 2.448832086031528

Epoch: 5| Step: 3
Training loss: 2.3266338719167217
Validation loss: 2.444086164596897

Epoch: 5| Step: 4
Training loss: 2.2484736033411368
Validation loss: 2.435783718057469

Epoch: 5| Step: 5
Training loss: 2.3801341528709767
Validation loss: 2.461644843621133

Epoch: 5| Step: 6
Training loss: 2.2920630256748553
Validation loss: 2.4720917682242436

Epoch: 5| Step: 7
Training loss: 2.346309230993709
Validation loss: 2.479574067816187

Epoch: 5| Step: 8
Training loss: 2.429340889791607
Validation loss: 2.4982835455703727

Epoch: 5| Step: 9
Training loss: 2.6393864000938256
Validation loss: 2.5114874571496704

Epoch: 5| Step: 10
Training loss: 2.7116677128047915
Validation loss: 2.520721785632419

Epoch: 190| Step: 0
Training loss: 2.532996340556613
Validation loss: 2.5339596473911326

Epoch: 5| Step: 1
Training loss: 2.6174495736614296
Validation loss: 2.556059507397801

Epoch: 5| Step: 2
Training loss: 1.5467088398171316
Validation loss: 2.579749071698423

Epoch: 5| Step: 3
Training loss: 2.3199293032101886
Validation loss: 2.613323917460896

Epoch: 5| Step: 4
Training loss: 2.467102466782441
Validation loss: 2.6182375857554603

Epoch: 5| Step: 5
Training loss: 2.648741938104823
Validation loss: 2.609484286049453

Epoch: 5| Step: 6
Training loss: 2.5008619729825465
Validation loss: 2.6304490606204576

Epoch: 5| Step: 7
Training loss: 2.403620682926101
Validation loss: 2.6128188734517965

Epoch: 5| Step: 8
Training loss: 2.3189411670612743
Validation loss: 2.614422368189075

Epoch: 5| Step: 9
Training loss: 2.146977708961106
Validation loss: 2.596877386027061

Epoch: 5| Step: 10
Training loss: 2.5016759976546146
Validation loss: 2.596686170936181

Epoch: 191| Step: 0
Training loss: 2.4948775264058827
Validation loss: 2.6030413908969923

Epoch: 5| Step: 1
Training loss: 2.474283993351337
Validation loss: 2.5964323244700105

Epoch: 5| Step: 2
Training loss: 1.820145038547612
Validation loss: 2.5865968694420913

Epoch: 5| Step: 3
Training loss: 2.372459759707609
Validation loss: 2.55649403755267

Epoch: 5| Step: 4
Training loss: 2.4667891429015794
Validation loss: 2.544270872966115

Epoch: 5| Step: 5
Training loss: 2.739008090082138
Validation loss: 2.550905827863661

Epoch: 5| Step: 6
Training loss: 2.2171937024363784
Validation loss: 2.530013922635568

Epoch: 5| Step: 7
Training loss: 2.1027356811950244
Validation loss: 2.548624216725015

Epoch: 5| Step: 8
Training loss: 2.552787143946989
Validation loss: 2.571019827604254

Epoch: 5| Step: 9
Training loss: 2.29741688259401
Validation loss: 2.5878153370581867

Epoch: 5| Step: 10
Training loss: 2.0621914488293167
Validation loss: 2.630954409432666

Epoch: 192| Step: 0
Training loss: 2.767220161025534
Validation loss: 2.6653710029322317

Epoch: 5| Step: 1
Training loss: 2.319812039949746
Validation loss: 2.641945387638791

Epoch: 5| Step: 2
Training loss: 2.2776239919566557
Validation loss: 2.626961341079896

Epoch: 5| Step: 3
Training loss: 2.48456807855758
Validation loss: 2.5992599428363223

Epoch: 5| Step: 4
Training loss: 2.5122478871040066
Validation loss: 2.600389928740835

Epoch: 5| Step: 5
Training loss: 2.1895541764147053
Validation loss: 2.591568895739296

Epoch: 5| Step: 6
Training loss: 2.08192440710703
Validation loss: 2.633605189197329

Epoch: 5| Step: 7
Training loss: 2.2516656644166213
Validation loss: 2.6512869683071982

Epoch: 5| Step: 8
Training loss: 2.280081044479992
Validation loss: 2.635912516397285

Epoch: 5| Step: 9
Training loss: 2.1657011252670935
Validation loss: 2.6324780191059833

Epoch: 5| Step: 10
Training loss: 2.508851023466076
Validation loss: 2.6303836308831836

Epoch: 193| Step: 0
Training loss: 2.2338984054509874
Validation loss: 2.594980492841883

Epoch: 5| Step: 1
Training loss: 2.511578260796868
Validation loss: 2.5754189542613597

Epoch: 5| Step: 2
Training loss: 2.2764353698966837
Validation loss: 2.5651985403868696

Epoch: 5| Step: 3
Training loss: 2.1923905336375733
Validation loss: 2.5680521161400693

Epoch: 5| Step: 4
Training loss: 1.6743595521562418
Validation loss: 2.5587540706006187

Epoch: 5| Step: 5
Training loss: 2.503601912691282
Validation loss: 2.5697969917777472

Epoch: 5| Step: 6
Training loss: 2.0631611082377743
Validation loss: 2.544853619716411

Epoch: 5| Step: 7
Training loss: 2.213872356770542
Validation loss: 2.5795938781475796

Epoch: 5| Step: 8
Training loss: 2.7612789510691735
Validation loss: 2.595075483841122

Epoch: 5| Step: 9
Training loss: 2.3546470107031814
Validation loss: 2.557830224192598

Epoch: 5| Step: 10
Training loss: 2.3767011472850053
Validation loss: 2.5503224003173366

Epoch: 194| Step: 0
Training loss: 2.3711575997568195
Validation loss: 2.55917931689509

Epoch: 5| Step: 1
Training loss: 2.1489028704080027
Validation loss: 2.5561214277592135

Epoch: 5| Step: 2
Training loss: 2.3592385764185497
Validation loss: 2.5416380919153556

Epoch: 5| Step: 3
Training loss: 2.047117379084849
Validation loss: 2.5504918982639686

Epoch: 5| Step: 4
Training loss: 2.5264147505911208
Validation loss: 2.5721935823645246

Epoch: 5| Step: 5
Training loss: 1.828066963513536
Validation loss: 2.604442022389026

Epoch: 5| Step: 6
Training loss: 2.052267295479199
Validation loss: 2.638667766249385

Epoch: 5| Step: 7
Training loss: 2.632059957563418
Validation loss: 2.653881261366326

Epoch: 5| Step: 8
Training loss: 2.365259171977261
Validation loss: 2.6373259456177727

Epoch: 5| Step: 9
Training loss: 2.336073243142573
Validation loss: 2.6335227487613504

Epoch: 5| Step: 10
Training loss: 2.364850291056262
Validation loss: 2.6487779765381276

Epoch: 195| Step: 0
Training loss: 2.1014142179114708
Validation loss: 2.6360739036317895

Epoch: 5| Step: 1
Training loss: 1.8688999128652828
Validation loss: 2.6422116043969597

Epoch: 5| Step: 2
Training loss: 1.9702829115216745
Validation loss: 2.647123317042087

Epoch: 5| Step: 3
Training loss: 2.6173410854538965
Validation loss: 2.6786225550665614

Epoch: 5| Step: 4
Training loss: 2.005553641043912
Validation loss: 2.6438410645324684

Epoch: 5| Step: 5
Training loss: 2.1995493774144017
Validation loss: 2.585756422498304

Epoch: 5| Step: 6
Training loss: 2.639552423365943
Validation loss: 2.5242907192428428

Epoch: 5| Step: 7
Training loss: 2.0923587105106303
Validation loss: 2.518310407281719

Epoch: 5| Step: 8
Training loss: 2.5763750090200905
Validation loss: 2.483296241725505

Epoch: 5| Step: 9
Training loss: 2.1882850328254078
Validation loss: 2.4774956066377034

Epoch: 5| Step: 10
Training loss: 2.4460667431101033
Validation loss: 2.4765739177982695

Epoch: 196| Step: 0
Training loss: 2.0399928984798916
Validation loss: 2.484298953580067

Epoch: 5| Step: 1
Training loss: 2.444556561220431
Validation loss: 2.527958095499768

Epoch: 5| Step: 2
Training loss: 2.339936982145848
Validation loss: 2.568233223096392

Epoch: 5| Step: 3
Training loss: 2.2098737658183216
Validation loss: 2.6003609913888686

Epoch: 5| Step: 4
Training loss: 2.3393861963288
Validation loss: 2.6410774435080424

Epoch: 5| Step: 5
Training loss: 2.532109432549423
Validation loss: 2.6639747334523447

Epoch: 5| Step: 6
Training loss: 2.2177522591940697
Validation loss: 2.6681571289420543

Epoch: 5| Step: 7
Training loss: 1.4201583560437352
Validation loss: 2.6417618860104586

Epoch: 5| Step: 8
Training loss: 2.5351582249426534
Validation loss: 2.643416649710929

Epoch: 5| Step: 9
Training loss: 2.1864606295411977
Validation loss: 2.6483830242995747

Epoch: 5| Step: 10
Training loss: 2.096807951217648
Validation loss: 2.6755410478427506

Epoch: 197| Step: 0
Training loss: 2.3529717667778987
Validation loss: 2.65533533725539

Epoch: 5| Step: 1
Training loss: 1.9899939334719408
Validation loss: 2.633510620340496

Epoch: 5| Step: 2
Training loss: 2.3056561002549407
Validation loss: 2.613234985418805

Epoch: 5| Step: 3
Training loss: 2.6555038301687715
Validation loss: 2.618438140761482

Epoch: 5| Step: 4
Training loss: 1.6069547361445293
Validation loss: 2.6189427315370666

Epoch: 5| Step: 5
Training loss: 2.2460184897377617
Validation loss: 2.63082501664688

Epoch: 5| Step: 6
Training loss: 2.389444595828073
Validation loss: 2.6313816029753903

Epoch: 5| Step: 7
Training loss: 1.934063601965813
Validation loss: 2.619956733257434

Epoch: 5| Step: 8
Training loss: 2.1882617169195826
Validation loss: 2.5799833370070338

Epoch: 5| Step: 9
Training loss: 2.1961669345143484
Validation loss: 2.5976809383048445

Epoch: 5| Step: 10
Training loss: 1.950229115353172
Validation loss: 2.614695062044836

Epoch: 198| Step: 0
Training loss: 1.8867013744873113
Validation loss: 2.6256519627209896

Epoch: 5| Step: 1
Training loss: 1.9249323894963377
Validation loss: 2.625076652224159

Epoch: 5| Step: 2
Training loss: 2.0626507328324633
Validation loss: 2.6549143831200634

Epoch: 5| Step: 3
Training loss: 2.564543583735164
Validation loss: 2.671984982297343

Epoch: 5| Step: 4
Training loss: 2.213778877263814
Validation loss: 2.689627005780118

Epoch: 5| Step: 5
Training loss: 2.0921178120978907
Validation loss: 2.693647671169594

Epoch: 5| Step: 6
Training loss: 1.9900368245230449
Validation loss: 2.6959624075380604

Epoch: 5| Step: 7
Training loss: 2.0955429371444567
Validation loss: 2.698848234912724

Epoch: 5| Step: 8
Training loss: 2.7159737629697633
Validation loss: 2.7321706082226975

Epoch: 5| Step: 9
Training loss: 2.070508148737415
Validation loss: 2.7389500370772533

Epoch: 5| Step: 10
Training loss: 2.3571753953776913
Validation loss: 2.7188931857546086

Epoch: 199| Step: 0
Training loss: 1.8827689391356095
Validation loss: 2.6557201805350696

Epoch: 5| Step: 1
Training loss: 2.1914426967153533
Validation loss: 2.6331161343898613

Epoch: 5| Step: 2
Training loss: 2.63992110582434
Validation loss: 2.5834303029570744

Epoch: 5| Step: 3
Training loss: 2.158917311483862
Validation loss: 2.5595122601723403

Epoch: 5| Step: 4
Training loss: 2.3425635831787686
Validation loss: 2.526980695038501

Epoch: 5| Step: 5
Training loss: 2.080377376324686
Validation loss: 2.561650072954962

Epoch: 5| Step: 6
Training loss: 2.11625273504379
Validation loss: 2.5598432322907936

Epoch: 5| Step: 7
Training loss: 2.1658931109330073
Validation loss: 2.57664749004439

Epoch: 5| Step: 8
Training loss: 2.0503136092562206
Validation loss: 2.6012809512626056

Epoch: 5| Step: 9
Training loss: 1.8636111561197495
Validation loss: 2.5921263759449826

Epoch: 5| Step: 10
Training loss: 1.9862982373535005
Validation loss: 2.593593336687436

Epoch: 200| Step: 0
Training loss: 2.2858478771066437
Validation loss: 2.6267309912621757

Epoch: 5| Step: 1
Training loss: 1.8646689951166902
Validation loss: 2.6456580533146448

Epoch: 5| Step: 2
Training loss: 2.0256767696178684
Validation loss: 2.6853727300270274

Epoch: 5| Step: 3
Training loss: 2.060108069390623
Validation loss: 2.6948607144742356

Epoch: 5| Step: 4
Training loss: 2.0068099194253195
Validation loss: 2.6726512672407674

Epoch: 5| Step: 5
Training loss: 2.105247245276696
Validation loss: 2.639195634392234

Epoch: 5| Step: 6
Training loss: 2.0666751794742284
Validation loss: 2.636539319981163

Epoch: 5| Step: 7
Training loss: 2.4579874431143485
Validation loss: 2.626085620394861

Epoch: 5| Step: 8
Training loss: 2.1426717064866856
Validation loss: 2.5865113032206564

Epoch: 5| Step: 9
Training loss: 2.272435652490132
Validation loss: 2.5656626783185312

Epoch: 5| Step: 10
Training loss: 2.0240648394440535
Validation loss: 2.546808621037094

Epoch: 201| Step: 0
Training loss: 2.5167083303105935
Validation loss: 2.5472840444261604

Epoch: 5| Step: 1
Training loss: 2.3560923799366207
Validation loss: 2.5855629026342

Epoch: 5| Step: 2
Training loss: 2.301595184446302
Validation loss: 2.6211706318667334

Epoch: 5| Step: 3
Training loss: 1.8350889152168375
Validation loss: 2.6438061912637516

Epoch: 5| Step: 4
Training loss: 1.7480571725211707
Validation loss: 2.6522110742086427

Epoch: 5| Step: 5
Training loss: 2.30772887164273
Validation loss: 2.6636965439579887

Epoch: 5| Step: 6
Training loss: 2.0098429702986222
Validation loss: 2.6875933253917768

Epoch: 5| Step: 7
Training loss: 1.598232025632564
Validation loss: 2.699294983270643

Epoch: 5| Step: 8
Training loss: 2.406671957695271
Validation loss: 2.7186364694855425

Epoch: 5| Step: 9
Training loss: 1.8288268347848105
Validation loss: 2.706769541150015

Epoch: 5| Step: 10
Training loss: 1.660276233600825
Validation loss: 2.683550228029824

Epoch: 202| Step: 0
Training loss: 2.2662158064201012
Validation loss: 2.6486842891421074

Epoch: 5| Step: 1
Training loss: 2.425663403091797
Validation loss: 2.6204773479300276

Epoch: 5| Step: 2
Training loss: 2.011480046897046
Validation loss: 2.579123770470913

Epoch: 5| Step: 3
Training loss: 1.602947994223855
Validation loss: 2.5623433585203297

Epoch: 5| Step: 4
Training loss: 1.7133942823788189
Validation loss: 2.566711570443903

Epoch: 5| Step: 5
Training loss: 2.27561610336681
Validation loss: 2.565269171491903

Epoch: 5| Step: 6
Training loss: 2.368389265226349
Validation loss: 2.5681561140723166

Epoch: 5| Step: 7
Training loss: 2.447182814528201
Validation loss: 2.59396883647624

Epoch: 5| Step: 8
Training loss: 1.6575316023079427
Validation loss: 2.6207514640356067

Epoch: 5| Step: 9
Training loss: 1.6702797667933151
Validation loss: 2.623517767935475

Epoch: 5| Step: 10
Training loss: 2.0305942357187656
Validation loss: 2.6465310018353914

Epoch: 203| Step: 0
Training loss: 1.6005660516086595
Validation loss: 2.696658430000841

Epoch: 5| Step: 1
Training loss: 1.8039533434668629
Validation loss: 2.737773923925569

Epoch: 5| Step: 2
Training loss: 1.9548445799335445
Validation loss: 2.787141708346407

Epoch: 5| Step: 3
Training loss: 2.2152206934393894
Validation loss: 2.823074484135099

Epoch: 5| Step: 4
Training loss: 1.900468720794655
Validation loss: 2.847695540823817

Epoch: 5| Step: 5
Training loss: 2.7294897417252013
Validation loss: 2.8223671926486174

Epoch: 5| Step: 6
Training loss: 1.5661193128225734
Validation loss: 2.718907593207365

Epoch: 5| Step: 7
Training loss: 1.9618050529306794
Validation loss: 2.651691919751566

Epoch: 5| Step: 8
Training loss: 2.445756085901878
Validation loss: 2.5591026974147804

Epoch: 5| Step: 9
Training loss: 2.3730915834587307
Validation loss: 2.523721950993377

Epoch: 5| Step: 10
Training loss: 1.8806778452767619
Validation loss: 2.4961620126784116

Epoch: 204| Step: 0
Training loss: 2.404170140661135
Validation loss: 2.495116771377443

Epoch: 5| Step: 1
Training loss: 2.279754880310718
Validation loss: 2.4914303922912655

Epoch: 5| Step: 2
Training loss: 2.0066401402356093
Validation loss: 2.5192878007107002

Epoch: 5| Step: 3
Training loss: 1.7925475712506302
Validation loss: 2.599410927602909

Epoch: 5| Step: 4
Training loss: 2.0057564386775346
Validation loss: 2.6397307400415335

Epoch: 5| Step: 5
Training loss: 2.175754183972419
Validation loss: 2.671716884599391

Epoch: 5| Step: 6
Training loss: 1.9821213668286675
Validation loss: 2.655819009926134

Epoch: 5| Step: 7
Training loss: 1.5863979028358006
Validation loss: 2.6941181444167825

Epoch: 5| Step: 8
Training loss: 2.482752720165366
Validation loss: 2.679570521529143

Epoch: 5| Step: 9
Training loss: 2.065914102657544
Validation loss: 2.611458317914267

Epoch: 5| Step: 10
Training loss: 1.7949768655715348
Validation loss: 2.5962876538786603

Epoch: 205| Step: 0
Training loss: 2.1171462839766995
Validation loss: 2.587811762760721

Epoch: 5| Step: 1
Training loss: 2.028508845655314
Validation loss: 2.548915372625162

Epoch: 5| Step: 2
Training loss: 2.1866089232116583
Validation loss: 2.5451574789672162

Epoch: 5| Step: 3
Training loss: 2.367586310000701
Validation loss: 2.5695679016814674

Epoch: 5| Step: 4
Training loss: 2.130581202125396
Validation loss: 2.5714795162213617

Epoch: 5| Step: 5
Training loss: 1.6522347344403094
Validation loss: 2.607102548493815

Epoch: 5| Step: 6
Training loss: 1.833080715056816
Validation loss: 2.6246468989669176

Epoch: 5| Step: 7
Training loss: 2.039117220440328
Validation loss: 2.647255956330128

Epoch: 5| Step: 8
Training loss: 2.0639759909024447
Validation loss: 2.6419145697656456

Epoch: 5| Step: 9
Training loss: 2.023177082285834
Validation loss: 2.654060920052069

Epoch: 5| Step: 10
Training loss: 1.7689323169575846
Validation loss: 2.629082912410296

Epoch: 206| Step: 0
Training loss: 2.0771250219061
Validation loss: 2.630299281486402

Epoch: 5| Step: 1
Training loss: 1.806263487346413
Validation loss: 2.6255156981721224

Epoch: 5| Step: 2
Training loss: 1.9980424002767891
Validation loss: 2.611068455091611

Epoch: 5| Step: 3
Training loss: 1.936773533140544
Validation loss: 2.632110711521932

Epoch: 5| Step: 4
Training loss: 1.7443165450106808
Validation loss: 2.6354036659569537

Epoch: 5| Step: 5
Training loss: 2.086861052350838
Validation loss: 2.677876546763728

Epoch: 5| Step: 6
Training loss: 1.6288510686003248
Validation loss: 2.7111728584131907

Epoch: 5| Step: 7
Training loss: 1.8517511971810892
Validation loss: 2.6824520347882097

Epoch: 5| Step: 8
Training loss: 2.367979615884114
Validation loss: 2.6572323453886195

Epoch: 5| Step: 9
Training loss: 2.274840456220463
Validation loss: 2.6945519214633156

Epoch: 5| Step: 10
Training loss: 1.962301501786661
Validation loss: 2.695801016616439

Epoch: 207| Step: 0
Training loss: 1.513090787529943
Validation loss: 2.6749049346441818

Epoch: 5| Step: 1
Training loss: 1.7053922907788688
Validation loss: 2.6245897473514237

Epoch: 5| Step: 2
Training loss: 2.033141092165784
Validation loss: 2.5883674502707543

Epoch: 5| Step: 3
Training loss: 1.9807852768621987
Validation loss: 2.5702336280506612

Epoch: 5| Step: 4
Training loss: 1.6432531468918286
Validation loss: 2.56506775852615

Epoch: 5| Step: 5
Training loss: 1.9498731474085969
Validation loss: 2.541983613079689

Epoch: 5| Step: 6
Training loss: 1.981856542698023
Validation loss: 2.5569085796456252

Epoch: 5| Step: 7
Training loss: 2.3350801967923203
Validation loss: 2.566649885592866

Epoch: 5| Step: 8
Training loss: 2.267116713256801
Validation loss: 2.5468612530612424

Epoch: 5| Step: 9
Training loss: 2.1702329067633244
Validation loss: 2.5689715770589183

Epoch: 5| Step: 10
Training loss: 1.9314933697583987
Validation loss: 2.5530863632672802

Epoch: 208| Step: 0
Training loss: 1.643455026362309
Validation loss: 2.597920385713421

Epoch: 5| Step: 1
Training loss: 1.7998909890756
Validation loss: 2.5912868696145575

Epoch: 5| Step: 2
Training loss: 2.1934404638422285
Validation loss: 2.625676275509133

Epoch: 5| Step: 3
Training loss: 2.090020117046878
Validation loss: 2.6498896512959003

Epoch: 5| Step: 4
Training loss: 1.4797918941485633
Validation loss: 2.6880303746907077

Epoch: 5| Step: 5
Training loss: 1.8761464111074206
Validation loss: 2.681078211250619

Epoch: 5| Step: 6
Training loss: 1.9212371263835908
Validation loss: 2.6874365440178436

Epoch: 5| Step: 7
Training loss: 1.8957132014964397
Validation loss: 2.660365657693365

Epoch: 5| Step: 8
Training loss: 2.4362876028776954
Validation loss: 2.6215820464074238

Epoch: 5| Step: 9
Training loss: 1.8834720580172961
Validation loss: 2.60259250111256

Epoch: 5| Step: 10
Training loss: 1.9087963919507163
Validation loss: 2.5754560988362707

Epoch: 209| Step: 0
Training loss: 1.9983246461978
Validation loss: 2.5855385834774265

Epoch: 5| Step: 1
Training loss: 1.7420086961347403
Validation loss: 2.5734629123217356

Epoch: 5| Step: 2
Training loss: 2.200865973919414
Validation loss: 2.5603044129349626

Epoch: 5| Step: 3
Training loss: 1.7092741802268903
Validation loss: 2.5672795112088838

Epoch: 5| Step: 4
Training loss: 1.9111026221587042
Validation loss: 2.550054446782617

Epoch: 5| Step: 5
Training loss: 2.141747173572402
Validation loss: 2.5670533302764267

Epoch: 5| Step: 6
Training loss: 1.732655953438137
Validation loss: 2.585712364197941

Epoch: 5| Step: 7
Training loss: 2.3034550879281435
Validation loss: 2.6197747348001834

Epoch: 5| Step: 8
Training loss: 1.2583036233960918
Validation loss: 2.665653947513541

Epoch: 5| Step: 9
Training loss: 2.0854852879146373
Validation loss: 2.64504467061559

Epoch: 5| Step: 10
Training loss: 1.725079482085663
Validation loss: 2.661684574284736

Epoch: 210| Step: 0
Training loss: 1.4265108097066637
Validation loss: 2.6842438588818487

Epoch: 5| Step: 1
Training loss: 2.1420600702961345
Validation loss: 2.6950973760172148

Epoch: 5| Step: 2
Training loss: 2.3825381261731065
Validation loss: 2.7307388453981263

Epoch: 5| Step: 3
Training loss: 1.7529181264852047
Validation loss: 2.7213501444415593

Epoch: 5| Step: 4
Training loss: 1.5759675036434866
Validation loss: 2.7055555156420747

Epoch: 5| Step: 5
Training loss: 1.7012412476437098
Validation loss: 2.6998631822109758

Epoch: 5| Step: 6
Training loss: 1.6307915405054028
Validation loss: 2.6713460722413522

Epoch: 5| Step: 7
Training loss: 1.629842804542862
Validation loss: 2.6381252801702795

Epoch: 5| Step: 8
Training loss: 2.3308558481124857
Validation loss: 2.624795183980011

Epoch: 5| Step: 9
Training loss: 2.0648647969761265
Validation loss: 2.5953915241378653

Epoch: 5| Step: 10
Training loss: 1.723184240828933
Validation loss: 2.570256397392937

Epoch: 211| Step: 0
Training loss: 1.7648575726930742
Validation loss: 2.6075770964659393

Epoch: 5| Step: 1
Training loss: 1.8359217216949988
Validation loss: 2.597384613808469

Epoch: 5| Step: 2
Training loss: 1.9068337469099115
Validation loss: 2.6017641127773556

Epoch: 5| Step: 3
Training loss: 2.0028929053713687
Validation loss: 2.5998977635904987

Epoch: 5| Step: 4
Training loss: 1.9507376156083476
Validation loss: 2.6054146353581613

Epoch: 5| Step: 5
Training loss: 1.947835978368484
Validation loss: 2.576249522279243

Epoch: 5| Step: 6
Training loss: 1.4719578227655616
Validation loss: 2.555779382716365

Epoch: 5| Step: 7
Training loss: 1.6057735998304223
Validation loss: 2.557614365868833

Epoch: 5| Step: 8
Training loss: 2.3585576542723334
Validation loss: 2.5486198903799777

Epoch: 5| Step: 9
Training loss: 2.070335186528118
Validation loss: 2.577608833834814

Epoch: 5| Step: 10
Training loss: 1.6319971558555428
Validation loss: 2.5834966955886745

Epoch: 212| Step: 0
Training loss: 1.884360915300609
Validation loss: 2.649602785328581

Epoch: 5| Step: 1
Training loss: 1.700274891226196
Validation loss: 2.6805668855303306

Epoch: 5| Step: 2
Training loss: 1.453630831057982
Validation loss: 2.663291795854262

Epoch: 5| Step: 3
Training loss: 1.7549079464411168
Validation loss: 2.6891120493418255

Epoch: 5| Step: 4
Training loss: 2.0520158811478906
Validation loss: 2.651296518775802

Epoch: 5| Step: 5
Training loss: 1.8124677063268357
Validation loss: 2.6437628967270035

Epoch: 5| Step: 6
Training loss: 2.244129469721785
Validation loss: 2.6054760095437035

Epoch: 5| Step: 7
Training loss: 2.1625916478135374
Validation loss: 2.631687869962688

Epoch: 5| Step: 8
Training loss: 1.5237465569423614
Validation loss: 2.6252323053702544

Epoch: 5| Step: 9
Training loss: 2.0415171613903875
Validation loss: 2.6381127210356965

Epoch: 5| Step: 10
Training loss: 1.5248548125897592
Validation loss: 2.6698572877882634

Epoch: 213| Step: 0
Training loss: 1.8854165331873838
Validation loss: 2.686570784578668

Epoch: 5| Step: 1
Training loss: 2.0651310409458468
Validation loss: 2.702748118909055

Epoch: 5| Step: 2
Training loss: 1.6985863923029347
Validation loss: 2.6785494776235046

Epoch: 5| Step: 3
Training loss: 2.028084386292539
Validation loss: 2.641595332934998

Epoch: 5| Step: 4
Training loss: 1.7458240548238564
Validation loss: 2.6200186777595897

Epoch: 5| Step: 5
Training loss: 1.0777514266586683
Validation loss: 2.574063642314341

Epoch: 5| Step: 6
Training loss: 1.7322457104625821
Validation loss: 2.571292485784605

Epoch: 5| Step: 7
Training loss: 1.642740321004147
Validation loss: 2.5512706481394183

Epoch: 5| Step: 8
Training loss: 1.9246861437287828
Validation loss: 2.587338136565399

Epoch: 5| Step: 9
Training loss: 1.7500588543395743
Validation loss: 2.6020152863127124

Epoch: 5| Step: 10
Training loss: 2.329976721553187
Validation loss: 2.6034049983060163

Epoch: 214| Step: 0
Training loss: 1.7846002359752848
Validation loss: 2.6502046416678686

Epoch: 5| Step: 1
Training loss: 1.8399985991348242
Validation loss: 2.65734031059239

Epoch: 5| Step: 2
Training loss: 2.184641578136023
Validation loss: 2.657420208135485

Epoch: 5| Step: 3
Training loss: 2.2561871971625354
Validation loss: 2.689888240473229

Epoch: 5| Step: 4
Training loss: 0.9878663711315803
Validation loss: 2.6615751892742936

Epoch: 5| Step: 5
Training loss: 2.011062307567678
Validation loss: 2.6876534754168175

Epoch: 5| Step: 6
Training loss: 1.6954515813215407
Validation loss: 2.7098918507113785

Epoch: 5| Step: 7
Training loss: 1.5744372043534383
Validation loss: 2.664366961674777

Epoch: 5| Step: 8
Training loss: 1.6874289321063047
Validation loss: 2.6271404528474167

Epoch: 5| Step: 9
Training loss: 1.963837443638195
Validation loss: 2.581102474451999

Epoch: 5| Step: 10
Training loss: 1.5649724853095663
Validation loss: 2.547363520267586

Epoch: 215| Step: 0
Training loss: 1.8160245104576667
Validation loss: 2.536376326839533

Epoch: 5| Step: 1
Training loss: 1.3795997669497388
Validation loss: 2.535641372250362

Epoch: 5| Step: 2
Training loss: 2.008722477589644
Validation loss: 2.5288423942729903

Epoch: 5| Step: 3
Training loss: 1.3107700300037728
Validation loss: 2.5675480739392227

Epoch: 5| Step: 4
Training loss: 1.6020853073180712
Validation loss: 2.557524483008337

Epoch: 5| Step: 5
Training loss: 2.0408669157472636
Validation loss: 2.623396292278072

Epoch: 5| Step: 6
Training loss: 2.0189353314529694
Validation loss: 2.6225080767414415

Epoch: 5| Step: 7
Training loss: 1.7576441027194158
Validation loss: 2.624744297353637

Epoch: 5| Step: 8
Training loss: 1.8023924002098173
Validation loss: 2.6283631546898856

Epoch: 5| Step: 9
Training loss: 1.8309188751716219
Validation loss: 2.632284786395662

Epoch: 5| Step: 10
Training loss: 2.071669914486529
Validation loss: 2.5951051321283187

Epoch: 216| Step: 0
Training loss: 1.289119233703589
Validation loss: 2.6236414199023104

Epoch: 5| Step: 1
Training loss: 2.0346687304076747
Validation loss: 2.6513128174407847

Epoch: 5| Step: 2
Training loss: 2.0233064704800228
Validation loss: 2.650125523939823

Epoch: 5| Step: 3
Training loss: 2.193296545390739
Validation loss: 2.627502738650149

Epoch: 5| Step: 4
Training loss: 1.5813739682782872
Validation loss: 2.624197524231139

Epoch: 5| Step: 5
Training loss: 1.5704863342934228
Validation loss: 2.621746363377165

Epoch: 5| Step: 6
Training loss: 1.8423553623276407
Validation loss: 2.606407863506038

Epoch: 5| Step: 7
Training loss: 1.874096080332236
Validation loss: 2.6136233188376248

Epoch: 5| Step: 8
Training loss: 1.2238508244907504
Validation loss: 2.6119716163532423

Epoch: 5| Step: 9
Training loss: 2.0005566299229844
Validation loss: 2.5848943960230333

Epoch: 5| Step: 10
Training loss: 1.4225633233696777
Validation loss: 2.5712329971536416

Epoch: 217| Step: 0
Training loss: 1.7803784965615252
Validation loss: 2.5908672336137153

Epoch: 5| Step: 1
Training loss: 2.170932263287979
Validation loss: 2.6448297384112753

Epoch: 5| Step: 2
Training loss: 1.9705275730545393
Validation loss: 2.689002697481482

Epoch: 5| Step: 3
Training loss: 1.8460222886662787
Validation loss: 2.7373404393762772

Epoch: 5| Step: 4
Training loss: 1.9726817516529227
Validation loss: 2.773097126080978

Epoch: 5| Step: 5
Training loss: 1.8210049732356108
Validation loss: 2.7920513500247752

Epoch: 5| Step: 6
Training loss: 1.3992684735143108
Validation loss: 2.8023780246631094

Epoch: 5| Step: 7
Training loss: 1.1662502340334937
Validation loss: 2.7256261791191494

Epoch: 5| Step: 8
Training loss: 1.9136540814063239
Validation loss: 2.7234176964768433

Epoch: 5| Step: 9
Training loss: 1.5969733758473506
Validation loss: 2.641216209223463

Epoch: 5| Step: 10
Training loss: 1.3579793320545168
Validation loss: 2.5928097041154614

Epoch: 218| Step: 0
Training loss: 1.7312589955010123
Validation loss: 2.5379178757300447

Epoch: 5| Step: 1
Training loss: 1.674743615641243
Validation loss: 2.5307659343114812

Epoch: 5| Step: 2
Training loss: 1.8401022565457272
Validation loss: 2.5453888783509835

Epoch: 5| Step: 3
Training loss: 1.9857142577313445
Validation loss: 2.5501935597468752

Epoch: 5| Step: 4
Training loss: 1.5272480576141139
Validation loss: 2.540043757721184

Epoch: 5| Step: 5
Training loss: 1.551506122897892
Validation loss: 2.5848445725980027

Epoch: 5| Step: 6
Training loss: 1.8456702496865476
Validation loss: 2.606122019090933

Epoch: 5| Step: 7
Training loss: 2.039382850942835
Validation loss: 2.5983475058904855

Epoch: 5| Step: 8
Training loss: 1.6727214346188226
Validation loss: 2.5975933172494985

Epoch: 5| Step: 9
Training loss: 1.4390966421709879
Validation loss: 2.6378359073477515

Epoch: 5| Step: 10
Training loss: 1.7710778086331465
Validation loss: 2.663278972286517

Epoch: 219| Step: 0
Training loss: 1.3631963402831064
Validation loss: 2.6506638334526595

Epoch: 5| Step: 1
Training loss: 1.8529368261612118
Validation loss: 2.6171127443346367

Epoch: 5| Step: 2
Training loss: 1.7679598064255393
Validation loss: 2.5940019613902106

Epoch: 5| Step: 3
Training loss: 1.5436681007560362
Validation loss: 2.5592942122645534

Epoch: 5| Step: 4
Training loss: 1.8816956812758998
Validation loss: 2.5531945533931513

Epoch: 5| Step: 5
Training loss: 1.7614412279462142
Validation loss: 2.5472216958704945

Epoch: 5| Step: 6
Training loss: 1.7908677900196754
Validation loss: 2.5579202737054785

Epoch: 5| Step: 7
Training loss: 1.6458850643220797
Validation loss: 2.6030779182456314

Epoch: 5| Step: 8
Training loss: 1.9411896060900369
Validation loss: 2.604500250995708

Epoch: 5| Step: 9
Training loss: 1.554726604947504
Validation loss: 2.675037697193014

Epoch: 5| Step: 10
Training loss: 1.834268403733438
Validation loss: 2.704525232754543

Epoch: 220| Step: 0
Training loss: 1.755500527651541
Validation loss: 2.703912219538998

Epoch: 5| Step: 1
Training loss: 2.048171120788729
Validation loss: 2.691742980077393

Epoch: 5| Step: 2
Training loss: 1.8117886166674069
Validation loss: 2.633845603748705

Epoch: 5| Step: 3
Training loss: 1.959071696532608
Validation loss: 2.620585914672656

Epoch: 5| Step: 4
Training loss: 1.4443635866976163
Validation loss: 2.6061226102941983

Epoch: 5| Step: 5
Training loss: 1.3187059639181802
Validation loss: 2.587189605240247

Epoch: 5| Step: 6
Training loss: 1.395903310397631
Validation loss: 2.597317345348563

Epoch: 5| Step: 7
Training loss: 1.41250845307378
Validation loss: 2.582436312232139

Epoch: 5| Step: 8
Training loss: 1.861606444998725
Validation loss: 2.5879486791964204

Epoch: 5| Step: 9
Training loss: 1.4413541458761023
Validation loss: 2.5831207111147045

Epoch: 5| Step: 10
Training loss: 2.022805487120995
Validation loss: 2.5843417531204973

Epoch: 221| Step: 0
Training loss: 1.4441062223563625
Validation loss: 2.576461349686123

Epoch: 5| Step: 1
Training loss: 1.2854859645141088
Validation loss: 2.56992374625451

Epoch: 5| Step: 2
Training loss: 2.0400838230713636
Validation loss: 2.587283586231439

Epoch: 5| Step: 3
Training loss: 1.4619983758356385
Validation loss: 2.605660100797521

Epoch: 5| Step: 4
Training loss: 1.4088015402544474
Validation loss: 2.6231472305362535

Epoch: 5| Step: 5
Training loss: 1.8541944766012857
Validation loss: 2.6268269724010698

Epoch: 5| Step: 6
Training loss: 1.3691662664910116
Validation loss: 2.6351022389689884

Epoch: 5| Step: 7
Training loss: 1.8932661414088618
Validation loss: 2.679445248418923

Epoch: 5| Step: 8
Training loss: 1.584322553439994
Validation loss: 2.667499288874921

Epoch: 5| Step: 9
Training loss: 1.7421394649435276
Validation loss: 2.6645452523719992

Epoch: 5| Step: 10
Training loss: 1.9594641998283449
Validation loss: 2.617773577092419

Epoch: 222| Step: 0
Training loss: 1.8145088376134584
Validation loss: 2.55689654902529

Epoch: 5| Step: 1
Training loss: 1.6592136714120074
Validation loss: 2.5631458670065417

Epoch: 5| Step: 2
Training loss: 1.6707821420388733
Validation loss: 2.569109283008969

Epoch: 5| Step: 3
Training loss: 1.7031417985840123
Validation loss: 2.5372313645745312

Epoch: 5| Step: 4
Training loss: 1.5069711343928218
Validation loss: 2.5914889375555554

Epoch: 5| Step: 5
Training loss: 1.730228243749049
Validation loss: 2.6008582417892177

Epoch: 5| Step: 6
Training loss: 1.714795366095619
Validation loss: 2.671585139246753

Epoch: 5| Step: 7
Training loss: 1.7348377881913541
Validation loss: 2.6619873047777864

Epoch: 5| Step: 8
Training loss: 1.4129831399282933
Validation loss: 2.6854553113972828

Epoch: 5| Step: 9
Training loss: 1.4523114624045996
Validation loss: 2.679061037193395

Epoch: 5| Step: 10
Training loss: 1.662520217772573
Validation loss: 2.6278213656260276

Epoch: 223| Step: 0
Training loss: 1.2269357975777986
Validation loss: 2.6046261212699995

Epoch: 5| Step: 1
Training loss: 1.7313093980866263
Validation loss: 2.58700711109096

Epoch: 5| Step: 2
Training loss: 1.585153320069141
Validation loss: 2.5424687474763745

Epoch: 5| Step: 3
Training loss: 1.451124393307581
Validation loss: 2.5448454941573537

Epoch: 5| Step: 4
Training loss: 1.2593871501781386
Validation loss: 2.5681316670156717

Epoch: 5| Step: 5
Training loss: 1.554290183973998
Validation loss: 2.6038116534675213

Epoch: 5| Step: 6
Training loss: 1.356028768189252
Validation loss: 2.6575987044162592

Epoch: 5| Step: 7
Training loss: 2.2107831813483796
Validation loss: 2.719946570016421

Epoch: 5| Step: 8
Training loss: 1.6592763925338263
Validation loss: 2.7228360285262907

Epoch: 5| Step: 9
Training loss: 1.9379068378184743
Validation loss: 2.7221002800113867

Epoch: 5| Step: 10
Training loss: 1.7609808279290318
Validation loss: 2.7858665683603823

Epoch: 224| Step: 0
Training loss: 1.6387377101690503
Validation loss: 2.7381590468257437

Epoch: 5| Step: 1
Training loss: 1.6420461403268425
Validation loss: 2.7200300903936045

Epoch: 5| Step: 2
Training loss: 1.537839839562822
Validation loss: 2.6982674005865084

Epoch: 5| Step: 3
Training loss: 1.3955728183392049
Validation loss: 2.6687233617892674

Epoch: 5| Step: 4
Training loss: 1.7982121675251297
Validation loss: 2.6597096641107902

Epoch: 5| Step: 5
Training loss: 1.6144382862855455
Validation loss: 2.647166186672201

Epoch: 5| Step: 6
Training loss: 1.2572317737556087
Validation loss: 2.6049813972769265

Epoch: 5| Step: 7
Training loss: 1.6745824549624355
Validation loss: 2.5977033190333727

Epoch: 5| Step: 8
Training loss: 1.691318148461485
Validation loss: 2.577979793293959

Epoch: 5| Step: 9
Training loss: 1.8455899642889748
Validation loss: 2.576648403410186

Epoch: 5| Step: 10
Training loss: 1.6172051912528709
Validation loss: 2.566839579907943

Epoch: 225| Step: 0
Training loss: 1.6121239748627114
Validation loss: 2.5496205008294983

Epoch: 5| Step: 1
Training loss: 1.4466801126942217
Validation loss: 2.563791947284957

Epoch: 5| Step: 2
Training loss: 1.4243261986239915
Validation loss: 2.56729348932999

Epoch: 5| Step: 3
Training loss: 1.818213435461665
Validation loss: 2.5930030459836657

Epoch: 5| Step: 4
Training loss: 1.4139534502501072
Validation loss: 2.572316269115139

Epoch: 5| Step: 5
Training loss: 1.9363215769768054
Validation loss: 2.6237954326805872

Epoch: 5| Step: 6
Training loss: 1.5152400206234249
Validation loss: 2.6163437633179547

Epoch: 5| Step: 7
Training loss: 1.6185987276659346
Validation loss: 2.657506936105279

Epoch: 5| Step: 8
Training loss: 1.613435530039774
Validation loss: 2.6743184428274382

Epoch: 5| Step: 9
Training loss: 1.6611203255427935
Validation loss: 2.675665656756849

Epoch: 5| Step: 10
Training loss: 1.3492180661374795
Validation loss: 2.630206915482308

Epoch: 226| Step: 0
Training loss: 1.3835887131257354
Validation loss: 2.590616750578475

Epoch: 5| Step: 1
Training loss: 1.5056231322065132
Validation loss: 2.5785934027708826

Epoch: 5| Step: 2
Training loss: 1.1963308148007274
Validation loss: 2.561575624067424

Epoch: 5| Step: 3
Training loss: 1.8515277971967135
Validation loss: 2.557324068038666

Epoch: 5| Step: 4
Training loss: 1.6184289562340861
Validation loss: 2.5737807394046914

Epoch: 5| Step: 5
Training loss: 1.8857383945294584
Validation loss: 2.6037265092230397

Epoch: 5| Step: 6
Training loss: 1.7759803321367944
Validation loss: 2.603692728210775

Epoch: 5| Step: 7
Training loss: 1.2798840754884182
Validation loss: 2.6289597786981433

Epoch: 5| Step: 8
Training loss: 1.2240472260788993
Validation loss: 2.6323149593069433

Epoch: 5| Step: 9
Training loss: 1.8445898180028228
Validation loss: 2.592398484980567

Epoch: 5| Step: 10
Training loss: 1.2961672034899958
Validation loss: 2.6458237343994253

Epoch: 227| Step: 0
Training loss: 1.43087585756315
Validation loss: 2.639048490751396

Epoch: 5| Step: 1
Training loss: 1.0457175389558633
Validation loss: 2.6068865325543853

Epoch: 5| Step: 2
Training loss: 1.6009624566674545
Validation loss: 2.634314287560648

Epoch: 5| Step: 3
Training loss: 1.8391070338636726
Validation loss: 2.6421068876383607

Epoch: 5| Step: 4
Training loss: 1.468602274506626
Validation loss: 2.5804233880015093

Epoch: 5| Step: 5
Training loss: 1.6302473735908092
Validation loss: 2.6125788230915927

Epoch: 5| Step: 6
Training loss: 1.7166264680519903
Validation loss: 2.5901454069993157

Epoch: 5| Step: 7
Training loss: 1.30064803807442
Validation loss: 2.5654790056086827

Epoch: 5| Step: 8
Training loss: 1.712625794071609
Validation loss: 2.570821413043206

Epoch: 5| Step: 9
Training loss: 1.8072598442625338
Validation loss: 2.5915717170029424

Epoch: 5| Step: 10
Training loss: 1.2848038581594254
Validation loss: 2.615200901933104

Epoch: 228| Step: 0
Training loss: 1.248637410416022
Validation loss: 2.657136045724863

Epoch: 5| Step: 1
Training loss: 1.546684099227947
Validation loss: 2.6806780308439224

Epoch: 5| Step: 2
Training loss: 1.4775470498947605
Validation loss: 2.662814708310379

Epoch: 5| Step: 3
Training loss: 1.5123556998279617
Validation loss: 2.709027643555601

Epoch: 5| Step: 4
Training loss: 1.770863686095761
Validation loss: 2.678072455575131

Epoch: 5| Step: 5
Training loss: 1.4603004086412437
Validation loss: 2.6612957683071228

Epoch: 5| Step: 6
Training loss: 1.6698266431635933
Validation loss: 2.6488374381552493

Epoch: 5| Step: 7
Training loss: 1.6424585178658717
Validation loss: 2.6607018916848832

Epoch: 5| Step: 8
Training loss: 1.733591263482613
Validation loss: 2.6522495322452015

Epoch: 5| Step: 9
Training loss: 1.1722863047732353
Validation loss: 2.650669882122445

Epoch: 5| Step: 10
Training loss: 1.4577942351314268
Validation loss: 2.6435504573588755

Epoch: 229| Step: 0
Training loss: 1.7467091817753297
Validation loss: 2.634489436622361

Epoch: 5| Step: 1
Training loss: 1.2955085725636857
Validation loss: 2.641750083634468

Epoch: 5| Step: 2
Training loss: 1.1336420639121703
Validation loss: 2.620621705415206

Epoch: 5| Step: 3
Training loss: 1.8265039804970271
Validation loss: 2.6131704843977968

Epoch: 5| Step: 4
Training loss: 1.8844005804397443
Validation loss: 2.6210101951650637

Epoch: 5| Step: 5
Training loss: 1.513448115391733
Validation loss: 2.6007170762704654

Epoch: 5| Step: 6
Training loss: 1.2876063589959972
Validation loss: 2.6103388766123863

Epoch: 5| Step: 7
Training loss: 1.3903519437360317
Validation loss: 2.6134924173994394

Epoch: 5| Step: 8
Training loss: 1.4759269840302809
Validation loss: 2.613094659227955

Epoch: 5| Step: 9
Training loss: 1.5861932707999151
Validation loss: 2.592755647599854

Epoch: 5| Step: 10
Training loss: 1.1223035392371643
Validation loss: 2.6020291428592457

Epoch: 230| Step: 0
Training loss: 1.607678973378162
Validation loss: 2.6525145196074136

Epoch: 5| Step: 1
Training loss: 1.2543593209070318
Validation loss: 2.674176319647256

Epoch: 5| Step: 2
Training loss: 1.445389534211844
Validation loss: 2.624151556639821

Epoch: 5| Step: 3
Training loss: 1.3770770943750894
Validation loss: 2.6198044989053115

Epoch: 5| Step: 4
Training loss: 1.6411280995965178
Validation loss: 2.591256766073617

Epoch: 5| Step: 5
Training loss: 1.7819799968568666
Validation loss: 2.5762779721946867

Epoch: 5| Step: 6
Training loss: 1.6948296347102674
Validation loss: 2.604092940404625

Epoch: 5| Step: 7
Training loss: 1.2603029982749931
Validation loss: 2.593143753541809

Epoch: 5| Step: 8
Training loss: 1.3800059140120124
Validation loss: 2.574255290963963

Epoch: 5| Step: 9
Training loss: 1.7584777929375153
Validation loss: 2.5731655912302083

Epoch: 5| Step: 10
Training loss: 1.0535872194986429
Validation loss: 2.599113545702894

Epoch: 231| Step: 0
Training loss: 1.9736973196564718
Validation loss: 2.599484070995027

Epoch: 5| Step: 1
Training loss: 1.2001478342546648
Validation loss: 2.606562974221876

Epoch: 5| Step: 2
Training loss: 1.157855697423171
Validation loss: 2.6351363730039155

Epoch: 5| Step: 3
Training loss: 1.312655757562949
Validation loss: 2.5818358929760064

Epoch: 5| Step: 4
Training loss: 1.6044820087502378
Validation loss: 2.6065891645898778

Epoch: 5| Step: 5
Training loss: 1.2042825258125849
Validation loss: 2.633646009345895

Epoch: 5| Step: 6
Training loss: 1.4232025656086793
Validation loss: 2.6102669664895646

Epoch: 5| Step: 7
Training loss: 1.642889077308619
Validation loss: 2.5836512439134576

Epoch: 5| Step: 8
Training loss: 1.633233340115481
Validation loss: 2.6010181483613946

Epoch: 5| Step: 9
Training loss: 1.139230476625639
Validation loss: 2.6087933248715784

Epoch: 5| Step: 10
Training loss: 1.6652248424352933
Validation loss: 2.602708762012328

Epoch: 232| Step: 0
Training loss: 1.1984386081019007
Validation loss: 2.5872959442310863

Epoch: 5| Step: 1
Training loss: 1.2366797262120857
Validation loss: 2.5872663204058584

Epoch: 5| Step: 2
Training loss: 1.2738601825590878
Validation loss: 2.5772199153871327

Epoch: 5| Step: 3
Training loss: 1.875224926490916
Validation loss: 2.6204062922714253

Epoch: 5| Step: 4
Training loss: 1.3537880539410854
Validation loss: 2.638662758792008

Epoch: 5| Step: 5
Training loss: 1.5707489469950582
Validation loss: 2.660394915637188

Epoch: 5| Step: 6
Training loss: 1.851216344224791
Validation loss: 2.6528170131977458

Epoch: 5| Step: 7
Training loss: 1.1830383609217732
Validation loss: 2.6209345664803103

Epoch: 5| Step: 8
Training loss: 1.5551423600706333
Validation loss: 2.6156675977087063

Epoch: 5| Step: 9
Training loss: 1.4250053907593603
Validation loss: 2.5900429749693723

Epoch: 5| Step: 10
Training loss: 1.3854331491202136
Validation loss: 2.553406126762031

Epoch: 233| Step: 0
Training loss: 1.8484595328893771
Validation loss: 2.5563564974459627

Epoch: 5| Step: 1
Training loss: 1.5209725024504714
Validation loss: 2.5552263191222595

Epoch: 5| Step: 2
Training loss: 1.551530325595367
Validation loss: 2.5282028656972133

Epoch: 5| Step: 3
Training loss: 1.3612446697820828
Validation loss: 2.556868245411648

Epoch: 5| Step: 4
Training loss: 1.3616338794236278
Validation loss: 2.60064918129685

Epoch: 5| Step: 5
Training loss: 1.2000365311307313
Validation loss: 2.5842438944508284

Epoch: 5| Step: 6
Training loss: 1.1387828426042708
Validation loss: 2.5631249658875386

Epoch: 5| Step: 7
Training loss: 1.373049305985579
Validation loss: 2.6149404514168975

Epoch: 5| Step: 8
Training loss: 1.3861905663616896
Validation loss: 2.6397191830331304

Epoch: 5| Step: 9
Training loss: 1.3790028135728798
Validation loss: 2.6121733610279225

Epoch: 5| Step: 10
Training loss: 1.6218774578685917
Validation loss: 2.584939507630145

Epoch: 234| Step: 0
Training loss: 1.619599096824901
Validation loss: 2.6070632936878626

Epoch: 5| Step: 1
Training loss: 1.499039501389905
Validation loss: 2.5879056245721666

Epoch: 5| Step: 2
Training loss: 1.3959462656292874
Validation loss: 2.6263488091512106

Epoch: 5| Step: 3
Training loss: 1.6652803218264638
Validation loss: 2.6373646707695912

Epoch: 5| Step: 4
Training loss: 1.234839919213569
Validation loss: 2.6565629807290234

Epoch: 5| Step: 5
Training loss: 1.601104968707265
Validation loss: 2.6536096420282846

Epoch: 5| Step: 6
Training loss: 1.5406863558237558
Validation loss: 2.666942259816815

Epoch: 5| Step: 7
Training loss: 1.502952848160562
Validation loss: 2.644843893100887

Epoch: 5| Step: 8
Training loss: 1.2860231577269838
Validation loss: 2.643938934906777

Epoch: 5| Step: 9
Training loss: 1.424134021442172
Validation loss: 2.5985688783658616

Epoch: 5| Step: 10
Training loss: 0.6375450669982806
Validation loss: 2.610212734266962

Epoch: 235| Step: 0
Training loss: 1.4107707790079542
Validation loss: 2.5912329010421815

Epoch: 5| Step: 1
Training loss: 1.703342808786054
Validation loss: 2.6039555506296015

Epoch: 5| Step: 2
Training loss: 1.419039067467841
Validation loss: 2.6422037535007687

Epoch: 5| Step: 3
Training loss: 1.450907830800352
Validation loss: 2.597623410519656

Epoch: 5| Step: 4
Training loss: 1.457552982630159
Validation loss: 2.585469356858433

Epoch: 5| Step: 5
Training loss: 1.3858401671833884
Validation loss: 2.5995988185882695

Epoch: 5| Step: 6
Training loss: 1.0445003051282584
Validation loss: 2.5693447169807535

Epoch: 5| Step: 7
Training loss: 0.9156779173053491
Validation loss: 2.5317476867766247

Epoch: 5| Step: 8
Training loss: 1.6159144011384516
Validation loss: 2.5230954755406585

Epoch: 5| Step: 9
Training loss: 1.2695778236649367
Validation loss: 2.497374029151082

Epoch: 5| Step: 10
Training loss: 1.710873885692201
Validation loss: 2.5280999976659047

Epoch: 236| Step: 0
Training loss: 1.6585200605585162
Validation loss: 2.5515864042692544

Epoch: 5| Step: 1
Training loss: 1.586483490265002
Validation loss: 2.5759311583372377

Epoch: 5| Step: 2
Training loss: 1.2444075892351578
Validation loss: 2.5691576563646366

Epoch: 5| Step: 3
Training loss: 0.9414743106029657
Validation loss: 2.5461583138554946

Epoch: 5| Step: 4
Training loss: 1.3656037667236494
Validation loss: 2.5306007608985315

Epoch: 5| Step: 5
Training loss: 1.3158969516526644
Validation loss: 2.535275672107001

Epoch: 5| Step: 6
Training loss: 2.0648599474614775
Validation loss: 2.5247127412200516

Epoch: 5| Step: 7
Training loss: 1.1248274246940875
Validation loss: 2.5219994592508526

Epoch: 5| Step: 8
Training loss: 1.4426377574124207
Validation loss: 2.488362990496025

Epoch: 5| Step: 9
Training loss: 1.3322341182747819
Validation loss: 2.5003714849461214

Epoch: 5| Step: 10
Training loss: 0.48106942194909463
Validation loss: 2.503343327766692

Epoch: 237| Step: 0
Training loss: 1.0976023270472501
Validation loss: 2.533905417967132

Epoch: 5| Step: 1
Training loss: 1.7614950304440409
Validation loss: 2.563979376370956

Epoch: 5| Step: 2
Training loss: 1.57860104774103
Validation loss: 2.5814386237849036

Epoch: 5| Step: 3
Training loss: 1.0745376945725031
Validation loss: 2.581188493106226

Epoch: 5| Step: 4
Training loss: 1.5014503143351885
Validation loss: 2.574332135639835

Epoch: 5| Step: 5
Training loss: 1.322429787659513
Validation loss: 2.5512038509618393

Epoch: 5| Step: 6
Training loss: 1.264253320425213
Validation loss: 2.569141906210992

Epoch: 5| Step: 7
Training loss: 1.0738362689106653
Validation loss: 2.585648145287928

Epoch: 5| Step: 8
Training loss: 1.3979899793219357
Validation loss: 2.5997283134939284

Epoch: 5| Step: 9
Training loss: 1.2325719388352112
Validation loss: 2.5997345299786128

Epoch: 5| Step: 10
Training loss: 1.505958088807099
Validation loss: 2.5909936202361625

Epoch: 238| Step: 0
Training loss: 1.580328432304176
Validation loss: 2.5949341697118995

Epoch: 5| Step: 1
Training loss: 1.3169410592679596
Validation loss: 2.5661753267159857

Epoch: 5| Step: 2
Training loss: 1.0563034111829543
Validation loss: 2.528320736339373

Epoch: 5| Step: 3
Training loss: 1.383836614832218
Validation loss: 2.552958038755412

Epoch: 5| Step: 4
Training loss: 1.621591808607794
Validation loss: 2.5348584255998037

Epoch: 5| Step: 5
Training loss: 1.0227990525035027
Validation loss: 2.533965472829524

Epoch: 5| Step: 6
Training loss: 1.2387405650744772
Validation loss: 2.538219606444379

Epoch: 5| Step: 7
Training loss: 1.4774020598557673
Validation loss: 2.564267725054464

Epoch: 5| Step: 8
Training loss: 1.4666666717240304
Validation loss: 2.570592761301776

Epoch: 5| Step: 9
Training loss: 1.2539953277415672
Validation loss: 2.562995524582935

Epoch: 5| Step: 10
Training loss: 1.3109460441665561
Validation loss: 2.5714601423878047

Epoch: 239| Step: 0
Training loss: 1.4755836754408538
Validation loss: 2.57354098301464

Epoch: 5| Step: 1
Training loss: 1.6624908905927007
Validation loss: 2.5616721009641763

Epoch: 5| Step: 2
Training loss: 1.325718753130672
Validation loss: 2.5675815347207505

Epoch: 5| Step: 3
Training loss: 0.9330698243044772
Validation loss: 2.5598027900665885

Epoch: 5| Step: 4
Training loss: 1.3919113724490693
Validation loss: 2.5591756705470203

Epoch: 5| Step: 5
Training loss: 1.0971208128495562
Validation loss: 2.523389205183471

Epoch: 5| Step: 6
Training loss: 1.2409459273110524
Validation loss: 2.5370314493588433

Epoch: 5| Step: 7
Training loss: 1.0668775474191656
Validation loss: 2.488039473467628

Epoch: 5| Step: 8
Training loss: 1.5876021645179192
Validation loss: 2.494878773865496

Epoch: 5| Step: 9
Training loss: 1.2787944709898142
Validation loss: 2.53991076010266

Epoch: 5| Step: 10
Training loss: 1.4644589338291703
Validation loss: 2.5498030426220795

Epoch: 240| Step: 0
Training loss: 1.3912469566017172
Validation loss: 2.5686012384073904

Epoch: 5| Step: 1
Training loss: 1.2873047375060442
Validation loss: 2.607025590030929

Epoch: 5| Step: 2
Training loss: 1.795092619203919
Validation loss: 2.583358357321867

Epoch: 5| Step: 3
Training loss: 1.1840923505510388
Validation loss: 2.610189295949464

Epoch: 5| Step: 4
Training loss: 1.2409545729727607
Validation loss: 2.5552394712561233

Epoch: 5| Step: 5
Training loss: 1.1626170868513557
Validation loss: 2.5945733615900846

Epoch: 5| Step: 6
Training loss: 1.3813070949992223
Validation loss: 2.6028072315135002

Epoch: 5| Step: 7
Training loss: 1.3286243173294403
Validation loss: 2.583629708915373

Epoch: 5| Step: 8
Training loss: 0.7298138380444299
Validation loss: 2.585316897476342

Epoch: 5| Step: 9
Training loss: 1.3214797328559602
Validation loss: 2.574457747705368

Epoch: 5| Step: 10
Training loss: 1.456028815896075
Validation loss: 2.5945372895789167

Epoch: 241| Step: 0
Training loss: 1.425446687925079
Validation loss: 2.506514821149229

Epoch: 5| Step: 1
Training loss: 1.578658438690648
Validation loss: 2.5121708975551513

Epoch: 5| Step: 2
Training loss: 1.0860127484713171
Validation loss: 2.483588332705147

Epoch: 5| Step: 3
Training loss: 1.3415888773637357
Validation loss: 2.494006793345581

Epoch: 5| Step: 4
Training loss: 1.3246762545954902
Validation loss: 2.493851983718058

Epoch: 5| Step: 5
Training loss: 1.180205326239225
Validation loss: 2.520720055669897

Epoch: 5| Step: 6
Training loss: 1.497424298444343
Validation loss: 2.5362493442351455

Epoch: 5| Step: 7
Training loss: 0.5658599060131944
Validation loss: 2.565721864952518

Epoch: 5| Step: 8
Training loss: 1.3026379688284682
Validation loss: 2.5358409562742636

Epoch: 5| Step: 9
Training loss: 1.5716053968496617
Validation loss: 2.559072913520859

Epoch: 5| Step: 10
Training loss: 1.1564117009271917
Validation loss: 2.5553270918954922

Epoch: 242| Step: 0
Training loss: 1.0335184059737157
Validation loss: 2.5945352027285096

Epoch: 5| Step: 1
Training loss: 1.3678540594015687
Validation loss: 2.63400195239361

Epoch: 5| Step: 2
Training loss: 1.4618926164561301
Validation loss: 2.627799733104815

Epoch: 5| Step: 3
Training loss: 1.0442734462232872
Validation loss: 2.6013578145748917

Epoch: 5| Step: 4
Training loss: 1.3059500792573693
Validation loss: 2.539564840825567

Epoch: 5| Step: 5
Training loss: 1.2336776308673452
Validation loss: 2.5094718668299714

Epoch: 5| Step: 6
Training loss: 1.2602117650384772
Validation loss: 2.4863641393428058

Epoch: 5| Step: 7
Training loss: 1.3152687297126253
Validation loss: 2.4746279406903877

Epoch: 5| Step: 8
Training loss: 1.2882257693658656
Validation loss: 2.4657248059985126

Epoch: 5| Step: 9
Training loss: 1.522829844256444
Validation loss: 2.493050983882667

Epoch: 5| Step: 10
Training loss: 1.514933398831816
Validation loss: 2.5446598453650116

Epoch: 243| Step: 0
Training loss: 1.3291548831062605
Validation loss: 2.5712319741830205

Epoch: 5| Step: 1
Training loss: 1.2113082810307727
Validation loss: 2.6473328163238667

Epoch: 5| Step: 2
Training loss: 0.9782564349120055
Validation loss: 2.6970240531031706

Epoch: 5| Step: 3
Training loss: 1.1933045320036557
Validation loss: 2.659752021474894

Epoch: 5| Step: 4
Training loss: 1.308644262449186
Validation loss: 2.6083322619835965

Epoch: 5| Step: 5
Training loss: 1.295100917492482
Validation loss: 2.568688307451642

Epoch: 5| Step: 6
Training loss: 1.2522030490169744
Validation loss: 2.5289321013659705

Epoch: 5| Step: 7
Training loss: 1.255832131952033
Validation loss: 2.5065408244510574

Epoch: 5| Step: 8
Training loss: 1.3143515469666676
Validation loss: 2.5346363608422986

Epoch: 5| Step: 9
Training loss: 1.505140793636942
Validation loss: 2.465373708624506

Epoch: 5| Step: 10
Training loss: 1.620388309540926
Validation loss: 2.472355363800283

Epoch: 244| Step: 0
Training loss: 1.0291870753520846
Validation loss: 2.514528765731472

Epoch: 5| Step: 1
Training loss: 0.988620322943397
Validation loss: 2.503721588627073

Epoch: 5| Step: 2
Training loss: 1.1153606603842763
Validation loss: 2.546367840122797

Epoch: 5| Step: 3
Training loss: 1.2407466281104864
Validation loss: 2.5871302359048562

Epoch: 5| Step: 4
Training loss: 1.288998735180124
Validation loss: 2.5956600888754027

Epoch: 5| Step: 5
Training loss: 1.1483531583579722
Validation loss: 2.595233555722069

Epoch: 5| Step: 6
Training loss: 1.1344225261389975
Validation loss: 2.5835600778928103

Epoch: 5| Step: 7
Training loss: 1.368640498131489
Validation loss: 2.579887850933597

Epoch: 5| Step: 8
Training loss: 1.8721714300905943
Validation loss: 2.5412418596160027

Epoch: 5| Step: 9
Training loss: 1.0971724777909961
Validation loss: 2.5623705031125783

Epoch: 5| Step: 10
Training loss: 1.5909748974107933
Validation loss: 2.5447537418401383

Epoch: 245| Step: 0
Training loss: 1.5010120633356598
Validation loss: 2.5135083933122417

Epoch: 5| Step: 1
Training loss: 1.3682358564318082
Validation loss: 2.48127570907281

Epoch: 5| Step: 2
Training loss: 1.0652800821221098
Validation loss: 2.498468937215243

Epoch: 5| Step: 3
Training loss: 1.3160747710671878
Validation loss: 2.467348252470739

Epoch: 5| Step: 4
Training loss: 1.4131656563607484
Validation loss: 2.509601585454188

Epoch: 5| Step: 5
Training loss: 0.9581956902770323
Validation loss: 2.489667594377219

Epoch: 5| Step: 6
Training loss: 1.220120271007439
Validation loss: 2.5067175884099306

Epoch: 5| Step: 7
Training loss: 1.1062689267710784
Validation loss: 2.541303175606471

Epoch: 5| Step: 8
Training loss: 1.2936746566137143
Validation loss: 2.5258236827277516

Epoch: 5| Step: 9
Training loss: 0.71659835852143
Validation loss: 2.5609836408763047

Epoch: 5| Step: 10
Training loss: 1.8289691899553109
Validation loss: 2.5538710366095922

Epoch: 246| Step: 0
Training loss: 1.1028528974770437
Validation loss: 2.551394742411251

Epoch: 5| Step: 1
Training loss: 1.1991119834267387
Validation loss: 2.4996157309835594

Epoch: 5| Step: 2
Training loss: 1.6047134293315737
Validation loss: 2.5060092158467

Epoch: 5| Step: 3
Training loss: 0.9645324081149457
Validation loss: 2.5262844898025167

Epoch: 5| Step: 4
Training loss: 0.9207202338472898
Validation loss: 2.4823996673424817

Epoch: 5| Step: 5
Training loss: 1.4100195482941558
Validation loss: 2.529043090621111

Epoch: 5| Step: 6
Training loss: 1.3837542586704736
Validation loss: 2.5456205965894503

Epoch: 5| Step: 7
Training loss: 1.182184973564544
Validation loss: 2.579217446005071

Epoch: 5| Step: 8
Training loss: 1.0264440738179677
Validation loss: 2.554525188011165

Epoch: 5| Step: 9
Training loss: 1.5612226987456772
Validation loss: 2.593584413428218

Epoch: 5| Step: 10
Training loss: 1.2421843330774784
Validation loss: 2.58174759415003

Epoch: 247| Step: 0
Training loss: 1.2724674016827846
Validation loss: 2.5723058633083813

Epoch: 5| Step: 1
Training loss: 1.3060194971139352
Validation loss: 2.548670648275423

Epoch: 5| Step: 2
Training loss: 1.4635575407893657
Validation loss: 2.563243002913004

Epoch: 5| Step: 3
Training loss: 1.5880113393921613
Validation loss: 2.576883306761878

Epoch: 5| Step: 4
Training loss: 1.0292679784435537
Validation loss: 2.5596171133791277

Epoch: 5| Step: 5
Training loss: 1.3923271134882742
Validation loss: 2.5839963549056115

Epoch: 5| Step: 6
Training loss: 1.089553302086019
Validation loss: 2.5519664751880846

Epoch: 5| Step: 7
Training loss: 0.9175953856525952
Validation loss: 2.516080030090856

Epoch: 5| Step: 8
Training loss: 1.0222226569329134
Validation loss: 2.51542306694761

Epoch: 5| Step: 9
Training loss: 1.4145565961165865
Validation loss: 2.514866418945341

Epoch: 5| Step: 10
Training loss: 1.0541847443569772
Validation loss: 2.5013401500296704

Epoch: 248| Step: 0
Training loss: 1.5306860994828908
Validation loss: 2.5237583860683745

Epoch: 5| Step: 1
Training loss: 0.8784166795128463
Validation loss: 2.53277305480255

Epoch: 5| Step: 2
Training loss: 1.0380458590790425
Validation loss: 2.5413222739425545

Epoch: 5| Step: 3
Training loss: 1.1618314522907807
Validation loss: 2.54138939137013

Epoch: 5| Step: 4
Training loss: 1.7194885747762358
Validation loss: 2.552025052263808

Epoch: 5| Step: 5
Training loss: 1.0758532486856744
Validation loss: 2.5777116570324763

Epoch: 5| Step: 6
Training loss: 1.2855257471296337
Validation loss: 2.5783709386693316

Epoch: 5| Step: 7
Training loss: 1.029789150007814
Validation loss: 2.613279750043707

Epoch: 5| Step: 8
Training loss: 1.0488007327006652
Validation loss: 2.6023385648348545

Epoch: 5| Step: 9
Training loss: 1.2509030894517086
Validation loss: 2.593525832988858

Epoch: 5| Step: 10
Training loss: 1.3638597807504873
Validation loss: 2.58502106425579

Epoch: 249| Step: 0
Training loss: 1.114628562128412
Validation loss: 2.5514962025541634

Epoch: 5| Step: 1
Training loss: 0.9899337583112664
Validation loss: 2.5315144090739037

Epoch: 5| Step: 2
Training loss: 1.4829472953860985
Validation loss: 2.5480111775760874

Epoch: 5| Step: 3
Training loss: 1.2110615820532031
Validation loss: 2.5674364855908878

Epoch: 5| Step: 4
Training loss: 1.039811058304366
Validation loss: 2.516424627902002

Epoch: 5| Step: 5
Training loss: 1.5345128387878628
Validation loss: 2.5469482112397426

Epoch: 5| Step: 6
Training loss: 1.2717873582941437
Validation loss: 2.507475934556481

Epoch: 5| Step: 7
Training loss: 0.9191225957176277
Validation loss: 2.4959383898585012

Epoch: 5| Step: 8
Training loss: 0.8028835705592642
Validation loss: 2.53061485854849

Epoch: 5| Step: 9
Training loss: 1.6959805205234149
Validation loss: 2.544888518224087

Epoch: 5| Step: 10
Training loss: 1.060996450322979
Validation loss: 2.5446896448222915

Epoch: 250| Step: 0
Training loss: 0.7965909040077792
Validation loss: 2.5758123451941315

Epoch: 5| Step: 1
Training loss: 1.3111997248900091
Validation loss: 2.547818522800609

Epoch: 5| Step: 2
Training loss: 1.1991801302279743
Validation loss: 2.5814334963766346

Epoch: 5| Step: 3
Training loss: 1.03873294967815
Validation loss: 2.5536023345500043

Epoch: 5| Step: 4
Training loss: 0.9491925334057233
Validation loss: 2.5736808470679997

Epoch: 5| Step: 5
Training loss: 1.4794488378034498
Validation loss: 2.588711562149762

Epoch: 5| Step: 6
Training loss: 1.2280619015391043
Validation loss: 2.569448170709573

Epoch: 5| Step: 7
Training loss: 1.475183155520335
Validation loss: 2.4895207798875902

Epoch: 5| Step: 8
Training loss: 0.9303029371442194
Validation loss: 2.487667696906569

Epoch: 5| Step: 9
Training loss: 1.6765917971878495
Validation loss: 2.4723420206469484

Epoch: 5| Step: 10
Training loss: 0.9215173835874092
Validation loss: 2.5003327209810813

Epoch: 251| Step: 0
Training loss: 0.720465478767641
Validation loss: 2.460590603350699

Epoch: 5| Step: 1
Training loss: 1.0185380094923806
Validation loss: 2.5085617334968036

Epoch: 5| Step: 2
Training loss: 1.4919721837506124
Validation loss: 2.5168186210188197

Epoch: 5| Step: 3
Training loss: 1.235949948099869
Validation loss: 2.525751020843003

Epoch: 5| Step: 4
Training loss: 1.5118336399787224
Validation loss: 2.5755793966089846

Epoch: 5| Step: 5
Training loss: 1.0417607201394727
Validation loss: 2.604567807383686

Epoch: 5| Step: 6
Training loss: 1.117395555023152
Validation loss: 2.6047983751228663

Epoch: 5| Step: 7
Training loss: 1.3329359992389045
Validation loss: 2.581747845375615

Epoch: 5| Step: 8
Training loss: 1.4422573481845513
Validation loss: 2.584734699010742

Epoch: 5| Step: 9
Training loss: 0.8382157270807005
Validation loss: 2.5861885948450594

Epoch: 5| Step: 10
Training loss: 1.3207135917386472
Validation loss: 2.563571902828955

Epoch: 252| Step: 0
Training loss: 1.2823877167952908
Validation loss: 2.512382151150389

Epoch: 5| Step: 1
Training loss: 0.4327143953872455
Validation loss: 2.5053564299104862

Epoch: 5| Step: 2
Training loss: 1.2245601175674738
Validation loss: 2.468047656228138

Epoch: 5| Step: 3
Training loss: 0.7904156705548074
Validation loss: 2.4574676349954623

Epoch: 5| Step: 4
Training loss: 1.078567414109366
Validation loss: 2.461068573648336

Epoch: 5| Step: 5
Training loss: 1.2577021769601004
Validation loss: 2.4831098132872382

Epoch: 5| Step: 6
Training loss: 1.0091133888811816
Validation loss: 2.5148825966817485

Epoch: 5| Step: 7
Training loss: 1.9490514159762797
Validation loss: 2.57130170275759

Epoch: 5| Step: 8
Training loss: 1.2392400645615202
Validation loss: 2.5828843025878396

Epoch: 5| Step: 9
Training loss: 1.2789177485690706
Validation loss: 2.613726322284981

Epoch: 5| Step: 10
Training loss: 1.1008973514578735
Validation loss: 2.5966595815377906

Epoch: 253| Step: 0
Training loss: 1.419010672799984
Validation loss: 2.5930807152299016

Epoch: 5| Step: 1
Training loss: 0.957692598987178
Validation loss: 2.561518301753469

Epoch: 5| Step: 2
Training loss: 1.2352892712957486
Validation loss: 2.5378790508797797

Epoch: 5| Step: 3
Training loss: 1.3069502801434916
Validation loss: 2.5555963411456863

Epoch: 5| Step: 4
Training loss: 1.1640082737114095
Validation loss: 2.5228924576808813

Epoch: 5| Step: 5
Training loss: 1.032739026663517
Validation loss: 2.504231425156045

Epoch: 5| Step: 6
Training loss: 1.0510574601760243
Validation loss: 2.470418973133489

Epoch: 5| Step: 7
Training loss: 1.4587983162142484
Validation loss: 2.4885266705003137

Epoch: 5| Step: 8
Training loss: 1.1248081891468547
Validation loss: 2.5219044258635437

Epoch: 5| Step: 9
Training loss: 1.1690636545444264
Validation loss: 2.5358007257052106

Epoch: 5| Step: 10
Training loss: 1.0734915751644993
Validation loss: 2.5250379710803053

Epoch: 254| Step: 0
Training loss: 1.2779978905781275
Validation loss: 2.5609654419500756

Epoch: 5| Step: 1
Training loss: 1.6027446570776693
Validation loss: 2.5569084503059796

Epoch: 5| Step: 2
Training loss: 0.780369300348529
Validation loss: 2.564036337211765

Epoch: 5| Step: 3
Training loss: 1.0061931167541498
Validation loss: 2.5822255587369027

Epoch: 5| Step: 4
Training loss: 1.0588427036238461
Validation loss: 2.539455353262305

Epoch: 5| Step: 5
Training loss: 0.8894516091717053
Validation loss: 2.526989738848608

Epoch: 5| Step: 6
Training loss: 1.1443446401072108
Validation loss: 2.5303398951212297

Epoch: 5| Step: 7
Training loss: 1.7412293540678112
Validation loss: 2.5106985088579146

Epoch: 5| Step: 8
Training loss: 1.1919799424026438
Validation loss: 2.5013447636435675

Epoch: 5| Step: 9
Training loss: 1.0167386331778738
Validation loss: 2.5308898999810574

Epoch: 5| Step: 10
Training loss: 0.9260243607667948
Validation loss: 2.5289481455340237

Epoch: 255| Step: 0
Training loss: 1.7124219751334073
Validation loss: 2.5213529016943563

Epoch: 5| Step: 1
Training loss: 0.9813578552451035
Validation loss: 2.5664853894041633

Epoch: 5| Step: 2
Training loss: 1.4529198942740258
Validation loss: 2.564037621013287

Epoch: 5| Step: 3
Training loss: 0.9252585694050979
Validation loss: 2.607136671768017

Epoch: 5| Step: 4
Training loss: 1.1574998235187437
Validation loss: 2.6049000527324258

Epoch: 5| Step: 5
Training loss: 0.9851170119866995
Validation loss: 2.6091567836093543

Epoch: 5| Step: 6
Training loss: 0.8676627978725795
Validation loss: 2.6053136597465096

Epoch: 5| Step: 7
Training loss: 1.153492603789231
Validation loss: 2.5886463906609527

Epoch: 5| Step: 8
Training loss: 0.9544620203941794
Validation loss: 2.549642188343258

Epoch: 5| Step: 9
Training loss: 1.109959085930457
Validation loss: 2.557187955055815

Epoch: 5| Step: 10
Training loss: 1.3212956937974532
Validation loss: 2.508115379892123

Epoch: 256| Step: 0
Training loss: 0.8425380338239582
Validation loss: 2.496894957029007

Epoch: 5| Step: 1
Training loss: 0.8778809734403605
Validation loss: 2.4751362100299357

Epoch: 5| Step: 2
Training loss: 1.6973088898757842
Validation loss: 2.466052601376472

Epoch: 5| Step: 3
Training loss: 1.2748197297204837
Validation loss: 2.4764874973173274

Epoch: 5| Step: 4
Training loss: 0.9241964884097945
Validation loss: 2.4540858856109553

Epoch: 5| Step: 5
Training loss: 1.1322101438502223
Validation loss: 2.5128355783108836

Epoch: 5| Step: 6
Training loss: 1.0883200874710384
Validation loss: 2.5247399654651614

Epoch: 5| Step: 7
Training loss: 0.9965286203189586
Validation loss: 2.5589703777790724

Epoch: 5| Step: 8
Training loss: 1.2168976817003396
Validation loss: 2.5691867286355157

Epoch: 5| Step: 9
Training loss: 1.3514498625109026
Validation loss: 2.6155152225087512

Epoch: 5| Step: 10
Training loss: 1.1775463960096217
Validation loss: 2.5993137092403233

Epoch: 257| Step: 0
Training loss: 1.1524305925135874
Validation loss: 2.584372570091605

Epoch: 5| Step: 1
Training loss: 0.9403671291376369
Validation loss: 2.560472522194003

Epoch: 5| Step: 2
Training loss: 1.270841280594454
Validation loss: 2.5470926682610076

Epoch: 5| Step: 3
Training loss: 0.9882871906569382
Validation loss: 2.5303705313919598

Epoch: 5| Step: 4
Training loss: 1.3040252192433974
Validation loss: 2.505435418494009

Epoch: 5| Step: 5
Training loss: 1.0053190391074098
Validation loss: 2.5048679446914734

Epoch: 5| Step: 6
Training loss: 0.918583895141666
Validation loss: 2.4518186582584605

Epoch: 5| Step: 7
Training loss: 0.9470180856595045
Validation loss: 2.4885773468011116

Epoch: 5| Step: 8
Training loss: 1.226194387218924
Validation loss: 2.532857844310634

Epoch: 5| Step: 9
Training loss: 1.1629263434468207
Validation loss: 2.5253470403379814

Epoch: 5| Step: 10
Training loss: 1.681584622007736
Validation loss: 2.551809099710178

Epoch: 258| Step: 0
Training loss: 0.8864668433695734
Validation loss: 2.5583244436877246

Epoch: 5| Step: 1
Training loss: 1.6467915493924143
Validation loss: 2.5528408818900403

Epoch: 5| Step: 2
Training loss: 1.4796054708589557
Validation loss: 2.592847364341302

Epoch: 5| Step: 3
Training loss: 0.9068392120703148
Validation loss: 2.58941591819361

Epoch: 5| Step: 4
Training loss: 1.1077508454591851
Validation loss: 2.558163656723529

Epoch: 5| Step: 5
Training loss: 1.1933125238539952
Validation loss: 2.526523547085004

Epoch: 5| Step: 6
Training loss: 0.9468643439672152
Validation loss: 2.553742553763687

Epoch: 5| Step: 7
Training loss: 0.9433374501083461
Validation loss: 2.487559657917853

Epoch: 5| Step: 8
Training loss: 1.3259926676281346
Validation loss: 2.463961169427644

Epoch: 5| Step: 9
Training loss: 1.0770966421420465
Validation loss: 2.490445751763499

Epoch: 5| Step: 10
Training loss: 1.0322777799460754
Validation loss: 2.477543057160203

Epoch: 259| Step: 0
Training loss: 1.6592635323824871
Validation loss: 2.532006211921184

Epoch: 5| Step: 1
Training loss: 1.273333118115818
Validation loss: 2.5025891412225003

Epoch: 5| Step: 2
Training loss: 0.9318003007818303
Validation loss: 2.509745510207928

Epoch: 5| Step: 3
Training loss: 1.2254388120574862
Validation loss: 2.5598713948520144

Epoch: 5| Step: 4
Training loss: 1.0554820141075318
Validation loss: 2.5389579172106735

Epoch: 5| Step: 5
Training loss: 1.2759162789326488
Validation loss: 2.601314756695899

Epoch: 5| Step: 6
Training loss: 1.0651049376891437
Validation loss: 2.5808692196195295

Epoch: 5| Step: 7
Training loss: 1.1038096888507296
Validation loss: 2.5567653635634584

Epoch: 5| Step: 8
Training loss: 0.7238485861458066
Validation loss: 2.537108192764708

Epoch: 5| Step: 9
Training loss: 1.1764497092441892
Validation loss: 2.507968332818883

Epoch: 5| Step: 10
Training loss: 0.9881734072984588
Validation loss: 2.4891139998089136

Epoch: 260| Step: 0
Training loss: 1.405178679239836
Validation loss: 2.519936009237687

Epoch: 5| Step: 1
Training loss: 1.2938744637148512
Validation loss: 2.516903116847692

Epoch: 5| Step: 2
Training loss: 1.1986762195750338
Validation loss: 2.506543114455156

Epoch: 5| Step: 3
Training loss: 1.2134626087201208
Validation loss: 2.5278723090284485

Epoch: 5| Step: 4
Training loss: 1.3559087649235058
Validation loss: 2.525344569428336

Epoch: 5| Step: 5
Training loss: 1.0191714649498171
Validation loss: 2.558389839965124

Epoch: 5| Step: 6
Training loss: 1.0595611993775726
Validation loss: 2.548467270615562

Epoch: 5| Step: 7
Training loss: 1.3722719960617253
Validation loss: 2.540234143042195

Epoch: 5| Step: 8
Training loss: 0.4722240142538936
Validation loss: 2.5146706906704055

Epoch: 5| Step: 9
Training loss: 0.4751772838328717
Validation loss: 2.5547205471994516

Epoch: 5| Step: 10
Training loss: 1.1862061127240973
Validation loss: 2.547411677576565

Epoch: 261| Step: 0
Training loss: 1.1249638127758763
Validation loss: 2.552576102791456

Epoch: 5| Step: 1
Training loss: 1.1135920575941147
Validation loss: 2.5479128260810726

Epoch: 5| Step: 2
Training loss: 1.1236260819560935
Validation loss: 2.5093017701068407

Epoch: 5| Step: 3
Training loss: 0.8360509706295245
Validation loss: 2.4813654848260978

Epoch: 5| Step: 4
Training loss: 1.6137614055203897
Validation loss: 2.4491601896310446

Epoch: 5| Step: 5
Training loss: 1.085354655441427
Validation loss: 2.5132902369614145

Epoch: 5| Step: 6
Training loss: 1.3971985171367247
Validation loss: 2.507897671352878

Epoch: 5| Step: 7
Training loss: 0.9877983994459588
Validation loss: 2.5018189975544547

Epoch: 5| Step: 8
Training loss: 0.6224316037378812
Validation loss: 2.488954905398417

Epoch: 5| Step: 9
Training loss: 1.1085315237935633
Validation loss: 2.4665900330195147

Epoch: 5| Step: 10
Training loss: 1.12134280744588
Validation loss: 2.4768250670622693

Epoch: 262| Step: 0
Training loss: 1.2588874535768937
Validation loss: 2.4701088846319776

Epoch: 5| Step: 1
Training loss: 1.218498839883796
Validation loss: 2.4917293629866144

Epoch: 5| Step: 2
Training loss: 1.2227634955710258
Validation loss: 2.5049728751245506

Epoch: 5| Step: 3
Training loss: 1.0017716687769402
Validation loss: 2.515299559515084

Epoch: 5| Step: 4
Training loss: 1.0974189257383553
Validation loss: 2.5307633157309235

Epoch: 5| Step: 5
Training loss: 1.1106286822823108
Validation loss: 2.512392500559845

Epoch: 5| Step: 6
Training loss: 1.2197391701772844
Validation loss: 2.5125321560208356

Epoch: 5| Step: 7
Training loss: 0.846203169435513
Validation loss: 2.5252506446446055

Epoch: 5| Step: 8
Training loss: 0.7515090622016054
Validation loss: 2.5187358338647146

Epoch: 5| Step: 9
Training loss: 0.8084554876531608
Validation loss: 2.573908182653924

Epoch: 5| Step: 10
Training loss: 1.6261647525056833
Validation loss: 2.5671180707770125

Epoch: 263| Step: 0
Training loss: 0.7473280916960308
Validation loss: 2.545517535090175

Epoch: 5| Step: 1
Training loss: 0.8661265713829819
Validation loss: 2.559921876576687

Epoch: 5| Step: 2
Training loss: 1.3313744231629225
Validation loss: 2.5534441844124447

Epoch: 5| Step: 3
Training loss: 0.45142946692603403
Validation loss: 2.540650649989987

Epoch: 5| Step: 4
Training loss: 1.158448166037914
Validation loss: 2.5493476984025474

Epoch: 5| Step: 5
Training loss: 0.7768157239106293
Validation loss: 2.554561948455436

Epoch: 5| Step: 6
Training loss: 1.148170388227384
Validation loss: 2.5813360746775564

Epoch: 5| Step: 7
Training loss: 1.6371312315857864
Validation loss: 2.5501873441365714

Epoch: 5| Step: 8
Training loss: 1.0748484482505163
Validation loss: 2.544851307772853

Epoch: 5| Step: 9
Training loss: 1.3704327242405268
Validation loss: 2.556481583805416

Epoch: 5| Step: 10
Training loss: 1.1189432286306198
Validation loss: 2.497048033892273

Epoch: 264| Step: 0
Training loss: 1.5834062040860082
Validation loss: 2.506749354036741

Epoch: 5| Step: 1
Training loss: 0.7687069888604503
Validation loss: 2.5295134735075173

Epoch: 5| Step: 2
Training loss: 0.8191853727052739
Validation loss: 2.5294541602437164

Epoch: 5| Step: 3
Training loss: 1.2137280213303858
Validation loss: 2.495087759758167

Epoch: 5| Step: 4
Training loss: 1.1863939253841258
Validation loss: 2.4958931615414954

Epoch: 5| Step: 5
Training loss: 1.1605612821657332
Validation loss: 2.4889356302903414

Epoch: 5| Step: 6
Training loss: 1.030045354826018
Validation loss: 2.4962069562627294

Epoch: 5| Step: 7
Training loss: 0.7932054138300859
Validation loss: 2.5118276716972927

Epoch: 5| Step: 8
Training loss: 1.0729567449300013
Validation loss: 2.513527069458063

Epoch: 5| Step: 9
Training loss: 1.1872699916342864
Validation loss: 2.515801261220234

Epoch: 5| Step: 10
Training loss: 0.9997850127388563
Validation loss: 2.5686542622587543

Epoch: 265| Step: 0
Training loss: 0.3710541955045255
Validation loss: 2.5430196035526342

Epoch: 5| Step: 1
Training loss: 0.8229817513589932
Validation loss: 2.5287289052888187

Epoch: 5| Step: 2
Training loss: 0.951041586723756
Validation loss: 2.5283776822647384

Epoch: 5| Step: 3
Training loss: 1.2532534697549493
Validation loss: 2.5438903919815443

Epoch: 5| Step: 4
Training loss: 1.2496733238597106
Validation loss: 2.5218965658907075

Epoch: 5| Step: 5
Training loss: 0.9502246064142903
Validation loss: 2.4807558730190276

Epoch: 5| Step: 6
Training loss: 0.984608788959656
Validation loss: 2.4867571761256424

Epoch: 5| Step: 7
Training loss: 1.2587105051036414
Validation loss: 2.484253029884012

Epoch: 5| Step: 8
Training loss: 0.8122120126780403
Validation loss: 2.4852630417023547

Epoch: 5| Step: 9
Training loss: 1.1255813791823803
Validation loss: 2.4926917836674543

Epoch: 5| Step: 10
Training loss: 1.7492749210690701
Validation loss: 2.4919174726457674

Epoch: 266| Step: 0
Training loss: 1.2062368402109127
Validation loss: 2.5035024985520846

Epoch: 5| Step: 1
Training loss: 0.8623101481592033
Validation loss: 2.5255716967303714

Epoch: 5| Step: 2
Training loss: 1.1349520242945321
Validation loss: 2.5092938165102603

Epoch: 5| Step: 3
Training loss: 1.037102650766072
Validation loss: 2.512944649768884

Epoch: 5| Step: 4
Training loss: 1.27020466477011
Validation loss: 2.4984522904753987

Epoch: 5| Step: 5
Training loss: 0.8565144875231453
Validation loss: 2.499756653540116

Epoch: 5| Step: 6
Training loss: 1.0809967935251679
Validation loss: 2.522510360910652

Epoch: 5| Step: 7
Training loss: 0.8678591077828295
Validation loss: 2.5791767608870737

Epoch: 5| Step: 8
Training loss: 0.9498029881030127
Validation loss: 2.5653943229354526

Epoch: 5| Step: 9
Training loss: 1.6682827584714572
Validation loss: 2.55313431523264

Epoch: 5| Step: 10
Training loss: 0.5152407861965778
Validation loss: 2.535378069015111

Epoch: 267| Step: 0
Training loss: 0.6968079034296308
Validation loss: 2.527147360935392

Epoch: 5| Step: 1
Training loss: 1.0510505983384621
Validation loss: 2.51676703127098

Epoch: 5| Step: 2
Training loss: 0.9431778000498455
Validation loss: 2.5204794765965874

Epoch: 5| Step: 3
Training loss: 1.0087033851186284
Validation loss: 2.443620297732199

Epoch: 5| Step: 4
Training loss: 0.8068238205047195
Validation loss: 2.450190797709086

Epoch: 5| Step: 5
Training loss: 0.9433713481767191
Validation loss: 2.4918332149781723

Epoch: 5| Step: 6
Training loss: 0.5871939348859971
Validation loss: 2.4762005761322126

Epoch: 5| Step: 7
Training loss: 1.2157272119380813
Validation loss: 2.4970073774874866

Epoch: 5| Step: 8
Training loss: 1.191545922268835
Validation loss: 2.4806296035046387

Epoch: 5| Step: 9
Training loss: 1.6224889427478355
Validation loss: 2.50407121753615

Epoch: 5| Step: 10
Training loss: 1.306079418963072
Validation loss: 2.5093406519506147

Epoch: 268| Step: 0
Training loss: 0.6882529253982355
Validation loss: 2.512860361074568

Epoch: 5| Step: 1
Training loss: 1.7473771330680357
Validation loss: 2.4935191094444162

Epoch: 5| Step: 2
Training loss: 0.9286760871196711
Validation loss: 2.479181659998184

Epoch: 5| Step: 3
Training loss: 0.9735596838819343
Validation loss: 2.5154320458084567

Epoch: 5| Step: 4
Training loss: 1.0584840612134967
Validation loss: 2.501274085711977

Epoch: 5| Step: 5
Training loss: 0.7316132010286187
Validation loss: 2.513380473639135

Epoch: 5| Step: 6
Training loss: 0.6644230032344005
Validation loss: 2.4640970137260574

Epoch: 5| Step: 7
Training loss: 1.2850596382907402
Validation loss: 2.4800593584716046

Epoch: 5| Step: 8
Training loss: 1.1130628405033944
Validation loss: 2.533804879872025

Epoch: 5| Step: 9
Training loss: 0.9101916785159648
Validation loss: 2.516707863769634

Epoch: 5| Step: 10
Training loss: 1.1049319740000574
Validation loss: 2.5834568667638376

Epoch: 269| Step: 0
Training loss: 0.9877264704739129
Validation loss: 2.557689448263178

Epoch: 5| Step: 1
Training loss: 1.4472795452318494
Validation loss: 2.551997389778785

Epoch: 5| Step: 2
Training loss: 0.9031861571622103
Validation loss: 2.5389378756725134

Epoch: 5| Step: 3
Training loss: 1.0087552060320266
Validation loss: 2.5593602473706882

Epoch: 5| Step: 4
Training loss: 0.9848975353875155
Validation loss: 2.526993486930034

Epoch: 5| Step: 5
Training loss: 0.929961284426358
Validation loss: 2.5012865622013805

Epoch: 5| Step: 6
Training loss: 1.086964402999501
Validation loss: 2.5118789117830604

Epoch: 5| Step: 7
Training loss: 1.0130961699857979
Validation loss: 2.5030245389739014

Epoch: 5| Step: 8
Training loss: 0.9298603954950272
Validation loss: 2.49110945637861

Epoch: 5| Step: 9
Training loss: 1.0265755918181856
Validation loss: 2.4975635376832197

Epoch: 5| Step: 10
Training loss: 1.1240534509120117
Validation loss: 2.4888631007385844

Epoch: 270| Step: 0
Training loss: 1.7567132522129183
Validation loss: 2.492147997697601

Epoch: 5| Step: 1
Training loss: 1.107172700813737
Validation loss: 2.498828391907798

Epoch: 5| Step: 2
Training loss: 0.6899373242688761
Validation loss: 2.5102817963988135

Epoch: 5| Step: 3
Training loss: 0.8035422017065444
Validation loss: 2.504039818753623

Epoch: 5| Step: 4
Training loss: 1.221938925239216
Validation loss: 2.4868564040458465

Epoch: 5| Step: 5
Training loss: 0.8000708429440784
Validation loss: 2.4924710009915376

Epoch: 5| Step: 6
Training loss: 0.884661232555989
Validation loss: 2.4761104029400474

Epoch: 5| Step: 7
Training loss: 0.9340557088697581
Validation loss: 2.4677155896294596

Epoch: 5| Step: 8
Training loss: 1.0198701025023178
Validation loss: 2.5126686372641025

Epoch: 5| Step: 9
Training loss: 0.6021719483454419
Validation loss: 2.5501807746532865

Epoch: 5| Step: 10
Training loss: 1.0318791175542943
Validation loss: 2.5254654391498375

Epoch: 271| Step: 0
Training loss: 0.9321935520365698
Validation loss: 2.5380776559349227

Epoch: 5| Step: 1
Training loss: 0.8336388186969536
Validation loss: 2.5447964571773825

Epoch: 5| Step: 2
Training loss: 1.6764042192102455
Validation loss: 2.541299406765111

Epoch: 5| Step: 3
Training loss: 0.9217425752345391
Validation loss: 2.5465663187097514

Epoch: 5| Step: 4
Training loss: 1.0478614600461615
Validation loss: 2.523410383616158

Epoch: 5| Step: 5
Training loss: 0.8681128093064024
Validation loss: 2.5335955643037176

Epoch: 5| Step: 6
Training loss: 0.9763229686707431
Validation loss: 2.5596571478989647

Epoch: 5| Step: 7
Training loss: 0.8387431185080474
Validation loss: 2.5042257035586974

Epoch: 5| Step: 8
Training loss: 0.6475708927096302
Validation loss: 2.5487534051860012

Epoch: 5| Step: 9
Training loss: 1.0837195820483054
Validation loss: 2.5097803544986896

Epoch: 5| Step: 10
Training loss: 1.004878363863604
Validation loss: 2.5158745508089577

Epoch: 272| Step: 0
Training loss: 1.1726984309997497
Validation loss: 2.545575876860792

Epoch: 5| Step: 1
Training loss: 1.0559808783244908
Validation loss: 2.5540252867903295

Epoch: 5| Step: 2
Training loss: 1.016138680473791
Validation loss: 2.5495194029481776

Epoch: 5| Step: 3
Training loss: 0.8445067014840504
Validation loss: 2.548305151961355

Epoch: 5| Step: 4
Training loss: 1.4461543750059593
Validation loss: 2.5550954532574846

Epoch: 5| Step: 5
Training loss: 0.6454900834365632
Validation loss: 2.5486349646580573

Epoch: 5| Step: 6
Training loss: 0.9761025222865319
Validation loss: 2.5185792391649064

Epoch: 5| Step: 7
Training loss: 0.9546802838890953
Validation loss: 2.4911710209397606

Epoch: 5| Step: 8
Training loss: 0.8709007015057685
Validation loss: 2.4708923705759314

Epoch: 5| Step: 9
Training loss: 0.8613193018454874
Validation loss: 2.5301719272787313

Epoch: 5| Step: 10
Training loss: 1.1403342621123111
Validation loss: 2.541869325054307

Epoch: 273| Step: 0
Training loss: 0.9269739507947165
Validation loss: 2.5729795656407766

Epoch: 5| Step: 1
Training loss: 0.7604082229006105
Validation loss: 2.585451736827778

Epoch: 5| Step: 2
Training loss: 0.6384032264804811
Validation loss: 2.6004554220700347

Epoch: 5| Step: 3
Training loss: 1.1243001032296458
Validation loss: 2.5674402100735336

Epoch: 5| Step: 4
Training loss: 1.0776631568531383
Validation loss: 2.53632607491802

Epoch: 5| Step: 5
Training loss: 1.0274886112556532
Validation loss: 2.5345788940356933

Epoch: 5| Step: 6
Training loss: 1.4652788253627766
Validation loss: 2.5538918026613824

Epoch: 5| Step: 7
Training loss: 0.6255865444212562
Validation loss: 2.5184666028698333

Epoch: 5| Step: 8
Training loss: 1.0423766323433175
Validation loss: 2.4940047025544683

Epoch: 5| Step: 9
Training loss: 1.0411370011617052
Validation loss: 2.5068014723455008

Epoch: 5| Step: 10
Training loss: 1.02555982374495
Validation loss: 2.503167884300252

Epoch: 274| Step: 0
Training loss: 0.9616888876771277
Validation loss: 2.5579241273012765

Epoch: 5| Step: 1
Training loss: 1.0336580194515266
Validation loss: 2.5215215317324717

Epoch: 5| Step: 2
Training loss: 1.056977956800043
Validation loss: 2.5458140682168704

Epoch: 5| Step: 3
Training loss: 1.5313054288835786
Validation loss: 2.57447051480365

Epoch: 5| Step: 4
Training loss: 1.0850824516364483
Validation loss: 2.5661577790054864

Epoch: 5| Step: 5
Training loss: 0.6911030336153627
Validation loss: 2.5841248127115954

Epoch: 5| Step: 6
Training loss: 0.8544449624226883
Validation loss: 2.5717846420755435

Epoch: 5| Step: 7
Training loss: 0.6855083139556732
Validation loss: 2.5923002075321815

Epoch: 5| Step: 8
Training loss: 1.0893393822700088
Validation loss: 2.553296579087702

Epoch: 5| Step: 9
Training loss: 0.8505575567299875
Validation loss: 2.512855629344685

Epoch: 5| Step: 10
Training loss: 0.8834835641494716
Validation loss: 2.5417132085058745

Epoch: 275| Step: 0
Training loss: 1.4275040760416338
Validation loss: 2.537304384749869

Epoch: 5| Step: 1
Training loss: 1.1155115641563473
Validation loss: 2.5177236801469136

Epoch: 5| Step: 2
Training loss: 0.7745823719360011
Validation loss: 2.510895930234797

Epoch: 5| Step: 3
Training loss: 0.9184043662320498
Validation loss: 2.5228619231634863

Epoch: 5| Step: 4
Training loss: 0.8977051113233439
Validation loss: 2.5457537108042074

Epoch: 5| Step: 5
Training loss: 1.0738022430287077
Validation loss: 2.541692901736832

Epoch: 5| Step: 6
Training loss: 0.9569244636592941
Validation loss: 2.552968632878847

Epoch: 5| Step: 7
Training loss: 0.7438539368268028
Validation loss: 2.57539910985713

Epoch: 5| Step: 8
Training loss: 0.9529176705414477
Validation loss: 2.5680336708141978

Epoch: 5| Step: 9
Training loss: 1.0487805005845465
Validation loss: 2.587768998603261

Epoch: 5| Step: 10
Training loss: 0.7658768064621729
Validation loss: 2.565797109263018

Epoch: 276| Step: 0
Training loss: 1.5699686461555526
Validation loss: 2.563440893969082

Epoch: 5| Step: 1
Training loss: 1.0892523251224802
Validation loss: 2.554343577833499

Epoch: 5| Step: 2
Training loss: 0.9399239674721573
Validation loss: 2.5075216072553546

Epoch: 5| Step: 3
Training loss: 0.6510912583854793
Validation loss: 2.5034061239762027

Epoch: 5| Step: 4
Training loss: 0.8948304121683004
Validation loss: 2.489809807960743

Epoch: 5| Step: 5
Training loss: 0.8003419741230701
Validation loss: 2.4480518020127406

Epoch: 5| Step: 6
Training loss: 1.0731718753625692
Validation loss: 2.458626360155473

Epoch: 5| Step: 7
Training loss: 0.6269184709044904
Validation loss: 2.478794493590494

Epoch: 5| Step: 8
Training loss: 0.900175685424442
Validation loss: 2.5433637425887845

Epoch: 5| Step: 9
Training loss: 0.7175922190985397
Validation loss: 2.491656392081399

Epoch: 5| Step: 10
Training loss: 1.0728801918619724
Validation loss: 2.517471000998949

Epoch: 277| Step: 0
Training loss: 1.3856225207370712
Validation loss: 2.5037244740657663

Epoch: 5| Step: 1
Training loss: 0.9463666602601
Validation loss: 2.543710300232212

Epoch: 5| Step: 2
Training loss: 0.9489257423060897
Validation loss: 2.5262744880421355

Epoch: 5| Step: 3
Training loss: 0.9693816187108135
Validation loss: 2.518372254618724

Epoch: 5| Step: 4
Training loss: 0.9263300496361527
Validation loss: 2.5213944863030164

Epoch: 5| Step: 5
Training loss: 0.36742892343523964
Validation loss: 2.5449007607445275

Epoch: 5| Step: 6
Training loss: 1.1342847005250016
Validation loss: 2.542173538488841

Epoch: 5| Step: 7
Training loss: 1.1483578297494164
Validation loss: 2.513358760868426

Epoch: 5| Step: 8
Training loss: 0.6684654575259862
Validation loss: 2.547721699403774

Epoch: 5| Step: 9
Training loss: 0.6523780356894049
Validation loss: 2.5624434662231943

Epoch: 5| Step: 10
Training loss: 1.054410601400963
Validation loss: 2.556880879756766

Epoch: 278| Step: 0
Training loss: 0.7187108568230565
Validation loss: 2.5844864972414046

Epoch: 5| Step: 1
Training loss: 0.7938036352343949
Validation loss: 2.568072429105299

Epoch: 5| Step: 2
Training loss: 0.8638198346228959
Validation loss: 2.5525268025402337

Epoch: 5| Step: 3
Training loss: 1.00243135754751
Validation loss: 2.5800024789097304

Epoch: 5| Step: 4
Training loss: 0.8553753109420887
Validation loss: 2.5828592266944477

Epoch: 5| Step: 5
Training loss: 1.704106599204591
Validation loss: 2.5305426290434894

Epoch: 5| Step: 6
Training loss: 0.7026624005510599
Validation loss: 2.5253876770137844

Epoch: 5| Step: 7
Training loss: 0.8017468840845103
Validation loss: 2.5182504570421522

Epoch: 5| Step: 8
Training loss: 1.1240046124244891
Validation loss: 2.5151021112446235

Epoch: 5| Step: 9
Training loss: 0.9074747754103879
Validation loss: 2.506736964564623

Epoch: 5| Step: 10
Training loss: 0.5019357878663278
Validation loss: 2.49527487548623

Epoch: 279| Step: 0
Training loss: 0.8730118507682046
Validation loss: 2.5649068490511353

Epoch: 5| Step: 1
Training loss: 1.0125082463058166
Validation loss: 2.5431402572094206

Epoch: 5| Step: 2
Training loss: 0.8085616837929608
Validation loss: 2.5838913792797187

Epoch: 5| Step: 3
Training loss: 0.6673408367832041
Validation loss: 2.613115560937392

Epoch: 5| Step: 4
Training loss: 0.8875065467485552
Validation loss: 2.5487242124959124

Epoch: 5| Step: 5
Training loss: 1.0790720111373624
Validation loss: 2.5925717149069016

Epoch: 5| Step: 6
Training loss: 1.3889625556270921
Validation loss: 2.5496720361498117

Epoch: 5| Step: 7
Training loss: 0.8952177653364362
Validation loss: 2.546164628912197

Epoch: 5| Step: 8
Training loss: 1.0084068852125634
Validation loss: 2.5144968368688545

Epoch: 5| Step: 9
Training loss: 0.6525128311050279
Validation loss: 2.5262562755222566

Epoch: 5| Step: 10
Training loss: 1.0244752121994323
Validation loss: 2.4828868218298465

Epoch: 280| Step: 0
Training loss: 0.7343487024671491
Validation loss: 2.4745459308998194

Epoch: 5| Step: 1
Training loss: 1.0709710983736376
Validation loss: 2.493513647028843

Epoch: 5| Step: 2
Training loss: 0.7821483025233755
Validation loss: 2.4806827519061736

Epoch: 5| Step: 3
Training loss: 0.9051661751912674
Validation loss: 2.5268922994619545

Epoch: 5| Step: 4
Training loss: 1.0662263711544975
Validation loss: 2.5458424655235

Epoch: 5| Step: 5
Training loss: 0.7806786546066332
Validation loss: 2.563921563358073

Epoch: 5| Step: 6
Training loss: 0.6258610992350747
Validation loss: 2.5542056830486723

Epoch: 5| Step: 7
Training loss: 0.9570212227432289
Validation loss: 2.5577354466302586

Epoch: 5| Step: 8
Training loss: 0.9005541870106266
Validation loss: 2.5549085323944207

Epoch: 5| Step: 9
Training loss: 1.4361355152102102
Validation loss: 2.5542841325656864

Epoch: 5| Step: 10
Training loss: 0.8866422174842618
Validation loss: 2.5395202622897304

Epoch: 281| Step: 0
Training loss: 0.7332761131706579
Validation loss: 2.5546659772446163

Epoch: 5| Step: 1
Training loss: 0.7606418136957569
Validation loss: 2.531978758002484

Epoch: 5| Step: 2
Training loss: 1.1542289184601626
Validation loss: 2.5192231503984175

Epoch: 5| Step: 3
Training loss: 1.5537024976691733
Validation loss: 2.500277486393578

Epoch: 5| Step: 4
Training loss: 0.8447241987074045
Validation loss: 2.5121855660090167

Epoch: 5| Step: 5
Training loss: 0.8967528761814128
Validation loss: 2.533752678822594

Epoch: 5| Step: 6
Training loss: 0.8038962464595268
Validation loss: 2.503549447454203

Epoch: 5| Step: 7
Training loss: 0.9315461244778619
Validation loss: 2.5304521543693386

Epoch: 5| Step: 8
Training loss: 0.8328487696094703
Validation loss: 2.51437059169923

Epoch: 5| Step: 9
Training loss: 0.7941521144172791
Validation loss: 2.496105292085249

Epoch: 5| Step: 10
Training loss: 0.5960119978813984
Validation loss: 2.5194650033195805

Epoch: 282| Step: 0
Training loss: 0.7752661617135808
Validation loss: 2.4990501496471276

Epoch: 5| Step: 1
Training loss: 0.7199954975835108
Validation loss: 2.561559582095431

Epoch: 5| Step: 2
Training loss: 0.8710160840911162
Validation loss: 2.5480563837810704

Epoch: 5| Step: 3
Training loss: 0.9250065262022996
Validation loss: 2.557956289816788

Epoch: 5| Step: 4
Training loss: 0.9429557679301159
Validation loss: 2.5452757262712753

Epoch: 5| Step: 5
Training loss: 0.5277292043798267
Validation loss: 2.5547909823080945

Epoch: 5| Step: 6
Training loss: 0.9541139006426999
Validation loss: 2.541862652378989

Epoch: 5| Step: 7
Training loss: 0.7520598100556903
Validation loss: 2.5114384405158656

Epoch: 5| Step: 8
Training loss: 1.4832033854080706
Validation loss: 2.521362441029737

Epoch: 5| Step: 9
Training loss: 1.356687058725899
Validation loss: 2.5255745627884747

Epoch: 5| Step: 10
Training loss: 0.5440494567780034
Validation loss: 2.4852167974710495

Epoch: 283| Step: 0
Training loss: 0.7553498672629672
Validation loss: 2.558655202240813

Epoch: 5| Step: 1
Training loss: 0.5250278056819436
Validation loss: 2.5210280892756884

Epoch: 5| Step: 2
Training loss: 0.49110070085597846
Validation loss: 2.5440962375481555

Epoch: 5| Step: 3
Training loss: 0.5491091731495822
Validation loss: 2.5474785500360757

Epoch: 5| Step: 4
Training loss: 0.8413201418198659
Validation loss: 2.5199582116454273

Epoch: 5| Step: 5
Training loss: 0.9776435056943709
Validation loss: 2.5644727427075393

Epoch: 5| Step: 6
Training loss: 0.8505703106746579
Validation loss: 2.5250132507281937

Epoch: 5| Step: 7
Training loss: 0.9235318053447853
Validation loss: 2.520015196997751

Epoch: 5| Step: 8
Training loss: 0.9827681247900094
Validation loss: 2.4995628692586402

Epoch: 5| Step: 9
Training loss: 1.4154551692588644
Validation loss: 2.5097565615144677

Epoch: 5| Step: 10
Training loss: 1.324965140046085
Validation loss: 2.4809311219826045

Epoch: 284| Step: 0
Training loss: 0.8011788474402156
Validation loss: 2.5089569736221473

Epoch: 5| Step: 1
Training loss: 0.7502697618443814
Validation loss: 2.502679510722701

Epoch: 5| Step: 2
Training loss: 0.7471309462730789
Validation loss: 2.537506355638565

Epoch: 5| Step: 3
Training loss: 1.1072760053635375
Validation loss: 2.5189230238558262

Epoch: 5| Step: 4
Training loss: 1.0171716504246529
Validation loss: 2.5472012750028945

Epoch: 5| Step: 5
Training loss: 0.6491147836005727
Validation loss: 2.5113034992189913

Epoch: 5| Step: 6
Training loss: 0.9338027209472068
Validation loss: 2.538123019873654

Epoch: 5| Step: 7
Training loss: 1.0377853116152953
Validation loss: 2.5919734852220984

Epoch: 5| Step: 8
Training loss: 0.8365871365111112
Validation loss: 2.550449068233903

Epoch: 5| Step: 9
Training loss: 1.394638869463221
Validation loss: 2.5889004252211056

Epoch: 5| Step: 10
Training loss: 0.6293672802857955
Validation loss: 2.556382124131639

Epoch: 285| Step: 0
Training loss: 0.8953573751604162
Validation loss: 2.616433503867913

Epoch: 5| Step: 1
Training loss: 0.7526876453886372
Validation loss: 2.572092550441498

Epoch: 5| Step: 2
Training loss: 0.7629492186875008
Validation loss: 2.5827795557179987

Epoch: 5| Step: 3
Training loss: 1.00283411865136
Validation loss: 2.5270899703412564

Epoch: 5| Step: 4
Training loss: 0.45108146917673364
Validation loss: 2.5363624704393213

Epoch: 5| Step: 5
Training loss: 0.6414040736209127
Validation loss: 2.4690506454673624

Epoch: 5| Step: 6
Training loss: 0.9109815531264718
Validation loss: 2.4745574439906663

Epoch: 5| Step: 7
Training loss: 0.8357448534155197
Validation loss: 2.4773346148372495

Epoch: 5| Step: 8
Training loss: 1.0696929475030983
Validation loss: 2.529166454507023

Epoch: 5| Step: 9
Training loss: 1.5622673624422676
Validation loss: 2.5136402585586137

Epoch: 5| Step: 10
Training loss: 0.7760424432601286
Validation loss: 2.5130333711996893

Epoch: 286| Step: 0
Training loss: 0.6770859620458974
Validation loss: 2.5696644765764134

Epoch: 5| Step: 1
Training loss: 1.0069556918922824
Validation loss: 2.5573531084269474

Epoch: 5| Step: 2
Training loss: 0.6644240124585562
Validation loss: 2.5622938970142224

Epoch: 5| Step: 3
Training loss: 0.8198782361736309
Validation loss: 2.582723786458136

Epoch: 5| Step: 4
Training loss: 0.8436501408577017
Validation loss: 2.5707264871738653

Epoch: 5| Step: 5
Training loss: 0.6033462237285994
Validation loss: 2.5615406696733785

Epoch: 5| Step: 6
Training loss: 0.6600924353821005
Validation loss: 2.5796299076866953

Epoch: 5| Step: 7
Training loss: 1.4991043913910205
Validation loss: 2.5547159742840915

Epoch: 5| Step: 8
Training loss: 0.8861663711109234
Validation loss: 2.4935872781094206

Epoch: 5| Step: 9
Training loss: 1.1057644505859956
Validation loss: 2.533874231045812

Epoch: 5| Step: 10
Training loss: 0.7928808755526127
Validation loss: 2.5501139077103

Epoch: 287| Step: 0
Training loss: 0.8267384924051688
Validation loss: 2.5550733906229

Epoch: 5| Step: 1
Training loss: 0.9188331267969416
Validation loss: 2.534897031237883

Epoch: 5| Step: 2
Training loss: 0.8407555531940262
Validation loss: 2.5327299433555774

Epoch: 5| Step: 3
Training loss: 1.5560985660028381
Validation loss: 2.5229878887483634

Epoch: 5| Step: 4
Training loss: 0.8233298620415945
Validation loss: 2.561641550323319

Epoch: 5| Step: 5
Training loss: 0.6523656327466292
Validation loss: 2.519062163087133

Epoch: 5| Step: 6
Training loss: 0.9169997274883036
Validation loss: 2.5433691498513555

Epoch: 5| Step: 7
Training loss: 0.6593970272488933
Validation loss: 2.505281126792976

Epoch: 5| Step: 8
Training loss: 0.965030142506068
Validation loss: 2.5630716266035907

Epoch: 5| Step: 9
Training loss: 0.6565134791103924
Validation loss: 2.5634999643909104

Epoch: 5| Step: 10
Training loss: 0.6042062455948342
Validation loss: 2.5475967047015384

Epoch: 288| Step: 0
Training loss: 0.8209148556911945
Validation loss: 2.547337821974701

Epoch: 5| Step: 1
Training loss: 1.0218039718347642
Validation loss: 2.5715576630795267

Epoch: 5| Step: 2
Training loss: 0.5757730946681442
Validation loss: 2.566495644004596

Epoch: 5| Step: 3
Training loss: 0.7150189544592881
Validation loss: 2.5684660025196844

Epoch: 5| Step: 4
Training loss: 1.1631823803227026
Validation loss: 2.547397314612534

Epoch: 5| Step: 5
Training loss: 0.6971111821116249
Validation loss: 2.5560732058699513

Epoch: 5| Step: 6
Training loss: 0.6071257037857121
Validation loss: 2.55740388345381

Epoch: 5| Step: 7
Training loss: 0.5039614270186141
Validation loss: 2.491937785869857

Epoch: 5| Step: 8
Training loss: 0.9351137309339378
Validation loss: 2.507904313774927

Epoch: 5| Step: 9
Training loss: 0.7173197655478935
Validation loss: 2.524172295798665

Epoch: 5| Step: 10
Training loss: 1.5233208244834078
Validation loss: 2.53411723403404

Epoch: 289| Step: 0
Training loss: 0.892907046558312
Validation loss: 2.4889127280625045

Epoch: 5| Step: 1
Training loss: 0.8488443372207811
Validation loss: 2.514567762499085

Epoch: 5| Step: 2
Training loss: 1.1087515785180244
Validation loss: 2.5311443606094914

Epoch: 5| Step: 3
Training loss: 0.6770244034773785
Validation loss: 2.5148407290569423

Epoch: 5| Step: 4
Training loss: 0.7075007444721524
Validation loss: 2.505866927717706

Epoch: 5| Step: 5
Training loss: 1.1563585591259287
Validation loss: 2.5408476097015193

Epoch: 5| Step: 6
Training loss: 0.9503958354263062
Validation loss: 2.545064667642613

Epoch: 5| Step: 7
Training loss: 0.7348928857460811
Validation loss: 2.5628858096267075

Epoch: 5| Step: 8
Training loss: 0.8681657788975229
Validation loss: 2.5564243894502803

Epoch: 5| Step: 9
Training loss: 0.9744453062736106
Validation loss: 2.6172809552921588

Epoch: 5| Step: 10
Training loss: 0.4549824200629488
Validation loss: 2.635889900854828

Epoch: 290| Step: 0
Training loss: 0.6991417272330792
Validation loss: 2.67347227408261

Epoch: 5| Step: 1
Training loss: 0.9113084433695344
Validation loss: 2.595623069968239

Epoch: 5| Step: 2
Training loss: 0.5353753970775071
Validation loss: 2.5802193635196264

Epoch: 5| Step: 3
Training loss: 0.7844099986866443
Validation loss: 2.5920106413110844

Epoch: 5| Step: 4
Training loss: 0.8864974699484518
Validation loss: 2.580335038852684

Epoch: 5| Step: 5
Training loss: 0.8128047151643737
Validation loss: 2.5720804353543847

Epoch: 5| Step: 6
Training loss: 0.9193509024671799
Validation loss: 2.5898973456357686

Epoch: 5| Step: 7
Training loss: 1.1650557408893674
Validation loss: 2.5836761027561566

Epoch: 5| Step: 8
Training loss: 1.3325121506500208
Validation loss: 2.537089941811186

Epoch: 5| Step: 9
Training loss: 0.7541413014890126
Validation loss: 2.525262835166173

Epoch: 5| Step: 10
Training loss: 0.5509806062535775
Validation loss: 2.5088432585030893

Epoch: 291| Step: 0
Training loss: 0.9799240544631055
Validation loss: 2.4686882330116133

Epoch: 5| Step: 1
Training loss: 0.6926274694602852
Validation loss: 2.464751178846737

Epoch: 5| Step: 2
Training loss: 0.7144121211462171
Validation loss: 2.4493045940016773

Epoch: 5| Step: 3
Training loss: 0.9516974217265995
Validation loss: 2.473858852663952

Epoch: 5| Step: 4
Training loss: 0.6162873959753021
Validation loss: 2.456709990234673

Epoch: 5| Step: 5
Training loss: 0.8222386951521878
Validation loss: 2.488749721118735

Epoch: 5| Step: 6
Training loss: 0.9548707202466407
Validation loss: 2.5201045865806635

Epoch: 5| Step: 7
Training loss: 1.4572905854263638
Validation loss: 2.519183084913125

Epoch: 5| Step: 8
Training loss: 0.6890788588885091
Validation loss: 2.5392012747047814

Epoch: 5| Step: 9
Training loss: 0.8396914321813023
Validation loss: 2.546974967818041

Epoch: 5| Step: 10
Training loss: 0.42047079714500357
Validation loss: 2.549443411238818

Epoch: 292| Step: 0
Training loss: 0.6405170628867908
Validation loss: 2.556074037324127

Epoch: 5| Step: 1
Training loss: 1.1317213920447606
Validation loss: 2.5539898872743176

Epoch: 5| Step: 2
Training loss: 0.9309111804449339
Validation loss: 2.5217974658168485

Epoch: 5| Step: 3
Training loss: 0.6252149927389894
Validation loss: 2.521135012308566

Epoch: 5| Step: 4
Training loss: 1.114989405782687
Validation loss: 2.5233303951390944

Epoch: 5| Step: 5
Training loss: 0.8767615026106141
Validation loss: 2.50358745199071

Epoch: 5| Step: 6
Training loss: 0.6097007516567583
Validation loss: 2.4626327444305987

Epoch: 5| Step: 7
Training loss: 0.6288739782547617
Validation loss: 2.5325755106562085

Epoch: 5| Step: 8
Training loss: 0.8780693647469421
Validation loss: 2.5129768171774796

Epoch: 5| Step: 9
Training loss: 0.8073658119525776
Validation loss: 2.5133055874010646

Epoch: 5| Step: 10
Training loss: 0.9164014056793981
Validation loss: 2.5309585895764783

Epoch: 293| Step: 0
Training loss: 0.8372704048871015
Validation loss: 2.5602027946789168

Epoch: 5| Step: 1
Training loss: 0.6334620074220578
Validation loss: 2.550189750764775

Epoch: 5| Step: 2
Training loss: 0.8502556808986287
Validation loss: 2.54511649666834

Epoch: 5| Step: 3
Training loss: 0.7959079109985461
Validation loss: 2.5486572741443454

Epoch: 5| Step: 4
Training loss: 1.2620500064772324
Validation loss: 2.523418720429084

Epoch: 5| Step: 5
Training loss: 1.0603738155338138
Validation loss: 2.5181173610752863

Epoch: 5| Step: 6
Training loss: 0.6429860174147857
Validation loss: 2.4917035919684354

Epoch: 5| Step: 7
Training loss: 0.7904441747334572
Validation loss: 2.4675081223249453

Epoch: 5| Step: 8
Training loss: 0.5050623443569288
Validation loss: 2.461587368290577

Epoch: 5| Step: 9
Training loss: 0.549649936721966
Validation loss: 2.4729887022761834

Epoch: 5| Step: 10
Training loss: 1.0549671508773326
Validation loss: 2.4805355802961966

Epoch: 294| Step: 0
Training loss: 0.608858329643417
Validation loss: 2.514217046142862

Epoch: 5| Step: 1
Training loss: 0.873690681408611
Validation loss: 2.5056130226897984

Epoch: 5| Step: 2
Training loss: 0.9574116476346151
Validation loss: 2.5077995847125965

Epoch: 5| Step: 3
Training loss: 0.7658431462505662
Validation loss: 2.5109529875041896

Epoch: 5| Step: 4
Training loss: 0.6276982713060214
Validation loss: 2.5907104038932847

Epoch: 5| Step: 5
Training loss: 0.7506097063702962
Validation loss: 2.56772620524722

Epoch: 5| Step: 6
Training loss: 0.6621181971319521
Validation loss: 2.5399231467272845

Epoch: 5| Step: 7
Training loss: 0.8219910296788323
Validation loss: 2.548331979299879

Epoch: 5| Step: 8
Training loss: 0.7914325510156627
Validation loss: 2.5041502497304857

Epoch: 5| Step: 9
Training loss: 0.9984931918329026
Validation loss: 2.5006949186993594

Epoch: 5| Step: 10
Training loss: 1.2958953558418755
Validation loss: 2.4992162552685233

Epoch: 295| Step: 0
Training loss: 0.563836258930927
Validation loss: 2.469045193813286

Epoch: 5| Step: 1
Training loss: 1.0170743138029141
Validation loss: 2.464270724872179

Epoch: 5| Step: 2
Training loss: 0.7760089551615404
Validation loss: 2.4917792879172413

Epoch: 5| Step: 3
Training loss: 0.8283234484432613
Validation loss: 2.5157194971399295

Epoch: 5| Step: 4
Training loss: 1.07228202320894
Validation loss: 2.498520228608454

Epoch: 5| Step: 5
Training loss: 0.7921473942523157
Validation loss: 2.53060301849313

Epoch: 5| Step: 6
Training loss: 1.0285304652678056
Validation loss: 2.4813796467881084

Epoch: 5| Step: 7
Training loss: 0.4518336277405781
Validation loss: 2.5241563279165895

Epoch: 5| Step: 8
Training loss: 0.8353328122096505
Validation loss: 2.4986580795271376

Epoch: 5| Step: 9
Training loss: 0.9330227115009282
Validation loss: 2.523153134800048

Epoch: 5| Step: 10
Training loss: 0.6041072180428061
Validation loss: 2.5272876288029553

Epoch: 296| Step: 0
Training loss: 0.8350808219284404
Validation loss: 2.478607523829214

Epoch: 5| Step: 1
Training loss: 0.8601592906652162
Validation loss: 2.5242779299044114

Epoch: 5| Step: 2
Training loss: 0.6058229456364753
Validation loss: 2.491330406021262

Epoch: 5| Step: 3
Training loss: 0.9020305271565382
Validation loss: 2.476374977646385

Epoch: 5| Step: 4
Training loss: 0.6500302481949161
Validation loss: 2.4915593380731766

Epoch: 5| Step: 5
Training loss: 0.638723808766865
Validation loss: 2.4327897168871573

Epoch: 5| Step: 6
Training loss: 1.2860400283006277
Validation loss: 2.4781592855784518

Epoch: 5| Step: 7
Training loss: 0.868028044370632
Validation loss: 2.505893321895911

Epoch: 5| Step: 8
Training loss: 0.6915851296964118
Validation loss: 2.52591025329175

Epoch: 5| Step: 9
Training loss: 0.8532691791814355
Validation loss: 2.503019808110459

Epoch: 5| Step: 10
Training loss: 0.3510084554864223
Validation loss: 2.5134903952961065

Epoch: 297| Step: 0
Training loss: 0.9683065630078843
Validation loss: 2.4765646313953504

Epoch: 5| Step: 1
Training loss: 0.8399416134615268
Validation loss: 2.48817261224172

Epoch: 5| Step: 2
Training loss: 0.8489428130683374
Validation loss: 2.4751921257971166

Epoch: 5| Step: 3
Training loss: 0.29667393249997287
Validation loss: 2.534886409626097

Epoch: 5| Step: 4
Training loss: 0.7448263938294869
Validation loss: 2.4944127015265627

Epoch: 5| Step: 5
Training loss: 0.7781744117827979
Validation loss: 2.5088827206969646

Epoch: 5| Step: 6
Training loss: 0.6664206651959852
Validation loss: 2.518094942891387

Epoch: 5| Step: 7
Training loss: 0.930053190227923
Validation loss: 2.5383438453857674

Epoch: 5| Step: 8
Training loss: 0.8460895457211737
Validation loss: 2.5394128307540234

Epoch: 5| Step: 9
Training loss: 0.9259770504206523
Validation loss: 2.5308900255856646

Epoch: 5| Step: 10
Training loss: 0.6941666537563815
Validation loss: 2.52456427857322

Epoch: 298| Step: 0
Training loss: 0.9643020344670106
Validation loss: 2.534890873691926

Epoch: 5| Step: 1
Training loss: 0.8379237028408564
Validation loss: 2.5184550904836844

Epoch: 5| Step: 2
Training loss: 0.7295388407260224
Validation loss: 2.5517373154112657

Epoch: 5| Step: 3
Training loss: 0.7526381505841447
Validation loss: 2.5605855173417273

Epoch: 5| Step: 4
Training loss: 0.7803579196383603
Validation loss: 2.5645260448525957

Epoch: 5| Step: 5
Training loss: 0.7602394019319288
Validation loss: 2.5388781671369536

Epoch: 5| Step: 6
Training loss: 0.6208614178733486
Validation loss: 2.514813898180261

Epoch: 5| Step: 7
Training loss: 0.8737186177393235
Validation loss: 2.495467131248326

Epoch: 5| Step: 8
Training loss: 1.1178105890877856
Validation loss: 2.491016761145451

Epoch: 5| Step: 9
Training loss: 0.4514264301029167
Validation loss: 2.495788733777742

Epoch: 5| Step: 10
Training loss: 0.6128802841413098
Validation loss: 2.5064491571111422

Epoch: 299| Step: 0
Training loss: 1.040440040624233
Validation loss: 2.5259578792849404

Epoch: 5| Step: 1
Training loss: 0.8359587836007113
Validation loss: 2.5200217881508427

Epoch: 5| Step: 2
Training loss: 0.925128755114186
Validation loss: 2.5047782017200486

Epoch: 5| Step: 3
Training loss: 0.6372479305076593
Validation loss: 2.486203831633088

Epoch: 5| Step: 4
Training loss: 0.397115158648328
Validation loss: 2.49570449330014

Epoch: 5| Step: 5
Training loss: 0.9519557660128432
Validation loss: 2.477714941479197

Epoch: 5| Step: 6
Training loss: 0.7193620812178266
Validation loss: 2.51839909746514

Epoch: 5| Step: 7
Training loss: 1.1650266302937105
Validation loss: 2.5271541799952413

Epoch: 5| Step: 8
Training loss: 0.5784691224607306
Validation loss: 2.5153602777238926

Epoch: 5| Step: 9
Training loss: 0.5923884239647905
Validation loss: 2.553926423079718

Epoch: 5| Step: 10
Training loss: 0.62840407325777
Validation loss: 2.5353836080738548

Epoch: 300| Step: 0
Training loss: 0.818097930880034
Validation loss: 2.5675622423049935

Epoch: 5| Step: 1
Training loss: 0.9827541449223351
Validation loss: 2.481454484557665

Epoch: 5| Step: 2
Training loss: 0.7307573044340396
Validation loss: 2.466270664951932

Epoch: 5| Step: 3
Training loss: 0.8596492676465055
Validation loss: 2.4995080874102484

Epoch: 5| Step: 4
Training loss: 0.6604894440519976
Validation loss: 2.43414579119069

Epoch: 5| Step: 5
Training loss: 0.7958586700427344
Validation loss: 2.4477543435161264

Epoch: 5| Step: 6
Training loss: 0.8185137327739795
Validation loss: 2.4909010689072972

Epoch: 5| Step: 7
Training loss: 0.4600661819470287
Validation loss: 2.4451772644626613

Epoch: 5| Step: 8
Training loss: 0.49646309747729844
Validation loss: 2.4485479706338866

Epoch: 5| Step: 9
Training loss: 1.2270319337987459
Validation loss: 2.5091160335100535

Epoch: 5| Step: 10
Training loss: 0.49949340190099917
Validation loss: 2.5469331476129216

Epoch: 301| Step: 0
Training loss: 0.7689996035020498
Validation loss: 2.6061812430233635

Epoch: 5| Step: 1
Training loss: 0.6458746117556915
Validation loss: 2.518656960096235

Epoch: 5| Step: 2
Training loss: 0.7989076980467278
Validation loss: 2.4828666286726917

Epoch: 5| Step: 3
Training loss: 0.6799076206203805
Validation loss: 2.4504718257549194

Epoch: 5| Step: 4
Training loss: 1.0139337396209256
Validation loss: 2.4369312077092604

Epoch: 5| Step: 5
Training loss: 0.7376586064626478
Validation loss: 2.4186377084603077

Epoch: 5| Step: 6
Training loss: 0.8813715965844765
Validation loss: 2.414521139762521

Epoch: 5| Step: 7
Training loss: 1.0068340430995757
Validation loss: 2.3955832081079214

Epoch: 5| Step: 8
Training loss: 0.6046612430756517
Validation loss: 2.410088677568533

Epoch: 5| Step: 9
Training loss: 0.7599372571845505
Validation loss: 2.4936915153491817

Epoch: 5| Step: 10
Training loss: 0.8457017506506768
Validation loss: 2.507564116955753

Epoch: 302| Step: 0
Training loss: 0.9007797889664539
Validation loss: 2.577623661502218

Epoch: 5| Step: 1
Training loss: 0.535733795378427
Validation loss: 2.5635241691047974

Epoch: 5| Step: 2
Training loss: 0.6749315818797745
Validation loss: 2.561023059427217

Epoch: 5| Step: 3
Training loss: 0.7493585386528296
Validation loss: 2.578506082590082

Epoch: 5| Step: 4
Training loss: 0.8416083317234547
Validation loss: 2.538793427224916

Epoch: 5| Step: 5
Training loss: 0.431613179020396
Validation loss: 2.55805761047229

Epoch: 5| Step: 6
Training loss: 0.7756693841006562
Validation loss: 2.541952151103388

Epoch: 5| Step: 7
Training loss: 1.0312919608162443
Validation loss: 2.5244392985150856

Epoch: 5| Step: 8
Training loss: 0.5965404691469881
Validation loss: 2.4977124916001614

Epoch: 5| Step: 9
Training loss: 0.8371752194610644
Validation loss: 2.4982883613383535

Epoch: 5| Step: 10
Training loss: 1.005806397459537
Validation loss: 2.485437828459149

Epoch: 303| Step: 0
Training loss: 0.7620144001308472
Validation loss: 2.4681408194018593

Epoch: 5| Step: 1
Training loss: 0.5799992054900943
Validation loss: 2.489874587749085

Epoch: 5| Step: 2
Training loss: 1.0822431997119473
Validation loss: 2.4627831052644176

Epoch: 5| Step: 3
Training loss: 0.517620790270536
Validation loss: 2.4476772619791287

Epoch: 5| Step: 4
Training loss: 0.6162382624593568
Validation loss: 2.460407094315211

Epoch: 5| Step: 5
Training loss: 0.9305879095409139
Validation loss: 2.456029694520807

Epoch: 5| Step: 6
Training loss: 0.6415996580516589
Validation loss: 2.4420860281991095

Epoch: 5| Step: 7
Training loss: 0.5584392734151474
Validation loss: 2.4982185589879964

Epoch: 5| Step: 8
Training loss: 0.7344765288599957
Validation loss: 2.536940997926831

Epoch: 5| Step: 9
Training loss: 0.8251893534247668
Validation loss: 2.5704440901599126

Epoch: 5| Step: 10
Training loss: 0.8699298832580005
Validation loss: 2.544740920349388

Epoch: 304| Step: 0
Training loss: 1.2188807686317225
Validation loss: 2.5501506191507493

Epoch: 5| Step: 1
Training loss: 0.7983857214574941
Validation loss: 2.55526429448276

Epoch: 5| Step: 2
Training loss: 0.6515769334836489
Validation loss: 2.498934819325283

Epoch: 5| Step: 3
Training loss: 0.48755092171499825
Validation loss: 2.4564139898317188

Epoch: 5| Step: 4
Training loss: 0.8879921797588457
Validation loss: 2.4463315474100185

Epoch: 5| Step: 5
Training loss: 0.8144051883046975
Validation loss: 2.4441754770979345

Epoch: 5| Step: 6
Training loss: 0.32120958174176184
Validation loss: 2.453766522018647

Epoch: 5| Step: 7
Training loss: 0.7330557966294141
Validation loss: 2.4714146505997037

Epoch: 5| Step: 8
Training loss: 0.898080141066138
Validation loss: 2.498813352651286

Epoch: 5| Step: 9
Training loss: 0.6539036494377681
Validation loss: 2.5247519289714306

Epoch: 5| Step: 10
Training loss: 0.8352219558433351
Validation loss: 2.548500366284562

Epoch: 305| Step: 0
Training loss: 0.7565230578068379
Validation loss: 2.562687105420565

Epoch: 5| Step: 1
Training loss: 0.578618946932968
Validation loss: 2.563668027603996

Epoch: 5| Step: 2
Training loss: 0.8208103667271942
Validation loss: 2.5380338290466904

Epoch: 5| Step: 3
Training loss: 1.1182810626390254
Validation loss: 2.4738611584130243

Epoch: 5| Step: 4
Training loss: 0.5517776350663532
Validation loss: 2.451504651548548

Epoch: 5| Step: 5
Training loss: 0.8196596363260482
Validation loss: 2.4428027528966214

Epoch: 5| Step: 6
Training loss: 0.7823515183825169
Validation loss: 2.4229537789474804

Epoch: 5| Step: 7
Training loss: 0.8710556364060695
Validation loss: 2.4694176141520576

Epoch: 5| Step: 8
Training loss: 0.4605866244361691
Validation loss: 2.4794287463343867

Epoch: 5| Step: 9
Training loss: 0.8882832442423125
Validation loss: 2.5210479757492843

Epoch: 5| Step: 10
Training loss: 0.720773874340612
Validation loss: 2.5674268418517348

Epoch: 306| Step: 0
Training loss: 0.9156324158456086
Validation loss: 2.624780438680407

Epoch: 5| Step: 1
Training loss: 0.6286563732292918
Validation loss: 2.583567410904948

Epoch: 5| Step: 2
Training loss: 0.775161440246959
Validation loss: 2.5994697580706325

Epoch: 5| Step: 3
Training loss: 0.7268267735417997
Validation loss: 2.577357040883415

Epoch: 5| Step: 4
Training loss: 0.9540418998625901
Validation loss: 2.5405411839936196

Epoch: 5| Step: 5
Training loss: 0.570227002567747
Validation loss: 2.5485636582912417

Epoch: 5| Step: 6
Training loss: 0.9164561044281875
Validation loss: 2.493660427938444

Epoch: 5| Step: 7
Training loss: 0.7144615527407308
Validation loss: 2.4674250872965526

Epoch: 5| Step: 8
Training loss: 0.31974153104964465
Validation loss: 2.444980958328906

Epoch: 5| Step: 9
Training loss: 0.5174874568193095
Validation loss: 2.445837402829509

Epoch: 5| Step: 10
Training loss: 1.0856595129523643
Validation loss: 2.455282204012713

Epoch: 307| Step: 0
Training loss: 0.5015628351228254
Validation loss: 2.4251746483206773

Epoch: 5| Step: 1
Training loss: 0.5962611352132673
Validation loss: 2.4533267785011956

Epoch: 5| Step: 2
Training loss: 0.6712628392460332
Validation loss: 2.4780641941103045

Epoch: 5| Step: 3
Training loss: 1.101318602920265
Validation loss: 2.4799352522868485

Epoch: 5| Step: 4
Training loss: 0.6793458013919016
Validation loss: 2.4821354507871853

Epoch: 5| Step: 5
Training loss: 0.8892442809042466
Validation loss: 2.497442227066891

Epoch: 5| Step: 6
Training loss: 0.766572754920016
Validation loss: 2.465829920076367

Epoch: 5| Step: 7
Training loss: 0.29641718448625504
Validation loss: 2.4562183891916907

Epoch: 5| Step: 8
Training loss: 0.7294122327831565
Validation loss: 2.4609486392293687

Epoch: 5| Step: 9
Training loss: 0.8590828485670383
Validation loss: 2.4507825316624214

Epoch: 5| Step: 10
Training loss: 0.8032067016130109
Validation loss: 2.477387795639314

Epoch: 308| Step: 0
Training loss: 0.5225295262458585
Validation loss: 2.4215908840536953

Epoch: 5| Step: 1
Training loss: 0.8166734541072479
Validation loss: 2.4166836347256546

Epoch: 5| Step: 2
Training loss: 0.7913354297820133
Validation loss: 2.456235092023075

Epoch: 5| Step: 3
Training loss: 0.7469987822552091
Validation loss: 2.491724777353441

Epoch: 5| Step: 4
Training loss: 0.8894941947880523
Validation loss: 2.5056602297804207

Epoch: 5| Step: 5
Training loss: 0.6404634132358343
Validation loss: 2.506990832967097

Epoch: 5| Step: 6
Training loss: 0.6315797171305684
Validation loss: 2.5216252354254935

Epoch: 5| Step: 7
Training loss: 0.5598735686614129
Validation loss: 2.480988129556912

Epoch: 5| Step: 8
Training loss: 0.9836496678123132
Validation loss: 2.4275136755626763

Epoch: 5| Step: 9
Training loss: 0.9346294324585339
Validation loss: 2.429612717435322

Epoch: 5| Step: 10
Training loss: 0.4584946474940166
Validation loss: 2.4184880449227677

Epoch: 309| Step: 0
Training loss: 0.60050914242413
Validation loss: 2.44035089442064

Epoch: 5| Step: 1
Training loss: 0.6993874500860777
Validation loss: 2.465567689778543

Epoch: 5| Step: 2
Training loss: 1.050905865508755
Validation loss: 2.499158088885381

Epoch: 5| Step: 3
Training loss: 0.5947177930163438
Validation loss: 2.512582454778327

Epoch: 5| Step: 4
Training loss: 0.6821766142385094
Validation loss: 2.519955126067749

Epoch: 5| Step: 5
Training loss: 0.967120368858669
Validation loss: 2.5151683301405923

Epoch: 5| Step: 6
Training loss: 0.8083220684275965
Validation loss: 2.51415596433907

Epoch: 5| Step: 7
Training loss: 0.9707296509831415
Validation loss: 2.520309675216732

Epoch: 5| Step: 8
Training loss: 0.6601993614430591
Validation loss: 2.480011401502538

Epoch: 5| Step: 9
Training loss: 0.5803597790794444
Validation loss: 2.4615893741384767

Epoch: 5| Step: 10
Training loss: 0.6457051770407857
Validation loss: 2.4266911080184417

Epoch: 310| Step: 0
Training loss: 0.6732657034197388
Validation loss: 2.442250771691918

Epoch: 5| Step: 1
Training loss: 0.8405224209279311
Validation loss: 2.440305153243298

Epoch: 5| Step: 2
Training loss: 0.8464346314351843
Validation loss: 2.471462729778818

Epoch: 5| Step: 3
Training loss: 0.45377324859182794
Validation loss: 2.472999021136768

Epoch: 5| Step: 4
Training loss: 0.6370189403760274
Validation loss: 2.516388361710697

Epoch: 5| Step: 5
Training loss: 0.7253778295256355
Validation loss: 2.521001426959014

Epoch: 5| Step: 6
Training loss: 1.0886091123186585
Validation loss: 2.548287361478448

Epoch: 5| Step: 7
Training loss: 0.5853092640361144
Validation loss: 2.541228319276995

Epoch: 5| Step: 8
Training loss: 0.8199417002817712
Validation loss: 2.5449433572655917

Epoch: 5| Step: 9
Training loss: 0.5819638104378942
Validation loss: 2.4833519742755668

Epoch: 5| Step: 10
Training loss: 0.6128740842105529
Validation loss: 2.4683201785499147

Epoch: 311| Step: 0
Training loss: 0.6897317253213818
Validation loss: 2.457711220500183

Epoch: 5| Step: 1
Training loss: 0.7406100726333488
Validation loss: 2.4336992179478374

Epoch: 5| Step: 2
Training loss: 0.6078289176861419
Validation loss: 2.454980851931143

Epoch: 5| Step: 3
Training loss: 0.7955687044638815
Validation loss: 2.461063955886068

Epoch: 5| Step: 4
Training loss: 0.7752055756881151
Validation loss: 2.489014363894426

Epoch: 5| Step: 5
Training loss: 0.6068276691149717
Validation loss: 2.4945549035724564

Epoch: 5| Step: 6
Training loss: 0.8468704096821045
Validation loss: 2.5238983882425745

Epoch: 5| Step: 7
Training loss: 0.5101212470531872
Validation loss: 2.533241716902229

Epoch: 5| Step: 8
Training loss: 0.7408828511833374
Validation loss: 2.5131736301287164

Epoch: 5| Step: 9
Training loss: 0.5688247610568226
Validation loss: 2.49141003222708

Epoch: 5| Step: 10
Training loss: 0.7910953434463417
Validation loss: 2.520502257024031

Epoch: 312| Step: 0
Training loss: 0.9167826680276046
Validation loss: 2.5040604892279537

Epoch: 5| Step: 1
Training loss: 0.530195676606307
Validation loss: 2.4945066107074525

Epoch: 5| Step: 2
Training loss: 0.6791233922671479
Validation loss: 2.506605880106251

Epoch: 5| Step: 3
Training loss: 0.6775820338284795
Validation loss: 2.4891287480057933

Epoch: 5| Step: 4
Training loss: 0.2732889862012458
Validation loss: 2.524302639176972

Epoch: 5| Step: 5
Training loss: 0.80277554668643
Validation loss: 2.523353020801236

Epoch: 5| Step: 6
Training loss: 0.8215168422753296
Validation loss: 2.483045977230868

Epoch: 5| Step: 7
Training loss: 0.7221376775097916
Validation loss: 2.476111563567003

Epoch: 5| Step: 8
Training loss: 0.528569865914837
Validation loss: 2.475515467046115

Epoch: 5| Step: 9
Training loss: 0.8231638082568052
Validation loss: 2.4650722517551062

Epoch: 5| Step: 10
Training loss: 0.6474214889913729
Validation loss: 2.4130865839648

Epoch: 313| Step: 0
Training loss: 0.767614582156931
Validation loss: 2.447310865256576

Epoch: 5| Step: 1
Training loss: 0.5915813494226907
Validation loss: 2.4444551694503582

Epoch: 5| Step: 2
Training loss: 0.6538719961293916
Validation loss: 2.454326052672776

Epoch: 5| Step: 3
Training loss: 0.6148034175842964
Validation loss: 2.434131457632659

Epoch: 5| Step: 4
Training loss: 0.5585272155831151
Validation loss: 2.4238978464288463

Epoch: 5| Step: 5
Training loss: 0.8622280963826512
Validation loss: 2.4397245121318325

Epoch: 5| Step: 6
Training loss: 0.7441068626614359
Validation loss: 2.456350574648577

Epoch: 5| Step: 7
Training loss: 0.42654909664796653
Validation loss: 2.4688218130848525

Epoch: 5| Step: 8
Training loss: 0.6650036369668846
Validation loss: 2.4461221946325646

Epoch: 5| Step: 9
Training loss: 0.7853908283290678
Validation loss: 2.4708851617629004

Epoch: 5| Step: 10
Training loss: 0.8941522653337808
Validation loss: 2.4561098759488273

Epoch: 314| Step: 0
Training loss: 0.4499598816366563
Validation loss: 2.43578075634577

Epoch: 5| Step: 1
Training loss: 0.877550325336258
Validation loss: 2.40765538516977

Epoch: 5| Step: 2
Training loss: 0.42437956134777427
Validation loss: 2.441248407195928

Epoch: 5| Step: 3
Training loss: 0.8457471734748718
Validation loss: 2.424472142710719

Epoch: 5| Step: 4
Training loss: 0.6247369689589881
Validation loss: 2.414048038169477

Epoch: 5| Step: 5
Training loss: 0.6375172061094163
Validation loss: 2.4463478204950153

Epoch: 5| Step: 6
Training loss: 0.6609321413657115
Validation loss: 2.4289176340325547

Epoch: 5| Step: 7
Training loss: 0.8960290554542476
Validation loss: 2.468783106178872

Epoch: 5| Step: 8
Training loss: 0.9383056675563033
Validation loss: 2.462362105420657

Epoch: 5| Step: 9
Training loss: 0.5064758315124118
Validation loss: 2.5359866682085

Epoch: 5| Step: 10
Training loss: 0.8062456840577046
Validation loss: 2.5204518116840315

Epoch: 315| Step: 0
Training loss: 0.6823426050482723
Validation loss: 2.4979923801048263

Epoch: 5| Step: 1
Training loss: 0.44545838827327244
Validation loss: 2.4801469822341193

Epoch: 5| Step: 2
Training loss: 0.7452732387734204
Validation loss: 2.456260890749201

Epoch: 5| Step: 3
Training loss: 0.5548475330151842
Validation loss: 2.464114494424638

Epoch: 5| Step: 4
Training loss: 0.8935664608706105
Validation loss: 2.5046269944689317

Epoch: 5| Step: 5
Training loss: 0.7816673689827547
Validation loss: 2.501475886033936

Epoch: 5| Step: 6
Training loss: 0.3823575216041632
Validation loss: 2.5126112404195644

Epoch: 5| Step: 7
Training loss: 0.7752758488877306
Validation loss: 2.4812332712753653

Epoch: 5| Step: 8
Training loss: 0.9263548542756384
Validation loss: 2.521805674280416

Epoch: 5| Step: 9
Training loss: 0.5949878838852224
Validation loss: 2.4943534046009024

Epoch: 5| Step: 10
Training loss: 0.5861811576310614
Validation loss: 2.4786322653588755

Epoch: 316| Step: 0
Training loss: 0.712056798453563
Validation loss: 2.4646421092954456

Epoch: 5| Step: 1
Training loss: 0.8478814454382722
Validation loss: 2.4622923825173837

Epoch: 5| Step: 2
Training loss: 0.6326130211160897
Validation loss: 2.4752782051886135

Epoch: 5| Step: 3
Training loss: 0.4286134995803051
Validation loss: 2.4476433487273774

Epoch: 5| Step: 4
Training loss: 0.6650007015597436
Validation loss: 2.443465566089506

Epoch: 5| Step: 5
Training loss: 0.7713309992664513
Validation loss: 2.5027959509241695

Epoch: 5| Step: 6
Training loss: 0.7694084340569577
Validation loss: 2.5069397373780395

Epoch: 5| Step: 7
Training loss: 0.5784206150090362
Validation loss: 2.527440630840918

Epoch: 5| Step: 8
Training loss: 0.7978151049274453
Validation loss: 2.532304238136896

Epoch: 5| Step: 9
Training loss: 0.6507791269549376
Validation loss: 2.499743212565991

Epoch: 5| Step: 10
Training loss: 0.482208807221694
Validation loss: 2.4606381668059893

Epoch: 317| Step: 0
Training loss: 0.9183331354790651
Validation loss: 2.469161004350373

Epoch: 5| Step: 1
Training loss: 0.6906555540135616
Validation loss: 2.446904367465986

Epoch: 5| Step: 2
Training loss: 0.7567868715193953
Validation loss: 2.437240466869525

Epoch: 5| Step: 3
Training loss: 0.4038256234541519
Validation loss: 2.376210056646377

Epoch: 5| Step: 4
Training loss: 0.5545135010227139
Validation loss: 2.392128828704477

Epoch: 5| Step: 5
Training loss: 0.6116609733647466
Validation loss: 2.3972789952252884

Epoch: 5| Step: 6
Training loss: 0.6217073013160406
Validation loss: 2.4024006301011434

Epoch: 5| Step: 7
Training loss: 0.5081479358540713
Validation loss: 2.406824662054242

Epoch: 5| Step: 8
Training loss: 0.49558410598489816
Validation loss: 2.408791437815043

Epoch: 5| Step: 9
Training loss: 0.8794133736616144
Validation loss: 2.469170065911367

Epoch: 5| Step: 10
Training loss: 0.7402279735278324
Validation loss: 2.39742591343951

Epoch: 318| Step: 0
Training loss: 0.5042116289608237
Validation loss: 2.468200237640056

Epoch: 5| Step: 1
Training loss: 0.6331902306742287
Validation loss: 2.464308008771535

Epoch: 5| Step: 2
Training loss: 0.8987766786629301
Validation loss: 2.4292394560422137

Epoch: 5| Step: 3
Training loss: 0.6411309454083123
Validation loss: 2.4672569660550283

Epoch: 5| Step: 4
Training loss: 0.8728849871098372
Validation loss: 2.41669833431634

Epoch: 5| Step: 5
Training loss: 0.532686647111245
Validation loss: 2.424497804653465

Epoch: 5| Step: 6
Training loss: 0.4142086562830246
Validation loss: 2.4216805773341874

Epoch: 5| Step: 7
Training loss: 0.5022276487603523
Validation loss: 2.434498373620126

Epoch: 5| Step: 8
Training loss: 0.7049546913034705
Validation loss: 2.4357006072076968

Epoch: 5| Step: 9
Training loss: 0.5885373230720408
Validation loss: 2.4290971769858114

Epoch: 5| Step: 10
Training loss: 0.7389151460560163
Validation loss: 2.4495060676253213

Epoch: 319| Step: 0
Training loss: 0.563233056830754
Validation loss: 2.4591916260433457

Epoch: 5| Step: 1
Training loss: 0.6260478772084368
Validation loss: 2.424627982831682

Epoch: 5| Step: 2
Training loss: 0.6825390117450723
Validation loss: 2.4728763831409637

Epoch: 5| Step: 3
Training loss: 0.5630221063091934
Validation loss: 2.4758465403148113

Epoch: 5| Step: 4
Training loss: 0.49857338395420364
Validation loss: 2.4491320676792725

Epoch: 5| Step: 5
Training loss: 0.7354887369591434
Validation loss: 2.477779742603298

Epoch: 5| Step: 6
Training loss: 0.837654169325903
Validation loss: 2.4896624138906813

Epoch: 5| Step: 7
Training loss: 0.5153439651793226
Validation loss: 2.4589757488370854

Epoch: 5| Step: 8
Training loss: 0.536726437087447
Validation loss: 2.4751114066232973

Epoch: 5| Step: 9
Training loss: 0.864789275647997
Validation loss: 2.479779897079616

Epoch: 5| Step: 10
Training loss: 0.6942561408222231
Validation loss: 2.4718478273704605

Epoch: 320| Step: 0
Training loss: 0.6875639798998261
Validation loss: 2.495634642306314

Epoch: 5| Step: 1
Training loss: 0.5198724816388135
Validation loss: 2.4859962222193253

Epoch: 5| Step: 2
Training loss: 0.5808480031401697
Validation loss: 2.478683754171618

Epoch: 5| Step: 3
Training loss: 0.6763100291771839
Validation loss: 2.4355810545739796

Epoch: 5| Step: 4
Training loss: 0.634426789448228
Validation loss: 2.447717381422686

Epoch: 5| Step: 5
Training loss: 0.3970948954270218
Validation loss: 2.442074969320301

Epoch: 5| Step: 6
Training loss: 0.48179626054076663
Validation loss: 2.493027357729452

Epoch: 5| Step: 7
Training loss: 0.5765359794906139
Validation loss: 2.4586137021135226

Epoch: 5| Step: 8
Training loss: 0.7359519017586121
Validation loss: 2.4579245681287603

Epoch: 5| Step: 9
Training loss: 0.8265836514685377
Validation loss: 2.4652451267263045

Epoch: 5| Step: 10
Training loss: 0.8387614173510032
Validation loss: 2.4636317955550977

Epoch: 321| Step: 0
Training loss: 0.8656888504441917
Validation loss: 2.4968419750694553

Epoch: 5| Step: 1
Training loss: 0.5606548457882126
Validation loss: 2.497173339749069

Epoch: 5| Step: 2
Training loss: 0.47137378068724267
Validation loss: 2.505816891114219

Epoch: 5| Step: 3
Training loss: 0.47745814349681753
Validation loss: 2.428332428866954

Epoch: 5| Step: 4
Training loss: 0.7343492706336763
Validation loss: 2.4494456856797004

Epoch: 5| Step: 5
Training loss: 0.41428959215162664
Validation loss: 2.4395054596535672

Epoch: 5| Step: 6
Training loss: 0.7746095735258232
Validation loss: 2.4826007667316814

Epoch: 5| Step: 7
Training loss: 0.33353741056159925
Validation loss: 2.450173482388652

Epoch: 5| Step: 8
Training loss: 0.7210640765828649
Validation loss: 2.492542104933295

Epoch: 5| Step: 9
Training loss: 0.5807541013647546
Validation loss: 2.466029714040608

Epoch: 5| Step: 10
Training loss: 0.7952883388843851
Validation loss: 2.4611716163480644

Epoch: 322| Step: 0
Training loss: 0.6465277066647875
Validation loss: 2.4682826114675587

Epoch: 5| Step: 1
Training loss: 0.5508951651005272
Validation loss: 2.4886764320995995

Epoch: 5| Step: 2
Training loss: 0.7054072745100316
Validation loss: 2.469452568616137

Epoch: 5| Step: 3
Training loss: 0.582246215857153
Validation loss: 2.468967779649302

Epoch: 5| Step: 4
Training loss: 0.5643239120899453
Validation loss: 2.4544433756847055

Epoch: 5| Step: 5
Training loss: 0.6235634984779527
Validation loss: 2.4824830049299575

Epoch: 5| Step: 6
Training loss: 0.589618715723032
Validation loss: 2.44631372113951

Epoch: 5| Step: 7
Training loss: 0.7728013784654932
Validation loss: 2.4084372464568524

Epoch: 5| Step: 8
Training loss: 0.7280311916973679
Validation loss: 2.416178370385391

Epoch: 5| Step: 9
Training loss: 0.42089417139002255
Validation loss: 2.403941078697173

Epoch: 5| Step: 10
Training loss: 0.6272397678417946
Validation loss: 2.417446533270882

Epoch: 323| Step: 0
Training loss: 0.6799013086535571
Validation loss: 2.4316398975436955

Epoch: 5| Step: 1
Training loss: 0.468001308168311
Validation loss: 2.436966477180769

Epoch: 5| Step: 2
Training loss: 0.6136168272508085
Validation loss: 2.422364073403975

Epoch: 5| Step: 3
Training loss: 0.287092273228772
Validation loss: 2.463316722025526

Epoch: 5| Step: 4
Training loss: 0.6098499647875003
Validation loss: 2.480989805592221

Epoch: 5| Step: 5
Training loss: 0.5365073419301419
Validation loss: 2.458758361417823

Epoch: 5| Step: 6
Training loss: 0.6421492052378226
Validation loss: 2.4557535314733925

Epoch: 5| Step: 7
Training loss: 0.9151619713636823
Validation loss: 2.4370794383073133

Epoch: 5| Step: 8
Training loss: 0.7788708126841429
Validation loss: 2.442070667319458

Epoch: 5| Step: 9
Training loss: 0.5950246730865892
Validation loss: 2.4468300576664435

Epoch: 5| Step: 10
Training loss: 0.49268240494146
Validation loss: 2.429526306382708

Epoch: 324| Step: 0
Training loss: 0.3821181403265965
Validation loss: 2.4148324010263584

Epoch: 5| Step: 1
Training loss: 0.3075969749955189
Validation loss: 2.39144077975792

Epoch: 5| Step: 2
Training loss: 0.7673744921622776
Validation loss: 2.4439694541919614

Epoch: 5| Step: 3
Training loss: 0.3926266692404497
Validation loss: 2.3942900906934987

Epoch: 5| Step: 4
Training loss: 0.45133244353095847
Validation loss: 2.436505609440077

Epoch: 5| Step: 5
Training loss: 0.7520657541716131
Validation loss: 2.4302297508769644

Epoch: 5| Step: 6
Training loss: 0.8284972451854298
Validation loss: 2.4399381758780203

Epoch: 5| Step: 7
Training loss: 0.7692378690281919
Validation loss: 2.4764394535795247

Epoch: 5| Step: 8
Training loss: 0.7315459035810215
Validation loss: 2.4794764984785655

Epoch: 5| Step: 9
Training loss: 0.6579369705848886
Validation loss: 2.431425947417358

Epoch: 5| Step: 10
Training loss: 0.5917504925067046
Validation loss: 2.4409842534735535

Epoch: 325| Step: 0
Training loss: 0.681880766532144
Validation loss: 2.4248484046642025

Epoch: 5| Step: 1
Training loss: 0.5927494804656778
Validation loss: 2.389721746901058

Epoch: 5| Step: 2
Training loss: 0.6264826830779145
Validation loss: 2.3706813746327744

Epoch: 5| Step: 3
Training loss: 0.4446259275420828
Validation loss: 2.390827170138433

Epoch: 5| Step: 4
Training loss: 0.2861481620134645
Validation loss: 2.423207137688324

Epoch: 5| Step: 5
Training loss: 0.32826623828741136
Validation loss: 2.428792046131631

Epoch: 5| Step: 6
Training loss: 0.7605589424355423
Validation loss: 2.4194021662318117

Epoch: 5| Step: 7
Training loss: 0.585095525425016
Validation loss: 2.4695058745189367

Epoch: 5| Step: 8
Training loss: 0.6650537161536055
Validation loss: 2.498282684621315

Epoch: 5| Step: 9
Training loss: 0.8822979060241035
Validation loss: 2.4715180596135737

Epoch: 5| Step: 10
Training loss: 0.5762938030996634
Validation loss: 2.456640713743951

Epoch: 326| Step: 0
Training loss: 0.6965904279187014
Validation loss: 2.4629340580321766

Epoch: 5| Step: 1
Training loss: 0.4367723032918052
Validation loss: 2.4666450039398202

Epoch: 5| Step: 2
Training loss: 0.6917409356202007
Validation loss: 2.4448993575900473

Epoch: 5| Step: 3
Training loss: 0.31960460315201505
Validation loss: 2.4564618366215534

Epoch: 5| Step: 4
Training loss: 0.6593248899682282
Validation loss: 2.433712223097564

Epoch: 5| Step: 5
Training loss: 0.8075748972216122
Validation loss: 2.39990654989038

Epoch: 5| Step: 6
Training loss: 0.6675450726982484
Validation loss: 2.392042179247894

Epoch: 5| Step: 7
Training loss: 0.6290840939995439
Validation loss: 2.422438356928405

Epoch: 5| Step: 8
Training loss: 0.44506564743714017
Validation loss: 2.422834027456992

Epoch: 5| Step: 9
Training loss: 0.7957816008951465
Validation loss: 2.404582363731359

Epoch: 5| Step: 10
Training loss: 0.5463685824441261
Validation loss: 2.4159205939590302

Epoch: 327| Step: 0
Training loss: 0.3688027788635226
Validation loss: 2.462368490146031

Epoch: 5| Step: 1
Training loss: 0.6797462525680071
Validation loss: 2.4636506853868196

Epoch: 5| Step: 2
Training loss: 0.7333293531772223
Validation loss: 2.43874755687695

Epoch: 5| Step: 3
Training loss: 0.6475893241437661
Validation loss: 2.4407531216424783

Epoch: 5| Step: 4
Training loss: 0.7046256687417611
Validation loss: 2.4623241689307154

Epoch: 5| Step: 5
Training loss: 0.7833921437473124
Validation loss: 2.4127844833021013

Epoch: 5| Step: 6
Training loss: 0.32606349217953245
Validation loss: 2.409605081457844

Epoch: 5| Step: 7
Training loss: 0.5385704835846934
Validation loss: 2.441810539652095

Epoch: 5| Step: 8
Training loss: 0.40733464039521566
Validation loss: 2.427923343838997

Epoch: 5| Step: 9
Training loss: 0.7186506451476393
Validation loss: 2.43034729408623

Epoch: 5| Step: 10
Training loss: 0.6977043588076502
Validation loss: 2.4358786719518966

Epoch: 328| Step: 0
Training loss: 0.4371625757099922
Validation loss: 2.4661573932626824

Epoch: 5| Step: 1
Training loss: 0.6724741504267449
Validation loss: 2.462986511506625

Epoch: 5| Step: 2
Training loss: 0.8849713757837445
Validation loss: 2.468752521323052

Epoch: 5| Step: 3
Training loss: 0.6712729395777342
Validation loss: 2.4610771169544443

Epoch: 5| Step: 4
Training loss: 0.6682709573555593
Validation loss: 2.491026380632211

Epoch: 5| Step: 5
Training loss: 0.4147617266183093
Validation loss: 2.483370966508133

Epoch: 5| Step: 6
Training loss: 0.6145508375035976
Validation loss: 2.4564570724397226

Epoch: 5| Step: 7
Training loss: 0.5415600127588421
Validation loss: 2.465180338250597

Epoch: 5| Step: 8
Training loss: 0.7874668341419241
Validation loss: 2.465077393960529

Epoch: 5| Step: 9
Training loss: 0.35354005086406304
Validation loss: 2.4291835653108143

Epoch: 5| Step: 10
Training loss: 0.44545188194833923
Validation loss: 2.4597507853353004

Epoch: 329| Step: 0
Training loss: 0.7546906022981494
Validation loss: 2.466875397035845

Epoch: 5| Step: 1
Training loss: 0.37838571718663017
Validation loss: 2.502670983949332

Epoch: 5| Step: 2
Training loss: 0.5770945773997453
Validation loss: 2.462948446717368

Epoch: 5| Step: 3
Training loss: 0.6632504603200639
Validation loss: 2.480948241235734

Epoch: 5| Step: 4
Training loss: 0.41363184503774847
Validation loss: 2.4928972414874133

Epoch: 5| Step: 5
Training loss: 0.5814464626742959
Validation loss: 2.4177345505580514

Epoch: 5| Step: 6
Training loss: 0.6093669548481723
Validation loss: 2.4164996218489456

Epoch: 5| Step: 7
Training loss: 0.6258260513251117
Validation loss: 2.4498153556254505

Epoch: 5| Step: 8
Training loss: 0.6382135969375247
Validation loss: 2.3954207993888663

Epoch: 5| Step: 9
Training loss: 0.3276898018463096
Validation loss: 2.4220150296115714

Epoch: 5| Step: 10
Training loss: 0.9153516758550905
Validation loss: 2.4326491751357877

Epoch: 330| Step: 0
Training loss: 0.683065788201791
Validation loss: 2.466942686510308

Epoch: 5| Step: 1
Training loss: 0.5623606933178078
Validation loss: 2.4332705621409456

Epoch: 5| Step: 2
Training loss: 0.3304984785014636
Validation loss: 2.4680926931690697

Epoch: 5| Step: 3
Training loss: 0.4709160983785885
Validation loss: 2.4657746705426677

Epoch: 5| Step: 4
Training loss: 0.5174837710190061
Validation loss: 2.468435528873251

Epoch: 5| Step: 5
Training loss: 0.635849318143001
Validation loss: 2.4157274314255734

Epoch: 5| Step: 6
Training loss: 0.7073674535434752
Validation loss: 2.4083822897779177

Epoch: 5| Step: 7
Training loss: 0.6824705432990731
Validation loss: 2.436810553463873

Epoch: 5| Step: 8
Training loss: 0.6594722296454825
Validation loss: 2.4489954937785248

Epoch: 5| Step: 9
Training loss: 0.6557102708666903
Validation loss: 2.399816231887318

Epoch: 5| Step: 10
Training loss: 0.5990358523639245
Validation loss: 2.4429701917012134

Epoch: 331| Step: 0
Training loss: 0.7825730374408789
Validation loss: 2.439580168053446

Epoch: 5| Step: 1
Training loss: 0.6471300387143052
Validation loss: 2.40524000288056

Epoch: 5| Step: 2
Training loss: 0.5599601945183584
Validation loss: 2.414848732973103

Epoch: 5| Step: 3
Training loss: 0.5890229937917735
Validation loss: 2.468452447104394

Epoch: 5| Step: 4
Training loss: 0.3565164782406105
Validation loss: 2.490718969895878

Epoch: 5| Step: 5
Training loss: 0.7357769833593145
Validation loss: 2.503863095101402

Epoch: 5| Step: 6
Training loss: 0.6575996054419613
Validation loss: 2.460519443987694

Epoch: 5| Step: 7
Training loss: 0.5745976294504136
Validation loss: 2.458709685555251

Epoch: 5| Step: 8
Training loss: 0.5724547142125239
Validation loss: 2.4590232747196445

Epoch: 5| Step: 9
Training loss: 0.5652380900336702
Validation loss: 2.4613309041518563

Epoch: 5| Step: 10
Training loss: 0.32900202573135207
Validation loss: 2.455094264404697

Epoch: 332| Step: 0
Training loss: 0.4858140028019085
Validation loss: 2.470061189065369

Epoch: 5| Step: 1
Training loss: 0.6287843100285307
Validation loss: 2.441447349284438

Epoch: 5| Step: 2
Training loss: 0.642399957415887
Validation loss: 2.468472908765918

Epoch: 5| Step: 3
Training loss: 0.6263454736812348
Validation loss: 2.4790784207076593

Epoch: 5| Step: 4
Training loss: 0.5756779768316285
Validation loss: 2.414782869454674

Epoch: 5| Step: 5
Training loss: 0.5041868921694503
Validation loss: 2.415296202753239

Epoch: 5| Step: 6
Training loss: 0.6198461465907037
Validation loss: 2.4105456315863623

Epoch: 5| Step: 7
Training loss: 0.6322007931468083
Validation loss: 2.386828390137125

Epoch: 5| Step: 8
Training loss: 0.4642905140722988
Validation loss: 2.4181459354571753

Epoch: 5| Step: 9
Training loss: 0.603754113738141
Validation loss: 2.4264962239139867

Epoch: 5| Step: 10
Training loss: 0.5831518203029892
Validation loss: 2.4566176218419558

Epoch: 333| Step: 0
Training loss: 0.5972688204553223
Validation loss: 2.4447677830158394

Epoch: 5| Step: 1
Training loss: 0.7717814971877712
Validation loss: 2.4741131026987295

Epoch: 5| Step: 2
Training loss: 0.5359198141933414
Validation loss: 2.485979202696326

Epoch: 5| Step: 3
Training loss: 0.505349804710863
Validation loss: 2.4932359250530167

Epoch: 5| Step: 4
Training loss: 0.7064532029837373
Validation loss: 2.472324275634619

Epoch: 5| Step: 5
Training loss: 0.5989254707498584
Validation loss: 2.4836420520849374

Epoch: 5| Step: 6
Training loss: 0.5020121973805189
Validation loss: 2.5418605827971725

Epoch: 5| Step: 7
Training loss: 0.5030374652227149
Validation loss: 2.4960877262797494

Epoch: 5| Step: 8
Training loss: 0.6444342800367377
Validation loss: 2.426644298002889

Epoch: 5| Step: 9
Training loss: 0.4361152874320746
Validation loss: 2.4419814542073026

Epoch: 5| Step: 10
Training loss: 0.47361319589793044
Validation loss: 2.4083857897389995

Epoch: 334| Step: 0
Training loss: 0.46627978490544714
Validation loss: 2.4221228666883916

Epoch: 5| Step: 1
Training loss: 0.6892919162821353
Validation loss: 2.3701956886746873

Epoch: 5| Step: 2
Training loss: 0.5730475594088076
Validation loss: 2.4083687699595555

Epoch: 5| Step: 3
Training loss: 0.47604762858936134
Validation loss: 2.4257666139044045

Epoch: 5| Step: 4
Training loss: 0.6157601668013746
Validation loss: 2.3868410083759146

Epoch: 5| Step: 5
Training loss: 0.4238014388582504
Validation loss: 2.4167250642803455

Epoch: 5| Step: 6
Training loss: 0.6790590779288059
Validation loss: 2.375887151350088

Epoch: 5| Step: 7
Training loss: 0.6225287456463036
Validation loss: 2.4159901000403887

Epoch: 5| Step: 8
Training loss: 0.6350678414051738
Validation loss: 2.396150340276263

Epoch: 5| Step: 9
Training loss: 0.36917077804210646
Validation loss: 2.39028553352422

Epoch: 5| Step: 10
Training loss: 0.5837718615226485
Validation loss: 2.38807051777112

Epoch: 335| Step: 0
Training loss: 0.6989399444692881
Validation loss: 2.4160720495368113

Epoch: 5| Step: 1
Training loss: 0.526910080788281
Validation loss: 2.3824992756206047

Epoch: 5| Step: 2
Training loss: 0.5806253594191048
Validation loss: 2.4008699052757363

Epoch: 5| Step: 3
Training loss: 0.6680441027518977
Validation loss: 2.3919004785294913

Epoch: 5| Step: 4
Training loss: 0.49126056397705603
Validation loss: 2.412523501153822

Epoch: 5| Step: 5
Training loss: 0.7815622087346159
Validation loss: 2.398511033505698

Epoch: 5| Step: 6
Training loss: 0.4431345701596571
Validation loss: 2.4178570579721272

Epoch: 5| Step: 7
Training loss: 0.5274309156928787
Validation loss: 2.4206526694821

Epoch: 5| Step: 8
Training loss: 0.4409442103826288
Validation loss: 2.4240613592158313

Epoch: 5| Step: 9
Training loss: 0.3911899105826024
Validation loss: 2.455222992617007

Epoch: 5| Step: 10
Training loss: 0.6062503568903865
Validation loss: 2.455653035266278

Epoch: 336| Step: 0
Training loss: 0.31116672050924776
Validation loss: 2.4335704141249637

Epoch: 5| Step: 1
Training loss: 0.3248757060499397
Validation loss: 2.4484129284632763

Epoch: 5| Step: 2
Training loss: 0.7997010551636482
Validation loss: 2.471967520775949

Epoch: 5| Step: 3
Training loss: 0.5205359818098694
Validation loss: 2.466810072513615

Epoch: 5| Step: 4
Training loss: 0.671837694773629
Validation loss: 2.4479589733970304

Epoch: 5| Step: 5
Training loss: 0.4300527753990321
Validation loss: 2.4985418928211702

Epoch: 5| Step: 6
Training loss: 0.5681171228683158
Validation loss: 2.4954318775227375

Epoch: 5| Step: 7
Training loss: 0.792463357661947
Validation loss: 2.493548019025608

Epoch: 5| Step: 8
Training loss: 0.5579062011834967
Validation loss: 2.4632771355681595

Epoch: 5| Step: 9
Training loss: 0.5632654650800457
Validation loss: 2.441301259923286

Epoch: 5| Step: 10
Training loss: 0.35920730078107455
Validation loss: 2.413647719148622

Epoch: 337| Step: 0
Training loss: 0.42439627471878905
Validation loss: 2.4030407963888565

Epoch: 5| Step: 1
Training loss: 0.6993382527615036
Validation loss: 2.4032229995731793

Epoch: 5| Step: 2
Training loss: 0.5332090216789186
Validation loss: 2.385140531228073

Epoch: 5| Step: 3
Training loss: 0.7021263235798552
Validation loss: 2.3673566364349155

Epoch: 5| Step: 4
Training loss: 0.29517396674793966
Validation loss: 2.3438563420497873

Epoch: 5| Step: 5
Training loss: 0.6517782444161945
Validation loss: 2.371788953780311

Epoch: 5| Step: 6
Training loss: 0.5418191444534324
Validation loss: 2.403875883601686

Epoch: 5| Step: 7
Training loss: 0.4554650785844554
Validation loss: 2.4373877415076457

Epoch: 5| Step: 8
Training loss: 0.7489983704909563
Validation loss: 2.4710100752330533

Epoch: 5| Step: 9
Training loss: 0.5232009922739996
Validation loss: 2.4384068536732717

Epoch: 5| Step: 10
Training loss: 0.42356572620277133
Validation loss: 2.4474313527607934

Epoch: 338| Step: 0
Training loss: 0.599859477515397
Validation loss: 2.4838784221318373

Epoch: 5| Step: 1
Training loss: 0.44011020280058155
Validation loss: 2.4401823813064185

Epoch: 5| Step: 2
Training loss: 0.36279855469707045
Validation loss: 2.452804321873943

Epoch: 5| Step: 3
Training loss: 0.6461631230262143
Validation loss: 2.410157608321963

Epoch: 5| Step: 4
Training loss: 0.48893812627312166
Validation loss: 2.411150515572871

Epoch: 5| Step: 5
Training loss: 0.6415464241105963
Validation loss: 2.4062635977778624

Epoch: 5| Step: 6
Training loss: 0.4944753154199914
Validation loss: 2.3909773513652373

Epoch: 5| Step: 7
Training loss: 0.5739550082138679
Validation loss: 2.433943723358793

Epoch: 5| Step: 8
Training loss: 0.5920934909492418
Validation loss: 2.389183476834717

Epoch: 5| Step: 9
Training loss: 0.14201884117937746
Validation loss: 2.4265345055404444

Epoch: 5| Step: 10
Training loss: 0.8178876732811139
Validation loss: 2.404431802930415

Epoch: 339| Step: 0
Training loss: 0.29290473238552767
Validation loss: 2.427516103481799

Epoch: 5| Step: 1
Training loss: 0.5083919447060369
Validation loss: 2.42199746099161

Epoch: 5| Step: 2
Training loss: 0.7226004914088602
Validation loss: 2.4034701248143375

Epoch: 5| Step: 3
Training loss: 0.679176116265241
Validation loss: 2.4105061665149687

Epoch: 5| Step: 4
Training loss: 0.5552404361005958
Validation loss: 2.3776232998737

Epoch: 5| Step: 5
Training loss: 0.5550295352809431
Validation loss: 2.4196657793817313

Epoch: 5| Step: 6
Training loss: 0.39790005058361116
Validation loss: 2.41490033648536

Epoch: 5| Step: 7
Training loss: 0.5684856785704057
Validation loss: 2.453188654273148

Epoch: 5| Step: 8
Training loss: 0.7019069718019681
Validation loss: 2.4320551722212786

Epoch: 5| Step: 9
Training loss: 0.3962941018541347
Validation loss: 2.4630552285673755

Epoch: 5| Step: 10
Training loss: 0.44978984521718196
Validation loss: 2.4243376713394595

Epoch: 340| Step: 0
Training loss: 0.3610087245999067
Validation loss: 2.453564225903687

Epoch: 5| Step: 1
Training loss: 0.5259990643413185
Validation loss: 2.4679400942010066

Epoch: 5| Step: 2
Training loss: 0.31392026261402634
Validation loss: 2.475366157169856

Epoch: 5| Step: 3
Training loss: 0.5832794936629104
Validation loss: 2.428083980812102

Epoch: 5| Step: 4
Training loss: 0.5722334400279045
Validation loss: 2.4554914215579036

Epoch: 5| Step: 5
Training loss: 0.5235197088107626
Validation loss: 2.415133501948436

Epoch: 5| Step: 6
Training loss: 0.7566828615987427
Validation loss: 2.3932113924421703

Epoch: 5| Step: 7
Training loss: 0.5551747344719271
Validation loss: 2.3868403778951888

Epoch: 5| Step: 8
Training loss: 0.5401469669531962
Validation loss: 2.4249689626869424

Epoch: 5| Step: 9
Training loss: 0.603600727488305
Validation loss: 2.431221548816005

Epoch: 5| Step: 10
Training loss: 0.4763669097261452
Validation loss: 2.430797595401708

Epoch: 341| Step: 0
Training loss: 0.29909429975034046
Validation loss: 2.414363557838668

Epoch: 5| Step: 1
Training loss: 0.7643804750534942
Validation loss: 2.4486700828596337

Epoch: 5| Step: 2
Training loss: 0.5694155236656135
Validation loss: 2.4720985161884825

Epoch: 5| Step: 3
Training loss: 0.7108040988391772
Validation loss: 2.470749922067664

Epoch: 5| Step: 4
Training loss: 0.5011469084778964
Validation loss: 2.4844012035583054

Epoch: 5| Step: 5
Training loss: 0.3834199950832291
Validation loss: 2.421270803611546

Epoch: 5| Step: 6
Training loss: 0.3566359754679207
Validation loss: 2.430856813804082

Epoch: 5| Step: 7
Training loss: 0.3924408857816475
Validation loss: 2.4559465887397263

Epoch: 5| Step: 8
Training loss: 0.6358876098633317
Validation loss: 2.4185434869338835

Epoch: 5| Step: 9
Training loss: 0.43083383064253616
Validation loss: 2.4194295285772314

Epoch: 5| Step: 10
Training loss: 0.664142917924815
Validation loss: 2.4434986156306264

Epoch: 342| Step: 0
Training loss: 0.44306092152722637
Validation loss: 2.403316710224902

Epoch: 5| Step: 1
Training loss: 0.40819825164952245
Validation loss: 2.4171082882027695

Epoch: 5| Step: 2
Training loss: 0.5563425972835584
Validation loss: 2.4267107153668235

Epoch: 5| Step: 3
Training loss: 0.6298000547468998
Validation loss: 2.441533502228002

Epoch: 5| Step: 4
Training loss: 0.4060696605070407
Validation loss: 2.453486587632066

Epoch: 5| Step: 5
Training loss: 0.4014959569634831
Validation loss: 2.4374434162447547

Epoch: 5| Step: 6
Training loss: 0.5623522140489192
Validation loss: 2.427190769195536

Epoch: 5| Step: 7
Training loss: 0.5459747807002259
Validation loss: 2.4303371274651115

Epoch: 5| Step: 8
Training loss: 0.6773780963641798
Validation loss: 2.433495948938569

Epoch: 5| Step: 9
Training loss: 0.5247060009328388
Validation loss: 2.4363320326122735

Epoch: 5| Step: 10
Training loss: 0.6038409100281015
Validation loss: 2.4264183196680404

Epoch: 343| Step: 0
Training loss: 0.6474325136415611
Validation loss: 2.4269355103249173

Epoch: 5| Step: 1
Training loss: 0.31822576234851907
Validation loss: 2.447983775444066

Epoch: 5| Step: 2
Training loss: 0.7029489296762073
Validation loss: 2.447930257458858

Epoch: 5| Step: 3
Training loss: 0.33350313103820306
Validation loss: 2.440437984235376

Epoch: 5| Step: 4
Training loss: 0.728561849891783
Validation loss: 2.4328605160746495

Epoch: 5| Step: 5
Training loss: 0.6261091404340108
Validation loss: 2.4442811680995358

Epoch: 5| Step: 6
Training loss: 0.47120337594596695
Validation loss: 2.436841002160603

Epoch: 5| Step: 7
Training loss: 0.23155559857698038
Validation loss: 2.4394691702095175

Epoch: 5| Step: 8
Training loss: 0.400936517513555
Validation loss: 2.4340151951873414

Epoch: 5| Step: 9
Training loss: 0.5997761050351307
Validation loss: 2.401350114772849

Epoch: 5| Step: 10
Training loss: 0.46991982717218456
Validation loss: 2.41511533659768

Epoch: 344| Step: 0
Training loss: 0.3813063517338839
Validation loss: 2.407972642103551

Epoch: 5| Step: 1
Training loss: 0.41314621073049157
Validation loss: 2.406127378942877

Epoch: 5| Step: 2
Training loss: 0.5778528810278598
Validation loss: 2.381977048209269

Epoch: 5| Step: 3
Training loss: 0.46775373445240354
Validation loss: 2.4199198197828475

Epoch: 5| Step: 4
Training loss: 0.7380563302523181
Validation loss: 2.3959853951098764

Epoch: 5| Step: 5
Training loss: 0.5539571762885838
Validation loss: 2.379185109262491

Epoch: 5| Step: 6
Training loss: 0.47525705484394426
Validation loss: 2.4039864000469766

Epoch: 5| Step: 7
Training loss: 0.4112859517763408
Validation loss: 2.43837263748498

Epoch: 5| Step: 8
Training loss: 0.6051396121361078
Validation loss: 2.4465722383362625

Epoch: 5| Step: 9
Training loss: 0.5580963107314707
Validation loss: 2.4116050391916484

Epoch: 5| Step: 10
Training loss: 0.4964625121914715
Validation loss: 2.3911759708555493

Epoch: 345| Step: 0
Training loss: 0.36455004630945914
Validation loss: 2.4315715546889596

Epoch: 5| Step: 1
Training loss: 0.5128926215383539
Validation loss: 2.441060023543137

Epoch: 5| Step: 2
Training loss: 0.36332044082408016
Validation loss: 2.476564504070667

Epoch: 5| Step: 3
Training loss: 0.5112964838902697
Validation loss: 2.418723011918235

Epoch: 5| Step: 4
Training loss: 0.6311355317072493
Validation loss: 2.408730122510564

Epoch: 5| Step: 5
Training loss: 0.36249872240301784
Validation loss: 2.4172869997529314

Epoch: 5| Step: 6
Training loss: 0.2513030485355375
Validation loss: 2.402439677699866

Epoch: 5| Step: 7
Training loss: 0.8051901793479386
Validation loss: 2.3884025890615868

Epoch: 5| Step: 8
Training loss: 0.5335588770539298
Validation loss: 2.4040765203269623

Epoch: 5| Step: 9
Training loss: 0.5086024668894354
Validation loss: 2.399770099471081

Epoch: 5| Step: 10
Training loss: 0.6762411063379796
Validation loss: 2.416654598077237

Epoch: 346| Step: 0
Training loss: 0.6859667326448424
Validation loss: 2.4071824196022917

Epoch: 5| Step: 1
Training loss: 0.4859935421534236
Validation loss: 2.428220984440237

Epoch: 5| Step: 2
Training loss: 0.37814746663839977
Validation loss: 2.429805532093841

Epoch: 5| Step: 3
Training loss: 0.4565366203968298
Validation loss: 2.406613903445004

Epoch: 5| Step: 4
Training loss: 0.5816218837488129
Validation loss: 2.420753311871592

Epoch: 5| Step: 5
Training loss: 0.506384676220985
Validation loss: 2.445625328935945

Epoch: 5| Step: 6
Training loss: 0.771531270207435
Validation loss: 2.45628130263288

Epoch: 5| Step: 7
Training loss: 0.4519844169631186
Validation loss: 2.471709237318077

Epoch: 5| Step: 8
Training loss: 0.47538431895327876
Validation loss: 2.456991897206042

Epoch: 5| Step: 9
Training loss: 0.47088978655418623
Validation loss: 2.442729002071027

Epoch: 5| Step: 10
Training loss: 0.31749868771890094
Validation loss: 2.4594363085837108

Epoch: 347| Step: 0
Training loss: 0.2797826663667092
Validation loss: 2.441405797420993

Epoch: 5| Step: 1
Training loss: 0.5909888161215847
Validation loss: 2.457201354164095

Epoch: 5| Step: 2
Training loss: 0.40581294538578355
Validation loss: 2.435825046926568

Epoch: 5| Step: 3
Training loss: 0.4315534477748518
Validation loss: 2.4635940581221454

Epoch: 5| Step: 4
Training loss: 0.5087165707658041
Validation loss: 2.4180586698745996

Epoch: 5| Step: 5
Training loss: 0.6820888193485067
Validation loss: 2.450463284706456

Epoch: 5| Step: 6
Training loss: 0.5652274394318334
Validation loss: 2.405167955232932

Epoch: 5| Step: 7
Training loss: 0.37551451195816304
Validation loss: 2.436954506667957

Epoch: 5| Step: 8
Training loss: 0.6128379531702126
Validation loss: 2.4174615495445226

Epoch: 5| Step: 9
Training loss: 0.6278001524117811
Validation loss: 2.4419753180024943

Epoch: 5| Step: 10
Training loss: 0.5133622835663536
Validation loss: 2.4388487833356636

Epoch: 348| Step: 0
Training loss: 0.5368583508753231
Validation loss: 2.3839496515556418

Epoch: 5| Step: 1
Training loss: 0.5394409344046385
Validation loss: 2.4036750082866183

Epoch: 5| Step: 2
Training loss: 0.3771083294854174
Validation loss: 2.415210854687801

Epoch: 5| Step: 3
Training loss: 0.6438745100478284
Validation loss: 2.4141012474662253

Epoch: 5| Step: 4
Training loss: 0.5220920579622222
Validation loss: 2.4473430808963217

Epoch: 5| Step: 5
Training loss: 0.5464798726025214
Validation loss: 2.447029199706215

Epoch: 5| Step: 6
Training loss: 0.578844087174409
Validation loss: 2.483596406298655

Epoch: 5| Step: 7
Training loss: 0.5481891645850518
Validation loss: 2.4499326916427497

Epoch: 5| Step: 8
Training loss: 0.5060577003804501
Validation loss: 2.45590714340702

Epoch: 5| Step: 9
Training loss: 0.44971813142643957
Validation loss: 2.421269529875254

Epoch: 5| Step: 10
Training loss: 0.5446967203275783
Validation loss: 2.447139295218727

Epoch: 349| Step: 0
Training loss: 0.3464177391201435
Validation loss: 2.4214910747379537

Epoch: 5| Step: 1
Training loss: 0.7863703587991905
Validation loss: 2.4184492140350664

Epoch: 5| Step: 2
Training loss: 0.5509702209518795
Validation loss: 2.4158714316994083

Epoch: 5| Step: 3
Training loss: 0.18681299991164285
Validation loss: 2.3786999352852773

Epoch: 5| Step: 4
Training loss: 0.5886129966203775
Validation loss: 2.4387445419991423

Epoch: 5| Step: 5
Training loss: 0.4693916221093273
Validation loss: 2.4181322502414484

Epoch: 5| Step: 6
Training loss: 0.6962999554353169
Validation loss: 2.4649528563906684

Epoch: 5| Step: 7
Training loss: 0.5284657727601414
Validation loss: 2.4590820557909057

Epoch: 5| Step: 8
Training loss: 0.588004319866038
Validation loss: 2.4245576310625787

Epoch: 5| Step: 9
Training loss: 0.4484054500810104
Validation loss: 2.410100286895098

Epoch: 5| Step: 10
Training loss: 0.4038986234848771
Validation loss: 2.4508119066575302

Epoch: 350| Step: 0
Training loss: 0.455591624258064
Validation loss: 2.4284423849594745

Epoch: 5| Step: 1
Training loss: 0.4147780012481891
Validation loss: 2.400027840057191

Epoch: 5| Step: 2
Training loss: 0.40119809860799166
Validation loss: 2.4237806737246985

Epoch: 5| Step: 3
Training loss: 0.5631973923735236
Validation loss: 2.4047026669925478

Epoch: 5| Step: 4
Training loss: 0.5175601884145148
Validation loss: 2.459905127816773

Epoch: 5| Step: 5
Training loss: 0.35364810294919774
Validation loss: 2.400857356497721

Epoch: 5| Step: 6
Training loss: 0.45902665937726383
Validation loss: 2.4007334401999176

Epoch: 5| Step: 7
Training loss: 0.575161892449502
Validation loss: 2.4017830804791185

Epoch: 5| Step: 8
Training loss: 0.7202410780444451
Validation loss: 2.4142877739314925

Epoch: 5| Step: 9
Training loss: 0.5144029353865615
Validation loss: 2.4165507625781517

Epoch: 5| Step: 10
Training loss: 0.6022960846839074
Validation loss: 2.429273574506536

Testing loss: 2.659299837398276
