Epoch: 1| Step: 0
Training loss: 5.777398883590038
Validation loss: 5.739677808826857

Epoch: 5| Step: 1
Training loss: 5.7742428766323854
Validation loss: 5.718523022465251

Epoch: 5| Step: 2
Training loss: 5.855626079336509
Validation loss: 5.7046136967096475

Epoch: 5| Step: 3
Training loss: 6.458775593371188
Validation loss: 5.691407968881197

Epoch: 5| Step: 4
Training loss: 4.81927508747679
Validation loss: 5.676708456597862

Epoch: 5| Step: 5
Training loss: 5.0446184623118775
Validation loss: 5.66010069907071

Epoch: 5| Step: 6
Training loss: 6.016376398891988
Validation loss: 5.641421867637654

Epoch: 5| Step: 7
Training loss: 6.041612015400269
Validation loss: 5.619951813623015

Epoch: 5| Step: 8
Training loss: 5.925326104183463
Validation loss: 5.596173782711918

Epoch: 5| Step: 9
Training loss: 5.594426801431248
Validation loss: 5.568891970428874

Epoch: 5| Step: 10
Training loss: 4.996994641215451
Validation loss: 5.538049251685518

Epoch: 2| Step: 0
Training loss: 4.958915334358408
Validation loss: 5.504998844914033

Epoch: 5| Step: 1
Training loss: 6.059473914548502
Validation loss: 5.4666512723706475

Epoch: 5| Step: 2
Training loss: 5.680488708318329
Validation loss: 5.4257125510539055

Epoch: 5| Step: 3
Training loss: 5.56535574654229
Validation loss: 5.381783754947089

Epoch: 5| Step: 4
Training loss: 4.804164653335419
Validation loss: 5.332941732463234

Epoch: 5| Step: 5
Training loss: 5.223547278142717
Validation loss: 5.282743387127823

Epoch: 5| Step: 6
Training loss: 6.0998094997989805
Validation loss: 5.2313091754059595

Epoch: 5| Step: 7
Training loss: 4.181521574817481
Validation loss: 5.1800726013949205

Epoch: 5| Step: 8
Training loss: 5.406263053745982
Validation loss: 5.128973332300908

Epoch: 5| Step: 9
Training loss: 5.396896827004212
Validation loss: 5.078375031000852

Epoch: 5| Step: 10
Training loss: 4.899790794421897
Validation loss: 5.030560128663315

Epoch: 3| Step: 0
Training loss: 4.690154481145246
Validation loss: 4.981710676414929

Epoch: 5| Step: 1
Training loss: 5.090731047947737
Validation loss: 4.933427708966655

Epoch: 5| Step: 2
Training loss: 4.958856293270121
Validation loss: 4.890470204895926

Epoch: 5| Step: 3
Training loss: 4.47663876666599
Validation loss: 4.845921176220058

Epoch: 5| Step: 4
Training loss: 4.831477609185571
Validation loss: 4.798497220619181

Epoch: 5| Step: 5
Training loss: 4.8525244209189955
Validation loss: 4.752164072474756

Epoch: 5| Step: 6
Training loss: 4.17876377058941
Validation loss: 4.70382493893642

Epoch: 5| Step: 7
Training loss: 5.476332982106567
Validation loss: 4.652070197687666

Epoch: 5| Step: 8
Training loss: 5.165542644345013
Validation loss: 4.606628153465023

Epoch: 5| Step: 9
Training loss: 4.697521026710441
Validation loss: 4.566565940062842

Epoch: 5| Step: 10
Training loss: 4.731535308580374
Validation loss: 4.528057646547183

Epoch: 4| Step: 0
Training loss: 4.135622623161012
Validation loss: 4.492095540564711

Epoch: 5| Step: 1
Training loss: 5.1019716901962004
Validation loss: 4.451633438311475

Epoch: 5| Step: 2
Training loss: 4.170398465153456
Validation loss: 4.414909400174326

Epoch: 5| Step: 3
Training loss: 5.441043970408164
Validation loss: 4.381052568124848

Epoch: 5| Step: 4
Training loss: 3.958663618797327
Validation loss: 4.350946823912532

Epoch: 5| Step: 5
Training loss: 4.4152838983553675
Validation loss: 4.3193087527105805

Epoch: 5| Step: 6
Training loss: 4.445071570868303
Validation loss: 4.283823877786

Epoch: 5| Step: 7
Training loss: 4.325825765641457
Validation loss: 4.254410623592872

Epoch: 5| Step: 8
Training loss: 4.407815425186241
Validation loss: 4.218920044261639

Epoch: 5| Step: 9
Training loss: 4.212088970653885
Validation loss: 4.1870778752165

Epoch: 5| Step: 10
Training loss: 3.984259629916703
Validation loss: 4.1658319638037264

Epoch: 5| Step: 0
Training loss: 4.341107998938435
Validation loss: 4.1417824258797244

Epoch: 5| Step: 1
Training loss: 3.923212438863603
Validation loss: 4.112083147525352

Epoch: 5| Step: 2
Training loss: 3.9574634733942284
Validation loss: 4.085790470377972

Epoch: 5| Step: 3
Training loss: 4.698847146375894
Validation loss: 4.0628005958582625

Epoch: 5| Step: 4
Training loss: 4.563728480668375
Validation loss: 4.0387202920603515

Epoch: 5| Step: 5
Training loss: 3.754299877539833
Validation loss: 4.01287993889351

Epoch: 5| Step: 6
Training loss: 4.1532345495421685
Validation loss: 3.989633943749776

Epoch: 5| Step: 7
Training loss: 4.497642111279779
Validation loss: 3.971071510793096

Epoch: 5| Step: 8
Training loss: 3.8313253921135315
Validation loss: 3.946884405178018

Epoch: 5| Step: 9
Training loss: 4.3689679660369265
Validation loss: 3.9338967731769015

Epoch: 5| Step: 10
Training loss: 3.5313137352517043
Validation loss: 3.920699470216219

Epoch: 6| Step: 0
Training loss: 3.369743067741268
Validation loss: 3.9025590209781993

Epoch: 5| Step: 1
Training loss: 4.903091094056006
Validation loss: 3.894012327405084

Epoch: 5| Step: 2
Training loss: 4.4608045247529775
Validation loss: 3.879374823440847

Epoch: 5| Step: 3
Training loss: 4.365425095456121
Validation loss: 3.8646665223140095

Epoch: 5| Step: 4
Training loss: 3.3039342143457713
Validation loss: 3.843995986912138

Epoch: 5| Step: 5
Training loss: 3.7201462376471146
Validation loss: 3.827077253856675

Epoch: 5| Step: 6
Training loss: 3.8098409165939486
Validation loss: 3.8100979461710693

Epoch: 5| Step: 7
Training loss: 3.487543282188997
Validation loss: 3.792961039405997

Epoch: 5| Step: 8
Training loss: 4.4659218541990295
Validation loss: 3.7777048467255367

Epoch: 5| Step: 9
Training loss: 4.402081188099681
Validation loss: 3.7601250949136853

Epoch: 5| Step: 10
Training loss: 3.1655896680993485
Validation loss: 3.745964732678258

Epoch: 7| Step: 0
Training loss: 3.71578194276346
Validation loss: 3.732010646083657

Epoch: 5| Step: 1
Training loss: 4.473525689921616
Validation loss: 3.720312365103187

Epoch: 5| Step: 2
Training loss: 4.10762038683099
Validation loss: 3.705228350203797

Epoch: 5| Step: 3
Training loss: 4.069241139292071
Validation loss: 3.6941965115922244

Epoch: 5| Step: 4
Training loss: 3.1865256821264696
Validation loss: 3.6859524084536663

Epoch: 5| Step: 5
Training loss: 3.7330120584214983
Validation loss: 3.676127264893108

Epoch: 5| Step: 6
Training loss: 4.064418867737659
Validation loss: 3.665420950339585

Epoch: 5| Step: 7
Training loss: 3.784332154186581
Validation loss: 3.653012494547883

Epoch: 5| Step: 8
Training loss: 3.0519460879422584
Validation loss: 3.644778921825072

Epoch: 5| Step: 9
Training loss: 4.098090746074509
Validation loss: 3.6335192549154014

Epoch: 5| Step: 10
Training loss: 4.071203913979758
Validation loss: 3.62237041006779

Epoch: 8| Step: 0
Training loss: 4.119007960390316
Validation loss: 3.610103167758173

Epoch: 5| Step: 1
Training loss: 3.934267079249539
Validation loss: 3.5993836276870614

Epoch: 5| Step: 2
Training loss: 3.476873422499235
Validation loss: 3.5897746608547423

Epoch: 5| Step: 3
Training loss: 3.598982476440064
Validation loss: 3.585146015291092

Epoch: 5| Step: 4
Training loss: 3.99582358721412
Validation loss: 3.5864596859655733

Epoch: 5| Step: 5
Training loss: 3.6107642732647283
Validation loss: 3.5729348308888746

Epoch: 5| Step: 6
Training loss: 3.1492269203119796
Validation loss: 3.574500443813836

Epoch: 5| Step: 7
Training loss: 4.18867999859326
Validation loss: 3.566368501149369

Epoch: 5| Step: 8
Training loss: 3.87637821422167
Validation loss: 3.5607855571252607

Epoch: 5| Step: 9
Training loss: 3.7561517483624214
Validation loss: 3.5651398761554587

Epoch: 5| Step: 10
Training loss: 3.7840583397882357
Validation loss: 3.5524522859624104

Epoch: 9| Step: 0
Training loss: 3.4921722070414587
Validation loss: 3.534063757482877

Epoch: 5| Step: 1
Training loss: 3.8285885899937937
Validation loss: 3.523417183993204

Epoch: 5| Step: 2
Training loss: 3.200970031817275
Validation loss: 3.5131260238363913

Epoch: 5| Step: 3
Training loss: 3.66853199819622
Validation loss: 3.5069762199882173

Epoch: 5| Step: 4
Training loss: 3.4962064074900403
Validation loss: 3.5012442783943154

Epoch: 5| Step: 5
Training loss: 3.671821756179795
Validation loss: 3.496705694969011

Epoch: 5| Step: 6
Training loss: 3.882227893930257
Validation loss: 3.4894028057529494

Epoch: 5| Step: 7
Training loss: 3.9338601864055263
Validation loss: 3.480857906455193

Epoch: 5| Step: 8
Training loss: 3.4609414955271096
Validation loss: 3.473350447487636

Epoch: 5| Step: 9
Training loss: 4.068402506672469
Validation loss: 3.469844995232801

Epoch: 5| Step: 10
Training loss: 4.049862028055902
Validation loss: 3.468579188409989

Epoch: 10| Step: 0
Training loss: 3.6331498184288264
Validation loss: 3.4578791435122955

Epoch: 5| Step: 1
Training loss: 3.459445054638037
Validation loss: 3.4520341565123633

Epoch: 5| Step: 2
Training loss: 2.9886723281167966
Validation loss: 3.449768627582835

Epoch: 5| Step: 3
Training loss: 3.893122472757648
Validation loss: 3.446000117507453

Epoch: 5| Step: 4
Training loss: 3.9186290667550283
Validation loss: 3.4384566928806803

Epoch: 5| Step: 5
Training loss: 3.7483635192668814
Validation loss: 3.429867395534245

Epoch: 5| Step: 6
Training loss: 4.01689869908259
Validation loss: 3.4249281647336596

Epoch: 5| Step: 7
Training loss: 2.764324852464633
Validation loss: 3.4183510445886887

Epoch: 5| Step: 8
Training loss: 3.108176148831975
Validation loss: 3.415784742001242

Epoch: 5| Step: 9
Training loss: 4.368809707517374
Validation loss: 3.40959664035074

Epoch: 5| Step: 10
Training loss: 4.031650493747611
Validation loss: 3.406842057899967

Epoch: 11| Step: 0
Training loss: 3.6426239419873223
Validation loss: 3.4081682740240273

Epoch: 5| Step: 1
Training loss: 3.4935566311247177
Validation loss: 3.419181211062227

Epoch: 5| Step: 2
Training loss: 4.682688367061979
Validation loss: 3.397146376649967

Epoch: 5| Step: 3
Training loss: 3.5132351360556298
Validation loss: 3.385108206479302

Epoch: 5| Step: 4
Training loss: 3.511922149368852
Validation loss: 3.3804655912728507

Epoch: 5| Step: 5
Training loss: 3.8134956935739717
Validation loss: 3.4065936012067137

Epoch: 5| Step: 6
Training loss: 3.854395074348264
Validation loss: 3.383334683217409

Epoch: 5| Step: 7
Training loss: 3.3317218381948535
Validation loss: 3.3832277724523308

Epoch: 5| Step: 8
Training loss: 3.538125560432286
Validation loss: 3.385989710518564

Epoch: 5| Step: 9
Training loss: 2.687729493034645
Validation loss: 3.399037852316308

Epoch: 5| Step: 10
Training loss: 3.4430204972303238
Validation loss: 3.4111191988761136

Epoch: 12| Step: 0
Training loss: 3.786999705292212
Validation loss: 3.403441203671114

Epoch: 5| Step: 1
Training loss: 3.8946284642612303
Validation loss: 3.3822404590500397

Epoch: 5| Step: 2
Training loss: 4.269646059326678
Validation loss: 3.367485645891295

Epoch: 5| Step: 3
Training loss: 3.106220734917002
Validation loss: 3.3557441483138617

Epoch: 5| Step: 4
Training loss: 3.4593875764171944
Validation loss: 3.353414023190262

Epoch: 5| Step: 5
Training loss: 3.865001577004411
Validation loss: 3.3521328044144387

Epoch: 5| Step: 6
Training loss: 3.3648115303121338
Validation loss: 3.361365421703616

Epoch: 5| Step: 7
Training loss: 3.6888160296857717
Validation loss: 3.347908889148165

Epoch: 5| Step: 8
Training loss: 3.257569228495748
Validation loss: 3.3372539095706153

Epoch: 5| Step: 9
Training loss: 3.4419104285812647
Validation loss: 3.332079561358362

Epoch: 5| Step: 10
Training loss: 3.1635413223348476
Validation loss: 3.3310020313391773

Epoch: 13| Step: 0
Training loss: 3.6949429155826023
Validation loss: 3.329727339427192

Epoch: 5| Step: 1
Training loss: 3.384553316020715
Validation loss: 3.3296753690777563

Epoch: 5| Step: 2
Training loss: 3.539681285799825
Validation loss: 3.328833387205466

Epoch: 5| Step: 3
Training loss: 3.366571994117629
Validation loss: 3.3247356550581415

Epoch: 5| Step: 4
Training loss: 3.7701062648377626
Validation loss: 3.324040017834088

Epoch: 5| Step: 5
Training loss: 4.202885390475066
Validation loss: 3.3183254678229934

Epoch: 5| Step: 6
Training loss: 3.091371488918004
Validation loss: 3.3159262454989515

Epoch: 5| Step: 7
Training loss: 3.947954498082913
Validation loss: 3.311747769900693

Epoch: 5| Step: 8
Training loss: 3.285563657992372
Validation loss: 3.310962015806947

Epoch: 5| Step: 9
Training loss: 3.1366196328128897
Validation loss: 3.3090165733920704

Epoch: 5| Step: 10
Training loss: 3.5844051768887586
Validation loss: 3.3081485402114366

Epoch: 14| Step: 0
Training loss: 3.152225459076275
Validation loss: 3.307833963313942

Epoch: 5| Step: 1
Training loss: 3.377042505549723
Validation loss: 3.3076835221254575

Epoch: 5| Step: 2
Training loss: 4.18144266229218
Validation loss: 3.305377871899398

Epoch: 5| Step: 3
Training loss: 3.523243427218239
Validation loss: 3.303154092669251

Epoch: 5| Step: 4
Training loss: 3.5209357944605264
Validation loss: 3.3026752701562323

Epoch: 5| Step: 5
Training loss: 3.1827611665326816
Validation loss: 3.299603973744252

Epoch: 5| Step: 6
Training loss: 3.2713731615891395
Validation loss: 3.297835046521552

Epoch: 5| Step: 7
Training loss: 3.199203099921657
Validation loss: 3.2957595005687046

Epoch: 5| Step: 8
Training loss: 3.166332796130958
Validation loss: 3.2962002472203737

Epoch: 5| Step: 9
Training loss: 4.145906815125269
Validation loss: 3.290440005405403

Epoch: 5| Step: 10
Training loss: 4.103858639280984
Validation loss: 3.2894632533134183

Epoch: 15| Step: 0
Training loss: 3.7171578725601813
Validation loss: 3.2881984209455464

Epoch: 5| Step: 1
Training loss: 3.731293240652857
Validation loss: 3.284817206570881

Epoch: 5| Step: 2
Training loss: 3.255385851279453
Validation loss: 3.2841008799943405

Epoch: 5| Step: 3
Training loss: 3.33392287445107
Validation loss: 3.283092227347428

Epoch: 5| Step: 4
Training loss: 3.166645418062362
Validation loss: 3.2818730026069907

Epoch: 5| Step: 5
Training loss: 3.7989368256459626
Validation loss: 3.2803492023031455

Epoch: 5| Step: 6
Training loss: 3.1747132179321773
Validation loss: 3.280887519280836

Epoch: 5| Step: 7
Training loss: 3.3051783420385448
Validation loss: 3.275712261949351

Epoch: 5| Step: 8
Training loss: 3.9657297732293038
Validation loss: 3.272518461938314

Epoch: 5| Step: 9
Training loss: 3.4885163607077696
Validation loss: 3.270558349533247

Epoch: 5| Step: 10
Training loss: 3.7485133721137407
Validation loss: 3.2688048461637007

Epoch: 16| Step: 0
Training loss: 3.5467768584130046
Validation loss: 3.265231581058777

Epoch: 5| Step: 1
Training loss: 3.472861937191002
Validation loss: 3.2612680262413685

Epoch: 5| Step: 2
Training loss: 3.5380851288641084
Validation loss: 3.259631186571753

Epoch: 5| Step: 3
Training loss: 3.0634941511588645
Validation loss: 3.256700972730101

Epoch: 5| Step: 4
Training loss: 3.6691192025268236
Validation loss: 3.251872776522803

Epoch: 5| Step: 5
Training loss: 3.5632435875900983
Validation loss: 3.247936101439585

Epoch: 5| Step: 6
Training loss: 4.0904490433771254
Validation loss: 3.2448930711507877

Epoch: 5| Step: 7
Training loss: 3.910931155069701
Validation loss: 3.2429047264783923

Epoch: 5| Step: 8
Training loss: 3.499547929178591
Validation loss: 3.2407579010253396

Epoch: 5| Step: 9
Training loss: 2.7460701345890697
Validation loss: 3.240420927455514

Epoch: 5| Step: 10
Training loss: 3.1591590090609953
Validation loss: 3.2398289399861797

Epoch: 17| Step: 0
Training loss: 3.541861599812184
Validation loss: 3.2464561861766597

Epoch: 5| Step: 1
Training loss: 3.508036786833673
Validation loss: 3.2427582925394467

Epoch: 5| Step: 2
Training loss: 3.6092502853183115
Validation loss: 3.23434899551379

Epoch: 5| Step: 3
Training loss: 3.3882257789045003
Validation loss: 3.23235510780174

Epoch: 5| Step: 4
Training loss: 2.962062491129277
Validation loss: 3.2306308056193545

Epoch: 5| Step: 5
Training loss: 3.3179453590957197
Validation loss: 3.2302340936758425

Epoch: 5| Step: 6
Training loss: 2.7570121835820607
Validation loss: 3.230070261740779

Epoch: 5| Step: 7
Training loss: 3.4473541507755106
Validation loss: 3.230528233156539

Epoch: 5| Step: 8
Training loss: 4.060622500347949
Validation loss: 3.229791033214224

Epoch: 5| Step: 9
Training loss: 3.8339245519960286
Validation loss: 3.228662164174682

Epoch: 5| Step: 10
Training loss: 3.78654613506763
Validation loss: 3.2271827030770326

Epoch: 18| Step: 0
Training loss: 3.3980961069096374
Validation loss: 3.237541184721853

Epoch: 5| Step: 1
Training loss: 3.4834113049944566
Validation loss: 3.2370390634495543

Epoch: 5| Step: 2
Training loss: 3.3436548807750714
Validation loss: 3.2224339399229653

Epoch: 5| Step: 3
Training loss: 3.519803425111724
Validation loss: 3.224161666116355

Epoch: 5| Step: 4
Training loss: 3.497918599991362
Validation loss: 3.2299311870454317

Epoch: 5| Step: 5
Training loss: 3.1147013528124834
Validation loss: 3.22930783622483

Epoch: 5| Step: 6
Training loss: 3.8330090565284607
Validation loss: 3.2209867914426185

Epoch: 5| Step: 7
Training loss: 3.395878110875138
Validation loss: 3.217446508998364

Epoch: 5| Step: 8
Training loss: 3.8134136668548906
Validation loss: 3.2159535212729646

Epoch: 5| Step: 9
Training loss: 3.086914216970496
Validation loss: 3.214523460357966

Epoch: 5| Step: 10
Training loss: 3.7485080294157354
Validation loss: 3.215895785393962

Epoch: 19| Step: 0
Training loss: 3.853711130525881
Validation loss: 3.2196542242552377

Epoch: 5| Step: 1
Training loss: 3.606594980224338
Validation loss: 3.213330012971496

Epoch: 5| Step: 2
Training loss: 3.5396446439759233
Validation loss: 3.2095554020925543

Epoch: 5| Step: 3
Training loss: 3.2513034847543203
Validation loss: 3.208546686662896

Epoch: 5| Step: 4
Training loss: 3.7541125317282256
Validation loss: 3.207810178010562

Epoch: 5| Step: 5
Training loss: 3.093224991457673
Validation loss: 3.2073369012366637

Epoch: 5| Step: 6
Training loss: 3.544333467436939
Validation loss: 3.2076867172056267

Epoch: 5| Step: 7
Training loss: 3.737460087081447
Validation loss: 3.2059710648529762

Epoch: 5| Step: 8
Training loss: 2.98716741011403
Validation loss: 3.205647190029116

Epoch: 5| Step: 9
Training loss: 2.495226307851169
Validation loss: 3.2048842750361355

Epoch: 5| Step: 10
Training loss: 4.074739300398362
Validation loss: 3.2042092797900166

Epoch: 20| Step: 0
Training loss: 3.5464357616673814
Validation loss: 3.2018784493244037

Epoch: 5| Step: 1
Training loss: 3.7331441343140606
Validation loss: 3.1997392569980336

Epoch: 5| Step: 2
Training loss: 3.391724017234013
Validation loss: 3.2002092882647575

Epoch: 5| Step: 3
Training loss: 3.5286291068080655
Validation loss: 3.1958608338607264

Epoch: 5| Step: 4
Training loss: 3.978556015266565
Validation loss: 3.1966206217487123

Epoch: 5| Step: 5
Training loss: 3.077904398027729
Validation loss: 3.196809372884725

Epoch: 5| Step: 6
Training loss: 4.010772028780208
Validation loss: 3.1945484622988

Epoch: 5| Step: 7
Training loss: 3.7851925307858765
Validation loss: 3.191567396545058

Epoch: 5| Step: 8
Training loss: 2.4167842397919066
Validation loss: 3.1906707229769826

Epoch: 5| Step: 9
Training loss: 2.9460956534028258
Validation loss: 3.189760307914478

Epoch: 5| Step: 10
Training loss: 3.190453750244045
Validation loss: 3.191535210781193

Epoch: 21| Step: 0
Training loss: 2.6785564204204264
Validation loss: 3.1984872285288466

Epoch: 5| Step: 1
Training loss: 4.048144756231825
Validation loss: 3.204713325866206

Epoch: 5| Step: 2
Training loss: 3.646385514360205
Validation loss: 3.187093125268331

Epoch: 5| Step: 3
Training loss: 3.719258506051827
Validation loss: 3.185001116821796

Epoch: 5| Step: 4
Training loss: 3.287549030823102
Validation loss: 3.185914826334197

Epoch: 5| Step: 5
Training loss: 3.7505708895687686
Validation loss: 3.187413088381526

Epoch: 5| Step: 6
Training loss: 3.4223879077018275
Validation loss: 3.189681355339165

Epoch: 5| Step: 7
Training loss: 3.189953327375647
Validation loss: 3.190536937510944

Epoch: 5| Step: 8
Training loss: 3.5395888722364988
Validation loss: 3.1874737803832307

Epoch: 5| Step: 9
Training loss: 2.968102796177922
Validation loss: 3.1849998853085917

Epoch: 5| Step: 10
Training loss: 3.5457752556233895
Validation loss: 3.1817886252749115

Epoch: 22| Step: 0
Training loss: 3.50419093307699
Validation loss: 3.1796295506618657

Epoch: 5| Step: 1
Training loss: 3.280669242689918
Validation loss: 3.1792315281908827

Epoch: 5| Step: 2
Training loss: 3.958968476318595
Validation loss: 3.177759940838848

Epoch: 5| Step: 3
Training loss: 3.432121646974913
Validation loss: 3.1771366146521216

Epoch: 5| Step: 4
Training loss: 2.853462819283818
Validation loss: 3.177795998890396

Epoch: 5| Step: 5
Training loss: 3.6899595947948076
Validation loss: 3.179988847912792

Epoch: 5| Step: 6
Training loss: 3.2220042545946423
Validation loss: 3.1790395350954173

Epoch: 5| Step: 7
Training loss: 3.645057304988885
Validation loss: 3.1743996008973294

Epoch: 5| Step: 8
Training loss: 3.5297213596241437
Validation loss: 3.1736138127795517

Epoch: 5| Step: 9
Training loss: 3.505741995118912
Validation loss: 3.172346189125762

Epoch: 5| Step: 10
Training loss: 3.0092950511227565
Validation loss: 3.171135660701725

Epoch: 23| Step: 0
Training loss: 3.73147278700465
Validation loss: 3.1720964439428707

Epoch: 5| Step: 1
Training loss: 3.298486541715965
Validation loss: 3.1693929331107666

Epoch: 5| Step: 2
Training loss: 3.3767526102629977
Validation loss: 3.1716714669743182

Epoch: 5| Step: 3
Training loss: 3.1716654290179993
Validation loss: 3.1690045962481377

Epoch: 5| Step: 4
Training loss: 3.2446338662137597
Validation loss: 3.172815115359721

Epoch: 5| Step: 5
Training loss: 3.4009235978869845
Validation loss: 3.1699533558325856

Epoch: 5| Step: 6
Training loss: 3.873583380878507
Validation loss: 3.1734765882653644

Epoch: 5| Step: 7
Training loss: 2.871960567490561
Validation loss: 3.1687784008120565

Epoch: 5| Step: 8
Training loss: 3.8261121790981845
Validation loss: 3.1646305604814593

Epoch: 5| Step: 9
Training loss: 3.375697593650002
Validation loss: 3.164820985415038

Epoch: 5| Step: 10
Training loss: 3.421936034611925
Validation loss: 3.160629533324997

Epoch: 24| Step: 0
Training loss: 2.4602792010772716
Validation loss: 3.160012431976321

Epoch: 5| Step: 1
Training loss: 3.6903499646142133
Validation loss: 3.1597584211465164

Epoch: 5| Step: 2
Training loss: 3.602048894843701
Validation loss: 3.158766216362394

Epoch: 5| Step: 3
Training loss: 4.0384192775429435
Validation loss: 3.158257238389301

Epoch: 5| Step: 4
Training loss: 3.063162440063587
Validation loss: 3.1574766183234786

Epoch: 5| Step: 5
Training loss: 3.3580441699869
Validation loss: 3.157584381936294

Epoch: 5| Step: 6
Training loss: 3.8908850648052318
Validation loss: 3.157239132912951

Epoch: 5| Step: 7
Training loss: 3.5329989263045416
Validation loss: 3.159796511740501

Epoch: 5| Step: 8
Training loss: 3.184849553410089
Validation loss: 3.1601340755271448

Epoch: 5| Step: 9
Training loss: 3.280491332494015
Validation loss: 3.1668057052277967

Epoch: 5| Step: 10
Training loss: 3.2007349541192873
Validation loss: 3.189951784346422

Epoch: 25| Step: 0
Training loss: 3.746726323758062
Validation loss: 3.1946607837180467

Epoch: 5| Step: 1
Training loss: 3.0516995306934733
Validation loss: 3.165142812850024

Epoch: 5| Step: 2
Training loss: 3.558441661344182
Validation loss: 3.1533311033935854

Epoch: 5| Step: 3
Training loss: 3.735635967522551
Validation loss: 3.1491653723470763

Epoch: 5| Step: 4
Training loss: 3.5874941569955276
Validation loss: 3.1484273022154428

Epoch: 5| Step: 5
Training loss: 3.0295993990824757
Validation loss: 3.1494562504988806

Epoch: 5| Step: 6
Training loss: 3.8727420257925576
Validation loss: 3.1611706302641096

Epoch: 5| Step: 7
Training loss: 2.8483401969825484
Validation loss: 3.15308792819492

Epoch: 5| Step: 8
Training loss: 3.3962476668702593
Validation loss: 3.1558743308836785

Epoch: 5| Step: 9
Training loss: 2.8545418003193626
Validation loss: 3.1495329946103534

Epoch: 5| Step: 10
Training loss: 3.764711894528413
Validation loss: 3.1497027021656665

Epoch: 26| Step: 0
Training loss: 3.4284971774099233
Validation loss: 3.1462528400247884

Epoch: 5| Step: 1
Training loss: 3.2144023086957296
Validation loss: 3.1449840442071366

Epoch: 5| Step: 2
Training loss: 3.241447051649535
Validation loss: 3.146121443738301

Epoch: 5| Step: 3
Training loss: 3.333700890939231
Validation loss: 3.144905822860404

Epoch: 5| Step: 4
Training loss: 3.247268409135851
Validation loss: 3.1425096447313416

Epoch: 5| Step: 5
Training loss: 3.8358026236073397
Validation loss: 3.141685029003902

Epoch: 5| Step: 6
Training loss: 3.3972438075108617
Validation loss: 3.1446260285506136

Epoch: 5| Step: 7
Training loss: 3.6334716198937405
Validation loss: 3.1436532304729297

Epoch: 5| Step: 8
Training loss: 3.2568835207824574
Validation loss: 3.1379583493554644

Epoch: 5| Step: 9
Training loss: 3.363379074960163
Validation loss: 3.1367375143375105

Epoch: 5| Step: 10
Training loss: 3.479771331202103
Validation loss: 3.13477870337983

Epoch: 27| Step: 0
Training loss: 3.764442226437282
Validation loss: 3.1351600312732373

Epoch: 5| Step: 1
Training loss: 3.884897451336066
Validation loss: 3.1351508058952935

Epoch: 5| Step: 2
Training loss: 3.563133986427793
Validation loss: 3.133913160381672

Epoch: 5| Step: 3
Training loss: 2.9989695368711327
Validation loss: 3.1326717623018316

Epoch: 5| Step: 4
Training loss: 3.553917166273216
Validation loss: 3.1313031852688185

Epoch: 5| Step: 5
Training loss: 3.367541372020981
Validation loss: 3.1302622667489186

Epoch: 5| Step: 6
Training loss: 3.2412163808236154
Validation loss: 3.127711595068351

Epoch: 5| Step: 7
Training loss: 2.3010507629776553
Validation loss: 3.1287573607584505

Epoch: 5| Step: 8
Training loss: 3.7630477253130072
Validation loss: 3.128493791222172

Epoch: 5| Step: 9
Training loss: 3.199305494760341
Validation loss: 3.1270073577788944

Epoch: 5| Step: 10
Training loss: 3.4495463750298305
Validation loss: 3.1272129304135547

Epoch: 28| Step: 0
Training loss: 3.6850387635385515
Validation loss: 3.126833987490211

Epoch: 5| Step: 1
Training loss: 3.636326425535375
Validation loss: 3.12681013123931

Epoch: 5| Step: 2
Training loss: 3.521280444646327
Validation loss: 3.1225927634395165

Epoch: 5| Step: 3
Training loss: 2.9451117409198426
Validation loss: 3.1202970543907567

Epoch: 5| Step: 4
Training loss: 2.319319901260351
Validation loss: 3.124913497876097

Epoch: 5| Step: 5
Training loss: 3.6032517582084416
Validation loss: 3.120004088775379

Epoch: 5| Step: 6
Training loss: 3.3834123674253593
Validation loss: 3.1185397176107785

Epoch: 5| Step: 7
Training loss: 3.752002181566983
Validation loss: 3.1211810438295147

Epoch: 5| Step: 8
Training loss: 2.588818101047047
Validation loss: 3.118392589265637

Epoch: 5| Step: 9
Training loss: 3.68481619201793
Validation loss: 3.1172652211105625

Epoch: 5| Step: 10
Training loss: 3.823193546146518
Validation loss: 3.1189762312333156

Epoch: 29| Step: 0
Training loss: 3.4173404835529317
Validation loss: 3.1141291560300712

Epoch: 5| Step: 1
Training loss: 3.3882392893016546
Validation loss: 3.1148705268619885

Epoch: 5| Step: 2
Training loss: 3.2486854242098655
Validation loss: 3.1121107386240636

Epoch: 5| Step: 3
Training loss: 3.3644556704336273
Validation loss: 3.1131026082851423

Epoch: 5| Step: 4
Training loss: 3.199690005069247
Validation loss: 3.109102778608274

Epoch: 5| Step: 5
Training loss: 3.479144082976424
Validation loss: 3.110900524466829

Epoch: 5| Step: 6
Training loss: 3.865839066125317
Validation loss: 3.109720150861576

Epoch: 5| Step: 7
Training loss: 3.6470766980929343
Validation loss: 3.111187654741202

Epoch: 5| Step: 8
Training loss: 2.8976531496954463
Validation loss: 3.1075866028139942

Epoch: 5| Step: 9
Training loss: 3.476831592903953
Validation loss: 3.108677797915959

Epoch: 5| Step: 10
Training loss: 3.0396699666015348
Validation loss: 3.106309160595297

Epoch: 30| Step: 0
Training loss: 3.453429333838809
Validation loss: 3.1051824027889947

Epoch: 5| Step: 1
Training loss: 3.88821360916496
Validation loss: 3.1050386689926106

Epoch: 5| Step: 2
Training loss: 3.2912811987151924
Validation loss: 3.1039643938543517

Epoch: 5| Step: 3
Training loss: 2.6222269760868206
Validation loss: 3.1034617119403465

Epoch: 5| Step: 4
Training loss: 3.561268108264306
Validation loss: 3.1049017923885414

Epoch: 5| Step: 5
Training loss: 3.8730247139116365
Validation loss: 3.106650803294112

Epoch: 5| Step: 6
Training loss: 3.7526111412998304
Validation loss: 3.108289963302188

Epoch: 5| Step: 7
Training loss: 3.081110402130964
Validation loss: 3.1062577207970365

Epoch: 5| Step: 8
Training loss: 3.3643574515814634
Validation loss: 3.101352154586669

Epoch: 5| Step: 9
Training loss: 2.8205766633395437
Validation loss: 3.1029896513959554

Epoch: 5| Step: 10
Training loss: 3.0961956799593002
Validation loss: 3.097522409886011

Epoch: 31| Step: 0
Training loss: 2.774304579468196
Validation loss: 3.0974798456043

Epoch: 5| Step: 1
Training loss: 3.461235911849348
Validation loss: 3.096476399605456

Epoch: 5| Step: 2
Training loss: 3.2584830858658793
Validation loss: 3.095275804280259

Epoch: 5| Step: 3
Training loss: 3.5060159207301917
Validation loss: 3.094012479149632

Epoch: 5| Step: 4
Training loss: 2.7408247384477553
Validation loss: 3.093706735801705

Epoch: 5| Step: 5
Training loss: 3.487392470366736
Validation loss: 3.092219234523559

Epoch: 5| Step: 6
Training loss: 3.5766042617752833
Validation loss: 3.092188967818769

Epoch: 5| Step: 7
Training loss: 4.102701432270986
Validation loss: 3.0927355808038164

Epoch: 5| Step: 8
Training loss: 3.2000066697527996
Validation loss: 3.0917757790579943

Epoch: 5| Step: 9
Training loss: 2.975376323331537
Validation loss: 3.090323235742513

Epoch: 5| Step: 10
Training loss: 3.724249611869321
Validation loss: 3.0873636203069053

Epoch: 32| Step: 0
Training loss: 3.6432024955000473
Validation loss: 3.0890878016295007

Epoch: 5| Step: 1
Training loss: 3.8893589886104825
Validation loss: 3.0883247318531772

Epoch: 5| Step: 2
Training loss: 3.210425120216114
Validation loss: 3.088530397348776

Epoch: 5| Step: 3
Training loss: 3.4503162404950403
Validation loss: 3.0856508598782795

Epoch: 5| Step: 4
Training loss: 2.7647543361032034
Validation loss: 3.085853267510239

Epoch: 5| Step: 5
Training loss: 3.3919624468326086
Validation loss: 3.084123254732315

Epoch: 5| Step: 6
Training loss: 3.7379083875978965
Validation loss: 3.0844242712438867

Epoch: 5| Step: 7
Training loss: 3.1305086030986575
Validation loss: 3.084816445999063

Epoch: 5| Step: 8
Training loss: 3.6583427243702356
Validation loss: 3.084040503873145

Epoch: 5| Step: 9
Training loss: 3.162970460419112
Validation loss: 3.083729924374634

Epoch: 5| Step: 10
Training loss: 2.508055202825716
Validation loss: 3.082022607562144

Epoch: 33| Step: 0
Training loss: 2.816360621406781
Validation loss: 3.084933869647017

Epoch: 5| Step: 1
Training loss: 2.6631511124908824
Validation loss: 3.0856473338484185

Epoch: 5| Step: 2
Training loss: 2.944928617276156
Validation loss: 3.0973623182054304

Epoch: 5| Step: 3
Training loss: 4.0920299381715886
Validation loss: 3.1187008364366187

Epoch: 5| Step: 4
Training loss: 3.910445256942481
Validation loss: 3.108891727056917

Epoch: 5| Step: 5
Training loss: 3.2398005143907973
Validation loss: 3.1058732059166414

Epoch: 5| Step: 6
Training loss: 3.4831642134160243
Validation loss: 3.085595405031556

Epoch: 5| Step: 7
Training loss: 3.0837805827417615
Validation loss: 3.074637517499418

Epoch: 5| Step: 8
Training loss: 3.4785734725503015
Validation loss: 3.072356403070144

Epoch: 5| Step: 9
Training loss: 3.4162638046817624
Validation loss: 3.0743222789456146

Epoch: 5| Step: 10
Training loss: 3.5391797178953097
Validation loss: 3.073626911112643

Epoch: 34| Step: 0
Training loss: 2.460110867645932
Validation loss: 3.0729863368347563

Epoch: 5| Step: 1
Training loss: 3.655003783593261
Validation loss: 3.072276310900534

Epoch: 5| Step: 2
Training loss: 3.9230554027743865
Validation loss: 3.0717332396927635

Epoch: 5| Step: 3
Training loss: 3.9093011765252546
Validation loss: 3.070669098012206

Epoch: 5| Step: 4
Training loss: 2.2281760275456253
Validation loss: 3.071059120893653

Epoch: 5| Step: 5
Training loss: 3.45963209346123
Validation loss: 3.068630278374551

Epoch: 5| Step: 6
Training loss: 3.1005225756321133
Validation loss: 3.0695385373214443

Epoch: 5| Step: 7
Training loss: 3.431948253410432
Validation loss: 3.0676335012042197

Epoch: 5| Step: 8
Training loss: 3.883232600552364
Validation loss: 3.0671998609992595

Epoch: 5| Step: 9
Training loss: 3.4470430556248557
Validation loss: 3.0681099371377543

Epoch: 5| Step: 10
Training loss: 2.6656993860059943
Validation loss: 3.0662195513967294

Epoch: 35| Step: 0
Training loss: 3.318377768121479
Validation loss: 3.06706965517447

Epoch: 5| Step: 1
Training loss: 3.316360527235609
Validation loss: 3.064250014926212

Epoch: 5| Step: 2
Training loss: 3.213465380059404
Validation loss: 3.0634325929215867

Epoch: 5| Step: 3
Training loss: 3.3131504499850046
Validation loss: 3.0627205513749898

Epoch: 5| Step: 4
Training loss: 3.4414541910146847
Validation loss: 3.0658882254814306

Epoch: 5| Step: 5
Training loss: 2.859764197705729
Validation loss: 3.0631167033838933

Epoch: 5| Step: 6
Training loss: 3.2223768818303498
Validation loss: 3.067051732613428

Epoch: 5| Step: 7
Training loss: 3.1254873277245263
Validation loss: 3.0636366458661444

Epoch: 5| Step: 8
Training loss: 3.7512709689038877
Validation loss: 3.0676885971542314

Epoch: 5| Step: 9
Training loss: 3.9883192697594034
Validation loss: 3.062570049999072

Epoch: 5| Step: 10
Training loss: 2.8997876911714813
Validation loss: 3.0693123818931496

Epoch: 36| Step: 0
Training loss: 3.166939941125856
Validation loss: 3.071693575503747

Epoch: 5| Step: 1
Training loss: 2.9970668122739417
Validation loss: 3.0697239417069855

Epoch: 5| Step: 2
Training loss: 3.418128623493148
Validation loss: 3.067381007226338

Epoch: 5| Step: 3
Training loss: 3.926989256577723
Validation loss: 3.0623444531709745

Epoch: 5| Step: 4
Training loss: 3.530892143008835
Validation loss: 3.060668245150701

Epoch: 5| Step: 5
Training loss: 2.9828544857533212
Validation loss: 3.053784320432206

Epoch: 5| Step: 6
Training loss: 3.2758977926144537
Validation loss: 3.059458407744352

Epoch: 5| Step: 7
Training loss: 3.1413801054114425
Validation loss: 3.0536201844207365

Epoch: 5| Step: 8
Training loss: 3.1501449612156525
Validation loss: 3.0558011000769296

Epoch: 5| Step: 9
Training loss: 3.8362895236895653
Validation loss: 3.0583524965974154

Epoch: 5| Step: 10
Training loss: 2.934414318337238
Validation loss: 3.0571206810479326

Epoch: 37| Step: 0
Training loss: 3.263912792433917
Validation loss: 3.058709870409567

Epoch: 5| Step: 1
Training loss: 3.6414124779114974
Validation loss: 3.0618810005098127

Epoch: 5| Step: 2
Training loss: 2.8603582307237057
Validation loss: 3.0523603084694004

Epoch: 5| Step: 3
Training loss: 3.4264072729211215
Validation loss: 3.0512317969046197

Epoch: 5| Step: 4
Training loss: 3.3323054318244596
Validation loss: 3.05242560905884

Epoch: 5| Step: 5
Training loss: 2.5984187563038357
Validation loss: 3.048383512558322

Epoch: 5| Step: 6
Training loss: 3.8953637368772283
Validation loss: 3.0462468587564864

Epoch: 5| Step: 7
Training loss: 2.9074327256741967
Validation loss: 3.04675604054524

Epoch: 5| Step: 8
Training loss: 3.3441129113167296
Validation loss: 3.0439234756054443

Epoch: 5| Step: 9
Training loss: 3.776080420284253
Validation loss: 3.041905802655006

Epoch: 5| Step: 10
Training loss: 3.2832896841281527
Validation loss: 3.043803273868647

Epoch: 38| Step: 0
Training loss: 2.9629548379557082
Validation loss: 3.0501002689437082

Epoch: 5| Step: 1
Training loss: 2.5318007635280413
Validation loss: 3.042911137295029

Epoch: 5| Step: 2
Training loss: 3.2068837511756936
Validation loss: 3.0423028179259766

Epoch: 5| Step: 3
Training loss: 3.439373546158464
Validation loss: 3.0416648708534306

Epoch: 5| Step: 4
Training loss: 3.2174392549816804
Validation loss: 3.0416897008554407

Epoch: 5| Step: 5
Training loss: 3.5825973612512247
Validation loss: 3.040100146585968

Epoch: 5| Step: 6
Training loss: 3.764262859226498
Validation loss: 3.0398434866735755

Epoch: 5| Step: 7
Training loss: 3.2329565798778503
Validation loss: 3.0379893346755895

Epoch: 5| Step: 8
Training loss: 3.227580281743222
Validation loss: 3.038838218694509

Epoch: 5| Step: 9
Training loss: 3.7920775697395586
Validation loss: 3.0424471157465187

Epoch: 5| Step: 10
Training loss: 3.2764965685612957
Validation loss: 3.0409593258372105

Epoch: 39| Step: 0
Training loss: 3.53059219039877
Validation loss: 3.0395889439950254

Epoch: 5| Step: 1
Training loss: 3.4927296740324323
Validation loss: 3.0370240803209945

Epoch: 5| Step: 2
Training loss: 4.018556942017898
Validation loss: 3.036788731364161

Epoch: 5| Step: 3
Training loss: 2.8227373091997148
Validation loss: 3.0367686707017225

Epoch: 5| Step: 4
Training loss: 2.2450626029820624
Validation loss: 3.0364542768156464

Epoch: 5| Step: 5
Training loss: 3.436325427435141
Validation loss: 3.0410251376363204

Epoch: 5| Step: 6
Training loss: 3.140181628763071
Validation loss: 3.0356723371285512

Epoch: 5| Step: 7
Training loss: 3.6931030894604504
Validation loss: 3.042349560167674

Epoch: 5| Step: 8
Training loss: 3.581321121761193
Validation loss: 3.036198300827411

Epoch: 5| Step: 9
Training loss: 3.1812563313419315
Validation loss: 3.0330773205535437

Epoch: 5| Step: 10
Training loss: 2.7711617602597434
Validation loss: 3.031222937982934

Epoch: 40| Step: 0
Training loss: 3.8358565747335067
Validation loss: 3.0296914183213435

Epoch: 5| Step: 1
Training loss: 3.5020427192422225
Validation loss: 3.0315694705098704

Epoch: 5| Step: 2
Training loss: 2.7453265793883865
Validation loss: 3.027744318209705

Epoch: 5| Step: 3
Training loss: 3.3694497140827644
Validation loss: 3.0244270518407204

Epoch: 5| Step: 4
Training loss: 3.1684049219040022
Validation loss: 3.0278883827235332

Epoch: 5| Step: 5
Training loss: 3.1257332513771305
Validation loss: 3.023552630418692

Epoch: 5| Step: 6
Training loss: 3.5509233267952043
Validation loss: 3.0254728379083766

Epoch: 5| Step: 7
Training loss: 2.7012163601271837
Validation loss: 3.023984541968467

Epoch: 5| Step: 8
Training loss: 3.7742364325925433
Validation loss: 3.022648886900254

Epoch: 5| Step: 9
Training loss: 3.1232045928847048
Validation loss: 3.0235479152976295

Epoch: 5| Step: 10
Training loss: 3.201727734495837
Validation loss: 3.0280642271570843

Epoch: 41| Step: 0
Training loss: 3.6071953075000245
Validation loss: 3.026253087533775

Epoch: 5| Step: 1
Training loss: 3.5525588148967753
Validation loss: 3.030733605595149

Epoch: 5| Step: 2
Training loss: 2.6575831041234186
Validation loss: 3.0247001032835827

Epoch: 5| Step: 3
Training loss: 3.078122366502284
Validation loss: 3.02090614465893

Epoch: 5| Step: 4
Training loss: 3.412077791693411
Validation loss: 3.0230383972456405

Epoch: 5| Step: 5
Training loss: 3.4146402599034094
Validation loss: 3.0234306996540297

Epoch: 5| Step: 6
Training loss: 3.3978770528355677
Validation loss: 3.027835707160337

Epoch: 5| Step: 7
Training loss: 3.3927970995645285
Validation loss: 3.0272067385342596

Epoch: 5| Step: 8
Training loss: 2.7671092732603775
Validation loss: 3.02352271331297

Epoch: 5| Step: 9
Training loss: 3.4276356044352196
Validation loss: 3.0205284386284106

Epoch: 5| Step: 10
Training loss: 3.3772630521728355
Validation loss: 3.014611440007189

Epoch: 42| Step: 0
Training loss: 2.206461875186796
Validation loss: 3.015852006430078

Epoch: 5| Step: 1
Training loss: 3.5208984158311143
Validation loss: 3.0160392023234164

Epoch: 5| Step: 2
Training loss: 3.7157757830364044
Validation loss: 3.0162488226369395

Epoch: 5| Step: 3
Training loss: 2.6276241083714806
Validation loss: 3.0131432851763007

Epoch: 5| Step: 4
Training loss: 3.135306642614897
Validation loss: 3.0126153038049535

Epoch: 5| Step: 5
Training loss: 3.360779934235121
Validation loss: 3.013167720609182

Epoch: 5| Step: 6
Training loss: 3.1329363943511215
Validation loss: 3.0122647882223887

Epoch: 5| Step: 7
Training loss: 3.810822039454748
Validation loss: 3.01069205429253

Epoch: 5| Step: 8
Training loss: 4.052039426485624
Validation loss: 3.0072960757431346

Epoch: 5| Step: 9
Training loss: 3.7046987030619305
Validation loss: 3.0074276905308786

Epoch: 5| Step: 10
Training loss: 2.123329178922333
Validation loss: 3.0076772829092118

Epoch: 43| Step: 0
Training loss: 3.4149092054235677
Validation loss: 3.0050018786161607

Epoch: 5| Step: 1
Training loss: 2.7989460187574124
Validation loss: 3.0067243704790485

Epoch: 5| Step: 2
Training loss: 2.9679451905611067
Validation loss: 3.005075512593272

Epoch: 5| Step: 3
Training loss: 2.984602195520021
Validation loss: 3.0076703574307824

Epoch: 5| Step: 4
Training loss: 3.4560746933141653
Validation loss: 3.0062268078337318

Epoch: 5| Step: 5
Training loss: 3.6615834257734625
Validation loss: 3.006188615126999

Epoch: 5| Step: 6
Training loss: 3.4557303012059335
Validation loss: 3.0066553982783026

Epoch: 5| Step: 7
Training loss: 3.3492396559350874
Validation loss: 3.0067248343128514

Epoch: 5| Step: 8
Training loss: 3.710143444033556
Validation loss: 3.0070946831841594

Epoch: 5| Step: 9
Training loss: 3.2786574521312115
Validation loss: 3.005540733674139

Epoch: 5| Step: 10
Training loss: 2.734727934812055
Validation loss: 3.003597911776762

Epoch: 44| Step: 0
Training loss: 2.921188518642745
Validation loss: 3.0048998244278384

Epoch: 5| Step: 1
Training loss: 3.826451149718768
Validation loss: 3.0025709989769744

Epoch: 5| Step: 2
Training loss: 2.731469839924958
Validation loss: 3.003850274342092

Epoch: 5| Step: 3
Training loss: 3.1437518747373416
Validation loss: 3.0020766334544042

Epoch: 5| Step: 4
Training loss: 2.434042410111959
Validation loss: 2.9988101253961985

Epoch: 5| Step: 5
Training loss: 3.8470381651795638
Validation loss: 3.0002141212973057

Epoch: 5| Step: 6
Training loss: 3.4359894641452677
Validation loss: 2.9962470018145946

Epoch: 5| Step: 7
Training loss: 2.942412793107715
Validation loss: 2.9942144507325628

Epoch: 5| Step: 8
Training loss: 3.408728581449715
Validation loss: 2.9953213607505793

Epoch: 5| Step: 9
Training loss: 3.6299110557231202
Validation loss: 2.9959853220961423

Epoch: 5| Step: 10
Training loss: 3.4132953541351423
Validation loss: 2.9931339748399797

Epoch: 45| Step: 0
Training loss: 2.9178510894952727
Validation loss: 2.9926005481889617

Epoch: 5| Step: 1
Training loss: 3.347880726502472
Validation loss: 2.9915558302394705

Epoch: 5| Step: 2
Training loss: 3.64732484372108
Validation loss: 2.993597991445832

Epoch: 5| Step: 3
Training loss: 2.981305046293105
Validation loss: 2.999612431973943

Epoch: 5| Step: 4
Training loss: 3.6312205118108025
Validation loss: 3.0068441037309395

Epoch: 5| Step: 5
Training loss: 3.568373539671531
Validation loss: 3.003643554439004

Epoch: 5| Step: 6
Training loss: 3.6429103505498945
Validation loss: 2.9910975911738653

Epoch: 5| Step: 7
Training loss: 2.985840921721494
Validation loss: 3.0180280274172477

Epoch: 5| Step: 8
Training loss: 3.126331808490939
Validation loss: 3.074588120971316

Epoch: 5| Step: 9
Training loss: 2.978130258113226
Validation loss: 3.103494347684262

Epoch: 5| Step: 10
Training loss: 3.2961939971645116
Validation loss: 3.0825407217262946

Epoch: 46| Step: 0
Training loss: 3.7980314777630664
Validation loss: 3.022794636882527

Epoch: 5| Step: 1
Training loss: 3.4993915028905995
Validation loss: 2.994459294533659

Epoch: 5| Step: 2
Training loss: 2.9150402075479325
Validation loss: 3.0111379223868147

Epoch: 5| Step: 3
Training loss: 3.512097432698874
Validation loss: 3.112357725820654

Epoch: 5| Step: 4
Training loss: 3.3856162770429874
Validation loss: 3.0364939226130447

Epoch: 5| Step: 5
Training loss: 3.1798106176736405
Validation loss: 3.0054564230810423

Epoch: 5| Step: 6
Training loss: 3.2615202152339764
Validation loss: 3.0201196904658527

Epoch: 5| Step: 7
Training loss: 3.4603813878480554
Validation loss: 3.0473949997268432

Epoch: 5| Step: 8
Training loss: 3.415623637458271
Validation loss: 3.026863170616409

Epoch: 5| Step: 9
Training loss: 2.7647407109402624
Validation loss: 3.027672719874815

Epoch: 5| Step: 10
Training loss: 2.9079199474392916
Validation loss: 3.0077579352175006

Epoch: 47| Step: 0
Training loss: 3.2860058424114684
Validation loss: 2.995932665771251

Epoch: 5| Step: 1
Training loss: 3.0384130102589153
Validation loss: 2.9883524872885636

Epoch: 5| Step: 2
Training loss: 3.7800597532282576
Validation loss: 2.9872711290997094

Epoch: 5| Step: 3
Training loss: 3.0467296076588513
Validation loss: 2.9766994982334825

Epoch: 5| Step: 4
Training loss: 2.8803006939740716
Validation loss: 2.972054459872545

Epoch: 5| Step: 5
Training loss: 3.6873564611397134
Validation loss: 2.971623317025105

Epoch: 5| Step: 6
Training loss: 3.036670047103502
Validation loss: 2.9744825213500143

Epoch: 5| Step: 7
Training loss: 3.397019785556439
Validation loss: 2.9749994092337313

Epoch: 5| Step: 8
Training loss: 3.6039588883031257
Validation loss: 2.977025368636836

Epoch: 5| Step: 9
Training loss: 2.994197638380049
Validation loss: 2.973514378423938

Epoch: 5| Step: 10
Training loss: 2.9903294145167716
Validation loss: 2.9810089575239984

Epoch: 48| Step: 0
Training loss: 3.4145999022836895
Validation loss: 2.9746677555436656

Epoch: 5| Step: 1
Training loss: 2.940286005083011
Validation loss: 2.9744728562359692

Epoch: 5| Step: 2
Training loss: 3.466376377447278
Validation loss: 2.9804558202453695

Epoch: 5| Step: 3
Training loss: 3.3098813628633987
Validation loss: 2.9766131012335957

Epoch: 5| Step: 4
Training loss: 3.215177164135336
Validation loss: 2.9691061828446013

Epoch: 5| Step: 5
Training loss: 2.89531232871947
Validation loss: 2.967874724583785

Epoch: 5| Step: 6
Training loss: 3.5792184016996544
Validation loss: 2.9666955182796166

Epoch: 5| Step: 7
Training loss: 2.7062788188712545
Validation loss: 2.966324104887346

Epoch: 5| Step: 8
Training loss: 3.6552015578275197
Validation loss: 2.97231202345604

Epoch: 5| Step: 9
Training loss: 3.1193595336457265
Validation loss: 2.9717679429059136

Epoch: 5| Step: 10
Training loss: 3.340718258589965
Validation loss: 2.9651576986297985

Epoch: 49| Step: 0
Training loss: 3.227603033358096
Validation loss: 2.965836106685766

Epoch: 5| Step: 1
Training loss: 2.685330690872549
Validation loss: 2.9645371584499163

Epoch: 5| Step: 2
Training loss: 3.7522460568966665
Validation loss: 2.963457762756335

Epoch: 5| Step: 3
Training loss: 3.1776470413821123
Validation loss: 2.9639545649508796

Epoch: 5| Step: 4
Training loss: 2.8586564959207537
Validation loss: 2.9621247747224233

Epoch: 5| Step: 5
Training loss: 3.421884336415274
Validation loss: 2.962850420028212

Epoch: 5| Step: 6
Training loss: 2.6834994858978845
Validation loss: 2.9622094401931247

Epoch: 5| Step: 7
Training loss: 3.2930785100887587
Validation loss: 2.961365129941832

Epoch: 5| Step: 8
Training loss: 3.502153279190159
Validation loss: 2.960911236081922

Epoch: 5| Step: 9
Training loss: 3.0917490644005508
Validation loss: 2.9588122698715558

Epoch: 5| Step: 10
Training loss: 3.8464318820520664
Validation loss: 2.9592304461115466

Epoch: 50| Step: 0
Training loss: 3.2237292543700002
Validation loss: 2.9580497923566536

Epoch: 5| Step: 1
Training loss: 3.0125598252556958
Validation loss: 2.958206800302262

Epoch: 5| Step: 2
Training loss: 3.7822897246130003
Validation loss: 2.956891830178333

Epoch: 5| Step: 3
Training loss: 2.8598999208666456
Validation loss: 2.9571617599311506

Epoch: 5| Step: 4
Training loss: 3.059121584503371
Validation loss: 2.955870848040872

Epoch: 5| Step: 5
Training loss: 3.5951862948008313
Validation loss: 2.9540136072144496

Epoch: 5| Step: 6
Training loss: 3.024379218851999
Validation loss: 2.9521437394615484

Epoch: 5| Step: 7
Training loss: 3.037072478925805
Validation loss: 2.95616827955483

Epoch: 5| Step: 8
Training loss: 3.6657878660686456
Validation loss: 2.9521905267279642

Epoch: 5| Step: 9
Training loss: 3.220384053375142
Validation loss: 2.952008279900353

Epoch: 5| Step: 10
Training loss: 2.9142328371064705
Validation loss: 2.9545260507411277

Epoch: 51| Step: 0
Training loss: 2.8845804887274795
Validation loss: 2.954067746671179

Epoch: 5| Step: 1
Training loss: 2.907165547205708
Validation loss: 2.9579041559812285

Epoch: 5| Step: 2
Training loss: 3.4130737828377997
Validation loss: 2.953820690015479

Epoch: 5| Step: 3
Training loss: 3.466066026616732
Validation loss: 2.9563882063844895

Epoch: 5| Step: 4
Training loss: 3.222247399491205
Validation loss: 2.9515734375775704

Epoch: 5| Step: 5
Training loss: 3.204676703514389
Validation loss: 2.9499468347935682

Epoch: 5| Step: 6
Training loss: 2.958851907616543
Validation loss: 2.9462003109936927

Epoch: 5| Step: 7
Training loss: 3.8436781713705948
Validation loss: 2.9459390320679257

Epoch: 5| Step: 8
Training loss: 3.0410403996060515
Validation loss: 2.9440054298881813

Epoch: 5| Step: 9
Training loss: 3.1912457765460878
Validation loss: 2.945245651461799

Epoch: 5| Step: 10
Training loss: 3.3168551048025723
Validation loss: 2.9447481183639264

Epoch: 52| Step: 0
Training loss: 3.0533600481466583
Validation loss: 2.9428002952488614

Epoch: 5| Step: 1
Training loss: 2.8326619044576815
Validation loss: 2.942644415025194

Epoch: 5| Step: 2
Training loss: 3.7677707494336867
Validation loss: 2.9419538524775573

Epoch: 5| Step: 3
Training loss: 3.779416230754174
Validation loss: 2.940016535845779

Epoch: 5| Step: 4
Training loss: 2.7676103437940256
Validation loss: 2.940909034099361

Epoch: 5| Step: 5
Training loss: 3.3308834768921742
Validation loss: 2.9379827538634595

Epoch: 5| Step: 6
Training loss: 3.095403980518909
Validation loss: 2.938245765485358

Epoch: 5| Step: 7
Training loss: 4.124834230733433
Validation loss: 2.936577894171707

Epoch: 5| Step: 8
Training loss: 2.959605377801164
Validation loss: 2.9364924669890993

Epoch: 5| Step: 9
Training loss: 3.051730468627499
Validation loss: 2.9353434741975684

Epoch: 5| Step: 10
Training loss: 2.1338074986689244
Validation loss: 2.934021113526205

Epoch: 53| Step: 0
Training loss: 3.5591938672685766
Validation loss: 2.934747333465541

Epoch: 5| Step: 1
Training loss: 3.361447426930267
Validation loss: 2.9349155301800143

Epoch: 5| Step: 2
Training loss: 3.171838769564863
Validation loss: 2.939478783506909

Epoch: 5| Step: 3
Training loss: 3.134065829210703
Validation loss: 2.9427935063156982

Epoch: 5| Step: 4
Training loss: 3.292491439310008
Validation loss: 2.948025881024993

Epoch: 5| Step: 5
Training loss: 3.3025013431427945
Validation loss: 2.9384603813351107

Epoch: 5| Step: 6
Training loss: 3.0680208851129516
Validation loss: 2.9367411097257943

Epoch: 5| Step: 7
Training loss: 3.4204187647665583
Validation loss: 2.937745420265955

Epoch: 5| Step: 8
Training loss: 2.9563708355263687
Validation loss: 2.935468082223248

Epoch: 5| Step: 9
Training loss: 2.9862648936651146
Validation loss: 2.9305310742971247

Epoch: 5| Step: 10
Training loss: 3.08428323564775
Validation loss: 2.927557812679266

Epoch: 54| Step: 0
Training loss: 4.0227547964477965
Validation loss: 2.9298322709386304

Epoch: 5| Step: 1
Training loss: 2.7420347339647773
Validation loss: 2.934247071432276

Epoch: 5| Step: 2
Training loss: 3.141628275939426
Validation loss: 2.930252218093728

Epoch: 5| Step: 3
Training loss: 2.795902189571356
Validation loss: 2.9444628431359727

Epoch: 5| Step: 4
Training loss: 3.3887847265970987
Validation loss: 2.935626807919733

Epoch: 5| Step: 5
Training loss: 3.645299440075191
Validation loss: 2.929390796362622

Epoch: 5| Step: 6
Training loss: 2.658498283777406
Validation loss: 2.926091070014417

Epoch: 5| Step: 7
Training loss: 3.4080604151712204
Validation loss: 2.929356347841854

Epoch: 5| Step: 8
Training loss: 3.034966304535444
Validation loss: 2.9261103711282854

Epoch: 5| Step: 9
Training loss: 3.189144832103402
Validation loss: 2.928628988044423

Epoch: 5| Step: 10
Training loss: 3.0207258183430836
Validation loss: 2.9256865233620775

Epoch: 55| Step: 0
Training loss: 3.4309277214635734
Validation loss: 2.923429009091499

Epoch: 5| Step: 1
Training loss: 3.7829316238246
Validation loss: 2.920369611804596

Epoch: 5| Step: 2
Training loss: 3.156668455881366
Validation loss: 2.9195858534757404

Epoch: 5| Step: 3
Training loss: 2.9633030764648156
Validation loss: 2.9219051840118433

Epoch: 5| Step: 4
Training loss: 3.6314111775593423
Validation loss: 2.918946466554896

Epoch: 5| Step: 5
Training loss: 3.1559277360521274
Validation loss: 2.918132651469169

Epoch: 5| Step: 6
Training loss: 2.8366802493471366
Validation loss: 2.9183293939936816

Epoch: 5| Step: 7
Training loss: 3.114806831701754
Validation loss: 2.916978287347277

Epoch: 5| Step: 8
Training loss: 3.265267238458409
Validation loss: 2.918253491279308

Epoch: 5| Step: 9
Training loss: 3.1665531104624463
Validation loss: 2.9177708374244777

Epoch: 5| Step: 10
Training loss: 2.5404499664635183
Validation loss: 2.915956210846769

Epoch: 56| Step: 0
Training loss: 2.6945898884149413
Validation loss: 2.9160838258212025

Epoch: 5| Step: 1
Training loss: 3.244139743095154
Validation loss: 2.915043268042503

Epoch: 5| Step: 2
Training loss: 3.3473071135488226
Validation loss: 2.915093168601394

Epoch: 5| Step: 3
Training loss: 3.4305582874474263
Validation loss: 2.915204901562468

Epoch: 5| Step: 4
Training loss: 3.1595333131391317
Validation loss: 2.919932682945955

Epoch: 5| Step: 5
Training loss: 2.9658434643688056
Validation loss: 2.9167685219929718

Epoch: 5| Step: 6
Training loss: 3.3577943853756813
Validation loss: 2.922754648075424

Epoch: 5| Step: 7
Training loss: 3.3091657159926093
Validation loss: 2.921593322214702

Epoch: 5| Step: 8
Training loss: 3.110462247834337
Validation loss: 2.9200627070386065

Epoch: 5| Step: 9
Training loss: 2.8247437048586246
Validation loss: 2.9118863838816234

Epoch: 5| Step: 10
Training loss: 3.707499049489471
Validation loss: 2.91068039423271

Epoch: 57| Step: 0
Training loss: 2.5947287677587543
Validation loss: 2.909192015805691

Epoch: 5| Step: 1
Training loss: 3.143165737334886
Validation loss: 2.910810071548575

Epoch: 5| Step: 2
Training loss: 3.1952741476056374
Validation loss: 2.9085406519490786

Epoch: 5| Step: 3
Training loss: 3.708555593509274
Validation loss: 2.9071837720346974

Epoch: 5| Step: 4
Training loss: 3.459384957482705
Validation loss: 2.9067796552438487

Epoch: 5| Step: 5
Training loss: 2.9543231773794427
Validation loss: 2.908333887690818

Epoch: 5| Step: 6
Training loss: 3.5784152383822274
Validation loss: 2.9082798621090387

Epoch: 5| Step: 7
Training loss: 2.9352989878912554
Validation loss: 2.905128388713901

Epoch: 5| Step: 8
Training loss: 2.541293153260384
Validation loss: 2.9034453501006907

Epoch: 5| Step: 9
Training loss: 3.1693811995577863
Validation loss: 2.903367623416917

Epoch: 5| Step: 10
Training loss: 3.648403649510057
Validation loss: 2.9019192844117034

Epoch: 58| Step: 0
Training loss: 3.3353013586778397
Validation loss: 2.8996550259339378

Epoch: 5| Step: 1
Training loss: 3.028186626614263
Validation loss: 2.899243026300476

Epoch: 5| Step: 2
Training loss: 3.644073163157516
Validation loss: 2.8953337387071794

Epoch: 5| Step: 3
Training loss: 3.146343434052437
Validation loss: 2.896185667520999

Epoch: 5| Step: 4
Training loss: 2.940546282404826
Validation loss: 2.8968676878925383

Epoch: 5| Step: 5
Training loss: 2.70577766930606
Validation loss: 2.8971476248520456

Epoch: 5| Step: 6
Training loss: 3.2828349327399446
Validation loss: 2.8952362077589897

Epoch: 5| Step: 7
Training loss: 2.9013941406312846
Validation loss: 2.9003679653804664

Epoch: 5| Step: 8
Training loss: 2.975865079620871
Validation loss: 2.9112361565116007

Epoch: 5| Step: 9
Training loss: 3.581599518395162
Validation loss: 2.896856032815839

Epoch: 5| Step: 10
Training loss: 3.393595716928228
Validation loss: 2.8844724861922213

Epoch: 59| Step: 0
Training loss: 3.271199264628532
Validation loss: 2.881185048283488

Epoch: 5| Step: 1
Training loss: 3.4177212521999594
Validation loss: 2.883242294758763

Epoch: 5| Step: 2
Training loss: 3.7197157944022403
Validation loss: 2.8858174697625545

Epoch: 5| Step: 3
Training loss: 3.5739911449901176
Validation loss: 2.8810423015779736

Epoch: 5| Step: 4
Training loss: 2.4230647948477393
Validation loss: 2.886590807523612

Epoch: 5| Step: 5
Training loss: 3.147148228046991
Validation loss: 2.886171938590134

Epoch: 5| Step: 6
Training loss: 2.868909936905343
Validation loss: 2.905328171075644

Epoch: 5| Step: 7
Training loss: 3.23048616748252
Validation loss: 2.924678422520138

Epoch: 5| Step: 8
Training loss: 3.3147194102943214
Validation loss: 2.9311695330181053

Epoch: 5| Step: 9
Training loss: 2.973088838278367
Validation loss: 2.897812874445244

Epoch: 5| Step: 10
Training loss: 2.8015262565247028
Validation loss: 2.89649278419928

Epoch: 60| Step: 0
Training loss: 2.6930599806969298
Validation loss: 2.8835335297879965

Epoch: 5| Step: 1
Training loss: 3.656943752625036
Validation loss: 2.87646040399969

Epoch: 5| Step: 2
Training loss: 2.7749078855605185
Validation loss: 2.876927910444824

Epoch: 5| Step: 3
Training loss: 2.6659824467086137
Validation loss: 2.8770053338249015

Epoch: 5| Step: 4
Training loss: 3.8428898290823215
Validation loss: 2.8791890489862735

Epoch: 5| Step: 5
Training loss: 2.646242385442461
Validation loss: 2.8752132486490334

Epoch: 5| Step: 6
Training loss: 3.579739002538306
Validation loss: 2.8720090457272676

Epoch: 5| Step: 7
Training loss: 3.3898476267641033
Validation loss: 2.8741697625845655

Epoch: 5| Step: 8
Training loss: 3.151646344304105
Validation loss: 2.8709332227388797

Epoch: 5| Step: 9
Training loss: 3.2619905095900816
Validation loss: 2.8715642085313404

Epoch: 5| Step: 10
Training loss: 2.832262079763163
Validation loss: 2.871743944780557

Epoch: 61| Step: 0
Training loss: 3.2167349127874227
Validation loss: 2.869587052896104

Epoch: 5| Step: 1
Training loss: 2.936095531000837
Validation loss: 2.8702465225675216

Epoch: 5| Step: 2
Training loss: 3.179985913419413
Validation loss: 2.869324203970317

Epoch: 5| Step: 3
Training loss: 3.2205715025314188
Validation loss: 2.8683428990650497

Epoch: 5| Step: 4
Training loss: 3.9565663191666416
Validation loss: 2.8687265852216726

Epoch: 5| Step: 5
Training loss: 3.104714279174504
Validation loss: 2.867020069120245

Epoch: 5| Step: 6
Training loss: 2.8326812629578018
Validation loss: 2.8680121634142126

Epoch: 5| Step: 7
Training loss: 3.4858533519948556
Validation loss: 2.8650769715436217

Epoch: 5| Step: 8
Training loss: 2.803703964474523
Validation loss: 2.867350700154999

Epoch: 5| Step: 9
Training loss: 2.695501613893134
Validation loss: 2.863601370090414

Epoch: 5| Step: 10
Training loss: 3.1277379058440635
Validation loss: 2.8651034213975493

Epoch: 62| Step: 0
Training loss: 3.284257654766981
Validation loss: 2.8720407883573884

Epoch: 5| Step: 1
Training loss: 3.20373618644984
Validation loss: 2.8764854524259604

Epoch: 5| Step: 2
Training loss: 3.640490484413062
Validation loss: 2.8911268388964078

Epoch: 5| Step: 3
Training loss: 2.86734099847756
Validation loss: 2.8952590040573187

Epoch: 5| Step: 4
Training loss: 2.9973359995464715
Validation loss: 2.8683478988135875

Epoch: 5| Step: 5
Training loss: 2.5236781333300398
Validation loss: 2.8619289297303663

Epoch: 5| Step: 6
Training loss: 3.5905049143764076
Validation loss: 2.8645206770472336

Epoch: 5| Step: 7
Training loss: 3.369473913542072
Validation loss: 2.8578318221903034

Epoch: 5| Step: 8
Training loss: 2.954950484943739
Validation loss: 2.8599280437745915

Epoch: 5| Step: 9
Training loss: 3.125329267321254
Validation loss: 2.859948885904291

Epoch: 5| Step: 10
Training loss: 3.0612105165538934
Validation loss: 2.862994254255404

Epoch: 63| Step: 0
Training loss: 3.6281198690478362
Validation loss: 2.873583395147368

Epoch: 5| Step: 1
Training loss: 3.7126866765724302
Validation loss: 2.8669813283795884

Epoch: 5| Step: 2
Training loss: 3.3220270733910002
Validation loss: 2.8600046787070235

Epoch: 5| Step: 3
Training loss: 2.78253649842761
Validation loss: 2.8568188589066863

Epoch: 5| Step: 4
Training loss: 2.675969694978096
Validation loss: 2.856206635715272

Epoch: 5| Step: 5
Training loss: 3.0978037160477387
Validation loss: 2.854934483715246

Epoch: 5| Step: 6
Training loss: 2.9690498602160136
Validation loss: 2.8569705571865884

Epoch: 5| Step: 7
Training loss: 2.8161667551333864
Validation loss: 2.8579960786404803

Epoch: 5| Step: 8
Training loss: 3.200860688571754
Validation loss: 2.8599644849077883

Epoch: 5| Step: 9
Training loss: 2.91058256367782
Validation loss: 2.856601708997359

Epoch: 5| Step: 10
Training loss: 3.4526790831551843
Validation loss: 2.8629670103525093

Epoch: 64| Step: 0
Training loss: 2.6532114039573544
Validation loss: 2.8575180302538805

Epoch: 5| Step: 1
Training loss: 3.159867734434638
Validation loss: 2.855433389019331

Epoch: 5| Step: 2
Training loss: 3.1273148164880653
Validation loss: 2.8575937851375133

Epoch: 5| Step: 3
Training loss: 3.3888958859675427
Validation loss: 2.851786554681619

Epoch: 5| Step: 4
Training loss: 3.6850892284672208
Validation loss: 2.8480957624747063

Epoch: 5| Step: 5
Training loss: 3.15783893134349
Validation loss: 2.8522656895143177

Epoch: 5| Step: 6
Training loss: 3.223599234668732
Validation loss: 2.8495115493767713

Epoch: 5| Step: 7
Training loss: 3.439114971531855
Validation loss: 2.8479583893689613

Epoch: 5| Step: 8
Training loss: 3.1705940553977476
Validation loss: 2.843113122603352

Epoch: 5| Step: 9
Training loss: 2.633406031687531
Validation loss: 2.844819282680093

Epoch: 5| Step: 10
Training loss: 2.747876474483261
Validation loss: 2.8436842294051554

Epoch: 65| Step: 0
Training loss: 3.1589546323913607
Validation loss: 2.842617660036696

Epoch: 5| Step: 1
Training loss: 3.3625727138669403
Validation loss: 2.840943523067809

Epoch: 5| Step: 2
Training loss: 2.975933979789032
Validation loss: 2.840468126501229

Epoch: 5| Step: 3
Training loss: 3.0939858086623637
Validation loss: 2.845244287197335

Epoch: 5| Step: 4
Training loss: 3.462290893189788
Validation loss: 2.8467573986169836

Epoch: 5| Step: 5
Training loss: 3.4398558433401574
Validation loss: 2.8465710980333103

Epoch: 5| Step: 6
Training loss: 2.6840882047096777
Validation loss: 2.868177019377606

Epoch: 5| Step: 7
Training loss: 3.1495288254284306
Validation loss: 2.877513813736051

Epoch: 5| Step: 8
Training loss: 2.659711848261704
Validation loss: 2.8422763039045047

Epoch: 5| Step: 9
Training loss: 3.475990505525991
Validation loss: 2.839367159865393

Epoch: 5| Step: 10
Training loss: 2.9287601071230953
Validation loss: 2.8405822948161354

Epoch: 66| Step: 0
Training loss: 2.511726343787121
Validation loss: 2.838971973748294

Epoch: 5| Step: 1
Training loss: 3.8777708176189387
Validation loss: 2.8347644364573754

Epoch: 5| Step: 2
Training loss: 2.9566580815353674
Validation loss: 2.838888624033527

Epoch: 5| Step: 3
Training loss: 2.632585464785642
Validation loss: 2.839808391258333

Epoch: 5| Step: 4
Training loss: 3.44016481625702
Validation loss: 2.8378138165672717

Epoch: 5| Step: 5
Training loss: 2.7261702903068454
Validation loss: 2.8423074649042466

Epoch: 5| Step: 6
Training loss: 2.4609939810916814
Validation loss: 2.847660771119096

Epoch: 5| Step: 7
Training loss: 2.767220161025534
Validation loss: 2.863052206569645

Epoch: 5| Step: 8
Training loss: 3.8462187739540634
Validation loss: 2.8627245313287664

Epoch: 5| Step: 9
Training loss: 3.7201399569691564
Validation loss: 2.8410470668888355

Epoch: 5| Step: 10
Training loss: 3.1317733601383835
Validation loss: 2.8387818226521344

Epoch: 67| Step: 0
Training loss: 2.544274810715023
Validation loss: 2.834116209282283

Epoch: 5| Step: 1
Training loss: 2.009760879792746
Validation loss: 2.835888548872368

Epoch: 5| Step: 2
Training loss: 3.455954380740969
Validation loss: 2.832158109760648

Epoch: 5| Step: 3
Training loss: 3.496218000367155
Validation loss: 2.8344931813265055

Epoch: 5| Step: 4
Training loss: 3.6399168709285803
Validation loss: 2.8362927107165135

Epoch: 5| Step: 5
Training loss: 3.3536882394968166
Validation loss: 2.8322994887320805

Epoch: 5| Step: 6
Training loss: 3.159839967948832
Validation loss: 2.829929528255597

Epoch: 5| Step: 7
Training loss: 2.883484470029934
Validation loss: 2.8306372522945327

Epoch: 5| Step: 8
Training loss: 3.32632770274111
Validation loss: 2.8274509123107543

Epoch: 5| Step: 9
Training loss: 2.928987546592799
Validation loss: 2.8292450450898587

Epoch: 5| Step: 10
Training loss: 3.3264081224820345
Validation loss: 2.8266712768007847

Epoch: 68| Step: 0
Training loss: 2.642422397307716
Validation loss: 2.825362086053024

Epoch: 5| Step: 1
Training loss: 3.1136235488091253
Validation loss: 2.8269839711543634

Epoch: 5| Step: 2
Training loss: 3.092513020148041
Validation loss: 2.8261515756839253

Epoch: 5| Step: 3
Training loss: 2.7733827397487847
Validation loss: 2.8247654772770288

Epoch: 5| Step: 4
Training loss: 3.3775276326391057
Validation loss: 2.8264807430644088

Epoch: 5| Step: 5
Training loss: 3.6021238208184645
Validation loss: 2.8252956796105564

Epoch: 5| Step: 6
Training loss: 2.887561721472374
Validation loss: 2.8267912515338085

Epoch: 5| Step: 7
Training loss: 2.9801989991993993
Validation loss: 2.828691353203947

Epoch: 5| Step: 8
Training loss: 3.3685801164188485
Validation loss: 2.8283789473156884

Epoch: 5| Step: 9
Training loss: 3.229028825996859
Validation loss: 2.831851151411306

Epoch: 5| Step: 10
Training loss: 3.1346682714633682
Validation loss: 2.8415524405970545

Epoch: 69| Step: 0
Training loss: 3.7285839172471498
Validation loss: 2.843532135163598

Epoch: 5| Step: 1
Training loss: 2.8780685303291507
Validation loss: 2.850907237618773

Epoch: 5| Step: 2
Training loss: 3.1667616645885457
Validation loss: 2.8389447711266373

Epoch: 5| Step: 3
Training loss: 3.0366658073895856
Validation loss: 2.833907709468271

Epoch: 5| Step: 4
Training loss: 2.99991003537388
Validation loss: 2.8302033657516636

Epoch: 5| Step: 5
Training loss: 3.0895728994456126
Validation loss: 2.820449501718472

Epoch: 5| Step: 6
Training loss: 3.4590251797423788
Validation loss: 2.8179255339592344

Epoch: 5| Step: 7
Training loss: 3.1780547277732913
Validation loss: 2.817649480552219

Epoch: 5| Step: 8
Training loss: 2.352005723518103
Validation loss: 2.815563785500817

Epoch: 5| Step: 9
Training loss: 3.277798535843402
Validation loss: 2.815427769842798

Epoch: 5| Step: 10
Training loss: 2.9932212537868117
Validation loss: 2.8146313046880467

Epoch: 70| Step: 0
Training loss: 2.7395920167115735
Validation loss: 2.8149497389262064

Epoch: 5| Step: 1
Training loss: 2.7941394406463744
Validation loss: 2.812999370182065

Epoch: 5| Step: 2
Training loss: 3.267284792852092
Validation loss: 2.81296701872136

Epoch: 5| Step: 3
Training loss: 2.496329569534573
Validation loss: 2.812975778751341

Epoch: 5| Step: 4
Training loss: 3.70725042983499
Validation loss: 2.8153736114224404

Epoch: 5| Step: 5
Training loss: 3.1118624911389197
Validation loss: 2.8107496587207828

Epoch: 5| Step: 6
Training loss: 3.3593620832327984
Validation loss: 2.8122355720791004

Epoch: 5| Step: 7
Training loss: 3.3806873015496977
Validation loss: 2.8123108429917365

Epoch: 5| Step: 8
Training loss: 2.622115048501054
Validation loss: 2.8155079196978487

Epoch: 5| Step: 9
Training loss: 3.43772693231758
Validation loss: 2.8183125873137165

Epoch: 5| Step: 10
Training loss: 3.1257945767180293
Validation loss: 2.8240364111271266

Epoch: 71| Step: 0
Training loss: 2.9417904302769333
Validation loss: 2.820522176591647

Epoch: 5| Step: 1
Training loss: 3.506877953095213
Validation loss: 2.8217258333860546

Epoch: 5| Step: 2
Training loss: 2.7036515092480897
Validation loss: 2.8179127799815413

Epoch: 5| Step: 3
Training loss: 3.176083033112884
Validation loss: 2.8173680369055676

Epoch: 5| Step: 4
Training loss: 3.457087250164367
Validation loss: 2.8069035770588022

Epoch: 5| Step: 5
Training loss: 3.2278235975184235
Validation loss: 2.8030475903503262

Epoch: 5| Step: 6
Training loss: 3.004882336437645
Validation loss: 2.8035365353344113

Epoch: 5| Step: 7
Training loss: 3.129314648362646
Validation loss: 2.8055339542194795

Epoch: 5| Step: 8
Training loss: 2.8983634671938345
Validation loss: 2.8051379680659774

Epoch: 5| Step: 9
Training loss: 3.25623793938393
Validation loss: 2.803141749516914

Epoch: 5| Step: 10
Training loss: 2.8227853685838507
Validation loss: 2.8018188595725855

Epoch: 72| Step: 0
Training loss: 3.527034707963158
Validation loss: 2.804284249957562

Epoch: 5| Step: 1
Training loss: 2.6066992283354047
Validation loss: 2.8098791711308992

Epoch: 5| Step: 2
Training loss: 3.172280572227284
Validation loss: 2.8116629974142695

Epoch: 5| Step: 3
Training loss: 2.660722445423346
Validation loss: 2.8181804321916446

Epoch: 5| Step: 4
Training loss: 2.912491525793231
Validation loss: 2.8331323229033623

Epoch: 5| Step: 5
Training loss: 2.919992585107455
Validation loss: 2.8391211518889747

Epoch: 5| Step: 6
Training loss: 3.3522510310383464
Validation loss: 2.843839367897125

Epoch: 5| Step: 7
Training loss: 3.3547840063661503
Validation loss: 2.8251238994052117

Epoch: 5| Step: 8
Training loss: 3.5360196739961296
Validation loss: 2.8120946630809365

Epoch: 5| Step: 9
Training loss: 3.292324885618948
Validation loss: 2.7987698119550206

Epoch: 5| Step: 10
Training loss: 2.5960895144542544
Validation loss: 2.796612529546234

Epoch: 73| Step: 0
Training loss: 2.9698037937487145
Validation loss: 2.795123315905904

Epoch: 5| Step: 1
Training loss: 2.5054108239790978
Validation loss: 2.8021982790561317

Epoch: 5| Step: 2
Training loss: 3.120466835357948
Validation loss: 2.7947861499680027

Epoch: 5| Step: 3
Training loss: 3.138945628715824
Validation loss: 2.793971069491107

Epoch: 5| Step: 4
Training loss: 3.674281983071725
Validation loss: 2.7945029596166764

Epoch: 5| Step: 5
Training loss: 3.315357918728001
Validation loss: 2.7942525567951537

Epoch: 5| Step: 6
Training loss: 3.1231168031766248
Validation loss: 2.7976790602784907

Epoch: 5| Step: 7
Training loss: 3.4854190100559186
Validation loss: 2.7933719668941293

Epoch: 5| Step: 8
Training loss: 3.101366935348957
Validation loss: 2.789730741212087

Epoch: 5| Step: 9
Training loss: 3.0515640563492097
Validation loss: 2.7893361741257605

Epoch: 5| Step: 10
Training loss: 2.375507501287225
Validation loss: 2.7889737934636805

Epoch: 74| Step: 0
Training loss: 3.572067530558611
Validation loss: 2.789053569267077

Epoch: 5| Step: 1
Training loss: 2.790119131272555
Validation loss: 2.7921729224935943

Epoch: 5| Step: 2
Training loss: 2.7626109105280734
Validation loss: 2.802842281048426

Epoch: 5| Step: 3
Training loss: 2.9658371940888495
Validation loss: 2.8022203016643608

Epoch: 5| Step: 4
Training loss: 3.1752372172490078
Validation loss: 2.810115774390815

Epoch: 5| Step: 5
Training loss: 3.2081791894387464
Validation loss: 2.7960532768632533

Epoch: 5| Step: 6
Training loss: 3.178303035224272
Validation loss: 2.7894727561953743

Epoch: 5| Step: 7
Training loss: 2.8339396183362795
Validation loss: 2.787301979699781

Epoch: 5| Step: 8
Training loss: 2.8400741126907536
Validation loss: 2.7863010905331556

Epoch: 5| Step: 9
Training loss: 3.2753156495313456
Validation loss: 2.7855612512090233

Epoch: 5| Step: 10
Training loss: 3.374277814669214
Validation loss: 2.787466723552793

Epoch: 75| Step: 0
Training loss: 2.7908654462854385
Validation loss: 2.788066806350079

Epoch: 5| Step: 1
Training loss: 2.985061007440158
Validation loss: 2.7873304460349972

Epoch: 5| Step: 2
Training loss: 2.9703652254308275
Validation loss: 2.791473839947478

Epoch: 5| Step: 3
Training loss: 2.767010357968679
Validation loss: 2.7887686219601204

Epoch: 5| Step: 4
Training loss: 3.078143744242183
Validation loss: 2.786168545104556

Epoch: 5| Step: 5
Training loss: 3.0858070828849953
Validation loss: 2.7808220702236484

Epoch: 5| Step: 6
Training loss: 2.857087768296079
Validation loss: 2.7812661685176367

Epoch: 5| Step: 7
Training loss: 3.2315139279036615
Validation loss: 2.781565927663332

Epoch: 5| Step: 8
Training loss: 3.193913309658585
Validation loss: 2.7831991439528925

Epoch: 5| Step: 9
Training loss: 3.562731551291422
Validation loss: 2.7811792891683806

Epoch: 5| Step: 10
Training loss: 3.4407690976048113
Validation loss: 2.7767849465264636

Epoch: 76| Step: 0
Training loss: 3.5113719391282747
Validation loss: 2.78163406192477

Epoch: 5| Step: 1
Training loss: 3.1254113498797294
Validation loss: 2.778983845288853

Epoch: 5| Step: 2
Training loss: 2.656048037760997
Validation loss: 2.7795510951220375

Epoch: 5| Step: 3
Training loss: 3.1442358411318643
Validation loss: 2.7779422385913066

Epoch: 5| Step: 4
Training loss: 2.9293854010909866
Validation loss: 2.779452970338145

Epoch: 5| Step: 5
Training loss: 2.8053371346518046
Validation loss: 2.775663338107667

Epoch: 5| Step: 6
Training loss: 3.0329852299190687
Validation loss: 2.778077365877471

Epoch: 5| Step: 7
Training loss: 2.6679484644463525
Validation loss: 2.775918656596501

Epoch: 5| Step: 8
Training loss: 3.04301466313445
Validation loss: 2.776116576524372

Epoch: 5| Step: 9
Training loss: 3.204589806550453
Validation loss: 2.774305802931358

Epoch: 5| Step: 10
Training loss: 3.7896813585306
Validation loss: 2.7786033179569802

Epoch: 77| Step: 0
Training loss: 2.989159707992816
Validation loss: 2.774638983433085

Epoch: 5| Step: 1
Training loss: 2.960767111996398
Validation loss: 2.7718919657252643

Epoch: 5| Step: 2
Training loss: 2.966091853257078
Validation loss: 2.7832367094467885

Epoch: 5| Step: 3
Training loss: 3.517929203659165
Validation loss: 2.781043536883398

Epoch: 5| Step: 4
Training loss: 3.233606219492296
Validation loss: 2.778065500808389

Epoch: 5| Step: 5
Training loss: 3.6387164307188864
Validation loss: 2.7767461276803207

Epoch: 5| Step: 6
Training loss: 2.2876655560394012
Validation loss: 2.769454397047606

Epoch: 5| Step: 7
Training loss: 3.0505864939636314
Validation loss: 2.778114387427987

Epoch: 5| Step: 8
Training loss: 3.237161219483097
Validation loss: 2.7746006926396007

Epoch: 5| Step: 9
Training loss: 2.6894673088769045
Validation loss: 2.7836979647877884

Epoch: 5| Step: 10
Training loss: 3.119995993587171
Validation loss: 2.780524937874852

Epoch: 78| Step: 0
Training loss: 3.479465464174323
Validation loss: 2.7717054353005586

Epoch: 5| Step: 1
Training loss: 3.1521256192924487
Validation loss: 2.766261694953451

Epoch: 5| Step: 2
Training loss: 3.797049059233702
Validation loss: 2.7679525872016293

Epoch: 5| Step: 3
Training loss: 2.8633621849705526
Validation loss: 2.7679761928192135

Epoch: 5| Step: 4
Training loss: 3.000634762049478
Validation loss: 2.76820389653094

Epoch: 5| Step: 5
Training loss: 2.7962275773344354
Validation loss: 2.7676863327917114

Epoch: 5| Step: 6
Training loss: 2.3644466836798412
Validation loss: 2.766537115866983

Epoch: 5| Step: 7
Training loss: 3.2745828377413924
Validation loss: 2.769612442035161

Epoch: 5| Step: 8
Training loss: 2.5619506247033663
Validation loss: 2.7690670867684957

Epoch: 5| Step: 9
Training loss: 3.2542012276729273
Validation loss: 2.7639722205707864

Epoch: 5| Step: 10
Training loss: 3.0868457857839937
Validation loss: 2.763850796207316

Epoch: 79| Step: 0
Training loss: 3.5351681198005145
Validation loss: 2.765932887631423

Epoch: 5| Step: 1
Training loss: 3.268702758681091
Validation loss: 2.765274138685398

Epoch: 5| Step: 2
Training loss: 2.5275784461641684
Validation loss: 2.7646264067723063

Epoch: 5| Step: 3
Training loss: 3.2250114204145386
Validation loss: 2.7683568668465965

Epoch: 5| Step: 4
Training loss: 3.2906814903634336
Validation loss: 2.767679402388138

Epoch: 5| Step: 5
Training loss: 2.8342057923066437
Validation loss: 2.767112360252971

Epoch: 5| Step: 6
Training loss: 3.1592444388167142
Validation loss: 2.7745723849054382

Epoch: 5| Step: 7
Training loss: 2.9103890754704387
Validation loss: 2.776312582914377

Epoch: 5| Step: 8
Training loss: 2.901423230010326
Validation loss: 2.761238636700987

Epoch: 5| Step: 9
Training loss: 2.6618614613102958
Validation loss: 2.75904022714205

Epoch: 5| Step: 10
Training loss: 3.351986162489414
Validation loss: 2.761540641273958

Epoch: 80| Step: 0
Training loss: 2.857937143818523
Validation loss: 2.762089460480159

Epoch: 5| Step: 1
Training loss: 2.905134417629771
Validation loss: 2.76527344800794

Epoch: 5| Step: 2
Training loss: 3.0240320217516055
Validation loss: 2.762715276324858

Epoch: 5| Step: 3
Training loss: 2.773034896642014
Validation loss: 2.757583771822312

Epoch: 5| Step: 4
Training loss: 3.272254165496378
Validation loss: 2.755211937354167

Epoch: 5| Step: 5
Training loss: 3.3219729591201506
Validation loss: 2.7589932642067208

Epoch: 5| Step: 6
Training loss: 3.0150966675604094
Validation loss: 2.754343866111775

Epoch: 5| Step: 7
Training loss: 3.0337459081017837
Validation loss: 2.7528669053184176

Epoch: 5| Step: 8
Training loss: 2.949978398389445
Validation loss: 2.750247392312544

Epoch: 5| Step: 9
Training loss: 3.4042802067237523
Validation loss: 2.7513301425463914

Epoch: 5| Step: 10
Training loss: 3.1694601854458537
Validation loss: 2.7538491720188403

Epoch: 81| Step: 0
Training loss: 2.9352593500033737
Validation loss: 2.7503680284034795

Epoch: 5| Step: 1
Training loss: 3.096400657071654
Validation loss: 2.7473291439252954

Epoch: 5| Step: 2
Training loss: 3.21039541453251
Validation loss: 2.7507212784604107

Epoch: 5| Step: 3
Training loss: 3.555737552024811
Validation loss: 2.7544742331015963

Epoch: 5| Step: 4
Training loss: 2.35677482365785
Validation loss: 2.763191734588586

Epoch: 5| Step: 5
Training loss: 2.8752214097721938
Validation loss: 2.7906510123760815

Epoch: 5| Step: 6
Training loss: 3.027823330208934
Validation loss: 2.830044698750289

Epoch: 5| Step: 7
Training loss: 2.751723876241339
Validation loss: 2.8581173701625886

Epoch: 5| Step: 8
Training loss: 3.6478519337369972
Validation loss: 2.837901300904059

Epoch: 5| Step: 9
Training loss: 3.2618949065923064
Validation loss: 2.800802891991854

Epoch: 5| Step: 10
Training loss: 2.973673542414
Validation loss: 2.7606761953548196

Epoch: 82| Step: 0
Training loss: 3.247509075149178
Validation loss: 2.7449324921720595

Epoch: 5| Step: 1
Training loss: 3.1561863958918512
Validation loss: 2.7463828300111865

Epoch: 5| Step: 2
Training loss: 3.068175836679299
Validation loss: 2.749749245868892

Epoch: 5| Step: 3
Training loss: 3.297539377389536
Validation loss: 2.760309234837992

Epoch: 5| Step: 4
Training loss: 3.3923911843105143
Validation loss: 2.7634856747438983

Epoch: 5| Step: 5
Training loss: 2.977202259106018
Validation loss: 2.7518232478497144

Epoch: 5| Step: 6
Training loss: 2.93944631176536
Validation loss: 2.7512724580969263

Epoch: 5| Step: 7
Training loss: 2.840947373565747
Validation loss: 2.7485326672594126

Epoch: 5| Step: 8
Training loss: 2.994006527798658
Validation loss: 2.747903372330417

Epoch: 5| Step: 9
Training loss: 2.801413152216942
Validation loss: 2.746612652439072

Epoch: 5| Step: 10
Training loss: 3.0753426151605545
Validation loss: 2.7441369684468184

Epoch: 83| Step: 0
Training loss: 2.950968767570286
Validation loss: 2.745955026158142

Epoch: 5| Step: 1
Training loss: 2.780206891875729
Validation loss: 2.802787938891894

Epoch: 5| Step: 2
Training loss: 3.2073971426951853
Validation loss: 2.849145614558293

Epoch: 5| Step: 3
Training loss: 3.047326000775907
Validation loss: 2.7708411656491903

Epoch: 5| Step: 4
Training loss: 2.8295480088176808
Validation loss: 2.7712131350662985

Epoch: 5| Step: 5
Training loss: 3.357839259932559
Validation loss: 2.761980012408247

Epoch: 5| Step: 6
Training loss: 2.9664829633034846
Validation loss: 2.772023518008969

Epoch: 5| Step: 7
Training loss: 2.869622716528653
Validation loss: 2.761695404657233

Epoch: 5| Step: 8
Training loss: 3.3853450043747415
Validation loss: 2.7857943835893333

Epoch: 5| Step: 9
Training loss: 3.425359615185998
Validation loss: 2.7503565522631845

Epoch: 5| Step: 10
Training loss: 2.933052104415603
Validation loss: 2.737865149852592

Epoch: 84| Step: 0
Training loss: 3.627416660184892
Validation loss: 2.7354636551584903

Epoch: 5| Step: 1
Training loss: 2.269096818797601
Validation loss: 2.7349109299074885

Epoch: 5| Step: 2
Training loss: 2.6731539336755374
Validation loss: 2.7370993266611405

Epoch: 5| Step: 3
Training loss: 3.4421762737241752
Validation loss: 2.7318463396544783

Epoch: 5| Step: 4
Training loss: 2.756688826524568
Validation loss: 2.736558223200161

Epoch: 5| Step: 5
Training loss: 2.789495354410075
Validation loss: 2.730704364624587

Epoch: 5| Step: 6
Training loss: 3.2551905923995723
Validation loss: 2.7311976062951864

Epoch: 5| Step: 7
Training loss: 2.746480597085298
Validation loss: 2.73340828162784

Epoch: 5| Step: 8
Training loss: 3.5646825429166764
Validation loss: 2.734509230921281

Epoch: 5| Step: 9
Training loss: 3.3726651627893585
Validation loss: 2.736139029544408

Epoch: 5| Step: 10
Training loss: 2.8663132501436785
Validation loss: 2.731651308620819

Epoch: 85| Step: 0
Training loss: 3.314636405233818
Validation loss: 2.729644482443857

Epoch: 5| Step: 1
Training loss: 2.8114454199621712
Validation loss: 2.7336792522755866

Epoch: 5| Step: 2
Training loss: 3.5699653707155075
Validation loss: 2.735313535257138

Epoch: 5| Step: 3
Training loss: 3.435366714203823
Validation loss: 2.7310065973329034

Epoch: 5| Step: 4
Training loss: 2.836495672945178
Validation loss: 2.730536011121175

Epoch: 5| Step: 5
Training loss: 2.2410093395510056
Validation loss: 2.73118049088409

Epoch: 5| Step: 6
Training loss: 2.9919991296981117
Validation loss: 2.7309240003067408

Epoch: 5| Step: 7
Training loss: 2.706124818650953
Validation loss: 2.730613480614994

Epoch: 5| Step: 8
Training loss: 2.874341474662304
Validation loss: 2.7297977174147774

Epoch: 5| Step: 9
Training loss: 3.1065331128546188
Validation loss: 2.7281125426772985

Epoch: 5| Step: 10
Training loss: 3.5077087794816766
Validation loss: 2.727742265304538

Epoch: 86| Step: 0
Training loss: 3.614697384019795
Validation loss: 2.7243448007330278

Epoch: 5| Step: 1
Training loss: 2.855734253110686
Validation loss: 2.7232608217798875

Epoch: 5| Step: 2
Training loss: 2.7529622509381295
Validation loss: 2.724701387937391

Epoch: 5| Step: 3
Training loss: 2.9939100123192137
Validation loss: 2.7206889984310867

Epoch: 5| Step: 4
Training loss: 3.024218081467086
Validation loss: 2.7198709136889256

Epoch: 5| Step: 5
Training loss: 3.3575783826777887
Validation loss: 2.7241409097203064

Epoch: 5| Step: 6
Training loss: 3.1629731740281297
Validation loss: 2.722113983930108

Epoch: 5| Step: 7
Training loss: 2.839214186954175
Validation loss: 2.723482636324961

Epoch: 5| Step: 8
Training loss: 3.129465803196914
Validation loss: 2.721403383725596

Epoch: 5| Step: 9
Training loss: 2.29295044977791
Validation loss: 2.7232146802771626

Epoch: 5| Step: 10
Training loss: 3.2527850029272694
Validation loss: 2.7272596853879114

Epoch: 87| Step: 0
Training loss: 3.0549011936223747
Validation loss: 2.7203961335741194

Epoch: 5| Step: 1
Training loss: 3.4202804682431105
Validation loss: 2.717920708925374

Epoch: 5| Step: 2
Training loss: 3.05683530729859
Validation loss: 2.719807681338327

Epoch: 5| Step: 3
Training loss: 3.212893593273705
Validation loss: 2.716000309425351

Epoch: 5| Step: 4
Training loss: 3.3025663165033254
Validation loss: 2.715202831294967

Epoch: 5| Step: 5
Training loss: 2.544007635542969
Validation loss: 2.7115035457142205

Epoch: 5| Step: 6
Training loss: 3.168454585704192
Validation loss: 2.714342114314167

Epoch: 5| Step: 7
Training loss: 2.3177594354260735
Validation loss: 2.7127719568726314

Epoch: 5| Step: 8
Training loss: 2.9739233617290792
Validation loss: 2.713486671106961

Epoch: 5| Step: 9
Training loss: 3.3970809860031106
Validation loss: 2.708872164250989

Epoch: 5| Step: 10
Training loss: 2.655358557618734
Validation loss: 2.7102491050818087

Epoch: 88| Step: 0
Training loss: 3.2500516447218764
Validation loss: 2.7052399404444656

Epoch: 5| Step: 1
Training loss: 2.668386401526961
Validation loss: 2.712498872130203

Epoch: 5| Step: 2
Training loss: 2.680007248199682
Validation loss: 2.7089337931993627

Epoch: 5| Step: 3
Training loss: 2.5049316401491017
Validation loss: 2.709872501478271

Epoch: 5| Step: 4
Training loss: 3.569974052698209
Validation loss: 2.709820093339691

Epoch: 5| Step: 5
Training loss: 3.215705394574009
Validation loss: 2.7119365885600386

Epoch: 5| Step: 6
Training loss: 3.287469256007103
Validation loss: 2.707320122393943

Epoch: 5| Step: 7
Training loss: 2.832811213985936
Validation loss: 2.7116310211534755

Epoch: 5| Step: 8
Training loss: 3.1287277875623105
Validation loss: 2.7088935222222306

Epoch: 5| Step: 9
Training loss: 2.924274132805676
Validation loss: 2.70831099154689

Epoch: 5| Step: 10
Training loss: 3.0937136252991047
Validation loss: 2.703723796336166

Epoch: 89| Step: 0
Training loss: 3.2157409824997285
Validation loss: 2.705633710816773

Epoch: 5| Step: 1
Training loss: 2.145347898320429
Validation loss: 2.7126833214151924

Epoch: 5| Step: 2
Training loss: 3.1249102770322787
Validation loss: 2.703354560625879

Epoch: 5| Step: 3
Training loss: 3.0909235209367885
Validation loss: 2.6993238192599294

Epoch: 5| Step: 4
Training loss: 3.1587416379068403
Validation loss: 2.7012284445953796

Epoch: 5| Step: 5
Training loss: 3.263899643972727
Validation loss: 2.7006736849210173

Epoch: 5| Step: 6
Training loss: 2.634837834617889
Validation loss: 2.702294007541487

Epoch: 5| Step: 7
Training loss: 3.3057195977148184
Validation loss: 2.7020519980927564

Epoch: 5| Step: 8
Training loss: 2.9571525115493285
Validation loss: 2.7018151268647217

Epoch: 5| Step: 9
Training loss: 3.364011324197803
Validation loss: 2.7020919991189647

Epoch: 5| Step: 10
Training loss: 2.7833140568627246
Validation loss: 2.6995098316255257

Epoch: 90| Step: 0
Training loss: 2.812299509319882
Validation loss: 2.7031914838384385

Epoch: 5| Step: 1
Training loss: 2.7926899377334875
Validation loss: 2.7050944692277046

Epoch: 5| Step: 2
Training loss: 2.8742280006519048
Validation loss: 2.7069254684360478

Epoch: 5| Step: 3
Training loss: 3.3410790729864868
Validation loss: 2.731153923018028

Epoch: 5| Step: 4
Training loss: 3.2245026079197774
Validation loss: 2.7176435965882835

Epoch: 5| Step: 5
Training loss: 2.8410009154305196
Validation loss: 2.712492315815373

Epoch: 5| Step: 6
Training loss: 3.1369408401781875
Validation loss: 2.706326146193539

Epoch: 5| Step: 7
Training loss: 3.218637853353881
Validation loss: 2.7008906627285376

Epoch: 5| Step: 8
Training loss: 2.9869830334656933
Validation loss: 2.7086345691241633

Epoch: 5| Step: 9
Training loss: 2.9616377915788927
Validation loss: 2.7034104065144806

Epoch: 5| Step: 10
Training loss: 3.0363671282009426
Validation loss: 2.6961276626062243

Epoch: 91| Step: 0
Training loss: 2.81555907990475
Validation loss: 2.6964115887911553

Epoch: 5| Step: 1
Training loss: 3.3472695054917554
Validation loss: 2.6993094364441514

Epoch: 5| Step: 2
Training loss: 3.185419637921089
Validation loss: 2.6939149662014716

Epoch: 5| Step: 3
Training loss: 3.5979178765314597
Validation loss: 2.6963448645703547

Epoch: 5| Step: 4
Training loss: 2.457434398283888
Validation loss: 2.6941106013148555

Epoch: 5| Step: 5
Training loss: 2.548860863954011
Validation loss: 2.695853301691653

Epoch: 5| Step: 6
Training loss: 3.0618455148567087
Validation loss: 2.702412998221621

Epoch: 5| Step: 7
Training loss: 3.0426780552039396
Validation loss: 2.697280881726188

Epoch: 5| Step: 8
Training loss: 3.1986490378149113
Validation loss: 2.696985146096906

Epoch: 5| Step: 9
Training loss: 3.023069847286812
Validation loss: 2.700051129486336

Epoch: 5| Step: 10
Training loss: 2.6992424219973206
Validation loss: 2.698579955078481

Epoch: 92| Step: 0
Training loss: 3.2801296683011087
Validation loss: 2.6933450726507386

Epoch: 5| Step: 1
Training loss: 3.0451855793042144
Validation loss: 2.691171741602412

Epoch: 5| Step: 2
Training loss: 2.9378269094814353
Validation loss: 2.688441973567269

Epoch: 5| Step: 3
Training loss: 2.988278696894334
Validation loss: 2.6888292015635127

Epoch: 5| Step: 4
Training loss: 2.6999436549206157
Validation loss: 2.689306801742257

Epoch: 5| Step: 5
Training loss: 2.5428950567159108
Validation loss: 2.6891119392309433

Epoch: 5| Step: 6
Training loss: 3.076656552839205
Validation loss: 2.688927004740132

Epoch: 5| Step: 7
Training loss: 3.0405044076966337
Validation loss: 2.6910300874305007

Epoch: 5| Step: 8
Training loss: 3.2299390955990637
Validation loss: 2.6862433190918016

Epoch: 5| Step: 9
Training loss: 3.2045551363849785
Validation loss: 2.685390517350773

Epoch: 5| Step: 10
Training loss: 3.0450219412578456
Validation loss: 2.688069135685554

Epoch: 93| Step: 0
Training loss: 3.1602466320414915
Validation loss: 2.6891859775329325

Epoch: 5| Step: 1
Training loss: 3.4718164859651264
Validation loss: 2.7035837660836237

Epoch: 5| Step: 2
Training loss: 2.714850512159969
Validation loss: 2.7138105941821906

Epoch: 5| Step: 3
Training loss: 2.751308736629117
Validation loss: 2.7194349807229963

Epoch: 5| Step: 4
Training loss: 3.064497938247861
Validation loss: 2.687189002619006

Epoch: 5| Step: 5
Training loss: 2.709229648655509
Validation loss: 2.683993894932737

Epoch: 5| Step: 6
Training loss: 3.2765489598887196
Validation loss: 2.6883894127566226

Epoch: 5| Step: 7
Training loss: 3.2225676183361203
Validation loss: 2.6838906813437657

Epoch: 5| Step: 8
Training loss: 2.6571655490744246
Validation loss: 2.686414857746145

Epoch: 5| Step: 9
Training loss: 2.9709472555937473
Validation loss: 2.685511646923454

Epoch: 5| Step: 10
Training loss: 3.153404841939577
Validation loss: 2.6871026716733986

Epoch: 94| Step: 0
Training loss: 2.767884963638488
Validation loss: 2.687479481257459

Epoch: 5| Step: 1
Training loss: 2.748253874855221
Validation loss: 2.682930002897771

Epoch: 5| Step: 2
Training loss: 2.9202553242923157
Validation loss: 2.6796735800678704

Epoch: 5| Step: 3
Training loss: 3.118072460631885
Validation loss: 2.6804246976967097

Epoch: 5| Step: 4
Training loss: 2.992061124279272
Validation loss: 2.683845019738902

Epoch: 5| Step: 5
Training loss: 3.225066570215911
Validation loss: 2.694612976961614

Epoch: 5| Step: 6
Training loss: 2.788045232846474
Validation loss: 2.6972259582485996

Epoch: 5| Step: 7
Training loss: 2.95340771810345
Validation loss: 2.710458235863169

Epoch: 5| Step: 8
Training loss: 2.9287102862411745
Validation loss: 2.7221276548176014

Epoch: 5| Step: 9
Training loss: 3.2426036889314243
Validation loss: 2.725599692555578

Epoch: 5| Step: 10
Training loss: 3.475321413173999
Validation loss: 2.705551430764474

Epoch: 95| Step: 0
Training loss: 2.9459880185734995
Validation loss: 2.683264959090049

Epoch: 5| Step: 1
Training loss: 2.5310553958637794
Validation loss: 2.680303214846996

Epoch: 5| Step: 2
Training loss: 3.0644931146311265
Validation loss: 2.6781346401233934

Epoch: 5| Step: 3
Training loss: 4.004380212038857
Validation loss: 2.677979971086293

Epoch: 5| Step: 4
Training loss: 2.7491497979673314
Validation loss: 2.674313339158575

Epoch: 5| Step: 5
Training loss: 3.0065644288143596
Validation loss: 2.675359073391463

Epoch: 5| Step: 6
Training loss: 2.6332981103239512
Validation loss: 2.677965036146707

Epoch: 5| Step: 7
Training loss: 3.4291994620910673
Validation loss: 2.6782935654785347

Epoch: 5| Step: 8
Training loss: 2.2918342760232213
Validation loss: 2.6784000614779737

Epoch: 5| Step: 9
Training loss: 3.154150387223502
Validation loss: 2.6714932410593697

Epoch: 5| Step: 10
Training loss: 2.8916225052538627
Validation loss: 2.6764990183783666

Epoch: 96| Step: 0
Training loss: 2.877883128918014
Validation loss: 2.6777535773362517

Epoch: 5| Step: 1
Training loss: 3.2525369572573952
Validation loss: 2.673842392721308

Epoch: 5| Step: 2
Training loss: 3.3653925029955643
Validation loss: 2.674373422642581

Epoch: 5| Step: 3
Training loss: 3.3463261742911574
Validation loss: 2.6710504376014956

Epoch: 5| Step: 4
Training loss: 2.3836775413346563
Validation loss: 2.668562709823079

Epoch: 5| Step: 5
Training loss: 2.825866387444948
Validation loss: 2.670572646278188

Epoch: 5| Step: 6
Training loss: 3.3103731633075264
Validation loss: 2.6730083409540293

Epoch: 5| Step: 7
Training loss: 2.546843546105619
Validation loss: 2.6718586732473133

Epoch: 5| Step: 8
Training loss: 3.2522324450706193
Validation loss: 2.684437558224259

Epoch: 5| Step: 9
Training loss: 2.7573115512508957
Validation loss: 2.6910175046486002

Epoch: 5| Step: 10
Training loss: 2.856358171747734
Validation loss: 2.697562571993746

Epoch: 97| Step: 0
Training loss: 3.168045964928678
Validation loss: 2.7110134670990833

Epoch: 5| Step: 1
Training loss: 3.092684013054365
Validation loss: 2.720951284402114

Epoch: 5| Step: 2
Training loss: 3.1309665940000286
Validation loss: 2.7035620722095492

Epoch: 5| Step: 3
Training loss: 3.292638289227428
Validation loss: 2.6931277858187492

Epoch: 5| Step: 4
Training loss: 3.044275514954208
Validation loss: 2.679301277807686

Epoch: 5| Step: 5
Training loss: 2.80683319556721
Validation loss: 2.6757361369697192

Epoch: 5| Step: 6
Training loss: 2.8865428246354825
Validation loss: 2.6773825822499933

Epoch: 5| Step: 7
Training loss: 2.815593035957882
Validation loss: 2.675642233203615

Epoch: 5| Step: 8
Training loss: 2.9830533441472884
Validation loss: 2.673813660649478

Epoch: 5| Step: 9
Training loss: 2.746212258094776
Validation loss: 2.6690170594041285

Epoch: 5| Step: 10
Training loss: 2.9199169758529133
Validation loss: 2.6659247407113082

Epoch: 98| Step: 0
Training loss: 2.68389819776761
Validation loss: 2.664982516416047

Epoch: 5| Step: 1
Training loss: 3.0923489567499494
Validation loss: 2.6611843375465254

Epoch: 5| Step: 2
Training loss: 2.4665456660551808
Validation loss: 2.66415033293999

Epoch: 5| Step: 3
Training loss: 3.3112874240855668
Validation loss: 2.661175067254176

Epoch: 5| Step: 4
Training loss: 2.9553256438597226
Validation loss: 2.6616158824179776

Epoch: 5| Step: 5
Training loss: 2.67573705483575
Validation loss: 2.6579088497518732

Epoch: 5| Step: 6
Training loss: 3.2090698156515813
Validation loss: 2.6598987002625063

Epoch: 5| Step: 7
Training loss: 3.3130879869968015
Validation loss: 2.663806275899659

Epoch: 5| Step: 8
Training loss: 3.460412805881601
Validation loss: 2.6729275944177027

Epoch: 5| Step: 9
Training loss: 2.6524355258710037
Validation loss: 2.6798818768831465

Epoch: 5| Step: 10
Training loss: 2.970379673229873
Validation loss: 2.6980874245143056

Epoch: 99| Step: 0
Training loss: 2.900929164017701
Validation loss: 2.670478049268624

Epoch: 5| Step: 1
Training loss: 3.403300557017626
Validation loss: 2.664599081113463

Epoch: 5| Step: 2
Training loss: 2.803177536011745
Validation loss: 2.656808438071449

Epoch: 5| Step: 3
Training loss: 2.8253571681189986
Validation loss: 2.6577913159209117

Epoch: 5| Step: 4
Training loss: 2.9648720560242983
Validation loss: 2.656930176947917

Epoch: 5| Step: 5
Training loss: 3.538118956641053
Validation loss: 2.6594341667072245

Epoch: 5| Step: 6
Training loss: 2.6449538644037287
Validation loss: 2.6579640812277257

Epoch: 5| Step: 7
Training loss: 3.0863168217720336
Validation loss: 2.6569101660557157

Epoch: 5| Step: 8
Training loss: 3.141918921693882
Validation loss: 2.6573774450781253

Epoch: 5| Step: 9
Training loss: 2.6155297338348533
Validation loss: 2.6612365619341705

Epoch: 5| Step: 10
Training loss: 2.831564987210153
Validation loss: 2.662435749277596

Epoch: 100| Step: 0
Training loss: 2.566341776741997
Validation loss: 2.678414683875742

Epoch: 5| Step: 1
Training loss: 3.038302525126801
Validation loss: 2.6625473096442764

Epoch: 5| Step: 2
Training loss: 3.0527424973900263
Validation loss: 2.6615035451750866

Epoch: 5| Step: 3
Training loss: 2.5817694596212606
Validation loss: 2.6572311220492004

Epoch: 5| Step: 4
Training loss: 2.958164496820044
Validation loss: 2.66060838134729

Epoch: 5| Step: 5
Training loss: 3.4278267437696925
Validation loss: 2.6623652713204633

Epoch: 5| Step: 6
Training loss: 2.3958887729588234
Validation loss: 2.6712677937367397

Epoch: 5| Step: 7
Training loss: 3.353852741090959
Validation loss: 2.673697433406355

Epoch: 5| Step: 8
Training loss: 2.624060144653935
Validation loss: 2.687360616371455

Epoch: 5| Step: 9
Training loss: 3.332962317481765
Validation loss: 2.6880128108414922

Epoch: 5| Step: 10
Training loss: 3.3509707339701307
Validation loss: 2.6739465675028193

Epoch: 101| Step: 0
Training loss: 2.723055007171636
Validation loss: 2.662615237066813

Epoch: 5| Step: 1
Training loss: 2.977227564726615
Validation loss: 2.65238754818891

Epoch: 5| Step: 2
Training loss: 3.110264943112953
Validation loss: 2.6488140435164533

Epoch: 5| Step: 3
Training loss: 3.171591158790115
Validation loss: 2.648696229032312

Epoch: 5| Step: 4
Training loss: 3.3252690199246446
Validation loss: 2.6538784879882487

Epoch: 5| Step: 5
Training loss: 3.0706600545772513
Validation loss: 2.650613719102595

Epoch: 5| Step: 6
Training loss: 2.5146814318223782
Validation loss: 2.6484577714078483

Epoch: 5| Step: 7
Training loss: 3.1663925821916186
Validation loss: 2.647885421509591

Epoch: 5| Step: 8
Training loss: 2.5198595882837456
Validation loss: 2.6505881929654005

Epoch: 5| Step: 9
Training loss: 3.47871315259811
Validation loss: 2.6506855114962913

Epoch: 5| Step: 10
Training loss: 2.5567390067432174
Validation loss: 2.67663169802854

Epoch: 102| Step: 0
Training loss: 3.1258308831936428
Validation loss: 2.6871640156813577

Epoch: 5| Step: 1
Training loss: 3.1712675969376534
Validation loss: 2.7005573924109596

Epoch: 5| Step: 2
Training loss: 2.982067234460807
Validation loss: 2.6836207810698416

Epoch: 5| Step: 3
Training loss: 3.062985440141457
Validation loss: 2.66236487652387

Epoch: 5| Step: 4
Training loss: 3.5865178854004567
Validation loss: 2.6548017883778647

Epoch: 5| Step: 5
Training loss: 2.6219947505697605
Validation loss: 2.6498599426180696

Epoch: 5| Step: 6
Training loss: 3.242069839732501
Validation loss: 2.6490351867992254

Epoch: 5| Step: 7
Training loss: 2.7165457899509344
Validation loss: 2.650062079465771

Epoch: 5| Step: 8
Training loss: 2.562959676311487
Validation loss: 2.6548104339337537

Epoch: 5| Step: 9
Training loss: 3.378432894498844
Validation loss: 2.6533166042181207

Epoch: 5| Step: 10
Training loss: 1.8234019115018307
Validation loss: 2.6589784587818146

Epoch: 103| Step: 0
Training loss: 3.194958506331144
Validation loss: 2.6546013596397247

Epoch: 5| Step: 1
Training loss: 3.2809798356505944
Validation loss: 2.6462193282526596

Epoch: 5| Step: 2
Training loss: 2.7408786704130654
Validation loss: 2.651509163227412

Epoch: 5| Step: 3
Training loss: 3.0712878204488745
Validation loss: 2.6504189213356804

Epoch: 5| Step: 4
Training loss: 3.219971064088069
Validation loss: 2.6415392739529553

Epoch: 5| Step: 5
Training loss: 2.221837219689674
Validation loss: 2.6451014985128074

Epoch: 5| Step: 6
Training loss: 3.2545068742917125
Validation loss: 2.6438352969576555

Epoch: 5| Step: 7
Training loss: 2.360038007333172
Validation loss: 2.642006203340988

Epoch: 5| Step: 8
Training loss: 3.0177751692846626
Validation loss: 2.6418459761706004

Epoch: 5| Step: 9
Training loss: 3.3789703186664295
Validation loss: 2.6438315191311537

Epoch: 5| Step: 10
Training loss: 2.6624660686784374
Validation loss: 2.648025828689998

Epoch: 104| Step: 0
Training loss: 3.005144635367819
Validation loss: 2.6490838881022793

Epoch: 5| Step: 1
Training loss: 3.078593416928876
Validation loss: 2.6455732364208453

Epoch: 5| Step: 2
Training loss: 2.8635859932260783
Validation loss: 2.655604251784024

Epoch: 5| Step: 3
Training loss: 3.0775144329708746
Validation loss: 2.656257155503462

Epoch: 5| Step: 4
Training loss: 2.8175429168113357
Validation loss: 2.6501164326210156

Epoch: 5| Step: 5
Training loss: 2.770705045631912
Validation loss: 2.6447262662307454

Epoch: 5| Step: 6
Training loss: 3.1550780282747293
Validation loss: 2.6531609251346207

Epoch: 5| Step: 7
Training loss: 2.758565567551099
Validation loss: 2.641841806369407

Epoch: 5| Step: 8
Training loss: 2.8601363372317956
Validation loss: 2.638545122587196

Epoch: 5| Step: 9
Training loss: 3.2866194615510915
Validation loss: 2.644861336521597

Epoch: 5| Step: 10
Training loss: 2.975761085415895
Validation loss: 2.6417176258581625

Epoch: 105| Step: 0
Training loss: 2.6696044018742
Validation loss: 2.6390870337440955

Epoch: 5| Step: 1
Training loss: 2.978009050159524
Validation loss: 2.6367293439900674

Epoch: 5| Step: 2
Training loss: 2.7951445953963785
Validation loss: 2.6338509328075763

Epoch: 5| Step: 3
Training loss: 3.3345567047747737
Validation loss: 2.6367793051246595

Epoch: 5| Step: 4
Training loss: 3.6557397730930217
Validation loss: 2.6352634063545026

Epoch: 5| Step: 5
Training loss: 2.7923099194263354
Validation loss: 2.637516202120172

Epoch: 5| Step: 6
Training loss: 2.8616444071143
Validation loss: 2.6370429927608554

Epoch: 5| Step: 7
Training loss: 2.6085253034479132
Validation loss: 2.647260433305846

Epoch: 5| Step: 8
Training loss: 2.638089740502182
Validation loss: 2.659935670846279

Epoch: 5| Step: 9
Training loss: 3.0689611979915665
Validation loss: 2.6596847650491475

Epoch: 5| Step: 10
Training loss: 3.1085216175424155
Validation loss: 2.646215857062527

Epoch: 106| Step: 0
Training loss: 3.1801217647248294
Validation loss: 2.635621218849585

Epoch: 5| Step: 1
Training loss: 2.554232588929044
Validation loss: 2.633955673149454

Epoch: 5| Step: 2
Training loss: 3.1073951744021007
Validation loss: 2.636259529233741

Epoch: 5| Step: 3
Training loss: 2.8262793488225055
Validation loss: 2.6373010626932043

Epoch: 5| Step: 4
Training loss: 2.802236181767733
Validation loss: 2.636080836734094

Epoch: 5| Step: 5
Training loss: 2.7944991607146026
Validation loss: 2.631116279094167

Epoch: 5| Step: 6
Training loss: 2.7527632268869007
Validation loss: 2.6347190779664156

Epoch: 5| Step: 7
Training loss: 3.0670745315774406
Validation loss: 2.6379501397602287

Epoch: 5| Step: 8
Training loss: 2.6289477862269384
Validation loss: 2.6343297439179767

Epoch: 5| Step: 9
Training loss: 3.4393107413476494
Validation loss: 2.64209948519681

Epoch: 5| Step: 10
Training loss: 3.3976094256499136
Validation loss: 2.6417103751712965

Epoch: 107| Step: 0
Training loss: 3.5625107079060565
Validation loss: 2.633894206313034

Epoch: 5| Step: 1
Training loss: 2.835692508088147
Validation loss: 2.629239001654803

Epoch: 5| Step: 2
Training loss: 3.70434614561276
Validation loss: 2.6295678753491543

Epoch: 5| Step: 3
Training loss: 2.6795283234144445
Validation loss: 2.624276334409701

Epoch: 5| Step: 4
Training loss: 2.714769013837537
Validation loss: 2.6244044753931393

Epoch: 5| Step: 5
Training loss: 2.611931376655486
Validation loss: 2.6208332096655886

Epoch: 5| Step: 6
Training loss: 2.6930694534688993
Validation loss: 2.6209179722846287

Epoch: 5| Step: 7
Training loss: 2.5392167734081266
Validation loss: 2.6253692105567272

Epoch: 5| Step: 8
Training loss: 3.2453894556919067
Validation loss: 2.6240041702397066

Epoch: 5| Step: 9
Training loss: 2.6171076064939527
Validation loss: 2.6260312599271107

Epoch: 5| Step: 10
Training loss: 3.140923329318425
Validation loss: 2.6320837066301617

Epoch: 108| Step: 0
Training loss: 3.319339672511873
Validation loss: 2.639157884665158

Epoch: 5| Step: 1
Training loss: 2.63162068635064
Validation loss: 2.6395714440744795

Epoch: 5| Step: 2
Training loss: 3.1455857303683787
Validation loss: 2.6547086757042844

Epoch: 5| Step: 3
Training loss: 3.307416650207725
Validation loss: 2.626264193503823

Epoch: 5| Step: 4
Training loss: 2.812054577630171
Validation loss: 2.6206021832525934

Epoch: 5| Step: 5
Training loss: 2.93724188786639
Validation loss: 2.6246660823923524

Epoch: 5| Step: 6
Training loss: 3.1467792697198935
Validation loss: 2.6369237589012027

Epoch: 5| Step: 7
Training loss: 2.912966770211756
Validation loss: 2.640207427409924

Epoch: 5| Step: 8
Training loss: 2.6482970614036963
Validation loss: 2.634859695408749

Epoch: 5| Step: 9
Training loss: 2.792872457911766
Validation loss: 2.6363724695454325

Epoch: 5| Step: 10
Training loss: 2.9295385704333605
Validation loss: 2.6374374133391583

Epoch: 109| Step: 0
Training loss: 2.936374205085251
Validation loss: 2.634183823338299

Epoch: 5| Step: 1
Training loss: 2.8729599058471855
Validation loss: 2.634914979010006

Epoch: 5| Step: 2
Training loss: 3.1313144212746846
Validation loss: 2.6344607473197192

Epoch: 5| Step: 3
Training loss: 2.5698572932598704
Validation loss: 2.6307174776266637

Epoch: 5| Step: 4
Training loss: 3.524218690466706
Validation loss: 2.6429613387593043

Epoch: 5| Step: 5
Training loss: 2.9773433592212255
Validation loss: 2.6317317352618566

Epoch: 5| Step: 6
Training loss: 3.2409297847609992
Validation loss: 2.6309502993482767

Epoch: 5| Step: 7
Training loss: 2.8991589740747243
Validation loss: 2.633495120723368

Epoch: 5| Step: 8
Training loss: 3.1971340816518112
Validation loss: 2.6415704620825147

Epoch: 5| Step: 9
Training loss: 2.4980558465314857
Validation loss: 2.6567954992609217

Epoch: 5| Step: 10
Training loss: 2.4912727614462105
Validation loss: 2.655031412819922

Epoch: 110| Step: 0
Training loss: 3.646957064426856
Validation loss: 2.6651641229929766

Epoch: 5| Step: 1
Training loss: 2.9428974642220065
Validation loss: 2.6376469558982674

Epoch: 5| Step: 2
Training loss: 2.831766050352363
Validation loss: 2.6302861547679037

Epoch: 5| Step: 3
Training loss: 3.155170520460597
Validation loss: 2.6225024719353325

Epoch: 5| Step: 4
Training loss: 3.121305647091601
Validation loss: 2.6254782380224686

Epoch: 5| Step: 5
Training loss: 3.3070971494327366
Validation loss: 2.620983416287209

Epoch: 5| Step: 6
Training loss: 2.548970770224185
Validation loss: 2.6316403547288667

Epoch: 5| Step: 7
Training loss: 2.91655879956555
Validation loss: 2.6293443454561416

Epoch: 5| Step: 8
Training loss: 2.889628305522977
Validation loss: 2.63639338799273

Epoch: 5| Step: 9
Training loss: 2.2168510800090973
Validation loss: 2.6233844326847775

Epoch: 5| Step: 10
Training loss: 2.8195493727662067
Validation loss: 2.6279049692466057

Epoch: 111| Step: 0
Training loss: 3.082269192831021
Validation loss: 2.621919449482683

Epoch: 5| Step: 1
Training loss: 2.5749422715021404
Validation loss: 2.624336507479036

Epoch: 5| Step: 2
Training loss: 3.2067881409549397
Validation loss: 2.623573251446146

Epoch: 5| Step: 3
Training loss: 3.1954769474607274
Validation loss: 2.625454942820441

Epoch: 5| Step: 4
Training loss: 3.3062421600306533
Validation loss: 2.6216457684201346

Epoch: 5| Step: 5
Training loss: 3.091744591758269
Validation loss: 2.6215661242188957

Epoch: 5| Step: 6
Training loss: 3.106970082257152
Validation loss: 2.622423803476007

Epoch: 5| Step: 7
Training loss: 3.143037087998747
Validation loss: 2.6297479662596066

Epoch: 5| Step: 8
Training loss: 2.457890443723969
Validation loss: 2.6452944510942866

Epoch: 5| Step: 9
Training loss: 2.5063262052675213
Validation loss: 2.664206191355084

Epoch: 5| Step: 10
Training loss: 2.6072886457945184
Validation loss: 2.705687200605002

Epoch: 112| Step: 0
Training loss: 3.0219808218730564
Validation loss: 2.747095515117167

Epoch: 5| Step: 1
Training loss: 2.709896888319684
Validation loss: 2.7274024873701457

Epoch: 5| Step: 2
Training loss: 3.1177679683047312
Validation loss: 2.716969597449441

Epoch: 5| Step: 3
Training loss: 3.6304175573375854
Validation loss: 2.6785833558902548

Epoch: 5| Step: 4
Training loss: 2.805428919646202
Validation loss: 2.6578842530835756

Epoch: 5| Step: 5
Training loss: 2.455521985750415
Validation loss: 2.651914726023322

Epoch: 5| Step: 6
Training loss: 2.7245479453760457
Validation loss: 2.650790119540434

Epoch: 5| Step: 7
Training loss: 3.274688408858141
Validation loss: 2.652353848565229

Epoch: 5| Step: 8
Training loss: 2.9579209232760926
Validation loss: 2.6562882914669537

Epoch: 5| Step: 9
Training loss: 2.8528073454697584
Validation loss: 2.682829297850157

Epoch: 5| Step: 10
Training loss: 3.2780733262635904
Validation loss: 2.658991804442629

Epoch: 113| Step: 0
Training loss: 2.927270813138434
Validation loss: 2.656294142991467

Epoch: 5| Step: 1
Training loss: 3.1333030259580745
Validation loss: 2.654639838094056

Epoch: 5| Step: 2
Training loss: 3.3075690365922417
Validation loss: 2.6554514437996053

Epoch: 5| Step: 3
Training loss: 2.9749572109703513
Validation loss: 2.654900237702812

Epoch: 5| Step: 4
Training loss: 2.8587729231862355
Validation loss: 2.65275635642913

Epoch: 5| Step: 5
Training loss: 2.7158170643128274
Validation loss: 2.649448506841406

Epoch: 5| Step: 6
Training loss: 3.043053994313063
Validation loss: 2.6516974043699624

Epoch: 5| Step: 7
Training loss: 2.8920197292409413
Validation loss: 2.653523992405511

Epoch: 5| Step: 8
Training loss: 2.8260269391503017
Validation loss: 2.655888769691834

Epoch: 5| Step: 9
Training loss: 3.020760230572011
Validation loss: 2.6586551208289

Epoch: 5| Step: 10
Training loss: 3.117841532460109
Validation loss: 2.651739952557779

Epoch: 114| Step: 0
Training loss: 2.6297310474799658
Validation loss: 2.6539821056455692

Epoch: 5| Step: 1
Training loss: 3.1660406263471517
Validation loss: 2.6611163138700107

Epoch: 5| Step: 2
Training loss: 2.8955338320921977
Validation loss: 2.66715172104224

Epoch: 5| Step: 3
Training loss: 3.2506273104397794
Validation loss: 2.6673462781074115

Epoch: 5| Step: 4
Training loss: 2.8749535598321247
Validation loss: 2.6567426211446827

Epoch: 5| Step: 5
Training loss: 2.5675807918625853
Validation loss: 2.6524529135674877

Epoch: 5| Step: 6
Training loss: 3.029395883345355
Validation loss: 2.6509792782216675

Epoch: 5| Step: 7
Training loss: 3.1234784809151073
Validation loss: 2.6459258527391873

Epoch: 5| Step: 8
Training loss: 3.14257023480209
Validation loss: 2.6446327939696466

Epoch: 5| Step: 9
Training loss: 2.6727697647729816
Validation loss: 2.642185952454466

Epoch: 5| Step: 10
Training loss: 3.311848270432936
Validation loss: 2.6401076203476648

Epoch: 115| Step: 0
Training loss: 3.3162759815956813
Validation loss: 2.6386523095561074

Epoch: 5| Step: 1
Training loss: 2.9233326259541137
Validation loss: 2.6212383845509777

Epoch: 5| Step: 2
Training loss: 2.9724404937203532
Validation loss: 2.6042451018960215

Epoch: 5| Step: 3
Training loss: 2.9951619237264655
Validation loss: 2.6013174491277065

Epoch: 5| Step: 4
Training loss: 3.2120994822866935
Validation loss: 2.5998098553543425

Epoch: 5| Step: 5
Training loss: 2.9365505550897053
Validation loss: 2.6040131664361637

Epoch: 5| Step: 6
Training loss: 2.8979126488451845
Validation loss: 2.6002247295171306

Epoch: 5| Step: 7
Training loss: 2.4911640421522043
Validation loss: 2.6053273747665777

Epoch: 5| Step: 8
Training loss: 2.8909463239903572
Validation loss: 2.6130242171266618

Epoch: 5| Step: 9
Training loss: 2.279138083920896
Validation loss: 2.6192717646179142

Epoch: 5| Step: 10
Training loss: 3.3752589656235226
Validation loss: 2.6257582827646777

Epoch: 116| Step: 0
Training loss: 3.2126573101075535
Validation loss: 2.621207044482059

Epoch: 5| Step: 1
Training loss: 2.7683511003187857
Validation loss: 2.640601542310943

Epoch: 5| Step: 2
Training loss: 2.9384942502687164
Validation loss: 2.637736456657965

Epoch: 5| Step: 3
Training loss: 2.559794975355826
Validation loss: 2.6406227515193414

Epoch: 5| Step: 4
Training loss: 3.0637749334197784
Validation loss: 2.625673073002224

Epoch: 5| Step: 5
Training loss: 3.135500546639805
Validation loss: 2.6273086355476987

Epoch: 5| Step: 6
Training loss: 2.886694467981856
Validation loss: 2.6136367565603664

Epoch: 5| Step: 7
Training loss: 2.784385884924098
Validation loss: 2.6033881840549724

Epoch: 5| Step: 8
Training loss: 3.051688436711438
Validation loss: 2.598661007499898

Epoch: 5| Step: 9
Training loss: 3.068509181376423
Validation loss: 2.597655902609323

Epoch: 5| Step: 10
Training loss: 2.800988778867788
Validation loss: 2.597474059911697

Epoch: 117| Step: 0
Training loss: 3.1461482279901167
Validation loss: 2.5942426545499204

Epoch: 5| Step: 1
Training loss: 2.598586571248671
Validation loss: 2.5977335728768733

Epoch: 5| Step: 2
Training loss: 3.0685447670858355
Validation loss: 2.593743251253578

Epoch: 5| Step: 3
Training loss: 3.1993694339799914
Validation loss: 2.5991099001436417

Epoch: 5| Step: 4
Training loss: 2.2604212489865407
Validation loss: 2.594064917030371

Epoch: 5| Step: 5
Training loss: 3.1523913979031426
Validation loss: 2.600159477851956

Epoch: 5| Step: 6
Training loss: 2.7448953588444605
Validation loss: 2.6158090922887185

Epoch: 5| Step: 7
Training loss: 3.1606297085262844
Validation loss: 2.637367414368916

Epoch: 5| Step: 8
Training loss: 3.3053093363496195
Validation loss: 2.667011889164157

Epoch: 5| Step: 9
Training loss: 2.86090247207274
Validation loss: 2.6935133246156937

Epoch: 5| Step: 10
Training loss: 2.6609971654074793
Validation loss: 2.691539198712199

Epoch: 118| Step: 0
Training loss: 2.7391272529046513
Validation loss: 2.6848974482822276

Epoch: 5| Step: 1
Training loss: 3.009871137528377
Validation loss: 2.6454047573857298

Epoch: 5| Step: 2
Training loss: 2.804715127197888
Validation loss: 2.6041232007408777

Epoch: 5| Step: 3
Training loss: 2.855372060659935
Validation loss: 2.594764096104166

Epoch: 5| Step: 4
Training loss: 2.299591534044624
Validation loss: 2.5935780378877356

Epoch: 5| Step: 5
Training loss: 2.9483887167545344
Validation loss: 2.589802560667584

Epoch: 5| Step: 6
Training loss: 3.200708287054345
Validation loss: 2.5899356054942535

Epoch: 5| Step: 7
Training loss: 2.9280109134950125
Validation loss: 2.5934929461505507

Epoch: 5| Step: 8
Training loss: 3.4881590408498715
Validation loss: 2.5958379828367097

Epoch: 5| Step: 9
Training loss: 2.9663165911029026
Validation loss: 2.5970430424937487

Epoch: 5| Step: 10
Training loss: 3.067604792887154
Validation loss: 2.594367317425904

Epoch: 119| Step: 0
Training loss: 2.688624656802436
Validation loss: 2.6084833987796805

Epoch: 5| Step: 1
Training loss: 2.259104850520881
Validation loss: 2.6195127616429454

Epoch: 5| Step: 2
Training loss: 3.1945199892998217
Validation loss: 2.6335679619006327

Epoch: 5| Step: 3
Training loss: 2.955317899124846
Validation loss: 2.5915550258006665

Epoch: 5| Step: 4
Training loss: 3.137286637183102
Validation loss: 2.5951220227676983

Epoch: 5| Step: 5
Training loss: 2.5601525137591463
Validation loss: 2.591924777072228

Epoch: 5| Step: 6
Training loss: 2.7126359263875455
Validation loss: 2.5859240965394683

Epoch: 5| Step: 7
Training loss: 3.2720449030063814
Validation loss: 2.594084244585669

Epoch: 5| Step: 8
Training loss: 2.8179061641569785
Validation loss: 2.62592431537688

Epoch: 5| Step: 9
Training loss: 3.0593860910465933
Validation loss: 2.6442764054495154

Epoch: 5| Step: 10
Training loss: 3.680090491384726
Validation loss: 2.655898133726294

Epoch: 120| Step: 0
Training loss: 3.064815346661338
Validation loss: 2.654063052827623

Epoch: 5| Step: 1
Training loss: 3.404670839238291
Validation loss: 2.6744556074693113

Epoch: 5| Step: 2
Training loss: 3.2167764187077257
Validation loss: 2.688613298522403

Epoch: 5| Step: 3
Training loss: 3.4239261698026966
Validation loss: 2.6453353714254475

Epoch: 5| Step: 4
Training loss: 3.018924311626347
Validation loss: 2.6086017518363236

Epoch: 5| Step: 5
Training loss: 2.9328552210464855
Validation loss: 2.5831805636208687

Epoch: 5| Step: 6
Training loss: 2.631896904007445
Validation loss: 2.5818391578020563

Epoch: 5| Step: 7
Training loss: 2.7050946066454125
Validation loss: 2.580773439507003

Epoch: 5| Step: 8
Training loss: 2.718417969521803
Validation loss: 2.5837185774543263

Epoch: 5| Step: 9
Training loss: 2.594870451705212
Validation loss: 2.6021012737411344

Epoch: 5| Step: 10
Training loss: 2.470055150640283
Validation loss: 2.6291370674187062

Epoch: 121| Step: 0
Training loss: 3.530940354536236
Validation loss: 2.6521088808200215

Epoch: 5| Step: 1
Training loss: 2.3532101761396405
Validation loss: 2.616115616393181

Epoch: 5| Step: 2
Training loss: 3.3044331049117073
Validation loss: 2.6024638899992496

Epoch: 5| Step: 3
Training loss: 2.600698149921362
Validation loss: 2.582895814151793

Epoch: 5| Step: 4
Training loss: 3.1122791012734754
Validation loss: 2.5812239581066216

Epoch: 5| Step: 5
Training loss: 2.966148923493278
Validation loss: 2.583691977144848

Epoch: 5| Step: 6
Training loss: 2.915964441687022
Validation loss: 2.5780771399586606

Epoch: 5| Step: 7
Training loss: 2.7047156796896386
Validation loss: 2.582047769442376

Epoch: 5| Step: 8
Training loss: 2.7405461890482052
Validation loss: 2.582599298594641

Epoch: 5| Step: 9
Training loss: 2.9619354740303403
Validation loss: 2.5831196333043263

Epoch: 5| Step: 10
Training loss: 2.986004130100631
Validation loss: 2.587565388843318

Epoch: 122| Step: 0
Training loss: 3.2222877985394494
Validation loss: 2.5970088670476166

Epoch: 5| Step: 1
Training loss: 3.0195959955259393
Validation loss: 2.62174099700214

Epoch: 5| Step: 2
Training loss: 3.2714708197013946
Validation loss: 2.6294609240063784

Epoch: 5| Step: 3
Training loss: 3.0275935506817757
Validation loss: 2.6471644076341287

Epoch: 5| Step: 4
Training loss: 2.7140202213172158
Validation loss: 2.619131446683979

Epoch: 5| Step: 5
Training loss: 3.173367604810579
Validation loss: 2.596670833589937

Epoch: 5| Step: 6
Training loss: 2.7700748313683903
Validation loss: 2.5856976171208577

Epoch: 5| Step: 7
Training loss: 2.823925124399606
Validation loss: 2.583682174298406

Epoch: 5| Step: 8
Training loss: 2.821134748559744
Validation loss: 2.574180655901148

Epoch: 5| Step: 9
Training loss: 2.803662976340042
Validation loss: 2.573571699209865

Epoch: 5| Step: 10
Training loss: 2.4423422034059024
Validation loss: 2.573506128380418

Epoch: 123| Step: 0
Training loss: 2.8910381949721105
Validation loss: 2.574047007891034

Epoch: 5| Step: 1
Training loss: 2.5994545584535316
Validation loss: 2.573328201908991

Epoch: 5| Step: 2
Training loss: 3.35648153916477
Validation loss: 2.5812914314372413

Epoch: 5| Step: 3
Training loss: 2.868150762332969
Validation loss: 2.587260864678278

Epoch: 5| Step: 4
Training loss: 2.902818027523518
Validation loss: 2.600781004910707

Epoch: 5| Step: 5
Training loss: 2.0122793657186424
Validation loss: 2.60063112193696

Epoch: 5| Step: 6
Training loss: 2.9448785841674834
Validation loss: 2.6086184558273944

Epoch: 5| Step: 7
Training loss: 3.467687908160964
Validation loss: 2.6065960708798825

Epoch: 5| Step: 8
Training loss: 2.7139314065303504
Validation loss: 2.606550697734377

Epoch: 5| Step: 9
Training loss: 3.1653441294180955
Validation loss: 2.5928633808206993

Epoch: 5| Step: 10
Training loss: 3.123210241877069
Validation loss: 2.586111771378554

Epoch: 124| Step: 0
Training loss: 2.5266097121584177
Validation loss: 2.5826145413261132

Epoch: 5| Step: 1
Training loss: 2.462211545518633
Validation loss: 2.5838900021575304

Epoch: 5| Step: 2
Training loss: 2.831682023187691
Validation loss: 2.582637860630233

Epoch: 5| Step: 3
Training loss: 3.494632419799215
Validation loss: 2.5791068267467234

Epoch: 5| Step: 4
Training loss: 3.0955820535275866
Validation loss: 2.5786004019377775

Epoch: 5| Step: 5
Training loss: 2.8928309915426933
Validation loss: 2.5735303261475124

Epoch: 5| Step: 6
Training loss: 3.127649023712115
Validation loss: 2.570608956831297

Epoch: 5| Step: 7
Training loss: 3.0252301719677113
Validation loss: 2.5706989341817224

Epoch: 5| Step: 8
Training loss: 3.0909063969054698
Validation loss: 2.5701736675516966

Epoch: 5| Step: 9
Training loss: 2.3754366423119317
Validation loss: 2.5701843373392297

Epoch: 5| Step: 10
Training loss: 3.0070451029980982
Validation loss: 2.5735513409929505

Epoch: 125| Step: 0
Training loss: 3.0780129969014487
Validation loss: 2.5721121846355004

Epoch: 5| Step: 1
Training loss: 2.578382259595951
Validation loss: 2.5718203045373103

Epoch: 5| Step: 2
Training loss: 3.2114054021062564
Validation loss: 2.5737497871449557

Epoch: 5| Step: 3
Training loss: 2.7837919127756754
Validation loss: 2.5755537797774504

Epoch: 5| Step: 4
Training loss: 2.7210331242236943
Validation loss: 2.575616676726066

Epoch: 5| Step: 5
Training loss: 3.305565106532157
Validation loss: 2.5796989123798926

Epoch: 5| Step: 6
Training loss: 2.775780689981341
Validation loss: 2.5792098670440198

Epoch: 5| Step: 7
Training loss: 3.143614451707443
Validation loss: 2.5833676012077285

Epoch: 5| Step: 8
Training loss: 3.0823129735487176
Validation loss: 2.584349009515631

Epoch: 5| Step: 9
Training loss: 2.7580847241097275
Validation loss: 2.5772845129083906

Epoch: 5| Step: 10
Training loss: 2.4582348712233313
Validation loss: 2.580693010750543

Epoch: 126| Step: 0
Training loss: 2.662650262595228
Validation loss: 2.5760168003247026

Epoch: 5| Step: 1
Training loss: 2.178539452329295
Validation loss: 2.5808972620112334

Epoch: 5| Step: 2
Training loss: 3.3316289518001767
Validation loss: 2.570499228240127

Epoch: 5| Step: 3
Training loss: 3.272924269180323
Validation loss: 2.5758027228611984

Epoch: 5| Step: 4
Training loss: 2.9663791224254235
Validation loss: 2.578035136148563

Epoch: 5| Step: 5
Training loss: 2.908375936667964
Validation loss: 2.5751768406884197

Epoch: 5| Step: 6
Training loss: 2.9727500870640235
Validation loss: 2.5733118078071233

Epoch: 5| Step: 7
Training loss: 2.9352504151596377
Validation loss: 2.5804920714485013

Epoch: 5| Step: 8
Training loss: 3.083958708431035
Validation loss: 2.5822232872032123

Epoch: 5| Step: 9
Training loss: 2.722690401451432
Validation loss: 2.585514952220529

Epoch: 5| Step: 10
Training loss: 2.867974030508793
Validation loss: 2.591170641382072

Epoch: 127| Step: 0
Training loss: 3.298036921982124
Validation loss: 2.5933445340393475

Epoch: 5| Step: 1
Training loss: 3.2906732307514934
Validation loss: 2.5954443720674334

Epoch: 5| Step: 2
Training loss: 2.522151276724516
Validation loss: 2.5854049484697206

Epoch: 5| Step: 3
Training loss: 2.9434995054669333
Validation loss: 2.588680533405209

Epoch: 5| Step: 4
Training loss: 2.9513832082257423
Validation loss: 2.5963989847042663

Epoch: 5| Step: 5
Training loss: 3.0063596709424734
Validation loss: 2.5952158054059113

Epoch: 5| Step: 6
Training loss: 2.958537958796151
Validation loss: 2.598465072563193

Epoch: 5| Step: 7
Training loss: 1.8941417805012652
Validation loss: 2.627593202534631

Epoch: 5| Step: 8
Training loss: 2.9863650093270757
Validation loss: 2.6347187393546045

Epoch: 5| Step: 9
Training loss: 3.316791992758964
Validation loss: 2.6058869279424965

Epoch: 5| Step: 10
Training loss: 2.58091815727386
Validation loss: 2.579329624945794

Epoch: 128| Step: 0
Training loss: 3.2169169419190875
Validation loss: 2.5702351112358794

Epoch: 5| Step: 1
Training loss: 2.7930582098872123
Validation loss: 2.5742082254050644

Epoch: 5| Step: 2
Training loss: 2.4756435289775385
Validation loss: 2.5671720749545526

Epoch: 5| Step: 3
Training loss: 2.756021323200448
Validation loss: 2.5684947462561585

Epoch: 5| Step: 4
Training loss: 2.69054550780081
Validation loss: 2.566834074771414

Epoch: 5| Step: 5
Training loss: 3.193285907985177
Validation loss: 2.5656728642642452

Epoch: 5| Step: 6
Training loss: 3.063418814954206
Validation loss: 2.56206604119051

Epoch: 5| Step: 7
Training loss: 2.697395559132772
Validation loss: 2.56455863738887

Epoch: 5| Step: 8
Training loss: 3.156978258775216
Validation loss: 2.5627896615143304

Epoch: 5| Step: 9
Training loss: 3.2591172494037903
Validation loss: 2.5637976789402543

Epoch: 5| Step: 10
Training loss: 2.656587377327854
Validation loss: 2.572328840541267

Epoch: 129| Step: 0
Training loss: 2.994424088628495
Validation loss: 2.60069030727509

Epoch: 5| Step: 1
Training loss: 2.9194265296290394
Validation loss: 2.6078391410724016

Epoch: 5| Step: 2
Training loss: 2.809497756737151
Validation loss: 2.644557038175379

Epoch: 5| Step: 3
Training loss: 3.230833021519288
Validation loss: 2.6599870513843262

Epoch: 5| Step: 4
Training loss: 3.010969293859041
Validation loss: 2.657860636653351

Epoch: 5| Step: 5
Training loss: 2.7166810329814095
Validation loss: 2.6320763003494383

Epoch: 5| Step: 6
Training loss: 2.3750208803564035
Validation loss: 2.58033484908842

Epoch: 5| Step: 7
Training loss: 3.0089202822530234
Validation loss: 2.5651476268210875

Epoch: 5| Step: 8
Training loss: 3.326794138844262
Validation loss: 2.5647976586562957

Epoch: 5| Step: 9
Training loss: 2.5444359831505046
Validation loss: 2.5643221041761057

Epoch: 5| Step: 10
Training loss: 3.090573462200235
Validation loss: 2.5808721707849416

Epoch: 130| Step: 0
Training loss: 2.6459745134148345
Validation loss: 2.5713189651134316

Epoch: 5| Step: 1
Training loss: 2.7769696162055166
Validation loss: 2.571399537525805

Epoch: 5| Step: 2
Training loss: 2.7182509742608065
Validation loss: 2.568637485014555

Epoch: 5| Step: 3
Training loss: 3.1295648422240063
Validation loss: 2.6088958697266893

Epoch: 5| Step: 4
Training loss: 2.9712499432529675
Validation loss: 2.6434870315839705

Epoch: 5| Step: 5
Training loss: 2.964358806529685
Validation loss: 2.6890199326248037

Epoch: 5| Step: 6
Training loss: 3.2581871786940435
Validation loss: 2.7036807065007453

Epoch: 5| Step: 7
Training loss: 3.1189927918258205
Validation loss: 2.660706508870786

Epoch: 5| Step: 8
Training loss: 2.5089869140916234
Validation loss: 2.635687502903117

Epoch: 5| Step: 9
Training loss: 2.710880685700138
Validation loss: 2.564612101686599

Epoch: 5| Step: 10
Training loss: 3.591068627530568
Validation loss: 2.5637270062953905

Epoch: 131| Step: 0
Training loss: 3.185093738128676
Validation loss: 2.5562168809482433

Epoch: 5| Step: 1
Training loss: 2.3988543716632225
Validation loss: 2.5636515897269327

Epoch: 5| Step: 2
Training loss: 2.8186052813881703
Validation loss: 2.6052119264442863

Epoch: 5| Step: 3
Training loss: 2.6435963543193033
Validation loss: 2.616722276921113

Epoch: 5| Step: 4
Training loss: 2.799714336128263
Validation loss: 2.6524867946019275

Epoch: 5| Step: 5
Training loss: 3.066011556505295
Validation loss: 2.6743021357851986

Epoch: 5| Step: 6
Training loss: 3.1480546060598082
Validation loss: 2.675414836728

Epoch: 5| Step: 7
Training loss: 3.3160526729675177
Validation loss: 2.632179345516771

Epoch: 5| Step: 8
Training loss: 3.0819186152580698
Validation loss: 2.6194173806081653

Epoch: 5| Step: 9
Training loss: 3.0121655163723093
Validation loss: 2.6145347378580506

Epoch: 5| Step: 10
Training loss: 2.8647766787851934
Validation loss: 2.616500352389527

Epoch: 132| Step: 0
Training loss: 3.272864826519491
Validation loss: 2.6329596036454546

Epoch: 5| Step: 1
Training loss: 3.0074801967409632
Validation loss: 2.6162218908656576

Epoch: 5| Step: 2
Training loss: 3.3004795997519674
Validation loss: 2.6127647481641287

Epoch: 5| Step: 3
Training loss: 3.3518323811886046
Validation loss: 2.6114386290798492

Epoch: 5| Step: 4
Training loss: 2.2485900275776336
Validation loss: 2.619399206456049

Epoch: 5| Step: 5
Training loss: 2.653878174038963
Validation loss: 2.631655832148708

Epoch: 5| Step: 6
Training loss: 3.2666313409517134
Validation loss: 2.645963596983675

Epoch: 5| Step: 7
Training loss: 2.8855364576094615
Validation loss: 2.594345040332667

Epoch: 5| Step: 8
Training loss: 2.471128259804377
Validation loss: 2.5659372030915946

Epoch: 5| Step: 9
Training loss: 2.8199394169515593
Validation loss: 2.5997488473619703

Epoch: 5| Step: 10
Training loss: 2.7043475434910964
Validation loss: 2.6495037172923914

Epoch: 133| Step: 0
Training loss: 3.2428472008621756
Validation loss: 2.7090895632696492

Epoch: 5| Step: 1
Training loss: 3.0508265766679235
Validation loss: 2.7285835778586267

Epoch: 5| Step: 2
Training loss: 2.730340913718826
Validation loss: 2.7274411183829095

Epoch: 5| Step: 3
Training loss: 3.131333913078468
Validation loss: 2.765967138711736

Epoch: 5| Step: 4
Training loss: 3.0257729669837246
Validation loss: 2.8011381604060857

Epoch: 5| Step: 5
Training loss: 3.4816213084459378
Validation loss: 2.7945974690601623

Epoch: 5| Step: 6
Training loss: 2.9607007578715434
Validation loss: 2.730967507964245

Epoch: 5| Step: 7
Training loss: 2.551829941814485
Validation loss: 2.6947419458987736

Epoch: 5| Step: 8
Training loss: 2.7403849793509836
Validation loss: 2.6160899829541004

Epoch: 5| Step: 9
Training loss: 2.81816192379415
Validation loss: 2.610587198259111

Epoch: 5| Step: 10
Training loss: 3.248878578967522
Validation loss: 2.606644526516821

Epoch: 134| Step: 0
Training loss: 3.004574466985489
Validation loss: 2.603044553784424

Epoch: 5| Step: 1
Training loss: 3.312540018091851
Validation loss: 2.6017325134903975

Epoch: 5| Step: 2
Training loss: 3.0975769725530813
Validation loss: 2.605629824857874

Epoch: 5| Step: 3
Training loss: 2.901015459053011
Validation loss: 2.6108034745850115

Epoch: 5| Step: 4
Training loss: 2.78714017042377
Validation loss: 2.6047668146139697

Epoch: 5| Step: 5
Training loss: 2.7138397775468985
Validation loss: 2.5997940414170935

Epoch: 5| Step: 6
Training loss: 3.027985378073861
Validation loss: 2.5831936716784623

Epoch: 5| Step: 7
Training loss: 2.8575894143039844
Validation loss: 2.58456393341123

Epoch: 5| Step: 8
Training loss: 3.2630912040475697
Validation loss: 2.581694994123679

Epoch: 5| Step: 9
Training loss: 2.6620074537417913
Validation loss: 2.576698244037173

Epoch: 5| Step: 10
Training loss: 2.603388423344929
Validation loss: 2.579920740284531

Epoch: 135| Step: 0
Training loss: 3.017982312635361
Validation loss: 2.5740216018935898

Epoch: 5| Step: 1
Training loss: 2.8323226883987394
Validation loss: 2.57946484187813

Epoch: 5| Step: 2
Training loss: 2.720815465925902
Validation loss: 2.5786327400294073

Epoch: 5| Step: 3
Training loss: 2.8426588710918974
Validation loss: 2.583532239048982

Epoch: 5| Step: 4
Training loss: 3.1869947743655773
Validation loss: 2.5991000573053915

Epoch: 5| Step: 5
Training loss: 2.7527550854748974
Validation loss: 2.6044129577990796

Epoch: 5| Step: 6
Training loss: 2.8209501692120926
Validation loss: 2.615193308149008

Epoch: 5| Step: 7
Training loss: 3.019306209019828
Validation loss: 2.628505578066062

Epoch: 5| Step: 8
Training loss: 3.3609657956771763
Validation loss: 2.627244709357239

Epoch: 5| Step: 9
Training loss: 2.4658244701388217
Validation loss: 2.5940942517298313

Epoch: 5| Step: 10
Training loss: 3.046927427183161
Validation loss: 2.5832666301815563

Epoch: 136| Step: 0
Training loss: 2.8377520008189325
Validation loss: 2.5699233013448803

Epoch: 5| Step: 1
Training loss: 3.062393965150553
Validation loss: 2.567386837621322

Epoch: 5| Step: 2
Training loss: 1.8274407695768542
Validation loss: 2.5666809179786414

Epoch: 5| Step: 3
Training loss: 3.1465252921571394
Validation loss: 2.5685835296124573

Epoch: 5| Step: 4
Training loss: 2.8560413042282002
Validation loss: 2.5658582136352566

Epoch: 5| Step: 5
Training loss: 3.2404336252970922
Validation loss: 2.5689890067556274

Epoch: 5| Step: 6
Training loss: 3.2480923849600325
Validation loss: 2.5642824414124714

Epoch: 5| Step: 7
Training loss: 2.7662782059311866
Validation loss: 2.5732132576870184

Epoch: 5| Step: 8
Training loss: 2.988292898516921
Validation loss: 2.57393222475103

Epoch: 5| Step: 9
Training loss: 2.9632815139010065
Validation loss: 2.580705296997598

Epoch: 5| Step: 10
Training loss: 2.895819702848195
Validation loss: 2.587879838013568

Epoch: 137| Step: 0
Training loss: 3.0511991676181403
Validation loss: 2.602812367049058

Epoch: 5| Step: 1
Training loss: 3.422313087324972
Validation loss: 2.629838325615251

Epoch: 5| Step: 2
Training loss: 3.036564523575114
Validation loss: 2.632812513632178

Epoch: 5| Step: 3
Training loss: 2.6689791685958664
Validation loss: 2.627288165831264

Epoch: 5| Step: 4
Training loss: 2.628993584144399
Validation loss: 2.6071964940939103

Epoch: 5| Step: 5
Training loss: 2.788190176329639
Validation loss: 2.5833043531154525

Epoch: 5| Step: 6
Training loss: 2.989702034076887
Validation loss: 2.5684198010652337

Epoch: 5| Step: 7
Training loss: 2.3670932260002293
Validation loss: 2.564861926845182

Epoch: 5| Step: 8
Training loss: 2.792305820991518
Validation loss: 2.5638951321181973

Epoch: 5| Step: 9
Training loss: 2.9851654763417352
Validation loss: 2.560681089454587

Epoch: 5| Step: 10
Training loss: 3.2426107475056063
Validation loss: 2.5632612166733417

Epoch: 138| Step: 0
Training loss: 3.037227282427924
Validation loss: 2.560738863499736

Epoch: 5| Step: 1
Training loss: 3.329923761543262
Validation loss: 2.5549724061613035

Epoch: 5| Step: 2
Training loss: 2.502555685271707
Validation loss: 2.5462826134827936

Epoch: 5| Step: 3
Training loss: 2.649898609884853
Validation loss: 2.5343722845600376

Epoch: 5| Step: 4
Training loss: 2.816790635204268
Validation loss: 2.5307105950746145

Epoch: 5| Step: 5
Training loss: 2.9241092727636735
Validation loss: 2.531668833591577

Epoch: 5| Step: 6
Training loss: 2.94342660605657
Validation loss: 2.5371301963972526

Epoch: 5| Step: 7
Training loss: 3.0312817758684054
Validation loss: 2.5494189023937595

Epoch: 5| Step: 8
Training loss: 3.0594962823692162
Validation loss: 2.5476590898650815

Epoch: 5| Step: 9
Training loss: 2.957174763793673
Validation loss: 2.55747372641439

Epoch: 5| Step: 10
Training loss: 2.4433452261218536
Validation loss: 2.5593600229960507

Epoch: 139| Step: 0
Training loss: 3.2343764742788004
Validation loss: 2.5594410760522526

Epoch: 5| Step: 1
Training loss: 2.8814661040118685
Validation loss: 2.5464352031028556

Epoch: 5| Step: 2
Training loss: 2.86701303725643
Validation loss: 2.5433515541564637

Epoch: 5| Step: 3
Training loss: 2.639156316847924
Validation loss: 2.554269696839063

Epoch: 5| Step: 4
Training loss: 2.9432877681858667
Validation loss: 2.562202250231966

Epoch: 5| Step: 5
Training loss: 3.1680412989727693
Validation loss: 2.5710662136668

Epoch: 5| Step: 6
Training loss: 2.6763949170847834
Validation loss: 2.594927647320332

Epoch: 5| Step: 7
Training loss: 3.120751353784213
Validation loss: 2.586108874766654

Epoch: 5| Step: 8
Training loss: 2.790736959332442
Validation loss: 2.553342233894163

Epoch: 5| Step: 9
Training loss: 2.7035168490540054
Validation loss: 2.5522343781512364

Epoch: 5| Step: 10
Training loss: 2.6642476574047262
Validation loss: 2.548818861459266

Epoch: 140| Step: 0
Training loss: 2.8859018039612736
Validation loss: 2.541733070311675

Epoch: 5| Step: 1
Training loss: 2.5647870534207184
Validation loss: 2.5376859279464568

Epoch: 5| Step: 2
Training loss: 2.461349985582278
Validation loss: 2.5321209127227897

Epoch: 5| Step: 3
Training loss: 2.9315908530710026
Validation loss: 2.5335090246249474

Epoch: 5| Step: 4
Training loss: 2.740792813703755
Validation loss: 2.5258624147821203

Epoch: 5| Step: 5
Training loss: 3.362535276546991
Validation loss: 2.5278429066328885

Epoch: 5| Step: 6
Training loss: 3.265711294977864
Validation loss: 2.5282955339967037

Epoch: 5| Step: 7
Training loss: 3.026807065583809
Validation loss: 2.5359908715464203

Epoch: 5| Step: 8
Training loss: 2.5391032523772856
Validation loss: 2.527076169541583

Epoch: 5| Step: 9
Training loss: 2.9796851891767226
Validation loss: 2.536030645210815

Epoch: 5| Step: 10
Training loss: 2.847620080788819
Validation loss: 2.5358742420029072

Epoch: 141| Step: 0
Training loss: 2.160420461986694
Validation loss: 2.5417636736495273

Epoch: 5| Step: 1
Training loss: 2.961400300346375
Validation loss: 2.5457031364400446

Epoch: 5| Step: 2
Training loss: 2.795952842041846
Validation loss: 2.5575987861988514

Epoch: 5| Step: 3
Training loss: 3.272129279952007
Validation loss: 2.565997738148209

Epoch: 5| Step: 4
Training loss: 3.0173071088349426
Validation loss: 2.5624241221168997

Epoch: 5| Step: 5
Training loss: 3.220476150611539
Validation loss: 2.572688320057892

Epoch: 5| Step: 6
Training loss: 3.0580087543210053
Validation loss: 2.5812086748845813

Epoch: 5| Step: 7
Training loss: 2.7849841820423458
Validation loss: 2.5796131610795774

Epoch: 5| Step: 8
Training loss: 2.5749163456633513
Validation loss: 2.5867540035619965

Epoch: 5| Step: 9
Training loss: 2.5250799072010066
Validation loss: 2.5893466071220583

Epoch: 5| Step: 10
Training loss: 3.2021945997740016
Validation loss: 2.572989732584079

Epoch: 142| Step: 0
Training loss: 3.0266173838777695
Validation loss: 2.5518630948361047

Epoch: 5| Step: 1
Training loss: 2.6029507252399813
Validation loss: 2.554693691615825

Epoch: 5| Step: 2
Training loss: 3.2399250271446953
Validation loss: 2.5442712719808673

Epoch: 5| Step: 3
Training loss: 3.011801870661096
Validation loss: 2.558328343772318

Epoch: 5| Step: 4
Training loss: 2.9984800939034355
Validation loss: 2.554381058483308

Epoch: 5| Step: 5
Training loss: 2.5197327052757754
Validation loss: 2.5542417314640105

Epoch: 5| Step: 6
Training loss: 2.788980947632544
Validation loss: 2.5511505608860947

Epoch: 5| Step: 7
Training loss: 3.028111671756981
Validation loss: 2.5443466624786804

Epoch: 5| Step: 8
Training loss: 2.5590320473826136
Validation loss: 2.5454995005353744

Epoch: 5| Step: 9
Training loss: 3.1123465136328976
Validation loss: 2.5416029389728747

Epoch: 5| Step: 10
Training loss: 2.6413083969715836
Validation loss: 2.5352811527406764

Epoch: 143| Step: 0
Training loss: 2.2653363274136686
Validation loss: 2.556132609531182

Epoch: 5| Step: 1
Training loss: 3.1560412045147204
Validation loss: 2.5521547476190136

Epoch: 5| Step: 2
Training loss: 2.514367399344073
Validation loss: 2.556187200327705

Epoch: 5| Step: 3
Training loss: 2.7336178848583574
Validation loss: 2.5646514654678763

Epoch: 5| Step: 4
Training loss: 3.1060587772327346
Validation loss: 2.6111079736858165

Epoch: 5| Step: 5
Training loss: 3.112391862944078
Validation loss: 2.594545053991497

Epoch: 5| Step: 6
Training loss: 2.919507214756312
Validation loss: 2.5945296367977893

Epoch: 5| Step: 7
Training loss: 3.1910344891335543
Validation loss: 2.5681244506472787

Epoch: 5| Step: 8
Training loss: 2.8099222025843376
Validation loss: 2.5671230295459235

Epoch: 5| Step: 9
Training loss: 3.1824140176597644
Validation loss: 2.58264992817825

Epoch: 5| Step: 10
Training loss: 2.423315985441315
Validation loss: 2.5443074087544226

Epoch: 144| Step: 0
Training loss: 2.855327806242834
Validation loss: 2.5290328210072377

Epoch: 5| Step: 1
Training loss: 2.3026973083981326
Validation loss: 2.5286457170797525

Epoch: 5| Step: 2
Training loss: 3.082138465786025
Validation loss: 2.5254615837359347

Epoch: 5| Step: 3
Training loss: 2.887437207088308
Validation loss: 2.5281872031424197

Epoch: 5| Step: 4
Training loss: 2.948792847455065
Validation loss: 2.528245054535688

Epoch: 5| Step: 5
Training loss: 2.532126663420634
Validation loss: 2.5240989373647507

Epoch: 5| Step: 6
Training loss: 3.3339025647182847
Validation loss: 2.5272181080401106

Epoch: 5| Step: 7
Training loss: 2.9948189819859365
Validation loss: 2.5237483113168793

Epoch: 5| Step: 8
Training loss: 2.926115498211667
Validation loss: 2.524558529435396

Epoch: 5| Step: 9
Training loss: 2.823576837087623
Validation loss: 2.523324117421669

Epoch: 5| Step: 10
Training loss: 2.903543504129238
Validation loss: 2.5273840837413775

Epoch: 145| Step: 0
Training loss: 3.2143718980406693
Validation loss: 2.5361565895167466

Epoch: 5| Step: 1
Training loss: 2.8461169777780198
Validation loss: 2.549639450391544

Epoch: 5| Step: 2
Training loss: 2.7601997914080005
Validation loss: 2.5604213924987294

Epoch: 5| Step: 3
Training loss: 2.642676014014046
Validation loss: 2.551533594413528

Epoch: 5| Step: 4
Training loss: 2.567803361125986
Validation loss: 2.5519645383675704

Epoch: 5| Step: 5
Training loss: 2.697441874276459
Validation loss: 2.5602621435787913

Epoch: 5| Step: 6
Training loss: 2.6862814158807704
Validation loss: 2.5581725181398016

Epoch: 5| Step: 7
Training loss: 2.8820909046711356
Validation loss: 2.5457048554673047

Epoch: 5| Step: 8
Training loss: 3.1273338757982545
Validation loss: 2.5448424709914543

Epoch: 5| Step: 9
Training loss: 2.8947566018046156
Validation loss: 2.552086892710437

Epoch: 5| Step: 10
Training loss: 3.228520498947092
Validation loss: 2.5771207283495445

Epoch: 146| Step: 0
Training loss: 3.0117776471624307
Validation loss: 2.5868713350354815

Epoch: 5| Step: 1
Training loss: 2.6690685859291894
Validation loss: 2.5836029137014633

Epoch: 5| Step: 2
Training loss: 3.021328133585609
Validation loss: 2.579798799753763

Epoch: 5| Step: 3
Training loss: 2.5308368486973083
Validation loss: 2.5602824542647573

Epoch: 5| Step: 4
Training loss: 2.5099744182970016
Validation loss: 2.5533565624132195

Epoch: 5| Step: 5
Training loss: 3.0455529107780466
Validation loss: 2.55265756910119

Epoch: 5| Step: 6
Training loss: 2.663663146215442
Validation loss: 2.55098113484274

Epoch: 5| Step: 7
Training loss: 3.2491170710884187
Validation loss: 2.551553557613947

Epoch: 5| Step: 8
Training loss: 2.939303716873582
Validation loss: 2.543615447067011

Epoch: 5| Step: 9
Training loss: 2.7676568622466755
Validation loss: 2.5332167041865685

Epoch: 5| Step: 10
Training loss: 3.1830937466827613
Validation loss: 2.527072027460937

Epoch: 147| Step: 0
Training loss: 3.2233234986316615
Validation loss: 2.532949022507009

Epoch: 5| Step: 1
Training loss: 2.961975720848913
Validation loss: 2.527462328126614

Epoch: 5| Step: 2
Training loss: 2.920408809210628
Validation loss: 2.537269791136677

Epoch: 5| Step: 3
Training loss: 2.9691418840857087
Validation loss: 2.5443213115622054

Epoch: 5| Step: 4
Training loss: 2.691607685053083
Validation loss: 2.5553260555345028

Epoch: 5| Step: 5
Training loss: 3.1866804079001594
Validation loss: 2.586561048948045

Epoch: 5| Step: 6
Training loss: 2.652122522041115
Validation loss: 2.579408140244885

Epoch: 5| Step: 7
Training loss: 2.5613165192648744
Validation loss: 2.5573250544689468

Epoch: 5| Step: 8
Training loss: 2.9609238113449248
Validation loss: 2.545321937896612

Epoch: 5| Step: 9
Training loss: 2.9791850554069903
Validation loss: 2.550728345079644

Epoch: 5| Step: 10
Training loss: 2.3779603678077263
Validation loss: 2.5452973913800148

Epoch: 148| Step: 0
Training loss: 2.6331723473830855
Validation loss: 2.5336073787379907

Epoch: 5| Step: 1
Training loss: 2.805108593965301
Validation loss: 2.521460632470176

Epoch: 5| Step: 2
Training loss: 2.8854842378896084
Validation loss: 2.52216556288864

Epoch: 5| Step: 3
Training loss: 2.585600678327443
Validation loss: 2.5221410491839977

Epoch: 5| Step: 4
Training loss: 2.4948178942316446
Validation loss: 2.5233410679340533

Epoch: 5| Step: 5
Training loss: 2.9892855683128268
Validation loss: 2.516447659993489

Epoch: 5| Step: 6
Training loss: 3.1684169616846236
Validation loss: 2.5274280937801232

Epoch: 5| Step: 7
Training loss: 3.0042399009070744
Validation loss: 2.538422034728765

Epoch: 5| Step: 8
Training loss: 3.3029620488591167
Validation loss: 2.5362868830447884

Epoch: 5| Step: 9
Training loss: 2.7689210033782508
Validation loss: 2.547737380729062

Epoch: 5| Step: 10
Training loss: 2.7682313868219772
Validation loss: 2.5682559852185496

Epoch: 149| Step: 0
Training loss: 3.099602759966555
Validation loss: 2.5957605175702754

Epoch: 5| Step: 1
Training loss: 2.90780597995558
Validation loss: 2.59429217791426

Epoch: 5| Step: 2
Training loss: 2.707157632979392
Validation loss: 2.5852597232619505

Epoch: 5| Step: 3
Training loss: 2.6434948015704847
Validation loss: 2.5817353049192433

Epoch: 5| Step: 4
Training loss: 3.0335222360108176
Validation loss: 2.594750070343259

Epoch: 5| Step: 5
Training loss: 2.9624227457395573
Validation loss: 2.6172014290260357

Epoch: 5| Step: 6
Training loss: 3.3462942550976025
Validation loss: 2.6374540600928382

Epoch: 5| Step: 7
Training loss: 2.636257193398644
Validation loss: 2.6364060992329232

Epoch: 5| Step: 8
Training loss: 2.7478154782474635
Validation loss: 2.600905498308017

Epoch: 5| Step: 9
Training loss: 2.7850407687478556
Validation loss: 2.5760701188710167

Epoch: 5| Step: 10
Training loss: 2.6559202999370894
Validation loss: 2.554650227560572

Epoch: 150| Step: 0
Training loss: 2.6183442705080986
Validation loss: 2.5445905544093157

Epoch: 5| Step: 1
Training loss: 3.333321968695023
Validation loss: 2.545436080973986

Epoch: 5| Step: 2
Training loss: 2.785847154180408
Validation loss: 2.5440164389465156

Epoch: 5| Step: 3
Training loss: 3.3579362494101255
Validation loss: 2.5369271628003243

Epoch: 5| Step: 4
Training loss: 2.384549667740205
Validation loss: 2.5239820752146134

Epoch: 5| Step: 5
Training loss: 3.0181407811298726
Validation loss: 2.522069041530473

Epoch: 5| Step: 6
Training loss: 3.310472839787941
Validation loss: 2.5188021516308012

Epoch: 5| Step: 7
Training loss: 2.511693025875513
Validation loss: 2.512112784164715

Epoch: 5| Step: 8
Training loss: 2.420644336704956
Validation loss: 2.5227290847187414

Epoch: 5| Step: 9
Training loss: 2.8148656432914723
Validation loss: 2.5343811335713937

Epoch: 5| Step: 10
Training loss: 2.7718582170014923
Validation loss: 2.524915824923936

Epoch: 151| Step: 0
Training loss: 2.364673853638601
Validation loss: 2.5201636712832123

Epoch: 5| Step: 1
Training loss: 2.8588081173145454
Validation loss: 2.5140575125837206

Epoch: 5| Step: 2
Training loss: 3.1613399141978684
Validation loss: 2.5163728232634965

Epoch: 5| Step: 3
Training loss: 2.835672833831898
Validation loss: 2.520863196137541

Epoch: 5| Step: 4
Training loss: 3.3520878733494945
Validation loss: 2.517610906292081

Epoch: 5| Step: 5
Training loss: 2.6533632636498754
Validation loss: 2.5159532112130325

Epoch: 5| Step: 6
Training loss: 2.8133878366183676
Validation loss: 2.5196881986159436

Epoch: 5| Step: 7
Training loss: 2.913316892087214
Validation loss: 2.525911557485896

Epoch: 5| Step: 8
Training loss: 2.4895332576126146
Validation loss: 2.536150186362394

Epoch: 5| Step: 9
Training loss: 2.9728464875272858
Validation loss: 2.5327158837961066

Epoch: 5| Step: 10
Training loss: 2.870122836205738
Validation loss: 2.539445347852145

Epoch: 152| Step: 0
Training loss: 2.753192349150287
Validation loss: 2.547733841773107

Epoch: 5| Step: 1
Training loss: 3.012649253851732
Validation loss: 2.547155891579724

Epoch: 5| Step: 2
Training loss: 3.198844766707459
Validation loss: 2.54215941417752

Epoch: 5| Step: 3
Training loss: 2.9046549367900565
Validation loss: 2.565069434592572

Epoch: 5| Step: 4
Training loss: 2.1262131762133176
Validation loss: 2.5920744048914646

Epoch: 5| Step: 5
Training loss: 2.716954833429244
Validation loss: 2.626499122978972

Epoch: 5| Step: 6
Training loss: 3.3620793302799536
Validation loss: 2.6605710115585928

Epoch: 5| Step: 7
Training loss: 2.7763308624349405
Validation loss: 2.621247709039162

Epoch: 5| Step: 8
Training loss: 2.7216281783338947
Validation loss: 2.576661184527657

Epoch: 5| Step: 9
Training loss: 2.493859379026002
Validation loss: 2.5167974497621963

Epoch: 5| Step: 10
Training loss: 3.141772312104809
Validation loss: 2.5070858651706964

Epoch: 153| Step: 0
Training loss: 2.702694809038646
Validation loss: 2.515251165011381

Epoch: 5| Step: 1
Training loss: 2.751379707325813
Validation loss: 2.5172837203457283

Epoch: 5| Step: 2
Training loss: 3.3967974333693682
Validation loss: 2.526280563588598

Epoch: 5| Step: 3
Training loss: 2.704064531165722
Validation loss: 2.5293761801836703

Epoch: 5| Step: 4
Training loss: 2.8374787653325932
Validation loss: 2.532378739716747

Epoch: 5| Step: 5
Training loss: 2.763650911608876
Validation loss: 2.531541267509314

Epoch: 5| Step: 6
Training loss: 2.643723605409714
Validation loss: 2.5315982250423845

Epoch: 5| Step: 7
Training loss: 2.588302867371948
Validation loss: 2.5319785474014775

Epoch: 5| Step: 8
Training loss: 3.207672315266774
Validation loss: 2.53299563512418

Epoch: 5| Step: 9
Training loss: 3.390767459249826
Validation loss: 2.5325277180802797

Epoch: 5| Step: 10
Training loss: 2.909395054339365
Validation loss: 2.526096368181957

Epoch: 154| Step: 0
Training loss: 2.7190721693657265
Validation loss: 2.5225748040062124

Epoch: 5| Step: 1
Training loss: 2.1683691256494084
Validation loss: 2.5244410919381863

Epoch: 5| Step: 2
Training loss: 2.8775470894839
Validation loss: 2.526209386330527

Epoch: 5| Step: 3
Training loss: 2.3852769458169525
Validation loss: 2.527267415088197

Epoch: 5| Step: 4
Training loss: 2.583326883205442
Validation loss: 2.5477189614006717

Epoch: 5| Step: 5
Training loss: 3.365075956170365
Validation loss: 2.579207279755561

Epoch: 5| Step: 6
Training loss: 2.735604233326309
Validation loss: 2.61492809465256

Epoch: 5| Step: 7
Training loss: 3.0654494426828394
Validation loss: 2.6150785286984672

Epoch: 5| Step: 8
Training loss: 3.3442385307731874
Validation loss: 2.6266596050593325

Epoch: 5| Step: 9
Training loss: 2.8561483219003763
Validation loss: 2.6599361884057457

Epoch: 5| Step: 10
Training loss: 3.2804881346734662
Validation loss: 2.628247020033337

Epoch: 155| Step: 0
Training loss: 2.7731433981112548
Validation loss: 2.5616532243999934

Epoch: 5| Step: 1
Training loss: 2.782838946157367
Validation loss: 2.531196282739833

Epoch: 5| Step: 2
Training loss: 2.958762303444826
Validation loss: 2.5118727942586014

Epoch: 5| Step: 3
Training loss: 3.0986689755709653
Validation loss: 2.5173903930303787

Epoch: 5| Step: 4
Training loss: 3.332591323917617
Validation loss: 2.5213511050578705

Epoch: 5| Step: 5
Training loss: 3.1012307092880795
Validation loss: 2.5367391710083997

Epoch: 5| Step: 6
Training loss: 2.624779101568597
Validation loss: 2.528428363891044

Epoch: 5| Step: 7
Training loss: 2.670248060525919
Validation loss: 2.521568284425333

Epoch: 5| Step: 8
Training loss: 2.8979991982447726
Validation loss: 2.51895979804465

Epoch: 5| Step: 9
Training loss: 2.4590445852748144
Validation loss: 2.506745810906573

Epoch: 5| Step: 10
Training loss: 2.542217090811956
Validation loss: 2.510469481958888

Epoch: 156| Step: 0
Training loss: 3.187474718180605
Validation loss: 2.514064429350908

Epoch: 5| Step: 1
Training loss: 2.3769144072314004
Validation loss: 2.5132448736151596

Epoch: 5| Step: 2
Training loss: 2.5329332759425776
Validation loss: 2.5217001785701743

Epoch: 5| Step: 3
Training loss: 3.171782543920754
Validation loss: 2.5261572678279993

Epoch: 5| Step: 4
Training loss: 2.407095030001822
Validation loss: 2.531694908647498

Epoch: 5| Step: 5
Training loss: 2.6806526781406714
Validation loss: 2.5400299950061496

Epoch: 5| Step: 6
Training loss: 2.8865092902272735
Validation loss: 2.565387063890807

Epoch: 5| Step: 7
Training loss: 3.073244049391714
Validation loss: 2.579872944361491

Epoch: 5| Step: 8
Training loss: 3.0237115937814183
Validation loss: 2.6198751197808186

Epoch: 5| Step: 9
Training loss: 2.59549002135006
Validation loss: 2.6113270058181848

Epoch: 5| Step: 10
Training loss: 3.064887692508159
Validation loss: 2.6303199149024423

Epoch: 157| Step: 0
Training loss: 2.772314225655433
Validation loss: 2.6039007596675834

Epoch: 5| Step: 1
Training loss: 2.716879892074993
Validation loss: 2.600813875492226

Epoch: 5| Step: 2
Training loss: 3.6203580930009696
Validation loss: 2.625290128512565

Epoch: 5| Step: 3
Training loss: 2.551337702812292
Validation loss: 2.597954374013175

Epoch: 5| Step: 4
Training loss: 2.7478415948669523
Validation loss: 2.561991977630643

Epoch: 5| Step: 5
Training loss: 2.8780014293208493
Validation loss: 2.542339422178312

Epoch: 5| Step: 6
Training loss: 2.65052141781875
Validation loss: 2.536158586929652

Epoch: 5| Step: 7
Training loss: 3.0538163369742297
Validation loss: 2.5328099042241194

Epoch: 5| Step: 8
Training loss: 2.8249520896967493
Validation loss: 2.5460110352832226

Epoch: 5| Step: 9
Training loss: 2.5785108797688214
Validation loss: 2.5484852660616637

Epoch: 5| Step: 10
Training loss: 2.7098372367600687
Validation loss: 2.54625037097088

Epoch: 158| Step: 0
Training loss: 2.693006242004708
Validation loss: 2.5318023441586504

Epoch: 5| Step: 1
Training loss: 2.153015917934003
Validation loss: 2.5276518232945975

Epoch: 5| Step: 2
Training loss: 2.8032837651603297
Validation loss: 2.5438996512984415

Epoch: 5| Step: 3
Training loss: 2.4003444384732218
Validation loss: 2.5750382018050666

Epoch: 5| Step: 4
Training loss: 3.2030929935996197
Validation loss: 2.603952175700336

Epoch: 5| Step: 5
Training loss: 2.918917214547768
Validation loss: 2.5913716341150517

Epoch: 5| Step: 6
Training loss: 2.792162286594419
Validation loss: 2.552224947173187

Epoch: 5| Step: 7
Training loss: 2.673907126241146
Validation loss: 2.536362045922254

Epoch: 5| Step: 8
Training loss: 2.9554082531022483
Validation loss: 2.544268978652801

Epoch: 5| Step: 9
Training loss: 3.4288666944292983
Validation loss: 2.5254492479960886

Epoch: 5| Step: 10
Training loss: 2.851615508122466
Validation loss: 2.5194735119223064

Epoch: 159| Step: 0
Training loss: 2.797028691848055
Validation loss: 2.515742319650668

Epoch: 5| Step: 1
Training loss: 2.861844356695214
Validation loss: 2.5200583591237287

Epoch: 5| Step: 2
Training loss: 2.9458421792451017
Validation loss: 2.5283952559308047

Epoch: 5| Step: 3
Training loss: 2.796847977321229
Validation loss: 2.523320743865984

Epoch: 5| Step: 4
Training loss: 2.831483985377322
Validation loss: 2.5290198306107325

Epoch: 5| Step: 5
Training loss: 2.817796424903635
Validation loss: 2.561869626027595

Epoch: 5| Step: 6
Training loss: 2.735411354944941
Validation loss: 2.6142252551146177

Epoch: 5| Step: 7
Training loss: 2.795610877414359
Validation loss: 2.697334085699543

Epoch: 5| Step: 8
Training loss: 2.9129608771973783
Validation loss: 2.8447855988789614

Epoch: 5| Step: 9
Training loss: 2.780197287221103
Validation loss: 2.847475800892747

Epoch: 5| Step: 10
Training loss: 3.139269332185826
Validation loss: 2.7890814956363315

Epoch: 160| Step: 0
Training loss: 2.8517001184150925
Validation loss: 2.656017739687547

Epoch: 5| Step: 1
Training loss: 2.838276552657911
Validation loss: 2.528972326651167

Epoch: 5| Step: 2
Training loss: 2.712463828693879
Validation loss: 2.5034414691928837

Epoch: 5| Step: 3
Training loss: 2.8116514833315853
Validation loss: 2.51882278034735

Epoch: 5| Step: 4
Training loss: 2.8606871215662713
Validation loss: 2.536045574452839

Epoch: 5| Step: 5
Training loss: 2.9504506752896065
Validation loss: 2.5837119920217138

Epoch: 5| Step: 6
Training loss: 3.3057345992751332
Validation loss: 2.716181414760891

Epoch: 5| Step: 7
Training loss: 3.0035751021349606
Validation loss: 2.6962669029863915

Epoch: 5| Step: 8
Training loss: 3.1457670259540182
Validation loss: 2.727089410194426

Epoch: 5| Step: 9
Training loss: 2.9156502905563433
Validation loss: 2.6393340804063783

Epoch: 5| Step: 10
Training loss: 3.2885382227637443
Validation loss: 2.5881442691813024

Epoch: 161| Step: 0
Training loss: 3.1117562994964842
Validation loss: 2.539077110027626

Epoch: 5| Step: 1
Training loss: 2.5992344242651826
Validation loss: 2.5237116424574895

Epoch: 5| Step: 2
Training loss: 2.8813514211682105
Validation loss: 2.555946625100134

Epoch: 5| Step: 3
Training loss: 2.489675661128077
Validation loss: 2.5817357964498786

Epoch: 5| Step: 4
Training loss: 2.9243959373707833
Validation loss: 2.590677014735704

Epoch: 5| Step: 5
Training loss: 3.323287098166636
Validation loss: 2.6276864555493225

Epoch: 5| Step: 6
Training loss: 3.402974224691332
Validation loss: 2.6283290846080463

Epoch: 5| Step: 7
Training loss: 2.548556001248119
Validation loss: 2.653248422309794

Epoch: 5| Step: 8
Training loss: 2.47066886787639
Validation loss: 2.6015230571428916

Epoch: 5| Step: 9
Training loss: 2.679516133425875
Validation loss: 2.5782335225592647

Epoch: 5| Step: 10
Training loss: 3.1102695424330853
Validation loss: 2.5626480335903

Epoch: 162| Step: 0
Training loss: 2.72612962319717
Validation loss: 2.538086107191501

Epoch: 5| Step: 1
Training loss: 2.8931812427762362
Validation loss: 2.5184007526747165

Epoch: 5| Step: 2
Training loss: 3.0218354941530396
Validation loss: 2.5077230372173043

Epoch: 5| Step: 3
Training loss: 3.2533915503040585
Validation loss: 2.501551214539596

Epoch: 5| Step: 4
Training loss: 2.502127123938379
Validation loss: 2.514835097858687

Epoch: 5| Step: 5
Training loss: 2.507508066303214
Validation loss: 2.539205343489555

Epoch: 5| Step: 6
Training loss: 2.669839541010593
Validation loss: 2.546293547491995

Epoch: 5| Step: 7
Training loss: 3.031195571253449
Validation loss: 2.5566027713613257

Epoch: 5| Step: 8
Training loss: 2.77474205605325
Validation loss: 2.5610823222518695

Epoch: 5| Step: 9
Training loss: 3.250405212963749
Validation loss: 2.5572425037745363

Epoch: 5| Step: 10
Training loss: 2.131002028014544
Validation loss: 2.563946885958119

Epoch: 163| Step: 0
Training loss: 2.6504807593944935
Validation loss: 2.566046123204663

Epoch: 5| Step: 1
Training loss: 2.7536619253874672
Validation loss: 2.543540082267404

Epoch: 5| Step: 2
Training loss: 2.4128599659282846
Validation loss: 2.5316201656799566

Epoch: 5| Step: 3
Training loss: 3.407422205260144
Validation loss: 2.5122322567173834

Epoch: 5| Step: 4
Training loss: 3.303392233094112
Validation loss: 2.5164457589981657

Epoch: 5| Step: 5
Training loss: 3.028200168680512
Validation loss: 2.5267201642218162

Epoch: 5| Step: 6
Training loss: 2.660205185225839
Validation loss: 2.5314866358841277

Epoch: 5| Step: 7
Training loss: 2.620928012934887
Validation loss: 2.5194971073219183

Epoch: 5| Step: 8
Training loss: 3.0584141470256383
Validation loss: 2.5112047921990466

Epoch: 5| Step: 9
Training loss: 2.296398087379498
Validation loss: 2.5242317463763078

Epoch: 5| Step: 10
Training loss: 2.634807430809457
Validation loss: 2.520584453831918

Epoch: 164| Step: 0
Training loss: 2.933695500586442
Validation loss: 2.526870654096526

Epoch: 5| Step: 1
Training loss: 2.534970974727798
Validation loss: 2.510070550895564

Epoch: 5| Step: 2
Training loss: 3.276015111252583
Validation loss: 2.5033657735985995

Epoch: 5| Step: 3
Training loss: 3.1118080932755157
Validation loss: 2.504998209771341

Epoch: 5| Step: 4
Training loss: 2.4057613718889286
Validation loss: 2.513940603796623

Epoch: 5| Step: 5
Training loss: 2.2675167210140095
Validation loss: 2.519779469793481

Epoch: 5| Step: 6
Training loss: 2.838952849584777
Validation loss: 2.547284525495443

Epoch: 5| Step: 7
Training loss: 2.8156357133092085
Validation loss: 2.5655325686394246

Epoch: 5| Step: 8
Training loss: 2.715128009651693
Validation loss: 2.599919990147775

Epoch: 5| Step: 9
Training loss: 2.9602864941284546
Validation loss: 2.6407905667966327

Epoch: 5| Step: 10
Training loss: 3.1635995031619046
Validation loss: 2.6515044923181086

Epoch: 165| Step: 0
Training loss: 2.3021311920392606
Validation loss: 2.563110594956584

Epoch: 5| Step: 1
Training loss: 3.228611034868948
Validation loss: 2.547327125933665

Epoch: 5| Step: 2
Training loss: 2.8271327517375737
Validation loss: 2.513727776994622

Epoch: 5| Step: 3
Training loss: 2.256068945723979
Validation loss: 2.50489988985053

Epoch: 5| Step: 4
Training loss: 2.8668119512011603
Validation loss: 2.499319943869872

Epoch: 5| Step: 5
Training loss: 3.2228869176443875
Validation loss: 2.498598575543685

Epoch: 5| Step: 6
Training loss: 2.7383897354468525
Validation loss: 2.489668192639828

Epoch: 5| Step: 7
Training loss: 3.1334008784487626
Validation loss: 2.4975037622928986

Epoch: 5| Step: 8
Training loss: 2.569086031502636
Validation loss: 2.4929034816772004

Epoch: 5| Step: 9
Training loss: 2.963877644905357
Validation loss: 2.4917916668818054

Epoch: 5| Step: 10
Training loss: 2.3484214513132606
Validation loss: 2.49456541481081

Epoch: 166| Step: 0
Training loss: 2.508208151531426
Validation loss: 2.4953007740028257

Epoch: 5| Step: 1
Training loss: 2.469564858690307
Validation loss: 2.496108862130353

Epoch: 5| Step: 2
Training loss: 3.0489646592686572
Validation loss: 2.5083190152930857

Epoch: 5| Step: 3
Training loss: 2.93920378276974
Validation loss: 2.5145066295717102

Epoch: 5| Step: 4
Training loss: 2.796612945725719
Validation loss: 2.5610002260117337

Epoch: 5| Step: 5
Training loss: 3.028018448001192
Validation loss: 2.6231174466983522

Epoch: 5| Step: 6
Training loss: 2.742379467105448
Validation loss: 2.619100900679905

Epoch: 5| Step: 7
Training loss: 2.538022341780929
Validation loss: 2.6624158596863525

Epoch: 5| Step: 8
Training loss: 2.867392051946408
Validation loss: 2.663594808553708

Epoch: 5| Step: 9
Training loss: 2.710967577676715
Validation loss: 2.6156880779964333

Epoch: 5| Step: 10
Training loss: 3.150651404223428
Validation loss: 2.5926088129810014

Epoch: 167| Step: 0
Training loss: 2.7752560952726766
Validation loss: 2.5581993863074652

Epoch: 5| Step: 1
Training loss: 2.347894894471607
Validation loss: 2.5297137740821647

Epoch: 5| Step: 2
Training loss: 2.3688664792694514
Validation loss: 2.515251184376911

Epoch: 5| Step: 3
Training loss: 2.930481175045723
Validation loss: 2.5078197396468136

Epoch: 5| Step: 4
Training loss: 2.5709063646854635
Validation loss: 2.5137344070704577

Epoch: 5| Step: 5
Training loss: 3.0494070633666395
Validation loss: 2.504377587112548

Epoch: 5| Step: 6
Training loss: 2.8417384820031657
Validation loss: 2.5015641067466006

Epoch: 5| Step: 7
Training loss: 2.867299257018157
Validation loss: 2.4941049896828735

Epoch: 5| Step: 8
Training loss: 3.6044211472357977
Validation loss: 2.5006243490127074

Epoch: 5| Step: 9
Training loss: 2.2633540907157492
Validation loss: 2.4945700949079654

Epoch: 5| Step: 10
Training loss: 2.978906384459822
Validation loss: 2.5017622345997013

Epoch: 168| Step: 0
Training loss: 3.128335926974127
Validation loss: 2.5092405630325003

Epoch: 5| Step: 1
Training loss: 2.639435539734643
Validation loss: 2.51937967963604

Epoch: 5| Step: 2
Training loss: 2.8906779516370493
Validation loss: 2.527209154823031

Epoch: 5| Step: 3
Training loss: 2.888374070813754
Validation loss: 2.5353455553658804

Epoch: 5| Step: 4
Training loss: 2.725828755195184
Validation loss: 2.554197726754822

Epoch: 5| Step: 5
Training loss: 2.9743786908355467
Validation loss: 2.58798600005417

Epoch: 5| Step: 6
Training loss: 2.545671424358112
Validation loss: 2.5910837005340546

Epoch: 5| Step: 7
Training loss: 2.937260557114963
Validation loss: 2.6249645805020196

Epoch: 5| Step: 8
Training loss: 2.7972175771941337
Validation loss: 2.603656259703641

Epoch: 5| Step: 9
Training loss: 2.6985892460250795
Validation loss: 2.592422995910028

Epoch: 5| Step: 10
Training loss: 2.129984227511613
Validation loss: 2.572167905899058

Epoch: 169| Step: 0
Training loss: 2.7833669085580954
Validation loss: 2.5362151112432088

Epoch: 5| Step: 1
Training loss: 1.825196422823532
Validation loss: 2.545025640557918

Epoch: 5| Step: 2
Training loss: 2.5501596064265293
Validation loss: 2.5395867848131624

Epoch: 5| Step: 3
Training loss: 2.847976729330081
Validation loss: 2.5381658286200817

Epoch: 5| Step: 4
Training loss: 3.0738776477000163
Validation loss: 2.505938975868432

Epoch: 5| Step: 5
Training loss: 2.7932591427378823
Validation loss: 2.5169279606526502

Epoch: 5| Step: 6
Training loss: 3.155760774371764
Validation loss: 2.5130623970162933

Epoch: 5| Step: 7
Training loss: 3.0648640441611588
Validation loss: 2.5200190353114102

Epoch: 5| Step: 8
Training loss: 2.744658397549371
Validation loss: 2.5300597868157153

Epoch: 5| Step: 9
Training loss: 2.5733920030214206
Validation loss: 2.5474390748669085

Epoch: 5| Step: 10
Training loss: 2.6498607311000466
Validation loss: 2.5432458796527664

Epoch: 170| Step: 0
Training loss: 2.819373230642898
Validation loss: 2.5348717794902798

Epoch: 5| Step: 1
Training loss: 2.622242705575859
Validation loss: 2.548003264320021

Epoch: 5| Step: 2
Training loss: 2.192641510175518
Validation loss: 2.5813762391292165

Epoch: 5| Step: 3
Training loss: 2.7886877155401764
Validation loss: 2.594075947106031

Epoch: 5| Step: 4
Training loss: 2.419967195272756
Validation loss: 2.5881422866300365

Epoch: 5| Step: 5
Training loss: 3.1369510246347536
Validation loss: 2.5863003405736977

Epoch: 5| Step: 6
Training loss: 3.0410799131170276
Validation loss: 2.5522291056873474

Epoch: 5| Step: 7
Training loss: 2.9649482879503526
Validation loss: 2.550131442168702

Epoch: 5| Step: 8
Training loss: 3.447502149729235
Validation loss: 2.546217944301919

Epoch: 5| Step: 9
Training loss: 2.1028034843016856
Validation loss: 2.5468178284735346

Epoch: 5| Step: 10
Training loss: 2.2656595161702673
Validation loss: 2.539609671449263

Epoch: 171| Step: 0
Training loss: 2.382963282082555
Validation loss: 2.529866381120195

Epoch: 5| Step: 1
Training loss: 2.8237597249451682
Validation loss: 2.5273450412820804

Epoch: 5| Step: 2
Training loss: 2.611593981885527
Validation loss: 2.5538823687694823

Epoch: 5| Step: 3
Training loss: 2.689898285768583
Validation loss: 2.5469489243830754

Epoch: 5| Step: 4
Training loss: 3.3330568834744723
Validation loss: 2.6050214786197934

Epoch: 5| Step: 5
Training loss: 2.5462523091174196
Validation loss: 2.6049900261154613

Epoch: 5| Step: 6
Training loss: 2.96237703221066
Validation loss: 2.5864445082397123

Epoch: 5| Step: 7
Training loss: 2.471206022806136
Validation loss: 2.5853866517365844

Epoch: 5| Step: 8
Training loss: 3.246698903805626
Validation loss: 2.5714033679301598

Epoch: 5| Step: 9
Training loss: 2.443956285438485
Validation loss: 2.5459231775995304

Epoch: 5| Step: 10
Training loss: 2.2995661326315333
Validation loss: 2.530228700837303

Epoch: 172| Step: 0
Training loss: 3.142249906385889
Validation loss: 2.533460070781208

Epoch: 5| Step: 1
Training loss: 2.8039967315861567
Validation loss: 2.5405642668759194

Epoch: 5| Step: 2
Training loss: 3.0377525507169287
Validation loss: 2.5316111728415334

Epoch: 5| Step: 3
Training loss: 2.692709376164621
Validation loss: 2.560568228680348

Epoch: 5| Step: 4
Training loss: 2.367451265955349
Validation loss: 2.6066170256831365

Epoch: 5| Step: 5
Training loss: 2.4949520646193855
Validation loss: 2.653443187228251

Epoch: 5| Step: 6
Training loss: 2.9816509816876824
Validation loss: 2.626593314251402

Epoch: 5| Step: 7
Training loss: 2.4217464289839237
Validation loss: 2.5811509716620864

Epoch: 5| Step: 8
Training loss: 2.958431743722201
Validation loss: 2.5392466296756058

Epoch: 5| Step: 9
Training loss: 2.868219756279581
Validation loss: 2.502503880370991

Epoch: 5| Step: 10
Training loss: 2.4306746559632555
Validation loss: 2.5019463673862563

Epoch: 173| Step: 0
Training loss: 2.9483817624401767
Validation loss: 2.5051330383854893

Epoch: 5| Step: 1
Training loss: 2.229447272872155
Validation loss: 2.5155077584467396

Epoch: 5| Step: 2
Training loss: 2.855131074532094
Validation loss: 2.538629495127925

Epoch: 5| Step: 3
Training loss: 3.245159652849972
Validation loss: 2.5439509578646367

Epoch: 5| Step: 4
Training loss: 2.7009948981419454
Validation loss: 2.591050745101044

Epoch: 5| Step: 5
Training loss: 2.435955144929629
Validation loss: 2.6205203364996046

Epoch: 5| Step: 6
Training loss: 2.905077954295242
Validation loss: 2.693119541232047

Epoch: 5| Step: 7
Training loss: 2.6936511240644783
Validation loss: 2.734016107542196

Epoch: 5| Step: 8
Training loss: 2.1333055310623195
Validation loss: 2.7637858503949007

Epoch: 5| Step: 9
Training loss: 3.1602362208863055
Validation loss: 2.7534510184811736

Epoch: 5| Step: 10
Training loss: 2.584115207442283
Validation loss: 2.61243530278112

Epoch: 174| Step: 0
Training loss: 2.796031974031178
Validation loss: 2.530168108420122

Epoch: 5| Step: 1
Training loss: 2.7472023171103497
Validation loss: 2.492535205581365

Epoch: 5| Step: 2
Training loss: 2.941892869877643
Validation loss: 2.494965673203078

Epoch: 5| Step: 3
Training loss: 2.669091364091792
Validation loss: 2.499827448724967

Epoch: 5| Step: 4
Training loss: 3.1098362566168576
Validation loss: 2.5013061915607415

Epoch: 5| Step: 5
Training loss: 2.411236735654015
Validation loss: 2.510871604641182

Epoch: 5| Step: 6
Training loss: 3.1467607827847774
Validation loss: 2.508103466842665

Epoch: 5| Step: 7
Training loss: 2.6298321344738858
Validation loss: 2.557174976355589

Epoch: 5| Step: 8
Training loss: 2.8367636241846217
Validation loss: 2.556182659622203

Epoch: 5| Step: 9
Training loss: 2.8138788869750533
Validation loss: 2.5821290833130637

Epoch: 5| Step: 10
Training loss: 3.1050331050072426
Validation loss: 2.6074892740885676

Epoch: 175| Step: 0
Training loss: 2.9622893053290382
Validation loss: 2.5799658047119935

Epoch: 5| Step: 1
Training loss: 2.2564760892663287
Validation loss: 2.5804971480735786

Epoch: 5| Step: 2
Training loss: 3.1907466734459575
Validation loss: 2.580060978879744

Epoch: 5| Step: 3
Training loss: 2.5791988101696175
Validation loss: 2.5881353835955676

Epoch: 5| Step: 4
Training loss: 2.618427586339241
Validation loss: 2.639290032573818

Epoch: 5| Step: 5
Training loss: 2.7935491639046455
Validation loss: 2.692743579918408

Epoch: 5| Step: 6
Training loss: 2.8905228880296288
Validation loss: 2.684076872601264

Epoch: 5| Step: 7
Training loss: 2.8677119884936486
Validation loss: 2.5895669443026694

Epoch: 5| Step: 8
Training loss: 2.85806644702547
Validation loss: 2.571733906746198

Epoch: 5| Step: 9
Training loss: 2.634065052772993
Validation loss: 2.535438883738837

Epoch: 5| Step: 10
Training loss: 2.901255427942618
Validation loss: 2.5335645344557567

Epoch: 176| Step: 0
Training loss: 3.0638557080289504
Validation loss: 2.517051739058784

Epoch: 5| Step: 1
Training loss: 2.932578326363814
Validation loss: 2.538190097665863

Epoch: 5| Step: 2
Training loss: 3.089228398793872
Validation loss: 2.584077610435907

Epoch: 5| Step: 3
Training loss: 2.74393122949977
Validation loss: 2.6106265287199815

Epoch: 5| Step: 4
Training loss: 2.3072369456350215
Validation loss: 2.6211862708682445

Epoch: 5| Step: 5
Training loss: 2.6851287849271377
Validation loss: 2.597739578009732

Epoch: 5| Step: 6
Training loss: 3.2271255112796213
Validation loss: 2.576165509108979

Epoch: 5| Step: 7
Training loss: 3.091800730661288
Validation loss: 2.5775004913580095

Epoch: 5| Step: 8
Training loss: 2.4400405359809545
Validation loss: 2.5928273759842675

Epoch: 5| Step: 9
Training loss: 2.327027234864375
Validation loss: 2.5845322701372946

Epoch: 5| Step: 10
Training loss: 2.6440384150612912
Validation loss: 2.5938834393134163

Epoch: 177| Step: 0
Training loss: 2.824276407795564
Validation loss: 2.591019832428908

Epoch: 5| Step: 1
Training loss: 2.2592324408460587
Validation loss: 2.632539503427534

Epoch: 5| Step: 2
Training loss: 2.5085643936478164
Validation loss: 2.6784145163747466

Epoch: 5| Step: 3
Training loss: 2.5307000587130846
Validation loss: 2.7121022966787565

Epoch: 5| Step: 4
Training loss: 2.5579301978303977
Validation loss: 2.728015797591052

Epoch: 5| Step: 5
Training loss: 2.838800671627873
Validation loss: 2.7162955282814547

Epoch: 5| Step: 6
Training loss: 3.0707434431883556
Validation loss: 2.623598784411083

Epoch: 5| Step: 7
Training loss: 2.3016538147379917
Validation loss: 2.5697085606121823

Epoch: 5| Step: 8
Training loss: 3.1009211802031538
Validation loss: 2.5398235746033477

Epoch: 5| Step: 9
Training loss: 3.013908095135021
Validation loss: 2.5311469327117337

Epoch: 5| Step: 10
Training loss: 2.9466465526717096
Validation loss: 2.4901664419316254

Epoch: 178| Step: 0
Training loss: 2.3768218230669245
Validation loss: 2.4856659531598617

Epoch: 5| Step: 1
Training loss: 2.7740490736082637
Validation loss: 2.4813474664989768

Epoch: 5| Step: 2
Training loss: 2.7101088254973855
Validation loss: 2.501846316704266

Epoch: 5| Step: 3
Training loss: 2.7434457353884802
Validation loss: 2.5096368188988007

Epoch: 5| Step: 4
Training loss: 3.2894108603652072
Validation loss: 2.508657516572594

Epoch: 5| Step: 5
Training loss: 2.6068448346152584
Validation loss: 2.5313278899266902

Epoch: 5| Step: 6
Training loss: 2.54693491110516
Validation loss: 2.542669265618407

Epoch: 5| Step: 7
Training loss: 3.2218426411406966
Validation loss: 2.5757588386751897

Epoch: 5| Step: 8
Training loss: 2.365447560034092
Validation loss: 2.5740836847493656

Epoch: 5| Step: 9
Training loss: 2.454505871925627
Validation loss: 2.5759840492238633

Epoch: 5| Step: 10
Training loss: 2.543830221724801
Validation loss: 2.5803494484768525

Epoch: 179| Step: 0
Training loss: 3.174309759128654
Validation loss: 2.56795221610035

Epoch: 5| Step: 1
Training loss: 2.893216512785719
Validation loss: 2.552711967576233

Epoch: 5| Step: 2
Training loss: 2.6885378408324727
Validation loss: 2.5594677125477383

Epoch: 5| Step: 3
Training loss: 2.380329176313617
Validation loss: 2.589149034595346

Epoch: 5| Step: 4
Training loss: 2.4951517778301944
Validation loss: 2.5782640784453816

Epoch: 5| Step: 5
Training loss: 2.879568036851608
Validation loss: 2.5585087953472465

Epoch: 5| Step: 6
Training loss: 2.3855648966436926
Validation loss: 2.557999005173442

Epoch: 5| Step: 7
Training loss: 2.5058814484121337
Validation loss: 2.5387697506383824

Epoch: 5| Step: 8
Training loss: 2.533273900322019
Validation loss: 2.528263694830064

Epoch: 5| Step: 9
Training loss: 2.9443075959975094
Validation loss: 2.5413535510417207

Epoch: 5| Step: 10
Training loss: 2.404125613474169
Validation loss: 2.576869247348245

Epoch: 180| Step: 0
Training loss: 2.638627510064908
Validation loss: 2.588798798543893

Epoch: 5| Step: 1
Training loss: 2.316090245427276
Validation loss: 2.5686999964100568

Epoch: 5| Step: 2
Training loss: 2.4346386669982003
Validation loss: 2.543878111342296

Epoch: 5| Step: 3
Training loss: 2.9080432568655628
Validation loss: 2.548204748389473

Epoch: 5| Step: 4
Training loss: 2.336829892151916
Validation loss: 2.5800770697657085

Epoch: 5| Step: 5
Training loss: 3.0156457139326642
Validation loss: 2.6068216000741105

Epoch: 5| Step: 6
Training loss: 2.6169299554076737
Validation loss: 2.64451104737433

Epoch: 5| Step: 7
Training loss: 2.8935136537864197
Validation loss: 2.676355158444699

Epoch: 5| Step: 8
Training loss: 2.7893337256788096
Validation loss: 2.6591723499380113

Epoch: 5| Step: 9
Training loss: 2.779291813752639
Validation loss: 2.573397087675784

Epoch: 5| Step: 10
Training loss: 2.535357310076491
Validation loss: 2.52537009053967

Epoch: 181| Step: 0
Training loss: 2.9564424480357068
Validation loss: 2.5049145333351444

Epoch: 5| Step: 1
Training loss: 2.5830965138656876
Validation loss: 2.4867552483098136

Epoch: 5| Step: 2
Training loss: 2.6022784190250072
Validation loss: 2.48148581682784

Epoch: 5| Step: 3
Training loss: 2.0832565166298678
Validation loss: 2.4826674678698937

Epoch: 5| Step: 4
Training loss: 2.3312044195469714
Validation loss: 2.482923752363164

Epoch: 5| Step: 5
Training loss: 3.17450548661263
Validation loss: 2.49420150060815

Epoch: 5| Step: 6
Training loss: 2.9365046011825204
Validation loss: 2.482646030681846

Epoch: 5| Step: 7
Training loss: 2.958145959498989
Validation loss: 2.4893514218212367

Epoch: 5| Step: 8
Training loss: 2.52118622592805
Validation loss: 2.528189022299498

Epoch: 5| Step: 9
Training loss: 2.951499531984494
Validation loss: 2.5464890690489694

Epoch: 5| Step: 10
Training loss: 2.808150000394056
Validation loss: 2.5887211107521555

Epoch: 182| Step: 0
Training loss: 2.976141151382794
Validation loss: 2.599344939481125

Epoch: 5| Step: 1
Training loss: 2.5341424310845175
Validation loss: 2.583998829257664

Epoch: 5| Step: 2
Training loss: 2.8561120932777966
Validation loss: 2.5758167472899838

Epoch: 5| Step: 3
Training loss: 2.2778536453121103
Validation loss: 2.6034143187210868

Epoch: 5| Step: 4
Training loss: 2.5607511553833895
Validation loss: 2.6514976556235617

Epoch: 5| Step: 5
Training loss: 2.5103776118827112
Validation loss: 2.6859865451049654

Epoch: 5| Step: 6
Training loss: 2.329819644938615
Validation loss: 2.6919090922504516

Epoch: 5| Step: 7
Training loss: 2.5617670080834505
Validation loss: 2.7068724918132476

Epoch: 5| Step: 8
Training loss: 3.1305256628237603
Validation loss: 2.6968365631446267

Epoch: 5| Step: 9
Training loss: 2.53035371712669
Validation loss: 2.6125552313339395

Epoch: 5| Step: 10
Training loss: 2.882256017385662
Validation loss: 2.5626162961055856

Epoch: 183| Step: 0
Training loss: 2.410201852821459
Validation loss: 2.524548998622653

Epoch: 5| Step: 1
Training loss: 2.7225418833023394
Validation loss: 2.5108817473958287

Epoch: 5| Step: 2
Training loss: 3.153494056600495
Validation loss: 2.4926709942348233

Epoch: 5| Step: 3
Training loss: 2.8733802876836414
Validation loss: 2.4889916583469693

Epoch: 5| Step: 4
Training loss: 2.450017138829911
Validation loss: 2.486688874864247

Epoch: 5| Step: 5
Training loss: 2.6405486146611956
Validation loss: 2.4864571673218516

Epoch: 5| Step: 6
Training loss: 2.806676642731661
Validation loss: 2.486488199416579

Epoch: 5| Step: 7
Training loss: 2.405233688738503
Validation loss: 2.500839927024347

Epoch: 5| Step: 8
Training loss: 2.76204704265047
Validation loss: 2.514461250446702

Epoch: 5| Step: 9
Training loss: 2.5900232589443206
Validation loss: 2.569110540326605

Epoch: 5| Step: 10
Training loss: 2.498949879394411
Validation loss: 2.6593007341052317

Epoch: 184| Step: 0
Training loss: 2.4224034871027147
Validation loss: 2.749904253347207

Epoch: 5| Step: 1
Training loss: 2.9002763616486598
Validation loss: 2.887551126185961

Epoch: 5| Step: 2
Training loss: 3.215871468191283
Validation loss: 2.962478351492285

Epoch: 5| Step: 3
Training loss: 2.926039721247369
Validation loss: 2.8859852651549467

Epoch: 5| Step: 4
Training loss: 2.722958431687311
Validation loss: 2.665549446717029

Epoch: 5| Step: 5
Training loss: 2.2271206340277043
Validation loss: 2.5440640680964357

Epoch: 5| Step: 6
Training loss: 3.0557411503539216
Validation loss: 2.4566997918343594

Epoch: 5| Step: 7
Training loss: 2.5070413610076763
Validation loss: 2.462374480788915

Epoch: 5| Step: 8
Training loss: 2.497253626068565
Validation loss: 2.466010430754685

Epoch: 5| Step: 9
Training loss: 2.9095930335338265
Validation loss: 2.4776429577869443

Epoch: 5| Step: 10
Training loss: 2.8127365012868495
Validation loss: 2.4756127109622246

Epoch: 185| Step: 0
Training loss: 2.4208475209891165
Validation loss: 2.4884565345776983

Epoch: 5| Step: 1
Training loss: 2.964216766606098
Validation loss: 2.502719349750269

Epoch: 5| Step: 2
Training loss: 2.2704855509661357
Validation loss: 2.5045319467593563

Epoch: 5| Step: 3
Training loss: 2.603779074753327
Validation loss: 2.4787007762110904

Epoch: 5| Step: 4
Training loss: 3.081654185931231
Validation loss: 2.4940336753768393

Epoch: 5| Step: 5
Training loss: 3.019204342851209
Validation loss: 2.4868779430761605

Epoch: 5| Step: 6
Training loss: 2.7545147162747328
Validation loss: 2.4835455488793947

Epoch: 5| Step: 7
Training loss: 2.8734169623764756
Validation loss: 2.4832991137324787

Epoch: 5| Step: 8
Training loss: 2.801951654642023
Validation loss: 2.4884147714467306

Epoch: 5| Step: 9
Training loss: 2.880205500476587
Validation loss: 2.5056724675253457

Epoch: 5| Step: 10
Training loss: 3.0051163913319
Validation loss: 2.525470493407858

Epoch: 186| Step: 0
Training loss: 2.6605873150763197
Validation loss: 2.5375004544740887

Epoch: 5| Step: 1
Training loss: 2.8104954675740705
Validation loss: 2.5861024421354006

Epoch: 5| Step: 2
Training loss: 2.913440300427533
Validation loss: 2.652190704862065

Epoch: 5| Step: 3
Training loss: 1.9464446300879064
Validation loss: 2.654636442617913

Epoch: 5| Step: 4
Training loss: 2.572638297112475
Validation loss: 2.6819651759325116

Epoch: 5| Step: 5
Training loss: 3.0508156358097374
Validation loss: 2.6678208467020217

Epoch: 5| Step: 6
Training loss: 2.428992659638183
Validation loss: 2.6494449605376404

Epoch: 5| Step: 7
Training loss: 2.5415965419746964
Validation loss: 2.648671808143893

Epoch: 5| Step: 8
Training loss: 2.7167026220957373
Validation loss: 2.6137085739712402

Epoch: 5| Step: 9
Training loss: 2.460941956531183
Validation loss: 2.5935314663131646

Epoch: 5| Step: 10
Training loss: 2.7938718389445696
Validation loss: 2.5818816925079733

Epoch: 187| Step: 0
Training loss: 2.6470584486044824
Validation loss: 2.5708100747767064

Epoch: 5| Step: 1
Training loss: 2.307220205286785
Validation loss: 2.551830038258802

Epoch: 5| Step: 2
Training loss: 2.702173142618361
Validation loss: 2.546520946118459

Epoch: 5| Step: 3
Training loss: 2.8045544606057593
Validation loss: 2.5431058609257597

Epoch: 5| Step: 4
Training loss: 2.1370806901805963
Validation loss: 2.5258333300193945

Epoch: 5| Step: 5
Training loss: 2.364273140568858
Validation loss: 2.5441219635460737

Epoch: 5| Step: 6
Training loss: 2.9469554578653017
Validation loss: 2.5444409684916653

Epoch: 5| Step: 7
Training loss: 2.7698098971964966
Validation loss: 2.5772734711496352

Epoch: 5| Step: 8
Training loss: 2.8606937890077946
Validation loss: 2.598325762167372

Epoch: 5| Step: 9
Training loss: 2.186328901434224
Validation loss: 2.6325781407430617

Epoch: 5| Step: 10
Training loss: 2.7389522932897155
Validation loss: 2.7090998117959226

Epoch: 188| Step: 0
Training loss: 2.440164234856439
Validation loss: 2.807379822101509

Epoch: 5| Step: 1
Training loss: 2.268910308302552
Validation loss: 2.819651336477112

Epoch: 5| Step: 2
Training loss: 2.301180793513103
Validation loss: 2.8500059115152987

Epoch: 5| Step: 3
Training loss: 2.7171595514405515
Validation loss: 2.842673922862394

Epoch: 5| Step: 4
Training loss: 2.972788102262277
Validation loss: 2.786490027763311

Epoch: 5| Step: 5
Training loss: 2.8417933513186915
Validation loss: 2.674376570666271

Epoch: 5| Step: 6
Training loss: 2.0834524374930314
Validation loss: 2.5634389828194655

Epoch: 5| Step: 7
Training loss: 2.572949016743478
Validation loss: 2.4865661037539337

Epoch: 5| Step: 8
Training loss: 2.688941214273901
Validation loss: 2.4480714869887925

Epoch: 5| Step: 9
Training loss: 3.23890773846954
Validation loss: 2.4492034165843033

Epoch: 5| Step: 10
Training loss: 2.782621409876947
Validation loss: 2.449543717542046

Epoch: 189| Step: 0
Training loss: 3.007532993557415
Validation loss: 2.467124862014478

Epoch: 5| Step: 1
Training loss: 2.768786417633355
Validation loss: 2.462032545216938

Epoch: 5| Step: 2
Training loss: 2.8099025175894825
Validation loss: 2.4919883691419544

Epoch: 5| Step: 3
Training loss: 2.8425523520608276
Validation loss: 2.513391538542635

Epoch: 5| Step: 4
Training loss: 2.9520167940690683
Validation loss: 2.516992504915732

Epoch: 5| Step: 5
Training loss: 1.9079515960999385
Validation loss: 2.5495175668337002

Epoch: 5| Step: 6
Training loss: 2.5063010916888913
Validation loss: 2.5577937753232676

Epoch: 5| Step: 7
Training loss: 2.2763547238303685
Validation loss: 2.587331473151278

Epoch: 5| Step: 8
Training loss: 2.563345420752683
Validation loss: 2.640626582478763

Epoch: 5| Step: 9
Training loss: 2.454966151825745
Validation loss: 2.6579674628077905

Epoch: 5| Step: 10
Training loss: 2.7754240416542535
Validation loss: 2.6630991677555684

Epoch: 190| Step: 0
Training loss: 2.6061588042699415
Validation loss: 2.638486551256061

Epoch: 5| Step: 1
Training loss: 2.57326127394487
Validation loss: 2.602906933357432

Epoch: 5| Step: 2
Training loss: 2.1944155778341
Validation loss: 2.588836585445486

Epoch: 5| Step: 3
Training loss: 2.56891925931678
Validation loss: 2.558667606332661

Epoch: 5| Step: 4
Training loss: 2.818988520982855
Validation loss: 2.563080219496412

Epoch: 5| Step: 5
Training loss: 2.805352517346444
Validation loss: 2.5777220280880186

Epoch: 5| Step: 6
Training loss: 2.746959305685744
Validation loss: 2.5733788958439288

Epoch: 5| Step: 7
Training loss: 1.951488694443869
Validation loss: 2.577207721447885

Epoch: 5| Step: 8
Training loss: 2.0937430538233075
Validation loss: 2.591209824311384

Epoch: 5| Step: 9
Training loss: 2.9031787354061334
Validation loss: 2.612809709232351

Epoch: 5| Step: 10
Training loss: 2.6520107773781914
Validation loss: 2.6267013154035705

Epoch: 191| Step: 0
Training loss: 2.3327817491981735
Validation loss: 2.680725071857927

Epoch: 5| Step: 1
Training loss: 2.440844661972448
Validation loss: 2.70241021298754

Epoch: 5| Step: 2
Training loss: 2.1528295394526573
Validation loss: 2.695706468977337

Epoch: 5| Step: 3
Training loss: 2.739825239246797
Validation loss: 2.670359394359176

Epoch: 5| Step: 4
Training loss: 2.98488736373045
Validation loss: 2.6418562410150326

Epoch: 5| Step: 5
Training loss: 2.2732685458925403
Validation loss: 2.600874134024719

Epoch: 5| Step: 6
Training loss: 2.6406771863486913
Validation loss: 2.5560890174944078

Epoch: 5| Step: 7
Training loss: 2.3693804261817872
Validation loss: 2.5880545016204963

Epoch: 5| Step: 8
Training loss: 2.131810438464085
Validation loss: 2.604733931910694

Epoch: 5| Step: 9
Training loss: 2.785063368865673
Validation loss: 2.6242941470402115

Epoch: 5| Step: 10
Training loss: 2.9036091937617323
Validation loss: 2.621823075524293

Epoch: 192| Step: 0
Training loss: 2.655014199400322
Validation loss: 2.609429603316303

Epoch: 5| Step: 1
Training loss: 2.375633657149127
Validation loss: 2.615643472202347

Epoch: 5| Step: 2
Training loss: 2.7912208049253544
Validation loss: 2.5962458726072803

Epoch: 5| Step: 3
Training loss: 2.5906139856709465
Validation loss: 2.5685155108554536

Epoch: 5| Step: 4
Training loss: 2.783610852810215
Validation loss: 2.556298003578514

Epoch: 5| Step: 5
Training loss: 2.4929770053211597
Validation loss: 2.5529093554315363

Epoch: 5| Step: 6
Training loss: 2.4609168642177965
Validation loss: 2.546774375966592

Epoch: 5| Step: 7
Training loss: 2.2913126122909664
Validation loss: 2.577261091452054

Epoch: 5| Step: 8
Training loss: 2.1826724598007052
Validation loss: 2.613989107792562

Epoch: 5| Step: 9
Training loss: 2.6669398008975245
Validation loss: 2.6652149054393988

Epoch: 5| Step: 10
Training loss: 2.2752019059010933
Validation loss: 2.7461491076257807

Epoch: 193| Step: 0
Training loss: 1.9982949379781678
Validation loss: 2.7515250179059207

Epoch: 5| Step: 1
Training loss: 2.738120342321207
Validation loss: 2.768259078726356

Epoch: 5| Step: 2
Training loss: 2.3010445461943054
Validation loss: 2.708525491970058

Epoch: 5| Step: 3
Training loss: 2.456838918657266
Validation loss: 2.657775105214053

Epoch: 5| Step: 4
Training loss: 2.3835298052637324
Validation loss: 2.6084235951568786

Epoch: 5| Step: 5
Training loss: 2.7725919912227406
Validation loss: 2.583094621724749

Epoch: 5| Step: 6
Training loss: 2.6634331012829597
Validation loss: 2.562567205020516

Epoch: 5| Step: 7
Training loss: 2.8533642237170627
Validation loss: 2.555443985300192

Epoch: 5| Step: 8
Training loss: 2.3037731361158826
Validation loss: 2.5500590557037666

Epoch: 5| Step: 9
Training loss: 2.7690989771684262
Validation loss: 2.5685380908192204

Epoch: 5| Step: 10
Training loss: 2.109550638304008
Validation loss: 2.5935213166335114

Epoch: 194| Step: 0
Training loss: 2.435039941667711
Validation loss: 2.59774496337344

Epoch: 5| Step: 1
Training loss: 2.460525429755281
Validation loss: 2.646276008859106

Epoch: 5| Step: 2
Training loss: 2.815640878579672
Validation loss: 2.657515689586408

Epoch: 5| Step: 3
Training loss: 2.098542834128568
Validation loss: 2.706879361018204

Epoch: 5| Step: 4
Training loss: 2.108977103675648
Validation loss: 2.7050565748436193

Epoch: 5| Step: 5
Training loss: 2.645654977709278
Validation loss: 2.6894252412626245

Epoch: 5| Step: 6
Training loss: 2.380766743961712
Validation loss: 2.6281866994641607

Epoch: 5| Step: 7
Training loss: 2.5252458924774763
Validation loss: 2.6064853910026913

Epoch: 5| Step: 8
Training loss: 2.404961278052494
Validation loss: 2.5771088557503576

Epoch: 5| Step: 9
Training loss: 2.665306270814375
Validation loss: 2.566386734978217

Epoch: 5| Step: 10
Training loss: 2.8509044149131326
Validation loss: 2.559599492663627

Epoch: 195| Step: 0
Training loss: 2.6189700305064427
Validation loss: 2.586933811140405

Epoch: 5| Step: 1
Training loss: 2.3155870195123485
Validation loss: 2.5929316793808095

Epoch: 5| Step: 2
Training loss: 2.548663301363729
Validation loss: 2.588829344599676

Epoch: 5| Step: 3
Training loss: 2.656760222854969
Validation loss: 2.617249712803808

Epoch: 5| Step: 4
Training loss: 2.5917484879738137
Validation loss: 2.603690972637721

Epoch: 5| Step: 5
Training loss: 2.5800081715713143
Validation loss: 2.6355220230977845

Epoch: 5| Step: 6
Training loss: 2.43886948285484
Validation loss: 2.648365320447879

Epoch: 5| Step: 7
Training loss: 2.3264812837032736
Validation loss: 2.672648612139112

Epoch: 5| Step: 8
Training loss: 2.284724685476947
Validation loss: 2.6711025746654404

Epoch: 5| Step: 9
Training loss: 2.514435670610442
Validation loss: 2.6912683965731703

Epoch: 5| Step: 10
Training loss: 1.9348825186420635
Validation loss: 2.7134785866354836

Epoch: 196| Step: 0
Training loss: 2.5343256972629087
Validation loss: 2.724728805294975

Epoch: 5| Step: 1
Training loss: 2.475659323061698
Validation loss: 2.6638240946307135

Epoch: 5| Step: 2
Training loss: 1.8261896305955008
Validation loss: 2.6490867371453035

Epoch: 5| Step: 3
Training loss: 2.6921974646881477
Validation loss: 2.6135602161096756

Epoch: 5| Step: 4
Training loss: 2.459374212824733
Validation loss: 2.598447692593401

Epoch: 5| Step: 5
Training loss: 2.765163577106117
Validation loss: 2.6171542806388977

Epoch: 5| Step: 6
Training loss: 2.431236239592928
Validation loss: 2.603623239894077

Epoch: 5| Step: 7
Training loss: 2.6512715078270146
Validation loss: 2.5846520755192013

Epoch: 5| Step: 8
Training loss: 2.511723875808825
Validation loss: 2.578128616564151

Epoch: 5| Step: 9
Training loss: 1.7973884843978012
Validation loss: 2.570748944005272

Epoch: 5| Step: 10
Training loss: 2.622390903643786
Validation loss: 2.576235587776163

Epoch: 197| Step: 0
Training loss: 2.909665305694473
Validation loss: 2.60937963530377

Epoch: 5| Step: 1
Training loss: 2.4262346958815653
Validation loss: 2.622136955722779

Epoch: 5| Step: 2
Training loss: 2.155955640078168
Validation loss: 2.658816130384147

Epoch: 5| Step: 3
Training loss: 2.6117007917630612
Validation loss: 2.7153758798405723

Epoch: 5| Step: 4
Training loss: 2.005958740388159
Validation loss: 2.6884515722719553

Epoch: 5| Step: 5
Training loss: 1.8613310710807613
Validation loss: 2.706403147354571

Epoch: 5| Step: 6
Training loss: 2.3298534147461085
Validation loss: 2.6789361718485165

Epoch: 5| Step: 7
Training loss: 2.0759137083726227
Validation loss: 2.616611483566615

Epoch: 5| Step: 8
Training loss: 2.7063987180095075
Validation loss: 2.5946216514726053

Epoch: 5| Step: 9
Training loss: 3.017341718085834
Validation loss: 2.6114420758146224

Epoch: 5| Step: 10
Training loss: 2.328943915000168
Validation loss: 2.58603799201677

Epoch: 198| Step: 0
Training loss: 2.378655481510351
Validation loss: 2.583128126755503

Epoch: 5| Step: 1
Training loss: 2.025048869920829
Validation loss: 2.567344485160374

Epoch: 5| Step: 2
Training loss: 2.677006484139605
Validation loss: 2.5494049911839234

Epoch: 5| Step: 3
Training loss: 2.484782827240112
Validation loss: 2.571264518607349

Epoch: 5| Step: 4
Training loss: 2.7036214383653134
Validation loss: 2.550167415478918

Epoch: 5| Step: 5
Training loss: 2.453118779848802
Validation loss: 2.572330573168789

Epoch: 5| Step: 6
Training loss: 2.1104173133700987
Validation loss: 2.5887458961531014

Epoch: 5| Step: 7
Training loss: 2.696161108908221
Validation loss: 2.6134271428770974

Epoch: 5| Step: 8
Training loss: 2.105633391275554
Validation loss: 2.639954521336559

Epoch: 5| Step: 9
Training loss: 2.6764898767990717
Validation loss: 2.644343605872412

Epoch: 5| Step: 10
Training loss: 2.2453729949213383
Validation loss: 2.650153884049442

Epoch: 199| Step: 0
Training loss: 2.215473280690244
Validation loss: 2.6629346110846774

Epoch: 5| Step: 1
Training loss: 2.2035450636356737
Validation loss: 2.6513921482341445

Epoch: 5| Step: 2
Training loss: 2.33184169593162
Validation loss: 2.6359406141367807

Epoch: 5| Step: 3
Training loss: 2.432944221826167
Validation loss: 2.6129992077617485

Epoch: 5| Step: 4
Training loss: 2.0235294041327023
Validation loss: 2.5844818232430646

Epoch: 5| Step: 5
Training loss: 2.6014794688678435
Validation loss: 2.6011725702614035

Epoch: 5| Step: 6
Training loss: 2.720302796058941
Validation loss: 2.569758547809288

Epoch: 5| Step: 7
Training loss: 2.6665966700268235
Validation loss: 2.586789095934677

Epoch: 5| Step: 8
Training loss: 2.487551979020265
Validation loss: 2.5909043452093203

Epoch: 5| Step: 9
Training loss: 2.6434702695932
Validation loss: 2.608072478592537

Epoch: 5| Step: 10
Training loss: 1.9578663763014528
Validation loss: 2.622814171779209

Epoch: 200| Step: 0
Training loss: 2.2650827745550353
Validation loss: 2.6272962940197657

Epoch: 5| Step: 1
Training loss: 2.779723016127096
Validation loss: 2.6575478671120862

Epoch: 5| Step: 2
Training loss: 2.5400496691255383
Validation loss: 2.6393290509014142

Epoch: 5| Step: 3
Training loss: 2.5594772560642736
Validation loss: 2.622066198266981

Epoch: 5| Step: 4
Training loss: 2.662869183371621
Validation loss: 2.59081881042454

Epoch: 5| Step: 5
Training loss: 2.487272096861476
Validation loss: 2.6123623178891386

Epoch: 5| Step: 6
Training loss: 2.186309599546592
Validation loss: 2.5899780314846463

Epoch: 5| Step: 7
Training loss: 2.2819293330130708
Validation loss: 2.5952147424970455

Epoch: 5| Step: 8
Training loss: 2.4591787684095556
Validation loss: 2.6037413225544346

Epoch: 5| Step: 9
Training loss: 1.8573150764511903
Validation loss: 2.6198604965064924

Epoch: 5| Step: 10
Training loss: 2.190303749549205
Validation loss: 2.660472803876419

Testing loss: 2.74990696219842
