Epoch: 1| Step: 0
Training loss: 5.378046035766602
Validation loss: 5.153235645704372

Epoch: 6| Step: 1
Training loss: 4.248871326446533
Validation loss: 5.125345235229821

Epoch: 6| Step: 2
Training loss: 5.037677764892578
Validation loss: 5.095553244313886

Epoch: 6| Step: 3
Training loss: 5.105262279510498
Validation loss: 5.064348713044198

Epoch: 6| Step: 4
Training loss: 4.289008140563965
Validation loss: 5.031345300776984

Epoch: 6| Step: 5
Training loss: 5.537624359130859
Validation loss: 4.994830813459171

Epoch: 6| Step: 6
Training loss: 3.97999906539917
Validation loss: 4.953983409430391

Epoch: 6| Step: 7
Training loss: 6.1366801261901855
Validation loss: 4.910083704097296

Epoch: 6| Step: 8
Training loss: 3.6578564643859863
Validation loss: 4.861658332168415

Epoch: 6| Step: 9
Training loss: 4.797491073608398
Validation loss: 4.808235999076597

Epoch: 6| Step: 10
Training loss: 4.951371192932129
Validation loss: 4.751866074018581

Epoch: 6| Step: 11
Training loss: 4.420541763305664
Validation loss: 4.694133773926766

Epoch: 6| Step: 12
Training loss: 3.727546215057373
Validation loss: 4.633297463899018

Epoch: 6| Step: 13
Training loss: 4.37317419052124
Validation loss: 4.572900413185038

Epoch: 2| Step: 0
Training loss: 5.278669357299805
Validation loss: 4.5119322525557655

Epoch: 6| Step: 1
Training loss: 3.6691339015960693
Validation loss: 4.451467452510711

Epoch: 6| Step: 2
Training loss: 4.385589122772217
Validation loss: 4.392264386659027

Epoch: 6| Step: 3
Training loss: 4.491789817810059
Validation loss: 4.334232212394796

Epoch: 6| Step: 4
Training loss: 3.9913721084594727
Validation loss: 4.275397316102059

Epoch: 6| Step: 5
Training loss: 5.3705244064331055
Validation loss: 4.218882206947573

Epoch: 6| Step: 6
Training loss: 5.114928245544434
Validation loss: 4.15988705747871

Epoch: 6| Step: 7
Training loss: 4.117252349853516
Validation loss: 4.103899237930134

Epoch: 6| Step: 8
Training loss: 3.6220643520355225
Validation loss: 4.051625887552897

Epoch: 6| Step: 9
Training loss: 3.4552407264709473
Validation loss: 3.999324511456233

Epoch: 6| Step: 10
Training loss: 2.8073878288269043
Validation loss: 3.946726670829199

Epoch: 6| Step: 11
Training loss: 3.2517290115356445
Validation loss: 3.8862940906196513

Epoch: 6| Step: 12
Training loss: 3.206134080886841
Validation loss: 3.8100511540648756

Epoch: 6| Step: 13
Training loss: 2.345414876937866
Validation loss: 3.764558966441821

Epoch: 3| Step: 0
Training loss: 3.2223012447357178
Validation loss: 3.7340306261534333

Epoch: 6| Step: 1
Training loss: 3.9291443824768066
Validation loss: 3.698029225872409

Epoch: 6| Step: 2
Training loss: 2.5455663204193115
Validation loss: 3.6550682231944096

Epoch: 6| Step: 3
Training loss: 4.360447883605957
Validation loss: 3.614520472864951

Epoch: 6| Step: 4
Training loss: 3.6397225856781006
Validation loss: 3.5812581867300053

Epoch: 6| Step: 5
Training loss: 4.184901237487793
Validation loss: 3.5433842674378426

Epoch: 6| Step: 6
Training loss: 2.8526482582092285
Validation loss: 3.51158373073865

Epoch: 6| Step: 7
Training loss: 3.8469460010528564
Validation loss: 3.4826177294536302

Epoch: 6| Step: 8
Training loss: 4.740697383880615
Validation loss: 3.4567244309251026

Epoch: 6| Step: 9
Training loss: 2.413578987121582
Validation loss: 3.428760451655234

Epoch: 6| Step: 10
Training loss: 3.088693141937256
Validation loss: 3.402770073183121

Epoch: 6| Step: 11
Training loss: 3.1283340454101562
Validation loss: 3.3772366764724895

Epoch: 6| Step: 12
Training loss: 2.8931596279144287
Validation loss: 3.353398428168348

Epoch: 6| Step: 13
Training loss: 3.4924392700195312
Validation loss: 3.332022995077154

Epoch: 4| Step: 0
Training loss: 3.643336772918701
Validation loss: 3.3128434432450162

Epoch: 6| Step: 1
Training loss: 3.572904586791992
Validation loss: 3.2947523465720554

Epoch: 6| Step: 2
Training loss: 3.601353645324707
Validation loss: 3.273913527047762

Epoch: 6| Step: 3
Training loss: 2.059554100036621
Validation loss: 3.258479415729482

Epoch: 6| Step: 4
Training loss: 2.342834949493408
Validation loss: 3.2471983842952277

Epoch: 6| Step: 5
Training loss: 3.7303388118743896
Validation loss: 3.234775391958093

Epoch: 6| Step: 6
Training loss: 3.237508535385132
Validation loss: 3.2226548605067755

Epoch: 6| Step: 7
Training loss: 2.9425582885742188
Validation loss: 3.2134278128224034

Epoch: 6| Step: 8
Training loss: 2.673068046569824
Validation loss: 3.2181741165858444

Epoch: 6| Step: 9
Training loss: 3.2375376224517822
Validation loss: 3.2253503312346754

Epoch: 6| Step: 10
Training loss: 4.150381088256836
Validation loss: 3.2454824447631836

Epoch: 6| Step: 11
Training loss: 3.7392427921295166
Validation loss: 3.1870449896781676

Epoch: 6| Step: 12
Training loss: 3.336698055267334
Validation loss: 3.1653917040876163

Epoch: 6| Step: 13
Training loss: 2.526848316192627
Validation loss: 3.188214402044973

Epoch: 5| Step: 0
Training loss: 3.203950881958008
Validation loss: 3.1630194110255085

Epoch: 6| Step: 1
Training loss: 2.944657802581787
Validation loss: 3.1583863945417505

Epoch: 6| Step: 2
Training loss: 2.757150173187256
Validation loss: 3.144172489002187

Epoch: 6| Step: 3
Training loss: 3.6362452507019043
Validation loss: 3.1312151596110356

Epoch: 6| Step: 4
Training loss: 3.217576026916504
Validation loss: 3.119498639978388

Epoch: 6| Step: 5
Training loss: 2.88448429107666
Validation loss: 3.110297228700371

Epoch: 6| Step: 6
Training loss: 2.9674582481384277
Validation loss: 3.10855681409118

Epoch: 6| Step: 7
Training loss: 3.235065221786499
Validation loss: 3.1022586591782106

Epoch: 6| Step: 8
Training loss: 2.6744375228881836
Validation loss: 3.096605803376885

Epoch: 6| Step: 9
Training loss: 3.52097225189209
Validation loss: 3.093063146837296

Epoch: 6| Step: 10
Training loss: 3.71748685836792
Validation loss: 3.0851470424282934

Epoch: 6| Step: 11
Training loss: 2.8357093334198
Validation loss: 3.0746258715147614

Epoch: 6| Step: 12
Training loss: 3.166715383529663
Validation loss: 3.063464641571045

Epoch: 6| Step: 13
Training loss: 3.0417115688323975
Validation loss: 3.0542331357156076

Epoch: 6| Step: 0
Training loss: 4.135322570800781
Validation loss: 3.046198273217806

Epoch: 6| Step: 1
Training loss: 3.0528602600097656
Validation loss: 3.034026745826967

Epoch: 6| Step: 2
Training loss: 3.228966236114502
Validation loss: 3.0265886014507664

Epoch: 6| Step: 3
Training loss: 2.327817916870117
Validation loss: 3.0165278629590104

Epoch: 6| Step: 4
Training loss: 3.542865753173828
Validation loss: 3.010065263317477

Epoch: 6| Step: 5
Training loss: 3.0897672176361084
Validation loss: 2.9978273965979136

Epoch: 6| Step: 6
Training loss: 2.3761441707611084
Validation loss: 2.9926734919189126

Epoch: 6| Step: 7
Training loss: 4.265233039855957
Validation loss: 2.985495990322482

Epoch: 6| Step: 8
Training loss: 2.5573854446411133
Validation loss: 2.9762448059615267

Epoch: 6| Step: 9
Training loss: 2.782898426055908
Validation loss: 2.969873410399242

Epoch: 6| Step: 10
Training loss: 2.3752195835113525
Validation loss: 2.978544545430009

Epoch: 6| Step: 11
Training loss: 3.1575264930725098
Validation loss: 2.967742709703343

Epoch: 6| Step: 12
Training loss: 2.8026909828186035
Validation loss: 2.964231255233929

Epoch: 6| Step: 13
Training loss: 3.2173991203308105
Validation loss: 2.9470861804100776

Epoch: 7| Step: 0
Training loss: 3.5923690795898438
Validation loss: 2.9456638264399704

Epoch: 6| Step: 1
Training loss: 3.626631736755371
Validation loss: 2.93624117553875

Epoch: 6| Step: 2
Training loss: 2.6926403045654297
Validation loss: 2.92899739614097

Epoch: 6| Step: 3
Training loss: 2.6895740032196045
Validation loss: 2.9196723635478685

Epoch: 6| Step: 4
Training loss: 3.642974853515625
Validation loss: 2.914433128090315

Epoch: 6| Step: 5
Training loss: 2.23169207572937
Validation loss: 2.9074250190488753

Epoch: 6| Step: 6
Training loss: 3.278463125228882
Validation loss: 2.9032621793849493

Epoch: 6| Step: 7
Training loss: 3.401592254638672
Validation loss: 2.8942826409493723

Epoch: 6| Step: 8
Training loss: 3.001934051513672
Validation loss: 2.889071720902638

Epoch: 6| Step: 9
Training loss: 2.040139675140381
Validation loss: 2.8797889627436155

Epoch: 6| Step: 10
Training loss: 2.832524299621582
Validation loss: 2.8784657729569303

Epoch: 6| Step: 11
Training loss: 3.0657904148101807
Validation loss: 2.870655426415064

Epoch: 6| Step: 12
Training loss: 2.763420343399048
Validation loss: 2.8740129445188787

Epoch: 6| Step: 13
Training loss: 3.055798053741455
Validation loss: 2.864152503269975

Epoch: 8| Step: 0
Training loss: 2.3120627403259277
Validation loss: 2.9252702754030944

Epoch: 6| Step: 1
Training loss: 2.5119638442993164
Validation loss: 2.8732463364960044

Epoch: 6| Step: 2
Training loss: 2.5392906665802
Validation loss: 2.8616142606222503

Epoch: 6| Step: 3
Training loss: 2.62807559967041
Validation loss: 2.8653671664576374

Epoch: 6| Step: 4
Training loss: 2.6821975708007812
Validation loss: 2.846407885192543

Epoch: 6| Step: 5
Training loss: 3.0182294845581055
Validation loss: 2.842152782665786

Epoch: 6| Step: 6
Training loss: 4.336048603057861
Validation loss: 2.8366859343744095

Epoch: 6| Step: 7
Training loss: 2.75921630859375
Validation loss: 2.8378262289108767

Epoch: 6| Step: 8
Training loss: 3.52736496925354
Validation loss: 2.8398226666194137

Epoch: 6| Step: 9
Training loss: 2.4970388412475586
Validation loss: 2.8407189230765066

Epoch: 6| Step: 10
Training loss: 3.6482577323913574
Validation loss: 2.8404139036773355

Epoch: 6| Step: 11
Training loss: 2.7838234901428223
Validation loss: 2.8574881630559124

Epoch: 6| Step: 12
Training loss: 2.468522787094116
Validation loss: 2.8699485640372

Epoch: 6| Step: 13
Training loss: 4.466824054718018
Validation loss: 2.9250000984438005

Epoch: 9| Step: 0
Training loss: 3.340954303741455
Validation loss: 2.835341694534466

Epoch: 6| Step: 1
Training loss: 3.2732958793640137
Validation loss: 2.8211622391977618

Epoch: 6| Step: 2
Training loss: 2.837742567062378
Validation loss: 2.8377283286022883

Epoch: 6| Step: 3
Training loss: 3.8265442848205566
Validation loss: 2.861700132328977

Epoch: 6| Step: 4
Training loss: 3.622105121612549
Validation loss: 2.8727499592688774

Epoch: 6| Step: 5
Training loss: 2.5304811000823975
Validation loss: 2.8634861207777456

Epoch: 6| Step: 6
Training loss: 2.7663207054138184
Validation loss: 2.840975574267808

Epoch: 6| Step: 7
Training loss: 2.3276290893554688
Validation loss: 2.824298028023012

Epoch: 6| Step: 8
Training loss: 2.6909008026123047
Validation loss: 2.8883619257198867

Epoch: 6| Step: 9
Training loss: 2.568371057510376
Validation loss: 2.938124536186136

Epoch: 6| Step: 10
Training loss: 3.390702724456787
Validation loss: 2.967367431168915

Epoch: 6| Step: 11
Training loss: 2.520819664001465
Validation loss: 2.9553143337208736

Epoch: 6| Step: 12
Training loss: 3.390807628631592
Validation loss: 2.913891000132407

Epoch: 6| Step: 13
Training loss: 2.3523054122924805
Validation loss: 2.8655473442487818

Epoch: 10| Step: 0
Training loss: 2.6834347248077393
Validation loss: 2.78622874136894

Epoch: 6| Step: 1
Training loss: 3.5138163566589355
Validation loss: 2.7967420329329786

Epoch: 6| Step: 2
Training loss: 2.379338026046753
Validation loss: 2.835684632742277

Epoch: 6| Step: 3
Training loss: 3.3164095878601074
Validation loss: 2.8559157643266904

Epoch: 6| Step: 4
Training loss: 2.704073429107666
Validation loss: 2.826797931425033

Epoch: 6| Step: 5
Training loss: 2.8103809356689453
Validation loss: 2.802495107855848

Epoch: 6| Step: 6
Training loss: 3.268609046936035
Validation loss: 2.8050846258799234

Epoch: 6| Step: 7
Training loss: 2.1963765621185303
Validation loss: 2.809742742969144

Epoch: 6| Step: 8
Training loss: 3.1063179969787598
Validation loss: 2.8108856754918254

Epoch: 6| Step: 9
Training loss: 2.482074737548828
Validation loss: 2.812732296605264

Epoch: 6| Step: 10
Training loss: 2.587416172027588
Validation loss: 2.820562014015772

Epoch: 6| Step: 11
Training loss: 3.389720916748047
Validation loss: 2.8210141992056244

Epoch: 6| Step: 12
Training loss: 3.374955177307129
Validation loss: 2.8276449095818306

Epoch: 6| Step: 13
Training loss: 3.7624528408050537
Validation loss: 2.8163630885462605

Epoch: 11| Step: 0
Training loss: 2.6898021697998047
Validation loss: 2.811671095509683

Epoch: 6| Step: 1
Training loss: 3.306621551513672
Validation loss: 2.8128131666491107

Epoch: 6| Step: 2
Training loss: 2.596041440963745
Validation loss: 2.8209124406178794

Epoch: 6| Step: 3
Training loss: 3.0971529483795166
Validation loss: 2.824820667184809

Epoch: 6| Step: 4
Training loss: 2.5020694732666016
Validation loss: 2.8112976243419032

Epoch: 6| Step: 5
Training loss: 2.8660595417022705
Validation loss: 2.798626597209643

Epoch: 6| Step: 6
Training loss: 2.573026657104492
Validation loss: 2.792321592248896

Epoch: 6| Step: 7
Training loss: 2.256131172180176
Validation loss: 2.7822136725148847

Epoch: 6| Step: 8
Training loss: 2.614433765411377
Validation loss: 2.7741494153135564

Epoch: 6| Step: 9
Training loss: 4.05763053894043
Validation loss: 2.76646747127656

Epoch: 6| Step: 10
Training loss: 2.915783643722534
Validation loss: 2.761981628274405

Epoch: 6| Step: 11
Training loss: 3.447502851486206
Validation loss: 2.754833229126469

Epoch: 6| Step: 12
Training loss: 3.203192949295044
Validation loss: 2.753078378656859

Epoch: 6| Step: 13
Training loss: 2.6450421810150146
Validation loss: 2.748551958350725

Epoch: 12| Step: 0
Training loss: 2.981835126876831
Validation loss: 2.7444825608243226

Epoch: 6| Step: 1
Training loss: 3.501349687576294
Validation loss: 2.7427833413565033

Epoch: 6| Step: 2
Training loss: 2.5766122341156006
Validation loss: 2.7430706357443206

Epoch: 6| Step: 3
Training loss: 3.221112012863159
Validation loss: 2.746542763966386

Epoch: 6| Step: 4
Training loss: 2.3846659660339355
Validation loss: 2.738953371201792

Epoch: 6| Step: 5
Training loss: 3.285966396331787
Validation loss: 2.728223418676725

Epoch: 6| Step: 6
Training loss: 2.845688819885254
Validation loss: 2.7159913252758723

Epoch: 6| Step: 7
Training loss: 3.6281304359436035
Validation loss: 2.709751375259892

Epoch: 6| Step: 8
Training loss: 2.1883835792541504
Validation loss: 2.704407589409941

Epoch: 6| Step: 9
Training loss: 2.6046292781829834
Validation loss: 2.70492200697622

Epoch: 6| Step: 10
Training loss: 2.8213963508605957
Validation loss: 2.702772863449589

Epoch: 6| Step: 11
Training loss: 2.95684814453125
Validation loss: 2.6942041279167257

Epoch: 6| Step: 12
Training loss: 2.5114753246307373
Validation loss: 2.693176095203687

Epoch: 6| Step: 13
Training loss: 2.8718421459198
Validation loss: 2.690731197275141

Epoch: 13| Step: 0
Training loss: 2.9897379875183105
Validation loss: 2.6905160616802912

Epoch: 6| Step: 1
Training loss: 2.1749980449676514
Validation loss: 2.690222078754056

Epoch: 6| Step: 2
Training loss: 3.0438039302825928
Validation loss: 2.6955556869506836

Epoch: 6| Step: 3
Training loss: 3.0096616744995117
Validation loss: 2.69428764876499

Epoch: 6| Step: 4
Training loss: 2.5518784523010254
Validation loss: 2.6900778867865123

Epoch: 6| Step: 5
Training loss: 2.3457064628601074
Validation loss: 2.6871094703674316

Epoch: 6| Step: 6
Training loss: 2.9344005584716797
Validation loss: 2.6834794065003753

Epoch: 6| Step: 7
Training loss: 1.9938794374465942
Validation loss: 2.6830910969805974

Epoch: 6| Step: 8
Training loss: 3.024127721786499
Validation loss: 2.6870299385439966

Epoch: 6| Step: 9
Training loss: 3.040858268737793
Validation loss: 2.683229277210851

Epoch: 6| Step: 10
Training loss: 3.4560513496398926
Validation loss: 2.680459681377616

Epoch: 6| Step: 11
Training loss: 2.4229297637939453
Validation loss: 2.671249146102577

Epoch: 6| Step: 12
Training loss: 3.7929956912994385
Validation loss: 2.6655131514354418

Epoch: 6| Step: 13
Training loss: 3.5084080696105957
Validation loss: 2.66241717338562

Epoch: 14| Step: 0
Training loss: 2.884314775466919
Validation loss: 2.6564554937424196

Epoch: 6| Step: 1
Training loss: 3.0990774631500244
Validation loss: 2.6540550031969623

Epoch: 6| Step: 2
Training loss: 3.2158334255218506
Validation loss: 2.652986762344196

Epoch: 6| Step: 3
Training loss: 3.4883744716644287
Validation loss: 2.6528706960780646

Epoch: 6| Step: 4
Training loss: 2.1147897243499756
Validation loss: 2.6491238558164207

Epoch: 6| Step: 5
Training loss: 2.283907413482666
Validation loss: 2.649370957446355

Epoch: 6| Step: 6
Training loss: 3.0089476108551025
Validation loss: 2.6423241476858816

Epoch: 6| Step: 7
Training loss: 3.5426855087280273
Validation loss: 2.6418217766669487

Epoch: 6| Step: 8
Training loss: 2.170745849609375
Validation loss: 2.643175317395118

Epoch: 6| Step: 9
Training loss: 2.618894338607788
Validation loss: 2.638537319757605

Epoch: 6| Step: 10
Training loss: 2.4371337890625
Validation loss: 2.641823773743004

Epoch: 6| Step: 11
Training loss: 2.224980354309082
Validation loss: 2.641212240342171

Epoch: 6| Step: 12
Training loss: 3.913908004760742
Validation loss: 2.6415885340782905

Epoch: 6| Step: 13
Training loss: 2.5329723358154297
Validation loss: 2.639115923194475

Epoch: 15| Step: 0
Training loss: 3.2268338203430176
Validation loss: 2.636353123572565

Epoch: 6| Step: 1
Training loss: 2.260103464126587
Validation loss: 2.6400099697933403

Epoch: 6| Step: 2
Training loss: 2.155134439468384
Validation loss: 2.6346791252013175

Epoch: 6| Step: 3
Training loss: 2.714034080505371
Validation loss: 2.632177168323148

Epoch: 6| Step: 4
Training loss: 3.283064842224121
Validation loss: 2.630841526933896

Epoch: 6| Step: 5
Training loss: 2.8983376026153564
Validation loss: 2.631186690381778

Epoch: 6| Step: 6
Training loss: 1.864511251449585
Validation loss: 2.630035538827219

Epoch: 6| Step: 7
Training loss: 3.2150745391845703
Validation loss: 2.629113810036772

Epoch: 6| Step: 8
Training loss: 3.0806884765625
Validation loss: 2.6379919282851683

Epoch: 6| Step: 9
Training loss: 2.650211811065674
Validation loss: 2.6272099710279897

Epoch: 6| Step: 10
Training loss: 3.4269967079162598
Validation loss: 2.6254174452956005

Epoch: 6| Step: 11
Training loss: 2.4281437397003174
Validation loss: 2.6202238605868433

Epoch: 6| Step: 12
Training loss: 3.262082099914551
Validation loss: 2.620592506982947

Epoch: 6| Step: 13
Training loss: 3.106123924255371
Validation loss: 2.616309840192077

Epoch: 16| Step: 0
Training loss: 2.90407395362854
Validation loss: 2.6175464071253294

Epoch: 6| Step: 1
Training loss: 1.8852241039276123
Validation loss: 2.612438086540468

Epoch: 6| Step: 2
Training loss: 2.6965179443359375
Validation loss: 2.612291646260087

Epoch: 6| Step: 3
Training loss: 3.2337164878845215
Validation loss: 2.6268925359172206

Epoch: 6| Step: 4
Training loss: 2.0655574798583984
Validation loss: 2.6598965762763895

Epoch: 6| Step: 5
Training loss: 2.9535775184631348
Validation loss: 2.6701339060260403

Epoch: 6| Step: 6
Training loss: 2.580097198486328
Validation loss: 2.654659873695784

Epoch: 6| Step: 7
Training loss: 3.2434306144714355
Validation loss: 2.604185296643165

Epoch: 6| Step: 8
Training loss: 2.8062448501586914
Validation loss: 2.6170084630289385

Epoch: 6| Step: 9
Training loss: 3.0711586475372314
Validation loss: 2.632012608230755

Epoch: 6| Step: 10
Training loss: 3.2082679271698
Validation loss: 2.6677317362959667

Epoch: 6| Step: 11
Training loss: 3.027217388153076
Validation loss: 2.6956942260906263

Epoch: 6| Step: 12
Training loss: 2.9186251163482666
Validation loss: 2.654290122370566

Epoch: 6| Step: 13
Training loss: 2.9540469646453857
Validation loss: 2.6179236468448432

Epoch: 17| Step: 0
Training loss: 2.824978828430176
Validation loss: 2.6152802769855787

Epoch: 6| Step: 1
Training loss: 2.508969783782959
Validation loss: 2.6132265213997132

Epoch: 6| Step: 2
Training loss: 3.2176458835601807
Validation loss: 2.6279585207662275

Epoch: 6| Step: 3
Training loss: 3.260493755340576
Validation loss: 2.63670680856192

Epoch: 6| Step: 4
Training loss: 2.58970308303833
Validation loss: 2.632448242556664

Epoch: 6| Step: 5
Training loss: 2.7091541290283203
Validation loss: 2.629852041121452

Epoch: 6| Step: 6
Training loss: 3.4046518802642822
Validation loss: 2.6276051587955926

Epoch: 6| Step: 7
Training loss: 3.081683397293091
Validation loss: 2.6193925129470004

Epoch: 6| Step: 8
Training loss: 3.039933204650879
Validation loss: 2.613452075630106

Epoch: 6| Step: 9
Training loss: 2.240488052368164
Validation loss: 2.608420874482842

Epoch: 6| Step: 10
Training loss: 3.2156577110290527
Validation loss: 2.6099287361227055

Epoch: 6| Step: 11
Training loss: 2.9147846698760986
Validation loss: 2.6026236088045183

Epoch: 6| Step: 12
Training loss: 2.328507423400879
Validation loss: 2.6035425073357037

Epoch: 6| Step: 13
Training loss: 1.3491790294647217
Validation loss: 2.5999386566941456

Epoch: 18| Step: 0
Training loss: 2.6295270919799805
Validation loss: 2.600264979946998

Epoch: 6| Step: 1
Training loss: 2.4570281505584717
Validation loss: 2.602070249536986

Epoch: 6| Step: 2
Training loss: 3.108694553375244
Validation loss: 2.597137479371922

Epoch: 6| Step: 3
Training loss: 2.2744576930999756
Validation loss: 2.6095475868512223

Epoch: 6| Step: 4
Training loss: 2.946730613708496
Validation loss: 2.6078939412229802

Epoch: 6| Step: 5
Training loss: 2.8385677337646484
Validation loss: 2.6013067255737963

Epoch: 6| Step: 6
Training loss: 2.8236031532287598
Validation loss: 2.6048649190574564

Epoch: 6| Step: 7
Training loss: 3.0385963916778564
Validation loss: 2.6011996269226074

Epoch: 6| Step: 8
Training loss: 2.8150031566619873
Validation loss: 2.5899575807714976

Epoch: 6| Step: 9
Training loss: 3.3274283409118652
Validation loss: 2.5877982237005748

Epoch: 6| Step: 10
Training loss: 2.0915279388427734
Validation loss: 2.578445057715139

Epoch: 6| Step: 11
Training loss: 2.9553205966949463
Validation loss: 2.579029667762018

Epoch: 6| Step: 12
Training loss: 2.8648149967193604
Validation loss: 2.5759028260425856

Epoch: 6| Step: 13
Training loss: 2.713031530380249
Validation loss: 2.5775630192090104

Epoch: 19| Step: 0
Training loss: 3.576906681060791
Validation loss: 2.577305369479682

Epoch: 6| Step: 1
Training loss: 2.807880401611328
Validation loss: 2.5744621266600904

Epoch: 6| Step: 2
Training loss: 3.1999716758728027
Validation loss: 2.5758864084879556

Epoch: 6| Step: 3
Training loss: 2.890958070755005
Validation loss: 2.574515527294528

Epoch: 6| Step: 4
Training loss: 1.988358497619629
Validation loss: 2.5744342598863827

Epoch: 6| Step: 5
Training loss: 3.1807162761688232
Validation loss: 2.573510149473785

Epoch: 6| Step: 6
Training loss: 2.643770456314087
Validation loss: 2.572556270066128

Epoch: 6| Step: 7
Training loss: 3.8162920475006104
Validation loss: 2.5714025548709336

Epoch: 6| Step: 8
Training loss: 2.3142032623291016
Validation loss: 2.572928387631652

Epoch: 6| Step: 9
Training loss: 2.7477753162384033
Validation loss: 2.577102156095607

Epoch: 6| Step: 10
Training loss: 2.1501846313476562
Validation loss: 2.608542191084995

Epoch: 6| Step: 11
Training loss: 2.3940677642822266
Validation loss: 2.6325402131644626

Epoch: 6| Step: 12
Training loss: 2.9244203567504883
Validation loss: 2.6367086184922086

Epoch: 6| Step: 13
Training loss: 1.6863837242126465
Validation loss: 2.6232887775667253

Epoch: 20| Step: 0
Training loss: 3.099857807159424
Validation loss: 2.61552656081415

Epoch: 6| Step: 1
Training loss: 3.1953165531158447
Validation loss: 2.598893029715425

Epoch: 6| Step: 2
Training loss: 3.1213276386260986
Validation loss: 2.5704799877699984

Epoch: 6| Step: 3
Training loss: 2.4999189376831055
Validation loss: 2.5687625433809016

Epoch: 6| Step: 4
Training loss: 2.2289016246795654
Validation loss: 2.5706087184208695

Epoch: 6| Step: 5
Training loss: 2.7380216121673584
Validation loss: 2.576705119943106

Epoch: 6| Step: 6
Training loss: 3.926353693008423
Validation loss: 2.5808024291069276

Epoch: 6| Step: 7
Training loss: 3.216649055480957
Validation loss: 2.5783721759755123

Epoch: 6| Step: 8
Training loss: 2.0175247192382812
Validation loss: 2.573396746830274

Epoch: 6| Step: 9
Training loss: 1.61367928981781
Validation loss: 2.573029843709802

Epoch: 6| Step: 10
Training loss: 2.478302001953125
Validation loss: 2.566265839402394

Epoch: 6| Step: 11
Training loss: 2.194033145904541
Validation loss: 2.5621716822347333

Epoch: 6| Step: 12
Training loss: 3.6626501083374023
Validation loss: 2.5560162118686143

Epoch: 6| Step: 13
Training loss: 2.928317070007324
Validation loss: 2.5547685712896366

Epoch: 21| Step: 0
Training loss: 2.6156671047210693
Validation loss: 2.5713860834798505

Epoch: 6| Step: 1
Training loss: 3.260836124420166
Validation loss: 2.5841792142519386

Epoch: 6| Step: 2
Training loss: 2.761563777923584
Validation loss: 2.573599100112915

Epoch: 6| Step: 3
Training loss: 2.2478301525115967
Validation loss: 2.5570581625866633

Epoch: 6| Step: 4
Training loss: 3.064063787460327
Validation loss: 2.5531936691653345

Epoch: 6| Step: 5
Training loss: 3.5448687076568604
Validation loss: 2.5431840804315384

Epoch: 6| Step: 6
Training loss: 2.9145348072052
Validation loss: 2.5450512568155923

Epoch: 6| Step: 7
Training loss: 1.6440579891204834
Validation loss: 2.541713317235311

Epoch: 6| Step: 8
Training loss: 2.5185546875
Validation loss: 2.5488977380978164

Epoch: 6| Step: 9
Training loss: 2.805497884750366
Validation loss: 2.548097796337579

Epoch: 6| Step: 10
Training loss: 2.86503267288208
Validation loss: 2.538949010192707

Epoch: 6| Step: 11
Training loss: 2.932039737701416
Validation loss: 2.5388300367580947

Epoch: 6| Step: 12
Training loss: 2.356168746948242
Validation loss: 2.536978688291324

Epoch: 6| Step: 13
Training loss: 3.203359842300415
Validation loss: 2.5363862642677883

Epoch: 22| Step: 0
Training loss: 3.1085400581359863
Validation loss: 2.5353821221218316

Epoch: 6| Step: 1
Training loss: 2.8057103157043457
Validation loss: 2.5351565217459076

Epoch: 6| Step: 2
Training loss: 2.8912651538848877
Validation loss: 2.533297126011182

Epoch: 6| Step: 3
Training loss: 3.336822748184204
Validation loss: 2.5334146304797103

Epoch: 6| Step: 4
Training loss: 2.2621970176696777
Validation loss: 2.5355817476908364

Epoch: 6| Step: 5
Training loss: 3.183490037918091
Validation loss: 2.5380099024823917

Epoch: 6| Step: 6
Training loss: 3.004720449447632
Validation loss: 2.550704538181264

Epoch: 6| Step: 7
Training loss: 2.9051902294158936
Validation loss: 2.539511829294184

Epoch: 6| Step: 8
Training loss: 2.508455514907837
Validation loss: 2.536248483965474

Epoch: 6| Step: 9
Training loss: 2.477522134780884
Validation loss: 2.531987126155566

Epoch: 6| Step: 10
Training loss: 3.0327701568603516
Validation loss: 2.527951619958365

Epoch: 6| Step: 11
Training loss: 1.5600271224975586
Validation loss: 2.5203419962236957

Epoch: 6| Step: 12
Training loss: 2.4343223571777344
Validation loss: 2.5244830423785793

Epoch: 6| Step: 13
Training loss: 2.907320261001587
Validation loss: 2.528447997185492

Epoch: 23| Step: 0
Training loss: 2.1518921852111816
Validation loss: 2.529670133385607

Epoch: 6| Step: 1
Training loss: 2.6106739044189453
Validation loss: 2.529166849710608

Epoch: 6| Step: 2
Training loss: 2.559858798980713
Validation loss: 2.5307585141992055

Epoch: 6| Step: 3
Training loss: 3.0516748428344727
Validation loss: 2.5314686708552863

Epoch: 6| Step: 4
Training loss: 2.6464827060699463
Validation loss: 2.5295996999227874

Epoch: 6| Step: 5
Training loss: 2.608293294906616
Validation loss: 2.528347030762703

Epoch: 6| Step: 6
Training loss: 3.047546148300171
Validation loss: 2.526126007879934

Epoch: 6| Step: 7
Training loss: 2.669090986251831
Validation loss: 2.52173872147837

Epoch: 6| Step: 8
Training loss: 2.263413190841675
Validation loss: 2.5204057462753786

Epoch: 6| Step: 9
Training loss: 3.4475345611572266
Validation loss: 2.519232798648137

Epoch: 6| Step: 10
Training loss: 3.069706439971924
Validation loss: 2.51974578057566

Epoch: 6| Step: 11
Training loss: 2.4495959281921387
Validation loss: 2.5162659357952815

Epoch: 6| Step: 12
Training loss: 2.7435531616210938
Validation loss: 2.5154876657711562

Epoch: 6| Step: 13
Training loss: 3.191622018814087
Validation loss: 2.525996546591482

Epoch: 24| Step: 0
Training loss: 2.8311092853546143
Validation loss: 2.554077151001141

Epoch: 6| Step: 1
Training loss: 2.9138877391815186
Validation loss: 2.56164724339721

Epoch: 6| Step: 2
Training loss: 2.4521963596343994
Validation loss: 2.5696924835123043

Epoch: 6| Step: 3
Training loss: 2.5872395038604736
Validation loss: 2.5454485493321575

Epoch: 6| Step: 4
Training loss: 2.4508771896362305
Validation loss: 2.523422080983398

Epoch: 6| Step: 5
Training loss: 3.1849308013916016
Validation loss: 2.5125280298212522

Epoch: 6| Step: 6
Training loss: 2.246666431427002
Validation loss: 2.522521762437718

Epoch: 6| Step: 7
Training loss: 2.6640567779541016
Validation loss: 2.5397310282594416

Epoch: 6| Step: 8
Training loss: 3.088109016418457
Validation loss: 2.559166887755035

Epoch: 6| Step: 9
Training loss: 3.1352570056915283
Validation loss: 2.641154476391372

Epoch: 6| Step: 10
Training loss: 2.9575881958007812
Validation loss: 2.601278661399759

Epoch: 6| Step: 11
Training loss: 2.2613208293914795
Validation loss: 2.5266269176237044

Epoch: 6| Step: 12
Training loss: 2.776782989501953
Validation loss: 2.5127321135613228

Epoch: 6| Step: 13
Training loss: 3.4776735305786133
Validation loss: 2.5060309440858903

Epoch: 25| Step: 0
Training loss: 2.457108974456787
Validation loss: 2.5122035934079077

Epoch: 6| Step: 1
Training loss: 1.9002395868301392
Validation loss: 2.528081573465819

Epoch: 6| Step: 2
Training loss: 2.9080047607421875
Validation loss: 2.5818155298950853

Epoch: 6| Step: 3
Training loss: 2.6187777519226074
Validation loss: 2.6363150047999557

Epoch: 6| Step: 4
Training loss: 2.902111291885376
Validation loss: 2.684097328493672

Epoch: 6| Step: 5
Training loss: 3.062798023223877
Validation loss: 2.695022621462422

Epoch: 6| Step: 6
Training loss: 3.345917224884033
Validation loss: 2.6582346731616604

Epoch: 6| Step: 7
Training loss: 2.2631335258483887
Validation loss: 2.595002071831816

Epoch: 6| Step: 8
Training loss: 3.017439842224121
Validation loss: 2.522228758822205

Epoch: 6| Step: 9
Training loss: 3.2079155445098877
Validation loss: 2.4927802701150217

Epoch: 6| Step: 10
Training loss: 3.5014538764953613
Validation loss: 2.49512989546663

Epoch: 6| Step: 11
Training loss: 2.773798704147339
Validation loss: 2.504770540422009

Epoch: 6| Step: 12
Training loss: 2.358427047729492
Validation loss: 2.5089239433247554

Epoch: 6| Step: 13
Training loss: 2.1753063201904297
Validation loss: 2.512292590192569

Epoch: 26| Step: 0
Training loss: 2.589024543762207
Validation loss: 2.5163433064696608

Epoch: 6| Step: 1
Training loss: 3.2364532947540283
Validation loss: 2.521431794730566

Epoch: 6| Step: 2
Training loss: 2.9430758953094482
Validation loss: 2.522037793231267

Epoch: 6| Step: 3
Training loss: 2.874797821044922
Validation loss: 2.514410739303917

Epoch: 6| Step: 4
Training loss: 2.6939404010772705
Validation loss: 2.508117929581673

Epoch: 6| Step: 5
Training loss: 2.73862361907959
Validation loss: 2.4992681767350886

Epoch: 6| Step: 6
Training loss: 2.8889832496643066
Validation loss: 2.4956597410222536

Epoch: 6| Step: 7
Training loss: 2.7027692794799805
Validation loss: 2.492080980731595

Epoch: 6| Step: 8
Training loss: 2.457386016845703
Validation loss: 2.4970628869148994

Epoch: 6| Step: 9
Training loss: 2.368903160095215
Validation loss: 2.493092349780503

Epoch: 6| Step: 10
Training loss: 2.010568141937256
Validation loss: 2.4866757674883773

Epoch: 6| Step: 11
Training loss: 3.327528715133667
Validation loss: 2.4899915315771617

Epoch: 6| Step: 12
Training loss: 2.2060117721557617
Validation loss: 2.506124757951306

Epoch: 6| Step: 13
Training loss: 3.699158191680908
Validation loss: 2.530946385475897

Epoch: 27| Step: 0
Training loss: 2.681668519973755
Validation loss: 2.550485452016195

Epoch: 6| Step: 1
Training loss: 2.6153154373168945
Validation loss: 2.552699086486652

Epoch: 6| Step: 2
Training loss: 3.4244208335876465
Validation loss: 2.523202660263226

Epoch: 6| Step: 3
Training loss: 2.091658115386963
Validation loss: 2.4801302058722383

Epoch: 6| Step: 4
Training loss: 3.131988048553467
Validation loss: 2.4770567186417116

Epoch: 6| Step: 5
Training loss: 2.692228317260742
Validation loss: 2.485799717646773

Epoch: 6| Step: 6
Training loss: 3.5412402153015137
Validation loss: 2.488283354748962

Epoch: 6| Step: 7
Training loss: 2.2862672805786133
Validation loss: 2.4921614431565806

Epoch: 6| Step: 8
Training loss: 2.283154010772705
Validation loss: 2.49375049273173

Epoch: 6| Step: 9
Training loss: 3.563610315322876
Validation loss: 2.4857944237288607

Epoch: 6| Step: 10
Training loss: 2.492431879043579
Validation loss: 2.485561527231688

Epoch: 6| Step: 11
Training loss: 2.2421112060546875
Validation loss: 2.4857521467311408

Epoch: 6| Step: 12
Training loss: 3.0385384559631348
Validation loss: 2.4829132787642942

Epoch: 6| Step: 13
Training loss: 1.5289465188980103
Validation loss: 2.4784731326564664

Epoch: 28| Step: 0
Training loss: 2.48500919342041
Validation loss: 2.5065919891480477

Epoch: 6| Step: 1
Training loss: 3.1925599575042725
Validation loss: 2.593851404805337

Epoch: 6| Step: 2
Training loss: 2.9250569343566895
Validation loss: 2.67642230115911

Epoch: 6| Step: 3
Training loss: 2.6939799785614014
Validation loss: 2.737534499937488

Epoch: 6| Step: 4
Training loss: 2.89144229888916
Validation loss: 2.7887885416707685

Epoch: 6| Step: 5
Training loss: 3.131547212600708
Validation loss: 2.770025617332869

Epoch: 6| Step: 6
Training loss: 2.26762318611145
Validation loss: 2.7453877182417017

Epoch: 6| Step: 7
Training loss: 2.1683764457702637
Validation loss: 2.686687833519392

Epoch: 6| Step: 8
Training loss: 2.978384017944336
Validation loss: 2.6146177117542555

Epoch: 6| Step: 9
Training loss: 3.1858150959014893
Validation loss: 2.570525574427779

Epoch: 6| Step: 10
Training loss: 3.18507981300354
Validation loss: 2.548547995987759

Epoch: 6| Step: 11
Training loss: 2.7650928497314453
Validation loss: 2.498902633625974

Epoch: 6| Step: 12
Training loss: 2.421236038208008
Validation loss: 2.4835502819348405

Epoch: 6| Step: 13
Training loss: 2.473935127258301
Validation loss: 2.483889405445386

Epoch: 29| Step: 0
Training loss: 2.5630300045013428
Validation loss: 2.491118161909042

Epoch: 6| Step: 1
Training loss: 2.2991442680358887
Validation loss: 2.492413748977005

Epoch: 6| Step: 2
Training loss: 2.184392213821411
Validation loss: 2.5012791182405207

Epoch: 6| Step: 3
Training loss: 2.655431032180786
Validation loss: 2.529153367524506

Epoch: 6| Step: 4
Training loss: 2.5368475914001465
Validation loss: 2.5079035271880445

Epoch: 6| Step: 5
Training loss: 2.755066156387329
Validation loss: 2.4867803358262583

Epoch: 6| Step: 6
Training loss: 2.4701433181762695
Validation loss: 2.472941801112185

Epoch: 6| Step: 7
Training loss: 3.6353704929351807
Validation loss: 2.462264471156623

Epoch: 6| Step: 8
Training loss: 2.7184839248657227
Validation loss: 2.4562824362067768

Epoch: 6| Step: 9
Training loss: 2.8052830696105957
Validation loss: 2.4498272634321645

Epoch: 6| Step: 10
Training loss: 2.2202646732330322
Validation loss: 2.4542311109522337

Epoch: 6| Step: 11
Training loss: 3.2000834941864014
Validation loss: 2.464104057640158

Epoch: 6| Step: 12
Training loss: 3.034505605697632
Validation loss: 2.4871436370316373

Epoch: 6| Step: 13
Training loss: 2.993961811065674
Validation loss: 2.53859539698529

Epoch: 30| Step: 0
Training loss: 2.802841901779175
Validation loss: 2.594142354944701

Epoch: 6| Step: 1
Training loss: 2.8975319862365723
Validation loss: 2.63622349052019

Epoch: 6| Step: 2
Training loss: 2.73502779006958
Validation loss: 2.6538046072888117

Epoch: 6| Step: 3
Training loss: 2.972475051879883
Validation loss: 2.640964687511485

Epoch: 6| Step: 4
Training loss: 2.5324583053588867
Validation loss: 2.61778356952052

Epoch: 6| Step: 5
Training loss: 2.7432796955108643
Validation loss: 2.59702363065494

Epoch: 6| Step: 6
Training loss: 2.8799967765808105
Validation loss: 2.586261772340344

Epoch: 6| Step: 7
Training loss: 2.935497760772705
Validation loss: 2.569438426725326

Epoch: 6| Step: 8
Training loss: 2.0558948516845703
Validation loss: 2.5527785772918374

Epoch: 6| Step: 9
Training loss: 2.3787927627563477
Validation loss: 2.517312385702646

Epoch: 6| Step: 10
Training loss: 3.542217254638672
Validation loss: 2.4992843597166

Epoch: 6| Step: 11
Training loss: 2.1149275302886963
Validation loss: 2.4871694041836645

Epoch: 6| Step: 12
Training loss: 2.8160362243652344
Validation loss: 2.5026753897308023

Epoch: 6| Step: 13
Training loss: 3.3342840671539307
Validation loss: 2.5892552483466362

Epoch: 31| Step: 0
Training loss: 2.1893982887268066
Validation loss: 2.6747373791151148

Epoch: 6| Step: 1
Training loss: 2.69928240776062
Validation loss: 2.751967858242732

Epoch: 6| Step: 2
Training loss: 3.114156723022461
Validation loss: 2.794802955401841

Epoch: 6| Step: 3
Training loss: 2.7814595699310303
Validation loss: 2.700827693426481

Epoch: 6| Step: 4
Training loss: 3.1815109252929688
Validation loss: 2.5592171299842095

Epoch: 6| Step: 5
Training loss: 2.8054676055908203
Validation loss: 2.4531403792801725

Epoch: 6| Step: 6
Training loss: 2.5948119163513184
Validation loss: 2.439551379090996

Epoch: 6| Step: 7
Training loss: 2.825505495071411
Validation loss: 2.439667929885208

Epoch: 6| Step: 8
Training loss: 2.824721336364746
Validation loss: 2.4705526777493056

Epoch: 6| Step: 9
Training loss: 2.46624493598938
Validation loss: 2.517659838481616

Epoch: 6| Step: 10
Training loss: 2.883194923400879
Validation loss: 2.5931997453012774

Epoch: 6| Step: 11
Training loss: 2.7669074535369873
Validation loss: 2.644972209007509

Epoch: 6| Step: 12
Training loss: 2.801532506942749
Validation loss: 2.6678908255792435

Epoch: 6| Step: 13
Training loss: 3.6232621669769287
Validation loss: 2.7173656648205173

Epoch: 32| Step: 0
Training loss: 2.517583131790161
Validation loss: 2.710869312286377

Epoch: 6| Step: 1
Training loss: 3.02439022064209
Validation loss: 2.692907751247447

Epoch: 6| Step: 2
Training loss: 2.3301150798797607
Validation loss: 2.618818203608195

Epoch: 6| Step: 3
Training loss: 2.3441555500030518
Validation loss: 2.521393911812895

Epoch: 6| Step: 4
Training loss: 3.1256041526794434
Validation loss: 2.4704210271117506

Epoch: 6| Step: 5
Training loss: 2.8501455783843994
Validation loss: 2.441591703763572

Epoch: 6| Step: 6
Training loss: 3.105501651763916
Validation loss: 2.4406519589885587

Epoch: 6| Step: 7
Training loss: 2.016282558441162
Validation loss: 2.4426109842074815

Epoch: 6| Step: 8
Training loss: 2.8810982704162598
Validation loss: 2.4465335645983295

Epoch: 6| Step: 9
Training loss: 3.1956794261932373
Validation loss: 2.462047007776076

Epoch: 6| Step: 10
Training loss: 3.160038948059082
Validation loss: 2.4695508095525924

Epoch: 6| Step: 11
Training loss: 1.9964237213134766
Validation loss: 2.4748690307781263

Epoch: 6| Step: 12
Training loss: 3.0565974712371826
Validation loss: 2.474032712239091

Epoch: 6| Step: 13
Training loss: 2.826817274093628
Validation loss: 2.454237402126353

Epoch: 33| Step: 0
Training loss: 2.5730485916137695
Validation loss: 2.4514512144109255

Epoch: 6| Step: 1
Training loss: 2.054517984390259
Validation loss: 2.4718565094855522

Epoch: 6| Step: 2
Training loss: 2.4048047065734863
Validation loss: 2.529524387851838

Epoch: 6| Step: 3
Training loss: 1.7951210737228394
Validation loss: 2.5277436420481694

Epoch: 6| Step: 4
Training loss: 3.5900321006774902
Validation loss: 2.5548222475154425

Epoch: 6| Step: 5
Training loss: 3.1278748512268066
Validation loss: 2.4861109820745324

Epoch: 6| Step: 6
Training loss: 2.951798915863037
Validation loss: 2.4612618723223285

Epoch: 6| Step: 7
Training loss: 2.3847858905792236
Validation loss: 2.431354820087392

Epoch: 6| Step: 8
Training loss: 1.6957064867019653
Validation loss: 2.4198813438415527

Epoch: 6| Step: 9
Training loss: 3.292912006378174
Validation loss: 2.422948124588177

Epoch: 6| Step: 10
Training loss: 3.3114066123962402
Validation loss: 2.4234705535314416

Epoch: 6| Step: 11
Training loss: 3.1059412956237793
Validation loss: 2.4328487509040424

Epoch: 6| Step: 12
Training loss: 2.870337724685669
Validation loss: 2.450785001118978

Epoch: 6| Step: 13
Training loss: 1.9885728359222412
Validation loss: 2.4328049177764566

Epoch: 34| Step: 0
Training loss: 2.842262029647827
Validation loss: 2.4296220630727787

Epoch: 6| Step: 1
Training loss: 3.377556800842285
Validation loss: 2.4442484173723447

Epoch: 6| Step: 2
Training loss: 1.9387943744659424
Validation loss: 2.4545942455209713

Epoch: 6| Step: 3
Training loss: 2.399825096130371
Validation loss: 2.4589379090134815

Epoch: 6| Step: 4
Training loss: 3.499142646789551
Validation loss: 2.474008875508462

Epoch: 6| Step: 5
Training loss: 2.8831405639648438
Validation loss: 2.4599756886882167

Epoch: 6| Step: 6
Training loss: 2.0555310249328613
Validation loss: 2.447492430287023

Epoch: 6| Step: 7
Training loss: 2.536468982696533
Validation loss: 2.43284277249408

Epoch: 6| Step: 8
Training loss: 2.8098673820495605
Validation loss: 2.4358306110546155

Epoch: 6| Step: 9
Training loss: 2.6640427112579346
Validation loss: 2.418131466834776

Epoch: 6| Step: 10
Training loss: 3.0357351303100586
Validation loss: 2.4104592530958113

Epoch: 6| Step: 11
Training loss: 2.1972317695617676
Validation loss: 2.404785344677587

Epoch: 6| Step: 12
Training loss: 2.522818088531494
Validation loss: 2.408106001474524

Epoch: 6| Step: 13
Training loss: 2.620957612991333
Validation loss: 2.4101567165825957

Epoch: 35| Step: 0
Training loss: 2.441859722137451
Validation loss: 2.4192395825539865

Epoch: 6| Step: 1
Training loss: 2.78407883644104
Validation loss: 2.421913235418258

Epoch: 6| Step: 2
Training loss: 2.5266470909118652
Validation loss: 2.4112551314856416

Epoch: 6| Step: 3
Training loss: 3.3149237632751465
Validation loss: 2.4082044375840055

Epoch: 6| Step: 4
Training loss: 2.3205254077911377
Validation loss: 2.404207447523712

Epoch: 6| Step: 5
Training loss: 2.5492324829101562
Validation loss: 2.4022980095237814

Epoch: 6| Step: 6
Training loss: 2.934150218963623
Validation loss: 2.405471877385211

Epoch: 6| Step: 7
Training loss: 2.0249838829040527
Validation loss: 2.40442394697538

Epoch: 6| Step: 8
Training loss: 3.2028396129608154
Validation loss: 2.411117101228365

Epoch: 6| Step: 9
Training loss: 2.4454429149627686
Validation loss: 2.414998592868928

Epoch: 6| Step: 10
Training loss: 2.9134840965270996
Validation loss: 2.4385458730882212

Epoch: 6| Step: 11
Training loss: 2.8285629749298096
Validation loss: 2.472946774575018

Epoch: 6| Step: 12
Training loss: 2.6308963298797607
Validation loss: 2.4932606092063327

Epoch: 6| Step: 13
Training loss: 2.586653232574463
Validation loss: 2.5186059654399915

Epoch: 36| Step: 0
Training loss: 3.3621339797973633
Validation loss: 2.5010214262111212

Epoch: 6| Step: 1
Training loss: 3.1457977294921875
Validation loss: 2.4426734806388937

Epoch: 6| Step: 2
Training loss: 2.6654417514801025
Validation loss: 2.412061760502477

Epoch: 6| Step: 3
Training loss: 2.6958906650543213
Validation loss: 2.395166302240023

Epoch: 6| Step: 4
Training loss: 3.3639912605285645
Validation loss: 2.397014541010703

Epoch: 6| Step: 5
Training loss: 2.3220646381378174
Validation loss: 2.4010382570246214

Epoch: 6| Step: 6
Training loss: 2.8664093017578125
Validation loss: 2.406235273166369

Epoch: 6| Step: 7
Training loss: 2.947812557220459
Validation loss: 2.4115668573687152

Epoch: 6| Step: 8
Training loss: 2.558201313018799
Validation loss: 2.4180937633719495

Epoch: 6| Step: 9
Training loss: 2.6443190574645996
Validation loss: 2.4203327419937297

Epoch: 6| Step: 10
Training loss: 2.6758153438568115
Validation loss: 2.4183035332669496

Epoch: 6| Step: 11
Training loss: 2.440892219543457
Validation loss: 2.415806706233691

Epoch: 6| Step: 12
Training loss: 1.7642507553100586
Validation loss: 2.4084922703363563

Epoch: 6| Step: 13
Training loss: 2.1795296669006348
Validation loss: 2.4020321779353644

Epoch: 37| Step: 0
Training loss: 2.71923828125
Validation loss: 2.3997831677877777

Epoch: 6| Step: 1
Training loss: 2.929090976715088
Validation loss: 2.3947527536781887

Epoch: 6| Step: 2
Training loss: 2.87406849861145
Validation loss: 2.3908554969295377

Epoch: 6| Step: 3
Training loss: 2.652639389038086
Validation loss: 2.388278543308217

Epoch: 6| Step: 4
Training loss: 2.5616321563720703
Validation loss: 2.397942178992815

Epoch: 6| Step: 5
Training loss: 2.14795184135437
Validation loss: 2.409764741056709

Epoch: 6| Step: 6
Training loss: 3.480968475341797
Validation loss: 2.4120900823223974

Epoch: 6| Step: 7
Training loss: 1.784877896308899
Validation loss: 2.4221854184263494

Epoch: 6| Step: 8
Training loss: 1.9785130023956299
Validation loss: 2.4256160771974953

Epoch: 6| Step: 9
Training loss: 3.0092129707336426
Validation loss: 2.4229487783165387

Epoch: 6| Step: 10
Training loss: 3.1043357849121094
Validation loss: 2.4221775518950595

Epoch: 6| Step: 11
Training loss: 2.901068687438965
Validation loss: 2.410706030425205

Epoch: 6| Step: 12
Training loss: 2.5010433197021484
Validation loss: 2.4131023396727858

Epoch: 6| Step: 13
Training loss: 2.3112454414367676
Validation loss: 2.405859416530978

Epoch: 38| Step: 0
Training loss: 3.0223569869995117
Validation loss: 2.4036791196433445

Epoch: 6| Step: 1
Training loss: 3.0708751678466797
Validation loss: 2.4049692846113637

Epoch: 6| Step: 2
Training loss: 2.498414993286133
Validation loss: 2.3962687484679686

Epoch: 6| Step: 3
Training loss: 2.840053081512451
Validation loss: 2.401336867322204

Epoch: 6| Step: 4
Training loss: 2.499454975128174
Validation loss: 2.4066792970062583

Epoch: 6| Step: 5
Training loss: 3.485750198364258
Validation loss: 2.390118291301112

Epoch: 6| Step: 6
Training loss: 1.826169490814209
Validation loss: 2.381232676967498

Epoch: 6| Step: 7
Training loss: 2.853536605834961
Validation loss: 2.3803900928907495

Epoch: 6| Step: 8
Training loss: 2.7517943382263184
Validation loss: 2.3725394356635308

Epoch: 6| Step: 9
Training loss: 1.3343510627746582
Validation loss: 2.368966289745864

Epoch: 6| Step: 10
Training loss: 3.1976492404937744
Validation loss: 2.373421674133629

Epoch: 6| Step: 11
Training loss: 1.8647083044052124
Validation loss: 2.3741946733126076

Epoch: 6| Step: 12
Training loss: 3.157418727874756
Validation loss: 2.385128143013165

Epoch: 6| Step: 13
Training loss: 2.3771824836730957
Validation loss: 2.385361502247472

Epoch: 39| Step: 0
Training loss: 2.272197723388672
Validation loss: 2.3996264857630574

Epoch: 6| Step: 1
Training loss: 2.3356573581695557
Validation loss: 2.4376840078702537

Epoch: 6| Step: 2
Training loss: 2.894519805908203
Validation loss: 2.502467901475968

Epoch: 6| Step: 3
Training loss: 2.3249833583831787
Validation loss: 2.554353911389587

Epoch: 6| Step: 4
Training loss: 2.4464316368103027
Validation loss: 2.5282816451082946

Epoch: 6| Step: 5
Training loss: 2.993525505065918
Validation loss: 2.489568169398974

Epoch: 6| Step: 6
Training loss: 3.2715060710906982
Validation loss: 2.433931617326634

Epoch: 6| Step: 7
Training loss: 2.0297164916992188
Validation loss: 2.3829372108623548

Epoch: 6| Step: 8
Training loss: 2.768413543701172
Validation loss: 2.3635407058141564

Epoch: 6| Step: 9
Training loss: 2.6586103439331055
Validation loss: 2.362257537021432

Epoch: 6| Step: 10
Training loss: 2.9504141807556152
Validation loss: 2.363597877563969

Epoch: 6| Step: 11
Training loss: 2.5625038146972656
Validation loss: 2.3666510735788653

Epoch: 6| Step: 12
Training loss: 2.868285894393921
Validation loss: 2.365469854365113

Epoch: 6| Step: 13
Training loss: 2.950807571411133
Validation loss: 2.367323492162971

Epoch: 40| Step: 0
Training loss: 3.5339393615722656
Validation loss: 2.3677697079156035

Epoch: 6| Step: 1
Training loss: 2.484748363494873
Validation loss: 2.3698808762335006

Epoch: 6| Step: 2
Training loss: 2.598860263824463
Validation loss: 2.3689654360535326

Epoch: 6| Step: 3
Training loss: 2.2047438621520996
Validation loss: 2.3680547950088338

Epoch: 6| Step: 4
Training loss: 2.3297722339630127
Validation loss: 2.3659919872078845

Epoch: 6| Step: 5
Training loss: 2.717560052871704
Validation loss: 2.3641069140485538

Epoch: 6| Step: 6
Training loss: 2.692688465118408
Validation loss: 2.3635142182791107

Epoch: 6| Step: 7
Training loss: 2.744659662246704
Validation loss: 2.358073598595076

Epoch: 6| Step: 8
Training loss: 3.0077545642852783
Validation loss: 2.3576078953281527

Epoch: 6| Step: 9
Training loss: 2.360807180404663
Validation loss: 2.3555613858725435

Epoch: 6| Step: 10
Training loss: 2.5754456520080566
Validation loss: 2.350475711207236

Epoch: 6| Step: 11
Training loss: 2.8125534057617188
Validation loss: 2.347102161376707

Epoch: 6| Step: 12
Training loss: 2.208512783050537
Validation loss: 2.356612108087027

Epoch: 6| Step: 13
Training loss: 2.949091911315918
Validation loss: 2.3621891877984487

Epoch: 41| Step: 0
Training loss: 3.203411102294922
Validation loss: 2.3637778835911907

Epoch: 6| Step: 1
Training loss: 2.984473705291748
Validation loss: 2.370406222599809

Epoch: 6| Step: 2
Training loss: 2.922024726867676
Validation loss: 2.369466543197632

Epoch: 6| Step: 3
Training loss: 1.7121692895889282
Validation loss: 2.3681217162839827

Epoch: 6| Step: 4
Training loss: 2.418839454650879
Validation loss: 2.3784298102060952

Epoch: 6| Step: 5
Training loss: 2.2403712272644043
Validation loss: 2.391255488959692

Epoch: 6| Step: 6
Training loss: 2.9846179485321045
Validation loss: 2.4094780721972064

Epoch: 6| Step: 7
Training loss: 2.322436809539795
Validation loss: 2.4171083127298663

Epoch: 6| Step: 8
Training loss: 2.5514259338378906
Validation loss: 2.421964248021444

Epoch: 6| Step: 9
Training loss: 2.664896011352539
Validation loss: 2.4054720324854695

Epoch: 6| Step: 10
Training loss: 3.173600673675537
Validation loss: 2.393723226362659

Epoch: 6| Step: 11
Training loss: 2.6567296981811523
Validation loss: 2.390839757457856

Epoch: 6| Step: 12
Training loss: 2.2530970573425293
Validation loss: 2.3855340685895694

Epoch: 6| Step: 13
Training loss: 2.5813114643096924
Validation loss: 2.3738908126790035

Epoch: 42| Step: 0
Training loss: 2.8236327171325684
Validation loss: 2.3550368842258247

Epoch: 6| Step: 1
Training loss: 3.2612085342407227
Validation loss: 2.3486742998964045

Epoch: 6| Step: 2
Training loss: 2.935856342315674
Validation loss: 2.3472067822692213

Epoch: 6| Step: 3
Training loss: 2.03326153755188
Validation loss: 2.3571034169966176

Epoch: 6| Step: 4
Training loss: 2.3928894996643066
Validation loss: 2.3693844451699206

Epoch: 6| Step: 5
Training loss: 3.0274558067321777
Validation loss: 2.390523797722273

Epoch: 6| Step: 6
Training loss: 2.517075300216675
Validation loss: 2.3772190514431206

Epoch: 6| Step: 7
Training loss: 2.9248602390289307
Validation loss: 2.3671976571441977

Epoch: 6| Step: 8
Training loss: 2.541654586791992
Validation loss: 2.3630634200188423

Epoch: 6| Step: 9
Training loss: 2.0959436893463135
Validation loss: 2.358300930710249

Epoch: 6| Step: 10
Training loss: 2.845189094543457
Validation loss: 2.354795379023398

Epoch: 6| Step: 11
Training loss: 2.6301462650299072
Validation loss: 2.3526449536764495

Epoch: 6| Step: 12
Training loss: 2.465618848800659
Validation loss: 2.3511946534597747

Epoch: 6| Step: 13
Training loss: 2.631429672241211
Validation loss: 2.345038790856638

Epoch: 43| Step: 0
Training loss: 2.174299478530884
Validation loss: 2.340113280921854

Epoch: 6| Step: 1
Training loss: 2.964341402053833
Validation loss: 2.3412310820753857

Epoch: 6| Step: 2
Training loss: 2.5456271171569824
Validation loss: 2.3440112798444686

Epoch: 6| Step: 3
Training loss: 1.9633026123046875
Validation loss: 2.3543827149175827

Epoch: 6| Step: 4
Training loss: 2.8207945823669434
Validation loss: 2.366273328822146

Epoch: 6| Step: 5
Training loss: 3.091188669204712
Validation loss: 2.374615489795644

Epoch: 6| Step: 6
Training loss: 2.897944688796997
Validation loss: 2.3727914697380474

Epoch: 6| Step: 7
Training loss: 1.995058536529541
Validation loss: 2.3820445691385577

Epoch: 6| Step: 8
Training loss: 2.490945816040039
Validation loss: 2.3823764811279955

Epoch: 6| Step: 9
Training loss: 2.785766839981079
Validation loss: 2.382350743457835

Epoch: 6| Step: 10
Training loss: 2.385082244873047
Validation loss: 2.375656011284039

Epoch: 6| Step: 11
Training loss: 2.615994453430176
Validation loss: 2.3706292144713865

Epoch: 6| Step: 12
Training loss: 2.5826416015625
Validation loss: 2.3815387884775796

Epoch: 6| Step: 13
Training loss: 3.837247133255005
Validation loss: 2.3889309795953895

Epoch: 44| Step: 0
Training loss: 2.9014151096343994
Validation loss: 2.404716823690681

Epoch: 6| Step: 1
Training loss: 2.412266254425049
Validation loss: 2.4069750642263763

Epoch: 6| Step: 2
Training loss: 3.2639107704162598
Validation loss: 2.396385528708017

Epoch: 6| Step: 3
Training loss: 1.8838438987731934
Validation loss: 2.3851760382293374

Epoch: 6| Step: 4
Training loss: 2.443567991256714
Validation loss: 2.3742960576088197

Epoch: 6| Step: 5
Training loss: 2.9773478507995605
Validation loss: 2.361509930702948

Epoch: 6| Step: 6
Training loss: 2.566537380218506
Validation loss: 2.3505887600683395

Epoch: 6| Step: 7
Training loss: 2.866257667541504
Validation loss: 2.338893923708188

Epoch: 6| Step: 8
Training loss: 2.4501636028289795
Validation loss: 2.3349950698114212

Epoch: 6| Step: 9
Training loss: 2.498244524002075
Validation loss: 2.325691989673081

Epoch: 6| Step: 10
Training loss: 2.382460594177246
Validation loss: 2.3270703002970707

Epoch: 6| Step: 11
Training loss: 2.089780330657959
Validation loss: 2.323539190394904

Epoch: 6| Step: 12
Training loss: 3.3928310871124268
Validation loss: 2.3193324945306264

Epoch: 6| Step: 13
Training loss: 2.182776689529419
Validation loss: 2.3219692296879266

Epoch: 45| Step: 0
Training loss: 2.605900764465332
Validation loss: 2.3202060217498452

Epoch: 6| Step: 1
Training loss: 2.535539150238037
Validation loss: 2.3245364824930825

Epoch: 6| Step: 2
Training loss: 2.7412772178649902
Validation loss: 2.321385124678253

Epoch: 6| Step: 3
Training loss: 3.8253002166748047
Validation loss: 2.31812798079624

Epoch: 6| Step: 4
Training loss: 2.1242904663085938
Validation loss: 2.3222727467936854

Epoch: 6| Step: 5
Training loss: 2.6140642166137695
Validation loss: 2.3201749376071397

Epoch: 6| Step: 6
Training loss: 2.285548210144043
Validation loss: 2.324892026121898

Epoch: 6| Step: 7
Training loss: 2.4297118186950684
Validation loss: 2.3315408716919603

Epoch: 6| Step: 8
Training loss: 1.9963760375976562
Validation loss: 2.3292852678606586

Epoch: 6| Step: 9
Training loss: 2.63690185546875
Validation loss: 2.3421200321566675

Epoch: 6| Step: 10
Training loss: 3.0337982177734375
Validation loss: 2.3552274345069804

Epoch: 6| Step: 11
Training loss: 2.271094560623169
Validation loss: 2.374133304883075

Epoch: 6| Step: 12
Training loss: 2.588512897491455
Validation loss: 2.3783991926459858

Epoch: 6| Step: 13
Training loss: 2.9029438495635986
Validation loss: 2.38711198940072

Epoch: 46| Step: 0
Training loss: 2.280665874481201
Validation loss: 2.370119656285932

Epoch: 6| Step: 1
Training loss: 2.824990749359131
Validation loss: 2.340813216342721

Epoch: 6| Step: 2
Training loss: 3.090191125869751
Validation loss: 2.3250134837242866

Epoch: 6| Step: 3
Training loss: 3.171196937561035
Validation loss: 2.316986918449402

Epoch: 6| Step: 4
Training loss: 2.753041982650757
Validation loss: 2.3079464217667938

Epoch: 6| Step: 5
Training loss: 2.7399885654449463
Validation loss: 2.3083362348618044

Epoch: 6| Step: 6
Training loss: 2.645777940750122
Validation loss: 2.310747149170086

Epoch: 6| Step: 7
Training loss: 2.3204545974731445
Validation loss: 2.3103713553438903

Epoch: 6| Step: 8
Training loss: 3.321601390838623
Validation loss: 2.3099725066974597

Epoch: 6| Step: 9
Training loss: 2.364902973175049
Validation loss: 2.302628001859111

Epoch: 6| Step: 10
Training loss: 2.6897010803222656
Validation loss: 2.3021539411237164

Epoch: 6| Step: 11
Training loss: 1.871569275856018
Validation loss: 2.3035767668037006

Epoch: 6| Step: 12
Training loss: 1.946825385093689
Validation loss: 2.3017185964891986

Epoch: 6| Step: 13
Training loss: 2.4740257263183594
Validation loss: 2.3025551970287035

Epoch: 47| Step: 0
Training loss: 2.493877410888672
Validation loss: 2.3019738710054787

Epoch: 6| Step: 1
Training loss: 2.754971504211426
Validation loss: 2.300688594900152

Epoch: 6| Step: 2
Training loss: 2.136803388595581
Validation loss: 2.305701178889121

Epoch: 6| Step: 3
Training loss: 2.5142698287963867
Validation loss: 2.3040390578649377

Epoch: 6| Step: 4
Training loss: 2.918447256088257
Validation loss: 2.3070673122200915

Epoch: 6| Step: 5
Training loss: 2.5945229530334473
Validation loss: 2.309343530285743

Epoch: 6| Step: 6
Training loss: 2.9537787437438965
Validation loss: 2.315003997536116

Epoch: 6| Step: 7
Training loss: 2.5663576126098633
Validation loss: 2.3201235801942888

Epoch: 6| Step: 8
Training loss: 2.7217540740966797
Validation loss: 2.3297247386747792

Epoch: 6| Step: 9
Training loss: 1.9841194152832031
Validation loss: 2.3310001075908704

Epoch: 6| Step: 10
Training loss: 2.3303802013397217
Validation loss: 2.341952600786763

Epoch: 6| Step: 11
Training loss: 3.2194507122039795
Validation loss: 2.3456738354057394

Epoch: 6| Step: 12
Training loss: 2.4229655265808105
Validation loss: 2.3417169329940632

Epoch: 6| Step: 13
Training loss: 2.480945348739624
Validation loss: 2.332626747828658

Epoch: 48| Step: 0
Training loss: 2.739715099334717
Validation loss: 2.3258935918090162

Epoch: 6| Step: 1
Training loss: 1.6564111709594727
Validation loss: 2.3165337859943347

Epoch: 6| Step: 2
Training loss: 1.4566857814788818
Validation loss: 2.314888213270454

Epoch: 6| Step: 3
Training loss: 3.2732913494110107
Validation loss: 2.3082749100141626

Epoch: 6| Step: 4
Training loss: 2.7266058921813965
Validation loss: 2.3099186548622708

Epoch: 6| Step: 5
Training loss: 2.1801373958587646
Validation loss: 2.3015016125094507

Epoch: 6| Step: 6
Training loss: 2.556152105331421
Validation loss: 2.3077726338499334

Epoch: 6| Step: 7
Training loss: 3.1376264095306396
Validation loss: 2.304583722545255

Epoch: 6| Step: 8
Training loss: 2.6668787002563477
Validation loss: 2.302784373683314

Epoch: 6| Step: 9
Training loss: 2.623782157897949
Validation loss: 2.310117438275327

Epoch: 6| Step: 10
Training loss: 2.3675174713134766
Validation loss: 2.310416513873685

Epoch: 6| Step: 11
Training loss: 2.9402880668640137
Validation loss: 2.311088231302077

Epoch: 6| Step: 12
Training loss: 2.6440629959106445
Validation loss: 2.3152662579731276

Epoch: 6| Step: 13
Training loss: 3.5962932109832764
Validation loss: 2.3153905227620113

Epoch: 49| Step: 0
Training loss: 2.886427164077759
Validation loss: 2.307976325352987

Epoch: 6| Step: 1
Training loss: 2.6092395782470703
Validation loss: 2.298872870783652

Epoch: 6| Step: 2
Training loss: 2.6908788681030273
Validation loss: 2.294562405155551

Epoch: 6| Step: 3
Training loss: 2.628633499145508
Validation loss: 2.2937297346771404

Epoch: 6| Step: 4
Training loss: 3.065314769744873
Validation loss: 2.2908112182412097

Epoch: 6| Step: 5
Training loss: 2.564237356185913
Validation loss: 2.2868890698238085

Epoch: 6| Step: 6
Training loss: 1.9958914518356323
Validation loss: 2.290618578592936

Epoch: 6| Step: 7
Training loss: 2.6106557846069336
Validation loss: 2.294656340793897

Epoch: 6| Step: 8
Training loss: 2.049210786819458
Validation loss: 2.3145427678221013

Epoch: 6| Step: 9
Training loss: 2.296583652496338
Validation loss: 2.3466299297989055

Epoch: 6| Step: 10
Training loss: 2.5342869758605957
Validation loss: 2.368180831273397

Epoch: 6| Step: 11
Training loss: 2.9443066120147705
Validation loss: 2.3842598366481003

Epoch: 6| Step: 12
Training loss: 2.7626821994781494
Validation loss: 2.3929253573058755

Epoch: 6| Step: 13
Training loss: 2.6540117263793945
Validation loss: 2.3757173809953915

Epoch: 50| Step: 0
Training loss: 2.7067201137542725
Validation loss: 2.353066767415693

Epoch: 6| Step: 1
Training loss: 2.4436416625976562
Validation loss: 2.3452941499730593

Epoch: 6| Step: 2
Training loss: 2.0892386436462402
Validation loss: 2.3269152154204664

Epoch: 6| Step: 3
Training loss: 2.741255521774292
Validation loss: 2.316527651202294

Epoch: 6| Step: 4
Training loss: 3.338735818862915
Validation loss: 2.3081438631139775

Epoch: 6| Step: 5
Training loss: 2.9872798919677734
Validation loss: 2.304459123201268

Epoch: 6| Step: 6
Training loss: 2.170440673828125
Validation loss: 2.3051346963451755

Epoch: 6| Step: 7
Training loss: 2.5252914428710938
Validation loss: 2.2881294296633814

Epoch: 6| Step: 8
Training loss: 2.830169916152954
Validation loss: 2.2830736790933917

Epoch: 6| Step: 9
Training loss: 2.46254301071167
Validation loss: 2.2800817540896836

Epoch: 6| Step: 10
Training loss: 2.900481700897217
Validation loss: 2.2795014842864005

Epoch: 6| Step: 11
Training loss: 2.4954028129577637
Validation loss: 2.278305028074531

Epoch: 6| Step: 12
Training loss: 1.8523603677749634
Validation loss: 2.2784108756690897

Epoch: 6| Step: 13
Training loss: 2.158320426940918
Validation loss: 2.2807597780740387

Epoch: 51| Step: 0
Training loss: 2.424468517303467
Validation loss: 2.27891291341474

Epoch: 6| Step: 1
Training loss: 2.5223734378814697
Validation loss: 2.27812252377951

Epoch: 6| Step: 2
Training loss: 2.2044506072998047
Validation loss: 2.2803719505187003

Epoch: 6| Step: 3
Training loss: 2.435990333557129
Validation loss: 2.2753292283704205

Epoch: 6| Step: 4
Training loss: 2.745598316192627
Validation loss: 2.2807652360649517

Epoch: 6| Step: 5
Training loss: 2.5450236797332764
Validation loss: 2.2926425267291326

Epoch: 6| Step: 6
Training loss: 2.3194591999053955
Validation loss: 2.3026737372080484

Epoch: 6| Step: 7
Training loss: 2.9336998462677
Validation loss: 2.328782458459177

Epoch: 6| Step: 8
Training loss: 2.494905710220337
Validation loss: 2.344694827192573

Epoch: 6| Step: 9
Training loss: 2.223982334136963
Validation loss: 2.3491990694435696

Epoch: 6| Step: 10
Training loss: 3.1391806602478027
Validation loss: 2.33593818705569

Epoch: 6| Step: 11
Training loss: 2.3279829025268555
Validation loss: 2.311419669017997

Epoch: 6| Step: 12
Training loss: 3.193765163421631
Validation loss: 2.2969304130923365

Epoch: 6| Step: 13
Training loss: 2.4901139736175537
Validation loss: 2.2778090123207337

Epoch: 52| Step: 0
Training loss: 2.205522060394287
Validation loss: 2.2720137898639967

Epoch: 6| Step: 1
Training loss: 2.5948731899261475
Validation loss: 2.2721664623547624

Epoch: 6| Step: 2
Training loss: 2.511026382446289
Validation loss: 2.2734885369577715

Epoch: 6| Step: 3
Training loss: 2.2860162258148193
Validation loss: 2.273935056501819

Epoch: 6| Step: 4
Training loss: 3.6949684619903564
Validation loss: 2.274013450068812

Epoch: 6| Step: 5
Training loss: 2.8355164527893066
Validation loss: 2.26936020646044

Epoch: 6| Step: 6
Training loss: 2.260768413543701
Validation loss: 2.2743201768526466

Epoch: 6| Step: 7
Training loss: 2.131314277648926
Validation loss: 2.2716826956759215

Epoch: 6| Step: 8
Training loss: 3.247894763946533
Validation loss: 2.27020489656797

Epoch: 6| Step: 9
Training loss: 1.8677849769592285
Validation loss: 2.271061230731267

Epoch: 6| Step: 10
Training loss: 1.9785257577896118
Validation loss: 2.2694304373956498

Epoch: 6| Step: 11
Training loss: 2.4493017196655273
Validation loss: 2.267450160877679

Epoch: 6| Step: 12
Training loss: 2.9860007762908936
Validation loss: 2.2680814035477175

Epoch: 6| Step: 13
Training loss: 3.511878728866577
Validation loss: 2.2709326564624743

Epoch: 53| Step: 0
Training loss: 1.8290178775787354
Validation loss: 2.2701690350809405

Epoch: 6| Step: 1
Training loss: 2.7622737884521484
Validation loss: 2.2799414703922887

Epoch: 6| Step: 2
Training loss: 2.3620200157165527
Validation loss: 2.278340998516288

Epoch: 6| Step: 3
Training loss: 2.1806745529174805
Validation loss: 2.2810963174348236

Epoch: 6| Step: 4
Training loss: 2.5256659984588623
Validation loss: 2.284622048818937

Epoch: 6| Step: 5
Training loss: 2.25164794921875
Validation loss: 2.293397113841067

Epoch: 6| Step: 6
Training loss: 2.568343162536621
Validation loss: 2.2843729526765886

Epoch: 6| Step: 7
Training loss: 2.6028037071228027
Validation loss: 2.279825727144877

Epoch: 6| Step: 8
Training loss: 2.964350700378418
Validation loss: 2.274520899659844

Epoch: 6| Step: 9
Training loss: 2.908897876739502
Validation loss: 2.2679306742965535

Epoch: 6| Step: 10
Training loss: 2.363694667816162
Validation loss: 2.260848476040748

Epoch: 6| Step: 11
Training loss: 3.2853806018829346
Validation loss: 2.2650369072473175

Epoch: 6| Step: 12
Training loss: 2.7473816871643066
Validation loss: 2.26513417818213

Epoch: 6| Step: 13
Training loss: 2.3598132133483887
Validation loss: 2.2704629077706286

Epoch: 54| Step: 0
Training loss: 2.485403537750244
Validation loss: 2.268116328024095

Epoch: 6| Step: 1
Training loss: 2.499255657196045
Validation loss: 2.270937976016793

Epoch: 6| Step: 2
Training loss: 2.669677257537842
Validation loss: 2.281287408644153

Epoch: 6| Step: 3
Training loss: 2.52021861076355
Validation loss: 2.286875868356356

Epoch: 6| Step: 4
Training loss: 2.76802396774292
Validation loss: 2.2933699982140654

Epoch: 6| Step: 5
Training loss: 2.323462963104248
Validation loss: 2.3032750634736914

Epoch: 6| Step: 6
Training loss: 3.089120864868164
Validation loss: 2.315394296441027

Epoch: 6| Step: 7
Training loss: 2.519547939300537
Validation loss: 2.3041742104356007

Epoch: 6| Step: 8
Training loss: 2.388922691345215
Validation loss: 2.3087204720384333

Epoch: 6| Step: 9
Training loss: 3.002439498901367
Validation loss: 2.2833434433065434

Epoch: 6| Step: 10
Training loss: 2.157700777053833
Validation loss: 2.274597998588316

Epoch: 6| Step: 11
Training loss: 1.9192030429840088
Validation loss: 2.265767538419334

Epoch: 6| Step: 12
Training loss: 2.647658109664917
Validation loss: 2.259362354073473

Epoch: 6| Step: 13
Training loss: 2.8473262786865234
Validation loss: 2.253588050924322

Epoch: 55| Step: 0
Training loss: 2.670607089996338
Validation loss: 2.2569065991268364

Epoch: 6| Step: 1
Training loss: 2.805448293685913
Validation loss: 2.2525688512350923

Epoch: 6| Step: 2
Training loss: 2.368913173675537
Validation loss: 2.254665884920346

Epoch: 6| Step: 3
Training loss: 2.3991873264312744
Validation loss: 2.252599839241274

Epoch: 6| Step: 4
Training loss: 2.2188515663146973
Validation loss: 2.262219008579049

Epoch: 6| Step: 5
Training loss: 3.230177164077759
Validation loss: 2.2765487829844155

Epoch: 6| Step: 6
Training loss: 2.256904363632202
Validation loss: 2.2691225864553966

Epoch: 6| Step: 7
Training loss: 2.1404058933258057
Validation loss: 2.2724948903565765

Epoch: 6| Step: 8
Training loss: 3.102790355682373
Validation loss: 2.2712406932666735

Epoch: 6| Step: 9
Training loss: 2.5916690826416016
Validation loss: 2.2720901273911998

Epoch: 6| Step: 10
Training loss: 2.8484232425689697
Validation loss: 2.2764285866932203

Epoch: 6| Step: 11
Training loss: 2.2850940227508545
Validation loss: 2.2680463201256207

Epoch: 6| Step: 12
Training loss: 1.9808437824249268
Validation loss: 2.2679631966416554

Epoch: 6| Step: 13
Training loss: 2.7893946170806885
Validation loss: 2.267947325142481

Epoch: 56| Step: 0
Training loss: 2.8111486434936523
Validation loss: 2.268204624934863

Epoch: 6| Step: 1
Training loss: 2.8737642765045166
Validation loss: 2.255666502060429

Epoch: 6| Step: 2
Training loss: 2.401146411895752
Validation loss: 2.2500629437867032

Epoch: 6| Step: 3
Training loss: 2.7284488677978516
Validation loss: 2.242628284679946

Epoch: 6| Step: 4
Training loss: 2.274977684020996
Validation loss: 2.2459929245774464

Epoch: 6| Step: 5
Training loss: 2.6424527168273926
Validation loss: 2.245031056865569

Epoch: 6| Step: 6
Training loss: 1.6835881471633911
Validation loss: 2.2557888928280083

Epoch: 6| Step: 7
Training loss: 2.2838845252990723
Validation loss: 2.2678622661098355

Epoch: 6| Step: 8
Training loss: 2.0359201431274414
Validation loss: 2.2704888492502193

Epoch: 6| Step: 9
Training loss: 2.1029810905456543
Validation loss: 2.28364319955149

Epoch: 6| Step: 10
Training loss: 2.70701265335083
Validation loss: 2.2856163876031035

Epoch: 6| Step: 11
Training loss: 3.2983245849609375
Validation loss: 2.278639547286495

Epoch: 6| Step: 12
Training loss: 2.6031250953674316
Validation loss: 2.2662472032731578

Epoch: 6| Step: 13
Training loss: 3.35784649848938
Validation loss: 2.276445088847991

Epoch: 57| Step: 0
Training loss: 2.586425304412842
Validation loss: 2.2733557967729467

Epoch: 6| Step: 1
Training loss: 2.1383485794067383
Validation loss: 2.2824327048435005

Epoch: 6| Step: 2
Training loss: 2.1979947090148926
Validation loss: 2.2647562065432147

Epoch: 6| Step: 3
Training loss: 2.6944069862365723
Validation loss: 2.259863635545136

Epoch: 6| Step: 4
Training loss: 2.069856882095337
Validation loss: 2.2483872546944568

Epoch: 6| Step: 5
Training loss: 3.2390332221984863
Validation loss: 2.246884378053809

Epoch: 6| Step: 6
Training loss: 2.611057758331299
Validation loss: 2.2340148994999547

Epoch: 6| Step: 7
Training loss: 2.3302745819091797
Validation loss: 2.231516509927729

Epoch: 6| Step: 8
Training loss: 2.31781005859375
Validation loss: 2.2343327870932956

Epoch: 6| Step: 9
Training loss: 2.908719778060913
Validation loss: 2.2353556797068608

Epoch: 6| Step: 10
Training loss: 2.229583740234375
Validation loss: 2.2314436692063526

Epoch: 6| Step: 11
Training loss: 2.1403539180755615
Validation loss: 2.2370193696791127

Epoch: 6| Step: 12
Training loss: 2.8714776039123535
Validation loss: 2.2393548104070846

Epoch: 6| Step: 13
Training loss: 3.3982419967651367
Validation loss: 2.245797869979694

Epoch: 58| Step: 0
Training loss: 2.0977962017059326
Validation loss: 2.244855123181497

Epoch: 6| Step: 1
Training loss: 2.7295098304748535
Validation loss: 2.2492602179127354

Epoch: 6| Step: 2
Training loss: 2.273623466491699
Validation loss: 2.2589943024419967

Epoch: 6| Step: 3
Training loss: 1.7941632270812988
Validation loss: 2.2716616199862574

Epoch: 6| Step: 4
Training loss: 2.224708080291748
Validation loss: 2.280291730357755

Epoch: 6| Step: 5
Training loss: 3.438807487487793
Validation loss: 2.300332994871242

Epoch: 6| Step: 6
Training loss: 2.901789665222168
Validation loss: 2.3370906383760515

Epoch: 6| Step: 7
Training loss: 2.8175601959228516
Validation loss: 2.34456628881475

Epoch: 6| Step: 8
Training loss: 2.497556686401367
Validation loss: 2.292254609446372

Epoch: 6| Step: 9
Training loss: 2.29365873336792
Validation loss: 2.2451336204364734

Epoch: 6| Step: 10
Training loss: 2.161273956298828
Validation loss: 2.216751152469266

Epoch: 6| Step: 11
Training loss: 3.05827260017395
Validation loss: 2.213859381214265

Epoch: 6| Step: 12
Training loss: 2.2645742893218994
Validation loss: 2.218080935939666

Epoch: 6| Step: 13
Training loss: 2.8270387649536133
Validation loss: 2.2160514400851343

Epoch: 59| Step: 0
Training loss: 2.7642831802368164
Validation loss: 2.2163377705440728

Epoch: 6| Step: 1
Training loss: 1.8045413494110107
Validation loss: 2.213994103093301

Epoch: 6| Step: 2
Training loss: 3.203739643096924
Validation loss: 2.217877008581674

Epoch: 6| Step: 3
Training loss: 1.2946804761886597
Validation loss: 2.2167873715841644

Epoch: 6| Step: 4
Training loss: 2.964162826538086
Validation loss: 2.227109129710864

Epoch: 6| Step: 5
Training loss: 2.6658082008361816
Validation loss: 2.251974498071978

Epoch: 6| Step: 6
Training loss: 2.6172714233398438
Validation loss: 2.2905318608847995

Epoch: 6| Step: 7
Training loss: 2.8845090866088867
Validation loss: 2.326426929043185

Epoch: 6| Step: 8
Training loss: 2.5017266273498535
Validation loss: 2.3654053159939346

Epoch: 6| Step: 9
Training loss: 2.4902918338775635
Validation loss: 2.3802374280909055

Epoch: 6| Step: 10
Training loss: 3.941223382949829
Validation loss: 2.3650763957731185

Epoch: 6| Step: 11
Training loss: 2.383165121078491
Validation loss: 2.3146337155372865

Epoch: 6| Step: 12
Training loss: 1.6969660520553589
Validation loss: 2.265496369331114

Epoch: 6| Step: 13
Training loss: 2.68666934967041
Validation loss: 2.2451050589161534

Epoch: 60| Step: 0
Training loss: 2.498433828353882
Validation loss: 2.2319811646656325

Epoch: 6| Step: 1
Training loss: 2.3785219192504883
Validation loss: 2.2219595191299275

Epoch: 6| Step: 2
Training loss: 2.4912033081054688
Validation loss: 2.2198171615600586

Epoch: 6| Step: 3
Training loss: 2.348033905029297
Validation loss: 2.22420443642524

Epoch: 6| Step: 4
Training loss: 2.174290657043457
Validation loss: 2.214197228031774

Epoch: 6| Step: 5
Training loss: 1.4549291133880615
Validation loss: 2.2224748698613976

Epoch: 6| Step: 6
Training loss: 2.655843496322632
Validation loss: 2.2230478537979947

Epoch: 6| Step: 7
Training loss: 2.9731192588806152
Validation loss: 2.223333571546821

Epoch: 6| Step: 8
Training loss: 3.7438266277313232
Validation loss: 2.2397545230004097

Epoch: 6| Step: 9
Training loss: 2.673035144805908
Validation loss: 2.2346983635297386

Epoch: 6| Step: 10
Training loss: 3.1171982288360596
Validation loss: 2.22976775323191

Epoch: 6| Step: 11
Training loss: 2.41624116897583
Validation loss: 2.2180069467072845

Epoch: 6| Step: 12
Training loss: 1.8256839513778687
Validation loss: 2.2198461255719586

Epoch: 6| Step: 13
Training loss: 2.5976946353912354
Validation loss: 2.222573467480239

Epoch: 61| Step: 0
Training loss: 2.221066474914551
Validation loss: 2.209114759199081

Epoch: 6| Step: 1
Training loss: 2.0915985107421875
Validation loss: 2.204328206277663

Epoch: 6| Step: 2
Training loss: 2.406383514404297
Validation loss: 2.2149846861439366

Epoch: 6| Step: 3
Training loss: 2.242556571960449
Validation loss: 2.2231989214497228

Epoch: 6| Step: 4
Training loss: 2.328061819076538
Validation loss: 2.2413695858370875

Epoch: 6| Step: 5
Training loss: 1.918850064277649
Validation loss: 2.2409754876167542

Epoch: 6| Step: 6
Training loss: 2.7642858028411865
Validation loss: 2.2329721220078005

Epoch: 6| Step: 7
Training loss: 2.784101963043213
Validation loss: 2.2262166546237085

Epoch: 6| Step: 8
Training loss: 2.6549313068389893
Validation loss: 2.212078235482657

Epoch: 6| Step: 9
Training loss: 1.948310375213623
Validation loss: 2.2073441731032504

Epoch: 6| Step: 10
Training loss: 3.321329116821289
Validation loss: 2.2039700067171486

Epoch: 6| Step: 11
Training loss: 2.7573678493499756
Validation loss: 2.2024545951556136

Epoch: 6| Step: 12
Training loss: 2.7504725456237793
Validation loss: 2.1988722893499557

Epoch: 6| Step: 13
Training loss: 3.185502767562866
Validation loss: 2.196539689135808

Epoch: 62| Step: 0
Training loss: 2.7622480392456055
Validation loss: 2.192724971361058

Epoch: 6| Step: 1
Training loss: 1.6761207580566406
Validation loss: 2.200949566338652

Epoch: 6| Step: 2
Training loss: 2.729384660720825
Validation loss: 2.2028046090115785

Epoch: 6| Step: 3
Training loss: 2.919558525085449
Validation loss: 2.2132186223101873

Epoch: 6| Step: 4
Training loss: 2.7662670612335205
Validation loss: 2.205546445744012

Epoch: 6| Step: 5
Training loss: 2.803628921508789
Validation loss: 2.214856642548756

Epoch: 6| Step: 6
Training loss: 2.651641607284546
Validation loss: 2.2119536425477717

Epoch: 6| Step: 7
Training loss: 2.8605895042419434
Validation loss: 2.2034022346619637

Epoch: 6| Step: 8
Training loss: 2.981107234954834
Validation loss: 2.204580537734493

Epoch: 6| Step: 9
Training loss: 2.4913270473480225
Validation loss: 2.19821947620761

Epoch: 6| Step: 10
Training loss: 1.468827247619629
Validation loss: 2.21257504083777

Epoch: 6| Step: 11
Training loss: 2.4472107887268066
Validation loss: 2.2470897295141734

Epoch: 6| Step: 12
Training loss: 1.512205719947815
Validation loss: 2.2824528589043567

Epoch: 6| Step: 13
Training loss: 2.8910698890686035
Validation loss: 2.302568768942228

Epoch: 63| Step: 0
Training loss: 2.1522295475006104
Validation loss: 2.327947452504148

Epoch: 6| Step: 1
Training loss: 2.362901210784912
Validation loss: 2.3454133002988753

Epoch: 6| Step: 2
Training loss: 3.0313968658447266
Validation loss: 2.3374874027826453

Epoch: 6| Step: 3
Training loss: 2.272204637527466
Validation loss: 2.3162126951320197

Epoch: 6| Step: 4
Training loss: 2.45635986328125
Validation loss: 2.29005366627888

Epoch: 6| Step: 5
Training loss: 3.0710389614105225
Validation loss: 2.245251242832471

Epoch: 6| Step: 6
Training loss: 2.5677971839904785
Validation loss: 2.2164409596432924

Epoch: 6| Step: 7
Training loss: 2.685671329498291
Validation loss: 2.1959196521389868

Epoch: 6| Step: 8
Training loss: 3.1822333335876465
Validation loss: 2.1835911402138333

Epoch: 6| Step: 9
Training loss: 2.058629274368286
Validation loss: 2.176993621292935

Epoch: 6| Step: 10
Training loss: 2.6629295349121094
Validation loss: 2.1718832446682836

Epoch: 6| Step: 11
Training loss: 1.6267998218536377
Validation loss: 2.169973534922446

Epoch: 6| Step: 12
Training loss: 2.5148189067840576
Validation loss: 2.170754719805974

Epoch: 6| Step: 13
Training loss: 2.4518845081329346
Validation loss: 2.1715381786387455

Epoch: 64| Step: 0
Training loss: 2.7528696060180664
Validation loss: 2.171396815648643

Epoch: 6| Step: 1
Training loss: 2.5288772583007812
Validation loss: 2.166066115902316

Epoch: 6| Step: 2
Training loss: 2.3797240257263184
Validation loss: 2.17096867099885

Epoch: 6| Step: 3
Training loss: 1.8711776733398438
Validation loss: 2.174798252762005

Epoch: 6| Step: 4
Training loss: 2.513028621673584
Validation loss: 2.2004056181958926

Epoch: 6| Step: 5
Training loss: 1.9147753715515137
Validation loss: 2.2221038546613467

Epoch: 6| Step: 6
Training loss: 2.7281832695007324
Validation loss: 2.235645140371015

Epoch: 6| Step: 7
Training loss: 2.3723645210266113
Validation loss: 2.236858444829141

Epoch: 6| Step: 8
Training loss: 3.4072301387786865
Validation loss: 2.240968119713568

Epoch: 6| Step: 9
Training loss: 2.433079719543457
Validation loss: 2.219129729014571

Epoch: 6| Step: 10
Training loss: 2.5383992195129395
Validation loss: 2.222349464252431

Epoch: 6| Step: 11
Training loss: 2.6646060943603516
Validation loss: 2.2057363192240396

Epoch: 6| Step: 12
Training loss: 2.7499256134033203
Validation loss: 2.192740260913808

Epoch: 6| Step: 13
Training loss: 1.71956467628479
Validation loss: 2.200250476919195

Epoch: 65| Step: 0
Training loss: 3.006408214569092
Validation loss: 2.1997208415821032

Epoch: 6| Step: 1
Training loss: 2.9356226921081543
Validation loss: 2.2115040261258363

Epoch: 6| Step: 2
Training loss: 2.103003978729248
Validation loss: 2.2057535186890633

Epoch: 6| Step: 3
Training loss: 2.1271371841430664
Validation loss: 2.195551186479548

Epoch: 6| Step: 4
Training loss: 2.5964393615722656
Validation loss: 2.1901132252908524

Epoch: 6| Step: 5
Training loss: 2.728379011154175
Validation loss: 2.200486144711894

Epoch: 6| Step: 6
Training loss: 2.4685473442077637
Validation loss: 2.2000257558720087

Epoch: 6| Step: 7
Training loss: 2.46506404876709
Validation loss: 2.2023925947886642

Epoch: 6| Step: 8
Training loss: 2.3316686153411865
Validation loss: 2.1980206915127334

Epoch: 6| Step: 9
Training loss: 1.9703723192214966
Validation loss: 2.1944457946285123

Epoch: 6| Step: 10
Training loss: 1.8666431903839111
Validation loss: 2.190340385642103

Epoch: 6| Step: 11
Training loss: 1.8580814599990845
Validation loss: 2.174034018670359

Epoch: 6| Step: 12
Training loss: 2.6839113235473633
Validation loss: 2.180163957739389

Epoch: 6| Step: 13
Training loss: 4.254732608795166
Validation loss: 2.1905200045595885

Epoch: 66| Step: 0
Training loss: 2.7968263626098633
Validation loss: 2.1873996898692143

Epoch: 6| Step: 1
Training loss: 1.7249817848205566
Validation loss: 2.196858180466519

Epoch: 6| Step: 2
Training loss: 2.487495183944702
Validation loss: 2.202585784337854

Epoch: 6| Step: 3
Training loss: 2.9857187271118164
Validation loss: 2.1888538611832487

Epoch: 6| Step: 4
Training loss: 2.560685634613037
Validation loss: 2.167529957268828

Epoch: 6| Step: 5
Training loss: 2.4005861282348633
Validation loss: 2.1577578821489887

Epoch: 6| Step: 6
Training loss: 2.0441763401031494
Validation loss: 2.1469050556100826

Epoch: 6| Step: 7
Training loss: 2.1502087116241455
Validation loss: 2.1444879706187914

Epoch: 6| Step: 8
Training loss: 2.103266716003418
Validation loss: 2.1462983956900974

Epoch: 6| Step: 9
Training loss: 2.7501187324523926
Validation loss: 2.1477641495325233

Epoch: 6| Step: 10
Training loss: 2.428428888320923
Validation loss: 2.1478529514804965

Epoch: 6| Step: 11
Training loss: 3.1409990787506104
Validation loss: 2.1458189846366964

Epoch: 6| Step: 12
Training loss: 2.457918167114258
Validation loss: 2.145784552379321

Epoch: 6| Step: 13
Training loss: 2.7382328510284424
Validation loss: 2.1376375639310448

Epoch: 67| Step: 0
Training loss: 2.231170654296875
Validation loss: 2.1436322991565993

Epoch: 6| Step: 1
Training loss: 2.5702385902404785
Validation loss: 2.1528763463420253

Epoch: 6| Step: 2
Training loss: 2.453195571899414
Validation loss: 2.173272914783929

Epoch: 6| Step: 3
Training loss: 3.0283191204071045
Validation loss: 2.237628065129762

Epoch: 6| Step: 4
Training loss: 2.4167890548706055
Validation loss: 2.244874431240943

Epoch: 6| Step: 5
Training loss: 2.5145535469055176
Validation loss: 2.278811408627418

Epoch: 6| Step: 6
Training loss: 2.701582431793213
Validation loss: 2.3030338210444294

Epoch: 6| Step: 7
Training loss: 2.1622536182403564
Validation loss: 2.267544518234909

Epoch: 6| Step: 8
Training loss: 2.5730979442596436
Validation loss: 2.2119896950260287

Epoch: 6| Step: 9
Training loss: 2.5681092739105225
Validation loss: 2.1614705208809144

Epoch: 6| Step: 10
Training loss: 3.1739144325256348
Validation loss: 2.1450509102113786

Epoch: 6| Step: 11
Training loss: 1.6824660301208496
Validation loss: 2.136957222415555

Epoch: 6| Step: 12
Training loss: 2.2712199687957764
Validation loss: 2.1383306518677743

Epoch: 6| Step: 13
Training loss: 2.766296148300171
Validation loss: 2.1394059376050065

Epoch: 68| Step: 0
Training loss: 1.5989835262298584
Validation loss: 2.143884369122085

Epoch: 6| Step: 1
Training loss: 3.036515712738037
Validation loss: 2.1403003392680997

Epoch: 6| Step: 2
Training loss: 2.226742744445801
Validation loss: 2.1419539861781622

Epoch: 6| Step: 3
Training loss: 2.0469021797180176
Validation loss: 2.138410847674134

Epoch: 6| Step: 4
Training loss: 2.471918821334839
Validation loss: 2.133172424890662

Epoch: 6| Step: 5
Training loss: 2.7332234382629395
Validation loss: 2.136037216391615

Epoch: 6| Step: 6
Training loss: 2.6341335773468018
Validation loss: 2.132565975189209

Epoch: 6| Step: 7
Training loss: 2.931413173675537
Validation loss: 2.133285891625189

Epoch: 6| Step: 8
Training loss: 2.635861873626709
Validation loss: 2.1252036453575216

Epoch: 6| Step: 9
Training loss: 2.308781385421753
Validation loss: 2.1258334972525157

Epoch: 6| Step: 10
Training loss: 2.155648708343506
Validation loss: 2.126498514606107

Epoch: 6| Step: 11
Training loss: 2.454655647277832
Validation loss: 2.139834355282527

Epoch: 6| Step: 12
Training loss: 2.4299302101135254
Validation loss: 2.1500503478511686

Epoch: 6| Step: 13
Training loss: 3.6455862522125244
Validation loss: 2.1786214638781805

Epoch: 69| Step: 0
Training loss: 2.131899356842041
Validation loss: 2.1876098609739736

Epoch: 6| Step: 1
Training loss: 2.3563766479492188
Validation loss: 2.2086668988709808

Epoch: 6| Step: 2
Training loss: 2.440692663192749
Validation loss: 2.230537924715268

Epoch: 6| Step: 3
Training loss: 2.988300323486328
Validation loss: 2.2237706492024083

Epoch: 6| Step: 4
Training loss: 1.6026967763900757
Validation loss: 2.2342726376748856

Epoch: 6| Step: 5
Training loss: 2.2493302822113037
Validation loss: 2.2169521034404798

Epoch: 6| Step: 6
Training loss: 2.6251041889190674
Validation loss: 2.172560671324371

Epoch: 6| Step: 7
Training loss: 2.42763614654541
Validation loss: 2.138353472114891

Epoch: 6| Step: 8
Training loss: 2.8626723289489746
Validation loss: 2.111502565363402

Epoch: 6| Step: 9
Training loss: 2.2704880237579346
Validation loss: 2.110328564079859

Epoch: 6| Step: 10
Training loss: 2.449737071990967
Validation loss: 2.1069701845927904

Epoch: 6| Step: 11
Training loss: 2.927077531814575
Validation loss: 2.113270451945643

Epoch: 6| Step: 12
Training loss: 3.1712114810943604
Validation loss: 2.1093740206892773

Epoch: 6| Step: 13
Training loss: 1.543896198272705
Validation loss: 2.1120131554142123

Epoch: 70| Step: 0
Training loss: 2.7950656414031982
Validation loss: 2.108729659870107

Epoch: 6| Step: 1
Training loss: 2.814268112182617
Validation loss: 2.110562286069316

Epoch: 6| Step: 2
Training loss: 2.016000747680664
Validation loss: 2.1111390565031316

Epoch: 6| Step: 3
Training loss: 1.9437265396118164
Validation loss: 2.122934094039343

Epoch: 6| Step: 4
Training loss: 2.4914302825927734
Validation loss: 2.1364754143581597

Epoch: 6| Step: 5
Training loss: 2.523940324783325
Validation loss: 2.1684072402215775

Epoch: 6| Step: 6
Training loss: 2.499032974243164
Validation loss: 2.213396064696773

Epoch: 6| Step: 7
Training loss: 2.7843551635742188
Validation loss: 2.247516833325868

Epoch: 6| Step: 8
Training loss: 2.4253835678100586
Validation loss: 2.272453567033173

Epoch: 6| Step: 9
Training loss: 2.651801586151123
Validation loss: 2.266558539482855

Epoch: 6| Step: 10
Training loss: 2.258739471435547
Validation loss: 2.22929742259364

Epoch: 6| Step: 11
Training loss: 2.3446028232574463
Validation loss: 2.2018014795036724

Epoch: 6| Step: 12
Training loss: 2.8031036853790283
Validation loss: 2.1604690115938903

Epoch: 6| Step: 13
Training loss: 1.8654378652572632
Validation loss: 2.111126721546214

Epoch: 71| Step: 0
Training loss: 2.308839797973633
Validation loss: 2.105495914336174

Epoch: 6| Step: 1
Training loss: 2.472378730773926
Validation loss: 2.0995684721136607

Epoch: 6| Step: 2
Training loss: 2.0639867782592773
Validation loss: 2.1012328991325955

Epoch: 6| Step: 3
Training loss: 2.4842052459716797
Validation loss: 2.104087639880437

Epoch: 6| Step: 4
Training loss: 2.4067282676696777
Validation loss: 2.114558063527589

Epoch: 6| Step: 5
Training loss: 2.700007915496826
Validation loss: 2.1210951574387087

Epoch: 6| Step: 6
Training loss: 3.1013026237487793
Validation loss: 2.120191381823632

Epoch: 6| Step: 7
Training loss: 2.4033052921295166
Validation loss: 2.116814274941721

Epoch: 6| Step: 8
Training loss: 2.9937424659729004
Validation loss: 2.1152998119272213

Epoch: 6| Step: 9
Training loss: 2.5507984161376953
Validation loss: 2.116129083018149

Epoch: 6| Step: 10
Training loss: 2.4679346084594727
Validation loss: 2.1232672968218402

Epoch: 6| Step: 11
Training loss: 2.671052932739258
Validation loss: 2.1242131110160583

Epoch: 6| Step: 12
Training loss: 2.131397008895874
Validation loss: 2.1275782469780213

Epoch: 6| Step: 13
Training loss: 1.5013889074325562
Validation loss: 2.125131030236521

Epoch: 72| Step: 0
Training loss: 2.771735906600952
Validation loss: 2.1191580090471493

Epoch: 6| Step: 1
Training loss: 2.8440074920654297
Validation loss: 2.1233027250536027

Epoch: 6| Step: 2
Training loss: 2.692147731781006
Validation loss: 2.1269879648762364

Epoch: 6| Step: 3
Training loss: 2.8903074264526367
Validation loss: 2.133547890570856

Epoch: 6| Step: 4
Training loss: 2.0730364322662354
Validation loss: 2.1309811248574206

Epoch: 6| Step: 5
Training loss: 1.355911135673523
Validation loss: 2.125986458152853

Epoch: 6| Step: 6
Training loss: 2.20331072807312
Validation loss: 2.1322652627063055

Epoch: 6| Step: 7
Training loss: 2.4120616912841797
Validation loss: 2.1391653066040366

Epoch: 6| Step: 8
Training loss: 2.501913547515869
Validation loss: 2.146435558155019

Epoch: 6| Step: 9
Training loss: 2.8777976036071777
Validation loss: 2.163729788154684

Epoch: 6| Step: 10
Training loss: 2.3716626167297363
Validation loss: 2.1849431209666754

Epoch: 6| Step: 11
Training loss: 2.1487677097320557
Validation loss: 2.2149427244740147

Epoch: 6| Step: 12
Training loss: 2.192943572998047
Validation loss: 2.2158053305841263

Epoch: 6| Step: 13
Training loss: 2.668485164642334
Validation loss: 2.2163381499628865

Epoch: 73| Step: 0
Training loss: 2.506767749786377
Validation loss: 2.211014169518666

Epoch: 6| Step: 1
Training loss: 2.6541409492492676
Validation loss: 2.183018422895862

Epoch: 6| Step: 2
Training loss: 1.6925374269485474
Validation loss: 2.166572811783001

Epoch: 6| Step: 3
Training loss: 2.06203556060791
Validation loss: 2.163188272906888

Epoch: 6| Step: 4
Training loss: 2.200859546661377
Validation loss: 2.167606025613764

Epoch: 6| Step: 5
Training loss: 2.573064088821411
Validation loss: 2.1685899073077786

Epoch: 6| Step: 6
Training loss: 2.517943859100342
Validation loss: 2.1723897354577177

Epoch: 6| Step: 7
Training loss: 2.9316580295562744
Validation loss: 2.174344979306703

Epoch: 6| Step: 8
Training loss: 2.593276262283325
Validation loss: 2.159475916175432

Epoch: 6| Step: 9
Training loss: 1.6377477645874023
Validation loss: 2.127015616304131

Epoch: 6| Step: 10
Training loss: 3.0766444206237793
Validation loss: 2.127435968768212

Epoch: 6| Step: 11
Training loss: 2.0009727478027344
Validation loss: 2.116636400581688

Epoch: 6| Step: 12
Training loss: 2.6623315811157227
Validation loss: 2.113561561030726

Epoch: 6| Step: 13
Training loss: 2.9669580459594727
Validation loss: 2.1051324157304663

Epoch: 74| Step: 0
Training loss: 2.425691604614258
Validation loss: 2.1198228405367945

Epoch: 6| Step: 1
Training loss: 2.5509543418884277
Validation loss: 2.130488257254324

Epoch: 6| Step: 2
Training loss: 2.416010856628418
Validation loss: 2.1429028126501266

Epoch: 6| Step: 3
Training loss: 2.179861068725586
Validation loss: 2.160460736161919

Epoch: 6| Step: 4
Training loss: 2.1022136211395264
Validation loss: 2.187444725344258

Epoch: 6| Step: 5
Training loss: 3.133918285369873
Validation loss: 2.2122026720354633

Epoch: 6| Step: 6
Training loss: 1.6832833290100098
Validation loss: 2.212612098263156

Epoch: 6| Step: 7
Training loss: 2.919743061065674
Validation loss: 2.1653159331249934

Epoch: 6| Step: 8
Training loss: 2.370281219482422
Validation loss: 2.1577322508699153

Epoch: 6| Step: 9
Training loss: 2.901899814605713
Validation loss: 2.1203671501528834

Epoch: 6| Step: 10
Training loss: 2.4142837524414062
Validation loss: 2.099864964844078

Epoch: 6| Step: 11
Training loss: 2.7781405448913574
Validation loss: 2.1012044158033145

Epoch: 6| Step: 12
Training loss: 1.6626648902893066
Validation loss: 2.106341738854685

Epoch: 6| Step: 13
Training loss: 2.1849491596221924
Validation loss: 2.1152950461192797

Epoch: 75| Step: 0
Training loss: 2.346242904663086
Validation loss: 2.1091858686939364

Epoch: 6| Step: 1
Training loss: 1.9382838010787964
Validation loss: 2.1033658109685427

Epoch: 6| Step: 2
Training loss: 2.7375152111053467
Validation loss: 2.100973577909572

Epoch: 6| Step: 3
Training loss: 3.2373523712158203
Validation loss: 2.094624227093112

Epoch: 6| Step: 4
Training loss: 2.6226553916931152
Validation loss: 2.095375775009073

Epoch: 6| Step: 5
Training loss: 2.3525173664093018
Validation loss: 2.09232065498188

Epoch: 6| Step: 6
Training loss: 1.9189976453781128
Validation loss: 2.0975503511326288

Epoch: 6| Step: 7
Training loss: 3.119201183319092
Validation loss: 2.1140431152876986

Epoch: 6| Step: 8
Training loss: 2.145303249359131
Validation loss: 2.136271019135752

Epoch: 6| Step: 9
Training loss: 2.2415428161621094
Validation loss: 2.166346760206325

Epoch: 6| Step: 10
Training loss: 2.43654727935791
Validation loss: 2.182701156985375

Epoch: 6| Step: 11
Training loss: 2.2201499938964844
Validation loss: 2.1853446204175233

Epoch: 6| Step: 12
Training loss: 2.3656814098358154
Validation loss: 2.195518711561798

Epoch: 6| Step: 13
Training loss: 2.3649463653564453
Validation loss: 2.1638435907261346

Epoch: 76| Step: 0
Training loss: 2.5231001377105713
Validation loss: 2.1542014998774373

Epoch: 6| Step: 1
Training loss: 2.5786070823669434
Validation loss: 2.1327438790311097

Epoch: 6| Step: 2
Training loss: 2.2649240493774414
Validation loss: 2.1180006406640493

Epoch: 6| Step: 3
Training loss: 2.8845605850219727
Validation loss: 2.1073011980261853

Epoch: 6| Step: 4
Training loss: 2.417973756790161
Validation loss: 2.0968509463853735

Epoch: 6| Step: 5
Training loss: 3.0825729370117188
Validation loss: 2.093778342329046

Epoch: 6| Step: 6
Training loss: 1.5404483079910278
Validation loss: 2.100182928064818

Epoch: 6| Step: 7
Training loss: 2.0777509212493896
Validation loss: 2.0972254891549387

Epoch: 6| Step: 8
Training loss: 2.086339235305786
Validation loss: 2.113195296256773

Epoch: 6| Step: 9
Training loss: 1.8287369012832642
Validation loss: 2.1096729745147047

Epoch: 6| Step: 10
Training loss: 2.4660658836364746
Validation loss: 2.10889442377193

Epoch: 6| Step: 11
Training loss: 2.726740837097168
Validation loss: 2.109207845503284

Epoch: 6| Step: 12
Training loss: 2.6177186965942383
Validation loss: 2.1130824909415296

Epoch: 6| Step: 13
Training loss: 2.549546003341675
Validation loss: 2.0987008848497943

Epoch: 77| Step: 0
Training loss: 2.9406394958496094
Validation loss: 2.094598308686287

Epoch: 6| Step: 1
Training loss: 1.845412254333496
Validation loss: 2.0878172356595277

Epoch: 6| Step: 2
Training loss: 2.7904396057128906
Validation loss: 2.08639504191696

Epoch: 6| Step: 3
Training loss: 2.3399696350097656
Validation loss: 2.094985218458278

Epoch: 6| Step: 4
Training loss: 2.564039945602417
Validation loss: 2.110915691621842

Epoch: 6| Step: 5
Training loss: 2.756335973739624
Validation loss: 2.1264579680658158

Epoch: 6| Step: 6
Training loss: 2.2093214988708496
Validation loss: 2.1261837097906295

Epoch: 6| Step: 7
Training loss: 2.064338207244873
Validation loss: 2.134639383644186

Epoch: 6| Step: 8
Training loss: 2.8332626819610596
Validation loss: 2.1184148378269647

Epoch: 6| Step: 9
Training loss: 2.0794718265533447
Validation loss: 2.1152991351260932

Epoch: 6| Step: 10
Training loss: 2.174287796020508
Validation loss: 2.104254359840065

Epoch: 6| Step: 11
Training loss: 2.1497621536254883
Validation loss: 2.099571645900767

Epoch: 6| Step: 12
Training loss: 2.4533164501190186
Validation loss: 2.0889951490586802

Epoch: 6| Step: 13
Training loss: 2.0065717697143555
Validation loss: 2.078131555229105

Epoch: 78| Step: 0
Training loss: 2.3977646827697754
Validation loss: 2.075967360568303

Epoch: 6| Step: 1
Training loss: 1.9021921157836914
Validation loss: 2.0755561487649077

Epoch: 6| Step: 2
Training loss: 2.6970901489257812
Validation loss: 2.081808352983126

Epoch: 6| Step: 3
Training loss: 2.170414924621582
Validation loss: 2.0773908579221336

Epoch: 6| Step: 4
Training loss: 2.479949474334717
Validation loss: 2.0824843440004575

Epoch: 6| Step: 5
Training loss: 2.6960792541503906
Validation loss: 2.0857296835991646

Epoch: 6| Step: 6
Training loss: 2.537479877471924
Validation loss: 2.092674127189062

Epoch: 6| Step: 7
Training loss: 2.9038023948669434
Validation loss: 2.083741718722928

Epoch: 6| Step: 8
Training loss: 2.5746235847473145
Validation loss: 2.078016027327507

Epoch: 6| Step: 9
Training loss: 2.294069528579712
Validation loss: 2.0757303955734416

Epoch: 6| Step: 10
Training loss: 2.316049098968506
Validation loss: 2.07776689657601

Epoch: 6| Step: 11
Training loss: 1.75673246383667
Validation loss: 2.0721941724900277

Epoch: 6| Step: 12
Training loss: 2.3409764766693115
Validation loss: 2.0708813667297363

Epoch: 6| Step: 13
Training loss: 2.0659289360046387
Validation loss: 2.0613332986831665

Epoch: 79| Step: 0
Training loss: 2.4970624446868896
Validation loss: 2.0687386220501316

Epoch: 6| Step: 1
Training loss: 1.7970856428146362
Validation loss: 2.0684327156313005

Epoch: 6| Step: 2
Training loss: 1.8223896026611328
Validation loss: 2.0636205519399335

Epoch: 6| Step: 3
Training loss: 2.768442153930664
Validation loss: 2.0645919692131782

Epoch: 6| Step: 4
Training loss: 3.022413492202759
Validation loss: 2.073297287828179

Epoch: 6| Step: 5
Training loss: 1.6517812013626099
Validation loss: 2.0807606917555614

Epoch: 6| Step: 6
Training loss: 2.2567543983459473
Validation loss: 2.0991963237844486

Epoch: 6| Step: 7
Training loss: 3.0267319679260254
Validation loss: 2.1257188858524447

Epoch: 6| Step: 8
Training loss: 3.0725574493408203
Validation loss: 2.1231963660127375

Epoch: 6| Step: 9
Training loss: 2.4462485313415527
Validation loss: 2.145640796230685

Epoch: 6| Step: 10
Training loss: 2.0067033767700195
Validation loss: 2.1544136026854157

Epoch: 6| Step: 11
Training loss: 2.9392640590667725
Validation loss: 2.1268335491098385

Epoch: 6| Step: 12
Training loss: 2.0152461528778076
Validation loss: 2.1266507871689333

Epoch: 6| Step: 13
Training loss: 1.90883469581604
Validation loss: 2.0857888511432114

Epoch: 80| Step: 0
Training loss: 2.578179359436035
Validation loss: 2.061689717795259

Epoch: 6| Step: 1
Training loss: 2.3758342266082764
Validation loss: 2.0434941194390737

Epoch: 6| Step: 2
Training loss: 1.7413591146469116
Validation loss: 2.0539370672677153

Epoch: 6| Step: 3
Training loss: 2.8739356994628906
Validation loss: 2.050619027947867

Epoch: 6| Step: 4
Training loss: 2.2563438415527344
Validation loss: 2.0467921303164576

Epoch: 6| Step: 5
Training loss: 2.7157392501831055
Validation loss: 2.04643766854399

Epoch: 6| Step: 6
Training loss: 2.3376078605651855
Validation loss: 2.04478552392734

Epoch: 6| Step: 7
Training loss: 2.617955207824707
Validation loss: 2.0363797013477614

Epoch: 6| Step: 8
Training loss: 2.668675661087036
Validation loss: 2.0438280618318947

Epoch: 6| Step: 9
Training loss: 2.2690765857696533
Validation loss: 2.049181569007135

Epoch: 6| Step: 10
Training loss: 2.2209315299987793
Validation loss: 2.058025215261726

Epoch: 6| Step: 11
Training loss: 1.7891271114349365
Validation loss: 2.077784461359824

Epoch: 6| Step: 12
Training loss: 1.9358792304992676
Validation loss: 2.0916847234131186

Epoch: 6| Step: 13
Training loss: 3.0011110305786133
Validation loss: 2.0901495128549556

Epoch: 81| Step: 0
Training loss: 2.0310158729553223
Validation loss: 2.07633585955507

Epoch: 6| Step: 1
Training loss: 2.723780870437622
Validation loss: 2.0690795349818405

Epoch: 6| Step: 2
Training loss: 2.4809975624084473
Validation loss: 2.0550186326426845

Epoch: 6| Step: 3
Training loss: 2.3820087909698486
Validation loss: 2.0376931005908596

Epoch: 6| Step: 4
Training loss: 1.9801908731460571
Validation loss: 2.036560845631425

Epoch: 6| Step: 5
Training loss: 2.638261079788208
Validation loss: 2.0332058655318392

Epoch: 6| Step: 6
Training loss: 2.614762783050537
Validation loss: 2.0399118014561233

Epoch: 6| Step: 7
Training loss: 2.019583225250244
Validation loss: 2.0402253725195445

Epoch: 6| Step: 8
Training loss: 1.960951566696167
Validation loss: 2.046341924257176

Epoch: 6| Step: 9
Training loss: 2.613819122314453
Validation loss: 2.0377957256891395

Epoch: 6| Step: 10
Training loss: 2.4413042068481445
Validation loss: 2.033838645104439

Epoch: 6| Step: 11
Training loss: 2.11810040473938
Validation loss: 2.034597599378196

Epoch: 6| Step: 12
Training loss: 2.2611775398254395
Validation loss: 2.042695733808702

Epoch: 6| Step: 13
Training loss: 2.610154151916504
Validation loss: 2.0416173140207925

Epoch: 82| Step: 0
Training loss: 1.500732421875
Validation loss: 2.049097629003627

Epoch: 6| Step: 1
Training loss: 2.614013433456421
Validation loss: 2.0678314291020876

Epoch: 6| Step: 2
Training loss: 2.695993423461914
Validation loss: 2.0820253831084057

Epoch: 6| Step: 3
Training loss: 2.7296853065490723
Validation loss: 2.0941277421930784

Epoch: 6| Step: 4
Training loss: 2.023453950881958
Validation loss: 2.089930938136193

Epoch: 6| Step: 5
Training loss: 3.2864139080047607
Validation loss: 2.097737363589707

Epoch: 6| Step: 6
Training loss: 2.6690025329589844
Validation loss: 2.0924900680459957

Epoch: 6| Step: 7
Training loss: 2.5708515644073486
Validation loss: 2.0723617153783

Epoch: 6| Step: 8
Training loss: 2.030956268310547
Validation loss: 2.0528056711278935

Epoch: 6| Step: 9
Training loss: 2.5111823081970215
Validation loss: 2.047323835793362

Epoch: 6| Step: 10
Training loss: 1.4866580963134766
Validation loss: 2.0358836343211513

Epoch: 6| Step: 11
Training loss: 2.430553436279297
Validation loss: 2.040376600398812

Epoch: 6| Step: 12
Training loss: 2.2818796634674072
Validation loss: 2.025555169710549

Epoch: 6| Step: 13
Training loss: 1.83650541305542
Validation loss: 2.0312832299099175

Epoch: 83| Step: 0
Training loss: 2.355494499206543
Validation loss: 2.0335665518237698

Epoch: 6| Step: 1
Training loss: 2.0336828231811523
Validation loss: 2.032847750571466

Epoch: 6| Step: 2
Training loss: 2.52423095703125
Validation loss: 2.038715280512328

Epoch: 6| Step: 3
Training loss: 2.479267120361328
Validation loss: 2.03961165489689

Epoch: 6| Step: 4
Training loss: 2.340240001678467
Validation loss: 2.0339591323688464

Epoch: 6| Step: 5
Training loss: 2.191056251525879
Validation loss: 2.0296075472267727

Epoch: 6| Step: 6
Training loss: 2.7976794242858887
Validation loss: 2.033558209737142

Epoch: 6| Step: 7
Training loss: 2.5582633018493652
Validation loss: 2.0309267569613714

Epoch: 6| Step: 8
Training loss: 1.6973854303359985
Validation loss: 2.0341009709142868

Epoch: 6| Step: 9
Training loss: 2.1260249614715576
Validation loss: 2.030578528681109

Epoch: 6| Step: 10
Training loss: 1.8273332118988037
Validation loss: 2.0324709389799382

Epoch: 6| Step: 11
Training loss: 2.552544116973877
Validation loss: 2.0378110742056244

Epoch: 6| Step: 12
Training loss: 2.39572811126709
Validation loss: 2.047865136977165

Epoch: 6| Step: 13
Training loss: 3.0056395530700684
Validation loss: 2.057677330509309

Epoch: 84| Step: 0
Training loss: 1.9840880632400513
Validation loss: 2.0441156228383384

Epoch: 6| Step: 1
Training loss: 2.086638927459717
Validation loss: 2.050294973516977

Epoch: 6| Step: 2
Training loss: 2.505432605743408
Validation loss: 2.0575406961543585

Epoch: 6| Step: 3
Training loss: 1.7249810695648193
Validation loss: 2.053125277642281

Epoch: 6| Step: 4
Training loss: 3.302511692047119
Validation loss: 2.057686867252473

Epoch: 6| Step: 5
Training loss: 2.2077038288116455
Validation loss: 2.055228292301137

Epoch: 6| Step: 6
Training loss: 2.076063632965088
Validation loss: 2.056364300430462

Epoch: 6| Step: 7
Training loss: 2.4571444988250732
Validation loss: 2.0523537307657223

Epoch: 6| Step: 8
Training loss: 2.4731287956237793
Validation loss: 2.05309102483975

Epoch: 6| Step: 9
Training loss: 2.6314587593078613
Validation loss: 2.0484347253717403

Epoch: 6| Step: 10
Training loss: 2.351776599884033
Validation loss: 2.0469008799522155

Epoch: 6| Step: 11
Training loss: 2.272630214691162
Validation loss: 2.036149896601195

Epoch: 6| Step: 12
Training loss: 2.235445022583008
Validation loss: 2.028366320876665

Epoch: 6| Step: 13
Training loss: 2.1688244342803955
Validation loss: 2.0327420311589397

Epoch: 85| Step: 0
Training loss: 2.2268786430358887
Validation loss: 2.0320162568041074

Epoch: 6| Step: 1
Training loss: 2.7807517051696777
Validation loss: 2.0554913884849957

Epoch: 6| Step: 2
Training loss: 2.4230518341064453
Validation loss: 2.0688331524531045

Epoch: 6| Step: 3
Training loss: 1.6997488737106323
Validation loss: 2.0469494019785235

Epoch: 6| Step: 4
Training loss: 2.5783538818359375
Validation loss: 2.02886934562396

Epoch: 6| Step: 5
Training loss: 2.652268409729004
Validation loss: 2.0294588970881637

Epoch: 6| Step: 6
Training loss: 2.2680749893188477
Validation loss: 2.026111443837484

Epoch: 6| Step: 7
Training loss: 1.2441751956939697
Validation loss: 2.0176973137804257

Epoch: 6| Step: 8
Training loss: 2.677321434020996
Validation loss: 2.0160051494516353

Epoch: 6| Step: 9
Training loss: 2.3381710052490234
Validation loss: 2.0194883141466367

Epoch: 6| Step: 10
Training loss: 2.5383358001708984
Validation loss: 2.0163131836921937

Epoch: 6| Step: 11
Training loss: 2.1800739765167236
Validation loss: 2.0068650271302912

Epoch: 6| Step: 12
Training loss: 2.694201946258545
Validation loss: 2.005844998103316

Epoch: 6| Step: 13
Training loss: 1.7760998010635376
Validation loss: 2.0065350224894862

Epoch: 86| Step: 0
Training loss: 2.3852028846740723
Validation loss: 2.020207384581207

Epoch: 6| Step: 1
Training loss: 2.116607189178467
Validation loss: 2.013449979084794

Epoch: 6| Step: 2
Training loss: 2.3437085151672363
Validation loss: 2.0180873934940626

Epoch: 6| Step: 3
Training loss: 2.1528496742248535
Validation loss: 2.0258249775055917

Epoch: 6| Step: 4
Training loss: 2.3000614643096924
Validation loss: 2.0411321834851335

Epoch: 6| Step: 5
Training loss: 1.9107518196105957
Validation loss: 2.0447977281385854

Epoch: 6| Step: 6
Training loss: 2.179023265838623
Validation loss: 2.034648902954594

Epoch: 6| Step: 7
Training loss: 2.502688407897949
Validation loss: 2.046937334922052

Epoch: 6| Step: 8
Training loss: 2.643540382385254
Validation loss: 2.025504889026765

Epoch: 6| Step: 9
Training loss: 2.1265811920166016
Validation loss: 2.0103078837035806

Epoch: 6| Step: 10
Training loss: 2.199502944946289
Validation loss: 2.001618008459768

Epoch: 6| Step: 11
Training loss: 2.629915237426758
Validation loss: 1.999390608520918

Epoch: 6| Step: 12
Training loss: 1.9852991104125977
Validation loss: 2.000407871379647

Epoch: 6| Step: 13
Training loss: 3.201881170272827
Validation loss: 2.011758563339069

Epoch: 87| Step: 0
Training loss: 2.0024657249450684
Validation loss: 2.0118527835415256

Epoch: 6| Step: 1
Training loss: 1.7545926570892334
Validation loss: 2.0117284149251957

Epoch: 6| Step: 2
Training loss: 2.4783811569213867
Validation loss: 2.0246460745411534

Epoch: 6| Step: 3
Training loss: 2.501732587814331
Validation loss: 2.0404516804602837

Epoch: 6| Step: 4
Training loss: 2.391876697540283
Validation loss: 2.0393739387553227

Epoch: 6| Step: 5
Training loss: 2.523430824279785
Validation loss: 2.022573346732765

Epoch: 6| Step: 6
Training loss: 2.8792076110839844
Validation loss: 2.0180136131983932

Epoch: 6| Step: 7
Training loss: 2.2208099365234375
Validation loss: 2.0065235373794392

Epoch: 6| Step: 8
Training loss: 2.1204380989074707
Validation loss: 2.010229137636

Epoch: 6| Step: 9
Training loss: 1.9162265062332153
Validation loss: 1.9993178844451904

Epoch: 6| Step: 10
Training loss: 2.619913101196289
Validation loss: 2.010761708341619

Epoch: 6| Step: 11
Training loss: 2.0217010974884033
Validation loss: 2.014979693197435

Epoch: 6| Step: 12
Training loss: 2.4545984268188477
Validation loss: 2.0313732547144734

Epoch: 6| Step: 13
Training loss: 2.5060606002807617
Validation loss: 2.0666394605431506

Epoch: 88| Step: 0
Training loss: 2.2919187545776367
Validation loss: 2.0596872119493383

Epoch: 6| Step: 1
Training loss: 2.380182981491089
Validation loss: 2.031433041377734

Epoch: 6| Step: 2
Training loss: 2.60607647895813
Validation loss: 2.013183637331891

Epoch: 6| Step: 3
Training loss: 2.001424789428711
Validation loss: 2.0156105103031283

Epoch: 6| Step: 4
Training loss: 2.3332409858703613
Validation loss: 2.014250504073276

Epoch: 6| Step: 5
Training loss: 2.224747657775879
Validation loss: 2.010630146149666

Epoch: 6| Step: 6
Training loss: 2.7413227558135986
Validation loss: 2.005422975427361

Epoch: 6| Step: 7
Training loss: 2.6185097694396973
Validation loss: 2.0074758157935193

Epoch: 6| Step: 8
Training loss: 2.2542757987976074
Validation loss: 2.0223385544233423

Epoch: 6| Step: 9
Training loss: 1.6630734205245972
Validation loss: 2.0331873381009666

Epoch: 6| Step: 10
Training loss: 2.8447647094726562
Validation loss: 2.024925119133406

Epoch: 6| Step: 11
Training loss: 1.4769222736358643
Validation loss: 2.0040632217161116

Epoch: 6| Step: 12
Training loss: 2.5166635513305664
Validation loss: 2.005821911237573

Epoch: 6| Step: 13
Training loss: 2.2042236328125
Validation loss: 1.9985374994175409

Epoch: 89| Step: 0
Training loss: 1.6955922842025757
Validation loss: 1.99961261082721

Epoch: 6| Step: 1
Training loss: 2.518906593322754
Validation loss: 2.0016858539273663

Epoch: 6| Step: 2
Training loss: 2.2811801433563232
Validation loss: 1.9910319723108763

Epoch: 6| Step: 3
Training loss: 1.9844186305999756
Validation loss: 2.0030343929926553

Epoch: 6| Step: 4
Training loss: 2.1950881481170654
Validation loss: 2.036118245893909

Epoch: 6| Step: 5
Training loss: 2.4636118412017822
Validation loss: 2.064331445642697

Epoch: 6| Step: 6
Training loss: 2.7061777114868164
Validation loss: 2.0810857716427056

Epoch: 6| Step: 7
Training loss: 2.431689739227295
Validation loss: 2.0888708842697965

Epoch: 6| Step: 8
Training loss: 2.1721770763397217
Validation loss: 2.059874447443152

Epoch: 6| Step: 9
Training loss: 2.780132293701172
Validation loss: 2.0444620193973666

Epoch: 6| Step: 10
Training loss: 2.7152395248413086
Validation loss: 2.0277331913671186

Epoch: 6| Step: 11
Training loss: 1.833905816078186
Validation loss: 2.0166338002809914

Epoch: 6| Step: 12
Training loss: 2.0955848693847656
Validation loss: 2.0079281458290676

Epoch: 6| Step: 13
Training loss: 2.541633129119873
Validation loss: 2.002023850717852

Epoch: 90| Step: 0
Training loss: 2.254730224609375
Validation loss: 2.001417782998854

Epoch: 6| Step: 1
Training loss: 2.773099899291992
Validation loss: 2.00827802893936

Epoch: 6| Step: 2
Training loss: 2.305138111114502
Validation loss: 2.0107988029397945

Epoch: 6| Step: 3
Training loss: 2.060634136199951
Validation loss: 2.000423167341499

Epoch: 6| Step: 4
Training loss: 2.2988667488098145
Validation loss: 2.0108460226366596

Epoch: 6| Step: 5
Training loss: 1.8922324180603027
Validation loss: 2.006648091859715

Epoch: 6| Step: 6
Training loss: 1.849467396736145
Validation loss: 2.0233941514004945

Epoch: 6| Step: 7
Training loss: 2.3294451236724854
Validation loss: 2.070968102383357

Epoch: 6| Step: 8
Training loss: 2.937241554260254
Validation loss: 2.1352120471257034

Epoch: 6| Step: 9
Training loss: 2.854219436645508
Validation loss: 2.149335515114569

Epoch: 6| Step: 10
Training loss: 2.628929615020752
Validation loss: 2.144609805076353

Epoch: 6| Step: 11
Training loss: 1.7928380966186523
Validation loss: 2.100694957599845

Epoch: 6| Step: 12
Training loss: 2.0331778526306152
Validation loss: 2.033734139575753

Epoch: 6| Step: 13
Training loss: 2.8191020488739014
Validation loss: 1.9968212214849328

Epoch: 91| Step: 0
Training loss: 1.5587600469589233
Validation loss: 1.9962606814599806

Epoch: 6| Step: 1
Training loss: 1.7506797313690186
Validation loss: 1.9917630303290583

Epoch: 6| Step: 2
Training loss: 1.826583981513977
Validation loss: 2.0191374081437305

Epoch: 6| Step: 3
Training loss: 2.6465845108032227
Validation loss: 2.0441432204297794

Epoch: 6| Step: 4
Training loss: 2.7287309169769287
Validation loss: 2.0907509237207393

Epoch: 6| Step: 5
Training loss: 2.1803548336029053
Validation loss: 2.1294272279226654

Epoch: 6| Step: 6
Training loss: 3.263063669204712
Validation loss: 2.1711505459200953

Epoch: 6| Step: 7
Training loss: 2.599480628967285
Validation loss: 2.1177205783064648

Epoch: 6| Step: 8
Training loss: 1.9620651006698608
Validation loss: 2.052374783382621

Epoch: 6| Step: 9
Training loss: 1.9866536855697632
Validation loss: 2.0300885669646727

Epoch: 6| Step: 10
Training loss: 2.192051887512207
Validation loss: 2.036376960815922

Epoch: 6| Step: 11
Training loss: 2.513286828994751
Validation loss: 2.026187394254951

Epoch: 6| Step: 12
Training loss: 2.919492721557617
Validation loss: 2.03698294906206

Epoch: 6| Step: 13
Training loss: 2.800821542739868
Validation loss: 2.037612081855856

Epoch: 92| Step: 0
Training loss: 3.2450315952301025
Validation loss: 2.0246059125469578

Epoch: 6| Step: 1
Training loss: 2.401447057723999
Validation loss: 2.025464866750984

Epoch: 6| Step: 2
Training loss: 2.4213013648986816
Validation loss: 2.023241061036305

Epoch: 6| Step: 3
Training loss: 2.9637651443481445
Validation loss: 2.0230351673659457

Epoch: 6| Step: 4
Training loss: 2.1978507041931152
Validation loss: 2.022241935935072

Epoch: 6| Step: 5
Training loss: 2.5535359382629395
Validation loss: 2.032770046623804

Epoch: 6| Step: 6
Training loss: 2.997605562210083
Validation loss: 2.019232225674455

Epoch: 6| Step: 7
Training loss: 1.7815340757369995
Validation loss: 2.0214332457511657

Epoch: 6| Step: 8
Training loss: 1.9085032939910889
Validation loss: 2.014552124084965

Epoch: 6| Step: 9
Training loss: 1.4884803295135498
Validation loss: 2.025117822872695

Epoch: 6| Step: 10
Training loss: 2.235978126525879
Validation loss: 2.0348790819926927

Epoch: 6| Step: 11
Training loss: 2.035085439682007
Validation loss: 2.0727959986655944

Epoch: 6| Step: 12
Training loss: 1.6295421123504639
Validation loss: 2.0898634977238153

Epoch: 6| Step: 13
Training loss: 2.8205671310424805
Validation loss: 2.0691174768632457

Epoch: 93| Step: 0
Training loss: 2.365741729736328
Validation loss: 2.0492736395969184

Epoch: 6| Step: 1
Training loss: 2.349424362182617
Validation loss: 2.0230933466265277

Epoch: 6| Step: 2
Training loss: 1.2579880952835083
Validation loss: 2.0300120051189134

Epoch: 6| Step: 3
Training loss: 2.534877300262451
Validation loss: 2.036598938767628

Epoch: 6| Step: 4
Training loss: 1.8131663799285889
Validation loss: 2.041783622516099

Epoch: 6| Step: 5
Training loss: 2.100130558013916
Validation loss: 2.037495643861832

Epoch: 6| Step: 6
Training loss: 1.8323272466659546
Validation loss: 2.041176090958298

Epoch: 6| Step: 7
Training loss: 2.976794958114624
Validation loss: 2.0353368687373337

Epoch: 6| Step: 8
Training loss: 2.400547504425049
Validation loss: 2.033297364429761

Epoch: 6| Step: 9
Training loss: 2.4707627296447754
Validation loss: 2.035143936834028

Epoch: 6| Step: 10
Training loss: 2.252896785736084
Validation loss: 2.021962600369607

Epoch: 6| Step: 11
Training loss: 2.3875179290771484
Validation loss: 2.02868547490848

Epoch: 6| Step: 12
Training loss: 2.426893711090088
Validation loss: 2.0138475228381414

Epoch: 6| Step: 13
Training loss: 3.2283334732055664
Validation loss: 2.0069166050162366

Epoch: 94| Step: 0
Training loss: 1.403545618057251
Validation loss: 2.0010145889815463

Epoch: 6| Step: 1
Training loss: 3.1231861114501953
Validation loss: 2.0034026689426874

Epoch: 6| Step: 2
Training loss: 2.523158550262451
Validation loss: 2.0043435801741896

Epoch: 6| Step: 3
Training loss: 2.117424488067627
Validation loss: 1.9986791200535272

Epoch: 6| Step: 4
Training loss: 2.714573383331299
Validation loss: 1.9947951314269856

Epoch: 6| Step: 5
Training loss: 2.901634693145752
Validation loss: 1.9920471406752063

Epoch: 6| Step: 6
Training loss: 2.4648513793945312
Validation loss: 1.9946394902403637

Epoch: 6| Step: 7
Training loss: 2.3818862438201904
Validation loss: 1.9981134809473509

Epoch: 6| Step: 8
Training loss: 1.4165804386138916
Validation loss: 1.9937469728531376

Epoch: 6| Step: 9
Training loss: 2.165369987487793
Validation loss: 2.0018133912035214

Epoch: 6| Step: 10
Training loss: 2.126844644546509
Validation loss: 2.000175573492563

Epoch: 6| Step: 11
Training loss: 2.3288581371307373
Validation loss: 2.0036324095982376

Epoch: 6| Step: 12
Training loss: 1.7115577459335327
Validation loss: 1.9927803188241937

Epoch: 6| Step: 13
Training loss: 2.187345266342163
Validation loss: 2.000595531155986

Epoch: 95| Step: 0
Training loss: 2.0501222610473633
Validation loss: 2.0097922278988745

Epoch: 6| Step: 1
Training loss: 2.417463779449463
Validation loss: 2.0021179388928156

Epoch: 6| Step: 2
Training loss: 2.4150733947753906
Validation loss: 2.0091985066731772

Epoch: 6| Step: 3
Training loss: 2.3465607166290283
Validation loss: 2.007921472672493

Epoch: 6| Step: 4
Training loss: 2.387612819671631
Validation loss: 2.0133114143084456

Epoch: 6| Step: 5
Training loss: 2.342057943344116
Validation loss: 2.0189869737112396

Epoch: 6| Step: 6
Training loss: 1.906963586807251
Validation loss: 2.0119943593138006

Epoch: 6| Step: 7
Training loss: 2.2892446517944336
Validation loss: 2.01332809335442

Epoch: 6| Step: 8
Training loss: 2.6889467239379883
Validation loss: 2.023871560250559

Epoch: 6| Step: 9
Training loss: 2.3363425731658936
Validation loss: 2.0299917690215574

Epoch: 6| Step: 10
Training loss: 2.4527716636657715
Validation loss: 2.017133310276975

Epoch: 6| Step: 11
Training loss: 2.151254653930664
Validation loss: 1.994704540057849

Epoch: 6| Step: 12
Training loss: 1.3962270021438599
Validation loss: 1.9866252035223029

Epoch: 6| Step: 13
Training loss: 2.823577880859375
Validation loss: 1.9817675044459682

Epoch: 96| Step: 0
Training loss: 2.8261871337890625
Validation loss: 1.9852311995721632

Epoch: 6| Step: 1
Training loss: 1.9527699947357178
Validation loss: 2.0045830818914596

Epoch: 6| Step: 2
Training loss: 2.6803207397460938
Validation loss: 2.0263251386662966

Epoch: 6| Step: 3
Training loss: 2.5535836219787598
Validation loss: 2.0196189470188592

Epoch: 6| Step: 4
Training loss: 2.633289337158203
Validation loss: 2.014006722357965

Epoch: 6| Step: 5
Training loss: 2.2355685234069824
Validation loss: 2.016398911835045

Epoch: 6| Step: 6
Training loss: 2.163898229598999
Validation loss: 2.01218403667532

Epoch: 6| Step: 7
Training loss: 2.308302164077759
Validation loss: 2.0054358461851716

Epoch: 6| Step: 8
Training loss: 2.280428171157837
Validation loss: 2.0025213251831713

Epoch: 6| Step: 9
Training loss: 1.5920549631118774
Validation loss: 1.9894615488667642

Epoch: 6| Step: 10
Training loss: 2.3778634071350098
Validation loss: 1.9879255064072148

Epoch: 6| Step: 11
Training loss: 2.3200507164001465
Validation loss: 1.9923530983668503

Epoch: 6| Step: 12
Training loss: 2.3988585472106934
Validation loss: 2.003896665829484

Epoch: 6| Step: 13
Training loss: 2.5179848670959473
Validation loss: 2.0399203659385763

Epoch: 97| Step: 0
Training loss: 2.1298012733459473
Validation loss: 2.0578764125864994

Epoch: 6| Step: 1
Training loss: 2.4702610969543457
Validation loss: 2.064013914395404

Epoch: 6| Step: 2
Training loss: 2.115967273712158
Validation loss: 2.074148110164109

Epoch: 6| Step: 3
Training loss: 2.5289461612701416
Validation loss: 2.0778992406783567

Epoch: 6| Step: 4
Training loss: 2.0107295513153076
Validation loss: 2.0539216533783944

Epoch: 6| Step: 5
Training loss: 2.6611344814300537
Validation loss: 2.0259795111994587

Epoch: 6| Step: 6
Training loss: 2.7421998977661133
Validation loss: 2.013176066901094

Epoch: 6| Step: 7
Training loss: 2.3477983474731445
Validation loss: 2.0035477094752814

Epoch: 6| Step: 8
Training loss: 1.9962457418441772
Validation loss: 2.008889736667756

Epoch: 6| Step: 9
Training loss: 2.359638214111328
Validation loss: 2.020634410201862

Epoch: 6| Step: 10
Training loss: 2.361710548400879
Validation loss: 2.034422512977354

Epoch: 6| Step: 11
Training loss: 1.865639328956604
Validation loss: 2.045572634666197

Epoch: 6| Step: 12
Training loss: 2.07018780708313
Validation loss: 2.03393562762968

Epoch: 6| Step: 13
Training loss: 2.4990382194519043
Validation loss: 2.0281196678838422

Epoch: 98| Step: 0
Training loss: 1.654811143875122
Validation loss: 2.027229059127069

Epoch: 6| Step: 1
Training loss: 2.5578317642211914
Validation loss: 2.026107616322015

Epoch: 6| Step: 2
Training loss: 1.7818951606750488
Validation loss: 2.009066184361776

Epoch: 6| Step: 3
Training loss: 2.4093856811523438
Validation loss: 1.9926785448546052

Epoch: 6| Step: 4
Training loss: 2.1923511028289795
Validation loss: 2.0132387120236634

Epoch: 6| Step: 5
Training loss: 2.891136646270752
Validation loss: 2.0102984354060185

Epoch: 6| Step: 6
Training loss: 2.2987327575683594
Validation loss: 2.010083329293036

Epoch: 6| Step: 7
Training loss: 2.3688876628875732
Validation loss: 2.0068149438468357

Epoch: 6| Step: 8
Training loss: 2.2946109771728516
Validation loss: 2.004289719366258

Epoch: 6| Step: 9
Training loss: 2.045501470565796
Validation loss: 2.0020221048785793

Epoch: 6| Step: 10
Training loss: 2.220978260040283
Validation loss: 1.9934432275833622

Epoch: 6| Step: 11
Training loss: 2.212036609649658
Validation loss: 1.9919628481711111

Epoch: 6| Step: 12
Training loss: 2.327240467071533
Validation loss: 1.9998775592414282

Epoch: 6| Step: 13
Training loss: 2.5005786418914795
Validation loss: 2.006763635143157

Epoch: 99| Step: 0
Training loss: 2.5208091735839844
Validation loss: 1.999165581118676

Epoch: 6| Step: 1
Training loss: 1.8096082210540771
Validation loss: 1.993230240319365

Epoch: 6| Step: 2
Training loss: 2.692932605743408
Validation loss: 1.983333956810736

Epoch: 6| Step: 3
Training loss: 2.7802510261535645
Validation loss: 1.9854784665569183

Epoch: 6| Step: 4
Training loss: 2.158332586288452
Validation loss: 1.9825770598585888

Epoch: 6| Step: 5
Training loss: 2.355623245239258
Validation loss: 1.9837235468690113

Epoch: 6| Step: 6
Training loss: 2.099552869796753
Validation loss: 1.9844562302353561

Epoch: 6| Step: 7
Training loss: 2.40901517868042
Validation loss: 1.9925194222440001

Epoch: 6| Step: 8
Training loss: 2.601940155029297
Validation loss: 1.987347379807503

Epoch: 6| Step: 9
Training loss: 1.6838946342468262
Validation loss: 1.9907187364434684

Epoch: 6| Step: 10
Training loss: 2.227409839630127
Validation loss: 1.988944088259051

Epoch: 6| Step: 11
Training loss: 1.7404435873031616
Validation loss: 1.9859750142661474

Epoch: 6| Step: 12
Training loss: 2.518716335296631
Validation loss: 1.989169818098827

Epoch: 6| Step: 13
Training loss: 1.4654736518859863
Validation loss: 1.9988165363188712

Epoch: 100| Step: 0
Training loss: 1.9722832441329956
Validation loss: 2.0489257740718063

Epoch: 6| Step: 1
Training loss: 2.554408073425293
Validation loss: 2.0726932479489233

Epoch: 6| Step: 2
Training loss: 2.173025131225586
Validation loss: 2.063267969316052

Epoch: 6| Step: 3
Training loss: 2.1031017303466797
Validation loss: 2.0491584885504937

Epoch: 6| Step: 4
Training loss: 2.126967430114746
Validation loss: 2.029940712836481

Epoch: 6| Step: 5
Training loss: 2.544463634490967
Validation loss: 2.0064391577115623

Epoch: 6| Step: 6
Training loss: 1.8317468166351318
Validation loss: 1.9918280160555275

Epoch: 6| Step: 7
Training loss: 2.101177930831909
Validation loss: 1.983624601876864

Epoch: 6| Step: 8
Training loss: 2.47151255607605
Validation loss: 1.9842662939461329

Epoch: 6| Step: 9
Training loss: 2.3348119258880615
Validation loss: 1.9856372917852094

Epoch: 6| Step: 10
Training loss: 2.71640944480896
Validation loss: 1.9861779392406504

Epoch: 6| Step: 11
Training loss: 3.083373785018921
Validation loss: 1.9878270497886084

Epoch: 6| Step: 12
Training loss: 1.7025645971298218
Validation loss: 1.9976594435271395

Epoch: 6| Step: 13
Training loss: 2.271803855895996
Validation loss: 1.9982067051754202

Epoch: 101| Step: 0
Training loss: 1.4254275560379028
Validation loss: 2.018614927927653

Epoch: 6| Step: 1
Training loss: 2.623434543609619
Validation loss: 2.0416656899195846

Epoch: 6| Step: 2
Training loss: 3.1628479957580566
Validation loss: 2.0449786481036933

Epoch: 6| Step: 3
Training loss: 1.8220854997634888
Validation loss: 2.061593092897887

Epoch: 6| Step: 4
Training loss: 2.072071075439453
Validation loss: 2.065219348476779

Epoch: 6| Step: 5
Training loss: 2.1806507110595703
Validation loss: 2.068570278024161

Epoch: 6| Step: 6
Training loss: 2.3026413917541504
Validation loss: 2.069170544224401

Epoch: 6| Step: 7
Training loss: 2.389995574951172
Validation loss: 2.0730569644640853

Epoch: 6| Step: 8
Training loss: 2.063565731048584
Validation loss: 2.0617761176119567

Epoch: 6| Step: 9
Training loss: 2.1420631408691406
Validation loss: 2.0309562426741405

Epoch: 6| Step: 10
Training loss: 1.6459393501281738
Validation loss: 2.0060116911447174

Epoch: 6| Step: 11
Training loss: 2.7188029289245605
Validation loss: 1.9917572749558317

Epoch: 6| Step: 12
Training loss: 2.622286558151245
Validation loss: 1.9959336493604927

Epoch: 6| Step: 13
Training loss: 2.132230043411255
Validation loss: 1.9906077077311854

Epoch: 102| Step: 0
Training loss: 1.8212684392929077
Validation loss: 1.9792238819983698

Epoch: 6| Step: 1
Training loss: 2.885640859603882
Validation loss: 1.975428230019026

Epoch: 6| Step: 2
Training loss: 2.502498149871826
Validation loss: 1.9818334105194255

Epoch: 6| Step: 3
Training loss: 2.5820870399475098
Validation loss: 1.966625803260393

Epoch: 6| Step: 4
Training loss: 2.6959948539733887
Validation loss: 1.976400444584508

Epoch: 6| Step: 5
Training loss: 1.573209285736084
Validation loss: 2.000432350302255

Epoch: 6| Step: 6
Training loss: 2.2975845336914062
Validation loss: 2.009822234030693

Epoch: 6| Step: 7
Training loss: 2.022686719894409
Validation loss: 2.014157067063034

Epoch: 6| Step: 8
Training loss: 1.4966895580291748
Validation loss: 2.0156372054930656

Epoch: 6| Step: 9
Training loss: 2.576307773590088
Validation loss: 2.0149935317295853

Epoch: 6| Step: 10
Training loss: 2.609950542449951
Validation loss: 2.0045313681325605

Epoch: 6| Step: 11
Training loss: 2.6705124378204346
Validation loss: 1.99733534935982

Epoch: 6| Step: 12
Training loss: 1.721131682395935
Validation loss: 1.9714175372995355

Epoch: 6| Step: 13
Training loss: 1.7959551811218262
Validation loss: 1.9604468678915372

Epoch: 103| Step: 0
Training loss: 2.6839380264282227
Validation loss: 1.960212888256196

Epoch: 6| Step: 1
Training loss: 2.1304843425750732
Validation loss: 1.9551213325992707

Epoch: 6| Step: 2
Training loss: 2.4682350158691406
Validation loss: 1.9632987873528593

Epoch: 6| Step: 3
Training loss: 1.914151668548584
Validation loss: 1.964042550774031

Epoch: 6| Step: 4
Training loss: 2.5141851902008057
Validation loss: 1.9726026570925148

Epoch: 6| Step: 5
Training loss: 1.9961621761322021
Validation loss: 1.967513007502402

Epoch: 6| Step: 6
Training loss: 2.384267568588257
Validation loss: 1.9883654553403136

Epoch: 6| Step: 7
Training loss: 2.0416817665100098
Validation loss: 1.9993742089117728

Epoch: 6| Step: 8
Training loss: 2.4444689750671387
Validation loss: 2.031882885963686

Epoch: 6| Step: 9
Training loss: 2.106663942337036
Validation loss: 2.044182221094767

Epoch: 6| Step: 10
Training loss: 2.354815721511841
Validation loss: 2.0701425434440694

Epoch: 6| Step: 11
Training loss: 3.038247585296631
Validation loss: 2.060914583103631

Epoch: 6| Step: 12
Training loss: 1.7647863626480103
Validation loss: 2.0542530949397753

Epoch: 6| Step: 13
Training loss: 1.2330875396728516
Validation loss: 2.017579329911099

Epoch: 104| Step: 0
Training loss: 2.1823418140411377
Validation loss: 1.993768584343695

Epoch: 6| Step: 1
Training loss: 1.655799388885498
Validation loss: 1.9687170264541463

Epoch: 6| Step: 2
Training loss: 2.3347606658935547
Validation loss: 1.9677439710145355

Epoch: 6| Step: 3
Training loss: 2.251321792602539
Validation loss: 1.9707404990350046

Epoch: 6| Step: 4
Training loss: 2.1789355278015137
Validation loss: 1.9667035866809148

Epoch: 6| Step: 5
Training loss: 2.305572032928467
Validation loss: 1.9756243472458215

Epoch: 6| Step: 6
Training loss: 2.36501407623291
Validation loss: 1.9764450173224173

Epoch: 6| Step: 7
Training loss: 2.2272021770477295
Validation loss: 1.9895138355993456

Epoch: 6| Step: 8
Training loss: 2.081484794616699
Validation loss: 1.9879555138208533

Epoch: 6| Step: 9
Training loss: 2.314574718475342
Validation loss: 1.9835476670213925

Epoch: 6| Step: 10
Training loss: 1.6344553232192993
Validation loss: 1.9889720165601341

Epoch: 6| Step: 11
Training loss: 3.0301952362060547
Validation loss: 1.9840619089782878

Epoch: 6| Step: 12
Training loss: 2.1483306884765625
Validation loss: 1.979166869194277

Epoch: 6| Step: 13
Training loss: 2.7188310623168945
Validation loss: 1.9739407826495428

Epoch: 105| Step: 0
Training loss: 2.15073561668396
Validation loss: 1.9571594089590094

Epoch: 6| Step: 1
Training loss: 1.8781472444534302
Validation loss: 1.9677332998603903

Epoch: 6| Step: 2
Training loss: 2.6034460067749023
Validation loss: 1.966431276772612

Epoch: 6| Step: 3
Training loss: 2.628573179244995
Validation loss: 1.9830555249285955

Epoch: 6| Step: 4
Training loss: 2.89715576171875
Validation loss: 1.9826334432889057

Epoch: 6| Step: 5
Training loss: 1.748351812362671
Validation loss: 1.9844679832458496

Epoch: 6| Step: 6
Training loss: 2.1863479614257812
Validation loss: 1.989603393821306

Epoch: 6| Step: 7
Training loss: 3.025902271270752
Validation loss: 1.996662647493424

Epoch: 6| Step: 8
Training loss: 1.6367415189743042
Validation loss: 1.9992149235099874

Epoch: 6| Step: 9
Training loss: 2.425431966781616
Validation loss: 2.013672517191979

Epoch: 6| Step: 10
Training loss: 2.319889545440674
Validation loss: 2.014774441719055

Epoch: 6| Step: 11
Training loss: 2.0349984169006348
Validation loss: 2.0177917301013903

Epoch: 6| Step: 12
Training loss: 1.560927391052246
Validation loss: 2.019082700052569

Epoch: 6| Step: 13
Training loss: 1.7802497148513794
Validation loss: 2.020228280816027

Epoch: 106| Step: 0
Training loss: 1.6437230110168457
Validation loss: 2.017998057027017

Epoch: 6| Step: 1
Training loss: 2.3122241497039795
Validation loss: 2.017305862519049

Epoch: 6| Step: 2
Training loss: 2.4818148612976074
Validation loss: 2.0064873644100722

Epoch: 6| Step: 3
Training loss: 1.6867196559906006
Validation loss: 2.0026747142114947

Epoch: 6| Step: 4
Training loss: 2.252692937850952
Validation loss: 1.9814861743680892

Epoch: 6| Step: 5
Training loss: 2.745054244995117
Validation loss: 1.9841000418509207

Epoch: 6| Step: 6
Training loss: 2.264155626296997
Validation loss: 1.988959438057356

Epoch: 6| Step: 7
Training loss: 2.068948745727539
Validation loss: 1.974236084568885

Epoch: 6| Step: 8
Training loss: 2.0791234970092773
Validation loss: 1.9724871163727136

Epoch: 6| Step: 9
Training loss: 2.7113423347473145
Validation loss: 1.975546504861565

Epoch: 6| Step: 10
Training loss: 1.9890999794006348
Validation loss: 1.9703880586931783

Epoch: 6| Step: 11
Training loss: 1.8525681495666504
Validation loss: 1.9527615988126366

Epoch: 6| Step: 12
Training loss: 1.843650221824646
Validation loss: 1.9490736069217804

Epoch: 6| Step: 13
Training loss: 3.2661049365997314
Validation loss: 1.9497735256789832

Epoch: 107| Step: 0
Training loss: 1.8602157831192017
Validation loss: 1.9493643981154247

Epoch: 6| Step: 1
Training loss: 1.7160191535949707
Validation loss: 1.9439725209307928

Epoch: 6| Step: 2
Training loss: 2.31256103515625
Validation loss: 1.9380760372325938

Epoch: 6| Step: 3
Training loss: 2.4493041038513184
Validation loss: 1.9348949796410018

Epoch: 6| Step: 4
Training loss: 2.0568947792053223
Validation loss: 1.940245597593246

Epoch: 6| Step: 5
Training loss: 2.1718013286590576
Validation loss: 1.9383942491264754

Epoch: 6| Step: 6
Training loss: 2.1586804389953613
Validation loss: 1.94355817251308

Epoch: 6| Step: 7
Training loss: 1.9709017276763916
Validation loss: 1.9591977493737334

Epoch: 6| Step: 8
Training loss: 2.9082746505737305
Validation loss: 1.9591199685168523

Epoch: 6| Step: 9
Training loss: 1.7904832363128662
Validation loss: 1.956904734334638

Epoch: 6| Step: 10
Training loss: 1.9716253280639648
Validation loss: 1.948445103501761

Epoch: 6| Step: 11
Training loss: 2.691802978515625
Validation loss: 1.9458719684231667

Epoch: 6| Step: 12
Training loss: 2.1418118476867676
Validation loss: 1.941518026013528

Epoch: 6| Step: 13
Training loss: 2.5909581184387207
Validation loss: 1.942530438464175

Epoch: 108| Step: 0
Training loss: 1.7693185806274414
Validation loss: 1.9414504651100404

Epoch: 6| Step: 1
Training loss: 2.116772174835205
Validation loss: 1.9391901672527354

Epoch: 6| Step: 2
Training loss: 2.2356390953063965
Validation loss: 1.9434405296079573

Epoch: 6| Step: 3
Training loss: 2.5261588096618652
Validation loss: 1.9500060773664905

Epoch: 6| Step: 4
Training loss: 2.6534266471862793
Validation loss: 1.9597597237556212

Epoch: 6| Step: 5
Training loss: 2.4305477142333984
Validation loss: 1.9689078753994358

Epoch: 6| Step: 6
Training loss: 2.0083250999450684
Validation loss: 1.9732607872255388

Epoch: 6| Step: 7
Training loss: 2.0305542945861816
Validation loss: 1.971762127773736

Epoch: 6| Step: 8
Training loss: 2.11982798576355
Validation loss: 1.953591565931997

Epoch: 6| Step: 9
Training loss: 2.989291191101074
Validation loss: 1.9551792452412267

Epoch: 6| Step: 10
Training loss: 2.0994980335235596
Validation loss: 1.953155803424056

Epoch: 6| Step: 11
Training loss: 1.7313563823699951
Validation loss: 1.9612965917074552

Epoch: 6| Step: 12
Training loss: 1.8160572052001953
Validation loss: 1.9624948142677225

Epoch: 6| Step: 13
Training loss: 2.3063507080078125
Validation loss: 1.9749473525631813

Epoch: 109| Step: 0
Training loss: 2.0199105739593506
Validation loss: 1.9816825812862766

Epoch: 6| Step: 1
Training loss: 2.0057809352874756
Validation loss: 1.9915355841318767

Epoch: 6| Step: 2
Training loss: 2.683908462524414
Validation loss: 1.9993961780301985

Epoch: 6| Step: 3
Training loss: 1.8691617250442505
Validation loss: 1.9892447545964231

Epoch: 6| Step: 4
Training loss: 1.6798759698867798
Validation loss: 1.9839610040828746

Epoch: 6| Step: 5
Training loss: 2.6320509910583496
Validation loss: 1.963838997707572

Epoch: 6| Step: 6
Training loss: 1.8198981285095215
Validation loss: 1.9475965576787149

Epoch: 6| Step: 7
Training loss: 1.6339669227600098
Validation loss: 1.9451417922973633

Epoch: 6| Step: 8
Training loss: 2.3717384338378906
Validation loss: 1.9373222256219516

Epoch: 6| Step: 9
Training loss: 2.564018726348877
Validation loss: 1.929059164498442

Epoch: 6| Step: 10
Training loss: 2.7204604148864746
Validation loss: 1.9372500681108045

Epoch: 6| Step: 11
Training loss: 2.008273124694824
Validation loss: 1.9297665293498705

Epoch: 6| Step: 12
Training loss: 2.6638967990875244
Validation loss: 1.9493687178498955

Epoch: 6| Step: 13
Training loss: 1.6583815813064575
Validation loss: 1.9552998106966737

Epoch: 110| Step: 0
Training loss: 1.495868444442749
Validation loss: 1.9436484331725745

Epoch: 6| Step: 1
Training loss: 2.4921505451202393
Validation loss: 1.9494796978530062

Epoch: 6| Step: 2
Training loss: 2.025287628173828
Validation loss: 1.9597331567477154

Epoch: 6| Step: 3
Training loss: 2.1302666664123535
Validation loss: 1.971417461672137

Epoch: 6| Step: 4
Training loss: 2.2311792373657227
Validation loss: 2.016605995034659

Epoch: 6| Step: 5
Training loss: 1.688767433166504
Validation loss: 2.034347117588084

Epoch: 6| Step: 6
Training loss: 2.0454280376434326
Validation loss: 2.042731431222731

Epoch: 6| Step: 7
Training loss: 2.7344727516174316
Validation loss: 2.0184341604991625

Epoch: 6| Step: 8
Training loss: 2.78090238571167
Validation loss: 1.9858383927294003

Epoch: 6| Step: 9
Training loss: 1.957126498222351
Validation loss: 1.98883915844784

Epoch: 6| Step: 10
Training loss: 2.211120843887329
Validation loss: 2.006851318061993

Epoch: 6| Step: 11
Training loss: 2.2276768684387207
Validation loss: 2.0177462139437274

Epoch: 6| Step: 12
Training loss: 2.2403714656829834
Validation loss: 2.0157343008184947

Epoch: 6| Step: 13
Training loss: 2.7549314498901367
Validation loss: 2.035778154609024

Epoch: 111| Step: 0
Training loss: 2.346378803253174
Validation loss: 2.0291699747885428

Epoch: 6| Step: 1
Training loss: 2.6384735107421875
Validation loss: 2.003063267277133

Epoch: 6| Step: 2
Training loss: 1.8842921257019043
Validation loss: 1.9893156072144866

Epoch: 6| Step: 3
Training loss: 2.191915273666382
Validation loss: 1.987665786538073

Epoch: 6| Step: 4
Training loss: 2.2253332138061523
Validation loss: 2.003750446022198

Epoch: 6| Step: 5
Training loss: 2.654345989227295
Validation loss: 2.01517500159561

Epoch: 6| Step: 6
Training loss: 1.4905133247375488
Validation loss: 2.0163986118890906

Epoch: 6| Step: 7
Training loss: 2.7836387157440186
Validation loss: 1.9952989970484087

Epoch: 6| Step: 8
Training loss: 3.0368480682373047
Validation loss: 1.9859785661902478

Epoch: 6| Step: 9
Training loss: 2.2839083671569824
Validation loss: 2.001473770346693

Epoch: 6| Step: 10
Training loss: 1.6898045539855957
Validation loss: 2.0153236414796565

Epoch: 6| Step: 11
Training loss: 2.355776786804199
Validation loss: 2.03852318948315

Epoch: 6| Step: 12
Training loss: 1.8890379667282104
Validation loss: 2.0324354107661913

Epoch: 6| Step: 13
Training loss: 1.4392602443695068
Validation loss: 2.001832046816426

Epoch: 112| Step: 0
Training loss: 2.1954097747802734
Validation loss: 1.9879439287288214

Epoch: 6| Step: 1
Training loss: 1.697669267654419
Validation loss: 1.9721359386239001

Epoch: 6| Step: 2
Training loss: 1.6228740215301514
Validation loss: 1.9724576434781473

Epoch: 6| Step: 3
Training loss: 2.311516761779785
Validation loss: 1.9798030417452577

Epoch: 6| Step: 4
Training loss: 1.7963004112243652
Validation loss: 1.9880081274176156

Epoch: 6| Step: 5
Training loss: 2.5051259994506836
Validation loss: 1.9919427774285758

Epoch: 6| Step: 6
Training loss: 1.7918652296066284
Validation loss: 1.9841882567251883

Epoch: 6| Step: 7
Training loss: 2.1130640506744385
Validation loss: 1.9741527034390358

Epoch: 6| Step: 8
Training loss: 2.712714672088623
Validation loss: 1.9757620570480183

Epoch: 6| Step: 9
Training loss: 1.7044175863265991
Validation loss: 1.9725052131119596

Epoch: 6| Step: 10
Training loss: 3.018603563308716
Validation loss: 1.9637675964704124

Epoch: 6| Step: 11
Training loss: 1.604170799255371
Validation loss: 1.9761048017009613

Epoch: 6| Step: 12
Training loss: 2.486732006072998
Validation loss: 1.9813471250636603

Epoch: 6| Step: 13
Training loss: 3.0014331340789795
Validation loss: 1.986068123130388

Epoch: 113| Step: 0
Training loss: 2.2909584045410156
Validation loss: 1.9796052978884788

Epoch: 6| Step: 1
Training loss: 2.1972298622131348
Validation loss: 1.9927556809558664

Epoch: 6| Step: 2
Training loss: 2.3864247798919678
Validation loss: 2.0057970067506194

Epoch: 6| Step: 3
Training loss: 2.0158886909484863
Validation loss: 2.025848304071734

Epoch: 6| Step: 4
Training loss: 2.214106559753418
Validation loss: 2.030479751607423

Epoch: 6| Step: 5
Training loss: 2.1147990226745605
Validation loss: 2.0054221383986937

Epoch: 6| Step: 6
Training loss: 1.8995623588562012
Validation loss: 1.993946211312407

Epoch: 6| Step: 7
Training loss: 1.864980936050415
Validation loss: 1.9713144302368164

Epoch: 6| Step: 8
Training loss: 2.071025848388672
Validation loss: 1.9541323928422825

Epoch: 6| Step: 9
Training loss: 2.122828960418701
Validation loss: 1.957570142643426

Epoch: 6| Step: 10
Training loss: 2.243316173553467
Validation loss: 1.9576498449489634

Epoch: 6| Step: 11
Training loss: 2.5287022590637207
Validation loss: 1.9700323535550026

Epoch: 6| Step: 12
Training loss: 1.6252224445343018
Validation loss: 1.954626944757277

Epoch: 6| Step: 13
Training loss: 3.0667266845703125
Validation loss: 1.9352543918035363

Epoch: 114| Step: 0
Training loss: 2.272697687149048
Validation loss: 1.9382392898682625

Epoch: 6| Step: 1
Training loss: 1.5029025077819824
Validation loss: 1.9321332413663146

Epoch: 6| Step: 2
Training loss: 3.204941987991333
Validation loss: 1.9336786859778947

Epoch: 6| Step: 3
Training loss: 1.1626307964324951
Validation loss: 1.924260849593788

Epoch: 6| Step: 4
Training loss: 2.2561120986938477
Validation loss: 1.9350840096832604

Epoch: 6| Step: 5
Training loss: 2.0727267265319824
Validation loss: 1.929875954504936

Epoch: 6| Step: 6
Training loss: 1.967603087425232
Validation loss: 1.9298635426387991

Epoch: 6| Step: 7
Training loss: 1.8149354457855225
Validation loss: 1.9379723379688878

Epoch: 6| Step: 8
Training loss: 2.115497589111328
Validation loss: 1.9320191260307067

Epoch: 6| Step: 9
Training loss: 1.913663387298584
Validation loss: 1.9540978452210784

Epoch: 6| Step: 10
Training loss: 2.173239231109619
Validation loss: 1.9659587260215514

Epoch: 6| Step: 11
Training loss: 2.2824931144714355
Validation loss: 1.9877944184887795

Epoch: 6| Step: 12
Training loss: 2.7432632446289062
Validation loss: 2.004731467975083

Epoch: 6| Step: 13
Training loss: 2.9064741134643555
Validation loss: 2.00088127838668

Epoch: 115| Step: 0
Training loss: 1.4431986808776855
Validation loss: 1.9702704080971338

Epoch: 6| Step: 1
Training loss: 2.1494319438934326
Validation loss: 1.9750398589718727

Epoch: 6| Step: 2
Training loss: 1.9825563430786133
Validation loss: 1.957344098757672

Epoch: 6| Step: 3
Training loss: 2.668229341506958
Validation loss: 1.9560839335123699

Epoch: 6| Step: 4
Training loss: 2.4519753456115723
Validation loss: 1.9469403733489334

Epoch: 6| Step: 5
Training loss: 2.2234699726104736
Validation loss: 1.9440563160886046

Epoch: 6| Step: 6
Training loss: 2.4732723236083984
Validation loss: 1.9390059209639026

Epoch: 6| Step: 7
Training loss: 2.610269546508789
Validation loss: 1.9343315119384437

Epoch: 6| Step: 8
Training loss: 1.6118040084838867
Validation loss: 1.9484318071796047

Epoch: 6| Step: 9
Training loss: 2.454698085784912
Validation loss: 1.9624084362419703

Epoch: 6| Step: 10
Training loss: 1.964468002319336
Validation loss: 2.010707634751515

Epoch: 6| Step: 11
Training loss: 2.53316330909729
Validation loss: 2.022163683368314

Epoch: 6| Step: 12
Training loss: 1.9824151992797852
Validation loss: 2.0249514528500137

Epoch: 6| Step: 13
Training loss: 1.932471752166748
Validation loss: 1.9640651902844828

Epoch: 116| Step: 0
Training loss: 1.5145341157913208
Validation loss: 1.9351209607175601

Epoch: 6| Step: 1
Training loss: 1.9599542617797852
Validation loss: 1.9088528579281223

Epoch: 6| Step: 2
Training loss: 1.5781885385513306
Validation loss: 1.9077924451520365

Epoch: 6| Step: 3
Training loss: 2.1603569984436035
Validation loss: 1.9234297147361181

Epoch: 6| Step: 4
Training loss: 1.9284167289733887
Validation loss: 1.9307368237485167

Epoch: 6| Step: 5
Training loss: 3.0305087566375732
Validation loss: 1.942849241277223

Epoch: 6| Step: 6
Training loss: 2.2763335704803467
Validation loss: 1.964101142780755

Epoch: 6| Step: 7
Training loss: 2.239367723464966
Validation loss: 1.9777123107705066

Epoch: 6| Step: 8
Training loss: 2.130051851272583
Validation loss: 2.0008749436306696

Epoch: 6| Step: 9
Training loss: 2.4954612255096436
Validation loss: 2.0011605921611992

Epoch: 6| Step: 10
Training loss: 2.9392457008361816
Validation loss: 2.0173459796495337

Epoch: 6| Step: 11
Training loss: 1.938528060913086
Validation loss: 2.035697889584367

Epoch: 6| Step: 12
Training loss: 1.9369372129440308
Validation loss: 2.03237610478555

Epoch: 6| Step: 13
Training loss: 1.761156678199768
Validation loss: 2.020624832440448

Epoch: 117| Step: 0
Training loss: 1.554070234298706
Validation loss: 2.016957579120513

Epoch: 6| Step: 1
Training loss: 1.485093593597412
Validation loss: 1.9689819505137782

Epoch: 6| Step: 2
Training loss: 2.6397128105163574
Validation loss: 1.9578183543297552

Epoch: 6| Step: 3
Training loss: 1.5632672309875488
Validation loss: 1.9323704755434425

Epoch: 6| Step: 4
Training loss: 1.909864068031311
Validation loss: 1.9201640006034606

Epoch: 6| Step: 5
Training loss: 1.9632712602615356
Validation loss: 1.9221960062621741

Epoch: 6| Step: 6
Training loss: 2.6560933589935303
Validation loss: 1.923960808784731

Epoch: 6| Step: 7
Training loss: 2.531437397003174
Validation loss: 1.9349863529205322

Epoch: 6| Step: 8
Training loss: 2.0323710441589355
Validation loss: 1.952326451578448

Epoch: 6| Step: 9
Training loss: 2.475341796875
Validation loss: 1.9836960813050628

Epoch: 6| Step: 10
Training loss: 1.5812251567840576
Validation loss: 1.9861787737056773

Epoch: 6| Step: 11
Training loss: 2.376621723175049
Validation loss: 2.0018368023698048

Epoch: 6| Step: 12
Training loss: 3.3231921195983887
Validation loss: 1.9877167081320157

Epoch: 6| Step: 13
Training loss: 0.9718623757362366
Validation loss: 1.9753085849105672

Epoch: 118| Step: 0
Training loss: 2.619586944580078
Validation loss: 1.9794610059389504

Epoch: 6| Step: 1
Training loss: 1.5852259397506714
Validation loss: 1.9883598166127359

Epoch: 6| Step: 2
Training loss: 2.036695957183838
Validation loss: 1.978888601385137

Epoch: 6| Step: 3
Training loss: 2.3331706523895264
Validation loss: 1.9903784695491995

Epoch: 6| Step: 4
Training loss: 2.352975845336914
Validation loss: 2.015055607723933

Epoch: 6| Step: 5
Training loss: 1.9663938283920288
Validation loss: 2.0142911608501146

Epoch: 6| Step: 6
Training loss: 1.8836473226547241
Validation loss: 2.0115666325374315

Epoch: 6| Step: 7
Training loss: 2.5127508640289307
Validation loss: 2.003376163462157

Epoch: 6| Step: 8
Training loss: 1.722303867340088
Validation loss: 2.0107477121455695

Epoch: 6| Step: 9
Training loss: 2.1494879722595215
Validation loss: 1.9947806481392152

Epoch: 6| Step: 10
Training loss: 2.114598512649536
Validation loss: 2.0025398859413723

Epoch: 6| Step: 11
Training loss: 2.448596477508545
Validation loss: 1.9888064553660731

Epoch: 6| Step: 12
Training loss: 2.083080291748047
Validation loss: 1.9636632370692428

Epoch: 6| Step: 13
Training loss: 1.2382702827453613
Validation loss: 1.9539752109076387

Epoch: 119| Step: 0
Training loss: 2.6523571014404297
Validation loss: 1.9896534617229173

Epoch: 6| Step: 1
Training loss: 1.627490520477295
Validation loss: 2.023856242497762

Epoch: 6| Step: 2
Training loss: 2.420637845993042
Validation loss: 2.063507849170316

Epoch: 6| Step: 3
Training loss: 2.8974390029907227
Validation loss: 2.0909017696175525

Epoch: 6| Step: 4
Training loss: 1.9139463901519775
Validation loss: 2.067429991178615

Epoch: 6| Step: 5
Training loss: 2.73121976852417
Validation loss: 2.026891120018498

Epoch: 6| Step: 6
Training loss: 1.604485034942627
Validation loss: 1.985093766643155

Epoch: 6| Step: 7
Training loss: 2.0753564834594727
Validation loss: 1.932482357948057

Epoch: 6| Step: 8
Training loss: 1.8293089866638184
Validation loss: 1.926785679273708

Epoch: 6| Step: 9
Training loss: 1.9814453125
Validation loss: 1.9287596300084104

Epoch: 6| Step: 10
Training loss: 1.7909311056137085
Validation loss: 1.9586427057943037

Epoch: 6| Step: 11
Training loss: 2.0305614471435547
Validation loss: 1.9758773055127872

Epoch: 6| Step: 12
Training loss: 2.182793140411377
Validation loss: 1.9998800780183525

Epoch: 6| Step: 13
Training loss: 2.3435275554656982
Validation loss: 1.9929161738323908

Epoch: 120| Step: 0
Training loss: 2.3311514854431152
Validation loss: 2.0240558924213534

Epoch: 6| Step: 1
Training loss: 1.938369631767273
Validation loss: 2.0370006099823983

Epoch: 6| Step: 2
Training loss: 1.6422736644744873
Validation loss: 2.0672823613689792

Epoch: 6| Step: 3
Training loss: 2.002973794937134
Validation loss: 2.0526865810476322

Epoch: 6| Step: 4
Training loss: 2.6621689796447754
Validation loss: 2.047361150864632

Epoch: 6| Step: 5
Training loss: 1.6301594972610474
Validation loss: 2.0299182579081547

Epoch: 6| Step: 6
Training loss: 2.5821802616119385
Validation loss: 2.027763201344398

Epoch: 6| Step: 7
Training loss: 2.387451648712158
Validation loss: 1.9929770346610778

Epoch: 6| Step: 8
Training loss: 2.4320130348205566
Validation loss: 1.97492092399187

Epoch: 6| Step: 9
Training loss: 2.2429840564727783
Validation loss: 1.9390180303204445

Epoch: 6| Step: 10
Training loss: 2.001023769378662
Validation loss: 1.9255143519370788

Epoch: 6| Step: 11
Training loss: 2.2394564151763916
Validation loss: 1.9221855876266316

Epoch: 6| Step: 12
Training loss: 1.6023237705230713
Validation loss: 1.9317009551550752

Epoch: 6| Step: 13
Training loss: 1.2000408172607422
Validation loss: 1.9326773920366842

Epoch: 121| Step: 0
Training loss: 2.293558120727539
Validation loss: 1.948274318889905

Epoch: 6| Step: 1
Training loss: 2.554894208908081
Validation loss: 1.9509468886160082

Epoch: 6| Step: 2
Training loss: 2.2475218772888184
Validation loss: 1.9570122354774064

Epoch: 6| Step: 3
Training loss: 1.882326364517212
Validation loss: 1.952968346175327

Epoch: 6| Step: 4
Training loss: 2.0854616165161133
Validation loss: 1.9501099125031502

Epoch: 6| Step: 5
Training loss: 2.059086322784424
Validation loss: 1.9448091701794696

Epoch: 6| Step: 6
Training loss: 2.437346935272217
Validation loss: 1.933952464852282

Epoch: 6| Step: 7
Training loss: 2.136446475982666
Validation loss: 1.9573193237345705

Epoch: 6| Step: 8
Training loss: 1.3758063316345215
Validation loss: 1.957369455727198

Epoch: 6| Step: 9
Training loss: 2.445889711380005
Validation loss: 1.9374184403368222

Epoch: 6| Step: 10
Training loss: 2.143782138824463
Validation loss: 1.941509755708838

Epoch: 6| Step: 11
Training loss: 1.4135901927947998
Validation loss: 1.955410357444517

Epoch: 6| Step: 12
Training loss: 1.5096163749694824
Validation loss: 1.9735042613039735

Epoch: 6| Step: 13
Training loss: 2.2449581623077393
Validation loss: 2.013961866337766

Epoch: 122| Step: 0
Training loss: 2.3540661334991455
Validation loss: 2.0382415645865986

Epoch: 6| Step: 1
Training loss: 2.151109218597412
Validation loss: 2.0642099585584415

Epoch: 6| Step: 2
Training loss: 2.228577136993408
Validation loss: 2.059523646549512

Epoch: 6| Step: 3
Training loss: 1.4984521865844727
Validation loss: 2.040154887783912

Epoch: 6| Step: 4
Training loss: 1.4543659687042236
Validation loss: 2.0301034732531478

Epoch: 6| Step: 5
Training loss: 2.276829242706299
Validation loss: 1.987246380057386

Epoch: 6| Step: 6
Training loss: 2.3287477493286133
Validation loss: 1.9907354488167712

Epoch: 6| Step: 7
Training loss: 1.6492977142333984
Validation loss: 2.0094609760469004

Epoch: 6| Step: 8
Training loss: 1.581242561340332
Validation loss: 1.9791357030150711

Epoch: 6| Step: 9
Training loss: 2.1183295249938965
Validation loss: 1.9705343502824024

Epoch: 6| Step: 10
Training loss: 2.3338117599487305
Validation loss: 1.9699327150980632

Epoch: 6| Step: 11
Training loss: 2.376227378845215
Validation loss: 1.9619887195607668

Epoch: 6| Step: 12
Training loss: 1.719997525215149
Validation loss: 1.9509014429584626

Epoch: 6| Step: 13
Training loss: 3.2906320095062256
Validation loss: 1.957568814677577

Epoch: 123| Step: 0
Training loss: 2.093980312347412
Validation loss: 1.972143162963211

Epoch: 6| Step: 1
Training loss: 2.6602392196655273
Validation loss: 1.983916877418436

Epoch: 6| Step: 2
Training loss: 1.744742751121521
Validation loss: 1.9829215131780153

Epoch: 6| Step: 3
Training loss: 1.9532407522201538
Validation loss: 1.9722121761691185

Epoch: 6| Step: 4
Training loss: 2.1121346950531006
Validation loss: 1.9684393752005793

Epoch: 6| Step: 5
Training loss: 1.9050958156585693
Validation loss: 1.990895732756584

Epoch: 6| Step: 6
Training loss: 2.6287717819213867
Validation loss: 1.9979607328291862

Epoch: 6| Step: 7
Training loss: 1.616543173789978
Validation loss: 2.0084191278744767

Epoch: 6| Step: 8
Training loss: 2.2102713584899902
Validation loss: 2.0225923253643896

Epoch: 6| Step: 9
Training loss: 2.115962505340576
Validation loss: 2.041082884675713

Epoch: 6| Step: 10
Training loss: 1.6642875671386719
Validation loss: 2.0301288699591034

Epoch: 6| Step: 11
Training loss: 1.9515196084976196
Validation loss: 1.9962573461635138

Epoch: 6| Step: 12
Training loss: 1.7684584856033325
Validation loss: 1.9892634243093512

Epoch: 6| Step: 13
Training loss: 1.5365114212036133
Validation loss: 1.996378114146571

Epoch: 124| Step: 0
Training loss: 1.3732917308807373
Validation loss: 1.9968265051482825

Epoch: 6| Step: 1
Training loss: 2.015336513519287
Validation loss: 1.9901066685235629

Epoch: 6| Step: 2
Training loss: 2.659407377243042
Validation loss: 1.9849747560357536

Epoch: 6| Step: 3
Training loss: 2.165806770324707
Validation loss: 1.976378971530545

Epoch: 6| Step: 4
Training loss: 2.622509002685547
Validation loss: 1.981148035295548

Epoch: 6| Step: 5
Training loss: 1.6490106582641602
Validation loss: 1.9777905171917332

Epoch: 6| Step: 6
Training loss: 2.0722384452819824
Validation loss: 1.9601493984140375

Epoch: 6| Step: 7
Training loss: 1.9078187942504883
Validation loss: 1.9302939215014059

Epoch: 6| Step: 8
Training loss: 2.4629359245300293
Validation loss: 1.9106115051495132

Epoch: 6| Step: 9
Training loss: 2.365499973297119
Validation loss: 1.9062408452392907

Epoch: 6| Step: 10
Training loss: 0.8250592947006226
Validation loss: 1.9000162437397947

Epoch: 6| Step: 11
Training loss: 1.7524534463882446
Validation loss: 1.9175489230822491

Epoch: 6| Step: 12
Training loss: 2.090681314468384
Validation loss: 1.9168385677440192

Epoch: 6| Step: 13
Training loss: 1.75416100025177
Validation loss: 1.9211841424306233

Epoch: 125| Step: 0
Training loss: 2.000580310821533
Validation loss: 1.9133133465243923

Epoch: 6| Step: 1
Training loss: 1.7041494846343994
Validation loss: 1.92442863346428

Epoch: 6| Step: 2
Training loss: 2.411874532699585
Validation loss: 1.9288455568334109

Epoch: 6| Step: 3
Training loss: 2.252805233001709
Validation loss: 1.9811691763580486

Epoch: 6| Step: 4
Training loss: 1.8054145574569702
Validation loss: 2.013859760376715

Epoch: 6| Step: 5
Training loss: 1.7928630113601685
Validation loss: 2.043277527696343

Epoch: 6| Step: 6
Training loss: 2.673894166946411
Validation loss: 2.0527432913421304

Epoch: 6| Step: 7
Training loss: 2.369164228439331
Validation loss: 2.031467822290236

Epoch: 6| Step: 8
Training loss: 1.7573974132537842
Validation loss: 1.9901820998038016

Epoch: 6| Step: 9
Training loss: 1.9460134506225586
Validation loss: 1.9579084278434835

Epoch: 6| Step: 10
Training loss: 1.6306030750274658
Validation loss: 1.9747811581498833

Epoch: 6| Step: 11
Training loss: 1.5904977321624756
Validation loss: 1.9893265026871876

Epoch: 6| Step: 12
Training loss: 2.498079538345337
Validation loss: 2.003422660212363

Epoch: 6| Step: 13
Training loss: 1.5300211906433105
Validation loss: 1.999394101481284

Epoch: 126| Step: 0
Training loss: 2.2526001930236816
Validation loss: 1.9880058150137625

Epoch: 6| Step: 1
Training loss: 1.9374181032180786
Validation loss: 1.9602348842928488

Epoch: 6| Step: 2
Training loss: 1.0196921825408936
Validation loss: 1.9434309441556212

Epoch: 6| Step: 3
Training loss: 2.0476577281951904
Validation loss: 1.8956838051478069

Epoch: 6| Step: 4
Training loss: 1.926128625869751
Validation loss: 1.8958078071635256

Epoch: 6| Step: 5
Training loss: 2.322598457336426
Validation loss: 1.917203446870209

Epoch: 6| Step: 6
Training loss: 1.7453343868255615
Validation loss: 1.9625024500713553

Epoch: 6| Step: 7
Training loss: 2.0595645904541016
Validation loss: 1.9637128781246882

Epoch: 6| Step: 8
Training loss: 1.685739517211914
Validation loss: 1.9615156381360945

Epoch: 6| Step: 9
Training loss: 2.032496929168701
Validation loss: 1.9427487914280226

Epoch: 6| Step: 10
Training loss: 2.0482640266418457
Validation loss: 1.90580665808852

Epoch: 6| Step: 11
Training loss: 2.5475101470947266
Validation loss: 1.9030171748130553

Epoch: 6| Step: 12
Training loss: 2.5292134284973145
Validation loss: 1.9055903214280323

Epoch: 6| Step: 13
Training loss: 1.8932054042816162
Validation loss: 1.9136136219065676

Epoch: 127| Step: 0
Training loss: 2.749922752380371
Validation loss: 1.9475195382231025

Epoch: 6| Step: 1
Training loss: 2.194995880126953
Validation loss: 1.9775713169446556

Epoch: 6| Step: 2
Training loss: 2.1380481719970703
Validation loss: 1.9910411270715858

Epoch: 6| Step: 3
Training loss: 2.2354657649993896
Validation loss: 2.005728316563432

Epoch: 6| Step: 4
Training loss: 1.4532727003097534
Validation loss: 2.0172061227983042

Epoch: 6| Step: 5
Training loss: 1.4400787353515625
Validation loss: 2.0010078850612847

Epoch: 6| Step: 6
Training loss: 1.90240478515625
Validation loss: 1.976850458370742

Epoch: 6| Step: 7
Training loss: 1.9582440853118896
Validation loss: 2.0037762144560456

Epoch: 6| Step: 8
Training loss: 2.1882128715515137
Validation loss: 2.0352576522416967

Epoch: 6| Step: 9
Training loss: 1.4835705757141113
Validation loss: 2.048125131155855

Epoch: 6| Step: 10
Training loss: 1.3823117017745972
Validation loss: 2.026816637285294

Epoch: 6| Step: 11
Training loss: 2.246081829071045
Validation loss: 2.0156468499091362

Epoch: 6| Step: 12
Training loss: 1.723281979560852
Validation loss: 2.0049098127631733

Epoch: 6| Step: 13
Training loss: 2.4832565784454346
Validation loss: 1.9876450236125658

Epoch: 128| Step: 0
Training loss: 2.3057262897491455
Validation loss: 1.9735031602203206

Epoch: 6| Step: 1
Training loss: 2.2032556533813477
Validation loss: 1.9658803580909647

Epoch: 6| Step: 2
Training loss: 1.1104066371917725
Validation loss: 1.953425709919263

Epoch: 6| Step: 3
Training loss: 2.1640191078186035
Validation loss: 1.9549690792637486

Epoch: 6| Step: 4
Training loss: 2.498270273208618
Validation loss: 1.9732427545773086

Epoch: 6| Step: 5
Training loss: 1.8852179050445557
Validation loss: 1.9830219335453485

Epoch: 6| Step: 6
Training loss: 1.7177350521087646
Validation loss: 1.9860644494333575

Epoch: 6| Step: 7
Training loss: 1.939403772354126
Validation loss: 1.988785873177231

Epoch: 6| Step: 8
Training loss: 2.136329174041748
Validation loss: 1.9905111905067199

Epoch: 6| Step: 9
Training loss: 1.4285533428192139
Validation loss: 1.9955341918494112

Epoch: 6| Step: 10
Training loss: 2.080979824066162
Validation loss: 2.0152293136042934

Epoch: 6| Step: 11
Training loss: 1.7425435781478882
Validation loss: 2.016185438761147

Epoch: 6| Step: 12
Training loss: 1.652245044708252
Validation loss: 2.0185623527855

Epoch: 6| Step: 13
Training loss: 1.9360673427581787
Validation loss: 1.9922522857624998

Epoch: 129| Step: 0
Training loss: 2.4440183639526367
Validation loss: 1.9742039967608709

Epoch: 6| Step: 1
Training loss: 1.57416570186615
Validation loss: 1.9614699527781496

Epoch: 6| Step: 2
Training loss: 2.151503086090088
Validation loss: 1.9221680177155362

Epoch: 6| Step: 3
Training loss: 2.7071990966796875
Validation loss: 1.9193544157089726

Epoch: 6| Step: 4
Training loss: 2.1793012619018555
Validation loss: 1.9285876340763544

Epoch: 6| Step: 5
Training loss: 1.8687283992767334
Validation loss: 1.939380576533656

Epoch: 6| Step: 6
Training loss: 1.7824735641479492
Validation loss: 1.9660499044643935

Epoch: 6| Step: 7
Training loss: 0.8826801180839539
Validation loss: 1.9808443412985852

Epoch: 6| Step: 8
Training loss: 1.4703073501586914
Validation loss: 1.9926811443862094

Epoch: 6| Step: 9
Training loss: 2.277273654937744
Validation loss: 1.9748021274484613

Epoch: 6| Step: 10
Training loss: 2.1454243659973145
Validation loss: 1.9697573928422825

Epoch: 6| Step: 11
Training loss: 1.5988538265228271
Validation loss: 1.9937456602691321

Epoch: 6| Step: 12
Training loss: 1.8901115655899048
Validation loss: 2.009242903801703

Epoch: 6| Step: 13
Training loss: 1.4868524074554443
Validation loss: 2.0369665071528447

Epoch: 130| Step: 0
Training loss: 1.3681566715240479
Validation loss: 2.0756854139348513

Epoch: 6| Step: 1
Training loss: 1.6731698513031006
Validation loss: 2.086853442653533

Epoch: 6| Step: 2
Training loss: 2.0146167278289795
Validation loss: 2.0974882661655383

Epoch: 6| Step: 3
Training loss: 2.1428022384643555
Validation loss: 2.1039173474875827

Epoch: 6| Step: 4
Training loss: 2.1146833896636963
Validation loss: 2.13246290914474

Epoch: 6| Step: 5
Training loss: 2.1431479454040527
Validation loss: 2.1049486949879634

Epoch: 6| Step: 6
Training loss: 2.069033145904541
Validation loss: 2.072448592032156

Epoch: 6| Step: 7
Training loss: 1.6066213846206665
Validation loss: 2.049898778238604

Epoch: 6| Step: 8
Training loss: 1.6383237838745117
Validation loss: 2.0259410565899265

Epoch: 6| Step: 9
Training loss: 2.174144744873047
Validation loss: 2.013817629506511

Epoch: 6| Step: 10
Training loss: 1.6740869283676147
Validation loss: 1.993975636779621

Epoch: 6| Step: 11
Training loss: 2.1987247467041016
Validation loss: 1.9610657973956036

Epoch: 6| Step: 12
Training loss: 1.4593623876571655
Validation loss: 1.9559290524451964

Epoch: 6| Step: 13
Training loss: 2.5244877338409424
Validation loss: 1.944282784256884

Epoch: 131| Step: 0
Training loss: 2.1294138431549072
Validation loss: 1.9280309805306055

Epoch: 6| Step: 1
Training loss: 1.9709396362304688
Validation loss: 1.9342805365080475

Epoch: 6| Step: 2
Training loss: 1.6591222286224365
Validation loss: 1.928543104920336

Epoch: 6| Step: 3
Training loss: 1.8369107246398926
Validation loss: 1.9452895720799763

Epoch: 6| Step: 4
Training loss: 1.5881831645965576
Validation loss: 1.9462636670758646

Epoch: 6| Step: 5
Training loss: 2.2290782928466797
Validation loss: 1.9683412172461068

Epoch: 6| Step: 6
Training loss: 1.9238433837890625
Validation loss: 1.989930243902309

Epoch: 6| Step: 7
Training loss: 1.302860975265503
Validation loss: 1.9892322863301923

Epoch: 6| Step: 8
Training loss: 1.7793484926223755
Validation loss: 2.0202566654451433

Epoch: 6| Step: 9
Training loss: 2.4186367988586426
Validation loss: 1.9956112189959454

Epoch: 6| Step: 10
Training loss: 2.5090274810791016
Validation loss: 1.9817525033027894

Epoch: 6| Step: 11
Training loss: 1.668747901916504
Validation loss: 1.9326873338350685

Epoch: 6| Step: 12
Training loss: 1.4216344356536865
Validation loss: 1.9251294828230334

Epoch: 6| Step: 13
Training loss: 2.2493104934692383
Validation loss: 1.9183376091782764

Epoch: 132| Step: 0
Training loss: 2.0730907917022705
Validation loss: 1.9494133457060783

Epoch: 6| Step: 1
Training loss: 2.2807676792144775
Validation loss: 1.9787419290952786

Epoch: 6| Step: 2
Training loss: 1.1262938976287842
Validation loss: 2.0187882607983005

Epoch: 6| Step: 3
Training loss: 1.7532992362976074
Validation loss: 2.04287282113106

Epoch: 6| Step: 4
Training loss: 1.6523748636245728
Validation loss: 2.1321720923146894

Epoch: 6| Step: 5
Training loss: 2.307508945465088
Validation loss: 2.1519174139986754

Epoch: 6| Step: 6
Training loss: 1.9338526725769043
Validation loss: 2.1392003361896803

Epoch: 6| Step: 7
Training loss: 2.3264575004577637
Validation loss: 2.1285479632757043

Epoch: 6| Step: 8
Training loss: 1.9463874101638794
Validation loss: 2.1053703190178

Epoch: 6| Step: 9
Training loss: 1.933634877204895
Validation loss: 2.1013333682091004

Epoch: 6| Step: 10
Training loss: 2.6382360458374023
Validation loss: 2.061572628636514

Epoch: 6| Step: 11
Training loss: 0.9528042078018188
Validation loss: 2.0023492126054663

Epoch: 6| Step: 12
Training loss: 1.4244117736816406
Validation loss: 1.9676378747468353

Epoch: 6| Step: 13
Training loss: 1.919688105583191
Validation loss: 1.9637720533596572

Epoch: 133| Step: 0
Training loss: 2.1005563735961914
Validation loss: 1.9712316528443368

Epoch: 6| Step: 1
Training loss: 1.2881128787994385
Validation loss: 1.9682099280818817

Epoch: 6| Step: 2
Training loss: 1.9153523445129395
Validation loss: 1.9618364662252448

Epoch: 6| Step: 3
Training loss: 1.7307581901550293
Validation loss: 1.9615144883432696

Epoch: 6| Step: 4
Training loss: 2.092099189758301
Validation loss: 1.9755983455206758

Epoch: 6| Step: 5
Training loss: 1.6534968614578247
Validation loss: 1.9919556853591756

Epoch: 6| Step: 6
Training loss: 2.1337602138519287
Validation loss: 2.0064329383193806

Epoch: 6| Step: 7
Training loss: 1.8589280843734741
Validation loss: 2.0218224397269626

Epoch: 6| Step: 8
Training loss: 1.9490468502044678
Validation loss: 2.048324510615359

Epoch: 6| Step: 9
Training loss: 1.1242108345031738
Validation loss: 2.0435270570939585

Epoch: 6| Step: 10
Training loss: 1.8529388904571533
Validation loss: 2.0502213790852535

Epoch: 6| Step: 11
Training loss: 2.0261900424957275
Validation loss: 2.062081206229425

Epoch: 6| Step: 12
Training loss: 2.5657238960266113
Validation loss: 2.07951936926893

Epoch: 6| Step: 13
Training loss: 1.2019468545913696
Validation loss: 2.066907416107834

Epoch: 134| Step: 0
Training loss: 2.116157054901123
Validation loss: 2.040767385113624

Epoch: 6| Step: 1
Training loss: 1.9711776971817017
Validation loss: 1.9814018280275407

Epoch: 6| Step: 2
Training loss: 2.1251823902130127
Validation loss: 1.9395316903309157

Epoch: 6| Step: 3
Training loss: 1.9098173379898071
Validation loss: 1.9266243224502893

Epoch: 6| Step: 4
Training loss: 1.2499061822891235
Validation loss: 1.918319712403

Epoch: 6| Step: 5
Training loss: 2.1595516204833984
Validation loss: 1.9326559356463853

Epoch: 6| Step: 6
Training loss: 1.759581208229065
Validation loss: 1.9550228670079222

Epoch: 6| Step: 7
Training loss: 1.4390110969543457
Validation loss: 1.9823255795304493

Epoch: 6| Step: 8
Training loss: 1.8311151266098022
Validation loss: 2.0021732866123156

Epoch: 6| Step: 9
Training loss: 1.6443531513214111
Validation loss: 2.0068350402257775

Epoch: 6| Step: 10
Training loss: 2.19580340385437
Validation loss: 2.0186750017186648

Epoch: 6| Step: 11
Training loss: 1.5533562898635864
Validation loss: 2.0435722950966126

Epoch: 6| Step: 12
Training loss: 2.3749639987945557
Validation loss: 2.077148574654774

Epoch: 6| Step: 13
Training loss: 1.423954725265503
Validation loss: 2.0984452847511537

Epoch: 135| Step: 0
Training loss: 2.130953311920166
Validation loss: 2.084133771158034

Epoch: 6| Step: 1
Training loss: 3.079237461090088
Validation loss: 2.0646388223094325

Epoch: 6| Step: 2
Training loss: 1.1496543884277344
Validation loss: 2.040390404321814

Epoch: 6| Step: 3
Training loss: 1.922061562538147
Validation loss: 2.021112847071822

Epoch: 6| Step: 4
Training loss: 1.8119747638702393
Validation loss: 1.988200964466218

Epoch: 6| Step: 5
Training loss: 2.4734318256378174
Validation loss: 1.9775041816055134

Epoch: 6| Step: 6
Training loss: 1.2494072914123535
Validation loss: 1.9823493572973436

Epoch: 6| Step: 7
Training loss: 2.1040570735931396
Validation loss: 1.979651315237886

Epoch: 6| Step: 8
Training loss: 1.5358171463012695
Validation loss: 2.008025244999957

Epoch: 6| Step: 9
Training loss: 1.187917709350586
Validation loss: 2.0344490517852125

Epoch: 6| Step: 10
Training loss: 1.2169179916381836
Validation loss: 2.0809701950319353

Epoch: 6| Step: 11
Training loss: 1.8762238025665283
Validation loss: 2.1326085726420083

Epoch: 6| Step: 12
Training loss: 1.8756611347198486
Validation loss: 2.1716065919527443

Epoch: 6| Step: 13
Training loss: 1.9849810600280762
Validation loss: 2.202614043348579

Epoch: 136| Step: 0
Training loss: 2.4491162300109863
Validation loss: 2.216545856127175

Epoch: 6| Step: 1
Training loss: 2.0714235305786133
Validation loss: 2.2035294886558288

Epoch: 6| Step: 2
Training loss: 2.076186418533325
Validation loss: 2.1792687882659254

Epoch: 6| Step: 3
Training loss: 1.6828316450119019
Validation loss: 2.105399008720152

Epoch: 6| Step: 4
Training loss: 1.1726783514022827
Validation loss: 2.0623486247113956

Epoch: 6| Step: 5
Training loss: 1.2775741815567017
Validation loss: 1.984137350513089

Epoch: 6| Step: 6
Training loss: 1.853980302810669
Validation loss: 1.9656894232637139

Epoch: 6| Step: 7
Training loss: 1.7727129459381104
Validation loss: 1.959449646293476

Epoch: 6| Step: 8
Training loss: 1.475595235824585
Validation loss: 1.9528206548383158

Epoch: 6| Step: 9
Training loss: 2.3543529510498047
Validation loss: 1.9557527162695443

Epoch: 6| Step: 10
Training loss: 1.615581750869751
Validation loss: 1.9688029032881542

Epoch: 6| Step: 11
Training loss: 2.080517292022705
Validation loss: 1.953316242464127

Epoch: 6| Step: 12
Training loss: 1.45634126663208
Validation loss: 1.9643541946206042

Epoch: 6| Step: 13
Training loss: 2.0340471267700195
Validation loss: 1.9788688639158845

Epoch: 137| Step: 0
Training loss: 1.2393734455108643
Validation loss: 1.9823350265461912

Epoch: 6| Step: 1
Training loss: 1.6919232606887817
Validation loss: 1.9953102193852907

Epoch: 6| Step: 2
Training loss: 1.7439606189727783
Validation loss: 1.9830574950864237

Epoch: 6| Step: 3
Training loss: 1.954262614250183
Validation loss: 1.9769139930766115

Epoch: 6| Step: 4
Training loss: 2.0460541248321533
Validation loss: 1.9648449997748099

Epoch: 6| Step: 5
Training loss: 1.5470050573349
Validation loss: 1.9867985581838956

Epoch: 6| Step: 6
Training loss: 1.6576259136199951
Validation loss: 1.9828541727476223

Epoch: 6| Step: 7
Training loss: 1.8655924797058105
Validation loss: 2.0107695594910653

Epoch: 6| Step: 8
Training loss: 1.0489325523376465
Validation loss: 2.021209357887186

Epoch: 6| Step: 9
Training loss: 2.3405542373657227
Validation loss: 1.9973450706851097

Epoch: 6| Step: 10
Training loss: 0.8955967426300049
Validation loss: 1.999737448589776

Epoch: 6| Step: 11
Training loss: 1.7396070957183838
Validation loss: 2.0035892160989905

Epoch: 6| Step: 12
Training loss: 2.7224807739257812
Validation loss: 2.00592496959112

Epoch: 6| Step: 13
Training loss: 2.1576104164123535
Validation loss: 2.002075751622518

Epoch: 138| Step: 0
Training loss: 1.5382829904556274
Validation loss: 2.0165848321812128

Epoch: 6| Step: 1
Training loss: 1.70412278175354
Validation loss: 2.0104689777538343

Epoch: 6| Step: 2
Training loss: 1.7821681499481201
Validation loss: 1.9828477521096506

Epoch: 6| Step: 3
Training loss: 1.5810192823410034
Validation loss: 1.991507311021128

Epoch: 6| Step: 4
Training loss: 2.478440046310425
Validation loss: 1.9886324559488604

Epoch: 6| Step: 5
Training loss: 1.6805315017700195
Validation loss: 1.9996921157324186

Epoch: 6| Step: 6
Training loss: 1.3756734132766724
Validation loss: 2.0162080872443413

Epoch: 6| Step: 7
Training loss: 1.6476123332977295
Validation loss: 2.028527100880941

Epoch: 6| Step: 8
Training loss: 1.958990454673767
Validation loss: 2.0140534216357815

Epoch: 6| Step: 9
Training loss: 2.1822261810302734
Validation loss: 2.0239709179888488

Epoch: 6| Step: 10
Training loss: 0.7008213400840759
Validation loss: 2.0104096397276847

Epoch: 6| Step: 11
Training loss: 1.4089093208312988
Validation loss: 1.993103393944361

Epoch: 6| Step: 12
Training loss: 1.830873966217041
Validation loss: 1.969596920474883

Epoch: 6| Step: 13
Training loss: 2.205688953399658
Validation loss: 1.9708687938669676

Epoch: 139| Step: 0
Training loss: 2.133396625518799
Validation loss: 1.9646100664651522

Epoch: 6| Step: 1
Training loss: 1.6706323623657227
Validation loss: 1.9979870665457942

Epoch: 6| Step: 2
Training loss: 1.6874809265136719
Validation loss: 1.9995461586982972

Epoch: 6| Step: 3
Training loss: 1.299178123474121
Validation loss: 2.003638662317748

Epoch: 6| Step: 4
Training loss: 1.9660791158676147
Validation loss: 2.0397879564633934

Epoch: 6| Step: 5
Training loss: 1.6547818183898926
Validation loss: 2.057029212674787

Epoch: 6| Step: 6
Training loss: 1.9713141918182373
Validation loss: 2.0797350637374388

Epoch: 6| Step: 7
Training loss: 2.1696062088012695
Validation loss: 2.0754814481222503

Epoch: 6| Step: 8
Training loss: 1.3526966571807861
Validation loss: 2.0596233414065455

Epoch: 6| Step: 9
Training loss: 1.3981521129608154
Validation loss: 2.0334752477625364

Epoch: 6| Step: 10
Training loss: 1.6283962726593018
Validation loss: 2.0312604993902226

Epoch: 6| Step: 11
Training loss: 1.5072928667068481
Validation loss: 2.0110369382366056

Epoch: 6| Step: 12
Training loss: 1.51297926902771
Validation loss: 2.0018431717349636

Epoch: 6| Step: 13
Training loss: 2.6394848823547363
Validation loss: 2.02239142951145

Epoch: 140| Step: 0
Training loss: 2.1098978519439697
Validation loss: 2.0069861604321386

Epoch: 6| Step: 1
Training loss: 1.7395719289779663
Validation loss: 2.0015736959313832

Epoch: 6| Step: 2
Training loss: 2.4352526664733887
Validation loss: 1.9849569951334307

Epoch: 6| Step: 3
Training loss: 1.6253643035888672
Validation loss: 1.9834377868201143

Epoch: 6| Step: 4
Training loss: 1.412877082824707
Validation loss: 1.9793578501670592

Epoch: 6| Step: 5
Training loss: 0.7359126806259155
Validation loss: 1.9866043572784753

Epoch: 6| Step: 6
Training loss: 1.7157009840011597
Validation loss: 2.0156429403571674

Epoch: 6| Step: 7
Training loss: 1.4479621648788452
Validation loss: 2.057107521641639

Epoch: 6| Step: 8
Training loss: 1.3405280113220215
Validation loss: 2.0459692683271182

Epoch: 6| Step: 9
Training loss: 1.9784667491912842
Validation loss: 2.029590238807022

Epoch: 6| Step: 10
Training loss: 1.8919061422348022
Validation loss: 1.9986616488425963

Epoch: 6| Step: 11
Training loss: 2.002000093460083
Validation loss: 1.9939925978260655

Epoch: 6| Step: 12
Training loss: 2.0381643772125244
Validation loss: 2.0032664191338325

Epoch: 6| Step: 13
Training loss: 1.6121472120285034
Validation loss: 2.0035706848226567

Epoch: 141| Step: 0
Training loss: 1.5402979850769043
Validation loss: 2.006950857818768

Epoch: 6| Step: 1
Training loss: 1.3247523307800293
Validation loss: 1.991433217961301

Epoch: 6| Step: 2
Training loss: 2.170746326446533
Validation loss: 1.9842669425472137

Epoch: 6| Step: 3
Training loss: 1.162163257598877
Validation loss: 2.008132355187529

Epoch: 6| Step: 4
Training loss: 1.7171579599380493
Validation loss: 2.0144491977589105

Epoch: 6| Step: 5
Training loss: 1.9660459756851196
Validation loss: 2.048216888981481

Epoch: 6| Step: 6
Training loss: 2.1438522338867188
Validation loss: 2.0723575033167356

Epoch: 6| Step: 7
Training loss: 1.7334318161010742
Validation loss: 2.0763466973458566

Epoch: 6| Step: 8
Training loss: 1.8249378204345703
Validation loss: 2.111254871532481

Epoch: 6| Step: 9
Training loss: 1.7613444328308105
Validation loss: 2.1284283912310036

Epoch: 6| Step: 10
Training loss: 1.4359190464019775
Validation loss: 2.1008182161597797

Epoch: 6| Step: 11
Training loss: 1.2477471828460693
Validation loss: 2.0782410303751626

Epoch: 6| Step: 12
Training loss: 2.1420631408691406
Validation loss: 2.047398708199942

Epoch: 6| Step: 13
Training loss: 1.8871814012527466
Validation loss: 2.0071117929233018

Epoch: 142| Step: 0
Training loss: 1.5309453010559082
Validation loss: 1.9780818185498636

Epoch: 6| Step: 1
Training loss: 2.1722164154052734
Validation loss: 1.957122229760693

Epoch: 6| Step: 2
Training loss: 2.2365174293518066
Validation loss: 1.9263095035347888

Epoch: 6| Step: 3
Training loss: 0.9861675500869751
Validation loss: 1.9156577958855578

Epoch: 6| Step: 4
Training loss: 1.5330719947814941
Validation loss: 1.8932959623234247

Epoch: 6| Step: 5
Training loss: 1.0914005041122437
Validation loss: 1.8934988449978571

Epoch: 6| Step: 6
Training loss: 2.268118381500244
Validation loss: 1.9264223626864854

Epoch: 6| Step: 7
Training loss: 2.1862921714782715
Validation loss: 1.9348850506608204

Epoch: 6| Step: 8
Training loss: 1.287595272064209
Validation loss: 1.9520077795110724

Epoch: 6| Step: 9
Training loss: 1.4223418235778809
Validation loss: 1.9928360549352502

Epoch: 6| Step: 10
Training loss: 2.296309471130371
Validation loss: 2.034993976675054

Epoch: 6| Step: 11
Training loss: 1.339940071105957
Validation loss: 2.0557343857262724

Epoch: 6| Step: 12
Training loss: 1.0984935760498047
Validation loss: 2.109937378155288

Epoch: 6| Step: 13
Training loss: 2.595506429672241
Validation loss: 2.1118104342491395

Epoch: 143| Step: 0
Training loss: 1.438114881515503
Validation loss: 2.144515984801836

Epoch: 6| Step: 1
Training loss: 1.9050381183624268
Validation loss: 2.1138032379970757

Epoch: 6| Step: 2
Training loss: 0.9466006755828857
Validation loss: 2.0966110767856723

Epoch: 6| Step: 3
Training loss: 1.9164788722991943
Validation loss: 2.0664015726376603

Epoch: 6| Step: 4
Training loss: 1.5951569080352783
Validation loss: 2.0238094252924763

Epoch: 6| Step: 5
Training loss: 1.1917672157287598
Validation loss: 2.015349066385659

Epoch: 6| Step: 6
Training loss: 1.8285984992980957
Validation loss: 2.0037642371269966

Epoch: 6| Step: 7
Training loss: 1.717705249786377
Validation loss: 1.989831457855881

Epoch: 6| Step: 8
Training loss: 2.095846652984619
Validation loss: 1.9708427934236423

Epoch: 6| Step: 9
Training loss: 1.6975412368774414
Validation loss: 1.9512791595151346

Epoch: 6| Step: 10
Training loss: 1.6166197061538696
Validation loss: 1.9509840729416057

Epoch: 6| Step: 11
Training loss: 1.6225615739822388
Validation loss: 1.9569357646408903

Epoch: 6| Step: 12
Training loss: 1.6380575895309448
Validation loss: 1.9753435991143669

Epoch: 6| Step: 13
Training loss: 1.5162744522094727
Validation loss: 1.9877938429514568

Epoch: 144| Step: 0
Training loss: 2.069021701812744
Validation loss: 2.0047912328473982

Epoch: 6| Step: 1
Training loss: 1.3474581241607666
Validation loss: 2.0112096340425554

Epoch: 6| Step: 2
Training loss: 2.0347418785095215
Validation loss: 2.018975870583647

Epoch: 6| Step: 3
Training loss: 2.07871675491333
Validation loss: 2.0453106126477643

Epoch: 6| Step: 4
Training loss: 1.0985444784164429
Validation loss: 2.0370834771023003

Epoch: 6| Step: 5
Training loss: 1.2749377489089966
Validation loss: 2.0185360395780174

Epoch: 6| Step: 6
Training loss: 1.8120622634887695
Validation loss: 1.9975850671850226

Epoch: 6| Step: 7
Training loss: 1.4738656282424927
Validation loss: 2.0199610033342914

Epoch: 6| Step: 8
Training loss: 1.5771398544311523
Validation loss: 2.0067972316536853

Epoch: 6| Step: 9
Training loss: 1.6891800165176392
Validation loss: 1.9914454311452887

Epoch: 6| Step: 10
Training loss: 1.4535362720489502
Validation loss: 1.9895375582479662

Epoch: 6| Step: 11
Training loss: 1.5035803318023682
Validation loss: 1.9873289664586384

Epoch: 6| Step: 12
Training loss: 1.80318021774292
Validation loss: 1.968790505522041

Epoch: 6| Step: 13
Training loss: 1.0006098747253418
Validation loss: 1.9394870304292249

Epoch: 145| Step: 0
Training loss: 1.2890357971191406
Validation loss: 1.9408742009952504

Epoch: 6| Step: 1
Training loss: 1.854526400566101
Validation loss: 1.9316894431268015

Epoch: 6| Step: 2
Training loss: 1.5510348081588745
Validation loss: 1.9327785084324498

Epoch: 6| Step: 3
Training loss: 1.4206968545913696
Validation loss: 1.9262660164986887

Epoch: 6| Step: 4
Training loss: 2.0826382637023926
Validation loss: 1.930225368468992

Epoch: 6| Step: 5
Training loss: 2.1075472831726074
Validation loss: 1.9201430505321873

Epoch: 6| Step: 6
Training loss: 1.0461865663528442
Validation loss: 1.964562318658316

Epoch: 6| Step: 7
Training loss: 1.6750601530075073
Validation loss: 2.0072862525140085

Epoch: 6| Step: 8
Training loss: 1.7264914512634277
Validation loss: 2.0318602028713433

Epoch: 6| Step: 9
Training loss: 1.307747483253479
Validation loss: 2.0387510843174432

Epoch: 6| Step: 10
Training loss: 1.867222785949707
Validation loss: 2.0649657659633185

Epoch: 6| Step: 11
Training loss: 1.35341477394104
Validation loss: 2.064613785794986

Epoch: 6| Step: 12
Training loss: 1.4626340866088867
Validation loss: 2.0750047314551567

Epoch: 6| Step: 13
Training loss: 1.464750051498413
Validation loss: 2.0770908530040453

Epoch: 146| Step: 0
Training loss: 1.885361671447754
Validation loss: 2.042819869133734

Epoch: 6| Step: 1
Training loss: 1.1963014602661133
Validation loss: 2.020067357247876

Epoch: 6| Step: 2
Training loss: 1.1645673513412476
Validation loss: 1.9830211734259

Epoch: 6| Step: 3
Training loss: 2.7705674171447754
Validation loss: 1.9717601217249388

Epoch: 6| Step: 4
Training loss: 1.1463432312011719
Validation loss: 1.9620853316399358

Epoch: 6| Step: 5
Training loss: 1.3298165798187256
Validation loss: 1.9804988266319357

Epoch: 6| Step: 6
Training loss: 1.7734065055847168
Validation loss: 2.0028751486091205

Epoch: 6| Step: 7
Training loss: 1.2821999788284302
Validation loss: 2.0206883492008334

Epoch: 6| Step: 8
Training loss: 1.1475521326065063
Validation loss: 2.023180256607712

Epoch: 6| Step: 9
Training loss: 1.9272485971450806
Validation loss: 2.038285191341113

Epoch: 6| Step: 10
Training loss: 1.3985061645507812
Validation loss: 2.0370946289390646

Epoch: 6| Step: 11
Training loss: 2.01900315284729
Validation loss: 2.0496392737152758

Epoch: 6| Step: 12
Training loss: 1.7814016342163086
Validation loss: 2.020381409634826

Epoch: 6| Step: 13
Training loss: 1.300830602645874
Validation loss: 2.0293076884362007

Epoch: 147| Step: 0
Training loss: 1.7997140884399414
Validation loss: 2.0513530418437016

Epoch: 6| Step: 1
Training loss: 1.5753545761108398
Validation loss: 2.010027459872666

Epoch: 6| Step: 2
Training loss: 0.9248491525650024
Validation loss: 2.011399394722395

Epoch: 6| Step: 3
Training loss: 1.602995753288269
Validation loss: 1.9895526619367703

Epoch: 6| Step: 4
Training loss: 1.5897860527038574
Validation loss: 1.9895764973855787

Epoch: 6| Step: 5
Training loss: 1.214724063873291
Validation loss: 1.9891249582331667

Epoch: 6| Step: 6
Training loss: 1.4098491668701172
Validation loss: 2.0199333301154514

Epoch: 6| Step: 7
Training loss: 1.4839965105056763
Validation loss: 2.0174647992657078

Epoch: 6| Step: 8
Training loss: 1.971700668334961
Validation loss: 2.0107729306785007

Epoch: 6| Step: 9
Training loss: 2.1233601570129395
Validation loss: 2.0305421954842022

Epoch: 6| Step: 10
Training loss: 1.808696985244751
Validation loss: 2.0399028024365826

Epoch: 6| Step: 11
Training loss: 1.6249432563781738
Validation loss: 2.0290947101449452

Epoch: 6| Step: 12
Training loss: 1.4817084074020386
Validation loss: 2.03001001317014

Epoch: 6| Step: 13
Training loss: 1.3176826238632202
Validation loss: 2.03214386458038

Epoch: 148| Step: 0
Training loss: 1.6983764171600342
Validation loss: 2.0052865589818647

Epoch: 6| Step: 1
Training loss: 1.1256632804870605
Validation loss: 1.980273844093405

Epoch: 6| Step: 2
Training loss: 1.2382029294967651
Validation loss: 1.980992219781363

Epoch: 6| Step: 3
Training loss: 2.086833953857422
Validation loss: 1.9473298775252474

Epoch: 6| Step: 4
Training loss: 1.3003183603286743
Validation loss: 1.9400167913847073

Epoch: 6| Step: 5
Training loss: 1.4178681373596191
Validation loss: 1.907876504364834

Epoch: 6| Step: 6
Training loss: 1.522063970565796
Validation loss: 1.9174394966453634

Epoch: 6| Step: 7
Training loss: 1.2935649156570435
Validation loss: 1.9204380307146298

Epoch: 6| Step: 8
Training loss: 1.5827610492706299
Validation loss: 1.9528423996381863

Epoch: 6| Step: 9
Training loss: 1.9491699934005737
Validation loss: 1.9753957102375646

Epoch: 6| Step: 10
Training loss: 1.5953364372253418
Validation loss: 2.011470380649772

Epoch: 6| Step: 11
Training loss: 0.9880443811416626
Validation loss: 2.041970996446507

Epoch: 6| Step: 12
Training loss: 1.6892898082733154
Validation loss: 2.064686047133579

Epoch: 6| Step: 13
Training loss: 2.6620376110076904
Validation loss: 2.045936876727689

Epoch: 149| Step: 0
Training loss: 0.8992701768875122
Validation loss: 2.067148688018963

Epoch: 6| Step: 1
Training loss: 1.8291089534759521
Validation loss: 2.063755045654953

Epoch: 6| Step: 2
Training loss: 1.9137321710586548
Validation loss: 2.0533281269893853

Epoch: 6| Step: 3
Training loss: 1.6589640378952026
Validation loss: 2.028068160498014

Epoch: 6| Step: 4
Training loss: 1.6275526285171509
Validation loss: 2.010377856992906

Epoch: 6| Step: 5
Training loss: 0.7914376854896545
Validation loss: 1.9942796627680461

Epoch: 6| Step: 6
Training loss: 1.8221285343170166
Validation loss: 1.9770050241101174

Epoch: 6| Step: 7
Training loss: 2.1931328773498535
Validation loss: 1.9631529636280511

Epoch: 6| Step: 8
Training loss: 1.3014494180679321
Validation loss: 1.972900527779774

Epoch: 6| Step: 9
Training loss: 1.348677635192871
Validation loss: 1.9761947252417122

Epoch: 6| Step: 10
Training loss: 1.9396809339523315
Validation loss: 1.9726469350117508

Epoch: 6| Step: 11
Training loss: 1.4044311046600342
Validation loss: 1.9983655073309456

Epoch: 6| Step: 12
Training loss: 1.807443618774414
Validation loss: 1.9998916951558923

Epoch: 6| Step: 13
Training loss: 1.255195140838623
Validation loss: 2.010135655762047

Epoch: 150| Step: 0
Training loss: 2.211496353149414
Validation loss: 2.016284118416489

Epoch: 6| Step: 1
Training loss: 1.2795194387435913
Validation loss: 2.0082073544943206

Epoch: 6| Step: 2
Training loss: 1.4649529457092285
Validation loss: 1.994400703778831

Epoch: 6| Step: 3
Training loss: 1.0802322626113892
Validation loss: 2.0060893374104656

Epoch: 6| Step: 4
Training loss: 1.5721300840377808
Validation loss: 2.0130693758687666

Epoch: 6| Step: 5
Training loss: 1.1090892553329468
Validation loss: 1.9937801899448517

Epoch: 6| Step: 6
Training loss: 1.5376873016357422
Validation loss: 1.9996826687166769

Epoch: 6| Step: 7
Training loss: 1.4130371809005737
Validation loss: 2.0128894159870763

Epoch: 6| Step: 8
Training loss: 1.4952054023742676
Validation loss: 2.0263562894636586

Epoch: 6| Step: 9
Training loss: 1.2537808418273926
Validation loss: 2.033956978910713

Epoch: 6| Step: 10
Training loss: 1.823046088218689
Validation loss: 2.0488039383324246

Epoch: 6| Step: 11
Training loss: 1.588667392730713
Validation loss: 2.0422522816606747

Epoch: 6| Step: 12
Training loss: 1.8268015384674072
Validation loss: 2.0616824421831357

Epoch: 6| Step: 13
Training loss: 1.2426304817199707
Validation loss: 2.0874698905534643

Epoch: 151| Step: 0
Training loss: 1.5466389656066895
Validation loss: 2.1201937314002746

Epoch: 6| Step: 1
Training loss: 2.0684597492218018
Validation loss: 2.1520233641388598

Epoch: 6| Step: 2
Training loss: 1.9802274703979492
Validation loss: 2.186522135170557

Epoch: 6| Step: 3
Training loss: 1.7504165172576904
Validation loss: 2.150518468631211

Epoch: 6| Step: 4
Training loss: 1.6066174507141113
Validation loss: 2.11373814716134

Epoch: 6| Step: 5
Training loss: 1.1478006839752197
Validation loss: 2.078978882041029

Epoch: 6| Step: 6
Training loss: 1.3572635650634766
Validation loss: 2.027629908695016

Epoch: 6| Step: 7
Training loss: 0.9203352928161621
Validation loss: 1.9848351350394629

Epoch: 6| Step: 8
Training loss: 1.564939260482788
Validation loss: 1.9673451595408942

Epoch: 6| Step: 9
Training loss: 1.635324478149414
Validation loss: 1.9207259801126295

Epoch: 6| Step: 10
Training loss: 2.003664493560791
Validation loss: 1.9169892675133162

Epoch: 6| Step: 11
Training loss: 1.2997735738754272
Validation loss: 1.9135725818654543

Epoch: 6| Step: 12
Training loss: 1.1968624591827393
Validation loss: 1.9115916477736605

Epoch: 6| Step: 13
Training loss: 1.3007017374038696
Validation loss: 1.9351702300451135

Epoch: 152| Step: 0
Training loss: 1.4329781532287598
Validation loss: 1.9641627919289373

Epoch: 6| Step: 1
Training loss: 1.656320333480835
Validation loss: 1.9822635099452028

Epoch: 6| Step: 2
Training loss: 1.7323706150054932
Validation loss: 1.9820840128006474

Epoch: 6| Step: 3
Training loss: 1.8008376359939575
Validation loss: 1.963200492243613

Epoch: 6| Step: 4
Training loss: 0.9766772389411926
Validation loss: 1.96517365465882

Epoch: 6| Step: 5
Training loss: 2.2973504066467285
Validation loss: 1.9799911924587783

Epoch: 6| Step: 6
Training loss: 1.5399930477142334
Validation loss: 2.007125331509498

Epoch: 6| Step: 7
Training loss: 1.6608827114105225
Validation loss: 2.0315809954879103

Epoch: 6| Step: 8
Training loss: 1.6140164136886597
Validation loss: 2.056876646575107

Epoch: 6| Step: 9
Training loss: 1.278364896774292
Validation loss: 2.088479370199224

Epoch: 6| Step: 10
Training loss: 1.475967288017273
Validation loss: 2.0906764614966606

Epoch: 6| Step: 11
Training loss: 1.1653265953063965
Validation loss: 2.067380533423475

Epoch: 6| Step: 12
Training loss: 1.4249407052993774
Validation loss: 2.016514914010161

Epoch: 6| Step: 13
Training loss: 1.5724812746047974
Validation loss: 2.0100148954699115

Epoch: 153| Step: 0
Training loss: 1.3929508924484253
Validation loss: 1.9904633132360314

Epoch: 6| Step: 1
Training loss: 1.5821129083633423
Validation loss: 2.009608845556936

Epoch: 6| Step: 2
Training loss: 1.2944974899291992
Validation loss: 2.0155202816891413

Epoch: 6| Step: 3
Training loss: 1.7224764823913574
Validation loss: 2.033274876174106

Epoch: 6| Step: 4
Training loss: 1.3154857158660889
Validation loss: 2.000362644913376

Epoch: 6| Step: 5
Training loss: 1.645918369293213
Validation loss: 2.0079964796702066

Epoch: 6| Step: 6
Training loss: 1.0552549362182617
Validation loss: 1.9949437700292116

Epoch: 6| Step: 7
Training loss: 2.0304512977600098
Validation loss: 1.9496579324045489

Epoch: 6| Step: 8
Training loss: 2.040653705596924
Validation loss: 1.9524131833866079

Epoch: 6| Step: 9
Training loss: 1.6602758169174194
Validation loss: 1.985868921843908

Epoch: 6| Step: 10
Training loss: 1.231203317642212
Validation loss: 1.9626334662078528

Epoch: 6| Step: 11
Training loss: 1.2425453662872314
Validation loss: 2.003423721559586

Epoch: 6| Step: 12
Training loss: 1.1013092994689941
Validation loss: 2.0148433523793376

Epoch: 6| Step: 13
Training loss: 1.3548189401626587
Validation loss: 2.022365085540279

Epoch: 154| Step: 0
Training loss: 1.2509411573410034
Validation loss: 2.010563499184065

Epoch: 6| Step: 1
Training loss: 1.3732292652130127
Validation loss: 2.018178291218255

Epoch: 6| Step: 2
Training loss: 0.9643471240997314
Validation loss: 2.025958139409301

Epoch: 6| Step: 3
Training loss: 2.461143970489502
Validation loss: 2.0101749832912157

Epoch: 6| Step: 4
Training loss: 1.6112217903137207
Validation loss: 1.999794634439612

Epoch: 6| Step: 5
Training loss: 1.5892517566680908
Validation loss: 1.9873978155915455

Epoch: 6| Step: 6
Training loss: 1.3026554584503174
Validation loss: 1.9873560641401558

Epoch: 6| Step: 7
Training loss: 1.4124215841293335
Validation loss: 1.9982990039292203

Epoch: 6| Step: 8
Training loss: 1.9962539672851562
Validation loss: 2.028121094549856

Epoch: 6| Step: 9
Training loss: 1.6491641998291016
Validation loss: 2.0196458152545396

Epoch: 6| Step: 10
Training loss: 0.8824511766433716
Validation loss: 2.0096240223094983

Epoch: 6| Step: 11
Training loss: 1.3448026180267334
Validation loss: 1.997685836207482

Epoch: 6| Step: 12
Training loss: 1.2419308423995972
Validation loss: 1.9659716967613465

Epoch: 6| Step: 13
Training loss: 1.0407519340515137
Validation loss: 1.954930692590693

Epoch: 155| Step: 0
Training loss: 1.594541311264038
Validation loss: 1.9359607901624454

Epoch: 6| Step: 1
Training loss: 1.0373926162719727
Validation loss: 1.9335771145359162

Epoch: 6| Step: 2
Training loss: 1.5353167057037354
Validation loss: 1.951561676558628

Epoch: 6| Step: 3
Training loss: 1.0716561079025269
Validation loss: 1.9548908907880065

Epoch: 6| Step: 4
Training loss: 1.7748136520385742
Validation loss: 1.9591678868057907

Epoch: 6| Step: 5
Training loss: 1.2864487171173096
Validation loss: 1.9858463195062452

Epoch: 6| Step: 6
Training loss: 1.5887205600738525
Validation loss: 2.0195364195813417

Epoch: 6| Step: 7
Training loss: 1.64551842212677
Validation loss: 2.0333175005451327

Epoch: 6| Step: 8
Training loss: 1.8744367361068726
Validation loss: 2.0412062996177265

Epoch: 6| Step: 9
Training loss: 1.6465816497802734
Validation loss: 2.0422178827306277

Epoch: 6| Step: 10
Training loss: 1.2674686908721924
Validation loss: 2.0495382714015182

Epoch: 6| Step: 11
Training loss: 1.3514102697372437
Validation loss: 2.024306301147707

Epoch: 6| Step: 12
Training loss: 0.9135849475860596
Validation loss: 2.0388676812571864

Epoch: 6| Step: 13
Training loss: 1.5011569261550903
Validation loss: 2.031517004454008

Epoch: 156| Step: 0
Training loss: 1.2249562740325928
Validation loss: 2.0131233225586596

Epoch: 6| Step: 1
Training loss: 1.2374578714370728
Validation loss: 1.9967501689028997

Epoch: 6| Step: 2
Training loss: 2.0033304691314697
Validation loss: 1.99307769344699

Epoch: 6| Step: 3
Training loss: 1.5068211555480957
Validation loss: 1.9779376573460077

Epoch: 6| Step: 4
Training loss: 1.579113245010376
Validation loss: 1.9700361464613227

Epoch: 6| Step: 5
Training loss: 0.9745804071426392
Validation loss: 1.9706241494865828

Epoch: 6| Step: 6
Training loss: 1.3826565742492676
Validation loss: 1.968347043119451

Epoch: 6| Step: 7
Training loss: 2.17647385597229
Validation loss: 1.9652520905258835

Epoch: 6| Step: 8
Training loss: 1.2574656009674072
Validation loss: 1.9669882289824947

Epoch: 6| Step: 9
Training loss: 1.3702318668365479
Validation loss: 1.9550610537170081

Epoch: 6| Step: 10
Training loss: 1.1552411317825317
Validation loss: 1.9705807137232956

Epoch: 6| Step: 11
Training loss: 0.7173797488212585
Validation loss: 1.9855009048215804

Epoch: 6| Step: 12
Training loss: 1.4845099449157715
Validation loss: 2.0071409325445853

Epoch: 6| Step: 13
Training loss: 1.5409908294677734
Validation loss: 2.0463788573459913

Epoch: 157| Step: 0
Training loss: 1.0929932594299316
Validation loss: 2.0501548859380905

Epoch: 6| Step: 1
Training loss: 1.5982836484909058
Validation loss: 2.0914281965583883

Epoch: 6| Step: 2
Training loss: 1.0452067852020264
Validation loss: 2.071501911327403

Epoch: 6| Step: 3
Training loss: 0.891560971736908
Validation loss: 2.0275075435638428

Epoch: 6| Step: 4
Training loss: 1.6358628273010254
Validation loss: 2.024350761085428

Epoch: 6| Step: 5
Training loss: 0.9677121639251709
Validation loss: 2.0063082428388697

Epoch: 6| Step: 6
Training loss: 1.1389391422271729
Validation loss: 1.9879135213872439

Epoch: 6| Step: 7
Training loss: 1.411311149597168
Validation loss: 1.96861663428686

Epoch: 6| Step: 8
Training loss: 1.2568620443344116
Validation loss: 1.9458446643685783

Epoch: 6| Step: 9
Training loss: 1.3125929832458496
Validation loss: 1.9570009964768604

Epoch: 6| Step: 10
Training loss: 1.5719218254089355
Validation loss: 1.9524966029710666

Epoch: 6| Step: 11
Training loss: 1.191030740737915
Validation loss: 1.9601573610818515

Epoch: 6| Step: 12
Training loss: 2.246588706970215
Validation loss: 1.9881527526404268

Epoch: 6| Step: 13
Training loss: 2.5402870178222656
Validation loss: 2.0245798044307257

Epoch: 158| Step: 0
Training loss: 1.0987699031829834
Validation loss: 2.0370575561318347

Epoch: 6| Step: 1
Training loss: 1.4267756938934326
Validation loss: 2.025430290929733

Epoch: 6| Step: 2
Training loss: 1.4861949682235718
Validation loss: 2.0232134660085044

Epoch: 6| Step: 3
Training loss: 1.3935987949371338
Validation loss: 2.008148390759704

Epoch: 6| Step: 4
Training loss: 1.5891387462615967
Validation loss: 2.009678284327189

Epoch: 6| Step: 5
Training loss: 1.5711828470230103
Validation loss: 2.0625075858126403

Epoch: 6| Step: 6
Training loss: 1.5645848512649536
Validation loss: 2.1109128216261506

Epoch: 6| Step: 7
Training loss: 1.9224375486373901
Validation loss: 2.095756907616892

Epoch: 6| Step: 8
Training loss: 1.4886512756347656
Validation loss: 2.0545015053082536

Epoch: 6| Step: 9
Training loss: 1.3207266330718994
Validation loss: 2.002897298464211

Epoch: 6| Step: 10
Training loss: 0.846872866153717
Validation loss: 1.9860176142825876

Epoch: 6| Step: 11
Training loss: 1.2202510833740234
Validation loss: 1.9960349541838451

Epoch: 6| Step: 12
Training loss: 1.4342305660247803
Validation loss: 2.010439972723684

Epoch: 6| Step: 13
Training loss: 1.1390974521636963
Validation loss: 2.0384058080693728

Epoch: 159| Step: 0
Training loss: 1.7401504516601562
Validation loss: 2.0392097401362594

Epoch: 6| Step: 1
Training loss: 1.674274206161499
Validation loss: 2.0188812696805565

Epoch: 6| Step: 2
Training loss: 1.6182801723480225
Validation loss: 2.02644540673943

Epoch: 6| Step: 3
Training loss: 1.4278137683868408
Validation loss: 1.99967610707847

Epoch: 6| Step: 4
Training loss: 1.3757202625274658
Validation loss: 2.0477828120672577

Epoch: 6| Step: 5
Training loss: 1.5028791427612305
Validation loss: 2.063916221741707

Epoch: 6| Step: 6
Training loss: 0.9162245392799377
Validation loss: 2.0551359512472667

Epoch: 6| Step: 7
Training loss: 0.7714405059814453
Validation loss: 2.0510391932661816

Epoch: 6| Step: 8
Training loss: 1.3956315517425537
Validation loss: 2.0228100822817896

Epoch: 6| Step: 9
Training loss: 0.8598974943161011
Validation loss: 2.0120660233241257

Epoch: 6| Step: 10
Training loss: 2.029283046722412
Validation loss: 1.990700255158127

Epoch: 6| Step: 11
Training loss: 1.6254448890686035
Validation loss: 1.9699840558472501

Epoch: 6| Step: 12
Training loss: 0.8601717352867126
Validation loss: 1.9783484307668542

Epoch: 6| Step: 13
Training loss: 2.0911343097686768
Validation loss: 1.9386968561398086

Epoch: 160| Step: 0
Training loss: 1.7600579261779785
Validation loss: 1.946944518755841

Epoch: 6| Step: 1
Training loss: 1.5488168001174927
Validation loss: 1.9467806893010293

Epoch: 6| Step: 2
Training loss: 1.0737181901931763
Validation loss: 1.959166572939965

Epoch: 6| Step: 3
Training loss: 1.8096356391906738
Validation loss: 1.9358505843788065

Epoch: 6| Step: 4
Training loss: 1.2860357761383057
Validation loss: 1.9555557466322375

Epoch: 6| Step: 5
Training loss: 1.2528150081634521
Validation loss: 1.9554451075933312

Epoch: 6| Step: 6
Training loss: 0.7629558444023132
Validation loss: 1.9660736809494674

Epoch: 6| Step: 7
Training loss: 1.514366865158081
Validation loss: 1.986841881146995

Epoch: 6| Step: 8
Training loss: 1.5872766971588135
Validation loss: 1.9908302535292923

Epoch: 6| Step: 9
Training loss: 1.6281096935272217
Validation loss: 1.9916977369657127

Epoch: 6| Step: 10
Training loss: 1.2147161960601807
Validation loss: 1.9977016102883123

Epoch: 6| Step: 11
Training loss: 0.993524432182312
Validation loss: 2.022858154389166

Epoch: 6| Step: 12
Training loss: 0.9768791198730469
Validation loss: 2.0343483981265815

Epoch: 6| Step: 13
Training loss: 0.6419535279273987
Validation loss: 2.0004176273140857

Epoch: 161| Step: 0
Training loss: 1.1600534915924072
Validation loss: 1.98372551830866

Epoch: 6| Step: 1
Training loss: 1.3189971446990967
Validation loss: 1.972719000231835

Epoch: 6| Step: 2
Training loss: 1.7540621757507324
Validation loss: 1.9519986029594176

Epoch: 6| Step: 3
Training loss: 1.7974592447280884
Validation loss: 1.9355766081040906

Epoch: 6| Step: 4
Training loss: 1.308688759803772
Validation loss: 1.95882047119961

Epoch: 6| Step: 5
Training loss: 0.9364993572235107
Validation loss: 1.9547895180281771

Epoch: 6| Step: 6
Training loss: 0.7449573278427124
Validation loss: 1.955317961272373

Epoch: 6| Step: 7
Training loss: 1.1509580612182617
Validation loss: 1.9532390281718264

Epoch: 6| Step: 8
Training loss: 1.1233892440795898
Validation loss: 1.9511496789993779

Epoch: 6| Step: 9
Training loss: 1.6570258140563965
Validation loss: 1.970379155169251

Epoch: 6| Step: 10
Training loss: 1.732977032661438
Validation loss: 1.978212046366866

Epoch: 6| Step: 11
Training loss: 1.0301439762115479
Validation loss: 1.981907449742799

Epoch: 6| Step: 12
Training loss: 1.4890755414962769
Validation loss: 1.9953297197177846

Epoch: 6| Step: 13
Training loss: 1.0395187139511108
Validation loss: 1.969731330871582

Epoch: 162| Step: 0
Training loss: 1.2311763763427734
Validation loss: 1.9999445176893664

Epoch: 6| Step: 1
Training loss: 0.6131942272186279
Validation loss: 1.9814529393308906

Epoch: 6| Step: 2
Training loss: 1.552938461303711
Validation loss: 1.9806917380261164

Epoch: 6| Step: 3
Training loss: 1.485708236694336
Validation loss: 1.9821019890487834

Epoch: 6| Step: 4
Training loss: 1.2473723888397217
Validation loss: 1.9792745280009445

Epoch: 6| Step: 5
Training loss: 1.2508811950683594
Validation loss: 1.9881183896013486

Epoch: 6| Step: 6
Training loss: 1.3189716339111328
Validation loss: 2.0128731522508847

Epoch: 6| Step: 7
Training loss: 1.74934983253479
Validation loss: 2.0247541460939633

Epoch: 6| Step: 8
Training loss: 1.3781156539916992
Validation loss: 2.0090717141346266

Epoch: 6| Step: 9
Training loss: 1.0857934951782227
Validation loss: 2.0037040095175467

Epoch: 6| Step: 10
Training loss: 1.1119922399520874
Validation loss: 1.9901720951962214

Epoch: 6| Step: 11
Training loss: 1.1973419189453125
Validation loss: 1.9623134520746046

Epoch: 6| Step: 12
Training loss: 1.58485746383667
Validation loss: 1.9684766056717082

Epoch: 6| Step: 13
Training loss: 1.1198506355285645
Validation loss: 1.960820859478366

Epoch: 163| Step: 0
Training loss: 1.4268878698349
Validation loss: 1.968784624530423

Epoch: 6| Step: 1
Training loss: 1.5657217502593994
Validation loss: 1.9468251761569773

Epoch: 6| Step: 2
Training loss: 1.1929301023483276
Validation loss: 1.9554092089335124

Epoch: 6| Step: 3
Training loss: 1.0367227792739868
Validation loss: 1.9589802488203971

Epoch: 6| Step: 4
Training loss: 2.1516478061676025
Validation loss: 1.9694409062785487

Epoch: 6| Step: 5
Training loss: 1.8033956289291382
Validation loss: 1.9973377707184001

Epoch: 6| Step: 6
Training loss: 0.8362440466880798
Validation loss: 2.02170661059759

Epoch: 6| Step: 7
Training loss: 0.6718475818634033
Validation loss: 2.023457116978143

Epoch: 6| Step: 8
Training loss: 1.280784249305725
Validation loss: 2.0449496623008483

Epoch: 6| Step: 9
Training loss: 1.2150094509124756
Validation loss: 2.0628978116537935

Epoch: 6| Step: 10
Training loss: 1.6590303182601929
Validation loss: 2.082577113182314

Epoch: 6| Step: 11
Training loss: 1.2210516929626465
Validation loss: 2.085591167531988

Epoch: 6| Step: 12
Training loss: 0.9598478078842163
Validation loss: 2.045649782303841

Epoch: 6| Step: 13
Training loss: 0.909613847732544
Validation loss: 2.0008590054768387

Epoch: 164| Step: 0
Training loss: 1.474327564239502
Validation loss: 1.9479506092686807

Epoch: 6| Step: 1
Training loss: 1.0843151807785034
Validation loss: 1.937676275930097

Epoch: 6| Step: 2
Training loss: 1.0555062294006348
Validation loss: 1.9446314752742808

Epoch: 6| Step: 3
Training loss: 1.2063648700714111
Validation loss: 1.9502246226033857

Epoch: 6| Step: 4
Training loss: 1.2758381366729736
Validation loss: 1.9547868287691506

Epoch: 6| Step: 5
Training loss: 0.7225103974342346
Validation loss: 1.9492774342977872

Epoch: 6| Step: 6
Training loss: 1.3442596197128296
Validation loss: 1.9641424763587214

Epoch: 6| Step: 7
Training loss: 1.2508680820465088
Validation loss: 2.0005837768636723

Epoch: 6| Step: 8
Training loss: 1.639505386352539
Validation loss: 2.032667020315765

Epoch: 6| Step: 9
Training loss: 1.5425341129302979
Validation loss: 2.0388792099491244

Epoch: 6| Step: 10
Training loss: 1.9009957313537598
Validation loss: 2.0727595308775544

Epoch: 6| Step: 11
Training loss: 0.6333494186401367
Validation loss: 2.083077638379989

Epoch: 6| Step: 12
Training loss: 1.1236152648925781
Validation loss: 2.0653313872634724

Epoch: 6| Step: 13
Training loss: 1.8894081115722656
Validation loss: 2.0573203563690186

Epoch: 165| Step: 0
Training loss: 0.9156387448310852
Validation loss: 2.0524845764201176

Epoch: 6| Step: 1
Training loss: 0.8937817811965942
Validation loss: 2.0522228774204048

Epoch: 6| Step: 2
Training loss: 1.260841965675354
Validation loss: 2.0166890262275614

Epoch: 6| Step: 3
Training loss: 1.476108193397522
Validation loss: 2.020159408610354

Epoch: 6| Step: 4
Training loss: 0.5970100164413452
Validation loss: 2.0032119161339215

Epoch: 6| Step: 5
Training loss: 0.8727437257766724
Validation loss: 1.9759912388299101

Epoch: 6| Step: 6
Training loss: 1.1280590295791626
Validation loss: 1.9590428747156614

Epoch: 6| Step: 7
Training loss: 1.4359471797943115
Validation loss: 1.9518532112080564

Epoch: 6| Step: 8
Training loss: 1.5666029453277588
Validation loss: 1.9415489242922874

Epoch: 6| Step: 9
Training loss: 1.258150577545166
Validation loss: 1.9524231008304063

Epoch: 6| Step: 10
Training loss: 1.771942138671875
Validation loss: 1.966900542218198

Epoch: 6| Step: 11
Training loss: 1.4886460304260254
Validation loss: 1.949319129349083

Epoch: 6| Step: 12
Training loss: 1.0892839431762695
Validation loss: 1.9481303589318388

Epoch: 6| Step: 13
Training loss: 1.1697663068771362
Validation loss: 1.9473420650728288

Epoch: 166| Step: 0
Training loss: 1.0428556203842163
Validation loss: 1.9485556874223935

Epoch: 6| Step: 1
Training loss: 0.8902992010116577
Validation loss: 1.9431851499824113

Epoch: 6| Step: 2
Training loss: 1.3022048473358154
Validation loss: 1.9314427375793457

Epoch: 6| Step: 3
Training loss: 1.3392726182937622
Validation loss: 1.92611192118737

Epoch: 6| Step: 4
Training loss: 1.883943796157837
Validation loss: 1.935386178314045

Epoch: 6| Step: 5
Training loss: 1.204942226409912
Validation loss: 1.9408549390813357

Epoch: 6| Step: 6
Training loss: 1.4620877504348755
Validation loss: 1.962754418773036

Epoch: 6| Step: 7
Training loss: 0.9798199534416199
Validation loss: 1.9694941056671964

Epoch: 6| Step: 8
Training loss: 1.1625800132751465
Validation loss: 1.9835644152856642

Epoch: 6| Step: 9
Training loss: 0.637848436832428
Validation loss: 1.9992525987727667

Epoch: 6| Step: 10
Training loss: 0.8766319751739502
Validation loss: 2.0287354146280596

Epoch: 6| Step: 11
Training loss: 1.415008783340454
Validation loss: 2.042705612797891

Epoch: 6| Step: 12
Training loss: 1.4332242012023926
Validation loss: 2.0348982503337245

Epoch: 6| Step: 13
Training loss: 0.7279942035675049
Validation loss: 2.0410797288340907

Epoch: 167| Step: 0
Training loss: 0.9881675243377686
Validation loss: 1.9984637998765515

Epoch: 6| Step: 1
Training loss: 1.4319761991500854
Validation loss: 2.0054891083830144

Epoch: 6| Step: 2
Training loss: 1.3188045024871826
Validation loss: 1.952461258057625

Epoch: 6| Step: 3
Training loss: 1.3150138854980469
Validation loss: 1.9341048091970465

Epoch: 6| Step: 4
Training loss: 1.069728136062622
Validation loss: 1.908704351353389

Epoch: 6| Step: 5
Training loss: 1.2378952503204346
Validation loss: 1.9065186733840613

Epoch: 6| Step: 6
Training loss: 1.098787546157837
Validation loss: 1.904148288952407

Epoch: 6| Step: 7
Training loss: 0.8511531352996826
Validation loss: 1.9037103934954571

Epoch: 6| Step: 8
Training loss: 1.393688678741455
Validation loss: 1.9248939380850842

Epoch: 6| Step: 9
Training loss: 1.2684049606323242
Validation loss: 1.957940657933553

Epoch: 6| Step: 10
Training loss: 1.0990233421325684
Validation loss: 1.975548998002083

Epoch: 6| Step: 11
Training loss: 1.6177163124084473
Validation loss: 2.027892440877935

Epoch: 6| Step: 12
Training loss: 0.816703200340271
Validation loss: 2.0410114513930453

Epoch: 6| Step: 13
Training loss: 1.486112117767334
Validation loss: 2.0297603171358825

Epoch: 168| Step: 0
Training loss: 1.5445661544799805
Validation loss: 2.005262922215205

Epoch: 6| Step: 1
Training loss: 1.1914228200912476
Validation loss: 1.999500225949031

Epoch: 6| Step: 2
Training loss: 1.2801685333251953
Validation loss: 1.9960015858373334

Epoch: 6| Step: 3
Training loss: 1.2624205350875854
Validation loss: 1.982854417575303

Epoch: 6| Step: 4
Training loss: 1.311867356300354
Validation loss: 2.011067262259863

Epoch: 6| Step: 5
Training loss: 1.5510709285736084
Validation loss: 1.9775617737923898

Epoch: 6| Step: 6
Training loss: 0.5578130483627319
Validation loss: 1.9527654468372304

Epoch: 6| Step: 7
Training loss: 0.9837857484817505
Validation loss: 1.9333213413915327

Epoch: 6| Step: 8
Training loss: 0.5190542340278625
Validation loss: 1.9327499635757939

Epoch: 6| Step: 9
Training loss: 0.9951837658882141
Validation loss: 1.92298303240089

Epoch: 6| Step: 10
Training loss: 1.5376275777816772
Validation loss: 1.9460554276743243

Epoch: 6| Step: 11
Training loss: 1.2035311460494995
Validation loss: 1.9618020903679632

Epoch: 6| Step: 12
Training loss: 1.094070315361023
Validation loss: 1.9917630726291287

Epoch: 6| Step: 13
Training loss: 1.5584131479263306
Validation loss: 1.997231332204675

Epoch: 169| Step: 0
Training loss: 1.585683822631836
Validation loss: 2.0139485533519457

Epoch: 6| Step: 1
Training loss: 1.443160057067871
Validation loss: 2.0154855046221005

Epoch: 6| Step: 2
Training loss: 1.2978370189666748
Validation loss: 1.9912776498384372

Epoch: 6| Step: 3
Training loss: 1.4604947566986084
Validation loss: 2.0106297052034767

Epoch: 6| Step: 4
Training loss: 1.31291663646698
Validation loss: 1.9814632092752764

Epoch: 6| Step: 5
Training loss: 1.2490373849868774
Validation loss: 1.9776568637099317

Epoch: 6| Step: 6
Training loss: 0.8349305987358093
Validation loss: 1.9753484418315272

Epoch: 6| Step: 7
Training loss: 0.8511185050010681
Validation loss: 1.962881136966008

Epoch: 6| Step: 8
Training loss: 0.995453417301178
Validation loss: 1.9889975773390902

Epoch: 6| Step: 9
Training loss: 1.0612599849700928
Validation loss: 2.025942661428964

Epoch: 6| Step: 10
Training loss: 0.9593002796173096
Validation loss: 1.9883451795065274

Epoch: 6| Step: 11
Training loss: 0.7204210758209229
Validation loss: 1.9942209733429777

Epoch: 6| Step: 12
Training loss: 0.7452927231788635
Validation loss: 1.9876208305358887

Epoch: 6| Step: 13
Training loss: 1.824439525604248
Validation loss: 1.95918652062775

Epoch: 170| Step: 0
Training loss: 0.7368333339691162
Validation loss: 1.9700103549547092

Epoch: 6| Step: 1
Training loss: 0.8098037242889404
Validation loss: 1.955093461980102

Epoch: 6| Step: 2
Training loss: 1.6436161994934082
Validation loss: 1.9629787270740797

Epoch: 6| Step: 3
Training loss: 0.7935438752174377
Validation loss: 1.9640063547318982

Epoch: 6| Step: 4
Training loss: 1.246668815612793
Validation loss: 1.9680904624282674

Epoch: 6| Step: 5
Training loss: 1.390728235244751
Validation loss: 1.9918121804473221

Epoch: 6| Step: 6
Training loss: 0.9242743849754333
Validation loss: 2.0077953082258984

Epoch: 6| Step: 7
Training loss: 1.5479644536972046
Validation loss: 2.0227356059576875

Epoch: 6| Step: 8
Training loss: 0.7909402847290039
Validation loss: 2.0107360334806543

Epoch: 6| Step: 9
Training loss: 0.5246256589889526
Validation loss: 2.0058021622319377

Epoch: 6| Step: 10
Training loss: 1.7934437990188599
Validation loss: 1.9879528937801239

Epoch: 6| Step: 11
Training loss: 1.1583397388458252
Validation loss: 1.9712523670606716

Epoch: 6| Step: 12
Training loss: 1.2182124853134155
Validation loss: 1.9286458671733897

Epoch: 6| Step: 13
Training loss: 1.723183512687683
Validation loss: 1.9348830766575311

Epoch: 171| Step: 0
Training loss: 1.495462417602539
Validation loss: 1.9246477644930604

Epoch: 6| Step: 1
Training loss: 0.7622479200363159
Validation loss: 1.9129159770986086

Epoch: 6| Step: 2
Training loss: 1.025770664215088
Validation loss: 1.892143475753005

Epoch: 6| Step: 3
Training loss: 1.5751807689666748
Validation loss: 1.8935766784093713

Epoch: 6| Step: 4
Training loss: 1.2707555294036865
Validation loss: 1.869192369522587

Epoch: 6| Step: 5
Training loss: 0.9710389375686646
Validation loss: 1.9114632503960722

Epoch: 6| Step: 6
Training loss: 1.0173377990722656
Validation loss: 1.9361952786804528

Epoch: 6| Step: 7
Training loss: 0.9452180862426758
Validation loss: 1.9717537510779597

Epoch: 6| Step: 8
Training loss: 1.2551968097686768
Validation loss: 1.9686535609665738

Epoch: 6| Step: 9
Training loss: 1.533379316329956
Validation loss: 1.986673496102774

Epoch: 6| Step: 10
Training loss: 1.1658744812011719
Validation loss: 1.9771923736859394

Epoch: 6| Step: 11
Training loss: 1.1355491876602173
Validation loss: 1.9450116029349707

Epoch: 6| Step: 12
Training loss: 0.9511139392852783
Validation loss: 1.9433811736363236

Epoch: 6| Step: 13
Training loss: 1.4310071468353271
Validation loss: 1.967164010129949

Epoch: 172| Step: 0
Training loss: 1.2992784976959229
Validation loss: 1.9717583746038458

Epoch: 6| Step: 1
Training loss: 1.2345495223999023
Validation loss: 1.941184655312569

Epoch: 6| Step: 2
Training loss: 1.1051867008209229
Validation loss: 1.9394156009920183

Epoch: 6| Step: 3
Training loss: 1.0617625713348389
Validation loss: 1.9124839126422841

Epoch: 6| Step: 4
Training loss: 1.636406421661377
Validation loss: 1.9135078332757438

Epoch: 6| Step: 5
Training loss: 1.001868486404419
Validation loss: 1.9291972524376326

Epoch: 6| Step: 6
Training loss: 1.699075698852539
Validation loss: 1.9532221901801325

Epoch: 6| Step: 7
Training loss: 0.845474898815155
Validation loss: 1.9436696972898257

Epoch: 6| Step: 8
Training loss: 0.839728057384491
Validation loss: 1.9796030226574148

Epoch: 6| Step: 9
Training loss: 0.8298999071121216
Validation loss: 2.0139407906481015

Epoch: 6| Step: 10
Training loss: 1.3542288541793823
Validation loss: 2.0472144260201404

Epoch: 6| Step: 11
Training loss: 0.8949019908905029
Validation loss: 2.066760755354358

Epoch: 6| Step: 12
Training loss: 1.0282158851623535
Validation loss: 2.061143325221154

Epoch: 6| Step: 13
Training loss: 1.5173524618148804
Validation loss: 2.0182402800488215

Epoch: 173| Step: 0
Training loss: 1.5773218870162964
Validation loss: 2.0022376686014156

Epoch: 6| Step: 1
Training loss: 1.0334949493408203
Validation loss: 1.9694397398220596

Epoch: 6| Step: 2
Training loss: 0.7677987813949585
Validation loss: 1.9475074814211937

Epoch: 6| Step: 3
Training loss: 1.4879329204559326
Validation loss: 1.9125261960491058

Epoch: 6| Step: 4
Training loss: 0.8951117992401123
Validation loss: 1.9202441271915232

Epoch: 6| Step: 5
Training loss: 0.9589923024177551
Validation loss: 1.8982401535075197

Epoch: 6| Step: 6
Training loss: 1.0567409992218018
Validation loss: 1.900916516139943

Epoch: 6| Step: 7
Training loss: 1.0786851644515991
Validation loss: 1.9074083143664944

Epoch: 6| Step: 8
Training loss: 1.0242652893066406
Validation loss: 1.9314771019002444

Epoch: 6| Step: 9
Training loss: 1.3403972387313843
Validation loss: 1.9793209568146737

Epoch: 6| Step: 10
Training loss: 1.024282455444336
Validation loss: 2.0381252804110126

Epoch: 6| Step: 11
Training loss: 0.957320511341095
Validation loss: 2.0839555648065384

Epoch: 6| Step: 12
Training loss: 1.1435108184814453
Validation loss: 2.0511501912147767

Epoch: 6| Step: 13
Training loss: 1.595698595046997
Validation loss: 2.005156377310394

Epoch: 174| Step: 0
Training loss: 1.058901071548462
Validation loss: 1.975373229672832

Epoch: 6| Step: 1
Training loss: 1.3692041635513306
Validation loss: 1.977750378270303

Epoch: 6| Step: 2
Training loss: 1.2949011325836182
Validation loss: 1.9607915647568241

Epoch: 6| Step: 3
Training loss: 1.1109070777893066
Validation loss: 1.9401740438194686

Epoch: 6| Step: 4
Training loss: 0.8501002788543701
Validation loss: 1.941604506584906

Epoch: 6| Step: 5
Training loss: 1.1380568742752075
Validation loss: 1.9487195937864241

Epoch: 6| Step: 6
Training loss: 1.1944847106933594
Validation loss: 1.935976238660915

Epoch: 6| Step: 7
Training loss: 1.1277434825897217
Validation loss: 1.9350094615772206

Epoch: 6| Step: 8
Training loss: 0.9565846920013428
Validation loss: 1.9630897673227454

Epoch: 6| Step: 9
Training loss: 0.7256492972373962
Validation loss: 1.9890717357717536

Epoch: 6| Step: 10
Training loss: 0.6761755347251892
Validation loss: 2.0000171007648593

Epoch: 6| Step: 11
Training loss: 1.4562406539916992
Validation loss: 1.9912238890124905

Epoch: 6| Step: 12
Training loss: 0.8335316181182861
Validation loss: 2.000759187565055

Epoch: 6| Step: 13
Training loss: 1.210755467414856
Validation loss: 2.0145406864022695

Epoch: 175| Step: 0
Training loss: 1.0163122415542603
Validation loss: 2.0223524749919934

Epoch: 6| Step: 1
Training loss: 1.3891615867614746
Validation loss: 2.0423421116285425

Epoch: 6| Step: 2
Training loss: 1.2002849578857422
Validation loss: 2.0281533938582226

Epoch: 6| Step: 3
Training loss: 0.8096996545791626
Validation loss: 2.0222204372447026

Epoch: 6| Step: 4
Training loss: 1.0814807415008545
Validation loss: 1.9551060597101848

Epoch: 6| Step: 5
Training loss: 0.529484748840332
Validation loss: 1.9298581000297301

Epoch: 6| Step: 6
Training loss: 1.2025572061538696
Validation loss: 1.9002793835055443

Epoch: 6| Step: 7
Training loss: 1.3811436891555786
Validation loss: 1.9161077442989554

Epoch: 6| Step: 8
Training loss: 0.5914572477340698
Validation loss: 1.9272125010849328

Epoch: 6| Step: 9
Training loss: 0.7394018173217773
Validation loss: 1.9195323041690293

Epoch: 6| Step: 10
Training loss: 1.2769747972488403
Validation loss: 1.9151696479448708

Epoch: 6| Step: 11
Training loss: 1.0993794202804565
Validation loss: 1.8938062037191083

Epoch: 6| Step: 12
Training loss: 1.189213752746582
Validation loss: 1.907744731954349

Epoch: 6| Step: 13
Training loss: 1.7048914432525635
Validation loss: 1.896146156454599

Epoch: 176| Step: 0
Training loss: 1.201212763786316
Validation loss: 1.889749639777727

Epoch: 6| Step: 1
Training loss: 0.7661741375923157
Validation loss: 1.9122031170834777

Epoch: 6| Step: 2
Training loss: 1.5028356313705444
Validation loss: 1.9141951043118712

Epoch: 6| Step: 3
Training loss: 0.5984860062599182
Validation loss: 1.8916850410481936

Epoch: 6| Step: 4
Training loss: 0.7722532153129578
Validation loss: 1.9044721434193272

Epoch: 6| Step: 5
Training loss: 0.9418460726737976
Validation loss: 1.9190671008120301

Epoch: 6| Step: 6
Training loss: 1.0645694732666016
Validation loss: 1.9542119067202333

Epoch: 6| Step: 7
Training loss: 1.2035553455352783
Validation loss: 1.9906616518574376

Epoch: 6| Step: 8
Training loss: 0.7046632766723633
Validation loss: 1.9597599057741062

Epoch: 6| Step: 9
Training loss: 0.6023119688034058
Validation loss: 1.902200727052586

Epoch: 6| Step: 10
Training loss: 1.259718418121338
Validation loss: 1.8786107788803756

Epoch: 6| Step: 11
Training loss: 1.205916404724121
Validation loss: 1.8778362415170158

Epoch: 6| Step: 12
Training loss: 1.3928260803222656
Validation loss: 1.8826703409994803

Epoch: 6| Step: 13
Training loss: 1.646963119506836
Validation loss: 1.8989260465868059

Epoch: 177| Step: 0
Training loss: 0.9615893363952637
Validation loss: 1.8947660333366805

Epoch: 6| Step: 1
Training loss: 0.5451248288154602
Validation loss: 1.8932791063862462

Epoch: 6| Step: 2
Training loss: 0.8656550645828247
Validation loss: 1.890267595168083

Epoch: 6| Step: 3
Training loss: 1.2270331382751465
Validation loss: 1.9190263196986208

Epoch: 6| Step: 4
Training loss: 1.9305751323699951
Validation loss: 1.923610806465149

Epoch: 6| Step: 5
Training loss: 0.9308075904846191
Validation loss: 1.9525791778359363

Epoch: 6| Step: 6
Training loss: 1.4172980785369873
Validation loss: 1.963420582073991

Epoch: 6| Step: 7
Training loss: 0.8274236917495728
Validation loss: 1.9836944533932594

Epoch: 6| Step: 8
Training loss: 0.4471929371356964
Validation loss: 1.9377496370705225

Epoch: 6| Step: 9
Training loss: 1.152601718902588
Validation loss: 1.9328420662110852

Epoch: 6| Step: 10
Training loss: 1.030411720275879
Validation loss: 1.9373922232658631

Epoch: 6| Step: 11
Training loss: 0.9500470161437988
Validation loss: 1.9379346985970773

Epoch: 6| Step: 12
Training loss: 1.118897557258606
Validation loss: 1.9313585066026258

Epoch: 6| Step: 13
Training loss: 0.5977634191513062
Validation loss: 1.90843032252404

Epoch: 178| Step: 0
Training loss: 1.0659178495407104
Validation loss: 1.871239532706558

Epoch: 6| Step: 1
Training loss: 0.6285053491592407
Validation loss: 1.8633825138051023

Epoch: 6| Step: 2
Training loss: 1.247431993484497
Validation loss: 1.8358654591345018

Epoch: 6| Step: 3
Training loss: 1.6014667749404907
Validation loss: 1.8217969953372914

Epoch: 6| Step: 4
Training loss: 1.0029449462890625
Validation loss: 1.825114341192348

Epoch: 6| Step: 5
Training loss: 0.9766628742218018
Validation loss: 1.8398092100697179

Epoch: 6| Step: 6
Training loss: 0.571078896522522
Validation loss: 1.837679530984612

Epoch: 6| Step: 7
Training loss: 1.5471105575561523
Validation loss: 1.857554502384637

Epoch: 6| Step: 8
Training loss: 1.3902424573898315
Validation loss: 1.894431019342074

Epoch: 6| Step: 9
Training loss: 0.5908199548721313
Validation loss: 1.9332371296421174

Epoch: 6| Step: 10
Training loss: 1.0268688201904297
Validation loss: 1.944625594282663

Epoch: 6| Step: 11
Training loss: 0.6736167073249817
Validation loss: 1.9684374998974543

Epoch: 6| Step: 12
Training loss: 0.5168641805648804
Validation loss: 1.9800607158291725

Epoch: 6| Step: 13
Training loss: 1.197418212890625
Validation loss: 1.986788095966462

Epoch: 179| Step: 0
Training loss: 1.0939074754714966
Validation loss: 1.994208243585402

Epoch: 6| Step: 1
Training loss: 1.3456453084945679
Validation loss: 1.96809220826754

Epoch: 6| Step: 2
Training loss: 1.0115199089050293
Validation loss: 1.9523818057070497

Epoch: 6| Step: 3
Training loss: 1.4045367240905762
Validation loss: 1.925478958314465

Epoch: 6| Step: 4
Training loss: 1.0430598258972168
Validation loss: 1.9017394229929934

Epoch: 6| Step: 5
Training loss: 1.0985615253448486
Validation loss: 1.911359179404474

Epoch: 6| Step: 6
Training loss: 0.636699378490448
Validation loss: 1.9071380810071064

Epoch: 6| Step: 7
Training loss: 0.7095392942428589
Validation loss: 1.914716402689616

Epoch: 6| Step: 8
Training loss: 1.0639472007751465
Validation loss: 1.9435170735082319

Epoch: 6| Step: 9
Training loss: 0.7316502332687378
Validation loss: 1.9928710229935185

Epoch: 6| Step: 10
Training loss: 0.6251473426818848
Validation loss: 2.008551320722026

Epoch: 6| Step: 11
Training loss: 1.2621221542358398
Validation loss: 2.012911460732901

Epoch: 6| Step: 12
Training loss: 0.845401406288147
Validation loss: 1.9669578665046281

Epoch: 6| Step: 13
Training loss: 0.9680821895599365
Validation loss: 1.9358541786029775

Epoch: 180| Step: 0
Training loss: 0.7462596297264099
Validation loss: 1.9156575382396739

Epoch: 6| Step: 1
Training loss: 1.0511558055877686
Validation loss: 1.9549602129126107

Epoch: 6| Step: 2
Training loss: 0.8600938320159912
Validation loss: 1.9273578351543796

Epoch: 6| Step: 3
Training loss: 1.0280417203903198
Validation loss: 1.9284593764171805

Epoch: 6| Step: 4
Training loss: 1.304236650466919
Validation loss: 1.9580250734923987

Epoch: 6| Step: 5
Training loss: 0.8922891616821289
Validation loss: 1.9620757013238885

Epoch: 6| Step: 6
Training loss: 1.1056033372879028
Validation loss: 1.9842974473071355

Epoch: 6| Step: 7
Training loss: 1.1532446146011353
Validation loss: 2.0144697389295025

Epoch: 6| Step: 8
Training loss: 0.7418837547302246
Validation loss: 2.0039479194148893

Epoch: 6| Step: 9
Training loss: 1.3295066356658936
Validation loss: 1.9802128627736082

Epoch: 6| Step: 10
Training loss: 1.0161242485046387
Validation loss: 1.9691243710056427

Epoch: 6| Step: 11
Training loss: 0.9468501806259155
Validation loss: 1.9646777927234609

Epoch: 6| Step: 12
Training loss: 0.5637506246566772
Validation loss: 1.9734055496031238

Epoch: 6| Step: 13
Training loss: 1.2882353067398071
Validation loss: 2.013819674009918

Epoch: 181| Step: 0
Training loss: 1.0116218328475952
Validation loss: 2.071986970081124

Epoch: 6| Step: 1
Training loss: 1.732473373413086
Validation loss: 2.1205810116183375

Epoch: 6| Step: 2
Training loss: 0.7084543704986572
Validation loss: 2.060489603268203

Epoch: 6| Step: 3
Training loss: 0.4580102562904358
Validation loss: 1.98666412086897

Epoch: 6| Step: 4
Training loss: 1.163276195526123
Validation loss: 1.9317904710769653

Epoch: 6| Step: 5
Training loss: 1.028921365737915
Validation loss: 1.9506493076201408

Epoch: 6| Step: 6
Training loss: 1.1833724975585938
Validation loss: 1.9720013590269192

Epoch: 6| Step: 7
Training loss: 1.632750391960144
Validation loss: 1.9602170990359398

Epoch: 6| Step: 8
Training loss: 0.9787200689315796
Validation loss: 1.9308767664817073

Epoch: 6| Step: 9
Training loss: 1.296795129776001
Validation loss: 1.9453556345355125

Epoch: 6| Step: 10
Training loss: 1.1332447528839111
Validation loss: 1.9473459041246803

Epoch: 6| Step: 11
Training loss: 0.8870334029197693
Validation loss: 1.936268127092751

Epoch: 6| Step: 12
Training loss: 0.9579572677612305
Validation loss: 1.9238914853783065

Epoch: 6| Step: 13
Training loss: 1.2238515615463257
Validation loss: 1.9286894785460604

Epoch: 182| Step: 0
Training loss: 1.0136594772338867
Validation loss: 1.9546571482894242

Epoch: 6| Step: 1
Training loss: 1.0819143056869507
Validation loss: 1.9552359888630528

Epoch: 6| Step: 2
Training loss: 0.37740930914878845
Validation loss: 1.9525414320730394

Epoch: 6| Step: 3
Training loss: 1.3497450351715088
Validation loss: 1.9482190916615147

Epoch: 6| Step: 4
Training loss: 1.2265598773956299
Validation loss: 1.9548938889657297

Epoch: 6| Step: 5
Training loss: 0.815743088722229
Validation loss: 1.916403224391322

Epoch: 6| Step: 6
Training loss: 1.404118299484253
Validation loss: 1.897682733433221

Epoch: 6| Step: 7
Training loss: 0.7826244235038757
Validation loss: 1.859703322892548

Epoch: 6| Step: 8
Training loss: 0.7916339039802551
Validation loss: 1.887378070944099

Epoch: 6| Step: 9
Training loss: 1.3552498817443848
Validation loss: 1.868427618857353

Epoch: 6| Step: 10
Training loss: 0.9702107906341553
Validation loss: 1.8915529533099102

Epoch: 6| Step: 11
Training loss: 0.6863988637924194
Validation loss: 1.9097306305362332

Epoch: 6| Step: 12
Training loss: 0.867141842842102
Validation loss: 1.8774153647884246

Epoch: 6| Step: 13
Training loss: 0.49578291177749634
Validation loss: 1.896492470977127

Epoch: 183| Step: 0
Training loss: 1.1710593700408936
Validation loss: 1.8983557967729465

Epoch: 6| Step: 1
Training loss: 1.0989327430725098
Validation loss: 1.8970615492072156

Epoch: 6| Step: 2
Training loss: 1.110891342163086
Validation loss: 1.9201108627421881

Epoch: 6| Step: 3
Training loss: 0.9361616969108582
Validation loss: 1.9142326308834938

Epoch: 6| Step: 4
Training loss: 0.672863781452179
Validation loss: 1.9295830931714786

Epoch: 6| Step: 5
Training loss: 1.0000394582748413
Validation loss: 1.9090534871624363

Epoch: 6| Step: 6
Training loss: 1.1443989276885986
Validation loss: 1.9086047885238484

Epoch: 6| Step: 7
Training loss: 1.0542149543762207
Validation loss: 1.8935506510478195

Epoch: 6| Step: 8
Training loss: 1.1442464590072632
Validation loss: 1.8633002568316717

Epoch: 6| Step: 9
Training loss: 0.7927086353302002
Validation loss: 1.8623154278724425

Epoch: 6| Step: 10
Training loss: 0.8155980110168457
Validation loss: 1.896040738269847

Epoch: 6| Step: 11
Training loss: 0.6676040887832642
Validation loss: 1.8678316018914665

Epoch: 6| Step: 12
Training loss: 0.6037531495094299
Validation loss: 1.8873306115468342

Epoch: 6| Step: 13
Training loss: 0.5984465479850769
Validation loss: 1.922878014144077

Epoch: 184| Step: 0
Training loss: 0.6022793054580688
Validation loss: 1.93341185456963

Epoch: 6| Step: 1
Training loss: 0.8013663291931152
Validation loss: 1.9860460630027197

Epoch: 6| Step: 2
Training loss: 0.8225110173225403
Validation loss: 2.0207342575955134

Epoch: 6| Step: 3
Training loss: 0.5581614375114441
Validation loss: 2.0320104860490367

Epoch: 6| Step: 4
Training loss: 1.091587781906128
Validation loss: 2.024696796171127

Epoch: 6| Step: 5
Training loss: 0.8620737791061401
Validation loss: 2.0010771341221307

Epoch: 6| Step: 6
Training loss: 1.0592501163482666
Validation loss: 1.9880344918979111

Epoch: 6| Step: 7
Training loss: 1.070927381515503
Validation loss: 1.9611311125498947

Epoch: 6| Step: 8
Training loss: 1.1497124433517456
Validation loss: 1.9102503253567604

Epoch: 6| Step: 9
Training loss: 0.9711899161338806
Validation loss: 1.890842532598844

Epoch: 6| Step: 10
Training loss: 1.1073201894760132
Validation loss: 1.8524290451439478

Epoch: 6| Step: 11
Training loss: 1.6848399639129639
Validation loss: 1.8468575592963927

Epoch: 6| Step: 12
Training loss: 0.8147170543670654
Validation loss: 1.815848106979042

Epoch: 6| Step: 13
Training loss: 0.6405385136604309
Validation loss: 1.840860641130837

Epoch: 185| Step: 0
Training loss: 1.0084308385849
Validation loss: 1.8448277211958362

Epoch: 6| Step: 1
Training loss: 1.4140241146087646
Validation loss: 1.8674052146173292

Epoch: 6| Step: 2
Training loss: 0.8431185483932495
Validation loss: 1.8718834384795158

Epoch: 6| Step: 3
Training loss: 0.9087889194488525
Validation loss: 1.9279895303069905

Epoch: 6| Step: 4
Training loss: 0.9899758100509644
Validation loss: 1.9679792632338822

Epoch: 6| Step: 5
Training loss: 0.943488597869873
Validation loss: 2.0006009250558834

Epoch: 6| Step: 6
Training loss: 0.5600242614746094
Validation loss: 2.0254050121512464

Epoch: 6| Step: 7
Training loss: 1.4758474826812744
Validation loss: 2.005943964886409

Epoch: 6| Step: 8
Training loss: 0.6856817007064819
Validation loss: 2.000677973993363

Epoch: 6| Step: 9
Training loss: 0.8455474376678467
Validation loss: 1.9734514349250383

Epoch: 6| Step: 10
Training loss: 1.1361548900604248
Validation loss: 1.94119062987707

Epoch: 6| Step: 11
Training loss: 0.5192540884017944
Validation loss: 1.9209679595885738

Epoch: 6| Step: 12
Training loss: 0.8883572220802307
Validation loss: 1.918287556658509

Epoch: 6| Step: 13
Training loss: 0.6282666921615601
Validation loss: 1.9108525655602897

Epoch: 186| Step: 0
Training loss: 0.9701361656188965
Validation loss: 1.9143666323795114

Epoch: 6| Step: 1
Training loss: 1.57453453540802
Validation loss: 1.8909140043361212

Epoch: 6| Step: 2
Training loss: 0.8295075297355652
Validation loss: 1.869103882902412

Epoch: 6| Step: 3
Training loss: 0.9381494522094727
Validation loss: 1.8848133343522266

Epoch: 6| Step: 4
Training loss: 0.7676006555557251
Validation loss: 1.8852611049529044

Epoch: 6| Step: 5
Training loss: 1.3333700895309448
Validation loss: 1.8917150779436993

Epoch: 6| Step: 6
Training loss: 0.458551287651062
Validation loss: 1.8854722181955974

Epoch: 6| Step: 7
Training loss: 0.8663746118545532
Validation loss: 1.8713037083225865

Epoch: 6| Step: 8
Training loss: 1.3269073963165283
Validation loss: 1.8662578136690202

Epoch: 6| Step: 9
Training loss: 0.4516814649105072
Validation loss: 1.8887383245652722

Epoch: 6| Step: 10
Training loss: 1.297971248626709
Validation loss: 1.9116993155530704

Epoch: 6| Step: 11
Training loss: 0.5976760983467102
Validation loss: 1.9626136120929514

Epoch: 6| Step: 12
Training loss: 0.7124860882759094
Validation loss: 1.940012055058633

Epoch: 6| Step: 13
Training loss: 0.9731314182281494
Validation loss: 1.9432068332549064

Epoch: 187| Step: 0
Training loss: 0.6016360521316528
Validation loss: 1.9378104543173185

Epoch: 6| Step: 1
Training loss: 0.605915904045105
Validation loss: 1.956622305736747

Epoch: 6| Step: 2
Training loss: 0.9746760129928589
Validation loss: 1.9310132034363285

Epoch: 6| Step: 3
Training loss: 0.5521739721298218
Validation loss: 1.8838661024647374

Epoch: 6| Step: 4
Training loss: 1.4586844444274902
Validation loss: 1.887375036875407

Epoch: 6| Step: 5
Training loss: 1.096231460571289
Validation loss: 1.8898379559157996

Epoch: 6| Step: 6
Training loss: 0.5400874614715576
Validation loss: 1.9007579998303485

Epoch: 6| Step: 7
Training loss: 1.0701279640197754
Validation loss: 1.8945325177202943

Epoch: 6| Step: 8
Training loss: 1.2498031854629517
Validation loss: 1.8652429606324883

Epoch: 6| Step: 9
Training loss: 1.1919443607330322
Validation loss: 1.8617346696956183

Epoch: 6| Step: 10
Training loss: 1.0086601972579956
Validation loss: 1.8404357074409403

Epoch: 6| Step: 11
Training loss: 1.124659538269043
Validation loss: 1.8512319467400993

Epoch: 6| Step: 12
Training loss: 0.928405225276947
Validation loss: 1.8683962104141072

Epoch: 6| Step: 13
Training loss: 0.4426468014717102
Validation loss: 1.8808008496479323

Epoch: 188| Step: 0
Training loss: 0.7106653451919556
Validation loss: 1.9178655557734992

Epoch: 6| Step: 1
Training loss: 0.6186891794204712
Validation loss: 1.923215014960176

Epoch: 6| Step: 2
Training loss: 0.8486340045928955
Validation loss: 1.948893536803543

Epoch: 6| Step: 3
Training loss: 1.2074507474899292
Validation loss: 1.9501011384430753

Epoch: 6| Step: 4
Training loss: 1.1123425960540771
Validation loss: 1.9520349938382384

Epoch: 6| Step: 5
Training loss: 0.6716047525405884
Validation loss: 1.942064639060728

Epoch: 6| Step: 6
Training loss: 1.1598637104034424
Validation loss: 1.936473741326281

Epoch: 6| Step: 7
Training loss: 0.7390351891517639
Validation loss: 1.9179496137044763

Epoch: 6| Step: 8
Training loss: 0.7807247042655945
Validation loss: 1.8897262439932874

Epoch: 6| Step: 9
Training loss: 1.178589105606079
Validation loss: 1.872423025869554

Epoch: 6| Step: 10
Training loss: 0.6302344799041748
Validation loss: 1.8553935417564966

Epoch: 6| Step: 11
Training loss: 0.7007861733436584
Validation loss: 1.8504902829406082

Epoch: 6| Step: 12
Training loss: 1.314476728439331
Validation loss: 1.8505597306836037

Epoch: 6| Step: 13
Training loss: 1.2114412784576416
Validation loss: 1.8440458377202351

Epoch: 189| Step: 0
Training loss: 0.9427024722099304
Validation loss: 1.8775634611806562

Epoch: 6| Step: 1
Training loss: 1.1816165447235107
Validation loss: 1.8807024955749512

Epoch: 6| Step: 2
Training loss: 1.0806970596313477
Validation loss: 1.899380422407581

Epoch: 6| Step: 3
Training loss: 0.4753021001815796
Validation loss: 1.9018368387735018

Epoch: 6| Step: 4
Training loss: 1.013517141342163
Validation loss: 1.8839052338753977

Epoch: 6| Step: 5
Training loss: 1.1980817317962646
Validation loss: 1.890451910675213

Epoch: 6| Step: 6
Training loss: 1.0233076810836792
Validation loss: 1.9173951866806194

Epoch: 6| Step: 7
Training loss: 0.8685852289199829
Validation loss: 1.93868379182713

Epoch: 6| Step: 8
Training loss: 1.012528896331787
Validation loss: 1.9560117131920272

Epoch: 6| Step: 9
Training loss: 0.7248384952545166
Validation loss: 1.9366432261723343

Epoch: 6| Step: 10
Training loss: 0.6846829056739807
Validation loss: 1.9302200399419314

Epoch: 6| Step: 11
Training loss: 0.5267348289489746
Validation loss: 1.9143870748499388

Epoch: 6| Step: 12
Training loss: 1.0501166582107544
Validation loss: 1.904825682281166

Epoch: 6| Step: 13
Training loss: 0.965373694896698
Validation loss: 1.8841459084582586

Epoch: 190| Step: 0
Training loss: 1.3932645320892334
Validation loss: 1.8704047408155215

Epoch: 6| Step: 1
Training loss: 0.8776031732559204
Validation loss: 1.887471523336185

Epoch: 6| Step: 2
Training loss: 1.1002368927001953
Validation loss: 1.901679882439234

Epoch: 6| Step: 3
Training loss: 0.90538489818573
Validation loss: 1.9126746064873152

Epoch: 6| Step: 4
Training loss: 0.5307850241661072
Validation loss: 1.9041442678820701

Epoch: 6| Step: 5
Training loss: 0.6803263425827026
Validation loss: 1.925688212917697

Epoch: 6| Step: 6
Training loss: 0.3450528681278229
Validation loss: 1.9343690513282694

Epoch: 6| Step: 7
Training loss: 0.8561059236526489
Validation loss: 1.9677921136220295

Epoch: 6| Step: 8
Training loss: 1.0540521144866943
Validation loss: 2.0147326787312827

Epoch: 6| Step: 9
Training loss: 1.154590368270874
Validation loss: 1.9926274399603567

Epoch: 6| Step: 10
Training loss: 0.8009077906608582
Validation loss: 1.9800036978977982

Epoch: 6| Step: 11
Training loss: 0.859526515007019
Validation loss: 1.9365217967699933

Epoch: 6| Step: 12
Training loss: 0.7629472017288208
Validation loss: 1.8790923754374187

Epoch: 6| Step: 13
Training loss: 0.6797173023223877
Validation loss: 1.882002522868495

Epoch: 191| Step: 0
Training loss: 1.009921908378601
Validation loss: 1.8449278608445199

Epoch: 6| Step: 1
Training loss: 1.1615700721740723
Validation loss: 1.847026401950467

Epoch: 6| Step: 2
Training loss: 0.5663679242134094
Validation loss: 1.8507541328348138

Epoch: 6| Step: 3
Training loss: 0.5591491460800171
Validation loss: 1.847158783225603

Epoch: 6| Step: 4
Training loss: 1.0118831396102905
Validation loss: 1.8469797488181823

Epoch: 6| Step: 5
Training loss: 1.0043768882751465
Validation loss: 1.8533145073921449

Epoch: 6| Step: 6
Training loss: 1.0078949928283691
Validation loss: 1.8401022393216369

Epoch: 6| Step: 7
Training loss: 1.3233349323272705
Validation loss: 1.8594959038560108

Epoch: 6| Step: 8
Training loss: 0.8497933149337769
Validation loss: 1.8892372115965812

Epoch: 6| Step: 9
Training loss: 0.5351231098175049
Validation loss: 1.891951883992841

Epoch: 6| Step: 10
Training loss: 0.8735349178314209
Validation loss: 1.8791993702611616

Epoch: 6| Step: 11
Training loss: 0.9523458480834961
Validation loss: 1.9046577792013846

Epoch: 6| Step: 12
Training loss: 0.5522475242614746
Validation loss: 1.9224117596944172

Epoch: 6| Step: 13
Training loss: 0.42338255047798157
Validation loss: 1.9351471649703158

Epoch: 192| Step: 0
Training loss: 0.9275730848312378
Validation loss: 1.8764019179087814

Epoch: 6| Step: 1
Training loss: 0.7561924457550049
Validation loss: 1.8921700959564538

Epoch: 6| Step: 2
Training loss: 1.1591289043426514
Validation loss: 1.906549794699556

Epoch: 6| Step: 3
Training loss: 0.5922673344612122
Validation loss: 1.890491859887236

Epoch: 6| Step: 4
Training loss: 0.6853606700897217
Validation loss: 1.8753014982387584

Epoch: 6| Step: 5
Training loss: 0.412443608045578
Validation loss: 1.9266457724314865

Epoch: 6| Step: 6
Training loss: 1.1224188804626465
Validation loss: 1.886375638746446

Epoch: 6| Step: 7
Training loss: 0.7078537940979004
Validation loss: 1.888324668330531

Epoch: 6| Step: 8
Training loss: 1.549015760421753
Validation loss: 1.8880967427325506

Epoch: 6| Step: 9
Training loss: 1.0749478340148926
Validation loss: 1.8955455121173654

Epoch: 6| Step: 10
Training loss: 0.434267520904541
Validation loss: 1.9078957009059128

Epoch: 6| Step: 11
Training loss: 0.8326993584632874
Validation loss: 1.9331030050913494

Epoch: 6| Step: 12
Training loss: 0.6703032851219177
Validation loss: 1.9661034332808627

Epoch: 6| Step: 13
Training loss: 0.8270070552825928
Validation loss: 1.998120471995364

Epoch: 193| Step: 0
Training loss: 0.6341776847839355
Validation loss: 1.9904031702267226

Epoch: 6| Step: 1
Training loss: 0.6927233934402466
Validation loss: 2.0038381161228305

Epoch: 6| Step: 2
Training loss: 0.5808840990066528
Validation loss: 1.9824456784033007

Epoch: 6| Step: 3
Training loss: 0.7949538826942444
Validation loss: 1.9493518183308263

Epoch: 6| Step: 4
Training loss: 1.0910608768463135
Validation loss: 1.923135906137446

Epoch: 6| Step: 5
Training loss: 1.0819356441497803
Validation loss: 1.916555041907936

Epoch: 6| Step: 6
Training loss: 0.8727442026138306
Validation loss: 1.893133658234791

Epoch: 6| Step: 7
Training loss: 0.7992280125617981
Validation loss: 1.857931492149189

Epoch: 6| Step: 8
Training loss: 1.004744529724121
Validation loss: 1.8468457139948362

Epoch: 6| Step: 9
Training loss: 0.9071674346923828
Validation loss: 1.8607638112960323

Epoch: 6| Step: 10
Training loss: 0.9360755681991577
Validation loss: 1.8797753075117707

Epoch: 6| Step: 11
Training loss: 0.6826217770576477
Validation loss: 1.8737017557185183

Epoch: 6| Step: 12
Training loss: 0.6525319218635559
Validation loss: 1.8798633301129906

Epoch: 6| Step: 13
Training loss: 0.7030462622642517
Validation loss: 1.9184324100453367

Epoch: 194| Step: 0
Training loss: 0.7741167545318604
Validation loss: 1.9037890754720217

Epoch: 6| Step: 1
Training loss: 1.0742908716201782
Validation loss: 1.9183560366271644

Epoch: 6| Step: 2
Training loss: 1.2325632572174072
Validation loss: 1.9526482910238288

Epoch: 6| Step: 3
Training loss: 0.6291859149932861
Validation loss: 1.9203967355912732

Epoch: 6| Step: 4
Training loss: 0.4898379445075989
Validation loss: 1.9204543944328063

Epoch: 6| Step: 5
Training loss: 0.8183211088180542
Validation loss: 1.9063497525389477

Epoch: 6| Step: 6
Training loss: 1.2563049793243408
Validation loss: 1.886159235431302

Epoch: 6| Step: 7
Training loss: 0.8230605721473694
Validation loss: 1.896310705010609

Epoch: 6| Step: 8
Training loss: 0.5971593260765076
Validation loss: 1.9087412562421573

Epoch: 6| Step: 9
Training loss: 0.47567978501319885
Validation loss: 1.8734264783961798

Epoch: 6| Step: 10
Training loss: 0.437129408121109
Validation loss: 1.8654323188207482

Epoch: 6| Step: 11
Training loss: 0.9548685550689697
Validation loss: 1.870665645086637

Epoch: 6| Step: 12
Training loss: 1.0936546325683594
Validation loss: 1.856460778943954

Epoch: 6| Step: 13
Training loss: 0.6914911866188049
Validation loss: 1.838327851346744

Epoch: 195| Step: 0
Training loss: 0.6056012511253357
Validation loss: 1.8535917100086008

Epoch: 6| Step: 1
Training loss: 0.6515141725540161
Validation loss: 1.8533612566609536

Epoch: 6| Step: 2
Training loss: 0.8499208688735962
Validation loss: 1.8536528207922494

Epoch: 6| Step: 3
Training loss: 0.7861008644104004
Validation loss: 1.8574054958999797

Epoch: 6| Step: 4
Training loss: 0.6458382606506348
Validation loss: 1.8679141793199765

Epoch: 6| Step: 5
Training loss: 0.6473850011825562
Validation loss: 1.8997168874227872

Epoch: 6| Step: 6
Training loss: 0.6442524194717407
Validation loss: 1.916207072555378

Epoch: 6| Step: 7
Training loss: 0.8862707018852234
Validation loss: 1.8628389963539698

Epoch: 6| Step: 8
Training loss: 0.816532552242279
Validation loss: 1.858346011049004

Epoch: 6| Step: 9
Training loss: 1.1314258575439453
Validation loss: 1.8512389300971903

Epoch: 6| Step: 10
Training loss: 0.7202388048171997
Validation loss: 1.8308394012912628

Epoch: 6| Step: 11
Training loss: 1.0129411220550537
Validation loss: 1.8235760760563675

Epoch: 6| Step: 12
Training loss: 0.8604297637939453
Validation loss: 1.8355278353537283

Epoch: 6| Step: 13
Training loss: 0.6948924660682678
Validation loss: 1.8582652486780638

Epoch: 196| Step: 0
Training loss: 0.7365320324897766
Validation loss: 1.8484834214692474

Epoch: 6| Step: 1
Training loss: 0.5976226329803467
Validation loss: 1.8595863849886003

Epoch: 6| Step: 2
Training loss: 0.6486417055130005
Validation loss: 1.8763453370781356

Epoch: 6| Step: 3
Training loss: 0.8142898082733154
Validation loss: 1.8913742470484909

Epoch: 6| Step: 4
Training loss: 0.7176961898803711
Validation loss: 1.9078245893601449

Epoch: 6| Step: 5
Training loss: 0.461708128452301
Validation loss: 1.929704834056157

Epoch: 6| Step: 6
Training loss: 0.6324009895324707
Validation loss: 1.8942984586120934

Epoch: 6| Step: 7
Training loss: 0.6346099376678467
Validation loss: 1.851854319213539

Epoch: 6| Step: 8
Training loss: 0.9159918427467346
Validation loss: 1.844053558124009

Epoch: 6| Step: 9
Training loss: 0.9817966818809509
Validation loss: 1.8601724332378757

Epoch: 6| Step: 10
Training loss: 0.7728263139724731
Validation loss: 1.8725564582373506

Epoch: 6| Step: 11
Training loss: 1.0683412551879883
Validation loss: 1.8304619942941973

Epoch: 6| Step: 12
Training loss: 0.9536011219024658
Validation loss: 1.836896527198053

Epoch: 6| Step: 13
Training loss: 0.7626869082450867
Validation loss: 1.83480030234142

Epoch: 197| Step: 0
Training loss: 0.7378952503204346
Validation loss: 1.8134819974181473

Epoch: 6| Step: 1
Training loss: 1.3109064102172852
Validation loss: 1.8665265947259881

Epoch: 6| Step: 2
Training loss: 0.5238909721374512
Validation loss: 1.8929397906026533

Epoch: 6| Step: 3
Training loss: 0.6372369527816772
Validation loss: 1.8940742990022064

Epoch: 6| Step: 4
Training loss: 0.8462957739830017
Validation loss: 1.9010883197989514

Epoch: 6| Step: 5
Training loss: 0.9307399392127991
Validation loss: 1.914533845839962

Epoch: 6| Step: 6
Training loss: 0.8348540663719177
Validation loss: 1.8567302688475578

Epoch: 6| Step: 7
Training loss: 0.794904351234436
Validation loss: 1.8250830711856965

Epoch: 6| Step: 8
Training loss: 0.8404468297958374
Validation loss: 1.8253565513959495

Epoch: 6| Step: 9
Training loss: 0.7398777008056641
Validation loss: 1.8223226275495303

Epoch: 6| Step: 10
Training loss: 0.6507725715637207
Validation loss: 1.8365870457823559

Epoch: 6| Step: 11
Training loss: 0.6054105758666992
Validation loss: 1.8261736157119914

Epoch: 6| Step: 12
Training loss: 0.4017869532108307
Validation loss: 1.8186058382834158

Epoch: 6| Step: 13
Training loss: 1.3403822183609009
Validation loss: 1.8316571917585147

Epoch: 198| Step: 0
Training loss: 0.6293855309486389
Validation loss: 1.8385486448964765

Epoch: 6| Step: 1
Training loss: 0.4407140910625458
Validation loss: 1.843768419757966

Epoch: 6| Step: 2
Training loss: 0.36886945366859436
Validation loss: 1.8549732546652518

Epoch: 6| Step: 3
Training loss: 1.1116572618484497
Validation loss: 1.8880379071799658

Epoch: 6| Step: 4
Training loss: 0.7263610363006592
Validation loss: 1.910163297448107

Epoch: 6| Step: 5
Training loss: 1.37845778465271
Validation loss: 1.9474233747810445

Epoch: 6| Step: 6
Training loss: 0.8359681367874146
Validation loss: 1.9412718613942463

Epoch: 6| Step: 7
Training loss: 0.8404132723808289
Validation loss: 1.9388705261291996

Epoch: 6| Step: 8
Training loss: 0.7361449003219604
Validation loss: 1.9421226311755437

Epoch: 6| Step: 9
Training loss: 0.4976505637168884
Validation loss: 1.9184112702646563

Epoch: 6| Step: 10
Training loss: 1.083430528640747
Validation loss: 1.8971630604036394

Epoch: 6| Step: 11
Training loss: 0.5563819408416748
Validation loss: 1.8922345356274677

Epoch: 6| Step: 12
Training loss: 0.43953344225883484
Validation loss: 1.8764825200521817

Epoch: 6| Step: 13
Training loss: 1.09934401512146
Validation loss: 1.8345005883965442

Epoch: 199| Step: 0
Training loss: 0.6080525517463684
Validation loss: 1.841309698679114

Epoch: 6| Step: 1
Training loss: 0.810836136341095
Validation loss: 1.8316368108154626

Epoch: 6| Step: 2
Training loss: 0.24681466817855835
Validation loss: 1.8444454464861142

Epoch: 6| Step: 3
Training loss: 0.914768397808075
Validation loss: 1.8512754671035274

Epoch: 6| Step: 4
Training loss: 0.4474979639053345
Validation loss: 1.8661830809808546

Epoch: 6| Step: 5
Training loss: 0.8015714883804321
Validation loss: 1.8759024643128919

Epoch: 6| Step: 6
Training loss: 1.4240607023239136
Validation loss: 1.8787237367322367

Epoch: 6| Step: 7
Training loss: 0.7707026600837708
Validation loss: 1.9045668596862464

Epoch: 6| Step: 8
Training loss: 0.7783340215682983
Validation loss: 1.9171612493453487

Epoch: 6| Step: 9
Training loss: 0.8487746119499207
Validation loss: 1.8961897216817385

Epoch: 6| Step: 10
Training loss: 0.7087909579277039
Validation loss: 1.8877217359440301

Epoch: 6| Step: 11
Training loss: 0.8330080509185791
Validation loss: 1.8552211946056736

Epoch: 6| Step: 12
Training loss: 0.6609973311424255
Validation loss: 1.8791934110785042

Epoch: 6| Step: 13
Training loss: 0.31563571095466614
Validation loss: 1.856623072778025

Epoch: 200| Step: 0
Training loss: 0.7339702844619751
Validation loss: 1.8559168538739603

Epoch: 6| Step: 1
Training loss: 0.7039933800697327
Validation loss: 1.8557711711493872

Epoch: 6| Step: 2
Training loss: 0.34650367498397827
Validation loss: 1.8657161240936608

Epoch: 6| Step: 3
Training loss: 1.150099754333496
Validation loss: 1.8258716290996921

Epoch: 6| Step: 4
Training loss: 0.7081762552261353
Validation loss: 1.8250163755109232

Epoch: 6| Step: 5
Training loss: 0.930976390838623
Validation loss: 1.8325615595745783

Epoch: 6| Step: 6
Training loss: 1.0522568225860596
Validation loss: 1.8179177263731598

Epoch: 6| Step: 7
Training loss: 0.6235603094100952
Validation loss: 1.8052459109214045

Epoch: 6| Step: 8
Training loss: 0.33835023641586304
Validation loss: 1.835056527968376

Epoch: 6| Step: 9
Training loss: 0.7449149489402771
Validation loss: 1.8631144390311292

Epoch: 6| Step: 10
Training loss: 1.0787146091461182
Validation loss: 1.8567859203584733

Epoch: 6| Step: 11
Training loss: 0.7758604884147644
Validation loss: 1.8933737457439463

Epoch: 6| Step: 12
Training loss: 0.5655244588851929
Validation loss: 1.8688262252397434

Epoch: 6| Step: 13
Training loss: 0.6319876909255981
Validation loss: 1.8839160921753093

Epoch: 201| Step: 0
Training loss: 0.5922234058380127
Validation loss: 1.8972791253879506

Epoch: 6| Step: 1
Training loss: 0.8102974891662598
Validation loss: 1.898959013723558

Epoch: 6| Step: 2
Training loss: 0.6497780084609985
Validation loss: 1.9096180251849595

Epoch: 6| Step: 3
Training loss: 0.8168944120407104
Validation loss: 1.9306844998431463

Epoch: 6| Step: 4
Training loss: 0.43815046548843384
Validation loss: 1.9235178386011431

Epoch: 6| Step: 5
Training loss: 0.6116185784339905
Validation loss: 1.905214855747838

Epoch: 6| Step: 6
Training loss: 0.7365590333938599
Validation loss: 1.8631479663233603

Epoch: 6| Step: 7
Training loss: 0.49890342354774475
Validation loss: 1.8568561512936828

Epoch: 6| Step: 8
Training loss: 0.4341036379337311
Validation loss: 1.8278573418176303

Epoch: 6| Step: 9
Training loss: 1.2606054544448853
Validation loss: 1.8437639397959555

Epoch: 6| Step: 10
Training loss: 1.0588901042938232
Validation loss: 1.8668545561452066

Epoch: 6| Step: 11
Training loss: 0.6367290019989014
Validation loss: 1.8768896556669665

Epoch: 6| Step: 12
Training loss: 0.8439571261405945
Validation loss: 1.9115133541886524

Epoch: 6| Step: 13
Training loss: 0.8911370038986206
Validation loss: 1.896558956433368

Epoch: 202| Step: 0
Training loss: 0.888225793838501
Validation loss: 1.8904486766425512

Epoch: 6| Step: 1
Training loss: 0.4736648201942444
Validation loss: 1.8508118506400817

Epoch: 6| Step: 2
Training loss: 0.8889420032501221
Validation loss: 1.8404079021946076

Epoch: 6| Step: 3
Training loss: 0.5126426219940186
Validation loss: 1.8266222310322586

Epoch: 6| Step: 4
Training loss: 0.5524321794509888
Validation loss: 1.8278008096961564

Epoch: 6| Step: 5
Training loss: 0.6985036134719849
Validation loss: 1.8607580597682665

Epoch: 6| Step: 6
Training loss: 0.8305442333221436
Validation loss: 1.8624693475743777

Epoch: 6| Step: 7
Training loss: 0.639228105545044
Validation loss: 1.8641001716736825

Epoch: 6| Step: 8
Training loss: 1.0210843086242676
Validation loss: 1.8912703555117372

Epoch: 6| Step: 9
Training loss: 0.6514930725097656
Validation loss: 1.8828121500630532

Epoch: 6| Step: 10
Training loss: 0.651266872882843
Validation loss: 1.856045566579347

Epoch: 6| Step: 11
Training loss: 0.543475329875946
Validation loss: 1.8499188320611113

Epoch: 6| Step: 12
Training loss: 0.7895838022232056
Validation loss: 1.8389932442736883

Epoch: 6| Step: 13
Training loss: 0.9247275590896606
Validation loss: 1.8444317861269879

Epoch: 203| Step: 0
Training loss: 0.9664958119392395
Validation loss: 1.841113087951496

Epoch: 6| Step: 1
Training loss: 0.806881308555603
Validation loss: 1.8645040245466336

Epoch: 6| Step: 2
Training loss: 0.7334004640579224
Validation loss: 1.8602929410114084

Epoch: 6| Step: 3
Training loss: 0.5060514807701111
Validation loss: 1.847173595941195

Epoch: 6| Step: 4
Training loss: 0.5380920767784119
Validation loss: 1.8361470212218582

Epoch: 6| Step: 5
Training loss: 0.8811799883842468
Validation loss: 1.8193187264985935

Epoch: 6| Step: 6
Training loss: 0.45256316661834717
Validation loss: 1.7913297376325052

Epoch: 6| Step: 7
Training loss: 0.5378265380859375
Validation loss: 1.7975707925775999

Epoch: 6| Step: 8
Training loss: 1.3839011192321777
Validation loss: 1.7961506446202595

Epoch: 6| Step: 9
Training loss: 0.6951369643211365
Validation loss: 1.8192329176010624

Epoch: 6| Step: 10
Training loss: 0.5814589262008667
Validation loss: 1.8288879625258907

Epoch: 6| Step: 11
Training loss: 0.48259133100509644
Validation loss: 1.8344609660487021

Epoch: 6| Step: 12
Training loss: 0.3283601999282837
Validation loss: 1.8422571330942132

Epoch: 6| Step: 13
Training loss: 0.8323538303375244
Validation loss: 1.8530660598508772

Epoch: 204| Step: 0
Training loss: 0.8026878237724304
Validation loss: 1.8946931900516633

Epoch: 6| Step: 1
Training loss: 0.7335100173950195
Validation loss: 1.8762679023127402

Epoch: 6| Step: 2
Training loss: 0.3353942036628723
Validation loss: 1.8688329573600524

Epoch: 6| Step: 3
Training loss: 0.7149996757507324
Validation loss: 1.8964205147117696

Epoch: 6| Step: 4
Training loss: 1.186258316040039
Validation loss: 1.899064451135615

Epoch: 6| Step: 5
Training loss: 0.7752118110656738
Validation loss: 1.8919822528798094

Epoch: 6| Step: 6
Training loss: 0.5662179589271545
Validation loss: 1.845599594936576

Epoch: 6| Step: 7
Training loss: 0.6586761474609375
Validation loss: 1.8641884493571457

Epoch: 6| Step: 8
Training loss: 0.888141393661499
Validation loss: 1.8581614673778575

Epoch: 6| Step: 9
Training loss: 0.9231668710708618
Validation loss: 1.8511739469343615

Epoch: 6| Step: 10
Training loss: 0.5371606945991516
Validation loss: 1.8358146041952155

Epoch: 6| Step: 11
Training loss: 0.4128631353378296
Validation loss: 1.8308203258822042

Epoch: 6| Step: 12
Training loss: 0.591739296913147
Validation loss: 1.8098471459522043

Epoch: 6| Step: 13
Training loss: 0.6072115898132324
Validation loss: 1.8227882808254612

Epoch: 205| Step: 0
Training loss: 0.6687948703765869
Validation loss: 1.8540718863087315

Epoch: 6| Step: 1
Training loss: 0.2975098788738251
Validation loss: 1.8423527773990427

Epoch: 6| Step: 2
Training loss: 0.43638455867767334
Validation loss: 1.8463607693231234

Epoch: 6| Step: 3
Training loss: 0.7089842557907104
Validation loss: 1.828658611543717

Epoch: 6| Step: 4
Training loss: 0.8557910323143005
Validation loss: 1.8365904797789872

Epoch: 6| Step: 5
Training loss: 0.6369836330413818
Validation loss: 1.8117240744252359

Epoch: 6| Step: 6
Training loss: 0.6884016394615173
Validation loss: 1.8258590570060156

Epoch: 6| Step: 7
Training loss: 0.9764196872711182
Validation loss: 1.8174207697632492

Epoch: 6| Step: 8
Training loss: 0.5553970336914062
Validation loss: 1.8262133470145605

Epoch: 6| Step: 9
Training loss: 0.7459571361541748
Validation loss: 1.8321975392680014

Epoch: 6| Step: 10
Training loss: 0.6997144222259521
Validation loss: 1.8317550382306498

Epoch: 6| Step: 11
Training loss: 0.7195332050323486
Validation loss: 1.845021709319084

Epoch: 6| Step: 12
Training loss: 0.6160074472427368
Validation loss: 1.8362052004824403

Epoch: 6| Step: 13
Training loss: 0.6045176982879639
Validation loss: 1.8374457602859826

Epoch: 206| Step: 0
Training loss: 0.530540943145752
Validation loss: 1.8655682609927269

Epoch: 6| Step: 1
Training loss: 0.44326239824295044
Validation loss: 1.8814616113580682

Epoch: 6| Step: 2
Training loss: 0.740567147731781
Validation loss: 1.8761685586744739

Epoch: 6| Step: 3
Training loss: 0.8355490565299988
Validation loss: 1.919884809883692

Epoch: 6| Step: 4
Training loss: 0.231405571103096
Validation loss: 1.8663462310708978

Epoch: 6| Step: 5
Training loss: 1.0472619533538818
Validation loss: 1.8420911604358303

Epoch: 6| Step: 6
Training loss: 0.8961622714996338
Validation loss: 1.8249644643516951

Epoch: 6| Step: 7
Training loss: 0.5237087607383728
Validation loss: 1.8115195010298042

Epoch: 6| Step: 8
Training loss: 0.9227137565612793
Validation loss: 1.7689899347161735

Epoch: 6| Step: 9
Training loss: 0.6380321383476257
Validation loss: 1.7858851641737006

Epoch: 6| Step: 10
Training loss: 0.7484170198440552
Validation loss: 1.7625306524256223

Epoch: 6| Step: 11
Training loss: 0.5905210971832275
Validation loss: 1.7923911771466654

Epoch: 6| Step: 12
Training loss: 0.4681730568408966
Validation loss: 1.787914785005713

Epoch: 6| Step: 13
Training loss: 0.5421393513679504
Validation loss: 1.8059887527137675

Epoch: 207| Step: 0
Training loss: 0.5997764468193054
Validation loss: 1.8361478902960335

Epoch: 6| Step: 1
Training loss: 0.6471414566040039
Validation loss: 1.8468443219379713

Epoch: 6| Step: 2
Training loss: 0.5887988805770874
Validation loss: 1.8469528536642752

Epoch: 6| Step: 3
Training loss: 0.647148072719574
Validation loss: 1.8564076449281426

Epoch: 6| Step: 4
Training loss: 0.48310646414756775
Validation loss: 1.8301474894246748

Epoch: 6| Step: 5
Training loss: 0.6771482825279236
Validation loss: 1.8372776815968175

Epoch: 6| Step: 6
Training loss: 0.609130859375
Validation loss: 1.8060347521176903

Epoch: 6| Step: 7
Training loss: 0.839530348777771
Validation loss: 1.7895781801592918

Epoch: 6| Step: 8
Training loss: 0.636602520942688
Validation loss: 1.807951150401946

Epoch: 6| Step: 9
Training loss: 0.4902324676513672
Validation loss: 1.791060842493529

Epoch: 6| Step: 10
Training loss: 0.4100022315979004
Validation loss: 1.7938550133858957

Epoch: 6| Step: 11
Training loss: 0.9882230162620544
Validation loss: 1.7988654862168014

Epoch: 6| Step: 12
Training loss: 0.4852815568447113
Validation loss: 1.8222090890330653

Epoch: 6| Step: 13
Training loss: 1.1605868339538574
Validation loss: 1.7932134264258928

Epoch: 208| Step: 0
Training loss: 0.8035658597946167
Validation loss: 1.797931953143048

Epoch: 6| Step: 1
Training loss: 0.6034502387046814
Validation loss: 1.7852461876407746

Epoch: 6| Step: 2
Training loss: 0.6174319982528687
Validation loss: 1.8078386757963447

Epoch: 6| Step: 3
Training loss: 1.0930757522583008
Validation loss: 1.785535430395475

Epoch: 6| Step: 4
Training loss: 0.08824962377548218
Validation loss: 1.79318529816084

Epoch: 6| Step: 5
Training loss: 0.553856611251831
Validation loss: 1.8236362985385361

Epoch: 6| Step: 6
Training loss: 0.659142255783081
Validation loss: 1.8401372381435928

Epoch: 6| Step: 7
Training loss: 0.593541145324707
Validation loss: 1.8579874551424416

Epoch: 6| Step: 8
Training loss: 0.9130634069442749
Validation loss: 1.85328766094741

Epoch: 6| Step: 9
Training loss: 0.609228253364563
Validation loss: 1.8844017674846034

Epoch: 6| Step: 10
Training loss: 0.5232967734336853
Validation loss: 1.8458649291787097

Epoch: 6| Step: 11
Training loss: 0.6366305351257324
Validation loss: 1.8192567389498475

Epoch: 6| Step: 12
Training loss: 0.624323308467865
Validation loss: 1.7762946057063278

Epoch: 6| Step: 13
Training loss: 0.47628477215766907
Validation loss: 1.7893321591038858

Epoch: 209| Step: 0
Training loss: 0.5631991624832153
Validation loss: 1.7949774137107275

Epoch: 6| Step: 1
Training loss: 0.6326771974563599
Validation loss: 1.7897495813267206

Epoch: 6| Step: 2
Training loss: 0.8665646314620972
Validation loss: 1.804489863816128

Epoch: 6| Step: 3
Training loss: 0.5647633671760559
Validation loss: 1.7970484149071477

Epoch: 6| Step: 4
Training loss: 1.0664231777191162
Validation loss: 1.8150770651396884

Epoch: 6| Step: 5
Training loss: 0.41410499811172485
Validation loss: 1.826125721777639

Epoch: 6| Step: 6
Training loss: 0.49183109402656555
Validation loss: 1.8315733017459992

Epoch: 6| Step: 7
Training loss: 0.4125339984893799
Validation loss: 1.8758316373312345

Epoch: 6| Step: 8
Training loss: 0.5792745351791382
Validation loss: 1.881840185452533

Epoch: 6| Step: 9
Training loss: 0.9430363178253174
Validation loss: 1.8994940878242574

Epoch: 6| Step: 10
Training loss: 0.5813999772071838
Validation loss: 1.893268140413428

Epoch: 6| Step: 11
Training loss: 0.4536404013633728
Validation loss: 1.8634428516510995

Epoch: 6| Step: 12
Training loss: 0.7472628355026245
Validation loss: 1.8512588136939592

Epoch: 6| Step: 13
Training loss: 1.2769050598144531
Validation loss: 1.8412080887825257

Epoch: 210| Step: 0
Training loss: 0.45327797532081604
Validation loss: 1.819272546358006

Epoch: 6| Step: 1
Training loss: 0.4807141423225403
Validation loss: 1.8145460146729664

Epoch: 6| Step: 2
Training loss: 0.5969732999801636
Validation loss: 1.8181152587295861

Epoch: 6| Step: 3
Training loss: 0.8508036136627197
Validation loss: 1.8353695613081737

Epoch: 6| Step: 4
Training loss: 0.4901760518550873
Validation loss: 1.8759125637751755

Epoch: 6| Step: 5
Training loss: 0.410767138004303
Validation loss: 1.8640490501157698

Epoch: 6| Step: 6
Training loss: 0.7158607244491577
Validation loss: 1.8668102410531813

Epoch: 6| Step: 7
Training loss: 0.5658361911773682
Validation loss: 1.8769400529963995

Epoch: 6| Step: 8
Training loss: 1.0425941944122314
Validation loss: 1.8989108454796575

Epoch: 6| Step: 9
Training loss: 0.7065762281417847
Validation loss: 1.8953817736717962

Epoch: 6| Step: 10
Training loss: 0.5263906121253967
Validation loss: 1.8831760985876924

Epoch: 6| Step: 11
Training loss: 0.7639150023460388
Validation loss: 1.86389724926282

Epoch: 6| Step: 12
Training loss: 0.6785305738449097
Validation loss: 1.8308199849179996

Epoch: 6| Step: 13
Training loss: 0.8363131284713745
Validation loss: 1.8624679760266376

Epoch: 211| Step: 0
Training loss: 0.594741940498352
Validation loss: 1.87380511529984

Epoch: 6| Step: 1
Training loss: 0.8869841694831848
Validation loss: 1.8898134205930976

Epoch: 6| Step: 2
Training loss: 0.5189859867095947
Validation loss: 1.874172006883929

Epoch: 6| Step: 3
Training loss: 0.5100499391555786
Validation loss: 1.8951236522325905

Epoch: 6| Step: 4
Training loss: 0.9282183647155762
Validation loss: 1.9282724677875478

Epoch: 6| Step: 5
Training loss: 0.6524771451950073
Validation loss: 1.9247255709863478

Epoch: 6| Step: 6
Training loss: 0.7474780082702637
Validation loss: 1.8774832499924528

Epoch: 6| Step: 7
Training loss: 0.47129905223846436
Validation loss: 1.8705365375805927

Epoch: 6| Step: 8
Training loss: 0.6329402923583984
Validation loss: 1.8624151624659055

Epoch: 6| Step: 9
Training loss: 0.4251936078071594
Validation loss: 1.8002176259153633

Epoch: 6| Step: 10
Training loss: 0.5267151594161987
Validation loss: 1.829903252663151

Epoch: 6| Step: 11
Training loss: 1.260030746459961
Validation loss: 1.8513613772648636

Epoch: 6| Step: 12
Training loss: 0.37854811549186707
Validation loss: 1.8559700032716155

Epoch: 6| Step: 13
Training loss: 0.5959020853042603
Validation loss: 1.8830819899036038

Epoch: 212| Step: 0
Training loss: 0.6824760437011719
Validation loss: 1.873712719127696

Epoch: 6| Step: 1
Training loss: 0.4925884008407593
Validation loss: 1.8732768156195199

Epoch: 6| Step: 2
Training loss: 0.7092264890670776
Validation loss: 1.8731157497693134

Epoch: 6| Step: 3
Training loss: 0.6033357381820679
Validation loss: 1.8645476115647184

Epoch: 6| Step: 4
Training loss: 0.8832079768180847
Validation loss: 1.8660450199598908

Epoch: 6| Step: 5
Training loss: 0.5533283948898315
Validation loss: 1.873103891649554

Epoch: 6| Step: 6
Training loss: 0.46745336055755615
Validation loss: 1.9136307252350675

Epoch: 6| Step: 7
Training loss: 0.9041405916213989
Validation loss: 1.9183697854318926

Epoch: 6| Step: 8
Training loss: 0.6286511421203613
Validation loss: 1.891935577956579

Epoch: 6| Step: 9
Training loss: 1.2676429748535156
Validation loss: 1.90109763222356

Epoch: 6| Step: 10
Training loss: 0.5617508292198181
Validation loss: 1.8630609922511603

Epoch: 6| Step: 11
Training loss: 0.3510397970676422
Validation loss: 1.8445912984109694

Epoch: 6| Step: 12
Training loss: 0.4357161819934845
Validation loss: 1.8617839556868359

Epoch: 6| Step: 13
Training loss: 0.3570482134819031
Validation loss: 1.8925985584976852

Epoch: 213| Step: 0
Training loss: 0.6573847532272339
Validation loss: 1.9098810585596229

Epoch: 6| Step: 1
Training loss: 0.6104543805122375
Validation loss: 1.9045592354189964

Epoch: 6| Step: 2
Training loss: 0.6247265934944153
Validation loss: 1.9052058009691135

Epoch: 6| Step: 3
Training loss: 0.6418862342834473
Validation loss: 1.884188804575192

Epoch: 6| Step: 4
Training loss: 0.7839670777320862
Validation loss: 1.8469499516230758

Epoch: 6| Step: 5
Training loss: 0.7182447910308838
Validation loss: 1.8322068773290163

Epoch: 6| Step: 6
Training loss: 0.7995938062667847
Validation loss: 1.8269282566603793

Epoch: 6| Step: 7
Training loss: 0.8774743676185608
Validation loss: 1.8290479849743586

Epoch: 6| Step: 8
Training loss: 0.5549922585487366
Validation loss: 1.8250888932135798

Epoch: 6| Step: 9
Training loss: 1.0703097581863403
Validation loss: 1.8328847808222617

Epoch: 6| Step: 10
Training loss: 0.5002802610397339
Validation loss: 1.8541158694092945

Epoch: 6| Step: 11
Training loss: 0.444500207901001
Validation loss: 1.833528362294679

Epoch: 6| Step: 12
Training loss: 0.4038397967815399
Validation loss: 1.8608911832173665

Epoch: 6| Step: 13
Training loss: 0.46549081802368164
Validation loss: 1.898027995581268

Epoch: 214| Step: 0
Training loss: 0.9271698594093323
Validation loss: 1.880558552280549

Epoch: 6| Step: 1
Training loss: 0.7682651281356812
Validation loss: 1.888052826286644

Epoch: 6| Step: 2
Training loss: 0.8054308891296387
Validation loss: 1.8939201959999659

Epoch: 6| Step: 3
Training loss: 0.4620528221130371
Validation loss: 1.8672894534244333

Epoch: 6| Step: 4
Training loss: 0.863072395324707
Validation loss: 1.8563560106421029

Epoch: 6| Step: 5
Training loss: 0.5186111330986023
Validation loss: 1.846693113286008

Epoch: 6| Step: 6
Training loss: 0.8111567497253418
Validation loss: 1.8387043886287238

Epoch: 6| Step: 7
Training loss: 0.30254343152046204
Validation loss: 1.823003097247052

Epoch: 6| Step: 8
Training loss: 0.3753085136413574
Validation loss: 1.8367027287842126

Epoch: 6| Step: 9
Training loss: 0.7021206617355347
Validation loss: 1.8654298000438239

Epoch: 6| Step: 10
Training loss: 0.385530561208725
Validation loss: 1.8342551749239686

Epoch: 6| Step: 11
Training loss: 0.48756277561187744
Validation loss: 1.8691462214275072

Epoch: 6| Step: 12
Training loss: 0.7853438854217529
Validation loss: 1.8339668140616467

Epoch: 6| Step: 13
Training loss: 1.0192018747329712
Validation loss: 1.8189304579970658

Epoch: 215| Step: 0
Training loss: 0.4582766890525818
Validation loss: 1.8377710952553699

Epoch: 6| Step: 1
Training loss: 0.49863895773887634
Validation loss: 1.828920397707211

Epoch: 6| Step: 2
Training loss: 0.5846455693244934
Validation loss: 1.8216175417746268

Epoch: 6| Step: 3
Training loss: 0.7924021482467651
Validation loss: 1.8389424739345428

Epoch: 6| Step: 4
Training loss: 0.7527776956558228
Validation loss: 1.842966333512337

Epoch: 6| Step: 5
Training loss: 0.24951252341270447
Validation loss: 1.8533613111383171

Epoch: 6| Step: 6
Training loss: 0.6185040473937988
Validation loss: 1.915368136539254

Epoch: 6| Step: 7
Training loss: 0.6078118085861206
Validation loss: 1.9273617088153798

Epoch: 6| Step: 8
Training loss: 0.7183166742324829
Validation loss: 1.951310501303724

Epoch: 6| Step: 9
Training loss: 1.053403615951538
Validation loss: 1.9522407221537765

Epoch: 6| Step: 10
Training loss: 1.1870622634887695
Validation loss: 1.9213471412658691

Epoch: 6| Step: 11
Training loss: 0.43550342321395874
Validation loss: 1.921518600115212

Epoch: 6| Step: 12
Training loss: 0.62965989112854
Validation loss: 1.8913066874268234

Epoch: 6| Step: 13
Training loss: 0.4295717477798462
Validation loss: 1.8695232701557938

Epoch: 216| Step: 0
Training loss: 0.6446269154548645
Validation loss: 1.8409180846265567

Epoch: 6| Step: 1
Training loss: 0.40226155519485474
Validation loss: 1.8535736376239407

Epoch: 6| Step: 2
Training loss: 0.7276995182037354
Validation loss: 1.8414158436559862

Epoch: 6| Step: 3
Training loss: 0.6856435537338257
Validation loss: 1.8350026581877021

Epoch: 6| Step: 4
Training loss: 0.7606102228164673
Validation loss: 1.8386865174898537

Epoch: 6| Step: 5
Training loss: 0.3831934928894043
Validation loss: 1.8378029151629376

Epoch: 6| Step: 6
Training loss: 0.6626065969467163
Validation loss: 1.810991793550471

Epoch: 6| Step: 7
Training loss: 0.3477444350719452
Validation loss: 1.8479571855196388

Epoch: 6| Step: 8
Training loss: 0.5251368284225464
Validation loss: 1.8249805217148156

Epoch: 6| Step: 9
Training loss: 0.9209039211273193
Validation loss: 1.866303179853706

Epoch: 6| Step: 10
Training loss: 0.41447770595550537
Validation loss: 1.8858510909541961

Epoch: 6| Step: 11
Training loss: 0.5667273998260498
Validation loss: 1.851663145967709

Epoch: 6| Step: 12
Training loss: 0.5727314949035645
Validation loss: 1.8235772668674428

Epoch: 6| Step: 13
Training loss: 1.3278160095214844
Validation loss: 1.8323226923583655

Epoch: 217| Step: 0
Training loss: 0.4425460696220398
Validation loss: 1.820076637370612

Epoch: 6| Step: 1
Training loss: 0.2831836938858032
Validation loss: 1.8471327815004575

Epoch: 6| Step: 2
Training loss: 0.6919455528259277
Validation loss: 1.8784828352671799

Epoch: 6| Step: 3
Training loss: 1.0994770526885986
Validation loss: 1.8581476211547852

Epoch: 6| Step: 4
Training loss: 0.33538389205932617
Validation loss: 1.845720580829087

Epoch: 6| Step: 5
Training loss: 0.5761061310768127
Validation loss: 1.8537280790267452

Epoch: 6| Step: 6
Training loss: 1.1760164499282837
Validation loss: 1.8332061972669376

Epoch: 6| Step: 7
Training loss: 0.3709591031074524
Validation loss: 1.8425408242851176

Epoch: 6| Step: 8
Training loss: 0.3158493638038635
Validation loss: 1.8055893310936548

Epoch: 6| Step: 9
Training loss: 0.5685290098190308
Validation loss: 1.7990524756011141

Epoch: 6| Step: 10
Training loss: 0.755465030670166
Validation loss: 1.7816897540964105

Epoch: 6| Step: 11
Training loss: 0.43511462211608887
Validation loss: 1.767714940091615

Epoch: 6| Step: 12
Training loss: 0.4245310425758362
Validation loss: 1.762203929244831

Epoch: 6| Step: 13
Training loss: 0.901682436466217
Validation loss: 1.7666879982076666

Epoch: 218| Step: 0
Training loss: 0.5053278207778931
Validation loss: 1.782060202731881

Epoch: 6| Step: 1
Training loss: 0.7216388583183289
Validation loss: 1.8313088340144004

Epoch: 6| Step: 2
Training loss: 0.710700511932373
Validation loss: 1.8544308306068502

Epoch: 6| Step: 3
Training loss: 0.8882590532302856
Validation loss: 1.8376893023008942

Epoch: 6| Step: 4
Training loss: 0.6945880651473999
Validation loss: 1.867440979967835

Epoch: 6| Step: 5
Training loss: 0.49044084548950195
Validation loss: 1.8508234267593713

Epoch: 6| Step: 6
Training loss: 0.6787772178649902
Validation loss: 1.8653603010280158

Epoch: 6| Step: 7
Training loss: 0.5609937310218811
Validation loss: 1.872230601567094

Epoch: 6| Step: 8
Training loss: 0.3391122817993164
Validation loss: 1.8711228934667443

Epoch: 6| Step: 9
Training loss: 0.3370773196220398
Validation loss: 1.8989706282974572

Epoch: 6| Step: 10
Training loss: 0.6811864376068115
Validation loss: 1.8696572357608425

Epoch: 6| Step: 11
Training loss: 0.7165735363960266
Validation loss: 1.8810018672738025

Epoch: 6| Step: 12
Training loss: 0.46930405497550964
Validation loss: 1.845234130018501

Epoch: 6| Step: 13
Training loss: 0.2915557622909546
Validation loss: 1.840922450506559

Epoch: 219| Step: 0
Training loss: 0.4802764058113098
Validation loss: 1.8478721111051497

Epoch: 6| Step: 1
Training loss: 0.7118455171585083
Validation loss: 1.8638820225192654

Epoch: 6| Step: 2
Training loss: 0.5332062840461731
Validation loss: 1.8360595292942499

Epoch: 6| Step: 3
Training loss: 0.4927011728286743
Validation loss: 1.8562461176226217

Epoch: 6| Step: 4
Training loss: 0.7854601144790649
Validation loss: 1.8820613174028293

Epoch: 6| Step: 5
Training loss: 0.5587026476860046
Validation loss: 1.8820349516407135

Epoch: 6| Step: 6
Training loss: 0.5716520547866821
Validation loss: 1.877485321414086

Epoch: 6| Step: 7
Training loss: 0.3877815902233124
Validation loss: 1.8677732098487116

Epoch: 6| Step: 8
Training loss: 0.4175783097743988
Validation loss: 1.8680161071080033

Epoch: 6| Step: 9
Training loss: 0.3836311995983124
Validation loss: 1.8868606872456049

Epoch: 6| Step: 10
Training loss: 1.1354975700378418
Validation loss: 1.8650096879210523

Epoch: 6| Step: 11
Training loss: 0.4450226128101349
Validation loss: 1.8417278848668581

Epoch: 6| Step: 12
Training loss: 0.2852276861667633
Validation loss: 1.851537848672559

Epoch: 6| Step: 13
Training loss: 0.7347928285598755
Validation loss: 1.8362674636225547

Epoch: 220| Step: 0
Training loss: 0.2601178288459778
Validation loss: 1.8331740056314776

Epoch: 6| Step: 1
Training loss: 0.34594154357910156
Validation loss: 1.8055695308152067

Epoch: 6| Step: 2
Training loss: 0.4070606231689453
Validation loss: 1.815035463661276

Epoch: 6| Step: 3
Training loss: 0.4896416664123535
Validation loss: 1.8040969346159248

Epoch: 6| Step: 4
Training loss: 0.39607858657836914
Validation loss: 1.8040828269015077

Epoch: 6| Step: 5
Training loss: 0.7026292085647583
Validation loss: 1.807277041096841

Epoch: 6| Step: 6
Training loss: 0.6467483639717102
Validation loss: 1.8052369727883288

Epoch: 6| Step: 7
Training loss: 0.701565146446228
Validation loss: 1.7617757884404992

Epoch: 6| Step: 8
Training loss: 0.599334180355072
Validation loss: 1.7929037424825853

Epoch: 6| Step: 9
Training loss: 0.6742404699325562
Validation loss: 1.8049387393459198

Epoch: 6| Step: 10
Training loss: 0.7580004930496216
Validation loss: 1.8082563607923445

Epoch: 6| Step: 11
Training loss: 0.5120863914489746
Validation loss: 1.827383407982447

Epoch: 6| Step: 12
Training loss: 0.49977022409439087
Validation loss: 1.820562808744369

Epoch: 6| Step: 13
Training loss: 0.6258734464645386
Validation loss: 1.8331365931418635

Epoch: 221| Step: 0
Training loss: 0.4251478314399719
Validation loss: 1.785655612586647

Epoch: 6| Step: 1
Training loss: 0.22094155848026276
Validation loss: 1.7932176436147382

Epoch: 6| Step: 2
Training loss: 0.6154065132141113
Validation loss: 1.8018359381665465

Epoch: 6| Step: 3
Training loss: 0.48555564880371094
Validation loss: 1.800501500406573

Epoch: 6| Step: 4
Training loss: 0.608201265335083
Validation loss: 1.806547131589664

Epoch: 6| Step: 5
Training loss: 0.7990473508834839
Validation loss: 1.8199832618877452

Epoch: 6| Step: 6
Training loss: 0.869489312171936
Validation loss: 1.85462882057313

Epoch: 6| Step: 7
Training loss: 0.619264543056488
Validation loss: 1.8547292255586194

Epoch: 6| Step: 8
Training loss: 0.461614727973938
Validation loss: 1.8559104652814968

Epoch: 6| Step: 9
Training loss: 0.34861642122268677
Validation loss: 1.8460104555212042

Epoch: 6| Step: 10
Training loss: 0.44819265604019165
Validation loss: 1.8374706981002644

Epoch: 6| Step: 11
Training loss: 0.937441349029541
Validation loss: 1.8393135692483635

Epoch: 6| Step: 12
Training loss: 0.46639466285705566
Validation loss: 1.8418191017643097

Epoch: 6| Step: 13
Training loss: 0.2775661051273346
Validation loss: 1.8329929049297045

Epoch: 222| Step: 0
Training loss: 0.5811106562614441
Validation loss: 1.8399576128170054

Epoch: 6| Step: 1
Training loss: 0.4952613115310669
Validation loss: 1.8525095485871839

Epoch: 6| Step: 2
Training loss: 0.3584374785423279
Validation loss: 1.8255146793139878

Epoch: 6| Step: 3
Training loss: 0.44179004430770874
Validation loss: 1.83550872084915

Epoch: 6| Step: 4
Training loss: 0.46722328662872314
Validation loss: 1.8560994594327864

Epoch: 6| Step: 5
Training loss: 0.5562744140625
Validation loss: 1.8544179572853992

Epoch: 6| Step: 6
Training loss: 0.7016865611076355
Validation loss: 1.8285147067039245

Epoch: 6| Step: 7
Training loss: 0.7231371402740479
Validation loss: 1.805143431950641

Epoch: 6| Step: 8
Training loss: 0.6737691164016724
Validation loss: 1.7856284085140433

Epoch: 6| Step: 9
Training loss: 0.42158037424087524
Validation loss: 1.7731847852788947

Epoch: 6| Step: 10
Training loss: 0.751213788986206
Validation loss: 1.7977187761696436

Epoch: 6| Step: 11
Training loss: 0.8106108903884888
Validation loss: 1.8289591099626274

Epoch: 6| Step: 12
Training loss: 0.5419536828994751
Validation loss: 1.832218329111735

Epoch: 6| Step: 13
Training loss: 0.23611018061637878
Validation loss: 1.8303785593278947

Epoch: 223| Step: 0
Training loss: 0.5319610238075256
Validation loss: 1.8164117067090926

Epoch: 6| Step: 1
Training loss: 0.5272760391235352
Validation loss: 1.781114101409912

Epoch: 6| Step: 2
Training loss: 0.5272659659385681
Validation loss: 1.78325528483237

Epoch: 6| Step: 3
Training loss: 0.4488264322280884
Validation loss: 1.7520600595781881

Epoch: 6| Step: 4
Training loss: 0.36563003063201904
Validation loss: 1.7585528230154386

Epoch: 6| Step: 5
Training loss: 0.6370604038238525
Validation loss: 1.7612346808115642

Epoch: 6| Step: 6
Training loss: 0.734510064125061
Validation loss: 1.7708815214454487

Epoch: 6| Step: 7
Training loss: 0.5009982585906982
Validation loss: 1.7467609990027644

Epoch: 6| Step: 8
Training loss: 0.33223390579223633
Validation loss: 1.7875680410733787

Epoch: 6| Step: 9
Training loss: 0.5661677718162537
Validation loss: 1.8197392007356048

Epoch: 6| Step: 10
Training loss: 0.4356718063354492
Validation loss: 1.8050081652979697

Epoch: 6| Step: 11
Training loss: 0.9872806072235107
Validation loss: 1.8185345831737723

Epoch: 6| Step: 12
Training loss: 0.7267917394638062
Validation loss: 1.7954185252548547

Epoch: 6| Step: 13
Training loss: 0.17492620646953583
Validation loss: 1.7612704615439139

Epoch: 224| Step: 0
Training loss: 0.8085125088691711
Validation loss: 1.7744347151889597

Epoch: 6| Step: 1
Training loss: 0.2187207043170929
Validation loss: 1.7649749889168689

Epoch: 6| Step: 2
Training loss: 0.3683236241340637
Validation loss: 1.7963647098951443

Epoch: 6| Step: 3
Training loss: 0.514711856842041
Validation loss: 1.811968768796613

Epoch: 6| Step: 4
Training loss: 0.8096712231636047
Validation loss: 1.8347124630405056

Epoch: 6| Step: 5
Training loss: 0.37069451808929443
Validation loss: 1.8334957374039518

Epoch: 6| Step: 6
Training loss: 0.21628637611865997
Validation loss: 1.8728305101394653

Epoch: 6| Step: 7
Training loss: 0.5100932121276855
Validation loss: 1.852877022117697

Epoch: 6| Step: 8
Training loss: 0.5969504117965698
Validation loss: 1.8227832086624638

Epoch: 6| Step: 9
Training loss: 0.4541340470314026
Validation loss: 1.8529401466410647

Epoch: 6| Step: 10
Training loss: 0.6393476724624634
Validation loss: 1.829608194289669

Epoch: 6| Step: 11
Training loss: 0.3585391342639923
Validation loss: 1.8178348348986717

Epoch: 6| Step: 12
Training loss: 0.8810538053512573
Validation loss: 1.7863293822093675

Epoch: 6| Step: 13
Training loss: 0.36593249440193176
Validation loss: 1.7854756104048861

Epoch: 225| Step: 0
Training loss: 0.3008860945701599
Validation loss: 1.7947352368344542

Epoch: 6| Step: 1
Training loss: 0.7065613269805908
Validation loss: 1.7627558580008886

Epoch: 6| Step: 2
Training loss: 0.5491166710853577
Validation loss: 1.753498282483829

Epoch: 6| Step: 3
Training loss: 0.5595251321792603
Validation loss: 1.7715397932196175

Epoch: 6| Step: 4
Training loss: 0.5244656801223755
Validation loss: 1.7799599375776065

Epoch: 6| Step: 5
Training loss: 0.30968838930130005
Validation loss: 1.8049825391461771

Epoch: 6| Step: 6
Training loss: 0.49036121368408203
Validation loss: 1.80391263961792

Epoch: 6| Step: 7
Training loss: 0.32649344205856323
Validation loss: 1.8303170486163067

Epoch: 6| Step: 8
Training loss: 0.47952941060066223
Validation loss: 1.7939921540598716

Epoch: 6| Step: 9
Training loss: 0.692656397819519
Validation loss: 1.8210135557318246

Epoch: 6| Step: 10
Training loss: 0.5763510465621948
Validation loss: 1.8157187918181061

Epoch: 6| Step: 11
Training loss: 0.356228232383728
Validation loss: 1.8115263356957385

Epoch: 6| Step: 12
Training loss: 0.5002800226211548
Validation loss: 1.7938913055645522

Epoch: 6| Step: 13
Training loss: 0.97025465965271
Validation loss: 1.821733920804916

Epoch: 226| Step: 0
Training loss: 0.32176491618156433
Validation loss: 1.8097133905656877

Epoch: 6| Step: 1
Training loss: 0.37286514043807983
Validation loss: 1.7900003643446072

Epoch: 6| Step: 2
Training loss: 0.3499068021774292
Validation loss: 1.786049537761237

Epoch: 6| Step: 3
Training loss: 0.7683611512184143
Validation loss: 1.8059041205272879

Epoch: 6| Step: 4
Training loss: 0.34990209341049194
Validation loss: 1.7685262182707429

Epoch: 6| Step: 5
Training loss: 0.527511477470398
Validation loss: 1.7755459534224642

Epoch: 6| Step: 6
Training loss: 0.5528676509857178
Validation loss: 1.7706488255531556

Epoch: 6| Step: 7
Training loss: 0.41470152139663696
Validation loss: 1.7448967131235267

Epoch: 6| Step: 8
Training loss: 0.697557806968689
Validation loss: 1.7754195300481652

Epoch: 6| Step: 9
Training loss: 0.6640945672988892
Validation loss: 1.768161613454101

Epoch: 6| Step: 10
Training loss: 0.6822673082351685
Validation loss: 1.7819604194292458

Epoch: 6| Step: 11
Training loss: 0.47156691551208496
Validation loss: 1.8017975335480065

Epoch: 6| Step: 12
Training loss: 0.3968352973461151
Validation loss: 1.7945401425002723

Epoch: 6| Step: 13
Training loss: 0.42398393154144287
Validation loss: 1.7950443836950487

Epoch: 227| Step: 0
Training loss: 0.869512677192688
Validation loss: 1.8239548360147784

Epoch: 6| Step: 1
Training loss: 0.55860835313797
Validation loss: 1.812163891330842

Epoch: 6| Step: 2
Training loss: 0.563117504119873
Validation loss: 1.7627741149676743

Epoch: 6| Step: 3
Training loss: 0.4075133502483368
Validation loss: 1.776405890782674

Epoch: 6| Step: 4
Training loss: 0.6387062668800354
Validation loss: 1.7774090946361583

Epoch: 6| Step: 5
Training loss: 0.2613734006881714
Validation loss: 1.7884064374431488

Epoch: 6| Step: 6
Training loss: 0.3318386971950531
Validation loss: 1.7684793139016757

Epoch: 6| Step: 7
Training loss: 0.29828906059265137
Validation loss: 1.782746486766364

Epoch: 6| Step: 8
Training loss: 0.6538811922073364
Validation loss: 1.7998311981078117

Epoch: 6| Step: 9
Training loss: 0.4537234604358673
Validation loss: 1.7939268965874948

Epoch: 6| Step: 10
Training loss: 0.12258244305849075
Validation loss: 1.7896788812452746

Epoch: 6| Step: 11
Training loss: 0.3835190534591675
Validation loss: 1.807489561778243

Epoch: 6| Step: 12
Training loss: 0.9953332543373108
Validation loss: 1.7733153886692499

Epoch: 6| Step: 13
Training loss: 0.5078611373901367
Validation loss: 1.769937329394843

Epoch: 228| Step: 0
Training loss: 0.3596908450126648
Validation loss: 1.7981086187465216

Epoch: 6| Step: 1
Training loss: 0.5576035380363464
Validation loss: 1.8457027789085143

Epoch: 6| Step: 2
Training loss: 0.5751770734786987
Validation loss: 1.8167320169428343

Epoch: 6| Step: 3
Training loss: 0.4597693979740143
Validation loss: 1.87533994900283

Epoch: 6| Step: 4
Training loss: 0.7417376041412354
Validation loss: 1.8481258705098143

Epoch: 6| Step: 5
Training loss: 0.7459709048271179
Validation loss: 1.8475976887569632

Epoch: 6| Step: 6
Training loss: 0.22165939211845398
Validation loss: 1.8213859219704904

Epoch: 6| Step: 7
Training loss: 0.40579813718795776
Validation loss: 1.8324787616729736

Epoch: 6| Step: 8
Training loss: 0.28153565526008606
Validation loss: 1.7987100385850476

Epoch: 6| Step: 9
Training loss: 0.5819149613380432
Validation loss: 1.8076714879723006

Epoch: 6| Step: 10
Training loss: 0.475843608379364
Validation loss: 1.7959623067609725

Epoch: 6| Step: 11
Training loss: 0.5542320609092712
Validation loss: 1.7879524102775

Epoch: 6| Step: 12
Training loss: 0.45429515838623047
Validation loss: 1.7904320455366565

Epoch: 6| Step: 13
Training loss: 0.7441672086715698
Validation loss: 1.7673327384456512

Epoch: 229| Step: 0
Training loss: 0.6783105731010437
Validation loss: 1.7597713649913829

Epoch: 6| Step: 1
Training loss: 0.6556153893470764
Validation loss: 1.7587175125716834

Epoch: 6| Step: 2
Training loss: 0.4620410203933716
Validation loss: 1.7830592278511292

Epoch: 6| Step: 3
Training loss: 0.3614261746406555
Validation loss: 1.7662838915342927

Epoch: 6| Step: 4
Training loss: 0.38490214943885803
Validation loss: 1.7784264113313408

Epoch: 6| Step: 5
Training loss: 0.1903802752494812
Validation loss: 1.8158168241541872

Epoch: 6| Step: 6
Training loss: 0.4904612600803375
Validation loss: 1.8080332407387354

Epoch: 6| Step: 7
Training loss: 0.6062171459197998
Validation loss: 1.8217235611331077

Epoch: 6| Step: 8
Training loss: 0.40565675497055054
Validation loss: 1.8172115023418138

Epoch: 6| Step: 9
Training loss: 0.5120068192481995
Validation loss: 1.825647977090651

Epoch: 6| Step: 10
Training loss: 0.3171587884426117
Validation loss: 1.803840882034712

Epoch: 6| Step: 11
Training loss: 0.3249933123588562
Validation loss: 1.8055281062279978

Epoch: 6| Step: 12
Training loss: 0.7226272225379944
Validation loss: 1.8059511159055976

Epoch: 6| Step: 13
Training loss: 0.809575080871582
Validation loss: 1.776977103243592

Epoch: 230| Step: 0
Training loss: 0.27576154470443726
Validation loss: 1.772555060284112

Epoch: 6| Step: 1
Training loss: 0.2769906520843506
Validation loss: 1.7552818175285094

Epoch: 6| Step: 2
Training loss: 0.6533359289169312
Validation loss: 1.7832185004347114

Epoch: 6| Step: 3
Training loss: 0.5196866393089294
Validation loss: 1.7890763372503302

Epoch: 6| Step: 4
Training loss: 0.4599445164203644
Validation loss: 1.7931387757742276

Epoch: 6| Step: 5
Training loss: 0.47189441323280334
Validation loss: 1.7970362388959495

Epoch: 6| Step: 6
Training loss: 0.4765632152557373
Validation loss: 1.8015905426394554

Epoch: 6| Step: 7
Training loss: 0.979210615158081
Validation loss: 1.7840698970261442

Epoch: 6| Step: 8
Training loss: 0.6033018827438354
Validation loss: 1.7761521621416974

Epoch: 6| Step: 9
Training loss: 0.1435309648513794
Validation loss: 1.7421388703007852

Epoch: 6| Step: 10
Training loss: 0.47583672404289246
Validation loss: 1.7658486699545255

Epoch: 6| Step: 11
Training loss: 0.44181275367736816
Validation loss: 1.765960249849545

Epoch: 6| Step: 12
Training loss: 0.3562507927417755
Validation loss: 1.753904664388267

Epoch: 6| Step: 13
Training loss: 0.4838019013404846
Validation loss: 1.7337651534747052

Epoch: 231| Step: 0
Training loss: 0.5026120543479919
Validation loss: 1.7517240714001399

Epoch: 6| Step: 1
Training loss: 0.23990726470947266
Validation loss: 1.7563341253547258

Epoch: 6| Step: 2
Training loss: 0.12534692883491516
Validation loss: 1.7756577307178127

Epoch: 6| Step: 3
Training loss: 0.5412538647651672
Validation loss: 1.7680302178987892

Epoch: 6| Step: 4
Training loss: 0.6637369990348816
Validation loss: 1.7745067188816686

Epoch: 6| Step: 5
Training loss: 0.5405580997467041
Validation loss: 1.7551818342619045

Epoch: 6| Step: 6
Training loss: 0.5967835187911987
Validation loss: 1.765535016213694

Epoch: 6| Step: 7
Training loss: 0.3229004442691803
Validation loss: 1.7398622510253743

Epoch: 6| Step: 8
Training loss: 0.34077033400535583
Validation loss: 1.7092047314490042

Epoch: 6| Step: 9
Training loss: 0.32477864623069763
Validation loss: 1.7391150869348997

Epoch: 6| Step: 10
Training loss: 0.32779958844184875
Validation loss: 1.7303331308467413

Epoch: 6| Step: 11
Training loss: 0.6297131776809692
Validation loss: 1.7304505712242537

Epoch: 6| Step: 12
Training loss: 0.6384477615356445
Validation loss: 1.7531741562710013

Epoch: 6| Step: 13
Training loss: 0.676859438419342
Validation loss: 1.8013508063490673

Epoch: 232| Step: 0
Training loss: 0.6085644960403442
Validation loss: 1.8384115965135637

Epoch: 6| Step: 1
Training loss: 0.5453087091445923
Validation loss: 1.8197519663841493

Epoch: 6| Step: 2
Training loss: 0.3945466876029968
Validation loss: 1.8056324579382454

Epoch: 6| Step: 3
Training loss: 0.8563512563705444
Validation loss: 1.77687172607709

Epoch: 6| Step: 4
Training loss: 0.3657442033290863
Validation loss: 1.769854986539451

Epoch: 6| Step: 5
Training loss: 0.3515253961086273
Validation loss: 1.724294634275539

Epoch: 6| Step: 6
Training loss: 0.3628259599208832
Validation loss: 1.730285595822078

Epoch: 6| Step: 7
Training loss: 0.4266161322593689
Validation loss: 1.7398135469805809

Epoch: 6| Step: 8
Training loss: 0.4205072522163391
Validation loss: 1.7302815683426396

Epoch: 6| Step: 9
Training loss: 0.4257675111293793
Validation loss: 1.7552317624451013

Epoch: 6| Step: 10
Training loss: 0.485562264919281
Validation loss: 1.7598838633106602

Epoch: 6| Step: 11
Training loss: 0.26415538787841797
Validation loss: 1.7378887950733144

Epoch: 6| Step: 12
Training loss: 0.5115865468978882
Validation loss: 1.7631338873217184

Epoch: 6| Step: 13
Training loss: 0.34510499238967896
Validation loss: 1.7798895579512402

Epoch: 233| Step: 0
Training loss: 0.29510098695755005
Validation loss: 1.7986743014345887

Epoch: 6| Step: 1
Training loss: 0.3874855637550354
Validation loss: 1.7877734066337667

Epoch: 6| Step: 2
Training loss: 0.42117124795913696
Validation loss: 1.7605516179915397

Epoch: 6| Step: 3
Training loss: 0.3342244029045105
Validation loss: 1.740573674119929

Epoch: 6| Step: 4
Training loss: 0.59001624584198
Validation loss: 1.7477054467765234

Epoch: 6| Step: 5
Training loss: 0.5749518275260925
Validation loss: 1.7373630833882157

Epoch: 6| Step: 6
Training loss: 0.6625573039054871
Validation loss: 1.7209961042609265

Epoch: 6| Step: 7
Training loss: 0.7617241740226746
Validation loss: 1.7298083433540918

Epoch: 6| Step: 8
Training loss: 0.20376819372177124
Validation loss: 1.727155347024241

Epoch: 6| Step: 9
Training loss: 0.5464529991149902
Validation loss: 1.6951871123365176

Epoch: 6| Step: 10
Training loss: 0.24673637747764587
Validation loss: 1.7272507721377957

Epoch: 6| Step: 11
Training loss: 0.5109502077102661
Validation loss: 1.7134656880491523

Epoch: 6| Step: 12
Training loss: 0.3603709936141968
Validation loss: 1.7202773529996154

Epoch: 6| Step: 13
Training loss: 0.33428266644477844
Validation loss: 1.7272950000660394

Epoch: 234| Step: 0
Training loss: 0.3397647738456726
Validation loss: 1.696782826095499

Epoch: 6| Step: 1
Training loss: 0.8395509123802185
Validation loss: 1.7524920919890046

Epoch: 6| Step: 2
Training loss: 0.4143751859664917
Validation loss: 1.7649903630697599

Epoch: 6| Step: 3
Training loss: 0.3212599754333496
Validation loss: 1.753110506201303

Epoch: 6| Step: 4
Training loss: 0.4009864330291748
Validation loss: 1.761809681051521

Epoch: 6| Step: 5
Training loss: 0.18816113471984863
Validation loss: 1.7625739061704246

Epoch: 6| Step: 6
Training loss: 0.5494614839553833
Validation loss: 1.7616618999870874

Epoch: 6| Step: 7
Training loss: 0.29417306184768677
Validation loss: 1.7515926220083748

Epoch: 6| Step: 8
Training loss: 0.5060914158821106
Validation loss: 1.7169332478636055

Epoch: 6| Step: 9
Training loss: 0.19807317852973938
Validation loss: 1.7446574677703202

Epoch: 6| Step: 10
Training loss: 0.6516150832176208
Validation loss: 1.7232912266126243

Epoch: 6| Step: 11
Training loss: 0.36440378427505493
Validation loss: 1.7218544675457863

Epoch: 6| Step: 12
Training loss: 0.4655247628688812
Validation loss: 1.7092867602584183

Epoch: 6| Step: 13
Training loss: 1.0006599426269531
Validation loss: 1.7261497346303796

Epoch: 235| Step: 0
Training loss: 0.5446099638938904
Validation loss: 1.7141211981414466

Epoch: 6| Step: 1
Training loss: 0.3055267035961151
Validation loss: 1.7417231387989496

Epoch: 6| Step: 2
Training loss: 0.30385005474090576
Validation loss: 1.7447437137685797

Epoch: 6| Step: 3
Training loss: 0.3005827069282532
Validation loss: 1.7556112017682803

Epoch: 6| Step: 4
Training loss: 0.3506965637207031
Validation loss: 1.7921718743539625

Epoch: 6| Step: 5
Training loss: 0.8845837116241455
Validation loss: 1.7930329743252005

Epoch: 6| Step: 6
Training loss: 0.3869934380054474
Validation loss: 1.8064815485349266

Epoch: 6| Step: 7
Training loss: 0.6364887952804565
Validation loss: 1.7858876528278473

Epoch: 6| Step: 8
Training loss: 0.38430216908454895
Validation loss: 1.8047918529920681

Epoch: 6| Step: 9
Training loss: 0.5263003706932068
Validation loss: 1.7943416641604515

Epoch: 6| Step: 10
Training loss: 0.4400216341018677
Validation loss: 1.8107237713311308

Epoch: 6| Step: 11
Training loss: 0.15253788232803345
Validation loss: 1.80009719633287

Epoch: 6| Step: 12
Training loss: 0.5988644361495972
Validation loss: 1.7717694928569179

Epoch: 6| Step: 13
Training loss: 0.2710660696029663
Validation loss: 1.7753803563374344

Epoch: 236| Step: 0
Training loss: 0.3032381534576416
Validation loss: 1.7659764687220256

Epoch: 6| Step: 1
Training loss: 0.4742673933506012
Validation loss: 1.7695367336273193

Epoch: 6| Step: 2
Training loss: 0.49535071849823
Validation loss: 1.8032610262593916

Epoch: 6| Step: 3
Training loss: 0.7126410603523254
Validation loss: 1.7955367513882217

Epoch: 6| Step: 4
Training loss: 0.360258549451828
Validation loss: 1.7949770785147143

Epoch: 6| Step: 5
Training loss: 0.40985846519470215
Validation loss: 1.8033654061696862

Epoch: 6| Step: 6
Training loss: 0.48511141538619995
Validation loss: 1.852626536482124

Epoch: 6| Step: 7
Training loss: 0.3826415240764618
Validation loss: 1.8573840023368917

Epoch: 6| Step: 8
Training loss: 0.6496565341949463
Validation loss: 1.8868178757288123

Epoch: 6| Step: 9
Training loss: 0.5112723112106323
Validation loss: 1.8976284380882018

Epoch: 6| Step: 10
Training loss: 0.5819354057312012
Validation loss: 1.8726666435118644

Epoch: 6| Step: 11
Training loss: 0.3672524094581604
Validation loss: 1.8202914845558904

Epoch: 6| Step: 12
Training loss: 0.2964227497577667
Validation loss: 1.7725805492811306

Epoch: 6| Step: 13
Training loss: 0.5092166066169739
Validation loss: 1.7330936590830486

Epoch: 237| Step: 0
Training loss: 0.6486324071884155
Validation loss: 1.712550324778403

Epoch: 6| Step: 1
Training loss: 0.3635232448577881
Validation loss: 1.7115092687709357

Epoch: 6| Step: 2
Training loss: 0.22364480793476105
Validation loss: 1.6889764531966178

Epoch: 6| Step: 3
Training loss: 0.404440701007843
Validation loss: 1.688026964023549

Epoch: 6| Step: 4
Training loss: 0.42345067858695984
Validation loss: 1.6966426987801828

Epoch: 6| Step: 5
Training loss: 0.3642232418060303
Validation loss: 1.7661497336561962

Epoch: 6| Step: 6
Training loss: 0.8599007725715637
Validation loss: 1.7462217448860087

Epoch: 6| Step: 7
Training loss: 0.31859290599823
Validation loss: 1.7540547527292722

Epoch: 6| Step: 8
Training loss: 0.6861743330955505
Validation loss: 1.77787535677674

Epoch: 6| Step: 9
Training loss: 0.2315453737974167
Validation loss: 1.7743564062221076

Epoch: 6| Step: 10
Training loss: 0.40805739164352417
Validation loss: 1.747707320797828

Epoch: 6| Step: 11
Training loss: 0.43313348293304443
Validation loss: 1.7519230381135018

Epoch: 6| Step: 12
Training loss: 0.49603506922721863
Validation loss: 1.7769987711342432

Epoch: 6| Step: 13
Training loss: 0.6504136323928833
Validation loss: 1.75180184841156

Epoch: 238| Step: 0
Training loss: 0.2716904282569885
Validation loss: 1.7512656245180356

Epoch: 6| Step: 1
Training loss: 0.31595751643180847
Validation loss: 1.7308994787995533

Epoch: 6| Step: 2
Training loss: 0.45399391651153564
Validation loss: 1.7339886978108396

Epoch: 6| Step: 3
Training loss: 0.48802441358566284
Validation loss: 1.738224421778033

Epoch: 6| Step: 4
Training loss: 0.5781450867652893
Validation loss: 1.7245670505749282

Epoch: 6| Step: 5
Training loss: 0.2768669128417969
Validation loss: 1.740382190673582

Epoch: 6| Step: 6
Training loss: 0.37238436937332153
Validation loss: 1.7679286644022951

Epoch: 6| Step: 7
Training loss: 0.4757393002510071
Validation loss: 1.7665679454803467

Epoch: 6| Step: 8
Training loss: 0.7633845806121826
Validation loss: 1.79051237721597

Epoch: 6| Step: 9
Training loss: 0.2782911956310272
Validation loss: 1.7932647210295483

Epoch: 6| Step: 10
Training loss: 0.4177892804145813
Validation loss: 1.8014181544703822

Epoch: 6| Step: 11
Training loss: 0.6823605298995972
Validation loss: 1.7791898660762335

Epoch: 6| Step: 12
Training loss: 0.3045717477798462
Validation loss: 1.786356513218213

Epoch: 6| Step: 13
Training loss: 0.5710659027099609
Validation loss: 1.7574028456082909

Epoch: 239| Step: 0
Training loss: 0.4108622074127197
Validation loss: 1.7534388778030232

Epoch: 6| Step: 1
Training loss: 0.38748201727867126
Validation loss: 1.7237081066254647

Epoch: 6| Step: 2
Training loss: 0.6478024125099182
Validation loss: 1.7139801261245564

Epoch: 6| Step: 3
Training loss: 0.3367089033126831
Validation loss: 1.7071131262727963

Epoch: 6| Step: 4
Training loss: 0.5065710544586182
Validation loss: 1.7378407947478756

Epoch: 6| Step: 5
Training loss: 0.6329773664474487
Validation loss: 1.7140146250365882

Epoch: 6| Step: 6
Training loss: 0.2929304540157318
Validation loss: 1.7026552743809198

Epoch: 6| Step: 7
Training loss: 0.4036448001861572
Validation loss: 1.7046807209650676

Epoch: 6| Step: 8
Training loss: 0.539675235748291
Validation loss: 1.725848723483342

Epoch: 6| Step: 9
Training loss: 0.35789763927459717
Validation loss: 1.7323958643021122

Epoch: 6| Step: 10
Training loss: 0.44967883825302124
Validation loss: 1.744565184398364

Epoch: 6| Step: 11
Training loss: 0.43926721811294556
Validation loss: 1.7680168946584065

Epoch: 6| Step: 12
Training loss: 0.4389527440071106
Validation loss: 1.7754710002612042

Epoch: 6| Step: 13
Training loss: 0.47147735953330994
Validation loss: 1.7654867877242386

Epoch: 240| Step: 0
Training loss: 0.3533855080604553
Validation loss: 1.7415832832295408

Epoch: 6| Step: 1
Training loss: 0.3565155267715454
Validation loss: 1.732082801480447

Epoch: 6| Step: 2
Training loss: 0.49463221430778503
Validation loss: 1.70883628501687

Epoch: 6| Step: 3
Training loss: 0.4585185647010803
Validation loss: 1.7098046733487038

Epoch: 6| Step: 4
Training loss: 0.46600091457366943
Validation loss: 1.723460461503716

Epoch: 6| Step: 5
Training loss: 0.3613285422325134
Validation loss: 1.7170344398867698

Epoch: 6| Step: 6
Training loss: 0.3528740406036377
Validation loss: 1.7176190409609067

Epoch: 6| Step: 7
Training loss: 0.6163958311080933
Validation loss: 1.7366686456946916

Epoch: 6| Step: 8
Training loss: 0.34551873803138733
Validation loss: 1.7280593161941857

Epoch: 6| Step: 9
Training loss: 0.3768957853317261
Validation loss: 1.719425396252704

Epoch: 6| Step: 10
Training loss: 0.27820974588394165
Validation loss: 1.7293961830036615

Epoch: 6| Step: 11
Training loss: 0.1688089370727539
Validation loss: 1.7542057165535547

Epoch: 6| Step: 12
Training loss: 0.9254916906356812
Validation loss: 1.7463282987635622

Epoch: 6| Step: 13
Training loss: 0.38190439343452454
Validation loss: 1.753575668540052

Epoch: 241| Step: 0
Training loss: 0.43070095777511597
Validation loss: 1.7409651176903838

Epoch: 6| Step: 1
Training loss: 0.4333786964416504
Validation loss: 1.735415397151824

Epoch: 6| Step: 2
Training loss: 0.36914247274398804
Validation loss: 1.7535800574928202

Epoch: 6| Step: 3
Training loss: 0.17831531167030334
Validation loss: 1.7727592093970186

Epoch: 6| Step: 4
Training loss: 0.669920027256012
Validation loss: 1.7736101483785978

Epoch: 6| Step: 5
Training loss: 0.198399156332016
Validation loss: 1.7870289612841863

Epoch: 6| Step: 6
Training loss: 0.5215997695922852
Validation loss: 1.7882766941542267

Epoch: 6| Step: 7
Training loss: 0.5068414211273193
Validation loss: 1.809107070328087

Epoch: 6| Step: 8
Training loss: 0.5795365571975708
Validation loss: 1.8217575062987625

Epoch: 6| Step: 9
Training loss: 0.23563268780708313
Validation loss: 1.8009646887420325

Epoch: 6| Step: 10
Training loss: 0.3815656900405884
Validation loss: 1.7779698884615334

Epoch: 6| Step: 11
Training loss: 0.21137771010398865
Validation loss: 1.7436600795356176

Epoch: 6| Step: 12
Training loss: 0.9252216815948486
Validation loss: 1.7513388741400935

Epoch: 6| Step: 13
Training loss: 0.2392985224723816
Validation loss: 1.7360658812266525

Epoch: 242| Step: 0
Training loss: 0.32975059747695923
Validation loss: 1.7327692252333446

Epoch: 6| Step: 1
Training loss: 0.249678373336792
Validation loss: 1.7176459681603216

Epoch: 6| Step: 2
Training loss: 0.4358200430870056
Validation loss: 1.707306795222785

Epoch: 6| Step: 3
Training loss: 0.23789885640144348
Validation loss: 1.688721453630796

Epoch: 6| Step: 4
Training loss: 0.37926995754241943
Validation loss: 1.6775589771168207

Epoch: 6| Step: 5
Training loss: 0.2657122313976288
Validation loss: 1.6819675340447375

Epoch: 6| Step: 6
Training loss: 0.6829445958137512
Validation loss: 1.6716299492825744

Epoch: 6| Step: 7
Training loss: 0.39498311281204224
Validation loss: 1.6654528725531794

Epoch: 6| Step: 8
Training loss: 0.5314934253692627
Validation loss: 1.6849196841639857

Epoch: 6| Step: 9
Training loss: 0.661405086517334
Validation loss: 1.677908771781511

Epoch: 6| Step: 10
Training loss: 0.5243769884109497
Validation loss: 1.7358510442959365

Epoch: 6| Step: 11
Training loss: 0.38209062814712524
Validation loss: 1.7570479813442434

Epoch: 6| Step: 12
Training loss: 0.5342528820037842
Validation loss: 1.8223620601879653

Epoch: 6| Step: 13
Training loss: 0.3600751757621765
Validation loss: 1.862840421738163

Epoch: 243| Step: 0
Training loss: 0.6343309879302979
Validation loss: 1.8697216459499892

Epoch: 6| Step: 1
Training loss: 0.4514414966106415
Validation loss: 1.8546873395160963

Epoch: 6| Step: 2
Training loss: 0.713214635848999
Validation loss: 1.8329221683163797

Epoch: 6| Step: 3
Training loss: 0.5414881706237793
Validation loss: 1.8057061010791409

Epoch: 6| Step: 4
Training loss: 0.2888393700122833
Validation loss: 1.7861479302888275

Epoch: 6| Step: 5
Training loss: 0.3338107466697693
Validation loss: 1.7922907131974415

Epoch: 6| Step: 6
Training loss: 0.5129725933074951
Validation loss: 1.7828686673154113

Epoch: 6| Step: 7
Training loss: 0.5375128388404846
Validation loss: 1.8076534835241174

Epoch: 6| Step: 8
Training loss: 0.39478951692581177
Validation loss: 1.7987700893032936

Epoch: 6| Step: 9
Training loss: 0.7056630849838257
Validation loss: 1.7934141543603712

Epoch: 6| Step: 10
Training loss: 0.259260892868042
Validation loss: 1.778792247977308

Epoch: 6| Step: 11
Training loss: 0.33139097690582275
Validation loss: 1.7627968916329004

Epoch: 6| Step: 12
Training loss: 0.3677205443382263
Validation loss: 1.7649978155730872

Epoch: 6| Step: 13
Training loss: 0.8014941215515137
Validation loss: 1.7533332519633795

Epoch: 244| Step: 0
Training loss: 0.44934430718421936
Validation loss: 1.756488520611999

Epoch: 6| Step: 1
Training loss: 0.5078701376914978
Validation loss: 1.7653236978797502

Epoch: 6| Step: 2
Training loss: 0.31258395314216614
Validation loss: 1.7702224716063468

Epoch: 6| Step: 3
Training loss: 0.4341515898704529
Validation loss: 1.7879443117367324

Epoch: 6| Step: 4
Training loss: 0.5214076042175293
Validation loss: 1.7684007216525335

Epoch: 6| Step: 5
Training loss: 0.4079732596874237
Validation loss: 1.7992535227088517

Epoch: 6| Step: 6
Training loss: 0.38889700174331665
Validation loss: 1.7918780337097824

Epoch: 6| Step: 7
Training loss: 0.4741549789905548
Validation loss: 1.7764898371952835

Epoch: 6| Step: 8
Training loss: 0.46774178743362427
Validation loss: 1.7681005577887259

Epoch: 6| Step: 9
Training loss: 0.5914379358291626
Validation loss: 1.784159900039755

Epoch: 6| Step: 10
Training loss: 0.3237101435661316
Validation loss: 1.7468334244143577

Epoch: 6| Step: 11
Training loss: 0.47292056679725647
Validation loss: 1.7306181000125023

Epoch: 6| Step: 12
Training loss: 0.39958328008651733
Validation loss: 1.7243040838549215

Epoch: 6| Step: 13
Training loss: 0.29827821254730225
Validation loss: 1.7562919765390375

Epoch: 245| Step: 0
Training loss: 0.25159794092178345
Validation loss: 1.80269673691001

Epoch: 6| Step: 1
Training loss: 0.5864440202713013
Validation loss: 1.833617111688019

Epoch: 6| Step: 2
Training loss: 0.34281978011131287
Validation loss: 1.8697231841343704

Epoch: 6| Step: 3
Training loss: 0.322091281414032
Validation loss: 1.8418680083367132

Epoch: 6| Step: 4
Training loss: 0.5444780588150024
Validation loss: 1.801491310519557

Epoch: 6| Step: 5
Training loss: 0.2993382513523102
Validation loss: 1.7888560564287248

Epoch: 6| Step: 6
Training loss: 0.38866233825683594
Validation loss: 1.7597117654738887

Epoch: 6| Step: 7
Training loss: 0.3698151707649231
Validation loss: 1.7532580155198292

Epoch: 6| Step: 8
Training loss: 0.5983269214630127
Validation loss: 1.7293731807380595

Epoch: 6| Step: 9
Training loss: 0.4957508146762848
Validation loss: 1.7347298001730314

Epoch: 6| Step: 10
Training loss: 0.5663522481918335
Validation loss: 1.7536893531840334

Epoch: 6| Step: 11
Training loss: 0.22610770165920258
Validation loss: 1.76766840745044

Epoch: 6| Step: 12
Training loss: 0.26968663930892944
Validation loss: 1.7748417649217831

Epoch: 6| Step: 13
Training loss: 0.5669763088226318
Validation loss: 1.7405035162484774

Epoch: 246| Step: 0
Training loss: 0.266907662153244
Validation loss: 1.7790730525088567

Epoch: 6| Step: 1
Training loss: 0.24260959029197693
Validation loss: 1.813903906012094

Epoch: 6| Step: 2
Training loss: 0.5500331521034241
Validation loss: 1.7907113054747223

Epoch: 6| Step: 3
Training loss: 0.7546899318695068
Validation loss: 1.8113949901314192

Epoch: 6| Step: 4
Training loss: 0.3562105596065521
Validation loss: 1.828638389546384

Epoch: 6| Step: 5
Training loss: 0.6674968004226685
Validation loss: 1.8383949187494093

Epoch: 6| Step: 6
Training loss: 0.3450890779495239
Validation loss: 1.8215680019829863

Epoch: 6| Step: 7
Training loss: 0.30349868535995483
Validation loss: 1.8137745549601894

Epoch: 6| Step: 8
Training loss: 0.20645354688167572
Validation loss: 1.8016073216674149

Epoch: 6| Step: 9
Training loss: 0.21448077261447906
Validation loss: 1.7776806610886768

Epoch: 6| Step: 10
Training loss: 0.38988280296325684
Validation loss: 1.7949566072033298

Epoch: 6| Step: 11
Training loss: 0.6030786633491516
Validation loss: 1.8057173144432805

Epoch: 6| Step: 12
Training loss: 0.2652996778488159
Validation loss: 1.801360373855919

Epoch: 6| Step: 13
Training loss: 0.7151273488998413
Validation loss: 1.792360762114166

Epoch: 247| Step: 0
Training loss: 0.133741095662117
Validation loss: 1.7804952001058927

Epoch: 6| Step: 1
Training loss: 0.29791098833084106
Validation loss: 1.7850405426435574

Epoch: 6| Step: 2
Training loss: 0.41530951857566833
Validation loss: 1.7832803290377381

Epoch: 6| Step: 3
Training loss: 0.5203638076782227
Validation loss: 1.7423953830554921

Epoch: 6| Step: 4
Training loss: 0.49582183361053467
Validation loss: 1.7268863749760452

Epoch: 6| Step: 5
Training loss: 0.32219263911247253
Validation loss: 1.7192321772216468

Epoch: 6| Step: 6
Training loss: 0.4412935674190521
Validation loss: 1.71298469907494

Epoch: 6| Step: 7
Training loss: 0.20403453707695007
Validation loss: 1.6830467152339157

Epoch: 6| Step: 8
Training loss: 0.5846660137176514
Validation loss: 1.714818218702911

Epoch: 6| Step: 9
Training loss: 0.23340702056884766
Validation loss: 1.6837277796960646

Epoch: 6| Step: 10
Training loss: 0.4245111346244812
Validation loss: 1.7400817127637966

Epoch: 6| Step: 11
Training loss: 0.5021231770515442
Validation loss: 1.7136370904984013

Epoch: 6| Step: 12
Training loss: 0.534788191318512
Validation loss: 1.7488850970422067

Epoch: 6| Step: 13
Training loss: 0.1487123668193817
Validation loss: 1.721863615897394

Epoch: 248| Step: 0
Training loss: 0.623422384262085
Validation loss: 1.7066212597713675

Epoch: 6| Step: 1
Training loss: 0.4391738772392273
Validation loss: 1.7311890330365909

Epoch: 6| Step: 2
Training loss: 0.39227765798568726
Validation loss: 1.7334411144256592

Epoch: 6| Step: 3
Training loss: 0.2650664746761322
Validation loss: 1.7260016190108431

Epoch: 6| Step: 4
Training loss: 0.3088394105434418
Validation loss: 1.707552581705073

Epoch: 6| Step: 5
Training loss: 0.30677950382232666
Validation loss: 1.7138491612608715

Epoch: 6| Step: 6
Training loss: 0.4401957094669342
Validation loss: 1.7105420404864895

Epoch: 6| Step: 7
Training loss: 0.49244552850723267
Validation loss: 1.7243189081068961

Epoch: 6| Step: 8
Training loss: 0.31696009635925293
Validation loss: 1.7695073940420663

Epoch: 6| Step: 9
Training loss: 0.3794802725315094
Validation loss: 1.7803260036694106

Epoch: 6| Step: 10
Training loss: 0.4900270700454712
Validation loss: 1.7909775498092815

Epoch: 6| Step: 11
Training loss: 0.2973097562789917
Validation loss: 1.8053188349611016

Epoch: 6| Step: 12
Training loss: 0.36034101247787476
Validation loss: 1.8164150227782547

Epoch: 6| Step: 13
Training loss: 0.47296592593193054
Validation loss: 1.8314807773918234

Epoch: 249| Step: 0
Training loss: 0.31383511424064636
Validation loss: 1.8271844310145224

Epoch: 6| Step: 1
Training loss: 0.2654893696308136
Validation loss: 1.7959570089975994

Epoch: 6| Step: 2
Training loss: 0.4914209544658661
Validation loss: 1.8054050463502125

Epoch: 6| Step: 3
Training loss: 0.20865753293037415
Validation loss: 1.7663036110580608

Epoch: 6| Step: 4
Training loss: 0.499724805355072
Validation loss: 1.7667789741228985

Epoch: 6| Step: 5
Training loss: 0.6586802005767822
Validation loss: 1.7661474930342806

Epoch: 6| Step: 6
Training loss: 0.3502904176712036
Validation loss: 1.7680160871116064

Epoch: 6| Step: 7
Training loss: 0.3218761086463928
Validation loss: 1.7637562841497443

Epoch: 6| Step: 8
Training loss: 0.6249094605445862
Validation loss: 1.7390243609746296

Epoch: 6| Step: 9
Training loss: 0.4180104732513428
Validation loss: 1.7304700318203177

Epoch: 6| Step: 10
Training loss: 0.4286039471626282
Validation loss: 1.7340003726302937

Epoch: 6| Step: 11
Training loss: 0.564083993434906
Validation loss: 1.738346029353398

Epoch: 6| Step: 12
Training loss: 0.3155266046524048
Validation loss: 1.760421460674655

Epoch: 6| Step: 13
Training loss: 0.1349778175354004
Validation loss: 1.7939749661312308

Epoch: 250| Step: 0
Training loss: 0.1535961925983429
Validation loss: 1.8129652879571403

Epoch: 6| Step: 1
Training loss: 0.46092382073402405
Validation loss: 1.841274776766377

Epoch: 6| Step: 2
Training loss: 0.4093799293041229
Validation loss: 1.850570745365594

Epoch: 6| Step: 3
Training loss: 0.17318877577781677
Validation loss: 1.8328867727710354

Epoch: 6| Step: 4
Training loss: 0.305630624294281
Validation loss: 1.8295489536818637

Epoch: 6| Step: 5
Training loss: 0.40709054470062256
Validation loss: 1.7852251683512042

Epoch: 6| Step: 6
Training loss: 0.29313546419143677
Validation loss: 1.7400713889829573

Epoch: 6| Step: 7
Training loss: 0.5441233515739441
Validation loss: 1.7341929610057543

Epoch: 6| Step: 8
Training loss: 0.33189401030540466
Validation loss: 1.6905351646484867

Epoch: 6| Step: 9
Training loss: 0.3718927204608917
Validation loss: 1.676941164078251

Epoch: 6| Step: 10
Training loss: 0.41419437527656555
Validation loss: 1.6658297020901915

Epoch: 6| Step: 11
Training loss: 0.5073436498641968
Validation loss: 1.6980546251420052

Epoch: 6| Step: 12
Training loss: 0.4070685803890228
Validation loss: 1.6698554715802592

Epoch: 6| Step: 13
Training loss: 0.46210554242134094
Validation loss: 1.7038652743062666

Epoch: 251| Step: 0
Training loss: 0.34047776460647583
Validation loss: 1.7082855163082

Epoch: 6| Step: 1
Training loss: 0.3488503098487854
Validation loss: 1.7344312155118553

Epoch: 6| Step: 2
Training loss: 0.49414724111557007
Validation loss: 1.7480754660021873

Epoch: 6| Step: 3
Training loss: 0.3033124804496765
Validation loss: 1.7276081308241813

Epoch: 6| Step: 4
Training loss: 0.3895624577999115
Validation loss: 1.7499763978424894

Epoch: 6| Step: 5
Training loss: 0.2861161530017853
Validation loss: 1.7380497993961457

Epoch: 6| Step: 6
Training loss: 0.27413997054100037
Validation loss: 1.7217547739705732

Epoch: 6| Step: 7
Training loss: 0.4550444483757019
Validation loss: 1.7003980823742446

Epoch: 6| Step: 8
Training loss: 0.3026655912399292
Validation loss: 1.7344006633245816

Epoch: 6| Step: 9
Training loss: 0.5998934507369995
Validation loss: 1.7242699438525784

Epoch: 6| Step: 10
Training loss: 0.0874108225107193
Validation loss: 1.75216963214259

Epoch: 6| Step: 11
Training loss: 0.36078962683677673
Validation loss: 1.750085453833303

Epoch: 6| Step: 12
Training loss: 0.4559151232242584
Validation loss: 1.7248461733582199

Epoch: 6| Step: 13
Training loss: 0.18822148442268372
Validation loss: 1.745267124586208

Epoch: 252| Step: 0
Training loss: 0.13904798030853271
Validation loss: 1.7284047513879754

Epoch: 6| Step: 1
Training loss: 0.40968984365463257
Validation loss: 1.7097652727557766

Epoch: 6| Step: 2
Training loss: 0.2985440492630005
Validation loss: 1.7375545911891486

Epoch: 6| Step: 3
Training loss: 0.46960335969924927
Validation loss: 1.7334498256765387

Epoch: 6| Step: 4
Training loss: 0.2458043098449707
Validation loss: 1.7326884628624044

Epoch: 6| Step: 5
Training loss: 0.4417476952075958
Validation loss: 1.7787462934370963

Epoch: 6| Step: 6
Training loss: 0.44081631302833557
Validation loss: 1.784910119989867

Epoch: 6| Step: 7
Training loss: 0.2667419910430908
Validation loss: 1.8023913701375325

Epoch: 6| Step: 8
Training loss: 0.4150663912296295
Validation loss: 1.838078583440473

Epoch: 6| Step: 9
Training loss: 0.6812507510185242
Validation loss: 1.8536312118653329

Epoch: 6| Step: 10
Training loss: 0.3273383378982544
Validation loss: 1.8195941191847607

Epoch: 6| Step: 11
Training loss: 0.2268373966217041
Validation loss: 1.781358350348729

Epoch: 6| Step: 12
Training loss: 0.4159484803676605
Validation loss: 1.770467855597055

Epoch: 6| Step: 13
Training loss: 0.3740668296813965
Validation loss: 1.7732105665309454

Epoch: 253| Step: 0
Training loss: 0.4092843532562256
Validation loss: 1.7416612114957584

Epoch: 6| Step: 1
Training loss: 0.5781588554382324
Validation loss: 1.7357157353431947

Epoch: 6| Step: 2
Training loss: 0.2857770025730133
Validation loss: 1.7415452746934788

Epoch: 6| Step: 3
Training loss: 0.2506553530693054
Validation loss: 1.730458333928098

Epoch: 6| Step: 4
Training loss: 0.38886892795562744
Validation loss: 1.7115060001291253

Epoch: 6| Step: 5
Training loss: 0.3267326056957245
Validation loss: 1.7145991158741776

Epoch: 6| Step: 6
Training loss: 0.4371384382247925
Validation loss: 1.7173254310443837

Epoch: 6| Step: 7
Training loss: 0.13801945745944977
Validation loss: 1.7250717109249485

Epoch: 6| Step: 8
Training loss: 0.39026910066604614
Validation loss: 1.7132830465993574

Epoch: 6| Step: 9
Training loss: 0.540364146232605
Validation loss: 1.7385195711607575

Epoch: 6| Step: 10
Training loss: 0.2854216396808624
Validation loss: 1.7412411628230926

Epoch: 6| Step: 11
Training loss: 0.3894028067588806
Validation loss: 1.7420683291650587

Epoch: 6| Step: 12
Training loss: 0.3108697831630707
Validation loss: 1.7158190883615965

Epoch: 6| Step: 13
Training loss: 0.2839185297489166
Validation loss: 1.698372620408253

Epoch: 254| Step: 0
Training loss: 0.14094524085521698
Validation loss: 1.7363803796870734

Epoch: 6| Step: 1
Training loss: 0.47308507561683655
Validation loss: 1.732189328439774

Epoch: 6| Step: 2
Training loss: 0.4294922947883606
Validation loss: 1.7325591182196012

Epoch: 6| Step: 3
Training loss: 0.39736515283584595
Validation loss: 1.7263058680360035

Epoch: 6| Step: 4
Training loss: 0.40808436274528503
Validation loss: 1.7716220899294781

Epoch: 6| Step: 5
Training loss: 0.1578729748725891
Validation loss: 1.7525163696658226

Epoch: 6| Step: 6
Training loss: 0.22822578251361847
Validation loss: 1.743242572712642

Epoch: 6| Step: 7
Training loss: 0.3327847719192505
Validation loss: 1.7326439926701207

Epoch: 6| Step: 8
Training loss: 0.2152765989303589
Validation loss: 1.6978792593043337

Epoch: 6| Step: 9
Training loss: 0.14963579177856445
Validation loss: 1.692751464023385

Epoch: 6| Step: 10
Training loss: 0.4470770061016083
Validation loss: 1.692265925868865

Epoch: 6| Step: 11
Training loss: 0.40442192554473877
Validation loss: 1.7040128432294375

Epoch: 6| Step: 12
Training loss: 0.3321252763271332
Validation loss: 1.695762857314079

Epoch: 6| Step: 13
Training loss: 0.7436644434928894
Validation loss: 1.6727274156385852

Epoch: 255| Step: 0
Training loss: 0.41143324971199036
Validation loss: 1.706477572841029

Epoch: 6| Step: 1
Training loss: 0.21650931239128113
Validation loss: 1.7317160073147024

Epoch: 6| Step: 2
Training loss: 0.24018365144729614
Validation loss: 1.7222738804355744

Epoch: 6| Step: 3
Training loss: 0.6098955869674683
Validation loss: 1.7345661988822363

Epoch: 6| Step: 4
Training loss: 0.19554361701011658
Validation loss: 1.7326902651017713

Epoch: 6| Step: 5
Training loss: 0.37727054953575134
Validation loss: 1.7429587264214792

Epoch: 6| Step: 6
Training loss: 0.1755242496728897
Validation loss: 1.732274104190129

Epoch: 6| Step: 7
Training loss: 0.4949464201927185
Validation loss: 1.7073362552991478

Epoch: 6| Step: 8
Training loss: 0.2921941876411438
Validation loss: 1.7266063151821014

Epoch: 6| Step: 9
Training loss: 0.501669704914093
Validation loss: 1.7378319130148938

Epoch: 6| Step: 10
Training loss: 0.2492857575416565
Validation loss: 1.7384648848605413

Epoch: 6| Step: 11
Training loss: 0.18386784195899963
Validation loss: 1.7481339964815366

Epoch: 6| Step: 12
Training loss: 0.2591729462146759
Validation loss: 1.7644246803816928

Epoch: 6| Step: 13
Training loss: 0.1922273188829422
Validation loss: 1.754948721137098

Epoch: 256| Step: 0
Training loss: 0.35077714920043945
Validation loss: 1.8025285813116259

Epoch: 6| Step: 1
Training loss: 0.14510370790958405
Validation loss: 1.8038085417080951

Epoch: 6| Step: 2
Training loss: 0.4893076419830322
Validation loss: 1.7897310205685195

Epoch: 6| Step: 3
Training loss: 0.2955288887023926
Validation loss: 1.7871430022742159

Epoch: 6| Step: 4
Training loss: 0.11026296764612198
Validation loss: 1.7317499499167166

Epoch: 6| Step: 5
Training loss: 0.252380907535553
Validation loss: 1.719330435158104

Epoch: 6| Step: 6
Training loss: 0.3068372905254364
Validation loss: 1.7425753993372763

Epoch: 6| Step: 7
Training loss: 0.5259979963302612
Validation loss: 1.728220526890088

Epoch: 6| Step: 8
Training loss: 0.6467880010604858
Validation loss: 1.704471072842998

Epoch: 6| Step: 9
Training loss: 0.30484360456466675
Validation loss: 1.712343345406235

Epoch: 6| Step: 10
Training loss: 0.3520001769065857
Validation loss: 1.7242215474446614

Epoch: 6| Step: 11
Training loss: 0.2214459776878357
Validation loss: 1.6950499421806746

Epoch: 6| Step: 12
Training loss: 0.3590872585773468
Validation loss: 1.7082450697498937

Epoch: 6| Step: 13
Training loss: 0.6633614897727966
Validation loss: 1.7385817996917232

Epoch: 257| Step: 0
Training loss: 0.21392154693603516
Validation loss: 1.7424202272968907

Epoch: 6| Step: 1
Training loss: 0.46600407361984253
Validation loss: 1.7616254116899224

Epoch: 6| Step: 2
Training loss: 0.4135357439517975
Validation loss: 1.7697013526834466

Epoch: 6| Step: 3
Training loss: 0.41761308908462524
Validation loss: 1.7749267829361783

Epoch: 6| Step: 4
Training loss: 0.42892974615097046
Validation loss: 1.7932415880182737

Epoch: 6| Step: 5
Training loss: 0.3420477509498596
Validation loss: 1.7850449008326377

Epoch: 6| Step: 6
Training loss: 0.11376477777957916
Validation loss: 1.767253582195569

Epoch: 6| Step: 7
Training loss: 0.6036848425865173
Validation loss: 1.7699378203320246

Epoch: 6| Step: 8
Training loss: 0.23165979981422424
Validation loss: 1.7728273586560321

Epoch: 6| Step: 9
Training loss: 0.35436251759529114
Validation loss: 1.7306849200238463

Epoch: 6| Step: 10
Training loss: 0.3074862062931061
Validation loss: 1.72004912489204

Epoch: 6| Step: 11
Training loss: 0.4394291043281555
Validation loss: 1.7268609257154568

Epoch: 6| Step: 12
Training loss: 0.2569175660610199
Validation loss: 1.7015686791430238

Epoch: 6| Step: 13
Training loss: 0.37630560994148254
Validation loss: 1.6980158321319088

Epoch: 258| Step: 0
Training loss: 0.49446454644203186
Validation loss: 1.714035202098149

Epoch: 6| Step: 1
Training loss: 0.2682265639305115
Validation loss: 1.708126619297971

Epoch: 6| Step: 2
Training loss: 0.45958489179611206
Validation loss: 1.7415567149398148

Epoch: 6| Step: 3
Training loss: 0.3259204030036926
Validation loss: 1.7338950031547136

Epoch: 6| Step: 4
Training loss: 0.3366020619869232
Validation loss: 1.7438821946420977

Epoch: 6| Step: 5
Training loss: 0.3237774968147278
Validation loss: 1.7633912281323505

Epoch: 6| Step: 6
Training loss: 0.28162020444869995
Validation loss: 1.724735386909977

Epoch: 6| Step: 7
Training loss: 0.4760946035385132
Validation loss: 1.731119982657894

Epoch: 6| Step: 8
Training loss: 0.5011716485023499
Validation loss: 1.7235806988131614

Epoch: 6| Step: 9
Training loss: 0.32376721501350403
Validation loss: 1.7203422284895373

Epoch: 6| Step: 10
Training loss: 0.35363346338272095
Validation loss: 1.7333523458050144

Epoch: 6| Step: 11
Training loss: 0.23049582540988922
Validation loss: 1.718074111528294

Epoch: 6| Step: 12
Training loss: 0.29168903827667236
Validation loss: 1.7354915392014287

Epoch: 6| Step: 13
Training loss: 0.45140737295150757
Validation loss: 1.7610607224126016

Epoch: 259| Step: 0
Training loss: 0.2221239060163498
Validation loss: 1.774770785403508

Epoch: 6| Step: 1
Training loss: 0.24175912141799927
Validation loss: 1.7822467216881372

Epoch: 6| Step: 2
Training loss: 0.2751425504684448
Validation loss: 1.8264775801730413

Epoch: 6| Step: 3
Training loss: 0.3959220051765442
Validation loss: 1.8216964134605982

Epoch: 6| Step: 4
Training loss: 0.39846688508987427
Validation loss: 1.7990740140279133

Epoch: 6| Step: 5
Training loss: 0.3499603271484375
Validation loss: 1.8071345257502731

Epoch: 6| Step: 6
Training loss: 0.3537236154079437
Validation loss: 1.7913277097927627

Epoch: 6| Step: 7
Training loss: 0.2650464177131653
Validation loss: 1.7802971063121673

Epoch: 6| Step: 8
Training loss: 0.4329920709133148
Validation loss: 1.7786628994890439

Epoch: 6| Step: 9
Training loss: 0.9293923377990723
Validation loss: 1.7519680761521863

Epoch: 6| Step: 10
Training loss: 0.3061382472515106
Validation loss: 1.7370624362781484

Epoch: 6| Step: 11
Training loss: 0.19161488115787506
Validation loss: 1.7011526714089096

Epoch: 6| Step: 12
Training loss: 0.3352241516113281
Validation loss: 1.6991963437808457

Epoch: 6| Step: 13
Training loss: 0.4728460907936096
Validation loss: 1.6925505617613434

Epoch: 260| Step: 0
Training loss: 0.35744762420654297
Validation loss: 1.7029334319535123

Epoch: 6| Step: 1
Training loss: 0.5116395354270935
Validation loss: 1.7509489367085118

Epoch: 6| Step: 2
Training loss: 0.3994162380695343
Validation loss: 1.7847704400298416

Epoch: 6| Step: 3
Training loss: 0.5236057639122009
Validation loss: 1.828736227045777

Epoch: 6| Step: 4
Training loss: 0.4497184157371521
Validation loss: 1.8648998724517

Epoch: 6| Step: 5
Training loss: 0.22847706079483032
Validation loss: 1.8549949328104656

Epoch: 6| Step: 6
Training loss: 0.44857388734817505
Validation loss: 1.8415600215235064

Epoch: 6| Step: 7
Training loss: 0.3070552945137024
Validation loss: 1.8394774929169686

Epoch: 6| Step: 8
Training loss: 0.2569989562034607
Validation loss: 1.8358684239848968

Epoch: 6| Step: 9
Training loss: 0.5402160882949829
Validation loss: 1.815360188484192

Epoch: 6| Step: 10
Training loss: 0.4636825621128082
Validation loss: 1.7609416964233562

Epoch: 6| Step: 11
Training loss: 0.16885486245155334
Validation loss: 1.7671108027940154

Epoch: 6| Step: 12
Training loss: 0.2870824337005615
Validation loss: 1.7572866485964866

Epoch: 6| Step: 13
Training loss: 0.28579139709472656
Validation loss: 1.721016546731354

Epoch: 261| Step: 0
Training loss: 0.36854004859924316
Validation loss: 1.695162611622964

Epoch: 6| Step: 1
Training loss: 0.18013650178909302
Validation loss: 1.7134743159817112

Epoch: 6| Step: 2
Training loss: 0.3267403542995453
Validation loss: 1.735546991389285

Epoch: 6| Step: 3
Training loss: 0.5402236580848694
Validation loss: 1.7334109660117858

Epoch: 6| Step: 4
Training loss: 0.2228088676929474
Validation loss: 1.7504900834893669

Epoch: 6| Step: 5
Training loss: 0.44117921590805054
Validation loss: 1.7447584136839835

Epoch: 6| Step: 6
Training loss: 0.2480309158563614
Validation loss: 1.7589240522794827

Epoch: 6| Step: 7
Training loss: 0.4186675548553467
Validation loss: 1.7361262677818217

Epoch: 6| Step: 8
Training loss: 0.5272243022918701
Validation loss: 1.7416130765791862

Epoch: 6| Step: 9
Training loss: 0.2689948081970215
Validation loss: 1.7121528989525252

Epoch: 6| Step: 10
Training loss: 0.3574075698852539
Validation loss: 1.6972040027700446

Epoch: 6| Step: 11
Training loss: 0.2502811551094055
Validation loss: 1.7028587108017297

Epoch: 6| Step: 12
Training loss: 0.13300693035125732
Validation loss: 1.7135495895980506

Epoch: 6| Step: 13
Training loss: 0.27996042370796204
Validation loss: 1.73148202255208

Epoch: 262| Step: 0
Training loss: 0.5474609136581421
Validation loss: 1.7334103712471582

Epoch: 6| Step: 1
Training loss: 0.4070659875869751
Validation loss: 1.724329174205821

Epoch: 6| Step: 2
Training loss: 0.21622340381145477
Validation loss: 1.699847775120889

Epoch: 6| Step: 3
Training loss: 0.4211359918117523
Validation loss: 1.7126393407903693

Epoch: 6| Step: 4
Training loss: 0.5656840205192566
Validation loss: 1.7253033653382333

Epoch: 6| Step: 5
Training loss: 0.3298254907131195
Validation loss: 1.7642286323731946

Epoch: 6| Step: 6
Training loss: 0.4798277020454407
Validation loss: 1.7662603111677273

Epoch: 6| Step: 7
Training loss: 0.40966716408729553
Validation loss: 1.7626908415107316

Epoch: 6| Step: 8
Training loss: 0.5640159249305725
Validation loss: 1.738524199813925

Epoch: 6| Step: 9
Training loss: 0.2837812304496765
Validation loss: 1.7076205822729296

Epoch: 6| Step: 10
Training loss: 0.4105403423309326
Validation loss: 1.6834167306141188

Epoch: 6| Step: 11
Training loss: 0.14252237975597382
Validation loss: 1.6826344549015004

Epoch: 6| Step: 12
Training loss: 0.25771385431289673
Validation loss: 1.6615533059643162

Epoch: 6| Step: 13
Training loss: 0.19306820631027222
Validation loss: 1.7040870458849016

Epoch: 263| Step: 0
Training loss: 0.31210288405418396
Validation loss: 1.7083295634997788

Epoch: 6| Step: 1
Training loss: 0.7914049029350281
Validation loss: 1.7473884269755373

Epoch: 6| Step: 2
Training loss: 0.36754828691482544
Validation loss: 1.710505941862701

Epoch: 6| Step: 3
Training loss: 0.5526325702667236
Validation loss: 1.708666439979307

Epoch: 6| Step: 4
Training loss: 0.3056327998638153
Validation loss: 1.6625552241520216

Epoch: 6| Step: 5
Training loss: 0.17995500564575195
Validation loss: 1.6627481855371946

Epoch: 6| Step: 6
Training loss: 0.2532409131526947
Validation loss: 1.7021105956005793

Epoch: 6| Step: 7
Training loss: 0.41310083866119385
Validation loss: 1.7361274791020218

Epoch: 6| Step: 8
Training loss: 0.4920862317085266
Validation loss: 1.801034653058616

Epoch: 6| Step: 9
Training loss: 0.3990936875343323
Validation loss: 1.7823176589063419

Epoch: 6| Step: 10
Training loss: 0.4091726243495941
Validation loss: 1.7621550534361152

Epoch: 6| Step: 11
Training loss: 0.33460530638694763
Validation loss: 1.7488382554823352

Epoch: 6| Step: 12
Training loss: 0.1433846652507782
Validation loss: 1.7379699201994045

Epoch: 6| Step: 13
Training loss: 0.16450361907482147
Validation loss: 1.7319631371446835

Epoch: 264| Step: 0
Training loss: 0.49080514907836914
Validation loss: 1.7190467747308875

Epoch: 6| Step: 1
Training loss: 0.331218957901001
Validation loss: 1.7458710350016111

Epoch: 6| Step: 2
Training loss: 0.49268972873687744
Validation loss: 1.7285114924112956

Epoch: 6| Step: 3
Training loss: 0.2964898347854614
Validation loss: 1.7457953345391057

Epoch: 6| Step: 4
Training loss: 0.4587433636188507
Validation loss: 1.7397922815815094

Epoch: 6| Step: 5
Training loss: 0.24792355298995972
Validation loss: 1.7630282217456448

Epoch: 6| Step: 6
Training loss: 0.20809414982795715
Validation loss: 1.7517777360895628

Epoch: 6| Step: 7
Training loss: 0.5352543592453003
Validation loss: 1.7709139623949606

Epoch: 6| Step: 8
Training loss: 0.540318489074707
Validation loss: 1.746869114137465

Epoch: 6| Step: 9
Training loss: 0.34477847814559937
Validation loss: 1.7396777035087667

Epoch: 6| Step: 10
Training loss: 0.2719216048717499
Validation loss: 1.7485035286154798

Epoch: 6| Step: 11
Training loss: 0.19907315075397491
Validation loss: 1.7435982240143644

Epoch: 6| Step: 12
Training loss: 0.30724987387657166
Validation loss: 1.7479459784364189

Epoch: 6| Step: 13
Training loss: 0.21636594831943512
Validation loss: 1.752620207366123

Epoch: 265| Step: 0
Training loss: 0.31467390060424805
Validation loss: 1.7218889626123572

Epoch: 6| Step: 1
Training loss: 0.5795153379440308
Validation loss: 1.7027369519715667

Epoch: 6| Step: 2
Training loss: 0.36437129974365234
Validation loss: 1.6965846477016326

Epoch: 6| Step: 3
Training loss: 0.27529245615005493
Validation loss: 1.6805495498000935

Epoch: 6| Step: 4
Training loss: 0.2854366600513458
Validation loss: 1.6975569212308494

Epoch: 6| Step: 5
Training loss: 0.19786390662193298
Validation loss: 1.694862965614565

Epoch: 6| Step: 6
Training loss: 0.3116872310638428
Validation loss: 1.7317681927834787

Epoch: 6| Step: 7
Training loss: 0.4182581305503845
Validation loss: 1.7141526424756615

Epoch: 6| Step: 8
Training loss: 0.1966400444507599
Validation loss: 1.7138568291100122

Epoch: 6| Step: 9
Training loss: 0.2212454378604889
Validation loss: 1.6888282965588313

Epoch: 6| Step: 10
Training loss: 0.3124007284641266
Validation loss: 1.719852484682555

Epoch: 6| Step: 11
Training loss: 0.3300682604312897
Validation loss: 1.6896166186178885

Epoch: 6| Step: 12
Training loss: 0.2161847949028015
Validation loss: 1.6738892139927033

Epoch: 6| Step: 13
Training loss: 0.615710973739624
Validation loss: 1.6896434368625763

Epoch: 266| Step: 0
Training loss: 0.1510569155216217
Validation loss: 1.712032659720349

Epoch: 6| Step: 1
Training loss: 0.40010249614715576
Validation loss: 1.6865554458351546

Epoch: 6| Step: 2
Training loss: 0.28483879566192627
Validation loss: 1.7091049122554

Epoch: 6| Step: 3
Training loss: 0.32424822449684143
Validation loss: 1.7074297589640464

Epoch: 6| Step: 4
Training loss: 0.5955395102500916
Validation loss: 1.7328835328420003

Epoch: 6| Step: 5
Training loss: 0.35256263613700867
Validation loss: 1.751818847912614

Epoch: 6| Step: 6
Training loss: 0.37731486558914185
Validation loss: 1.7617822116421116

Epoch: 6| Step: 7
Training loss: 0.1891404539346695
Validation loss: 1.7652103977818643

Epoch: 6| Step: 8
Training loss: 0.33047592639923096
Validation loss: 1.755673954563756

Epoch: 6| Step: 9
Training loss: 0.2091846764087677
Validation loss: 1.7287923738520632

Epoch: 6| Step: 10
Training loss: 0.302822470664978
Validation loss: 1.7288813052638885

Epoch: 6| Step: 11
Training loss: 0.20536041259765625
Validation loss: 1.6950770321712698

Epoch: 6| Step: 12
Training loss: 0.24785743653774261
Validation loss: 1.6769034708699873

Epoch: 6| Step: 13
Training loss: 0.6901801824569702
Validation loss: 1.695736926089051

Epoch: 267| Step: 0
Training loss: 0.4340291917324066
Validation loss: 1.6992944876352947

Epoch: 6| Step: 1
Training loss: 0.3205662965774536
Validation loss: 1.6737864876306185

Epoch: 6| Step: 2
Training loss: 0.29639142751693726
Validation loss: 1.6884723914566862

Epoch: 6| Step: 3
Training loss: 0.34588533639907837
Validation loss: 1.7054471123603083

Epoch: 6| Step: 4
Training loss: 0.2524692416191101
Validation loss: 1.6853530644088663

Epoch: 6| Step: 5
Training loss: 0.31386062502861023
Validation loss: 1.7041297048650763

Epoch: 6| Step: 6
Training loss: 0.447206974029541
Validation loss: 1.7056973531682005

Epoch: 6| Step: 7
Training loss: 0.1417236030101776
Validation loss: 1.7404254251910793

Epoch: 6| Step: 8
Training loss: 0.18776416778564453
Validation loss: 1.75869571457627

Epoch: 6| Step: 9
Training loss: 0.4152846932411194
Validation loss: 1.7645660625991

Epoch: 6| Step: 10
Training loss: 0.3433988094329834
Validation loss: 1.7394810440719768

Epoch: 6| Step: 11
Training loss: 0.3354906737804413
Validation loss: 1.756558754110849

Epoch: 6| Step: 12
Training loss: 0.2148919701576233
Validation loss: 1.720301846022247

Epoch: 6| Step: 13
Training loss: 0.13801881670951843
Validation loss: 1.71744716295632

Epoch: 268| Step: 0
Training loss: 0.23745191097259521
Validation loss: 1.7367062876301427

Epoch: 6| Step: 1
Training loss: 0.24408656358718872
Validation loss: 1.730457862218221

Epoch: 6| Step: 2
Training loss: 0.203952357172966
Validation loss: 1.7176686217707973

Epoch: 6| Step: 3
Training loss: 0.2604335844516754
Validation loss: 1.6675303238694386

Epoch: 6| Step: 4
Training loss: 0.33864495158195496
Validation loss: 1.6772837690127793

Epoch: 6| Step: 5
Training loss: 0.2944560945034027
Validation loss: 1.6722992030523156

Epoch: 6| Step: 6
Training loss: 0.32834070920944214
Validation loss: 1.667331172573951

Epoch: 6| Step: 7
Training loss: 0.3634408116340637
Validation loss: 1.671046309573676

Epoch: 6| Step: 8
Training loss: 0.5418505668640137
Validation loss: 1.6877383083425543

Epoch: 6| Step: 9
Training loss: 0.14194941520690918
Validation loss: 1.6678690794975526

Epoch: 6| Step: 10
Training loss: 0.15618285536766052
Validation loss: 1.679603474114531

Epoch: 6| Step: 11
Training loss: 0.45686468482017517
Validation loss: 1.7195878246779084

Epoch: 6| Step: 12
Training loss: 0.1990644782781601
Validation loss: 1.7255375603193879

Epoch: 6| Step: 13
Training loss: 0.5242598652839661
Validation loss: 1.7252977073833506

Epoch: 269| Step: 0
Training loss: 0.2996233105659485
Validation loss: 1.7253130353907102

Epoch: 6| Step: 1
Training loss: 0.47063112258911133
Validation loss: 1.7120082263023622

Epoch: 6| Step: 2
Training loss: 0.4005727171897888
Validation loss: 1.6970373033195414

Epoch: 6| Step: 3
Training loss: 0.23260702192783356
Validation loss: 1.676200310389201

Epoch: 6| Step: 4
Training loss: 0.25558286905288696
Validation loss: 1.6542430231648106

Epoch: 6| Step: 5
Training loss: 0.32796424627304077
Validation loss: 1.6574978700248144

Epoch: 6| Step: 6
Training loss: 0.32024186849594116
Validation loss: 1.6544467736315984

Epoch: 6| Step: 7
Training loss: 0.24037188291549683
Validation loss: 1.6367395270255305

Epoch: 6| Step: 8
Training loss: 0.19662883877754211
Validation loss: 1.6659562331373974

Epoch: 6| Step: 9
Training loss: 0.2941707670688629
Validation loss: 1.670946221197805

Epoch: 6| Step: 10
Training loss: 0.12112464755773544
Validation loss: 1.6577613789548156

Epoch: 6| Step: 11
Training loss: 0.3856756091117859
Validation loss: 1.6602371713166595

Epoch: 6| Step: 12
Training loss: 0.2821926772594452
Validation loss: 1.6979346493239045

Epoch: 6| Step: 13
Training loss: 0.49235236644744873
Validation loss: 1.6466471225984636

Epoch: 270| Step: 0
Training loss: 0.3538087010383606
Validation loss: 1.6587260743623138

Epoch: 6| Step: 1
Training loss: 0.23648890852928162
Validation loss: 1.6674164469524095

Epoch: 6| Step: 2
Training loss: 0.3190702497959137
Validation loss: 1.6667198340098064

Epoch: 6| Step: 3
Training loss: 0.10837382078170776
Validation loss: 1.6425147312943653

Epoch: 6| Step: 4
Training loss: 0.1854393482208252
Validation loss: 1.6516970088404994

Epoch: 6| Step: 5
Training loss: 0.4411976933479309
Validation loss: 1.6598299575108353

Epoch: 6| Step: 6
Training loss: 0.3575618267059326
Validation loss: 1.6765331824620564

Epoch: 6| Step: 7
Training loss: 0.18678294122219086
Validation loss: 1.6751962887343539

Epoch: 6| Step: 8
Training loss: 0.7243075966835022
Validation loss: 1.6639811710644794

Epoch: 6| Step: 9
Training loss: 0.35175204277038574
Validation loss: 1.6644950566753265

Epoch: 6| Step: 10
Training loss: 0.2552866041660309
Validation loss: 1.628089044683723

Epoch: 6| Step: 11
Training loss: 0.34422767162323
Validation loss: 1.6427795502447313

Epoch: 6| Step: 12
Training loss: 0.2057361900806427
Validation loss: 1.6530652302567677

Epoch: 6| Step: 13
Training loss: 0.23100394010543823
Validation loss: 1.6708532776883853

Epoch: 271| Step: 0
Training loss: 0.33443012833595276
Validation loss: 1.7016574644273328

Epoch: 6| Step: 1
Training loss: 0.19970260560512543
Validation loss: 1.6701089182207662

Epoch: 6| Step: 2
Training loss: 0.6552598476409912
Validation loss: 1.6739578939253283

Epoch: 6| Step: 3
Training loss: 0.2533070147037506
Validation loss: 1.6622625333006664

Epoch: 6| Step: 4
Training loss: 0.31575334072113037
Validation loss: 1.6548459811877179

Epoch: 6| Step: 5
Training loss: 0.2454996109008789
Validation loss: 1.6507818378427976

Epoch: 6| Step: 6
Training loss: 0.20861583948135376
Validation loss: 1.690057013624458

Epoch: 6| Step: 7
Training loss: 0.21562626957893372
Validation loss: 1.6962032728297736

Epoch: 6| Step: 8
Training loss: 0.41796451807022095
Validation loss: 1.7083714239058956

Epoch: 6| Step: 9
Training loss: 0.3686349093914032
Validation loss: 1.7184113892175819

Epoch: 6| Step: 10
Training loss: 0.47847282886505127
Validation loss: 1.6930679377689157

Epoch: 6| Step: 11
Training loss: 0.31792646646499634
Validation loss: 1.662005788536482

Epoch: 6| Step: 12
Training loss: 0.2486964613199234
Validation loss: 1.5986564620848625

Epoch: 6| Step: 13
Training loss: 0.2631612718105316
Validation loss: 1.6015927330140145

Epoch: 272| Step: 0
Training loss: 0.27040964365005493
Validation loss: 1.6139330223042478

Epoch: 6| Step: 1
Training loss: 0.344231516122818
Validation loss: 1.5968644695897256

Epoch: 6| Step: 2
Training loss: 0.1734265685081482
Validation loss: 1.5912430068498016

Epoch: 6| Step: 3
Training loss: 0.37968143820762634
Validation loss: 1.6125918101238947

Epoch: 6| Step: 4
Training loss: 0.30110251903533936
Validation loss: 1.6345557153865855

Epoch: 6| Step: 5
Training loss: 0.3504921793937683
Validation loss: 1.6669813894456433

Epoch: 6| Step: 6
Training loss: 0.539609432220459
Validation loss: 1.6696423907433786

Epoch: 6| Step: 7
Training loss: 0.4880295693874359
Validation loss: 1.7181637594776769

Epoch: 6| Step: 8
Training loss: 0.5383784174919128
Validation loss: 1.7380005967232488

Epoch: 6| Step: 9
Training loss: 0.33589598536491394
Validation loss: 1.73072136217548

Epoch: 6| Step: 10
Training loss: 0.349580854177475
Validation loss: 1.7581244220015824

Epoch: 6| Step: 11
Training loss: 0.2972874045372009
Validation loss: 1.7328446065225909

Epoch: 6| Step: 12
Training loss: 0.44342491030693054
Validation loss: 1.7285657249471194

Epoch: 6| Step: 13
Training loss: 0.3255959153175354
Validation loss: 1.689493243412305

Epoch: 273| Step: 0
Training loss: 0.2663631737232208
Validation loss: 1.6481904419519569

Epoch: 6| Step: 1
Training loss: 0.21323494613170624
Validation loss: 1.6111118101304578

Epoch: 6| Step: 2
Training loss: 0.17570239305496216
Validation loss: 1.6206323895403134

Epoch: 6| Step: 3
Training loss: 0.4467167854309082
Validation loss: 1.6575730167409426

Epoch: 6| Step: 4
Training loss: 0.48432204127311707
Validation loss: 1.678158301179127

Epoch: 6| Step: 5
Training loss: 0.6078649163246155
Validation loss: 1.7352921911465224

Epoch: 6| Step: 6
Training loss: 0.4165748953819275
Validation loss: 1.7237973341377832

Epoch: 6| Step: 7
Training loss: 0.6798303127288818
Validation loss: 1.735140214684189

Epoch: 6| Step: 8
Training loss: 0.6179967522621155
Validation loss: 1.7388084729512532

Epoch: 6| Step: 9
Training loss: 0.31526443362236023
Validation loss: 1.7647291639799714

Epoch: 6| Step: 10
Training loss: 0.1926804929971695
Validation loss: 1.7842298502563148

Epoch: 6| Step: 11
Training loss: 0.3566831946372986
Validation loss: 1.8053877968941965

Epoch: 6| Step: 12
Training loss: 0.31105920672416687
Validation loss: 1.7615074470479002

Epoch: 6| Step: 13
Training loss: 0.30213531851768494
Validation loss: 1.761790915202069

Epoch: 274| Step: 0
Training loss: 0.42954352498054504
Validation loss: 1.7391763143641974

Epoch: 6| Step: 1
Training loss: 0.42766574025154114
Validation loss: 1.7369030547398392

Epoch: 6| Step: 2
Training loss: 0.49512261152267456
Validation loss: 1.694519112187047

Epoch: 6| Step: 3
Training loss: 0.3408367335796356
Validation loss: 1.7023641601685555

Epoch: 6| Step: 4
Training loss: 0.26217466592788696
Validation loss: 1.6819588317666003

Epoch: 6| Step: 5
Training loss: 0.620464563369751
Validation loss: 1.6732679695211432

Epoch: 6| Step: 6
Training loss: 0.2010056972503662
Validation loss: 1.6474200371773011

Epoch: 6| Step: 7
Training loss: 0.3145613670349121
Validation loss: 1.6679697280289025

Epoch: 6| Step: 8
Training loss: 0.3239351511001587
Validation loss: 1.6785163943485548

Epoch: 6| Step: 9
Training loss: 0.2675696611404419
Validation loss: 1.6812763367929766

Epoch: 6| Step: 10
Training loss: 0.384574830532074
Validation loss: 1.6891363372084915

Epoch: 6| Step: 11
Training loss: 0.18214359879493713
Validation loss: 1.6747129463380384

Epoch: 6| Step: 12
Training loss: 0.24038201570510864
Validation loss: 1.691476809081211

Epoch: 6| Step: 13
Training loss: 0.3688420057296753
Validation loss: 1.6898479436033516

Epoch: 275| Step: 0
Training loss: 0.4529324173927307
Validation loss: 1.7256106048501947

Epoch: 6| Step: 1
Training loss: 0.40615114569664
Validation loss: 1.7412419524244083

Epoch: 6| Step: 2
Training loss: 0.4302169680595398
Validation loss: 1.7431793174436014

Epoch: 6| Step: 3
Training loss: 0.3556269109249115
Validation loss: 1.7406156319443897

Epoch: 6| Step: 4
Training loss: 0.4343002140522003
Validation loss: 1.7067615806415517

Epoch: 6| Step: 5
Training loss: 0.431479811668396
Validation loss: 1.728786232650921

Epoch: 6| Step: 6
Training loss: 0.1528884619474411
Validation loss: 1.6815175574312928

Epoch: 6| Step: 7
Training loss: 0.1163085401058197
Validation loss: 1.6841224175627514

Epoch: 6| Step: 8
Training loss: 0.305972695350647
Validation loss: 1.6188374334766018

Epoch: 6| Step: 9
Training loss: 0.31725773215293884
Validation loss: 1.6263690097357637

Epoch: 6| Step: 10
Training loss: 0.41137373447418213
Validation loss: 1.635262438046035

Epoch: 6| Step: 11
Training loss: 0.20757755637168884
Validation loss: 1.6337456703186035

Epoch: 6| Step: 12
Training loss: 0.4904918670654297
Validation loss: 1.6366372121277677

Epoch: 6| Step: 13
Training loss: 0.12281651049852371
Validation loss: 1.6532278548004806

Epoch: 276| Step: 0
Training loss: 0.2539442777633667
Validation loss: 1.6187324011197655

Epoch: 6| Step: 1
Training loss: 0.46848565340042114
Validation loss: 1.6505288488121443

Epoch: 6| Step: 2
Training loss: 0.26485952734947205
Validation loss: 1.6503465919084446

Epoch: 6| Step: 3
Training loss: 0.2753596603870392
Validation loss: 1.672664851270696

Epoch: 6| Step: 4
Training loss: 0.22767043113708496
Validation loss: 1.6617015036203528

Epoch: 6| Step: 5
Training loss: 0.19494156539440155
Validation loss: 1.670547894893154

Epoch: 6| Step: 6
Training loss: 0.354399174451828
Validation loss: 1.6920408279665056

Epoch: 6| Step: 7
Training loss: 0.28383108973503113
Validation loss: 1.715868701216995

Epoch: 6| Step: 8
Training loss: 0.22967052459716797
Validation loss: 1.7425242611156997

Epoch: 6| Step: 9
Training loss: 0.35474693775177
Validation loss: 1.7439742190863496

Epoch: 6| Step: 10
Training loss: 0.25126129388809204
Validation loss: 1.7249310747269662

Epoch: 6| Step: 11
Training loss: 0.2585906386375427
Validation loss: 1.7522091006719938

Epoch: 6| Step: 12
Training loss: 0.45531684160232544
Validation loss: 1.7206110646647792

Epoch: 6| Step: 13
Training loss: 0.14881852269172668
Validation loss: 1.6870315677376204

Epoch: 277| Step: 0
Training loss: 0.439839631319046
Validation loss: 1.679539406171409

Epoch: 6| Step: 1
Training loss: 0.19875575602054596
Validation loss: 1.666139151460381

Epoch: 6| Step: 2
Training loss: 0.24040737748146057
Validation loss: 1.648764144989752

Epoch: 6| Step: 3
Training loss: 0.5135161280632019
Validation loss: 1.638649885372449

Epoch: 6| Step: 4
Training loss: 0.3406985402107239
Validation loss: 1.668148281753704

Epoch: 6| Step: 5
Training loss: 0.25078657269477844
Validation loss: 1.6553341470738894

Epoch: 6| Step: 6
Training loss: 0.21023014187812805
Validation loss: 1.6773759959846415

Epoch: 6| Step: 7
Training loss: 0.35906782746315
Validation loss: 1.6894455904601722

Epoch: 6| Step: 8
Training loss: 0.35159042477607727
Validation loss: 1.7132050926967333

Epoch: 6| Step: 9
Training loss: 0.2210012674331665
Validation loss: 1.7154163673359861

Epoch: 6| Step: 10
Training loss: 0.31770631670951843
Validation loss: 1.7749852441972302

Epoch: 6| Step: 11
Training loss: 0.3735182583332062
Validation loss: 1.8099199571917135

Epoch: 6| Step: 12
Training loss: 0.1576697826385498
Validation loss: 1.7807145131531583

Epoch: 6| Step: 13
Training loss: 0.3267039656639099
Validation loss: 1.7725422792537238

Epoch: 278| Step: 0
Training loss: 0.4973900020122528
Validation loss: 1.727547178986252

Epoch: 6| Step: 1
Training loss: 0.16355344653129578
Validation loss: 1.7481699938415198

Epoch: 6| Step: 2
Training loss: 0.23293405771255493
Validation loss: 1.668893083449333

Epoch: 6| Step: 3
Training loss: 0.1346701681613922
Validation loss: 1.6637715408878941

Epoch: 6| Step: 4
Training loss: 0.31411486864089966
Validation loss: 1.6902008748823596

Epoch: 6| Step: 5
Training loss: 0.25178611278533936
Validation loss: 1.6457580635624547

Epoch: 6| Step: 6
Training loss: 0.21891114115715027
Validation loss: 1.649629880023259

Epoch: 6| Step: 7
Training loss: 0.37696608901023865
Validation loss: 1.6628026000915035

Epoch: 6| Step: 8
Training loss: 0.09538134187459946
Validation loss: 1.6683159310330626

Epoch: 6| Step: 9
Training loss: 0.3565140962600708
Validation loss: 1.681753445697087

Epoch: 6| Step: 10
Training loss: 0.22094771265983582
Validation loss: 1.6896454986705576

Epoch: 6| Step: 11
Training loss: 0.2595650553703308
Validation loss: 1.692272702852885

Epoch: 6| Step: 12
Training loss: 0.2296638786792755
Validation loss: 1.7321732146765596

Epoch: 6| Step: 13
Training loss: 0.6107988953590393
Validation loss: 1.7454257267777638

Epoch: 279| Step: 0
Training loss: 0.232208251953125
Validation loss: 1.722489082685081

Epoch: 6| Step: 1
Training loss: 0.21957463026046753
Validation loss: 1.7058020971154655

Epoch: 6| Step: 2
Training loss: 0.304263710975647
Validation loss: 1.7098878839964509

Epoch: 6| Step: 3
Training loss: 0.33364665508270264
Validation loss: 1.698376299232565

Epoch: 6| Step: 4
Training loss: 0.2791363000869751
Validation loss: 1.656622794366652

Epoch: 6| Step: 5
Training loss: 0.36047929525375366
Validation loss: 1.686031105697796

Epoch: 6| Step: 6
Training loss: 0.3808479309082031
Validation loss: 1.6974630676290041

Epoch: 6| Step: 7
Training loss: 0.508070170879364
Validation loss: 1.6893366844423356

Epoch: 6| Step: 8
Training loss: 0.2129245102405548
Validation loss: 1.6680687909485192

Epoch: 6| Step: 9
Training loss: 0.2686837315559387
Validation loss: 1.6348119730590491

Epoch: 6| Step: 10
Training loss: 0.2813794016838074
Validation loss: 1.6256282752560032

Epoch: 6| Step: 11
Training loss: 0.3096378445625305
Validation loss: 1.622196589746783

Epoch: 6| Step: 12
Training loss: 0.21685358881950378
Validation loss: 1.6288422205114876

Epoch: 6| Step: 13
Training loss: 0.17375725507736206
Validation loss: 1.6326907347607356

Epoch: 280| Step: 0
Training loss: 0.192054882645607
Validation loss: 1.6204963627681936

Epoch: 6| Step: 1
Training loss: 0.36741897463798523
Validation loss: 1.6617489758358206

Epoch: 6| Step: 2
Training loss: 0.49917352199554443
Validation loss: 1.6963718245106358

Epoch: 6| Step: 3
Training loss: 0.18748047947883606
Validation loss: 1.7420669729991625

Epoch: 6| Step: 4
Training loss: 0.3744713366031647
Validation loss: 1.7291315165899133

Epoch: 6| Step: 5
Training loss: 0.2398156225681305
Validation loss: 1.7558488192096833

Epoch: 6| Step: 6
Training loss: 0.2979001998901367
Validation loss: 1.747993073155803

Epoch: 6| Step: 7
Training loss: 0.205572709441185
Validation loss: 1.7475072132643832

Epoch: 6| Step: 8
Training loss: 0.1639035940170288
Validation loss: 1.7096514483933807

Epoch: 6| Step: 9
Training loss: 0.31433239579200745
Validation loss: 1.7342536526341592

Epoch: 6| Step: 10
Training loss: 0.13224372267723083
Validation loss: 1.7012891660454452

Epoch: 6| Step: 11
Training loss: 0.20088914036750793
Validation loss: 1.6886920339317733

Epoch: 6| Step: 12
Training loss: 0.3734634220600128
Validation loss: 1.6830066211761967

Epoch: 6| Step: 13
Training loss: 0.46471548080444336
Validation loss: 1.6813331124603108

Epoch: 281| Step: 0
Training loss: 0.2550649344921112
Validation loss: 1.6849188458534978

Epoch: 6| Step: 1
Training loss: 0.18048933148384094
Validation loss: 1.689141467053403

Epoch: 6| Step: 2
Training loss: 0.23104184865951538
Validation loss: 1.7168652190957019

Epoch: 6| Step: 3
Training loss: 0.25454503297805786
Validation loss: 1.6845708418917913

Epoch: 6| Step: 4
Training loss: 0.4361875653266907
Validation loss: 1.689624063430294

Epoch: 6| Step: 5
Training loss: 0.18895530700683594
Validation loss: 1.6292311555595809

Epoch: 6| Step: 6
Training loss: 0.2800651788711548
Validation loss: 1.613920086173601

Epoch: 6| Step: 7
Training loss: 0.2184813916683197
Validation loss: 1.6114299374241983

Epoch: 6| Step: 8
Training loss: 0.3252982199192047
Validation loss: 1.612215571506049

Epoch: 6| Step: 9
Training loss: 0.28894856572151184
Validation loss: 1.6097159590772403

Epoch: 6| Step: 10
Training loss: 0.25298160314559937
Validation loss: 1.6023057468475834

Epoch: 6| Step: 11
Training loss: 0.3292873203754425
Validation loss: 1.6055929763342744

Epoch: 6| Step: 12
Training loss: 0.39880502223968506
Validation loss: 1.6147339331206454

Epoch: 6| Step: 13
Training loss: 0.19451427459716797
Validation loss: 1.6031796868129442

Epoch: 282| Step: 0
Training loss: 0.23007693886756897
Validation loss: 1.6563976798006284

Epoch: 6| Step: 1
Training loss: 0.21379151940345764
Validation loss: 1.7124609537022089

Epoch: 6| Step: 2
Training loss: 0.46076303720474243
Validation loss: 1.7184892251927366

Epoch: 6| Step: 3
Training loss: 0.20725254714488983
Validation loss: 1.6953646905960575

Epoch: 6| Step: 4
Training loss: 0.27201008796691895
Validation loss: 1.6820028430672103

Epoch: 6| Step: 5
Training loss: 0.41833141446113586
Validation loss: 1.6499611626389206

Epoch: 6| Step: 6
Training loss: 0.2071426808834076
Validation loss: 1.6437797418204687

Epoch: 6| Step: 7
Training loss: 0.27600228786468506
Validation loss: 1.6485402789167178

Epoch: 6| Step: 8
Training loss: 0.3946572244167328
Validation loss: 1.6192306216045091

Epoch: 6| Step: 9
Training loss: 0.35176733136177063
Validation loss: 1.6173576257562126

Epoch: 6| Step: 10
Training loss: 0.20173662900924683
Validation loss: 1.6022404650206208

Epoch: 6| Step: 11
Training loss: 0.15913978219032288
Validation loss: 1.5922280255184378

Epoch: 6| Step: 12
Training loss: 0.42429250478744507
Validation loss: 1.5615328076065227

Epoch: 6| Step: 13
Training loss: 0.23959964513778687
Validation loss: 1.5925868647072905

Epoch: 283| Step: 0
Training loss: 0.32433223724365234
Validation loss: 1.5738782933963242

Epoch: 6| Step: 1
Training loss: 0.3126668930053711
Validation loss: 1.6035970744266306

Epoch: 6| Step: 2
Training loss: 0.3047032952308655
Validation loss: 1.6069369886511116

Epoch: 6| Step: 3
Training loss: 0.32818618416786194
Validation loss: 1.620154938390178

Epoch: 6| Step: 4
Training loss: 0.32324880361557007
Validation loss: 1.6297346507349322

Epoch: 6| Step: 5
Training loss: 0.49681779742240906
Validation loss: 1.6370200957021406

Epoch: 6| Step: 6
Training loss: 0.11056844890117645
Validation loss: 1.675114650880137

Epoch: 6| Step: 7
Training loss: 0.18430635333061218
Validation loss: 1.6560863551273142

Epoch: 6| Step: 8
Training loss: 0.2008284628391266
Validation loss: 1.6608037897335586

Epoch: 6| Step: 9
Training loss: 0.26216980814933777
Validation loss: 1.6822119720520512

Epoch: 6| Step: 10
Training loss: 0.14500300586223602
Validation loss: 1.6641192820764357

Epoch: 6| Step: 11
Training loss: 0.11997147649526596
Validation loss: 1.6753692947408205

Epoch: 6| Step: 12
Training loss: 0.2638698220252991
Validation loss: 1.6930305932157783

Epoch: 6| Step: 13
Training loss: 0.23070938885211945
Validation loss: 1.6848471100612352

Epoch: 284| Step: 0
Training loss: 0.20107519626617432
Validation loss: 1.7198796938824397

Epoch: 6| Step: 1
Training loss: 0.43954983353614807
Validation loss: 1.7061523468263688

Epoch: 6| Step: 2
Training loss: 0.13317818939685822
Validation loss: 1.6855693094192012

Epoch: 6| Step: 3
Training loss: 0.31522542238235474
Validation loss: 1.6580544158976565

Epoch: 6| Step: 4
Training loss: 0.49166643619537354
Validation loss: 1.6327676388525194

Epoch: 6| Step: 5
Training loss: 0.29613059759140015
Validation loss: 1.6273260116577148

Epoch: 6| Step: 6
Training loss: 0.2088858187198639
Validation loss: 1.6053678912501181

Epoch: 6| Step: 7
Training loss: 0.10913131386041641
Validation loss: 1.6055072610096266

Epoch: 6| Step: 8
Training loss: 0.31435221433639526
Validation loss: 1.5988615123174523

Epoch: 6| Step: 9
Training loss: 0.13896828889846802
Validation loss: 1.6309674414255286

Epoch: 6| Step: 10
Training loss: 0.3365519940853119
Validation loss: 1.6379623079812655

Epoch: 6| Step: 11
Training loss: 0.17153246700763702
Validation loss: 1.6482398894525343

Epoch: 6| Step: 12
Training loss: 0.14302797615528107
Validation loss: 1.6465431977343816

Epoch: 6| Step: 13
Training loss: 0.3680664598941803
Validation loss: 1.660690547317587

Epoch: 285| Step: 0
Training loss: 0.4095613956451416
Validation loss: 1.6842967105168167

Epoch: 6| Step: 1
Training loss: 0.27643024921417236
Validation loss: 1.6899857021147204

Epoch: 6| Step: 2
Training loss: 0.38281601667404175
Validation loss: 1.6744240086565736

Epoch: 6| Step: 3
Training loss: 0.17781171202659607
Validation loss: 1.6696173144925026

Epoch: 6| Step: 4
Training loss: 0.18403638899326324
Validation loss: 1.6627856915996921

Epoch: 6| Step: 5
Training loss: 0.2391495406627655
Validation loss: 1.6808621755210302

Epoch: 6| Step: 6
Training loss: 0.3316184878349304
Validation loss: 1.6698309926576511

Epoch: 6| Step: 7
Training loss: 0.27447956800460815
Validation loss: 1.6675900669508084

Epoch: 6| Step: 8
Training loss: 0.14001226425170898
Validation loss: 1.6506258287737448

Epoch: 6| Step: 9
Training loss: 0.2336738109588623
Validation loss: 1.6621938687498852

Epoch: 6| Step: 10
Training loss: 0.5649971961975098
Validation loss: 1.6663308028251893

Epoch: 6| Step: 11
Training loss: 0.15310588479042053
Validation loss: 1.6296272303468438

Epoch: 6| Step: 12
Training loss: 0.16555002331733704
Validation loss: 1.6582792728177962

Epoch: 6| Step: 13
Training loss: 0.22026249766349792
Validation loss: 1.6244818946366668

Epoch: 286| Step: 0
Training loss: 0.2962496280670166
Validation loss: 1.647505679438191

Epoch: 6| Step: 1
Training loss: 0.254765123128891
Validation loss: 1.6441801760786323

Epoch: 6| Step: 2
Training loss: 0.5335085391998291
Validation loss: 1.599860361827317

Epoch: 6| Step: 3
Training loss: 0.16047601401805878
Validation loss: 1.5979267781780613

Epoch: 6| Step: 4
Training loss: 0.09772855788469315
Validation loss: 1.5900786961278608

Epoch: 6| Step: 5
Training loss: 0.2901109457015991
Validation loss: 1.59629617070639

Epoch: 6| Step: 6
Training loss: 0.29293695092201233
Validation loss: 1.587870502984652

Epoch: 6| Step: 7
Training loss: 0.1819673776626587
Validation loss: 1.600467393475194

Epoch: 6| Step: 8
Training loss: 0.1890464425086975
Validation loss: 1.6184065059948993

Epoch: 6| Step: 9
Training loss: 0.22408786416053772
Validation loss: 1.5900091125119118

Epoch: 6| Step: 10
Training loss: 0.3937942087650299
Validation loss: 1.5745326299821176

Epoch: 6| Step: 11
Training loss: 0.2195284068584442
Validation loss: 1.5660820789234613

Epoch: 6| Step: 12
Training loss: 0.31727537512779236
Validation loss: 1.567606008181008

Epoch: 6| Step: 13
Training loss: 0.34393903613090515
Validation loss: 1.6034958990671302

Epoch: 287| Step: 0
Training loss: 0.23133330047130585
Validation loss: 1.6097631992832306

Epoch: 6| Step: 1
Training loss: 0.21864211559295654
Validation loss: 1.6147370056439472

Epoch: 6| Step: 2
Training loss: 0.22877635061740875
Validation loss: 1.6637089226835517

Epoch: 6| Step: 3
Training loss: 0.39460235834121704
Validation loss: 1.670644602467937

Epoch: 6| Step: 4
Training loss: 0.21445828676223755
Validation loss: 1.6898423753758913

Epoch: 6| Step: 5
Training loss: 0.31041860580444336
Validation loss: 1.6748186362686979

Epoch: 6| Step: 6
Training loss: 0.19347213208675385
Validation loss: 1.6340853744937527

Epoch: 6| Step: 7
Training loss: 0.3179537355899811
Validation loss: 1.6614095344338367

Epoch: 6| Step: 8
Training loss: 0.19068670272827148
Validation loss: 1.6792128765454857

Epoch: 6| Step: 9
Training loss: 0.35470181703567505
Validation loss: 1.6444138198770502

Epoch: 6| Step: 10
Training loss: 0.2454189658164978
Validation loss: 1.6327439110766175

Epoch: 6| Step: 11
Training loss: 0.10831311345100403
Validation loss: 1.6177476913698259

Epoch: 6| Step: 12
Training loss: 0.3646318316459656
Validation loss: 1.640005124512539

Epoch: 6| Step: 13
Training loss: 0.3864000737667084
Validation loss: 1.6265300896859938

Epoch: 288| Step: 0
Training loss: 0.24030807614326477
Validation loss: 1.6392985133714573

Epoch: 6| Step: 1
Training loss: 0.42126303911209106
Validation loss: 1.6353684676590787

Epoch: 6| Step: 2
Training loss: 0.19653192162513733
Validation loss: 1.6499155894402535

Epoch: 6| Step: 3
Training loss: 0.19719509780406952
Validation loss: 1.6447858297696678

Epoch: 6| Step: 4
Training loss: 0.22206147015094757
Validation loss: 1.6440071380266579

Epoch: 6| Step: 5
Training loss: 0.19384926557540894
Validation loss: 1.6338581846606346

Epoch: 6| Step: 6
Training loss: 0.33192867040634155
Validation loss: 1.6495003879711192

Epoch: 6| Step: 7
Training loss: 0.38972437381744385
Validation loss: 1.6561892378714778

Epoch: 6| Step: 8
Training loss: 0.1509765386581421
Validation loss: 1.6734575507461384

Epoch: 6| Step: 9
Training loss: 0.19285187125205994
Validation loss: 1.6650896892752698

Epoch: 6| Step: 10
Training loss: 0.2547878921031952
Validation loss: 1.6808470320957962

Epoch: 6| Step: 11
Training loss: 0.24323761463165283
Validation loss: 1.684858113206843

Epoch: 6| Step: 12
Training loss: 0.19933375716209412
Validation loss: 1.715548119237346

Epoch: 6| Step: 13
Training loss: 0.2112703025341034
Validation loss: 1.7210823425682642

Epoch: 289| Step: 0
Training loss: 0.3974357545375824
Validation loss: 1.722968320692739

Epoch: 6| Step: 1
Training loss: 0.16187506914138794
Validation loss: 1.7597453171207058

Epoch: 6| Step: 2
Training loss: 0.2736102342605591
Validation loss: 1.7081864341612785

Epoch: 6| Step: 3
Training loss: 0.20192240178585052
Validation loss: 1.678712708975679

Epoch: 6| Step: 4
Training loss: 0.25529906153678894
Validation loss: 1.6443195035380702

Epoch: 6| Step: 5
Training loss: 0.28784358501434326
Validation loss: 1.6418642587559198

Epoch: 6| Step: 6
Training loss: 0.2211831510066986
Validation loss: 1.6213305560491418

Epoch: 6| Step: 7
Training loss: 0.3426237106323242
Validation loss: 1.6322748366222586

Epoch: 6| Step: 8
Training loss: 0.3279111981391907
Validation loss: 1.625289168409122

Epoch: 6| Step: 9
Training loss: 0.17226055264472961
Validation loss: 1.5948846276088426

Epoch: 6| Step: 10
Training loss: 0.2893848419189453
Validation loss: 1.6360221037300684

Epoch: 6| Step: 11
Training loss: 0.28423717617988586
Validation loss: 1.6320220180737075

Epoch: 6| Step: 12
Training loss: 0.2564442753791809
Validation loss: 1.6236682015080606

Epoch: 6| Step: 13
Training loss: 0.36208659410476685
Validation loss: 1.625969289451517

Epoch: 290| Step: 0
Training loss: 0.24829891324043274
Validation loss: 1.6869233872300835

Epoch: 6| Step: 1
Training loss: 0.25237828493118286
Validation loss: 1.6927533662447365

Epoch: 6| Step: 2
Training loss: 0.3958064913749695
Validation loss: 1.7029126408279582

Epoch: 6| Step: 3
Training loss: 0.36459702253341675
Validation loss: 1.674841232197259

Epoch: 6| Step: 4
Training loss: 0.295675665140152
Validation loss: 1.6448863219189387

Epoch: 6| Step: 5
Training loss: 0.33150655031204224
Validation loss: 1.6193841913694977

Epoch: 6| Step: 6
Training loss: 0.3294965624809265
Validation loss: 1.5851456426805066

Epoch: 6| Step: 7
Training loss: 0.14498601853847504
Validation loss: 1.5716245956318353

Epoch: 6| Step: 8
Training loss: 0.14234767854213715
Validation loss: 1.5681493923228274

Epoch: 6| Step: 9
Training loss: 0.24117299914360046
Validation loss: 1.5550687748898742

Epoch: 6| Step: 10
Training loss: 0.2920548915863037
Validation loss: 1.60404505396402

Epoch: 6| Step: 11
Training loss: 0.15952546894550323
Validation loss: 1.6034571073388542

Epoch: 6| Step: 12
Training loss: 0.34712621569633484
Validation loss: 1.6058403574010378

Epoch: 6| Step: 13
Training loss: 0.25702735781669617
Validation loss: 1.626052624435835

Epoch: 291| Step: 0
Training loss: 0.37164151668548584
Validation loss: 1.6458075431085402

Epoch: 6| Step: 1
Training loss: 0.4396972060203552
Validation loss: 1.6425393037898566

Epoch: 6| Step: 2
Training loss: 0.3128046691417694
Validation loss: 1.6712285998047038

Epoch: 6| Step: 3
Training loss: 0.17629475891590118
Validation loss: 1.675803292182184

Epoch: 6| Step: 4
Training loss: 0.3089841902256012
Validation loss: 1.693979077441718

Epoch: 6| Step: 5
Training loss: 0.2668866515159607
Validation loss: 1.6589854660854544

Epoch: 6| Step: 6
Training loss: 0.27805304527282715
Validation loss: 1.659538883034901

Epoch: 6| Step: 7
Training loss: 0.20530831813812256
Validation loss: 1.6495327539341424

Epoch: 6| Step: 8
Training loss: 0.17068356275558472
Validation loss: 1.6079204120943624

Epoch: 6| Step: 9
Training loss: 0.14966672658920288
Validation loss: 1.5791217665518484

Epoch: 6| Step: 10
Training loss: 0.19472120702266693
Validation loss: 1.5831147739964146

Epoch: 6| Step: 11
Training loss: 0.2509041428565979
Validation loss: 1.5723869018657233

Epoch: 6| Step: 12
Training loss: 0.2755791246891022
Validation loss: 1.6152000504155313

Epoch: 6| Step: 13
Training loss: 0.13300582766532898
Validation loss: 1.5848806641435111

Epoch: 292| Step: 0
Training loss: 0.15788374841213226
Validation loss: 1.6258609307709562

Epoch: 6| Step: 1
Training loss: 0.1773335039615631
Validation loss: 1.6704870872600104

Epoch: 6| Step: 2
Training loss: 0.21684259176254272
Validation loss: 1.7081156366614885

Epoch: 6| Step: 3
Training loss: 0.1427641212940216
Validation loss: 1.6947007743261193

Epoch: 6| Step: 4
Training loss: 0.3002646565437317
Validation loss: 1.7160093104967507

Epoch: 6| Step: 5
Training loss: 0.24064801633358002
Validation loss: 1.7045692807884627

Epoch: 6| Step: 6
Training loss: 0.23403415083885193
Validation loss: 1.6658667313155306

Epoch: 6| Step: 7
Training loss: 0.22749927639961243
Validation loss: 1.6293640764810706

Epoch: 6| Step: 8
Training loss: 0.16448494791984558
Validation loss: 1.6230486939030309

Epoch: 6| Step: 9
Training loss: 0.22180265188217163
Validation loss: 1.6123546361923218

Epoch: 6| Step: 10
Training loss: 0.3370240330696106
Validation loss: 1.5955840272288169

Epoch: 6| Step: 11
Training loss: 0.5494174361228943
Validation loss: 1.6059468382148332

Epoch: 6| Step: 12
Training loss: 0.29910004138946533
Validation loss: 1.5925819822537002

Epoch: 6| Step: 13
Training loss: 0.6964995265007019
Validation loss: 1.585465124858323

Epoch: 293| Step: 0
Training loss: 0.2110128402709961
Validation loss: 1.583627188077537

Epoch: 6| Step: 1
Training loss: 0.21679982542991638
Validation loss: 1.5907618448298464

Epoch: 6| Step: 2
Training loss: 0.3807244896888733
Validation loss: 1.617227053770455

Epoch: 6| Step: 3
Training loss: 0.15573182702064514
Validation loss: 1.6488693221922843

Epoch: 6| Step: 4
Training loss: 0.4261298179626465
Validation loss: 1.6682302221175163

Epoch: 6| Step: 5
Training loss: 0.27431461215019226
Validation loss: 1.6956169989801222

Epoch: 6| Step: 6
Training loss: 0.2592073976993561
Validation loss: 1.7199382307708904

Epoch: 6| Step: 7
Training loss: 0.20341148972511292
Validation loss: 1.7088924889923425

Epoch: 6| Step: 8
Training loss: 0.36183297634124756
Validation loss: 1.724609040444897

Epoch: 6| Step: 9
Training loss: 0.25112196803092957
Validation loss: 1.7382072838403846

Epoch: 6| Step: 10
Training loss: 0.30761754512786865
Validation loss: 1.6976492635665401

Epoch: 6| Step: 11
Training loss: 0.32421451807022095
Validation loss: 1.6928244829177856

Epoch: 6| Step: 12
Training loss: 0.1288428157567978
Validation loss: 1.686983387957337

Epoch: 6| Step: 13
Training loss: 0.13331085443496704
Validation loss: 1.665294671571383

Epoch: 294| Step: 0
Training loss: 0.1372356116771698
Validation loss: 1.6446471944932015

Epoch: 6| Step: 1
Training loss: 0.315873920917511
Validation loss: 1.6708280091644616

Epoch: 6| Step: 2
Training loss: 0.5626118779182434
Validation loss: 1.6372956973250195

Epoch: 6| Step: 3
Training loss: 0.1851808726787567
Validation loss: 1.6487939614121632

Epoch: 6| Step: 4
Training loss: 0.30467113852500916
Validation loss: 1.6556507438741705

Epoch: 6| Step: 5
Training loss: 0.18760742247104645
Validation loss: 1.6929857807774698

Epoch: 6| Step: 6
Training loss: 0.37508144974708557
Validation loss: 1.713576401433637

Epoch: 6| Step: 7
Training loss: 0.3404999375343323
Validation loss: 1.6694501920412945

Epoch: 6| Step: 8
Training loss: 0.24918875098228455
Validation loss: 1.676374868039162

Epoch: 6| Step: 9
Training loss: 0.2933233380317688
Validation loss: 1.6661673694528558

Epoch: 6| Step: 10
Training loss: 0.1435008943080902
Validation loss: 1.707312741587239

Epoch: 6| Step: 11
Training loss: 0.2075539231300354
Validation loss: 1.7011093503685408

Epoch: 6| Step: 12
Training loss: 0.2051592618227005
Validation loss: 1.708056770345216

Epoch: 6| Step: 13
Training loss: 0.09075189381837845
Validation loss: 1.7426388725157707

Epoch: 295| Step: 0
Training loss: 0.18244770169258118
Validation loss: 1.7007655559047576

Epoch: 6| Step: 1
Training loss: 0.2604735791683197
Validation loss: 1.69503354513517

Epoch: 6| Step: 2
Training loss: 0.2107633352279663
Validation loss: 1.7085986868027718

Epoch: 6| Step: 3
Training loss: 0.2234332263469696
Validation loss: 1.6999465342490905

Epoch: 6| Step: 4
Training loss: 0.4628424048423767
Validation loss: 1.7058253685633342

Epoch: 6| Step: 5
Training loss: 0.2001563310623169
Validation loss: 1.6903065853221442

Epoch: 6| Step: 6
Training loss: 0.16565003991127014
Validation loss: 1.6833287823584773

Epoch: 6| Step: 7
Training loss: 0.2713424563407898
Validation loss: 1.6785814351932977

Epoch: 6| Step: 8
Training loss: 0.22028958797454834
Validation loss: 1.7021233753491474

Epoch: 6| Step: 9
Training loss: 0.18836766481399536
Validation loss: 1.6768558307360577

Epoch: 6| Step: 10
Training loss: 0.40058737993240356
Validation loss: 1.6916182502623527

Epoch: 6| Step: 11
Training loss: 0.45353931188583374
Validation loss: 1.6725874357326056

Epoch: 6| Step: 12
Training loss: 0.182814359664917
Validation loss: 1.6479262126389371

Epoch: 6| Step: 13
Training loss: 0.1624743491411209
Validation loss: 1.634232408256941

Epoch: 296| Step: 0
Training loss: 0.24605509638786316
Validation loss: 1.6352487520505024

Epoch: 6| Step: 1
Training loss: 0.17673911154270172
Validation loss: 1.6548936873353937

Epoch: 6| Step: 2
Training loss: 0.25128135085105896
Validation loss: 1.6735769112904866

Epoch: 6| Step: 3
Training loss: 0.25422680377960205
Validation loss: 1.6504249970118205

Epoch: 6| Step: 4
Training loss: 0.44927215576171875
Validation loss: 1.6712442751853698

Epoch: 6| Step: 5
Training loss: 0.20365190505981445
Validation loss: 1.6429715643646896

Epoch: 6| Step: 6
Training loss: 0.25901010632514954
Validation loss: 1.6066612569234704

Epoch: 6| Step: 7
Training loss: 0.2566204369068146
Validation loss: 1.6131503441000496

Epoch: 6| Step: 8
Training loss: 0.1710195541381836
Validation loss: 1.6312401435708488

Epoch: 6| Step: 9
Training loss: 0.25138893723487854
Validation loss: 1.5965887449120963

Epoch: 6| Step: 10
Training loss: 0.2522105276584625
Validation loss: 1.5759362283573355

Epoch: 6| Step: 11
Training loss: 0.12357095628976822
Validation loss: 1.5731775228695204

Epoch: 6| Step: 12
Training loss: 0.3349820077419281
Validation loss: 1.5994020726091118

Epoch: 6| Step: 13
Training loss: 0.33514657616615295
Validation loss: 1.6088097108307706

Epoch: 297| Step: 0
Training loss: 0.15296252071857452
Validation loss: 1.6083828505649362

Epoch: 6| Step: 1
Training loss: 0.29230839014053345
Validation loss: 1.6641739273584017

Epoch: 6| Step: 2
Training loss: 0.30082225799560547
Validation loss: 1.6709616325234855

Epoch: 6| Step: 3
Training loss: 0.1272684633731842
Validation loss: 1.6929775591819518

Epoch: 6| Step: 4
Training loss: 0.2621607780456543
Validation loss: 1.6865543088605326

Epoch: 6| Step: 5
Training loss: 0.15031170845031738
Validation loss: 1.6952671466335174

Epoch: 6| Step: 6
Training loss: 0.31672847270965576
Validation loss: 1.680041479808028

Epoch: 6| Step: 7
Training loss: 0.21205031871795654
Validation loss: 1.6500379257304694

Epoch: 6| Step: 8
Training loss: 0.3719790577888489
Validation loss: 1.6370932402149323

Epoch: 6| Step: 9
Training loss: 0.29139572381973267
Validation loss: 1.6126766384288829

Epoch: 6| Step: 10
Training loss: 0.24326585233211517
Validation loss: 1.6403977127485379

Epoch: 6| Step: 11
Training loss: 0.13843250274658203
Validation loss: 1.6485899955995622

Epoch: 6| Step: 12
Training loss: 0.1383247673511505
Validation loss: 1.6439437571392264

Epoch: 6| Step: 13
Training loss: 0.14142870903015137
Validation loss: 1.6481500876847135

Epoch: 298| Step: 0
Training loss: 0.15061162412166595
Validation loss: 1.6525989988798737

Epoch: 6| Step: 1
Training loss: 0.2759054899215698
Validation loss: 1.650241563397069

Epoch: 6| Step: 2
Training loss: 0.18681395053863525
Validation loss: 1.6425201380124657

Epoch: 6| Step: 3
Training loss: 0.18169736862182617
Validation loss: 1.6554649119736047

Epoch: 6| Step: 4
Training loss: 0.2911832332611084
Validation loss: 1.6648389498392742

Epoch: 6| Step: 5
Training loss: 0.104002445936203
Validation loss: 1.679195889862635

Epoch: 6| Step: 6
Training loss: 0.16618917882442474
Validation loss: 1.6959114305434688

Epoch: 6| Step: 7
Training loss: 0.21916425228118896
Validation loss: 1.7168477658302552

Epoch: 6| Step: 8
Training loss: 0.12526944279670715
Validation loss: 1.696362792804677

Epoch: 6| Step: 9
Training loss: 0.4104786515235901
Validation loss: 1.684383935184889

Epoch: 6| Step: 10
Training loss: 0.232972651720047
Validation loss: 1.6784694912613078

Epoch: 6| Step: 11
Training loss: 0.26151853799819946
Validation loss: 1.6479667784065328

Epoch: 6| Step: 12
Training loss: 0.38921478390693665
Validation loss: 1.6383463900576356

Epoch: 6| Step: 13
Training loss: 0.2961646318435669
Validation loss: 1.6080618814755512

Epoch: 299| Step: 0
Training loss: 0.29183873534202576
Validation loss: 1.6213253377586283

Epoch: 6| Step: 1
Training loss: 0.4287552237510681
Validation loss: 1.6428233949086999

Epoch: 6| Step: 2
Training loss: 0.09472252428531647
Validation loss: 1.6004928908040446

Epoch: 6| Step: 3
Training loss: 0.18987812101840973
Validation loss: 1.6319258354043449

Epoch: 6| Step: 4
Training loss: 0.21205145120620728
Validation loss: 1.651042898495992

Epoch: 6| Step: 5
Training loss: 0.1366509050130844
Validation loss: 1.6366579481350478

Epoch: 6| Step: 6
Training loss: 0.17027586698532104
Validation loss: 1.6049320133783485

Epoch: 6| Step: 7
Training loss: 0.31660768389701843
Validation loss: 1.5960830949967908

Epoch: 6| Step: 8
Training loss: 0.17944836616516113
Validation loss: 1.590827436857326

Epoch: 6| Step: 9
Training loss: 0.2136811763048172
Validation loss: 1.6145242273166616

Epoch: 6| Step: 10
Training loss: 0.16156120598316193
Validation loss: 1.6374185790297806

Epoch: 6| Step: 11
Training loss: 0.2312108278274536
Validation loss: 1.614281274939096

Epoch: 6| Step: 12
Training loss: 0.180314838886261
Validation loss: 1.6159419782700077

Epoch: 6| Step: 13
Training loss: 0.33315616846084595
Validation loss: 1.618703047434489

Epoch: 300| Step: 0
Training loss: 0.10270926356315613
Validation loss: 1.6337847325109667

Epoch: 6| Step: 1
Training loss: 0.3138480484485626
Validation loss: 1.6423339061839606

Epoch: 6| Step: 2
Training loss: 0.18389582633972168
Validation loss: 1.6704815049325266

Epoch: 6| Step: 3
Training loss: 0.13897806406021118
Validation loss: 1.6648681189424248

Epoch: 6| Step: 4
Training loss: 0.20499840378761292
Validation loss: 1.6452029546101887

Epoch: 6| Step: 5
Training loss: 0.2601766884326935
Validation loss: 1.633326873984388

Epoch: 6| Step: 6
Training loss: 0.27341336011886597
Validation loss: 1.5885296201193204

Epoch: 6| Step: 7
Training loss: 0.3066965341567993
Validation loss: 1.6182040014574606

Epoch: 6| Step: 8
Training loss: 0.22864237427711487
Validation loss: 1.61124240198443

Epoch: 6| Step: 9
Training loss: 0.1581200659275055
Validation loss: 1.5848432458857054

Epoch: 6| Step: 10
Training loss: 0.24797412753105164
Validation loss: 1.626240158593783

Epoch: 6| Step: 11
Training loss: 0.19773614406585693
Validation loss: 1.5980460579677294

Epoch: 6| Step: 12
Training loss: 0.3511906862258911
Validation loss: 1.6367936467611661

Epoch: 6| Step: 13
Training loss: 0.21727249026298523
Validation loss: 1.603823757940723

Epoch: 301| Step: 0
Training loss: 0.22566792368888855
Validation loss: 1.6535079633035967

Epoch: 6| Step: 1
Training loss: 0.3662697970867157
Validation loss: 1.6849775724513556

Epoch: 6| Step: 2
Training loss: 0.5040243864059448
Validation loss: 1.696072240029612

Epoch: 6| Step: 3
Training loss: 0.19696077704429626
Validation loss: 1.7112676123137116

Epoch: 6| Step: 4
Training loss: 0.21998539566993713
Validation loss: 1.7458615033857283

Epoch: 6| Step: 5
Training loss: 0.24350278079509735
Validation loss: 1.7540026467333558

Epoch: 6| Step: 6
Training loss: 0.26342418789863586
Validation loss: 1.7185210848367343

Epoch: 6| Step: 7
Training loss: 0.11360576748847961
Validation loss: 1.7263374341431486

Epoch: 6| Step: 8
Training loss: 0.12509427964687347
Validation loss: 1.6760811677543066

Epoch: 6| Step: 9
Training loss: 0.11481830477714539
Validation loss: 1.680596972024569

Epoch: 6| Step: 10
Training loss: 0.14247211813926697
Validation loss: 1.702495546751125

Epoch: 6| Step: 11
Training loss: 0.22670122981071472
Validation loss: 1.6926424144416727

Epoch: 6| Step: 12
Training loss: 0.29149186611175537
Validation loss: 1.6559586960782287

Epoch: 6| Step: 13
Training loss: 0.15363246202468872
Validation loss: 1.635446950953494

Epoch: 302| Step: 0
Training loss: 0.21195544302463531
Validation loss: 1.6207977546158658

Epoch: 6| Step: 1
Training loss: 0.19406723976135254
Validation loss: 1.6207674741744995

Epoch: 6| Step: 2
Training loss: 0.22957293689250946
Validation loss: 1.6058759420148787

Epoch: 6| Step: 3
Training loss: 0.22287669777870178
Validation loss: 1.6453454391930693

Epoch: 6| Step: 4
Training loss: 0.3676866292953491
Validation loss: 1.6118299576543993

Epoch: 6| Step: 5
Training loss: 0.18245258927345276
Validation loss: 1.6175341849685998

Epoch: 6| Step: 6
Training loss: 0.2267598807811737
Validation loss: 1.60781701021297

Epoch: 6| Step: 7
Training loss: 0.2044176161289215
Validation loss: 1.5994896901551114

Epoch: 6| Step: 8
Training loss: 0.2343500256538391
Validation loss: 1.6235306314242783

Epoch: 6| Step: 9
Training loss: 0.3176497519016266
Validation loss: 1.6351500275314494

Epoch: 6| Step: 10
Training loss: 0.2606448233127594
Validation loss: 1.6546874853872484

Epoch: 6| Step: 11
Training loss: 0.30755311250686646
Validation loss: 1.687316902222172

Epoch: 6| Step: 12
Training loss: 0.39807507395744324
Validation loss: 1.7033543663640176

Epoch: 6| Step: 13
Training loss: 0.2980702221393585
Validation loss: 1.708614686483978

Epoch: 303| Step: 0
Training loss: 0.18899327516555786
Validation loss: 1.7355655316383607

Epoch: 6| Step: 1
Training loss: 0.31344157457351685
Validation loss: 1.778457139127998

Epoch: 6| Step: 2
Training loss: 0.20709934830665588
Validation loss: 1.7581503775811964

Epoch: 6| Step: 3
Training loss: 0.2742818593978882
Validation loss: 1.762981664749884

Epoch: 6| Step: 4
Training loss: 0.17233175039291382
Validation loss: 1.7318850101963166

Epoch: 6| Step: 5
Training loss: 0.5771433115005493
Validation loss: 1.7009258013899609

Epoch: 6| Step: 6
Training loss: 0.22436007857322693
Validation loss: 1.6948776809118127

Epoch: 6| Step: 7
Training loss: 0.22515881061553955
Validation loss: 1.6829982957532328

Epoch: 6| Step: 8
Training loss: 0.17894989252090454
Validation loss: 1.6672386674470798

Epoch: 6| Step: 9
Training loss: 0.12767276167869568
Validation loss: 1.66082610366165

Epoch: 6| Step: 10
Training loss: 0.19176171720027924
Validation loss: 1.6518720375594271

Epoch: 6| Step: 11
Training loss: 0.24041740596294403
Validation loss: 1.6462693060598066

Epoch: 6| Step: 12
Training loss: 0.16649214923381805
Validation loss: 1.659559884378987

Epoch: 6| Step: 13
Training loss: 0.1718200147151947
Validation loss: 1.6546755208764026

Epoch: 304| Step: 0
Training loss: 0.23953109979629517
Validation loss: 1.6497747000827585

Epoch: 6| Step: 1
Training loss: 0.14451667666435242
Validation loss: 1.671151215030301

Epoch: 6| Step: 2
Training loss: 0.27221202850341797
Validation loss: 1.6169017899420954

Epoch: 6| Step: 3
Training loss: 0.11959274858236313
Validation loss: 1.6287908630986367

Epoch: 6| Step: 4
Training loss: 0.14646181464195251
Validation loss: 1.6133000017494283

Epoch: 6| Step: 5
Training loss: 0.32638809084892273
Validation loss: 1.6298520052304832

Epoch: 6| Step: 6
Training loss: 0.25932615995407104
Validation loss: 1.6211016960041498

Epoch: 6| Step: 7
Training loss: 0.265990287065506
Validation loss: 1.6187051829471384

Epoch: 6| Step: 8
Training loss: 0.21136033535003662
Validation loss: 1.6049091162220124

Epoch: 6| Step: 9
Training loss: 0.1431221067905426
Validation loss: 1.6559501771003968

Epoch: 6| Step: 10
Training loss: 0.36141785979270935
Validation loss: 1.6035488151734876

Epoch: 6| Step: 11
Training loss: 0.24875861406326294
Validation loss: 1.6269313891728718

Epoch: 6| Step: 12
Training loss: 0.1281239539384842
Validation loss: 1.6544751749243787

Epoch: 6| Step: 13
Training loss: 0.17185337841510773
Validation loss: 1.6657104440914687

Epoch: 305| Step: 0
Training loss: 0.16918113827705383
Validation loss: 1.6922845378998788

Epoch: 6| Step: 1
Training loss: 0.11000983417034149
Validation loss: 1.67849144499789

Epoch: 6| Step: 2
Training loss: 0.3466002941131592
Validation loss: 1.6885655474278234

Epoch: 6| Step: 3
Training loss: 0.10927662253379822
Validation loss: 1.6514985433188818

Epoch: 6| Step: 4
Training loss: 0.2239379733800888
Validation loss: 1.652320236288091

Epoch: 6| Step: 5
Training loss: 0.23853562772274017
Validation loss: 1.639530187012047

Epoch: 6| Step: 6
Training loss: 0.2093295454978943
Validation loss: 1.6410084552662347

Epoch: 6| Step: 7
Training loss: 0.1592072993516922
Validation loss: 1.6240513632374425

Epoch: 6| Step: 8
Training loss: 0.15810321271419525
Validation loss: 1.6436001908394597

Epoch: 6| Step: 9
Training loss: 0.12418144196271896
Validation loss: 1.607225787255072

Epoch: 6| Step: 10
Training loss: 0.28874069452285767
Validation loss: 1.590745460602545

Epoch: 6| Step: 11
Training loss: 0.2948096990585327
Validation loss: 1.616866506556029

Epoch: 6| Step: 12
Training loss: 0.1788233369588852
Validation loss: 1.5939210102122316

Epoch: 6| Step: 13
Training loss: 0.41192978620529175
Validation loss: 1.5963159748302993

Epoch: 306| Step: 0
Training loss: 0.20507478713989258
Validation loss: 1.5867371354051816

Epoch: 6| Step: 1
Training loss: 0.1595703363418579
Validation loss: 1.571016982037534

Epoch: 6| Step: 2
Training loss: 0.22277754545211792
Validation loss: 1.591628595065045

Epoch: 6| Step: 3
Training loss: 0.4471028745174408
Validation loss: 1.6186950898939563

Epoch: 6| Step: 4
Training loss: 0.28588050603866577
Validation loss: 1.612297067719121

Epoch: 6| Step: 5
Training loss: 0.21664956212043762
Validation loss: 1.621686444487623

Epoch: 6| Step: 6
Training loss: 0.1769123524427414
Validation loss: 1.6406095361196866

Epoch: 6| Step: 7
Training loss: 0.28857412934303284
Validation loss: 1.6272250336985434

Epoch: 6| Step: 8
Training loss: 0.21634460985660553
Validation loss: 1.6199666915401336

Epoch: 6| Step: 9
Training loss: 0.19182363152503967
Validation loss: 1.6153348004946144

Epoch: 6| Step: 10
Training loss: 0.14882710576057434
Validation loss: 1.649567263100737

Epoch: 6| Step: 11
Training loss: 0.15855221450328827
Validation loss: 1.6434413797111922

Epoch: 6| Step: 12
Training loss: 0.12100227177143097
Validation loss: 1.655388396273377

Epoch: 6| Step: 13
Training loss: 0.10544564574956894
Validation loss: 1.6514416817695863

Epoch: 307| Step: 0
Training loss: 0.15988066792488098
Validation loss: 1.6614041783476388

Epoch: 6| Step: 1
Training loss: 0.2391274869441986
Validation loss: 1.7070151452095277

Epoch: 6| Step: 2
Training loss: 0.3425825536251068
Validation loss: 1.697138649161144

Epoch: 6| Step: 3
Training loss: 0.20408940315246582
Validation loss: 1.6722245165096816

Epoch: 6| Step: 4
Training loss: 0.15247605741024017
Validation loss: 1.6843726660615654

Epoch: 6| Step: 5
Training loss: 0.16750597953796387
Validation loss: 1.6146712764616935

Epoch: 6| Step: 6
Training loss: 0.17545843124389648
Validation loss: 1.6093619587600871

Epoch: 6| Step: 7
Training loss: 0.1815597414970398
Validation loss: 1.5984496916494062

Epoch: 6| Step: 8
Training loss: 0.40592160820961
Validation loss: 1.6198240313478696

Epoch: 6| Step: 9
Training loss: 0.2613070607185364
Validation loss: 1.639070612128063

Epoch: 6| Step: 10
Training loss: 0.37167730927467346
Validation loss: 1.6530459157882198

Epoch: 6| Step: 11
Training loss: 0.4765172600746155
Validation loss: 1.6613626505738945

Epoch: 6| Step: 12
Training loss: 0.32674968242645264
Validation loss: 1.6723312479193493

Epoch: 6| Step: 13
Training loss: 0.17687392234802246
Validation loss: 1.6213665675091486

Epoch: 308| Step: 0
Training loss: 0.3332596719264984
Validation loss: 1.595561304400044

Epoch: 6| Step: 1
Training loss: 0.2389264851808548
Validation loss: 1.5843739304491269

Epoch: 6| Step: 2
Training loss: 0.20752280950546265
Validation loss: 1.5746129071840675

Epoch: 6| Step: 3
Training loss: 0.36502301692962646
Validation loss: 1.6030492064773396

Epoch: 6| Step: 4
Training loss: 0.3836759626865387
Validation loss: 1.6168043574979227

Epoch: 6| Step: 5
Training loss: 0.3701957166194916
Validation loss: 1.6039251210868999

Epoch: 6| Step: 6
Training loss: 0.2999322712421417
Validation loss: 1.621583470734217

Epoch: 6| Step: 7
Training loss: 0.13335487246513367
Validation loss: 1.614742471325782

Epoch: 6| Step: 8
Training loss: 0.36435359716415405
Validation loss: 1.6322365230129612

Epoch: 6| Step: 9
Training loss: 0.18112075328826904
Validation loss: 1.6506942907969158

Epoch: 6| Step: 10
Training loss: 0.18305674195289612
Validation loss: 1.6878607119283369

Epoch: 6| Step: 11
Training loss: 0.2833755612373352
Validation loss: 1.7330534150523524

Epoch: 6| Step: 12
Training loss: 0.3024703860282898
Validation loss: 1.727397261127349

Epoch: 6| Step: 13
Training loss: 0.3442791998386383
Validation loss: 1.6960295451584684

Epoch: 309| Step: 0
Training loss: 0.3524205982685089
Validation loss: 1.6755851609732515

Epoch: 6| Step: 1
Training loss: 0.16318953037261963
Validation loss: 1.6481298092872865

Epoch: 6| Step: 2
Training loss: 0.25581419467926025
Validation loss: 1.6039131277350969

Epoch: 6| Step: 3
Training loss: 0.12455935776233673
Validation loss: 1.620553772936585

Epoch: 6| Step: 4
Training loss: 0.24756239354610443
Validation loss: 1.6392055890893424

Epoch: 6| Step: 5
Training loss: 0.11964007467031479
Validation loss: 1.6165214533446937

Epoch: 6| Step: 6
Training loss: 0.2599770426750183
Validation loss: 1.6096389050124793

Epoch: 6| Step: 7
Training loss: 0.3621686100959778
Validation loss: 1.63104002001465

Epoch: 6| Step: 8
Training loss: 0.19061733782291412
Validation loss: 1.6115392907973258

Epoch: 6| Step: 9
Training loss: 0.23446379601955414
Validation loss: 1.6398022341471847

Epoch: 6| Step: 10
Training loss: 0.24430802464485168
Validation loss: 1.6299730270139632

Epoch: 6| Step: 11
Training loss: 0.27429449558258057
Validation loss: 1.6570038731380174

Epoch: 6| Step: 12
Training loss: 0.39394280314445496
Validation loss: 1.687467699409813

Epoch: 6| Step: 13
Training loss: 0.16121621429920197
Validation loss: 1.6722191995190037

Epoch: 310| Step: 0
Training loss: 0.22493727505207062
Validation loss: 1.69693075841473

Epoch: 6| Step: 1
Training loss: 0.1764942705631256
Validation loss: 1.6839026122964837

Epoch: 6| Step: 2
Training loss: 0.16758349537849426
Validation loss: 1.7024042913990636

Epoch: 6| Step: 3
Training loss: 0.28772640228271484
Validation loss: 1.6759303462120794

Epoch: 6| Step: 4
Training loss: 0.31310150027275085
Validation loss: 1.6811913033967376

Epoch: 6| Step: 5
Training loss: 0.1634654998779297
Validation loss: 1.6693433676996539

Epoch: 6| Step: 6
Training loss: 0.16411566734313965
Validation loss: 1.657842302835116

Epoch: 6| Step: 7
Training loss: 0.27171480655670166
Validation loss: 1.6512420126186904

Epoch: 6| Step: 8
Training loss: 0.22339683771133423
Validation loss: 1.5909538743316487

Epoch: 6| Step: 9
Training loss: 0.3192375600337982
Validation loss: 1.601821296958513

Epoch: 6| Step: 10
Training loss: 0.24435466527938843
Validation loss: 1.5904200077056885

Epoch: 6| Step: 11
Training loss: 0.11035741865634918
Validation loss: 1.613956884671283

Epoch: 6| Step: 12
Training loss: 0.16224247217178345
Validation loss: 1.6189576259223364

Epoch: 6| Step: 13
Training loss: 0.15934480726718903
Validation loss: 1.5920412348162742

Epoch: 311| Step: 0
Training loss: 0.22261977195739746
Validation loss: 1.6111477164811985

Epoch: 6| Step: 1
Training loss: 0.13998770713806152
Validation loss: 1.6067372752774147

Epoch: 6| Step: 2
Training loss: 0.18635067343711853
Validation loss: 1.61668820534983

Epoch: 6| Step: 3
Training loss: 0.14787544310092926
Validation loss: 1.6514263569667775

Epoch: 6| Step: 4
Training loss: 0.14636321365833282
Validation loss: 1.6185544190868255

Epoch: 6| Step: 5
Training loss: 0.23952080309391022
Validation loss: 1.6179757002861268

Epoch: 6| Step: 6
Training loss: 0.17700862884521484
Validation loss: 1.6076075389821043

Epoch: 6| Step: 7
Training loss: 0.2722514271736145
Validation loss: 1.6134423889139646

Epoch: 6| Step: 8
Training loss: 0.21588242053985596
Validation loss: 1.6123314852355628

Epoch: 6| Step: 9
Training loss: 0.18815016746520996
Validation loss: 1.6110673668564006

Epoch: 6| Step: 10
Training loss: 0.30450767278671265
Validation loss: 1.6364389452882993

Epoch: 6| Step: 11
Training loss: 0.33119529485702515
Validation loss: 1.6666670076308712

Epoch: 6| Step: 12
Training loss: 0.36848002672195435
Validation loss: 1.676701799515755

Epoch: 6| Step: 13
Training loss: 0.5290029644966125
Validation loss: 1.7115784101588751

Epoch: 312| Step: 0
Training loss: 0.10766273736953735
Validation loss: 1.7211405961744246

Epoch: 6| Step: 1
Training loss: 0.3215264081954956
Validation loss: 1.6934773293874597

Epoch: 6| Step: 2
Training loss: 0.31352975964546204
Validation loss: 1.742840996352575

Epoch: 6| Step: 3
Training loss: 0.1971469670534134
Validation loss: 1.7224242661588935

Epoch: 6| Step: 4
Training loss: 0.2354225516319275
Validation loss: 1.7438623674454228

Epoch: 6| Step: 5
Training loss: 0.13522492349147797
Validation loss: 1.7559891541798909

Epoch: 6| Step: 6
Training loss: 0.3348490595817566
Validation loss: 1.7231839779884583

Epoch: 6| Step: 7
Training loss: 0.18723134696483612
Validation loss: 1.731866931402555

Epoch: 6| Step: 8
Training loss: 0.21529805660247803
Validation loss: 1.702987758062219

Epoch: 6| Step: 9
Training loss: 0.24794498085975647
Validation loss: 1.7149446472044914

Epoch: 6| Step: 10
Training loss: 0.22387054562568665
Validation loss: 1.7181661103361396

Epoch: 6| Step: 11
Training loss: 0.37034913897514343
Validation loss: 1.722934361427061

Epoch: 6| Step: 12
Training loss: 0.29192644357681274
Validation loss: 1.7313552518044748

Epoch: 6| Step: 13
Training loss: 0.11628586798906326
Validation loss: 1.719955240526507

Epoch: 313| Step: 0
Training loss: 0.18344484269618988
Validation loss: 1.712369038212684

Epoch: 6| Step: 1
Training loss: 0.20464737713336945
Validation loss: 1.6917617564560266

Epoch: 6| Step: 2
Training loss: 0.24847835302352905
Validation loss: 1.676819480875487

Epoch: 6| Step: 3
Training loss: 0.1909005492925644
Validation loss: 1.678948712605302

Epoch: 6| Step: 4
Training loss: 0.18960319459438324
Validation loss: 1.6614625569312804

Epoch: 6| Step: 5
Training loss: 0.2926531732082367
Validation loss: 1.6411506309304187

Epoch: 6| Step: 6
Training loss: 0.13496994972229004
Validation loss: 1.6832423415235294

Epoch: 6| Step: 7
Training loss: 0.120043084025383
Validation loss: 1.6625136854828044

Epoch: 6| Step: 8
Training loss: 0.47812503576278687
Validation loss: 1.6526264605983612

Epoch: 6| Step: 9
Training loss: 0.25085678696632385
Validation loss: 1.6746662765420892

Epoch: 6| Step: 10
Training loss: 0.29960134625434875
Validation loss: 1.682344853237111

Epoch: 6| Step: 11
Training loss: 0.18150004744529724
Validation loss: 1.6516323192145235

Epoch: 6| Step: 12
Training loss: 0.22733154892921448
Validation loss: 1.6967593328927153

Epoch: 6| Step: 13
Training loss: 0.37529414892196655
Validation loss: 1.6885245205253683

Epoch: 314| Step: 0
Training loss: 0.1264730989933014
Validation loss: 1.644262594561423

Epoch: 6| Step: 1
Training loss: 0.3070791959762573
Validation loss: 1.6710168418063913

Epoch: 6| Step: 2
Training loss: 0.21025502681732178
Validation loss: 1.6612224719857658

Epoch: 6| Step: 3
Training loss: 0.2448650449514389
Validation loss: 1.6895615413624754

Epoch: 6| Step: 4
Training loss: 0.1602405160665512
Validation loss: 1.6758200071191276

Epoch: 6| Step: 5
Training loss: 0.3307868242263794
Validation loss: 1.6829236079287786

Epoch: 6| Step: 6
Training loss: 0.28220510482788086
Validation loss: 1.664538057901526

Epoch: 6| Step: 7
Training loss: 0.28237882256507874
Validation loss: 1.6772555510203044

Epoch: 6| Step: 8
Training loss: 0.2861519455909729
Validation loss: 1.710574250067434

Epoch: 6| Step: 9
Training loss: 0.2769400477409363
Validation loss: 1.6960752574346398

Epoch: 6| Step: 10
Training loss: 0.3376310467720032
Validation loss: 1.6933483462179861

Epoch: 6| Step: 11
Training loss: 0.16081473231315613
Validation loss: 1.6625006647520169

Epoch: 6| Step: 12
Training loss: 0.24526157975196838
Validation loss: 1.6396305561065674

Epoch: 6| Step: 13
Training loss: 0.2676376700401306
Validation loss: 1.6263188610794723

Epoch: 315| Step: 0
Training loss: 0.10408742725849152
Validation loss: 1.6187349916786276

Epoch: 6| Step: 1
Training loss: 0.1476140320301056
Validation loss: 1.6092635611052155

Epoch: 6| Step: 2
Training loss: 0.4223010540008545
Validation loss: 1.6321965456008911

Epoch: 6| Step: 3
Training loss: 0.17766478657722473
Validation loss: 1.611683027718657

Epoch: 6| Step: 4
Training loss: 0.3012760877609253
Validation loss: 1.6237061792804348

Epoch: 6| Step: 5
Training loss: 0.36077600717544556
Validation loss: 1.638451531369199

Epoch: 6| Step: 6
Training loss: 0.16047140955924988
Validation loss: 1.6253157213170042

Epoch: 6| Step: 7
Training loss: 0.252960741519928
Validation loss: 1.6523259929431382

Epoch: 6| Step: 8
Training loss: 0.16595083475112915
Validation loss: 1.6366969770000828

Epoch: 6| Step: 9
Training loss: 0.20591306686401367
Validation loss: 1.6659901142120361

Epoch: 6| Step: 10
Training loss: 0.19448721408843994
Validation loss: 1.6463129969053372

Epoch: 6| Step: 11
Training loss: 0.2183363139629364
Validation loss: 1.6625443812339538

Epoch: 6| Step: 12
Training loss: 0.21544653177261353
Validation loss: 1.629062965352048

Epoch: 6| Step: 13
Training loss: 0.1984466016292572
Validation loss: 1.6140804162589453

Epoch: 316| Step: 0
Training loss: 0.19060301780700684
Validation loss: 1.63753633088963

Epoch: 6| Step: 1
Training loss: 0.19422799348831177
Validation loss: 1.6337837583275252

Epoch: 6| Step: 2
Training loss: 0.30454450845718384
Validation loss: 1.605529103227841

Epoch: 6| Step: 3
Training loss: 0.14707252383232117
Validation loss: 1.6221588965385192

Epoch: 6| Step: 4
Training loss: 0.3072158694267273
Validation loss: 1.6063603983130506

Epoch: 6| Step: 5
Training loss: 0.2674142122268677
Validation loss: 1.6183966218784291

Epoch: 6| Step: 6
Training loss: 0.20588773488998413
Validation loss: 1.620525360748332

Epoch: 6| Step: 7
Training loss: 0.23602908849716187
Validation loss: 1.6644690254683137

Epoch: 6| Step: 8
Training loss: 0.1948413997888565
Validation loss: 1.6735986894176853

Epoch: 6| Step: 9
Training loss: 0.2539424002170563
Validation loss: 1.6844901141299997

Epoch: 6| Step: 10
Training loss: 0.183345764875412
Validation loss: 1.6691849564993253

Epoch: 6| Step: 11
Training loss: 0.16590294241905212
Validation loss: 1.652685631987869

Epoch: 6| Step: 12
Training loss: 0.18257880210876465
Validation loss: 1.6619174518892843

Epoch: 6| Step: 13
Training loss: 0.2910371720790863
Validation loss: 1.6216887197186869

Epoch: 317| Step: 0
Training loss: 0.16116684675216675
Validation loss: 1.6209006988874046

Epoch: 6| Step: 1
Training loss: 0.1687299907207489
Validation loss: 1.6148705392755487

Epoch: 6| Step: 2
Training loss: 0.29180580377578735
Validation loss: 1.6057064366597

Epoch: 6| Step: 3
Training loss: 0.29230108857154846
Validation loss: 1.5927206752120808

Epoch: 6| Step: 4
Training loss: 0.18202926218509674
Validation loss: 1.5695936513203446

Epoch: 6| Step: 5
Training loss: 0.16645565629005432
Validation loss: 1.5909010633345573

Epoch: 6| Step: 6
Training loss: 0.30194994807243347
Validation loss: 1.586534959013744

Epoch: 6| Step: 7
Training loss: 0.34566730260849
Validation loss: 1.6079944026085637

Epoch: 6| Step: 8
Training loss: 0.2655182480812073
Validation loss: 1.6104414360497588

Epoch: 6| Step: 9
Training loss: 0.13907232880592346
Validation loss: 1.627565013465061

Epoch: 6| Step: 10
Training loss: 0.19209250807762146
Validation loss: 1.599048868302376

Epoch: 6| Step: 11
Training loss: 0.16222792863845825
Validation loss: 1.624036499249038

Epoch: 6| Step: 12
Training loss: 0.12186530232429504
Validation loss: 1.6180343128019763

Epoch: 6| Step: 13
Training loss: 0.23209476470947266
Validation loss: 1.6358232857078634

Epoch: 318| Step: 0
Training loss: 0.14023736119270325
Validation loss: 1.6543156946859052

Epoch: 6| Step: 1
Training loss: 0.1309220939874649
Validation loss: 1.692409123143842

Epoch: 6| Step: 2
Training loss: 0.18009433150291443
Validation loss: 1.6710318929405623

Epoch: 6| Step: 3
Training loss: 0.36995023488998413
Validation loss: 1.6771147892039309

Epoch: 6| Step: 4
Training loss: 0.2151496857404709
Validation loss: 1.6842119430982938

Epoch: 6| Step: 5
Training loss: 0.2354002296924591
Validation loss: 1.6634020523358417

Epoch: 6| Step: 6
Training loss: 0.25443196296691895
Validation loss: 1.6686682957474903

Epoch: 6| Step: 7
Training loss: 0.27402713894844055
Validation loss: 1.6498581414581628

Epoch: 6| Step: 8
Training loss: 0.16967472434043884
Validation loss: 1.6250731996310654

Epoch: 6| Step: 9
Training loss: 0.16096335649490356
Validation loss: 1.6046733651109921

Epoch: 6| Step: 10
Training loss: 0.2633213400840759
Validation loss: 1.6028809060332596

Epoch: 6| Step: 11
Training loss: 0.30501818656921387
Validation loss: 1.6182835255899737

Epoch: 6| Step: 12
Training loss: 0.16055768728256226
Validation loss: 1.6166452848783104

Epoch: 6| Step: 13
Training loss: 0.13196271657943726
Validation loss: 1.6257950311066003

Epoch: 319| Step: 0
Training loss: 0.12506014108657837
Validation loss: 1.6220713841017855

Epoch: 6| Step: 1
Training loss: 0.22158212959766388
Validation loss: 1.6511348409037436

Epoch: 6| Step: 2
Training loss: 0.14824751019477844
Validation loss: 1.6505564130762571

Epoch: 6| Step: 3
Training loss: 0.13843338191509247
Validation loss: 1.6595007373440651

Epoch: 6| Step: 4
Training loss: 0.230987086892128
Validation loss: 1.643856821521636

Epoch: 6| Step: 5
Training loss: 0.21384455263614655
Validation loss: 1.6349543768872496

Epoch: 6| Step: 6
Training loss: 0.20978312194347382
Validation loss: 1.632865318047103

Epoch: 6| Step: 7
Training loss: 0.2948787212371826
Validation loss: 1.5890509159334245

Epoch: 6| Step: 8
Training loss: 0.1385825276374817
Validation loss: 1.581046639591135

Epoch: 6| Step: 9
Training loss: 0.36808866262435913
Validation loss: 1.5534495730553903

Epoch: 6| Step: 10
Training loss: 0.21458008885383606
Validation loss: 1.5797181052546347

Epoch: 6| Step: 11
Training loss: 0.1746589094400406
Validation loss: 1.567569807011594

Epoch: 6| Step: 12
Training loss: 0.22610808908939362
Validation loss: 1.590707677666859

Epoch: 6| Step: 13
Training loss: 0.10996748507022858
Validation loss: 1.6031398145101403

Epoch: 320| Step: 0
Training loss: 0.18573090434074402
Validation loss: 1.6284742111800818

Epoch: 6| Step: 1
Training loss: 0.11687364429235458
Validation loss: 1.6311229121300481

Epoch: 6| Step: 2
Training loss: 0.2961956262588501
Validation loss: 1.6608520246321155

Epoch: 6| Step: 3
Training loss: 0.13953325152397156
Validation loss: 1.673148480794763

Epoch: 6| Step: 4
Training loss: 0.2008940577507019
Validation loss: 1.6445891190600652

Epoch: 6| Step: 5
Training loss: 0.23274461925029755
Validation loss: 1.6335479969619422

Epoch: 6| Step: 6
Training loss: 0.1628451943397522
Validation loss: 1.6184121575406802

Epoch: 6| Step: 7
Training loss: 0.10394809395074844
Validation loss: 1.6256183738349586

Epoch: 6| Step: 8
Training loss: 0.29918450117111206
Validation loss: 1.609321521174523

Epoch: 6| Step: 9
Training loss: 0.130308598279953
Validation loss: 1.6092566354300386

Epoch: 6| Step: 10
Training loss: 0.10733368992805481
Validation loss: 1.6145713419042609

Epoch: 6| Step: 11
Training loss: 0.16509486734867096
Validation loss: 1.5915770505064277

Epoch: 6| Step: 12
Training loss: 0.22373592853546143
Validation loss: 1.6025877114265197

Epoch: 6| Step: 13
Training loss: 0.11444231867790222
Validation loss: 1.5990575833987164

Epoch: 321| Step: 0
Training loss: 0.14307299256324768
Validation loss: 1.6279705057861984

Epoch: 6| Step: 1
Training loss: 0.1689557582139969
Validation loss: 1.6455036030020764

Epoch: 6| Step: 2
Training loss: 0.22849991917610168
Validation loss: 1.6790867723444456

Epoch: 6| Step: 3
Training loss: 0.33621031045913696
Validation loss: 1.6728480144213604

Epoch: 6| Step: 4
Training loss: 0.15774574875831604
Validation loss: 1.664242531663628

Epoch: 6| Step: 5
Training loss: 0.2260591834783554
Validation loss: 1.7020001090982908

Epoch: 6| Step: 6
Training loss: 0.18730822205543518
Validation loss: 1.6813365490205827

Epoch: 6| Step: 7
Training loss: 0.25361716747283936
Validation loss: 1.6459136291216778

Epoch: 6| Step: 8
Training loss: 0.18846487998962402
Validation loss: 1.619929208550402

Epoch: 6| Step: 9
Training loss: 0.2100353240966797
Validation loss: 1.594209441574671

Epoch: 6| Step: 10
Training loss: 0.14528779685497284
Validation loss: 1.6097529998389624

Epoch: 6| Step: 11
Training loss: 0.19597293436527252
Validation loss: 1.5714029240351852

Epoch: 6| Step: 12
Training loss: 0.2904558777809143
Validation loss: 1.5752077807662308

Epoch: 6| Step: 13
Training loss: 0.1936933398246765
Validation loss: 1.5856723368808787

Epoch: 322| Step: 0
Training loss: 0.16795293986797333
Validation loss: 1.5947379245552966

Epoch: 6| Step: 1
Training loss: 0.11018286645412445
Validation loss: 1.6225903559756536

Epoch: 6| Step: 2
Training loss: 0.29326146841049194
Validation loss: 1.665397765815899

Epoch: 6| Step: 3
Training loss: 0.2721920609474182
Validation loss: 1.6641227904186453

Epoch: 6| Step: 4
Training loss: 0.2434815615415573
Validation loss: 1.6375543558469383

Epoch: 6| Step: 5
Training loss: 0.20235034823417664
Validation loss: 1.6506396852513796

Epoch: 6| Step: 6
Training loss: 0.20133760571479797
Validation loss: 1.658575898857527

Epoch: 6| Step: 7
Training loss: 0.17772604525089264
Validation loss: 1.6552558945071312

Epoch: 6| Step: 8
Training loss: 0.22339273989200592
Validation loss: 1.6356715127345054

Epoch: 6| Step: 9
Training loss: 0.09421859681606293
Validation loss: 1.6672850321697932

Epoch: 6| Step: 10
Training loss: 0.14931342005729675
Validation loss: 1.6152820946067892

Epoch: 6| Step: 11
Training loss: 0.15141496062278748
Validation loss: 1.612730872246527

Epoch: 6| Step: 12
Training loss: 0.1433596909046173
Validation loss: 1.6154231691873202

Epoch: 6| Step: 13
Training loss: 0.30025023221969604
Validation loss: 1.5959315120532949

Epoch: 323| Step: 0
Training loss: 0.0875416174530983
Validation loss: 1.5949611356181483

Epoch: 6| Step: 1
Training loss: 0.1354479193687439
Validation loss: 1.6178677928063177

Epoch: 6| Step: 2
Training loss: 0.1363927721977234
Validation loss: 1.6578211374180292

Epoch: 6| Step: 3
Training loss: 0.21921858191490173
Validation loss: 1.650060958759759

Epoch: 6| Step: 4
Training loss: 0.10356825590133667
Validation loss: 1.6770546128672938

Epoch: 6| Step: 5
Training loss: 0.14002008736133575
Validation loss: 1.6868437951610935

Epoch: 6| Step: 6
Training loss: 0.3136776387691498
Validation loss: 1.6734652602544395

Epoch: 6| Step: 7
Training loss: 0.3289978802204132
Validation loss: 1.6623799929054834

Epoch: 6| Step: 8
Training loss: 0.2788650393486023
Validation loss: 1.6331497546165221

Epoch: 6| Step: 9
Training loss: 0.13065537810325623
Validation loss: 1.6197169583330873

Epoch: 6| Step: 10
Training loss: 0.298793762922287
Validation loss: 1.6458014980439217

Epoch: 6| Step: 11
Training loss: 0.16934140026569366
Validation loss: 1.5976334874347975

Epoch: 6| Step: 12
Training loss: 0.24946185946464539
Validation loss: 1.6182549666332942

Epoch: 6| Step: 13
Training loss: 0.4648147225379944
Validation loss: 1.5955109288615565

Epoch: 324| Step: 0
Training loss: 0.16270878911018372
Validation loss: 1.6017847368794103

Epoch: 6| Step: 1
Training loss: 0.18336117267608643
Validation loss: 1.6034883940091698

Epoch: 6| Step: 2
Training loss: 0.23742784559726715
Validation loss: 1.6295192190395889

Epoch: 6| Step: 3
Training loss: 0.25315767526626587
Validation loss: 1.619372590895622

Epoch: 6| Step: 4
Training loss: 0.22365926206111908
Validation loss: 1.597654140123757

Epoch: 6| Step: 5
Training loss: 0.2172970473766327
Validation loss: 1.571393047609637

Epoch: 6| Step: 6
Training loss: 0.10449311882257462
Validation loss: 1.5661395115237082

Epoch: 6| Step: 7
Training loss: 0.2792913317680359
Validation loss: 1.597590624645192

Epoch: 6| Step: 8
Training loss: 0.2515212297439575
Validation loss: 1.5987701287833593

Epoch: 6| Step: 9
Training loss: 0.18006625771522522
Validation loss: 1.5995020879212247

Epoch: 6| Step: 10
Training loss: 0.2310885339975357
Validation loss: 1.617443118044125

Epoch: 6| Step: 11
Training loss: 0.2450104057788849
Validation loss: 1.6370177961164905

Epoch: 6| Step: 12
Training loss: 0.15949594974517822
Validation loss: 1.6347371224434144

Epoch: 6| Step: 13
Training loss: 0.09884564578533173
Validation loss: 1.6378556195125784

Epoch: 325| Step: 0
Training loss: 0.1389988660812378
Validation loss: 1.6375707990379744

Epoch: 6| Step: 1
Training loss: 0.15035168826580048
Validation loss: 1.6181466399982412

Epoch: 6| Step: 2
Training loss: 0.10472993552684784
Validation loss: 1.6371964152141283

Epoch: 6| Step: 3
Training loss: 0.21000456809997559
Validation loss: 1.6152986147070443

Epoch: 6| Step: 4
Training loss: 0.2009526491165161
Validation loss: 1.6136494067407423

Epoch: 6| Step: 5
Training loss: 0.16325247287750244
Validation loss: 1.6423233042481125

Epoch: 6| Step: 6
Training loss: 0.2831394672393799
Validation loss: 1.6134179048640753

Epoch: 6| Step: 7
Training loss: 0.15960624814033508
Validation loss: 1.607452138777702

Epoch: 6| Step: 8
Training loss: 0.26136183738708496
Validation loss: 1.5892830471838675

Epoch: 6| Step: 9
Training loss: 0.16048912703990936
Validation loss: 1.5583623218280014

Epoch: 6| Step: 10
Training loss: 0.10468680411577225
Validation loss: 1.5917318879917104

Epoch: 6| Step: 11
Training loss: 0.10996182262897491
Validation loss: 1.5625334478193713

Epoch: 6| Step: 12
Training loss: 0.24415865540504456
Validation loss: 1.5900646153316702

Epoch: 6| Step: 13
Training loss: 0.31299710273742676
Validation loss: 1.585831457568753

Epoch: 326| Step: 0
Training loss: 0.15002793073654175
Validation loss: 1.594233259077995

Epoch: 6| Step: 1
Training loss: 0.14193183183670044
Validation loss: 1.6024908865651777

Epoch: 6| Step: 2
Training loss: 0.16962826251983643
Validation loss: 1.5967456845827

Epoch: 6| Step: 3
Training loss: 0.35083988308906555
Validation loss: 1.6127894475895872

Epoch: 6| Step: 4
Training loss: 0.21856027841567993
Validation loss: 1.61854721653846

Epoch: 6| Step: 5
Training loss: 0.19937533140182495
Validation loss: 1.6206518385999946

Epoch: 6| Step: 6
Training loss: 0.12560021877288818
Validation loss: 1.6211237997137091

Epoch: 6| Step: 7
Training loss: 0.14864344894886017
Validation loss: 1.6302892456772506

Epoch: 6| Step: 8
Training loss: 0.1133122593164444
Validation loss: 1.584514057764443

Epoch: 6| Step: 9
Training loss: 0.13398945331573486
Validation loss: 1.5822275800089682

Epoch: 6| Step: 10
Training loss: 0.1646975576877594
Validation loss: 1.5616224145376554

Epoch: 6| Step: 11
Training loss: 0.18009155988693237
Validation loss: 1.578109879647532

Epoch: 6| Step: 12
Training loss: 0.23074579238891602
Validation loss: 1.55678306728281

Epoch: 6| Step: 13
Training loss: 0.17220929265022278
Validation loss: 1.5551359512472664

Epoch: 327| Step: 0
Training loss: 0.2986067533493042
Validation loss: 1.6114681407969484

Epoch: 6| Step: 1
Training loss: 0.11097028851509094
Validation loss: 1.6067306175026843

Epoch: 6| Step: 2
Training loss: 0.18457531929016113
Validation loss: 1.6165018940484652

Epoch: 6| Step: 3
Training loss: 0.24203288555145264
Validation loss: 1.5809391980530114

Epoch: 6| Step: 4
Training loss: 0.11618982255458832
Validation loss: 1.5822367873243106

Epoch: 6| Step: 5
Training loss: 0.09075023233890533
Validation loss: 1.572182455370503

Epoch: 6| Step: 6
Training loss: 0.2098626345396042
Validation loss: 1.6187979008561821

Epoch: 6| Step: 7
Training loss: 0.09786047041416168
Validation loss: 1.5767944641010736

Epoch: 6| Step: 8
Training loss: 0.13995389640331268
Validation loss: 1.6282300692732616

Epoch: 6| Step: 9
Training loss: 0.2598908841609955
Validation loss: 1.606508397286938

Epoch: 6| Step: 10
Training loss: 0.14596207439899445
Validation loss: 1.5955984054073211

Epoch: 6| Step: 11
Training loss: 0.23341475427150726
Validation loss: 1.6138626452415221

Epoch: 6| Step: 12
Training loss: 0.22414430975914001
Validation loss: 1.5917587357182656

Epoch: 6| Step: 13
Training loss: 0.06188138201832771
Validation loss: 1.6078231962778236

Epoch: 328| Step: 0
Training loss: 0.21923789381980896
Validation loss: 1.606814621597208

Epoch: 6| Step: 1
Training loss: 0.27810800075531006
Validation loss: 1.6082086627201369

Epoch: 6| Step: 2
Training loss: 0.27082571387290955
Validation loss: 1.560275553375162

Epoch: 6| Step: 3
Training loss: 0.11586962640285492
Validation loss: 1.5705540744207238

Epoch: 6| Step: 4
Training loss: 0.08068317174911499
Validation loss: 1.5410592889273038

Epoch: 6| Step: 5
Training loss: 0.1328403353691101
Validation loss: 1.5396592899035382

Epoch: 6| Step: 6
Training loss: 0.20442268252372742
Validation loss: 1.5236882394359959

Epoch: 6| Step: 7
Training loss: 0.18465228378772736
Validation loss: 1.5489047804186422

Epoch: 6| Step: 8
Training loss: 0.14847269654273987
Validation loss: 1.5259115119134226

Epoch: 6| Step: 9
Training loss: 0.2144962102174759
Validation loss: 1.5670132675478536

Epoch: 6| Step: 10
Training loss: 0.12442465126514435
Validation loss: 1.6015459837452057

Epoch: 6| Step: 11
Training loss: 0.16142773628234863
Validation loss: 1.6253513930946268

Epoch: 6| Step: 12
Training loss: 0.1336456537246704
Validation loss: 1.6107025979667582

Epoch: 6| Step: 13
Training loss: 0.1250891238451004
Validation loss: 1.6393963585617721

Epoch: 329| Step: 0
Training loss: 0.32356759905815125
Validation loss: 1.6251578106675098

Epoch: 6| Step: 1
Training loss: 0.14651015400886536
Validation loss: 1.634796456624103

Epoch: 6| Step: 2
Training loss: 0.09709890186786652
Validation loss: 1.5855600167346258

Epoch: 6| Step: 3
Training loss: 0.18472012877464294
Validation loss: 1.5688074654148472

Epoch: 6| Step: 4
Training loss: 0.18891599774360657
Validation loss: 1.5821865322769328

Epoch: 6| Step: 5
Training loss: 0.17576713860034943
Validation loss: 1.5892108608317632

Epoch: 6| Step: 6
Training loss: 0.09052366763353348
Validation loss: 1.6070140061839935

Epoch: 6| Step: 7
Training loss: 0.13484883308410645
Validation loss: 1.619847991774159

Epoch: 6| Step: 8
Training loss: 0.13448989391326904
Validation loss: 1.6138902876966743

Epoch: 6| Step: 9
Training loss: 0.3967371881008148
Validation loss: 1.589173222100863

Epoch: 6| Step: 10
Training loss: 0.12679609656333923
Validation loss: 1.5759469270706177

Epoch: 6| Step: 11
Training loss: 0.1912578046321869
Validation loss: 1.607081191514128

Epoch: 6| Step: 12
Training loss: 0.14136460423469543
Validation loss: 1.5785507745640253

Epoch: 6| Step: 13
Training loss: 0.1413085162639618
Validation loss: 1.6083766645000828

Epoch: 330| Step: 0
Training loss: 0.19859522581100464
Validation loss: 1.5695194454603298

Epoch: 6| Step: 1
Training loss: 0.11264044046401978
Validation loss: 1.5967051393242293

Epoch: 6| Step: 2
Training loss: 0.2425566166639328
Validation loss: 1.6467868326812662

Epoch: 6| Step: 3
Training loss: 0.16372841596603394
Validation loss: 1.6382407308906637

Epoch: 6| Step: 4
Training loss: 0.15414130687713623
Validation loss: 1.6254227712590208

Epoch: 6| Step: 5
Training loss: 0.16693857312202454
Validation loss: 1.6221915086110432

Epoch: 6| Step: 6
Training loss: 0.2429901510477066
Validation loss: 1.6203398986529278

Epoch: 6| Step: 7
Training loss: 0.08533282577991486
Validation loss: 1.6049000691342097

Epoch: 6| Step: 8
Training loss: 0.11573366820812225
Validation loss: 1.6226431323635964

Epoch: 6| Step: 9
Training loss: 0.08600496500730515
Validation loss: 1.5956716640021211

Epoch: 6| Step: 10
Training loss: 0.3046974837779999
Validation loss: 1.6153032164419852

Epoch: 6| Step: 11
Training loss: 0.3149997591972351
Validation loss: 1.6020192330883396

Epoch: 6| Step: 12
Training loss: 0.14615900814533234
Validation loss: 1.5850563856863207

Epoch: 6| Step: 13
Training loss: 0.16280582547187805
Validation loss: 1.5782460320380427

Epoch: 331| Step: 0
Training loss: 0.3659343719482422
Validation loss: 1.5749462253303939

Epoch: 6| Step: 1
Training loss: 0.11164477467536926
Validation loss: 1.5816581351782686

Epoch: 6| Step: 2
Training loss: 0.15631887316703796
Validation loss: 1.5911803130180604

Epoch: 6| Step: 3
Training loss: 0.23499131202697754
Validation loss: 1.6178646164555703

Epoch: 6| Step: 4
Training loss: 0.22272475063800812
Validation loss: 1.6224767905409618

Epoch: 6| Step: 5
Training loss: 0.1035914421081543
Validation loss: 1.6346921228593396

Epoch: 6| Step: 6
Training loss: 0.10829149186611176
Validation loss: 1.6554570505695958

Epoch: 6| Step: 7
Training loss: 0.25380823016166687
Validation loss: 1.6374002810447448

Epoch: 6| Step: 8
Training loss: 0.15179811418056488
Validation loss: 1.5863644833205848

Epoch: 6| Step: 9
Training loss: 0.18962505459785461
Validation loss: 1.6091763896326865

Epoch: 6| Step: 10
Training loss: 0.14436973631381989
Validation loss: 1.5588887532552083

Epoch: 6| Step: 11
Training loss: 0.198448047041893
Validation loss: 1.5561966870420723

Epoch: 6| Step: 12
Training loss: 0.18851320445537567
Validation loss: 1.5815109091420327

Epoch: 6| Step: 13
Training loss: 0.3204094469547272
Validation loss: 1.5727180165629233

Epoch: 332| Step: 0
Training loss: 0.21559830009937286
Validation loss: 1.5867698884779406

Epoch: 6| Step: 1
Training loss: 0.17680905759334564
Validation loss: 1.6050886992485291

Epoch: 6| Step: 2
Training loss: 0.11257214844226837
Validation loss: 1.5904056666999735

Epoch: 6| Step: 3
Training loss: 0.1792374551296234
Validation loss: 1.6265738625680246

Epoch: 6| Step: 4
Training loss: 0.13342279195785522
Validation loss: 1.6317807102716098

Epoch: 6| Step: 5
Training loss: 0.30631735920906067
Validation loss: 1.6633084538162395

Epoch: 6| Step: 6
Training loss: 0.14919555187225342
Validation loss: 1.6663110160058545

Epoch: 6| Step: 7
Training loss: 0.1063792034983635
Validation loss: 1.6715648571650188

Epoch: 6| Step: 8
Training loss: 0.18417951464653015
Validation loss: 1.693450967470805

Epoch: 6| Step: 9
Training loss: 0.29979103803634644
Validation loss: 1.6788512808020397

Epoch: 6| Step: 10
Training loss: 0.14035534858703613
Validation loss: 1.6680870030515937

Epoch: 6| Step: 11
Training loss: 0.28926873207092285
Validation loss: 1.6471745134681783

Epoch: 6| Step: 12
Training loss: 0.20294445753097534
Validation loss: 1.6432337876289123

Epoch: 6| Step: 13
Training loss: 0.13152503967285156
Validation loss: 1.6137553748264108

Epoch: 333| Step: 0
Training loss: 0.16137957572937012
Validation loss: 1.6239390142502323

Epoch: 6| Step: 1
Training loss: 0.176246777176857
Validation loss: 1.620988829161531

Epoch: 6| Step: 2
Training loss: 0.1437739133834839
Validation loss: 1.6022278942087644

Epoch: 6| Step: 3
Training loss: 0.13422241806983948
Validation loss: 1.632109603574199

Epoch: 6| Step: 4
Training loss: 0.15885865688323975
Validation loss: 1.6663754678541614

Epoch: 6| Step: 5
Training loss: 0.11725376546382904
Validation loss: 1.6414860269074798

Epoch: 6| Step: 6
Training loss: 0.11810861527919769
Validation loss: 1.625483230877948

Epoch: 6| Step: 7
Training loss: 0.09530390053987503
Validation loss: 1.6416176288358626

Epoch: 6| Step: 8
Training loss: 0.2078559398651123
Validation loss: 1.6563953020239388

Epoch: 6| Step: 9
Training loss: 0.156950443983078
Validation loss: 1.6926904474535296

Epoch: 6| Step: 10
Training loss: 0.20980674028396606
Validation loss: 1.6738032961404452

Epoch: 6| Step: 11
Training loss: 0.31994131207466125
Validation loss: 1.6776856863370506

Epoch: 6| Step: 12
Training loss: 0.21311506628990173
Validation loss: 1.6753384297893894

Epoch: 6| Step: 13
Training loss: 0.11200042814016342
Validation loss: 1.6883020567637619

Epoch: 334| Step: 0
Training loss: 0.17380017042160034
Validation loss: 1.6919944337619248

Epoch: 6| Step: 1
Training loss: 0.24329431354999542
Validation loss: 1.7074654486871534

Epoch: 6| Step: 2
Training loss: 0.22730019688606262
Validation loss: 1.6728846949915732

Epoch: 6| Step: 3
Training loss: 0.266399085521698
Validation loss: 1.6301291014558525

Epoch: 6| Step: 4
Training loss: 0.11021101474761963
Validation loss: 1.6397933575414843

Epoch: 6| Step: 5
Training loss: 0.11573413014411926
Validation loss: 1.6330598682485602

Epoch: 6| Step: 6
Training loss: 0.3381461203098297
Validation loss: 1.6127486959580453

Epoch: 6| Step: 7
Training loss: 0.146098330616951
Validation loss: 1.6062913902344242

Epoch: 6| Step: 8
Training loss: 0.20966887474060059
Validation loss: 1.6259179346023067

Epoch: 6| Step: 9
Training loss: 0.14166279137134552
Validation loss: 1.6126266987093034

Epoch: 6| Step: 10
Training loss: 0.10099291056394577
Validation loss: 1.6336261444194342

Epoch: 6| Step: 11
Training loss: 0.12120800465345383
Validation loss: 1.6462042600877824

Epoch: 6| Step: 12
Training loss: 0.14285418391227722
Validation loss: 1.6673981835765224

Epoch: 6| Step: 13
Training loss: 0.20278829336166382
Validation loss: 1.7068319371951524

Epoch: 335| Step: 0
Training loss: 0.09511317312717438
Validation loss: 1.73760393358046

Epoch: 6| Step: 1
Training loss: 0.2633346617221832
Validation loss: 1.7316920167656356

Epoch: 6| Step: 2
Training loss: 0.2033296823501587
Validation loss: 1.744285265604655

Epoch: 6| Step: 3
Training loss: 0.2517833113670349
Validation loss: 1.7145249407778504

Epoch: 6| Step: 4
Training loss: 0.1585390567779541
Validation loss: 1.6966654869817919

Epoch: 6| Step: 5
Training loss: 0.2323242425918579
Validation loss: 1.6740041778933616

Epoch: 6| Step: 6
Training loss: 0.16371434926986694
Validation loss: 1.6142087123727287

Epoch: 6| Step: 7
Training loss: 0.13477519154548645
Validation loss: 1.5979563798955692

Epoch: 6| Step: 8
Training loss: 0.18169079720973969
Validation loss: 1.5618238423460273

Epoch: 6| Step: 9
Training loss: 0.1538706123828888
Validation loss: 1.5762448836398382

Epoch: 6| Step: 10
Training loss: 0.2168707251548767
Validation loss: 1.5515946777918006

Epoch: 6| Step: 11
Training loss: 0.11485325545072556
Validation loss: 1.5379997402109125

Epoch: 6| Step: 12
Training loss: 0.22526344656944275
Validation loss: 1.5672391524878881

Epoch: 6| Step: 13
Training loss: 0.1563624143600464
Validation loss: 1.566406415354821

Epoch: 336| Step: 0
Training loss: 0.20109853148460388
Validation loss: 1.569786371723298

Epoch: 6| Step: 1
Training loss: 0.17476625740528107
Validation loss: 1.5986341904568415

Epoch: 6| Step: 2
Training loss: 0.25503575801849365
Validation loss: 1.6405249205968713

Epoch: 6| Step: 3
Training loss: 0.19456270337104797
Validation loss: 1.6336567017339891

Epoch: 6| Step: 4
Training loss: 0.16918694972991943
Validation loss: 1.6123686298247306

Epoch: 6| Step: 5
Training loss: 0.3007328510284424
Validation loss: 1.6220129971863122

Epoch: 6| Step: 6
Training loss: 0.1148863434791565
Validation loss: 1.62334236919239

Epoch: 6| Step: 7
Training loss: 0.1552412211894989
Validation loss: 1.5845393685884372

Epoch: 6| Step: 8
Training loss: 0.2349075973033905
Validation loss: 1.5976884467627412

Epoch: 6| Step: 9
Training loss: 0.09281785786151886
Validation loss: 1.5956691375342749

Epoch: 6| Step: 10
Training loss: 0.1750921607017517
Validation loss: 1.5999550024668376

Epoch: 6| Step: 11
Training loss: 0.11749686300754547
Validation loss: 1.60533820813702

Epoch: 6| Step: 12
Training loss: 0.152227520942688
Validation loss: 1.5837368016601892

Epoch: 6| Step: 13
Training loss: 0.11276596039533615
Validation loss: 1.5774894632318968

Epoch: 337| Step: 0
Training loss: 0.2145283967256546
Validation loss: 1.604316940871618

Epoch: 6| Step: 1
Training loss: 0.1436322033405304
Validation loss: 1.5820936977222402

Epoch: 6| Step: 2
Training loss: 0.14734145998954773
Validation loss: 1.5879368256497126

Epoch: 6| Step: 3
Training loss: 0.1398744434118271
Validation loss: 1.5644356685300027

Epoch: 6| Step: 4
Training loss: 0.14547917246818542
Validation loss: 1.5769189775630992

Epoch: 6| Step: 5
Training loss: 0.21903452277183533
Validation loss: 1.5817755012102024

Epoch: 6| Step: 6
Training loss: 0.06503008306026459
Validation loss: 1.5938150421265633

Epoch: 6| Step: 7
Training loss: 0.1279948353767395
Validation loss: 1.5949219760074411

Epoch: 6| Step: 8
Training loss: 0.23724396526813507
Validation loss: 1.6159599442635812

Epoch: 6| Step: 9
Training loss: 0.15669316053390503
Validation loss: 1.637310076785344

Epoch: 6| Step: 10
Training loss: 0.13448989391326904
Validation loss: 1.6329192192323747

Epoch: 6| Step: 11
Training loss: 0.2642669677734375
Validation loss: 1.6249593175867552

Epoch: 6| Step: 12
Training loss: 0.27838432788848877
Validation loss: 1.6213456084651332

Epoch: 6| Step: 13
Training loss: 0.16059593856334686
Validation loss: 1.5999715712762648

Epoch: 338| Step: 0
Training loss: 0.13213461637496948
Validation loss: 1.6078861234008626

Epoch: 6| Step: 1
Training loss: 0.15718883275985718
Validation loss: 1.5573388479089225

Epoch: 6| Step: 2
Training loss: 0.1655663549900055
Validation loss: 1.5499739352092947

Epoch: 6| Step: 3
Training loss: 0.18051552772521973
Validation loss: 1.5648133844457648

Epoch: 6| Step: 4
Training loss: 0.12238997966051102
Validation loss: 1.5430085203980888

Epoch: 6| Step: 5
Training loss: 0.11669715493917465
Validation loss: 1.552054016820846

Epoch: 6| Step: 6
Training loss: 0.15083561837673187
Validation loss: 1.5678988727190162

Epoch: 6| Step: 7
Training loss: 0.2992449402809143
Validation loss: 1.5807885835247655

Epoch: 6| Step: 8
Training loss: 0.156127467751503
Validation loss: 1.5578090734379266

Epoch: 6| Step: 9
Training loss: 0.20936554670333862
Validation loss: 1.5830328259416806

Epoch: 6| Step: 10
Training loss: 0.13618473708629608
Validation loss: 1.5723029272530669

Epoch: 6| Step: 11
Training loss: 0.1900237798690796
Validation loss: 1.571427070966331

Epoch: 6| Step: 12
Training loss: 0.14229997992515564
Validation loss: 1.5921233110530402

Epoch: 6| Step: 13
Training loss: 0.23817706108093262
Validation loss: 1.591287390519214

Epoch: 339| Step: 0
Training loss: 0.09818369150161743
Validation loss: 1.5904393965198147

Epoch: 6| Step: 1
Training loss: 0.26341119408607483
Validation loss: 1.6175709962844849

Epoch: 6| Step: 2
Training loss: 0.11114125698804855
Validation loss: 1.604701344684888

Epoch: 6| Step: 3
Training loss: 0.22449812293052673
Validation loss: 1.5880229960205734

Epoch: 6| Step: 4
Training loss: 0.20361246168613434
Validation loss: 1.5948541574580695

Epoch: 6| Step: 5
Training loss: 0.148624449968338
Validation loss: 1.5846105314070178

Epoch: 6| Step: 6
Training loss: 0.12449374794960022
Validation loss: 1.5913261751974783

Epoch: 6| Step: 7
Training loss: 0.1583189070224762
Validation loss: 1.570879142771485

Epoch: 6| Step: 8
Training loss: 0.16346505284309387
Validation loss: 1.5537843345313944

Epoch: 6| Step: 9
Training loss: 0.18107643723487854
Validation loss: 1.5818362748751076

Epoch: 6| Step: 10
Training loss: 0.25561806559562683
Validation loss: 1.5530104637145996

Epoch: 6| Step: 11
Training loss: 0.14200831949710846
Validation loss: 1.552595983269394

Epoch: 6| Step: 12
Training loss: 0.1353783756494522
Validation loss: 1.5540619492530823

Epoch: 6| Step: 13
Training loss: 0.14962540566921234
Validation loss: 1.577069405586489

Epoch: 340| Step: 0
Training loss: 0.12391601502895355
Validation loss: 1.5986085361050022

Epoch: 6| Step: 1
Training loss: 0.160615012049675
Validation loss: 1.609271328936341

Epoch: 6| Step: 2
Training loss: 0.11045439541339874
Validation loss: 1.6101716910639117

Epoch: 6| Step: 3
Training loss: 0.11219673603773117
Validation loss: 1.6334954974471882

Epoch: 6| Step: 4
Training loss: 0.11476495862007141
Validation loss: 1.6116615879920222

Epoch: 6| Step: 5
Training loss: 0.11623351275920868
Validation loss: 1.6011729342963106

Epoch: 6| Step: 6
Training loss: 0.10279145836830139
Validation loss: 1.5970964201035038

Epoch: 6| Step: 7
Training loss: 0.13985732197761536
Validation loss: 1.5894160834691857

Epoch: 6| Step: 8
Training loss: 0.28001025319099426
Validation loss: 1.5777999470310826

Epoch: 6| Step: 9
Training loss: 0.22111569344997406
Validation loss: 1.5973344233728224

Epoch: 6| Step: 10
Training loss: 0.10089054703712463
Validation loss: 1.5914690468900947

Epoch: 6| Step: 11
Training loss: 0.18944445252418518
Validation loss: 1.600555807031611

Epoch: 6| Step: 12
Training loss: 0.24563145637512207
Validation loss: 1.6013759041345248

Epoch: 6| Step: 13
Training loss: 0.35951024293899536
Validation loss: 1.6071309735698085

Epoch: 341| Step: 0
Training loss: 0.12734854221343994
Validation loss: 1.6158196644116474

Epoch: 6| Step: 1
Training loss: 0.25411564111709595
Validation loss: 1.6453309136052285

Epoch: 6| Step: 2
Training loss: 0.08429386466741562
Validation loss: 1.6200312324749526

Epoch: 6| Step: 3
Training loss: 0.09546862542629242
Validation loss: 1.6741403892476072

Epoch: 6| Step: 4
Training loss: 0.10196682810783386
Validation loss: 1.6724399302595405

Epoch: 6| Step: 5
Training loss: 0.10335372388362885
Validation loss: 1.672351973031157

Epoch: 6| Step: 6
Training loss: 0.2064460813999176
Validation loss: 1.6407176627907702

Epoch: 6| Step: 7
Training loss: 0.23836475610733032
Validation loss: 1.6612901867076915

Epoch: 6| Step: 8
Training loss: 0.15040719509124756
Validation loss: 1.6148182269065612

Epoch: 6| Step: 9
Training loss: 0.24185022711753845
Validation loss: 1.6124810621302614

Epoch: 6| Step: 10
Training loss: 0.16203129291534424
Validation loss: 1.6010744405049149

Epoch: 6| Step: 11
Training loss: 0.15607213973999023
Validation loss: 1.5815278932612429

Epoch: 6| Step: 12
Training loss: 0.1415933221578598
Validation loss: 1.5979563241363854

Epoch: 6| Step: 13
Training loss: 0.1771923154592514
Validation loss: 1.5804679701405187

Epoch: 342| Step: 0
Training loss: 0.16121689975261688
Validation loss: 1.599146722465433

Epoch: 6| Step: 1
Training loss: 0.16427527368068695
Validation loss: 1.6018039808478406

Epoch: 6| Step: 2
Training loss: 0.1296360194683075
Validation loss: 1.6068704474356867

Epoch: 6| Step: 3
Training loss: 0.14005407691001892
Validation loss: 1.607331282349043

Epoch: 6| Step: 4
Training loss: 0.1373005360364914
Validation loss: 1.6228813484150877

Epoch: 6| Step: 5
Training loss: 0.1106782928109169
Validation loss: 1.631376616416439

Epoch: 6| Step: 6
Training loss: 0.19982437789440155
Validation loss: 1.6481655438741047

Epoch: 6| Step: 7
Training loss: 0.1621505618095398
Validation loss: 1.6350983458180581

Epoch: 6| Step: 8
Training loss: 0.2500201463699341
Validation loss: 1.65502711906228

Epoch: 6| Step: 9
Training loss: 0.16788345575332642
Validation loss: 1.652173165352114

Epoch: 6| Step: 10
Training loss: 0.2404680848121643
Validation loss: 1.6761477403743292

Epoch: 6| Step: 11
Training loss: 0.15777724981307983
Validation loss: 1.65992655164452

Epoch: 6| Step: 12
Training loss: 0.13775837421417236
Validation loss: 1.6955673617701377

Epoch: 6| Step: 13
Training loss: 0.15699273347854614
Validation loss: 1.6905043971153997

Epoch: 343| Step: 0
Training loss: 0.2711082696914673
Validation loss: 1.6554795080615627

Epoch: 6| Step: 1
Training loss: 0.13095623254776
Validation loss: 1.6309985242864138

Epoch: 6| Step: 2
Training loss: 0.0999518409371376
Validation loss: 1.6452614274076236

Epoch: 6| Step: 3
Training loss: 0.18721766769886017
Validation loss: 1.6210876216170609

Epoch: 6| Step: 4
Training loss: 0.13744893670082092
Validation loss: 1.6095150337424329

Epoch: 6| Step: 5
Training loss: 0.21168683469295502
Validation loss: 1.5915883202706613

Epoch: 6| Step: 6
Training loss: 0.13422106206417084
Validation loss: 1.6122802194728647

Epoch: 6| Step: 7
Training loss: 0.11451936513185501
Validation loss: 1.6062206933575292

Epoch: 6| Step: 8
Training loss: 0.19246691465377808
Validation loss: 1.5988435078692693

Epoch: 6| Step: 9
Training loss: 0.06766028702259064
Validation loss: 1.61451385354483

Epoch: 6| Step: 10
Training loss: 0.2995469570159912
Validation loss: 1.602725649392733

Epoch: 6| Step: 11
Training loss: 0.15181803703308105
Validation loss: 1.567177027784368

Epoch: 6| Step: 12
Training loss: 0.12235547602176666
Validation loss: 1.5799898691074823

Epoch: 6| Step: 13
Training loss: 0.0586518831551075
Validation loss: 1.5739825156427198

Epoch: 344| Step: 0
Training loss: 0.13316994905471802
Validation loss: 1.5467302850497666

Epoch: 6| Step: 1
Training loss: 0.13372282683849335
Validation loss: 1.577191178516675

Epoch: 6| Step: 2
Training loss: 0.2292722761631012
Validation loss: 1.5678814059944564

Epoch: 6| Step: 3
Training loss: 0.16341586410999298
Validation loss: 1.5837293312113772

Epoch: 6| Step: 4
Training loss: 0.17473411560058594
Validation loss: 1.5717796035992202

Epoch: 6| Step: 5
Training loss: 0.20269422233104706
Validation loss: 1.5753372523092455

Epoch: 6| Step: 6
Training loss: 0.1775098443031311
Validation loss: 1.5795120193112282

Epoch: 6| Step: 7
Training loss: 0.0911014974117279
Validation loss: 1.6190350786332162

Epoch: 6| Step: 8
Training loss: 0.23613515496253967
Validation loss: 1.617297493001466

Epoch: 6| Step: 9
Training loss: 0.2732198238372803
Validation loss: 1.6001550478319968

Epoch: 6| Step: 10
Training loss: 0.09470683336257935
Validation loss: 1.6131749121091699

Epoch: 6| Step: 11
Training loss: 0.13898789882659912
Validation loss: 1.6291199794379614

Epoch: 6| Step: 12
Training loss: 0.1157027930021286
Validation loss: 1.6083275182272798

Epoch: 6| Step: 13
Training loss: 0.08684572577476501
Validation loss: 1.6215883454968851

Epoch: 345| Step: 0
Training loss: 0.25084877014160156
Validation loss: 1.5906532310670423

Epoch: 6| Step: 1
Training loss: 0.23582737147808075
Validation loss: 1.60439613685813

Epoch: 6| Step: 2
Training loss: 0.17308303713798523
Validation loss: 1.5970821175523984

Epoch: 6| Step: 3
Training loss: 0.23758473992347717
Validation loss: 1.6050652496276363

Epoch: 6| Step: 4
Training loss: 0.13066288828849792
Validation loss: 1.6162481782256917

Epoch: 6| Step: 5
Training loss: 0.09920701384544373
Validation loss: 1.6089965810057938

Epoch: 6| Step: 6
Training loss: 0.1165831983089447
Validation loss: 1.6230682211537515

Epoch: 6| Step: 7
Training loss: 0.16685912013053894
Validation loss: 1.6222102667695733

Epoch: 6| Step: 8
Training loss: 0.1075337827205658
Validation loss: 1.657328680638344

Epoch: 6| Step: 9
Training loss: 0.14920376241207123
Validation loss: 1.6382374593647577

Epoch: 6| Step: 10
Training loss: 0.12905141711235046
Validation loss: 1.6232584240616008

Epoch: 6| Step: 11
Training loss: 0.16543345153331757
Validation loss: 1.605915904045105

Epoch: 6| Step: 12
Training loss: 0.1513092815876007
Validation loss: 1.618294104453056

Epoch: 6| Step: 13
Training loss: 0.06420091539621353
Validation loss: 1.6006361874200965

Epoch: 346| Step: 0
Training loss: 0.1529170572757721
Validation loss: 1.6161098249496952

Epoch: 6| Step: 1
Training loss: 0.20618002116680145
Validation loss: 1.6069336886047034

Epoch: 6| Step: 2
Training loss: 0.10125657171010971
Validation loss: 1.607757806777954

Epoch: 6| Step: 3
Training loss: 0.1339380145072937
Validation loss: 1.613224196177657

Epoch: 6| Step: 4
Training loss: 0.1062450110912323
Validation loss: 1.6006093922481741

Epoch: 6| Step: 5
Training loss: 0.09438067674636841
Validation loss: 1.6126491010829966

Epoch: 6| Step: 6
Training loss: 0.1687314361333847
Validation loss: 1.5987036471725793

Epoch: 6| Step: 7
Training loss: 0.1684512495994568
Validation loss: 1.6053699985627206

Epoch: 6| Step: 8
Training loss: 0.12852713465690613
Validation loss: 1.5833412716465611

Epoch: 6| Step: 9
Training loss: 0.1835222840309143
Validation loss: 1.5598116792658323

Epoch: 6| Step: 10
Training loss: 0.22518318891525269
Validation loss: 1.5316826630664129

Epoch: 6| Step: 11
Training loss: 0.1756199151277542
Validation loss: 1.5572331925874114

Epoch: 6| Step: 12
Training loss: 0.2159859836101532
Validation loss: 1.5368878520945066

Epoch: 6| Step: 13
Training loss: 0.1834743320941925
Validation loss: 1.552253750062758

Epoch: 347| Step: 0
Training loss: 0.11227118968963623
Validation loss: 1.5501744413888583

Epoch: 6| Step: 1
Training loss: 0.17831139266490936
Validation loss: 1.5794189489015968

Epoch: 6| Step: 2
Training loss: 0.13342785835266113
Validation loss: 1.5719075202941895

Epoch: 6| Step: 3
Training loss: 0.09081348776817322
Validation loss: 1.5911191522434194

Epoch: 6| Step: 4
Training loss: 0.0748833417892456
Validation loss: 1.5954409517267698

Epoch: 6| Step: 5
Training loss: 0.2812449336051941
Validation loss: 1.5870492535252725

Epoch: 6| Step: 6
Training loss: 0.10543356835842133
Validation loss: 1.5875596448939333

Epoch: 6| Step: 7
Training loss: 0.13235878944396973
Validation loss: 1.583130551922706

Epoch: 6| Step: 8
Training loss: 0.1392594873905182
Validation loss: 1.602227908308788

Epoch: 6| Step: 9
Training loss: 0.0725286602973938
Validation loss: 1.5797093875946537

Epoch: 6| Step: 10
Training loss: 0.20111900568008423
Validation loss: 1.5716325929087978

Epoch: 6| Step: 11
Training loss: 0.21733358502388
Validation loss: 1.5979492779700988

Epoch: 6| Step: 12
Training loss: 0.19519782066345215
Validation loss: 1.6074009121105235

Epoch: 6| Step: 13
Training loss: 0.3183803856372833
Validation loss: 1.5823562017051123

Epoch: 348| Step: 0
Training loss: 0.15738144516944885
Validation loss: 1.5791563551913026

Epoch: 6| Step: 1
Training loss: 0.09299571067094803
Validation loss: 1.567897209557154

Epoch: 6| Step: 2
Training loss: 0.14082062244415283
Validation loss: 1.5977774384201213

Epoch: 6| Step: 3
Training loss: 0.13941195607185364
Validation loss: 1.5752590728062454

Epoch: 6| Step: 4
Training loss: 0.2536078989505768
Validation loss: 1.5600010605268582

Epoch: 6| Step: 5
Training loss: 0.11119657009840012
Validation loss: 1.577013797657464

Epoch: 6| Step: 6
Training loss: 0.12387732416391373
Validation loss: 1.5792983219187746

Epoch: 6| Step: 7
Training loss: 0.14362770318984985
Validation loss: 1.5789362922791512

Epoch: 6| Step: 8
Training loss: 0.24381107091903687
Validation loss: 1.5856333804386917

Epoch: 6| Step: 9
Training loss: 0.15747278928756714
Validation loss: 1.5762687870251235

Epoch: 6| Step: 10
Training loss: 0.1273379623889923
Validation loss: 1.5423228535600888

Epoch: 6| Step: 11
Training loss: 0.12972471117973328
Validation loss: 1.57268738490279

Epoch: 6| Step: 12
Training loss: 0.23677955567836761
Validation loss: 1.602243923371838

Epoch: 6| Step: 13
Training loss: 0.11248699575662613
Validation loss: 1.5947704866368284

Epoch: 349| Step: 0
Training loss: 0.20772022008895874
Validation loss: 1.6231104622605026

Epoch: 6| Step: 1
Training loss: 0.28096839785575867
Validation loss: 1.6281861310364099

Epoch: 6| Step: 2
Training loss: 0.12147421389818192
Validation loss: 1.6284402134597942

Epoch: 6| Step: 3
Training loss: 0.12034491449594498
Validation loss: 1.6469588446360763

Epoch: 6| Step: 4
Training loss: 0.16074810922145844
Validation loss: 1.6297011298518027

Epoch: 6| Step: 5
Training loss: 0.23576366901397705
Validation loss: 1.6570502378607308

Epoch: 6| Step: 6
Training loss: 0.05796418339014053
Validation loss: 1.6395714526535363

Epoch: 6| Step: 7
Training loss: 0.17602550983428955
Validation loss: 1.6497451592517156

Epoch: 6| Step: 8
Training loss: 0.21121996641159058
Validation loss: 1.6178079241065568

Epoch: 6| Step: 9
Training loss: 0.20681142807006836
Validation loss: 1.620735518393978

Epoch: 6| Step: 10
Training loss: 0.10580846667289734
Validation loss: 1.6325459877649944

Epoch: 6| Step: 11
Training loss: 0.14546680450439453
Validation loss: 1.6148919969476678

Epoch: 6| Step: 12
Training loss: 0.1528356671333313
Validation loss: 1.616165364301333

Epoch: 6| Step: 13
Training loss: 0.1380496323108673
Validation loss: 1.6173802774439576

Epoch: 350| Step: 0
Training loss: 0.19645044207572937
Validation loss: 1.6196069794316446

Epoch: 6| Step: 1
Training loss: 0.16276228427886963
Validation loss: 1.61185787698274

Epoch: 6| Step: 2
Training loss: 0.1398911029100418
Validation loss: 1.6130236938435545

Epoch: 6| Step: 3
Training loss: 0.22203993797302246
Validation loss: 1.6083811970167263

Epoch: 6| Step: 4
Training loss: 0.20375798642635345
Validation loss: 1.6032799495163785

Epoch: 6| Step: 5
Training loss: 0.161738783121109
Validation loss: 1.5991558708170408

Epoch: 6| Step: 6
Training loss: 0.1235094889998436
Validation loss: 1.583178444575238

Epoch: 6| Step: 7
Training loss: 0.14059413969516754
Validation loss: 1.5828509843477638

Epoch: 6| Step: 8
Training loss: 0.1331043392419815
Validation loss: 1.5540416471419796

Epoch: 6| Step: 9
Training loss: 0.1513364464044571
Validation loss: 1.5542466986563899

Epoch: 6| Step: 10
Training loss: 0.24487341940402985
Validation loss: 1.5557311760481967

Epoch: 6| Step: 11
Training loss: 0.11793127655982971
Validation loss: 1.527381230426091

Epoch: 6| Step: 12
Training loss: 0.18571604788303375
Validation loss: 1.5383246714068997

Epoch: 6| Step: 13
Training loss: 0.08861099183559418
Validation loss: 1.5352887581753474

Epoch: 351| Step: 0
Training loss: 0.19403018057346344
Validation loss: 1.52026572919661

Epoch: 6| Step: 1
Training loss: 0.13057106733322144
Validation loss: 1.550965097642714

Epoch: 6| Step: 2
Training loss: 0.13293346762657166
Validation loss: 1.5316776101307203

Epoch: 6| Step: 3
Training loss: 0.1403442770242691
Validation loss: 1.566378156344096

Epoch: 6| Step: 4
Training loss: 0.0666121318936348
Validation loss: 1.593025497210923

Epoch: 6| Step: 5
Training loss: 0.13841742277145386
Validation loss: 1.5661291063472789

Epoch: 6| Step: 6
Training loss: 0.18699583411216736
Validation loss: 1.5987683675622428

Epoch: 6| Step: 7
Training loss: 0.1387207955121994
Validation loss: 1.55729470586264

Epoch: 6| Step: 8
Training loss: 0.135822594165802
Validation loss: 1.589956166923687

Epoch: 6| Step: 9
Training loss: 0.14435657858848572
Validation loss: 1.561657242877509

Epoch: 6| Step: 10
Training loss: 0.29248517751693726
Validation loss: 1.5597129329558341

Epoch: 6| Step: 11
Training loss: 0.2519543766975403
Validation loss: 1.5787733985531716

Epoch: 6| Step: 12
Training loss: 0.1345389038324356
Validation loss: 1.5898114071097424

Epoch: 6| Step: 13
Training loss: 0.1104179099202156
Validation loss: 1.5958654995887511

Epoch: 352| Step: 0
Training loss: 0.22006440162658691
Validation loss: 1.60282144623418

Epoch: 6| Step: 1
Training loss: 0.1898464411497116
Validation loss: 1.6302382317922448

Epoch: 6| Step: 2
Training loss: 0.1729719042778015
Validation loss: 1.5932400713684738

Epoch: 6| Step: 3
Training loss: 0.215147465467453
Validation loss: 1.5932319036094091

Epoch: 6| Step: 4
Training loss: 0.1675839126110077
Validation loss: 1.6135025306414532

Epoch: 6| Step: 5
Training loss: 0.1285988837480545
Validation loss: 1.6023009297668294

Epoch: 6| Step: 6
Training loss: 0.12426568567752838
Validation loss: 1.556705697890251

Epoch: 6| Step: 7
Training loss: 0.23940801620483398
Validation loss: 1.5588944573556223

Epoch: 6| Step: 8
Training loss: 0.20354752242565155
Validation loss: 1.5475896814818024

Epoch: 6| Step: 9
Training loss: 0.185550719499588
Validation loss: 1.577512434092901

Epoch: 6| Step: 10
Training loss: 0.1384737491607666
Validation loss: 1.5851475102927095

Epoch: 6| Step: 11
Training loss: 0.09896716475486755
Validation loss: 1.5738593288647231

Epoch: 6| Step: 12
Training loss: 0.09711095690727234
Validation loss: 1.5610644560988232

Epoch: 6| Step: 13
Training loss: 0.0916077196598053
Validation loss: 1.565744282096945

Epoch: 353| Step: 0
Training loss: 0.3061444163322449
Validation loss: 1.558476395504449

Epoch: 6| Step: 1
Training loss: 0.16523534059524536
Validation loss: 1.5621042328496133

Epoch: 6| Step: 2
Training loss: 0.09994735568761826
Validation loss: 1.5583810114091443

Epoch: 6| Step: 3
Training loss: 0.09621664881706238
Validation loss: 1.587847634028363

Epoch: 6| Step: 4
Training loss: 0.08920257538557053
Validation loss: 1.5913010233192033

Epoch: 6| Step: 5
Training loss: 0.2007266879081726
Validation loss: 1.5635821832123624

Epoch: 6| Step: 6
Training loss: 0.18657083809375763
Validation loss: 1.5888129190732074

Epoch: 6| Step: 7
Training loss: 0.13487419486045837
Validation loss: 1.632405250303207

Epoch: 6| Step: 8
Training loss: 0.11984264850616455
Validation loss: 1.634569901292042

Epoch: 6| Step: 9
Training loss: 0.14531923830509186
Validation loss: 1.637890177388345

Epoch: 6| Step: 10
Training loss: 0.17382211983203888
Validation loss: 1.6138319648722166

Epoch: 6| Step: 11
Training loss: 0.09066154807806015
Validation loss: 1.5830336898885748

Epoch: 6| Step: 12
Training loss: 0.1618126630783081
Validation loss: 1.571641629742038

Epoch: 6| Step: 13
Training loss: 0.11544401198625565
Validation loss: 1.5828607415640226

Epoch: 354| Step: 0
Training loss: 0.11244294047355652
Validation loss: 1.564328691010834

Epoch: 6| Step: 1
Training loss: 0.20161034166812897
Validation loss: 1.5377660694942679

Epoch: 6| Step: 2
Training loss: 0.16315904259681702
Validation loss: 1.5439928065064132

Epoch: 6| Step: 3
Training loss: 0.17008492350578308
Validation loss: 1.5182545120998094

Epoch: 6| Step: 4
Training loss: 0.32459431886672974
Validation loss: 1.5518921568829527

Epoch: 6| Step: 5
Training loss: 0.1577114462852478
Validation loss: 1.5459777206502936

Epoch: 6| Step: 6
Training loss: 0.15604300796985626
Validation loss: 1.5202376855316984

Epoch: 6| Step: 7
Training loss: 0.11735258251428604
Validation loss: 1.5261507623939103

Epoch: 6| Step: 8
Training loss: 0.11293677985668182
Validation loss: 1.5011880224750889

Epoch: 6| Step: 9
Training loss: 0.11899722367525101
Validation loss: 1.5267379976088

Epoch: 6| Step: 10
Training loss: 0.14180070161819458
Validation loss: 1.5441704591115315

Epoch: 6| Step: 11
Training loss: 0.22956189513206482
Validation loss: 1.5619095089615032

Epoch: 6| Step: 12
Training loss: 0.12569426000118256
Validation loss: 1.5587601841136973

Epoch: 6| Step: 13
Training loss: 0.06602154672145844
Validation loss: 1.6111215827285603

Epoch: 355| Step: 0
Training loss: 0.152741476893425
Validation loss: 1.6303356539818548

Epoch: 6| Step: 1
Training loss: 0.16720443964004517
Validation loss: 1.6299386947385726

Epoch: 6| Step: 2
Training loss: 0.14916285872459412
Validation loss: 1.6307664878906742

Epoch: 6| Step: 3
Training loss: 0.30474746227264404
Validation loss: 1.6183582223871702

Epoch: 6| Step: 4
Training loss: 0.18959033489227295
Validation loss: 1.6217250567610546

Epoch: 6| Step: 5
Training loss: 0.1524965465068817
Validation loss: 1.6022275699082242

Epoch: 6| Step: 6
Training loss: 0.1024141013622284
Validation loss: 1.5685551576716925

Epoch: 6| Step: 7
Training loss: 0.1305585503578186
Validation loss: 1.5682940380547636

Epoch: 6| Step: 8
Training loss: 0.3183562755584717
Validation loss: 1.5703626704472367

Epoch: 6| Step: 9
Training loss: 0.19837933778762817
Validation loss: 1.5656722848133375

Epoch: 6| Step: 10
Training loss: 0.09755788743495941
Validation loss: 1.576895930433786

Epoch: 6| Step: 11
Training loss: 0.17020180821418762
Validation loss: 1.6044146668526433

Epoch: 6| Step: 12
Training loss: 0.0820937305688858
Validation loss: 1.5912004632334555

Epoch: 6| Step: 13
Training loss: 0.17071400582790375
Validation loss: 1.6315886717970653

Epoch: 356| Step: 0
Training loss: 0.12054087221622467
Validation loss: 1.6210597458706106

Epoch: 6| Step: 1
Training loss: 0.19200149178504944
Validation loss: 1.6081138490348734

Epoch: 6| Step: 2
Training loss: 0.15995822846889496
Validation loss: 1.614160653083555

Epoch: 6| Step: 3
Training loss: 0.19972199201583862
Validation loss: 1.5891855070667882

Epoch: 6| Step: 4
Training loss: 0.21462827920913696
Validation loss: 1.5828074639843357

Epoch: 6| Step: 5
Training loss: 0.13232889771461487
Validation loss: 1.5694487992153372

Epoch: 6| Step: 6
Training loss: 0.17012149095535278
Validation loss: 1.560535442444586

Epoch: 6| Step: 7
Training loss: 0.11205867677927017
Validation loss: 1.5625599456089798

Epoch: 6| Step: 8
Training loss: 0.23653584718704224
Validation loss: 1.5547159256473664

Epoch: 6| Step: 9
Training loss: 0.2531171143054962
Validation loss: 1.5647731032422794

Epoch: 6| Step: 10
Training loss: 0.22199569642543793
Validation loss: 1.5592807569811422

Epoch: 6| Step: 11
Training loss: 0.1693865954875946
Validation loss: 1.5808769656765846

Epoch: 6| Step: 12
Training loss: 0.2388451099395752
Validation loss: 1.5966439708586662

Epoch: 6| Step: 13
Training loss: 0.1556731015443802
Validation loss: 1.5916796679137855

Epoch: 357| Step: 0
Training loss: 0.19691431522369385
Validation loss: 1.64752947643239

Epoch: 6| Step: 1
Training loss: 0.14216679334640503
Validation loss: 1.661143777190998

Epoch: 6| Step: 2
Training loss: 0.17680171132087708
Validation loss: 1.6720264124613937

Epoch: 6| Step: 3
Training loss: 0.19539469480514526
Validation loss: 1.63305361552905

Epoch: 6| Step: 4
Training loss: 0.15522509813308716
Validation loss: 1.641247392982565

Epoch: 6| Step: 5
Training loss: 0.15816082060337067
Validation loss: 1.5939873803046443

Epoch: 6| Step: 6
Training loss: 0.13947820663452148
Validation loss: 1.6097516449548865

Epoch: 6| Step: 7
Training loss: 0.11786562949419022
Validation loss: 1.614875010264817

Epoch: 6| Step: 8
Training loss: 0.21324914693832397
Validation loss: 1.618064562479655

Epoch: 6| Step: 9
Training loss: 0.38558435440063477
Validation loss: 1.6031901503121981

Epoch: 6| Step: 10
Training loss: 0.2839086949825287
Validation loss: 1.5931963536047167

Epoch: 6| Step: 11
Training loss: 0.1309572458267212
Validation loss: 1.5964569455833846

Epoch: 6| Step: 12
Training loss: 0.1500573307275772
Validation loss: 1.5690413572454964

Epoch: 6| Step: 13
Training loss: 0.12333541363477707
Validation loss: 1.5464860098336333

Epoch: 358| Step: 0
Training loss: 0.12859871983528137
Validation loss: 1.5582732051931403

Epoch: 6| Step: 1
Training loss: 0.14375817775726318
Validation loss: 1.5896878806493615

Epoch: 6| Step: 2
Training loss: 0.1371329426765442
Validation loss: 1.5903016610812115

Epoch: 6| Step: 3
Training loss: 0.14910709857940674
Validation loss: 1.6020108089652112

Epoch: 6| Step: 4
Training loss: 0.26801201701164246
Validation loss: 1.618216537660168

Epoch: 6| Step: 5
Training loss: 0.1338224709033966
Validation loss: 1.6321679148622739

Epoch: 6| Step: 6
Training loss: 0.09716475009918213
Validation loss: 1.6237395463451263

Epoch: 6| Step: 7
Training loss: 0.2676498293876648
Validation loss: 1.6320798191972958

Epoch: 6| Step: 8
Training loss: 0.1443086862564087
Validation loss: 1.5957460018896288

Epoch: 6| Step: 9
Training loss: 0.1428992748260498
Validation loss: 1.6052869468606927

Epoch: 6| Step: 10
Training loss: 0.194681316614151
Validation loss: 1.573036423293493

Epoch: 6| Step: 11
Training loss: 0.06739236414432526
Validation loss: 1.577829772426236

Epoch: 6| Step: 12
Training loss: 0.1333867609500885
Validation loss: 1.5935850656160744

Epoch: 6| Step: 13
Training loss: 0.130307137966156
Validation loss: 1.536055177770635

Epoch: 359| Step: 0
Training loss: 0.09852425754070282
Validation loss: 1.557755648448903

Epoch: 6| Step: 1
Training loss: 0.13777585327625275
Validation loss: 1.5756883082851287

Epoch: 6| Step: 2
Training loss: 0.1628451645374298
Validation loss: 1.5775795803275159

Epoch: 6| Step: 3
Training loss: 0.17365694046020508
Validation loss: 1.5751435410591863

Epoch: 6| Step: 4
Training loss: 0.1695658266544342
Validation loss: 1.6184299620248939

Epoch: 6| Step: 5
Training loss: 0.11679903417825699
Validation loss: 1.650078679925652

Epoch: 6| Step: 6
Training loss: 0.23284360766410828
Validation loss: 1.6433631117625902

Epoch: 6| Step: 7
Training loss: 0.13771533966064453
Validation loss: 1.6373712580691102

Epoch: 6| Step: 8
Training loss: 0.1313750445842743
Validation loss: 1.6758425453657746

Epoch: 6| Step: 9
Training loss: 0.14507345855236053
Validation loss: 1.6898407936096191

Epoch: 6| Step: 10
Training loss: 0.12954631447792053
Validation loss: 1.6735738695308726

Epoch: 6| Step: 11
Training loss: 0.1873832643032074
Validation loss: 1.6445867656379618

Epoch: 6| Step: 12
Training loss: 0.09851721674203873
Validation loss: 1.6555339982432704

Epoch: 6| Step: 13
Training loss: 0.11053195595741272
Validation loss: 1.6170942834628526

Epoch: 360| Step: 0
Training loss: 0.10467126220464706
Validation loss: 1.6207108395074004

Epoch: 6| Step: 1
Training loss: 0.20989643037319183
Validation loss: 1.5849312338777768

Epoch: 6| Step: 2
Training loss: 0.22992445528507233
Validation loss: 1.610379538228435

Epoch: 6| Step: 3
Training loss: 0.18133556842803955
Validation loss: 1.58645172016595

Epoch: 6| Step: 4
Training loss: 0.22510533034801483
Validation loss: 1.5923415422439575

Epoch: 6| Step: 5
Training loss: 0.14366966485977173
Validation loss: 1.583834240513463

Epoch: 6| Step: 6
Training loss: 0.11443918943405151
Validation loss: 1.6066431973570137

Epoch: 6| Step: 7
Training loss: 0.3015902042388916
Validation loss: 1.6109527054653372

Epoch: 6| Step: 8
Training loss: 0.24038025736808777
Validation loss: 1.6238427072442987

Epoch: 6| Step: 9
Training loss: 0.154914990067482
Validation loss: 1.6316085579574748

Epoch: 6| Step: 10
Training loss: 0.14626775681972504
Validation loss: 1.6644181282289567

Epoch: 6| Step: 11
Training loss: 0.24306942522525787
Validation loss: 1.6765288819548905

Epoch: 6| Step: 12
Training loss: 0.22978253662586212
Validation loss: 1.6649326996136737

Epoch: 6| Step: 13
Training loss: 0.10625012964010239
Validation loss: 1.6199423856632684

Epoch: 361| Step: 0
Training loss: 0.1180867850780487
Validation loss: 1.5957512342801659

Epoch: 6| Step: 1
Training loss: 0.14944171905517578
Validation loss: 1.5692748869619062

Epoch: 6| Step: 2
Training loss: 0.170688658952713
Validation loss: 1.533704864081516

Epoch: 6| Step: 3
Training loss: 0.1379079818725586
Validation loss: 1.5484669029071767

Epoch: 6| Step: 4
Training loss: 0.1576826572418213
Validation loss: 1.5457254609754008

Epoch: 6| Step: 5
Training loss: 0.13289789855480194
Validation loss: 1.5122544041243933

Epoch: 6| Step: 6
Training loss: 0.24197649955749512
Validation loss: 1.5523176552146993

Epoch: 6| Step: 7
Training loss: 0.1821369230747223
Validation loss: 1.5282103259076354

Epoch: 6| Step: 8
Training loss: 0.19596508145332336
Validation loss: 1.5521179347909906

Epoch: 6| Step: 9
Training loss: 0.20813524723052979
Validation loss: 1.5480265604552401

Epoch: 6| Step: 10
Training loss: 0.11151283234357834
Validation loss: 1.5527560698088778

Epoch: 6| Step: 11
Training loss: 0.14919772744178772
Validation loss: 1.545311773976972

Epoch: 6| Step: 12
Training loss: 0.19497518241405487
Validation loss: 1.6233346334067724

Epoch: 6| Step: 13
Training loss: 0.24688488245010376
Validation loss: 1.5906111040422994

Epoch: 362| Step: 0
Training loss: 0.17167629301548004
Validation loss: 1.5857811345848987

Epoch: 6| Step: 1
Training loss: 0.10016200691461563
Validation loss: 1.5772838515620078

Epoch: 6| Step: 2
Training loss: 0.11629679054021835
Validation loss: 1.586202741951071

Epoch: 6| Step: 3
Training loss: 0.11738540232181549
Validation loss: 1.5745067122162029

Epoch: 6| Step: 4
Training loss: 0.3471969962120056
Validation loss: 1.5826124773230603

Epoch: 6| Step: 5
Training loss: 0.14140956103801727
Validation loss: 1.5664290612743748

Epoch: 6| Step: 6
Training loss: 0.08452257513999939
Validation loss: 1.5620939680325088

Epoch: 6| Step: 7
Training loss: 0.14393825829029083
Validation loss: 1.570654538369948

Epoch: 6| Step: 8
Training loss: 0.144260972738266
Validation loss: 1.5868914614441574

Epoch: 6| Step: 9
Training loss: 0.2040254771709442
Validation loss: 1.5697583254947458

Epoch: 6| Step: 10
Training loss: 0.1062612384557724
Validation loss: 1.6048471222641647

Epoch: 6| Step: 11
Training loss: 0.07502561062574387
Validation loss: 1.5610467451874928

Epoch: 6| Step: 12
Training loss: 0.1155841201543808
Validation loss: 1.5827829645526024

Epoch: 6| Step: 13
Training loss: 0.0956449881196022
Validation loss: 1.5408695026110577

Epoch: 363| Step: 0
Training loss: 0.16474254429340363
Validation loss: 1.569575653281263

Epoch: 6| Step: 1
Training loss: 0.16137006878852844
Validation loss: 1.5450672065058062

Epoch: 6| Step: 2
Training loss: 0.13300929963588715
Validation loss: 1.559384161426175

Epoch: 6| Step: 3
Training loss: 0.10414840281009674
Validation loss: 1.5444327964577624

Epoch: 6| Step: 4
Training loss: 0.2700585126876831
Validation loss: 1.5558143559322561

Epoch: 6| Step: 5
Training loss: 0.12180871516466141
Validation loss: 1.582816825118116

Epoch: 6| Step: 6
Training loss: 0.05794108286499977
Validation loss: 1.5584163383771015

Epoch: 6| Step: 7
Training loss: 0.07336802780628204
Validation loss: 1.5665523775162236

Epoch: 6| Step: 8
Training loss: 0.14041489362716675
Validation loss: 1.5747188255991986

Epoch: 6| Step: 9
Training loss: 0.09722159057855606
Validation loss: 1.5876370873502506

Epoch: 6| Step: 10
Training loss: 0.1558433473110199
Validation loss: 1.571710427602132

Epoch: 6| Step: 11
Training loss: 0.11562210321426392
Validation loss: 1.5772962070280505

Epoch: 6| Step: 12
Training loss: 0.07185345888137817
Validation loss: 1.5766537240756455

Epoch: 6| Step: 13
Training loss: 0.17580479383468628
Validation loss: 1.5821609855980001

Epoch: 364| Step: 0
Training loss: 0.08091489970684052
Validation loss: 1.551835888175554

Epoch: 6| Step: 1
Training loss: 0.17975857853889465
Validation loss: 1.5696345093429729

Epoch: 6| Step: 2
Training loss: 0.13150262832641602
Validation loss: 1.56450528483237

Epoch: 6| Step: 3
Training loss: 0.10763697326183319
Validation loss: 1.553865328911812

Epoch: 6| Step: 4
Training loss: 0.246717631816864
Validation loss: 1.5609356716114988

Epoch: 6| Step: 5
Training loss: 0.19729776680469513
Validation loss: 1.5600375385694607

Epoch: 6| Step: 6
Training loss: 0.13348424434661865
Validation loss: 1.5718083356016426

Epoch: 6| Step: 7
Training loss: 0.12164941430091858
Validation loss: 1.5456062055403186

Epoch: 6| Step: 8
Training loss: 0.12224031984806061
Validation loss: 1.558174740883612

Epoch: 6| Step: 9
Training loss: 0.12697148323059082
Validation loss: 1.5420674021526048

Epoch: 6| Step: 10
Training loss: 0.08676503598690033
Validation loss: 1.5619818651547996

Epoch: 6| Step: 11
Training loss: 0.09439994394779205
Validation loss: 1.589185945449337

Epoch: 6| Step: 12
Training loss: 0.1178414523601532
Validation loss: 1.6056418085610995

Epoch: 6| Step: 13
Training loss: 0.08323293924331665
Validation loss: 1.622168811418677

Epoch: 365| Step: 0
Training loss: 0.14358928799629211
Validation loss: 1.6590948668859338

Epoch: 6| Step: 1
Training loss: 0.25562936067581177
Validation loss: 1.671854765184464

Epoch: 6| Step: 2
Training loss: 0.15125134587287903
Validation loss: 1.6309302314635246

Epoch: 6| Step: 3
Training loss: 0.15405213832855225
Validation loss: 1.6354422107819588

Epoch: 6| Step: 4
Training loss: 0.06841516494750977
Validation loss: 1.6516502550853196

Epoch: 6| Step: 5
Training loss: 0.12808334827423096
Validation loss: 1.614064690887287

Epoch: 6| Step: 6
Training loss: 0.07868945598602295
Validation loss: 1.5926104079010666

Epoch: 6| Step: 7
Training loss: 0.10438411682844162
Validation loss: 1.5646087559320594

Epoch: 6| Step: 8
Training loss: 0.08516044169664383
Validation loss: 1.57153396965355

Epoch: 6| Step: 9
Training loss: 0.14721381664276123
Validation loss: 1.5717055477121824

Epoch: 6| Step: 10
Training loss: 0.1584380865097046
Validation loss: 1.5321756255242132

Epoch: 6| Step: 11
Training loss: 0.07572509348392487
Validation loss: 1.5554684323649253

Epoch: 6| Step: 12
Training loss: 0.10444754362106323
Validation loss: 1.5420688403550016

Epoch: 6| Step: 13
Training loss: 0.23031748831272125
Validation loss: 1.5535642978965596

Epoch: 366| Step: 0
Training loss: 0.061097003519535065
Validation loss: 1.5507150157805412

Epoch: 6| Step: 1
Training loss: 0.07335366308689117
Validation loss: 1.550971902826781

Epoch: 6| Step: 2
Training loss: 0.07232843339443207
Validation loss: 1.5858361541583974

Epoch: 6| Step: 3
Training loss: 0.14829491078853607
Validation loss: 1.5796982075578423

Epoch: 6| Step: 4
Training loss: 0.11911545693874359
Validation loss: 1.5630738607016943

Epoch: 6| Step: 5
Training loss: 0.192026287317276
Validation loss: 1.5693048366936304

Epoch: 6| Step: 6
Training loss: 0.12804220616817474
Validation loss: 1.5949154156510548

Epoch: 6| Step: 7
Training loss: 0.0799395889043808
Validation loss: 1.5854068456157562

Epoch: 6| Step: 8
Training loss: 0.23063340783119202
Validation loss: 1.5926336934489589

Epoch: 6| Step: 9
Training loss: 0.1790502965450287
Validation loss: 1.6050096801532212

Epoch: 6| Step: 10
Training loss: 0.171312153339386
Validation loss: 1.583784229011946

Epoch: 6| Step: 11
Training loss: 0.12998652458190918
Validation loss: 1.5747964548808273

Epoch: 6| Step: 12
Training loss: 0.09181724488735199
Validation loss: 1.59170433398216

Epoch: 6| Step: 13
Training loss: 0.20555512607097626
Validation loss: 1.5846186914751608

Epoch: 367| Step: 0
Training loss: 0.11393751204013824
Validation loss: 1.5531661792468

Epoch: 6| Step: 1
Training loss: 0.0945422351360321
Validation loss: 1.54245670892859

Epoch: 6| Step: 2
Training loss: 0.09126797318458557
Validation loss: 1.5224583289956535

Epoch: 6| Step: 3
Training loss: 0.10119644552469254
Validation loss: 1.508189042409261

Epoch: 6| Step: 4
Training loss: 0.20526447892189026
Validation loss: 1.5200782770751624

Epoch: 6| Step: 5
Training loss: 0.13659636676311493
Validation loss: 1.4979295910045665

Epoch: 6| Step: 6
Training loss: 0.12499391287565231
Validation loss: 1.4972993276452506

Epoch: 6| Step: 7
Training loss: 0.18640504777431488
Validation loss: 1.5156292825616815

Epoch: 6| Step: 8
Training loss: 0.07919950783252716
Validation loss: 1.4932912831665368

Epoch: 6| Step: 9
Training loss: 0.16588199138641357
Validation loss: 1.5153189551445745

Epoch: 6| Step: 10
Training loss: 0.07103664427995682
Validation loss: 1.4861270548194967

Epoch: 6| Step: 11
Training loss: 0.1918850541114807
Validation loss: 1.5117511249357654

Epoch: 6| Step: 12
Training loss: 0.14658918976783752
Validation loss: 1.5540924610630158

Epoch: 6| Step: 13
Training loss: 0.12769238650798798
Validation loss: 1.5836032718740485

Epoch: 368| Step: 0
Training loss: 0.10994408279657364
Validation loss: 1.5869260654654553

Epoch: 6| Step: 1
Training loss: 0.1907864511013031
Validation loss: 1.613956089942686

Epoch: 6| Step: 2
Training loss: 0.28129255771636963
Validation loss: 1.6084857243363575

Epoch: 6| Step: 3
Training loss: 0.12641970813274384
Validation loss: 1.584016853763211

Epoch: 6| Step: 4
Training loss: 0.1362496316432953
Validation loss: 1.556288057757962

Epoch: 6| Step: 5
Training loss: 0.13538694381713867
Validation loss: 1.5061177822851366

Epoch: 6| Step: 6
Training loss: 0.0856688916683197
Validation loss: 1.5255664522929857

Epoch: 6| Step: 7
Training loss: 0.0652102679014206
Validation loss: 1.5185057328593345

Epoch: 6| Step: 8
Training loss: 0.0873606950044632
Validation loss: 1.5210777399360493

Epoch: 6| Step: 9
Training loss: 0.08238841593265533
Validation loss: 1.5110931979712618

Epoch: 6| Step: 10
Training loss: 0.22723527252674103
Validation loss: 1.5239500102176462

Epoch: 6| Step: 11
Training loss: 0.07939207553863525
Validation loss: 1.5004569804796608

Epoch: 6| Step: 12
Training loss: 0.15893308818340302
Validation loss: 1.5241022007439726

Epoch: 6| Step: 13
Training loss: 0.07312984019517899
Validation loss: 1.4980536712113248

Epoch: 369| Step: 0
Training loss: 0.1780058741569519
Validation loss: 1.521865197407302

Epoch: 6| Step: 1
Training loss: 0.07446964830160141
Validation loss: 1.5326611816242177

Epoch: 6| Step: 2
Training loss: 0.1649666428565979
Validation loss: 1.540906963809844

Epoch: 6| Step: 3
Training loss: 0.20218202471733093
Validation loss: 1.5174658336947042

Epoch: 6| Step: 4
Training loss: 0.18460725247859955
Validation loss: 1.5295356601797125

Epoch: 6| Step: 5
Training loss: 0.08060923218727112
Validation loss: 1.5557038143116941

Epoch: 6| Step: 6
Training loss: 0.1582028567790985
Validation loss: 1.546655188324631

Epoch: 6| Step: 7
Training loss: 0.08975794911384583
Validation loss: 1.556803463607706

Epoch: 6| Step: 8
Training loss: 0.07634685933589935
Validation loss: 1.5503417368858092

Epoch: 6| Step: 9
Training loss: 0.09357036650180817
Validation loss: 1.5745938824069114

Epoch: 6| Step: 10
Training loss: 0.1054777130484581
Validation loss: 1.5634188895584435

Epoch: 6| Step: 11
Training loss: 0.10261982679367065
Validation loss: 1.5585506603281984

Epoch: 6| Step: 12
Training loss: 0.09202732890844345
Validation loss: 1.5479313814511864

Epoch: 6| Step: 13
Training loss: 0.07296368479728699
Validation loss: 1.5177010759230583

Epoch: 370| Step: 0
Training loss: 0.07338602840900421
Validation loss: 1.5160554730764

Epoch: 6| Step: 1
Training loss: 0.12361452728509903
Validation loss: 1.4906644026438396

Epoch: 6| Step: 2
Training loss: 0.16339227557182312
Validation loss: 1.5201455662327428

Epoch: 6| Step: 3
Training loss: 0.14244304597377777
Validation loss: 1.5212244756760136

Epoch: 6| Step: 4
Training loss: 0.18783193826675415
Validation loss: 1.508242404589089

Epoch: 6| Step: 5
Training loss: 0.09670885652303696
Validation loss: 1.507322112719218

Epoch: 6| Step: 6
Training loss: 0.22042497992515564
Validation loss: 1.5216969174723471

Epoch: 6| Step: 7
Training loss: 0.15033063292503357
Validation loss: 1.5732986491213563

Epoch: 6| Step: 8
Training loss: 0.12578323483467102
Validation loss: 1.580401191147425

Epoch: 6| Step: 9
Training loss: 0.06788124144077301
Validation loss: 1.5704983280551048

Epoch: 6| Step: 10
Training loss: 0.08246516436338425
Validation loss: 1.5869198704278598

Epoch: 6| Step: 11
Training loss: 0.08721346408128738
Validation loss: 1.5986015194205827

Epoch: 6| Step: 12
Training loss: 0.07186898589134216
Validation loss: 1.5845679288269372

Epoch: 6| Step: 13
Training loss: 0.12438000738620758
Validation loss: 1.5617083240580816

Epoch: 371| Step: 0
Training loss: 0.07342346012592316
Validation loss: 1.577065194806745

Epoch: 6| Step: 1
Training loss: 0.110537588596344
Validation loss: 1.6007189468670917

Epoch: 6| Step: 2
Training loss: 0.08624067902565002
Validation loss: 1.5811649727564987

Epoch: 6| Step: 3
Training loss: 0.13413600623607635
Validation loss: 1.5805302948080084

Epoch: 6| Step: 4
Training loss: 0.19975650310516357
Validation loss: 1.5969128095975487

Epoch: 6| Step: 5
Training loss: 0.12603752315044403
Validation loss: 1.5412410331028763

Epoch: 6| Step: 6
Training loss: 0.12246484309434891
Validation loss: 1.5547444089766471

Epoch: 6| Step: 7
Training loss: 0.09147251397371292
Validation loss: 1.5469764785100055

Epoch: 6| Step: 8
Training loss: 0.2173503041267395
Validation loss: 1.5611456158340618

Epoch: 6| Step: 9
Training loss: 0.09640464186668396
Validation loss: 1.5188960439415389

Epoch: 6| Step: 10
Training loss: 0.16677118837833405
Validation loss: 1.5364877690551102

Epoch: 6| Step: 11
Training loss: 0.10734470188617706
Validation loss: 1.5417356298815819

Epoch: 6| Step: 12
Training loss: 0.13370856642723083
Validation loss: 1.5548985260789112

Epoch: 6| Step: 13
Training loss: 0.16633670032024384
Validation loss: 1.5731228064465266

Epoch: 372| Step: 0
Training loss: 0.07464318722486496
Validation loss: 1.5547220412121023

Epoch: 6| Step: 1
Training loss: 0.0922057181596756
Validation loss: 1.5740600914083502

Epoch: 6| Step: 2
Training loss: 0.14913570880889893
Validation loss: 1.56108848638432

Epoch: 6| Step: 3
Training loss: 0.07212367653846741
Validation loss: 1.5844402979778986

Epoch: 6| Step: 4
Training loss: 0.09018103033304214
Validation loss: 1.572939407440924

Epoch: 6| Step: 5
Training loss: 0.15011674165725708
Validation loss: 1.5851258039474487

Epoch: 6| Step: 6
Training loss: 0.16682025790214539
Validation loss: 1.5694490209702523

Epoch: 6| Step: 7
Training loss: 0.13274575769901276
Validation loss: 1.5656647989826817

Epoch: 6| Step: 8
Training loss: 0.08544276654720306
Validation loss: 1.582290409713663

Epoch: 6| Step: 9
Training loss: 0.11731534451246262
Validation loss: 1.5374555382677304

Epoch: 6| Step: 10
Training loss: 0.18735185265541077
Validation loss: 1.527094764094199

Epoch: 6| Step: 11
Training loss: 0.1433635950088501
Validation loss: 1.5481630909827448

Epoch: 6| Step: 12
Training loss: 0.11099113523960114
Validation loss: 1.516294656261321

Epoch: 6| Step: 13
Training loss: 0.06873934715986252
Validation loss: 1.5223694309111564

Epoch: 373| Step: 0
Training loss: 0.11819203943014145
Validation loss: 1.5389966721175818

Epoch: 6| Step: 1
Training loss: 0.1376141607761383
Validation loss: 1.5589736712876188

Epoch: 6| Step: 2
Training loss: 0.1443438082933426
Validation loss: 1.6046460956655524

Epoch: 6| Step: 3
Training loss: 0.1866360604763031
Validation loss: 1.5989503937382852

Epoch: 6| Step: 4
Training loss: 0.16264095902442932
Validation loss: 1.5795780099848264

Epoch: 6| Step: 5
Training loss: 0.1676187664270401
Validation loss: 1.5714580948634813

Epoch: 6| Step: 6
Training loss: 0.1737041026353836
Validation loss: 1.5452590603982248

Epoch: 6| Step: 7
Training loss: 0.1302715539932251
Validation loss: 1.5486491687836186

Epoch: 6| Step: 8
Training loss: 0.1330120861530304
Validation loss: 1.541905867156162

Epoch: 6| Step: 9
Training loss: 0.2170894294977188
Validation loss: 1.5670799580953454

Epoch: 6| Step: 10
Training loss: 0.14427588880062103
Validation loss: 1.5563965228296095

Epoch: 6| Step: 11
Training loss: 0.14106255769729614
Validation loss: 1.545790716525047

Epoch: 6| Step: 12
Training loss: 0.0759444534778595
Validation loss: 1.5481675850447787

Epoch: 6| Step: 13
Training loss: 0.07339747995138168
Validation loss: 1.5549609468829246

Epoch: 374| Step: 0
Training loss: 0.08015435934066772
Validation loss: 1.5588407901025587

Epoch: 6| Step: 1
Training loss: 0.07271795719861984
Validation loss: 1.560224518981031

Epoch: 6| Step: 2
Training loss: 0.08353596180677414
Validation loss: 1.5813440610003728

Epoch: 6| Step: 3
Training loss: 0.1167614534497261
Validation loss: 1.5454467188927434

Epoch: 6| Step: 4
Training loss: 0.13051152229309082
Validation loss: 1.5204561987230856

Epoch: 6| Step: 5
Training loss: 0.1726023256778717
Validation loss: 1.5432370567834506

Epoch: 6| Step: 6
Training loss: 0.1485823094844818
Validation loss: 1.5432071358926835

Epoch: 6| Step: 7
Training loss: 0.10844051837921143
Validation loss: 1.5267750627251082

Epoch: 6| Step: 8
Training loss: 0.1823749840259552
Validation loss: 1.5516162162185998

Epoch: 6| Step: 9
Training loss: 0.18610146641731262
Validation loss: 1.5507001723012617

Epoch: 6| Step: 10
Training loss: 0.07644758373498917
Validation loss: 1.5814212445289857

Epoch: 6| Step: 11
Training loss: 0.2568361759185791
Validation loss: 1.5738802276631838

Epoch: 6| Step: 12
Training loss: 0.23069685697555542
Validation loss: 1.5937311482685868

Epoch: 6| Step: 13
Training loss: 0.1250535398721695
Validation loss: 1.582071215875687

Epoch: 375| Step: 0
Training loss: 0.11125007271766663
Validation loss: 1.563127452327359

Epoch: 6| Step: 1
Training loss: 0.11778350174427032
Validation loss: 1.5914937501312585

Epoch: 6| Step: 2
Training loss: 0.1350555121898651
Validation loss: 1.5793589161288353

Epoch: 6| Step: 3
Training loss: 0.12206612527370453
Validation loss: 1.5665663256440112

Epoch: 6| Step: 4
Training loss: 0.08612124621868134
Validation loss: 1.558475681530532

Epoch: 6| Step: 5
Training loss: 0.12393993139266968
Validation loss: 1.5716020189305788

Epoch: 6| Step: 6
Training loss: 0.13622847199440002
Validation loss: 1.5661985105083835

Epoch: 6| Step: 7
Training loss: 0.11582627147436142
Validation loss: 1.5586497001750494

Epoch: 6| Step: 8
Training loss: 0.11136339604854584
Validation loss: 1.5418951460110244

Epoch: 6| Step: 9
Training loss: 0.10796409845352173
Validation loss: 1.5666114194418794

Epoch: 6| Step: 10
Training loss: 0.14488762617111206
Validation loss: 1.5498278653749855

Epoch: 6| Step: 11
Training loss: 0.17387302219867706
Validation loss: 1.5811114682946155

Epoch: 6| Step: 12
Training loss: 0.1148945614695549
Validation loss: 1.5944857046168337

Epoch: 6| Step: 13
Training loss: 0.08865189552307129
Validation loss: 1.5917456380782589

Epoch: 376| Step: 0
Training loss: 0.1527891755104065
Validation loss: 1.5657519320006013

Epoch: 6| Step: 1
Training loss: 0.10399705171585083
Validation loss: 1.6050608927203762

Epoch: 6| Step: 2
Training loss: 0.10683384537696838
Validation loss: 1.564363334768562

Epoch: 6| Step: 3
Training loss: 0.07721389085054398
Validation loss: 1.551873863384288

Epoch: 6| Step: 4
Training loss: 0.16446544229984283
Validation loss: 1.554498855785657

Epoch: 6| Step: 5
Training loss: 0.09135344624519348
Validation loss: 1.5538629870260916

Epoch: 6| Step: 6
Training loss: 0.13204309344291687
Validation loss: 1.5589005536930536

Epoch: 6| Step: 7
Training loss: 0.13521723449230194
Validation loss: 1.5580357607974802

Epoch: 6| Step: 8
Training loss: 0.15712042152881622
Validation loss: 1.5230055316801994

Epoch: 6| Step: 9
Training loss: 0.15316806733608246
Validation loss: 1.5708373797837125

Epoch: 6| Step: 10
Training loss: 0.09949274361133575
Validation loss: 1.5362508989149524

Epoch: 6| Step: 11
Training loss: 0.1255495846271515
Validation loss: 1.5412601309437906

Epoch: 6| Step: 12
Training loss: 0.15681660175323486
Validation loss: 1.5745633353469193

Epoch: 6| Step: 13
Training loss: 0.16055409610271454
Validation loss: 1.5733688185291905

Epoch: 377| Step: 0
Training loss: 0.08229829370975494
Validation loss: 1.596667875525772

Epoch: 6| Step: 1
Training loss: 0.25341641902923584
Validation loss: 1.6029144986983268

Epoch: 6| Step: 2
Training loss: 0.1278250515460968
Validation loss: 1.5980001867458384

Epoch: 6| Step: 3
Training loss: 0.09008406102657318
Validation loss: 1.6092422687879173

Epoch: 6| Step: 4
Training loss: 0.12472036480903625
Validation loss: 1.587229799198848

Epoch: 6| Step: 5
Training loss: 0.16051965951919556
Validation loss: 1.5987233679781678

Epoch: 6| Step: 6
Training loss: 0.11171369254589081
Validation loss: 1.5873254396582162

Epoch: 6| Step: 7
Training loss: 0.09875164180994034
Validation loss: 1.5655846262490878

Epoch: 6| Step: 8
Training loss: 0.1628255546092987
Validation loss: 1.5866167442772978

Epoch: 6| Step: 9
Training loss: 0.17090262472629547
Validation loss: 1.5723655031573387

Epoch: 6| Step: 10
Training loss: 0.13504964113235474
Validation loss: 1.5755478297510455

Epoch: 6| Step: 11
Training loss: 0.13514219224452972
Validation loss: 1.5850860893085439

Epoch: 6| Step: 12
Training loss: 0.10415825992822647
Validation loss: 1.5777193230967368

Epoch: 6| Step: 13
Training loss: 0.20717331767082214
Validation loss: 1.5713207362800516

Epoch: 378| Step: 0
Training loss: 0.1656722128391266
Validation loss: 1.5491995516643728

Epoch: 6| Step: 1
Training loss: 0.08400258421897888
Validation loss: 1.5364118532467914

Epoch: 6| Step: 2
Training loss: 0.1708906888961792
Validation loss: 1.52465804225655

Epoch: 6| Step: 3
Training loss: 0.15397897362709045
Validation loss: 1.5416799988797916

Epoch: 6| Step: 4
Training loss: 0.11068154871463776
Validation loss: 1.5193641865125267

Epoch: 6| Step: 5
Training loss: 0.16623854637145996
Validation loss: 1.5407761373827535

Epoch: 6| Step: 6
Training loss: 0.13414151966571808
Validation loss: 1.5006015710933234

Epoch: 6| Step: 7
Training loss: 0.10072194039821625
Validation loss: 1.5327979659521451

Epoch: 6| Step: 8
Training loss: 0.08267520368099213
Validation loss: 1.5621787373737623

Epoch: 6| Step: 9
Training loss: 0.10872822999954224
Validation loss: 1.5797779688271143

Epoch: 6| Step: 10
Training loss: 0.21503525972366333
Validation loss: 1.574918903330321

Epoch: 6| Step: 11
Training loss: 0.1509394496679306
Validation loss: 1.5809552015796784

Epoch: 6| Step: 12
Training loss: 0.10343471169471741
Validation loss: 1.5727129533726683

Epoch: 6| Step: 13
Training loss: 0.1715489625930786
Validation loss: 1.5837588412787325

Epoch: 379| Step: 0
Training loss: 0.089177206158638
Validation loss: 1.5603530778679797

Epoch: 6| Step: 1
Training loss: 0.1921703815460205
Validation loss: 1.5521315041408743

Epoch: 6| Step: 2
Training loss: 0.15382380783557892
Validation loss: 1.5467416432596022

Epoch: 6| Step: 3
Training loss: 0.15811461210250854
Validation loss: 1.5599592142207648

Epoch: 6| Step: 4
Training loss: 0.083364337682724
Validation loss: 1.5568030572706653

Epoch: 6| Step: 5
Training loss: 0.2448464035987854
Validation loss: 1.5581483738396757

Epoch: 6| Step: 6
Training loss: 0.15597772598266602
Validation loss: 1.5864967864046815

Epoch: 6| Step: 7
Training loss: 0.12627089023590088
Validation loss: 1.5773997178641699

Epoch: 6| Step: 8
Training loss: 0.11442086100578308
Validation loss: 1.5873560008182321

Epoch: 6| Step: 9
Training loss: 0.13267391920089722
Validation loss: 1.5687548550226356

Epoch: 6| Step: 10
Training loss: 0.11801065504550934
Validation loss: 1.5708611331960207

Epoch: 6| Step: 11
Training loss: 0.14276662468910217
Validation loss: 1.5833758769496795

Epoch: 6| Step: 12
Training loss: 0.1381988525390625
Validation loss: 1.549318012370858

Epoch: 6| Step: 13
Training loss: 0.22914797067642212
Validation loss: 1.5771050325004004

Epoch: 380| Step: 0
Training loss: 0.21614208817481995
Validation loss: 1.570685455876012

Epoch: 6| Step: 1
Training loss: 0.12139005959033966
Validation loss: 1.5796225147862588

Epoch: 6| Step: 2
Training loss: 0.1483231484889984
Validation loss: 1.600691133929837

Epoch: 6| Step: 3
Training loss: 0.1663968861103058
Validation loss: 1.5830153995944607

Epoch: 6| Step: 4
Training loss: 0.172984778881073
Validation loss: 1.5890150172736055

Epoch: 6| Step: 5
Training loss: 0.18555092811584473
Validation loss: 1.5888540578144852

Epoch: 6| Step: 6
Training loss: 0.2139739990234375
Validation loss: 1.566201530477052

Epoch: 6| Step: 7
Training loss: 0.09430904686450958
Validation loss: 1.5811934637767013

Epoch: 6| Step: 8
Training loss: 0.10622081160545349
Validation loss: 1.5398820830929665

Epoch: 6| Step: 9
Training loss: 0.14091825485229492
Validation loss: 1.5478614068800403

Epoch: 6| Step: 10
Training loss: 0.14561742544174194
Validation loss: 1.5593893399802587

Epoch: 6| Step: 11
Training loss: 0.11323260515928268
Validation loss: 1.5602486684758177

Epoch: 6| Step: 12
Training loss: 0.07643714547157288
Validation loss: 1.5368745403905069

Epoch: 6| Step: 13
Training loss: 0.18261374533176422
Validation loss: 1.5531074590580438

Epoch: 381| Step: 0
Training loss: 0.104302778840065
Validation loss: 1.5532121594234178

Epoch: 6| Step: 1
Training loss: 0.15496528148651123
Validation loss: 1.554743283538408

Epoch: 6| Step: 2
Training loss: 0.08423402905464172
Validation loss: 1.5942879440963909

Epoch: 6| Step: 3
Training loss: 0.1186445876955986
Validation loss: 1.566228981940977

Epoch: 6| Step: 4
Training loss: 0.20837172865867615
Validation loss: 1.582672966423855

Epoch: 6| Step: 5
Training loss: 0.23801928758621216
Validation loss: 1.6219336576359247

Epoch: 6| Step: 6
Training loss: 0.18570604920387268
Validation loss: 1.5703074598825106

Epoch: 6| Step: 7
Training loss: 0.06046639382839203
Validation loss: 1.5595713994836296

Epoch: 6| Step: 8
Training loss: 0.12667714059352875
Validation loss: 1.561118184879262

Epoch: 6| Step: 9
Training loss: 0.13133031129837036
Validation loss: 1.5414012664107866

Epoch: 6| Step: 10
Training loss: 0.14739586412906647
Validation loss: 1.5428024761138424

Epoch: 6| Step: 11
Training loss: 0.08162625133991241
Validation loss: 1.5456191173163794

Epoch: 6| Step: 12
Training loss: 0.13589534163475037
Validation loss: 1.52987906945649

Epoch: 6| Step: 13
Training loss: 0.26164066791534424
Validation loss: 1.5912961139473865

Epoch: 382| Step: 0
Training loss: 0.06419296562671661
Validation loss: 1.5493575283276138

Epoch: 6| Step: 1
Training loss: 0.12117202579975128
Validation loss: 1.5587032110460344

Epoch: 6| Step: 2
Training loss: 0.17508676648139954
Validation loss: 1.564552677574978

Epoch: 6| Step: 3
Training loss: 0.13582636415958405
Validation loss: 1.5598623906412432

Epoch: 6| Step: 4
Training loss: 0.2688152492046356
Validation loss: 1.5423798689278223

Epoch: 6| Step: 5
Training loss: 0.14427712559700012
Validation loss: 1.5669866133761663

Epoch: 6| Step: 6
Training loss: 0.16247406601905823
Validation loss: 1.5551837362268919

Epoch: 6| Step: 7
Training loss: 0.08166320621967316
Validation loss: 1.5632681103162869

Epoch: 6| Step: 8
Training loss: 0.06900718808174133
Validation loss: 1.57383563569797

Epoch: 6| Step: 9
Training loss: 0.11064939945936203
Validation loss: 1.5721264295680548

Epoch: 6| Step: 10
Training loss: 0.12823238968849182
Validation loss: 1.5784612714603383

Epoch: 6| Step: 11
Training loss: 0.12534219026565552
Validation loss: 1.566832007900361

Epoch: 6| Step: 12
Training loss: 0.20469525456428528
Validation loss: 1.5485554408001643

Epoch: 6| Step: 13
Training loss: 0.1646224558353424
Validation loss: 1.5707637750974266

Epoch: 383| Step: 0
Training loss: 0.16097810864448547
Validation loss: 1.5390955837824012

Epoch: 6| Step: 1
Training loss: 0.08808514475822449
Validation loss: 1.5293152845034035

Epoch: 6| Step: 2
Training loss: 0.12417764961719513
Validation loss: 1.5089938717503701

Epoch: 6| Step: 3
Training loss: 0.23446299135684967
Validation loss: 1.5032456318537395

Epoch: 6| Step: 4
Training loss: 0.24992194771766663
Validation loss: 1.476895978373866

Epoch: 6| Step: 5
Training loss: 0.14424562454223633
Validation loss: 1.476218601708771

Epoch: 6| Step: 6
Training loss: 0.13392437994480133
Validation loss: 1.4815934210695245

Epoch: 6| Step: 7
Training loss: 0.10709927976131439
Validation loss: 1.506147329525281

Epoch: 6| Step: 8
Training loss: 0.1368120312690735
Validation loss: 1.515218193813037

Epoch: 6| Step: 9
Training loss: 0.20579080283641815
Validation loss: 1.5355764589002054

Epoch: 6| Step: 10
Training loss: 0.21287277340888977
Validation loss: 1.5408065780516593

Epoch: 6| Step: 11
Training loss: 0.12302418798208237
Validation loss: 1.5689147774891188

Epoch: 6| Step: 12
Training loss: 0.1006457731127739
Validation loss: 1.558258133549844

Epoch: 6| Step: 13
Training loss: 0.15692941844463348
Validation loss: 1.5605812066344804

Epoch: 384| Step: 0
Training loss: 0.14916226267814636
Validation loss: 1.5836579466378817

Epoch: 6| Step: 1
Training loss: 0.11310192197561264
Validation loss: 1.565073590124807

Epoch: 6| Step: 2
Training loss: 0.14027604460716248
Validation loss: 1.6112163887229016

Epoch: 6| Step: 3
Training loss: 0.21707862615585327
Validation loss: 1.5762243155510194

Epoch: 6| Step: 4
Training loss: 0.11781475692987442
Validation loss: 1.5716849168141682

Epoch: 6| Step: 5
Training loss: 0.15864363312721252
Validation loss: 1.5700114606529154

Epoch: 6| Step: 6
Training loss: 0.10695742815732956
Validation loss: 1.5724472281753377

Epoch: 6| Step: 7
Training loss: 0.17430709302425385
Validation loss: 1.5786817842914211

Epoch: 6| Step: 8
Training loss: 0.18848806619644165
Validation loss: 1.5725138084862822

Epoch: 6| Step: 9
Training loss: 0.21193096041679382
Validation loss: 1.5432088516091789

Epoch: 6| Step: 10
Training loss: 0.14637231826782227
Validation loss: 1.5753581530304366

Epoch: 6| Step: 11
Training loss: 0.08866797387599945
Validation loss: 1.5635919955468947

Epoch: 6| Step: 12
Training loss: 0.13213013112545013
Validation loss: 1.5645154650493334

Epoch: 6| Step: 13
Training loss: 0.10659139603376389
Validation loss: 1.5699490347216207

Epoch: 385| Step: 0
Training loss: 0.10632681846618652
Validation loss: 1.5777991638388684

Epoch: 6| Step: 1
Training loss: 0.14101213216781616
Validation loss: 1.5746188779031076

Epoch: 6| Step: 2
Training loss: 0.31187644600868225
Validation loss: 1.6005782658053982

Epoch: 6| Step: 3
Training loss: 0.15947511792182922
Validation loss: 1.5911052919203235

Epoch: 6| Step: 4
Training loss: 0.21018600463867188
Validation loss: 1.5847153996908536

Epoch: 6| Step: 5
Training loss: 0.1491893231868744
Validation loss: 1.5678222525504328

Epoch: 6| Step: 6
Training loss: 0.07762327790260315
Validation loss: 1.5633475395940966

Epoch: 6| Step: 7
Training loss: 0.1351165771484375
Validation loss: 1.60026619895812

Epoch: 6| Step: 8
Training loss: 0.10058339685201645
Validation loss: 1.60871841830592

Epoch: 6| Step: 9
Training loss: 0.10970979928970337
Validation loss: 1.612184832173009

Epoch: 6| Step: 10
Training loss: 0.1617511361837387
Validation loss: 1.5888946883140072

Epoch: 6| Step: 11
Training loss: 0.14579416811466217
Validation loss: 1.6050155784494133

Epoch: 6| Step: 12
Training loss: 0.19776980578899384
Validation loss: 1.5897121083351873

Epoch: 6| Step: 13
Training loss: 0.08523356914520264
Validation loss: 1.588526983414927

Epoch: 386| Step: 0
Training loss: 0.10968411713838577
Validation loss: 1.5960581597461496

Epoch: 6| Step: 1
Training loss: 0.240132138133049
Validation loss: 1.5681829311514413

Epoch: 6| Step: 2
Training loss: 0.1552860587835312
Validation loss: 1.591321647808116

Epoch: 6| Step: 3
Training loss: 0.20726388692855835
Validation loss: 1.5821545059962938

Epoch: 6| Step: 4
Training loss: 0.21814964711666107
Validation loss: 1.5577940812674902

Epoch: 6| Step: 5
Training loss: 0.17533698678016663
Validation loss: 1.5445914697903458

Epoch: 6| Step: 6
Training loss: 0.0887930691242218
Validation loss: 1.5782650439969954

Epoch: 6| Step: 7
Training loss: 0.11352492868900299
Validation loss: 1.5461303700682938

Epoch: 6| Step: 8
Training loss: 0.09301804006099701
Validation loss: 1.547948968025946

Epoch: 6| Step: 9
Training loss: 0.1365889608860016
Validation loss: 1.5620727077607186

Epoch: 6| Step: 10
Training loss: 0.1529313176870346
Validation loss: 1.5594434494613318

Epoch: 6| Step: 11
Training loss: 0.13500267267227173
Validation loss: 1.5935356822065128

Epoch: 6| Step: 12
Training loss: 0.18129649758338928
Validation loss: 1.550131574753792

Epoch: 6| Step: 13
Training loss: 0.1321248710155487
Validation loss: 1.5364099702527445

Epoch: 387| Step: 0
Training loss: 0.09171847999095917
Validation loss: 1.5192324423020886

Epoch: 6| Step: 1
Training loss: 0.17221179604530334
Validation loss: 1.5056384840319235

Epoch: 6| Step: 2
Training loss: 0.20727187395095825
Validation loss: 1.4938876603239326

Epoch: 6| Step: 3
Training loss: 0.12356870621442795
Validation loss: 1.5025085454346032

Epoch: 6| Step: 4
Training loss: 0.141416534781456
Validation loss: 1.507469545128525

Epoch: 6| Step: 5
Training loss: 0.12380202859640121
Validation loss: 1.5227567790656962

Epoch: 6| Step: 6
Training loss: 0.19773882627487183
Validation loss: 1.5296739750010993

Epoch: 6| Step: 7
Training loss: 0.16859570145606995
Validation loss: 1.495162695966741

Epoch: 6| Step: 8
Training loss: 0.15565624833106995
Validation loss: 1.532684976054776

Epoch: 6| Step: 9
Training loss: 0.11002540588378906
Validation loss: 1.5221902388398365

Epoch: 6| Step: 10
Training loss: 0.10343635827302933
Validation loss: 1.5405823543507566

Epoch: 6| Step: 11
Training loss: 0.08075284957885742
Validation loss: 1.5087420196943386

Epoch: 6| Step: 12
Training loss: 0.13006819784641266
Validation loss: 1.526837843720631

Epoch: 6| Step: 13
Training loss: 0.1560385525226593
Validation loss: 1.512580563945155

Epoch: 388| Step: 0
Training loss: 0.09295308589935303
Validation loss: 1.5203017964158008

Epoch: 6| Step: 1
Training loss: 0.10788910835981369
Validation loss: 1.5204745543900358

Epoch: 6| Step: 2
Training loss: 0.16331258416175842
Validation loss: 1.542046344408425

Epoch: 6| Step: 3
Training loss: 0.08923929929733276
Validation loss: 1.5347929821219495

Epoch: 6| Step: 4
Training loss: 0.16012707352638245
Validation loss: 1.5454091577119724

Epoch: 6| Step: 5
Training loss: 0.16361618041992188
Validation loss: 1.5411447158423803

Epoch: 6| Step: 6
Training loss: 0.11709100008010864
Validation loss: 1.5550933512308265

Epoch: 6| Step: 7
Training loss: 0.13516104221343994
Validation loss: 1.560648674605995

Epoch: 6| Step: 8
Training loss: 0.0694708526134491
Validation loss: 1.5316066318942654

Epoch: 6| Step: 9
Training loss: 0.137532040476799
Validation loss: 1.5384085947467434

Epoch: 6| Step: 10
Training loss: 0.10938049107789993
Validation loss: 1.5374822334576679

Epoch: 6| Step: 11
Training loss: 0.1809110939502716
Validation loss: 1.5207337987038396

Epoch: 6| Step: 12
Training loss: 0.10014037042856216
Validation loss: 1.5134933494752454

Epoch: 6| Step: 13
Training loss: 0.07653690874576569
Validation loss: 1.5329687223639539

Epoch: 389| Step: 0
Training loss: 0.060037143528461456
Validation loss: 1.5241432459123674

Epoch: 6| Step: 1
Training loss: 0.20476961135864258
Validation loss: 1.519559081523649

Epoch: 6| Step: 2
Training loss: 0.11984751373529434
Validation loss: 1.5343613714300177

Epoch: 6| Step: 3
Training loss: 0.21483467519283295
Validation loss: 1.5401081103150562

Epoch: 6| Step: 4
Training loss: 0.10420326888561249
Validation loss: 1.5761697817874212

Epoch: 6| Step: 5
Training loss: 0.08365969359874725
Validation loss: 1.5838778788043606

Epoch: 6| Step: 6
Training loss: 0.09751225262880325
Validation loss: 1.5788778489635837

Epoch: 6| Step: 7
Training loss: 0.23098602890968323
Validation loss: 1.6084665252316384

Epoch: 6| Step: 8
Training loss: 0.12866714596748352
Validation loss: 1.6081310625999206

Epoch: 6| Step: 9
Training loss: 0.16666731238365173
Validation loss: 1.6080399303026096

Epoch: 6| Step: 10
Training loss: 0.13100597262382507
Validation loss: 1.6034636574406778

Epoch: 6| Step: 11
Training loss: 0.1473715901374817
Validation loss: 1.6133107254582066

Epoch: 6| Step: 12
Training loss: 0.1098334938287735
Validation loss: 1.5745795208920714

Epoch: 6| Step: 13
Training loss: 0.10164693742990494
Validation loss: 1.554998400390789

Epoch: 390| Step: 0
Training loss: 0.11893647909164429
Validation loss: 1.5226955208727109

Epoch: 6| Step: 1
Training loss: 0.08790731430053711
Validation loss: 1.5156762971672961

Epoch: 6| Step: 2
Training loss: 0.10202235728502274
Validation loss: 1.5213629045794088

Epoch: 6| Step: 3
Training loss: 0.2631414532661438
Validation loss: 1.5301825897667998

Epoch: 6| Step: 4
Training loss: 0.21776443719863892
Validation loss: 1.5253808498382568

Epoch: 6| Step: 5
Training loss: 0.13498367369174957
Validation loss: 1.5204674569509362

Epoch: 6| Step: 6
Training loss: 0.10976813733577728
Validation loss: 1.524480269801232

Epoch: 6| Step: 7
Training loss: 0.08610312640666962
Validation loss: 1.4945416950410413

Epoch: 6| Step: 8
Training loss: 0.10354401916265488
Validation loss: 1.540849934342087

Epoch: 6| Step: 9
Training loss: 0.18895408511161804
Validation loss: 1.5244774638965566

Epoch: 6| Step: 10
Training loss: 0.14773857593536377
Validation loss: 1.505358434492542

Epoch: 6| Step: 11
Training loss: 0.1539866179227829
Validation loss: 1.5285439016998454

Epoch: 6| Step: 12
Training loss: 0.08636300265789032
Validation loss: 1.531010748237692

Epoch: 6| Step: 13
Training loss: 0.11658252775669098
Validation loss: 1.5591346243376374

Epoch: 391| Step: 0
Training loss: 0.07462316751480103
Validation loss: 1.574024897749706

Epoch: 6| Step: 1
Training loss: 0.11550295352935791
Validation loss: 1.5511484594755276

Epoch: 6| Step: 2
Training loss: 0.10665425658226013
Validation loss: 1.5642785487636444

Epoch: 6| Step: 3
Training loss: 0.19110839068889618
Validation loss: 1.579022378049871

Epoch: 6| Step: 4
Training loss: 0.16407400369644165
Validation loss: 1.589487951288941

Epoch: 6| Step: 5
Training loss: 0.1482245922088623
Validation loss: 1.5751498911970405

Epoch: 6| Step: 6
Training loss: 0.16662421822547913
Validation loss: 1.5888365519944059

Epoch: 6| Step: 7
Training loss: 0.12375283241271973
Validation loss: 1.5685366122953353

Epoch: 6| Step: 8
Training loss: 0.12292250990867615
Validation loss: 1.581937168234138

Epoch: 6| Step: 9
Training loss: 0.10634247958660126
Validation loss: 1.5869248041542627

Epoch: 6| Step: 10
Training loss: 0.0886535570025444
Validation loss: 1.565642435063598

Epoch: 6| Step: 11
Training loss: 0.1187681332230568
Validation loss: 1.5933948075899513

Epoch: 6| Step: 12
Training loss: 0.13685950636863708
Validation loss: 1.594881260266868

Epoch: 6| Step: 13
Training loss: 0.09227252006530762
Validation loss: 1.5967823754074753

Epoch: 392| Step: 0
Training loss: 0.11082261800765991
Validation loss: 1.6026175778399232

Epoch: 6| Step: 1
Training loss: 0.142660990357399
Validation loss: 1.567879653746082

Epoch: 6| Step: 2
Training loss: 0.1298207938671112
Validation loss: 1.566121252634192

Epoch: 6| Step: 3
Training loss: 0.07097576558589935
Validation loss: 1.5765689290979856

Epoch: 6| Step: 4
Training loss: 0.06645102798938751
Validation loss: 1.5443656047185261

Epoch: 6| Step: 5
Training loss: 0.08863945305347443
Validation loss: 1.5480164007474018

Epoch: 6| Step: 6
Training loss: 0.07798056304454803
Validation loss: 1.5274356347258373

Epoch: 6| Step: 7
Training loss: 0.06418082118034363
Validation loss: 1.5312018830289122

Epoch: 6| Step: 8
Training loss: 0.1633036732673645
Validation loss: 1.521167524399296

Epoch: 6| Step: 9
Training loss: 0.1552795022726059
Validation loss: 1.517337647176558

Epoch: 6| Step: 10
Training loss: 0.1997348517179489
Validation loss: 1.5117840587451894

Epoch: 6| Step: 11
Training loss: 0.08202861994504929
Validation loss: 1.5397735180393342

Epoch: 6| Step: 12
Training loss: 0.20780017971992493
Validation loss: 1.5558294067459721

Epoch: 6| Step: 13
Training loss: 0.042432770133018494
Validation loss: 1.5552960262503674

Epoch: 393| Step: 0
Training loss: 0.1452571451663971
Validation loss: 1.5433553957170056

Epoch: 6| Step: 1
Training loss: 0.09049797058105469
Validation loss: 1.56563102686277

Epoch: 6| Step: 2
Training loss: 0.08311529457569122
Validation loss: 1.5546179663750432

Epoch: 6| Step: 3
Training loss: 0.0689622163772583
Validation loss: 1.5466539962317354

Epoch: 6| Step: 4
Training loss: 0.0755377858877182
Validation loss: 1.5451105627962338

Epoch: 6| Step: 5
Training loss: 0.17849227786064148
Validation loss: 1.5580066903944938

Epoch: 6| Step: 6
Training loss: 0.071099191904068
Validation loss: 1.5481486346132012

Epoch: 6| Step: 7
Training loss: 0.14374218881130219
Validation loss: 1.5421376574424006

Epoch: 6| Step: 8
Training loss: 0.08643049746751785
Validation loss: 1.5373489292719031

Epoch: 6| Step: 9
Training loss: 0.15065892040729523
Validation loss: 1.509265608684991

Epoch: 6| Step: 10
Training loss: 0.11875241994857788
Validation loss: 1.500755080612757

Epoch: 6| Step: 11
Training loss: 0.13583290576934814
Validation loss: 1.5029436606232838

Epoch: 6| Step: 12
Training loss: 0.1843986213207245
Validation loss: 1.5039889299741356

Epoch: 6| Step: 13
Training loss: 0.06308335810899734
Validation loss: 1.5175182204092703

Epoch: 394| Step: 0
Training loss: 0.07131673395633698
Validation loss: 1.5142877781262962

Epoch: 6| Step: 1
Training loss: 0.13931632041931152
Validation loss: 1.5403395634825512

Epoch: 6| Step: 2
Training loss: 0.09655448794364929
Validation loss: 1.535149540952457

Epoch: 6| Step: 3
Training loss: 0.08215632289648056
Validation loss: 1.5543037793969596

Epoch: 6| Step: 4
Training loss: 0.1522952914237976
Validation loss: 1.5473306794320383

Epoch: 6| Step: 5
Training loss: 0.1289920210838318
Validation loss: 1.5577278790935394

Epoch: 6| Step: 6
Training loss: 0.1407257318496704
Validation loss: 1.5415254908223306

Epoch: 6| Step: 7
Training loss: 0.17231133580207825
Validation loss: 1.5711278594950193

Epoch: 6| Step: 8
Training loss: 0.126484215259552
Validation loss: 1.5549200901421167

Epoch: 6| Step: 9
Training loss: 0.18178510665893555
Validation loss: 1.5525445874019335

Epoch: 6| Step: 10
Training loss: 0.08582553267478943
Validation loss: 1.5159252407730266

Epoch: 6| Step: 11
Training loss: 0.12622158229351044
Validation loss: 1.5304865952460998

Epoch: 6| Step: 12
Training loss: 0.1490873396396637
Validation loss: 1.5187406155370897

Epoch: 6| Step: 13
Training loss: 0.09199336171150208
Validation loss: 1.5110480439278386

Epoch: 395| Step: 0
Training loss: 0.09536842256784439
Validation loss: 1.5137578697614773

Epoch: 6| Step: 1
Training loss: 0.13016220927238464
Validation loss: 1.5059149572926183

Epoch: 6| Step: 2
Training loss: 0.09370482712984085
Validation loss: 1.5183722178141277

Epoch: 6| Step: 3
Training loss: 0.10676056146621704
Validation loss: 1.5049911955351472

Epoch: 6| Step: 4
Training loss: 0.18484801054000854
Validation loss: 1.5095315159008067

Epoch: 6| Step: 5
Training loss: 0.07800590246915817
Validation loss: 1.4946277769663001

Epoch: 6| Step: 6
Training loss: 0.13057659566402435
Validation loss: 1.533997622869348

Epoch: 6| Step: 7
Training loss: 0.11622125655412674
Validation loss: 1.541818646974461

Epoch: 6| Step: 8
Training loss: 0.11679240316152573
Validation loss: 1.5500300597119074

Epoch: 6| Step: 9
Training loss: 0.14360423386096954
Validation loss: 1.5712447550988966

Epoch: 6| Step: 10
Training loss: 0.1972823143005371
Validation loss: 1.5566431162177876

Epoch: 6| Step: 11
Training loss: 0.14503686130046844
Validation loss: 1.561837923142218

Epoch: 6| Step: 12
Training loss: 0.10030676424503326
Validation loss: 1.5619257380885463

Epoch: 6| Step: 13
Training loss: 0.0708186998963356
Validation loss: 1.572387505603093

Epoch: 396| Step: 0
Training loss: 0.1200060099363327
Validation loss: 1.5447851560449088

Epoch: 6| Step: 1
Training loss: 0.19081464409828186
Validation loss: 1.565519291867492

Epoch: 6| Step: 2
Training loss: 0.09626434743404388
Validation loss: 1.5638167550486903

Epoch: 6| Step: 3
Training loss: 0.1451026350259781
Validation loss: 1.5634209391891316

Epoch: 6| Step: 4
Training loss: 0.16789557039737701
Validation loss: 1.5337178630213584

Epoch: 6| Step: 5
Training loss: 0.11172838509082794
Validation loss: 1.540435537215202

Epoch: 6| Step: 6
Training loss: 0.0729232057929039
Validation loss: 1.5165290845337736

Epoch: 6| Step: 7
Training loss: 0.15439772605895996
Validation loss: 1.5062518568449124

Epoch: 6| Step: 8
Training loss: 0.1236056238412857
Validation loss: 1.483588868571866

Epoch: 6| Step: 9
Training loss: 0.17204272747039795
Validation loss: 1.4816111774854763

Epoch: 6| Step: 10
Training loss: 0.1435680389404297
Validation loss: 1.5162893277342602

Epoch: 6| Step: 11
Training loss: 0.11267751455307007
Validation loss: 1.5276099699799732

Epoch: 6| Step: 12
Training loss: 0.19747111201286316
Validation loss: 1.5178877935614636

Epoch: 6| Step: 13
Training loss: 0.20018212497234344
Validation loss: 1.5222146844351163

Epoch: 397| Step: 0
Training loss: 0.08785025775432587
Validation loss: 1.5225586198991345

Epoch: 6| Step: 1
Training loss: 0.22651202976703644
Validation loss: 1.5389200154171194

Epoch: 6| Step: 2
Training loss: 0.1286458969116211
Validation loss: 1.556255804595127

Epoch: 6| Step: 3
Training loss: 0.14063899219036102
Validation loss: 1.5199326789507301

Epoch: 6| Step: 4
Training loss: 0.08768440783023834
Validation loss: 1.5350530878190072

Epoch: 6| Step: 5
Training loss: 0.11489778757095337
Validation loss: 1.5548697684400825

Epoch: 6| Step: 6
Training loss: 0.10239186137914658
Validation loss: 1.5418864616783716

Epoch: 6| Step: 7
Training loss: 0.16976958513259888
Validation loss: 1.550260393850265

Epoch: 6| Step: 8
Training loss: 0.20432084798812866
Validation loss: 1.55125984966114

Epoch: 6| Step: 9
Training loss: 0.10784289240837097
Validation loss: 1.5744931572867977

Epoch: 6| Step: 10
Training loss: 0.08506935834884644
Validation loss: 1.5528709850003641

Epoch: 6| Step: 11
Training loss: 0.09746789932250977
Validation loss: 1.56425981367788

Epoch: 6| Step: 12
Training loss: 0.15369194746017456
Validation loss: 1.5368165303302068

Epoch: 6| Step: 13
Training loss: 0.13786981999874115
Validation loss: 1.5304277327752882

Epoch: 398| Step: 0
Training loss: 0.16916096210479736
Validation loss: 1.531088093275665

Epoch: 6| Step: 1
Training loss: 0.11110971868038177
Validation loss: 1.5501662556843092

Epoch: 6| Step: 2
Training loss: 0.1129985898733139
Validation loss: 1.5309461803846462

Epoch: 6| Step: 3
Training loss: 0.08433305472135544
Validation loss: 1.505893054828849

Epoch: 6| Step: 4
Training loss: 0.09749642759561539
Validation loss: 1.5071235158110177

Epoch: 6| Step: 5
Training loss: 0.12186813354492188
Validation loss: 1.5060160634338216

Epoch: 6| Step: 6
Training loss: 0.11452924460172653
Validation loss: 1.4790114914217303

Epoch: 6| Step: 7
Training loss: 0.14929358661174774
Validation loss: 1.4926257607757405

Epoch: 6| Step: 8
Training loss: 0.09051521867513657
Validation loss: 1.4804090094822708

Epoch: 6| Step: 9
Training loss: 0.14722448587417603
Validation loss: 1.4891679030592724

Epoch: 6| Step: 10
Training loss: 0.14934006333351135
Validation loss: 1.485252397034758

Epoch: 6| Step: 11
Training loss: 0.19514498114585876
Validation loss: 1.491833612483035

Epoch: 6| Step: 12
Training loss: 0.17299781739711761
Validation loss: 1.49910637768366

Epoch: 6| Step: 13
Training loss: 0.20933900773525238
Validation loss: 1.5158316948080575

Epoch: 399| Step: 0
Training loss: 0.15175634622573853
Validation loss: 1.4962816853677072

Epoch: 6| Step: 1
Training loss: 0.08636688441038132
Validation loss: 1.5368680184887302

Epoch: 6| Step: 2
Training loss: 0.10274823755025864
Validation loss: 1.53176377665612

Epoch: 6| Step: 3
Training loss: 0.08492434024810791
Validation loss: 1.5283525105445617

Epoch: 6| Step: 4
Training loss: 0.24871814250946045
Validation loss: 1.538301339713476

Epoch: 6| Step: 5
Training loss: 0.09230144321918488
Validation loss: 1.5223205153660109

Epoch: 6| Step: 6
Training loss: 0.08557145297527313
Validation loss: 1.513845492434758

Epoch: 6| Step: 7
Training loss: 0.07468576729297638
Validation loss: 1.5233431144427227

Epoch: 6| Step: 8
Training loss: 0.2537790536880493
Validation loss: 1.5009591643528273

Epoch: 6| Step: 9
Training loss: 0.09317882359027863
Validation loss: 1.5265371735377977

Epoch: 6| Step: 10
Training loss: 0.12457118928432465
Validation loss: 1.5106500887101697

Epoch: 6| Step: 11
Training loss: 0.19749405980110168
Validation loss: 1.5064098783718642

Epoch: 6| Step: 12
Training loss: 0.15849870443344116
Validation loss: 1.5252511065493348

Epoch: 6| Step: 13
Training loss: 0.10453706234693527
Validation loss: 1.5616179448302074

Epoch: 400| Step: 0
Training loss: 0.08949397504329681
Validation loss: 1.5388185413934852

Epoch: 6| Step: 1
Training loss: 0.08915767818689346
Validation loss: 1.5570653074531144

Epoch: 6| Step: 2
Training loss: 0.07256808131933212
Validation loss: 1.5515175839906097

Epoch: 6| Step: 3
Training loss: 0.09764473140239716
Validation loss: 1.5423368177106302

Epoch: 6| Step: 4
Training loss: 0.14636670053005219
Validation loss: 1.5606196029211885

Epoch: 6| Step: 5
Training loss: 0.09478169679641724
Validation loss: 1.565025471871899

Epoch: 6| Step: 6
Training loss: 0.06774825602769852
Validation loss: 1.574941324931319

Epoch: 6| Step: 7
Training loss: 0.10924001038074493
Validation loss: 1.5522115512560772

Epoch: 6| Step: 8
Training loss: 0.07050979882478714
Validation loss: 1.564916653017844

Epoch: 6| Step: 9
Training loss: 0.0944523960351944
Validation loss: 1.5549291051844114

Epoch: 6| Step: 10
Training loss: 0.11802395433187485
Validation loss: 1.5378639851847002

Epoch: 6| Step: 11
Training loss: 0.09498237073421478
Validation loss: 1.5547232832959903

Epoch: 6| Step: 12
Training loss: 0.2538355886936188
Validation loss: 1.5426182484114042

Epoch: 6| Step: 13
Training loss: 0.062124356627464294
Validation loss: 1.5649994496376283

Epoch: 401| Step: 0
Training loss: 0.20446254312992096
Validation loss: 1.549725350513253

Epoch: 6| Step: 1
Training loss: 0.06191306561231613
Validation loss: 1.5198888009594334

Epoch: 6| Step: 2
Training loss: 0.10831423103809357
Validation loss: 1.5494750981689782

Epoch: 6| Step: 3
Training loss: 0.11397548019886017
Validation loss: 1.5449713673642886

Epoch: 6| Step: 4
Training loss: 0.10721305012702942
Validation loss: 1.5406779217463669

Epoch: 6| Step: 5
Training loss: 0.13759486377239227
Validation loss: 1.5237016306128552

Epoch: 6| Step: 6
Training loss: 0.15931366384029388
Validation loss: 1.5323173602422078

Epoch: 6| Step: 7
Training loss: 0.08732779324054718
Validation loss: 1.5535972682378625

Epoch: 6| Step: 8
Training loss: 0.17947092652320862
Validation loss: 1.5224487473887782

Epoch: 6| Step: 9
Training loss: 0.09312888979911804
Validation loss: 1.5309731691114363

Epoch: 6| Step: 10
Training loss: 0.08968701213598251
Validation loss: 1.5415891614011539

Epoch: 6| Step: 11
Training loss: 0.12384139001369476
Validation loss: 1.5202380700777935

Epoch: 6| Step: 12
Training loss: 0.14768803119659424
Validation loss: 1.5102666783076462

Epoch: 6| Step: 13
Training loss: 0.15622170269489288
Validation loss: 1.5176010535609337

Epoch: 402| Step: 0
Training loss: 0.09709308296442032
Validation loss: 1.5210464577521048

Epoch: 6| Step: 1
Training loss: 0.21516427397727966
Validation loss: 1.5174127240334787

Epoch: 6| Step: 2
Training loss: 0.0983147919178009
Validation loss: 1.5131533581723449

Epoch: 6| Step: 3
Training loss: 0.11528156697750092
Validation loss: 1.5619178766845374

Epoch: 6| Step: 4
Training loss: 0.07725144922733307
Validation loss: 1.5408094185654835

Epoch: 6| Step: 5
Training loss: 0.16925491392612457
Validation loss: 1.5452418096603886

Epoch: 6| Step: 6
Training loss: 0.10845910012722015
Validation loss: 1.5472225642973376

Epoch: 6| Step: 7
Training loss: 0.07283706963062286
Validation loss: 1.534817402080823

Epoch: 6| Step: 8
Training loss: 0.10367494821548462
Validation loss: 1.5285362274416032

Epoch: 6| Step: 9
Training loss: 0.11283696442842484
Validation loss: 1.5105197711657452

Epoch: 6| Step: 10
Training loss: 0.16740986704826355
Validation loss: 1.5361542426129824

Epoch: 6| Step: 11
Training loss: 0.1758306324481964
Validation loss: 1.50825814085622

Epoch: 6| Step: 12
Training loss: 0.09305384010076523
Validation loss: 1.5147396774702175

Epoch: 6| Step: 13
Training loss: 0.17920605838298798
Validation loss: 1.5061027619146532

Epoch: 403| Step: 0
Training loss: 0.15541872382164001
Validation loss: 1.5277916359645065

Epoch: 6| Step: 1
Training loss: 0.15736982226371765
Validation loss: 1.5120429736311718

Epoch: 6| Step: 2
Training loss: 0.07557964324951172
Validation loss: 1.518902515852323

Epoch: 6| Step: 3
Training loss: 0.11831871420145035
Validation loss: 1.4835050593140304

Epoch: 6| Step: 4
Training loss: 0.12222543358802795
Validation loss: 1.5334268231545725

Epoch: 6| Step: 5
Training loss: 0.08943335711956024
Validation loss: 1.540036935960093

Epoch: 6| Step: 6
Training loss: 0.12228665500879288
Validation loss: 1.5230818692074026

Epoch: 6| Step: 7
Training loss: 0.08809369802474976
Validation loss: 1.4971784699347712

Epoch: 6| Step: 8
Training loss: 0.13365837931632996
Validation loss: 1.5220115620602843

Epoch: 6| Step: 9
Training loss: 0.06285024434328079
Validation loss: 1.5270900867318595

Epoch: 6| Step: 10
Training loss: 0.07470601052045822
Validation loss: 1.5499765924228135

Epoch: 6| Step: 11
Training loss: 0.17817464470863342
Validation loss: 1.5651178129257695

Epoch: 6| Step: 12
Training loss: 0.139009490609169
Validation loss: 1.5475055517688874

Epoch: 6| Step: 13
Training loss: 0.11022111028432846
Validation loss: 1.5575856611292849

Epoch: 404| Step: 0
Training loss: 0.1729818880558014
Validation loss: 1.5619815126542123

Epoch: 6| Step: 1
Training loss: 0.08582539111375809
Validation loss: 1.5396607639969035

Epoch: 6| Step: 2
Training loss: 0.17524226009845734
Validation loss: 1.533139483903044

Epoch: 6| Step: 3
Training loss: 0.16664069890975952
Validation loss: 1.4809191060322586

Epoch: 6| Step: 4
Training loss: 0.12827371060848236
Validation loss: 1.4919663488223989

Epoch: 6| Step: 5
Training loss: 0.09861692786216736
Validation loss: 1.4780725074070755

Epoch: 6| Step: 6
Training loss: 0.09374608099460602
Validation loss: 1.4768466359825545

Epoch: 6| Step: 7
Training loss: 0.1176907941699028
Validation loss: 1.450165356359174

Epoch: 6| Step: 8
Training loss: 0.125893235206604
Validation loss: 1.487461748943534

Epoch: 6| Step: 9
Training loss: 0.12987153232097626
Validation loss: 1.4600824745752479

Epoch: 6| Step: 10
Training loss: 0.07406820356845856
Validation loss: 1.465794394093175

Epoch: 6| Step: 11
Training loss: 0.1358504593372345
Validation loss: 1.4602586530870008

Epoch: 6| Step: 12
Training loss: 0.17314495146274567
Validation loss: 1.4886783515253375

Epoch: 6| Step: 13
Training loss: 0.1402454972267151
Validation loss: 1.5086563556425032

Epoch: 405| Step: 0
Training loss: 0.09499205648899078
Validation loss: 1.5405443381237727

Epoch: 6| Step: 1
Training loss: 0.09134392440319061
Validation loss: 1.542156014391171

Epoch: 6| Step: 2
Training loss: 0.11595705151557922
Validation loss: 1.5520305043907576

Epoch: 6| Step: 3
Training loss: 0.11634472757577896
Validation loss: 1.5531052697089411

Epoch: 6| Step: 4
Training loss: 0.06014290079474449
Validation loss: 1.549143716853152

Epoch: 6| Step: 5
Training loss: 0.13968735933303833
Validation loss: 1.5510111880558792

Epoch: 6| Step: 6
Training loss: 0.21342036128044128
Validation loss: 1.545060779458733

Epoch: 6| Step: 7
Training loss: 0.08389204740524292
Validation loss: 1.5348765401430027

Epoch: 6| Step: 8
Training loss: 0.07016166299581528
Validation loss: 1.5035313803662536

Epoch: 6| Step: 9
Training loss: 0.1237473338842392
Validation loss: 1.523899624424596

Epoch: 6| Step: 10
Training loss: 0.08819206058979034
Validation loss: 1.496977311308666

Epoch: 6| Step: 11
Training loss: 0.11089056730270386
Validation loss: 1.493707787606024

Epoch: 6| Step: 12
Training loss: 0.10550004243850708
Validation loss: 1.4788872964920536

Epoch: 6| Step: 13
Training loss: 0.1056588888168335
Validation loss: 1.4793281567993986

Epoch: 406| Step: 0
Training loss: 0.09596842527389526
Validation loss: 1.4928785677879088

Epoch: 6| Step: 1
Training loss: 0.14114496111869812
Validation loss: 1.512162644376037

Epoch: 6| Step: 2
Training loss: 0.10473403334617615
Validation loss: 1.5233004798171341

Epoch: 6| Step: 3
Training loss: 0.05947236716747284
Validation loss: 1.5423352538898427

Epoch: 6| Step: 4
Training loss: 0.12130707502365112
Validation loss: 1.5267116920922392

Epoch: 6| Step: 5
Training loss: 0.09617672860622406
Validation loss: 1.5639930604606547

Epoch: 6| Step: 6
Training loss: 0.09708631783723831
Validation loss: 1.559168892522012

Epoch: 6| Step: 7
Training loss: 0.139992356300354
Validation loss: 1.5700566320009128

Epoch: 6| Step: 8
Training loss: 0.14828726649284363
Validation loss: 1.5674796899159749

Epoch: 6| Step: 9
Training loss: 0.1153608039021492
Validation loss: 1.5758618552197692

Epoch: 6| Step: 10
Training loss: 0.16510877013206482
Validation loss: 1.5583311062987133

Epoch: 6| Step: 11
Training loss: 0.08469928056001663
Validation loss: 1.5507916840173865

Epoch: 6| Step: 12
Training loss: 0.11219950020313263
Validation loss: 1.5619565825308523

Epoch: 6| Step: 13
Training loss: 0.1125144436955452
Validation loss: 1.5471604549756615

Epoch: 407| Step: 0
Training loss: 0.14774781465530396
Validation loss: 1.5286086131167669

Epoch: 6| Step: 1
Training loss: 0.0891299620270729
Validation loss: 1.5139407637298747

Epoch: 6| Step: 2
Training loss: 0.06170346587896347
Validation loss: 1.5281996227079822

Epoch: 6| Step: 3
Training loss: 0.19365724921226501
Validation loss: 1.5183769079946703

Epoch: 6| Step: 4
Training loss: 0.07515747845172882
Validation loss: 1.5225681451059156

Epoch: 6| Step: 5
Training loss: 0.09191108494997025
Validation loss: 1.504807517092715

Epoch: 6| Step: 6
Training loss: 0.10609316825866699
Validation loss: 1.5504046396542621

Epoch: 6| Step: 7
Training loss: 0.07091077417135239
Validation loss: 1.5272090153027607

Epoch: 6| Step: 8
Training loss: 0.11329655349254608
Validation loss: 1.531413290449368

Epoch: 6| Step: 9
Training loss: 0.08961556106805801
Validation loss: 1.5697087139211676

Epoch: 6| Step: 10
Training loss: 0.12013521045446396
Validation loss: 1.536136616942703

Epoch: 6| Step: 11
Training loss: 0.12208867073059082
Validation loss: 1.568586807097158

Epoch: 6| Step: 12
Training loss: 0.13486021757125854
Validation loss: 1.5640795000137822

Epoch: 6| Step: 13
Training loss: 0.08176615834236145
Validation loss: 1.5452999966118925

Epoch: 408| Step: 0
Training loss: 0.08686970174312592
Validation loss: 1.5364017191753592

Epoch: 6| Step: 1
Training loss: 0.10083617269992828
Validation loss: 1.5410189231236775

Epoch: 6| Step: 2
Training loss: 0.06598430871963501
Validation loss: 1.5518300251294208

Epoch: 6| Step: 3
Training loss: 0.13200441002845764
Validation loss: 1.5617780429060741

Epoch: 6| Step: 4
Training loss: 0.11908919364213943
Validation loss: 1.5430352662199287

Epoch: 6| Step: 5
Training loss: 0.06905476003885269
Validation loss: 1.5337802428071217

Epoch: 6| Step: 6
Training loss: 0.11074116826057434
Validation loss: 1.5525217697184572

Epoch: 6| Step: 7
Training loss: 0.10422694683074951
Validation loss: 1.536563019598684

Epoch: 6| Step: 8
Training loss: 0.22249183058738708
Validation loss: 1.506510970413044

Epoch: 6| Step: 9
Training loss: 0.1055765300989151
Validation loss: 1.5258809084533362

Epoch: 6| Step: 10
Training loss: 0.07344768941402435
Validation loss: 1.5187387261339413

Epoch: 6| Step: 11
Training loss: 0.06745240092277527
Validation loss: 1.5236764422027014

Epoch: 6| Step: 12
Training loss: 0.0666520968079567
Validation loss: 1.535762269009826

Epoch: 6| Step: 13
Training loss: 0.18575900793075562
Validation loss: 1.5340342701122325

Epoch: 409| Step: 0
Training loss: 0.0384378582239151
Validation loss: 1.5463026877372497

Epoch: 6| Step: 1
Training loss: 0.0890064612030983
Validation loss: 1.5443286453523943

Epoch: 6| Step: 2
Training loss: 0.08551425486803055
Validation loss: 1.5811049810019873

Epoch: 6| Step: 3
Training loss: 0.12216276675462723
Validation loss: 1.557792696901547

Epoch: 6| Step: 4
Training loss: 0.14063194394111633
Validation loss: 1.5616735425046695

Epoch: 6| Step: 5
Training loss: 0.09389446675777435
Validation loss: 1.54586539858131

Epoch: 6| Step: 6
Training loss: 0.07648193091154099
Validation loss: 1.5338192537266722

Epoch: 6| Step: 7
Training loss: 0.13410350680351257
Validation loss: 1.5121299835943407

Epoch: 6| Step: 8
Training loss: 0.10940097272396088
Validation loss: 1.5014581718752462

Epoch: 6| Step: 9
Training loss: 0.12280063331127167
Validation loss: 1.5218445716365692

Epoch: 6| Step: 10
Training loss: 0.1200941950082779
Validation loss: 1.5040439380112516

Epoch: 6| Step: 11
Training loss: 0.1380809247493744
Validation loss: 1.5125260917089318

Epoch: 6| Step: 12
Training loss: 0.1137305349111557
Validation loss: 1.510481338347158

Epoch: 6| Step: 13
Training loss: 0.10238742083311081
Validation loss: 1.4941200261474938

Epoch: 410| Step: 0
Training loss: 0.15061241388320923
Validation loss: 1.5129461403815978

Epoch: 6| Step: 1
Training loss: 0.12222670018672943
Validation loss: 1.5376574339405182

Epoch: 6| Step: 2
Training loss: 0.10279633849859238
Validation loss: 1.4954693400731651

Epoch: 6| Step: 3
Training loss: 0.05808909982442856
Validation loss: 1.5483862251363776

Epoch: 6| Step: 4
Training loss: 0.15818780660629272
Validation loss: 1.5504696189716298

Epoch: 6| Step: 5
Training loss: 0.15792222321033478
Validation loss: 1.5765605882931781

Epoch: 6| Step: 6
Training loss: 0.07569227367639542
Validation loss: 1.5734243264762304

Epoch: 6| Step: 7
Training loss: 0.06514135003089905
Validation loss: 1.5645232873578225

Epoch: 6| Step: 8
Training loss: 0.07895640283823013
Validation loss: 1.5733264659040718

Epoch: 6| Step: 9
Training loss: 0.06686744093894958
Validation loss: 1.550436230115993

Epoch: 6| Step: 10
Training loss: 0.09629649668931961
Validation loss: 1.5542381091784405

Epoch: 6| Step: 11
Training loss: 0.04650116339325905
Validation loss: 1.5614748693281604

Epoch: 6| Step: 12
Training loss: 0.11840499192476273
Validation loss: 1.5384221807602914

Epoch: 6| Step: 13
Training loss: 0.11336293816566467
Validation loss: 1.5209333294181413

Epoch: 411| Step: 0
Training loss: 0.10998564213514328
Validation loss: 1.5189148520910611

Epoch: 6| Step: 1
Training loss: 0.09469686448574066
Validation loss: 1.5114873493871381

Epoch: 6| Step: 2
Training loss: 0.05304288864135742
Validation loss: 1.531643106091407

Epoch: 6| Step: 3
Training loss: 0.0948067158460617
Validation loss: 1.5128085856796594

Epoch: 6| Step: 4
Training loss: 0.1516760289669037
Validation loss: 1.5236711822530276

Epoch: 6| Step: 5
Training loss: 0.07816191017627716
Validation loss: 1.5265533847193564

Epoch: 6| Step: 6
Training loss: 0.040566205978393555
Validation loss: 1.5349490283637919

Epoch: 6| Step: 7
Training loss: 0.14236143231391907
Validation loss: 1.5588319737424132

Epoch: 6| Step: 8
Training loss: 0.07696571946144104
Validation loss: 1.5584684546275804

Epoch: 6| Step: 9
Training loss: 0.08989197015762329
Validation loss: 1.56604467797023

Epoch: 6| Step: 10
Training loss: 0.12062697857618332
Validation loss: 1.5939239186625327

Epoch: 6| Step: 11
Training loss: 0.09229447692632675
Validation loss: 1.5914658352892885

Epoch: 6| Step: 12
Training loss: 0.14227935671806335
Validation loss: 1.6047051427184895

Epoch: 6| Step: 13
Training loss: 0.14442017674446106
Validation loss: 1.5808548106942126

Epoch: 412| Step: 0
Training loss: 0.12065336108207703
Validation loss: 1.5856012605851697

Epoch: 6| Step: 1
Training loss: 0.08306768536567688
Validation loss: 1.5874263266081452

Epoch: 6| Step: 2
Training loss: 0.06922738999128342
Validation loss: 1.550442749454129

Epoch: 6| Step: 3
Training loss: 0.07840415090322495
Validation loss: 1.5623073911154142

Epoch: 6| Step: 4
Training loss: 0.10016308724880219
Validation loss: 1.5268547137578328

Epoch: 6| Step: 5
Training loss: 0.12902075052261353
Validation loss: 1.5022048155466716

Epoch: 6| Step: 6
Training loss: 0.12058125436306
Validation loss: 1.5267523091326478

Epoch: 6| Step: 7
Training loss: 0.13513198494911194
Validation loss: 1.5281484716682023

Epoch: 6| Step: 8
Training loss: 0.07510961592197418
Validation loss: 1.5575731262083976

Epoch: 6| Step: 9
Training loss: 0.10042537748813629
Validation loss: 1.5544992121317054

Epoch: 6| Step: 10
Training loss: 0.09763839840888977
Validation loss: 1.5798370620255828

Epoch: 6| Step: 11
Training loss: 0.10201002657413483
Validation loss: 1.5732496271851242

Epoch: 6| Step: 12
Training loss: 0.07133345305919647
Validation loss: 1.5543584272425661

Epoch: 6| Step: 13
Training loss: 0.07147811353206635
Validation loss: 1.5447073469879806

Epoch: 413| Step: 0
Training loss: 0.056572325527668
Validation loss: 1.5306469343041862

Epoch: 6| Step: 1
Training loss: 0.10301028192043304
Validation loss: 1.5218456150383077

Epoch: 6| Step: 2
Training loss: 0.10221956670284271
Validation loss: 1.5140549367473972

Epoch: 6| Step: 3
Training loss: 0.07738062739372253
Validation loss: 1.5165213718209216

Epoch: 6| Step: 4
Training loss: 0.13048726320266724
Validation loss: 1.5570467518221947

Epoch: 6| Step: 5
Training loss: 0.08340460062026978
Validation loss: 1.5529955510170228

Epoch: 6| Step: 6
Training loss: 0.11543551087379456
Validation loss: 1.5514297331533125

Epoch: 6| Step: 7
Training loss: 0.09589186310768127
Validation loss: 1.5307193545884983

Epoch: 6| Step: 8
Training loss: 0.15044564008712769
Validation loss: 1.534237789851363

Epoch: 6| Step: 9
Training loss: 0.11130590736865997
Validation loss: 1.5270665345653411

Epoch: 6| Step: 10
Training loss: 0.12746188044548035
Validation loss: 1.5286905586078603

Epoch: 6| Step: 11
Training loss: 0.06731275469064713
Validation loss: 1.5346811650901713

Epoch: 6| Step: 12
Training loss: 0.17513905465602875
Validation loss: 1.5367539646804973

Epoch: 6| Step: 13
Training loss: 0.08273731172084808
Validation loss: 1.559906905697238

Epoch: 414| Step: 0
Training loss: 0.0881994366645813
Validation loss: 1.5494442870540004

Epoch: 6| Step: 1
Training loss: 0.1645004004240036
Validation loss: 1.5674827714120187

Epoch: 6| Step: 2
Training loss: 0.13568897545337677
Validation loss: 1.541599170495105

Epoch: 6| Step: 3
Training loss: 0.2114151418209076
Validation loss: 1.5093421442534334

Epoch: 6| Step: 4
Training loss: 0.12284484505653381
Validation loss: 1.519016203059945

Epoch: 6| Step: 5
Training loss: 0.06653353571891785
Validation loss: 1.5597842483110325

Epoch: 6| Step: 6
Training loss: 0.06970328092575073
Validation loss: 1.5231982104239925

Epoch: 6| Step: 7
Training loss: 0.07975109666585922
Validation loss: 1.5241400067524244

Epoch: 6| Step: 8
Training loss: 0.05633319914340973
Validation loss: 1.5165760055665047

Epoch: 6| Step: 9
Training loss: 0.09358568489551544
Validation loss: 1.534583043667578

Epoch: 6| Step: 10
Training loss: 0.11571787297725677
Validation loss: 1.5374474025541736

Epoch: 6| Step: 11
Training loss: 0.1038653776049614
Validation loss: 1.541841480039781

Epoch: 6| Step: 12
Training loss: 0.08473698794841766
Validation loss: 1.5188206716250348

Epoch: 6| Step: 13
Training loss: 0.10997658967971802
Validation loss: 1.531543061297427

Epoch: 415| Step: 0
Training loss: 0.08391188085079193
Validation loss: 1.5415361209582257

Epoch: 6| Step: 1
Training loss: 0.1239081621170044
Validation loss: 1.5425730386087972

Epoch: 6| Step: 2
Training loss: 0.09704041481018066
Validation loss: 1.5369084842743412

Epoch: 6| Step: 3
Training loss: 0.176713764667511
Validation loss: 1.5447341293416998

Epoch: 6| Step: 4
Training loss: 0.09598536044359207
Validation loss: 1.5521730684464978

Epoch: 6| Step: 5
Training loss: 0.14786699414253235
Validation loss: 1.5242633294033747

Epoch: 6| Step: 6
Training loss: 0.06073411554098129
Validation loss: 1.5089690044362059

Epoch: 6| Step: 7
Training loss: 0.09792916476726532
Validation loss: 1.48969691927715

Epoch: 6| Step: 8
Training loss: 0.06932570785284042
Validation loss: 1.5097178156657884

Epoch: 6| Step: 9
Training loss: 0.11775558441877365
Validation loss: 1.4976692199707031

Epoch: 6| Step: 10
Training loss: 0.1299097239971161
Validation loss: 1.531863203612707

Epoch: 6| Step: 11
Training loss: 0.09862945973873138
Validation loss: 1.5148931325122874

Epoch: 6| Step: 12
Training loss: 0.14737331867218018
Validation loss: 1.4940876345480643

Epoch: 6| Step: 13
Training loss: 0.09617174416780472
Validation loss: 1.4864705647191694

Epoch: 416| Step: 0
Training loss: 0.08431079983711243
Validation loss: 1.5128849103886595

Epoch: 6| Step: 1
Training loss: 0.1031494066119194
Validation loss: 1.5367430038349603

Epoch: 6| Step: 2
Training loss: 0.11917737126350403
Validation loss: 1.5404314610265917

Epoch: 6| Step: 3
Training loss: 0.11552248895168304
Validation loss: 1.5284556150436401

Epoch: 6| Step: 4
Training loss: 0.12295465171337128
Validation loss: 1.5321887564915482

Epoch: 6| Step: 5
Training loss: 0.12449406087398529
Validation loss: 1.5210743681077035

Epoch: 6| Step: 6
Training loss: 0.09082941710948944
Validation loss: 1.5294918706340175

Epoch: 6| Step: 7
Training loss: 0.11725109815597534
Validation loss: 1.5199941794077556

Epoch: 6| Step: 8
Training loss: 0.14960679411888123
Validation loss: 1.511932324337703

Epoch: 6| Step: 9
Training loss: 0.16565895080566406
Validation loss: 1.5457541186322448

Epoch: 6| Step: 10
Training loss: 0.08162351697683334
Validation loss: 1.5204207281912527

Epoch: 6| Step: 11
Training loss: 0.09509705007076263
Validation loss: 1.5347334108045023

Epoch: 6| Step: 12
Training loss: 0.14216654002666473
Validation loss: 1.547892121217584

Epoch: 6| Step: 13
Training loss: 0.06891332566738129
Validation loss: 1.5564182009748233

Epoch: 417| Step: 0
Training loss: 0.0954233705997467
Validation loss: 1.5625355012955204

Epoch: 6| Step: 1
Training loss: 0.10586029291152954
Validation loss: 1.5707582286609116

Epoch: 6| Step: 2
Training loss: 0.09152735769748688
Validation loss: 1.5739331117240332

Epoch: 6| Step: 3
Training loss: 0.17315298318862915
Validation loss: 1.5859379858099005

Epoch: 6| Step: 4
Training loss: 0.08998201042413712
Validation loss: 1.570658791449762

Epoch: 6| Step: 5
Training loss: 0.09409956634044647
Validation loss: 1.5815414139019546

Epoch: 6| Step: 6
Training loss: 0.09782996773719788
Validation loss: 1.5880619518218502

Epoch: 6| Step: 7
Training loss: 0.12185703963041306
Validation loss: 1.5568928103293143

Epoch: 6| Step: 8
Training loss: 0.15659183263778687
Validation loss: 1.5167606466559953

Epoch: 6| Step: 9
Training loss: 0.10245160758495331
Validation loss: 1.5227067585914367

Epoch: 6| Step: 10
Training loss: 0.12184309959411621
Validation loss: 1.514653951891007

Epoch: 6| Step: 11
Training loss: 0.08344392478466034
Validation loss: 1.4958356452244583

Epoch: 6| Step: 12
Training loss: 0.14692997932434082
Validation loss: 1.5047520078638548

Epoch: 6| Step: 13
Training loss: 0.1500350385904312
Validation loss: 1.4785684283061693

Epoch: 418| Step: 0
Training loss: 0.045573655515909195
Validation loss: 1.4930894022346826

Epoch: 6| Step: 1
Training loss: 0.14770932495594025
Validation loss: 1.4980023842985912

Epoch: 6| Step: 2
Training loss: 0.06276384741067886
Validation loss: 1.5019566769241004

Epoch: 6| Step: 3
Training loss: 0.07207833230495453
Validation loss: 1.534071340355822

Epoch: 6| Step: 4
Training loss: 0.1112365871667862
Validation loss: 1.5350430755205051

Epoch: 6| Step: 5
Training loss: 0.13665294647216797
Validation loss: 1.5265761972755514

Epoch: 6| Step: 6
Training loss: 0.1224166750907898
Validation loss: 1.5455025190948157

Epoch: 6| Step: 7
Training loss: 0.08252564817667007
Validation loss: 1.5294025533942766

Epoch: 6| Step: 8
Training loss: 0.08215299248695374
Validation loss: 1.525641131144698

Epoch: 6| Step: 9
Training loss: 0.13425786793231964
Validation loss: 1.5221106659981511

Epoch: 6| Step: 10
Training loss: 0.04978306591510773
Validation loss: 1.4972844239204162

Epoch: 6| Step: 11
Training loss: 0.06643179059028625
Validation loss: 1.5066794464665074

Epoch: 6| Step: 12
Training loss: 0.07195855677127838
Validation loss: 1.5030103575798772

Epoch: 6| Step: 13
Training loss: 0.04675736650824547
Validation loss: 1.5091423667887205

Epoch: 419| Step: 0
Training loss: 0.10618916898965836
Validation loss: 1.5015897879036524

Epoch: 6| Step: 1
Training loss: 0.07807806879281998
Validation loss: 1.5088179124298917

Epoch: 6| Step: 2
Training loss: 0.1006937101483345
Validation loss: 1.5285973536070956

Epoch: 6| Step: 3
Training loss: 0.04261239618062973
Validation loss: 1.525589773731847

Epoch: 6| Step: 4
Training loss: 0.06770573556423187
Validation loss: 1.5228287750674832

Epoch: 6| Step: 5
Training loss: 0.12110423296689987
Validation loss: 1.5089112186944613

Epoch: 6| Step: 6
Training loss: 0.11416826397180557
Validation loss: 1.5238256044285272

Epoch: 6| Step: 7
Training loss: 0.08282244950532913
Validation loss: 1.5066080208747619

Epoch: 6| Step: 8
Training loss: 0.07338707149028778
Validation loss: 1.538803614595885

Epoch: 6| Step: 9
Training loss: 0.1602519154548645
Validation loss: 1.5178781311999086

Epoch: 6| Step: 10
Training loss: 0.14734765887260437
Validation loss: 1.5632614576688377

Epoch: 6| Step: 11
Training loss: 0.07233287394046783
Validation loss: 1.5431470204425115

Epoch: 6| Step: 12
Training loss: 0.08833445608615875
Validation loss: 1.5287354851281771

Epoch: 6| Step: 13
Training loss: 0.07627081871032715
Validation loss: 1.521249681390742

Epoch: 420| Step: 0
Training loss: 0.10751364380121231
Validation loss: 1.5190164222512195

Epoch: 6| Step: 1
Training loss: 0.10343936830759048
Validation loss: 1.547467835487858

Epoch: 6| Step: 2
Training loss: 0.10258297622203827
Validation loss: 1.5124023550300187

Epoch: 6| Step: 3
Training loss: 0.11809616535902023
Validation loss: 1.5485018036698783

Epoch: 6| Step: 4
Training loss: 0.0832991823554039
Validation loss: 1.5384220243782125

Epoch: 6| Step: 5
Training loss: 0.0625000149011612
Validation loss: 1.5490893881808045

Epoch: 6| Step: 6
Training loss: 0.14439347386360168
Validation loss: 1.52438312192117

Epoch: 6| Step: 7
Training loss: 0.0574350468814373
Validation loss: 1.526154932155404

Epoch: 6| Step: 8
Training loss: 0.06926342099905014
Validation loss: 1.5023054576689197

Epoch: 6| Step: 9
Training loss: 0.06432481855154037
Validation loss: 1.4976749227892967

Epoch: 6| Step: 10
Training loss: 0.1063266396522522
Validation loss: 1.4981829184357838

Epoch: 6| Step: 11
Training loss: 0.14473611116409302
Validation loss: 1.4987645867050334

Epoch: 6| Step: 12
Training loss: 0.06639939546585083
Validation loss: 1.4956770225237774

Epoch: 6| Step: 13
Training loss: 0.1214619055390358
Validation loss: 1.4885971552582198

Epoch: 421| Step: 0
Training loss: 0.13875803351402283
Validation loss: 1.4982635282701062

Epoch: 6| Step: 1
Training loss: 0.07759161293506622
Validation loss: 1.513318971921039

Epoch: 6| Step: 2
Training loss: 0.08028747886419296
Validation loss: 1.5074498217592958

Epoch: 6| Step: 3
Training loss: 0.07161238044500351
Validation loss: 1.5474484325737081

Epoch: 6| Step: 4
Training loss: 0.06989942491054535
Validation loss: 1.5254354425655898

Epoch: 6| Step: 5
Training loss: 0.0997191071510315
Validation loss: 1.5521323885968936

Epoch: 6| Step: 6
Training loss: 0.10477910190820694
Validation loss: 1.5550601802846438

Epoch: 6| Step: 7
Training loss: 0.06103549525141716
Validation loss: 1.5449412074140323

Epoch: 6| Step: 8
Training loss: 0.09054189920425415
Validation loss: 1.5459365062816168

Epoch: 6| Step: 9
Training loss: 0.08608195185661316
Validation loss: 1.5459174058770622

Epoch: 6| Step: 10
Training loss: 0.15168432891368866
Validation loss: 1.5083062776955225

Epoch: 6| Step: 11
Training loss: 0.1476370096206665
Validation loss: 1.5340558585300241

Epoch: 6| Step: 12
Training loss: 0.08404560387134552
Validation loss: 1.5161994708481656

Epoch: 6| Step: 13
Training loss: 0.12053635716438293
Validation loss: 1.473869542921743

Epoch: 422| Step: 0
Training loss: 0.061335768550634384
Validation loss: 1.488974130281838

Epoch: 6| Step: 1
Training loss: 0.08409719169139862
Validation loss: 1.5048561967829222

Epoch: 6| Step: 2
Training loss: 0.1021651029586792
Validation loss: 1.4914676950823875

Epoch: 6| Step: 3
Training loss: 0.06139004975557327
Validation loss: 1.5128578178344234

Epoch: 6| Step: 4
Training loss: 0.11848343163728714
Validation loss: 1.5165672315064298

Epoch: 6| Step: 5
Training loss: 0.03783012926578522
Validation loss: 1.5337054928143818

Epoch: 6| Step: 6
Training loss: 0.13921785354614258
Validation loss: 1.5518890273186468

Epoch: 6| Step: 7
Training loss: 0.10419546067714691
Validation loss: 1.5198941948593303

Epoch: 6| Step: 8
Training loss: 0.055685751140117645
Validation loss: 1.5170118603655087

Epoch: 6| Step: 9
Training loss: 0.09085831791162491
Validation loss: 1.5623739073353429

Epoch: 6| Step: 10
Training loss: 0.17670713365077972
Validation loss: 1.5512205195683304

Epoch: 6| Step: 11
Training loss: 0.11168579757213593
Validation loss: 1.5249515079682874

Epoch: 6| Step: 12
Training loss: 0.09814053028821945
Validation loss: 1.5223768372689523

Epoch: 6| Step: 13
Training loss: 0.2118149846792221
Validation loss: 1.5298987921848093

Epoch: 423| Step: 0
Training loss: 0.06504283100366592
Validation loss: 1.5311662868786884

Epoch: 6| Step: 1
Training loss: 0.059711284935474396
Validation loss: 1.5409703152154082

Epoch: 6| Step: 2
Training loss: 0.08770795166492462
Validation loss: 1.498726120559118

Epoch: 6| Step: 3
Training loss: 0.06855180114507675
Validation loss: 1.500607910976615

Epoch: 6| Step: 4
Training loss: 0.12107495963573456
Validation loss: 1.5375810630859867

Epoch: 6| Step: 5
Training loss: 0.08091969043016434
Validation loss: 1.5240366497347433

Epoch: 6| Step: 6
Training loss: 0.06231146305799484
Validation loss: 1.5296000229415072

Epoch: 6| Step: 7
Training loss: 0.15619681775569916
Validation loss: 1.510451732143279

Epoch: 6| Step: 8
Training loss: 0.23028407990932465
Validation loss: 1.5346537918172858

Epoch: 6| Step: 9
Training loss: 0.07647145539522171
Validation loss: 1.54262686416667

Epoch: 6| Step: 10
Training loss: 0.07758957147598267
Validation loss: 1.5048048509064542

Epoch: 6| Step: 11
Training loss: 0.098550945520401
Validation loss: 1.4933826743915517

Epoch: 6| Step: 12
Training loss: 0.1268211305141449
Validation loss: 1.4960977415884695

Epoch: 6| Step: 13
Training loss: 0.0816088542342186
Validation loss: 1.4968955914179485

Epoch: 424| Step: 0
Training loss: 0.09284816682338715
Validation loss: 1.5092730240155292

Epoch: 6| Step: 1
Training loss: 0.12411333620548248
Validation loss: 1.4841897949095695

Epoch: 6| Step: 2
Training loss: 0.059184931218624115
Validation loss: 1.5001246108803699

Epoch: 6| Step: 3
Training loss: 0.050882574170827866
Validation loss: 1.4900728092398694

Epoch: 6| Step: 4
Training loss: 0.09906882792711258
Validation loss: 1.5029746614476687

Epoch: 6| Step: 5
Training loss: 0.10123545676469803
Validation loss: 1.5018569179760513

Epoch: 6| Step: 6
Training loss: 0.09008476883172989
Validation loss: 1.5373012474788132

Epoch: 6| Step: 7
Training loss: 0.09587819874286652
Validation loss: 1.5228816488737702

Epoch: 6| Step: 8
Training loss: 0.06863607466220856
Validation loss: 1.54547829140899

Epoch: 6| Step: 9
Training loss: 0.07892288267612457
Validation loss: 1.5246229966481526

Epoch: 6| Step: 10
Training loss: 0.0723205953836441
Validation loss: 1.55607557553117

Epoch: 6| Step: 11
Training loss: 0.10275179147720337
Validation loss: 1.5618335072712233

Epoch: 6| Step: 12
Training loss: 0.12409470975399017
Validation loss: 1.5837038909235308

Epoch: 6| Step: 13
Training loss: 0.16892385482788086
Validation loss: 1.5403511319109189

Epoch: 425| Step: 0
Training loss: 0.1281786561012268
Validation loss: 1.5389589468638103

Epoch: 6| Step: 1
Training loss: 0.06261402368545532
Validation loss: 1.52632361970922

Epoch: 6| Step: 2
Training loss: 0.06339910626411438
Validation loss: 1.5183161471479683

Epoch: 6| Step: 3
Training loss: 0.12029141187667847
Validation loss: 1.5131712690476449

Epoch: 6| Step: 4
Training loss: 0.056738607585430145
Validation loss: 1.4921752579750553

Epoch: 6| Step: 5
Training loss: 0.06743863970041275
Validation loss: 1.5152757078088739

Epoch: 6| Step: 6
Training loss: 0.07488676905632019
Validation loss: 1.5087981736788185

Epoch: 6| Step: 7
Training loss: 0.05784387141466141
Validation loss: 1.516447841480214

Epoch: 6| Step: 8
Training loss: 0.060212504118680954
Validation loss: 1.530119312706814

Epoch: 6| Step: 9
Training loss: 0.06896773725748062
Validation loss: 1.5188939443198584

Epoch: 6| Step: 10
Training loss: 0.1295861005783081
Validation loss: 1.515335685463362

Epoch: 6| Step: 11
Training loss: 0.16863472759723663
Validation loss: 1.514460015040572

Epoch: 6| Step: 12
Training loss: 0.06490907818078995
Validation loss: 1.5111316480944235

Epoch: 6| Step: 13
Training loss: 0.06662347167730331
Validation loss: 1.4887739919847058

Epoch: 426| Step: 0
Training loss: 0.05917969346046448
Validation loss: 1.5300037803188447

Epoch: 6| Step: 1
Training loss: 0.059922222048044205
Validation loss: 1.5235223821414414

Epoch: 6| Step: 2
Training loss: 0.07241076231002808
Validation loss: 1.5170820964279996

Epoch: 6| Step: 3
Training loss: 0.07484584301710129
Validation loss: 1.5188556948015768

Epoch: 6| Step: 4
Training loss: 0.126572385430336
Validation loss: 1.5178469445115776

Epoch: 6| Step: 5
Training loss: 0.10438110679388046
Validation loss: 1.521571922045882

Epoch: 6| Step: 6
Training loss: 0.10690580308437347
Validation loss: 1.5111119593343427

Epoch: 6| Step: 7
Training loss: 0.11276133358478546
Validation loss: 1.506758532216472

Epoch: 6| Step: 8
Training loss: 0.10875844955444336
Validation loss: 1.5146154447268414

Epoch: 6| Step: 9
Training loss: 0.07141480594873428
Validation loss: 1.5244574662177794

Epoch: 6| Step: 10
Training loss: 0.08495777100324631
Validation loss: 1.512929876645406

Epoch: 6| Step: 11
Training loss: 0.1434735655784607
Validation loss: 1.528626540655731

Epoch: 6| Step: 12
Training loss: 0.09587706625461578
Validation loss: 1.5540141264597576

Epoch: 6| Step: 13
Training loss: 0.0635853260755539
Validation loss: 1.5294052208623579

Epoch: 427| Step: 0
Training loss: 0.09484615176916122
Validation loss: 1.545546543213629

Epoch: 6| Step: 1
Training loss: 0.07665669173002243
Validation loss: 1.547066460373581

Epoch: 6| Step: 2
Training loss: 0.09897419810295105
Validation loss: 1.533352977486067

Epoch: 6| Step: 3
Training loss: 0.11521882563829422
Validation loss: 1.535652716954549

Epoch: 6| Step: 4
Training loss: 0.09528923779726028
Validation loss: 1.5099216033053655

Epoch: 6| Step: 5
Training loss: 0.055570393800735474
Validation loss: 1.5157846750751618

Epoch: 6| Step: 6
Training loss: 0.07045648992061615
Validation loss: 1.536938158414697

Epoch: 6| Step: 7
Training loss: 0.10187356919050217
Validation loss: 1.5174874413398005

Epoch: 6| Step: 8
Training loss: 0.10120036453008652
Validation loss: 1.5214331009054696

Epoch: 6| Step: 9
Training loss: 0.08886686712503433
Validation loss: 1.4919128924287774

Epoch: 6| Step: 10
Training loss: 0.17556820809841156
Validation loss: 1.5224566344291932

Epoch: 6| Step: 11
Training loss: 0.05912259593605995
Validation loss: 1.5053331877595635

Epoch: 6| Step: 12
Training loss: 0.11659083515405655
Validation loss: 1.4870359282339773

Epoch: 6| Step: 13
Training loss: 0.09268506616353989
Validation loss: 1.4664999220960884

Epoch: 428| Step: 0
Training loss: 0.11438765376806259
Validation loss: 1.4826430005411948

Epoch: 6| Step: 1
Training loss: 0.1034800112247467
Validation loss: 1.4895672669974707

Epoch: 6| Step: 2
Training loss: 0.09244492650032043
Validation loss: 1.498660268322114

Epoch: 6| Step: 3
Training loss: 0.10333458334207535
Validation loss: 1.5115705856712915

Epoch: 6| Step: 4
Training loss: 0.13277024030685425
Validation loss: 1.5171713931586153

Epoch: 6| Step: 5
Training loss: 0.12158611416816711
Validation loss: 1.5231215184734714

Epoch: 6| Step: 6
Training loss: 0.08427980542182922
Validation loss: 1.4966488717704691

Epoch: 6| Step: 7
Training loss: 0.059538714587688446
Validation loss: 1.4923824187247985

Epoch: 6| Step: 8
Training loss: 0.08335061371326447
Validation loss: 1.4871887827432284

Epoch: 6| Step: 9
Training loss: 0.14935946464538574
Validation loss: 1.4834020330059914

Epoch: 6| Step: 10
Training loss: 0.08246895670890808
Validation loss: 1.4682383562928887

Epoch: 6| Step: 11
Training loss: 0.05961126089096069
Validation loss: 1.45973023035193

Epoch: 6| Step: 12
Training loss: 0.0850926861166954
Validation loss: 1.477138166786522

Epoch: 6| Step: 13
Training loss: 0.1428934931755066
Validation loss: 1.4938132673181512

Epoch: 429| Step: 0
Training loss: 0.09254039824008942
Validation loss: 1.473510383277811

Epoch: 6| Step: 1
Training loss: 0.08923903107643127
Validation loss: 1.5047460448357366

Epoch: 6| Step: 2
Training loss: 0.08428805321455002
Validation loss: 1.4872872931982881

Epoch: 6| Step: 3
Training loss: 0.1147165447473526
Validation loss: 1.5037757235188638

Epoch: 6| Step: 4
Training loss: 0.054923951625823975
Validation loss: 1.4964322890004804

Epoch: 6| Step: 5
Training loss: 0.06406664848327637
Validation loss: 1.5240629937059136

Epoch: 6| Step: 6
Training loss: 0.12212150543928146
Validation loss: 1.5252951819409606

Epoch: 6| Step: 7
Training loss: 0.08812984824180603
Validation loss: 1.5487723030069822

Epoch: 6| Step: 8
Training loss: 0.11762832850217819
Validation loss: 1.5206518750036917

Epoch: 6| Step: 9
Training loss: 0.09791596233844757
Validation loss: 1.5567924502075359

Epoch: 6| Step: 10
Training loss: 0.07194353640079498
Validation loss: 1.5237683288512691

Epoch: 6| Step: 11
Training loss: 0.09287361800670624
Validation loss: 1.5490341776160783

Epoch: 6| Step: 12
Training loss: 0.0909128338098526
Validation loss: 1.5258334618742748

Epoch: 6| Step: 13
Training loss: 0.09391185641288757
Validation loss: 1.5267307873695128

Epoch: 430| Step: 0
Training loss: 0.07222554087638855
Validation loss: 1.5364093197289335

Epoch: 6| Step: 1
Training loss: 0.120687335729599
Validation loss: 1.5535119323320286

Epoch: 6| Step: 2
Training loss: 0.05895499885082245
Validation loss: 1.5522826602382045

Epoch: 6| Step: 3
Training loss: 0.09585577994585037
Validation loss: 1.5413882770845968

Epoch: 6| Step: 4
Training loss: 0.15320977568626404
Validation loss: 1.569305871763537

Epoch: 6| Step: 5
Training loss: 0.16967670619487762
Validation loss: 1.5826632168985182

Epoch: 6| Step: 6
Training loss: 0.1240561306476593
Validation loss: 1.540163524689213

Epoch: 6| Step: 7
Training loss: 0.11672830581665039
Validation loss: 1.5785034779579408

Epoch: 6| Step: 8
Training loss: 0.08114881813526154
Validation loss: 1.552647224036596

Epoch: 6| Step: 9
Training loss: 0.06940868496894836
Validation loss: 1.529222878076697

Epoch: 6| Step: 10
Training loss: 0.1524842083454132
Validation loss: 1.537086671398532

Epoch: 6| Step: 11
Training loss: 0.06286519765853882
Validation loss: 1.5240751158806585

Epoch: 6| Step: 12
Training loss: 0.0574570968747139
Validation loss: 1.485740409102491

Epoch: 6| Step: 13
Training loss: 0.0626269206404686
Validation loss: 1.4997525804786271

Epoch: 431| Step: 0
Training loss: 0.07827292382717133
Validation loss: 1.5072972543777958

Epoch: 6| Step: 1
Training loss: 0.05718349292874336
Validation loss: 1.4867989568300144

Epoch: 6| Step: 2
Training loss: 0.13345752656459808
Validation loss: 1.4956827637969807

Epoch: 6| Step: 3
Training loss: 0.12775933742523193
Validation loss: 1.4807886961967713

Epoch: 6| Step: 4
Training loss: 0.08778495341539383
Validation loss: 1.5205279216971448

Epoch: 6| Step: 5
Training loss: 0.14552652835845947
Validation loss: 1.510323973112209

Epoch: 6| Step: 6
Training loss: 0.09338130056858063
Validation loss: 1.5173276624371927

Epoch: 6| Step: 7
Training loss: 0.07242363691329956
Validation loss: 1.5226378902312248

Epoch: 6| Step: 8
Training loss: 0.11974703520536423
Validation loss: 1.5320621075168732

Epoch: 6| Step: 9
Training loss: 0.10965435206890106
Validation loss: 1.5329526162916614

Epoch: 6| Step: 10
Training loss: 0.08311732113361359
Validation loss: 1.5307510309321906

Epoch: 6| Step: 11
Training loss: 0.12125395238399506
Validation loss: 1.5349276476008917

Epoch: 6| Step: 12
Training loss: 0.11727520823478699
Validation loss: 1.539835250505837

Epoch: 6| Step: 13
Training loss: 0.14895765483379364
Validation loss: 1.5435245344715733

Epoch: 432| Step: 0
Training loss: 0.06928130984306335
Validation loss: 1.5566867493814038

Epoch: 6| Step: 1
Training loss: 0.0902593806385994
Validation loss: 1.5338547178494033

Epoch: 6| Step: 2
Training loss: 0.06928938627243042
Validation loss: 1.5725628163224907

Epoch: 6| Step: 3
Training loss: 0.13482919335365295
Validation loss: 1.5813711292000228

Epoch: 6| Step: 4
Training loss: 0.06330662965774536
Validation loss: 1.5684286496972526

Epoch: 6| Step: 5
Training loss: 0.09073996543884277
Validation loss: 1.5621452152088124

Epoch: 6| Step: 6
Training loss: 0.10431334376335144
Validation loss: 1.5550939472772742

Epoch: 6| Step: 7
Training loss: 0.056153804063797
Validation loss: 1.5543647645622172

Epoch: 6| Step: 8
Training loss: 0.1660577952861786
Validation loss: 1.5509790566659742

Epoch: 6| Step: 9
Training loss: 0.17683333158493042
Validation loss: 1.5397887012009979

Epoch: 6| Step: 10
Training loss: 0.07554233074188232
Validation loss: 1.5162066003327728

Epoch: 6| Step: 11
Training loss: 0.07807345688343048
Validation loss: 1.533738857956343

Epoch: 6| Step: 12
Training loss: 0.11749796569347382
Validation loss: 1.4980734048351165

Epoch: 6| Step: 13
Training loss: 0.08745777606964111
Validation loss: 1.4927278090548772

Epoch: 433| Step: 0
Training loss: 0.10361087322235107
Validation loss: 1.4920261303583782

Epoch: 6| Step: 1
Training loss: 0.10387812554836273
Validation loss: 1.5042117372635873

Epoch: 6| Step: 2
Training loss: 0.055443208664655685
Validation loss: 1.5024546910357732

Epoch: 6| Step: 3
Training loss: 0.06740511208772659
Validation loss: 1.5194734014490598

Epoch: 6| Step: 4
Training loss: 0.11862265318632126
Validation loss: 1.5203212550891343

Epoch: 6| Step: 5
Training loss: 0.0792049989104271
Validation loss: 1.5360445732711463

Epoch: 6| Step: 6
Training loss: 0.11760631203651428
Validation loss: 1.54428558452155

Epoch: 6| Step: 7
Training loss: 0.07306139171123505
Validation loss: 1.540376538871437

Epoch: 6| Step: 8
Training loss: 0.054851632565259933
Validation loss: 1.537533885689192

Epoch: 6| Step: 9
Training loss: 0.06322284042835236
Validation loss: 1.530307415992983

Epoch: 6| Step: 10
Training loss: 0.05745108425617218
Validation loss: 1.5323694662381244

Epoch: 6| Step: 11
Training loss: 0.152146577835083
Validation loss: 1.5193949085409924

Epoch: 6| Step: 12
Training loss: 0.09031713008880615
Validation loss: 1.5407232751128495

Epoch: 6| Step: 13
Training loss: 0.10048913210630417
Validation loss: 1.537028499828872

Epoch: 434| Step: 0
Training loss: 0.10075027495622635
Validation loss: 1.5261621552128946

Epoch: 6| Step: 1
Training loss: 0.12511752545833588
Validation loss: 1.5017585036575154

Epoch: 6| Step: 2
Training loss: 0.12057124078273773
Validation loss: 1.4927280795189641

Epoch: 6| Step: 3
Training loss: 0.08141547441482544
Validation loss: 1.5329572039265786

Epoch: 6| Step: 4
Training loss: 0.05899442732334137
Validation loss: 1.5430551805803854

Epoch: 6| Step: 5
Training loss: 0.09810835868120193
Validation loss: 1.5598068916669456

Epoch: 6| Step: 6
Training loss: 0.1098136454820633
Validation loss: 1.5727677704185568

Epoch: 6| Step: 7
Training loss: 0.11388133466243744
Validation loss: 1.5823941141046503

Epoch: 6| Step: 8
Training loss: 0.13064412772655487
Validation loss: 1.5814003034304547

Epoch: 6| Step: 9
Training loss: 0.1310432255268097
Validation loss: 1.584002987671924

Epoch: 6| Step: 10
Training loss: 0.08017780631780624
Validation loss: 1.5848222894053305

Epoch: 6| Step: 11
Training loss: 0.06032807379961014
Validation loss: 1.5737219382357854

Epoch: 6| Step: 12
Training loss: 0.05838773027062416
Validation loss: 1.5584508283163911

Epoch: 6| Step: 13
Training loss: 0.0407966785132885
Validation loss: 1.5562095046043396

Epoch: 435| Step: 0
Training loss: 0.07376264780759811
Validation loss: 1.5521784354281682

Epoch: 6| Step: 1
Training loss: 0.10459591448307037
Validation loss: 1.551566611054123

Epoch: 6| Step: 2
Training loss: 0.07463410496711731
Validation loss: 1.5285097129883305

Epoch: 6| Step: 3
Training loss: 0.08285561203956604
Validation loss: 1.5546197993780977

Epoch: 6| Step: 4
Training loss: 0.060705553740262985
Validation loss: 1.5664119656367967

Epoch: 6| Step: 5
Training loss: 0.1123054027557373
Validation loss: 1.552107584091925

Epoch: 6| Step: 6
Training loss: 0.06320548057556152
Validation loss: 1.6021050727495583

Epoch: 6| Step: 7
Training loss: 0.11157132685184479
Validation loss: 1.598908132122409

Epoch: 6| Step: 8
Training loss: 0.14404244720935822
Validation loss: 1.5932173344396776

Epoch: 6| Step: 9
Training loss: 0.14348071813583374
Validation loss: 1.6154707965030466

Epoch: 6| Step: 10
Training loss: 0.17562170326709747
Validation loss: 1.6131966985682005

Epoch: 6| Step: 11
Training loss: 0.06077677756547928
Validation loss: 1.6008783194326586

Epoch: 6| Step: 12
Training loss: 0.13970617949962616
Validation loss: 1.5867070164731754

Epoch: 6| Step: 13
Training loss: 0.05105246603488922
Validation loss: 1.576108951722422

Epoch: 436| Step: 0
Training loss: 0.07023615390062332
Validation loss: 1.5929734424878192

Epoch: 6| Step: 1
Training loss: 0.09132511913776398
Validation loss: 1.5924357137372416

Epoch: 6| Step: 2
Training loss: 0.11014353483915329
Validation loss: 1.605321241322384

Epoch: 6| Step: 3
Training loss: 0.1896173506975174
Validation loss: 1.578459039811165

Epoch: 6| Step: 4
Training loss: 0.13500121235847473
Validation loss: 1.5761050524250153

Epoch: 6| Step: 5
Training loss: 0.13504573702812195
Validation loss: 1.5467089645324215

Epoch: 6| Step: 6
Training loss: 0.07691985368728638
Validation loss: 1.5502826500964422

Epoch: 6| Step: 7
Training loss: 0.07493649423122406
Validation loss: 1.5424800636947795

Epoch: 6| Step: 8
Training loss: 0.062129050493240356
Validation loss: 1.5556859816274335

Epoch: 6| Step: 9
Training loss: 0.10454396158456802
Validation loss: 1.5616592271353609

Epoch: 6| Step: 10
Training loss: 0.1978207230567932
Validation loss: 1.5598583644436252

Epoch: 6| Step: 11
Training loss: 0.05207338184118271
Validation loss: 1.5462130038968978

Epoch: 6| Step: 12
Training loss: 0.0868300274014473
Validation loss: 1.5289284516406316

Epoch: 6| Step: 13
Training loss: 0.07483000308275223
Validation loss: 1.5588317930057485

Epoch: 437| Step: 0
Training loss: 0.06777021288871765
Validation loss: 1.5508539010119695

Epoch: 6| Step: 1
Training loss: 0.14232666790485382
Validation loss: 1.5681057245500627

Epoch: 6| Step: 2
Training loss: 0.10413088649511337
Validation loss: 1.5558731927666614

Epoch: 6| Step: 3
Training loss: 0.05499769747257233
Validation loss: 1.5736140999742734

Epoch: 6| Step: 4
Training loss: 0.11930672824382782
Validation loss: 1.522777029263076

Epoch: 6| Step: 5
Training loss: 0.05710342153906822
Validation loss: 1.521624530515363

Epoch: 6| Step: 6
Training loss: 0.1189250573515892
Validation loss: 1.5134344113770353

Epoch: 6| Step: 7
Training loss: 0.10326141119003296
Validation loss: 1.4996611020898307

Epoch: 6| Step: 8
Training loss: 0.1344851553440094
Validation loss: 1.4897595502996956

Epoch: 6| Step: 9
Training loss: 0.11547623574733734
Validation loss: 1.513406785585547

Epoch: 6| Step: 10
Training loss: 0.07968127727508545
Validation loss: 1.5050102395396079

Epoch: 6| Step: 11
Training loss: 0.08611240983009338
Validation loss: 1.4970813002637637

Epoch: 6| Step: 12
Training loss: 0.08068512380123138
Validation loss: 1.4972611281179613

Epoch: 6| Step: 13
Training loss: 0.09705699980258942
Validation loss: 1.5280018814148442

Epoch: 438| Step: 0
Training loss: 0.08978375792503357
Validation loss: 1.520473104010346

Epoch: 6| Step: 1
Training loss: 0.07750826328992844
Validation loss: 1.5378217261324647

Epoch: 6| Step: 2
Training loss: 0.11046041548252106
Validation loss: 1.5256921450297039

Epoch: 6| Step: 3
Training loss: 0.10943133383989334
Validation loss: 1.5249931607195126

Epoch: 6| Step: 4
Training loss: 0.0830661877989769
Validation loss: 1.5125595754192722

Epoch: 6| Step: 5
Training loss: 0.08918435126543045
Validation loss: 1.4922794218986266

Epoch: 6| Step: 6
Training loss: 0.17560552060604095
Validation loss: 1.516929264991514

Epoch: 6| Step: 7
Training loss: 0.10548602044582367
Validation loss: 1.4843405792790074

Epoch: 6| Step: 8
Training loss: 0.052833735942840576
Validation loss: 1.4832926065691057

Epoch: 6| Step: 9
Training loss: 0.10750862210988998
Validation loss: 1.4794649257454822

Epoch: 6| Step: 10
Training loss: 0.14280396699905396
Validation loss: 1.4905588883225636

Epoch: 6| Step: 11
Training loss: 0.1311681717634201
Validation loss: 1.5077812620388564

Epoch: 6| Step: 12
Training loss: 0.08182714879512787
Validation loss: 1.5353466028808265

Epoch: 6| Step: 13
Training loss: 0.04914366453886032
Validation loss: 1.5523165938674763

Epoch: 439| Step: 0
Training loss: 0.061350733041763306
Validation loss: 1.5704806966166343

Epoch: 6| Step: 1
Training loss: 0.09467697143554688
Validation loss: 1.5920329132387716

Epoch: 6| Step: 2
Training loss: 0.14986783266067505
Validation loss: 1.5978633678087624

Epoch: 6| Step: 3
Training loss: 0.13363106548786163
Validation loss: 1.606963502463474

Epoch: 6| Step: 4
Training loss: 0.12121261656284332
Validation loss: 1.5694492593888314

Epoch: 6| Step: 5
Training loss: 0.103089340031147
Validation loss: 1.5765951730871712

Epoch: 6| Step: 6
Training loss: 0.07577269524335861
Validation loss: 1.5638019269512546

Epoch: 6| Step: 7
Training loss: 0.12511301040649414
Validation loss: 1.5401506270131757

Epoch: 6| Step: 8
Training loss: 0.06010821461677551
Validation loss: 1.5276738315500238

Epoch: 6| Step: 9
Training loss: 0.1354002207517624
Validation loss: 1.5141098101933796

Epoch: 6| Step: 10
Training loss: 0.13778892159461975
Validation loss: 1.4954762183209902

Epoch: 6| Step: 11
Training loss: 0.06271494179964066
Validation loss: 1.4785444467298445

Epoch: 6| Step: 12
Training loss: 0.11243384331464767
Validation loss: 1.5014129812999437

Epoch: 6| Step: 13
Training loss: 0.06998830288648605
Validation loss: 1.46618059373671

Epoch: 440| Step: 0
Training loss: 0.11485078185796738
Validation loss: 1.4868110072228216

Epoch: 6| Step: 1
Training loss: 0.058340877294540405
Validation loss: 1.4898898986078077

Epoch: 6| Step: 2
Training loss: 0.10969316959381104
Validation loss: 1.5292313342453332

Epoch: 6| Step: 3
Training loss: 0.07245513796806335
Validation loss: 1.4982548093283048

Epoch: 6| Step: 4
Training loss: 0.06568832695484161
Validation loss: 1.5200144308869556

Epoch: 6| Step: 5
Training loss: 0.14093153178691864
Validation loss: 1.5335847793086883

Epoch: 6| Step: 6
Training loss: 0.11222955584526062
Validation loss: 1.5029715107333275

Epoch: 6| Step: 7
Training loss: 0.10567642748355865
Validation loss: 1.5168882198231195

Epoch: 6| Step: 8
Training loss: 0.14401789009571075
Validation loss: 1.5077456940886795

Epoch: 6| Step: 9
Training loss: 0.061577387154102325
Validation loss: 1.5041311505020305

Epoch: 6| Step: 10
Training loss: 0.0739358589053154
Validation loss: 1.5014116565386455

Epoch: 6| Step: 11
Training loss: 0.06857673823833466
Validation loss: 1.4735321742232128

Epoch: 6| Step: 12
Training loss: 0.11103874444961548
Validation loss: 1.4957818395348006

Epoch: 6| Step: 13
Training loss: 0.16754759848117828
Validation loss: 1.4610894758214232

Epoch: 441| Step: 0
Training loss: 0.07522325217723846
Validation loss: 1.4851964442960677

Epoch: 6| Step: 1
Training loss: 0.09156384319067001
Validation loss: 1.497732577785369

Epoch: 6| Step: 2
Training loss: 0.05597469210624695
Validation loss: 1.5012518590496433

Epoch: 6| Step: 3
Training loss: 0.05032975971698761
Validation loss: 1.5282625357309978

Epoch: 6| Step: 4
Training loss: 0.1282416135072708
Validation loss: 1.5391224142043822

Epoch: 6| Step: 5
Training loss: 0.08979745209217072
Validation loss: 1.5403519689395864

Epoch: 6| Step: 6
Training loss: 0.14990770816802979
Validation loss: 1.5598287031214724

Epoch: 6| Step: 7
Training loss: 0.1206786185503006
Validation loss: 1.54658120037407

Epoch: 6| Step: 8
Training loss: 0.05425924062728882
Validation loss: 1.5228450657219015

Epoch: 6| Step: 9
Training loss: 0.1321628838777542
Validation loss: 1.5231813192367554

Epoch: 6| Step: 10
Training loss: 0.09531159698963165
Validation loss: 1.510707031014145

Epoch: 6| Step: 11
Training loss: 0.15060845017433167
Validation loss: 1.4918978867992279

Epoch: 6| Step: 12
Training loss: 0.11549561470746994
Validation loss: 1.4953405703267744

Epoch: 6| Step: 13
Training loss: 0.0665651261806488
Validation loss: 1.4960849849126672

Epoch: 442| Step: 0
Training loss: 0.1318977326154709
Validation loss: 1.492741306622823

Epoch: 6| Step: 1
Training loss: 0.1277085393667221
Validation loss: 1.478364715012171

Epoch: 6| Step: 2
Training loss: 0.10688547790050507
Validation loss: 1.4894481012898106

Epoch: 6| Step: 3
Training loss: 0.11408058553934097
Validation loss: 1.4967390875662527

Epoch: 6| Step: 4
Training loss: 0.10084358602762222
Validation loss: 1.5216828969217115

Epoch: 6| Step: 5
Training loss: 0.10028287023305893
Validation loss: 1.5295451661591888

Epoch: 6| Step: 6
Training loss: 0.09537307918071747
Validation loss: 1.5547009732133599

Epoch: 6| Step: 7
Training loss: 0.12197692692279816
Validation loss: 1.548601596586166

Epoch: 6| Step: 8
Training loss: 0.13569694757461548
Validation loss: 1.542467007073023

Epoch: 6| Step: 9
Training loss: 0.14646130800247192
Validation loss: 1.565880544724003

Epoch: 6| Step: 10
Training loss: 0.09972493350505829
Validation loss: 1.5613975717175392

Epoch: 6| Step: 11
Training loss: 0.06377760320901871
Validation loss: 1.5417677728078698

Epoch: 6| Step: 12
Training loss: 0.14708642661571503
Validation loss: 1.5411383836500105

Epoch: 6| Step: 13
Training loss: 0.08041217923164368
Validation loss: 1.5456600881391955

Epoch: 443| Step: 0
Training loss: 0.07457999885082245
Validation loss: 1.5198258776818552

Epoch: 6| Step: 1
Training loss: 0.10460376739501953
Validation loss: 1.5383130914421492

Epoch: 6| Step: 2
Training loss: 0.05895911157131195
Validation loss: 1.5423264516297208

Epoch: 6| Step: 3
Training loss: 0.07707685977220535
Validation loss: 1.5410085839609946

Epoch: 6| Step: 4
Training loss: 0.08453348278999329
Validation loss: 1.5188723187292776

Epoch: 6| Step: 5
Training loss: 0.08028092980384827
Validation loss: 1.5325400983133624

Epoch: 6| Step: 6
Training loss: 0.09883549809455872
Validation loss: 1.5418802512589322

Epoch: 6| Step: 7
Training loss: 0.07065191864967346
Validation loss: 1.5499956928273684

Epoch: 6| Step: 8
Training loss: 0.12837907671928406
Validation loss: 1.5642233971626527

Epoch: 6| Step: 9
Training loss: 0.11541301757097244
Validation loss: 1.557902107956589

Epoch: 6| Step: 10
Training loss: 0.07536307722330093
Validation loss: 1.5389559076678367

Epoch: 6| Step: 11
Training loss: 0.1300334930419922
Validation loss: 1.536985542184563

Epoch: 6| Step: 12
Training loss: 0.10730141401290894
Validation loss: 1.5126591779852425

Epoch: 6| Step: 13
Training loss: 0.04218212515115738
Validation loss: 1.522983875325931

Epoch: 444| Step: 0
Training loss: 0.06353854387998581
Validation loss: 1.5001262221285092

Epoch: 6| Step: 1
Training loss: 0.08322753757238388
Validation loss: 1.5092869176659534

Epoch: 6| Step: 2
Training loss: 0.10537084192037582
Validation loss: 1.5108026304552633

Epoch: 6| Step: 3
Training loss: 0.1803726702928543
Validation loss: 1.4899693791584303

Epoch: 6| Step: 4
Training loss: 0.13573916256427765
Validation loss: 1.5116073482780046

Epoch: 6| Step: 5
Training loss: 0.10685132443904877
Validation loss: 1.5100831088199411

Epoch: 6| Step: 6
Training loss: 0.07039864361286163
Validation loss: 1.5283911279452744

Epoch: 6| Step: 7
Training loss: 0.10097163915634155
Validation loss: 1.499716269072666

Epoch: 6| Step: 8
Training loss: 0.1087380200624466
Validation loss: 1.5337844100049747

Epoch: 6| Step: 9
Training loss: 0.15637052059173584
Validation loss: 1.5152056050556961

Epoch: 6| Step: 10
Training loss: 0.14174960553646088
Validation loss: 1.5229608884421728

Epoch: 6| Step: 11
Training loss: 0.08362805098295212
Validation loss: 1.5318614411097702

Epoch: 6| Step: 12
Training loss: 0.06393074244260788
Validation loss: 1.5278469119020688

Epoch: 6| Step: 13
Training loss: 0.08214695006608963
Validation loss: 1.5303504902829406

Epoch: 445| Step: 0
Training loss: 0.12108701467514038
Validation loss: 1.5426400624295717

Epoch: 6| Step: 1
Training loss: 0.11016366630792618
Validation loss: 1.53380371421896

Epoch: 6| Step: 2
Training loss: 0.1353324055671692
Validation loss: 1.5359472587544432

Epoch: 6| Step: 3
Training loss: 0.09862403571605682
Validation loss: 1.5415099769510248

Epoch: 6| Step: 4
Training loss: 0.09795183688402176
Validation loss: 1.5413882950300812

Epoch: 6| Step: 5
Training loss: 0.112577423453331
Validation loss: 1.5004874993396062

Epoch: 6| Step: 6
Training loss: 0.11454766243696213
Validation loss: 1.505608961146365

Epoch: 6| Step: 7
Training loss: 0.10187049955129623
Validation loss: 1.5214515962908346

Epoch: 6| Step: 8
Training loss: 0.11529042571783066
Validation loss: 1.540339244309292

Epoch: 6| Step: 9
Training loss: 0.1116638109087944
Validation loss: 1.538459421485983

Epoch: 6| Step: 10
Training loss: 0.11068939417600632
Validation loss: 1.5583954703423284

Epoch: 6| Step: 11
Training loss: 0.08253689110279083
Validation loss: 1.5517309506734211

Epoch: 6| Step: 12
Training loss: 0.11675398796796799
Validation loss: 1.5725294723305652

Epoch: 6| Step: 13
Training loss: 0.11524403095245361
Validation loss: 1.5529268736480384

Epoch: 446| Step: 0
Training loss: 0.09371400624513626
Validation loss: 1.5714064362228557

Epoch: 6| Step: 1
Training loss: 0.08943761885166168
Validation loss: 1.5506362043401247

Epoch: 6| Step: 2
Training loss: 0.06750842183828354
Validation loss: 1.5138094745656496

Epoch: 6| Step: 3
Training loss: 0.09351549297571182
Validation loss: 1.52238320150683

Epoch: 6| Step: 4
Training loss: 0.10205511003732681
Validation loss: 1.504273130047706

Epoch: 6| Step: 5
Training loss: 0.11834227293729782
Validation loss: 1.5148201475861252

Epoch: 6| Step: 6
Training loss: 0.11557294428348541
Validation loss: 1.5098317938466226

Epoch: 6| Step: 7
Training loss: 0.09507940709590912
Validation loss: 1.5108957957195979

Epoch: 6| Step: 8
Training loss: 0.15905135869979858
Validation loss: 1.4953680948544574

Epoch: 6| Step: 9
Training loss: 0.0949985608458519
Validation loss: 1.503629667784578

Epoch: 6| Step: 10
Training loss: 0.0807737335562706
Validation loss: 1.5113550629667056

Epoch: 6| Step: 11
Training loss: 0.08364797383546829
Validation loss: 1.5065625047170987

Epoch: 6| Step: 12
Training loss: 0.07011501491069794
Validation loss: 1.5102589720038957

Epoch: 6| Step: 13
Training loss: 0.14625009894371033
Validation loss: 1.524561269308931

Epoch: 447| Step: 0
Training loss: 0.08047156035900116
Validation loss: 1.513653355260049

Epoch: 6| Step: 1
Training loss: 0.07072620838880539
Validation loss: 1.5339886808908114

Epoch: 6| Step: 2
Training loss: 0.08160703629255295
Validation loss: 1.5136242630661174

Epoch: 6| Step: 3
Training loss: 0.11462961137294769
Validation loss: 1.5488029346671155

Epoch: 6| Step: 4
Training loss: 0.11255502700805664
Validation loss: 1.5657723308891378

Epoch: 6| Step: 5
Training loss: 0.11563000082969666
Validation loss: 1.5557601964601906

Epoch: 6| Step: 6
Training loss: 0.18337006866931915
Validation loss: 1.5398137133608583

Epoch: 6| Step: 7
Training loss: 0.08035191148519516
Validation loss: 1.5210254448716358

Epoch: 6| Step: 8
Training loss: 0.09168288111686707
Validation loss: 1.5234759135912823

Epoch: 6| Step: 9
Training loss: 0.053031161427497864
Validation loss: 1.5086549379492318

Epoch: 6| Step: 10
Training loss: 0.0845523327589035
Validation loss: 1.5248422315043788

Epoch: 6| Step: 11
Training loss: 0.11936730146408081
Validation loss: 1.5226926957407305

Epoch: 6| Step: 12
Training loss: 0.06576471030712128
Validation loss: 1.5249995422619644

Epoch: 6| Step: 13
Training loss: 0.0743928775191307
Validation loss: 1.5267471741604548

Epoch: 448| Step: 0
Training loss: 0.12949466705322266
Validation loss: 1.525199233844716

Epoch: 6| Step: 1
Training loss: 0.11355099827051163
Validation loss: 1.5172555215897099

Epoch: 6| Step: 2
Training loss: 0.08455204218626022
Validation loss: 1.5349461583681003

Epoch: 6| Step: 3
Training loss: 0.07662274688482285
Validation loss: 1.553282892832192

Epoch: 6| Step: 4
Training loss: 0.11822357773780823
Validation loss: 1.5566905698468607

Epoch: 6| Step: 5
Training loss: 0.15024471282958984
Validation loss: 1.5374611295679563

Epoch: 6| Step: 6
Training loss: 0.09933120012283325
Validation loss: 1.5461339950561523

Epoch: 6| Step: 7
Training loss: 0.0630660206079483
Validation loss: 1.554443113265499

Epoch: 6| Step: 8
Training loss: 0.06009136140346527
Validation loss: 1.5300562984199935

Epoch: 6| Step: 9
Training loss: 0.07570667564868927
Validation loss: 1.530892345213121

Epoch: 6| Step: 10
Training loss: 0.07226231694221497
Validation loss: 1.5367144384691793

Epoch: 6| Step: 11
Training loss: 0.08224603533744812
Validation loss: 1.5164560438484274

Epoch: 6| Step: 12
Training loss: 0.07342085242271423
Validation loss: 1.5050688379554338

Epoch: 6| Step: 13
Training loss: 0.14290744066238403
Validation loss: 1.524033861775552

Epoch: 449| Step: 0
Training loss: 0.11952745914459229
Validation loss: 1.4924664202556814

Epoch: 6| Step: 1
Training loss: 0.08255697041749954
Validation loss: 1.5058636614071426

Epoch: 6| Step: 2
Training loss: 0.11430255323648453
Validation loss: 1.499480244933918

Epoch: 6| Step: 3
Training loss: 0.08503004908561707
Validation loss: 1.5149449084394722

Epoch: 6| Step: 4
Training loss: 0.08622914552688599
Validation loss: 1.503909319959661

Epoch: 6| Step: 5
Training loss: 0.060631778091192245
Validation loss: 1.5099810720771871

Epoch: 6| Step: 6
Training loss: 0.08848203718662262
Validation loss: 1.5089080538800967

Epoch: 6| Step: 7
Training loss: 0.16219016909599304
Validation loss: 1.5133762942847384

Epoch: 6| Step: 8
Training loss: 0.1940455436706543
Validation loss: 1.5037278898300663

Epoch: 6| Step: 9
Training loss: 0.0667167529463768
Validation loss: 1.5040129320595854

Epoch: 6| Step: 10
Training loss: 0.12838897109031677
Validation loss: 1.521021193073642

Epoch: 6| Step: 11
Training loss: 0.07647274434566498
Validation loss: 1.489036093475998

Epoch: 6| Step: 12
Training loss: 0.07364408671855927
Validation loss: 1.4944194439918763

Epoch: 6| Step: 13
Training loss: 0.06006848067045212
Validation loss: 1.449038879845732

Epoch: 450| Step: 0
Training loss: 0.12265346944332123
Validation loss: 1.4826293260820451

Epoch: 6| Step: 1
Training loss: 0.1814831793308258
Validation loss: 1.4938204237209853

Epoch: 6| Step: 2
Training loss: 0.12999941408634186
Validation loss: 1.4674304659648607

Epoch: 6| Step: 3
Training loss: 0.0830192118883133
Validation loss: 1.4632668392632597

Epoch: 6| Step: 4
Training loss: 0.07591091096401215
Validation loss: 1.4780408079906175

Epoch: 6| Step: 5
Training loss: 0.12274813652038574
Validation loss: 1.4881907470764653

Epoch: 6| Step: 6
Training loss: 0.054898496717214584
Validation loss: 1.489782307737617

Epoch: 6| Step: 7
Training loss: 0.13243649899959564
Validation loss: 1.5134874774563698

Epoch: 6| Step: 8
Training loss: 0.1225753128528595
Validation loss: 1.5015528112329461

Epoch: 6| Step: 9
Training loss: 0.08918964117765427
Validation loss: 1.5115475116237518

Epoch: 6| Step: 10
Training loss: 0.10484916716814041
Validation loss: 1.5238650473215247

Epoch: 6| Step: 11
Training loss: 0.1167803704738617
Validation loss: 1.4990658131978845

Epoch: 6| Step: 12
Training loss: 0.059184812009334564
Validation loss: 1.5386649511193717

Epoch: 6| Step: 13
Training loss: 0.09007798880338669
Validation loss: 1.545622903813598

Epoch: 451| Step: 0
Training loss: 0.10777752846479416
Validation loss: 1.4889584536193519

Epoch: 6| Step: 1
Training loss: 0.06532641500234604
Validation loss: 1.5195567607879639

Epoch: 6| Step: 2
Training loss: 0.09328792244195938
Validation loss: 1.5216219668747277

Epoch: 6| Step: 3
Training loss: 0.1341978758573532
Validation loss: 1.5172686589661466

Epoch: 6| Step: 4
Training loss: 0.18975001573562622
Validation loss: 1.5310067130673317

Epoch: 6| Step: 5
Training loss: 0.16553278267383575
Validation loss: 1.5163997604000954

Epoch: 6| Step: 6
Training loss: 0.0939057469367981
Validation loss: 1.4938710748508413

Epoch: 6| Step: 7
Training loss: 0.10936978459358215
Validation loss: 1.4664400168644485

Epoch: 6| Step: 8
Training loss: 0.1192840188741684
Validation loss: 1.5023066625800183

Epoch: 6| Step: 9
Training loss: 0.06582220643758774
Validation loss: 1.4827581554330804

Epoch: 6| Step: 10
Training loss: 0.06385596096515656
Validation loss: 1.5049034959526473

Epoch: 6| Step: 11
Training loss: 0.09822443127632141
Validation loss: 1.5148440599441528

Epoch: 6| Step: 12
Training loss: 0.07604755461215973
Validation loss: 1.5136966166957733

Epoch: 6| Step: 13
Training loss: 0.21887339651584625
Validation loss: 1.5189303813442108

Epoch: 452| Step: 0
Training loss: 0.09428416192531586
Validation loss: 1.494863716504907

Epoch: 6| Step: 1
Training loss: 0.050694022327661514
Validation loss: 1.502978290280988

Epoch: 6| Step: 2
Training loss: 0.10705243796110153
Validation loss: 1.5067585129891672

Epoch: 6| Step: 3
Training loss: 0.12895044684410095
Validation loss: 1.4759090177474483

Epoch: 6| Step: 4
Training loss: 0.101533442735672
Validation loss: 1.4840067330227102

Epoch: 6| Step: 5
Training loss: 0.12089864164590836
Validation loss: 1.5096236172542776

Epoch: 6| Step: 6
Training loss: 0.10594434291124344
Validation loss: 1.5137922353641962

Epoch: 6| Step: 7
Training loss: 0.06313081085681915
Validation loss: 1.5413963756253641

Epoch: 6| Step: 8
Training loss: 0.11963632702827454
Validation loss: 1.5459285705320296

Epoch: 6| Step: 9
Training loss: 0.11242824047803879
Validation loss: 1.5273929590819983

Epoch: 6| Step: 10
Training loss: 0.08795367181301117
Validation loss: 1.5582800206317697

Epoch: 6| Step: 11
Training loss: 0.0861339122056961
Validation loss: 1.5404531545536493

Epoch: 6| Step: 12
Training loss: 0.0940878838300705
Validation loss: 1.5486418252350183

Epoch: 6| Step: 13
Training loss: 0.07849651575088501
Validation loss: 1.5442702347232449

Epoch: 453| Step: 0
Training loss: 0.08115392923355103
Validation loss: 1.527813579446526

Epoch: 6| Step: 1
Training loss: 0.05335916578769684
Validation loss: 1.5302633873877987

Epoch: 6| Step: 2
Training loss: 0.07127280533313751
Validation loss: 1.5410554300072372

Epoch: 6| Step: 3
Training loss: 0.08293730765581131
Validation loss: 1.527776559193929

Epoch: 6| Step: 4
Training loss: 0.08029665797948837
Validation loss: 1.5204532710454797

Epoch: 6| Step: 5
Training loss: 0.08662556856870651
Validation loss: 1.5219718640850437

Epoch: 6| Step: 6
Training loss: 0.05923585966229439
Validation loss: 1.5394739604765368

Epoch: 6| Step: 7
Training loss: 0.06929890066385269
Validation loss: 1.550625462685862

Epoch: 6| Step: 8
Training loss: 0.07256105542182922
Validation loss: 1.5203498178912747

Epoch: 6| Step: 9
Training loss: 0.09708940982818604
Validation loss: 1.5311523522100141

Epoch: 6| Step: 10
Training loss: 0.18389026820659637
Validation loss: 1.5382243599942935

Epoch: 6| Step: 11
Training loss: 0.09325752407312393
Validation loss: 1.5243935508112754

Epoch: 6| Step: 12
Training loss: 0.08868832886219025
Validation loss: 1.5260286408085977

Epoch: 6| Step: 13
Training loss: 0.06124991923570633
Validation loss: 1.519958101293092

Epoch: 454| Step: 0
Training loss: 0.09629712998867035
Validation loss: 1.5067657578376032

Epoch: 6| Step: 1
Training loss: 0.06494414806365967
Validation loss: 1.5004375762836908

Epoch: 6| Step: 2
Training loss: 0.09489250183105469
Validation loss: 1.5122920146552465

Epoch: 6| Step: 3
Training loss: 0.062627874314785
Validation loss: 1.4938156656039658

Epoch: 6| Step: 4
Training loss: 0.12010536342859268
Validation loss: 1.500342192188386

Epoch: 6| Step: 5
Training loss: 0.08315321803092957
Validation loss: 1.5206562203745688

Epoch: 6| Step: 6
Training loss: 0.10597769170999527
Validation loss: 1.5012036318420081

Epoch: 6| Step: 7
Training loss: 0.06486432999372482
Validation loss: 1.5213110767385012

Epoch: 6| Step: 8
Training loss: 0.06793132424354553
Validation loss: 1.5036468531495781

Epoch: 6| Step: 9
Training loss: 0.09936344623565674
Validation loss: 1.5022381236476283

Epoch: 6| Step: 10
Training loss: 0.061248913407325745
Validation loss: 1.5350159214388939

Epoch: 6| Step: 11
Training loss: 0.07403969764709473
Validation loss: 1.5481620232264202

Epoch: 6| Step: 12
Training loss: 0.11689621210098267
Validation loss: 1.5138577902188866

Epoch: 6| Step: 13
Training loss: 0.1636417955160141
Validation loss: 1.4765343960895334

Epoch: 455| Step: 0
Training loss: 0.052969638258218765
Validation loss: 1.4779559117491528

Epoch: 6| Step: 1
Training loss: 0.07690843194723129
Validation loss: 1.4730550896736883

Epoch: 6| Step: 2
Training loss: 0.13747960329055786
Validation loss: 1.4592455920352732

Epoch: 6| Step: 3
Training loss: 0.13726720213890076
Validation loss: 1.4595387469055832

Epoch: 6| Step: 4
Training loss: 0.10023152083158493
Validation loss: 1.4612336581753147

Epoch: 6| Step: 5
Training loss: 0.12131781131029129
Validation loss: 1.4710931419044413

Epoch: 6| Step: 6
Training loss: 0.12415782362222672
Validation loss: 1.4708981001248924

Epoch: 6| Step: 7
Training loss: 0.08617018908262253
Validation loss: 1.4846934900488904

Epoch: 6| Step: 8
Training loss: 0.14054909348487854
Validation loss: 1.517154215484537

Epoch: 6| Step: 9
Training loss: 0.08156196773052216
Validation loss: 1.5084012080264348

Epoch: 6| Step: 10
Training loss: 0.06027674674987793
Validation loss: 1.5436856439036708

Epoch: 6| Step: 11
Training loss: 0.13135303556919098
Validation loss: 1.5500508546829224

Epoch: 6| Step: 12
Training loss: 0.09155512601137161
Validation loss: 1.5480266617190452

Epoch: 6| Step: 13
Training loss: 0.09215272963047028
Validation loss: 1.5341386025951755

Epoch: 456| Step: 0
Training loss: 0.09089195728302002
Validation loss: 1.531880691487302

Epoch: 6| Step: 1
Training loss: 0.09630399942398071
Validation loss: 1.502366264661153

Epoch: 6| Step: 2
Training loss: 0.10017701983451843
Validation loss: 1.4918222632459415

Epoch: 6| Step: 3
Training loss: 0.09874879568815231
Validation loss: 1.4829103664685321

Epoch: 6| Step: 4
Training loss: 0.18273383378982544
Validation loss: 1.4999401274547781

Epoch: 6| Step: 5
Training loss: 0.04656130075454712
Validation loss: 1.4853854064018495

Epoch: 6| Step: 6
Training loss: 0.06468512117862701
Validation loss: 1.4892230418420607

Epoch: 6| Step: 7
Training loss: 0.08671809732913971
Validation loss: 1.4982038518433929

Epoch: 6| Step: 8
Training loss: 0.11403783410787582
Validation loss: 1.5118585325056506

Epoch: 6| Step: 9
Training loss: 0.09780026972293854
Validation loss: 1.5078883504354825

Epoch: 6| Step: 10
Training loss: 0.14754536747932434
Validation loss: 1.4885163909645491

Epoch: 6| Step: 11
Training loss: 0.08263509720563889
Validation loss: 1.4909459108947425

Epoch: 6| Step: 12
Training loss: 0.07373736053705215
Validation loss: 1.5254707477426017

Epoch: 6| Step: 13
Training loss: 0.065248504281044
Validation loss: 1.5061525260248492

Epoch: 457| Step: 0
Training loss: 0.11338307708501816
Validation loss: 1.5285347187390892

Epoch: 6| Step: 1
Training loss: 0.13681751489639282
Validation loss: 1.5383422387543546

Epoch: 6| Step: 2
Training loss: 0.07910490036010742
Validation loss: 1.5297707364123354

Epoch: 6| Step: 3
Training loss: 0.08944812417030334
Validation loss: 1.5117968102937103

Epoch: 6| Step: 4
Training loss: 0.0712476372718811
Validation loss: 1.5432684447175713

Epoch: 6| Step: 5
Training loss: 0.06563758850097656
Validation loss: 1.5511490119400846

Epoch: 6| Step: 6
Training loss: 0.06423244625329971
Validation loss: 1.5647631165801839

Epoch: 6| Step: 7
Training loss: 0.061433739960193634
Validation loss: 1.567195459078717

Epoch: 6| Step: 8
Training loss: 0.1135079562664032
Validation loss: 1.5767942269643147

Epoch: 6| Step: 9
Training loss: 0.05853630602359772
Validation loss: 1.5749774850824827

Epoch: 6| Step: 10
Training loss: 0.11863492429256439
Validation loss: 1.578677245365676

Epoch: 6| Step: 11
Training loss: 0.12125862389802933
Validation loss: 1.5768358668973368

Epoch: 6| Step: 12
Training loss: 0.15780246257781982
Validation loss: 1.5585857065775062

Epoch: 6| Step: 13
Training loss: 0.08699262887239456
Validation loss: 1.5539872223331082

Epoch: 458| Step: 0
Training loss: 0.10341975837945938
Validation loss: 1.5672348109624719

Epoch: 6| Step: 1
Training loss: 0.09602783620357513
Validation loss: 1.535232304244913

Epoch: 6| Step: 2
Training loss: 0.10885948687791824
Validation loss: 1.5189479525371263

Epoch: 6| Step: 3
Training loss: 0.14874769747257233
Validation loss: 1.5368764554300616

Epoch: 6| Step: 4
Training loss: 0.06963876634836197
Validation loss: 1.5236997110869295

Epoch: 6| Step: 5
Training loss: 0.1112586259841919
Validation loss: 1.51992206868305

Epoch: 6| Step: 6
Training loss: 0.10841052234172821
Validation loss: 1.5322023591687601

Epoch: 6| Step: 7
Training loss: 0.12725427746772766
Validation loss: 1.5275909593028407

Epoch: 6| Step: 8
Training loss: 0.11071714013814926
Validation loss: 1.5234995849670903

Epoch: 6| Step: 9
Training loss: 0.13164398074150085
Validation loss: 1.557099187245933

Epoch: 6| Step: 10
Training loss: 0.06159944832324982
Validation loss: 1.5244682834994407

Epoch: 6| Step: 11
Training loss: 0.11360617727041245
Validation loss: 1.530347680532804

Epoch: 6| Step: 12
Training loss: 0.06803315132856369
Validation loss: 1.5478117158336024

Epoch: 6| Step: 13
Training loss: 0.10222145915031433
Validation loss: 1.5503135003069395

Epoch: 459| Step: 0
Training loss: 0.13247178494930267
Validation loss: 1.5580742359161377

Epoch: 6| Step: 1
Training loss: 0.06926193088293076
Validation loss: 1.5489797643435899

Epoch: 6| Step: 2
Training loss: 0.08505077660083771
Validation loss: 1.4991802477067517

Epoch: 6| Step: 3
Training loss: 0.06664852797985077
Validation loss: 1.5230656464894612

Epoch: 6| Step: 4
Training loss: 0.087436743080616
Validation loss: 1.5116088172440887

Epoch: 6| Step: 5
Training loss: 0.11515213549137115
Validation loss: 1.5183518625074817

Epoch: 6| Step: 6
Training loss: 0.06634769588708878
Validation loss: 1.4857111438628166

Epoch: 6| Step: 7
Training loss: 0.1750452220439911
Validation loss: 1.5201708309112056

Epoch: 6| Step: 8
Training loss: 0.15039223432540894
Validation loss: 1.487394517467868

Epoch: 6| Step: 9
Training loss: 0.13276326656341553
Validation loss: 1.4926712743697628

Epoch: 6| Step: 10
Training loss: 0.07439185678958893
Validation loss: 1.4593232709874389

Epoch: 6| Step: 11
Training loss: 0.12317079305648804
Validation loss: 1.4947525775560768

Epoch: 6| Step: 12
Training loss: 0.10648053139448166
Validation loss: 1.4568478522762176

Epoch: 6| Step: 13
Training loss: 0.18569143116474152
Validation loss: 1.4689142780919229

Epoch: 460| Step: 0
Training loss: 0.11829159408807755
Validation loss: 1.4708208717325681

Epoch: 6| Step: 1
Training loss: 0.15963280200958252
Validation loss: 1.48793839639233

Epoch: 6| Step: 2
Training loss: 0.12862393260002136
Validation loss: 1.502588209285531

Epoch: 6| Step: 3
Training loss: 0.14146804809570312
Validation loss: 1.4976300783054803

Epoch: 6| Step: 4
Training loss: 0.1284266710281372
Validation loss: 1.506044671099673

Epoch: 6| Step: 5
Training loss: 0.0830000638961792
Validation loss: 1.495755180235832

Epoch: 6| Step: 6
Training loss: 0.13414445519447327
Validation loss: 1.502297547555739

Epoch: 6| Step: 7
Training loss: 0.10682784765958786
Validation loss: 1.5246602168647192

Epoch: 6| Step: 8
Training loss: 0.10327038913965225
Validation loss: 1.5377625239792692

Epoch: 6| Step: 9
Training loss: 0.13315331935882568
Validation loss: 1.5061071765038274

Epoch: 6| Step: 10
Training loss: 0.17097605764865875
Validation loss: 1.483083450666038

Epoch: 6| Step: 11
Training loss: 0.11840206384658813
Validation loss: 1.48275468426366

Epoch: 6| Step: 12
Training loss: 0.08700628578662872
Validation loss: 1.4979860398077196

Epoch: 6| Step: 13
Training loss: 0.1396462619304657
Validation loss: 1.503193542521487

Epoch: 461| Step: 0
Training loss: 0.09835729002952576
Validation loss: 1.5161548942647955

Epoch: 6| Step: 1
Training loss: 0.14689108729362488
Validation loss: 1.555531512024582

Epoch: 6| Step: 2
Training loss: 0.2254999279975891
Validation loss: 1.5944677309323383

Epoch: 6| Step: 3
Training loss: 0.14316734671592712
Validation loss: 1.5551096277852212

Epoch: 6| Step: 4
Training loss: 0.1496219038963318
Validation loss: 1.5521770754168112

Epoch: 6| Step: 5
Training loss: 0.1183176189661026
Validation loss: 1.5301392719309816

Epoch: 6| Step: 6
Training loss: 0.17689087986946106
Validation loss: 1.5278605991794216

Epoch: 6| Step: 7
Training loss: 0.13450105488300323
Validation loss: 1.518424194346192

Epoch: 6| Step: 8
Training loss: 0.13196852803230286
Validation loss: 1.5140810948546215

Epoch: 6| Step: 9
Training loss: 0.18822532892227173
Validation loss: 1.5557103067316034

Epoch: 6| Step: 10
Training loss: 0.10606116056442261
Validation loss: 1.5225605631387362

Epoch: 6| Step: 11
Training loss: 0.11947357654571533
Validation loss: 1.5312366203595233

Epoch: 6| Step: 12
Training loss: 0.06248760223388672
Validation loss: 1.5456094370093396

Epoch: 6| Step: 13
Training loss: 0.05499842017889023
Validation loss: 1.552182948717507

Epoch: 462| Step: 0
Training loss: 0.08281666040420532
Validation loss: 1.5581194559733074

Epoch: 6| Step: 1
Training loss: 0.1259716898202896
Validation loss: 1.5497890057102326

Epoch: 6| Step: 2
Training loss: 0.09255507588386536
Validation loss: 1.5824774247343822

Epoch: 6| Step: 3
Training loss: 0.11533994227647781
Validation loss: 1.5773704872336438

Epoch: 6| Step: 4
Training loss: 0.08909289538860321
Validation loss: 1.5384229895889119

Epoch: 6| Step: 5
Training loss: 0.11770561337471008
Validation loss: 1.5569344823078444

Epoch: 6| Step: 6
Training loss: 0.06157347559928894
Validation loss: 1.5566361488834504

Epoch: 6| Step: 7
Training loss: 0.07304764539003372
Validation loss: 1.5324887287232183

Epoch: 6| Step: 8
Training loss: 0.141744464635849
Validation loss: 1.5318103836428734

Epoch: 6| Step: 9
Training loss: 0.08263982832431793
Validation loss: 1.5390780023349229

Epoch: 6| Step: 10
Training loss: 0.1253155767917633
Validation loss: 1.523101322112545

Epoch: 6| Step: 11
Training loss: 0.09241697192192078
Validation loss: 1.5252913986482928

Epoch: 6| Step: 12
Training loss: 0.08282878249883652
Validation loss: 1.5533696592495005

Epoch: 6| Step: 13
Training loss: 0.08322426676750183
Validation loss: 1.536692960287935

Epoch: 463| Step: 0
Training loss: 0.13557347655296326
Validation loss: 1.518360968559019

Epoch: 6| Step: 1
Training loss: 0.1606227457523346
Validation loss: 1.5395860838633713

Epoch: 6| Step: 2
Training loss: 0.07652270793914795
Validation loss: 1.527515999732479

Epoch: 6| Step: 3
Training loss: 0.08206488192081451
Validation loss: 1.5079690307699225

Epoch: 6| Step: 4
Training loss: 0.11740169674158096
Validation loss: 1.4757674560751965

Epoch: 6| Step: 5
Training loss: 0.054978445172309875
Validation loss: 1.4825948848519275

Epoch: 6| Step: 6
Training loss: 0.0867672860622406
Validation loss: 1.4782567902277874

Epoch: 6| Step: 7
Training loss: 0.08106882125139236
Validation loss: 1.4968679092263664

Epoch: 6| Step: 8
Training loss: 0.09843596071004868
Validation loss: 1.4920609420345676

Epoch: 6| Step: 9
Training loss: 0.09972734749317169
Validation loss: 1.4797986169015207

Epoch: 6| Step: 10
Training loss: 0.12331092357635498
Validation loss: 1.4671204282391457

Epoch: 6| Step: 11
Training loss: 0.08385372161865234
Validation loss: 1.465809238854275

Epoch: 6| Step: 12
Training loss: 0.07118042558431625
Validation loss: 1.4701456767256542

Epoch: 6| Step: 13
Training loss: 0.15633821487426758
Validation loss: 1.4745649996624197

Epoch: 464| Step: 0
Training loss: 0.10090817511081696
Validation loss: 1.4752716383626383

Epoch: 6| Step: 1
Training loss: 0.16351188719272614
Validation loss: 1.4434603196318432

Epoch: 6| Step: 2
Training loss: 0.10915758460760117
Validation loss: 1.5010509670421641

Epoch: 6| Step: 3
Training loss: 0.1056334376335144
Validation loss: 1.4891755529629287

Epoch: 6| Step: 4
Training loss: 0.0945332795381546
Validation loss: 1.5258272078729445

Epoch: 6| Step: 5
Training loss: 0.08801676332950592
Validation loss: 1.524180535988141

Epoch: 6| Step: 6
Training loss: 0.071654312312603
Validation loss: 1.5502737606725385

Epoch: 6| Step: 7
Training loss: 0.11441962420940399
Validation loss: 1.5444243659255326

Epoch: 6| Step: 8
Training loss: 0.21896669268608093
Validation loss: 1.5214389267788138

Epoch: 6| Step: 9
Training loss: 0.12150286138057709
Validation loss: 1.5064846418237174

Epoch: 6| Step: 10
Training loss: 0.09120538085699081
Validation loss: 1.4880056868317306

Epoch: 6| Step: 11
Training loss: 0.07489816844463348
Validation loss: 1.4848164595583433

Epoch: 6| Step: 12
Training loss: 0.11228716373443604
Validation loss: 1.4670713255482335

Epoch: 6| Step: 13
Training loss: 0.08676066994667053
Validation loss: 1.4639968872070312

Epoch: 465| Step: 0
Training loss: 0.06724146008491516
Validation loss: 1.4611371364644778

Epoch: 6| Step: 1
Training loss: 0.07920543849468231
Validation loss: 1.4348121612302718

Epoch: 6| Step: 2
Training loss: 0.08979196846485138
Validation loss: 1.4329832792282104

Epoch: 6| Step: 3
Training loss: 0.06455445289611816
Validation loss: 1.476623309555874

Epoch: 6| Step: 4
Training loss: 0.07077283412218094
Validation loss: 1.4588236962595293

Epoch: 6| Step: 5
Training loss: 0.0963846743106842
Validation loss: 1.481969392427834

Epoch: 6| Step: 6
Training loss: 0.24603649973869324
Validation loss: 1.4935635648747927

Epoch: 6| Step: 7
Training loss: 0.15918844938278198
Validation loss: 1.5274131656974874

Epoch: 6| Step: 8
Training loss: 0.1170089915394783
Validation loss: 1.5338797107819588

Epoch: 6| Step: 9
Training loss: 0.1823895275592804
Validation loss: 1.5296622053269417

Epoch: 6| Step: 10
Training loss: 0.07757321745157242
Validation loss: 1.512475408533568

Epoch: 6| Step: 11
Training loss: 0.09272312372922897
Validation loss: 1.5033582192595287

Epoch: 6| Step: 12
Training loss: 0.044298574328422546
Validation loss: 1.4864057661384664

Epoch: 6| Step: 13
Training loss: 0.1738450527191162
Validation loss: 1.4751448759468653

Epoch: 466| Step: 0
Training loss: 0.12682990729808807
Validation loss: 1.4590843403211204

Epoch: 6| Step: 1
Training loss: 0.08157460391521454
Validation loss: 1.4658772445494128

Epoch: 6| Step: 2
Training loss: 0.12399367988109589
Validation loss: 1.4637879569043395

Epoch: 6| Step: 3
Training loss: 0.09298977255821228
Validation loss: 1.4826070288176179

Epoch: 6| Step: 4
Training loss: 0.14681872725486755
Validation loss: 1.4782343961859261

Epoch: 6| Step: 5
Training loss: 0.11606746166944504
Validation loss: 1.4709009406387166

Epoch: 6| Step: 6
Training loss: 0.13592632114887238
Validation loss: 1.4727623667768253

Epoch: 6| Step: 7
Training loss: 0.10865551233291626
Validation loss: 1.4615679094868321

Epoch: 6| Step: 8
Training loss: 0.1213223934173584
Validation loss: 1.4834067642047841

Epoch: 6| Step: 9
Training loss: 0.1110178604722023
Validation loss: 1.5203755876069427

Epoch: 6| Step: 10
Training loss: 0.07873290777206421
Validation loss: 1.5292114057848532

Epoch: 6| Step: 11
Training loss: 0.0818261206150055
Validation loss: 1.5658298782123032

Epoch: 6| Step: 12
Training loss: 0.17117005586624146
Validation loss: 1.5513122453484485

Epoch: 6| Step: 13
Training loss: 0.09953561425209045
Validation loss: 1.57289703430668

Epoch: 467| Step: 0
Training loss: 0.10582840442657471
Validation loss: 1.5367059246186288

Epoch: 6| Step: 1
Training loss: 0.15478864312171936
Validation loss: 1.5208280804336711

Epoch: 6| Step: 2
Training loss: 0.12368715554475784
Validation loss: 1.5052573873150734

Epoch: 6| Step: 3
Training loss: 0.08938895910978317
Validation loss: 1.5076797444333312

Epoch: 6| Step: 4
Training loss: 0.10526010394096375
Validation loss: 1.4998560092782462

Epoch: 6| Step: 5
Training loss: 0.06526391208171844
Validation loss: 1.4658116794401599

Epoch: 6| Step: 6
Training loss: 0.11678579449653625
Validation loss: 1.4567420264726043

Epoch: 6| Step: 7
Training loss: 0.11491084843873978
Validation loss: 1.4743044684010167

Epoch: 6| Step: 8
Training loss: 0.06564486771821976
Validation loss: 1.444240640568477

Epoch: 6| Step: 9
Training loss: 0.11408126354217529
Validation loss: 1.4577211603041618

Epoch: 6| Step: 10
Training loss: 0.060016877949237823
Validation loss: 1.4547237683367986

Epoch: 6| Step: 11
Training loss: 0.10290835797786713
Validation loss: 1.4638522401932748

Epoch: 6| Step: 12
Training loss: 0.08207600563764572
Validation loss: 1.4741811739501132

Epoch: 6| Step: 13
Training loss: 0.09215685725212097
Validation loss: 1.4884346992738786

Epoch: 468| Step: 0
Training loss: 0.1301271915435791
Validation loss: 1.474488574971435

Epoch: 6| Step: 1
Training loss: 0.10110437870025635
Validation loss: 1.5084338290717012

Epoch: 6| Step: 2
Training loss: 0.1031651496887207
Validation loss: 1.4827649054988739

Epoch: 6| Step: 3
Training loss: 0.12312769889831543
Validation loss: 1.4697465178787068

Epoch: 6| Step: 4
Training loss: 0.13460972905158997
Validation loss: 1.4881297913930749

Epoch: 6| Step: 5
Training loss: 0.09594853967428207
Validation loss: 1.4730633163964877

Epoch: 6| Step: 6
Training loss: 0.05556637421250343
Validation loss: 1.4717124021181496

Epoch: 6| Step: 7
Training loss: 0.07293397933244705
Validation loss: 1.4575843702080429

Epoch: 6| Step: 8
Training loss: 0.05779954046010971
Validation loss: 1.4513754357573807

Epoch: 6| Step: 9
Training loss: 0.09751614928245544
Validation loss: 1.4511200522863736

Epoch: 6| Step: 10
Training loss: 0.09734548628330231
Validation loss: 1.4340158252305881

Epoch: 6| Step: 11
Training loss: 0.0853230357170105
Validation loss: 1.4361223456680134

Epoch: 6| Step: 12
Training loss: 0.05145280063152313
Validation loss: 1.4320610556551205

Epoch: 6| Step: 13
Training loss: 0.07862314581871033
Validation loss: 1.4612041852807487

Epoch: 469| Step: 0
Training loss: 0.112942174077034
Validation loss: 1.4468872547149658

Epoch: 6| Step: 1
Training loss: 0.08337412774562836
Validation loss: 1.4662293887907458

Epoch: 6| Step: 2
Training loss: 0.07745908200740814
Validation loss: 1.4629054979611469

Epoch: 6| Step: 3
Training loss: 0.0700535848736763
Validation loss: 1.4753843353640648

Epoch: 6| Step: 4
Training loss: 0.1472950279712677
Validation loss: 1.4806212622632262

Epoch: 6| Step: 5
Training loss: 0.09735805541276932
Validation loss: 1.4721258904344292

Epoch: 6| Step: 6
Training loss: 0.07418270409107208
Validation loss: 1.4725481630653463

Epoch: 6| Step: 7
Training loss: 0.050037115812301636
Validation loss: 1.453315047487136

Epoch: 6| Step: 8
Training loss: 0.10568131506443024
Validation loss: 1.448882831040249

Epoch: 6| Step: 9
Training loss: 0.09387629479169846
Validation loss: 1.4367914866375666

Epoch: 6| Step: 10
Training loss: 0.07357367873191833
Validation loss: 1.447533046045611

Epoch: 6| Step: 11
Training loss: 0.1374896913766861
Validation loss: 1.4664338878405991

Epoch: 6| Step: 12
Training loss: 0.07444395124912262
Validation loss: 1.4484802035875217

Epoch: 6| Step: 13
Training loss: 0.14138028025627136
Validation loss: 1.45660263235851

Epoch: 470| Step: 0
Training loss: 0.09275299310684204
Validation loss: 1.4320558873555993

Epoch: 6| Step: 1
Training loss: 0.15343382954597473
Validation loss: 1.4570629340346142

Epoch: 6| Step: 2
Training loss: 0.10025638341903687
Validation loss: 1.448200962876761

Epoch: 6| Step: 3
Training loss: 0.08272261917591095
Validation loss: 1.4639504160932315

Epoch: 6| Step: 4
Training loss: 0.09647528827190399
Validation loss: 1.4925377086926532

Epoch: 6| Step: 5
Training loss: 0.05648278445005417
Validation loss: 1.4976013091302687

Epoch: 6| Step: 6
Training loss: 0.07049954682588577
Validation loss: 1.4871756402395104

Epoch: 6| Step: 7
Training loss: 0.05852966755628586
Validation loss: 1.469135461315032

Epoch: 6| Step: 8
Training loss: 0.055270880460739136
Validation loss: 1.4871334939874628

Epoch: 6| Step: 9
Training loss: 0.05239539593458176
Validation loss: 1.4878185673426556

Epoch: 6| Step: 10
Training loss: 0.08776931464672089
Validation loss: 1.5039165801899408

Epoch: 6| Step: 11
Training loss: 0.0992039144039154
Validation loss: 1.477043979911394

Epoch: 6| Step: 12
Training loss: 0.07755051553249359
Validation loss: 1.4793739536757111

Epoch: 6| Step: 13
Training loss: 0.1076633632183075
Validation loss: 1.4650741802748812

Epoch: 471| Step: 0
Training loss: 0.08627240359783173
Validation loss: 1.49202944642754

Epoch: 6| Step: 1
Training loss: 0.0798121839761734
Validation loss: 1.4887175957361858

Epoch: 6| Step: 2
Training loss: 0.0585361085832119
Validation loss: 1.4908880790074666

Epoch: 6| Step: 3
Training loss: 0.04237920045852661
Validation loss: 1.4913054614938714

Epoch: 6| Step: 4
Training loss: 0.0845782533288002
Validation loss: 1.5140530011987174

Epoch: 6| Step: 5
Training loss: 0.13061735033988953
Validation loss: 1.5203314609425043

Epoch: 6| Step: 6
Training loss: 0.058742377907037735
Validation loss: 1.5088239023762364

Epoch: 6| Step: 7
Training loss: 0.11069512367248535
Validation loss: 1.4877619051164197

Epoch: 6| Step: 8
Training loss: 0.060061950236558914
Validation loss: 1.4957461113570838

Epoch: 6| Step: 9
Training loss: 0.06003110855817795
Validation loss: 1.473745879306588

Epoch: 6| Step: 10
Training loss: 0.042228542268276215
Validation loss: 1.4739995874384397

Epoch: 6| Step: 11
Training loss: 0.03881824016571045
Validation loss: 1.44979654717189

Epoch: 6| Step: 12
Training loss: 0.08194495737552643
Validation loss: 1.4693539116972236

Epoch: 6| Step: 13
Training loss: 0.15426328778266907
Validation loss: 1.4666660056319287

Epoch: 472| Step: 0
Training loss: 0.11436372250318527
Validation loss: 1.4390378023988457

Epoch: 6| Step: 1
Training loss: 0.11945144832134247
Validation loss: 1.42971222887757

Epoch: 6| Step: 2
Training loss: 0.03745759278535843
Validation loss: 1.4453186091556345

Epoch: 6| Step: 3
Training loss: 0.09882671386003494
Validation loss: 1.4560132347127444

Epoch: 6| Step: 4
Training loss: 0.07503806799650192
Validation loss: 1.4707384263315508

Epoch: 6| Step: 5
Training loss: 0.07259686291217804
Validation loss: 1.4541444265714256

Epoch: 6| Step: 6
Training loss: 0.07591445744037628
Validation loss: 1.4549342534875358

Epoch: 6| Step: 7
Training loss: 0.10154663026332855
Validation loss: 1.4443232269697293

Epoch: 6| Step: 8
Training loss: 0.09135923534631729
Validation loss: 1.4501350823269095

Epoch: 6| Step: 9
Training loss: 0.08179884403944016
Validation loss: 1.447253950180546

Epoch: 6| Step: 10
Training loss: 0.06621326506137848
Validation loss: 1.4795006616141206

Epoch: 6| Step: 11
Training loss: 0.10443133115768433
Validation loss: 1.4637640868463824

Epoch: 6| Step: 12
Training loss: 0.05483105778694153
Validation loss: 1.4794803127165763

Epoch: 6| Step: 13
Training loss: 0.06357778608798981
Validation loss: 1.4799527365674254

Epoch: 473| Step: 0
Training loss: 0.05608817934989929
Validation loss: 1.4823692870396439

Epoch: 6| Step: 1
Training loss: 0.11402344703674316
Validation loss: 1.5001487590933358

Epoch: 6| Step: 2
Training loss: 0.048592690378427505
Validation loss: 1.4895833781970444

Epoch: 6| Step: 3
Training loss: 0.04039968550205231
Validation loss: 1.494183753126411

Epoch: 6| Step: 4
Training loss: 0.09989933669567108
Validation loss: 1.4941444832791564

Epoch: 6| Step: 5
Training loss: 0.05337289348244667
Validation loss: 1.5139056738986765

Epoch: 6| Step: 6
Training loss: 0.12646454572677612
Validation loss: 1.500123695660663

Epoch: 6| Step: 7
Training loss: 0.05963115766644478
Validation loss: 1.507328752548464

Epoch: 6| Step: 8
Training loss: 0.07905507832765579
Validation loss: 1.5005387977887226

Epoch: 6| Step: 9
Training loss: 0.10546104609966278
Validation loss: 1.4865816100951164

Epoch: 6| Step: 10
Training loss: 0.09437625855207443
Validation loss: 1.491471670007193

Epoch: 6| Step: 11
Training loss: 0.08419916033744812
Validation loss: 1.4792194520273516

Epoch: 6| Step: 12
Training loss: 0.06587383896112442
Validation loss: 1.4741314764945739

Epoch: 6| Step: 13
Training loss: 0.09212371706962585
Validation loss: 1.4528617333340388

Epoch: 474| Step: 0
Training loss: 0.08761508017778397
Validation loss: 1.45942719264697

Epoch: 6| Step: 1
Training loss: 0.0732608214020729
Validation loss: 1.450482665851552

Epoch: 6| Step: 2
Training loss: 0.07246728241443634
Validation loss: 1.4621606674245609

Epoch: 6| Step: 3
Training loss: 0.08071677386760712
Validation loss: 1.4449957724540465

Epoch: 6| Step: 4
Training loss: 0.06942977756261826
Validation loss: 1.5051025773889275

Epoch: 6| Step: 5
Training loss: 0.07973344624042511
Validation loss: 1.4928758734016008

Epoch: 6| Step: 6
Training loss: 0.10912308096885681
Validation loss: 1.5060783176011936

Epoch: 6| Step: 7
Training loss: 0.10066435486078262
Validation loss: 1.5077844140350178

Epoch: 6| Step: 8
Training loss: 0.12308152765035629
Validation loss: 1.4975455102100168

Epoch: 6| Step: 9
Training loss: 0.05125733092427254
Validation loss: 1.4860514530571558

Epoch: 6| Step: 10
Training loss: 0.06094684079289436
Validation loss: 1.4580217869051042

Epoch: 6| Step: 11
Training loss: 0.13569602370262146
Validation loss: 1.454839604516183

Epoch: 6| Step: 12
Training loss: 0.08275825530290604
Validation loss: 1.4579510432417675

Epoch: 6| Step: 13
Training loss: 0.06006798520684242
Validation loss: 1.4640519824079288

Epoch: 475| Step: 0
Training loss: 0.12013181298971176
Validation loss: 1.4628582654460784

Epoch: 6| Step: 1
Training loss: 0.05684647709131241
Validation loss: 1.4612056504013717

Epoch: 6| Step: 2
Training loss: 0.10532522201538086
Validation loss: 1.4623340547725718

Epoch: 6| Step: 3
Training loss: 0.054074935615062714
Validation loss: 1.4698533550385506

Epoch: 6| Step: 4
Training loss: 0.055977240204811096
Validation loss: 1.4692015968343264

Epoch: 6| Step: 5
Training loss: 0.05862729623913765
Validation loss: 1.488606059423057

Epoch: 6| Step: 6
Training loss: 0.07641755044460297
Validation loss: 1.5091353629225044

Epoch: 6| Step: 7
Training loss: 0.12123450636863708
Validation loss: 1.5144462559812812

Epoch: 6| Step: 8
Training loss: 0.08878914266824722
Validation loss: 1.4955682164879256

Epoch: 6| Step: 9
Training loss: 0.1291450411081314
Validation loss: 1.501176470069475

Epoch: 6| Step: 10
Training loss: 0.09893050789833069
Validation loss: 1.4509916843906525

Epoch: 6| Step: 11
Training loss: 0.09273800253868103
Validation loss: 1.4205715361461844

Epoch: 6| Step: 12
Training loss: 0.05238792300224304
Validation loss: 1.396874375240777

Epoch: 6| Step: 13
Training loss: 0.04539172351360321
Validation loss: 1.3970494770234632

Epoch: 476| Step: 0
Training loss: 0.051604725420475006
Validation loss: 1.4061476043475571

Epoch: 6| Step: 1
Training loss: 0.10095829516649246
Validation loss: 1.3986734331295054

Epoch: 6| Step: 2
Training loss: 0.08855831623077393
Validation loss: 1.395493204875659

Epoch: 6| Step: 3
Training loss: 0.07794457674026489
Validation loss: 1.3652187771694635

Epoch: 6| Step: 4
Training loss: 0.10750304907560349
Validation loss: 1.3875134324514737

Epoch: 6| Step: 5
Training loss: 0.06323006749153137
Validation loss: 1.4009939086052678

Epoch: 6| Step: 6
Training loss: 0.08728570491075516
Validation loss: 1.3842286999507616

Epoch: 6| Step: 7
Training loss: 0.0789918303489685
Validation loss: 1.4019456576275569

Epoch: 6| Step: 8
Training loss: 0.09405463188886642
Validation loss: 1.4315130710601807

Epoch: 6| Step: 9
Training loss: 0.050452329218387604
Validation loss: 1.410511637246737

Epoch: 6| Step: 10
Training loss: 0.12147454172372818
Validation loss: 1.4703333018928446

Epoch: 6| Step: 11
Training loss: 0.12364360690116882
Validation loss: 1.4449952161440285

Epoch: 6| Step: 12
Training loss: 0.13504743576049805
Validation loss: 1.4468545670150428

Epoch: 6| Step: 13
Training loss: 0.06321540474891663
Validation loss: 1.4440524680640108

Epoch: 477| Step: 0
Training loss: 0.06024321913719177
Validation loss: 1.4443019615706576

Epoch: 6| Step: 1
Training loss: 0.09678103029727936
Validation loss: 1.4430840540957708

Epoch: 6| Step: 2
Training loss: 0.0973605290055275
Validation loss: 1.4391462495250087

Epoch: 6| Step: 3
Training loss: 0.048204340040683746
Validation loss: 1.432630761977165

Epoch: 6| Step: 4
Training loss: 0.09114569425582886
Validation loss: 1.413079797580678

Epoch: 6| Step: 5
Training loss: 0.06920497119426727
Validation loss: 1.4279847093807754

Epoch: 6| Step: 6
Training loss: 0.06354083120822906
Validation loss: 1.417045211279264

Epoch: 6| Step: 7
Training loss: 0.05756791681051254
Validation loss: 1.4123194743228216

Epoch: 6| Step: 8
Training loss: 0.07787302136421204
Validation loss: 1.4051823821119083

Epoch: 6| Step: 9
Training loss: 0.08538411557674408
Validation loss: 1.4043723472984888

Epoch: 6| Step: 10
Training loss: 0.056996554136276245
Validation loss: 1.405650205509637

Epoch: 6| Step: 11
Training loss: 0.14843177795410156
Validation loss: 1.4190900120683896

Epoch: 6| Step: 12
Training loss: 0.0769209936261177
Validation loss: 1.4215623755608835

Epoch: 6| Step: 13
Training loss: 0.06302279978990555
Validation loss: 1.4206217655571558

Epoch: 478| Step: 0
Training loss: 0.07433418929576874
Validation loss: 1.4476405702611452

Epoch: 6| Step: 1
Training loss: 0.05573068559169769
Validation loss: 1.4532210198781823

Epoch: 6| Step: 2
Training loss: 0.13311801850795746
Validation loss: 1.426184190857795

Epoch: 6| Step: 3
Training loss: 0.07087426632642746
Validation loss: 1.449243257122655

Epoch: 6| Step: 4
Training loss: 0.0868026465177536
Validation loss: 1.4327373543093282

Epoch: 6| Step: 5
Training loss: 0.07598163187503815
Validation loss: 1.4481379460262995

Epoch: 6| Step: 6
Training loss: 0.1094779446721077
Validation loss: 1.4419109994365322

Epoch: 6| Step: 7
Training loss: 0.09532628953456879
Validation loss: 1.4531425545292516

Epoch: 6| Step: 8
Training loss: 0.06869875639677048
Validation loss: 1.4650595829051027

Epoch: 6| Step: 9
Training loss: 0.06608838587999344
Validation loss: 1.4671919627856183

Epoch: 6| Step: 10
Training loss: 0.06694288551807404
Validation loss: 1.4684247252761677

Epoch: 6| Step: 11
Training loss: 0.085446298122406
Validation loss: 1.4805955784295195

Epoch: 6| Step: 12
Training loss: 0.09338273108005524
Validation loss: 1.4897654960232396

Epoch: 6| Step: 13
Training loss: 0.14526385068893433
Validation loss: 1.4879005750020344

Epoch: 479| Step: 0
Training loss: 0.12108790129423141
Validation loss: 1.4765415287786914

Epoch: 6| Step: 1
Training loss: 0.06351035833358765
Validation loss: 1.478889755023423

Epoch: 6| Step: 2
Training loss: 0.09561827033758163
Validation loss: 1.5236138656575193

Epoch: 6| Step: 3
Training loss: 0.06421675533056259
Validation loss: 1.5036819147807297

Epoch: 6| Step: 4
Training loss: 0.07166432589292526
Validation loss: 1.4764255374990485

Epoch: 6| Step: 5
Training loss: 0.08394702523946762
Validation loss: 1.498295998060575

Epoch: 6| Step: 6
Training loss: 0.08196975290775299
Validation loss: 1.4390583076784689

Epoch: 6| Step: 7
Training loss: 0.06621210277080536
Validation loss: 1.456827643097088

Epoch: 6| Step: 8
Training loss: 0.07505134493112564
Validation loss: 1.4615335041476833

Epoch: 6| Step: 9
Training loss: 0.1030484065413475
Validation loss: 1.477062185605367

Epoch: 6| Step: 10
Training loss: 0.13942262530326843
Validation loss: 1.4783387940417054

Epoch: 6| Step: 11
Training loss: 0.08235695958137512
Validation loss: 1.4930064447464482

Epoch: 6| Step: 12
Training loss: 0.1292887181043625
Validation loss: 1.4838713971517419

Epoch: 6| Step: 13
Training loss: 0.07790768891572952
Validation loss: 1.4643339495505057

Epoch: 480| Step: 0
Training loss: 0.1415092647075653
Validation loss: 1.4705626131385885

Epoch: 6| Step: 1
Training loss: 0.07973220944404602
Validation loss: 1.4624792106689946

Epoch: 6| Step: 2
Training loss: 0.06357230246067047
Validation loss: 1.4667169432486258

Epoch: 6| Step: 3
Training loss: 0.11332324147224426
Validation loss: 1.4717257022857666

Epoch: 6| Step: 4
Training loss: 0.08845343440771103
Validation loss: 1.4475568673943962

Epoch: 6| Step: 5
Training loss: 0.10390225797891617
Validation loss: 1.4592434424226002

Epoch: 6| Step: 6
Training loss: 0.07566516101360321
Validation loss: 1.4302279846642607

Epoch: 6| Step: 7
Training loss: 0.07617036998271942
Validation loss: 1.4454239517129877

Epoch: 6| Step: 8
Training loss: 0.07729518413543701
Validation loss: 1.440156327780857

Epoch: 6| Step: 9
Training loss: 0.037743955850601196
Validation loss: 1.4625100140930505

Epoch: 6| Step: 10
Training loss: 0.08813643455505371
Validation loss: 1.460016458265243

Epoch: 6| Step: 11
Training loss: 0.0689215287566185
Validation loss: 1.4420133547116352

Epoch: 6| Step: 12
Training loss: 0.08399732410907745
Validation loss: 1.452604506605415

Epoch: 6| Step: 13
Training loss: 0.07410314679145813
Validation loss: 1.4893587250863352

Epoch: 481| Step: 0
Training loss: 0.09891670197248459
Validation loss: 1.4791302911696895

Epoch: 6| Step: 1
Training loss: 0.049268193542957306
Validation loss: 1.4911254746939546

Epoch: 6| Step: 2
Training loss: 0.09841879457235336
Validation loss: 1.5234709773012387

Epoch: 6| Step: 3
Training loss: 0.15643952786922455
Validation loss: 1.507139769933557

Epoch: 6| Step: 4
Training loss: 0.11843771487474442
Validation loss: 1.5193748730485157

Epoch: 6| Step: 5
Training loss: 0.07460824400186539
Validation loss: 1.519835364434027

Epoch: 6| Step: 6
Training loss: 0.06665549427270889
Validation loss: 1.5309262185968378

Epoch: 6| Step: 7
Training loss: 0.07980352640151978
Validation loss: 1.5394054599987563

Epoch: 6| Step: 8
Training loss: 0.06393401324748993
Validation loss: 1.5390035516472274

Epoch: 6| Step: 9
Training loss: 0.0668158233165741
Validation loss: 1.5209656915357035

Epoch: 6| Step: 10
Training loss: 0.08288253098726273
Validation loss: 1.4935533295395553

Epoch: 6| Step: 11
Training loss: 0.10922059416770935
Validation loss: 1.4897262652715046

Epoch: 6| Step: 12
Training loss: 0.05058402195572853
Validation loss: 1.4649115121492775

Epoch: 6| Step: 13
Training loss: 0.09730609506368637
Validation loss: 1.4308536437249952

Epoch: 482| Step: 0
Training loss: 0.0604088194668293
Validation loss: 1.4470711023576799

Epoch: 6| Step: 1
Training loss: 0.09644357115030289
Validation loss: 1.4515731328277177

Epoch: 6| Step: 2
Training loss: 0.1200665682554245
Validation loss: 1.4562859483944472

Epoch: 6| Step: 3
Training loss: 0.09681232273578644
Validation loss: 1.4443314184424698

Epoch: 6| Step: 4
Training loss: 0.0712900161743164
Validation loss: 1.4234236004532024

Epoch: 6| Step: 5
Training loss: 0.14177554845809937
Validation loss: 1.4306442724761141

Epoch: 6| Step: 6
Training loss: 0.09139730036258698
Validation loss: 1.4458761035755117

Epoch: 6| Step: 7
Training loss: 0.09034739434719086
Validation loss: 1.4546013839783207

Epoch: 6| Step: 8
Training loss: 0.08204510062932968
Validation loss: 1.4882521437060448

Epoch: 6| Step: 9
Training loss: 0.0565229095518589
Validation loss: 1.4838649124227545

Epoch: 6| Step: 10
Training loss: 0.09748650342226028
Validation loss: 1.491034274460167

Epoch: 6| Step: 11
Training loss: 0.05532511696219444
Validation loss: 1.5114028979373235

Epoch: 6| Step: 12
Training loss: 0.05953274667263031
Validation loss: 1.5011144671388852

Epoch: 6| Step: 13
Training loss: 0.043922848999500275
Validation loss: 1.5068275505496609

Epoch: 483| Step: 0
Training loss: 0.08903572708368301
Validation loss: 1.500770781629829

Epoch: 6| Step: 1
Training loss: 0.11041475832462311
Validation loss: 1.498031013755388

Epoch: 6| Step: 2
Training loss: 0.07209683954715729
Validation loss: 1.4847827560158187

Epoch: 6| Step: 3
Training loss: 0.08935720473527908
Validation loss: 1.4662110613238426

Epoch: 6| Step: 4
Training loss: 0.08194909989833832
Validation loss: 1.4671648702313822

Epoch: 6| Step: 5
Training loss: 0.05995193123817444
Validation loss: 1.4655018942330473

Epoch: 6| Step: 6
Training loss: 0.1015707403421402
Validation loss: 1.4494569737424132

Epoch: 6| Step: 7
Training loss: 0.0682942271232605
Validation loss: 1.4623546126068279

Epoch: 6| Step: 8
Training loss: 0.06664744764566422
Validation loss: 1.4769623010389266

Epoch: 6| Step: 9
Training loss: 0.09033121168613434
Validation loss: 1.4749675925059984

Epoch: 6| Step: 10
Training loss: 0.11095872521400452
Validation loss: 1.4875127987195087

Epoch: 6| Step: 11
Training loss: 0.055281274020671844
Validation loss: 1.5053756595939718

Epoch: 6| Step: 12
Training loss: 0.0927577093243599
Validation loss: 1.509158895861718

Epoch: 6| Step: 13
Training loss: 0.0762825608253479
Validation loss: 1.486082273785786

Epoch: 484| Step: 0
Training loss: 0.07425293326377869
Validation loss: 1.4836627155221918

Epoch: 6| Step: 1
Training loss: 0.08904090523719788
Validation loss: 1.4947167852873444

Epoch: 6| Step: 2
Training loss: 0.07241453230381012
Validation loss: 1.4706148870529667

Epoch: 6| Step: 3
Training loss: 0.06449718773365021
Validation loss: 1.4824633982873732

Epoch: 6| Step: 4
Training loss: 0.1407892107963562
Validation loss: 1.4679886833313973

Epoch: 6| Step: 5
Training loss: 0.062478989362716675
Validation loss: 1.449026761516448

Epoch: 6| Step: 6
Training loss: 0.056079305708408356
Validation loss: 1.4633492744097145

Epoch: 6| Step: 7
Training loss: 0.06436367332935333
Validation loss: 1.4584546730082522

Epoch: 6| Step: 8
Training loss: 0.07924431562423706
Validation loss: 1.4655769409671906

Epoch: 6| Step: 9
Training loss: 0.08010207116603851
Validation loss: 1.470860077488807

Epoch: 6| Step: 10
Training loss: 0.16114813089370728
Validation loss: 1.471017490151108

Epoch: 6| Step: 11
Training loss: 0.05936489254236221
Validation loss: 1.4545355355867775

Epoch: 6| Step: 12
Training loss: 0.05580984055995941
Validation loss: 1.473353740989521

Epoch: 6| Step: 13
Training loss: 0.05522863566875458
Validation loss: 1.490508088501551

Epoch: 485| Step: 0
Training loss: 0.11426082998514175
Validation loss: 1.4802670978730725

Epoch: 6| Step: 1
Training loss: 0.10461580753326416
Validation loss: 1.5030396497377785

Epoch: 6| Step: 2
Training loss: 0.056745246052742004
Validation loss: 1.498860397646504

Epoch: 6| Step: 3
Training loss: 0.04726097360253334
Validation loss: 1.4740623069065872

Epoch: 6| Step: 4
Training loss: 0.07504723966121674
Validation loss: 1.496012089073017

Epoch: 6| Step: 5
Training loss: 0.0840911790728569
Validation loss: 1.5058780793220765

Epoch: 6| Step: 6
Training loss: 0.093428835272789
Validation loss: 1.4974669192426948

Epoch: 6| Step: 7
Training loss: 0.04880116134881973
Validation loss: 1.4985945878490325

Epoch: 6| Step: 8
Training loss: 0.09344041347503662
Validation loss: 1.4853495244056947

Epoch: 6| Step: 9
Training loss: 0.11584748327732086
Validation loss: 1.477973589333155

Epoch: 6| Step: 10
Training loss: 0.08305476605892181
Validation loss: 1.4733842534403647

Epoch: 6| Step: 11
Training loss: 0.07663629204034805
Validation loss: 1.4654174991833266

Epoch: 6| Step: 12
Training loss: 0.07546276599168777
Validation loss: 1.4637692871914114

Epoch: 6| Step: 13
Training loss: 0.12882131338119507
Validation loss: 1.4544580521122101

Epoch: 486| Step: 0
Training loss: 0.10524982959032059
Validation loss: 1.4563582610058528

Epoch: 6| Step: 1
Training loss: 0.1282424032688141
Validation loss: 1.4744298253008115

Epoch: 6| Step: 2
Training loss: 0.09676392376422882
Validation loss: 1.4982218332188104

Epoch: 6| Step: 3
Training loss: 0.06767918169498444
Validation loss: 1.5184584574032856

Epoch: 6| Step: 4
Training loss: 0.06158256530761719
Validation loss: 1.5183639398185156

Epoch: 6| Step: 5
Training loss: 0.08535142242908478
Validation loss: 1.5332771949870612

Epoch: 6| Step: 6
Training loss: 0.15923021733760834
Validation loss: 1.562924111402163

Epoch: 6| Step: 7
Training loss: 0.11294478178024292
Validation loss: 1.5513204105438725

Epoch: 6| Step: 8
Training loss: 0.09974545240402222
Validation loss: 1.5574209177365868

Epoch: 6| Step: 9
Training loss: 0.12981832027435303
Validation loss: 1.5441319609201083

Epoch: 6| Step: 10
Training loss: 0.0809234082698822
Validation loss: 1.5065292722435408

Epoch: 6| Step: 11
Training loss: 0.11896316707134247
Validation loss: 1.4885285054483721

Epoch: 6| Step: 12
Training loss: 0.0879436731338501
Validation loss: 1.4897099784625474

Epoch: 6| Step: 13
Training loss: 0.07584115117788315
Validation loss: 1.456059939117842

Epoch: 487| Step: 0
Training loss: 0.10211524367332458
Validation loss: 1.455203278090364

Epoch: 6| Step: 1
Training loss: 0.10084058344364166
Validation loss: 1.4570008080492738

Epoch: 6| Step: 2
Training loss: 0.08914261311292648
Validation loss: 1.4273386898861136

Epoch: 6| Step: 3
Training loss: 0.12626102566719055
Validation loss: 1.4322037235383065

Epoch: 6| Step: 4
Training loss: 0.17072716355323792
Validation loss: 1.4502279047043092

Epoch: 6| Step: 5
Training loss: 0.1036500409245491
Validation loss: 1.4572280517188452

Epoch: 6| Step: 6
Training loss: 0.07005471736192703
Validation loss: 1.4908924846238987

Epoch: 6| Step: 7
Training loss: 0.08834142982959747
Validation loss: 1.510654721208798

Epoch: 6| Step: 8
Training loss: 0.14698700606822968
Validation loss: 1.5175163245970202

Epoch: 6| Step: 9
Training loss: 0.06679610908031464
Validation loss: 1.507818587364689

Epoch: 6| Step: 10
Training loss: 0.07431594282388687
Validation loss: 1.499898874631492

Epoch: 6| Step: 11
Training loss: 0.10219863057136536
Validation loss: 1.5160504976908367

Epoch: 6| Step: 12
Training loss: 0.09463154524564743
Validation loss: 1.4865347185442526

Epoch: 6| Step: 13
Training loss: 0.06552987545728683
Validation loss: 1.4894179938941874

Epoch: 488| Step: 0
Training loss: 0.0725221335887909
Validation loss: 1.459483983696148

Epoch: 6| Step: 1
Training loss: 0.11878851801156998
Validation loss: 1.4409317175547283

Epoch: 6| Step: 2
Training loss: 0.135176882147789
Validation loss: 1.4403563577641723

Epoch: 6| Step: 3
Training loss: 0.10299898684024811
Validation loss: 1.4053911034778883

Epoch: 6| Step: 4
Training loss: 0.12250722944736481
Validation loss: 1.418657600238759

Epoch: 6| Step: 5
Training loss: 0.09850002825260162
Validation loss: 1.426742220437655

Epoch: 6| Step: 6
Training loss: 0.1326478123664856
Validation loss: 1.4394582779176774

Epoch: 6| Step: 7
Training loss: 0.11337851732969284
Validation loss: 1.4135485041526057

Epoch: 6| Step: 8
Training loss: 0.06454140692949295
Validation loss: 1.437705559115256

Epoch: 6| Step: 9
Training loss: 0.10038504004478455
Validation loss: 1.4275964357519662

Epoch: 6| Step: 10
Training loss: 0.0688028484582901
Validation loss: 1.4473471423631072

Epoch: 6| Step: 11
Training loss: 0.10457976907491684
Validation loss: 1.4402447041644846

Epoch: 6| Step: 12
Training loss: 0.05579140782356262
Validation loss: 1.462933583926129

Epoch: 6| Step: 13
Training loss: 0.1295211911201477
Validation loss: 1.475789386739013

Epoch: 489| Step: 0
Training loss: 0.07101213186979294
Validation loss: 1.498923845188592

Epoch: 6| Step: 1
Training loss: 0.07250449806451797
Validation loss: 1.4938262021669777

Epoch: 6| Step: 2
Training loss: 0.11816392093896866
Validation loss: 1.48424102926767

Epoch: 6| Step: 3
Training loss: 0.12181702256202698
Validation loss: 1.478857260878368

Epoch: 6| Step: 4
Training loss: 0.056950509548187256
Validation loss: 1.4680495364691621

Epoch: 6| Step: 5
Training loss: 0.07685157656669617
Validation loss: 1.4696644685601676

Epoch: 6| Step: 6
Training loss: 0.06232976168394089
Validation loss: 1.4386363747299358

Epoch: 6| Step: 7
Training loss: 0.06564611196517944
Validation loss: 1.4686867562673425

Epoch: 6| Step: 8
Training loss: 0.0818108320236206
Validation loss: 1.4250878018717612

Epoch: 6| Step: 9
Training loss: 0.1084141656756401
Validation loss: 1.4330412854430497

Epoch: 6| Step: 10
Training loss: 0.07252390682697296
Validation loss: 1.4491724070682321

Epoch: 6| Step: 11
Training loss: 0.06805726140737534
Validation loss: 1.4608593820243754

Epoch: 6| Step: 12
Training loss: 0.10628342628479004
Validation loss: 1.4541435683927229

Epoch: 6| Step: 13
Training loss: 0.11326953768730164
Validation loss: 1.4787443773720854

Epoch: 490| Step: 0
Training loss: 0.12437723577022552
Validation loss: 1.4598419871381534

Epoch: 6| Step: 1
Training loss: 0.06761854887008667
Validation loss: 1.4577020778450915

Epoch: 6| Step: 2
Training loss: 0.06114421412348747
Validation loss: 1.4601752129934167

Epoch: 6| Step: 3
Training loss: 0.10335148870944977
Validation loss: 1.4660563789388186

Epoch: 6| Step: 4
Training loss: 0.09688979387283325
Validation loss: 1.4572850170955862

Epoch: 6| Step: 5
Training loss: 0.05709800124168396
Validation loss: 1.4517818497073265

Epoch: 6| Step: 6
Training loss: 0.14749617874622345
Validation loss: 1.4498843313545309

Epoch: 6| Step: 7
Training loss: 0.07660682499408722
Validation loss: 1.4580358061739194

Epoch: 6| Step: 8
Training loss: 0.08764628320932388
Validation loss: 1.4218395570273041

Epoch: 6| Step: 9
Training loss: 0.09255395829677582
Validation loss: 1.449140873006595

Epoch: 6| Step: 10
Training loss: 0.05797827988862991
Validation loss: 1.4240420095382198

Epoch: 6| Step: 11
Training loss: 0.07674068957567215
Validation loss: 1.425381040060392

Epoch: 6| Step: 12
Training loss: 0.04608060419559479
Validation loss: 1.4269555448203959

Epoch: 6| Step: 13
Training loss: 0.09871745854616165
Validation loss: 1.470803883126987

Epoch: 491| Step: 0
Training loss: 0.07818791270256042
Validation loss: 1.454336177918219

Epoch: 6| Step: 1
Training loss: 0.08085980266332626
Validation loss: 1.4657782508480934

Epoch: 6| Step: 2
Training loss: 0.06052784621715546
Validation loss: 1.4627676484405354

Epoch: 6| Step: 3
Training loss: 0.10314483195543289
Validation loss: 1.455300259333785

Epoch: 6| Step: 4
Training loss: 0.041074976325035095
Validation loss: 1.4579052162426773

Epoch: 6| Step: 5
Training loss: 0.11159412562847137
Validation loss: 1.4894615501485846

Epoch: 6| Step: 6
Training loss: 0.05670606344938278
Validation loss: 1.4654933137278403

Epoch: 6| Step: 7
Training loss: 0.0539727658033371
Validation loss: 1.488061883116281

Epoch: 6| Step: 8
Training loss: 0.154500350356102
Validation loss: 1.4741060003157584

Epoch: 6| Step: 9
Training loss: 0.1131402850151062
Validation loss: 1.4679216313105758

Epoch: 6| Step: 10
Training loss: 0.07251100242137909
Validation loss: 1.4714749250360715

Epoch: 6| Step: 11
Training loss: 0.059416092932224274
Validation loss: 1.492600271778722

Epoch: 6| Step: 12
Training loss: 0.11383859813213348
Validation loss: 1.477515511615302

Epoch: 6| Step: 13
Training loss: 0.03934081271290779
Validation loss: 1.473023203111464

Epoch: 492| Step: 0
Training loss: 0.04539208859205246
Validation loss: 1.4775291489016624

Epoch: 6| Step: 1
Training loss: 0.07349777221679688
Validation loss: 1.4842186538122033

Epoch: 6| Step: 2
Training loss: 0.06534499675035477
Validation loss: 1.4852787217786234

Epoch: 6| Step: 3
Training loss: 0.05523819103837013
Validation loss: 1.482044868571784

Epoch: 6| Step: 4
Training loss: 0.10202204436063766
Validation loss: 1.4709535119354085

Epoch: 6| Step: 5
Training loss: 0.0865778997540474
Validation loss: 1.4882407483234201

Epoch: 6| Step: 6
Training loss: 0.07073009759187698
Validation loss: 1.4529175719907206

Epoch: 6| Step: 7
Training loss: 0.07526594400405884
Validation loss: 1.4953038923202022

Epoch: 6| Step: 8
Training loss: 0.07662533223628998
Validation loss: 1.4832720461712088

Epoch: 6| Step: 9
Training loss: 0.10866620391607285
Validation loss: 1.4822042642101165

Epoch: 6| Step: 10
Training loss: 0.07033620029687881
Validation loss: 1.4805211533782303

Epoch: 6| Step: 11
Training loss: 0.05153682827949524
Validation loss: 1.4539978888727003

Epoch: 6| Step: 12
Training loss: 0.14329519867897034
Validation loss: 1.4715206584622782

Epoch: 6| Step: 13
Training loss: 0.03619460389018059
Validation loss: 1.4653612798260105

Epoch: 493| Step: 0
Training loss: 0.06581126153469086
Validation loss: 1.4419930135050127

Epoch: 6| Step: 1
Training loss: 0.08851282298564911
Validation loss: 1.4503586035902782

Epoch: 6| Step: 2
Training loss: 0.05536564439535141
Validation loss: 1.4466714794917772

Epoch: 6| Step: 3
Training loss: 0.06429974734783173
Validation loss: 1.4148412378885413

Epoch: 6| Step: 4
Training loss: 0.104678675532341
Validation loss: 1.440093332721341

Epoch: 6| Step: 5
Training loss: 0.10375034809112549
Validation loss: 1.4474097349310433

Epoch: 6| Step: 6
Training loss: 0.07340157777070999
Validation loss: 1.4317300063307568

Epoch: 6| Step: 7
Training loss: 0.13929608464241028
Validation loss: 1.4425860361386371

Epoch: 6| Step: 8
Training loss: 0.03256348893046379
Validation loss: 1.450727233322718

Epoch: 6| Step: 9
Training loss: 0.05565141141414642
Validation loss: 1.4495917071578324

Epoch: 6| Step: 10
Training loss: 0.06993202120065689
Validation loss: 1.4303125553233649

Epoch: 6| Step: 11
Training loss: 0.08239218592643738
Validation loss: 1.4188463405896259

Epoch: 6| Step: 12
Training loss: 0.04775455594062805
Validation loss: 1.4333291476772678

Epoch: 6| Step: 13
Training loss: 0.0657292902469635
Validation loss: 1.414487333707912

Epoch: 494| Step: 0
Training loss: 0.0642039105296135
Validation loss: 1.4300742835126898

Epoch: 6| Step: 1
Training loss: 0.06291338801383972
Validation loss: 1.4324492972384217

Epoch: 6| Step: 2
Training loss: 0.0648893266916275
Validation loss: 1.459006695337193

Epoch: 6| Step: 3
Training loss: 0.08011198043823242
Validation loss: 1.4534050347984477

Epoch: 6| Step: 4
Training loss: 0.08396470546722412
Validation loss: 1.4759734343456965

Epoch: 6| Step: 5
Training loss: 0.06425502151250839
Validation loss: 1.469721758237449

Epoch: 6| Step: 6
Training loss: 0.11024385690689087
Validation loss: 1.4605582029588762

Epoch: 6| Step: 7
Training loss: 0.05775102227926254
Validation loss: 1.459455506775969

Epoch: 6| Step: 8
Training loss: 0.1386432945728302
Validation loss: 1.4945916219424176

Epoch: 6| Step: 9
Training loss: 0.09644269198179245
Validation loss: 1.4493898012304818

Epoch: 6| Step: 10
Training loss: 0.11555249989032745
Validation loss: 1.4441046227690995

Epoch: 6| Step: 11
Training loss: 0.06751232594251633
Validation loss: 1.4400274266478836

Epoch: 6| Step: 12
Training loss: 0.088139608502388
Validation loss: 1.4413055771140642

Epoch: 6| Step: 13
Training loss: 0.1272445172071457
Validation loss: 1.455146587023171

Epoch: 495| Step: 0
Training loss: 0.06744547188282013
Validation loss: 1.4510360597282328

Epoch: 6| Step: 1
Training loss: 0.0867300033569336
Validation loss: 1.438932227832015

Epoch: 6| Step: 2
Training loss: 0.08334828913211823
Validation loss: 1.4434051270126014

Epoch: 6| Step: 3
Training loss: 0.05153682455420494
Validation loss: 1.4723677417283416

Epoch: 6| Step: 4
Training loss: 0.06223076581954956
Validation loss: 1.470796960656361

Epoch: 6| Step: 5
Training loss: 0.07968953251838684
Validation loss: 1.4578201296508952

Epoch: 6| Step: 6
Training loss: 0.0763215646147728
Validation loss: 1.4333930143745996

Epoch: 6| Step: 7
Training loss: 0.07655713707208633
Validation loss: 1.428682170888429

Epoch: 6| Step: 8
Training loss: 0.0994797796010971
Validation loss: 1.432584274199701

Epoch: 6| Step: 9
Training loss: 0.0629969984292984
Validation loss: 1.42127045764718

Epoch: 6| Step: 10
Training loss: 0.10171801596879959
Validation loss: 1.4393890339841124

Epoch: 6| Step: 11
Training loss: 0.09948492050170898
Validation loss: 1.444825674897881

Epoch: 6| Step: 12
Training loss: 0.08993677794933319
Validation loss: 1.4198601361243957

Epoch: 6| Step: 13
Training loss: 0.059280913323163986
Validation loss: 1.4178398482261165

Epoch: 496| Step: 0
Training loss: 0.06463342905044556
Validation loss: 1.4457192465823183

Epoch: 6| Step: 1
Training loss: 0.034289658069610596
Validation loss: 1.4483357981968952

Epoch: 6| Step: 2
Training loss: 0.06363585591316223
Validation loss: 1.432244445687981

Epoch: 6| Step: 3
Training loss: 0.043078504502773285
Validation loss: 1.4303054860843125

Epoch: 6| Step: 4
Training loss: 0.14342643320560455
Validation loss: 1.4354408415414954

Epoch: 6| Step: 5
Training loss: 0.12296076118946075
Validation loss: 1.3962230631100234

Epoch: 6| Step: 6
Training loss: 0.06817960739135742
Validation loss: 1.3902025556051603

Epoch: 6| Step: 7
Training loss: 0.05619416385889053
Validation loss: 1.404302249031682

Epoch: 6| Step: 8
Training loss: 0.07263229787349701
Validation loss: 1.390674647464547

Epoch: 6| Step: 9
Training loss: 0.057979412376880646
Validation loss: 1.4107837651365547

Epoch: 6| Step: 10
Training loss: 0.14461755752563477
Validation loss: 1.3940222173608758

Epoch: 6| Step: 11
Training loss: 0.1571907103061676
Validation loss: 1.4085375499981705

Epoch: 6| Step: 12
Training loss: 0.07259944826364517
Validation loss: 1.4320172212457145

Epoch: 6| Step: 13
Training loss: 0.07251209765672684
Validation loss: 1.4393499346189602

Epoch: 497| Step: 0
Training loss: 0.10851531475782394
Validation loss: 1.4678557560008059

Epoch: 6| Step: 1
Training loss: 0.06541986763477325
Validation loss: 1.4613834901522564

Epoch: 6| Step: 2
Training loss: 0.11279083788394928
Validation loss: 1.4570831816683534

Epoch: 6| Step: 3
Training loss: 0.06361646205186844
Validation loss: 1.4458380181302306

Epoch: 6| Step: 4
Training loss: 0.059315942227840424
Validation loss: 1.4700804923170356

Epoch: 6| Step: 5
Training loss: 0.09257430583238602
Validation loss: 1.4585340343495852

Epoch: 6| Step: 6
Training loss: 0.05493462085723877
Validation loss: 1.4825695650551909

Epoch: 6| Step: 7
Training loss: 0.11764292418956757
Validation loss: 1.4583668042254705

Epoch: 6| Step: 8
Training loss: 0.08055546134710312
Validation loss: 1.4471101517318397

Epoch: 6| Step: 9
Training loss: 0.05800182372331619
Validation loss: 1.4173855589282127

Epoch: 6| Step: 10
Training loss: 0.07575779408216476
Validation loss: 1.442422551493491

Epoch: 6| Step: 11
Training loss: 0.04800616204738617
Validation loss: 1.4178615475213656

Epoch: 6| Step: 12
Training loss: 0.07129774987697601
Validation loss: 1.4176248811906385

Epoch: 6| Step: 13
Training loss: 0.06550567597150803
Validation loss: 1.4247219882985598

Epoch: 498| Step: 0
Training loss: 0.143067866563797
Validation loss: 1.4271290167685478

Epoch: 6| Step: 1
Training loss: 0.05256771668791771
Validation loss: 1.4055316922485188

Epoch: 6| Step: 2
Training loss: 0.07535183429718018
Validation loss: 1.3970484977127404

Epoch: 6| Step: 3
Training loss: 0.06224341690540314
Validation loss: 1.4218511260965818

Epoch: 6| Step: 4
Training loss: 0.05722912400960922
Validation loss: 1.425270245280317

Epoch: 6| Step: 5
Training loss: 0.10493091493844986
Validation loss: 1.4254014331807372

Epoch: 6| Step: 6
Training loss: 0.039064064621925354
Validation loss: 1.4433098095719532

Epoch: 6| Step: 7
Training loss: 0.06459338963031769
Validation loss: 1.4577297869549002

Epoch: 6| Step: 8
Training loss: 0.0726081132888794
Validation loss: 1.4680925248771586

Epoch: 6| Step: 9
Training loss: 0.031621284782886505
Validation loss: 1.4583599375140281

Epoch: 6| Step: 10
Training loss: 0.07871454954147339
Validation loss: 1.4808995146905222

Epoch: 6| Step: 11
Training loss: 0.05043024942278862
Validation loss: 1.462151937587287

Epoch: 6| Step: 12
Training loss: 0.06837096810340881
Validation loss: 1.496908922349253

Epoch: 6| Step: 13
Training loss: 0.0739574059844017
Validation loss: 1.5023002022056169

Epoch: 499| Step: 0
Training loss: 0.12725228071212769
Validation loss: 1.5079837140216623

Epoch: 6| Step: 1
Training loss: 0.05150385573506355
Validation loss: 1.506927341543218

Epoch: 6| Step: 2
Training loss: 0.043049342930316925
Validation loss: 1.4826129815911735

Epoch: 6| Step: 3
Training loss: 0.0790116935968399
Validation loss: 1.4805897999835271

Epoch: 6| Step: 4
Training loss: 0.05634662136435509
Validation loss: 1.4944687863831878

Epoch: 6| Step: 5
Training loss: 0.04190221056342125
Validation loss: 1.4710754886750252

Epoch: 6| Step: 6
Training loss: 0.05085238814353943
Validation loss: 1.4833011896379533

Epoch: 6| Step: 7
Training loss: 0.04614926129579544
Validation loss: 1.485417543559946

Epoch: 6| Step: 8
Training loss: 0.08403948694467545
Validation loss: 1.4642005197463497

Epoch: 6| Step: 9
Training loss: 0.08490543812513351
Validation loss: 1.4731852764724402

Epoch: 6| Step: 10
Training loss: 0.049995213747024536
Validation loss: 1.4370174074685702

Epoch: 6| Step: 11
Training loss: 0.06659219413995743
Validation loss: 1.4361175119235952

Epoch: 6| Step: 12
Training loss: 0.15198896825313568
Validation loss: 1.4339229701667704

Epoch: 6| Step: 13
Training loss: 0.08531740307807922
Validation loss: 1.4109695675552532

Epoch: 500| Step: 0
Training loss: 0.048709675669670105
Validation loss: 1.421435906041053

Epoch: 6| Step: 1
Training loss: 0.0778556764125824
Validation loss: 1.423616204210507

Epoch: 6| Step: 2
Training loss: 0.040831081569194794
Validation loss: 1.4288389170041649

Epoch: 6| Step: 3
Training loss: 0.06972161680459976
Validation loss: 1.4285534902285504

Epoch: 6| Step: 4
Training loss: 0.06892534345388412
Validation loss: 1.4422766553458346

Epoch: 6| Step: 5
Training loss: 0.10737372934818268
Validation loss: 1.4470629486986386

Epoch: 6| Step: 6
Training loss: 0.06265392154455185
Validation loss: 1.4749081583433254

Epoch: 6| Step: 7
Training loss: 0.04281069338321686
Validation loss: 1.4646421619640884

Epoch: 6| Step: 8
Training loss: 0.07686735689640045
Validation loss: 1.4463516883952643

Epoch: 6| Step: 9
Training loss: 0.11425352096557617
Validation loss: 1.4258001568496868

Epoch: 6| Step: 10
Training loss: 0.14067590236663818
Validation loss: 1.409677049165131

Epoch: 6| Step: 11
Training loss: 0.09225787222385406
Validation loss: 1.4108661579829391

Epoch: 6| Step: 12
Training loss: 0.15270188450813293
Validation loss: 1.4062638564776349

Epoch: 6| Step: 13
Training loss: 0.11419069766998291
Validation loss: 1.4033875106483378

Epoch: 501| Step: 0
Training loss: 0.04108419269323349
Validation loss: 1.4123206779520998

Epoch: 6| Step: 1
Training loss: 0.07124283909797668
Validation loss: 1.437145879191737

Epoch: 6| Step: 2
Training loss: 0.053954675793647766
Validation loss: 1.4226026701670822

Epoch: 6| Step: 3
Training loss: 0.05944688990712166
Validation loss: 1.4448071525942894

Epoch: 6| Step: 4
Training loss: 0.11889037489891052
Validation loss: 1.4265033442486998

Epoch: 6| Step: 5
Training loss: 0.13219964504241943
Validation loss: 1.4504043402210358

Epoch: 6| Step: 6
Training loss: 0.0999981164932251
Validation loss: 1.4630435782094156

Epoch: 6| Step: 7
Training loss: 0.044364169239997864
Validation loss: 1.4545878338557419

Epoch: 6| Step: 8
Training loss: 0.08406781405210495
Validation loss: 1.4752318718100106

Epoch: 6| Step: 9
Training loss: 0.11792007088661194
Validation loss: 1.487895820730476

Epoch: 6| Step: 10
Training loss: 0.08935961127281189
Validation loss: 1.501682622458345

Epoch: 6| Step: 11
Training loss: 0.1201876774430275
Validation loss: 1.4966292304377402

Epoch: 6| Step: 12
Training loss: 0.06768552958965302
Validation loss: 1.4961150551355014

Epoch: 6| Step: 13
Training loss: 0.07556802779436111
Validation loss: 1.48270103111062

Epoch: 502| Step: 0
Training loss: 0.05853345990180969
Validation loss: 1.4779731227505593

Epoch: 6| Step: 1
Training loss: 0.06980767101049423
Validation loss: 1.4359789676563715

Epoch: 6| Step: 2
Training loss: 0.07655254751443863
Validation loss: 1.4367501171686317

Epoch: 6| Step: 3
Training loss: 0.08300561457872391
Validation loss: 1.4452812479388328

Epoch: 6| Step: 4
Training loss: 0.09492826461791992
Validation loss: 1.4130082220159552

Epoch: 6| Step: 5
Training loss: 0.03631485998630524
Validation loss: 1.4079045711025115

Epoch: 6| Step: 6
Training loss: 0.13150851428508759
Validation loss: 1.4175922293816843

Epoch: 6| Step: 7
Training loss: 0.045831549912691116
Validation loss: 1.4166019084633037

Epoch: 6| Step: 8
Training loss: 0.08645860850811005
Validation loss: 1.4139847422158847

Epoch: 6| Step: 9
Training loss: 0.08342915773391724
Validation loss: 1.3915300023171209

Epoch: 6| Step: 10
Training loss: 0.07752887904644012
Validation loss: 1.3843626130011775

Epoch: 6| Step: 11
Training loss: 0.06776074320077896
Validation loss: 1.4192138423201859

Epoch: 6| Step: 12
Training loss: 0.10371649265289307
Validation loss: 1.4028923524323331

Epoch: 6| Step: 13
Training loss: 0.062318604439496994
Validation loss: 1.4295428337589386

Epoch: 503| Step: 0
Training loss: 0.0618341863155365
Validation loss: 1.460862095637988

Epoch: 6| Step: 1
Training loss: 0.09643271565437317
Validation loss: 1.5037452059407388

Epoch: 6| Step: 2
Training loss: 0.16431568562984467
Validation loss: 1.5018656843452043

Epoch: 6| Step: 3
Training loss: 0.07878437638282776
Validation loss: 1.5067649118361934

Epoch: 6| Step: 4
Training loss: 0.08078688383102417
Validation loss: 1.5100360249960294

Epoch: 6| Step: 5
Training loss: 0.058723583817481995
Validation loss: 1.4749697075095227

Epoch: 6| Step: 6
Training loss: 0.03665389120578766
Validation loss: 1.4741030944290983

Epoch: 6| Step: 7
Training loss: 0.08969259262084961
Validation loss: 1.4677059086420203

Epoch: 6| Step: 8
Training loss: 0.0505053773522377
Validation loss: 1.4723956777203469

Epoch: 6| Step: 9
Training loss: 0.059019386768341064
Validation loss: 1.4748814644352082

Epoch: 6| Step: 10
Training loss: 0.06702212989330292
Validation loss: 1.460027370401608

Epoch: 6| Step: 11
Training loss: 0.10423433035612106
Validation loss: 1.4684247445034724

Epoch: 6| Step: 12
Training loss: 0.0940835177898407
Validation loss: 1.489040317073945

Epoch: 6| Step: 13
Training loss: 0.06262677162885666
Validation loss: 1.4623442157622306

Epoch: 504| Step: 0
Training loss: 0.04936400055885315
Validation loss: 1.5000883879200104

Epoch: 6| Step: 1
Training loss: 0.047252751886844635
Validation loss: 1.500595643956174

Epoch: 6| Step: 2
Training loss: 0.1498076617717743
Validation loss: 1.491197935996517

Epoch: 6| Step: 3
Training loss: 0.12699882686138153
Validation loss: 1.475217257776568

Epoch: 6| Step: 4
Training loss: 0.05046825855970383
Validation loss: 1.477371613184611

Epoch: 6| Step: 5
Training loss: 0.0826449990272522
Validation loss: 1.4678120279824862

Epoch: 6| Step: 6
Training loss: 0.07891713827848434
Validation loss: 1.4664062159035796

Epoch: 6| Step: 7
Training loss: 0.0649518147110939
Validation loss: 1.4516176869792323

Epoch: 6| Step: 8
Training loss: 0.06477600336074829
Validation loss: 1.4454413844693093

Epoch: 6| Step: 9
Training loss: 0.07684304565191269
Validation loss: 1.418500187576458

Epoch: 6| Step: 10
Training loss: 0.05874372273683548
Validation loss: 1.4191533993649226

Epoch: 6| Step: 11
Training loss: 0.06809460371732712
Validation loss: 1.4305202191875828

Epoch: 6| Step: 12
Training loss: 0.1346590518951416
Validation loss: 1.4257839123408

Epoch: 6| Step: 13
Training loss: 0.10123300552368164
Validation loss: 1.4334153289436011

Epoch: 505| Step: 0
Training loss: 0.08831387013196945
Validation loss: 1.4560923755809825

Epoch: 6| Step: 1
Training loss: 0.0469358004629612
Validation loss: 1.4474173002345587

Epoch: 6| Step: 2
Training loss: 0.03568616509437561
Validation loss: 1.4542714536830943

Epoch: 6| Step: 3
Training loss: 0.08390502631664276
Validation loss: 1.457832988872323

Epoch: 6| Step: 4
Training loss: 0.1083144098520279
Validation loss: 1.4717268789968183

Epoch: 6| Step: 5
Training loss: 0.08049163222312927
Validation loss: 1.467390916680777

Epoch: 6| Step: 6
Training loss: 0.04775625467300415
Validation loss: 1.475171782637155

Epoch: 6| Step: 7
Training loss: 0.11113536357879639
Validation loss: 1.4592707451953684

Epoch: 6| Step: 8
Training loss: 0.04436977580189705
Validation loss: 1.4741436339193774

Epoch: 6| Step: 9
Training loss: 0.09426321089267731
Validation loss: 1.5023298519913868

Epoch: 6| Step: 10
Training loss: 0.06299006938934326
Validation loss: 1.4827162091450026

Epoch: 6| Step: 11
Training loss: 0.08686283230781555
Validation loss: 1.4805301017658685

Epoch: 6| Step: 12
Training loss: 0.05860438197851181
Validation loss: 1.489792287349701

Epoch: 6| Step: 13
Training loss: 0.06215095520019531
Validation loss: 1.4547908331758233

Epoch: 506| Step: 0
Training loss: 0.06366191804409027
Validation loss: 1.4608921709881033

Epoch: 6| Step: 1
Training loss: 0.05329713225364685
Validation loss: 1.4952204842721262

Epoch: 6| Step: 2
Training loss: 0.04132932052016258
Validation loss: 1.4544261988773142

Epoch: 6| Step: 3
Training loss: 0.04892545938491821
Validation loss: 1.468953271065989

Epoch: 6| Step: 4
Training loss: 0.04966375231742859
Validation loss: 1.470876855234946

Epoch: 6| Step: 5
Training loss: 0.04985474795103073
Validation loss: 1.4731230646051385

Epoch: 6| Step: 6
Training loss: 0.12488481402397156
Validation loss: 1.4712479563169583

Epoch: 6| Step: 7
Training loss: 0.09359103441238403
Validation loss: 1.4831425848827566

Epoch: 6| Step: 8
Training loss: 0.10710403323173523
Validation loss: 1.4745340398562852

Epoch: 6| Step: 9
Training loss: 0.10055141896009445
Validation loss: 1.5065997492882512

Epoch: 6| Step: 10
Training loss: 0.12343454360961914
Validation loss: 1.4895065907509095

Epoch: 6| Step: 11
Training loss: 0.08092311024665833
Validation loss: 1.4907679250163417

Epoch: 6| Step: 12
Training loss: 0.10224070399999619
Validation loss: 1.455637308859056

Epoch: 6| Step: 13
Training loss: 0.06529458612203598
Validation loss: 1.4378458530672136

Epoch: 507| Step: 0
Training loss: 0.0666503980755806
Validation loss: 1.4594777707130677

Epoch: 6| Step: 1
Training loss: 0.10580267012119293
Validation loss: 1.4602969481099037

Epoch: 6| Step: 2
Training loss: 0.055884651839733124
Validation loss: 1.4448034083971413

Epoch: 6| Step: 3
Training loss: 0.042353227734565735
Validation loss: 1.42922943381853

Epoch: 6| Step: 4
Training loss: 0.0583360493183136
Validation loss: 1.431144296482045

Epoch: 6| Step: 5
Training loss: 0.110051229596138
Validation loss: 1.4418558523219118

Epoch: 6| Step: 6
Training loss: 0.08744529634714127
Validation loss: 1.4314891651112547

Epoch: 6| Step: 7
Training loss: 0.0834033265709877
Validation loss: 1.433745841826162

Epoch: 6| Step: 8
Training loss: 0.07406485825777054
Validation loss: 1.4646873813803478

Epoch: 6| Step: 9
Training loss: 0.05295291543006897
Validation loss: 1.4767146879626858

Epoch: 6| Step: 10
Training loss: 0.05773590877652168
Validation loss: 1.500410718302573

Epoch: 6| Step: 11
Training loss: 0.08869469165802002
Validation loss: 1.4652414257808397

Epoch: 6| Step: 12
Training loss: 0.05158358812332153
Validation loss: 1.4863195137311054

Epoch: 6| Step: 13
Training loss: 0.07027048617601395
Validation loss: 1.456973091248543

Epoch: 508| Step: 0
Training loss: 0.06443431973457336
Validation loss: 1.4777461636450984

Epoch: 6| Step: 1
Training loss: 0.07592864334583282
Validation loss: 1.487594836501665

Epoch: 6| Step: 2
Training loss: 0.06557215750217438
Validation loss: 1.4645704902628416

Epoch: 6| Step: 3
Training loss: 0.06195022910833359
Validation loss: 1.4501155871216969

Epoch: 6| Step: 4
Training loss: 0.1288280040025711
Validation loss: 1.4386661411613546

Epoch: 6| Step: 5
Training loss: 0.08388322591781616
Validation loss: 1.4572483211435296

Epoch: 6| Step: 6
Training loss: 0.0952383279800415
Validation loss: 1.4326866365248156

Epoch: 6| Step: 7
Training loss: 0.05209578573703766
Validation loss: 1.4365180705183296

Epoch: 6| Step: 8
Training loss: 0.0561830960214138
Validation loss: 1.4461046367563226

Epoch: 6| Step: 9
Training loss: 0.10682427138090134
Validation loss: 1.4625459204437912

Epoch: 6| Step: 10
Training loss: 0.08154930174350739
Validation loss: 1.472820576801095

Epoch: 6| Step: 11
Training loss: 0.06792216002941132
Validation loss: 1.4606288761220954

Epoch: 6| Step: 12
Training loss: 0.08791311085224152
Validation loss: 1.5076924735499966

Epoch: 6| Step: 13
Training loss: 0.11626594513654709
Validation loss: 1.4959633119644657

Epoch: 509| Step: 0
Training loss: 0.05491583049297333
Validation loss: 1.4915721467746201

Epoch: 6| Step: 1
Training loss: 0.11366717517375946
Validation loss: 1.4782705230097617

Epoch: 6| Step: 2
Training loss: 0.10471595823764801
Validation loss: 1.4676030297433176

Epoch: 6| Step: 3
Training loss: 0.05666054040193558
Validation loss: 1.4401818856757174

Epoch: 6| Step: 4
Training loss: 0.05671009048819542
Validation loss: 1.4310735964005994

Epoch: 6| Step: 5
Training loss: 0.08383622765541077
Validation loss: 1.4192320903142293

Epoch: 6| Step: 6
Training loss: 0.08659282326698303
Validation loss: 1.404351447218208

Epoch: 6| Step: 7
Training loss: 0.12188564240932465
Validation loss: 1.435058662968297

Epoch: 6| Step: 8
Training loss: 0.10056442022323608
Validation loss: 1.436414772464383

Epoch: 6| Step: 9
Training loss: 0.17325197160243988
Validation loss: 1.4534991107961184

Epoch: 6| Step: 10
Training loss: 0.06589504331350327
Validation loss: 1.4483115788429015

Epoch: 6| Step: 11
Training loss: 0.08455638587474823
Validation loss: 1.435084475624946

Epoch: 6| Step: 12
Training loss: 0.08522991836071014
Validation loss: 1.4668847591646257

Epoch: 6| Step: 13
Training loss: 0.057062454521656036
Validation loss: 1.4613373689754035

Epoch: 510| Step: 0
Training loss: 0.05040117725729942
Validation loss: 1.477366880703998

Epoch: 6| Step: 1
Training loss: 0.08760891109704971
Validation loss: 1.477617835485807

Epoch: 6| Step: 2
Training loss: 0.09003448486328125
Validation loss: 1.4768067059978363

Epoch: 6| Step: 3
Training loss: 0.12698034942150116
Validation loss: 1.4999086715841805

Epoch: 6| Step: 4
Training loss: 0.08683332800865173
Validation loss: 1.4996236306364819

Epoch: 6| Step: 5
Training loss: 0.06338516622781754
Validation loss: 1.490382391919372

Epoch: 6| Step: 6
Training loss: 0.039994582533836365
Validation loss: 1.5026505031893331

Epoch: 6| Step: 7
Training loss: 0.09040218591690063
Validation loss: 1.5029397908077444

Epoch: 6| Step: 8
Training loss: 0.08948002755641937
Validation loss: 1.5010492288938133

Epoch: 6| Step: 9
Training loss: 0.11773154139518738
Validation loss: 1.4963472030496086

Epoch: 6| Step: 10
Training loss: 0.05716802924871445
Validation loss: 1.469811486941512

Epoch: 6| Step: 11
Training loss: 0.05049334466457367
Validation loss: 1.463986409607754

Epoch: 6| Step: 12
Training loss: 0.11344119906425476
Validation loss: 1.4467821762125979

Epoch: 6| Step: 13
Training loss: 0.09256339073181152
Validation loss: 1.4399042821699573

Epoch: 511| Step: 0
Training loss: 0.08765661716461182
Validation loss: 1.4539850745149838

Epoch: 6| Step: 1
Training loss: 0.05283544212579727
Validation loss: 1.430725666784471

Epoch: 6| Step: 2
Training loss: 0.09287910908460617
Validation loss: 1.428893498195115

Epoch: 6| Step: 3
Training loss: 0.11924901604652405
Validation loss: 1.4396303456316712

Epoch: 6| Step: 4
Training loss: 0.1115042120218277
Validation loss: 1.4343634164461525

Epoch: 6| Step: 5
Training loss: 0.04454794153571129
Validation loss: 1.4548373952988656

Epoch: 6| Step: 6
Training loss: 0.05622510612010956
Validation loss: 1.4752452924687376

Epoch: 6| Step: 7
Training loss: 0.05132206901907921
Validation loss: 1.4738016141358243

Epoch: 6| Step: 8
Training loss: 0.06727589666843414
Validation loss: 1.4848054378263411

Epoch: 6| Step: 9
Training loss: 0.0904766395688057
Validation loss: 1.4647958586292882

Epoch: 6| Step: 10
Training loss: 0.05752366781234741
Validation loss: 1.4651049529352496

Epoch: 6| Step: 11
Training loss: 0.09223505109548569
Validation loss: 1.463271556362029

Epoch: 6| Step: 12
Training loss: 0.06709221750497818
Validation loss: 1.4581317311973983

Epoch: 6| Step: 13
Training loss: 0.04971548542380333
Validation loss: 1.4553935220164638

Epoch: 512| Step: 0
Training loss: 0.07278214395046234
Validation loss: 1.4494391231126682

Epoch: 6| Step: 1
Training loss: 0.046233441680669785
Validation loss: 1.4615673736859394

Epoch: 6| Step: 2
Training loss: 0.06612645089626312
Validation loss: 1.4494564494779032

Epoch: 6| Step: 3
Training loss: 0.07257447391748428
Validation loss: 1.471479206956843

Epoch: 6| Step: 4
Training loss: 0.05869128555059433
Validation loss: 1.4776418157803115

Epoch: 6| Step: 5
Training loss: 0.0473250150680542
Validation loss: 1.4736203583337928

Epoch: 6| Step: 6
Training loss: 0.08506031334400177
Validation loss: 1.4844868503591067

Epoch: 6| Step: 7
Training loss: 0.10813712328672409
Validation loss: 1.474687550657539

Epoch: 6| Step: 8
Training loss: 0.06032709777355194
Validation loss: 1.460180007001405

Epoch: 6| Step: 9
Training loss: 0.09025167673826218
Validation loss: 1.4646351350251066

Epoch: 6| Step: 10
Training loss: 0.08669435977935791
Validation loss: 1.4725712178855814

Epoch: 6| Step: 11
Training loss: 0.10178707540035248
Validation loss: 1.4828374770379835

Epoch: 6| Step: 12
Training loss: 0.07397250086069107
Validation loss: 1.4717303219661917

Epoch: 6| Step: 13
Training loss: 0.11008984595537186
Validation loss: 1.462636536167514

Epoch: 513| Step: 0
Training loss: 0.043715860694646835
Validation loss: 1.448613510336927

Epoch: 6| Step: 1
Training loss: 0.0886896625161171
Validation loss: 1.4576251058168308

Epoch: 6| Step: 2
Training loss: 0.07012671232223511
Validation loss: 1.4546118628594182

Epoch: 6| Step: 3
Training loss: 0.06379756331443787
Validation loss: 1.4644278531433434

Epoch: 6| Step: 4
Training loss: 0.043850675225257874
Validation loss: 1.4341514507929485

Epoch: 6| Step: 5
Training loss: 0.05960056558251381
Validation loss: 1.4503701271549347

Epoch: 6| Step: 6
Training loss: 0.0683201253414154
Validation loss: 1.4535684957299182

Epoch: 6| Step: 7
Training loss: 0.03876243531703949
Validation loss: 1.422852482206078

Epoch: 6| Step: 8
Training loss: 0.1044222041964531
Validation loss: 1.4584863044882332

Epoch: 6| Step: 9
Training loss: 0.06958970427513123
Validation loss: 1.442609803650969

Epoch: 6| Step: 10
Training loss: 0.07160231471061707
Validation loss: 1.4577461942549674

Epoch: 6| Step: 11
Training loss: 0.12498867511749268
Validation loss: 1.430382292757752

Epoch: 6| Step: 12
Training loss: 0.09336301684379578
Validation loss: 1.4323673299563828

Epoch: 6| Step: 13
Training loss: 0.04596706107258797
Validation loss: 1.4328548728778798

Epoch: 514| Step: 0
Training loss: 0.06619048118591309
Validation loss: 1.4542255952794065

Epoch: 6| Step: 1
Training loss: 0.038479994982481
Validation loss: 1.4542009868929464

Epoch: 6| Step: 2
Training loss: 0.0650179535150528
Validation loss: 1.469304165532512

Epoch: 6| Step: 3
Training loss: 0.08937513828277588
Validation loss: 1.4824623702674784

Epoch: 6| Step: 4
Training loss: 0.07936673611402512
Validation loss: 1.4728335872773202

Epoch: 6| Step: 5
Training loss: 0.059086643159389496
Validation loss: 1.4602161171615764

Epoch: 6| Step: 6
Training loss: 0.08875102549791336
Validation loss: 1.458556140622785

Epoch: 6| Step: 7
Training loss: 0.07207821309566498
Validation loss: 1.4428441844960695

Epoch: 6| Step: 8
Training loss: 0.09372811019420624
Validation loss: 1.464987418343944

Epoch: 6| Step: 9
Training loss: 0.05896982550621033
Validation loss: 1.4465559656902025

Epoch: 6| Step: 10
Training loss: 0.08926726877689362
Validation loss: 1.4260476186711302

Epoch: 6| Step: 11
Training loss: 0.07193323969841003
Validation loss: 1.4347598334794402

Epoch: 6| Step: 12
Training loss: 0.05427473038434982
Validation loss: 1.4636847831869637

Epoch: 6| Step: 13
Training loss: 0.050555434077978134
Validation loss: 1.4436564330131776

Epoch: 515| Step: 0
Training loss: 0.042596906423568726
Validation loss: 1.442242895403216

Epoch: 6| Step: 1
Training loss: 0.09080228209495544
Validation loss: 1.433949185955909

Epoch: 6| Step: 2
Training loss: 0.09321466088294983
Validation loss: 1.460451888781722

Epoch: 6| Step: 3
Training loss: 0.04460344463586807
Validation loss: 1.4568539409227268

Epoch: 6| Step: 4
Training loss: 0.056392692029476166
Validation loss: 1.4595187876814155

Epoch: 6| Step: 5
Training loss: 0.043799713253974915
Validation loss: 1.4375456347260425

Epoch: 6| Step: 6
Training loss: 0.062059395015239716
Validation loss: 1.448984638337166

Epoch: 6| Step: 7
Training loss: 0.10538969933986664
Validation loss: 1.4342587288989816

Epoch: 6| Step: 8
Training loss: 0.07481084018945694
Validation loss: 1.4495053188775175

Epoch: 6| Step: 9
Training loss: 0.10855178534984589
Validation loss: 1.4361381235943045

Epoch: 6| Step: 10
Training loss: 0.09043313562870026
Validation loss: 1.4408796346315773

Epoch: 6| Step: 11
Training loss: 0.07382529973983765
Validation loss: 1.4400385848937496

Epoch: 6| Step: 12
Training loss: 0.06441713124513626
Validation loss: 1.3925732810010192

Epoch: 6| Step: 13
Training loss: 0.03085988014936447
Validation loss: 1.4152516882906678

Epoch: 516| Step: 0
Training loss: 0.04123282805085182
Validation loss: 1.4039585872363018

Epoch: 6| Step: 1
Training loss: 0.05998023599386215
Validation loss: 1.3845264040013796

Epoch: 6| Step: 2
Training loss: 0.13645505905151367
Validation loss: 1.4006889738062376

Epoch: 6| Step: 3
Training loss: 0.043933551758527756
Validation loss: 1.4119743134385796

Epoch: 6| Step: 4
Training loss: 0.06753423810005188
Validation loss: 1.4231574522551669

Epoch: 6| Step: 5
Training loss: 0.05623288080096245
Validation loss: 1.4374173084894817

Epoch: 6| Step: 6
Training loss: 0.1332278549671173
Validation loss: 1.43686302374768

Epoch: 6| Step: 7
Training loss: 0.05561145395040512
Validation loss: 1.4604314540022163

Epoch: 6| Step: 8
Training loss: 0.06992609798908234
Validation loss: 1.487930836216096

Epoch: 6| Step: 9
Training loss: 0.07830078154802322
Validation loss: 1.4976687815881544

Epoch: 6| Step: 10
Training loss: 0.11321643739938736
Validation loss: 1.4886342184517973

Epoch: 6| Step: 11
Training loss: 0.12705188989639282
Validation loss: 1.4795372569432823

Epoch: 6| Step: 12
Training loss: 0.08045964688062668
Validation loss: 1.4842765485086749

Epoch: 6| Step: 13
Training loss: 0.06885351985692978
Validation loss: 1.4944829953614103

Epoch: 517| Step: 0
Training loss: 0.08132672309875488
Validation loss: 1.4972252025399158

Epoch: 6| Step: 1
Training loss: 0.03496307134628296
Validation loss: 1.4996458240734634

Epoch: 6| Step: 2
Training loss: 0.09151116758584976
Validation loss: 1.504195055653972

Epoch: 6| Step: 3
Training loss: 0.10653659701347351
Validation loss: 1.535795796302057

Epoch: 6| Step: 4
Training loss: 0.11819593608379364
Validation loss: 1.5393967423387753

Epoch: 6| Step: 5
Training loss: 0.09614594280719757
Validation loss: 1.50640195415866

Epoch: 6| Step: 6
Training loss: 0.08878433704376221
Validation loss: 1.5025537475462882

Epoch: 6| Step: 7
Training loss: 0.08791707456111908
Validation loss: 1.478340115598453

Epoch: 6| Step: 8
Training loss: 0.09393230825662613
Validation loss: 1.5040815953285462

Epoch: 6| Step: 9
Training loss: 0.07341936230659485
Validation loss: 1.5197153693886214

Epoch: 6| Step: 10
Training loss: 0.07551683485507965
Validation loss: 1.513507959663227

Epoch: 6| Step: 11
Training loss: 0.06812552362680435
Validation loss: 1.503443314183143

Epoch: 6| Step: 12
Training loss: 0.06436465680599213
Validation loss: 1.497143373694471

Epoch: 6| Step: 13
Training loss: 0.12669993937015533
Validation loss: 1.486959844507197

Epoch: 518| Step: 0
Training loss: 0.05614610016345978
Validation loss: 1.493346861613694

Epoch: 6| Step: 1
Training loss: 0.0707954540848732
Validation loss: 1.4891901913509573

Epoch: 6| Step: 2
Training loss: 0.08212491124868393
Validation loss: 1.4703003443697447

Epoch: 6| Step: 3
Training loss: 0.09735345095396042
Validation loss: 1.4749441313487228

Epoch: 6| Step: 4
Training loss: 0.07494273781776428
Validation loss: 1.4862750922479937

Epoch: 6| Step: 5
Training loss: 0.05207878351211548
Validation loss: 1.4726386563752287

Epoch: 6| Step: 6
Training loss: 0.1414424180984497
Validation loss: 1.4801709305855535

Epoch: 6| Step: 7
Training loss: 0.07826085388660431
Validation loss: 1.4895537559704115

Epoch: 6| Step: 8
Training loss: 0.05344805866479874
Validation loss: 1.468374212582906

Epoch: 6| Step: 9
Training loss: 0.10463869571685791
Validation loss: 1.4649162894936019

Epoch: 6| Step: 10
Training loss: 0.07675948739051819
Validation loss: 1.4634417821002264

Epoch: 6| Step: 11
Training loss: 0.0539611354470253
Validation loss: 1.456132089578977

Epoch: 6| Step: 12
Training loss: 0.053822144865989685
Validation loss: 1.4589114381420998

Epoch: 6| Step: 13
Training loss: 0.08649926632642746
Validation loss: 1.4313359709196194

Epoch: 519| Step: 0
Training loss: 0.08408461511135101
Validation loss: 1.4573243894884664

Epoch: 6| Step: 1
Training loss: 0.05391499772667885
Validation loss: 1.434378359907417

Epoch: 6| Step: 2
Training loss: 0.07467880100011826
Validation loss: 1.4481159884442565

Epoch: 6| Step: 3
Training loss: 0.11415235698223114
Validation loss: 1.4296467624684817

Epoch: 6| Step: 4
Training loss: 0.06301126629114151
Validation loss: 1.4421848545792282

Epoch: 6| Step: 5
Training loss: 0.08616640418767929
Validation loss: 1.4349487135487218

Epoch: 6| Step: 6
Training loss: 0.05689897760748863
Validation loss: 1.4435861392687726

Epoch: 6| Step: 7
Training loss: 0.040983449667692184
Validation loss: 1.4504787229722547

Epoch: 6| Step: 8
Training loss: 0.053360842168331146
Validation loss: 1.474599721611187

Epoch: 6| Step: 9
Training loss: 0.09924245625734329
Validation loss: 1.4698457384622226

Epoch: 6| Step: 10
Training loss: 0.07072927802801132
Validation loss: 1.486495626870022

Epoch: 6| Step: 11
Training loss: 0.059379011392593384
Validation loss: 1.4878705829702399

Epoch: 6| Step: 12
Training loss: 0.1324564814567566
Validation loss: 1.475983436389636

Epoch: 6| Step: 13
Training loss: 0.06336702406406403
Validation loss: 1.4811532805042882

Epoch: 520| Step: 0
Training loss: 0.1185615211725235
Validation loss: 1.4856331938056535

Epoch: 6| Step: 1
Training loss: 0.07731943577528
Validation loss: 1.4893659430165445

Epoch: 6| Step: 2
Training loss: 0.07017922401428223
Validation loss: 1.4958575182063605

Epoch: 6| Step: 3
Training loss: 0.12972155213356018
Validation loss: 1.4788165425741544

Epoch: 6| Step: 4
Training loss: 0.05236932262778282
Validation loss: 1.4499507540015764

Epoch: 6| Step: 5
Training loss: 0.057705529034137726
Validation loss: 1.4945228144686709

Epoch: 6| Step: 6
Training loss: 0.045008428394794464
Validation loss: 1.4705959917396627

Epoch: 6| Step: 7
Training loss: 0.03333691135048866
Validation loss: 1.467621700738066

Epoch: 6| Step: 8
Training loss: 0.037120621651411057
Validation loss: 1.4628853541548534

Epoch: 6| Step: 9
Training loss: 0.04038507491350174
Validation loss: 1.443487521140806

Epoch: 6| Step: 10
Training loss: 0.06269149482250214
Validation loss: 1.4558316264101254

Epoch: 6| Step: 11
Training loss: 0.039327897131443024
Validation loss: 1.4492774342977872

Epoch: 6| Step: 12
Training loss: 0.11786384135484695
Validation loss: 1.4328934838694911

Epoch: 6| Step: 13
Training loss: 0.06500282138586044
Validation loss: 1.4203622341156006

Epoch: 521| Step: 0
Training loss: 0.0416681170463562
Validation loss: 1.4425794578367663

Epoch: 6| Step: 1
Training loss: 0.05362054705619812
Validation loss: 1.4368493108339206

Epoch: 6| Step: 2
Training loss: 0.09026575088500977
Validation loss: 1.4408636567413167

Epoch: 6| Step: 3
Training loss: 0.05305253714323044
Validation loss: 1.4513831734657288

Epoch: 6| Step: 4
Training loss: 0.049975816160440445
Validation loss: 1.465853697510176

Epoch: 6| Step: 5
Training loss: 0.044461000710725784
Validation loss: 1.4536398482579056

Epoch: 6| Step: 6
Training loss: 0.056530654430389404
Validation loss: 1.4633852986879246

Epoch: 6| Step: 7
Training loss: 0.08270417153835297
Validation loss: 1.4932229929072882

Epoch: 6| Step: 8
Training loss: 0.05888485163450241
Validation loss: 1.493838898597225

Epoch: 6| Step: 9
Training loss: 0.09747660905122757
Validation loss: 1.4952429276640697

Epoch: 6| Step: 10
Training loss: 0.09733252227306366
Validation loss: 1.4888569014046782

Epoch: 6| Step: 11
Training loss: 0.06269994378089905
Validation loss: 1.4618452300307572

Epoch: 6| Step: 12
Training loss: 0.08866734802722931
Validation loss: 1.4343774216149443

Epoch: 6| Step: 13
Training loss: 0.06316620111465454
Validation loss: 1.4380300391104914

Epoch: 522| Step: 0
Training loss: 0.08964864164590836
Validation loss: 1.4149465727549728

Epoch: 6| Step: 1
Training loss: 0.04526635259389877
Validation loss: 1.4163762843737038

Epoch: 6| Step: 2
Training loss: 0.1139582023024559
Validation loss: 1.4301337349799372

Epoch: 6| Step: 3
Training loss: 0.059678785502910614
Validation loss: 1.4276574068172003

Epoch: 6| Step: 4
Training loss: 0.09247606992721558
Validation loss: 1.4011701435171149

Epoch: 6| Step: 5
Training loss: 0.06184641271829605
Validation loss: 1.4424516706056492

Epoch: 6| Step: 6
Training loss: 0.08219383656978607
Validation loss: 1.4647314324173877

Epoch: 6| Step: 7
Training loss: 0.11831281334161758
Validation loss: 1.441613781195815

Epoch: 6| Step: 8
Training loss: 0.04665351286530495
Validation loss: 1.473395952614405

Epoch: 6| Step: 9
Training loss: 0.08243811130523682
Validation loss: 1.48218422935855

Epoch: 6| Step: 10
Training loss: 0.06477917730808258
Validation loss: 1.4770241937329691

Epoch: 6| Step: 11
Training loss: 0.06872408837080002
Validation loss: 1.4649469621719853

Epoch: 6| Step: 12
Training loss: 0.035217247903347015
Validation loss: 1.4701753893206198

Epoch: 6| Step: 13
Training loss: 0.030187487602233887
Validation loss: 1.4576892083691013

Epoch: 523| Step: 0
Training loss: 0.057933419942855835
Validation loss: 1.486627568480789

Epoch: 6| Step: 1
Training loss: 0.05616661533713341
Validation loss: 1.468326727549235

Epoch: 6| Step: 2
Training loss: 0.023545628413558006
Validation loss: 1.4596359768221456

Epoch: 6| Step: 3
Training loss: 0.0397077351808548
Validation loss: 1.4473363776360788

Epoch: 6| Step: 4
Training loss: 0.07164732366800308
Validation loss: 1.4713571417716242

Epoch: 6| Step: 5
Training loss: 0.07512965053319931
Validation loss: 1.4827229143470846

Epoch: 6| Step: 6
Training loss: 0.0879560112953186
Validation loss: 1.4697416008159678

Epoch: 6| Step: 7
Training loss: 0.06079377233982086
Validation loss: 1.4889000897766442

Epoch: 6| Step: 8
Training loss: 0.061404839158058167
Validation loss: 1.4773542996375792

Epoch: 6| Step: 9
Training loss: 0.06182166561484337
Validation loss: 1.4861192882701915

Epoch: 6| Step: 10
Training loss: 0.0739956945180893
Validation loss: 1.5027445618824293

Epoch: 6| Step: 11
Training loss: 0.13844522833824158
Validation loss: 1.5043539834278885

Epoch: 6| Step: 12
Training loss: 0.07603663206100464
Validation loss: 1.526251910835184

Epoch: 6| Step: 13
Training loss: 0.06169402599334717
Validation loss: 1.5034090280532837

Epoch: 524| Step: 0
Training loss: 0.0675327256321907
Validation loss: 1.495274139988807

Epoch: 6| Step: 1
Training loss: 0.055529654026031494
Validation loss: 1.4998707361118768

Epoch: 6| Step: 2
Training loss: 0.06837837398052216
Validation loss: 1.4953648492854128

Epoch: 6| Step: 3
Training loss: 0.06869037449359894
Validation loss: 1.49533889883308

Epoch: 6| Step: 4
Training loss: 0.05559907853603363
Validation loss: 1.4956225143965853

Epoch: 6| Step: 5
Training loss: 0.0758129134774208
Validation loss: 1.5103991108555948

Epoch: 6| Step: 6
Training loss: 0.04429716244339943
Validation loss: 1.493392898190406

Epoch: 6| Step: 7
Training loss: 0.11826454102993011
Validation loss: 1.508805618491224

Epoch: 6| Step: 8
Training loss: 0.053398068994283676
Validation loss: 1.4831392085680397

Epoch: 6| Step: 9
Training loss: 0.03911080211400986
Validation loss: 1.4804405307257047

Epoch: 6| Step: 10
Training loss: 0.08574861288070679
Validation loss: 1.462064593069015

Epoch: 6| Step: 11
Training loss: 0.05966001749038696
Validation loss: 1.4695473230013283

Epoch: 6| Step: 12
Training loss: 0.0832444578409195
Validation loss: 1.4660743353187398

Epoch: 6| Step: 13
Training loss: 0.06517830491065979
Validation loss: 1.463942091952088

Epoch: 525| Step: 0
Training loss: 0.050248026847839355
Validation loss: 1.4632264657687115

Epoch: 6| Step: 1
Training loss: 0.035584449768066406
Validation loss: 1.4769107282802623

Epoch: 6| Step: 2
Training loss: 0.057976022362709045
Validation loss: 1.4743543324931976

Epoch: 6| Step: 3
Training loss: 0.07357686758041382
Validation loss: 1.4868152590208157

Epoch: 6| Step: 4
Training loss: 0.05164087936282158
Validation loss: 1.4789465678635465

Epoch: 6| Step: 5
Training loss: 0.12646609544754028
Validation loss: 1.492202874152891

Epoch: 6| Step: 6
Training loss: 0.06778721511363983
Validation loss: 1.4782653470193186

Epoch: 6| Step: 7
Training loss: 0.07688338309526443
Validation loss: 1.5018923115986649

Epoch: 6| Step: 8
Training loss: 0.0479593500494957
Validation loss: 1.4928646062010078

Epoch: 6| Step: 9
Training loss: 0.061841413378715515
Validation loss: 1.466048022752167

Epoch: 6| Step: 10
Training loss: 0.08710388839244843
Validation loss: 1.4741409081284718

Epoch: 6| Step: 11
Training loss: 0.06695500016212463
Validation loss: 1.4936652260441934

Epoch: 6| Step: 12
Training loss: 0.05005589872598648
Validation loss: 1.4761082151884675

Epoch: 6| Step: 13
Training loss: 0.017634915187954903
Validation loss: 1.4650604365974345

Epoch: 526| Step: 0
Training loss: 0.10600458085536957
Validation loss: 1.4662252895293697

Epoch: 6| Step: 1
Training loss: 0.10811358690261841
Validation loss: 1.4504850692646478

Epoch: 6| Step: 2
Training loss: 0.04321587085723877
Validation loss: 1.4633223074738697

Epoch: 6| Step: 3
Training loss: 0.047301579266786575
Validation loss: 1.46729608889549

Epoch: 6| Step: 4
Training loss: 0.08965004980564117
Validation loss: 1.4551366618884507

Epoch: 6| Step: 5
Training loss: 0.09154170751571655
Validation loss: 1.4754205878062914

Epoch: 6| Step: 6
Training loss: 0.0701243057847023
Validation loss: 1.4661543625657276

Epoch: 6| Step: 7
Training loss: 0.042856719344854355
Validation loss: 1.4356912323223647

Epoch: 6| Step: 8
Training loss: 0.04694068431854248
Validation loss: 1.4480564619905205

Epoch: 6| Step: 9
Training loss: 0.04293002188205719
Validation loss: 1.4421628585425756

Epoch: 6| Step: 10
Training loss: 0.08217965811491013
Validation loss: 1.4542383724643337

Epoch: 6| Step: 11
Training loss: 0.06172735616564751
Validation loss: 1.4551628552457339

Epoch: 6| Step: 12
Training loss: 0.05281852185726166
Validation loss: 1.4541258337677165

Epoch: 6| Step: 13
Training loss: 0.10448537766933441
Validation loss: 1.4286838744276313

Epoch: 527| Step: 0
Training loss: 0.05258028581738472
Validation loss: 1.4363882490383681

Epoch: 6| Step: 1
Training loss: 0.08142879605293274
Validation loss: 1.429921446308013

Epoch: 6| Step: 2
Training loss: 0.07777559757232666
Validation loss: 1.4229160803620533

Epoch: 6| Step: 3
Training loss: 0.07996382564306259
Validation loss: 1.437027842767777

Epoch: 6| Step: 4
Training loss: 0.10434350371360779
Validation loss: 1.4446499463050597

Epoch: 6| Step: 5
Training loss: 0.08341842889785767
Validation loss: 1.427537529699264

Epoch: 6| Step: 6
Training loss: 0.06358382105827332
Validation loss: 1.425327536880329

Epoch: 6| Step: 7
Training loss: 0.11050410568714142
Validation loss: 1.4244751391872283

Epoch: 6| Step: 8
Training loss: 0.0600665882229805
Validation loss: 1.4011285202477568

Epoch: 6| Step: 9
Training loss: 0.06774625927209854
Validation loss: 1.4484801561601701

Epoch: 6| Step: 10
Training loss: 0.04006148502230644
Validation loss: 1.4285120784595449

Epoch: 6| Step: 11
Training loss: 0.06907786428928375
Validation loss: 1.4193064435835807

Epoch: 6| Step: 12
Training loss: 0.05381161719560623
Validation loss: 1.4138071588290635

Epoch: 6| Step: 13
Training loss: 0.03826570138335228
Validation loss: 1.4542221792282597

Epoch: 528| Step: 0
Training loss: 0.049308791756629944
Validation loss: 1.462462943087342

Epoch: 6| Step: 1
Training loss: 0.056816279888153076
Validation loss: 1.498236028097009

Epoch: 6| Step: 2
Training loss: 0.1006237119436264
Validation loss: 1.4812132876406434

Epoch: 6| Step: 3
Training loss: 0.07906247675418854
Validation loss: 1.4866973020697152

Epoch: 6| Step: 4
Training loss: 0.08518985658884048
Validation loss: 1.4810820420583088

Epoch: 6| Step: 5
Training loss: 0.04492811858654022
Validation loss: 1.4724319064488975

Epoch: 6| Step: 6
Training loss: 0.06136295571923256
Validation loss: 1.4734664476045998

Epoch: 6| Step: 7
Training loss: 0.05104045942425728
Validation loss: 1.4660089490234212

Epoch: 6| Step: 8
Training loss: 0.05565989017486572
Validation loss: 1.4846526371535433

Epoch: 6| Step: 9
Training loss: 0.04622811824083328
Validation loss: 1.4582165377114409

Epoch: 6| Step: 10
Training loss: 0.0940949097275734
Validation loss: 1.4675996803468274

Epoch: 6| Step: 11
Training loss: 0.14774669706821442
Validation loss: 1.4666860411244054

Epoch: 6| Step: 12
Training loss: 0.052375197410583496
Validation loss: 1.446032008817119

Epoch: 6| Step: 13
Training loss: 0.11069305986166
Validation loss: 1.462596627973741

Epoch: 529| Step: 0
Training loss: 0.04445512592792511
Validation loss: 1.4470558038321875

Epoch: 6| Step: 1
Training loss: 0.039712801575660706
Validation loss: 1.4613834683613112

Epoch: 6| Step: 2
Training loss: 0.10582563281059265
Validation loss: 1.460122718605944

Epoch: 6| Step: 3
Training loss: 0.05344390124082565
Validation loss: 1.440356421214278

Epoch: 6| Step: 4
Training loss: 0.04471758380532265
Validation loss: 1.4569057892727595

Epoch: 6| Step: 5
Training loss: 0.0939062237739563
Validation loss: 1.4629049813875588

Epoch: 6| Step: 6
Training loss: 0.07621479034423828
Validation loss: 1.445299780496987

Epoch: 6| Step: 7
Training loss: 0.08306439965963364
Validation loss: 1.4725505933966687

Epoch: 6| Step: 8
Training loss: 0.07391239702701569
Validation loss: 1.4663714619093045

Epoch: 6| Step: 9
Training loss: 0.05548280104994774
Validation loss: 1.4584898256486463

Epoch: 6| Step: 10
Training loss: 0.0580105297267437
Validation loss: 1.4747847613467966

Epoch: 6| Step: 11
Training loss: 0.074432373046875
Validation loss: 1.4764505663225729

Epoch: 6| Step: 12
Training loss: 0.05082646757364273
Validation loss: 1.4793483441875828

Epoch: 6| Step: 13
Training loss: 0.05491987243294716
Validation loss: 1.4756198160109981

Epoch: 530| Step: 0
Training loss: 0.04962451010942459
Validation loss: 1.472593818941424

Epoch: 6| Step: 1
Training loss: 0.0780993402004242
Validation loss: 1.4976519320600776

Epoch: 6| Step: 2
Training loss: 0.04920221120119095
Validation loss: 1.4828146119271555

Epoch: 6| Step: 3
Training loss: 0.0988808274269104
Validation loss: 1.4632853397759058

Epoch: 6| Step: 4
Training loss: 0.05148888751864433
Validation loss: 1.4790142043944328

Epoch: 6| Step: 5
Training loss: 0.06333489716053009
Validation loss: 1.476055952810472

Epoch: 6| Step: 6
Training loss: 0.11527766287326813
Validation loss: 1.4744602493060532

Epoch: 6| Step: 7
Training loss: 0.1001339703798294
Validation loss: 1.4954021374384563

Epoch: 6| Step: 8
Training loss: 0.0743924081325531
Validation loss: 1.471885299169889

Epoch: 6| Step: 9
Training loss: 0.0603179857134819
Validation loss: 1.5007946298968406

Epoch: 6| Step: 10
Training loss: 0.06004570797085762
Validation loss: 1.4914305735659856

Epoch: 6| Step: 11
Training loss: 0.11695683747529984
Validation loss: 1.498469869295756

Epoch: 6| Step: 12
Training loss: 0.05209622532129288
Validation loss: 1.4983307610275924

Epoch: 6| Step: 13
Training loss: 0.04018840566277504
Validation loss: 1.5099850354656097

Epoch: 531| Step: 0
Training loss: 0.08392493426799774
Validation loss: 1.4940825982760357

Epoch: 6| Step: 1
Training loss: 0.04506397247314453
Validation loss: 1.4595717473696637

Epoch: 6| Step: 2
Training loss: 0.08552461117506027
Validation loss: 1.465320437185226

Epoch: 6| Step: 3
Training loss: 0.08442758023738861
Validation loss: 1.4494777969134751

Epoch: 6| Step: 4
Training loss: 0.06640667468309402
Validation loss: 1.4584174425371232

Epoch: 6| Step: 5
Training loss: 0.06215454265475273
Validation loss: 1.4496812153888006

Epoch: 6| Step: 6
Training loss: 0.05918693542480469
Validation loss: 1.4434084379544823

Epoch: 6| Step: 7
Training loss: 0.042097486555576324
Validation loss: 1.4599704806522658

Epoch: 6| Step: 8
Training loss: 0.09351766109466553
Validation loss: 1.4693446043998963

Epoch: 6| Step: 9
Training loss: 0.06294525414705276
Validation loss: 1.4919785786700506

Epoch: 6| Step: 10
Training loss: 0.09340119361877441
Validation loss: 1.4893482269779328

Epoch: 6| Step: 11
Training loss: 0.0831616222858429
Validation loss: 1.5090120377079133

Epoch: 6| Step: 12
Training loss: 0.10044414550065994
Validation loss: 1.4906512396309965

Epoch: 6| Step: 13
Training loss: 0.07686088234186172
Validation loss: 1.496192277118724

Epoch: 532| Step: 0
Training loss: 0.05277739465236664
Validation loss: 1.4818748562566695

Epoch: 6| Step: 1
Training loss: 0.055113594979047775
Validation loss: 1.4934800286446848

Epoch: 6| Step: 2
Training loss: 0.06323404610157013
Validation loss: 1.466833915761722

Epoch: 6| Step: 3
Training loss: 0.08821550011634827
Validation loss: 1.4639423412661399

Epoch: 6| Step: 4
Training loss: 0.06431564688682556
Validation loss: 1.4668791473552745

Epoch: 6| Step: 5
Training loss: 0.05387750267982483
Validation loss: 1.4453810004777805

Epoch: 6| Step: 6
Training loss: 0.10553897172212601
Validation loss: 1.4342632421883204

Epoch: 6| Step: 7
Training loss: 0.07462175190448761
Validation loss: 1.4576901812707224

Epoch: 6| Step: 8
Training loss: 0.13595163822174072
Validation loss: 1.4539818853460333

Epoch: 6| Step: 9
Training loss: 0.04618411511182785
Validation loss: 1.470034868486466

Epoch: 6| Step: 10
Training loss: 0.08499231189489365
Validation loss: 1.4741548658699117

Epoch: 6| Step: 11
Training loss: 0.08335237205028534
Validation loss: 1.473200794189207

Epoch: 6| Step: 12
Training loss: 0.04536473751068115
Validation loss: 1.4727785036128054

Epoch: 6| Step: 13
Training loss: 0.06335175037384033
Validation loss: 1.467730963101951

Epoch: 533| Step: 0
Training loss: 0.07799547165632248
Validation loss: 1.4835861306036673

Epoch: 6| Step: 1
Training loss: 0.08653779327869415
Validation loss: 1.4970669592580488

Epoch: 6| Step: 2
Training loss: 0.06953761726617813
Validation loss: 1.4852600341202111

Epoch: 6| Step: 3
Training loss: 0.10415685176849365
Validation loss: 1.5038906399921705

Epoch: 6| Step: 4
Training loss: 0.052792686969041824
Validation loss: 1.4898256999190136

Epoch: 6| Step: 5
Training loss: 0.08691880106925964
Validation loss: 1.4753660982654941

Epoch: 6| Step: 6
Training loss: 0.06941835582256317
Validation loss: 1.4668502153888825

Epoch: 6| Step: 7
Training loss: 0.1134192943572998
Validation loss: 1.4375098443800403

Epoch: 6| Step: 8
Training loss: 0.14006811380386353
Validation loss: 1.4439079159049577

Epoch: 6| Step: 9
Training loss: 0.11079634726047516
Validation loss: 1.4285924165479598

Epoch: 6| Step: 10
Training loss: 0.08155462890863419
Validation loss: 1.4505696040327831

Epoch: 6| Step: 11
Training loss: 0.041856151074171066
Validation loss: 1.4393934639551307

Epoch: 6| Step: 12
Training loss: 0.06148001179099083
Validation loss: 1.458026837277156

Epoch: 6| Step: 13
Training loss: 0.05506087839603424
Validation loss: 1.4597191105606735

Epoch: 534| Step: 0
Training loss: 0.12680760025978088
Validation loss: 1.4585649031464771

Epoch: 6| Step: 1
Training loss: 0.08109843730926514
Validation loss: 1.4585553869124381

Epoch: 6| Step: 2
Training loss: 0.10327714681625366
Validation loss: 1.4505828670276109

Epoch: 6| Step: 3
Training loss: 0.10996384918689728
Validation loss: 1.4318308240623885

Epoch: 6| Step: 4
Training loss: 0.07640323787927628
Validation loss: 1.445979484947779

Epoch: 6| Step: 5
Training loss: 0.08283798396587372
Validation loss: 1.4081701732450915

Epoch: 6| Step: 6
Training loss: 0.08201025426387787
Validation loss: 1.443387786547343

Epoch: 6| Step: 7
Training loss: 0.07937592267990112
Validation loss: 1.4200314808917303

Epoch: 6| Step: 8
Training loss: 0.05526043474674225
Validation loss: 1.4224197646623016

Epoch: 6| Step: 9
Training loss: 0.07966156303882599
Validation loss: 1.4426792321666595

Epoch: 6| Step: 10
Training loss: 0.045785821974277496
Validation loss: 1.4304016790082377

Epoch: 6| Step: 11
Training loss: 0.06484148651361465
Validation loss: 1.4434609554147209

Epoch: 6| Step: 12
Training loss: 0.056684188544750214
Validation loss: 1.439282057105854

Epoch: 6| Step: 13
Training loss: 0.08069542050361633
Validation loss: 1.4349820575406473

Epoch: 535| Step: 0
Training loss: 0.06518743932247162
Validation loss: 1.438899588841264

Epoch: 6| Step: 1
Training loss: 0.07210572808980942
Validation loss: 1.445327167869896

Epoch: 6| Step: 2
Training loss: 0.13809087872505188
Validation loss: 1.4554707721997333

Epoch: 6| Step: 3
Training loss: 0.08091571927070618
Validation loss: 1.4538749815315328

Epoch: 6| Step: 4
Training loss: 0.09198863059282303
Validation loss: 1.4412600340381745

Epoch: 6| Step: 5
Training loss: 0.06609262526035309
Validation loss: 1.4482759788472166

Epoch: 6| Step: 6
Training loss: 0.12464530766010284
Validation loss: 1.4539838503765803

Epoch: 6| Step: 7
Training loss: 0.07839837670326233
Validation loss: 1.4648717167556926

Epoch: 6| Step: 8
Training loss: 0.07352219521999359
Validation loss: 1.4228783230627737

Epoch: 6| Step: 9
Training loss: 0.05768442153930664
Validation loss: 1.4252834371341172

Epoch: 6| Step: 10
Training loss: 0.09059306979179382
Validation loss: 1.4375471222785212

Epoch: 6| Step: 11
Training loss: 0.07184629142284393
Validation loss: 1.4682935450666694

Epoch: 6| Step: 12
Training loss: 0.082085981965065
Validation loss: 1.443846110374697

Epoch: 6| Step: 13
Training loss: 0.05616716668009758
Validation loss: 1.4532191458568777

Epoch: 536| Step: 0
Training loss: 0.06610945612192154
Validation loss: 1.4507269461949666

Epoch: 6| Step: 1
Training loss: 0.11817777901887894
Validation loss: 1.4468334560753198

Epoch: 6| Step: 2
Training loss: 0.13730478286743164
Validation loss: 1.4536102061630578

Epoch: 6| Step: 3
Training loss: 0.07401061803102493
Validation loss: 1.4471304301292665

Epoch: 6| Step: 4
Training loss: 0.06508618593215942
Validation loss: 1.4795702618937339

Epoch: 6| Step: 5
Training loss: 0.0656680092215538
Validation loss: 1.4790389845448155

Epoch: 6| Step: 6
Training loss: 0.08530790358781815
Validation loss: 1.4636413589600594

Epoch: 6| Step: 7
Training loss: 0.07768281549215317
Validation loss: 1.5018785307484288

Epoch: 6| Step: 8
Training loss: 0.05599796772003174
Validation loss: 1.4866015180464713

Epoch: 6| Step: 9
Training loss: 0.07957550883293152
Validation loss: 1.4907984143944197

Epoch: 6| Step: 10
Training loss: 0.1025644987821579
Validation loss: 1.4648902364956435

Epoch: 6| Step: 11
Training loss: 0.07270722836256027
Validation loss: 1.451448002169209

Epoch: 6| Step: 12
Training loss: 0.0896402895450592
Validation loss: 1.4397997292139197

Epoch: 6| Step: 13
Training loss: 0.10269796848297119
Validation loss: 1.4268924433697936

Epoch: 537| Step: 0
Training loss: 0.10091253370046616
Validation loss: 1.4438899896478141

Epoch: 6| Step: 1
Training loss: 0.06909144669771194
Validation loss: 1.4547555677352413

Epoch: 6| Step: 2
Training loss: 0.06922025978565216
Validation loss: 1.4521119351028113

Epoch: 6| Step: 3
Training loss: 0.09910500049591064
Validation loss: 1.4601198140011038

Epoch: 6| Step: 4
Training loss: 0.07127102464437485
Validation loss: 1.47319854715819

Epoch: 6| Step: 5
Training loss: 0.044975802302360535
Validation loss: 1.4647118378711004

Epoch: 6| Step: 6
Training loss: 0.04899732023477554
Validation loss: 1.4955014823585429

Epoch: 6| Step: 7
Training loss: 0.0859077051281929
Validation loss: 1.5162917888292702

Epoch: 6| Step: 8
Training loss: 0.09197625517845154
Validation loss: 1.5303617215925647

Epoch: 6| Step: 9
Training loss: 0.11244393140077591
Validation loss: 1.525283912176727

Epoch: 6| Step: 10
Training loss: 0.1177605539560318
Validation loss: 1.5320871203176436

Epoch: 6| Step: 11
Training loss: 0.06938561052083969
Validation loss: 1.5117400794900873

Epoch: 6| Step: 12
Training loss: 0.09218968451023102
Validation loss: 1.4860520491036036

Epoch: 6| Step: 13
Training loss: 0.0462007112801075
Validation loss: 1.4687971286876227

Epoch: 538| Step: 0
Training loss: 0.07671965658664703
Validation loss: 1.445576007648181

Epoch: 6| Step: 1
Training loss: 0.07028788328170776
Validation loss: 1.4210448104848143

Epoch: 6| Step: 2
Training loss: 0.08583827316761017
Validation loss: 1.4415240774872482

Epoch: 6| Step: 3
Training loss: 0.07717602699995041
Validation loss: 1.4322647497218142

Epoch: 6| Step: 4
Training loss: 0.064708411693573
Validation loss: 1.4167410455724245

Epoch: 6| Step: 5
Training loss: 0.09394277632236481
Validation loss: 1.4304111375603625

Epoch: 6| Step: 6
Training loss: 0.08501432836055756
Validation loss: 1.4165360440490067

Epoch: 6| Step: 7
Training loss: 0.08894647657871246
Validation loss: 1.4325780227620115

Epoch: 6| Step: 8
Training loss: 0.10103684663772583
Validation loss: 1.4386554571890062

Epoch: 6| Step: 9
Training loss: 0.06856638193130493
Validation loss: 1.4517043329054309

Epoch: 6| Step: 10
Training loss: 0.07347865402698517
Validation loss: 1.4443837301705473

Epoch: 6| Step: 11
Training loss: 0.05218212306499481
Validation loss: 1.4557172290740474

Epoch: 6| Step: 12
Training loss: 0.12504942715168
Validation loss: 1.454046162225867

Epoch: 6| Step: 13
Training loss: 0.04782237485051155
Validation loss: 1.4799018418917091

Epoch: 539| Step: 0
Training loss: 0.11211704462766647
Validation loss: 1.4800689720338391

Epoch: 6| Step: 1
Training loss: 0.08970539271831512
Validation loss: 1.4630882637475127

Epoch: 6| Step: 2
Training loss: 0.07450531423091888
Validation loss: 1.4684566349111579

Epoch: 6| Step: 3
Training loss: 0.09283172339200974
Validation loss: 1.465652269701804

Epoch: 6| Step: 4
Training loss: 0.07741362601518631
Validation loss: 1.47228548090945

Epoch: 6| Step: 5
Training loss: 0.10437501966953278
Validation loss: 1.4452532190148548

Epoch: 6| Step: 6
Training loss: 0.0609201118350029
Validation loss: 1.4336015844857821

Epoch: 6| Step: 7
Training loss: 0.06376399099826813
Validation loss: 1.4338546696529593

Epoch: 6| Step: 8
Training loss: 0.04370690882205963
Validation loss: 1.4321696168632918

Epoch: 6| Step: 9
Training loss: 0.034771811217069626
Validation loss: 1.4251811517182218

Epoch: 6| Step: 10
Training loss: 0.09537969529628754
Validation loss: 1.444864833226768

Epoch: 6| Step: 11
Training loss: 0.04405400529503822
Validation loss: 1.4400362885126503

Epoch: 6| Step: 12
Training loss: 0.08119615167379379
Validation loss: 1.4741026477147174

Epoch: 6| Step: 13
Training loss: 0.08459055423736572
Validation loss: 1.4581214663802937

Epoch: 540| Step: 0
Training loss: 0.0406460165977478
Validation loss: 1.4708817075657588

Epoch: 6| Step: 1
Training loss: 0.09622875601053238
Validation loss: 1.4923115699521956

Epoch: 6| Step: 2
Training loss: 0.06942477822303772
Validation loss: 1.4968081187176447

Epoch: 6| Step: 3
Training loss: 0.08577482402324677
Validation loss: 1.4795066669423094

Epoch: 6| Step: 4
Training loss: 0.07833676040172577
Validation loss: 1.4794815048094718

Epoch: 6| Step: 5
Training loss: 0.040090322494506836
Validation loss: 1.469992188997166

Epoch: 6| Step: 6
Training loss: 0.04938618466258049
Validation loss: 1.4437734593627274

Epoch: 6| Step: 7
Training loss: 0.07601067423820496
Validation loss: 1.4745482501163278

Epoch: 6| Step: 8
Training loss: 0.0366319864988327
Validation loss: 1.4433674491861814

Epoch: 6| Step: 9
Training loss: 0.0661725252866745
Validation loss: 1.4204561594993836

Epoch: 6| Step: 10
Training loss: 0.07991652190685272
Validation loss: 1.4107569949601286

Epoch: 6| Step: 11
Training loss: 0.06358566135168076
Validation loss: 1.4462058274976668

Epoch: 6| Step: 12
Training loss: 0.06195995211601257
Validation loss: 1.4383605487885014

Epoch: 6| Step: 13
Training loss: 0.08867476135492325
Validation loss: 1.4491570444517239

Epoch: 541| Step: 0
Training loss: 0.05505039542913437
Validation loss: 1.4276368054010535

Epoch: 6| Step: 1
Training loss: 0.04827551171183586
Validation loss: 1.4622869722304805

Epoch: 6| Step: 2
Training loss: 0.07057715207338333
Validation loss: 1.4590307794591433

Epoch: 6| Step: 3
Training loss: 0.055308036506175995
Validation loss: 1.4409712655569917

Epoch: 6| Step: 4
Training loss: 0.06769794225692749
Validation loss: 1.44085221393134

Epoch: 6| Step: 5
Training loss: 0.0931175947189331
Validation loss: 1.4638119295079222

Epoch: 6| Step: 6
Training loss: 0.05280238017439842
Validation loss: 1.44496125559653

Epoch: 6| Step: 7
Training loss: 0.06913844496011734
Validation loss: 1.4364359212178055

Epoch: 6| Step: 8
Training loss: 0.041540391743183136
Validation loss: 1.4244697952783236

Epoch: 6| Step: 9
Training loss: 0.06124132126569748
Validation loss: 1.392407178237874

Epoch: 6| Step: 10
Training loss: 0.1066398024559021
Validation loss: 1.41852996682608

Epoch: 6| Step: 11
Training loss: 0.035567961633205414
Validation loss: 1.442924778948548

Epoch: 6| Step: 12
Training loss: 0.07712619006633759
Validation loss: 1.4169496131199661

Epoch: 6| Step: 13
Training loss: 0.14109733700752258
Validation loss: 1.4366806040528

Epoch: 542| Step: 0
Training loss: 0.05057337135076523
Validation loss: 1.4494291684960807

Epoch: 6| Step: 1
Training loss: 0.048584096133708954
Validation loss: 1.470708603500038

Epoch: 6| Step: 2
Training loss: 0.07351605594158173
Validation loss: 1.4500663729124172

Epoch: 6| Step: 3
Training loss: 0.06823898106813431
Validation loss: 1.4595053567681262

Epoch: 6| Step: 4
Training loss: 0.08714024722576141
Validation loss: 1.4548760242359613

Epoch: 6| Step: 5
Training loss: 0.06282587349414825
Validation loss: 1.445357144519847

Epoch: 6| Step: 6
Training loss: 0.09952809661626816
Validation loss: 1.4614434319157754

Epoch: 6| Step: 7
Training loss: 0.06371036171913147
Validation loss: 1.437732918288118

Epoch: 6| Step: 8
Training loss: 0.05511980876326561
Validation loss: 1.431039846071633

Epoch: 6| Step: 9
Training loss: 0.1251417100429535
Validation loss: 1.4562328707787298

Epoch: 6| Step: 10
Training loss: 0.05052829906344414
Validation loss: 1.4527336423115065

Epoch: 6| Step: 11
Training loss: 0.06459847092628479
Validation loss: 1.4774051943132955

Epoch: 6| Step: 12
Training loss: 0.07576806843280792
Validation loss: 1.4603989496025989

Epoch: 6| Step: 13
Training loss: 0.03307440131902695
Validation loss: 1.450457009576982

Epoch: 543| Step: 0
Training loss: 0.04430157691240311
Validation loss: 1.4769167169447868

Epoch: 6| Step: 1
Training loss: 0.05546692758798599
Validation loss: 1.4923387214701662

Epoch: 6| Step: 2
Training loss: 0.07461167871952057
Validation loss: 1.4712995495847476

Epoch: 6| Step: 3
Training loss: 0.07102347910404205
Validation loss: 1.5103785991668701

Epoch: 6| Step: 4
Training loss: 0.05282137542963028
Validation loss: 1.5123562876896193

Epoch: 6| Step: 5
Training loss: 0.09577725827693939
Validation loss: 1.4906172611380135

Epoch: 6| Step: 6
Training loss: 0.05870240181684494
Validation loss: 1.4658391885859992

Epoch: 6| Step: 7
Training loss: 0.05936403200030327
Validation loss: 1.490524063828171

Epoch: 6| Step: 8
Training loss: 0.037079714238643646
Validation loss: 1.4780313584112352

Epoch: 6| Step: 9
Training loss: 0.08539678156375885
Validation loss: 1.44245078614963

Epoch: 6| Step: 10
Training loss: 0.11420967429876328
Validation loss: 1.4668003974422332

Epoch: 6| Step: 11
Training loss: 0.06360676139593124
Validation loss: 1.4406000029656194

Epoch: 6| Step: 12
Training loss: 0.073458731174469
Validation loss: 1.452492352454893

Epoch: 6| Step: 13
Training loss: 0.1289033591747284
Validation loss: 1.4343915062565957

Epoch: 544| Step: 0
Training loss: 0.07716523110866547
Validation loss: 1.4630132670043616

Epoch: 6| Step: 1
Training loss: 0.05619334056973457
Validation loss: 1.4703099458448348

Epoch: 6| Step: 2
Training loss: 0.09095870703458786
Validation loss: 1.4726524327390937

Epoch: 6| Step: 3
Training loss: 0.05702301859855652
Validation loss: 1.4916156632925874

Epoch: 6| Step: 4
Training loss: 0.06615515053272247
Validation loss: 1.4732688960208689

Epoch: 6| Step: 5
Training loss: 0.09053178876638412
Validation loss: 1.5108470429656327

Epoch: 6| Step: 6
Training loss: 0.10898308455944061
Validation loss: 1.4947503343705209

Epoch: 6| Step: 7
Training loss: 0.09432721138000488
Validation loss: 1.4957507618011967

Epoch: 6| Step: 8
Training loss: 0.0934075266122818
Validation loss: 1.4957809678969844

Epoch: 6| Step: 9
Training loss: 0.057443998754024506
Validation loss: 1.4567872965207664

Epoch: 6| Step: 10
Training loss: 0.08032360672950745
Validation loss: 1.456497617947158

Epoch: 6| Step: 11
Training loss: 0.05447530373930931
Validation loss: 1.435975097199922

Epoch: 6| Step: 12
Training loss: 0.04876253753900528
Validation loss: 1.4248221215381418

Epoch: 6| Step: 13
Training loss: 0.042969029396772385
Validation loss: 1.4085095736288256

Epoch: 545| Step: 0
Training loss: 0.0862150639295578
Validation loss: 1.4202186702400126

Epoch: 6| Step: 1
Training loss: 0.1131126880645752
Validation loss: 1.4155541927583757

Epoch: 6| Step: 2
Training loss: 0.10131316632032394
Validation loss: 1.3977613115823397

Epoch: 6| Step: 3
Training loss: 0.0870298370718956
Validation loss: 1.4323652700711322

Epoch: 6| Step: 4
Training loss: 0.08469551801681519
Validation loss: 1.4205778632112729

Epoch: 6| Step: 5
Training loss: 0.08420972526073456
Validation loss: 1.42467491216557

Epoch: 6| Step: 6
Training loss: 0.1466299593448639
Validation loss: 1.4441044894597863

Epoch: 6| Step: 7
Training loss: 0.05474497377872467
Validation loss: 1.4568502851711806

Epoch: 6| Step: 8
Training loss: 0.08849363029003143
Validation loss: 1.4438889065096456

Epoch: 6| Step: 9
Training loss: 0.09023170173168182
Validation loss: 1.4726770629164994

Epoch: 6| Step: 10
Training loss: 0.07163076847791672
Validation loss: 1.4701583949468469

Epoch: 6| Step: 11
Training loss: 0.04489123821258545
Validation loss: 1.4666028964904048

Epoch: 6| Step: 12
Training loss: 0.09579499065876007
Validation loss: 1.4601102400851507

Epoch: 6| Step: 13
Training loss: 0.10589712113142014
Validation loss: 1.4585187832514446

Epoch: 546| Step: 0
Training loss: 0.07632812112569809
Validation loss: 1.467648458737199

Epoch: 6| Step: 1
Training loss: 0.1418967992067337
Validation loss: 1.4618599068733953

Epoch: 6| Step: 2
Training loss: 0.07157441973686218
Validation loss: 1.466566877980386

Epoch: 6| Step: 3
Training loss: 0.08297958225011826
Validation loss: 1.4553010412441787

Epoch: 6| Step: 4
Training loss: 0.08842203766107559
Validation loss: 1.472522210049373

Epoch: 6| Step: 5
Training loss: 0.05876471847295761
Validation loss: 1.4436840216318767

Epoch: 6| Step: 6
Training loss: 0.049968548119068146
Validation loss: 1.4445764185279928

Epoch: 6| Step: 7
Training loss: 0.0621938556432724
Validation loss: 1.4332388741995699

Epoch: 6| Step: 8
Training loss: 0.1022270917892456
Validation loss: 1.4397600876387728

Epoch: 6| Step: 9
Training loss: 0.13349877297878265
Validation loss: 1.4315057736571117

Epoch: 6| Step: 10
Training loss: 0.22763311862945557
Validation loss: 1.4451698769805252

Epoch: 6| Step: 11
Training loss: 0.07887713611125946
Validation loss: 1.4414972861607869

Epoch: 6| Step: 12
Training loss: 0.08007529377937317
Validation loss: 1.4248576676973732

Epoch: 6| Step: 13
Training loss: 0.11587440967559814
Validation loss: 1.4384504966838385

Epoch: 547| Step: 0
Training loss: 0.06489415466785431
Validation loss: 1.4434131242895638

Epoch: 6| Step: 1
Training loss: 0.07598104327917099
Validation loss: 1.4759239509541502

Epoch: 6| Step: 2
Training loss: 0.11384913325309753
Validation loss: 1.4729154084318428

Epoch: 6| Step: 3
Training loss: 0.12482252717018127
Validation loss: 1.4743687786081785

Epoch: 6| Step: 4
Training loss: 0.11831998825073242
Validation loss: 1.4744798521841727

Epoch: 6| Step: 5
Training loss: 0.06435135751962662
Validation loss: 1.4642666475747221

Epoch: 6| Step: 6
Training loss: 0.048162881284952164
Validation loss: 1.4610725025976858

Epoch: 6| Step: 7
Training loss: 0.06610582768917084
Validation loss: 1.4686959533281223

Epoch: 6| Step: 8
Training loss: 0.07242525368928909
Validation loss: 1.4514520975851244

Epoch: 6| Step: 9
Training loss: 0.06978877633810043
Validation loss: 1.431211498475844

Epoch: 6| Step: 10
Training loss: 0.09486106038093567
Validation loss: 1.4445496707834222

Epoch: 6| Step: 11
Training loss: 0.06664274632930756
Validation loss: 1.4494855955082884

Epoch: 6| Step: 12
Training loss: 0.15955287218093872
Validation loss: 1.4437803247923493

Epoch: 6| Step: 13
Training loss: 0.05877436697483063
Validation loss: 1.4414071562469646

Epoch: 548| Step: 0
Training loss: 0.05980373173952103
Validation loss: 1.4278711426642634

Epoch: 6| Step: 1
Training loss: 0.06285607069730759
Validation loss: 1.4439479253625358

Epoch: 6| Step: 2
Training loss: 0.051482997834682465
Validation loss: 1.4492662850246634

Epoch: 6| Step: 3
Training loss: 0.05990614742040634
Validation loss: 1.4501962110560427

Epoch: 6| Step: 4
Training loss: 0.1254090964794159
Validation loss: 1.446033090673467

Epoch: 6| Step: 5
Training loss: 0.11305707693099976
Validation loss: 1.4825993212320472

Epoch: 6| Step: 6
Training loss: 0.09019220620393753
Validation loss: 1.4744370227218957

Epoch: 6| Step: 7
Training loss: 0.06762958317995071
Validation loss: 1.472805461575908

Epoch: 6| Step: 8
Training loss: 0.07534883916378021
Validation loss: 1.4603174642849994

Epoch: 6| Step: 9
Training loss: 0.10338214784860611
Validation loss: 1.4709673927676292

Epoch: 6| Step: 10
Training loss: 0.05192835256457329
Validation loss: 1.447390894736013

Epoch: 6| Step: 11
Training loss: 0.047603897750377655
Validation loss: 1.4228027943641908

Epoch: 6| Step: 12
Training loss: 0.0661400556564331
Validation loss: 1.4575294922756892

Epoch: 6| Step: 13
Training loss: 0.05756086856126785
Validation loss: 1.44068451850645

Epoch: 549| Step: 0
Training loss: 0.08680349588394165
Validation loss: 1.451013021571662

Epoch: 6| Step: 1
Training loss: 0.06737032532691956
Validation loss: 1.4423307629041775

Epoch: 6| Step: 2
Training loss: 0.05542723461985588
Validation loss: 1.456477285713278

Epoch: 6| Step: 3
Training loss: 0.08775745332241058
Validation loss: 1.4554918222529913

Epoch: 6| Step: 4
Training loss: 0.049415282905101776
Validation loss: 1.4593627273395497

Epoch: 6| Step: 5
Training loss: 0.07176586985588074
Validation loss: 1.4887282053629558

Epoch: 6| Step: 6
Training loss: 0.04516908526420593
Validation loss: 1.4681571978394703

Epoch: 6| Step: 7
Training loss: 0.13065482676029205
Validation loss: 1.4716929774130545

Epoch: 6| Step: 8
Training loss: 0.06341354548931122
Validation loss: 1.4894843793684436

Epoch: 6| Step: 9
Training loss: 0.06165393814444542
Validation loss: 1.469689837066076

Epoch: 6| Step: 10
Training loss: 0.057585716247558594
Validation loss: 1.4443628390630086

Epoch: 6| Step: 11
Training loss: 0.06416550278663635
Validation loss: 1.4434990267599783

Epoch: 6| Step: 12
Training loss: 0.06901860237121582
Validation loss: 1.4646179893965363

Epoch: 6| Step: 13
Training loss: 0.10445535182952881
Validation loss: 1.4377794874611722

Epoch: 550| Step: 0
Training loss: 0.06519822776317596
Validation loss: 1.4496138185583136

Epoch: 6| Step: 1
Training loss: 0.0771583616733551
Validation loss: 1.4552604344583326

Epoch: 6| Step: 2
Training loss: 0.08573095500469208
Validation loss: 1.4629636233852756

Epoch: 6| Step: 3
Training loss: 0.07068862020969391
Validation loss: 1.454123471372871

Epoch: 6| Step: 4
Training loss: 0.07786628603935242
Validation loss: 1.4624402241040302

Epoch: 6| Step: 5
Training loss: 0.08830325305461884
Validation loss: 1.4471426984315277

Epoch: 6| Step: 6
Training loss: 0.1028124988079071
Validation loss: 1.4564721558683662

Epoch: 6| Step: 7
Training loss: 0.05454782396554947
Validation loss: 1.4422027628908876

Epoch: 6| Step: 8
Training loss: 0.08353149145841599
Validation loss: 1.4430734444690008

Epoch: 6| Step: 9
Training loss: 0.08548645675182343
Validation loss: 1.4636318388805594

Epoch: 6| Step: 10
Training loss: 0.07334759086370468
Validation loss: 1.4469357434139456

Epoch: 6| Step: 11
Training loss: 0.04517963528633118
Validation loss: 1.4516668999066917

Epoch: 6| Step: 12
Training loss: 0.047821253538131714
Validation loss: 1.4662407623824252

Epoch: 6| Step: 13
Training loss: 0.051672130823135376
Validation loss: 1.4672093827237365

Testing loss: 2.107757870356242
