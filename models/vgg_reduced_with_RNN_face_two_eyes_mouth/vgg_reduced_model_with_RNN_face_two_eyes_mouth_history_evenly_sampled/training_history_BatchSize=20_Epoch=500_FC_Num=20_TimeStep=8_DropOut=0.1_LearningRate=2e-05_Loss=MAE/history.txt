Epoch: 1| Step: 0
Training loss: 4.515888214111328
Validation loss: 5.122561562445856

Epoch: 5| Step: 1
Training loss: 5.124314785003662
Validation loss: 5.098460638394919

Epoch: 5| Step: 2
Training loss: 5.216207027435303
Validation loss: 5.0749258277236775

Epoch: 5| Step: 3
Training loss: 5.065848350524902
Validation loss: 5.049435897540021

Epoch: 5| Step: 4
Training loss: 4.706087589263916
Validation loss: 5.020359987853675

Epoch: 5| Step: 5
Training loss: 5.144782543182373
Validation loss: 4.986419303442842

Epoch: 5| Step: 6
Training loss: 4.255215644836426
Validation loss: 4.948952951738911

Epoch: 5| Step: 7
Training loss: 4.665948390960693
Validation loss: 4.905368410130983

Epoch: 5| Step: 8
Training loss: 3.5936572551727295
Validation loss: 4.8559415314787175

Epoch: 5| Step: 9
Training loss: 5.616887092590332
Validation loss: 4.80092038390457

Epoch: 5| Step: 10
Training loss: 4.339329719543457
Validation loss: 4.73893056890016

Epoch: 2| Step: 0
Training loss: 4.400495529174805
Validation loss: 4.6716977909047115

Epoch: 5| Step: 1
Training loss: 4.795472145080566
Validation loss: 4.598418851052561

Epoch: 5| Step: 2
Training loss: 5.660939693450928
Validation loss: 4.519872660277992

Epoch: 5| Step: 3
Training loss: 4.314413070678711
Validation loss: 4.435186345090148

Epoch: 5| Step: 4
Training loss: 4.649877071380615
Validation loss: 4.350913506682201

Epoch: 5| Step: 5
Training loss: 3.979895830154419
Validation loss: 4.263446043896419

Epoch: 5| Step: 6
Training loss: 3.665449857711792
Validation loss: 4.177995784308321

Epoch: 5| Step: 7
Training loss: 3.7454140186309814
Validation loss: 4.090081307195848

Epoch: 5| Step: 8
Training loss: 3.802079439163208
Validation loss: 4.003500028323102

Epoch: 5| Step: 9
Training loss: 3.0092360973358154
Validation loss: 3.9172735393688245

Epoch: 5| Step: 10
Training loss: 2.7397353649139404
Validation loss: 3.840747574324249

Epoch: 3| Step: 0
Training loss: 3.7651443481445312
Validation loss: 3.769242743010162

Epoch: 5| Step: 1
Training loss: 3.741013765335083
Validation loss: 3.7102184039290234

Epoch: 5| Step: 2
Training loss: 3.446592330932617
Validation loss: 3.6564121912884455

Epoch: 5| Step: 3
Training loss: 3.348684787750244
Validation loss: 3.6086870521627445

Epoch: 5| Step: 4
Training loss: 3.4175143241882324
Validation loss: 3.5639437552421325

Epoch: 5| Step: 5
Training loss: 3.2408039569854736
Validation loss: 3.525272000220514

Epoch: 5| Step: 6
Training loss: 3.750148057937622
Validation loss: 3.4930885940469723

Epoch: 5| Step: 7
Training loss: 2.5697102546691895
Validation loss: 3.4634186939526628

Epoch: 5| Step: 8
Training loss: 4.098509788513184
Validation loss: 3.4333491069014355

Epoch: 5| Step: 9
Training loss: 3.9946224689483643
Validation loss: 3.404282869831208

Epoch: 5| Step: 10
Training loss: 2.7353596687316895
Validation loss: 3.3796587349266134

Epoch: 4| Step: 0
Training loss: 4.2111029624938965
Validation loss: 3.3508646718917356

Epoch: 5| Step: 1
Training loss: 3.0101263523101807
Validation loss: 3.3226637558270524

Epoch: 5| Step: 2
Training loss: 2.136430263519287
Validation loss: 3.3005229529514106

Epoch: 5| Step: 3
Training loss: 3.2518844604492188
Validation loss: 3.281798683187013

Epoch: 5| Step: 4
Training loss: 3.5689525604248047
Validation loss: 3.2656109820130053

Epoch: 5| Step: 5
Training loss: 3.131945848464966
Validation loss: 3.245624965237033

Epoch: 5| Step: 6
Training loss: 4.222216606140137
Validation loss: 3.2220613161722818

Epoch: 5| Step: 7
Training loss: 3.1900625228881836
Validation loss: 3.195344791617445

Epoch: 5| Step: 8
Training loss: 2.978344440460205
Validation loss: 3.16967035108997

Epoch: 5| Step: 9
Training loss: 2.807668685913086
Validation loss: 3.1595613469359694

Epoch: 5| Step: 10
Training loss: 3.046069622039795
Validation loss: 3.129487932369273

Epoch: 5| Step: 0
Training loss: 2.557772636413574
Validation loss: 3.1117389022663073

Epoch: 5| Step: 1
Training loss: 2.6637156009674072
Validation loss: 3.097725775934035

Epoch: 5| Step: 2
Training loss: 3.843301773071289
Validation loss: 3.085466261832945

Epoch: 5| Step: 3
Training loss: 3.4354076385498047
Validation loss: 3.0726726901146675

Epoch: 5| Step: 4
Training loss: 2.806180477142334
Validation loss: 3.0603443884080455

Epoch: 5| Step: 5
Training loss: 3.1814773082733154
Validation loss: 3.0524429582780406

Epoch: 5| Step: 6
Training loss: 3.0646939277648926
Validation loss: 3.045774849512244

Epoch: 5| Step: 7
Training loss: 3.095329761505127
Validation loss: 3.035784354773901

Epoch: 5| Step: 8
Training loss: 2.9325530529022217
Validation loss: 3.0216675496870473

Epoch: 5| Step: 9
Training loss: 3.715791702270508
Validation loss: 2.9675762960987706

Epoch: 5| Step: 10
Training loss: 2.818894147872925
Validation loss: 2.9569372669343026

Epoch: 6| Step: 0
Training loss: 3.340672254562378
Validation loss: 2.9502681968032674

Epoch: 5| Step: 1
Training loss: 3.6493935585021973
Validation loss: 2.9421995583400933

Epoch: 5| Step: 2
Training loss: 2.1636435985565186
Validation loss: 2.9331453307982414

Epoch: 5| Step: 3
Training loss: 3.255096435546875
Validation loss: 2.927336303136682

Epoch: 5| Step: 4
Training loss: 2.457395315170288
Validation loss: 2.91537110523511

Epoch: 5| Step: 5
Training loss: 2.6188759803771973
Validation loss: 2.906401659852715

Epoch: 5| Step: 6
Training loss: 2.819610595703125
Validation loss: 2.899827382897818

Epoch: 5| Step: 7
Training loss: 2.4766287803649902
Validation loss: 2.8985312933562906

Epoch: 5| Step: 8
Training loss: 3.126085042953491
Validation loss: 2.8970935319059636

Epoch: 5| Step: 9
Training loss: 3.7361197471618652
Validation loss: 2.8862620425480667

Epoch: 5| Step: 10
Training loss: 3.562709093093872
Validation loss: 2.8732169289742746

Epoch: 7| Step: 0
Training loss: 2.5515799522399902
Validation loss: 2.8668176281836724

Epoch: 5| Step: 1
Training loss: 3.4402899742126465
Validation loss: 2.855383701221917

Epoch: 5| Step: 2
Training loss: 2.7277579307556152
Validation loss: 2.8502570480428715

Epoch: 5| Step: 3
Training loss: 3.1376397609710693
Validation loss: 2.8426773419944187

Epoch: 5| Step: 4
Training loss: 2.8242201805114746
Validation loss: 2.833361300089026

Epoch: 5| Step: 5
Training loss: 3.092836618423462
Validation loss: 2.8237351409850584

Epoch: 5| Step: 6
Training loss: 2.312997817993164
Validation loss: 2.821825963194652

Epoch: 5| Step: 7
Training loss: 2.8682351112365723
Validation loss: 2.860923659416937

Epoch: 5| Step: 8
Training loss: 2.9481358528137207
Validation loss: 2.8525663986000964

Epoch: 5| Step: 9
Training loss: 3.447722911834717
Validation loss: 2.8178182289164555

Epoch: 5| Step: 10
Training loss: 3.2450480461120605
Validation loss: 2.7837919086538334

Epoch: 8| Step: 0
Training loss: 2.8696415424346924
Validation loss: 2.7928491741098385

Epoch: 5| Step: 1
Training loss: 2.4416441917419434
Validation loss: 2.8261950682568293

Epoch: 5| Step: 2
Training loss: 2.5201778411865234
Validation loss: 2.8038808504740396

Epoch: 5| Step: 3
Training loss: 3.3651821613311768
Validation loss: 2.804120745710147

Epoch: 5| Step: 4
Training loss: 3.1468780040740967
Validation loss: 2.792078833426199

Epoch: 5| Step: 5
Training loss: 2.7318224906921387
Validation loss: 2.7834783574586273

Epoch: 5| Step: 6
Training loss: 2.524536609649658
Validation loss: 2.767339006547005

Epoch: 5| Step: 7
Training loss: 3.549793243408203
Validation loss: 2.754631309099095

Epoch: 5| Step: 8
Training loss: 3.251659393310547
Validation loss: 2.7445354718033985

Epoch: 5| Step: 9
Training loss: 2.8311164379119873
Validation loss: 2.7367499182301183

Epoch: 5| Step: 10
Training loss: 2.8685388565063477
Validation loss: 2.7322986971947456

Epoch: 9| Step: 0
Training loss: 3.3053009510040283
Validation loss: 2.7255044829460884

Epoch: 5| Step: 1
Training loss: 2.802356243133545
Validation loss: 2.7172142844046316

Epoch: 5| Step: 2
Training loss: 3.9607415199279785
Validation loss: 2.7199042151051183

Epoch: 5| Step: 3
Training loss: 2.7221972942352295
Validation loss: 2.7070170999855123

Epoch: 5| Step: 4
Training loss: 2.729335069656372
Validation loss: 2.6961345518788984

Epoch: 5| Step: 5
Training loss: 2.1543807983398438
Validation loss: 2.6910593766038136

Epoch: 5| Step: 6
Training loss: 3.409287214279175
Validation loss: 2.6898285240255375

Epoch: 5| Step: 7
Training loss: 3.0532848834991455
Validation loss: 2.685920569204515

Epoch: 5| Step: 8
Training loss: 2.5472140312194824
Validation loss: 2.6917390336272535

Epoch: 5| Step: 9
Training loss: 2.3886020183563232
Validation loss: 2.6797404058517946

Epoch: 5| Step: 10
Training loss: 2.4463179111480713
Validation loss: 2.6762661677534862

Epoch: 10| Step: 0
Training loss: 2.8367888927459717
Validation loss: 2.6657998536222722

Epoch: 5| Step: 1
Training loss: 2.461796522140503
Validation loss: 2.656785349692068

Epoch: 5| Step: 2
Training loss: 2.723156690597534
Validation loss: 2.6489309880041305

Epoch: 5| Step: 3
Training loss: 3.323284864425659
Validation loss: 2.648197930346253

Epoch: 5| Step: 4
Training loss: 2.524975299835205
Validation loss: 2.6397137744452364

Epoch: 5| Step: 5
Training loss: 2.2621684074401855
Validation loss: 2.640248308899582

Epoch: 5| Step: 6
Training loss: 2.870800018310547
Validation loss: 2.635296752375941

Epoch: 5| Step: 7
Training loss: 3.260953903198242
Validation loss: 2.631151194213539

Epoch: 5| Step: 8
Training loss: 2.8927032947540283
Validation loss: 2.62833902143663

Epoch: 5| Step: 9
Training loss: 2.824028730392456
Validation loss: 2.6229991656477734

Epoch: 5| Step: 10
Training loss: 3.1867411136627197
Validation loss: 2.6177715947551112

Epoch: 11| Step: 0
Training loss: 2.6643149852752686
Validation loss: 2.6177695746062906

Epoch: 5| Step: 1
Training loss: 3.1850504875183105
Validation loss: 2.615075442098802

Epoch: 5| Step: 2
Training loss: 2.534302234649658
Validation loss: 2.6132224708475094

Epoch: 5| Step: 3
Training loss: 2.4624078273773193
Validation loss: 2.6105729354325162

Epoch: 5| Step: 4
Training loss: 2.867265224456787
Validation loss: 2.6033695820839173

Epoch: 5| Step: 5
Training loss: 2.8459832668304443
Validation loss: 2.5990741842536518

Epoch: 5| Step: 6
Training loss: 2.263575553894043
Validation loss: 2.5954753891114266

Epoch: 5| Step: 7
Training loss: 2.9757466316223145
Validation loss: 2.594455021683888

Epoch: 5| Step: 8
Training loss: 3.0774669647216797
Validation loss: 2.5892135532953406

Epoch: 5| Step: 9
Training loss: 3.4214138984680176
Validation loss: 2.589611902031847

Epoch: 5| Step: 10
Training loss: 2.538480520248413
Validation loss: 2.5829021059056765

Epoch: 12| Step: 0
Training loss: 2.7122511863708496
Validation loss: 2.5794776511448685

Epoch: 5| Step: 1
Training loss: 3.225836992263794
Validation loss: 2.575340429941813

Epoch: 5| Step: 2
Training loss: 2.519437313079834
Validation loss: 2.5735979798019573

Epoch: 5| Step: 3
Training loss: 2.474238157272339
Validation loss: 2.571937048307029

Epoch: 5| Step: 4
Training loss: 2.797961473464966
Validation loss: 2.5704017608396468

Epoch: 5| Step: 5
Training loss: 3.607372283935547
Validation loss: 2.5972300960171606

Epoch: 5| Step: 6
Training loss: 2.9854493141174316
Validation loss: 2.562106083798152

Epoch: 5| Step: 7
Training loss: 3.1663734912872314
Validation loss: 2.5738516699883247

Epoch: 5| Step: 8
Training loss: 2.4281229972839355
Validation loss: 2.5934764723623953

Epoch: 5| Step: 9
Training loss: 2.265288829803467
Validation loss: 2.6299810973546838

Epoch: 5| Step: 10
Training loss: 2.543579578399658
Validation loss: 2.655279944019933

Epoch: 13| Step: 0
Training loss: 4.066418647766113
Validation loss: 2.679500377306374

Epoch: 5| Step: 1
Training loss: 2.612596035003662
Validation loss: 2.6032148074078303

Epoch: 5| Step: 2
Training loss: 2.3979172706604004
Validation loss: 2.5784576862089095

Epoch: 5| Step: 3
Training loss: 2.631805658340454
Validation loss: 2.5711082899442284

Epoch: 5| Step: 4
Training loss: 2.8651015758514404
Validation loss: 2.5672136275999007

Epoch: 5| Step: 5
Training loss: 2.927100896835327
Validation loss: 2.5681683401907645

Epoch: 5| Step: 6
Training loss: 2.6676220893859863
Validation loss: 2.5663212678765737

Epoch: 5| Step: 7
Training loss: 2.287630081176758
Validation loss: 2.5655631711406093

Epoch: 5| Step: 8
Training loss: 3.1505978107452393
Validation loss: 2.5591519032755206

Epoch: 5| Step: 9
Training loss: 2.496558427810669
Validation loss: 2.5547561901871876

Epoch: 5| Step: 10
Training loss: 2.591642379760742
Validation loss: 2.5489824946208666

Epoch: 14| Step: 0
Training loss: 3.0331389904022217
Validation loss: 2.543864204037574

Epoch: 5| Step: 1
Training loss: 2.8066983222961426
Validation loss: 2.538549512945196

Epoch: 5| Step: 2
Training loss: 2.6318416595458984
Validation loss: 2.531965030136929

Epoch: 5| Step: 3
Training loss: 2.185830593109131
Validation loss: 2.5279317825071272

Epoch: 5| Step: 4
Training loss: 2.8859000205993652
Validation loss: 2.521550142636863

Epoch: 5| Step: 5
Training loss: 2.9435508251190186
Validation loss: 2.5215610816914547

Epoch: 5| Step: 6
Training loss: 2.7186570167541504
Validation loss: 2.5197863604432795

Epoch: 5| Step: 7
Training loss: 3.2149033546447754
Validation loss: 2.5194351365489345

Epoch: 5| Step: 8
Training loss: 2.2059333324432373
Validation loss: 2.5323344763889106

Epoch: 5| Step: 9
Training loss: 2.669618606567383
Validation loss: 2.534345357648788

Epoch: 5| Step: 10
Training loss: 3.0753185749053955
Validation loss: 2.542153461005098

Epoch: 15| Step: 0
Training loss: 2.635870933532715
Validation loss: 2.534181051356818

Epoch: 5| Step: 1
Training loss: 2.3509485721588135
Validation loss: 2.528931276772612

Epoch: 5| Step: 2
Training loss: 2.969198703765869
Validation loss: 2.519809179408576

Epoch: 5| Step: 3
Training loss: 2.612635374069214
Validation loss: 2.5171176977055048

Epoch: 5| Step: 4
Training loss: 2.3621931076049805
Validation loss: 2.5054028059846614

Epoch: 5| Step: 5
Training loss: 3.5061450004577637
Validation loss: 2.5002103774778304

Epoch: 5| Step: 6
Training loss: 2.5999059677124023
Validation loss: 2.5002838193729358

Epoch: 5| Step: 7
Training loss: 2.9390156269073486
Validation loss: 2.5041766833233576

Epoch: 5| Step: 8
Training loss: 2.8850185871124268
Validation loss: 2.513715003126411

Epoch: 5| Step: 9
Training loss: 2.8458921909332275
Validation loss: 2.5101100757557857

Epoch: 5| Step: 10
Training loss: 2.344194173812866
Validation loss: 2.4974997787065405

Epoch: 16| Step: 0
Training loss: 2.4987335205078125
Validation loss: 2.491708973402618

Epoch: 5| Step: 1
Training loss: 2.5026087760925293
Validation loss: 2.494181671450215

Epoch: 5| Step: 2
Training loss: 3.1466221809387207
Validation loss: 2.490605236381613

Epoch: 5| Step: 3
Training loss: 2.4440300464630127
Validation loss: 2.4846323459379134

Epoch: 5| Step: 4
Training loss: 2.755643844604492
Validation loss: 2.493070420398507

Epoch: 5| Step: 5
Training loss: 3.4636948108673096
Validation loss: 2.5110568487516014

Epoch: 5| Step: 6
Training loss: 2.557823657989502
Validation loss: 2.5471183151327152

Epoch: 5| Step: 7
Training loss: 2.86059308052063
Validation loss: 2.542254429991527

Epoch: 5| Step: 8
Training loss: 2.328402519226074
Validation loss: 2.5096497330614316

Epoch: 5| Step: 9
Training loss: 2.9943017959594727
Validation loss: 2.4903515538861676

Epoch: 5| Step: 10
Training loss: 2.416109800338745
Validation loss: 2.477357615706741

Epoch: 17| Step: 0
Training loss: 3.56391978263855
Validation loss: 2.4689096943024667

Epoch: 5| Step: 1
Training loss: 2.72753643989563
Validation loss: 2.491096681164157

Epoch: 5| Step: 2
Training loss: 2.6084461212158203
Validation loss: 2.4705831748183056

Epoch: 5| Step: 3
Training loss: 3.250760555267334
Validation loss: 2.468776418316749

Epoch: 5| Step: 4
Training loss: 3.231006145477295
Validation loss: 2.468754296661705

Epoch: 5| Step: 5
Training loss: 1.9058643579483032
Validation loss: 2.4789620958348757

Epoch: 5| Step: 6
Training loss: 3.085300922393799
Validation loss: 2.5104281594676356

Epoch: 5| Step: 7
Training loss: 2.594923257827759
Validation loss: 2.504150785425658

Epoch: 5| Step: 8
Training loss: 2.349310874938965
Validation loss: 2.4891608479202434

Epoch: 5| Step: 9
Training loss: 2.586505651473999
Validation loss: 2.4798448342148975

Epoch: 5| Step: 10
Training loss: 1.9714269638061523
Validation loss: 2.4672535465609644

Epoch: 18| Step: 0
Training loss: 1.6406421661376953
Validation loss: 2.4589601729505803

Epoch: 5| Step: 1
Training loss: 3.2332663536071777
Validation loss: 2.462714100396761

Epoch: 5| Step: 2
Training loss: 2.3231778144836426
Validation loss: 2.4564993586591495

Epoch: 5| Step: 3
Training loss: 3.1267566680908203
Validation loss: 2.454716820870676

Epoch: 5| Step: 4
Training loss: 2.715465784072876
Validation loss: 2.474315304909983

Epoch: 5| Step: 5
Training loss: 3.0829384326934814
Validation loss: 2.4818913398250455

Epoch: 5| Step: 6
Training loss: 3.1257667541503906
Validation loss: 2.4757713528089624

Epoch: 5| Step: 7
Training loss: 2.059436082839966
Validation loss: 2.4690773769091536

Epoch: 5| Step: 8
Training loss: 1.9786752462387085
Validation loss: 2.4604283814789145

Epoch: 5| Step: 9
Training loss: 3.2806522846221924
Validation loss: 2.4475478895248903

Epoch: 5| Step: 10
Training loss: 3.2746527194976807
Validation loss: 2.443046892842939

Epoch: 19| Step: 0
Training loss: 2.1487414836883545
Validation loss: 2.4470228738682245

Epoch: 5| Step: 1
Training loss: 2.55022931098938
Validation loss: 2.445672817127679

Epoch: 5| Step: 2
Training loss: 2.7559306621551514
Validation loss: 2.4452465298355266

Epoch: 5| Step: 3
Training loss: 3.0930867195129395
Validation loss: 2.4485202399633264

Epoch: 5| Step: 4
Training loss: 3.0952980518341064
Validation loss: 2.4434481872025358

Epoch: 5| Step: 5
Training loss: 2.4657161235809326
Validation loss: 2.441752992650514

Epoch: 5| Step: 6
Training loss: 2.955165386199951
Validation loss: 2.447510314244096

Epoch: 5| Step: 7
Training loss: 2.4177372455596924
Validation loss: 2.458433599882228

Epoch: 5| Step: 8
Training loss: 2.101407527923584
Validation loss: 2.4680421326750066

Epoch: 5| Step: 9
Training loss: 3.080598831176758
Validation loss: 2.5138165425228816

Epoch: 5| Step: 10
Training loss: 3.0231099128723145
Validation loss: 2.4927428153253373

Epoch: 20| Step: 0
Training loss: 3.3648438453674316
Validation loss: 2.478163347449354

Epoch: 5| Step: 1
Training loss: 2.7440314292907715
Validation loss: 2.4645089923694568

Epoch: 5| Step: 2
Training loss: 2.545686721801758
Validation loss: 2.444512200611894

Epoch: 5| Step: 3
Training loss: 2.6008336544036865
Validation loss: 2.4335702619244977

Epoch: 5| Step: 4
Training loss: 2.1966137886047363
Validation loss: 2.430843227653093

Epoch: 5| Step: 5
Training loss: 2.9752609729766846
Validation loss: 2.4248518354149273

Epoch: 5| Step: 6
Training loss: 2.9976589679718018
Validation loss: 2.4285484129382717

Epoch: 5| Step: 7
Training loss: 2.015780210494995
Validation loss: 2.4234092632929483

Epoch: 5| Step: 8
Training loss: 2.2406535148620605
Validation loss: 2.4347430813697075

Epoch: 5| Step: 9
Training loss: 3.263965606689453
Validation loss: 2.4519937525513353

Epoch: 5| Step: 10
Training loss: 2.612656593322754
Validation loss: 2.4632325697970647

Epoch: 21| Step: 0
Training loss: 2.758263349533081
Validation loss: 2.44610075284076

Epoch: 5| Step: 1
Training loss: 2.6029715538024902
Validation loss: 2.4266523417606147

Epoch: 5| Step: 2
Training loss: 2.4817862510681152
Validation loss: 2.4292996314264115

Epoch: 5| Step: 3
Training loss: 3.3969714641571045
Validation loss: 2.4315062517760904

Epoch: 5| Step: 4
Training loss: 3.4916443824768066
Validation loss: 2.443913362359488

Epoch: 5| Step: 5
Training loss: 2.999061107635498
Validation loss: 2.4382166836851384

Epoch: 5| Step: 6
Training loss: 2.2513935565948486
Validation loss: 2.4267123181332826

Epoch: 5| Step: 7
Training loss: 2.3538506031036377
Validation loss: 2.43870315500485

Epoch: 5| Step: 8
Training loss: 2.2520852088928223
Validation loss: 2.4582511737782466

Epoch: 5| Step: 9
Training loss: 2.335510730743408
Validation loss: 2.5133063408636276

Epoch: 5| Step: 10
Training loss: 2.582261323928833
Validation loss: 2.5278008548162316

Epoch: 22| Step: 0
Training loss: 2.2049601078033447
Validation loss: 2.5623398057876097

Epoch: 5| Step: 1
Training loss: 3.190371036529541
Validation loss: 2.546856446932721

Epoch: 5| Step: 2
Training loss: 2.567124843597412
Validation loss: 2.492326572377195

Epoch: 5| Step: 3
Training loss: 2.5817883014678955
Validation loss: 2.4633009651655793

Epoch: 5| Step: 4
Training loss: 2.9133667945861816
Validation loss: 2.457669693936584

Epoch: 5| Step: 5
Training loss: 2.719322681427002
Validation loss: 2.4505416526589343

Epoch: 5| Step: 6
Training loss: 2.7832889556884766
Validation loss: 2.4442126981673704

Epoch: 5| Step: 7
Training loss: 2.9101054668426514
Validation loss: 2.432802761754682

Epoch: 5| Step: 8
Training loss: 2.2130768299102783
Validation loss: 2.4279387176677747

Epoch: 5| Step: 9
Training loss: 2.9677603244781494
Validation loss: 2.4235265870248117

Epoch: 5| Step: 10
Training loss: 2.424093246459961
Validation loss: 2.4225777784983316

Epoch: 23| Step: 0
Training loss: 2.997760772705078
Validation loss: 2.425916597407351

Epoch: 5| Step: 1
Training loss: 2.476714849472046
Validation loss: 2.4221752048820577

Epoch: 5| Step: 2
Training loss: 2.488640785217285
Validation loss: 2.4320819506081204

Epoch: 5| Step: 3
Training loss: 2.3400328159332275
Validation loss: 2.4354286783485004

Epoch: 5| Step: 4
Training loss: 2.8137688636779785
Validation loss: 2.440483572662518

Epoch: 5| Step: 5
Training loss: 3.0121123790740967
Validation loss: 2.430333452840005

Epoch: 5| Step: 6
Training loss: 2.728768825531006
Validation loss: 2.4288088634449947

Epoch: 5| Step: 7
Training loss: 2.6899847984313965
Validation loss: 2.44397000856297

Epoch: 5| Step: 8
Training loss: 2.627244472503662
Validation loss: 2.4297568387882684

Epoch: 5| Step: 9
Training loss: 2.5557332038879395
Validation loss: 2.4258246037267868

Epoch: 5| Step: 10
Training loss: 2.664851188659668
Validation loss: 2.417884293422904

Epoch: 24| Step: 0
Training loss: 2.763666868209839
Validation loss: 2.422186302882369

Epoch: 5| Step: 1
Training loss: 2.872821092605591
Validation loss: 2.441178088547081

Epoch: 5| Step: 2
Training loss: 2.6001038551330566
Validation loss: 2.4546864289109425

Epoch: 5| Step: 3
Training loss: 2.9195175170898438
Validation loss: 2.4635981385425856

Epoch: 5| Step: 4
Training loss: 2.9949984550476074
Validation loss: 2.4522041864292596

Epoch: 5| Step: 5
Training loss: 3.0183584690093994
Validation loss: 2.42293740600668

Epoch: 5| Step: 6
Training loss: 2.2306933403015137
Validation loss: 2.401748784126774

Epoch: 5| Step: 7
Training loss: 2.6577348709106445
Validation loss: 2.4023822943369546

Epoch: 5| Step: 8
Training loss: 2.588315486907959
Validation loss: 2.401426997236026

Epoch: 5| Step: 9
Training loss: 2.283663272857666
Validation loss: 2.405562952000608

Epoch: 5| Step: 10
Training loss: 2.411489486694336
Validation loss: 2.405540358635687

Epoch: 25| Step: 0
Training loss: 2.548588991165161
Validation loss: 2.4048350511058683

Epoch: 5| Step: 1
Training loss: 2.914428234100342
Validation loss: 2.4044191914220012

Epoch: 5| Step: 2
Training loss: 2.5896248817443848
Validation loss: 2.4022536354680217

Epoch: 5| Step: 3
Training loss: 3.0659329891204834
Validation loss: 2.4046828592977216

Epoch: 5| Step: 4
Training loss: 1.3135629892349243
Validation loss: 2.4104645508591847

Epoch: 5| Step: 5
Training loss: 3.3847765922546387
Validation loss: 2.4163243732144757

Epoch: 5| Step: 6
Training loss: 3.082282066345215
Validation loss: 2.4374567642006824

Epoch: 5| Step: 7
Training loss: 2.903571605682373
Validation loss: 2.451208027460242

Epoch: 5| Step: 8
Training loss: 2.3253254890441895
Validation loss: 2.4546452978605866

Epoch: 5| Step: 9
Training loss: 2.737581968307495
Validation loss: 2.4393739982317855

Epoch: 5| Step: 10
Training loss: 2.486734628677368
Validation loss: 2.432765542819936

Epoch: 26| Step: 0
Training loss: 3.192394256591797
Validation loss: 2.4227219089385

Epoch: 5| Step: 1
Training loss: 2.373002529144287
Validation loss: 2.4143175873705136

Epoch: 5| Step: 2
Training loss: 3.128042221069336
Validation loss: 2.4044006691184094

Epoch: 5| Step: 3
Training loss: 2.5794410705566406
Validation loss: 2.3952423859668035

Epoch: 5| Step: 4
Training loss: 2.6198697090148926
Validation loss: 2.3924162695484776

Epoch: 5| Step: 5
Training loss: 2.4800496101379395
Validation loss: 2.390871960629699

Epoch: 5| Step: 6
Training loss: 2.44538950920105
Validation loss: 2.3945657873666413

Epoch: 5| Step: 7
Training loss: 2.6975152492523193
Validation loss: 2.400134409627607

Epoch: 5| Step: 8
Training loss: 2.621229887008667
Validation loss: 2.4293151337613343

Epoch: 5| Step: 9
Training loss: 2.5467731952667236
Validation loss: 2.4413151587209394

Epoch: 5| Step: 10
Training loss: 2.4345638751983643
Validation loss: 2.454497168141027

Epoch: 27| Step: 0
Training loss: 2.3902852535247803
Validation loss: 2.4382444171495337

Epoch: 5| Step: 1
Training loss: 2.905714511871338
Validation loss: 2.4261040559379

Epoch: 5| Step: 2
Training loss: 2.4671578407287598
Validation loss: 2.3906685511271157

Epoch: 5| Step: 3
Training loss: 3.1996140480041504
Validation loss: 2.381659456478652

Epoch: 5| Step: 4
Training loss: 3.1389572620391846
Validation loss: 2.3826745530610443

Epoch: 5| Step: 5
Training loss: 2.0549628734588623
Validation loss: 2.377224865780082

Epoch: 5| Step: 6
Training loss: 2.834503412246704
Validation loss: 2.3916093854493994

Epoch: 5| Step: 7
Training loss: 2.840290069580078
Validation loss: 2.3928098832407305

Epoch: 5| Step: 8
Training loss: 2.424654245376587
Validation loss: 2.380484765575778

Epoch: 5| Step: 9
Training loss: 2.2744743824005127
Validation loss: 2.373604682184035

Epoch: 5| Step: 10
Training loss: 2.7332587242126465
Validation loss: 2.3758242796826106

Epoch: 28| Step: 0
Training loss: 2.9334731101989746
Validation loss: 2.378960899127427

Epoch: 5| Step: 1
Training loss: 2.7432849407196045
Validation loss: 2.3768294113938526

Epoch: 5| Step: 2
Training loss: 3.071056842803955
Validation loss: 2.376613078578826

Epoch: 5| Step: 3
Training loss: 1.8275375366210938
Validation loss: 2.388961427955217

Epoch: 5| Step: 4
Training loss: 2.970689296722412
Validation loss: 2.391361323736047

Epoch: 5| Step: 5
Training loss: 2.9966373443603516
Validation loss: 2.4146641941480738

Epoch: 5| Step: 6
Training loss: 3.1045730113983154
Validation loss: 2.460245486228697

Epoch: 5| Step: 7
Training loss: 2.5093071460723877
Validation loss: 2.454005477248981

Epoch: 5| Step: 8
Training loss: 2.60235857963562
Validation loss: 2.444782926190284

Epoch: 5| Step: 9
Training loss: 1.753289818763733
Validation loss: 2.4047067088465535

Epoch: 5| Step: 10
Training loss: 2.7015600204467773
Validation loss: 2.3850685396502094

Epoch: 29| Step: 0
Training loss: 2.8210501670837402
Validation loss: 2.378469544072305

Epoch: 5| Step: 1
Training loss: 2.2032361030578613
Validation loss: 2.3698473463776293

Epoch: 5| Step: 2
Training loss: 2.6313881874084473
Validation loss: 2.3594945425628335

Epoch: 5| Step: 3
Training loss: 2.4118573665618896
Validation loss: 2.356446066210347

Epoch: 5| Step: 4
Training loss: 3.0381603240966797
Validation loss: 2.3539805258474042

Epoch: 5| Step: 5
Training loss: 3.2705795764923096
Validation loss: 2.3629062252659954

Epoch: 5| Step: 6
Training loss: 2.7472476959228516
Validation loss: 2.3758000135421753

Epoch: 5| Step: 7
Training loss: 1.7502591609954834
Validation loss: 2.396207812011883

Epoch: 5| Step: 8
Training loss: 2.382678508758545
Validation loss: 2.4242479314086256

Epoch: 5| Step: 9
Training loss: 2.6620967388153076
Validation loss: 2.454047287664106

Epoch: 5| Step: 10
Training loss: 3.3623931407928467
Validation loss: 2.425355206253708

Epoch: 30| Step: 0
Training loss: 2.898425579071045
Validation loss: 2.3874439436902284

Epoch: 5| Step: 1
Training loss: 2.517016649246216
Validation loss: 2.3659580446058706

Epoch: 5| Step: 2
Training loss: 2.9485247135162354
Validation loss: 2.3518672707260295

Epoch: 5| Step: 3
Training loss: 2.563723564147949
Validation loss: 2.350193187754641

Epoch: 5| Step: 4
Training loss: 2.4236068725585938
Validation loss: 2.357499317456317

Epoch: 5| Step: 5
Training loss: 2.7464442253112793
Validation loss: 2.366775738295688

Epoch: 5| Step: 6
Training loss: 2.3240699768066406
Validation loss: 2.366396209245087

Epoch: 5| Step: 7
Training loss: 3.1102638244628906
Validation loss: 2.3614767059203117

Epoch: 5| Step: 8
Training loss: 2.484764337539673
Validation loss: 2.355649781483476

Epoch: 5| Step: 9
Training loss: 2.4739439487457275
Validation loss: 2.345938305700979

Epoch: 5| Step: 10
Training loss: 2.6438145637512207
Validation loss: 2.33731411862117

Epoch: 31| Step: 0
Training loss: 2.049572229385376
Validation loss: 2.341577778580368

Epoch: 5| Step: 1
Training loss: 2.928933620452881
Validation loss: 2.3530838233168407

Epoch: 5| Step: 2
Training loss: 3.0352590084075928
Validation loss: 2.360138952091176

Epoch: 5| Step: 3
Training loss: 3.2704787254333496
Validation loss: 2.355631207907072

Epoch: 5| Step: 4
Training loss: 2.424778461456299
Validation loss: 2.347124671423307

Epoch: 5| Step: 5
Training loss: 2.1603472232818604
Validation loss: 2.342775342284992

Epoch: 5| Step: 6
Training loss: 3.0591633319854736
Validation loss: 2.3373679166199057

Epoch: 5| Step: 7
Training loss: 2.6248583793640137
Validation loss: 2.3345158997402398

Epoch: 5| Step: 8
Training loss: 1.6495425701141357
Validation loss: 2.3375679036622405

Epoch: 5| Step: 9
Training loss: 3.104539394378662
Validation loss: 2.338187321539848

Epoch: 5| Step: 10
Training loss: 2.5175278186798096
Validation loss: 2.33775064509402

Epoch: 32| Step: 0
Training loss: 2.6149909496307373
Validation loss: 2.3446672834375852

Epoch: 5| Step: 1
Training loss: 2.385831832885742
Validation loss: 2.346315863311932

Epoch: 5| Step: 2
Training loss: 2.335814952850342
Validation loss: 2.344098839708554

Epoch: 5| Step: 3
Training loss: 2.8117263317108154
Validation loss: 2.3439439753050446

Epoch: 5| Step: 4
Training loss: 2.4564995765686035
Validation loss: 2.3426690704079083

Epoch: 5| Step: 5
Training loss: 2.525373697280884
Validation loss: 2.3378339608510337

Epoch: 5| Step: 6
Training loss: 2.763439655303955
Validation loss: 2.3382699566502727

Epoch: 5| Step: 7
Training loss: 2.157630443572998
Validation loss: 2.3454936294145483

Epoch: 5| Step: 8
Training loss: 3.8002333641052246
Validation loss: 2.3698785920296945

Epoch: 5| Step: 9
Training loss: 2.80057692527771
Validation loss: 2.3686907932322514

Epoch: 5| Step: 10
Training loss: 2.165058135986328
Validation loss: 2.3577284992382093

Epoch: 33| Step: 0
Training loss: 2.9647231101989746
Validation loss: 2.3547346079221336

Epoch: 5| Step: 1
Training loss: 1.9667789936065674
Validation loss: 2.347370151550539

Epoch: 5| Step: 2
Training loss: 3.014896869659424
Validation loss: 2.337379611948485

Epoch: 5| Step: 3
Training loss: 2.6921513080596924
Validation loss: 2.331047647742815

Epoch: 5| Step: 4
Training loss: 2.1029460430145264
Validation loss: 2.324604683024909

Epoch: 5| Step: 5
Training loss: 3.0863196849823
Validation loss: 2.337301746491463

Epoch: 5| Step: 6
Training loss: 2.3382973670959473
Validation loss: 2.3359950639868297

Epoch: 5| Step: 7
Training loss: 2.2993578910827637
Validation loss: 2.3395001324274207

Epoch: 5| Step: 8
Training loss: 2.592755079269409
Validation loss: 2.3421848794465423

Epoch: 5| Step: 9
Training loss: 2.6008453369140625
Validation loss: 2.3402771744676816

Epoch: 5| Step: 10
Training loss: 3.0754334926605225
Validation loss: 2.3310722894566034

Epoch: 34| Step: 0
Training loss: 3.0274956226348877
Validation loss: 2.3329280525125484

Epoch: 5| Step: 1
Training loss: 2.388380765914917
Validation loss: 2.332548767007807

Epoch: 5| Step: 2
Training loss: 2.843925714492798
Validation loss: 2.3272030481728176

Epoch: 5| Step: 3
Training loss: 2.361600399017334
Validation loss: 2.3234612557195846

Epoch: 5| Step: 4
Training loss: 2.2228684425354004
Validation loss: 2.3234664458100514

Epoch: 5| Step: 5
Training loss: 2.595674753189087
Validation loss: 2.3282367978044736

Epoch: 5| Step: 6
Training loss: 2.4425036907196045
Validation loss: 2.3412875872786327

Epoch: 5| Step: 7
Training loss: 3.227926254272461
Validation loss: 2.3463010172690115

Epoch: 5| Step: 8
Training loss: 2.9464774131774902
Validation loss: 2.344055237308625

Epoch: 5| Step: 9
Training loss: 1.906158685684204
Validation loss: 2.3672875717122066

Epoch: 5| Step: 10
Training loss: 2.678128242492676
Validation loss: 2.408320293631605

Epoch: 35| Step: 0
Training loss: 2.677316188812256
Validation loss: 2.4177557063359085

Epoch: 5| Step: 1
Training loss: 2.5210838317871094
Validation loss: 2.3941570046127483

Epoch: 5| Step: 2
Training loss: 2.4006869792938232
Validation loss: 2.3878755954004105

Epoch: 5| Step: 3
Training loss: 2.9177560806274414
Validation loss: 2.3848134112614456

Epoch: 5| Step: 4
Training loss: 1.96340012550354
Validation loss: 2.39571229873165

Epoch: 5| Step: 5
Training loss: 2.4962306022644043
Validation loss: 2.4306710304752475

Epoch: 5| Step: 6
Training loss: 2.571157932281494
Validation loss: 2.438194492811798

Epoch: 5| Step: 7
Training loss: 2.754892587661743
Validation loss: 2.4314084591404086

Epoch: 5| Step: 8
Training loss: 3.4930636882781982
Validation loss: 2.42392820953041

Epoch: 5| Step: 9
Training loss: 2.603799819946289
Validation loss: 2.4214418626600698

Epoch: 5| Step: 10
Training loss: 2.470182180404663
Validation loss: 2.420916111238541

Epoch: 36| Step: 0
Training loss: 2.643315076828003
Validation loss: 2.387303331846832

Epoch: 5| Step: 1
Training loss: 2.0324254035949707
Validation loss: 2.3556626278867006

Epoch: 5| Step: 2
Training loss: 2.4799628257751465
Validation loss: 2.345442388647346

Epoch: 5| Step: 3
Training loss: 2.58317494392395
Validation loss: 2.3408278060215775

Epoch: 5| Step: 4
Training loss: 2.36358642578125
Validation loss: 2.3270830646637948

Epoch: 5| Step: 5
Training loss: 2.8360962867736816
Validation loss: 2.3289370664986233

Epoch: 5| Step: 6
Training loss: 2.621779680252075
Validation loss: 2.3181336797693723

Epoch: 5| Step: 7
Training loss: 2.897075891494751
Validation loss: 2.321598126042274

Epoch: 5| Step: 8
Training loss: 2.8181521892547607
Validation loss: 2.3294564318913284

Epoch: 5| Step: 9
Training loss: 2.350870132446289
Validation loss: 2.325140563390588

Epoch: 5| Step: 10
Training loss: 3.129232406616211
Validation loss: 2.3393276019762923

Epoch: 37| Step: 0
Training loss: 2.471662998199463
Validation loss: 2.3676573512374715

Epoch: 5| Step: 1
Training loss: 2.505631685256958
Validation loss: 2.3890352915692072

Epoch: 5| Step: 2
Training loss: 3.0779690742492676
Validation loss: 2.422933909200853

Epoch: 5| Step: 3
Training loss: 2.5154757499694824
Validation loss: 2.4400370146638606

Epoch: 5| Step: 4
Training loss: 2.826986312866211
Validation loss: 2.442249095568093

Epoch: 5| Step: 5
Training loss: 2.5858283042907715
Validation loss: 2.3850706136354836

Epoch: 5| Step: 6
Training loss: 2.3796417713165283
Validation loss: 2.3567127284183296

Epoch: 5| Step: 7
Training loss: 2.744155168533325
Validation loss: 2.351918661466209

Epoch: 5| Step: 8
Training loss: 3.0737204551696777
Validation loss: 2.376520187624039

Epoch: 5| Step: 9
Training loss: 2.490502119064331
Validation loss: 2.3256062435847458

Epoch: 5| Step: 10
Training loss: 2.4072883129119873
Validation loss: 2.3142891750540784

Epoch: 38| Step: 0
Training loss: 3.2786850929260254
Validation loss: 2.3092726661312963

Epoch: 5| Step: 1
Training loss: 2.7626466751098633
Validation loss: 2.307059375188684

Epoch: 5| Step: 2
Training loss: 2.593383550643921
Validation loss: 2.304679197649802

Epoch: 5| Step: 3
Training loss: 2.1216933727264404
Validation loss: 2.2978068910619265

Epoch: 5| Step: 4
Training loss: 2.0507397651672363
Validation loss: 2.298977836485832

Epoch: 5| Step: 5
Training loss: 2.5915637016296387
Validation loss: 2.315606729958647

Epoch: 5| Step: 6
Training loss: 2.7434256076812744
Validation loss: 2.3516104016252743

Epoch: 5| Step: 7
Training loss: 2.1897382736206055
Validation loss: 2.3607361470499346

Epoch: 5| Step: 8
Training loss: 2.8025074005126953
Validation loss: 2.3863936649855746

Epoch: 5| Step: 9
Training loss: 2.750182628631592
Validation loss: 2.4120803443334435

Epoch: 5| Step: 10
Training loss: 2.9065115451812744
Validation loss: 2.4119266515137046

Epoch: 39| Step: 0
Training loss: 2.56359601020813
Validation loss: 2.3955073536083265

Epoch: 5| Step: 1
Training loss: 2.472334861755371
Validation loss: 2.383773188437185

Epoch: 5| Step: 2
Training loss: 2.9845898151397705
Validation loss: 2.405751043750394

Epoch: 5| Step: 3
Training loss: 2.549081325531006
Validation loss: 2.4136298830791185

Epoch: 5| Step: 4
Training loss: 2.1388630867004395
Validation loss: 2.408638608071112

Epoch: 5| Step: 5
Training loss: 2.746368885040283
Validation loss: 2.3896595047366236

Epoch: 5| Step: 6
Training loss: 2.7636499404907227
Validation loss: 2.364373980029937

Epoch: 5| Step: 7
Training loss: 2.903719186782837
Validation loss: 2.3245996070164505

Epoch: 5| Step: 8
Training loss: 2.074709892272949
Validation loss: 2.3036217561332126

Epoch: 5| Step: 9
Training loss: 2.1915993690490723
Validation loss: 2.2944172710500736

Epoch: 5| Step: 10
Training loss: 3.1355273723602295
Validation loss: 2.3067740906951246

Epoch: 40| Step: 0
Training loss: 2.087278366088867
Validation loss: 2.312808818714593

Epoch: 5| Step: 1
Training loss: 2.812412738800049
Validation loss: 2.3258866135792067

Epoch: 5| Step: 2
Training loss: 3.492398500442505
Validation loss: 2.341059297643682

Epoch: 5| Step: 3
Training loss: 2.619232177734375
Validation loss: 2.3376876487526843

Epoch: 5| Step: 4
Training loss: 2.9795331954956055
Validation loss: 2.338249919235065

Epoch: 5| Step: 5
Training loss: 2.657306671142578
Validation loss: 2.329147900304487

Epoch: 5| Step: 6
Training loss: 2.568108320236206
Validation loss: 2.3082918197877946

Epoch: 5| Step: 7
Training loss: 2.498863458633423
Validation loss: 2.300274028572985

Epoch: 5| Step: 8
Training loss: 2.204843521118164
Validation loss: 2.2978467595192695

Epoch: 5| Step: 9
Training loss: 2.560333728790283
Validation loss: 2.3024526719124085

Epoch: 5| Step: 10
Training loss: 2.4766595363616943
Validation loss: 2.3253789640242055

Epoch: 41| Step: 0
Training loss: 3.0315043926239014
Validation loss: 2.3556897306954987

Epoch: 5| Step: 1
Training loss: 3.0979044437408447
Validation loss: 2.368837835968182

Epoch: 5| Step: 2
Training loss: 2.604102849960327
Validation loss: 2.415486246026972

Epoch: 5| Step: 3
Training loss: 3.330420970916748
Validation loss: 2.40878818368399

Epoch: 5| Step: 4
Training loss: 1.9418118000030518
Validation loss: 2.384591382036927

Epoch: 5| Step: 5
Training loss: 2.5918288230895996
Validation loss: 2.3585927999147804

Epoch: 5| Step: 6
Training loss: 1.986608862876892
Validation loss: 2.3265772814391763

Epoch: 5| Step: 7
Training loss: 2.4206652641296387
Validation loss: 2.298935203142064

Epoch: 5| Step: 8
Training loss: 2.6773018836975098
Validation loss: 2.300379832585653

Epoch: 5| Step: 9
Training loss: 2.310349702835083
Validation loss: 2.301932461800114

Epoch: 5| Step: 10
Training loss: 2.641834020614624
Validation loss: 2.2897957550582064

Epoch: 42| Step: 0
Training loss: 2.075397491455078
Validation loss: 2.2888885287828344

Epoch: 5| Step: 1
Training loss: 2.4916393756866455
Validation loss: 2.2816279319024857

Epoch: 5| Step: 2
Training loss: 3.084746837615967
Validation loss: 2.2790876793605026

Epoch: 5| Step: 3
Training loss: 2.6386876106262207
Validation loss: 2.2975584383933776

Epoch: 5| Step: 4
Training loss: 2.4912335872650146
Validation loss: 2.31395830903002

Epoch: 5| Step: 5
Training loss: 2.025847911834717
Validation loss: 2.3332081571702035

Epoch: 5| Step: 6
Training loss: 1.9329465627670288
Validation loss: 2.353825379443425

Epoch: 5| Step: 7
Training loss: 2.856492280960083
Validation loss: 2.3418320571222613

Epoch: 5| Step: 8
Training loss: 3.021879196166992
Validation loss: 2.313583904697049

Epoch: 5| Step: 9
Training loss: 3.1191697120666504
Validation loss: 2.276631884677436

Epoch: 5| Step: 10
Training loss: 2.4183692932128906
Validation loss: 2.2602813474593626

Epoch: 43| Step: 0
Training loss: 2.920780897140503
Validation loss: 2.252429726303265

Epoch: 5| Step: 1
Training loss: 1.9191491603851318
Validation loss: 2.2485462555321316

Epoch: 5| Step: 2
Training loss: 2.5462207794189453
Validation loss: 2.247481348694012

Epoch: 5| Step: 3
Training loss: 3.320596218109131
Validation loss: 2.244268237903554

Epoch: 5| Step: 4
Training loss: 2.040867328643799
Validation loss: 2.2437761419562885

Epoch: 5| Step: 5
Training loss: 2.68475079536438
Validation loss: 2.244430849629064

Epoch: 5| Step: 6
Training loss: 2.365546464920044
Validation loss: 2.249791027397238

Epoch: 5| Step: 7
Training loss: 2.7080955505371094
Validation loss: 2.2543958617794897

Epoch: 5| Step: 8
Training loss: 2.4993934631347656
Validation loss: 2.2575447456811064

Epoch: 5| Step: 9
Training loss: 2.341127872467041
Validation loss: 2.2523190488097486

Epoch: 5| Step: 10
Training loss: 2.7518250942230225
Validation loss: 2.246359581588417

Epoch: 44| Step: 0
Training loss: 2.8514552116394043
Validation loss: 2.2419234334781604

Epoch: 5| Step: 1
Training loss: 2.9521968364715576
Validation loss: 2.230809985950429

Epoch: 5| Step: 2
Training loss: 2.1214897632598877
Validation loss: 2.2314998539545203

Epoch: 5| Step: 3
Training loss: 3.2150866985321045
Validation loss: 2.232765895064159

Epoch: 5| Step: 4
Training loss: 2.2385413646698
Validation loss: 2.239034011799802

Epoch: 5| Step: 5
Training loss: 2.564476490020752
Validation loss: 2.254706733970232

Epoch: 5| Step: 6
Training loss: 2.496701717376709
Validation loss: 2.2452048332460466

Epoch: 5| Step: 7
Training loss: 2.596813201904297
Validation loss: 2.247636292570381

Epoch: 5| Step: 8
Training loss: 2.4354705810546875
Validation loss: 2.2488654634003997

Epoch: 5| Step: 9
Training loss: 2.285270929336548
Validation loss: 2.2681025074374292

Epoch: 5| Step: 10
Training loss: 2.290635585784912
Validation loss: 2.2866311919304634

Epoch: 45| Step: 0
Training loss: 2.5206027030944824
Validation loss: 2.2854774408443

Epoch: 5| Step: 1
Training loss: 2.5438430309295654
Validation loss: 2.258692092792962

Epoch: 5| Step: 2
Training loss: 2.7061707973480225
Validation loss: 2.2456101140668316

Epoch: 5| Step: 3
Training loss: 2.553560256958008
Validation loss: 2.2417843957101145

Epoch: 5| Step: 4
Training loss: 2.5534911155700684
Validation loss: 2.2452031361159457

Epoch: 5| Step: 5
Training loss: 2.1629271507263184
Validation loss: 2.24667110238024

Epoch: 5| Step: 6
Training loss: 2.878912925720215
Validation loss: 2.2477800641008603

Epoch: 5| Step: 7
Training loss: 3.0238945484161377
Validation loss: 2.253632853108068

Epoch: 5| Step: 8
Training loss: 2.6478774547576904
Validation loss: 2.2458041867902203

Epoch: 5| Step: 9
Training loss: 2.4938948154449463
Validation loss: 2.2479956355146182

Epoch: 5| Step: 10
Training loss: 1.8266258239746094
Validation loss: 2.246949981617671

Epoch: 46| Step: 0
Training loss: 1.9316635131835938
Validation loss: 2.249244474595593

Epoch: 5| Step: 1
Training loss: 2.2584214210510254
Validation loss: 2.244043823211424

Epoch: 5| Step: 2
Training loss: 2.292567014694214
Validation loss: 2.259522868740943

Epoch: 5| Step: 3
Training loss: 2.7967379093170166
Validation loss: 2.286163005777585

Epoch: 5| Step: 4
Training loss: 2.562681198120117
Validation loss: 2.2827070733552337

Epoch: 5| Step: 5
Training loss: 2.576509952545166
Validation loss: 2.297618096874606

Epoch: 5| Step: 6
Training loss: 2.8034629821777344
Validation loss: 2.295987867539929

Epoch: 5| Step: 7
Training loss: 2.4479563236236572
Validation loss: 2.2889518635247343

Epoch: 5| Step: 8
Training loss: 3.0890026092529297
Validation loss: 2.2694794618955223

Epoch: 5| Step: 9
Training loss: 2.7855498790740967
Validation loss: 2.2505157993685816

Epoch: 5| Step: 10
Training loss: 2.289592742919922
Validation loss: 2.2442888944379744

Epoch: 47| Step: 0
Training loss: 2.4854044914245605
Validation loss: 2.229673342038226

Epoch: 5| Step: 1
Training loss: 2.3702430725097656
Validation loss: 2.2305877388164563

Epoch: 5| Step: 2
Training loss: 2.2139477729797363
Validation loss: 2.2347734282093663

Epoch: 5| Step: 3
Training loss: 2.3691375255584717
Validation loss: 2.2418399639027093

Epoch: 5| Step: 4
Training loss: 2.700117588043213
Validation loss: 2.2401090104092836

Epoch: 5| Step: 5
Training loss: 2.1701929569244385
Validation loss: 2.239816088830271

Epoch: 5| Step: 6
Training loss: 2.7140891551971436
Validation loss: 2.231232630309238

Epoch: 5| Step: 7
Training loss: 2.896340847015381
Validation loss: 2.2364914506994267

Epoch: 5| Step: 8
Training loss: 2.8560736179351807
Validation loss: 2.2445504255192255

Epoch: 5| Step: 9
Training loss: 2.537381410598755
Validation loss: 2.2597364046240367

Epoch: 5| Step: 10
Training loss: 2.4324734210968018
Validation loss: 2.279100115581225

Epoch: 48| Step: 0
Training loss: 2.483032703399658
Validation loss: 2.3139287246170865

Epoch: 5| Step: 1
Training loss: 2.9247050285339355
Validation loss: 2.325698983284735

Epoch: 5| Step: 2
Training loss: 2.3264694213867188
Validation loss: 2.337983592864006

Epoch: 5| Step: 3
Training loss: 2.9723446369171143
Validation loss: 2.3440688092221498

Epoch: 5| Step: 4
Training loss: 2.8496594429016113
Validation loss: 2.360700773936446

Epoch: 5| Step: 5
Training loss: 1.9198634624481201
Validation loss: 2.28274630987516

Epoch: 5| Step: 6
Training loss: 2.9034647941589355
Validation loss: 2.244835945867723

Epoch: 5| Step: 7
Training loss: 2.302321195602417
Validation loss: 2.237658815999185

Epoch: 5| Step: 8
Training loss: 2.443655252456665
Validation loss: 2.225718429011683

Epoch: 5| Step: 9
Training loss: 2.4035019874572754
Validation loss: 2.2304926610762075

Epoch: 5| Step: 10
Training loss: 2.6435203552246094
Validation loss: 2.2500147101699666

Epoch: 49| Step: 0
Training loss: 1.7130775451660156
Validation loss: 2.26769652417911

Epoch: 5| Step: 1
Training loss: 1.9204375743865967
Validation loss: 2.2615400924477527

Epoch: 5| Step: 2
Training loss: 2.2857296466827393
Validation loss: 2.2509740821776854

Epoch: 5| Step: 3
Training loss: 2.626288652420044
Validation loss: 2.2567539881634455

Epoch: 5| Step: 4
Training loss: 2.3781697750091553
Validation loss: 2.270863684274817

Epoch: 5| Step: 5
Training loss: 3.323627471923828
Validation loss: 2.2837813797817437

Epoch: 5| Step: 6
Training loss: 2.5429060459136963
Validation loss: 2.3045459383277485

Epoch: 5| Step: 7
Training loss: 2.762965679168701
Validation loss: 2.3061512080571984

Epoch: 5| Step: 8
Training loss: 2.525491237640381
Validation loss: 2.306134769993444

Epoch: 5| Step: 9
Training loss: 3.0393218994140625
Validation loss: 2.3068753724457114

Epoch: 5| Step: 10
Training loss: 2.9568827152252197
Validation loss: 2.254368369297315

Epoch: 50| Step: 0
Training loss: 2.515986919403076
Validation loss: 2.218915823967226

Epoch: 5| Step: 1
Training loss: 2.489933490753174
Validation loss: 2.2027691102796987

Epoch: 5| Step: 2
Training loss: 3.054197072982788
Validation loss: 2.196161631614931

Epoch: 5| Step: 3
Training loss: 2.713517665863037
Validation loss: 2.2047385015795307

Epoch: 5| Step: 4
Training loss: 2.2452704906463623
Validation loss: 2.2160928992814917

Epoch: 5| Step: 5
Training loss: 2.4919345378875732
Validation loss: 2.225686195076153

Epoch: 5| Step: 6
Training loss: 2.5269525051116943
Validation loss: 2.2361457322233464

Epoch: 5| Step: 7
Training loss: 3.239891767501831
Validation loss: 2.2258359027165238

Epoch: 5| Step: 8
Training loss: 2.1130013465881348
Validation loss: 2.221902229452646

Epoch: 5| Step: 9
Training loss: 2.299787998199463
Validation loss: 2.220849826771726

Epoch: 5| Step: 10
Training loss: 2.5707547664642334
Validation loss: 2.2110943973705335

Epoch: 51| Step: 0
Training loss: 2.843252658843994
Validation loss: 2.198568400516305

Epoch: 5| Step: 1
Training loss: 1.8991400003433228
Validation loss: 2.2022348526985414

Epoch: 5| Step: 2
Training loss: 2.509445905685425
Validation loss: 2.2096252223496795

Epoch: 5| Step: 3
Training loss: 2.8745532035827637
Validation loss: 2.231587863737537

Epoch: 5| Step: 4
Training loss: 2.6785454750061035
Validation loss: 2.2527977881893033

Epoch: 5| Step: 5
Training loss: 2.6977438926696777
Validation loss: 2.294386486853323

Epoch: 5| Step: 6
Training loss: 2.3225202560424805
Validation loss: 2.3503717273794194

Epoch: 5| Step: 7
Training loss: 2.6731460094451904
Validation loss: 2.357721077498569

Epoch: 5| Step: 8
Training loss: 2.4992403984069824
Validation loss: 2.34093052341092

Epoch: 5| Step: 9
Training loss: 2.407996654510498
Validation loss: 2.3387784240066365

Epoch: 5| Step: 10
Training loss: 2.5741477012634277
Validation loss: 2.3116661835742254

Epoch: 52| Step: 0
Training loss: 2.9319984912872314
Validation loss: 2.263051507293537

Epoch: 5| Step: 1
Training loss: 2.7172915935516357
Validation loss: 2.2341092991572555

Epoch: 5| Step: 2
Training loss: 2.1139016151428223
Validation loss: 2.216942435951643

Epoch: 5| Step: 3
Training loss: 3.1750454902648926
Validation loss: 2.2128170536410425

Epoch: 5| Step: 4
Training loss: 2.5296478271484375
Validation loss: 2.210576688089678

Epoch: 5| Step: 5
Training loss: 2.680626392364502
Validation loss: 2.20596388078505

Epoch: 5| Step: 6
Training loss: 2.064826726913452
Validation loss: 2.1990978128166607

Epoch: 5| Step: 7
Training loss: 1.9526656866073608
Validation loss: 2.1973561189507924

Epoch: 5| Step: 8
Training loss: 2.6996712684631348
Validation loss: 2.201113008683728

Epoch: 5| Step: 9
Training loss: 3.137207508087158
Validation loss: 2.1955597246846845

Epoch: 5| Step: 10
Training loss: 1.8008533716201782
Validation loss: 2.1938990854447886

Epoch: 53| Step: 0
Training loss: 2.669874906539917
Validation loss: 2.1991055524477394

Epoch: 5| Step: 1
Training loss: 3.0691323280334473
Validation loss: 2.197094876279113

Epoch: 5| Step: 2
Training loss: 2.571322202682495
Validation loss: 2.2003854038894817

Epoch: 5| Step: 3
Training loss: 2.45707631111145
Validation loss: 2.205986281876923

Epoch: 5| Step: 4
Training loss: 2.3169972896575928
Validation loss: 2.2126483865963515

Epoch: 5| Step: 5
Training loss: 2.136920690536499
Validation loss: 2.2389764875494023

Epoch: 5| Step: 6
Training loss: 2.077510118484497
Validation loss: 2.2544943158344557

Epoch: 5| Step: 7
Training loss: 2.086320638656616
Validation loss: 2.281947120543449

Epoch: 5| Step: 8
Training loss: 3.099788188934326
Validation loss: 2.3156457203690723

Epoch: 5| Step: 9
Training loss: 3.0692813396453857
Validation loss: 2.31521192930078

Epoch: 5| Step: 10
Training loss: 2.0284581184387207
Validation loss: 2.3003685000122234

Epoch: 54| Step: 0
Training loss: 2.3057968616485596
Validation loss: 2.286875706846996

Epoch: 5| Step: 1
Training loss: 2.788943290710449
Validation loss: 2.2679801064152874

Epoch: 5| Step: 2
Training loss: 2.4288125038146973
Validation loss: 2.232990526383923

Epoch: 5| Step: 3
Training loss: 2.3926613330841064
Validation loss: 2.213189726234764

Epoch: 5| Step: 4
Training loss: 2.32881498336792
Validation loss: 2.198999547189282

Epoch: 5| Step: 5
Training loss: 2.6129472255706787
Validation loss: 2.190475981722596

Epoch: 5| Step: 6
Training loss: 2.571112632751465
Validation loss: 2.1827424033995597

Epoch: 5| Step: 7
Training loss: 2.100574016571045
Validation loss: 2.173753599966726

Epoch: 5| Step: 8
Training loss: 2.8614909648895264
Validation loss: 2.173537226133449

Epoch: 5| Step: 9
Training loss: 2.168654203414917
Validation loss: 2.1756346200102117

Epoch: 5| Step: 10
Training loss: 2.979837656021118
Validation loss: 2.1707982452966834

Epoch: 55| Step: 0
Training loss: 1.9717891216278076
Validation loss: 2.1720569338849796

Epoch: 5| Step: 1
Training loss: 2.0313925743103027
Validation loss: 2.174066871725103

Epoch: 5| Step: 2
Training loss: 2.077178955078125
Validation loss: 2.1721365656903995

Epoch: 5| Step: 3
Training loss: 2.3981997966766357
Validation loss: 2.1741673792562177

Epoch: 5| Step: 4
Training loss: 3.266328811645508
Validation loss: 2.1847862928144393

Epoch: 5| Step: 5
Training loss: 3.0136570930480957
Validation loss: 2.1902274623993905

Epoch: 5| Step: 6
Training loss: 2.5773937702178955
Validation loss: 2.189402477715605

Epoch: 5| Step: 7
Training loss: 2.4363934993743896
Validation loss: 2.196935010212724

Epoch: 5| Step: 8
Training loss: 2.6489760875701904
Validation loss: 2.2098915833298878

Epoch: 5| Step: 9
Training loss: 2.73118257522583
Validation loss: 2.212393744017488

Epoch: 5| Step: 10
Training loss: 2.291886806488037
Validation loss: 2.2286819924590406

Epoch: 56| Step: 0
Training loss: 2.920088291168213
Validation loss: 2.236376380407682

Epoch: 5| Step: 1
Training loss: 2.7086997032165527
Validation loss: 2.235039258515963

Epoch: 5| Step: 2
Training loss: 2.037330389022827
Validation loss: 2.209675174887462

Epoch: 5| Step: 3
Training loss: 2.1685333251953125
Validation loss: 2.183860783935875

Epoch: 5| Step: 4
Training loss: 2.6511242389678955
Validation loss: 2.1705726064661497

Epoch: 5| Step: 5
Training loss: 2.595548152923584
Validation loss: 2.1701567108913133

Epoch: 5| Step: 6
Training loss: 2.847801923751831
Validation loss: 2.169841939403165

Epoch: 5| Step: 7
Training loss: 2.9267630577087402
Validation loss: 2.1698303914839223

Epoch: 5| Step: 8
Training loss: 1.9022529125213623
Validation loss: 2.1679866262661514

Epoch: 5| Step: 9
Training loss: 2.4917430877685547
Validation loss: 2.1710004601427304

Epoch: 5| Step: 10
Training loss: 2.065164089202881
Validation loss: 2.1704567606731127

Epoch: 57| Step: 0
Training loss: 2.736783504486084
Validation loss: 2.1755236502616637

Epoch: 5| Step: 1
Training loss: 2.9766132831573486
Validation loss: 2.1774547638431674

Epoch: 5| Step: 2
Training loss: 2.3744394779205322
Validation loss: 2.1786947096547773

Epoch: 5| Step: 3
Training loss: 2.261603355407715
Validation loss: 2.1879311787184847

Epoch: 5| Step: 4
Training loss: 2.4327971935272217
Validation loss: 2.198634104062152

Epoch: 5| Step: 5
Training loss: 2.228783130645752
Validation loss: 2.2214512132829234

Epoch: 5| Step: 6
Training loss: 2.478079319000244
Validation loss: 2.2123199637218187

Epoch: 5| Step: 7
Training loss: 2.4442756175994873
Validation loss: 2.2294052365005657

Epoch: 5| Step: 8
Training loss: 2.3980841636657715
Validation loss: 2.2155154161555792

Epoch: 5| Step: 9
Training loss: 2.600592851638794
Validation loss: 2.2034043240290817

Epoch: 5| Step: 10
Training loss: 2.263620376586914
Validation loss: 2.186663193087424

Epoch: 58| Step: 0
Training loss: 3.1720969676971436
Validation loss: 2.17710042256181

Epoch: 5| Step: 1
Training loss: 3.324098587036133
Validation loss: 2.1624951926610803

Epoch: 5| Step: 2
Training loss: 2.8322949409484863
Validation loss: 2.156686303436115

Epoch: 5| Step: 3
Training loss: 1.979499101638794
Validation loss: 2.1552909804928686

Epoch: 5| Step: 4
Training loss: 2.1850924491882324
Validation loss: 2.1545431921558995

Epoch: 5| Step: 5
Training loss: 2.078606605529785
Validation loss: 2.146741877319992

Epoch: 5| Step: 6
Training loss: 2.240865707397461
Validation loss: 2.140857970842751

Epoch: 5| Step: 7
Training loss: 2.2194793224334717
Validation loss: 2.152653544179855

Epoch: 5| Step: 8
Training loss: 2.198230266571045
Validation loss: 2.1717503583559425

Epoch: 5| Step: 9
Training loss: 2.7020866870880127
Validation loss: 2.173383035967427

Epoch: 5| Step: 10
Training loss: 2.3208882808685303
Validation loss: 2.2046061344044183

Epoch: 59| Step: 0
Training loss: 2.632897138595581
Validation loss: 2.23034998678392

Epoch: 5| Step: 1
Training loss: 2.5064985752105713
Validation loss: 2.2641591948847615

Epoch: 5| Step: 2
Training loss: 2.6079835891723633
Validation loss: 2.27761762116545

Epoch: 5| Step: 3
Training loss: 2.8141567707061768
Validation loss: 2.2586975764202815

Epoch: 5| Step: 4
Training loss: 2.340989589691162
Validation loss: 2.2141566532914356

Epoch: 5| Step: 5
Training loss: 2.3201966285705566
Validation loss: 2.173162425718

Epoch: 5| Step: 6
Training loss: 2.2195277214050293
Validation loss: 2.153272262183569

Epoch: 5| Step: 7
Training loss: 2.555124521255493
Validation loss: 2.14949401732414

Epoch: 5| Step: 8
Training loss: 2.670929193496704
Validation loss: 2.1466967008447133

Epoch: 5| Step: 9
Training loss: 2.1636147499084473
Validation loss: 2.147376673195952

Epoch: 5| Step: 10
Training loss: 2.5375537872314453
Validation loss: 2.1506051658302225

Epoch: 60| Step: 0
Training loss: 2.4523065090179443
Validation loss: 2.1528160982234503

Epoch: 5| Step: 1
Training loss: 2.209235429763794
Validation loss: 2.1598182121912637

Epoch: 5| Step: 2
Training loss: 2.9395830631256104
Validation loss: 2.1548258668632916

Epoch: 5| Step: 3
Training loss: 2.6148033142089844
Validation loss: 2.149052343060893

Epoch: 5| Step: 4
Training loss: 1.5994160175323486
Validation loss: 2.1546901887462986

Epoch: 5| Step: 5
Training loss: 2.3537402153015137
Validation loss: 2.151306342053157

Epoch: 5| Step: 6
Training loss: 2.8475866317749023
Validation loss: 2.147311284977903

Epoch: 5| Step: 7
Training loss: 2.115659713745117
Validation loss: 2.1438138766955306

Epoch: 5| Step: 8
Training loss: 2.9916024208068848
Validation loss: 2.1473691155833583

Epoch: 5| Step: 9
Training loss: 2.5272908210754395
Validation loss: 2.155335534003473

Epoch: 5| Step: 10
Training loss: 2.573723316192627
Validation loss: 2.168693047697826

Epoch: 61| Step: 0
Training loss: 2.9360909461975098
Validation loss: 2.19655426086918

Epoch: 5| Step: 1
Training loss: 2.794739007949829
Validation loss: 2.2115681799509193

Epoch: 5| Step: 2
Training loss: 2.2419497966766357
Validation loss: 2.2154439008364113

Epoch: 5| Step: 3
Training loss: 2.02593731880188
Validation loss: 2.2424640168425856

Epoch: 5| Step: 4
Training loss: 2.7724881172180176
Validation loss: 2.2283197602918072

Epoch: 5| Step: 5
Training loss: 2.664783000946045
Validation loss: 2.2262417539473502

Epoch: 5| Step: 6
Training loss: 2.1563801765441895
Validation loss: 2.2137315965467885

Epoch: 5| Step: 7
Training loss: 2.014244556427002
Validation loss: 2.1637052592410835

Epoch: 5| Step: 8
Training loss: 2.5364668369293213
Validation loss: 2.1637583394204416

Epoch: 5| Step: 9
Training loss: 2.434196949005127
Validation loss: 2.1455793867829027

Epoch: 5| Step: 10
Training loss: 2.529020309448242
Validation loss: 2.141625245412191

Epoch: 62| Step: 0
Training loss: 2.19132661819458
Validation loss: 2.1456345281293316

Epoch: 5| Step: 1
Training loss: 3.0424885749816895
Validation loss: 2.14176699935749

Epoch: 5| Step: 2
Training loss: 3.2363815307617188
Validation loss: 2.1347770229462655

Epoch: 5| Step: 3
Training loss: 2.5867295265197754
Validation loss: 2.137178603038993

Epoch: 5| Step: 4
Training loss: 2.783280611038208
Validation loss: 2.1425157285505727

Epoch: 5| Step: 5
Training loss: 1.7508636713027954
Validation loss: 2.159257804193804

Epoch: 5| Step: 6
Training loss: 1.7551383972167969
Validation loss: 2.1930666610758793

Epoch: 5| Step: 7
Training loss: 1.8857002258300781
Validation loss: 2.221872293820945

Epoch: 5| Step: 8
Training loss: 2.3900063037872314
Validation loss: 2.240038982001684

Epoch: 5| Step: 9
Training loss: 2.8126678466796875
Validation loss: 2.2084069418650802

Epoch: 5| Step: 10
Training loss: 2.7851812839508057
Validation loss: 2.1557603164385726

Epoch: 63| Step: 0
Training loss: 1.5882089138031006
Validation loss: 2.128352142149402

Epoch: 5| Step: 1
Training loss: 3.0173020362854004
Validation loss: 2.1413643949775287

Epoch: 5| Step: 2
Training loss: 2.688811779022217
Validation loss: 2.1541437051629506

Epoch: 5| Step: 3
Training loss: 3.0784435272216797
Validation loss: 2.1653855641682944

Epoch: 5| Step: 4
Training loss: 2.750840663909912
Validation loss: 2.1741668793462936

Epoch: 5| Step: 5
Training loss: 2.351280689239502
Validation loss: 2.193550512354861

Epoch: 5| Step: 6
Training loss: 2.306887149810791
Validation loss: 2.190728279852098

Epoch: 5| Step: 7
Training loss: 2.3580658435821533
Validation loss: 2.187566336765084

Epoch: 5| Step: 8
Training loss: 1.932940125465393
Validation loss: 2.1903092322811

Epoch: 5| Step: 9
Training loss: 3.555744171142578
Validation loss: 2.180641940844956

Epoch: 5| Step: 10
Training loss: 2.3484089374542236
Validation loss: 2.175110237572783

Epoch: 64| Step: 0
Training loss: 1.9478391408920288
Validation loss: 2.1766578561516217

Epoch: 5| Step: 1
Training loss: 1.9741077423095703
Validation loss: 2.1742581987893708

Epoch: 5| Step: 2
Training loss: 2.440337657928467
Validation loss: 2.1849626020718644

Epoch: 5| Step: 3
Training loss: 2.57664155960083
Validation loss: 2.2066626292403027

Epoch: 5| Step: 4
Training loss: 2.760110855102539
Validation loss: 2.215622276388189

Epoch: 5| Step: 5
Training loss: 2.5647754669189453
Validation loss: 2.2196105321248374

Epoch: 5| Step: 6
Training loss: 2.452000379562378
Validation loss: 2.203444342459402

Epoch: 5| Step: 7
Training loss: 2.9434738159179688
Validation loss: 2.237461592561455

Epoch: 5| Step: 8
Training loss: 1.9717813730239868
Validation loss: 2.2127623122225524

Epoch: 5| Step: 9
Training loss: 3.132920980453491
Validation loss: 2.1852750906380276

Epoch: 5| Step: 10
Training loss: 2.4836554527282715
Validation loss: 2.1997213491829495

Epoch: 65| Step: 0
Training loss: 2.501302719116211
Validation loss: 2.215413207648903

Epoch: 5| Step: 1
Training loss: 2.18739652633667
Validation loss: 2.237947663953227

Epoch: 5| Step: 2
Training loss: 2.4788951873779297
Validation loss: 2.2429158892682803

Epoch: 5| Step: 3
Training loss: 2.25994873046875
Validation loss: 2.218452912504955

Epoch: 5| Step: 4
Training loss: 2.23947811126709
Validation loss: 2.1706516614524265

Epoch: 5| Step: 5
Training loss: 2.5095927715301514
Validation loss: 2.143753554231377

Epoch: 5| Step: 6
Training loss: 2.6163947582244873
Validation loss: 2.1303204336474018

Epoch: 5| Step: 7
Training loss: 2.595149517059326
Validation loss: 2.1174050864352973

Epoch: 5| Step: 8
Training loss: 2.9174790382385254
Validation loss: 2.1250315712344263

Epoch: 5| Step: 9
Training loss: 2.2257392406463623
Validation loss: 2.156707881599344

Epoch: 5| Step: 10
Training loss: 2.7484371662139893
Validation loss: 2.1826562420014413

Epoch: 66| Step: 0
Training loss: 2.828301191329956
Validation loss: 2.195335626602173

Epoch: 5| Step: 1
Training loss: 2.7827258110046387
Validation loss: 2.2070695379728913

Epoch: 5| Step: 2
Training loss: 2.379842758178711
Validation loss: 2.1980595845048145

Epoch: 5| Step: 3
Training loss: 2.0246639251708984
Validation loss: 2.1693761348724365

Epoch: 5| Step: 4
Training loss: 1.8931947946548462
Validation loss: 2.139734004133491

Epoch: 5| Step: 5
Training loss: 3.122211217880249
Validation loss: 2.122827676034743

Epoch: 5| Step: 6
Training loss: 2.4799118041992188
Validation loss: 2.139708918909873

Epoch: 5| Step: 7
Training loss: 2.318138837814331
Validation loss: 2.1473885633612193

Epoch: 5| Step: 8
Training loss: 2.2337646484375
Validation loss: 2.177482745980704

Epoch: 5| Step: 9
Training loss: 3.0865063667297363
Validation loss: 2.2126228911902315

Epoch: 5| Step: 10
Training loss: 2.1473255157470703
Validation loss: 2.232096187530025

Epoch: 67| Step: 0
Training loss: 2.5299630165100098
Validation loss: 2.2497336582470964

Epoch: 5| Step: 1
Training loss: 2.151918411254883
Validation loss: 2.221097256547661

Epoch: 5| Step: 2
Training loss: 2.5838756561279297
Validation loss: 2.200795024953863

Epoch: 5| Step: 3
Training loss: 2.065558671951294
Validation loss: 2.1976783147422214

Epoch: 5| Step: 4
Training loss: 2.3584554195404053
Validation loss: 2.1819431358768093

Epoch: 5| Step: 5
Training loss: 2.3054451942443848
Validation loss: 2.160565266045191

Epoch: 5| Step: 6
Training loss: 2.3904051780700684
Validation loss: 2.154908385328067

Epoch: 5| Step: 7
Training loss: 2.6099934577941895
Validation loss: 2.1610832803992817

Epoch: 5| Step: 8
Training loss: 2.662703275680542
Validation loss: 2.1497352430897374

Epoch: 5| Step: 9
Training loss: 2.9223554134368896
Validation loss: 2.1402717815932406

Epoch: 5| Step: 10
Training loss: 2.1457083225250244
Validation loss: 2.125757707062588

Epoch: 68| Step: 0
Training loss: 2.4860239028930664
Validation loss: 2.1184314309909777

Epoch: 5| Step: 1
Training loss: 2.535309076309204
Validation loss: 2.1248729421246435

Epoch: 5| Step: 2
Training loss: 2.2896995544433594
Validation loss: 2.1159521020868772

Epoch: 5| Step: 3
Training loss: 2.994311809539795
Validation loss: 2.1344574497592066

Epoch: 5| Step: 4
Training loss: 2.581923723220825
Validation loss: 2.124243672176074

Epoch: 5| Step: 5
Training loss: 2.0712010860443115
Validation loss: 2.131760912556802

Epoch: 5| Step: 6
Training loss: 2.136613130569458
Validation loss: 2.1248134797619236

Epoch: 5| Step: 7
Training loss: 2.3762645721435547
Validation loss: 2.128524649527765

Epoch: 5| Step: 8
Training loss: 2.5147387981414795
Validation loss: 2.1304344746374313

Epoch: 5| Step: 9
Training loss: 2.495814085006714
Validation loss: 2.1162419280698224

Epoch: 5| Step: 10
Training loss: 2.320213556289673
Validation loss: 2.1054991163233274

Epoch: 69| Step: 0
Training loss: 2.5539450645446777
Validation loss: 2.1129231427305486

Epoch: 5| Step: 1
Training loss: 2.7155380249023438
Validation loss: 2.0997540950775146

Epoch: 5| Step: 2
Training loss: 1.866957426071167
Validation loss: 2.10082677102858

Epoch: 5| Step: 3
Training loss: 2.537964344024658
Validation loss: 2.093709791860273

Epoch: 5| Step: 4
Training loss: 2.5958969593048096
Validation loss: 2.0905373455375753

Epoch: 5| Step: 5
Training loss: 2.702702760696411
Validation loss: 2.091691963134273

Epoch: 5| Step: 6
Training loss: 2.655222177505493
Validation loss: 2.0966871041123585

Epoch: 5| Step: 7
Training loss: 2.542858600616455
Validation loss: 2.0974435370455504

Epoch: 5| Step: 8
Training loss: 1.9781696796417236
Validation loss: 2.1153655359821935

Epoch: 5| Step: 9
Training loss: 1.9501463174819946
Validation loss: 2.119888554337204

Epoch: 5| Step: 10
Training loss: 2.567591667175293
Validation loss: 2.1376941127161824

Epoch: 70| Step: 0
Training loss: 1.8756071329116821
Validation loss: 2.150190520030196

Epoch: 5| Step: 1
Training loss: 2.647806406021118
Validation loss: 2.170343247793054

Epoch: 5| Step: 2
Training loss: 2.4078123569488525
Validation loss: 2.169802975910966

Epoch: 5| Step: 3
Training loss: 2.9541783332824707
Validation loss: 2.1720607690913702

Epoch: 5| Step: 4
Training loss: 2.352993965148926
Validation loss: 2.1756375835787867

Epoch: 5| Step: 5
Training loss: 2.7754428386688232
Validation loss: 2.161901634226563

Epoch: 5| Step: 6
Training loss: 1.8796991109848022
Validation loss: 2.1121929140501123

Epoch: 5| Step: 7
Training loss: 2.756342649459839
Validation loss: 2.081677926483975

Epoch: 5| Step: 8
Training loss: 2.1396093368530273
Validation loss: 2.0879809420595885

Epoch: 5| Step: 9
Training loss: 2.687345027923584
Validation loss: 2.081746088561191

Epoch: 5| Step: 10
Training loss: 2.2700605392456055
Validation loss: 2.096832331790719

Epoch: 71| Step: 0
Training loss: 2.712919235229492
Validation loss: 2.091386136188302

Epoch: 5| Step: 1
Training loss: 2.2933220863342285
Validation loss: 2.1031600864984656

Epoch: 5| Step: 2
Training loss: 2.314281940460205
Validation loss: 2.137623776671707

Epoch: 5| Step: 3
Training loss: 2.4483659267425537
Validation loss: 2.1609527821181924

Epoch: 5| Step: 4
Training loss: 2.9805684089660645
Validation loss: 2.19260347530406

Epoch: 5| Step: 5
Training loss: 2.770261764526367
Validation loss: 2.2263146574779222

Epoch: 5| Step: 6
Training loss: 2.1281135082244873
Validation loss: 2.186585557076239

Epoch: 5| Step: 7
Training loss: 1.9699897766113281
Validation loss: 2.1778117174743326

Epoch: 5| Step: 8
Training loss: 2.158787250518799
Validation loss: 2.160272249611475

Epoch: 5| Step: 9
Training loss: 2.5761234760284424
Validation loss: 2.1461935299699024

Epoch: 5| Step: 10
Training loss: 2.336399793624878
Validation loss: 2.132731985020381

Epoch: 72| Step: 0
Training loss: 2.012458562850952
Validation loss: 2.114117698002887

Epoch: 5| Step: 1
Training loss: 2.0357792377471924
Validation loss: 2.1097262136397825

Epoch: 5| Step: 2
Training loss: 2.3471686840057373
Validation loss: 2.1069377750478764

Epoch: 5| Step: 3
Training loss: 2.911679744720459
Validation loss: 2.1090132139062368

Epoch: 5| Step: 4
Training loss: 2.615577220916748
Validation loss: 2.096238467001146

Epoch: 5| Step: 5
Training loss: 2.1622650623321533
Validation loss: 2.1065362576515443

Epoch: 5| Step: 6
Training loss: 2.532305955886841
Validation loss: 2.1036678796173423

Epoch: 5| Step: 7
Training loss: 2.6493468284606934
Validation loss: 2.109015787801435

Epoch: 5| Step: 8
Training loss: 2.685715913772583
Validation loss: 2.131275492329751

Epoch: 5| Step: 9
Training loss: 2.2916934490203857
Validation loss: 2.1720167026724866

Epoch: 5| Step: 10
Training loss: 2.457782506942749
Validation loss: 2.168689534228335

Epoch: 73| Step: 0
Training loss: 1.7536952495574951
Validation loss: 2.208084744791831

Epoch: 5| Step: 1
Training loss: 2.7905526161193848
Validation loss: 2.21121185569353

Epoch: 5| Step: 2
Training loss: 2.430318832397461
Validation loss: 2.2196888308371268

Epoch: 5| Step: 3
Training loss: 3.0514369010925293
Validation loss: 2.2308016182273946

Epoch: 5| Step: 4
Training loss: 2.4102864265441895
Validation loss: 2.182172549668179

Epoch: 5| Step: 5
Training loss: 2.176377296447754
Validation loss: 2.131346559011808

Epoch: 5| Step: 6
Training loss: 2.1763885021209717
Validation loss: 2.124956569363994

Epoch: 5| Step: 7
Training loss: 1.8171823024749756
Validation loss: 2.120886048962993

Epoch: 5| Step: 8
Training loss: 3.2433509826660156
Validation loss: 2.1320364065067743

Epoch: 5| Step: 9
Training loss: 2.2689640522003174
Validation loss: 2.1247319636806363

Epoch: 5| Step: 10
Training loss: 2.504802942276001
Validation loss: 2.1033233596432592

Epoch: 74| Step: 0
Training loss: 2.8873558044433594
Validation loss: 2.099185538548295

Epoch: 5| Step: 1
Training loss: 2.6470251083374023
Validation loss: 2.1011271040926696

Epoch: 5| Step: 2
Training loss: 2.092360734939575
Validation loss: 2.099524997895764

Epoch: 5| Step: 3
Training loss: 2.478753089904785
Validation loss: 2.106439418690179

Epoch: 5| Step: 4
Training loss: 2.699152708053589
Validation loss: 2.1140466633663384

Epoch: 5| Step: 5
Training loss: 2.3877930641174316
Validation loss: 2.101771311093402

Epoch: 5| Step: 6
Training loss: 1.8812897205352783
Validation loss: 2.100162127966522

Epoch: 5| Step: 7
Training loss: 1.910904884338379
Validation loss: 2.0845740687462593

Epoch: 5| Step: 8
Training loss: 2.7700066566467285
Validation loss: 2.075972878804771

Epoch: 5| Step: 9
Training loss: 2.420515298843384
Validation loss: 2.070304145095169

Epoch: 5| Step: 10
Training loss: 2.266777515411377
Validation loss: 2.07066503647835

Epoch: 75| Step: 0
Training loss: 2.867280960083008
Validation loss: 2.078565230933569

Epoch: 5| Step: 1
Training loss: 2.225533962249756
Validation loss: 2.0741294994149158

Epoch: 5| Step: 2
Training loss: 2.3566360473632812
Validation loss: 2.0869158724302888

Epoch: 5| Step: 3
Training loss: 2.783048152923584
Validation loss: 2.0976666404354956

Epoch: 5| Step: 4
Training loss: 2.4826290607452393
Validation loss: 2.118794802696474

Epoch: 5| Step: 5
Training loss: 2.7549498081207275
Validation loss: 2.1294866313216505

Epoch: 5| Step: 6
Training loss: 2.183943271636963
Validation loss: 2.147732980789677

Epoch: 5| Step: 7
Training loss: 1.8512945175170898
Validation loss: 2.142637978317917

Epoch: 5| Step: 8
Training loss: 1.9513270854949951
Validation loss: 2.1410599626520628

Epoch: 5| Step: 9
Training loss: 2.615838050842285
Validation loss: 2.121458048461586

Epoch: 5| Step: 10
Training loss: 2.158935070037842
Validation loss: 2.099084650316546

Epoch: 76| Step: 0
Training loss: 2.5390872955322266
Validation loss: 2.0987021974338

Epoch: 5| Step: 1
Training loss: 2.0351030826568604
Validation loss: 2.105476256339781

Epoch: 5| Step: 2
Training loss: 2.65342378616333
Validation loss: 2.086433820827033

Epoch: 5| Step: 3
Training loss: 2.26165509223938
Validation loss: 2.0832601644659556

Epoch: 5| Step: 4
Training loss: 2.665618658065796
Validation loss: 2.079648833121023

Epoch: 5| Step: 5
Training loss: 2.1098785400390625
Validation loss: 2.092615376236618

Epoch: 5| Step: 6
Training loss: 2.084293842315674
Validation loss: 2.091083767593548

Epoch: 5| Step: 7
Training loss: 2.454418897628784
Validation loss: 2.110742184423631

Epoch: 5| Step: 8
Training loss: 3.123868942260742
Validation loss: 2.127783442056307

Epoch: 5| Step: 9
Training loss: 2.103140115737915
Validation loss: 2.111936051358459

Epoch: 5| Step: 10
Training loss: 2.1451172828674316
Validation loss: 2.095567508410382

Epoch: 77| Step: 0
Training loss: 2.527573585510254
Validation loss: 2.079955900869062

Epoch: 5| Step: 1
Training loss: 1.851457953453064
Validation loss: 2.0675227206240416

Epoch: 5| Step: 2
Training loss: 2.3173792362213135
Validation loss: 2.0630157634776127

Epoch: 5| Step: 3
Training loss: 2.28745698928833
Validation loss: 2.060671107743376

Epoch: 5| Step: 4
Training loss: 2.778273820877075
Validation loss: 2.071338052390724

Epoch: 5| Step: 5
Training loss: 2.455085039138794
Validation loss: 2.0657737537096907

Epoch: 5| Step: 6
Training loss: 2.3169541358947754
Validation loss: 2.0707750192252536

Epoch: 5| Step: 7
Training loss: 2.2924022674560547
Validation loss: 2.0876853222488077

Epoch: 5| Step: 8
Training loss: 2.4337711334228516
Validation loss: 2.093498711944908

Epoch: 5| Step: 9
Training loss: 2.1825051307678223
Validation loss: 2.09461038087004

Epoch: 5| Step: 10
Training loss: 2.6425304412841797
Validation loss: 2.092868927986391

Epoch: 78| Step: 0
Training loss: 2.7775886058807373
Validation loss: 2.095566995682255

Epoch: 5| Step: 1
Training loss: 2.4198496341705322
Validation loss: 2.086011481541459

Epoch: 5| Step: 2
Training loss: 2.482703685760498
Validation loss: 2.0689294799681632

Epoch: 5| Step: 3
Training loss: 2.046734094619751
Validation loss: 2.050024365866056

Epoch: 5| Step: 4
Training loss: 1.9830195903778076
Validation loss: 2.052202922041698

Epoch: 5| Step: 5
Training loss: 2.0509231090545654
Validation loss: 2.056187484854011

Epoch: 5| Step: 6
Training loss: 2.7899932861328125
Validation loss: 2.061885528666999

Epoch: 5| Step: 7
Training loss: 2.540067672729492
Validation loss: 2.0519571637594574

Epoch: 5| Step: 8
Training loss: 2.274820327758789
Validation loss: 2.0538591864288493

Epoch: 5| Step: 9
Training loss: 2.4212753772735596
Validation loss: 2.047307252883911

Epoch: 5| Step: 10
Training loss: 2.158848285675049
Validation loss: 2.045296138332736

Epoch: 79| Step: 0
Training loss: 2.0557053089141846
Validation loss: 2.0548804229305637

Epoch: 5| Step: 1
Training loss: 2.094407796859741
Validation loss: 2.065839618764898

Epoch: 5| Step: 2
Training loss: 2.3261523246765137
Validation loss: 2.085016369819641

Epoch: 5| Step: 3
Training loss: 3.0003204345703125
Validation loss: 2.121954761525636

Epoch: 5| Step: 4
Training loss: 2.791963577270508
Validation loss: 2.155980917715257

Epoch: 5| Step: 5
Training loss: 2.0695793628692627
Validation loss: 2.1556244127212034

Epoch: 5| Step: 6
Training loss: 1.4633067846298218
Validation loss: 2.1468359398585495

Epoch: 5| Step: 7
Training loss: 2.585200548171997
Validation loss: 2.112590633412843

Epoch: 5| Step: 8
Training loss: 2.802443504333496
Validation loss: 2.0826325390928533

Epoch: 5| Step: 9
Training loss: 2.3144383430480957
Validation loss: 2.058007988878476

Epoch: 5| Step: 10
Training loss: 2.4885830879211426
Validation loss: 2.0431585183707615

Epoch: 80| Step: 0
Training loss: 2.659479856491089
Validation loss: 2.033606506163074

Epoch: 5| Step: 1
Training loss: 2.538891553878784
Validation loss: 2.0363804768490534

Epoch: 5| Step: 2
Training loss: 2.154944658279419
Validation loss: 2.040800198431938

Epoch: 5| Step: 3
Training loss: 2.338304042816162
Validation loss: 2.0351571600924254

Epoch: 5| Step: 4
Training loss: 2.671172618865967
Validation loss: 2.037527753460792

Epoch: 5| Step: 5
Training loss: 2.571699619293213
Validation loss: 2.043954034005442

Epoch: 5| Step: 6
Training loss: 2.6355133056640625
Validation loss: 2.0434888614121305

Epoch: 5| Step: 7
Training loss: 2.2570393085479736
Validation loss: 2.0382189378943494

Epoch: 5| Step: 8
Training loss: 1.559849739074707
Validation loss: 2.0489169820662467

Epoch: 5| Step: 9
Training loss: 2.3850150108337402
Validation loss: 2.0684715509414673

Epoch: 5| Step: 10
Training loss: 2.3038628101348877
Validation loss: 2.125451660925342

Epoch: 81| Step: 0
Training loss: 2.295454978942871
Validation loss: 2.1776866656477734

Epoch: 5| Step: 1
Training loss: 2.772095203399658
Validation loss: 2.1952362855275473

Epoch: 5| Step: 2
Training loss: 2.2615621089935303
Validation loss: 2.1716242092911915

Epoch: 5| Step: 3
Training loss: 2.4397501945495605
Validation loss: 2.1307133807930896

Epoch: 5| Step: 4
Training loss: 2.2579550743103027
Validation loss: 2.0835441722664783

Epoch: 5| Step: 5
Training loss: 2.348958730697632
Validation loss: 2.0551422385759253

Epoch: 5| Step: 6
Training loss: 2.019930362701416
Validation loss: 2.0406745287679855

Epoch: 5| Step: 7
Training loss: 2.5025100708007812
Validation loss: 2.0390144804472565

Epoch: 5| Step: 8
Training loss: 2.8137409687042236
Validation loss: 2.0481558563888713

Epoch: 5| Step: 9
Training loss: 2.471325159072876
Validation loss: 2.0620021691886325

Epoch: 5| Step: 10
Training loss: 1.8484309911727905
Validation loss: 2.0609390543353174

Epoch: 82| Step: 0
Training loss: 2.1373424530029297
Validation loss: 2.0671168296567854

Epoch: 5| Step: 1
Training loss: 2.383612632751465
Validation loss: 2.0778188500353085

Epoch: 5| Step: 2
Training loss: 2.0669989585876465
Validation loss: 2.068712729279713

Epoch: 5| Step: 3
Training loss: 2.1362340450286865
Validation loss: 2.0611973001110937

Epoch: 5| Step: 4
Training loss: 2.3446669578552246
Validation loss: 2.074132647565616

Epoch: 5| Step: 5
Training loss: 1.9194797277450562
Validation loss: 2.074684948049566

Epoch: 5| Step: 6
Training loss: 3.3369510173797607
Validation loss: 2.0824976480135353

Epoch: 5| Step: 7
Training loss: 2.881103515625
Validation loss: 2.0955657138619372

Epoch: 5| Step: 8
Training loss: 1.9419851303100586
Validation loss: 2.1187434786109516

Epoch: 5| Step: 9
Training loss: 2.3044886589050293
Validation loss: 2.1412267608027302

Epoch: 5| Step: 10
Training loss: 2.3834218978881836
Validation loss: 2.144838297238914

Epoch: 83| Step: 0
Training loss: 2.6509461402893066
Validation loss: 2.1359016062110983

Epoch: 5| Step: 1
Training loss: 2.22044038772583
Validation loss: 2.1108741401344218

Epoch: 5| Step: 2
Training loss: 2.120215892791748
Validation loss: 2.104308018120386

Epoch: 5| Step: 3
Training loss: 1.8448069095611572
Validation loss: 2.0854533846660326

Epoch: 5| Step: 4
Training loss: 2.349670171737671
Validation loss: 2.075457619082543

Epoch: 5| Step: 5
Training loss: 2.315645933151245
Validation loss: 2.0736570307003555

Epoch: 5| Step: 6
Training loss: 2.8519363403320312
Validation loss: 2.0622773580653693

Epoch: 5| Step: 7
Training loss: 2.3339829444885254
Validation loss: 2.0474394752133276

Epoch: 5| Step: 8
Training loss: 2.2364132404327393
Validation loss: 2.0309078449844034

Epoch: 5| Step: 9
Training loss: 2.3088414669036865
Validation loss: 2.030104708927934

Epoch: 5| Step: 10
Training loss: 2.4969615936279297
Validation loss: 2.0301141200527066

Epoch: 84| Step: 0
Training loss: 2.167567729949951
Validation loss: 2.027878386999971

Epoch: 5| Step: 1
Training loss: 2.1617331504821777
Validation loss: 2.015185188221675

Epoch: 5| Step: 2
Training loss: 2.4705116748809814
Validation loss: 2.0247307810732114

Epoch: 5| Step: 3
Training loss: 2.4405477046966553
Validation loss: 2.021199434034286

Epoch: 5| Step: 4
Training loss: 2.4143404960632324
Validation loss: 2.0301608142032417

Epoch: 5| Step: 5
Training loss: 2.3292083740234375
Validation loss: 2.0309090332318376

Epoch: 5| Step: 6
Training loss: 2.45995831489563
Validation loss: 2.026141192323418

Epoch: 5| Step: 7
Training loss: 2.3169655799865723
Validation loss: 2.027520061821066

Epoch: 5| Step: 8
Training loss: 2.320441484451294
Validation loss: 2.0421111237618232

Epoch: 5| Step: 9
Training loss: 2.6426918506622314
Validation loss: 2.048052046888618

Epoch: 5| Step: 10
Training loss: 1.875673770904541
Validation loss: 2.026577745714495

Epoch: 85| Step: 0
Training loss: 2.374115467071533
Validation loss: 2.0231279327023413

Epoch: 5| Step: 1
Training loss: 2.7981719970703125
Validation loss: 2.0265070776785574

Epoch: 5| Step: 2
Training loss: 2.167135715484619
Validation loss: 2.019568495852973

Epoch: 5| Step: 3
Training loss: 2.0262579917907715
Validation loss: 2.026440276894518

Epoch: 5| Step: 4
Training loss: 2.619597911834717
Validation loss: 2.03031652204452

Epoch: 5| Step: 5
Training loss: 2.92997145652771
Validation loss: 2.0404269977282454

Epoch: 5| Step: 6
Training loss: 2.412538766860962
Validation loss: 2.052449154597457

Epoch: 5| Step: 7
Training loss: 2.514594793319702
Validation loss: 2.056582727739888

Epoch: 5| Step: 8
Training loss: 1.782213568687439
Validation loss: 2.0519438661554807

Epoch: 5| Step: 9
Training loss: 1.7387511730194092
Validation loss: 2.0698977721634733

Epoch: 5| Step: 10
Training loss: 2.046215534210205
Validation loss: 2.0685527581040577

Epoch: 86| Step: 0
Training loss: 2.4308419227600098
Validation loss: 2.0738001177387853

Epoch: 5| Step: 1
Training loss: 1.9880939722061157
Validation loss: 2.0802284594505065

Epoch: 5| Step: 2
Training loss: 2.0202622413635254
Validation loss: 2.0808640923551334

Epoch: 5| Step: 3
Training loss: 2.716228485107422
Validation loss: 2.061828436390046

Epoch: 5| Step: 4
Training loss: 3.013617992401123
Validation loss: 2.0577852918255712

Epoch: 5| Step: 5
Training loss: 2.481874942779541
Validation loss: 2.0553946828329437

Epoch: 5| Step: 6
Training loss: 2.1327948570251465
Validation loss: 2.0511850644183416

Epoch: 5| Step: 7
Training loss: 1.7045942544937134
Validation loss: 2.062777885826685

Epoch: 5| Step: 8
Training loss: 2.3996174335479736
Validation loss: 2.055766995235156

Epoch: 5| Step: 9
Training loss: 2.26825213432312
Validation loss: 2.0489929952929096

Epoch: 5| Step: 10
Training loss: 2.562986135482788
Validation loss: 2.058763437373664

Epoch: 87| Step: 0
Training loss: 2.42429780960083
Validation loss: 2.060634668155383

Epoch: 5| Step: 1
Training loss: 2.120260238647461
Validation loss: 2.065353432009297

Epoch: 5| Step: 2
Training loss: 2.2396903038024902
Validation loss: 2.0771500782300065

Epoch: 5| Step: 3
Training loss: 2.5600485801696777
Validation loss: 2.0928876848631006

Epoch: 5| Step: 4
Training loss: 2.291487216949463
Validation loss: 2.0929523629526936

Epoch: 5| Step: 5
Training loss: 2.6865522861480713
Validation loss: 2.0938291408682383

Epoch: 5| Step: 6
Training loss: 2.3519949913024902
Validation loss: 2.109408090191503

Epoch: 5| Step: 7
Training loss: 2.1985690593719482
Validation loss: 2.1130976010394353

Epoch: 5| Step: 8
Training loss: 2.1829895973205566
Validation loss: 2.116759361759309

Epoch: 5| Step: 9
Training loss: 2.1217474937438965
Validation loss: 2.124380676977096

Epoch: 5| Step: 10
Training loss: 2.256150960922241
Validation loss: 2.1106895233995173

Epoch: 88| Step: 0
Training loss: 2.346771478652954
Validation loss: 2.08317518490617

Epoch: 5| Step: 1
Training loss: 2.22755765914917
Validation loss: 2.0367906260234054

Epoch: 5| Step: 2
Training loss: 2.177852153778076
Validation loss: 2.010167929434007

Epoch: 5| Step: 3
Training loss: 2.2940404415130615
Validation loss: 2.0081054664427236

Epoch: 5| Step: 4
Training loss: 2.644205093383789
Validation loss: 2.006705666101107

Epoch: 5| Step: 5
Training loss: 2.4983575344085693
Validation loss: 2.0063814706699823

Epoch: 5| Step: 6
Training loss: 2.3707146644592285
Validation loss: 2.005795858239615

Epoch: 5| Step: 7
Training loss: 2.0309605598449707
Validation loss: 2.0069712131254134

Epoch: 5| Step: 8
Training loss: 2.4421072006225586
Validation loss: 2.0036955738580353

Epoch: 5| Step: 9
Training loss: 2.413330078125
Validation loss: 2.005723120063864

Epoch: 5| Step: 10
Training loss: 2.330831527709961
Validation loss: 1.9994239076491325

Epoch: 89| Step: 0
Training loss: 2.2460122108459473
Validation loss: 2.0265364493093183

Epoch: 5| Step: 1
Training loss: 2.2774739265441895
Validation loss: 2.0803323048417286

Epoch: 5| Step: 2
Training loss: 2.003105878829956
Validation loss: 2.1397864357117684

Epoch: 5| Step: 3
Training loss: 2.6018402576446533
Validation loss: 2.236251204244552

Epoch: 5| Step: 4
Training loss: 2.2458744049072266
Validation loss: 2.2746324923730667

Epoch: 5| Step: 5
Training loss: 2.391308546066284
Validation loss: 2.2036695095800583

Epoch: 5| Step: 6
Training loss: 2.899470806121826
Validation loss: 2.146456157007525

Epoch: 5| Step: 7
Training loss: 2.36824107170105
Validation loss: 2.0583880627027122

Epoch: 5| Step: 8
Training loss: 2.146115779876709
Validation loss: 2.009490571996217

Epoch: 5| Step: 9
Training loss: 2.268791913986206
Validation loss: 2.0102725490447013

Epoch: 5| Step: 10
Training loss: 2.4255597591400146
Validation loss: 2.0306421146597913

Epoch: 90| Step: 0
Training loss: 2.4378042221069336
Validation loss: 2.0504280072386547

Epoch: 5| Step: 1
Training loss: 2.7743754386901855
Validation loss: 2.087845287015361

Epoch: 5| Step: 2
Training loss: 1.9283697605133057
Validation loss: 2.094261215579125

Epoch: 5| Step: 3
Training loss: 2.213568925857544
Validation loss: 2.0991581678390503

Epoch: 5| Step: 4
Training loss: 2.111118793487549
Validation loss: 2.09686521304551

Epoch: 5| Step: 5
Training loss: 2.3326244354248047
Validation loss: 2.0860622634169874

Epoch: 5| Step: 6
Training loss: 2.604630708694458
Validation loss: 2.0873083606843026

Epoch: 5| Step: 7
Training loss: 2.0685153007507324
Validation loss: 2.0852855982319003

Epoch: 5| Step: 8
Training loss: 2.5762240886688232
Validation loss: 2.0807325904087355

Epoch: 5| Step: 9
Training loss: 3.1024508476257324
Validation loss: 2.069400125934232

Epoch: 5| Step: 10
Training loss: 2.3426527976989746
Validation loss: 2.0764688432857556

Epoch: 91| Step: 0
Training loss: 2.3029818534851074
Validation loss: 2.0630321374503513

Epoch: 5| Step: 1
Training loss: 2.039905548095703
Validation loss: 2.065039925677802

Epoch: 5| Step: 2
Training loss: 3.153823137283325
Validation loss: 2.0570998640470606

Epoch: 5| Step: 3
Training loss: 1.9957342147827148
Validation loss: 2.0832371506639706

Epoch: 5| Step: 4
Training loss: 2.2830088138580322
Validation loss: 2.0941020083683792

Epoch: 5| Step: 5
Training loss: 1.7982279062271118
Validation loss: 2.1021123214434554

Epoch: 5| Step: 6
Training loss: 2.1105589866638184
Validation loss: 2.103611989687848

Epoch: 5| Step: 7
Training loss: 2.6735875606536865
Validation loss: 2.0762619972229004

Epoch: 5| Step: 8
Training loss: 2.3302879333496094
Validation loss: 2.050071233062334

Epoch: 5| Step: 9
Training loss: 2.791252613067627
Validation loss: 2.028941300607497

Epoch: 5| Step: 10
Training loss: 1.9838346242904663
Validation loss: 2.0205400554082726

Epoch: 92| Step: 0
Training loss: 2.916633129119873
Validation loss: 2.012205587920322

Epoch: 5| Step: 1
Training loss: 2.2532355785369873
Validation loss: 2.0141263085026897

Epoch: 5| Step: 2
Training loss: 2.422114849090576
Validation loss: 2.003044177127141

Epoch: 5| Step: 3
Training loss: 2.1966071128845215
Validation loss: 2.0137652684283514

Epoch: 5| Step: 4
Training loss: 2.610351085662842
Validation loss: 2.0204051797107985

Epoch: 5| Step: 5
Training loss: 2.0140438079833984
Validation loss: 2.026883266305411

Epoch: 5| Step: 6
Training loss: 2.5183284282684326
Validation loss: 2.022093008923274

Epoch: 5| Step: 7
Training loss: 1.9008550643920898
Validation loss: 2.0143900699512933

Epoch: 5| Step: 8
Training loss: 2.4881033897399902
Validation loss: 2.027639635147587

Epoch: 5| Step: 9
Training loss: 2.1765365600585938
Validation loss: 2.02161697546641

Epoch: 5| Step: 10
Training loss: 1.7212153673171997
Validation loss: 2.039059196749041

Epoch: 93| Step: 0
Training loss: 2.684502601623535
Validation loss: 2.076623096260973

Epoch: 5| Step: 1
Training loss: 2.2183375358581543
Validation loss: 2.095555058089636

Epoch: 5| Step: 2
Training loss: 2.448925495147705
Validation loss: 2.125033332455543

Epoch: 5| Step: 3
Training loss: 2.609560251235962
Validation loss: 2.140123112227327

Epoch: 5| Step: 4
Training loss: 2.228947162628174
Validation loss: 2.179471613258444

Epoch: 5| Step: 5
Training loss: 2.3431918621063232
Validation loss: 2.184959310357289

Epoch: 5| Step: 6
Training loss: 2.030505895614624
Validation loss: 2.15200069386472

Epoch: 5| Step: 7
Training loss: 2.15439772605896
Validation loss: 2.123186970269808

Epoch: 5| Step: 8
Training loss: 2.137011766433716
Validation loss: 2.0782879860170427

Epoch: 5| Step: 9
Training loss: 2.256012201309204
Validation loss: 2.0541869414749967

Epoch: 5| Step: 10
Training loss: 2.600637674331665
Validation loss: 2.044011495446646

Epoch: 94| Step: 0
Training loss: 2.4618258476257324
Validation loss: 2.048176670587191

Epoch: 5| Step: 1
Training loss: 2.439566135406494
Validation loss: 2.052342671220021

Epoch: 5| Step: 2
Training loss: 2.7560181617736816
Validation loss: 2.032957142399203

Epoch: 5| Step: 3
Training loss: 2.7492520809173584
Validation loss: 2.0166144601760374

Epoch: 5| Step: 4
Training loss: 2.244697093963623
Validation loss: 1.9920173896256315

Epoch: 5| Step: 5
Training loss: 2.668555736541748
Validation loss: 1.9970593606272051

Epoch: 5| Step: 6
Training loss: 1.8308422565460205
Validation loss: 1.993073542912801

Epoch: 5| Step: 7
Training loss: 2.2427737712860107
Validation loss: 1.9940767160025976

Epoch: 5| Step: 8
Training loss: 1.8102363348007202
Validation loss: 1.9904742766452093

Epoch: 5| Step: 9
Training loss: 2.460442543029785
Validation loss: 2.0089784142791585

Epoch: 5| Step: 10
Training loss: 1.8172463178634644
Validation loss: 2.0477965762538295

Epoch: 95| Step: 0
Training loss: 2.8590614795684814
Validation loss: 2.0684710676952074

Epoch: 5| Step: 1
Training loss: 2.412898540496826
Validation loss: 2.0853373081453386

Epoch: 5| Step: 2
Training loss: 2.0927748680114746
Validation loss: 2.1104357627130326

Epoch: 5| Step: 3
Training loss: 1.1054153442382812
Validation loss: 2.08246353877488

Epoch: 5| Step: 4
Training loss: 2.5286707878112793
Validation loss: 2.05847139768703

Epoch: 5| Step: 5
Training loss: 2.518488645553589
Validation loss: 2.036346814965689

Epoch: 5| Step: 6
Training loss: 2.2770495414733887
Validation loss: 2.0361524320417836

Epoch: 5| Step: 7
Training loss: 2.5053563117980957
Validation loss: 2.016757849724062

Epoch: 5| Step: 8
Training loss: 2.104295015335083
Validation loss: 2.011430835211149

Epoch: 5| Step: 9
Training loss: 2.819589138031006
Validation loss: 2.0112460377395793

Epoch: 5| Step: 10
Training loss: 1.7445571422576904
Validation loss: 2.0123058595964984

Epoch: 96| Step: 0
Training loss: 2.273571729660034
Validation loss: 2.0168932919861167

Epoch: 5| Step: 1
Training loss: 1.4740467071533203
Validation loss: 2.010406264694788

Epoch: 5| Step: 2
Training loss: 2.3311545848846436
Validation loss: 2.0144723935793807

Epoch: 5| Step: 3
Training loss: 2.276646375656128
Validation loss: 2.0138025463268323

Epoch: 5| Step: 4
Training loss: 2.0393624305725098
Validation loss: 2.016988597890382

Epoch: 5| Step: 5
Training loss: 2.296449661254883
Validation loss: 2.043051976029591

Epoch: 5| Step: 6
Training loss: 2.6503090858459473
Validation loss: 2.0690653965037358

Epoch: 5| Step: 7
Training loss: 2.3038570880889893
Validation loss: 2.1274055947539625

Epoch: 5| Step: 8
Training loss: 2.985466718673706
Validation loss: 2.1705447781470513

Epoch: 5| Step: 9
Training loss: 2.2594425678253174
Validation loss: 2.178505592448737

Epoch: 5| Step: 10
Training loss: 2.1927878856658936
Validation loss: 2.14495075133539

Epoch: 97| Step: 0
Training loss: 2.120335340499878
Validation loss: 2.111977118317799

Epoch: 5| Step: 1
Training loss: 2.460707187652588
Validation loss: 2.084517240524292

Epoch: 5| Step: 2
Training loss: 2.245128870010376
Validation loss: 2.0658334814092165

Epoch: 5| Step: 3
Training loss: 2.7896602153778076
Validation loss: 2.046317687598608

Epoch: 5| Step: 4
Training loss: 2.912832736968994
Validation loss: 2.0324080041659776

Epoch: 5| Step: 5
Training loss: 1.3994734287261963
Validation loss: 2.0334642779442573

Epoch: 5| Step: 6
Training loss: 2.179600238800049
Validation loss: 2.040323511246712

Epoch: 5| Step: 7
Training loss: 2.129006862640381
Validation loss: 2.0387422269390476

Epoch: 5| Step: 8
Training loss: 2.4422669410705566
Validation loss: 2.041929737214119

Epoch: 5| Step: 9
Training loss: 2.2052836418151855
Validation loss: 2.041336226206954

Epoch: 5| Step: 10
Training loss: 2.2129459381103516
Validation loss: 2.043487484737109

Epoch: 98| Step: 0
Training loss: 2.2081832885742188
Validation loss: 2.043861860870033

Epoch: 5| Step: 1
Training loss: 2.5251080989837646
Validation loss: 2.0504008903298327

Epoch: 5| Step: 2
Training loss: 2.3835506439208984
Validation loss: 2.05517666826966

Epoch: 5| Step: 3
Training loss: 2.529541254043579
Validation loss: 2.066539746458812

Epoch: 5| Step: 4
Training loss: 3.137230634689331
Validation loss: 2.09593451920376

Epoch: 5| Step: 5
Training loss: 2.0067825317382812
Validation loss: 2.0723290020419705

Epoch: 5| Step: 6
Training loss: 2.364419460296631
Validation loss: 2.0718607530798963

Epoch: 5| Step: 7
Training loss: 2.394779682159424
Validation loss: 2.0828426486702374

Epoch: 5| Step: 8
Training loss: 1.8115524053573608
Validation loss: 2.070651097964215

Epoch: 5| Step: 9
Training loss: 1.611027479171753
Validation loss: 2.0707527975882254

Epoch: 5| Step: 10
Training loss: 1.7917224168777466
Validation loss: 2.051674133987837

Epoch: 99| Step: 0
Training loss: 1.5537999868392944
Validation loss: 2.03675478248186

Epoch: 5| Step: 1
Training loss: 2.3318111896514893
Validation loss: 2.0392705138011644

Epoch: 5| Step: 2
Training loss: 2.244891405105591
Validation loss: 2.0240053758826306

Epoch: 5| Step: 3
Training loss: 1.926743507385254
Validation loss: 2.0243112041104223

Epoch: 5| Step: 4
Training loss: 2.1045150756835938
Validation loss: 2.0223338552700576

Epoch: 5| Step: 5
Training loss: 2.4444398880004883
Validation loss: 2.0317802172835155

Epoch: 5| Step: 6
Training loss: 2.2102084159851074
Validation loss: 2.0322774610211773

Epoch: 5| Step: 7
Training loss: 1.5543328523635864
Validation loss: 2.035362538471017

Epoch: 5| Step: 8
Training loss: 2.4541964530944824
Validation loss: 2.0483984049930366

Epoch: 5| Step: 9
Training loss: 3.101762294769287
Validation loss: 2.0526483289657103

Epoch: 5| Step: 10
Training loss: 2.767920732498169
Validation loss: 2.0770947830651396

Epoch: 100| Step: 0
Training loss: 1.738534927368164
Validation loss: 2.1030949290080736

Epoch: 5| Step: 1
Training loss: 2.473747730255127
Validation loss: 2.118918376584207

Epoch: 5| Step: 2
Training loss: 2.503701686859131
Validation loss: 2.1293301736154864

Epoch: 5| Step: 3
Training loss: 1.9947116374969482
Validation loss: 2.128621196234098

Epoch: 5| Step: 4
Training loss: 2.8886353969573975
Validation loss: 2.1216824823810208

Epoch: 5| Step: 5
Training loss: 1.7504093647003174
Validation loss: 2.106262073721937

Epoch: 5| Step: 6
Training loss: 2.1618525981903076
Validation loss: 2.1082119582801737

Epoch: 5| Step: 7
Training loss: 2.072359085083008
Validation loss: 2.0950165000013126

Epoch: 5| Step: 8
Training loss: 2.5625245571136475
Validation loss: 2.0901780769389164

Epoch: 5| Step: 9
Training loss: 2.157684326171875
Validation loss: 2.088845173517863

Epoch: 5| Step: 10
Training loss: 2.0505690574645996
Validation loss: 2.0712984966975387

Epoch: 101| Step: 0
Training loss: 2.6679797172546387
Validation loss: 2.068559809397626

Epoch: 5| Step: 1
Training loss: 1.9376344680786133
Validation loss: 2.061424773226502

Epoch: 5| Step: 2
Training loss: 1.9133937358856201
Validation loss: 2.065958765245253

Epoch: 5| Step: 3
Training loss: 1.990340232849121
Validation loss: 2.0659242676150416

Epoch: 5| Step: 4
Training loss: 2.389993190765381
Validation loss: 2.0628601697183426

Epoch: 5| Step: 5
Training loss: 2.0713937282562256
Validation loss: 2.056795517603556

Epoch: 5| Step: 6
Training loss: 1.9389927387237549
Validation loss: 2.0578940453067904

Epoch: 5| Step: 7
Training loss: 2.484097719192505
Validation loss: 2.080251257906678

Epoch: 5| Step: 8
Training loss: 2.149442434310913
Validation loss: 2.0876654706975466

Epoch: 5| Step: 9
Training loss: 2.3812122344970703
Validation loss: 2.115900331927884

Epoch: 5| Step: 10
Training loss: 2.216503143310547
Validation loss: 2.107410104044022

Epoch: 102| Step: 0
Training loss: 2.764954090118408
Validation loss: 2.1058897587560836

Epoch: 5| Step: 1
Training loss: 2.598174571990967
Validation loss: 2.1004399791840584

Epoch: 5| Step: 2
Training loss: 2.396939992904663
Validation loss: 2.1204337407183904

Epoch: 5| Step: 3
Training loss: 2.0963687896728516
Validation loss: 2.127043321568479

Epoch: 5| Step: 4
Training loss: 2.3205831050872803
Validation loss: 2.137043801687097

Epoch: 5| Step: 5
Training loss: 1.3919768333435059
Validation loss: 2.1210055402530137

Epoch: 5| Step: 6
Training loss: 1.9911190271377563
Validation loss: 2.1176848360287246

Epoch: 5| Step: 7
Training loss: 1.3973227739334106
Validation loss: 2.1181079661974342

Epoch: 5| Step: 8
Training loss: 2.839787006378174
Validation loss: 2.1121924743857434

Epoch: 5| Step: 9
Training loss: 2.0529322624206543
Validation loss: 2.0943627985574866

Epoch: 5| Step: 10
Training loss: 2.0447442531585693
Validation loss: 2.06416908643579

Epoch: 103| Step: 0
Training loss: 2.31658673286438
Validation loss: 2.035814239132789

Epoch: 5| Step: 1
Training loss: 2.507354259490967
Validation loss: 2.0101075531334005

Epoch: 5| Step: 2
Training loss: 2.4098284244537354
Validation loss: 1.989738046482045

Epoch: 5| Step: 3
Training loss: 2.140828847885132
Validation loss: 1.995559751346547

Epoch: 5| Step: 4
Training loss: 2.2784841060638428
Validation loss: 1.990313942714404

Epoch: 5| Step: 5
Training loss: 2.1129963397979736
Validation loss: 2.005823989068308

Epoch: 5| Step: 6
Training loss: 1.9689613580703735
Validation loss: 2.0113705332561205

Epoch: 5| Step: 7
Training loss: 2.1111340522766113
Validation loss: 2.0221506921193932

Epoch: 5| Step: 8
Training loss: 1.5897756814956665
Validation loss: 2.0280961349446285

Epoch: 5| Step: 9
Training loss: 2.220778703689575
Validation loss: 2.036466101164459

Epoch: 5| Step: 10
Training loss: 2.286761522293091
Validation loss: 2.0527781107092418

Epoch: 104| Step: 0
Training loss: 2.3802504539489746
Validation loss: 2.0655861208515782

Epoch: 5| Step: 1
Training loss: 1.9776413440704346
Validation loss: 2.0646072715841313

Epoch: 5| Step: 2
Training loss: 2.209618330001831
Validation loss: 2.065809826697073

Epoch: 5| Step: 3
Training loss: 2.2294580936431885
Validation loss: 2.077285183373318

Epoch: 5| Step: 4
Training loss: 2.5514187812805176
Validation loss: 2.0631104066807735

Epoch: 5| Step: 5
Training loss: 2.687197685241699
Validation loss: 2.046693450661116

Epoch: 5| Step: 6
Training loss: 1.717508316040039
Validation loss: 2.027855311670611

Epoch: 5| Step: 7
Training loss: 1.7481212615966797
Validation loss: 2.022836897962837

Epoch: 5| Step: 8
Training loss: 2.046257734298706
Validation loss: 2.027310371398926

Epoch: 5| Step: 9
Training loss: 2.0715956687927246
Validation loss: 2.024758182546144

Epoch: 5| Step: 10
Training loss: 2.213282585144043
Validation loss: 2.0245034566489597

Epoch: 105| Step: 0
Training loss: 2.317408800125122
Validation loss: 2.0326769390413837

Epoch: 5| Step: 1
Training loss: 1.808441162109375
Validation loss: 2.04203506951691

Epoch: 5| Step: 2
Training loss: 1.9842113256454468
Validation loss: 2.045222948956233

Epoch: 5| Step: 3
Training loss: 2.2056326866149902
Validation loss: 2.0447575738353114

Epoch: 5| Step: 4
Training loss: 2.2771873474121094
Validation loss: 2.0582526473588842

Epoch: 5| Step: 5
Training loss: 2.1661276817321777
Validation loss: 2.0623176764416438

Epoch: 5| Step: 6
Training loss: 2.0801844596862793
Validation loss: 2.0666748234020766

Epoch: 5| Step: 7
Training loss: 1.803551435470581
Validation loss: 2.0651505044711533

Epoch: 5| Step: 8
Training loss: 2.03471302986145
Validation loss: 2.0760374812669653

Epoch: 5| Step: 9
Training loss: 1.8328313827514648
Validation loss: 2.074519585537654

Epoch: 5| Step: 10
Training loss: 2.9481115341186523
Validation loss: 2.0707966448158346

Epoch: 106| Step: 0
Training loss: 1.7003885507583618
Validation loss: 2.074351167166105

Epoch: 5| Step: 1
Training loss: 2.4325857162475586
Validation loss: 2.083176253944315

Epoch: 5| Step: 2
Training loss: 2.392484664916992
Validation loss: 2.072737464340784

Epoch: 5| Step: 3
Training loss: 2.1698708534240723
Validation loss: 2.0759726955044653

Epoch: 5| Step: 4
Training loss: 1.666599988937378
Validation loss: 2.0927603014053835

Epoch: 5| Step: 5
Training loss: 2.173879623413086
Validation loss: 2.0952339069817656

Epoch: 5| Step: 6
Training loss: 1.5576146841049194
Validation loss: 2.076792582388847

Epoch: 5| Step: 7
Training loss: 2.491213083267212
Validation loss: 2.0658902904038787

Epoch: 5| Step: 8
Training loss: 2.5579514503479004
Validation loss: 2.06541730255209

Epoch: 5| Step: 9
Training loss: 1.9197666645050049
Validation loss: 2.052153082304103

Epoch: 5| Step: 10
Training loss: 2.0615503787994385
Validation loss: 2.0405295164354387

Epoch: 107| Step: 0
Training loss: 1.9761409759521484
Validation loss: 2.0444258259188746

Epoch: 5| Step: 1
Training loss: 2.2284748554229736
Validation loss: 2.038929952088223

Epoch: 5| Step: 2
Training loss: 2.1788394451141357
Validation loss: 2.0389586212814494

Epoch: 5| Step: 3
Training loss: 1.8131446838378906
Validation loss: 2.038328170776367

Epoch: 5| Step: 4
Training loss: 2.2054648399353027
Validation loss: 2.027243668033231

Epoch: 5| Step: 5
Training loss: 2.2224955558776855
Validation loss: 2.0296243211274505

Epoch: 5| Step: 6
Training loss: 1.4518709182739258
Validation loss: 2.028702271881924

Epoch: 5| Step: 7
Training loss: 1.63168466091156
Validation loss: 2.04391699324372

Epoch: 5| Step: 8
Training loss: 2.431272268295288
Validation loss: 2.058912008039413

Epoch: 5| Step: 9
Training loss: 2.05505108833313
Validation loss: 2.0901257209880377

Epoch: 5| Step: 10
Training loss: 3.0873265266418457
Validation loss: 2.0983094220520346

Epoch: 108| Step: 0
Training loss: 2.015594244003296
Validation loss: 2.110382103150891

Epoch: 5| Step: 1
Training loss: 2.0667145252227783
Validation loss: 2.1055047717145694

Epoch: 5| Step: 2
Training loss: 3.0752511024475098
Validation loss: 2.1016159595981723

Epoch: 5| Step: 3
Training loss: 2.2094082832336426
Validation loss: 2.0998153019976873

Epoch: 5| Step: 4
Training loss: 2.119765520095825
Validation loss: 2.0996214805110807

Epoch: 5| Step: 5
Training loss: 1.4432411193847656
Validation loss: 2.0922960389044976

Epoch: 5| Step: 6
Training loss: 2.103682279586792
Validation loss: 2.084054805899179

Epoch: 5| Step: 7
Training loss: 1.8394105434417725
Validation loss: 2.0761929135168753

Epoch: 5| Step: 8
Training loss: 2.0836257934570312
Validation loss: 2.0588869792158886

Epoch: 5| Step: 9
Training loss: 2.3859012126922607
Validation loss: 2.039826331600066

Epoch: 5| Step: 10
Training loss: 1.4082424640655518
Validation loss: 2.0489462793514295

Epoch: 109| Step: 0
Training loss: 2.4282591342926025
Validation loss: 2.063136093078121

Epoch: 5| Step: 1
Training loss: 2.114469528198242
Validation loss: 2.0556750092455136

Epoch: 5| Step: 2
Training loss: 1.5872894525527954
Validation loss: 2.0350137807989634

Epoch: 5| Step: 3
Training loss: 2.500788688659668
Validation loss: 2.029559662265162

Epoch: 5| Step: 4
Training loss: 2.214139461517334
Validation loss: 2.0285718851192023

Epoch: 5| Step: 5
Training loss: 2.1024727821350098
Validation loss: 2.0256467480813303

Epoch: 5| Step: 6
Training loss: 1.4983848333358765
Validation loss: 2.033701060920633

Epoch: 5| Step: 7
Training loss: 2.2048282623291016
Validation loss: 2.049051341190133

Epoch: 5| Step: 8
Training loss: 2.1593425273895264
Validation loss: 2.073307870536722

Epoch: 5| Step: 9
Training loss: 1.7287471294403076
Validation loss: 2.1078394459139917

Epoch: 5| Step: 10
Training loss: 2.3824095726013184
Validation loss: 2.1633680200064056

Epoch: 110| Step: 0
Training loss: 2.3834824562072754
Validation loss: 2.1750330719896542

Epoch: 5| Step: 1
Training loss: 2.1364083290100098
Validation loss: 2.154924364500148

Epoch: 5| Step: 2
Training loss: 2.4041624069213867
Validation loss: 2.1256437378544963

Epoch: 5| Step: 3
Training loss: 1.7579389810562134
Validation loss: 2.0866326619220037

Epoch: 5| Step: 4
Training loss: 1.6231021881103516
Validation loss: 2.0552429127436813

Epoch: 5| Step: 5
Training loss: 1.9839061498641968
Validation loss: 2.0513906222517773

Epoch: 5| Step: 6
Training loss: 2.7199509143829346
Validation loss: 2.042845969559044

Epoch: 5| Step: 7
Training loss: 1.696864366531372
Validation loss: 2.0285857915878296

Epoch: 5| Step: 8
Training loss: 2.5645127296447754
Validation loss: 2.0336506520548174

Epoch: 5| Step: 9
Training loss: 1.6939811706542969
Validation loss: 2.0398039151263494

Epoch: 5| Step: 10
Training loss: 2.322019577026367
Validation loss: 2.0564160603348927

Epoch: 111| Step: 0
Training loss: 2.4226181507110596
Validation loss: 2.0631251309507634

Epoch: 5| Step: 1
Training loss: 2.059098243713379
Validation loss: 2.063563903172811

Epoch: 5| Step: 2
Training loss: 1.8771699666976929
Validation loss: 2.072871764500936

Epoch: 5| Step: 3
Training loss: 2.260887622833252
Validation loss: 2.0648235249262985

Epoch: 5| Step: 4
Training loss: 2.7762348651885986
Validation loss: 2.0547655269663823

Epoch: 5| Step: 5
Training loss: 1.3301451206207275
Validation loss: 2.050624757684687

Epoch: 5| Step: 6
Training loss: 1.5968372821807861
Validation loss: 2.0323412008182977

Epoch: 5| Step: 7
Training loss: 2.322566509246826
Validation loss: 2.0120057828964724

Epoch: 5| Step: 8
Training loss: 2.2682247161865234
Validation loss: 2.050440513959495

Epoch: 5| Step: 9
Training loss: 1.6182734966278076
Validation loss: 2.090403523496402

Epoch: 5| Step: 10
Training loss: 2.529113531112671
Validation loss: 2.1258711430334274

Epoch: 112| Step: 0
Training loss: 2.4573330879211426
Validation loss: 2.1597113160676855

Epoch: 5| Step: 1
Training loss: 1.785313367843628
Validation loss: 2.1654785140868156

Epoch: 5| Step: 2
Training loss: 2.5404224395751953
Validation loss: 2.1503372961475002

Epoch: 5| Step: 3
Training loss: 2.2508273124694824
Validation loss: 2.1283784527932443

Epoch: 5| Step: 4
Training loss: 2.015369415283203
Validation loss: 2.1050752106533257

Epoch: 5| Step: 5
Training loss: 2.391395092010498
Validation loss: 2.0697654959976033

Epoch: 5| Step: 6
Training loss: 1.8569233417510986
Validation loss: 2.0638694353001092

Epoch: 5| Step: 7
Training loss: 2.3395965099334717
Validation loss: 2.035858815716159

Epoch: 5| Step: 8
Training loss: 1.3721128702163696
Validation loss: 2.0336550743349138

Epoch: 5| Step: 9
Training loss: 1.8967167139053345
Validation loss: 2.03710598586708

Epoch: 5| Step: 10
Training loss: 2.2096736431121826
Validation loss: 2.0408320785850607

Epoch: 113| Step: 0
Training loss: 2.0370945930480957
Validation loss: 2.0544069582416165

Epoch: 5| Step: 1
Training loss: 2.2017323970794678
Validation loss: 2.0670590887787523

Epoch: 5| Step: 2
Training loss: 1.3625606298446655
Validation loss: 2.066914468683222

Epoch: 5| Step: 3
Training loss: 2.4091484546661377
Validation loss: 2.0754264631579

Epoch: 5| Step: 4
Training loss: 2.1352767944335938
Validation loss: 2.092285515159689

Epoch: 5| Step: 5
Training loss: 2.0093255043029785
Validation loss: 2.0916061555185625

Epoch: 5| Step: 6
Training loss: 1.3146350383758545
Validation loss: 2.078368707369733

Epoch: 5| Step: 7
Training loss: 2.404787302017212
Validation loss: 2.068760980841934

Epoch: 5| Step: 8
Training loss: 2.2940948009490967
Validation loss: 2.081875821595551

Epoch: 5| Step: 9
Training loss: 2.459660053253174
Validation loss: 2.0921551771061395

Epoch: 5| Step: 10
Training loss: 1.8084464073181152
Validation loss: 2.0991779963175454

Epoch: 114| Step: 0
Training loss: 1.686098337173462
Validation loss: 2.08607643265878

Epoch: 5| Step: 1
Training loss: 2.123344898223877
Validation loss: 2.075145703490062

Epoch: 5| Step: 2
Training loss: 2.0886409282684326
Validation loss: 2.0878585205283215

Epoch: 5| Step: 3
Training loss: 2.6181912422180176
Validation loss: 2.0974126849123227

Epoch: 5| Step: 4
Training loss: 2.1204445362091064
Validation loss: 2.0869310312373663

Epoch: 5| Step: 5
Training loss: 2.4086060523986816
Validation loss: 2.0754926127772175

Epoch: 5| Step: 6
Training loss: 2.316682815551758
Validation loss: 2.065560030680831

Epoch: 5| Step: 7
Training loss: 1.937758207321167
Validation loss: 2.04604669027431

Epoch: 5| Step: 8
Training loss: 1.2093241214752197
Validation loss: 2.0350110146307174

Epoch: 5| Step: 9
Training loss: 2.040584087371826
Validation loss: 2.0409919754151375

Epoch: 5| Step: 10
Training loss: 1.9556137323379517
Validation loss: 2.0380779107411704

Epoch: 115| Step: 0
Training loss: 2.3898508548736572
Validation loss: 2.04461766827491

Epoch: 5| Step: 1
Training loss: 2.209444761276245
Validation loss: 2.040019835195234

Epoch: 5| Step: 2
Training loss: 2.5659306049346924
Validation loss: 2.0248342483274397

Epoch: 5| Step: 3
Training loss: 1.800229787826538
Validation loss: 2.0107834300687237

Epoch: 5| Step: 4
Training loss: 1.561725378036499
Validation loss: 2.019535049315422

Epoch: 5| Step: 5
Training loss: 1.3404028415679932
Validation loss: 2.0405207705754105

Epoch: 5| Step: 6
Training loss: 1.7251272201538086
Validation loss: 2.040694587974138

Epoch: 5| Step: 7
Training loss: 2.0467305183410645
Validation loss: 2.062228282292684

Epoch: 5| Step: 8
Training loss: 2.4628186225891113
Validation loss: 2.078471185058676

Epoch: 5| Step: 9
Training loss: 2.1682236194610596
Validation loss: 2.0896402110335646

Epoch: 5| Step: 10
Training loss: 1.9623156785964966
Validation loss: 2.107886665610857

Epoch: 116| Step: 0
Training loss: 2.2285690307617188
Validation loss: 2.1168901394772273

Epoch: 5| Step: 1
Training loss: 1.7005659341812134
Validation loss: 2.1472595276371127

Epoch: 5| Step: 2
Training loss: 2.1608760356903076
Validation loss: 2.1423575570506435

Epoch: 5| Step: 3
Training loss: 2.165285587310791
Validation loss: 2.179882203378985

Epoch: 5| Step: 4
Training loss: 2.148355007171631
Validation loss: 2.1817455881385395

Epoch: 5| Step: 5
Training loss: 2.1562459468841553
Validation loss: 2.1559867730704685

Epoch: 5| Step: 6
Training loss: 2.367893695831299
Validation loss: 2.1523243714404363

Epoch: 5| Step: 7
Training loss: 1.8119628429412842
Validation loss: 2.130844703284643

Epoch: 5| Step: 8
Training loss: 1.9458316564559937
Validation loss: 2.109725393274779

Epoch: 5| Step: 9
Training loss: 2.0356037616729736
Validation loss: 2.101905266443888

Epoch: 5| Step: 10
Training loss: 1.6088789701461792
Validation loss: 2.0926783046414776

Epoch: 117| Step: 0
Training loss: 2.1994686126708984
Validation loss: 2.0855089823404946

Epoch: 5| Step: 1
Training loss: 2.330570936203003
Validation loss: 2.0745966331933134

Epoch: 5| Step: 2
Training loss: 1.6079059839248657
Validation loss: 2.0683733263323383

Epoch: 5| Step: 3
Training loss: 2.306516647338867
Validation loss: 2.0566954612731934

Epoch: 5| Step: 4
Training loss: 2.039088010787964
Validation loss: 2.0367547747909382

Epoch: 5| Step: 5
Training loss: 2.273643732070923
Validation loss: 2.010434567287404

Epoch: 5| Step: 6
Training loss: 1.7583816051483154
Validation loss: 1.9961653896557388

Epoch: 5| Step: 7
Training loss: 2.6848080158233643
Validation loss: 2.0096518301194712

Epoch: 5| Step: 8
Training loss: 2.0357167720794678
Validation loss: 2.0300840485480522

Epoch: 5| Step: 9
Training loss: 1.8767772912979126
Validation loss: 2.0489967817901285

Epoch: 5| Step: 10
Training loss: 1.379835605621338
Validation loss: 2.1061413365025676

Epoch: 118| Step: 0
Training loss: 2.7959816455841064
Validation loss: 2.10966129713161

Epoch: 5| Step: 1
Training loss: 2.430363178253174
Validation loss: 2.112076353001338

Epoch: 5| Step: 2
Training loss: 2.0897281169891357
Validation loss: 2.106211118800666

Epoch: 5| Step: 3
Training loss: 2.1031877994537354
Validation loss: 2.088809246657997

Epoch: 5| Step: 4
Training loss: 1.899664282798767
Validation loss: 2.078445884489244

Epoch: 5| Step: 5
Training loss: 2.0123467445373535
Validation loss: 2.0569758453676776

Epoch: 5| Step: 6
Training loss: 1.8523041009902954
Validation loss: 2.053317969845187

Epoch: 5| Step: 7
Training loss: 1.903909683227539
Validation loss: 2.0971657281280844

Epoch: 5| Step: 8
Training loss: 1.9452323913574219
Validation loss: 2.1024484608763006

Epoch: 5| Step: 9
Training loss: 1.802605390548706
Validation loss: 2.09263180148217

Epoch: 5| Step: 10
Training loss: 1.3834689855575562
Validation loss: 2.0732993848862185

Epoch: 119| Step: 0
Training loss: 1.928288221359253
Validation loss: 2.0593005303413636

Epoch: 5| Step: 1
Training loss: 1.9226354360580444
Validation loss: 2.0642058208424556

Epoch: 5| Step: 2
Training loss: 1.9414889812469482
Validation loss: 2.067996650613764

Epoch: 5| Step: 3
Training loss: 2.1704652309417725
Validation loss: 2.090491556352185

Epoch: 5| Step: 4
Training loss: 1.9670908451080322
Validation loss: 2.0814225007128972

Epoch: 5| Step: 5
Training loss: 2.046276807785034
Validation loss: 2.0914648297012493

Epoch: 5| Step: 6
Training loss: 2.4005372524261475
Validation loss: 2.101897075612058

Epoch: 5| Step: 7
Training loss: 2.284682035446167
Validation loss: 2.090301831563314

Epoch: 5| Step: 8
Training loss: 2.120109796524048
Validation loss: 2.086502650732635

Epoch: 5| Step: 9
Training loss: 0.8440402746200562
Validation loss: 2.0760777778522943

Epoch: 5| Step: 10
Training loss: 2.447782516479492
Validation loss: 2.040823672407417

Epoch: 120| Step: 0
Training loss: 1.7314364910125732
Validation loss: 2.0364731075943157

Epoch: 5| Step: 1
Training loss: 2.1723523139953613
Validation loss: 2.0285148133513746

Epoch: 5| Step: 2
Training loss: 2.0352942943573
Validation loss: 2.0297317479246404

Epoch: 5| Step: 3
Training loss: 1.2978074550628662
Validation loss: 2.0277366715092815

Epoch: 5| Step: 4
Training loss: 2.2967374324798584
Validation loss: 2.03572916728194

Epoch: 5| Step: 5
Training loss: 2.0001282691955566
Validation loss: 2.029502719961187

Epoch: 5| Step: 6
Training loss: 2.5551865100860596
Validation loss: 2.040624382675335

Epoch: 5| Step: 7
Training loss: 2.0696017742156982
Validation loss: 2.0458366781152706

Epoch: 5| Step: 8
Training loss: 1.7118046283721924
Validation loss: 2.0675927464680006

Epoch: 5| Step: 9
Training loss: 1.5018670558929443
Validation loss: 2.0890969281555503

Epoch: 5| Step: 10
Training loss: 2.802584648132324
Validation loss: 2.0911788094428276

Epoch: 121| Step: 0
Training loss: 1.6889740228652954
Validation loss: 2.1021066955340806

Epoch: 5| Step: 1
Training loss: 2.1195836067199707
Validation loss: 2.112374846653272

Epoch: 5| Step: 2
Training loss: 2.5363917350769043
Validation loss: 2.1278412457435363

Epoch: 5| Step: 3
Training loss: 2.261091709136963
Validation loss: 2.103010103266726

Epoch: 5| Step: 4
Training loss: 2.321608543395996
Validation loss: 2.0818439786152174

Epoch: 5| Step: 5
Training loss: 2.1840031147003174
Validation loss: 2.075250917865384

Epoch: 5| Step: 6
Training loss: 2.07928729057312
Validation loss: 2.0688563880100044

Epoch: 5| Step: 7
Training loss: 1.3327667713165283
Validation loss: 2.053361092844317

Epoch: 5| Step: 8
Training loss: 1.5237572193145752
Validation loss: 2.0357329704428233

Epoch: 5| Step: 9
Training loss: 1.8833757638931274
Validation loss: 2.0348195465662147

Epoch: 5| Step: 10
Training loss: 1.8201876878738403
Validation loss: 2.024558018612605

Epoch: 122| Step: 0
Training loss: 1.624211072921753
Validation loss: 2.036215397619432

Epoch: 5| Step: 1
Training loss: 1.8871047496795654
Validation loss: 2.0308541046675814

Epoch: 5| Step: 2
Training loss: 1.7711855173110962
Validation loss: 2.0349960891149377

Epoch: 5| Step: 3
Training loss: 1.2848161458969116
Validation loss: 2.027088289619774

Epoch: 5| Step: 4
Training loss: 1.6340452432632446
Validation loss: 2.01860838038947

Epoch: 5| Step: 5
Training loss: 2.373439073562622
Validation loss: 2.027414575699837

Epoch: 5| Step: 6
Training loss: 1.7566163539886475
Validation loss: 2.040600492108253

Epoch: 5| Step: 7
Training loss: 1.9382011890411377
Validation loss: 2.0424867112149476

Epoch: 5| Step: 8
Training loss: 2.6189911365509033
Validation loss: 2.0576717738182313

Epoch: 5| Step: 9
Training loss: 2.0093202590942383
Validation loss: 2.057399406228014

Epoch: 5| Step: 10
Training loss: 2.6908600330352783
Validation loss: 2.0589537671817246

Epoch: 123| Step: 0
Training loss: 1.79453444480896
Validation loss: 2.0760818886500534

Epoch: 5| Step: 1
Training loss: 1.7482373714447021
Validation loss: 2.0724963936754452

Epoch: 5| Step: 2
Training loss: 1.0530979633331299
Validation loss: 2.09411213731253

Epoch: 5| Step: 3
Training loss: 2.417456865310669
Validation loss: 2.0905163365025676

Epoch: 5| Step: 4
Training loss: 2.429333448410034
Validation loss: 2.101971959555021

Epoch: 5| Step: 5
Training loss: 2.126397132873535
Validation loss: 2.0784891959159606

Epoch: 5| Step: 6
Training loss: 2.4414539337158203
Validation loss: 2.0679828556635047

Epoch: 5| Step: 7
Training loss: 1.3176600933074951
Validation loss: 2.06081836710694

Epoch: 5| Step: 8
Training loss: 1.6343085765838623
Validation loss: 2.046799505910566

Epoch: 5| Step: 9
Training loss: 2.32956862449646
Validation loss: 2.041213834157554

Epoch: 5| Step: 10
Training loss: 2.2381162643432617
Validation loss: 2.034332211299609

Epoch: 124| Step: 0
Training loss: 1.5925266742706299
Validation loss: 2.033066758545496

Epoch: 5| Step: 1
Training loss: 1.6202102899551392
Validation loss: 2.0536272730878604

Epoch: 5| Step: 2
Training loss: 2.146829128265381
Validation loss: 2.050250212351481

Epoch: 5| Step: 3
Training loss: 2.630488872528076
Validation loss: 2.0525438529188915

Epoch: 5| Step: 4
Training loss: 2.2457120418548584
Validation loss: 2.0375502647892123

Epoch: 5| Step: 5
Training loss: 2.1820359230041504
Validation loss: 2.0542620638365388

Epoch: 5| Step: 6
Training loss: 1.2297533750534058
Validation loss: 2.0678434333493634

Epoch: 5| Step: 7
Training loss: 2.075904607772827
Validation loss: 2.0788422066678285

Epoch: 5| Step: 8
Training loss: 1.392148733139038
Validation loss: 2.0712417658939155

Epoch: 5| Step: 9
Training loss: 2.4577927589416504
Validation loss: 2.0676549724353257

Epoch: 5| Step: 10
Training loss: 1.5312687158584595
Validation loss: 2.072851029775476

Epoch: 125| Step: 0
Training loss: 1.8285515308380127
Validation loss: 2.059412531955268

Epoch: 5| Step: 1
Training loss: 2.0762298107147217
Validation loss: 2.064376897709344

Epoch: 5| Step: 2
Training loss: 2.6221206188201904
Validation loss: 2.0668079545420985

Epoch: 5| Step: 3
Training loss: 1.3455451726913452
Validation loss: 2.0703747041763796

Epoch: 5| Step: 4
Training loss: 2.2717185020446777
Validation loss: 2.083826777755573

Epoch: 5| Step: 5
Training loss: 1.9299932718276978
Validation loss: 2.0957978669033257

Epoch: 5| Step: 6
Training loss: 1.524071455001831
Validation loss: 2.1103918603671494

Epoch: 5| Step: 7
Training loss: 2.032599449157715
Validation loss: 2.0986234193207114

Epoch: 5| Step: 8
Training loss: 1.0438951253890991
Validation loss: 2.0960662082959245

Epoch: 5| Step: 9
Training loss: 2.1095240116119385
Validation loss: 2.0841773376669934

Epoch: 5| Step: 10
Training loss: 2.3707423210144043
Validation loss: 2.082499448971082

Epoch: 126| Step: 0
Training loss: 2.0836987495422363
Validation loss: 2.0668182937047814

Epoch: 5| Step: 1
Training loss: 1.7619984149932861
Validation loss: 2.065162484363843

Epoch: 5| Step: 2
Training loss: 1.4852237701416016
Validation loss: 2.03513801610598

Epoch: 5| Step: 3
Training loss: 1.9282443523406982
Validation loss: 2.0380278736032467

Epoch: 5| Step: 4
Training loss: 1.4270756244659424
Validation loss: 2.029419340113158

Epoch: 5| Step: 5
Training loss: 1.754845380783081
Validation loss: 2.018211136582077

Epoch: 5| Step: 6
Training loss: 2.1382675170898438
Validation loss: 2.0197259508153445

Epoch: 5| Step: 7
Training loss: 2.1959168910980225
Validation loss: 2.026346463029103

Epoch: 5| Step: 8
Training loss: 1.9838154315948486
Validation loss: 2.026960734398134

Epoch: 5| Step: 9
Training loss: 1.4880495071411133
Validation loss: 2.040650636919083

Epoch: 5| Step: 10
Training loss: 2.684920310974121
Validation loss: 2.054209286166776

Epoch: 127| Step: 0
Training loss: 1.9619356393814087
Validation loss: 2.050539783252183

Epoch: 5| Step: 1
Training loss: 1.7900558710098267
Validation loss: 2.0501014904309343

Epoch: 5| Step: 2
Training loss: 1.3559834957122803
Validation loss: 2.0539664158257107

Epoch: 5| Step: 3
Training loss: 2.0656142234802246
Validation loss: 2.0341167937042894

Epoch: 5| Step: 4
Training loss: 1.870589256286621
Validation loss: 2.0346043212439424

Epoch: 5| Step: 5
Training loss: 1.7525722980499268
Validation loss: 2.0355815733632734

Epoch: 5| Step: 6
Training loss: 1.5124263763427734
Validation loss: 2.0442417783121907

Epoch: 5| Step: 7
Training loss: 1.8886115550994873
Validation loss: 2.0362278799856863

Epoch: 5| Step: 8
Training loss: 1.488309621810913
Validation loss: 2.0349863139531945

Epoch: 5| Step: 9
Training loss: 2.224532127380371
Validation loss: 2.0401702850095687

Epoch: 5| Step: 10
Training loss: 2.638557195663452
Validation loss: 2.038083249522794

Epoch: 128| Step: 0
Training loss: 1.3962252140045166
Validation loss: 2.037012835984589

Epoch: 5| Step: 1
Training loss: 2.115647792816162
Validation loss: 2.0333070011549097

Epoch: 5| Step: 2
Training loss: 1.5322946310043335
Validation loss: 2.0256324737302718

Epoch: 5| Step: 3
Training loss: 2.0766284465789795
Validation loss: 2.036600212897024

Epoch: 5| Step: 4
Training loss: 2.0278964042663574
Validation loss: 2.050787692428917

Epoch: 5| Step: 5
Training loss: 2.0048418045043945
Validation loss: 2.0634925032174714

Epoch: 5| Step: 6
Training loss: 1.472298264503479
Validation loss: 2.079957207043966

Epoch: 5| Step: 7
Training loss: 2.177699089050293
Validation loss: 2.0801160886723506

Epoch: 5| Step: 8
Training loss: 1.7653160095214844
Validation loss: 2.103226900100708

Epoch: 5| Step: 9
Training loss: 2.128173351287842
Validation loss: 2.075132272576773

Epoch: 5| Step: 10
Training loss: 1.8757504224777222
Validation loss: 2.055018073769026

Epoch: 129| Step: 0
Training loss: 2.4130733013153076
Validation loss: 2.067070384179392

Epoch: 5| Step: 1
Training loss: 2.135612964630127
Validation loss: 2.0602920106662217

Epoch: 5| Step: 2
Training loss: 1.2904574871063232
Validation loss: 2.0663362779924945

Epoch: 5| Step: 3
Training loss: 2.3102898597717285
Validation loss: 2.06825529631748

Epoch: 5| Step: 4
Training loss: 1.8344539403915405
Validation loss: 2.0429917714929067

Epoch: 5| Step: 5
Training loss: 1.6550447940826416
Validation loss: 2.040817581197267

Epoch: 5| Step: 6
Training loss: 1.6199004650115967
Validation loss: 2.0223955274910055

Epoch: 5| Step: 7
Training loss: 1.542790412902832
Validation loss: 2.028214875087943

Epoch: 5| Step: 8
Training loss: 2.221658229827881
Validation loss: 2.0367312495426466

Epoch: 5| Step: 9
Training loss: 1.715566635131836
Validation loss: 2.0310784629596177

Epoch: 5| Step: 10
Training loss: 1.800176739692688
Validation loss: 2.040165219255673

Epoch: 130| Step: 0
Training loss: 2.0522074699401855
Validation loss: 2.029672009970552

Epoch: 5| Step: 1
Training loss: 1.8554083108901978
Validation loss: 2.0361969676069034

Epoch: 5| Step: 2
Training loss: 1.7058426141738892
Validation loss: 2.039047228392734

Epoch: 5| Step: 3
Training loss: 1.9513194561004639
Validation loss: 2.058336252807289

Epoch: 5| Step: 4
Training loss: 1.6530532836914062
Validation loss: 2.07312213349086

Epoch: 5| Step: 5
Training loss: 1.8149206638336182
Validation loss: 2.0752818097350416

Epoch: 5| Step: 6
Training loss: 1.6268367767333984
Validation loss: 2.061365883837464

Epoch: 5| Step: 7
Training loss: 1.980889916419983
Validation loss: 2.040157230951453

Epoch: 5| Step: 8
Training loss: 2.2614593505859375
Validation loss: 2.038914453598761

Epoch: 5| Step: 9
Training loss: 1.8549238443374634
Validation loss: 2.020600051008245

Epoch: 5| Step: 10
Training loss: 1.655645489692688
Validation loss: 2.022648225548447

Epoch: 131| Step: 0
Training loss: 1.8264026641845703
Validation loss: 2.0279308801056235

Epoch: 5| Step: 1
Training loss: 1.7330820560455322
Validation loss: 2.0449932634189563

Epoch: 5| Step: 2
Training loss: 2.111727476119995
Validation loss: 2.0815720968349005

Epoch: 5| Step: 3
Training loss: 1.616571068763733
Validation loss: 2.073586843347037

Epoch: 5| Step: 4
Training loss: 1.9068689346313477
Validation loss: 2.074325710214594

Epoch: 5| Step: 5
Training loss: 1.864935278892517
Validation loss: 2.0784276070133334

Epoch: 5| Step: 6
Training loss: 2.1245975494384766
Validation loss: 2.065030781171655

Epoch: 5| Step: 7
Training loss: 2.0165905952453613
Validation loss: 2.0696326558307936

Epoch: 5| Step: 8
Training loss: 1.6290476322174072
Validation loss: 2.056629858991151

Epoch: 5| Step: 9
Training loss: 2.0029184818267822
Validation loss: 2.0730025550370574

Epoch: 5| Step: 10
Training loss: 1.6653205156326294
Validation loss: 2.0797794249749955

Epoch: 132| Step: 0
Training loss: 1.8345636129379272
Validation loss: 2.0823922388015257

Epoch: 5| Step: 1
Training loss: 1.7852576971054077
Validation loss: 2.0691952449019237

Epoch: 5| Step: 2
Training loss: 1.7476857900619507
Validation loss: 2.047133594430903

Epoch: 5| Step: 3
Training loss: 2.391080141067505
Validation loss: 2.0625804726795485

Epoch: 5| Step: 4
Training loss: 1.5402084589004517
Validation loss: 2.0433271674699682

Epoch: 5| Step: 5
Training loss: 2.1724953651428223
Validation loss: 2.0443351140586277

Epoch: 5| Step: 6
Training loss: 1.8542520999908447
Validation loss: 2.04283239892734

Epoch: 5| Step: 7
Training loss: 1.8682432174682617
Validation loss: 2.027439139222586

Epoch: 5| Step: 8
Training loss: 1.7054731845855713
Validation loss: 2.0355089851604995

Epoch: 5| Step: 9
Training loss: 1.2417895793914795
Validation loss: 2.040283936326222

Epoch: 5| Step: 10
Training loss: 1.8630098104476929
Validation loss: 2.0481769346421763

Epoch: 133| Step: 0
Training loss: 1.7754743099212646
Validation loss: 2.0616967575524443

Epoch: 5| Step: 1
Training loss: 2.006655216217041
Validation loss: 2.0892746730517318

Epoch: 5| Step: 2
Training loss: 1.427189826965332
Validation loss: 2.0834885207555627

Epoch: 5| Step: 3
Training loss: 1.6307274103164673
Validation loss: 2.0632684640986945

Epoch: 5| Step: 4
Training loss: 1.555225133895874
Validation loss: 2.0599671871431413

Epoch: 5| Step: 5
Training loss: 2.1526520252227783
Validation loss: 2.062831894043953

Epoch: 5| Step: 6
Training loss: 1.6535654067993164
Validation loss: 2.05467947195935

Epoch: 5| Step: 7
Training loss: 1.7547409534454346
Validation loss: 2.071308817914737

Epoch: 5| Step: 8
Training loss: 1.8353393077850342
Validation loss: 2.057144740576385

Epoch: 5| Step: 9
Training loss: 2.225597858428955
Validation loss: 2.0447432892296904

Epoch: 5| Step: 10
Training loss: 1.925887107849121
Validation loss: 2.0536823170159453

Epoch: 134| Step: 0
Training loss: 2.2965362071990967
Validation loss: 2.07120261141049

Epoch: 5| Step: 1
Training loss: 1.9820482730865479
Validation loss: 2.069309530719634

Epoch: 5| Step: 2
Training loss: 1.6483592987060547
Validation loss: 2.0798019850125877

Epoch: 5| Step: 3
Training loss: 1.465789556503296
Validation loss: 2.0692030588785806

Epoch: 5| Step: 4
Training loss: 2.123533010482788
Validation loss: 2.0600384871164956

Epoch: 5| Step: 5
Training loss: 2.3242135047912598
Validation loss: 2.0571492692475677

Epoch: 5| Step: 6
Training loss: 1.3455047607421875
Validation loss: 2.0634404792580554

Epoch: 5| Step: 7
Training loss: 1.9202044010162354
Validation loss: 2.0601325509368733

Epoch: 5| Step: 8
Training loss: 1.4561662673950195
Validation loss: 2.0687413805274555

Epoch: 5| Step: 9
Training loss: 1.6752923727035522
Validation loss: 2.0799442414314515

Epoch: 5| Step: 10
Training loss: 1.6389750242233276
Validation loss: 2.066890690916328

Epoch: 135| Step: 0
Training loss: 1.8986711502075195
Validation loss: 2.063452564260011

Epoch: 5| Step: 1
Training loss: 1.8061097860336304
Validation loss: 2.0608896286256853

Epoch: 5| Step: 2
Training loss: 1.612013816833496
Validation loss: 2.057158059971307

Epoch: 5| Step: 3
Training loss: 1.5039771795272827
Validation loss: 2.0677211976820424

Epoch: 5| Step: 4
Training loss: 1.1731407642364502
Validation loss: 2.079265599609703

Epoch: 5| Step: 5
Training loss: 2.8901076316833496
Validation loss: 2.0856479060265327

Epoch: 5| Step: 6
Training loss: 1.763038992881775
Validation loss: 2.0706108077879875

Epoch: 5| Step: 7
Training loss: 1.910461664199829
Validation loss: 2.0593891887254614

Epoch: 5| Step: 8
Training loss: 1.7639766931533813
Validation loss: 2.055698960058151

Epoch: 5| Step: 9
Training loss: 1.8985958099365234
Validation loss: 2.0741869275287916

Epoch: 5| Step: 10
Training loss: 1.7261666059494019
Validation loss: 2.0691596948972313

Epoch: 136| Step: 0
Training loss: 1.5627778768539429
Validation loss: 2.0680432409368534

Epoch: 5| Step: 1
Training loss: 2.2420835494995117
Validation loss: 2.0724601412332184

Epoch: 5| Step: 2
Training loss: 1.1245243549346924
Validation loss: 2.066677479333775

Epoch: 5| Step: 3
Training loss: 2.122843027114868
Validation loss: 2.0533936613349506

Epoch: 5| Step: 4
Training loss: 1.8959362506866455
Validation loss: 2.0492471469345914

Epoch: 5| Step: 5
Training loss: 1.2930302619934082
Validation loss: 2.032083016569896

Epoch: 5| Step: 6
Training loss: 2.528195858001709
Validation loss: 2.0387051105499268

Epoch: 5| Step: 7
Training loss: 1.4657236337661743
Validation loss: 2.0430987086347354

Epoch: 5| Step: 8
Training loss: 1.7922680377960205
Validation loss: 2.0423781641067995

Epoch: 5| Step: 9
Training loss: 1.8103163242340088
Validation loss: 2.0654537088127545

Epoch: 5| Step: 10
Training loss: 1.724759817123413
Validation loss: 2.0648521710467596

Epoch: 137| Step: 0
Training loss: 1.2898924350738525
Validation loss: 2.0707932262010473

Epoch: 5| Step: 1
Training loss: 1.700524091720581
Validation loss: 2.0781939157875637

Epoch: 5| Step: 2
Training loss: 1.0594360828399658
Validation loss: 2.083962917327881

Epoch: 5| Step: 3
Training loss: 2.4805421829223633
Validation loss: 2.0739365585388674

Epoch: 5| Step: 4
Training loss: 1.5416299104690552
Validation loss: 2.0385783462114233

Epoch: 5| Step: 5
Training loss: 1.9223934412002563
Validation loss: 2.0218218141986477

Epoch: 5| Step: 6
Training loss: 1.3783724308013916
Validation loss: 2.0366557067440403

Epoch: 5| Step: 7
Training loss: 2.1030259132385254
Validation loss: 2.041026048762824

Epoch: 5| Step: 8
Training loss: 2.0435614585876465
Validation loss: 2.0546042919158936

Epoch: 5| Step: 9
Training loss: 1.6237274408340454
Validation loss: 2.049690908001315

Epoch: 5| Step: 10
Training loss: 2.3615634441375732
Validation loss: 2.072615082545947

Epoch: 138| Step: 0
Training loss: 1.6082985401153564
Validation loss: 2.059204929618425

Epoch: 5| Step: 1
Training loss: 2.2811195850372314
Validation loss: 2.0641609289312877

Epoch: 5| Step: 2
Training loss: 1.2851295471191406
Validation loss: 2.0586140630065755

Epoch: 5| Step: 3
Training loss: 1.9801136255264282
Validation loss: 2.050463343179354

Epoch: 5| Step: 4
Training loss: 1.8176395893096924
Validation loss: 2.054644315473495

Epoch: 5| Step: 5
Training loss: 1.87374746799469
Validation loss: 2.0402806356389034

Epoch: 5| Step: 6
Training loss: 1.5862995386123657
Validation loss: 2.038339768686602

Epoch: 5| Step: 7
Training loss: 1.9554942846298218
Validation loss: 2.045816185653851

Epoch: 5| Step: 8
Training loss: 1.7758560180664062
Validation loss: 2.064952306849982

Epoch: 5| Step: 9
Training loss: 1.2515634298324585
Validation loss: 2.0535823734857703

Epoch: 5| Step: 10
Training loss: 1.704448938369751
Validation loss: 2.0456970404553156

Epoch: 139| Step: 0
Training loss: 1.792386770248413
Validation loss: 2.065501379710372

Epoch: 5| Step: 1
Training loss: 1.5005744695663452
Validation loss: 2.0639281683070685

Epoch: 5| Step: 2
Training loss: 1.4332586526870728
Validation loss: 2.050483574149429

Epoch: 5| Step: 3
Training loss: 1.527681589126587
Validation loss: 2.0405999909165087

Epoch: 5| Step: 4
Training loss: 1.3516591787338257
Validation loss: 2.0475782091899584

Epoch: 5| Step: 5
Training loss: 2.127322196960449
Validation loss: 2.039293255857242

Epoch: 5| Step: 6
Training loss: 2.3370540142059326
Validation loss: 2.0448424636676745

Epoch: 5| Step: 7
Training loss: 2.1307365894317627
Validation loss: 2.04165667615911

Epoch: 5| Step: 8
Training loss: 1.7521803379058838
Validation loss: 2.051863952349591

Epoch: 5| Step: 9
Training loss: 1.6796295642852783
Validation loss: 2.044708789035838

Epoch: 5| Step: 10
Training loss: 1.5940816402435303
Validation loss: 2.032185459649691

Epoch: 140| Step: 0
Training loss: 1.7491859197616577
Validation loss: 2.039361603798405

Epoch: 5| Step: 1
Training loss: 1.9078786373138428
Validation loss: 2.056036562047979

Epoch: 5| Step: 2
Training loss: 1.899466872215271
Validation loss: 2.0645172685705204

Epoch: 5| Step: 3
Training loss: 1.4573829174041748
Validation loss: 2.0785448948542276

Epoch: 5| Step: 4
Training loss: 2.0825910568237305
Validation loss: 2.056340963609757

Epoch: 5| Step: 5
Training loss: 1.5765575170516968
Validation loss: 2.0377355006433304

Epoch: 5| Step: 6
Training loss: 1.5659382343292236
Validation loss: 2.017989727758592

Epoch: 5| Step: 7
Training loss: 1.8218587636947632
Validation loss: 2.018269977261943

Epoch: 5| Step: 8
Training loss: 1.1669374704360962
Validation loss: 2.0332722740788616

Epoch: 5| Step: 9
Training loss: 1.5875238180160522
Validation loss: 2.0148449508092736

Epoch: 5| Step: 10
Training loss: 2.0945355892181396
Validation loss: 2.006617722972747

Epoch: 141| Step: 0
Training loss: 1.6885582208633423
Validation loss: 1.9931575405982234

Epoch: 5| Step: 1
Training loss: 2.0630125999450684
Validation loss: 2.0126974980036416

Epoch: 5| Step: 2
Training loss: 1.3450193405151367
Validation loss: 2.0065670500519457

Epoch: 5| Step: 3
Training loss: 1.4626967906951904
Validation loss: 2.0231852890342794

Epoch: 5| Step: 4
Training loss: 1.6083545684814453
Validation loss: 2.0296599377867994

Epoch: 5| Step: 5
Training loss: 1.6853313446044922
Validation loss: 2.0456297474522747

Epoch: 5| Step: 6
Training loss: 1.520318865776062
Validation loss: 2.0447257359822593

Epoch: 5| Step: 7
Training loss: 1.5361721515655518
Validation loss: 2.048129981563937

Epoch: 5| Step: 8
Training loss: 1.7795708179473877
Validation loss: 2.03986188673204

Epoch: 5| Step: 9
Training loss: 2.31846284866333
Validation loss: 2.040342128405007

Epoch: 5| Step: 10
Training loss: 1.6098514795303345
Validation loss: 2.0408173197059223

Epoch: 142| Step: 0
Training loss: 1.2681373357772827
Validation loss: 2.0286855287449335

Epoch: 5| Step: 1
Training loss: 2.189856767654419
Validation loss: 2.0397114689632128

Epoch: 5| Step: 2
Training loss: 1.4287521839141846
Validation loss: 2.030171032874815

Epoch: 5| Step: 3
Training loss: 1.0237772464752197
Validation loss: 2.0223137614547566

Epoch: 5| Step: 4
Training loss: 1.8944644927978516
Validation loss: 2.01988229187586

Epoch: 5| Step: 5
Training loss: 2.0365841388702393
Validation loss: 2.0220822467598865

Epoch: 5| Step: 6
Training loss: 1.7005958557128906
Validation loss: 2.007270505351405

Epoch: 5| Step: 7
Training loss: 1.6660667657852173
Validation loss: 1.9981208411596154

Epoch: 5| Step: 8
Training loss: 2.225266933441162
Validation loss: 2.0066184228466404

Epoch: 5| Step: 9
Training loss: 1.2473244667053223
Validation loss: 2.0136913817415953

Epoch: 5| Step: 10
Training loss: 1.8507022857666016
Validation loss: 2.0227616089646534

Epoch: 143| Step: 0
Training loss: 1.651192307472229
Validation loss: 2.013303236294818

Epoch: 5| Step: 1
Training loss: 1.902557134628296
Validation loss: 2.013418828287432

Epoch: 5| Step: 2
Training loss: 1.4090553522109985
Validation loss: 2.0284470601748397

Epoch: 5| Step: 3
Training loss: 1.8877824544906616
Validation loss: 2.012599227248981

Epoch: 5| Step: 4
Training loss: 1.5752538442611694
Validation loss: 2.030566005296605

Epoch: 5| Step: 5
Training loss: 1.8370780944824219
Validation loss: 2.037880172011673

Epoch: 5| Step: 6
Training loss: 1.5134303569793701
Validation loss: 2.048153151748001

Epoch: 5| Step: 7
Training loss: 2.1962502002716064
Validation loss: 2.0366166983881304

Epoch: 5| Step: 8
Training loss: 1.3240997791290283
Validation loss: 2.0405066154336415

Epoch: 5| Step: 9
Training loss: 1.3184046745300293
Validation loss: 2.018080901074153

Epoch: 5| Step: 10
Training loss: 1.7119760513305664
Validation loss: 2.050138432492492

Epoch: 144| Step: 0
Training loss: 1.111741304397583
Validation loss: 2.043545353797174

Epoch: 5| Step: 1
Training loss: 1.4027925729751587
Validation loss: 2.031831137595638

Epoch: 5| Step: 2
Training loss: 1.7119085788726807
Validation loss: 2.0396939477612896

Epoch: 5| Step: 3
Training loss: 1.9342949390411377
Validation loss: 2.019361839499525

Epoch: 5| Step: 4
Training loss: 1.6101785898208618
Validation loss: 2.0242830168816353

Epoch: 5| Step: 5
Training loss: 1.7664072513580322
Validation loss: 2.0503345279283423

Epoch: 5| Step: 6
Training loss: 1.685354232788086
Validation loss: 2.052127827880203

Epoch: 5| Step: 7
Training loss: 1.9423106908798218
Validation loss: 2.046480135251117

Epoch: 5| Step: 8
Training loss: 1.843456506729126
Validation loss: 2.031782178468602

Epoch: 5| Step: 9
Training loss: 1.440548300743103
Validation loss: 2.022995102790094

Epoch: 5| Step: 10
Training loss: 1.7087295055389404
Validation loss: 2.0340312693708684

Epoch: 145| Step: 0
Training loss: 1.3492413759231567
Validation loss: 2.0478907605653167

Epoch: 5| Step: 1
Training loss: 1.3529274463653564
Validation loss: 2.0443664673836

Epoch: 5| Step: 2
Training loss: 2.1438965797424316
Validation loss: 2.0632620011606524

Epoch: 5| Step: 3
Training loss: 1.1768296957015991
Validation loss: 2.0442925422422347

Epoch: 5| Step: 4
Training loss: 1.2676154375076294
Validation loss: 2.018369218354584

Epoch: 5| Step: 5
Training loss: 1.7395366430282593
Validation loss: 2.030540920072986

Epoch: 5| Step: 6
Training loss: 1.482720136642456
Validation loss: 2.0276478900704333

Epoch: 5| Step: 7
Training loss: 2.312546968460083
Validation loss: 2.024555524190267

Epoch: 5| Step: 8
Training loss: 1.5937509536743164
Validation loss: 2.025801820139731

Epoch: 5| Step: 9
Training loss: 1.7832825183868408
Validation loss: 2.0194714069366455

Epoch: 5| Step: 10
Training loss: 1.5187485218048096
Validation loss: 2.016550592196885

Epoch: 146| Step: 0
Training loss: 1.859513521194458
Validation loss: 2.0159138710268083

Epoch: 5| Step: 1
Training loss: 1.612468957901001
Validation loss: 2.006226170447565

Epoch: 5| Step: 2
Training loss: 1.4566326141357422
Validation loss: 2.021824441930299

Epoch: 5| Step: 3
Training loss: 1.8348352909088135
Validation loss: 2.042480368768015

Epoch: 5| Step: 4
Training loss: 1.631728172302246
Validation loss: 2.0421926026703208

Epoch: 5| Step: 5
Training loss: 1.5807212591171265
Validation loss: 2.0447677027794624

Epoch: 5| Step: 6
Training loss: 1.4430347681045532
Validation loss: 2.069174566576558

Epoch: 5| Step: 7
Training loss: 1.4042003154754639
Validation loss: 2.035719439547549

Epoch: 5| Step: 8
Training loss: 1.660109281539917
Validation loss: 2.033763947025422

Epoch: 5| Step: 9
Training loss: 1.36151921749115
Validation loss: 2.06011224562122

Epoch: 5| Step: 10
Training loss: 1.8191945552825928
Validation loss: 2.0511767377135572

Epoch: 147| Step: 0
Training loss: 1.3866318464279175
Validation loss: 2.0328558593667965

Epoch: 5| Step: 1
Training loss: 1.2709136009216309
Validation loss: 2.0393747950112946

Epoch: 5| Step: 2
Training loss: 1.636840581893921
Validation loss: 2.014318750750634

Epoch: 5| Step: 3
Training loss: 2.0177412033081055
Validation loss: 2.010688579210671

Epoch: 5| Step: 4
Training loss: 1.339850664138794
Validation loss: 2.016063391521413

Epoch: 5| Step: 5
Training loss: 1.7237069606781006
Validation loss: 1.9888748532982283

Epoch: 5| Step: 6
Training loss: 1.7030216455459595
Validation loss: 2.017453888411163

Epoch: 5| Step: 7
Training loss: 1.883456826210022
Validation loss: 2.0035410773369575

Epoch: 5| Step: 8
Training loss: 1.968336820602417
Validation loss: 1.994899062700169

Epoch: 5| Step: 9
Training loss: 1.2346055507659912
Validation loss: 1.9817388032072334

Epoch: 5| Step: 10
Training loss: 1.4457663297653198
Validation loss: 1.969944736009003

Epoch: 148| Step: 0
Training loss: 1.8753821849822998
Validation loss: 1.9930464708676903

Epoch: 5| Step: 1
Training loss: 1.7115049362182617
Validation loss: 2.027701747032904

Epoch: 5| Step: 2
Training loss: 2.0723490715026855
Validation loss: 2.0906156057952554

Epoch: 5| Step: 3
Training loss: 1.5091791152954102
Validation loss: 2.104814214091147

Epoch: 5| Step: 4
Training loss: 1.5813626050949097
Validation loss: 2.0921666622161865

Epoch: 5| Step: 5
Training loss: 1.9364116191864014
Validation loss: 2.0612779996728383

Epoch: 5| Step: 6
Training loss: 1.3015415668487549
Validation loss: 2.030388362946049

Epoch: 5| Step: 7
Training loss: 1.5355432033538818
Validation loss: 2.0213404906693326

Epoch: 5| Step: 8
Training loss: 1.5271557569503784
Validation loss: 2.027853509431244

Epoch: 5| Step: 9
Training loss: 1.440677523612976
Validation loss: 2.0105292027996433

Epoch: 5| Step: 10
Training loss: 1.0449291467666626
Validation loss: 1.9993467330932617

Epoch: 149| Step: 0
Training loss: 1.741318702697754
Validation loss: 2.0136443850814656

Epoch: 5| Step: 1
Training loss: 1.4984984397888184
Validation loss: 1.9862589490029119

Epoch: 5| Step: 2
Training loss: 1.890430212020874
Validation loss: 2.0229440889050885

Epoch: 5| Step: 3
Training loss: 1.8684955835342407
Validation loss: 2.034896207112138

Epoch: 5| Step: 4
Training loss: 1.8636503219604492
Validation loss: 2.051729348398024

Epoch: 5| Step: 5
Training loss: 0.7103246450424194
Validation loss: 2.0522417483791227

Epoch: 5| Step: 6
Training loss: 1.6250708103179932
Validation loss: 2.025186727123876

Epoch: 5| Step: 7
Training loss: 1.7312614917755127
Validation loss: 2.0082687895785094

Epoch: 5| Step: 8
Training loss: 1.4182065725326538
Validation loss: 2.013543850632124

Epoch: 5| Step: 9
Training loss: 1.674451470375061
Validation loss: 2.017168234753352

Epoch: 5| Step: 10
Training loss: 1.1508972644805908
Validation loss: 2.0211167822601976

Epoch: 150| Step: 0
Training loss: 1.271337866783142
Validation loss: 2.0529569182344662

Epoch: 5| Step: 1
Training loss: 1.9040113687515259
Validation loss: 2.0554717868886967

Epoch: 5| Step: 2
Training loss: 1.2367208003997803
Validation loss: 2.082608853617022

Epoch: 5| Step: 3
Training loss: 1.8898757696151733
Validation loss: 2.0986205236886137

Epoch: 5| Step: 4
Training loss: 1.7523910999298096
Validation loss: 2.143651711043491

Epoch: 5| Step: 5
Training loss: 1.7124214172363281
Validation loss: 2.1255516018918765

Epoch: 5| Step: 6
Training loss: 1.705541968345642
Validation loss: 2.104574913619667

Epoch: 5| Step: 7
Training loss: 1.5520799160003662
Validation loss: 2.080624689338028

Epoch: 5| Step: 8
Training loss: 1.6647346019744873
Validation loss: 2.0525597526181127

Epoch: 5| Step: 9
Training loss: 1.3609416484832764
Validation loss: 2.0419186084501204

Epoch: 5| Step: 10
Training loss: 1.2994130849838257
Validation loss: 1.9960942755463302

Epoch: 151| Step: 0
Training loss: 1.3400475978851318
Validation loss: 1.9850536623308737

Epoch: 5| Step: 1
Training loss: 1.1438238620758057
Validation loss: 1.9839911947968185

Epoch: 5| Step: 2
Training loss: 1.5181554555892944
Validation loss: 1.9802997701911516

Epoch: 5| Step: 3
Training loss: 2.0433404445648193
Validation loss: 1.9892914346469346

Epoch: 5| Step: 4
Training loss: 1.651856780052185
Validation loss: 2.0111047208950086

Epoch: 5| Step: 5
Training loss: 1.0141681432724
Validation loss: 2.028203632241936

Epoch: 5| Step: 6
Training loss: 1.7573378086090088
Validation loss: 2.032065233876628

Epoch: 5| Step: 7
Training loss: 1.9903457164764404
Validation loss: 2.0432478356105026

Epoch: 5| Step: 8
Training loss: 1.1318833827972412
Validation loss: 2.0418302833393054

Epoch: 5| Step: 9
Training loss: 1.3651983737945557
Validation loss: 2.0316083508153118

Epoch: 5| Step: 10
Training loss: 2.403782367706299
Validation loss: 2.039673768064027

Epoch: 152| Step: 0
Training loss: 2.2855706214904785
Validation loss: 2.0380382922387894

Epoch: 5| Step: 1
Training loss: 1.688049077987671
Validation loss: 2.0372010507891254

Epoch: 5| Step: 2
Training loss: 1.7274240255355835
Validation loss: 2.020128380867743

Epoch: 5| Step: 3
Training loss: 1.7182461023330688
Validation loss: 1.9907682147077335

Epoch: 5| Step: 4
Training loss: 1.5936555862426758
Validation loss: 1.9955155964820617

Epoch: 5| Step: 5
Training loss: 1.3284406661987305
Validation loss: 1.98222602182819

Epoch: 5| Step: 6
Training loss: 1.1276211738586426
Validation loss: 1.989882174358573

Epoch: 5| Step: 7
Training loss: 1.7014198303222656
Validation loss: 2.009636482884807

Epoch: 5| Step: 8
Training loss: 1.4807512760162354
Validation loss: 2.012545476677597

Epoch: 5| Step: 9
Training loss: 1.6865034103393555
Validation loss: 2.025144156589303

Epoch: 5| Step: 10
Training loss: 0.6757944822311401
Validation loss: 2.030972937101959

Epoch: 153| Step: 0
Training loss: 1.5827832221984863
Validation loss: 1.9957431208702825

Epoch: 5| Step: 1
Training loss: 1.268707036972046
Validation loss: 1.9909663020923574

Epoch: 5| Step: 2
Training loss: 1.6957759857177734
Validation loss: 1.9926505780989123

Epoch: 5| Step: 3
Training loss: 1.045973777770996
Validation loss: 2.007907739249609

Epoch: 5| Step: 4
Training loss: 2.045060396194458
Validation loss: 2.0080883772142473

Epoch: 5| Step: 5
Training loss: 1.0161583423614502
Validation loss: 2.0666132703904183

Epoch: 5| Step: 6
Training loss: 1.7386060953140259
Validation loss: 2.0934926899530555

Epoch: 5| Step: 7
Training loss: 1.760620355606079
Validation loss: 2.1292625396482405

Epoch: 5| Step: 8
Training loss: 1.4924230575561523
Validation loss: 2.1548540233283915

Epoch: 5| Step: 9
Training loss: 1.7852998971939087
Validation loss: 2.12924018982918

Epoch: 5| Step: 10
Training loss: 1.8582500219345093
Validation loss: 2.0731292155481156

Epoch: 154| Step: 0
Training loss: 1.3459609746932983
Validation loss: 2.0513837106766237

Epoch: 5| Step: 1
Training loss: 1.6259195804595947
Validation loss: 2.0249297157410653

Epoch: 5| Step: 2
Training loss: 1.6747173070907593
Validation loss: 1.976001775392922

Epoch: 5| Step: 3
Training loss: 1.111246109008789
Validation loss: 1.9849780246775637

Epoch: 5| Step: 4
Training loss: 1.565953016281128
Validation loss: 1.9663869257896178

Epoch: 5| Step: 5
Training loss: 1.7186648845672607
Validation loss: 1.9584036924505746

Epoch: 5| Step: 6
Training loss: 1.1602952480316162
Validation loss: 1.958903322937668

Epoch: 5| Step: 7
Training loss: 1.502098798751831
Validation loss: 1.9660093527968212

Epoch: 5| Step: 8
Training loss: 1.434942364692688
Validation loss: 1.9751862428521598

Epoch: 5| Step: 9
Training loss: 1.9113963842391968
Validation loss: 1.9988653557274931

Epoch: 5| Step: 10
Training loss: 1.4404082298278809
Validation loss: 2.029856111413689

Epoch: 155| Step: 0
Training loss: 1.620572805404663
Validation loss: 2.0557984421330113

Epoch: 5| Step: 1
Training loss: 1.1765110492706299
Validation loss: 2.0603821662164505

Epoch: 5| Step: 2
Training loss: 0.8353699445724487
Validation loss: 2.074794861578172

Epoch: 5| Step: 3
Training loss: 1.193864345550537
Validation loss: 2.072992153065179

Epoch: 5| Step: 4
Training loss: 1.9279041290283203
Validation loss: 2.101463771635486

Epoch: 5| Step: 5
Training loss: 1.3516756296157837
Validation loss: 2.064565325296053

Epoch: 5| Step: 6
Training loss: 1.1981619596481323
Validation loss: 2.0354932174887708

Epoch: 5| Step: 7
Training loss: 1.3022860288619995
Validation loss: 2.0119799644716325

Epoch: 5| Step: 8
Training loss: 1.8133020401000977
Validation loss: 2.0092350923886864

Epoch: 5| Step: 9
Training loss: 1.6852668523788452
Validation loss: 1.9819162943029915

Epoch: 5| Step: 10
Training loss: 2.2466070652008057
Validation loss: 1.9882446809481549

Epoch: 156| Step: 0
Training loss: 1.7619235515594482
Validation loss: 1.9758751187273251

Epoch: 5| Step: 1
Training loss: 1.3860973119735718
Validation loss: 1.9737569978160243

Epoch: 5| Step: 2
Training loss: 1.3061424493789673
Validation loss: 1.9775628300123318

Epoch: 5| Step: 3
Training loss: 0.9937843084335327
Validation loss: 1.987995993706488

Epoch: 5| Step: 4
Training loss: 1.030153512954712
Validation loss: 1.9971246155359412

Epoch: 5| Step: 5
Training loss: 1.370119333267212
Validation loss: 2.0055010370028916

Epoch: 5| Step: 6
Training loss: 2.340386390686035
Validation loss: 1.9931474757450882

Epoch: 5| Step: 7
Training loss: 1.2500194311141968
Validation loss: 1.9632274053430046

Epoch: 5| Step: 8
Training loss: 1.3149349689483643
Validation loss: 1.9656629229104647

Epoch: 5| Step: 9
Training loss: 1.6721961498260498
Validation loss: 1.9483386419152702

Epoch: 5| Step: 10
Training loss: 1.707162857055664
Validation loss: 1.9615206718444824

Epoch: 157| Step: 0
Training loss: 1.3467656373977661
Validation loss: 1.9802135447020173

Epoch: 5| Step: 1
Training loss: 1.5378587245941162
Validation loss: 1.9719552865592382

Epoch: 5| Step: 2
Training loss: 1.5702532529830933
Validation loss: 1.9753565237086306

Epoch: 5| Step: 3
Training loss: 1.0159685611724854
Validation loss: 1.995482075598932

Epoch: 5| Step: 4
Training loss: 1.300769329071045
Validation loss: 2.0037554284577728

Epoch: 5| Step: 5
Training loss: 1.407677412033081
Validation loss: 2.045883483784173

Epoch: 5| Step: 6
Training loss: 1.497512698173523
Validation loss: 2.087676409752138

Epoch: 5| Step: 7
Training loss: 1.381425142288208
Validation loss: 2.1181605913305797

Epoch: 5| Step: 8
Training loss: 1.2864677906036377
Validation loss: 2.102192340358611

Epoch: 5| Step: 9
Training loss: 1.464420199394226
Validation loss: 2.097043106632848

Epoch: 5| Step: 10
Training loss: 1.9377347230911255
Validation loss: 2.0838925966652493

Epoch: 158| Step: 0
Training loss: 1.1779460906982422
Validation loss: 2.067048074096762

Epoch: 5| Step: 1
Training loss: 1.6413915157318115
Validation loss: 2.042549112791656

Epoch: 5| Step: 2
Training loss: 1.7351562976837158
Validation loss: 2.052842991326445

Epoch: 5| Step: 3
Training loss: 1.0526745319366455
Validation loss: 2.050591577765762

Epoch: 5| Step: 4
Training loss: 1.234548568725586
Validation loss: 2.053957264910462

Epoch: 5| Step: 5
Training loss: 1.3682199716567993
Validation loss: 2.037121429238268

Epoch: 5| Step: 6
Training loss: 1.9098436832427979
Validation loss: 2.047323247437836

Epoch: 5| Step: 7
Training loss: 1.2196046113967896
Validation loss: 2.0357781353817193

Epoch: 5| Step: 8
Training loss: 1.9968572854995728
Validation loss: 2.0109580229687434

Epoch: 5| Step: 9
Training loss: 1.1388299465179443
Validation loss: 2.01534072045357

Epoch: 5| Step: 10
Training loss: 1.0100163221359253
Validation loss: 2.008162103673463

Epoch: 159| Step: 0
Training loss: 1.1454205513000488
Validation loss: 2.0185396966113838

Epoch: 5| Step: 1
Training loss: 1.682794213294983
Validation loss: 2.0173211892445884

Epoch: 5| Step: 2
Training loss: 1.4329583644866943
Validation loss: 1.9929819953057073

Epoch: 5| Step: 3
Training loss: 1.8696155548095703
Validation loss: 1.9956701237668273

Epoch: 5| Step: 4
Training loss: 1.6151479482650757
Validation loss: 1.9849660781122023

Epoch: 5| Step: 5
Training loss: 1.4078843593597412
Validation loss: 1.9963918091148458

Epoch: 5| Step: 6
Training loss: 1.2631322145462036
Validation loss: 2.0000197438783545

Epoch: 5| Step: 7
Training loss: 1.1938756704330444
Validation loss: 2.0314522212551487

Epoch: 5| Step: 8
Training loss: 0.9735246896743774
Validation loss: 2.049728503791235

Epoch: 5| Step: 9
Training loss: 1.5029633045196533
Validation loss: 2.0452717465739094

Epoch: 5| Step: 10
Training loss: 1.2627439498901367
Validation loss: 2.0599436580493884

Epoch: 160| Step: 0
Training loss: 1.2180054187774658
Validation loss: 2.089251684886153

Epoch: 5| Step: 1
Training loss: 1.7773950099945068
Validation loss: 2.077153380199145

Epoch: 5| Step: 2
Training loss: 1.420636773109436
Validation loss: 2.076564327363045

Epoch: 5| Step: 3
Training loss: 1.570515513420105
Validation loss: 2.05181739535383

Epoch: 5| Step: 4
Training loss: 1.7431808710098267
Validation loss: 2.0233741114216466

Epoch: 5| Step: 5
Training loss: 1.0658595561981201
Validation loss: 2.0177999722060336

Epoch: 5| Step: 6
Training loss: 1.0325677394866943
Validation loss: 2.0225190783059723

Epoch: 5| Step: 7
Training loss: 1.3049603700637817
Validation loss: 2.029775195224311

Epoch: 5| Step: 8
Training loss: 1.5292972326278687
Validation loss: 2.0218057094081754

Epoch: 5| Step: 9
Training loss: 1.0099258422851562
Validation loss: 2.049062431499522

Epoch: 5| Step: 10
Training loss: 1.6679637432098389
Validation loss: 2.061940180358066

Epoch: 161| Step: 0
Training loss: 1.7900173664093018
Validation loss: 2.0325264930725098

Epoch: 5| Step: 1
Training loss: 1.203617811203003
Validation loss: 2.0210237887597855

Epoch: 5| Step: 2
Training loss: 1.1434094905853271
Validation loss: 2.001093018439508

Epoch: 5| Step: 3
Training loss: 1.4455674886703491
Validation loss: 2.0033595010798466

Epoch: 5| Step: 4
Training loss: 1.9387304782867432
Validation loss: 2.005086386075584

Epoch: 5| Step: 5
Training loss: 1.3703362941741943
Validation loss: 2.008163082984186

Epoch: 5| Step: 6
Training loss: 1.7376600503921509
Validation loss: 2.0345555300353677

Epoch: 5| Step: 7
Training loss: 0.9055718183517456
Validation loss: 2.028830391104503

Epoch: 5| Step: 8
Training loss: 1.2840092182159424
Validation loss: 2.0394991469639603

Epoch: 5| Step: 9
Training loss: 1.0615551471710205
Validation loss: 2.031074712353368

Epoch: 5| Step: 10
Training loss: 1.3685840368270874
Validation loss: 2.0686396911580074

Epoch: 162| Step: 0
Training loss: 0.9107105135917664
Validation loss: 2.061019612896827

Epoch: 5| Step: 1
Training loss: 1.4456878900527954
Validation loss: 2.041795269135506

Epoch: 5| Step: 2
Training loss: 1.2953598499298096
Validation loss: 2.049878305004489

Epoch: 5| Step: 3
Training loss: 1.8314502239227295
Validation loss: 2.024826030577383

Epoch: 5| Step: 4
Training loss: 1.097407579421997
Validation loss: 2.0006891155755646

Epoch: 5| Step: 5
Training loss: 1.2721645832061768
Validation loss: 2.0057768949898342

Epoch: 5| Step: 6
Training loss: 1.097536325454712
Validation loss: 1.9722021151614446

Epoch: 5| Step: 7
Training loss: 1.6711311340332031
Validation loss: 1.983933194991081

Epoch: 5| Step: 8
Training loss: 1.3931835889816284
Validation loss: 1.9762778397529357

Epoch: 5| Step: 9
Training loss: 1.2993913888931274
Validation loss: 1.9813473211821688

Epoch: 5| Step: 10
Training loss: 1.6447844505310059
Validation loss: 2.0054543069613877

Epoch: 163| Step: 0
Training loss: 1.0144151449203491
Validation loss: 2.028103733575472

Epoch: 5| Step: 1
Training loss: 1.7133417129516602
Validation loss: 2.0480539529554305

Epoch: 5| Step: 2
Training loss: 1.5392181873321533
Validation loss: 2.0453919492742068

Epoch: 5| Step: 3
Training loss: 1.1913695335388184
Validation loss: 2.0354924689057055

Epoch: 5| Step: 4
Training loss: 1.3875833749771118
Validation loss: 2.0569485515676518

Epoch: 5| Step: 5
Training loss: 0.9044443368911743
Validation loss: 2.052366010604366

Epoch: 5| Step: 6
Training loss: 1.4047958850860596
Validation loss: 2.053273570153021

Epoch: 5| Step: 7
Training loss: 1.2347766160964966
Validation loss: 2.0582129045199324

Epoch: 5| Step: 8
Training loss: 1.139847755432129
Validation loss: 2.0528136094411216

Epoch: 5| Step: 9
Training loss: 1.8023086786270142
Validation loss: 2.038438925179102

Epoch: 5| Step: 10
Training loss: 1.2143651247024536
Validation loss: 2.0658293142113635

Epoch: 164| Step: 0
Training loss: 1.5225600004196167
Validation loss: 2.088105942613335

Epoch: 5| Step: 1
Training loss: 1.1413885354995728
Validation loss: 2.096958757728659

Epoch: 5| Step: 2
Training loss: 1.0235483646392822
Validation loss: 2.0895741267870833

Epoch: 5| Step: 3
Training loss: 1.674647569656372
Validation loss: 2.106366011404222

Epoch: 5| Step: 4
Training loss: 0.861703097820282
Validation loss: 2.077091283695672

Epoch: 5| Step: 5
Training loss: 1.099492073059082
Validation loss: 2.0632621575427312

Epoch: 5| Step: 6
Training loss: 0.9465994834899902
Validation loss: 2.051429525498421

Epoch: 5| Step: 7
Training loss: 1.4708226919174194
Validation loss: 2.044499156295612

Epoch: 5| Step: 8
Training loss: 1.1613349914550781
Validation loss: 2.0446173939653622

Epoch: 5| Step: 9
Training loss: 1.8847163915634155
Validation loss: 2.053337679114393

Epoch: 5| Step: 10
Training loss: 1.8111933469772339
Validation loss: 2.0428074995676675

Epoch: 165| Step: 0
Training loss: 1.012152075767517
Validation loss: 2.0585192890577417

Epoch: 5| Step: 1
Training loss: 1.1805874109268188
Validation loss: 2.084952696677177

Epoch: 5| Step: 2
Training loss: 1.1306679248809814
Validation loss: 2.081443807130219

Epoch: 5| Step: 3
Training loss: 1.7012345790863037
Validation loss: 2.1003311731482066

Epoch: 5| Step: 4
Training loss: 0.935402512550354
Validation loss: 2.1044689493794597

Epoch: 5| Step: 5
Training loss: 1.7840940952301025
Validation loss: 2.0541825217585408

Epoch: 5| Step: 6
Training loss: 1.3747844696044922
Validation loss: 2.0613265934810845

Epoch: 5| Step: 7
Training loss: 1.7038112878799438
Validation loss: 2.0587726305889826

Epoch: 5| Step: 8
Training loss: 1.1546701192855835
Validation loss: 2.030637095051427

Epoch: 5| Step: 9
Training loss: 0.7859503030776978
Validation loss: 2.029595926243772

Epoch: 5| Step: 10
Training loss: 1.479386329650879
Validation loss: 2.019242722501037

Epoch: 166| Step: 0
Training loss: 1.2012428045272827
Validation loss: 1.9889808111293341

Epoch: 5| Step: 1
Training loss: 1.4118086099624634
Validation loss: 2.000317629947457

Epoch: 5| Step: 2
Training loss: 1.6296974420547485
Validation loss: 2.00505349328441

Epoch: 5| Step: 3
Training loss: 1.2609411478042603
Validation loss: 1.9793852939400622

Epoch: 5| Step: 4
Training loss: 0.831001877784729
Validation loss: 2.006155019165367

Epoch: 5| Step: 5
Training loss: 1.5433070659637451
Validation loss: 2.025947875874017

Epoch: 5| Step: 6
Training loss: 1.446141004562378
Validation loss: 2.035079438199279

Epoch: 5| Step: 7
Training loss: 0.9457173347473145
Validation loss: 2.0670089234587965

Epoch: 5| Step: 8
Training loss: 1.2546330690383911
Validation loss: 1.990208734748184

Epoch: 5| Step: 9
Training loss: 1.0588147640228271
Validation loss: 1.9694092812076691

Epoch: 5| Step: 10
Training loss: 1.6340608596801758
Validation loss: 1.957236833469842

Epoch: 167| Step: 0
Training loss: 1.4766312837600708
Validation loss: 1.9758771773307555

Epoch: 5| Step: 1
Training loss: 1.101223349571228
Validation loss: 1.9736891638848089

Epoch: 5| Step: 2
Training loss: 1.2731082439422607
Validation loss: 2.0150408719175603

Epoch: 5| Step: 3
Training loss: 1.3476108312606812
Validation loss: 2.0222789472149265

Epoch: 5| Step: 4
Training loss: 1.3220701217651367
Validation loss: 2.041195305444861

Epoch: 5| Step: 5
Training loss: 1.2997722625732422
Validation loss: 2.0669188627632717

Epoch: 5| Step: 6
Training loss: 1.5718467235565186
Validation loss: 2.066341753928892

Epoch: 5| Step: 7
Training loss: 1.306168794631958
Validation loss: 2.05324806961962

Epoch: 5| Step: 8
Training loss: 1.1689690351486206
Validation loss: 2.039892941392878

Epoch: 5| Step: 9
Training loss: 1.1758803129196167
Validation loss: 2.0535039235186834

Epoch: 5| Step: 10
Training loss: 1.2623881101608276
Validation loss: 2.0573967323508313

Epoch: 168| Step: 0
Training loss: 1.1568599939346313
Validation loss: 2.0584652244403796

Epoch: 5| Step: 1
Training loss: 1.012052059173584
Validation loss: 2.052630971836787

Epoch: 5| Step: 2
Training loss: 1.5093748569488525
Validation loss: 2.050784211004934

Epoch: 5| Step: 3
Training loss: 1.7057092189788818
Validation loss: 2.0557733376820884

Epoch: 5| Step: 4
Training loss: 1.1780115365982056
Validation loss: 2.0539696267856065

Epoch: 5| Step: 5
Training loss: 1.470062017440796
Validation loss: 2.053190380014399

Epoch: 5| Step: 6
Training loss: 1.2056469917297363
Validation loss: 2.073385569357103

Epoch: 5| Step: 7
Training loss: 1.1557550430297852
Validation loss: 2.0790687427725842

Epoch: 5| Step: 8
Training loss: 1.4820523262023926
Validation loss: 2.1105521161069154

Epoch: 5| Step: 9
Training loss: 1.1720407009124756
Validation loss: 2.1087240685698805

Epoch: 5| Step: 10
Training loss: 1.0057090520858765
Validation loss: 2.072694996351837

Epoch: 169| Step: 0
Training loss: 1.0036357641220093
Validation loss: 2.045556729839694

Epoch: 5| Step: 1
Training loss: 1.2975374460220337
Validation loss: 2.0669889975619573

Epoch: 5| Step: 2
Training loss: 1.0562204122543335
Validation loss: 2.1015415499287267

Epoch: 5| Step: 3
Training loss: 1.3841601610183716
Validation loss: 2.0892196111781622

Epoch: 5| Step: 4
Training loss: 1.1517140865325928
Validation loss: 2.0775765244678785

Epoch: 5| Step: 5
Training loss: 1.2750674486160278
Validation loss: 2.0260733494194607

Epoch: 5| Step: 6
Training loss: 1.5613850355148315
Validation loss: 2.0125530086537844

Epoch: 5| Step: 7
Training loss: 1.37661874294281
Validation loss: 2.0082042960710424

Epoch: 5| Step: 8
Training loss: 1.6553153991699219
Validation loss: 2.0206615360834266

Epoch: 5| Step: 9
Training loss: 0.9866853952407837
Validation loss: 2.0554158969592025

Epoch: 5| Step: 10
Training loss: 1.3990049362182617
Validation loss: 2.071134936424994

Epoch: 170| Step: 0
Training loss: 0.9796684980392456
Validation loss: 2.1360795408166866

Epoch: 5| Step: 1
Training loss: 1.3082859516143799
Validation loss: 2.1680514248468543

Epoch: 5| Step: 2
Training loss: 1.6684761047363281
Validation loss: 2.208494891402542

Epoch: 5| Step: 3
Training loss: 1.4313900470733643
Validation loss: 2.222365005041963

Epoch: 5| Step: 4
Training loss: 1.4590803384780884
Validation loss: 2.2144732077916465

Epoch: 5| Step: 5
Training loss: 1.5055795907974243
Validation loss: 2.125370438380908

Epoch: 5| Step: 6
Training loss: 1.0434553623199463
Validation loss: 2.0379790003581713

Epoch: 5| Step: 7
Training loss: 1.082881212234497
Validation loss: 1.9773975085186701

Epoch: 5| Step: 8
Training loss: 1.6213432550430298
Validation loss: 1.9334040944294264

Epoch: 5| Step: 9
Training loss: 1.4698317050933838
Validation loss: 1.8886067341732722

Epoch: 5| Step: 10
Training loss: 1.3722206354141235
Validation loss: 1.8906122779333463

Epoch: 171| Step: 0
Training loss: 1.20969557762146
Validation loss: 1.8766040776365547

Epoch: 5| Step: 1
Training loss: 1.3128741979599
Validation loss: 1.8710270286888204

Epoch: 5| Step: 2
Training loss: 1.6609128713607788
Validation loss: 1.9309680090155652

Epoch: 5| Step: 3
Training loss: 1.6398082971572876
Validation loss: 1.9380043475858626

Epoch: 5| Step: 4
Training loss: 1.233759880065918
Validation loss: 1.9714934364441903

Epoch: 5| Step: 5
Training loss: 1.1241600513458252
Validation loss: 2.005335336090416

Epoch: 5| Step: 6
Training loss: 1.2855288982391357
Validation loss: 2.0387789767275573

Epoch: 5| Step: 7
Training loss: 1.242928147315979
Validation loss: 2.084456257922675

Epoch: 5| Step: 8
Training loss: 1.6565824747085571
Validation loss: 2.150382739241405

Epoch: 5| Step: 9
Training loss: 1.7550535202026367
Validation loss: 2.236020177923223

Epoch: 5| Step: 10
Training loss: 1.2587112188339233
Validation loss: 2.231723341890561

Epoch: 172| Step: 0
Training loss: 1.4702852964401245
Validation loss: 2.244087391002204

Epoch: 5| Step: 1
Training loss: 0.9084097146987915
Validation loss: 2.2136525492514334

Epoch: 5| Step: 2
Training loss: 1.1402827501296997
Validation loss: 2.176421706394483

Epoch: 5| Step: 3
Training loss: 1.1168432235717773
Validation loss: 2.142429318479312

Epoch: 5| Step: 4
Training loss: 1.0524370670318604
Validation loss: 2.100626876277308

Epoch: 5| Step: 5
Training loss: 1.6440216302871704
Validation loss: 2.0449266177351757

Epoch: 5| Step: 6
Training loss: 1.3505504131317139
Validation loss: 1.997421282593922

Epoch: 5| Step: 7
Training loss: 0.9809600710868835
Validation loss: 1.987905329273593

Epoch: 5| Step: 8
Training loss: 1.1520047187805176
Validation loss: 1.9716247422720796

Epoch: 5| Step: 9
Training loss: 1.59828782081604
Validation loss: 1.9675640534329157

Epoch: 5| Step: 10
Training loss: 2.0606043338775635
Validation loss: 1.9662855748207337

Epoch: 173| Step: 0
Training loss: 1.4613261222839355
Validation loss: 1.971404743450944

Epoch: 5| Step: 1
Training loss: 1.292088508605957
Validation loss: 2.0042383183715162

Epoch: 5| Step: 2
Training loss: 1.1616772413253784
Validation loss: 2.0165808611018683

Epoch: 5| Step: 3
Training loss: 1.16090726852417
Validation loss: 2.0407796700795493

Epoch: 5| Step: 4
Training loss: 1.4383013248443604
Validation loss: 2.0196495504789453

Epoch: 5| Step: 5
Training loss: 1.0331220626831055
Validation loss: 2.026783909848941

Epoch: 5| Step: 6
Training loss: 1.1757560968399048
Validation loss: 2.0106686648502143

Epoch: 5| Step: 7
Training loss: 1.0820906162261963
Validation loss: 2.014164860530566

Epoch: 5| Step: 8
Training loss: 1.4771839380264282
Validation loss: 2.0105769403519167

Epoch: 5| Step: 9
Training loss: 1.5703489780426025
Validation loss: 2.020573236609018

Epoch: 5| Step: 10
Training loss: 0.8057169318199158
Validation loss: 2.053719869223974

Epoch: 174| Step: 0
Training loss: 1.3089935779571533
Validation loss: 2.0779592875511415

Epoch: 5| Step: 1
Training loss: 1.2880933284759521
Validation loss: 2.0559544230020173

Epoch: 5| Step: 2
Training loss: 1.6285587549209595
Validation loss: 2.071730121489494

Epoch: 5| Step: 3
Training loss: 0.7257779240608215
Validation loss: 2.057168767016421

Epoch: 5| Step: 4
Training loss: 1.0444412231445312
Validation loss: 2.0716275335640035

Epoch: 5| Step: 5
Training loss: 0.926986575126648
Validation loss: 2.0540384220820602

Epoch: 5| Step: 6
Training loss: 1.0885589122772217
Validation loss: 2.064852709411293

Epoch: 5| Step: 7
Training loss: 1.4551821947097778
Validation loss: 2.064346577531548

Epoch: 5| Step: 8
Training loss: 1.3472926616668701
Validation loss: 2.059231109516595

Epoch: 5| Step: 9
Training loss: 0.9210481643676758
Validation loss: 2.0679668893096266

Epoch: 5| Step: 10
Training loss: 1.7579410076141357
Validation loss: 2.0330913271955264

Epoch: 175| Step: 0
Training loss: 0.8020893931388855
Validation loss: 2.0053192851363972

Epoch: 5| Step: 1
Training loss: 1.4748172760009766
Validation loss: 1.9790020963197112

Epoch: 5| Step: 2
Training loss: 1.4307396411895752
Validation loss: 1.9597206231086486

Epoch: 5| Step: 3
Training loss: 1.0835793018341064
Validation loss: 1.9584205868423625

Epoch: 5| Step: 4
Training loss: 1.1573847532272339
Validation loss: 1.9989727825246832

Epoch: 5| Step: 5
Training loss: 1.4977796077728271
Validation loss: 2.014762645126671

Epoch: 5| Step: 6
Training loss: 1.2237768173217773
Validation loss: 1.9926088702294134

Epoch: 5| Step: 7
Training loss: 1.2022826671600342
Validation loss: 2.0114768294877905

Epoch: 5| Step: 8
Training loss: 1.4137142896652222
Validation loss: 2.0302834677439865

Epoch: 5| Step: 9
Training loss: 0.9053748250007629
Validation loss: 2.0373405564215874

Epoch: 5| Step: 10
Training loss: 0.9649110436439514
Validation loss: 2.039475529424606

Epoch: 176| Step: 0
Training loss: 1.5087916851043701
Validation loss: 2.0502350099625124

Epoch: 5| Step: 1
Training loss: 1.272186040878296
Validation loss: 2.0486054279470958

Epoch: 5| Step: 2
Training loss: 1.3220722675323486
Validation loss: 2.041970419627364

Epoch: 5| Step: 3
Training loss: 1.4118731021881104
Validation loss: 2.044807272572671

Epoch: 5| Step: 4
Training loss: 1.0001423358917236
Validation loss: 2.016030999921983

Epoch: 5| Step: 5
Training loss: 1.6248245239257812
Validation loss: 2.0338401409887497

Epoch: 5| Step: 6
Training loss: 0.7095214128494263
Validation loss: 2.070637664487285

Epoch: 5| Step: 7
Training loss: 0.8243195414543152
Validation loss: 2.066364290893719

Epoch: 5| Step: 8
Training loss: 1.0024148225784302
Validation loss: 2.0550278694398942

Epoch: 5| Step: 9
Training loss: 1.2605267763137817
Validation loss: 2.0722576315684984

Epoch: 5| Step: 10
Training loss: 1.1988857984542847
Validation loss: 2.062181111304991

Epoch: 177| Step: 0
Training loss: 0.9631684422492981
Validation loss: 2.012230779535027

Epoch: 5| Step: 1
Training loss: 1.0983672142028809
Validation loss: 1.9962186172444334

Epoch: 5| Step: 2
Training loss: 1.0583840608596802
Validation loss: 1.976663499750117

Epoch: 5| Step: 3
Training loss: 1.2354141473770142
Validation loss: 1.9583419522931498

Epoch: 5| Step: 4
Training loss: 1.2610584497451782
Validation loss: 1.9483115032155027

Epoch: 5| Step: 5
Training loss: 1.3057522773742676
Validation loss: 1.9787486548064857

Epoch: 5| Step: 6
Training loss: 1.1038801670074463
Validation loss: 1.982591652101086

Epoch: 5| Step: 7
Training loss: 1.2650164365768433
Validation loss: 2.002414212431959

Epoch: 5| Step: 8
Training loss: 1.0940417051315308
Validation loss: 1.960463164955057

Epoch: 5| Step: 9
Training loss: 1.2679095268249512
Validation loss: 1.9885083885603054

Epoch: 5| Step: 10
Training loss: 1.282839059829712
Validation loss: 1.9908764618699268

Epoch: 178| Step: 0
Training loss: 1.0491528511047363
Validation loss: 2.0141842813902002

Epoch: 5| Step: 1
Training loss: 1.201087236404419
Validation loss: 2.0071066643602107

Epoch: 5| Step: 2
Training loss: 0.9827570915222168
Validation loss: 1.9906842375314364

Epoch: 5| Step: 3
Training loss: 1.4171696901321411
Validation loss: 1.993895584537137

Epoch: 5| Step: 4
Training loss: 1.2819361686706543
Validation loss: 1.9891935317747054

Epoch: 5| Step: 5
Training loss: 1.3964192867279053
Validation loss: 2.0329119338784167

Epoch: 5| Step: 6
Training loss: 0.8463441729545593
Validation loss: 2.0401657345474407

Epoch: 5| Step: 7
Training loss: 1.009869933128357
Validation loss: 2.0504283828120076

Epoch: 5| Step: 8
Training loss: 0.9340225458145142
Validation loss: 2.0525823511103147

Epoch: 5| Step: 9
Training loss: 1.1306308507919312
Validation loss: 2.0540049152989543

Epoch: 5| Step: 10
Training loss: 1.4303739070892334
Validation loss: 2.0658928553263345

Epoch: 179| Step: 0
Training loss: 1.1736067533493042
Validation loss: 2.056039205161474

Epoch: 5| Step: 1
Training loss: 1.0505176782608032
Validation loss: 2.033058968923425

Epoch: 5| Step: 2
Training loss: 1.287954568862915
Validation loss: 2.0165166598494335

Epoch: 5| Step: 3
Training loss: 0.8266139030456543
Validation loss: 2.029993937861535

Epoch: 5| Step: 4
Training loss: 1.1630668640136719
Validation loss: 2.0205506970805507

Epoch: 5| Step: 5
Training loss: 1.287311315536499
Validation loss: 2.014519532521566

Epoch: 5| Step: 6
Training loss: 1.2772867679595947
Validation loss: 2.0147110954407723

Epoch: 5| Step: 7
Training loss: 1.374941110610962
Validation loss: 1.985745273610597

Epoch: 5| Step: 8
Training loss: 0.9059869647026062
Validation loss: 1.9749465065617715

Epoch: 5| Step: 9
Training loss: 1.2844041585922241
Validation loss: 1.974377816723239

Epoch: 5| Step: 10
Training loss: 0.9517748355865479
Validation loss: 1.9484200426327285

Epoch: 180| Step: 0
Training loss: 1.0509377717971802
Validation loss: 1.9635604068797121

Epoch: 5| Step: 1
Training loss: 1.007668375968933
Validation loss: 2.0002032454295824

Epoch: 5| Step: 2
Training loss: 0.6117645502090454
Validation loss: 2.0170140650964554

Epoch: 5| Step: 3
Training loss: 0.9655477404594421
Validation loss: 2.0315252170767835

Epoch: 5| Step: 4
Training loss: 1.0977236032485962
Validation loss: 2.0441910733458815

Epoch: 5| Step: 5
Training loss: 1.2472126483917236
Validation loss: 2.053108704987393

Epoch: 5| Step: 6
Training loss: 1.4118716716766357
Validation loss: 2.034890695284772

Epoch: 5| Step: 7
Training loss: 1.1938648223876953
Validation loss: 2.049188070399787

Epoch: 5| Step: 8
Training loss: 1.6801378726959229
Validation loss: 2.0418908749857256

Epoch: 5| Step: 9
Training loss: 0.7715015411376953
Validation loss: 2.063251576116008

Epoch: 5| Step: 10
Training loss: 1.0389004945755005
Validation loss: 2.034671818056414

Epoch: 181| Step: 0
Training loss: 0.738409161567688
Validation loss: 2.0308086359372703

Epoch: 5| Step: 1
Training loss: 1.1666990518569946
Validation loss: 2.0434999594124417

Epoch: 5| Step: 2
Training loss: 1.2497199773788452
Validation loss: 2.031835627812211

Epoch: 5| Step: 3
Training loss: 1.1006622314453125
Validation loss: 2.0184419257666475

Epoch: 5| Step: 4
Training loss: 1.3325750827789307
Validation loss: 2.016351576774351

Epoch: 5| Step: 5
Training loss: 0.8433601260185242
Validation loss: 1.98847415754872

Epoch: 5| Step: 6
Training loss: 1.0163030624389648
Validation loss: 1.96604569496647

Epoch: 5| Step: 7
Training loss: 1.4545974731445312
Validation loss: 1.9336775784851403

Epoch: 5| Step: 8
Training loss: 1.0367498397827148
Validation loss: 1.9563142714961883

Epoch: 5| Step: 9
Training loss: 0.9521558880805969
Validation loss: 1.9206667369411838

Epoch: 5| Step: 10
Training loss: 1.1632602214813232
Validation loss: 1.9203270455842376

Epoch: 182| Step: 0
Training loss: 1.3977060317993164
Validation loss: 1.913958240580815

Epoch: 5| Step: 1
Training loss: 1.0232336521148682
Validation loss: 1.9451608786018946

Epoch: 5| Step: 2
Training loss: 1.135350227355957
Validation loss: 1.9567170668673772

Epoch: 5| Step: 3
Training loss: 1.0629323720932007
Validation loss: 1.9521128464770574

Epoch: 5| Step: 4
Training loss: 0.8250299692153931
Validation loss: 1.9508552474360312

Epoch: 5| Step: 5
Training loss: 1.006521463394165
Validation loss: 1.9909135987681728

Epoch: 5| Step: 6
Training loss: 1.163319706916809
Validation loss: 2.005873792914934

Epoch: 5| Step: 7
Training loss: 1.0789902210235596
Validation loss: 2.0199932641880487

Epoch: 5| Step: 8
Training loss: 1.214360237121582
Validation loss: 2.0809348552457747

Epoch: 5| Step: 9
Training loss: 0.9672781229019165
Validation loss: 2.0570732803754908

Epoch: 5| Step: 10
Training loss: 1.1388850212097168
Validation loss: 2.0532816738210697

Epoch: 183| Step: 0
Training loss: 0.7514764070510864
Validation loss: 2.0342267585057083

Epoch: 5| Step: 1
Training loss: 1.1879316568374634
Validation loss: 2.000814994176229

Epoch: 5| Step: 2
Training loss: 1.2025506496429443
Validation loss: 1.9813384650855936

Epoch: 5| Step: 3
Training loss: 1.0938297510147095
Validation loss: 1.9849305486166349

Epoch: 5| Step: 4
Training loss: 1.1571916341781616
Validation loss: 1.9534036177460865

Epoch: 5| Step: 5
Training loss: 0.8725780248641968
Validation loss: 1.930424367227862

Epoch: 5| Step: 6
Training loss: 1.0969314575195312
Validation loss: 1.9479546982754943

Epoch: 5| Step: 7
Training loss: 1.384703278541565
Validation loss: 1.929152802754474

Epoch: 5| Step: 8
Training loss: 1.3413513898849487
Validation loss: 1.9478025051855272

Epoch: 5| Step: 9
Training loss: 1.041137933731079
Validation loss: 1.983997557752876

Epoch: 5| Step: 10
Training loss: 0.9256725311279297
Validation loss: 2.0087241690645934

Epoch: 184| Step: 0
Training loss: 1.4271163940429688
Validation loss: 2.0168030185084187

Epoch: 5| Step: 1
Training loss: 0.8730806112289429
Validation loss: 1.9891819851372832

Epoch: 5| Step: 2
Training loss: 1.0424050092697144
Validation loss: 2.0170086929875035

Epoch: 5| Step: 3
Training loss: 1.0576279163360596
Validation loss: 2.005024512608846

Epoch: 5| Step: 4
Training loss: 0.79444420337677
Validation loss: 2.039577555912797

Epoch: 5| Step: 5
Training loss: 0.82672119140625
Validation loss: 2.0607915578349942

Epoch: 5| Step: 6
Training loss: 1.3365589380264282
Validation loss: 2.108793488112829

Epoch: 5| Step: 7
Training loss: 1.681825876235962
Validation loss: 2.083930879510859

Epoch: 5| Step: 8
Training loss: 0.8692065477371216
Validation loss: 2.0855510375832997

Epoch: 5| Step: 9
Training loss: 1.1249160766601562
Validation loss: 2.076270523891654

Epoch: 5| Step: 10
Training loss: 0.8088118433952332
Validation loss: 2.0659858360085437

Epoch: 185| Step: 0
Training loss: 1.086098551750183
Validation loss: 2.0840668960284163

Epoch: 5| Step: 1
Training loss: 0.8444180488586426
Validation loss: 2.059162806439143

Epoch: 5| Step: 2
Training loss: 1.203636884689331
Validation loss: 2.0240569576140373

Epoch: 5| Step: 3
Training loss: 0.9545170068740845
Validation loss: 2.0217428258670274

Epoch: 5| Step: 4
Training loss: 1.3510358333587646
Validation loss: 2.022308631609845

Epoch: 5| Step: 5
Training loss: 1.0978868007659912
Validation loss: 2.0010968190367504

Epoch: 5| Step: 6
Training loss: 1.1410648822784424
Validation loss: 2.0189825860402917

Epoch: 5| Step: 7
Training loss: 0.898454487323761
Validation loss: 2.035709996377268

Epoch: 5| Step: 8
Training loss: 0.9135204553604126
Validation loss: 2.0461400837026615

Epoch: 5| Step: 9
Training loss: 1.161516547203064
Validation loss: 2.032641517218723

Epoch: 5| Step: 10
Training loss: 1.066369891166687
Validation loss: 2.014531083004449

Epoch: 186| Step: 0
Training loss: 1.237890601158142
Validation loss: 2.022221108918549

Epoch: 5| Step: 1
Training loss: 0.8953555822372437
Validation loss: 1.966392852926767

Epoch: 5| Step: 2
Training loss: 0.9804657697677612
Validation loss: 1.9820487024963542

Epoch: 5| Step: 3
Training loss: 0.9464419484138489
Validation loss: 2.0040801237988215

Epoch: 5| Step: 4
Training loss: 0.7332267761230469
Validation loss: 2.018314689718267

Epoch: 5| Step: 5
Training loss: 1.1867555379867554
Validation loss: 2.0379884217375066

Epoch: 5| Step: 6
Training loss: 0.8597772717475891
Validation loss: 2.0454241832097373

Epoch: 5| Step: 7
Training loss: 1.4900946617126465
Validation loss: 2.061002769777852

Epoch: 5| Step: 8
Training loss: 1.2455708980560303
Validation loss: 2.0494729383017427

Epoch: 5| Step: 9
Training loss: 1.1507083177566528
Validation loss: 2.036040782928467

Epoch: 5| Step: 10
Training loss: 0.6485541462898254
Validation loss: 1.9830549288821477

Epoch: 187| Step: 0
Training loss: 0.957615077495575
Validation loss: 2.0344974763931765

Epoch: 5| Step: 1
Training loss: 1.102010726928711
Validation loss: 1.991274426060338

Epoch: 5| Step: 2
Training loss: 1.365545630455017
Validation loss: 2.005120813205678

Epoch: 5| Step: 3
Training loss: 0.7094301581382751
Validation loss: 2.042500804829341

Epoch: 5| Step: 4
Training loss: 1.1221234798431396
Validation loss: 2.0739694641482447

Epoch: 5| Step: 5
Training loss: 1.2029714584350586
Validation loss: 2.077088217581472

Epoch: 5| Step: 6
Training loss: 0.821245014667511
Validation loss: 2.058781664858582

Epoch: 5| Step: 7
Training loss: 1.3631739616394043
Validation loss: 2.0446544180634203

Epoch: 5| Step: 8
Training loss: 0.7702426910400391
Validation loss: 2.013280568584319

Epoch: 5| Step: 9
Training loss: 1.0694923400878906
Validation loss: 1.996028051581434

Epoch: 5| Step: 10
Training loss: 0.9099265933036804
Validation loss: 1.9493833767470492

Epoch: 188| Step: 0
Training loss: 1.2557510137557983
Validation loss: 1.988534786367929

Epoch: 5| Step: 1
Training loss: 0.800653338432312
Validation loss: 1.9860336947184738

Epoch: 5| Step: 2
Training loss: 1.1234863996505737
Validation loss: 2.0235109739406134

Epoch: 5| Step: 3
Training loss: 1.464859962463379
Validation loss: 1.990004890708513

Epoch: 5| Step: 4
Training loss: 1.248560905456543
Validation loss: 2.0220467634098505

Epoch: 5| Step: 5
Training loss: 0.6138180494308472
Validation loss: 2.0028598065017373

Epoch: 5| Step: 6
Training loss: 0.7619549036026001
Validation loss: 2.0083580658000004

Epoch: 5| Step: 7
Training loss: 0.824627697467804
Validation loss: 1.989749579019444

Epoch: 5| Step: 8
Training loss: 1.1420878171920776
Validation loss: 2.017336312160697

Epoch: 5| Step: 9
Training loss: 0.98089599609375
Validation loss: 2.0371297892703804

Epoch: 5| Step: 10
Training loss: 1.074275016784668
Validation loss: 2.0505238194619455

Epoch: 189| Step: 0
Training loss: 1.0321887731552124
Validation loss: 2.0148457686106362

Epoch: 5| Step: 1
Training loss: 0.9670584797859192
Validation loss: 2.0203446970191052

Epoch: 5| Step: 2
Training loss: 1.1220954656600952
Validation loss: 2.000911484482468

Epoch: 5| Step: 3
Training loss: 1.1826835870742798
Validation loss: 2.020405287383705

Epoch: 5| Step: 4
Training loss: 0.8374303579330444
Validation loss: 2.061614018614574

Epoch: 5| Step: 5
Training loss: 0.8170989751815796
Validation loss: 2.0788893725282405

Epoch: 5| Step: 6
Training loss: 1.480452299118042
Validation loss: 2.1011134924427157

Epoch: 5| Step: 7
Training loss: 0.9422141909599304
Validation loss: 2.070653494968209

Epoch: 5| Step: 8
Training loss: 1.2880743741989136
Validation loss: 2.0425791355871383

Epoch: 5| Step: 9
Training loss: 1.0827876329421997
Validation loss: 1.9982772386202248

Epoch: 5| Step: 10
Training loss: 0.6544989347457886
Validation loss: 2.0118999686292423

Epoch: 190| Step: 0
Training loss: 1.1274906396865845
Validation loss: 1.9855957467068908

Epoch: 5| Step: 1
Training loss: 0.9318987131118774
Validation loss: 2.021920581017771

Epoch: 5| Step: 2
Training loss: 1.2952382564544678
Validation loss: 1.9826618753453737

Epoch: 5| Step: 3
Training loss: 1.127124547958374
Validation loss: 2.0154861506595405

Epoch: 5| Step: 4
Training loss: 0.8418623208999634
Validation loss: 1.9890016330185758

Epoch: 5| Step: 5
Training loss: 0.9044227600097656
Validation loss: 2.0017060900247223

Epoch: 5| Step: 6
Training loss: 0.8276242017745972
Validation loss: 2.023814070609308

Epoch: 5| Step: 7
Training loss: 1.169447660446167
Validation loss: 2.043266959087823

Epoch: 5| Step: 8
Training loss: 1.1885526180267334
Validation loss: 2.0588750172686834

Epoch: 5| Step: 9
Training loss: 1.291126012802124
Validation loss: 2.059923279669977

Epoch: 5| Step: 10
Training loss: 0.8340575098991394
Validation loss: 2.0519930867738623

Epoch: 191| Step: 0
Training loss: 1.3423017263412476
Validation loss: 2.050743502955283

Epoch: 5| Step: 1
Training loss: 0.9761131405830383
Validation loss: 2.059009558411055

Epoch: 5| Step: 2
Training loss: 1.2355897426605225
Validation loss: 2.070260755477413

Epoch: 5| Step: 3
Training loss: 0.781535267829895
Validation loss: 2.054634609530049

Epoch: 5| Step: 4
Training loss: 0.6483350396156311
Validation loss: 2.079367112087947

Epoch: 5| Step: 5
Training loss: 1.0893540382385254
Validation loss: 2.0525557289841356

Epoch: 5| Step: 6
Training loss: 0.8394508361816406
Validation loss: 2.0309399045923704

Epoch: 5| Step: 7
Training loss: 1.1603256464004517
Validation loss: 1.9965872187768259

Epoch: 5| Step: 8
Training loss: 1.124506950378418
Validation loss: 1.9634454404154131

Epoch: 5| Step: 9
Training loss: 0.9678568840026855
Validation loss: 1.9332358119308308

Epoch: 5| Step: 10
Training loss: 0.627512514591217
Validation loss: 1.9145545062198435

Epoch: 192| Step: 0
Training loss: 1.1958757638931274
Validation loss: 1.9302223485003236

Epoch: 5| Step: 1
Training loss: 1.0033485889434814
Validation loss: 1.9505491769441994

Epoch: 5| Step: 2
Training loss: 1.1912561655044556
Validation loss: 1.9700527844890472

Epoch: 5| Step: 3
Training loss: 0.4001404643058777
Validation loss: 1.9602694921596076

Epoch: 5| Step: 4
Training loss: 1.4507169723510742
Validation loss: 2.0143388958387476

Epoch: 5| Step: 5
Training loss: 0.821306586265564
Validation loss: 2.025609465055568

Epoch: 5| Step: 6
Training loss: 0.9260903596878052
Validation loss: 2.028661658686976

Epoch: 5| Step: 7
Training loss: 1.0660709142684937
Validation loss: 1.9893930483889837

Epoch: 5| Step: 8
Training loss: 1.0877790451049805
Validation loss: 2.002033825843565

Epoch: 5| Step: 9
Training loss: 0.7472904920578003
Validation loss: 1.9788717057115288

Epoch: 5| Step: 10
Training loss: 1.2474080324172974
Validation loss: 1.9777679404904764

Epoch: 193| Step: 0
Training loss: 1.149644136428833
Validation loss: 1.9804257295464958

Epoch: 5| Step: 1
Training loss: 0.9373252987861633
Validation loss: 1.9972817244068268

Epoch: 5| Step: 2
Training loss: 1.0248472690582275
Validation loss: 2.0136459796659407

Epoch: 5| Step: 3
Training loss: 1.122020959854126
Validation loss: 2.026545932216029

Epoch: 5| Step: 4
Training loss: 1.3130145072937012
Validation loss: 2.0747929029567267

Epoch: 5| Step: 5
Training loss: 1.374356746673584
Validation loss: 2.0587099290663198

Epoch: 5| Step: 6
Training loss: 0.41926151514053345
Validation loss: 2.03797903624914

Epoch: 5| Step: 7
Training loss: 1.1453131437301636
Validation loss: 2.0413589221175

Epoch: 5| Step: 8
Training loss: 0.6759799718856812
Validation loss: 2.0608755965386667

Epoch: 5| Step: 9
Training loss: 0.5337761640548706
Validation loss: 2.0455119584196355

Epoch: 5| Step: 10
Training loss: 1.0957484245300293
Validation loss: 2.0329409850540983

Epoch: 194| Step: 0
Training loss: 0.9223130941390991
Validation loss: 2.0183842823069584

Epoch: 5| Step: 1
Training loss: 1.1560351848602295
Validation loss: 1.9885730256316483

Epoch: 5| Step: 2
Training loss: 1.3461424112319946
Validation loss: 1.9533825048836329

Epoch: 5| Step: 3
Training loss: 0.904650092124939
Validation loss: 1.9340431549215829

Epoch: 5| Step: 4
Training loss: 1.1034438610076904
Validation loss: 1.9447836055550525

Epoch: 5| Step: 5
Training loss: 0.7387207746505737
Validation loss: 1.9509384632110596

Epoch: 5| Step: 6
Training loss: 0.8547523617744446
Validation loss: 1.9628172074594805

Epoch: 5| Step: 7
Training loss: 0.7851758599281311
Validation loss: 2.005162913312194

Epoch: 5| Step: 8
Training loss: 0.819699764251709
Validation loss: 2.0410948671320432

Epoch: 5| Step: 9
Training loss: 1.0290217399597168
Validation loss: 2.078298532834617

Epoch: 5| Step: 10
Training loss: 1.1855695247650146
Validation loss: 2.064826588476858

Epoch: 195| Step: 0
Training loss: 0.9970605969429016
Validation loss: 2.0427792328660206

Epoch: 5| Step: 1
Training loss: 0.8811405897140503
Validation loss: 1.9978384869073027

Epoch: 5| Step: 2
Training loss: 0.9163681268692017
Validation loss: 1.9835901542376446

Epoch: 5| Step: 3
Training loss: 1.1112765073776245
Validation loss: 1.9733232875024118

Epoch: 5| Step: 4
Training loss: 0.7080492973327637
Validation loss: 1.957617457194995

Epoch: 5| Step: 5
Training loss: 1.0280826091766357
Validation loss: 1.9765469387013426

Epoch: 5| Step: 6
Training loss: 0.6816679239273071
Validation loss: 1.9679439272931827

Epoch: 5| Step: 7
Training loss: 1.2491906881332397
Validation loss: 1.9998794319809123

Epoch: 5| Step: 8
Training loss: 1.0869966745376587
Validation loss: 2.0013886113320627

Epoch: 5| Step: 9
Training loss: 0.6889504194259644
Validation loss: 2.039327600950836

Epoch: 5| Step: 10
Training loss: 1.268612027168274
Validation loss: 2.042585790798228

Epoch: 196| Step: 0
Training loss: 1.161480188369751
Validation loss: 2.036714912742697

Epoch: 5| Step: 1
Training loss: 1.1701362133026123
Validation loss: 2.019396117938462

Epoch: 5| Step: 2
Training loss: 0.4986090660095215
Validation loss: 2.0106427054251395

Epoch: 5| Step: 3
Training loss: 0.8545534014701843
Validation loss: 1.9859094747933008

Epoch: 5| Step: 4
Training loss: 1.19316828250885
Validation loss: 1.9593846387760614

Epoch: 5| Step: 5
Training loss: 1.1912972927093506
Validation loss: 1.9434058140682917

Epoch: 5| Step: 6
Training loss: 1.0162272453308105
Validation loss: 1.9468533069856706

Epoch: 5| Step: 7
Training loss: 0.6939035058021545
Validation loss: 1.9377245005740915

Epoch: 5| Step: 8
Training loss: 0.8146167993545532
Validation loss: 1.9546600182851155

Epoch: 5| Step: 9
Training loss: 0.8714838027954102
Validation loss: 1.9489880172155236

Epoch: 5| Step: 10
Training loss: 0.9056992530822754
Validation loss: 1.9694521939882668

Epoch: 197| Step: 0
Training loss: 0.711466908454895
Validation loss: 2.0255397007029545

Epoch: 5| Step: 1
Training loss: 1.101801872253418
Validation loss: 2.0164618569035686

Epoch: 5| Step: 2
Training loss: 0.7327245473861694
Validation loss: 2.039962366063108

Epoch: 5| Step: 3
Training loss: 0.9443308115005493
Validation loss: 2.0139755254150717

Epoch: 5| Step: 4
Training loss: 1.1014893054962158
Validation loss: 2.021139193606633

Epoch: 5| Step: 5
Training loss: 0.6875492334365845
Validation loss: 2.02291674511407

Epoch: 5| Step: 6
Training loss: 1.1034657955169678
Validation loss: 1.9985954658959502

Epoch: 5| Step: 7
Training loss: 0.8185526132583618
Validation loss: 1.9572552634823708

Epoch: 5| Step: 8
Training loss: 0.8517179489135742
Validation loss: 1.969304112977879

Epoch: 5| Step: 9
Training loss: 1.1212248802185059
Validation loss: 2.0055581497889694

Epoch: 5| Step: 10
Training loss: 0.9835485816001892
Validation loss: 2.036851324060912

Epoch: 198| Step: 0
Training loss: 0.9069510698318481
Validation loss: 2.0414185600896038

Epoch: 5| Step: 1
Training loss: 0.7922695279121399
Validation loss: 2.037173835180139

Epoch: 5| Step: 2
Training loss: 1.0867717266082764
Validation loss: 2.0049143401525353

Epoch: 5| Step: 3
Training loss: 0.7701596021652222
Validation loss: 1.997924909796766

Epoch: 5| Step: 4
Training loss: 1.2417372465133667
Validation loss: 1.972250997379262

Epoch: 5| Step: 5
Training loss: 0.9123579263687134
Validation loss: 1.9772782889745568

Epoch: 5| Step: 6
Training loss: 0.7811461091041565
Validation loss: 1.9819986538220478

Epoch: 5| Step: 7
Training loss: 0.8708913922309875
Validation loss: 1.951499549291467

Epoch: 5| Step: 8
Training loss: 0.8660971522331238
Validation loss: 1.9705799523220267

Epoch: 5| Step: 9
Training loss: 0.6902022361755371
Validation loss: 1.978122926527454

Epoch: 5| Step: 10
Training loss: 1.1122748851776123
Validation loss: 1.972317937881716

Epoch: 199| Step: 0
Training loss: 0.7015644907951355
Validation loss: 1.968128159481992

Epoch: 5| Step: 1
Training loss: 0.9097016453742981
Validation loss: 1.9832934538523357

Epoch: 5| Step: 2
Training loss: 1.1420280933380127
Validation loss: 1.9991496968012985

Epoch: 5| Step: 3
Training loss: 1.0088788270950317
Validation loss: 2.002366554352545

Epoch: 5| Step: 4
Training loss: 0.7852486371994019
Validation loss: 1.9962222858141827

Epoch: 5| Step: 5
Training loss: 1.1567704677581787
Validation loss: 2.025785511539828

Epoch: 5| Step: 6
Training loss: 0.6536346673965454
Validation loss: 2.0424125540641045

Epoch: 5| Step: 7
Training loss: 0.8037558794021606
Validation loss: 2.071896058256908

Epoch: 5| Step: 8
Training loss: 0.9627825617790222
Validation loss: 2.0632236285876204

Epoch: 5| Step: 9
Training loss: 0.8549195528030396
Validation loss: 2.06517989917468

Epoch: 5| Step: 10
Training loss: 1.0428904294967651
Validation loss: 2.038297455797913

Epoch: 200| Step: 0
Training loss: 0.8106217384338379
Validation loss: 2.012133703436903

Epoch: 5| Step: 1
Training loss: 0.945470929145813
Validation loss: 1.967341092325026

Epoch: 5| Step: 2
Training loss: 1.0574889183044434
Validation loss: 1.950097914664976

Epoch: 5| Step: 3
Training loss: 0.6656931638717651
Validation loss: 1.9461189521256315

Epoch: 5| Step: 4
Training loss: 1.1698193550109863
Validation loss: 1.9849562978231778

Epoch: 5| Step: 5
Training loss: 0.9811891317367554
Validation loss: 1.9887263774871826

Epoch: 5| Step: 6
Training loss: 0.8207910656929016
Validation loss: 1.976026520934156

Epoch: 5| Step: 7
Training loss: 0.6298531889915466
Validation loss: 1.9652815224021993

Epoch: 5| Step: 8
Training loss: 0.8608999252319336
Validation loss: 1.9609842364506056

Epoch: 5| Step: 9
Training loss: 0.7485061883926392
Validation loss: 1.9666952727943339

Epoch: 5| Step: 10
Training loss: 1.3098347187042236
Validation loss: 1.9321330080750168

Epoch: 201| Step: 0
Training loss: 0.7724514007568359
Validation loss: 1.9531329293404855

Epoch: 5| Step: 1
Training loss: 0.9876841306686401
Validation loss: 1.9266331939287082

Epoch: 5| Step: 2
Training loss: 0.594699501991272
Validation loss: 1.9279650642025856

Epoch: 5| Step: 3
Training loss: 1.2767082452774048
Validation loss: 1.9681033754861483

Epoch: 5| Step: 4
Training loss: 0.6423124074935913
Validation loss: 1.9394581817811536

Epoch: 5| Step: 5
Training loss: 0.6189700365066528
Validation loss: 1.955046530692808

Epoch: 5| Step: 6
Training loss: 1.0948293209075928
Validation loss: 1.965088636644425

Epoch: 5| Step: 7
Training loss: 1.0162605047225952
Validation loss: 1.9879917893358456

Epoch: 5| Step: 8
Training loss: 1.0147663354873657
Validation loss: 2.0105033689929592

Epoch: 5| Step: 9
Training loss: 0.7605510354042053
Validation loss: 2.063831331909344

Epoch: 5| Step: 10
Training loss: 1.0762497186660767
Validation loss: 2.064620711470163

Epoch: 202| Step: 0
Training loss: 1.110508680343628
Validation loss: 2.044827530460973

Epoch: 5| Step: 1
Training loss: 1.0676782131195068
Validation loss: 2.008601191223309

Epoch: 5| Step: 2
Training loss: 0.522710919380188
Validation loss: 1.9602909088134766

Epoch: 5| Step: 3
Training loss: 1.0034101009368896
Validation loss: 1.9443201300918416

Epoch: 5| Step: 4
Training loss: 0.8980738520622253
Validation loss: 1.9154603340292489

Epoch: 5| Step: 5
Training loss: 0.996492862701416
Validation loss: 1.9150619096653436

Epoch: 5| Step: 6
Training loss: 1.234968900680542
Validation loss: 1.918037155623077

Epoch: 5| Step: 7
Training loss: 0.7717235088348389
Validation loss: 1.9385165604211951

Epoch: 5| Step: 8
Training loss: 1.1032947301864624
Validation loss: 1.9287979987359816

Epoch: 5| Step: 9
Training loss: 0.7899304032325745
Validation loss: 1.964421449169036

Epoch: 5| Step: 10
Training loss: 0.5509889721870422
Validation loss: 2.0147706513763755

Epoch: 203| Step: 0
Training loss: 0.9201062917709351
Validation loss: 2.0081446222079697

Epoch: 5| Step: 1
Training loss: 1.1940152645111084
Validation loss: 2.001855133682169

Epoch: 5| Step: 2
Training loss: 0.956808865070343
Validation loss: 1.9633178698119296

Epoch: 5| Step: 3
Training loss: 0.9247792959213257
Validation loss: 1.9786499648965814

Epoch: 5| Step: 4
Training loss: 1.1011409759521484
Validation loss: 1.9466698387617707

Epoch: 5| Step: 5
Training loss: 0.919634997844696
Validation loss: 1.9226545813263103

Epoch: 5| Step: 6
Training loss: 0.7902790307998657
Validation loss: 1.9084910872162029

Epoch: 5| Step: 7
Training loss: 1.113415241241455
Validation loss: 1.9381546487090409

Epoch: 5| Step: 8
Training loss: 0.860945999622345
Validation loss: 1.9541595674330188

Epoch: 5| Step: 9
Training loss: 0.6482405662536621
Validation loss: 1.9734387769494006

Epoch: 5| Step: 10
Training loss: 0.6492265462875366
Validation loss: 2.027537002358385

Epoch: 204| Step: 0
Training loss: 1.00131094455719
Validation loss: 2.048794742553465

Epoch: 5| Step: 1
Training loss: 0.9960273504257202
Validation loss: 2.063175168088687

Epoch: 5| Step: 2
Training loss: 0.7943921089172363
Validation loss: 2.0542906279204995

Epoch: 5| Step: 3
Training loss: 1.1395238637924194
Validation loss: 1.9756278376425467

Epoch: 5| Step: 4
Training loss: 0.9551225900650024
Validation loss: 1.9870740675157117

Epoch: 5| Step: 5
Training loss: 0.8434059023857117
Validation loss: 1.9453868404511483

Epoch: 5| Step: 6
Training loss: 0.7565387487411499
Validation loss: 1.9540998179425475

Epoch: 5| Step: 7
Training loss: 0.6514915227890015
Validation loss: 1.9345450093669276

Epoch: 5| Step: 8
Training loss: 1.152489423751831
Validation loss: 1.895430221352526

Epoch: 5| Step: 9
Training loss: 0.8668180704116821
Validation loss: 1.931996947975569

Epoch: 5| Step: 10
Training loss: 0.9429147243499756
Validation loss: 1.9453721789903538

Epoch: 205| Step: 0
Training loss: 0.8930137753486633
Validation loss: 1.9410867280857538

Epoch: 5| Step: 1
Training loss: 0.9036186337471008
Validation loss: 1.968971324223344

Epoch: 5| Step: 2
Training loss: 0.5758687853813171
Validation loss: 2.016806928060388

Epoch: 5| Step: 3
Training loss: 1.0029395818710327
Validation loss: 2.060853645365725

Epoch: 5| Step: 4
Training loss: 0.8649591207504272
Validation loss: 2.0665695231447936

Epoch: 5| Step: 5
Training loss: 0.6134017705917358
Validation loss: 2.0782210929419405

Epoch: 5| Step: 6
Training loss: 0.7083057165145874
Validation loss: 2.039643254331363

Epoch: 5| Step: 7
Training loss: 0.8336910009384155
Validation loss: 2.035824756468496

Epoch: 5| Step: 8
Training loss: 1.1539947986602783
Validation loss: 1.9788280481933265

Epoch: 5| Step: 9
Training loss: 1.1226158142089844
Validation loss: 1.942112135630782

Epoch: 5| Step: 10
Training loss: 0.9845082759857178
Validation loss: 1.9151228550941712

Epoch: 206| Step: 0
Training loss: 0.6634470224380493
Validation loss: 1.8920583571157148

Epoch: 5| Step: 1
Training loss: 1.0442912578582764
Validation loss: 1.9431758696033108

Epoch: 5| Step: 2
Training loss: 1.1394604444503784
Validation loss: 1.948906047369844

Epoch: 5| Step: 3
Training loss: 0.8147302865982056
Validation loss: 1.9339252261705295

Epoch: 5| Step: 4
Training loss: 0.8700932264328003
Validation loss: 1.9428602803137995

Epoch: 5| Step: 5
Training loss: 0.8987533450126648
Validation loss: 1.982663631439209

Epoch: 5| Step: 6
Training loss: 0.8758214712142944
Validation loss: 2.0270308986786874

Epoch: 5| Step: 7
Training loss: 0.7721779346466064
Validation loss: 2.060793202410462

Epoch: 5| Step: 8
Training loss: 0.9303058385848999
Validation loss: 2.063995120345905

Epoch: 5| Step: 9
Training loss: 0.6571713089942932
Validation loss: 2.0467172027916036

Epoch: 5| Step: 10
Training loss: 0.7886728644371033
Validation loss: 2.027718154332971

Epoch: 207| Step: 0
Training loss: 0.9486422538757324
Validation loss: 2.0072579178758847

Epoch: 5| Step: 1
Training loss: 1.0939900875091553
Validation loss: 2.0096828450438795

Epoch: 5| Step: 2
Training loss: 1.0125856399536133
Validation loss: 1.9913977358930854

Epoch: 5| Step: 3
Training loss: 1.2226876020431519
Validation loss: 1.9866547930625178

Epoch: 5| Step: 4
Training loss: 1.0382940769195557
Validation loss: 1.9322084560189197

Epoch: 5| Step: 5
Training loss: 0.48350563645362854
Validation loss: 1.939183485123419

Epoch: 5| Step: 6
Training loss: 0.6238528490066528
Validation loss: 1.9292900152103876

Epoch: 5| Step: 7
Training loss: 0.7554448246955872
Validation loss: 1.9212990601857503

Epoch: 5| Step: 8
Training loss: 0.8441290855407715
Validation loss: 1.9474054267329555

Epoch: 5| Step: 9
Training loss: 0.6923307180404663
Validation loss: 1.963610646545246

Epoch: 5| Step: 10
Training loss: 0.7247895002365112
Validation loss: 2.008837571708105

Epoch: 208| Step: 0
Training loss: 1.0957956314086914
Validation loss: 2.055655207685245

Epoch: 5| Step: 1
Training loss: 1.04721999168396
Validation loss: 2.0307590987092707

Epoch: 5| Step: 2
Training loss: 0.6620630025863647
Validation loss: 2.01009456060266

Epoch: 5| Step: 3
Training loss: 0.8187726140022278
Validation loss: 1.992619888756865

Epoch: 5| Step: 4
Training loss: 1.07533860206604
Validation loss: 1.9749868095562022

Epoch: 5| Step: 5
Training loss: 0.6398268938064575
Validation loss: 1.9804005366499706

Epoch: 5| Step: 6
Training loss: 0.751498818397522
Validation loss: 1.9688516739876039

Epoch: 5| Step: 7
Training loss: 1.2339617013931274
Validation loss: 1.970349693811068

Epoch: 5| Step: 8
Training loss: 0.9924432635307312
Validation loss: 1.963985663588329

Epoch: 5| Step: 9
Training loss: 0.7908016443252563
Validation loss: 1.986853552120988

Epoch: 5| Step: 10
Training loss: 0.4602656364440918
Validation loss: 1.9707490500583444

Epoch: 209| Step: 0
Training loss: 0.24866461753845215
Validation loss: 1.9984501805356754

Epoch: 5| Step: 1
Training loss: 0.5931478142738342
Validation loss: 2.031574959396034

Epoch: 5| Step: 2
Training loss: 0.9716118574142456
Validation loss: 2.0002800264666156

Epoch: 5| Step: 3
Training loss: 0.9881685972213745
Validation loss: 1.9935889654262091

Epoch: 5| Step: 4
Training loss: 0.9710056185722351
Validation loss: 2.009705662727356

Epoch: 5| Step: 5
Training loss: 1.0208207368850708
Validation loss: 1.9860283021003968

Epoch: 5| Step: 6
Training loss: 1.2144473791122437
Validation loss: 1.97292919312754

Epoch: 5| Step: 7
Training loss: 0.8170086145401001
Validation loss: 1.9483184301724998

Epoch: 5| Step: 8
Training loss: 0.5410188436508179
Validation loss: 1.9052642699210875

Epoch: 5| Step: 9
Training loss: 0.9166675806045532
Validation loss: 1.9268643022865377

Epoch: 5| Step: 10
Training loss: 0.8154295086860657
Validation loss: 1.914874025570449

Epoch: 210| Step: 0
Training loss: 0.6195818185806274
Validation loss: 1.9243602893685783

Epoch: 5| Step: 1
Training loss: 0.761015772819519
Validation loss: 1.9195750810766732

Epoch: 5| Step: 2
Training loss: 0.576298177242279
Validation loss: 1.9303385583303307

Epoch: 5| Step: 3
Training loss: 0.8748311996459961
Validation loss: 1.9656456439725813

Epoch: 5| Step: 4
Training loss: 1.2293636798858643
Validation loss: 2.000063015568641

Epoch: 5| Step: 5
Training loss: 0.8391523361206055
Validation loss: 2.008539831766518

Epoch: 5| Step: 6
Training loss: 0.6754320859909058
Validation loss: 2.0002060731252036

Epoch: 5| Step: 7
Training loss: 1.3069782257080078
Validation loss: 2.0324119239725094

Epoch: 5| Step: 8
Training loss: 0.8648779988288879
Validation loss: 2.0124755341519593

Epoch: 5| Step: 9
Training loss: 0.6013666391372681
Validation loss: 2.001487138450787

Epoch: 5| Step: 10
Training loss: 0.9204345345497131
Validation loss: 1.9961852206978747

Epoch: 211| Step: 0
Training loss: 1.0100980997085571
Validation loss: 1.9702392829361783

Epoch: 5| Step: 1
Training loss: 0.8955942988395691
Validation loss: 1.9760033981774443

Epoch: 5| Step: 2
Training loss: 0.5865576863288879
Validation loss: 1.983502108563659

Epoch: 5| Step: 3
Training loss: 0.6481313705444336
Validation loss: 2.010595361391703

Epoch: 5| Step: 4
Training loss: 0.9156303405761719
Validation loss: 2.0172318361138784

Epoch: 5| Step: 5
Training loss: 0.8370094299316406
Validation loss: 1.9906739137505973

Epoch: 5| Step: 6
Training loss: 0.7656352519989014
Validation loss: 1.9812974878536758

Epoch: 5| Step: 7
Training loss: 1.148584246635437
Validation loss: 1.982683507345056

Epoch: 5| Step: 8
Training loss: 0.6686608791351318
Validation loss: 1.970223972874303

Epoch: 5| Step: 9
Training loss: 0.8554303050041199
Validation loss: 1.93970121875886

Epoch: 5| Step: 10
Training loss: 0.5142555832862854
Validation loss: 1.922082620282327

Epoch: 212| Step: 0
Training loss: 0.6970610022544861
Validation loss: 1.9457345085759317

Epoch: 5| Step: 1
Training loss: 0.9077022671699524
Validation loss: 1.955499610593242

Epoch: 5| Step: 2
Training loss: 0.8876350522041321
Validation loss: 1.9548523502965127

Epoch: 5| Step: 3
Training loss: 1.173071265220642
Validation loss: 1.9479782978693645

Epoch: 5| Step: 4
Training loss: 0.5394395589828491
Validation loss: 1.947083819297052

Epoch: 5| Step: 5
Training loss: 0.39097973704338074
Validation loss: 1.958014178019698

Epoch: 5| Step: 6
Training loss: 1.039124608039856
Validation loss: 1.970477573333248

Epoch: 5| Step: 7
Training loss: 0.9905921816825867
Validation loss: 1.9887725589095906

Epoch: 5| Step: 8
Training loss: 0.7407987713813782
Validation loss: 1.999943261505455

Epoch: 5| Step: 9
Training loss: 0.3271375000476837
Validation loss: 1.9738196301203903

Epoch: 5| Step: 10
Training loss: 1.094807505607605
Validation loss: 1.9859435353227841

Epoch: 213| Step: 0
Training loss: 0.7835615277290344
Validation loss: 1.9966941059276622

Epoch: 5| Step: 1
Training loss: 0.539300799369812
Validation loss: 1.9741393173894575

Epoch: 5| Step: 2
Training loss: 1.0587430000305176
Validation loss: 1.9443230231602986

Epoch: 5| Step: 3
Training loss: 0.79835045337677
Validation loss: 1.95972062951775

Epoch: 5| Step: 4
Training loss: 0.7322469353675842
Validation loss: 1.9370372346652451

Epoch: 5| Step: 5
Training loss: 1.1155972480773926
Validation loss: 1.9081919500904698

Epoch: 5| Step: 6
Training loss: 0.7257307171821594
Validation loss: 1.933361784104378

Epoch: 5| Step: 7
Training loss: 0.5357397198677063
Validation loss: 1.9000948270161946

Epoch: 5| Step: 8
Training loss: 1.1495062112808228
Validation loss: 1.9127161425928916

Epoch: 5| Step: 9
Training loss: 0.5257851481437683
Validation loss: 1.9653640511215373

Epoch: 5| Step: 10
Training loss: 0.9028909206390381
Validation loss: 1.935337015377578

Epoch: 214| Step: 0
Training loss: 1.0011932849884033
Validation loss: 1.9439852391519854

Epoch: 5| Step: 1
Training loss: 0.6690270304679871
Validation loss: 1.9396587187244045

Epoch: 5| Step: 2
Training loss: 0.6494980454444885
Validation loss: 1.952437528999903

Epoch: 5| Step: 3
Training loss: 0.6620584726333618
Validation loss: 1.965431704316088

Epoch: 5| Step: 4
Training loss: 0.9569652676582336
Validation loss: 1.9824759793537918

Epoch: 5| Step: 5
Training loss: 1.1463391780853271
Validation loss: 1.9868281425968293

Epoch: 5| Step: 6
Training loss: 0.5081550478935242
Validation loss: 1.9807142544818181

Epoch: 5| Step: 7
Training loss: 1.0976741313934326
Validation loss: 1.984925962263538

Epoch: 5| Step: 8
Training loss: 0.25682035088539124
Validation loss: 1.9685416426709903

Epoch: 5| Step: 9
Training loss: 0.8415576219558716
Validation loss: 1.9857555756004908

Epoch: 5| Step: 10
Training loss: 0.788436770439148
Validation loss: 2.019377741762387

Epoch: 215| Step: 0
Training loss: 0.861064612865448
Validation loss: 1.978882335847424

Epoch: 5| Step: 1
Training loss: 1.0776381492614746
Validation loss: 2.008739390680867

Epoch: 5| Step: 2
Training loss: 1.1916711330413818
Validation loss: 1.9569004556184173

Epoch: 5| Step: 3
Training loss: 0.6756621599197388
Validation loss: 1.9450807161228632

Epoch: 5| Step: 4
Training loss: 0.8149725198745728
Validation loss: 1.9395565204722907

Epoch: 5| Step: 5
Training loss: 0.7195184826850891
Validation loss: 1.937771084488079

Epoch: 5| Step: 6
Training loss: 0.6009151935577393
Validation loss: 1.9355261172017744

Epoch: 5| Step: 7
Training loss: 0.530243456363678
Validation loss: 1.9135593688616188

Epoch: 5| Step: 8
Training loss: 0.6744073629379272
Validation loss: 1.916798669804809

Epoch: 5| Step: 9
Training loss: 1.0136085748672485
Validation loss: 1.9560692284696846

Epoch: 5| Step: 10
Training loss: 0.46435320377349854
Validation loss: 1.953537082159391

Epoch: 216| Step: 0
Training loss: 0.742606520652771
Validation loss: 1.9828621072153891

Epoch: 5| Step: 1
Training loss: 0.7656252384185791
Validation loss: 2.0189657903486684

Epoch: 5| Step: 2
Training loss: 0.6102384924888611
Validation loss: 2.0517096224651543

Epoch: 5| Step: 3
Training loss: 0.5907127261161804
Validation loss: 2.032930193408843

Epoch: 5| Step: 4
Training loss: 1.1422877311706543
Validation loss: 2.0082666553476805

Epoch: 5| Step: 5
Training loss: 0.4992643892765045
Validation loss: 2.007402226489077

Epoch: 5| Step: 6
Training loss: 0.9031987190246582
Validation loss: 1.9845541818167574

Epoch: 5| Step: 7
Training loss: 0.9242404103279114
Validation loss: 2.0001184171245945

Epoch: 5| Step: 8
Training loss: 1.0519262552261353
Validation loss: 1.9776945537136448

Epoch: 5| Step: 9
Training loss: 0.8166343569755554
Validation loss: 1.9736713632460563

Epoch: 5| Step: 10
Training loss: 0.5692324042320251
Validation loss: 1.981200473282927

Epoch: 217| Step: 0
Training loss: 0.6652237772941589
Validation loss: 1.9927112094817623

Epoch: 5| Step: 1
Training loss: 0.6612170338630676
Validation loss: 1.9652734212977911

Epoch: 5| Step: 2
Training loss: 0.7103457450866699
Validation loss: 1.9732140212930658

Epoch: 5| Step: 3
Training loss: 0.6873694658279419
Validation loss: 1.9580760912228656

Epoch: 5| Step: 4
Training loss: 0.38113170862197876
Validation loss: 1.9584871415169007

Epoch: 5| Step: 5
Training loss: 0.8551794290542603
Validation loss: 1.9730347061669955

Epoch: 5| Step: 6
Training loss: 1.0500757694244385
Validation loss: 1.9502858256780973

Epoch: 5| Step: 7
Training loss: 1.2812564373016357
Validation loss: 1.9407191404732325

Epoch: 5| Step: 8
Training loss: 0.5546030402183533
Validation loss: 1.908101729167405

Epoch: 5| Step: 9
Training loss: 0.7859595417976379
Validation loss: 1.9436900192691433

Epoch: 5| Step: 10
Training loss: 0.7191832065582275
Validation loss: 1.9573002656300862

Epoch: 218| Step: 0
Training loss: 0.3540964126586914
Validation loss: 1.957359347292172

Epoch: 5| Step: 1
Training loss: 0.5196841359138489
Validation loss: 1.9862263330849268

Epoch: 5| Step: 2
Training loss: 0.6618516445159912
Validation loss: 2.0171287995512768

Epoch: 5| Step: 3
Training loss: 0.904659628868103
Validation loss: 2.026509367009645

Epoch: 5| Step: 4
Training loss: 0.7269847989082336
Validation loss: 2.0062207560385428

Epoch: 5| Step: 5
Training loss: 1.0363479852676392
Validation loss: 1.9694278650386359

Epoch: 5| Step: 6
Training loss: 0.9360440969467163
Validation loss: 1.9294941233050438

Epoch: 5| Step: 7
Training loss: 0.9269507527351379
Validation loss: 1.895359134161344

Epoch: 5| Step: 8
Training loss: 0.7837845087051392
Validation loss: 1.8474628515140985

Epoch: 5| Step: 9
Training loss: 0.8747838735580444
Validation loss: 1.8546768349985923

Epoch: 5| Step: 10
Training loss: 0.9362144470214844
Validation loss: 1.8595602102177118

Epoch: 219| Step: 0
Training loss: 0.8500480651855469
Validation loss: 1.9035969985428678

Epoch: 5| Step: 1
Training loss: 1.027952790260315
Validation loss: 1.928854698775917

Epoch: 5| Step: 2
Training loss: 0.9372946619987488
Validation loss: 1.9836745864601546

Epoch: 5| Step: 3
Training loss: 0.951119601726532
Validation loss: 2.0316192924335437

Epoch: 5| Step: 4
Training loss: 0.671420693397522
Validation loss: 2.0660494283963273

Epoch: 5| Step: 5
Training loss: 0.6982123255729675
Validation loss: 2.0840446820823093

Epoch: 5| Step: 6
Training loss: 0.6360217928886414
Validation loss: 2.039562488114962

Epoch: 5| Step: 7
Training loss: 0.5279273986816406
Validation loss: 2.0352026006226898

Epoch: 5| Step: 8
Training loss: 0.8387886881828308
Validation loss: 1.9803128575765958

Epoch: 5| Step: 9
Training loss: 0.7670515179634094
Validation loss: 1.9268755451325448

Epoch: 5| Step: 10
Training loss: 0.6562864184379578
Validation loss: 1.925981495970039

Epoch: 220| Step: 0
Training loss: 0.9384137392044067
Validation loss: 1.900110322942016

Epoch: 5| Step: 1
Training loss: 0.5573044419288635
Validation loss: 1.9203031242534678

Epoch: 5| Step: 2
Training loss: 0.8235666155815125
Validation loss: 1.9064223817599717

Epoch: 5| Step: 3
Training loss: 0.8375700116157532
Validation loss: 1.9474711982152795

Epoch: 5| Step: 4
Training loss: 0.8093113899230957
Validation loss: 1.9647750059763591

Epoch: 5| Step: 5
Training loss: 0.5737911462783813
Validation loss: 1.9877484511303645

Epoch: 5| Step: 6
Training loss: 0.8172993659973145
Validation loss: 1.962701718012492

Epoch: 5| Step: 7
Training loss: 0.9403945803642273
Validation loss: 1.9952889898771882

Epoch: 5| Step: 8
Training loss: 0.5261791944503784
Validation loss: 2.011321129337434

Epoch: 5| Step: 9
Training loss: 0.6976811289787292
Validation loss: 2.015851354086271

Epoch: 5| Step: 10
Training loss: 1.0685979127883911
Validation loss: 1.99429286936278

Epoch: 221| Step: 0
Training loss: 0.5883042216300964
Validation loss: 1.9729907102482294

Epoch: 5| Step: 1
Training loss: 0.6795037388801575
Validation loss: 1.9348985174650788

Epoch: 5| Step: 2
Training loss: 0.7208895683288574
Validation loss: 1.9365838445642942

Epoch: 5| Step: 3
Training loss: 0.8496154546737671
Validation loss: 1.9286765449790544

Epoch: 5| Step: 4
Training loss: 1.0016844272613525
Validation loss: 1.9161877414231658

Epoch: 5| Step: 5
Training loss: 0.659615695476532
Validation loss: 1.9058552941968363

Epoch: 5| Step: 6
Training loss: 0.5175944566726685
Validation loss: 1.9269980294730074

Epoch: 5| Step: 7
Training loss: 0.9268673062324524
Validation loss: 1.9706582241160895

Epoch: 5| Step: 8
Training loss: 0.9988824129104614
Validation loss: 1.9788388039476128

Epoch: 5| Step: 9
Training loss: 0.7548766136169434
Validation loss: 1.9849566003327728

Epoch: 5| Step: 10
Training loss: 0.6015120148658752
Validation loss: 1.9864901945155153

Epoch: 222| Step: 0
Training loss: 0.46420472860336304
Validation loss: 1.9637328911853094

Epoch: 5| Step: 1
Training loss: 0.9573414921760559
Validation loss: 1.9493419444689186

Epoch: 5| Step: 2
Training loss: 0.5582086443901062
Validation loss: 1.9302726407204904

Epoch: 5| Step: 3
Training loss: 0.7494863271713257
Validation loss: 1.9313857593844015

Epoch: 5| Step: 4
Training loss: 0.8576639294624329
Validation loss: 1.9616994588605818

Epoch: 5| Step: 5
Training loss: 1.1057941913604736
Validation loss: 1.9368865643778155

Epoch: 5| Step: 6
Training loss: 0.4459097981452942
Validation loss: 1.9685615519041657

Epoch: 5| Step: 7
Training loss: 0.9306936264038086
Validation loss: 1.98572555921411

Epoch: 5| Step: 8
Training loss: 0.44112491607666016
Validation loss: 2.0102627200465046

Epoch: 5| Step: 9
Training loss: 0.7534395456314087
Validation loss: 2.049634543798303

Epoch: 5| Step: 10
Training loss: 0.9142727851867676
Validation loss: 2.085419290809221

Epoch: 223| Step: 0
Training loss: 0.8965713381767273
Validation loss: 2.048797795849462

Epoch: 5| Step: 1
Training loss: 0.922260582447052
Validation loss: 2.018587745645995

Epoch: 5| Step: 2
Training loss: 0.7334068417549133
Validation loss: 2.0305482097851333

Epoch: 5| Step: 3
Training loss: 0.47976821660995483
Validation loss: 2.021436604120398

Epoch: 5| Step: 4
Training loss: 0.49413543939590454
Validation loss: 2.008599796602803

Epoch: 5| Step: 5
Training loss: 0.9216263890266418
Validation loss: 1.9963970004871328

Epoch: 5| Step: 6
Training loss: 0.9841932058334351
Validation loss: 1.9527835076855076

Epoch: 5| Step: 7
Training loss: 0.6538832783699036
Validation loss: 1.970343041163619

Epoch: 5| Step: 8
Training loss: 0.7399741411209106
Validation loss: 1.9909734213224022

Epoch: 5| Step: 9
Training loss: 0.5164331197738647
Validation loss: 2.0080433776301723

Epoch: 5| Step: 10
Training loss: 0.593063473701477
Validation loss: 2.016595786617648

Epoch: 224| Step: 0
Training loss: 0.5126428008079529
Validation loss: 2.017951883295531

Epoch: 5| Step: 1
Training loss: 1.2416892051696777
Validation loss: 2.048710864077332

Epoch: 5| Step: 2
Training loss: 1.1268750429153442
Validation loss: 2.0456146450452906

Epoch: 5| Step: 3
Training loss: 1.0856181383132935
Validation loss: 2.0259333733589417

Epoch: 5| Step: 4
Training loss: 0.7955676317214966
Validation loss: 1.9968524850824827

Epoch: 5| Step: 5
Training loss: 0.5571918487548828
Validation loss: 2.008832836663851

Epoch: 5| Step: 6
Training loss: 0.4798755645751953
Validation loss: 1.978531188862298

Epoch: 5| Step: 7
Training loss: 0.5840662717819214
Validation loss: 1.9630812842358825

Epoch: 5| Step: 8
Training loss: 0.60938960313797
Validation loss: 1.9559484938139557

Epoch: 5| Step: 9
Training loss: 0.3412664830684662
Validation loss: 1.9666699414612145

Epoch: 5| Step: 10
Training loss: 0.6150954961776733
Validation loss: 1.9415959055705736

Epoch: 225| Step: 0
Training loss: 0.6744942665100098
Validation loss: 1.9466096739615164

Epoch: 5| Step: 1
Training loss: 0.8961769342422485
Validation loss: 1.9383169451067526

Epoch: 5| Step: 2
Training loss: 0.40484684705734253
Validation loss: 1.9395957403285529

Epoch: 5| Step: 3
Training loss: 0.5870314836502075
Validation loss: 1.9109286428779684

Epoch: 5| Step: 4
Training loss: 0.4812825322151184
Validation loss: 1.90344665896508

Epoch: 5| Step: 5
Training loss: 1.0814695358276367
Validation loss: 1.9404224772607126

Epoch: 5| Step: 6
Training loss: 0.5419537425041199
Validation loss: 1.9347829075269802

Epoch: 5| Step: 7
Training loss: 0.8847277760505676
Validation loss: 1.9632313097676923

Epoch: 5| Step: 8
Training loss: 0.8015395402908325
Validation loss: 2.0025541949015793

Epoch: 5| Step: 9
Training loss: 0.8088383674621582
Validation loss: 2.045904900438042

Epoch: 5| Step: 10
Training loss: 0.6998598575592041
Validation loss: 2.0772125977341847

Epoch: 226| Step: 0
Training loss: 0.7572669982910156
Validation loss: 2.0381483800949587

Epoch: 5| Step: 1
Training loss: 0.7644577622413635
Validation loss: 2.024155660342145

Epoch: 5| Step: 2
Training loss: 0.5122875571250916
Validation loss: 1.9812971827804402

Epoch: 5| Step: 3
Training loss: 1.0313974618911743
Validation loss: 1.9601996996069466

Epoch: 5| Step: 4
Training loss: 0.46378177404403687
Validation loss: 1.9508085635400587

Epoch: 5| Step: 5
Training loss: 0.7995682954788208
Validation loss: 1.9392752608945292

Epoch: 5| Step: 6
Training loss: 0.8192530870437622
Validation loss: 1.9619317080384941

Epoch: 5| Step: 7
Training loss: 0.5388683676719666
Validation loss: 1.9684215771254672

Epoch: 5| Step: 8
Training loss: 0.7368549108505249
Validation loss: 1.9472391349013134

Epoch: 5| Step: 9
Training loss: 0.683147132396698
Validation loss: 1.951145766883768

Epoch: 5| Step: 10
Training loss: 0.6345582008361816
Validation loss: 1.9747487678322742

Epoch: 227| Step: 0
Training loss: 0.9033892750740051
Validation loss: 1.986518172807591

Epoch: 5| Step: 1
Training loss: 0.6352659463882446
Validation loss: 2.0027817372352845

Epoch: 5| Step: 2
Training loss: 0.6853705048561096
Validation loss: 1.9774587923480618

Epoch: 5| Step: 3
Training loss: 0.44794583320617676
Validation loss: 1.9779386135839647

Epoch: 5| Step: 4
Training loss: 0.5167865753173828
Validation loss: 1.958602600200202

Epoch: 5| Step: 5
Training loss: 0.6217872500419617
Validation loss: 1.9886122659970356

Epoch: 5| Step: 6
Training loss: 0.719002366065979
Validation loss: 1.9361185796799198

Epoch: 5| Step: 7
Training loss: 0.7219657301902771
Validation loss: 1.9461507335785897

Epoch: 5| Step: 8
Training loss: 0.9120190739631653
Validation loss: 1.9039066081405969

Epoch: 5| Step: 9
Training loss: 1.1451318264007568
Validation loss: 1.8979858326655563

Epoch: 5| Step: 10
Training loss: 0.6009746789932251
Validation loss: 1.8823702540448917

Epoch: 228| Step: 0
Training loss: 0.8461235165596008
Validation loss: 1.8995451183729275

Epoch: 5| Step: 1
Training loss: 1.048003911972046
Validation loss: 1.9010424921589513

Epoch: 5| Step: 2
Training loss: 0.7764689922332764
Validation loss: 1.9351400867585213

Epoch: 5| Step: 3
Training loss: 0.9316834211349487
Validation loss: 1.950855230772367

Epoch: 5| Step: 4
Training loss: 0.8256235122680664
Validation loss: 1.9581977449437624

Epoch: 5| Step: 5
Training loss: 0.718154788017273
Validation loss: 1.9531324781397337

Epoch: 5| Step: 6
Training loss: 0.7269504070281982
Validation loss: 1.9227988540485341

Epoch: 5| Step: 7
Training loss: 0.6251569986343384
Validation loss: 1.9043237060628913

Epoch: 5| Step: 8
Training loss: 0.3873273730278015
Validation loss: 1.933222721981746

Epoch: 5| Step: 9
Training loss: 0.9218053817749023
Validation loss: 1.948496287868869

Epoch: 5| Step: 10
Training loss: 0.30126243829727173
Validation loss: 2.0018288730293192

Epoch: 229| Step: 0
Training loss: 0.8002992868423462
Validation loss: 2.0068729910799252

Epoch: 5| Step: 1
Training loss: 0.7456512451171875
Validation loss: 2.050694845056021

Epoch: 5| Step: 2
Training loss: 0.5549505352973938
Validation loss: 2.030075878225347

Epoch: 5| Step: 3
Training loss: 0.6619656682014465
Validation loss: 2.0180828443137546

Epoch: 5| Step: 4
Training loss: 0.7625083923339844
Validation loss: 1.9545720777203959

Epoch: 5| Step: 5
Training loss: 0.7559175491333008
Validation loss: 1.9721064183019823

Epoch: 5| Step: 6
Training loss: 0.6197870373725891
Validation loss: 1.965949296951294

Epoch: 5| Step: 7
Training loss: 0.7805142402648926
Validation loss: 1.9500244202152375

Epoch: 5| Step: 8
Training loss: 0.660400927066803
Validation loss: 1.9603670643221947

Epoch: 5| Step: 9
Training loss: 0.8343124389648438
Validation loss: 1.968513455442203

Epoch: 5| Step: 10
Training loss: 0.4801907241344452
Validation loss: 1.954810570645076

Epoch: 230| Step: 0
Training loss: 1.0418168306350708
Validation loss: 1.9709061332928237

Epoch: 5| Step: 1
Training loss: 0.5298281908035278
Validation loss: 1.9387244639858123

Epoch: 5| Step: 2
Training loss: 0.842145562171936
Validation loss: 1.9558277117308749

Epoch: 5| Step: 3
Training loss: 0.3649902939796448
Validation loss: 1.9950055383866834

Epoch: 5| Step: 4
Training loss: 0.8060722351074219
Validation loss: 2.0098795660080446

Epoch: 5| Step: 5
Training loss: 0.7446862459182739
Validation loss: 1.9944646614854054

Epoch: 5| Step: 6
Training loss: 0.6588900685310364
Validation loss: 1.9995459382252028

Epoch: 5| Step: 7
Training loss: 0.44552478194236755
Validation loss: 1.9696350962884965

Epoch: 5| Step: 8
Training loss: 0.6169521808624268
Validation loss: 1.951875368754069

Epoch: 5| Step: 9
Training loss: 0.7529193758964539
Validation loss: 1.9250122321549283

Epoch: 5| Step: 10
Training loss: 0.5878481268882751
Validation loss: 1.889433330105197

Epoch: 231| Step: 0
Training loss: 0.623085618019104
Validation loss: 1.912734608496389

Epoch: 5| Step: 1
Training loss: 0.6131137013435364
Validation loss: 1.919456317860593

Epoch: 5| Step: 2
Training loss: 0.45133209228515625
Validation loss: 1.9184027256504181

Epoch: 5| Step: 3
Training loss: 0.9927484393119812
Validation loss: 1.9315942961682555

Epoch: 5| Step: 4
Training loss: 0.6681714057922363
Validation loss: 1.9271551485984557

Epoch: 5| Step: 5
Training loss: 0.41305238008499146
Validation loss: 1.9359884210812148

Epoch: 5| Step: 6
Training loss: 0.9836514592170715
Validation loss: 1.9021381485846736

Epoch: 5| Step: 7
Training loss: 0.5847300887107849
Validation loss: 1.929466224485828

Epoch: 5| Step: 8
Training loss: 0.804251492023468
Validation loss: 1.9229427332519202

Epoch: 5| Step: 9
Training loss: 0.8367582559585571
Validation loss: 1.9387054443359375

Epoch: 5| Step: 10
Training loss: 0.34869423508644104
Validation loss: 1.9541889852093113

Epoch: 232| Step: 0
Training loss: 0.5229746699333191
Validation loss: 2.0130627360395206

Epoch: 5| Step: 1
Training loss: 0.6188807487487793
Validation loss: 2.0182880714375484

Epoch: 5| Step: 2
Training loss: 0.5850217342376709
Validation loss: 2.012973041944606

Epoch: 5| Step: 3
Training loss: 0.5655268430709839
Validation loss: 1.9576999474597234

Epoch: 5| Step: 4
Training loss: 0.5014170408248901
Validation loss: 1.9743620426424089

Epoch: 5| Step: 5
Training loss: 0.9806932210922241
Validation loss: 1.9524051707278016

Epoch: 5| Step: 6
Training loss: 0.6855911612510681
Validation loss: 1.9587447976553312

Epoch: 5| Step: 7
Training loss: 0.6156309843063354
Validation loss: 1.9512544588376117

Epoch: 5| Step: 8
Training loss: 0.7879642248153687
Validation loss: 1.942889395580497

Epoch: 5| Step: 9
Training loss: 0.7842764258384705
Validation loss: 1.9564242657794748

Epoch: 5| Step: 10
Training loss: 0.7872218489646912
Validation loss: 1.9163954975784465

Epoch: 233| Step: 0
Training loss: 0.462970107793808
Validation loss: 1.9109895613885695

Epoch: 5| Step: 1
Training loss: 0.6697145700454712
Validation loss: 1.8957288213955459

Epoch: 5| Step: 2
Training loss: 0.7898470163345337
Validation loss: 1.9059786309478104

Epoch: 5| Step: 3
Training loss: 0.7259387373924255
Validation loss: 1.92829543031672

Epoch: 5| Step: 4
Training loss: 0.708168625831604
Validation loss: 1.917529458640724

Epoch: 5| Step: 5
Training loss: 0.6069773435592651
Validation loss: 1.9223385600633518

Epoch: 5| Step: 6
Training loss: 0.844942569732666
Validation loss: 1.9319949496176936

Epoch: 5| Step: 7
Training loss: 0.6669436693191528
Validation loss: 1.9536917773626183

Epoch: 5| Step: 8
Training loss: 0.7432460188865662
Validation loss: 1.9740921912654754

Epoch: 5| Step: 9
Training loss: 0.48116636276245117
Validation loss: 1.9742731548124743

Epoch: 5| Step: 10
Training loss: 0.5209603309631348
Validation loss: 1.9834511485151065

Epoch: 234| Step: 0
Training loss: 0.7218812108039856
Validation loss: 1.9760740521133586

Epoch: 5| Step: 1
Training loss: 0.5033798217773438
Validation loss: 1.966941140031302

Epoch: 5| Step: 2
Training loss: 0.8883743286132812
Validation loss: 1.9391363359266711

Epoch: 5| Step: 3
Training loss: 0.4605124592781067
Validation loss: 1.9204838173363799

Epoch: 5| Step: 4
Training loss: 0.5922995805740356
Validation loss: 1.8920837012670373

Epoch: 5| Step: 5
Training loss: 0.9022926092147827
Validation loss: 1.8572444954226095

Epoch: 5| Step: 6
Training loss: 0.8481389880180359
Validation loss: 1.8484412572717155

Epoch: 5| Step: 7
Training loss: 0.4969816207885742
Validation loss: 1.8387691385002547

Epoch: 5| Step: 8
Training loss: 0.699719250202179
Validation loss: 1.8699115604482672

Epoch: 5| Step: 9
Training loss: 0.4694674611091614
Validation loss: 1.8676512574636808

Epoch: 5| Step: 10
Training loss: 0.6290574073791504
Validation loss: 1.8841345899848527

Epoch: 235| Step: 0
Training loss: 0.5151637196540833
Validation loss: 1.9360675645130936

Epoch: 5| Step: 1
Training loss: 0.6172067523002625
Validation loss: 1.942458752662905

Epoch: 5| Step: 2
Training loss: 0.5028653144836426
Validation loss: 1.9855883711127824

Epoch: 5| Step: 3
Training loss: 1.0651566982269287
Validation loss: 2.0229419764652046

Epoch: 5| Step: 4
Training loss: 0.984965980052948
Validation loss: 2.0249553906020297

Epoch: 5| Step: 5
Training loss: 0.7073262333869934
Validation loss: 1.9892743851548882

Epoch: 5| Step: 6
Training loss: 0.6043190360069275
Validation loss: 2.0107166087755592

Epoch: 5| Step: 7
Training loss: 0.7804869413375854
Validation loss: 1.9990847444021573

Epoch: 5| Step: 8
Training loss: 0.4398784041404724
Validation loss: 1.9614742032943233

Epoch: 5| Step: 9
Training loss: 0.42480698227882385
Validation loss: 1.9343974628756124

Epoch: 5| Step: 10
Training loss: 0.5062108635902405
Validation loss: 1.91443298709008

Epoch: 236| Step: 0
Training loss: 0.4267355501651764
Validation loss: 1.9126972242068219

Epoch: 5| Step: 1
Training loss: 1.123234510421753
Validation loss: 1.8905459219409573

Epoch: 5| Step: 2
Training loss: 0.46610918641090393
Validation loss: 1.9082011830422185

Epoch: 5| Step: 3
Training loss: 0.5756206512451172
Validation loss: 1.9069274984380251

Epoch: 5| Step: 4
Training loss: 0.5433453321456909
Validation loss: 1.9061536494121756

Epoch: 5| Step: 5
Training loss: 0.8084927797317505
Validation loss: 1.9091413918361868

Epoch: 5| Step: 6
Training loss: 0.42344504594802856
Validation loss: 1.9194081316712082

Epoch: 5| Step: 7
Training loss: 0.94227135181427
Validation loss: 1.9382571968981015

Epoch: 5| Step: 8
Training loss: 0.6519128680229187
Validation loss: 1.9470816632752777

Epoch: 5| Step: 9
Training loss: 0.5958285331726074
Validation loss: 1.9438487137517622

Epoch: 5| Step: 10
Training loss: 0.5955950021743774
Validation loss: 1.9062718101727065

Epoch: 237| Step: 0
Training loss: 0.642902672290802
Validation loss: 1.9153914297780683

Epoch: 5| Step: 1
Training loss: 0.49654093384742737
Validation loss: 1.9022747265395297

Epoch: 5| Step: 2
Training loss: 0.529056966304779
Validation loss: 1.9114368718157533

Epoch: 5| Step: 3
Training loss: 0.5221791863441467
Validation loss: 1.9115928526847594

Epoch: 5| Step: 4
Training loss: 0.6820865869522095
Validation loss: 1.8826184080493065

Epoch: 5| Step: 5
Training loss: 1.0497913360595703
Validation loss: 1.854183566185736

Epoch: 5| Step: 6
Training loss: 0.5166966319084167
Validation loss: 1.867496128364276

Epoch: 5| Step: 7
Training loss: 0.8230531811714172
Validation loss: 1.8867461912093624

Epoch: 5| Step: 8
Training loss: 0.6055760383605957
Validation loss: 1.9280174406625892

Epoch: 5| Step: 9
Training loss: 0.7456663250923157
Validation loss: 1.9347348546469083

Epoch: 5| Step: 10
Training loss: 0.6159157752990723
Validation loss: 1.9704208220205

Epoch: 238| Step: 0
Training loss: 0.5805593132972717
Validation loss: 1.9984746876583304

Epoch: 5| Step: 1
Training loss: 0.7953373789787292
Validation loss: 1.9986934905411096

Epoch: 5| Step: 2
Training loss: 0.4440445303916931
Validation loss: 1.9765605221512497

Epoch: 5| Step: 3
Training loss: 0.7013788223266602
Validation loss: 1.947592096944009

Epoch: 5| Step: 4
Training loss: 0.9112927317619324
Validation loss: 1.8894942742522045

Epoch: 5| Step: 5
Training loss: 0.5861371755599976
Validation loss: 1.8881616054042694

Epoch: 5| Step: 6
Training loss: 0.9810434579849243
Validation loss: 1.8430822228872648

Epoch: 5| Step: 7
Training loss: 0.5493469834327698
Validation loss: 1.823073753746607

Epoch: 5| Step: 8
Training loss: 0.5557829737663269
Validation loss: 1.878289274631008

Epoch: 5| Step: 9
Training loss: 0.3229054808616638
Validation loss: 1.8917742390786447

Epoch: 5| Step: 10
Training loss: 0.7849584817886353
Validation loss: 1.9231537465126283

Epoch: 239| Step: 0
Training loss: 0.47097787261009216
Validation loss: 1.9589056661052089

Epoch: 5| Step: 1
Training loss: 0.6465961337089539
Validation loss: 2.0034326173925914

Epoch: 5| Step: 2
Training loss: 0.501017689704895
Validation loss: 2.0244655442494217

Epoch: 5| Step: 3
Training loss: 0.5590516924858093
Validation loss: 2.014327518401607

Epoch: 5| Step: 4
Training loss: 0.7968363761901855
Validation loss: 2.0223122924886723

Epoch: 5| Step: 5
Training loss: 0.6003147959709167
Validation loss: 2.025035899172547

Epoch: 5| Step: 6
Training loss: 0.6610585451126099
Validation loss: 2.0198489491657545

Epoch: 5| Step: 7
Training loss: 0.6680875420570374
Validation loss: 1.9746967105455295

Epoch: 5| Step: 8
Training loss: 1.0256810188293457
Validation loss: 1.9298803242303992

Epoch: 5| Step: 9
Training loss: 0.6510620713233948
Validation loss: 1.9373272875303864

Epoch: 5| Step: 10
Training loss: 0.3551959991455078
Validation loss: 1.8735470579516502

Epoch: 240| Step: 0
Training loss: 0.3330584168434143
Validation loss: 1.8568055629730225

Epoch: 5| Step: 1
Training loss: 0.7424208521842957
Validation loss: 1.8825714793256534

Epoch: 5| Step: 2
Training loss: 0.5199611783027649
Validation loss: 1.9306198114989905

Epoch: 5| Step: 3
Training loss: 0.5503734350204468
Validation loss: 1.8870440324147542

Epoch: 5| Step: 4
Training loss: 0.6851019859313965
Validation loss: 1.9227671315593104

Epoch: 5| Step: 5
Training loss: 0.6978712677955627
Validation loss: 1.9539278271377727

Epoch: 5| Step: 6
Training loss: 0.5935378670692444
Validation loss: 1.9532624342108285

Epoch: 5| Step: 7
Training loss: 0.469362735748291
Validation loss: 1.9300960609989781

Epoch: 5| Step: 8
Training loss: 0.6806166768074036
Validation loss: 1.9433150099169823

Epoch: 5| Step: 9
Training loss: 0.6565394401550293
Validation loss: 1.9584659094451575

Epoch: 5| Step: 10
Training loss: 0.7898105382919312
Validation loss: 1.9656542424232728

Epoch: 241| Step: 0
Training loss: 0.4159848093986511
Validation loss: 1.9730091876881097

Epoch: 5| Step: 1
Training loss: 0.9311442375183105
Validation loss: 1.941824584878901

Epoch: 5| Step: 2
Training loss: 0.5594652891159058
Validation loss: 1.959783346422257

Epoch: 5| Step: 3
Training loss: 0.3707793354988098
Validation loss: 1.9476203726183983

Epoch: 5| Step: 4
Training loss: 0.6148155927658081
Validation loss: 1.9773591949093727

Epoch: 5| Step: 5
Training loss: 0.6388896703720093
Validation loss: 1.9543847345536756

Epoch: 5| Step: 6
Training loss: 0.47081294655799866
Validation loss: 1.9998318918289677

Epoch: 5| Step: 7
Training loss: 0.6227113008499146
Validation loss: 1.9950796711829402

Epoch: 5| Step: 8
Training loss: 0.47040754556655884
Validation loss: 1.9799382045704832

Epoch: 5| Step: 9
Training loss: 0.5942437052726746
Validation loss: 1.9815830223021969

Epoch: 5| Step: 10
Training loss: 0.9200482368469238
Validation loss: 1.9696785660200222

Epoch: 242| Step: 0
Training loss: 0.895712673664093
Validation loss: 1.9550291415183776

Epoch: 5| Step: 1
Training loss: 0.6058821082115173
Validation loss: 1.951857869343091

Epoch: 5| Step: 2
Training loss: 0.4463554322719574
Validation loss: 1.9086364456402358

Epoch: 5| Step: 3
Training loss: 0.6461397409439087
Validation loss: 1.9257636967525686

Epoch: 5| Step: 4
Training loss: 0.6424177289009094
Validation loss: 1.8946376577500375

Epoch: 5| Step: 5
Training loss: 0.5918052792549133
Validation loss: 1.923190357864544

Epoch: 5| Step: 6
Training loss: 0.5511422753334045
Validation loss: 1.9564071996237642

Epoch: 5| Step: 7
Training loss: 0.515352725982666
Validation loss: 1.945756337975943

Epoch: 5| Step: 8
Training loss: 0.49755507707595825
Validation loss: 1.9682283375852851

Epoch: 5| Step: 9
Training loss: 0.5504664182662964
Validation loss: 1.9734714146583312

Epoch: 5| Step: 10
Training loss: 0.563024640083313
Validation loss: 1.9804381683308592

Epoch: 243| Step: 0
Training loss: 0.9671584963798523
Validation loss: 1.9449686234997166

Epoch: 5| Step: 1
Training loss: 0.648527979850769
Validation loss: 1.9247510663924678

Epoch: 5| Step: 2
Training loss: 0.5075917840003967
Validation loss: 1.9422884141245196

Epoch: 5| Step: 3
Training loss: 0.7118114829063416
Validation loss: 1.914677914752755

Epoch: 5| Step: 4
Training loss: 0.5504162907600403
Validation loss: 1.925911218889298

Epoch: 5| Step: 5
Training loss: 0.4471868574619293
Validation loss: 1.9158810184847923

Epoch: 5| Step: 6
Training loss: 0.5173364877700806
Validation loss: 1.8962033000043643

Epoch: 5| Step: 7
Training loss: 0.5144200325012207
Validation loss: 1.9330507837316042

Epoch: 5| Step: 8
Training loss: 0.6237720847129822
Validation loss: 1.9409146334535332

Epoch: 5| Step: 9
Training loss: 0.591771125793457
Validation loss: 1.9635758835782287

Epoch: 5| Step: 10
Training loss: 0.3443712294101715
Validation loss: 1.9650698169585197

Epoch: 244| Step: 0
Training loss: 0.7832309007644653
Validation loss: 1.9823327090150566

Epoch: 5| Step: 1
Training loss: 0.8450876474380493
Validation loss: 1.969285685528991

Epoch: 5| Step: 2
Training loss: 0.5380112528800964
Validation loss: 1.984616982039585

Epoch: 5| Step: 3
Training loss: 0.37146449089050293
Validation loss: 1.946329862840714

Epoch: 5| Step: 4
Training loss: 0.3651282489299774
Validation loss: 1.9232299981578704

Epoch: 5| Step: 5
Training loss: 0.7267245650291443
Validation loss: 1.9355180994156869

Epoch: 5| Step: 6
Training loss: 0.5611175298690796
Validation loss: 1.9211497973370295

Epoch: 5| Step: 7
Training loss: 0.7004498839378357
Validation loss: 1.9201719965986026

Epoch: 5| Step: 8
Training loss: 0.4721698760986328
Validation loss: 1.9184123598119265

Epoch: 5| Step: 9
Training loss: 0.6139739751815796
Validation loss: 1.9417446608184485

Epoch: 5| Step: 10
Training loss: 0.3160285949707031
Validation loss: 1.9827557994473366

Epoch: 245| Step: 0
Training loss: 0.4081171154975891
Validation loss: 1.9802140010300504

Epoch: 5| Step: 1
Training loss: 0.647032618522644
Validation loss: 1.9865822881780646

Epoch: 5| Step: 2
Training loss: 0.3059273660182953
Validation loss: 1.9607599550677883

Epoch: 5| Step: 3
Training loss: 0.42980122566223145
Validation loss: 1.9684039802961453

Epoch: 5| Step: 4
Training loss: 0.8342632055282593
Validation loss: 1.956684818831823

Epoch: 5| Step: 5
Training loss: 0.6161089539527893
Validation loss: 1.920601603805378

Epoch: 5| Step: 6
Training loss: 0.6303990483283997
Validation loss: 1.907055139541626

Epoch: 5| Step: 7
Training loss: 0.5105894804000854
Validation loss: 1.9243824815237394

Epoch: 5| Step: 8
Training loss: 0.7069711089134216
Validation loss: 1.8792050307796848

Epoch: 5| Step: 9
Training loss: 0.555277943611145
Validation loss: 1.878855618097449

Epoch: 5| Step: 10
Training loss: 0.7441890835762024
Validation loss: 1.89356925026063

Epoch: 246| Step: 0
Training loss: 0.6670870780944824
Validation loss: 1.895875197584911

Epoch: 5| Step: 1
Training loss: 0.7346401810646057
Validation loss: 1.8918551052770307

Epoch: 5| Step: 2
Training loss: 0.4401743412017822
Validation loss: 1.9074953461206088

Epoch: 5| Step: 3
Training loss: 0.7769337296485901
Validation loss: 1.9141293136022424

Epoch: 5| Step: 4
Training loss: 0.4033489227294922
Validation loss: 1.9157665916668472

Epoch: 5| Step: 5
Training loss: 0.4807875156402588
Validation loss: 1.9474963026662027

Epoch: 5| Step: 6
Training loss: 0.7103961706161499
Validation loss: 1.9448062527564265

Epoch: 5| Step: 7
Training loss: 0.4518253207206726
Validation loss: 1.9358683542538715

Epoch: 5| Step: 8
Training loss: 0.4663930833339691
Validation loss: 1.902397290352852

Epoch: 5| Step: 9
Training loss: 0.3334770202636719
Validation loss: 1.967066962231872

Epoch: 5| Step: 10
Training loss: 0.8227554559707642
Validation loss: 1.9762620490084413

Epoch: 247| Step: 0
Training loss: 0.589255690574646
Validation loss: 1.9567568917428293

Epoch: 5| Step: 1
Training loss: 0.3497764468193054
Validation loss: 1.9491105169378302

Epoch: 5| Step: 2
Training loss: 0.512032151222229
Validation loss: 1.9941504488709152

Epoch: 5| Step: 3
Training loss: 0.47886934876441956
Validation loss: 1.975707951412406

Epoch: 5| Step: 4
Training loss: 0.6139453649520874
Validation loss: 1.9795880471506426

Epoch: 5| Step: 5
Training loss: 0.29541724920272827
Validation loss: 1.9943541044829993

Epoch: 5| Step: 6
Training loss: 0.6266158819198608
Validation loss: 1.9790246371299989

Epoch: 5| Step: 7
Training loss: 0.7094284296035767
Validation loss: 2.0031140978618334

Epoch: 5| Step: 8
Training loss: 0.7325059771537781
Validation loss: 2.0177766148762037

Epoch: 5| Step: 9
Training loss: 0.650667667388916
Validation loss: 1.9711753886233094

Epoch: 5| Step: 10
Training loss: 0.7596943974494934
Validation loss: 1.9922129531060495

Epoch: 248| Step: 0
Training loss: 0.7144371867179871
Validation loss: 1.9848461574123752

Epoch: 5| Step: 1
Training loss: 0.5366221070289612
Validation loss: 1.9933157018435899

Epoch: 5| Step: 2
Training loss: 0.4354744851589203
Validation loss: 1.9520517600479947

Epoch: 5| Step: 3
Training loss: 0.5085101127624512
Validation loss: 1.9414149638145202

Epoch: 5| Step: 4
Training loss: 0.3590937554836273
Validation loss: 1.9364684922720796

Epoch: 5| Step: 5
Training loss: 0.5193077921867371
Validation loss: 1.983196061144593

Epoch: 5| Step: 6
Training loss: 0.5293639898300171
Validation loss: 1.9411925756803123

Epoch: 5| Step: 7
Training loss: 0.7389458417892456
Validation loss: 1.9294877206125567

Epoch: 5| Step: 8
Training loss: 0.5033695697784424
Validation loss: 1.9241454280832762

Epoch: 5| Step: 9
Training loss: 0.6862466931343079
Validation loss: 1.8747533534162788

Epoch: 5| Step: 10
Training loss: 0.6626280546188354
Validation loss: 1.9169077770684355

Epoch: 249| Step: 0
Training loss: 0.8080469965934753
Validation loss: 1.897462773066695

Epoch: 5| Step: 1
Training loss: 0.5991765856742859
Validation loss: 1.895011713427882

Epoch: 5| Step: 2
Training loss: 0.5918974876403809
Validation loss: 1.9655107503296227

Epoch: 5| Step: 3
Training loss: 0.9396141767501831
Validation loss: 1.9428124120158534

Epoch: 5| Step: 4
Training loss: 0.38738125562667847
Validation loss: 1.9728072574061732

Epoch: 5| Step: 5
Training loss: 0.48815304040908813
Validation loss: 1.968399599034299

Epoch: 5| Step: 6
Training loss: 0.5425313711166382
Validation loss: 1.9918656990092287

Epoch: 5| Step: 7
Training loss: 0.3691462278366089
Validation loss: 1.9702989183446413

Epoch: 5| Step: 8
Training loss: 0.37252435088157654
Validation loss: 1.9596884968460246

Epoch: 5| Step: 9
Training loss: 0.4744855761528015
Validation loss: 1.9141676913025558

Epoch: 5| Step: 10
Training loss: 0.4492228031158447
Validation loss: 1.9318879137757003

Epoch: 250| Step: 0
Training loss: 0.7698615193367004
Validation loss: 1.904846768225393

Epoch: 5| Step: 1
Training loss: 0.5290039777755737
Validation loss: 1.8488855977212229

Epoch: 5| Step: 2
Training loss: 0.6022157669067383
Validation loss: 1.8872999183593258

Epoch: 5| Step: 3
Training loss: 0.4579997956752777
Validation loss: 1.8731641871954805

Epoch: 5| Step: 4
Training loss: 0.5863103866577148
Validation loss: 1.8739102412295598

Epoch: 5| Step: 5
Training loss: 0.38528555631637573
Validation loss: 1.9010661417438137

Epoch: 5| Step: 6
Training loss: 0.46624860167503357
Validation loss: 1.9159828655181392

Epoch: 5| Step: 7
Training loss: 0.7619127631187439
Validation loss: 1.8998445131445443

Epoch: 5| Step: 8
Training loss: 0.43128061294555664
Validation loss: 1.914976095640531

Epoch: 5| Step: 9
Training loss: 0.43658724427223206
Validation loss: 1.8800906929918515

Epoch: 5| Step: 10
Training loss: 0.5813881754875183
Validation loss: 1.90361725899481

Epoch: 251| Step: 0
Training loss: 0.38254478573799133
Validation loss: 1.9101933381890739

Epoch: 5| Step: 1
Training loss: 0.7797465920448303
Validation loss: 1.9109026142345962

Epoch: 5| Step: 2
Training loss: 0.5967763662338257
Validation loss: 1.9073656694863432

Epoch: 5| Step: 3
Training loss: 0.5353649854660034
Validation loss: 1.8987282617117769

Epoch: 5| Step: 4
Training loss: 0.5050808191299438
Validation loss: 1.892075728344661

Epoch: 5| Step: 5
Training loss: 0.43901100754737854
Validation loss: 1.8617404930053219

Epoch: 5| Step: 6
Training loss: 0.6081076860427856
Validation loss: 1.8750257056246522

Epoch: 5| Step: 7
Training loss: 0.4418720304965973
Validation loss: 1.8372881899597824

Epoch: 5| Step: 8
Training loss: 0.6989418268203735
Validation loss: 1.8442446531787995

Epoch: 5| Step: 9
Training loss: 0.4260993003845215
Validation loss: 1.8560391600413988

Epoch: 5| Step: 10
Training loss: 0.29577383399009705
Validation loss: 1.8484533166372648

Epoch: 252| Step: 0
Training loss: 0.5763899087905884
Validation loss: 1.8817390895658923

Epoch: 5| Step: 1
Training loss: 0.560248613357544
Validation loss: 1.8716378711885022

Epoch: 5| Step: 2
Training loss: 0.6181002855300903
Validation loss: 1.877970576286316

Epoch: 5| Step: 3
Training loss: 0.5861420631408691
Validation loss: 1.8929328200637654

Epoch: 5| Step: 4
Training loss: 0.4385620951652527
Validation loss: 1.8981186651414441

Epoch: 5| Step: 5
Training loss: 0.6713532209396362
Validation loss: 1.923153664476128

Epoch: 5| Step: 6
Training loss: 0.6752480864524841
Validation loss: 1.9170004142227994

Epoch: 5| Step: 7
Training loss: 0.5490217208862305
Validation loss: 1.9231382441777054

Epoch: 5| Step: 8
Training loss: 0.37833476066589355
Validation loss: 1.9263651409456808

Epoch: 5| Step: 9
Training loss: 0.4927040934562683
Validation loss: 1.9036935042309504

Epoch: 5| Step: 10
Training loss: 0.3308066129684448
Validation loss: 1.9347760946519914

Epoch: 253| Step: 0
Training loss: 0.7846099734306335
Validation loss: 1.9384599783087288

Epoch: 5| Step: 1
Training loss: 0.5292779803276062
Validation loss: 1.941311800351707

Epoch: 5| Step: 2
Training loss: 0.4568272531032562
Validation loss: 1.9626651835697952

Epoch: 5| Step: 3
Training loss: 0.6712470650672913
Validation loss: 1.9302797394414102

Epoch: 5| Step: 4
Training loss: 0.27715450525283813
Validation loss: 1.8947497978005359

Epoch: 5| Step: 5
Training loss: 0.4443710744380951
Validation loss: 1.874936883167554

Epoch: 5| Step: 6
Training loss: 0.4128356873989105
Validation loss: 1.8402883237408054

Epoch: 5| Step: 7
Training loss: 0.5221245884895325
Validation loss: 1.8559607293016167

Epoch: 5| Step: 8
Training loss: 0.7116521596908569
Validation loss: 1.8310745851967924

Epoch: 5| Step: 9
Training loss: 0.794755756855011
Validation loss: 1.8822478568682106

Epoch: 5| Step: 10
Training loss: 0.6659719944000244
Validation loss: 1.852793833260895

Epoch: 254| Step: 0
Training loss: 0.5506502389907837
Validation loss: 1.9473270652114705

Epoch: 5| Step: 1
Training loss: 0.5452857613563538
Validation loss: 1.9850025638457267

Epoch: 5| Step: 2
Training loss: 0.5720122456550598
Validation loss: 2.0583388856662217

Epoch: 5| Step: 3
Training loss: 0.7990407347679138
Validation loss: 2.0827535942036617

Epoch: 5| Step: 4
Training loss: 0.38905414938926697
Validation loss: 2.099240777313068

Epoch: 5| Step: 5
Training loss: 0.6381493806838989
Validation loss: 2.041086084099226

Epoch: 5| Step: 6
Training loss: 0.4172683358192444
Validation loss: 2.0109078807215535

Epoch: 5| Step: 7
Training loss: 0.6734704971313477
Validation loss: 1.9811719361171927

Epoch: 5| Step: 8
Training loss: 0.9267837405204773
Validation loss: 1.9196377646538518

Epoch: 5| Step: 9
Training loss: 0.4811355173587799
Validation loss: 1.8492188735674786

Epoch: 5| Step: 10
Training loss: 0.20172297954559326
Validation loss: 1.8674563413025231

Epoch: 255| Step: 0
Training loss: 0.7043856978416443
Validation loss: 1.840248651401971

Epoch: 5| Step: 1
Training loss: 0.41697821021080017
Validation loss: 1.863789427664972

Epoch: 5| Step: 2
Training loss: 0.6380108594894409
Validation loss: 1.863681593248921

Epoch: 5| Step: 3
Training loss: 0.31425899267196655
Validation loss: 1.8812528015464864

Epoch: 5| Step: 4
Training loss: 0.35443979501724243
Validation loss: 1.9091255293097547

Epoch: 5| Step: 5
Training loss: 0.637794554233551
Validation loss: 1.912781443647159

Epoch: 5| Step: 6
Training loss: 0.32641884684562683
Validation loss: 1.9526612950909523

Epoch: 5| Step: 7
Training loss: 0.34648072719573975
Validation loss: 1.9394024597701205

Epoch: 5| Step: 8
Training loss: 0.6606202125549316
Validation loss: 1.945370046041345

Epoch: 5| Step: 9
Training loss: 0.8946945071220398
Validation loss: 1.964653858574488

Epoch: 5| Step: 10
Training loss: 0.644432783126831
Validation loss: 1.9722478248739754

Epoch: 256| Step: 0
Training loss: 0.5299216508865356
Validation loss: 1.990458583319059

Epoch: 5| Step: 1
Training loss: 0.5632487535476685
Validation loss: 1.9603779392857705

Epoch: 5| Step: 2
Training loss: 0.52805095911026
Validation loss: 1.977809888060375

Epoch: 5| Step: 3
Training loss: 0.4557366371154785
Validation loss: 1.948456007947204

Epoch: 5| Step: 4
Training loss: 0.5582393407821655
Validation loss: 1.919132891521659

Epoch: 5| Step: 5
Training loss: 0.6135584712028503
Validation loss: 1.8890264546999367

Epoch: 5| Step: 6
Training loss: 0.5911601185798645
Validation loss: 1.8842028007712415

Epoch: 5| Step: 7
Training loss: 0.46740788221359253
Validation loss: 1.8831738477112145

Epoch: 5| Step: 8
Training loss: 0.32736772298812866
Validation loss: 1.9098908003940378

Epoch: 5| Step: 9
Training loss: 0.442863404750824
Validation loss: 1.9134210630129742

Epoch: 5| Step: 10
Training loss: 0.5446596741676331
Validation loss: 1.9227908900989

Epoch: 257| Step: 0
Training loss: 0.701117992401123
Validation loss: 1.953229223528216

Epoch: 5| Step: 1
Training loss: 0.6865739822387695
Validation loss: 1.9376928614031883

Epoch: 5| Step: 2
Training loss: 0.5158863067626953
Validation loss: 1.9313482904946933

Epoch: 5| Step: 3
Training loss: 0.5159356594085693
Validation loss: 1.9226141411771056

Epoch: 5| Step: 4
Training loss: 0.47294729948043823
Validation loss: 1.8838916875982796

Epoch: 5| Step: 5
Training loss: 0.2302444726228714
Validation loss: 1.9195994266899683

Epoch: 5| Step: 6
Training loss: 0.7361161708831787
Validation loss: 1.929532330523255

Epoch: 5| Step: 7
Training loss: 0.2231379747390747
Validation loss: 1.9538377895150134

Epoch: 5| Step: 8
Training loss: 0.3188613951206207
Validation loss: 1.9368854479123188

Epoch: 5| Step: 9
Training loss: 0.5640579462051392
Validation loss: 1.9124983087662728

Epoch: 5| Step: 10
Training loss: 0.4497773349285126
Validation loss: 1.9081723984851633

Epoch: 258| Step: 0
Training loss: 0.4946504533290863
Validation loss: 1.929643556635867

Epoch: 5| Step: 1
Training loss: 0.405707448720932
Validation loss: 1.9166715042565459

Epoch: 5| Step: 2
Training loss: 0.4636445641517639
Validation loss: 1.9224568131149455

Epoch: 5| Step: 3
Training loss: 0.45533618330955505
Validation loss: 1.925883823825467

Epoch: 5| Step: 4
Training loss: 0.3403699994087219
Validation loss: 1.940504623997596

Epoch: 5| Step: 5
Training loss: 0.4939797818660736
Validation loss: 1.9404573197005897

Epoch: 5| Step: 6
Training loss: 0.5069872140884399
Validation loss: 1.918125298715407

Epoch: 5| Step: 7
Training loss: 0.5405546426773071
Validation loss: 1.948404606952462

Epoch: 5| Step: 8
Training loss: 0.398165762424469
Validation loss: 1.9107167874613116

Epoch: 5| Step: 9
Training loss: 0.666979968547821
Validation loss: 1.900997979666597

Epoch: 5| Step: 10
Training loss: 0.44909077882766724
Validation loss: 1.876024684598369

Epoch: 259| Step: 0
Training loss: 0.4315248429775238
Validation loss: 1.891067192118655

Epoch: 5| Step: 1
Training loss: 0.3435691297054291
Validation loss: 1.8656116019013107

Epoch: 5| Step: 2
Training loss: 0.573773205280304
Validation loss: 1.8515856945386497

Epoch: 5| Step: 3
Training loss: 0.4632807672023773
Validation loss: 1.8212475058852986

Epoch: 5| Step: 4
Training loss: 0.6048792004585266
Validation loss: 1.8571970642253917

Epoch: 5| Step: 5
Training loss: 0.4491778314113617
Validation loss: 1.8659917564802273

Epoch: 5| Step: 6
Training loss: 0.66281658411026
Validation loss: 1.8780475893328268

Epoch: 5| Step: 7
Training loss: 0.5769250988960266
Validation loss: 1.9013307171483194

Epoch: 5| Step: 8
Training loss: 0.31277161836624146
Validation loss: 1.8880768847721878

Epoch: 5| Step: 9
Training loss: 0.44673505425453186
Validation loss: 1.9187994105841524

Epoch: 5| Step: 10
Training loss: 0.5493907332420349
Validation loss: 1.958828733813378

Epoch: 260| Step: 0
Training loss: 0.7794908285140991
Validation loss: 1.9388241152609549

Epoch: 5| Step: 1
Training loss: 0.349826842546463
Validation loss: 1.868620249532884

Epoch: 5| Step: 2
Training loss: 0.3767467439174652
Validation loss: 1.867643028177241

Epoch: 5| Step: 3
Training loss: 0.2856970429420471
Validation loss: 1.8788739917098836

Epoch: 5| Step: 4
Training loss: 0.6032568216323853
Validation loss: 1.8279788635110343

Epoch: 5| Step: 5
Training loss: 0.5408338904380798
Validation loss: 1.8695574729673323

Epoch: 5| Step: 6
Training loss: 0.39726173877716064
Validation loss: 1.827322167734946

Epoch: 5| Step: 7
Training loss: 0.4049145579338074
Validation loss: 1.8429737424337735

Epoch: 5| Step: 8
Training loss: 0.29928654432296753
Validation loss: 1.869159137049029

Epoch: 5| Step: 9
Training loss: 0.8775194883346558
Validation loss: 1.8218849551293157

Epoch: 5| Step: 10
Training loss: 0.3901408016681671
Validation loss: 1.8739847085809196

Epoch: 261| Step: 0
Training loss: 0.4914010465145111
Validation loss: 1.8692723910013835

Epoch: 5| Step: 1
Training loss: 0.5412524342536926
Validation loss: 1.8787077883238434

Epoch: 5| Step: 2
Training loss: 0.4496009349822998
Validation loss: 1.8825310032854798

Epoch: 5| Step: 3
Training loss: 0.41269174218177795
Validation loss: 1.8918335719775128

Epoch: 5| Step: 4
Training loss: 0.6888661980628967
Validation loss: 1.9117292845120994

Epoch: 5| Step: 5
Training loss: 0.6939533352851868
Validation loss: 1.8903351086442188

Epoch: 5| Step: 6
Training loss: 0.4469345510005951
Validation loss: 1.8848360648719213

Epoch: 5| Step: 7
Training loss: 0.44008374214172363
Validation loss: 1.8555739182297901

Epoch: 5| Step: 8
Training loss: 0.4339751601219177
Validation loss: 1.885063507223642

Epoch: 5| Step: 9
Training loss: 0.18813855946063995
Validation loss: 1.8798179472646406

Epoch: 5| Step: 10
Training loss: 0.27785524725914
Validation loss: 1.888822296614288

Epoch: 262| Step: 0
Training loss: 0.35955196619033813
Validation loss: 1.862323836613727

Epoch: 5| Step: 1
Training loss: 0.5736465454101562
Validation loss: 1.8483470819329704

Epoch: 5| Step: 2
Training loss: 0.3189677298069
Validation loss: 1.8783414645861554

Epoch: 5| Step: 3
Training loss: 0.4419783055782318
Validation loss: 1.8842742725085186

Epoch: 5| Step: 4
Training loss: 0.6027490496635437
Validation loss: 1.8868878618363412

Epoch: 5| Step: 5
Training loss: 0.5008684992790222
Validation loss: 1.9243836684893536

Epoch: 5| Step: 6
Training loss: 0.4075864255428314
Validation loss: 1.9588211069824875

Epoch: 5| Step: 7
Training loss: 0.4939427971839905
Validation loss: 1.9807944220881308

Epoch: 5| Step: 8
Training loss: 0.4512324333190918
Validation loss: 1.985564217772535

Epoch: 5| Step: 9
Training loss: 0.5984078645706177
Validation loss: 1.9824954463589577

Epoch: 5| Step: 10
Training loss: 0.45940151810646057
Validation loss: 1.9874962581101285

Epoch: 263| Step: 0
Training loss: 0.507294774055481
Validation loss: 1.951482033216825

Epoch: 5| Step: 1
Training loss: 0.3938911557197571
Validation loss: 1.96656451430372

Epoch: 5| Step: 2
Training loss: 0.642501950263977
Validation loss: 1.9597772065029349

Epoch: 5| Step: 3
Training loss: 0.5021819472312927
Validation loss: 1.9302473196419336

Epoch: 5| Step: 4
Training loss: 0.463581383228302
Validation loss: 1.940831676606209

Epoch: 5| Step: 5
Training loss: 0.44727054238319397
Validation loss: 1.931390320101092

Epoch: 5| Step: 6
Training loss: 0.2698695957660675
Validation loss: 1.9601246323636783

Epoch: 5| Step: 7
Training loss: 0.5059296488761902
Validation loss: 1.968820829545298

Epoch: 5| Step: 8
Training loss: 0.7672268152236938
Validation loss: 1.935418576322576

Epoch: 5| Step: 9
Training loss: 0.4496919512748718
Validation loss: 1.964475026694677

Epoch: 5| Step: 10
Training loss: 0.24379466474056244
Validation loss: 1.9490219495629753

Epoch: 264| Step: 0
Training loss: 0.3959278166294098
Validation loss: 1.9492993354797363

Epoch: 5| Step: 1
Training loss: 0.2943357229232788
Validation loss: 1.914641495673887

Epoch: 5| Step: 2
Training loss: 0.37831419706344604
Validation loss: 1.8707800090953868

Epoch: 5| Step: 3
Training loss: 0.20429453253746033
Validation loss: 1.8848837447422806

Epoch: 5| Step: 4
Training loss: 0.42130574584007263
Validation loss: 1.8789214716162732

Epoch: 5| Step: 5
Training loss: 0.6542154550552368
Validation loss: 1.90551878816338

Epoch: 5| Step: 6
Training loss: 0.43888401985168457
Validation loss: 1.8891614124339113

Epoch: 5| Step: 7
Training loss: 0.3327181339263916
Validation loss: 1.8826167378374326

Epoch: 5| Step: 8
Training loss: 0.5856868624687195
Validation loss: 1.86047694119074

Epoch: 5| Step: 9
Training loss: 0.5391942262649536
Validation loss: 1.8637644834415887

Epoch: 5| Step: 10
Training loss: 0.7641556859016418
Validation loss: 1.8768486720259472

Epoch: 265| Step: 0
Training loss: 0.5976325273513794
Validation loss: 1.87823272520496

Epoch: 5| Step: 1
Training loss: 0.5541096925735474
Validation loss: 1.8845212421109598

Epoch: 5| Step: 2
Training loss: 0.29338520765304565
Validation loss: 1.8827821067584458

Epoch: 5| Step: 3
Training loss: 0.6123102903366089
Validation loss: 1.8613931402083366

Epoch: 5| Step: 4
Training loss: 0.4170066714286804
Validation loss: 1.8466670038879558

Epoch: 5| Step: 5
Training loss: 0.42503872513771057
Validation loss: 1.8501354199583813

Epoch: 5| Step: 6
Training loss: 0.5098746418952942
Validation loss: 1.8558568518648866

Epoch: 5| Step: 7
Training loss: 0.5268034934997559
Validation loss: 1.8627879927235265

Epoch: 5| Step: 8
Training loss: 0.37701505422592163
Validation loss: 1.8301177537569435

Epoch: 5| Step: 9
Training loss: 0.23795799911022186
Validation loss: 1.862222021625888

Epoch: 5| Step: 10
Training loss: 0.5444588661193848
Validation loss: 1.8587380365658832

Epoch: 266| Step: 0
Training loss: 0.6313726305961609
Validation loss: 1.8619449125823153

Epoch: 5| Step: 1
Training loss: 0.3162544071674347
Validation loss: 1.8937459748278382

Epoch: 5| Step: 2
Training loss: 0.28884759545326233
Validation loss: 1.919198420739943

Epoch: 5| Step: 3
Training loss: 0.5395519733428955
Validation loss: 1.924454463425503

Epoch: 5| Step: 4
Training loss: 0.6778280735015869
Validation loss: 1.9337229331334431

Epoch: 5| Step: 5
Training loss: 0.21859721839427948
Validation loss: 1.9620872518067718

Epoch: 5| Step: 6
Training loss: 0.35237693786621094
Validation loss: 1.964294736103345

Epoch: 5| Step: 7
Training loss: 0.5350304841995239
Validation loss: 1.9558595662475915

Epoch: 5| Step: 8
Training loss: 0.4716881215572357
Validation loss: 1.9407908660109325

Epoch: 5| Step: 9
Training loss: 0.2948229908943176
Validation loss: 1.9446540571028186

Epoch: 5| Step: 10
Training loss: 0.4251129925251007
Validation loss: 1.919485060117578

Epoch: 267| Step: 0
Training loss: 0.24131326377391815
Validation loss: 1.930401550826206

Epoch: 5| Step: 1
Training loss: 0.3221173584461212
Validation loss: 1.9380056832426338

Epoch: 5| Step: 2
Training loss: 0.3302495777606964
Validation loss: 1.9289200767394035

Epoch: 5| Step: 3
Training loss: 0.43303078413009644
Validation loss: 1.9408974339885097

Epoch: 5| Step: 4
Training loss: 0.48199567198753357
Validation loss: 1.9215354355432654

Epoch: 5| Step: 5
Training loss: 0.25370490550994873
Validation loss: 1.9099186851132302

Epoch: 5| Step: 6
Training loss: 0.6570185422897339
Validation loss: 1.8867320424766951

Epoch: 5| Step: 7
Training loss: 0.40314140915870667
Validation loss: 1.8834308167939544

Epoch: 5| Step: 8
Training loss: 0.6163615584373474
Validation loss: 1.9083462274202736

Epoch: 5| Step: 9
Training loss: 0.2674805819988251
Validation loss: 1.9153018459197013

Epoch: 5| Step: 10
Training loss: 0.7252973318099976
Validation loss: 1.9594837286139046

Epoch: 268| Step: 0
Training loss: 0.37479454278945923
Validation loss: 1.9517681444844892

Epoch: 5| Step: 1
Training loss: 0.3917198181152344
Validation loss: 1.9707618656978811

Epoch: 5| Step: 2
Training loss: 0.3260767459869385
Validation loss: 1.9390105034715386

Epoch: 5| Step: 3
Training loss: 0.3788108229637146
Validation loss: 1.9283140859296244

Epoch: 5| Step: 4
Training loss: 0.48549914360046387
Validation loss: 1.909940411967616

Epoch: 5| Step: 5
Training loss: 0.3190680146217346
Validation loss: 1.898367940738637

Epoch: 5| Step: 6
Training loss: 0.5162466764450073
Validation loss: 1.8424166517872964

Epoch: 5| Step: 7
Training loss: 0.7209349870681763
Validation loss: 1.8685351751183952

Epoch: 5| Step: 8
Training loss: 0.4105854034423828
Validation loss: 1.8618112956323931

Epoch: 5| Step: 9
Training loss: 0.4606432020664215
Validation loss: 1.8686213095982869

Epoch: 5| Step: 10
Training loss: 0.31680700182914734
Validation loss: 1.8745107099574099

Epoch: 269| Step: 0
Training loss: 0.6356631517410278
Validation loss: 1.8876520626006588

Epoch: 5| Step: 1
Training loss: 0.45995646715164185
Validation loss: 1.8968247854581444

Epoch: 5| Step: 2
Training loss: 0.5592024922370911
Validation loss: 1.9293267034715222

Epoch: 5| Step: 3
Training loss: 0.5002110600471497
Validation loss: 1.944724380329091

Epoch: 5| Step: 4
Training loss: 0.3308548629283905
Validation loss: 1.9532979124335832

Epoch: 5| Step: 5
Training loss: 0.6624355912208557
Validation loss: 1.9383530975669943

Epoch: 5| Step: 6
Training loss: 0.48197707533836365
Validation loss: 1.92367462958059

Epoch: 5| Step: 7
Training loss: 0.42851266264915466
Validation loss: 1.9234710739504906

Epoch: 5| Step: 8
Training loss: 0.26740220189094543
Validation loss: 1.8966547801930418

Epoch: 5| Step: 9
Training loss: 0.3345218896865845
Validation loss: 1.9120166737546203

Epoch: 5| Step: 10
Training loss: 0.27339351177215576
Validation loss: 1.9055056943688342

Epoch: 270| Step: 0
Training loss: 0.37233391404151917
Validation loss: 1.8857096497730543

Epoch: 5| Step: 1
Training loss: 0.6228634119033813
Validation loss: 1.8939885964957617

Epoch: 5| Step: 2
Training loss: 0.30333173274993896
Validation loss: 1.8677201553057599

Epoch: 5| Step: 3
Training loss: 0.46974557638168335
Validation loss: 1.875075779935365

Epoch: 5| Step: 4
Training loss: 0.33123770356178284
Validation loss: 1.832605702902681

Epoch: 5| Step: 5
Training loss: 0.2077997922897339
Validation loss: 1.8544514768867082

Epoch: 5| Step: 6
Training loss: 0.39317786693573
Validation loss: 1.82306408433504

Epoch: 5| Step: 7
Training loss: 0.4550444185733795
Validation loss: 1.8288535841049687

Epoch: 5| Step: 8
Training loss: 0.48016175627708435
Validation loss: 1.8260941492613925

Epoch: 5| Step: 9
Training loss: 0.35375314950942993
Validation loss: 1.8612022553720782

Epoch: 5| Step: 10
Training loss: 0.8396647572517395
Validation loss: 1.872325861325828

Epoch: 271| Step: 0
Training loss: 0.6316372156143188
Validation loss: 1.8722952463293587

Epoch: 5| Step: 1
Training loss: 0.3009178042411804
Validation loss: 1.912406688095421

Epoch: 5| Step: 2
Training loss: 0.36968180537223816
Validation loss: 1.9151345119681409

Epoch: 5| Step: 3
Training loss: 0.3539162278175354
Validation loss: 1.917604213119835

Epoch: 5| Step: 4
Training loss: 0.5601477026939392
Validation loss: 1.9218047447102045

Epoch: 5| Step: 5
Training loss: 0.5181061029434204
Validation loss: 1.946349690037389

Epoch: 5| Step: 6
Training loss: 0.4256523549556732
Validation loss: 1.9230735225062217

Epoch: 5| Step: 7
Training loss: 0.40967923402786255
Validation loss: 1.9580286984802575

Epoch: 5| Step: 8
Training loss: 0.46164456009864807
Validation loss: 1.908594839034542

Epoch: 5| Step: 9
Training loss: 0.21340322494506836
Validation loss: 1.8948932963032876

Epoch: 5| Step: 10
Training loss: 0.3297068476676941
Validation loss: 1.9279762468030375

Epoch: 272| Step: 0
Training loss: 0.4457801282405853
Validation loss: 1.952540987281389

Epoch: 5| Step: 1
Training loss: 0.40318363904953003
Validation loss: 1.9176153649565995

Epoch: 5| Step: 2
Training loss: 0.46424636244773865
Validation loss: 1.9077565182921707

Epoch: 5| Step: 3
Training loss: 0.4816121459007263
Validation loss: 1.8867702099584764

Epoch: 5| Step: 4
Training loss: 0.38257288932800293
Validation loss: 1.892110591293663

Epoch: 5| Step: 5
Training loss: 0.46057844161987305
Validation loss: 1.91914580457954

Epoch: 5| Step: 6
Training loss: 0.27390414476394653
Validation loss: 1.9022996169264599

Epoch: 5| Step: 7
Training loss: 0.6545301675796509
Validation loss: 1.8946363759297196

Epoch: 5| Step: 8
Training loss: 0.25503426790237427
Validation loss: 1.9100295061706214

Epoch: 5| Step: 9
Training loss: 0.3677510619163513
Validation loss: 1.9018487712388397

Epoch: 5| Step: 10
Training loss: 0.25422924757003784
Validation loss: 1.903389935852379

Epoch: 273| Step: 0
Training loss: 0.24819311499595642
Validation loss: 1.8956965041416947

Epoch: 5| Step: 1
Training loss: 0.39960914850234985
Validation loss: 1.9090112665648102

Epoch: 5| Step: 2
Training loss: 0.39392396807670593
Validation loss: 1.881642064740581

Epoch: 5| Step: 3
Training loss: 0.3208414912223816
Validation loss: 1.8788041837753788

Epoch: 5| Step: 4
Training loss: 0.4471970498561859
Validation loss: 1.872981015072074

Epoch: 5| Step: 5
Training loss: 0.4348234534263611
Validation loss: 1.866227388381958

Epoch: 5| Step: 6
Training loss: 0.32938870787620544
Validation loss: 1.8299871542120492

Epoch: 5| Step: 7
Training loss: 0.41170644760131836
Validation loss: 1.7932692638007544

Epoch: 5| Step: 8
Training loss: 0.6052669882774353
Validation loss: 1.819728635972546

Epoch: 5| Step: 9
Training loss: 0.4667741358280182
Validation loss: 1.8483764894547001

Epoch: 5| Step: 10
Training loss: 0.33109399676322937
Validation loss: 1.8507761891170214

Epoch: 274| Step: 0
Training loss: 0.26730960607528687
Validation loss: 1.8682273818600563

Epoch: 5| Step: 1
Training loss: 0.5340709686279297
Validation loss: 1.8594422289120254

Epoch: 5| Step: 2
Training loss: 0.6505659818649292
Validation loss: 1.8890839597230316

Epoch: 5| Step: 3
Training loss: 0.2667281925678253
Validation loss: 1.861889112380243

Epoch: 5| Step: 4
Training loss: 0.4920317530632019
Validation loss: 1.8486725053479593

Epoch: 5| Step: 5
Training loss: 0.3778742253780365
Validation loss: 1.8454071680704753

Epoch: 5| Step: 6
Training loss: 0.4226999878883362
Validation loss: 1.8521229887521395

Epoch: 5| Step: 7
Training loss: 0.3015342056751251
Validation loss: 1.8573553485255088

Epoch: 5| Step: 8
Training loss: 0.3040044903755188
Validation loss: 1.8135688279264717

Epoch: 5| Step: 9
Training loss: 0.28472694754600525
Validation loss: 1.8319832022472093

Epoch: 5| Step: 10
Training loss: 0.3991587460041046
Validation loss: 1.857080864649947

Epoch: 275| Step: 0
Training loss: 0.3227553069591522
Validation loss: 1.8512421141388595

Epoch: 5| Step: 1
Training loss: 0.47028055787086487
Validation loss: 1.890338807977656

Epoch: 5| Step: 2
Training loss: 0.28884071111679077
Validation loss: 1.8782469175195182

Epoch: 5| Step: 3
Training loss: 0.304046094417572
Validation loss: 1.8805702450454875

Epoch: 5| Step: 4
Training loss: 0.5312494039535522
Validation loss: 1.8692748918328235

Epoch: 5| Step: 5
Training loss: 0.22035661339759827
Validation loss: 1.8654009757503387

Epoch: 5| Step: 6
Training loss: 0.6517223119735718
Validation loss: 1.8405430906562394

Epoch: 5| Step: 7
Training loss: 0.47080594301223755
Validation loss: 1.794778662343179

Epoch: 5| Step: 8
Training loss: 0.2858007848262787
Validation loss: 1.773562298026136

Epoch: 5| Step: 9
Training loss: 0.6157202124595642
Validation loss: 1.7645334838539042

Epoch: 5| Step: 10
Training loss: 0.19209350645542145
Validation loss: 1.8528777963371688

Epoch: 276| Step: 0
Training loss: 0.6717556715011597
Validation loss: 1.8438503985763879

Epoch: 5| Step: 1
Training loss: 0.24892565608024597
Validation loss: 1.8609560651163901

Epoch: 5| Step: 2
Training loss: 0.2729106545448303
Validation loss: 1.9075802192893079

Epoch: 5| Step: 3
Training loss: 0.44388771057128906
Validation loss: 1.906373864860945

Epoch: 5| Step: 4
Training loss: 0.2870432138442993
Validation loss: 1.925717161547753

Epoch: 5| Step: 5
Training loss: 0.37246042490005493
Validation loss: 1.9377803725581015

Epoch: 5| Step: 6
Training loss: 0.40974393486976624
Validation loss: 1.8976686000823975

Epoch: 5| Step: 7
Training loss: 0.40686964988708496
Validation loss: 1.9017756497988136

Epoch: 5| Step: 8
Training loss: 0.5283819437026978
Validation loss: 1.8816222016529371

Epoch: 5| Step: 9
Training loss: 0.29337000846862793
Validation loss: 1.857565399139158

Epoch: 5| Step: 10
Training loss: 0.4863247573375702
Validation loss: 1.8375244678989533

Epoch: 277| Step: 0
Training loss: 0.4633437693119049
Validation loss: 1.8276767705076484

Epoch: 5| Step: 1
Training loss: 0.3912622332572937
Validation loss: 1.8266857734290503

Epoch: 5| Step: 2
Training loss: 0.47358760237693787
Validation loss: 1.8446348649199291

Epoch: 5| Step: 3
Training loss: 0.45486897230148315
Validation loss: 1.851076219671516

Epoch: 5| Step: 4
Training loss: 0.41264158487319946
Validation loss: 1.8031791153774466

Epoch: 5| Step: 5
Training loss: 0.1957828402519226
Validation loss: 1.874955197816254

Epoch: 5| Step: 6
Training loss: 0.20065250992774963
Validation loss: 1.8665509659756896

Epoch: 5| Step: 7
Training loss: 0.4958271086215973
Validation loss: 1.913907822742257

Epoch: 5| Step: 8
Training loss: 0.5622516870498657
Validation loss: 1.9579661712851575

Epoch: 5| Step: 9
Training loss: 0.44488152861595154
Validation loss: 1.9583348381903865

Epoch: 5| Step: 10
Training loss: 0.27602657675743103
Validation loss: 1.9791069825490315

Epoch: 278| Step: 0
Training loss: 0.36198845505714417
Validation loss: 1.958245679896365

Epoch: 5| Step: 1
Training loss: 0.5931928157806396
Validation loss: 1.920671623240235

Epoch: 5| Step: 2
Training loss: 0.35957056283950806
Validation loss: 1.9075996901399346

Epoch: 5| Step: 3
Training loss: 0.3485638201236725
Validation loss: 1.8772359663440334

Epoch: 5| Step: 4
Training loss: 0.6095227003097534
Validation loss: 1.8657170034223987

Epoch: 5| Step: 5
Training loss: 0.33785298466682434
Validation loss: 1.8706533678116337

Epoch: 5| Step: 6
Training loss: 0.412183940410614
Validation loss: 1.845173611435839

Epoch: 5| Step: 7
Training loss: 0.28360509872436523
Validation loss: 1.884321443496212

Epoch: 5| Step: 8
Training loss: 0.278105765581131
Validation loss: 1.8527379958860335

Epoch: 5| Step: 9
Training loss: 0.2819213569164276
Validation loss: 1.872840662156382

Epoch: 5| Step: 10
Training loss: 0.3557209074497223
Validation loss: 1.8391536563955329

Epoch: 279| Step: 0
Training loss: 0.2472364455461502
Validation loss: 1.8743689444757277

Epoch: 5| Step: 1
Training loss: 0.3572351038455963
Validation loss: 1.8957421279722644

Epoch: 5| Step: 2
Training loss: 0.32734012603759766
Validation loss: 1.861425979163057

Epoch: 5| Step: 3
Training loss: 0.312777042388916
Validation loss: 1.8639049606938516

Epoch: 5| Step: 4
Training loss: 0.4597269892692566
Validation loss: 1.8937868841232792

Epoch: 5| Step: 5
Training loss: 0.3537414073944092
Validation loss: 1.9046529544297086

Epoch: 5| Step: 6
Training loss: 0.2720983028411865
Validation loss: 1.8782917145759828

Epoch: 5| Step: 7
Training loss: 0.5931448340415955
Validation loss: 1.8537777264912922

Epoch: 5| Step: 8
Training loss: 0.4606383442878723
Validation loss: 1.7935588654651438

Epoch: 5| Step: 9
Training loss: 0.2968096435070038
Validation loss: 1.7811587190115323

Epoch: 5| Step: 10
Training loss: 0.5366498231887817
Validation loss: 1.7832893389527515

Epoch: 280| Step: 0
Training loss: 0.6232866048812866
Validation loss: 1.7386984402133572

Epoch: 5| Step: 1
Training loss: 0.2585408687591553
Validation loss: 1.7751490557065575

Epoch: 5| Step: 2
Training loss: 0.4852234721183777
Validation loss: 1.8033594803143573

Epoch: 5| Step: 3
Training loss: 0.45840558409690857
Validation loss: 1.8465736707051594

Epoch: 5| Step: 4
Training loss: 0.633421003818512
Validation loss: 1.869333787630963

Epoch: 5| Step: 5
Training loss: 0.4558040201663971
Validation loss: 1.899041042532972

Epoch: 5| Step: 6
Training loss: 0.35058557987213135
Validation loss: 1.8927051354480047

Epoch: 5| Step: 7
Training loss: 0.30176466703414917
Validation loss: 1.8853316255795058

Epoch: 5| Step: 8
Training loss: 0.29333972930908203
Validation loss: 1.8748865601836995

Epoch: 5| Step: 9
Training loss: 0.2566072344779968
Validation loss: 1.8823436126914075

Epoch: 5| Step: 10
Training loss: 0.4010154902935028
Validation loss: 1.882237470278176

Epoch: 281| Step: 0
Training loss: 0.2857164740562439
Validation loss: 1.875707382796913

Epoch: 5| Step: 1
Training loss: 0.3139358460903168
Validation loss: 1.8663490985029487

Epoch: 5| Step: 2
Training loss: 0.4229661822319031
Validation loss: 1.8189271906370759

Epoch: 5| Step: 3
Training loss: 0.3720150589942932
Validation loss: 1.8673837748906945

Epoch: 5| Step: 4
Training loss: 0.24224357306957245
Validation loss: 1.8700036784654022

Epoch: 5| Step: 5
Training loss: 0.3153882622718811
Validation loss: 1.8696237969142135

Epoch: 5| Step: 6
Training loss: 0.30582675337791443
Validation loss: 1.8352073777106501

Epoch: 5| Step: 7
Training loss: 0.5174086689949036
Validation loss: 1.8426301992067726

Epoch: 5| Step: 8
Training loss: 0.27508026361465454
Validation loss: 1.831116735294301

Epoch: 5| Step: 9
Training loss: 0.4448365271091461
Validation loss: 1.8569237852609286

Epoch: 5| Step: 10
Training loss: 0.5038467645645142
Validation loss: 1.8617931591567172

Epoch: 282| Step: 0
Training loss: 0.2665935158729553
Validation loss: 1.8879390237151936

Epoch: 5| Step: 1
Training loss: 0.351447731256485
Validation loss: 1.8616959279583347

Epoch: 5| Step: 2
Training loss: 0.5650441646575928
Validation loss: 1.8645738542720836

Epoch: 5| Step: 3
Training loss: 0.4401553273200989
Validation loss: 1.8303653783695673

Epoch: 5| Step: 4
Training loss: 0.3594951033592224
Validation loss: 1.8217582984637188

Epoch: 5| Step: 5
Training loss: 0.5068514943122864
Validation loss: 1.796751550448838

Epoch: 5| Step: 6
Training loss: 0.5060242414474487
Validation loss: 1.7775507268085275

Epoch: 5| Step: 7
Training loss: 0.3696870505809784
Validation loss: 1.81408082285235

Epoch: 5| Step: 8
Training loss: 0.30880579352378845
Validation loss: 1.8494316198492562

Epoch: 5| Step: 9
Training loss: 0.3157804310321808
Validation loss: 1.8513243121485556

Epoch: 5| Step: 10
Training loss: 0.37375786900520325
Validation loss: 1.8631269854883994

Epoch: 283| Step: 0
Training loss: 0.32510852813720703
Validation loss: 1.8265567159139982

Epoch: 5| Step: 1
Training loss: 0.34203022718429565
Validation loss: 1.856817078846757

Epoch: 5| Step: 2
Training loss: 0.4703059196472168
Validation loss: 1.8999927108005812

Epoch: 5| Step: 3
Training loss: 0.25980496406555176
Validation loss: 1.8994809812115085

Epoch: 5| Step: 4
Training loss: 0.2887735068798065
Validation loss: 1.865264302940779

Epoch: 5| Step: 5
Training loss: 0.44140690565109253
Validation loss: 1.8836496119858117

Epoch: 5| Step: 6
Training loss: 0.552049994468689
Validation loss: 1.8481276753128215

Epoch: 5| Step: 7
Training loss: 0.27785158157348633
Validation loss: 1.859662591770131

Epoch: 5| Step: 8
Training loss: 0.214376300573349
Validation loss: 1.8473393173627957

Epoch: 5| Step: 9
Training loss: 0.34464120864868164
Validation loss: 1.8350547846927439

Epoch: 5| Step: 10
Training loss: 0.5431502461433411
Validation loss: 1.856320224782472

Epoch: 284| Step: 0
Training loss: 0.4505237638950348
Validation loss: 1.8269708438586163

Epoch: 5| Step: 1
Training loss: 0.4217812418937683
Validation loss: 1.8612008684424943

Epoch: 5| Step: 2
Training loss: 0.4231530725955963
Validation loss: 1.8632414815246419

Epoch: 5| Step: 3
Training loss: 0.23066456615924835
Validation loss: 1.9213689988659275

Epoch: 5| Step: 4
Training loss: 0.42823824286460876
Validation loss: 1.8833840047159502

Epoch: 5| Step: 5
Training loss: 0.3380303382873535
Validation loss: 1.8909988787866407

Epoch: 5| Step: 6
Training loss: 0.5909262895584106
Validation loss: 1.8896413669791272

Epoch: 5| Step: 7
Training loss: 0.1745937168598175
Validation loss: 1.8758630662836053

Epoch: 5| Step: 8
Training loss: 0.2118503749370575
Validation loss: 1.8507040533968198

Epoch: 5| Step: 9
Training loss: 0.4442283511161804
Validation loss: 1.8863699718188214

Epoch: 5| Step: 10
Training loss: 0.40454229712486267
Validation loss: 1.8875519639702254

Epoch: 285| Step: 0
Training loss: 0.44394007325172424
Validation loss: 1.851006248945831

Epoch: 5| Step: 1
Training loss: 0.27579498291015625
Validation loss: 1.834816389186408

Epoch: 5| Step: 2
Training loss: 0.3099576234817505
Validation loss: 1.8322812382892897

Epoch: 5| Step: 3
Training loss: 0.37001341581344604
Validation loss: 1.8200056238840985

Epoch: 5| Step: 4
Training loss: 0.3117777705192566
Validation loss: 1.8257285356521606

Epoch: 5| Step: 5
Training loss: 0.36780038475990295
Validation loss: 1.8508990221126105

Epoch: 5| Step: 6
Training loss: 0.29581722617149353
Validation loss: 1.8421253542746268

Epoch: 5| Step: 7
Training loss: 0.3628290891647339
Validation loss: 1.8656541096266879

Epoch: 5| Step: 8
Training loss: 0.2929445505142212
Validation loss: 1.8701975025156492

Epoch: 5| Step: 9
Training loss: 0.5539153814315796
Validation loss: 1.8756598041903587

Epoch: 5| Step: 10
Training loss: 0.41423511505126953
Validation loss: 1.8908472343157696

Epoch: 286| Step: 0
Training loss: 0.31528469920158386
Validation loss: 1.8559056353825394

Epoch: 5| Step: 1
Training loss: 0.3375388979911804
Validation loss: 1.8141959956897202

Epoch: 5| Step: 2
Training loss: 0.30265727639198303
Validation loss: 1.855299650981862

Epoch: 5| Step: 3
Training loss: 0.5052974820137024
Validation loss: 1.859921581001692

Epoch: 5| Step: 4
Training loss: 0.26534488797187805
Validation loss: 1.815153129639164

Epoch: 5| Step: 5
Training loss: 0.1830909550189972
Validation loss: 1.82229773588078

Epoch: 5| Step: 6
Training loss: 0.3965577185153961
Validation loss: 1.8283414251060897

Epoch: 5| Step: 7
Training loss: 0.4833228588104248
Validation loss: 1.8227365119482881

Epoch: 5| Step: 8
Training loss: 0.46232977509498596
Validation loss: 1.7968800170447237

Epoch: 5| Step: 9
Training loss: 0.30931025743484497
Validation loss: 1.8235453969688826

Epoch: 5| Step: 10
Training loss: 0.5533976554870605
Validation loss: 1.8397472994301909

Epoch: 287| Step: 0
Training loss: 0.32731688022613525
Validation loss: 1.8509380804595126

Epoch: 5| Step: 1
Training loss: 0.22748227417469025
Validation loss: 1.8283554136112172

Epoch: 5| Step: 2
Training loss: 0.5279096364974976
Validation loss: 1.842328686867991

Epoch: 5| Step: 3
Training loss: 0.3334950804710388
Validation loss: 1.8492692747423727

Epoch: 5| Step: 4
Training loss: 0.4711105227470398
Validation loss: 1.8576902112653177

Epoch: 5| Step: 5
Training loss: 0.3649929165840149
Validation loss: 1.8383224882105345

Epoch: 5| Step: 6
Training loss: 0.3788984715938568
Validation loss: 1.8956613668831446

Epoch: 5| Step: 7
Training loss: 0.29410409927368164
Validation loss: 1.8566935370045323

Epoch: 5| Step: 8
Training loss: 0.47268038988113403
Validation loss: 1.8636350067712928

Epoch: 5| Step: 9
Training loss: 0.3015502393245697
Validation loss: 1.869553283978534

Epoch: 5| Step: 10
Training loss: 0.404816597700119
Validation loss: 1.8600652858775149

Epoch: 288| Step: 0
Training loss: 0.359870582818985
Validation loss: 1.8385688310028405

Epoch: 5| Step: 1
Training loss: 0.26015692949295044
Validation loss: 1.846392640503504

Epoch: 5| Step: 2
Training loss: 0.35413289070129395
Validation loss: 1.8147172594583163

Epoch: 5| Step: 3
Training loss: 0.47607937455177307
Validation loss: 1.8076905415904136

Epoch: 5| Step: 4
Training loss: 0.2172342985868454
Validation loss: 1.7901386189204391

Epoch: 5| Step: 5
Training loss: 0.5234012007713318
Validation loss: 1.8190285723696473

Epoch: 5| Step: 6
Training loss: 0.18857617676258087
Validation loss: 1.7870374187346427

Epoch: 5| Step: 7
Training loss: 0.39881062507629395
Validation loss: 1.82704343077957

Epoch: 5| Step: 8
Training loss: 0.5266719460487366
Validation loss: 1.8367945353190105

Epoch: 5| Step: 9
Training loss: 0.27646535634994507
Validation loss: 1.844094894265616

Epoch: 5| Step: 10
Training loss: 0.28194400668144226
Validation loss: 1.9032122050562212

Epoch: 289| Step: 0
Training loss: 0.2663041353225708
Validation loss: 1.9352008937507548

Epoch: 5| Step: 1
Training loss: 0.377816379070282
Validation loss: 1.9260175176846084

Epoch: 5| Step: 2
Training loss: 0.4034309387207031
Validation loss: 1.8839599829848095

Epoch: 5| Step: 3
Training loss: 0.5483566522598267
Validation loss: 1.8706839238443682

Epoch: 5| Step: 4
Training loss: 0.2729836106300354
Validation loss: 1.8654246176442792

Epoch: 5| Step: 5
Training loss: 0.38643890619277954
Validation loss: 1.8501553074006112

Epoch: 5| Step: 6
Training loss: 0.3878230154514313
Validation loss: 1.8402926204025105

Epoch: 5| Step: 7
Training loss: 0.5307689309120178
Validation loss: 1.8139308626933763

Epoch: 5| Step: 8
Training loss: 0.26520198583602905
Validation loss: 1.8213180816301735

Epoch: 5| Step: 9
Training loss: 0.2466478794813156
Validation loss: 1.8538899780601583

Epoch: 5| Step: 10
Training loss: 0.26575925946235657
Validation loss: 1.8647987957923644

Epoch: 290| Step: 0
Training loss: 0.22240182757377625
Validation loss: 1.8793646020274009

Epoch: 5| Step: 1
Training loss: 0.6127958297729492
Validation loss: 1.863434676201113

Epoch: 5| Step: 2
Training loss: 0.2709197402000427
Validation loss: 1.8688032242559618

Epoch: 5| Step: 3
Training loss: 0.37449926137924194
Validation loss: 1.8427034321651663

Epoch: 5| Step: 4
Training loss: 0.2870787978172302
Validation loss: 1.8331915614425496

Epoch: 5| Step: 5
Training loss: 0.24939951300621033
Validation loss: 1.816563299907151

Epoch: 5| Step: 6
Training loss: 0.5443223714828491
Validation loss: 1.8097425635142992

Epoch: 5| Step: 7
Training loss: 0.35774484276771545
Validation loss: 1.8133158427412792

Epoch: 5| Step: 8
Training loss: 0.34750762581825256
Validation loss: 1.8218661828707623

Epoch: 5| Step: 9
Training loss: 0.3284962773323059
Validation loss: 1.8206272791790705

Epoch: 5| Step: 10
Training loss: 0.2586810290813446
Validation loss: 1.7941639141369892

Epoch: 291| Step: 0
Training loss: 0.24732670187950134
Validation loss: 1.8331593057160736

Epoch: 5| Step: 1
Training loss: 0.3297342360019684
Validation loss: 1.8503649811590872

Epoch: 5| Step: 2
Training loss: 0.3551020920276642
Validation loss: 1.8184315696839364

Epoch: 5| Step: 3
Training loss: 0.5208220481872559
Validation loss: 1.8455644525507444

Epoch: 5| Step: 4
Training loss: 0.35354530811309814
Validation loss: 1.843822620248282

Epoch: 5| Step: 5
Training loss: 0.5675452351570129
Validation loss: 1.8475519559716667

Epoch: 5| Step: 6
Training loss: 0.29336318373680115
Validation loss: 1.8455434012156662

Epoch: 5| Step: 7
Training loss: 0.32502418756484985
Validation loss: 1.845423347206526

Epoch: 5| Step: 8
Training loss: 0.2606002688407898
Validation loss: 1.840183078601796

Epoch: 5| Step: 9
Training loss: 0.316120445728302
Validation loss: 1.8250462662789129

Epoch: 5| Step: 10
Training loss: 0.3094666600227356
Validation loss: 1.8523735923151816

Epoch: 292| Step: 0
Training loss: 0.30376777052879333
Validation loss: 1.833890248370427

Epoch: 5| Step: 1
Training loss: 0.3439596891403198
Validation loss: 1.8508516665427917

Epoch: 5| Step: 2
Training loss: 0.4729855954647064
Validation loss: 1.8658982528153287

Epoch: 5| Step: 3
Training loss: 0.49527081847190857
Validation loss: 1.8716768090442946

Epoch: 5| Step: 4
Training loss: 0.401639461517334
Validation loss: 1.8545759531759447

Epoch: 5| Step: 5
Training loss: 0.35038721561431885
Validation loss: 1.8710903929125877

Epoch: 5| Step: 6
Training loss: 0.3674311637878418
Validation loss: 1.81469718487032

Epoch: 5| Step: 7
Training loss: 0.19703832268714905
Validation loss: 1.8096567776895338

Epoch: 5| Step: 8
Training loss: 0.3863218128681183
Validation loss: 1.8135890165964763

Epoch: 5| Step: 9
Training loss: 0.22535213828086853
Validation loss: 1.760504545704011

Epoch: 5| Step: 10
Training loss: 0.18640738725662231
Validation loss: 1.8194266987103287

Epoch: 293| Step: 0
Training loss: 0.33378157019615173
Validation loss: 1.808670986083246

Epoch: 5| Step: 1
Training loss: 0.5376276969909668
Validation loss: 1.803067781591928

Epoch: 5| Step: 2
Training loss: 0.39361700415611267
Validation loss: 1.797207934882051

Epoch: 5| Step: 3
Training loss: 0.38355553150177
Validation loss: 1.8211949794523177

Epoch: 5| Step: 4
Training loss: 0.4440292716026306
Validation loss: 1.823852745435571

Epoch: 5| Step: 5
Training loss: 0.17579300701618195
Validation loss: 1.824585457001963

Epoch: 5| Step: 6
Training loss: 0.2689115107059479
Validation loss: 1.8005854160554948

Epoch: 5| Step: 7
Training loss: 0.3907300531864166
Validation loss: 1.7935152553742932

Epoch: 5| Step: 8
Training loss: 0.23740097880363464
Validation loss: 1.7952935785375617

Epoch: 5| Step: 9
Training loss: 0.32248052954673767
Validation loss: 1.7675419545942737

Epoch: 5| Step: 10
Training loss: 0.17440643906593323
Validation loss: 1.816580895454653

Epoch: 294| Step: 0
Training loss: 0.433793306350708
Validation loss: 1.7980176300130866

Epoch: 5| Step: 1
Training loss: 0.2736676335334778
Validation loss: 1.805698617812126

Epoch: 5| Step: 2
Training loss: 0.29670965671539307
Validation loss: 1.8026416353000108

Epoch: 5| Step: 3
Training loss: 0.42815837264060974
Validation loss: 1.8435161818740189

Epoch: 5| Step: 4
Training loss: 0.38763293623924255
Validation loss: 1.8233237612632014

Epoch: 5| Step: 5
Training loss: 0.3294595181941986
Validation loss: 1.8137203775426394

Epoch: 5| Step: 6
Training loss: 0.3199661374092102
Validation loss: 1.8246220209265267

Epoch: 5| Step: 7
Training loss: 0.16371065378189087
Validation loss: 1.825938578574888

Epoch: 5| Step: 8
Training loss: 0.33160677552223206
Validation loss: 1.8290917181199597

Epoch: 5| Step: 9
Training loss: 0.41850337386131287
Validation loss: 1.8335562957230436

Epoch: 5| Step: 10
Training loss: 0.28397563099861145
Validation loss: 1.8170966191958355

Epoch: 295| Step: 0
Training loss: 0.5267051458358765
Validation loss: 1.8315797467385568

Epoch: 5| Step: 1
Training loss: 0.1895684450864792
Validation loss: 1.8035545272211875

Epoch: 5| Step: 2
Training loss: 0.493190199136734
Validation loss: 1.797382608536751

Epoch: 5| Step: 3
Training loss: 0.443316787481308
Validation loss: 1.8083273415924401

Epoch: 5| Step: 4
Training loss: 0.3220484256744385
Validation loss: 1.7970630699588406

Epoch: 5| Step: 5
Training loss: 0.3466484248638153
Validation loss: 1.8192494902559506

Epoch: 5| Step: 6
Training loss: 0.2726125717163086
Validation loss: 1.8144805149365497

Epoch: 5| Step: 7
Training loss: 0.19585534930229187
Validation loss: 1.7911063804421374

Epoch: 5| Step: 8
Training loss: 0.23464202880859375
Validation loss: 1.824737589205465

Epoch: 5| Step: 9
Training loss: 0.22241322696208954
Validation loss: 1.8226056560393302

Epoch: 5| Step: 10
Training loss: 0.4692981243133545
Validation loss: 1.8680125244202153

Epoch: 296| Step: 0
Training loss: 0.4685783386230469
Validation loss: 1.887384263418054

Epoch: 5| Step: 1
Training loss: 0.2401314228773117
Validation loss: 1.8874723180647819

Epoch: 5| Step: 2
Training loss: 0.465796560049057
Validation loss: 1.908207252461423

Epoch: 5| Step: 3
Training loss: 0.3787025213241577
Validation loss: 1.9193636499425417

Epoch: 5| Step: 4
Training loss: 0.37446320056915283
Validation loss: 1.9011221342189337

Epoch: 5| Step: 5
Training loss: 0.3004096448421478
Validation loss: 1.8595663078369633

Epoch: 5| Step: 6
Training loss: 0.28074637055397034
Validation loss: 1.8322497080731135

Epoch: 5| Step: 7
Training loss: 0.19837424159049988
Validation loss: 1.8176518076209611

Epoch: 5| Step: 8
Training loss: 0.4775978624820709
Validation loss: 1.7743980564096922

Epoch: 5| Step: 9
Training loss: 0.311549574136734
Validation loss: 1.7802370773848666

Epoch: 5| Step: 10
Training loss: 0.3300841450691223
Validation loss: 1.7660258463633958

Epoch: 297| Step: 0
Training loss: 0.2703041136264801
Validation loss: 1.774289559292537

Epoch: 5| Step: 1
Training loss: 0.37364497780799866
Validation loss: 1.7494915787891676

Epoch: 5| Step: 2
Training loss: 0.38251590728759766
Validation loss: 1.7852911256974744

Epoch: 5| Step: 3
Training loss: 0.2927955985069275
Validation loss: 1.781941948398467

Epoch: 5| Step: 4
Training loss: 0.4636608958244324
Validation loss: 1.8062568428695842

Epoch: 5| Step: 5
Training loss: 0.4313177168369293
Validation loss: 1.843828047475507

Epoch: 5| Step: 6
Training loss: 0.4316309094429016
Validation loss: 1.8269743099007556

Epoch: 5| Step: 7
Training loss: 0.35923296213150024
Validation loss: 1.8277421074528848

Epoch: 5| Step: 8
Training loss: 0.34227028489112854
Validation loss: 1.8705342918313959

Epoch: 5| Step: 9
Training loss: 0.29254016280174255
Validation loss: 1.8827462196350098

Epoch: 5| Step: 10
Training loss: 0.31233859062194824
Validation loss: 1.8435636643440492

Epoch: 298| Step: 0
Training loss: 0.25111061334609985
Validation loss: 1.8699200204623643

Epoch: 5| Step: 1
Training loss: 0.35597068071365356
Validation loss: 1.8712268080762637

Epoch: 5| Step: 2
Training loss: 0.262496680021286
Validation loss: 1.8421340962891937

Epoch: 5| Step: 3
Training loss: 0.4237357974052429
Validation loss: 1.8266552661054878

Epoch: 5| Step: 4
Training loss: 0.2451867163181305
Validation loss: 1.8510256826236684

Epoch: 5| Step: 5
Training loss: 0.3174702823162079
Validation loss: 1.837600064534013

Epoch: 5| Step: 6
Training loss: 0.3580622673034668
Validation loss: 1.8386947865127234

Epoch: 5| Step: 7
Training loss: 0.44328412413597107
Validation loss: 1.8681537118009341

Epoch: 5| Step: 8
Training loss: 0.4040536880493164
Validation loss: 1.8570502573443997

Epoch: 5| Step: 9
Training loss: 0.3905922770500183
Validation loss: 1.8527181327983897

Epoch: 5| Step: 10
Training loss: 0.49153462052345276
Validation loss: 1.799330880565028

Epoch: 299| Step: 0
Training loss: 0.4357585906982422
Validation loss: 1.837256912262209

Epoch: 5| Step: 1
Training loss: 0.3960130214691162
Validation loss: 1.8289405748408327

Epoch: 5| Step: 2
Training loss: 0.24730005860328674
Validation loss: 1.8384579432907926

Epoch: 5| Step: 3
Training loss: 0.3579879403114319
Validation loss: 1.822483031980453

Epoch: 5| Step: 4
Training loss: 0.23035331070423126
Validation loss: 1.8237284806466871

Epoch: 5| Step: 5
Training loss: 0.43765488266944885
Validation loss: 1.7942594341052476

Epoch: 5| Step: 6
Training loss: 0.32728615403175354
Validation loss: 1.8298832575480144

Epoch: 5| Step: 7
Training loss: 0.4192458987236023
Validation loss: 1.8382727484549246

Epoch: 5| Step: 8
Training loss: 0.5440796613693237
Validation loss: 1.8541703390818771

Epoch: 5| Step: 9
Training loss: 0.23789462447166443
Validation loss: 1.8527271632225282

Epoch: 5| Step: 10
Training loss: 0.35958805680274963
Validation loss: 1.8027724912089687

Epoch: 300| Step: 0
Training loss: 0.3838627338409424
Validation loss: 1.8099812615302302

Epoch: 5| Step: 1
Training loss: 0.35149577260017395
Validation loss: 1.7801917881094

Epoch: 5| Step: 2
Training loss: 0.38925498723983765
Validation loss: 1.8046327444814867

Epoch: 5| Step: 3
Training loss: 0.41036930680274963
Validation loss: 1.8185098863417102

Epoch: 5| Step: 4
Training loss: 0.24610432982444763
Validation loss: 1.8324823956335745

Epoch: 5| Step: 5
Training loss: 0.44718924164772034
Validation loss: 1.8296397783422982

Epoch: 5| Step: 6
Training loss: 0.32897311449050903
Validation loss: 1.848589026799766

Epoch: 5| Step: 7
Training loss: 0.19205628335475922
Validation loss: 1.8711229216667913

Epoch: 5| Step: 8
Training loss: 0.44743698835372925
Validation loss: 1.8402922082972784

Epoch: 5| Step: 9
Training loss: 0.1912539005279541
Validation loss: 1.8713573896756737

Epoch: 5| Step: 10
Training loss: 0.33942440152168274
Validation loss: 1.8843121079988376

Epoch: 301| Step: 0
Training loss: 0.38993018865585327
Validation loss: 1.8871939797555246

Epoch: 5| Step: 1
Training loss: 0.277455598115921
Validation loss: 1.8596011977041922

Epoch: 5| Step: 2
Training loss: 0.23842668533325195
Validation loss: 1.834314553968368

Epoch: 5| Step: 3
Training loss: 0.2993129789829254
Validation loss: 1.8328062142095258

Epoch: 5| Step: 4
Training loss: 0.40181732177734375
Validation loss: 1.7971264200825845

Epoch: 5| Step: 5
Training loss: 0.35143885016441345
Validation loss: 1.8069798177288425

Epoch: 5| Step: 6
Training loss: 0.1821204274892807
Validation loss: 1.7857691985304638

Epoch: 5| Step: 7
Training loss: 0.3753012418746948
Validation loss: 1.7873572611039685

Epoch: 5| Step: 8
Training loss: 0.3285931944847107
Validation loss: 1.7842710556522492

Epoch: 5| Step: 9
Training loss: 0.3009912967681885
Validation loss: 1.8048804947125014

Epoch: 5| Step: 10
Training loss: 0.257281094789505
Validation loss: 1.8065123455498808

Epoch: 302| Step: 0
Training loss: 0.4868488907814026
Validation loss: 1.8174170986298592

Epoch: 5| Step: 1
Training loss: 0.3739014267921448
Validation loss: 1.7998650920006536

Epoch: 5| Step: 2
Training loss: 0.17683981359004974
Validation loss: 1.8106543838336904

Epoch: 5| Step: 3
Training loss: 0.28893375396728516
Validation loss: 1.7985271330802672

Epoch: 5| Step: 4
Training loss: 0.12765967845916748
Validation loss: 1.8090968106382637

Epoch: 5| Step: 5
Training loss: 0.32073360681533813
Validation loss: 1.8259233108130835

Epoch: 5| Step: 6
Training loss: 0.36487165093421936
Validation loss: 1.8062719568129508

Epoch: 5| Step: 7
Training loss: 0.34084954857826233
Validation loss: 1.8425108796806746

Epoch: 5| Step: 8
Training loss: 0.3140299618244171
Validation loss: 1.8237428024250975

Epoch: 5| Step: 9
Training loss: 0.4162973463535309
Validation loss: 1.8379023267376808

Epoch: 5| Step: 10
Training loss: 0.29387763142585754
Validation loss: 1.8430823126146871

Epoch: 303| Step: 0
Training loss: 0.22053968906402588
Validation loss: 1.8600742778470438

Epoch: 5| Step: 1
Training loss: 0.49486011266708374
Validation loss: 1.8502090310537687

Epoch: 5| Step: 2
Training loss: 0.3127608597278595
Validation loss: 1.8372987726683259

Epoch: 5| Step: 3
Training loss: 0.24297955632209778
Validation loss: 1.8057061087700628

Epoch: 5| Step: 4
Training loss: 0.2626612186431885
Validation loss: 1.78082541624705

Epoch: 5| Step: 5
Training loss: 0.2628329396247864
Validation loss: 1.7961063743919454

Epoch: 5| Step: 6
Training loss: 0.30548956990242004
Validation loss: 1.7461133182689708

Epoch: 5| Step: 7
Training loss: 0.33275410532951355
Validation loss: 1.7772495797885361

Epoch: 5| Step: 8
Training loss: 0.392345130443573
Validation loss: 1.7816776562762517

Epoch: 5| Step: 9
Training loss: 0.37549254298210144
Validation loss: 1.7815395978189283

Epoch: 5| Step: 10
Training loss: 0.2571985721588135
Validation loss: 1.8138705543292466

Epoch: 304| Step: 0
Training loss: 0.19951210916042328
Validation loss: 1.8517856444081953

Epoch: 5| Step: 1
Training loss: 0.30539312958717346
Validation loss: 1.8601954316580167

Epoch: 5| Step: 2
Training loss: 0.31610000133514404
Validation loss: 1.8701777073644823

Epoch: 5| Step: 3
Training loss: 0.21021947264671326
Validation loss: 1.8885278342872538

Epoch: 5| Step: 4
Training loss: 0.5650020837783813
Validation loss: 1.8854847210709766

Epoch: 5| Step: 5
Training loss: 0.4058356285095215
Validation loss: 1.870815771882252

Epoch: 5| Step: 6
Training loss: 0.16317826509475708
Validation loss: 1.8690213580285349

Epoch: 5| Step: 7
Training loss: 0.4145539700984955
Validation loss: 1.82157652865174

Epoch: 5| Step: 8
Training loss: 0.29198500514030457
Validation loss: 1.7635965629290509

Epoch: 5| Step: 9
Training loss: 0.20979586243629456
Validation loss: 1.7796727688081804

Epoch: 5| Step: 10
Training loss: 0.30296996235847473
Validation loss: 1.7506883759652414

Epoch: 305| Step: 0
Training loss: 0.27490848302841187
Validation loss: 1.7456688945011427

Epoch: 5| Step: 1
Training loss: 0.36856213212013245
Validation loss: 1.7571066233419603

Epoch: 5| Step: 2
Training loss: 0.34607750177383423
Validation loss: 1.7362435735682005

Epoch: 5| Step: 3
Training loss: 0.23938660323619843
Validation loss: 1.7625833147315568

Epoch: 5| Step: 4
Training loss: 0.29289549589157104
Validation loss: 1.7998347256773262

Epoch: 5| Step: 5
Training loss: 0.2703839838504791
Validation loss: 1.7905140384551017

Epoch: 5| Step: 6
Training loss: 0.29813218116760254
Validation loss: 1.855206799763505

Epoch: 5| Step: 7
Training loss: 0.2836332619190216
Validation loss: 1.8292132910861765

Epoch: 5| Step: 8
Training loss: 0.21149225533008575
Validation loss: 1.8254003294052616

Epoch: 5| Step: 9
Training loss: 0.5737650394439697
Validation loss: 1.8323261481459423

Epoch: 5| Step: 10
Training loss: 0.1921508014202118
Validation loss: 1.7680433052842335

Epoch: 306| Step: 0
Training loss: 0.27496594190597534
Validation loss: 1.8272664085511239

Epoch: 5| Step: 1
Training loss: 0.2584502100944519
Validation loss: 1.8080620291412517

Epoch: 5| Step: 2
Training loss: 0.31894832849502563
Validation loss: 1.7721709371894918

Epoch: 5| Step: 3
Training loss: 0.24723000824451447
Validation loss: 1.8113891309307468

Epoch: 5| Step: 4
Training loss: 0.39866572618484497
Validation loss: 1.7799994048251901

Epoch: 5| Step: 5
Training loss: 0.43223294615745544
Validation loss: 1.8152949630573232

Epoch: 5| Step: 6
Training loss: 0.1527046263217926
Validation loss: 1.8151147442479287

Epoch: 5| Step: 7
Training loss: 0.420968234539032
Validation loss: 1.8492020701849332

Epoch: 5| Step: 8
Training loss: 0.14627708494663239
Validation loss: 1.8228497005278064

Epoch: 5| Step: 9
Training loss: 0.28891462087631226
Validation loss: 1.876466340916131

Epoch: 5| Step: 10
Training loss: 0.3554557263851166
Validation loss: 1.8536356469636321

Epoch: 307| Step: 0
Training loss: 0.22011308372020721
Validation loss: 1.8893491606558523

Epoch: 5| Step: 1
Training loss: 0.13805581629276276
Validation loss: 1.8772728135508876

Epoch: 5| Step: 2
Training loss: 0.35536032915115356
Validation loss: 1.8590528990632744

Epoch: 5| Step: 3
Training loss: 0.38545137643814087
Validation loss: 1.878137783337665

Epoch: 5| Step: 4
Training loss: 0.35832542181015015
Validation loss: 1.890776672670918

Epoch: 5| Step: 5
Training loss: 0.2910462021827698
Validation loss: 1.8460794982089792

Epoch: 5| Step: 6
Training loss: 0.45887795090675354
Validation loss: 1.8880287575465378

Epoch: 5| Step: 7
Training loss: 0.20988373458385468
Validation loss: 1.849288111091942

Epoch: 5| Step: 8
Training loss: 0.34093865752220154
Validation loss: 1.8171836035225981

Epoch: 5| Step: 9
Training loss: 0.44035497307777405
Validation loss: 1.8227534294128418

Epoch: 5| Step: 10
Training loss: 0.28627821803092957
Validation loss: 1.8419730355662685

Epoch: 308| Step: 0
Training loss: 0.30900150537490845
Validation loss: 1.8457042478745984

Epoch: 5| Step: 1
Training loss: 0.20712578296661377
Validation loss: 1.8386222149736138

Epoch: 5| Step: 2
Training loss: 0.3946283161640167
Validation loss: 1.8318500877708517

Epoch: 5| Step: 3
Training loss: 0.39243951439857483
Validation loss: 1.8539001031588482

Epoch: 5| Step: 4
Training loss: 0.3195369839668274
Validation loss: 1.8656904069326257

Epoch: 5| Step: 5
Training loss: 0.2564154267311096
Validation loss: 1.8631282288541076

Epoch: 5| Step: 6
Training loss: 0.31845754384994507
Validation loss: 1.876949240443527

Epoch: 5| Step: 7
Training loss: 0.2607232928276062
Validation loss: 1.8651309269730763

Epoch: 5| Step: 8
Training loss: 0.24569380283355713
Validation loss: 1.86280599845353

Epoch: 5| Step: 9
Training loss: 0.29659321904182434
Validation loss: 1.8611491726290794

Epoch: 5| Step: 10
Training loss: 0.43083906173706055
Validation loss: 1.8259777176764704

Epoch: 309| Step: 0
Training loss: 0.2555367350578308
Validation loss: 1.873566855666458

Epoch: 5| Step: 1
Training loss: 0.24403317272663116
Validation loss: 1.839788559944399

Epoch: 5| Step: 2
Training loss: 0.39467304944992065
Validation loss: 1.8126907079450545

Epoch: 5| Step: 3
Training loss: 0.3780977129936218
Validation loss: 1.8566537416109474

Epoch: 5| Step: 4
Training loss: 0.2576785087585449
Validation loss: 1.8499224185943604

Epoch: 5| Step: 5
Training loss: 0.34490376710891724
Validation loss: 1.8323439769847418

Epoch: 5| Step: 6
Training loss: 0.2937813699245453
Validation loss: 1.8218580151116976

Epoch: 5| Step: 7
Training loss: 0.35752400755882263
Validation loss: 1.8165742428072038

Epoch: 5| Step: 8
Training loss: 0.30405858159065247
Validation loss: 1.8530944470436341

Epoch: 5| Step: 9
Training loss: 0.3779101073741913
Validation loss: 1.8518107603955012

Epoch: 5| Step: 10
Training loss: 0.28656935691833496
Validation loss: 1.874445144848157

Epoch: 310| Step: 0
Training loss: 0.28492632508277893
Validation loss: 1.8501931467363912

Epoch: 5| Step: 1
Training loss: 0.2026500254869461
Validation loss: 1.8635953908325524

Epoch: 5| Step: 2
Training loss: 0.35736507177352905
Validation loss: 1.872703856037509

Epoch: 5| Step: 3
Training loss: 0.2441328465938568
Validation loss: 1.8322087026411487

Epoch: 5| Step: 4
Training loss: 0.22539083659648895
Validation loss: 1.8251755122215516

Epoch: 5| Step: 5
Training loss: 0.22232206165790558
Validation loss: 1.8405476539365706

Epoch: 5| Step: 6
Training loss: 0.5021332502365112
Validation loss: 1.8713317417329358

Epoch: 5| Step: 7
Training loss: 0.23475904762744904
Validation loss: 1.8351318784939346

Epoch: 5| Step: 8
Training loss: 0.46343499422073364
Validation loss: 1.8340163564169278

Epoch: 5| Step: 9
Training loss: 0.3156619668006897
Validation loss: 1.8478645214470484

Epoch: 5| Step: 10
Training loss: 0.23850595951080322
Validation loss: 1.8306804549309514

Epoch: 311| Step: 0
Training loss: 0.25749605894088745
Validation loss: 1.807982539617887

Epoch: 5| Step: 1
Training loss: 0.13568717241287231
Validation loss: 1.836607244706923

Epoch: 5| Step: 2
Training loss: 0.4616320729255676
Validation loss: 1.8188493841437883

Epoch: 5| Step: 3
Training loss: 0.2189522087574005
Validation loss: 1.8186225429657967

Epoch: 5| Step: 4
Training loss: 0.26594844460487366
Validation loss: 1.8574303298868158

Epoch: 5| Step: 5
Training loss: 0.1579107940196991
Validation loss: 1.883262716313844

Epoch: 5| Step: 6
Training loss: 0.43956702947616577
Validation loss: 1.8688439784511444

Epoch: 5| Step: 7
Training loss: 0.3910611867904663
Validation loss: 1.9188732267707906

Epoch: 5| Step: 8
Training loss: 0.331752747297287
Validation loss: 1.9174366125496485

Epoch: 5| Step: 9
Training loss: 0.3565078377723694
Validation loss: 1.8859205758699806

Epoch: 5| Step: 10
Training loss: 0.2384435385465622
Validation loss: 1.8679974707224036

Epoch: 312| Step: 0
Training loss: 0.2908654808998108
Validation loss: 1.8253449945039646

Epoch: 5| Step: 1
Training loss: 0.3037165701389313
Validation loss: 1.8304491171272852

Epoch: 5| Step: 2
Training loss: 0.4405759274959564
Validation loss: 1.7903729895109772

Epoch: 5| Step: 3
Training loss: 0.22072140872478485
Validation loss: 1.832080336027248

Epoch: 5| Step: 4
Training loss: 0.3017549514770508
Validation loss: 1.8230462638280724

Epoch: 5| Step: 5
Training loss: 0.25887531042099
Validation loss: 1.7955232179293068

Epoch: 5| Step: 6
Training loss: 0.23494413495063782
Validation loss: 1.79023765876729

Epoch: 5| Step: 7
Training loss: 0.26360565423965454
Validation loss: 1.7795034326532835

Epoch: 5| Step: 8
Training loss: 0.2791498303413391
Validation loss: 1.804659128189087

Epoch: 5| Step: 9
Training loss: 0.3149227499961853
Validation loss: 1.7947641572644633

Epoch: 5| Step: 10
Training loss: 0.2422669380903244
Validation loss: 1.8015377726606143

Epoch: 313| Step: 0
Training loss: 0.367267370223999
Validation loss: 1.813203385440252

Epoch: 5| Step: 1
Training loss: 0.252020925283432
Validation loss: 1.8353758217186056

Epoch: 5| Step: 2
Training loss: 0.21943417191505432
Validation loss: 1.8513635743048884

Epoch: 5| Step: 3
Training loss: 0.2889692783355713
Validation loss: 1.8705467947067753

Epoch: 5| Step: 4
Training loss: 0.394455224275589
Validation loss: 1.8919354972018991

Epoch: 5| Step: 5
Training loss: 0.2998560070991516
Validation loss: 1.8733884596055554

Epoch: 5| Step: 6
Training loss: 0.2762165665626526
Validation loss: 1.8456596777003298

Epoch: 5| Step: 7
Training loss: 0.4627684950828552
Validation loss: 1.8372872106490596

Epoch: 5| Step: 8
Training loss: 0.18651023507118225
Validation loss: 1.8004619011314966

Epoch: 5| Step: 9
Training loss: 0.2079743891954422
Validation loss: 1.7826071887887933

Epoch: 5| Step: 10
Training loss: 0.36768507957458496
Validation loss: 1.7485249478329894

Epoch: 314| Step: 0
Training loss: 0.20123514533042908
Validation loss: 1.7528427429096674

Epoch: 5| Step: 1
Training loss: 0.2682719826698303
Validation loss: 1.7464789600782498

Epoch: 5| Step: 2
Training loss: 0.22083444893360138
Validation loss: 1.7761174889021023

Epoch: 5| Step: 3
Training loss: 0.1838812381029129
Validation loss: 1.787708919535401

Epoch: 5| Step: 4
Training loss: 0.2386607676744461
Validation loss: 1.7866993719531643

Epoch: 5| Step: 5
Training loss: 0.36448225378990173
Validation loss: 1.7960512958547121

Epoch: 5| Step: 6
Training loss: 0.6945332288742065
Validation loss: 1.8186639431984193

Epoch: 5| Step: 7
Training loss: 0.24400849640369415
Validation loss: 1.8499944402325539

Epoch: 5| Step: 8
Training loss: 0.2808072566986084
Validation loss: 1.8615226643059843

Epoch: 5| Step: 9
Training loss: 0.36924633383750916
Validation loss: 1.8569438611307452

Epoch: 5| Step: 10
Training loss: 0.15610933303833008
Validation loss: 1.8613805206873084

Epoch: 315| Step: 0
Training loss: 0.3334314227104187
Validation loss: 1.8300181896455827

Epoch: 5| Step: 1
Training loss: 0.36881572008132935
Validation loss: 1.8205279688681326

Epoch: 5| Step: 2
Training loss: 0.2273908108472824
Validation loss: 1.8337113895723898

Epoch: 5| Step: 3
Training loss: 0.4723373353481293
Validation loss: 1.8440199718680432

Epoch: 5| Step: 4
Training loss: 0.3706360459327698
Validation loss: 1.841248381522394

Epoch: 5| Step: 5
Training loss: 0.2181851863861084
Validation loss: 1.8330575625101726

Epoch: 5| Step: 6
Training loss: 0.29387813806533813
Validation loss: 1.8466340213693597

Epoch: 5| Step: 7
Training loss: 0.3051859438419342
Validation loss: 1.8227381231964275

Epoch: 5| Step: 8
Training loss: 0.21157512068748474
Validation loss: 1.790985103576414

Epoch: 5| Step: 9
Training loss: 0.342407763004303
Validation loss: 1.8368214638002458

Epoch: 5| Step: 10
Training loss: 0.164389505982399
Validation loss: 1.8456832273032076

Epoch: 316| Step: 0
Training loss: 0.26031145453453064
Validation loss: 1.833999249242967

Epoch: 5| Step: 1
Training loss: 0.26380687952041626
Validation loss: 1.821723735460671

Epoch: 5| Step: 2
Training loss: 0.32660412788391113
Validation loss: 1.8339723476799585

Epoch: 5| Step: 3
Training loss: 0.317217618227005
Validation loss: 1.8321093026027884

Epoch: 5| Step: 4
Training loss: 0.2262926548719406
Validation loss: 1.8405848030121095

Epoch: 5| Step: 5
Training loss: 0.21514053642749786
Validation loss: 1.8238981949385775

Epoch: 5| Step: 6
Training loss: 0.2081773281097412
Validation loss: 1.803705588463814

Epoch: 5| Step: 7
Training loss: 0.5478006601333618
Validation loss: 1.8064670549925936

Epoch: 5| Step: 8
Training loss: 0.19527354836463928
Validation loss: 1.7922191119963122

Epoch: 5| Step: 9
Training loss: 0.24051840603351593
Validation loss: 1.7929424265379548

Epoch: 5| Step: 10
Training loss: 0.2081058770418167
Validation loss: 1.8165180888227237

Epoch: 317| Step: 0
Training loss: 0.2984617352485657
Validation loss: 1.824035313821608

Epoch: 5| Step: 1
Training loss: 0.2270854413509369
Validation loss: 1.8451020615075224

Epoch: 5| Step: 2
Training loss: 0.23589348793029785
Validation loss: 1.8285764750613962

Epoch: 5| Step: 3
Training loss: 0.23464319109916687
Validation loss: 1.8546095817319808

Epoch: 5| Step: 4
Training loss: 0.09170019626617432
Validation loss: 1.8627533092293689

Epoch: 5| Step: 5
Training loss: 0.16816356778144836
Validation loss: 1.843109861496956

Epoch: 5| Step: 6
Training loss: 0.348061203956604
Validation loss: 1.8078722620523104

Epoch: 5| Step: 7
Training loss: 0.30389752984046936
Validation loss: 1.8466877206679313

Epoch: 5| Step: 8
Training loss: 0.587417721748352
Validation loss: 1.8287161319486556

Epoch: 5| Step: 9
Training loss: 0.24762578308582306
Validation loss: 1.830265555330502

Epoch: 5| Step: 10
Training loss: 0.29960018396377563
Validation loss: 1.8367676004286735

Epoch: 318| Step: 0
Training loss: 0.24669703841209412
Validation loss: 1.7779659430185955

Epoch: 5| Step: 1
Training loss: 0.2089344561100006
Validation loss: 1.811181934930945

Epoch: 5| Step: 2
Training loss: 0.2621592879295349
Validation loss: 1.7796431869588873

Epoch: 5| Step: 3
Training loss: 0.23433656990528107
Validation loss: 1.8094022197108115

Epoch: 5| Step: 4
Training loss: 0.21131817996501923
Validation loss: 1.821485556581969

Epoch: 5| Step: 5
Training loss: 0.29491403698921204
Validation loss: 1.8227778186080277

Epoch: 5| Step: 6
Training loss: 0.4247209429740906
Validation loss: 1.8536056831318846

Epoch: 5| Step: 7
Training loss: 0.34053489565849304
Validation loss: 1.8809118629783712

Epoch: 5| Step: 8
Training loss: 0.2655832767486572
Validation loss: 1.8758456425000263

Epoch: 5| Step: 9
Training loss: 0.45193129777908325
Validation loss: 1.880172433391694

Epoch: 5| Step: 10
Training loss: 0.17600314319133759
Validation loss: 1.8663953068435832

Epoch: 319| Step: 0
Training loss: 0.20300202071666718
Validation loss: 1.8593073403963478

Epoch: 5| Step: 1
Training loss: 0.30594104528427124
Validation loss: 1.834459799592213

Epoch: 5| Step: 2
Training loss: 0.1214824691414833
Validation loss: 1.8146564742570281

Epoch: 5| Step: 3
Training loss: 0.2906267046928406
Validation loss: 1.79964062219025

Epoch: 5| Step: 4
Training loss: 0.26695892214775085
Validation loss: 1.800084880603257

Epoch: 5| Step: 5
Training loss: 0.3680558502674103
Validation loss: 1.7636396679826962

Epoch: 5| Step: 6
Training loss: 0.207393616437912
Validation loss: 1.7686328734121015

Epoch: 5| Step: 7
Training loss: 0.2050713300704956
Validation loss: 1.8000055448983305

Epoch: 5| Step: 8
Training loss: 0.21555392444133759
Validation loss: 1.7811782898441437

Epoch: 5| Step: 9
Training loss: 0.4169653356075287
Validation loss: 1.7660331033891248

Epoch: 5| Step: 10
Training loss: 0.22881823778152466
Validation loss: 1.8068537622369745

Epoch: 320| Step: 0
Training loss: 0.24878215789794922
Validation loss: 1.7561090069432412

Epoch: 5| Step: 1
Training loss: 0.29907724261283875
Validation loss: 1.780283861262824

Epoch: 5| Step: 2
Training loss: 0.16613799333572388
Validation loss: 1.8088541774339573

Epoch: 5| Step: 3
Training loss: 0.2768566310405731
Validation loss: 1.795698783730948

Epoch: 5| Step: 4
Training loss: 0.13687951862812042
Validation loss: 1.8074689821530414

Epoch: 5| Step: 5
Training loss: 0.27483832836151123
Validation loss: 1.8240967745422034

Epoch: 5| Step: 6
Training loss: 0.5191668272018433
Validation loss: 1.8218419603122178

Epoch: 5| Step: 7
Training loss: 0.2424699068069458
Validation loss: 1.826245629659263

Epoch: 5| Step: 8
Training loss: 0.15753647685050964
Validation loss: 1.8384833579422326

Epoch: 5| Step: 9
Training loss: 0.2048841416835785
Validation loss: 1.7991836686288156

Epoch: 5| Step: 10
Training loss: 0.23410233855247498
Validation loss: 1.7964777767017324

Epoch: 321| Step: 0
Training loss: 0.2902299463748932
Validation loss: 1.8080546702108076

Epoch: 5| Step: 1
Training loss: 0.23409095406532288
Validation loss: 1.8014198592914048

Epoch: 5| Step: 2
Training loss: 0.2259168177843094
Validation loss: 1.8267814049156763

Epoch: 5| Step: 3
Training loss: 0.19030682742595673
Validation loss: 1.8168098541998094

Epoch: 5| Step: 4
Training loss: 0.3590847849845886
Validation loss: 1.8280804913531068

Epoch: 5| Step: 5
Training loss: 0.18068838119506836
Validation loss: 1.8177661947024766

Epoch: 5| Step: 6
Training loss: 0.4208933711051941
Validation loss: 1.817474280634234

Epoch: 5| Step: 7
Training loss: 0.26776114106178284
Validation loss: 1.8039626011284449

Epoch: 5| Step: 8
Training loss: 0.17830145359039307
Validation loss: 1.841200501688065

Epoch: 5| Step: 9
Training loss: 0.27389857172966003
Validation loss: 1.8035963658363587

Epoch: 5| Step: 10
Training loss: 0.18315790593624115
Validation loss: 1.8114885284054665

Epoch: 322| Step: 0
Training loss: 0.2085002362728119
Validation loss: 1.8117793324173137

Epoch: 5| Step: 1
Training loss: 0.3554840385913849
Validation loss: 1.8109904617391608

Epoch: 5| Step: 2
Training loss: 0.25996944308280945
Validation loss: 1.8017622245255338

Epoch: 5| Step: 3
Training loss: 0.29287204146385193
Validation loss: 1.7996852538918937

Epoch: 5| Step: 4
Training loss: 0.264143168926239
Validation loss: 1.8186932481745237

Epoch: 5| Step: 5
Training loss: 0.2567369341850281
Validation loss: 1.7766918405409782

Epoch: 5| Step: 6
Training loss: 0.15783189237117767
Validation loss: 1.8061018541295042

Epoch: 5| Step: 7
Training loss: 0.23066739737987518
Validation loss: 1.7844482852566628

Epoch: 5| Step: 8
Training loss: 0.30990228056907654
Validation loss: 1.8009363220584007

Epoch: 5| Step: 9
Training loss: 0.1948111355304718
Validation loss: 1.814443278056319

Epoch: 5| Step: 10
Training loss: 0.17950843274593353
Validation loss: 1.796817010448825

Epoch: 323| Step: 0
Training loss: 0.196133092045784
Validation loss: 1.8008633826368599

Epoch: 5| Step: 1
Training loss: 0.18405359983444214
Validation loss: 1.7919833839580577

Epoch: 5| Step: 2
Training loss: 0.23741380870342255
Validation loss: 1.784895807184199

Epoch: 5| Step: 3
Training loss: 0.230230450630188
Validation loss: 1.7782618614935106

Epoch: 5| Step: 4
Training loss: 0.27757591009140015
Validation loss: 1.7957763543692968

Epoch: 5| Step: 5
Training loss: 0.12282421439886093
Validation loss: 1.8002190948814474

Epoch: 5| Step: 6
Training loss: 0.15996289253234863
Validation loss: 1.786904054303323

Epoch: 5| Step: 7
Training loss: 0.23446354269981384
Validation loss: 1.770282232633201

Epoch: 5| Step: 8
Training loss: 0.4218573570251465
Validation loss: 1.7655091131887128

Epoch: 5| Step: 9
Training loss: 0.24034690856933594
Validation loss: 1.7605781888449064

Epoch: 5| Step: 10
Training loss: 0.46450337767601013
Validation loss: 1.7481255499265527

Epoch: 324| Step: 0
Training loss: 0.23892657458782196
Validation loss: 1.7780228084133518

Epoch: 5| Step: 1
Training loss: 0.23803576827049255
Validation loss: 1.7766898601285872

Epoch: 5| Step: 2
Training loss: 0.236134335398674
Validation loss: 1.8018249337391188

Epoch: 5| Step: 3
Training loss: 0.2111966609954834
Validation loss: 1.8118279492983254

Epoch: 5| Step: 4
Training loss: 0.23559851944446564
Validation loss: 1.810784811614662

Epoch: 5| Step: 5
Training loss: 0.3281434178352356
Validation loss: 1.803848357610805

Epoch: 5| Step: 6
Training loss: 0.22550109028816223
Validation loss: 1.8391056291518673

Epoch: 5| Step: 7
Training loss: 0.2511370778083801
Validation loss: 1.8104319982631232

Epoch: 5| Step: 8
Training loss: 0.23597900569438934
Validation loss: 1.8380677892315773

Epoch: 5| Step: 9
Training loss: 0.2876646816730499
Validation loss: 1.802145359336689

Epoch: 5| Step: 10
Training loss: 0.2316814810037613
Validation loss: 1.8015129463647002

Epoch: 325| Step: 0
Training loss: 0.21010801196098328
Validation loss: 1.8080933004297235

Epoch: 5| Step: 1
Training loss: 0.39147061109542847
Validation loss: 1.8201449712117512

Epoch: 5| Step: 2
Training loss: 0.23257477581501007
Validation loss: 1.8163277551692019

Epoch: 5| Step: 3
Training loss: 0.26532116532325745
Validation loss: 1.7952216671359154

Epoch: 5| Step: 4
Training loss: 0.2987123727798462
Validation loss: 1.8032401710428216

Epoch: 5| Step: 5
Training loss: 0.13780207931995392
Validation loss: 1.790323268982672

Epoch: 5| Step: 6
Training loss: 0.1767689287662506
Validation loss: 1.8111365328552902

Epoch: 5| Step: 7
Training loss: 0.271750807762146
Validation loss: 1.7920403160074705

Epoch: 5| Step: 8
Training loss: 0.14486560225486755
Validation loss: 1.782902374062487

Epoch: 5| Step: 9
Training loss: 0.30259495973587036
Validation loss: 1.7623520038461173

Epoch: 5| Step: 10
Training loss: 0.24506403505802155
Validation loss: 1.768197972287414

Epoch: 326| Step: 0
Training loss: 0.38259634375572205
Validation loss: 1.7834376776090233

Epoch: 5| Step: 1
Training loss: 0.23482780158519745
Validation loss: 1.7787565928633495

Epoch: 5| Step: 2
Training loss: 0.3239346146583557
Validation loss: 1.7766745372485089

Epoch: 5| Step: 3
Training loss: 0.24479122459888458
Validation loss: 1.7891160236891879

Epoch: 5| Step: 4
Training loss: 0.13787397742271423
Validation loss: 1.7891557767827024

Epoch: 5| Step: 5
Training loss: 0.1753036081790924
Validation loss: 1.7827248188757128

Epoch: 5| Step: 6
Training loss: 0.23122486472129822
Validation loss: 1.7957861961856965

Epoch: 5| Step: 7
Training loss: 0.23140820860862732
Validation loss: 1.8034414399054743

Epoch: 5| Step: 8
Training loss: 0.17251093685626984
Validation loss: 1.778322942795292

Epoch: 5| Step: 9
Training loss: 0.19043834507465363
Validation loss: 1.806890841453306

Epoch: 5| Step: 10
Training loss: 0.23679612576961517
Validation loss: 1.8234107635354484

Epoch: 327| Step: 0
Training loss: 0.29977095127105713
Validation loss: 1.8549271783521097

Epoch: 5| Step: 1
Training loss: 0.2635977566242218
Validation loss: 1.8640322621150682

Epoch: 5| Step: 2
Training loss: 0.21137849986553192
Validation loss: 1.8443282855454313

Epoch: 5| Step: 3
Training loss: 0.2321738749742508
Validation loss: 1.8264812051608998

Epoch: 5| Step: 4
Training loss: 0.24604347348213196
Validation loss: 1.8200762797427434

Epoch: 5| Step: 5
Training loss: 0.23835773766040802
Validation loss: 1.8023107590213898

Epoch: 5| Step: 6
Training loss: 0.3064182996749878
Validation loss: 1.7875345624903196

Epoch: 5| Step: 7
Training loss: 0.3358187973499298
Validation loss: 1.7564643236898607

Epoch: 5| Step: 8
Training loss: 0.1429939866065979
Validation loss: 1.7450620692263368

Epoch: 5| Step: 9
Training loss: 0.23208418488502502
Validation loss: 1.7458870923647316

Epoch: 5| Step: 10
Training loss: 0.23046870529651642
Validation loss: 1.7253588361124839

Epoch: 328| Step: 0
Training loss: 0.25664567947387695
Validation loss: 1.7600585260698873

Epoch: 5| Step: 1
Training loss: 0.18260522186756134
Validation loss: 1.7313543391484085

Epoch: 5| Step: 2
Training loss: 0.3833969235420227
Validation loss: 1.7352314149179766

Epoch: 5| Step: 3
Training loss: 0.24070481956005096
Validation loss: 1.7355982629201745

Epoch: 5| Step: 4
Training loss: 0.17643821239471436
Validation loss: 1.778486268494719

Epoch: 5| Step: 5
Training loss: 0.2579638361930847
Validation loss: 1.7978119081066501

Epoch: 5| Step: 6
Training loss: 0.3081137537956238
Validation loss: 1.7934987468104209

Epoch: 5| Step: 7
Training loss: 0.23715391755104065
Validation loss: 1.7547604999234598

Epoch: 5| Step: 8
Training loss: 0.24146802723407745
Validation loss: 1.7532420568568732

Epoch: 5| Step: 9
Training loss: 0.31644853949546814
Validation loss: 1.7604573208798644

Epoch: 5| Step: 10
Training loss: 0.26355844736099243
Validation loss: 1.752382537370087

Epoch: 329| Step: 0
Training loss: 0.16611766815185547
Validation loss: 1.7436795881999436

Epoch: 5| Step: 1
Training loss: 0.22582168877124786
Validation loss: 1.7279259133082565

Epoch: 5| Step: 2
Training loss: 0.20674386620521545
Validation loss: 1.7470416599704373

Epoch: 5| Step: 3
Training loss: 0.17122036218643188
Validation loss: 1.746796659244004

Epoch: 5| Step: 4
Training loss: 0.264834463596344
Validation loss: 1.7770688277418896

Epoch: 5| Step: 5
Training loss: 0.23728224635124207
Validation loss: 1.7582369773618636

Epoch: 5| Step: 6
Training loss: 0.4757402539253235
Validation loss: 1.7762382812397455

Epoch: 5| Step: 7
Training loss: 0.3243197202682495
Validation loss: 1.8052272527448592

Epoch: 5| Step: 8
Training loss: 0.2231791466474533
Validation loss: 1.79685591882275

Epoch: 5| Step: 9
Training loss: 0.3400205373764038
Validation loss: 1.8219865060621692

Epoch: 5| Step: 10
Training loss: 0.272258996963501
Validation loss: 1.8121478826768938

Epoch: 330| Step: 0
Training loss: 0.19736218452453613
Validation loss: 1.782129692774947

Epoch: 5| Step: 1
Training loss: 0.2977787256240845
Validation loss: 1.767435085388922

Epoch: 5| Step: 2
Training loss: 0.24730411171913147
Validation loss: 1.7978232579846536

Epoch: 5| Step: 3
Training loss: 0.34226855635643005
Validation loss: 1.7840206059076453

Epoch: 5| Step: 4
Training loss: 0.2484939992427826
Validation loss: 1.7972298770822503

Epoch: 5| Step: 5
Training loss: 0.15802620351314545
Validation loss: 1.8009215311337543

Epoch: 5| Step: 6
Training loss: 0.2415986806154251
Validation loss: 1.8079783890836982

Epoch: 5| Step: 7
Training loss: 0.19982323050498962
Validation loss: 1.8127344500633977

Epoch: 5| Step: 8
Training loss: 0.3607423007488251
Validation loss: 1.815533672609637

Epoch: 5| Step: 9
Training loss: 0.2604590952396393
Validation loss: 1.87938186430162

Epoch: 5| Step: 10
Training loss: 0.27615582942962646
Validation loss: 1.837460853720224

Epoch: 331| Step: 0
Training loss: 0.16196505725383759
Validation loss: 1.8549911540041688

Epoch: 5| Step: 1
Training loss: 0.395577996969223
Validation loss: 1.858642194860725

Epoch: 5| Step: 2
Training loss: 0.2532999813556671
Validation loss: 1.8492235727207635

Epoch: 5| Step: 3
Training loss: 0.26195085048675537
Validation loss: 1.787605329226422

Epoch: 5| Step: 4
Training loss: 0.2669261395931244
Validation loss: 1.7959032699625979

Epoch: 5| Step: 5
Training loss: 0.2865797281265259
Validation loss: 1.7684938625622821

Epoch: 5| Step: 6
Training loss: 0.2762610614299774
Validation loss: 1.7562793903453375

Epoch: 5| Step: 7
Training loss: 0.20071081817150116
Validation loss: 1.7828007436567737

Epoch: 5| Step: 8
Training loss: 0.16440680623054504
Validation loss: 1.7640203455443024

Epoch: 5| Step: 9
Training loss: 0.3325321078300476
Validation loss: 1.7628788627604002

Epoch: 5| Step: 10
Training loss: 0.29999586939811707
Validation loss: 1.7369619236197522

Epoch: 332| Step: 0
Training loss: 0.16231989860534668
Validation loss: 1.7499912233762844

Epoch: 5| Step: 1
Training loss: 0.16261523962020874
Validation loss: 1.7576043298167567

Epoch: 5| Step: 2
Training loss: 0.21803133189678192
Validation loss: 1.7577594082842591

Epoch: 5| Step: 3
Training loss: 0.30955320596694946
Validation loss: 1.772314476710494

Epoch: 5| Step: 4
Training loss: 0.2364831268787384
Validation loss: 1.7910673285043368

Epoch: 5| Step: 5
Training loss: 0.1984122097492218
Validation loss: 1.7571357168177122

Epoch: 5| Step: 6
Training loss: 0.20770850777626038
Validation loss: 1.7580494214129705

Epoch: 5| Step: 7
Training loss: 0.38760071992874146
Validation loss: 1.7949593720897552

Epoch: 5| Step: 8
Training loss: 0.2399960458278656
Validation loss: 1.7920039981924079

Epoch: 5| Step: 9
Training loss: 0.17550703883171082
Validation loss: 1.775579293568929

Epoch: 5| Step: 10
Training loss: 0.10392629355192184
Validation loss: 1.7674665374140586

Epoch: 333| Step: 0
Training loss: 0.2597711682319641
Validation loss: 1.7679968623704807

Epoch: 5| Step: 1
Training loss: 0.1891779750585556
Validation loss: 1.8062017412595852

Epoch: 5| Step: 2
Training loss: 0.23933210968971252
Validation loss: 1.789232248901039

Epoch: 5| Step: 3
Training loss: 0.23006245493888855
Validation loss: 1.794677112692146

Epoch: 5| Step: 4
Training loss: 0.2023216187953949
Validation loss: 1.7647053221220612

Epoch: 5| Step: 5
Training loss: 0.3845009207725525
Validation loss: 1.7728446670757827

Epoch: 5| Step: 6
Training loss: 0.22023019194602966
Validation loss: 1.7972325689049178

Epoch: 5| Step: 7
Training loss: 0.24638886749744415
Validation loss: 1.7622886511587328

Epoch: 5| Step: 8
Training loss: 0.3265751004219055
Validation loss: 1.7935229347598167

Epoch: 5| Step: 9
Training loss: 0.18653999269008636
Validation loss: 1.7898920505277571

Epoch: 5| Step: 10
Training loss: 0.26505497097969055
Validation loss: 1.777630929023989

Epoch: 334| Step: 0
Training loss: 0.16455869376659393
Validation loss: 1.7746056356737692

Epoch: 5| Step: 1
Training loss: 0.19898942112922668
Validation loss: 1.7517696131942093

Epoch: 5| Step: 2
Training loss: 0.18643049895763397
Validation loss: 1.791881388233554

Epoch: 5| Step: 3
Training loss: 0.22997388243675232
Validation loss: 1.7548411584669543

Epoch: 5| Step: 4
Training loss: 0.2090894728899002
Validation loss: 1.8030298063831944

Epoch: 5| Step: 5
Training loss: 0.4092804789543152
Validation loss: 1.782739144499584

Epoch: 5| Step: 6
Training loss: 0.2607138156890869
Validation loss: 1.7879951320668703

Epoch: 5| Step: 7
Training loss: 0.2184033840894699
Validation loss: 1.7830400415646133

Epoch: 5| Step: 8
Training loss: 0.22876980900764465
Validation loss: 1.8077441479570122

Epoch: 5| Step: 9
Training loss: 0.14001762866973877
Validation loss: 1.7913482791634017

Epoch: 5| Step: 10
Training loss: 0.16068501770496368
Validation loss: 1.8092039336440384

Epoch: 335| Step: 0
Training loss: 0.18271349370479584
Validation loss: 1.795718426345497

Epoch: 5| Step: 1
Training loss: 0.1870257556438446
Validation loss: 1.8001024069324616

Epoch: 5| Step: 2
Training loss: 0.23503991961479187
Validation loss: 1.8071573318973664

Epoch: 5| Step: 3
Training loss: 0.30852165818214417
Validation loss: 1.7844082168353501

Epoch: 5| Step: 4
Training loss: 0.1837787926197052
Validation loss: 1.8097892884285218

Epoch: 5| Step: 5
Training loss: 0.2900843620300293
Validation loss: 1.7690296147459297

Epoch: 5| Step: 6
Training loss: 0.23991075158119202
Validation loss: 1.7777934266674904

Epoch: 5| Step: 7
Training loss: 0.173456072807312
Validation loss: 1.763642216241488

Epoch: 5| Step: 8
Training loss: 0.2782018780708313
Validation loss: 1.8019866366540231

Epoch: 5| Step: 9
Training loss: 0.10283036530017853
Validation loss: 1.779522524085096

Epoch: 5| Step: 10
Training loss: 0.25023409724235535
Validation loss: 1.7778639037122008

Epoch: 336| Step: 0
Training loss: 0.2679978013038635
Validation loss: 1.7950765753305087

Epoch: 5| Step: 1
Training loss: 0.24133548140525818
Validation loss: 1.7795763477202384

Epoch: 5| Step: 2
Training loss: 0.1766788810491562
Validation loss: 1.7966027208553847

Epoch: 5| Step: 3
Training loss: 0.19357533752918243
Validation loss: 1.7711038051113006

Epoch: 5| Step: 4
Training loss: 0.21979212760925293
Validation loss: 1.7993233421797394

Epoch: 5| Step: 5
Training loss: 0.2281649112701416
Validation loss: 1.8299367241961981

Epoch: 5| Step: 6
Training loss: 0.21202881634235382
Validation loss: 1.8149656730313455

Epoch: 5| Step: 7
Training loss: 0.2744598388671875
Validation loss: 1.7750561916699974

Epoch: 5| Step: 8
Training loss: 0.23495689034461975
Validation loss: 1.7755188121590564

Epoch: 5| Step: 9
Training loss: 0.15151545405387878
Validation loss: 1.821030496269144

Epoch: 5| Step: 10
Training loss: 0.3861244320869446
Validation loss: 1.8246267546889603

Epoch: 337| Step: 0
Training loss: 0.20219926536083221
Validation loss: 1.824638803799947

Epoch: 5| Step: 1
Training loss: 0.18588748574256897
Validation loss: 1.790435642324468

Epoch: 5| Step: 2
Training loss: 0.3429533839225769
Validation loss: 1.7465708371131652

Epoch: 5| Step: 3
Training loss: 0.2628411650657654
Validation loss: 1.752173840358693

Epoch: 5| Step: 4
Training loss: 0.2005983293056488
Validation loss: 1.721256668849658

Epoch: 5| Step: 5
Training loss: 0.4559510350227356
Validation loss: 1.7383045611842987

Epoch: 5| Step: 6
Training loss: 0.22212477028369904
Validation loss: 1.7472095361319921

Epoch: 5| Step: 7
Training loss: 0.2411484718322754
Validation loss: 1.7637338766487696

Epoch: 5| Step: 8
Training loss: 0.26901641488075256
Validation loss: 1.7542160505889564

Epoch: 5| Step: 9
Training loss: 0.17204126715660095
Validation loss: 1.791131555393178

Epoch: 5| Step: 10
Training loss: 0.18321575224399567
Validation loss: 1.7699459675819642

Epoch: 338| Step: 0
Training loss: 0.22145438194274902
Validation loss: 1.7986007877575454

Epoch: 5| Step: 1
Training loss: 0.2422349900007248
Validation loss: 1.782271569774997

Epoch: 5| Step: 2
Training loss: 0.21706266701221466
Validation loss: 1.8208543049391879

Epoch: 5| Step: 3
Training loss: 0.22716808319091797
Validation loss: 1.8292776820480183

Epoch: 5| Step: 4
Training loss: 0.3679518699645996
Validation loss: 1.8420145806445871

Epoch: 5| Step: 5
Training loss: 0.20427259802818298
Validation loss: 1.787979184940297

Epoch: 5| Step: 6
Training loss: 0.3634651303291321
Validation loss: 1.806672921744726

Epoch: 5| Step: 7
Training loss: 0.16440708935260773
Validation loss: 1.7787253766931512

Epoch: 5| Step: 8
Training loss: 0.4011078476905823
Validation loss: 1.7768426274740567

Epoch: 5| Step: 9
Training loss: 0.16254857182502747
Validation loss: 1.814508758565431

Epoch: 5| Step: 10
Training loss: 0.1792256087064743
Validation loss: 1.7935889792698685

Epoch: 339| Step: 0
Training loss: 0.2457515299320221
Validation loss: 1.7612970509836752

Epoch: 5| Step: 1
Training loss: 0.32078441977500916
Validation loss: 1.784115340120049

Epoch: 5| Step: 2
Training loss: 0.1604413092136383
Validation loss: 1.749740485222109

Epoch: 5| Step: 3
Training loss: 0.19978228211402893
Validation loss: 1.7553014755249023

Epoch: 5| Step: 4
Training loss: 0.3047683835029602
Validation loss: 1.756585846665085

Epoch: 5| Step: 5
Training loss: 0.2022312879562378
Validation loss: 1.7836182719917708

Epoch: 5| Step: 6
Training loss: 0.35916441679000854
Validation loss: 1.7960427499586535

Epoch: 5| Step: 7
Training loss: 0.28109243512153625
Validation loss: 1.8121794205839916

Epoch: 5| Step: 8
Training loss: 0.32458701729774475
Validation loss: 1.7743487742639357

Epoch: 5| Step: 9
Training loss: 0.21261124312877655
Validation loss: 1.7948823974978538

Epoch: 5| Step: 10
Training loss: 0.22900186479091644
Validation loss: 1.8339108549138552

Epoch: 340| Step: 0
Training loss: 0.2277638018131256
Validation loss: 1.8472471134636992

Epoch: 5| Step: 1
Training loss: 0.26300936937332153
Validation loss: 1.873745205581829

Epoch: 5| Step: 2
Training loss: 0.2516184151172638
Validation loss: 1.8324156166404806

Epoch: 5| Step: 3
Training loss: 0.257345587015152
Validation loss: 1.8363565027072866

Epoch: 5| Step: 4
Training loss: 0.24361839890480042
Validation loss: 1.8153384795752905

Epoch: 5| Step: 5
Training loss: 0.18964365124702454
Validation loss: 1.8001618308405722

Epoch: 5| Step: 6
Training loss: 0.14674796164035797
Validation loss: 1.7893940684615925

Epoch: 5| Step: 7
Training loss: 0.24237242341041565
Validation loss: 1.7940490668819797

Epoch: 5| Step: 8
Training loss: 0.2264864444732666
Validation loss: 1.8051241546548822

Epoch: 5| Step: 9
Training loss: 0.2378244400024414
Validation loss: 1.7831112595014675

Epoch: 5| Step: 10
Training loss: 0.5264145135879517
Validation loss: 1.792220692480764

Epoch: 341| Step: 0
Training loss: 0.30843645334243774
Validation loss: 1.8088610890091106

Epoch: 5| Step: 1
Training loss: 0.30583715438842773
Validation loss: 1.8153490404928885

Epoch: 5| Step: 2
Training loss: 0.24625280499458313
Validation loss: 1.8067409325671453

Epoch: 5| Step: 3
Training loss: 0.26300397515296936
Validation loss: 1.8384562051424416

Epoch: 5| Step: 4
Training loss: 0.3201194405555725
Validation loss: 1.8690786438603555

Epoch: 5| Step: 5
Training loss: 0.11460544914007187
Validation loss: 1.8438261875542261

Epoch: 5| Step: 6
Training loss: 0.1540514975786209
Validation loss: 1.8393348468247281

Epoch: 5| Step: 7
Training loss: 0.23041734099388123
Validation loss: 1.8199562193245016

Epoch: 5| Step: 8
Training loss: 0.29295963048934937
Validation loss: 1.8346639679324241

Epoch: 5| Step: 9
Training loss: 0.15008501708507538
Validation loss: 1.8453788206141482

Epoch: 5| Step: 10
Training loss: 0.15600639581680298
Validation loss: 1.826511880402924

Epoch: 342| Step: 0
Training loss: 0.2524290084838867
Validation loss: 1.7997339861367339

Epoch: 5| Step: 1
Training loss: 0.19353730976581573
Validation loss: 1.7959171802766862

Epoch: 5| Step: 2
Training loss: 0.1240951269865036
Validation loss: 1.8080716210026895

Epoch: 5| Step: 3
Training loss: 0.2198266088962555
Validation loss: 1.7622894189691032

Epoch: 5| Step: 4
Training loss: 0.234554722905159
Validation loss: 1.7735069926067064

Epoch: 5| Step: 5
Training loss: 0.19734904170036316
Validation loss: 1.783431545380623

Epoch: 5| Step: 6
Training loss: 0.41317567229270935
Validation loss: 1.7603528807240147

Epoch: 5| Step: 7
Training loss: 0.11725212633609772
Validation loss: 1.7776462621586298

Epoch: 5| Step: 8
Training loss: 0.18388119339942932
Validation loss: 1.7941351693163636

Epoch: 5| Step: 9
Training loss: 0.15651774406433105
Validation loss: 1.7924197155942199

Epoch: 5| Step: 10
Training loss: 0.20239479839801788
Validation loss: 1.7924474798223025

Epoch: 343| Step: 0
Training loss: 0.24538786709308624
Validation loss: 1.7486567766435686

Epoch: 5| Step: 1
Training loss: 0.15357288718223572
Validation loss: 1.792596273524787

Epoch: 5| Step: 2
Training loss: 0.3320642113685608
Validation loss: 1.8008883050692979

Epoch: 5| Step: 3
Training loss: 0.4169873595237732
Validation loss: 1.7889220086477136

Epoch: 5| Step: 4
Training loss: 0.16715219616889954
Validation loss: 1.7922588753443893

Epoch: 5| Step: 5
Training loss: 0.1469896286725998
Validation loss: 1.8382495218707668

Epoch: 5| Step: 6
Training loss: 0.2395033836364746
Validation loss: 1.8106954225929834

Epoch: 5| Step: 7
Training loss: 0.12642589211463928
Validation loss: 1.8126440996764808

Epoch: 5| Step: 8
Training loss: 0.23635713756084442
Validation loss: 1.8179911772410076

Epoch: 5| Step: 9
Training loss: 0.11452863365411758
Validation loss: 1.8031757467536516

Epoch: 5| Step: 10
Training loss: 0.28817614912986755
Validation loss: 1.7901765890018915

Epoch: 344| Step: 0
Training loss: 0.37337514758110046
Validation loss: 1.8029010526595577

Epoch: 5| Step: 1
Training loss: 0.08556745201349258
Validation loss: 1.793897577511367

Epoch: 5| Step: 2
Training loss: 0.23503927886486053
Validation loss: 1.8011305832093762

Epoch: 5| Step: 3
Training loss: 0.2046918421983719
Validation loss: 1.80721620334092

Epoch: 5| Step: 4
Training loss: 0.19056972861289978
Validation loss: 1.8005490456857989

Epoch: 5| Step: 5
Training loss: 0.28367358446121216
Validation loss: 1.7970754459340086

Epoch: 5| Step: 6
Training loss: 0.3098185956478119
Validation loss: 1.8358133826204526

Epoch: 5| Step: 7
Training loss: 0.1034388542175293
Validation loss: 1.8125330055913618

Epoch: 5| Step: 8
Training loss: 0.23153991997241974
Validation loss: 1.8383260952529086

Epoch: 5| Step: 9
Training loss: 0.19540245831012726
Validation loss: 1.8325774785011046

Epoch: 5| Step: 10
Training loss: 0.30018380284309387
Validation loss: 1.8350738338244859

Epoch: 345| Step: 0
Training loss: 0.22474607825279236
Validation loss: 1.8200088418940061

Epoch: 5| Step: 1
Training loss: 0.24424004554748535
Validation loss: 1.825110931550303

Epoch: 5| Step: 2
Training loss: 0.18551014363765717
Validation loss: 1.818639934703868

Epoch: 5| Step: 3
Training loss: 0.17749185860157013
Validation loss: 1.7713701981370167

Epoch: 5| Step: 4
Training loss: 0.19906151294708252
Validation loss: 1.7847300261579535

Epoch: 5| Step: 5
Training loss: 0.3848232626914978
Validation loss: 1.8069336491246377

Epoch: 5| Step: 6
Training loss: 0.17638054490089417
Validation loss: 1.7837284918754333

Epoch: 5| Step: 7
Training loss: 0.33265605568885803
Validation loss: 1.7645863435601676

Epoch: 5| Step: 8
Training loss: 0.18643362820148468
Validation loss: 1.7737750007260231

Epoch: 5| Step: 9
Training loss: 0.2206467092037201
Validation loss: 1.7963126244083527

Epoch: 5| Step: 10
Training loss: 0.16002756357192993
Validation loss: 1.792541116796514

Epoch: 346| Step: 0
Training loss: 0.26395779848098755
Validation loss: 1.821125630409487

Epoch: 5| Step: 1
Training loss: 0.4158632159233093
Validation loss: 1.8566660714405838

Epoch: 5| Step: 2
Training loss: 0.20641624927520752
Validation loss: 1.8395267455808577

Epoch: 5| Step: 3
Training loss: 0.14857123792171478
Validation loss: 1.8611153479545348

Epoch: 5| Step: 4
Training loss: 0.2275383025407791
Validation loss: 1.849327697548815

Epoch: 5| Step: 5
Training loss: 0.18466031551361084
Validation loss: 1.8511770463758899

Epoch: 5| Step: 6
Training loss: 0.17529012262821198
Validation loss: 1.8442476513565227

Epoch: 5| Step: 7
Training loss: 0.2923958897590637
Validation loss: 1.7983962387166998

Epoch: 5| Step: 8
Training loss: 0.1866151988506317
Validation loss: 1.7770789259223527

Epoch: 5| Step: 9
Training loss: 0.09975150227546692
Validation loss: 1.772772995374536

Epoch: 5| Step: 10
Training loss: 0.16522617638111115
Validation loss: 1.766264937257254

Epoch: 347| Step: 0
Training loss: 0.2475743293762207
Validation loss: 1.7303506456395632

Epoch: 5| Step: 1
Training loss: 0.21769115328788757
Validation loss: 1.7604982801662978

Epoch: 5| Step: 2
Training loss: 0.11830788850784302
Validation loss: 1.7680621634247482

Epoch: 5| Step: 3
Training loss: 0.2456652820110321
Validation loss: 1.740008834869631

Epoch: 5| Step: 4
Training loss: 0.15064513683319092
Validation loss: 1.7828490016280965

Epoch: 5| Step: 5
Training loss: 0.18062366545200348
Validation loss: 1.7979701090884466

Epoch: 5| Step: 6
Training loss: 0.2598850131034851
Validation loss: 1.853671666114561

Epoch: 5| Step: 7
Training loss: 0.22571082413196564
Validation loss: 1.8155227630369124

Epoch: 5| Step: 8
Training loss: 0.16389933228492737
Validation loss: 1.815653924019106

Epoch: 5| Step: 9
Training loss: 0.15988942980766296
Validation loss: 1.8136998043265393

Epoch: 5| Step: 10
Training loss: 0.32522886991500854
Validation loss: 1.8178373459846742

Epoch: 348| Step: 0
Training loss: 0.18031564354896545
Validation loss: 1.8055447532284645

Epoch: 5| Step: 1
Training loss: 0.29046064615249634
Validation loss: 1.7865704400565035

Epoch: 5| Step: 2
Training loss: 0.31101173162460327
Validation loss: 1.771080091435422

Epoch: 5| Step: 3
Training loss: 0.22120937705039978
Validation loss: 1.766192005526635

Epoch: 5| Step: 4
Training loss: 0.20328083634376526
Validation loss: 1.7778422358215495

Epoch: 5| Step: 5
Training loss: 0.15459904074668884
Validation loss: 1.787360647673248

Epoch: 5| Step: 6
Training loss: 0.40794309973716736
Validation loss: 1.7715891984201246

Epoch: 5| Step: 7
Training loss: 0.11547990143299103
Validation loss: 1.796966866780353

Epoch: 5| Step: 8
Training loss: 0.20178866386413574
Validation loss: 1.8463285905058666

Epoch: 5| Step: 9
Training loss: 0.2659958004951477
Validation loss: 1.8274955416238436

Epoch: 5| Step: 10
Training loss: 0.20769762992858887
Validation loss: 1.834035845213039

Epoch: 349| Step: 0
Training loss: 0.17880699038505554
Validation loss: 1.8518391373336955

Epoch: 5| Step: 1
Training loss: 0.4207639694213867
Validation loss: 1.8885075392261628

Epoch: 5| Step: 2
Training loss: 0.2661305069923401
Validation loss: 1.857141681896743

Epoch: 5| Step: 3
Training loss: 0.19625483453273773
Validation loss: 1.8289565091492028

Epoch: 5| Step: 4
Training loss: 0.1340094655752182
Validation loss: 1.7971200045718942

Epoch: 5| Step: 5
Training loss: 0.20739412307739258
Validation loss: 1.782065672259177

Epoch: 5| Step: 6
Training loss: 0.14034271240234375
Validation loss: 1.7644030432547293

Epoch: 5| Step: 7
Training loss: 0.282127320766449
Validation loss: 1.7638576364004483

Epoch: 5| Step: 8
Training loss: 0.1933409869670868
Validation loss: 1.77347828367705

Epoch: 5| Step: 9
Training loss: 0.18086858093738556
Validation loss: 1.7608211463497532

Epoch: 5| Step: 10
Training loss: 0.1981930136680603
Validation loss: 1.7794997256289247

Epoch: 350| Step: 0
Training loss: 0.11083328723907471
Validation loss: 1.7729428134938723

Epoch: 5| Step: 1
Training loss: 0.1848566234111786
Validation loss: 1.791456691680416

Epoch: 5| Step: 2
Training loss: 0.3582022786140442
Validation loss: 1.7645934704811341

Epoch: 5| Step: 3
Training loss: 0.2653079628944397
Validation loss: 1.7924712486164545

Epoch: 5| Step: 4
Training loss: 0.19144614040851593
Validation loss: 1.7870101223709762

Epoch: 5| Step: 5
Training loss: 0.25198444724082947
Validation loss: 1.7979024789666618

Epoch: 5| Step: 6
Training loss: 0.18513917922973633
Validation loss: 1.7722763963924941

Epoch: 5| Step: 7
Training loss: 0.17996230721473694
Validation loss: 1.7862697237281389

Epoch: 5| Step: 8
Training loss: 0.20912852883338928
Validation loss: 1.7829377907578663

Epoch: 5| Step: 9
Training loss: 0.2611590027809143
Validation loss: 1.7651996407457577

Epoch: 5| Step: 10
Training loss: 0.15070295333862305
Validation loss: 1.7971532755000617

Epoch: 351| Step: 0
Training loss: 0.28310102224349976
Validation loss: 1.7828984773287209

Epoch: 5| Step: 1
Training loss: 0.24150189757347107
Validation loss: 1.7612603095269972

Epoch: 5| Step: 2
Training loss: 0.10382501035928726
Validation loss: 1.7436450117377824

Epoch: 5| Step: 3
Training loss: 0.19135966897010803
Validation loss: 1.743881453749954

Epoch: 5| Step: 4
Training loss: 0.23201517760753632
Validation loss: 1.7452305209252141

Epoch: 5| Step: 5
Training loss: 0.20196738839149475
Validation loss: 1.7509895396488968

Epoch: 5| Step: 6
Training loss: 0.17800097167491913
Validation loss: 1.7417759074959704

Epoch: 5| Step: 7
Training loss: 0.23949146270751953
Validation loss: 1.7537380033923733

Epoch: 5| Step: 8
Training loss: 0.2071276158094406
Validation loss: 1.7677157527656966

Epoch: 5| Step: 9
Training loss: 0.21128292381763458
Validation loss: 1.786530645944739

Epoch: 5| Step: 10
Training loss: 0.1620105504989624
Validation loss: 1.7902349400263962

Epoch: 352| Step: 0
Training loss: 0.33280402421951294
Validation loss: 1.8221300161013039

Epoch: 5| Step: 1
Training loss: 0.27147597074508667
Validation loss: 1.7955893944668513

Epoch: 5| Step: 2
Training loss: 0.11906756460666656
Validation loss: 1.8225198407326975

Epoch: 5| Step: 3
Training loss: 0.22227783501148224
Validation loss: 1.798146217100082

Epoch: 5| Step: 4
Training loss: 0.18810434639453888
Validation loss: 1.8280791877418436

Epoch: 5| Step: 5
Training loss: 0.16554784774780273
Validation loss: 1.8175139209275604

Epoch: 5| Step: 6
Training loss: 0.3581067621707916
Validation loss: 1.8309680210646762

Epoch: 5| Step: 7
Training loss: 0.23916658759117126
Validation loss: 1.8172199469740673

Epoch: 5| Step: 8
Training loss: 0.19259309768676758
Validation loss: 1.7865668483959731

Epoch: 5| Step: 9
Training loss: 0.22775574028491974
Validation loss: 1.7751172793808805

Epoch: 5| Step: 10
Training loss: 0.12086588144302368
Validation loss: 1.787838420560283

Epoch: 353| Step: 0
Training loss: 0.4124837815761566
Validation loss: 1.753643681926112

Epoch: 5| Step: 1
Training loss: 0.21630744636058807
Validation loss: 1.7292181355978853

Epoch: 5| Step: 2
Training loss: 0.12067577987909317
Validation loss: 1.765148728124557

Epoch: 5| Step: 3
Training loss: 0.2077585756778717
Validation loss: 1.747251456783664

Epoch: 5| Step: 4
Training loss: 0.2617693245410919
Validation loss: 1.7899284798611876

Epoch: 5| Step: 5
Training loss: 0.24770836532115936
Validation loss: 1.7656757126572311

Epoch: 5| Step: 6
Training loss: 0.2298005074262619
Validation loss: 1.7479019421403126

Epoch: 5| Step: 7
Training loss: 0.145775705575943
Validation loss: 1.7347048764587731

Epoch: 5| Step: 8
Training loss: 0.14778617024421692
Validation loss: 1.7683664842318463

Epoch: 5| Step: 9
Training loss: 0.23172101378440857
Validation loss: 1.7842923210513206

Epoch: 5| Step: 10
Training loss: 0.3474365770816803
Validation loss: 1.8166760783041678

Epoch: 354| Step: 0
Training loss: 0.235072061419487
Validation loss: 1.8370508058096773

Epoch: 5| Step: 1
Training loss: 0.36929449439048767
Validation loss: 1.8192619175039313

Epoch: 5| Step: 2
Training loss: 0.2315421998500824
Validation loss: 1.8595922223983272

Epoch: 5| Step: 3
Training loss: 0.2424386441707611
Validation loss: 1.8133690523844894

Epoch: 5| Step: 4
Training loss: 0.1939864456653595
Validation loss: 1.8148859188120852

Epoch: 5| Step: 5
Training loss: 0.19909615814685822
Validation loss: 1.7997092405954997

Epoch: 5| Step: 6
Training loss: 0.10855845361948013
Validation loss: 1.8349139331489481

Epoch: 5| Step: 7
Training loss: 0.22302567958831787
Validation loss: 1.8374230771936395

Epoch: 5| Step: 8
Training loss: 0.18123862147331238
Validation loss: 1.7898787272873746

Epoch: 5| Step: 9
Training loss: 0.2412663698196411
Validation loss: 1.8018823092983616

Epoch: 5| Step: 10
Training loss: 0.18098734319210052
Validation loss: 1.7597832833566973

Epoch: 355| Step: 0
Training loss: 0.18453319370746613
Validation loss: 1.7703366535966114

Epoch: 5| Step: 1
Training loss: 0.2664700150489807
Validation loss: 1.7125710172037925

Epoch: 5| Step: 2
Training loss: 0.28080081939697266
Validation loss: 1.7392639139647126

Epoch: 5| Step: 3
Training loss: 0.262967973947525
Validation loss: 1.7694186087577575

Epoch: 5| Step: 4
Training loss: 0.2895514965057373
Validation loss: 1.7670671247666883

Epoch: 5| Step: 5
Training loss: 0.13409166038036346
Validation loss: 1.7741420563831125

Epoch: 5| Step: 6
Training loss: 0.15064482390880585
Validation loss: 1.7832264028569704

Epoch: 5| Step: 7
Training loss: 0.3173002600669861
Validation loss: 1.7931533334075764

Epoch: 5| Step: 8
Training loss: 0.19455523788928986
Validation loss: 1.7937635337152789

Epoch: 5| Step: 9
Training loss: 0.18298278748989105
Validation loss: 1.8072641408571632

Epoch: 5| Step: 10
Training loss: 0.18634414672851562
Validation loss: 1.801196131654965

Epoch: 356| Step: 0
Training loss: 0.15995077788829803
Validation loss: 1.7766826396347375

Epoch: 5| Step: 1
Training loss: 0.13691160082817078
Validation loss: 1.798893053044555

Epoch: 5| Step: 2
Training loss: 0.3461812138557434
Validation loss: 1.8101244216324182

Epoch: 5| Step: 3
Training loss: 0.2578114867210388
Validation loss: 1.7639590155693792

Epoch: 5| Step: 4
Training loss: 0.18365970253944397
Validation loss: 1.7667465312506563

Epoch: 5| Step: 5
Training loss: 0.1580197513103485
Validation loss: 1.776842260873446

Epoch: 5| Step: 6
Training loss: 0.2828918993473053
Validation loss: 1.7754221808525823

Epoch: 5| Step: 7
Training loss: 0.2782643437385559
Validation loss: 1.75511795731001

Epoch: 5| Step: 8
Training loss: 0.2176496982574463
Validation loss: 1.7716440846843104

Epoch: 5| Step: 9
Training loss: 0.19354693591594696
Validation loss: 1.7510147299817813

Epoch: 5| Step: 10
Training loss: 0.12251218408346176
Validation loss: 1.7266769870635001

Epoch: 357| Step: 0
Training loss: 0.3200477957725525
Validation loss: 1.751490128937588

Epoch: 5| Step: 1
Training loss: 0.1962849199771881
Validation loss: 1.7418455641756776

Epoch: 5| Step: 2
Training loss: 0.1898205578327179
Validation loss: 1.7415201176879227

Epoch: 5| Step: 3
Training loss: 0.2771258056163788
Validation loss: 1.7286618614709506

Epoch: 5| Step: 4
Training loss: 0.11321304738521576
Validation loss: 1.7351908914504512

Epoch: 5| Step: 5
Training loss: 0.13303738832473755
Validation loss: 1.7431286727228472

Epoch: 5| Step: 6
Training loss: 0.2111392468214035
Validation loss: 1.7181868732616465

Epoch: 5| Step: 7
Training loss: 0.2643110752105713
Validation loss: 1.7466898951479184

Epoch: 5| Step: 8
Training loss: 0.2984023094177246
Validation loss: 1.753383295510405

Epoch: 5| Step: 9
Training loss: 0.15295466780662537
Validation loss: 1.7428100198827765

Epoch: 5| Step: 10
Training loss: 0.11655023694038391
Validation loss: 1.7302129922374603

Epoch: 358| Step: 0
Training loss: 0.14207462966442108
Validation loss: 1.7651534016414354

Epoch: 5| Step: 1
Training loss: 0.24913375079631805
Validation loss: 1.7728694215897591

Epoch: 5| Step: 2
Training loss: 0.21532674133777618
Validation loss: 1.761499894562588

Epoch: 5| Step: 3
Training loss: 0.26141437888145447
Validation loss: 1.77439752317244

Epoch: 5| Step: 4
Training loss: 0.19922666251659393
Validation loss: 1.769678545254533

Epoch: 5| Step: 5
Training loss: 0.2975880205631256
Validation loss: 1.7764046768988333

Epoch: 5| Step: 6
Training loss: 0.22937417030334473
Validation loss: 1.7950139712261897

Epoch: 5| Step: 7
Training loss: 0.14411623775959015
Validation loss: 1.7740016150218185

Epoch: 5| Step: 8
Training loss: 0.22399196028709412
Validation loss: 1.792333895801216

Epoch: 5| Step: 9
Training loss: 0.13716155290603638
Validation loss: 1.7616430444102134

Epoch: 5| Step: 10
Training loss: 0.17375142872333527
Validation loss: 1.7666302419477893

Epoch: 359| Step: 0
Training loss: 0.2214382141828537
Validation loss: 1.7782051640172158

Epoch: 5| Step: 1
Training loss: 0.2837428152561188
Validation loss: 1.7449330386295114

Epoch: 5| Step: 2
Training loss: 0.1368614137172699
Validation loss: 1.7415585184610018

Epoch: 5| Step: 3
Training loss: 0.2331928312778473
Validation loss: 1.7559274755498415

Epoch: 5| Step: 4
Training loss: 0.16210095584392548
Validation loss: 1.7655015107124084

Epoch: 5| Step: 5
Training loss: 0.24363136291503906
Validation loss: 1.737319323324388

Epoch: 5| Step: 6
Training loss: 0.23558907210826874
Validation loss: 1.7206892326313963

Epoch: 5| Step: 7
Training loss: 0.10008218139410019
Validation loss: 1.7554088254128732

Epoch: 5| Step: 8
Training loss: 0.14889439940452576
Validation loss: 1.7562983112950479

Epoch: 5| Step: 9
Training loss: 0.34354811906814575
Validation loss: 1.79873324337826

Epoch: 5| Step: 10
Training loss: 0.20092229545116425
Validation loss: 1.791690621965675

Epoch: 360| Step: 0
Training loss: 0.17502287030220032
Validation loss: 1.8046601036543488

Epoch: 5| Step: 1
Training loss: 0.15122640132904053
Validation loss: 1.797452058843387

Epoch: 5| Step: 2
Training loss: 0.216681569814682
Validation loss: 1.8415555877070273

Epoch: 5| Step: 3
Training loss: 0.25460004806518555
Validation loss: 1.860433465691023

Epoch: 5| Step: 4
Training loss: 0.27189648151397705
Validation loss: 1.8075460580087477

Epoch: 5| Step: 5
Training loss: 0.17329856753349304
Validation loss: 1.7874607552764237

Epoch: 5| Step: 6
Training loss: 0.17401404678821564
Validation loss: 1.831568366737776

Epoch: 5| Step: 7
Training loss: 0.19246523082256317
Validation loss: 1.8077044204999042

Epoch: 5| Step: 8
Training loss: 0.29449403285980225
Validation loss: 1.8020849356087305

Epoch: 5| Step: 9
Training loss: 0.43690410256385803
Validation loss: 1.8009808730053645

Epoch: 5| Step: 10
Training loss: 0.1745530366897583
Validation loss: 1.7733362118403118

Epoch: 361| Step: 0
Training loss: 0.2907511293888092
Validation loss: 1.7536244520577051

Epoch: 5| Step: 1
Training loss: 0.13824501633644104
Validation loss: 1.7591912784884054

Epoch: 5| Step: 2
Training loss: 0.32031920552253723
Validation loss: 1.7769446039712558

Epoch: 5| Step: 3
Training loss: 0.23676708340644836
Validation loss: 1.7604595448381157

Epoch: 5| Step: 4
Training loss: 0.33028000593185425
Validation loss: 1.7426592367951588

Epoch: 5| Step: 5
Training loss: 0.24465210735797882
Validation loss: 1.768787134078241

Epoch: 5| Step: 6
Training loss: 0.2565811276435852
Validation loss: 1.7853662454953758

Epoch: 5| Step: 7
Training loss: 0.18131712079048157
Validation loss: 1.7641976982034662

Epoch: 5| Step: 8
Training loss: 0.15690560638904572
Validation loss: 1.7489777226601877

Epoch: 5| Step: 9
Training loss: 0.19742779433727264
Validation loss: 1.740396616279438

Epoch: 5| Step: 10
Training loss: 0.11636607348918915
Validation loss: 1.7347419902842531

Epoch: 362| Step: 0
Training loss: 0.25286656618118286
Validation loss: 1.7825743062521822

Epoch: 5| Step: 1
Training loss: 0.23513250052928925
Validation loss: 1.8272193388272358

Epoch: 5| Step: 2
Training loss: 0.3059048354625702
Validation loss: 1.825155391488024

Epoch: 5| Step: 3
Training loss: 0.14978668093681335
Validation loss: 1.7878714133334417

Epoch: 5| Step: 4
Training loss: 0.29285335540771484
Validation loss: 1.7876349841394732

Epoch: 5| Step: 5
Training loss: 0.1859663724899292
Validation loss: 1.7603727297116352

Epoch: 5| Step: 6
Training loss: 0.2566496431827545
Validation loss: 1.7685184888942267

Epoch: 5| Step: 7
Training loss: 0.1861482858657837
Validation loss: 1.7529034024925643

Epoch: 5| Step: 8
Training loss: 0.20804491639137268
Validation loss: 1.7502491884334113

Epoch: 5| Step: 9
Training loss: 0.2776380479335785
Validation loss: 1.7309139966964722

Epoch: 5| Step: 10
Training loss: 0.19919906556606293
Validation loss: 1.7172073484748922

Epoch: 363| Step: 0
Training loss: 0.2023470401763916
Validation loss: 1.7249342395413307

Epoch: 5| Step: 1
Training loss: 0.3761325180530548
Validation loss: 1.725526007272864

Epoch: 5| Step: 2
Training loss: 0.1376049518585205
Validation loss: 1.7101997393433765

Epoch: 5| Step: 3
Training loss: 0.1515621840953827
Validation loss: 1.739877067586427

Epoch: 5| Step: 4
Training loss: 0.21028749644756317
Validation loss: 1.749491112206572

Epoch: 5| Step: 5
Training loss: 0.2450021505355835
Validation loss: 1.7454300663804496

Epoch: 5| Step: 6
Training loss: 0.17660179734230042
Validation loss: 1.7504594992565852

Epoch: 5| Step: 7
Training loss: 0.15835213661193848
Validation loss: 1.7310392702779462

Epoch: 5| Step: 8
Training loss: 0.20090869069099426
Validation loss: 1.7494592948626446

Epoch: 5| Step: 9
Training loss: 0.1778942048549652
Validation loss: 1.7429594186044508

Epoch: 5| Step: 10
Training loss: 0.17824414372444153
Validation loss: 1.7525512191557115

Epoch: 364| Step: 0
Training loss: 0.11783169209957123
Validation loss: 1.7636973691242996

Epoch: 5| Step: 1
Training loss: 0.08144207298755646
Validation loss: 1.75950256470711

Epoch: 5| Step: 2
Training loss: 0.29419511556625366
Validation loss: 1.7585543650452808

Epoch: 5| Step: 3
Training loss: 0.157754585146904
Validation loss: 1.7873979358262913

Epoch: 5| Step: 4
Training loss: 0.20711302757263184
Validation loss: 1.7739940689456077

Epoch: 5| Step: 5
Training loss: 0.32046738266944885
Validation loss: 1.7811318494940316

Epoch: 5| Step: 6
Training loss: 0.11380495876073837
Validation loss: 1.7554312585502543

Epoch: 5| Step: 7
Training loss: 0.21210122108459473
Validation loss: 1.770574499202031

Epoch: 5| Step: 8
Training loss: 0.16796061396598816
Validation loss: 1.7371668661794355

Epoch: 5| Step: 9
Training loss: 0.18935957551002502
Validation loss: 1.7457638427775393

Epoch: 5| Step: 10
Training loss: 0.15439775586128235
Validation loss: 1.7537881674305085

Epoch: 365| Step: 0
Training loss: 0.13669846951961517
Validation loss: 1.7413509866242767

Epoch: 5| Step: 1
Training loss: 0.2092798948287964
Validation loss: 1.7571670342517156

Epoch: 5| Step: 2
Training loss: 0.18839682638645172
Validation loss: 1.7240194710352088

Epoch: 5| Step: 3
Training loss: 0.15925216674804688
Validation loss: 1.7211783791101107

Epoch: 5| Step: 4
Training loss: 0.2185612916946411
Validation loss: 1.7289186690443306

Epoch: 5| Step: 5
Training loss: 0.2480788677930832
Validation loss: 1.725140397266675

Epoch: 5| Step: 6
Training loss: 0.12204070389270782
Validation loss: 1.7088191073427919

Epoch: 5| Step: 7
Training loss: 0.16826221346855164
Validation loss: 1.7482193875056442

Epoch: 5| Step: 8
Training loss: 0.3250388503074646
Validation loss: 1.7325837945425382

Epoch: 5| Step: 9
Training loss: 0.16961261630058289
Validation loss: 1.720702168762043

Epoch: 5| Step: 10
Training loss: 0.16706670820713043
Validation loss: 1.7573274976463729

Epoch: 366| Step: 0
Training loss: 0.1764432191848755
Validation loss: 1.7584859068675707

Epoch: 5| Step: 1
Training loss: 0.1989312320947647
Validation loss: 1.7647506985613095

Epoch: 5| Step: 2
Training loss: 0.3054313361644745
Validation loss: 1.751472339835218

Epoch: 5| Step: 3
Training loss: 0.143450528383255
Validation loss: 1.7442999168108868

Epoch: 5| Step: 4
Training loss: 0.2024880200624466
Validation loss: 1.745402733484904

Epoch: 5| Step: 5
Training loss: 0.24246427416801453
Validation loss: 1.7648911437680643

Epoch: 5| Step: 6
Training loss: 0.10700907558202744
Validation loss: 1.7775332261157293

Epoch: 5| Step: 7
Training loss: 0.19420933723449707
Validation loss: 1.798330113451968

Epoch: 5| Step: 8
Training loss: 0.3123374581336975
Validation loss: 1.795826321007103

Epoch: 5| Step: 9
Training loss: 0.2510968744754791
Validation loss: 1.8041563303239885

Epoch: 5| Step: 10
Training loss: 0.1945272982120514
Validation loss: 1.7860206057948451

Epoch: 367| Step: 0
Training loss: 0.17306503653526306
Validation loss: 1.7845701235596851

Epoch: 5| Step: 1
Training loss: 0.3519662320613861
Validation loss: 1.7876410856041858

Epoch: 5| Step: 2
Training loss: 0.24657312035560608
Validation loss: 1.798758165810698

Epoch: 5| Step: 3
Training loss: 0.19373326003551483
Validation loss: 1.7932186600982503

Epoch: 5| Step: 4
Training loss: 0.2861810624599457
Validation loss: 1.770116295865787

Epoch: 5| Step: 5
Training loss: 0.4028088450431824
Validation loss: 1.7938616173241728

Epoch: 5| Step: 6
Training loss: 0.28075432777404785
Validation loss: 1.7535138412188458

Epoch: 5| Step: 7
Training loss: 0.34626612067222595
Validation loss: 1.744027599211662

Epoch: 5| Step: 8
Training loss: 0.24637499451637268
Validation loss: 1.7533285387100712

Epoch: 5| Step: 9
Training loss: 0.14769646525382996
Validation loss: 1.7402763674336095

Epoch: 5| Step: 10
Training loss: 0.12639425694942474
Validation loss: 1.7373451302128453

Epoch: 368| Step: 0
Training loss: 0.253091424703598
Validation loss: 1.7711550586967058

Epoch: 5| Step: 1
Training loss: 0.4230031371116638
Validation loss: 1.7846446780748264

Epoch: 5| Step: 2
Training loss: 0.1505453735589981
Validation loss: 1.7806809589427004

Epoch: 5| Step: 3
Training loss: 0.25191134214401245
Validation loss: 1.7783459694154802

Epoch: 5| Step: 4
Training loss: 0.25511154532432556
Validation loss: 1.7615798801504157

Epoch: 5| Step: 5
Training loss: 0.20331665873527527
Validation loss: 1.7458962471254411

Epoch: 5| Step: 6
Training loss: 0.11399537324905396
Validation loss: 1.7140761639482232

Epoch: 5| Step: 7
Training loss: 0.23910458385944366
Validation loss: 1.7556150062109834

Epoch: 5| Step: 8
Training loss: 0.13095691800117493
Validation loss: 1.7124453885580904

Epoch: 5| Step: 9
Training loss: 0.32284337282180786
Validation loss: 1.7299319121145433

Epoch: 5| Step: 10
Training loss: 0.2367095649242401
Validation loss: 1.7294463752418436

Epoch: 369| Step: 0
Training loss: 0.20922818779945374
Validation loss: 1.7028264012388004

Epoch: 5| Step: 1
Training loss: 0.20678286254405975
Validation loss: 1.7041667751086655

Epoch: 5| Step: 2
Training loss: 0.16212964057922363
Validation loss: 1.6952120142598306

Epoch: 5| Step: 3
Training loss: 0.28527989983558655
Validation loss: 1.7144761085510254

Epoch: 5| Step: 4
Training loss: 0.19932493567466736
Validation loss: 1.6720412085133214

Epoch: 5| Step: 5
Training loss: 0.1355568915605545
Validation loss: 1.6640182079807404

Epoch: 5| Step: 6
Training loss: 0.16208124160766602
Validation loss: 1.675921114542151

Epoch: 5| Step: 7
Training loss: 0.310014933347702
Validation loss: 1.6909518652064826

Epoch: 5| Step: 8
Training loss: 0.0977620854973793
Validation loss: 1.6526243404675556

Epoch: 5| Step: 9
Training loss: 0.1469670534133911
Validation loss: 1.6427233526783604

Epoch: 5| Step: 10
Training loss: 0.1601570099592209
Validation loss: 1.6544615261016353

Epoch: 370| Step: 0
Training loss: 0.26507753133773804
Validation loss: 1.6573117509964974

Epoch: 5| Step: 1
Training loss: 0.17735514044761658
Validation loss: 1.6673655381766699

Epoch: 5| Step: 2
Training loss: 0.11744171380996704
Validation loss: 1.6698686281840007

Epoch: 5| Step: 3
Training loss: 0.19580692052841187
Validation loss: 1.642997887826735

Epoch: 5| Step: 4
Training loss: 0.1623205691576004
Validation loss: 1.6935815118974256

Epoch: 5| Step: 5
Training loss: 0.11542986333370209
Validation loss: 1.6798596241140877

Epoch: 5| Step: 6
Training loss: 0.14586897194385529
Validation loss: 1.6976621625243977

Epoch: 5| Step: 7
Training loss: 0.17192383110523224
Validation loss: 1.6730405874149774

Epoch: 5| Step: 8
Training loss: 0.1413615494966507
Validation loss: 1.6824059717116817

Epoch: 5| Step: 9
Training loss: 0.3678796887397766
Validation loss: 1.6925809626938195

Epoch: 5| Step: 10
Training loss: 0.18345218896865845
Validation loss: 1.6518194547263525

Epoch: 371| Step: 0
Training loss: 0.11292459815740585
Validation loss: 1.6602073241305608

Epoch: 5| Step: 1
Training loss: 0.17330431938171387
Validation loss: 1.6347918536073418

Epoch: 5| Step: 2
Training loss: 0.17231085896492004
Validation loss: 1.6724178265499812

Epoch: 5| Step: 3
Training loss: 0.31542059779167175
Validation loss: 1.685891673129092

Epoch: 5| Step: 4
Training loss: 0.14803721010684967
Validation loss: 1.6839219088195472

Epoch: 5| Step: 5
Training loss: 0.17675577104091644
Validation loss: 1.6994882206762991

Epoch: 5| Step: 6
Training loss: 0.1365528106689453
Validation loss: 1.6943189123625397

Epoch: 5| Step: 7
Training loss: 0.2256530225276947
Validation loss: 1.7142035922696512

Epoch: 5| Step: 8
Training loss: 0.2439921647310257
Validation loss: 1.7193870582888204

Epoch: 5| Step: 9
Training loss: 0.16973628103733063
Validation loss: 1.734295723258808

Epoch: 5| Step: 10
Training loss: 0.14527028799057007
Validation loss: 1.7129790424018778

Epoch: 372| Step: 0
Training loss: 0.25630196928977966
Validation loss: 1.7207294176983576

Epoch: 5| Step: 1
Training loss: 0.313982754945755
Validation loss: 1.7102011878003356

Epoch: 5| Step: 2
Training loss: 0.12067743390798569
Validation loss: 1.739028762745601

Epoch: 5| Step: 3
Training loss: 0.21941149234771729
Validation loss: 1.7434333127032045

Epoch: 5| Step: 4
Training loss: 0.1547337770462036
Validation loss: 1.7340248092528312

Epoch: 5| Step: 5
Training loss: 0.2941373586654663
Validation loss: 1.740330793524301

Epoch: 5| Step: 6
Training loss: 0.22617526352405548
Validation loss: 1.7615572278217604

Epoch: 5| Step: 7
Training loss: 0.17749424278736115
Validation loss: 1.7459215092402633

Epoch: 5| Step: 8
Training loss: 0.14829443395137787
Validation loss: 1.7464268258822861

Epoch: 5| Step: 9
Training loss: 0.19381487369537354
Validation loss: 1.7249067239863898

Epoch: 5| Step: 10
Training loss: 0.13802313804626465
Validation loss: 1.7214853853307746

Epoch: 373| Step: 0
Training loss: 0.32353585958480835
Validation loss: 1.7270412662977814

Epoch: 5| Step: 1
Training loss: 0.2358386069536209
Validation loss: 1.7232195626022995

Epoch: 5| Step: 2
Training loss: 0.2036658227443695
Validation loss: 1.6943721002148044

Epoch: 5| Step: 3
Training loss: 0.20284898579120636
Validation loss: 1.6873392879322011

Epoch: 5| Step: 4
Training loss: 0.20279577374458313
Validation loss: 1.684386275147879

Epoch: 5| Step: 5
Training loss: 0.20935341715812683
Validation loss: 1.679951197357588

Epoch: 5| Step: 6
Training loss: 0.2306649386882782
Validation loss: 1.7126622302557832

Epoch: 5| Step: 7
Training loss: 0.26706263422966003
Validation loss: 1.6741540995977258

Epoch: 5| Step: 8
Training loss: 0.1727783977985382
Validation loss: 1.6869871001089773

Epoch: 5| Step: 9
Training loss: 0.2231181114912033
Validation loss: 1.720836780404532

Epoch: 5| Step: 10
Training loss: 0.20294319093227386
Validation loss: 1.7050410380927465

Epoch: 374| Step: 0
Training loss: 0.12053026258945465
Validation loss: 1.7172731250844977

Epoch: 5| Step: 1
Training loss: 0.3292504549026489
Validation loss: 1.7380237463981874

Epoch: 5| Step: 2
Training loss: 0.2659105360507965
Validation loss: 1.7416398345783193

Epoch: 5| Step: 3
Training loss: 0.19842371344566345
Validation loss: 1.7423613250896495

Epoch: 5| Step: 4
Training loss: 0.22534456849098206
Validation loss: 1.7443627490792224

Epoch: 5| Step: 5
Training loss: 0.19507357478141785
Validation loss: 1.7200277261836554

Epoch: 5| Step: 6
Training loss: 0.17054428160190582
Validation loss: 1.7104424545841832

Epoch: 5| Step: 7
Training loss: 0.19716806709766388
Validation loss: 1.7064222353760914

Epoch: 5| Step: 8
Training loss: 0.1930743008852005
Validation loss: 1.743768822762274

Epoch: 5| Step: 9
Training loss: 0.31920570135116577
Validation loss: 1.7378247271301925

Epoch: 5| Step: 10
Training loss: 0.13805237412452698
Validation loss: 1.7251704277530793

Epoch: 375| Step: 0
Training loss: 0.17597059905529022
Validation loss: 1.7279255800349738

Epoch: 5| Step: 1
Training loss: 0.15262408554553986
Validation loss: 1.743320716324673

Epoch: 5| Step: 2
Training loss: 0.21054701507091522
Validation loss: 1.7373330644381944

Epoch: 5| Step: 3
Training loss: 0.15986721217632294
Validation loss: 1.729874227636604

Epoch: 5| Step: 4
Training loss: 0.26521745324134827
Validation loss: 1.7528958243708457

Epoch: 5| Step: 5
Training loss: 0.17719610035419464
Validation loss: 1.7457080951301

Epoch: 5| Step: 6
Training loss: 0.1952400654554367
Validation loss: 1.7127890368943572

Epoch: 5| Step: 7
Training loss: 0.18398499488830566
Validation loss: 1.7667159918815858

Epoch: 5| Step: 8
Training loss: 0.23314885795116425
Validation loss: 1.7363009952729749

Epoch: 5| Step: 9
Training loss: 0.25643086433410645
Validation loss: 1.7403399354668074

Epoch: 5| Step: 10
Training loss: 0.19862839579582214
Validation loss: 1.7455357992520897

Epoch: 376| Step: 0
Training loss: 0.18975313007831573
Validation loss: 1.7756024611893522

Epoch: 5| Step: 1
Training loss: 0.15139174461364746
Validation loss: 1.762517959840836

Epoch: 5| Step: 2
Training loss: 0.18527887761592865
Validation loss: 1.7514171997706096

Epoch: 5| Step: 3
Training loss: 0.20334935188293457
Validation loss: 1.7275217386984056

Epoch: 5| Step: 4
Training loss: 0.3374131917953491
Validation loss: 1.7384686354667909

Epoch: 5| Step: 5
Training loss: 0.18936991691589355
Validation loss: 1.7242845143041303

Epoch: 5| Step: 6
Training loss: 0.2234557867050171
Validation loss: 1.7301950775166994

Epoch: 5| Step: 7
Training loss: 0.17540612816810608
Validation loss: 1.7539085483038297

Epoch: 5| Step: 8
Training loss: 0.17327609658241272
Validation loss: 1.7399740911299182

Epoch: 5| Step: 9
Training loss: 0.17085027694702148
Validation loss: 1.7605356708649667

Epoch: 5| Step: 10
Training loss: 0.23389704525470734
Validation loss: 1.7481538531600789

Epoch: 377| Step: 0
Training loss: 0.08651456236839294
Validation loss: 1.7471553100052701

Epoch: 5| Step: 1
Training loss: 0.15307068824768066
Validation loss: 1.747370868600825

Epoch: 5| Step: 2
Training loss: 0.20876911282539368
Validation loss: 1.7189454724711757

Epoch: 5| Step: 3
Training loss: 0.13074776530265808
Validation loss: 1.7069132917670793

Epoch: 5| Step: 4
Training loss: 0.26520904898643494
Validation loss: 1.680364583128242

Epoch: 5| Step: 5
Training loss: 0.25591522455215454
Validation loss: 1.662543830051217

Epoch: 5| Step: 6
Training loss: 0.1243927851319313
Validation loss: 1.6767161418032903

Epoch: 5| Step: 7
Training loss: 0.13336288928985596
Validation loss: 1.6893116684370144

Epoch: 5| Step: 8
Training loss: 0.2088020145893097
Validation loss: 1.6708916899978474

Epoch: 5| Step: 9
Training loss: 0.2006818950176239
Validation loss: 1.7191803711716847

Epoch: 5| Step: 10
Training loss: 0.16888593137264252
Validation loss: 1.7041889544456237

Epoch: 378| Step: 0
Training loss: 0.22602780163288116
Validation loss: 1.6789509737363426

Epoch: 5| Step: 1
Training loss: 0.14153581857681274
Validation loss: 1.7045257783705188

Epoch: 5| Step: 2
Training loss: 0.18916645646095276
Validation loss: 1.6999349401843162

Epoch: 5| Step: 3
Training loss: 0.10360117256641388
Validation loss: 1.710038588893029

Epoch: 5| Step: 4
Training loss: 0.24384400248527527
Validation loss: 1.7176022657784082

Epoch: 5| Step: 5
Training loss: 0.17684534192085266
Validation loss: 1.6900882669674453

Epoch: 5| Step: 6
Training loss: 0.12063579261302948
Validation loss: 1.6822288241437686

Epoch: 5| Step: 7
Training loss: 0.12343478202819824
Validation loss: 1.7142375220534622

Epoch: 5| Step: 8
Training loss: 0.17064298689365387
Validation loss: 1.7051018079121907

Epoch: 5| Step: 9
Training loss: 0.1144227609038353
Validation loss: 1.7029416509853896

Epoch: 5| Step: 10
Training loss: 0.2070547342300415
Validation loss: 1.7046139214628486

Epoch: 379| Step: 0
Training loss: 0.146396204829216
Validation loss: 1.7226273603336786

Epoch: 5| Step: 1
Training loss: 0.1796104907989502
Validation loss: 1.7669944545274139

Epoch: 5| Step: 2
Training loss: 0.10088193416595459
Validation loss: 1.7562759178940968

Epoch: 5| Step: 3
Training loss: 0.15166951715946198
Validation loss: 1.7805893728809972

Epoch: 5| Step: 4
Training loss: 0.16740605235099792
Validation loss: 1.7780999880965038

Epoch: 5| Step: 5
Training loss: 0.19733497500419617
Validation loss: 1.7794825646185106

Epoch: 5| Step: 6
Training loss: 0.15112903714179993
Validation loss: 1.7767188343950497

Epoch: 5| Step: 7
Training loss: 0.20963986217975616
Validation loss: 1.753618964584925

Epoch: 5| Step: 8
Training loss: 0.1744491010904312
Validation loss: 1.7238960496840938

Epoch: 5| Step: 9
Training loss: 0.31804531812667847
Validation loss: 1.7143136583348757

Epoch: 5| Step: 10
Training loss: 0.09585442394018173
Validation loss: 1.7129565105643323

Epoch: 380| Step: 0
Training loss: 0.19690121710300446
Validation loss: 1.6788688193085373

Epoch: 5| Step: 1
Training loss: 0.08948980271816254
Validation loss: 1.6981332853276243

Epoch: 5| Step: 2
Training loss: 0.15244077146053314
Validation loss: 1.7044579752029911

Epoch: 5| Step: 3
Training loss: 0.19566601514816284
Validation loss: 1.6705478532339937

Epoch: 5| Step: 4
Training loss: 0.11736154556274414
Validation loss: 1.7186748443111297

Epoch: 5| Step: 5
Training loss: 0.19734688103199005
Validation loss: 1.7021602975424899

Epoch: 5| Step: 6
Training loss: 0.3200635313987732
Validation loss: 1.7211399219369377

Epoch: 5| Step: 7
Training loss: 0.138551265001297
Validation loss: 1.702160958320864

Epoch: 5| Step: 8
Training loss: 0.09818525612354279
Validation loss: 1.6779002002490464

Epoch: 5| Step: 9
Training loss: 0.16203446686267853
Validation loss: 1.6865110025610974

Epoch: 5| Step: 10
Training loss: 0.18317893147468567
Validation loss: 1.664273133841894

Epoch: 381| Step: 0
Training loss: 0.08037839829921722
Validation loss: 1.6759995952729256

Epoch: 5| Step: 1
Training loss: 0.3008670210838318
Validation loss: 1.6422363699123423

Epoch: 5| Step: 2
Training loss: 0.20373181998729706
Validation loss: 1.652216443451502

Epoch: 5| Step: 3
Training loss: 0.2807956635951996
Validation loss: 1.675738133409972

Epoch: 5| Step: 4
Training loss: 0.16833050549030304
Validation loss: 1.6741342877828946

Epoch: 5| Step: 5
Training loss: 0.10545852035284042
Validation loss: 1.660165399633428

Epoch: 5| Step: 6
Training loss: 0.13840213418006897
Validation loss: 1.6598890558365853

Epoch: 5| Step: 7
Training loss: 0.18184982240200043
Validation loss: 1.702973388856457

Epoch: 5| Step: 8
Training loss: 0.14357805252075195
Validation loss: 1.7275377704251198

Epoch: 5| Step: 9
Training loss: 0.1446254998445511
Validation loss: 1.7381552444991244

Epoch: 5| Step: 10
Training loss: 0.14302553236484528
Validation loss: 1.764541123502998

Epoch: 382| Step: 0
Training loss: 0.1927785575389862
Validation loss: 1.7264904975891113

Epoch: 5| Step: 1
Training loss: 0.11384624242782593
Validation loss: 1.713177478441628

Epoch: 5| Step: 2
Training loss: 0.09173289686441422
Validation loss: 1.7191738582426501

Epoch: 5| Step: 3
Training loss: 0.17620377242565155
Validation loss: 1.712307689010456

Epoch: 5| Step: 4
Training loss: 0.15323016047477722
Validation loss: 1.7254531793696906

Epoch: 5| Step: 5
Training loss: 0.08668304979801178
Validation loss: 1.7158303183894004

Epoch: 5| Step: 6
Training loss: 0.19396856427192688
Validation loss: 1.7102145559044295

Epoch: 5| Step: 7
Training loss: 0.15655900537967682
Validation loss: 1.7313269517754997

Epoch: 5| Step: 8
Training loss: 0.0638558492064476
Validation loss: 1.7059082344014158

Epoch: 5| Step: 9
Training loss: 0.1875678300857544
Validation loss: 1.7013393589245376

Epoch: 5| Step: 10
Training loss: 0.3171204924583435
Validation loss: 1.703931548262155

Epoch: 383| Step: 0
Training loss: 0.2488449066877365
Validation loss: 1.7266663864094725

Epoch: 5| Step: 1
Training loss: 0.16834385693073273
Validation loss: 1.7008128294380762

Epoch: 5| Step: 2
Training loss: 0.1278938353061676
Validation loss: 1.6891709989117039

Epoch: 5| Step: 3
Training loss: 0.1415088176727295
Validation loss: 1.7196145788315804

Epoch: 5| Step: 4
Training loss: 0.11100516468286514
Validation loss: 1.720585811522699

Epoch: 5| Step: 5
Training loss: 0.12379062175750732
Validation loss: 1.7292776184697305

Epoch: 5| Step: 6
Training loss: 0.11526523530483246
Validation loss: 1.6980165461058259

Epoch: 5| Step: 7
Training loss: 0.24489831924438477
Validation loss: 1.7133041927891393

Epoch: 5| Step: 8
Training loss: 0.08787137269973755
Validation loss: 1.7062334168341853

Epoch: 5| Step: 9
Training loss: 0.1680201143026352
Validation loss: 1.6845739169787335

Epoch: 5| Step: 10
Training loss: 0.09943130612373352
Validation loss: 1.6784590367347962

Epoch: 384| Step: 0
Training loss: 0.2066253423690796
Validation loss: 1.7154984204999861

Epoch: 5| Step: 1
Training loss: 0.15425370633602142
Validation loss: 1.7437647965646559

Epoch: 5| Step: 2
Training loss: 0.18124862015247345
Validation loss: 1.7353866523311985

Epoch: 5| Step: 3
Training loss: 0.13936392962932587
Validation loss: 1.7219034638456119

Epoch: 5| Step: 4
Training loss: 0.12348989397287369
Validation loss: 1.7347254932567637

Epoch: 5| Step: 5
Training loss: 0.16225405037403107
Validation loss: 1.7321850458780925

Epoch: 5| Step: 6
Training loss: 0.11982027441263199
Validation loss: 1.6999321169750665

Epoch: 5| Step: 7
Training loss: 0.1662779003381729
Validation loss: 1.6814568055573331

Epoch: 5| Step: 8
Training loss: 0.2818974256515503
Validation loss: 1.693931898763103

Epoch: 5| Step: 9
Training loss: 0.1902160346508026
Validation loss: 1.6891492502663725

Epoch: 5| Step: 10
Training loss: 0.08507249504327774
Validation loss: 1.6910381317138672

Epoch: 385| Step: 0
Training loss: 0.15279260277748108
Validation loss: 1.6900282803402151

Epoch: 5| Step: 1
Training loss: 0.13923387229442596
Validation loss: 1.6782315905376146

Epoch: 5| Step: 2
Training loss: 0.20579469203948975
Validation loss: 1.6901246027279926

Epoch: 5| Step: 3
Training loss: 0.12452651560306549
Validation loss: 1.6766012381481867

Epoch: 5| Step: 4
Training loss: 0.10313200950622559
Validation loss: 1.6726999205927695

Epoch: 5| Step: 5
Training loss: 0.16467267274856567
Validation loss: 1.6919674283714705

Epoch: 5| Step: 6
Training loss: 0.31482505798339844
Validation loss: 1.6768389837716215

Epoch: 5| Step: 7
Training loss: 0.1353876143693924
Validation loss: 1.6952895810527187

Epoch: 5| Step: 8
Training loss: 0.15331269800662994
Validation loss: 1.7039841951862458

Epoch: 5| Step: 9
Training loss: 0.18147239089012146
Validation loss: 1.7181412045673659

Epoch: 5| Step: 10
Training loss: 0.12579402327537537
Validation loss: 1.727776720959653

Epoch: 386| Step: 0
Training loss: 0.14375844597816467
Validation loss: 1.7390472414673015

Epoch: 5| Step: 1
Training loss: 0.2187337875366211
Validation loss: 1.7592559617052796

Epoch: 5| Step: 2
Training loss: 0.23393657803535461
Validation loss: 1.7810038751171482

Epoch: 5| Step: 3
Training loss: 0.2916829586029053
Validation loss: 1.7584218132880427

Epoch: 5| Step: 4
Training loss: 0.13245275616645813
Validation loss: 1.7558729635771884

Epoch: 5| Step: 5
Training loss: 0.14104284346103668
Validation loss: 1.7472941439638856

Epoch: 5| Step: 6
Training loss: 0.1461380422115326
Validation loss: 1.746799607430735

Epoch: 5| Step: 7
Training loss: 0.12189583480358124
Validation loss: 1.762377687679824

Epoch: 5| Step: 8
Training loss: 0.2056322991847992
Validation loss: 1.7370583382985925

Epoch: 5| Step: 9
Training loss: 0.14892981946468353
Validation loss: 1.7000201902081888

Epoch: 5| Step: 10
Training loss: 0.14101673662662506
Validation loss: 1.710032711746872

Epoch: 387| Step: 0
Training loss: 0.12427904456853867
Validation loss: 1.7297147807254587

Epoch: 5| Step: 1
Training loss: 0.15435859560966492
Validation loss: 1.7269679192573792

Epoch: 5| Step: 2
Training loss: 0.12296786159276962
Validation loss: 1.7009078648782545

Epoch: 5| Step: 3
Training loss: 0.26158565282821655
Validation loss: 1.7066554279737576

Epoch: 5| Step: 4
Training loss: 0.1160690188407898
Validation loss: 1.714106805862919

Epoch: 5| Step: 5
Training loss: 0.20458641648292542
Validation loss: 1.7360602168626682

Epoch: 5| Step: 6
Training loss: 0.09817154705524445
Validation loss: 1.702425177379321

Epoch: 5| Step: 7
Training loss: 0.08102761209011078
Validation loss: 1.715588975978154

Epoch: 5| Step: 8
Training loss: 0.195499986410141
Validation loss: 1.72100539617641

Epoch: 5| Step: 9
Training loss: 0.2878194749355316
Validation loss: 1.7307001518946823

Epoch: 5| Step: 10
Training loss: 0.20611613988876343
Validation loss: 1.6781590856531614

Epoch: 388| Step: 0
Training loss: 0.1898006945848465
Validation loss: 1.7037237908250542

Epoch: 5| Step: 1
Training loss: 0.17301985621452332
Validation loss: 1.6603264757381972

Epoch: 5| Step: 2
Training loss: 0.2992621958255768
Validation loss: 1.6540836082991732

Epoch: 5| Step: 3
Training loss: 0.16148683428764343
Validation loss: 1.6768338205993816

Epoch: 5| Step: 4
Training loss: 0.19896414875984192
Validation loss: 1.647226022776737

Epoch: 5| Step: 5
Training loss: 0.15634630620479584
Validation loss: 1.6456645496429936

Epoch: 5| Step: 6
Training loss: 0.12262175232172012
Validation loss: 1.6708016510932677

Epoch: 5| Step: 7
Training loss: 0.1819494068622589
Validation loss: 1.7099871802073654

Epoch: 5| Step: 8
Training loss: 0.13669152557849884
Validation loss: 1.6899092966510403

Epoch: 5| Step: 9
Training loss: 0.10559135675430298
Validation loss: 1.7188874944563834

Epoch: 5| Step: 10
Training loss: 0.15106171369552612
Validation loss: 1.7301976309027722

Epoch: 389| Step: 0
Training loss: 0.17175021767616272
Validation loss: 1.7410126552786878

Epoch: 5| Step: 1
Training loss: 0.17290356755256653
Validation loss: 1.7282767744474514

Epoch: 5| Step: 2
Training loss: 0.12004674971103668
Validation loss: 1.7690731287002563

Epoch: 5| Step: 3
Training loss: 0.17544099688529968
Validation loss: 1.7497315445253927

Epoch: 5| Step: 4
Training loss: 0.20031166076660156
Validation loss: 1.7440512975056965

Epoch: 5| Step: 5
Training loss: 0.17783382534980774
Validation loss: 1.7213694908285653

Epoch: 5| Step: 6
Training loss: 0.23810824751853943
Validation loss: 1.7125969612470238

Epoch: 5| Step: 7
Training loss: 0.12024788558483124
Validation loss: 1.7251103975439583

Epoch: 5| Step: 8
Training loss: 0.23001649975776672
Validation loss: 1.691974264319225

Epoch: 5| Step: 9
Training loss: 0.11366117000579834
Validation loss: 1.656221987098776

Epoch: 5| Step: 10
Training loss: 0.2262895256280899
Validation loss: 1.6794381154480802

Epoch: 390| Step: 0
Training loss: 0.13024333119392395
Validation loss: 1.6872360655056533

Epoch: 5| Step: 1
Training loss: 0.1676088124513626
Validation loss: 1.6709991501223656

Epoch: 5| Step: 2
Training loss: 0.15150080621242523
Validation loss: 1.6326397247211908

Epoch: 5| Step: 3
Training loss: 0.1485958993434906
Validation loss: 1.6676052116578626

Epoch: 5| Step: 4
Training loss: 0.17959168553352356
Validation loss: 1.6416054823065316

Epoch: 5| Step: 5
Training loss: 0.18657667934894562
Validation loss: 1.6390971470904607

Epoch: 5| Step: 6
Training loss: 0.16234652698040009
Validation loss: 1.6370835996443225

Epoch: 5| Step: 7
Training loss: 0.1373172551393509
Validation loss: 1.6596530124705324

Epoch: 5| Step: 8
Training loss: 0.17792896926403046
Validation loss: 1.6993024682485929

Epoch: 5| Step: 9
Training loss: 0.26743876934051514
Validation loss: 1.6509282973504835

Epoch: 5| Step: 10
Training loss: 0.12135469168424606
Validation loss: 1.7056521907929452

Epoch: 391| Step: 0
Training loss: 0.12834961712360382
Validation loss: 1.708509801536478

Epoch: 5| Step: 1
Training loss: 0.20422419905662537
Validation loss: 1.6883018285997453

Epoch: 5| Step: 2
Training loss: 0.19779524207115173
Validation loss: 1.6718842432063112

Epoch: 5| Step: 3
Training loss: 0.16775190830230713
Validation loss: 1.6664749204471547

Epoch: 5| Step: 4
Training loss: 0.0900808721780777
Validation loss: 1.6512897937528548

Epoch: 5| Step: 5
Training loss: 0.15673087537288666
Validation loss: 1.6769342730122228

Epoch: 5| Step: 6
Training loss: 0.1017056331038475
Validation loss: 1.6633961149441299

Epoch: 5| Step: 7
Training loss: 0.1140863299369812
Validation loss: 1.6547364560506677

Epoch: 5| Step: 8
Training loss: 0.12284443527460098
Validation loss: 1.64991577722693

Epoch: 5| Step: 9
Training loss: 0.1441870480775833
Validation loss: 1.698837762237877

Epoch: 5| Step: 10
Training loss: 0.2635931372642517
Validation loss: 1.6658689206646335

Epoch: 392| Step: 0
Training loss: 0.19316460192203522
Validation loss: 1.6886519488467966

Epoch: 5| Step: 1
Training loss: 0.16659319400787354
Validation loss: 1.658073684220673

Epoch: 5| Step: 2
Training loss: 0.12199336290359497
Validation loss: 1.6680591157687608

Epoch: 5| Step: 3
Training loss: 0.1753247082233429
Validation loss: 1.6710633244565738

Epoch: 5| Step: 4
Training loss: 0.12521669268608093
Validation loss: 1.6719049817772322

Epoch: 5| Step: 5
Training loss: 0.13461652398109436
Validation loss: 1.7001670316983295

Epoch: 5| Step: 6
Training loss: 0.15603455901145935
Validation loss: 1.6625668092440533

Epoch: 5| Step: 7
Training loss: 0.0925619974732399
Validation loss: 1.678521575466279

Epoch: 5| Step: 8
Training loss: 0.30712780356407166
Validation loss: 1.6947693324858142

Epoch: 5| Step: 9
Training loss: 0.13530300557613373
Validation loss: 1.698524441770328

Epoch: 5| Step: 10
Training loss: 0.18318812549114227
Validation loss: 1.6965043647314912

Epoch: 393| Step: 0
Training loss: 0.2981916069984436
Validation loss: 1.6850679343746555

Epoch: 5| Step: 1
Training loss: 0.1545456349849701
Validation loss: 1.6835826455905873

Epoch: 5| Step: 2
Training loss: 0.0844869390130043
Validation loss: 1.6635712205722768

Epoch: 5| Step: 3
Training loss: 0.1833743155002594
Validation loss: 1.6850846505934192

Epoch: 5| Step: 4
Training loss: 0.13981667160987854
Validation loss: 1.6712868213653564

Epoch: 5| Step: 5
Training loss: 0.13585272431373596
Validation loss: 1.6999138337309643

Epoch: 5| Step: 6
Training loss: 0.10452616214752197
Validation loss: 1.6842283484756306

Epoch: 5| Step: 7
Training loss: 0.13385304808616638
Validation loss: 1.677411299879833

Epoch: 5| Step: 8
Training loss: 0.14745751023292542
Validation loss: 1.7034786516620266

Epoch: 5| Step: 9
Training loss: 0.16698847711086273
Validation loss: 1.690562778903592

Epoch: 5| Step: 10
Training loss: 0.19623181223869324
Validation loss: 1.6699109359454083

Epoch: 394| Step: 0
Training loss: 0.237591952085495
Validation loss: 1.7089797790332506

Epoch: 5| Step: 1
Training loss: 0.13442502915859222
Validation loss: 1.700593303608638

Epoch: 5| Step: 2
Training loss: 0.12545332312583923
Validation loss: 1.6679614051695792

Epoch: 5| Step: 3
Training loss: 0.13687865436077118
Validation loss: 1.7126265700145433

Epoch: 5| Step: 4
Training loss: 0.23339048027992249
Validation loss: 1.6954351804589713

Epoch: 5| Step: 5
Training loss: 0.10450910031795502
Validation loss: 1.6922680870179208

Epoch: 5| Step: 6
Training loss: 0.21287760138511658
Validation loss: 1.676914341988102

Epoch: 5| Step: 7
Training loss: 0.16631878912448883
Validation loss: 1.6715207253732989

Epoch: 5| Step: 8
Training loss: 0.07012920081615448
Validation loss: 1.6476212534853207

Epoch: 5| Step: 9
Training loss: 0.11519958078861237
Validation loss: 1.678439514611357

Epoch: 5| Step: 10
Training loss: 0.09717175364494324
Validation loss: 1.6762404800743185

Epoch: 395| Step: 0
Training loss: 0.14651645720005035
Validation loss: 1.6750340000275643

Epoch: 5| Step: 1
Training loss: 0.1368347406387329
Validation loss: 1.701949442586591

Epoch: 5| Step: 2
Training loss: 0.16879624128341675
Validation loss: 1.6893667046741774

Epoch: 5| Step: 3
Training loss: 0.1098407730460167
Validation loss: 1.6838104981248097

Epoch: 5| Step: 4
Training loss: 0.17080017924308777
Validation loss: 1.6814023205029067

Epoch: 5| Step: 5
Training loss: 0.1690872609615326
Validation loss: 1.6839823005019978

Epoch: 5| Step: 6
Training loss: 0.1533307582139969
Validation loss: 1.695055316853267

Epoch: 5| Step: 7
Training loss: 0.2976990342140198
Validation loss: 1.7008415345222718

Epoch: 5| Step: 8
Training loss: 0.13426968455314636
Validation loss: 1.6945322175179758

Epoch: 5| Step: 9
Training loss: 0.153830885887146
Validation loss: 1.697805711018142

Epoch: 5| Step: 10
Training loss: 0.16497541964054108
Validation loss: 1.7113780078067575

Epoch: 396| Step: 0
Training loss: 0.1772800236940384
Validation loss: 1.698449465536302

Epoch: 5| Step: 1
Training loss: 0.049752939492464066
Validation loss: 1.7114188722384873

Epoch: 5| Step: 2
Training loss: 0.22768592834472656
Validation loss: 1.7313510871702624

Epoch: 5| Step: 3
Training loss: 0.10179716348648071
Validation loss: 1.7353583125657932

Epoch: 5| Step: 4
Training loss: 0.15409639477729797
Validation loss: 1.7224126349213302

Epoch: 5| Step: 5
Training loss: 0.12146009504795074
Validation loss: 1.707393733404016

Epoch: 5| Step: 6
Training loss: 0.18424858152866364
Validation loss: 1.7197591848270868

Epoch: 5| Step: 7
Training loss: 0.16629180312156677
Validation loss: 1.6960196674510997

Epoch: 5| Step: 8
Training loss: 0.13166117668151855
Validation loss: 1.6694084367444437

Epoch: 5| Step: 9
Training loss: 0.17591793835163116
Validation loss: 1.633777379989624

Epoch: 5| Step: 10
Training loss: 0.2689840793609619
Validation loss: 1.6617379816629554

Epoch: 397| Step: 0
Training loss: 0.09690017998218536
Validation loss: 1.6808250642591906

Epoch: 5| Step: 1
Training loss: 0.12331116199493408
Validation loss: 1.6885462678888792

Epoch: 5| Step: 2
Training loss: 0.12049517780542374
Validation loss: 1.670959161814823

Epoch: 5| Step: 3
Training loss: 0.15416650474071503
Validation loss: 1.6859915230863838

Epoch: 5| Step: 4
Training loss: 0.1978321224451065
Validation loss: 1.6627799900629188

Epoch: 5| Step: 5
Training loss: 0.11678387969732285
Validation loss: 1.7079744864535589

Epoch: 5| Step: 6
Training loss: 0.30361437797546387
Validation loss: 1.7089445526881883

Epoch: 5| Step: 7
Training loss: 0.147043377161026
Validation loss: 1.7091472623168782

Epoch: 5| Step: 8
Training loss: 0.13080134987831116
Validation loss: 1.7170427230096632

Epoch: 5| Step: 9
Training loss: 0.12381722033023834
Validation loss: 1.726329057447372

Epoch: 5| Step: 10
Training loss: 0.1397722214460373
Validation loss: 1.7696764020509617

Epoch: 398| Step: 0
Training loss: 0.1694815456867218
Validation loss: 1.7563276201166131

Epoch: 5| Step: 1
Training loss: 0.15330295264720917
Validation loss: 1.776565885031095

Epoch: 5| Step: 2
Training loss: 0.11258821189403534
Validation loss: 1.7667949212494718

Epoch: 5| Step: 3
Training loss: 0.09486924111843109
Validation loss: 1.800520848202449

Epoch: 5| Step: 4
Training loss: 0.2848430573940277
Validation loss: 1.7592072653514084

Epoch: 5| Step: 5
Training loss: 0.19761881232261658
Validation loss: 1.73508192646888

Epoch: 5| Step: 6
Training loss: 0.08683522790670395
Validation loss: 1.7153481655223395

Epoch: 5| Step: 7
Training loss: 0.13135048747062683
Validation loss: 1.6949773860234085

Epoch: 5| Step: 8
Training loss: 0.14502844214439392
Validation loss: 1.6866703020629061

Epoch: 5| Step: 9
Training loss: 0.1991543024778366
Validation loss: 1.696276246860463

Epoch: 5| Step: 10
Training loss: 0.1279449462890625
Validation loss: 1.685103181869753

Epoch: 399| Step: 0
Training loss: 0.10902667045593262
Validation loss: 1.710797502148536

Epoch: 5| Step: 1
Training loss: 0.16547685861587524
Validation loss: 1.732059581305391

Epoch: 5| Step: 2
Training loss: 0.16486375033855438
Validation loss: 1.7010902973913378

Epoch: 5| Step: 3
Training loss: 0.18638935685157776
Validation loss: 1.732393318606961

Epoch: 5| Step: 4
Training loss: 0.11372031271457672
Validation loss: 1.7634195499522711

Epoch: 5| Step: 5
Training loss: 0.2724296450614929
Validation loss: 1.702779475078788

Epoch: 5| Step: 6
Training loss: 0.14218026399612427
Validation loss: 1.733065975609646

Epoch: 5| Step: 7
Training loss: 0.15023405849933624
Validation loss: 1.6859631987028225

Epoch: 5| Step: 8
Training loss: 0.1444588005542755
Validation loss: 1.7046414139450237

Epoch: 5| Step: 9
Training loss: 0.09951931238174438
Validation loss: 1.677108754393875

Epoch: 5| Step: 10
Training loss: 0.1379256546497345
Validation loss: 1.7026712958530714

Epoch: 400| Step: 0
Training loss: 0.12635871767997742
Validation loss: 1.6752395027427263

Epoch: 5| Step: 1
Training loss: 0.12597651779651642
Validation loss: 1.699477784095272

Epoch: 5| Step: 2
Training loss: 0.12067701667547226
Validation loss: 1.7083155314127605

Epoch: 5| Step: 3
Training loss: 0.15958765149116516
Validation loss: 1.7073769928306661

Epoch: 5| Step: 4
Training loss: 0.14569847285747528
Validation loss: 1.7159392423527215

Epoch: 5| Step: 5
Training loss: 0.11028116941452026
Validation loss: 1.704417315862512

Epoch: 5| Step: 6
Training loss: 0.20276348292827606
Validation loss: 1.6971313543217157

Epoch: 5| Step: 7
Training loss: 0.15112023055553436
Validation loss: 1.6758119034510788

Epoch: 5| Step: 8
Training loss: 0.24328184127807617
Validation loss: 1.669457035679971

Epoch: 5| Step: 9
Training loss: 0.13761688768863678
Validation loss: 1.6327573355808054

Epoch: 5| Step: 10
Training loss: 0.12252117693424225
Validation loss: 1.635568421374085

Epoch: 401| Step: 0
Training loss: 0.15542252361774445
Validation loss: 1.6518369233736427

Epoch: 5| Step: 1
Training loss: 0.12409831583499908
Validation loss: 1.6493132575865714

Epoch: 5| Step: 2
Training loss: 0.1090255156159401
Validation loss: 1.6577940000000821

Epoch: 5| Step: 3
Training loss: 0.23975488543510437
Validation loss: 1.653317875759576

Epoch: 5| Step: 4
Training loss: 0.1609124392271042
Validation loss: 1.6559497258996452

Epoch: 5| Step: 5
Training loss: 0.12214045226573944
Validation loss: 1.6678532079983783

Epoch: 5| Step: 6
Training loss: 0.10247147083282471
Validation loss: 1.7065437006694015

Epoch: 5| Step: 7
Training loss: 0.16572770476341248
Validation loss: 1.7142416302875807

Epoch: 5| Step: 8
Training loss: 0.13913322985172272
Validation loss: 1.6796532959066413

Epoch: 5| Step: 9
Training loss: 0.12876348197460175
Validation loss: 1.688651502773326

Epoch: 5| Step: 10
Training loss: 0.10763832926750183
Validation loss: 1.6945934193108672

Epoch: 402| Step: 0
Training loss: 0.1443726122379303
Validation loss: 1.674663661628641

Epoch: 5| Step: 1
Training loss: 0.16192537546157837
Validation loss: 1.6983859526213778

Epoch: 5| Step: 2
Training loss: 0.1398243010044098
Validation loss: 1.6886606934250041

Epoch: 5| Step: 3
Training loss: 0.20094449818134308
Validation loss: 1.693635893124406

Epoch: 5| Step: 4
Training loss: 0.12920717895030975
Validation loss: 1.7059947893183718

Epoch: 5| Step: 5
Training loss: 0.19277723133563995
Validation loss: 1.707713868028374

Epoch: 5| Step: 6
Training loss: 0.12069062143564224
Validation loss: 1.7381307668583368

Epoch: 5| Step: 7
Training loss: 0.14860615134239197
Validation loss: 1.7446076229054441

Epoch: 5| Step: 8
Training loss: 0.12590323388576508
Validation loss: 1.7245497415142674

Epoch: 5| Step: 9
Training loss: 0.2881179749965668
Validation loss: 1.7476376141271284

Epoch: 5| Step: 10
Training loss: 0.10084309428930283
Validation loss: 1.7457628403940508

Epoch: 403| Step: 0
Training loss: 0.13003087043762207
Validation loss: 1.7629965838565622

Epoch: 5| Step: 1
Training loss: 0.2198808640241623
Validation loss: 1.7100057640383322

Epoch: 5| Step: 2
Training loss: 0.14132900536060333
Validation loss: 1.7342998609747937

Epoch: 5| Step: 3
Training loss: 0.2238427698612213
Validation loss: 1.728868951079666

Epoch: 5| Step: 4
Training loss: 0.1108938679099083
Validation loss: 1.6998308576563352

Epoch: 5| Step: 5
Training loss: 0.08336341381072998
Validation loss: 1.7194568239232546

Epoch: 5| Step: 6
Training loss: 0.1347830891609192
Validation loss: 1.7066973550345308

Epoch: 5| Step: 7
Training loss: 0.1619904339313507
Validation loss: 1.7201669690429524

Epoch: 5| Step: 8
Training loss: 0.1425478607416153
Validation loss: 1.6952628948355233

Epoch: 5| Step: 9
Training loss: 0.15453726053237915
Validation loss: 1.7018872204647268

Epoch: 5| Step: 10
Training loss: 0.23838438093662262
Validation loss: 1.7272620149838027

Epoch: 404| Step: 0
Training loss: 0.12261843681335449
Validation loss: 1.688078841855449

Epoch: 5| Step: 1
Training loss: 0.09492816776037216
Validation loss: 1.6866176641115578

Epoch: 5| Step: 2
Training loss: 0.21315304934978485
Validation loss: 1.6895407989460935

Epoch: 5| Step: 3
Training loss: 0.11980600655078888
Validation loss: 1.6825552601968088

Epoch: 5| Step: 4
Training loss: 0.10519343614578247
Validation loss: 1.6878362009602208

Epoch: 5| Step: 5
Training loss: 0.13612186908721924
Validation loss: 1.6797396617551004

Epoch: 5| Step: 6
Training loss: 0.17553019523620605
Validation loss: 1.6942204172893236

Epoch: 5| Step: 7
Training loss: 0.2837352752685547
Validation loss: 1.6605474654064383

Epoch: 5| Step: 8
Training loss: 0.13519151508808136
Validation loss: 1.650403368857599

Epoch: 5| Step: 9
Training loss: 0.09816515445709229
Validation loss: 1.6401580764401344

Epoch: 5| Step: 10
Training loss: 0.11544642597436905
Validation loss: 1.6305118363390687

Epoch: 405| Step: 0
Training loss: 0.11613277345895767
Validation loss: 1.6326855305702455

Epoch: 5| Step: 1
Training loss: 0.26031845808029175
Validation loss: 1.6275874478842622

Epoch: 5| Step: 2
Training loss: 0.13312040269374847
Validation loss: 1.6288391031244749

Epoch: 5| Step: 3
Training loss: 0.11058633029460907
Validation loss: 1.6061032959209975

Epoch: 5| Step: 4
Training loss: 0.21654188632965088
Validation loss: 1.6272652969565442

Epoch: 5| Step: 5
Training loss: 0.10415041446685791
Validation loss: 1.6299905392431444

Epoch: 5| Step: 6
Training loss: 0.1429882049560547
Validation loss: 1.6528423499035578

Epoch: 5| Step: 7
Training loss: 0.15074525773525238
Validation loss: 1.6188322215951898

Epoch: 5| Step: 8
Training loss: 0.07664445787668228
Validation loss: 1.6458766204054638

Epoch: 5| Step: 9
Training loss: 0.10882826894521713
Validation loss: 1.6611076029398109

Epoch: 5| Step: 10
Training loss: 0.1293511688709259
Validation loss: 1.6324853922731133

Epoch: 406| Step: 0
Training loss: 0.2757038474082947
Validation loss: 1.68775023183515

Epoch: 5| Step: 1
Training loss: 0.16611695289611816
Validation loss: 1.6744905248765023

Epoch: 5| Step: 2
Training loss: 0.12257485091686249
Validation loss: 1.7057399724119453

Epoch: 5| Step: 3
Training loss: 0.13077287375926971
Validation loss: 1.7134198488727692

Epoch: 5| Step: 4
Training loss: 0.2061905860900879
Validation loss: 1.6921893563321841

Epoch: 5| Step: 5
Training loss: 0.12932904064655304
Validation loss: 1.6842075611955376

Epoch: 5| Step: 6
Training loss: 0.1256527453660965
Validation loss: 1.6757375091634772

Epoch: 5| Step: 7
Training loss: 0.134706050157547
Validation loss: 1.6797988017400105

Epoch: 5| Step: 8
Training loss: 0.129440039396286
Validation loss: 1.702538445431699

Epoch: 5| Step: 9
Training loss: 0.0922643169760704
Validation loss: 1.7065952618916829

Epoch: 5| Step: 10
Training loss: 0.18934960663318634
Validation loss: 1.721626740629955

Epoch: 407| Step: 0
Training loss: 0.1346426010131836
Validation loss: 1.7114285474182458

Epoch: 5| Step: 1
Training loss: 0.13680267333984375
Validation loss: 1.678228856414877

Epoch: 5| Step: 2
Training loss: 0.22163410484790802
Validation loss: 1.6470238252352642

Epoch: 5| Step: 3
Training loss: 0.10024116188287735
Validation loss: 1.6450564745933778

Epoch: 5| Step: 4
Training loss: 0.12086129188537598
Validation loss: 1.6147305196331394

Epoch: 5| Step: 5
Training loss: 0.15568767488002777
Validation loss: 1.6352175089620775

Epoch: 5| Step: 6
Training loss: 0.11975324153900146
Validation loss: 1.6646886089796662

Epoch: 5| Step: 7
Training loss: 0.12487497180700302
Validation loss: 1.6610265547229397

Epoch: 5| Step: 8
Training loss: 0.1510811597108841
Validation loss: 1.6715492638208533

Epoch: 5| Step: 9
Training loss: 0.16013772785663605
Validation loss: 1.674518613405125

Epoch: 5| Step: 10
Training loss: 0.08704928308725357
Validation loss: 1.6531386439518263

Epoch: 408| Step: 0
Training loss: 0.1615658849477768
Validation loss: 1.6808928315357496

Epoch: 5| Step: 1
Training loss: 0.1410052627325058
Validation loss: 1.651423249193417

Epoch: 5| Step: 2
Training loss: 0.12401020526885986
Validation loss: 1.6603497087314565

Epoch: 5| Step: 3
Training loss: 0.0778122991323471
Validation loss: 1.6440337729710404

Epoch: 5| Step: 4
Training loss: 0.10347648710012436
Validation loss: 1.639806543627093

Epoch: 5| Step: 5
Training loss: 0.10390733182430267
Validation loss: 1.6778100408533567

Epoch: 5| Step: 6
Training loss: 0.2538348138332367
Validation loss: 1.6463109857292586

Epoch: 5| Step: 7
Training loss: 0.16859039664268494
Validation loss: 1.6552182974353913

Epoch: 5| Step: 8
Training loss: 0.1080518364906311
Validation loss: 1.6787379069994854

Epoch: 5| Step: 9
Training loss: 0.2434546947479248
Validation loss: 1.6589499173625823

Epoch: 5| Step: 10
Training loss: 0.13184534013271332
Validation loss: 1.691697056575488

Epoch: 409| Step: 0
Training loss: 0.09613938629627228
Validation loss: 1.694337660266507

Epoch: 5| Step: 1
Training loss: 0.07841210067272186
Validation loss: 1.698444471564344

Epoch: 5| Step: 2
Training loss: 0.07629374414682388
Validation loss: 1.6956237926278064

Epoch: 5| Step: 3
Training loss: 0.107057586312294
Validation loss: 1.6776348006340764

Epoch: 5| Step: 4
Training loss: 0.06582031399011612
Validation loss: 1.6869803577341058

Epoch: 5| Step: 5
Training loss: 0.2667568325996399
Validation loss: 1.6541506090471823

Epoch: 5| Step: 6
Training loss: 0.12527355551719666
Validation loss: 1.6662752782144854

Epoch: 5| Step: 7
Training loss: 0.21706461906433105
Validation loss: 1.6634906350925405

Epoch: 5| Step: 8
Training loss: 0.21806268393993378
Validation loss: 1.6887910468603975

Epoch: 5| Step: 9
Training loss: 0.1423097550868988
Validation loss: 1.68269851387188

Epoch: 5| Step: 10
Training loss: 0.09251493215560913
Validation loss: 1.695497884545275

Epoch: 410| Step: 0
Training loss: 0.1488809734582901
Validation loss: 1.6760990696568643

Epoch: 5| Step: 1
Training loss: 0.10246416181325912
Validation loss: 1.6866401446762906

Epoch: 5| Step: 2
Training loss: 0.16442540287971497
Validation loss: 1.7004410246367097

Epoch: 5| Step: 3
Training loss: 0.07864288985729218
Validation loss: 1.7137108515667658

Epoch: 5| Step: 4
Training loss: 0.1398629993200302
Validation loss: 1.691083610698741

Epoch: 5| Step: 5
Training loss: 0.12274327129125595
Validation loss: 1.6915239864780056

Epoch: 5| Step: 6
Training loss: 0.2633053660392761
Validation loss: 1.709228108006139

Epoch: 5| Step: 7
Training loss: 0.1393740326166153
Validation loss: 1.6792954321830504

Epoch: 5| Step: 8
Training loss: 0.15143898129463196
Validation loss: 1.6543583344387751

Epoch: 5| Step: 9
Training loss: 0.17549340426921844
Validation loss: 1.6855098329564577

Epoch: 5| Step: 10
Training loss: 0.21386902034282684
Validation loss: 1.655074433613849

Epoch: 411| Step: 0
Training loss: 0.11111219972372055
Validation loss: 1.6769367815345846

Epoch: 5| Step: 1
Training loss: 0.10103604942560196
Validation loss: 1.643120429849112

Epoch: 5| Step: 2
Training loss: 0.13883592188358307
Validation loss: 1.6308006291748376

Epoch: 5| Step: 3
Training loss: 0.10896811634302139
Validation loss: 1.6431117185982325

Epoch: 5| Step: 4
Training loss: 0.12350597232580185
Validation loss: 1.653964707928319

Epoch: 5| Step: 5
Training loss: 0.07569635659456253
Validation loss: 1.6529349691124373

Epoch: 5| Step: 6
Training loss: 0.1445646733045578
Validation loss: 1.6638282358005483

Epoch: 5| Step: 7
Training loss: 0.11380831152200699
Validation loss: 1.688711170227297

Epoch: 5| Step: 8
Training loss: 0.16052529215812683
Validation loss: 1.6989998189351891

Epoch: 5| Step: 9
Training loss: 0.19963951408863068
Validation loss: 1.701967905926448

Epoch: 5| Step: 10
Training loss: 0.16785864531993866
Validation loss: 1.690999916804734

Epoch: 412| Step: 0
Training loss: 0.11534474790096283
Validation loss: 1.6720470625867125

Epoch: 5| Step: 1
Training loss: 0.18021216988563538
Validation loss: 1.6825101990853586

Epoch: 5| Step: 2
Training loss: 0.08788975328207016
Validation loss: 1.6873179968967233

Epoch: 5| Step: 3
Training loss: 0.14922846853733063
Validation loss: 1.6740240768719745

Epoch: 5| Step: 4
Training loss: 0.13501998782157898
Validation loss: 1.662788434695172

Epoch: 5| Step: 5
Training loss: 0.11551070213317871
Validation loss: 1.6585381377127864

Epoch: 5| Step: 6
Training loss: 0.14677003026008606
Validation loss: 1.648102447550784

Epoch: 5| Step: 7
Training loss: 0.2519707977771759
Validation loss: 1.645088538367261

Epoch: 5| Step: 8
Training loss: 0.10931366682052612
Validation loss: 1.6505621351221555

Epoch: 5| Step: 9
Training loss: 0.09432079643011093
Validation loss: 1.669737244165072

Epoch: 5| Step: 10
Training loss: 0.11891042441129684
Validation loss: 1.6372880243485974

Epoch: 413| Step: 0
Training loss: 0.12236678600311279
Validation loss: 1.6542626773157427

Epoch: 5| Step: 1
Training loss: 0.21701988577842712
Validation loss: 1.6225117201446204

Epoch: 5| Step: 2
Training loss: 0.14728882908821106
Validation loss: 1.6387815116554179

Epoch: 5| Step: 3
Training loss: 0.07564058154821396
Validation loss: 1.618241035810081

Epoch: 5| Step: 4
Training loss: 0.12966887652873993
Validation loss: 1.6345258758914085

Epoch: 5| Step: 5
Training loss: 0.14546573162078857
Validation loss: 1.6144168492286437

Epoch: 5| Step: 6
Training loss: 0.14691489934921265
Validation loss: 1.6249227959622619

Epoch: 5| Step: 7
Training loss: 0.1050967127084732
Validation loss: 1.6532172246645855

Epoch: 5| Step: 8
Training loss: 0.12952527403831482
Validation loss: 1.6236531337102253

Epoch: 5| Step: 9
Training loss: 0.07259615510702133
Validation loss: 1.658536067572973

Epoch: 5| Step: 10
Training loss: 0.11471712589263916
Validation loss: 1.6457344998595536

Epoch: 414| Step: 0
Training loss: 0.07421563565731049
Validation loss: 1.673523195328251

Epoch: 5| Step: 1
Training loss: 0.08903997391462326
Validation loss: 1.6731307211742605

Epoch: 5| Step: 2
Training loss: 0.13718950748443604
Validation loss: 1.685343421915526

Epoch: 5| Step: 3
Training loss: 0.1280370056629181
Validation loss: 1.6964119352320188

Epoch: 5| Step: 4
Training loss: 0.14550045132637024
Validation loss: 1.712051550547282

Epoch: 5| Step: 5
Training loss: 0.08983076363801956
Validation loss: 1.6972802133970364

Epoch: 5| Step: 6
Training loss: 0.08530394732952118
Validation loss: 1.6865310207489999

Epoch: 5| Step: 7
Training loss: 0.126593679189682
Validation loss: 1.6876504549416163

Epoch: 5| Step: 8
Training loss: 0.145769864320755
Validation loss: 1.7018136984558516

Epoch: 5| Step: 9
Training loss: 0.1874009668827057
Validation loss: 1.7093389623908586

Epoch: 5| Step: 10
Training loss: 0.24581404030323029
Validation loss: 1.6793651183446248

Epoch: 415| Step: 0
Training loss: 0.08546580374240875
Validation loss: 1.6398080946296774

Epoch: 5| Step: 1
Training loss: 0.11607831716537476
Validation loss: 1.6540741535925096

Epoch: 5| Step: 2
Training loss: 0.16460049152374268
Validation loss: 1.655196943590718

Epoch: 5| Step: 3
Training loss: 0.26397505402565
Validation loss: 1.632035142631941

Epoch: 5| Step: 4
Training loss: 0.12613600492477417
Validation loss: 1.6309358663456415

Epoch: 5| Step: 5
Training loss: 0.14315415918827057
Validation loss: 1.6356923016168738

Epoch: 5| Step: 6
Training loss: 0.1802133172750473
Validation loss: 1.6258132893552062

Epoch: 5| Step: 7
Training loss: 0.15938961505889893
Validation loss: 1.6392766083440473

Epoch: 5| Step: 8
Training loss: 0.1127777248620987
Validation loss: 1.6177899517038816

Epoch: 5| Step: 9
Training loss: 0.06584247946739197
Validation loss: 1.649436326437099

Epoch: 5| Step: 10
Training loss: 0.16204077005386353
Validation loss: 1.6374186726026638

Epoch: 416| Step: 0
Training loss: 0.1325209140777588
Validation loss: 1.6327245671262023

Epoch: 5| Step: 1
Training loss: 0.26393353939056396
Validation loss: 1.6327012777328491

Epoch: 5| Step: 2
Training loss: 0.11523767560720444
Validation loss: 1.644768241913088

Epoch: 5| Step: 3
Training loss: 0.09359170496463776
Validation loss: 1.6277369735061482

Epoch: 5| Step: 4
Training loss: 0.11599819362163544
Validation loss: 1.6340560874631327

Epoch: 5| Step: 5
Training loss: 0.12111973762512207
Validation loss: 1.6323553240427406

Epoch: 5| Step: 6
Training loss: 0.11591106653213501
Validation loss: 1.6241886179934266

Epoch: 5| Step: 7
Training loss: 0.12788712978363037
Validation loss: 1.627316585151098

Epoch: 5| Step: 8
Training loss: 0.07901044189929962
Validation loss: 1.6087427446919103

Epoch: 5| Step: 9
Training loss: 0.08980841189622879
Validation loss: 1.6116931797355734

Epoch: 5| Step: 10
Training loss: 0.08863600343465805
Validation loss: 1.5676686917581866

Epoch: 417| Step: 0
Training loss: 0.13823838531970978
Validation loss: 1.5886875762734363

Epoch: 5| Step: 1
Training loss: 0.08379105478525162
Validation loss: 1.5734979439807195

Epoch: 5| Step: 2
Training loss: 0.14168094098567963
Validation loss: 1.5684016122612903

Epoch: 5| Step: 3
Training loss: 0.13489413261413574
Validation loss: 1.6082608007615613

Epoch: 5| Step: 4
Training loss: 0.13775208592414856
Validation loss: 1.6068254337515882

Epoch: 5| Step: 5
Training loss: 0.14071761071681976
Validation loss: 1.600212961114863

Epoch: 5| Step: 6
Training loss: 0.10053984820842743
Validation loss: 1.606236801352552

Epoch: 5| Step: 7
Training loss: 0.13547490537166595
Validation loss: 1.6125668748732536

Epoch: 5| Step: 8
Training loss: 0.22475740313529968
Validation loss: 1.6092926276627408

Epoch: 5| Step: 9
Training loss: 0.11370948702096939
Validation loss: 1.610075492371795

Epoch: 5| Step: 10
Training loss: 0.1372348517179489
Validation loss: 1.6404978857245496

Epoch: 418| Step: 0
Training loss: 0.07060419768095016
Validation loss: 1.658569888402057

Epoch: 5| Step: 1
Training loss: 0.1448272168636322
Validation loss: 1.6630461792792044

Epoch: 5| Step: 2
Training loss: 0.09801497310400009
Validation loss: 1.6538505733654063

Epoch: 5| Step: 3
Training loss: 0.08894870430231094
Validation loss: 1.6538808781613585

Epoch: 5| Step: 4
Training loss: 0.13894350826740265
Validation loss: 1.661220771010204

Epoch: 5| Step: 5
Training loss: 0.09655960649251938
Validation loss: 1.6650958291945919

Epoch: 5| Step: 6
Training loss: 0.11257652938365936
Validation loss: 1.6676329002585462

Epoch: 5| Step: 7
Training loss: 0.11595194041728973
Validation loss: 1.6578513089046683

Epoch: 5| Step: 8
Training loss: 0.27986961603164673
Validation loss: 1.6160238455700617

Epoch: 5| Step: 9
Training loss: 0.14075526595115662
Validation loss: 1.6185505236348798

Epoch: 5| Step: 10
Training loss: 0.08280622959136963
Validation loss: 1.6185978228046047

Epoch: 419| Step: 0
Training loss: 0.0689476728439331
Validation loss: 1.6012320851766935

Epoch: 5| Step: 1
Training loss: 0.24177250266075134
Validation loss: 1.602889876211843

Epoch: 5| Step: 2
Training loss: 0.12116353213787079
Validation loss: 1.5871798402519637

Epoch: 5| Step: 3
Training loss: 0.12537899613380432
Validation loss: 1.5923673837415633

Epoch: 5| Step: 4
Training loss: 0.10309368371963501
Validation loss: 1.6055440748891523

Epoch: 5| Step: 5
Training loss: 0.12314560264348984
Validation loss: 1.5924360265013993

Epoch: 5| Step: 6
Training loss: 0.12184631824493408
Validation loss: 1.6023443565573743

Epoch: 5| Step: 7
Training loss: 0.13176651298999786
Validation loss: 1.6050314211076306

Epoch: 5| Step: 8
Training loss: 0.18423354625701904
Validation loss: 1.6314199714250461

Epoch: 5| Step: 9
Training loss: 0.13680441677570343
Validation loss: 1.6108202959901543

Epoch: 5| Step: 10
Training loss: 0.05582505092024803
Validation loss: 1.6310822015167565

Epoch: 420| Step: 0
Training loss: 0.21657013893127441
Validation loss: 1.6521158231201993

Epoch: 5| Step: 1
Training loss: 0.09644263982772827
Validation loss: 1.6819204861117947

Epoch: 5| Step: 2
Training loss: 0.15643832087516785
Validation loss: 1.6547463991308724

Epoch: 5| Step: 3
Training loss: 0.052225906401872635
Validation loss: 1.633139407762917

Epoch: 5| Step: 4
Training loss: 0.11988357454538345
Validation loss: 1.682821951886659

Epoch: 5| Step: 5
Training loss: 0.1354953944683075
Validation loss: 1.6395091831043203

Epoch: 5| Step: 6
Training loss: 0.14415529370307922
Validation loss: 1.66227372231022

Epoch: 5| Step: 7
Training loss: 0.16958999633789062
Validation loss: 1.6700553035223356

Epoch: 5| Step: 8
Training loss: 0.09078327566385269
Validation loss: 1.6458414293104602

Epoch: 5| Step: 9
Training loss: 0.09924474358558655
Validation loss: 1.6379312340931227

Epoch: 5| Step: 10
Training loss: 0.1364063322544098
Validation loss: 1.6299231193398918

Epoch: 421| Step: 0
Training loss: 0.08801139891147614
Validation loss: 1.6192779374378983

Epoch: 5| Step: 1
Training loss: 0.1209392175078392
Validation loss: 1.63272060373778

Epoch: 5| Step: 2
Training loss: 0.07479258626699448
Validation loss: 1.6017162799835205

Epoch: 5| Step: 3
Training loss: 0.1679588258266449
Validation loss: 1.6156827172925394

Epoch: 5| Step: 4
Training loss: 0.1794874221086502
Validation loss: 1.6242190868623796

Epoch: 5| Step: 5
Training loss: 0.09658395498991013
Validation loss: 1.6011614837954122

Epoch: 5| Step: 6
Training loss: 0.10850240290164948
Validation loss: 1.6285687710649224

Epoch: 5| Step: 7
Training loss: 0.0809357613325119
Validation loss: 1.6351662489675707

Epoch: 5| Step: 8
Training loss: 0.09429974853992462
Validation loss: 1.617949398615027

Epoch: 5| Step: 9
Training loss: 0.20626473426818848
Validation loss: 1.6518729976428452

Epoch: 5| Step: 10
Training loss: 0.16754230856895447
Validation loss: 1.6333027860169769

Epoch: 422| Step: 0
Training loss: 0.2111019641160965
Validation loss: 1.6426401099851053

Epoch: 5| Step: 1
Training loss: 0.11311719566583633
Validation loss: 1.6116234743466942

Epoch: 5| Step: 2
Training loss: 0.12554225325584412
Validation loss: 1.6614552954191804

Epoch: 5| Step: 3
Training loss: 0.07476504147052765
Validation loss: 1.6216763988617928

Epoch: 5| Step: 4
Training loss: 0.11938457190990448
Validation loss: 1.6289489448711436

Epoch: 5| Step: 5
Training loss: 0.11787332594394684
Validation loss: 1.5937642871692617

Epoch: 5| Step: 6
Training loss: 0.1155262216925621
Validation loss: 1.6288647228671658

Epoch: 5| Step: 7
Training loss: 0.17600758373737335
Validation loss: 1.6125770538083968

Epoch: 5| Step: 8
Training loss: 0.16006425023078918
Validation loss: 1.6206479021297988

Epoch: 5| Step: 9
Training loss: 0.12828874588012695
Validation loss: 1.6194853974926857

Epoch: 5| Step: 10
Training loss: 0.10341808199882507
Validation loss: 1.633128273871637

Epoch: 423| Step: 0
Training loss: 0.15214142203330994
Validation loss: 1.6057381835035098

Epoch: 5| Step: 1
Training loss: 0.2691163420677185
Validation loss: 1.6297012932838932

Epoch: 5| Step: 2
Training loss: 0.12236330658197403
Validation loss: 1.6297297458494864

Epoch: 5| Step: 3
Training loss: 0.09349268674850464
Validation loss: 1.6383435239074051

Epoch: 5| Step: 4
Training loss: 0.1602831929922104
Validation loss: 1.6670404711077291

Epoch: 5| Step: 5
Training loss: 0.1120760589838028
Validation loss: 1.6709234240234538

Epoch: 5| Step: 6
Training loss: 0.17564024031162262
Validation loss: 1.6648370777407

Epoch: 5| Step: 7
Training loss: 0.17331011593341827
Validation loss: 1.6651966712808097

Epoch: 5| Step: 8
Training loss: 0.17149774730205536
Validation loss: 1.6515562867605558

Epoch: 5| Step: 9
Training loss: 0.19566036760807037
Validation loss: 1.6220377145274993

Epoch: 5| Step: 10
Training loss: 0.1417885720729828
Validation loss: 1.6289383172988892

Epoch: 424| Step: 0
Training loss: 0.13226750493049622
Validation loss: 1.6070626410104896

Epoch: 5| Step: 1
Training loss: 0.10563042014837265
Validation loss: 1.6258828845075382

Epoch: 5| Step: 2
Training loss: 0.23978500068187714
Validation loss: 1.6435563974483038

Epoch: 5| Step: 3
Training loss: 0.08894527703523636
Validation loss: 1.6361719972343856

Epoch: 5| Step: 4
Training loss: 0.10570506751537323
Validation loss: 1.660889087184783

Epoch: 5| Step: 5
Training loss: 0.10328269004821777
Validation loss: 1.671941138082935

Epoch: 5| Step: 6
Training loss: 0.16829705238342285
Validation loss: 1.662845274453522

Epoch: 5| Step: 7
Training loss: 0.12316665798425674
Validation loss: 1.679883894099984

Epoch: 5| Step: 8
Training loss: 0.19087210297584534
Validation loss: 1.669752037653359

Epoch: 5| Step: 9
Training loss: 0.08816971629858017
Validation loss: 1.6627978547926872

Epoch: 5| Step: 10
Training loss: 0.16359910368919373
Validation loss: 1.6458997393167147

Epoch: 425| Step: 0
Training loss: 0.08841890096664429
Validation loss: 1.6508921423266012

Epoch: 5| Step: 1
Training loss: 0.15087053179740906
Validation loss: 1.657512262303342

Epoch: 5| Step: 2
Training loss: 0.09857042133808136
Validation loss: 1.6560513050325456

Epoch: 5| Step: 3
Training loss: 0.1379968822002411
Validation loss: 1.63988233125338

Epoch: 5| Step: 4
Training loss: 0.10248545557260513
Validation loss: 1.6530998701690345

Epoch: 5| Step: 5
Training loss: 0.10324599593877792
Validation loss: 1.6420619410853232

Epoch: 5| Step: 6
Training loss: 0.16102218627929688
Validation loss: 1.6253548014548518

Epoch: 5| Step: 7
Training loss: 0.15241681039333344
Validation loss: 1.629374465634746

Epoch: 5| Step: 8
Training loss: 0.10505704581737518
Validation loss: 1.6472960492616058

Epoch: 5| Step: 9
Training loss: 0.07715118676424026
Validation loss: 1.639744621451183

Epoch: 5| Step: 10
Training loss: 0.21277166903018951
Validation loss: 1.6412381638762772

Epoch: 426| Step: 0
Training loss: 0.10193485021591187
Validation loss: 1.6691424090375182

Epoch: 5| Step: 1
Training loss: 0.17312635481357574
Validation loss: 1.66559644668333

Epoch: 5| Step: 2
Training loss: 0.11822017282247543
Validation loss: 1.6592790747201571

Epoch: 5| Step: 3
Training loss: 0.0952853411436081
Validation loss: 1.660657645553671

Epoch: 5| Step: 4
Training loss: 0.081760473549366
Validation loss: 1.6585970155654415

Epoch: 5| Step: 5
Training loss: 0.20342564582824707
Validation loss: 1.663728585807226

Epoch: 5| Step: 6
Training loss: 0.09764275699853897
Validation loss: 1.6437588955766411

Epoch: 5| Step: 7
Training loss: 0.08568832278251648
Validation loss: 1.6459121986102032

Epoch: 5| Step: 8
Training loss: 0.15186230838298798
Validation loss: 1.6425111204065301

Epoch: 5| Step: 9
Training loss: 0.10679104179143906
Validation loss: 1.6110760627254364

Epoch: 5| Step: 10
Training loss: 0.12409534305334091
Validation loss: 1.6488031110455912

Epoch: 427| Step: 0
Training loss: 0.08172893524169922
Validation loss: 1.6331889244817919

Epoch: 5| Step: 1
Training loss: 0.07125099003314972
Validation loss: 1.618513564909658

Epoch: 5| Step: 2
Training loss: 0.09667688608169556
Validation loss: 1.6006511219086186

Epoch: 5| Step: 3
Training loss: 0.21541079878807068
Validation loss: 1.6332412099325528

Epoch: 5| Step: 4
Training loss: 0.12831923365592957
Validation loss: 1.6162230212201354

Epoch: 5| Step: 5
Training loss: 0.1976633369922638
Validation loss: 1.6385563265892766

Epoch: 5| Step: 6
Training loss: 0.11812756210565567
Validation loss: 1.6184550459666918

Epoch: 5| Step: 7
Training loss: 0.12036089599132538
Validation loss: 1.6018512184901903

Epoch: 5| Step: 8
Training loss: 0.12000314891338348
Validation loss: 1.6192340850830078

Epoch: 5| Step: 9
Training loss: 0.14044274389743805
Validation loss: 1.6301343133372646

Epoch: 5| Step: 10
Training loss: 0.10085137188434601
Validation loss: 1.6466390830214306

Epoch: 428| Step: 0
Training loss: 0.13221342861652374
Validation loss: 1.651936727185403

Epoch: 5| Step: 1
Training loss: 0.07223591208457947
Validation loss: 1.6769212753542009

Epoch: 5| Step: 2
Training loss: 0.23782368004322052
Validation loss: 1.6813312666390532

Epoch: 5| Step: 3
Training loss: 0.15894600749015808
Validation loss: 1.6967604019308602

Epoch: 5| Step: 4
Training loss: 0.09961529821157455
Validation loss: 1.6941401779010732

Epoch: 5| Step: 5
Training loss: 0.11384739726781845
Validation loss: 1.6978522757048249

Epoch: 5| Step: 6
Training loss: 0.08501552045345306
Validation loss: 1.6500450629059986

Epoch: 5| Step: 7
Training loss: 0.11364978551864624
Validation loss: 1.6665640954048402

Epoch: 5| Step: 8
Training loss: 0.1415451169013977
Validation loss: 1.6578616660128358

Epoch: 5| Step: 9
Training loss: 0.16874389350414276
Validation loss: 1.6775666949569539

Epoch: 5| Step: 10
Training loss: 0.1449253112077713
Validation loss: 1.6381223919571086

Epoch: 429| Step: 0
Training loss: 0.19101056456565857
Validation loss: 1.6181697704458748

Epoch: 5| Step: 1
Training loss: 0.11335283517837524
Validation loss: 1.6495852951080567

Epoch: 5| Step: 2
Training loss: 0.12437329441308975
Validation loss: 1.6239059548224173

Epoch: 5| Step: 3
Training loss: 0.1318882703781128
Validation loss: 1.6472063590121526

Epoch: 5| Step: 4
Training loss: 0.1427709460258484
Validation loss: 1.6411134940321728

Epoch: 5| Step: 5
Training loss: 0.13946953415870667
Validation loss: 1.6673722247923575

Epoch: 5| Step: 6
Training loss: 0.15706081688404083
Validation loss: 1.661580575409756

Epoch: 5| Step: 7
Training loss: 0.08510921150445938
Validation loss: 1.6142282062961208

Epoch: 5| Step: 8
Training loss: 0.09244903922080994
Validation loss: 1.6580589919961908

Epoch: 5| Step: 9
Training loss: 0.12847425043582916
Validation loss: 1.6737854352561377

Epoch: 5| Step: 10
Training loss: 0.11069995164871216
Validation loss: 1.6582702577755015

Epoch: 430| Step: 0
Training loss: 0.07571443915367126
Validation loss: 1.6636675878237652

Epoch: 5| Step: 1
Training loss: 0.11065517365932465
Validation loss: 1.6615929110075838

Epoch: 5| Step: 2
Training loss: 0.1569545567035675
Validation loss: 1.6606266908748175

Epoch: 5| Step: 3
Training loss: 0.13258282840251923
Validation loss: 1.625614704624299

Epoch: 5| Step: 4
Training loss: 0.21521945297718048
Validation loss: 1.6399605043472782

Epoch: 5| Step: 5
Training loss: 0.12843284010887146
Validation loss: 1.6074394808020642

Epoch: 5| Step: 6
Training loss: 0.1225641742348671
Validation loss: 1.6063307305817962

Epoch: 5| Step: 7
Training loss: 0.15412381291389465
Validation loss: 1.6129599886555825

Epoch: 5| Step: 8
Training loss: 0.10134132206439972
Validation loss: 1.6004303860408005

Epoch: 5| Step: 9
Training loss: 0.11501405388116837
Validation loss: 1.6273230557800622

Epoch: 5| Step: 10
Training loss: 0.08683660626411438
Validation loss: 1.6064943651999197

Epoch: 431| Step: 0
Training loss: 0.12264089286327362
Validation loss: 1.6406474510828655

Epoch: 5| Step: 1
Training loss: 0.22040729224681854
Validation loss: 1.6407526782763902

Epoch: 5| Step: 2
Training loss: 0.10639002174139023
Validation loss: 1.6448249560530468

Epoch: 5| Step: 3
Training loss: 0.14694471657276154
Validation loss: 1.6394332480686966

Epoch: 5| Step: 4
Training loss: 0.08565036952495575
Validation loss: 1.636352078889006

Epoch: 5| Step: 5
Training loss: 0.17995354533195496
Validation loss: 1.6777041945406186

Epoch: 5| Step: 6
Training loss: 0.0998724028468132
Validation loss: 1.635840449281918

Epoch: 5| Step: 7
Training loss: 0.08373095095157623
Validation loss: 1.6159899952591106

Epoch: 5| Step: 8
Training loss: 0.09676410257816315
Validation loss: 1.6191415222742225

Epoch: 5| Step: 9
Training loss: 0.20513176918029785
Validation loss: 1.6128054318889495

Epoch: 5| Step: 10
Training loss: 0.08414953202009201
Validation loss: 1.621513589735954

Epoch: 432| Step: 0
Training loss: 0.09067528694868088
Validation loss: 1.6127154160571355

Epoch: 5| Step: 1
Training loss: 0.11146531254053116
Validation loss: 1.6370883705795451

Epoch: 5| Step: 2
Training loss: 0.09350358694791794
Validation loss: 1.6484640311169367

Epoch: 5| Step: 3
Training loss: 0.08033294975757599
Validation loss: 1.656092175873377

Epoch: 5| Step: 4
Training loss: 0.13819782435894012
Validation loss: 1.613634724770823

Epoch: 5| Step: 5
Training loss: 0.08412128686904907
Validation loss: 1.6121654715589298

Epoch: 5| Step: 6
Training loss: 0.08223531395196915
Validation loss: 1.6484938180574806

Epoch: 5| Step: 7
Training loss: 0.10265399515628815
Validation loss: 1.6484690891799105

Epoch: 5| Step: 8
Training loss: 0.10967393964529037
Validation loss: 1.6447080719855525

Epoch: 5| Step: 9
Training loss: 0.2514466941356659
Validation loss: 1.6643704983495897

Epoch: 5| Step: 10
Training loss: 0.1494043618440628
Validation loss: 1.665087725526543

Epoch: 433| Step: 0
Training loss: 0.08750595152378082
Validation loss: 1.6115668832614858

Epoch: 5| Step: 1
Training loss: 0.12659184634685516
Validation loss: 1.608492620529667

Epoch: 5| Step: 2
Training loss: 0.09324528276920319
Validation loss: 1.6206341481977893

Epoch: 5| Step: 3
Training loss: 0.08419283479452133
Validation loss: 1.604636925522999

Epoch: 5| Step: 4
Training loss: 0.13579753041267395
Validation loss: 1.6078358504080004

Epoch: 5| Step: 5
Training loss: 0.11179205030202866
Validation loss: 1.6117468405795354

Epoch: 5| Step: 6
Training loss: 0.09666457772254944
Validation loss: 1.5972768427223287

Epoch: 5| Step: 7
Training loss: 0.105978824198246
Validation loss: 1.6297528295106785

Epoch: 5| Step: 8
Training loss: 0.25712355971336365
Validation loss: 1.6558665357610232

Epoch: 5| Step: 9
Training loss: 0.11198483407497406
Validation loss: 1.6469103123552056

Epoch: 5| Step: 10
Training loss: 0.14879724383354187
Validation loss: 1.6756915174504763

Epoch: 434| Step: 0
Training loss: 0.2515701353549957
Validation loss: 1.69363905537513

Epoch: 5| Step: 1
Training loss: 0.09503879398107529
Validation loss: 1.6801177724715202

Epoch: 5| Step: 2
Training loss: 0.09548145532608032
Validation loss: 1.667923141551274

Epoch: 5| Step: 3
Training loss: 0.08739112317562103
Validation loss: 1.6475115719661917

Epoch: 5| Step: 4
Training loss: 0.05523856729269028
Validation loss: 1.6314956757330126

Epoch: 5| Step: 5
Training loss: 0.11418826878070831
Validation loss: 1.6324435126396917

Epoch: 5| Step: 6
Training loss: 0.174169659614563
Validation loss: 1.6056475895707325

Epoch: 5| Step: 7
Training loss: 0.1806027591228485
Validation loss: 1.603683271715718

Epoch: 5| Step: 8
Training loss: 0.11415443569421768
Validation loss: 1.6087487730928647

Epoch: 5| Step: 9
Training loss: 0.16318956017494202
Validation loss: 1.5924074701083604

Epoch: 5| Step: 10
Training loss: 0.1820482313632965
Validation loss: 1.604415605145116

Epoch: 435| Step: 0
Training loss: 0.09368641674518585
Validation loss: 1.62080507380988

Epoch: 5| Step: 1
Training loss: 0.10067828744649887
Validation loss: 1.6172789142977806

Epoch: 5| Step: 2
Training loss: 0.12478712946176529
Validation loss: 1.6340141847569456

Epoch: 5| Step: 3
Training loss: 0.08341918140649796
Validation loss: 1.6298729142835062

Epoch: 5| Step: 4
Training loss: 0.13323521614074707
Validation loss: 1.6407085029027795

Epoch: 5| Step: 5
Training loss: 0.1672949492931366
Validation loss: 1.6339691480000813

Epoch: 5| Step: 6
Training loss: 0.14396461844444275
Validation loss: 1.6426711133731309

Epoch: 5| Step: 7
Training loss: 0.11663515865802765
Validation loss: 1.6530520095620105

Epoch: 5| Step: 8
Training loss: 0.10552480071783066
Validation loss: 1.6506613595511324

Epoch: 5| Step: 9
Training loss: 0.210039883852005
Validation loss: 1.6358245418917747

Epoch: 5| Step: 10
Training loss: 0.07081777602434158
Validation loss: 1.6357353797522924

Epoch: 436| Step: 0
Training loss: 0.041671134531497955
Validation loss: 1.608783580923593

Epoch: 5| Step: 1
Training loss: 0.13222870230674744
Validation loss: 1.609781019149288

Epoch: 5| Step: 2
Training loss: 0.1087988018989563
Validation loss: 1.613911824841653

Epoch: 5| Step: 3
Training loss: 0.08994783461093903
Validation loss: 1.6089149226424515

Epoch: 5| Step: 4
Training loss: 0.2703053951263428
Validation loss: 1.5942924061129171

Epoch: 5| Step: 5
Training loss: 0.132589191198349
Validation loss: 1.6050813531362882

Epoch: 5| Step: 6
Training loss: 0.10173094272613525
Validation loss: 1.612446133808423

Epoch: 5| Step: 7
Training loss: 0.09533105790615082
Validation loss: 1.6019443363271735

Epoch: 5| Step: 8
Training loss: 0.12215086072683334
Validation loss: 1.5838558891768098

Epoch: 5| Step: 9
Training loss: 0.09497446566820145
Validation loss: 1.5914375346194032

Epoch: 5| Step: 10
Training loss: 0.11854083091020584
Validation loss: 1.6640373353035218

Epoch: 437| Step: 0
Training loss: 0.14396603405475616
Validation loss: 1.6373787464634064

Epoch: 5| Step: 1
Training loss: 0.12012924998998642
Validation loss: 1.6575505374580302

Epoch: 5| Step: 2
Training loss: 0.09563329070806503
Validation loss: 1.6462132738482567

Epoch: 5| Step: 3
Training loss: 0.1633710116147995
Validation loss: 1.6611910699516215

Epoch: 5| Step: 4
Training loss: 0.13691912591457367
Validation loss: 1.6645253396803332

Epoch: 5| Step: 5
Training loss: 0.12693822383880615
Validation loss: 1.6343674044455252

Epoch: 5| Step: 6
Training loss: 0.11905471235513687
Validation loss: 1.6434258568671443

Epoch: 5| Step: 7
Training loss: 0.1085389256477356
Validation loss: 1.6299660974933254

Epoch: 5| Step: 8
Training loss: 0.08519710600376129
Validation loss: 1.632200987108292

Epoch: 5| Step: 9
Training loss: 0.13016197085380554
Validation loss: 1.6312744015006608

Epoch: 5| Step: 10
Training loss: 0.2944886386394501
Validation loss: 1.644666648680164

Epoch: 438| Step: 0
Training loss: 0.10723432153463364
Validation loss: 1.6154952177437403

Epoch: 5| Step: 1
Training loss: 0.10000374168157578
Validation loss: 1.6341028777501916

Epoch: 5| Step: 2
Training loss: 0.09389154613018036
Validation loss: 1.6321419092916674

Epoch: 5| Step: 3
Training loss: 0.1001824289560318
Validation loss: 1.6481804078625095

Epoch: 5| Step: 4
Training loss: 0.07827411592006683
Validation loss: 1.652905833336615

Epoch: 5| Step: 5
Training loss: 0.10254025459289551
Validation loss: 1.6422331666433683

Epoch: 5| Step: 6
Training loss: 0.22109827399253845
Validation loss: 1.63849268292868

Epoch: 5| Step: 7
Training loss: 0.06626461446285248
Validation loss: 1.6402281234341283

Epoch: 5| Step: 8
Training loss: 0.1858312487602234
Validation loss: 1.6422507506544872

Epoch: 5| Step: 9
Training loss: 0.08169370889663696
Validation loss: 1.6377100162608649

Epoch: 5| Step: 10
Training loss: 0.11845515668392181
Validation loss: 1.6475482204908967

Epoch: 439| Step: 0
Training loss: 0.055363915860652924
Validation loss: 1.6445637518359768

Epoch: 5| Step: 1
Training loss: 0.15674234926700592
Validation loss: 1.6408506849760651

Epoch: 5| Step: 2
Training loss: 0.10427077859640121
Validation loss: 1.652878229336072

Epoch: 5| Step: 3
Training loss: 0.21842613816261292
Validation loss: 1.6621292329603625

Epoch: 5| Step: 4
Training loss: 0.1340014934539795
Validation loss: 1.6539709068113757

Epoch: 5| Step: 5
Training loss: 0.1218036562204361
Validation loss: 1.6470892301169775

Epoch: 5| Step: 6
Training loss: 0.18583032488822937
Validation loss: 1.6688710438307894

Epoch: 5| Step: 7
Training loss: 0.07861021161079407
Validation loss: 1.6760889086672055

Epoch: 5| Step: 8
Training loss: 0.09269963949918747
Validation loss: 1.6817020972569783

Epoch: 5| Step: 9
Training loss: 0.09721550345420837
Validation loss: 1.6593688329060872

Epoch: 5| Step: 10
Training loss: 0.07874513417482376
Validation loss: 1.637787406162549

Epoch: 440| Step: 0
Training loss: 0.08123031258583069
Validation loss: 1.6095365939601776

Epoch: 5| Step: 1
Training loss: 0.10495924949645996
Validation loss: 1.6248274990307388

Epoch: 5| Step: 2
Training loss: 0.0772470086812973
Validation loss: 1.6034277203262493

Epoch: 5| Step: 3
Training loss: 0.10145743191242218
Validation loss: 1.5960938046055455

Epoch: 5| Step: 4
Training loss: 0.1185264140367508
Validation loss: 1.591375509897868

Epoch: 5| Step: 5
Training loss: 0.10809610038995743
Validation loss: 1.619826316833496

Epoch: 5| Step: 6
Training loss: 0.1204538568854332
Validation loss: 1.5988534240312473

Epoch: 5| Step: 7
Training loss: 0.10937533527612686
Validation loss: 1.6116954806030437

Epoch: 5| Step: 8
Training loss: 0.08488249778747559
Validation loss: 1.6165717622285247

Epoch: 5| Step: 9
Training loss: 0.1876707375049591
Validation loss: 1.6063176662691179

Epoch: 5| Step: 10
Training loss: 0.14392875134944916
Validation loss: 1.579938245076005

Epoch: 441| Step: 0
Training loss: 0.15896372497081757
Validation loss: 1.6098683675130208

Epoch: 5| Step: 1
Training loss: 0.17415867745876312
Validation loss: 1.63069704527496

Epoch: 5| Step: 2
Training loss: 0.13114266097545624
Validation loss: 1.6043709388343237

Epoch: 5| Step: 3
Training loss: 0.1039780005812645
Validation loss: 1.5938841027598227

Epoch: 5| Step: 4
Training loss: 0.09971947968006134
Validation loss: 1.5801913110158776

Epoch: 5| Step: 5
Training loss: 0.21119168400764465
Validation loss: 1.584861433634194

Epoch: 5| Step: 6
Training loss: 0.058040551841259
Validation loss: 1.5862999321312032

Epoch: 5| Step: 7
Training loss: 0.1065158098936081
Validation loss: 1.6149822012070687

Epoch: 5| Step: 8
Training loss: 0.16051381826400757
Validation loss: 1.5997930342151272

Epoch: 5| Step: 9
Training loss: 0.11577063798904419
Validation loss: 1.604923935346706

Epoch: 5| Step: 10
Training loss: 0.11174579709768295
Validation loss: 1.5945496879598147

Epoch: 442| Step: 0
Training loss: 0.11230484396219254
Validation loss: 1.571275318822553

Epoch: 5| Step: 1
Training loss: 0.09070469439029694
Validation loss: 1.593489113674369

Epoch: 5| Step: 2
Training loss: 0.13254806399345398
Validation loss: 1.5800901869291901

Epoch: 5| Step: 3
Training loss: 0.11688975989818573
Validation loss: 1.5753481554728683

Epoch: 5| Step: 4
Training loss: 0.1435190737247467
Validation loss: 1.554442790246779

Epoch: 5| Step: 5
Training loss: 0.23634293675422668
Validation loss: 1.584971941927428

Epoch: 5| Step: 6
Training loss: 0.13095930218696594
Validation loss: 1.5524737194020262

Epoch: 5| Step: 7
Training loss: 0.09425459802150726
Validation loss: 1.5726850417352491

Epoch: 5| Step: 8
Training loss: 0.08944503217935562
Validation loss: 1.5838472163805397

Epoch: 5| Step: 9
Training loss: 0.10834119468927383
Validation loss: 1.588157380780866

Epoch: 5| Step: 10
Training loss: 0.08131705224514008
Validation loss: 1.5985019207000732

Epoch: 443| Step: 0
Training loss: 0.08975442498922348
Validation loss: 1.5945678923719673

Epoch: 5| Step: 1
Training loss: 0.20902784168720245
Validation loss: 1.591945654602461

Epoch: 5| Step: 2
Training loss: 0.12244024127721786
Validation loss: 1.5778290584523191

Epoch: 5| Step: 3
Training loss: 0.12314577400684357
Validation loss: 1.5557944338808778

Epoch: 5| Step: 4
Training loss: 0.10096832364797592
Validation loss: 1.5619614149934502

Epoch: 5| Step: 5
Training loss: 0.11652545630931854
Validation loss: 1.5472003862422

Epoch: 5| Step: 6
Training loss: 0.19611090421676636
Validation loss: 1.5953054799828479

Epoch: 5| Step: 7
Training loss: 0.1004447340965271
Validation loss: 1.5730030998106925

Epoch: 5| Step: 8
Training loss: 0.10294780880212784
Validation loss: 1.5579446964366461

Epoch: 5| Step: 9
Training loss: 0.1770113706588745
Validation loss: 1.5910180948113883

Epoch: 5| Step: 10
Training loss: 0.1342095136642456
Validation loss: 1.6112958885008288

Epoch: 444| Step: 0
Training loss: 0.13625821471214294
Validation loss: 1.6021656079958844

Epoch: 5| Step: 1
Training loss: 0.13183972239494324
Validation loss: 1.6568312388594433

Epoch: 5| Step: 2
Training loss: 0.08575908094644547
Validation loss: 1.6553000160442886

Epoch: 5| Step: 3
Training loss: 0.12372181564569473
Validation loss: 1.6513050704874017

Epoch: 5| Step: 4
Training loss: 0.1279890388250351
Validation loss: 1.6804093507028395

Epoch: 5| Step: 5
Training loss: 0.1568712741136551
Validation loss: 1.7007669159161147

Epoch: 5| Step: 6
Training loss: 0.1228066086769104
Validation loss: 1.6859469183029667

Epoch: 5| Step: 7
Training loss: 0.1087731346487999
Validation loss: 1.6659883004362865

Epoch: 5| Step: 8
Training loss: 0.11030498892068863
Validation loss: 1.6984212039619364

Epoch: 5| Step: 9
Training loss: 0.2174091637134552
Validation loss: 1.655437933501377

Epoch: 5| Step: 10
Training loss: 0.11954955756664276
Validation loss: 1.647669110246884

Epoch: 445| Step: 0
Training loss: 0.06406793743371964
Validation loss: 1.5892177833023893

Epoch: 5| Step: 1
Training loss: 0.1021023541688919
Validation loss: 1.6141842725456401

Epoch: 5| Step: 2
Training loss: 0.20980115234851837
Validation loss: 1.586677493587617

Epoch: 5| Step: 3
Training loss: 0.09978695213794708
Validation loss: 1.609998776707598

Epoch: 5| Step: 4
Training loss: 0.1236782819032669
Validation loss: 1.5533985399430799

Epoch: 5| Step: 5
Training loss: 0.10598480701446533
Validation loss: 1.6041993082210582

Epoch: 5| Step: 6
Training loss: 0.2047996073961258
Validation loss: 1.6011640948633994

Epoch: 5| Step: 7
Training loss: 0.12661226093769073
Validation loss: 1.6230524252819758

Epoch: 5| Step: 8
Training loss: 0.11190900951623917
Validation loss: 1.5973077589465725

Epoch: 5| Step: 9
Training loss: 0.13053838908672333
Validation loss: 1.6232275347555838

Epoch: 5| Step: 10
Training loss: 0.11318521201610565
Validation loss: 1.609487231059741

Epoch: 446| Step: 0
Training loss: 0.08315841108560562
Validation loss: 1.6233114298953806

Epoch: 5| Step: 1
Training loss: 0.11882190406322479
Validation loss: 1.65512369396866

Epoch: 5| Step: 2
Training loss: 0.13734987378120422
Validation loss: 1.6493109208281322

Epoch: 5| Step: 3
Training loss: 0.16774997115135193
Validation loss: 1.6496311695344987

Epoch: 5| Step: 4
Training loss: 0.13071557879447937
Validation loss: 1.6343134692920152

Epoch: 5| Step: 5
Training loss: 0.11151112616062164
Validation loss: 1.6207886331824846

Epoch: 5| Step: 6
Training loss: 0.09742490947246552
Validation loss: 1.6239935787775184

Epoch: 5| Step: 7
Training loss: 0.06075872853398323
Validation loss: 1.6110851431405673

Epoch: 5| Step: 8
Training loss: 0.0856061577796936
Validation loss: 1.6592652541334911

Epoch: 5| Step: 9
Training loss: 0.07322254031896591
Validation loss: 1.6290408244696997

Epoch: 5| Step: 10
Training loss: 0.19715732336044312
Validation loss: 1.6393533175991428

Epoch: 447| Step: 0
Training loss: 0.12008364498615265
Validation loss: 1.6524766773305914

Epoch: 5| Step: 1
Training loss: 0.1015729308128357
Validation loss: 1.6495581211582306

Epoch: 5| Step: 2
Training loss: 0.12685589492321014
Validation loss: 1.6177566833393549

Epoch: 5| Step: 3
Training loss: 0.1304711401462555
Validation loss: 1.653421546823235

Epoch: 5| Step: 4
Training loss: 0.07227016985416412
Validation loss: 1.623079333254086

Epoch: 5| Step: 5
Training loss: 0.06161761283874512
Validation loss: 1.640271020191972

Epoch: 5| Step: 6
Training loss: 0.06398985534906387
Validation loss: 1.6372035293168918

Epoch: 5| Step: 7
Training loss: 0.20063018798828125
Validation loss: 1.6619085086289274

Epoch: 5| Step: 8
Training loss: 0.06814108043909073
Validation loss: 1.6430799358634538

Epoch: 5| Step: 9
Training loss: 0.0816287249326706
Validation loss: 1.6664261779477518

Epoch: 5| Step: 10
Training loss: 0.05973469465970993
Validation loss: 1.6505940197616495

Epoch: 448| Step: 0
Training loss: 0.18339017033576965
Validation loss: 1.660793940226237

Epoch: 5| Step: 1
Training loss: 0.10660672187805176
Validation loss: 1.6686777889087636

Epoch: 5| Step: 2
Training loss: 0.1553974151611328
Validation loss: 1.6720387288319167

Epoch: 5| Step: 3
Training loss: 0.04966028779745102
Validation loss: 1.6646687510193034

Epoch: 5| Step: 4
Training loss: 0.07014355808496475
Validation loss: 1.669860524515952

Epoch: 5| Step: 5
Training loss: 0.08073322474956512
Validation loss: 1.622222505589967

Epoch: 5| Step: 6
Training loss: 0.11098562180995941
Validation loss: 1.6303193953729445

Epoch: 5| Step: 7
Training loss: 0.06784157454967499
Validation loss: 1.6294897730632494

Epoch: 5| Step: 8
Training loss: 0.10089985281229019
Validation loss: 1.6261086758746897

Epoch: 5| Step: 9
Training loss: 0.09674787521362305
Validation loss: 1.6472881583757297

Epoch: 5| Step: 10
Training loss: 0.048321809619665146
Validation loss: 1.5991496950067499

Epoch: 449| Step: 0
Training loss: 0.09750337898731232
Validation loss: 1.6196484411916425

Epoch: 5| Step: 1
Training loss: 0.13301405310630798
Validation loss: 1.6120218423105055

Epoch: 5| Step: 2
Training loss: 0.10762272030115128
Validation loss: 1.5885467131932576

Epoch: 5| Step: 3
Training loss: 0.11031796783208847
Validation loss: 1.562606325713537

Epoch: 5| Step: 4
Training loss: 0.09044010937213898
Validation loss: 1.553594086759834

Epoch: 5| Step: 5
Training loss: 0.14346082508563995
Validation loss: 1.5585882702181417

Epoch: 5| Step: 6
Training loss: 0.08021632581949234
Validation loss: 1.587015184023047

Epoch: 5| Step: 7
Training loss: 0.20671960711479187
Validation loss: 1.5914506361048708

Epoch: 5| Step: 8
Training loss: 0.12388887256383896
Validation loss: 1.6066260466011621

Epoch: 5| Step: 9
Training loss: 0.0946277529001236
Validation loss: 1.625236339466546

Epoch: 5| Step: 10
Training loss: 0.0687827616930008
Validation loss: 1.6392149694504277

Epoch: 450| Step: 0
Training loss: 0.2533470690250397
Validation loss: 1.6322001667432888

Epoch: 5| Step: 1
Training loss: 0.06402616202831268
Validation loss: 1.6336040817281252

Epoch: 5| Step: 2
Training loss: 0.06509869545698166
Validation loss: 1.627045239171674

Epoch: 5| Step: 3
Training loss: 0.07339878380298615
Validation loss: 1.622624861296787

Epoch: 5| Step: 4
Training loss: 0.08676169812679291
Validation loss: 1.6363059500212311

Epoch: 5| Step: 5
Training loss: 0.10502264648675919
Validation loss: 1.6285023561087988

Epoch: 5| Step: 6
Training loss: 0.08092093467712402
Validation loss: 1.6312025823900778

Epoch: 5| Step: 7
Training loss: 0.08560016751289368
Validation loss: 1.6297576042913622

Epoch: 5| Step: 8
Training loss: 0.09633489698171616
Validation loss: 1.651824361534529

Epoch: 5| Step: 9
Training loss: 0.1601742058992386
Validation loss: 1.6177809981889621

Epoch: 5| Step: 10
Training loss: 0.08899606764316559
Validation loss: 1.6247663587652228

Epoch: 451| Step: 0
Training loss: 0.06502814590930939
Validation loss: 1.6418294560524724

Epoch: 5| Step: 1
Training loss: 0.06978212296962738
Validation loss: 1.6315117536052581

Epoch: 5| Step: 2
Training loss: 0.10225919634103775
Validation loss: 1.6120962327526462

Epoch: 5| Step: 3
Training loss: 0.1434069126844406
Validation loss: 1.5963554472051642

Epoch: 5| Step: 4
Training loss: 0.11369641870260239
Validation loss: 1.5935859244356874

Epoch: 5| Step: 5
Training loss: 0.10264214128255844
Validation loss: 1.6365908627868981

Epoch: 5| Step: 6
Training loss: 0.07830555737018585
Validation loss: 1.6192647590432117

Epoch: 5| Step: 7
Training loss: 0.10207636654376984
Validation loss: 1.6318150899743522

Epoch: 5| Step: 8
Training loss: 0.06270582973957062
Validation loss: 1.6680481228777158

Epoch: 5| Step: 9
Training loss: 0.10835401713848114
Validation loss: 1.6370039050297072

Epoch: 5| Step: 10
Training loss: 0.19949127733707428
Validation loss: 1.6520788387585712

Epoch: 452| Step: 0
Training loss: 0.1101672425866127
Validation loss: 1.6442964897360852

Epoch: 5| Step: 1
Training loss: 0.12350279092788696
Validation loss: 1.6300317933482509

Epoch: 5| Step: 2
Training loss: 0.11417712271213531
Validation loss: 1.629415827412759

Epoch: 5| Step: 3
Training loss: 0.09880296885967255
Validation loss: 1.6168611100924912

Epoch: 5| Step: 4
Training loss: 0.08929356187582016
Validation loss: 1.601825475692749

Epoch: 5| Step: 5
Training loss: 0.11068663746118546
Validation loss: 1.6271765821723527

Epoch: 5| Step: 6
Training loss: 0.13753867149353027
Validation loss: 1.5963965821009811

Epoch: 5| Step: 7
Training loss: 0.13874788582324982
Validation loss: 1.61732526235683

Epoch: 5| Step: 8
Training loss: 0.09741709381341934
Validation loss: 1.6265631644956526

Epoch: 5| Step: 9
Training loss: 0.12771454453468323
Validation loss: 1.6197146010655228

Epoch: 5| Step: 10
Training loss: 0.21667300164699554
Validation loss: 1.6023236654138053

Epoch: 453| Step: 0
Training loss: 0.11555330455303192
Validation loss: 1.6135887727942517

Epoch: 5| Step: 1
Training loss: 0.0849972516298294
Validation loss: 1.5984144044178787

Epoch: 5| Step: 2
Training loss: 0.17149682343006134
Validation loss: 1.5781730067345403

Epoch: 5| Step: 3
Training loss: 0.10464845597743988
Validation loss: 1.6002120715315624

Epoch: 5| Step: 4
Training loss: 0.11236810684204102
Validation loss: 1.5699578126271565

Epoch: 5| Step: 5
Training loss: 0.12749138474464417
Validation loss: 1.58270642834325

Epoch: 5| Step: 6
Training loss: 0.11711877584457397
Validation loss: 1.5756538593640892

Epoch: 5| Step: 7
Training loss: 0.0767199844121933
Validation loss: 1.5822901302768337

Epoch: 5| Step: 8
Training loss: 0.1074376106262207
Validation loss: 1.605003123642296

Epoch: 5| Step: 9
Training loss: 0.18860013782978058
Validation loss: 1.5911763201477707

Epoch: 5| Step: 10
Training loss: 0.15039201080799103
Validation loss: 1.578705031384704

Epoch: 454| Step: 0
Training loss: 0.13163039088249207
Validation loss: 1.5924416062652424

Epoch: 5| Step: 1
Training loss: 0.1069578155875206
Validation loss: 1.580139237065469

Epoch: 5| Step: 2
Training loss: 0.12292888015508652
Validation loss: 1.588191011900543

Epoch: 5| Step: 3
Training loss: 0.08024521917104721
Validation loss: 1.572747903485452

Epoch: 5| Step: 4
Training loss: 0.07529842108488083
Validation loss: 1.6028151012236072

Epoch: 5| Step: 5
Training loss: 0.1279831826686859
Validation loss: 1.6067909233031734

Epoch: 5| Step: 6
Training loss: 0.19704455137252808
Validation loss: 1.6000978241684616

Epoch: 5| Step: 7
Training loss: 0.08072245121002197
Validation loss: 1.6007586743241997

Epoch: 5| Step: 8
Training loss: 0.10904407501220703
Validation loss: 1.5920031186073058

Epoch: 5| Step: 9
Training loss: 0.06908814609050751
Validation loss: 1.5799723773874261

Epoch: 5| Step: 10
Training loss: 0.05925097316503525
Validation loss: 1.583119038612612

Epoch: 455| Step: 0
Training loss: 0.11129410564899445
Validation loss: 1.6332670591210807

Epoch: 5| Step: 1
Training loss: 0.1084529384970665
Validation loss: 1.6375225628575971

Epoch: 5| Step: 2
Training loss: 0.08492560684680939
Validation loss: 1.631663755703998

Epoch: 5| Step: 3
Training loss: 0.19485150277614594
Validation loss: 1.6468909158501575

Epoch: 5| Step: 4
Training loss: 0.06719198077917099
Validation loss: 1.6188628878644717

Epoch: 5| Step: 5
Training loss: 0.07176829129457474
Validation loss: 1.6235717522200717

Epoch: 5| Step: 6
Training loss: 0.07808926701545715
Validation loss: 1.6402581725069272

Epoch: 5| Step: 7
Training loss: 0.1295110434293747
Validation loss: 1.6453037415781329

Epoch: 5| Step: 8
Training loss: 0.12920837104320526
Validation loss: 1.640395211917098

Epoch: 5| Step: 9
Training loss: 0.11094214022159576
Validation loss: 1.6573140236639208

Epoch: 5| Step: 10
Training loss: 0.06883662939071655
Validation loss: 1.6735645737699283

Epoch: 456| Step: 0
Training loss: 0.09388694912195206
Validation loss: 1.666712612234136

Epoch: 5| Step: 1
Training loss: 0.10295236110687256
Validation loss: 1.6651517396332116

Epoch: 5| Step: 2
Training loss: 0.13018710911273956
Validation loss: 1.6458674246265041

Epoch: 5| Step: 3
Training loss: 0.10731033980846405
Validation loss: 1.6729506766924294

Epoch: 5| Step: 4
Training loss: 0.18023264408111572
Validation loss: 1.6569314259354786

Epoch: 5| Step: 5
Training loss: 0.07153575122356415
Validation loss: 1.639731881439045

Epoch: 5| Step: 6
Training loss: 0.07436954975128174
Validation loss: 1.6341908022921572

Epoch: 5| Step: 7
Training loss: 0.0962962731719017
Validation loss: 1.6445618829419535

Epoch: 5| Step: 8
Training loss: 0.13415727019309998
Validation loss: 1.6279167295784078

Epoch: 5| Step: 9
Training loss: 0.07800235599279404
Validation loss: 1.6201559535918697

Epoch: 5| Step: 10
Training loss: 0.0903170108795166
Validation loss: 1.5993847077892673

Epoch: 457| Step: 0
Training loss: 0.1146966964006424
Validation loss: 1.6217991370026783

Epoch: 5| Step: 1
Training loss: 0.1426219642162323
Validation loss: 1.6094183229630994

Epoch: 5| Step: 2
Training loss: 0.17505493760108948
Validation loss: 1.6167597565599667

Epoch: 5| Step: 3
Training loss: 0.09420114755630493
Validation loss: 1.610521972820323

Epoch: 5| Step: 4
Training loss: 0.09302438795566559
Validation loss: 1.6523944729117936

Epoch: 5| Step: 5
Training loss: 0.0872119665145874
Validation loss: 1.6474173543273762

Epoch: 5| Step: 6
Training loss: 0.10091555118560791
Validation loss: 1.6382192270730132

Epoch: 5| Step: 7
Training loss: 0.10216257721185684
Validation loss: 1.6559225987362605

Epoch: 5| Step: 8
Training loss: 0.08642177283763885
Validation loss: 1.6348287879779775

Epoch: 5| Step: 9
Training loss: 0.0871627926826477
Validation loss: 1.6578918990268503

Epoch: 5| Step: 10
Training loss: 0.22547651827335358
Validation loss: 1.6288626040181806

Epoch: 458| Step: 0
Training loss: 0.07081331312656403
Validation loss: 1.634376081087256

Epoch: 5| Step: 1
Training loss: 0.2202434241771698
Validation loss: 1.6157862319741199

Epoch: 5| Step: 2
Training loss: 0.05428898334503174
Validation loss: 1.5784621828345842

Epoch: 5| Step: 3
Training loss: 0.09396626055240631
Validation loss: 1.5602922349847772

Epoch: 5| Step: 4
Training loss: 0.10223257541656494
Validation loss: 1.578225854904421

Epoch: 5| Step: 5
Training loss: 0.1018461212515831
Validation loss: 1.5481445212518015

Epoch: 5| Step: 6
Training loss: 0.09235069155693054
Validation loss: 1.5717173507136684

Epoch: 5| Step: 7
Training loss: 0.13700927793979645
Validation loss: 1.560686408832509

Epoch: 5| Step: 8
Training loss: 0.1530609428882599
Validation loss: 1.6049218613614318

Epoch: 5| Step: 9
Training loss: 0.07783319801092148
Validation loss: 1.603018783753918

Epoch: 5| Step: 10
Training loss: 0.11251255124807358
Validation loss: 1.6230614992880052

Epoch: 459| Step: 0
Training loss: 0.10957033932209015
Validation loss: 1.6117975122185164

Epoch: 5| Step: 1
Training loss: 0.08595933765172958
Validation loss: 1.6463882038670201

Epoch: 5| Step: 2
Training loss: 0.06437378376722336
Validation loss: 1.6117398610679052

Epoch: 5| Step: 3
Training loss: 0.07738805562257767
Validation loss: 1.6471771129997828

Epoch: 5| Step: 4
Training loss: 0.14102229475975037
Validation loss: 1.6538547136450326

Epoch: 5| Step: 5
Training loss: 0.2009551078081131
Validation loss: 1.6791106731660905

Epoch: 5| Step: 6
Training loss: 0.13006752729415894
Validation loss: 1.6611232283294841

Epoch: 5| Step: 7
Training loss: 0.14709191024303436
Validation loss: 1.668525964983048

Epoch: 5| Step: 8
Training loss: 0.14420856535434723
Validation loss: 1.6517235220119517

Epoch: 5| Step: 9
Training loss: 0.06593675911426544
Validation loss: 1.6574595551336966

Epoch: 5| Step: 10
Training loss: 0.11797944456338882
Validation loss: 1.6516788275011125

Epoch: 460| Step: 0
Training loss: 0.07600881159305573
Validation loss: 1.6560264043910529

Epoch: 5| Step: 1
Training loss: 0.15678346157073975
Validation loss: 1.6423045166077153

Epoch: 5| Step: 2
Training loss: 0.1167084127664566
Validation loss: 1.6082886290806595

Epoch: 5| Step: 3
Training loss: 0.08543809503316879
Validation loss: 1.6063139861629856

Epoch: 5| Step: 4
Training loss: 0.08522669225931168
Validation loss: 1.5875832329514206

Epoch: 5| Step: 5
Training loss: 0.12253148853778839
Validation loss: 1.598890555802212

Epoch: 5| Step: 6
Training loss: 0.10895373672246933
Validation loss: 1.5769633823825466

Epoch: 5| Step: 7
Training loss: 0.11616799980401993
Validation loss: 1.5893571812619445

Epoch: 5| Step: 8
Training loss: 0.1638261377811432
Validation loss: 1.5909491380055745

Epoch: 5| Step: 9
Training loss: 0.09166621416807175
Validation loss: 1.632790018153447

Epoch: 5| Step: 10
Training loss: 0.07174676656723022
Validation loss: 1.633660145985183

Epoch: 461| Step: 0
Training loss: 0.09460531175136566
Validation loss: 1.6484642400536487

Epoch: 5| Step: 1
Training loss: 0.12056238949298859
Validation loss: 1.6552189998729254

Epoch: 5| Step: 2
Training loss: 0.06518961489200592
Validation loss: 1.6550267563071301

Epoch: 5| Step: 3
Training loss: 0.12531669437885284
Validation loss: 1.6563742673525246

Epoch: 5| Step: 4
Training loss: 0.07690344005823135
Validation loss: 1.6714673144842989

Epoch: 5| Step: 5
Training loss: 0.07464095950126648
Validation loss: 1.6741152630057385

Epoch: 5| Step: 6
Training loss: 0.08460422605276108
Validation loss: 1.6812159290877722

Epoch: 5| Step: 7
Training loss: 0.11584009230136871
Validation loss: 1.7224743443150674

Epoch: 5| Step: 8
Training loss: 0.07191693037748337
Validation loss: 1.7013425288661834

Epoch: 5| Step: 9
Training loss: 0.0948650985956192
Validation loss: 1.6972081392042098

Epoch: 5| Step: 10
Training loss: 0.23017410933971405
Validation loss: 1.6771414279937744

Epoch: 462| Step: 0
Training loss: 0.11181499809026718
Validation loss: 1.6880589287768129

Epoch: 5| Step: 1
Training loss: 0.0552494041621685
Validation loss: 1.6872614455479447

Epoch: 5| Step: 2
Training loss: 0.13100695610046387
Validation loss: 1.635151429842877

Epoch: 5| Step: 3
Training loss: 0.11152766644954681
Validation loss: 1.6270607979066911

Epoch: 5| Step: 4
Training loss: 0.09451619535684586
Validation loss: 1.6020928595655708

Epoch: 5| Step: 5
Training loss: 0.23531274497509003
Validation loss: 1.6110180295923704

Epoch: 5| Step: 6
Training loss: 0.14574602246284485
Validation loss: 1.6010868280164656

Epoch: 5| Step: 7
Training loss: 0.11588206142187119
Validation loss: 1.6001135046764086

Epoch: 5| Step: 8
Training loss: 0.09378284960985184
Validation loss: 1.6122803893140567

Epoch: 5| Step: 9
Training loss: 0.07737771421670914
Validation loss: 1.5901426653708182

Epoch: 5| Step: 10
Training loss: 0.13347570598125458
Validation loss: 1.6126682783967705

Epoch: 463| Step: 0
Training loss: 0.08046220242977142
Validation loss: 1.6307977681518884

Epoch: 5| Step: 1
Training loss: 0.12332324683666229
Validation loss: 1.6833828674849642

Epoch: 5| Step: 2
Training loss: 0.08239907026290894
Validation loss: 1.663932615710843

Epoch: 5| Step: 3
Training loss: 0.1497373878955841
Validation loss: 1.6727035712170344

Epoch: 5| Step: 4
Training loss: 0.09352288395166397
Validation loss: 1.6452555387250838

Epoch: 5| Step: 5
Training loss: 0.08979775011539459
Validation loss: 1.6297636903742307

Epoch: 5| Step: 6
Training loss: 0.06923483312129974
Validation loss: 1.5988540431504608

Epoch: 5| Step: 7
Training loss: 0.1952100694179535
Validation loss: 1.6241866491174186

Epoch: 5| Step: 8
Training loss: 0.0962173268198967
Validation loss: 1.6314968973077753

Epoch: 5| Step: 9
Training loss: 0.11582956463098526
Validation loss: 1.608701572623304

Epoch: 5| Step: 10
Training loss: 0.1290159821510315
Validation loss: 1.5983083325047647

Epoch: 464| Step: 0
Training loss: 0.09260336309671402
Validation loss: 1.614368664321079

Epoch: 5| Step: 1
Training loss: 0.08151088654994965
Validation loss: 1.63679414667109

Epoch: 5| Step: 2
Training loss: 0.16247043013572693
Validation loss: 1.593286673227946

Epoch: 5| Step: 3
Training loss: 0.11747302114963531
Validation loss: 1.6059597769091207

Epoch: 5| Step: 4
Training loss: 0.11887607723474503
Validation loss: 1.60488760471344

Epoch: 5| Step: 5
Training loss: 0.1295131891965866
Validation loss: 1.6188097653850433

Epoch: 5| Step: 6
Training loss: 0.07138264179229736
Validation loss: 1.6030678313265565

Epoch: 5| Step: 7
Training loss: 0.13592171669006348
Validation loss: 1.5972505987331431

Epoch: 5| Step: 8
Training loss: 0.09610039740800858
Validation loss: 1.6256853906057214

Epoch: 5| Step: 9
Training loss: 0.18274536728858948
Validation loss: 1.620134053691741

Epoch: 5| Step: 10
Training loss: 0.09132155030965805
Validation loss: 1.617807335751031

Epoch: 465| Step: 0
Training loss: 0.0707583874464035
Validation loss: 1.6307734648386638

Epoch: 5| Step: 1
Training loss: 0.16888481378555298
Validation loss: 1.6262696584065754

Epoch: 5| Step: 2
Training loss: 0.05754101276397705
Validation loss: 1.628327145371386

Epoch: 5| Step: 3
Training loss: 0.09112559258937836
Validation loss: 1.6157875061035156

Epoch: 5| Step: 4
Training loss: 0.09768147766590118
Validation loss: 1.6200167094507525

Epoch: 5| Step: 5
Training loss: 0.12355790287256241
Validation loss: 1.6138758595271776

Epoch: 5| Step: 6
Training loss: 0.09411655366420746
Validation loss: 1.605274813149565

Epoch: 5| Step: 7
Training loss: 0.0668218731880188
Validation loss: 1.59764664916582

Epoch: 5| Step: 8
Training loss: 0.10393866151571274
Validation loss: 1.570470090835325

Epoch: 5| Step: 9
Training loss: 0.08916816115379333
Validation loss: 1.5962261922897831

Epoch: 5| Step: 10
Training loss: 0.10547488182783127
Validation loss: 1.6157595944660965

Epoch: 466| Step: 0
Training loss: 0.07242169231176376
Validation loss: 1.5989242151219358

Epoch: 5| Step: 1
Training loss: 0.07306141406297684
Validation loss: 1.5924181066533571

Epoch: 5| Step: 2
Training loss: 0.08041870594024658
Validation loss: 1.6053048179995628

Epoch: 5| Step: 3
Training loss: 0.09343934059143066
Validation loss: 1.6022350871434776

Epoch: 5| Step: 4
Training loss: 0.1801333725452423
Validation loss: 1.5865367445894467

Epoch: 5| Step: 5
Training loss: 0.09034886211156845
Validation loss: 1.5871409664871872

Epoch: 5| Step: 6
Training loss: 0.08642927557229996
Validation loss: 1.615212566109114

Epoch: 5| Step: 7
Training loss: 0.14537326991558075
Validation loss: 1.5847075780232747

Epoch: 5| Step: 8
Training loss: 0.10968919098377228
Validation loss: 1.586421484588295

Epoch: 5| Step: 9
Training loss: 0.1033610850572586
Validation loss: 1.59161772266511

Epoch: 5| Step: 10
Training loss: 0.07394498586654663
Validation loss: 1.6043819624890563

Epoch: 467| Step: 0
Training loss: 0.2159854918718338
Validation loss: 1.5551258633213658

Epoch: 5| Step: 1
Training loss: 0.08986796438694
Validation loss: 1.5890369312737578

Epoch: 5| Step: 2
Training loss: 0.10037758201360703
Validation loss: 1.5822234730566702

Epoch: 5| Step: 3
Training loss: 0.06366945803165436
Validation loss: 1.587661103535724

Epoch: 5| Step: 4
Training loss: 0.1420784741640091
Validation loss: 1.5835383656204387

Epoch: 5| Step: 5
Training loss: 0.0861460268497467
Validation loss: 1.5642329877422703

Epoch: 5| Step: 6
Training loss: 0.07619979232549667
Validation loss: 1.584918575261229

Epoch: 5| Step: 7
Training loss: 0.12153518199920654
Validation loss: 1.5637435810540312

Epoch: 5| Step: 8
Training loss: 0.07708271592855453
Validation loss: 1.561164781611453

Epoch: 5| Step: 9
Training loss: 0.14291658997535706
Validation loss: 1.5687651326579433

Epoch: 5| Step: 10
Training loss: 0.16270329058170319
Validation loss: 1.5800058059794928

Epoch: 468| Step: 0
Training loss: 0.06322721391916275
Validation loss: 1.5498014944855885

Epoch: 5| Step: 1
Training loss: 0.08420629799365997
Validation loss: 1.571383935148998

Epoch: 5| Step: 2
Training loss: 0.1776963174343109
Validation loss: 1.593740690139032

Epoch: 5| Step: 3
Training loss: 0.1084970012307167
Validation loss: 1.5613627831141155

Epoch: 5| Step: 4
Training loss: 0.12632450461387634
Validation loss: 1.5871680334050169

Epoch: 5| Step: 5
Training loss: 0.12022974342107773
Validation loss: 1.6380319851700977

Epoch: 5| Step: 6
Training loss: 0.11961235851049423
Validation loss: 1.629435020749287

Epoch: 5| Step: 7
Training loss: 0.19110065698623657
Validation loss: 1.6074382028272074

Epoch: 5| Step: 8
Training loss: 0.04687267541885376
Validation loss: 1.6100530560298631

Epoch: 5| Step: 9
Training loss: 0.05653499811887741
Validation loss: 1.6131048112787225

Epoch: 5| Step: 10
Training loss: 0.05668129026889801
Validation loss: 1.6299535138632661

Epoch: 469| Step: 0
Training loss: 0.15074938535690308
Validation loss: 1.6455655174870645

Epoch: 5| Step: 1
Training loss: 0.07279225438833237
Validation loss: 1.6258273381058888

Epoch: 5| Step: 2
Training loss: 0.06113126128911972
Validation loss: 1.6341399338937574

Epoch: 5| Step: 3
Training loss: 0.07756903767585754
Validation loss: 1.6214374560181812

Epoch: 5| Step: 4
Training loss: 0.09525707364082336
Validation loss: 1.6351195907080045

Epoch: 5| Step: 5
Training loss: 0.08085863292217255
Validation loss: 1.6152607958803895

Epoch: 5| Step: 6
Training loss: 0.1508844643831253
Validation loss: 1.5993223959399807

Epoch: 5| Step: 7
Training loss: 0.07761800289154053
Validation loss: 1.6259970703432638

Epoch: 5| Step: 8
Training loss: 0.06418608129024506
Validation loss: 1.642786677165698

Epoch: 5| Step: 9
Training loss: 0.10470889508724213
Validation loss: 1.6293198741892332

Epoch: 5| Step: 10
Training loss: 0.1064264178276062
Validation loss: 1.6625617768174858

Epoch: 470| Step: 0
Training loss: 0.1239876002073288
Validation loss: 1.6233555898871472

Epoch: 5| Step: 1
Training loss: 0.0519959032535553
Validation loss: 1.6450162767082133

Epoch: 5| Step: 2
Training loss: 0.07541988044977188
Validation loss: 1.6359224422003633

Epoch: 5| Step: 3
Training loss: 0.08004069328308105
Validation loss: 1.6450970403609737

Epoch: 5| Step: 4
Training loss: 0.11228930950164795
Validation loss: 1.6295959167583014

Epoch: 5| Step: 5
Training loss: 0.06763072311878204
Validation loss: 1.6343203116488714

Epoch: 5| Step: 6
Training loss: 0.060040056705474854
Validation loss: 1.6235841115315754

Epoch: 5| Step: 7
Training loss: 0.09388898313045502
Validation loss: 1.5905618533011405

Epoch: 5| Step: 8
Training loss: 0.20462504029273987
Validation loss: 1.5818828216163061

Epoch: 5| Step: 9
Training loss: 0.09877345710992813
Validation loss: 1.5877784093221028

Epoch: 5| Step: 10
Training loss: 0.08281029760837555
Validation loss: 1.5718778358992709

Epoch: 471| Step: 0
Training loss: 0.08395249396562576
Validation loss: 1.5741239183692521

Epoch: 5| Step: 1
Training loss: 0.18671216070652008
Validation loss: 1.5818950886367469

Epoch: 5| Step: 2
Training loss: 0.10555309057235718
Validation loss: 1.5723326334389307

Epoch: 5| Step: 3
Training loss: 0.07321139425039291
Validation loss: 1.6167868478323824

Epoch: 5| Step: 4
Training loss: 0.05696796625852585
Validation loss: 1.5765600537741056

Epoch: 5| Step: 5
Training loss: 0.06601060926914215
Validation loss: 1.5863204489472091

Epoch: 5| Step: 6
Training loss: 0.09497908502817154
Validation loss: 1.5800199636849024

Epoch: 5| Step: 7
Training loss: 0.11377571523189545
Validation loss: 1.5837901843491422

Epoch: 5| Step: 8
Training loss: 0.07570703327655792
Validation loss: 1.5909024079640706

Epoch: 5| Step: 9
Training loss: 0.12002965062856674
Validation loss: 1.630353509738881

Epoch: 5| Step: 10
Training loss: 0.07588406652212143
Validation loss: 1.5920024533425607

Epoch: 472| Step: 0
Training loss: 0.08896569162607193
Validation loss: 1.610353890285697

Epoch: 5| Step: 1
Training loss: 0.07876864075660706
Validation loss: 1.6123080715056388

Epoch: 5| Step: 2
Training loss: 0.06379567086696625
Validation loss: 1.6133482392116258

Epoch: 5| Step: 3
Training loss: 0.0962037593126297
Validation loss: 1.6065686287418488

Epoch: 5| Step: 4
Training loss: 0.052766673266887665
Validation loss: 1.5731573681677542

Epoch: 5| Step: 5
Training loss: 0.09322142601013184
Validation loss: 1.6075080607527046

Epoch: 5| Step: 6
Training loss: 0.09313325583934784
Validation loss: 1.5970601932976836

Epoch: 5| Step: 7
Training loss: 0.10686856508255005
Validation loss: 1.5821041009759391

Epoch: 5| Step: 8
Training loss: 0.12521764636039734
Validation loss: 1.6105542926378147

Epoch: 5| Step: 9
Training loss: 0.07351301610469818
Validation loss: 1.6180376775803105

Epoch: 5| Step: 10
Training loss: 0.23055040836334229
Validation loss: 1.5766384640047628

Epoch: 473| Step: 0
Training loss: 0.059461452066898346
Validation loss: 1.5920992846130042

Epoch: 5| Step: 1
Training loss: 0.10905442386865616
Validation loss: 1.6075232028961182

Epoch: 5| Step: 2
Training loss: 0.09530695527791977
Validation loss: 1.5889646334032859

Epoch: 5| Step: 3
Training loss: 0.10900070518255234
Validation loss: 1.6059885396752307

Epoch: 5| Step: 4
Training loss: 0.05388019233942032
Validation loss: 1.5766051994856967

Epoch: 5| Step: 5
Training loss: 0.06412915885448456
Validation loss: 1.5993635667267667

Epoch: 5| Step: 6
Training loss: 0.0862317681312561
Validation loss: 1.5733541865502634

Epoch: 5| Step: 7
Training loss: 0.06449337303638458
Validation loss: 1.574960902173032

Epoch: 5| Step: 8
Training loss: 0.06949100643396378
Validation loss: 1.5438879395043978

Epoch: 5| Step: 9
Training loss: 0.21410751342773438
Validation loss: 1.5640819175269014

Epoch: 5| Step: 10
Training loss: 0.07643435895442963
Validation loss: 1.5494111763533724

Epoch: 474| Step: 0
Training loss: 0.05103442072868347
Validation loss: 1.5372139266742173

Epoch: 5| Step: 1
Training loss: 0.07963140308856964
Validation loss: 1.578505713452575

Epoch: 5| Step: 2
Training loss: 0.07887209206819534
Validation loss: 1.5814165274302165

Epoch: 5| Step: 3
Training loss: 0.05758175998926163
Validation loss: 1.575061337281299

Epoch: 5| Step: 4
Training loss: 0.10594198852777481
Validation loss: 1.5707815180542648

Epoch: 5| Step: 5
Training loss: 0.1116039901971817
Validation loss: 1.617996177365703

Epoch: 5| Step: 6
Training loss: 0.10774588584899902
Validation loss: 1.5866946738253358

Epoch: 5| Step: 7
Training loss: 0.08017931878566742
Validation loss: 1.5670573519122215

Epoch: 5| Step: 8
Training loss: 0.0725691094994545
Validation loss: 1.60225558921855

Epoch: 5| Step: 9
Training loss: 0.18296799063682556
Validation loss: 1.5780682589418145

Epoch: 5| Step: 10
Training loss: 0.136071115732193
Validation loss: 1.5883987693376438

Epoch: 475| Step: 0
Training loss: 0.07882902026176453
Validation loss: 1.609455015069695

Epoch: 5| Step: 1
Training loss: 0.09935890138149261
Validation loss: 1.6044452485217844

Epoch: 5| Step: 2
Training loss: 0.07827137410640717
Validation loss: 1.5930012605523551

Epoch: 5| Step: 3
Training loss: 0.10037191212177277
Validation loss: 1.6003954359280166

Epoch: 5| Step: 4
Training loss: 0.07986540347337723
Validation loss: 1.6097032562378915

Epoch: 5| Step: 5
Training loss: 0.17390501499176025
Validation loss: 1.6108647790006412

Epoch: 5| Step: 6
Training loss: 0.10180497169494629
Validation loss: 1.6159917654529694

Epoch: 5| Step: 7
Training loss: 0.11007507890462875
Validation loss: 1.5883964377064859

Epoch: 5| Step: 8
Training loss: 0.09190059453248978
Validation loss: 1.598840643000859

Epoch: 5| Step: 9
Training loss: 0.10486204922199249
Validation loss: 1.6036661709508588

Epoch: 5| Step: 10
Training loss: 0.07373037934303284
Validation loss: 1.6062746983702465

Epoch: 476| Step: 0
Training loss: 0.11323802173137665
Validation loss: 1.5904932304095196

Epoch: 5| Step: 1
Training loss: 0.059572458267211914
Validation loss: 1.6023723502312937

Epoch: 5| Step: 2
Training loss: 0.09463363885879517
Validation loss: 1.5746355133671914

Epoch: 5| Step: 3
Training loss: 0.10441818088293076
Validation loss: 1.5705916253469323

Epoch: 5| Step: 4
Training loss: 0.07179872691631317
Validation loss: 1.6045263441660071

Epoch: 5| Step: 5
Training loss: 0.12873966991901398
Validation loss: 1.5497942099007227

Epoch: 5| Step: 6
Training loss: 0.17272867262363434
Validation loss: 1.5591480937055362

Epoch: 5| Step: 7
Training loss: 0.13318891823291779
Validation loss: 1.5478368779664398

Epoch: 5| Step: 8
Training loss: 0.08021970093250275
Validation loss: 1.551526141423051

Epoch: 5| Step: 9
Training loss: 0.10549776256084442
Validation loss: 1.572666795023026

Epoch: 5| Step: 10
Training loss: 0.10485385358333588
Validation loss: 1.5575839255445747

Epoch: 477| Step: 0
Training loss: 0.12229220569133759
Validation loss: 1.563530824517691

Epoch: 5| Step: 1
Training loss: 0.08693147450685501
Validation loss: 1.572905005947236

Epoch: 5| Step: 2
Training loss: 0.1219022125005722
Validation loss: 1.5451578491477556

Epoch: 5| Step: 3
Training loss: 0.06243843957781792
Validation loss: 1.5605720948147517

Epoch: 5| Step: 4
Training loss: 0.04890722781419754
Validation loss: 1.5576393168459657

Epoch: 5| Step: 5
Training loss: 0.1189238578081131
Validation loss: 1.5704966168249808

Epoch: 5| Step: 6
Training loss: 0.09114938974380493
Validation loss: 1.5713119737563594

Epoch: 5| Step: 7
Training loss: 0.12500309944152832
Validation loss: 1.573402694476548

Epoch: 5| Step: 8
Training loss: 0.09017539024353027
Validation loss: 1.5695740202421784

Epoch: 5| Step: 9
Training loss: 0.21768417954444885
Validation loss: 1.5714170663587508

Epoch: 5| Step: 10
Training loss: 0.09238976240158081
Validation loss: 1.5841700941003778

Epoch: 478| Step: 0
Training loss: 0.2923823595046997
Validation loss: 1.5850150803084015

Epoch: 5| Step: 1
Training loss: 0.06704787909984589
Validation loss: 1.5610753823352117

Epoch: 5| Step: 2
Training loss: 0.054896824061870575
Validation loss: 1.569566995866837

Epoch: 5| Step: 3
Training loss: 0.08554704487323761
Validation loss: 1.5691149100180595

Epoch: 5| Step: 4
Training loss: 0.07490246742963791
Validation loss: 1.566071815388177

Epoch: 5| Step: 5
Training loss: 0.11012504994869232
Validation loss: 1.5692336764386905

Epoch: 5| Step: 6
Training loss: 0.11878421157598495
Validation loss: 1.5755740320810707

Epoch: 5| Step: 7
Training loss: 0.08566776663064957
Validation loss: 1.603394530152762

Epoch: 5| Step: 8
Training loss: 0.08512166142463684
Validation loss: 1.6083462135766142

Epoch: 5| Step: 9
Training loss: 0.08427298069000244
Validation loss: 1.5738954556885587

Epoch: 5| Step: 10
Training loss: 0.07710213959217072
Validation loss: 1.6180144125415432

Epoch: 479| Step: 0
Training loss: 0.07965217530727386
Validation loss: 1.6034747528773483

Epoch: 5| Step: 1
Training loss: 0.05911948159337044
Validation loss: 1.6002451950503933

Epoch: 5| Step: 2
Training loss: 0.08606100082397461
Validation loss: 1.6154963278001355

Epoch: 5| Step: 3
Training loss: 0.07843051105737686
Validation loss: 1.6299075759867185

Epoch: 5| Step: 4
Training loss: 0.09605662524700165
Validation loss: 1.6226622199499479

Epoch: 5| Step: 5
Training loss: 0.051471810787916183
Validation loss: 1.6167648402593469

Epoch: 5| Step: 6
Training loss: 0.07775727659463882
Validation loss: 1.6113986379356795

Epoch: 5| Step: 7
Training loss: 0.08670975267887115
Validation loss: 1.5998597350171817

Epoch: 5| Step: 8
Training loss: 0.16182830929756165
Validation loss: 1.5678788282537972

Epoch: 5| Step: 9
Training loss: 0.07289557158946991
Validation loss: 1.57710261114182

Epoch: 5| Step: 10
Training loss: 0.06890908628702164
Validation loss: 1.586722154771128

Epoch: 480| Step: 0
Training loss: 0.08354474604129791
Validation loss: 1.6065358923327537

Epoch: 5| Step: 1
Training loss: 0.10580827295780182
Validation loss: 1.639461491697578

Epoch: 5| Step: 2
Training loss: 0.08431457728147507
Validation loss: 1.6430309357181672

Epoch: 5| Step: 3
Training loss: 0.06203131750226021
Validation loss: 1.6162152444162676

Epoch: 5| Step: 4
Training loss: 0.20179228484630585
Validation loss: 1.6368574506493025

Epoch: 5| Step: 5
Training loss: 0.062452562153339386
Validation loss: 1.592538329862779

Epoch: 5| Step: 6
Training loss: 0.0643845722079277
Validation loss: 1.5977808865167762

Epoch: 5| Step: 7
Training loss: 0.10032167285680771
Validation loss: 1.5995209140162314

Epoch: 5| Step: 8
Training loss: 0.09841954708099365
Validation loss: 1.60575387682966

Epoch: 5| Step: 9
Training loss: 0.052261434495449066
Validation loss: 1.5811748107274373

Epoch: 5| Step: 10
Training loss: 0.08696159720420837
Validation loss: 1.585570937843733

Epoch: 481| Step: 0
Training loss: 0.08441464602947235
Validation loss: 1.5621693159944268

Epoch: 5| Step: 1
Training loss: 0.07406401634216309
Validation loss: 1.5889055728912354

Epoch: 5| Step: 2
Training loss: 0.06379499286413193
Validation loss: 1.5489671230316162

Epoch: 5| Step: 3
Training loss: 0.07666130363941193
Validation loss: 1.5762760895554737

Epoch: 5| Step: 4
Training loss: 0.12240970134735107
Validation loss: 1.5595134996598767

Epoch: 5| Step: 5
Training loss: 0.0972740650177002
Validation loss: 1.571339835402786

Epoch: 5| Step: 6
Training loss: 0.17146775126457214
Validation loss: 1.580599602832589

Epoch: 5| Step: 7
Training loss: 0.07006284594535828
Validation loss: 1.58022722377572

Epoch: 5| Step: 8
Training loss: 0.0752062052488327
Validation loss: 1.603192936989569

Epoch: 5| Step: 9
Training loss: 0.04757396876811981
Validation loss: 1.5871965167342976

Epoch: 5| Step: 10
Training loss: 0.10854414105415344
Validation loss: 1.6131791043025192

Epoch: 482| Step: 0
Training loss: 0.08294282108545303
Validation loss: 1.5772002538045247

Epoch: 5| Step: 1
Training loss: 0.06705175340175629
Validation loss: 1.6363546707296883

Epoch: 5| Step: 2
Training loss: 0.11701905727386475
Validation loss: 1.6170080143918273

Epoch: 5| Step: 3
Training loss: 0.05467884987592697
Validation loss: 1.6298864221060148

Epoch: 5| Step: 4
Training loss: 0.09848883002996445
Validation loss: 1.6194999749942491

Epoch: 5| Step: 5
Training loss: 0.08274783194065094
Validation loss: 1.6154461958075081

Epoch: 5| Step: 6
Training loss: 0.0896739587187767
Validation loss: 1.5906827924072102

Epoch: 5| Step: 7
Training loss: 0.07159073650836945
Validation loss: 1.6239844265804495

Epoch: 5| Step: 8
Training loss: 0.10369382053613663
Validation loss: 1.6011649600921138

Epoch: 5| Step: 9
Training loss: 0.1823863834142685
Validation loss: 1.6029328255243198

Epoch: 5| Step: 10
Training loss: 0.08822297304868698
Validation loss: 1.6164861045857912

Epoch: 483| Step: 0
Training loss: 0.09906575083732605
Validation loss: 1.6244317472621959

Epoch: 5| Step: 1
Training loss: 0.10244512557983398
Validation loss: 1.608576004223157

Epoch: 5| Step: 2
Training loss: 0.12530066072940826
Validation loss: 1.6050025622049968

Epoch: 5| Step: 3
Training loss: 0.049361132085323334
Validation loss: 1.588411404240516

Epoch: 5| Step: 4
Training loss: 0.07032229006290436
Validation loss: 1.5682647946060344

Epoch: 5| Step: 5
Training loss: 0.05754870921373367
Validation loss: 1.584787098310327

Epoch: 5| Step: 6
Training loss: 0.05889872461557388
Validation loss: 1.57323653979968

Epoch: 5| Step: 7
Training loss: 0.21123743057250977
Validation loss: 1.566711159162624

Epoch: 5| Step: 8
Training loss: 0.1580779105424881
Validation loss: 1.5884473541731476

Epoch: 5| Step: 9
Training loss: 0.0705924779176712
Validation loss: 1.5812456550136689

Epoch: 5| Step: 10
Training loss: 0.10083246976137161
Validation loss: 1.5594783354830999

Epoch: 484| Step: 0
Training loss: 0.05383498594164848
Validation loss: 1.557981453916078

Epoch: 5| Step: 1
Training loss: 0.07291437685489655
Validation loss: 1.545452138429047

Epoch: 5| Step: 2
Training loss: 0.13615503907203674
Validation loss: 1.5438360321906306

Epoch: 5| Step: 3
Training loss: 0.1218913346529007
Validation loss: 1.5609509560369677

Epoch: 5| Step: 4
Training loss: 0.07657917588949203
Validation loss: 1.5615156222415227

Epoch: 5| Step: 5
Training loss: 0.06931162625551224
Validation loss: 1.5309506680375786

Epoch: 5| Step: 6
Training loss: 0.10736827552318573
Validation loss: 1.5424554117264286

Epoch: 5| Step: 7
Training loss: 0.09888898581266403
Validation loss: 1.5449667592202463

Epoch: 5| Step: 8
Training loss: 0.0900360718369484
Validation loss: 1.5365687390809417

Epoch: 5| Step: 9
Training loss: 0.1264946460723877
Validation loss: 1.5637478495156893

Epoch: 5| Step: 10
Training loss: 0.2731308043003082
Validation loss: 1.5717508587785947

Epoch: 485| Step: 0
Training loss: 0.0746663361787796
Validation loss: 1.5888388438891339

Epoch: 5| Step: 1
Training loss: 0.17107099294662476
Validation loss: 1.572962543015839

Epoch: 5| Step: 2
Training loss: 0.11857442557811737
Validation loss: 1.583691588012121

Epoch: 5| Step: 3
Training loss: 0.07085206359624863
Validation loss: 1.562275145643501

Epoch: 5| Step: 4
Training loss: 0.1791916787624359
Validation loss: 1.5673046432515627

Epoch: 5| Step: 5
Training loss: 0.1057024747133255
Validation loss: 1.569558270515934

Epoch: 5| Step: 6
Training loss: 0.11355394124984741
Validation loss: 1.5568888610409153

Epoch: 5| Step: 7
Training loss: 0.14275391399860382
Validation loss: 1.5668760409919165

Epoch: 5| Step: 8
Training loss: 0.09372705966234207
Validation loss: 1.5679076961291734

Epoch: 5| Step: 9
Training loss: 0.11823417991399765
Validation loss: 1.5741253649034808

Epoch: 5| Step: 10
Training loss: 0.09386862814426422
Validation loss: 1.552134447200324

Epoch: 486| Step: 0
Training loss: 0.10950927436351776
Validation loss: 1.5862642539444791

Epoch: 5| Step: 1
Training loss: 0.19446155428886414
Validation loss: 1.5732513999426236

Epoch: 5| Step: 2
Training loss: 0.13500569760799408
Validation loss: 1.569615533274989

Epoch: 5| Step: 3
Training loss: 0.13977983593940735
Validation loss: 1.5840532702784385

Epoch: 5| Step: 4
Training loss: 0.10083906352519989
Validation loss: 1.5634106718083864

Epoch: 5| Step: 5
Training loss: 0.11249325424432755
Validation loss: 1.5675257367472495

Epoch: 5| Step: 6
Training loss: 0.0695619061589241
Validation loss: 1.560287275621968

Epoch: 5| Step: 7
Training loss: 0.12405743449926376
Validation loss: 1.536840836207072

Epoch: 5| Step: 8
Training loss: 0.11264423280954361
Validation loss: 1.5765352877237464

Epoch: 5| Step: 9
Training loss: 0.08270785212516785
Validation loss: 1.5667219674715431

Epoch: 5| Step: 10
Training loss: 0.12409820407629013
Validation loss: 1.5791219152430052

Epoch: 487| Step: 0
Training loss: 0.11330129951238632
Validation loss: 1.6062619416944441

Epoch: 5| Step: 1
Training loss: 0.10475633293390274
Validation loss: 1.5875312718012

Epoch: 5| Step: 2
Training loss: 0.08589726686477661
Validation loss: 1.5844218218198387

Epoch: 5| Step: 3
Training loss: 0.19265085458755493
Validation loss: 1.581660375800184

Epoch: 5| Step: 4
Training loss: 0.07706400007009506
Validation loss: 1.5983908189240323

Epoch: 5| Step: 5
Training loss: 0.07994064688682556
Validation loss: 1.6135409288508917

Epoch: 5| Step: 6
Training loss: 0.11429782211780548
Validation loss: 1.6167317119336897

Epoch: 5| Step: 7
Training loss: 0.12119381129741669
Validation loss: 1.6216622732018913

Epoch: 5| Step: 8
Training loss: 0.11446794122457504
Validation loss: 1.6339071707058979

Epoch: 5| Step: 9
Training loss: 0.1037842407822609
Validation loss: 1.612168086472378

Epoch: 5| Step: 10
Training loss: 0.08523409068584442
Validation loss: 1.6216473053860407

Epoch: 488| Step: 0
Training loss: 0.060243405401706696
Validation loss: 1.6055841330559022

Epoch: 5| Step: 1
Training loss: 0.16022351384162903
Validation loss: 1.6318767570680188

Epoch: 5| Step: 2
Training loss: 0.10744283348321915
Validation loss: 1.5822348774120372

Epoch: 5| Step: 3
Training loss: 0.10753631591796875
Validation loss: 1.589729807710135

Epoch: 5| Step: 4
Training loss: 0.1631767898797989
Validation loss: 1.5811164641893038

Epoch: 5| Step: 5
Training loss: 0.21820437908172607
Validation loss: 1.5684727545707458

Epoch: 5| Step: 6
Training loss: 0.1298460066318512
Validation loss: 1.5780537410448956

Epoch: 5| Step: 7
Training loss: 0.12981823086738586
Validation loss: 1.593166559614161

Epoch: 5| Step: 8
Training loss: 0.10558690875768661
Validation loss: 1.575440873381912

Epoch: 5| Step: 9
Training loss: 0.11021195352077484
Validation loss: 1.5926281162487563

Epoch: 5| Step: 10
Training loss: 0.1231895163655281
Validation loss: 1.5941491562833068

Epoch: 489| Step: 0
Training loss: 0.11692149937152863
Validation loss: 1.5745606217333066

Epoch: 5| Step: 1
Training loss: 0.1611572951078415
Validation loss: 1.594985733750046

Epoch: 5| Step: 2
Training loss: 0.1147431880235672
Validation loss: 1.6269325658839235

Epoch: 5| Step: 3
Training loss: 0.13500730693340302
Validation loss: 1.604613547684044

Epoch: 5| Step: 4
Training loss: 0.17932914197444916
Validation loss: 1.6303251738189368

Epoch: 5| Step: 5
Training loss: 0.07366104423999786
Validation loss: 1.609105856187882

Epoch: 5| Step: 6
Training loss: 0.07184533774852753
Validation loss: 1.6319444717899445

Epoch: 5| Step: 7
Training loss: 0.08031508326530457
Validation loss: 1.5923964823445966

Epoch: 5| Step: 8
Training loss: 0.1618478000164032
Validation loss: 1.57041004268072

Epoch: 5| Step: 9
Training loss: 0.08500460535287857
Validation loss: 1.587155149829003

Epoch: 5| Step: 10
Training loss: 0.08540792018175125
Validation loss: 1.5697461289744223

Epoch: 490| Step: 0
Training loss: 0.08185073733329773
Validation loss: 1.5523657048902204

Epoch: 5| Step: 1
Training loss: 0.06574948877096176
Validation loss: 1.565045411868762

Epoch: 5| Step: 2
Training loss: 0.09820003807544708
Validation loss: 1.5700539542782692

Epoch: 5| Step: 3
Training loss: 0.09759734570980072
Validation loss: 1.5537432034810383

Epoch: 5| Step: 4
Training loss: 0.0715964064002037
Validation loss: 1.5994599608964817

Epoch: 5| Step: 5
Training loss: 0.1000143513083458
Validation loss: 1.601892678968368

Epoch: 5| Step: 6
Training loss: 0.08406171947717667
Validation loss: 1.6445840122879192

Epoch: 5| Step: 7
Training loss: 0.12118879705667496
Validation loss: 1.604268249645028

Epoch: 5| Step: 8
Training loss: 0.04436656832695007
Validation loss: 1.5919362780868367

Epoch: 5| Step: 9
Training loss: 0.19967269897460938
Validation loss: 1.613795075365292

Epoch: 5| Step: 10
Training loss: 0.10558037459850311
Validation loss: 1.554209836067692

Epoch: 491| Step: 0
Training loss: 0.05757492035627365
Validation loss: 1.5743828332552345

Epoch: 5| Step: 1
Training loss: 0.10535862296819687
Validation loss: 1.5733332339153494

Epoch: 5| Step: 2
Training loss: 0.08292894065380096
Validation loss: 1.5686982690647084

Epoch: 5| Step: 3
Training loss: 0.06737072765827179
Validation loss: 1.5700057232251732

Epoch: 5| Step: 4
Training loss: 0.0971585363149643
Validation loss: 1.5876482455961165

Epoch: 5| Step: 5
Training loss: 0.24036303162574768
Validation loss: 1.5787822815679735

Epoch: 5| Step: 6
Training loss: 0.08733101189136505
Validation loss: 1.5929408727153656

Epoch: 5| Step: 7
Training loss: 0.06853917241096497
Validation loss: 1.5831097313152847

Epoch: 5| Step: 8
Training loss: 0.0629388839006424
Validation loss: 1.5864828504541868

Epoch: 5| Step: 9
Training loss: 0.08734811842441559
Validation loss: 1.5790329389674689

Epoch: 5| Step: 10
Training loss: 0.1284865438938141
Validation loss: 1.5728327164085962

Epoch: 492| Step: 0
Training loss: 0.06504169851541519
Validation loss: 1.5850998855406238

Epoch: 5| Step: 1
Training loss: 0.1134398803114891
Validation loss: 1.5888628331563805

Epoch: 5| Step: 2
Training loss: 0.07017099857330322
Validation loss: 1.5686975435544086

Epoch: 5| Step: 3
Training loss: 0.1875968873500824
Validation loss: 1.5637945039297945

Epoch: 5| Step: 4
Training loss: 0.056564997881650925
Validation loss: 1.541993224492637

Epoch: 5| Step: 5
Training loss: 0.06327680498361588
Validation loss: 1.5384051735683153

Epoch: 5| Step: 6
Training loss: 0.07235316187143326
Validation loss: 1.5483697050361223

Epoch: 5| Step: 7
Training loss: 0.0727611631155014
Validation loss: 1.5345634529667516

Epoch: 5| Step: 8
Training loss: 0.09141866117715836
Validation loss: 1.5536145753757928

Epoch: 5| Step: 9
Training loss: 0.07622019201517105
Validation loss: 1.5356166170489403

Epoch: 5| Step: 10
Training loss: 0.1289190649986267
Validation loss: 1.5293430025859545

Epoch: 493| Step: 0
Training loss: 0.08687935769557953
Validation loss: 1.5283368556730208

Epoch: 5| Step: 1
Training loss: 0.10761284828186035
Validation loss: 1.5340433877001527

Epoch: 5| Step: 2
Training loss: 0.05794971063733101
Validation loss: 1.5408209754574684

Epoch: 5| Step: 3
Training loss: 0.06640883535146713
Validation loss: 1.5409870455341954

Epoch: 5| Step: 4
Training loss: 0.06891210377216339
Validation loss: 1.5303109627898022

Epoch: 5| Step: 5
Training loss: 0.06612211465835571
Validation loss: 1.556953210984507

Epoch: 5| Step: 6
Training loss: 0.10230068862438202
Validation loss: 1.5289307755808677

Epoch: 5| Step: 7
Training loss: 0.165228009223938
Validation loss: 1.5263674156640166

Epoch: 5| Step: 8
Training loss: 0.09289510548114777
Validation loss: 1.5461031160046976

Epoch: 5| Step: 9
Training loss: 0.10004465281963348
Validation loss: 1.539770414752345

Epoch: 5| Step: 10
Training loss: 0.13788527250289917
Validation loss: 1.5440834632483862

Epoch: 494| Step: 0
Training loss: 0.10766588151454926
Validation loss: 1.53547990193931

Epoch: 5| Step: 1
Training loss: 0.10095622390508652
Validation loss: 1.5194309449964953

Epoch: 5| Step: 2
Training loss: 0.11265604197978973
Validation loss: 1.529080185838925

Epoch: 5| Step: 3
Training loss: 0.0582294836640358
Validation loss: 1.5419884509937738

Epoch: 5| Step: 4
Training loss: 0.10415904223918915
Validation loss: 1.528600988849517

Epoch: 5| Step: 5
Training loss: 0.18207970261573792
Validation loss: 1.523992097505959

Epoch: 5| Step: 6
Training loss: 0.09893076121807098
Validation loss: 1.5412450080276818

Epoch: 5| Step: 7
Training loss: 0.08426185697317123
Validation loss: 1.526882754859104

Epoch: 5| Step: 8
Training loss: 0.05434960126876831
Validation loss: 1.5773209435965425

Epoch: 5| Step: 9
Training loss: 0.0717003345489502
Validation loss: 1.580944223429567

Epoch: 5| Step: 10
Training loss: 0.12916943430900574
Validation loss: 1.554448514856318

Epoch: 495| Step: 0
Training loss: 0.10166043043136597
Validation loss: 1.5505889397795483

Epoch: 5| Step: 1
Training loss: 0.08099546283483505
Validation loss: 1.5590956916091263

Epoch: 5| Step: 2
Training loss: 0.07145076245069504
Validation loss: 1.5643232073835147

Epoch: 5| Step: 3
Training loss: 0.05751022696495056
Validation loss: 1.5516255376159505

Epoch: 5| Step: 4
Training loss: 0.07467441260814667
Validation loss: 1.54050156634341

Epoch: 5| Step: 5
Training loss: 0.07549396902322769
Validation loss: 1.5524662720259799

Epoch: 5| Step: 6
Training loss: 0.1169588565826416
Validation loss: 1.5619761572089246

Epoch: 5| Step: 7
Training loss: 0.17837396264076233
Validation loss: 1.570650025080609

Epoch: 5| Step: 8
Training loss: 0.06877610832452774
Validation loss: 1.5627066653261903

Epoch: 5| Step: 9
Training loss: 0.13050015270709991
Validation loss: 1.5382227590007167

Epoch: 5| Step: 10
Training loss: 0.09676864743232727
Validation loss: 1.564133499258308

Epoch: 496| Step: 0
Training loss: 0.07998953014612198
Validation loss: 1.5413420059347664

Epoch: 5| Step: 1
Training loss: 0.1002812534570694
Validation loss: 1.543242472474293

Epoch: 5| Step: 2
Training loss: 0.06464330852031708
Validation loss: 1.5497437882167038

Epoch: 5| Step: 3
Training loss: 0.07215826213359833
Validation loss: 1.5649508186565932

Epoch: 5| Step: 4
Training loss: 0.07307460159063339
Validation loss: 1.552847425142924

Epoch: 5| Step: 5
Training loss: 0.06068187206983566
Validation loss: 1.5502457067530642

Epoch: 5| Step: 6
Training loss: 0.09142671525478363
Validation loss: 1.5485710379897908

Epoch: 5| Step: 7
Training loss: 0.1873045116662979
Validation loss: 1.563122913401614

Epoch: 5| Step: 8
Training loss: 0.09269484132528305
Validation loss: 1.5553178415503552

Epoch: 5| Step: 9
Training loss: 0.13326947391033173
Validation loss: 1.540468337715313

Epoch: 5| Step: 10
Training loss: 0.0902337059378624
Validation loss: 1.529668850283469

Epoch: 497| Step: 0
Training loss: 0.06337112933397293
Validation loss: 1.5776532926867086

Epoch: 5| Step: 1
Training loss: 0.05855964869260788
Validation loss: 1.6079678202188143

Epoch: 5| Step: 2
Training loss: 0.059539057314395905
Validation loss: 1.611345382146938

Epoch: 5| Step: 3
Training loss: 0.08737585693597794
Validation loss: 1.6300732833082958

Epoch: 5| Step: 4
Training loss: 0.10080526024103165
Validation loss: 1.610647665557041

Epoch: 5| Step: 5
Training loss: 0.08140791207551956
Validation loss: 1.6070934777618737

Epoch: 5| Step: 6
Training loss: 0.0751374140381813
Validation loss: 1.5793765283400012

Epoch: 5| Step: 7
Training loss: 0.19072997570037842
Validation loss: 1.5944565329500424

Epoch: 5| Step: 8
Training loss: 0.06250909715890884
Validation loss: 1.5854535487390333

Epoch: 5| Step: 9
Training loss: 0.06559927761554718
Validation loss: 1.5413431377821072

Epoch: 5| Step: 10
Training loss: 0.134837344288826
Validation loss: 1.5739927214960898

Epoch: 498| Step: 0
Training loss: 0.10199661552906036
Validation loss: 1.5593645829026417

Epoch: 5| Step: 1
Training loss: 0.11083116382360458
Validation loss: 1.5324596346065562

Epoch: 5| Step: 2
Training loss: 0.15148113667964935
Validation loss: 1.5940142575130667

Epoch: 5| Step: 3
Training loss: 0.0550151951611042
Validation loss: 1.5413076146956413

Epoch: 5| Step: 4
Training loss: 0.0639161691069603
Validation loss: 1.5673404252657326

Epoch: 5| Step: 5
Training loss: 0.11504457145929337
Validation loss: 1.5669467756825108

Epoch: 5| Step: 6
Training loss: 0.08668820559978485
Validation loss: 1.557017603228169

Epoch: 5| Step: 7
Training loss: 0.04900120943784714
Validation loss: 1.5640850964412893

Epoch: 5| Step: 8
Training loss: 0.08531676232814789
Validation loss: 1.5609269956106782

Epoch: 5| Step: 9
Training loss: 0.16267916560173035
Validation loss: 1.5553150459002423

Epoch: 5| Step: 10
Training loss: 0.07307201623916626
Validation loss: 1.5793715792317544

Epoch: 499| Step: 0
Training loss: 0.08562583476305008
Validation loss: 1.5614658286494594

Epoch: 5| Step: 1
Training loss: 0.05897309631109238
Validation loss: 1.601489814378882

Epoch: 5| Step: 2
Training loss: 0.08645234256982803
Validation loss: 1.5947577286792058

Epoch: 5| Step: 3
Training loss: 0.0820569321513176
Validation loss: 1.6127992881241666

Epoch: 5| Step: 4
Training loss: 0.08781498670578003
Validation loss: 1.6101486234254734

Epoch: 5| Step: 5
Training loss: 0.07193949818611145
Validation loss: 1.6088148496484245

Epoch: 5| Step: 6
Training loss: 0.245289608836174
Validation loss: 1.6109558920706473

Epoch: 5| Step: 7
Training loss: 0.10292889922857285
Validation loss: 1.6252399926544518

Epoch: 5| Step: 8
Training loss: 0.08261021226644516
Validation loss: 1.6231722793271464

Epoch: 5| Step: 9
Training loss: 0.08794678002595901
Validation loss: 1.6305703142637848

Epoch: 5| Step: 10
Training loss: 0.10751726478338242
Validation loss: 1.6316537382782146

Epoch: 500| Step: 0
Training loss: 0.07244459539651871
Validation loss: 1.626292041552964

Epoch: 5| Step: 1
Training loss: 0.1805187165737152
Validation loss: 1.6128062150811637

Epoch: 5| Step: 2
Training loss: 0.12167210876941681
Validation loss: 1.6161673120273057

Epoch: 5| Step: 3
Training loss: 0.08828099071979523
Validation loss: 1.6022415058587187

Epoch: 5| Step: 4
Training loss: 0.08237333595752716
Validation loss: 1.6169632045171594

Epoch: 5| Step: 5
Training loss: 0.0951579138636589
Validation loss: 1.5842371294575353

Epoch: 5| Step: 6
Training loss: 0.0826353132724762
Validation loss: 1.5897490209148777

Epoch: 5| Step: 7
Training loss: 0.06653015315532684
Validation loss: 1.5862804151350451

Epoch: 5| Step: 8
Training loss: 0.10071791708469391
Validation loss: 1.5658881946276593

Epoch: 5| Step: 9
Training loss: 0.09458871185779572
Validation loss: 1.5609993844903924

Epoch: 5| Step: 10
Training loss: 0.06523871421813965
Validation loss: 1.5617794644448064

Testing loss: 2.081640985276964
