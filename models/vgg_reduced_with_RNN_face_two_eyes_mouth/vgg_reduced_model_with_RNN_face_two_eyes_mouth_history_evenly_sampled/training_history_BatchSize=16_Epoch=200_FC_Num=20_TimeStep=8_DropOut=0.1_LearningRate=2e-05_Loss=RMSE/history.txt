Epoch: 1| Step: 0
Training loss: 5.651579725488679
Validation loss: 5.831027227588814

Epoch: 6| Step: 1
Training loss: 5.622383696021908
Validation loss: 5.809406668985956

Epoch: 6| Step: 2
Training loss: 6.037738373593936
Validation loss: 5.788784725052559

Epoch: 6| Step: 3
Training loss: 5.143741857028601
Validation loss: 5.767509262155969

Epoch: 6| Step: 4
Training loss: 5.712653240260346
Validation loss: 5.743988032962635

Epoch: 6| Step: 5
Training loss: 5.687985577657579
Validation loss: 5.717725066949485

Epoch: 6| Step: 6
Training loss: 5.478474194919104
Validation loss: 5.688027006909782

Epoch: 6| Step: 7
Training loss: 5.88814875112136
Validation loss: 5.65283046821246

Epoch: 6| Step: 8
Training loss: 5.9003857761276
Validation loss: 5.6140415363174885

Epoch: 6| Step: 9
Training loss: 6.655840220844409
Validation loss: 5.568375919703172

Epoch: 6| Step: 10
Training loss: 4.676810117131558
Validation loss: 5.516651653768402

Epoch: 6| Step: 11
Training loss: 6.503491271014224
Validation loss: 5.4589556605644

Epoch: 6| Step: 12
Training loss: 4.8327644057151655
Validation loss: 5.3955186087005185

Epoch: 6| Step: 13
Training loss: 5.0696605386647855
Validation loss: 5.327317903716492

Epoch: 2| Step: 0
Training loss: 5.244401580739549
Validation loss: 5.256301051934398

Epoch: 6| Step: 1
Training loss: 5.185198353695169
Validation loss: 5.183885635934227

Epoch: 6| Step: 2
Training loss: 4.7135565263995165
Validation loss: 5.11072047032085

Epoch: 6| Step: 3
Training loss: 4.707025779625971
Validation loss: 5.041660372225802

Epoch: 6| Step: 4
Training loss: 6.189158515984732
Validation loss: 4.972384235560163

Epoch: 6| Step: 5
Training loss: 5.419577867742687
Validation loss: 4.908475625126677

Epoch: 6| Step: 6
Training loss: 4.903229968452954
Validation loss: 4.843127708407676

Epoch: 6| Step: 7
Training loss: 4.452958381614258
Validation loss: 4.77992981720381

Epoch: 6| Step: 8
Training loss: 5.3299695175473
Validation loss: 4.717578373322585

Epoch: 6| Step: 9
Training loss: 5.025122091603592
Validation loss: 4.655646205244106

Epoch: 6| Step: 10
Training loss: 4.939492511705363
Validation loss: 4.598365566087453

Epoch: 6| Step: 11
Training loss: 4.275767805070333
Validation loss: 4.5443970513884775

Epoch: 6| Step: 12
Training loss: 3.730927603897248
Validation loss: 4.489332213153751

Epoch: 6| Step: 13
Training loss: 3.7498231210319615
Validation loss: 4.437545184549986

Epoch: 3| Step: 0
Training loss: 5.827823252703027
Validation loss: 4.383676739659925

Epoch: 6| Step: 1
Training loss: 3.964612471125471
Validation loss: 4.334231386924666

Epoch: 6| Step: 2
Training loss: 3.060273275701478
Validation loss: 4.287953649949237

Epoch: 6| Step: 3
Training loss: 5.133801230041934
Validation loss: 4.249367275346336

Epoch: 6| Step: 4
Training loss: 4.304023262187958
Validation loss: 4.2021450698650415

Epoch: 6| Step: 5
Training loss: 4.027601853544343
Validation loss: 4.155908313183239

Epoch: 6| Step: 6
Training loss: 3.7360611305218354
Validation loss: 4.114057423741491

Epoch: 6| Step: 7
Training loss: 3.501497357097425
Validation loss: 4.075551837875417

Epoch: 6| Step: 8
Training loss: 4.343726507987847
Validation loss: 4.039521747542679

Epoch: 6| Step: 9
Training loss: 3.78105150442651
Validation loss: 4.005978218727174

Epoch: 6| Step: 10
Training loss: 4.005265584800234
Validation loss: 3.974637102353518

Epoch: 6| Step: 11
Training loss: 4.2472660022245305
Validation loss: 3.9460205924224327

Epoch: 6| Step: 12
Training loss: 4.836810253561233
Validation loss: 3.919339020825138

Epoch: 6| Step: 13
Training loss: 4.094725980242327
Validation loss: 3.8926645609571406

Epoch: 4| Step: 0
Training loss: 3.429542903415437
Validation loss: 3.870051674993471

Epoch: 6| Step: 1
Training loss: 3.778054013780438
Validation loss: 3.846366320713239

Epoch: 6| Step: 2
Training loss: 4.7162630715026
Validation loss: 3.824737873246996

Epoch: 6| Step: 3
Training loss: 4.250259167118036
Validation loss: 3.7994389072798005

Epoch: 6| Step: 4
Training loss: 4.726807037837404
Validation loss: 3.77226497785539

Epoch: 6| Step: 5
Training loss: 3.43620470091379
Validation loss: 3.739889577902896

Epoch: 6| Step: 6
Training loss: 4.090989674631841
Validation loss: 3.709882355763361

Epoch: 6| Step: 7
Training loss: 2.670076713174331
Validation loss: 3.692517794075066

Epoch: 6| Step: 8
Training loss: 4.554856259604061
Validation loss: 3.703148928273727

Epoch: 6| Step: 9
Training loss: 4.000504938680153
Validation loss: 3.677522060674194

Epoch: 6| Step: 10
Training loss: 4.041117575139768
Validation loss: 3.6758174874620533

Epoch: 6| Step: 11
Training loss: 2.8671845064485395
Validation loss: 3.6696237910635663

Epoch: 6| Step: 12
Training loss: 3.8919391174572784
Validation loss: 3.633157851252737

Epoch: 6| Step: 13
Training loss: 3.6477370314682265
Validation loss: 3.612588018528854

Epoch: 5| Step: 0
Training loss: 4.224074556920931
Validation loss: 3.592854459303817

Epoch: 6| Step: 1
Training loss: 3.949221768552568
Validation loss: 3.5771060532914487

Epoch: 6| Step: 2
Training loss: 3.465765691709984
Validation loss: 3.5670698180897302

Epoch: 6| Step: 3
Training loss: 3.8447616610428024
Validation loss: 3.560872245604317

Epoch: 6| Step: 4
Training loss: 3.7232260813302425
Validation loss: 3.5532480308595074

Epoch: 6| Step: 5
Training loss: 2.7445848207270407
Validation loss: 3.5433822896820546

Epoch: 6| Step: 6
Training loss: 4.37296356762431
Validation loss: 3.5367860847735173

Epoch: 6| Step: 7
Training loss: 3.0314408075114714
Validation loss: 3.520063518653042

Epoch: 6| Step: 8
Training loss: 3.91052622383357
Validation loss: 3.5078077261667273

Epoch: 6| Step: 9
Training loss: 4.14591785645067
Validation loss: 3.499977489697895

Epoch: 6| Step: 10
Training loss: 3.4930009342588786
Validation loss: 3.4892619871979327

Epoch: 6| Step: 11
Training loss: 3.9764961881673266
Validation loss: 3.484250477403732

Epoch: 6| Step: 12
Training loss: 3.8016318832694878
Validation loss: 3.4707458025533997

Epoch: 6| Step: 13
Training loss: 2.747170726840778
Validation loss: 3.456468184213601

Epoch: 6| Step: 0
Training loss: 4.246361240640125
Validation loss: 3.438302069768071

Epoch: 6| Step: 1
Training loss: 3.978839215025337
Validation loss: 3.427398567402081

Epoch: 6| Step: 2
Training loss: 3.2194536051173235
Validation loss: 3.418518885438276

Epoch: 6| Step: 3
Training loss: 3.7246768427210752
Validation loss: 3.4062296992925005

Epoch: 6| Step: 4
Training loss: 4.469563443501869
Validation loss: 3.4092737545972915

Epoch: 6| Step: 5
Training loss: 3.7268072723678016
Validation loss: 3.397232688867316

Epoch: 6| Step: 6
Training loss: 3.3484851429692126
Validation loss: 3.3977385963394897

Epoch: 6| Step: 7
Training loss: 3.369195255444766
Validation loss: 3.3902612147639464

Epoch: 6| Step: 8
Training loss: 3.3334833270340156
Validation loss: 3.385642625006001

Epoch: 6| Step: 9
Training loss: 3.188277804151532
Validation loss: 3.3766095566894205

Epoch: 6| Step: 10
Training loss: 3.438642416033432
Validation loss: 3.3688915611588244

Epoch: 6| Step: 11
Training loss: 3.4630462215642503
Validation loss: 3.3634013470055315

Epoch: 6| Step: 12
Training loss: 3.6840297080963826
Validation loss: 3.356206099766421

Epoch: 6| Step: 13
Training loss: 2.8939457145402807
Validation loss: 3.3499008156681502

Epoch: 7| Step: 0
Training loss: 4.610304709602269
Validation loss: 3.346161592283662

Epoch: 6| Step: 1
Training loss: 3.3773183983604222
Validation loss: 3.344478766586688

Epoch: 6| Step: 2
Training loss: 3.2624107494788928
Validation loss: 3.3388581963450434

Epoch: 6| Step: 3
Training loss: 3.7594794939823557
Validation loss: 3.3303639050018052

Epoch: 6| Step: 4
Training loss: 3.569478878806759
Validation loss: 3.325044992213273

Epoch: 6| Step: 5
Training loss: 3.2481320221476193
Validation loss: 3.3196064184161083

Epoch: 6| Step: 6
Training loss: 3.2308339070564043
Validation loss: 3.31774384812225

Epoch: 6| Step: 7
Training loss: 3.5663201445999344
Validation loss: 3.3139080027859333

Epoch: 6| Step: 8
Training loss: 4.076436946714863
Validation loss: 3.3095557481690636

Epoch: 6| Step: 9
Training loss: 3.988102384884849
Validation loss: 3.3238196064129863

Epoch: 6| Step: 10
Training loss: 2.821660615163834
Validation loss: 3.3032191354573825

Epoch: 6| Step: 11
Training loss: 2.388111962784755
Validation loss: 3.319295548747086

Epoch: 6| Step: 12
Training loss: 3.6213605303054406
Validation loss: 3.3538813687817735

Epoch: 6| Step: 13
Training loss: 4.059475286241976
Validation loss: 3.334487966299252

Epoch: 8| Step: 0
Training loss: 4.107260504512553
Validation loss: 3.3087787215439968

Epoch: 6| Step: 1
Training loss: 4.475700255433697
Validation loss: 3.294789944828229

Epoch: 6| Step: 2
Training loss: 2.8615920846677647
Validation loss: 3.291287493930505

Epoch: 6| Step: 3
Training loss: 3.357915658906081
Validation loss: 3.291483314135608

Epoch: 6| Step: 4
Training loss: 2.4838453963936713
Validation loss: 3.293982828918073

Epoch: 6| Step: 5
Training loss: 3.907962881288762
Validation loss: 3.293688998027458

Epoch: 6| Step: 6
Training loss: 3.6620731769044332
Validation loss: 3.291524922714878

Epoch: 6| Step: 7
Training loss: 3.621166965110693
Validation loss: 3.2891044525361885

Epoch: 6| Step: 8
Training loss: 3.5428002432020382
Validation loss: 3.2810563287648185

Epoch: 6| Step: 9
Training loss: 3.8570142931427314
Validation loss: 3.279710357454574

Epoch: 6| Step: 10
Training loss: 3.3326727371491205
Validation loss: 3.2799250305200887

Epoch: 6| Step: 11
Training loss: 3.204217789485611
Validation loss: 3.2673238786492798

Epoch: 6| Step: 12
Training loss: 3.3760145569799356
Validation loss: 3.2622958319191286

Epoch: 6| Step: 13
Training loss: 2.919961067880778
Validation loss: 3.2574398386046393

Epoch: 9| Step: 0
Training loss: 3.125797017502721
Validation loss: 3.257394643403582

Epoch: 6| Step: 1
Training loss: 4.083669817288825
Validation loss: 3.252213269532892

Epoch: 6| Step: 2
Training loss: 3.8396883959306174
Validation loss: 3.2527372950606783

Epoch: 6| Step: 3
Training loss: 3.8235141935088808
Validation loss: 3.2469968796015793

Epoch: 6| Step: 4
Training loss: 4.380664101686154
Validation loss: 3.2423215310336664

Epoch: 6| Step: 5
Training loss: 3.377830731105105
Validation loss: 3.238074819397982

Epoch: 6| Step: 6
Training loss: 3.709798730495844
Validation loss: 3.2354195483281987

Epoch: 6| Step: 7
Training loss: 3.295741171016469
Validation loss: 3.233387323133216

Epoch: 6| Step: 8
Training loss: 3.5251076539827784
Validation loss: 3.229991402367755

Epoch: 6| Step: 9
Training loss: 3.3965993536012276
Validation loss: 3.2248813967602574

Epoch: 6| Step: 10
Training loss: 3.8461053346362197
Validation loss: 3.2213120093122023

Epoch: 6| Step: 11
Training loss: 2.648006707998348
Validation loss: 3.2182039147476647

Epoch: 6| Step: 12
Training loss: 2.2772541322954365
Validation loss: 3.2163164572882876

Epoch: 6| Step: 13
Training loss: 2.4870648487503595
Validation loss: 3.2178923430648982

Epoch: 10| Step: 0
Training loss: 3.319416382980025
Validation loss: 3.2132738990105527

Epoch: 6| Step: 1
Training loss: 1.8084969875741959
Validation loss: 3.210118421355242

Epoch: 6| Step: 2
Training loss: 3.2570911221709777
Validation loss: 3.2078822750688243

Epoch: 6| Step: 3
Training loss: 3.6802865287937836
Validation loss: 3.2070645424573136

Epoch: 6| Step: 4
Training loss: 3.292925018707989
Validation loss: 3.2035435076776673

Epoch: 6| Step: 5
Training loss: 3.5610474419287077
Validation loss: 3.1992235868443633

Epoch: 6| Step: 6
Training loss: 3.77777217104128
Validation loss: 3.196386271642896

Epoch: 6| Step: 7
Training loss: 3.798655779148012
Validation loss: 3.1943599595829846

Epoch: 6| Step: 8
Training loss: 3.489050085213932
Validation loss: 3.19036624571074

Epoch: 6| Step: 9
Training loss: 3.5233715922414657
Validation loss: 3.1935229179764657

Epoch: 6| Step: 10
Training loss: 2.954663879848823
Validation loss: 3.187186005110737

Epoch: 6| Step: 11
Training loss: 3.7992468438903186
Validation loss: 3.1888740902678645

Epoch: 6| Step: 12
Training loss: 3.755879053469964
Validation loss: 3.188362611287419

Epoch: 6| Step: 13
Training loss: 4.151221424200851
Validation loss: 3.1855567801249673

Epoch: 11| Step: 0
Training loss: 3.939766609908734
Validation loss: 3.178534956850077

Epoch: 6| Step: 1
Training loss: 3.1374836104371475
Validation loss: 3.1744956301853335

Epoch: 6| Step: 2
Training loss: 3.645059267250339
Validation loss: 3.1703010815336494

Epoch: 6| Step: 3
Training loss: 4.1004646503183935
Validation loss: 3.1662947096793603

Epoch: 6| Step: 4
Training loss: 2.728513702632197
Validation loss: 3.1642220932263725

Epoch: 6| Step: 5
Training loss: 2.708094004302457
Validation loss: 3.161279824978005

Epoch: 6| Step: 6
Training loss: 3.844560739256441
Validation loss: 3.154810265693164

Epoch: 6| Step: 7
Training loss: 3.4068588972507166
Validation loss: 3.1503064850445255

Epoch: 6| Step: 8
Training loss: 3.344164671096821
Validation loss: 3.144672347169208

Epoch: 6| Step: 9
Training loss: 2.9741390104353824
Validation loss: 3.143961032189196

Epoch: 6| Step: 10
Training loss: 3.8277191569787545
Validation loss: 3.1520089842673125

Epoch: 6| Step: 11
Training loss: 2.562495347925941
Validation loss: 3.1386751486987867

Epoch: 6| Step: 12
Training loss: 3.8426680864291334
Validation loss: 3.1378155964875423

Epoch: 6| Step: 13
Training loss: 3.4390141706870767
Validation loss: 3.138008325090866

Epoch: 12| Step: 0
Training loss: 3.7062457491510985
Validation loss: 3.1480933855062974

Epoch: 6| Step: 1
Training loss: 3.924998707376255
Validation loss: 3.132420716639081

Epoch: 6| Step: 2
Training loss: 3.61602540432606
Validation loss: 3.133623151416543

Epoch: 6| Step: 3
Training loss: 3.532302834528678
Validation loss: 3.1407149817320117

Epoch: 6| Step: 4
Training loss: 3.5388256271619274
Validation loss: 3.148452773815788

Epoch: 6| Step: 5
Training loss: 3.4565280354092764
Validation loss: 3.1392756529428056

Epoch: 6| Step: 6
Training loss: 2.394448905885596
Validation loss: 3.1368237565974

Epoch: 6| Step: 7
Training loss: 4.038322927031502
Validation loss: 3.1845139381079024

Epoch: 6| Step: 8
Training loss: 3.1920934751968857
Validation loss: 3.195332875475012

Epoch: 6| Step: 9
Training loss: 3.355406080022659
Validation loss: 3.201911632024382

Epoch: 6| Step: 10
Training loss: 2.619334328221208
Validation loss: 3.2081939327115654

Epoch: 6| Step: 11
Training loss: 3.647480677866595
Validation loss: 3.213072903835935

Epoch: 6| Step: 12
Training loss: 3.7735545138268827
Validation loss: 3.1978280847248395

Epoch: 6| Step: 13
Training loss: 2.258608562219027
Validation loss: 3.1876031166044365

Epoch: 13| Step: 0
Training loss: 3.690429299872631
Validation loss: 3.186574838245168

Epoch: 6| Step: 1
Training loss: 3.8211383200046436
Validation loss: 3.186152341192597

Epoch: 6| Step: 2
Training loss: 3.177214389453487
Validation loss: 3.178137570064288

Epoch: 6| Step: 3
Training loss: 3.107921164613752
Validation loss: 3.1389196601695444

Epoch: 6| Step: 4
Training loss: 3.748777571751984
Validation loss: 3.1308263792646334

Epoch: 6| Step: 5
Training loss: 3.7620670715875133
Validation loss: 3.1157464908412837

Epoch: 6| Step: 6
Training loss: 2.8492464039629155
Validation loss: 3.113794551548806

Epoch: 6| Step: 7
Training loss: 3.333852648018315
Validation loss: 3.1108616085458594

Epoch: 6| Step: 8
Training loss: 3.379225734534674
Validation loss: 3.1167983817322367

Epoch: 6| Step: 9
Training loss: 3.3075032964965354
Validation loss: 3.1212164093042936

Epoch: 6| Step: 10
Training loss: 3.9688278551049594
Validation loss: 3.106475797640048

Epoch: 6| Step: 11
Training loss: 3.0285805815175393
Validation loss: 3.105214426847791

Epoch: 6| Step: 12
Training loss: 2.6027785199993336
Validation loss: 3.1058356756283945

Epoch: 6| Step: 13
Training loss: 3.7321883307689774
Validation loss: 3.1058460429742567

Epoch: 14| Step: 0
Training loss: 3.3141699845915533
Validation loss: 3.103305536712706

Epoch: 6| Step: 1
Training loss: 3.128951968884148
Validation loss: 3.1028709933965244

Epoch: 6| Step: 2
Training loss: 3.4268670443815243
Validation loss: 3.099402755646343

Epoch: 6| Step: 3
Training loss: 3.160096496847013
Validation loss: 3.0970995120712033

Epoch: 6| Step: 4
Training loss: 3.320959553220421
Validation loss: 3.098549439748861

Epoch: 6| Step: 5
Training loss: 3.0652161056228846
Validation loss: 3.100335708790394

Epoch: 6| Step: 6
Training loss: 4.227412619564677
Validation loss: 3.098189823238449

Epoch: 6| Step: 7
Training loss: 3.253568304310735
Validation loss: 3.0937387866673296

Epoch: 6| Step: 8
Training loss: 3.0023489339338543
Validation loss: 3.0903372728711123

Epoch: 6| Step: 9
Training loss: 3.7255074789002633
Validation loss: 3.0891328118750727

Epoch: 6| Step: 10
Training loss: 3.453654943339211
Validation loss: 3.0908770156089047

Epoch: 6| Step: 11
Training loss: 2.960142486854386
Validation loss: 3.08709030498723

Epoch: 6| Step: 12
Training loss: 3.5471349948589395
Validation loss: 3.0866709346294785

Epoch: 6| Step: 13
Training loss: 3.5232177124492896
Validation loss: 3.0856052272238323

Epoch: 15| Step: 0
Training loss: 3.5628520055500688
Validation loss: 3.0855697369082855

Epoch: 6| Step: 1
Training loss: 3.1955967709066493
Validation loss: 3.084660184456724

Epoch: 6| Step: 2
Training loss: 3.6820760373330352
Validation loss: 3.0804685011982436

Epoch: 6| Step: 3
Training loss: 3.642518038420302
Validation loss: 3.0779956011498153

Epoch: 6| Step: 4
Training loss: 2.4789548083483686
Validation loss: 3.078623216901571

Epoch: 6| Step: 5
Training loss: 3.1297542265903027
Validation loss: 3.0763642054636944

Epoch: 6| Step: 6
Training loss: 3.4112900709438527
Validation loss: 3.075807656796396

Epoch: 6| Step: 7
Training loss: 3.1825684938454315
Validation loss: 3.074768176587275

Epoch: 6| Step: 8
Training loss: 3.754116596278948
Validation loss: 3.0757308118207085

Epoch: 6| Step: 9
Training loss: 3.8173438397377426
Validation loss: 3.0729665349991766

Epoch: 6| Step: 10
Training loss: 3.322348870025566
Validation loss: 3.072827362937557

Epoch: 6| Step: 11
Training loss: 3.4208836621861907
Validation loss: 3.0718245100331623

Epoch: 6| Step: 12
Training loss: 2.6839402154213596
Validation loss: 3.0702807999306505

Epoch: 6| Step: 13
Training loss: 3.6026949808696136
Validation loss: 3.0707409436167277

Epoch: 16| Step: 0
Training loss: 3.6153016416452735
Validation loss: 3.0710539803503987

Epoch: 6| Step: 1
Training loss: 3.638148435495216
Validation loss: 3.069088951288453

Epoch: 6| Step: 2
Training loss: 3.55795225355631
Validation loss: 3.0690146169882984

Epoch: 6| Step: 3
Training loss: 3.5030512452337033
Validation loss: 3.0699320441605145

Epoch: 6| Step: 4
Training loss: 3.236405919025776
Validation loss: 3.0670814332541663

Epoch: 6| Step: 5
Training loss: 3.9520353843556637
Validation loss: 3.0647596770885173

Epoch: 6| Step: 6
Training loss: 3.2652944005055127
Validation loss: 3.062755300341411

Epoch: 6| Step: 7
Training loss: 3.0153014646919853
Validation loss: 3.0610835767957703

Epoch: 6| Step: 8
Training loss: 2.563194459924176
Validation loss: 3.061017142661773

Epoch: 6| Step: 9
Training loss: 1.9702619771507435
Validation loss: 3.0604680418813865

Epoch: 6| Step: 10
Training loss: 3.3153944505215103
Validation loss: 3.059782637904802

Epoch: 6| Step: 11
Training loss: 3.5492841294296094
Validation loss: 3.058955356414067

Epoch: 6| Step: 12
Training loss: 3.9997622896133573
Validation loss: 3.058833455661397

Epoch: 6| Step: 13
Training loss: 3.0162978928672852
Validation loss: 3.0578742234889824

Epoch: 17| Step: 0
Training loss: 3.684161986841524
Validation loss: 3.057122526762225

Epoch: 6| Step: 1
Training loss: 1.8817922273319454
Validation loss: 3.054434422648781

Epoch: 6| Step: 2
Training loss: 3.38343519862375
Validation loss: 3.054589237575239

Epoch: 6| Step: 3
Training loss: 2.705395048560268
Validation loss: 3.05257218132843

Epoch: 6| Step: 4
Training loss: 2.591862554803152
Validation loss: 3.0522171378121112

Epoch: 6| Step: 5
Training loss: 3.352540342584594
Validation loss: 3.0626345670399533

Epoch: 6| Step: 6
Training loss: 3.4668820136992866
Validation loss: 3.06904869242453

Epoch: 6| Step: 7
Training loss: 4.325092230899375
Validation loss: 3.0861151007973078

Epoch: 6| Step: 8
Training loss: 4.315279741999235
Validation loss: 3.0498888413406378

Epoch: 6| Step: 9
Training loss: 3.467677044958882
Validation loss: 3.0879693192614472

Epoch: 6| Step: 10
Training loss: 3.679656528739419
Validation loss: 3.083025472670583

Epoch: 6| Step: 11
Training loss: 2.770583110400582
Validation loss: 3.073622513022981

Epoch: 6| Step: 12
Training loss: 3.182697492945882
Validation loss: 3.0982391910040583

Epoch: 6| Step: 13
Training loss: 3.262270139584251
Validation loss: 3.1027181736092198

Epoch: 18| Step: 0
Training loss: 3.153479540488613
Validation loss: 3.1078778955929125

Epoch: 6| Step: 1
Training loss: 3.145958163245751
Validation loss: 3.112386591334755

Epoch: 6| Step: 2
Training loss: 3.6509702986609054
Validation loss: 3.120085736267582

Epoch: 6| Step: 3
Training loss: 2.601770890970995
Validation loss: 3.089843527640628

Epoch: 6| Step: 4
Training loss: 3.0691381640167683
Validation loss: 3.098318653399463

Epoch: 6| Step: 5
Training loss: 3.5539178371345375
Validation loss: 3.106370106014136

Epoch: 6| Step: 6
Training loss: 3.7694171473177605
Validation loss: 3.085517985420882

Epoch: 6| Step: 7
Training loss: 3.466474869508657
Validation loss: 3.067543464229227

Epoch: 6| Step: 8
Training loss: 3.069289330599851
Validation loss: 3.0572725022092957

Epoch: 6| Step: 9
Training loss: 2.510094005906462
Validation loss: 3.053782240159668

Epoch: 6| Step: 10
Training loss: 4.042426178870938
Validation loss: 3.046717640673455

Epoch: 6| Step: 11
Training loss: 3.796642406230934
Validation loss: 3.0392269532158536

Epoch: 6| Step: 12
Training loss: 3.480938641032306
Validation loss: 3.0396917007975874

Epoch: 6| Step: 13
Training loss: 3.1415974643954465
Validation loss: 3.0376447109988223

Epoch: 19| Step: 0
Training loss: 3.5084070326312213
Validation loss: 3.0383626484911477

Epoch: 6| Step: 1
Training loss: 3.68453433506819
Validation loss: 3.0384980735807328

Epoch: 6| Step: 2
Training loss: 3.370490699835593
Validation loss: 3.038576062652602

Epoch: 6| Step: 3
Training loss: 2.7200367831099173
Validation loss: 3.038009743384667

Epoch: 6| Step: 4
Training loss: 3.5018572647922865
Validation loss: 3.035338394705723

Epoch: 6| Step: 5
Training loss: 3.169517655845339
Validation loss: 3.033713507354612

Epoch: 6| Step: 6
Training loss: 3.2020255830446853
Validation loss: 3.032879348267269

Epoch: 6| Step: 7
Training loss: 3.453504446594283
Validation loss: 3.030681247633103

Epoch: 6| Step: 8
Training loss: 2.8867914296500157
Validation loss: 3.0299953980480123

Epoch: 6| Step: 9
Training loss: 3.1485183743296163
Validation loss: 3.0274122864331594

Epoch: 6| Step: 10
Training loss: 3.07684221986755
Validation loss: 3.02611867833389

Epoch: 6| Step: 11
Training loss: 3.8577257099485758
Validation loss: 3.02398102202914

Epoch: 6| Step: 12
Training loss: 3.3062424484772426
Validation loss: 3.0227991606595475

Epoch: 6| Step: 13
Training loss: 3.510270173197894
Validation loss: 3.023035463045099

Epoch: 20| Step: 0
Training loss: 3.1680861520708934
Validation loss: 3.0233216291722202

Epoch: 6| Step: 1
Training loss: 2.984835604129514
Validation loss: 3.0215073107699837

Epoch: 6| Step: 2
Training loss: 2.8436778971156254
Validation loss: 3.021746491832094

Epoch: 6| Step: 3
Training loss: 3.7190467010872776
Validation loss: 3.0298951612732807

Epoch: 6| Step: 4
Training loss: 3.5193185350362652
Validation loss: 3.026926233118821

Epoch: 6| Step: 5
Training loss: 3.3635724481044647
Validation loss: 3.0166096411059224

Epoch: 6| Step: 6
Training loss: 2.6452435614609637
Validation loss: 3.014931605589824

Epoch: 6| Step: 7
Training loss: 3.071735547335759
Validation loss: 3.014384341853814

Epoch: 6| Step: 8
Training loss: 3.70392648256477
Validation loss: 3.026737868339904

Epoch: 6| Step: 9
Training loss: 3.4976045040199337
Validation loss: 3.023453616419701

Epoch: 6| Step: 10
Training loss: 3.5703063564122473
Validation loss: 3.0155368745086117

Epoch: 6| Step: 11
Training loss: 4.35200955681593
Validation loss: 3.0136285398508407

Epoch: 6| Step: 12
Training loss: 2.5410296053432186
Validation loss: 3.0168366014878587

Epoch: 6| Step: 13
Training loss: 2.7181886992421074
Validation loss: 3.031755865892631

Epoch: 21| Step: 0
Training loss: 3.7099890852199513
Validation loss: 3.0508244960592035

Epoch: 6| Step: 1
Training loss: 4.112472701054555
Validation loss: 3.031313707016082

Epoch: 6| Step: 2
Training loss: 2.959495011890176
Validation loss: 3.0110267020783774

Epoch: 6| Step: 3
Training loss: 3.2721075665763335
Validation loss: 3.011583738090026

Epoch: 6| Step: 4
Training loss: 3.0418277506218403
Validation loss: 3.007124779073504

Epoch: 6| Step: 5
Training loss: 3.174779905365058
Validation loss: 3.005643714572879

Epoch: 6| Step: 6
Training loss: 3.745548912738271
Validation loss: 3.013620296727508

Epoch: 6| Step: 7
Training loss: 3.285920951101412
Validation loss: 3.0119458797563667

Epoch: 6| Step: 8
Training loss: 2.5777615377674605
Validation loss: 3.009999536097182

Epoch: 6| Step: 9
Training loss: 3.551114544055835
Validation loss: 3.009288830488704

Epoch: 6| Step: 10
Training loss: 2.429512238391011
Validation loss: 3.0077501004728435

Epoch: 6| Step: 11
Training loss: 2.971374796941464
Validation loss: 3.0038412806563244

Epoch: 6| Step: 12
Training loss: 3.3983507868786456
Validation loss: 3.0030743320543563

Epoch: 6| Step: 13
Training loss: 3.9302597084330726
Validation loss: 2.99940261567211

Epoch: 22| Step: 0
Training loss: 3.480143762008697
Validation loss: 2.9964484424252444

Epoch: 6| Step: 1
Training loss: 3.467101659137632
Validation loss: 2.9935332539806736

Epoch: 6| Step: 2
Training loss: 2.9482672564870755
Validation loss: 2.992605268380826

Epoch: 6| Step: 3
Training loss: 3.031927917811324
Validation loss: 2.990930155617876

Epoch: 6| Step: 4
Training loss: 2.9480031318699673
Validation loss: 2.9890657441151354

Epoch: 6| Step: 5
Training loss: 3.402386495363301
Validation loss: 2.990088517725302

Epoch: 6| Step: 6
Training loss: 3.407350414908274
Validation loss: 2.9884951883873008

Epoch: 6| Step: 7
Training loss: 3.8684314306975622
Validation loss: 2.9873545669921384

Epoch: 6| Step: 8
Training loss: 3.5229162942956465
Validation loss: 2.9860331919536747

Epoch: 6| Step: 9
Training loss: 3.6321787291592136
Validation loss: 2.9840170726132125

Epoch: 6| Step: 10
Training loss: 2.590900188412498
Validation loss: 2.9836919726978444

Epoch: 6| Step: 11
Training loss: 3.098383968350603
Validation loss: 2.980448304240614

Epoch: 6| Step: 12
Training loss: 3.169991370830163
Validation loss: 2.9831447401008706

Epoch: 6| Step: 13
Training loss: 3.2825374439018478
Validation loss: 2.9766279372777946

Epoch: 23| Step: 0
Training loss: 2.234603976808084
Validation loss: 2.9780877039246514

Epoch: 6| Step: 1
Training loss: 3.217538253687193
Validation loss: 2.980807077279582

Epoch: 6| Step: 2
Training loss: 2.9781909402950424
Validation loss: 2.9810788868654363

Epoch: 6| Step: 3
Training loss: 2.809519226649305
Validation loss: 2.982865187715512

Epoch: 6| Step: 4
Training loss: 3.8033098863909243
Validation loss: 2.9876280213599236

Epoch: 6| Step: 5
Training loss: 3.1001871360161974
Validation loss: 2.99465858595368

Epoch: 6| Step: 6
Training loss: 3.088060020901146
Validation loss: 2.9939149873317077

Epoch: 6| Step: 7
Training loss: 3.642334630769117
Validation loss: 2.9873142596075772

Epoch: 6| Step: 8
Training loss: 2.480645409248033
Validation loss: 2.9874004792802835

Epoch: 6| Step: 9
Training loss: 4.136589185146372
Validation loss: 2.9810746893452675

Epoch: 6| Step: 10
Training loss: 3.7725712826455116
Validation loss: 2.9730184924903043

Epoch: 6| Step: 11
Training loss: 3.6678566880012937
Validation loss: 2.9739797455011967

Epoch: 6| Step: 12
Training loss: 3.164578468732546
Validation loss: 2.976015014269516

Epoch: 6| Step: 13
Training loss: 3.210579882381428
Validation loss: 2.980482718751176

Epoch: 24| Step: 0
Training loss: 2.7710233255132173
Validation loss: 2.9793459506093622

Epoch: 6| Step: 1
Training loss: 2.719518092604986
Validation loss: 2.9747559714217515

Epoch: 6| Step: 2
Training loss: 3.7979438438984654
Validation loss: 2.9784865138962764

Epoch: 6| Step: 3
Training loss: 3.0662564963930143
Validation loss: 2.9655761039063373

Epoch: 6| Step: 4
Training loss: 3.8269621659425463
Validation loss: 2.965223100554592

Epoch: 6| Step: 5
Training loss: 2.4007691223851166
Validation loss: 2.963497440444914

Epoch: 6| Step: 6
Training loss: 2.6903162549817163
Validation loss: 2.9656973151664596

Epoch: 6| Step: 7
Training loss: 3.714475723793188
Validation loss: 2.967449604191916

Epoch: 6| Step: 8
Training loss: 3.4368558800375855
Validation loss: 2.9737100129904928

Epoch: 6| Step: 9
Training loss: 3.4652629198780627
Validation loss: 2.9761884848006424

Epoch: 6| Step: 10
Training loss: 3.712911173338721
Validation loss: 2.9769335195703457

Epoch: 6| Step: 11
Training loss: 3.463746870267315
Validation loss: 2.9745768903076324

Epoch: 6| Step: 12
Training loss: 3.250303694400719
Validation loss: 2.9672229822719967

Epoch: 6| Step: 13
Training loss: 2.9919305994889327
Validation loss: 2.9621685638983397

Epoch: 25| Step: 0
Training loss: 3.0249716639176776
Validation loss: 2.957120105573764

Epoch: 6| Step: 1
Training loss: 3.6962401695494855
Validation loss: 2.956682686385035

Epoch: 6| Step: 2
Training loss: 3.180323281799794
Validation loss: 2.9544939595703084

Epoch: 6| Step: 3
Training loss: 3.0207878547840528
Validation loss: 2.95303066259459

Epoch: 6| Step: 4
Training loss: 2.8128685603781536
Validation loss: 2.9523668576401185

Epoch: 6| Step: 5
Training loss: 2.447659667031259
Validation loss: 2.952487956494821

Epoch: 6| Step: 6
Training loss: 3.8544550744824635
Validation loss: 2.9540004176010823

Epoch: 6| Step: 7
Training loss: 2.719205445474782
Validation loss: 2.9530517721833505

Epoch: 6| Step: 8
Training loss: 3.0677235489075563
Validation loss: 2.9530106588715177

Epoch: 6| Step: 9
Training loss: 3.9733509217796787
Validation loss: 2.9522802713101495

Epoch: 6| Step: 10
Training loss: 3.7808899510996956
Validation loss: 2.9490946551757946

Epoch: 6| Step: 11
Training loss: 3.085974893464109
Validation loss: 2.948294057372358

Epoch: 6| Step: 12
Training loss: 2.822159603463825
Validation loss: 2.9478747610808704

Epoch: 6| Step: 13
Training loss: 3.90369704172428
Validation loss: 2.946826997938713

Epoch: 26| Step: 0
Training loss: 3.4269604105292015
Validation loss: 2.9438156206658292

Epoch: 6| Step: 1
Training loss: 3.388898840787134
Validation loss: 2.9464953080405616

Epoch: 6| Step: 2
Training loss: 3.5367769183040982
Validation loss: 2.943955989789408

Epoch: 6| Step: 3
Training loss: 3.114221830450254
Validation loss: 2.941677056036572

Epoch: 6| Step: 4
Training loss: 3.593725851226609
Validation loss: 2.9433845709307165

Epoch: 6| Step: 5
Training loss: 3.206563155736764
Validation loss: 2.9410730195596613

Epoch: 6| Step: 6
Training loss: 3.6759776469351118
Validation loss: 2.9407989559649845

Epoch: 6| Step: 7
Training loss: 2.671397205486294
Validation loss: 2.9398839794303933

Epoch: 6| Step: 8
Training loss: 3.153751555271196
Validation loss: 2.9389313993815662

Epoch: 6| Step: 9
Training loss: 2.774826003109777
Validation loss: 2.9410136374169498

Epoch: 6| Step: 10
Training loss: 3.4424016511009348
Validation loss: 2.940138822633024

Epoch: 6| Step: 11
Training loss: 2.991126925801525
Validation loss: 2.937667989367365

Epoch: 6| Step: 12
Training loss: 3.3902193872810775
Validation loss: 2.939548465020818

Epoch: 6| Step: 13
Training loss: 2.5146962222401585
Validation loss: 2.935345761552444

Epoch: 27| Step: 0
Training loss: 4.07554293332999
Validation loss: 2.931772494314765

Epoch: 6| Step: 1
Training loss: 3.33081862642924
Validation loss: 2.931717311783101

Epoch: 6| Step: 2
Training loss: 3.3294338464450686
Validation loss: 2.931939639298554

Epoch: 6| Step: 3
Training loss: 3.3246857688247444
Validation loss: 2.931219431046514

Epoch: 6| Step: 4
Training loss: 2.8571807279801726
Validation loss: 2.929787097181383

Epoch: 6| Step: 5
Training loss: 3.2738491336688704
Validation loss: 2.9297729654732616

Epoch: 6| Step: 6
Training loss: 3.097847277221833
Validation loss: 2.9280310424826985

Epoch: 6| Step: 7
Training loss: 3.4072952766519844
Validation loss: 2.9275400886079224

Epoch: 6| Step: 8
Training loss: 2.7707355070890727
Validation loss: 2.9251812114032987

Epoch: 6| Step: 9
Training loss: 2.962830434148832
Validation loss: 2.926743090674934

Epoch: 6| Step: 10
Training loss: 3.5576133005485904
Validation loss: 2.9255624275792584

Epoch: 6| Step: 11
Training loss: 3.1093605846281736
Validation loss: 2.928316521245768

Epoch: 6| Step: 12
Training loss: 2.6378237521082184
Validation loss: 2.926743476962835

Epoch: 6| Step: 13
Training loss: 3.298603924302866
Validation loss: 2.9277363810900106

Epoch: 28| Step: 0
Training loss: 3.0789634221113618
Validation loss: 2.9296209494849377

Epoch: 6| Step: 1
Training loss: 2.6876444223322316
Validation loss: 2.936291936921538

Epoch: 6| Step: 2
Training loss: 3.3750587740831457
Validation loss: 2.9409269905446718

Epoch: 6| Step: 3
Training loss: 3.638637802611542
Validation loss: 2.941321904373716

Epoch: 6| Step: 4
Training loss: 3.4419332873602695
Validation loss: 2.927777750370011

Epoch: 6| Step: 5
Training loss: 3.405106238725787
Validation loss: 2.9229953616842494

Epoch: 6| Step: 6
Training loss: 3.671457599696893
Validation loss: 2.919208556939441

Epoch: 6| Step: 7
Training loss: 3.2386815982074975
Validation loss: 2.919031208419771

Epoch: 6| Step: 8
Training loss: 2.1931295707613696
Validation loss: 2.9169563401579315

Epoch: 6| Step: 9
Training loss: 2.8427323417353323
Validation loss: 2.917317677869433

Epoch: 6| Step: 10
Training loss: 3.7383394147120783
Validation loss: 2.9167117969402456

Epoch: 6| Step: 11
Training loss: 2.5135889758450456
Validation loss: 2.9168261573769545

Epoch: 6| Step: 12
Training loss: 3.341793593154803
Validation loss: 2.9136932041392605

Epoch: 6| Step: 13
Training loss: 3.7098897318120643
Validation loss: 2.9144504571159318

Epoch: 29| Step: 0
Training loss: 3.0330723269448283
Validation loss: 2.9136980169667313

Epoch: 6| Step: 1
Training loss: 2.6740000344207235
Validation loss: 2.9131637463350923

Epoch: 6| Step: 2
Training loss: 3.2778663264093906
Validation loss: 2.9140175093403355

Epoch: 6| Step: 3
Training loss: 3.107967805889612
Validation loss: 2.92046478653435

Epoch: 6| Step: 4
Training loss: 3.1863966883598818
Validation loss: 2.917265482195806

Epoch: 6| Step: 5
Training loss: 3.249120153025866
Validation loss: 2.917655675769571

Epoch: 6| Step: 6
Training loss: 3.7924979140616046
Validation loss: 2.917979472052056

Epoch: 6| Step: 7
Training loss: 3.584015108647176
Validation loss: 2.9126970487401533

Epoch: 6| Step: 8
Training loss: 3.0532518217986695
Validation loss: 2.9085249820542947

Epoch: 6| Step: 9
Training loss: 3.0121534852617344
Validation loss: 2.9076167295812234

Epoch: 6| Step: 10
Training loss: 3.417184898958058
Validation loss: 2.9085435412364684

Epoch: 6| Step: 11
Training loss: 3.2336551768258013
Validation loss: 2.9067265383069185

Epoch: 6| Step: 12
Training loss: 2.392247964305412
Validation loss: 2.9067427391372953

Epoch: 6| Step: 13
Training loss: 3.9959785989258916
Validation loss: 2.9067166302582583

Epoch: 30| Step: 0
Training loss: 2.919099029648953
Validation loss: 2.90649787550569

Epoch: 6| Step: 1
Training loss: 2.8364454082559236
Validation loss: 2.904747062601575

Epoch: 6| Step: 2
Training loss: 2.719416657192093
Validation loss: 2.9031022158047377

Epoch: 6| Step: 3
Training loss: 3.463223014839312
Validation loss: 2.9006706470814936

Epoch: 6| Step: 4
Training loss: 3.9651935892841963
Validation loss: 2.899088629506332

Epoch: 6| Step: 5
Training loss: 2.900244794576699
Validation loss: 2.8967772142394663

Epoch: 6| Step: 6
Training loss: 3.935531850932861
Validation loss: 2.894072781770723

Epoch: 6| Step: 7
Training loss: 3.284466139148624
Validation loss: 2.8924717585395054

Epoch: 6| Step: 8
Training loss: 2.950686138984609
Validation loss: 2.890185053991248

Epoch: 6| Step: 9
Training loss: 3.0565894564407254
Validation loss: 2.8877841087522036

Epoch: 6| Step: 10
Training loss: 3.208161502216526
Validation loss: 2.886156529197549

Epoch: 6| Step: 11
Training loss: 3.1243628806092616
Validation loss: 2.886147876700496

Epoch: 6| Step: 12
Training loss: 3.318031299307774
Validation loss: 2.8843458199580705

Epoch: 6| Step: 13
Training loss: 2.4007962336570743
Validation loss: 2.8826931110761027

Epoch: 31| Step: 0
Training loss: 2.8080412383569935
Validation loss: 2.8809180731587265

Epoch: 6| Step: 1
Training loss: 2.1836033583755508
Validation loss: 2.8821976373332965

Epoch: 6| Step: 2
Training loss: 3.5793638791577123
Validation loss: 2.8806917829589667

Epoch: 6| Step: 3
Training loss: 3.64803780892505
Validation loss: 2.8805472398521226

Epoch: 6| Step: 4
Training loss: 2.743935573967077
Validation loss: 2.878019054064806

Epoch: 6| Step: 5
Training loss: 3.1523703724092687
Validation loss: 2.8778575982542485

Epoch: 6| Step: 6
Training loss: 2.9913048301355034
Validation loss: 2.881109023890025

Epoch: 6| Step: 7
Training loss: 3.133208518552115
Validation loss: 2.879314329625447

Epoch: 6| Step: 8
Training loss: 3.5370638089796946
Validation loss: 2.8829183015778903

Epoch: 6| Step: 9
Training loss: 3.2938461492355686
Validation loss: 2.8735441255228653

Epoch: 6| Step: 10
Training loss: 2.8826308774723195
Validation loss: 2.873655576450844

Epoch: 6| Step: 11
Training loss: 3.3449194458526446
Validation loss: 2.878034469614594

Epoch: 6| Step: 12
Training loss: 3.6659126084353875
Validation loss: 2.893403852028798

Epoch: 6| Step: 13
Training loss: 3.328098350740577
Validation loss: 2.8958270312707164

Epoch: 32| Step: 0
Training loss: 3.328503940840674
Validation loss: 2.8884891644505153

Epoch: 6| Step: 1
Training loss: 3.0094574628803494
Validation loss: 2.876545826213454

Epoch: 6| Step: 2
Training loss: 3.408066571404812
Validation loss: 2.8703195684026435

Epoch: 6| Step: 3
Training loss: 2.992613918905503
Validation loss: 2.8701698752727585

Epoch: 6| Step: 4
Training loss: 3.385139774834418
Validation loss: 2.8675449436105627

Epoch: 6| Step: 5
Training loss: 3.221108026539957
Validation loss: 2.8682889027449496

Epoch: 6| Step: 6
Training loss: 3.241764344326705
Validation loss: 2.8702183694634265

Epoch: 6| Step: 7
Training loss: 2.6847275028438857
Validation loss: 2.877264211085545

Epoch: 6| Step: 8
Training loss: 2.9785377176434755
Validation loss: 2.8808083911164264

Epoch: 6| Step: 9
Training loss: 2.8653526983812316
Validation loss: 2.896725167068049

Epoch: 6| Step: 10
Training loss: 3.5255426516735735
Validation loss: 2.917508639852096

Epoch: 6| Step: 11
Training loss: 2.9507388208079424
Validation loss: 2.9139361865645728

Epoch: 6| Step: 12
Training loss: 3.597578315014979
Validation loss: 2.897482225437416

Epoch: 6| Step: 13
Training loss: 3.4800644285442255
Validation loss: 2.872324234732031

Epoch: 33| Step: 0
Training loss: 3.08624188817234
Validation loss: 2.8633889595487627

Epoch: 6| Step: 1
Training loss: 3.088031145502069
Validation loss: 2.8631311476973473

Epoch: 6| Step: 2
Training loss: 3.2959172453167076
Validation loss: 2.8605478563100752

Epoch: 6| Step: 3
Training loss: 3.5977392197442732
Validation loss: 2.8593052600550743

Epoch: 6| Step: 4
Training loss: 3.331118101904808
Validation loss: 2.858341119112793

Epoch: 6| Step: 5
Training loss: 2.3853416153430116
Validation loss: 2.857038885230299

Epoch: 6| Step: 6
Training loss: 2.9852341618537452
Validation loss: 2.860546845389338

Epoch: 6| Step: 7
Training loss: 3.669386389676836
Validation loss: 2.856833008696165

Epoch: 6| Step: 8
Training loss: 3.168819816467298
Validation loss: 2.854695664447632

Epoch: 6| Step: 9
Training loss: 3.323648370205478
Validation loss: 2.856905520780547

Epoch: 6| Step: 10
Training loss: 3.1598627545937266
Validation loss: 2.855104306019228

Epoch: 6| Step: 11
Training loss: 2.687264897908422
Validation loss: 2.85626164894388

Epoch: 6| Step: 12
Training loss: 2.8992987738635962
Validation loss: 2.8585122134432943

Epoch: 6| Step: 13
Training loss: 3.690580471458195
Validation loss: 2.8556367773561893

Epoch: 34| Step: 0
Training loss: 2.890022668716597
Validation loss: 2.8562835957777812

Epoch: 6| Step: 1
Training loss: 3.1314660886718784
Validation loss: 2.852414895012614

Epoch: 6| Step: 2
Training loss: 3.041996106287604
Validation loss: 2.853727657387018

Epoch: 6| Step: 3
Training loss: 3.84311329600211
Validation loss: 2.8496496626774612

Epoch: 6| Step: 4
Training loss: 2.998019677451961
Validation loss: 2.850180170423052

Epoch: 6| Step: 5
Training loss: 2.921674425717235
Validation loss: 2.8495417135950234

Epoch: 6| Step: 6
Training loss: 2.883203495461296
Validation loss: 2.848314208900971

Epoch: 6| Step: 7
Training loss: 3.4263518846652086
Validation loss: 2.847711535537649

Epoch: 6| Step: 8
Training loss: 3.6026601711565704
Validation loss: 2.8457827852119064

Epoch: 6| Step: 9
Training loss: 3.2408376802346806
Validation loss: 2.843319434441773

Epoch: 6| Step: 10
Training loss: 3.1771444512830773
Validation loss: 2.8445446910303396

Epoch: 6| Step: 11
Training loss: 3.3538008464722306
Validation loss: 2.8432017756548107

Epoch: 6| Step: 12
Training loss: 2.275862092383852
Validation loss: 2.843744544116744

Epoch: 6| Step: 13
Training loss: 3.1227656196641536
Validation loss: 2.839712122036504

Epoch: 35| Step: 0
Training loss: 2.6633185189622486
Validation loss: 2.839699954316317

Epoch: 6| Step: 1
Training loss: 2.82860346166354
Validation loss: 2.8388304023997044

Epoch: 6| Step: 2
Training loss: 3.515967322743431
Validation loss: 2.839149890563087

Epoch: 6| Step: 3
Training loss: 3.066987933731846
Validation loss: 2.838203705538623

Epoch: 6| Step: 4
Training loss: 3.543532624213061
Validation loss: 2.838318782356242

Epoch: 6| Step: 5
Training loss: 3.379888032491996
Validation loss: 2.8367691187982143

Epoch: 6| Step: 6
Training loss: 3.3377470517963013
Validation loss: 2.8392242456902226

Epoch: 6| Step: 7
Training loss: 2.816060165326076
Validation loss: 2.841141791209365

Epoch: 6| Step: 8
Training loss: 3.473243620794494
Validation loss: 2.849070036361633

Epoch: 6| Step: 9
Training loss: 2.9206928983077947
Validation loss: 2.854279536479664

Epoch: 6| Step: 10
Training loss: 2.8758566865403004
Validation loss: 2.8697763116558006

Epoch: 6| Step: 11
Training loss: 3.087933553919652
Validation loss: 2.8753302154014353

Epoch: 6| Step: 12
Training loss: 3.205702028797518
Validation loss: 2.8728032897718836

Epoch: 6| Step: 13
Training loss: 3.3697119363887356
Validation loss: 2.8604924021196494

Epoch: 36| Step: 0
Training loss: 3.8948007258904753
Validation loss: 2.8511745555905605

Epoch: 6| Step: 1
Training loss: 2.7254884019687844
Validation loss: 2.8433443195007815

Epoch: 6| Step: 2
Training loss: 2.5700158408897633
Validation loss: 2.8323563430102645

Epoch: 6| Step: 3
Training loss: 3.375228732799936
Validation loss: 2.8277268565436358

Epoch: 6| Step: 4
Training loss: 3.0602453846497375
Validation loss: 2.8284166269890862

Epoch: 6| Step: 5
Training loss: 3.556136219638116
Validation loss: 2.8273876305142824

Epoch: 6| Step: 6
Training loss: 3.247184414113663
Validation loss: 2.826731036711503

Epoch: 6| Step: 7
Training loss: 3.451425954277288
Validation loss: 2.8262186731760632

Epoch: 6| Step: 8
Training loss: 2.669535186827193
Validation loss: 2.8269648030740444

Epoch: 6| Step: 9
Training loss: 2.683695473332473
Validation loss: 2.8260498846014186

Epoch: 6| Step: 10
Training loss: 2.8708980986695325
Validation loss: 2.824938114180638

Epoch: 6| Step: 11
Training loss: 3.1702428668155265
Validation loss: 2.824432052277413

Epoch: 6| Step: 12
Training loss: 3.01787455562621
Validation loss: 2.8230937140454357

Epoch: 6| Step: 13
Training loss: 3.589007490879935
Validation loss: 2.82125542307489

Epoch: 37| Step: 0
Training loss: 3.328671119548932
Validation loss: 2.8190546749543337

Epoch: 6| Step: 1
Training loss: 3.322924782355432
Validation loss: 2.820986357755958

Epoch: 6| Step: 2
Training loss: 2.7355318946324707
Validation loss: 2.8241843194226814

Epoch: 6| Step: 3
Training loss: 2.4112914146398645
Validation loss: 2.8287075396608747

Epoch: 6| Step: 4
Training loss: 3.1413430678837995
Validation loss: 2.8375614607913104

Epoch: 6| Step: 5
Training loss: 3.3486318157168973
Validation loss: 2.854835742312535

Epoch: 6| Step: 6
Training loss: 3.2835923326712977
Validation loss: 2.8530117674709983

Epoch: 6| Step: 7
Training loss: 3.0562864835780936
Validation loss: 2.840449887882108

Epoch: 6| Step: 8
Training loss: 2.8069652775763085
Validation loss: 2.825810886808395

Epoch: 6| Step: 9
Training loss: 2.7408510086666484
Validation loss: 2.813045010462994

Epoch: 6| Step: 10
Training loss: 3.9149432076613664
Validation loss: 2.813543456562213

Epoch: 6| Step: 11
Training loss: 3.17454018454654
Validation loss: 2.8060402952128993

Epoch: 6| Step: 12
Training loss: 3.4413802008449426
Validation loss: 2.8021875256808

Epoch: 6| Step: 13
Training loss: 2.520812189523177
Validation loss: 2.7963729795577383

Epoch: 38| Step: 0
Training loss: 3.404990006934919
Validation loss: 2.7965152711023302

Epoch: 6| Step: 1
Training loss: 2.9662101722998124
Validation loss: 2.7967517280464045

Epoch: 6| Step: 2
Training loss: 3.22986085054629
Validation loss: 2.7934505167326593

Epoch: 6| Step: 3
Training loss: 2.8287642794394894
Validation loss: 2.798073819729594

Epoch: 6| Step: 4
Training loss: 2.814504290717252
Validation loss: 2.8025233364755495

Epoch: 6| Step: 5
Training loss: 3.763346889145941
Validation loss: 2.804784111282854

Epoch: 6| Step: 6
Training loss: 2.0286723287384083
Validation loss: 2.809245783937413

Epoch: 6| Step: 7
Training loss: 2.8708967699222145
Validation loss: 2.806594431162428

Epoch: 6| Step: 8
Training loss: 3.619697375636052
Validation loss: 2.805847193287622

Epoch: 6| Step: 9
Training loss: 3.545446839357551
Validation loss: 2.806337107562054

Epoch: 6| Step: 10
Training loss: 3.1193755843036453
Validation loss: 2.7998601441972832

Epoch: 6| Step: 11
Training loss: 2.724785255579947
Validation loss: 2.7911209310127174

Epoch: 6| Step: 12
Training loss: 2.6784456005514703
Validation loss: 2.786592008834215

Epoch: 6| Step: 13
Training loss: 3.7962075733957987
Validation loss: 2.7876240719641667

Epoch: 39| Step: 0
Training loss: 3.1356108004434975
Validation loss: 2.784151078454348

Epoch: 6| Step: 1
Training loss: 2.972812643461165
Validation loss: 2.7852745328461026

Epoch: 6| Step: 2
Training loss: 2.7947461428200624
Validation loss: 2.782386424096991

Epoch: 6| Step: 3
Training loss: 3.337449742771037
Validation loss: 2.7832794251532005

Epoch: 6| Step: 4
Training loss: 2.518288854597103
Validation loss: 2.790222129113794

Epoch: 6| Step: 5
Training loss: 2.8187095757607508
Validation loss: 2.787946644720662

Epoch: 6| Step: 6
Training loss: 3.1688286946473627
Validation loss: 2.7888795778830824

Epoch: 6| Step: 7
Training loss: 3.6655616540142772
Validation loss: 2.792655392459428

Epoch: 6| Step: 8
Training loss: 3.0740177229380934
Validation loss: 2.798542850142693

Epoch: 6| Step: 9
Training loss: 3.1923394957293705
Validation loss: 2.788035851970778

Epoch: 6| Step: 10
Training loss: 3.0746710128334387
Validation loss: 2.778551926632782

Epoch: 6| Step: 11
Training loss: 3.3784734018726037
Validation loss: 2.778290761901532

Epoch: 6| Step: 12
Training loss: 2.994228692697397
Validation loss: 2.775087801538213

Epoch: 6| Step: 13
Training loss: 3.2759699891966636
Validation loss: 2.7736905666671174

Epoch: 40| Step: 0
Training loss: 3.22439864710259
Validation loss: 2.772282220584098

Epoch: 6| Step: 1
Training loss: 2.731519068682645
Validation loss: 2.771241095053463

Epoch: 6| Step: 2
Training loss: 4.535900386772794
Validation loss: 2.7784834501374913

Epoch: 6| Step: 3
Training loss: 2.7240646856976864
Validation loss: 2.7808278597513585

Epoch: 6| Step: 4
Training loss: 2.3017696207137717
Validation loss: 2.7836180299721005

Epoch: 6| Step: 5
Training loss: 3.238414214088321
Validation loss: 2.7934565737613233

Epoch: 6| Step: 6
Training loss: 2.7276339898558946
Validation loss: 2.7978107305312294

Epoch: 6| Step: 7
Training loss: 2.684782028869663
Validation loss: 2.7929504683068562

Epoch: 6| Step: 8
Training loss: 3.349317247647739
Validation loss: 2.780028545657724

Epoch: 6| Step: 9
Training loss: 3.4559696959915343
Validation loss: 2.7695907618083284

Epoch: 6| Step: 10
Training loss: 2.790772157144553
Validation loss: 2.767125387286727

Epoch: 6| Step: 11
Training loss: 2.959650811914608
Validation loss: 2.76470456044454

Epoch: 6| Step: 12
Training loss: 3.0465457053625964
Validation loss: 2.7662956963761647

Epoch: 6| Step: 13
Training loss: 2.9215854766526506
Validation loss: 2.7664226968770538

Epoch: 41| Step: 0
Training loss: 3.0359567497298885
Validation loss: 2.772926652567884

Epoch: 6| Step: 1
Training loss: 3.0371767288049982
Validation loss: 2.779056487857659

Epoch: 6| Step: 2
Training loss: 2.4023661790746673
Validation loss: 2.767930503119897

Epoch: 6| Step: 3
Training loss: 2.9602188405769
Validation loss: 2.767186463718069

Epoch: 6| Step: 4
Training loss: 3.2317274379147745
Validation loss: 2.7642010711916263

Epoch: 6| Step: 5
Training loss: 3.1248895244144106
Validation loss: 2.761917984525327

Epoch: 6| Step: 6
Training loss: 2.8608341350456143
Validation loss: 2.761909935074144

Epoch: 6| Step: 7
Training loss: 3.2478401636718157
Validation loss: 2.7619507427278753

Epoch: 6| Step: 8
Training loss: 3.235739599758653
Validation loss: 2.7663775292080732

Epoch: 6| Step: 9
Training loss: 2.1867923136797756
Validation loss: 2.7754273734140433

Epoch: 6| Step: 10
Training loss: 3.72948413257673
Validation loss: 2.787096074362294

Epoch: 6| Step: 11
Training loss: 3.5758929224560254
Validation loss: 2.798550451620405

Epoch: 6| Step: 12
Training loss: 2.8019194903682316
Validation loss: 2.7814137593905395

Epoch: 6| Step: 13
Training loss: 3.802187621197448
Validation loss: 2.7724625316487668

Epoch: 42| Step: 0
Training loss: 2.5756161591438977
Validation loss: 2.7607433556855887

Epoch: 6| Step: 1
Training loss: 3.2285967087991723
Validation loss: 2.7584480492904913

Epoch: 6| Step: 2
Training loss: 3.4670967079848714
Validation loss: 2.761802728107782

Epoch: 6| Step: 3
Training loss: 2.631194480618342
Validation loss: 2.7670646745419143

Epoch: 6| Step: 4
Training loss: 2.8008547976744973
Validation loss: 2.7686147712489824

Epoch: 6| Step: 5
Training loss: 3.201463221755625
Validation loss: 2.764623615595101

Epoch: 6| Step: 6
Training loss: 3.10454517762066
Validation loss: 2.762883896871402

Epoch: 6| Step: 7
Training loss: 3.768405505072295
Validation loss: 2.7601053283297694

Epoch: 6| Step: 8
Training loss: 3.026886621232756
Validation loss: 2.760355336735999

Epoch: 6| Step: 9
Training loss: 2.401513925531452
Validation loss: 2.7587514419596872

Epoch: 6| Step: 10
Training loss: 2.6650828983088686
Validation loss: 2.757209949750061

Epoch: 6| Step: 11
Training loss: 3.3796486099693377
Validation loss: 2.757101398670123

Epoch: 6| Step: 12
Training loss: 3.0614489873323993
Validation loss: 2.7564468439622876

Epoch: 6| Step: 13
Training loss: 4.062288014676528
Validation loss: 2.7547818110083497

Epoch: 43| Step: 0
Training loss: 2.8021913434356747
Validation loss: 2.752960001551498

Epoch: 6| Step: 1
Training loss: 3.116355230373296
Validation loss: 2.7533133115216497

Epoch: 6| Step: 2
Training loss: 3.7161776838249794
Validation loss: 2.7529073576502516

Epoch: 6| Step: 3
Training loss: 2.8957513664958356
Validation loss: 2.7509855590674603

Epoch: 6| Step: 4
Training loss: 3.465440976044357
Validation loss: 2.7498531563372395

Epoch: 6| Step: 5
Training loss: 2.8217007504015896
Validation loss: 2.749477433776754

Epoch: 6| Step: 6
Training loss: 2.674452313836535
Validation loss: 2.7494958310996513

Epoch: 6| Step: 7
Training loss: 3.0427769415639525
Validation loss: 2.74862096651808

Epoch: 6| Step: 8
Training loss: 3.022569635313202
Validation loss: 2.7453952507123134

Epoch: 6| Step: 9
Training loss: 3.1141691581043065
Validation loss: 2.746708892772863

Epoch: 6| Step: 10
Training loss: 2.9460362524118575
Validation loss: 2.746160395037354

Epoch: 6| Step: 11
Training loss: 3.2816435078400623
Validation loss: 2.7454011261539693

Epoch: 6| Step: 12
Training loss: 3.0405550628177833
Validation loss: 2.7472547437261

Epoch: 6| Step: 13
Training loss: 2.959423312122149
Validation loss: 2.755711762556533

Epoch: 44| Step: 0
Training loss: 3.5710082596998745
Validation loss: 2.7723785518645427

Epoch: 6| Step: 1
Training loss: 2.5804054116200175
Validation loss: 2.777070530784818

Epoch: 6| Step: 2
Training loss: 2.8564399706146633
Validation loss: 2.777504009852634

Epoch: 6| Step: 3
Training loss: 2.267228920240769
Validation loss: 2.7650274993125965

Epoch: 6| Step: 4
Training loss: 2.6731187033963737
Validation loss: 2.787143820229219

Epoch: 6| Step: 5
Training loss: 3.631539070323643
Validation loss: 2.7750280066764454

Epoch: 6| Step: 6
Training loss: 2.9359262999137754
Validation loss: 2.768052249570431

Epoch: 6| Step: 7
Training loss: 2.8212173151735076
Validation loss: 2.7467414646266444

Epoch: 6| Step: 8
Training loss: 3.5276387071272564
Validation loss: 2.7387219806153564

Epoch: 6| Step: 9
Training loss: 3.2821712109007986
Validation loss: 2.7419559098278534

Epoch: 6| Step: 10
Training loss: 2.7442605206236728
Validation loss: 2.743365073473906

Epoch: 6| Step: 11
Training loss: 3.4906260436627665
Validation loss: 2.744965715516055

Epoch: 6| Step: 12
Training loss: 3.532977466536227
Validation loss: 2.748101159654503

Epoch: 6| Step: 13
Training loss: 2.604709772061675
Validation loss: 2.7428123066850976

Epoch: 45| Step: 0
Training loss: 3.1421846531077824
Validation loss: 2.740948348267595

Epoch: 6| Step: 1
Training loss: 3.142057936476009
Validation loss: 2.740260260755742

Epoch: 6| Step: 2
Training loss: 2.902615150710608
Validation loss: 2.741984984369093

Epoch: 6| Step: 3
Training loss: 3.0436915272573444
Validation loss: 2.7429806572158544

Epoch: 6| Step: 4
Training loss: 2.8422069345473533
Validation loss: 2.7430150659169907

Epoch: 6| Step: 5
Training loss: 3.7247117923123954
Validation loss: 2.74562600175419

Epoch: 6| Step: 6
Training loss: 2.5763769523661697
Validation loss: 2.7491837424641816

Epoch: 6| Step: 7
Training loss: 2.014509853639077
Validation loss: 2.7554762115108145

Epoch: 6| Step: 8
Training loss: 3.64822119126741
Validation loss: 2.7479045935541615

Epoch: 6| Step: 9
Training loss: 2.9438897296115396
Validation loss: 2.742310074282778

Epoch: 6| Step: 10
Training loss: 2.9698948309160143
Validation loss: 2.73515820749658

Epoch: 6| Step: 11
Training loss: 3.4165391820678686
Validation loss: 2.7295540581109545

Epoch: 6| Step: 12
Training loss: 3.170066280213596
Validation loss: 2.7286493230156936

Epoch: 6| Step: 13
Training loss: 3.03075900476407
Validation loss: 2.728233227245579

Epoch: 46| Step: 0
Training loss: 3.0212610577723047
Validation loss: 2.7291053164519776

Epoch: 6| Step: 1
Training loss: 2.8617177235827738
Validation loss: 2.7301764525049177

Epoch: 6| Step: 2
Training loss: 3.215731195859417
Validation loss: 2.7312975576282383

Epoch: 6| Step: 3
Training loss: 3.7922245635243903
Validation loss: 2.7311947809550183

Epoch: 6| Step: 4
Training loss: 3.563916376539276
Validation loss: 2.7315060069865225

Epoch: 6| Step: 5
Training loss: 3.3791151037331275
Validation loss: 2.7297152772768074

Epoch: 6| Step: 6
Training loss: 2.614304597341221
Validation loss: 2.7280930952640325

Epoch: 6| Step: 7
Training loss: 2.4693920411236636
Validation loss: 2.7268491134160735

Epoch: 6| Step: 8
Training loss: 2.725071190420332
Validation loss: 2.726088852976168

Epoch: 6| Step: 9
Training loss: 3.0678140117963673
Validation loss: 2.726587627029606

Epoch: 6| Step: 10
Training loss: 2.525642022573703
Validation loss: 2.729796885343619

Epoch: 6| Step: 11
Training loss: 2.892975712251952
Validation loss: 2.7373220624419794

Epoch: 6| Step: 12
Training loss: 2.8439974834361257
Validation loss: 2.761301768878127

Epoch: 6| Step: 13
Training loss: 3.9585582200799694
Validation loss: 2.789466364255891

Epoch: 47| Step: 0
Training loss: 2.109008305077007
Validation loss: 2.7601020519157804

Epoch: 6| Step: 1
Training loss: 3.2434811872110485
Validation loss: 2.73996270061471

Epoch: 6| Step: 2
Training loss: 2.926602379506299
Validation loss: 2.7197945238101546

Epoch: 6| Step: 3
Training loss: 2.504367922684123
Validation loss: 2.7191140715278506

Epoch: 6| Step: 4
Training loss: 3.312808040475196
Validation loss: 2.7204607035850428

Epoch: 6| Step: 5
Training loss: 3.060211728070082
Validation loss: 2.724527931473671

Epoch: 6| Step: 6
Training loss: 3.2740448818404526
Validation loss: 2.734757205250918

Epoch: 6| Step: 7
Training loss: 3.1647583749631525
Validation loss: 2.7334775975025947

Epoch: 6| Step: 8
Training loss: 2.9772714486473455
Validation loss: 2.7303380424227375

Epoch: 6| Step: 9
Training loss: 3.074450628316316
Validation loss: 2.7253071051871034

Epoch: 6| Step: 10
Training loss: 3.77792312928365
Validation loss: 2.725305491921214

Epoch: 6| Step: 11
Training loss: 3.1402964254038657
Validation loss: 2.726638239558331

Epoch: 6| Step: 12
Training loss: 3.1086334417723127
Validation loss: 2.728613425319021

Epoch: 6| Step: 13
Training loss: 2.6206960362150737
Validation loss: 2.721749600656746

Epoch: 48| Step: 0
Training loss: 2.705866399276513
Validation loss: 2.721543960009553

Epoch: 6| Step: 1
Training loss: 2.9882748672317456
Validation loss: 2.722646605221104

Epoch: 6| Step: 2
Training loss: 2.999922751385813
Validation loss: 2.7188161998209646

Epoch: 6| Step: 3
Training loss: 3.1620093948929235
Validation loss: 2.7167126191998374

Epoch: 6| Step: 4
Training loss: 3.2654798557569595
Validation loss: 2.715680264057754

Epoch: 6| Step: 5
Training loss: 3.281154958165961
Validation loss: 2.714866069502174

Epoch: 6| Step: 6
Training loss: 2.906103971360694
Validation loss: 2.7158190102993025

Epoch: 6| Step: 7
Training loss: 3.487348169009239
Validation loss: 2.711706036661948

Epoch: 6| Step: 8
Training loss: 2.2933261989142464
Validation loss: 2.714319457099531

Epoch: 6| Step: 9
Training loss: 2.5059171270076788
Validation loss: 2.7114722250051035

Epoch: 6| Step: 10
Training loss: 2.743812535991848
Validation loss: 2.7133932744835154

Epoch: 6| Step: 11
Training loss: 3.5164365382776888
Validation loss: 2.716003608364069

Epoch: 6| Step: 12
Training loss: 3.193795662570311
Validation loss: 2.7148854992934077

Epoch: 6| Step: 13
Training loss: 3.6101932011099933
Validation loss: 2.713763410612254

Epoch: 49| Step: 0
Training loss: 2.5772454813400385
Validation loss: 2.7101777232443984

Epoch: 6| Step: 1
Training loss: 2.6816575174153856
Validation loss: 2.7065222680631185

Epoch: 6| Step: 2
Training loss: 2.8777237304888312
Validation loss: 2.7054175947860055

Epoch: 6| Step: 3
Training loss: 2.8233994262357496
Validation loss: 2.703824702602199

Epoch: 6| Step: 4
Training loss: 3.049956655976035
Validation loss: 2.7031538501389933

Epoch: 6| Step: 5
Training loss: 2.8360353563308056
Validation loss: 2.7005586625748057

Epoch: 6| Step: 6
Training loss: 3.21689189128988
Validation loss: 2.7024682526501738

Epoch: 6| Step: 7
Training loss: 2.7424676214095913
Validation loss: 2.70297069110307

Epoch: 6| Step: 8
Training loss: 3.7038634002659427
Validation loss: 2.699589129716514

Epoch: 6| Step: 9
Training loss: 3.283149097004896
Validation loss: 2.6995604219151574

Epoch: 6| Step: 10
Training loss: 3.4995236753863868
Validation loss: 2.698259737968979

Epoch: 6| Step: 11
Training loss: 3.0282658310965074
Validation loss: 2.696766069715924

Epoch: 6| Step: 12
Training loss: 3.18316115734238
Validation loss: 2.698128761800959

Epoch: 6| Step: 13
Training loss: 2.69334370675623
Validation loss: 2.6951197163656397

Epoch: 50| Step: 0
Training loss: 3.0767078526124556
Validation loss: 2.695587090000514

Epoch: 6| Step: 1
Training loss: 3.071342625476892
Validation loss: 2.696391588526864

Epoch: 6| Step: 2
Training loss: 2.428969102244449
Validation loss: 2.694377148231185

Epoch: 6| Step: 3
Training loss: 3.341406740906996
Validation loss: 2.691940769142272

Epoch: 6| Step: 4
Training loss: 3.1864462213866958
Validation loss: 2.692017593246823

Epoch: 6| Step: 5
Training loss: 3.1942720468044956
Validation loss: 2.6913270118139216

Epoch: 6| Step: 6
Training loss: 2.8168927115151643
Validation loss: 2.6899512621676793

Epoch: 6| Step: 7
Training loss: 3.1571223498111767
Validation loss: 2.6944819724285782

Epoch: 6| Step: 8
Training loss: 2.66006760862663
Validation loss: 2.6887289892084643

Epoch: 6| Step: 9
Training loss: 3.0521007619800655
Validation loss: 2.687708067989595

Epoch: 6| Step: 10
Training loss: 3.0997718234841116
Validation loss: 2.689764075047108

Epoch: 6| Step: 11
Training loss: 3.4891980921718986
Validation loss: 2.688562817862686

Epoch: 6| Step: 12
Training loss: 2.5311876454149482
Validation loss: 2.690087770752506

Epoch: 6| Step: 13
Training loss: 3.1780695817554863
Validation loss: 2.697960791490486

Epoch: 51| Step: 0
Training loss: 3.4473881772656494
Validation loss: 2.6916810156250746

Epoch: 6| Step: 1
Training loss: 2.899373440636201
Validation loss: 2.6972092232173495

Epoch: 6| Step: 2
Training loss: 3.2787730722782675
Validation loss: 2.6866693302805875

Epoch: 6| Step: 3
Training loss: 2.738736407317186
Validation loss: 2.686777032410624

Epoch: 6| Step: 4
Training loss: 3.2972287535145224
Validation loss: 2.6890372887353275

Epoch: 6| Step: 5
Training loss: 3.3533400154679183
Validation loss: 2.687938049704827

Epoch: 6| Step: 6
Training loss: 2.4513839082844404
Validation loss: 2.692241978122246

Epoch: 6| Step: 7
Training loss: 3.1864218290860324
Validation loss: 2.6841683175166327

Epoch: 6| Step: 8
Training loss: 2.6696999603448663
Validation loss: 2.6833281067242094

Epoch: 6| Step: 9
Training loss: 3.193587231454188
Validation loss: 2.681119849509351

Epoch: 6| Step: 10
Training loss: 2.848310063242699
Validation loss: 2.6816723543557246

Epoch: 6| Step: 11
Training loss: 3.1212671491940873
Validation loss: 2.684809210303437

Epoch: 6| Step: 12
Training loss: 3.103239053126525
Validation loss: 2.682189485152967

Epoch: 6| Step: 13
Training loss: 2.2156194172991968
Validation loss: 2.6815772779725764

Epoch: 52| Step: 0
Training loss: 3.3452558602638875
Validation loss: 2.6808645461131566

Epoch: 6| Step: 1
Training loss: 3.3755232793846894
Validation loss: 2.6801909319991997

Epoch: 6| Step: 2
Training loss: 3.3386910931279687
Validation loss: 2.680964552322373

Epoch: 6| Step: 3
Training loss: 2.5480380532853095
Validation loss: 2.679503072730636

Epoch: 6| Step: 4
Training loss: 3.1424995256057904
Validation loss: 2.678278254194756

Epoch: 6| Step: 5
Training loss: 3.8027121803329575
Validation loss: 2.6791222026676187

Epoch: 6| Step: 6
Training loss: 2.882669254041858
Validation loss: 2.677719811118024

Epoch: 6| Step: 7
Training loss: 2.1510555337700588
Validation loss: 2.6762718508418932

Epoch: 6| Step: 8
Training loss: 2.116951228960729
Validation loss: 2.677015090544368

Epoch: 6| Step: 9
Training loss: 2.6886046157753025
Validation loss: 2.675671518601429

Epoch: 6| Step: 10
Training loss: 3.0834032686567427
Validation loss: 2.67868232464284

Epoch: 6| Step: 11
Training loss: 3.4023597270183137
Validation loss: 2.6981822412223297

Epoch: 6| Step: 12
Training loss: 2.7668974799274206
Validation loss: 2.712124082933692

Epoch: 6| Step: 13
Training loss: 3.2988340514396883
Validation loss: 2.781191288898828

Epoch: 53| Step: 0
Training loss: 3.2613304409576758
Validation loss: 2.7268033099807156

Epoch: 6| Step: 1
Training loss: 3.2092081503876697
Validation loss: 2.68303890522483

Epoch: 6| Step: 2
Training loss: 3.765257251558007
Validation loss: 2.6757749994101805

Epoch: 6| Step: 3
Training loss: 2.7088396821713268
Validation loss: 2.685232000571871

Epoch: 6| Step: 4
Training loss: 2.6225916395731503
Validation loss: 2.70982170068778

Epoch: 6| Step: 5
Training loss: 3.185374729503328
Validation loss: 2.7563300826822053

Epoch: 6| Step: 6
Training loss: 2.9037014851846386
Validation loss: 2.6955486606112533

Epoch: 6| Step: 7
Training loss: 2.8678182381103547
Validation loss: 2.683416655175534

Epoch: 6| Step: 8
Training loss: 3.1202878902345432
Validation loss: 2.68094646979761

Epoch: 6| Step: 9
Training loss: 3.182924464732608
Validation loss: 2.6781841552640038

Epoch: 6| Step: 10
Training loss: 3.0838074878024035
Validation loss: 2.6847118969022645

Epoch: 6| Step: 11
Training loss: 3.066095227061001
Validation loss: 2.7206021059811056

Epoch: 6| Step: 12
Training loss: 2.2804982239980376
Validation loss: 2.786269430144493

Epoch: 6| Step: 13
Training loss: 3.2285748503434175
Validation loss: 2.7758301044787332

Epoch: 54| Step: 0
Training loss: 3.201085180815854
Validation loss: 2.73013036684603

Epoch: 6| Step: 1
Training loss: 3.2910205512759867
Validation loss: 2.7004368275997095

Epoch: 6| Step: 2
Training loss: 3.3268427281495887
Validation loss: 2.67415635440458

Epoch: 6| Step: 3
Training loss: 2.7313842111953934
Validation loss: 2.6822783627027316

Epoch: 6| Step: 4
Training loss: 3.314280625160895
Validation loss: 2.7140019981953714

Epoch: 6| Step: 5
Training loss: 3.0457652100451997
Validation loss: 2.817816005623366

Epoch: 6| Step: 6
Training loss: 2.909262951456147
Validation loss: 2.910441514259701

Epoch: 6| Step: 7
Training loss: 3.0840363259557195
Validation loss: 2.8825488666528645

Epoch: 6| Step: 8
Training loss: 3.223897281165204
Validation loss: 2.829671603301918

Epoch: 6| Step: 9
Training loss: 3.6262049809803796
Validation loss: 2.791712083907775

Epoch: 6| Step: 10
Training loss: 2.433067203582934
Validation loss: 2.7399323723524156

Epoch: 6| Step: 11
Training loss: 2.36303820660764
Validation loss: 2.7373217327761465

Epoch: 6| Step: 12
Training loss: 3.323635744998192
Validation loss: 2.7367176836330147

Epoch: 6| Step: 13
Training loss: 3.5772864012860603
Validation loss: 2.754979706575526

Epoch: 55| Step: 0
Training loss: 3.06315325562265
Validation loss: 2.7770401905134934

Epoch: 6| Step: 1
Training loss: 3.193822536652574
Validation loss: 2.7568726170742743

Epoch: 6| Step: 2
Training loss: 3.790752482334374
Validation loss: 2.749948447034183

Epoch: 6| Step: 3
Training loss: 2.9053600958714445
Validation loss: 2.735680133012177

Epoch: 6| Step: 4
Training loss: 2.632626490148821
Validation loss: 2.717635523539568

Epoch: 6| Step: 5
Training loss: 3.2118126634857065
Validation loss: 2.7086667621543246

Epoch: 6| Step: 6
Training loss: 2.8647465514876274
Validation loss: 2.696716878651095

Epoch: 6| Step: 7
Training loss: 2.483625478862824
Validation loss: 2.6968622542164353

Epoch: 6| Step: 8
Training loss: 2.744797553985671
Validation loss: 2.7073031666255476

Epoch: 6| Step: 9
Training loss: 3.084299932646617
Validation loss: 2.7279634955525354

Epoch: 6| Step: 10
Training loss: 2.982510288729192
Validation loss: 2.7387779028507206

Epoch: 6| Step: 11
Training loss: 3.591648980353076
Validation loss: 2.7426314783194146

Epoch: 6| Step: 12
Training loss: 2.6790752990552194
Validation loss: 2.7194382359013254

Epoch: 6| Step: 13
Training loss: 3.6139241404422275
Validation loss: 2.7210331977119457

Epoch: 56| Step: 0
Training loss: 3.1938461259384234
Validation loss: 2.706531323360304

Epoch: 6| Step: 1
Training loss: 3.39338339832998
Validation loss: 2.7050900244718576

Epoch: 6| Step: 2
Training loss: 2.9621866052382537
Validation loss: 2.7090892178661954

Epoch: 6| Step: 3
Training loss: 2.9301090191553865
Validation loss: 2.6879697094931667

Epoch: 6| Step: 4
Training loss: 2.9159688568963915
Validation loss: 2.6836616147025385

Epoch: 6| Step: 5
Training loss: 2.949551473884585
Validation loss: 2.684161249790829

Epoch: 6| Step: 6
Training loss: 2.736119874358196
Validation loss: 2.6853442941218675

Epoch: 6| Step: 7
Training loss: 3.2804613891431766
Validation loss: 2.6865343799719277

Epoch: 6| Step: 8
Training loss: 3.069497657955188
Validation loss: 2.690682572199812

Epoch: 6| Step: 9
Training loss: 3.657752095293638
Validation loss: 2.687204195395424

Epoch: 6| Step: 10
Training loss: 2.359230289695021
Validation loss: 2.6895611626966365

Epoch: 6| Step: 11
Training loss: 2.776515574319012
Validation loss: 2.691052617779568

Epoch: 6| Step: 12
Training loss: 2.8440209563565655
Validation loss: 2.6818971774910043

Epoch: 6| Step: 13
Training loss: 3.1802904461829455
Validation loss: 2.678985269300911

Epoch: 57| Step: 0
Training loss: 2.705626460388029
Validation loss: 2.67726559978325

Epoch: 6| Step: 1
Training loss: 3.0144870963264143
Validation loss: 2.676841138498788

Epoch: 6| Step: 2
Training loss: 3.4746456047858207
Validation loss: 2.659796637425978

Epoch: 6| Step: 3
Training loss: 2.7677486908228786
Validation loss: 2.650395314315865

Epoch: 6| Step: 4
Training loss: 3.2229876723519766
Validation loss: 2.6545221488982205

Epoch: 6| Step: 5
Training loss: 3.4736056322734754
Validation loss: 2.6544936104330086

Epoch: 6| Step: 6
Training loss: 3.150199302544516
Validation loss: 2.6522016584920727

Epoch: 6| Step: 7
Training loss: 2.335403840718595
Validation loss: 2.665348273769913

Epoch: 6| Step: 8
Training loss: 3.2038047999570805
Validation loss: 2.6872169114685978

Epoch: 6| Step: 9
Training loss: 2.600518461033168
Validation loss: 2.7087704683573435

Epoch: 6| Step: 10
Training loss: 3.067332289509498
Validation loss: 2.7064581062469952

Epoch: 6| Step: 11
Training loss: 2.78246657948675
Validation loss: 2.701807238042445

Epoch: 6| Step: 12
Training loss: 3.43679802402745
Validation loss: 2.670395680586026

Epoch: 6| Step: 13
Training loss: 2.802612982589977
Validation loss: 2.6562770448836424

Epoch: 58| Step: 0
Training loss: 2.51486450452201
Validation loss: 2.647910530277695

Epoch: 6| Step: 1
Training loss: 3.2563947707666174
Validation loss: 2.6423197161857193

Epoch: 6| Step: 2
Training loss: 3.4183984104944662
Validation loss: 2.639800486969904

Epoch: 6| Step: 3
Training loss: 2.4436173581079914
Validation loss: 2.6411925645989913

Epoch: 6| Step: 4
Training loss: 3.1602538745640003
Validation loss: 2.638804353274954

Epoch: 6| Step: 5
Training loss: 3.3184389819946487
Validation loss: 2.637501052633065

Epoch: 6| Step: 6
Training loss: 2.7953073381063906
Validation loss: 2.6373054331152654

Epoch: 6| Step: 7
Training loss: 2.861036807909143
Validation loss: 2.6407014374950815

Epoch: 6| Step: 8
Training loss: 3.8478625866707974
Validation loss: 2.644946073502702

Epoch: 6| Step: 9
Training loss: 2.8942478880362588
Validation loss: 2.649742608079859

Epoch: 6| Step: 10
Training loss: 3.214582838222015
Validation loss: 2.6545186016464677

Epoch: 6| Step: 11
Training loss: 2.7376166610594255
Validation loss: 2.654469196522427

Epoch: 6| Step: 12
Training loss: 2.595215532763902
Validation loss: 2.645665306263993

Epoch: 6| Step: 13
Training loss: 2.4281428784432695
Validation loss: 2.644711451756345

Epoch: 59| Step: 0
Training loss: 2.4850790117931334
Validation loss: 2.6410643101771263

Epoch: 6| Step: 1
Training loss: 3.1448528622896905
Validation loss: 2.640408212804331

Epoch: 6| Step: 2
Training loss: 3.164065363376405
Validation loss: 2.639783121790526

Epoch: 6| Step: 3
Training loss: 2.750717416297299
Validation loss: 2.6361506150740324

Epoch: 6| Step: 4
Training loss: 2.971156379787893
Validation loss: 2.637647578913205

Epoch: 6| Step: 5
Training loss: 3.2894372432095675
Validation loss: 2.6447245000915203

Epoch: 6| Step: 6
Training loss: 2.67504641055908
Validation loss: 2.6496716454362854

Epoch: 6| Step: 7
Training loss: 2.998867138907839
Validation loss: 2.6729306175413856

Epoch: 6| Step: 8
Training loss: 3.511085665351741
Validation loss: 2.687199596071673

Epoch: 6| Step: 9
Training loss: 3.487069905330004
Validation loss: 2.6729950326655856

Epoch: 6| Step: 10
Training loss: 3.1347650165497853
Validation loss: 2.6641846829872344

Epoch: 6| Step: 11
Training loss: 2.7742134835427694
Validation loss: 2.661782077514518

Epoch: 6| Step: 12
Training loss: 2.3067346823408963
Validation loss: 2.649576827593236

Epoch: 6| Step: 13
Training loss: 3.0721163122291215
Validation loss: 2.6491220170247285

Epoch: 60| Step: 0
Training loss: 3.283536277992311
Validation loss: 2.6413450687066353

Epoch: 6| Step: 1
Training loss: 3.1181235377984393
Validation loss: 2.635061622824194

Epoch: 6| Step: 2
Training loss: 2.3460337384424803
Validation loss: 2.633148276136535

Epoch: 6| Step: 3
Training loss: 2.828310712754969
Validation loss: 2.6311277978907675

Epoch: 6| Step: 4
Training loss: 2.3636295787006976
Validation loss: 2.6317675108026433

Epoch: 6| Step: 5
Training loss: 2.4513042520591624
Validation loss: 2.629350739572939

Epoch: 6| Step: 6
Training loss: 3.1784068534948093
Validation loss: 2.632894067847835

Epoch: 6| Step: 7
Training loss: 3.067743289318739
Validation loss: 2.6305630592829132

Epoch: 6| Step: 8
Training loss: 3.1294694600782575
Validation loss: 2.6306513431608947

Epoch: 6| Step: 9
Training loss: 2.683203434218709
Validation loss: 2.6295299430453754

Epoch: 6| Step: 10
Training loss: 3.6847765935829404
Validation loss: 2.630343617302808

Epoch: 6| Step: 11
Training loss: 3.263842228404882
Validation loss: 2.6316290875619788

Epoch: 6| Step: 12
Training loss: 3.037619907853819
Validation loss: 2.630924389493509

Epoch: 6| Step: 13
Training loss: 3.105565176372453
Validation loss: 2.6291093893933275

Epoch: 61| Step: 0
Training loss: 3.2746384632229764
Validation loss: 2.6282521458522954

Epoch: 6| Step: 1
Training loss: 2.5336128791700956
Validation loss: 2.6294782754571786

Epoch: 6| Step: 2
Training loss: 3.173438678029385
Validation loss: 2.6360740660430073

Epoch: 6| Step: 3
Training loss: 3.139020975160108
Validation loss: 2.6391576253051223

Epoch: 6| Step: 4
Training loss: 2.6126755723865545
Validation loss: 2.647316476692647

Epoch: 6| Step: 5
Training loss: 2.905728201014993
Validation loss: 2.653191369848674

Epoch: 6| Step: 6
Training loss: 3.085936572883563
Validation loss: 2.663470993026123

Epoch: 6| Step: 7
Training loss: 2.8018832412996755
Validation loss: 2.6622019399349144

Epoch: 6| Step: 8
Training loss: 3.2016148426548763
Validation loss: 2.6600254904828438

Epoch: 6| Step: 9
Training loss: 2.8467562369103008
Validation loss: 2.659081784187829

Epoch: 6| Step: 10
Training loss: 3.436126295786181
Validation loss: 2.674841462601913

Epoch: 6| Step: 11
Training loss: 2.7987723281739787
Validation loss: 2.6695369980131334

Epoch: 6| Step: 12
Training loss: 3.135351051497342
Validation loss: 2.6540509516218633

Epoch: 6| Step: 13
Training loss: 2.5722926898016167
Validation loss: 2.631970488775965

Epoch: 62| Step: 0
Training loss: 2.5251712098949306
Validation loss: 2.625384955396535

Epoch: 6| Step: 1
Training loss: 2.552716629445302
Validation loss: 2.6220910253359957

Epoch: 6| Step: 2
Training loss: 3.055571211187156
Validation loss: 2.6194703520687717

Epoch: 6| Step: 3
Training loss: 3.4943708383408834
Validation loss: 2.6192812664109253

Epoch: 6| Step: 4
Training loss: 2.535606026976933
Validation loss: 2.6204136395725817

Epoch: 6| Step: 5
Training loss: 3.3908809442209646
Validation loss: 2.6212570325161577

Epoch: 6| Step: 6
Training loss: 2.530684796562144
Validation loss: 2.620637411278811

Epoch: 6| Step: 7
Training loss: 3.2350881776186213
Validation loss: 2.6206901687914836

Epoch: 6| Step: 8
Training loss: 2.90060467171034
Validation loss: 2.6217453933626675

Epoch: 6| Step: 9
Training loss: 2.830689674155765
Validation loss: 2.620175222345677

Epoch: 6| Step: 10
Training loss: 3.0297942451137847
Validation loss: 2.6183865088669815

Epoch: 6| Step: 11
Training loss: 2.8763341710499852
Validation loss: 2.6187186642580436

Epoch: 6| Step: 12
Training loss: 3.6434891203310467
Validation loss: 2.6164588037445236

Epoch: 6| Step: 13
Training loss: 2.7376250216706715
Validation loss: 2.616374118106822

Epoch: 63| Step: 0
Training loss: 2.9090996994080816
Validation loss: 2.620081925082341

Epoch: 6| Step: 1
Training loss: 2.4498816753541557
Validation loss: 2.6418868519067527

Epoch: 6| Step: 2
Training loss: 2.821039079819378
Validation loss: 2.6901078636274987

Epoch: 6| Step: 3
Training loss: 3.2555646940355496
Validation loss: 2.7429853863816978

Epoch: 6| Step: 4
Training loss: 3.0803933088181643
Validation loss: 2.680574263992099

Epoch: 6| Step: 5
Training loss: 2.764327957405074
Validation loss: 2.6317682082679186

Epoch: 6| Step: 6
Training loss: 3.3163957539494535
Validation loss: 2.6203192814404432

Epoch: 6| Step: 7
Training loss: 2.964244917754618
Validation loss: 2.6112409962425485

Epoch: 6| Step: 8
Training loss: 3.1835257493696223
Validation loss: 2.612453364934225

Epoch: 6| Step: 9
Training loss: 3.121875879785912
Validation loss: 2.6109329101151397

Epoch: 6| Step: 10
Training loss: 2.5678387364410535
Validation loss: 2.612571739306532

Epoch: 6| Step: 11
Training loss: 3.077696484786279
Validation loss: 2.6144150020894665

Epoch: 6| Step: 12
Training loss: 2.7340945726737798
Validation loss: 2.613486180669422

Epoch: 6| Step: 13
Training loss: 3.696653094689577
Validation loss: 2.6124044007637592

Epoch: 64| Step: 0
Training loss: 3.2876398267127724
Validation loss: 2.615511335165168

Epoch: 6| Step: 1
Training loss: 3.2750059753829373
Validation loss: 2.613308633615816

Epoch: 6| Step: 2
Training loss: 2.9956622552813403
Validation loss: 2.6126892330614573

Epoch: 6| Step: 3
Training loss: 1.8833737625013693
Validation loss: 2.609638465341315

Epoch: 6| Step: 4
Training loss: 2.652316423368066
Validation loss: 2.6110889135252244

Epoch: 6| Step: 5
Training loss: 3.2492654410454174
Validation loss: 2.618471139211277

Epoch: 6| Step: 6
Training loss: 2.6538178921898967
Validation loss: 2.6331852036596537

Epoch: 6| Step: 7
Training loss: 2.6387979179451597
Validation loss: 2.655269763807028

Epoch: 6| Step: 8
Training loss: 3.217138090490698
Validation loss: 2.665062525376911

Epoch: 6| Step: 9
Training loss: 3.2612766354556233
Validation loss: 2.678689132151331

Epoch: 6| Step: 10
Training loss: 3.523732378138513
Validation loss: 2.665715691818369

Epoch: 6| Step: 11
Training loss: 3.0131352874637214
Validation loss: 2.676544605121531

Epoch: 6| Step: 12
Training loss: 2.5096558068143047
Validation loss: 2.6303809711271127

Epoch: 6| Step: 13
Training loss: 3.3148789410472936
Validation loss: 2.608699721768192

Epoch: 65| Step: 0
Training loss: 3.217860867552736
Validation loss: 2.6044701239866135

Epoch: 6| Step: 1
Training loss: 1.6456375568981483
Validation loss: 2.6050834525228734

Epoch: 6| Step: 2
Training loss: 2.3067894612227193
Validation loss: 2.608722560252466

Epoch: 6| Step: 3
Training loss: 3.043559299894631
Validation loss: 2.610205886654229

Epoch: 6| Step: 4
Training loss: 2.939889463565492
Validation loss: 2.6141084707910744

Epoch: 6| Step: 5
Training loss: 3.372859982789232
Validation loss: 2.6159620148508607

Epoch: 6| Step: 6
Training loss: 2.927830140403416
Validation loss: 2.6238067413033566

Epoch: 6| Step: 7
Training loss: 2.6061491985632976
Validation loss: 2.627604380172951

Epoch: 6| Step: 8
Training loss: 3.1765099847133174
Validation loss: 2.643951959904963

Epoch: 6| Step: 9
Training loss: 4.005601775146237
Validation loss: 2.655364609110781

Epoch: 6| Step: 10
Training loss: 2.899913155143279
Validation loss: 2.6491683632490775

Epoch: 6| Step: 11
Training loss: 2.8354369002794453
Validation loss: 2.6362706978421437

Epoch: 6| Step: 12
Training loss: 3.0645807165518937
Validation loss: 2.6244764650709613

Epoch: 6| Step: 13
Training loss: 3.160287672782915
Validation loss: 2.6163356158010362

Epoch: 66| Step: 0
Training loss: 2.422297090234675
Validation loss: 2.6074712109772973

Epoch: 6| Step: 1
Training loss: 3.1591191611763745
Validation loss: 2.6014187375311244

Epoch: 6| Step: 2
Training loss: 2.8588614914690753
Validation loss: 2.600963320162373

Epoch: 6| Step: 3
Training loss: 3.1239196435750647
Validation loss: 2.5991661808537785

Epoch: 6| Step: 4
Training loss: 3.337725479567354
Validation loss: 2.6032706614709897

Epoch: 6| Step: 5
Training loss: 2.960156662377907
Validation loss: 2.599646389408205

Epoch: 6| Step: 6
Training loss: 2.967917074510242
Validation loss: 2.6000613419117427

Epoch: 6| Step: 7
Training loss: 3.11173224114614
Validation loss: 2.605960767082256

Epoch: 6| Step: 8
Training loss: 2.74787994506763
Validation loss: 2.6062569102970823

Epoch: 6| Step: 9
Training loss: 2.29195349083226
Validation loss: 2.6060027506805787

Epoch: 6| Step: 10
Training loss: 3.4919460819097483
Validation loss: 2.608171749158637

Epoch: 6| Step: 11
Training loss: 3.2277608128720296
Validation loss: 2.5995564598709398

Epoch: 6| Step: 12
Training loss: 2.5184213958766852
Validation loss: 2.6015904829185748

Epoch: 6| Step: 13
Training loss: 3.0268054902033104
Validation loss: 2.613996424094042

Epoch: 67| Step: 0
Training loss: 2.660781674798059
Validation loss: 2.6093132331527493

Epoch: 6| Step: 1
Training loss: 2.6309068614636075
Validation loss: 2.6033487063270133

Epoch: 6| Step: 2
Training loss: 3.4329202835601658
Validation loss: 2.600162111336836

Epoch: 6| Step: 3
Training loss: 3.064770538054641
Validation loss: 2.592417886271578

Epoch: 6| Step: 4
Training loss: 3.169155665206438
Validation loss: 2.5969192499335825

Epoch: 6| Step: 5
Training loss: 2.241601422103714
Validation loss: 2.5934152714567236

Epoch: 6| Step: 6
Training loss: 2.734146806186892
Validation loss: 2.595328758724056

Epoch: 6| Step: 7
Training loss: 3.5031933521745167
Validation loss: 2.5967441943530103

Epoch: 6| Step: 8
Training loss: 3.5234791822991807
Validation loss: 2.5953146718080147

Epoch: 6| Step: 9
Training loss: 2.755000855987471
Validation loss: 2.595975687671906

Epoch: 6| Step: 10
Training loss: 2.7019744364830167
Validation loss: 2.5955467637825738

Epoch: 6| Step: 11
Training loss: 2.8728576639343903
Validation loss: 2.593601630274583

Epoch: 6| Step: 12
Training loss: 3.371672367374606
Validation loss: 2.5936002958692876

Epoch: 6| Step: 13
Training loss: 2.119500280000021
Validation loss: 2.590593948414674

Epoch: 68| Step: 0
Training loss: 2.9794542578399397
Validation loss: 2.594071343752498

Epoch: 6| Step: 1
Training loss: 3.0971762440399653
Validation loss: 2.5951904446372684

Epoch: 6| Step: 2
Training loss: 2.711746666714285
Validation loss: 2.5997638628290467

Epoch: 6| Step: 3
Training loss: 2.881651440372987
Validation loss: 2.600450353846508

Epoch: 6| Step: 4
Training loss: 3.2790839902609306
Validation loss: 2.603512733965657

Epoch: 6| Step: 5
Training loss: 2.4119330337869367
Validation loss: 2.6061692185275587

Epoch: 6| Step: 6
Training loss: 3.7183638941251167
Validation loss: 2.602959952731807

Epoch: 6| Step: 7
Training loss: 3.017687156707407
Validation loss: 2.5990124347735897

Epoch: 6| Step: 8
Training loss: 3.098154343032631
Validation loss: 2.595018655034703

Epoch: 6| Step: 9
Training loss: 3.0214588087759666
Validation loss: 2.5911649158599808

Epoch: 6| Step: 10
Training loss: 2.7068404753867368
Validation loss: 2.587578444965961

Epoch: 6| Step: 11
Training loss: 2.6647976842526053
Validation loss: 2.5893652342773796

Epoch: 6| Step: 12
Training loss: 2.9467392761755105
Validation loss: 2.587221314768248

Epoch: 6| Step: 13
Training loss: 2.565295206820928
Validation loss: 2.588596434447213

Epoch: 69| Step: 0
Training loss: 3.2826327362300582
Validation loss: 2.5873506617558157

Epoch: 6| Step: 1
Training loss: 2.62766149109892
Validation loss: 2.5860123102579236

Epoch: 6| Step: 2
Training loss: 3.144878789994897
Validation loss: 2.591346377195697

Epoch: 6| Step: 3
Training loss: 3.6064229675807233
Validation loss: 2.592316309474028

Epoch: 6| Step: 4
Training loss: 2.6312203049966216
Validation loss: 2.588991108110311

Epoch: 6| Step: 5
Training loss: 2.930538287922958
Validation loss: 2.587993291798458

Epoch: 6| Step: 6
Training loss: 3.0119749126022795
Validation loss: 2.590223882462106

Epoch: 6| Step: 7
Training loss: 2.5553072956223946
Validation loss: 2.590310677981058

Epoch: 6| Step: 8
Training loss: 2.8662503657317897
Validation loss: 2.586361612268499

Epoch: 6| Step: 9
Training loss: 3.091151523772318
Validation loss: 2.588745329700208

Epoch: 6| Step: 10
Training loss: 2.734464894588173
Validation loss: 2.5930307089987443

Epoch: 6| Step: 11
Training loss: 2.720656855313664
Validation loss: 2.5914710310081674

Epoch: 6| Step: 12
Training loss: 2.8979588856330976
Validation loss: 2.5956187903545462

Epoch: 6| Step: 13
Training loss: 3.112865539901593
Validation loss: 2.601316026041842

Epoch: 70| Step: 0
Training loss: 2.7532632712932203
Validation loss: 2.6072366731432095

Epoch: 6| Step: 1
Training loss: 3.1778835268661356
Validation loss: 2.5991477028454315

Epoch: 6| Step: 2
Training loss: 3.1083653023092537
Validation loss: 2.6123028542979196

Epoch: 6| Step: 3
Training loss: 2.7921335959074414
Validation loss: 2.5869169126242126

Epoch: 6| Step: 4
Training loss: 2.642225784755295
Validation loss: 2.5845774222855336

Epoch: 6| Step: 5
Training loss: 2.948311571465357
Validation loss: 2.581236273608322

Epoch: 6| Step: 6
Training loss: 3.35313595559356
Validation loss: 2.58027908362196

Epoch: 6| Step: 7
Training loss: 2.8663940995032404
Validation loss: 2.579166589507295

Epoch: 6| Step: 8
Training loss: 3.3320359725292588
Validation loss: 2.5780521495640474

Epoch: 6| Step: 9
Training loss: 3.1414737598343914
Validation loss: 2.5813727592014533

Epoch: 6| Step: 10
Training loss: 3.3811386231078835
Validation loss: 2.5842567729178625

Epoch: 6| Step: 11
Training loss: 2.4481391535085186
Validation loss: 2.5799719416250118

Epoch: 6| Step: 12
Training loss: 2.3998517268791084
Validation loss: 2.5802478888910882

Epoch: 6| Step: 13
Training loss: 2.528946664491373
Validation loss: 2.581920504058589

Epoch: 71| Step: 0
Training loss: 2.979565964907204
Validation loss: 2.585525684623613

Epoch: 6| Step: 1
Training loss: 3.026658503595623
Validation loss: 2.584456441459332

Epoch: 6| Step: 2
Training loss: 3.220009418497468
Validation loss: 2.5895578076857477

Epoch: 6| Step: 3
Training loss: 2.407194868579389
Validation loss: 2.5972282393220216

Epoch: 6| Step: 4
Training loss: 3.2007096278617975
Validation loss: 2.6133224695215107

Epoch: 6| Step: 5
Training loss: 3.29178751148247
Validation loss: 2.603765383084647

Epoch: 6| Step: 6
Training loss: 3.102025533171393
Validation loss: 2.5963939915028225

Epoch: 6| Step: 7
Training loss: 2.7249873729728233
Validation loss: 2.5865555709189056

Epoch: 6| Step: 8
Training loss: 3.077826316013132
Validation loss: 2.5800184618524726

Epoch: 6| Step: 9
Training loss: 3.2741590628693844
Validation loss: 2.5769572129289173

Epoch: 6| Step: 10
Training loss: 2.6846324792729246
Validation loss: 2.5741744165457208

Epoch: 6| Step: 11
Training loss: 2.8542952311349103
Validation loss: 2.5751262896661227

Epoch: 6| Step: 12
Training loss: 2.75359993171182
Validation loss: 2.574677579713451

Epoch: 6| Step: 13
Training loss: 1.947737809671987
Validation loss: 2.5779450404408135

Epoch: 72| Step: 0
Training loss: 2.6316980555834513
Validation loss: 2.573144738621228

Epoch: 6| Step: 1
Training loss: 2.8667610537345074
Validation loss: 2.5726995344551455

Epoch: 6| Step: 2
Training loss: 3.2027678499916195
Validation loss: 2.572595013659898

Epoch: 6| Step: 3
Training loss: 3.3416339203584866
Validation loss: 2.5718233169240814

Epoch: 6| Step: 4
Training loss: 2.585209401132736
Validation loss: 2.5736692365131466

Epoch: 6| Step: 5
Training loss: 3.0606994006645
Validation loss: 2.5769803148243193

Epoch: 6| Step: 6
Training loss: 2.9862749532852217
Validation loss: 2.5740415948579924

Epoch: 6| Step: 7
Training loss: 3.280733340322736
Validation loss: 2.5735050106813437

Epoch: 6| Step: 8
Training loss: 2.552331707344801
Validation loss: 2.5784584583004566

Epoch: 6| Step: 9
Training loss: 3.193035928286911
Validation loss: 2.5838634140306533

Epoch: 6| Step: 10
Training loss: 3.008747223114647
Validation loss: 2.5977771509769676

Epoch: 6| Step: 11
Training loss: 2.7918141359313626
Validation loss: 2.6035922293477873

Epoch: 6| Step: 12
Training loss: 2.9291430158098923
Validation loss: 2.590836811524514

Epoch: 6| Step: 13
Training loss: 2.282346905925306
Validation loss: 2.58550830294697

Epoch: 73| Step: 0
Training loss: 2.9540957515438713
Validation loss: 2.5749079923901053

Epoch: 6| Step: 1
Training loss: 2.92860787398891
Validation loss: 2.577364054349241

Epoch: 6| Step: 2
Training loss: 2.9062613210149966
Validation loss: 2.570322489981648

Epoch: 6| Step: 3
Training loss: 3.1703698105611866
Validation loss: 2.569451186875138

Epoch: 6| Step: 4
Training loss: 3.0160111096124402
Validation loss: 2.5678785489367897

Epoch: 6| Step: 5
Training loss: 2.285510539442625
Validation loss: 2.5672450878388977

Epoch: 6| Step: 6
Training loss: 3.101306664511549
Validation loss: 2.568187967768788

Epoch: 6| Step: 7
Training loss: 3.253655944942034
Validation loss: 2.5686024695249023

Epoch: 6| Step: 8
Training loss: 3.1199907972738066
Validation loss: 2.5657042591848795

Epoch: 6| Step: 9
Training loss: 2.085079288027105
Validation loss: 2.56988847944576

Epoch: 6| Step: 10
Training loss: 2.64690685770979
Validation loss: 2.5715833855145336

Epoch: 6| Step: 11
Training loss: 3.374528922654109
Validation loss: 2.572902057817633

Epoch: 6| Step: 12
Training loss: 2.984658592291021
Validation loss: 2.573944452135731

Epoch: 6| Step: 13
Training loss: 3.047143073393339
Validation loss: 2.573171811113297

Epoch: 74| Step: 0
Training loss: 2.960149413539133
Validation loss: 2.575419818789251

Epoch: 6| Step: 1
Training loss: 2.640632945393002
Validation loss: 2.573017587850029

Epoch: 6| Step: 2
Training loss: 2.4802172916340823
Validation loss: 2.572337452341322

Epoch: 6| Step: 3
Training loss: 3.004570975501523
Validation loss: 2.570759079881088

Epoch: 6| Step: 4
Training loss: 3.225909520317699
Validation loss: 2.5694670578540664

Epoch: 6| Step: 5
Training loss: 3.247735922145629
Validation loss: 2.5692624048033195

Epoch: 6| Step: 6
Training loss: 2.6318242513365315
Validation loss: 2.575306274975628

Epoch: 6| Step: 7
Training loss: 2.88122746589107
Validation loss: 2.5807797940318538

Epoch: 6| Step: 8
Training loss: 3.0135642803217024
Validation loss: 2.59104443060701

Epoch: 6| Step: 9
Training loss: 2.786820138039232
Validation loss: 2.602330354752182

Epoch: 6| Step: 10
Training loss: 2.7594800019725856
Validation loss: 2.6164936848587024

Epoch: 6| Step: 11
Training loss: 3.4286721362355213
Validation loss: 2.636660375340103

Epoch: 6| Step: 12
Training loss: 2.7768705369980875
Validation loss: 2.588913678104952

Epoch: 6| Step: 13
Training loss: 3.3287421715386847
Validation loss: 2.5779996093804693

Epoch: 75| Step: 0
Training loss: 3.157369887086693
Validation loss: 2.565596585596463

Epoch: 6| Step: 1
Training loss: 3.3529212171592344
Validation loss: 2.5625301352308902

Epoch: 6| Step: 2
Training loss: 2.4620249449754557
Validation loss: 2.56635853902587

Epoch: 6| Step: 3
Training loss: 2.241973335059904
Validation loss: 2.5677097873591688

Epoch: 6| Step: 4
Training loss: 3.2877995111640175
Validation loss: 2.5682345167785217

Epoch: 6| Step: 5
Training loss: 2.81218607528079
Validation loss: 2.5692756327618

Epoch: 6| Step: 6
Training loss: 2.6622397712011656
Validation loss: 2.572523695769648

Epoch: 6| Step: 7
Training loss: 3.4151941863628203
Validation loss: 2.569819635301328

Epoch: 6| Step: 8
Training loss: 2.532584415546478
Validation loss: 2.5668628887169427

Epoch: 6| Step: 9
Training loss: 2.942158029239516
Validation loss: 2.5678840678076917

Epoch: 6| Step: 10
Training loss: 3.0203049471662546
Validation loss: 2.5627660455664873

Epoch: 6| Step: 11
Training loss: 3.2015390331028226
Validation loss: 2.564201809330638

Epoch: 6| Step: 12
Training loss: 2.5851582162572324
Validation loss: 2.568997668670156

Epoch: 6| Step: 13
Training loss: 3.4592953611612804
Validation loss: 2.562934082385421

Epoch: 76| Step: 0
Training loss: 2.791242671671642
Validation loss: 2.5632981838779583

Epoch: 6| Step: 1
Training loss: 2.599561683681621
Validation loss: 2.5615676045951994

Epoch: 6| Step: 2
Training loss: 3.0210793932091957
Validation loss: 2.5646862905000147

Epoch: 6| Step: 3
Training loss: 3.3216349043972837
Validation loss: 2.5749395733951426

Epoch: 6| Step: 4
Training loss: 2.842339134260792
Validation loss: 2.5864529233723466

Epoch: 6| Step: 5
Training loss: 2.786805080812284
Validation loss: 2.5933294487819256

Epoch: 6| Step: 6
Training loss: 2.9594954952535035
Validation loss: 2.5865166505110064

Epoch: 6| Step: 7
Training loss: 3.7341763112350055
Validation loss: 2.589625934055759

Epoch: 6| Step: 8
Training loss: 2.8072290832300135
Validation loss: 2.556777002751468

Epoch: 6| Step: 9
Training loss: 2.5439738032233774
Validation loss: 2.5547073743311235

Epoch: 6| Step: 10
Training loss: 2.880364761565446
Validation loss: 2.556395995368153

Epoch: 6| Step: 11
Training loss: 2.507998735874715
Validation loss: 2.5576379702462355

Epoch: 6| Step: 12
Training loss: 2.9292177357750484
Validation loss: 2.5626895493283963

Epoch: 6| Step: 13
Training loss: 3.2360234137255075
Validation loss: 2.5628114906673556

Epoch: 77| Step: 0
Training loss: 2.617043653492132
Validation loss: 2.563087989183104

Epoch: 6| Step: 1
Training loss: 2.8861299773811107
Validation loss: 2.56102682226646

Epoch: 6| Step: 2
Training loss: 3.4618012532307683
Validation loss: 2.5591209696936934

Epoch: 6| Step: 3
Training loss: 2.36275184944007
Validation loss: 2.5605873985829324

Epoch: 6| Step: 4
Training loss: 2.8201351374177692
Validation loss: 2.5638473054199062

Epoch: 6| Step: 5
Training loss: 3.1587355995831197
Validation loss: 2.558089817910436

Epoch: 6| Step: 6
Training loss: 2.8211428616605785
Validation loss: 2.55396914360146

Epoch: 6| Step: 7
Training loss: 2.8543495249587645
Validation loss: 2.5513140150249676

Epoch: 6| Step: 8
Training loss: 2.9337962724492823
Validation loss: 2.552620885680812

Epoch: 6| Step: 9
Training loss: 3.23353071757317
Validation loss: 2.5509713615627265

Epoch: 6| Step: 10
Training loss: 2.6111497154718815
Validation loss: 2.5513698740002315

Epoch: 6| Step: 11
Training loss: 3.2648577359153954
Validation loss: 2.5568122578976245

Epoch: 6| Step: 12
Training loss: 2.777584188921047
Validation loss: 2.5829879842172714

Epoch: 6| Step: 13
Training loss: 2.8415639670450132
Validation loss: 2.6249125857235396

Epoch: 78| Step: 0
Training loss: 3.4695712655226623
Validation loss: 2.6804857440642103

Epoch: 6| Step: 1
Training loss: 2.899333640525359
Validation loss: 2.6339663862891536

Epoch: 6| Step: 2
Training loss: 2.435847578169099
Validation loss: 2.577622487903184

Epoch: 6| Step: 3
Training loss: 2.6874149220329344
Validation loss: 2.5515191486513173

Epoch: 6| Step: 4
Training loss: 2.9382242162230923
Validation loss: 2.5485635813386764

Epoch: 6| Step: 5
Training loss: 2.8577304133769426
Validation loss: 2.547369052386249

Epoch: 6| Step: 6
Training loss: 3.380914944390949
Validation loss: 2.5498237945493893

Epoch: 6| Step: 7
Training loss: 2.6261274550478793
Validation loss: 2.5521038731813053

Epoch: 6| Step: 8
Training loss: 2.8943286160727126
Validation loss: 2.557233198534366

Epoch: 6| Step: 9
Training loss: 2.271990338405698
Validation loss: 2.559139998170036

Epoch: 6| Step: 10
Training loss: 3.4513202628859054
Validation loss: 2.554203760974152

Epoch: 6| Step: 11
Training loss: 3.10287301845047
Validation loss: 2.546471016709551

Epoch: 6| Step: 12
Training loss: 2.987528468040275
Validation loss: 2.544147608670903

Epoch: 6| Step: 13
Training loss: 2.6449731544906223
Validation loss: 2.5434239682308517

Epoch: 79| Step: 0
Training loss: 3.4142407124182066
Validation loss: 2.551984063219124

Epoch: 6| Step: 1
Training loss: 2.7685839669968493
Validation loss: 2.5484039450296576

Epoch: 6| Step: 2
Training loss: 2.7192577019558106
Validation loss: 2.549778854951793

Epoch: 6| Step: 3
Training loss: 3.2407711750195958
Validation loss: 2.549745495357132

Epoch: 6| Step: 4
Training loss: 3.340537408549331
Validation loss: 2.553647282154741

Epoch: 6| Step: 5
Training loss: 2.3042369337445043
Validation loss: 2.5510800765168247

Epoch: 6| Step: 6
Training loss: 2.7736988213155347
Validation loss: 2.555192353415872

Epoch: 6| Step: 7
Training loss: 3.060436098276404
Validation loss: 2.5675407630718436

Epoch: 6| Step: 8
Training loss: 2.76111834742798
Validation loss: 2.5687723785416425

Epoch: 6| Step: 9
Training loss: 3.185152273804852
Validation loss: 2.5767898557863975

Epoch: 6| Step: 10
Training loss: 3.2453863702116528
Validation loss: 2.56806220376157

Epoch: 6| Step: 11
Training loss: 2.2959869121085448
Validation loss: 2.5604760205147947

Epoch: 6| Step: 12
Training loss: 2.943656476067933
Validation loss: 2.5448520733840243

Epoch: 6| Step: 13
Training loss: 2.28824077347694
Validation loss: 2.541045954488763

Epoch: 80| Step: 0
Training loss: 2.6359943666412406
Validation loss: 2.5400827745523817

Epoch: 6| Step: 1
Training loss: 2.4165713412020637
Validation loss: 2.537641053234955

Epoch: 6| Step: 2
Training loss: 2.897697745052042
Validation loss: 2.541238007960826

Epoch: 6| Step: 3
Training loss: 3.031518039454022
Validation loss: 2.5430433333167635

Epoch: 6| Step: 4
Training loss: 2.6278320657267313
Validation loss: 2.5433103104148214

Epoch: 6| Step: 5
Training loss: 2.9981367364891875
Validation loss: 2.5475152632259603

Epoch: 6| Step: 6
Training loss: 3.2555767044173183
Validation loss: 2.5442569235322603

Epoch: 6| Step: 7
Training loss: 3.0298897748985305
Validation loss: 2.5415711212624257

Epoch: 6| Step: 8
Training loss: 3.004593670074777
Validation loss: 2.5406702224352844

Epoch: 6| Step: 9
Training loss: 3.2146452869140494
Validation loss: 2.5384182717090793

Epoch: 6| Step: 10
Training loss: 3.0578595250899125
Validation loss: 2.538348877030716

Epoch: 6| Step: 11
Training loss: 2.9379384139781783
Validation loss: 2.542497488675148

Epoch: 6| Step: 12
Training loss: 2.600694024550423
Validation loss: 2.565318324796373

Epoch: 6| Step: 13
Training loss: 3.0381747716842
Validation loss: 2.597870251592192

Epoch: 81| Step: 0
Training loss: 2.964480090046932
Validation loss: 2.632582554063009

Epoch: 6| Step: 1
Training loss: 2.943469859924538
Validation loss: 2.606713514349465

Epoch: 6| Step: 2
Training loss: 2.6602225722505124
Validation loss: 2.562752545925521

Epoch: 6| Step: 3
Training loss: 2.879508919438602
Validation loss: 2.549617800057995

Epoch: 6| Step: 4
Training loss: 2.890794408834352
Validation loss: 2.5472539643320746

Epoch: 6| Step: 5
Training loss: 3.161618642916521
Validation loss: 2.5428646484649

Epoch: 6| Step: 6
Training loss: 3.0942998840547014
Validation loss: 2.542555705143582

Epoch: 6| Step: 7
Training loss: 2.7640633349635717
Validation loss: 2.5382353686941985

Epoch: 6| Step: 8
Training loss: 2.6974339194419312
Validation loss: 2.5377864789691778

Epoch: 6| Step: 9
Training loss: 2.5934990451238082
Validation loss: 2.5411842839250958

Epoch: 6| Step: 10
Training loss: 2.8070529324304356
Validation loss: 2.5434686350809788

Epoch: 6| Step: 11
Training loss: 3.4602748675674095
Validation loss: 2.5366830393787927

Epoch: 6| Step: 12
Training loss: 2.73891904099456
Validation loss: 2.536397689947092

Epoch: 6| Step: 13
Training loss: 3.4244709358068066
Validation loss: 2.538952387969204

Epoch: 82| Step: 0
Training loss: 2.5941364046466573
Validation loss: 2.5373920023471843

Epoch: 6| Step: 1
Training loss: 3.210212421459607
Validation loss: 2.53875054221799

Epoch: 6| Step: 2
Training loss: 3.3265711062612517
Validation loss: 2.5451624764931573

Epoch: 6| Step: 3
Training loss: 3.007802670945791
Validation loss: 2.546131733457085

Epoch: 6| Step: 4
Training loss: 2.7424980487660062
Validation loss: 2.5526469525963202

Epoch: 6| Step: 5
Training loss: 2.115252972888289
Validation loss: 2.553939122167974

Epoch: 6| Step: 6
Training loss: 3.057882759795779
Validation loss: 2.5543746985039

Epoch: 6| Step: 7
Training loss: 2.993932946972393
Validation loss: 2.55609977014553

Epoch: 6| Step: 8
Training loss: 2.9056192349355987
Validation loss: 2.553754997779175

Epoch: 6| Step: 9
Training loss: 3.040226338393191
Validation loss: 2.5559315748871865

Epoch: 6| Step: 10
Training loss: 2.9349942172511776
Validation loss: 2.5702773322826307

Epoch: 6| Step: 11
Training loss: 2.5907791772848725
Validation loss: 2.5758487918926134

Epoch: 6| Step: 12
Training loss: 3.22137359062307
Validation loss: 2.5883899432231594

Epoch: 6| Step: 13
Training loss: 2.7301254820717795
Validation loss: 2.5925430077112965

Epoch: 83| Step: 0
Training loss: 2.866279312695933
Validation loss: 2.6000063525359716

Epoch: 6| Step: 1
Training loss: 2.532622730410569
Validation loss: 2.6105292429089673

Epoch: 6| Step: 2
Training loss: 2.8179469451187598
Validation loss: 2.613161539204415

Epoch: 6| Step: 3
Training loss: 2.666650851520689
Validation loss: 2.6012322124012135

Epoch: 6| Step: 4
Training loss: 3.6574897946406346
Validation loss: 2.5912285538272335

Epoch: 6| Step: 5
Training loss: 3.435655966236282
Validation loss: 2.5734243089352633

Epoch: 6| Step: 6
Training loss: 2.3588328970294605
Validation loss: 2.5694126379573343

Epoch: 6| Step: 7
Training loss: 2.7625233990122746
Validation loss: 2.5677564608515593

Epoch: 6| Step: 8
Training loss: 2.8991326580664403
Validation loss: 2.5579057542665127

Epoch: 6| Step: 9
Training loss: 2.95044469552764
Validation loss: 2.5663193342899153

Epoch: 6| Step: 10
Training loss: 3.102144508621119
Validation loss: 2.5621217908258975

Epoch: 6| Step: 11
Training loss: 2.655741474616605
Validation loss: 2.5640607783227356

Epoch: 6| Step: 12
Training loss: 3.027836401446713
Validation loss: 2.565996685116188

Epoch: 6| Step: 13
Training loss: 2.7730326612263823
Validation loss: 2.550854317469841

Epoch: 84| Step: 0
Training loss: 3.026401693141866
Validation loss: 2.569544051712855

Epoch: 6| Step: 1
Training loss: 2.9700406130187775
Validation loss: 2.5736361945556956

Epoch: 6| Step: 2
Training loss: 2.761968749734819
Validation loss: 2.5905916189053455

Epoch: 6| Step: 3
Training loss: 3.7213096464718327
Validation loss: 2.5862363226212137

Epoch: 6| Step: 4
Training loss: 3.14367831017601
Validation loss: 2.57930352354847

Epoch: 6| Step: 5
Training loss: 2.853960591322825
Validation loss: 2.5593822970912274

Epoch: 6| Step: 6
Training loss: 3.3157899461393727
Validation loss: 2.542531249892168

Epoch: 6| Step: 7
Training loss: 2.899905920146915
Validation loss: 2.534455107791269

Epoch: 6| Step: 8
Training loss: 2.8266281466138654
Validation loss: 2.5316854477368924

Epoch: 6| Step: 9
Training loss: 2.679562935561463
Validation loss: 2.533986590184352

Epoch: 6| Step: 10
Training loss: 2.362223238603372
Validation loss: 2.5372632710597287

Epoch: 6| Step: 11
Training loss: 2.901176700611141
Validation loss: 2.539497870011036

Epoch: 6| Step: 12
Training loss: 2.8523917886601104
Validation loss: 2.5450807264533806

Epoch: 6| Step: 13
Training loss: 1.8757927808045736
Validation loss: 2.5432839290682647

Epoch: 85| Step: 0
Training loss: 3.163091515267929
Validation loss: 2.5373176065431036

Epoch: 6| Step: 1
Training loss: 3.2841362747558134
Validation loss: 2.5398258790110138

Epoch: 6| Step: 2
Training loss: 2.8565139214516817
Validation loss: 2.543441444991634

Epoch: 6| Step: 3
Training loss: 2.3235151492126334
Validation loss: 2.549156768812545

Epoch: 6| Step: 4
Training loss: 2.836165153676821
Validation loss: 2.5726692223868852

Epoch: 6| Step: 5
Training loss: 2.7687926175043045
Validation loss: 2.578488782845474

Epoch: 6| Step: 6
Training loss: 2.9029440175649635
Validation loss: 2.6197116160858993

Epoch: 6| Step: 7
Training loss: 3.0772865044101123
Validation loss: 2.6429973017876462

Epoch: 6| Step: 8
Training loss: 3.370253722377329
Validation loss: 2.6564486164536083

Epoch: 6| Step: 9
Training loss: 3.502773139971383
Validation loss: 2.599225881854455

Epoch: 6| Step: 10
Training loss: 2.1119357918747115
Validation loss: 2.559725755085542

Epoch: 6| Step: 11
Training loss: 2.9229070299406152
Validation loss: 2.5414131686358044

Epoch: 6| Step: 12
Training loss: 2.8162540389369375
Validation loss: 2.536871669956994

Epoch: 6| Step: 13
Training loss: 2.603189412175307
Validation loss: 2.542354884608552

Epoch: 86| Step: 0
Training loss: 3.166123912543165
Validation loss: 2.551848874969627

Epoch: 6| Step: 1
Training loss: 2.999895729796027
Validation loss: 2.55789304680835

Epoch: 6| Step: 2
Training loss: 2.3743625588529165
Validation loss: 2.552739746847328

Epoch: 6| Step: 3
Training loss: 3.0774031823901242
Validation loss: 2.5423968728908335

Epoch: 6| Step: 4
Training loss: 2.685406246317989
Validation loss: 2.5401477730136373

Epoch: 6| Step: 5
Training loss: 3.2043402622721664
Validation loss: 2.5345770167539117

Epoch: 6| Step: 6
Training loss: 2.7500406609043435
Validation loss: 2.5347095012884067

Epoch: 6| Step: 7
Training loss: 2.9711575032088944
Validation loss: 2.5316125556172016

Epoch: 6| Step: 8
Training loss: 2.552660216441473
Validation loss: 2.533995261471871

Epoch: 6| Step: 9
Training loss: 3.033226234166235
Validation loss: 2.545153112985953

Epoch: 6| Step: 10
Training loss: 2.41544152040468
Validation loss: 2.5552401384424352

Epoch: 6| Step: 11
Training loss: 3.381032003824967
Validation loss: 2.575051716684293

Epoch: 6| Step: 12
Training loss: 3.1666497849131545
Validation loss: 2.594124823385311

Epoch: 6| Step: 13
Training loss: 2.883801629142108
Validation loss: 2.5747381980238093

Epoch: 87| Step: 0
Training loss: 2.855360203883373
Validation loss: 2.578538720131294

Epoch: 6| Step: 1
Training loss: 2.8440179384205044
Validation loss: 2.58059156353215

Epoch: 6| Step: 2
Training loss: 2.7727381724500106
Validation loss: 2.5737903648147267

Epoch: 6| Step: 3
Training loss: 2.862734962381909
Validation loss: 2.546029898935061

Epoch: 6| Step: 4
Training loss: 3.2035462637427963
Validation loss: 2.5414197537218475

Epoch: 6| Step: 5
Training loss: 2.604069323945658
Validation loss: 2.534437602443504

Epoch: 6| Step: 6
Training loss: 2.6385666990743037
Validation loss: 2.5322629430379147

Epoch: 6| Step: 7
Training loss: 3.0859515612318096
Validation loss: 2.537920309145006

Epoch: 6| Step: 8
Training loss: 2.7193699272457392
Validation loss: 2.532919367306818

Epoch: 6| Step: 9
Training loss: 3.1885259136686077
Validation loss: 2.530708758482881

Epoch: 6| Step: 10
Training loss: 2.833325068143869
Validation loss: 2.529682721954594

Epoch: 6| Step: 11
Training loss: 3.121100319484247
Validation loss: 2.527186785843506

Epoch: 6| Step: 12
Training loss: 3.2830753154034293
Validation loss: 2.526620070764051

Epoch: 6| Step: 13
Training loss: 2.3175778698724154
Validation loss: 2.534745143266619

Epoch: 88| Step: 0
Training loss: 2.929698242167806
Validation loss: 2.5361414026578646

Epoch: 6| Step: 1
Training loss: 3.1100775916916885
Validation loss: 2.531517413724884

Epoch: 6| Step: 2
Training loss: 3.173364299040731
Validation loss: 2.534588403822149

Epoch: 6| Step: 3
Training loss: 3.252642510918316
Validation loss: 2.5482098460779987

Epoch: 6| Step: 4
Training loss: 2.658969339883304
Validation loss: 2.5329547126221024

Epoch: 6| Step: 5
Training loss: 2.1712830100353036
Validation loss: 2.533748606340723

Epoch: 6| Step: 6
Training loss: 3.3284063802340036
Validation loss: 2.5357261320688194

Epoch: 6| Step: 7
Training loss: 2.655012493211911
Validation loss: 2.5368082287328613

Epoch: 6| Step: 8
Training loss: 2.7416362153964267
Validation loss: 2.547011066231793

Epoch: 6| Step: 9
Training loss: 3.2711906642874826
Validation loss: 2.5491780871667635

Epoch: 6| Step: 10
Training loss: 2.7405569766225
Validation loss: 2.555390783648138

Epoch: 6| Step: 11
Training loss: 2.6572708860806267
Validation loss: 2.5521707291714035

Epoch: 6| Step: 12
Training loss: 2.44610270934412
Validation loss: 2.5602875108835703

Epoch: 6| Step: 13
Training loss: 3.092889068725691
Validation loss: 2.5340265420021773

Epoch: 89| Step: 0
Training loss: 3.2227732874107575
Validation loss: 2.5253517689660505

Epoch: 6| Step: 1
Training loss: 3.5143404500023827
Validation loss: 2.5198110305705517

Epoch: 6| Step: 2
Training loss: 2.742438236956396
Validation loss: 2.516481021922035

Epoch: 6| Step: 3
Training loss: 2.469450645977749
Validation loss: 2.5130504737537174

Epoch: 6| Step: 4
Training loss: 2.4228346369320133
Validation loss: 2.514826369680354

Epoch: 6| Step: 5
Training loss: 3.2975197111962102
Validation loss: 2.5209096834123668

Epoch: 6| Step: 6
Training loss: 2.386957983835379
Validation loss: 2.5181260371235896

Epoch: 6| Step: 7
Training loss: 2.9934586098445624
Validation loss: 2.5162272979714917

Epoch: 6| Step: 8
Training loss: 2.923184188233756
Validation loss: 2.524657516052358

Epoch: 6| Step: 9
Training loss: 2.8944671664949806
Validation loss: 2.522271569695509

Epoch: 6| Step: 10
Training loss: 3.2273837838498283
Validation loss: 2.522254857966496

Epoch: 6| Step: 11
Training loss: 2.6636114102152564
Validation loss: 2.517797325132626

Epoch: 6| Step: 12
Training loss: 2.601696847190344
Validation loss: 2.5261741759889556

Epoch: 6| Step: 13
Training loss: 2.6505889705915795
Validation loss: 2.535309813632732

Epoch: 90| Step: 0
Training loss: 2.925422351047253
Validation loss: 2.5454049054049817

Epoch: 6| Step: 1
Training loss: 3.3733604121974654
Validation loss: 2.555857420827877

Epoch: 6| Step: 2
Training loss: 3.3764249831003066
Validation loss: 2.553219488876649

Epoch: 6| Step: 3
Training loss: 3.3535130655748824
Validation loss: 2.555381151634011

Epoch: 6| Step: 4
Training loss: 2.8411192410509836
Validation loss: 2.542057502212582

Epoch: 6| Step: 5
Training loss: 2.9764689433295737
Validation loss: 2.5169696917039075

Epoch: 6| Step: 6
Training loss: 2.820215112584499
Validation loss: 2.5147139934624856

Epoch: 6| Step: 7
Training loss: 2.872207114325248
Validation loss: 2.5086520237608374

Epoch: 6| Step: 8
Training loss: 3.346169140322918
Validation loss: 2.5166695123808656

Epoch: 6| Step: 9
Training loss: 2.5329511600971024
Validation loss: 2.5189993745040766

Epoch: 6| Step: 10
Training loss: 2.0037165918260214
Validation loss: 2.522006627169222

Epoch: 6| Step: 11
Training loss: 2.392161156268238
Validation loss: 2.525810853447486

Epoch: 6| Step: 12
Training loss: 2.633097556781798
Validation loss: 2.5248596741289346

Epoch: 6| Step: 13
Training loss: 2.8867433621773007
Validation loss: 2.5253601003851616

Epoch: 91| Step: 0
Training loss: 2.592634765594837
Validation loss: 2.523989391382551

Epoch: 6| Step: 1
Training loss: 3.086484604636907
Validation loss: 2.5183616259166683

Epoch: 6| Step: 2
Training loss: 2.5958939848825704
Validation loss: 2.51445606802491

Epoch: 6| Step: 3
Training loss: 2.592745115193709
Validation loss: 2.5105358598084404

Epoch: 6| Step: 4
Training loss: 3.3218268318308506
Validation loss: 2.5090797689637276

Epoch: 6| Step: 5
Training loss: 3.1040573271540572
Validation loss: 2.50660964128045

Epoch: 6| Step: 6
Training loss: 2.361210595322634
Validation loss: 2.508888190523533

Epoch: 6| Step: 7
Training loss: 3.2637414200026056
Validation loss: 2.5109809622860624

Epoch: 6| Step: 8
Training loss: 2.2491355930974226
Validation loss: 2.5133805776788307

Epoch: 6| Step: 9
Training loss: 3.331601042439122
Validation loss: 2.5331109945004897

Epoch: 6| Step: 10
Training loss: 2.8359284203754447
Validation loss: 2.546906395124847

Epoch: 6| Step: 11
Training loss: 3.098111247912728
Validation loss: 2.5237984225992496

Epoch: 6| Step: 12
Training loss: 3.0613994567200726
Validation loss: 2.51372660110025

Epoch: 6| Step: 13
Training loss: 2.4770994356453895
Validation loss: 2.510673530912951

Epoch: 92| Step: 0
Training loss: 2.4362054957576578
Validation loss: 2.514510562954792

Epoch: 6| Step: 1
Training loss: 3.3088939399956803
Validation loss: 2.5170769816670027

Epoch: 6| Step: 2
Training loss: 3.099228756856954
Validation loss: 2.514809969349291

Epoch: 6| Step: 3
Training loss: 2.761798172257906
Validation loss: 2.5179721280179916

Epoch: 6| Step: 4
Training loss: 3.1617622208487663
Validation loss: 2.517488279109155

Epoch: 6| Step: 5
Training loss: 2.6357562985913483
Validation loss: 2.5197467680935923

Epoch: 6| Step: 6
Training loss: 2.785732814182243
Validation loss: 2.5220397768113503

Epoch: 6| Step: 7
Training loss: 2.557824498208439
Validation loss: 2.5324269177633436

Epoch: 6| Step: 8
Training loss: 3.253757065814066
Validation loss: 2.5427754097124065

Epoch: 6| Step: 9
Training loss: 2.9752259945982433
Validation loss: 2.5342782563424406

Epoch: 6| Step: 10
Training loss: 2.5950224179749353
Validation loss: 2.5452845685989702

Epoch: 6| Step: 11
Training loss: 3.0068413293634673
Validation loss: 2.542575973764852

Epoch: 6| Step: 12
Training loss: 2.9012559210089437
Validation loss: 2.526990490595795

Epoch: 6| Step: 13
Training loss: 2.376291225182099
Validation loss: 2.52052036770853

Epoch: 93| Step: 0
Training loss: 2.7191470502994766
Validation loss: 2.5155752965997364

Epoch: 6| Step: 1
Training loss: 3.087405394058374
Validation loss: 2.5192545400616853

Epoch: 6| Step: 2
Training loss: 2.2818884805214785
Validation loss: 2.517371675277984

Epoch: 6| Step: 3
Training loss: 3.219067604172732
Validation loss: 2.529160869395979

Epoch: 6| Step: 4
Training loss: 2.8062016642258545
Validation loss: 2.511984806689294

Epoch: 6| Step: 5
Training loss: 3.08984621918359
Validation loss: 2.5049407425844814

Epoch: 6| Step: 6
Training loss: 3.0196638978787598
Validation loss: 2.5053532618836414

Epoch: 6| Step: 7
Training loss: 2.553511509301888
Validation loss: 2.4978964456753783

Epoch: 6| Step: 8
Training loss: 2.415660736490793
Validation loss: 2.5043367917311876

Epoch: 6| Step: 9
Training loss: 3.1865027868622917
Validation loss: 2.5029575266220148

Epoch: 6| Step: 10
Training loss: 3.397149765005792
Validation loss: 2.5041839689784133

Epoch: 6| Step: 11
Training loss: 2.46636935023103
Validation loss: 2.51311295803953

Epoch: 6| Step: 12
Training loss: 2.883104263055776
Validation loss: 2.5081768679084075

Epoch: 6| Step: 13
Training loss: 2.7531292191125623
Validation loss: 2.515161568281104

Epoch: 94| Step: 0
Training loss: 3.139841162193354
Validation loss: 2.5102368014936394

Epoch: 6| Step: 1
Training loss: 2.856010083028481
Validation loss: 2.514741795916802

Epoch: 6| Step: 2
Training loss: 3.0169810670455215
Validation loss: 2.519369040938089

Epoch: 6| Step: 3
Training loss: 2.7838760151494912
Validation loss: 2.534046862657264

Epoch: 6| Step: 4
Training loss: 2.6640773560230024
Validation loss: 2.5303002300802167

Epoch: 6| Step: 5
Training loss: 2.7691569216573293
Validation loss: 2.5484687473554857

Epoch: 6| Step: 6
Training loss: 3.296812807192569
Validation loss: 2.5504557516154547

Epoch: 6| Step: 7
Training loss: 2.475574284211971
Validation loss: 2.5375903192054587

Epoch: 6| Step: 8
Training loss: 2.617624183776708
Validation loss: 2.5292797728341325

Epoch: 6| Step: 9
Training loss: 2.8096410843862762
Validation loss: 2.519300754792952

Epoch: 6| Step: 10
Training loss: 3.028512249288716
Validation loss: 2.5161089158154573

Epoch: 6| Step: 11
Training loss: 2.785040683141
Validation loss: 2.518637412015552

Epoch: 6| Step: 12
Training loss: 2.9964155399838717
Validation loss: 2.510702776996327

Epoch: 6| Step: 13
Training loss: 2.647404562118783
Validation loss: 2.508003848842758

Epoch: 95| Step: 0
Training loss: 2.6993287170356863
Validation loss: 2.508206193186233

Epoch: 6| Step: 1
Training loss: 2.9083078953487624
Validation loss: 2.512844089722006

Epoch: 6| Step: 2
Training loss: 3.13929378707495
Validation loss: 2.505893867178625

Epoch: 6| Step: 3
Training loss: 2.9379616232612467
Validation loss: 2.51253615677637

Epoch: 6| Step: 4
Training loss: 3.2587893551468254
Validation loss: 2.509545754994491

Epoch: 6| Step: 5
Training loss: 2.854545141218971
Validation loss: 2.506576719692273

Epoch: 6| Step: 6
Training loss: 2.9628119260209833
Validation loss: 2.5028540901233853

Epoch: 6| Step: 7
Training loss: 2.9074730709334395
Validation loss: 2.504099190367495

Epoch: 6| Step: 8
Training loss: 2.7225357532518055
Validation loss: 2.497874222673417

Epoch: 6| Step: 9
Training loss: 2.7613716824660868
Validation loss: 2.5051939508097187

Epoch: 6| Step: 10
Training loss: 2.7164756645349764
Validation loss: 2.5097447737248215

Epoch: 6| Step: 11
Training loss: 3.3303601992887852
Validation loss: 2.514137402481635

Epoch: 6| Step: 12
Training loss: 2.4622691593313646
Validation loss: 2.5261268559916727

Epoch: 6| Step: 13
Training loss: 1.799668371592717
Validation loss: 2.523620761363294

Epoch: 96| Step: 0
Training loss: 3.02231200410525
Validation loss: 2.5396841969505397

Epoch: 6| Step: 1
Training loss: 2.6248917330258448
Validation loss: 2.5520838801316628

Epoch: 6| Step: 2
Training loss: 2.2221352984064286
Validation loss: 2.54806671858503

Epoch: 6| Step: 3
Training loss: 2.8184866873152843
Validation loss: 2.537497847894758

Epoch: 6| Step: 4
Training loss: 2.650166625056614
Validation loss: 2.525201310399753

Epoch: 6| Step: 5
Training loss: 2.9463850340165587
Validation loss: 2.5216417042799684

Epoch: 6| Step: 6
Training loss: 3.185279371863455
Validation loss: 2.50557842432771

Epoch: 6| Step: 7
Training loss: 3.117562560652164
Validation loss: 2.505551167869208

Epoch: 6| Step: 8
Training loss: 2.8694479033145774
Validation loss: 2.505794827364252

Epoch: 6| Step: 9
Training loss: 2.583817549414453
Validation loss: 2.501809804345737

Epoch: 6| Step: 10
Training loss: 3.1582041818856457
Validation loss: 2.5015649481196447

Epoch: 6| Step: 11
Training loss: 2.0835640080220483
Validation loss: 2.5082225999015195

Epoch: 6| Step: 12
Training loss: 3.5626825653947307
Validation loss: 2.5127314361029818

Epoch: 6| Step: 13
Training loss: 2.891496351724929
Validation loss: 2.5160073476576135

Epoch: 97| Step: 0
Training loss: 2.4263750169669622
Validation loss: 2.5229940636591297

Epoch: 6| Step: 1
Training loss: 3.1505613523175193
Validation loss: 2.5166165331458425

Epoch: 6| Step: 2
Training loss: 2.3244725193000146
Validation loss: 2.5237757714720614

Epoch: 6| Step: 3
Training loss: 2.354061788287676
Validation loss: 2.5254247250525417

Epoch: 6| Step: 4
Training loss: 2.458013050314741
Validation loss: 2.5204570133088433

Epoch: 6| Step: 5
Training loss: 2.9103256688311063
Validation loss: 2.515909711689931

Epoch: 6| Step: 6
Training loss: 2.9613655203705025
Validation loss: 2.511405972172834

Epoch: 6| Step: 7
Training loss: 3.1389997082017738
Validation loss: 2.5150708389621492

Epoch: 6| Step: 8
Training loss: 2.955943543758358
Validation loss: 2.5209626181866005

Epoch: 6| Step: 9
Training loss: 2.2703803307625523
Validation loss: 2.515238598279829

Epoch: 6| Step: 10
Training loss: 3.4352070877307677
Validation loss: 2.5114823328998623

Epoch: 6| Step: 11
Training loss: 3.257555176157114
Validation loss: 2.5245515545961026

Epoch: 6| Step: 12
Training loss: 3.3356636167209692
Validation loss: 2.5263790397962667

Epoch: 6| Step: 13
Training loss: 2.624229227166073
Validation loss: 2.5250035180638255

Epoch: 98| Step: 0
Training loss: 2.906086250532187
Validation loss: 2.545658566199754

Epoch: 6| Step: 1
Training loss: 2.8688117060123033
Validation loss: 2.5577329849587676

Epoch: 6| Step: 2
Training loss: 2.611926082377188
Validation loss: 2.564752449661411

Epoch: 6| Step: 3
Training loss: 3.5859828439143633
Validation loss: 2.5959414749665046

Epoch: 6| Step: 4
Training loss: 2.571002716798953
Validation loss: 2.566473254840611

Epoch: 6| Step: 5
Training loss: 2.5920042114576813
Validation loss: 2.5562765049131304

Epoch: 6| Step: 6
Training loss: 2.9894340734847984
Validation loss: 2.5444666507027365

Epoch: 6| Step: 7
Training loss: 2.741282691464918
Validation loss: 2.5077460265528493

Epoch: 6| Step: 8
Training loss: 3.1838317407689485
Validation loss: 2.4976249015856933

Epoch: 6| Step: 9
Training loss: 2.691442038155564
Validation loss: 2.4938884563336003

Epoch: 6| Step: 10
Training loss: 3.216576444187402
Validation loss: 2.486308529992354

Epoch: 6| Step: 11
Training loss: 2.5675627774862697
Validation loss: 2.4927124834511853

Epoch: 6| Step: 12
Training loss: 2.5361759621317237
Validation loss: 2.4896289623718237

Epoch: 6| Step: 13
Training loss: 2.7724151876288685
Validation loss: 2.4940935000137743

Epoch: 99| Step: 0
Training loss: 2.671602737207634
Validation loss: 2.4927504866012766

Epoch: 6| Step: 1
Training loss: 3.1134797419472036
Validation loss: 2.499397538513345

Epoch: 6| Step: 2
Training loss: 2.4802050833351688
Validation loss: 2.517727375328046

Epoch: 6| Step: 3
Training loss: 2.257115028651282
Validation loss: 2.535798072895596

Epoch: 6| Step: 4
Training loss: 2.895380346056047
Validation loss: 2.569535564243302

Epoch: 6| Step: 5
Training loss: 2.5032630606116006
Validation loss: 2.566031441938193

Epoch: 6| Step: 6
Training loss: 2.8110642901287948
Validation loss: 2.5496502744838905

Epoch: 6| Step: 7
Training loss: 3.1647797701660605
Validation loss: 2.51976149316953

Epoch: 6| Step: 8
Training loss: 3.1201671614249094
Validation loss: 2.5059085202004256

Epoch: 6| Step: 9
Training loss: 2.5656593199651954
Validation loss: 2.4953647496250175

Epoch: 6| Step: 10
Training loss: 3.0768922767564795
Validation loss: 2.4896365658717157

Epoch: 6| Step: 11
Training loss: 2.8483634667079554
Validation loss: 2.486484315528524

Epoch: 6| Step: 12
Training loss: 3.316026358082082
Validation loss: 2.4918105037370712

Epoch: 6| Step: 13
Training loss: 3.00537502062345
Validation loss: 2.484743175234325

Epoch: 100| Step: 0
Training loss: 2.3759113370234344
Validation loss: 2.4922665726738686

Epoch: 6| Step: 1
Training loss: 3.116724883435084
Validation loss: 2.49899265339415

Epoch: 6| Step: 2
Training loss: 3.140730215559157
Validation loss: 2.5248400989343556

Epoch: 6| Step: 3
Training loss: 2.931579304561469
Validation loss: 2.525197784530308

Epoch: 6| Step: 4
Training loss: 2.842554365055898
Validation loss: 2.5273283722302478

Epoch: 6| Step: 5
Training loss: 2.9943836409655704
Validation loss: 2.536278640080045

Epoch: 6| Step: 6
Training loss: 3.0353337730621326
Validation loss: 2.5248611951372326

Epoch: 6| Step: 7
Training loss: 2.583101405735836
Validation loss: 2.53338740832976

Epoch: 6| Step: 8
Training loss: 2.9847905533758934
Validation loss: 2.5207727737359455

Epoch: 6| Step: 9
Training loss: 2.7351991991660594
Validation loss: 2.519368129192971

Epoch: 6| Step: 10
Training loss: 2.7780795081826186
Validation loss: 2.4999204869084957

Epoch: 6| Step: 11
Training loss: 2.2918492562351616
Validation loss: 2.4951138800943533

Epoch: 6| Step: 12
Training loss: 2.7686926428922485
Validation loss: 2.4974514553431177

Epoch: 6| Step: 13
Training loss: 3.319458759725677
Validation loss: 2.496711550383795

Epoch: 101| Step: 0
Training loss: 2.688170061192756
Validation loss: 2.494433483637442

Epoch: 6| Step: 1
Training loss: 3.0325270646688742
Validation loss: 2.495542730503624

Epoch: 6| Step: 2
Training loss: 2.2546597019736927
Validation loss: 2.4974478995352705

Epoch: 6| Step: 3
Training loss: 1.9774917408497017
Validation loss: 2.505704253051784

Epoch: 6| Step: 4
Training loss: 3.4543073882430764
Validation loss: 2.4958366479755263

Epoch: 6| Step: 5
Training loss: 3.1853379041283145
Validation loss: 2.4922546795304643

Epoch: 6| Step: 6
Training loss: 2.7160999931839096
Validation loss: 2.4971918634444434

Epoch: 6| Step: 7
Training loss: 3.1596987172651
Validation loss: 2.4995810598652546

Epoch: 6| Step: 8
Training loss: 3.038593010811346
Validation loss: 2.506185514021282

Epoch: 6| Step: 9
Training loss: 2.9109111856365635
Validation loss: 2.502098347293001

Epoch: 6| Step: 10
Training loss: 2.5376839519402927
Validation loss: 2.50471212675527

Epoch: 6| Step: 11
Training loss: 2.8015912745413423
Validation loss: 2.5093141351665293

Epoch: 6| Step: 12
Training loss: 3.0652070828998763
Validation loss: 2.5221031382101313

Epoch: 6| Step: 13
Training loss: 2.068461962236964
Validation loss: 2.5480201331589343

Epoch: 102| Step: 0
Training loss: 3.2762014150964944
Validation loss: 2.572749606032874

Epoch: 6| Step: 1
Training loss: 2.4783227483253554
Validation loss: 2.598575852339684

Epoch: 6| Step: 2
Training loss: 2.6308382595605395
Validation loss: 2.5946861699693367

Epoch: 6| Step: 3
Training loss: 3.181342666565388
Validation loss: 2.5366045993539204

Epoch: 6| Step: 4
Training loss: 2.741161013027294
Validation loss: 2.4989794175893043

Epoch: 6| Step: 5
Training loss: 3.1176295528703637
Validation loss: 2.4910444400968355

Epoch: 6| Step: 6
Training loss: 2.565163879215885
Validation loss: 2.490142208792946

Epoch: 6| Step: 7
Training loss: 2.4952609922172484
Validation loss: 2.4861195494369053

Epoch: 6| Step: 8
Training loss: 3.3214039164388383
Validation loss: 2.489937317977582

Epoch: 6| Step: 9
Training loss: 2.73282784424406
Validation loss: 2.491112676480538

Epoch: 6| Step: 10
Training loss: 2.75138204698794
Validation loss: 2.500936933527189

Epoch: 6| Step: 11
Training loss: 2.5853711571224287
Validation loss: 2.496146110049558

Epoch: 6| Step: 12
Training loss: 2.9922732348397725
Validation loss: 2.4846196517549872

Epoch: 6| Step: 13
Training loss: 2.8960979715815096
Validation loss: 2.5142206037258727

Epoch: 103| Step: 0
Training loss: 2.494233538182254
Validation loss: 2.52926000683121

Epoch: 6| Step: 1
Training loss: 2.6319279755474385
Validation loss: 2.563806401391096

Epoch: 6| Step: 2
Training loss: 3.0365136448493764
Validation loss: 2.573706749493195

Epoch: 6| Step: 3
Training loss: 2.3390325244927155
Validation loss: 2.5557022470238717

Epoch: 6| Step: 4
Training loss: 2.7399959664419518
Validation loss: 2.561695130544387

Epoch: 6| Step: 5
Training loss: 3.144755669398633
Validation loss: 2.495953016075172

Epoch: 6| Step: 6
Training loss: 3.301939920064836
Validation loss: 2.4837261200533116

Epoch: 6| Step: 7
Training loss: 2.772795095054836
Validation loss: 2.4864864167673595

Epoch: 6| Step: 8
Training loss: 3.259616416409898
Validation loss: 2.4969932153510315

Epoch: 6| Step: 9
Training loss: 2.6961645576333764
Validation loss: 2.4968111866564016

Epoch: 6| Step: 10
Training loss: 3.2240184147689868
Validation loss: 2.507455527391409

Epoch: 6| Step: 11
Training loss: 2.878284899715145
Validation loss: 2.5000210556046

Epoch: 6| Step: 12
Training loss: 3.0636709660484116
Validation loss: 2.503366615390187

Epoch: 6| Step: 13
Training loss: 1.9322011537422674
Validation loss: 2.511944887020998

Epoch: 104| Step: 0
Training loss: 2.762819580648958
Validation loss: 2.5231086844110115

Epoch: 6| Step: 1
Training loss: 2.5267468179388515
Validation loss: 2.5353781640629536

Epoch: 6| Step: 2
Training loss: 2.829029254825443
Validation loss: 2.562811257591963

Epoch: 6| Step: 3
Training loss: 2.737264185812343
Validation loss: 2.5806233471799582

Epoch: 6| Step: 4
Training loss: 2.997943968358073
Validation loss: 2.5876197989921845

Epoch: 6| Step: 5
Training loss: 2.9600592042827265
Validation loss: 2.5823265903250765

Epoch: 6| Step: 6
Training loss: 2.7940984828634257
Validation loss: 2.5777569311373045

Epoch: 6| Step: 7
Training loss: 3.2838757862384744
Validation loss: 2.550353419274639

Epoch: 6| Step: 8
Training loss: 3.440112976170748
Validation loss: 2.5192669397155396

Epoch: 6| Step: 9
Training loss: 2.867887240056639
Validation loss: 2.5021163217208158

Epoch: 6| Step: 10
Training loss: 2.6218824493338753
Validation loss: 2.497685544469719

Epoch: 6| Step: 11
Training loss: 2.6045049117084664
Validation loss: 2.4982643378187266

Epoch: 6| Step: 12
Training loss: 2.373876607128943
Validation loss: 2.4925074717012796

Epoch: 6| Step: 13
Training loss: 3.057137601870819
Validation loss: 2.496137159384328

Epoch: 105| Step: 0
Training loss: 2.9407522176046523
Validation loss: 2.4960635593582348

Epoch: 6| Step: 1
Training loss: 2.852701706838316
Validation loss: 2.492773614019557

Epoch: 6| Step: 2
Training loss: 3.356813953833947
Validation loss: 2.499269129453412

Epoch: 6| Step: 3
Training loss: 3.036889090936146
Validation loss: 2.5200586154818425

Epoch: 6| Step: 4
Training loss: 2.7057643639652813
Validation loss: 2.559661265293431

Epoch: 6| Step: 5
Training loss: 3.13812064913
Validation loss: 2.5451768017061247

Epoch: 6| Step: 6
Training loss: 2.991198025039466
Validation loss: 2.5415307544403154

Epoch: 6| Step: 7
Training loss: 2.3549561203677283
Validation loss: 2.5022453120905555

Epoch: 6| Step: 8
Training loss: 3.0101089232244225
Validation loss: 2.4944103911362996

Epoch: 6| Step: 9
Training loss: 2.683767521325293
Validation loss: 2.491462374949514

Epoch: 6| Step: 10
Training loss: 2.979286689385778
Validation loss: 2.494324420075502

Epoch: 6| Step: 11
Training loss: 2.3401125337977664
Validation loss: 2.4856343858259327

Epoch: 6| Step: 12
Training loss: 2.4738313555338727
Validation loss: 2.4923719420877757

Epoch: 6| Step: 13
Training loss: 2.4557892733702125
Validation loss: 2.4935545454567545

Epoch: 106| Step: 0
Training loss: 3.086891046309719
Validation loss: 2.5039008655329904

Epoch: 6| Step: 1
Training loss: 2.51823886578864
Validation loss: 2.5148614519414325

Epoch: 6| Step: 2
Training loss: 2.879911125719163
Validation loss: 2.5271531361385664

Epoch: 6| Step: 3
Training loss: 2.826196002132241
Validation loss: 2.525766143302489

Epoch: 6| Step: 4
Training loss: 2.590444089603144
Validation loss: 2.528918495118038

Epoch: 6| Step: 5
Training loss: 2.3748972017226344
Validation loss: 2.555271822067049

Epoch: 6| Step: 6
Training loss: 2.6929934932943187
Validation loss: 2.5703692666365643

Epoch: 6| Step: 7
Training loss: 3.1139376342055534
Validation loss: 2.6106155911580977

Epoch: 6| Step: 8
Training loss: 3.043225729280605
Validation loss: 2.6562789896107555

Epoch: 6| Step: 9
Training loss: 3.364657059718955
Validation loss: 2.6859500266341887

Epoch: 6| Step: 10
Training loss: 2.955352104884082
Validation loss: 2.5903664580831807

Epoch: 6| Step: 11
Training loss: 2.1128019399256326
Validation loss: 2.53098332681473

Epoch: 6| Step: 12
Training loss: 3.271280602329125
Validation loss: 2.5059912662719737

Epoch: 6| Step: 13
Training loss: 2.109696427333309
Validation loss: 2.5007415143507186

Epoch: 107| Step: 0
Training loss: 2.4168893996451692
Validation loss: 2.498116944862247

Epoch: 6| Step: 1
Training loss: 2.232137239721587
Validation loss: 2.5125926564371057

Epoch: 6| Step: 2
Training loss: 3.300290765379221
Validation loss: 2.5158466008900846

Epoch: 6| Step: 3
Training loss: 3.075955163497459
Validation loss: 2.4985531188603503

Epoch: 6| Step: 4
Training loss: 2.526607824896867
Validation loss: 2.4841714513648485

Epoch: 6| Step: 5
Training loss: 2.4570367810015745
Validation loss: 2.4840524352740307

Epoch: 6| Step: 6
Training loss: 3.2592051797371533
Validation loss: 2.4919259724307885

Epoch: 6| Step: 7
Training loss: 3.138487130919492
Validation loss: 2.5027662928568652

Epoch: 6| Step: 8
Training loss: 3.4164518118192317
Validation loss: 2.5308264577155115

Epoch: 6| Step: 9
Training loss: 2.8245672957955494
Validation loss: 2.6152027061459115

Epoch: 6| Step: 10
Training loss: 2.93711006336024
Validation loss: 2.734982130208208

Epoch: 6| Step: 11
Training loss: 2.809437164874866
Validation loss: 2.733022267901677

Epoch: 6| Step: 12
Training loss: 2.948734632761694
Validation loss: 2.6348236894180928

Epoch: 6| Step: 13
Training loss: 2.491955402532407
Validation loss: 2.5397986277172278

Epoch: 108| Step: 0
Training loss: 2.144116748990311
Validation loss: 2.488822747374149

Epoch: 6| Step: 1
Training loss: 3.282435321156114
Validation loss: 2.4918122661162125

Epoch: 6| Step: 2
Training loss: 2.431737887111053
Validation loss: 2.5007539637679037

Epoch: 6| Step: 3
Training loss: 3.0217231404630476
Validation loss: 2.500566309704246

Epoch: 6| Step: 4
Training loss: 2.8965317869518135
Validation loss: 2.5393672657347692

Epoch: 6| Step: 5
Training loss: 3.010083101969399
Validation loss: 2.5661383230347536

Epoch: 6| Step: 6
Training loss: 3.168215891350225
Validation loss: 2.5655626362735813

Epoch: 6| Step: 7
Training loss: 2.9251556746308727
Validation loss: 2.539617862214484

Epoch: 6| Step: 8
Training loss: 2.7720906170542396
Validation loss: 2.488949848574584

Epoch: 6| Step: 9
Training loss: 3.07320572522658
Validation loss: 2.494478241514842

Epoch: 6| Step: 10
Training loss: 2.782640259695883
Validation loss: 2.498521522474306

Epoch: 6| Step: 11
Training loss: 2.8591848841766594
Validation loss: 2.5098849273680917

Epoch: 6| Step: 12
Training loss: 2.9884867678510965
Validation loss: 2.5107181912463084

Epoch: 6| Step: 13
Training loss: 2.901277287135889
Validation loss: 2.5439807777183563

Epoch: 109| Step: 0
Training loss: 2.883445608198541
Validation loss: 2.555747766572371

Epoch: 6| Step: 1
Training loss: 2.8327460708866976
Validation loss: 2.5925574686386494

Epoch: 6| Step: 2
Training loss: 2.7327464458319275
Validation loss: 2.625262937253815

Epoch: 6| Step: 3
Training loss: 2.805045697389067
Validation loss: 2.6030403907678457

Epoch: 6| Step: 4
Training loss: 3.145472491118435
Validation loss: 2.584049923006604

Epoch: 6| Step: 5
Training loss: 2.7719412192570676
Validation loss: 2.5370350335583667

Epoch: 6| Step: 6
Training loss: 2.7197878380384104
Validation loss: 2.5080131936286674

Epoch: 6| Step: 7
Training loss: 3.0125544436271805
Validation loss: 2.488101440100204

Epoch: 6| Step: 8
Training loss: 2.6286332554091434
Validation loss: 2.476061313409064

Epoch: 6| Step: 9
Training loss: 2.373337314241621
Validation loss: 2.4769286445352776

Epoch: 6| Step: 10
Training loss: 2.8910014139420683
Validation loss: 2.4771189751695624

Epoch: 6| Step: 11
Training loss: 2.8497537807717617
Validation loss: 2.479675054364829

Epoch: 6| Step: 12
Training loss: 3.27655900146414
Validation loss: 2.4797799012148873

Epoch: 6| Step: 13
Training loss: 2.596531307461445
Validation loss: 2.479085080369322

Epoch: 110| Step: 0
Training loss: 2.55078087612459
Validation loss: 2.479646699516502

Epoch: 6| Step: 1
Training loss: 2.8451011717494747
Validation loss: 2.4781940200190737

Epoch: 6| Step: 2
Training loss: 2.894849999055013
Validation loss: 2.4945691484068115

Epoch: 6| Step: 3
Training loss: 3.3402973067853234
Validation loss: 2.5200990505613508

Epoch: 6| Step: 4
Training loss: 2.726126649664275
Validation loss: 2.5189295140562478

Epoch: 6| Step: 5
Training loss: 2.6566881603805794
Validation loss: 2.503859969211747

Epoch: 6| Step: 6
Training loss: 2.8477677688426053
Validation loss: 2.494749963688289

Epoch: 6| Step: 7
Training loss: 3.0129221133734743
Validation loss: 2.488373347596566

Epoch: 6| Step: 8
Training loss: 3.111837820676454
Validation loss: 2.485733601842975

Epoch: 6| Step: 9
Training loss: 2.9355212100716073
Validation loss: 2.491521428909609

Epoch: 6| Step: 10
Training loss: 2.4270621586695915
Validation loss: 2.486723742226603

Epoch: 6| Step: 11
Training loss: 2.336552669702932
Validation loss: 2.4861165053870766

Epoch: 6| Step: 12
Training loss: 3.3875836914534765
Validation loss: 2.4933113811778593

Epoch: 6| Step: 13
Training loss: 1.7584695223937616
Validation loss: 2.4908635709326816

Epoch: 111| Step: 0
Training loss: 2.4047767786180216
Validation loss: 2.4947040951903583

Epoch: 6| Step: 1
Training loss: 2.806196821426811
Validation loss: 2.498468912589211

Epoch: 6| Step: 2
Training loss: 2.893667733195067
Validation loss: 2.5045776818443226

Epoch: 6| Step: 3
Training loss: 2.725873537652458
Validation loss: 2.5258474552930372

Epoch: 6| Step: 4
Training loss: 3.1558828612467753
Validation loss: 2.542002552001209

Epoch: 6| Step: 5
Training loss: 2.5903408212180032
Validation loss: 2.5309195232497808

Epoch: 6| Step: 6
Training loss: 3.045756442816786
Validation loss: 2.518806561760887

Epoch: 6| Step: 7
Training loss: 2.7059133624229297
Validation loss: 2.5049074183398927

Epoch: 6| Step: 8
Training loss: 3.2668932044699015
Validation loss: 2.4899928354752525

Epoch: 6| Step: 9
Training loss: 2.608912261318088
Validation loss: 2.480240547290125

Epoch: 6| Step: 10
Training loss: 3.0245718787025835
Validation loss: 2.479718313855314

Epoch: 6| Step: 11
Training loss: 2.5823016003510864
Validation loss: 2.475428145893622

Epoch: 6| Step: 12
Training loss: 3.2060212230301177
Validation loss: 2.472586804414464

Epoch: 6| Step: 13
Training loss: 2.1358790447549323
Validation loss: 2.47468952213271

Epoch: 112| Step: 0
Training loss: 2.860072149953895
Validation loss: 2.469246466133414

Epoch: 6| Step: 1
Training loss: 3.606727586985015
Validation loss: 2.4732220105874085

Epoch: 6| Step: 2
Training loss: 2.952113063952395
Validation loss: 2.4729389598711116

Epoch: 6| Step: 3
Training loss: 2.5428758361061954
Validation loss: 2.476368422502622

Epoch: 6| Step: 4
Training loss: 2.790762588851216
Validation loss: 2.4825666598436533

Epoch: 6| Step: 5
Training loss: 2.8301365900944266
Validation loss: 2.488292810809191

Epoch: 6| Step: 6
Training loss: 2.603993056550269
Validation loss: 2.4995707266405374

Epoch: 6| Step: 7
Training loss: 2.7470410640717646
Validation loss: 2.513754254359539

Epoch: 6| Step: 8
Training loss: 2.3957616933533084
Validation loss: 2.5045039920684293

Epoch: 6| Step: 9
Training loss: 2.4819111632587396
Validation loss: 2.499265975251315

Epoch: 6| Step: 10
Training loss: 2.609850720196035
Validation loss: 2.497956836682635

Epoch: 6| Step: 11
Training loss: 2.8515551423278365
Validation loss: 2.4867787758080877

Epoch: 6| Step: 12
Training loss: 2.8689644527686293
Validation loss: 2.5065337161177292

Epoch: 6| Step: 13
Training loss: 2.9838165239989474
Validation loss: 2.4822051363352586

Epoch: 113| Step: 0
Training loss: 2.5717048004678746
Validation loss: 2.478172003096437

Epoch: 6| Step: 1
Training loss: 2.5883447788408778
Validation loss: 2.473702900280156

Epoch: 6| Step: 2
Training loss: 2.7188205052145675
Validation loss: 2.468878450241312

Epoch: 6| Step: 3
Training loss: 2.5067816306021093
Validation loss: 2.468119594657477

Epoch: 6| Step: 4
Training loss: 2.4616326213213693
Validation loss: 2.469731801412178

Epoch: 6| Step: 5
Training loss: 2.9716512858587723
Validation loss: 2.467737711270721

Epoch: 6| Step: 6
Training loss: 2.504548322269703
Validation loss: 2.472704682423956

Epoch: 6| Step: 7
Training loss: 2.946890249040941
Validation loss: 2.478179868300627

Epoch: 6| Step: 8
Training loss: 2.74426712341888
Validation loss: 2.4939233731205377

Epoch: 6| Step: 9
Training loss: 2.827748647696747
Validation loss: 2.5041270195590988

Epoch: 6| Step: 10
Training loss: 3.0873442328693192
Validation loss: 2.534542543706237

Epoch: 6| Step: 11
Training loss: 2.3089422747110846
Validation loss: 2.5671023175969205

Epoch: 6| Step: 12
Training loss: 3.520683481010742
Validation loss: 2.5981281116873918

Epoch: 6| Step: 13
Training loss: 3.585599463659312
Validation loss: 2.560847238378008

Epoch: 114| Step: 0
Training loss: 3.1795882225940497
Validation loss: 2.530509494544813

Epoch: 6| Step: 1
Training loss: 2.2739188087885642
Validation loss: 2.520646001787094

Epoch: 6| Step: 2
Training loss: 3.3491546589133936
Validation loss: 2.499302197560837

Epoch: 6| Step: 3
Training loss: 3.125371529428213
Validation loss: 2.4931934810717493

Epoch: 6| Step: 4
Training loss: 2.678173827679886
Validation loss: 2.497472561175732

Epoch: 6| Step: 5
Training loss: 1.9695782206047792
Validation loss: 2.4874897441383603

Epoch: 6| Step: 6
Training loss: 2.5809885479134635
Validation loss: 2.490931627016999

Epoch: 6| Step: 7
Training loss: 2.5146708130072466
Validation loss: 2.486442474936449

Epoch: 6| Step: 8
Training loss: 2.529867194840285
Validation loss: 2.479328249178284

Epoch: 6| Step: 9
Training loss: 2.7357184897037974
Validation loss: 2.481635681018185

Epoch: 6| Step: 10
Training loss: 2.4977012556243414
Validation loss: 2.4738411413305426

Epoch: 6| Step: 11
Training loss: 3.4438704675556897
Validation loss: 2.481006477018662

Epoch: 6| Step: 12
Training loss: 2.7687642874252205
Validation loss: 2.484312165437574

Epoch: 6| Step: 13
Training loss: 2.9892239947245853
Validation loss: 2.484087455745037

Epoch: 115| Step: 0
Training loss: 3.1754070591744736
Validation loss: 2.48104754338729

Epoch: 6| Step: 1
Training loss: 2.7760301963087275
Validation loss: 2.4880984324770354

Epoch: 6| Step: 2
Training loss: 2.454286919731023
Validation loss: 2.4962661557551797

Epoch: 6| Step: 3
Training loss: 2.7814907869840937
Validation loss: 2.5039555441087877

Epoch: 6| Step: 4
Training loss: 2.887435555667826
Validation loss: 2.5057572235997494

Epoch: 6| Step: 5
Training loss: 3.2596655682292344
Validation loss: 2.5099491328571237

Epoch: 6| Step: 6
Training loss: 2.043677008489075
Validation loss: 2.5034893685126915

Epoch: 6| Step: 7
Training loss: 2.7763730269460223
Validation loss: 2.5060127093800086

Epoch: 6| Step: 8
Training loss: 2.745903779102049
Validation loss: 2.5063326667157497

Epoch: 6| Step: 9
Training loss: 2.2567432868192516
Validation loss: 2.5068822651002187

Epoch: 6| Step: 10
Training loss: 3.506333071018701
Validation loss: 2.489187989672784

Epoch: 6| Step: 11
Training loss: 2.6336189642247727
Validation loss: 2.4921511562795113

Epoch: 6| Step: 12
Training loss: 2.803151849896666
Validation loss: 2.4952468253059776

Epoch: 6| Step: 13
Training loss: 2.3247520027385846
Validation loss: 2.5034881980495896

Epoch: 116| Step: 0
Training loss: 3.156069910935885
Validation loss: 2.509888284765493

Epoch: 6| Step: 1
Training loss: 2.3664457965819543
Validation loss: 2.50553229720997

Epoch: 6| Step: 2
Training loss: 2.5994360312111717
Validation loss: 2.5011886232124416

Epoch: 6| Step: 3
Training loss: 2.306953169976971
Validation loss: 2.5264871478282322

Epoch: 6| Step: 4
Training loss: 3.21033600234069
Validation loss: 2.5393505928160227

Epoch: 6| Step: 5
Training loss: 2.4536761982760336
Validation loss: 2.56878638945714

Epoch: 6| Step: 6
Training loss: 3.3680656686392862
Validation loss: 2.582401357270844

Epoch: 6| Step: 7
Training loss: 2.816006911242197
Validation loss: 2.5849660797299197

Epoch: 6| Step: 8
Training loss: 2.9090516727142344
Validation loss: 2.5642255090332924

Epoch: 6| Step: 9
Training loss: 3.086542693079688
Validation loss: 2.5298115217982753

Epoch: 6| Step: 10
Training loss: 2.288994797886928
Validation loss: 2.5015596549459054

Epoch: 6| Step: 11
Training loss: 2.679337815137261
Validation loss: 2.489013306617413

Epoch: 6| Step: 12
Training loss: 3.0378255410645845
Validation loss: 2.4846027507470594

Epoch: 6| Step: 13
Training loss: 2.712147027882982
Validation loss: 2.474207631596881

Epoch: 117| Step: 0
Training loss: 1.8633951276292324
Validation loss: 2.480175670917898

Epoch: 6| Step: 1
Training loss: 3.4783541402543263
Validation loss: 2.4808799743197563

Epoch: 6| Step: 2
Training loss: 2.8049810994373354
Validation loss: 2.4978892799001025

Epoch: 6| Step: 3
Training loss: 2.699265210515035
Validation loss: 2.504244149495339

Epoch: 6| Step: 4
Training loss: 3.0556490816387325
Validation loss: 2.513415301196657

Epoch: 6| Step: 5
Training loss: 2.9286392981609923
Validation loss: 2.5491246602066515

Epoch: 6| Step: 6
Training loss: 3.232920886472621
Validation loss: 2.636927553429644

Epoch: 6| Step: 7
Training loss: 2.960376213239387
Validation loss: 2.624521396444554

Epoch: 6| Step: 8
Training loss: 1.8962802010974589
Validation loss: 2.560415793461731

Epoch: 6| Step: 9
Training loss: 3.011971746324852
Validation loss: 2.529079146964996

Epoch: 6| Step: 10
Training loss: 2.8272189380242465
Validation loss: 2.512809461353948

Epoch: 6| Step: 11
Training loss: 2.4530690180714187
Validation loss: 2.505459327208971

Epoch: 6| Step: 12
Training loss: 2.560343975114387
Validation loss: 2.498313286611739

Epoch: 6| Step: 13
Training loss: 3.326829111749165
Validation loss: 2.4983360444313285

Epoch: 118| Step: 0
Training loss: 2.751844307864557
Validation loss: 2.4879097975762785

Epoch: 6| Step: 1
Training loss: 3.091541156808876
Validation loss: 2.4940895395707474

Epoch: 6| Step: 2
Training loss: 2.205514248072251
Validation loss: 2.5097856374850624

Epoch: 6| Step: 3
Training loss: 2.3019752189369576
Validation loss: 2.4996343068334723

Epoch: 6| Step: 4
Training loss: 3.0356649122310233
Validation loss: 2.5101431162002426

Epoch: 6| Step: 5
Training loss: 2.8168657115904177
Validation loss: 2.5076849624557553

Epoch: 6| Step: 6
Training loss: 2.548401731875084
Validation loss: 2.533883202194023

Epoch: 6| Step: 7
Training loss: 3.0548645124343983
Validation loss: 2.543683648900059

Epoch: 6| Step: 8
Training loss: 2.9996364691139457
Validation loss: 2.5438968275529987

Epoch: 6| Step: 9
Training loss: 2.7274553208926853
Validation loss: 2.5414378656466967

Epoch: 6| Step: 10
Training loss: 2.624780918243352
Validation loss: 2.549304189460115

Epoch: 6| Step: 11
Training loss: 2.9923768145479506
Validation loss: 2.5536141196692332

Epoch: 6| Step: 12
Training loss: 3.050866744910803
Validation loss: 2.561934716166734

Epoch: 6| Step: 13
Training loss: 2.7393712202181404
Validation loss: 2.5797760152590716

Epoch: 119| Step: 0
Training loss: 2.9013450002833077
Validation loss: 2.571580974981787

Epoch: 6| Step: 1
Training loss: 2.728648527235922
Validation loss: 2.5691838199264683

Epoch: 6| Step: 2
Training loss: 2.639709223570593
Validation loss: 2.5620817267766487

Epoch: 6| Step: 3
Training loss: 3.1138642840888426
Validation loss: 2.564570708038132

Epoch: 6| Step: 4
Training loss: 2.851810141483624
Validation loss: 2.5478678417094898

Epoch: 6| Step: 5
Training loss: 2.4725735184989595
Validation loss: 2.5562460858530462

Epoch: 6| Step: 6
Training loss: 2.223948446664268
Validation loss: 2.5602502048175046

Epoch: 6| Step: 7
Training loss: 2.880804091100905
Validation loss: 2.5701991873914087

Epoch: 6| Step: 8
Training loss: 3.0155449891223474
Validation loss: 2.5548975610009093

Epoch: 6| Step: 9
Training loss: 2.74520395115353
Validation loss: 2.5291678705486436

Epoch: 6| Step: 10
Training loss: 2.302468062022955
Validation loss: 2.51721858979823

Epoch: 6| Step: 11
Training loss: 2.8289505401742963
Validation loss: 2.5184122831235425

Epoch: 6| Step: 12
Training loss: 3.178778891122731
Validation loss: 2.5087485493620836

Epoch: 6| Step: 13
Training loss: 2.971087368826141
Validation loss: 2.5007379058124126

Epoch: 120| Step: 0
Training loss: 3.14893180052776
Validation loss: 2.495224041365844

Epoch: 6| Step: 1
Training loss: 2.775847427605706
Validation loss: 2.4970646946136044

Epoch: 6| Step: 2
Training loss: 2.6687306423512585
Validation loss: 2.490591346526843

Epoch: 6| Step: 3
Training loss: 2.9095294456584915
Validation loss: 2.4994241461444715

Epoch: 6| Step: 4
Training loss: 3.0228526414698114
Validation loss: 2.501215702745073

Epoch: 6| Step: 5
Training loss: 3.289271259705085
Validation loss: 2.501341269227692

Epoch: 6| Step: 6
Training loss: 2.433434152038709
Validation loss: 2.508284416439908

Epoch: 6| Step: 7
Training loss: 2.5947242653534714
Validation loss: 2.512593225773846

Epoch: 6| Step: 8
Training loss: 2.8089725838420216
Validation loss: 2.5126521044953534

Epoch: 6| Step: 9
Training loss: 2.470943779966943
Validation loss: 2.513590468996397

Epoch: 6| Step: 10
Training loss: 2.6300226932895496
Validation loss: 2.5316631871673945

Epoch: 6| Step: 11
Training loss: 2.8198695799246503
Validation loss: 2.5279073932896337

Epoch: 6| Step: 12
Training loss: 2.465403642859096
Validation loss: 2.549920072636011

Epoch: 6| Step: 13
Training loss: 2.69911372509023
Validation loss: 2.5630289267706123

Epoch: 121| Step: 0
Training loss: 2.00648828915511
Validation loss: 2.561517091251057

Epoch: 6| Step: 1
Training loss: 2.2395969006031335
Validation loss: 2.5294600122746163

Epoch: 6| Step: 2
Training loss: 3.095991151328835
Validation loss: 2.516250327793871

Epoch: 6| Step: 3
Training loss: 3.285840556283265
Validation loss: 2.497659747662362

Epoch: 6| Step: 4
Training loss: 2.848033989864214
Validation loss: 2.5005381866261045

Epoch: 6| Step: 5
Training loss: 2.822310904697326
Validation loss: 2.48307253087569

Epoch: 6| Step: 6
Training loss: 2.601836135724278
Validation loss: 2.477924577283544

Epoch: 6| Step: 7
Training loss: 2.4762255322067372
Validation loss: 2.4743876637243676

Epoch: 6| Step: 8
Training loss: 2.816783271347247
Validation loss: 2.4739000470085464

Epoch: 6| Step: 9
Training loss: 3.3949183692163465
Validation loss: 2.4738840914317626

Epoch: 6| Step: 10
Training loss: 2.7186263483801767
Validation loss: 2.463777974913784

Epoch: 6| Step: 11
Training loss: 2.7574675346946553
Validation loss: 2.4753834008684437

Epoch: 6| Step: 12
Training loss: 2.7201564264196083
Validation loss: 2.4753847094168835

Epoch: 6| Step: 13
Training loss: 2.836281159231042
Validation loss: 2.4919863702739766

Epoch: 122| Step: 0
Training loss: 2.740341391074519
Validation loss: 2.5067242810034647

Epoch: 6| Step: 1
Training loss: 3.2307722140567408
Validation loss: 2.531961218321154

Epoch: 6| Step: 2
Training loss: 2.9445482471650575
Validation loss: 2.555842473403912

Epoch: 6| Step: 3
Training loss: 2.71472852723113
Validation loss: 2.5684772962374085

Epoch: 6| Step: 4
Training loss: 2.919610926168944
Validation loss: 2.5990285326133082

Epoch: 6| Step: 5
Training loss: 2.6268916807114757
Validation loss: 2.58111269382397

Epoch: 6| Step: 6
Training loss: 2.136191350088258
Validation loss: 2.532137847883072

Epoch: 6| Step: 7
Training loss: 2.4806884668313782
Validation loss: 2.5204773864055188

Epoch: 6| Step: 8
Training loss: 2.5196800010595113
Validation loss: 2.498941764613671

Epoch: 6| Step: 9
Training loss: 3.2772480128857913
Validation loss: 2.4751045084003

Epoch: 6| Step: 10
Training loss: 2.966310161072117
Validation loss: 2.4770481353814398

Epoch: 6| Step: 11
Training loss: 2.9162131547296672
Validation loss: 2.4751604445628432

Epoch: 6| Step: 12
Training loss: 2.393384550001736
Validation loss: 2.479081972874142

Epoch: 6| Step: 13
Training loss: 2.801484385484859
Validation loss: 2.473799194675185

Epoch: 123| Step: 0
Training loss: 2.785808898730378
Validation loss: 2.47774743537302

Epoch: 6| Step: 1
Training loss: 2.1231357025963753
Validation loss: 2.4845091172867364

Epoch: 6| Step: 2
Training loss: 2.9433326441532537
Validation loss: 2.4892861042146364

Epoch: 6| Step: 3
Training loss: 2.3393530737144648
Validation loss: 2.492134512601192

Epoch: 6| Step: 4
Training loss: 2.8400680684273714
Validation loss: 2.502661044546733

Epoch: 6| Step: 5
Training loss: 2.9403824968709893
Validation loss: 2.4989485508701645

Epoch: 6| Step: 6
Training loss: 3.2110046231198837
Validation loss: 2.509875393438118

Epoch: 6| Step: 7
Training loss: 2.355443748733662
Validation loss: 2.506009509446905

Epoch: 6| Step: 8
Training loss: 2.8913325912876893
Validation loss: 2.5000025985047976

Epoch: 6| Step: 9
Training loss: 2.9968015787082796
Validation loss: 2.515573617110681

Epoch: 6| Step: 10
Training loss: 2.546154084007257
Validation loss: 2.5076114703155263

Epoch: 6| Step: 11
Training loss: 2.5519061799098357
Validation loss: 2.51565687276187

Epoch: 6| Step: 12
Training loss: 3.1236891476740105
Validation loss: 2.5355585159817435

Epoch: 6| Step: 13
Training loss: 2.4754720988988663
Validation loss: 2.5067810681269056

Epoch: 124| Step: 0
Training loss: 2.233784204017297
Validation loss: 2.5148125943473114

Epoch: 6| Step: 1
Training loss: 2.552151322270123
Validation loss: 2.497967167346839

Epoch: 6| Step: 2
Training loss: 2.909964372082509
Validation loss: 2.49884953843285

Epoch: 6| Step: 3
Training loss: 2.142562212402453
Validation loss: 2.490589406238852

Epoch: 6| Step: 4
Training loss: 2.4369268477100596
Validation loss: 2.493866620115284

Epoch: 6| Step: 5
Training loss: 3.075771613344537
Validation loss: 2.5068761082824

Epoch: 6| Step: 6
Training loss: 2.3305034393173862
Validation loss: 2.507628828628092

Epoch: 6| Step: 7
Training loss: 3.0291992801413037
Validation loss: 2.5092329484406877

Epoch: 6| Step: 8
Training loss: 2.4869604512787022
Validation loss: 2.498441850485713

Epoch: 6| Step: 9
Training loss: 2.874075035904894
Validation loss: 2.4917373016576136

Epoch: 6| Step: 10
Training loss: 3.100018248965786
Validation loss: 2.482342308001254

Epoch: 6| Step: 11
Training loss: 2.987989383979946
Validation loss: 2.4895517717350746

Epoch: 6| Step: 12
Training loss: 2.919779633084306
Validation loss: 2.490757871129753

Epoch: 6| Step: 13
Training loss: 3.152136662333171
Validation loss: 2.502888483392314

Epoch: 125| Step: 0
Training loss: 2.7645099353221934
Validation loss: 2.515873708107496

Epoch: 6| Step: 1
Training loss: 2.1772516237279795
Validation loss: 2.5352799211159125

Epoch: 6| Step: 2
Training loss: 2.8786014721643696
Validation loss: 2.5401653601192127

Epoch: 6| Step: 3
Training loss: 2.5414818138899307
Validation loss: 2.522861940438269

Epoch: 6| Step: 4
Training loss: 2.77864501342952
Validation loss: 2.517249464690538

Epoch: 6| Step: 5
Training loss: 2.526282251181423
Validation loss: 2.4994836253456283

Epoch: 6| Step: 6
Training loss: 2.8296649597045387
Validation loss: 2.497990719582577

Epoch: 6| Step: 7
Training loss: 3.404582043958255
Validation loss: 2.4932286286634593

Epoch: 6| Step: 8
Training loss: 2.799420524988398
Validation loss: 2.501182116701189

Epoch: 6| Step: 9
Training loss: 2.4690149865203552
Validation loss: 2.507124041059331

Epoch: 6| Step: 10
Training loss: 2.626351871248658
Validation loss: 2.5117227153070263

Epoch: 6| Step: 11
Training loss: 2.5165752251119895
Validation loss: 2.527497152332141

Epoch: 6| Step: 12
Training loss: 3.0803677671261123
Validation loss: 2.5391896761083337

Epoch: 6| Step: 13
Training loss: 2.5240061210824103
Validation loss: 2.5408258360218428

Epoch: 126| Step: 0
Training loss: 2.5501165999139603
Validation loss: 2.550142206871074

Epoch: 6| Step: 1
Training loss: 2.670107072547771
Validation loss: 2.555310387671508

Epoch: 6| Step: 2
Training loss: 2.79352851006752
Validation loss: 2.574024916469713

Epoch: 6| Step: 3
Training loss: 2.6669968360907856
Validation loss: 2.554814423118292

Epoch: 6| Step: 4
Training loss: 3.155455234288026
Validation loss: 2.529000466027679

Epoch: 6| Step: 5
Training loss: 2.3189822921175542
Validation loss: 2.5319800489457696

Epoch: 6| Step: 6
Training loss: 2.525136275438158
Validation loss: 2.5036526350732453

Epoch: 6| Step: 7
Training loss: 3.1671481686649634
Validation loss: 2.488733592919443

Epoch: 6| Step: 8
Training loss: 2.693021381019908
Validation loss: 2.483909498828654

Epoch: 6| Step: 9
Training loss: 2.433023401231719
Validation loss: 2.4807013610184185

Epoch: 6| Step: 10
Training loss: 2.9174863117750065
Validation loss: 2.4855773146330438

Epoch: 6| Step: 11
Training loss: 3.00043166551804
Validation loss: 2.4950282035060676

Epoch: 6| Step: 12
Training loss: 2.897836792588059
Validation loss: 2.534918932198463

Epoch: 6| Step: 13
Training loss: 2.5455682128446524
Validation loss: 2.5252685151900596

Epoch: 127| Step: 0
Training loss: 2.6665968488454457
Validation loss: 2.5265835115658186

Epoch: 6| Step: 1
Training loss: 2.1458869359503367
Validation loss: 2.533256642846362

Epoch: 6| Step: 2
Training loss: 3.0603557008436186
Validation loss: 2.5510607708560356

Epoch: 6| Step: 3
Training loss: 2.7775008402633428
Validation loss: 2.5423139090636537

Epoch: 6| Step: 4
Training loss: 3.05331960036453
Validation loss: 2.5206108723938656

Epoch: 6| Step: 5
Training loss: 3.039838755497375
Validation loss: 2.519628980667575

Epoch: 6| Step: 6
Training loss: 2.8862803207529617
Validation loss: 2.497042716770293

Epoch: 6| Step: 7
Training loss: 2.611008640966066
Validation loss: 2.4990649453803924

Epoch: 6| Step: 8
Training loss: 3.048640126230496
Validation loss: 2.493670819066059

Epoch: 6| Step: 9
Training loss: 2.2800633727853348
Validation loss: 2.4977796025888015

Epoch: 6| Step: 10
Training loss: 2.8485867794425097
Validation loss: 2.5071811044111434

Epoch: 6| Step: 11
Training loss: 3.0299070863987683
Validation loss: 2.5027500552387947

Epoch: 6| Step: 12
Training loss: 2.2026117687465487
Validation loss: 2.5161035808967207

Epoch: 6| Step: 13
Training loss: 2.223452138953094
Validation loss: 2.5090948876844097

Epoch: 128| Step: 0
Training loss: 2.7635023516635817
Validation loss: 2.515248013524197

Epoch: 6| Step: 1
Training loss: 3.1204046412480015
Validation loss: 2.5222869223936133

Epoch: 6| Step: 2
Training loss: 2.6708438958382197
Validation loss: 2.524545318503772

Epoch: 6| Step: 3
Training loss: 2.9837834436007022
Validation loss: 2.525421090368122

Epoch: 6| Step: 4
Training loss: 2.5728424514589494
Validation loss: 2.548391546812361

Epoch: 6| Step: 5
Training loss: 2.9501313067163086
Validation loss: 2.56203192701052

Epoch: 6| Step: 6
Training loss: 2.965497614513384
Validation loss: 2.5966239284907537

Epoch: 6| Step: 7
Training loss: 3.139743358547629
Validation loss: 2.626352126992689

Epoch: 6| Step: 8
Training loss: 2.871454125448579
Validation loss: 2.659005151964731

Epoch: 6| Step: 9
Training loss: 2.3600275008975373
Validation loss: 2.6170427385510426

Epoch: 6| Step: 10
Training loss: 2.5028614834152476
Validation loss: 2.561766528733074

Epoch: 6| Step: 11
Training loss: 2.490835367123014
Validation loss: 2.518392465418317

Epoch: 6| Step: 12
Training loss: 2.408411417644549
Validation loss: 2.496851800052062

Epoch: 6| Step: 13
Training loss: 2.729075325949174
Validation loss: 2.4872368156224645

Epoch: 129| Step: 0
Training loss: 3.2143521680471623
Validation loss: 2.480972735191971

Epoch: 6| Step: 1
Training loss: 2.7903887162772225
Validation loss: 2.4892410500918385

Epoch: 6| Step: 2
Training loss: 2.645623256323204
Validation loss: 2.498465156090431

Epoch: 6| Step: 3
Training loss: 2.6315755683475683
Validation loss: 2.507173320983463

Epoch: 6| Step: 4
Training loss: 2.486796800141763
Validation loss: 2.5184743798974067

Epoch: 6| Step: 5
Training loss: 2.621787512391467
Validation loss: 2.5522599096197816

Epoch: 6| Step: 6
Training loss: 2.6299001280239
Validation loss: 2.581682500082129

Epoch: 6| Step: 7
Training loss: 2.672475111642964
Validation loss: 2.6082460750213685

Epoch: 6| Step: 8
Training loss: 2.7501299567293445
Validation loss: 2.55546206805185

Epoch: 6| Step: 9
Training loss: 2.751562021700608
Validation loss: 2.507368328853033

Epoch: 6| Step: 10
Training loss: 2.9827891025654663
Validation loss: 2.497493999411213

Epoch: 6| Step: 11
Training loss: 2.783689136567769
Validation loss: 2.4861006313080254

Epoch: 6| Step: 12
Training loss: 2.530057649822585
Validation loss: 2.477401570037369

Epoch: 6| Step: 13
Training loss: 2.776860233931312
Validation loss: 2.4716870257205077

Epoch: 130| Step: 0
Training loss: 3.1684151557204467
Validation loss: 2.4775255630773856

Epoch: 6| Step: 1
Training loss: 2.371890793497731
Validation loss: 2.466375976646127

Epoch: 6| Step: 2
Training loss: 2.6288837584940548
Validation loss: 2.475411302264685

Epoch: 6| Step: 3
Training loss: 2.98481387760982
Validation loss: 2.4822054058980596

Epoch: 6| Step: 4
Training loss: 2.780132797966423
Validation loss: 2.4723185984066225

Epoch: 6| Step: 5
Training loss: 2.404747035310161
Validation loss: 2.4863995561771457

Epoch: 6| Step: 6
Training loss: 3.1088983371685877
Validation loss: 2.4946663185958124

Epoch: 6| Step: 7
Training loss: 2.748850755705434
Validation loss: 2.4937986965556243

Epoch: 6| Step: 8
Training loss: 2.521473879389707
Validation loss: 2.5005652004116143

Epoch: 6| Step: 9
Training loss: 2.4499249816619866
Validation loss: 2.520166635552757

Epoch: 6| Step: 10
Training loss: 2.757982459518058
Validation loss: 2.5281528843061993

Epoch: 6| Step: 11
Training loss: 3.0404212875578542
Validation loss: 2.521419867432162

Epoch: 6| Step: 12
Training loss: 2.4660691783449247
Validation loss: 2.5131342699956383

Epoch: 6| Step: 13
Training loss: 2.622760180430207
Validation loss: 2.5004642875811354

Epoch: 131| Step: 0
Training loss: 2.6015152110707747
Validation loss: 2.4936954568914165

Epoch: 6| Step: 1
Training loss: 2.288022583016406
Validation loss: 2.4850928487842108

Epoch: 6| Step: 2
Training loss: 2.865813796751521
Validation loss: 2.494122680462804

Epoch: 6| Step: 3
Training loss: 2.9284802199990665
Validation loss: 2.489014754772662

Epoch: 6| Step: 4
Training loss: 3.0551165891585956
Validation loss: 2.5064056082223565

Epoch: 6| Step: 5
Training loss: 2.859920095381221
Validation loss: 2.5105445564409026

Epoch: 6| Step: 6
Training loss: 2.536948676889693
Validation loss: 2.549756780498676

Epoch: 6| Step: 7
Training loss: 2.1584386360471437
Validation loss: 2.561756531405201

Epoch: 6| Step: 8
Training loss: 2.756509878488571
Validation loss: 2.5835855230580496

Epoch: 6| Step: 9
Training loss: 2.860456418518068
Validation loss: 2.5565382153253147

Epoch: 6| Step: 10
Training loss: 2.4380602070585105
Validation loss: 2.5517816307903693

Epoch: 6| Step: 11
Training loss: 2.9534882821566963
Validation loss: 2.536259727150676

Epoch: 6| Step: 12
Training loss: 2.5962007273818237
Validation loss: 2.50899811894099

Epoch: 6| Step: 13
Training loss: 2.8372438222717205
Validation loss: 2.504668415627296

Epoch: 132| Step: 0
Training loss: 2.4780511563664978
Validation loss: 2.493229268229463

Epoch: 6| Step: 1
Training loss: 2.7588670135558053
Validation loss: 2.500917643646312

Epoch: 6| Step: 2
Training loss: 2.6976412677984083
Validation loss: 2.513643245819394

Epoch: 6| Step: 3
Training loss: 3.0113529918345114
Validation loss: 2.531078369771458

Epoch: 6| Step: 4
Training loss: 2.3510009500687405
Validation loss: 2.516058798107643

Epoch: 6| Step: 5
Training loss: 2.829968773497716
Validation loss: 2.5181995247618922

Epoch: 6| Step: 6
Training loss: 2.9469769780787516
Validation loss: 2.5246451601366

Epoch: 6| Step: 7
Training loss: 2.8267685814544747
Validation loss: 2.5315140186816794

Epoch: 6| Step: 8
Training loss: 2.9792586803676344
Validation loss: 2.5494927369257607

Epoch: 6| Step: 9
Training loss: 2.5887097023369834
Validation loss: 2.5645099883477784

Epoch: 6| Step: 10
Training loss: 1.9626910511494067
Validation loss: 2.5446381194174696

Epoch: 6| Step: 11
Training loss: 2.636588809732231
Validation loss: 2.560073874555534

Epoch: 6| Step: 12
Training loss: 2.534348839790617
Validation loss: 2.5545149566113174

Epoch: 6| Step: 13
Training loss: 2.7413328746369765
Validation loss: 2.5425733663390955

Epoch: 133| Step: 0
Training loss: 3.1007348020366132
Validation loss: 2.555566408798025

Epoch: 6| Step: 1
Training loss: 2.2993921513292337
Validation loss: 2.552175029407351

Epoch: 6| Step: 2
Training loss: 2.2488114078570285
Validation loss: 2.5313220857630396

Epoch: 6| Step: 3
Training loss: 2.7121501925579614
Validation loss: 2.5286904188910864

Epoch: 6| Step: 4
Training loss: 2.7556074366590577
Validation loss: 2.5144927800992583

Epoch: 6| Step: 5
Training loss: 2.410979342143899
Validation loss: 2.509876980726594

Epoch: 6| Step: 6
Training loss: 2.645882152998072
Validation loss: 2.4979208309153207

Epoch: 6| Step: 7
Training loss: 2.9120514094457333
Validation loss: 2.4853909097951887

Epoch: 6| Step: 8
Training loss: 2.21449990269378
Validation loss: 2.4990450470838437

Epoch: 6| Step: 9
Training loss: 2.868490229794289
Validation loss: 2.5154286896954345

Epoch: 6| Step: 10
Training loss: 2.579358354962612
Validation loss: 2.5111781470700727

Epoch: 6| Step: 11
Training loss: 2.5261591828267633
Validation loss: 2.520945955745703

Epoch: 6| Step: 12
Training loss: 3.3885556423689818
Validation loss: 2.520851300618851

Epoch: 6| Step: 13
Training loss: 2.4493734259185445
Validation loss: 2.515622777370357

Epoch: 134| Step: 0
Training loss: 3.053687671051836
Validation loss: 2.5480380744139004

Epoch: 6| Step: 1
Training loss: 2.5481639946841983
Validation loss: 2.610016714740408

Epoch: 6| Step: 2
Training loss: 2.3673465285059248
Validation loss: 2.6378893092668645

Epoch: 6| Step: 3
Training loss: 2.898210789124601
Validation loss: 2.747005399251243

Epoch: 6| Step: 4
Training loss: 2.3469623168468683
Validation loss: 2.862803180604006

Epoch: 6| Step: 5
Training loss: 2.5826103265171096
Validation loss: 2.890879994558081

Epoch: 6| Step: 6
Training loss: 3.324141289674779
Validation loss: 2.7939429405803256

Epoch: 6| Step: 7
Training loss: 2.7856998635362373
Validation loss: 2.7603191297360095

Epoch: 6| Step: 8
Training loss: 3.285710382163057
Validation loss: 2.688806165371146

Epoch: 6| Step: 9
Training loss: 2.297509657182623
Validation loss: 2.578703631477871

Epoch: 6| Step: 10
Training loss: 2.950096878788607
Validation loss: 2.50901813550431

Epoch: 6| Step: 11
Training loss: 2.2280847532428063
Validation loss: 2.5125364822647445

Epoch: 6| Step: 12
Training loss: 2.5533357829720456
Validation loss: 2.5551330994642214

Epoch: 6| Step: 13
Training loss: 2.822039975976081
Validation loss: 2.5466477568089223

Epoch: 135| Step: 0
Training loss: 2.778260928627227
Validation loss: 2.5202639265592612

Epoch: 6| Step: 1
Training loss: 3.311601480944123
Validation loss: 2.4941050811641916

Epoch: 6| Step: 2
Training loss: 2.5567196104526966
Validation loss: 2.4703075666385423

Epoch: 6| Step: 3
Training loss: 2.2557824323999465
Validation loss: 2.470120916576678

Epoch: 6| Step: 4
Training loss: 2.918769695860841
Validation loss: 2.5115063575790786

Epoch: 6| Step: 5
Training loss: 2.682317127489648
Validation loss: 2.6389660387000173

Epoch: 6| Step: 6
Training loss: 2.872979324760359
Validation loss: 2.716650197562823

Epoch: 6| Step: 7
Training loss: 3.2321896749114973
Validation loss: 2.821120577839081

Epoch: 6| Step: 8
Training loss: 3.5889159488609206
Validation loss: 2.7947075275912563

Epoch: 6| Step: 9
Training loss: 2.5358750275104978
Validation loss: 2.6925788959835137

Epoch: 6| Step: 10
Training loss: 2.3581448815561923
Validation loss: 2.609499051959308

Epoch: 6| Step: 11
Training loss: 2.2576477624265157
Validation loss: 2.5326919519992956

Epoch: 6| Step: 12
Training loss: 2.215561630999977
Validation loss: 2.533895438194072

Epoch: 6| Step: 13
Training loss: 2.7712927893887036
Validation loss: 2.5156823994182154

Epoch: 136| Step: 0
Training loss: 2.306510178691336
Validation loss: 2.505479820211635

Epoch: 6| Step: 1
Training loss: 2.7698095528860884
Validation loss: 2.496994001796267

Epoch: 6| Step: 2
Training loss: 2.148184799591744
Validation loss: 2.4891943833484294

Epoch: 6| Step: 3
Training loss: 2.7290346147656073
Validation loss: 2.4808211465385

Epoch: 6| Step: 4
Training loss: 2.3376912451858574
Validation loss: 2.491330030427202

Epoch: 6| Step: 5
Training loss: 2.7115264164958335
Validation loss: 2.4973215059603517

Epoch: 6| Step: 6
Training loss: 3.314085383068688
Validation loss: 2.4949162477135927

Epoch: 6| Step: 7
Training loss: 2.947435499266925
Validation loss: 2.4987764651032514

Epoch: 6| Step: 8
Training loss: 1.9786893235504888
Validation loss: 2.5310584395488327

Epoch: 6| Step: 9
Training loss: 3.092780221317947
Validation loss: 2.553519147469452

Epoch: 6| Step: 10
Training loss: 2.664311819631667
Validation loss: 2.5865653504862247

Epoch: 6| Step: 11
Training loss: 2.031899685763993
Validation loss: 2.6271310487635975

Epoch: 6| Step: 12
Training loss: 2.8656650419776035
Validation loss: 2.677536634721157

Epoch: 6| Step: 13
Training loss: 3.8535767524770344
Validation loss: 2.7244841798371557

Epoch: 137| Step: 0
Training loss: 2.7687790122137486
Validation loss: 2.6544583633148973

Epoch: 6| Step: 1
Training loss: 3.2230978923232434
Validation loss: 2.5784055764119436

Epoch: 6| Step: 2
Training loss: 2.366767770550803
Validation loss: 2.539236368011471

Epoch: 6| Step: 3
Training loss: 2.9198754960781557
Validation loss: 2.5138193002754647

Epoch: 6| Step: 4
Training loss: 2.6717471265030484
Validation loss: 2.4883587499756965

Epoch: 6| Step: 5
Training loss: 2.8100263101561045
Validation loss: 2.4859573867231455

Epoch: 6| Step: 6
Training loss: 2.173113462973188
Validation loss: 2.4934815868394153

Epoch: 6| Step: 7
Training loss: 2.2366197953901015
Validation loss: 2.497157581128193

Epoch: 6| Step: 8
Training loss: 2.683676905780415
Validation loss: 2.5057186923280867

Epoch: 6| Step: 9
Training loss: 2.568852900093845
Validation loss: 2.520568067573378

Epoch: 6| Step: 10
Training loss: 3.2842306495544213
Validation loss: 2.5144689154767033

Epoch: 6| Step: 11
Training loss: 1.9975038687390423
Validation loss: 2.523651996775382

Epoch: 6| Step: 12
Training loss: 2.5552009276572916
Validation loss: 2.5398484697666897

Epoch: 6| Step: 13
Training loss: 3.216827707426616
Validation loss: 2.543589123310932

Epoch: 138| Step: 0
Training loss: 3.2412937633003533
Validation loss: 2.581675856826067

Epoch: 6| Step: 1
Training loss: 2.5694638042465217
Validation loss: 2.617770132328537

Epoch: 6| Step: 2
Training loss: 2.3694612265684842
Validation loss: 2.624823780658997

Epoch: 6| Step: 3
Training loss: 2.4550598677970714
Validation loss: 2.6040072146585866

Epoch: 6| Step: 4
Training loss: 2.678417828106766
Validation loss: 2.589877628502081

Epoch: 6| Step: 5
Training loss: 2.2401356097452734
Validation loss: 2.586593151729815

Epoch: 6| Step: 6
Training loss: 2.901663000844721
Validation loss: 2.574751664693526

Epoch: 6| Step: 7
Training loss: 2.7518423151539633
Validation loss: 2.5765054199130284

Epoch: 6| Step: 8
Training loss: 2.8306017405101174
Validation loss: 2.5642612036413657

Epoch: 6| Step: 9
Training loss: 2.4924706564259753
Validation loss: 2.568180733590416

Epoch: 6| Step: 10
Training loss: 2.8850162012448584
Validation loss: 2.5612420406630365

Epoch: 6| Step: 11
Training loss: 2.53018486312549
Validation loss: 2.5369359645000844

Epoch: 6| Step: 12
Training loss: 2.5630443273990884
Validation loss: 2.5402386017470815

Epoch: 6| Step: 13
Training loss: 2.283233616268813
Validation loss: 2.519525781911551

Epoch: 139| Step: 0
Training loss: 3.0031375372681524
Validation loss: 2.5102972826787764

Epoch: 6| Step: 1
Training loss: 2.3675277012268854
Validation loss: 2.502793698463959

Epoch: 6| Step: 2
Training loss: 3.0309526749921374
Validation loss: 2.492177722464385

Epoch: 6| Step: 3
Training loss: 2.6324545959440653
Validation loss: 2.479058121038519

Epoch: 6| Step: 4
Training loss: 2.639695946494862
Validation loss: 2.4890475800856287

Epoch: 6| Step: 5
Training loss: 2.3236701894990714
Validation loss: 2.4808546031500978

Epoch: 6| Step: 6
Training loss: 2.3633280599702973
Validation loss: 2.4810572438911356

Epoch: 6| Step: 7
Training loss: 2.9416314149064546
Validation loss: 2.491502276037933

Epoch: 6| Step: 8
Training loss: 2.559986742849594
Validation loss: 2.5072291040670747

Epoch: 6| Step: 9
Training loss: 2.686526188628862
Validation loss: 2.5267721270418146

Epoch: 6| Step: 10
Training loss: 1.7759207258316674
Validation loss: 2.5538724359418277

Epoch: 6| Step: 11
Training loss: 2.968878652896989
Validation loss: 2.576920977892151

Epoch: 6| Step: 12
Training loss: 2.525215113324168
Validation loss: 2.5940404739942107

Epoch: 6| Step: 13
Training loss: 3.1088190396399766
Validation loss: 2.5805337729948836

Epoch: 140| Step: 0
Training loss: 3.0191823898468972
Validation loss: 2.5957571191469073

Epoch: 6| Step: 1
Training loss: 2.606899709243755
Validation loss: 2.555622093573341

Epoch: 6| Step: 2
Training loss: 2.79593305869457
Validation loss: 2.5319876477789856

Epoch: 6| Step: 3
Training loss: 2.6571483215006295
Validation loss: 2.5264650098993546

Epoch: 6| Step: 4
Training loss: 2.660024138319589
Validation loss: 2.505122736248657

Epoch: 6| Step: 5
Training loss: 3.3477350178980765
Validation loss: 2.4900761248440477

Epoch: 6| Step: 6
Training loss: 2.537827787227595
Validation loss: 2.4848322479490492

Epoch: 6| Step: 7
Training loss: 1.6667624048710068
Validation loss: 2.4827109757055053

Epoch: 6| Step: 8
Training loss: 2.435168398256813
Validation loss: 2.4929670807430475

Epoch: 6| Step: 9
Training loss: 2.5625171195598107
Validation loss: 2.487120995227309

Epoch: 6| Step: 10
Training loss: 2.963604774987566
Validation loss: 2.494305267143239

Epoch: 6| Step: 11
Training loss: 2.43057578184401
Validation loss: 2.517493391134117

Epoch: 6| Step: 12
Training loss: 2.4444706354279413
Validation loss: 2.556677743082065

Epoch: 6| Step: 13
Training loss: 1.565832475327356
Validation loss: 2.5649899266719682

Epoch: 141| Step: 0
Training loss: 2.4455864603548165
Validation loss: 2.6278735525943695

Epoch: 6| Step: 1
Training loss: 2.351366611572215
Validation loss: 2.651682253724529

Epoch: 6| Step: 2
Training loss: 2.8787740731402613
Validation loss: 2.69054564405593

Epoch: 6| Step: 3
Training loss: 2.652329008036167
Validation loss: 2.7013816354325235

Epoch: 6| Step: 4
Training loss: 2.626076704550881
Validation loss: 2.694119599366144

Epoch: 6| Step: 5
Training loss: 2.9430421532979896
Validation loss: 2.672899933444526

Epoch: 6| Step: 6
Training loss: 2.3741725684918626
Validation loss: 2.63092134538551

Epoch: 6| Step: 7
Training loss: 2.3640024645255164
Validation loss: 2.580789032253299

Epoch: 6| Step: 8
Training loss: 2.659509700676413
Validation loss: 2.563622444685798

Epoch: 6| Step: 9
Training loss: 2.6047709158187526
Validation loss: 2.5457080639122665

Epoch: 6| Step: 10
Training loss: 3.2009217663219713
Validation loss: 2.5537211701133553

Epoch: 6| Step: 11
Training loss: 2.5928290697009473
Validation loss: 2.554363116616552

Epoch: 6| Step: 12
Training loss: 1.8941000536198078
Validation loss: 2.546640662776906

Epoch: 6| Step: 13
Training loss: 3.414351182687314
Validation loss: 2.5624196810056312

Epoch: 142| Step: 0
Training loss: 3.1366059507465693
Validation loss: 2.5858011244775136

Epoch: 6| Step: 1
Training loss: 2.2825471508424733
Validation loss: 2.616180234906962

Epoch: 6| Step: 2
Training loss: 2.599688247183486
Validation loss: 2.64653525433549

Epoch: 6| Step: 3
Training loss: 2.0379652089002867
Validation loss: 2.716925342891425

Epoch: 6| Step: 4
Training loss: 2.762021578274243
Validation loss: 2.739351164878608

Epoch: 6| Step: 5
Training loss: 2.8596064572902637
Validation loss: 2.7047455668494997

Epoch: 6| Step: 6
Training loss: 2.518444021869512
Validation loss: 2.6481639611781858

Epoch: 6| Step: 7
Training loss: 2.58344732053576
Validation loss: 2.617668782261651

Epoch: 6| Step: 8
Training loss: 2.3037180785245934
Validation loss: 2.604604375334811

Epoch: 6| Step: 9
Training loss: 2.9658344608857456
Validation loss: 2.5975083106616044

Epoch: 6| Step: 10
Training loss: 3.086280359464181
Validation loss: 2.579952916749668

Epoch: 6| Step: 11
Training loss: 2.5543840793927077
Validation loss: 2.5735375363228647

Epoch: 6| Step: 12
Training loss: 2.636170913862978
Validation loss: 2.564013291665296

Epoch: 6| Step: 13
Training loss: 2.7410214980074605
Validation loss: 2.549216290402233

Epoch: 143| Step: 0
Training loss: 2.3469161963370984
Validation loss: 2.546094117273786

Epoch: 6| Step: 1
Training loss: 3.0636538453345548
Validation loss: 2.5317988649473695

Epoch: 6| Step: 2
Training loss: 2.255803570738343
Validation loss: 2.5431203418773576

Epoch: 6| Step: 3
Training loss: 2.9142176200754473
Validation loss: 2.541179685642058

Epoch: 6| Step: 4
Training loss: 2.922037211928607
Validation loss: 2.577901131066928

Epoch: 6| Step: 5
Training loss: 2.7689723216196125
Validation loss: 2.621686522980337

Epoch: 6| Step: 6
Training loss: 3.206306180406008
Validation loss: 2.659373291172401

Epoch: 6| Step: 7
Training loss: 2.054230962008868
Validation loss: 2.711672701734344

Epoch: 6| Step: 8
Training loss: 2.675942520516446
Validation loss: 2.744903224700048

Epoch: 6| Step: 9
Training loss: 2.5826481761687314
Validation loss: 2.6855320002795535

Epoch: 6| Step: 10
Training loss: 2.817551040254802
Validation loss: 2.628680561678844

Epoch: 6| Step: 11
Training loss: 2.139359928738875
Validation loss: 2.5145703795938337

Epoch: 6| Step: 12
Training loss: 2.100679346736183
Validation loss: 2.4674970864740486

Epoch: 6| Step: 13
Training loss: 2.576257295038296
Validation loss: 2.4657925261096785

Epoch: 144| Step: 0
Training loss: 2.7548153073526565
Validation loss: 2.459994071295012

Epoch: 6| Step: 1
Training loss: 2.90166957413208
Validation loss: 2.465775736224425

Epoch: 6| Step: 2
Training loss: 2.5143930012861935
Validation loss: 2.45018190621473

Epoch: 6| Step: 3
Training loss: 2.0335666064086015
Validation loss: 2.464038282581244

Epoch: 6| Step: 4
Training loss: 1.9917860636442952
Validation loss: 2.4612269712941814

Epoch: 6| Step: 5
Training loss: 2.2157116355152837
Validation loss: 2.451132603845384

Epoch: 6| Step: 6
Training loss: 2.755867853293567
Validation loss: 2.472176956939757

Epoch: 6| Step: 7
Training loss: 2.81889227193007
Validation loss: 2.4866621711712535

Epoch: 6| Step: 8
Training loss: 2.625874146733781
Validation loss: 2.512198477116544

Epoch: 6| Step: 9
Training loss: 2.6330815299479946
Validation loss: 2.5436761535405226

Epoch: 6| Step: 10
Training loss: 2.6038368524871363
Validation loss: 2.5620939031519905

Epoch: 6| Step: 11
Training loss: 3.255951054591801
Validation loss: 2.57459476092582

Epoch: 6| Step: 12
Training loss: 2.0274263045420717
Validation loss: 2.599437182140805

Epoch: 6| Step: 13
Training loss: 2.6424048029300145
Validation loss: 2.5741136435365055

Epoch: 145| Step: 0
Training loss: 2.638965152731567
Validation loss: 2.5785689641955662

Epoch: 6| Step: 1
Training loss: 1.7425154988763982
Validation loss: 2.5948954895760377

Epoch: 6| Step: 2
Training loss: 2.4604030452634387
Validation loss: 2.6103185380114384

Epoch: 6| Step: 3
Training loss: 3.0120535935273067
Validation loss: 2.5882239909499942

Epoch: 6| Step: 4
Training loss: 2.523823144692598
Validation loss: 2.5645667484715795

Epoch: 6| Step: 5
Training loss: 2.5565136090369083
Validation loss: 2.54374243686843

Epoch: 6| Step: 6
Training loss: 2.179483602414425
Validation loss: 2.5383960075667646

Epoch: 6| Step: 7
Training loss: 2.838049572394078
Validation loss: 2.5298305731236628

Epoch: 6| Step: 8
Training loss: 2.621821249955368
Validation loss: 2.5189016865807075

Epoch: 6| Step: 9
Training loss: 2.691989254197415
Validation loss: 2.526453525334737

Epoch: 6| Step: 10
Training loss: 2.4069912251850183
Validation loss: 2.50776952579502

Epoch: 6| Step: 11
Training loss: 2.0728855482158672
Validation loss: 2.501063359647352

Epoch: 6| Step: 12
Training loss: 2.6718147672589905
Validation loss: 2.490941656448328

Epoch: 6| Step: 13
Training loss: 2.838013280750086
Validation loss: 2.4863721709284294

Epoch: 146| Step: 0
Training loss: 2.9369746610946628
Validation loss: 2.4754395647815017

Epoch: 6| Step: 1
Training loss: 2.7012371902126784
Validation loss: 2.478547422634873

Epoch: 6| Step: 2
Training loss: 2.9276775331686062
Validation loss: 2.4730897130916962

Epoch: 6| Step: 3
Training loss: 1.607648275012452
Validation loss: 2.4681427347510403

Epoch: 6| Step: 4
Training loss: 1.8163078035317721
Validation loss: 2.468074263210684

Epoch: 6| Step: 5
Training loss: 1.627855872464179
Validation loss: 2.4798774472437555

Epoch: 6| Step: 6
Training loss: 2.346714230655042
Validation loss: 2.4671658155015463

Epoch: 6| Step: 7
Training loss: 2.9331273750768636
Validation loss: 2.4913405254300516

Epoch: 6| Step: 8
Training loss: 2.559044345461042
Validation loss: 2.5010781824215256

Epoch: 6| Step: 9
Training loss: 2.0386708786028773
Validation loss: 2.5121800982594764

Epoch: 6| Step: 10
Training loss: 2.354883225576911
Validation loss: 2.5114245210424606

Epoch: 6| Step: 11
Training loss: 3.0018463810722626
Validation loss: 2.515155354774658

Epoch: 6| Step: 12
Training loss: 3.1906916776708476
Validation loss: 2.5212944966264974

Epoch: 6| Step: 13
Training loss: 2.276025825870189
Validation loss: 2.540252792244882

Epoch: 147| Step: 0
Training loss: 2.4571615648507996
Validation loss: 2.5348083579976994

Epoch: 6| Step: 1
Training loss: 2.618071358450616
Validation loss: 2.553389003345123

Epoch: 6| Step: 2
Training loss: 2.35104962709426
Validation loss: 2.5759431786815123

Epoch: 6| Step: 3
Training loss: 2.672649962711382
Validation loss: 2.595610794085359

Epoch: 6| Step: 4
Training loss: 2.361407585479373
Validation loss: 2.577221464680255

Epoch: 6| Step: 5
Training loss: 2.428144645856917
Validation loss: 2.6310684836366667

Epoch: 6| Step: 6
Training loss: 2.7477626368860526
Validation loss: 2.6606939638269598

Epoch: 6| Step: 7
Training loss: 2.7783388482466047
Validation loss: 2.641207580318946

Epoch: 6| Step: 8
Training loss: 2.025364962997386
Validation loss: 2.5898809891065415

Epoch: 6| Step: 9
Training loss: 1.4652269192869245
Validation loss: 2.532523013986021

Epoch: 6| Step: 10
Training loss: 2.6226549118443114
Validation loss: 2.503418194554377

Epoch: 6| Step: 11
Training loss: 2.7009250751541924
Validation loss: 2.4709410720519434

Epoch: 6| Step: 12
Training loss: 2.6989499522738747
Validation loss: 2.466946783542991

Epoch: 6| Step: 13
Training loss: 2.8700814674857025
Validation loss: 2.463936670753215

Epoch: 148| Step: 0
Training loss: 2.459728222387391
Validation loss: 2.457163611871599

Epoch: 6| Step: 1
Training loss: 3.0296228505201834
Validation loss: 2.4771936969038473

Epoch: 6| Step: 2
Training loss: 2.2605149091006584
Validation loss: 2.4757462467116365

Epoch: 6| Step: 3
Training loss: 2.697932377085854
Validation loss: 2.4688830725975097

Epoch: 6| Step: 4
Training loss: 2.7019848486237636
Validation loss: 2.4709750577263625

Epoch: 6| Step: 5
Training loss: 3.062213339332107
Validation loss: 2.4845394699997794

Epoch: 6| Step: 6
Training loss: 2.9802741990893744
Validation loss: 2.502603612813521

Epoch: 6| Step: 7
Training loss: 2.7900729018773913
Validation loss: 2.510423336463564

Epoch: 6| Step: 8
Training loss: 2.322482035621833
Validation loss: 2.522961801946049

Epoch: 6| Step: 9
Training loss: 2.0159650412283527
Validation loss: 2.541947038848445

Epoch: 6| Step: 10
Training loss: 2.00132314306499
Validation loss: 2.560551404462081

Epoch: 6| Step: 11
Training loss: 2.2970820742314837
Validation loss: 2.577374806767944

Epoch: 6| Step: 12
Training loss: 1.3793158422660616
Validation loss: 2.571964029931656

Epoch: 6| Step: 13
Training loss: 1.9857641449066346
Validation loss: 2.575378667537012

Epoch: 149| Step: 0
Training loss: 2.51573872753409
Validation loss: 2.5916692440820857

Epoch: 6| Step: 1
Training loss: 2.391154211970358
Validation loss: 2.587367929991065

Epoch: 6| Step: 2
Training loss: 2.996565760468394
Validation loss: 2.60296265232591

Epoch: 6| Step: 3
Training loss: 1.894775123237362
Validation loss: 2.569399195188304

Epoch: 6| Step: 4
Training loss: 2.5907148504378665
Validation loss: 2.544949747362215

Epoch: 6| Step: 5
Training loss: 1.8552945025089789
Validation loss: 2.537923694103159

Epoch: 6| Step: 6
Training loss: 2.203024354624313
Validation loss: 2.5485699221216813

Epoch: 6| Step: 7
Training loss: 2.844283169240744
Validation loss: 2.5439315960861335

Epoch: 6| Step: 8
Training loss: 2.6194256222820536
Validation loss: 2.5289394579545563

Epoch: 6| Step: 9
Training loss: 2.5278733890975182
Validation loss: 2.515628256999818

Epoch: 6| Step: 10
Training loss: 2.4585713955542055
Validation loss: 2.5149195420823784

Epoch: 6| Step: 11
Training loss: 2.5226223694955987
Validation loss: 2.4895654294034424

Epoch: 6| Step: 12
Training loss: 2.293481616708095
Validation loss: 2.4727945236446915

Epoch: 6| Step: 13
Training loss: 2.9999136912328312
Validation loss: 2.4660075885130426

Epoch: 150| Step: 0
Training loss: 1.959789289514476
Validation loss: 2.488530749510958

Epoch: 6| Step: 1
Training loss: 3.0375282317682353
Validation loss: 2.5188304952078036

Epoch: 6| Step: 2
Training loss: 1.9264770241344231
Validation loss: 2.4890587428593443

Epoch: 6| Step: 3
Training loss: 2.754822231033641
Validation loss: 2.4733881975515866

Epoch: 6| Step: 4
Training loss: 2.202713298882811
Validation loss: 2.4708900319679064

Epoch: 6| Step: 5
Training loss: 2.3713973980560143
Validation loss: 2.4454011030570975

Epoch: 6| Step: 6
Training loss: 2.7037284927112384
Validation loss: 2.465996603124733

Epoch: 6| Step: 7
Training loss: 2.782079508662017
Validation loss: 2.45938427400561

Epoch: 6| Step: 8
Training loss: 2.683749309623214
Validation loss: 2.482872820762731

Epoch: 6| Step: 9
Training loss: 2.2544554994835475
Validation loss: 2.5099793719908408

Epoch: 6| Step: 10
Training loss: 2.3953510517718204
Validation loss: 2.5363312177072137

Epoch: 6| Step: 11
Training loss: 2.1997709241726624
Validation loss: 2.582065282636496

Epoch: 6| Step: 12
Training loss: 2.4264848705286206
Validation loss: 2.5634498956546286

Epoch: 6| Step: 13
Training loss: 2.633709219973058
Validation loss: 2.563877120842934

Epoch: 151| Step: 0
Training loss: 2.947402981236409
Validation loss: 2.5785354193112244

Epoch: 6| Step: 1
Training loss: 3.017520921282233
Validation loss: 2.587698985592687

Epoch: 6| Step: 2
Training loss: 2.4016959953061563
Validation loss: 2.5605837432268816

Epoch: 6| Step: 3
Training loss: 2.6532755634913445
Validation loss: 2.529221542705609

Epoch: 6| Step: 4
Training loss: 2.513718160752955
Validation loss: 2.484908803175617

Epoch: 6| Step: 5
Training loss: 2.0583444983711083
Validation loss: 2.466557470612155

Epoch: 6| Step: 6
Training loss: 2.8237638621604257
Validation loss: 2.470199097361942

Epoch: 6| Step: 7
Training loss: 1.7928029235084049
Validation loss: 2.4470061595846313

Epoch: 6| Step: 8
Training loss: 1.3958812344810596
Validation loss: 2.457020013712659

Epoch: 6| Step: 9
Training loss: 2.2566793693662035
Validation loss: 2.454727845793711

Epoch: 6| Step: 10
Training loss: 2.1998353029505235
Validation loss: 2.4528213468754947

Epoch: 6| Step: 11
Training loss: 2.823019572466823
Validation loss: 2.474739120061441

Epoch: 6| Step: 12
Training loss: 2.2215274029195786
Validation loss: 2.481843176937184

Epoch: 6| Step: 13
Training loss: 3.0656141679516042
Validation loss: 2.47938062930807

Epoch: 152| Step: 0
Training loss: 2.6757152242937465
Validation loss: 2.499810430045864

Epoch: 6| Step: 1
Training loss: 2.396421995960008
Validation loss: 2.5347784727152622

Epoch: 6| Step: 2
Training loss: 2.0565099719969986
Validation loss: 2.5546579967946554

Epoch: 6| Step: 3
Training loss: 1.3644189323031062
Validation loss: 2.56711752202131

Epoch: 6| Step: 4
Training loss: 2.6365293985829714
Validation loss: 2.584682289707536

Epoch: 6| Step: 5
Training loss: 1.4541083669407198
Validation loss: 2.583918865016682

Epoch: 6| Step: 6
Training loss: 2.5724381118907518
Validation loss: 2.5848292096195573

Epoch: 6| Step: 7
Training loss: 2.8128429627588685
Validation loss: 2.5670396504503867

Epoch: 6| Step: 8
Training loss: 2.7359136993226962
Validation loss: 2.5418240652934663

Epoch: 6| Step: 9
Training loss: 2.685076485792929
Validation loss: 2.546318981466941

Epoch: 6| Step: 10
Training loss: 2.9865047185564535
Validation loss: 2.529263390202906

Epoch: 6| Step: 11
Training loss: 2.3619286063158236
Validation loss: 2.5400282993892813

Epoch: 6| Step: 12
Training loss: 2.400268948903246
Validation loss: 2.547612875350673

Epoch: 6| Step: 13
Training loss: 2.0544205989018858
Validation loss: 2.5489142230217117

Epoch: 153| Step: 0
Training loss: 1.9710754708173188
Validation loss: 2.516236630556307

Epoch: 6| Step: 1
Training loss: 1.9659120601765936
Validation loss: 2.489398922867132

Epoch: 6| Step: 2
Training loss: 2.765308771535054
Validation loss: 2.4651250679183843

Epoch: 6| Step: 3
Training loss: 2.5770547205807315
Validation loss: 2.455052003708378

Epoch: 6| Step: 4
Training loss: 2.193592415825597
Validation loss: 2.4405596429874907

Epoch: 6| Step: 5
Training loss: 2.428458635932584
Validation loss: 2.433209828925596

Epoch: 6| Step: 6
Training loss: 2.3891096111714702
Validation loss: 2.4388048682804015

Epoch: 6| Step: 7
Training loss: 2.6428558136041898
Validation loss: 2.416193372258954

Epoch: 6| Step: 8
Training loss: 2.389871715470571
Validation loss: 2.417693406574594

Epoch: 6| Step: 9
Training loss: 2.919883171513978
Validation loss: 2.433573742492617

Epoch: 6| Step: 10
Training loss: 1.9177402585542667
Validation loss: 2.4575002223931808

Epoch: 6| Step: 11
Training loss: 2.2706203769140116
Validation loss: 2.513335975874502

Epoch: 6| Step: 12
Training loss: 2.3199924029850716
Validation loss: 2.537743843640003

Epoch: 6| Step: 13
Training loss: 2.9568907932399147
Validation loss: 2.5901485371357893

Epoch: 154| Step: 0
Training loss: 2.1881795645052886
Validation loss: 2.581594313188995

Epoch: 6| Step: 1
Training loss: 2.56026146969062
Validation loss: 2.583739988676329

Epoch: 6| Step: 2
Training loss: 2.3195563217663397
Validation loss: 2.5648640248448586

Epoch: 6| Step: 3
Training loss: 1.8650247346194064
Validation loss: 2.5583743642213164

Epoch: 6| Step: 4
Training loss: 2.112207390197303
Validation loss: 2.5192875045875387

Epoch: 6| Step: 5
Training loss: 2.4876917166128716
Validation loss: 2.5021673037210097

Epoch: 6| Step: 6
Training loss: 2.1463279771275383
Validation loss: 2.512770943339804

Epoch: 6| Step: 7
Training loss: 1.9098181552103513
Validation loss: 2.5170597099000402

Epoch: 6| Step: 8
Training loss: 2.6612528642645277
Validation loss: 2.5326528648347613

Epoch: 6| Step: 9
Training loss: 3.1925072329206987
Validation loss: 2.525566178277833

Epoch: 6| Step: 10
Training loss: 2.465103063227825
Validation loss: 2.505466371058031

Epoch: 6| Step: 11
Training loss: 2.228601425618771
Validation loss: 2.4937632023313854

Epoch: 6| Step: 12
Training loss: 2.737755130392727
Validation loss: 2.457312678812748

Epoch: 6| Step: 13
Training loss: 1.687095310994286
Validation loss: 2.4634094724863864

Epoch: 155| Step: 0
Training loss: 2.621539514331496
Validation loss: 2.4515369940344196

Epoch: 6| Step: 1
Training loss: 2.086160597854121
Validation loss: 2.471432783873103

Epoch: 6| Step: 2
Training loss: 2.239758069222808
Validation loss: 2.4939062863964305

Epoch: 6| Step: 3
Training loss: 2.5575597639363106
Validation loss: 2.525000849849266

Epoch: 6| Step: 4
Training loss: 3.2192151372428524
Validation loss: 2.5460077859361085

Epoch: 6| Step: 5
Training loss: 1.9298928340747792
Validation loss: 2.5528061172024166

Epoch: 6| Step: 6
Training loss: 2.218352591156096
Validation loss: 2.5683356974724627

Epoch: 6| Step: 7
Training loss: 2.9637618069713216
Validation loss: 2.6453798264069897

Epoch: 6| Step: 8
Training loss: 2.3824124359979644
Validation loss: 2.631163287393341

Epoch: 6| Step: 9
Training loss: 2.2980566812734318
Validation loss: 2.6016464774145325

Epoch: 6| Step: 10
Training loss: 2.2461436390519234
Validation loss: 2.4952382402562803

Epoch: 6| Step: 11
Training loss: 2.323205550723893
Validation loss: 2.432697684294745

Epoch: 6| Step: 12
Training loss: 1.7627423140158485
Validation loss: 2.4303215836761605

Epoch: 6| Step: 13
Training loss: 1.5113093489611735
Validation loss: 2.4131101057104476

Epoch: 156| Step: 0
Training loss: 2.9624631468979516
Validation loss: 2.4271992168059926

Epoch: 6| Step: 1
Training loss: 1.9498417227650682
Validation loss: 2.4301264395110804

Epoch: 6| Step: 2
Training loss: 2.5263120735919125
Validation loss: 2.4309367999399103

Epoch: 6| Step: 3
Training loss: 2.507539823449774
Validation loss: 2.462014046985844

Epoch: 6| Step: 4
Training loss: 2.2818051015554275
Validation loss: 2.504141189467161

Epoch: 6| Step: 5
Training loss: 1.8649304526812824
Validation loss: 2.5346435663531994

Epoch: 6| Step: 6
Training loss: 2.4758763852052255
Validation loss: 2.5555684672804215

Epoch: 6| Step: 7
Training loss: 2.1490445475835953
Validation loss: 2.547254431316978

Epoch: 6| Step: 8
Training loss: 2.4284547088527755
Validation loss: 2.543034871315737

Epoch: 6| Step: 9
Training loss: 2.1177248114604494
Validation loss: 2.546293273638931

Epoch: 6| Step: 10
Training loss: 2.4054491766455097
Validation loss: 2.5262144248927023

Epoch: 6| Step: 11
Training loss: 2.0921620282651743
Validation loss: 2.5148743987517057

Epoch: 6| Step: 12
Training loss: 2.1775169366644316
Validation loss: 2.4848596842152606

Epoch: 6| Step: 13
Training loss: 2.3869778606409278
Validation loss: 2.492711066240888

Epoch: 157| Step: 0
Training loss: 2.0641121776762157
Validation loss: 2.4898172760242003

Epoch: 6| Step: 1
Training loss: 2.5661114620639696
Validation loss: 2.511724972007921

Epoch: 6| Step: 2
Training loss: 2.3499082912649927
Validation loss: 2.514151852466353

Epoch: 6| Step: 3
Training loss: 2.5791170003501898
Validation loss: 2.517108628272034

Epoch: 6| Step: 4
Training loss: 2.3474275347460227
Validation loss: 2.517138619459228

Epoch: 6| Step: 5
Training loss: 2.5074718398455462
Validation loss: 2.5145911449767744

Epoch: 6| Step: 6
Training loss: 2.1200781651248177
Validation loss: 2.4890082239051154

Epoch: 6| Step: 7
Training loss: 2.145856270775529
Validation loss: 2.47901655945513

Epoch: 6| Step: 8
Training loss: 1.9193454626127875
Validation loss: 2.4970840655910553

Epoch: 6| Step: 9
Training loss: 2.0920054441275426
Validation loss: 2.5026474644911407

Epoch: 6| Step: 10
Training loss: 2.395061490219229
Validation loss: 2.5101521588851616

Epoch: 6| Step: 11
Training loss: 2.2293115610347805
Validation loss: 2.5296785010410137

Epoch: 6| Step: 12
Training loss: 2.3033002395939133
Validation loss: 2.548631732738736

Epoch: 6| Step: 13
Training loss: 1.891224159321359
Validation loss: 2.5437858635654274

Epoch: 158| Step: 0
Training loss: 2.2594310410594476
Validation loss: 2.5071222516094913

Epoch: 6| Step: 1
Training loss: 1.8583868269926
Validation loss: 2.5086249785132306

Epoch: 6| Step: 2
Training loss: 2.289175922591257
Validation loss: 2.482616181464204

Epoch: 6| Step: 3
Training loss: 2.155797606846661
Validation loss: 2.460135472153456

Epoch: 6| Step: 4
Training loss: 2.29808199562419
Validation loss: 2.433440363509803

Epoch: 6| Step: 5
Training loss: 2.300971290498799
Validation loss: 2.453842864829882

Epoch: 6| Step: 6
Training loss: 2.558666897958437
Validation loss: 2.4362950413869933

Epoch: 6| Step: 7
Training loss: 2.064191875691407
Validation loss: 2.445213619118619

Epoch: 6| Step: 8
Training loss: 2.394555544457711
Validation loss: 2.4641721199250486

Epoch: 6| Step: 9
Training loss: 2.4760167817269645
Validation loss: 2.4810639922699815

Epoch: 6| Step: 10
Training loss: 2.439685721872551
Validation loss: 2.4939266677136667

Epoch: 6| Step: 11
Training loss: 2.341520546079492
Validation loss: 2.5182172839866603

Epoch: 6| Step: 12
Training loss: 2.010213403523083
Validation loss: 2.5082907593943045

Epoch: 6| Step: 13
Training loss: 1.0660907991433597
Validation loss: 2.5168113665131644

Epoch: 159| Step: 0
Training loss: 2.0155533179023393
Validation loss: 2.5152719533123875

Epoch: 6| Step: 1
Training loss: 1.0141442875729496
Validation loss: 2.5165978992826785

Epoch: 6| Step: 2
Training loss: 2.098889774941389
Validation loss: 2.5405507531982106

Epoch: 6| Step: 3
Training loss: 2.0503993087413157
Validation loss: 2.5447782623709125

Epoch: 6| Step: 4
Training loss: 2.903701813618628
Validation loss: 2.5697141803046764

Epoch: 6| Step: 5
Training loss: 2.0472531733710135
Validation loss: 2.556334334377665

Epoch: 6| Step: 6
Training loss: 2.5045906833491545
Validation loss: 2.569971654390985

Epoch: 6| Step: 7
Training loss: 2.3326243504191706
Validation loss: 2.5627783227254617

Epoch: 6| Step: 8
Training loss: 1.9969536707608624
Validation loss: 2.5446624436006204

Epoch: 6| Step: 9
Training loss: 2.128872428415401
Validation loss: 2.522058607309551

Epoch: 6| Step: 10
Training loss: 2.410365264089521
Validation loss: 2.5046767145157665

Epoch: 6| Step: 11
Training loss: 2.596626984175103
Validation loss: 2.447056167226661

Epoch: 6| Step: 12
Training loss: 2.274073141580824
Validation loss: 2.4364423358195304

Epoch: 6| Step: 13
Training loss: 1.887784416041616
Validation loss: 2.406973995307917

Epoch: 160| Step: 0
Training loss: 2.3456754786047735
Validation loss: 2.383264902608123

Epoch: 6| Step: 1
Training loss: 2.0783584578320324
Validation loss: 2.3917276508516494

Epoch: 6| Step: 2
Training loss: 2.473581728462355
Validation loss: 2.395673387136499

Epoch: 6| Step: 3
Training loss: 2.273346574675777
Validation loss: 2.397737057194695

Epoch: 6| Step: 4
Training loss: 2.1092122333035115
Validation loss: 2.4191856004116894

Epoch: 6| Step: 5
Training loss: 2.652900109347003
Validation loss: 2.4420056272398223

Epoch: 6| Step: 6
Training loss: 2.1807424528635737
Validation loss: 2.5004887605571384

Epoch: 6| Step: 7
Training loss: 2.364504058001935
Validation loss: 2.5922120436223275

Epoch: 6| Step: 8
Training loss: 2.0379972635087946
Validation loss: 2.725731589517489

Epoch: 6| Step: 9
Training loss: 2.1687516182225592
Validation loss: 2.792495775838254

Epoch: 6| Step: 10
Training loss: 2.7126122833779363
Validation loss: 2.8354603934357563

Epoch: 6| Step: 11
Training loss: 2.6622933249335694
Validation loss: 2.7414807404307475

Epoch: 6| Step: 12
Training loss: 1.6078885815769017
Validation loss: 2.6083255607958065

Epoch: 6| Step: 13
Training loss: 2.3755300833777016
Validation loss: 2.5249594119527945

Epoch: 161| Step: 0
Training loss: 1.8356516514091241
Validation loss: 2.4567446298344966

Epoch: 6| Step: 1
Training loss: 1.6406648176901788
Validation loss: 2.454515088250084

Epoch: 6| Step: 2
Training loss: 2.7732311763043778
Validation loss: 2.450648862724641

Epoch: 6| Step: 3
Training loss: 2.4550886131190053
Validation loss: 2.442024338972143

Epoch: 6| Step: 4
Training loss: 2.1731007362395722
Validation loss: 2.428724113971003

Epoch: 6| Step: 5
Training loss: 2.8143172433150654
Validation loss: 2.4366244354579107

Epoch: 6| Step: 6
Training loss: 2.352812780004539
Validation loss: 2.441932174115872

Epoch: 6| Step: 7
Training loss: 2.0005619928412437
Validation loss: 2.438551504270504

Epoch: 6| Step: 8
Training loss: 1.8927233692412433
Validation loss: 2.457663812674479

Epoch: 6| Step: 9
Training loss: 2.6245936124577836
Validation loss: 2.4750586077977967

Epoch: 6| Step: 10
Training loss: 2.321293889844318
Validation loss: 2.463523506875145

Epoch: 6| Step: 11
Training loss: 2.1919578905098316
Validation loss: 2.4719180010229755

Epoch: 6| Step: 12
Training loss: 2.4489377969464616
Validation loss: 2.4809714662737514

Epoch: 6| Step: 13
Training loss: 1.8904229048228811
Validation loss: 2.515426702319989

Epoch: 162| Step: 0
Training loss: 1.7563785383761552
Validation loss: 2.5345802170330103

Epoch: 6| Step: 1
Training loss: 1.7697998920838536
Validation loss: 2.520514812260234

Epoch: 6| Step: 2
Training loss: 1.818678683426293
Validation loss: 2.527386184450005

Epoch: 6| Step: 3
Training loss: 2.1909265112067415
Validation loss: 2.5328770083502867

Epoch: 6| Step: 4
Training loss: 1.6687513744334301
Validation loss: 2.541534708539024

Epoch: 6| Step: 5
Training loss: 2.287295860812264
Validation loss: 2.5791764746218764

Epoch: 6| Step: 6
Training loss: 2.2873924855464947
Validation loss: 2.55764406651316

Epoch: 6| Step: 7
Training loss: 2.668734483874775
Validation loss: 2.5494329201184174

Epoch: 6| Step: 8
Training loss: 1.923397174725476
Validation loss: 2.507185838670234

Epoch: 6| Step: 9
Training loss: 2.6911619211145097
Validation loss: 2.4992254903292945

Epoch: 6| Step: 10
Training loss: 2.5709904759222106
Validation loss: 2.478701400908821

Epoch: 6| Step: 11
Training loss: 2.573446293939181
Validation loss: 2.458161412883113

Epoch: 6| Step: 12
Training loss: 2.0556712533276844
Validation loss: 2.4555645682663005

Epoch: 6| Step: 13
Training loss: 2.380669202086246
Validation loss: 2.43595096472567

Epoch: 163| Step: 0
Training loss: 2.3551023081203644
Validation loss: 2.4663495477980284

Epoch: 6| Step: 1
Training loss: 1.8338663308988723
Validation loss: 2.488692191887972

Epoch: 6| Step: 2
Training loss: 1.9971341223187558
Validation loss: 2.5709236506362956

Epoch: 6| Step: 3
Training loss: 2.161838421474923
Validation loss: 2.556237825513665

Epoch: 6| Step: 4
Training loss: 2.246190979553158
Validation loss: 2.575128225990248

Epoch: 6| Step: 5
Training loss: 1.9661638743265495
Validation loss: 2.6195792663725643

Epoch: 6| Step: 6
Training loss: 1.7956386127214847
Validation loss: 2.6361740938919276

Epoch: 6| Step: 7
Training loss: 2.3421281416422457
Validation loss: 2.6407537650406523

Epoch: 6| Step: 8
Training loss: 2.6180031487582207
Validation loss: 2.6059585991196865

Epoch: 6| Step: 9
Training loss: 2.046682916611932
Validation loss: 2.54523606786738

Epoch: 6| Step: 10
Training loss: 2.415284375335338
Validation loss: 2.5081396555577995

Epoch: 6| Step: 11
Training loss: 1.8157139925395347
Validation loss: 2.4466060585079923

Epoch: 6| Step: 12
Training loss: 1.7629199616628226
Validation loss: 2.4376389953175543

Epoch: 6| Step: 13
Training loss: 2.3521954771281384
Validation loss: 2.4197214894724546

Epoch: 164| Step: 0
Training loss: 2.1808566987658216
Validation loss: 2.427906434621413

Epoch: 6| Step: 1
Training loss: 1.4117107329908853
Validation loss: 2.414414603654313

Epoch: 6| Step: 2
Training loss: 2.0520301721596623
Validation loss: 2.40562092474377

Epoch: 6| Step: 3
Training loss: 2.427765015142528
Validation loss: 2.419395602952727

Epoch: 6| Step: 4
Training loss: 1.869176340110715
Validation loss: 2.445163718480029

Epoch: 6| Step: 5
Training loss: 1.6324206160307495
Validation loss: 2.4801606281224426

Epoch: 6| Step: 6
Training loss: 2.710366752413162
Validation loss: 2.5222896676758917

Epoch: 6| Step: 7
Training loss: 2.3160895248464106
Validation loss: 2.5806713934495735

Epoch: 6| Step: 8
Training loss: 2.1440609275501856
Validation loss: 2.6171101675790016

Epoch: 6| Step: 9
Training loss: 2.366436326096168
Validation loss: 2.6083750418505898

Epoch: 6| Step: 10
Training loss: 2.183160455668642
Validation loss: 2.6033643435749587

Epoch: 6| Step: 11
Training loss: 2.2052636554201386
Validation loss: 2.5955404543003047

Epoch: 6| Step: 12
Training loss: 1.5974037325273729
Validation loss: 2.5580136784218737

Epoch: 6| Step: 13
Training loss: 1.5194381253848968
Validation loss: 2.5702033836526956

Epoch: 165| Step: 0
Training loss: 2.183654347570115
Validation loss: 2.5795732166385283

Epoch: 6| Step: 1
Training loss: 1.4434147928668903
Validation loss: 2.5560898529552567

Epoch: 6| Step: 2
Training loss: 1.8788007996087812
Validation loss: 2.5575764594832364

Epoch: 6| Step: 3
Training loss: 2.270971369849695
Validation loss: 2.5569891629889643

Epoch: 6| Step: 4
Training loss: 2.198650388299209
Validation loss: 2.5831227188578842

Epoch: 6| Step: 5
Training loss: 2.3850767290420594
Validation loss: 2.574309487990379

Epoch: 6| Step: 6
Training loss: 1.9583787980449747
Validation loss: 2.5334845579403478

Epoch: 6| Step: 7
Training loss: 1.983507342144912
Validation loss: 2.5037136577492625

Epoch: 6| Step: 8
Training loss: 2.2790310663011533
Validation loss: 2.43697364115583

Epoch: 6| Step: 9
Training loss: 2.3756454995988783
Validation loss: 2.4215051258076246

Epoch: 6| Step: 10
Training loss: 1.7371633985768589
Validation loss: 2.4217945838409594

Epoch: 6| Step: 11
Training loss: 2.236862292065779
Validation loss: 2.4089243170521306

Epoch: 6| Step: 12
Training loss: 1.6632333041725946
Validation loss: 2.4294194965043303

Epoch: 6| Step: 13
Training loss: 2.2194766077165418
Validation loss: 2.4465626965958704

Epoch: 166| Step: 0
Training loss: 1.8908985034689574
Validation loss: 2.4806510808541686

Epoch: 6| Step: 1
Training loss: 1.9088755177495975
Validation loss: 2.5224173581149807

Epoch: 6| Step: 2
Training loss: 2.486778008812267
Validation loss: 2.5591906666210744

Epoch: 6| Step: 3
Training loss: 2.3296575430486133
Validation loss: 2.5860375369920727

Epoch: 6| Step: 4
Training loss: 1.6517563084521871
Validation loss: 2.6137845127608776

Epoch: 6| Step: 5
Training loss: 1.8925341590207303
Validation loss: 2.5951549363788087

Epoch: 6| Step: 6
Training loss: 2.110874462527678
Validation loss: 2.6175850652126185

Epoch: 6| Step: 7
Training loss: 2.6717336516888066
Validation loss: 2.570006641749479

Epoch: 6| Step: 8
Training loss: 1.7794713961689086
Validation loss: 2.5444949260236287

Epoch: 6| Step: 9
Training loss: 2.1681730706787463
Validation loss: 2.5417538760222387

Epoch: 6| Step: 10
Training loss: 1.4183756767224942
Validation loss: 2.51054130458908

Epoch: 6| Step: 11
Training loss: 2.346265536436203
Validation loss: 2.512303897316753

Epoch: 6| Step: 12
Training loss: 1.6631045024057391
Validation loss: 2.4976200434811315

Epoch: 6| Step: 13
Training loss: 1.8421812334026884
Validation loss: 2.4876331107190417

Epoch: 167| Step: 0
Training loss: 1.9370456901246529
Validation loss: 2.471470584178487

Epoch: 6| Step: 1
Training loss: 1.6657322489436586
Validation loss: 2.4455114888646223

Epoch: 6| Step: 2
Training loss: 2.269474941480907
Validation loss: 2.444671693670698

Epoch: 6| Step: 3
Training loss: 2.2808248045258606
Validation loss: 2.448308960308497

Epoch: 6| Step: 4
Training loss: 2.083717336232747
Validation loss: 2.4509681451287624

Epoch: 6| Step: 5
Training loss: 2.4797999644360313
Validation loss: 2.464500594604211

Epoch: 6| Step: 6
Training loss: 1.3750869550086056
Validation loss: 2.4674199214114165

Epoch: 6| Step: 7
Training loss: 1.8053460839204905
Validation loss: 2.515086477190601

Epoch: 6| Step: 8
Training loss: 2.3659608388386246
Validation loss: 2.5561508749593003

Epoch: 6| Step: 9
Training loss: 2.0763092139135315
Validation loss: 2.5698288211447453

Epoch: 6| Step: 10
Training loss: 2.1842412381017726
Validation loss: 2.5838900150556525

Epoch: 6| Step: 11
Training loss: 1.5198188254649134
Validation loss: 2.5921026524375574

Epoch: 6| Step: 12
Training loss: 1.682847992957511
Validation loss: 2.581318926981575

Epoch: 6| Step: 13
Training loss: 2.350089692372362
Validation loss: 2.6080820600138352

Epoch: 168| Step: 0
Training loss: 2.3445683385806655
Validation loss: 2.637782839650356

Epoch: 6| Step: 1
Training loss: 1.6377030283155298
Validation loss: 2.628507438005414

Epoch: 6| Step: 2
Training loss: 2.5010798982946962
Validation loss: 2.6211030769588715

Epoch: 6| Step: 3
Training loss: 2.267500528589963
Validation loss: 2.6311270349742304

Epoch: 6| Step: 4
Training loss: 1.6831699908986373
Validation loss: 2.5916411050749932

Epoch: 6| Step: 5
Training loss: 1.62943725712824
Validation loss: 2.601291967494563

Epoch: 6| Step: 6
Training loss: 2.012368343619734
Validation loss: 2.6005968226087157

Epoch: 6| Step: 7
Training loss: 1.7511014197065768
Validation loss: 2.593590123724583

Epoch: 6| Step: 8
Training loss: 1.9723140608607923
Validation loss: 2.6006336819968614

Epoch: 6| Step: 9
Training loss: 2.1129635274097995
Validation loss: 2.598771462263501

Epoch: 6| Step: 10
Training loss: 2.225981733639635
Validation loss: 2.5624562871782666

Epoch: 6| Step: 11
Training loss: 1.631434173710366
Validation loss: 2.5308136082117785

Epoch: 6| Step: 12
Training loss: 2.02208225420264
Validation loss: 2.4898250189809983

Epoch: 6| Step: 13
Training loss: 1.9929605218410176
Validation loss: 2.4873121620543026

Epoch: 169| Step: 0
Training loss: 1.885718987044134
Validation loss: 2.452819978734056

Epoch: 6| Step: 1
Training loss: 2.0352211500718314
Validation loss: 2.45301460982841

Epoch: 6| Step: 2
Training loss: 2.0251832007907673
Validation loss: 2.459145635096812

Epoch: 6| Step: 3
Training loss: 1.6260180585451958
Validation loss: 2.4952695360926556

Epoch: 6| Step: 4
Training loss: 2.2570721425504425
Validation loss: 2.541908136359359

Epoch: 6| Step: 5
Training loss: 2.077957605489386
Validation loss: 2.583111414737288

Epoch: 6| Step: 6
Training loss: 1.9050511827376444
Validation loss: 2.603953536305368

Epoch: 6| Step: 7
Training loss: 1.523303529766418
Validation loss: 2.6548645170263723

Epoch: 6| Step: 8
Training loss: 2.2382046618182203
Validation loss: 2.6694748513533675

Epoch: 6| Step: 9
Training loss: 1.715964817655691
Validation loss: 2.6649443200511826

Epoch: 6| Step: 10
Training loss: 1.8359791852398635
Validation loss: 2.6246402482242175

Epoch: 6| Step: 11
Training loss: 2.360781723932346
Validation loss: 2.591566568095553

Epoch: 6| Step: 12
Training loss: 2.2420472423534212
Validation loss: 2.55178916362503

Epoch: 6| Step: 13
Training loss: 1.727005086245223
Validation loss: 2.5381266752554876

Epoch: 170| Step: 0
Training loss: 2.4133712618395755
Validation loss: 2.5038215060129234

Epoch: 6| Step: 1
Training loss: 2.1532524392293437
Validation loss: 2.4882396441391323

Epoch: 6| Step: 2
Training loss: 2.359255655061817
Validation loss: 2.474343816822542

Epoch: 6| Step: 3
Training loss: 2.2348284494670643
Validation loss: 2.468283242956554

Epoch: 6| Step: 4
Training loss: 2.2053747932076364
Validation loss: 2.4656450843666264

Epoch: 6| Step: 5
Training loss: 2.0853136822871363
Validation loss: 2.5118985930870066

Epoch: 6| Step: 6
Training loss: 1.5355520733046868
Validation loss: 2.525276919977659

Epoch: 6| Step: 7
Training loss: 1.6263429521037887
Validation loss: 2.5646289732377756

Epoch: 6| Step: 8
Training loss: 1.4841595141955835
Validation loss: 2.563063551798643

Epoch: 6| Step: 9
Training loss: 1.9176261269519026
Validation loss: 2.5799431687569885

Epoch: 6| Step: 10
Training loss: 1.7208783236973244
Validation loss: 2.556301240848472

Epoch: 6| Step: 11
Training loss: 1.3632401074866067
Validation loss: 2.543417436715518

Epoch: 6| Step: 12
Training loss: 2.075444952815359
Validation loss: 2.5451273873380926

Epoch: 6| Step: 13
Training loss: 1.7856843196534422
Validation loss: 2.5655645518367387

Epoch: 171| Step: 0
Training loss: 1.3930116810497155
Validation loss: 2.5618582451402094

Epoch: 6| Step: 1
Training loss: 1.958505223894201
Validation loss: 2.5763023737921165

Epoch: 6| Step: 2
Training loss: 1.865255593383894
Validation loss: 2.5925656740715417

Epoch: 6| Step: 3
Training loss: 1.7415708810607007
Validation loss: 2.5874860807463236

Epoch: 6| Step: 4
Training loss: 2.0188099146594016
Validation loss: 2.593655400306069

Epoch: 6| Step: 5
Training loss: 2.0240904001395323
Validation loss: 2.575119955038771

Epoch: 6| Step: 6
Training loss: 1.9701367898107471
Validation loss: 2.560098251354772

Epoch: 6| Step: 7
Training loss: 1.71846567749963
Validation loss: 2.5676383577410933

Epoch: 6| Step: 8
Training loss: 2.182259303712585
Validation loss: 2.524378176147441

Epoch: 6| Step: 9
Training loss: 2.530319796468403
Validation loss: 2.522267667727089

Epoch: 6| Step: 10
Training loss: 1.741107212299774
Validation loss: 2.534085897970107

Epoch: 6| Step: 11
Training loss: 2.222573438016825
Validation loss: 2.547573623650407

Epoch: 6| Step: 12
Training loss: 1.5642242073662729
Validation loss: 2.5544950065182226

Epoch: 6| Step: 13
Training loss: 1.6670132832904692
Validation loss: 2.5654972484619427

Epoch: 172| Step: 0
Training loss: 1.698248434905307
Validation loss: 2.5697981240584253

Epoch: 6| Step: 1
Training loss: 2.1620983478433793
Validation loss: 2.5754635375415202

Epoch: 6| Step: 2
Training loss: 1.9768719939728518
Validation loss: 2.5733961362962745

Epoch: 6| Step: 3
Training loss: 2.1432670382880685
Validation loss: 2.5690242709435074

Epoch: 6| Step: 4
Training loss: 2.140770454755393
Validation loss: 2.5531876648149647

Epoch: 6| Step: 5
Training loss: 1.6267057416214583
Validation loss: 2.553077882338048

Epoch: 6| Step: 6
Training loss: 1.9083934677288874
Validation loss: 2.585912942467686

Epoch: 6| Step: 7
Training loss: 1.8602989529757707
Validation loss: 2.5627872987289395

Epoch: 6| Step: 8
Training loss: 1.5304139638133094
Validation loss: 2.574357907032347

Epoch: 6| Step: 9
Training loss: 2.004818833078639
Validation loss: 2.5739766515173597

Epoch: 6| Step: 10
Training loss: 1.4301325204439952
Validation loss: 2.5874568296555225

Epoch: 6| Step: 11
Training loss: 1.3588264937219132
Validation loss: 2.5837453536087853

Epoch: 6| Step: 12
Training loss: 2.302838220430675
Validation loss: 2.5874936572629217

Epoch: 6| Step: 13
Training loss: 2.315075445408233
Validation loss: 2.566342128371484

Epoch: 173| Step: 0
Training loss: 2.0053760276791324
Validation loss: 2.5677230313034403

Epoch: 6| Step: 1
Training loss: 1.9503922532554414
Validation loss: 2.5390336457057296

Epoch: 6| Step: 2
Training loss: 2.1535612287282078
Validation loss: 2.514836946042995

Epoch: 6| Step: 3
Training loss: 2.0489435590693934
Validation loss: 2.519230242261812

Epoch: 6| Step: 4
Training loss: 1.6531453093523323
Validation loss: 2.459867328001158

Epoch: 6| Step: 5
Training loss: 2.269375977974284
Validation loss: 2.480605999081545

Epoch: 6| Step: 6
Training loss: 1.8047414003720303
Validation loss: 2.4920969187421127

Epoch: 6| Step: 7
Training loss: 1.709855665172191
Validation loss: 2.526916047770506

Epoch: 6| Step: 8
Training loss: 1.8810586318714486
Validation loss: 2.554495087808218

Epoch: 6| Step: 9
Training loss: 1.9752757592172219
Validation loss: 2.588166506537118

Epoch: 6| Step: 10
Training loss: 1.6134544445849646
Validation loss: 2.6179154518879586

Epoch: 6| Step: 11
Training loss: 1.8301618917178448
Validation loss: 2.632635758720989

Epoch: 6| Step: 12
Training loss: 1.8921893875024456
Validation loss: 2.6057461912821065

Epoch: 6| Step: 13
Training loss: 1.5257539792609793
Validation loss: 2.5665791876046824

Epoch: 174| Step: 0
Training loss: 1.942095198705187
Validation loss: 2.5521339724558003

Epoch: 6| Step: 1
Training loss: 1.6283670900737954
Validation loss: 2.5132451072070725

Epoch: 6| Step: 2
Training loss: 1.8093378171905041
Validation loss: 2.5150619576853477

Epoch: 6| Step: 3
Training loss: 1.9804190304024611
Validation loss: 2.5158257643491058

Epoch: 6| Step: 4
Training loss: 1.1591086747513055
Validation loss: 2.527229200612112

Epoch: 6| Step: 5
Training loss: 1.9509902884878556
Validation loss: 2.5385982571769614

Epoch: 6| Step: 6
Training loss: 1.9531170654135703
Validation loss: 2.549743340677689

Epoch: 6| Step: 7
Training loss: 1.5321717115690068
Validation loss: 2.5644865481893797

Epoch: 6| Step: 8
Training loss: 2.0407794140377478
Validation loss: 2.568909899571729

Epoch: 6| Step: 9
Training loss: 1.5783673846241681
Validation loss: 2.602283120167657

Epoch: 6| Step: 10
Training loss: 2.261750374212199
Validation loss: 2.637948204844818

Epoch: 6| Step: 11
Training loss: 2.3415356157043217
Validation loss: 2.624121859426334

Epoch: 6| Step: 12
Training loss: 1.7155112529353325
Validation loss: 2.595366656998713

Epoch: 6| Step: 13
Training loss: 2.420852149807085
Validation loss: 2.5559320372775876

Epoch: 175| Step: 0
Training loss: 2.167993713785046
Validation loss: 2.515038182048219

Epoch: 6| Step: 1
Training loss: 2.2145965815016577
Validation loss: 2.50190412958131

Epoch: 6| Step: 2
Training loss: 1.3578714408417005
Validation loss: 2.4853851355417733

Epoch: 6| Step: 3
Training loss: 2.4347791892006954
Validation loss: 2.4931800602410403

Epoch: 6| Step: 4
Training loss: 2.119450109709499
Validation loss: 2.4717856368441846

Epoch: 6| Step: 5
Training loss: 1.5796954961285707
Validation loss: 2.4760050393520325

Epoch: 6| Step: 6
Training loss: 1.392077555312849
Validation loss: 2.49466624768805

Epoch: 6| Step: 7
Training loss: 2.155614455173236
Validation loss: 2.531497185174998

Epoch: 6| Step: 8
Training loss: 2.4089069312562885
Validation loss: 2.5542205567451086

Epoch: 6| Step: 9
Training loss: 1.7940490393639468
Validation loss: 2.599005303161991

Epoch: 6| Step: 10
Training loss: 1.53900851237302
Validation loss: 2.6187492088469195

Epoch: 6| Step: 11
Training loss: 1.4730531678714032
Validation loss: 2.6128050054438487

Epoch: 6| Step: 12
Training loss: 1.468988034053547
Validation loss: 2.600509630051135

Epoch: 6| Step: 13
Training loss: 1.4158120475966691
Validation loss: 2.60635521722258

Epoch: 176| Step: 0
Training loss: 1.5413063848349502
Validation loss: 2.6234013112855883

Epoch: 6| Step: 1
Training loss: 1.9359204406232957
Validation loss: 2.5887465418300253

Epoch: 6| Step: 2
Training loss: 1.8934430015170503
Validation loss: 2.5580767390586274

Epoch: 6| Step: 3
Training loss: 2.0880714959075237
Validation loss: 2.5299697812628286

Epoch: 6| Step: 4
Training loss: 2.226756733235858
Validation loss: 2.4813656780264886

Epoch: 6| Step: 5
Training loss: 1.9655945937772066
Validation loss: 2.447962280630422

Epoch: 6| Step: 6
Training loss: 2.171786519176203
Validation loss: 2.4573114195855172

Epoch: 6| Step: 7
Training loss: 1.7973222922180323
Validation loss: 2.474152128771326

Epoch: 6| Step: 8
Training loss: 1.2449268390040662
Validation loss: 2.4822207853885514

Epoch: 6| Step: 9
Training loss: 2.137417136922953
Validation loss: 2.5428521874493626

Epoch: 6| Step: 10
Training loss: 1.544371997763951
Validation loss: 2.558765206803188

Epoch: 6| Step: 11
Training loss: 1.5220820730590336
Validation loss: 2.579339323573704

Epoch: 6| Step: 12
Training loss: 2.000857527000179
Validation loss: 2.607002356117371

Epoch: 6| Step: 13
Training loss: 1.4240434481175301
Validation loss: 2.611484326660531

Epoch: 177| Step: 0
Training loss: 1.5702398482639681
Validation loss: 2.619676976476345

Epoch: 6| Step: 1
Training loss: 1.8905307966991234
Validation loss: 2.5885497118433523

Epoch: 6| Step: 2
Training loss: 1.8298533168226998
Validation loss: 2.555875479590688

Epoch: 6| Step: 3
Training loss: 1.8263086277965817
Validation loss: 2.549117874776869

Epoch: 6| Step: 4
Training loss: 1.8089622962442855
Validation loss: 2.5115892877074852

Epoch: 6| Step: 5
Training loss: 1.9417425282711407
Validation loss: 2.497551516820775

Epoch: 6| Step: 6
Training loss: 2.1749636416849287
Validation loss: 2.462467296931415

Epoch: 6| Step: 7
Training loss: 1.6315024929559514
Validation loss: 2.4688537220721996

Epoch: 6| Step: 8
Training loss: 2.11288905426661
Validation loss: 2.4614946767552857

Epoch: 6| Step: 9
Training loss: 1.6339478264536949
Validation loss: 2.49217743237805

Epoch: 6| Step: 10
Training loss: 1.5845320915277863
Validation loss: 2.5008795185806916

Epoch: 6| Step: 11
Training loss: 1.4357976370057002
Validation loss: 2.5104552599480168

Epoch: 6| Step: 12
Training loss: 2.132546991722695
Validation loss: 2.5507923928691283

Epoch: 6| Step: 13
Training loss: 1.6785394337976092
Validation loss: 2.6057429298462638

Epoch: 178| Step: 0
Training loss: 1.9373087019464847
Validation loss: 2.6594772046800883

Epoch: 6| Step: 1
Training loss: 1.823521025247489
Validation loss: 2.710432143990574

Epoch: 6| Step: 2
Training loss: 2.1496997801070465
Validation loss: 2.7013013061589763

Epoch: 6| Step: 3
Training loss: 1.952847087161294
Validation loss: 2.6923508799078744

Epoch: 6| Step: 4
Training loss: 1.073683615820654
Validation loss: 2.622787744630155

Epoch: 6| Step: 5
Training loss: 2.121942115138002
Validation loss: 2.5957929144645258

Epoch: 6| Step: 6
Training loss: 2.293634945013336
Validation loss: 2.553950118758478

Epoch: 6| Step: 7
Training loss: 1.4228636270507733
Validation loss: 2.518157749953594

Epoch: 6| Step: 8
Training loss: 1.7679636497946556
Validation loss: 2.4758942548980296

Epoch: 6| Step: 9
Training loss: 2.0490416496441255
Validation loss: 2.459298295030432

Epoch: 6| Step: 10
Training loss: 1.7855433872733795
Validation loss: 2.4421438181489044

Epoch: 6| Step: 11
Training loss: 1.5901575926889076
Validation loss: 2.442595419812635

Epoch: 6| Step: 12
Training loss: 1.5088128442957855
Validation loss: 2.438450714393155

Epoch: 6| Step: 13
Training loss: 1.5747417783230355
Validation loss: 2.4325895682783196

Epoch: 179| Step: 0
Training loss: 1.921021931202857
Validation loss: 2.449401996200869

Epoch: 6| Step: 1
Training loss: 1.1411860927976538
Validation loss: 2.4651499156463133

Epoch: 6| Step: 2
Training loss: 1.444661504176172
Validation loss: 2.4869889227202178

Epoch: 6| Step: 3
Training loss: 1.8314013994665446
Validation loss: 2.4966503416744783

Epoch: 6| Step: 4
Training loss: 2.240217772524573
Validation loss: 2.5069228498145217

Epoch: 6| Step: 5
Training loss: 2.2920130959115035
Validation loss: 2.5151020755691644

Epoch: 6| Step: 6
Training loss: 1.8620824256132789
Validation loss: 2.517094583306872

Epoch: 6| Step: 7
Training loss: 2.1545832729788366
Validation loss: 2.5474499304484555

Epoch: 6| Step: 8
Training loss: 1.113142895048683
Validation loss: 2.520437723302925

Epoch: 6| Step: 9
Training loss: 1.7227706352197083
Validation loss: 2.5348633898288155

Epoch: 6| Step: 10
Training loss: 1.4443955270521005
Validation loss: 2.545517415242938

Epoch: 6| Step: 11
Training loss: 1.8405323076467126
Validation loss: 2.5459086562002335

Epoch: 6| Step: 12
Training loss: 1.8859165926882944
Validation loss: 2.563473993334286

Epoch: 6| Step: 13
Training loss: 1.7441722700402946
Validation loss: 2.5548806753582776

Epoch: 180| Step: 0
Training loss: 1.8488301264052658
Validation loss: 2.557827294550983

Epoch: 6| Step: 1
Training loss: 1.4670502587298788
Validation loss: 2.5486424273281894

Epoch: 6| Step: 2
Training loss: 1.2763996426601263
Validation loss: 2.561534320464662

Epoch: 6| Step: 3
Training loss: 1.8658114673968287
Validation loss: 2.566613538500111

Epoch: 6| Step: 4
Training loss: 2.151799127868198
Validation loss: 2.5699785313987

Epoch: 6| Step: 5
Training loss: 1.540325595322532
Validation loss: 2.599443325354713

Epoch: 6| Step: 6
Training loss: 2.3865268461554447
Validation loss: 2.5822012875740104

Epoch: 6| Step: 7
Training loss: 0.9013470185607467
Validation loss: 2.5562298775506784

Epoch: 6| Step: 8
Training loss: 1.8064233927675948
Validation loss: 2.5338513168873544

Epoch: 6| Step: 9
Training loss: 2.021267821281158
Validation loss: 2.5522308775739315

Epoch: 6| Step: 10
Training loss: 1.582011507641091
Validation loss: 2.544453261527433

Epoch: 6| Step: 11
Training loss: 1.777385602185812
Validation loss: 2.5106526657348307

Epoch: 6| Step: 12
Training loss: 2.1234515663337907
Validation loss: 2.5431920942044464

Epoch: 6| Step: 13
Training loss: 2.0220905077078783
Validation loss: 2.5150011170889828

Epoch: 181| Step: 0
Training loss: 2.1398842079708307
Validation loss: 2.540662881650793

Epoch: 6| Step: 1
Training loss: 1.9572875565070713
Validation loss: 2.5174314626317082

Epoch: 6| Step: 2
Training loss: 1.218622249852551
Validation loss: 2.5179827430921735

Epoch: 6| Step: 3
Training loss: 1.8441563821130333
Validation loss: 2.526376600338463

Epoch: 6| Step: 4
Training loss: 1.6241245846151453
Validation loss: 2.5487366166388283

Epoch: 6| Step: 5
Training loss: 1.5352170509936043
Validation loss: 2.5384478555993186

Epoch: 6| Step: 6
Training loss: 2.1194688955851717
Validation loss: 2.5853988244529296

Epoch: 6| Step: 7
Training loss: 1.6542779950682536
Validation loss: 2.5723736044451138

Epoch: 6| Step: 8
Training loss: 1.9637583470546551
Validation loss: 2.5550630771362606

Epoch: 6| Step: 9
Training loss: 1.6721099260644139
Validation loss: 2.5434246304529973

Epoch: 6| Step: 10
Training loss: 2.0533881775025695
Validation loss: 2.5424068767690544

Epoch: 6| Step: 11
Training loss: 1.6385926510525348
Validation loss: 2.5339944339019005

Epoch: 6| Step: 12
Training loss: 1.4504691022851746
Validation loss: 2.536836084130725

Epoch: 6| Step: 13
Training loss: 1.4196519345852716
Validation loss: 2.548891740526126

Epoch: 182| Step: 0
Training loss: 1.411254244004821
Validation loss: 2.5276726739142616

Epoch: 6| Step: 1
Training loss: 1.9991870062194763
Validation loss: 2.542683535309158

Epoch: 6| Step: 2
Training loss: 1.4241702659000446
Validation loss: 2.535077260133644

Epoch: 6| Step: 3
Training loss: 1.656418989665275
Validation loss: 2.538887768863032

Epoch: 6| Step: 4
Training loss: 1.9615306185224648
Validation loss: 2.499419383849593

Epoch: 6| Step: 5
Training loss: 2.1160077964408326
Validation loss: 2.495853600279433

Epoch: 6| Step: 6
Training loss: 2.0151631617214956
Validation loss: 2.546310239384738

Epoch: 6| Step: 7
Training loss: 1.4878198103553864
Validation loss: 2.5722821991850306

Epoch: 6| Step: 8
Training loss: 1.585385531881279
Validation loss: 2.6107826083720873

Epoch: 6| Step: 9
Training loss: 1.675559716153453
Validation loss: 2.639574257736894

Epoch: 6| Step: 10
Training loss: 1.6957188132543903
Validation loss: 2.680692712541167

Epoch: 6| Step: 11
Training loss: 2.1680072402973964
Validation loss: 2.6922366694201494

Epoch: 6| Step: 12
Training loss: 1.7145952813746903
Validation loss: 2.677218457765169

Epoch: 6| Step: 13
Training loss: 1.6398490887500934
Validation loss: 2.6457193175820812

Epoch: 183| Step: 0
Training loss: 1.8683015061910881
Validation loss: 2.6037948152588695

Epoch: 6| Step: 1
Training loss: 2.008905847814501
Validation loss: 2.5653707099794167

Epoch: 6| Step: 2
Training loss: 1.583343263226876
Validation loss: 2.5051782989253617

Epoch: 6| Step: 3
Training loss: 1.8810884805582226
Validation loss: 2.5028495402368787

Epoch: 6| Step: 4
Training loss: 1.6353326358791087
Validation loss: 2.4878785704251647

Epoch: 6| Step: 5
Training loss: 1.5182532106287385
Validation loss: 2.4508578607367495

Epoch: 6| Step: 6
Training loss: 1.4616648449482252
Validation loss: 2.4878322583684374

Epoch: 6| Step: 7
Training loss: 2.0556678898791567
Validation loss: 2.4939558203044094

Epoch: 6| Step: 8
Training loss: 1.780605668096552
Validation loss: 2.5010361800622394

Epoch: 6| Step: 9
Training loss: 1.6819705794502198
Validation loss: 2.5186867262235486

Epoch: 6| Step: 10
Training loss: 1.605805893000229
Validation loss: 2.5566915706005537

Epoch: 6| Step: 11
Training loss: 1.5410276153832874
Validation loss: 2.5880348328531433

Epoch: 6| Step: 12
Training loss: 1.951887669590883
Validation loss: 2.6195102307990483

Epoch: 6| Step: 13
Training loss: 1.1552145677724501
Validation loss: 2.6050167656889367

Epoch: 184| Step: 0
Training loss: 1.7736168321188466
Validation loss: 2.6760210052424394

Epoch: 6| Step: 1
Training loss: 1.1822447186305884
Validation loss: 2.652003809070235

Epoch: 6| Step: 2
Training loss: 1.4632059529041064
Validation loss: 2.618259679145134

Epoch: 6| Step: 3
Training loss: 2.0640701328456994
Validation loss: 2.609906708387418

Epoch: 6| Step: 4
Training loss: 1.2480611069036451
Validation loss: 2.5568530782997003

Epoch: 6| Step: 5
Training loss: 1.8550670951986072
Validation loss: 2.5433117115256048

Epoch: 6| Step: 6
Training loss: 1.8471551259920644
Validation loss: 2.5251625915555453

Epoch: 6| Step: 7
Training loss: 1.9919984615618729
Validation loss: 2.5116982027708454

Epoch: 6| Step: 8
Training loss: 1.836355737974759
Validation loss: 2.484536374485786

Epoch: 6| Step: 9
Training loss: 2.0138473360298375
Validation loss: 2.4747512745230837

Epoch: 6| Step: 10
Training loss: 1.7067409940766691
Validation loss: 2.4939564401530445

Epoch: 6| Step: 11
Training loss: 1.7627270978349572
Validation loss: 2.523463578836928

Epoch: 6| Step: 12
Training loss: 1.6276408524511392
Validation loss: 2.537385781647061

Epoch: 6| Step: 13
Training loss: 1.6530314428035593
Validation loss: 2.5603796387272046

Epoch: 185| Step: 0
Training loss: 1.4308416991895534
Validation loss: 2.5812386185129137

Epoch: 6| Step: 1
Training loss: 1.9077753936633202
Validation loss: 2.571488403032628

Epoch: 6| Step: 2
Training loss: 1.6785808377451517
Validation loss: 2.5462962789733363

Epoch: 6| Step: 3
Training loss: 1.3573225026154478
Validation loss: 2.53129245859681

Epoch: 6| Step: 4
Training loss: 1.4421839489794954
Validation loss: 2.531039105756067

Epoch: 6| Step: 5
Training loss: 2.043453939383115
Validation loss: 2.5060695177424095

Epoch: 6| Step: 6
Training loss: 1.321428718714172
Validation loss: 2.4836467331537397

Epoch: 6| Step: 7
Training loss: 1.7799182397302724
Validation loss: 2.466407201113903

Epoch: 6| Step: 8
Training loss: 2.1256526617927083
Validation loss: 2.4621632107222484

Epoch: 6| Step: 9
Training loss: 2.09177590296443
Validation loss: 2.4656177254207967

Epoch: 6| Step: 10
Training loss: 1.2766224635782633
Validation loss: 2.477863463187823

Epoch: 6| Step: 11
Training loss: 1.5804941504375334
Validation loss: 2.504970666582101

Epoch: 6| Step: 12
Training loss: 1.8090622626703303
Validation loss: 2.5479072176675968

Epoch: 6| Step: 13
Training loss: 1.311918038820366
Validation loss: 2.55332170032653

Epoch: 186| Step: 0
Training loss: 1.932696695027151
Validation loss: 2.5667055067003712

Epoch: 6| Step: 1
Training loss: 1.95341257648499
Validation loss: 2.5804520303358154

Epoch: 6| Step: 2
Training loss: 1.55578176049583
Validation loss: 2.6060016793826972

Epoch: 6| Step: 3
Training loss: 1.7213220944400898
Validation loss: 2.611275002604368

Epoch: 6| Step: 4
Training loss: 1.596089833348604
Validation loss: 2.6266860098454776

Epoch: 6| Step: 5
Training loss: 1.3921525259366525
Validation loss: 2.663524490240682

Epoch: 6| Step: 6
Training loss: 2.153492366638188
Validation loss: 2.6275212738579943

Epoch: 6| Step: 7
Training loss: 1.6918149106445635
Validation loss: 2.6155873666755913

Epoch: 6| Step: 8
Training loss: 1.703445684356987
Validation loss: 2.603372375113388

Epoch: 6| Step: 9
Training loss: 1.473035282968468
Validation loss: 2.5531453464169416

Epoch: 6| Step: 10
Training loss: 1.4228272655247902
Validation loss: 2.5425575069621944

Epoch: 6| Step: 11
Training loss: 1.18662405333104
Validation loss: 2.5194920461685273

Epoch: 6| Step: 12
Training loss: 1.7978617073697003
Validation loss: 2.528985267620221

Epoch: 6| Step: 13
Training loss: 1.2825362564375493
Validation loss: 2.5186844991708024

Epoch: 187| Step: 0
Training loss: 1.355284136861724
Validation loss: 2.539235601716706

Epoch: 6| Step: 1
Training loss: 1.5582092881768155
Validation loss: 2.5350495482254454

Epoch: 6| Step: 2
Training loss: 1.660576693083846
Validation loss: 2.5230218968030744

Epoch: 6| Step: 3
Training loss: 2.0723145215794045
Validation loss: 2.533724857317298

Epoch: 6| Step: 4
Training loss: 1.9599910442965127
Validation loss: 2.5339767746274293

Epoch: 6| Step: 5
Training loss: 1.9077243419027055
Validation loss: 2.529578671594839

Epoch: 6| Step: 6
Training loss: 1.6517705261239164
Validation loss: 2.5406870829513335

Epoch: 6| Step: 7
Training loss: 1.13009449023605
Validation loss: 2.510300461827437

Epoch: 6| Step: 8
Training loss: 1.66068853484316
Validation loss: 2.4980787401082316

Epoch: 6| Step: 9
Training loss: 1.945770332356647
Validation loss: 2.4821793934692673

Epoch: 6| Step: 10
Training loss: 1.5821888786248128
Validation loss: 2.4710766944826936

Epoch: 6| Step: 11
Training loss: 1.4722593870610254
Validation loss: 2.496739367454434

Epoch: 6| Step: 12
Training loss: 1.3122666469396713
Validation loss: 2.5296962795016418

Epoch: 6| Step: 13
Training loss: 1.3871705085004225
Validation loss: 2.562665407258245

Epoch: 188| Step: 0
Training loss: 1.983003758313902
Validation loss: 2.6047605530548794

Epoch: 6| Step: 1
Training loss: 2.0939337806323626
Validation loss: 2.6345653592982146

Epoch: 6| Step: 2
Training loss: 1.4817510602421746
Validation loss: 2.598454024614476

Epoch: 6| Step: 3
Training loss: 1.516909968944049
Validation loss: 2.6272395679116487

Epoch: 6| Step: 4
Training loss: 1.9441264263337439
Validation loss: 2.6033567354518237

Epoch: 6| Step: 5
Training loss: 1.7202891307494312
Validation loss: 2.5560670607231613

Epoch: 6| Step: 6
Training loss: 1.2509810412622304
Validation loss: 2.5470415090243224

Epoch: 6| Step: 7
Training loss: 1.6544428629227501
Validation loss: 2.513461547815998

Epoch: 6| Step: 8
Training loss: 1.252764886497001
Validation loss: 2.482586649943586

Epoch: 6| Step: 9
Training loss: 1.7669012807612683
Validation loss: 2.516026734803874

Epoch: 6| Step: 10
Training loss: 1.6001279034751748
Validation loss: 2.4895844118213177

Epoch: 6| Step: 11
Training loss: 1.4094009278612802
Validation loss: 2.5085458972109547

Epoch: 6| Step: 12
Training loss: 1.566861588276516
Validation loss: 2.531482589125191

Epoch: 6| Step: 13
Training loss: 1.2542895150243423
Validation loss: 2.5424528622385396

Epoch: 189| Step: 0
Training loss: 1.843246585202776
Validation loss: 2.539326869936161

Epoch: 6| Step: 1
Training loss: 1.045410840436488
Validation loss: 2.5608197928258414

Epoch: 6| Step: 2
Training loss: 1.1705125136132235
Validation loss: 2.588464804422432

Epoch: 6| Step: 3
Training loss: 1.3545163461171292
Validation loss: 2.581263295996787

Epoch: 6| Step: 4
Training loss: 2.1656275849650313
Validation loss: 2.5783629356410667

Epoch: 6| Step: 5
Training loss: 1.3187660776758245
Validation loss: 2.5846319493926875

Epoch: 6| Step: 6
Training loss: 1.2098621146399453
Validation loss: 2.6205814087570696

Epoch: 6| Step: 7
Training loss: 2.2010226127159647
Validation loss: 2.62171856527916

Epoch: 6| Step: 8
Training loss: 1.544723170025079
Validation loss: 2.6501453064953466

Epoch: 6| Step: 9
Training loss: 1.5736650955773055
Validation loss: 2.643957449428453

Epoch: 6| Step: 10
Training loss: 1.5816744931948217
Validation loss: 2.60585557934508

Epoch: 6| Step: 11
Training loss: 1.593380978814951
Validation loss: 2.593774814440064

Epoch: 6| Step: 12
Training loss: 1.6574086868656903
Validation loss: 2.573420892969407

Epoch: 6| Step: 13
Training loss: 1.4506958377081327
Validation loss: 2.5605244638566327

Epoch: 190| Step: 0
Training loss: 1.1854690953590188
Validation loss: 2.531508742051428

Epoch: 6| Step: 1
Training loss: 1.5926440272334241
Validation loss: 2.5312435302489646

Epoch: 6| Step: 2
Training loss: 1.4564271548984642
Validation loss: 2.56396911470632

Epoch: 6| Step: 3
Training loss: 1.8074472966827122
Validation loss: 2.587779594852042

Epoch: 6| Step: 4
Training loss: 1.6778929594360885
Validation loss: 2.58891683151586

Epoch: 6| Step: 5
Training loss: 1.3967459053619982
Validation loss: 2.626555402432508

Epoch: 6| Step: 6
Training loss: 1.2824820200829083
Validation loss: 2.6346231868116368

Epoch: 6| Step: 7
Training loss: 1.852863997144108
Validation loss: 2.6173811783172214

Epoch: 6| Step: 8
Training loss: 1.9085341979459012
Validation loss: 2.6244815396450347

Epoch: 6| Step: 9
Training loss: 1.4515736820705936
Validation loss: 2.62054170236441

Epoch: 6| Step: 10
Training loss: 2.1382812143199668
Validation loss: 2.6232795478057347

Epoch: 6| Step: 11
Training loss: 0.9712749309113929
Validation loss: 2.5785630874099246

Epoch: 6| Step: 12
Training loss: 1.2621950366632697
Validation loss: 2.5588272415277786

Epoch: 6| Step: 13
Training loss: 1.628878439979179
Validation loss: 2.553198872990602

Epoch: 191| Step: 0
Training loss: 1.8576811440040204
Validation loss: 2.5502838748864156

Epoch: 6| Step: 1
Training loss: 1.65259854852455
Validation loss: 2.555031865516851

Epoch: 6| Step: 2
Training loss: 1.211278166074383
Validation loss: 2.5404247885809927

Epoch: 6| Step: 3
Training loss: 1.514526677110483
Validation loss: 2.5530662795056154

Epoch: 6| Step: 4
Training loss: 1.2828251530235835
Validation loss: 2.541837863680544

Epoch: 6| Step: 5
Training loss: 1.749674698703959
Validation loss: 2.5486461410521035

Epoch: 6| Step: 6
Training loss: 1.3452208697120023
Validation loss: 2.522328618650771

Epoch: 6| Step: 7
Training loss: 0.9935518631052285
Validation loss: 2.5317207353459192

Epoch: 6| Step: 8
Training loss: 1.100664137708168
Validation loss: 2.545274837907232

Epoch: 6| Step: 9
Training loss: 1.9220025245102133
Validation loss: 2.52010122346564

Epoch: 6| Step: 10
Training loss: 1.8400246436085888
Validation loss: 2.548067315209407

Epoch: 6| Step: 11
Training loss: 1.5979672900971211
Validation loss: 2.5637665356588633

Epoch: 6| Step: 12
Training loss: 1.7078624246878806
Validation loss: 2.5673879689678563

Epoch: 6| Step: 13
Training loss: 1.311535389974273
Validation loss: 2.5468433387469873

Epoch: 192| Step: 0
Training loss: 1.329689988740235
Validation loss: 2.547533301624538

Epoch: 6| Step: 1
Training loss: 1.3157095041568307
Validation loss: 2.5372100236427046

Epoch: 6| Step: 2
Training loss: 1.6767415316396177
Validation loss: 2.553623352763661

Epoch: 6| Step: 3
Training loss: 1.0243518617727134
Validation loss: 2.540630539566667

Epoch: 6| Step: 4
Training loss: 1.8925125535878675
Validation loss: 2.5693768063812406

Epoch: 6| Step: 5
Training loss: 1.2009021487208302
Validation loss: 2.5586907370980834

Epoch: 6| Step: 6
Training loss: 1.2554002459482216
Validation loss: 2.5920793490502008

Epoch: 6| Step: 7
Training loss: 1.3455654566623065
Validation loss: 2.593643310819668

Epoch: 6| Step: 8
Training loss: 1.3449611085281867
Validation loss: 2.598535686374257

Epoch: 6| Step: 9
Training loss: 2.026236112101061
Validation loss: 2.5860901458421353

Epoch: 6| Step: 10
Training loss: 1.5173199801055768
Validation loss: 2.5920123444629364

Epoch: 6| Step: 11
Training loss: 1.8885498007423667
Validation loss: 2.5598594482594774

Epoch: 6| Step: 12
Training loss: 1.7121130680198449
Validation loss: 2.527966947695525

Epoch: 6| Step: 13
Training loss: 0.9160665404397292
Validation loss: 2.554714555845768

Epoch: 193| Step: 0
Training loss: 2.04422419468511
Validation loss: 2.549241842041405

Epoch: 6| Step: 1
Training loss: 1.565534239553851
Validation loss: 2.5297978083019808

Epoch: 6| Step: 2
Training loss: 1.6113190991697968
Validation loss: 2.5483579894865045

Epoch: 6| Step: 3
Training loss: 1.2599670722231386
Validation loss: 2.5377019076780107

Epoch: 6| Step: 4
Training loss: 1.3605627373891387
Validation loss: 2.532530207288662

Epoch: 6| Step: 5
Training loss: 1.121356574429651
Validation loss: 2.5096000970802823

Epoch: 6| Step: 6
Training loss: 1.2811354609209464
Validation loss: 2.500810008956148

Epoch: 6| Step: 7
Training loss: 1.5129484946137877
Validation loss: 2.498391219328694

Epoch: 6| Step: 8
Training loss: 2.033110250940777
Validation loss: 2.4971597329301045

Epoch: 6| Step: 9
Training loss: 1.7027773721074584
Validation loss: 2.4970492900209043

Epoch: 6| Step: 10
Training loss: 1.3917616581429386
Validation loss: 2.510049850249265

Epoch: 6| Step: 11
Training loss: 0.9810420028471004
Validation loss: 2.5314031483979864

Epoch: 6| Step: 12
Training loss: 1.3015362722037134
Validation loss: 2.5671966035488363

Epoch: 6| Step: 13
Training loss: 1.2947106742948622
Validation loss: 2.6126111125049123

Epoch: 194| Step: 0
Training loss: 1.6113786539189174
Validation loss: 2.604670838476207

Epoch: 6| Step: 1
Training loss: 1.3666991315257653
Validation loss: 2.634845588272363

Epoch: 6| Step: 2
Training loss: 1.1346099273968178
Validation loss: 2.606383066062621

Epoch: 6| Step: 3
Training loss: 1.8661768264886875
Validation loss: 2.5824911555543086

Epoch: 6| Step: 4
Training loss: 1.4816339180369882
Validation loss: 2.595135017164184

Epoch: 6| Step: 5
Training loss: 1.1541326570607011
Validation loss: 2.548574627780222

Epoch: 6| Step: 6
Training loss: 2.1236594964782896
Validation loss: 2.5114912013160264

Epoch: 6| Step: 7
Training loss: 1.4019311494505293
Validation loss: 2.4746178855438536

Epoch: 6| Step: 8
Training loss: 1.9685666437899634
Validation loss: 2.4692062962491286

Epoch: 6| Step: 9
Training loss: 1.014115958428464
Validation loss: 2.4668018249852297

Epoch: 6| Step: 10
Training loss: 1.264914419121474
Validation loss: 2.4881303477173478

Epoch: 6| Step: 11
Training loss: 1.2593272311330532
Validation loss: 2.5194271650259688

Epoch: 6| Step: 12
Training loss: 1.4406503075219999
Validation loss: 2.592021562431473

Epoch: 6| Step: 13
Training loss: 1.4782001758515981
Validation loss: 2.6132589251855007

Epoch: 195| Step: 0
Training loss: 1.8026564096637716
Validation loss: 2.6661732169669032

Epoch: 6| Step: 1
Training loss: 1.6899883855612468
Validation loss: 2.694281231830599

Epoch: 6| Step: 2
Training loss: 1.7437208467186276
Validation loss: 2.702877143565806

Epoch: 6| Step: 3
Training loss: 1.387730704707892
Validation loss: 2.703333135185337

Epoch: 6| Step: 4
Training loss: 1.3531785245180767
Validation loss: 2.6610951080767062

Epoch: 6| Step: 5
Training loss: 0.7596301274229363
Validation loss: 2.613858548578205

Epoch: 6| Step: 6
Training loss: 1.4126477830934998
Validation loss: 2.5741026942432756

Epoch: 6| Step: 7
Training loss: 1.6180066968593
Validation loss: 2.564768503648761

Epoch: 6| Step: 8
Training loss: 1.3088742994507514
Validation loss: 2.5017695906413713

Epoch: 6| Step: 9
Training loss: 0.9400893057848838
Validation loss: 2.512907251444348

Epoch: 6| Step: 10
Training loss: 2.030050657232217
Validation loss: 2.4899521735236627

Epoch: 6| Step: 11
Training loss: 1.5053909701341461
Validation loss: 2.485589206206011

Epoch: 6| Step: 12
Training loss: 1.641390739850603
Validation loss: 2.505014578651771

Epoch: 6| Step: 13
Training loss: 1.228174644418076
Validation loss: 2.5163715752526583

Epoch: 196| Step: 0
Training loss: 1.1427014928222958
Validation loss: 2.537255697120081

Epoch: 6| Step: 1
Training loss: 1.2567370063833965
Validation loss: 2.5362794770125743

Epoch: 6| Step: 2
Training loss: 1.6084672163876539
Validation loss: 2.5663271601009314

Epoch: 6| Step: 3
Training loss: 1.2733908334618118
Validation loss: 2.634913395046864

Epoch: 6| Step: 4
Training loss: 1.1821445872146399
Validation loss: 2.6765327597691932

Epoch: 6| Step: 5
Training loss: 1.4090925521505402
Validation loss: 2.7025301424159482

Epoch: 6| Step: 6
Training loss: 1.3705512383648184
Validation loss: 2.7255073732063746

Epoch: 6| Step: 7
Training loss: 1.7774045829003895
Validation loss: 2.710283395845789

Epoch: 6| Step: 8
Training loss: 1.428925357980752
Validation loss: 2.669690397929783

Epoch: 6| Step: 9
Training loss: 1.8776210267416202
Validation loss: 2.6197009023894386

Epoch: 6| Step: 10
Training loss: 1.7170661307181856
Validation loss: 2.6047411561019786

Epoch: 6| Step: 11
Training loss: 1.449215295175717
Validation loss: 2.5642904408973246

Epoch: 6| Step: 12
Training loss: 1.624374415950516
Validation loss: 2.5302677844157553

Epoch: 6| Step: 13
Training loss: 0.9813786270488551
Validation loss: 2.517032268140953

Epoch: 197| Step: 0
Training loss: 0.8646213607391628
Validation loss: 2.529786430578486

Epoch: 6| Step: 1
Training loss: 1.6412504911167778
Validation loss: 2.5188039745126476

Epoch: 6| Step: 2
Training loss: 1.2219009747878509
Validation loss: 2.4976274984557962

Epoch: 6| Step: 3
Training loss: 1.2198092918957766
Validation loss: 2.5107707017067606

Epoch: 6| Step: 4
Training loss: 1.1592575342765634
Validation loss: 2.5579687884995774

Epoch: 6| Step: 5
Training loss: 1.2696235505809663
Validation loss: 2.5524282564314715

Epoch: 6| Step: 6
Training loss: 1.363619699520825
Validation loss: 2.590546676975919

Epoch: 6| Step: 7
Training loss: 1.397388341738818
Validation loss: 2.6098567180761485

Epoch: 6| Step: 8
Training loss: 1.6176269229104878
Validation loss: 2.6177482649498343

Epoch: 6| Step: 9
Training loss: 1.8257688026509935
Validation loss: 2.6232808075006795

Epoch: 6| Step: 10
Training loss: 1.983963090091819
Validation loss: 2.6202837448601315

Epoch: 6| Step: 11
Training loss: 1.3190798450912022
Validation loss: 2.5984263680325017

Epoch: 6| Step: 12
Training loss: 1.6675922049175738
Validation loss: 2.60301522638748

Epoch: 6| Step: 13
Training loss: 1.0501348499716596
Validation loss: 2.5736151136627994

Epoch: 198| Step: 0
Training loss: 1.4874572875999101
Validation loss: 2.5323446912927143

Epoch: 6| Step: 1
Training loss: 1.5638428830158737
Validation loss: 2.489645579036999

Epoch: 6| Step: 2
Training loss: 1.8936589385948608
Validation loss: 2.482661665597237

Epoch: 6| Step: 3
Training loss: 0.7845997522560368
Validation loss: 2.504150877293274

Epoch: 6| Step: 4
Training loss: 1.8289951959529165
Validation loss: 2.4946190822754404

Epoch: 6| Step: 5
Training loss: 1.0924397386040954
Validation loss: 2.525338862166003

Epoch: 6| Step: 6
Training loss: 0.7279703999386226
Validation loss: 2.583644050055337

Epoch: 6| Step: 7
Training loss: 1.6192386905804697
Validation loss: 2.6020398711884836

Epoch: 6| Step: 8
Training loss: 1.346686946193726
Validation loss: 2.636502098622969

Epoch: 6| Step: 9
Training loss: 1.9481868726483291
Validation loss: 2.6642138547276573

Epoch: 6| Step: 10
Training loss: 0.869085554457029
Validation loss: 2.679738471208541

Epoch: 6| Step: 11
Training loss: 1.7644310349185208
Validation loss: 2.6882250247369246

Epoch: 6| Step: 12
Training loss: 1.3968433692303663
Validation loss: 2.6289678412590254

Epoch: 6| Step: 13
Training loss: 1.0544754945522181
Validation loss: 2.6124456449148172

Epoch: 199| Step: 0
Training loss: 1.6059146456809734
Validation loss: 2.5549092869644765

Epoch: 6| Step: 1
Training loss: 1.5586333688084049
Validation loss: 2.494418630627725

Epoch: 6| Step: 2
Training loss: 1.4222720084483225
Validation loss: 2.46713684720409

Epoch: 6| Step: 3
Training loss: 1.4802094486598358
Validation loss: 2.459424611088831

Epoch: 6| Step: 4
Training loss: 1.4514125454975864
Validation loss: 2.46300714972503

Epoch: 6| Step: 5
Training loss: 1.135371560183611
Validation loss: 2.4626451335334916

Epoch: 6| Step: 6
Training loss: 1.7477583833607166
Validation loss: 2.4604274603402443

Epoch: 6| Step: 7
Training loss: 1.267080341516634
Validation loss: 2.5044397467888757

Epoch: 6| Step: 8
Training loss: 1.6357847475806468
Validation loss: 2.5347879342179707

Epoch: 6| Step: 9
Training loss: 1.0219097236543233
Validation loss: 2.58379455429246

Epoch: 6| Step: 10
Training loss: 1.4576902152205744
Validation loss: 2.6107616889670267

Epoch: 6| Step: 11
Training loss: 1.5751333301361152
Validation loss: 2.662774882650997

Epoch: 6| Step: 12
Training loss: 1.2176316828080762
Validation loss: 2.7096184028501757

Epoch: 6| Step: 13
Training loss: 1.4298732616041494
Validation loss: 2.6603868278647926

Epoch: 200| Step: 0
Training loss: 2.1418599374250946
Validation loss: 2.665541218777565

Epoch: 6| Step: 1
Training loss: 1.5239371238513721
Validation loss: 2.6080987088476038

Epoch: 6| Step: 2
Training loss: 1.2413039994186672
Validation loss: 2.590043825212772

Epoch: 6| Step: 3
Training loss: 0.9656807361800682
Validation loss: 2.5147794580062364

Epoch: 6| Step: 4
Training loss: 1.356455419075695
Validation loss: 2.5029106137329435

Epoch: 6| Step: 5
Training loss: 1.4838089516167745
Validation loss: 2.4918074131404016

Epoch: 6| Step: 6
Training loss: 1.4893677117493154
Validation loss: 2.504114154879822

Epoch: 6| Step: 7
Training loss: 1.3560296912501366
Validation loss: 2.4858252611593303

Epoch: 6| Step: 8
Training loss: 1.1077878639914551
Validation loss: 2.5120439374570442

Epoch: 6| Step: 9
Training loss: 1.402761370601742
Validation loss: 2.4816528026422993

Epoch: 6| Step: 10
Training loss: 1.2257813803172484
Validation loss: 2.530740892567788

Epoch: 6| Step: 11
Training loss: 1.7044601806349116
Validation loss: 2.5230496747712223

Epoch: 6| Step: 12
Training loss: 1.2817510230021434
Validation loss: 2.559121633864532

Epoch: 6| Step: 13
Training loss: 0.9741613852980755
Validation loss: 2.5822569648681046

Testing loss: 2.5032216612606364
