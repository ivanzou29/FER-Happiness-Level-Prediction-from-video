Epoch: 1| Step: 0
Training loss: 5.43527597128547
Validation loss: 5.732346514741246

Epoch: 5| Step: 1
Training loss: 6.63746391904403
Validation loss: 5.705376241391969

Epoch: 5| Step: 2
Training loss: 5.4664811141615015
Validation loss: 5.679177232163598

Epoch: 5| Step: 3
Training loss: 5.07170962700443
Validation loss: 5.65123530880676

Epoch: 5| Step: 4
Training loss: 6.037257547821731
Validation loss: 5.622976944247308

Epoch: 5| Step: 5
Training loss: 6.307226414320633
Validation loss: 5.591790379470489

Epoch: 5| Step: 6
Training loss: 5.100163453418617
Validation loss: 5.555455066770199

Epoch: 5| Step: 7
Training loss: 6.1386249575641045
Validation loss: 5.514934775601459

Epoch: 5| Step: 8
Training loss: 5.366056764590332
Validation loss: 5.468162797145806

Epoch: 5| Step: 9
Training loss: 5.54988141319808
Validation loss: 5.4145334585224205

Epoch: 5| Step: 10
Training loss: 4.0898318577459625
Validation loss: 5.354044160829557

Epoch: 2| Step: 0
Training loss: 5.1874709530672085
Validation loss: 5.285219641703532

Epoch: 5| Step: 1
Training loss: 5.041921351701953
Validation loss: 5.206735867879219

Epoch: 5| Step: 2
Training loss: 4.198088510686106
Validation loss: 5.122511512918253

Epoch: 5| Step: 3
Training loss: 4.862953953281215
Validation loss: 5.027934178235233

Epoch: 5| Step: 4
Training loss: 5.836863657475393
Validation loss: 4.931377254874608

Epoch: 5| Step: 5
Training loss: 4.293330835930076
Validation loss: 4.829857841523954

Epoch: 5| Step: 6
Training loss: 5.908206030474492
Validation loss: 4.7281568709591

Epoch: 5| Step: 7
Training loss: 4.926207170820544
Validation loss: 4.6274905218662195

Epoch: 5| Step: 8
Training loss: 4.914976098748552
Validation loss: 4.529010984162039

Epoch: 5| Step: 9
Training loss: 4.096316865079026
Validation loss: 4.434743824559736

Epoch: 5| Step: 10
Training loss: 4.109204655006674
Validation loss: 4.336112633009675

Epoch: 3| Step: 0
Training loss: 4.2050311789791195
Validation loss: 4.249805450812261

Epoch: 5| Step: 1
Training loss: 3.318960834709995
Validation loss: 4.177303790892806

Epoch: 5| Step: 2
Training loss: 4.3286141349847576
Validation loss: 4.118453943805259

Epoch: 5| Step: 3
Training loss: 3.666394238032675
Validation loss: 4.0673630628687505

Epoch: 5| Step: 4
Training loss: 4.8161064605352095
Validation loss: 4.016258767181434

Epoch: 5| Step: 5
Training loss: 4.459603292159237
Validation loss: 3.972168168501562

Epoch: 5| Step: 6
Training loss: 4.130851525554008
Validation loss: 3.927631888983563

Epoch: 5| Step: 7
Training loss: 4.1646336491216704
Validation loss: 3.8787981486749703

Epoch: 5| Step: 8
Training loss: 3.6298343387350553
Validation loss: 3.83519361511932

Epoch: 5| Step: 9
Training loss: 3.4201664251691746
Validation loss: 3.7911466552715813

Epoch: 5| Step: 10
Training loss: 4.976294206366854
Validation loss: 3.755967025822821

Epoch: 4| Step: 0
Training loss: 3.9812605110640535
Validation loss: 3.721767643021395

Epoch: 5| Step: 1
Training loss: 4.096404634501508
Validation loss: 3.6886045742300535

Epoch: 5| Step: 2
Training loss: 3.866685746134898
Validation loss: 3.661512339325307

Epoch: 5| Step: 3
Training loss: 3.52918311201195
Validation loss: 3.6292560417243003

Epoch: 5| Step: 4
Training loss: 3.1356559653651233
Validation loss: 3.6063908339877937

Epoch: 5| Step: 5
Training loss: 3.582739773464268
Validation loss: 3.5747691321956623

Epoch: 5| Step: 6
Training loss: 3.9592226066858114
Validation loss: 3.552362236861911

Epoch: 5| Step: 7
Training loss: 4.195205204051592
Validation loss: 3.5189679199074493

Epoch: 5| Step: 8
Training loss: 3.4296460681402623
Validation loss: 3.4932408388302787

Epoch: 5| Step: 9
Training loss: 3.409764847464183
Validation loss: 3.469632032998142

Epoch: 5| Step: 10
Training loss: 4.209884936647268
Validation loss: 3.44607054250822

Epoch: 5| Step: 0
Training loss: 3.286452900458358
Validation loss: 3.425961138132816

Epoch: 5| Step: 1
Training loss: 3.1654882915535167
Validation loss: 3.412180978072907

Epoch: 5| Step: 2
Training loss: 3.5767043845921545
Validation loss: 3.401598675273995

Epoch: 5| Step: 3
Training loss: 3.895916018229057
Validation loss: 3.3868647646317642

Epoch: 5| Step: 4
Training loss: 2.653829571343607
Validation loss: 3.3748849129813587

Epoch: 5| Step: 5
Training loss: 3.988348920137837
Validation loss: 3.358922466868158

Epoch: 5| Step: 6
Training loss: 4.724235125602097
Validation loss: 3.3465758128846788

Epoch: 5| Step: 7
Training loss: 3.8596741100959573
Validation loss: 3.330904631640827

Epoch: 5| Step: 8
Training loss: 3.467453722985344
Validation loss: 3.3181010987876873

Epoch: 5| Step: 9
Training loss: 3.4691586640340732
Validation loss: 3.3028958243200783

Epoch: 5| Step: 10
Training loss: 2.835968942178919
Validation loss: 3.2925627706122

Epoch: 6| Step: 0
Training loss: 3.4260515478279108
Validation loss: 3.276302644507027

Epoch: 5| Step: 1
Training loss: 3.966162852073152
Validation loss: 3.268651592175865

Epoch: 5| Step: 2
Training loss: 2.4829688741366938
Validation loss: 3.251854986382536

Epoch: 5| Step: 3
Training loss: 3.771895889439294
Validation loss: 3.2435476321181596

Epoch: 5| Step: 4
Training loss: 4.138957828798131
Validation loss: 3.2327062689088066

Epoch: 5| Step: 5
Training loss: 3.0003971790609154
Validation loss: 3.217561989402767

Epoch: 5| Step: 6
Training loss: 3.808313040536673
Validation loss: 3.207311770986919

Epoch: 5| Step: 7
Training loss: 3.5934595405293472
Validation loss: 3.1956736921135103

Epoch: 5| Step: 8
Training loss: 2.913125877093789
Validation loss: 3.1871226773249997

Epoch: 5| Step: 9
Training loss: 3.1777999486646276
Validation loss: 3.1768764391500377

Epoch: 5| Step: 10
Training loss: 3.608299326277566
Validation loss: 3.1687193846715775

Epoch: 7| Step: 0
Training loss: 3.607668783002614
Validation loss: 3.156810870269977

Epoch: 5| Step: 1
Training loss: 3.301537710332351
Validation loss: 3.1509605831872585

Epoch: 5| Step: 2
Training loss: 3.8432222329651986
Validation loss: 3.143075749909297

Epoch: 5| Step: 3
Training loss: 3.1980480618566105
Validation loss: 3.1360542489367194

Epoch: 5| Step: 4
Training loss: 3.044784376405612
Validation loss: 3.1299760557682865

Epoch: 5| Step: 5
Training loss: 3.674623150869123
Validation loss: 3.1232436940121624

Epoch: 5| Step: 6
Training loss: 3.320022247193954
Validation loss: 3.115481444534332

Epoch: 5| Step: 7
Training loss: 3.126456722241228
Validation loss: 3.1099423456560475

Epoch: 5| Step: 8
Training loss: 3.5290269183729084
Validation loss: 3.1075236938804536

Epoch: 5| Step: 9
Training loss: 2.8378415612155834
Validation loss: 3.103898142429249

Epoch: 5| Step: 10
Training loss: 3.819194481887315
Validation loss: 3.0975036554542497

Epoch: 8| Step: 0
Training loss: 4.252703311821085
Validation loss: 3.0878261773660363

Epoch: 5| Step: 1
Training loss: 2.93524586650147
Validation loss: 3.0830470708601583

Epoch: 5| Step: 2
Training loss: 3.5225953578021945
Validation loss: 3.079208234225309

Epoch: 5| Step: 3
Training loss: 3.440647695468261
Validation loss: 3.0752495860566893

Epoch: 5| Step: 4
Training loss: 3.994109584995525
Validation loss: 3.066025931534767

Epoch: 5| Step: 5
Training loss: 3.3517336501591064
Validation loss: 3.061921357802567

Epoch: 5| Step: 6
Training loss: 2.548267288183794
Validation loss: 3.0570739399117404

Epoch: 5| Step: 7
Training loss: 3.1700349929755434
Validation loss: 3.0568582965164524

Epoch: 5| Step: 8
Training loss: 2.677377756357522
Validation loss: 3.052594779381084

Epoch: 5| Step: 9
Training loss: 3.444875676495985
Validation loss: 3.052100231125697

Epoch: 5| Step: 10
Training loss: 3.1116033649050263
Validation loss: 3.075598498203938

Epoch: 9| Step: 0
Training loss: 3.8521227941697687
Validation loss: 3.0466353766843586

Epoch: 5| Step: 1
Training loss: 2.9853774379398743
Validation loss: 3.035897943337812

Epoch: 5| Step: 2
Training loss: 3.57317826598845
Validation loss: 3.046513203442826

Epoch: 5| Step: 3
Training loss: 3.262205533006036
Validation loss: 3.056768445364355

Epoch: 5| Step: 4
Training loss: 3.571803476547001
Validation loss: 3.0598011610491964

Epoch: 5| Step: 5
Training loss: 3.2371693210292065
Validation loss: 3.0490367077282077

Epoch: 5| Step: 6
Training loss: 3.6322467322378498
Validation loss: 3.033683154684604

Epoch: 5| Step: 7
Training loss: 2.8951179846668773
Validation loss: 3.0310502844409872

Epoch: 5| Step: 8
Training loss: 2.7315117367962407
Validation loss: 3.0327362740226405

Epoch: 5| Step: 9
Training loss: 3.168324254193676
Validation loss: 3.0367087766414436

Epoch: 5| Step: 10
Training loss: 3.605493613639892
Validation loss: 3.033777142358129

Epoch: 10| Step: 0
Training loss: 3.298850963416354
Validation loss: 3.026312674323707

Epoch: 5| Step: 1
Training loss: 3.3292228786288756
Validation loss: 3.0167990019869895

Epoch: 5| Step: 2
Training loss: 2.4853565508299647
Validation loss: 3.0137827892847717

Epoch: 5| Step: 3
Training loss: 3.50116029307816
Validation loss: 3.011645040100467

Epoch: 5| Step: 4
Training loss: 3.480046478925734
Validation loss: 3.005281560752135

Epoch: 5| Step: 5
Training loss: 3.984918056205529
Validation loss: 3.0004519204235165

Epoch: 5| Step: 6
Training loss: 3.4013423738059148
Validation loss: 2.99672679099011

Epoch: 5| Step: 7
Training loss: 3.4793900895857903
Validation loss: 2.993922364206789

Epoch: 5| Step: 8
Training loss: 3.2754498762436692
Validation loss: 2.991829820043044

Epoch: 5| Step: 9
Training loss: 3.0521373201527706
Validation loss: 2.9972129235618277

Epoch: 5| Step: 10
Training loss: 2.7239012751733256
Validation loss: 2.992792058642963

Epoch: 11| Step: 0
Training loss: 3.2209835265862568
Validation loss: 2.9955495574983484

Epoch: 5| Step: 1
Training loss: 3.065701271220468
Validation loss: 2.9965258199597393

Epoch: 5| Step: 2
Training loss: 2.7765129123568166
Validation loss: 3.006441507206304

Epoch: 5| Step: 3
Training loss: 3.2344731855001867
Validation loss: 2.9937325787877103

Epoch: 5| Step: 4
Training loss: 4.13260504448893
Validation loss: 2.9787906885924533

Epoch: 5| Step: 5
Training loss: 3.1597298050301545
Validation loss: 2.9733031817555107

Epoch: 5| Step: 6
Training loss: 3.2942802740672943
Validation loss: 2.9744884269312606

Epoch: 5| Step: 7
Training loss: 3.3527390342341357
Validation loss: 2.976720689729962

Epoch: 5| Step: 8
Training loss: 3.754195854138469
Validation loss: 2.974222083209882

Epoch: 5| Step: 9
Training loss: 2.766805192244708
Validation loss: 2.9756265907102333

Epoch: 5| Step: 10
Training loss: 3.0532468242411666
Validation loss: 2.9745655948732894

Epoch: 12| Step: 0
Training loss: 3.0551020738496817
Validation loss: 2.9723659348445746

Epoch: 5| Step: 1
Training loss: 3.4869722684868445
Validation loss: 2.972533352685615

Epoch: 5| Step: 2
Training loss: 3.1322224886661325
Validation loss: 2.966903638264513

Epoch: 5| Step: 3
Training loss: 3.4958189105045907
Validation loss: 2.967601883556552

Epoch: 5| Step: 4
Training loss: 3.14239497626072
Validation loss: 2.9660085977145885

Epoch: 5| Step: 5
Training loss: 3.758725251756036
Validation loss: 2.958785906508823

Epoch: 5| Step: 6
Training loss: 3.0611337222052497
Validation loss: 2.9596510492525745

Epoch: 5| Step: 7
Training loss: 2.6614243317962196
Validation loss: 2.95582800981744

Epoch: 5| Step: 8
Training loss: 3.6508195766900027
Validation loss: 2.9560599447693527

Epoch: 5| Step: 9
Training loss: 3.397523533484867
Validation loss: 2.9564668300933366

Epoch: 5| Step: 10
Training loss: 2.8972311877019195
Validation loss: 2.9548364539146097

Epoch: 13| Step: 0
Training loss: 2.8011659919231207
Validation loss: 2.9543425804077947

Epoch: 5| Step: 1
Training loss: 2.6198078759199457
Validation loss: 2.953443779239102

Epoch: 5| Step: 2
Training loss: 2.8413407736432768
Validation loss: 2.9540355724156564

Epoch: 5| Step: 3
Training loss: 3.2556392455672714
Validation loss: 2.9522384751345876

Epoch: 5| Step: 4
Training loss: 3.296286435495487
Validation loss: 2.950589534083983

Epoch: 5| Step: 5
Training loss: 3.1749991829938664
Validation loss: 2.948176040176112

Epoch: 5| Step: 6
Training loss: 3.5659297027248575
Validation loss: 2.945987495574713

Epoch: 5| Step: 7
Training loss: 3.6939881998316677
Validation loss: 2.945229343844045

Epoch: 5| Step: 8
Training loss: 3.2384751725428234
Validation loss: 2.9424040524982686

Epoch: 5| Step: 9
Training loss: 3.119389647669367
Validation loss: 2.942090265543984

Epoch: 5| Step: 10
Training loss: 4.083941874928311
Validation loss: 2.941047751525347

Epoch: 14| Step: 0
Training loss: 3.611309903533668
Validation loss: 2.93892865511295

Epoch: 5| Step: 1
Training loss: 2.803660935421419
Validation loss: 2.9377165963028515

Epoch: 5| Step: 2
Training loss: 3.504371909814911
Validation loss: 2.9398197953663923

Epoch: 5| Step: 3
Training loss: 3.5340296515023404
Validation loss: 2.9390791551854103

Epoch: 5| Step: 4
Training loss: 3.0608936690287996
Validation loss: 2.9568771014570663

Epoch: 5| Step: 5
Training loss: 2.8220454674619195
Validation loss: 2.9989198753556083

Epoch: 5| Step: 6
Training loss: 2.3441132327581666
Validation loss: 3.0122528213386275

Epoch: 5| Step: 7
Training loss: 3.3135159931709266
Validation loss: 3.0399864490565385

Epoch: 5| Step: 8
Training loss: 3.8403726021478226
Validation loss: 3.018730498145414

Epoch: 5| Step: 9
Training loss: 3.35017988946087
Validation loss: 2.939438862715406

Epoch: 5| Step: 10
Training loss: 3.450912802643346
Validation loss: 2.937948123365577

Epoch: 15| Step: 0
Training loss: 2.9925273971132067
Validation loss: 2.9886133684871643

Epoch: 5| Step: 1
Training loss: 2.5210086246631964
Validation loss: 2.9982732551276516

Epoch: 5| Step: 2
Training loss: 3.4449241228979797
Validation loss: 2.99822869358277

Epoch: 5| Step: 3
Training loss: 3.5360212922124057
Validation loss: 2.9840618188912984

Epoch: 5| Step: 4
Training loss: 3.84696416681794
Validation loss: 2.957608491338639

Epoch: 5| Step: 5
Training loss: 2.4230757167193677
Validation loss: 2.9396583763194037

Epoch: 5| Step: 6
Training loss: 3.5416919632550554
Validation loss: 2.9338180604578254

Epoch: 5| Step: 7
Training loss: 3.5432286277604983
Validation loss: 2.933373314994256

Epoch: 5| Step: 8
Training loss: 3.476640404674888
Validation loss: 2.931380251337907

Epoch: 5| Step: 9
Training loss: 3.332285827714281
Validation loss: 2.9332599921114504

Epoch: 5| Step: 10
Training loss: 2.878697878207962
Validation loss: 2.930039865612522

Epoch: 16| Step: 0
Training loss: 3.2005865691935056
Validation loss: 2.9339967397913886

Epoch: 5| Step: 1
Training loss: 3.5634251781887207
Validation loss: 2.9355613954792292

Epoch: 5| Step: 2
Training loss: 3.187158454099144
Validation loss: 2.9412930256841583

Epoch: 5| Step: 3
Training loss: 3.1556149589815523
Validation loss: 2.9458482118624683

Epoch: 5| Step: 4
Training loss: 3.7054680602499093
Validation loss: 2.937013380264845

Epoch: 5| Step: 5
Training loss: 3.0465100192054417
Validation loss: 2.9229276413873366

Epoch: 5| Step: 6
Training loss: 2.888173811598502
Validation loss: 2.91622118880614

Epoch: 5| Step: 7
Training loss: 3.236636048737532
Validation loss: 2.9143397006866634

Epoch: 5| Step: 8
Training loss: 2.776040845993713
Validation loss: 2.9137842162640086

Epoch: 5| Step: 9
Training loss: 3.4781423343798865
Validation loss: 2.9189024281464877

Epoch: 5| Step: 10
Training loss: 3.2140010132423042
Validation loss: 2.912396904736227

Epoch: 17| Step: 0
Training loss: 3.342961013260795
Validation loss: 2.907628092886301

Epoch: 5| Step: 1
Training loss: 2.830816179264152
Validation loss: 2.908413352104093

Epoch: 5| Step: 2
Training loss: 2.5152493782857874
Validation loss: 2.9098578640970723

Epoch: 5| Step: 3
Training loss: 3.6390630293731503
Validation loss: 2.9123050561256076

Epoch: 5| Step: 4
Training loss: 3.339160229078776
Validation loss: 2.9149565580622783

Epoch: 5| Step: 5
Training loss: 3.1846758729342324
Validation loss: 2.91927032691707

Epoch: 5| Step: 6
Training loss: 3.7809818897877996
Validation loss: 2.9098391265204855

Epoch: 5| Step: 7
Training loss: 3.4092475230915773
Validation loss: 2.9035733719060604

Epoch: 5| Step: 8
Training loss: 2.5823565348891915
Validation loss: 2.901626168955878

Epoch: 5| Step: 9
Training loss: 3.467767387262393
Validation loss: 2.9006005106370005

Epoch: 5| Step: 10
Training loss: 3.0678068619056784
Validation loss: 2.9016761359190046

Epoch: 18| Step: 0
Training loss: 3.3493202373841875
Validation loss: 2.9106637308930616

Epoch: 5| Step: 1
Training loss: 3.7941673891326686
Validation loss: 2.928522351753319

Epoch: 5| Step: 2
Training loss: 3.4258031028824814
Validation loss: 2.9177838542970873

Epoch: 5| Step: 3
Training loss: 2.8077365803418672
Validation loss: 2.9008727407882633

Epoch: 5| Step: 4
Training loss: 3.4044361009431903
Validation loss: 2.8954464054947286

Epoch: 5| Step: 5
Training loss: 2.4487280833269787
Validation loss: 2.8923035346367967

Epoch: 5| Step: 6
Training loss: 3.559287647384478
Validation loss: 2.8898834501239685

Epoch: 5| Step: 7
Training loss: 3.223144790147789
Validation loss: 2.8882646754638963

Epoch: 5| Step: 8
Training loss: 2.718452349625621
Validation loss: 2.8887691341512682

Epoch: 5| Step: 9
Training loss: 2.728743503368855
Validation loss: 2.887804697459473

Epoch: 5| Step: 10
Training loss: 3.6189252003900365
Validation loss: 2.8885208502305626

Epoch: 19| Step: 0
Training loss: 3.31297485978536
Validation loss: 2.890025636837662

Epoch: 5| Step: 1
Training loss: 3.6424033606282697
Validation loss: 2.8944290738942935

Epoch: 5| Step: 2
Training loss: 2.8043093625662205
Validation loss: 2.890619258326155

Epoch: 5| Step: 3
Training loss: 3.3321813659124966
Validation loss: 2.8866662958957643

Epoch: 5| Step: 4
Training loss: 3.8443893273089236
Validation loss: 2.8854544929455574

Epoch: 5| Step: 5
Training loss: 2.6692148094190586
Validation loss: 2.8846907720819486

Epoch: 5| Step: 6
Training loss: 2.5212187564334334
Validation loss: 2.8860785749569087

Epoch: 5| Step: 7
Training loss: 2.652209720961218
Validation loss: 2.88359118578368

Epoch: 5| Step: 8
Training loss: 3.4356838630573328
Validation loss: 2.883897153745073

Epoch: 5| Step: 9
Training loss: 3.556269367078127
Validation loss: 2.881878349085606

Epoch: 5| Step: 10
Training loss: 3.0890623085897926
Validation loss: 2.8824025693665485

Epoch: 20| Step: 0
Training loss: 3.4880894590069853
Validation loss: 2.8810749466214336

Epoch: 5| Step: 1
Training loss: 2.9468329676424774
Validation loss: 2.8796470549289874

Epoch: 5| Step: 2
Training loss: 3.3637587222776872
Validation loss: 2.8813755471349114

Epoch: 5| Step: 3
Training loss: 3.371228689452395
Validation loss: 2.878502535324657

Epoch: 5| Step: 4
Training loss: 2.8745116772788557
Validation loss: 2.877534348526149

Epoch: 5| Step: 5
Training loss: 3.1354173594798254
Validation loss: 2.875429046525418

Epoch: 5| Step: 6
Training loss: 2.663757038223513
Validation loss: 2.8716776297874835

Epoch: 5| Step: 7
Training loss: 3.25196896111009
Validation loss: 2.8718883025224726

Epoch: 5| Step: 8
Training loss: 3.3076089701791194
Validation loss: 2.8793265240383428

Epoch: 5| Step: 9
Training loss: 3.1369888740417644
Validation loss: 2.888634359170805

Epoch: 5| Step: 10
Training loss: 3.4643504792621753
Validation loss: 2.8925154553035397

Epoch: 21| Step: 0
Training loss: 3.4588859453633662
Validation loss: 2.8842728929157504

Epoch: 5| Step: 1
Training loss: 3.4001373599859845
Validation loss: 2.8769453154264517

Epoch: 5| Step: 2
Training loss: 3.074976826402137
Validation loss: 2.8767038479929297

Epoch: 5| Step: 3
Training loss: 3.4323789424344997
Validation loss: 2.903354565751514

Epoch: 5| Step: 4
Training loss: 3.223921389925314
Validation loss: 2.893093290946977

Epoch: 5| Step: 5
Training loss: 2.7837333308021877
Validation loss: 2.8649227522216156

Epoch: 5| Step: 6
Training loss: 2.9138690792251216
Validation loss: 2.8631539283113696

Epoch: 5| Step: 7
Training loss: 3.3036345840367622
Validation loss: 2.8630811518428327

Epoch: 5| Step: 8
Training loss: 3.299767260580513
Validation loss: 2.8649374651038606

Epoch: 5| Step: 9
Training loss: 2.8279611107986358
Validation loss: 2.867754803842091

Epoch: 5| Step: 10
Training loss: 3.2176396204629336
Validation loss: 2.8666926256403373

Epoch: 22| Step: 0
Training loss: 3.3776079627343902
Validation loss: 2.8704876534895214

Epoch: 5| Step: 1
Training loss: 2.7658881800371096
Validation loss: 2.864146287678218

Epoch: 5| Step: 2
Training loss: 3.2524888705650343
Validation loss: 2.863954703674861

Epoch: 5| Step: 3
Training loss: 3.6812507564628096
Validation loss: 2.865406986676337

Epoch: 5| Step: 4
Training loss: 2.9071397957429204
Validation loss: 2.857262505990339

Epoch: 5| Step: 5
Training loss: 2.837390874033026
Validation loss: 2.8568728014625826

Epoch: 5| Step: 6
Training loss: 3.1026494117926955
Validation loss: 2.8507636141976884

Epoch: 5| Step: 7
Training loss: 3.371950537937627
Validation loss: 2.8430028342009104

Epoch: 5| Step: 8
Training loss: 2.922697879563099
Validation loss: 2.839806222848951

Epoch: 5| Step: 9
Training loss: 3.4459858969357207
Validation loss: 2.8358184736139975

Epoch: 5| Step: 10
Training loss: 3.027355563233
Validation loss: 2.833188375049942

Epoch: 23| Step: 0
Training loss: 2.9818456026833764
Validation loss: 2.834147360499977

Epoch: 5| Step: 1
Training loss: 3.22818196367373
Validation loss: 2.836435133593332

Epoch: 5| Step: 2
Training loss: 3.2000498827384174
Validation loss: 2.8320207538346582

Epoch: 5| Step: 3
Training loss: 3.101856899942705
Validation loss: 2.824913107816776

Epoch: 5| Step: 4
Training loss: 3.215234113982191
Validation loss: 2.819052310520431

Epoch: 5| Step: 5
Training loss: 3.23820173398303
Validation loss: 2.8186111515678447

Epoch: 5| Step: 6
Training loss: 3.6170318108621293
Validation loss: 2.8194178357328523

Epoch: 5| Step: 7
Training loss: 2.771254677155591
Validation loss: 2.8183677507834806

Epoch: 5| Step: 8
Training loss: 2.753800107384903
Validation loss: 2.829663027232878

Epoch: 5| Step: 9
Training loss: 2.976668708888852
Validation loss: 2.836481013180681

Epoch: 5| Step: 10
Training loss: 3.4896301873700732
Validation loss: 2.8443271637686633

Epoch: 24| Step: 0
Training loss: 3.3542438442915525
Validation loss: 2.8308823049726985

Epoch: 5| Step: 1
Training loss: 3.191683697634311
Validation loss: 2.8178116476922184

Epoch: 5| Step: 2
Training loss: 3.244671194290358
Validation loss: 2.8103797011900387

Epoch: 5| Step: 3
Training loss: 3.2495430845241473
Validation loss: 2.807646901505339

Epoch: 5| Step: 4
Training loss: 2.8310961212042165
Validation loss: 2.8074785222448555

Epoch: 5| Step: 5
Training loss: 2.182485882865282
Validation loss: 2.807346008701421

Epoch: 5| Step: 6
Training loss: 2.3263104427137207
Validation loss: 2.814786641852399

Epoch: 5| Step: 7
Training loss: 3.0499812016142323
Validation loss: 2.822334618840505

Epoch: 5| Step: 8
Training loss: 3.6364719786543227
Validation loss: 2.8303825429664777

Epoch: 5| Step: 9
Training loss: 3.6338225242429374
Validation loss: 2.8262066142679396

Epoch: 5| Step: 10
Training loss: 3.5859598395954473
Validation loss: 2.8165468213260985

Epoch: 25| Step: 0
Training loss: 3.0814900086188457
Validation loss: 2.8027523587152166

Epoch: 5| Step: 1
Training loss: 2.976829697037776
Validation loss: 2.7999520006914587

Epoch: 5| Step: 2
Training loss: 3.6540775202653935
Validation loss: 2.8030571130502073

Epoch: 5| Step: 3
Training loss: 3.5817679305307752
Validation loss: 2.810788290697916

Epoch: 5| Step: 4
Training loss: 2.758380950178672
Validation loss: 2.806159185988332

Epoch: 5| Step: 5
Training loss: 2.636753019887248
Validation loss: 2.8021832724414115

Epoch: 5| Step: 6
Training loss: 3.469735083017965
Validation loss: 2.801477653080097

Epoch: 5| Step: 7
Training loss: 3.2184947384845657
Validation loss: 2.799885574835953

Epoch: 5| Step: 8
Training loss: 2.468570557845179
Validation loss: 2.7980965692860065

Epoch: 5| Step: 9
Training loss: 3.5685393690492737
Validation loss: 2.7996852759772306

Epoch: 5| Step: 10
Training loss: 2.6126033890265994
Validation loss: 2.797499141049118

Epoch: 26| Step: 0
Training loss: 3.263693936705431
Validation loss: 2.799787575784024

Epoch: 5| Step: 1
Training loss: 3.211676667980966
Validation loss: 2.7966253504126795

Epoch: 5| Step: 2
Training loss: 2.932089347477214
Validation loss: 2.7957059564533577

Epoch: 5| Step: 3
Training loss: 3.6539630747632628
Validation loss: 2.7959304427270193

Epoch: 5| Step: 4
Training loss: 3.1298981997964193
Validation loss: 2.7924192427711523

Epoch: 5| Step: 5
Training loss: 2.728029484950274
Validation loss: 2.7898012509188503

Epoch: 5| Step: 6
Training loss: 3.478239533628456
Validation loss: 2.796689499696773

Epoch: 5| Step: 7
Training loss: 2.778080366396149
Validation loss: 2.790554569572245

Epoch: 5| Step: 8
Training loss: 3.258238547296884
Validation loss: 2.796288895495523

Epoch: 5| Step: 9
Training loss: 2.227772701708982
Validation loss: 2.795863960753304

Epoch: 5| Step: 10
Training loss: 3.434790497100539
Validation loss: 2.792358153622641

Epoch: 27| Step: 0
Training loss: 3.1592547023068356
Validation loss: 2.7870060459565913

Epoch: 5| Step: 1
Training loss: 3.280136791493709
Validation loss: 2.785491111838542

Epoch: 5| Step: 2
Training loss: 3.110452743154125
Validation loss: 2.7837254512614007

Epoch: 5| Step: 3
Training loss: 2.8140629134529993
Validation loss: 2.7824196627523845

Epoch: 5| Step: 4
Training loss: 3.229027053932323
Validation loss: 2.782271588973146

Epoch: 5| Step: 5
Training loss: 2.931895977490871
Validation loss: 2.78114627627669

Epoch: 5| Step: 6
Training loss: 2.5672260525316744
Validation loss: 2.781636199186616

Epoch: 5| Step: 7
Training loss: 3.042808283638087
Validation loss: 2.78168699899342

Epoch: 5| Step: 8
Training loss: 3.742710148702695
Validation loss: 2.780230110364195

Epoch: 5| Step: 9
Training loss: 3.298617368101019
Validation loss: 2.7792520696806737

Epoch: 5| Step: 10
Training loss: 2.9057756262401386
Validation loss: 2.7786632794513517

Epoch: 28| Step: 0
Training loss: 2.9720508094233424
Validation loss: 2.7773649100289144

Epoch: 5| Step: 1
Training loss: 3.0794555576720453
Validation loss: 2.7796584955788295

Epoch: 5| Step: 2
Training loss: 3.0653290429778712
Validation loss: 2.7865530000065553

Epoch: 5| Step: 3
Training loss: 3.098836859023917
Validation loss: 2.7959568342706094

Epoch: 5| Step: 4
Training loss: 3.0212350161728927
Validation loss: 2.786232952624695

Epoch: 5| Step: 5
Training loss: 3.1905177174016304
Validation loss: 2.77742777256648

Epoch: 5| Step: 6
Training loss: 2.807118586841247
Validation loss: 2.773821340479547

Epoch: 5| Step: 7
Training loss: 2.983401314442148
Validation loss: 2.772064039907987

Epoch: 5| Step: 8
Training loss: 3.3279269880392097
Validation loss: 2.7752758948426925

Epoch: 5| Step: 9
Training loss: 2.9208690523220975
Validation loss: 2.7724907490398514

Epoch: 5| Step: 10
Training loss: 3.700378687269618
Validation loss: 2.774160510136162

Epoch: 29| Step: 0
Training loss: 2.8929279123628246
Validation loss: 2.7694532510501246

Epoch: 5| Step: 1
Training loss: 2.8428507630221165
Validation loss: 2.7707279097987274

Epoch: 5| Step: 2
Training loss: 2.90170802756478
Validation loss: 2.7720018908583555

Epoch: 5| Step: 3
Training loss: 3.514549260331387
Validation loss: 2.7709167977387814

Epoch: 5| Step: 4
Training loss: 3.1941563536247513
Validation loss: 2.7698163021027336

Epoch: 5| Step: 5
Training loss: 2.719802126699374
Validation loss: 2.768779174248023

Epoch: 5| Step: 6
Training loss: 2.7419883894838004
Validation loss: 2.774677974969979

Epoch: 5| Step: 7
Training loss: 3.475898319192639
Validation loss: 2.784778262748861

Epoch: 5| Step: 8
Training loss: 3.5788076490848106
Validation loss: 2.786739234845921

Epoch: 5| Step: 9
Training loss: 3.0825572368817977
Validation loss: 2.7808610737070185

Epoch: 5| Step: 10
Training loss: 2.9753745604586346
Validation loss: 2.7782966425187454

Epoch: 30| Step: 0
Training loss: 2.8077913498970832
Validation loss: 2.769400742010677

Epoch: 5| Step: 1
Training loss: 3.0109726195571187
Validation loss: 2.76290505629734

Epoch: 5| Step: 2
Training loss: 3.220014305319907
Validation loss: 2.7667376249573636

Epoch: 5| Step: 3
Training loss: 2.727444918571958
Validation loss: 2.7639691337811523

Epoch: 5| Step: 4
Training loss: 3.3635613904090973
Validation loss: 2.764237346983173

Epoch: 5| Step: 5
Training loss: 3.1368953897376346
Validation loss: 2.764111413763285

Epoch: 5| Step: 6
Training loss: 3.0401425832639344
Validation loss: 2.7628735861855533

Epoch: 5| Step: 7
Training loss: 3.386233531507717
Validation loss: 2.7609272356779946

Epoch: 5| Step: 8
Training loss: 3.494324305628382
Validation loss: 2.7603025775410472

Epoch: 5| Step: 9
Training loss: 3.0150773732140417
Validation loss: 2.759978026917437

Epoch: 5| Step: 10
Training loss: 2.6488972942736666
Validation loss: 2.760485821951051

Epoch: 31| Step: 0
Training loss: 2.806586002888147
Validation loss: 2.7599987274738864

Epoch: 5| Step: 1
Training loss: 3.323827556897428
Validation loss: 2.7629934724399408

Epoch: 5| Step: 2
Training loss: 2.865641413551174
Validation loss: 2.7613258955559488

Epoch: 5| Step: 3
Training loss: 3.2547903703025574
Validation loss: 2.7579322697601425

Epoch: 5| Step: 4
Training loss: 2.8735960144495354
Validation loss: 2.757839233079231

Epoch: 5| Step: 5
Training loss: 2.9749770860831393
Validation loss: 2.755309215291181

Epoch: 5| Step: 6
Training loss: 3.510549993652643
Validation loss: 2.7569938187480254

Epoch: 5| Step: 7
Training loss: 2.411058155138469
Validation loss: 2.76000766862467

Epoch: 5| Step: 8
Training loss: 3.6209182120596557
Validation loss: 2.7595328948788604

Epoch: 5| Step: 9
Training loss: 3.1367593384963475
Validation loss: 2.7578051850302856

Epoch: 5| Step: 10
Training loss: 2.9836607073242534
Validation loss: 2.753249836945072

Epoch: 32| Step: 0
Training loss: 3.45376318648448
Validation loss: 2.751222808453496

Epoch: 5| Step: 1
Training loss: 3.0678164987109615
Validation loss: 2.751809292217161

Epoch: 5| Step: 2
Training loss: 2.8176534274822274
Validation loss: 2.749435448892469

Epoch: 5| Step: 3
Training loss: 2.897759947023095
Validation loss: 2.750523773683976

Epoch: 5| Step: 4
Training loss: 2.8989107717235023
Validation loss: 2.747816734963271

Epoch: 5| Step: 5
Training loss: 3.3884312437077666
Validation loss: 2.750323939331497

Epoch: 5| Step: 6
Training loss: 2.823817138819366
Validation loss: 2.7499505669708544

Epoch: 5| Step: 7
Training loss: 3.396296666526366
Validation loss: 2.747309800813849

Epoch: 5| Step: 8
Training loss: 3.017137375528343
Validation loss: 2.747428327371281

Epoch: 5| Step: 9
Training loss: 3.2291497671033764
Validation loss: 2.7476326157727473

Epoch: 5| Step: 10
Training loss: 2.754913362362736
Validation loss: 2.758093488354326

Epoch: 33| Step: 0
Training loss: 3.120201393865667
Validation loss: 2.7746231800674708

Epoch: 5| Step: 1
Training loss: 2.7208459601661827
Validation loss: 2.7870148139978856

Epoch: 5| Step: 2
Training loss: 2.9875551226650052
Validation loss: 2.8097352762442687

Epoch: 5| Step: 3
Training loss: 2.9600680642421535
Validation loss: 2.7822865527934026

Epoch: 5| Step: 4
Training loss: 2.540004895723686
Validation loss: 2.761457613268766

Epoch: 5| Step: 5
Training loss: 3.0115829021526346
Validation loss: 2.744492137707035

Epoch: 5| Step: 6
Training loss: 2.893066035403457
Validation loss: 2.7439821807927682

Epoch: 5| Step: 7
Training loss: 3.8474269740540508
Validation loss: 2.744106295808857

Epoch: 5| Step: 8
Training loss: 3.082064049453165
Validation loss: 2.7427626375566083

Epoch: 5| Step: 9
Training loss: 3.1914173065330202
Validation loss: 2.739520571260473

Epoch: 5| Step: 10
Training loss: 3.3563383350078055
Validation loss: 2.740513715686276

Epoch: 34| Step: 0
Training loss: 3.262378301579568
Validation loss: 2.742767980255754

Epoch: 5| Step: 1
Training loss: 2.7212693391322134
Validation loss: 2.738429113932436

Epoch: 5| Step: 2
Training loss: 3.0273917901934277
Validation loss: 2.736899756055669

Epoch: 5| Step: 3
Training loss: 3.4781090200490667
Validation loss: 2.738121627829996

Epoch: 5| Step: 4
Training loss: 3.080020998350622
Validation loss: 2.7355957072249946

Epoch: 5| Step: 5
Training loss: 3.486168233159458
Validation loss: 2.7337234977254043

Epoch: 5| Step: 6
Training loss: 3.1146661413575516
Validation loss: 2.7349422343465997

Epoch: 5| Step: 7
Training loss: 3.134234098726532
Validation loss: 2.7357214490626562

Epoch: 5| Step: 8
Training loss: 2.8774692049209762
Validation loss: 2.737548537233051

Epoch: 5| Step: 9
Training loss: 2.7299061906507736
Validation loss: 2.7359586006248025

Epoch: 5| Step: 10
Training loss: 2.663323532041897
Validation loss: 2.7439558910340653

Epoch: 35| Step: 0
Training loss: 2.8673656106867713
Validation loss: 2.750331167004966

Epoch: 5| Step: 1
Training loss: 2.615151413277571
Validation loss: 2.7435636206068312

Epoch: 5| Step: 2
Training loss: 3.30302383715453
Validation loss: 2.739345977419008

Epoch: 5| Step: 3
Training loss: 3.334395827395488
Validation loss: 2.7362037883344548

Epoch: 5| Step: 4
Training loss: 2.948157436571695
Validation loss: 2.733536214549805

Epoch: 5| Step: 5
Training loss: 2.891318902935842
Validation loss: 2.7352499878870606

Epoch: 5| Step: 6
Training loss: 3.0880263586451155
Validation loss: 2.7285107063289464

Epoch: 5| Step: 7
Training loss: 3.0802394362680983
Validation loss: 2.726622142939207

Epoch: 5| Step: 8
Training loss: 3.047751745601965
Validation loss: 2.7271759305017715

Epoch: 5| Step: 9
Training loss: 3.030443221808564
Validation loss: 2.7274698664043

Epoch: 5| Step: 10
Training loss: 3.4450315330623527
Validation loss: 2.725488071812209

Epoch: 36| Step: 0
Training loss: 2.9161824142270105
Validation loss: 2.7257908622061446

Epoch: 5| Step: 1
Training loss: 3.2699827477236263
Validation loss: 2.724963083550578

Epoch: 5| Step: 2
Training loss: 2.9727954806832413
Validation loss: 2.7231152428409637

Epoch: 5| Step: 3
Training loss: 3.424681048612995
Validation loss: 2.722511745166784

Epoch: 5| Step: 4
Training loss: 3.2038086696555794
Validation loss: 2.72362699552057

Epoch: 5| Step: 5
Training loss: 3.3438432626998127
Validation loss: 2.7238174574904974

Epoch: 5| Step: 6
Training loss: 2.716995023608433
Validation loss: 2.7368672375548244

Epoch: 5| Step: 7
Training loss: 3.431475127848015
Validation loss: 2.751521537011722

Epoch: 5| Step: 8
Training loss: 2.1610063808052162
Validation loss: 2.73746882441651

Epoch: 5| Step: 9
Training loss: 2.713602476604024
Validation loss: 2.724201417813239

Epoch: 5| Step: 10
Training loss: 3.2714684876013482
Validation loss: 2.7212130881766066

Epoch: 37| Step: 0
Training loss: 2.872863307251725
Validation loss: 2.7200904401730814

Epoch: 5| Step: 1
Training loss: 2.964645278580157
Validation loss: 2.71303363524311

Epoch: 5| Step: 2
Training loss: 3.3487128389752203
Validation loss: 2.7143469321001072

Epoch: 5| Step: 3
Training loss: 3.0739398524419217
Validation loss: 2.717683569051754

Epoch: 5| Step: 4
Training loss: 2.8331958138994664
Validation loss: 2.7168415062640885

Epoch: 5| Step: 5
Training loss: 2.7946001743415696
Validation loss: 2.715002551022737

Epoch: 5| Step: 6
Training loss: 2.875097521910874
Validation loss: 2.71182241262095

Epoch: 5| Step: 7
Training loss: 3.070434567885944
Validation loss: 2.7152832525372053

Epoch: 5| Step: 8
Training loss: 3.020961486904275
Validation loss: 2.7111816154489174

Epoch: 5| Step: 9
Training loss: 3.6463789758636054
Validation loss: 2.713447685536018

Epoch: 5| Step: 10
Training loss: 2.946113619134222
Validation loss: 2.7142644930409427

Epoch: 38| Step: 0
Training loss: 3.1486861743644425
Validation loss: 2.7201159813587785

Epoch: 5| Step: 1
Training loss: 3.4919836338966217
Validation loss: 2.7329376333706827

Epoch: 5| Step: 2
Training loss: 3.0080028919551016
Validation loss: 2.742610300823663

Epoch: 5| Step: 3
Training loss: 2.7261653053389283
Validation loss: 2.7206412472206365

Epoch: 5| Step: 4
Training loss: 2.842963812169386
Validation loss: 2.7160721281615388

Epoch: 5| Step: 5
Training loss: 3.659321595151643
Validation loss: 2.71064689459059

Epoch: 5| Step: 6
Training loss: 2.403285590908772
Validation loss: 2.7058920074568973

Epoch: 5| Step: 7
Training loss: 3.1287980459793845
Validation loss: 2.7043835168215327

Epoch: 5| Step: 8
Training loss: 2.5645102082731905
Validation loss: 2.703561759288508

Epoch: 5| Step: 9
Training loss: 3.048642159557072
Validation loss: 2.7055271184611773

Epoch: 5| Step: 10
Training loss: 3.3031461110518605
Validation loss: 2.7043407835078006

Epoch: 39| Step: 0
Training loss: 3.284300194785826
Validation loss: 2.70623069498063

Epoch: 5| Step: 1
Training loss: 3.0486332441920223
Validation loss: 2.7054773864326815

Epoch: 5| Step: 2
Training loss: 3.368692791794509
Validation loss: 2.7045830971688045

Epoch: 5| Step: 3
Training loss: 3.356075636101179
Validation loss: 2.704905567297672

Epoch: 5| Step: 4
Training loss: 2.686325437570226
Validation loss: 2.7087111923369718

Epoch: 5| Step: 5
Training loss: 3.0691450000764284
Validation loss: 2.7089419839776725

Epoch: 5| Step: 6
Training loss: 2.8820293572311826
Validation loss: 2.7282262868294778

Epoch: 5| Step: 7
Training loss: 2.648211174130667
Validation loss: 2.716857264516586

Epoch: 5| Step: 8
Training loss: 3.139814433549222
Validation loss: 2.7036933318064187

Epoch: 5| Step: 9
Training loss: 2.7925865498707982
Validation loss: 2.6981139398167358

Epoch: 5| Step: 10
Training loss: 3.116955282410055
Validation loss: 2.6978163683706713

Epoch: 40| Step: 0
Training loss: 3.5504099165964904
Validation loss: 2.6996433973580802

Epoch: 5| Step: 1
Training loss: 2.6978493955809637
Validation loss: 2.704521879054573

Epoch: 5| Step: 2
Training loss: 2.8242838365328184
Validation loss: 2.705593957345118

Epoch: 5| Step: 3
Training loss: 3.5063783564337143
Validation loss: 2.704634254175858

Epoch: 5| Step: 4
Training loss: 2.611711289934053
Validation loss: 2.7042618152994042

Epoch: 5| Step: 5
Training loss: 3.056242174009823
Validation loss: 2.7012714568154115

Epoch: 5| Step: 6
Training loss: 3.4798465605046096
Validation loss: 2.7071765044525176

Epoch: 5| Step: 7
Training loss: 3.1095130161344824
Validation loss: 2.7067729370533575

Epoch: 5| Step: 8
Training loss: 3.175691460235133
Validation loss: 2.702678487292858

Epoch: 5| Step: 9
Training loss: 2.6562899418240096
Validation loss: 2.7061647301076484

Epoch: 5| Step: 10
Training loss: 2.529412721315404
Validation loss: 2.704985075883238

Epoch: 41| Step: 0
Training loss: 2.8191420221186525
Validation loss: 2.707612150043508

Epoch: 5| Step: 1
Training loss: 2.43198328016833
Validation loss: 2.6999984357609805

Epoch: 5| Step: 2
Training loss: 3.2793847004692624
Validation loss: 2.693725832281199

Epoch: 5| Step: 3
Training loss: 3.4297183650198586
Validation loss: 2.6932245800053587

Epoch: 5| Step: 4
Training loss: 2.4742337900035265
Validation loss: 2.6936090394648864

Epoch: 5| Step: 5
Training loss: 3.120848530289676
Validation loss: 2.6920106013631013

Epoch: 5| Step: 6
Training loss: 2.6374398608831617
Validation loss: 2.686471874544868

Epoch: 5| Step: 7
Training loss: 3.1137667364760273
Validation loss: 2.6861441918052065

Epoch: 5| Step: 8
Training loss: 3.4295217695578337
Validation loss: 2.6893731991710514

Epoch: 5| Step: 9
Training loss: 3.3895139499933773
Validation loss: 2.688927633034979

Epoch: 5| Step: 10
Training loss: 2.9665777993196984
Validation loss: 2.689365797187223

Epoch: 42| Step: 0
Training loss: 3.374533444404904
Validation loss: 2.684524660545175

Epoch: 5| Step: 1
Training loss: 3.1151521773540582
Validation loss: 2.687968045205702

Epoch: 5| Step: 2
Training loss: 3.0126535273641974
Validation loss: 2.6886672871116577

Epoch: 5| Step: 3
Training loss: 2.775982529879298
Validation loss: 2.690494017163858

Epoch: 5| Step: 4
Training loss: 2.873981129435027
Validation loss: 2.6921211628020925

Epoch: 5| Step: 5
Training loss: 2.938750467564048
Validation loss: 2.689996790577708

Epoch: 5| Step: 6
Training loss: 3.183641978641591
Validation loss: 2.697099121288543

Epoch: 5| Step: 7
Training loss: 2.8323203314204823
Validation loss: 2.6951080144826496

Epoch: 5| Step: 8
Training loss: 2.7095240885228167
Validation loss: 2.7049337444880472

Epoch: 5| Step: 9
Training loss: 3.2978783115864396
Validation loss: 2.708096667251952

Epoch: 5| Step: 10
Training loss: 3.066836031784159
Validation loss: 2.7019788901592108

Epoch: 43| Step: 0
Training loss: 3.0367713273985033
Validation loss: 2.69664841178908

Epoch: 5| Step: 1
Training loss: 2.8741881841479184
Validation loss: 2.6973847491101495

Epoch: 5| Step: 2
Training loss: 2.728864250220295
Validation loss: 2.6947048677593717

Epoch: 5| Step: 3
Training loss: 2.4198331039193537
Validation loss: 2.6865224073766227

Epoch: 5| Step: 4
Training loss: 3.0319312205200757
Validation loss: 2.69690942834158

Epoch: 5| Step: 5
Training loss: 2.7400702755679953
Validation loss: 2.6870128078391065

Epoch: 5| Step: 6
Training loss: 3.0653097536967446
Validation loss: 2.687719940396756

Epoch: 5| Step: 7
Training loss: 3.4465941383015792
Validation loss: 2.6838585082519035

Epoch: 5| Step: 8
Training loss: 3.3713776257847607
Validation loss: 2.6832076047122824

Epoch: 5| Step: 9
Training loss: 3.08537067084551
Validation loss: 2.6747718415488855

Epoch: 5| Step: 10
Training loss: 3.2745040576284667
Validation loss: 2.6724180274097242

Epoch: 44| Step: 0
Training loss: 3.37111383566945
Validation loss: 2.6741938631687496

Epoch: 5| Step: 1
Training loss: 3.268043608039503
Validation loss: 2.675787452670804

Epoch: 5| Step: 2
Training loss: 3.2051450732838753
Validation loss: 2.675734514894638

Epoch: 5| Step: 3
Training loss: 2.481039050765493
Validation loss: 2.6731313004203523

Epoch: 5| Step: 4
Training loss: 2.7355820089914102
Validation loss: 2.6754688415596894

Epoch: 5| Step: 5
Training loss: 3.0308980835808716
Validation loss: 2.6741367331788815

Epoch: 5| Step: 6
Training loss: 2.733636636498438
Validation loss: 2.6731911994881004

Epoch: 5| Step: 7
Training loss: 2.9187937110388766
Validation loss: 2.672905191353348

Epoch: 5| Step: 8
Training loss: 2.895135278522374
Validation loss: 2.67492134056024

Epoch: 5| Step: 9
Training loss: 3.104817793655421
Validation loss: 2.6767386078090887

Epoch: 5| Step: 10
Training loss: 3.4264934151882755
Validation loss: 2.6776914624458716

Epoch: 45| Step: 0
Training loss: 3.104434588516866
Validation loss: 2.676658041805584

Epoch: 5| Step: 1
Training loss: 2.341651282028034
Validation loss: 2.6835873475629564

Epoch: 5| Step: 2
Training loss: 3.323235013215882
Validation loss: 2.6872252829221415

Epoch: 5| Step: 3
Training loss: 3.450652743523213
Validation loss: 2.6944680471020472

Epoch: 5| Step: 4
Training loss: 2.645101420976556
Validation loss: 2.6769340511500386

Epoch: 5| Step: 5
Training loss: 2.856623258346209
Validation loss: 2.6714209781484506

Epoch: 5| Step: 6
Training loss: 3.4751559380321537
Validation loss: 2.6697632290985065

Epoch: 5| Step: 7
Training loss: 3.238582656877426
Validation loss: 2.670072711318458

Epoch: 5| Step: 8
Training loss: 3.0835028593180924
Validation loss: 2.672361674875012

Epoch: 5| Step: 9
Training loss: 2.7219962547439045
Validation loss: 2.671273884045231

Epoch: 5| Step: 10
Training loss: 2.6928381135361423
Validation loss: 2.6762808418158777

Epoch: 46| Step: 0
Training loss: 2.8999787625817697
Validation loss: 2.676187978332189

Epoch: 5| Step: 1
Training loss: 2.7302123728439294
Validation loss: 2.681503245655136

Epoch: 5| Step: 2
Training loss: 2.9625584335036885
Validation loss: 2.6777558377208655

Epoch: 5| Step: 3
Training loss: 2.9042087072087046
Validation loss: 2.6743726183813665

Epoch: 5| Step: 4
Training loss: 2.783447511885597
Validation loss: 2.6750349007063354

Epoch: 5| Step: 5
Training loss: 3.3623753123936124
Validation loss: 2.6782815354649903

Epoch: 5| Step: 6
Training loss: 2.9190820411164458
Validation loss: 2.67971952704968

Epoch: 5| Step: 7
Training loss: 3.595136026878234
Validation loss: 2.676128627239599

Epoch: 5| Step: 8
Training loss: 2.924582140166365
Validation loss: 2.6756114690582

Epoch: 5| Step: 9
Training loss: 3.1743407038011204
Validation loss: 2.6797792778991525

Epoch: 5| Step: 10
Training loss: 2.6018715981271767
Validation loss: 2.6789080331843964

Epoch: 47| Step: 0
Training loss: 2.374886459848991
Validation loss: 2.69005634555343

Epoch: 5| Step: 1
Training loss: 2.7573983635246573
Validation loss: 2.7196474839375195

Epoch: 5| Step: 2
Training loss: 3.6853275688676517
Validation loss: 2.7104183119614644

Epoch: 5| Step: 3
Training loss: 2.8086231214236985
Validation loss: 2.682213713654838

Epoch: 5| Step: 4
Training loss: 3.099557992741257
Validation loss: 2.665938789167663

Epoch: 5| Step: 5
Training loss: 2.9375186676081544
Validation loss: 2.664630037823804

Epoch: 5| Step: 6
Training loss: 3.330574960645901
Validation loss: 2.660720558864245

Epoch: 5| Step: 7
Training loss: 3.010901195424047
Validation loss: 2.6585790982744166

Epoch: 5| Step: 8
Training loss: 3.3353409602293866
Validation loss: 2.661789603397187

Epoch: 5| Step: 9
Training loss: 2.3188666260377735
Validation loss: 2.6596557460514685

Epoch: 5| Step: 10
Training loss: 3.2066541628947385
Validation loss: 2.662777202926466

Epoch: 48| Step: 0
Training loss: 2.788870326668956
Validation loss: 2.6885224572540563

Epoch: 5| Step: 1
Training loss: 3.0237456566352447
Validation loss: 2.7124486233423055

Epoch: 5| Step: 2
Training loss: 2.7371214234718586
Validation loss: 2.710317157427851

Epoch: 5| Step: 3
Training loss: 3.4009990290276146
Validation loss: 2.689968003278161

Epoch: 5| Step: 4
Training loss: 3.238850174314977
Validation loss: 2.657229146181189

Epoch: 5| Step: 5
Training loss: 2.7969516338739617
Validation loss: 2.656874581436658

Epoch: 5| Step: 6
Training loss: 2.8737481750509035
Validation loss: 2.6586636043941994

Epoch: 5| Step: 7
Training loss: 2.980410194071742
Validation loss: 2.6645223968605647

Epoch: 5| Step: 8
Training loss: 2.6866331254870577
Validation loss: 2.667398494300698

Epoch: 5| Step: 9
Training loss: 3.3012242849403584
Validation loss: 2.677563103638201

Epoch: 5| Step: 10
Training loss: 3.2695884198257423
Validation loss: 2.6706959021881316

Epoch: 49| Step: 0
Training loss: 2.7772561017892348
Validation loss: 2.676980686785508

Epoch: 5| Step: 1
Training loss: 2.17304719537146
Validation loss: 2.674806221962497

Epoch: 5| Step: 2
Training loss: 3.1505422821719007
Validation loss: 2.6907150600493868

Epoch: 5| Step: 3
Training loss: 3.3376967639999187
Validation loss: 2.6852852962478466

Epoch: 5| Step: 4
Training loss: 3.170390265475972
Validation loss: 2.662742314820095

Epoch: 5| Step: 5
Training loss: 2.591362095279256
Validation loss: 2.660132394016035

Epoch: 5| Step: 6
Training loss: 3.101569572075533
Validation loss: 2.655829714026681

Epoch: 5| Step: 7
Training loss: 3.4226979002152227
Validation loss: 2.6612029541381284

Epoch: 5| Step: 8
Training loss: 3.163987448473315
Validation loss: 2.661425553208206

Epoch: 5| Step: 9
Training loss: 3.1446659035610653
Validation loss: 2.654592361874318

Epoch: 5| Step: 10
Training loss: 2.7764925611421396
Validation loss: 2.653420082467852

Epoch: 50| Step: 0
Training loss: 3.0851984998254482
Validation loss: 2.6512488212052356

Epoch: 5| Step: 1
Training loss: 3.036925204172758
Validation loss: 2.6541044909255564

Epoch: 5| Step: 2
Training loss: 3.3574255676426756
Validation loss: 2.660299058583138

Epoch: 5| Step: 3
Training loss: 2.219065361714099
Validation loss: 2.675411472409388

Epoch: 5| Step: 4
Training loss: 2.6493224519385525
Validation loss: 2.6918961202547282

Epoch: 5| Step: 5
Training loss: 3.019334162390723
Validation loss: 2.684596721617587

Epoch: 5| Step: 6
Training loss: 2.679548521302635
Validation loss: 2.672344952976869

Epoch: 5| Step: 7
Training loss: 3.3504749303055466
Validation loss: 2.6680596607482703

Epoch: 5| Step: 8
Training loss: 2.8531518138949994
Validation loss: 2.6555540520703578

Epoch: 5| Step: 9
Training loss: 3.2215284188873348
Validation loss: 2.6477017564200094

Epoch: 5| Step: 10
Training loss: 3.301847495593228
Validation loss: 2.6433107576982655

Epoch: 51| Step: 0
Training loss: 2.7708350638094976
Validation loss: 2.6423980930719613

Epoch: 5| Step: 1
Training loss: 3.1818177681464386
Validation loss: 2.642798812282051

Epoch: 5| Step: 2
Training loss: 3.0712854916016603
Validation loss: 2.6401566193614396

Epoch: 5| Step: 3
Training loss: 3.0293055324566005
Validation loss: 2.6408579559100396

Epoch: 5| Step: 4
Training loss: 2.2037765946192684
Validation loss: 2.6387563550907185

Epoch: 5| Step: 5
Training loss: 3.0004230836717465
Validation loss: 2.6387702100959567

Epoch: 5| Step: 6
Training loss: 2.84281067478188
Validation loss: 2.639064739746079

Epoch: 5| Step: 7
Training loss: 3.386063702691023
Validation loss: 2.6411181438002105

Epoch: 5| Step: 8
Training loss: 2.8476773484943707
Validation loss: 2.643994250709561

Epoch: 5| Step: 9
Training loss: 3.042489989866843
Validation loss: 2.6404214930949537

Epoch: 5| Step: 10
Training loss: 3.341972092316199
Validation loss: 2.6415093034594777

Epoch: 52| Step: 0
Training loss: 3.1714866663547117
Validation loss: 2.6418333512694283

Epoch: 5| Step: 1
Training loss: 2.7333343269377353
Validation loss: 2.637721423121824

Epoch: 5| Step: 2
Training loss: 2.6945737849213285
Validation loss: 2.644464916174596

Epoch: 5| Step: 3
Training loss: 3.1272372057774462
Validation loss: 2.6529780098647104

Epoch: 5| Step: 4
Training loss: 2.9676047274356367
Validation loss: 2.654261643620659

Epoch: 5| Step: 5
Training loss: 2.497741632848628
Validation loss: 2.6518208763408593

Epoch: 5| Step: 6
Training loss: 3.0787105100254255
Validation loss: 2.6484428877840287

Epoch: 5| Step: 7
Training loss: 3.2970482658669185
Validation loss: 2.641672838004

Epoch: 5| Step: 8
Training loss: 3.1705551032075734
Validation loss: 2.63125130853057

Epoch: 5| Step: 9
Training loss: 2.5118307560319906
Validation loss: 2.6306210001147194

Epoch: 5| Step: 10
Training loss: 3.4652113176562818
Validation loss: 2.629890883441401

Epoch: 53| Step: 0
Training loss: 2.8921822966740574
Validation loss: 2.6287087445212283

Epoch: 5| Step: 1
Training loss: 3.0227130347207947
Validation loss: 2.6298546324912957

Epoch: 5| Step: 2
Training loss: 2.7800889752921165
Validation loss: 2.6304369336211413

Epoch: 5| Step: 3
Training loss: 3.307611565124761
Validation loss: 2.6295302277285852

Epoch: 5| Step: 4
Training loss: 3.068660378944087
Validation loss: 2.6305657958450097

Epoch: 5| Step: 5
Training loss: 3.04765145605317
Validation loss: 2.6287021791494096

Epoch: 5| Step: 6
Training loss: 2.855499142173247
Validation loss: 2.6358822961612334

Epoch: 5| Step: 7
Training loss: 2.3235183301563405
Validation loss: 2.6447701469478733

Epoch: 5| Step: 8
Training loss: 2.98033739752948
Validation loss: 2.661462289705176

Epoch: 5| Step: 9
Training loss: 3.255817781490471
Validation loss: 2.6856785110623824

Epoch: 5| Step: 10
Training loss: 3.197250711060207
Validation loss: 2.650935234339471

Epoch: 54| Step: 0
Training loss: 2.6114378672831133
Validation loss: 2.6380939541332604

Epoch: 5| Step: 1
Training loss: 2.8867669830628784
Validation loss: 2.6295090109454513

Epoch: 5| Step: 2
Training loss: 2.91898484520737
Validation loss: 2.6262412547398797

Epoch: 5| Step: 3
Training loss: 2.8011575656196097
Validation loss: 2.628790326577952

Epoch: 5| Step: 4
Training loss: 2.6410722523071453
Validation loss: 2.6325774658900873

Epoch: 5| Step: 5
Training loss: 3.150629156344895
Validation loss: 2.6361839033332073

Epoch: 5| Step: 6
Training loss: 3.0879542460634437
Validation loss: 2.633233492266854

Epoch: 5| Step: 7
Training loss: 3.344743242431037
Validation loss: 2.6406375530109836

Epoch: 5| Step: 8
Training loss: 2.7334378625684814
Validation loss: 2.6320574611863705

Epoch: 5| Step: 9
Training loss: 3.4878965637723827
Validation loss: 2.632716504346685

Epoch: 5| Step: 10
Training loss: 2.89112478523562
Validation loss: 2.628951106639347

Epoch: 55| Step: 0
Training loss: 2.4758872667017315
Validation loss: 2.6256555128453702

Epoch: 5| Step: 1
Training loss: 2.8491577041483525
Validation loss: 2.6259143348348406

Epoch: 5| Step: 2
Training loss: 2.741113610029617
Validation loss: 2.628070612612625

Epoch: 5| Step: 3
Training loss: 3.0617640642578365
Validation loss: 2.624750612818509

Epoch: 5| Step: 4
Training loss: 3.0561752403804583
Validation loss: 2.624168658909165

Epoch: 5| Step: 5
Training loss: 3.0038806929077793
Validation loss: 2.6243745651561063

Epoch: 5| Step: 6
Training loss: 3.2370432292136373
Validation loss: 2.620475876550547

Epoch: 5| Step: 7
Training loss: 2.804521561073018
Validation loss: 2.6222440723328977

Epoch: 5| Step: 8
Training loss: 3.226149710419609
Validation loss: 2.6273753664184247

Epoch: 5| Step: 9
Training loss: 2.970663638482642
Validation loss: 2.630846459609421

Epoch: 5| Step: 10
Training loss: 3.101512072559201
Validation loss: 2.6481187087529157

Epoch: 56| Step: 0
Training loss: 3.0079746747574077
Validation loss: 2.6591758736284987

Epoch: 5| Step: 1
Training loss: 3.1584617494697906
Validation loss: 2.6791250427326836

Epoch: 5| Step: 2
Training loss: 2.598636757648029
Validation loss: 2.6616543769736345

Epoch: 5| Step: 3
Training loss: 2.42829565678336
Validation loss: 2.6549238944682214

Epoch: 5| Step: 4
Training loss: 2.889009426324716
Validation loss: 2.626261237705152

Epoch: 5| Step: 5
Training loss: 3.1385696290031664
Validation loss: 2.6173350939506097

Epoch: 5| Step: 6
Training loss: 3.5178848802165974
Validation loss: 2.6177472356733094

Epoch: 5| Step: 7
Training loss: 3.377231566564428
Validation loss: 2.6157160009481313

Epoch: 5| Step: 8
Training loss: 2.670527157266702
Validation loss: 2.616776385990941

Epoch: 5| Step: 9
Training loss: 2.865267991984965
Validation loss: 2.613183938428975

Epoch: 5| Step: 10
Training loss: 2.778498370694748
Validation loss: 2.614402978201241

Epoch: 57| Step: 0
Training loss: 2.8266420638915073
Validation loss: 2.6145221889516947

Epoch: 5| Step: 1
Training loss: 2.732244740785013
Validation loss: 2.612840577021038

Epoch: 5| Step: 2
Training loss: 2.8294570062245588
Validation loss: 2.6138099098767396

Epoch: 5| Step: 3
Training loss: 2.39129669127916
Validation loss: 2.616301767324397

Epoch: 5| Step: 4
Training loss: 3.2435391102116613
Validation loss: 2.6199272879209756

Epoch: 5| Step: 5
Training loss: 2.89686414270105
Validation loss: 2.622412119361069

Epoch: 5| Step: 6
Training loss: 2.6803346080564308
Validation loss: 2.6368223818182512

Epoch: 5| Step: 7
Training loss: 3.5233280139499183
Validation loss: 2.647489087943935

Epoch: 5| Step: 8
Training loss: 3.1990106722244396
Validation loss: 2.6276441422857544

Epoch: 5| Step: 9
Training loss: 3.1330952885343484
Validation loss: 2.617691785373077

Epoch: 5| Step: 10
Training loss: 2.9900562475010757
Validation loss: 2.616841281109438

Epoch: 58| Step: 0
Training loss: 2.8120316009428
Validation loss: 2.6127204692479533

Epoch: 5| Step: 1
Training loss: 2.8333567076074178
Validation loss: 2.6092118405106035

Epoch: 5| Step: 2
Training loss: 2.7717947379515566
Validation loss: 2.611840046396876

Epoch: 5| Step: 3
Training loss: 2.385233665232056
Validation loss: 2.612027453084381

Epoch: 5| Step: 4
Training loss: 2.775864090288627
Validation loss: 2.6112616997469287

Epoch: 5| Step: 5
Training loss: 2.9007611689860076
Validation loss: 2.613549838169421

Epoch: 5| Step: 6
Training loss: 3.4380043353396825
Validation loss: 2.613916742975869

Epoch: 5| Step: 7
Training loss: 3.304728334143034
Validation loss: 2.6165874941325318

Epoch: 5| Step: 8
Training loss: 3.7145174446759244
Validation loss: 2.6185296295669627

Epoch: 5| Step: 9
Training loss: 2.793107804258059
Validation loss: 2.6136965223119915

Epoch: 5| Step: 10
Training loss: 2.464900915386775
Validation loss: 2.6113882754082147

Epoch: 59| Step: 0
Training loss: 2.905727544605062
Validation loss: 2.609373551834311

Epoch: 5| Step: 1
Training loss: 3.4955565993602584
Validation loss: 2.6100339675797013

Epoch: 5| Step: 2
Training loss: 2.8445042877889133
Validation loss: 2.6130517976920196

Epoch: 5| Step: 3
Training loss: 2.905363214211631
Validation loss: 2.614626500518094

Epoch: 5| Step: 4
Training loss: 2.738245899881041
Validation loss: 2.6133845801029136

Epoch: 5| Step: 5
Training loss: 2.880283973257075
Validation loss: 2.6144741725028

Epoch: 5| Step: 6
Training loss: 3.130441124882009
Validation loss: 2.615366342973606

Epoch: 5| Step: 7
Training loss: 2.8706064238841114
Validation loss: 2.6186405522499836

Epoch: 5| Step: 8
Training loss: 3.0702954163209517
Validation loss: 2.6157930692963522

Epoch: 5| Step: 9
Training loss: 3.1848741074718063
Validation loss: 2.621602477557063

Epoch: 5| Step: 10
Training loss: 2.070560771522859
Validation loss: 2.629844986608099

Epoch: 60| Step: 0
Training loss: 3.1327742957166307
Validation loss: 2.6336760941433477

Epoch: 5| Step: 1
Training loss: 2.5739036448242105
Validation loss: 2.628916945685056

Epoch: 5| Step: 2
Training loss: 2.563369789443029
Validation loss: 2.6220170146925446

Epoch: 5| Step: 3
Training loss: 2.84499642021611
Validation loss: 2.63197243295613

Epoch: 5| Step: 4
Training loss: 3.5276473581097516
Validation loss: 2.6337466701242764

Epoch: 5| Step: 5
Training loss: 3.121183735453814
Validation loss: 2.6172745463809637

Epoch: 5| Step: 6
Training loss: 3.1644980048470033
Validation loss: 2.600383321446607

Epoch: 5| Step: 7
Training loss: 2.8436611287409588
Validation loss: 2.597474322940385

Epoch: 5| Step: 8
Training loss: 2.66114463873519
Validation loss: 2.5962037648025817

Epoch: 5| Step: 9
Training loss: 2.630586220565782
Validation loss: 2.598578982680032

Epoch: 5| Step: 10
Training loss: 3.207213086491998
Validation loss: 2.598929509591565

Epoch: 61| Step: 0
Training loss: 3.0786053432813008
Validation loss: 2.6000670931988554

Epoch: 5| Step: 1
Training loss: 2.9930372500665015
Validation loss: 2.596413989429109

Epoch: 5| Step: 2
Training loss: 2.4048677908549774
Validation loss: 2.59880198974862

Epoch: 5| Step: 3
Training loss: 2.943337180314047
Validation loss: 2.5966934343005366

Epoch: 5| Step: 4
Training loss: 3.2579023682711123
Validation loss: 2.594345618409053

Epoch: 5| Step: 5
Training loss: 2.9699902001935303
Validation loss: 2.5933950284827576

Epoch: 5| Step: 6
Training loss: 2.894865976766023
Validation loss: 2.5995890382507616

Epoch: 5| Step: 7
Training loss: 3.1237404382993637
Validation loss: 2.6084952337373095

Epoch: 5| Step: 8
Training loss: 2.9406194153751932
Validation loss: 2.6229374249076955

Epoch: 5| Step: 9
Training loss: 3.2417047715746423
Validation loss: 2.6527985194374875

Epoch: 5| Step: 10
Training loss: 2.5326704584354225
Validation loss: 2.6175113306829565

Epoch: 62| Step: 0
Training loss: 2.9264515005916194
Validation loss: 2.6109835985487626

Epoch: 5| Step: 1
Training loss: 2.5653997622088855
Validation loss: 2.6067221443386117

Epoch: 5| Step: 2
Training loss: 2.9717437105430786
Validation loss: 2.600936484212283

Epoch: 5| Step: 3
Training loss: 3.6621542965994824
Validation loss: 2.6166771646005187

Epoch: 5| Step: 4
Training loss: 2.9961459517127738
Validation loss: 2.6158765506661004

Epoch: 5| Step: 5
Training loss: 2.985923485196538
Validation loss: 2.610577439939364

Epoch: 5| Step: 6
Training loss: 2.689876481521009
Validation loss: 2.6091506986377384

Epoch: 5| Step: 7
Training loss: 2.6239998138125284
Validation loss: 2.6019583785230105

Epoch: 5| Step: 8
Training loss: 3.201823942606502
Validation loss: 2.596466893067832

Epoch: 5| Step: 9
Training loss: 2.2404487061676424
Validation loss: 2.6024415827191287

Epoch: 5| Step: 10
Training loss: 3.387151107557389
Validation loss: 2.5993095510975315

Epoch: 63| Step: 0
Training loss: 3.2590876949154675
Validation loss: 2.6008029843919607

Epoch: 5| Step: 1
Training loss: 3.0166334926685003
Validation loss: 2.603981490575853

Epoch: 5| Step: 2
Training loss: 2.9863653286699097
Validation loss: 2.6049957330608287

Epoch: 5| Step: 3
Training loss: 2.5721161146457714
Validation loss: 2.615168450887278

Epoch: 5| Step: 4
Training loss: 3.1339924937379258
Validation loss: 2.633318250022839

Epoch: 5| Step: 5
Training loss: 3.1914970917303744
Validation loss: 2.643349807841647

Epoch: 5| Step: 6
Training loss: 2.6708587141413043
Validation loss: 2.621847756270036

Epoch: 5| Step: 7
Training loss: 3.1089405158810326
Validation loss: 2.610943041203784

Epoch: 5| Step: 8
Training loss: 2.5088616669136017
Validation loss: 2.6000583829469672

Epoch: 5| Step: 9
Training loss: 3.098643892294247
Validation loss: 2.594678817002776

Epoch: 5| Step: 10
Training loss: 2.7474401871172938
Validation loss: 2.5900271687056833

Epoch: 64| Step: 0
Training loss: 3.141055860428936
Validation loss: 2.5906161221906596

Epoch: 5| Step: 1
Training loss: 2.5842859808686627
Validation loss: 2.5887691859743804

Epoch: 5| Step: 2
Training loss: 2.369750093088431
Validation loss: 2.5873981704280227

Epoch: 5| Step: 3
Training loss: 3.12139226562496
Validation loss: 2.589304109895267

Epoch: 5| Step: 4
Training loss: 3.24681948044335
Validation loss: 2.5877666071102965

Epoch: 5| Step: 5
Training loss: 2.8182724947898343
Validation loss: 2.5932716850766595

Epoch: 5| Step: 6
Training loss: 3.1712620335502097
Validation loss: 2.5976771338184115

Epoch: 5| Step: 7
Training loss: 2.896641917969831
Validation loss: 2.6084167929718323

Epoch: 5| Step: 8
Training loss: 3.0648489526864457
Validation loss: 2.606005560253096

Epoch: 5| Step: 9
Training loss: 3.0180461434185712
Validation loss: 2.612763754209943

Epoch: 5| Step: 10
Training loss: 2.7500388402796925
Validation loss: 2.6025679490383435

Epoch: 65| Step: 0
Training loss: 2.574947919596677
Validation loss: 2.6035966543845097

Epoch: 5| Step: 1
Training loss: 3.1169517638286717
Validation loss: 2.600437962732842

Epoch: 5| Step: 2
Training loss: 3.4105793449054236
Validation loss: 2.5972423306651984

Epoch: 5| Step: 3
Training loss: 3.0763614462917035
Validation loss: 2.587682526994698

Epoch: 5| Step: 4
Training loss: 2.713314981687503
Validation loss: 2.5879694937515323

Epoch: 5| Step: 5
Training loss: 2.8318286902236736
Validation loss: 2.5852557567086807

Epoch: 5| Step: 6
Training loss: 2.439096270467336
Validation loss: 2.580397210239342

Epoch: 5| Step: 7
Training loss: 3.3124811423862552
Validation loss: 2.5846601076755618

Epoch: 5| Step: 8
Training loss: 2.672416052217982
Validation loss: 2.581475588889418

Epoch: 5| Step: 9
Training loss: 2.6008155827363177
Validation loss: 2.5823016946645683

Epoch: 5| Step: 10
Training loss: 3.363863621000911
Validation loss: 2.5830272803550036

Epoch: 66| Step: 0
Training loss: 2.7301503706660104
Validation loss: 2.587323911022449

Epoch: 5| Step: 1
Training loss: 2.731870626997213
Validation loss: 2.586665146146115

Epoch: 5| Step: 2
Training loss: 2.7599031558530274
Validation loss: 2.59277634545284

Epoch: 5| Step: 3
Training loss: 2.9957795656036637
Validation loss: 2.5897910639655266

Epoch: 5| Step: 4
Training loss: 2.731298754363865
Validation loss: 2.5842997013391398

Epoch: 5| Step: 5
Training loss: 2.611187699279142
Validation loss: 2.578993965145332

Epoch: 5| Step: 6
Training loss: 3.177567358616097
Validation loss: 2.5801697737306726

Epoch: 5| Step: 7
Training loss: 3.0764865290462953
Validation loss: 2.5769800054341854

Epoch: 5| Step: 8
Training loss: 2.8540112158401905
Validation loss: 2.572721664161941

Epoch: 5| Step: 9
Training loss: 3.308514914986479
Validation loss: 2.5760389612454353

Epoch: 5| Step: 10
Training loss: 3.11605592615282
Validation loss: 2.577814335406772

Epoch: 67| Step: 0
Training loss: 3.5459323252133106
Validation loss: 2.5868166975565203

Epoch: 5| Step: 1
Training loss: 2.7221684504624015
Validation loss: 2.5845900407021656

Epoch: 5| Step: 2
Training loss: 3.1609692936352887
Validation loss: 2.5905281830079723

Epoch: 5| Step: 3
Training loss: 2.7939009384583513
Validation loss: 2.5830112852624554

Epoch: 5| Step: 4
Training loss: 2.7382269185943744
Validation loss: 2.5816784992353465

Epoch: 5| Step: 5
Training loss: 2.7677946901087584
Validation loss: 2.584005688776185

Epoch: 5| Step: 6
Training loss: 2.971971871675483
Validation loss: 2.577775980175911

Epoch: 5| Step: 7
Training loss: 2.698016504824004
Validation loss: 2.5779982629216436

Epoch: 5| Step: 8
Training loss: 2.5612467050228642
Validation loss: 2.5691348383680075

Epoch: 5| Step: 9
Training loss: 3.36202642800078
Validation loss: 2.5720069711543787

Epoch: 5| Step: 10
Training loss: 2.5543731589388856
Validation loss: 2.5686631698230515

Epoch: 68| Step: 0
Training loss: 2.879097382245032
Validation loss: 2.5704808982135248

Epoch: 5| Step: 1
Training loss: 3.0211775660324975
Validation loss: 2.574469511043751

Epoch: 5| Step: 2
Training loss: 2.6516717388105366
Validation loss: 2.571757199107692

Epoch: 5| Step: 3
Training loss: 2.6858860758795706
Validation loss: 2.5716392209155425

Epoch: 5| Step: 4
Training loss: 3.337341727743693
Validation loss: 2.5727121478533213

Epoch: 5| Step: 5
Training loss: 2.7886736088458943
Validation loss: 2.5759224868949198

Epoch: 5| Step: 6
Training loss: 3.012776032143916
Validation loss: 2.5727650580830304

Epoch: 5| Step: 7
Training loss: 3.1157255257905803
Validation loss: 2.579222553963766

Epoch: 5| Step: 8
Training loss: 3.1084716097949756
Validation loss: 2.577681895213038

Epoch: 5| Step: 9
Training loss: 2.850929336276916
Validation loss: 2.5815659883965907

Epoch: 5| Step: 10
Training loss: 2.4302288077993923
Validation loss: 2.586350826834712

Epoch: 69| Step: 0
Training loss: 2.7367904893258816
Validation loss: 2.5949200243408557

Epoch: 5| Step: 1
Training loss: 2.887980473164406
Validation loss: 2.5901749800808336

Epoch: 5| Step: 2
Training loss: 3.1520985409877604
Validation loss: 2.5802374425412156

Epoch: 5| Step: 3
Training loss: 3.268612895592023
Validation loss: 2.578578505617185

Epoch: 5| Step: 4
Training loss: 2.430975961808773
Validation loss: 2.565336851605175

Epoch: 5| Step: 5
Training loss: 2.404718778826938
Validation loss: 2.5659001739956775

Epoch: 5| Step: 6
Training loss: 3.166990230158584
Validation loss: 2.5641664798207318

Epoch: 5| Step: 7
Training loss: 2.949765024687
Validation loss: 2.5647198286011537

Epoch: 5| Step: 8
Training loss: 2.9530452334010557
Validation loss: 2.5675784374800434

Epoch: 5| Step: 9
Training loss: 2.6477724213607563
Validation loss: 2.5935325526468005

Epoch: 5| Step: 10
Training loss: 3.441725474694933
Validation loss: 2.6002533814829376

Epoch: 70| Step: 0
Training loss: 2.82878535027357
Validation loss: 2.5956937828220847

Epoch: 5| Step: 1
Training loss: 3.5320879186831715
Validation loss: 2.5759209353276757

Epoch: 5| Step: 2
Training loss: 2.6994697685944136
Validation loss: 2.574702454502234

Epoch: 5| Step: 3
Training loss: 2.3756713922070998
Validation loss: 2.5717439470299186

Epoch: 5| Step: 4
Training loss: 3.244063310431065
Validation loss: 2.569604575627141

Epoch: 5| Step: 5
Training loss: 2.9836995423952377
Validation loss: 2.5753181051162337

Epoch: 5| Step: 6
Training loss: 2.6401178900088023
Validation loss: 2.5717691193401633

Epoch: 5| Step: 7
Training loss: 2.89836675758093
Validation loss: 2.5729560651415992

Epoch: 5| Step: 8
Training loss: 3.0459494725605825
Validation loss: 2.5689759489640682

Epoch: 5| Step: 9
Training loss: 2.9427663791749326
Validation loss: 2.5757514794513163

Epoch: 5| Step: 10
Training loss: 2.617447569721869
Validation loss: 2.578399359211528

Epoch: 71| Step: 0
Training loss: 3.060085824249055
Validation loss: 2.576570338319476

Epoch: 5| Step: 1
Training loss: 2.5894177576982544
Validation loss: 2.568940907650716

Epoch: 5| Step: 2
Training loss: 3.283870268420989
Validation loss: 2.5643577444544436

Epoch: 5| Step: 3
Training loss: 3.0831644853978446
Validation loss: 2.562432287978806

Epoch: 5| Step: 4
Training loss: 2.4697291689821657
Validation loss: 2.564687016203913

Epoch: 5| Step: 5
Training loss: 3.021528247398839
Validation loss: 2.5593300718104066

Epoch: 5| Step: 6
Training loss: 2.889318387390593
Validation loss: 2.5656087233071667

Epoch: 5| Step: 7
Training loss: 2.4122429073299445
Validation loss: 2.561361117808585

Epoch: 5| Step: 8
Training loss: 2.774352446599985
Validation loss: 2.568318972048913

Epoch: 5| Step: 9
Training loss: 3.3514681716129235
Validation loss: 2.5901714763430332

Epoch: 5| Step: 10
Training loss: 2.881532793379046
Validation loss: 2.583834166576647

Epoch: 72| Step: 0
Training loss: 3.2627486561693595
Validation loss: 2.57953987463646

Epoch: 5| Step: 1
Training loss: 3.2163229374893647
Validation loss: 2.5777284239492846

Epoch: 5| Step: 2
Training loss: 2.490083577695229
Validation loss: 2.577479066100232

Epoch: 5| Step: 3
Training loss: 3.163888431988524
Validation loss: 2.5718213332548308

Epoch: 5| Step: 4
Training loss: 2.128264108108081
Validation loss: 2.5881198445192677

Epoch: 5| Step: 5
Training loss: 3.0484543057383697
Validation loss: 2.5824776448631903

Epoch: 5| Step: 6
Training loss: 2.560750782963608
Validation loss: 2.588362317769593

Epoch: 5| Step: 7
Training loss: 2.988691154739882
Validation loss: 2.5941302419475933

Epoch: 5| Step: 8
Training loss: 3.4505754958327466
Validation loss: 2.591202432293899

Epoch: 5| Step: 9
Training loss: 2.594821386934047
Validation loss: 2.579975030446257

Epoch: 5| Step: 10
Training loss: 2.6911456199209343
Validation loss: 2.5621988473204316

Epoch: 73| Step: 0
Training loss: 3.181258429795284
Validation loss: 2.553393790483736

Epoch: 5| Step: 1
Training loss: 3.051756718749804
Validation loss: 2.5528123384874086

Epoch: 5| Step: 2
Training loss: 2.6975811684658213
Validation loss: 2.5550170738032305

Epoch: 5| Step: 3
Training loss: 2.8264156676660677
Validation loss: 2.553085588075771

Epoch: 5| Step: 4
Training loss: 2.523556827522824
Validation loss: 2.5571923571320565

Epoch: 5| Step: 5
Training loss: 2.503086187892813
Validation loss: 2.55905258922784

Epoch: 5| Step: 6
Training loss: 2.846664109359176
Validation loss: 2.5745334282592007

Epoch: 5| Step: 7
Training loss: 3.5984115221988247
Validation loss: 2.57926282289122

Epoch: 5| Step: 8
Training loss: 3.0212025033155325
Validation loss: 2.6151269095103253

Epoch: 5| Step: 9
Training loss: 2.9230143727625535
Validation loss: 2.6394912092423484

Epoch: 5| Step: 10
Training loss: 2.7361470611155516
Validation loss: 2.6430961190274758

Epoch: 74| Step: 0
Training loss: 2.8948173844845826
Validation loss: 2.6654331144702557

Epoch: 5| Step: 1
Training loss: 3.322095970921769
Validation loss: 2.626397700767019

Epoch: 5| Step: 2
Training loss: 2.4645045994758057
Validation loss: 2.6062252031792656

Epoch: 5| Step: 3
Training loss: 3.336806744643542
Validation loss: 2.588265324757142

Epoch: 5| Step: 4
Training loss: 2.9143635694004337
Validation loss: 2.580150537683409

Epoch: 5| Step: 5
Training loss: 2.7783343859485385
Validation loss: 2.5834390127085634

Epoch: 5| Step: 6
Training loss: 2.9223061309809664
Validation loss: 2.592034172796705

Epoch: 5| Step: 7
Training loss: 2.734824181855949
Validation loss: 2.6055625783879854

Epoch: 5| Step: 8
Training loss: 3.0710799250634833
Validation loss: 2.622604101969626

Epoch: 5| Step: 9
Training loss: 2.746537282621578
Validation loss: 2.59891972624208

Epoch: 5| Step: 10
Training loss: 2.830073238813501
Validation loss: 2.583009495782985

Epoch: 75| Step: 0
Training loss: 2.9666911163465555
Validation loss: 2.590571353867087

Epoch: 5| Step: 1
Training loss: 2.0674321705255823
Validation loss: 2.5636227836881806

Epoch: 5| Step: 2
Training loss: 2.627347532253169
Validation loss: 2.5576595306383965

Epoch: 5| Step: 3
Training loss: 2.936861496379013
Validation loss: 2.5721513768253503

Epoch: 5| Step: 4
Training loss: 3.7156955773249307
Validation loss: 2.568841550144863

Epoch: 5| Step: 5
Training loss: 3.216947032061965
Validation loss: 2.578629961277968

Epoch: 5| Step: 6
Training loss: 3.1294129303099507
Validation loss: 2.5916858559090517

Epoch: 5| Step: 7
Training loss: 3.348282068928834
Validation loss: 2.6002056684546364

Epoch: 5| Step: 8
Training loss: 2.439292053329315
Validation loss: 2.5967318270190285

Epoch: 5| Step: 9
Training loss: 2.7949364619804093
Validation loss: 2.5896964146887043

Epoch: 5| Step: 10
Training loss: 2.556577024550306
Validation loss: 2.5838586615155354

Epoch: 76| Step: 0
Training loss: 2.6406045043872224
Validation loss: 2.585043147489387

Epoch: 5| Step: 1
Training loss: 2.956266478155879
Validation loss: 2.5831628227792045

Epoch: 5| Step: 2
Training loss: 2.964341594806213
Validation loss: 2.577956991728082

Epoch: 5| Step: 3
Training loss: 3.2469518011737573
Validation loss: 2.5853863314533587

Epoch: 5| Step: 4
Training loss: 2.7943276680709137
Validation loss: 2.5753468798847057

Epoch: 5| Step: 5
Training loss: 2.2397083572857874
Validation loss: 2.572721574479616

Epoch: 5| Step: 6
Training loss: 2.842918525958712
Validation loss: 2.574173726381454

Epoch: 5| Step: 7
Training loss: 2.9805602613326823
Validation loss: 2.563045970780816

Epoch: 5| Step: 8
Training loss: 3.1462840247938284
Validation loss: 2.5652129485906254

Epoch: 5| Step: 9
Training loss: 2.943272701371912
Validation loss: 2.566303852419876

Epoch: 5| Step: 10
Training loss: 3.131649115247472
Validation loss: 2.56408990838325

Epoch: 77| Step: 0
Training loss: 2.684242314533303
Validation loss: 2.5577351479422314

Epoch: 5| Step: 1
Training loss: 2.841516309174159
Validation loss: 2.5644455533884742

Epoch: 5| Step: 2
Training loss: 3.1340856081937685
Validation loss: 2.5668779417525105

Epoch: 5| Step: 3
Training loss: 3.0010831784775016
Validation loss: 2.5615443817113484

Epoch: 5| Step: 4
Training loss: 2.9520870584712533
Validation loss: 2.564647172157111

Epoch: 5| Step: 5
Training loss: 2.9229161656534024
Validation loss: 2.557050022168263

Epoch: 5| Step: 6
Training loss: 3.067703342055884
Validation loss: 2.5515002547469368

Epoch: 5| Step: 7
Training loss: 2.6133690150737907
Validation loss: 2.5494672953959947

Epoch: 5| Step: 8
Training loss: 3.0469717157125924
Validation loss: 2.5517369959278424

Epoch: 5| Step: 9
Training loss: 2.843857312535652
Validation loss: 2.5472365197678837

Epoch: 5| Step: 10
Training loss: 2.5710631784564817
Validation loss: 2.549956180128444

Epoch: 78| Step: 0
Training loss: 2.7769454048018303
Validation loss: 2.549382220640208

Epoch: 5| Step: 1
Training loss: 2.8909638077414423
Validation loss: 2.560235640014088

Epoch: 5| Step: 2
Training loss: 3.1496873367389764
Validation loss: 2.568358683273127

Epoch: 5| Step: 3
Training loss: 2.510411422111974
Validation loss: 2.571858839296931

Epoch: 5| Step: 4
Training loss: 2.491120112852147
Validation loss: 2.5599287755749347

Epoch: 5| Step: 5
Training loss: 3.0667926520577375
Validation loss: 2.554373742046735

Epoch: 5| Step: 6
Training loss: 3.0757785896907945
Validation loss: 2.5431631809183894

Epoch: 5| Step: 7
Training loss: 3.4139460144422857
Validation loss: 2.5424407521232184

Epoch: 5| Step: 8
Training loss: 2.6103852651969914
Validation loss: 2.539078204514217

Epoch: 5| Step: 9
Training loss: 2.5613897756301434
Validation loss: 2.541245541784823

Epoch: 5| Step: 10
Training loss: 3.0346823853866125
Validation loss: 2.5451314174381627

Epoch: 79| Step: 0
Training loss: 3.0194154941731086
Validation loss: 2.5421876778482693

Epoch: 5| Step: 1
Training loss: 3.0587898668965643
Validation loss: 2.5549039307163595

Epoch: 5| Step: 2
Training loss: 2.8361169006939497
Validation loss: 2.5692357740631544

Epoch: 5| Step: 3
Training loss: 3.086258729077985
Validation loss: 2.581498462657199

Epoch: 5| Step: 4
Training loss: 2.36348886129661
Validation loss: 2.5616618280553682

Epoch: 5| Step: 5
Training loss: 2.949061752081555
Validation loss: 2.558120449551337

Epoch: 5| Step: 6
Training loss: 2.963091627833011
Validation loss: 2.564096942140949

Epoch: 5| Step: 7
Training loss: 2.8459762410762512
Validation loss: 2.5525641863329778

Epoch: 5| Step: 8
Training loss: 2.8588057821725323
Validation loss: 2.5506206192334506

Epoch: 5| Step: 9
Training loss: 2.770794449918202
Validation loss: 2.544545593919494

Epoch: 5| Step: 10
Training loss: 2.761823552367461
Validation loss: 2.5341761837328742

Epoch: 80| Step: 0
Training loss: 2.4980921140963264
Validation loss: 2.531825875287772

Epoch: 5| Step: 1
Training loss: 2.9830822766192
Validation loss: 2.529315543017758

Epoch: 5| Step: 2
Training loss: 3.1661436418635662
Validation loss: 2.5244542754883725

Epoch: 5| Step: 3
Training loss: 2.6444862621092624
Validation loss: 2.52868105319101

Epoch: 5| Step: 4
Training loss: 3.340733673925915
Validation loss: 2.53399868607089

Epoch: 5| Step: 5
Training loss: 2.7185179512703965
Validation loss: 2.541393408231528

Epoch: 5| Step: 6
Training loss: 2.7068884785751917
Validation loss: 2.5559041181757545

Epoch: 5| Step: 7
Training loss: 2.9026381496044356
Validation loss: 2.561772111808409

Epoch: 5| Step: 8
Training loss: 2.95244578467585
Validation loss: 2.559274559870352

Epoch: 5| Step: 9
Training loss: 3.0844233021147436
Validation loss: 2.553373540464643

Epoch: 5| Step: 10
Training loss: 2.3633021330107815
Validation loss: 2.5552947156993806

Epoch: 81| Step: 0
Training loss: 2.2685238938329193
Validation loss: 2.5673217099639376

Epoch: 5| Step: 1
Training loss: 2.5296729555707387
Validation loss: 2.5786304305342354

Epoch: 5| Step: 2
Training loss: 2.578645318440326
Validation loss: 2.588228162940398

Epoch: 5| Step: 3
Training loss: 3.302504375261387
Validation loss: 2.585726195083276

Epoch: 5| Step: 4
Training loss: 2.9808304593445025
Validation loss: 2.5549871359235334

Epoch: 5| Step: 5
Training loss: 2.814878432933402
Validation loss: 2.5444727241198524

Epoch: 5| Step: 6
Training loss: 2.804442413587619
Validation loss: 2.5325331191228537

Epoch: 5| Step: 7
Training loss: 3.466016087252026
Validation loss: 2.534652809889197

Epoch: 5| Step: 8
Training loss: 3.1153467235814833
Validation loss: 2.532868747709483

Epoch: 5| Step: 9
Training loss: 3.055399389803791
Validation loss: 2.5310048326801167

Epoch: 5| Step: 10
Training loss: 2.4037252284225175
Validation loss: 2.5305320544985053

Epoch: 82| Step: 0
Training loss: 3.009154656920707
Validation loss: 2.533658941278775

Epoch: 5| Step: 1
Training loss: 2.360421359222228
Validation loss: 2.541220317308269

Epoch: 5| Step: 2
Training loss: 2.9926954988566665
Validation loss: 2.5493164449663257

Epoch: 5| Step: 3
Training loss: 2.6147033744905492
Validation loss: 2.5559338386936234

Epoch: 5| Step: 4
Training loss: 3.0420221269092487
Validation loss: 2.556058037049305

Epoch: 5| Step: 5
Training loss: 2.9150653984886548
Validation loss: 2.564625146710127

Epoch: 5| Step: 6
Training loss: 2.974648969440603
Validation loss: 2.5621314115076776

Epoch: 5| Step: 7
Training loss: 2.806022984895215
Validation loss: 2.5469959984473056

Epoch: 5| Step: 8
Training loss: 3.2128610905272463
Validation loss: 2.5311434019576033

Epoch: 5| Step: 9
Training loss: 3.140572466814215
Validation loss: 2.520056101746991

Epoch: 5| Step: 10
Training loss: 2.191805607654754
Validation loss: 2.5183752617158293

Epoch: 83| Step: 0
Training loss: 2.901845239720424
Validation loss: 2.5193342478591623

Epoch: 5| Step: 1
Training loss: 2.622698728815673
Validation loss: 2.517946101246872

Epoch: 5| Step: 2
Training loss: 3.0047782356578994
Validation loss: 2.5184434182273163

Epoch: 5| Step: 3
Training loss: 3.0035560512910475
Validation loss: 2.5275606943922964

Epoch: 5| Step: 4
Training loss: 2.7430170005524617
Validation loss: 2.5345148006642573

Epoch: 5| Step: 5
Training loss: 2.654323283015706
Validation loss: 2.5533202155999124

Epoch: 5| Step: 6
Training loss: 2.7448632208649895
Validation loss: 2.6023353789239194

Epoch: 5| Step: 7
Training loss: 3.2251651869467497
Validation loss: 2.603465634073854

Epoch: 5| Step: 8
Training loss: 2.847511570398738
Validation loss: 2.547537764661881

Epoch: 5| Step: 9
Training loss: 2.375760207730618
Validation loss: 2.523032527210944

Epoch: 5| Step: 10
Training loss: 3.570893689019774
Validation loss: 2.5167176437946703

Epoch: 84| Step: 0
Training loss: 2.989932652356069
Validation loss: 2.5154393053112236

Epoch: 5| Step: 1
Training loss: 3.2665900305756836
Validation loss: 2.515578814554972

Epoch: 5| Step: 2
Training loss: 3.0633797452425013
Validation loss: 2.5145524024326926

Epoch: 5| Step: 3
Training loss: 2.683936573325191
Validation loss: 2.516004940938856

Epoch: 5| Step: 4
Training loss: 3.077703921567669
Validation loss: 2.514681411432991

Epoch: 5| Step: 5
Training loss: 2.6830663259912098
Validation loss: 2.5155776711181494

Epoch: 5| Step: 6
Training loss: 2.93383983082821
Validation loss: 2.5119659292506697

Epoch: 5| Step: 7
Training loss: 2.7604707436692846
Validation loss: 2.510925955809387

Epoch: 5| Step: 8
Training loss: 3.013224065988221
Validation loss: 2.52257270589666

Epoch: 5| Step: 9
Training loss: 2.6432599346205463
Validation loss: 2.536946365826463

Epoch: 5| Step: 10
Training loss: 2.186870811438767
Validation loss: 2.5463694580230576

Epoch: 85| Step: 0
Training loss: 2.8194155970842667
Validation loss: 2.5523154204470533

Epoch: 5| Step: 1
Training loss: 3.0516931243144017
Validation loss: 2.5603399138887215

Epoch: 5| Step: 2
Training loss: 2.8937239248200877
Validation loss: 2.5600940906021563

Epoch: 5| Step: 3
Training loss: 2.9747767260458757
Validation loss: 2.553822690916513

Epoch: 5| Step: 4
Training loss: 2.5951175990864805
Validation loss: 2.5483393824970237

Epoch: 5| Step: 5
Training loss: 3.0264406099918935
Validation loss: 2.531464909290182

Epoch: 5| Step: 6
Training loss: 2.8976263263275284
Validation loss: 2.528170127440028

Epoch: 5| Step: 7
Training loss: 2.7085177921177674
Validation loss: 2.5234529360219664

Epoch: 5| Step: 8
Training loss: 3.0601508024866946
Validation loss: 2.5239023516818127

Epoch: 5| Step: 9
Training loss: 2.878610417190899
Validation loss: 2.524987769160726

Epoch: 5| Step: 10
Training loss: 2.2640718595470575
Validation loss: 2.5307128753639856

Epoch: 86| Step: 0
Training loss: 2.7886651447950723
Validation loss: 2.529372548643584

Epoch: 5| Step: 1
Training loss: 2.323089068619571
Validation loss: 2.5470590278961063

Epoch: 5| Step: 2
Training loss: 2.932175701190392
Validation loss: 2.5458086575877346

Epoch: 5| Step: 3
Training loss: 2.5519028165124777
Validation loss: 2.5416710344341262

Epoch: 5| Step: 4
Training loss: 2.8113719797364536
Validation loss: 2.5528374002205765

Epoch: 5| Step: 5
Training loss: 2.911360318758166
Validation loss: 2.524528552772879

Epoch: 5| Step: 6
Training loss: 2.6183144946991863
Validation loss: 2.5089435420859707

Epoch: 5| Step: 7
Training loss: 3.1776680496881338
Validation loss: 2.50534634050873

Epoch: 5| Step: 8
Training loss: 3.153737191542033
Validation loss: 2.5055618764932817

Epoch: 5| Step: 9
Training loss: 3.0501018944901594
Validation loss: 2.505812316938116

Epoch: 5| Step: 10
Training loss: 3.0712952727480936
Validation loss: 2.5071343278147777

Epoch: 87| Step: 0
Training loss: 2.859826224322939
Validation loss: 2.5132024482714357

Epoch: 5| Step: 1
Training loss: 2.601366190334106
Validation loss: 2.5161992266518434

Epoch: 5| Step: 2
Training loss: 2.6003241813735616
Validation loss: 2.5333563142029907

Epoch: 5| Step: 3
Training loss: 2.696040842912817
Validation loss: 2.5410376391882656

Epoch: 5| Step: 4
Training loss: 2.879314171140477
Validation loss: 2.537589700922733

Epoch: 5| Step: 5
Training loss: 2.6048089011126936
Validation loss: 2.5563040418659178

Epoch: 5| Step: 6
Training loss: 2.9988628457491595
Validation loss: 2.5556945802720854

Epoch: 5| Step: 7
Training loss: 2.9877846298936785
Validation loss: 2.5769720468327564

Epoch: 5| Step: 8
Training loss: 3.2442194075322623
Validation loss: 2.5651690541358687

Epoch: 5| Step: 9
Training loss: 2.895369476564736
Validation loss: 2.5436358281876306

Epoch: 5| Step: 10
Training loss: 2.8852930329388196
Validation loss: 2.5276612800324085

Epoch: 88| Step: 0
Training loss: 2.376092458737042
Validation loss: 2.5270634886462733

Epoch: 5| Step: 1
Training loss: 2.9331514352696013
Validation loss: 2.5164643084131426

Epoch: 5| Step: 2
Training loss: 3.334123819716754
Validation loss: 2.5204346210208577

Epoch: 5| Step: 3
Training loss: 2.8099964443197867
Validation loss: 2.5186112944029824

Epoch: 5| Step: 4
Training loss: 2.7326247362876845
Validation loss: 2.514520642093413

Epoch: 5| Step: 5
Training loss: 2.5995810354566764
Validation loss: 2.5156912927714803

Epoch: 5| Step: 6
Training loss: 2.8436498938746144
Validation loss: 2.5136851731643937

Epoch: 5| Step: 7
Training loss: 2.831395234347105
Validation loss: 2.5220598342094673

Epoch: 5| Step: 8
Training loss: 2.704984785872737
Validation loss: 2.5281380179726507

Epoch: 5| Step: 9
Training loss: 3.064691654644773
Validation loss: 2.537014762099922

Epoch: 5| Step: 10
Training loss: 2.8992616042246766
Validation loss: 2.5433976485407515

Epoch: 89| Step: 0
Training loss: 3.1530036471920777
Validation loss: 2.5540933963414627

Epoch: 5| Step: 1
Training loss: 3.4351603088285523
Validation loss: 2.5599642376747513

Epoch: 5| Step: 2
Training loss: 3.204263326694121
Validation loss: 2.547754551941229

Epoch: 5| Step: 3
Training loss: 2.3145639642499605
Validation loss: 2.528048102702815

Epoch: 5| Step: 4
Training loss: 2.6303339761367353
Validation loss: 2.5346420370550127

Epoch: 5| Step: 5
Training loss: 2.801099517062199
Validation loss: 2.532379670061515

Epoch: 5| Step: 6
Training loss: 2.7955740348388445
Validation loss: 2.530509868882529

Epoch: 5| Step: 7
Training loss: 2.6738545184508156
Validation loss: 2.5244676437938702

Epoch: 5| Step: 8
Training loss: 2.7063796895515853
Validation loss: 2.5204187403282954

Epoch: 5| Step: 9
Training loss: 3.074558263544566
Validation loss: 2.5263399726719786

Epoch: 5| Step: 10
Training loss: 2.170453271770149
Validation loss: 2.5241370661816402

Epoch: 90| Step: 0
Training loss: 2.8352719201095886
Validation loss: 2.5201250357696554

Epoch: 5| Step: 1
Training loss: 2.7296217230834663
Validation loss: 2.5277719518648527

Epoch: 5| Step: 2
Training loss: 2.651709681636973
Validation loss: 2.534266230578455

Epoch: 5| Step: 3
Training loss: 2.993961296509211
Validation loss: 2.5483080714236714

Epoch: 5| Step: 4
Training loss: 3.1227191994100685
Validation loss: 2.5473122361404896

Epoch: 5| Step: 5
Training loss: 2.9942519434113355
Validation loss: 2.5451110402359025

Epoch: 5| Step: 6
Training loss: 2.6623598626020457
Validation loss: 2.5315696203588183

Epoch: 5| Step: 7
Training loss: 2.6228938963499857
Validation loss: 2.515085602626618

Epoch: 5| Step: 8
Training loss: 2.757530565412349
Validation loss: 2.5023135759992687

Epoch: 5| Step: 9
Training loss: 2.874671585564778
Validation loss: 2.5017064064725196

Epoch: 5| Step: 10
Training loss: 2.9204101154306343
Validation loss: 2.503490116564282

Epoch: 91| Step: 0
Training loss: 2.6868441468992135
Validation loss: 2.5047167674226545

Epoch: 5| Step: 1
Training loss: 2.8492069077827487
Validation loss: 2.5029594747344133

Epoch: 5| Step: 2
Training loss: 3.0612580252776245
Validation loss: 2.4987505702927337

Epoch: 5| Step: 3
Training loss: 3.3605008390085325
Validation loss: 2.5030482945535253

Epoch: 5| Step: 4
Training loss: 2.944264192482026
Validation loss: 2.511846516494515

Epoch: 5| Step: 5
Training loss: 2.56352966834873
Validation loss: 2.5176159931201623

Epoch: 5| Step: 6
Training loss: 2.317282088156841
Validation loss: 2.5330864551511625

Epoch: 5| Step: 7
Training loss: 3.1394680036605407
Validation loss: 2.553316163032332

Epoch: 5| Step: 8
Training loss: 2.682452051990952
Validation loss: 2.5785213201885315

Epoch: 5| Step: 9
Training loss: 2.8905052366448483
Validation loss: 2.557093009319327

Epoch: 5| Step: 10
Training loss: 2.448148113158181
Validation loss: 2.5463514717871796

Epoch: 92| Step: 0
Training loss: 2.4377294579122486
Validation loss: 2.5248921410603646

Epoch: 5| Step: 1
Training loss: 3.101467025401973
Validation loss: 2.511800029888044

Epoch: 5| Step: 2
Training loss: 2.4834254147485275
Validation loss: 2.5050858561549374

Epoch: 5| Step: 3
Training loss: 2.9684407926453438
Validation loss: 2.5077126455350225

Epoch: 5| Step: 4
Training loss: 3.4102022532782654
Validation loss: 2.4993159732454595

Epoch: 5| Step: 5
Training loss: 2.5400441311584374
Validation loss: 2.502682706718689

Epoch: 5| Step: 6
Training loss: 2.8368127066123807
Validation loss: 2.498449448713399

Epoch: 5| Step: 7
Training loss: 3.0229684234191496
Validation loss: 2.5010150243495475

Epoch: 5| Step: 8
Training loss: 2.935205253169676
Validation loss: 2.502823502681331

Epoch: 5| Step: 9
Training loss: 2.5625005582483196
Validation loss: 2.510059559188212

Epoch: 5| Step: 10
Training loss: 2.641710227663306
Validation loss: 2.511262416683235

Epoch: 93| Step: 0
Training loss: 2.471909830689536
Validation loss: 2.5109784261909467

Epoch: 5| Step: 1
Training loss: 3.03797889356583
Validation loss: 2.510949590691025

Epoch: 5| Step: 2
Training loss: 2.8805935391119037
Validation loss: 2.5075670041070475

Epoch: 5| Step: 3
Training loss: 2.6937398109331845
Validation loss: 2.510843265155041

Epoch: 5| Step: 4
Training loss: 2.6619963478504696
Validation loss: 2.5048241267701474

Epoch: 5| Step: 5
Training loss: 2.8768603069718344
Validation loss: 2.509007812536032

Epoch: 5| Step: 6
Training loss: 2.753353241932393
Validation loss: 2.507829982658423

Epoch: 5| Step: 7
Training loss: 3.254616319864197
Validation loss: 2.511798150891261

Epoch: 5| Step: 8
Training loss: 3.1978622746682794
Validation loss: 2.512538108685646

Epoch: 5| Step: 9
Training loss: 2.633417620295824
Validation loss: 2.506713714388271

Epoch: 5| Step: 10
Training loss: 2.3137174958306157
Validation loss: 2.519241532825348

Epoch: 94| Step: 0
Training loss: 2.878161806415882
Validation loss: 2.522334925271621

Epoch: 5| Step: 1
Training loss: 2.707016982003795
Validation loss: 2.5376195450155943

Epoch: 5| Step: 2
Training loss: 2.919837281905897
Validation loss: 2.566509546484349

Epoch: 5| Step: 3
Training loss: 3.0691153252524916
Validation loss: 2.585334763353357

Epoch: 5| Step: 4
Training loss: 2.681290483502559
Validation loss: 2.5420902113803936

Epoch: 5| Step: 5
Training loss: 2.6015976912034264
Validation loss: 2.5048454969683798

Epoch: 5| Step: 6
Training loss: 2.999762207779586
Validation loss: 2.4993941762552305

Epoch: 5| Step: 7
Training loss: 2.432473501941282
Validation loss: 2.4880502955865382

Epoch: 5| Step: 8
Training loss: 3.061841932944754
Validation loss: 2.4938171358354824

Epoch: 5| Step: 9
Training loss: 2.7294848501690288
Validation loss: 2.502325530956234

Epoch: 5| Step: 10
Training loss: 3.058620097118721
Validation loss: 2.5098746927428857

Epoch: 95| Step: 0
Training loss: 3.024350839113557
Validation loss: 2.5084614070560054

Epoch: 5| Step: 1
Training loss: 2.333763003525061
Validation loss: 2.5031575505197785

Epoch: 5| Step: 2
Training loss: 3.1681027084231603
Validation loss: 2.5102465076669693

Epoch: 5| Step: 3
Training loss: 2.5732697052904836
Validation loss: 2.5003422636142134

Epoch: 5| Step: 4
Training loss: 3.1584926984399746
Validation loss: 2.5022412231636677

Epoch: 5| Step: 5
Training loss: 2.383027514152791
Validation loss: 2.5137642182290483

Epoch: 5| Step: 6
Training loss: 3.0048672610907294
Validation loss: 2.5482465638225444

Epoch: 5| Step: 7
Training loss: 3.0358364369155497
Validation loss: 2.5914306174119446

Epoch: 5| Step: 8
Training loss: 2.7520513686220807
Validation loss: 2.603589994179517

Epoch: 5| Step: 9
Training loss: 2.7470393282502106
Validation loss: 2.602156663171065

Epoch: 5| Step: 10
Training loss: 3.0392082591270695
Validation loss: 2.610361916817787

Epoch: 96| Step: 0
Training loss: 2.52303818888571
Validation loss: 2.5377064789254815

Epoch: 5| Step: 1
Training loss: 2.883115840345743
Validation loss: 2.500024164759843

Epoch: 5| Step: 2
Training loss: 2.599718419746453
Validation loss: 2.496436986632415

Epoch: 5| Step: 3
Training loss: 2.5930713547062574
Validation loss: 2.4937420630484843

Epoch: 5| Step: 4
Training loss: 2.3678421777056275
Validation loss: 2.4950537716766474

Epoch: 5| Step: 5
Training loss: 2.891084541702388
Validation loss: 2.504455471360426

Epoch: 5| Step: 6
Training loss: 2.9733906664545255
Validation loss: 2.5074448800200124

Epoch: 5| Step: 7
Training loss: 3.056781958094338
Validation loss: 2.5001759574864604

Epoch: 5| Step: 8
Training loss: 3.2423889832914443
Validation loss: 2.5005832668519825

Epoch: 5| Step: 9
Training loss: 3.134470056402655
Validation loss: 2.49179291485745

Epoch: 5| Step: 10
Training loss: 2.9227502501339733
Validation loss: 2.491079567582894

Epoch: 97| Step: 0
Training loss: 2.3531126065073487
Validation loss: 2.490953486905717

Epoch: 5| Step: 1
Training loss: 3.165339760766042
Validation loss: 2.4938030522142833

Epoch: 5| Step: 2
Training loss: 2.8898499145607066
Validation loss: 2.504945291742904

Epoch: 5| Step: 3
Training loss: 2.498084001660434
Validation loss: 2.5122608438115743

Epoch: 5| Step: 4
Training loss: 2.9887982089607052
Validation loss: 2.5351193831101457

Epoch: 5| Step: 5
Training loss: 3.302830961451754
Validation loss: 2.532285224657075

Epoch: 5| Step: 6
Training loss: 2.988521710862477
Validation loss: 2.532524329959042

Epoch: 5| Step: 7
Training loss: 2.7465529946381806
Validation loss: 2.533738460014563

Epoch: 5| Step: 8
Training loss: 2.4333646859365703
Validation loss: 2.523922456238143

Epoch: 5| Step: 9
Training loss: 2.64590224729486
Validation loss: 2.5190548041133116

Epoch: 5| Step: 10
Training loss: 2.8415706793569733
Validation loss: 2.5116170298245426

Epoch: 98| Step: 0
Training loss: 2.9964663038925985
Validation loss: 2.5158955255268167

Epoch: 5| Step: 1
Training loss: 2.754685138911265
Validation loss: 2.5211410219423316

Epoch: 5| Step: 2
Training loss: 2.653195049318192
Validation loss: 2.532950740068888

Epoch: 5| Step: 3
Training loss: 2.888543941819269
Validation loss: 2.546674668046575

Epoch: 5| Step: 4
Training loss: 2.9531601999596933
Validation loss: 2.569787652188931

Epoch: 5| Step: 5
Training loss: 3.198748468992725
Validation loss: 2.554380385050859

Epoch: 5| Step: 6
Training loss: 2.808188460902473
Validation loss: 2.5468806237720414

Epoch: 5| Step: 7
Training loss: 2.6308850214217196
Validation loss: 2.50331083635675

Epoch: 5| Step: 8
Training loss: 2.902472060641614
Validation loss: 2.496876882382748

Epoch: 5| Step: 9
Training loss: 2.694215413045982
Validation loss: 2.4920902084692282

Epoch: 5| Step: 10
Training loss: 2.472347873061582
Validation loss: 2.4866612000100003

Epoch: 99| Step: 0
Training loss: 3.257082923777545
Validation loss: 2.491527246562655

Epoch: 5| Step: 1
Training loss: 2.5754397192750655
Validation loss: 2.4863386607069526

Epoch: 5| Step: 2
Training loss: 3.096967315067782
Validation loss: 2.483782605201718

Epoch: 5| Step: 3
Training loss: 2.7837860032465387
Validation loss: 2.4890200684446264

Epoch: 5| Step: 4
Training loss: 2.380207676682218
Validation loss: 2.5066091994514417

Epoch: 5| Step: 5
Training loss: 2.479545649778099
Validation loss: 2.510903263091542

Epoch: 5| Step: 6
Training loss: 2.4494107063184685
Validation loss: 2.514327946760879

Epoch: 5| Step: 7
Training loss: 2.77073292562264
Validation loss: 2.5169027328469786

Epoch: 5| Step: 8
Training loss: 2.9950390169025436
Validation loss: 2.5084445931010566

Epoch: 5| Step: 9
Training loss: 3.135061926222511
Validation loss: 2.5168360110695676

Epoch: 5| Step: 10
Training loss: 2.912769838857041
Validation loss: 2.526451757693455

Epoch: 100| Step: 0
Training loss: 3.0691366103647217
Validation loss: 2.527695398642216

Epoch: 5| Step: 1
Training loss: 2.6776857601235178
Validation loss: 2.5155328167999778

Epoch: 5| Step: 2
Training loss: 3.0184202531431836
Validation loss: 2.516923987249291

Epoch: 5| Step: 3
Training loss: 2.6262942257134614
Validation loss: 2.5072563494421014

Epoch: 5| Step: 4
Training loss: 2.5927467704019396
Validation loss: 2.4967841373884814

Epoch: 5| Step: 5
Training loss: 2.94417576393718
Validation loss: 2.4966355665441204

Epoch: 5| Step: 6
Training loss: 3.110882724220336
Validation loss: 2.4885970846484597

Epoch: 5| Step: 7
Training loss: 3.0227198180226034
Validation loss: 2.4853337484276916

Epoch: 5| Step: 8
Training loss: 2.355163655679099
Validation loss: 2.4857708061838326

Epoch: 5| Step: 9
Training loss: 2.6717987942006216
Validation loss: 2.4857789103321415

Epoch: 5| Step: 10
Training loss: 2.6724255981651335
Validation loss: 2.4892382245912406

Testing loss: 2.7323415697615934
