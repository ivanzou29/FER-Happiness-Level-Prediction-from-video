Epoch: 1| Step: 0
Training loss: 6.604276670227714
Validation loss: 5.748595670368839

Epoch: 6| Step: 1
Training loss: 6.4182231385980915
Validation loss: 5.729598760186548

Epoch: 6| Step: 2
Training loss: 5.144204050374523
Validation loss: 5.7090353872739765

Epoch: 6| Step: 3
Training loss: 5.268079598742924
Validation loss: 5.686783291187128

Epoch: 6| Step: 4
Training loss: 5.549259672533626
Validation loss: 5.661345516398903

Epoch: 6| Step: 5
Training loss: 5.765826792920252
Validation loss: 5.631745626808443

Epoch: 6| Step: 6
Training loss: 5.3438583273810805
Validation loss: 5.598653071085907

Epoch: 6| Step: 7
Training loss: 6.409204611147829
Validation loss: 5.560547029909807

Epoch: 6| Step: 8
Training loss: 5.516722486200125
Validation loss: 5.519110633010351

Epoch: 6| Step: 9
Training loss: 5.830661743192224
Validation loss: 5.472360178878343

Epoch: 6| Step: 10
Training loss: 5.529084897197278
Validation loss: 5.419605161693581

Epoch: 6| Step: 11
Training loss: 4.1850205098040405
Validation loss: 5.359609260510943

Epoch: 6| Step: 12
Training loss: 5.311570389139101
Validation loss: 5.295087086611153

Epoch: 6| Step: 13
Training loss: 4.725182399559454
Validation loss: 5.224328824839908

Epoch: 2| Step: 0
Training loss: 5.397438939620678
Validation loss: 5.1513712036322445

Epoch: 6| Step: 1
Training loss: 4.891386417677112
Validation loss: 5.07364253029129

Epoch: 6| Step: 2
Training loss: 4.443100095457219
Validation loss: 4.994135481433904

Epoch: 6| Step: 3
Training loss: 4.6245690222287115
Validation loss: 4.913801151105741

Epoch: 6| Step: 4
Training loss: 5.04048247919253
Validation loss: 4.832409679571496

Epoch: 6| Step: 5
Training loss: 5.41774326287043
Validation loss: 4.752500343374311

Epoch: 6| Step: 6
Training loss: 5.148014404324147
Validation loss: 4.671188891811122

Epoch: 6| Step: 7
Training loss: 4.656027154902288
Validation loss: 4.591852980225875

Epoch: 6| Step: 8
Training loss: 5.082702639284022
Validation loss: 4.517052536470955

Epoch: 6| Step: 9
Training loss: 4.652633183954393
Validation loss: 4.448641108700879

Epoch: 6| Step: 10
Training loss: 4.409178281595844
Validation loss: 4.3890093158672805

Epoch: 6| Step: 11
Training loss: 3.694683126198394
Validation loss: 4.341085938302547

Epoch: 6| Step: 12
Training loss: 4.043273029763498
Validation loss: 4.300656656433924

Epoch: 6| Step: 13
Training loss: 4.799231928727022
Validation loss: 4.265997723917498

Epoch: 3| Step: 0
Training loss: 3.3278822832746062
Validation loss: 4.229984733926166

Epoch: 6| Step: 1
Training loss: 3.9402620830603547
Validation loss: 4.193390911133551

Epoch: 6| Step: 2
Training loss: 5.575235767254479
Validation loss: 4.158618361703339

Epoch: 6| Step: 3
Training loss: 3.772983815975143
Validation loss: 4.12250937443207

Epoch: 6| Step: 4
Training loss: 4.261180084899297
Validation loss: 4.088871246570759

Epoch: 6| Step: 5
Training loss: 3.551797282912386
Validation loss: 4.057134848180271

Epoch: 6| Step: 6
Training loss: 3.934921752655817
Validation loss: 4.02945361980421

Epoch: 6| Step: 7
Training loss: 3.6131315952960747
Validation loss: 4.006127404518678

Epoch: 6| Step: 8
Training loss: 4.037237880453558
Validation loss: 3.9852322734920103

Epoch: 6| Step: 9
Training loss: 4.574631956544898
Validation loss: 3.966508695793982

Epoch: 6| Step: 10
Training loss: 3.1959754610516087
Validation loss: 3.944180926699951

Epoch: 6| Step: 11
Training loss: 4.92766702540182
Validation loss: 3.918729846550106

Epoch: 6| Step: 12
Training loss: 4.812988058335759
Validation loss: 3.89307791015187

Epoch: 6| Step: 13
Training loss: 4.39000504756281
Validation loss: 3.8698970751780086

Epoch: 4| Step: 0
Training loss: 3.5923485718564048
Validation loss: 3.850176915532183

Epoch: 6| Step: 1
Training loss: 3.491830555810686
Validation loss: 3.8314674075267807

Epoch: 6| Step: 2
Training loss: 3.654309532188462
Validation loss: 3.8135227127416025

Epoch: 6| Step: 3
Training loss: 4.578594925754038
Validation loss: 3.79197622146903

Epoch: 6| Step: 4
Training loss: 4.088447689588072
Validation loss: 3.7705952123798436

Epoch: 6| Step: 5
Training loss: 3.916150904575776
Validation loss: 3.74851956695297

Epoch: 6| Step: 6
Training loss: 3.7072208464588328
Validation loss: 3.7280307583579337

Epoch: 6| Step: 7
Training loss: 3.787052211162825
Validation loss: 3.706631926330012

Epoch: 6| Step: 8
Training loss: 3.4347471832123904
Validation loss: 3.6894725503583135

Epoch: 6| Step: 9
Training loss: 4.432659679275569
Validation loss: 3.673556752713843

Epoch: 6| Step: 10
Training loss: 3.851039270605419
Validation loss: 3.659146387579183

Epoch: 6| Step: 11
Training loss: 4.095629544522648
Validation loss: 3.642347687078703

Epoch: 6| Step: 12
Training loss: 3.5836847413916857
Validation loss: 3.6247605360326753

Epoch: 6| Step: 13
Training loss: 4.537923174164492
Validation loss: 3.6122124456256888

Epoch: 5| Step: 0
Training loss: 3.4459741350687745
Validation loss: 3.5981130600895384

Epoch: 6| Step: 1
Training loss: 3.826505855765673
Validation loss: 3.584769471754426

Epoch: 6| Step: 2
Training loss: 4.157756790424412
Validation loss: 3.5717677599898114

Epoch: 6| Step: 3
Training loss: 2.946591208456962
Validation loss: 3.556821101082155

Epoch: 6| Step: 4
Training loss: 3.905523125731061
Validation loss: 3.5456334280564814

Epoch: 6| Step: 5
Training loss: 3.97108066638485
Validation loss: 3.530109030618822

Epoch: 6| Step: 6
Training loss: 4.246058487592194
Validation loss: 3.5165049818185468

Epoch: 6| Step: 7
Training loss: 3.654129848200494
Validation loss: 3.5042314382063626

Epoch: 6| Step: 8
Training loss: 4.430765118454386
Validation loss: 3.488749415681383

Epoch: 6| Step: 9
Training loss: 3.2767796172979584
Validation loss: 3.474906094854331

Epoch: 6| Step: 10
Training loss: 3.6227867999646413
Validation loss: 3.463401119622841

Epoch: 6| Step: 11
Training loss: 3.0470889285374536
Validation loss: 3.4544600645083303

Epoch: 6| Step: 12
Training loss: 3.209247376338287
Validation loss: 3.4409866892030925

Epoch: 6| Step: 13
Training loss: 4.187073187640993
Validation loss: 3.4251034465844667

Epoch: 6| Step: 0
Training loss: 3.5609964242824566
Validation loss: 3.413142296650279

Epoch: 6| Step: 1
Training loss: 2.686723286368935
Validation loss: 3.3992702415776312

Epoch: 6| Step: 2
Training loss: 3.7350538586431834
Validation loss: 3.391610876429114

Epoch: 6| Step: 3
Training loss: 3.5139488463046527
Validation loss: 3.381222984438502

Epoch: 6| Step: 4
Training loss: 3.9836243165379566
Validation loss: 3.3687785591133896

Epoch: 6| Step: 5
Training loss: 3.5781609812430784
Validation loss: 3.357075353265992

Epoch: 6| Step: 6
Training loss: 4.155649701126957
Validation loss: 3.3460196121171912

Epoch: 6| Step: 7
Training loss: 3.601055382630822
Validation loss: 3.3365406807969142

Epoch: 6| Step: 8
Training loss: 3.5060518259764937
Validation loss: 3.3277295574942736

Epoch: 6| Step: 9
Training loss: 3.6978146104654277
Validation loss: 3.3179095361090325

Epoch: 6| Step: 10
Training loss: 3.0966130119852067
Validation loss: 3.308971498480918

Epoch: 6| Step: 11
Training loss: 3.1545955740924994
Validation loss: 3.2971258114218953

Epoch: 6| Step: 12
Training loss: 4.49060943749478
Validation loss: 3.2883028454754926

Epoch: 6| Step: 13
Training loss: 2.2739556105616776
Validation loss: 3.2775212803918343

Epoch: 7| Step: 0
Training loss: 3.4038786026569716
Validation loss: 3.2656324876865375

Epoch: 6| Step: 1
Training loss: 3.04013819154555
Validation loss: 3.2593598878190972

Epoch: 6| Step: 2
Training loss: 2.8252913468274397
Validation loss: 3.252820713224592

Epoch: 6| Step: 3
Training loss: 3.4342801359506274
Validation loss: 3.255760839945775

Epoch: 6| Step: 4
Training loss: 2.8870722201979415
Validation loss: 3.2439456454943816

Epoch: 6| Step: 5
Training loss: 4.022169191023757
Validation loss: 3.255885973024351

Epoch: 6| Step: 6
Training loss: 3.754356651000946
Validation loss: 3.239642901836232

Epoch: 6| Step: 7
Training loss: 3.604179308801136
Validation loss: 3.246191898525234

Epoch: 6| Step: 8
Training loss: 4.052155690989496
Validation loss: 3.2494151060029335

Epoch: 6| Step: 9
Training loss: 4.02561474009182
Validation loss: 3.233528553146143

Epoch: 6| Step: 10
Training loss: 3.5655274494009497
Validation loss: 3.224608039360033

Epoch: 6| Step: 11
Training loss: 3.488199777708981
Validation loss: 3.2267267467977074

Epoch: 6| Step: 12
Training loss: 3.1280575862178934
Validation loss: 3.22205243661096

Epoch: 6| Step: 13
Training loss: 3.311122679921307
Validation loss: 3.2025262120390563

Epoch: 8| Step: 0
Training loss: 3.481920960451156
Validation loss: 3.189723623187491

Epoch: 6| Step: 1
Training loss: 3.4942527996073034
Validation loss: 3.1812354144247883

Epoch: 6| Step: 2
Training loss: 3.7835834963823225
Validation loss: 3.175772536561383

Epoch: 6| Step: 3
Training loss: 4.165114507852742
Validation loss: 3.166286755512251

Epoch: 6| Step: 4
Training loss: 3.156697458709845
Validation loss: 3.1595420194331925

Epoch: 6| Step: 5
Training loss: 3.4605051291540323
Validation loss: 3.1548448633253527

Epoch: 6| Step: 6
Training loss: 3.868672403719054
Validation loss: 3.1453828957071748

Epoch: 6| Step: 7
Training loss: 3.167877685141132
Validation loss: 3.1374020692460065

Epoch: 6| Step: 8
Training loss: 3.9143831346339915
Validation loss: 3.1299007070028337

Epoch: 6| Step: 9
Training loss: 3.4066577632312423
Validation loss: 3.1245377754543218

Epoch: 6| Step: 10
Training loss: 2.695842126972492
Validation loss: 3.118232970549018

Epoch: 6| Step: 11
Training loss: 3.0623567508748724
Validation loss: 3.150943748005624

Epoch: 6| Step: 12
Training loss: 2.8174887599230063
Validation loss: 3.111771268932977

Epoch: 6| Step: 13
Training loss: 2.649567849532471
Validation loss: 3.1073225980080235

Epoch: 9| Step: 0
Training loss: 3.742514832899811
Validation loss: 3.104487627516231

Epoch: 6| Step: 1
Training loss: 3.955018566295386
Validation loss: 3.1008540667682993

Epoch: 6| Step: 2
Training loss: 3.5957875985205683
Validation loss: 3.0971468096497317

Epoch: 6| Step: 3
Training loss: 2.813693323229719
Validation loss: 3.0856530565828764

Epoch: 6| Step: 4
Training loss: 1.9688908360076722
Validation loss: 3.0779797561547917

Epoch: 6| Step: 5
Training loss: 3.193857771217835
Validation loss: 3.076667656780406

Epoch: 6| Step: 6
Training loss: 3.4074356395439485
Validation loss: 3.0792488997558065

Epoch: 6| Step: 7
Training loss: 3.5131037508843286
Validation loss: 3.063548354187845

Epoch: 6| Step: 8
Training loss: 3.001425086732889
Validation loss: 3.05726481447885

Epoch: 6| Step: 9
Training loss: 2.8532009486507164
Validation loss: 3.053683078438526

Epoch: 6| Step: 10
Training loss: 3.01107207206891
Validation loss: 3.0492202437155242

Epoch: 6| Step: 11
Training loss: 3.91106563515186
Validation loss: 3.04370891860602

Epoch: 6| Step: 12
Training loss: 3.91966519658196
Validation loss: 3.0387993695036672

Epoch: 6| Step: 13
Training loss: 3.60983180998937
Validation loss: 3.0349323726859008

Epoch: 10| Step: 0
Training loss: 3.16352172751492
Validation loss: 3.030160521869419

Epoch: 6| Step: 1
Training loss: 2.4505695226023323
Validation loss: 3.0272375524698347

Epoch: 6| Step: 2
Training loss: 2.804980844442473
Validation loss: 3.0253238494116914

Epoch: 6| Step: 3
Training loss: 3.787711683344256
Validation loss: 3.014391197477158

Epoch: 6| Step: 4
Training loss: 2.980999220690902
Validation loss: 3.0171886676625417

Epoch: 6| Step: 5
Training loss: 3.8197235714422377
Validation loss: 3.01238604247378

Epoch: 6| Step: 6
Training loss: 2.915368163478755
Validation loss: 3.02815293203809

Epoch: 6| Step: 7
Training loss: 3.4304582081795436
Validation loss: 3.0138351022675383

Epoch: 6| Step: 8
Training loss: 3.5000128064602483
Validation loss: 3.01608959004626

Epoch: 6| Step: 9
Training loss: 3.992044046889043
Validation loss: 2.9991362534906445

Epoch: 6| Step: 10
Training loss: 2.6398947343647268
Validation loss: 2.9913145797029994

Epoch: 6| Step: 11
Training loss: 3.1720292378024566
Validation loss: 3.0573377129743085

Epoch: 6| Step: 12
Training loss: 3.7510247419858795
Validation loss: 3.0485500210878134

Epoch: 6| Step: 13
Training loss: 3.641585718531167
Validation loss: 2.9734805126460095

Epoch: 11| Step: 0
Training loss: 3.305532649483553
Validation loss: 2.9826911187824736

Epoch: 6| Step: 1
Training loss: 2.8812925058402916
Validation loss: 3.062772797720571

Epoch: 6| Step: 2
Training loss: 2.8351498185119253
Validation loss: 3.0996791041037275

Epoch: 6| Step: 3
Training loss: 3.5525514325922685
Validation loss: 3.043848135095296

Epoch: 6| Step: 4
Training loss: 3.1630642293365923
Validation loss: 2.9791627954592266

Epoch: 6| Step: 5
Training loss: 3.7298513171141714
Validation loss: 2.955435934731931

Epoch: 6| Step: 6
Training loss: 3.213543282399732
Validation loss: 3.03147831843374

Epoch: 6| Step: 7
Training loss: 3.3265976244145823
Validation loss: 3.0937126143322002

Epoch: 6| Step: 8
Training loss: 3.777533351869617
Validation loss: 3.076008403527902

Epoch: 6| Step: 9
Training loss: 2.665398315951712
Validation loss: 3.0102932732931147

Epoch: 6| Step: 10
Training loss: 3.665381220705839
Validation loss: 2.971006554589916

Epoch: 6| Step: 11
Training loss: 3.0820931354686745
Validation loss: 2.968533183428909

Epoch: 6| Step: 12
Training loss: 3.120332512865372
Validation loss: 2.9896425090768775

Epoch: 6| Step: 13
Training loss: 3.988661431285906
Validation loss: 3.013970236180335

Epoch: 12| Step: 0
Training loss: 2.8004134826536107
Validation loss: 3.0232972529121036

Epoch: 6| Step: 1
Training loss: 3.462269546055867
Validation loss: 2.965207757869447

Epoch: 6| Step: 2
Training loss: 2.7806574158034105
Validation loss: 2.946546389077977

Epoch: 6| Step: 3
Training loss: 2.7593708768405545
Validation loss: 2.9546693226685647

Epoch: 6| Step: 4
Training loss: 3.9259262741403274
Validation loss: 2.9791640156817945

Epoch: 6| Step: 5
Training loss: 3.494410547584992
Validation loss: 2.983247230005873

Epoch: 6| Step: 6
Training loss: 3.131595365623819
Validation loss: 2.9801105366847715

Epoch: 6| Step: 7
Training loss: 3.691772830260419
Validation loss: 2.9707189829745593

Epoch: 6| Step: 8
Training loss: 3.3836998601608186
Validation loss: 2.951961673857496

Epoch: 6| Step: 9
Training loss: 4.1539839683667825
Validation loss: 2.924952501322043

Epoch: 6| Step: 10
Training loss: 3.033203282205807
Validation loss: 2.9171257981972025

Epoch: 6| Step: 11
Training loss: 2.654940652704833
Validation loss: 2.9313086728623894

Epoch: 6| Step: 12
Training loss: 2.9045740032543255
Validation loss: 2.958895552883339

Epoch: 6| Step: 13
Training loss: 3.189393023679752
Validation loss: 3.092246016417782

Epoch: 13| Step: 0
Training loss: 3.625586495144869
Validation loss: 3.0549819108256178

Epoch: 6| Step: 1
Training loss: 2.7068741217475054
Validation loss: 2.939917593032607

Epoch: 6| Step: 2
Training loss: 3.105532318040428
Validation loss: 2.9115661099827452

Epoch: 6| Step: 3
Training loss: 3.1963400832316546
Validation loss: 2.9023386197882632

Epoch: 6| Step: 4
Training loss: 3.716365787204839
Validation loss: 2.9056639947753586

Epoch: 6| Step: 5
Training loss: 2.6312745806707967
Validation loss: 2.915292103642315

Epoch: 6| Step: 6
Training loss: 3.36278953014789
Validation loss: 2.9233724886960997

Epoch: 6| Step: 7
Training loss: 3.4132087390730113
Validation loss: 2.91198241472335

Epoch: 6| Step: 8
Training loss: 3.173524023892778
Validation loss: 2.912218193311648

Epoch: 6| Step: 9
Training loss: 3.5389985000852935
Validation loss: 2.911578190449141

Epoch: 6| Step: 10
Training loss: 3.5913542349772274
Validation loss: 2.94725447888784

Epoch: 6| Step: 11
Training loss: 2.9160736752740775
Validation loss: 2.8995744665271794

Epoch: 6| Step: 12
Training loss: 2.8926776917789554
Validation loss: 2.8892565369516463

Epoch: 6| Step: 13
Training loss: 3.2497150589670993
Validation loss: 2.8906930903802053

Epoch: 14| Step: 0
Training loss: 3.6152309456865153
Validation loss: 2.945365861104839

Epoch: 6| Step: 1
Training loss: 3.05218965694554
Validation loss: 2.896616182695792

Epoch: 6| Step: 2
Training loss: 2.45308029231255
Validation loss: 2.9038344255178705

Epoch: 6| Step: 3
Training loss: 3.286235981153533
Validation loss: 2.93629760587508

Epoch: 6| Step: 4
Training loss: 3.179749134413011
Validation loss: 2.958230926899577

Epoch: 6| Step: 5
Training loss: 3.4584293275555433
Validation loss: 2.9946808377268144

Epoch: 6| Step: 6
Training loss: 2.9666949738712884
Validation loss: 2.9884779492527005

Epoch: 6| Step: 7
Training loss: 3.7159041085738758
Validation loss: 2.9661666554060795

Epoch: 6| Step: 8
Training loss: 2.5706582807876335
Validation loss: 2.8999170820484594

Epoch: 6| Step: 9
Training loss: 3.220778335424141
Validation loss: 2.8945187777680257

Epoch: 6| Step: 10
Training loss: 3.66657045989545
Validation loss: 2.917917303106306

Epoch: 6| Step: 11
Training loss: 3.9613978251991036
Validation loss: 2.913502361643683

Epoch: 6| Step: 12
Training loss: 2.780522454930995
Validation loss: 2.905986746179092

Epoch: 6| Step: 13
Training loss: 2.7738502732555594
Validation loss: 2.900456490336244

Epoch: 15| Step: 0
Training loss: 3.4173143904874506
Validation loss: 2.8918676568264066

Epoch: 6| Step: 1
Training loss: 3.8481452437527097
Validation loss: 2.8883183822196115

Epoch: 6| Step: 2
Training loss: 3.472276836389609
Validation loss: 2.8706861521259124

Epoch: 6| Step: 3
Training loss: 2.8305586149652346
Validation loss: 2.8689841301601633

Epoch: 6| Step: 4
Training loss: 2.1930296625443897
Validation loss: 2.8769942327343756

Epoch: 6| Step: 5
Training loss: 2.917159901648291
Validation loss: 2.8828389525370537

Epoch: 6| Step: 6
Training loss: 3.4673303671820928
Validation loss: 2.8873693879767663

Epoch: 6| Step: 7
Training loss: 2.907657733551767
Validation loss: 2.8882531631930197

Epoch: 6| Step: 8
Training loss: 3.3028178235502974
Validation loss: 2.880535272213904

Epoch: 6| Step: 9
Training loss: 3.1168746600046657
Validation loss: 2.8766574620672465

Epoch: 6| Step: 10
Training loss: 3.1887402085199166
Validation loss: 2.872153454411013

Epoch: 6| Step: 11
Training loss: 2.9504543924328286
Validation loss: 2.877256192970929

Epoch: 6| Step: 12
Training loss: 3.6021741236020293
Validation loss: 2.8838570209250443

Epoch: 6| Step: 13
Training loss: 3.2645591931321856
Validation loss: 2.856776253869385

Epoch: 16| Step: 0
Training loss: 3.118347716904019
Validation loss: 2.850802901762525

Epoch: 6| Step: 1
Training loss: 2.74843596284356
Validation loss: 2.8509480141180434

Epoch: 6| Step: 2
Training loss: 3.932821976563498
Validation loss: 2.850404401216691

Epoch: 6| Step: 3
Training loss: 2.9050446338474725
Validation loss: 2.8552025074848166

Epoch: 6| Step: 4
Training loss: 2.9229874558598876
Validation loss: 2.8575485746779825

Epoch: 6| Step: 5
Training loss: 2.9810777594435742
Validation loss: 2.8543361631154895

Epoch: 6| Step: 6
Training loss: 3.038578887352291
Validation loss: 2.854236086067128

Epoch: 6| Step: 7
Training loss: 2.8069732617557857
Validation loss: 2.8525407494013693

Epoch: 6| Step: 8
Training loss: 2.6689102053296114
Validation loss: 2.847616776778339

Epoch: 6| Step: 9
Training loss: 3.0397298908699506
Validation loss: 2.84882937113563

Epoch: 6| Step: 10
Training loss: 3.5867494814882934
Validation loss: 2.8463454529209016

Epoch: 6| Step: 11
Training loss: 3.8437184898511534
Validation loss: 2.8470455556731316

Epoch: 6| Step: 12
Training loss: 3.416244542787159
Validation loss: 2.8440083996302135

Epoch: 6| Step: 13
Training loss: 3.3157557196560243
Validation loss: 2.8410810973001506

Epoch: 17| Step: 0
Training loss: 3.3827344079287336
Validation loss: 2.84672884751167

Epoch: 6| Step: 1
Training loss: 2.9748777091913468
Validation loss: 2.8510781729093844

Epoch: 6| Step: 2
Training loss: 2.7357587528278726
Validation loss: 2.8421346445865088

Epoch: 6| Step: 3
Training loss: 3.129790639487166
Validation loss: 2.838885673788055

Epoch: 6| Step: 4
Training loss: 3.1488812230938974
Validation loss: 2.838000852814907

Epoch: 6| Step: 5
Training loss: 2.5752993733715295
Validation loss: 2.8384091594227145

Epoch: 6| Step: 6
Training loss: 3.128000268726386
Validation loss: 2.8437057747704295

Epoch: 6| Step: 7
Training loss: 3.517800298152683
Validation loss: 2.8454055051119607

Epoch: 6| Step: 8
Training loss: 3.3691895942999213
Validation loss: 2.8621264195162843

Epoch: 6| Step: 9
Training loss: 3.190411154579628
Validation loss: 2.8475884737652764

Epoch: 6| Step: 10
Training loss: 3.034692598766199
Validation loss: 2.8355850077048363

Epoch: 6| Step: 11
Training loss: 3.703742382236131
Validation loss: 2.839186071062909

Epoch: 6| Step: 12
Training loss: 2.8269392868447576
Validation loss: 2.8354191410455676

Epoch: 6| Step: 13
Training loss: 3.443898020919204
Validation loss: 2.8331112545380153

Epoch: 18| Step: 0
Training loss: 3.523009280553933
Validation loss: 2.831224784040659

Epoch: 6| Step: 1
Training loss: 3.4629543791279414
Validation loss: 2.828574205265885

Epoch: 6| Step: 2
Training loss: 3.0544283627695403
Validation loss: 2.8268327794697647

Epoch: 6| Step: 3
Training loss: 3.266193541174969
Validation loss: 2.8258467654359025

Epoch: 6| Step: 4
Training loss: 3.5172042351438546
Validation loss: 2.822846792802002

Epoch: 6| Step: 5
Training loss: 2.8040164580413136
Validation loss: 2.823547836401336

Epoch: 6| Step: 6
Training loss: 2.950661898565886
Validation loss: 2.82221700356286

Epoch: 6| Step: 7
Training loss: 3.1589784820490356
Validation loss: 2.8254795404695225

Epoch: 6| Step: 8
Training loss: 3.489778579639704
Validation loss: 2.825215775669518

Epoch: 6| Step: 9
Training loss: 2.2987733638337393
Validation loss: 2.820813618051523

Epoch: 6| Step: 10
Training loss: 2.1591979068727585
Validation loss: 2.828407447084597

Epoch: 6| Step: 11
Training loss: 3.7020504193121013
Validation loss: 2.8331211802071277

Epoch: 6| Step: 12
Training loss: 3.056731103892507
Validation loss: 2.8235310120352346

Epoch: 6| Step: 13
Training loss: 3.312915847874814
Validation loss: 2.821794212641277

Epoch: 19| Step: 0
Training loss: 3.1807160834420283
Validation loss: 2.8207346459625446

Epoch: 6| Step: 1
Training loss: 2.9743697131888065
Validation loss: 2.8190529507365754

Epoch: 6| Step: 2
Training loss: 2.844097912644103
Validation loss: 2.8176230456230553

Epoch: 6| Step: 3
Training loss: 3.466290951200436
Validation loss: 2.816941502208286

Epoch: 6| Step: 4
Training loss: 3.1253544415693097
Validation loss: 2.8151622245362686

Epoch: 6| Step: 5
Training loss: 2.8300791359340844
Validation loss: 2.814663003091619

Epoch: 6| Step: 6
Training loss: 3.226952776269879
Validation loss: 2.814202155217711

Epoch: 6| Step: 7
Training loss: 3.335752531190049
Validation loss: 2.8158498742458025

Epoch: 6| Step: 8
Training loss: 3.1546938241911286
Validation loss: 2.813448879188055

Epoch: 6| Step: 9
Training loss: 3.1890243176609383
Validation loss: 2.8150617101429565

Epoch: 6| Step: 10
Training loss: 3.189115227240494
Validation loss: 2.813397703388872

Epoch: 6| Step: 11
Training loss: 2.8519482495399875
Validation loss: 2.816226777091843

Epoch: 6| Step: 12
Training loss: 3.1591863287217676
Validation loss: 2.819724639255109

Epoch: 6| Step: 13
Training loss: 3.3290893876739096
Validation loss: 2.827610001385469

Epoch: 20| Step: 0
Training loss: 2.8856960854502693
Validation loss: 2.8298757696704215

Epoch: 6| Step: 1
Training loss: 3.8772987192472503
Validation loss: 2.832822985955749

Epoch: 6| Step: 2
Training loss: 3.208807839978307
Validation loss: 2.8233323380168427

Epoch: 6| Step: 3
Training loss: 2.8736801434986936
Validation loss: 2.8183054266443106

Epoch: 6| Step: 4
Training loss: 2.9240639386994496
Validation loss: 2.8159867507714007

Epoch: 6| Step: 5
Training loss: 3.0689147407768154
Validation loss: 2.8158262739212083

Epoch: 6| Step: 6
Training loss: 3.430127786863969
Validation loss: 2.8170532868720386

Epoch: 6| Step: 7
Training loss: 3.666275494835095
Validation loss: 2.815451695846453

Epoch: 6| Step: 8
Training loss: 2.778618757312044
Validation loss: 2.808988191219952

Epoch: 6| Step: 9
Training loss: 2.792221716365354
Validation loss: 2.8063390168148987

Epoch: 6| Step: 10
Training loss: 2.887636361473431
Validation loss: 2.8022002963386377

Epoch: 6| Step: 11
Training loss: 2.5608926709797566
Validation loss: 2.801565129156505

Epoch: 6| Step: 12
Training loss: 3.3137597621571038
Validation loss: 2.8028449015408583

Epoch: 6| Step: 13
Training loss: 3.326128293534215
Validation loss: 2.805026327299204

Epoch: 21| Step: 0
Training loss: 3.39876482910872
Validation loss: 2.7996251173194673

Epoch: 6| Step: 1
Training loss: 3.6373112213333356
Validation loss: 2.800334362789022

Epoch: 6| Step: 2
Training loss: 3.860096975897118
Validation loss: 2.799380219588439

Epoch: 6| Step: 3
Training loss: 2.809119163465363
Validation loss: 2.797963008512565

Epoch: 6| Step: 4
Training loss: 3.3548860587998064
Validation loss: 2.796740825397862

Epoch: 6| Step: 5
Training loss: 3.00935177739612
Validation loss: 2.796576517869221

Epoch: 6| Step: 6
Training loss: 2.998907367096113
Validation loss: 2.7956566365083004

Epoch: 6| Step: 7
Training loss: 3.4823723071170862
Validation loss: 2.794750468837261

Epoch: 6| Step: 8
Training loss: 2.2691818204670993
Validation loss: 2.7906001984459734

Epoch: 6| Step: 9
Training loss: 2.7350255573759292
Validation loss: 2.7944627245687816

Epoch: 6| Step: 10
Training loss: 2.4303384871661247
Validation loss: 2.7952141119165663

Epoch: 6| Step: 11
Training loss: 2.8661339094738985
Validation loss: 2.7943172431292673

Epoch: 6| Step: 12
Training loss: 3.766177948048226
Validation loss: 2.8000313584231487

Epoch: 6| Step: 13
Training loss: 1.7371298416266765
Validation loss: 2.805513610663019

Epoch: 22| Step: 0
Training loss: 3.105025272972956
Validation loss: 2.821084813582429

Epoch: 6| Step: 1
Training loss: 2.6740016393321224
Validation loss: 2.8337277690402405

Epoch: 6| Step: 2
Training loss: 3.742573186634032
Validation loss: 2.841573542911041

Epoch: 6| Step: 3
Training loss: 3.252486085033632
Validation loss: 2.812058012766918

Epoch: 6| Step: 4
Training loss: 3.395868141292361
Validation loss: 2.7897754600240194

Epoch: 6| Step: 5
Training loss: 2.767836295545972
Validation loss: 2.78439529374905

Epoch: 6| Step: 6
Training loss: 3.4610080410418362
Validation loss: 2.782615167113066

Epoch: 6| Step: 7
Training loss: 2.39895614334605
Validation loss: 2.7836936750094314

Epoch: 6| Step: 8
Training loss: 2.699579902038733
Validation loss: 2.7876122728197648

Epoch: 6| Step: 9
Training loss: 3.2730921014542274
Validation loss: 2.781906093866417

Epoch: 6| Step: 10
Training loss: 2.342492949028355
Validation loss: 2.7803014188655006

Epoch: 6| Step: 11
Training loss: 3.3452507287727316
Validation loss: 2.7790962573272378

Epoch: 6| Step: 12
Training loss: 3.7379594144133335
Validation loss: 2.778278960951765

Epoch: 6| Step: 13
Training loss: 2.94998858174846
Validation loss: 2.779327646300084

Epoch: 23| Step: 0
Training loss: 2.8509587733118877
Validation loss: 2.775853445466813

Epoch: 6| Step: 1
Training loss: 2.7313121971887364
Validation loss: 2.772493220683216

Epoch: 6| Step: 2
Training loss: 2.872968536491467
Validation loss: 2.7727480673738802

Epoch: 6| Step: 3
Training loss: 3.577889647093972
Validation loss: 2.7703717677160866

Epoch: 6| Step: 4
Training loss: 2.653281224552211
Validation loss: 2.7714713975930816

Epoch: 6| Step: 5
Training loss: 2.6430896340108347
Validation loss: 2.784292371316192

Epoch: 6| Step: 6
Training loss: 3.1067817647293454
Validation loss: 2.800273117648928

Epoch: 6| Step: 7
Training loss: 3.269738631695887
Validation loss: 2.8070086532621246

Epoch: 6| Step: 8
Training loss: 3.7351931390015873
Validation loss: 2.8147598257414868

Epoch: 6| Step: 9
Training loss: 3.184648921666635
Validation loss: 2.809214779113364

Epoch: 6| Step: 10
Training loss: 2.859070308273115
Validation loss: 2.8026464661660073

Epoch: 6| Step: 11
Training loss: 2.7476963451367995
Validation loss: 2.8085416943345276

Epoch: 6| Step: 12
Training loss: 3.1956924175311086
Validation loss: 2.8153366331806047

Epoch: 6| Step: 13
Training loss: 4.055125188999954
Validation loss: 2.837297535222818

Epoch: 24| Step: 0
Training loss: 2.6202513112684636
Validation loss: 2.79148670002756

Epoch: 6| Step: 1
Training loss: 3.599065415610659
Validation loss: 2.7868834597426737

Epoch: 6| Step: 2
Training loss: 3.00827807501626
Validation loss: 2.8066878767130166

Epoch: 6| Step: 3
Training loss: 3.3082589404552434
Validation loss: 2.8075976963588283

Epoch: 6| Step: 4
Training loss: 2.8771422324664946
Validation loss: 2.812845164713771

Epoch: 6| Step: 5
Training loss: 2.5077065894083406
Validation loss: 2.8129692242246116

Epoch: 6| Step: 6
Training loss: 2.5469807795925297
Validation loss: 2.8075119359216316

Epoch: 6| Step: 7
Training loss: 3.136349476969525
Validation loss: 2.7822092947565156

Epoch: 6| Step: 8
Training loss: 3.0198818067449236
Validation loss: 2.768216756360818

Epoch: 6| Step: 9
Training loss: 3.771443537170475
Validation loss: 2.7664542313313056

Epoch: 6| Step: 10
Training loss: 3.827250976434795
Validation loss: 2.7657414040998933

Epoch: 6| Step: 11
Training loss: 2.9845680054572754
Validation loss: 2.7629555973855675

Epoch: 6| Step: 12
Training loss: 2.8146590528790263
Validation loss: 2.769131436563434

Epoch: 6| Step: 13
Training loss: 3.1345984488619765
Validation loss: 2.7749792227373256

Epoch: 25| Step: 0
Training loss: 3.0959012037378817
Validation loss: 2.770584461348836

Epoch: 6| Step: 1
Training loss: 2.859207231779938
Validation loss: 2.771921731592127

Epoch: 6| Step: 2
Training loss: 3.0765843287478685
Validation loss: 2.776445946963483

Epoch: 6| Step: 3
Training loss: 2.9007642922700705
Validation loss: 2.765669940805587

Epoch: 6| Step: 4
Training loss: 2.841788317480672
Validation loss: 2.7474640258916985

Epoch: 6| Step: 5
Training loss: 3.2738366077178016
Validation loss: 2.746864517003199

Epoch: 6| Step: 6
Training loss: 3.103962390160559
Validation loss: 2.744667095383605

Epoch: 6| Step: 7
Training loss: 3.4152338388567576
Validation loss: 2.7432082759915324

Epoch: 6| Step: 8
Training loss: 3.3191687195854787
Validation loss: 2.748143913079349

Epoch: 6| Step: 9
Training loss: 2.7285185959293954
Validation loss: 2.743274287436146

Epoch: 6| Step: 10
Training loss: 2.6229897931009787
Validation loss: 2.745332441903559

Epoch: 6| Step: 11
Training loss: 2.9480482595523116
Validation loss: 2.747713747668849

Epoch: 6| Step: 12
Training loss: 2.9176121587041286
Validation loss: 2.761405186142029

Epoch: 6| Step: 13
Training loss: 4.148702092182881
Validation loss: 2.765171789529865

Epoch: 26| Step: 0
Training loss: 3.160368847385678
Validation loss: 2.7755022450470546

Epoch: 6| Step: 1
Training loss: 2.875828167595577
Validation loss: 2.7642296696950144

Epoch: 6| Step: 2
Training loss: 3.009478219263545
Validation loss: 2.758657916210884

Epoch: 6| Step: 3
Training loss: 3.1264343021920116
Validation loss: 2.7541492311619766

Epoch: 6| Step: 4
Training loss: 2.901586749623106
Validation loss: 2.7412716907150148

Epoch: 6| Step: 5
Training loss: 1.9752266331304322
Validation loss: 2.732699736500984

Epoch: 6| Step: 6
Training loss: 3.143182576657786
Validation loss: 2.730683404442579

Epoch: 6| Step: 7
Training loss: 2.709900231583576
Validation loss: 2.730524441301054

Epoch: 6| Step: 8
Training loss: 4.058244324843204
Validation loss: 2.7334181472916566

Epoch: 6| Step: 9
Training loss: 3.5091559677184376
Validation loss: 2.728584575660519

Epoch: 6| Step: 10
Training loss: 3.5282639563119647
Validation loss: 2.725776174181385

Epoch: 6| Step: 11
Training loss: 3.026227742884967
Validation loss: 2.720715544108189

Epoch: 6| Step: 12
Training loss: 2.803024096251668
Validation loss: 2.718942546049361

Epoch: 6| Step: 13
Training loss: 2.0417205907227007
Validation loss: 2.722108909598651

Epoch: 27| Step: 0
Training loss: 3.379712664562969
Validation loss: 2.7203230087941384

Epoch: 6| Step: 1
Training loss: 2.447856128566315
Validation loss: 2.7243842551905577

Epoch: 6| Step: 2
Training loss: 2.736974559505419
Validation loss: 2.732658325980393

Epoch: 6| Step: 3
Training loss: 3.331058695669679
Validation loss: 2.7388158745040587

Epoch: 6| Step: 4
Training loss: 3.8414932697301234
Validation loss: 2.738366268921735

Epoch: 6| Step: 5
Training loss: 3.225249459724567
Validation loss: 2.7247875606852348

Epoch: 6| Step: 6
Training loss: 2.6234803115050696
Validation loss: 2.722347427795671

Epoch: 6| Step: 7
Training loss: 3.2804017923403
Validation loss: 2.725639286863074

Epoch: 6| Step: 8
Training loss: 3.09091210492645
Validation loss: 2.728794594502821

Epoch: 6| Step: 9
Training loss: 3.037309391022257
Validation loss: 2.723793203754449

Epoch: 6| Step: 10
Training loss: 2.831478933211185
Validation loss: 2.7278926261235577

Epoch: 6| Step: 11
Training loss: 2.861411114944091
Validation loss: 2.734820188503414

Epoch: 6| Step: 12
Training loss: 3.2101607299684303
Validation loss: 2.731160659813781

Epoch: 6| Step: 13
Training loss: 2.136936323117762
Validation loss: 2.7275699825367177

Epoch: 28| Step: 0
Training loss: 3.425512879667734
Validation loss: 2.7210708677168913

Epoch: 6| Step: 1
Training loss: 3.6501557512888394
Validation loss: 2.7250394282631243

Epoch: 6| Step: 2
Training loss: 2.947589833683906
Validation loss: 2.729917841035672

Epoch: 6| Step: 3
Training loss: 2.622453362529324
Validation loss: 2.7159976126933563

Epoch: 6| Step: 4
Training loss: 3.1235386292505507
Validation loss: 2.7225093364368096

Epoch: 6| Step: 5
Training loss: 3.106235471879538
Validation loss: 2.7210982999859312

Epoch: 6| Step: 6
Training loss: 3.1920157962876687
Validation loss: 2.722075672870433

Epoch: 6| Step: 7
Training loss: 2.9057477291426177
Validation loss: 2.7287327057324773

Epoch: 6| Step: 8
Training loss: 3.300059583877405
Validation loss: 2.7246710817451354

Epoch: 6| Step: 9
Training loss: 2.8629328371325165
Validation loss: 2.7299512442898455

Epoch: 6| Step: 10
Training loss: 3.0525772337394406
Validation loss: 2.735622316295184

Epoch: 6| Step: 11
Training loss: 2.9651013891887317
Validation loss: 2.734641501569853

Epoch: 6| Step: 12
Training loss: 2.60945330291032
Validation loss: 2.7284042945586164

Epoch: 6| Step: 13
Training loss: 2.1227638596435057
Validation loss: 2.7362151074030816

Epoch: 29| Step: 0
Training loss: 3.479466286433558
Validation loss: 2.747598554142892

Epoch: 6| Step: 1
Training loss: 3.0332570461140107
Validation loss: 2.7266624651670734

Epoch: 6| Step: 2
Training loss: 2.744142015124203
Validation loss: 2.7203018065282314

Epoch: 6| Step: 3
Training loss: 2.6220803145177016
Validation loss: 2.712419650900555

Epoch: 6| Step: 4
Training loss: 3.046417358459577
Validation loss: 2.7175780153444244

Epoch: 6| Step: 5
Training loss: 2.8201219489060505
Validation loss: 2.715613753669348

Epoch: 6| Step: 6
Training loss: 2.7357045456265765
Validation loss: 2.7145455041443562

Epoch: 6| Step: 7
Training loss: 3.388477682656236
Validation loss: 2.71004105360541

Epoch: 6| Step: 8
Training loss: 2.9603786293358354
Validation loss: 2.7090969728728593

Epoch: 6| Step: 9
Training loss: 3.038078089832359
Validation loss: 2.707451775502321

Epoch: 6| Step: 10
Training loss: 3.100151298276358
Validation loss: 2.7080385588839304

Epoch: 6| Step: 11
Training loss: 2.9876709956947445
Validation loss: 2.7047752716976423

Epoch: 6| Step: 12
Training loss: 3.381430821687096
Validation loss: 2.7051337050168547

Epoch: 6| Step: 13
Training loss: 3.271094892860142
Validation loss: 2.701942554626661

Epoch: 30| Step: 0
Training loss: 2.8510082803670844
Validation loss: 2.703528257562674

Epoch: 6| Step: 1
Training loss: 2.276056518040672
Validation loss: 2.7027551456182803

Epoch: 6| Step: 2
Training loss: 3.2087900076178686
Validation loss: 2.7116138332934385

Epoch: 6| Step: 3
Training loss: 3.095353144648909
Validation loss: 2.7347697630205943

Epoch: 6| Step: 4
Training loss: 3.2255482407254537
Validation loss: 2.7542081575614885

Epoch: 6| Step: 5
Training loss: 2.5306813107493262
Validation loss: 2.7384199567507963

Epoch: 6| Step: 6
Training loss: 3.540004579573433
Validation loss: 2.730140854714158

Epoch: 6| Step: 7
Training loss: 3.0358133476186557
Validation loss: 2.7077294811594776

Epoch: 6| Step: 8
Training loss: 2.5193609135734794
Validation loss: 2.703594548475463

Epoch: 6| Step: 9
Training loss: 3.2601605559521047
Validation loss: 2.699414732002283

Epoch: 6| Step: 10
Training loss: 2.821811774169704
Validation loss: 2.6984995789801047

Epoch: 6| Step: 11
Training loss: 3.614586836550258
Validation loss: 2.698404068954727

Epoch: 6| Step: 12
Training loss: 2.7080294707594956
Validation loss: 2.6986662295020043

Epoch: 6| Step: 13
Training loss: 3.5457125872184942
Validation loss: 2.691983641205597

Epoch: 31| Step: 0
Training loss: 2.8566451252229355
Validation loss: 2.6990135896920684

Epoch: 6| Step: 1
Training loss: 2.524031436337486
Validation loss: 2.7037632207910542

Epoch: 6| Step: 2
Training loss: 3.1947885097657633
Validation loss: 2.698004111407749

Epoch: 6| Step: 3
Training loss: 2.7539392347592453
Validation loss: 2.6972151171309826

Epoch: 6| Step: 4
Training loss: 3.2093027970346144
Validation loss: 2.6951749681240944

Epoch: 6| Step: 5
Training loss: 2.901654784214582
Validation loss: 2.6966105841004913

Epoch: 6| Step: 6
Training loss: 2.9612605338917684
Validation loss: 2.693950474557827

Epoch: 6| Step: 7
Training loss: 2.9507342960256837
Validation loss: 2.687691082925783

Epoch: 6| Step: 8
Training loss: 3.2240377898072134
Validation loss: 2.6897887299797247

Epoch: 6| Step: 9
Training loss: 3.622957377600806
Validation loss: 2.685783990708215

Epoch: 6| Step: 10
Training loss: 2.995176729519019
Validation loss: 2.690024163291296

Epoch: 6| Step: 11
Training loss: 3.255237027868321
Validation loss: 2.6932276412664433

Epoch: 6| Step: 12
Training loss: 2.7818248883278165
Validation loss: 2.692799862931886

Epoch: 6| Step: 13
Training loss: 2.936760829696113
Validation loss: 2.701169549741723

Epoch: 32| Step: 0
Training loss: 2.7083893598972595
Validation loss: 2.7057179506194102

Epoch: 6| Step: 1
Training loss: 3.093092106698017
Validation loss: 2.706476214398739

Epoch: 6| Step: 2
Training loss: 3.1469550417103034
Validation loss: 2.7115758674015256

Epoch: 6| Step: 3
Training loss: 3.2938090889134704
Validation loss: 2.707127233608074

Epoch: 6| Step: 4
Training loss: 2.8875493363298177
Validation loss: 2.698495362293195

Epoch: 6| Step: 5
Training loss: 3.1128399582850377
Validation loss: 2.692960403673964

Epoch: 6| Step: 6
Training loss: 2.293200193613877
Validation loss: 2.6886678744667636

Epoch: 6| Step: 7
Training loss: 3.6769146038531164
Validation loss: 2.683894870828505

Epoch: 6| Step: 8
Training loss: 1.9324938179104758
Validation loss: 2.686222445269449

Epoch: 6| Step: 9
Training loss: 3.584618419307156
Validation loss: 2.682958319151123

Epoch: 6| Step: 10
Training loss: 2.910896934107859
Validation loss: 2.6828982673935777

Epoch: 6| Step: 11
Training loss: 2.9557046270262055
Validation loss: 2.683347448644223

Epoch: 6| Step: 12
Training loss: 3.0377523937465494
Validation loss: 2.6871776163280607

Epoch: 6| Step: 13
Training loss: 3.225638712244245
Validation loss: 2.6836526866673855

Epoch: 33| Step: 0
Training loss: 2.9812941701883795
Validation loss: 2.6822919126168623

Epoch: 6| Step: 1
Training loss: 2.8090154466540436
Validation loss: 2.6833428341113854

Epoch: 6| Step: 2
Training loss: 2.389950127181025
Validation loss: 2.683021468747088

Epoch: 6| Step: 3
Training loss: 3.315976028484581
Validation loss: 2.6820824810446915

Epoch: 6| Step: 4
Training loss: 3.1289007636890105
Validation loss: 2.6813445535648386

Epoch: 6| Step: 5
Training loss: 3.4861593424655117
Validation loss: 2.6978419636386692

Epoch: 6| Step: 6
Training loss: 3.147215802585586
Validation loss: 2.701657228377133

Epoch: 6| Step: 7
Training loss: 3.268632589824556
Validation loss: 2.697583875055322

Epoch: 6| Step: 8
Training loss: 2.375934015622959
Validation loss: 2.7107087792081788

Epoch: 6| Step: 9
Training loss: 3.186148263377834
Validation loss: 2.7133484476108984

Epoch: 6| Step: 10
Training loss: 3.1192907441763267
Validation loss: 2.697772906697765

Epoch: 6| Step: 11
Training loss: 2.8431399183538106
Validation loss: 2.6897358409258207

Epoch: 6| Step: 12
Training loss: 2.6603155998642993
Validation loss: 2.676824991439907

Epoch: 6| Step: 13
Training loss: 3.3649907923398152
Validation loss: 2.676131432163014

Epoch: 34| Step: 0
Training loss: 3.176104952560248
Validation loss: 2.676399696855985

Epoch: 6| Step: 1
Training loss: 3.530001799499226
Validation loss: 2.679599770691694

Epoch: 6| Step: 2
Training loss: 3.486751413160292
Validation loss: 2.6843780361701155

Epoch: 6| Step: 3
Training loss: 2.8901386573554277
Validation loss: 2.69275469133219

Epoch: 6| Step: 4
Training loss: 2.5919718334763338
Validation loss: 2.6849984013479786

Epoch: 6| Step: 5
Training loss: 3.0113700932062195
Validation loss: 2.6809359988985846

Epoch: 6| Step: 6
Training loss: 3.1124882280364576
Validation loss: 2.677660640463902

Epoch: 6| Step: 7
Training loss: 3.169279492924608
Validation loss: 2.67513603237946

Epoch: 6| Step: 8
Training loss: 2.0378199039506657
Validation loss: 2.6759962886076587

Epoch: 6| Step: 9
Training loss: 3.012728391988166
Validation loss: 2.673252043743887

Epoch: 6| Step: 10
Training loss: 3.5386918233807556
Validation loss: 2.67257998336875

Epoch: 6| Step: 11
Training loss: 2.2078553408214163
Validation loss: 2.67375192117372

Epoch: 6| Step: 12
Training loss: 3.1606864342990297
Validation loss: 2.6685544834889114

Epoch: 6| Step: 13
Training loss: 2.875998116430268
Validation loss: 2.6706202867057307

Epoch: 35| Step: 0
Training loss: 2.689340360517246
Validation loss: 2.668593552346161

Epoch: 6| Step: 1
Training loss: 2.81113095341424
Validation loss: 2.670803213711967

Epoch: 6| Step: 2
Training loss: 3.0659187075095664
Validation loss: 2.6687681265083776

Epoch: 6| Step: 3
Training loss: 2.8554974722820163
Validation loss: 2.665868005696499

Epoch: 6| Step: 4
Training loss: 2.501046533883054
Validation loss: 2.6666865883231763

Epoch: 6| Step: 5
Training loss: 3.280100593885172
Validation loss: 2.665512486671465

Epoch: 6| Step: 6
Training loss: 3.1761214671124494
Validation loss: 2.663212624112961

Epoch: 6| Step: 7
Training loss: 3.33070653092977
Validation loss: 2.664151367383548

Epoch: 6| Step: 8
Training loss: 3.1810686640591372
Validation loss: 2.6621190455389883

Epoch: 6| Step: 9
Training loss: 2.4063799934448347
Validation loss: 2.6612604590760545

Epoch: 6| Step: 10
Training loss: 2.984428525115151
Validation loss: 2.6660918326343204

Epoch: 6| Step: 11
Training loss: 2.935430081519362
Validation loss: 2.662766734713282

Epoch: 6| Step: 12
Training loss: 3.089336908295854
Validation loss: 2.666578451615114

Epoch: 6| Step: 13
Training loss: 3.790223626054015
Validation loss: 2.6669859316913396

Epoch: 36| Step: 0
Training loss: 2.225914469327598
Validation loss: 2.6719773124291404

Epoch: 6| Step: 1
Training loss: 3.132238321174614
Validation loss: 2.6899528632803267

Epoch: 6| Step: 2
Training loss: 2.6293243030460087
Validation loss: 2.676476258240076

Epoch: 6| Step: 3
Training loss: 2.644118126023812
Validation loss: 2.6704111397878063

Epoch: 6| Step: 4
Training loss: 3.4403362710848615
Validation loss: 2.692618750206297

Epoch: 6| Step: 5
Training loss: 3.4354114082871434
Validation loss: 2.6860571744522197

Epoch: 6| Step: 6
Training loss: 3.213788106032897
Validation loss: 2.672675826806039

Epoch: 6| Step: 7
Training loss: 2.786563726315598
Validation loss: 2.672574020737859

Epoch: 6| Step: 8
Training loss: 2.8851398284717473
Validation loss: 2.671178063245772

Epoch: 6| Step: 9
Training loss: 2.4556917987999554
Validation loss: 2.666971262012406

Epoch: 6| Step: 10
Training loss: 3.0608703013935634
Validation loss: 2.672138669573024

Epoch: 6| Step: 11
Training loss: 3.4828698709314128
Validation loss: 2.665329433166324

Epoch: 6| Step: 12
Training loss: 3.3628022919524634
Validation loss: 2.6574111089723953

Epoch: 6| Step: 13
Training loss: 2.7758026783591427
Validation loss: 2.6534365651852667

Epoch: 37| Step: 0
Training loss: 2.6578217288153634
Validation loss: 2.652402423209257

Epoch: 6| Step: 1
Training loss: 2.883845281262885
Validation loss: 2.6512164163817706

Epoch: 6| Step: 2
Training loss: 2.8151442918673286
Validation loss: 2.6535366418735133

Epoch: 6| Step: 3
Training loss: 2.8042309742809524
Validation loss: 2.653044525089002

Epoch: 6| Step: 4
Training loss: 3.327365269158079
Validation loss: 2.6536255922189294

Epoch: 6| Step: 5
Training loss: 3.474525660792403
Validation loss: 2.6538748703242274

Epoch: 6| Step: 6
Training loss: 2.7973647727702646
Validation loss: 2.658533358724145

Epoch: 6| Step: 7
Training loss: 2.7647451089432344
Validation loss: 2.6652920997533207

Epoch: 6| Step: 8
Training loss: 2.7119177549376197
Validation loss: 2.6781355418514234

Epoch: 6| Step: 9
Training loss: 3.6895062436207247
Validation loss: 2.6877007052966726

Epoch: 6| Step: 10
Training loss: 3.2081915258469396
Validation loss: 2.6914805804724518

Epoch: 6| Step: 11
Training loss: 3.386851659012578
Validation loss: 2.6761289107975643

Epoch: 6| Step: 12
Training loss: 2.2669468673786386
Validation loss: 2.6537471438206133

Epoch: 6| Step: 13
Training loss: 2.944522498753661
Validation loss: 2.65079764664965

Epoch: 38| Step: 0
Training loss: 3.3154997288717185
Validation loss: 2.6468251831714644

Epoch: 6| Step: 1
Training loss: 3.0471845420687687
Validation loss: 2.650047485396666

Epoch: 6| Step: 2
Training loss: 3.3925511387095946
Validation loss: 2.648923054461179

Epoch: 6| Step: 3
Training loss: 3.0930347579152544
Validation loss: 2.652655026786161

Epoch: 6| Step: 4
Training loss: 3.3933474251005484
Validation loss: 2.652222933459568

Epoch: 6| Step: 5
Training loss: 3.1711170813131444
Validation loss: 2.654121191551807

Epoch: 6| Step: 6
Training loss: 3.4225918789687606
Validation loss: 2.652847817483921

Epoch: 6| Step: 7
Training loss: 2.705368257793811
Validation loss: 2.652681408623739

Epoch: 6| Step: 8
Training loss: 2.4427347947716083
Validation loss: 2.6523633323665545

Epoch: 6| Step: 9
Training loss: 2.9008071959897066
Validation loss: 2.6468184244677504

Epoch: 6| Step: 10
Training loss: 2.958965359365467
Validation loss: 2.648369775220108

Epoch: 6| Step: 11
Training loss: 2.377406757985225
Validation loss: 2.6470169476598797

Epoch: 6| Step: 12
Training loss: 2.5849450733835075
Validation loss: 2.6435343823729567

Epoch: 6| Step: 13
Training loss: 2.8394743247506162
Validation loss: 2.644005866599928

Epoch: 39| Step: 0
Training loss: 2.8811955246150878
Validation loss: 2.6449525103510427

Epoch: 6| Step: 1
Training loss: 2.5174694999658005
Validation loss: 2.6521310071700306

Epoch: 6| Step: 2
Training loss: 2.3998232140597846
Validation loss: 2.6579631851950936

Epoch: 6| Step: 3
Training loss: 2.705648313947526
Validation loss: 2.6541487623268187

Epoch: 6| Step: 4
Training loss: 2.838389615994009
Validation loss: 2.6548703634810735

Epoch: 6| Step: 5
Training loss: 3.025258858694471
Validation loss: 2.6473820689575542

Epoch: 6| Step: 6
Training loss: 2.7837555133026712
Validation loss: 2.6424994852049997

Epoch: 6| Step: 7
Training loss: 3.697034245186675
Validation loss: 2.639160239303418

Epoch: 6| Step: 8
Training loss: 3.1202929332350795
Validation loss: 2.6394942716333905

Epoch: 6| Step: 9
Training loss: 3.1813714444525534
Validation loss: 2.6363541628506355

Epoch: 6| Step: 10
Training loss: 3.186219350817812
Validation loss: 2.6402650206583123

Epoch: 6| Step: 11
Training loss: 3.3306906396915794
Validation loss: 2.6395784505448066

Epoch: 6| Step: 12
Training loss: 3.0200444386225316
Validation loss: 2.6444944159607124

Epoch: 6| Step: 13
Training loss: 2.675508493597115
Validation loss: 2.6392857800560554

Epoch: 40| Step: 0
Training loss: 3.033673762686602
Validation loss: 2.6389069676567036

Epoch: 6| Step: 1
Training loss: 2.8672500312493185
Validation loss: 2.639559302654567

Epoch: 6| Step: 2
Training loss: 2.765787066005339
Validation loss: 2.6408697001446644

Epoch: 6| Step: 3
Training loss: 3.13122487924211
Validation loss: 2.639991105059383

Epoch: 6| Step: 4
Training loss: 2.940541093300129
Validation loss: 2.6425650835289543

Epoch: 6| Step: 5
Training loss: 2.5399776746114155
Validation loss: 2.645487415767148

Epoch: 6| Step: 6
Training loss: 3.515809728219652
Validation loss: 2.6413424296942427

Epoch: 6| Step: 7
Training loss: 3.2051304935544964
Validation loss: 2.6403225708992553

Epoch: 6| Step: 8
Training loss: 2.6786917123580976
Validation loss: 2.6417552482721867

Epoch: 6| Step: 9
Training loss: 2.9183934322714102
Validation loss: 2.6435777097449957

Epoch: 6| Step: 10
Training loss: 2.970552238730594
Validation loss: 2.636432270269936

Epoch: 6| Step: 11
Training loss: 2.5602441488012326
Validation loss: 2.637366758238248

Epoch: 6| Step: 12
Training loss: 3.079831961964878
Validation loss: 2.6385964299738527

Epoch: 6| Step: 13
Training loss: 3.5457167561811076
Validation loss: 2.6447030649609036

Epoch: 41| Step: 0
Training loss: 3.3057092119793356
Validation loss: 2.669224399469912

Epoch: 6| Step: 1
Training loss: 3.83174391980727
Validation loss: 2.7261282060204484

Epoch: 6| Step: 2
Training loss: 2.988820704218527
Validation loss: 2.727852453651786

Epoch: 6| Step: 3
Training loss: 3.0984073608594667
Validation loss: 2.712150655726929

Epoch: 6| Step: 4
Training loss: 3.0877060856167615
Validation loss: 2.6956674069579387

Epoch: 6| Step: 5
Training loss: 2.712234055099433
Validation loss: 2.6934384829621387

Epoch: 6| Step: 6
Training loss: 2.9977328953054974
Validation loss: 2.700765671363666

Epoch: 6| Step: 7
Training loss: 3.1276357597811506
Validation loss: 2.7077512533651023

Epoch: 6| Step: 8
Training loss: 3.238054329683179
Validation loss: 2.685295154934543

Epoch: 6| Step: 9
Training loss: 3.1587783204753817
Validation loss: 2.6817490328788267

Epoch: 6| Step: 10
Training loss: 2.597122206323306
Validation loss: 2.6768459600912875

Epoch: 6| Step: 11
Training loss: 2.7391284714896442
Validation loss: 2.6776478713488903

Epoch: 6| Step: 12
Training loss: 2.0983922935041828
Validation loss: 2.679346007406799

Epoch: 6| Step: 13
Training loss: 2.7989534295430376
Validation loss: 2.67383035898061

Epoch: 42| Step: 0
Training loss: 2.997728600522425
Validation loss: 2.662269394692989

Epoch: 6| Step: 1
Training loss: 2.459917904794312
Validation loss: 2.6466566705017733

Epoch: 6| Step: 2
Training loss: 3.658480102676811
Validation loss: 2.6287305295011514

Epoch: 6| Step: 3
Training loss: 2.307431104133661
Validation loss: 2.6282327535243617

Epoch: 6| Step: 4
Training loss: 3.144942926031505
Validation loss: 2.644330100968902

Epoch: 6| Step: 5
Training loss: 2.567813574521584
Validation loss: 2.6398461859512405

Epoch: 6| Step: 6
Training loss: 3.648094275461007
Validation loss: 2.634994522312882

Epoch: 6| Step: 7
Training loss: 2.700506629035892
Validation loss: 2.632814727886449

Epoch: 6| Step: 8
Training loss: 2.133436845215244
Validation loss: 2.6301402223374457

Epoch: 6| Step: 9
Training loss: 3.1227069834390395
Validation loss: 2.627170815600705

Epoch: 6| Step: 10
Training loss: 3.1432473541129697
Validation loss: 2.6221513316570673

Epoch: 6| Step: 11
Training loss: 3.728960141620311
Validation loss: 2.62213293838592

Epoch: 6| Step: 12
Training loss: 2.9311205804880904
Validation loss: 2.6215789582027624

Epoch: 6| Step: 13
Training loss: 2.4428877340997057
Validation loss: 2.625223485258956

Epoch: 43| Step: 0
Training loss: 3.1531116254691107
Validation loss: 2.624909711418863

Epoch: 6| Step: 1
Training loss: 2.817905571897999
Validation loss: 2.624564527807818

Epoch: 6| Step: 2
Training loss: 2.3774703379163573
Validation loss: 2.6240242210446336

Epoch: 6| Step: 3
Training loss: 3.21698008642653
Validation loss: 2.635288644139224

Epoch: 6| Step: 4
Training loss: 3.3274764740969913
Validation loss: 2.6390567420319586

Epoch: 6| Step: 5
Training loss: 3.015365984767807
Validation loss: 2.634339905699715

Epoch: 6| Step: 6
Training loss: 3.157214933138573
Validation loss: 2.624871457376196

Epoch: 6| Step: 7
Training loss: 2.782900716849473
Validation loss: 2.627636459091826

Epoch: 6| Step: 8
Training loss: 2.899104203613703
Validation loss: 2.6323203752207407

Epoch: 6| Step: 9
Training loss: 2.810928074988976
Validation loss: 2.636192833617643

Epoch: 6| Step: 10
Training loss: 2.9967952140871725
Validation loss: 2.6337100415187105

Epoch: 6| Step: 11
Training loss: 2.927118665452534
Validation loss: 2.6271917102210662

Epoch: 6| Step: 12
Training loss: 3.0005740570149007
Validation loss: 2.629844025429725

Epoch: 6| Step: 13
Training loss: 2.8567749876527073
Validation loss: 2.625696846641023

Epoch: 44| Step: 0
Training loss: 2.2956381860817014
Validation loss: 2.621994886476226

Epoch: 6| Step: 1
Training loss: 2.974730881772287
Validation loss: 2.621513187771963

Epoch: 6| Step: 2
Training loss: 2.957519168485305
Validation loss: 2.6211263991011897

Epoch: 6| Step: 3
Training loss: 3.0126502035216927
Validation loss: 2.6234083765777934

Epoch: 6| Step: 4
Training loss: 2.9369610231103733
Validation loss: 2.623001068057094

Epoch: 6| Step: 5
Training loss: 3.2058239986586874
Validation loss: 2.620188519085352

Epoch: 6| Step: 6
Training loss: 2.9644107628084027
Validation loss: 2.619519493910689

Epoch: 6| Step: 7
Training loss: 3.1191782319077612
Validation loss: 2.6215985679472

Epoch: 6| Step: 8
Training loss: 2.8428180550861377
Validation loss: 2.6207559510728897

Epoch: 6| Step: 9
Training loss: 3.228183883912825
Validation loss: 2.6276639072598815

Epoch: 6| Step: 10
Training loss: 3.144819656319956
Validation loss: 2.639596695057637

Epoch: 6| Step: 11
Training loss: 3.003653209331715
Validation loss: 2.645151176490827

Epoch: 6| Step: 12
Training loss: 2.7039995487652915
Validation loss: 2.645426763435751

Epoch: 6| Step: 13
Training loss: 3.097739373687677
Validation loss: 2.637386194217513

Epoch: 45| Step: 0
Training loss: 2.640934491501696
Validation loss: 2.6254776462954537

Epoch: 6| Step: 1
Training loss: 3.1857214060672656
Validation loss: 2.6180918855412116

Epoch: 6| Step: 2
Training loss: 3.1975546434160957
Validation loss: 2.621977052358982

Epoch: 6| Step: 3
Training loss: 2.282407075258474
Validation loss: 2.617075442108609

Epoch: 6| Step: 4
Training loss: 2.743115651133649
Validation loss: 2.620603739670071

Epoch: 6| Step: 5
Training loss: 2.8558861966152604
Validation loss: 2.623629840877701

Epoch: 6| Step: 6
Training loss: 2.921887239644735
Validation loss: 2.6196193699979062

Epoch: 6| Step: 7
Training loss: 3.306848130810016
Validation loss: 2.6176994487881213

Epoch: 6| Step: 8
Training loss: 3.2917646240595575
Validation loss: 2.6216999225525384

Epoch: 6| Step: 9
Training loss: 2.733121224834104
Validation loss: 2.6181022405811767

Epoch: 6| Step: 10
Training loss: 3.028919070976541
Validation loss: 2.611325067865381

Epoch: 6| Step: 11
Training loss: 3.0931309552693227
Validation loss: 2.611671701940222

Epoch: 6| Step: 12
Training loss: 2.8164626286507737
Validation loss: 2.6096940415687815

Epoch: 6| Step: 13
Training loss: 3.1455132698454675
Validation loss: 2.60778688250481

Epoch: 46| Step: 0
Training loss: 3.0412548953517486
Validation loss: 2.606930509335564

Epoch: 6| Step: 1
Training loss: 3.020180063753265
Validation loss: 2.60834612723491

Epoch: 6| Step: 2
Training loss: 2.32701135408511
Validation loss: 2.609729276366464

Epoch: 6| Step: 3
Training loss: 2.5521266596223966
Validation loss: 2.6090909309444634

Epoch: 6| Step: 4
Training loss: 2.4603591481547844
Validation loss: 2.6115488546020718

Epoch: 6| Step: 5
Training loss: 3.2304696356369704
Validation loss: 2.610969291714333

Epoch: 6| Step: 6
Training loss: 3.650831592881282
Validation loss: 2.624111423606205

Epoch: 6| Step: 7
Training loss: 3.1946447742690656
Validation loss: 2.624992988799733

Epoch: 6| Step: 8
Training loss: 3.1055550425314284
Validation loss: 2.6234886918793676

Epoch: 6| Step: 9
Training loss: 3.0581955534816543
Validation loss: 2.6226129866084666

Epoch: 6| Step: 10
Training loss: 3.0409304803530666
Validation loss: 2.6201619646756567

Epoch: 6| Step: 11
Training loss: 2.6991193783433487
Validation loss: 2.6145874773172517

Epoch: 6| Step: 12
Training loss: 3.1872268260508605
Validation loss: 2.6163050116783118

Epoch: 6| Step: 13
Training loss: 2.1060887487247264
Validation loss: 2.6090660646732426

Epoch: 47| Step: 0
Training loss: 2.577934211838546
Validation loss: 2.6125893805353044

Epoch: 6| Step: 1
Training loss: 2.2566928925485845
Validation loss: 2.6107016105359953

Epoch: 6| Step: 2
Training loss: 2.8830040348592383
Validation loss: 2.6140374989603017

Epoch: 6| Step: 3
Training loss: 3.0037065496647677
Validation loss: 2.6101272910382205

Epoch: 6| Step: 4
Training loss: 3.001809845820329
Validation loss: 2.611676292921816

Epoch: 6| Step: 5
Training loss: 2.749355240577616
Validation loss: 2.6177933705639655

Epoch: 6| Step: 6
Training loss: 2.6231543092178664
Validation loss: 2.623935190509818

Epoch: 6| Step: 7
Training loss: 3.2588373488706126
Validation loss: 2.6137591820943475

Epoch: 6| Step: 8
Training loss: 2.9825366684481343
Validation loss: 2.615364738594124

Epoch: 6| Step: 9
Training loss: 3.0233450784283353
Validation loss: 2.619417217164186

Epoch: 6| Step: 10
Training loss: 3.4110501964927407
Validation loss: 2.612735734947042

Epoch: 6| Step: 11
Training loss: 2.6656161166151526
Validation loss: 2.5966825387527463

Epoch: 6| Step: 12
Training loss: 3.3780766345151534
Validation loss: 2.593652267977048

Epoch: 6| Step: 13
Training loss: 3.39480206953345
Validation loss: 2.597882664821255

Epoch: 48| Step: 0
Training loss: 2.752153593711904
Validation loss: 2.5960100016421253

Epoch: 6| Step: 1
Training loss: 2.9536989653347927
Validation loss: 2.5949037587483477

Epoch: 6| Step: 2
Training loss: 3.1455702682211526
Validation loss: 2.595499853185414

Epoch: 6| Step: 3
Training loss: 2.925761529629385
Validation loss: 2.6000738048253855

Epoch: 6| Step: 4
Training loss: 2.8899787799095753
Validation loss: 2.600588639558498

Epoch: 6| Step: 5
Training loss: 3.180379506383863
Validation loss: 2.5976561986809257

Epoch: 6| Step: 6
Training loss: 2.434711719970722
Validation loss: 2.6060609473662457

Epoch: 6| Step: 7
Training loss: 2.905398992822693
Validation loss: 2.62116438993276

Epoch: 6| Step: 8
Training loss: 3.5034594468907874
Validation loss: 2.615922871430664

Epoch: 6| Step: 9
Training loss: 3.1905109919430577
Validation loss: 2.607308121137421

Epoch: 6| Step: 10
Training loss: 2.8150582440653813
Validation loss: 2.5958449513086115

Epoch: 6| Step: 11
Training loss: 2.913373686760505
Validation loss: 2.594091123883764

Epoch: 6| Step: 12
Training loss: 2.1135741082025628
Validation loss: 2.5934322076998595

Epoch: 6| Step: 13
Training loss: 3.472995805820752
Validation loss: 2.5911353253844944

Epoch: 49| Step: 0
Training loss: 2.0457644179702137
Validation loss: 2.594508760251808

Epoch: 6| Step: 1
Training loss: 3.3996818281410945
Validation loss: 2.594295995270136

Epoch: 6| Step: 2
Training loss: 2.8458098612125013
Validation loss: 2.5894600708945674

Epoch: 6| Step: 3
Training loss: 2.9334794795591512
Validation loss: 2.5930708915235754

Epoch: 6| Step: 4
Training loss: 2.6874883784552956
Validation loss: 2.596360048932156

Epoch: 6| Step: 5
Training loss: 2.8123275703979105
Validation loss: 2.60026918178159

Epoch: 6| Step: 6
Training loss: 3.186090494311085
Validation loss: 2.605096300790581

Epoch: 6| Step: 7
Training loss: 3.17347263634152
Validation loss: 2.6042060373262985

Epoch: 6| Step: 8
Training loss: 3.2778459602922614
Validation loss: 2.6023051391743444

Epoch: 6| Step: 9
Training loss: 2.998704948643423
Validation loss: 2.6037605123147345

Epoch: 6| Step: 10
Training loss: 3.1431540559497866
Validation loss: 2.603551220104918

Epoch: 6| Step: 11
Training loss: 2.818546830867454
Validation loss: 2.5886203168523334

Epoch: 6| Step: 12
Training loss: 2.251044348897988
Validation loss: 2.5861954178258943

Epoch: 6| Step: 13
Training loss: 3.5122895418697664
Validation loss: 2.58431938861389

Epoch: 50| Step: 0
Training loss: 2.4312583040620255
Validation loss: 2.584085082855957

Epoch: 6| Step: 1
Training loss: 2.8255655920934073
Validation loss: 2.5844090508156623

Epoch: 6| Step: 2
Training loss: 2.8182799393528737
Validation loss: 2.584897795834775

Epoch: 6| Step: 3
Training loss: 3.459752967262608
Validation loss: 2.582971452922768

Epoch: 6| Step: 4
Training loss: 2.5204249489962898
Validation loss: 2.58516210858454

Epoch: 6| Step: 5
Training loss: 2.6394609221687224
Validation loss: 2.5808015634008266

Epoch: 6| Step: 6
Training loss: 2.8753986911481753
Validation loss: 2.5819879730873656

Epoch: 6| Step: 7
Training loss: 3.8520044533613693
Validation loss: 2.5794869920592842

Epoch: 6| Step: 8
Training loss: 3.0397945199086402
Validation loss: 2.5820026440489685

Epoch: 6| Step: 9
Training loss: 2.880586421126371
Validation loss: 2.586065160514066

Epoch: 6| Step: 10
Training loss: 2.9167737850319
Validation loss: 2.5879999148756547

Epoch: 6| Step: 11
Training loss: 2.949193850784793
Validation loss: 2.591582098375986

Epoch: 6| Step: 12
Training loss: 2.879992586762106
Validation loss: 2.5877632714989787

Epoch: 6| Step: 13
Training loss: 2.4476448611601165
Validation loss: 2.5966281353625225

Testing loss: 2.807636020468237
