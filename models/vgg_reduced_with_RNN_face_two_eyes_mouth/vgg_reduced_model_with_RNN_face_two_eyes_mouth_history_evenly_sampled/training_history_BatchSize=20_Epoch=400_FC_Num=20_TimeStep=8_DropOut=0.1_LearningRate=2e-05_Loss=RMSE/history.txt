Epoch: 1| Step: 0
Training loss: 6.375677932894972
Validation loss: 5.844875695580608

Epoch: 5| Step: 1
Training loss: 5.301027363943828
Validation loss: 5.816987058376204

Epoch: 5| Step: 2
Training loss: 6.20694705241037
Validation loss: 5.790497267025253

Epoch: 5| Step: 3
Training loss: 5.456713351122036
Validation loss: 5.762007703451285

Epoch: 5| Step: 4
Training loss: 4.620526392619943
Validation loss: 5.7317423213854095

Epoch: 5| Step: 5
Training loss: 6.000719027351209
Validation loss: 5.698609822434778

Epoch: 5| Step: 6
Training loss: 4.780224459497557
Validation loss: 5.660331465023708

Epoch: 5| Step: 7
Training loss: 6.964249461991411
Validation loss: 5.618539207611126

Epoch: 5| Step: 8
Training loss: 4.715681682673228
Validation loss: 5.572668835482133

Epoch: 5| Step: 9
Training loss: 6.082873531714434
Validation loss: 5.519859765230096

Epoch: 5| Step: 10
Training loss: 5.867451790090244
Validation loss: 5.462516732717178

Epoch: 2| Step: 0
Training loss: 4.989927828157899
Validation loss: 5.397782121785809

Epoch: 5| Step: 1
Training loss: 4.493165229875147
Validation loss: 5.330155169132192

Epoch: 5| Step: 2
Training loss: 5.564801029511017
Validation loss: 5.254559936674831

Epoch: 5| Step: 3
Training loss: 4.585568570791592
Validation loss: 5.1762457016231735

Epoch: 5| Step: 4
Training loss: 5.537423175080796
Validation loss: 5.094577388175615

Epoch: 5| Step: 5
Training loss: 4.999982833832837
Validation loss: 5.013011882525219

Epoch: 5| Step: 6
Training loss: 4.999946784689958
Validation loss: 4.931331332041711

Epoch: 5| Step: 7
Training loss: 5.245720526967282
Validation loss: 4.854243157178593

Epoch: 5| Step: 8
Training loss: 5.235910127910305
Validation loss: 4.780052762767738

Epoch: 5| Step: 9
Training loss: 4.845897567642551
Validation loss: 4.712333684402746

Epoch: 5| Step: 10
Training loss: 5.1983879451608415
Validation loss: 4.6477269781690005

Epoch: 3| Step: 0
Training loss: 4.375383414770083
Validation loss: 4.588511823534523

Epoch: 5| Step: 1
Training loss: 4.156386523765147
Validation loss: 4.534162023132403

Epoch: 5| Step: 2
Training loss: 5.158984759502522
Validation loss: 4.4842769987546935

Epoch: 5| Step: 3
Training loss: 4.603436074036886
Validation loss: 4.438321860299214

Epoch: 5| Step: 4
Training loss: 3.9877008656580206
Validation loss: 4.398151086243648

Epoch: 5| Step: 5
Training loss: 3.8717529474684294
Validation loss: 4.3634319019605226

Epoch: 5| Step: 6
Training loss: 5.131166423530502
Validation loss: 4.334973312851966

Epoch: 5| Step: 7
Training loss: 4.4731432253999435
Validation loss: 4.30623928537677

Epoch: 5| Step: 8
Training loss: 3.9692605959227123
Validation loss: 4.2767243237274615

Epoch: 5| Step: 9
Training loss: 5.226419991459165
Validation loss: 4.250109259149838

Epoch: 5| Step: 10
Training loss: 4.191464497498346
Validation loss: 4.224526609183554

Epoch: 4| Step: 0
Training loss: 3.9676986863805275
Validation loss: 4.203663536038964

Epoch: 5| Step: 1
Training loss: 4.509903289028668
Validation loss: 4.181337803786713

Epoch: 5| Step: 2
Training loss: 4.59368564275178
Validation loss: 4.157068954464433

Epoch: 5| Step: 3
Training loss: 4.529716705828147
Validation loss: 4.131589146963819

Epoch: 5| Step: 4
Training loss: 4.633233654313042
Validation loss: 4.11118093586693

Epoch: 5| Step: 5
Training loss: 4.047482006841182
Validation loss: 4.091681749425385

Epoch: 5| Step: 6
Training loss: 3.8761863123125013
Validation loss: 4.071082659493871

Epoch: 5| Step: 7
Training loss: 4.154164185263385
Validation loss: 4.0517643472585805

Epoch: 5| Step: 8
Training loss: 4.231676431238708
Validation loss: 4.0282389015580184

Epoch: 5| Step: 9
Training loss: 3.4385216321865197
Validation loss: 4.004234930594509

Epoch: 5| Step: 10
Training loss: 4.536477276849739
Validation loss: 3.9877497993368327

Epoch: 5| Step: 0
Training loss: 4.714918791798734
Validation loss: 3.974284586521603

Epoch: 5| Step: 1
Training loss: 4.258837991112822
Validation loss: 3.9595423477125786

Epoch: 5| Step: 2
Training loss: 3.999643906001745
Validation loss: 3.9472542488225786

Epoch: 5| Step: 3
Training loss: 3.857363775274482
Validation loss: 3.932933274491139

Epoch: 5| Step: 4
Training loss: 4.189422166260904
Validation loss: 3.914398177000299

Epoch: 5| Step: 5
Training loss: 3.151810800721922
Validation loss: 3.897723912447281

Epoch: 5| Step: 6
Training loss: 4.275546095919791
Validation loss: 3.881522958626548

Epoch: 5| Step: 7
Training loss: 4.10718597010381
Validation loss: 3.864205843509919

Epoch: 5| Step: 8
Training loss: 4.4760313667650555
Validation loss: 3.849255830812398

Epoch: 5| Step: 9
Training loss: 3.6527831766904924
Validation loss: 3.8327876064130115

Epoch: 5| Step: 10
Training loss: 3.7567764091088933
Validation loss: 3.81606540897518

Epoch: 6| Step: 0
Training loss: 4.00023793466533
Validation loss: 3.805040064751387

Epoch: 5| Step: 1
Training loss: 3.4822906965793936
Validation loss: 3.788244070963581

Epoch: 5| Step: 2
Training loss: 4.122252965665675
Validation loss: 3.7770121023367613

Epoch: 5| Step: 3
Training loss: 3.7821550783572007
Validation loss: 3.7665478009623623

Epoch: 5| Step: 4
Training loss: 4.161384107606511
Validation loss: 3.7483132537397497

Epoch: 5| Step: 5
Training loss: 4.339676518141012
Validation loss: 3.740271271108883

Epoch: 5| Step: 6
Training loss: 4.108453567530335
Validation loss: 3.72907552758414

Epoch: 5| Step: 7
Training loss: 3.69054506943702
Validation loss: 3.7125005813266165

Epoch: 5| Step: 8
Training loss: 3.49838192185573
Validation loss: 3.6987755704209495

Epoch: 5| Step: 9
Training loss: 3.438026665309534
Validation loss: 3.6858319736349383

Epoch: 5| Step: 10
Training loss: 4.396231875801201
Validation loss: 3.670729971735484

Epoch: 7| Step: 0
Training loss: 3.3747362104394574
Validation loss: 3.6551185682431173

Epoch: 5| Step: 1
Training loss: 3.652920241935938
Validation loss: 3.6435452872614937

Epoch: 5| Step: 2
Training loss: 3.870849108929032
Validation loss: 3.6342539746359184

Epoch: 5| Step: 3
Training loss: 3.4790954277983723
Validation loss: 3.6249322060994964

Epoch: 5| Step: 4
Training loss: 3.7400227379745177
Validation loss: 3.6146804135985935

Epoch: 5| Step: 5
Training loss: 4.267457002714794
Validation loss: 3.605622260755135

Epoch: 5| Step: 6
Training loss: 3.7867837562277917
Validation loss: 3.590783631354785

Epoch: 5| Step: 7
Training loss: 4.2962051146856535
Validation loss: 3.5847051407560784

Epoch: 5| Step: 8
Training loss: 4.185167260695802
Validation loss: 3.5742156356599812

Epoch: 5| Step: 9
Training loss: 3.456358901337996
Validation loss: 3.56615162836688

Epoch: 5| Step: 10
Training loss: 3.540240430695196
Validation loss: 3.56567748151939

Epoch: 8| Step: 0
Training loss: 3.570724496922489
Validation loss: 3.557805290263321

Epoch: 5| Step: 1
Training loss: 3.2331876925148184
Validation loss: 3.5480017914775894

Epoch: 5| Step: 2
Training loss: 3.725083287479251
Validation loss: 3.5378885654439385

Epoch: 5| Step: 3
Training loss: 3.8744175380901384
Validation loss: 3.528594662044371

Epoch: 5| Step: 4
Training loss: 3.6230446375919643
Validation loss: 3.5214476297361386

Epoch: 5| Step: 5
Training loss: 3.5602965651438225
Validation loss: 3.5119775078622024

Epoch: 5| Step: 6
Training loss: 3.631158004882313
Validation loss: 3.504514810309388

Epoch: 5| Step: 7
Training loss: 3.3452443143977173
Validation loss: 3.4972126859297785

Epoch: 5| Step: 8
Training loss: 4.00506985759412
Validation loss: 3.4959435783650936

Epoch: 5| Step: 9
Training loss: 4.222782496595083
Validation loss: 3.4810125526135227

Epoch: 5| Step: 10
Training loss: 4.118155146754932
Validation loss: 3.480945440206228

Epoch: 9| Step: 0
Training loss: 3.555436476726741
Validation loss: 3.473504407897179

Epoch: 5| Step: 1
Training loss: 3.6872359359072613
Validation loss: 3.466471054894049

Epoch: 5| Step: 2
Training loss: 3.806797202478206
Validation loss: 3.464041234652911

Epoch: 5| Step: 3
Training loss: 3.4144208706898085
Validation loss: 3.457301816368746

Epoch: 5| Step: 4
Training loss: 3.898489728130543
Validation loss: 3.45491824426542

Epoch: 5| Step: 5
Training loss: 3.6852230218818915
Validation loss: 3.448655776466159

Epoch: 5| Step: 6
Training loss: 3.5371867550032623
Validation loss: 3.4388796456865838

Epoch: 5| Step: 7
Training loss: 3.73049188576759
Validation loss: 3.4339920774749926

Epoch: 5| Step: 8
Training loss: 3.48826894725924
Validation loss: 3.4309289319516494

Epoch: 5| Step: 9
Training loss: 4.214821575909003
Validation loss: 3.4275140886527393

Epoch: 5| Step: 10
Training loss: 3.1184526137335427
Validation loss: 3.4199782819141697

Epoch: 10| Step: 0
Training loss: 3.652259540097059
Validation loss: 3.4112924878199298

Epoch: 5| Step: 1
Training loss: 2.5252998022990654
Validation loss: 3.406714656161027

Epoch: 5| Step: 2
Training loss: 3.3793871586959927
Validation loss: 3.402066382611

Epoch: 5| Step: 3
Training loss: 4.677251981259018
Validation loss: 3.402848722817575

Epoch: 5| Step: 4
Training loss: 2.4458397245134056
Validation loss: 3.3923145521248013

Epoch: 5| Step: 5
Training loss: 2.887327385569139
Validation loss: 3.3860523126292956

Epoch: 5| Step: 6
Training loss: 3.9230637895355636
Validation loss: 3.3863830661199383

Epoch: 5| Step: 7
Training loss: 3.415733923401182
Validation loss: 3.3793172595456413

Epoch: 5| Step: 8
Training loss: 4.352055355631571
Validation loss: 3.379192551136826

Epoch: 5| Step: 9
Training loss: 4.0535703674660715
Validation loss: 3.368839111342781

Epoch: 5| Step: 10
Training loss: 3.7861347016454534
Validation loss: 3.359758771537298

Epoch: 11| Step: 0
Training loss: 3.8276370613379265
Validation loss: 3.3553170644249506

Epoch: 5| Step: 1
Training loss: 3.6152066766058057
Validation loss: 3.355277269243713

Epoch: 5| Step: 2
Training loss: 3.8670540834782616
Validation loss: 3.350080332239018

Epoch: 5| Step: 3
Training loss: 3.8612992281259397
Validation loss: 3.3518019844812135

Epoch: 5| Step: 4
Training loss: 3.259478611821659
Validation loss: 3.3528790293723922

Epoch: 5| Step: 5
Training loss: 3.0111498264421708
Validation loss: 3.3514345558031917

Epoch: 5| Step: 6
Training loss: 3.8333231607937943
Validation loss: 3.3450441536611226

Epoch: 5| Step: 7
Training loss: 3.07781593591361
Validation loss: 3.3371345493536206

Epoch: 5| Step: 8
Training loss: 3.363878930270757
Validation loss: 3.334547757351657

Epoch: 5| Step: 9
Training loss: 3.951242473610815
Validation loss: 3.3319237656401395

Epoch: 5| Step: 10
Training loss: 3.560341565965998
Validation loss: 3.32709923160953

Epoch: 12| Step: 0
Training loss: 3.3912077372216802
Validation loss: 3.3220477366266254

Epoch: 5| Step: 1
Training loss: 3.530884580356572
Validation loss: 3.3190676327865156

Epoch: 5| Step: 2
Training loss: 4.209641180989261
Validation loss: 3.314520156602813

Epoch: 5| Step: 3
Training loss: 2.670739719061492
Validation loss: 3.3093315445079217

Epoch: 5| Step: 4
Training loss: 3.689956364153965
Validation loss: 3.30516496681216

Epoch: 5| Step: 5
Training loss: 3.4720106865766756
Validation loss: 3.3291167959862937

Epoch: 5| Step: 6
Training loss: 3.6100959883421306
Validation loss: 3.302783371045553

Epoch: 5| Step: 7
Training loss: 3.9643649408777253
Validation loss: 3.315852593265535

Epoch: 5| Step: 8
Training loss: 3.3744981180655778
Validation loss: 3.30846910331118

Epoch: 5| Step: 9
Training loss: 3.673983743506003
Validation loss: 3.3087809746606474

Epoch: 5| Step: 10
Training loss: 3.2375586132502616
Validation loss: 3.304557882114781

Epoch: 13| Step: 0
Training loss: 4.071598603945432
Validation loss: 3.302652979816766

Epoch: 5| Step: 1
Training loss: 3.6686496285480708
Validation loss: 3.300156080818911

Epoch: 5| Step: 2
Training loss: 3.9988690207900746
Validation loss: 3.297565562258779

Epoch: 5| Step: 3
Training loss: 3.2247405369202253
Validation loss: 3.285643360477136

Epoch: 5| Step: 4
Training loss: 3.24956538889046
Validation loss: 3.276025213937842

Epoch: 5| Step: 5
Training loss: 3.050711852003574
Validation loss: 3.2734524161205303

Epoch: 5| Step: 6
Training loss: 3.3655888774211995
Validation loss: 3.2742523299923247

Epoch: 5| Step: 7
Training loss: 3.9367958529144502
Validation loss: 3.2617745461326706

Epoch: 5| Step: 8
Training loss: 3.4665126974197094
Validation loss: 3.2580026743366406

Epoch: 5| Step: 9
Training loss: 3.7478435673917407
Validation loss: 3.255779845768515

Epoch: 5| Step: 10
Training loss: 2.600561367467485
Validation loss: 3.253201301845176

Epoch: 14| Step: 0
Training loss: 4.332027287391109
Validation loss: 3.2505836230988163

Epoch: 5| Step: 1
Training loss: 3.6392751655334816
Validation loss: 3.2477001322570236

Epoch: 5| Step: 2
Training loss: 2.5044954889081317
Validation loss: 3.2443367306606525

Epoch: 5| Step: 3
Training loss: 3.538705433059917
Validation loss: 3.254960448181021

Epoch: 5| Step: 4
Training loss: 4.1300872874791965
Validation loss: 3.2400179377805856

Epoch: 5| Step: 5
Training loss: 3.4482312630367167
Validation loss: 3.235336294810118

Epoch: 5| Step: 6
Training loss: 3.804901305032765
Validation loss: 3.2337494868947876

Epoch: 5| Step: 7
Training loss: 2.781190164329576
Validation loss: 3.2324140280381193

Epoch: 5| Step: 8
Training loss: 3.650547895722619
Validation loss: 3.2318028645608265

Epoch: 5| Step: 9
Training loss: 2.607294132375269
Validation loss: 3.232151539597267

Epoch: 5| Step: 10
Training loss: 3.496491444733664
Validation loss: 3.228978120113699

Epoch: 15| Step: 0
Training loss: 3.3057738338033333
Validation loss: 3.2277150813712296

Epoch: 5| Step: 1
Training loss: 3.3907117700680813
Validation loss: 3.2283495379570692

Epoch: 5| Step: 2
Training loss: 4.418854129756759
Validation loss: 3.2253371497221797

Epoch: 5| Step: 3
Training loss: 3.324909788356371
Validation loss: 3.2233502362872115

Epoch: 5| Step: 4
Training loss: 3.69448372255127
Validation loss: 3.2213223551820365

Epoch: 5| Step: 5
Training loss: 3.6915093301579986
Validation loss: 3.2206346120029217

Epoch: 5| Step: 6
Training loss: 3.8314685155587243
Validation loss: 3.2172529189934456

Epoch: 5| Step: 7
Training loss: 3.073212707397532
Validation loss: 3.2155235073365724

Epoch: 5| Step: 8
Training loss: 2.8593529872359644
Validation loss: 3.215097440309818

Epoch: 5| Step: 9
Training loss: 3.13381447310709
Validation loss: 3.2125927000994245

Epoch: 5| Step: 10
Training loss: 3.2258480287764244
Validation loss: 3.2110841084540347

Epoch: 16| Step: 0
Training loss: 3.464139331314879
Validation loss: 3.2094905834654877

Epoch: 5| Step: 1
Training loss: 3.401256996492468
Validation loss: 3.2084062139455343

Epoch: 5| Step: 2
Training loss: 3.8334731753729163
Validation loss: 3.2070756793018784

Epoch: 5| Step: 3
Training loss: 3.0321853610324796
Validation loss: 3.2051571750167773

Epoch: 5| Step: 4
Training loss: 2.6245269349122857
Validation loss: 3.2029306276234486

Epoch: 5| Step: 5
Training loss: 4.36931524153747
Validation loss: 3.203736271271401

Epoch: 5| Step: 6
Training loss: 3.246292053114786
Validation loss: 3.2019384019594037

Epoch: 5| Step: 7
Training loss: 3.8329784533111275
Validation loss: 3.20047916332594

Epoch: 5| Step: 8
Training loss: 2.9495429056645297
Validation loss: 3.197954937133126

Epoch: 5| Step: 9
Training loss: 3.2873307333184054
Validation loss: 3.196802254881441

Epoch: 5| Step: 10
Training loss: 3.761500842476532
Validation loss: 3.195133884096205

Epoch: 17| Step: 0
Training loss: 3.461345020008
Validation loss: 3.1944141426331587

Epoch: 5| Step: 1
Training loss: 3.0711415654169287
Validation loss: 3.194313868677218

Epoch: 5| Step: 2
Training loss: 3.692088876408756
Validation loss: 3.192716156099591

Epoch: 5| Step: 3
Training loss: 3.8651013845394218
Validation loss: 3.190453647391588

Epoch: 5| Step: 4
Training loss: 3.210562059863409
Validation loss: 3.190035007205128

Epoch: 5| Step: 5
Training loss: 3.5702435843663363
Validation loss: 3.1877889170475315

Epoch: 5| Step: 6
Training loss: 3.694736040569727
Validation loss: 3.1870559505331433

Epoch: 5| Step: 7
Training loss: 2.6436581318362027
Validation loss: 3.186728213333697

Epoch: 5| Step: 8
Training loss: 3.4835176653358646
Validation loss: 3.1849811984458802

Epoch: 5| Step: 9
Training loss: 2.6299236987109076
Validation loss: 3.183550582604154

Epoch: 5| Step: 10
Training loss: 4.412666788812284
Validation loss: 3.18412173541058

Epoch: 18| Step: 0
Training loss: 3.3355155159771357
Validation loss: 3.1814470190118533

Epoch: 5| Step: 1
Training loss: 3.266872623983526
Validation loss: 3.1805589621582167

Epoch: 5| Step: 2
Training loss: 3.6918498100737525
Validation loss: 3.1818747784695356

Epoch: 5| Step: 3
Training loss: 3.1399061604466993
Validation loss: 3.18156103903088

Epoch: 5| Step: 4
Training loss: 3.3538156329659445
Validation loss: 3.1798288689272938

Epoch: 5| Step: 5
Training loss: 3.70720849854504
Validation loss: 3.1789794739892843

Epoch: 5| Step: 6
Training loss: 3.821076923178103
Validation loss: 3.1778169142444375

Epoch: 5| Step: 7
Training loss: 3.0151243436613453
Validation loss: 3.1743650500265073

Epoch: 5| Step: 8
Training loss: 3.3394983659589768
Validation loss: 3.1737706696489916

Epoch: 5| Step: 9
Training loss: 3.4253218896342315
Validation loss: 3.1726334503242075

Epoch: 5| Step: 10
Training loss: 3.6986917605750946
Validation loss: 3.171157294209951

Epoch: 19| Step: 0
Training loss: 3.0008899640226523
Validation loss: 3.169672923922335

Epoch: 5| Step: 1
Training loss: 3.7626001389063193
Validation loss: 3.1686571959098453

Epoch: 5| Step: 2
Training loss: 3.6998708083821334
Validation loss: 3.166645775895004

Epoch: 5| Step: 3
Training loss: 3.3258260747654624
Validation loss: 3.1663383115034485

Epoch: 5| Step: 4
Training loss: 2.8804529970264423
Validation loss: 3.1655973081787985

Epoch: 5| Step: 5
Training loss: 3.3126410688195724
Validation loss: 3.164433808228288

Epoch: 5| Step: 6
Training loss: 2.9610449134849834
Validation loss: 3.1636376597416804

Epoch: 5| Step: 7
Training loss: 2.9812298724056863
Validation loss: 3.164710473388682

Epoch: 5| Step: 8
Training loss: 3.3844745596685972
Validation loss: 3.166247543054766

Epoch: 5| Step: 9
Training loss: 4.267634215520978
Validation loss: 3.1687639425822525

Epoch: 5| Step: 10
Training loss: 3.9455140921578287
Validation loss: 3.168268242912486

Epoch: 20| Step: 0
Training loss: 3.2042380283248444
Validation loss: 3.1679065918208726

Epoch: 5| Step: 1
Training loss: 3.673475849920112
Validation loss: 3.1626598794557843

Epoch: 5| Step: 2
Training loss: 2.8278064864557666
Validation loss: 3.1556365250384535

Epoch: 5| Step: 3
Training loss: 3.0948074537294206
Validation loss: 3.1561287623443834

Epoch: 5| Step: 4
Training loss: 3.5397009536812143
Validation loss: 3.1558180604534454

Epoch: 5| Step: 5
Training loss: 3.731660630523811
Validation loss: 3.154449823495647

Epoch: 5| Step: 6
Training loss: 3.736605564630803
Validation loss: 3.1531513565831766

Epoch: 5| Step: 7
Training loss: 3.3465783822116184
Validation loss: 3.1525897449936955

Epoch: 5| Step: 8
Training loss: 3.9110900190776867
Validation loss: 3.151775019642781

Epoch: 5| Step: 9
Training loss: 2.7289369403938224
Validation loss: 3.1499792344749613

Epoch: 5| Step: 10
Training loss: 3.6447083981096453
Validation loss: 3.1501674273598748

Epoch: 21| Step: 0
Training loss: 3.1782791805471575
Validation loss: 3.149343597318262

Epoch: 5| Step: 1
Training loss: 3.5791845626886944
Validation loss: 3.148725018494938

Epoch: 5| Step: 2
Training loss: 3.8080748845278602
Validation loss: 3.147214109900048

Epoch: 5| Step: 3
Training loss: 3.098274236658923
Validation loss: 3.1460757527171124

Epoch: 5| Step: 4
Training loss: 3.756999540522377
Validation loss: 3.147075042653951

Epoch: 5| Step: 5
Training loss: 3.5128493817424897
Validation loss: 3.1447741779035296

Epoch: 5| Step: 6
Training loss: 2.992643555629338
Validation loss: 3.1463091226372786

Epoch: 5| Step: 7
Training loss: 3.3650043960247826
Validation loss: 3.1407186491869434

Epoch: 5| Step: 8
Training loss: 3.305851147540128
Validation loss: 3.140037552289156

Epoch: 5| Step: 9
Training loss: 3.209936129686234
Validation loss: 3.14159086759465

Epoch: 5| Step: 10
Training loss: 3.642366181208344
Validation loss: 3.14384050465892

Epoch: 22| Step: 0
Training loss: 4.017447803777804
Validation loss: 3.1402716223831213

Epoch: 5| Step: 1
Training loss: 3.64648777492142
Validation loss: 3.1372497899403204

Epoch: 5| Step: 2
Training loss: 2.800806447105974
Validation loss: 3.1352590588687903

Epoch: 5| Step: 3
Training loss: 3.603077071467466
Validation loss: 3.1326977319025078

Epoch: 5| Step: 4
Training loss: 3.8916520444498635
Validation loss: 3.1343789212604722

Epoch: 5| Step: 5
Training loss: 3.1709014450824973
Validation loss: 3.1350130516320016

Epoch: 5| Step: 6
Training loss: 3.541473712526828
Validation loss: 3.133352107221101

Epoch: 5| Step: 7
Training loss: 3.4782887491373526
Validation loss: 3.131198609229045

Epoch: 5| Step: 8
Training loss: 2.3350383342071277
Validation loss: 3.1441805096235473

Epoch: 5| Step: 9
Training loss: 3.607931401609274
Validation loss: 3.1895997596882997

Epoch: 5| Step: 10
Training loss: 3.0032320096801186
Validation loss: 3.169821182113614

Epoch: 23| Step: 0
Training loss: 3.2155446508691803
Validation loss: 3.1363502633047213

Epoch: 5| Step: 1
Training loss: 3.3570500334919293
Validation loss: 3.134586020743683

Epoch: 5| Step: 2
Training loss: 3.5336244415225546
Validation loss: 3.13932277239675

Epoch: 5| Step: 3
Training loss: 3.2969409520210218
Validation loss: 3.135340704853028

Epoch: 5| Step: 4
Training loss: 3.7744520888689252
Validation loss: 3.132027266866518

Epoch: 5| Step: 5
Training loss: 3.52510521914315
Validation loss: 3.123092073860233

Epoch: 5| Step: 6
Training loss: 3.461873429548214
Validation loss: 3.121148418891453

Epoch: 5| Step: 7
Training loss: 3.422286892839976
Validation loss: 3.124222440068944

Epoch: 5| Step: 8
Training loss: 3.0837725421033673
Validation loss: 3.1199024832736035

Epoch: 5| Step: 9
Training loss: 3.4807819264087585
Validation loss: 3.1195308226952

Epoch: 5| Step: 10
Training loss: 3.0948644615162473
Validation loss: 3.122140305247249

Epoch: 24| Step: 0
Training loss: 2.5448171340806875
Validation loss: 3.1264037131858577

Epoch: 5| Step: 1
Training loss: 3.073518976354344
Validation loss: 3.1355699240016137

Epoch: 5| Step: 2
Training loss: 3.2442073551046393
Validation loss: 3.1385765997215107

Epoch: 5| Step: 3
Training loss: 3.7275207694976205
Validation loss: 3.12891364372289

Epoch: 5| Step: 4
Training loss: 3.576708517431152
Validation loss: 3.119434334924511

Epoch: 5| Step: 5
Training loss: 4.3114773187298425
Validation loss: 3.112959278068967

Epoch: 5| Step: 6
Training loss: 3.2398635072567945
Validation loss: 3.107659234088249

Epoch: 5| Step: 7
Training loss: 3.322079464351848
Validation loss: 3.106905188749437

Epoch: 5| Step: 8
Training loss: 3.0253356179937234
Validation loss: 3.107613423860456

Epoch: 5| Step: 9
Training loss: 3.8015898641219987
Validation loss: 3.1050271298422434

Epoch: 5| Step: 10
Training loss: 2.9514457328159236
Validation loss: 3.103365023601971

Epoch: 25| Step: 0
Training loss: 3.8716097121223996
Validation loss: 3.100867833829947

Epoch: 5| Step: 1
Training loss: 4.1338484678949685
Validation loss: 3.1000076438076536

Epoch: 5| Step: 2
Training loss: 3.0639498645674683
Validation loss: 3.100105198068597

Epoch: 5| Step: 3
Training loss: 3.8355384510327344
Validation loss: 3.0982467704445242

Epoch: 5| Step: 4
Training loss: 3.8627770136288015
Validation loss: 3.096129890761246

Epoch: 5| Step: 5
Training loss: 3.35932886846051
Validation loss: 3.09721713883673

Epoch: 5| Step: 6
Training loss: 2.730738374116256
Validation loss: 3.097902979483553

Epoch: 5| Step: 7
Training loss: 2.8697264029852607
Validation loss: 3.0975721781018617

Epoch: 5| Step: 8
Training loss: 3.3253967851500854
Validation loss: 3.0991550189079025

Epoch: 5| Step: 9
Training loss: 2.7725244872901107
Validation loss: 3.102508145353102

Epoch: 5| Step: 10
Training loss: 2.7395592943497866
Validation loss: 3.101521837732471

Epoch: 26| Step: 0
Training loss: 3.738889001056228
Validation loss: 3.1046987488972118

Epoch: 5| Step: 1
Training loss: 3.27913270485986
Validation loss: 3.10127727097664

Epoch: 5| Step: 2
Training loss: 3.5563905765256285
Validation loss: 3.0937223602051307

Epoch: 5| Step: 3
Training loss: 3.144984621334835
Validation loss: 3.0925548088973343

Epoch: 5| Step: 4
Training loss: 3.7773505667434613
Validation loss: 3.089206291127462

Epoch: 5| Step: 5
Training loss: 3.1359759029513605
Validation loss: 3.0900795000108356

Epoch: 5| Step: 6
Training loss: 3.130548510524251
Validation loss: 3.0921773583319028

Epoch: 5| Step: 7
Training loss: 3.2820735806080568
Validation loss: 3.094942473173256

Epoch: 5| Step: 8
Training loss: 3.40805565807401
Validation loss: 3.0913759886373082

Epoch: 5| Step: 9
Training loss: 3.171648440232646
Validation loss: 3.0893727752264017

Epoch: 5| Step: 10
Training loss: 3.232962184591634
Validation loss: 3.0868587898027573

Epoch: 27| Step: 0
Training loss: 2.935018262140234
Validation loss: 3.08507190556925

Epoch: 5| Step: 1
Training loss: 2.9272421435153704
Validation loss: 3.0850923160928687

Epoch: 5| Step: 2
Training loss: 3.7316435077647716
Validation loss: 3.083425484443989

Epoch: 5| Step: 3
Training loss: 3.8344833197057415
Validation loss: 3.082720882503709

Epoch: 5| Step: 4
Training loss: 4.106169984638851
Validation loss: 3.0818773743812984

Epoch: 5| Step: 5
Training loss: 3.7182578394287873
Validation loss: 3.0806920218687384

Epoch: 5| Step: 6
Training loss: 3.2267466347087885
Validation loss: 3.0789761463532144

Epoch: 5| Step: 7
Training loss: 3.2591744555974667
Validation loss: 3.0782093523551466

Epoch: 5| Step: 8
Training loss: 2.3955341871063873
Validation loss: 3.0774810535539476

Epoch: 5| Step: 9
Training loss: 2.856101909112204
Validation loss: 3.0783106242639846

Epoch: 5| Step: 10
Training loss: 3.45954856816192
Validation loss: 3.0786563274589898

Epoch: 28| Step: 0
Training loss: 3.523233412014752
Validation loss: 3.0789984540320745

Epoch: 5| Step: 1
Training loss: 4.352916678039798
Validation loss: 3.076177962050216

Epoch: 5| Step: 2
Training loss: 3.1442015670536607
Validation loss: 3.0756972613470195

Epoch: 5| Step: 3
Training loss: 3.0481358193601875
Validation loss: 3.0746366570150547

Epoch: 5| Step: 4
Training loss: 3.2420418947914613
Validation loss: 3.0751379017322074

Epoch: 5| Step: 5
Training loss: 2.874624808335218
Validation loss: 3.0766276720720636

Epoch: 5| Step: 6
Training loss: 3.8351195914310954
Validation loss: 3.0696576895585355

Epoch: 5| Step: 7
Training loss: 3.0332766964274533
Validation loss: 3.0695036229389308

Epoch: 5| Step: 8
Training loss: 3.32181994158386
Validation loss: 3.0672959809765024

Epoch: 5| Step: 9
Training loss: 2.62999694780528
Validation loss: 3.0651870267333923

Epoch: 5| Step: 10
Training loss: 3.400623399018645
Validation loss: 3.0649278362300847

Epoch: 29| Step: 0
Training loss: 2.497772559642809
Validation loss: 3.064444988474197

Epoch: 5| Step: 1
Training loss: 3.4841433050331503
Validation loss: 3.0633657302030666

Epoch: 5| Step: 2
Training loss: 3.4302577628659554
Validation loss: 3.063071084868331

Epoch: 5| Step: 3
Training loss: 3.4673438443953195
Validation loss: 3.0620793507202

Epoch: 5| Step: 4
Training loss: 3.373151060791446
Validation loss: 3.0612725030230927

Epoch: 5| Step: 5
Training loss: 3.5471226273862904
Validation loss: 3.0602628461164625

Epoch: 5| Step: 6
Training loss: 2.7253980363392674
Validation loss: 3.058748972949779

Epoch: 5| Step: 7
Training loss: 3.798718417037314
Validation loss: 3.05851782034751

Epoch: 5| Step: 8
Training loss: 3.0605732053051335
Validation loss: 3.0568645394363236

Epoch: 5| Step: 9
Training loss: 3.6857465033955443
Validation loss: 3.0575295156090037

Epoch: 5| Step: 10
Training loss: 3.3632382911836163
Validation loss: 3.056221644631564

Epoch: 30| Step: 0
Training loss: 3.1394819770219113
Validation loss: 3.0527836985356185

Epoch: 5| Step: 1
Training loss: 3.7211721530161452
Validation loss: 3.053884605013461

Epoch: 5| Step: 2
Training loss: 3.383751437155535
Validation loss: 3.0550477058610848

Epoch: 5| Step: 3
Training loss: 3.02497245208555
Validation loss: 3.0551982924967156

Epoch: 5| Step: 4
Training loss: 2.6640911380425547
Validation loss: 3.0615548103997607

Epoch: 5| Step: 5
Training loss: 3.026372387005456
Validation loss: 3.068724012731624

Epoch: 5| Step: 6
Training loss: 3.650888277424194
Validation loss: 3.0580260910725716

Epoch: 5| Step: 7
Training loss: 3.590822702780004
Validation loss: 3.0479019171971826

Epoch: 5| Step: 8
Training loss: 3.7576344660025582
Validation loss: 3.046895382005511

Epoch: 5| Step: 9
Training loss: 3.6300680314932174
Validation loss: 3.04868343882062

Epoch: 5| Step: 10
Training loss: 2.6057368516602164
Validation loss: 3.050685470199584

Epoch: 31| Step: 0
Training loss: 2.9958410044551114
Validation loss: 3.0549984272699255

Epoch: 5| Step: 1
Training loss: 3.450071616051439
Validation loss: 3.0548264142199493

Epoch: 5| Step: 2
Training loss: 3.5905173980287124
Validation loss: 3.0471721646242425

Epoch: 5| Step: 3
Training loss: 2.590438015106214
Validation loss: 3.0442620561870877

Epoch: 5| Step: 4
Training loss: 3.146284631016418
Validation loss: 3.043382640753183

Epoch: 5| Step: 5
Training loss: 3.687126787340361
Validation loss: 3.0431463177210483

Epoch: 5| Step: 6
Training loss: 3.1509483302561225
Validation loss: 3.0423687734054696

Epoch: 5| Step: 7
Training loss: 3.317299011627373
Validation loss: 3.042056089233183

Epoch: 5| Step: 8
Training loss: 3.295596919078477
Validation loss: 3.0404357877927595

Epoch: 5| Step: 9
Training loss: 3.302538161537372
Validation loss: 3.0385324870243373

Epoch: 5| Step: 10
Training loss: 3.912405794124683
Validation loss: 3.0390792548018313

Epoch: 32| Step: 0
Training loss: 3.1196438473606247
Validation loss: 3.0410806414718574

Epoch: 5| Step: 1
Training loss: 3.9988611507440073
Validation loss: 3.0408605228476335

Epoch: 5| Step: 2
Training loss: 3.1889002099391877
Validation loss: 3.0432112701387877

Epoch: 5| Step: 3
Training loss: 3.475489350038208
Validation loss: 3.041723298576543

Epoch: 5| Step: 4
Training loss: 3.4985036376044465
Validation loss: 3.040679175174368

Epoch: 5| Step: 5
Training loss: 3.57462149263566
Validation loss: 3.0380899457095225

Epoch: 5| Step: 6
Training loss: 2.86977874328325
Validation loss: 3.037082458045504

Epoch: 5| Step: 7
Training loss: 3.362452742801124
Validation loss: 3.036410049332918

Epoch: 5| Step: 8
Training loss: 3.306529151943743
Validation loss: 3.0357074700245668

Epoch: 5| Step: 9
Training loss: 2.750349802831151
Validation loss: 3.033116256557815

Epoch: 5| Step: 10
Training loss: 3.001363285568818
Validation loss: 3.0323384306395917

Epoch: 33| Step: 0
Training loss: 2.9677882192581864
Validation loss: 3.0332359343515343

Epoch: 5| Step: 1
Training loss: 3.4809834349122233
Validation loss: 3.0362777294614705

Epoch: 5| Step: 2
Training loss: 2.834054705472073
Validation loss: 3.0323409517213813

Epoch: 5| Step: 3
Training loss: 3.0088026918711104
Validation loss: 3.036386139510523

Epoch: 5| Step: 4
Training loss: 3.308201862352531
Validation loss: 3.032328402935709

Epoch: 5| Step: 5
Training loss: 3.957451785788529
Validation loss: 3.0292983864599927

Epoch: 5| Step: 6
Training loss: 3.409273817762008
Validation loss: 3.0255565161563256

Epoch: 5| Step: 7
Training loss: 3.354367804962908
Validation loss: 3.021866060841767

Epoch: 5| Step: 8
Training loss: 3.381651928153398
Validation loss: 3.0219484154472265

Epoch: 5| Step: 9
Training loss: 3.2581488346506444
Validation loss: 3.020530896575889

Epoch: 5| Step: 10
Training loss: 3.150423015468177
Validation loss: 3.0202987848580354

Epoch: 34| Step: 0
Training loss: 2.7039597826455464
Validation loss: 3.0184265721659718

Epoch: 5| Step: 1
Training loss: 3.5037690713113676
Validation loss: 3.024429406597767

Epoch: 5| Step: 2
Training loss: 3.325807436086568
Validation loss: 3.031238900525757

Epoch: 5| Step: 3
Training loss: 2.782537440950351
Validation loss: 3.0179562045182196

Epoch: 5| Step: 4
Training loss: 3.011607443883935
Validation loss: 3.0171359123565695

Epoch: 5| Step: 5
Training loss: 3.466628517038779
Validation loss: 3.0160492578353404

Epoch: 5| Step: 6
Training loss: 3.8955772166119282
Validation loss: 3.0156630272911484

Epoch: 5| Step: 7
Training loss: 3.3916028278413273
Validation loss: 3.014822930012454

Epoch: 5| Step: 8
Training loss: 3.9286450317225556
Validation loss: 3.0125469770697353

Epoch: 5| Step: 9
Training loss: 3.2553857048030626
Validation loss: 3.0118375782181537

Epoch: 5| Step: 10
Training loss: 2.70355882636317
Validation loss: 3.0129599042013906

Epoch: 35| Step: 0
Training loss: 3.018481547106049
Validation loss: 3.0143567669691658

Epoch: 5| Step: 1
Training loss: 3.624659423614145
Validation loss: 3.017019340659609

Epoch: 5| Step: 2
Training loss: 4.054557195491719
Validation loss: 3.017073301195046

Epoch: 5| Step: 3
Training loss: 3.2788294992469242
Validation loss: 3.0163070176968643

Epoch: 5| Step: 4
Training loss: 3.267763888407989
Validation loss: 3.016749843030199

Epoch: 5| Step: 5
Training loss: 3.6254991648090007
Validation loss: 3.0180463201015018

Epoch: 5| Step: 6
Training loss: 2.7127723311029897
Validation loss: 3.011749555559154

Epoch: 5| Step: 7
Training loss: 3.824998972774193
Validation loss: 3.0117769730078785

Epoch: 5| Step: 8
Training loss: 2.6475290186284983
Validation loss: 3.0076927899564976

Epoch: 5| Step: 9
Training loss: 3.065921507017886
Validation loss: 3.0055674946833384

Epoch: 5| Step: 10
Training loss: 2.5897136672824512
Validation loss: 3.004112806752325

Epoch: 36| Step: 0
Training loss: 2.4213057310418833
Validation loss: 3.0042761471944313

Epoch: 5| Step: 1
Training loss: 3.1677902303083934
Validation loss: 3.0032097452920556

Epoch: 5| Step: 2
Training loss: 3.2593628924283
Validation loss: 3.014481835499513

Epoch: 5| Step: 3
Training loss: 2.9174121085741183
Validation loss: 3.0063726649537883

Epoch: 5| Step: 4
Training loss: 3.3853628927019335
Validation loss: 2.9980307288906007

Epoch: 5| Step: 5
Training loss: 3.7072037394422854
Validation loss: 3.000617499532662

Epoch: 5| Step: 6
Training loss: 3.443701542618964
Validation loss: 2.9974152238198193

Epoch: 5| Step: 7
Training loss: 3.2254279037599827
Validation loss: 3.00028067475618

Epoch: 5| Step: 8
Training loss: 3.6527667285154166
Validation loss: 2.9984482252080094

Epoch: 5| Step: 9
Training loss: 3.3885391781025116
Validation loss: 2.9981834943525016

Epoch: 5| Step: 10
Training loss: 3.3037496187323163
Validation loss: 2.9975442713909453

Epoch: 37| Step: 0
Training loss: 2.5195418483304226
Validation loss: 2.9956174358122833

Epoch: 5| Step: 1
Training loss: 3.6152376724137447
Validation loss: 2.9958763528739554

Epoch: 5| Step: 2
Training loss: 3.062703495660581
Validation loss: 2.994841696529519

Epoch: 5| Step: 3
Training loss: 3.754191154600517
Validation loss: 2.994763557262928

Epoch: 5| Step: 4
Training loss: 3.1070409861434394
Validation loss: 2.992962244941721

Epoch: 5| Step: 5
Training loss: 3.475541211253379
Validation loss: 2.992376286806002

Epoch: 5| Step: 6
Training loss: 3.5434841803101644
Validation loss: 2.9887724815067935

Epoch: 5| Step: 7
Training loss: 3.0098236098202573
Validation loss: 2.9897973992023794

Epoch: 5| Step: 8
Training loss: 2.8447649475504164
Validation loss: 2.9888573038967863

Epoch: 5| Step: 9
Training loss: 3.4961005695638794
Validation loss: 2.98996132619893

Epoch: 5| Step: 10
Training loss: 3.3770981377464016
Validation loss: 2.9860733655289793

Epoch: 38| Step: 0
Training loss: 2.4301157877458857
Validation loss: 2.986618376528627

Epoch: 5| Step: 1
Training loss: 3.097067393342258
Validation loss: 2.9852677517399115

Epoch: 5| Step: 2
Training loss: 3.071339520402289
Validation loss: 2.98310260979311

Epoch: 5| Step: 3
Training loss: 3.373992062987267
Validation loss: 2.9837058095058806

Epoch: 5| Step: 4
Training loss: 3.7060784903303463
Validation loss: 2.982668059868866

Epoch: 5| Step: 5
Training loss: 3.610841659535125
Validation loss: 2.9988249490818903

Epoch: 5| Step: 6
Training loss: 3.1390191522836113
Validation loss: 2.9871167216165047

Epoch: 5| Step: 7
Training loss: 3.4938835104884767
Validation loss: 2.9830754409978235

Epoch: 5| Step: 8
Training loss: 2.6515291336648716
Validation loss: 2.978061100576481

Epoch: 5| Step: 9
Training loss: 3.5730203923033965
Validation loss: 2.9786774101409863

Epoch: 5| Step: 10
Training loss: 3.5570980408428396
Validation loss: 2.979402696407061

Epoch: 39| Step: 0
Training loss: 3.4771371430807836
Validation loss: 2.9753422529997917

Epoch: 5| Step: 1
Training loss: 2.8850968570416695
Validation loss: 2.9755801409303975

Epoch: 5| Step: 2
Training loss: 3.6907254353164234
Validation loss: 2.9761143807499675

Epoch: 5| Step: 3
Training loss: 3.709418248837951
Validation loss: 3.0071833467783744

Epoch: 5| Step: 4
Training loss: 3.6044977436627454
Validation loss: 2.9737012385058357

Epoch: 5| Step: 5
Training loss: 2.8614024494399826
Validation loss: 2.9714415571901114

Epoch: 5| Step: 6
Training loss: 2.4233479604406436
Validation loss: 2.975511464333816

Epoch: 5| Step: 7
Training loss: 3.149239184825012
Validation loss: 2.9875251900421893

Epoch: 5| Step: 8
Training loss: 3.652877817528596
Validation loss: 3.0046096409857053

Epoch: 5| Step: 9
Training loss: 3.2832678993275715
Validation loss: 2.99427734466988

Epoch: 5| Step: 10
Training loss: 2.856576185570286
Validation loss: 2.980832074503726

Epoch: 40| Step: 0
Training loss: 3.1577519535109695
Validation loss: 2.9834235066750483

Epoch: 5| Step: 1
Training loss: 3.279379175095166
Validation loss: 2.975147727041583

Epoch: 5| Step: 2
Training loss: 3.914340254927726
Validation loss: 2.9727774657826225

Epoch: 5| Step: 3
Training loss: 2.9999872843155
Validation loss: 2.9686906274321503

Epoch: 5| Step: 4
Training loss: 3.1470409542748725
Validation loss: 2.9662395793327496

Epoch: 5| Step: 5
Training loss: 3.067846186098256
Validation loss: 2.970164564646309

Epoch: 5| Step: 6
Training loss: 2.6875023952739596
Validation loss: 2.966270522735827

Epoch: 5| Step: 7
Training loss: 3.496170946686124
Validation loss: 2.9640070144028727

Epoch: 5| Step: 8
Training loss: 3.2745799253864822
Validation loss: 2.9641288243284083

Epoch: 5| Step: 9
Training loss: 3.641920653214664
Validation loss: 2.9627185218086596

Epoch: 5| Step: 10
Training loss: 2.8872395253461725
Validation loss: 2.9614244701806407

Epoch: 41| Step: 0
Training loss: 2.8145278401884393
Validation loss: 2.9605651122585956

Epoch: 5| Step: 1
Training loss: 2.820063614364488
Validation loss: 2.959310245239681

Epoch: 5| Step: 2
Training loss: 3.3803783936279155
Validation loss: 2.960138149657185

Epoch: 5| Step: 3
Training loss: 3.125280138810747
Validation loss: 2.9597560391195628

Epoch: 5| Step: 4
Training loss: 2.87555573109517
Validation loss: 2.9668390467541235

Epoch: 5| Step: 5
Training loss: 2.925603761879075
Validation loss: 2.9665156800839907

Epoch: 5| Step: 6
Training loss: 3.3978986641792672
Validation loss: 2.9715800070859477

Epoch: 5| Step: 7
Training loss: 3.387655478425002
Validation loss: 2.9676374318492305

Epoch: 5| Step: 8
Training loss: 3.549770971083001
Validation loss: 2.9634699837763328

Epoch: 5| Step: 9
Training loss: 4.130492743777246
Validation loss: 2.959896664790398

Epoch: 5| Step: 10
Training loss: 2.9818531186051165
Validation loss: 2.9525147051748615

Epoch: 42| Step: 0
Training loss: 3.083939381054379
Validation loss: 2.9510149340788834

Epoch: 5| Step: 1
Training loss: 3.7765486313324943
Validation loss: 2.9502525216643285

Epoch: 5| Step: 2
Training loss: 3.1916760782313878
Validation loss: 2.951352681165687

Epoch: 5| Step: 3
Training loss: 3.4295900370103203
Validation loss: 2.9515638659486716

Epoch: 5| Step: 4
Training loss: 3.277588899921283
Validation loss: 2.950769997133659

Epoch: 5| Step: 5
Training loss: 2.9309958016278626
Validation loss: 2.946343312572351

Epoch: 5| Step: 6
Training loss: 2.7233701889115354
Validation loss: 2.9469389517951083

Epoch: 5| Step: 7
Training loss: 3.375869638936284
Validation loss: 2.9451550692716424

Epoch: 5| Step: 8
Training loss: 3.3749717428649264
Validation loss: 2.94554250308764

Epoch: 5| Step: 9
Training loss: 3.0531214141043743
Validation loss: 2.94288170024594

Epoch: 5| Step: 10
Training loss: 3.23005070224331
Validation loss: 2.9455548671945553

Epoch: 43| Step: 0
Training loss: 3.5851974222259293
Validation loss: 2.9440485028361683

Epoch: 5| Step: 1
Training loss: 2.8053280409749712
Validation loss: 2.9452897699264056

Epoch: 5| Step: 2
Training loss: 3.4063001156541204
Validation loss: 2.943084257773872

Epoch: 5| Step: 3
Training loss: 3.1423465697980673
Validation loss: 2.9422578699726016

Epoch: 5| Step: 4
Training loss: 3.3623961592171967
Validation loss: 2.9450848370839275

Epoch: 5| Step: 5
Training loss: 3.1243378509919686
Validation loss: 2.9447051879795794

Epoch: 5| Step: 6
Training loss: 3.5741773926056717
Validation loss: 2.948336439003119

Epoch: 5| Step: 7
Training loss: 2.848488349900101
Validation loss: 2.9437386655644806

Epoch: 5| Step: 8
Training loss: 3.5055402775220115
Validation loss: 2.93833315625361

Epoch: 5| Step: 9
Training loss: 2.7735809718887405
Validation loss: 2.9387790510866987

Epoch: 5| Step: 10
Training loss: 3.2939173733713565
Validation loss: 2.9423896903798727

Epoch: 44| Step: 0
Training loss: 3.1408226748075037
Validation loss: 2.943304594358547

Epoch: 5| Step: 1
Training loss: 3.596397685073788
Validation loss: 2.948339255380498

Epoch: 5| Step: 2
Training loss: 2.974178450812155
Validation loss: 2.9546133781942103

Epoch: 5| Step: 3
Training loss: 3.343330998773289
Validation loss: 2.959555618798917

Epoch: 5| Step: 4
Training loss: 2.723098434378197
Validation loss: 2.958420060819134

Epoch: 5| Step: 5
Training loss: 2.8736011585054846
Validation loss: 2.9517687754091524

Epoch: 5| Step: 6
Training loss: 3.082844789996172
Validation loss: 2.943719364206537

Epoch: 5| Step: 7
Training loss: 3.6965146841229406
Validation loss: 2.938080197341076

Epoch: 5| Step: 8
Training loss: 3.2062773288803923
Validation loss: 2.9360700524843746

Epoch: 5| Step: 9
Training loss: 3.4922309207137014
Validation loss: 2.931218087662639

Epoch: 5| Step: 10
Training loss: 3.227802472467845
Validation loss: 2.9262527643813496

Epoch: 45| Step: 0
Training loss: 3.4419978452738924
Validation loss: 2.923149751640079

Epoch: 5| Step: 1
Training loss: 3.1678216902422767
Validation loss: 2.921814890755348

Epoch: 5| Step: 2
Training loss: 3.3855379679540585
Validation loss: 2.9210000036688095

Epoch: 5| Step: 3
Training loss: 3.3099837913001076
Validation loss: 2.9200007545264004

Epoch: 5| Step: 4
Training loss: 2.222455436337005
Validation loss: 2.918914985460083

Epoch: 5| Step: 5
Training loss: 3.406835803133776
Validation loss: 2.9177141819412507

Epoch: 5| Step: 6
Training loss: 3.0312622699292584
Validation loss: 2.9169600542822325

Epoch: 5| Step: 7
Training loss: 3.430068010150856
Validation loss: 2.9171608384637455

Epoch: 5| Step: 8
Training loss: 3.476005320958673
Validation loss: 2.916621872049602

Epoch: 5| Step: 9
Training loss: 2.6989725665874507
Validation loss: 2.9157558932356364

Epoch: 5| Step: 10
Training loss: 3.594872340878991
Validation loss: 2.920577886984439

Epoch: 46| Step: 0
Training loss: 3.345908065727712
Validation loss: 2.916577326963554

Epoch: 5| Step: 1
Training loss: 3.2896594595400312
Validation loss: 2.9147206056292987

Epoch: 5| Step: 2
Training loss: 3.4732410123079043
Validation loss: 2.9142144812999997

Epoch: 5| Step: 3
Training loss: 2.8875361254525385
Validation loss: 2.9148228514487426

Epoch: 5| Step: 4
Training loss: 2.7137405020021776
Validation loss: 2.91666321263497

Epoch: 5| Step: 5
Training loss: 3.4140599859651783
Validation loss: 2.9164914361259076

Epoch: 5| Step: 6
Training loss: 2.930851005939837
Validation loss: 2.9180681225142506

Epoch: 5| Step: 7
Training loss: 3.74672708736405
Validation loss: 2.9155543783267444

Epoch: 5| Step: 8
Training loss: 3.1829184722861976
Validation loss: 2.909669271421601

Epoch: 5| Step: 9
Training loss: 3.2388597438744893
Validation loss: 2.9102505906664633

Epoch: 5| Step: 10
Training loss: 2.8745194738434754
Validation loss: 2.9123678342979242

Epoch: 47| Step: 0
Training loss: 3.243009237920288
Validation loss: 2.9095006364607263

Epoch: 5| Step: 1
Training loss: 2.620862879584039
Validation loss: 2.90877440523682

Epoch: 5| Step: 2
Training loss: 3.1176625895986576
Validation loss: 2.9096449950250376

Epoch: 5| Step: 3
Training loss: 3.4566622607191717
Validation loss: 2.9105753851503304

Epoch: 5| Step: 4
Training loss: 3.380958947930716
Validation loss: 2.911127836917331

Epoch: 5| Step: 5
Training loss: 2.9841180660832136
Validation loss: 2.9129556125498985

Epoch: 5| Step: 6
Training loss: 3.3395920329576545
Validation loss: 2.908801748028725

Epoch: 5| Step: 7
Training loss: 3.134607271847346
Validation loss: 2.9140451513179384

Epoch: 5| Step: 8
Training loss: 3.1740558812510984
Validation loss: 2.9085106871019537

Epoch: 5| Step: 9
Training loss: 3.4381365100062546
Validation loss: 2.907853685152505

Epoch: 5| Step: 10
Training loss: 3.292447846505765
Validation loss: 2.9030844157209414

Epoch: 48| Step: 0
Training loss: 2.9059379163963905
Validation loss: 2.9008079471924275

Epoch: 5| Step: 1
Training loss: 2.86648692373357
Validation loss: 2.900235421268184

Epoch: 5| Step: 2
Training loss: 2.6766965317000246
Validation loss: 2.8999558698969023

Epoch: 5| Step: 3
Training loss: 3.2009213194158366
Validation loss: 2.8999992947688957

Epoch: 5| Step: 4
Training loss: 2.677908615575827
Validation loss: 2.9032094935046606

Epoch: 5| Step: 5
Training loss: 3.280882751258027
Validation loss: 2.9024549103103627

Epoch: 5| Step: 6
Training loss: 3.336474051643447
Validation loss: 2.8981972588669533

Epoch: 5| Step: 7
Training loss: 3.673617464928199
Validation loss: 2.8981076502752425

Epoch: 5| Step: 8
Training loss: 3.874224185189775
Validation loss: 2.89554369518125

Epoch: 5| Step: 9
Training loss: 3.727146190939885
Validation loss: 2.8962084802456762

Epoch: 5| Step: 10
Training loss: 2.543223941028629
Validation loss: 2.895710872971341

Epoch: 49| Step: 0
Training loss: 2.5635802620394417
Validation loss: 2.8960221155943993

Epoch: 5| Step: 1
Training loss: 3.5112776940768833
Validation loss: 2.9047670244858304

Epoch: 5| Step: 2
Training loss: 3.039915460364737
Validation loss: 2.8978627275726487

Epoch: 5| Step: 3
Training loss: 3.4040308731866564
Validation loss: 2.9043584536917604

Epoch: 5| Step: 4
Training loss: 3.59292274573383
Validation loss: 2.900274097019689

Epoch: 5| Step: 5
Training loss: 2.9895838472762426
Validation loss: 2.897933186824517

Epoch: 5| Step: 6
Training loss: 2.9159297738848284
Validation loss: 2.893859040365736

Epoch: 5| Step: 7
Training loss: 2.7427482357713147
Validation loss: 2.8896654287368793

Epoch: 5| Step: 8
Training loss: 3.82674697674294
Validation loss: 2.8890742830972487

Epoch: 5| Step: 9
Training loss: 3.2578149882428296
Validation loss: 2.8883154513980904

Epoch: 5| Step: 10
Training loss: 3.0094157912360693
Validation loss: 2.8886921538635884

Epoch: 50| Step: 0
Training loss: 2.675908574325856
Validation loss: 2.888417241117176

Epoch: 5| Step: 1
Training loss: 3.8089851060948177
Validation loss: 2.8875908312312557

Epoch: 5| Step: 2
Training loss: 3.3883197876346274
Validation loss: 2.887942853369146

Epoch: 5| Step: 3
Training loss: 3.654746504523823
Validation loss: 2.8858377402568554

Epoch: 5| Step: 4
Training loss: 2.631290709119469
Validation loss: 2.8849806692552398

Epoch: 5| Step: 5
Training loss: 3.356676019947869
Validation loss: 2.88410330279248

Epoch: 5| Step: 6
Training loss: 3.3567915097772016
Validation loss: 2.8835662550924557

Epoch: 5| Step: 7
Training loss: 3.0503709348652985
Validation loss: 2.884258375548833

Epoch: 5| Step: 8
Training loss: 2.4121839009868578
Validation loss: 2.8877773973274588

Epoch: 5| Step: 9
Training loss: 3.140648077884737
Validation loss: 2.8921014732696593

Epoch: 5| Step: 10
Training loss: 3.3162603087827573
Validation loss: 2.895524565715985

Epoch: 51| Step: 0
Training loss: 2.994086158690023
Validation loss: 2.898808594335104

Epoch: 5| Step: 1
Training loss: 2.453034709070589
Validation loss: 2.8912528489443043

Epoch: 5| Step: 2
Training loss: 3.131906278443
Validation loss: 2.880948280504635

Epoch: 5| Step: 3
Training loss: 3.6543420231210217
Validation loss: 2.8821344670679494

Epoch: 5| Step: 4
Training loss: 2.93262450439272
Validation loss: 2.8792938938959853

Epoch: 5| Step: 5
Training loss: 3.3042371366345282
Validation loss: 2.882647958986357

Epoch: 5| Step: 6
Training loss: 3.0128214557769017
Validation loss: 2.8785870482060134

Epoch: 5| Step: 7
Training loss: 3.5597199417710903
Validation loss: 2.875912088720646

Epoch: 5| Step: 8
Training loss: 3.4536059290644383
Validation loss: 2.8765792201041966

Epoch: 5| Step: 9
Training loss: 3.0163696634622346
Validation loss: 2.8779302469181713

Epoch: 5| Step: 10
Training loss: 3.24160739350902
Validation loss: 2.874622666188847

Epoch: 52| Step: 0
Training loss: 3.0528407453576927
Validation loss: 2.874810188915174

Epoch: 5| Step: 1
Training loss: 3.086184875616951
Validation loss: 2.872767315805713

Epoch: 5| Step: 2
Training loss: 3.041536789999732
Validation loss: 2.8728029935007333

Epoch: 5| Step: 3
Training loss: 3.3903739590154673
Validation loss: 2.8714157418387294

Epoch: 5| Step: 4
Training loss: 2.2719318870757808
Validation loss: 2.8724000293150405

Epoch: 5| Step: 5
Training loss: 3.0912462371914335
Validation loss: 2.8706263195367105

Epoch: 5| Step: 6
Training loss: 3.5317333869578453
Validation loss: 2.871016401150687

Epoch: 5| Step: 7
Training loss: 3.0522404305883515
Validation loss: 2.8711346326825806

Epoch: 5| Step: 8
Training loss: 2.976065847058057
Validation loss: 2.8690012232263515

Epoch: 5| Step: 9
Training loss: 3.648589365900459
Validation loss: 2.8681104038141982

Epoch: 5| Step: 10
Training loss: 3.5696984896239807
Validation loss: 2.866602657354218

Epoch: 53| Step: 0
Training loss: 2.5000341413074016
Validation loss: 2.8709186513118183

Epoch: 5| Step: 1
Training loss: 3.3883379417146666
Validation loss: 2.870865635267699

Epoch: 5| Step: 2
Training loss: 3.224680501799222
Validation loss: 2.872692257341259

Epoch: 5| Step: 3
Training loss: 3.9159457307509413
Validation loss: 2.872663773020576

Epoch: 5| Step: 4
Training loss: 2.3672627352098936
Validation loss: 2.8837833143275398

Epoch: 5| Step: 5
Training loss: 3.2214048233099377
Validation loss: 2.8682992845143325

Epoch: 5| Step: 6
Training loss: 3.4391223200336043
Validation loss: 2.8654242818067654

Epoch: 5| Step: 7
Training loss: 2.997582733310624
Validation loss: 2.864839051468007

Epoch: 5| Step: 8
Training loss: 2.872697654676793
Validation loss: 2.8641195882064503

Epoch: 5| Step: 9
Training loss: 3.2680902986039264
Validation loss: 2.862294663299446

Epoch: 5| Step: 10
Training loss: 3.357097474692959
Validation loss: 2.8637847616599523

Epoch: 54| Step: 0
Training loss: 3.234942695074749
Validation loss: 2.8622979091666565

Epoch: 5| Step: 1
Training loss: 3.034396553945156
Validation loss: 2.859307606444907

Epoch: 5| Step: 2
Training loss: 3.1807814457250516
Validation loss: 2.861781931284351

Epoch: 5| Step: 3
Training loss: 3.377584668615215
Validation loss: 2.8606247251208927

Epoch: 5| Step: 4
Training loss: 2.908440041611134
Validation loss: 2.8612287360256934

Epoch: 5| Step: 5
Training loss: 3.1233650508262167
Validation loss: 2.859446393278358

Epoch: 5| Step: 6
Training loss: 3.3807541573568094
Validation loss: 2.8587346670378055

Epoch: 5| Step: 7
Training loss: 2.305008791495084
Validation loss: 2.857805073592426

Epoch: 5| Step: 8
Training loss: 2.784142779289958
Validation loss: 2.860807850932185

Epoch: 5| Step: 9
Training loss: 3.7543066091136423
Validation loss: 2.866940474997303

Epoch: 5| Step: 10
Training loss: 3.496582406273981
Validation loss: 2.869992604094115

Epoch: 55| Step: 0
Training loss: 2.9819156439431302
Validation loss: 2.853203656770245

Epoch: 5| Step: 1
Training loss: 3.389041091197076
Validation loss: 2.8531379441622913

Epoch: 5| Step: 2
Training loss: 3.201922232737246
Validation loss: 2.8532142627982253

Epoch: 5| Step: 3
Training loss: 2.877653804483269
Validation loss: 2.8584673367915614

Epoch: 5| Step: 4
Training loss: 3.275313902509673
Validation loss: 2.8624910817945737

Epoch: 5| Step: 5
Training loss: 3.220791659922445
Validation loss: 2.8780148211431227

Epoch: 5| Step: 6
Training loss: 2.848765718317125
Validation loss: 2.8579357650909976

Epoch: 5| Step: 7
Training loss: 3.2622669239024704
Validation loss: 2.853425092102476

Epoch: 5| Step: 8
Training loss: 3.340964895429929
Validation loss: 2.853868865221138

Epoch: 5| Step: 9
Training loss: 2.853290191246994
Validation loss: 2.8556851260335714

Epoch: 5| Step: 10
Training loss: 3.53403558829954
Validation loss: 2.8534873571370927

Epoch: 56| Step: 0
Training loss: 3.275247078231185
Validation loss: 2.8500649410808654

Epoch: 5| Step: 1
Training loss: 3.0859812286755397
Validation loss: 2.846713374105008

Epoch: 5| Step: 2
Training loss: 3.2899094893229224
Validation loss: 2.8456010380063788

Epoch: 5| Step: 3
Training loss: 2.813401395673481
Validation loss: 2.84446797935857

Epoch: 5| Step: 4
Training loss: 3.7033956565614328
Validation loss: 2.8427783523585677

Epoch: 5| Step: 5
Training loss: 2.9702976409042785
Validation loss: 2.8399010147365154

Epoch: 5| Step: 6
Training loss: 3.1912614656474743
Validation loss: 2.8442198220902624

Epoch: 5| Step: 7
Training loss: 2.9179229937008224
Validation loss: 2.843961943767818

Epoch: 5| Step: 8
Training loss: 2.94951057253448
Validation loss: 2.8484123006516744

Epoch: 5| Step: 9
Training loss: 3.2514461820988902
Validation loss: 2.8515353995066617

Epoch: 5| Step: 10
Training loss: 3.098112171385868
Validation loss: 2.849837837326473

Epoch: 57| Step: 0
Training loss: 3.2150558457337133
Validation loss: 2.8463149269795593

Epoch: 5| Step: 1
Training loss: 2.950659797720219
Validation loss: 2.8447253161532253

Epoch: 5| Step: 2
Training loss: 2.9173969081260536
Validation loss: 2.845965172088065

Epoch: 5| Step: 3
Training loss: 2.5254873919552736
Validation loss: 2.8519198618670303

Epoch: 5| Step: 4
Training loss: 3.3030176295041827
Validation loss: 2.849161947549908

Epoch: 5| Step: 5
Training loss: 2.849098123099882
Validation loss: 2.844961167867125

Epoch: 5| Step: 6
Training loss: 3.4152056353696114
Validation loss: 2.8400557153789405

Epoch: 5| Step: 7
Training loss: 3.226039890333571
Validation loss: 2.836450754355667

Epoch: 5| Step: 8
Training loss: 3.4801034789211402
Validation loss: 2.8376333541003027

Epoch: 5| Step: 9
Training loss: 3.5165463744888483
Validation loss: 2.8391372879133008

Epoch: 5| Step: 10
Training loss: 3.01650877340904
Validation loss: 2.8388941380133237

Epoch: 58| Step: 0
Training loss: 3.1117982862355893
Validation loss: 2.8337784030928095

Epoch: 5| Step: 1
Training loss: 3.198006163762339
Validation loss: 2.836640200429707

Epoch: 5| Step: 2
Training loss: 3.3409129433500575
Validation loss: 2.837040520485846

Epoch: 5| Step: 3
Training loss: 3.265322292480038
Validation loss: 2.8370219372326435

Epoch: 5| Step: 4
Training loss: 3.0632630001070273
Validation loss: 2.832647252003335

Epoch: 5| Step: 5
Training loss: 3.0100195775710232
Validation loss: 2.833858131639784

Epoch: 5| Step: 6
Training loss: 3.2273233546487754
Validation loss: 2.8343310252365277

Epoch: 5| Step: 7
Training loss: 2.973869807879341
Validation loss: 2.834926375139344

Epoch: 5| Step: 8
Training loss: 2.9643200397966214
Validation loss: 2.84093231445247

Epoch: 5| Step: 9
Training loss: 3.2259980601655505
Validation loss: 2.8516135392823774

Epoch: 5| Step: 10
Training loss: 3.1376989597901304
Validation loss: 2.860205297735262

Epoch: 59| Step: 0
Training loss: 3.263825865513586
Validation loss: 2.8525816535333557

Epoch: 5| Step: 1
Training loss: 3.6217497362094746
Validation loss: 2.8254766116087247

Epoch: 5| Step: 2
Training loss: 2.966023689057094
Validation loss: 2.838004850934023

Epoch: 5| Step: 3
Training loss: 3.533487336983128
Validation loss: 2.8794187337104753

Epoch: 5| Step: 4
Training loss: 3.1622888185457403
Validation loss: 2.899831997322915

Epoch: 5| Step: 5
Training loss: 3.600858739580678
Validation loss: 2.893697334355496

Epoch: 5| Step: 6
Training loss: 3.3452658381408242
Validation loss: 2.895966590004349

Epoch: 5| Step: 7
Training loss: 2.416718734531078
Validation loss: 2.9402266645920805

Epoch: 5| Step: 8
Training loss: 2.650548942858126
Validation loss: 2.9298903012104915

Epoch: 5| Step: 9
Training loss: 3.447815416276567
Validation loss: 2.88337107043372

Epoch: 5| Step: 10
Training loss: 2.720869356377457
Validation loss: 2.8801312464742637

Epoch: 60| Step: 0
Training loss: 2.9083157652695033
Validation loss: 2.8806166497493706

Epoch: 5| Step: 1
Training loss: 3.0611273355702138
Validation loss: 2.876417724472549

Epoch: 5| Step: 2
Training loss: 3.5069992380089716
Validation loss: 2.873159601536148

Epoch: 5| Step: 3
Training loss: 3.362974713364567
Validation loss: 2.874742281483506

Epoch: 5| Step: 4
Training loss: 2.9960156048825426
Validation loss: 2.874119133672645

Epoch: 5| Step: 5
Training loss: 3.6540799996607762
Validation loss: 2.878626863534625

Epoch: 5| Step: 6
Training loss: 2.607128523994358
Validation loss: 2.8764333446807684

Epoch: 5| Step: 7
Training loss: 3.5669694938328367
Validation loss: 2.8784216493267154

Epoch: 5| Step: 8
Training loss: 2.6026307624850937
Validation loss: 2.8779856269973108

Epoch: 5| Step: 9
Training loss: 3.2445840457889186
Validation loss: 2.8744150906980526

Epoch: 5| Step: 10
Training loss: 3.1911006860583404
Validation loss: 2.8654253142684425

Epoch: 61| Step: 0
Training loss: 3.3045358465221266
Validation loss: 2.830557249167335

Epoch: 5| Step: 1
Training loss: 2.9539982549084964
Validation loss: 2.832698880978476

Epoch: 5| Step: 2
Training loss: 3.2911758700786695
Validation loss: 2.8510921731521943

Epoch: 5| Step: 3
Training loss: 3.084678682877541
Validation loss: 2.848968423655031

Epoch: 5| Step: 4
Training loss: 3.1576065320960502
Validation loss: 2.844172607125599

Epoch: 5| Step: 5
Training loss: 3.07825047580948
Validation loss: 2.8214091761456332

Epoch: 5| Step: 6
Training loss: 3.178128396841689
Validation loss: 2.8146419021338263

Epoch: 5| Step: 7
Training loss: 3.0395551345977863
Validation loss: 2.812186688799922

Epoch: 5| Step: 8
Training loss: 3.1845334778228525
Validation loss: 2.8134587083850358

Epoch: 5| Step: 9
Training loss: 3.392089668033409
Validation loss: 2.8162929749993015

Epoch: 5| Step: 10
Training loss: 2.6763792386090244
Validation loss: 2.817431895889718

Epoch: 62| Step: 0
Training loss: 2.9609967630942604
Validation loss: 2.8155125015457956

Epoch: 5| Step: 1
Training loss: 3.3681273951958164
Validation loss: 2.8159291462898937

Epoch: 5| Step: 2
Training loss: 3.279473541390325
Validation loss: 2.816431213562284

Epoch: 5| Step: 3
Training loss: 3.050848301970011
Validation loss: 2.8159815915976987

Epoch: 5| Step: 4
Training loss: 3.0019866405395654
Validation loss: 2.8105085379816455

Epoch: 5| Step: 5
Training loss: 2.405111762005674
Validation loss: 2.8138503539401523

Epoch: 5| Step: 6
Training loss: 3.0936655360550223
Validation loss: 2.8112813690813256

Epoch: 5| Step: 7
Training loss: 3.421173859969581
Validation loss: 2.8116009933217057

Epoch: 5| Step: 8
Training loss: 3.0464447500207843
Validation loss: 2.8094695962198593

Epoch: 5| Step: 9
Training loss: 2.8112695333532423
Validation loss: 2.8108042847428707

Epoch: 5| Step: 10
Training loss: 3.8490510687627735
Validation loss: 2.808831526667473

Epoch: 63| Step: 0
Training loss: 3.264940692076706
Validation loss: 2.8094471048330867

Epoch: 5| Step: 1
Training loss: 2.684862128612604
Validation loss: 2.8087877665819803

Epoch: 5| Step: 2
Training loss: 2.107001544656717
Validation loss: 2.81084467805708

Epoch: 5| Step: 3
Training loss: 3.4762868021827935
Validation loss: 2.8134820460979495

Epoch: 5| Step: 4
Training loss: 3.2983143633939
Validation loss: 2.818401576579349

Epoch: 5| Step: 5
Training loss: 2.7723541292938916
Validation loss: 2.82161230039327

Epoch: 5| Step: 6
Training loss: 3.2512993782632087
Validation loss: 2.822920207856257

Epoch: 5| Step: 7
Training loss: 3.776494590518026
Validation loss: 2.81874482536564

Epoch: 5| Step: 8
Training loss: 3.4789605603111102
Validation loss: 2.8143987847728265

Epoch: 5| Step: 9
Training loss: 2.9401922671709975
Validation loss: 2.8001378254911855

Epoch: 5| Step: 10
Training loss: 2.8314496304698227
Validation loss: 2.7960651861704093

Epoch: 64| Step: 0
Training loss: 3.242835143334564
Validation loss: 2.796072770545295

Epoch: 5| Step: 1
Training loss: 3.0454977982243325
Validation loss: 2.794250686992315

Epoch: 5| Step: 2
Training loss: 3.0236835231782844
Validation loss: 2.802552722122029

Epoch: 5| Step: 3
Training loss: 2.98241084308495
Validation loss: 2.8069572815010053

Epoch: 5| Step: 4
Training loss: 3.2247933254997134
Validation loss: 2.8238549229394216

Epoch: 5| Step: 5
Training loss: 3.130001643122525
Validation loss: 2.794832177568554

Epoch: 5| Step: 6
Training loss: 3.090217500210689
Validation loss: 2.7953635755226856

Epoch: 5| Step: 7
Training loss: 3.2674397805815123
Validation loss: 2.8014829625027353

Epoch: 5| Step: 8
Training loss: 3.2802571565724277
Validation loss: 2.8474210662865094

Epoch: 5| Step: 9
Training loss: 3.034409596867651
Validation loss: 2.9121103099188397

Epoch: 5| Step: 10
Training loss: 3.0683898341502185
Validation loss: 2.9354458173917486

Epoch: 65| Step: 0
Training loss: 3.3527232474256095
Validation loss: 2.8589268716569602

Epoch: 5| Step: 1
Training loss: 2.452206579420726
Validation loss: 2.8134846138541665

Epoch: 5| Step: 2
Training loss: 2.7661654703952427
Validation loss: 2.793786934496986

Epoch: 5| Step: 3
Training loss: 2.84197036895231
Validation loss: 2.8025759402604624

Epoch: 5| Step: 4
Training loss: 2.7219323135806217
Validation loss: 2.8004094857927644

Epoch: 5| Step: 5
Training loss: 3.747117269667658
Validation loss: 2.799990105025508

Epoch: 5| Step: 6
Training loss: 3.149207842085658
Validation loss: 2.7980782459666815

Epoch: 5| Step: 7
Training loss: 3.515684271418762
Validation loss: 2.7993956194480396

Epoch: 5| Step: 8
Training loss: 3.352303376373638
Validation loss: 2.796545391834229

Epoch: 5| Step: 9
Training loss: 3.3550149701803536
Validation loss: 2.797148013314288

Epoch: 5| Step: 10
Training loss: 2.6533323532690543
Validation loss: 2.79210769801229

Epoch: 66| Step: 0
Training loss: 2.289937864235208
Validation loss: 2.7919023004472874

Epoch: 5| Step: 1
Training loss: 3.239115903113266
Validation loss: 2.79094283396535

Epoch: 5| Step: 2
Training loss: 2.683668643622649
Validation loss: 2.79677022780227

Epoch: 5| Step: 3
Training loss: 2.7402091429589386
Validation loss: 2.8041373910877967

Epoch: 5| Step: 4
Training loss: 2.977259276529778
Validation loss: 2.8112388426650945

Epoch: 5| Step: 5
Training loss: 3.480983845862582
Validation loss: 2.821504129074803

Epoch: 5| Step: 6
Training loss: 3.451969557556084
Validation loss: 2.8156092330685825

Epoch: 5| Step: 7
Training loss: 2.912355470141042
Validation loss: 2.810322036511607

Epoch: 5| Step: 8
Training loss: 3.7563646346640374
Validation loss: 2.7905570573701266

Epoch: 5| Step: 9
Training loss: 3.0917746662973684
Validation loss: 2.7829156450446546

Epoch: 5| Step: 10
Training loss: 3.3612580455543295
Validation loss: 2.7905970648609038

Epoch: 67| Step: 0
Training loss: 2.667971073445639
Validation loss: 2.7969000508102067

Epoch: 5| Step: 1
Training loss: 3.142438678006579
Validation loss: 2.8014237941746627

Epoch: 5| Step: 2
Training loss: 3.1065777795652054
Validation loss: 2.79055260450433

Epoch: 5| Step: 3
Training loss: 3.226476044685773
Validation loss: 2.783113657836215

Epoch: 5| Step: 4
Training loss: 3.192459138206955
Validation loss: 2.785496333927842

Epoch: 5| Step: 5
Training loss: 3.0531351579323407
Validation loss: 2.783573998764084

Epoch: 5| Step: 6
Training loss: 3.5916505735055972
Validation loss: 2.7754802136474264

Epoch: 5| Step: 7
Training loss: 2.80066956280101
Validation loss: 2.7754112863439464

Epoch: 5| Step: 8
Training loss: 2.868937361173371
Validation loss: 2.778107614999306

Epoch: 5| Step: 9
Training loss: 2.848060945448116
Validation loss: 2.7775527808288034

Epoch: 5| Step: 10
Training loss: 3.49847692320037
Validation loss: 2.778020079480638

Epoch: 68| Step: 0
Training loss: 2.827066803117597
Validation loss: 2.78078547515138

Epoch: 5| Step: 1
Training loss: 3.0396337291016304
Validation loss: 2.782409593992474

Epoch: 5| Step: 2
Training loss: 3.1640680760463984
Validation loss: 2.789956549961362

Epoch: 5| Step: 3
Training loss: 3.0859730392534255
Validation loss: 2.7856260731056888

Epoch: 5| Step: 4
Training loss: 2.670015993391849
Validation loss: 2.7843339383203523

Epoch: 5| Step: 5
Training loss: 3.21315137738433
Validation loss: 2.7795218223178493

Epoch: 5| Step: 6
Training loss: 2.751433519051391
Validation loss: 2.778142933139549

Epoch: 5| Step: 7
Training loss: 3.8929120431131037
Validation loss: 2.7818308342778195

Epoch: 5| Step: 8
Training loss: 3.379242667501015
Validation loss: 2.7829273830361188

Epoch: 5| Step: 9
Training loss: 2.6135600444522087
Validation loss: 2.7788911471614837

Epoch: 5| Step: 10
Training loss: 3.133757565233969
Validation loss: 2.773115093990396

Epoch: 69| Step: 0
Training loss: 3.376669859161324
Validation loss: 2.771161141358385

Epoch: 5| Step: 1
Training loss: 2.337514185734915
Validation loss: 2.7860364276926792

Epoch: 5| Step: 2
Training loss: 3.130619185022097
Validation loss: 2.7981860301456987

Epoch: 5| Step: 3
Training loss: 2.478159777480247
Validation loss: 2.7965669144325767

Epoch: 5| Step: 4
Training loss: 3.3278192370731
Validation loss: 2.801522249355273

Epoch: 5| Step: 5
Training loss: 3.232359032149697
Validation loss: 2.7692539550611524

Epoch: 5| Step: 6
Training loss: 2.6639911720370173
Validation loss: 2.763926595465459

Epoch: 5| Step: 7
Training loss: 2.802599456410732
Validation loss: 2.7679099748798692

Epoch: 5| Step: 8
Training loss: 3.1514389081937852
Validation loss: 2.7724687944992885

Epoch: 5| Step: 9
Training loss: 3.8502026492203596
Validation loss: 2.7688722312800396

Epoch: 5| Step: 10
Training loss: 3.3960958898101867
Validation loss: 2.76569244708533

Epoch: 70| Step: 0
Training loss: 3.462950248226488
Validation loss: 2.766155657578372

Epoch: 5| Step: 1
Training loss: 2.9850940736806177
Validation loss: 2.7632890025103074

Epoch: 5| Step: 2
Training loss: 3.0584984931387065
Validation loss: 2.772303052126857

Epoch: 5| Step: 3
Training loss: 3.2450736930014785
Validation loss: 2.7706138535633564

Epoch: 5| Step: 4
Training loss: 2.8560049072885962
Validation loss: 2.7683795948317744

Epoch: 5| Step: 5
Training loss: 3.12850618126423
Validation loss: 2.7807923203425897

Epoch: 5| Step: 6
Training loss: 3.0501000184716345
Validation loss: 2.7669858129687848

Epoch: 5| Step: 7
Training loss: 2.5271629021160837
Validation loss: 2.759157546431602

Epoch: 5| Step: 8
Training loss: 3.423722556576274
Validation loss: 2.7643248580290454

Epoch: 5| Step: 9
Training loss: 2.9257789683110262
Validation loss: 2.7638443923176865

Epoch: 5| Step: 10
Training loss: 3.0587218977584656
Validation loss: 2.7675025915681446

Epoch: 71| Step: 0
Training loss: 3.678451557296222
Validation loss: 2.7689706430611656

Epoch: 5| Step: 1
Training loss: 2.674211606933611
Validation loss: 2.7806570820557286

Epoch: 5| Step: 2
Training loss: 2.4285152833523265
Validation loss: 2.7818232857207046

Epoch: 5| Step: 3
Training loss: 3.131864561277832
Validation loss: 2.7813291539571265

Epoch: 5| Step: 4
Training loss: 3.259861729269743
Validation loss: 2.775621510099689

Epoch: 5| Step: 5
Training loss: 2.978527952074901
Validation loss: 2.7703932900702304

Epoch: 5| Step: 6
Training loss: 3.17219248718946
Validation loss: 2.7539753692477777

Epoch: 5| Step: 7
Training loss: 3.256092523145973
Validation loss: 2.7542557717329714

Epoch: 5| Step: 8
Training loss: 2.9183558522620454
Validation loss: 2.7508410233301857

Epoch: 5| Step: 9
Training loss: 3.3102482753887745
Validation loss: 2.749429595125999

Epoch: 5| Step: 10
Training loss: 2.7393737442045056
Validation loss: 2.7522647207643853

Epoch: 72| Step: 0
Training loss: 3.1980790750390518
Validation loss: 2.750890816858163

Epoch: 5| Step: 1
Training loss: 3.0180347677342834
Validation loss: 2.7516510631866473

Epoch: 5| Step: 2
Training loss: 2.69302040716769
Validation loss: 2.7500698998033237

Epoch: 5| Step: 3
Training loss: 3.2387527104215126
Validation loss: 2.7495371390793233

Epoch: 5| Step: 4
Training loss: 3.1825831769335715
Validation loss: 2.7469470322919425

Epoch: 5| Step: 5
Training loss: 2.6898550316415863
Validation loss: 2.7470389297576885

Epoch: 5| Step: 6
Training loss: 3.2733451447853232
Validation loss: 2.7448717527366804

Epoch: 5| Step: 7
Training loss: 3.2881352438202467
Validation loss: 2.7434726991027842

Epoch: 5| Step: 8
Training loss: 2.56136929756875
Validation loss: 2.748211076499042

Epoch: 5| Step: 9
Training loss: 3.240171389344122
Validation loss: 2.7479548246567402

Epoch: 5| Step: 10
Training loss: 3.2425336905724
Validation loss: 2.7580374242213237

Epoch: 73| Step: 0
Training loss: 2.516205714708253
Validation loss: 2.7526947645171247

Epoch: 5| Step: 1
Training loss: 3.404922646695585
Validation loss: 2.7565858451934955

Epoch: 5| Step: 2
Training loss: 3.2706575447677926
Validation loss: 2.742780900459466

Epoch: 5| Step: 3
Training loss: 2.9367397217282076
Validation loss: 2.7405777958098954

Epoch: 5| Step: 4
Training loss: 3.195927269328863
Validation loss: 2.7400188707313093

Epoch: 5| Step: 5
Training loss: 2.7754413081996945
Validation loss: 2.7411765613312746

Epoch: 5| Step: 6
Training loss: 2.7945067539266564
Validation loss: 2.7401608917637468

Epoch: 5| Step: 7
Training loss: 3.2817059881264323
Validation loss: 2.73965509748719

Epoch: 5| Step: 8
Training loss: 3.1533479851778172
Validation loss: 2.7388608134056853

Epoch: 5| Step: 9
Training loss: 2.9957630119152565
Validation loss: 2.73966907105197

Epoch: 5| Step: 10
Training loss: 3.3181086148539896
Validation loss: 2.7436462034008677

Epoch: 74| Step: 0
Training loss: 3.159264965763614
Validation loss: 2.7467591849416895

Epoch: 5| Step: 1
Training loss: 2.689360484714153
Validation loss: 2.751917471671064

Epoch: 5| Step: 2
Training loss: 2.477288846622866
Validation loss: 2.7418585583116197

Epoch: 5| Step: 3
Training loss: 2.645496817587433
Validation loss: 2.73699596981347

Epoch: 5| Step: 4
Training loss: 3.60204585011566
Validation loss: 2.733978388980252

Epoch: 5| Step: 5
Training loss: 3.079530811243008
Validation loss: 2.733687815301392

Epoch: 5| Step: 6
Training loss: 3.340463895276303
Validation loss: 2.7326381200528456

Epoch: 5| Step: 7
Training loss: 2.6695442072124362
Validation loss: 2.731650051037455

Epoch: 5| Step: 8
Training loss: 3.6137778111076777
Validation loss: 2.7322602384934194

Epoch: 5| Step: 9
Training loss: 3.1905967778406423
Validation loss: 2.73127023436865

Epoch: 5| Step: 10
Training loss: 2.836241314380001
Validation loss: 2.7304068381469366

Epoch: 75| Step: 0
Training loss: 2.9012266655952845
Validation loss: 2.728190896634642

Epoch: 5| Step: 1
Training loss: 3.504990425913056
Validation loss: 2.729820278091747

Epoch: 5| Step: 2
Training loss: 2.597707463957083
Validation loss: 2.7275625357057978

Epoch: 5| Step: 3
Training loss: 3.2646374829217195
Validation loss: 2.7259876216255616

Epoch: 5| Step: 4
Training loss: 3.1990725305699415
Validation loss: 2.723395247495208

Epoch: 5| Step: 5
Training loss: 3.0647965209029087
Validation loss: 2.724920800924554

Epoch: 5| Step: 6
Training loss: 3.1518835703264094
Validation loss: 2.722929084315734

Epoch: 5| Step: 7
Training loss: 3.070843910257731
Validation loss: 2.7217744820130143

Epoch: 5| Step: 8
Training loss: 2.145558151328274
Validation loss: 2.7218076668477056

Epoch: 5| Step: 9
Training loss: 3.3924912621112195
Validation loss: 2.722756819948601

Epoch: 5| Step: 10
Training loss: 3.0156245256334633
Validation loss: 2.727269223612738

Epoch: 76| Step: 0
Training loss: 3.4483712041762544
Validation loss: 2.7256725168183262

Epoch: 5| Step: 1
Training loss: 2.6568697935567998
Validation loss: 2.7233201953127564

Epoch: 5| Step: 2
Training loss: 3.396138994623274
Validation loss: 2.721036341688236

Epoch: 5| Step: 3
Training loss: 2.926908512709692
Validation loss: 2.7189102983678284

Epoch: 5| Step: 4
Training loss: 3.027166703492297
Validation loss: 2.7161870900648135

Epoch: 5| Step: 5
Training loss: 3.0114535401731803
Validation loss: 2.7179375645002812

Epoch: 5| Step: 6
Training loss: 3.161779715193205
Validation loss: 2.7179805660222933

Epoch: 5| Step: 7
Training loss: 2.5769789489312602
Validation loss: 2.717220583897354

Epoch: 5| Step: 8
Training loss: 3.6244980036976973
Validation loss: 2.71628006406891

Epoch: 5| Step: 9
Training loss: 2.6652272829970314
Validation loss: 2.7141252295311737

Epoch: 5| Step: 10
Training loss: 2.8636562627456024
Validation loss: 2.716022298498871

Epoch: 77| Step: 0
Training loss: 2.9804338725637893
Validation loss: 2.712164509168704

Epoch: 5| Step: 1
Training loss: 3.500738883363366
Validation loss: 2.711051177037261

Epoch: 5| Step: 2
Training loss: 3.3188368446496144
Validation loss: 2.7099052228210314

Epoch: 5| Step: 3
Training loss: 2.707918624427214
Validation loss: 2.7113712695823153

Epoch: 5| Step: 4
Training loss: 2.9476388501569506
Validation loss: 2.7131489999133516

Epoch: 5| Step: 5
Training loss: 3.461721912641723
Validation loss: 2.7149127060555

Epoch: 5| Step: 6
Training loss: 2.934682265699364
Validation loss: 2.7171674560739

Epoch: 5| Step: 7
Training loss: 2.6815713649843724
Validation loss: 2.724390195705614

Epoch: 5| Step: 8
Training loss: 3.104121845783712
Validation loss: 2.714726055878827

Epoch: 5| Step: 9
Training loss: 2.8969265271720315
Validation loss: 2.7091495681711506

Epoch: 5| Step: 10
Training loss: 2.721774819213358
Validation loss: 2.7075129785007834

Epoch: 78| Step: 0
Training loss: 3.144509717026429
Validation loss: 2.707770679296421

Epoch: 5| Step: 1
Training loss: 2.3403332027987105
Validation loss: 2.7064437149303

Epoch: 5| Step: 2
Training loss: 2.833203219249792
Validation loss: 2.7062678586619775

Epoch: 5| Step: 3
Training loss: 2.946716945127188
Validation loss: 2.70853840230634

Epoch: 5| Step: 4
Training loss: 3.0463390954989933
Validation loss: 2.7107037468916912

Epoch: 5| Step: 5
Training loss: 2.5144141463973813
Validation loss: 2.712590364006026

Epoch: 5| Step: 6
Training loss: 3.278707191109285
Validation loss: 2.715780585422045

Epoch: 5| Step: 7
Training loss: 3.050432524733445
Validation loss: 2.71322745056748

Epoch: 5| Step: 8
Training loss: 3.2977778206517074
Validation loss: 2.7107147742822875

Epoch: 5| Step: 9
Training loss: 3.2231214152921455
Validation loss: 2.7028618420750523

Epoch: 5| Step: 10
Training loss: 3.580089845861883
Validation loss: 2.70331956840199

Epoch: 79| Step: 0
Training loss: 3.4217329997380834
Validation loss: 2.700879506952767

Epoch: 5| Step: 1
Training loss: 2.5268999562056025
Validation loss: 2.700851875967955

Epoch: 5| Step: 2
Training loss: 2.974111433926297
Validation loss: 2.6980986849506787

Epoch: 5| Step: 3
Training loss: 3.0061219059228192
Validation loss: 2.701024354751927

Epoch: 5| Step: 4
Training loss: 2.7774669335540403
Validation loss: 2.6979643110815603

Epoch: 5| Step: 5
Training loss: 3.328314977247279
Validation loss: 2.7017406034279623

Epoch: 5| Step: 6
Training loss: 3.273817818701338
Validation loss: 2.702158647837823

Epoch: 5| Step: 7
Training loss: 2.9055380000339204
Validation loss: 2.70409259861243

Epoch: 5| Step: 8
Training loss: 2.7547427807484928
Validation loss: 2.7109915915389617

Epoch: 5| Step: 9
Training loss: 3.3645808138212963
Validation loss: 2.7043400090141745

Epoch: 5| Step: 10
Training loss: 2.829186846099784
Validation loss: 2.703468848584766

Epoch: 80| Step: 0
Training loss: 2.809756318247568
Validation loss: 2.6958642633509937

Epoch: 5| Step: 1
Training loss: 3.6284360714479953
Validation loss: 2.693046899059153

Epoch: 5| Step: 2
Training loss: 3.307852597865283
Validation loss: 2.691331530737453

Epoch: 5| Step: 3
Training loss: 2.9193755694523333
Validation loss: 2.6905698944989274

Epoch: 5| Step: 4
Training loss: 2.7114679438718303
Validation loss: 2.688611996016774

Epoch: 5| Step: 5
Training loss: 3.3529212171592344
Validation loss: 2.6889169443753307

Epoch: 5| Step: 6
Training loss: 2.767767211226546
Validation loss: 2.691004445472641

Epoch: 5| Step: 7
Training loss: 2.9731440100103215
Validation loss: 2.6858694849528164

Epoch: 5| Step: 8
Training loss: 2.90104668900462
Validation loss: 2.686938823194998

Epoch: 5| Step: 9
Training loss: 2.8896380414965916
Validation loss: 2.6844736293258515

Epoch: 5| Step: 10
Training loss: 2.828175328265284
Validation loss: 2.6864976971796963

Epoch: 81| Step: 0
Training loss: 3.031481861803297
Validation loss: 2.6846826442308034

Epoch: 5| Step: 1
Training loss: 3.2466272312826816
Validation loss: 2.691519482277993

Epoch: 5| Step: 2
Training loss: 3.491336863987684
Validation loss: 2.6944500818402557

Epoch: 5| Step: 3
Training loss: 3.188217531112926
Validation loss: 2.6963246565387466

Epoch: 5| Step: 4
Training loss: 2.662952270062882
Validation loss: 2.691158956575665

Epoch: 5| Step: 5
Training loss: 2.8330564550611195
Validation loss: 2.6862200459910697

Epoch: 5| Step: 6
Training loss: 2.4049798164393126
Validation loss: 2.6841839333042827

Epoch: 5| Step: 7
Training loss: 3.005551922933656
Validation loss: 2.6804865302322765

Epoch: 5| Step: 8
Training loss: 3.2446613479496467
Validation loss: 2.6810514586198115

Epoch: 5| Step: 9
Training loss: 2.6876369707555865
Validation loss: 2.677867428076514

Epoch: 5| Step: 10
Training loss: 3.2016185660640333
Validation loss: 2.679474234880442

Epoch: 82| Step: 0
Training loss: 2.6768488404008672
Validation loss: 2.6783014910149014

Epoch: 5| Step: 1
Training loss: 2.8719157385193728
Validation loss: 2.6774489766466614

Epoch: 5| Step: 2
Training loss: 2.7134633898046348
Validation loss: 2.678629714929352

Epoch: 5| Step: 3
Training loss: 2.8419067781046254
Validation loss: 2.6791769279332343

Epoch: 5| Step: 4
Training loss: 3.6855740447627303
Validation loss: 2.677738545394949

Epoch: 5| Step: 5
Training loss: 2.7823233087174066
Validation loss: 2.6782331315353027

Epoch: 5| Step: 6
Training loss: 3.4910650646972634
Validation loss: 2.6824415984374994

Epoch: 5| Step: 7
Training loss: 2.824526272779012
Validation loss: 2.6830931521691403

Epoch: 5| Step: 8
Training loss: 3.0117922129496875
Validation loss: 2.6835506292628524

Epoch: 5| Step: 9
Training loss: 3.1356176436552574
Validation loss: 2.6825040362631185

Epoch: 5| Step: 10
Training loss: 2.9078363170601547
Validation loss: 2.6798955843204166

Epoch: 83| Step: 0
Training loss: 3.1535584710408395
Validation loss: 2.6786667581325037

Epoch: 5| Step: 1
Training loss: 2.978644016187718
Validation loss: 2.6762341269300336

Epoch: 5| Step: 2
Training loss: 2.9118278873953023
Validation loss: 2.677951931508651

Epoch: 5| Step: 3
Training loss: 2.524252367282818
Validation loss: 2.6733750025498018

Epoch: 5| Step: 4
Training loss: 3.167814163970736
Validation loss: 2.6784628576843925

Epoch: 5| Step: 5
Training loss: 3.3270122834997324
Validation loss: 2.673417203814685

Epoch: 5| Step: 6
Training loss: 3.1601429716191984
Validation loss: 2.6724886067005027

Epoch: 5| Step: 7
Training loss: 3.6000027868472015
Validation loss: 2.668334250782561

Epoch: 5| Step: 8
Training loss: 2.3684639589427556
Validation loss: 2.6676371606810827

Epoch: 5| Step: 9
Training loss: 2.909255903615171
Validation loss: 2.6690382253089497

Epoch: 5| Step: 10
Training loss: 2.7772267420247543
Validation loss: 2.6665251012367706

Epoch: 84| Step: 0
Training loss: 3.195451728753457
Validation loss: 2.6658764220724698

Epoch: 5| Step: 1
Training loss: 2.898971467303068
Validation loss: 2.6662009871504497

Epoch: 5| Step: 2
Training loss: 2.8985394976578154
Validation loss: 2.6658617693678694

Epoch: 5| Step: 3
Training loss: 2.5471932616044057
Validation loss: 2.6667235993901497

Epoch: 5| Step: 4
Training loss: 2.7514031905110072
Validation loss: 2.6647040761650023

Epoch: 5| Step: 5
Training loss: 3.1043186193222816
Validation loss: 2.664237319098394

Epoch: 5| Step: 6
Training loss: 3.56243066552938
Validation loss: 2.6651794134264217

Epoch: 5| Step: 7
Training loss: 2.792904811740828
Validation loss: 2.6672785980411193

Epoch: 5| Step: 8
Training loss: 2.8867344423520533
Validation loss: 2.662613544414564

Epoch: 5| Step: 9
Training loss: 3.5183222617428873
Validation loss: 2.6669046442558466

Epoch: 5| Step: 10
Training loss: 2.631563609229111
Validation loss: 2.661133935782662

Epoch: 85| Step: 0
Training loss: 3.3428059608956824
Validation loss: 2.6692153981732987

Epoch: 5| Step: 1
Training loss: 2.918457317176768
Validation loss: 2.6698164168264613

Epoch: 5| Step: 2
Training loss: 2.649736384109453
Validation loss: 2.672297044941215

Epoch: 5| Step: 3
Training loss: 3.305615594640988
Validation loss: 2.6595673983826207

Epoch: 5| Step: 4
Training loss: 2.873764104157259
Validation loss: 2.6585770202291434

Epoch: 5| Step: 5
Training loss: 2.8554148114455042
Validation loss: 2.6587519676318117

Epoch: 5| Step: 6
Training loss: 3.3412406275625246
Validation loss: 2.6630229115434667

Epoch: 5| Step: 7
Training loss: 3.4158160073358284
Validation loss: 2.668369575935295

Epoch: 5| Step: 8
Training loss: 2.602899980837085
Validation loss: 2.6649496643621924

Epoch: 5| Step: 9
Training loss: 2.904288337453827
Validation loss: 2.6696161272007672

Epoch: 5| Step: 10
Training loss: 2.6243834906901995
Validation loss: 2.674487036727297

Epoch: 86| Step: 0
Training loss: 2.993039958428391
Validation loss: 2.6883342389632507

Epoch: 5| Step: 1
Training loss: 2.7954878110802404
Validation loss: 2.698388021475688

Epoch: 5| Step: 2
Training loss: 3.6316144382828868
Validation loss: 2.703623093965138

Epoch: 5| Step: 3
Training loss: 2.8549645601067155
Validation loss: 2.7064964584054887

Epoch: 5| Step: 4
Training loss: 2.8484711076403797
Validation loss: 2.7084656701204013

Epoch: 5| Step: 5
Training loss: 2.8017388360121123
Validation loss: 2.7084637240565845

Epoch: 5| Step: 6
Training loss: 2.7503391403539474
Validation loss: 2.7031283876785617

Epoch: 5| Step: 7
Training loss: 2.8610629743294034
Validation loss: 2.6982254568714015

Epoch: 5| Step: 8
Training loss: 3.1403368158164917
Validation loss: 2.698407341902887

Epoch: 5| Step: 9
Training loss: 3.4876389889383743
Validation loss: 2.7126293770195016

Epoch: 5| Step: 10
Training loss: 2.9288745616909093
Validation loss: 2.7047483828527707

Epoch: 87| Step: 0
Training loss: 2.649781732747279
Validation loss: 2.6988045552275257

Epoch: 5| Step: 1
Training loss: 2.8741462103194153
Validation loss: 2.6654098789592684

Epoch: 5| Step: 2
Training loss: 2.9955162874484826
Validation loss: 2.6601760678244815

Epoch: 5| Step: 3
Training loss: 2.593216071268485
Validation loss: 2.658170918757671

Epoch: 5| Step: 4
Training loss: 3.1668648072209136
Validation loss: 2.661043378025741

Epoch: 5| Step: 5
Training loss: 2.926000935719276
Validation loss: 2.6626710867663337

Epoch: 5| Step: 6
Training loss: 3.2632183351084385
Validation loss: 2.6554960624967814

Epoch: 5| Step: 7
Training loss: 3.4393871329202907
Validation loss: 2.6558432878722864

Epoch: 5| Step: 8
Training loss: 3.115257794044026
Validation loss: 2.655524196306015

Epoch: 5| Step: 9
Training loss: 2.8469073196402257
Validation loss: 2.6500667625912895

Epoch: 5| Step: 10
Training loss: 2.9663878027618895
Validation loss: 2.648580604573687

Epoch: 88| Step: 0
Training loss: 3.323383661218753
Validation loss: 2.64853681505831

Epoch: 5| Step: 1
Training loss: 2.7967144797522865
Validation loss: 2.649949935437073

Epoch: 5| Step: 2
Training loss: 2.7634010640561053
Validation loss: 2.645406407748922

Epoch: 5| Step: 3
Training loss: 2.775859709902292
Validation loss: 2.6497606258741495

Epoch: 5| Step: 4
Training loss: 2.8531369396014212
Validation loss: 2.649699374742399

Epoch: 5| Step: 5
Training loss: 2.5156373207311833
Validation loss: 2.648182749652646

Epoch: 5| Step: 6
Training loss: 3.136737752170416
Validation loss: 2.651449996479065

Epoch: 5| Step: 7
Training loss: 3.360616623064767
Validation loss: 2.6521836041172793

Epoch: 5| Step: 8
Training loss: 3.6169976664549597
Validation loss: 2.65965527374071

Epoch: 5| Step: 9
Training loss: 2.8458860989133563
Validation loss: 2.6611117802451387

Epoch: 5| Step: 10
Training loss: 2.637629237330718
Validation loss: 2.6617697195722085

Epoch: 89| Step: 0
Training loss: 2.816314145511991
Validation loss: 2.660152101190492

Epoch: 5| Step: 1
Training loss: 2.4526819691631263
Validation loss: 2.6641811178083747

Epoch: 5| Step: 2
Training loss: 3.104314011185322
Validation loss: 2.664186844224242

Epoch: 5| Step: 3
Training loss: 2.974831385602571
Validation loss: 2.6588079423528086

Epoch: 5| Step: 4
Training loss: 3.415744951799626
Validation loss: 2.6482750027293487

Epoch: 5| Step: 5
Training loss: 3.043101629800897
Validation loss: 2.6434376588569526

Epoch: 5| Step: 6
Training loss: 3.2656768356662793
Validation loss: 2.6432050040184456

Epoch: 5| Step: 7
Training loss: 3.1698896837744694
Validation loss: 2.6398561079941567

Epoch: 5| Step: 8
Training loss: 2.9538248837374605
Validation loss: 2.6402507977265683

Epoch: 5| Step: 9
Training loss: 2.7974430125468626
Validation loss: 2.6379032494894434

Epoch: 5| Step: 10
Training loss: 2.731270908301872
Validation loss: 2.6409766384240405

Epoch: 90| Step: 0
Training loss: 2.728409630608322
Validation loss: 2.6392865027320105

Epoch: 5| Step: 1
Training loss: 3.012872734595367
Validation loss: 2.637682131227316

Epoch: 5| Step: 2
Training loss: 2.6706616061304413
Validation loss: 2.6386860277460618

Epoch: 5| Step: 3
Training loss: 2.9881443366306932
Validation loss: 2.639651283130087

Epoch: 5| Step: 4
Training loss: 3.114212031011485
Validation loss: 2.6508033555555692

Epoch: 5| Step: 5
Training loss: 2.9182798738083706
Validation loss: 2.6706700179589777

Epoch: 5| Step: 6
Training loss: 3.288888958409741
Validation loss: 2.649384363971371

Epoch: 5| Step: 7
Training loss: 3.079646165513295
Validation loss: 2.638564882175136

Epoch: 5| Step: 8
Training loss: 3.3017637336811
Validation loss: 2.6350643050968108

Epoch: 5| Step: 9
Training loss: 3.2989168759338705
Validation loss: 2.6362238020109543

Epoch: 5| Step: 10
Training loss: 2.1468496662627476
Validation loss: 2.6356605346590345

Epoch: 91| Step: 0
Training loss: 2.5851490858756314
Validation loss: 2.636647644907247

Epoch: 5| Step: 1
Training loss: 2.587269235539272
Validation loss: 2.636149318739222

Epoch: 5| Step: 2
Training loss: 3.3886831321859128
Validation loss: 2.6355286522167236

Epoch: 5| Step: 3
Training loss: 3.060764054295812
Validation loss: 2.6352173744758884

Epoch: 5| Step: 4
Training loss: 3.0001185711634863
Validation loss: 2.634658986337842

Epoch: 5| Step: 5
Training loss: 3.093652742957158
Validation loss: 2.6339714201942046

Epoch: 5| Step: 6
Training loss: 3.0006967371267503
Validation loss: 2.6327828741891306

Epoch: 5| Step: 7
Training loss: 2.838632863297537
Validation loss: 2.6321059487230136

Epoch: 5| Step: 8
Training loss: 3.142368269339055
Validation loss: 2.6323180690031007

Epoch: 5| Step: 9
Training loss: 2.983999817917233
Validation loss: 2.640835997215844

Epoch: 5| Step: 10
Training loss: 3.0045663730846415
Validation loss: 2.6363635651522888

Epoch: 92| Step: 0
Training loss: 3.2802212510268993
Validation loss: 2.635717232237122

Epoch: 5| Step: 1
Training loss: 3.1714907258373413
Validation loss: 2.642372327485592

Epoch: 5| Step: 2
Training loss: 3.088227245843909
Validation loss: 2.6362671425636623

Epoch: 5| Step: 3
Training loss: 3.324124936708702
Validation loss: 2.637028147761059

Epoch: 5| Step: 4
Training loss: 2.9054864680300545
Validation loss: 2.6311526641718905

Epoch: 5| Step: 5
Training loss: 2.520324109139994
Validation loss: 2.6351199365859945

Epoch: 5| Step: 6
Training loss: 2.89921752633614
Validation loss: 2.6310884737858404

Epoch: 5| Step: 7
Training loss: 2.769145987203203
Validation loss: 2.6305729393501722

Epoch: 5| Step: 8
Training loss: 2.671001090634722
Validation loss: 2.627239286883397

Epoch: 5| Step: 9
Training loss: 3.0138047807699486
Validation loss: 2.627275104082158

Epoch: 5| Step: 10
Training loss: 2.945623487653856
Validation loss: 2.6253856892225076

Epoch: 93| Step: 0
Training loss: 2.753045649689391
Validation loss: 2.6273582557500577

Epoch: 5| Step: 1
Training loss: 2.2905630980242115
Validation loss: 2.6290331872661232

Epoch: 5| Step: 2
Training loss: 2.950531320084703
Validation loss: 2.6285801745490693

Epoch: 5| Step: 3
Training loss: 2.7038934750876527
Validation loss: 2.627568130850155

Epoch: 5| Step: 4
Training loss: 2.8210403475359116
Validation loss: 2.6297615031546617

Epoch: 5| Step: 5
Training loss: 2.9013315235207093
Validation loss: 2.6243314521619956

Epoch: 5| Step: 6
Training loss: 2.878888030492721
Validation loss: 2.6270338062016534

Epoch: 5| Step: 7
Training loss: 3.8088649242403436
Validation loss: 2.6300567102402588

Epoch: 5| Step: 8
Training loss: 3.470958796901455
Validation loss: 2.6303614512226865

Epoch: 5| Step: 9
Training loss: 2.8113636688279517
Validation loss: 2.631547731846943

Epoch: 5| Step: 10
Training loss: 3.0707392505189586
Validation loss: 2.6347468576089974

Epoch: 94| Step: 0
Training loss: 3.0022977930185184
Validation loss: 2.6335724806409093

Epoch: 5| Step: 1
Training loss: 2.9374964287918783
Validation loss: 2.6316530148909965

Epoch: 5| Step: 2
Training loss: 2.20671859822242
Validation loss: 2.631754907690163

Epoch: 5| Step: 3
Training loss: 3.2728767734154616
Validation loss: 2.634994940668737

Epoch: 5| Step: 4
Training loss: 3.295103202673927
Validation loss: 2.6308851666133344

Epoch: 5| Step: 5
Training loss: 2.6658034020099315
Validation loss: 2.6341219228931867

Epoch: 5| Step: 6
Training loss: 3.2389095051281793
Validation loss: 2.641604485605979

Epoch: 5| Step: 7
Training loss: 2.781748523395332
Validation loss: 2.6331949015636638

Epoch: 5| Step: 8
Training loss: 3.1699096905091615
Validation loss: 2.6295665528583267

Epoch: 5| Step: 9
Training loss: 3.0540886411462447
Validation loss: 2.6294742215632643

Epoch: 5| Step: 10
Training loss: 2.7876580813619816
Validation loss: 2.6266276640292157

Epoch: 95| Step: 0
Training loss: 3.1602881254351796
Validation loss: 2.6173333534050696

Epoch: 5| Step: 1
Training loss: 3.1042382831547446
Validation loss: 2.614711328058594

Epoch: 5| Step: 2
Training loss: 2.6423132200464106
Validation loss: 2.6145270965441383

Epoch: 5| Step: 3
Training loss: 3.31516878115525
Validation loss: 2.6155542034435357

Epoch: 5| Step: 4
Training loss: 2.762176346267051
Validation loss: 2.6139553485823446

Epoch: 5| Step: 5
Training loss: 3.102812776868095
Validation loss: 2.6123159683378048

Epoch: 5| Step: 6
Training loss: 2.940714112572374
Validation loss: 2.611940178835622

Epoch: 5| Step: 7
Training loss: 3.2178626457664476
Validation loss: 2.61505206650965

Epoch: 5| Step: 8
Training loss: 2.355343943463565
Validation loss: 2.6152945497655486

Epoch: 5| Step: 9
Training loss: 2.5213653276324246
Validation loss: 2.6172031520276904

Epoch: 5| Step: 10
Training loss: 3.306794921735992
Validation loss: 2.6260171902972553

Epoch: 96| Step: 0
Training loss: 2.729502931413336
Validation loss: 2.6380513345383863

Epoch: 5| Step: 1
Training loss: 2.8734124817829945
Validation loss: 2.6151654119661774

Epoch: 5| Step: 2
Training loss: 3.0581902521602875
Validation loss: 2.6090015146298757

Epoch: 5| Step: 3
Training loss: 2.8587635824917483
Validation loss: 2.612147588796953

Epoch: 5| Step: 4
Training loss: 3.1177548152790657
Validation loss: 2.61528621224189

Epoch: 5| Step: 5
Training loss: 2.8765430455997834
Validation loss: 2.6188670176955617

Epoch: 5| Step: 6
Training loss: 3.079428150050467
Validation loss: 2.6214690038158404

Epoch: 5| Step: 7
Training loss: 3.191129226520989
Validation loss: 2.620225602836791

Epoch: 5| Step: 8
Training loss: 3.4219005008949197
Validation loss: 2.6226235525348733

Epoch: 5| Step: 9
Training loss: 2.6590573902285013
Validation loss: 2.6209778556597043

Epoch: 5| Step: 10
Training loss: 2.8288202432296505
Validation loss: 2.618164307293723

Epoch: 97| Step: 0
Training loss: 2.582310463817813
Validation loss: 2.6122670722517323

Epoch: 5| Step: 1
Training loss: 2.899544476216163
Validation loss: 2.616697646783835

Epoch: 5| Step: 2
Training loss: 3.234326643282836
Validation loss: 2.6148408544702386

Epoch: 5| Step: 3
Training loss: 2.6683226053314932
Validation loss: 2.6247354199292103

Epoch: 5| Step: 4
Training loss: 3.247770718632722
Validation loss: 2.642796235834379

Epoch: 5| Step: 5
Training loss: 2.962370110734584
Validation loss: 2.662812990753256

Epoch: 5| Step: 6
Training loss: 3.035016580753189
Validation loss: 2.6944158350497593

Epoch: 5| Step: 7
Training loss: 3.2471156892975985
Validation loss: 2.699544281596111

Epoch: 5| Step: 8
Training loss: 2.748131984539582
Validation loss: 2.698245288673892

Epoch: 5| Step: 9
Training loss: 3.2320476027184055
Validation loss: 2.6972904755889293

Epoch: 5| Step: 10
Training loss: 2.9001805084876224
Validation loss: 2.6382881169004153

Epoch: 98| Step: 0
Training loss: 2.8871260627942488
Validation loss: 2.6214855456267374

Epoch: 5| Step: 1
Training loss: 2.747142781299499
Validation loss: 2.6182416981714884

Epoch: 5| Step: 2
Training loss: 3.016733548878926
Validation loss: 2.6349021496595393

Epoch: 5| Step: 3
Training loss: 3.4845206054919027
Validation loss: 2.6434356358259214

Epoch: 5| Step: 4
Training loss: 3.10358445683582
Validation loss: 2.619339364799351

Epoch: 5| Step: 5
Training loss: 2.9487262238776575
Validation loss: 2.616547593881732

Epoch: 5| Step: 6
Training loss: 2.7968797736952977
Validation loss: 2.616681162881079

Epoch: 5| Step: 7
Training loss: 2.6750346457831413
Validation loss: 2.672615820265156

Epoch: 5| Step: 8
Training loss: 3.4588149474580563
Validation loss: 2.738508750117236

Epoch: 5| Step: 9
Training loss: 2.8085294034375257
Validation loss: 2.632368902713568

Epoch: 5| Step: 10
Training loss: 2.943450258063128
Validation loss: 2.6178388328442015

Epoch: 99| Step: 0
Training loss: 2.935472803456708
Validation loss: 2.618135090511614

Epoch: 5| Step: 1
Training loss: 3.2743212979422474
Validation loss: 2.641412072920597

Epoch: 5| Step: 2
Training loss: 3.0691798015986316
Validation loss: 2.6862404960962336

Epoch: 5| Step: 3
Training loss: 3.320932415704989
Validation loss: 2.722569514498586

Epoch: 5| Step: 4
Training loss: 2.385449960356892
Validation loss: 2.743896316550169

Epoch: 5| Step: 5
Training loss: 2.9234575687863407
Validation loss: 2.8050236640613275

Epoch: 5| Step: 6
Training loss: 2.775231009825659
Validation loss: 2.7690909726625734

Epoch: 5| Step: 7
Training loss: 2.8527912993473317
Validation loss: 2.727955585551339

Epoch: 5| Step: 8
Training loss: 3.358031674097665
Validation loss: 2.6546502697885317

Epoch: 5| Step: 9
Training loss: 3.231275759802724
Validation loss: 2.642709488789864

Epoch: 5| Step: 10
Training loss: 2.7294142710256386
Validation loss: 2.6503242666154754

Epoch: 100| Step: 0
Training loss: 3.1099458870059107
Validation loss: 2.6510221415853414

Epoch: 5| Step: 1
Training loss: 2.938844251463965
Validation loss: 2.6527956405571125

Epoch: 5| Step: 2
Training loss: 2.6315634280299287
Validation loss: 2.6608043051911308

Epoch: 5| Step: 3
Training loss: 2.6982629521855284
Validation loss: 2.641276936889572

Epoch: 5| Step: 4
Training loss: 2.885369384231328
Validation loss: 2.6375921834654297

Epoch: 5| Step: 5
Training loss: 2.8875007860587236
Validation loss: 2.6365390520985543

Epoch: 5| Step: 6
Training loss: 3.6629260808061233
Validation loss: 2.6319319438414697

Epoch: 5| Step: 7
Training loss: 2.987782714746357
Validation loss: 2.6217467021976684

Epoch: 5| Step: 8
Training loss: 2.5120353914428293
Validation loss: 2.6168863504350655

Epoch: 5| Step: 9
Training loss: 3.2660871114892855
Validation loss: 2.626582549078057

Epoch: 5| Step: 10
Training loss: 3.0399300481879474
Validation loss: 2.625465750210692

Epoch: 101| Step: 0
Training loss: 2.8522456774729426
Validation loss: 2.6248590692287834

Epoch: 5| Step: 1
Training loss: 3.2402593923273226
Validation loss: 2.623717879267218

Epoch: 5| Step: 2
Training loss: 3.129566670607349
Validation loss: 2.6251228858478854

Epoch: 5| Step: 3
Training loss: 2.9697267230660103
Validation loss: 2.641825267807557

Epoch: 5| Step: 4
Training loss: 1.8521061996347137
Validation loss: 2.6237754240959044

Epoch: 5| Step: 5
Training loss: 2.8921036521096366
Validation loss: 2.6168497160536806

Epoch: 5| Step: 6
Training loss: 3.214087507403777
Validation loss: 2.6116797854784193

Epoch: 5| Step: 7
Training loss: 2.9529606203217305
Validation loss: 2.609728870660143

Epoch: 5| Step: 8
Training loss: 3.396868744873352
Validation loss: 2.609478152719821

Epoch: 5| Step: 9
Training loss: 2.696537347654833
Validation loss: 2.6036091476385197

Epoch: 5| Step: 10
Training loss: 2.944590189063796
Validation loss: 2.6010302972042223

Epoch: 102| Step: 0
Training loss: 2.9586008156933055
Validation loss: 2.6027913156226936

Epoch: 5| Step: 1
Training loss: 2.93511557694279
Validation loss: 2.602235636463296

Epoch: 5| Step: 2
Training loss: 3.051180414127566
Validation loss: 2.605470481744439

Epoch: 5| Step: 3
Training loss: 3.207610771425036
Validation loss: 2.597736669691575

Epoch: 5| Step: 4
Training loss: 2.8357360600160226
Validation loss: 2.6007155651248386

Epoch: 5| Step: 5
Training loss: 3.0772671351273777
Validation loss: 2.5969972709556037

Epoch: 5| Step: 6
Training loss: 2.961614123815557
Validation loss: 2.602978806496692

Epoch: 5| Step: 7
Training loss: 3.0236138186435104
Validation loss: 2.5927744875669916

Epoch: 5| Step: 8
Training loss: 2.829927660283733
Validation loss: 2.5921160803234944

Epoch: 5| Step: 9
Training loss: 2.4757836498033394
Validation loss: 2.5882012925102074

Epoch: 5| Step: 10
Training loss: 2.8929663171636917
Validation loss: 2.58726891747083

Epoch: 103| Step: 0
Training loss: 3.187615635588234
Validation loss: 2.5840611138909177

Epoch: 5| Step: 1
Training loss: 3.0324732878185436
Validation loss: 2.5817573224209283

Epoch: 5| Step: 2
Training loss: 3.133327831777518
Validation loss: 2.584121309699212

Epoch: 5| Step: 3
Training loss: 2.4431570870436135
Validation loss: 2.5827825841076946

Epoch: 5| Step: 4
Training loss: 2.848507600843464
Validation loss: 2.581478764793054

Epoch: 5| Step: 5
Training loss: 2.7626863373617025
Validation loss: 2.5833778403977083

Epoch: 5| Step: 6
Training loss: 3.111557084619327
Validation loss: 2.5921077389609786

Epoch: 5| Step: 7
Training loss: 3.456712059328691
Validation loss: 2.5931774505257104

Epoch: 5| Step: 8
Training loss: 2.7041497906440903
Validation loss: 2.593460818064694

Epoch: 5| Step: 9
Training loss: 2.569529683758359
Validation loss: 2.596490029709212

Epoch: 5| Step: 10
Training loss: 2.8157381701826756
Validation loss: 2.6023901959478373

Epoch: 104| Step: 0
Training loss: 2.583545696594903
Validation loss: 2.6002368702358645

Epoch: 5| Step: 1
Training loss: 2.8253823992075318
Validation loss: 2.6175017519464685

Epoch: 5| Step: 2
Training loss: 2.784818866941544
Validation loss: 2.6142658654871127

Epoch: 5| Step: 3
Training loss: 3.1557536726383772
Validation loss: 2.6129271461731824

Epoch: 5| Step: 4
Training loss: 2.7439142860115493
Validation loss: 2.5894556652616476

Epoch: 5| Step: 5
Training loss: 2.9455127597390653
Validation loss: 2.5808642221991156

Epoch: 5| Step: 6
Training loss: 2.865902313825036
Validation loss: 2.580798013163543

Epoch: 5| Step: 7
Training loss: 3.270345242441651
Validation loss: 2.5783145908165785

Epoch: 5| Step: 8
Training loss: 3.3606946615384836
Validation loss: 2.576141270414495

Epoch: 5| Step: 9
Training loss: 2.9294838796426967
Validation loss: 2.576665561294632

Epoch: 5| Step: 10
Training loss: 2.631797708152308
Validation loss: 2.5780220227450386

Epoch: 105| Step: 0
Training loss: 3.6795185155598356
Validation loss: 2.578231960947874

Epoch: 5| Step: 1
Training loss: 2.875089892765006
Validation loss: 2.576993759829159

Epoch: 5| Step: 2
Training loss: 3.143305910570003
Validation loss: 2.577066480023233

Epoch: 5| Step: 3
Training loss: 2.8790205333702263
Validation loss: 2.576494315612248

Epoch: 5| Step: 4
Training loss: 2.939015423703421
Validation loss: 2.57798066541579

Epoch: 5| Step: 5
Training loss: 2.6597243082975126
Validation loss: 2.5768843205250107

Epoch: 5| Step: 6
Training loss: 3.0339774219977946
Validation loss: 2.5807963771124287

Epoch: 5| Step: 7
Training loss: 2.635821425726309
Validation loss: 2.5802976818489554

Epoch: 5| Step: 8
Training loss: 2.3877770907199527
Validation loss: 2.579855556398604

Epoch: 5| Step: 9
Training loss: 2.930193152977688
Validation loss: 2.5791205240754973

Epoch: 5| Step: 10
Training loss: 2.7706885240235435
Validation loss: 2.5757165920249325

Epoch: 106| Step: 0
Training loss: 3.404734703181417
Validation loss: 2.584202018652832

Epoch: 5| Step: 1
Training loss: 2.4421323139108293
Validation loss: 2.5894629825683

Epoch: 5| Step: 2
Training loss: 3.2645819791601536
Validation loss: 2.6096288724428547

Epoch: 5| Step: 3
Training loss: 2.6660437949232896
Validation loss: 2.620595881268669

Epoch: 5| Step: 4
Training loss: 2.713785659647119
Validation loss: 2.6284357694063427

Epoch: 5| Step: 5
Training loss: 3.0543214232271425
Validation loss: 2.626300113805826

Epoch: 5| Step: 6
Training loss: 2.307711411666045
Validation loss: 2.647280084263508

Epoch: 5| Step: 7
Training loss: 2.9856658859919136
Validation loss: 2.6424489322406703

Epoch: 5| Step: 8
Training loss: 2.86417373965643
Validation loss: 2.638677008743255

Epoch: 5| Step: 9
Training loss: 3.409735899511712
Validation loss: 2.6057815630871173

Epoch: 5| Step: 10
Training loss: 2.8864747642472524
Validation loss: 2.5794126942318396

Epoch: 107| Step: 0
Training loss: 2.2980926815164255
Validation loss: 2.5704800464859483

Epoch: 5| Step: 1
Training loss: 3.2720105103974477
Validation loss: 2.569087729894541

Epoch: 5| Step: 2
Training loss: 2.745343687849757
Validation loss: 2.568986773413943

Epoch: 5| Step: 3
Training loss: 2.922554793810913
Validation loss: 2.5692237143550685

Epoch: 5| Step: 4
Training loss: 3.092850679638137
Validation loss: 2.569446197179544

Epoch: 5| Step: 5
Training loss: 3.14354255249677
Validation loss: 2.5650326328392192

Epoch: 5| Step: 6
Training loss: 3.2230298374841317
Validation loss: 2.564779837637343

Epoch: 5| Step: 7
Training loss: 2.5418428662203287
Validation loss: 2.564128731285654

Epoch: 5| Step: 8
Training loss: 3.067139672690103
Validation loss: 2.5623310952854443

Epoch: 5| Step: 9
Training loss: 3.2923009880938308
Validation loss: 2.5648862191574873

Epoch: 5| Step: 10
Training loss: 2.279338715340054
Validation loss: 2.565879625024749

Epoch: 108| Step: 0
Training loss: 2.722041538193463
Validation loss: 2.567259402672424

Epoch: 5| Step: 1
Training loss: 3.146785937112467
Validation loss: 2.5651731816717476

Epoch: 5| Step: 2
Training loss: 3.249544845400738
Validation loss: 2.5720183410240645

Epoch: 5| Step: 3
Training loss: 2.49954553288016
Validation loss: 2.5674347891022293

Epoch: 5| Step: 4
Training loss: 2.9841604105707966
Validation loss: 2.5726126151204456

Epoch: 5| Step: 5
Training loss: 3.1397679616148713
Validation loss: 2.5713135114418577

Epoch: 5| Step: 6
Training loss: 3.197090530960795
Validation loss: 2.5798471416079956

Epoch: 5| Step: 7
Training loss: 2.7976479767498885
Validation loss: 2.591238357310977

Epoch: 5| Step: 8
Training loss: 2.4279836095542655
Validation loss: 2.6079633791328654

Epoch: 5| Step: 9
Training loss: 3.008288378040593
Validation loss: 2.6408896481384843

Epoch: 5| Step: 10
Training loss: 2.855790356269164
Validation loss: 2.5919562140415944

Epoch: 109| Step: 0
Training loss: 2.9777826326561567
Validation loss: 2.5700387937084455

Epoch: 5| Step: 1
Training loss: 3.2119587483114556
Validation loss: 2.561977787465783

Epoch: 5| Step: 2
Training loss: 2.4345326089827672
Validation loss: 2.5587311588260166

Epoch: 5| Step: 3
Training loss: 2.8922076867057025
Validation loss: 2.552508474017345

Epoch: 5| Step: 4
Training loss: 2.7169199956095
Validation loss: 2.5580628819469404

Epoch: 5| Step: 5
Training loss: 3.180448024066588
Validation loss: 2.5571955261009474

Epoch: 5| Step: 6
Training loss: 3.049735736342321
Validation loss: 2.5593055564725433

Epoch: 5| Step: 7
Training loss: 2.8372201252177156
Validation loss: 2.56079255871476

Epoch: 5| Step: 8
Training loss: 2.3878777369920994
Validation loss: 2.5581556100198695

Epoch: 5| Step: 9
Training loss: 2.9651970734484423
Validation loss: 2.559468673111099

Epoch: 5| Step: 10
Training loss: 3.3645932853874356
Validation loss: 2.5572425358545994

Epoch: 110| Step: 0
Training loss: 2.497565514637894
Validation loss: 2.554845224979225

Epoch: 5| Step: 1
Training loss: 2.605778574216205
Validation loss: 2.559602376207421

Epoch: 5| Step: 2
Training loss: 2.8405389787429955
Validation loss: 2.564412966412845

Epoch: 5| Step: 3
Training loss: 3.2686390086598895
Validation loss: 2.56761854955331

Epoch: 5| Step: 4
Training loss: 2.7096121678721405
Validation loss: 2.572438683927667

Epoch: 5| Step: 5
Training loss: 2.395171585466921
Validation loss: 2.5782264209734405

Epoch: 5| Step: 6
Training loss: 3.1665906060436955
Validation loss: 2.5922588406490403

Epoch: 5| Step: 7
Training loss: 3.0568580818215065
Validation loss: 2.5995873726065555

Epoch: 5| Step: 8
Training loss: 3.12665529280209
Validation loss: 2.5989403976922056

Epoch: 5| Step: 9
Training loss: 3.2480374793159354
Validation loss: 2.6058628378111344

Epoch: 5| Step: 10
Training loss: 3.009167016944101
Validation loss: 2.5789523142490998

Epoch: 111| Step: 0
Training loss: 2.442815023232814
Validation loss: 2.557198062476256

Epoch: 5| Step: 1
Training loss: 3.2046890534053554
Validation loss: 2.5488805906052083

Epoch: 5| Step: 2
Training loss: 2.80365991496155
Validation loss: 2.550306889691978

Epoch: 5| Step: 3
Training loss: 3.2130814794187508
Validation loss: 2.551460759408516

Epoch: 5| Step: 4
Training loss: 2.9487149041882024
Validation loss: 2.5539861978830602

Epoch: 5| Step: 5
Training loss: 3.192375792235704
Validation loss: 2.552454798378351

Epoch: 5| Step: 6
Training loss: 2.54144438308359
Validation loss: 2.5499136975085057

Epoch: 5| Step: 7
Training loss: 2.666402913004019
Validation loss: 2.5485602361631465

Epoch: 5| Step: 8
Training loss: 2.939525798520233
Validation loss: 2.549365692661888

Epoch: 5| Step: 9
Training loss: 2.855838276844256
Validation loss: 2.5512093556604327

Epoch: 5| Step: 10
Training loss: 3.2106545873596395
Validation loss: 2.549985486897511

Epoch: 112| Step: 0
Training loss: 2.969193114288622
Validation loss: 2.546472265069964

Epoch: 5| Step: 1
Training loss: 3.137565830953495
Validation loss: 2.5490544436613938

Epoch: 5| Step: 2
Training loss: 2.587660109132006
Validation loss: 2.562249770453777

Epoch: 5| Step: 3
Training loss: 2.791233788326623
Validation loss: 2.570672063023441

Epoch: 5| Step: 4
Training loss: 2.96117535040929
Validation loss: 2.5978984301978345

Epoch: 5| Step: 5
Training loss: 2.797889823718533
Validation loss: 2.5915865750798814

Epoch: 5| Step: 6
Training loss: 2.8852222987696927
Validation loss: 2.600030231694476

Epoch: 5| Step: 7
Training loss: 2.697951288381608
Validation loss: 2.583246074463795

Epoch: 5| Step: 8
Training loss: 2.7867875424624193
Validation loss: 2.569835064067806

Epoch: 5| Step: 9
Training loss: 2.6424587586504
Validation loss: 2.566272755536015

Epoch: 5| Step: 10
Training loss: 3.687914938129857
Validation loss: 2.5588214140797607

Epoch: 113| Step: 0
Training loss: 2.681778428439905
Validation loss: 2.5496313109253674

Epoch: 5| Step: 1
Training loss: 3.4805710902725315
Validation loss: 2.549194497189914

Epoch: 5| Step: 2
Training loss: 3.1504376970193033
Validation loss: 2.544370127972721

Epoch: 5| Step: 3
Training loss: 2.7121436873887195
Validation loss: 2.543445248456708

Epoch: 5| Step: 4
Training loss: 2.7757456456442013
Validation loss: 2.5387699748131802

Epoch: 5| Step: 5
Training loss: 3.031345641210249
Validation loss: 2.5417632480173373

Epoch: 5| Step: 6
Training loss: 2.8911848196292955
Validation loss: 2.5409110862784097

Epoch: 5| Step: 7
Training loss: 2.9740816125298717
Validation loss: 2.5421235615106608

Epoch: 5| Step: 8
Training loss: 2.785653646389009
Validation loss: 2.5453996318878906

Epoch: 5| Step: 9
Training loss: 2.502097013268301
Validation loss: 2.5490141229338965

Epoch: 5| Step: 10
Training loss: 2.7467341537733727
Validation loss: 2.5511872965995384

Epoch: 114| Step: 0
Training loss: 2.5649488889424217
Validation loss: 2.552875422163885

Epoch: 5| Step: 1
Training loss: 2.70545559119016
Validation loss: 2.555833831100918

Epoch: 5| Step: 2
Training loss: 2.4855435100546432
Validation loss: 2.5611385087058554

Epoch: 5| Step: 3
Training loss: 2.1993265074760537
Validation loss: 2.5626117782964495

Epoch: 5| Step: 4
Training loss: 3.322386616651556
Validation loss: 2.5605145237549105

Epoch: 5| Step: 5
Training loss: 2.805726435360034
Validation loss: 2.5611437768421714

Epoch: 5| Step: 6
Training loss: 3.4667338792691966
Validation loss: 2.5484964189695933

Epoch: 5| Step: 7
Training loss: 2.975015874227278
Validation loss: 2.539859858435259

Epoch: 5| Step: 8
Training loss: 3.1648843333726955
Validation loss: 2.5380850769214987

Epoch: 5| Step: 9
Training loss: 3.0333013770407846
Validation loss: 2.539235648158819

Epoch: 5| Step: 10
Training loss: 2.9254924392250428
Validation loss: 2.5376491685246525

Epoch: 115| Step: 0
Training loss: 3.050393132372273
Validation loss: 2.535188670010895

Epoch: 5| Step: 1
Training loss: 2.7406306615790563
Validation loss: 2.53786507136391

Epoch: 5| Step: 2
Training loss: 2.8748346364106827
Validation loss: 2.540882348323134

Epoch: 5| Step: 3
Training loss: 2.448169440887948
Validation loss: 2.5421425467870313

Epoch: 5| Step: 4
Training loss: 3.256695526161767
Validation loss: 2.549080957880641

Epoch: 5| Step: 5
Training loss: 2.7474872206303083
Validation loss: 2.5539737027972524

Epoch: 5| Step: 6
Training loss: 3.3739777889006795
Validation loss: 2.5616195505738784

Epoch: 5| Step: 7
Training loss: 2.892590983154237
Validation loss: 2.572996653336105

Epoch: 5| Step: 8
Training loss: 2.568161641330899
Validation loss: 2.5859286866376943

Epoch: 5| Step: 9
Training loss: 3.1615512253983598
Validation loss: 2.5738146535379967

Epoch: 5| Step: 10
Training loss: 2.5723235544504344
Validation loss: 2.568799284541623

Epoch: 116| Step: 0
Training loss: 2.7534084871240143
Validation loss: 2.5687859862663953

Epoch: 5| Step: 1
Training loss: 2.6837979034995563
Validation loss: 2.561191518395538

Epoch: 5| Step: 2
Training loss: 2.5865581954582875
Validation loss: 2.554548135502054

Epoch: 5| Step: 3
Training loss: 2.8548184135665227
Validation loss: 2.5502153811137185

Epoch: 5| Step: 4
Training loss: 2.832687827984324
Validation loss: 2.553642854892965

Epoch: 5| Step: 5
Training loss: 2.867577632794366
Validation loss: 2.5470557718338536

Epoch: 5| Step: 6
Training loss: 3.5699832689336666
Validation loss: 2.5557634583357327

Epoch: 5| Step: 7
Training loss: 3.074590057091358
Validation loss: 2.5528169469484694

Epoch: 5| Step: 8
Training loss: 2.734862976128688
Validation loss: 2.5545585474089663

Epoch: 5| Step: 9
Training loss: 3.0650838734039523
Validation loss: 2.5416388393299614

Epoch: 5| Step: 10
Training loss: 2.540469486971532
Validation loss: 2.541577740234369

Epoch: 117| Step: 0
Training loss: 2.552778177972743
Validation loss: 2.5391179792907477

Epoch: 5| Step: 1
Training loss: 3.4055849878540796
Validation loss: 2.5403510093888713

Epoch: 5| Step: 2
Training loss: 2.7672348940305436
Validation loss: 2.5385004721195146

Epoch: 5| Step: 3
Training loss: 3.411664107234301
Validation loss: 2.5403321853107146

Epoch: 5| Step: 4
Training loss: 3.0443608793065495
Validation loss: 2.538189467408911

Epoch: 5| Step: 5
Training loss: 2.522550066629712
Validation loss: 2.537687648363658

Epoch: 5| Step: 6
Training loss: 2.3201709023372064
Validation loss: 2.5309042593834765

Epoch: 5| Step: 7
Training loss: 2.743870927583207
Validation loss: 2.5353261400036566

Epoch: 5| Step: 8
Training loss: 3.0145967143582784
Validation loss: 2.531798002231842

Epoch: 5| Step: 9
Training loss: 2.991286817006059
Validation loss: 2.5312383021757

Epoch: 5| Step: 10
Training loss: 2.7150740930552946
Validation loss: 2.5322937802850904

Epoch: 118| Step: 0
Training loss: 3.243751975703878
Validation loss: 2.53092607081144

Epoch: 5| Step: 1
Training loss: 2.8495703858603263
Validation loss: 2.536685733709223

Epoch: 5| Step: 2
Training loss: 3.15558322624229
Validation loss: 2.540730638051869

Epoch: 5| Step: 3
Training loss: 2.6577687129249203
Validation loss: 2.5438861704555045

Epoch: 5| Step: 4
Training loss: 2.848765216165758
Validation loss: 2.5433900006400862

Epoch: 5| Step: 5
Training loss: 2.310613739258637
Validation loss: 2.5393702166735026

Epoch: 5| Step: 6
Training loss: 3.052937115888458
Validation loss: 2.534403689913603

Epoch: 5| Step: 7
Training loss: 3.0313793036814256
Validation loss: 2.534767202810845

Epoch: 5| Step: 8
Training loss: 2.8382269915291016
Validation loss: 2.5308820689266858

Epoch: 5| Step: 9
Training loss: 2.5257390630840746
Validation loss: 2.529079673564242

Epoch: 5| Step: 10
Training loss: 3.0857208562205765
Validation loss: 2.527187653176455

Epoch: 119| Step: 0
Training loss: 3.2947118813214016
Validation loss: 2.5289144006591107

Epoch: 5| Step: 1
Training loss: 2.8118380297358434
Validation loss: 2.5322544480493847

Epoch: 5| Step: 2
Training loss: 2.9881738581090995
Validation loss: 2.532609004299371

Epoch: 5| Step: 3
Training loss: 2.9192592723843243
Validation loss: 2.5301078854026433

Epoch: 5| Step: 4
Training loss: 2.6831433669269575
Validation loss: 2.535140171300564

Epoch: 5| Step: 5
Training loss: 3.058426931613784
Validation loss: 2.537243742050871

Epoch: 5| Step: 6
Training loss: 3.1331923865683704
Validation loss: 2.5347457015592263

Epoch: 5| Step: 7
Training loss: 2.454156840833112
Validation loss: 2.53960100923709

Epoch: 5| Step: 8
Training loss: 2.5218620933382065
Validation loss: 2.5410896673802403

Epoch: 5| Step: 9
Training loss: 2.698174148900135
Validation loss: 2.5404542381011535

Epoch: 5| Step: 10
Training loss: 2.949497477515966
Validation loss: 2.5409253703832233

Epoch: 120| Step: 0
Training loss: 3.311782759263606
Validation loss: 2.5442476191649637

Epoch: 5| Step: 1
Training loss: 2.8795239886983506
Validation loss: 2.5471726633709775

Epoch: 5| Step: 2
Training loss: 2.4262067879194844
Validation loss: 2.5453582682405416

Epoch: 5| Step: 3
Training loss: 2.802424545973801
Validation loss: 2.546260446296298

Epoch: 5| Step: 4
Training loss: 2.201105477280232
Validation loss: 2.5450847269122567

Epoch: 5| Step: 5
Training loss: 2.7238484950680486
Validation loss: 2.548299320068829

Epoch: 5| Step: 6
Training loss: 3.10084413910148
Validation loss: 2.542549080651193

Epoch: 5| Step: 7
Training loss: 2.606151211190479
Validation loss: 2.550344437707912

Epoch: 5| Step: 8
Training loss: 3.2138892943538524
Validation loss: 2.5563475209250273

Epoch: 5| Step: 9
Training loss: 3.311085380934975
Validation loss: 2.5503160312216697

Epoch: 5| Step: 10
Training loss: 2.788490557329874
Validation loss: 2.556304761926477

Epoch: 121| Step: 0
Training loss: 2.707357631895879
Validation loss: 2.533702994096557

Epoch: 5| Step: 1
Training loss: 2.737236400437025
Validation loss: 2.523810380410855

Epoch: 5| Step: 2
Training loss: 2.9321018697364045
Validation loss: 2.5217430541442587

Epoch: 5| Step: 3
Training loss: 3.397806323840583
Validation loss: 2.5211250409624606

Epoch: 5| Step: 4
Training loss: 2.908606773427229
Validation loss: 2.516974082636852

Epoch: 5| Step: 5
Training loss: 2.9265207494394114
Validation loss: 2.515446286562549

Epoch: 5| Step: 6
Training loss: 3.0226605030541607
Validation loss: 2.5147166909420005

Epoch: 5| Step: 7
Training loss: 2.679613740756697
Validation loss: 2.5143228935554

Epoch: 5| Step: 8
Training loss: 2.7688895747910345
Validation loss: 2.51841041211407

Epoch: 5| Step: 9
Training loss: 3.012627094800998
Validation loss: 2.5167241773721387

Epoch: 5| Step: 10
Training loss: 2.3284182779831664
Validation loss: 2.520087588867129

Epoch: 122| Step: 0
Training loss: 2.5720845059502833
Validation loss: 2.5324257171448803

Epoch: 5| Step: 1
Training loss: 2.6499712168731846
Validation loss: 2.5441474605445986

Epoch: 5| Step: 2
Training loss: 2.746139417461225
Validation loss: 2.574069284867176

Epoch: 5| Step: 3
Training loss: 3.2589485511241985
Validation loss: 2.6165517755788334

Epoch: 5| Step: 4
Training loss: 2.82920218339143
Validation loss: 2.5886038017197994

Epoch: 5| Step: 5
Training loss: 3.093174119776303
Validation loss: 2.5611655219285834

Epoch: 5| Step: 6
Training loss: 3.159574664982398
Validation loss: 2.538206712556318

Epoch: 5| Step: 7
Training loss: 2.723980224599211
Validation loss: 2.5203322567937914

Epoch: 5| Step: 8
Training loss: 3.0700646220311496
Validation loss: 2.5196375421334274

Epoch: 5| Step: 9
Training loss: 2.859335810491773
Validation loss: 2.5233079999024617

Epoch: 5| Step: 10
Training loss: 2.5677013177885484
Validation loss: 2.52732395566879

Epoch: 123| Step: 0
Training loss: 2.8064416696728047
Validation loss: 2.530988419685951

Epoch: 5| Step: 1
Training loss: 3.35983287441053
Validation loss: 2.537994758999609

Epoch: 5| Step: 2
Training loss: 3.127090975256284
Validation loss: 2.5407719448577297

Epoch: 5| Step: 3
Training loss: 3.628151411671738
Validation loss: 2.5379045297863256

Epoch: 5| Step: 4
Training loss: 2.5184578435057
Validation loss: 2.532820504684954

Epoch: 5| Step: 5
Training loss: 2.696632128550529
Validation loss: 2.527755504694684

Epoch: 5| Step: 6
Training loss: 3.056591484479194
Validation loss: 2.5272514779203368

Epoch: 5| Step: 7
Training loss: 2.5696265514094643
Validation loss: 2.5296996486087107

Epoch: 5| Step: 8
Training loss: 2.6049059212769303
Validation loss: 2.5516860870393687

Epoch: 5| Step: 9
Training loss: 2.681504503811467
Validation loss: 2.5799917841442896

Epoch: 5| Step: 10
Training loss: 2.614892847553607
Validation loss: 2.589931174934175

Epoch: 124| Step: 0
Training loss: 3.2033478450016415
Validation loss: 2.5809398137298376

Epoch: 5| Step: 1
Training loss: 2.7572339885709214
Validation loss: 2.5655330872566395

Epoch: 5| Step: 2
Training loss: 2.7337753074252533
Validation loss: 2.543272408563279

Epoch: 5| Step: 3
Training loss: 2.730784036445364
Validation loss: 2.534727972674696

Epoch: 5| Step: 4
Training loss: 2.867081393323598
Validation loss: 2.524938233313633

Epoch: 5| Step: 5
Training loss: 3.0252361615265366
Validation loss: 2.523509531590917

Epoch: 5| Step: 6
Training loss: 2.692069759439967
Validation loss: 2.523714893084309

Epoch: 5| Step: 7
Training loss: 3.0016289103447615
Validation loss: 2.5200580691948784

Epoch: 5| Step: 8
Training loss: 2.65394312597421
Validation loss: 2.5214667958702064

Epoch: 5| Step: 9
Training loss: 3.203693023186898
Validation loss: 2.521587330930073

Epoch: 5| Step: 10
Training loss: 2.5692967781959797
Validation loss: 2.524484927839619

Epoch: 125| Step: 0
Training loss: 3.0962178569506693
Validation loss: 2.529414948044142

Epoch: 5| Step: 1
Training loss: 2.9458423411129537
Validation loss: 2.5311297518902145

Epoch: 5| Step: 2
Training loss: 2.3580518637689294
Validation loss: 2.5370125733668902

Epoch: 5| Step: 3
Training loss: 2.6649468260250093
Validation loss: 2.53673948631706

Epoch: 5| Step: 4
Training loss: 2.9528227151836743
Validation loss: 2.5374906949423734

Epoch: 5| Step: 5
Training loss: 3.2825627198804184
Validation loss: 2.5362806990548648

Epoch: 5| Step: 6
Training loss: 2.919255842203833
Validation loss: 2.536493695366703

Epoch: 5| Step: 7
Training loss: 2.7391253379842806
Validation loss: 2.5393579666713966

Epoch: 5| Step: 8
Training loss: 2.6113746884288167
Validation loss: 2.54076742654864

Epoch: 5| Step: 9
Training loss: 3.0992032165368855
Validation loss: 2.5449384308311283

Epoch: 5| Step: 10
Training loss: 2.5988970324384315
Validation loss: 2.5416260202816776

Epoch: 126| Step: 0
Training loss: 3.488151658952003
Validation loss: 2.5393823343650967

Epoch: 5| Step: 1
Training loss: 2.691720000251404
Validation loss: 2.5435364850605184

Epoch: 5| Step: 2
Training loss: 2.5467848498531733
Validation loss: 2.534854121271129

Epoch: 5| Step: 3
Training loss: 3.2252113154768605
Validation loss: 2.5326588521994906

Epoch: 5| Step: 4
Training loss: 2.756278067724861
Validation loss: 2.528452299541699

Epoch: 5| Step: 5
Training loss: 2.9794185683095935
Validation loss: 2.525266010702103

Epoch: 5| Step: 6
Training loss: 2.5610258002242112
Validation loss: 2.520568461186572

Epoch: 5| Step: 7
Training loss: 2.3063479891173224
Validation loss: 2.5238500717723404

Epoch: 5| Step: 8
Training loss: 2.8807380469684265
Validation loss: 2.5219397059830597

Epoch: 5| Step: 9
Training loss: 2.81226644605897
Validation loss: 2.5223879480328995

Epoch: 5| Step: 10
Training loss: 2.9496415195221544
Validation loss: 2.5264853690487046

Epoch: 127| Step: 0
Training loss: 2.2966680109087476
Validation loss: 2.5451982833309246

Epoch: 5| Step: 1
Training loss: 2.900502746675424
Validation loss: 2.5471875117087452

Epoch: 5| Step: 2
Training loss: 2.259463013851281
Validation loss: 2.558922251654605

Epoch: 5| Step: 3
Training loss: 2.7361772973521226
Validation loss: 2.5459891275347846

Epoch: 5| Step: 4
Training loss: 3.37217226600688
Validation loss: 2.5593896352698153

Epoch: 5| Step: 5
Training loss: 2.7981242368218644
Validation loss: 2.5624548154979583

Epoch: 5| Step: 6
Training loss: 3.043015289930127
Validation loss: 2.5622129902353774

Epoch: 5| Step: 7
Training loss: 2.847182497403872
Validation loss: 2.562843293755996

Epoch: 5| Step: 8
Training loss: 2.6543136719655704
Validation loss: 2.5619730774063822

Epoch: 5| Step: 9
Training loss: 2.9561337276763653
Validation loss: 2.5567754606222626

Epoch: 5| Step: 10
Training loss: 3.3651426970336527
Validation loss: 2.53998130360525

Epoch: 128| Step: 0
Training loss: 2.306406601962069
Validation loss: 2.5338747288254786

Epoch: 5| Step: 1
Training loss: 3.249999853280871
Validation loss: 2.5220597162969907

Epoch: 5| Step: 2
Training loss: 2.87002580983323
Validation loss: 2.521651808797665

Epoch: 5| Step: 3
Training loss: 3.026653147035672
Validation loss: 2.519226441416285

Epoch: 5| Step: 4
Training loss: 2.793791109674424
Validation loss: 2.525883068048786

Epoch: 5| Step: 5
Training loss: 2.6943513345088332
Validation loss: 2.527548445982438

Epoch: 5| Step: 6
Training loss: 3.090722346146881
Validation loss: 2.5415333589009217

Epoch: 5| Step: 7
Training loss: 2.9745297036174705
Validation loss: 2.546900609351511

Epoch: 5| Step: 8
Training loss: 2.7083606620779133
Validation loss: 2.5402291696292307

Epoch: 5| Step: 9
Training loss: 2.856216270197534
Validation loss: 2.5415851898354047

Epoch: 5| Step: 10
Training loss: 2.66547416805873
Validation loss: 2.539625423052696

Epoch: 129| Step: 0
Training loss: 3.0184052454110435
Validation loss: 2.5386096181288305

Epoch: 5| Step: 1
Training loss: 2.921644232301668
Validation loss: 2.5407124030295773

Epoch: 5| Step: 2
Training loss: 2.6227027286687123
Validation loss: 2.5448227850667586

Epoch: 5| Step: 3
Training loss: 2.655189481967369
Validation loss: 2.5372131852361384

Epoch: 5| Step: 4
Training loss: 2.3672334269987805
Validation loss: 2.5493626849122797

Epoch: 5| Step: 5
Training loss: 2.8258862143446857
Validation loss: 2.5398200316860375

Epoch: 5| Step: 6
Training loss: 3.369069575790704
Validation loss: 2.5454976877065816

Epoch: 5| Step: 7
Training loss: 3.042530268171421
Validation loss: 2.5286066697679384

Epoch: 5| Step: 8
Training loss: 2.560958491687962
Validation loss: 2.5280689444767175

Epoch: 5| Step: 9
Training loss: 2.8983733383439154
Validation loss: 2.51791714700058

Epoch: 5| Step: 10
Training loss: 2.817229638654624
Validation loss: 2.5186325964770457

Epoch: 130| Step: 0
Training loss: 2.8340200452183146
Validation loss: 2.5121985199765757

Epoch: 5| Step: 1
Training loss: 2.79041554518228
Validation loss: 2.508600966094943

Epoch: 5| Step: 2
Training loss: 3.0391553849880006
Validation loss: 2.5131372823401636

Epoch: 5| Step: 3
Training loss: 2.76328855626265
Validation loss: 2.5070309966659567

Epoch: 5| Step: 4
Training loss: 3.139943974232011
Validation loss: 2.507180692335901

Epoch: 5| Step: 5
Training loss: 2.944169609470734
Validation loss: 2.5100644585827627

Epoch: 5| Step: 6
Training loss: 3.131583945613282
Validation loss: 2.5169806766609413

Epoch: 5| Step: 7
Training loss: 2.3042108592462642
Validation loss: 2.5138725730148814

Epoch: 5| Step: 8
Training loss: 2.4913782222842378
Validation loss: 2.5164927455581183

Epoch: 5| Step: 9
Training loss: 3.0697996376088583
Validation loss: 2.519511463481555

Epoch: 5| Step: 10
Training loss: 2.504093538085039
Validation loss: 2.5336876771831958

Epoch: 131| Step: 0
Training loss: 2.8805187166172392
Validation loss: 2.532427378371456

Epoch: 5| Step: 1
Training loss: 2.3308353904230423
Validation loss: 2.5498352301565337

Epoch: 5| Step: 2
Training loss: 2.262143847848893
Validation loss: 2.545263994200508

Epoch: 5| Step: 3
Training loss: 3.158619359601612
Validation loss: 2.53654372464934

Epoch: 5| Step: 4
Training loss: 3.038918146073559
Validation loss: 2.521195385597676

Epoch: 5| Step: 5
Training loss: 2.6340598934955852
Validation loss: 2.520099428988637

Epoch: 5| Step: 6
Training loss: 2.7168082834164675
Validation loss: 2.5098112984219334

Epoch: 5| Step: 7
Training loss: 3.3792765331791528
Validation loss: 2.503233460309282

Epoch: 5| Step: 8
Training loss: 2.8213110342256242
Validation loss: 2.5074237456615545

Epoch: 5| Step: 9
Training loss: 2.7204315422431593
Validation loss: 2.5000288438671245

Epoch: 5| Step: 10
Training loss: 3.0709633173837014
Validation loss: 2.501696038474176

Epoch: 132| Step: 0
Training loss: 3.5945383285323422
Validation loss: 2.5052913331124746

Epoch: 5| Step: 1
Training loss: 2.805513818092561
Validation loss: 2.512374998119777

Epoch: 5| Step: 2
Training loss: 2.823881728032535
Validation loss: 2.535557373466376

Epoch: 5| Step: 3
Training loss: 2.5770866383742344
Validation loss: 2.5633184074996653

Epoch: 5| Step: 4
Training loss: 2.8015170653744423
Validation loss: 2.5577485988919486

Epoch: 5| Step: 5
Training loss: 3.0008662880406267
Validation loss: 2.5307511598089065

Epoch: 5| Step: 6
Training loss: 2.9549821130821172
Validation loss: 2.5086072591959367

Epoch: 5| Step: 7
Training loss: 2.8692194004034213
Validation loss: 2.499067072971524

Epoch: 5| Step: 8
Training loss: 2.4701826550056123
Validation loss: 2.5043622904579195

Epoch: 5| Step: 9
Training loss: 2.543715219470791
Validation loss: 2.505611089941611

Epoch: 5| Step: 10
Training loss: 2.676254787449695
Validation loss: 2.5091036260938107

Epoch: 133| Step: 0
Training loss: 2.9306403073012572
Validation loss: 2.5096942653816083

Epoch: 5| Step: 1
Training loss: 2.8527882906893285
Validation loss: 2.5104106102551538

Epoch: 5| Step: 2
Training loss: 3.129649708558261
Validation loss: 2.5114937756823497

Epoch: 5| Step: 3
Training loss: 3.0494808693263997
Validation loss: 2.513545899474538

Epoch: 5| Step: 4
Training loss: 2.5064676547015208
Validation loss: 2.513512100810041

Epoch: 5| Step: 5
Training loss: 2.9415116208923475
Validation loss: 2.5149072983655865

Epoch: 5| Step: 6
Training loss: 2.3326923193766174
Validation loss: 2.5184012718361677

Epoch: 5| Step: 7
Training loss: 2.661866208429411
Validation loss: 2.522621554454812

Epoch: 5| Step: 8
Training loss: 3.3834643715974946
Validation loss: 2.516179920305885

Epoch: 5| Step: 9
Training loss: 2.59284148333496
Validation loss: 2.52508808621168

Epoch: 5| Step: 10
Training loss: 2.819443333651152
Validation loss: 2.5405033508220947

Epoch: 134| Step: 0
Training loss: 2.172364872635824
Validation loss: 2.5532852292670856

Epoch: 5| Step: 1
Training loss: 2.7974116487161926
Validation loss: 2.5664975219125687

Epoch: 5| Step: 2
Training loss: 3.0831446890644063
Validation loss: 2.563309356346034

Epoch: 5| Step: 3
Training loss: 2.9570202846147415
Validation loss: 2.5461714040887466

Epoch: 5| Step: 4
Training loss: 2.506407632412995
Validation loss: 2.5226515746112774

Epoch: 5| Step: 5
Training loss: 2.7172555433443675
Validation loss: 2.5139886314347866

Epoch: 5| Step: 6
Training loss: 3.1212063459919235
Validation loss: 2.499602823599317

Epoch: 5| Step: 7
Training loss: 2.796575775336636
Validation loss: 2.504186266256496

Epoch: 5| Step: 8
Training loss: 2.483958755267461
Validation loss: 2.5017082858757727

Epoch: 5| Step: 9
Training loss: 3.3093948205168817
Validation loss: 2.5016123935177976

Epoch: 5| Step: 10
Training loss: 3.045509384468988
Validation loss: 2.5016088374755623

Epoch: 135| Step: 0
Training loss: 2.822260640809829
Validation loss: 2.493960692742262

Epoch: 5| Step: 1
Training loss: 2.6518120885934677
Validation loss: 2.4966669639766743

Epoch: 5| Step: 2
Training loss: 3.1036578962630745
Validation loss: 2.4909944633883785

Epoch: 5| Step: 3
Training loss: 2.9758208544863054
Validation loss: 2.4889449374870356

Epoch: 5| Step: 4
Training loss: 2.672727393101375
Validation loss: 2.485803290685185

Epoch: 5| Step: 5
Training loss: 2.397579474539052
Validation loss: 2.489498271013277

Epoch: 5| Step: 6
Training loss: 2.57014135469226
Validation loss: 2.489759198961972

Epoch: 5| Step: 7
Training loss: 3.3652726324544746
Validation loss: 2.49155063845319

Epoch: 5| Step: 8
Training loss: 2.7815540447563025
Validation loss: 2.488205028295123

Epoch: 5| Step: 9
Training loss: 2.4824749860627
Validation loss: 2.493898797682772

Epoch: 5| Step: 10
Training loss: 3.088925848617023
Validation loss: 2.5040564165744437

Epoch: 136| Step: 0
Training loss: 2.5383209554162134
Validation loss: 2.517871145127255

Epoch: 5| Step: 1
Training loss: 3.106772248789275
Validation loss: 2.515056768346811

Epoch: 5| Step: 2
Training loss: 2.8490341892406983
Validation loss: 2.5251732515304495

Epoch: 5| Step: 3
Training loss: 2.9927369253242455
Validation loss: 2.5250922416993813

Epoch: 5| Step: 4
Training loss: 3.0648428849591727
Validation loss: 2.5103122888787053

Epoch: 5| Step: 5
Training loss: 2.6290539817622185
Validation loss: 2.513649896515946

Epoch: 5| Step: 6
Training loss: 2.5825249319728694
Validation loss: 2.508232587278476

Epoch: 5| Step: 7
Training loss: 2.0340538040891856
Validation loss: 2.4960356741580423

Epoch: 5| Step: 8
Training loss: 3.0251193629903854
Validation loss: 2.506217376919733

Epoch: 5| Step: 9
Training loss: 2.978767759563924
Validation loss: 2.5050398008152435

Epoch: 5| Step: 10
Training loss: 2.9030138271631922
Validation loss: 2.503652918710203

Epoch: 137| Step: 0
Training loss: 2.8023831988180308
Validation loss: 2.5100619225829837

Epoch: 5| Step: 1
Training loss: 2.779325269284639
Validation loss: 2.4989463010973783

Epoch: 5| Step: 2
Training loss: 3.219324301437292
Validation loss: 2.5089273536429313

Epoch: 5| Step: 3
Training loss: 2.7536179411915964
Validation loss: 2.49999910477653

Epoch: 5| Step: 4
Training loss: 3.165924955807649
Validation loss: 2.5055891144182536

Epoch: 5| Step: 5
Training loss: 2.9977546872581198
Validation loss: 2.5071184620617863

Epoch: 5| Step: 6
Training loss: 2.627766014737699
Validation loss: 2.5028578748605876

Epoch: 5| Step: 7
Training loss: 2.453261353414666
Validation loss: 2.501253271267473

Epoch: 5| Step: 8
Training loss: 2.7300614693117633
Validation loss: 2.5024838004334162

Epoch: 5| Step: 9
Training loss: 2.565202915724277
Validation loss: 2.498319790332984

Epoch: 5| Step: 10
Training loss: 2.600395238619255
Validation loss: 2.500840470333567

Epoch: 138| Step: 0
Training loss: 2.6720630066518516
Validation loss: 2.503996742943465

Epoch: 5| Step: 1
Training loss: 2.5020489879053964
Validation loss: 2.5013301366697753

Epoch: 5| Step: 2
Training loss: 3.232206935593622
Validation loss: 2.509310467440564

Epoch: 5| Step: 3
Training loss: 2.749374318470733
Validation loss: 2.517026561382662

Epoch: 5| Step: 4
Training loss: 2.897820173056136
Validation loss: 2.51239876222523

Epoch: 5| Step: 5
Training loss: 2.7612402688956283
Validation loss: 2.511065303346139

Epoch: 5| Step: 6
Training loss: 2.7201532710592247
Validation loss: 2.5068944953456582

Epoch: 5| Step: 7
Training loss: 2.8061443147532823
Validation loss: 2.500329989527653

Epoch: 5| Step: 8
Training loss: 2.9578772358931236
Validation loss: 2.496203029983367

Epoch: 5| Step: 9
Training loss: 2.7632738884980665
Validation loss: 2.492152372700234

Epoch: 5| Step: 10
Training loss: 2.6506582306350897
Validation loss: 2.4907155825417964

Epoch: 139| Step: 0
Training loss: 2.5998005900573884
Validation loss: 2.4874729028253304

Epoch: 5| Step: 1
Training loss: 2.2122632692059576
Validation loss: 2.4917608006340006

Epoch: 5| Step: 2
Training loss: 2.880974573967915
Validation loss: 2.488470900343448

Epoch: 5| Step: 3
Training loss: 2.47127124150148
Validation loss: 2.4870682235532926

Epoch: 5| Step: 4
Training loss: 3.109352150071113
Validation loss: 2.4894892614338096

Epoch: 5| Step: 5
Training loss: 2.8897099876745784
Validation loss: 2.49897891901398

Epoch: 5| Step: 6
Training loss: 2.9949839300829444
Validation loss: 2.508086621867923

Epoch: 5| Step: 7
Training loss: 2.558088273065058
Validation loss: 2.518273980424159

Epoch: 5| Step: 8
Training loss: 3.1084857224923
Validation loss: 2.535046113921961

Epoch: 5| Step: 9
Training loss: 2.796388040272191
Validation loss: 2.5519066410204183

Epoch: 5| Step: 10
Training loss: 3.1479370628182584
Validation loss: 2.5367952650150176

Epoch: 140| Step: 0
Training loss: 2.4513539524008303
Validation loss: 2.520551533729523

Epoch: 5| Step: 1
Training loss: 2.7067888599994623
Validation loss: 2.506230258421495

Epoch: 5| Step: 2
Training loss: 3.1926506165872155
Validation loss: 2.498352839195725

Epoch: 5| Step: 3
Training loss: 2.810751307768714
Validation loss: 2.485697007508597

Epoch: 5| Step: 4
Training loss: 3.209292545020844
Validation loss: 2.488375463724209

Epoch: 5| Step: 5
Training loss: 3.0355668937740687
Validation loss: 2.482561636993364

Epoch: 5| Step: 6
Training loss: 2.6341402684592286
Validation loss: 2.4835673044914084

Epoch: 5| Step: 7
Training loss: 2.384790518815863
Validation loss: 2.4791137280856677

Epoch: 5| Step: 8
Training loss: 2.595642318759662
Validation loss: 2.4783106320680255

Epoch: 5| Step: 9
Training loss: 2.7558162910235153
Validation loss: 2.4832159088374084

Epoch: 5| Step: 10
Training loss: 2.943491405621607
Validation loss: 2.48971912166295

Epoch: 141| Step: 0
Training loss: 2.2044084206046675
Validation loss: 2.5046650481622423

Epoch: 5| Step: 1
Training loss: 2.4155000523555548
Validation loss: 2.5177576890493194

Epoch: 5| Step: 2
Training loss: 2.2905936994925105
Validation loss: 2.556789902254843

Epoch: 5| Step: 3
Training loss: 3.003526839762357
Validation loss: 2.5765661444677064

Epoch: 5| Step: 4
Training loss: 2.6945476829003385
Validation loss: 2.586062893344316

Epoch: 5| Step: 5
Training loss: 3.3862349396712554
Validation loss: 2.560408356095368

Epoch: 5| Step: 6
Training loss: 2.7219144448226293
Validation loss: 2.529197396406952

Epoch: 5| Step: 7
Training loss: 2.8128275362665405
Validation loss: 2.5023645089032565

Epoch: 5| Step: 8
Training loss: 3.2972038792013616
Validation loss: 2.487800082713278

Epoch: 5| Step: 9
Training loss: 2.7904654428419846
Validation loss: 2.4803756963838945

Epoch: 5| Step: 10
Training loss: 3.0431420567023335
Validation loss: 2.483188815748976

Epoch: 142| Step: 0
Training loss: 2.9932862498000734
Validation loss: 2.487324164376982

Epoch: 5| Step: 1
Training loss: 2.6793071154320725
Validation loss: 2.4895036413208804

Epoch: 5| Step: 2
Training loss: 2.9613049764751165
Validation loss: 2.4966534314102615

Epoch: 5| Step: 3
Training loss: 2.569490156253948
Validation loss: 2.4949718897240865

Epoch: 5| Step: 4
Training loss: 3.186058316786029
Validation loss: 2.499538039523343

Epoch: 5| Step: 5
Training loss: 2.9760770627165454
Validation loss: 2.498567120300555

Epoch: 5| Step: 6
Training loss: 2.533473698174031
Validation loss: 2.50695113135717

Epoch: 5| Step: 7
Training loss: 2.997914861201807
Validation loss: 2.570354333786414

Epoch: 5| Step: 8
Training loss: 2.782767663987531
Validation loss: 2.544030662787941

Epoch: 5| Step: 9
Training loss: 2.7158347098233984
Validation loss: 2.54954897165014

Epoch: 5| Step: 10
Training loss: 2.9958551702291567
Validation loss: 2.5623458697898753

Epoch: 143| Step: 0
Training loss: 2.8878247693547014
Validation loss: 2.5667015863841716

Epoch: 5| Step: 1
Training loss: 3.183335369835114
Validation loss: 2.5674698599579493

Epoch: 5| Step: 2
Training loss: 2.710732487998489
Validation loss: 2.55052666936677

Epoch: 5| Step: 3
Training loss: 3.1280665800906444
Validation loss: 2.5793876819904162

Epoch: 5| Step: 4
Training loss: 3.02341321201081
Validation loss: 2.5702753165002514

Epoch: 5| Step: 5
Training loss: 2.5849144516740092
Validation loss: 2.5807476844982915

Epoch: 5| Step: 6
Training loss: 2.8413755124149414
Validation loss: 2.5210889349231373

Epoch: 5| Step: 7
Training loss: 2.4448273881389233
Validation loss: 2.4941823436484385

Epoch: 5| Step: 8
Training loss: 2.444392119435245
Validation loss: 2.4731499458798494

Epoch: 5| Step: 9
Training loss: 2.958725558503524
Validation loss: 2.4731912204459947

Epoch: 5| Step: 10
Training loss: 2.7878916443904016
Validation loss: 2.4735988146305874

Epoch: 144| Step: 0
Training loss: 2.701471517607231
Validation loss: 2.4798959838325225

Epoch: 5| Step: 1
Training loss: 2.245896199702392
Validation loss: 2.48366547385593

Epoch: 5| Step: 2
Training loss: 2.826095442934595
Validation loss: 2.4889811668298676

Epoch: 5| Step: 3
Training loss: 2.6558672460907045
Validation loss: 2.4848992435733526

Epoch: 5| Step: 4
Training loss: 3.0700034260187077
Validation loss: 2.484854960036385

Epoch: 5| Step: 5
Training loss: 2.9619354740303403
Validation loss: 2.4841165664228204

Epoch: 5| Step: 6
Training loss: 2.492430480783383
Validation loss: 2.4898210157105964

Epoch: 5| Step: 7
Training loss: 2.694537507467727
Validation loss: 2.4864698568332675

Epoch: 5| Step: 8
Training loss: 3.238641845357779
Validation loss: 2.481691383197356

Epoch: 5| Step: 9
Training loss: 2.622209973585038
Validation loss: 2.488712486112544

Epoch: 5| Step: 10
Training loss: 3.112431389845267
Validation loss: 2.492433208551037

Epoch: 145| Step: 0
Training loss: 3.2892600971950383
Validation loss: 2.4862325447755924

Epoch: 5| Step: 1
Training loss: 2.9728753589379213
Validation loss: 2.489789042858073

Epoch: 5| Step: 2
Training loss: 2.9969240950301144
Validation loss: 2.474413860116094

Epoch: 5| Step: 3
Training loss: 1.9563133156374592
Validation loss: 2.4709837270747257

Epoch: 5| Step: 4
Training loss: 2.9285357436554666
Validation loss: 2.4713945177491

Epoch: 5| Step: 5
Training loss: 2.5765592502182546
Validation loss: 2.475158311958327

Epoch: 5| Step: 6
Training loss: 3.141963540645733
Validation loss: 2.4697913562773444

Epoch: 5| Step: 7
Training loss: 2.5044556965594444
Validation loss: 2.4716169388610862

Epoch: 5| Step: 8
Training loss: 2.811981407673826
Validation loss: 2.4721854457844383

Epoch: 5| Step: 9
Training loss: 2.762017952818536
Validation loss: 2.4761376749413353

Epoch: 5| Step: 10
Training loss: 2.528245626431657
Validation loss: 2.490599988767354

Epoch: 146| Step: 0
Training loss: 3.1017188506030062
Validation loss: 2.494930678524644

Epoch: 5| Step: 1
Training loss: 2.69077190569664
Validation loss: 2.4950261002133733

Epoch: 5| Step: 2
Training loss: 2.419537603796751
Validation loss: 2.5032227878105173

Epoch: 5| Step: 3
Training loss: 2.866526514515931
Validation loss: 2.5143904839263795

Epoch: 5| Step: 4
Training loss: 2.4929075725512173
Validation loss: 2.526305991017781

Epoch: 5| Step: 5
Training loss: 3.0493701597168683
Validation loss: 2.516248787316843

Epoch: 5| Step: 6
Training loss: 2.6305836828335525
Validation loss: 2.5072475447786777

Epoch: 5| Step: 7
Training loss: 2.670920128882439
Validation loss: 2.5016849582208875

Epoch: 5| Step: 8
Training loss: 3.185558251244248
Validation loss: 2.4882985154681707

Epoch: 5| Step: 9
Training loss: 2.4405414483963046
Validation loss: 2.4669275578269323

Epoch: 5| Step: 10
Training loss: 2.961928712511165
Validation loss: 2.472684511866451

Epoch: 147| Step: 0
Training loss: 2.780325575226803
Validation loss: 2.472038947423323

Epoch: 5| Step: 1
Training loss: 2.587765511421398
Validation loss: 2.471772891134959

Epoch: 5| Step: 2
Training loss: 3.0073137142235153
Validation loss: 2.472701458048788

Epoch: 5| Step: 3
Training loss: 2.8781584929299506
Validation loss: 2.4710294761623195

Epoch: 5| Step: 4
Training loss: 2.3130847088598654
Validation loss: 2.474131546217484

Epoch: 5| Step: 5
Training loss: 2.7072537153244767
Validation loss: 2.4796133734190478

Epoch: 5| Step: 6
Training loss: 2.491167104732473
Validation loss: 2.4768875937130446

Epoch: 5| Step: 7
Training loss: 3.0254817232290088
Validation loss: 2.4773048330480294

Epoch: 5| Step: 8
Training loss: 2.924496866627249
Validation loss: 2.492303017059319

Epoch: 5| Step: 9
Training loss: 3.047189393084496
Validation loss: 2.5009793465501167

Epoch: 5| Step: 10
Training loss: 2.931817747657749
Validation loss: 2.4934804260724914

Epoch: 148| Step: 0
Training loss: 2.829470825325327
Validation loss: 2.50354386049089

Epoch: 5| Step: 1
Training loss: 2.8513936031959317
Validation loss: 2.5075131966299002

Epoch: 5| Step: 2
Training loss: 2.507277767415991
Validation loss: 2.500443021426505

Epoch: 5| Step: 3
Training loss: 2.3867363312568495
Validation loss: 2.491093891979383

Epoch: 5| Step: 4
Training loss: 2.460682301686169
Validation loss: 2.4895089611577963

Epoch: 5| Step: 5
Training loss: 2.6433202768542925
Validation loss: 2.477157605121133

Epoch: 5| Step: 6
Training loss: 3.3115143659102375
Validation loss: 2.4717421036856626

Epoch: 5| Step: 7
Training loss: 2.7064623214210335
Validation loss: 2.4689168960609025

Epoch: 5| Step: 8
Training loss: 3.2865740498253424
Validation loss: 2.459817929947229

Epoch: 5| Step: 9
Training loss: 2.5737173608060013
Validation loss: 2.457933604753368

Epoch: 5| Step: 10
Training loss: 2.8297121431319265
Validation loss: 2.4592114551011246

Epoch: 149| Step: 0
Training loss: 2.5381603340144907
Validation loss: 2.4613724341958316

Epoch: 5| Step: 1
Training loss: 3.073574672444098
Validation loss: 2.467852925725433

Epoch: 5| Step: 2
Training loss: 2.383223901472705
Validation loss: 2.4643488977589767

Epoch: 5| Step: 3
Training loss: 3.0690651415203796
Validation loss: 2.4678978633792936

Epoch: 5| Step: 4
Training loss: 3.109695341391496
Validation loss: 2.467482121191254

Epoch: 5| Step: 5
Training loss: 3.107074749330116
Validation loss: 2.4767556824715866

Epoch: 5| Step: 6
Training loss: 2.278933040865513
Validation loss: 2.4766926173405728

Epoch: 5| Step: 7
Training loss: 2.60766673563517
Validation loss: 2.4872094571147403

Epoch: 5| Step: 8
Training loss: 2.9161372839658197
Validation loss: 2.4872989918992787

Epoch: 5| Step: 9
Training loss: 2.512997220312206
Validation loss: 2.5036218331372035

Epoch: 5| Step: 10
Training loss: 2.7329210175855057
Validation loss: 2.507848918830401

Epoch: 150| Step: 0
Training loss: 2.976857248365873
Validation loss: 2.498444337740642

Epoch: 5| Step: 1
Training loss: 2.920972062397489
Validation loss: 2.509015150910997

Epoch: 5| Step: 2
Training loss: 2.6491326514123545
Validation loss: 2.5014762078372015

Epoch: 5| Step: 3
Training loss: 2.9477642186154926
Validation loss: 2.4995219173453744

Epoch: 5| Step: 4
Training loss: 3.1949216421723996
Validation loss: 2.482869929677091

Epoch: 5| Step: 5
Training loss: 2.6288719685148725
Validation loss: 2.480403009340772

Epoch: 5| Step: 6
Training loss: 2.7390774645399296
Validation loss: 2.47086111978364

Epoch: 5| Step: 7
Training loss: 3.0467184955798907
Validation loss: 2.466023110605529

Epoch: 5| Step: 8
Training loss: 2.1910688443112587
Validation loss: 2.468659937856409

Epoch: 5| Step: 9
Training loss: 2.833024138989064
Validation loss: 2.458718719294286

Epoch: 5| Step: 10
Training loss: 2.2853790957046893
Validation loss: 2.465319976453182

Epoch: 151| Step: 0
Training loss: 2.4915144917470275
Validation loss: 2.4637349225125007

Epoch: 5| Step: 1
Training loss: 2.9802703591409654
Validation loss: 2.4675320920396926

Epoch: 5| Step: 2
Training loss: 2.7569888346504428
Validation loss: 2.477433044627192

Epoch: 5| Step: 3
Training loss: 3.1154287630378383
Validation loss: 2.47410838960355

Epoch: 5| Step: 4
Training loss: 2.4107887761147326
Validation loss: 2.485886131564347

Epoch: 5| Step: 5
Training loss: 2.510739908473295
Validation loss: 2.4804461486474016

Epoch: 5| Step: 6
Training loss: 3.116610595552335
Validation loss: 2.489388173549905

Epoch: 5| Step: 7
Training loss: 2.4518836701507483
Validation loss: 2.4867321577022516

Epoch: 5| Step: 8
Training loss: 3.0064427811636683
Validation loss: 2.503340759355903

Epoch: 5| Step: 9
Training loss: 2.6778243012913348
Validation loss: 2.4870468686219884

Epoch: 5| Step: 10
Training loss: 2.7928059563843437
Validation loss: 2.4853502194863757

Epoch: 152| Step: 0
Training loss: 2.809433006561889
Validation loss: 2.476321190170495

Epoch: 5| Step: 1
Training loss: 2.6899842601443265
Validation loss: 2.4736138973304187

Epoch: 5| Step: 2
Training loss: 2.690351703157438
Validation loss: 2.469660131050134

Epoch: 5| Step: 3
Training loss: 2.895633955936921
Validation loss: 2.469457215332107

Epoch: 5| Step: 4
Training loss: 3.0266548800413995
Validation loss: 2.468915309436356

Epoch: 5| Step: 5
Training loss: 2.646073267913468
Validation loss: 2.478478358298137

Epoch: 5| Step: 6
Training loss: 2.943034052193934
Validation loss: 2.471709621079624

Epoch: 5| Step: 7
Training loss: 2.9971786583849687
Validation loss: 2.463520970834621

Epoch: 5| Step: 8
Training loss: 2.600203150368689
Validation loss: 2.4725900351600894

Epoch: 5| Step: 9
Training loss: 2.5652602611366637
Validation loss: 2.468101589732205

Epoch: 5| Step: 10
Training loss: 2.370604211588879
Validation loss: 2.4727430303937785

Epoch: 153| Step: 0
Training loss: 3.28758935262996
Validation loss: 2.4679527921844717

Epoch: 5| Step: 1
Training loss: 3.25403872216836
Validation loss: 2.4734190059704773

Epoch: 5| Step: 2
Training loss: 2.641989812330288
Validation loss: 2.4811220207508615

Epoch: 5| Step: 3
Training loss: 2.768106155796468
Validation loss: 2.4795499901514937

Epoch: 5| Step: 4
Training loss: 2.575757968786961
Validation loss: 2.482981390981916

Epoch: 5| Step: 5
Training loss: 2.766639566480283
Validation loss: 2.473692536683115

Epoch: 5| Step: 6
Training loss: 2.7997028397502763
Validation loss: 2.464925175667101

Epoch: 5| Step: 7
Training loss: 2.1150466962488634
Validation loss: 2.4552309031449813

Epoch: 5| Step: 8
Training loss: 2.540074730622309
Validation loss: 2.4606293807843924

Epoch: 5| Step: 9
Training loss: 2.7784332413340964
Validation loss: 2.4618345918314204

Epoch: 5| Step: 10
Training loss: 2.6449032047206016
Validation loss: 2.4588759921643737

Epoch: 154| Step: 0
Training loss: 3.0271774147852546
Validation loss: 2.462136952187615

Epoch: 5| Step: 1
Training loss: 2.68596374605414
Validation loss: 2.459085928747255

Epoch: 5| Step: 2
Training loss: 2.9033643281014347
Validation loss: 2.458014921407146

Epoch: 5| Step: 3
Training loss: 3.0205461738289023
Validation loss: 2.466556793469164

Epoch: 5| Step: 4
Training loss: 2.5634784226183727
Validation loss: 2.4717672587945514

Epoch: 5| Step: 5
Training loss: 2.7509137282882246
Validation loss: 2.475744676889834

Epoch: 5| Step: 6
Training loss: 2.328500294998868
Validation loss: 2.4911286843080185

Epoch: 5| Step: 7
Training loss: 2.8968458715330314
Validation loss: 2.4916187426498113

Epoch: 5| Step: 8
Training loss: 2.7957831441256404
Validation loss: 2.493610851151681

Epoch: 5| Step: 9
Training loss: 2.5839986764709577
Validation loss: 2.4875958827022253

Epoch: 5| Step: 10
Training loss: 2.8539218287091055
Validation loss: 2.4806247922097415

Epoch: 155| Step: 0
Training loss: 2.8832658447422985
Validation loss: 2.461693915502088

Epoch: 5| Step: 1
Training loss: 3.173583373976425
Validation loss: 2.460469846472102

Epoch: 5| Step: 2
Training loss: 3.063215833810415
Validation loss: 2.450107023548091

Epoch: 5| Step: 3
Training loss: 2.5148765445691024
Validation loss: 2.4544076820812917

Epoch: 5| Step: 4
Training loss: 2.736640558369939
Validation loss: 2.454981469089286

Epoch: 5| Step: 5
Training loss: 3.4761124566063915
Validation loss: 2.4542618335409507

Epoch: 5| Step: 6
Training loss: 2.5730455703465647
Validation loss: 2.46092985470716

Epoch: 5| Step: 7
Training loss: 2.4409547434060896
Validation loss: 2.456627759535077

Epoch: 5| Step: 8
Training loss: 2.4140583519761085
Validation loss: 2.452967406478476

Epoch: 5| Step: 9
Training loss: 2.491762705029078
Validation loss: 2.4583871591166586

Epoch: 5| Step: 10
Training loss: 2.357400838762812
Validation loss: 2.469698294811432

Epoch: 156| Step: 0
Training loss: 2.499410845954258
Validation loss: 2.463570720250928

Epoch: 5| Step: 1
Training loss: 2.3493169157008063
Validation loss: 2.4779128403282167

Epoch: 5| Step: 2
Training loss: 2.773891358110761
Validation loss: 2.4811587848523002

Epoch: 5| Step: 3
Training loss: 2.615618699589186
Validation loss: 2.4995608487557135

Epoch: 5| Step: 4
Training loss: 2.6291151941483206
Validation loss: 2.512790586029628

Epoch: 5| Step: 5
Training loss: 2.6027877717406964
Validation loss: 2.506621961323705

Epoch: 5| Step: 6
Training loss: 2.7771311060198784
Validation loss: 2.5023485125075746

Epoch: 5| Step: 7
Training loss: 3.099584607011551
Validation loss: 2.476852444013901

Epoch: 5| Step: 8
Training loss: 3.0112668501151703
Validation loss: 2.4763523699879095

Epoch: 5| Step: 9
Training loss: 3.2731811131694766
Validation loss: 2.4583325546816814

Epoch: 5| Step: 10
Training loss: 2.684267895019546
Validation loss: 2.455331414541652

Epoch: 157| Step: 0
Training loss: 3.0365079916050037
Validation loss: 2.4602902713886508

Epoch: 5| Step: 1
Training loss: 3.215523890026181
Validation loss: 2.464394265483791

Epoch: 5| Step: 2
Training loss: 2.8530428453631793
Validation loss: 2.4643244175033074

Epoch: 5| Step: 3
Training loss: 2.467005149282363
Validation loss: 2.456688633339674

Epoch: 5| Step: 4
Training loss: 2.5471083645303354
Validation loss: 2.457689047205631

Epoch: 5| Step: 5
Training loss: 2.27566241167847
Validation loss: 2.460691834516296

Epoch: 5| Step: 6
Training loss: 2.6865918599009024
Validation loss: 2.4539882629400274

Epoch: 5| Step: 7
Training loss: 2.753723225024008
Validation loss: 2.4562730395821335

Epoch: 5| Step: 8
Training loss: 2.632188672152995
Validation loss: 2.4709006750028704

Epoch: 5| Step: 9
Training loss: 2.749702003979205
Validation loss: 2.474950688569957

Epoch: 5| Step: 10
Training loss: 3.0616296582450344
Validation loss: 2.4823084898344385

Epoch: 158| Step: 0
Training loss: 2.670624200386483
Validation loss: 2.489463458987645

Epoch: 5| Step: 1
Training loss: 2.472169174263359
Validation loss: 2.47644880359956

Epoch: 5| Step: 2
Training loss: 3.1203771348580793
Validation loss: 2.470786462821482

Epoch: 5| Step: 3
Training loss: 2.73511543058234
Validation loss: 2.4696904472318155

Epoch: 5| Step: 4
Training loss: 2.6382463565289043
Validation loss: 2.465640940981765

Epoch: 5| Step: 5
Training loss: 3.1704687750264893
Validation loss: 2.4633954788356753

Epoch: 5| Step: 6
Training loss: 2.6749873187753863
Validation loss: 2.46657093392235

Epoch: 5| Step: 7
Training loss: 2.5423605758563155
Validation loss: 2.4608104135852154

Epoch: 5| Step: 8
Training loss: 2.597452669125497
Validation loss: 2.461656473287137

Epoch: 5| Step: 9
Training loss: 3.042995075704481
Validation loss: 2.4554907826030044

Epoch: 5| Step: 10
Training loss: 2.7953213260312992
Validation loss: 2.4557739945507024

Epoch: 159| Step: 0
Training loss: 2.791201329710215
Validation loss: 2.4626360080142917

Epoch: 5| Step: 1
Training loss: 2.7880654997335417
Validation loss: 2.4663264179059303

Epoch: 5| Step: 2
Training loss: 2.821502772523044
Validation loss: 2.4744376246227717

Epoch: 5| Step: 3
Training loss: 3.0088844668012937
Validation loss: 2.4759633985634326

Epoch: 5| Step: 4
Training loss: 2.9095851670678736
Validation loss: 2.4814525980795494

Epoch: 5| Step: 5
Training loss: 2.7379345204985452
Validation loss: 2.4999932873543482

Epoch: 5| Step: 6
Training loss: 2.5858192071048345
Validation loss: 2.513253903099862

Epoch: 5| Step: 7
Training loss: 2.394523284550373
Validation loss: 2.5208114155937142

Epoch: 5| Step: 8
Training loss: 2.5913727678511345
Validation loss: 2.5307113761068782

Epoch: 5| Step: 9
Training loss: 3.1774297473263413
Validation loss: 2.4999770522346236

Epoch: 5| Step: 10
Training loss: 2.517667616384859
Validation loss: 2.4917261827783705

Epoch: 160| Step: 0
Training loss: 2.760080242649082
Validation loss: 2.480322167242567

Epoch: 5| Step: 1
Training loss: 2.9344905290215184
Validation loss: 2.475188045001802

Epoch: 5| Step: 2
Training loss: 2.7732409770271675
Validation loss: 2.460414520338034

Epoch: 5| Step: 3
Training loss: 2.3094442643656032
Validation loss: 2.453760946033526

Epoch: 5| Step: 4
Training loss: 3.1937553510229146
Validation loss: 2.451238641212396

Epoch: 5| Step: 5
Training loss: 2.957531744302111
Validation loss: 2.4489341560419153

Epoch: 5| Step: 6
Training loss: 2.385009153336528
Validation loss: 2.442363740333269

Epoch: 5| Step: 7
Training loss: 2.4611215673970346
Validation loss: 2.4465109372974556

Epoch: 5| Step: 8
Training loss: 2.8873037692681858
Validation loss: 2.4449284016731756

Epoch: 5| Step: 9
Training loss: 2.680522466091852
Validation loss: 2.4385418165541113

Epoch: 5| Step: 10
Training loss: 2.984840236969874
Validation loss: 2.441529150972428

Epoch: 161| Step: 0
Training loss: 1.745116982569413
Validation loss: 2.4429492656264555

Epoch: 5| Step: 1
Training loss: 2.638456729727121
Validation loss: 2.446774300523008

Epoch: 5| Step: 2
Training loss: 3.2733659759209472
Validation loss: 2.447587455093612

Epoch: 5| Step: 3
Training loss: 2.8573381016641486
Validation loss: 2.460602913134497

Epoch: 5| Step: 4
Training loss: 3.4501513627614013
Validation loss: 2.4597501969930504

Epoch: 5| Step: 5
Training loss: 2.818373333109277
Validation loss: 2.474824309325556

Epoch: 5| Step: 6
Training loss: 2.30256725995861
Validation loss: 2.4545291181680473

Epoch: 5| Step: 7
Training loss: 2.1140291085887273
Validation loss: 2.454014255568357

Epoch: 5| Step: 8
Training loss: 3.0883297689396367
Validation loss: 2.4586062065241245

Epoch: 5| Step: 9
Training loss: 2.5471646196884254
Validation loss: 2.450199353309286

Epoch: 5| Step: 10
Training loss: 2.998447493337226
Validation loss: 2.4445622326590444

Epoch: 162| Step: 0
Training loss: 2.1724459768937807
Validation loss: 2.4487433024639507

Epoch: 5| Step: 1
Training loss: 2.9770685201338205
Validation loss: 2.4411090859975015

Epoch: 5| Step: 2
Training loss: 2.247515047933169
Validation loss: 2.4494891933171155

Epoch: 5| Step: 3
Training loss: 2.612674386076909
Validation loss: 2.449799631424961

Epoch: 5| Step: 4
Training loss: 2.6208150291915544
Validation loss: 2.4469616187854624

Epoch: 5| Step: 5
Training loss: 2.4832823647852
Validation loss: 2.45425117266818

Epoch: 5| Step: 6
Training loss: 3.339765652641363
Validation loss: 2.4548091125117604

Epoch: 5| Step: 7
Training loss: 3.0095431810644295
Validation loss: 2.4529952608079317

Epoch: 5| Step: 8
Training loss: 2.023991218125663
Validation loss: 2.4551252178069363

Epoch: 5| Step: 9
Training loss: 3.277318142778387
Validation loss: 2.460668792091959

Epoch: 5| Step: 10
Training loss: 3.0241736173895895
Validation loss: 2.4662574655913088

Epoch: 163| Step: 0
Training loss: 2.6860617404184595
Validation loss: 2.4816828752174316

Epoch: 5| Step: 1
Training loss: 2.9501717145696413
Validation loss: 2.482348444598039

Epoch: 5| Step: 2
Training loss: 2.980643131059377
Validation loss: 2.4720756931241175

Epoch: 5| Step: 3
Training loss: 2.9621898247308964
Validation loss: 2.4674322314111117

Epoch: 5| Step: 4
Training loss: 2.6265367823243193
Validation loss: 2.4555551241091056

Epoch: 5| Step: 5
Training loss: 2.611065619548115
Validation loss: 2.4527452304366135

Epoch: 5| Step: 6
Training loss: 2.7658374079802326
Validation loss: 2.445307316755431

Epoch: 5| Step: 7
Training loss: 2.564723840908988
Validation loss: 2.4440851649799193

Epoch: 5| Step: 8
Training loss: 2.5384459700696107
Validation loss: 2.446148672241339

Epoch: 5| Step: 9
Training loss: 2.3064517752193203
Validation loss: 2.4449794625976318

Epoch: 5| Step: 10
Training loss: 3.098716371637693
Validation loss: 2.4459382436364985

Epoch: 164| Step: 0
Training loss: 2.461675430347681
Validation loss: 2.438411939616424

Epoch: 5| Step: 1
Training loss: 3.3746293888763645
Validation loss: 2.4436915421468224

Epoch: 5| Step: 2
Training loss: 2.74084657232285
Validation loss: 2.4345008240587136

Epoch: 5| Step: 3
Training loss: 2.8873397716637457
Validation loss: 2.440918445050691

Epoch: 5| Step: 4
Training loss: 2.469786607427951
Validation loss: 2.444498646353675

Epoch: 5| Step: 5
Training loss: 1.8406168291464307
Validation loss: 2.4397345797399286

Epoch: 5| Step: 6
Training loss: 2.4313219466755593
Validation loss: 2.443772435767848

Epoch: 5| Step: 7
Training loss: 2.855387090305943
Validation loss: 2.445905426729947

Epoch: 5| Step: 8
Training loss: 2.968198383682846
Validation loss: 2.4478874934405814

Epoch: 5| Step: 9
Training loss: 2.982265985458041
Validation loss: 2.444679119253371

Epoch: 5| Step: 10
Training loss: 2.740187216996659
Validation loss: 2.460897355436669

Epoch: 165| Step: 0
Training loss: 2.891899034323162
Validation loss: 2.457824069946002

Epoch: 5| Step: 1
Training loss: 3.38206970658251
Validation loss: 2.447367136025612

Epoch: 5| Step: 2
Training loss: 2.526222416549259
Validation loss: 2.4429708171405364

Epoch: 5| Step: 3
Training loss: 2.6662700377979776
Validation loss: 2.4344454427021427

Epoch: 5| Step: 4
Training loss: 2.386783180678254
Validation loss: 2.441210751161161

Epoch: 5| Step: 5
Training loss: 2.7221655601867147
Validation loss: 2.4339506434427993

Epoch: 5| Step: 6
Training loss: 2.922281981494961
Validation loss: 2.4375239145742835

Epoch: 5| Step: 7
Training loss: 2.773047105418667
Validation loss: 2.4361451461491788

Epoch: 5| Step: 8
Training loss: 2.925305153342697
Validation loss: 2.4406173288503847

Epoch: 5| Step: 9
Training loss: 2.2375300613174054
Validation loss: 2.434974533756123

Epoch: 5| Step: 10
Training loss: 2.3163161879427503
Validation loss: 2.4348900312839667

Epoch: 166| Step: 0
Training loss: 2.540322704090559
Validation loss: 2.4368832662252977

Epoch: 5| Step: 1
Training loss: 3.3490484451977176
Validation loss: 2.440563266973346

Epoch: 5| Step: 2
Training loss: 2.9177690511693886
Validation loss: 2.4343195028438713

Epoch: 5| Step: 3
Training loss: 2.867576468794219
Validation loss: 2.4356331777113396

Epoch: 5| Step: 4
Training loss: 2.4585873962843903
Validation loss: 2.4394553098366094

Epoch: 5| Step: 5
Training loss: 3.0480087909521654
Validation loss: 2.4448640164345066

Epoch: 5| Step: 6
Training loss: 2.4112068742738884
Validation loss: 2.443780956140956

Epoch: 5| Step: 7
Training loss: 2.872987955346305
Validation loss: 2.4425709251523

Epoch: 5| Step: 8
Training loss: 2.0958485121837764
Validation loss: 2.446158159003242

Epoch: 5| Step: 9
Training loss: 2.6357009392613464
Validation loss: 2.440116892184445

Epoch: 5| Step: 10
Training loss: 2.5163057721130655
Validation loss: 2.44078403529478

Epoch: 167| Step: 0
Training loss: 2.5491975830770586
Validation loss: 2.4380136931434913

Epoch: 5| Step: 1
Training loss: 3.002681963867511
Validation loss: 2.438385868985927

Epoch: 5| Step: 2
Training loss: 2.4619730390409638
Validation loss: 2.435061532651977

Epoch: 5| Step: 3
Training loss: 2.8159933647326847
Validation loss: 2.4391548328192543

Epoch: 5| Step: 4
Training loss: 2.7590299950103296
Validation loss: 2.4403233233329265

Epoch: 5| Step: 5
Training loss: 2.656000641730817
Validation loss: 2.437236509761463

Epoch: 5| Step: 6
Training loss: 2.795535315497787
Validation loss: 2.438885158744919

Epoch: 5| Step: 7
Training loss: 2.7190212246009264
Validation loss: 2.429988025166684

Epoch: 5| Step: 8
Training loss: 2.4310554014646057
Validation loss: 2.4349971897327762

Epoch: 5| Step: 9
Training loss: 3.2466350154652464
Validation loss: 2.428648209213372

Epoch: 5| Step: 10
Training loss: 2.2483359647282537
Validation loss: 2.4323823232150756

Epoch: 168| Step: 0
Training loss: 2.4977028783622566
Validation loss: 2.4311510525191977

Epoch: 5| Step: 1
Training loss: 2.773492688986545
Validation loss: 2.435000844106591

Epoch: 5| Step: 2
Training loss: 2.605717820097025
Validation loss: 2.4351967425219656

Epoch: 5| Step: 3
Training loss: 2.184984886588546
Validation loss: 2.426237867892983

Epoch: 5| Step: 4
Training loss: 2.740775328877095
Validation loss: 2.422597396717788

Epoch: 5| Step: 5
Training loss: 2.8667281195980787
Validation loss: 2.4293319578651245

Epoch: 5| Step: 6
Training loss: 2.598846942805387
Validation loss: 2.4293557249060056

Epoch: 5| Step: 7
Training loss: 3.204955829191009
Validation loss: 2.4315810803999045

Epoch: 5| Step: 8
Training loss: 2.638080251061605
Validation loss: 2.42637453728309

Epoch: 5| Step: 9
Training loss: 2.5815732148579236
Validation loss: 2.4270373868248365

Epoch: 5| Step: 10
Training loss: 3.142472667833185
Validation loss: 2.4312713338673704

Epoch: 169| Step: 0
Training loss: 2.8382716805852994
Validation loss: 2.4231471271740284

Epoch: 5| Step: 1
Training loss: 2.8225252975803348
Validation loss: 2.4270817630204156

Epoch: 5| Step: 2
Training loss: 2.548222378481056
Validation loss: 2.4276437448210637

Epoch: 5| Step: 3
Training loss: 2.863127700414677
Validation loss: 2.4294922204860727

Epoch: 5| Step: 4
Training loss: 2.544832967286926
Validation loss: 2.424463081819786

Epoch: 5| Step: 5
Training loss: 2.9350247607250837
Validation loss: 2.433478020740634

Epoch: 5| Step: 6
Training loss: 2.827150798790033
Validation loss: 2.4291419503645892

Epoch: 5| Step: 7
Training loss: 2.650083497369429
Validation loss: 2.4393491837876424

Epoch: 5| Step: 8
Training loss: 3.11257064922995
Validation loss: 2.44921352477963

Epoch: 5| Step: 9
Training loss: 2.4749053320456302
Validation loss: 2.4386978046091112

Epoch: 5| Step: 10
Training loss: 1.9642431960520301
Validation loss: 2.4427972431891765

Epoch: 170| Step: 0
Training loss: 2.7593465974238094
Validation loss: 2.439569843398871

Epoch: 5| Step: 1
Training loss: 2.617160079584669
Validation loss: 2.4527592069819475

Epoch: 5| Step: 2
Training loss: 2.868950823899924
Validation loss: 2.4539898926454846

Epoch: 5| Step: 3
Training loss: 2.43016964952072
Validation loss: 2.447123275157672

Epoch: 5| Step: 4
Training loss: 2.1652161315446707
Validation loss: 2.448671251258058

Epoch: 5| Step: 5
Training loss: 2.7930689653677176
Validation loss: 2.4390471401961906

Epoch: 5| Step: 6
Training loss: 2.5480771650250547
Validation loss: 2.4404255674849424

Epoch: 5| Step: 7
Training loss: 3.0076644266514716
Validation loss: 2.427912972781704

Epoch: 5| Step: 8
Training loss: 2.637523296669133
Validation loss: 2.43050118904623

Epoch: 5| Step: 9
Training loss: 3.0395883924003333
Validation loss: 2.434774690046684

Epoch: 5| Step: 10
Training loss: 2.948223911265396
Validation loss: 2.4289004224831077

Epoch: 171| Step: 0
Training loss: 3.4603022903075416
Validation loss: 2.4334427676061305

Epoch: 5| Step: 1
Training loss: 2.940864908321459
Validation loss: 2.436244958072722

Epoch: 5| Step: 2
Training loss: 2.7850131175966744
Validation loss: 2.4299908240836414

Epoch: 5| Step: 3
Training loss: 2.7986097869575426
Validation loss: 2.447784883874383

Epoch: 5| Step: 4
Training loss: 2.7342741157449737
Validation loss: 2.4546896800916134

Epoch: 5| Step: 5
Training loss: 2.4328420099466648
Validation loss: 2.475856037537853

Epoch: 5| Step: 6
Training loss: 2.105883385873943
Validation loss: 2.494784898218042

Epoch: 5| Step: 7
Training loss: 2.414164124358997
Validation loss: 2.464854171603748

Epoch: 5| Step: 8
Training loss: 2.927886164969453
Validation loss: 2.476562525879022

Epoch: 5| Step: 9
Training loss: 2.6980921468530603
Validation loss: 2.4576876609117186

Epoch: 5| Step: 10
Training loss: 2.4346808734735563
Validation loss: 2.4435313310937965

Epoch: 172| Step: 0
Training loss: 2.9383392758308453
Validation loss: 2.433527807035157

Epoch: 5| Step: 1
Training loss: 2.828437071384949
Validation loss: 2.425811109517102

Epoch: 5| Step: 2
Training loss: 3.024947388246638
Validation loss: 2.4258051469431057

Epoch: 5| Step: 3
Training loss: 2.6421106436733237
Validation loss: 2.4209484962572385

Epoch: 5| Step: 4
Training loss: 2.3728400999805452
Validation loss: 2.421426694133333

Epoch: 5| Step: 5
Training loss: 2.4563194905708623
Validation loss: 2.4214273833674196

Epoch: 5| Step: 6
Training loss: 2.856425447313402
Validation loss: 2.4173841436848535

Epoch: 5| Step: 7
Training loss: 2.6104096514299835
Validation loss: 2.4218425842508093

Epoch: 5| Step: 8
Training loss: 2.92038676665991
Validation loss: 2.428793121707135

Epoch: 5| Step: 9
Training loss: 2.827953944644609
Validation loss: 2.452150120701532

Epoch: 5| Step: 10
Training loss: 2.262676451320019
Validation loss: 2.460786185664289

Epoch: 173| Step: 0
Training loss: 2.3992960135795682
Validation loss: 2.4725699538717434

Epoch: 5| Step: 1
Training loss: 2.781635643443396
Validation loss: 2.473688847232089

Epoch: 5| Step: 2
Training loss: 2.5853318718205545
Validation loss: 2.4721781894106476

Epoch: 5| Step: 3
Training loss: 3.108855237602211
Validation loss: 2.466416933213251

Epoch: 5| Step: 4
Training loss: 2.4453727544118955
Validation loss: 2.4566660187880505

Epoch: 5| Step: 5
Training loss: 2.7131355455216024
Validation loss: 2.4384738090683213

Epoch: 5| Step: 6
Training loss: 2.8007174900942915
Validation loss: 2.4255078815797186

Epoch: 5| Step: 7
Training loss: 3.036879198974671
Validation loss: 2.420614953587248

Epoch: 5| Step: 8
Training loss: 2.4169638768859643
Validation loss: 2.4303560714388572

Epoch: 5| Step: 9
Training loss: 2.738906244846709
Validation loss: 2.433227257587526

Epoch: 5| Step: 10
Training loss: 2.809774986027695
Validation loss: 2.442991194201899

Epoch: 174| Step: 0
Training loss: 2.610339414808762
Validation loss: 2.44461163643635

Epoch: 5| Step: 1
Training loss: 2.504570407236476
Validation loss: 2.440693858177143

Epoch: 5| Step: 2
Training loss: 2.9239217352040447
Validation loss: 2.4378789497255484

Epoch: 5| Step: 3
Training loss: 2.584165951670187
Validation loss: 2.431824292318748

Epoch: 5| Step: 4
Training loss: 2.8233744307600315
Validation loss: 2.4392792229643967

Epoch: 5| Step: 5
Training loss: 2.7603592392807883
Validation loss: 2.449512252993558

Epoch: 5| Step: 6
Training loss: 2.809587538914647
Validation loss: 2.4682273669801145

Epoch: 5| Step: 7
Training loss: 3.09865327931115
Validation loss: 2.4806170112342887

Epoch: 5| Step: 8
Training loss: 2.3006253926412326
Validation loss: 2.4845767087308563

Epoch: 5| Step: 9
Training loss: 2.6254757041409977
Validation loss: 2.4810482315580713

Epoch: 5| Step: 10
Training loss: 2.7489447736580352
Validation loss: 2.4480564689293445

Epoch: 175| Step: 0
Training loss: 2.6798019162321864
Validation loss: 2.4360474054246803

Epoch: 5| Step: 1
Training loss: 2.098275375636371
Validation loss: 2.4248052076701665

Epoch: 5| Step: 2
Training loss: 2.5768075061945765
Validation loss: 2.431164035447261

Epoch: 5| Step: 3
Training loss: 2.939476322323334
Validation loss: 2.446130627170009

Epoch: 5| Step: 4
Training loss: 2.4073453119480495
Validation loss: 2.4380679019843825

Epoch: 5| Step: 5
Training loss: 2.8840010345816904
Validation loss: 2.4321672947470265

Epoch: 5| Step: 6
Training loss: 2.3862760791982063
Validation loss: 2.4385054528442507

Epoch: 5| Step: 7
Training loss: 2.622460544751218
Validation loss: 2.4386292148687736

Epoch: 5| Step: 8
Training loss: 3.179442300176074
Validation loss: 2.4369636115848476

Epoch: 5| Step: 9
Training loss: 3.0523640022943597
Validation loss: 2.433025993295815

Epoch: 5| Step: 10
Training loss: 2.7852777184405784
Validation loss: 2.4532026763630013

Epoch: 176| Step: 0
Training loss: 2.7033890611742626
Validation loss: 2.458691196732868

Epoch: 5| Step: 1
Training loss: 2.6747688550105364
Validation loss: 2.470142180687567

Epoch: 5| Step: 2
Training loss: 2.3438243599857578
Validation loss: 2.4780779259538033

Epoch: 5| Step: 3
Training loss: 2.6147541633716513
Validation loss: 2.470234389472921

Epoch: 5| Step: 4
Training loss: 3.203516494272684
Validation loss: 2.4587893510620207

Epoch: 5| Step: 5
Training loss: 2.9480471273250024
Validation loss: 2.4547381777103334

Epoch: 5| Step: 6
Training loss: 2.7727441915118134
Validation loss: 2.4396349767883168

Epoch: 5| Step: 7
Training loss: 2.4088020167848776
Validation loss: 2.432685119492126

Epoch: 5| Step: 8
Training loss: 2.9445738334137257
Validation loss: 2.430334244558895

Epoch: 5| Step: 9
Training loss: 2.300216838732381
Validation loss: 2.418341856615005

Epoch: 5| Step: 10
Training loss: 2.6229109853168393
Validation loss: 2.4266566606084528

Epoch: 177| Step: 0
Training loss: 2.6043701600994913
Validation loss: 2.4258578193623572

Epoch: 5| Step: 1
Training loss: 2.7744920042235197
Validation loss: 2.426076957047121

Epoch: 5| Step: 2
Training loss: 2.5316910536066333
Validation loss: 2.421807899564396

Epoch: 5| Step: 3
Training loss: 2.187554277019152
Validation loss: 2.421176817438099

Epoch: 5| Step: 4
Training loss: 2.937383608845657
Validation loss: 2.432569196299643

Epoch: 5| Step: 5
Training loss: 3.247089256288725
Validation loss: 2.430729459839472

Epoch: 5| Step: 6
Training loss: 2.9676318823698153
Validation loss: 2.4303402825188187

Epoch: 5| Step: 7
Training loss: 2.690274514156006
Validation loss: 2.4442324157980546

Epoch: 5| Step: 8
Training loss: 2.7515055263324455
Validation loss: 2.4507791194455204

Epoch: 5| Step: 9
Training loss: 1.8059785526729943
Validation loss: 2.463842028210824

Epoch: 5| Step: 10
Training loss: 2.878273634329215
Validation loss: 2.4725166352276045

Epoch: 178| Step: 0
Training loss: 3.2899947125238755
Validation loss: 2.4714590753791272

Epoch: 5| Step: 1
Training loss: 2.082693370437053
Validation loss: 2.47223685524763

Epoch: 5| Step: 2
Training loss: 2.2572566737508226
Validation loss: 2.461435588766495

Epoch: 5| Step: 3
Training loss: 3.022807526321602
Validation loss: 2.472198921480332

Epoch: 5| Step: 4
Training loss: 2.673740828588877
Validation loss: 2.4512337026792514

Epoch: 5| Step: 5
Training loss: 3.071513089255962
Validation loss: 2.4507027151920666

Epoch: 5| Step: 6
Training loss: 2.7052779251291654
Validation loss: 2.4355920771527337

Epoch: 5| Step: 7
Training loss: 2.4697892138467488
Validation loss: 2.4301144785576976

Epoch: 5| Step: 8
Training loss: 2.954753124167952
Validation loss: 2.421387977072795

Epoch: 5| Step: 9
Training loss: 2.1596235339263585
Validation loss: 2.422945802188397

Epoch: 5| Step: 10
Training loss: 2.720269754020261
Validation loss: 2.4105298713724626

Epoch: 179| Step: 0
Training loss: 2.4399920708887057
Validation loss: 2.4151503822379525

Epoch: 5| Step: 1
Training loss: 2.4969163950901168
Validation loss: 2.414423678895698

Epoch: 5| Step: 2
Training loss: 2.243881170747475
Validation loss: 2.4264285106328964

Epoch: 5| Step: 3
Training loss: 2.616434290665329
Validation loss: 2.413699691933969

Epoch: 5| Step: 4
Training loss: 3.0101943060426906
Validation loss: 2.412145485137941

Epoch: 5| Step: 5
Training loss: 3.031107319098916
Validation loss: 2.419094324613266

Epoch: 5| Step: 6
Training loss: 2.686617240530001
Validation loss: 2.417241815889188

Epoch: 5| Step: 7
Training loss: 2.8508253006839146
Validation loss: 2.4268441013476423

Epoch: 5| Step: 8
Training loss: 2.405558895591353
Validation loss: 2.4432938907648802

Epoch: 5| Step: 9
Training loss: 2.6956660384360647
Validation loss: 2.453135229982514

Epoch: 5| Step: 10
Training loss: 3.0905484675081687
Validation loss: 2.46537094259845

Epoch: 180| Step: 0
Training loss: 2.404436988993329
Validation loss: 2.466953682753988

Epoch: 5| Step: 1
Training loss: 2.218723028314551
Validation loss: 2.457281937626196

Epoch: 5| Step: 2
Training loss: 2.463241612641467
Validation loss: 2.47061967956467

Epoch: 5| Step: 3
Training loss: 3.0740893868707984
Validation loss: 2.4481875766946333

Epoch: 5| Step: 4
Training loss: 2.4537535427104853
Validation loss: 2.419742080331351

Epoch: 5| Step: 5
Training loss: 2.6053409116114827
Validation loss: 2.4101331850018126

Epoch: 5| Step: 6
Training loss: 3.047402986604915
Validation loss: 2.4123707117292885

Epoch: 5| Step: 7
Training loss: 2.5809158478371477
Validation loss: 2.4192173237498515

Epoch: 5| Step: 8
Training loss: 3.4307117366545867
Validation loss: 2.410680713844091

Epoch: 5| Step: 9
Training loss: 2.6266960840788633
Validation loss: 2.4140887133071858

Epoch: 5| Step: 10
Training loss: 2.3885135676154543
Validation loss: 2.420019737335373

Epoch: 181| Step: 0
Training loss: 2.3211960057730576
Validation loss: 2.425484880652517

Epoch: 5| Step: 1
Training loss: 2.4245473576894625
Validation loss: 2.4187546703101375

Epoch: 5| Step: 2
Training loss: 2.4200752708456896
Validation loss: 2.43912817628716

Epoch: 5| Step: 3
Training loss: 2.5294393963224278
Validation loss: 2.438777854720287

Epoch: 5| Step: 4
Training loss: 3.044482264860047
Validation loss: 2.4364138734655385

Epoch: 5| Step: 5
Training loss: 2.9636863489930105
Validation loss: 2.441199611130789

Epoch: 5| Step: 6
Training loss: 3.067036907679203
Validation loss: 2.4443406707687823

Epoch: 5| Step: 7
Training loss: 2.269506877827397
Validation loss: 2.4403600591514

Epoch: 5| Step: 8
Training loss: 2.747749795153769
Validation loss: 2.4319260947372396

Epoch: 5| Step: 9
Training loss: 2.57102654924784
Validation loss: 2.433222843012614

Epoch: 5| Step: 10
Training loss: 2.978977775365336
Validation loss: 2.4200869021808273

Epoch: 182| Step: 0
Training loss: 2.606097052680875
Validation loss: 2.4256420529191693

Epoch: 5| Step: 1
Training loss: 2.770833084756558
Validation loss: 2.418361236956197

Epoch: 5| Step: 2
Training loss: 2.763316165961243
Validation loss: 2.4249060879126754

Epoch: 5| Step: 3
Training loss: 2.4828396257343526
Validation loss: 2.4159000214647444

Epoch: 5| Step: 4
Training loss: 2.2326399462196242
Validation loss: 2.410779059779597

Epoch: 5| Step: 5
Training loss: 2.8708381383345376
Validation loss: 2.408008554505359

Epoch: 5| Step: 6
Training loss: 2.5194632114420354
Validation loss: 2.4139475410281697

Epoch: 5| Step: 7
Training loss: 2.6553343148248447
Validation loss: 2.4218276216051944

Epoch: 5| Step: 8
Training loss: 3.031172289294638
Validation loss: 2.423827657504282

Epoch: 5| Step: 9
Training loss: 2.7151906182971692
Validation loss: 2.4330533293939003

Epoch: 5| Step: 10
Training loss: 2.7250795895213913
Validation loss: 2.4308807541848334

Epoch: 183| Step: 0
Training loss: 2.7136644175778306
Validation loss: 2.4257840939303446

Epoch: 5| Step: 1
Training loss: 2.3540313029124214
Validation loss: 2.436899598721828

Epoch: 5| Step: 2
Training loss: 2.8253705009630865
Validation loss: 2.427345110363879

Epoch: 5| Step: 3
Training loss: 2.719986995918379
Validation loss: 2.434108219069006

Epoch: 5| Step: 4
Training loss: 2.6365395266056613
Validation loss: 2.423075044882323

Epoch: 5| Step: 5
Training loss: 3.076508383132075
Validation loss: 2.426626151206556

Epoch: 5| Step: 6
Training loss: 2.370121513020105
Validation loss: 2.4163104640979323

Epoch: 5| Step: 7
Training loss: 2.6959900819782785
Validation loss: 2.40825174015111

Epoch: 5| Step: 8
Training loss: 2.870605261112108
Validation loss: 2.4166420251808556

Epoch: 5| Step: 9
Training loss: 2.3516982536798983
Validation loss: 2.4172195513580346

Epoch: 5| Step: 10
Training loss: 2.6970419822087286
Validation loss: 2.440486892171364

Epoch: 184| Step: 0
Training loss: 3.2499295740566634
Validation loss: 2.4654381946268646

Epoch: 5| Step: 1
Training loss: 2.335259788977008
Validation loss: 2.4563190146473324

Epoch: 5| Step: 2
Training loss: 2.311956393295936
Validation loss: 2.4616634550177867

Epoch: 5| Step: 3
Training loss: 3.191149847219981
Validation loss: 2.447831743102976

Epoch: 5| Step: 4
Training loss: 2.4737083763873
Validation loss: 2.428993416911722

Epoch: 5| Step: 5
Training loss: 2.4277628546323298
Validation loss: 2.4280954016837666

Epoch: 5| Step: 6
Training loss: 3.126584376192364
Validation loss: 2.44580647338747

Epoch: 5| Step: 7
Training loss: 2.702972584214576
Validation loss: 2.454026107346606

Epoch: 5| Step: 8
Training loss: 2.358701597201285
Validation loss: 2.454426760932042

Epoch: 5| Step: 9
Training loss: 2.3736755291916585
Validation loss: 2.4495148307490093

Epoch: 5| Step: 10
Training loss: 2.6121909656905546
Validation loss: 2.4465244653420664

Epoch: 185| Step: 0
Training loss: 2.4910170338713282
Validation loss: 2.450078115668227

Epoch: 5| Step: 1
Training loss: 2.900006221896107
Validation loss: 2.4425123292504716

Epoch: 5| Step: 2
Training loss: 2.4999242771124863
Validation loss: 2.427866322538195

Epoch: 5| Step: 3
Training loss: 2.596254357677287
Validation loss: 2.4219167027635846

Epoch: 5| Step: 4
Training loss: 2.761608245667561
Validation loss: 2.434582974980239

Epoch: 5| Step: 5
Training loss: 2.9669943989237035
Validation loss: 2.4445296961668395

Epoch: 5| Step: 6
Training loss: 2.6036206601268934
Validation loss: 2.451050620615312

Epoch: 5| Step: 7
Training loss: 2.827749069266326
Validation loss: 2.4620238360192297

Epoch: 5| Step: 8
Training loss: 2.8843282214304997
Validation loss: 2.434754515876862

Epoch: 5| Step: 9
Training loss: 2.4277044219227735
Validation loss: 2.414126857174891

Epoch: 5| Step: 10
Training loss: 2.5022983476638903
Validation loss: 2.4137746828698736

Epoch: 186| Step: 0
Training loss: 2.9872967064293516
Validation loss: 2.4023345032013856

Epoch: 5| Step: 1
Training loss: 2.230136719690787
Validation loss: 2.4011825240107796

Epoch: 5| Step: 2
Training loss: 3.268789410034443
Validation loss: 2.409028091249102

Epoch: 5| Step: 3
Training loss: 2.268068140725252
Validation loss: 2.40644297087712

Epoch: 5| Step: 4
Training loss: 2.7616322462031477
Validation loss: 2.4194196095905864

Epoch: 5| Step: 5
Training loss: 2.5993885201544877
Validation loss: 2.4148794792829666

Epoch: 5| Step: 6
Training loss: 2.67639848036192
Validation loss: 2.4233867456279166

Epoch: 5| Step: 7
Training loss: 2.5036085787983153
Validation loss: 2.422604026985138

Epoch: 5| Step: 8
Training loss: 2.686550948661845
Validation loss: 2.438136571655594

Epoch: 5| Step: 9
Training loss: 2.808938208242939
Validation loss: 2.4219161406908536

Epoch: 5| Step: 10
Training loss: 2.5409073451059907
Validation loss: 2.4206369422414307

Epoch: 187| Step: 0
Training loss: 2.753633179890177
Validation loss: 2.4200396095440526

Epoch: 5| Step: 1
Training loss: 3.091857022768544
Validation loss: 2.413676281616001

Epoch: 5| Step: 2
Training loss: 2.5219637225307645
Validation loss: 2.409413649160173

Epoch: 5| Step: 3
Training loss: 2.6307690214799666
Validation loss: 2.3978404789496115

Epoch: 5| Step: 4
Training loss: 2.617678103795486
Validation loss: 2.4059464809646482

Epoch: 5| Step: 5
Training loss: 2.971804041772491
Validation loss: 2.407646499504191

Epoch: 5| Step: 6
Training loss: 2.761170328768701
Validation loss: 2.412008730123134

Epoch: 5| Step: 7
Training loss: 2.3744608618506327
Validation loss: 2.4173541981053797

Epoch: 5| Step: 8
Training loss: 2.4844801778541905
Validation loss: 2.450110054264887

Epoch: 5| Step: 9
Training loss: 2.2284544285254406
Validation loss: 2.43883947101753

Epoch: 5| Step: 10
Training loss: 2.7617038149072384
Validation loss: 2.4460584890483745

Epoch: 188| Step: 0
Training loss: 2.3109281197977203
Validation loss: 2.439070857765534

Epoch: 5| Step: 1
Training loss: 2.950038851465975
Validation loss: 2.448251997043142

Epoch: 5| Step: 2
Training loss: 2.6450218297854375
Validation loss: 2.4521907576449964

Epoch: 5| Step: 3
Training loss: 2.617819729635969
Validation loss: 2.4488740133360123

Epoch: 5| Step: 4
Training loss: 2.465185561865709
Validation loss: 2.432342612732162

Epoch: 5| Step: 5
Training loss: 2.238310435905375
Validation loss: 2.4234963443052986

Epoch: 5| Step: 6
Training loss: 2.9566167946630144
Validation loss: 2.3995863045211725

Epoch: 5| Step: 7
Training loss: 2.500559744161025
Validation loss: 2.408826432316478

Epoch: 5| Step: 8
Training loss: 2.6794186115208203
Validation loss: 2.402037853631535

Epoch: 5| Step: 9
Training loss: 2.8354209240263164
Validation loss: 2.397921502781195

Epoch: 5| Step: 10
Training loss: 2.86840229129596
Validation loss: 2.3996770894906136

Epoch: 189| Step: 0
Training loss: 2.6518822157467414
Validation loss: 2.4026075350229004

Epoch: 5| Step: 1
Training loss: 2.959130372326438
Validation loss: 2.4073941403640347

Epoch: 5| Step: 2
Training loss: 2.6926156968218624
Validation loss: 2.4107991070552353

Epoch: 5| Step: 3
Training loss: 2.796478584369878
Validation loss: 2.41774961593926

Epoch: 5| Step: 4
Training loss: 2.57509828398455
Validation loss: 2.425974074876752

Epoch: 5| Step: 5
Training loss: 2.3318766633750934
Validation loss: 2.442935171565903

Epoch: 5| Step: 6
Training loss: 2.905582474372541
Validation loss: 2.451822965113075

Epoch: 5| Step: 7
Training loss: 2.6211558759578026
Validation loss: 2.453612015422392

Epoch: 5| Step: 8
Training loss: 2.2272325009621885
Validation loss: 2.4588590247240547

Epoch: 5| Step: 9
Training loss: 2.6100680407428327
Validation loss: 2.4596429912861537

Epoch: 5| Step: 10
Training loss: 2.7064707782717545
Validation loss: 2.46249860896039

Epoch: 190| Step: 0
Training loss: 3.4508942868609225
Validation loss: 2.4499681297214977

Epoch: 5| Step: 1
Training loss: 2.3744611630793044
Validation loss: 2.43253416343235

Epoch: 5| Step: 2
Training loss: 2.4978966447814157
Validation loss: 2.4206353006717003

Epoch: 5| Step: 3
Training loss: 2.4230912630823616
Validation loss: 2.4045744838187098

Epoch: 5| Step: 4
Training loss: 2.4906505281870337
Validation loss: 2.395931274709169

Epoch: 5| Step: 5
Training loss: 2.3431124010660564
Validation loss: 2.406210338754159

Epoch: 5| Step: 6
Training loss: 2.6847275916493882
Validation loss: 2.397058323753585

Epoch: 5| Step: 7
Training loss: 3.113558614477745
Validation loss: 2.4039545775604947

Epoch: 5| Step: 8
Training loss: 2.180844454515278
Validation loss: 2.4163760865209576

Epoch: 5| Step: 9
Training loss: 2.6395011180507506
Validation loss: 2.4359956194992494

Epoch: 5| Step: 10
Training loss: 2.5939683937141353
Validation loss: 2.451142011701665

Epoch: 191| Step: 0
Training loss: 2.617804884328576
Validation loss: 2.461140529619366

Epoch: 5| Step: 1
Training loss: 2.6895013498762794
Validation loss: 2.465095285257464

Epoch: 5| Step: 2
Training loss: 2.255010535983151
Validation loss: 2.4698618405848114

Epoch: 5| Step: 3
Training loss: 2.9918169633803813
Validation loss: 2.4612634867737033

Epoch: 5| Step: 4
Training loss: 2.690298885205107
Validation loss: 2.4437725291333385

Epoch: 5| Step: 5
Training loss: 2.5593845688637513
Validation loss: 2.4407391624750505

Epoch: 5| Step: 6
Training loss: 3.23371121141832
Validation loss: 2.443654028670226

Epoch: 5| Step: 7
Training loss: 2.5441418357692784
Validation loss: 2.4329688882196185

Epoch: 5| Step: 8
Training loss: 1.7542533276219072
Validation loss: 2.441924105024237

Epoch: 5| Step: 9
Training loss: 2.8604084086084782
Validation loss: 2.4547176600458145

Epoch: 5| Step: 10
Training loss: 2.664232712842696
Validation loss: 2.501707125851685

Epoch: 192| Step: 0
Training loss: 2.284462326196694
Validation loss: 2.476410080290918

Epoch: 5| Step: 1
Training loss: 2.4029198924859294
Validation loss: 2.4631285003669627

Epoch: 5| Step: 2
Training loss: 3.1072122537915403
Validation loss: 2.4490603408996883

Epoch: 5| Step: 3
Training loss: 2.321526720256782
Validation loss: 2.4490552388622806

Epoch: 5| Step: 4
Training loss: 2.6233404453993883
Validation loss: 2.4569028283496053

Epoch: 5| Step: 5
Training loss: 2.769212798626781
Validation loss: 2.481214419212854

Epoch: 5| Step: 6
Training loss: 2.568795263629492
Validation loss: 2.5004458839914574

Epoch: 5| Step: 7
Training loss: 3.043229959855484
Validation loss: 2.515428970985371

Epoch: 5| Step: 8
Training loss: 2.7236921619228416
Validation loss: 2.4980062020111027

Epoch: 5| Step: 9
Training loss: 2.171891136932801
Validation loss: 2.4396571124133213

Epoch: 5| Step: 10
Training loss: 3.2282744292749417
Validation loss: 2.4120558029097143

Epoch: 193| Step: 0
Training loss: 2.4844653994829606
Validation loss: 2.4046992245704755

Epoch: 5| Step: 1
Training loss: 2.3934754973703933
Validation loss: 2.3977148692252257

Epoch: 5| Step: 2
Training loss: 2.70823143009287
Validation loss: 2.4101889048265663

Epoch: 5| Step: 3
Training loss: 2.749265572706649
Validation loss: 2.4086712653318783

Epoch: 5| Step: 4
Training loss: 2.4869167353331765
Validation loss: 2.4327559211967595

Epoch: 5| Step: 5
Training loss: 2.30762400648326
Validation loss: 2.428661786088591

Epoch: 5| Step: 6
Training loss: 2.5935808609196873
Validation loss: 2.4479958543468907

Epoch: 5| Step: 7
Training loss: 2.5195594490306648
Validation loss: 2.468099866512498

Epoch: 5| Step: 8
Training loss: 3.1691067647141877
Validation loss: 2.4952879295721866

Epoch: 5| Step: 9
Training loss: 3.0823092607204656
Validation loss: 2.458021443102148

Epoch: 5| Step: 10
Training loss: 2.9605904327945116
Validation loss: 2.410810457746234

Epoch: 194| Step: 0
Training loss: 3.1841077518345653
Validation loss: 2.3877258329699167

Epoch: 5| Step: 1
Training loss: 2.9257180139611534
Validation loss: 2.409350126915443

Epoch: 5| Step: 2
Training loss: 2.5574506929031613
Validation loss: 2.426445387888052

Epoch: 5| Step: 3
Training loss: 2.45878453612981
Validation loss: 2.4559943225071876

Epoch: 5| Step: 4
Training loss: 2.1195927432089894
Validation loss: 2.491915310144395

Epoch: 5| Step: 5
Training loss: 2.7796240350641224
Validation loss: 2.4804021618229806

Epoch: 5| Step: 6
Training loss: 2.1326079218076486
Validation loss: 2.4383845484674844

Epoch: 5| Step: 7
Training loss: 2.831089552486678
Validation loss: 2.4254228384176457

Epoch: 5| Step: 8
Training loss: 2.4644613558803647
Validation loss: 2.406099441265118

Epoch: 5| Step: 9
Training loss: 2.394919135335246
Validation loss: 2.3882540986784018

Epoch: 5| Step: 10
Training loss: 3.0455925223100158
Validation loss: 2.384896121949871

Epoch: 195| Step: 0
Training loss: 2.633661150345672
Validation loss: 2.3777810002351356

Epoch: 5| Step: 1
Training loss: 2.4184567847926637
Validation loss: 2.395832025029136

Epoch: 5| Step: 2
Training loss: 3.178965493599619
Validation loss: 2.408930395373028

Epoch: 5| Step: 3
Training loss: 2.6586128048097635
Validation loss: 2.4200419771639856

Epoch: 5| Step: 4
Training loss: 2.667839170020781
Validation loss: 2.4180082353428114

Epoch: 5| Step: 5
Training loss: 2.3176835190948393
Validation loss: 2.414354279561234

Epoch: 5| Step: 6
Training loss: 2.8826080497877564
Validation loss: 2.4140458590111193

Epoch: 5| Step: 7
Training loss: 2.760292213561464
Validation loss: 2.4113107527722253

Epoch: 5| Step: 8
Training loss: 2.2010624747519616
Validation loss: 2.421429378016114

Epoch: 5| Step: 9
Training loss: 2.439039771043151
Validation loss: 2.430118220449865

Epoch: 5| Step: 10
Training loss: 2.5672957041731705
Validation loss: 2.4329024636199135

Epoch: 196| Step: 0
Training loss: 2.7364136861511583
Validation loss: 2.4399719818845984

Epoch: 5| Step: 1
Training loss: 2.8245156370848723
Validation loss: 2.4362589913959862

Epoch: 5| Step: 2
Training loss: 3.000922061364438
Validation loss: 2.4413460331535504

Epoch: 5| Step: 3
Training loss: 2.5380694985820558
Validation loss: 2.434562622314576

Epoch: 5| Step: 4
Training loss: 2.5291254994426735
Validation loss: 2.413597011346307

Epoch: 5| Step: 5
Training loss: 2.7467769462087963
Validation loss: 2.3957604440423976

Epoch: 5| Step: 6
Training loss: 2.525946158474863
Validation loss: 2.4016712580388297

Epoch: 5| Step: 7
Training loss: 2.481573672767259
Validation loss: 2.413196115549018

Epoch: 5| Step: 8
Training loss: 2.5097314260802266
Validation loss: 2.4082475225052042

Epoch: 5| Step: 9
Training loss: 2.2757527206523647
Validation loss: 2.4225870282575834

Epoch: 5| Step: 10
Training loss: 2.652686297807182
Validation loss: 2.4286645221438223

Epoch: 197| Step: 0
Training loss: 2.782385176545548
Validation loss: 2.4485682028644016

Epoch: 5| Step: 1
Training loss: 2.5807793102660135
Validation loss: 2.469517793132864

Epoch: 5| Step: 2
Training loss: 2.6399346527045964
Validation loss: 2.4701568978961626

Epoch: 5| Step: 3
Training loss: 2.540774100082281
Validation loss: 2.47539540717575

Epoch: 5| Step: 4
Training loss: 2.608679764464276
Validation loss: 2.4571119423330106

Epoch: 5| Step: 5
Training loss: 2.5650391442953806
Validation loss: 2.4356536298436637

Epoch: 5| Step: 6
Training loss: 2.0871491645619957
Validation loss: 2.408474860333597

Epoch: 5| Step: 7
Training loss: 2.69119452320544
Validation loss: 2.4014673549469783

Epoch: 5| Step: 8
Training loss: 2.251727288891534
Validation loss: 2.396421757399399

Epoch: 5| Step: 9
Training loss: 2.9392853850603045
Validation loss: 2.3950923428307536

Epoch: 5| Step: 10
Training loss: 2.961057313291598
Validation loss: 2.4363005173948853

Epoch: 198| Step: 0
Training loss: 1.9404374282290873
Validation loss: 2.478967796353752

Epoch: 5| Step: 1
Training loss: 2.8728335967213074
Validation loss: 2.541600727965549

Epoch: 5| Step: 2
Training loss: 2.7331625730006732
Validation loss: 2.5854375098296414

Epoch: 5| Step: 3
Training loss: 3.186856373150635
Validation loss: 2.628355781817264

Epoch: 5| Step: 4
Training loss: 2.7854546471352855
Validation loss: 2.6065725174248584

Epoch: 5| Step: 5
Training loss: 2.9139967187406124
Validation loss: 2.5294322327439307

Epoch: 5| Step: 6
Training loss: 2.7305698621635304
Validation loss: 2.4671925244733535

Epoch: 5| Step: 7
Training loss: 2.6159484663270804
Validation loss: 2.443537510602959

Epoch: 5| Step: 8
Training loss: 2.715221175709268
Validation loss: 2.4291607770157317

Epoch: 5| Step: 9
Training loss: 2.519755319493777
Validation loss: 2.431330491700717

Epoch: 5| Step: 10
Training loss: 2.2928825505185415
Validation loss: 2.4460334185603383

Epoch: 199| Step: 0
Training loss: 2.993996971949369
Validation loss: 2.4913001432487354

Epoch: 5| Step: 1
Training loss: 2.7868865257515907
Validation loss: 2.5284636290242792

Epoch: 5| Step: 2
Training loss: 3.1658377482708215
Validation loss: 2.5851792069883546

Epoch: 5| Step: 3
Training loss: 2.8937931329466284
Validation loss: 2.528259907564929

Epoch: 5| Step: 4
Training loss: 1.8997985607576686
Validation loss: 2.433600759041014

Epoch: 5| Step: 5
Training loss: 2.7210146362124146
Validation loss: 2.3996061173194128

Epoch: 5| Step: 6
Training loss: 2.5941715127777347
Validation loss: 2.3805738530916587

Epoch: 5| Step: 7
Training loss: 2.838928662905069
Validation loss: 2.380632094376753

Epoch: 5| Step: 8
Training loss: 2.7610827715941872
Validation loss: 2.390324050798856

Epoch: 5| Step: 9
Training loss: 2.238062237048893
Validation loss: 2.434587572418306

Epoch: 5| Step: 10
Training loss: 2.540403041551752
Validation loss: 2.485654312062403

Epoch: 200| Step: 0
Training loss: 2.6532327007814165
Validation loss: 2.50398078871373

Epoch: 5| Step: 1
Training loss: 2.713335367416007
Validation loss: 2.493177878269551

Epoch: 5| Step: 2
Training loss: 2.9084106945107213
Validation loss: 2.475888980359635

Epoch: 5| Step: 3
Training loss: 2.7602001369171405
Validation loss: 2.488687134015266

Epoch: 5| Step: 4
Training loss: 2.980727278269831
Validation loss: 2.473354509343862

Epoch: 5| Step: 5
Training loss: 2.800482527844698
Validation loss: 2.487761435104139

Epoch: 5| Step: 6
Training loss: 2.319682642671972
Validation loss: 2.4844465265434033

Epoch: 5| Step: 7
Training loss: 2.756530896187184
Validation loss: 2.4965236530536776

Epoch: 5| Step: 8
Training loss: 2.2287386783434244
Validation loss: 2.481160736648084

Epoch: 5| Step: 9
Training loss: 2.2119275360033903
Validation loss: 2.4697549378185055

Epoch: 5| Step: 10
Training loss: 2.8786828046237103
Validation loss: 2.4493969806997296

Epoch: 201| Step: 0
Training loss: 2.822465661163527
Validation loss: 2.446799817620544

Epoch: 5| Step: 1
Training loss: 2.5880875883182797
Validation loss: 2.4433018000433773

Epoch: 5| Step: 2
Training loss: 2.3611424375462993
Validation loss: 2.4435048177795804

Epoch: 5| Step: 3
Training loss: 2.6774031352839125
Validation loss: 2.4353697686637115

Epoch: 5| Step: 4
Training loss: 2.941249645669237
Validation loss: 2.439727607760246

Epoch: 5| Step: 5
Training loss: 2.5872665631686234
Validation loss: 2.4320257614699585

Epoch: 5| Step: 6
Training loss: 2.6175339199079914
Validation loss: 2.433882889496579

Epoch: 5| Step: 7
Training loss: 3.2087530051537927
Validation loss: 2.430318952862507

Epoch: 5| Step: 8
Training loss: 2.09699771709618
Validation loss: 2.4192816137355373

Epoch: 5| Step: 9
Training loss: 2.5838241931171515
Validation loss: 2.4135474193693742

Epoch: 5| Step: 10
Training loss: 2.3137821045662204
Validation loss: 2.4102533026772006

Epoch: 202| Step: 0
Training loss: 2.92086872581846
Validation loss: 2.408177657754909

Epoch: 5| Step: 1
Training loss: 2.7635883655669264
Validation loss: 2.4136129225402456

Epoch: 5| Step: 2
Training loss: 2.8007912948194176
Validation loss: 2.435707383893313

Epoch: 5| Step: 3
Training loss: 3.047406741961458
Validation loss: 2.447575575280046

Epoch: 5| Step: 4
Training loss: 2.7716744850340507
Validation loss: 2.4318858918826947

Epoch: 5| Step: 5
Training loss: 1.7222463937656025
Validation loss: 2.448292763608996

Epoch: 5| Step: 6
Training loss: 2.6116535951165134
Validation loss: 2.4485909948099938

Epoch: 5| Step: 7
Training loss: 2.7220102690447656
Validation loss: 2.461236292651728

Epoch: 5| Step: 8
Training loss: 2.6553999494330367
Validation loss: 2.4724485730708423

Epoch: 5| Step: 9
Training loss: 2.221167523382951
Validation loss: 2.4362799012765186

Epoch: 5| Step: 10
Training loss: 2.34058043739262
Validation loss: 2.431687580262653

Epoch: 203| Step: 0
Training loss: 2.8496622521224992
Validation loss: 2.427085727178358

Epoch: 5| Step: 1
Training loss: 2.2650815114560534
Validation loss: 2.42649662961745

Epoch: 5| Step: 2
Training loss: 2.4184333219392293
Validation loss: 2.4373690315192023

Epoch: 5| Step: 3
Training loss: 2.505825883934417
Validation loss: 2.4329163897752677

Epoch: 5| Step: 4
Training loss: 2.7219612186760784
Validation loss: 2.429984556319785

Epoch: 5| Step: 5
Training loss: 3.4043042986597913
Validation loss: 2.4156080019773256

Epoch: 5| Step: 6
Training loss: 2.2970890282801872
Validation loss: 2.426353061295205

Epoch: 5| Step: 7
Training loss: 2.1840756452685817
Validation loss: 2.4255025603589404

Epoch: 5| Step: 8
Training loss: 2.869093923792402
Validation loss: 2.44609501454084

Epoch: 5| Step: 9
Training loss: 2.79111428750452
Validation loss: 2.4643040072215356

Epoch: 5| Step: 10
Training loss: 2.3010863019333527
Validation loss: 2.440910599468483

Epoch: 204| Step: 0
Training loss: 2.822177597837846
Validation loss: 2.4279320528742683

Epoch: 5| Step: 1
Training loss: 3.047236181517157
Validation loss: 2.420423430338311

Epoch: 5| Step: 2
Training loss: 2.6915548031673753
Validation loss: 2.439021554603099

Epoch: 5| Step: 3
Training loss: 2.4985078173124426
Validation loss: 2.435122613423434

Epoch: 5| Step: 4
Training loss: 2.7618448749322795
Validation loss: 2.4351185812848843

Epoch: 5| Step: 5
Training loss: 2.532334366227475
Validation loss: 2.4361997533014237

Epoch: 5| Step: 6
Training loss: 2.196251719196756
Validation loss: 2.4311337882387782

Epoch: 5| Step: 7
Training loss: 1.9657324417418764
Validation loss: 2.4324480411276084

Epoch: 5| Step: 8
Training loss: 2.7240918177227944
Validation loss: 2.44378447464145

Epoch: 5| Step: 9
Training loss: 2.8988657015549815
Validation loss: 2.450932096532705

Epoch: 5| Step: 10
Training loss: 2.6158696286965752
Validation loss: 2.4478995262144596

Epoch: 205| Step: 0
Training loss: 2.4033198164808
Validation loss: 2.4335182699819606

Epoch: 5| Step: 1
Training loss: 2.459388463372456
Validation loss: 2.4259132551587914

Epoch: 5| Step: 2
Training loss: 2.347283509888283
Validation loss: 2.427641427911818

Epoch: 5| Step: 3
Training loss: 2.881367473731311
Validation loss: 2.4582834488124945

Epoch: 5| Step: 4
Training loss: 2.957988951790729
Validation loss: 2.479920899617943

Epoch: 5| Step: 5
Training loss: 2.7450491816382883
Validation loss: 2.479495821788616

Epoch: 5| Step: 6
Training loss: 2.3041091451886335
Validation loss: 2.4728054892007134

Epoch: 5| Step: 7
Training loss: 2.906249179634881
Validation loss: 2.451107468637462

Epoch: 5| Step: 8
Training loss: 2.4792824619295586
Validation loss: 2.4144177211155955

Epoch: 5| Step: 9
Training loss: 2.5484526258963474
Validation loss: 2.38252420629766

Epoch: 5| Step: 10
Training loss: 2.569126586040497
Validation loss: 2.3674418774586554

Epoch: 206| Step: 0
Training loss: 2.391387219557365
Validation loss: 2.381916943920758

Epoch: 5| Step: 1
Training loss: 2.148273031701928
Validation loss: 2.408470160893036

Epoch: 5| Step: 2
Training loss: 3.0879542460634437
Validation loss: 2.4280165303734873

Epoch: 5| Step: 3
Training loss: 2.715635949783286
Validation loss: 2.4823829815196867

Epoch: 5| Step: 4
Training loss: 3.119333240960969
Validation loss: 2.5136438006397146

Epoch: 5| Step: 5
Training loss: 2.709016498575984
Validation loss: 2.468940025047525

Epoch: 5| Step: 6
Training loss: 2.2099783066940613
Validation loss: 2.3940635218586803

Epoch: 5| Step: 7
Training loss: 2.8373308778348254
Validation loss: 2.374255112660813

Epoch: 5| Step: 8
Training loss: 2.9455770277637043
Validation loss: 2.3838071417839313

Epoch: 5| Step: 9
Training loss: 2.6905871558103214
Validation loss: 2.4088141644500767

Epoch: 5| Step: 10
Training loss: 1.9590561188998392
Validation loss: 2.433425121357404

Epoch: 207| Step: 0
Training loss: 3.2621707443185572
Validation loss: 2.4745065012917147

Epoch: 5| Step: 1
Training loss: 1.8809656606335332
Validation loss: 2.4434799828599076

Epoch: 5| Step: 2
Training loss: 2.9697061705461505
Validation loss: 2.4247740501261763

Epoch: 5| Step: 3
Training loss: 2.4678356553791114
Validation loss: 2.390588353531851

Epoch: 5| Step: 4
Training loss: 2.1638657242864445
Validation loss: 2.3753829694779776

Epoch: 5| Step: 5
Training loss: 2.5254555772776395
Validation loss: 2.390632572010608

Epoch: 5| Step: 6
Training loss: 2.8397450174119534
Validation loss: 2.406388716527446

Epoch: 5| Step: 7
Training loss: 2.6752668122894314
Validation loss: 2.431630931890443

Epoch: 5| Step: 8
Training loss: 2.517095384859929
Validation loss: 2.4541186411798517

Epoch: 5| Step: 9
Training loss: 2.681259628314179
Validation loss: 2.4676258938684152

Epoch: 5| Step: 10
Training loss: 2.5543588782749804
Validation loss: 2.4580132985422436

Epoch: 208| Step: 0
Training loss: 2.6444189140768604
Validation loss: 2.4929462524718917

Epoch: 5| Step: 1
Training loss: 2.7010875807357544
Validation loss: 2.5152073679549556

Epoch: 5| Step: 2
Training loss: 2.042882271973188
Validation loss: 2.4979972066969154

Epoch: 5| Step: 3
Training loss: 2.86156975568914
Validation loss: 2.4862497667276124

Epoch: 5| Step: 4
Training loss: 2.474250074886318
Validation loss: 2.4757857787627424

Epoch: 5| Step: 5
Training loss: 2.6803761478751262
Validation loss: 2.4281876282428088

Epoch: 5| Step: 6
Training loss: 2.6814184353793125
Validation loss: 2.4231140523847925

Epoch: 5| Step: 7
Training loss: 2.1967581879339573
Validation loss: 2.4117860176527897

Epoch: 5| Step: 8
Training loss: 2.00901989683834
Validation loss: 2.416197756408674

Epoch: 5| Step: 9
Training loss: 3.008651972950002
Validation loss: 2.413416165502136

Epoch: 5| Step: 10
Training loss: 2.6266015934346694
Validation loss: 2.4042984637485962

Epoch: 209| Step: 0
Training loss: 2.3356511887860076
Validation loss: 2.416123016814661

Epoch: 5| Step: 1
Training loss: 2.5986922643283825
Validation loss: 2.4255750175882063

Epoch: 5| Step: 2
Training loss: 2.4513638728963327
Validation loss: 2.4340681470469905

Epoch: 5| Step: 3
Training loss: 2.386063955736874
Validation loss: 2.4480511155621225

Epoch: 5| Step: 4
Training loss: 2.088235910410818
Validation loss: 2.4609797054642577

Epoch: 5| Step: 5
Training loss: 2.7433649996493847
Validation loss: 2.461557756328165

Epoch: 5| Step: 6
Training loss: 2.413121407285603
Validation loss: 2.4748275029659896

Epoch: 5| Step: 7
Training loss: 2.91190796429999
Validation loss: 2.4719024775737735

Epoch: 5| Step: 8
Training loss: 2.4619479572364287
Validation loss: 2.4628607028992677

Epoch: 5| Step: 9
Training loss: 2.7271684995155243
Validation loss: 2.4558812835515282

Epoch: 5| Step: 10
Training loss: 3.0063487268681097
Validation loss: 2.453980229312054

Epoch: 210| Step: 0
Training loss: 1.960331431801716
Validation loss: 2.441443705609859

Epoch: 5| Step: 1
Training loss: 2.3266244443252204
Validation loss: 2.438381582555223

Epoch: 5| Step: 2
Training loss: 2.5993219298374877
Validation loss: 2.4216238028527632

Epoch: 5| Step: 3
Training loss: 2.314901393825397
Validation loss: 2.4210149894007333

Epoch: 5| Step: 4
Training loss: 2.5380757923517905
Validation loss: 2.402375940106711

Epoch: 5| Step: 5
Training loss: 2.4460690823934357
Validation loss: 2.403329629108275

Epoch: 5| Step: 6
Training loss: 2.414775261699142
Validation loss: 2.416381304239798

Epoch: 5| Step: 7
Training loss: 3.124658489640089
Validation loss: 2.4198108971325123

Epoch: 5| Step: 8
Training loss: 2.4908968175270543
Validation loss: 2.4320640113996532

Epoch: 5| Step: 9
Training loss: 2.583433385162565
Validation loss: 2.461676134348217

Epoch: 5| Step: 10
Training loss: 2.7871212654956152
Validation loss: 2.457264359286932

Epoch: 211| Step: 0
Training loss: 2.7230471271607257
Validation loss: 2.442206608141935

Epoch: 5| Step: 1
Training loss: 2.581745633993837
Validation loss: 2.4408035672442767

Epoch: 5| Step: 2
Training loss: 2.2737357347071314
Validation loss: 2.456573981645217

Epoch: 5| Step: 3
Training loss: 2.076825416746797
Validation loss: 2.4523021424903093

Epoch: 5| Step: 4
Training loss: 2.3151421788759854
Validation loss: 2.4444048810120704

Epoch: 5| Step: 5
Training loss: 2.318105347879951
Validation loss: 2.454029586085989

Epoch: 5| Step: 6
Training loss: 2.7550989043938046
Validation loss: 2.4598939056988876

Epoch: 5| Step: 7
Training loss: 2.753846685969322
Validation loss: 2.4789560907088033

Epoch: 5| Step: 8
Training loss: 2.7253851767079964
Validation loss: 2.4995679379445814

Epoch: 5| Step: 9
Training loss: 2.37799946958698
Validation loss: 2.5057859285567363

Epoch: 5| Step: 10
Training loss: 2.3736274166103914
Validation loss: 2.4875302376457546

Epoch: 212| Step: 0
Training loss: 2.5653408399632016
Validation loss: 2.506075376300065

Epoch: 5| Step: 1
Training loss: 2.462306825448227
Validation loss: 2.475448521933216

Epoch: 5| Step: 2
Training loss: 2.776674772191973
Validation loss: 2.469043974314883

Epoch: 5| Step: 3
Training loss: 2.353970938678994
Validation loss: 2.4328756911631535

Epoch: 5| Step: 4
Training loss: 2.6375694880439178
Validation loss: 2.431168452178872

Epoch: 5| Step: 5
Training loss: 1.7228500706980066
Validation loss: 2.4164776485923496

Epoch: 5| Step: 6
Training loss: 2.495410330137967
Validation loss: 2.3998578190988162

Epoch: 5| Step: 7
Training loss: 2.5797363794179593
Validation loss: 2.3929037517185594

Epoch: 5| Step: 8
Training loss: 2.573016660242743
Validation loss: 2.380421490518855

Epoch: 5| Step: 9
Training loss: 2.9271826857316188
Validation loss: 2.3737146794140473

Epoch: 5| Step: 10
Training loss: 2.379759987661981
Validation loss: 2.3821196486323917

Epoch: 213| Step: 0
Training loss: 2.3211600557073666
Validation loss: 2.401151161365615

Epoch: 5| Step: 1
Training loss: 2.119216453496438
Validation loss: 2.3909193502894346

Epoch: 5| Step: 2
Training loss: 2.637865599834557
Validation loss: 2.405236639035167

Epoch: 5| Step: 3
Training loss: 1.8094568685349024
Validation loss: 2.3983813532413163

Epoch: 5| Step: 4
Training loss: 2.4442520523460645
Validation loss: 2.3924668892238596

Epoch: 5| Step: 5
Training loss: 2.684927218994058
Validation loss: 2.408397809639607

Epoch: 5| Step: 6
Training loss: 2.979015711092104
Validation loss: 2.423329293862846

Epoch: 5| Step: 7
Training loss: 2.35264222966762
Validation loss: 2.433079746392857

Epoch: 5| Step: 8
Training loss: 2.068071296665577
Validation loss: 2.465870025923129

Epoch: 5| Step: 9
Training loss: 2.6331874682271237
Validation loss: 2.4948810982078555

Epoch: 5| Step: 10
Training loss: 2.8188919336147737
Validation loss: 2.5294596190315373

Epoch: 214| Step: 0
Training loss: 2.6674006068009106
Validation loss: 2.5374333564303035

Epoch: 5| Step: 1
Training loss: 2.431285271474547
Validation loss: 2.565047331815877

Epoch: 5| Step: 2
Training loss: 2.50429337911402
Validation loss: 2.599578095668706

Epoch: 5| Step: 3
Training loss: 2.8766821211145213
Validation loss: 2.609743877822696

Epoch: 5| Step: 4
Training loss: 2.3675341462489587
Validation loss: 2.516350899952833

Epoch: 5| Step: 5
Training loss: 2.3602864102962484
Validation loss: 2.4512561257569723

Epoch: 5| Step: 6
Training loss: 2.3296518119672824
Validation loss: 2.4561274312374475

Epoch: 5| Step: 7
Training loss: 3.081842955819374
Validation loss: 2.452574964592707

Epoch: 5| Step: 8
Training loss: 2.250522658784269
Validation loss: 2.4253659855865437

Epoch: 5| Step: 9
Training loss: 2.410004102458074
Validation loss: 2.4177889161230492

Epoch: 5| Step: 10
Training loss: 1.927940906410474
Validation loss: 2.3949763823046974

Epoch: 215| Step: 0
Training loss: 2.3895319016588603
Validation loss: 2.3800469708635514

Epoch: 5| Step: 1
Training loss: 2.0678754173692995
Validation loss: 2.376564810008651

Epoch: 5| Step: 2
Training loss: 1.979495499715871
Validation loss: 2.374619909591463

Epoch: 5| Step: 3
Training loss: 2.5919229897903335
Validation loss: 2.41385432327159

Epoch: 5| Step: 4
Training loss: 2.5608691166236524
Validation loss: 2.428824790278595

Epoch: 5| Step: 5
Training loss: 2.4210321744146195
Validation loss: 2.417963313584771

Epoch: 5| Step: 6
Training loss: 2.551075846789785
Validation loss: 2.415422532691317

Epoch: 5| Step: 7
Training loss: 2.3435783832025145
Validation loss: 2.406598987796355

Epoch: 5| Step: 8
Training loss: 2.449870191755354
Validation loss: 2.4110284350917373

Epoch: 5| Step: 9
Training loss: 2.997725260131337
Validation loss: 2.418049853184311

Epoch: 5| Step: 10
Training loss: 2.5921782361785377
Validation loss: 2.427171984299962

Epoch: 216| Step: 0
Training loss: 2.6659035683581864
Validation loss: 2.437456712740706

Epoch: 5| Step: 1
Training loss: 2.7594767187774223
Validation loss: 2.434738293238152

Epoch: 5| Step: 2
Training loss: 2.8285852553014537
Validation loss: 2.440778553590824

Epoch: 5| Step: 3
Training loss: 2.4404519619331615
Validation loss: 2.445208612849854

Epoch: 5| Step: 4
Training loss: 2.7807015724811204
Validation loss: 2.4638298709171575

Epoch: 5| Step: 5
Training loss: 2.3119649525860213
Validation loss: 2.4400963041077066

Epoch: 5| Step: 6
Training loss: 2.024417124560516
Validation loss: 2.430702780519342

Epoch: 5| Step: 7
Training loss: 2.210487778287078
Validation loss: 2.4051722528911412

Epoch: 5| Step: 8
Training loss: 2.233275136141921
Validation loss: 2.4380452587701567

Epoch: 5| Step: 9
Training loss: 2.3492242587868257
Validation loss: 2.429922482324183

Epoch: 5| Step: 10
Training loss: 1.8294272715793571
Validation loss: 2.4274692491775434

Epoch: 217| Step: 0
Training loss: 2.1543159103590117
Validation loss: 2.4393663058491044

Epoch: 5| Step: 1
Training loss: 2.8688555862177436
Validation loss: 2.414589642979541

Epoch: 5| Step: 2
Training loss: 2.477029942823963
Validation loss: 2.397814835354894

Epoch: 5| Step: 3
Training loss: 2.59813053705884
Validation loss: 2.400361466020197

Epoch: 5| Step: 4
Training loss: 2.5103513041702192
Validation loss: 2.3945158329767335

Epoch: 5| Step: 5
Training loss: 2.098055156946393
Validation loss: 2.376482809928496

Epoch: 5| Step: 6
Training loss: 1.9559372453861585
Validation loss: 2.3904010368336284

Epoch: 5| Step: 7
Training loss: 2.149637116258905
Validation loss: 2.3919431776169278

Epoch: 5| Step: 8
Training loss: 2.295562265205158
Validation loss: 2.386572149628202

Epoch: 5| Step: 9
Training loss: 2.7148856399926915
Validation loss: 2.3985161329679467

Epoch: 5| Step: 10
Training loss: 2.354264642707793
Validation loss: 2.412691282237888

Epoch: 218| Step: 0
Training loss: 2.4316251332965355
Validation loss: 2.447984694925673

Epoch: 5| Step: 1
Training loss: 2.129645039169412
Validation loss: 2.481097658460269

Epoch: 5| Step: 2
Training loss: 2.7340527153821084
Validation loss: 2.487336376899882

Epoch: 5| Step: 3
Training loss: 2.2097209913099967
Validation loss: 2.4803213269322972

Epoch: 5| Step: 4
Training loss: 1.7522809286502483
Validation loss: 2.482335827482457

Epoch: 5| Step: 5
Training loss: 2.434751085409018
Validation loss: 2.4721664967266537

Epoch: 5| Step: 6
Training loss: 2.6069582409076726
Validation loss: 2.4693001388191393

Epoch: 5| Step: 7
Training loss: 2.4250052619169113
Validation loss: 2.475568771844847

Epoch: 5| Step: 8
Training loss: 2.445871794970632
Validation loss: 2.4636727321856764

Epoch: 5| Step: 9
Training loss: 2.246841863353368
Validation loss: 2.453146390009788

Epoch: 5| Step: 10
Training loss: 2.770095746144898
Validation loss: 2.4292220272634775

Epoch: 219| Step: 0
Training loss: 2.8747925061524313
Validation loss: 2.4318812297759664

Epoch: 5| Step: 1
Training loss: 2.476557590227044
Validation loss: 2.4131943664015663

Epoch: 5| Step: 2
Training loss: 2.3491961463827766
Validation loss: 2.3963718859431924

Epoch: 5| Step: 3
Training loss: 2.560839789751005
Validation loss: 2.396569018057554

Epoch: 5| Step: 4
Training loss: 2.215533974826299
Validation loss: 2.398634298292049

Epoch: 5| Step: 5
Training loss: 2.271926325201223
Validation loss: 2.3940095148914438

Epoch: 5| Step: 6
Training loss: 2.2255468360910786
Validation loss: 2.3901465731652722

Epoch: 5| Step: 7
Training loss: 2.210388546787871
Validation loss: 2.401944605932599

Epoch: 5| Step: 8
Training loss: 2.6070529862533145
Validation loss: 2.4339655800136777

Epoch: 5| Step: 9
Training loss: 1.727934486414404
Validation loss: 2.464020150032855

Epoch: 5| Step: 10
Training loss: 2.579488035608692
Validation loss: 2.469051269491754

Epoch: 220| Step: 0
Training loss: 2.7122945329749784
Validation loss: 2.4548537777487067

Epoch: 5| Step: 1
Training loss: 2.370453649151803
Validation loss: 2.4280639453249466

Epoch: 5| Step: 2
Training loss: 2.1303259359291093
Validation loss: 2.4045384636212983

Epoch: 5| Step: 3
Training loss: 2.129709298798241
Validation loss: 2.409756673326418

Epoch: 5| Step: 4
Training loss: 2.554386412816958
Validation loss: 2.4209232170954293

Epoch: 5| Step: 5
Training loss: 1.540522932962188
Validation loss: 2.429273201981505

Epoch: 5| Step: 6
Training loss: 2.1543887301218585
Validation loss: 2.429518582292941

Epoch: 5| Step: 7
Training loss: 2.7459687249277347
Validation loss: 2.41269827284105

Epoch: 5| Step: 8
Training loss: 2.4038210412694427
Validation loss: 2.408176805045182

Epoch: 5| Step: 9
Training loss: 2.4129434602945268
Validation loss: 2.4280578436331535

Epoch: 5| Step: 10
Training loss: 2.5855532818853333
Validation loss: 2.414669141839328

Epoch: 221| Step: 0
Training loss: 2.2503129953331675
Validation loss: 2.4143955038070524

Epoch: 5| Step: 1
Training loss: 2.3811648816692785
Validation loss: 2.4001899813672254

Epoch: 5| Step: 2
Training loss: 2.354676880587886
Validation loss: 2.379910006047488

Epoch: 5| Step: 3
Training loss: 2.211869653251763
Validation loss: 2.3713308963379047

Epoch: 5| Step: 4
Training loss: 2.245640558050351
Validation loss: 2.379054959611042

Epoch: 5| Step: 5
Training loss: 2.5754884127025
Validation loss: 2.3757654606971323

Epoch: 5| Step: 6
Training loss: 2.1021968068653614
Validation loss: 2.4038923219801878

Epoch: 5| Step: 7
Training loss: 1.869223916680315
Validation loss: 2.404473114131936

Epoch: 5| Step: 8
Training loss: 2.5203762323086756
Validation loss: 2.429237171259389

Epoch: 5| Step: 9
Training loss: 2.4294587545872184
Validation loss: 2.436679421147634

Epoch: 5| Step: 10
Training loss: 2.6755192760670674
Validation loss: 2.467860854981399

Epoch: 222| Step: 0
Training loss: 2.0825522166434114
Validation loss: 2.4645373622017406

Epoch: 5| Step: 1
Training loss: 2.04621002810708
Validation loss: 2.4683306290974945

Epoch: 5| Step: 2
Training loss: 2.3707323380218357
Validation loss: 2.437391406496571

Epoch: 5| Step: 3
Training loss: 2.1194830692494246
Validation loss: 2.438915059650349

Epoch: 5| Step: 4
Training loss: 2.190239743735896
Validation loss: 2.43598940928173

Epoch: 5| Step: 5
Training loss: 2.115712007116778
Validation loss: 2.434947680902411

Epoch: 5| Step: 6
Training loss: 2.3587098857822393
Validation loss: 2.419723965470261

Epoch: 5| Step: 7
Training loss: 2.2687686551590764
Validation loss: 2.432821289702492

Epoch: 5| Step: 8
Training loss: 2.461445589445565
Validation loss: 2.4189080882426355

Epoch: 5| Step: 9
Training loss: 2.7506532760099405
Validation loss: 2.4129608695975637

Epoch: 5| Step: 10
Training loss: 2.640378951849317
Validation loss: 2.4157292238411294

Epoch: 223| Step: 0
Training loss: 2.29814289416997
Validation loss: 2.439442395206431

Epoch: 5| Step: 1
Training loss: 1.9992725122101849
Validation loss: 2.477391397831341

Epoch: 5| Step: 2
Training loss: 2.7265506077373174
Validation loss: 2.529195758399332

Epoch: 5| Step: 3
Training loss: 2.449224980055872
Validation loss: 2.5311609787037814

Epoch: 5| Step: 4
Training loss: 2.8021990008866373
Validation loss: 2.50572932145663

Epoch: 5| Step: 5
Training loss: 1.9023064642978789
Validation loss: 2.4987552343434762

Epoch: 5| Step: 6
Training loss: 2.187812019983421
Validation loss: 2.4947163954150615

Epoch: 5| Step: 7
Training loss: 2.32394248538653
Validation loss: 2.4486495206312484

Epoch: 5| Step: 8
Training loss: 2.294580468288628
Validation loss: 2.447371892762205

Epoch: 5| Step: 9
Training loss: 2.730267125709181
Validation loss: 2.4506431781732627

Epoch: 5| Step: 10
Training loss: 1.8763435000936337
Validation loss: 2.4414160565579257

Epoch: 224| Step: 0
Training loss: 2.5443711405841714
Validation loss: 2.4257234765928293

Epoch: 5| Step: 1
Training loss: 2.3240704144497863
Validation loss: 2.402105567156929

Epoch: 5| Step: 2
Training loss: 2.3055873342670448
Validation loss: 2.4248766454275237

Epoch: 5| Step: 3
Training loss: 1.6890884976146299
Validation loss: 2.4548174969330128

Epoch: 5| Step: 4
Training loss: 2.3957966235015946
Validation loss: 2.464761143190341

Epoch: 5| Step: 5
Training loss: 2.4693349797069644
Validation loss: 2.4713343547292004

Epoch: 5| Step: 6
Training loss: 2.4632759730569567
Validation loss: 2.431924106589563

Epoch: 5| Step: 7
Training loss: 2.095548170748001
Validation loss: 2.436913763983642

Epoch: 5| Step: 8
Training loss: 2.1339123024693696
Validation loss: 2.414608913820782

Epoch: 5| Step: 9
Training loss: 2.2229559349398005
Validation loss: 2.4069361758437187

Epoch: 5| Step: 10
Training loss: 2.243924415206191
Validation loss: 2.399950205720471

Epoch: 225| Step: 0
Training loss: 2.0422010565776967
Validation loss: 2.4186828821461104

Epoch: 5| Step: 1
Training loss: 2.641644704187916
Validation loss: 2.472517801170504

Epoch: 5| Step: 2
Training loss: 2.388948338776759
Validation loss: 2.5459783211061975

Epoch: 5| Step: 3
Training loss: 2.5105397258898328
Validation loss: 2.558547310156041

Epoch: 5| Step: 4
Training loss: 2.6549085932512417
Validation loss: 2.527488928373483

Epoch: 5| Step: 5
Training loss: 2.5241592367152514
Validation loss: 2.4686154710121353

Epoch: 5| Step: 6
Training loss: 2.4692864137061576
Validation loss: 2.437752646706628

Epoch: 5| Step: 7
Training loss: 1.5751200857250045
Validation loss: 2.444673345316867

Epoch: 5| Step: 8
Training loss: 2.134204228775801
Validation loss: 2.439274361112876

Epoch: 5| Step: 9
Training loss: 2.316547460256344
Validation loss: 2.434146245119545

Epoch: 5| Step: 10
Training loss: 1.7779554718672308
Validation loss: 2.4197463764725113

Epoch: 226| Step: 0
Training loss: 2.227057579279391
Validation loss: 2.411309448258526

Epoch: 5| Step: 1
Training loss: 2.1252577008335702
Validation loss: 2.401524145852457

Epoch: 5| Step: 2
Training loss: 2.3024946739971845
Validation loss: 2.402356617557358

Epoch: 5| Step: 3
Training loss: 2.574481956443893
Validation loss: 2.416355389529302

Epoch: 5| Step: 4
Training loss: 2.2574021121544723
Validation loss: 2.439203237822642

Epoch: 5| Step: 5
Training loss: 1.4407668931305948
Validation loss: 2.445510629254802

Epoch: 5| Step: 6
Training loss: 2.1279879488065983
Validation loss: 2.450397493363953

Epoch: 5| Step: 7
Training loss: 2.5180813188094637
Validation loss: 2.4904536502625483

Epoch: 5| Step: 8
Training loss: 2.4198107382167438
Validation loss: 2.5218037742743205

Epoch: 5| Step: 9
Training loss: 2.291563783127922
Validation loss: 2.5273797291524565

Epoch: 5| Step: 10
Training loss: 2.5510753794994825
Validation loss: 2.491670342763434

Epoch: 227| Step: 0
Training loss: 1.5526005525321915
Validation loss: 2.474547304123358

Epoch: 5| Step: 1
Training loss: 2.3918650284582474
Validation loss: 2.448710842465122

Epoch: 5| Step: 2
Training loss: 2.078959706109102
Validation loss: 2.4442316973336062

Epoch: 5| Step: 3
Training loss: 2.368511673102706
Validation loss: 2.4394647038761

Epoch: 5| Step: 4
Training loss: 2.0916841478364514
Validation loss: 2.421567814690677

Epoch: 5| Step: 5
Training loss: 2.4632503237780714
Validation loss: 2.4244610812077245

Epoch: 5| Step: 6
Training loss: 2.4769663195701535
Validation loss: 2.4147762214284847

Epoch: 5| Step: 7
Training loss: 1.965251296381322
Validation loss: 2.392854138530809

Epoch: 5| Step: 8
Training loss: 2.592158369253604
Validation loss: 2.4008978151801013

Epoch: 5| Step: 9
Training loss: 2.188031595214684
Validation loss: 2.4015944945130543

Epoch: 5| Step: 10
Training loss: 1.9900243646481595
Validation loss: 2.3948465802212997

Epoch: 228| Step: 0
Training loss: 1.782416982014946
Validation loss: 2.410331632072291

Epoch: 5| Step: 1
Training loss: 2.14411474744985
Validation loss: 2.4218334447158303

Epoch: 5| Step: 2
Training loss: 2.280528751432088
Validation loss: 2.4190755277147113

Epoch: 5| Step: 3
Training loss: 2.302605985341493
Validation loss: 2.4089302910791104

Epoch: 5| Step: 4
Training loss: 1.894127682834181
Validation loss: 2.4306743812130245

Epoch: 5| Step: 5
Training loss: 2.5773476093283
Validation loss: 2.417707173271198

Epoch: 5| Step: 6
Training loss: 2.9961836700672793
Validation loss: 2.420803827942527

Epoch: 5| Step: 7
Training loss: 1.922293268604575
Validation loss: 2.4294100688983074

Epoch: 5| Step: 8
Training loss: 2.0824607420446086
Validation loss: 2.433183367506651

Epoch: 5| Step: 9
Training loss: 1.6412035693931952
Validation loss: 2.425395616619288

Epoch: 5| Step: 10
Training loss: 2.1770965600106273
Validation loss: 2.4234472405216145

Epoch: 229| Step: 0
Training loss: 2.1947957038087895
Validation loss: 2.428529091099148

Epoch: 5| Step: 1
Training loss: 2.181506420027252
Validation loss: 2.4476182740484154

Epoch: 5| Step: 2
Training loss: 1.8074767121520332
Validation loss: 2.457923847408539

Epoch: 5| Step: 3
Training loss: 1.5840004051140546
Validation loss: 2.4801975501511384

Epoch: 5| Step: 4
Training loss: 2.49447039378526
Validation loss: 2.5217103631671542

Epoch: 5| Step: 5
Training loss: 2.0901847204684882
Validation loss: 2.498920623485607

Epoch: 5| Step: 6
Training loss: 1.9925244813034921
Validation loss: 2.4524696780583155

Epoch: 5| Step: 7
Training loss: 2.3175100748939816
Validation loss: 2.397942679608468

Epoch: 5| Step: 8
Training loss: 2.8669446795594604
Validation loss: 2.357819007502431

Epoch: 5| Step: 9
Training loss: 2.1669555495931045
Validation loss: 2.3753228456571898

Epoch: 5| Step: 10
Training loss: 2.1183557419250723
Validation loss: 2.3786257144279372

Epoch: 230| Step: 0
Training loss: 2.1333309004690286
Validation loss: 2.4033024184092557

Epoch: 5| Step: 1
Training loss: 2.1488385190367367
Validation loss: 2.444126113278212

Epoch: 5| Step: 2
Training loss: 2.0558253861505515
Validation loss: 2.469956206794166

Epoch: 5| Step: 3
Training loss: 2.071419934315832
Validation loss: 2.4940680689879002

Epoch: 5| Step: 4
Training loss: 2.611424537767668
Validation loss: 2.490763279891909

Epoch: 5| Step: 5
Training loss: 2.0424399047004402
Validation loss: 2.4746694423418547

Epoch: 5| Step: 6
Training loss: 2.0636351958146646
Validation loss: 2.4506598604215926

Epoch: 5| Step: 7
Training loss: 1.69221445557038
Validation loss: 2.4462338673269053

Epoch: 5| Step: 8
Training loss: 2.6376991992231176
Validation loss: 2.439678737143516

Epoch: 5| Step: 9
Training loss: 2.298757806446289
Validation loss: 2.4228288945284646

Epoch: 5| Step: 10
Training loss: 2.5264980782132187
Validation loss: 2.3849656894556848

Epoch: 231| Step: 0
Training loss: 1.9590180870494696
Validation loss: 2.392209392274974

Epoch: 5| Step: 1
Training loss: 2.243203707100965
Validation loss: 2.385241902457696

Epoch: 5| Step: 2
Training loss: 2.341454869892939
Validation loss: 2.3681529425869625

Epoch: 5| Step: 3
Training loss: 2.0087141691571757
Validation loss: 2.3887250893318126

Epoch: 5| Step: 4
Training loss: 1.781698070186322
Validation loss: 2.3781647410808895

Epoch: 5| Step: 5
Training loss: 2.2565810069059697
Validation loss: 2.380268634603048

Epoch: 5| Step: 6
Training loss: 1.7597501121116674
Validation loss: 2.376554313530631

Epoch: 5| Step: 7
Training loss: 2.3186923449152657
Validation loss: 2.3699558807419545

Epoch: 5| Step: 8
Training loss: 1.7973373481684896
Validation loss: 2.37609950306936

Epoch: 5| Step: 9
Training loss: 2.475890348178779
Validation loss: 2.3681726286512985

Epoch: 5| Step: 10
Training loss: 2.5196659968813018
Validation loss: 2.3653636149285115

Epoch: 232| Step: 0
Training loss: 2.1128805912433344
Validation loss: 2.3873654397684168

Epoch: 5| Step: 1
Training loss: 2.2293108124044125
Validation loss: 2.405438296238352

Epoch: 5| Step: 2
Training loss: 2.2727281440386404
Validation loss: 2.466694144715621

Epoch: 5| Step: 3
Training loss: 2.4364463289401947
Validation loss: 2.5687489583158767

Epoch: 5| Step: 4
Training loss: 2.30333325959724
Validation loss: 2.633654463961633

Epoch: 5| Step: 5
Training loss: 2.0768026863157183
Validation loss: 2.5906829105511373

Epoch: 5| Step: 6
Training loss: 2.2740924324434104
Validation loss: 2.532854965744778

Epoch: 5| Step: 7
Training loss: 1.9620818792167498
Validation loss: 2.476560538369341

Epoch: 5| Step: 8
Training loss: 2.570395610358452
Validation loss: 2.4782065206364816

Epoch: 5| Step: 9
Training loss: 2.329209657475901
Validation loss: 2.4982076988221715

Epoch: 5| Step: 10
Training loss: 1.7694617251449463
Validation loss: 2.446707665528619

Epoch: 233| Step: 0
Training loss: 2.353195181277521
Validation loss: 2.4366587145970344

Epoch: 5| Step: 1
Training loss: 2.3384974304863704
Validation loss: 2.353803073146877

Epoch: 5| Step: 2
Training loss: 1.926673790655638
Validation loss: 2.3412848784259883

Epoch: 5| Step: 3
Training loss: 2.2175226174698826
Validation loss: 2.3643185511244718

Epoch: 5| Step: 4
Training loss: 2.3049611074679106
Validation loss: 2.4155717377084573

Epoch: 5| Step: 5
Training loss: 2.3268576635247182
Validation loss: 2.48047297093584

Epoch: 5| Step: 6
Training loss: 2.212157327441093
Validation loss: 2.452063489731834

Epoch: 5| Step: 7
Training loss: 2.0908396977003023
Validation loss: 2.4128654696224627

Epoch: 5| Step: 8
Training loss: 2.1410272596210516
Validation loss: 2.3482256316557097

Epoch: 5| Step: 9
Training loss: 2.0689294189833696
Validation loss: 2.3673989931044725

Epoch: 5| Step: 10
Training loss: 2.1014944299501077
Validation loss: 2.350214305610894

Epoch: 234| Step: 0
Training loss: 1.8261212183816367
Validation loss: 2.349393755453353

Epoch: 5| Step: 1
Training loss: 2.247599486800076
Validation loss: 2.3663441423379017

Epoch: 5| Step: 2
Training loss: 2.0709657034472437
Validation loss: 2.370697552231949

Epoch: 5| Step: 3
Training loss: 2.6491988896508865
Validation loss: 2.394238912416673

Epoch: 5| Step: 4
Training loss: 2.115004649416455
Validation loss: 2.402705370623522

Epoch: 5| Step: 5
Training loss: 1.925066213583709
Validation loss: 2.4529823840202427

Epoch: 5| Step: 6
Training loss: 1.8005582791393198
Validation loss: 2.528194997927221

Epoch: 5| Step: 7
Training loss: 2.230269174281929
Validation loss: 2.56438221449283

Epoch: 5| Step: 8
Training loss: 1.9367841813397513
Validation loss: 2.5322598066481374

Epoch: 5| Step: 9
Training loss: 2.344895146675298
Validation loss: 2.510603696112451

Epoch: 5| Step: 10
Training loss: 2.3304916743891133
Validation loss: 2.4600287532318212

Epoch: 235| Step: 0
Training loss: 1.8653349045430334
Validation loss: 2.4202109747515617

Epoch: 5| Step: 1
Training loss: 2.384149495231537
Validation loss: 2.402378874704633

Epoch: 5| Step: 2
Training loss: 2.49952979434334
Validation loss: 2.390769760549974

Epoch: 5| Step: 3
Training loss: 1.8216157103819743
Validation loss: 2.3869483895953563

Epoch: 5| Step: 4
Training loss: 2.239942749517979
Validation loss: 2.401318744708146

Epoch: 5| Step: 5
Training loss: 1.7890277176186955
Validation loss: 2.424446570376433

Epoch: 5| Step: 6
Training loss: 1.7827123695759672
Validation loss: 2.454456893432179

Epoch: 5| Step: 7
Training loss: 1.7977243157754739
Validation loss: 2.479648822057577

Epoch: 5| Step: 8
Training loss: 2.0651355434758383
Validation loss: 2.47295952332417

Epoch: 5| Step: 9
Training loss: 2.1080782825259523
Validation loss: 2.477430395545091

Epoch: 5| Step: 10
Training loss: 2.5850265142973603
Validation loss: 2.4523353431756525

Epoch: 236| Step: 0
Training loss: 2.5141954802911517
Validation loss: 2.4461428053544854

Epoch: 5| Step: 1
Training loss: 2.069050299754411
Validation loss: 2.399566565277324

Epoch: 5| Step: 2
Training loss: 2.0037246830055384
Validation loss: 2.371142438365789

Epoch: 5| Step: 3
Training loss: 1.970903157723853
Validation loss: 2.376636877992339

Epoch: 5| Step: 4
Training loss: 2.003811304174327
Validation loss: 2.3866488275613458

Epoch: 5| Step: 5
Training loss: 1.8494466289070521
Validation loss: 2.378282309283773

Epoch: 5| Step: 6
Training loss: 2.0200691613547526
Validation loss: 2.3813240393097463

Epoch: 5| Step: 7
Training loss: 1.9630579331487688
Validation loss: 2.3893349051422743

Epoch: 5| Step: 8
Training loss: 1.6396543265277284
Validation loss: 2.3875470165022947

Epoch: 5| Step: 9
Training loss: 2.4051448711769687
Validation loss: 2.40092760617309

Epoch: 5| Step: 10
Training loss: 2.0853879969173046
Validation loss: 2.4081936776767203

Epoch: 237| Step: 0
Training loss: 2.126012224451126
Validation loss: 2.398496587998864

Epoch: 5| Step: 1
Training loss: 2.515815775017015
Validation loss: 2.4372144457684266

Epoch: 5| Step: 2
Training loss: 1.9654332029471753
Validation loss: 2.4823181012407094

Epoch: 5| Step: 3
Training loss: 2.061963676310302
Validation loss: 2.50495306776555

Epoch: 5| Step: 4
Training loss: 1.963073904106674
Validation loss: 2.472932337565194

Epoch: 5| Step: 5
Training loss: 1.986347689761992
Validation loss: 2.4329030653039694

Epoch: 5| Step: 6
Training loss: 2.062383475046416
Validation loss: 2.412873273584289

Epoch: 5| Step: 7
Training loss: 1.3736094899816733
Validation loss: 2.4095391017377334

Epoch: 5| Step: 8
Training loss: 2.2078492935689233
Validation loss: 2.405487743130676

Epoch: 5| Step: 9
Training loss: 2.3674060481441606
Validation loss: 2.407780416689778

Epoch: 5| Step: 10
Training loss: 2.099935703201545
Validation loss: 2.3853668846792626

Epoch: 238| Step: 0
Training loss: 1.8707819222888966
Validation loss: 2.3631434854117157

Epoch: 5| Step: 1
Training loss: 1.5637988223619683
Validation loss: 2.3602414831736898

Epoch: 5| Step: 2
Training loss: 1.6759115670847542
Validation loss: 2.376008619976611

Epoch: 5| Step: 3
Training loss: 2.0979110591425827
Validation loss: 2.3755252799125364

Epoch: 5| Step: 4
Training loss: 2.21906826261893
Validation loss: 2.397495369191629

Epoch: 5| Step: 5
Training loss: 2.218628033791478
Validation loss: 2.3792037062605274

Epoch: 5| Step: 6
Training loss: 2.475060425608352
Validation loss: 2.370053189647699

Epoch: 5| Step: 7
Training loss: 2.0840847059157372
Validation loss: 2.3637929461576883

Epoch: 5| Step: 8
Training loss: 1.9485517748227885
Validation loss: 2.3360588066103003

Epoch: 5| Step: 9
Training loss: 2.125613741038698
Validation loss: 2.3425162488370956

Epoch: 5| Step: 10
Training loss: 1.9512870380373621
Validation loss: 2.3711088846723793

Epoch: 239| Step: 0
Training loss: 2.157143449196784
Validation loss: 2.4012999944292144

Epoch: 5| Step: 1
Training loss: 1.7224740345053937
Validation loss: 2.4066304062103616

Epoch: 5| Step: 2
Training loss: 2.1134837506592135
Validation loss: 2.4453088652299293

Epoch: 5| Step: 3
Training loss: 2.0017755494796075
Validation loss: 2.4537175935445963

Epoch: 5| Step: 4
Training loss: 2.1807308639496683
Validation loss: 2.463499690677318

Epoch: 5| Step: 5
Training loss: 1.6860693058960146
Validation loss: 2.4698898453553193

Epoch: 5| Step: 6
Training loss: 2.248780873941778
Validation loss: 2.476399398820456

Epoch: 5| Step: 7
Training loss: 2.0838102430618184
Validation loss: 2.4728555256068727

Epoch: 5| Step: 8
Training loss: 1.7197489523093528
Validation loss: 2.483631848666246

Epoch: 5| Step: 9
Training loss: 1.6056067785622705
Validation loss: 2.4430470324395586

Epoch: 5| Step: 10
Training loss: 2.1644011415009388
Validation loss: 2.4361354067699192

Epoch: 240| Step: 0
Training loss: 1.9939114161474465
Validation loss: 2.444668919951288

Epoch: 5| Step: 1
Training loss: 2.3327409696247816
Validation loss: 2.4557255351351692

Epoch: 5| Step: 2
Training loss: 1.9724813553735159
Validation loss: 2.424340129933213

Epoch: 5| Step: 3
Training loss: 1.8429687913973076
Validation loss: 2.4416783282533356

Epoch: 5| Step: 4
Training loss: 2.4056833764295322
Validation loss: 2.427435544694875

Epoch: 5| Step: 5
Training loss: 1.3994803775639673
Validation loss: 2.4252769307015445

Epoch: 5| Step: 6
Training loss: 2.321656322835028
Validation loss: 2.4116685870842476

Epoch: 5| Step: 7
Training loss: 2.114828562179949
Validation loss: 2.4132840960832715

Epoch: 5| Step: 8
Training loss: 1.7486530297247302
Validation loss: 2.437787702907359

Epoch: 5| Step: 9
Training loss: 1.229628696998777
Validation loss: 2.439486686564806

Epoch: 5| Step: 10
Training loss: 1.947136816357857
Validation loss: 2.4515655589713514

Epoch: 241| Step: 0
Training loss: 1.4828529987492551
Validation loss: 2.4596366093876294

Epoch: 5| Step: 1
Training loss: 1.7493053147371045
Validation loss: 2.4834802086404393

Epoch: 5| Step: 2
Training loss: 1.8833571156825943
Validation loss: 2.489862205431078

Epoch: 5| Step: 3
Training loss: 1.8521480358766569
Validation loss: 2.4653895196274114

Epoch: 5| Step: 4
Training loss: 2.475193740505892
Validation loss: 2.4454827913612616

Epoch: 5| Step: 5
Training loss: 2.233436013703354
Validation loss: 2.4507655594452613

Epoch: 5| Step: 6
Training loss: 1.9119426588374384
Validation loss: 2.43886168008597

Epoch: 5| Step: 7
Training loss: 2.1248958786531604
Validation loss: 2.4315427200764956

Epoch: 5| Step: 8
Training loss: 2.230376607458075
Validation loss: 2.4402557100804123

Epoch: 5| Step: 9
Training loss: 1.470084375567968
Validation loss: 2.466766490519702

Epoch: 5| Step: 10
Training loss: 1.8402629787721723
Validation loss: 2.466590159819731

Epoch: 242| Step: 0
Training loss: 1.668815308625181
Validation loss: 2.4664199839061447

Epoch: 5| Step: 1
Training loss: 2.2595734906097995
Validation loss: 2.4676432633396317

Epoch: 5| Step: 2
Training loss: 2.115581508623316
Validation loss: 2.460010762038135

Epoch: 5| Step: 3
Training loss: 1.7079077244741894
Validation loss: 2.4576775844403667

Epoch: 5| Step: 4
Training loss: 1.533186797036863
Validation loss: 2.438052049443179

Epoch: 5| Step: 5
Training loss: 2.110914332716598
Validation loss: 2.4308604738749167

Epoch: 5| Step: 6
Training loss: 1.9614350800867144
Validation loss: 2.410674834016755

Epoch: 5| Step: 7
Training loss: 2.2724771994946176
Validation loss: 2.4139143964761383

Epoch: 5| Step: 8
Training loss: 1.769140878358546
Validation loss: 2.4122786041861404

Epoch: 5| Step: 9
Training loss: 1.3265016395797402
Validation loss: 2.411064475292934

Epoch: 5| Step: 10
Training loss: 2.1671137592996472
Validation loss: 2.4126360675555727

Epoch: 243| Step: 0
Training loss: 2.0703863166748997
Validation loss: 2.43293528521514

Epoch: 5| Step: 1
Training loss: 1.8393707639312962
Validation loss: 2.4557775856455497

Epoch: 5| Step: 2
Training loss: 1.7973394705830807
Validation loss: 2.4918454887360126

Epoch: 5| Step: 3
Training loss: 1.7115467676341982
Validation loss: 2.472691746537149

Epoch: 5| Step: 4
Training loss: 1.8535217992520978
Validation loss: 2.4922326232670344

Epoch: 5| Step: 5
Training loss: 1.9860365512015987
Validation loss: 2.4858434481324574

Epoch: 5| Step: 6
Training loss: 1.989700799906253
Validation loss: 2.4761969722078647

Epoch: 5| Step: 7
Training loss: 1.821150885446246
Validation loss: 2.459353616566817

Epoch: 5| Step: 8
Training loss: 1.9120530148422619
Validation loss: 2.4368601491120137

Epoch: 5| Step: 9
Training loss: 2.287425214034821
Validation loss: 2.441347323717635

Epoch: 5| Step: 10
Training loss: 1.7509920850364662
Validation loss: 2.4286907509613287

Epoch: 244| Step: 0
Training loss: 1.8717813204089533
Validation loss: 2.4384717852572586

Epoch: 5| Step: 1
Training loss: 1.517409856591844
Validation loss: 2.412011550966269

Epoch: 5| Step: 2
Training loss: 1.383466275081552
Validation loss: 2.427105505620779

Epoch: 5| Step: 3
Training loss: 2.2296983554204255
Validation loss: 2.4460268596619663

Epoch: 5| Step: 4
Training loss: 2.1216036638533198
Validation loss: 2.463382233888868

Epoch: 5| Step: 5
Training loss: 1.8961430879955232
Validation loss: 2.451348095880317

Epoch: 5| Step: 6
Training loss: 2.083750288882633
Validation loss: 2.4426162513109446

Epoch: 5| Step: 7
Training loss: 2.014495533157816
Validation loss: 2.4392367870606395

Epoch: 5| Step: 8
Training loss: 1.9554952658525482
Validation loss: 2.410196974861616

Epoch: 5| Step: 9
Training loss: 1.9106727323100852
Validation loss: 2.4134630015794385

Epoch: 5| Step: 10
Training loss: 1.5858672929830444
Validation loss: 2.4066360477184454

Epoch: 245| Step: 0
Training loss: 1.4903134066322403
Validation loss: 2.403457679210761

Epoch: 5| Step: 1
Training loss: 1.6552238884545634
Validation loss: 2.4277166978187887

Epoch: 5| Step: 2
Training loss: 1.8745079030551812
Validation loss: 2.427090303961236

Epoch: 5| Step: 3
Training loss: 2.132681929954739
Validation loss: 2.422194134832957

Epoch: 5| Step: 4
Training loss: 1.8745850421767436
Validation loss: 2.431404613050892

Epoch: 5| Step: 5
Training loss: 1.6728914682557827
Validation loss: 2.4372518211674516

Epoch: 5| Step: 6
Training loss: 1.9863247641625943
Validation loss: 2.449254211492499

Epoch: 5| Step: 7
Training loss: 1.8505530200939484
Validation loss: 2.4370228605666404

Epoch: 5| Step: 8
Training loss: 1.9544520638072602
Validation loss: 2.470282608894041

Epoch: 5| Step: 9
Training loss: 2.0408885277412914
Validation loss: 2.4843720012803288

Epoch: 5| Step: 10
Training loss: 1.7483553651500947
Validation loss: 2.4696258926769463

Epoch: 246| Step: 0
Training loss: 2.3297946754328573
Validation loss: 2.480169404906443

Epoch: 5| Step: 1
Training loss: 1.8151102015770333
Validation loss: 2.473378843217111

Epoch: 5| Step: 2
Training loss: 1.7997232171349786
Validation loss: 2.44898528314198

Epoch: 5| Step: 3
Training loss: 2.0085526226615245
Validation loss: 2.4208264783409517

Epoch: 5| Step: 4
Training loss: 1.9367385721673374
Validation loss: 2.403756522287966

Epoch: 5| Step: 5
Training loss: 1.5968926803894101
Validation loss: 2.4107285356944135

Epoch: 5| Step: 6
Training loss: 1.8508223329801423
Validation loss: 2.3968519815812277

Epoch: 5| Step: 7
Training loss: 1.6485764142121846
Validation loss: 2.4181672378465215

Epoch: 5| Step: 8
Training loss: 2.113723341978453
Validation loss: 2.4055014890923987

Epoch: 5| Step: 9
Training loss: 1.5351769831764293
Validation loss: 2.4020264177273267

Epoch: 5| Step: 10
Training loss: 1.6205408095482745
Validation loss: 2.4372394854820802

Epoch: 247| Step: 0
Training loss: 1.6128864682772939
Validation loss: 2.4504294769693087

Epoch: 5| Step: 1
Training loss: 2.1756064654675553
Validation loss: 2.4573823510480914

Epoch: 5| Step: 2
Training loss: 1.162440097455006
Validation loss: 2.4386063918425003

Epoch: 5| Step: 3
Training loss: 2.0773167006218904
Validation loss: 2.4134049949018475

Epoch: 5| Step: 4
Training loss: 1.9087104552443852
Validation loss: 2.4053109399123156

Epoch: 5| Step: 5
Training loss: 2.1071134523644552
Validation loss: 2.41943414209482

Epoch: 5| Step: 6
Training loss: 1.5746921177830622
Validation loss: 2.428962747408381

Epoch: 5| Step: 7
Training loss: 1.9367755027540587
Validation loss: 2.4662933348812515

Epoch: 5| Step: 8
Training loss: 1.7088327918265593
Validation loss: 2.5064100667583387

Epoch: 5| Step: 9
Training loss: 1.8177411168447617
Validation loss: 2.501318693512893

Epoch: 5| Step: 10
Training loss: 1.9124521137301167
Validation loss: 2.490920091834555

Epoch: 248| Step: 0
Training loss: 2.240724518293653
Validation loss: 2.488630208030675

Epoch: 5| Step: 1
Training loss: 2.0414676439503974
Validation loss: 2.4503882280735447

Epoch: 5| Step: 2
Training loss: 1.3525657238036741
Validation loss: 2.403190222357185

Epoch: 5| Step: 3
Training loss: 1.9196042548065502
Validation loss: 2.38392125502564

Epoch: 5| Step: 4
Training loss: 2.1161469439735914
Validation loss: 2.389022600031811

Epoch: 5| Step: 5
Training loss: 1.3556587020181081
Validation loss: 2.39059905916719

Epoch: 5| Step: 6
Training loss: 1.6923148377641133
Validation loss: 2.415105812816855

Epoch: 5| Step: 7
Training loss: 1.9726746208921808
Validation loss: 2.4330650082684495

Epoch: 5| Step: 8
Training loss: 1.997342430173397
Validation loss: 2.4222109749135146

Epoch: 5| Step: 9
Training loss: 1.543062772179839
Validation loss: 2.4119337841933457

Epoch: 5| Step: 10
Training loss: 1.270772051766789
Validation loss: 2.3742375879892434

Epoch: 249| Step: 0
Training loss: 1.6268037908374373
Validation loss: 2.364649670658637

Epoch: 5| Step: 1
Training loss: 1.6961568672177225
Validation loss: 2.3820038045670247

Epoch: 5| Step: 2
Training loss: 2.0324837092536185
Validation loss: 2.371156079621722

Epoch: 5| Step: 3
Training loss: 1.8013289605437504
Validation loss: 2.386833328744147

Epoch: 5| Step: 4
Training loss: 1.8181270200967958
Validation loss: 2.446274876071895

Epoch: 5| Step: 5
Training loss: 1.518025650159521
Validation loss: 2.457210054371498

Epoch: 5| Step: 6
Training loss: 1.8348080021668953
Validation loss: 2.494899058868749

Epoch: 5| Step: 7
Training loss: 1.9863793770658635
Validation loss: 2.4977884447320235

Epoch: 5| Step: 8
Training loss: 1.8180568619618078
Validation loss: 2.5080243558081623

Epoch: 5| Step: 9
Training loss: 1.767454229407004
Validation loss: 2.519025930797342

Epoch: 5| Step: 10
Training loss: 1.7168925565718338
Validation loss: 2.4775255444517326

Epoch: 250| Step: 0
Training loss: 1.768052651795091
Validation loss: 2.3921833143022617

Epoch: 5| Step: 1
Training loss: 1.3464986058372082
Validation loss: 2.395632354381826

Epoch: 5| Step: 2
Training loss: 1.9538795539530043
Validation loss: 2.3835994954628013

Epoch: 5| Step: 3
Training loss: 1.9691672110129674
Validation loss: 2.3771981708319343

Epoch: 5| Step: 4
Training loss: 2.0117820359432685
Validation loss: 2.421318445949862

Epoch: 5| Step: 5
Training loss: 1.793550218362442
Validation loss: 2.4959514435555676

Epoch: 5| Step: 6
Training loss: 1.7711695482804868
Validation loss: 2.5112407197983284

Epoch: 5| Step: 7
Training loss: 2.1617800798667046
Validation loss: 2.465675254444905

Epoch: 5| Step: 8
Training loss: 1.655752071171392
Validation loss: 2.385106784288047

Epoch: 5| Step: 9
Training loss: 1.7371025975727568
Validation loss: 2.366210118963155

Epoch: 5| Step: 10
Training loss: 1.6637914015894328
Validation loss: 2.363918828153059

Epoch: 251| Step: 0
Training loss: 1.6984767653094766
Validation loss: 2.337648260303912

Epoch: 5| Step: 1
Training loss: 1.118808184341402
Validation loss: 2.3908110193743135

Epoch: 5| Step: 2
Training loss: 1.8946524355168448
Validation loss: 2.4399179246211835

Epoch: 5| Step: 3
Training loss: 1.9957022385624195
Validation loss: 2.5205614931051485

Epoch: 5| Step: 4
Training loss: 1.6591768854127678
Validation loss: 2.5393073941523467

Epoch: 5| Step: 5
Training loss: 2.1734232701179232
Validation loss: 2.543863451289357

Epoch: 5| Step: 6
Training loss: 1.7528876594456824
Validation loss: 2.4635393672154424

Epoch: 5| Step: 7
Training loss: 2.0391684318298924
Validation loss: 2.398422506780626

Epoch: 5| Step: 8
Training loss: 2.0850528741439804
Validation loss: 2.3838634414584017

Epoch: 5| Step: 9
Training loss: 1.4708780334135345
Validation loss: 2.3835545495778963

Epoch: 5| Step: 10
Training loss: 1.8903657719727982
Validation loss: 2.3881689961395742

Epoch: 252| Step: 0
Training loss: 2.0025669552471403
Validation loss: 2.404570276248228

Epoch: 5| Step: 1
Training loss: 1.2958411726556038
Validation loss: 2.488882664303655

Epoch: 5| Step: 2
Training loss: 1.5748551741120485
Validation loss: 2.5586615726211814

Epoch: 5| Step: 3
Training loss: 2.0302188309981517
Validation loss: 2.6641539828399785

Epoch: 5| Step: 4
Training loss: 1.896097632908313
Validation loss: 2.627093619454261

Epoch: 5| Step: 5
Training loss: 1.7315268973349671
Validation loss: 2.5445937179149642

Epoch: 5| Step: 6
Training loss: 1.8710133449663677
Validation loss: 2.4426892839988583

Epoch: 5| Step: 7
Training loss: 1.6306195294020487
Validation loss: 2.3955359496838513

Epoch: 5| Step: 8
Training loss: 2.0551793195168817
Validation loss: 2.3906499679197775

Epoch: 5| Step: 9
Training loss: 1.9784951995066415
Validation loss: 2.3630077328870147

Epoch: 5| Step: 10
Training loss: 1.7846635601860734
Validation loss: 2.354132611108888

Epoch: 253| Step: 0
Training loss: 1.8159347086188966
Validation loss: 2.334666280854315

Epoch: 5| Step: 1
Training loss: 1.6396952583212323
Validation loss: 2.3369660145788784

Epoch: 5| Step: 2
Training loss: 1.5012667393445955
Validation loss: 2.3854968371910408

Epoch: 5| Step: 3
Training loss: 1.8185378825972485
Validation loss: 2.5067659988578797

Epoch: 5| Step: 4
Training loss: 2.1851089488785767
Validation loss: 2.5924740521855076

Epoch: 5| Step: 5
Training loss: 1.714579429328463
Validation loss: 2.589860189914006

Epoch: 5| Step: 6
Training loss: 1.8027364910605133
Validation loss: 2.5140472031696213

Epoch: 5| Step: 7
Training loss: 1.7836881314343398
Validation loss: 2.42432473433667

Epoch: 5| Step: 8
Training loss: 2.261337221739833
Validation loss: 2.3909983184282626

Epoch: 5| Step: 9
Training loss: 1.6530941821508645
Validation loss: 2.3645600019652533

Epoch: 5| Step: 10
Training loss: 1.632415504196672
Validation loss: 2.3698586111113813

Epoch: 254| Step: 0
Training loss: 1.7239323947334269
Validation loss: 2.355804734482396

Epoch: 5| Step: 1
Training loss: 1.8397497975198598
Validation loss: 2.343389785048238

Epoch: 5| Step: 2
Training loss: 1.9382388029174862
Validation loss: 2.3494949559138636

Epoch: 5| Step: 3
Training loss: 1.6326820284903596
Validation loss: 2.3712033687734517

Epoch: 5| Step: 4
Training loss: 1.8294325497003705
Validation loss: 2.4011626633630163

Epoch: 5| Step: 5
Training loss: 1.487834553001271
Validation loss: 2.474892405589566

Epoch: 5| Step: 6
Training loss: 1.6560811370562216
Validation loss: 2.5543803991016123

Epoch: 5| Step: 7
Training loss: 2.061502851404202
Validation loss: 2.6124456939807303

Epoch: 5| Step: 8
Training loss: 1.7292933896367633
Validation loss: 2.5997700378124073

Epoch: 5| Step: 9
Training loss: 1.7030506642769012
Validation loss: 2.5207552588004978

Epoch: 5| Step: 10
Training loss: 1.7446023259458876
Validation loss: 2.4144703032466825

Epoch: 255| Step: 0
Training loss: 1.3042612807268796
Validation loss: 2.364730691232561

Epoch: 5| Step: 1
Training loss: 1.9043259212528376
Validation loss: 2.37733329043373

Epoch: 5| Step: 2
Training loss: 1.8889769630218873
Validation loss: 2.3846741723690297

Epoch: 5| Step: 3
Training loss: 1.6614036989546725
Validation loss: 2.4014787812369116

Epoch: 5| Step: 4
Training loss: 1.780726439511209
Validation loss: 2.424252695519702

Epoch: 5| Step: 5
Training loss: 1.2627530420357709
Validation loss: 2.4726537347311086

Epoch: 5| Step: 6
Training loss: 1.913126066370221
Validation loss: 2.5167360047951606

Epoch: 5| Step: 7
Training loss: 2.051372333902606
Validation loss: 2.5322447270181314

Epoch: 5| Step: 8
Training loss: 1.7905162252305118
Validation loss: 2.487166947397545

Epoch: 5| Step: 9
Training loss: 1.8081836606270039
Validation loss: 2.426847186996832

Epoch: 5| Step: 10
Training loss: 1.7429494517312552
Validation loss: 2.3778092533853314

Epoch: 256| Step: 0
Training loss: 1.9752775093869634
Validation loss: 2.3480509911951972

Epoch: 5| Step: 1
Training loss: 2.003964904759576
Validation loss: 2.3587020406508854

Epoch: 5| Step: 2
Training loss: 1.464293353629039
Validation loss: 2.337776171891157

Epoch: 5| Step: 3
Training loss: 1.5910932799638948
Validation loss: 2.3442665673876912

Epoch: 5| Step: 4
Training loss: 1.5681777031785453
Validation loss: 2.3441816319441795

Epoch: 5| Step: 5
Training loss: 1.6433327264894264
Validation loss: 2.364566688177248

Epoch: 5| Step: 6
Training loss: 1.3728115265354566
Validation loss: 2.3691009046630787

Epoch: 5| Step: 7
Training loss: 1.687211329883068
Validation loss: 2.3637089585586675

Epoch: 5| Step: 8
Training loss: 1.5767731872663333
Validation loss: 2.393568168894001

Epoch: 5| Step: 9
Training loss: 1.5078018267159883
Validation loss: 2.4403702417950406

Epoch: 5| Step: 10
Training loss: 2.057948204901279
Validation loss: 2.4353700923597073

Epoch: 257| Step: 0
Training loss: 1.6179487859874828
Validation loss: 2.3834539530796004

Epoch: 5| Step: 1
Training loss: 1.9339778017823435
Validation loss: 2.375597638429697

Epoch: 5| Step: 2
Training loss: 1.5224219434049768
Validation loss: 2.357243803802636

Epoch: 5| Step: 3
Training loss: 1.8919923109942731
Validation loss: 2.3613477040254907

Epoch: 5| Step: 4
Training loss: 1.6868108825822836
Validation loss: 2.3606524563271156

Epoch: 5| Step: 5
Training loss: 1.79859443993945
Validation loss: 2.3587511777195305

Epoch: 5| Step: 6
Training loss: 1.3943918623304346
Validation loss: 2.3744563272208463

Epoch: 5| Step: 7
Training loss: 1.3484956200584763
Validation loss: 2.3817371240833234

Epoch: 5| Step: 8
Training loss: 1.7887764914501605
Validation loss: 2.410666019034419

Epoch: 5| Step: 9
Training loss: 1.7705409388275812
Validation loss: 2.4464423958015895

Epoch: 5| Step: 10
Training loss: 1.3274658362523821
Validation loss: 2.4696410723047246

Epoch: 258| Step: 0
Training loss: 1.8122653151538728
Validation loss: 2.478341054488586

Epoch: 5| Step: 1
Training loss: 1.553612648991794
Validation loss: 2.4750377127205327

Epoch: 5| Step: 2
Training loss: 1.3952329350220614
Validation loss: 2.4117473998777164

Epoch: 5| Step: 3
Training loss: 1.7480709479182155
Validation loss: 2.3819462867172496

Epoch: 5| Step: 4
Training loss: 1.6590311703550342
Validation loss: 2.353096602169562

Epoch: 5| Step: 5
Training loss: 1.5458965096669517
Validation loss: 2.341393350377631

Epoch: 5| Step: 6
Training loss: 1.8085008107110512
Validation loss: 2.361808504681879

Epoch: 5| Step: 7
Training loss: 1.6055345359373763
Validation loss: 2.4002568519809326

Epoch: 5| Step: 8
Training loss: 1.59947858003212
Validation loss: 2.4523105966386476

Epoch: 5| Step: 9
Training loss: 1.3336821586565926
Validation loss: 2.483035244806965

Epoch: 5| Step: 10
Training loss: 2.2370962364699527
Validation loss: 2.534687309757035

Epoch: 259| Step: 0
Training loss: 1.800802565839474
Validation loss: 2.496438797091411

Epoch: 5| Step: 1
Training loss: 1.7016880377916679
Validation loss: 2.443079113585266

Epoch: 5| Step: 2
Training loss: 1.5009639344835168
Validation loss: 2.3991540990881273

Epoch: 5| Step: 3
Training loss: 2.0431545311680224
Validation loss: 2.3864536663506857

Epoch: 5| Step: 4
Training loss: 1.6806514369350725
Validation loss: 2.3641268107098092

Epoch: 5| Step: 5
Training loss: 1.4512021868942673
Validation loss: 2.37870859767425

Epoch: 5| Step: 6
Training loss: 1.363624245416375
Validation loss: 2.396366110081544

Epoch: 5| Step: 7
Training loss: 1.758618657373385
Validation loss: 2.409168632399458

Epoch: 5| Step: 8
Training loss: 1.4125848710885514
Validation loss: 2.430968742194047

Epoch: 5| Step: 9
Training loss: 1.4828147317369105
Validation loss: 2.4432675805304496

Epoch: 5| Step: 10
Training loss: 1.627850233678001
Validation loss: 2.4508457645585326

Epoch: 260| Step: 0
Training loss: 1.622689952693185
Validation loss: 2.4212022474824293

Epoch: 5| Step: 1
Training loss: 1.4823679958197011
Validation loss: 2.3882424593711926

Epoch: 5| Step: 2
Training loss: 1.6962953170986086
Validation loss: 2.381513423623206

Epoch: 5| Step: 3
Training loss: 1.368277110099737
Validation loss: 2.3764344273134563

Epoch: 5| Step: 4
Training loss: 1.4759397454924164
Validation loss: 2.3598143509352445

Epoch: 5| Step: 5
Training loss: 1.6945143547992167
Validation loss: 2.3670571141475976

Epoch: 5| Step: 6
Training loss: 1.7607547126955017
Validation loss: 2.3276504040569965

Epoch: 5| Step: 7
Training loss: 1.4418049082691151
Validation loss: 2.333712158859504

Epoch: 5| Step: 8
Training loss: 1.7266289883753037
Validation loss: 2.334125306020228

Epoch: 5| Step: 9
Training loss: 1.8638570923358462
Validation loss: 2.3592741483645163

Epoch: 5| Step: 10
Training loss: 1.3977484683835395
Validation loss: 2.3866925884032333

Epoch: 261| Step: 0
Training loss: 1.6197276046530622
Validation loss: 2.43936391179446

Epoch: 5| Step: 1
Training loss: 1.2125244570752944
Validation loss: 2.492585599826608

Epoch: 5| Step: 2
Training loss: 1.43783051381458
Validation loss: 2.5238326868804704

Epoch: 5| Step: 3
Training loss: 1.5606662671152347
Validation loss: 2.5033517682751367

Epoch: 5| Step: 4
Training loss: 2.0802223119773844
Validation loss: 2.495539277273249

Epoch: 5| Step: 5
Training loss: 1.2312131537331532
Validation loss: 2.422028163124936

Epoch: 5| Step: 6
Training loss: 1.5940514073811356
Validation loss: 2.3863142927008534

Epoch: 5| Step: 7
Training loss: 1.7801080355915722
Validation loss: 2.367478465313792

Epoch: 5| Step: 8
Training loss: 1.8967941141243962
Validation loss: 2.3734773159815554

Epoch: 5| Step: 9
Training loss: 1.2462906637033526
Validation loss: 2.3640695573624035

Epoch: 5| Step: 10
Training loss: 1.6638974389967671
Validation loss: 2.364382927017386

Epoch: 262| Step: 0
Training loss: 1.4303544786896853
Validation loss: 2.384408848514367

Epoch: 5| Step: 1
Training loss: 1.6647362576335802
Validation loss: 2.3807112228348317

Epoch: 5| Step: 2
Training loss: 1.9295176689997684
Validation loss: 2.4063596323600325

Epoch: 5| Step: 3
Training loss: 1.6290848814720027
Validation loss: 2.4250176889078663

Epoch: 5| Step: 4
Training loss: 1.3366115721068486
Validation loss: 2.4697653838520695

Epoch: 5| Step: 5
Training loss: 1.656621207618388
Validation loss: 2.470632998815208

Epoch: 5| Step: 6
Training loss: 1.1937112991690475
Validation loss: 2.456655778463238

Epoch: 5| Step: 7
Training loss: 1.6199445580779417
Validation loss: 2.4521672767456537

Epoch: 5| Step: 8
Training loss: 1.2584171145170813
Validation loss: 2.423989593896413

Epoch: 5| Step: 9
Training loss: 1.906752348199551
Validation loss: 2.3995014756903026

Epoch: 5| Step: 10
Training loss: 1.591162432278608
Validation loss: 2.391966938896511

Epoch: 263| Step: 0
Training loss: 1.4284110285764522
Validation loss: 2.3820111510641033

Epoch: 5| Step: 1
Training loss: 1.2907238051900103
Validation loss: 2.363104630340737

Epoch: 5| Step: 2
Training loss: 1.6626212455879774
Validation loss: 2.3735915186562573

Epoch: 5| Step: 3
Training loss: 1.7631474218934007
Validation loss: 2.3956881097024696

Epoch: 5| Step: 4
Training loss: 1.3819641700797956
Validation loss: 2.401088876873827

Epoch: 5| Step: 5
Training loss: 1.6353289181763342
Validation loss: 2.4232188021273053

Epoch: 5| Step: 6
Training loss: 1.6298268595988648
Validation loss: 2.4273671489467166

Epoch: 5| Step: 7
Training loss: 1.5716238287585564
Validation loss: 2.4114486753322213

Epoch: 5| Step: 8
Training loss: 1.5963689192504584
Validation loss: 2.3923089819234638

Epoch: 5| Step: 9
Training loss: 1.2781606506001801
Validation loss: 2.397488442259364

Epoch: 5| Step: 10
Training loss: 1.7971846603930954
Validation loss: 2.3606462667294394

Epoch: 264| Step: 0
Training loss: 1.6070274341855069
Validation loss: 2.3778356323925682

Epoch: 5| Step: 1
Training loss: 1.680367620414336
Validation loss: 2.3836894481442386

Epoch: 5| Step: 2
Training loss: 1.336880312173855
Validation loss: 2.38718051363039

Epoch: 5| Step: 3
Training loss: 1.446987933701069
Validation loss: 2.4002416501025654

Epoch: 5| Step: 4
Training loss: 1.6681689961856998
Validation loss: 2.402967671415708

Epoch: 5| Step: 5
Training loss: 1.4403628162443771
Validation loss: 2.3761325266726185

Epoch: 5| Step: 6
Training loss: 1.345609841622367
Validation loss: 2.3561601082153576

Epoch: 5| Step: 7
Training loss: 1.3981061574853935
Validation loss: 2.3623210467220566

Epoch: 5| Step: 8
Training loss: 1.3829446503161336
Validation loss: 2.364807244792729

Epoch: 5| Step: 9
Training loss: 1.9531312255760156
Validation loss: 2.3756493229687643

Epoch: 5| Step: 10
Training loss: 1.5599511528926189
Validation loss: 2.3705140500397976

Epoch: 265| Step: 0
Training loss: 1.341394977822151
Validation loss: 2.3867533194743835

Epoch: 5| Step: 1
Training loss: 1.1425545453629944
Validation loss: 2.424153558938755

Epoch: 5| Step: 2
Training loss: 1.355565356239125
Validation loss: 2.4777890399718787

Epoch: 5| Step: 3
Training loss: 1.72834120048172
Validation loss: 2.484636675431795

Epoch: 5| Step: 4
Training loss: 1.5756091468797326
Validation loss: 2.4821595859982986

Epoch: 5| Step: 5
Training loss: 1.6909119762608587
Validation loss: 2.4542357954841147

Epoch: 5| Step: 6
Training loss: 1.5400307799644508
Validation loss: 2.4053878635389183

Epoch: 5| Step: 7
Training loss: 1.5955045429429255
Validation loss: 2.405342889937426

Epoch: 5| Step: 8
Training loss: 1.7745778454870904
Validation loss: 2.381502466154815

Epoch: 5| Step: 9
Training loss: 1.5595176463350284
Validation loss: 2.3564580238055575

Epoch: 5| Step: 10
Training loss: 1.5354573583020201
Validation loss: 2.3380687875089996

Epoch: 266| Step: 0
Training loss: 1.1903023029670783
Validation loss: 2.3548134356271957

Epoch: 5| Step: 1
Training loss: 1.6357891930046504
Validation loss: 2.3728389979618902

Epoch: 5| Step: 2
Training loss: 1.1390285031618017
Validation loss: 2.413967643764747

Epoch: 5| Step: 3
Training loss: 1.6334522946820562
Validation loss: 2.460812476322882

Epoch: 5| Step: 4
Training loss: 1.2867552482834432
Validation loss: 2.464372753602829

Epoch: 5| Step: 5
Training loss: 1.4819800078965073
Validation loss: 2.4411949148282432

Epoch: 5| Step: 6
Training loss: 1.7600943441463643
Validation loss: 2.4364810956446816

Epoch: 5| Step: 7
Training loss: 1.7285823141045762
Validation loss: 2.3946432281414745

Epoch: 5| Step: 8
Training loss: 1.66306658390273
Validation loss: 2.3497398441917516

Epoch: 5| Step: 9
Training loss: 1.1973052523901844
Validation loss: 2.328296000731982

Epoch: 5| Step: 10
Training loss: 1.9485892768241408
Validation loss: 2.3173363721156095

Epoch: 267| Step: 0
Training loss: 1.216245866319585
Validation loss: 2.3205606601252162

Epoch: 5| Step: 1
Training loss: 1.309146547986481
Validation loss: 2.331913301340553

Epoch: 5| Step: 2
Training loss: 1.857844708727351
Validation loss: 2.3614701322225162

Epoch: 5| Step: 3
Training loss: 1.3857064864201791
Validation loss: 2.390658147878188

Epoch: 5| Step: 4
Training loss: 1.4418845274849807
Validation loss: 2.435263117175171

Epoch: 5| Step: 5
Training loss: 1.8589907978521636
Validation loss: 2.4387002224447807

Epoch: 5| Step: 6
Training loss: 1.4099607886956218
Validation loss: 2.4126607014314554

Epoch: 5| Step: 7
Training loss: 1.6212530218727108
Validation loss: 2.35574802976984

Epoch: 5| Step: 8
Training loss: 1.5381709580916318
Validation loss: 2.341230830000036

Epoch: 5| Step: 9
Training loss: 1.4239639196539773
Validation loss: 2.3327978995012937

Epoch: 5| Step: 10
Training loss: 1.565484515376406
Validation loss: 2.309901781388144

Epoch: 268| Step: 0
Training loss: 1.3752468927844488
Validation loss: 2.304390941496546

Epoch: 5| Step: 1
Training loss: 1.679124888743625
Validation loss: 2.3153024923464707

Epoch: 5| Step: 2
Training loss: 1.4852448173654693
Validation loss: 2.3226902606436317

Epoch: 5| Step: 3
Training loss: 1.3538043442206578
Validation loss: 2.366840888008591

Epoch: 5| Step: 4
Training loss: 1.8008289123979866
Validation loss: 2.392566460653622

Epoch: 5| Step: 5
Training loss: 1.303937410835951
Validation loss: 2.4479384533696553

Epoch: 5| Step: 6
Training loss: 1.5133909296987214
Validation loss: 2.4648481973883865

Epoch: 5| Step: 7
Training loss: 1.798808376274261
Validation loss: 2.462355651963926

Epoch: 5| Step: 8
Training loss: 1.1383059716927366
Validation loss: 2.4467030651936663

Epoch: 5| Step: 9
Training loss: 1.680593982323765
Validation loss: 2.4332874351361102

Epoch: 5| Step: 10
Training loss: 1.2900250626872118
Validation loss: 2.4019819906172875

Epoch: 269| Step: 0
Training loss: 1.2506987526044133
Validation loss: 2.3826209238908023

Epoch: 5| Step: 1
Training loss: 1.401094267849206
Validation loss: 2.3798865752019336

Epoch: 5| Step: 2
Training loss: 1.3225317367466645
Validation loss: 2.361748113446237

Epoch: 5| Step: 3
Training loss: 1.1959966060724234
Validation loss: 2.3660249127109054

Epoch: 5| Step: 4
Training loss: 1.5240931738308194
Validation loss: 2.38847137286629

Epoch: 5| Step: 5
Training loss: 1.5086131761861783
Validation loss: 2.3693969556512404

Epoch: 5| Step: 6
Training loss: 1.3722653939246665
Validation loss: 2.393639154083877

Epoch: 5| Step: 7
Training loss: 1.6307116413017435
Validation loss: 2.3785695893315606

Epoch: 5| Step: 8
Training loss: 1.692857714199363
Validation loss: 2.366215727912138

Epoch: 5| Step: 9
Training loss: 1.6407884062271403
Validation loss: 2.3582224011859565

Epoch: 5| Step: 10
Training loss: 1.6498956965221971
Validation loss: 2.3542954457486864

Epoch: 270| Step: 0
Training loss: 1.3976785315778686
Validation loss: 2.3580678540442928

Epoch: 5| Step: 1
Training loss: 1.8403670099405351
Validation loss: 2.390299158841092

Epoch: 5| Step: 2
Training loss: 1.6905850361668024
Validation loss: 2.402468366481359

Epoch: 5| Step: 3
Training loss: 1.016447350552857
Validation loss: 2.4210510355390653

Epoch: 5| Step: 4
Training loss: 1.4129034951414576
Validation loss: 2.4260821739798204

Epoch: 5| Step: 5
Training loss: 1.4776088498937403
Validation loss: 2.454114589065146

Epoch: 5| Step: 6
Training loss: 1.2108539183289588
Validation loss: 2.437679479263355

Epoch: 5| Step: 7
Training loss: 1.1434075369170962
Validation loss: 2.4272580582762253

Epoch: 5| Step: 8
Training loss: 1.6848170533745421
Validation loss: 2.4268553611488493

Epoch: 5| Step: 9
Training loss: 1.5003239758622127
Validation loss: 2.397836287360561

Epoch: 5| Step: 10
Training loss: 1.4556817153357786
Validation loss: 2.3946442997849124

Epoch: 271| Step: 0
Training loss: 0.9322022478635932
Validation loss: 2.3857441958655126

Epoch: 5| Step: 1
Training loss: 1.616485738297855
Validation loss: 2.387953649414892

Epoch: 5| Step: 2
Training loss: 1.3507778558197534
Validation loss: 2.37857435215905

Epoch: 5| Step: 3
Training loss: 1.4193990760283133
Validation loss: 2.402593735157931

Epoch: 5| Step: 4
Training loss: 1.3442169974817941
Validation loss: 2.4119249700919996

Epoch: 5| Step: 5
Training loss: 1.63424240362168
Validation loss: 2.4183629457940583

Epoch: 5| Step: 6
Training loss: 1.4567389719205057
Validation loss: 2.4271818293567007

Epoch: 5| Step: 7
Training loss: 1.5578977326212387
Validation loss: 2.428849421456094

Epoch: 5| Step: 8
Training loss: 1.5909016906268916
Validation loss: 2.396544216102311

Epoch: 5| Step: 9
Training loss: 1.3399158602958712
Validation loss: 2.4035518174875268

Epoch: 5| Step: 10
Training loss: 1.4525245328266008
Validation loss: 2.3927869742516616

Epoch: 272| Step: 0
Training loss: 1.2441326721991208
Validation loss: 2.366557957531164

Epoch: 5| Step: 1
Training loss: 1.0586199317312628
Validation loss: 2.388324193631347

Epoch: 5| Step: 2
Training loss: 1.519962043790235
Validation loss: 2.373268286249275

Epoch: 5| Step: 3
Training loss: 1.7173048706484972
Validation loss: 2.3632273206233156

Epoch: 5| Step: 4
Training loss: 1.6114342117065925
Validation loss: 2.3736271865593404

Epoch: 5| Step: 5
Training loss: 1.121124692483214
Validation loss: 2.3776031642576956

Epoch: 5| Step: 6
Training loss: 1.4625687900895528
Validation loss: 2.3866361911198517

Epoch: 5| Step: 7
Training loss: 1.469397544152443
Validation loss: 2.3587737093797916

Epoch: 5| Step: 8
Training loss: 1.5946331195353962
Validation loss: 2.3744554861540363

Epoch: 5| Step: 9
Training loss: 1.0730812847673548
Validation loss: 2.367055950951871

Epoch: 5| Step: 10
Training loss: 1.4597046081677207
Validation loss: 2.358172970989013

Epoch: 273| Step: 0
Training loss: 1.3627620899907715
Validation loss: 2.3555837234579524

Epoch: 5| Step: 1
Training loss: 1.1903661972276418
Validation loss: 2.3758607312863513

Epoch: 5| Step: 2
Training loss: 1.4912322017250264
Validation loss: 2.4011886005760004

Epoch: 5| Step: 3
Training loss: 1.3475843327448018
Validation loss: 2.4248344543754237

Epoch: 5| Step: 4
Training loss: 1.1873856539635315
Validation loss: 2.423086160322927

Epoch: 5| Step: 5
Training loss: 1.0776978904463486
Validation loss: 2.4302559364294334

Epoch: 5| Step: 6
Training loss: 1.4431336346380768
Validation loss: 2.4212657404264126

Epoch: 5| Step: 7
Training loss: 1.5715732353057694
Validation loss: 2.4130170617124644

Epoch: 5| Step: 8
Training loss: 1.4987974909877215
Validation loss: 2.3888921138671386

Epoch: 5| Step: 9
Training loss: 1.8659967432310542
Validation loss: 2.3771507205387823

Epoch: 5| Step: 10
Training loss: 1.3120680961236966
Validation loss: 2.3922427775378563

Epoch: 274| Step: 0
Training loss: 1.4083234547752013
Validation loss: 2.406806765258192

Epoch: 5| Step: 1
Training loss: 1.4303875652715752
Validation loss: 2.4377949643732375

Epoch: 5| Step: 2
Training loss: 1.6829699712693438
Validation loss: 2.444921326017288

Epoch: 5| Step: 3
Training loss: 0.9681486293600788
Validation loss: 2.419096909347605

Epoch: 5| Step: 4
Training loss: 1.399708686901623
Validation loss: 2.3579617702174556

Epoch: 5| Step: 5
Training loss: 1.3526241564922983
Validation loss: 2.345026081490368

Epoch: 5| Step: 6
Training loss: 1.5481584407196218
Validation loss: 2.3316931169282658

Epoch: 5| Step: 7
Training loss: 1.3520080184924463
Validation loss: 2.3201657627211496

Epoch: 5| Step: 8
Training loss: 1.2933862478862659
Validation loss: 2.3512810221897227

Epoch: 5| Step: 9
Training loss: 1.022864843999424
Validation loss: 2.3706074926428258

Epoch: 5| Step: 10
Training loss: 1.8029957558047187
Validation loss: 2.412713447236123

Epoch: 275| Step: 0
Training loss: 1.6242713027973321
Validation loss: 2.431948303163967

Epoch: 5| Step: 1
Training loss: 1.257278613402276
Validation loss: 2.435221455580052

Epoch: 5| Step: 2
Training loss: 1.5745703065644072
Validation loss: 2.4438395331641756

Epoch: 5| Step: 3
Training loss: 1.5813576100036806
Validation loss: 2.3908908156541293

Epoch: 5| Step: 4
Training loss: 1.496134705144801
Validation loss: 2.3452905723115824

Epoch: 5| Step: 5
Training loss: 1.358671378955462
Validation loss: 2.329858289265708

Epoch: 5| Step: 6
Training loss: 1.503625779193813
Validation loss: 2.3242887725443606

Epoch: 5| Step: 7
Training loss: 1.0375627291915637
Validation loss: 2.3171219614351446

Epoch: 5| Step: 8
Training loss: 1.4028507686841436
Validation loss: 2.3351565246369987

Epoch: 5| Step: 9
Training loss: 1.281010023764255
Validation loss: 2.3411996136186644

Epoch: 5| Step: 10
Training loss: 1.2605265840044524
Validation loss: 2.338758837346229

Epoch: 276| Step: 0
Training loss: 1.2584228930064894
Validation loss: 2.350359200171968

Epoch: 5| Step: 1
Training loss: 1.2028335119103444
Validation loss: 2.3428864975519086

Epoch: 5| Step: 2
Training loss: 1.2483501513578643
Validation loss: 2.3669770765003424

Epoch: 5| Step: 3
Training loss: 1.4153782745326144
Validation loss: 2.366714575960118

Epoch: 5| Step: 4
Training loss: 1.726306810045027
Validation loss: 2.358525036769852

Epoch: 5| Step: 5
Training loss: 1.220889731830614
Validation loss: 2.348025318083462

Epoch: 5| Step: 6
Training loss: 1.1660641862990277
Validation loss: 2.345614477455934

Epoch: 5| Step: 7
Training loss: 1.5900560092058076
Validation loss: 2.348644853312514

Epoch: 5| Step: 8
Training loss: 1.386552913581907
Validation loss: 2.360218310554196

Epoch: 5| Step: 9
Training loss: 1.2952781865966931
Validation loss: 2.399235711124065

Epoch: 5| Step: 10
Training loss: 1.5123879383283167
Validation loss: 2.4205103972501005

Epoch: 277| Step: 0
Training loss: 0.8241651978654826
Validation loss: 2.421231899824129

Epoch: 5| Step: 1
Training loss: 1.4432193755312508
Validation loss: 2.439654450684655

Epoch: 5| Step: 2
Training loss: 1.2182927863492292
Validation loss: 2.462134971775256

Epoch: 5| Step: 3
Training loss: 1.7036922105264842
Validation loss: 2.4735398986696606

Epoch: 5| Step: 4
Training loss: 1.3019388449292344
Validation loss: 2.4653007240119136

Epoch: 5| Step: 5
Training loss: 1.4486511435036182
Validation loss: 2.4619704941142517

Epoch: 5| Step: 6
Training loss: 1.3159959193198294
Validation loss: 2.4265695658626867

Epoch: 5| Step: 7
Training loss: 1.0547824393033358
Validation loss: 2.414845111269405

Epoch: 5| Step: 8
Training loss: 1.5702968615612
Validation loss: 2.3627955591964516

Epoch: 5| Step: 9
Training loss: 1.6087934313575043
Validation loss: 2.3700677144107374

Epoch: 5| Step: 10
Training loss: 1.2776962867034984
Validation loss: 2.33616928359262

Epoch: 278| Step: 0
Training loss: 1.4535418497050554
Validation loss: 2.3384406152475816

Epoch: 5| Step: 1
Training loss: 1.390760779449254
Validation loss: 2.366861856049858

Epoch: 5| Step: 2
Training loss: 1.2343250216253072
Validation loss: 2.383365099418639

Epoch: 5| Step: 3
Training loss: 1.5753515819929904
Validation loss: 2.4060584243605776

Epoch: 5| Step: 4
Training loss: 1.0795185647015708
Validation loss: 2.4380963376687848

Epoch: 5| Step: 5
Training loss: 1.2357978346432015
Validation loss: 2.4792224587870084

Epoch: 5| Step: 6
Training loss: 1.5517534336342795
Validation loss: 2.451385004798371

Epoch: 5| Step: 7
Training loss: 1.5219386625975933
Validation loss: 2.4054622119671274

Epoch: 5| Step: 8
Training loss: 1.020096077975394
Validation loss: 2.3826132876837316

Epoch: 5| Step: 9
Training loss: 1.4246376781617445
Validation loss: 2.3572996927735845

Epoch: 5| Step: 10
Training loss: 1.3327634259007262
Validation loss: 2.3614608692187944

Epoch: 279| Step: 0
Training loss: 1.1298293725039172
Validation loss: 2.367885928831431

Epoch: 5| Step: 1
Training loss: 1.787475748497835
Validation loss: 2.3941822988475234

Epoch: 5| Step: 2
Training loss: 1.419718269956823
Validation loss: 2.3993115013938544

Epoch: 5| Step: 3
Training loss: 1.404442070045724
Validation loss: 2.3996793928032476

Epoch: 5| Step: 4
Training loss: 1.1391912882017696
Validation loss: 2.42094159513156

Epoch: 5| Step: 5
Training loss: 1.3459123911042252
Validation loss: 2.4367886002882204

Epoch: 5| Step: 6
Training loss: 1.1231189472457828
Validation loss: 2.431695086610632

Epoch: 5| Step: 7
Training loss: 0.9012967265022346
Validation loss: 2.452881671852215

Epoch: 5| Step: 8
Training loss: 1.4632367487310158
Validation loss: 2.437297008003707

Epoch: 5| Step: 9
Training loss: 1.1030760843384084
Validation loss: 2.463104831268174

Epoch: 5| Step: 10
Training loss: 1.6622835778505207
Validation loss: 2.4513003103333175

Epoch: 280| Step: 0
Training loss: 1.4931534441813017
Validation loss: 2.4630991369534407

Epoch: 5| Step: 1
Training loss: 1.3885977037153965
Validation loss: 2.443615266167697

Epoch: 5| Step: 2
Training loss: 1.5656506625754356
Validation loss: 2.434775799831759

Epoch: 5| Step: 3
Training loss: 1.1248400892411934
Validation loss: 2.411435496956717

Epoch: 5| Step: 4
Training loss: 1.1661992783060262
Validation loss: 2.3989050549968236

Epoch: 5| Step: 5
Training loss: 1.2750219305807702
Validation loss: 2.3624421353016065

Epoch: 5| Step: 6
Training loss: 1.1876556896744892
Validation loss: 2.35370295977277

Epoch: 5| Step: 7
Training loss: 1.2464249986776144
Validation loss: 2.3416845166463136

Epoch: 5| Step: 8
Training loss: 1.5939526148636873
Validation loss: 2.3386262361820145

Epoch: 5| Step: 9
Training loss: 1.3012578509237742
Validation loss: 2.338677557186138

Epoch: 5| Step: 10
Training loss: 1.1400209159772734
Validation loss: 2.372459174031333

Epoch: 281| Step: 0
Training loss: 1.3611012602252828
Validation loss: 2.404323392036249

Epoch: 5| Step: 1
Training loss: 0.9876995862793295
Validation loss: 2.4472671565221193

Epoch: 5| Step: 2
Training loss: 1.0554541732944844
Validation loss: 2.4896994030078794

Epoch: 5| Step: 3
Training loss: 1.577778768800296
Validation loss: 2.499137755361212

Epoch: 5| Step: 4
Training loss: 1.5582574084684317
Validation loss: 2.431827236710735

Epoch: 5| Step: 5
Training loss: 1.0526864743349182
Validation loss: 2.358386100808622

Epoch: 5| Step: 6
Training loss: 1.4329526543578988
Validation loss: 2.330305682727587

Epoch: 5| Step: 7
Training loss: 1.1234544097519115
Validation loss: 2.333380429133925

Epoch: 5| Step: 8
Training loss: 1.6043011580067081
Validation loss: 2.343282716717861

Epoch: 5| Step: 9
Training loss: 1.496079566828577
Validation loss: 2.355468791358368

Epoch: 5| Step: 10
Training loss: 1.6303736528740398
Validation loss: 2.386436266708978

Epoch: 282| Step: 0
Training loss: 1.492106969767421
Validation loss: 2.432495002936634

Epoch: 5| Step: 1
Training loss: 1.1871449793114137
Validation loss: 2.4438949701837487

Epoch: 5| Step: 2
Training loss: 1.4540040013548141
Validation loss: 2.4498721313299705

Epoch: 5| Step: 3
Training loss: 1.494763372953203
Validation loss: 2.413644186987278

Epoch: 5| Step: 4
Training loss: 1.314109269805556
Validation loss: 2.381718017286442

Epoch: 5| Step: 5
Training loss: 0.8344313341761116
Validation loss: 2.3929134608203606

Epoch: 5| Step: 6
Training loss: 1.3194923336417794
Validation loss: 2.394595743471187

Epoch: 5| Step: 7
Training loss: 1.4865481881685068
Validation loss: 2.380010952150924

Epoch: 5| Step: 8
Training loss: 1.0774228670697792
Validation loss: 2.375526078512226

Epoch: 5| Step: 9
Training loss: 1.4796755636150685
Validation loss: 2.4088420802209223

Epoch: 5| Step: 10
Training loss: 1.2760733256662042
Validation loss: 2.4116420572651847

Epoch: 283| Step: 0
Training loss: 1.2211085264321084
Validation loss: 2.445838804225425

Epoch: 5| Step: 1
Training loss: 1.1919312867994853
Validation loss: 2.4440625817088146

Epoch: 5| Step: 2
Training loss: 1.1589051253298028
Validation loss: 2.418556733107725

Epoch: 5| Step: 3
Training loss: 1.3775182984481582
Validation loss: 2.4003183089692564

Epoch: 5| Step: 4
Training loss: 0.9527270002028851
Validation loss: 2.3983611850662996

Epoch: 5| Step: 5
Training loss: 1.3421697417784177
Validation loss: 2.4092432227512286

Epoch: 5| Step: 6
Training loss: 1.4669711114890298
Validation loss: 2.4249483305781383

Epoch: 5| Step: 7
Training loss: 1.6006250382512397
Validation loss: 2.4458248353014485

Epoch: 5| Step: 8
Training loss: 1.2298169059474813
Validation loss: 2.4500989107512274

Epoch: 5| Step: 9
Training loss: 1.4439772753155804
Validation loss: 2.44089480267455

Epoch: 5| Step: 10
Training loss: 1.1350161986518463
Validation loss: 2.440747807925176

Epoch: 284| Step: 0
Training loss: 0.9862786308938634
Validation loss: 2.411863121670535

Epoch: 5| Step: 1
Training loss: 1.1856017249300734
Validation loss: 2.3939874744216283

Epoch: 5| Step: 2
Training loss: 1.4273785566524
Validation loss: 2.3782517463141444

Epoch: 5| Step: 3
Training loss: 1.1151690088145922
Validation loss: 2.350295865257396

Epoch: 5| Step: 4
Training loss: 1.4410696075908753
Validation loss: 2.367423784735105

Epoch: 5| Step: 5
Training loss: 1.698018108060186
Validation loss: 2.3470323249607024

Epoch: 5| Step: 6
Training loss: 1.106655279372891
Validation loss: 2.3637136775784224

Epoch: 5| Step: 7
Training loss: 1.349839275117335
Validation loss: 2.386308193836789

Epoch: 5| Step: 8
Training loss: 0.9794314242957077
Validation loss: 2.4262869062180825

Epoch: 5| Step: 9
Training loss: 1.4688954382779429
Validation loss: 2.440481800572977

Epoch: 5| Step: 10
Training loss: 1.1092582426282918
Validation loss: 2.422653772723935

Epoch: 285| Step: 0
Training loss: 1.3673425640998609
Validation loss: 2.396952329160091

Epoch: 5| Step: 1
Training loss: 0.9965843039920802
Validation loss: 2.358998101819704

Epoch: 5| Step: 2
Training loss: 1.0566070607719351
Validation loss: 2.3234806716078893

Epoch: 5| Step: 3
Training loss: 1.4835694385884908
Validation loss: 2.3318604616162752

Epoch: 5| Step: 4
Training loss: 1.1222786307452646
Validation loss: 2.359996596150197

Epoch: 5| Step: 5
Training loss: 1.0404093338465183
Validation loss: 2.380339224804759

Epoch: 5| Step: 6
Training loss: 1.0773044725634553
Validation loss: 2.4231799856868785

Epoch: 5| Step: 7
Training loss: 1.3866019616176277
Validation loss: 2.4246918333097724

Epoch: 5| Step: 8
Training loss: 1.4867964419072197
Validation loss: 2.430169147905021

Epoch: 5| Step: 9
Training loss: 1.3881895620007783
Validation loss: 2.418555310603676

Epoch: 5| Step: 10
Training loss: 1.502602862044043
Validation loss: 2.40275160245927

Epoch: 286| Step: 0
Training loss: 1.0906542973559232
Validation loss: 2.376957704479308

Epoch: 5| Step: 1
Training loss: 1.191553825869078
Validation loss: 2.3684170621371656

Epoch: 5| Step: 2
Training loss: 0.9726723665794225
Validation loss: 2.3737584297620473

Epoch: 5| Step: 3
Training loss: 1.039624628585927
Validation loss: 2.3776373972372826

Epoch: 5| Step: 4
Training loss: 1.0640573308205767
Validation loss: 2.379109571134695

Epoch: 5| Step: 5
Training loss: 1.5519818095684772
Validation loss: 2.3701308552080094

Epoch: 5| Step: 6
Training loss: 1.4250507312243696
Validation loss: 2.3811540464103444

Epoch: 5| Step: 7
Training loss: 0.9297986324789289
Validation loss: 2.397488740060121

Epoch: 5| Step: 8
Training loss: 1.3159236759210655
Validation loss: 2.408703551812225

Epoch: 5| Step: 9
Training loss: 1.6161194743757477
Validation loss: 2.428729654548572

Epoch: 5| Step: 10
Training loss: 1.3905642635497673
Validation loss: 2.4267565828435256

Epoch: 287| Step: 0
Training loss: 1.5633733978641482
Validation loss: 2.440634128996281

Epoch: 5| Step: 1
Training loss: 1.141143106340951
Validation loss: 2.43760537571043

Epoch: 5| Step: 2
Training loss: 1.30446645725883
Validation loss: 2.454232486258887

Epoch: 5| Step: 3
Training loss: 1.493675648263359
Validation loss: 2.416501849717224

Epoch: 5| Step: 4
Training loss: 1.0446710303283808
Validation loss: 2.402641619805529

Epoch: 5| Step: 5
Training loss: 0.9091476942880606
Validation loss: 2.3513404077118514

Epoch: 5| Step: 6
Training loss: 1.2204033811676789
Validation loss: 2.3463611826434914

Epoch: 5| Step: 7
Training loss: 1.1945874876427551
Validation loss: 2.352399623696601

Epoch: 5| Step: 8
Training loss: 1.1324300186059157
Validation loss: 2.355312159835741

Epoch: 5| Step: 9
Training loss: 1.141864155768488
Validation loss: 2.3750595388629705

Epoch: 5| Step: 10
Training loss: 1.5934661911728434
Validation loss: 2.386834440412653

Epoch: 288| Step: 0
Training loss: 1.299783501570627
Validation loss: 2.4070526998105706

Epoch: 5| Step: 1
Training loss: 1.2661660533165577
Validation loss: 2.3960457681332357

Epoch: 5| Step: 2
Training loss: 1.184420356787862
Validation loss: 2.420601169537116

Epoch: 5| Step: 3
Training loss: 1.2319574947208318
Validation loss: 2.433804026143399

Epoch: 5| Step: 4
Training loss: 1.3615184415562254
Validation loss: 2.4093767192120428

Epoch: 5| Step: 5
Training loss: 1.397290318681188
Validation loss: 2.3870559002312737

Epoch: 5| Step: 6
Training loss: 0.9589592644847653
Validation loss: 2.363412509094525

Epoch: 5| Step: 7
Training loss: 1.2122973282524434
Validation loss: 2.375902018643746

Epoch: 5| Step: 8
Training loss: 1.2224157907389768
Validation loss: 2.365898791151935

Epoch: 5| Step: 9
Training loss: 1.4298180692490647
Validation loss: 2.359134015524122

Epoch: 5| Step: 10
Training loss: 0.8410680673906378
Validation loss: 2.3547534158790144

Epoch: 289| Step: 0
Training loss: 1.3868074630514486
Validation loss: 2.3411440372899306

Epoch: 5| Step: 1
Training loss: 1.0459260197839444
Validation loss: 2.3970141628503963

Epoch: 5| Step: 2
Training loss: 1.1672775111286755
Validation loss: 2.4135359583357467

Epoch: 5| Step: 3
Training loss: 1.302354519896207
Validation loss: 2.4381696245608606

Epoch: 5| Step: 4
Training loss: 1.4276784319687128
Validation loss: 2.4679433871234773

Epoch: 5| Step: 5
Training loss: 1.227272362821377
Validation loss: 2.473087777731683

Epoch: 5| Step: 6
Training loss: 0.8941406996607385
Validation loss: 2.4401587627914725

Epoch: 5| Step: 7
Training loss: 1.0984477925801899
Validation loss: 2.38376665328945

Epoch: 5| Step: 8
Training loss: 1.5420817082844978
Validation loss: 2.372289934004716

Epoch: 5| Step: 9
Training loss: 1.0358178669477367
Validation loss: 2.3581975584805557

Epoch: 5| Step: 10
Training loss: 1.4001691528720228
Validation loss: 2.344723631734798

Epoch: 290| Step: 0
Training loss: 1.3571660301553354
Validation loss: 2.3407283553405422

Epoch: 5| Step: 1
Training loss: 0.9166584484136533
Validation loss: 2.3865847058446836

Epoch: 5| Step: 2
Training loss: 1.1941981887295106
Validation loss: 2.40060109273013

Epoch: 5| Step: 3
Training loss: 1.16118999625932
Validation loss: 2.407753818475089

Epoch: 5| Step: 4
Training loss: 1.2498786867401903
Validation loss: 2.404969293142796

Epoch: 5| Step: 5
Training loss: 1.278251162320494
Validation loss: 2.3699604650882677

Epoch: 5| Step: 6
Training loss: 1.4060631521918423
Validation loss: 2.376619686940162

Epoch: 5| Step: 7
Training loss: 1.399118864838212
Validation loss: 2.3526769571502792

Epoch: 5| Step: 8
Training loss: 1.2499009093109394
Validation loss: 2.321651433303112

Epoch: 5| Step: 9
Training loss: 1.1251783229642438
Validation loss: 2.3260796484406323

Epoch: 5| Step: 10
Training loss: 1.1286957224387906
Validation loss: 2.3026538172266435

Epoch: 291| Step: 0
Training loss: 1.2668668047165177
Validation loss: 2.325222990713149

Epoch: 5| Step: 1
Training loss: 1.0297527425701223
Validation loss: 2.352432285808644

Epoch: 5| Step: 2
Training loss: 1.3332146452689069
Validation loss: 2.405039543162932

Epoch: 5| Step: 3
Training loss: 1.4363797010219173
Validation loss: 2.422698136094037

Epoch: 5| Step: 4
Training loss: 1.2849319865265572
Validation loss: 2.4706949755519525

Epoch: 5| Step: 5
Training loss: 1.4188339074147593
Validation loss: 2.477735559450029

Epoch: 5| Step: 6
Training loss: 1.0581962148694937
Validation loss: 2.491543179186531

Epoch: 5| Step: 7
Training loss: 1.3373882157859796
Validation loss: 2.5108783535493284

Epoch: 5| Step: 8
Training loss: 1.3456310590651015
Validation loss: 2.4499850384010737

Epoch: 5| Step: 9
Training loss: 1.1051339225395906
Validation loss: 2.405673168450382

Epoch: 5| Step: 10
Training loss: 0.6748479892732695
Validation loss: 2.3328367857107843

Epoch: 292| Step: 0
Training loss: 1.4737698419867529
Validation loss: 2.334609893979046

Epoch: 5| Step: 1
Training loss: 1.3021162359531036
Validation loss: 2.3198875628411697

Epoch: 5| Step: 2
Training loss: 1.3258332619386306
Validation loss: 2.3246951575864188

Epoch: 5| Step: 3
Training loss: 1.047162429295447
Validation loss: 2.325456212660843

Epoch: 5| Step: 4
Training loss: 1.3989935254375943
Validation loss: 2.366066957876452

Epoch: 5| Step: 5
Training loss: 1.1894901063178096
Validation loss: 2.415252122692435

Epoch: 5| Step: 6
Training loss: 0.7543765562811019
Validation loss: 2.426060093607917

Epoch: 5| Step: 7
Training loss: 1.3130666327089398
Validation loss: 2.428264396220991

Epoch: 5| Step: 8
Training loss: 1.2879151758197476
Validation loss: 2.385496917791879

Epoch: 5| Step: 9
Training loss: 1.135461958002281
Validation loss: 2.363293356115687

Epoch: 5| Step: 10
Training loss: 1.2423068774939034
Validation loss: 2.3439529210780923

Epoch: 293| Step: 0
Training loss: 1.6805388666100196
Validation loss: 2.3432880435834487

Epoch: 5| Step: 1
Training loss: 0.8667117695504102
Validation loss: 2.3861148924862094

Epoch: 5| Step: 2
Training loss: 0.9659499649334554
Validation loss: 2.375375785415485

Epoch: 5| Step: 3
Training loss: 1.312783800958746
Validation loss: 2.3787545016122564

Epoch: 5| Step: 4
Training loss: 1.497399460055617
Validation loss: 2.414407648813035

Epoch: 5| Step: 5
Training loss: 1.2657701385541513
Validation loss: 2.3976620062449214

Epoch: 5| Step: 6
Training loss: 1.3028081732897925
Validation loss: 2.432094013558799

Epoch: 5| Step: 7
Training loss: 1.0148235973915032
Validation loss: 2.440505524158498

Epoch: 5| Step: 8
Training loss: 0.841724684733119
Validation loss: 2.4300586628100693

Epoch: 5| Step: 9
Training loss: 1.0634423732954177
Validation loss: 2.4548958350866386

Epoch: 5| Step: 10
Training loss: 1.0643132949119152
Validation loss: 2.4121549664040187

Epoch: 294| Step: 0
Training loss: 0.6759210783665096
Validation loss: 2.396557845415819

Epoch: 5| Step: 1
Training loss: 1.136294046351903
Validation loss: 2.3662434311796554

Epoch: 5| Step: 2
Training loss: 0.9971974261013099
Validation loss: 2.3766285828964095

Epoch: 5| Step: 3
Training loss: 1.2845218565207273
Validation loss: 2.385681164189479

Epoch: 5| Step: 4
Training loss: 1.2169217800245504
Validation loss: 2.408389761251938

Epoch: 5| Step: 5
Training loss: 1.2921071942063806
Validation loss: 2.3893949553410834

Epoch: 5| Step: 6
Training loss: 1.2607494209253425
Validation loss: 2.3778067898059345

Epoch: 5| Step: 7
Training loss: 1.2740759156124062
Validation loss: 2.366425547982899

Epoch: 5| Step: 8
Training loss: 1.4468173054671312
Validation loss: 2.3709606173756166

Epoch: 5| Step: 9
Training loss: 0.8527624792272367
Validation loss: 2.3386253098789003

Epoch: 5| Step: 10
Training loss: 1.349477758766342
Validation loss: 2.342904123779162

Epoch: 295| Step: 0
Training loss: 1.029791523102947
Validation loss: 2.367666687615899

Epoch: 5| Step: 1
Training loss: 1.1143473021723092
Validation loss: 2.3801966135736325

Epoch: 5| Step: 2
Training loss: 1.237800914129455
Validation loss: 2.4224700482530084

Epoch: 5| Step: 3
Training loss: 1.153494412349533
Validation loss: 2.412166184242161

Epoch: 5| Step: 4
Training loss: 1.1136623867865718
Validation loss: 2.4107661212653073

Epoch: 5| Step: 5
Training loss: 0.7100226416134198
Validation loss: 2.42483545981385

Epoch: 5| Step: 6
Training loss: 1.1845542611011879
Validation loss: 2.3867518597555843

Epoch: 5| Step: 7
Training loss: 1.079898702056441
Validation loss: 2.385892661941151

Epoch: 5| Step: 8
Training loss: 1.500018914421357
Validation loss: 2.3974445469856143

Epoch: 5| Step: 9
Training loss: 1.426104365276185
Validation loss: 2.3990538318502033

Epoch: 5| Step: 10
Training loss: 1.116485962314397
Validation loss: 2.4141498054349038

Epoch: 296| Step: 0
Training loss: 1.554495027982626
Validation loss: 2.430660292970974

Epoch: 5| Step: 1
Training loss: 1.1975625993776278
Validation loss: 2.473682658061998

Epoch: 5| Step: 2
Training loss: 1.3967781238117665
Validation loss: 2.5001848090989016

Epoch: 5| Step: 3
Training loss: 1.0652386767724036
Validation loss: 2.473713229634123

Epoch: 5| Step: 4
Training loss: 1.1187623667965823
Validation loss: 2.414719158273979

Epoch: 5| Step: 5
Training loss: 1.193147631151311
Validation loss: 2.377883338548114

Epoch: 5| Step: 6
Training loss: 1.0436457461982678
Validation loss: 2.3409956215986174

Epoch: 5| Step: 7
Training loss: 0.8434872394720389
Validation loss: 2.3234338444462557

Epoch: 5| Step: 8
Training loss: 1.0914602016474972
Validation loss: 2.3295072317528995

Epoch: 5| Step: 9
Training loss: 1.1801423970473457
Validation loss: 2.3591066449759315

Epoch: 5| Step: 10
Training loss: 1.2511111565993236
Validation loss: 2.4068515165850846

Epoch: 297| Step: 0
Training loss: 1.1502668382141397
Validation loss: 2.4400617244470717

Epoch: 5| Step: 1
Training loss: 1.3191972344801528
Validation loss: 2.43030027073359

Epoch: 5| Step: 2
Training loss: 0.9988807136258618
Validation loss: 2.4324088839881504

Epoch: 5| Step: 3
Training loss: 1.2420228093213552
Validation loss: 2.4596612374001885

Epoch: 5| Step: 4
Training loss: 1.3077125884874092
Validation loss: 2.4168579342703547

Epoch: 5| Step: 5
Training loss: 1.2962353519211665
Validation loss: 2.4121076022138257

Epoch: 5| Step: 6
Training loss: 1.3488203245678143
Validation loss: 2.407761904124937

Epoch: 5| Step: 7
Training loss: 1.0160944513925345
Validation loss: 2.3982655351761144

Epoch: 5| Step: 8
Training loss: 0.9401141595001156
Validation loss: 2.3953258246170868

Epoch: 5| Step: 9
Training loss: 0.8347561412195794
Validation loss: 2.409395605608084

Epoch: 5| Step: 10
Training loss: 1.2004506000267372
Validation loss: 2.403775075298628

Epoch: 298| Step: 0
Training loss: 1.0819406299308902
Validation loss: 2.3837374382970657

Epoch: 5| Step: 1
Training loss: 1.4381806793773944
Validation loss: 2.377764785114904

Epoch: 5| Step: 2
Training loss: 0.8458073223668416
Validation loss: 2.3811167266191844

Epoch: 5| Step: 3
Training loss: 1.2791566262280853
Validation loss: 2.3682689673028934

Epoch: 5| Step: 4
Training loss: 0.9260238780203669
Validation loss: 2.3661967455153134

Epoch: 5| Step: 5
Training loss: 0.81700564926697
Validation loss: 2.370277431986613

Epoch: 5| Step: 6
Training loss: 1.3233856911634998
Validation loss: 2.385180779287266

Epoch: 5| Step: 7
Training loss: 0.9676912120759473
Validation loss: 2.3862780591819024

Epoch: 5| Step: 8
Training loss: 1.288205410938362
Validation loss: 2.4198110645237767

Epoch: 5| Step: 9
Training loss: 1.1464491258755554
Validation loss: 2.4134367002150525

Epoch: 5| Step: 10
Training loss: 1.353015008909401
Validation loss: 2.435802212360511

Epoch: 299| Step: 0
Training loss: 1.3831173835472288
Validation loss: 2.4616503965409566

Epoch: 5| Step: 1
Training loss: 1.1173685100608912
Validation loss: 2.4797692197862333

Epoch: 5| Step: 2
Training loss: 1.1076213246663278
Validation loss: 2.472673885840687

Epoch: 5| Step: 3
Training loss: 0.8956844109943849
Validation loss: 2.471803489957357

Epoch: 5| Step: 4
Training loss: 1.2565645934236664
Validation loss: 2.4517121754334874

Epoch: 5| Step: 5
Training loss: 1.1846507171740748
Validation loss: 2.4413349609467474

Epoch: 5| Step: 6
Training loss: 1.094847156099618
Validation loss: 2.4360444871810842

Epoch: 5| Step: 7
Training loss: 0.7282788912185154
Validation loss: 2.37253686240271

Epoch: 5| Step: 8
Training loss: 1.0756738413794185
Validation loss: 2.3773751997662846

Epoch: 5| Step: 9
Training loss: 1.3126609340275834
Validation loss: 2.3258199706192495

Epoch: 5| Step: 10
Training loss: 1.0584526953382176
Validation loss: 2.3203160886107344

Epoch: 300| Step: 0
Training loss: 0.9052050255004239
Validation loss: 2.3181066484423023

Epoch: 5| Step: 1
Training loss: 0.8895134263336032
Validation loss: 2.3209418472946552

Epoch: 5| Step: 2
Training loss: 1.269635287203458
Validation loss: 2.3151237693392366

Epoch: 5| Step: 3
Training loss: 1.2396303162633389
Validation loss: 2.3313637252842416

Epoch: 5| Step: 4
Training loss: 1.1604786434550545
Validation loss: 2.3399188679330156

Epoch: 5| Step: 5
Training loss: 1.135251176071986
Validation loss: 2.3506484869942184

Epoch: 5| Step: 6
Training loss: 1.3504360113001097
Validation loss: 2.3891799482072438

Epoch: 5| Step: 7
Training loss: 1.2465071037417517
Validation loss: 2.4166527278471293

Epoch: 5| Step: 8
Training loss: 1.2509317739957437
Validation loss: 2.454162622229047

Epoch: 5| Step: 9
Training loss: 0.8768681270468681
Validation loss: 2.4692705570566718

Epoch: 5| Step: 10
Training loss: 0.8632984073366612
Validation loss: 2.4651455894370495

Epoch: 301| Step: 0
Training loss: 1.1430444531978576
Validation loss: 2.4685298010975236

Epoch: 5| Step: 1
Training loss: 1.2438614320916852
Validation loss: 2.424993062683372

Epoch: 5| Step: 2
Training loss: 0.8043236511723786
Validation loss: 2.401293785228678

Epoch: 5| Step: 3
Training loss: 0.5700239470537772
Validation loss: 2.376125297404042

Epoch: 5| Step: 4
Training loss: 1.3545569615460082
Validation loss: 2.3544480426702914

Epoch: 5| Step: 5
Training loss: 1.1876886117624148
Validation loss: 2.3282711646344363

Epoch: 5| Step: 6
Training loss: 0.5708204124083562
Validation loss: 2.340350223325231

Epoch: 5| Step: 7
Training loss: 1.275422404011622
Validation loss: 2.3369646389464203

Epoch: 5| Step: 8
Training loss: 1.3141514062005506
Validation loss: 2.333746137082112

Epoch: 5| Step: 9
Training loss: 1.0004482456759074
Validation loss: 2.35213006085977

Epoch: 5| Step: 10
Training loss: 1.4991817626843342
Validation loss: 2.3849097479588037

Epoch: 302| Step: 0
Training loss: 1.1153057229222807
Validation loss: 2.3840674183757176

Epoch: 5| Step: 1
Training loss: 1.4043823555726984
Validation loss: 2.3626410562057814

Epoch: 5| Step: 2
Training loss: 0.9660581907156607
Validation loss: 2.3579799790315787

Epoch: 5| Step: 3
Training loss: 1.0630343720270008
Validation loss: 2.3248968566164003

Epoch: 5| Step: 4
Training loss: 1.274492259933297
Validation loss: 2.336633604665784

Epoch: 5| Step: 5
Training loss: 1.0809154610373592
Validation loss: 2.329913577762913

Epoch: 5| Step: 6
Training loss: 0.5533234655072952
Validation loss: 2.338554830838633

Epoch: 5| Step: 7
Training loss: 1.0118359236449748
Validation loss: 2.3087440204312517

Epoch: 5| Step: 8
Training loss: 0.9056670188238559
Validation loss: 2.3547209939093925

Epoch: 5| Step: 9
Training loss: 1.1900519005492898
Validation loss: 2.3619005756581255

Epoch: 5| Step: 10
Training loss: 1.3726387991146025
Validation loss: 2.362163682793971

Epoch: 303| Step: 0
Training loss: 0.8130210159630644
Validation loss: 2.366489814018434

Epoch: 5| Step: 1
Training loss: 0.9142535735392444
Validation loss: 2.4160273310563194

Epoch: 5| Step: 2
Training loss: 1.1332737476916295
Validation loss: 2.3915669451911805

Epoch: 5| Step: 3
Training loss: 1.015087748525728
Validation loss: 2.378639914167035

Epoch: 5| Step: 4
Training loss: 1.1451656419137533
Validation loss: 2.3441814602460527

Epoch: 5| Step: 5
Training loss: 1.1897916265180515
Validation loss: 2.344378364581504

Epoch: 5| Step: 6
Training loss: 1.0823621553750775
Validation loss: 2.3170468158654125

Epoch: 5| Step: 7
Training loss: 1.3128557177292335
Validation loss: 2.3112503861545153

Epoch: 5| Step: 8
Training loss: 1.185968566005148
Validation loss: 2.3374741577453673

Epoch: 5| Step: 9
Training loss: 1.0558323051208773
Validation loss: 2.3817428342421527

Epoch: 5| Step: 10
Training loss: 1.2461388558860962
Validation loss: 2.427960857511367

Epoch: 304| Step: 0
Training loss: 1.058708381780643
Validation loss: 2.4349003968397045

Epoch: 5| Step: 1
Training loss: 1.349764250551312
Validation loss: 2.405952165632508

Epoch: 5| Step: 2
Training loss: 0.9709623056023361
Validation loss: 2.362714043673323

Epoch: 5| Step: 3
Training loss: 1.1690037457003926
Validation loss: 2.312874479606174

Epoch: 5| Step: 4
Training loss: 0.7962894532326925
Validation loss: 2.284929553253921

Epoch: 5| Step: 5
Training loss: 1.3117080297253545
Validation loss: 2.2824557887018675

Epoch: 5| Step: 6
Training loss: 1.094049794118672
Validation loss: 2.273097101411545

Epoch: 5| Step: 7
Training loss: 1.1322295168630325
Validation loss: 2.2607224464905635

Epoch: 5| Step: 8
Training loss: 1.352460573859249
Validation loss: 2.2715548121541214

Epoch: 5| Step: 9
Training loss: 0.8933276946034563
Validation loss: 2.304478283523454

Epoch: 5| Step: 10
Training loss: 0.8062127481770436
Validation loss: 2.3361114690688827

Epoch: 305| Step: 0
Training loss: 1.0444888920209323
Validation loss: 2.3371022014749805

Epoch: 5| Step: 1
Training loss: 1.0495401874279255
Validation loss: 2.393489481551303

Epoch: 5| Step: 2
Training loss: 1.0329231791555775
Validation loss: 2.3731441500653334

Epoch: 5| Step: 3
Training loss: 1.2529550908071159
Validation loss: 2.332892924231447

Epoch: 5| Step: 4
Training loss: 0.8231925180097018
Validation loss: 2.3403464720941956

Epoch: 5| Step: 5
Training loss: 1.2018222443760251
Validation loss: 2.341257569673037

Epoch: 5| Step: 6
Training loss: 1.381716795189508
Validation loss: 2.335894621130626

Epoch: 5| Step: 7
Training loss: 1.1607082607825554
Validation loss: 2.337914240427211

Epoch: 5| Step: 8
Training loss: 1.0568724429090033
Validation loss: 2.344682813847368

Epoch: 5| Step: 9
Training loss: 0.8525313019808943
Validation loss: 2.35258590640775

Epoch: 5| Step: 10
Training loss: 1.026555676488393
Validation loss: 2.3801486947430996

Epoch: 306| Step: 0
Training loss: 1.0104318925686968
Validation loss: 2.382645329031589

Epoch: 5| Step: 1
Training loss: 0.7718609241020695
Validation loss: 2.4044841982844103

Epoch: 5| Step: 2
Training loss: 1.3292753286798604
Validation loss: 2.38425674929059

Epoch: 5| Step: 3
Training loss: 0.9420245660749427
Validation loss: 2.3970024035131487

Epoch: 5| Step: 4
Training loss: 1.1571511545842506
Validation loss: 2.378844986669659

Epoch: 5| Step: 5
Training loss: 0.9302688832384781
Validation loss: 2.3692974979421506

Epoch: 5| Step: 6
Training loss: 1.0424997368132993
Validation loss: 2.364043751315797

Epoch: 5| Step: 7
Training loss: 1.129407619560456
Validation loss: 2.3523174111608895

Epoch: 5| Step: 8
Training loss: 1.0156728879936066
Validation loss: 2.3833240720398434

Epoch: 5| Step: 9
Training loss: 1.2266385000215456
Validation loss: 2.4126175709973046

Epoch: 5| Step: 10
Training loss: 1.1200243804185397
Validation loss: 2.445330436834972

Epoch: 307| Step: 0
Training loss: 1.069544049918556
Validation loss: 2.44483371065122

Epoch: 5| Step: 1
Training loss: 1.2244834530959667
Validation loss: 2.4566568783636185

Epoch: 5| Step: 2
Training loss: 1.0720235693817262
Validation loss: 2.4844922774383047

Epoch: 5| Step: 3
Training loss: 1.0900488219570157
Validation loss: 2.461923741551445

Epoch: 5| Step: 4
Training loss: 0.991109517738984
Validation loss: 2.4450431087456588

Epoch: 5| Step: 5
Training loss: 1.4505775025105674
Validation loss: 2.406434337478685

Epoch: 5| Step: 6
Training loss: 0.8551072702542428
Validation loss: 2.4442638151102685

Epoch: 5| Step: 7
Training loss: 1.1123060807511578
Validation loss: 2.4250424084403157

Epoch: 5| Step: 8
Training loss: 0.5940171193022465
Validation loss: 2.404367307801868

Epoch: 5| Step: 9
Training loss: 0.7172630104089585
Validation loss: 2.382271242926957

Epoch: 5| Step: 10
Training loss: 1.2053198672389167
Validation loss: 2.342653576200158

Epoch: 308| Step: 0
Training loss: 1.156467365762664
Validation loss: 2.3541464914090264

Epoch: 5| Step: 1
Training loss: 0.778896831428723
Validation loss: 2.3365619683639185

Epoch: 5| Step: 2
Training loss: 1.0376571674110229
Validation loss: 2.3458126461575692

Epoch: 5| Step: 3
Training loss: 1.198467951540656
Validation loss: 2.3668600612876785

Epoch: 5| Step: 4
Training loss: 1.332402644582006
Validation loss: 2.3667867554084494

Epoch: 5| Step: 5
Training loss: 1.109836374972884
Validation loss: 2.3653332237334332

Epoch: 5| Step: 6
Training loss: 1.0067704010140401
Validation loss: 2.361697827848004

Epoch: 5| Step: 7
Training loss: 1.160841562817484
Validation loss: 2.3942770341640216

Epoch: 5| Step: 8
Training loss: 0.6534352564944225
Validation loss: 2.4107414254929163

Epoch: 5| Step: 9
Training loss: 1.0194039100836925
Validation loss: 2.433795269652444

Epoch: 5| Step: 10
Training loss: 0.9885037439359348
Validation loss: 2.4607359465557184

Epoch: 309| Step: 0
Training loss: 0.6795278120447319
Validation loss: 2.4616361601291272

Epoch: 5| Step: 1
Training loss: 1.054944212012502
Validation loss: 2.4506715913834216

Epoch: 5| Step: 2
Training loss: 1.070244000324273
Validation loss: 2.463729379493687

Epoch: 5| Step: 3
Training loss: 1.106524175946068
Validation loss: 2.4572102223449797

Epoch: 5| Step: 4
Training loss: 1.1019373046431715
Validation loss: 2.4427378086601683

Epoch: 5| Step: 5
Training loss: 0.8250777843681609
Validation loss: 2.4246509538240106

Epoch: 5| Step: 6
Training loss: 1.1252332551528559
Validation loss: 2.399314501712237

Epoch: 5| Step: 7
Training loss: 1.108578785747587
Validation loss: 2.3956049535188533

Epoch: 5| Step: 8
Training loss: 1.3352154570744783
Validation loss: 2.388021209430847

Epoch: 5| Step: 9
Training loss: 1.1524508151732258
Validation loss: 2.3870422188124

Epoch: 5| Step: 10
Training loss: 0.6613939409126672
Validation loss: 2.423325917042935

Epoch: 310| Step: 0
Training loss: 0.9157152150988724
Validation loss: 2.4120777431122953

Epoch: 5| Step: 1
Training loss: 1.1669944348173968
Validation loss: 2.3793052657824356

Epoch: 5| Step: 2
Training loss: 1.1105049718464692
Validation loss: 2.365652491972932

Epoch: 5| Step: 3
Training loss: 1.1729394782893166
Validation loss: 2.335539924419382

Epoch: 5| Step: 4
Training loss: 1.0925445453282951
Validation loss: 2.3325049842457912

Epoch: 5| Step: 5
Training loss: 0.8817524580027598
Validation loss: 2.336979569012975

Epoch: 5| Step: 6
Training loss: 1.0584796689206801
Validation loss: 2.344949385051307

Epoch: 5| Step: 7
Training loss: 0.5543468396368298
Validation loss: 2.384609185870583

Epoch: 5| Step: 8
Training loss: 0.8419313611009316
Validation loss: 2.411143138776681

Epoch: 5| Step: 9
Training loss: 1.1654599397599656
Validation loss: 2.3653021200563202

Epoch: 5| Step: 10
Training loss: 1.31010327172348
Validation loss: 2.3708511582263236

Epoch: 311| Step: 0
Training loss: 1.0788004873756267
Validation loss: 2.3859993906706185

Epoch: 5| Step: 1
Training loss: 0.6495045534345782
Validation loss: 2.3782390965166984

Epoch: 5| Step: 2
Training loss: 0.975961912486824
Validation loss: 2.3788310985291976

Epoch: 5| Step: 3
Training loss: 1.0760016055680106
Validation loss: 2.3812844048476975

Epoch: 5| Step: 4
Training loss: 1.0954737023592716
Validation loss: 2.423637491383054

Epoch: 5| Step: 5
Training loss: 1.1742296595266501
Validation loss: 2.4348200692091773

Epoch: 5| Step: 6
Training loss: 1.3623351391085823
Validation loss: 2.4739834740251307

Epoch: 5| Step: 7
Training loss: 0.7329833459874754
Validation loss: 2.442138889567369

Epoch: 5| Step: 8
Training loss: 0.920793642652988
Validation loss: 2.432360916081179

Epoch: 5| Step: 9
Training loss: 1.1280576691123285
Validation loss: 2.3666086424919235

Epoch: 5| Step: 10
Training loss: 0.8989805156200256
Validation loss: 2.361877204944723

Epoch: 312| Step: 0
Training loss: 1.0010184823539274
Validation loss: 2.3255619548449844

Epoch: 5| Step: 1
Training loss: 0.6494258793494324
Validation loss: 2.3349670595901872

Epoch: 5| Step: 2
Training loss: 0.9040273837440335
Validation loss: 2.3396799199755036

Epoch: 5| Step: 3
Training loss: 1.1091694171239932
Validation loss: 2.365912341822943

Epoch: 5| Step: 4
Training loss: 1.2043211799319475
Validation loss: 2.3481404769477234

Epoch: 5| Step: 5
Training loss: 1.0627178081086839
Validation loss: 2.3927689049613186

Epoch: 5| Step: 6
Training loss: 0.9640030692653152
Validation loss: 2.3859839647204995

Epoch: 5| Step: 7
Training loss: 1.0804333507947834
Validation loss: 2.3725305438882054

Epoch: 5| Step: 8
Training loss: 1.237222501679265
Validation loss: 2.3275906718453587

Epoch: 5| Step: 9
Training loss: 0.9062187584063041
Validation loss: 2.3501205681334563

Epoch: 5| Step: 10
Training loss: 0.9973919356280762
Validation loss: 2.3589356943888866

Epoch: 313| Step: 0
Training loss: 1.0066148605868688
Validation loss: 2.3850365501694224

Epoch: 5| Step: 1
Training loss: 0.9855835776614321
Validation loss: 2.421258348919444

Epoch: 5| Step: 2
Training loss: 0.8123108203433543
Validation loss: 2.428410195698162

Epoch: 5| Step: 3
Training loss: 1.349046161792145
Validation loss: 2.4334681073954916

Epoch: 5| Step: 4
Training loss: 1.033531093644575
Validation loss: 2.454529888191001

Epoch: 5| Step: 5
Training loss: 0.8287879881056497
Validation loss: 2.4129534367138663

Epoch: 5| Step: 6
Training loss: 0.754824341240396
Validation loss: 2.3782367735171834

Epoch: 5| Step: 7
Training loss: 1.216556335480635
Validation loss: 2.347246670590074

Epoch: 5| Step: 8
Training loss: 1.0253810337163034
Validation loss: 2.344652706755901

Epoch: 5| Step: 9
Training loss: 0.9199624994140054
Validation loss: 2.3450304658642724

Epoch: 5| Step: 10
Training loss: 1.1450492025406653
Validation loss: 2.328057237965748

Epoch: 314| Step: 0
Training loss: 0.9318325396867416
Validation loss: 2.33937513907148

Epoch: 5| Step: 1
Training loss: 1.1953181846333882
Validation loss: 2.389464443365545

Epoch: 5| Step: 2
Training loss: 0.9377313328478873
Validation loss: 2.379691850526837

Epoch: 5| Step: 3
Training loss: 1.0069556326993636
Validation loss: 2.383155969872412

Epoch: 5| Step: 4
Training loss: 1.1092031641304565
Validation loss: 2.358696154068024

Epoch: 5| Step: 5
Training loss: 0.961195593188356
Validation loss: 2.3603325476048878

Epoch: 5| Step: 6
Training loss: 1.0646718211764838
Validation loss: 2.3184326662323045

Epoch: 5| Step: 7
Training loss: 1.2943509829884188
Validation loss: 2.3301559578411206

Epoch: 5| Step: 8
Training loss: 1.0774028405021243
Validation loss: 2.345709285721334

Epoch: 5| Step: 9
Training loss: 0.81197835609407
Validation loss: 2.3920732454929583

Epoch: 5| Step: 10
Training loss: 0.9192490435531243
Validation loss: 2.4239807543586713

Epoch: 315| Step: 0
Training loss: 1.0586532632350016
Validation loss: 2.4829262050866183

Epoch: 5| Step: 1
Training loss: 1.1137877265885505
Validation loss: 2.50303519593056

Epoch: 5| Step: 2
Training loss: 0.9613219941837724
Validation loss: 2.415740048347303

Epoch: 5| Step: 3
Training loss: 0.9102764132176491
Validation loss: 2.3046166749934196

Epoch: 5| Step: 4
Training loss: 1.3607616148857178
Validation loss: 2.279375127620628

Epoch: 5| Step: 5
Training loss: 1.233520405130887
Validation loss: 2.284639091719386

Epoch: 5| Step: 6
Training loss: 1.2311309969947022
Validation loss: 2.325039428965857

Epoch: 5| Step: 7
Training loss: 0.979302856767886
Validation loss: 2.3543919270304983

Epoch: 5| Step: 8
Training loss: 0.8964824468720755
Validation loss: 2.45347853825526

Epoch: 5| Step: 9
Training loss: 1.498199017494174
Validation loss: 2.5707274943897427

Epoch: 5| Step: 10
Training loss: 0.5376841850528873
Validation loss: 2.4568226060179628

Epoch: 316| Step: 0
Training loss: 1.1907767211683782
Validation loss: 2.3514448496292424

Epoch: 5| Step: 1
Training loss: 1.0554389254791416
Validation loss: 2.317459260822059

Epoch: 5| Step: 2
Training loss: 0.969429270186226
Validation loss: 2.3085141784981245

Epoch: 5| Step: 3
Training loss: 1.0115293818989868
Validation loss: 2.3023085565901478

Epoch: 5| Step: 4
Training loss: 1.4181871482442183
Validation loss: 2.2741441760598042

Epoch: 5| Step: 5
Training loss: 0.9188528470454167
Validation loss: 2.292369592279501

Epoch: 5| Step: 6
Training loss: 0.7842029078787934
Validation loss: 2.37424408606185

Epoch: 5| Step: 7
Training loss: 1.075672123623169
Validation loss: 2.4583983589138936

Epoch: 5| Step: 8
Training loss: 1.1695634041177614
Validation loss: 2.5326085416997848

Epoch: 5| Step: 9
Training loss: 1.358673967271332
Validation loss: 2.5033574590993344

Epoch: 5| Step: 10
Training loss: 1.1768354588134513
Validation loss: 2.447981980464171

Epoch: 317| Step: 0
Training loss: 0.853245393411455
Validation loss: 2.381673791530082

Epoch: 5| Step: 1
Training loss: 1.0783591085377113
Validation loss: 2.366511419442271

Epoch: 5| Step: 2
Training loss: 0.6626995236065961
Validation loss: 2.352500595682559

Epoch: 5| Step: 3
Training loss: 1.2668750852896271
Validation loss: 2.3563600609929773

Epoch: 5| Step: 4
Training loss: 1.0646406935874002
Validation loss: 2.3699636431881763

Epoch: 5| Step: 5
Training loss: 1.18286261307496
Validation loss: 2.3611692481350217

Epoch: 5| Step: 6
Training loss: 0.9585966425745567
Validation loss: 2.386954038956626

Epoch: 5| Step: 7
Training loss: 1.0971919805380381
Validation loss: 2.398936390367769

Epoch: 5| Step: 8
Training loss: 0.925551341678689
Validation loss: 2.42578827633021

Epoch: 5| Step: 9
Training loss: 1.2305316727308115
Validation loss: 2.411287852978914

Epoch: 5| Step: 10
Training loss: 1.098269959610311
Validation loss: 2.4109249187261343

Epoch: 318| Step: 0
Training loss: 1.1694550004564739
Validation loss: 2.4738103464593544

Epoch: 5| Step: 1
Training loss: 0.8360577790904897
Validation loss: 2.4750579117469056

Epoch: 5| Step: 2
Training loss: 1.1186437119442727
Validation loss: 2.4449361808865073

Epoch: 5| Step: 3
Training loss: 1.2362632312587316
Validation loss: 2.3911047066864675

Epoch: 5| Step: 4
Training loss: 0.9072789237656402
Validation loss: 2.329163270191645

Epoch: 5| Step: 5
Training loss: 1.3615653708346476
Validation loss: 2.3100445689512497

Epoch: 5| Step: 6
Training loss: 0.6866726882641224
Validation loss: 2.29286433178846

Epoch: 5| Step: 7
Training loss: 1.1634172533001603
Validation loss: 2.3273436259235765

Epoch: 5| Step: 8
Training loss: 1.019916447040983
Validation loss: 2.337485897400483

Epoch: 5| Step: 9
Training loss: 1.126152137374323
Validation loss: 2.3703862514077434

Epoch: 5| Step: 10
Training loss: 0.8781149799141776
Validation loss: 2.389283472655247

Epoch: 319| Step: 0
Training loss: 1.093858658979013
Validation loss: 2.403040337651085

Epoch: 5| Step: 1
Training loss: 0.9371235409517037
Validation loss: 2.4442773912521005

Epoch: 5| Step: 2
Training loss: 1.1716796712212452
Validation loss: 2.444094070262622

Epoch: 5| Step: 3
Training loss: 0.6413066308072973
Validation loss: 2.353418554960107

Epoch: 5| Step: 4
Training loss: 0.9591368264650298
Validation loss: 2.3496995602288284

Epoch: 5| Step: 5
Training loss: 0.949890589687899
Validation loss: 2.309838273883804

Epoch: 5| Step: 6
Training loss: 0.836471422757305
Validation loss: 2.2739909438973687

Epoch: 5| Step: 7
Training loss: 1.1491725411840104
Validation loss: 2.2776796257225453

Epoch: 5| Step: 8
Training loss: 0.9771217270867447
Validation loss: 2.272228359064828

Epoch: 5| Step: 9
Training loss: 1.5967214223091064
Validation loss: 2.2958129108140652

Epoch: 5| Step: 10
Training loss: 0.7215658673670039
Validation loss: 2.358964664465922

Epoch: 320| Step: 0
Training loss: 0.7673360039893482
Validation loss: 2.3988498831453406

Epoch: 5| Step: 1
Training loss: 0.7059336620562527
Validation loss: 2.4760186236833794

Epoch: 5| Step: 2
Training loss: 1.1696741927763514
Validation loss: 2.571360382729455

Epoch: 5| Step: 3
Training loss: 0.9978343341659472
Validation loss: 2.4991329607204205

Epoch: 5| Step: 4
Training loss: 1.0346306384104533
Validation loss: 2.4171020517315043

Epoch: 5| Step: 5
Training loss: 1.015236295996944
Validation loss: 2.3702824786255885

Epoch: 5| Step: 6
Training loss: 0.9597292491461146
Validation loss: 2.3713178647491127

Epoch: 5| Step: 7
Training loss: 1.2680038889154432
Validation loss: 2.3317303267475733

Epoch: 5| Step: 8
Training loss: 1.2313177661352315
Validation loss: 2.311946579291802

Epoch: 5| Step: 9
Training loss: 1.175107896193204
Validation loss: 2.3364361074366475

Epoch: 5| Step: 10
Training loss: 0.5765466279530436
Validation loss: 2.3105763541394504

Epoch: 321| Step: 0
Training loss: 0.7813436833478392
Validation loss: 2.3155037922273194

Epoch: 5| Step: 1
Training loss: 1.0839053013459095
Validation loss: 2.339086438489986

Epoch: 5| Step: 2
Training loss: 0.7512045168318352
Validation loss: 2.3534923681840065

Epoch: 5| Step: 3
Training loss: 0.9008466844042803
Validation loss: 2.3629358963893607

Epoch: 5| Step: 4
Training loss: 0.7574211368488337
Validation loss: 2.3427610644891286

Epoch: 5| Step: 5
Training loss: 1.1312104571265145
Validation loss: 2.286487319504299

Epoch: 5| Step: 6
Training loss: 1.1177643040522685
Validation loss: 2.251512535220403

Epoch: 5| Step: 7
Training loss: 1.0632109227070776
Validation loss: 2.2464111503344473

Epoch: 5| Step: 8
Training loss: 1.086143748504949
Validation loss: 2.2739617153841913

Epoch: 5| Step: 9
Training loss: 1.046150013419829
Validation loss: 2.2722742123564696

Epoch: 5| Step: 10
Training loss: 1.0707278037610723
Validation loss: 2.2948957439567783

Epoch: 322| Step: 0
Training loss: 0.582644785663145
Validation loss: 2.3139108911821276

Epoch: 5| Step: 1
Training loss: 0.8072372336135718
Validation loss: 2.3607887792005866

Epoch: 5| Step: 2
Training loss: 1.029392129446343
Validation loss: 2.401985855315403

Epoch: 5| Step: 3
Training loss: 1.168196384867394
Validation loss: 2.4236041990363897

Epoch: 5| Step: 4
Training loss: 0.859263395518576
Validation loss: 2.4248087441899844

Epoch: 5| Step: 5
Training loss: 0.8905001770353489
Validation loss: 2.434938526333135

Epoch: 5| Step: 6
Training loss: 1.0283162550742009
Validation loss: 2.4461884803424008

Epoch: 5| Step: 7
Training loss: 0.6575782141198787
Validation loss: 2.410159486783182

Epoch: 5| Step: 8
Training loss: 1.0471404009648781
Validation loss: 2.423994134220748

Epoch: 5| Step: 9
Training loss: 1.0705274936792635
Validation loss: 2.400052826053926

Epoch: 5| Step: 10
Training loss: 1.1693794636154413
Validation loss: 2.374005359299671

Epoch: 323| Step: 0
Training loss: 0.8791248304046072
Validation loss: 2.3630544387021275

Epoch: 5| Step: 1
Training loss: 1.0322547410711502
Validation loss: 2.374174783168488

Epoch: 5| Step: 2
Training loss: 0.8763532732238773
Validation loss: 2.3414087503901717

Epoch: 5| Step: 3
Training loss: 0.9249074490099868
Validation loss: 2.347755179839962

Epoch: 5| Step: 4
Training loss: 0.8379091558652516
Validation loss: 2.358721152379933

Epoch: 5| Step: 5
Training loss: 1.0740355179310719
Validation loss: 2.340857732070752

Epoch: 5| Step: 6
Training loss: 0.7480603806992083
Validation loss: 2.363531371884181

Epoch: 5| Step: 7
Training loss: 1.1325544392214852
Validation loss: 2.3500970377291366

Epoch: 5| Step: 8
Training loss: 1.1311616641799058
Validation loss: 2.3574519864852537

Epoch: 5| Step: 9
Training loss: 0.7620824874600707
Validation loss: 2.3411776432036855

Epoch: 5| Step: 10
Training loss: 0.7057341801839487
Validation loss: 2.32149643930084

Epoch: 324| Step: 0
Training loss: 1.0239560509802115
Validation loss: 2.3241190466276627

Epoch: 5| Step: 1
Training loss: 0.8704725025967791
Validation loss: 2.329133810567057

Epoch: 5| Step: 2
Training loss: 0.9506258484123703
Validation loss: 2.3351089929406115

Epoch: 5| Step: 3
Training loss: 0.6510775950372747
Validation loss: 2.3534473598381522

Epoch: 5| Step: 4
Training loss: 0.8981170414497013
Validation loss: 2.3366208678014373

Epoch: 5| Step: 5
Training loss: 0.7656598764377814
Validation loss: 2.3596835544154198

Epoch: 5| Step: 6
Training loss: 1.227582568093412
Validation loss: 2.3682466547993593

Epoch: 5| Step: 7
Training loss: 0.9260559318367739
Validation loss: 2.3888988339257744

Epoch: 5| Step: 8
Training loss: 0.8981273945223665
Validation loss: 2.401335741859481

Epoch: 5| Step: 9
Training loss: 0.6721863579662771
Validation loss: 2.4141941073842275

Epoch: 5| Step: 10
Training loss: 1.167996664574838
Validation loss: 2.429294830500226

Epoch: 325| Step: 0
Training loss: 1.1720624646606017
Validation loss: 2.438674456603068

Epoch: 5| Step: 1
Training loss: 0.8436747623383245
Validation loss: 2.3980657972167596

Epoch: 5| Step: 2
Training loss: 1.2292261540301566
Validation loss: 2.390479995819924

Epoch: 5| Step: 3
Training loss: 0.5955640786908952
Validation loss: 2.3580676170393713

Epoch: 5| Step: 4
Training loss: 1.2718478619353837
Validation loss: 2.3343899024153516

Epoch: 5| Step: 5
Training loss: 0.9528375411003833
Validation loss: 2.344086399889296

Epoch: 5| Step: 6
Training loss: 0.7393796308925452
Validation loss: 2.3531944600749726

Epoch: 5| Step: 7
Training loss: 0.5083994774179451
Validation loss: 2.3483925225640196

Epoch: 5| Step: 8
Training loss: 0.7690640885616855
Validation loss: 2.3464541525531826

Epoch: 5| Step: 9
Training loss: 0.8036257210812973
Validation loss: 2.3669733680096687

Epoch: 5| Step: 10
Training loss: 0.8512932588001844
Validation loss: 2.362823179960318

Epoch: 326| Step: 0
Training loss: 1.1397428367240703
Validation loss: 2.346554501991977

Epoch: 5| Step: 1
Training loss: 0.805947511691402
Validation loss: 2.34456280030953

Epoch: 5| Step: 2
Training loss: 1.2105638973667805
Validation loss: 2.3561189509453992

Epoch: 5| Step: 3
Training loss: 0.792516795681374
Validation loss: 2.363176729119323

Epoch: 5| Step: 4
Training loss: 0.6102197123211425
Validation loss: 2.359665833522573

Epoch: 5| Step: 5
Training loss: 1.1751239751789617
Validation loss: 2.370222519620241

Epoch: 5| Step: 6
Training loss: 0.9509156056170508
Validation loss: 2.3373310430554692

Epoch: 5| Step: 7
Training loss: 0.88478314043438
Validation loss: 2.3249652455502487

Epoch: 5| Step: 8
Training loss: 0.6585740761855875
Validation loss: 2.3357588302902803

Epoch: 5| Step: 9
Training loss: 0.5793810936896423
Validation loss: 2.343068734423729

Epoch: 5| Step: 10
Training loss: 0.7752073056847161
Validation loss: 2.333935858315391

Epoch: 327| Step: 0
Training loss: 0.6287385468169776
Validation loss: 2.349216207374556

Epoch: 5| Step: 1
Training loss: 0.6226107227715709
Validation loss: 2.3545243023081377

Epoch: 5| Step: 2
Training loss: 0.9407259433862752
Validation loss: 2.376358121019324

Epoch: 5| Step: 3
Training loss: 0.9983962431071279
Validation loss: 2.374028179751668

Epoch: 5| Step: 4
Training loss: 0.8686266804721555
Validation loss: 2.3669419679949293

Epoch: 5| Step: 5
Training loss: 0.8628488208458306
Validation loss: 2.3543778641562123

Epoch: 5| Step: 6
Training loss: 0.8930991757545517
Validation loss: 2.3634886693073778

Epoch: 5| Step: 7
Training loss: 1.1169477085383221
Validation loss: 2.3867593882000695

Epoch: 5| Step: 8
Training loss: 0.9469383696951859
Validation loss: 2.3993506879490223

Epoch: 5| Step: 9
Training loss: 0.988219911383134
Validation loss: 2.3873199247658397

Epoch: 5| Step: 10
Training loss: 0.793978269298874
Validation loss: 2.377445725453498

Epoch: 328| Step: 0
Training loss: 1.0724576072939895
Validation loss: 2.379698092391455

Epoch: 5| Step: 1
Training loss: 0.7776204675770154
Validation loss: 2.375819784192918

Epoch: 5| Step: 2
Training loss: 0.8540401287477865
Validation loss: 2.353371687865042

Epoch: 5| Step: 3
Training loss: 1.0126736527336524
Validation loss: 2.381256316199256

Epoch: 5| Step: 4
Training loss: 0.8492322413575688
Validation loss: 2.3497888244579888

Epoch: 5| Step: 5
Training loss: 0.8189534145748679
Validation loss: 2.3654588519809012

Epoch: 5| Step: 6
Training loss: 1.039202802550345
Validation loss: 2.3485400139792567

Epoch: 5| Step: 7
Training loss: 0.7692628188975917
Validation loss: 2.3423391688558195

Epoch: 5| Step: 8
Training loss: 1.0752294606010087
Validation loss: 2.3386591103871663

Epoch: 5| Step: 9
Training loss: 0.6748740661552456
Validation loss: 2.3094206930571732

Epoch: 5| Step: 10
Training loss: 0.6669827819429148
Validation loss: 2.3181236839722557

Epoch: 329| Step: 0
Training loss: 1.1461944473432968
Validation loss: 2.3285782345254264

Epoch: 5| Step: 1
Training loss: 0.3981664521033272
Validation loss: 2.341102495029267

Epoch: 5| Step: 2
Training loss: 0.8407370496189759
Validation loss: 2.3261797846552397

Epoch: 5| Step: 3
Training loss: 0.7389743921775361
Validation loss: 2.330770095096443

Epoch: 5| Step: 4
Training loss: 0.9120132428303667
Validation loss: 2.3767176182901637

Epoch: 5| Step: 5
Training loss: 0.9347338239438839
Validation loss: 2.3581385967742947

Epoch: 5| Step: 6
Training loss: 1.039593955057703
Validation loss: 2.389679913561371

Epoch: 5| Step: 7
Training loss: 0.8707743516748349
Validation loss: 2.4004327138279673

Epoch: 5| Step: 8
Training loss: 1.056419194230635
Validation loss: 2.379033904529556

Epoch: 5| Step: 9
Training loss: 0.8931308095327954
Validation loss: 2.3932629901035227

Epoch: 5| Step: 10
Training loss: 0.522170569044366
Validation loss: 2.3806195207635605

Epoch: 330| Step: 0
Training loss: 1.0704444748199158
Validation loss: 2.34298199830752

Epoch: 5| Step: 1
Training loss: 0.8159940491230271
Validation loss: 2.345100386801823

Epoch: 5| Step: 2
Training loss: 0.7848652162678725
Validation loss: 2.3616460567155197

Epoch: 5| Step: 3
Training loss: 1.1092897301798492
Validation loss: 2.333464889802332

Epoch: 5| Step: 4
Training loss: 0.8817784152274857
Validation loss: 2.366657546616689

Epoch: 5| Step: 5
Training loss: 0.8601622010457383
Validation loss: 2.3896349533030974

Epoch: 5| Step: 6
Training loss: 0.771230844293798
Validation loss: 2.3543853643662844

Epoch: 5| Step: 7
Training loss: 0.9080818997766475
Validation loss: 2.3679760648621655

Epoch: 5| Step: 8
Training loss: 0.8576472166603465
Validation loss: 2.398111687679282

Epoch: 5| Step: 9
Training loss: 0.8909967884579545
Validation loss: 2.367392581284242

Epoch: 5| Step: 10
Training loss: 0.5187308376863492
Validation loss: 2.3557804158399627

Epoch: 331| Step: 0
Training loss: 0.9084954232356207
Validation loss: 2.340860926136205

Epoch: 5| Step: 1
Training loss: 0.6758173673823672
Validation loss: 2.3708276762394647

Epoch: 5| Step: 2
Training loss: 0.8797704220542684
Validation loss: 2.3682564611987003

Epoch: 5| Step: 3
Training loss: 0.752889827558826
Validation loss: 2.3726189767082797

Epoch: 5| Step: 4
Training loss: 1.0202166128156924
Validation loss: 2.345359194033447

Epoch: 5| Step: 5
Training loss: 1.0606650046074404
Validation loss: 2.3756091378890547

Epoch: 5| Step: 6
Training loss: 0.7090855886130811
Validation loss: 2.415720821019466

Epoch: 5| Step: 7
Training loss: 0.8901252683069408
Validation loss: 2.388936672804355

Epoch: 5| Step: 8
Training loss: 0.6861872928576336
Validation loss: 2.394948175390967

Epoch: 5| Step: 9
Training loss: 1.0151342526800855
Validation loss: 2.3650812182598147

Epoch: 5| Step: 10
Training loss: 0.843239771254178
Validation loss: 2.360494010222981

Epoch: 332| Step: 0
Training loss: 0.7937874537364786
Validation loss: 2.3653411492935836

Epoch: 5| Step: 1
Training loss: 0.859778638894614
Validation loss: 2.3681231474146074

Epoch: 5| Step: 2
Training loss: 1.0253444116260144
Validation loss: 2.3715365176317404

Epoch: 5| Step: 3
Training loss: 1.1566385183472985
Validation loss: 2.3668795858874834

Epoch: 5| Step: 4
Training loss: 0.7774817569469099
Validation loss: 2.370716783533765

Epoch: 5| Step: 5
Training loss: 0.8231608756783935
Validation loss: 2.3680473928295114

Epoch: 5| Step: 6
Training loss: 0.8089809504224202
Validation loss: 2.353065618377412

Epoch: 5| Step: 7
Training loss: 0.7512477985165753
Validation loss: 2.36768554941018

Epoch: 5| Step: 8
Training loss: 0.9664173344536927
Validation loss: 2.3624424532550687

Epoch: 5| Step: 9
Training loss: 0.7114173611134135
Validation loss: 2.370257580615365

Epoch: 5| Step: 10
Training loss: 0.7183600072562343
Validation loss: 2.358430778478524

Epoch: 333| Step: 0
Training loss: 0.9149212837754793
Validation loss: 2.353298691160497

Epoch: 5| Step: 1
Training loss: 1.0822940879013887
Validation loss: 2.360432399889959

Epoch: 5| Step: 2
Training loss: 0.620041705966857
Validation loss: 2.3570044243631147

Epoch: 5| Step: 3
Training loss: 0.9865687010808533
Validation loss: 2.3519131997840623

Epoch: 5| Step: 4
Training loss: 0.9535835601347216
Validation loss: 2.3714638925040656

Epoch: 5| Step: 5
Training loss: 0.5539091855335868
Validation loss: 2.399902067613288

Epoch: 5| Step: 6
Training loss: 0.9886419067905051
Validation loss: 2.3922693510296273

Epoch: 5| Step: 7
Training loss: 1.0989143519466968
Validation loss: 2.381933002158828

Epoch: 5| Step: 8
Training loss: 0.5076725400105693
Validation loss: 2.4049762118530094

Epoch: 5| Step: 9
Training loss: 0.769615672171619
Validation loss: 2.388009878170053

Epoch: 5| Step: 10
Training loss: 0.6552290695337685
Validation loss: 2.3919604391328626

Epoch: 334| Step: 0
Training loss: 0.9987679580869145
Validation loss: 2.3627739105718333

Epoch: 5| Step: 1
Training loss: 1.1238438175234173
Validation loss: 2.3514264299422205

Epoch: 5| Step: 2
Training loss: 0.3213967140055292
Validation loss: 2.357280762830515

Epoch: 5| Step: 3
Training loss: 0.7430256176995106
Validation loss: 2.3550789064108026

Epoch: 5| Step: 4
Training loss: 0.7618651420575114
Validation loss: 2.3465791456719387

Epoch: 5| Step: 5
Training loss: 0.8681295278608255
Validation loss: 2.355440707226776

Epoch: 5| Step: 6
Training loss: 0.8899964574143273
Validation loss: 2.3970854438410862

Epoch: 5| Step: 7
Training loss: 1.0406467721855213
Validation loss: 2.4137734858966295

Epoch: 5| Step: 8
Training loss: 0.723635448291421
Validation loss: 2.414338824534938

Epoch: 5| Step: 9
Training loss: 0.8818003498386443
Validation loss: 2.388392961983093

Epoch: 5| Step: 10
Training loss: 0.6150508546349899
Validation loss: 2.397181848787044

Epoch: 335| Step: 0
Training loss: 0.9990329835198859
Validation loss: 2.3867452077659714

Epoch: 5| Step: 1
Training loss: 0.7305135458200114
Validation loss: 2.348910873374189

Epoch: 5| Step: 2
Training loss: 0.9173357465210027
Validation loss: 2.3674717656680353

Epoch: 5| Step: 3
Training loss: 0.6026531587520932
Validation loss: 2.3508366609379046

Epoch: 5| Step: 4
Training loss: 0.9215760797047912
Validation loss: 2.3425257060418616

Epoch: 5| Step: 5
Training loss: 0.8847441344356424
Validation loss: 2.370835248762292

Epoch: 5| Step: 6
Training loss: 0.7692576275318102
Validation loss: 2.3841705744915127

Epoch: 5| Step: 7
Training loss: 1.052024927815747
Validation loss: 2.398146783503483

Epoch: 5| Step: 8
Training loss: 0.6633320100410081
Validation loss: 2.366031517853318

Epoch: 5| Step: 9
Training loss: 0.8874004617131434
Validation loss: 2.4002930272152327

Epoch: 5| Step: 10
Training loss: 0.6273740502209875
Validation loss: 2.373367144411334

Epoch: 336| Step: 0
Training loss: 1.0320963998541604
Validation loss: 2.3653034781241824

Epoch: 5| Step: 1
Training loss: 0.8311092659121728
Validation loss: 2.3609634829395314

Epoch: 5| Step: 2
Training loss: 0.758004429688507
Validation loss: 2.351169952289352

Epoch: 5| Step: 3
Training loss: 0.7700655868390383
Validation loss: 2.325330278161802

Epoch: 5| Step: 4
Training loss: 0.661624742335996
Validation loss: 2.3215866659097624

Epoch: 5| Step: 5
Training loss: 0.7590747035409131
Validation loss: 2.3181319982032296

Epoch: 5| Step: 6
Training loss: 1.1262663495637286
Validation loss: 2.3341974465369772

Epoch: 5| Step: 7
Training loss: 0.964851348476374
Validation loss: 2.3467430591068483

Epoch: 5| Step: 8
Training loss: 0.6046575711357268
Validation loss: 2.378839194116857

Epoch: 5| Step: 9
Training loss: 0.6800262659273347
Validation loss: 2.41823056876776

Epoch: 5| Step: 10
Training loss: 0.8035469119555418
Validation loss: 2.426995159394052

Epoch: 337| Step: 0
Training loss: 0.671435367555631
Validation loss: 2.4556280768266068

Epoch: 5| Step: 1
Training loss: 0.7500634166609258
Validation loss: 2.4512145780582553

Epoch: 5| Step: 2
Training loss: 0.7058463099103879
Validation loss: 2.4042605296900255

Epoch: 5| Step: 3
Training loss: 1.0467400535036215
Validation loss: 2.355151164889242

Epoch: 5| Step: 4
Training loss: 0.9471128989518097
Validation loss: 2.3378745361956623

Epoch: 5| Step: 5
Training loss: 0.8301010308190698
Validation loss: 2.323691652180787

Epoch: 5| Step: 6
Training loss: 0.8597233846393287
Validation loss: 2.3139586040512574

Epoch: 5| Step: 7
Training loss: 0.874455112007533
Validation loss: 2.290358529880423

Epoch: 5| Step: 8
Training loss: 0.9415150496424131
Validation loss: 2.3149485884903385

Epoch: 5| Step: 9
Training loss: 0.5764920137320378
Validation loss: 2.3122904326984153

Epoch: 5| Step: 10
Training loss: 0.8494035844294737
Validation loss: 2.326187132223659

Epoch: 338| Step: 0
Training loss: 0.961755079114694
Validation loss: 2.3498015990470473

Epoch: 5| Step: 1
Training loss: 0.581471500441272
Validation loss: 2.363675552596784

Epoch: 5| Step: 2
Training loss: 0.4863608782053179
Validation loss: 2.369123730154866

Epoch: 5| Step: 3
Training loss: 0.8506137567431563
Validation loss: 2.3701760221174215

Epoch: 5| Step: 4
Training loss: 0.7940147529067436
Validation loss: 2.3330592933557392

Epoch: 5| Step: 5
Training loss: 0.8857824953574811
Validation loss: 2.346621162893604

Epoch: 5| Step: 6
Training loss: 1.0998919650691192
Validation loss: 2.341467496703001

Epoch: 5| Step: 7
Training loss: 0.8762014519252559
Validation loss: 2.324876989364848

Epoch: 5| Step: 8
Training loss: 0.8372314278703241
Validation loss: 2.339908885252933

Epoch: 5| Step: 9
Training loss: 0.8442502128503659
Validation loss: 2.339690625162779

Epoch: 5| Step: 10
Training loss: 0.5013902231652472
Validation loss: 2.343706988415118

Epoch: 339| Step: 0
Training loss: 0.71672090964598
Validation loss: 2.3815181197425455

Epoch: 5| Step: 1
Training loss: 0.9295273009687813
Validation loss: 2.3792423425974

Epoch: 5| Step: 2
Training loss: 0.8092548045456803
Validation loss: 2.376245847613395

Epoch: 5| Step: 3
Training loss: 0.7663793156641855
Validation loss: 2.361037623821947

Epoch: 5| Step: 4
Training loss: 0.7643199229574414
Validation loss: 2.403696180286141

Epoch: 5| Step: 5
Training loss: 0.9823761885772089
Validation loss: 2.3912499935400007

Epoch: 5| Step: 6
Training loss: 1.089543892685717
Validation loss: 2.3808194307631485

Epoch: 5| Step: 7
Training loss: 0.8377218009690249
Validation loss: 2.390046093228913

Epoch: 5| Step: 8
Training loss: 0.47609866348500457
Validation loss: 2.357786308019199

Epoch: 5| Step: 9
Training loss: 0.5630002711161609
Validation loss: 2.3599837425891046

Epoch: 5| Step: 10
Training loss: 0.6455945578504113
Validation loss: 2.347145618945061

Epoch: 340| Step: 0
Training loss: 0.8769812632508973
Validation loss: 2.366052151219943

Epoch: 5| Step: 1
Training loss: 0.2983785625999386
Validation loss: 2.3603008441870204

Epoch: 5| Step: 2
Training loss: 0.8413981048558108
Validation loss: 2.344523098231194

Epoch: 5| Step: 3
Training loss: 1.186494200546424
Validation loss: 2.346665321680189

Epoch: 5| Step: 4
Training loss: 0.6054792833950179
Validation loss: 2.370498583882013

Epoch: 5| Step: 5
Training loss: 0.8291804227854024
Validation loss: 2.359657452692245

Epoch: 5| Step: 6
Training loss: 0.813528803399281
Validation loss: 2.361832885539517

Epoch: 5| Step: 7
Training loss: 0.5678963889263631
Validation loss: 2.3707527390748573

Epoch: 5| Step: 8
Training loss: 0.8068399621756465
Validation loss: 2.3581240017958294

Epoch: 5| Step: 9
Training loss: 0.6978008876437366
Validation loss: 2.3620007648700003

Epoch: 5| Step: 10
Training loss: 0.8480563999170018
Validation loss: 2.368832224514783

Epoch: 341| Step: 0
Training loss: 1.0153987926046943
Validation loss: 2.363616802923593

Epoch: 5| Step: 1
Training loss: 0.9178477755434882
Validation loss: 2.389295356893089

Epoch: 5| Step: 2
Training loss: 0.5353344530101404
Validation loss: 2.338929176814989

Epoch: 5| Step: 3
Training loss: 0.65318344803797
Validation loss: 2.3435250899713345

Epoch: 5| Step: 4
Training loss: 0.6118203762013932
Validation loss: 2.3413666034958514

Epoch: 5| Step: 5
Training loss: 0.6293599405542101
Validation loss: 2.359933407989205

Epoch: 5| Step: 6
Training loss: 0.7022255548776677
Validation loss: 2.375305220934315

Epoch: 5| Step: 7
Training loss: 1.0927317648024832
Validation loss: 2.3585153877374614

Epoch: 5| Step: 8
Training loss: 0.7239995071082782
Validation loss: 2.338770509716526

Epoch: 5| Step: 9
Training loss: 0.6248963985407705
Validation loss: 2.3781938329206502

Epoch: 5| Step: 10
Training loss: 0.8796176659084635
Validation loss: 2.3586469881368415

Epoch: 342| Step: 0
Training loss: 0.63645681598522
Validation loss: 2.360835679855227

Epoch: 5| Step: 1
Training loss: 1.0498911551417882
Validation loss: 2.335452415272691

Epoch: 5| Step: 2
Training loss: 0.9150493869585798
Validation loss: 2.3214707441847864

Epoch: 5| Step: 3
Training loss: 0.5048474828876659
Validation loss: 2.3231052035409867

Epoch: 5| Step: 4
Training loss: 0.5945906710912625
Validation loss: 2.332105074536222

Epoch: 5| Step: 5
Training loss: 0.5552617176817012
Validation loss: 2.352622155391693

Epoch: 5| Step: 6
Training loss: 0.7471547995271676
Validation loss: 2.3525685112738897

Epoch: 5| Step: 7
Training loss: 0.7815354779318363
Validation loss: 2.3664973928387867

Epoch: 5| Step: 8
Training loss: 0.7908738751030379
Validation loss: 2.367822463991831

Epoch: 5| Step: 9
Training loss: 1.0848081465709216
Validation loss: 2.394793145435683

Epoch: 5| Step: 10
Training loss: 0.5902925009543081
Validation loss: 2.3932643151658333

Epoch: 343| Step: 0
Training loss: 1.004651575944238
Validation loss: 2.3930221357913526

Epoch: 5| Step: 1
Training loss: 0.8262794370500429
Validation loss: 2.4243435719602795

Epoch: 5| Step: 2
Training loss: 0.877456860201885
Validation loss: 2.400610441249754

Epoch: 5| Step: 3
Training loss: 0.39181018323726036
Validation loss: 2.411464033002932

Epoch: 5| Step: 4
Training loss: 0.9301048111561785
Validation loss: 2.417760923396256

Epoch: 5| Step: 5
Training loss: 0.5775439203165748
Validation loss: 2.3787490677220253

Epoch: 5| Step: 6
Training loss: 0.5619035578631886
Validation loss: 2.3760983000641707

Epoch: 5| Step: 7
Training loss: 0.8019012806035529
Validation loss: 2.3753869303354094

Epoch: 5| Step: 8
Training loss: 0.6138179156063819
Validation loss: 2.3612956228512783

Epoch: 5| Step: 9
Training loss: 0.9457948573236654
Validation loss: 2.367902261944767

Epoch: 5| Step: 10
Training loss: 0.7309246578450216
Validation loss: 2.378765570888924

Epoch: 344| Step: 0
Training loss: 0.7383304155721196
Validation loss: 2.37086949944699

Epoch: 5| Step: 1
Training loss: 0.5962078520235067
Validation loss: 2.3825870379680136

Epoch: 5| Step: 2
Training loss: 0.7224542696382916
Validation loss: 2.346758451050609

Epoch: 5| Step: 3
Training loss: 1.0432717101166697
Validation loss: 2.369630991561813

Epoch: 5| Step: 4
Training loss: 0.7843641394361024
Validation loss: 2.3806570572604087

Epoch: 5| Step: 5
Training loss: 0.5924777152703422
Validation loss: 2.3517078609153232

Epoch: 5| Step: 6
Training loss: 0.5532454160232358
Validation loss: 2.3409060729884845

Epoch: 5| Step: 7
Training loss: 0.6950395026747187
Validation loss: 2.323413292717711

Epoch: 5| Step: 8
Training loss: 0.9987462648362461
Validation loss: 2.344687376537852

Epoch: 5| Step: 9
Training loss: 0.6260295018322273
Validation loss: 2.3382943966781373

Epoch: 5| Step: 10
Training loss: 0.9064740200054576
Validation loss: 2.3316992349544745

Epoch: 345| Step: 0
Training loss: 0.6350215454651567
Validation loss: 2.3238803296237585

Epoch: 5| Step: 1
Training loss: 0.9575062721186454
Validation loss: 2.338518376132448

Epoch: 5| Step: 2
Training loss: 0.6425117759887086
Validation loss: 2.335077956015727

Epoch: 5| Step: 3
Training loss: 0.680967112961253
Validation loss: 2.3399122356429847

Epoch: 5| Step: 4
Training loss: 0.7159429968061359
Validation loss: 2.3819730934669923

Epoch: 5| Step: 5
Training loss: 0.7367264456968982
Validation loss: 2.3695350106821853

Epoch: 5| Step: 6
Training loss: 0.8130507070041091
Validation loss: 2.3603474265262543

Epoch: 5| Step: 7
Training loss: 0.7920183772449972
Validation loss: 2.3574655367728172

Epoch: 5| Step: 8
Training loss: 0.7036419769301906
Validation loss: 2.358528180278469

Epoch: 5| Step: 9
Training loss: 0.6938885026434719
Validation loss: 2.36233250500121

Epoch: 5| Step: 10
Training loss: 0.8982403414467366
Validation loss: 2.3389597318843336

Epoch: 346| Step: 0
Training loss: 0.6952938763128114
Validation loss: 2.3363039137676913

Epoch: 5| Step: 1
Training loss: 0.5644020664657137
Validation loss: 2.3369229593123864

Epoch: 5| Step: 2
Training loss: 0.6304053689516242
Validation loss: 2.3241335661490816

Epoch: 5| Step: 3
Training loss: 1.1010863986472958
Validation loss: 2.327316164599261

Epoch: 5| Step: 4
Training loss: 0.9359378196957764
Validation loss: 2.3191611922733046

Epoch: 5| Step: 5
Training loss: 0.8955640535987393
Validation loss: 2.353216639131064

Epoch: 5| Step: 6
Training loss: 0.659909648093299
Validation loss: 2.347240117437617

Epoch: 5| Step: 7
Training loss: 0.8853480966981097
Validation loss: 2.3550717937602834

Epoch: 5| Step: 8
Training loss: 0.5237765566299976
Validation loss: 2.380701382667609

Epoch: 5| Step: 9
Training loss: 0.4612282627948683
Validation loss: 2.3454756489544706

Epoch: 5| Step: 10
Training loss: 0.7165564775775313
Validation loss: 2.3648593147581076

Epoch: 347| Step: 0
Training loss: 0.4886467900534834
Validation loss: 2.3598594643514836

Epoch: 5| Step: 1
Training loss: 0.6772663358208723
Validation loss: 2.330691822985904

Epoch: 5| Step: 2
Training loss: 0.5963675373916164
Validation loss: 2.3220508580003205

Epoch: 5| Step: 3
Training loss: 0.5472623815447192
Validation loss: 2.3211110003646476

Epoch: 5| Step: 4
Training loss: 0.9518385475778232
Validation loss: 2.3587452439806156

Epoch: 5| Step: 5
Training loss: 0.6179927932170907
Validation loss: 2.3550027561739864

Epoch: 5| Step: 6
Training loss: 0.9455343254168694
Validation loss: 2.3543397627636105

Epoch: 5| Step: 7
Training loss: 0.7033784197718586
Validation loss: 2.3654965672777957

Epoch: 5| Step: 8
Training loss: 0.6364810008264745
Validation loss: 2.3643297199739406

Epoch: 5| Step: 9
Training loss: 0.7663609607003552
Validation loss: 2.374347806627867

Epoch: 5| Step: 10
Training loss: 1.1073074954538238
Validation loss: 2.3966030416372868

Epoch: 348| Step: 0
Training loss: 0.7986729851309856
Validation loss: 2.3739918845202186

Epoch: 5| Step: 1
Training loss: 0.5447926795420035
Validation loss: 2.349115383416052

Epoch: 5| Step: 2
Training loss: 0.47516760943305986
Validation loss: 2.356663755954141

Epoch: 5| Step: 3
Training loss: 0.5998674266104214
Validation loss: 2.337033426159188

Epoch: 5| Step: 4
Training loss: 0.6302976912733835
Validation loss: 2.3309386064329134

Epoch: 5| Step: 5
Training loss: 0.9711781189682276
Validation loss: 2.3597037120272732

Epoch: 5| Step: 6
Training loss: 0.6377523259472274
Validation loss: 2.356006328941129

Epoch: 5| Step: 7
Training loss: 0.745000747641886
Validation loss: 2.373002257527534

Epoch: 5| Step: 8
Training loss: 0.8932561657145881
Validation loss: 2.38257467695893

Epoch: 5| Step: 9
Training loss: 0.9506652234638525
Validation loss: 2.3973962088583693

Epoch: 5| Step: 10
Training loss: 0.6901533337238475
Validation loss: 2.3907396853489447

Epoch: 349| Step: 0
Training loss: 0.732441487367624
Validation loss: 2.379920913217804

Epoch: 5| Step: 1
Training loss: 0.7723977392219871
Validation loss: 2.3474650657745575

Epoch: 5| Step: 2
Training loss: 0.6582527481525918
Validation loss: 2.3478241859501687

Epoch: 5| Step: 3
Training loss: 0.8530887610036225
Validation loss: 2.3209181011467774

Epoch: 5| Step: 4
Training loss: 0.4755515961516868
Validation loss: 2.3203255440431056

Epoch: 5| Step: 5
Training loss: 0.7099475046012562
Validation loss: 2.313456504090477

Epoch: 5| Step: 6
Training loss: 0.7928915878862877
Validation loss: 2.3395622681645447

Epoch: 5| Step: 7
Training loss: 0.9308017816947832
Validation loss: 2.351482837665735

Epoch: 5| Step: 8
Training loss: 0.6074348767229135
Validation loss: 2.3505153230189464

Epoch: 5| Step: 9
Training loss: 0.6842177676385246
Validation loss: 2.385187276566914

Epoch: 5| Step: 10
Training loss: 0.7938491368898805
Validation loss: 2.3597431836830105

Epoch: 350| Step: 0
Training loss: 0.7900991900259428
Validation loss: 2.3749193362412253

Epoch: 5| Step: 1
Training loss: 0.7560548357124548
Validation loss: 2.3628774060768434

Epoch: 5| Step: 2
Training loss: 0.8199163661151992
Validation loss: 2.3521554145117856

Epoch: 5| Step: 3
Training loss: 0.7086678210724872
Validation loss: 2.3334392067259726

Epoch: 5| Step: 4
Training loss: 0.48866308922496826
Validation loss: 2.338133306390765

Epoch: 5| Step: 5
Training loss: 1.0874742022556647
Validation loss: 2.353230756334289

Epoch: 5| Step: 6
Training loss: 0.7150423784968394
Validation loss: 2.351552366698823

Epoch: 5| Step: 7
Training loss: 0.8195602600956067
Validation loss: 2.374592950736515

Epoch: 5| Step: 8
Training loss: 0.4944027593658349
Validation loss: 2.4315786059327023

Epoch: 5| Step: 9
Training loss: 0.7881561966483843
Validation loss: 2.437951693189212

Epoch: 5| Step: 10
Training loss: 0.2348403522933479
Validation loss: 2.4282832053938064

Epoch: 351| Step: 0
Training loss: 0.767486411480722
Validation loss: 2.4184211383170484

Epoch: 5| Step: 1
Training loss: 0.7670537501827386
Validation loss: 2.3946242446639356

Epoch: 5| Step: 2
Training loss: 0.6549787014854503
Validation loss: 2.3632413058870227

Epoch: 5| Step: 3
Training loss: 0.7564216513544257
Validation loss: 2.3294473721692373

Epoch: 5| Step: 4
Training loss: 0.7048288047185307
Validation loss: 2.3114037058872876

Epoch: 5| Step: 5
Training loss: 0.5831076122852102
Validation loss: 2.353610534347356

Epoch: 5| Step: 6
Training loss: 0.7242771014066646
Validation loss: 2.326254253341354

Epoch: 5| Step: 7
Training loss: 0.6355529128375755
Validation loss: 2.359041493165297

Epoch: 5| Step: 8
Training loss: 0.6153702600975757
Validation loss: 2.3379503155582406

Epoch: 5| Step: 9
Training loss: 0.7282710342329106
Validation loss: 2.3719302558139823

Epoch: 5| Step: 10
Training loss: 1.0660568056018782
Validation loss: 2.316033038799907

Epoch: 352| Step: 0
Training loss: 0.6500796241775059
Validation loss: 2.3365168034059653

Epoch: 5| Step: 1
Training loss: 0.5076887126580801
Validation loss: 2.3406048685067327

Epoch: 5| Step: 2
Training loss: 0.6702205781664923
Validation loss: 2.3409148974076417

Epoch: 5| Step: 3
Training loss: 0.9224030550231201
Validation loss: 2.342717357374762

Epoch: 5| Step: 4
Training loss: 0.5866881584796927
Validation loss: 2.352377171569042

Epoch: 5| Step: 5
Training loss: 0.748523211897119
Validation loss: 2.3514901650429922

Epoch: 5| Step: 6
Training loss: 0.7502521647288926
Validation loss: 2.38518818478739

Epoch: 5| Step: 7
Training loss: 0.7266007690195665
Validation loss: 2.408647161145967

Epoch: 5| Step: 8
Training loss: 1.0047901581661873
Validation loss: 2.399773177200875

Epoch: 5| Step: 9
Training loss: 0.5617011808955822
Validation loss: 2.4175223910099706

Epoch: 5| Step: 10
Training loss: 0.5843253782695215
Validation loss: 2.409852138924839

Epoch: 353| Step: 0
Training loss: 0.6970508575931093
Validation loss: 2.400384397426962

Epoch: 5| Step: 1
Training loss: 0.9374869663604087
Validation loss: 2.3910077875890168

Epoch: 5| Step: 2
Training loss: 0.36612775748045717
Validation loss: 2.406790057059108

Epoch: 5| Step: 3
Training loss: 0.7392281006016247
Validation loss: 2.374624983707984

Epoch: 5| Step: 4
Training loss: 0.9461783550054098
Validation loss: 2.414220593230492

Epoch: 5| Step: 5
Training loss: 0.6587863454980406
Validation loss: 2.368385688839992

Epoch: 5| Step: 6
Training loss: 0.5969926228890144
Validation loss: 2.3791315856465522

Epoch: 5| Step: 7
Training loss: 0.528998991415436
Validation loss: 2.3806426735627193

Epoch: 5| Step: 8
Training loss: 0.6350038990892265
Validation loss: 2.3523293513758388

Epoch: 5| Step: 9
Training loss: 0.6392139852192829
Validation loss: 2.3846032234810965

Epoch: 5| Step: 10
Training loss: 0.8967294461904715
Validation loss: 2.354890944083765

Epoch: 354| Step: 0
Training loss: 0.6498278683379376
Validation loss: 2.384212773849748

Epoch: 5| Step: 1
Training loss: 0.5365107303943487
Validation loss: 2.3682841124498086

Epoch: 5| Step: 2
Training loss: 0.8237892586668357
Validation loss: 2.37492103423796

Epoch: 5| Step: 3
Training loss: 0.4038497184283451
Validation loss: 2.349845176031014

Epoch: 5| Step: 4
Training loss: 0.6828359272514736
Validation loss: 2.350736131138557

Epoch: 5| Step: 5
Training loss: 0.8765797659249572
Validation loss: 2.3328583016988897

Epoch: 5| Step: 6
Training loss: 0.5436393384027149
Validation loss: 2.332783068777523

Epoch: 5| Step: 7
Training loss: 0.526532488683656
Validation loss: 2.3284558841999106

Epoch: 5| Step: 8
Training loss: 0.9670104128130005
Validation loss: 2.342153976811174

Epoch: 5| Step: 9
Training loss: 0.7116896454840816
Validation loss: 2.348493548392983

Epoch: 5| Step: 10
Training loss: 0.8450921298482897
Validation loss: 2.373658926913385

Epoch: 355| Step: 0
Training loss: 0.6210504192856087
Validation loss: 2.379183703086904

Epoch: 5| Step: 1
Training loss: 0.505626079713779
Validation loss: 2.416521713724353

Epoch: 5| Step: 2
Training loss: 1.0544454226128084
Validation loss: 2.3789292233421317

Epoch: 5| Step: 3
Training loss: 0.7037653656090075
Validation loss: 2.3881647076015557

Epoch: 5| Step: 4
Training loss: 0.7922430240953546
Validation loss: 2.3806104340360186

Epoch: 5| Step: 5
Training loss: 0.7885152221908455
Validation loss: 2.360564771470968

Epoch: 5| Step: 6
Training loss: 0.48948895444282514
Validation loss: 2.3421851049488946

Epoch: 5| Step: 7
Training loss: 0.8583365668695769
Validation loss: 2.3195735787458776

Epoch: 5| Step: 8
Training loss: 0.44474207164608703
Validation loss: 2.312931324322777

Epoch: 5| Step: 9
Training loss: 0.6871757176019281
Validation loss: 2.34044411332664

Epoch: 5| Step: 10
Training loss: 0.5639078218771657
Validation loss: 2.3411850532047063

Epoch: 356| Step: 0
Training loss: 0.7555914115539839
Validation loss: 2.371397599675093

Epoch: 5| Step: 1
Training loss: 0.5876314726284184
Validation loss: 2.3768486940832987

Epoch: 5| Step: 2
Training loss: 0.5770640303439524
Validation loss: 2.3971210509228467

Epoch: 5| Step: 3
Training loss: 0.6156180986511368
Validation loss: 2.4029684832993707

Epoch: 5| Step: 4
Training loss: 1.0114462938518682
Validation loss: 2.416259074253736

Epoch: 5| Step: 5
Training loss: 0.45803597044452926
Validation loss: 2.40918476331606

Epoch: 5| Step: 6
Training loss: 0.7464409464724854
Validation loss: 2.373795432167079

Epoch: 5| Step: 7
Training loss: 0.6527876571376632
Validation loss: 2.367100763899547

Epoch: 5| Step: 8
Training loss: 0.43136753747233775
Validation loss: 2.3453240800055055

Epoch: 5| Step: 9
Training loss: 0.7847536487719342
Validation loss: 2.3599314976963695

Epoch: 5| Step: 10
Training loss: 0.8477802098076721
Validation loss: 2.383464484245926

Epoch: 357| Step: 0
Training loss: 0.6980461218797307
Validation loss: 2.3505881798526613

Epoch: 5| Step: 1
Training loss: 0.6512495446523879
Validation loss: 2.360315018944333

Epoch: 5| Step: 2
Training loss: 0.3965669367476648
Validation loss: 2.3685815735531555

Epoch: 5| Step: 3
Training loss: 0.8952549501467034
Validation loss: 2.3479392302063204

Epoch: 5| Step: 4
Training loss: 0.39065933076678067
Validation loss: 2.348570698347873

Epoch: 5| Step: 5
Training loss: 0.7497202033430747
Validation loss: 2.352120784506886

Epoch: 5| Step: 6
Training loss: 0.6724986575159336
Validation loss: 2.3264131784637825

Epoch: 5| Step: 7
Training loss: 0.7830860307257381
Validation loss: 2.328698124539968

Epoch: 5| Step: 8
Training loss: 0.33217773572077003
Validation loss: 2.3408391606266483

Epoch: 5| Step: 9
Training loss: 0.8299079989954127
Validation loss: 2.354731844649497

Epoch: 5| Step: 10
Training loss: 0.9092423266867659
Validation loss: 2.3608697813345243

Epoch: 358| Step: 0
Training loss: 0.7503364920762201
Validation loss: 2.336652727934977

Epoch: 5| Step: 1
Training loss: 0.7597616631961094
Validation loss: 2.3632147411919293

Epoch: 5| Step: 2
Training loss: 0.8678856178940721
Validation loss: 2.338876802500608

Epoch: 5| Step: 3
Training loss: 0.721726928321038
Validation loss: 2.326498273337908

Epoch: 5| Step: 4
Training loss: 0.8020173000220175
Validation loss: 2.331411524669291

Epoch: 5| Step: 5
Training loss: 0.5427029734497544
Validation loss: 2.3411068774432118

Epoch: 5| Step: 6
Training loss: 0.4025813391934906
Validation loss: 2.327576198120772

Epoch: 5| Step: 7
Training loss: 0.7090241812468338
Validation loss: 2.3390845193917773

Epoch: 5| Step: 8
Training loss: 0.5762080035763051
Validation loss: 2.37667567363142

Epoch: 5| Step: 9
Training loss: 0.7495663501822241
Validation loss: 2.365202891200364

Epoch: 5| Step: 10
Training loss: 0.35416439233311453
Validation loss: 2.4029888677838946

Epoch: 359| Step: 0
Training loss: 0.9723544590951977
Validation loss: 2.4071101641026598

Epoch: 5| Step: 1
Training loss: 0.6481500471051973
Validation loss: 2.401931822621309

Epoch: 5| Step: 2
Training loss: 0.5782727233208621
Validation loss: 2.4137310402256613

Epoch: 5| Step: 3
Training loss: 0.5297143563633018
Validation loss: 2.4058671137134704

Epoch: 5| Step: 4
Training loss: 0.7369925741497038
Validation loss: 2.403061010635126

Epoch: 5| Step: 5
Training loss: 0.6049169671796736
Validation loss: 2.428834115661646

Epoch: 5| Step: 6
Training loss: 0.7024052644975493
Validation loss: 2.3956480841869103

Epoch: 5| Step: 7
Training loss: 0.7487900033240721
Validation loss: 2.3841136847400177

Epoch: 5| Step: 8
Training loss: 0.6026670051151074
Validation loss: 2.3796358324525864

Epoch: 5| Step: 9
Training loss: 0.5970305614572292
Validation loss: 2.3726479369245896

Epoch: 5| Step: 10
Training loss: 0.5117917773138905
Validation loss: 2.3510468868574748

Epoch: 360| Step: 0
Training loss: 0.9004617857378278
Validation loss: 2.35425648766115

Epoch: 5| Step: 1
Training loss: 0.8133894380255626
Validation loss: 2.3550075220314004

Epoch: 5| Step: 2
Training loss: 0.5920448664903757
Validation loss: 2.3614485637248968

Epoch: 5| Step: 3
Training loss: 0.4631226034784538
Validation loss: 2.3617929739177455

Epoch: 5| Step: 4
Training loss: 0.6348460689336142
Validation loss: 2.3411975790863067

Epoch: 5| Step: 5
Training loss: 0.7129908243073099
Validation loss: 2.3445788331038733

Epoch: 5| Step: 6
Training loss: 0.5499126809336984
Validation loss: 2.308444912390035

Epoch: 5| Step: 7
Training loss: 0.8309134913631153
Validation loss: 2.320525792279186

Epoch: 5| Step: 8
Training loss: 0.6079804774290287
Validation loss: 2.3049876745318567

Epoch: 5| Step: 9
Training loss: 0.6903844492119032
Validation loss: 2.292946009425244

Epoch: 5| Step: 10
Training loss: 0.31625480324033983
Validation loss: 2.340161096610416

Epoch: 361| Step: 0
Training loss: 0.8490037184365374
Validation loss: 2.3134878277566573

Epoch: 5| Step: 1
Training loss: 0.5349084879248988
Validation loss: 2.339933790653803

Epoch: 5| Step: 2
Training loss: 0.5941779702392304
Validation loss: 2.341922618047607

Epoch: 5| Step: 3
Training loss: 0.42838711337262736
Validation loss: 2.3318697245681665

Epoch: 5| Step: 4
Training loss: 0.7889123528271489
Validation loss: 2.3625441006747456

Epoch: 5| Step: 5
Training loss: 0.7047775557801802
Validation loss: 2.3756793809381076

Epoch: 5| Step: 6
Training loss: 0.5664308476861893
Validation loss: 2.3852763041750387

Epoch: 5| Step: 7
Training loss: 0.6891325943083981
Validation loss: 2.363213328767977

Epoch: 5| Step: 8
Training loss: 0.7757721546020233
Validation loss: 2.3587721665912413

Epoch: 5| Step: 9
Training loss: 0.7504989633190866
Validation loss: 2.354657305431405

Epoch: 5| Step: 10
Training loss: 0.3183935416206391
Validation loss: 2.3592324901456885

Epoch: 362| Step: 0
Training loss: 0.6431668723722974
Validation loss: 2.3402566187565523

Epoch: 5| Step: 1
Training loss: 0.7267861791055571
Validation loss: 2.3366083722435698

Epoch: 5| Step: 2
Training loss: 0.8370292878034478
Validation loss: 2.3338330341003197

Epoch: 5| Step: 3
Training loss: 0.7601998076549308
Validation loss: 2.353498855454146

Epoch: 5| Step: 4
Training loss: 0.5460609644488059
Validation loss: 2.356888967646746

Epoch: 5| Step: 5
Training loss: 0.7090718028911271
Validation loss: 2.3676324501518926

Epoch: 5| Step: 6
Training loss: 0.32694695944310753
Validation loss: 2.3547952883337544

Epoch: 5| Step: 7
Training loss: 0.6460267951341931
Validation loss: 2.348392048784557

Epoch: 5| Step: 8
Training loss: 0.5777906791482524
Validation loss: 2.3660816192518057

Epoch: 5| Step: 9
Training loss: 0.6947563819180329
Validation loss: 2.368116855554666

Epoch: 5| Step: 10
Training loss: 0.5078048118596203
Validation loss: 2.371168482857723

Epoch: 363| Step: 0
Training loss: 0.33543976794038205
Validation loss: 2.3776854399975855

Epoch: 5| Step: 1
Training loss: 0.5779873967727104
Validation loss: 2.378865390353072

Epoch: 5| Step: 2
Training loss: 0.6622205207732266
Validation loss: 2.395883543782244

Epoch: 5| Step: 3
Training loss: 0.5751248431471885
Validation loss: 2.383746940064966

Epoch: 5| Step: 4
Training loss: 0.6080491240350878
Validation loss: 2.3869201211077034

Epoch: 5| Step: 5
Training loss: 0.7777936390742959
Validation loss: 2.3641079392284094

Epoch: 5| Step: 6
Training loss: 0.5090992397588158
Validation loss: 2.3827576236736756

Epoch: 5| Step: 7
Training loss: 0.9427476245988788
Validation loss: 2.3538516464819543

Epoch: 5| Step: 8
Training loss: 0.8452752773247789
Validation loss: 2.3677477337976147

Epoch: 5| Step: 9
Training loss: 0.4851706645501204
Validation loss: 2.366753547784663

Epoch: 5| Step: 10
Training loss: 0.6120577714367916
Validation loss: 2.354939460144326

Epoch: 364| Step: 0
Training loss: 0.8058219986058924
Validation loss: 2.358934410903109

Epoch: 5| Step: 1
Training loss: 0.5451188637226921
Validation loss: 2.3538915097835855

Epoch: 5| Step: 2
Training loss: 0.6992505029043027
Validation loss: 2.337264798338247

Epoch: 5| Step: 3
Training loss: 0.48181274506689725
Validation loss: 2.392180206445674

Epoch: 5| Step: 4
Training loss: 0.5330940106990174
Validation loss: 2.4045775084885452

Epoch: 5| Step: 5
Training loss: 0.6368752035752739
Validation loss: 2.3669139100597603

Epoch: 5| Step: 6
Training loss: 0.5190689783765706
Validation loss: 2.364774396935502

Epoch: 5| Step: 7
Training loss: 0.3112434635854819
Validation loss: 2.3468989598992964

Epoch: 5| Step: 8
Training loss: 0.5339795283311789
Validation loss: 2.308965574439227

Epoch: 5| Step: 9
Training loss: 1.0526398172181646
Validation loss: 2.330303668387551

Epoch: 5| Step: 10
Training loss: 0.7829585656740968
Validation loss: 2.3207771391525744

Epoch: 365| Step: 0
Training loss: 0.6483854709571801
Validation loss: 2.336143369071008

Epoch: 5| Step: 1
Training loss: 0.46568163520930067
Validation loss: 2.3434461564851543

Epoch: 5| Step: 2
Training loss: 0.7525353097710699
Validation loss: 2.37687312020242

Epoch: 5| Step: 3
Training loss: 0.64081986882765
Validation loss: 2.3880335411738938

Epoch: 5| Step: 4
Training loss: 0.7105735014655098
Validation loss: 2.408106364430459

Epoch: 5| Step: 5
Training loss: 0.9651919211634856
Validation loss: 2.416412763089923

Epoch: 5| Step: 6
Training loss: 0.493137441993082
Validation loss: 2.4353218127581324

Epoch: 5| Step: 7
Training loss: 0.794184424697807
Validation loss: 2.4168424793431296

Epoch: 5| Step: 8
Training loss: 0.6179493897464127
Validation loss: 2.4135573231881473

Epoch: 5| Step: 9
Training loss: 0.21816832829388558
Validation loss: 2.393316937863831

Epoch: 5| Step: 10
Training loss: 0.4290530983491471
Validation loss: 2.375939207781149

Epoch: 366| Step: 0
Training loss: 0.6100195385977472
Validation loss: 2.371649958729008

Epoch: 5| Step: 1
Training loss: 0.47179323018449537
Validation loss: 2.3717708450370005

Epoch: 5| Step: 2
Training loss: 0.6584259697366687
Validation loss: 2.355461725597179

Epoch: 5| Step: 3
Training loss: 0.7199114247648724
Validation loss: 2.373162989930249

Epoch: 5| Step: 4
Training loss: 0.46180323749173974
Validation loss: 2.368524090186655

Epoch: 5| Step: 5
Training loss: 0.5045366705505525
Validation loss: 2.3623891905701067

Epoch: 5| Step: 6
Training loss: 0.4616033141906821
Validation loss: 2.347102706722997

Epoch: 5| Step: 7
Training loss: 0.4689599361784884
Validation loss: 2.3648835563008106

Epoch: 5| Step: 8
Training loss: 0.7883261086560988
Validation loss: 2.341846251010598

Epoch: 5| Step: 9
Training loss: 0.8291093985431008
Validation loss: 2.350101243285996

Epoch: 5| Step: 10
Training loss: 0.9133178416444233
Validation loss: 2.3789927442650423

Epoch: 367| Step: 0
Training loss: 0.6663913953227892
Validation loss: 2.365166310416024

Epoch: 5| Step: 1
Training loss: 0.5463646005580296
Validation loss: 2.3659660561337916

Epoch: 5| Step: 2
Training loss: 0.8574833945621152
Validation loss: 2.359164566449026

Epoch: 5| Step: 3
Training loss: 0.6098412173016027
Validation loss: 2.3590193596360987

Epoch: 5| Step: 4
Training loss: 0.4163350951645139
Validation loss: 2.4227334376410465

Epoch: 5| Step: 5
Training loss: 0.639352418383303
Validation loss: 2.4193738340158513

Epoch: 5| Step: 6
Training loss: 0.5376869564051432
Validation loss: 2.3990312521227994

Epoch: 5| Step: 7
Training loss: 0.5334585507244531
Validation loss: 2.401332115255477

Epoch: 5| Step: 8
Training loss: 0.7625789382597263
Validation loss: 2.385632528606496

Epoch: 5| Step: 9
Training loss: 0.6304118928478526
Validation loss: 2.367308168013744

Epoch: 5| Step: 10
Training loss: 0.6990413760462625
Validation loss: 2.3368536411679037

Epoch: 368| Step: 0
Training loss: 0.4222950080861085
Validation loss: 2.3371317120323436

Epoch: 5| Step: 1
Training loss: 0.6124187649164795
Validation loss: 2.3674732470201443

Epoch: 5| Step: 2
Training loss: 0.5843890519926099
Validation loss: 2.3716767682229545

Epoch: 5| Step: 3
Training loss: 0.39848241365891873
Validation loss: 2.385749629941786

Epoch: 5| Step: 4
Training loss: 0.5221528187528932
Validation loss: 2.3829761090552832

Epoch: 5| Step: 5
Training loss: 0.5857003813016959
Validation loss: 2.3959562654420195

Epoch: 5| Step: 6
Training loss: 0.5318239141331658
Validation loss: 2.405466320460772

Epoch: 5| Step: 7
Training loss: 0.6286145357075291
Validation loss: 2.394231279000003

Epoch: 5| Step: 8
Training loss: 0.7946151779093436
Validation loss: 2.4020928722169748

Epoch: 5| Step: 9
Training loss: 0.8476869779721735
Validation loss: 2.4227559477831195

Epoch: 5| Step: 10
Training loss: 0.8764504604168862
Validation loss: 2.4178866283457126

Epoch: 369| Step: 0
Training loss: 0.5615642499604553
Validation loss: 2.435522447341804

Epoch: 5| Step: 1
Training loss: 0.473912390553744
Validation loss: 2.399169708565063

Epoch: 5| Step: 2
Training loss: 0.7031663034811421
Validation loss: 2.428850806266336

Epoch: 5| Step: 3
Training loss: 0.5556962954218013
Validation loss: 2.3865720518765783

Epoch: 5| Step: 4
Training loss: 0.6141783840333261
Validation loss: 2.3949255869273145

Epoch: 5| Step: 5
Training loss: 0.4205442562514253
Validation loss: 2.3650709076613072

Epoch: 5| Step: 6
Training loss: 0.48504764244230975
Validation loss: 2.353943457999141

Epoch: 5| Step: 7
Training loss: 0.5765660893191544
Validation loss: 2.335567527240224

Epoch: 5| Step: 8
Training loss: 0.8621487330659635
Validation loss: 2.360617342267541

Epoch: 5| Step: 9
Training loss: 0.6137037097776513
Validation loss: 2.3609798927166175

Epoch: 5| Step: 10
Training loss: 0.8779390565841149
Validation loss: 2.3517335679531937

Epoch: 370| Step: 0
Training loss: 0.6883027418680265
Validation loss: 2.330056245563218

Epoch: 5| Step: 1
Training loss: 0.5957158822116323
Validation loss: 2.3242576650324476

Epoch: 5| Step: 2
Training loss: 0.5911180234801077
Validation loss: 2.330117661169141

Epoch: 5| Step: 3
Training loss: 0.5692230950314565
Validation loss: 2.3253428629885424

Epoch: 5| Step: 4
Training loss: 0.609664579202107
Validation loss: 2.3246389741102362

Epoch: 5| Step: 5
Training loss: 0.7935826973803561
Validation loss: 2.3394304533272923

Epoch: 5| Step: 6
Training loss: 0.4766392098896483
Validation loss: 2.3042908285612747

Epoch: 5| Step: 7
Training loss: 0.75739170464898
Validation loss: 2.3340652375611337

Epoch: 5| Step: 8
Training loss: 0.6736008855255495
Validation loss: 2.3061269479026913

Epoch: 5| Step: 9
Training loss: 0.3428644782123214
Validation loss: 2.3283462991840205

Epoch: 5| Step: 10
Training loss: 0.5549360980800137
Validation loss: 2.3503275372910557

Epoch: 371| Step: 0
Training loss: 0.5133768256865298
Validation loss: 2.3499719922664295

Epoch: 5| Step: 1
Training loss: 0.6945727839028242
Validation loss: 2.389506805113122

Epoch: 5| Step: 2
Training loss: 0.5171049438231379
Validation loss: 2.386334848454469

Epoch: 5| Step: 3
Training loss: 0.5373232883685058
Validation loss: 2.3862975591940114

Epoch: 5| Step: 4
Training loss: 0.6851383959402422
Validation loss: 2.365882531436224

Epoch: 5| Step: 5
Training loss: 0.6341084761328737
Validation loss: 2.3995641229673

Epoch: 5| Step: 6
Training loss: 0.5746471338164604
Validation loss: 2.420777613218655

Epoch: 5| Step: 7
Training loss: 0.44853277490250715
Validation loss: 2.380663948094447

Epoch: 5| Step: 8
Training loss: 0.36187646858958306
Validation loss: 2.3780840628518605

Epoch: 5| Step: 9
Training loss: 0.9621359632119465
Validation loss: 2.3851015927394643

Epoch: 5| Step: 10
Training loss: 0.6247077735561334
Validation loss: 2.3864776767240707

Epoch: 372| Step: 0
Training loss: 0.5296917107788879
Validation loss: 2.3706569393278185

Epoch: 5| Step: 1
Training loss: 0.6170355211324076
Validation loss: 2.363774454587234

Epoch: 5| Step: 2
Training loss: 0.7644280789677182
Validation loss: 2.374942728117376

Epoch: 5| Step: 3
Training loss: 0.5414275106023525
Validation loss: 2.4014152941026867

Epoch: 5| Step: 4
Training loss: 0.7897483186960512
Validation loss: 2.383055639478604

Epoch: 5| Step: 5
Training loss: 0.492252496938732
Validation loss: 2.4034217788085885

Epoch: 5| Step: 6
Training loss: 0.5048349383620326
Validation loss: 2.3875419048859685

Epoch: 5| Step: 7
Training loss: 0.6506266122847487
Validation loss: 2.4125767881727107

Epoch: 5| Step: 8
Training loss: 0.7115890535502266
Validation loss: 2.390852021213961

Epoch: 5| Step: 9
Training loss: 0.36919870878336847
Validation loss: 2.3481263613487093

Epoch: 5| Step: 10
Training loss: 0.6156644256670113
Validation loss: 2.3513261341497853

Epoch: 373| Step: 0
Training loss: 0.7438795377618238
Validation loss: 2.3675692860371775

Epoch: 5| Step: 1
Training loss: 0.7772738938117514
Validation loss: 2.3852786729828557

Epoch: 5| Step: 2
Training loss: 0.6811926388870891
Validation loss: 2.3775056338461034

Epoch: 5| Step: 3
Training loss: 0.47691732236310636
Validation loss: 2.3833556606670494

Epoch: 5| Step: 4
Training loss: 0.4639973668586897
Validation loss: 2.400498419475584

Epoch: 5| Step: 5
Training loss: 0.5387710114915603
Validation loss: 2.3657522188706213

Epoch: 5| Step: 6
Training loss: 0.7022024247977542
Validation loss: 2.390813618601719

Epoch: 5| Step: 7
Training loss: 0.6562910067144241
Validation loss: 2.3556797531211284

Epoch: 5| Step: 8
Training loss: 0.5365145909955195
Validation loss: 2.3506886167354994

Epoch: 5| Step: 9
Training loss: 0.6187212513496844
Validation loss: 2.3439025708926575

Epoch: 5| Step: 10
Training loss: 0.369147891018519
Validation loss: 2.3590125805424056

Epoch: 374| Step: 0
Training loss: 0.7127290725552582
Validation loss: 2.363520022460808

Epoch: 5| Step: 1
Training loss: 0.6860895427174362
Validation loss: 2.3858599464284937

Epoch: 5| Step: 2
Training loss: 0.6317688141298117
Validation loss: 2.3807038287142883

Epoch: 5| Step: 3
Training loss: 0.6978376590551261
Validation loss: 2.3869668509281046

Epoch: 5| Step: 4
Training loss: 0.6078975814070282
Validation loss: 2.3954554840788647

Epoch: 5| Step: 5
Training loss: 0.46068441587499215
Validation loss: 2.4257580793997855

Epoch: 5| Step: 6
Training loss: 0.5374956718536706
Validation loss: 2.409015606251529

Epoch: 5| Step: 7
Training loss: 0.5788751323537525
Validation loss: 2.3784299493161876

Epoch: 5| Step: 8
Training loss: 0.6509910309491608
Validation loss: 2.3719430678745157

Epoch: 5| Step: 9
Training loss: 0.3918726071067164
Validation loss: 2.374829766001976

Epoch: 5| Step: 10
Training loss: 0.6189710222311275
Validation loss: 2.3303685994485197

Epoch: 375| Step: 0
Training loss: 0.5083877533043893
Validation loss: 2.3459510394546546

Epoch: 5| Step: 1
Training loss: 0.7102961319574392
Validation loss: 2.3621716010812865

Epoch: 5| Step: 2
Training loss: 0.4536362427647736
Validation loss: 2.378759078701358

Epoch: 5| Step: 3
Training loss: 0.6136391682592834
Validation loss: 2.4006000539144865

Epoch: 5| Step: 4
Training loss: 0.47936421102446086
Validation loss: 2.389584256268817

Epoch: 5| Step: 5
Training loss: 0.7493781054562068
Validation loss: 2.3969173463326126

Epoch: 5| Step: 6
Training loss: 0.6923254336321356
Validation loss: 2.361168016893661

Epoch: 5| Step: 7
Training loss: 0.3601193597398897
Validation loss: 2.350661578639636

Epoch: 5| Step: 8
Training loss: 0.6122650669061771
Validation loss: 2.3441739853504537

Epoch: 5| Step: 9
Training loss: 0.53083970550633
Validation loss: 2.338994604971254

Epoch: 5| Step: 10
Training loss: 0.7965783333654552
Validation loss: 2.3716574497170777

Epoch: 376| Step: 0
Training loss: 0.7176436326346096
Validation loss: 2.3830959507192664

Epoch: 5| Step: 1
Training loss: 0.6348635084535866
Validation loss: 2.3561580822490833

Epoch: 5| Step: 2
Training loss: 0.5368076100981122
Validation loss: 2.430305734932283

Epoch: 5| Step: 3
Training loss: 0.40925178712001403
Validation loss: 2.4467293332466395

Epoch: 5| Step: 4
Training loss: 0.675109485294687
Validation loss: 2.4223599036126093

Epoch: 5| Step: 5
Training loss: 0.6658390515869277
Validation loss: 2.382532590082729

Epoch: 5| Step: 6
Training loss: 0.6517983629451348
Validation loss: 2.3690440003989246

Epoch: 5| Step: 7
Training loss: 0.5316053212010738
Validation loss: 2.3500903970738074

Epoch: 5| Step: 8
Training loss: 0.5043008722904793
Validation loss: 2.367784416536523

Epoch: 5| Step: 9
Training loss: 0.5274321870469567
Validation loss: 2.3342007419729778

Epoch: 5| Step: 10
Training loss: 0.732291329511743
Validation loss: 2.3522245836220006

Epoch: 377| Step: 0
Training loss: 0.6581608789849106
Validation loss: 2.3802238875465838

Epoch: 5| Step: 1
Training loss: 0.7002252761196889
Validation loss: 2.40793538130267

Epoch: 5| Step: 2
Training loss: 0.3863501092192549
Validation loss: 2.431710414459067

Epoch: 5| Step: 3
Training loss: 0.5867179504876715
Validation loss: 2.4237523300212245

Epoch: 5| Step: 4
Training loss: 0.5819840892144083
Validation loss: 2.4183602192854328

Epoch: 5| Step: 5
Training loss: 0.8406237151976342
Validation loss: 2.3883490535763525

Epoch: 5| Step: 6
Training loss: 0.46793923197329323
Validation loss: 2.3626387623580043

Epoch: 5| Step: 7
Training loss: 0.633101715119129
Validation loss: 2.359615876749861

Epoch: 5| Step: 8
Training loss: 0.5144310624265892
Validation loss: 2.328599779953615

Epoch: 5| Step: 9
Training loss: 0.23860336637822102
Validation loss: 2.323996859766736

Epoch: 5| Step: 10
Training loss: 0.6074819504446557
Validation loss: 2.338110840345767

Epoch: 378| Step: 0
Training loss: 0.8103958540714365
Validation loss: 2.320727989551472

Epoch: 5| Step: 1
Training loss: 0.34036068679380954
Validation loss: 2.293421938851127

Epoch: 5| Step: 2
Training loss: 0.5943245617457604
Validation loss: 2.3213287640992863

Epoch: 5| Step: 3
Training loss: 0.5232774290467594
Validation loss: 2.306456810347098

Epoch: 5| Step: 4
Training loss: 0.397962005971463
Validation loss: 2.3052453018349266

Epoch: 5| Step: 5
Training loss: 0.6942094561572705
Validation loss: 2.3159559517359947

Epoch: 5| Step: 6
Training loss: 0.7616795847678618
Validation loss: 2.306647853647751

Epoch: 5| Step: 7
Training loss: 0.6124353588793634
Validation loss: 2.3703104036717635

Epoch: 5| Step: 8
Training loss: 0.5514093429552189
Validation loss: 2.314672811229293

Epoch: 5| Step: 9
Training loss: 0.270667486886213
Validation loss: 2.315228928733316

Epoch: 5| Step: 10
Training loss: 0.6872308811235706
Validation loss: 2.3285795047423905

Epoch: 379| Step: 0
Training loss: 0.4351294360297709
Validation loss: 2.3327785072553158

Epoch: 5| Step: 1
Training loss: 0.857831609405402
Validation loss: 2.3749623158028315

Epoch: 5| Step: 2
Training loss: 0.5194966584356082
Validation loss: 2.408324060664561

Epoch: 5| Step: 3
Training loss: 0.4850497007466789
Validation loss: 2.4111370325416024

Epoch: 5| Step: 4
Training loss: 0.3240363055819007
Validation loss: 2.438997019846291

Epoch: 5| Step: 5
Training loss: 0.4700745465378739
Validation loss: 2.4119199834806317

Epoch: 5| Step: 6
Training loss: 0.5677254671316868
Validation loss: 2.3941721660423974

Epoch: 5| Step: 7
Training loss: 0.6488544318684001
Validation loss: 2.372559401452307

Epoch: 5| Step: 8
Training loss: 0.8631391106183419
Validation loss: 2.341590202320087

Epoch: 5| Step: 9
Training loss: 0.5655708993150402
Validation loss: 2.339983303757947

Epoch: 5| Step: 10
Training loss: 0.37423803482855844
Validation loss: 2.3590052917452

Epoch: 380| Step: 0
Training loss: 0.5294352558166329
Validation loss: 2.3364720270906396

Epoch: 5| Step: 1
Training loss: 0.7131179238184798
Validation loss: 2.366036607137642

Epoch: 5| Step: 2
Training loss: 0.49737575417245966
Validation loss: 2.386457888137569

Epoch: 5| Step: 3
Training loss: 0.47611853760058936
Validation loss: 2.3805322402244573

Epoch: 5| Step: 4
Training loss: 0.45680293061398614
Validation loss: 2.3808516286959014

Epoch: 5| Step: 5
Training loss: 0.5386658743564913
Validation loss: 2.351032849772717

Epoch: 5| Step: 6
Training loss: 0.5149132989844395
Validation loss: 2.3761725561712304

Epoch: 5| Step: 7
Training loss: 0.5790193702046894
Validation loss: 2.3881129321559817

Epoch: 5| Step: 8
Training loss: 0.6637848666385173
Validation loss: 2.376770502712515

Epoch: 5| Step: 9
Training loss: 0.6995375987794326
Validation loss: 2.38982938379139

Epoch: 5| Step: 10
Training loss: 0.6382986488912471
Validation loss: 2.3686784161625964

Epoch: 381| Step: 0
Training loss: 0.5490303074404538
Validation loss: 2.407892395134782

Epoch: 5| Step: 1
Training loss: 0.3889394634527673
Validation loss: 2.3777500394427973

Epoch: 5| Step: 2
Training loss: 0.7521491649765819
Validation loss: 2.3750553264984853

Epoch: 5| Step: 3
Training loss: 0.3307466677543265
Validation loss: 2.36858024767074

Epoch: 5| Step: 4
Training loss: 0.6529713427110377
Validation loss: 2.3783503771236894

Epoch: 5| Step: 5
Training loss: 0.6262660554818857
Validation loss: 2.353243262764528

Epoch: 5| Step: 6
Training loss: 0.7147655756995497
Validation loss: 2.3593151441062097

Epoch: 5| Step: 7
Training loss: 0.6687424400829218
Validation loss: 2.332277426757512

Epoch: 5| Step: 8
Training loss: 0.5025580950030286
Validation loss: 2.347118349437271

Epoch: 5| Step: 9
Training loss: 0.6213945104436326
Validation loss: 2.3406989040925454

Epoch: 5| Step: 10
Training loss: 0.2000664645263687
Validation loss: 2.3442894012055353

Epoch: 382| Step: 0
Training loss: 0.40658628776797173
Validation loss: 2.326934740334191

Epoch: 5| Step: 1
Training loss: 0.7172339663277414
Validation loss: 2.332734119659119

Epoch: 5| Step: 2
Training loss: 0.3865974698481722
Validation loss: 2.352395900943353

Epoch: 5| Step: 3
Training loss: 0.8874275634647786
Validation loss: 2.364266155336447

Epoch: 5| Step: 4
Training loss: 0.7124398674603049
Validation loss: 2.3622960143370166

Epoch: 5| Step: 5
Training loss: 0.43886764519552585
Validation loss: 2.3803535085595957

Epoch: 5| Step: 6
Training loss: 0.6176685679621425
Validation loss: 2.4011811392585463

Epoch: 5| Step: 7
Training loss: 0.5214880325246268
Validation loss: 2.4013456335888925

Epoch: 5| Step: 8
Training loss: 0.4292653524333858
Validation loss: 2.3945432559381206

Epoch: 5| Step: 9
Training loss: 0.32268377976357515
Validation loss: 2.38489826217148

Epoch: 5| Step: 10
Training loss: 0.46252434962844297
Validation loss: 2.394419784827514

Epoch: 383| Step: 0
Training loss: 0.38289295051832095
Validation loss: 2.3979977312144416

Epoch: 5| Step: 1
Training loss: 0.8340003125992882
Validation loss: 2.401985359020633

Epoch: 5| Step: 2
Training loss: 0.5337421361714672
Validation loss: 2.410470474253364

Epoch: 5| Step: 3
Training loss: 0.6119685368257268
Validation loss: 2.3711762716069997

Epoch: 5| Step: 4
Training loss: 0.3912328568258507
Validation loss: 2.38832465465902

Epoch: 5| Step: 5
Training loss: 0.49093667293117116
Validation loss: 2.3601019834775925

Epoch: 5| Step: 6
Training loss: 0.5597000903614947
Validation loss: 2.3523033184469546

Epoch: 5| Step: 7
Training loss: 0.46132664498552844
Validation loss: 2.3577675703607133

Epoch: 5| Step: 8
Training loss: 0.27059440741617186
Validation loss: 2.3767496193902327

Epoch: 5| Step: 9
Training loss: 0.8328154902019819
Validation loss: 2.367656172804155

Epoch: 5| Step: 10
Training loss: 0.5475639363411443
Validation loss: 2.356013707537576

Epoch: 384| Step: 0
Training loss: 0.6389002493755901
Validation loss: 2.360917846600492

Epoch: 5| Step: 1
Training loss: 0.5157223811814323
Validation loss: 2.3658167025824004

Epoch: 5| Step: 2
Training loss: 0.45699235147423856
Validation loss: 2.364018770247797

Epoch: 5| Step: 3
Training loss: 0.45091722576327825
Validation loss: 2.3717418670850194

Epoch: 5| Step: 4
Training loss: 0.5195938302116495
Validation loss: 2.3672500364374787

Epoch: 5| Step: 5
Training loss: 0.5846539489482235
Validation loss: 2.3994283144381763

Epoch: 5| Step: 6
Training loss: 0.45025432472969085
Validation loss: 2.3593026611695382

Epoch: 5| Step: 7
Training loss: 0.6037110194462573
Validation loss: 2.3662623969507606

Epoch: 5| Step: 8
Training loss: 0.6343776514909326
Validation loss: 2.332041910048584

Epoch: 5| Step: 9
Training loss: 0.6039808881069592
Validation loss: 2.3779515148363055

Epoch: 5| Step: 10
Training loss: 0.6393998223461708
Validation loss: 2.34579833732124

Epoch: 385| Step: 0
Training loss: 0.5746018824811718
Validation loss: 2.3553321328172436

Epoch: 5| Step: 1
Training loss: 0.31374744345850636
Validation loss: 2.362110409481806

Epoch: 5| Step: 2
Training loss: 0.4676886941684769
Validation loss: 2.34651032254682

Epoch: 5| Step: 3
Training loss: 0.6643517705636954
Validation loss: 2.3648038700487577

Epoch: 5| Step: 4
Training loss: 0.5187603386457699
Validation loss: 2.3647598743512543

Epoch: 5| Step: 5
Training loss: 0.7512080476951348
Validation loss: 2.339944047675229

Epoch: 5| Step: 6
Training loss: 0.33047157178174574
Validation loss: 2.3664298423340426

Epoch: 5| Step: 7
Training loss: 0.35073328773532925
Validation loss: 2.3720626844779287

Epoch: 5| Step: 8
Training loss: 0.5756885893963297
Validation loss: 2.375176245103536

Epoch: 5| Step: 9
Training loss: 0.7714605786480337
Validation loss: 2.358521481295685

Epoch: 5| Step: 10
Training loss: 0.5285428296042421
Validation loss: 2.367883158275576

Epoch: 386| Step: 0
Training loss: 0.4875873059565301
Validation loss: 2.3625093440691263

Epoch: 5| Step: 1
Training loss: 0.5004986422326938
Validation loss: 2.3663343897663527

Epoch: 5| Step: 2
Training loss: 0.6223679433875767
Validation loss: 2.357261391733771

Epoch: 5| Step: 3
Training loss: 0.4987962059855616
Validation loss: 2.3661985678666864

Epoch: 5| Step: 4
Training loss: 0.5899966212353701
Validation loss: 2.358213223808816

Epoch: 5| Step: 5
Training loss: 0.49928772379702535
Validation loss: 2.3381922789031773

Epoch: 5| Step: 6
Training loss: 0.7406947332461474
Validation loss: 2.3155831877549993

Epoch: 5| Step: 7
Training loss: 0.5815803778440686
Validation loss: 2.3202195974659685

Epoch: 5| Step: 8
Training loss: 0.6665107475181172
Validation loss: 2.314619682040406

Epoch: 5| Step: 9
Training loss: 0.4100961913687515
Validation loss: 2.3194998891984833

Epoch: 5| Step: 10
Training loss: 0.2722981831637433
Validation loss: 2.3467574514881364

Epoch: 387| Step: 0
Training loss: 0.4605242444561863
Validation loss: 2.3329676984011667

Epoch: 5| Step: 1
Training loss: 0.5404036879273881
Validation loss: 2.3417567352021607

Epoch: 5| Step: 2
Training loss: 0.5367505071093043
Validation loss: 2.317372055149395

Epoch: 5| Step: 3
Training loss: 0.6400330530140019
Validation loss: 2.3769647354620447

Epoch: 5| Step: 4
Training loss: 0.49690993444123843
Validation loss: 2.3738194722974155

Epoch: 5| Step: 5
Training loss: 0.6436064356373071
Validation loss: 2.365099810175818

Epoch: 5| Step: 6
Training loss: 0.3977143138471143
Validation loss: 2.357779955955521

Epoch: 5| Step: 7
Training loss: 0.3714517573047148
Validation loss: 2.3582267724400996

Epoch: 5| Step: 8
Training loss: 0.4104616753673149
Validation loss: 2.337279365624419

Epoch: 5| Step: 9
Training loss: 0.6066529291775661
Validation loss: 2.373480698915403

Epoch: 5| Step: 10
Training loss: 0.7676824445426814
Validation loss: 2.3538579797401535

Epoch: 388| Step: 0
Training loss: 0.6646256919643436
Validation loss: 2.338233913435048

Epoch: 5| Step: 1
Training loss: 0.7088422396345713
Validation loss: 2.377349925822657

Epoch: 5| Step: 2
Training loss: 0.31646113449490976
Validation loss: 2.3796877567855437

Epoch: 5| Step: 3
Training loss: 0.635065518475937
Validation loss: 2.3801604544114663

Epoch: 5| Step: 4
Training loss: 0.4416748512457396
Validation loss: 2.394053235421155

Epoch: 5| Step: 5
Training loss: 0.48320900644409703
Validation loss: 2.4235055738310645

Epoch: 5| Step: 6
Training loss: 0.637331123984503
Validation loss: 2.406240767147067

Epoch: 5| Step: 7
Training loss: 0.5318132948354488
Validation loss: 2.3904545188564765

Epoch: 5| Step: 8
Training loss: 0.40672505552992694
Validation loss: 2.3746618322646458

Epoch: 5| Step: 9
Training loss: 0.2684175730848557
Validation loss: 2.373432548900316

Epoch: 5| Step: 10
Training loss: 0.6800355787295904
Validation loss: 2.364733096883106

Epoch: 389| Step: 0
Training loss: 0.6779860762935915
Validation loss: 2.341657065303724

Epoch: 5| Step: 1
Training loss: 0.2259162367316301
Validation loss: 2.3607536449068873

Epoch: 5| Step: 2
Training loss: 0.33894903420320416
Validation loss: 2.3781093392344204

Epoch: 5| Step: 3
Training loss: 0.7362255561281168
Validation loss: 2.350611218375471

Epoch: 5| Step: 4
Training loss: 0.5174324550408065
Validation loss: 2.3634961579605442

Epoch: 5| Step: 5
Training loss: 0.5860443526431451
Validation loss: 2.369708361012797

Epoch: 5| Step: 6
Training loss: 0.7212562402756076
Validation loss: 2.381757719340181

Epoch: 5| Step: 7
Training loss: 0.3963975858361746
Validation loss: 2.3712611045012824

Epoch: 5| Step: 8
Training loss: 0.24739623906286332
Validation loss: 2.353357909207097

Epoch: 5| Step: 9
Training loss: 0.3502157270243697
Validation loss: 2.3641023813964703

Epoch: 5| Step: 10
Training loss: 0.7766541148741832
Validation loss: 2.3748019988117215

Epoch: 390| Step: 0
Training loss: 0.5738772200531291
Validation loss: 2.358171382691515

Epoch: 5| Step: 1
Training loss: 0.11383271816152832
Validation loss: 2.369813764852925

Epoch: 5| Step: 2
Training loss: 0.7904504711528317
Validation loss: 2.387295690907922

Epoch: 5| Step: 3
Training loss: 0.5005712524117557
Validation loss: 2.388218221993029

Epoch: 5| Step: 4
Training loss: 0.46230776825665226
Validation loss: 2.402759077571693

Epoch: 5| Step: 5
Training loss: 0.651669456430433
Validation loss: 2.396222914221494

Epoch: 5| Step: 6
Training loss: 0.41874761296061647
Validation loss: 2.4096047495130204

Epoch: 5| Step: 7
Training loss: 0.5801341996239214
Validation loss: 2.4017651466493324

Epoch: 5| Step: 8
Training loss: 0.48199663455270986
Validation loss: 2.395312101601182

Epoch: 5| Step: 9
Training loss: 0.3244852326725707
Validation loss: 2.3983801165184837

Epoch: 5| Step: 10
Training loss: 0.6200784265614301
Validation loss: 2.408250739498787

Epoch: 391| Step: 0
Training loss: 0.5061495033639312
Validation loss: 2.392760192225391

Epoch: 5| Step: 1
Training loss: 0.33846179557941414
Validation loss: 2.391104916829311

Epoch: 5| Step: 2
Training loss: 0.4830640464715515
Validation loss: 2.36825169927081

Epoch: 5| Step: 3
Training loss: 0.3504487090518189
Validation loss: 2.3745077213439783

Epoch: 5| Step: 4
Training loss: 0.6495700734832157
Validation loss: 2.3751610062864175

Epoch: 5| Step: 5
Training loss: 0.6349844218017783
Validation loss: 2.3874925260336104

Epoch: 5| Step: 6
Training loss: 0.7026211522798997
Validation loss: 2.356668740368629

Epoch: 5| Step: 7
Training loss: 0.5495907246909891
Validation loss: 2.3829409511727984

Epoch: 5| Step: 8
Training loss: 0.4676898411732086
Validation loss: 2.4175248395677387

Epoch: 5| Step: 9
Training loss: 0.5066462108389428
Validation loss: 2.383510430768284

Epoch: 5| Step: 10
Training loss: 0.4258000080981238
Validation loss: 2.3783040813737983

Epoch: 392| Step: 0
Training loss: 0.6290496283634168
Validation loss: 2.3795555407759217

Epoch: 5| Step: 1
Training loss: 0.52183669400826
Validation loss: 2.3674940616518336

Epoch: 5| Step: 2
Training loss: 0.314593810839622
Validation loss: 2.361345702052072

Epoch: 5| Step: 3
Training loss: 0.36480393774517395
Validation loss: 2.3635157260767325

Epoch: 5| Step: 4
Training loss: 0.6693034529003729
Validation loss: 2.3710407324742313

Epoch: 5| Step: 5
Training loss: 0.6625879859078087
Validation loss: 2.3638947968703787

Epoch: 5| Step: 6
Training loss: 0.3487589631928456
Validation loss: 2.3827929391903657

Epoch: 5| Step: 7
Training loss: 0.4490073328502644
Validation loss: 2.3952353162268807

Epoch: 5| Step: 8
Training loss: 0.4550587400310669
Validation loss: 2.4256915138834376

Epoch: 5| Step: 9
Training loss: 0.6825307373838594
Validation loss: 2.40219473721394

Epoch: 5| Step: 10
Training loss: 0.4639076456194783
Validation loss: 2.399431755874837

Epoch: 393| Step: 0
Training loss: 0.33434437985908644
Validation loss: 2.370722657571008

Epoch: 5| Step: 1
Training loss: 0.5948728434745431
Validation loss: 2.3869225742070554

Epoch: 5| Step: 2
Training loss: 0.4413800695976777
Validation loss: 2.3775713482458825

Epoch: 5| Step: 3
Training loss: 0.684731327118434
Validation loss: 2.3930542980939076

Epoch: 5| Step: 4
Training loss: 0.477634818183083
Validation loss: 2.3966167679581907

Epoch: 5| Step: 5
Training loss: 0.37612717819470587
Validation loss: 2.439835956483245

Epoch: 5| Step: 6
Training loss: 0.6895269078875003
Validation loss: 2.4136136671135744

Epoch: 5| Step: 7
Training loss: 0.6627013899043578
Validation loss: 2.391618142592061

Epoch: 5| Step: 8
Training loss: 0.39290322654299314
Validation loss: 2.39152401963264

Epoch: 5| Step: 9
Training loss: 0.42810671203424394
Validation loss: 2.376236178835166

Epoch: 5| Step: 10
Training loss: 0.43380483008681603
Validation loss: 2.376797508056899

Epoch: 394| Step: 0
Training loss: 0.43191633437964105
Validation loss: 2.355449729427285

Epoch: 5| Step: 1
Training loss: 0.4259818418263989
Validation loss: 2.336907342147991

Epoch: 5| Step: 2
Training loss: 0.7506574689463678
Validation loss: 2.3589061941449723

Epoch: 5| Step: 3
Training loss: 0.688065859533898
Validation loss: 2.3276490372370664

Epoch: 5| Step: 4
Training loss: 0.4981382099252328
Validation loss: 2.340599476115019

Epoch: 5| Step: 5
Training loss: 0.5523380975285661
Validation loss: 2.3541757148033744

Epoch: 5| Step: 6
Training loss: 0.2946988456135855
Validation loss: 2.360003476157704

Epoch: 5| Step: 7
Training loss: 0.21722409536946233
Validation loss: 2.356777640449421

Epoch: 5| Step: 8
Training loss: 0.40957724256569245
Validation loss: 2.395506561451404

Epoch: 5| Step: 9
Training loss: 0.5799862567325688
Validation loss: 2.4009815183884067

Epoch: 5| Step: 10
Training loss: 0.5925830365595394
Validation loss: 2.406264614172181

Epoch: 395| Step: 0
Training loss: 0.6247190559283033
Validation loss: 2.381269624987881

Epoch: 5| Step: 1
Training loss: 0.2940631009459563
Validation loss: 2.351068155503667

Epoch: 5| Step: 2
Training loss: 0.7401086705549745
Validation loss: 2.35554964122596

Epoch: 5| Step: 3
Training loss: 0.5017863787058556
Validation loss: 2.351532699575472

Epoch: 5| Step: 4
Training loss: 0.27341399773003633
Validation loss: 2.348009606620776

Epoch: 5| Step: 5
Training loss: 0.4487077543302339
Validation loss: 2.3301382951423606

Epoch: 5| Step: 6
Training loss: 0.43932644183680364
Validation loss: 2.339654516052306

Epoch: 5| Step: 7
Training loss: 0.46322769254303064
Validation loss: 2.3613892380770354

Epoch: 5| Step: 8
Training loss: 0.5594094729323489
Validation loss: 2.393977902999033

Epoch: 5| Step: 9
Training loss: 0.6847582897744358
Validation loss: 2.3879096636834793

Epoch: 5| Step: 10
Training loss: 0.478603775312962
Validation loss: 2.3784294572680316

Epoch: 396| Step: 0
Training loss: 0.3740461257945552
Validation loss: 2.292691912228407

Epoch: 5| Step: 1
Training loss: 0.5777169927183526
Validation loss: 2.278729615155213

Epoch: 5| Step: 2
Training loss: 0.5950597571970966
Validation loss: 2.2761822864006285

Epoch: 5| Step: 3
Training loss: 0.441519899844324
Validation loss: 2.2966604092782386

Epoch: 5| Step: 4
Training loss: 0.5322172951547667
Validation loss: 2.360246354130602

Epoch: 5| Step: 5
Training loss: 0.5944359230483436
Validation loss: 2.3816706581191065

Epoch: 5| Step: 6
Training loss: 0.5151901723599637
Validation loss: 2.4261272735096355

Epoch: 5| Step: 7
Training loss: 0.5966118057521557
Validation loss: 2.439014161197523

Epoch: 5| Step: 8
Training loss: 0.6448459203899398
Validation loss: 2.423374564164861

Epoch: 5| Step: 9
Training loss: 0.41089407542727746
Validation loss: 2.412510468387308

Epoch: 5| Step: 10
Training loss: 0.6688623307264571
Validation loss: 2.362551286861993

Epoch: 397| Step: 0
Training loss: 0.5533444976637859
Validation loss: 2.3489394666814793

Epoch: 5| Step: 1
Training loss: 0.6475311287279256
Validation loss: 2.295809879640634

Epoch: 5| Step: 2
Training loss: 0.6460145931810006
Validation loss: 2.298144264036818

Epoch: 5| Step: 3
Training loss: 0.7133669999086623
Validation loss: 2.3414499242597224

Epoch: 5| Step: 4
Training loss: 0.5524963837069405
Validation loss: 2.3812765721847526

Epoch: 5| Step: 5
Training loss: 0.5679080915001898
Validation loss: 2.410697692841769

Epoch: 5| Step: 6
Training loss: 0.770818959351285
Validation loss: 2.3937615473699605

Epoch: 5| Step: 7
Training loss: 0.5334527126706311
Validation loss: 2.3584794866749954

Epoch: 5| Step: 8
Training loss: 0.45261080934180914
Validation loss: 2.295804057922765

Epoch: 5| Step: 9
Training loss: 0.3527635403865648
Validation loss: 2.2660449907826186

Epoch: 5| Step: 10
Training loss: 0.605538124293899
Validation loss: 2.2328515699748928

Epoch: 398| Step: 0
Training loss: 0.47515305826306226
Validation loss: 2.2360441302777465

Epoch: 5| Step: 1
Training loss: 0.6129027249349578
Validation loss: 2.2524484184481093

Epoch: 5| Step: 2
Training loss: 0.535246514274725
Validation loss: 2.292813983967245

Epoch: 5| Step: 3
Training loss: 0.6112665504914074
Validation loss: 2.3771779825459642

Epoch: 5| Step: 4
Training loss: 0.646667500631378
Validation loss: 2.406056685473863

Epoch: 5| Step: 5
Training loss: 0.7316725903649969
Validation loss: 2.4303024817312977

Epoch: 5| Step: 6
Training loss: 0.6827393778530256
Validation loss: 2.4217595745398035

Epoch: 5| Step: 7
Training loss: 0.4511657978655921
Validation loss: 2.400127809720695

Epoch: 5| Step: 8
Training loss: 0.6869719818487613
Validation loss: 2.3726208386979355

Epoch: 5| Step: 9
Training loss: 0.38072401722540644
Validation loss: 2.4040965504478287

Epoch: 5| Step: 10
Training loss: 0.28454304435539085
Validation loss: 2.399249270653703

Epoch: 399| Step: 0
Training loss: 0.5161383991751815
Validation loss: 2.3941922565380986

Epoch: 5| Step: 1
Training loss: 0.451754734343825
Validation loss: 2.410073202634333

Epoch: 5| Step: 2
Training loss: 0.3326141290081658
Validation loss: 2.4478798058186277

Epoch: 5| Step: 3
Training loss: 0.5504601266160066
Validation loss: 2.4809961490966184

Epoch: 5| Step: 4
Training loss: 0.6079525607229812
Validation loss: 2.5214407878871663

Epoch: 5| Step: 5
Training loss: 0.6018299647641658
Validation loss: 2.500488684688207

Epoch: 5| Step: 6
Training loss: 0.48690761373681596
Validation loss: 2.457868588085591

Epoch: 5| Step: 7
Training loss: 0.5047378479494719
Validation loss: 2.3666525951552404

Epoch: 5| Step: 8
Training loss: 0.5738016287319486
Validation loss: 2.3188369615263476

Epoch: 5| Step: 9
Training loss: 0.650595807310128
Validation loss: 2.3087219610224463

Epoch: 5| Step: 10
Training loss: 0.7392393888447928
Validation loss: 2.286060462801323

Epoch: 400| Step: 0
Training loss: 0.4444672945807798
Validation loss: 2.2912152286644023

Epoch: 5| Step: 1
Training loss: 0.5576236811324913
Validation loss: 2.288448269950473

Epoch: 5| Step: 2
Training loss: 0.44702838452783134
Validation loss: 2.277756620432732

Epoch: 5| Step: 3
Training loss: 0.6366619014520052
Validation loss: 2.3115394590655503

Epoch: 5| Step: 4
Training loss: 0.5242345065663919
Validation loss: 2.3414073762730117

Epoch: 5| Step: 5
Training loss: 0.6350562736026547
Validation loss: 2.301073994435883

Epoch: 5| Step: 6
Training loss: 0.26074411627238253
Validation loss: 2.31947699813328

Epoch: 5| Step: 7
Training loss: 0.47820220336426394
Validation loss: 2.3293807315616406

Epoch: 5| Step: 8
Training loss: 0.6531871665681442
Validation loss: 2.290903436045054

Epoch: 5| Step: 9
Training loss: 0.571572179821842
Validation loss: 2.316248587358482

Epoch: 5| Step: 10
Training loss: 0.6341494577414692
Validation loss: 2.3541660822472776

Testing loss: 2.7860448988094153
