Epoch: 1| Step: 0
Training loss: 5.768158477510798
Validation loss: 5.793914236055616

Epoch: 5| Step: 1
Training loss: 5.244502140704818
Validation loss: 5.759747682318127

Epoch: 5| Step: 2
Training loss: 5.3522724209777826
Validation loss: 5.725590550235793

Epoch: 5| Step: 3
Training loss: 5.320280413873969
Validation loss: 5.693380041293713

Epoch: 5| Step: 4
Training loss: 6.296892568407564
Validation loss: 5.657686139922049

Epoch: 5| Step: 5
Training loss: 5.656983723129314
Validation loss: 5.618102595905912

Epoch: 5| Step: 6
Training loss: 5.977722454327132
Validation loss: 5.574193131097598

Epoch: 5| Step: 7
Training loss: 6.256220964027119
Validation loss: 5.523847855698571

Epoch: 5| Step: 8
Training loss: 5.654077945351424
Validation loss: 5.467295598533323

Epoch: 5| Step: 9
Training loss: 4.918387979177802
Validation loss: 5.403476257470457

Epoch: 5| Step: 10
Training loss: 5.389322228503469
Validation loss: 5.33616797170585

Epoch: 2| Step: 0
Training loss: 5.745787030817938
Validation loss: 5.261204343938909

Epoch: 5| Step: 1
Training loss: 5.306740005567857
Validation loss: 5.181385869583924

Epoch: 5| Step: 2
Training loss: 4.442543280137903
Validation loss: 5.098588755142165

Epoch: 5| Step: 3
Training loss: 5.058478182499866
Validation loss: 5.016170398069556

Epoch: 5| Step: 4
Training loss: 5.700738945963874
Validation loss: 4.932383031092337

Epoch: 5| Step: 5
Training loss: 4.909625404814565
Validation loss: 4.852467832171969

Epoch: 5| Step: 6
Training loss: 5.116765547965977
Validation loss: 4.77911070222574

Epoch: 5| Step: 7
Training loss: 4.612257854442783
Validation loss: 4.707092676352085

Epoch: 5| Step: 8
Training loss: 5.803885033486931
Validation loss: 4.641589880957123

Epoch: 5| Step: 9
Training loss: 3.3558384932528935
Validation loss: 4.5806554576539105

Epoch: 5| Step: 10
Training loss: 3.7431087753548096
Validation loss: 4.520758699916588

Epoch: 3| Step: 0
Training loss: 5.317954460921746
Validation loss: 4.466253798376976

Epoch: 5| Step: 1
Training loss: 3.9024372261467724
Validation loss: 4.406804503924217

Epoch: 5| Step: 2
Training loss: 3.865961423773204
Validation loss: 4.35796483087681

Epoch: 5| Step: 3
Training loss: 4.811422252113689
Validation loss: 4.318122554842818

Epoch: 5| Step: 4
Training loss: 4.432385142947296
Validation loss: 4.2844772827732855

Epoch: 5| Step: 5
Training loss: 4.446128086566805
Validation loss: 4.248464843947789

Epoch: 5| Step: 6
Training loss: 4.189316085316947
Validation loss: 4.213489174336817

Epoch: 5| Step: 7
Training loss: 4.609590583544312
Validation loss: 4.178122179857826

Epoch: 5| Step: 8
Training loss: 3.8362624269683816
Validation loss: 4.143347293418178

Epoch: 5| Step: 9
Training loss: 3.796054453154738
Validation loss: 4.10901156784725

Epoch: 5| Step: 10
Training loss: 4.893306301849568
Validation loss: 4.07560800223719

Epoch: 4| Step: 0
Training loss: 4.22113467035505
Validation loss: 4.033647838267532

Epoch: 5| Step: 1
Training loss: 3.8306694449673473
Validation loss: 3.9911520092050194

Epoch: 5| Step: 2
Training loss: 3.9526789115741403
Validation loss: 3.9479161194680197

Epoch: 5| Step: 3
Training loss: 3.7529171088050326
Validation loss: 3.9120581504676664

Epoch: 5| Step: 4
Training loss: 4.670660467065487
Validation loss: 3.884635081080886

Epoch: 5| Step: 5
Training loss: 4.973228499574937
Validation loss: 3.864142566104819

Epoch: 5| Step: 6
Training loss: 3.863392210197149
Validation loss: 3.839414205224695

Epoch: 5| Step: 7
Training loss: 3.5896684107750687
Validation loss: 3.817859768142652

Epoch: 5| Step: 8
Training loss: 4.574002124794223
Validation loss: 3.796156615040727

Epoch: 5| Step: 9
Training loss: 3.0753914560641262
Validation loss: 3.773606229852648

Epoch: 5| Step: 10
Training loss: 3.510569824741386
Validation loss: 3.755713553164419

Epoch: 5| Step: 0
Training loss: 3.5559189895482
Validation loss: 3.730969177914565

Epoch: 5| Step: 1
Training loss: 3.2936165422477712
Validation loss: 3.7140171662635106

Epoch: 5| Step: 2
Training loss: 3.932782935303058
Validation loss: 3.699124672429085

Epoch: 5| Step: 3
Training loss: 4.419815500473695
Validation loss: 3.6744301504901085

Epoch: 5| Step: 4
Training loss: 3.1311376189815525
Validation loss: 3.6621061309909466

Epoch: 5| Step: 5
Training loss: 3.4759361817325614
Validation loss: 3.6499874505290713

Epoch: 5| Step: 6
Training loss: 3.467113624394281
Validation loss: 3.635367235225572

Epoch: 5| Step: 7
Training loss: 4.029310366025039
Validation loss: 3.623793575564217

Epoch: 5| Step: 8
Training loss: 4.508987776004738
Validation loss: 3.599272572835502

Epoch: 5| Step: 9
Training loss: 4.460078435644334
Validation loss: 3.5760732814489766

Epoch: 5| Step: 10
Training loss: 3.525376152368146
Validation loss: 3.5507577562569663

Epoch: 6| Step: 0
Training loss: 4.1087933843101885
Validation loss: 3.5421368952115944

Epoch: 5| Step: 1
Training loss: 3.69372240498364
Validation loss: 3.5222534550529336

Epoch: 5| Step: 2
Training loss: 2.7948509010031093
Validation loss: 3.511471771115134

Epoch: 5| Step: 3
Training loss: 4.03325963754294
Validation loss: 3.5031279490389693

Epoch: 5| Step: 4
Training loss: 3.52385633055826
Validation loss: 3.490924006227298

Epoch: 5| Step: 5
Training loss: 2.770831880114946
Validation loss: 3.4850728378043954

Epoch: 5| Step: 6
Training loss: 4.5377760621890735
Validation loss: 3.4706444135146173

Epoch: 5| Step: 7
Training loss: 3.888936852356151
Validation loss: 3.4595586106304044

Epoch: 5| Step: 8
Training loss: 3.788463427190522
Validation loss: 3.444311994574545

Epoch: 5| Step: 9
Training loss: 3.5971614402110057
Validation loss: 3.428975613905212

Epoch: 5| Step: 10
Training loss: 3.569283568784774
Validation loss: 3.425600981225822

Epoch: 7| Step: 0
Training loss: 4.382644949309604
Validation loss: 3.408210836516332

Epoch: 5| Step: 1
Training loss: 3.2817585868871313
Validation loss: 3.4015164999805156

Epoch: 5| Step: 2
Training loss: 3.5799848895047073
Validation loss: 3.39469836245081

Epoch: 5| Step: 3
Training loss: 4.305335022121968
Validation loss: 3.3850112972724444

Epoch: 5| Step: 4
Training loss: 3.3566605357695285
Validation loss: 3.375092531346344

Epoch: 5| Step: 5
Training loss: 3.4622246477833802
Validation loss: 3.361623383181251

Epoch: 5| Step: 6
Training loss: 3.8761490379551864
Validation loss: 3.350346439553051

Epoch: 5| Step: 7
Training loss: 3.3753893592319115
Validation loss: 3.347388983749552

Epoch: 5| Step: 8
Training loss: 3.1013887678633116
Validation loss: 3.335003239719449

Epoch: 5| Step: 9
Training loss: 3.231731421727018
Validation loss: 3.329033372119209

Epoch: 5| Step: 10
Training loss: 3.3805463922592875
Validation loss: 3.32305911498146

Epoch: 8| Step: 0
Training loss: 4.380147467094697
Validation loss: 3.316502095076054

Epoch: 5| Step: 1
Training loss: 3.5420655568204094
Validation loss: 3.309969975426684

Epoch: 5| Step: 2
Training loss: 3.3868443378891504
Validation loss: 3.2997158827524187

Epoch: 5| Step: 3
Training loss: 3.454983034437291
Validation loss: 3.2899138398365917

Epoch: 5| Step: 4
Training loss: 3.537187833458246
Validation loss: 3.284042068984989

Epoch: 5| Step: 5
Training loss: 3.495057294427805
Validation loss: 3.272506089138218

Epoch: 5| Step: 6
Training loss: 3.5793288425448884
Validation loss: 3.26570057005067

Epoch: 5| Step: 7
Training loss: 3.1339492828218845
Validation loss: 3.2600224503736164

Epoch: 5| Step: 8
Training loss: 3.598678923975265
Validation loss: 3.254101401595994

Epoch: 5| Step: 9
Training loss: 3.2494020645590544
Validation loss: 3.2483403612070907

Epoch: 5| Step: 10
Training loss: 3.2973429994031394
Validation loss: 3.250302728984284

Epoch: 9| Step: 0
Training loss: 3.52822543897495
Validation loss: 3.240621792774708

Epoch: 5| Step: 1
Training loss: 4.071046495794767
Validation loss: 3.2320464383094634

Epoch: 5| Step: 2
Training loss: 3.292765872448158
Validation loss: 3.22621073850456

Epoch: 5| Step: 3
Training loss: 3.723006433145814
Validation loss: 3.2236234410898805

Epoch: 5| Step: 4
Training loss: 3.4486113863524244
Validation loss: 3.2183057600133296

Epoch: 5| Step: 5
Training loss: 3.869344830118876
Validation loss: 3.213011642966141

Epoch: 5| Step: 6
Training loss: 3.7748529216080655
Validation loss: 3.2061232833738376

Epoch: 5| Step: 7
Training loss: 2.4959564887619186
Validation loss: 3.1971901413076873

Epoch: 5| Step: 8
Training loss: 3.372765260392277
Validation loss: 3.1974049883958893

Epoch: 5| Step: 9
Training loss: 3.1213079386181466
Validation loss: 3.189684251174826

Epoch: 5| Step: 10
Training loss: 3.210563842119663
Validation loss: 3.187474993246335

Epoch: 10| Step: 0
Training loss: 3.7001405431500167
Validation loss: 3.1774106996638145

Epoch: 5| Step: 1
Training loss: 3.450970145667601
Validation loss: 3.1714541919233112

Epoch: 5| Step: 2
Training loss: 2.7826409451414382
Validation loss: 3.162415234439262

Epoch: 5| Step: 3
Training loss: 3.7654190956899503
Validation loss: 3.1676881148782767

Epoch: 5| Step: 4
Training loss: 3.321891714289074
Validation loss: 3.1724813283781033

Epoch: 5| Step: 5
Training loss: 4.176206019380341
Validation loss: 3.1481830519855816

Epoch: 5| Step: 6
Training loss: 2.7746879230322365
Validation loss: 3.1480743623011844

Epoch: 5| Step: 7
Training loss: 3.623845146643353
Validation loss: 3.146305933473677

Epoch: 5| Step: 8
Training loss: 2.769449811203464
Validation loss: 3.1397936912591273

Epoch: 5| Step: 9
Training loss: 3.290346162435245
Validation loss: 3.1346686313106367

Epoch: 5| Step: 10
Training loss: 3.720137649778672
Validation loss: 3.126952628169288

Epoch: 11| Step: 0
Training loss: 3.7703981657765553
Validation loss: 3.1204579247405633

Epoch: 5| Step: 1
Training loss: 2.848617579825145
Validation loss: 3.1157858361339392

Epoch: 5| Step: 2
Training loss: 2.8714687387982316
Validation loss: 3.109894370519557

Epoch: 5| Step: 3
Training loss: 3.321206508778127
Validation loss: 3.1065850118709677

Epoch: 5| Step: 4
Training loss: 3.3740357328375827
Validation loss: 3.1042776297864196

Epoch: 5| Step: 5
Training loss: 3.7083849671158813
Validation loss: 3.100487600040779

Epoch: 5| Step: 6
Training loss: 2.8555724494358485
Validation loss: 3.0954837260549968

Epoch: 5| Step: 7
Training loss: 2.894873553794026
Validation loss: 3.092723800123202

Epoch: 5| Step: 8
Training loss: 4.209126665228257
Validation loss: 3.0864712103181633

Epoch: 5| Step: 9
Training loss: 3.6404971644669892
Validation loss: 3.084983313257364

Epoch: 5| Step: 10
Training loss: 3.3786375435063505
Validation loss: 3.0813896157718843

Epoch: 12| Step: 0
Training loss: 2.912254120103291
Validation loss: 3.0768505419088537

Epoch: 5| Step: 1
Training loss: 3.211576152318533
Validation loss: 3.075606591886462

Epoch: 5| Step: 2
Training loss: 2.8580666138645388
Validation loss: 3.0828876594534913

Epoch: 5| Step: 3
Training loss: 3.591247881720423
Validation loss: 3.1152200459935653

Epoch: 5| Step: 4
Training loss: 3.399857989318698
Validation loss: 3.064192074468921

Epoch: 5| Step: 5
Training loss: 3.4493326619780067
Validation loss: 3.06759764083739

Epoch: 5| Step: 6
Training loss: 3.887041394821222
Validation loss: 3.0836568367245287

Epoch: 5| Step: 7
Training loss: 3.141208727285021
Validation loss: 3.0800281648342933

Epoch: 5| Step: 8
Training loss: 3.658874482701419
Validation loss: 3.0711618932229956

Epoch: 5| Step: 9
Training loss: 3.533046569223612
Validation loss: 3.0648554202314324

Epoch: 5| Step: 10
Training loss: 3.129040661614376
Validation loss: 3.0603402001204696

Epoch: 13| Step: 0
Training loss: 3.6014798831359327
Validation loss: 3.0552102631847546

Epoch: 5| Step: 1
Training loss: 3.5916771259435847
Validation loss: 3.0526861205706703

Epoch: 5| Step: 2
Training loss: 3.872650418595569
Validation loss: 3.0496849277243143

Epoch: 5| Step: 3
Training loss: 3.2207134887454543
Validation loss: 3.0469774269491734

Epoch: 5| Step: 4
Training loss: 3.4015813908470762
Validation loss: 3.047738741272187

Epoch: 5| Step: 5
Training loss: 3.101086789025952
Validation loss: 3.051571883617039

Epoch: 5| Step: 6
Training loss: 2.5810207865549364
Validation loss: 3.051392691531601

Epoch: 5| Step: 7
Training loss: 3.071163768062327
Validation loss: 3.0394082584861475

Epoch: 5| Step: 8
Training loss: 3.035365977460785
Validation loss: 3.03103600573259

Epoch: 5| Step: 9
Training loss: 3.0329026898156677
Validation loss: 3.027769315713487

Epoch: 5| Step: 10
Training loss: 3.983864665540214
Validation loss: 3.0220331914496334

Epoch: 14| Step: 0
Training loss: 3.056158857800315
Validation loss: 3.0176425454256064

Epoch: 5| Step: 1
Training loss: 2.8019768412229964
Validation loss: 3.0156875953254088

Epoch: 5| Step: 2
Training loss: 3.8252547734001845
Validation loss: 3.023830751896408

Epoch: 5| Step: 3
Training loss: 3.56925310907658
Validation loss: 3.0085563891485636

Epoch: 5| Step: 4
Training loss: 3.2943967933346454
Validation loss: 3.0025706916035015

Epoch: 5| Step: 5
Training loss: 3.019307630383915
Validation loss: 2.9996291080006525

Epoch: 5| Step: 6
Training loss: 2.991496113313818
Validation loss: 2.99141561132488

Epoch: 5| Step: 7
Training loss: 3.3189408644338463
Validation loss: 2.9978723569602415

Epoch: 5| Step: 8
Training loss: 3.5444209141549794
Validation loss: 3.018696917127859

Epoch: 5| Step: 9
Training loss: 3.369346121450394
Validation loss: 2.998975342942227

Epoch: 5| Step: 10
Training loss: 3.426314587546221
Validation loss: 2.985416736715418

Epoch: 15| Step: 0
Training loss: 2.7942842386616835
Validation loss: 2.9858067681670666

Epoch: 5| Step: 1
Training loss: 3.3009395764543075
Validation loss: 2.989025857342726

Epoch: 5| Step: 2
Training loss: 3.6083098982709965
Validation loss: 2.9846531105352176

Epoch: 5| Step: 3
Training loss: 3.5447377222742946
Validation loss: 2.9710100484141937

Epoch: 5| Step: 4
Training loss: 3.551466335432995
Validation loss: 2.9675640455378085

Epoch: 5| Step: 5
Training loss: 3.120237306960098
Validation loss: 2.968660796487074

Epoch: 5| Step: 6
Training loss: 3.3230875065015515
Validation loss: 2.972485148629608

Epoch: 5| Step: 7
Training loss: 3.175321013074391
Validation loss: 2.974068286072099

Epoch: 5| Step: 8
Training loss: 3.4637247061107037
Validation loss: 2.9791000557258105

Epoch: 5| Step: 9
Training loss: 2.6509501823023895
Validation loss: 2.969488749531101

Epoch: 5| Step: 10
Training loss: 3.4228933552191796
Validation loss: 2.965822119085272

Epoch: 16| Step: 0
Training loss: 3.186463430566235
Validation loss: 2.9587589831793166

Epoch: 5| Step: 1
Training loss: 3.5976581055743044
Validation loss: 2.9575126187762453

Epoch: 5| Step: 2
Training loss: 2.855449378995513
Validation loss: 2.9643430996036297

Epoch: 5| Step: 3
Training loss: 2.8150392725425752
Validation loss: 2.961608422818476

Epoch: 5| Step: 4
Training loss: 3.793325012635914
Validation loss: 2.9563696058960622

Epoch: 5| Step: 5
Training loss: 2.934039410951163
Validation loss: 2.95424053172053

Epoch: 5| Step: 6
Training loss: 3.8246210995169974
Validation loss: 2.9501008153658814

Epoch: 5| Step: 7
Training loss: 3.241051605896605
Validation loss: 2.9527230233057797

Epoch: 5| Step: 8
Training loss: 3.63405241776968
Validation loss: 2.948842923691148

Epoch: 5| Step: 9
Training loss: 2.738822415542299
Validation loss: 2.948578951496686

Epoch: 5| Step: 10
Training loss: 2.9116128642791
Validation loss: 2.9479281766840635

Epoch: 17| Step: 0
Training loss: 3.3663487639955685
Validation loss: 2.9457049286406067

Epoch: 5| Step: 1
Training loss: 3.1474460905638035
Validation loss: 2.940896754195219

Epoch: 5| Step: 2
Training loss: 3.7907088330992167
Validation loss: 2.9398378343317626

Epoch: 5| Step: 3
Training loss: 3.5622209138471876
Validation loss: 2.938171634592045

Epoch: 5| Step: 4
Training loss: 3.599792442696268
Validation loss: 2.9368227324328195

Epoch: 5| Step: 5
Training loss: 2.4805585229202562
Validation loss: 2.934974703780981

Epoch: 5| Step: 6
Training loss: 3.197366292274036
Validation loss: 2.935384434086714

Epoch: 5| Step: 7
Training loss: 3.3029350522083303
Validation loss: 2.9338458689010376

Epoch: 5| Step: 8
Training loss: 2.974686639775423
Validation loss: 2.9394516440908953

Epoch: 5| Step: 9
Training loss: 3.2469965922082538
Validation loss: 2.9357747073374316

Epoch: 5| Step: 10
Training loss: 2.68900514194597
Validation loss: 2.939388860882325

Epoch: 18| Step: 0
Training loss: 3.3063109538295223
Validation loss: 2.941670212221651

Epoch: 5| Step: 1
Training loss: 2.868238043553447
Validation loss: 2.929033026765848

Epoch: 5| Step: 2
Training loss: 2.871006887769791
Validation loss: 2.928781066023617

Epoch: 5| Step: 3
Training loss: 2.841649547834842
Validation loss: 2.934603424374129

Epoch: 5| Step: 4
Training loss: 3.7866791140884555
Validation loss: 2.945556874202932

Epoch: 5| Step: 5
Training loss: 3.0569112737106643
Validation loss: 2.9455007540429845

Epoch: 5| Step: 6
Training loss: 3.3174936333877656
Validation loss: 2.939303716873582

Epoch: 5| Step: 7
Training loss: 3.417103266539057
Validation loss: 2.926821092642652

Epoch: 5| Step: 8
Training loss: 3.2760318499217402
Validation loss: 2.929501310167787

Epoch: 5| Step: 9
Training loss: 3.448805787539863
Validation loss: 2.9302017305337364

Epoch: 5| Step: 10
Training loss: 3.3310491046841957
Validation loss: 2.9270637288796606

Epoch: 19| Step: 0
Training loss: 3.497399999294607
Validation loss: 2.9271589232994386

Epoch: 5| Step: 1
Training loss: 3.097040911405819
Validation loss: 2.923517980987198

Epoch: 5| Step: 2
Training loss: 3.0435260854837467
Validation loss: 2.923710690652054

Epoch: 5| Step: 3
Training loss: 3.0943453437495108
Validation loss: 2.9354952759348207

Epoch: 5| Step: 4
Training loss: 3.4934153606403586
Validation loss: 2.977987235957304

Epoch: 5| Step: 5
Training loss: 3.143746717690182
Validation loss: 2.9408947910795025

Epoch: 5| Step: 6
Training loss: 3.8293471273432362
Validation loss: 2.928272832555677

Epoch: 5| Step: 7
Training loss: 3.2000211238163874
Validation loss: 2.933837125487931

Epoch: 5| Step: 8
Training loss: 3.0702837683034634
Validation loss: 2.9373299595951776

Epoch: 5| Step: 9
Training loss: 3.463682167052559
Validation loss: 2.937698785168839

Epoch: 5| Step: 10
Training loss: 2.31551092899044
Validation loss: 2.9338772107558135

Epoch: 20| Step: 0
Training loss: 3.542489049836695
Validation loss: 2.9272691579167343

Epoch: 5| Step: 1
Training loss: 3.091227880908579
Validation loss: 2.9243340705221907

Epoch: 5| Step: 2
Training loss: 3.0773071131930743
Validation loss: 2.9192927353135874

Epoch: 5| Step: 3
Training loss: 3.071152433864801
Validation loss: 2.9187137562950567

Epoch: 5| Step: 4
Training loss: 3.5830960453925615
Validation loss: 2.9206475270146326

Epoch: 5| Step: 5
Training loss: 2.9584088562114355
Validation loss: 2.928166261214751

Epoch: 5| Step: 6
Training loss: 3.2372908417878876
Validation loss: 2.9407567629763647

Epoch: 5| Step: 7
Training loss: 2.953155194486427
Validation loss: 2.9429156045373617

Epoch: 5| Step: 8
Training loss: 3.5188064760381614
Validation loss: 2.9246753948986157

Epoch: 5| Step: 9
Training loss: 3.1020518188378756
Validation loss: 2.9110472718036

Epoch: 5| Step: 10
Training loss: 3.2617072008122627
Validation loss: 2.904439578593063

Epoch: 21| Step: 0
Training loss: 3.375326352765151
Validation loss: 2.901443727235543

Epoch: 5| Step: 1
Training loss: 3.311655908678151
Validation loss: 2.901854526551737

Epoch: 5| Step: 2
Training loss: 3.071614152111343
Validation loss: 2.904288023209506

Epoch: 5| Step: 3
Training loss: 2.76051608692326
Validation loss: 2.905945094028897

Epoch: 5| Step: 4
Training loss: 3.780154487238279
Validation loss: 2.9123430513550903

Epoch: 5| Step: 5
Training loss: 3.332131280325511
Validation loss: 2.9194843469961094

Epoch: 5| Step: 6
Training loss: 3.388281931139328
Validation loss: 2.9187693858106187

Epoch: 5| Step: 7
Training loss: 3.55114703922401
Validation loss: 2.904650283733308

Epoch: 5| Step: 8
Training loss: 2.542288928127484
Validation loss: 2.8983746491876605

Epoch: 5| Step: 9
Training loss: 3.102358468490803
Validation loss: 2.896043142345067

Epoch: 5| Step: 10
Training loss: 2.8751320186655533
Validation loss: 2.9000792863450724

Epoch: 22| Step: 0
Training loss: 2.5099428819335405
Validation loss: 2.8961218596272698

Epoch: 5| Step: 1
Training loss: 2.951605027206943
Validation loss: 2.891846003983201

Epoch: 5| Step: 2
Training loss: 3.643804119879428
Validation loss: 2.8931966732367673

Epoch: 5| Step: 3
Training loss: 3.501872243122716
Validation loss: 2.8916342097952095

Epoch: 5| Step: 4
Training loss: 2.9392204927671792
Validation loss: 2.889205034872224

Epoch: 5| Step: 5
Training loss: 3.5280559576964206
Validation loss: 2.891147230001828

Epoch: 5| Step: 6
Training loss: 3.2299562206785404
Validation loss: 2.8920380131703567

Epoch: 5| Step: 7
Training loss: 2.8819783976034468
Validation loss: 2.8880444680337414

Epoch: 5| Step: 8
Training loss: 3.535936334856746
Validation loss: 2.889005761455213

Epoch: 5| Step: 9
Training loss: 3.3394553867769274
Validation loss: 2.890542334405828

Epoch: 5| Step: 10
Training loss: 2.880891816554625
Validation loss: 2.889000897731389

Epoch: 23| Step: 0
Training loss: 3.2090748677232246
Validation loss: 2.8891448084929943

Epoch: 5| Step: 1
Training loss: 2.5996994358343133
Validation loss: 2.8886577329598886

Epoch: 5| Step: 2
Training loss: 3.385183582596137
Validation loss: 2.885716557573286

Epoch: 5| Step: 3
Training loss: 3.038544519994366
Validation loss: 2.882919388243532

Epoch: 5| Step: 4
Training loss: 2.666419097216706
Validation loss: 2.8821492094998895

Epoch: 5| Step: 5
Training loss: 2.9115814201163595
Validation loss: 2.8799264082968987

Epoch: 5| Step: 6
Training loss: 3.8268728271358587
Validation loss: 2.87822954409903

Epoch: 5| Step: 7
Training loss: 3.682066972163869
Validation loss: 2.8778280657817303

Epoch: 5| Step: 8
Training loss: 3.023199816289262
Validation loss: 2.8844767105261595

Epoch: 5| Step: 9
Training loss: 2.9248932126106384
Validation loss: 2.8821238020179862

Epoch: 5| Step: 10
Training loss: 3.677988101352946
Validation loss: 2.8803977818702617

Epoch: 24| Step: 0
Training loss: 3.4155619316176686
Validation loss: 2.878421103363667

Epoch: 5| Step: 1
Training loss: 3.1632829624208134
Validation loss: 2.8750298682645807

Epoch: 5| Step: 2
Training loss: 3.2795792458648148
Validation loss: 2.873743893018008

Epoch: 5| Step: 3
Training loss: 2.8873458821175126
Validation loss: 2.8750054277794153

Epoch: 5| Step: 4
Training loss: 3.372489136493851
Validation loss: 2.8724738352265335

Epoch: 5| Step: 5
Training loss: 3.405998290674718
Validation loss: 2.8712577272407853

Epoch: 5| Step: 6
Training loss: 3.1983723434870757
Validation loss: 2.870415946261066

Epoch: 5| Step: 7
Training loss: 3.079789849084896
Validation loss: 2.870210387936719

Epoch: 5| Step: 8
Training loss: 2.9830175378266626
Validation loss: 2.8705025995264046

Epoch: 5| Step: 9
Training loss: 3.1691982456358896
Validation loss: 2.868331911921671

Epoch: 5| Step: 10
Training loss: 2.9389383568673755
Validation loss: 2.866372900870769

Epoch: 25| Step: 0
Training loss: 3.727338730043714
Validation loss: 2.8709739880518654

Epoch: 5| Step: 1
Training loss: 3.0614975826260737
Validation loss: 2.8768426778022977

Epoch: 5| Step: 2
Training loss: 3.6781432845731534
Validation loss: 2.872137029910385

Epoch: 5| Step: 3
Training loss: 2.7874780423107812
Validation loss: 2.876242463236587

Epoch: 5| Step: 4
Training loss: 3.163881951349512
Validation loss: 2.8697149923340906

Epoch: 5| Step: 5
Training loss: 3.151777214183947
Validation loss: 2.860257777305842

Epoch: 5| Step: 6
Training loss: 2.9456378949273834
Validation loss: 2.8585108538268793

Epoch: 5| Step: 7
Training loss: 2.9869345030013172
Validation loss: 2.857854026978434

Epoch: 5| Step: 8
Training loss: 3.364534753659344
Validation loss: 2.8563957309477774

Epoch: 5| Step: 9
Training loss: 2.859885581868938
Validation loss: 2.8549454676422363

Epoch: 5| Step: 10
Training loss: 3.028477137889477
Validation loss: 2.8537952069697448

Epoch: 26| Step: 0
Training loss: 2.563370440511731
Validation loss: 2.8526531907667194

Epoch: 5| Step: 1
Training loss: 2.965402422351688
Validation loss: 2.8545023235224316

Epoch: 5| Step: 2
Training loss: 3.3304700156595795
Validation loss: 2.8570148426887134

Epoch: 5| Step: 3
Training loss: 3.786797985320635
Validation loss: 2.853414515608432

Epoch: 5| Step: 4
Training loss: 3.1718718430075885
Validation loss: 2.8558130509117317

Epoch: 5| Step: 5
Training loss: 3.2887790584984082
Validation loss: 2.8730825974074725

Epoch: 5| Step: 6
Training loss: 2.7135990500407985
Validation loss: 2.887663103630678

Epoch: 5| Step: 7
Training loss: 3.6389925329640707
Validation loss: 2.879091597992509

Epoch: 5| Step: 8
Training loss: 3.4191791941479663
Validation loss: 2.8640174621532166

Epoch: 5| Step: 9
Training loss: 3.1350882390941948
Validation loss: 2.8569388158150404

Epoch: 5| Step: 10
Training loss: 2.675159510197248
Validation loss: 2.848152161914152

Epoch: 27| Step: 0
Training loss: 3.0880799401367196
Validation loss: 2.8470417233277496

Epoch: 5| Step: 1
Training loss: 3.5094923996756777
Validation loss: 2.8601934170750782

Epoch: 5| Step: 2
Training loss: 3.1309102435628957
Validation loss: 2.866198476198388

Epoch: 5| Step: 3
Training loss: 3.2216684388065215
Validation loss: 2.8687055646837547

Epoch: 5| Step: 4
Training loss: 2.7431768387863293
Validation loss: 2.8509106592126554

Epoch: 5| Step: 5
Training loss: 2.813701203582785
Validation loss: 2.846208286268946

Epoch: 5| Step: 6
Training loss: 3.1245315200600285
Validation loss: 2.84172181044165

Epoch: 5| Step: 7
Training loss: 3.1284962741511984
Validation loss: 2.84253603881163

Epoch: 5| Step: 8
Training loss: 2.736913146079603
Validation loss: 2.842264514263857

Epoch: 5| Step: 9
Training loss: 3.3360995894279077
Validation loss: 2.849338349950032

Epoch: 5| Step: 10
Training loss: 3.921892143303231
Validation loss: 2.8453168927921633

Epoch: 28| Step: 0
Training loss: 3.4854831729494227
Validation loss: 2.8461690929099883

Epoch: 5| Step: 1
Training loss: 3.1566781235204666
Validation loss: 2.8445163781788567

Epoch: 5| Step: 2
Training loss: 3.1952246021968294
Validation loss: 2.8401146592916957

Epoch: 5| Step: 3
Training loss: 3.23390761974457
Validation loss: 2.8412128116242754

Epoch: 5| Step: 4
Training loss: 2.9216409681299433
Validation loss: 2.844852878670801

Epoch: 5| Step: 5
Training loss: 2.3194064545201067
Validation loss: 2.849792916734015

Epoch: 5| Step: 6
Training loss: 3.42997139209795
Validation loss: 2.857142722386915

Epoch: 5| Step: 7
Training loss: 3.337162838025007
Validation loss: 2.857803641874246

Epoch: 5| Step: 8
Training loss: 3.3722173734403467
Validation loss: 2.8463195330923536

Epoch: 5| Step: 9
Training loss: 2.469741235993381
Validation loss: 2.8445472649938868

Epoch: 5| Step: 10
Training loss: 3.6361444103742224
Validation loss: 2.8433807216219567

Epoch: 29| Step: 0
Training loss: 2.815996497368802
Validation loss: 2.837941023080818

Epoch: 5| Step: 1
Training loss: 2.7519000165375354
Validation loss: 2.837873991359174

Epoch: 5| Step: 2
Training loss: 3.140461476182478
Validation loss: 2.834862537658787

Epoch: 5| Step: 3
Training loss: 3.1534694094126037
Validation loss: 2.8396289005781967

Epoch: 5| Step: 4
Training loss: 3.1680924735974245
Validation loss: 2.838695346224175

Epoch: 5| Step: 5
Training loss: 3.240269840683318
Validation loss: 2.833373495344489

Epoch: 5| Step: 6
Training loss: 3.1279578896929516
Validation loss: 2.835525032064214

Epoch: 5| Step: 7
Training loss: 3.8189216687564
Validation loss: 2.8339639434843473

Epoch: 5| Step: 8
Training loss: 3.0512333924413135
Validation loss: 2.829832587765343

Epoch: 5| Step: 9
Training loss: 3.5693248492902327
Validation loss: 2.826400792353303

Epoch: 5| Step: 10
Training loss: 2.5418340492373424
Validation loss: 2.828058690161862

Epoch: 30| Step: 0
Training loss: 3.3346067539320345
Validation loss: 2.83198938550264

Epoch: 5| Step: 1
Training loss: 3.4531172670303687
Validation loss: 2.8418481564275906

Epoch: 5| Step: 2
Training loss: 3.1808522033797946
Validation loss: 2.848848194128177

Epoch: 5| Step: 3
Training loss: 3.000923014745578
Validation loss: 2.8445080514521486

Epoch: 5| Step: 4
Training loss: 3.2527322288369587
Validation loss: 2.8456935342018745

Epoch: 5| Step: 5
Training loss: 3.105123402328636
Validation loss: 2.8383791406319268

Epoch: 5| Step: 6
Training loss: 3.4770489641658116
Validation loss: 2.83342293869676

Epoch: 5| Step: 7
Training loss: 3.015185072043963
Validation loss: 2.8258778191143468

Epoch: 5| Step: 8
Training loss: 2.327749746918114
Validation loss: 2.823122896473651

Epoch: 5| Step: 9
Training loss: 3.248710963567656
Validation loss: 2.8223477116290647

Epoch: 5| Step: 10
Training loss: 2.9548982009522295
Validation loss: 2.820229278764641

Epoch: 31| Step: 0
Training loss: 2.816709123852002
Validation loss: 2.826558533802253

Epoch: 5| Step: 1
Training loss: 3.171525005705679
Validation loss: 2.8877533168556617

Epoch: 5| Step: 2
Training loss: 3.7412523602428185
Validation loss: 2.8813765489685172

Epoch: 5| Step: 3
Training loss: 3.2468748472652456
Validation loss: 2.8442011938062923

Epoch: 5| Step: 4
Training loss: 3.2056630569611686
Validation loss: 2.845187325530901

Epoch: 5| Step: 5
Training loss: 2.8267099623543257
Validation loss: 2.8500430992766503

Epoch: 5| Step: 6
Training loss: 3.661670025728607
Validation loss: 2.8476966958455607

Epoch: 5| Step: 7
Training loss: 2.782455183218348
Validation loss: 2.8196952452736563

Epoch: 5| Step: 8
Training loss: 3.1718150166068564
Validation loss: 2.8190906832188087

Epoch: 5| Step: 9
Training loss: 3.402468340724326
Validation loss: 2.818442407677321

Epoch: 5| Step: 10
Training loss: 2.1918701116128303
Validation loss: 2.8248779297362794

Epoch: 32| Step: 0
Training loss: 3.2295897832149953
Validation loss: 2.834435915869819

Epoch: 5| Step: 1
Training loss: 3.3308853379243506
Validation loss: 2.8351189658586176

Epoch: 5| Step: 2
Training loss: 3.3970293306528028
Validation loss: 2.8341467490210963

Epoch: 5| Step: 3
Training loss: 2.4911159974314105
Validation loss: 2.8312535304286306

Epoch: 5| Step: 4
Training loss: 3.175388138242506
Validation loss: 2.8325249024083483

Epoch: 5| Step: 5
Training loss: 3.1103302528214285
Validation loss: 2.8289199751512473

Epoch: 5| Step: 6
Training loss: 3.534031000775307
Validation loss: 2.832805586807808

Epoch: 5| Step: 7
Training loss: 3.050270731432569
Validation loss: 2.8320935038172967

Epoch: 5| Step: 8
Training loss: 3.243035410115753
Validation loss: 2.8269795947095693

Epoch: 5| Step: 9
Training loss: 2.648645173429281
Validation loss: 2.82465991623845

Epoch: 5| Step: 10
Training loss: 3.1039186075590117
Validation loss: 2.8265745755656586

Epoch: 33| Step: 0
Training loss: 3.6588584528815344
Validation loss: 2.824676202034374

Epoch: 5| Step: 1
Training loss: 3.2447996348634773
Validation loss: 2.831295841335521

Epoch: 5| Step: 2
Training loss: 2.6446297879363905
Validation loss: 2.8218306928921093

Epoch: 5| Step: 3
Training loss: 3.219178550856936
Validation loss: 2.8232879836430795

Epoch: 5| Step: 4
Training loss: 3.0194852956258105
Validation loss: 2.8138497471613144

Epoch: 5| Step: 5
Training loss: 2.113501687108078
Validation loss: 2.8067465632359405

Epoch: 5| Step: 6
Training loss: 2.918410751591085
Validation loss: 2.810892064307615

Epoch: 5| Step: 7
Training loss: 3.133312613506664
Validation loss: 2.803625242879471

Epoch: 5| Step: 8
Training loss: 3.326200833421357
Validation loss: 2.803910693691296

Epoch: 5| Step: 9
Training loss: 3.534786647633363
Validation loss: 2.801569579159962

Epoch: 5| Step: 10
Training loss: 3.2940265228185743
Validation loss: 2.8040100645127195

Epoch: 34| Step: 0
Training loss: 2.9116423428732623
Validation loss: 2.8212770406769545

Epoch: 5| Step: 1
Training loss: 3.7233079177776767
Validation loss: 2.8386285282936674

Epoch: 5| Step: 2
Training loss: 2.919158978776521
Validation loss: 2.811084724839994

Epoch: 5| Step: 3
Training loss: 2.9884728862674272
Validation loss: 2.8044949859470827

Epoch: 5| Step: 4
Training loss: 3.3268516146124423
Validation loss: 2.7999660166862377

Epoch: 5| Step: 5
Training loss: 3.3065223740299925
Validation loss: 2.796683361669461

Epoch: 5| Step: 6
Training loss: 2.807326751282144
Validation loss: 2.800589881711923

Epoch: 5| Step: 7
Training loss: 3.107702217427627
Validation loss: 2.8002606632049165

Epoch: 5| Step: 8
Training loss: 3.2121275392724127
Validation loss: 2.7951798716121705

Epoch: 5| Step: 9
Training loss: 2.7264111321085456
Validation loss: 2.7915285841896162

Epoch: 5| Step: 10
Training loss: 3.0673750397863953
Validation loss: 2.7942570120219985

Epoch: 35| Step: 0
Training loss: 3.050679184382217
Validation loss: 2.7956751710207595

Epoch: 5| Step: 1
Training loss: 3.7216839155955386
Validation loss: 2.792098501566569

Epoch: 5| Step: 2
Training loss: 2.7639633618091946
Validation loss: 2.7927112697305545

Epoch: 5| Step: 3
Training loss: 3.443173806507073
Validation loss: 2.7997336138594897

Epoch: 5| Step: 4
Training loss: 3.277553838059255
Validation loss: 2.803643198020392

Epoch: 5| Step: 5
Training loss: 2.7359568352835746
Validation loss: 2.7860224943703487

Epoch: 5| Step: 6
Training loss: 2.455818398487082
Validation loss: 2.7834696985059235

Epoch: 5| Step: 7
Training loss: 2.6752014868604372
Validation loss: 2.7812773779341593

Epoch: 5| Step: 8
Training loss: 3.3032283943617013
Validation loss: 2.7819619727892646

Epoch: 5| Step: 9
Training loss: 3.1020528948545647
Validation loss: 2.7852024330602174

Epoch: 5| Step: 10
Training loss: 3.469222715317384
Validation loss: 2.785516029418005

Epoch: 36| Step: 0
Training loss: 3.3400137874752707
Validation loss: 2.792952339898051

Epoch: 5| Step: 1
Training loss: 2.6046668424284873
Validation loss: 2.7922603338370555

Epoch: 5| Step: 2
Training loss: 3.401542840847388
Validation loss: 2.790831574262487

Epoch: 5| Step: 3
Training loss: 2.9964755336017883
Validation loss: 2.7945328369161806

Epoch: 5| Step: 4
Training loss: 3.0285747560189775
Validation loss: 2.7849459487978874

Epoch: 5| Step: 5
Training loss: 3.0772945619958225
Validation loss: 2.7736645658890913

Epoch: 5| Step: 6
Training loss: 3.048458685476263
Validation loss: 2.7744104735668254

Epoch: 5| Step: 7
Training loss: 2.9847972631056976
Validation loss: 2.774563176536931

Epoch: 5| Step: 8
Training loss: 2.808707838433839
Validation loss: 2.7869020562813955

Epoch: 5| Step: 9
Training loss: 3.1162621981936347
Validation loss: 2.761297404384435

Epoch: 5| Step: 10
Training loss: 3.496370886362029
Validation loss: 2.7536307872115358

Epoch: 37| Step: 0
Training loss: 3.46584741619967
Validation loss: 2.756655948134142

Epoch: 5| Step: 1
Training loss: 3.1720767403323675
Validation loss: 2.759307625228996

Epoch: 5| Step: 2
Training loss: 3.290795818651797
Validation loss: 2.771342159025474

Epoch: 5| Step: 3
Training loss: 2.868818686998973
Validation loss: 2.777462222487009

Epoch: 5| Step: 4
Training loss: 3.184120031749261
Validation loss: 2.787314246472513

Epoch: 5| Step: 5
Training loss: 2.783303435007046
Validation loss: 2.774605219152285

Epoch: 5| Step: 6
Training loss: 2.5677944475839034
Validation loss: 2.761344369910764

Epoch: 5| Step: 7
Training loss: 3.0589544831375353
Validation loss: 2.7717500740368637

Epoch: 5| Step: 8
Training loss: 3.2614240136295813
Validation loss: 2.751480940851143

Epoch: 5| Step: 9
Training loss: 3.308139161786444
Validation loss: 2.746242200545461

Epoch: 5| Step: 10
Training loss: 2.7814096126404277
Validation loss: 2.744610033090557

Epoch: 38| Step: 0
Training loss: 3.1908615936226004
Validation loss: 2.744882299158171

Epoch: 5| Step: 1
Training loss: 2.461299712152255
Validation loss: 2.742588198694512

Epoch: 5| Step: 2
Training loss: 2.730540873566854
Validation loss: 2.782405352903432

Epoch: 5| Step: 3
Training loss: 2.756113798967246
Validation loss: 2.8257610852700825

Epoch: 5| Step: 4
Training loss: 3.715163352527304
Validation loss: 2.8542476924290194

Epoch: 5| Step: 5
Training loss: 3.2451452528973714
Validation loss: 2.766297450697003

Epoch: 5| Step: 6
Training loss: 3.8300883338243596
Validation loss: 2.750264664981154

Epoch: 5| Step: 7
Training loss: 3.166020745773928
Validation loss: 2.743038902026205

Epoch: 5| Step: 8
Training loss: 2.529598969199823
Validation loss: 2.7576075693912188

Epoch: 5| Step: 9
Training loss: 3.058907718060861
Validation loss: 2.775886197142399

Epoch: 5| Step: 10
Training loss: 2.9530274713144626
Validation loss: 2.78834158404187

Epoch: 39| Step: 0
Training loss: 2.771746568596657
Validation loss: 2.813694890373028

Epoch: 5| Step: 1
Training loss: 2.5679982442760703
Validation loss: 2.826135127851591

Epoch: 5| Step: 2
Training loss: 3.310839830787928
Validation loss: 2.8329832022348085

Epoch: 5| Step: 3
Training loss: 2.9020963129509596
Validation loss: 2.80471779895515

Epoch: 5| Step: 4
Training loss: 3.2914091242866634
Validation loss: 2.777427254748323

Epoch: 5| Step: 5
Training loss: 3.715552871042506
Validation loss: 2.769295501545112

Epoch: 5| Step: 6
Training loss: 3.39275859029946
Validation loss: 2.739699259061083

Epoch: 5| Step: 7
Training loss: 2.9132766277576296
Validation loss: 2.734168725268478

Epoch: 5| Step: 8
Training loss: 2.851839067816693
Validation loss: 2.7653712499269765

Epoch: 5| Step: 9
Training loss: 3.011326547855583
Validation loss: 2.749568134341792

Epoch: 5| Step: 10
Training loss: 3.279134304431434
Validation loss: 2.752427845409905

Epoch: 40| Step: 0
Training loss: 3.2365036009213486
Validation loss: 2.728192808893374

Epoch: 5| Step: 1
Training loss: 3.0960453650529445
Validation loss: 2.7279084239133553

Epoch: 5| Step: 2
Training loss: 3.25728407125845
Validation loss: 2.7282478851283614

Epoch: 5| Step: 3
Training loss: 3.839741050611928
Validation loss: 2.7311581770478774

Epoch: 5| Step: 4
Training loss: 3.12678263364461
Validation loss: 2.728168740646796

Epoch: 5| Step: 5
Training loss: 3.249361415628462
Validation loss: 2.728190104479895

Epoch: 5| Step: 6
Training loss: 2.301951293841012
Validation loss: 2.726398830153896

Epoch: 5| Step: 7
Training loss: 2.792438077863352
Validation loss: 2.729137787473938

Epoch: 5| Step: 8
Training loss: 2.9678393121596547
Validation loss: 2.7352034918935875

Epoch: 5| Step: 9
Training loss: 2.94312494530296
Validation loss: 2.7386025249414025

Epoch: 5| Step: 10
Training loss: 2.490476206088559
Validation loss: 2.74709144254817

Epoch: 41| Step: 0
Training loss: 3.102341100172392
Validation loss: 2.7366209298678656

Epoch: 5| Step: 1
Training loss: 2.9973013183822994
Validation loss: 2.7342938661038123

Epoch: 5| Step: 2
Training loss: 3.195485453133681
Validation loss: 2.7267090015006685

Epoch: 5| Step: 3
Training loss: 3.2470556273164166
Validation loss: 2.722983060036876

Epoch: 5| Step: 4
Training loss: 2.8913129657992283
Validation loss: 2.719841450999132

Epoch: 5| Step: 5
Training loss: 3.22178314403643
Validation loss: 2.7190694822802186

Epoch: 5| Step: 6
Training loss: 2.7380513789927146
Validation loss: 2.719576114060441

Epoch: 5| Step: 7
Training loss: 3.340325428990058
Validation loss: 2.7164720424670716

Epoch: 5| Step: 8
Training loss: 3.1823862980550977
Validation loss: 2.7145728059207768

Epoch: 5| Step: 9
Training loss: 2.897166999330428
Validation loss: 2.7160884741909643

Epoch: 5| Step: 10
Training loss: 2.5849983838074464
Validation loss: 2.7180641024808803

Epoch: 42| Step: 0
Training loss: 2.9602929372432034
Validation loss: 2.715607058548669

Epoch: 5| Step: 1
Training loss: 2.6921492881077804
Validation loss: 2.7146398319442393

Epoch: 5| Step: 2
Training loss: 3.176329242869266
Validation loss: 2.716459281198207

Epoch: 5| Step: 3
Training loss: 2.9025579812421762
Validation loss: 2.7148137426529124

Epoch: 5| Step: 4
Training loss: 3.3432722374254897
Validation loss: 2.7150798273272168

Epoch: 5| Step: 5
Training loss: 3.125337048474123
Validation loss: 2.71220412947036

Epoch: 5| Step: 6
Training loss: 3.0880001080073205
Validation loss: 2.7134361930753763

Epoch: 5| Step: 7
Training loss: 2.799356223075562
Validation loss: 2.7131950990537836

Epoch: 5| Step: 8
Training loss: 2.7625747497940147
Validation loss: 2.716406870844236

Epoch: 5| Step: 9
Training loss: 3.38301124605615
Validation loss: 2.734439659936276

Epoch: 5| Step: 10
Training loss: 3.1283211416969934
Validation loss: 2.744251982180735

Epoch: 43| Step: 0
Training loss: 2.7871152774825814
Validation loss: 2.754599555244445

Epoch: 5| Step: 1
Training loss: 3.5711054683034873
Validation loss: 2.7786361673101267

Epoch: 5| Step: 2
Training loss: 3.6536616105028803
Validation loss: 2.729530502473952

Epoch: 5| Step: 3
Training loss: 3.4474280127297945
Validation loss: 2.7048460388191917

Epoch: 5| Step: 4
Training loss: 2.2337961580858057
Validation loss: 2.7081144302792857

Epoch: 5| Step: 5
Training loss: 2.8912841045447886
Validation loss: 2.7292541781700344

Epoch: 5| Step: 6
Training loss: 2.6725934942037126
Validation loss: 2.7469906585403243

Epoch: 5| Step: 7
Training loss: 2.8992395653641743
Validation loss: 2.7716697715210254

Epoch: 5| Step: 8
Training loss: 2.611276721662403
Validation loss: 2.762582876186985

Epoch: 5| Step: 9
Training loss: 3.3272701114657526
Validation loss: 2.751570839330706

Epoch: 5| Step: 10
Training loss: 3.2916687269244607
Validation loss: 2.728141782605373

Epoch: 44| Step: 0
Training loss: 2.50275660171987
Validation loss: 2.719008559210693

Epoch: 5| Step: 1
Training loss: 3.5201369430173046
Validation loss: 2.706123125740405

Epoch: 5| Step: 2
Training loss: 3.376119074904582
Validation loss: 2.704427282717175

Epoch: 5| Step: 3
Training loss: 2.971440270814815
Validation loss: 2.7045115648370537

Epoch: 5| Step: 4
Training loss: 3.5057623974661762
Validation loss: 2.700603703641519

Epoch: 5| Step: 5
Training loss: 3.3910480006878037
Validation loss: 2.6950664962636774

Epoch: 5| Step: 6
Training loss: 3.396557518125961
Validation loss: 2.6944667664555317

Epoch: 5| Step: 7
Training loss: 2.5577442418744765
Validation loss: 2.6932930825049453

Epoch: 5| Step: 8
Training loss: 2.4978608516240306
Validation loss: 2.6933367078447885

Epoch: 5| Step: 9
Training loss: 1.998541956148339
Validation loss: 2.6988474588428906

Epoch: 5| Step: 10
Training loss: 3.2184888122658086
Validation loss: 2.702744044016395

Epoch: 45| Step: 0
Training loss: 3.0972827816123703
Validation loss: 2.702097497185786

Epoch: 5| Step: 1
Training loss: 3.295660726381447
Validation loss: 2.7019652141050523

Epoch: 5| Step: 2
Training loss: 2.7954013287933765
Validation loss: 2.704898865575583

Epoch: 5| Step: 3
Training loss: 2.473836848973791
Validation loss: 2.698777001791051

Epoch: 5| Step: 4
Training loss: 2.4753672125083734
Validation loss: 2.6956760355722102

Epoch: 5| Step: 5
Training loss: 3.203996493248324
Validation loss: 2.6983937038009778

Epoch: 5| Step: 6
Training loss: 3.039126358734205
Validation loss: 2.6963670196401495

Epoch: 5| Step: 7
Training loss: 3.2607455509210714
Validation loss: 2.694366196696912

Epoch: 5| Step: 8
Training loss: 2.6663046432167974
Validation loss: 2.695580436439927

Epoch: 5| Step: 9
Training loss: 3.3299688684881272
Validation loss: 2.70073128348561

Epoch: 5| Step: 10
Training loss: 3.5005120856462373
Validation loss: 2.7146094974740915

Epoch: 46| Step: 0
Training loss: 3.0874832338194502
Validation loss: 2.7294731368851233

Epoch: 5| Step: 1
Training loss: 3.59681385296533
Validation loss: 2.7244901163704887

Epoch: 5| Step: 2
Training loss: 2.968256859227084
Validation loss: 2.7138345422672687

Epoch: 5| Step: 3
Training loss: 2.2710411839918727
Validation loss: 2.697530069675229

Epoch: 5| Step: 4
Training loss: 3.1410918387000324
Validation loss: 2.6890966352044994

Epoch: 5| Step: 5
Training loss: 3.086667981185249
Validation loss: 2.688059211352379

Epoch: 5| Step: 6
Training loss: 2.924980593885945
Validation loss: 2.686557178951395

Epoch: 5| Step: 7
Training loss: 3.13256880651897
Validation loss: 2.6900671383280885

Epoch: 5| Step: 8
Training loss: 2.8435883528490873
Validation loss: 2.6875769720289537

Epoch: 5| Step: 9
Training loss: 2.7809678695397317
Validation loss: 2.6939129506245267

Epoch: 5| Step: 10
Training loss: 3.257878218246397
Validation loss: 2.7010415834216057

Epoch: 47| Step: 0
Training loss: 3.2359363270402417
Validation loss: 2.6963012327552347

Epoch: 5| Step: 1
Training loss: 2.788620857726445
Validation loss: 2.6869463081933906

Epoch: 5| Step: 2
Training loss: 3.1344108784867024
Validation loss: 2.684509616859907

Epoch: 5| Step: 3
Training loss: 2.4139153395553308
Validation loss: 2.6842684957530953

Epoch: 5| Step: 4
Training loss: 3.135806510405756
Validation loss: 2.684015725955594

Epoch: 5| Step: 5
Training loss: 3.245177873106586
Validation loss: 2.685273484679168

Epoch: 5| Step: 6
Training loss: 3.303949512659379
Validation loss: 2.6832909138599805

Epoch: 5| Step: 7
Training loss: 2.8944571172819575
Validation loss: 2.682754264212525

Epoch: 5| Step: 8
Training loss: 2.6546786877877118
Validation loss: 2.6817622881658667

Epoch: 5| Step: 9
Training loss: 3.0870918529254094
Validation loss: 2.678912127108534

Epoch: 5| Step: 10
Training loss: 3.209669173593823
Validation loss: 2.6881118406096935

Epoch: 48| Step: 0
Training loss: 3.401401393651573
Validation loss: 2.6905074570974232

Epoch: 5| Step: 1
Training loss: 2.68796269182018
Validation loss: 2.7084019812378584

Epoch: 5| Step: 2
Training loss: 3.378039933650128
Validation loss: 2.7370280418755626

Epoch: 5| Step: 3
Training loss: 2.4670516340885102
Validation loss: 2.7355145673617045

Epoch: 5| Step: 4
Training loss: 3.2385953191805945
Validation loss: 2.7199533600189487

Epoch: 5| Step: 5
Training loss: 2.885373019956767
Validation loss: 2.7040989250059706

Epoch: 5| Step: 6
Training loss: 3.171922354509118
Validation loss: 2.6997686135041343

Epoch: 5| Step: 7
Training loss: 3.573019858483668
Validation loss: 2.6941064353287323

Epoch: 5| Step: 8
Training loss: 2.0986604187269324
Validation loss: 2.68722702589842

Epoch: 5| Step: 9
Training loss: 3.2012879104484644
Validation loss: 2.6920145363235948

Epoch: 5| Step: 10
Training loss: 2.8262699850962587
Validation loss: 2.689778621370313

Epoch: 49| Step: 0
Training loss: 3.118389920717394
Validation loss: 2.687628946838126

Epoch: 5| Step: 1
Training loss: 3.4303165632253227
Validation loss: 2.681044833052124

Epoch: 5| Step: 2
Training loss: 3.26804185713036
Validation loss: 2.6824829517610214

Epoch: 5| Step: 3
Training loss: 2.880323705495183
Validation loss: 2.6757860471549075

Epoch: 5| Step: 4
Training loss: 3.535688193749269
Validation loss: 2.6754724779352843

Epoch: 5| Step: 5
Training loss: 2.7295583972850723
Validation loss: 2.6791946444374837

Epoch: 5| Step: 6
Training loss: 2.505637964113781
Validation loss: 2.6782088995685194

Epoch: 5| Step: 7
Training loss: 2.522952384496393
Validation loss: 2.6812887452723246

Epoch: 5| Step: 8
Training loss: 2.764318211330315
Validation loss: 2.685675713246268

Epoch: 5| Step: 9
Training loss: 3.36507142171125
Validation loss: 2.7052571138372725

Epoch: 5| Step: 10
Training loss: 2.730335412433056
Validation loss: 2.7093453276422172

Epoch: 50| Step: 0
Training loss: 2.4414583002264005
Validation loss: 2.742433721852174

Epoch: 5| Step: 1
Training loss: 3.070545760362397
Validation loss: 2.7949562202784906

Epoch: 5| Step: 2
Training loss: 3.403769333497671
Validation loss: 2.7871073532335737

Epoch: 5| Step: 3
Training loss: 2.853231197858424
Validation loss: 2.7359269020817627

Epoch: 5| Step: 4
Training loss: 3.8494311271597756
Validation loss: 2.7115854626863514

Epoch: 5| Step: 5
Training loss: 3.4340402011284477
Validation loss: 2.693904531434835

Epoch: 5| Step: 6
Training loss: 2.4005600673134144
Validation loss: 2.6856369272536162

Epoch: 5| Step: 7
Training loss: 3.0535118396779977
Validation loss: 2.7039356077293526

Epoch: 5| Step: 8
Training loss: 3.0102139485005166
Validation loss: 2.723456392483956

Epoch: 5| Step: 9
Training loss: 2.7888067219025605
Validation loss: 2.721441217227286

Epoch: 5| Step: 10
Training loss: 2.892871375612369
Validation loss: 2.6998775070035363

Epoch: 51| Step: 0
Training loss: 3.4287979953701266
Validation loss: 2.691233328171456

Epoch: 5| Step: 1
Training loss: 2.7225100068888386
Validation loss: 2.685503946000361

Epoch: 5| Step: 2
Training loss: 2.819513857717295
Validation loss: 2.679926739326376

Epoch: 5| Step: 3
Training loss: 3.0038148149283126
Validation loss: 2.67420786147422

Epoch: 5| Step: 4
Training loss: 2.905684221221747
Validation loss: 2.670452873329583

Epoch: 5| Step: 5
Training loss: 3.392989920405834
Validation loss: 2.6677446923031685

Epoch: 5| Step: 6
Training loss: 2.583862763164799
Validation loss: 2.6675404778876217

Epoch: 5| Step: 7
Training loss: 2.9666800259350077
Validation loss: 2.6653859661194854

Epoch: 5| Step: 8
Training loss: 3.0676315289367238
Validation loss: 2.6639890943641076

Epoch: 5| Step: 9
Training loss: 3.2698380885738487
Validation loss: 2.664943515830292

Epoch: 5| Step: 10
Training loss: 2.8982249385079575
Validation loss: 2.666503547158142

Epoch: 52| Step: 0
Training loss: 2.585803256050991
Validation loss: 2.693250921395861

Epoch: 5| Step: 1
Training loss: 3.580202657195449
Validation loss: 2.7357837241758762

Epoch: 5| Step: 2
Training loss: 3.31510592468327
Validation loss: 2.7355590675530963

Epoch: 5| Step: 3
Training loss: 3.327756906131539
Validation loss: 2.7193093484134137

Epoch: 5| Step: 4
Training loss: 2.7972219241345306
Validation loss: 2.7074280152576056

Epoch: 5| Step: 5
Training loss: 2.9479678703327417
Validation loss: 2.7078569259839678

Epoch: 5| Step: 6
Training loss: 2.8213946097263185
Validation loss: 2.713301731259778

Epoch: 5| Step: 7
Training loss: 3.037417086501794
Validation loss: 2.7118132492588702

Epoch: 5| Step: 8
Training loss: 3.079097690936751
Validation loss: 2.7122564093099997

Epoch: 5| Step: 9
Training loss: 3.0435688568041956
Validation loss: 2.716630207576836

Epoch: 5| Step: 10
Training loss: 2.594291814262152
Validation loss: 2.7105583324589557

Epoch: 53| Step: 0
Training loss: 3.025008865217349
Validation loss: 2.7039611166304334

Epoch: 5| Step: 1
Training loss: 3.0406883617358424
Validation loss: 2.699663051612098

Epoch: 5| Step: 2
Training loss: 3.104045344975184
Validation loss: 2.7015437311222623

Epoch: 5| Step: 3
Training loss: 2.792910958072323
Validation loss: 2.7034030467580754

Epoch: 5| Step: 4
Training loss: 3.2486879194433267
Validation loss: 2.701417076961357

Epoch: 5| Step: 5
Training loss: 2.8625370739530798
Validation loss: 2.7040628739400336

Epoch: 5| Step: 6
Training loss: 2.7324813825386642
Validation loss: 2.7035400386867545

Epoch: 5| Step: 7
Training loss: 2.5420199497859697
Validation loss: 2.7067130812056854

Epoch: 5| Step: 8
Training loss: 3.1002060544843193
Validation loss: 2.699964607816536

Epoch: 5| Step: 9
Training loss: 3.338155040680789
Validation loss: 2.6829686426510975

Epoch: 5| Step: 10
Training loss: 3.4126420546926735
Validation loss: 2.6828396935143393

Epoch: 54| Step: 0
Training loss: 3.3835482248798954
Validation loss: 2.6679492523869888

Epoch: 5| Step: 1
Training loss: 2.4135514493065413
Validation loss: 2.6645474171650654

Epoch: 5| Step: 2
Training loss: 3.257277483655604
Validation loss: 2.6603105801528524

Epoch: 5| Step: 3
Training loss: 3.10001394207188
Validation loss: 2.658924718727898

Epoch: 5| Step: 4
Training loss: 2.4105365768407983
Validation loss: 2.653861911415171

Epoch: 5| Step: 5
Training loss: 3.1826597376528127
Validation loss: 2.6518893675680912

Epoch: 5| Step: 6
Training loss: 2.9583329393270166
Validation loss: 2.655874055127522

Epoch: 5| Step: 7
Training loss: 2.8470640888081973
Validation loss: 2.6601089252397108

Epoch: 5| Step: 8
Training loss: 2.8795519742572333
Validation loss: 2.6854914767013405

Epoch: 5| Step: 9
Training loss: 3.3523548674549106
Validation loss: 2.700758243649455

Epoch: 5| Step: 10
Training loss: 3.0032731320369837
Validation loss: 2.697938965932413

Epoch: 55| Step: 0
Training loss: 3.262654683037957
Validation loss: 2.6914975178097205

Epoch: 5| Step: 1
Training loss: 3.1070256391191164
Validation loss: 2.681452277398796

Epoch: 5| Step: 2
Training loss: 3.049073194176359
Validation loss: 2.681984828782154

Epoch: 5| Step: 3
Training loss: 3.051575619561451
Validation loss: 2.679518829560295

Epoch: 5| Step: 4
Training loss: 3.0542756800605884
Validation loss: 2.6730704399893446

Epoch: 5| Step: 5
Training loss: 2.7673298381813063
Validation loss: 2.6633659310754783

Epoch: 5| Step: 6
Training loss: 2.866729283942687
Validation loss: 2.6509192524881215

Epoch: 5| Step: 7
Training loss: 3.0581498682635315
Validation loss: 2.645217981563867

Epoch: 5| Step: 8
Training loss: 2.5429579680370984
Validation loss: 2.6451977279713543

Epoch: 5| Step: 9
Training loss: 3.4229745709441195
Validation loss: 2.645980815993483

Epoch: 5| Step: 10
Training loss: 2.5873185356750352
Validation loss: 2.641430560993723

Epoch: 56| Step: 0
Training loss: 3.1660898754113296
Validation loss: 2.643614223933268

Epoch: 5| Step: 1
Training loss: 3.2980545609531577
Validation loss: 2.6480346106079806

Epoch: 5| Step: 2
Training loss: 2.809977693163752
Validation loss: 2.653120485920819

Epoch: 5| Step: 3
Training loss: 2.8811847671108226
Validation loss: 2.666880197846053

Epoch: 5| Step: 4
Training loss: 3.2644481820031084
Validation loss: 2.669509951098002

Epoch: 5| Step: 5
Training loss: 2.509052481061759
Validation loss: 2.6582435167896032

Epoch: 5| Step: 6
Training loss: 2.703115121459551
Validation loss: 2.667204580223422

Epoch: 5| Step: 7
Training loss: 3.292129065633673
Validation loss: 2.7008304857277103

Epoch: 5| Step: 8
Training loss: 3.4993484435561637
Validation loss: 2.7203542963946794

Epoch: 5| Step: 9
Training loss: 2.8237991548931545
Validation loss: 2.695615376009159

Epoch: 5| Step: 10
Training loss: 2.514609848763383
Validation loss: 2.6749594778404044

Epoch: 57| Step: 0
Training loss: 3.63219211982749
Validation loss: 2.6713131626505255

Epoch: 5| Step: 1
Training loss: 2.6675447766622487
Validation loss: 2.6562134307718273

Epoch: 5| Step: 2
Training loss: 2.648112499359711
Validation loss: 2.6522362096874277

Epoch: 5| Step: 3
Training loss: 2.8555283651117036
Validation loss: 2.6533727477080324

Epoch: 5| Step: 4
Training loss: 2.712802739982155
Validation loss: 2.649775855231429

Epoch: 5| Step: 5
Training loss: 2.547087116418574
Validation loss: 2.6464757196809843

Epoch: 5| Step: 6
Training loss: 3.121731994836041
Validation loss: 2.642508882133621

Epoch: 5| Step: 7
Training loss: 3.4123532274143336
Validation loss: 2.646220324172404

Epoch: 5| Step: 8
Training loss: 3.346985721982802
Validation loss: 2.6444274103519083

Epoch: 5| Step: 9
Training loss: 2.5510007988701573
Validation loss: 2.6430362692658154

Epoch: 5| Step: 10
Training loss: 3.296289184013374
Validation loss: 2.6461006483620872

Epoch: 58| Step: 0
Training loss: 2.7769939132530315
Validation loss: 2.6456281847135545

Epoch: 5| Step: 1
Training loss: 3.5206589665019594
Validation loss: 2.6445543180301074

Epoch: 5| Step: 2
Training loss: 2.805542881835244
Validation loss: 2.6445971740492724

Epoch: 5| Step: 3
Training loss: 3.775629579705156
Validation loss: 2.6445947127721197

Epoch: 5| Step: 4
Training loss: 2.770039628774814
Validation loss: 2.6424995948327923

Epoch: 5| Step: 5
Training loss: 3.1567601462047294
Validation loss: 2.6463528169083674

Epoch: 5| Step: 6
Training loss: 2.6792492744520993
Validation loss: 2.6465742123429634

Epoch: 5| Step: 7
Training loss: 2.4043150218585576
Validation loss: 2.6462411938363144

Epoch: 5| Step: 8
Training loss: 3.023955544735346
Validation loss: 2.647942024821399

Epoch: 5| Step: 9
Training loss: 3.0673266930655085
Validation loss: 2.6609171951034964

Epoch: 5| Step: 10
Training loss: 2.621945556855213
Validation loss: 2.6540500571659273

Epoch: 59| Step: 0
Training loss: 2.8266586801877946
Validation loss: 2.653068253480038

Epoch: 5| Step: 1
Training loss: 3.155890113783799
Validation loss: 2.642889335573404

Epoch: 5| Step: 2
Training loss: 3.123819814987931
Validation loss: 2.6550952580185805

Epoch: 5| Step: 3
Training loss: 3.1265056797490276
Validation loss: 2.6704912625816566

Epoch: 5| Step: 4
Training loss: 3.0942029525090815
Validation loss: 2.6437508637685707

Epoch: 5| Step: 5
Training loss: 2.961711208743449
Validation loss: 2.6399487297331823

Epoch: 5| Step: 6
Training loss: 3.1854046685188493
Validation loss: 2.6414197189565574

Epoch: 5| Step: 7
Training loss: 2.463385923165799
Validation loss: 2.647094193266556

Epoch: 5| Step: 8
Training loss: 2.990242348229899
Validation loss: 2.659523518897504

Epoch: 5| Step: 9
Training loss: 3.0088854176595032
Validation loss: 2.648836741313128

Epoch: 5| Step: 10
Training loss: 2.7575290091156797
Validation loss: 2.6451718161723927

Epoch: 60| Step: 0
Training loss: 2.7958286821655456
Validation loss: 2.6423051826831023

Epoch: 5| Step: 1
Training loss: 2.4963911712108957
Validation loss: 2.6444764330543413

Epoch: 5| Step: 2
Training loss: 2.704269784177014
Validation loss: 2.640916115473731

Epoch: 5| Step: 3
Training loss: 3.331843631377042
Validation loss: 2.643174677057377

Epoch: 5| Step: 4
Training loss: 2.568760551189648
Validation loss: 2.639268233733968

Epoch: 5| Step: 5
Training loss: 2.8170190744942523
Validation loss: 2.637928132564765

Epoch: 5| Step: 6
Training loss: 3.635905337713964
Validation loss: 2.636020613734137

Epoch: 5| Step: 7
Training loss: 3.404977123166843
Validation loss: 2.6342941812659166

Epoch: 5| Step: 8
Training loss: 3.0148826831874884
Validation loss: 2.6328767934355173

Epoch: 5| Step: 9
Training loss: 2.8102994151125227
Validation loss: 2.631598802549914

Epoch: 5| Step: 10
Training loss: 3.0787199578192097
Validation loss: 2.632380141392823

Epoch: 61| Step: 0
Training loss: 3.029912594582647
Validation loss: 2.6273144325720783

Epoch: 5| Step: 1
Training loss: 2.916768717115827
Validation loss: 2.631277464585755

Epoch: 5| Step: 2
Training loss: 2.7302428494546582
Validation loss: 2.6358482542142765

Epoch: 5| Step: 3
Training loss: 3.0359030336317163
Validation loss: 2.634736043530061

Epoch: 5| Step: 4
Training loss: 2.5536429693392844
Validation loss: 2.6374800282744575

Epoch: 5| Step: 5
Training loss: 3.03182333017333
Validation loss: 2.633892566256343

Epoch: 5| Step: 6
Training loss: 3.2944063462843314
Validation loss: 2.6437286192815534

Epoch: 5| Step: 7
Training loss: 2.5864705346001875
Validation loss: 2.6438209768721794

Epoch: 5| Step: 8
Training loss: 3.4454331841816574
Validation loss: 2.6513131171898547

Epoch: 5| Step: 9
Training loss: 3.0615260852759683
Validation loss: 2.6515428020397698

Epoch: 5| Step: 10
Training loss: 2.8324752143926917
Validation loss: 2.644169187596704

Epoch: 62| Step: 0
Training loss: 3.1923058874851673
Validation loss: 2.6749561694938593

Epoch: 5| Step: 1
Training loss: 2.893311278204938
Validation loss: 2.6892216408009406

Epoch: 5| Step: 2
Training loss: 3.097337280630004
Validation loss: 2.6956498510235103

Epoch: 5| Step: 3
Training loss: 2.754146743987065
Validation loss: 2.686931804737793

Epoch: 5| Step: 4
Training loss: 2.900467894067542
Validation loss: 2.634967447737388

Epoch: 5| Step: 5
Training loss: 2.8318418242145174
Validation loss: 2.6228710473555

Epoch: 5| Step: 6
Training loss: 3.0532872729873812
Validation loss: 2.6168351096716274

Epoch: 5| Step: 7
Training loss: 3.475813812905879
Validation loss: 2.614199338851821

Epoch: 5| Step: 8
Training loss: 2.933802773740928
Validation loss: 2.612718921871368

Epoch: 5| Step: 9
Training loss: 2.728742804384552
Validation loss: 2.616305963132593

Epoch: 5| Step: 10
Training loss: 2.8134028363192463
Validation loss: 2.6189842946137722

Epoch: 63| Step: 0
Training loss: 3.0431762154485047
Validation loss: 2.618322091670014

Epoch: 5| Step: 1
Training loss: 2.616261059208664
Validation loss: 2.6220987511770373

Epoch: 5| Step: 2
Training loss: 2.242034587896171
Validation loss: 2.6178914988849034

Epoch: 5| Step: 3
Training loss: 2.714923314088152
Validation loss: 2.621299180908022

Epoch: 5| Step: 4
Training loss: 3.3750631538416336
Validation loss: 2.620045056518092

Epoch: 5| Step: 5
Training loss: 2.955154609572821
Validation loss: 2.6148586500017545

Epoch: 5| Step: 6
Training loss: 3.695226817518805
Validation loss: 2.6125498264540514

Epoch: 5| Step: 7
Training loss: 3.063299269405526
Validation loss: 2.612188361998066

Epoch: 5| Step: 8
Training loss: 2.7653530870809298
Validation loss: 2.618899854117488

Epoch: 5| Step: 9
Training loss: 3.169450105451617
Validation loss: 2.6113448822359775

Epoch: 5| Step: 10
Training loss: 2.7327703508689454
Validation loss: 2.627044654914003

Epoch: 64| Step: 0
Training loss: 3.0604192710815177
Validation loss: 2.6363857935031167

Epoch: 5| Step: 1
Training loss: 2.766903511694939
Validation loss: 2.6411339675317396

Epoch: 5| Step: 2
Training loss: 3.5209391801863448
Validation loss: 2.6460086857097234

Epoch: 5| Step: 3
Training loss: 3.052941801574152
Validation loss: 2.6210566159334157

Epoch: 5| Step: 4
Training loss: 3.0665440230793033
Validation loss: 2.619198215580641

Epoch: 5| Step: 5
Training loss: 3.0510450730196785
Validation loss: 2.618881995008002

Epoch: 5| Step: 6
Training loss: 2.786577843690891
Validation loss: 2.62292698926205

Epoch: 5| Step: 7
Training loss: 2.9107508109606877
Validation loss: 2.629715068370101

Epoch: 5| Step: 8
Training loss: 2.919112424383721
Validation loss: 2.6404118382390327

Epoch: 5| Step: 9
Training loss: 2.4013830729700274
Validation loss: 2.665724503936026

Epoch: 5| Step: 10
Training loss: 2.927202885223743
Validation loss: 2.6667805219258245

Epoch: 65| Step: 0
Training loss: 3.3108715157011823
Validation loss: 2.6705321865735963

Epoch: 5| Step: 1
Training loss: 2.6095666872074585
Validation loss: 2.6690460880406004

Epoch: 5| Step: 2
Training loss: 3.2578925619190273
Validation loss: 2.6685341082400083

Epoch: 5| Step: 3
Training loss: 3.0385302393797233
Validation loss: 2.6369832739392214

Epoch: 5| Step: 4
Training loss: 2.8080166156092448
Validation loss: 2.6175621963205518

Epoch: 5| Step: 5
Training loss: 3.159614658038616
Validation loss: 2.6075476735559677

Epoch: 5| Step: 6
Training loss: 2.757778178317546
Validation loss: 2.610083884759513

Epoch: 5| Step: 7
Training loss: 2.811415569201142
Validation loss: 2.613931264156744

Epoch: 5| Step: 8
Training loss: 2.6375555674407867
Validation loss: 2.6131552742152526

Epoch: 5| Step: 9
Training loss: 3.390337250624727
Validation loss: 2.620269669806883

Epoch: 5| Step: 10
Training loss: 2.8089072274043345
Validation loss: 2.620361124994271

Epoch: 66| Step: 0
Training loss: 2.84802595336747
Validation loss: 2.6140885253593003

Epoch: 5| Step: 1
Training loss: 2.313220247020237
Validation loss: 2.630815996030952

Epoch: 5| Step: 2
Training loss: 3.131185741869276
Validation loss: 2.641054917815569

Epoch: 5| Step: 3
Training loss: 3.307990837785609
Validation loss: 2.638762974141284

Epoch: 5| Step: 4
Training loss: 3.123604424707261
Validation loss: 2.6333917055115608

Epoch: 5| Step: 5
Training loss: 2.889631935889855
Validation loss: 2.6274179396507837

Epoch: 5| Step: 6
Training loss: 2.637044250741935
Validation loss: 2.6277787881981487

Epoch: 5| Step: 7
Training loss: 2.9117166931128704
Validation loss: 2.6243338269411263

Epoch: 5| Step: 8
Training loss: 3.3067494986783132
Validation loss: 2.611092777016194

Epoch: 5| Step: 9
Training loss: 3.1084004317363223
Validation loss: 2.602691697014406

Epoch: 5| Step: 10
Training loss: 2.9938875553010704
Validation loss: 2.601192328916729

Epoch: 67| Step: 0
Training loss: 2.8057571963962586
Validation loss: 2.5999268530186868

Epoch: 5| Step: 1
Training loss: 3.1485907656941468
Validation loss: 2.5981644357787905

Epoch: 5| Step: 2
Training loss: 2.570763452735283
Validation loss: 2.5978579764598275

Epoch: 5| Step: 3
Training loss: 3.2093038370921527
Validation loss: 2.5985030642040856

Epoch: 5| Step: 4
Training loss: 3.016911997926831
Validation loss: 2.601651581738114

Epoch: 5| Step: 5
Training loss: 2.6918748245611193
Validation loss: 2.6007265748800132

Epoch: 5| Step: 6
Training loss: 3.236815632837157
Validation loss: 2.600067897766722

Epoch: 5| Step: 7
Training loss: 2.8322868284460294
Validation loss: 2.5994567251835132

Epoch: 5| Step: 8
Training loss: 2.7276885322565527
Validation loss: 2.605870408119805

Epoch: 5| Step: 9
Training loss: 2.8583487247983146
Validation loss: 2.606268131734729

Epoch: 5| Step: 10
Training loss: 3.402775803822747
Validation loss: 2.61649120694321

Epoch: 68| Step: 0
Training loss: 3.045651077544015
Validation loss: 2.620003180518745

Epoch: 5| Step: 1
Training loss: 2.9194820621420905
Validation loss: 2.6324524388446253

Epoch: 5| Step: 2
Training loss: 3.41658761157866
Validation loss: 2.6465467011793686

Epoch: 5| Step: 3
Training loss: 3.5061501555073002
Validation loss: 2.662623097583407

Epoch: 5| Step: 4
Training loss: 3.0577140312733464
Validation loss: 2.6572558260640013

Epoch: 5| Step: 5
Training loss: 3.0643964850963874
Validation loss: 2.633363799618172

Epoch: 5| Step: 6
Training loss: 2.7347595816323294
Validation loss: 2.6129152763455448

Epoch: 5| Step: 7
Training loss: 2.053458074438473
Validation loss: 2.603525123246227

Epoch: 5| Step: 8
Training loss: 2.931998762788811
Validation loss: 2.6017979158742177

Epoch: 5| Step: 9
Training loss: 2.6959402928858003
Validation loss: 2.597482426480974

Epoch: 5| Step: 10
Training loss: 2.8366563794868074
Validation loss: 2.5982399961162503

Epoch: 69| Step: 0
Training loss: 2.88126122726934
Validation loss: 2.5950202346996973

Epoch: 5| Step: 1
Training loss: 3.0802714807829368
Validation loss: 2.606675363062511

Epoch: 5| Step: 2
Training loss: 2.686616086870244
Validation loss: 2.6037792431172786

Epoch: 5| Step: 3
Training loss: 3.278541391581176
Validation loss: 2.610392230190004

Epoch: 5| Step: 4
Training loss: 3.147420790011169
Validation loss: 2.623518797879595

Epoch: 5| Step: 5
Training loss: 3.012965635663954
Validation loss: 2.619101212924963

Epoch: 5| Step: 6
Training loss: 2.70429420542692
Validation loss: 2.6295508281818023

Epoch: 5| Step: 7
Training loss: 2.570449500795321
Validation loss: 2.6073059324177974

Epoch: 5| Step: 8
Training loss: 2.9628069368536925
Validation loss: 2.588244676507841

Epoch: 5| Step: 9
Training loss: 2.7107327518591635
Validation loss: 2.5854864026612647

Epoch: 5| Step: 10
Training loss: 3.3323131589602863
Validation loss: 2.585485346659643

Epoch: 70| Step: 0
Training loss: 2.8900187088515894
Validation loss: 2.588306568761892

Epoch: 5| Step: 1
Training loss: 2.6364764066870725
Validation loss: 2.586420142856756

Epoch: 5| Step: 2
Training loss: 2.7723592032067605
Validation loss: 2.5836611257612203

Epoch: 5| Step: 3
Training loss: 2.722082003617401
Validation loss: 2.5886716600586657

Epoch: 5| Step: 4
Training loss: 3.2759881836488267
Validation loss: 2.5877246298076466

Epoch: 5| Step: 5
Training loss: 2.793665232215109
Validation loss: 2.590939062761317

Epoch: 5| Step: 6
Training loss: 2.583292366031142
Validation loss: 2.5872088959678092

Epoch: 5| Step: 7
Training loss: 2.9784154055885272
Validation loss: 2.5834049971766313

Epoch: 5| Step: 8
Training loss: 2.7776553466094995
Validation loss: 2.583515522698703

Epoch: 5| Step: 9
Training loss: 3.0485567586732008
Validation loss: 2.585938517648955

Epoch: 5| Step: 10
Training loss: 3.7775341092481485
Validation loss: 2.5813740959550815

Epoch: 71| Step: 0
Training loss: 3.0053616930321088
Validation loss: 2.5822658483437855

Epoch: 5| Step: 1
Training loss: 3.1847805315274993
Validation loss: 2.5898556087634863

Epoch: 5| Step: 2
Training loss: 3.2081179525898813
Validation loss: 2.5884779035479033

Epoch: 5| Step: 3
Training loss: 2.9567858091459707
Validation loss: 2.58747964163102

Epoch: 5| Step: 4
Training loss: 3.1073828981881437
Validation loss: 2.5869846814295028

Epoch: 5| Step: 5
Training loss: 3.207266758252851
Validation loss: 2.582922558141591

Epoch: 5| Step: 6
Training loss: 2.999831671760755
Validation loss: 2.580177077628203

Epoch: 5| Step: 7
Training loss: 2.796581487332223
Validation loss: 2.580878376068558

Epoch: 5| Step: 8
Training loss: 2.7800974654532227
Validation loss: 2.5825494105419042

Epoch: 5| Step: 9
Training loss: 2.57415354621518
Validation loss: 2.5828354359338994

Epoch: 5| Step: 10
Training loss: 2.2887997004447778
Validation loss: 2.5849183364342254

Epoch: 72| Step: 0
Training loss: 3.194356388223667
Validation loss: 2.5903672993132623

Epoch: 5| Step: 1
Training loss: 2.7795308832881034
Validation loss: 2.585697360330213

Epoch: 5| Step: 2
Training loss: 2.448139543059186
Validation loss: 2.5797114855922634

Epoch: 5| Step: 3
Training loss: 3.258027067368241
Validation loss: 2.586357007079132

Epoch: 5| Step: 4
Training loss: 2.8449721173091667
Validation loss: 2.5865610301164104

Epoch: 5| Step: 5
Training loss: 2.937898811701215
Validation loss: 2.587473153951018

Epoch: 5| Step: 6
Training loss: 2.5517630447468362
Validation loss: 2.5940621903876475

Epoch: 5| Step: 7
Training loss: 3.232537821277767
Validation loss: 2.608971724560213

Epoch: 5| Step: 8
Training loss: 2.8758409348325396
Validation loss: 2.6033180219123766

Epoch: 5| Step: 9
Training loss: 2.9765749953600915
Validation loss: 2.5944259361768722

Epoch: 5| Step: 10
Training loss: 3.105199569456028
Validation loss: 2.5920589908053464

Epoch: 73| Step: 0
Training loss: 2.562205693161383
Validation loss: 2.59572309615054

Epoch: 5| Step: 1
Training loss: 2.8765105549993137
Validation loss: 2.5945596361634737

Epoch: 5| Step: 2
Training loss: 3.2221301949904566
Validation loss: 2.5928588801198957

Epoch: 5| Step: 3
Training loss: 2.9849344897469785
Validation loss: 2.5863843179326977

Epoch: 5| Step: 4
Training loss: 2.707536394292054
Validation loss: 2.58009014788377

Epoch: 5| Step: 5
Training loss: 2.5676762473762795
Validation loss: 2.5752594635598096

Epoch: 5| Step: 6
Training loss: 3.440363714152435
Validation loss: 2.572774655904823

Epoch: 5| Step: 7
Training loss: 2.895409660541312
Validation loss: 2.5730503378521297

Epoch: 5| Step: 8
Training loss: 2.680708265374401
Validation loss: 2.568821924883947

Epoch: 5| Step: 9
Training loss: 3.009126292059697
Validation loss: 2.5729017598938966

Epoch: 5| Step: 10
Training loss: 3.189133618172513
Validation loss: 2.5740848749009793

Epoch: 74| Step: 0
Training loss: 3.24230662667067
Validation loss: 2.5693742999880946

Epoch: 5| Step: 1
Training loss: 2.8552628428560536
Validation loss: 2.572694932711769

Epoch: 5| Step: 2
Training loss: 2.8265347725608483
Validation loss: 2.584523879004627

Epoch: 5| Step: 3
Training loss: 2.8485879512022905
Validation loss: 2.591692181699586

Epoch: 5| Step: 4
Training loss: 3.318345149000186
Validation loss: 2.591375877708428

Epoch: 5| Step: 5
Training loss: 2.768689370621712
Validation loss: 2.597847903880444

Epoch: 5| Step: 6
Training loss: 2.7789354444530114
Validation loss: 2.596926619261755

Epoch: 5| Step: 7
Training loss: 2.9525381645559095
Validation loss: 2.599401432075726

Epoch: 5| Step: 8
Training loss: 2.686195766776638
Validation loss: 2.5760633571454603

Epoch: 5| Step: 9
Training loss: 2.4296598279548594
Validation loss: 2.568262435597748

Epoch: 5| Step: 10
Training loss: 3.4772007731327226
Validation loss: 2.56238720933509

Epoch: 75| Step: 0
Training loss: 3.331596319293351
Validation loss: 2.5642731247279684

Epoch: 5| Step: 1
Training loss: 2.942192387994645
Validation loss: 2.5631551837876994

Epoch: 5| Step: 2
Training loss: 3.046792210163276
Validation loss: 2.566689950251143

Epoch: 5| Step: 3
Training loss: 2.804161086131226
Validation loss: 2.566326860414965

Epoch: 5| Step: 4
Training loss: 2.944239737234395
Validation loss: 2.5652313372466815

Epoch: 5| Step: 5
Training loss: 2.512547286618239
Validation loss: 2.563529647347821

Epoch: 5| Step: 6
Training loss: 2.369036666715179
Validation loss: 2.5680515201655454

Epoch: 5| Step: 7
Training loss: 3.5988815159565277
Validation loss: 2.5775954790645494

Epoch: 5| Step: 8
Training loss: 3.0041592693546417
Validation loss: 2.583331385627301

Epoch: 5| Step: 9
Training loss: 2.965236793570348
Validation loss: 2.5952331013218117

Epoch: 5| Step: 10
Training loss: 2.385372800021113
Validation loss: 2.613849217346201

Epoch: 76| Step: 0
Training loss: 3.176838266061617
Validation loss: 2.60205443500445

Epoch: 5| Step: 1
Training loss: 2.3791725247695696
Validation loss: 2.5992528483968806

Epoch: 5| Step: 2
Training loss: 3.2583149401315508
Validation loss: 2.5925837381940604

Epoch: 5| Step: 3
Training loss: 3.050361555588454
Validation loss: 2.5786440240161097

Epoch: 5| Step: 4
Training loss: 2.3496733012266957
Validation loss: 2.5650718422495773

Epoch: 5| Step: 5
Training loss: 3.267988745773902
Validation loss: 2.5610730099419983

Epoch: 5| Step: 6
Training loss: 2.613097773156683
Validation loss: 2.5616710161309393

Epoch: 5| Step: 7
Training loss: 2.5831437707897846
Validation loss: 2.560342843659166

Epoch: 5| Step: 8
Training loss: 3.1795913719249262
Validation loss: 2.5619126153649683

Epoch: 5| Step: 9
Training loss: 2.884220761424958
Validation loss: 2.5662165865900075

Epoch: 5| Step: 10
Training loss: 3.1703959807962203
Validation loss: 2.5749087311431342

Epoch: 77| Step: 0
Training loss: 3.3449552271288447
Validation loss: 2.580014692927491

Epoch: 5| Step: 1
Training loss: 3.601446253292758
Validation loss: 2.5799617445636533

Epoch: 5| Step: 2
Training loss: 2.184951605708261
Validation loss: 2.5756946831325322

Epoch: 5| Step: 3
Training loss: 3.130019467326797
Validation loss: 2.5716765790854668

Epoch: 5| Step: 4
Training loss: 2.6594988532984556
Validation loss: 2.568900936977628

Epoch: 5| Step: 5
Training loss: 2.9015106607386234
Validation loss: 2.5758250627817434

Epoch: 5| Step: 6
Training loss: 2.919648490023731
Validation loss: 2.5739635283932234

Epoch: 5| Step: 7
Training loss: 2.7477696651060124
Validation loss: 2.573958242671545

Epoch: 5| Step: 8
Training loss: 2.7612742021707977
Validation loss: 2.5810313449527444

Epoch: 5| Step: 9
Training loss: 2.9672487980766795
Validation loss: 2.5909167561914295

Epoch: 5| Step: 10
Training loss: 2.489601539534605
Validation loss: 2.607715778932142

Epoch: 78| Step: 0
Training loss: 2.265596376435566
Validation loss: 2.598458951701534

Epoch: 5| Step: 1
Training loss: 2.923207351539191
Validation loss: 2.6180232876303027

Epoch: 5| Step: 2
Training loss: 3.2699430837548373
Validation loss: 2.6119696548320293

Epoch: 5| Step: 3
Training loss: 2.7563073911336025
Validation loss: 2.594966557164137

Epoch: 5| Step: 4
Training loss: 3.042896509843327
Validation loss: 2.582341592929662

Epoch: 5| Step: 5
Training loss: 3.0992256797211097
Validation loss: 2.5742603241194355

Epoch: 5| Step: 6
Training loss: 2.5865155176198313
Validation loss: 2.5751654529073527

Epoch: 5| Step: 7
Training loss: 2.8676900397254284
Validation loss: 2.5631320162960147

Epoch: 5| Step: 8
Training loss: 2.8978140846889033
Validation loss: 2.5695768190485566

Epoch: 5| Step: 9
Training loss: 3.1064542154462176
Validation loss: 2.564764164554064

Epoch: 5| Step: 10
Training loss: 3.1116856562956663
Validation loss: 2.558757972034187

Epoch: 79| Step: 0
Training loss: 2.6809359386549376
Validation loss: 2.5637922452673516

Epoch: 5| Step: 1
Training loss: 3.1641196163344025
Validation loss: 2.5634354115360654

Epoch: 5| Step: 2
Training loss: 2.89635234179431
Validation loss: 2.5632158805627294

Epoch: 5| Step: 3
Training loss: 2.8239197209972535
Validation loss: 2.5649223393534863

Epoch: 5| Step: 4
Training loss: 3.1090741035903617
Validation loss: 2.5620340363332716

Epoch: 5| Step: 5
Training loss: 2.7072169913110424
Validation loss: 2.555904658807207

Epoch: 5| Step: 6
Training loss: 2.8467389841594373
Validation loss: 2.5565612460271114

Epoch: 5| Step: 7
Training loss: 3.3540644343811388
Validation loss: 2.556637967742993

Epoch: 5| Step: 8
Training loss: 3.0072403004329966
Validation loss: 2.551841378477688

Epoch: 5| Step: 9
Training loss: 2.6294452630464513
Validation loss: 2.5545965587882775

Epoch: 5| Step: 10
Training loss: 2.6712081701692414
Validation loss: 2.556200338992913

Epoch: 80| Step: 0
Training loss: 2.6933756627952032
Validation loss: 2.558858293141051

Epoch: 5| Step: 1
Training loss: 2.8835344108484926
Validation loss: 2.5658931047166433

Epoch: 5| Step: 2
Training loss: 2.9522705456676723
Validation loss: 2.574258869644078

Epoch: 5| Step: 3
Training loss: 2.9641984279998264
Validation loss: 2.5673717965564373

Epoch: 5| Step: 4
Training loss: 3.2374961646804774
Validation loss: 2.566729361071129

Epoch: 5| Step: 5
Training loss: 2.894909297332598
Validation loss: 2.5727615186779174

Epoch: 5| Step: 6
Training loss: 2.5370952790818007
Validation loss: 2.569334432842258

Epoch: 5| Step: 7
Training loss: 3.029847912134618
Validation loss: 2.5557179064659676

Epoch: 5| Step: 8
Training loss: 2.6783556061036
Validation loss: 2.5547037597331483

Epoch: 5| Step: 9
Training loss: 3.012099819591169
Validation loss: 2.54566205466643

Epoch: 5| Step: 10
Training loss: 3.0219009792785156
Validation loss: 2.544799837018861

Epoch: 81| Step: 0
Training loss: 3.199147355211073
Validation loss: 2.5490726210195715

Epoch: 5| Step: 1
Training loss: 2.6160134486223123
Validation loss: 2.5452074190351976

Epoch: 5| Step: 2
Training loss: 2.9359363695988043
Validation loss: 2.5465828809639017

Epoch: 5| Step: 3
Training loss: 3.1077890616751445
Validation loss: 2.546787505311278

Epoch: 5| Step: 4
Training loss: 2.7736020321464743
Validation loss: 2.5470082690860196

Epoch: 5| Step: 5
Training loss: 3.1077203229656827
Validation loss: 2.5482725104950346

Epoch: 5| Step: 6
Training loss: 2.643497958242206
Validation loss: 2.5475668672976597

Epoch: 5| Step: 7
Training loss: 2.9636937500737277
Validation loss: 2.5539422479950478

Epoch: 5| Step: 8
Training loss: 2.4587214104328887
Validation loss: 2.5579049083741063

Epoch: 5| Step: 9
Training loss: 3.1958199916463297
Validation loss: 2.5544171465753687

Epoch: 5| Step: 10
Training loss: 2.81358884291423
Validation loss: 2.56076178033676

Epoch: 82| Step: 0
Training loss: 3.017889091986848
Validation loss: 2.583597469091181

Epoch: 5| Step: 1
Training loss: 3.291122552509956
Validation loss: 2.5850107775251447

Epoch: 5| Step: 2
Training loss: 2.7518703862484477
Validation loss: 2.6081311972355046

Epoch: 5| Step: 3
Training loss: 3.2576453442765856
Validation loss: 2.6038508174869897

Epoch: 5| Step: 4
Training loss: 3.064730085277571
Validation loss: 2.614255870345657

Epoch: 5| Step: 5
Training loss: 3.0983327196711246
Validation loss: 2.6017864120712493

Epoch: 5| Step: 6
Training loss: 2.1215948984614124
Validation loss: 2.5757688274393336

Epoch: 5| Step: 7
Training loss: 2.5091006574391104
Validation loss: 2.560860886713192

Epoch: 5| Step: 8
Training loss: 2.9827942181721867
Validation loss: 2.550702046486614

Epoch: 5| Step: 9
Training loss: 2.851184224160645
Validation loss: 2.538979248499462

Epoch: 5| Step: 10
Training loss: 2.9346437568804435
Validation loss: 2.5420204560555884

Epoch: 83| Step: 0
Training loss: 2.7051681999330834
Validation loss: 2.5428606833279876

Epoch: 5| Step: 1
Training loss: 2.8883747311674233
Validation loss: 2.5411470040993485

Epoch: 5| Step: 2
Training loss: 2.9911329836499925
Validation loss: 2.540625211740941

Epoch: 5| Step: 3
Training loss: 2.678349285905098
Validation loss: 2.5440449520505086

Epoch: 5| Step: 4
Training loss: 2.3912753548202685
Validation loss: 2.545437734716772

Epoch: 5| Step: 5
Training loss: 3.0257397149207548
Validation loss: 2.562083121624454

Epoch: 5| Step: 6
Training loss: 3.3180979804805113
Validation loss: 2.5711228609622108

Epoch: 5| Step: 7
Training loss: 2.9271846405272712
Validation loss: 2.553027689039451

Epoch: 5| Step: 8
Training loss: 2.779968395053501
Validation loss: 2.543916928279389

Epoch: 5| Step: 9
Training loss: 3.1711766268098804
Validation loss: 2.540675597591453

Epoch: 5| Step: 10
Training loss: 2.984437632277986
Validation loss: 2.5355699491956747

Epoch: 84| Step: 0
Training loss: 3.151947715112627
Validation loss: 2.53759670811814

Epoch: 5| Step: 1
Training loss: 2.816840065654217
Validation loss: 2.532055719347379

Epoch: 5| Step: 2
Training loss: 3.453360709176368
Validation loss: 2.534206918287228

Epoch: 5| Step: 3
Training loss: 2.7285554701367682
Validation loss: 2.540227346983973

Epoch: 5| Step: 4
Training loss: 2.959028851769693
Validation loss: 2.54693229606315

Epoch: 5| Step: 5
Training loss: 2.796710473021773
Validation loss: 2.5579182982969035

Epoch: 5| Step: 6
Training loss: 2.490929360740725
Validation loss: 2.5598400696041

Epoch: 5| Step: 7
Training loss: 2.8077668947858405
Validation loss: 2.566840712494437

Epoch: 5| Step: 8
Training loss: 3.010458993229197
Validation loss: 2.549645984066532

Epoch: 5| Step: 9
Training loss: 2.250871807317079
Validation loss: 2.5440652863993964

Epoch: 5| Step: 10
Training loss: 3.238329400416676
Validation loss: 2.542009295913474

Epoch: 85| Step: 0
Training loss: 2.4952791463764257
Validation loss: 2.5352462675971985

Epoch: 5| Step: 1
Training loss: 2.691543730614198
Validation loss: 2.5330239555011462

Epoch: 5| Step: 2
Training loss: 3.1047707978945076
Validation loss: 2.540520935466134

Epoch: 5| Step: 3
Training loss: 3.416658928715077
Validation loss: 2.534221332742206

Epoch: 5| Step: 4
Training loss: 2.4269735505211423
Validation loss: 2.5367489152406075

Epoch: 5| Step: 5
Training loss: 3.037049399025973
Validation loss: 2.536676260083116

Epoch: 5| Step: 6
Training loss: 2.5738121255692015
Validation loss: 2.533158572653195

Epoch: 5| Step: 7
Training loss: 2.946862741163692
Validation loss: 2.532365597421494

Epoch: 5| Step: 8
Training loss: 2.6878464941175384
Validation loss: 2.5345184248363584

Epoch: 5| Step: 9
Training loss: 3.066484156305325
Validation loss: 2.536867941017525

Epoch: 5| Step: 10
Training loss: 3.229351768520833
Validation loss: 2.544438655165615

Epoch: 86| Step: 0
Training loss: 2.6941596620254087
Validation loss: 2.54264933651474

Epoch: 5| Step: 1
Training loss: 3.0763216109390554
Validation loss: 2.563070165778939

Epoch: 5| Step: 2
Training loss: 2.708434870846164
Validation loss: 2.580862116346232

Epoch: 5| Step: 3
Training loss: 2.9273120252296643
Validation loss: 2.578787751837903

Epoch: 5| Step: 4
Training loss: 3.36034106181155
Validation loss: 2.5814477494142887

Epoch: 5| Step: 5
Training loss: 2.788789623599684
Validation loss: 2.548058189758889

Epoch: 5| Step: 6
Training loss: 2.90187399593667
Validation loss: 2.5371794108482644

Epoch: 5| Step: 7
Training loss: 2.7873894297476354
Validation loss: 2.5305753715582178

Epoch: 5| Step: 8
Training loss: 3.0812775399793746
Validation loss: 2.5279849663664247

Epoch: 5| Step: 9
Training loss: 2.6749897252536132
Validation loss: 2.52694910003677

Epoch: 5| Step: 10
Training loss: 2.5898523114783543
Validation loss: 2.5272930953134884

Epoch: 87| Step: 0
Training loss: 2.8321113943401257
Validation loss: 2.5304773210496236

Epoch: 5| Step: 1
Training loss: 2.8110627634701535
Validation loss: 2.529172556556171

Epoch: 5| Step: 2
Training loss: 3.2007705595188507
Validation loss: 2.529460416666276

Epoch: 5| Step: 3
Training loss: 2.92975423101085
Validation loss: 2.5297874652415393

Epoch: 5| Step: 4
Training loss: 2.7045379650225003
Validation loss: 2.532782871987824

Epoch: 5| Step: 5
Training loss: 3.273029019673221
Validation loss: 2.533772129512799

Epoch: 5| Step: 6
Training loss: 3.390970098275339
Validation loss: 2.536998514299401

Epoch: 5| Step: 7
Training loss: 2.2046869030579233
Validation loss: 2.5343307368854644

Epoch: 5| Step: 8
Training loss: 2.5573285651150917
Validation loss: 2.538905041579091

Epoch: 5| Step: 9
Training loss: 2.8963671587880326
Validation loss: 2.5453645077292886

Epoch: 5| Step: 10
Training loss: 2.7754688829077176
Validation loss: 2.5720514984546754

Epoch: 88| Step: 0
Training loss: 2.985105894373357
Validation loss: 2.5703319114083976

Epoch: 5| Step: 1
Training loss: 2.344303930309288
Validation loss: 2.5659081379640347

Epoch: 5| Step: 2
Training loss: 3.087686163969384
Validation loss: 2.5616361260878504

Epoch: 5| Step: 3
Training loss: 3.344712448647229
Validation loss: 2.5628763758317095

Epoch: 5| Step: 4
Training loss: 3.1036800199340293
Validation loss: 2.550782627408801

Epoch: 5| Step: 5
Training loss: 2.9623561067684125
Validation loss: 2.5473435534159212

Epoch: 5| Step: 6
Training loss: 2.86133829056428
Validation loss: 2.5403775786218

Epoch: 5| Step: 7
Training loss: 2.3626020984689102
Validation loss: 2.536948745605139

Epoch: 5| Step: 8
Training loss: 2.8413293617801965
Validation loss: 2.5313631490993465

Epoch: 5| Step: 9
Training loss: 2.8135080862083313
Validation loss: 2.528112158223078

Epoch: 5| Step: 10
Training loss: 2.8221331608187055
Validation loss: 2.528240181246706

Epoch: 89| Step: 0
Training loss: 2.724314815226643
Validation loss: 2.5267604845815583

Epoch: 5| Step: 1
Training loss: 3.038791830762754
Validation loss: 2.528209080599647

Epoch: 5| Step: 2
Training loss: 2.9751136437516643
Validation loss: 2.5276379403661564

Epoch: 5| Step: 3
Training loss: 3.3207405801708534
Validation loss: 2.5290919809531176

Epoch: 5| Step: 4
Training loss: 2.827202409350972
Validation loss: 2.531595850360632

Epoch: 5| Step: 5
Training loss: 2.716537276699107
Validation loss: 2.5317840478686073

Epoch: 5| Step: 6
Training loss: 2.6237952783029908
Validation loss: 2.528122442731364

Epoch: 5| Step: 7
Training loss: 3.0283426716362576
Validation loss: 2.5332456626871838

Epoch: 5| Step: 8
Training loss: 3.1359924767754292
Validation loss: 2.535880321845529

Epoch: 5| Step: 9
Training loss: 2.3490561882889316
Validation loss: 2.546490513713827

Epoch: 5| Step: 10
Training loss: 2.708744888336048
Validation loss: 2.552752980082379

Epoch: 90| Step: 0
Training loss: 2.824363947469177
Validation loss: 2.56593992864853

Epoch: 5| Step: 1
Training loss: 2.4408638069262287
Validation loss: 2.5706311848162695

Epoch: 5| Step: 2
Training loss: 2.9928167493235764
Validation loss: 2.585894682044912

Epoch: 5| Step: 3
Training loss: 2.905699647045918
Validation loss: 2.589131977260247

Epoch: 5| Step: 4
Training loss: 3.138517061414132
Validation loss: 2.581466900320073

Epoch: 5| Step: 5
Training loss: 3.090745950922219
Validation loss: 2.5673311783510067

Epoch: 5| Step: 6
Training loss: 3.478238299804522
Validation loss: 2.5587091966735236

Epoch: 5| Step: 7
Training loss: 2.675887190677639
Validation loss: 2.52606529645119

Epoch: 5| Step: 8
Training loss: 3.086465447570313
Validation loss: 2.5205549013291773

Epoch: 5| Step: 9
Training loss: 2.2626008996541396
Validation loss: 2.5298996978291095

Epoch: 5| Step: 10
Training loss: 2.6670890910626754
Validation loss: 2.5405267418230717

Epoch: 91| Step: 0
Training loss: 2.6784669637745195
Validation loss: 2.544464839153152

Epoch: 5| Step: 1
Training loss: 2.994606096350945
Validation loss: 2.548172508065152

Epoch: 5| Step: 2
Training loss: 3.2487988820055045
Validation loss: 2.5464237985377145

Epoch: 5| Step: 3
Training loss: 3.4883208918695137
Validation loss: 2.5357312937673866

Epoch: 5| Step: 4
Training loss: 3.1295381781788825
Validation loss: 2.529278053792988

Epoch: 5| Step: 5
Training loss: 2.725052467331048
Validation loss: 2.5212717833486398

Epoch: 5| Step: 6
Training loss: 2.763832243994399
Validation loss: 2.5164770274381416

Epoch: 5| Step: 7
Training loss: 2.529042541206441
Validation loss: 2.520683099684866

Epoch: 5| Step: 8
Training loss: 2.1663895087381118
Validation loss: 2.528422567266341

Epoch: 5| Step: 9
Training loss: 2.9322181453036453
Validation loss: 2.539050911876149

Epoch: 5| Step: 10
Training loss: 3.1131167493985417
Validation loss: 2.560996081740011

Epoch: 92| Step: 0
Training loss: 2.944741272109991
Validation loss: 2.5721761833529406

Epoch: 5| Step: 1
Training loss: 3.0000521337429755
Validation loss: 2.5777837712060636

Epoch: 5| Step: 2
Training loss: 2.5391316096363905
Validation loss: 2.56623926470269

Epoch: 5| Step: 3
Training loss: 2.8764439149664063
Validation loss: 2.5811329397612703

Epoch: 5| Step: 4
Training loss: 2.877942445414121
Validation loss: 2.5507488341953093

Epoch: 5| Step: 5
Training loss: 2.946969373209247
Validation loss: 2.5262047425229333

Epoch: 5| Step: 6
Training loss: 2.531549883374159
Validation loss: 2.513458430803666

Epoch: 5| Step: 7
Training loss: 2.724703179388809
Validation loss: 2.5123173312961242

Epoch: 5| Step: 8
Training loss: 3.286596102882349
Validation loss: 2.5140156679288395

Epoch: 5| Step: 9
Training loss: 2.9221599256340243
Validation loss: 2.5213954674714714

Epoch: 5| Step: 10
Training loss: 2.9028878401515965
Validation loss: 2.526205817216053

Epoch: 93| Step: 0
Training loss: 3.4792013718631063
Validation loss: 2.5288179381954263

Epoch: 5| Step: 1
Training loss: 3.020748549400637
Validation loss: 2.5300909984636863

Epoch: 5| Step: 2
Training loss: 2.756869146651733
Validation loss: 2.527655753463954

Epoch: 5| Step: 3
Training loss: 2.694030633810277
Validation loss: 2.5237475921255794

Epoch: 5| Step: 4
Training loss: 2.86380179176469
Validation loss: 2.519570600757684

Epoch: 5| Step: 5
Training loss: 3.268343729187109
Validation loss: 2.5084939819845347

Epoch: 5| Step: 6
Training loss: 2.881810290624187
Validation loss: 2.506378070270888

Epoch: 5| Step: 7
Training loss: 2.9371342532756546
Validation loss: 2.5072533719539933

Epoch: 5| Step: 8
Training loss: 2.3701247320066883
Validation loss: 2.507740822586396

Epoch: 5| Step: 9
Training loss: 2.950502068419799
Validation loss: 2.5164652802976577

Epoch: 5| Step: 10
Training loss: 2.489496769590594
Validation loss: 2.5227979396065265

Epoch: 94| Step: 0
Training loss: 2.6054372714084177
Validation loss: 2.5251921764283676

Epoch: 5| Step: 1
Training loss: 2.35058857466356
Validation loss: 2.5277221698662733

Epoch: 5| Step: 2
Training loss: 2.7222518292155633
Validation loss: 2.5367844002204185

Epoch: 5| Step: 3
Training loss: 2.77093909116755
Validation loss: 2.5453286518629996

Epoch: 5| Step: 4
Training loss: 3.239538227188412
Validation loss: 2.5448039472224195

Epoch: 5| Step: 5
Training loss: 3.185436403568082
Validation loss: 2.5270105842789956

Epoch: 5| Step: 6
Training loss: 3.148413721946113
Validation loss: 2.5234458661852677

Epoch: 5| Step: 7
Training loss: 2.9198181746322147
Validation loss: 2.5158952422510885

Epoch: 5| Step: 8
Training loss: 3.1128758031257906
Validation loss: 2.512493543964014

Epoch: 5| Step: 9
Training loss: 2.5865926690512366
Validation loss: 2.5127853460895766

Epoch: 5| Step: 10
Training loss: 2.806289088055567
Validation loss: 2.514348491872276

Epoch: 95| Step: 0
Training loss: 2.5928475522010697
Validation loss: 2.5173896302694128

Epoch: 5| Step: 1
Training loss: 2.6346189374648077
Validation loss: 2.520481840392087

Epoch: 5| Step: 2
Training loss: 2.8031739637846655
Validation loss: 2.5272934442608737

Epoch: 5| Step: 3
Training loss: 2.906361895632371
Validation loss: 2.5476987699205207

Epoch: 5| Step: 4
Training loss: 3.1919293015856103
Validation loss: 2.5557965222163364

Epoch: 5| Step: 5
Training loss: 2.5912833377001974
Validation loss: 2.550162795192829

Epoch: 5| Step: 6
Training loss: 2.9020935197164435
Validation loss: 2.5551003706435056

Epoch: 5| Step: 7
Training loss: 2.703811470140707
Validation loss: 2.555327565431061

Epoch: 5| Step: 8
Training loss: 2.962726143362144
Validation loss: 2.54931187543024

Epoch: 5| Step: 9
Training loss: 3.2379575781585066
Validation loss: 2.5435456801522265

Epoch: 5| Step: 10
Training loss: 2.99550816907232
Validation loss: 2.526779397591528

Epoch: 96| Step: 0
Training loss: 2.583262924547424
Validation loss: 2.5143874119079315

Epoch: 5| Step: 1
Training loss: 3.308131089903089
Validation loss: 2.508216379426409

Epoch: 5| Step: 2
Training loss: 2.538511339668341
Validation loss: 2.506428265971958

Epoch: 5| Step: 3
Training loss: 2.900789442803371
Validation loss: 2.5164745987562354

Epoch: 5| Step: 4
Training loss: 2.676916263181243
Validation loss: 2.5114705501479455

Epoch: 5| Step: 5
Training loss: 2.9432830699403283
Validation loss: 2.5177012844228766

Epoch: 5| Step: 6
Training loss: 3.0541663932713434
Validation loss: 2.5218129835468055

Epoch: 5| Step: 7
Training loss: 2.4108479154980675
Validation loss: 2.5229744140387136

Epoch: 5| Step: 8
Training loss: 2.9365364279933814
Validation loss: 2.523130054184674

Epoch: 5| Step: 9
Training loss: 3.148698289544284
Validation loss: 2.527641936482831

Epoch: 5| Step: 10
Training loss: 3.057617655351689
Validation loss: 2.5276275342052723

Epoch: 97| Step: 0
Training loss: 2.8099595358164904
Validation loss: 2.527505034445993

Epoch: 5| Step: 1
Training loss: 2.7003937963894478
Validation loss: 2.5199848911036256

Epoch: 5| Step: 2
Training loss: 3.229387796685594
Validation loss: 2.512961386176666

Epoch: 5| Step: 3
Training loss: 2.758422179006154
Validation loss: 2.5127011586699193

Epoch: 5| Step: 4
Training loss: 2.8582381192763444
Validation loss: 2.5127613713880446

Epoch: 5| Step: 5
Training loss: 2.561977891533282
Validation loss: 2.51054121472783

Epoch: 5| Step: 6
Training loss: 2.9168569956849733
Validation loss: 2.512856754636148

Epoch: 5| Step: 7
Training loss: 2.7071438060001074
Validation loss: 2.5152929911508575

Epoch: 5| Step: 8
Training loss: 3.468143581959999
Validation loss: 2.508725029655627

Epoch: 5| Step: 9
Training loss: 2.402899254562222
Validation loss: 2.513220846173798

Epoch: 5| Step: 10
Training loss: 2.896504459324332
Validation loss: 2.51804171061296

Epoch: 98| Step: 0
Training loss: 2.937965193903907
Validation loss: 2.517908742081938

Epoch: 5| Step: 1
Training loss: 2.773097917425807
Validation loss: 2.516628675847065

Epoch: 5| Step: 2
Training loss: 2.454071639789722
Validation loss: 2.5235286909388086

Epoch: 5| Step: 3
Training loss: 2.9924599944255403
Validation loss: 2.528094063390116

Epoch: 5| Step: 4
Training loss: 2.5699549835062356
Validation loss: 2.544356047090139

Epoch: 5| Step: 5
Training loss: 2.9529011959465326
Validation loss: 2.5352462675971985

Epoch: 5| Step: 6
Training loss: 3.1900262732305773
Validation loss: 2.538461689002217

Epoch: 5| Step: 7
Training loss: 2.2949581321936416
Validation loss: 2.5335243851176457

Epoch: 5| Step: 8
Training loss: 3.4791666971233313
Validation loss: 2.5307400603881147

Epoch: 5| Step: 9
Training loss: 2.8593780017274204
Validation loss: 2.5352178314868534

Epoch: 5| Step: 10
Training loss: 2.625959947447669
Validation loss: 2.541715112792987

Epoch: 99| Step: 0
Training loss: 2.617554505080391
Validation loss: 2.5431697478644204

Epoch: 5| Step: 1
Training loss: 2.113674839337057
Validation loss: 2.5263056135202047

Epoch: 5| Step: 2
Training loss: 3.1212152068338073
Validation loss: 2.5246008091308942

Epoch: 5| Step: 3
Training loss: 3.015847627792641
Validation loss: 2.5136691784390273

Epoch: 5| Step: 4
Training loss: 3.608848236089388
Validation loss: 2.5082989568674408

Epoch: 5| Step: 5
Training loss: 2.7055389562624597
Validation loss: 2.510637503297085

Epoch: 5| Step: 6
Training loss: 2.5449011707415186
Validation loss: 2.5124958295628868

Epoch: 5| Step: 7
Training loss: 2.745349593283752
Validation loss: 2.509989195596427

Epoch: 5| Step: 8
Training loss: 3.366767449963509
Validation loss: 2.509056147121337

Epoch: 5| Step: 9
Training loss: 2.8357794431247343
Validation loss: 2.5110376531446468

Epoch: 5| Step: 10
Training loss: 2.312763817662288
Validation loss: 2.510028884900273

Epoch: 100| Step: 0
Training loss: 3.3612502430965043
Validation loss: 2.5121282453805365

Epoch: 5| Step: 1
Training loss: 2.4282716998899296
Validation loss: 2.5182744945216715

Epoch: 5| Step: 2
Training loss: 3.4446153000189312
Validation loss: 2.5155904445620045

Epoch: 5| Step: 3
Training loss: 2.629201251818639
Validation loss: 2.5189254949580993

Epoch: 5| Step: 4
Training loss: 2.640306984074732
Validation loss: 2.5202888125078444

Epoch: 5| Step: 5
Training loss: 2.535125967353323
Validation loss: 2.5090281764226114

Epoch: 5| Step: 6
Training loss: 2.697703486873303
Validation loss: 2.5074868573313314

Epoch: 5| Step: 7
Training loss: 2.4230670579423004
Validation loss: 2.510216543412485

Epoch: 5| Step: 8
Training loss: 3.2286411637154857
Validation loss: 2.517453597513513

Epoch: 5| Step: 9
Training loss: 2.945042119655991
Validation loss: 2.5074037787383743

Epoch: 5| Step: 10
Training loss: 2.770952341683778
Validation loss: 2.511907434518663

Epoch: 101| Step: 0
Training loss: 3.166645568643524
Validation loss: 2.511685774937928

Epoch: 5| Step: 1
Training loss: 3.016217425566097
Validation loss: 2.518057090118792

Epoch: 5| Step: 2
Training loss: 3.08912467064279
Validation loss: 2.511077404488707

Epoch: 5| Step: 3
Training loss: 2.557584653853553
Validation loss: 2.5206260002649716

Epoch: 5| Step: 4
Training loss: 2.508807783996174
Validation loss: 2.5295910550990968

Epoch: 5| Step: 5
Training loss: 2.9945038676533904
Validation loss: 2.533325810683026

Epoch: 5| Step: 6
Training loss: 2.865818122837455
Validation loss: 2.5363950519122267

Epoch: 5| Step: 7
Training loss: 2.8492062383512478
Validation loss: 2.53064336461582

Epoch: 5| Step: 8
Training loss: 2.696717269369243
Validation loss: 2.5269304591758295

Epoch: 5| Step: 9
Training loss: 2.406377021112198
Validation loss: 2.5275327073580582

Epoch: 5| Step: 10
Training loss: 3.1976646961927297
Validation loss: 2.524995888059215

Epoch: 102| Step: 0
Training loss: 2.8122060834107643
Validation loss: 2.5147444230248728

Epoch: 5| Step: 1
Training loss: 2.997200772555669
Validation loss: 2.4967291415775534

Epoch: 5| Step: 2
Training loss: 3.0264771630147007
Validation loss: 2.495349239506522

Epoch: 5| Step: 3
Training loss: 3.2209992188787595
Validation loss: 2.4885276718390683

Epoch: 5| Step: 4
Training loss: 2.805839535742501
Validation loss: 2.4928178628123017

Epoch: 5| Step: 5
Training loss: 2.675944302456812
Validation loss: 2.4921864877876776

Epoch: 5| Step: 6
Training loss: 3.1278796851490416
Validation loss: 2.4906538734281165

Epoch: 5| Step: 7
Training loss: 2.0686353115779323
Validation loss: 2.496425063037842

Epoch: 5| Step: 8
Training loss: 2.611184229627371
Validation loss: 2.4898010177958603

Epoch: 5| Step: 9
Training loss: 2.624741132778454
Validation loss: 2.4917628675867753

Epoch: 5| Step: 10
Training loss: 3.2473428574528587
Validation loss: 2.487968937405302

Epoch: 103| Step: 0
Training loss: 1.6469970484176157
Validation loss: 2.489908239831287

Epoch: 5| Step: 1
Training loss: 2.8284883213081957
Validation loss: 2.49296118006851

Epoch: 5| Step: 2
Training loss: 2.9655444054862246
Validation loss: 2.4947256327468286

Epoch: 5| Step: 3
Training loss: 3.0989827302031174
Validation loss: 2.5073370439537883

Epoch: 5| Step: 4
Training loss: 3.257491647119711
Validation loss: 2.5053634863279743

Epoch: 5| Step: 5
Training loss: 3.0072761354660877
Validation loss: 2.517119904927009

Epoch: 5| Step: 6
Training loss: 2.8680624809109685
Validation loss: 2.514025394183689

Epoch: 5| Step: 7
Training loss: 2.998726892545271
Validation loss: 2.5165140655655147

Epoch: 5| Step: 8
Training loss: 2.814039275366363
Validation loss: 2.5080568883715455

Epoch: 5| Step: 9
Training loss: 2.883577736288422
Validation loss: 2.50254799143588

Epoch: 5| Step: 10
Training loss: 2.5574161061597245
Validation loss: 2.5001761323144405

Epoch: 104| Step: 0
Training loss: 2.779927657304447
Validation loss: 2.5014485008343517

Epoch: 5| Step: 1
Training loss: 2.680143890218925
Validation loss: 2.4943896026664474

Epoch: 5| Step: 2
Training loss: 2.3537015089650692
Validation loss: 2.4994575968305828

Epoch: 5| Step: 3
Training loss: 2.849347317563866
Validation loss: 2.501593940985483

Epoch: 5| Step: 4
Training loss: 2.9240097978169453
Validation loss: 2.502482475834145

Epoch: 5| Step: 5
Training loss: 2.7755175030650694
Validation loss: 2.5019506376469502

Epoch: 5| Step: 6
Training loss: 2.461445395723153
Validation loss: 2.4999133884644587

Epoch: 5| Step: 7
Training loss: 3.234314553990578
Validation loss: 2.502937695120241

Epoch: 5| Step: 8
Training loss: 3.03994698879802
Validation loss: 2.5051652472564037

Epoch: 5| Step: 9
Training loss: 3.063150764922056
Validation loss: 2.5030183025079644

Epoch: 5| Step: 10
Training loss: 2.975484978390652
Validation loss: 2.507214349355125

Epoch: 105| Step: 0
Training loss: 2.6711479223916297
Validation loss: 2.514886030996899

Epoch: 5| Step: 1
Training loss: 3.3130750336951387
Validation loss: 2.5274415934330636

Epoch: 5| Step: 2
Training loss: 3.2828420500625946
Validation loss: 2.536564389992514

Epoch: 5| Step: 3
Training loss: 2.8523712265542693
Validation loss: 2.551554976302401

Epoch: 5| Step: 4
Training loss: 2.866066196302757
Validation loss: 2.541519460007648

Epoch: 5| Step: 5
Training loss: 2.625835921386037
Validation loss: 2.5350623671569554

Epoch: 5| Step: 6
Training loss: 3.0614477412890855
Validation loss: 2.515557899362341

Epoch: 5| Step: 7
Training loss: 3.0638950829334273
Validation loss: 2.504297731875002

Epoch: 5| Step: 8
Training loss: 2.602098564386395
Validation loss: 2.4873748868208105

Epoch: 5| Step: 9
Training loss: 2.304543287000206
Validation loss: 2.4866201717089234

Epoch: 5| Step: 10
Training loss: 2.441641590219648
Validation loss: 2.48530876621971

Epoch: 106| Step: 0
Training loss: 3.484992139416098
Validation loss: 2.490679788086586

Epoch: 5| Step: 1
Training loss: 3.0780397974605487
Validation loss: 2.4872582111820236

Epoch: 5| Step: 2
Training loss: 2.9494417017859305
Validation loss: 2.486602601788692

Epoch: 5| Step: 3
Training loss: 2.4085146663029957
Validation loss: 2.4932386015558397

Epoch: 5| Step: 4
Training loss: 3.350166083247121
Validation loss: 2.4987968297809826

Epoch: 5| Step: 5
Training loss: 2.6269340656255618
Validation loss: 2.4988630057582815

Epoch: 5| Step: 6
Training loss: 2.600067350542281
Validation loss: 2.5136404513181225

Epoch: 5| Step: 7
Training loss: 2.7387544274827555
Validation loss: 2.525748835544203

Epoch: 5| Step: 8
Training loss: 2.704404847677056
Validation loss: 2.5340639549072543

Epoch: 5| Step: 9
Training loss: 2.7964158347232475
Validation loss: 2.542362311260833

Epoch: 5| Step: 10
Training loss: 2.2139814471024852
Validation loss: 2.540417572220837

Epoch: 107| Step: 0
Training loss: 2.5845681797509714
Validation loss: 2.5496362328169146

Epoch: 5| Step: 1
Training loss: 2.4606370530573303
Validation loss: 2.529033189988263

Epoch: 5| Step: 2
Training loss: 3.39624528004947
Validation loss: 2.5274112842835463

Epoch: 5| Step: 3
Training loss: 3.1639530869392707
Validation loss: 2.5067962682078897

Epoch: 5| Step: 4
Training loss: 2.5640266336911535
Validation loss: 2.4935193065867085

Epoch: 5| Step: 5
Training loss: 2.7738146028563784
Validation loss: 2.4848784518788776

Epoch: 5| Step: 6
Training loss: 2.312513299852221
Validation loss: 2.4846909360110616

Epoch: 5| Step: 7
Training loss: 3.082395118729711
Validation loss: 2.4824648336129207

Epoch: 5| Step: 8
Training loss: 2.8874981438436778
Validation loss: 2.487567094605096

Epoch: 5| Step: 9
Training loss: 2.9345852615051853
Validation loss: 2.481680649047399

Epoch: 5| Step: 10
Training loss: 2.7745156355152787
Validation loss: 2.481995576999069

Epoch: 108| Step: 0
Training loss: 2.740967394885729
Validation loss: 2.479253618661818

Epoch: 5| Step: 1
Training loss: 2.854434722415927
Validation loss: 2.481011550549411

Epoch: 5| Step: 2
Training loss: 2.6928905275392365
Validation loss: 2.4758491973043433

Epoch: 5| Step: 3
Training loss: 2.792532079746328
Validation loss: 2.480771458876155

Epoch: 5| Step: 4
Training loss: 2.5902003622432264
Validation loss: 2.4824955376498816

Epoch: 5| Step: 5
Training loss: 2.7132871268022303
Validation loss: 2.485309203583288

Epoch: 5| Step: 6
Training loss: 2.645527098547734
Validation loss: 2.492562307129759

Epoch: 5| Step: 7
Training loss: 2.8954710882472954
Validation loss: 2.4974007897359534

Epoch: 5| Step: 8
Training loss: 2.955628156686518
Validation loss: 2.4967856703661373

Epoch: 5| Step: 9
Training loss: 3.0108647700474997
Validation loss: 2.504379813580287

Epoch: 5| Step: 10
Training loss: 3.1148296416159043
Validation loss: 2.508583057547724

Epoch: 109| Step: 0
Training loss: 2.3452140812869624
Validation loss: 2.5246370710814166

Epoch: 5| Step: 1
Training loss: 2.8373643212502526
Validation loss: 2.5062086340728706

Epoch: 5| Step: 2
Training loss: 2.931180934458367
Validation loss: 2.507456681688895

Epoch: 5| Step: 3
Training loss: 3.365998308168871
Validation loss: 2.5095256997339073

Epoch: 5| Step: 4
Training loss: 2.2993289009900213
Validation loss: 2.513458578698645

Epoch: 5| Step: 5
Training loss: 3.1773246965289608
Validation loss: 2.514681144332006

Epoch: 5| Step: 6
Training loss: 2.9147305374837202
Validation loss: 2.509001333454469

Epoch: 5| Step: 7
Training loss: 2.4960851534843167
Validation loss: 2.497604976419792

Epoch: 5| Step: 8
Training loss: 3.0124085028591563
Validation loss: 2.491211018796852

Epoch: 5| Step: 9
Training loss: 2.8626879901041473
Validation loss: 2.487118274002651

Epoch: 5| Step: 10
Training loss: 2.6099886600934976
Validation loss: 2.486585666833165

Epoch: 110| Step: 0
Training loss: 3.118186847855601
Validation loss: 2.48223626289926

Epoch: 5| Step: 1
Training loss: 2.7650536415732674
Validation loss: 2.481485522392297

Epoch: 5| Step: 2
Training loss: 3.165296224559241
Validation loss: 2.4849786492636685

Epoch: 5| Step: 3
Training loss: 3.0868532005230813
Validation loss: 2.488805169311595

Epoch: 5| Step: 4
Training loss: 2.8976411368067723
Validation loss: 2.4925902013607004

Epoch: 5| Step: 5
Training loss: 2.8928179696204332
Validation loss: 2.4956721705476537

Epoch: 5| Step: 6
Training loss: 3.0543985449670092
Validation loss: 2.504684948893836

Epoch: 5| Step: 7
Training loss: 2.551177059852286
Validation loss: 2.495626814649193

Epoch: 5| Step: 8
Training loss: 2.0041419294050664
Validation loss: 2.4952519664585058

Epoch: 5| Step: 9
Training loss: 2.501319441701194
Validation loss: 2.4991062494584337

Epoch: 5| Step: 10
Training loss: 2.6630198656201385
Validation loss: 2.509805345418474

Epoch: 111| Step: 0
Training loss: 2.999536955384332
Validation loss: 2.5110890869925995

Epoch: 5| Step: 1
Training loss: 2.8736572447115205
Validation loss: 2.516643467044906

Epoch: 5| Step: 2
Training loss: 2.325573950855405
Validation loss: 2.516364454956941

Epoch: 5| Step: 3
Training loss: 3.0157284101238178
Validation loss: 2.51113534378385

Epoch: 5| Step: 4
Training loss: 2.709171390472615
Validation loss: 2.504629024191254

Epoch: 5| Step: 5
Training loss: 3.0924271346615297
Validation loss: 2.4989814272777195

Epoch: 5| Step: 6
Training loss: 2.9928035251355003
Validation loss: 2.4839559309828094

Epoch: 5| Step: 7
Training loss: 2.630102103829546
Validation loss: 2.4783287076443967

Epoch: 5| Step: 8
Training loss: 2.2531066216553897
Validation loss: 2.4824356121708337

Epoch: 5| Step: 9
Training loss: 2.7187887605556864
Validation loss: 2.474546792855385

Epoch: 5| Step: 10
Training loss: 3.2464340894557178
Validation loss: 2.469430354369242

Epoch: 112| Step: 0
Training loss: 2.96797973277326
Validation loss: 2.4692900297928726

Epoch: 5| Step: 1
Training loss: 2.1758906064725427
Validation loss: 2.4722795376876556

Epoch: 5| Step: 2
Training loss: 2.868858910448383
Validation loss: 2.473237073817521

Epoch: 5| Step: 3
Training loss: 2.928886120865163
Validation loss: 2.4766786164504317

Epoch: 5| Step: 4
Training loss: 2.7274896744935617
Validation loss: 2.4711211139259066

Epoch: 5| Step: 5
Training loss: 2.630422441184247
Validation loss: 2.4777085388747313

Epoch: 5| Step: 6
Training loss: 2.452588551173816
Validation loss: 2.477596958833033

Epoch: 5| Step: 7
Training loss: 2.9988521923288496
Validation loss: 2.4771660919041194

Epoch: 5| Step: 8
Training loss: 3.080060011786864
Validation loss: 2.476220591741841

Epoch: 5| Step: 9
Training loss: 2.5101390278828255
Validation loss: 2.4783843326088575

Epoch: 5| Step: 10
Training loss: 3.3542472561144576
Validation loss: 2.476062810554235

Epoch: 113| Step: 0
Training loss: 3.042435605473376
Validation loss: 2.490804770007721

Epoch: 5| Step: 1
Training loss: 3.095408601920237
Validation loss: 2.4962564424638916

Epoch: 5| Step: 2
Training loss: 2.9429323004279837
Validation loss: 2.488481434704862

Epoch: 5| Step: 3
Training loss: 2.3262399299973473
Validation loss: 2.5029320658211955

Epoch: 5| Step: 4
Training loss: 3.244426055606423
Validation loss: 2.5120314582662595

Epoch: 5| Step: 5
Training loss: 2.586737655897763
Validation loss: 2.5127177808993237

Epoch: 5| Step: 6
Training loss: 2.5275193968499305
Validation loss: 2.497867073255699

Epoch: 5| Step: 7
Training loss: 2.9230226924823217
Validation loss: 2.4904028628778083

Epoch: 5| Step: 8
Training loss: 2.781349951844691
Validation loss: 2.4864705543292143

Epoch: 5| Step: 9
Training loss: 2.7580356237477375
Validation loss: 2.4697171268247127

Epoch: 5| Step: 10
Training loss: 2.4028136251295384
Validation loss: 2.4686115330423877

Epoch: 114| Step: 0
Training loss: 2.7778718127122657
Validation loss: 2.4686687036049246

Epoch: 5| Step: 1
Training loss: 2.6705217113201543
Validation loss: 2.4685806230848804

Epoch: 5| Step: 2
Training loss: 3.0105750934312328
Validation loss: 2.471067755201472

Epoch: 5| Step: 3
Training loss: 2.957232973582972
Validation loss: 2.471222006047992

Epoch: 5| Step: 4
Training loss: 2.987239880589942
Validation loss: 2.4761306387709765

Epoch: 5| Step: 5
Training loss: 2.5522981721926286
Validation loss: 2.4837818290234583

Epoch: 5| Step: 6
Training loss: 2.7793508324710063
Validation loss: 2.4875888119543115

Epoch: 5| Step: 7
Training loss: 2.982943046514633
Validation loss: 2.5002621236405007

Epoch: 5| Step: 8
Training loss: 2.8505488017879137
Validation loss: 2.525635853121867

Epoch: 5| Step: 9
Training loss: 2.8806153895622733
Validation loss: 2.5381432703601976

Epoch: 5| Step: 10
Training loss: 2.4127074947959057
Validation loss: 2.501990655809022

Epoch: 115| Step: 0
Training loss: 3.046162526874874
Validation loss: 2.4815638937023303

Epoch: 5| Step: 1
Training loss: 2.7284119025840567
Validation loss: 2.4714188766258856

Epoch: 5| Step: 2
Training loss: 2.698530934830615
Validation loss: 2.48208138739318

Epoch: 5| Step: 3
Training loss: 2.7889704328455807
Validation loss: 2.486335886040368

Epoch: 5| Step: 4
Training loss: 2.396084106147297
Validation loss: 2.491765454104656

Epoch: 5| Step: 5
Training loss: 3.17908548940575
Validation loss: 2.4838733936772606

Epoch: 5| Step: 6
Training loss: 3.1575568486862666
Validation loss: 2.481414651257355

Epoch: 5| Step: 7
Training loss: 2.4136932979583148
Validation loss: 2.4739623159863333

Epoch: 5| Step: 8
Training loss: 3.034100637397587
Validation loss: 2.4798035383127224

Epoch: 5| Step: 9
Training loss: 2.753095358646789
Validation loss: 2.476487184689252

Epoch: 5| Step: 10
Training loss: 2.6963361040354914
Validation loss: 2.488939818327158

Epoch: 116| Step: 0
Training loss: 2.5229393434857292
Validation loss: 2.4906236034645746

Epoch: 5| Step: 1
Training loss: 2.781167532737611
Validation loss: 2.5116592339190147

Epoch: 5| Step: 2
Training loss: 2.712587585441511
Validation loss: 2.5270983863167644

Epoch: 5| Step: 3
Training loss: 2.732534519406801
Validation loss: 2.515476497322134

Epoch: 5| Step: 4
Training loss: 2.5824003893538774
Validation loss: 2.514446494331537

Epoch: 5| Step: 5
Training loss: 3.4083750684152454
Validation loss: 2.5258308260914797

Epoch: 5| Step: 6
Training loss: 3.1917247823366037
Validation loss: 2.508076360483502

Epoch: 5| Step: 7
Training loss: 2.8271660627958797
Validation loss: 2.4920572843558637

Epoch: 5| Step: 8
Training loss: 2.9320106349091257
Validation loss: 2.488056364525319

Epoch: 5| Step: 9
Training loss: 2.578943111199001
Validation loss: 2.4845736215178436

Epoch: 5| Step: 10
Training loss: 2.2723723862742777
Validation loss: 2.4776612948403423

Epoch: 117| Step: 0
Training loss: 2.3963580234239252
Validation loss: 2.4676847172770553

Epoch: 5| Step: 1
Training loss: 2.6365301220144537
Validation loss: 2.4687292093710225

Epoch: 5| Step: 2
Training loss: 2.5789073335078476
Validation loss: 2.4685730938906634

Epoch: 5| Step: 3
Training loss: 2.635917666213078
Validation loss: 2.4636063268836046

Epoch: 5| Step: 4
Training loss: 2.7421357674351428
Validation loss: 2.4609651109872197

Epoch: 5| Step: 5
Training loss: 3.169240073203916
Validation loss: 2.4657513793030246

Epoch: 5| Step: 6
Training loss: 3.0934609942840297
Validation loss: 2.4585309047433834

Epoch: 5| Step: 7
Training loss: 3.0391315364106024
Validation loss: 2.4705296191674044

Epoch: 5| Step: 8
Training loss: 2.6834283191936557
Validation loss: 2.4760560858183087

Epoch: 5| Step: 9
Training loss: 2.667621282735889
Validation loss: 2.481168219378732

Epoch: 5| Step: 10
Training loss: 2.9554815023350307
Validation loss: 2.4804782605313873

Epoch: 118| Step: 0
Training loss: 3.0809249923178226
Validation loss: 2.4789681986405943

Epoch: 5| Step: 1
Training loss: 2.7030489695887177
Validation loss: 2.476322040120255

Epoch: 5| Step: 2
Training loss: 3.3764162271106755
Validation loss: 2.469975514284955

Epoch: 5| Step: 3
Training loss: 2.5668266799721966
Validation loss: 2.4761839158324426

Epoch: 5| Step: 4
Training loss: 2.756624738688814
Validation loss: 2.4756154355139164

Epoch: 5| Step: 5
Training loss: 2.1115338616082533
Validation loss: 2.4805679049547713

Epoch: 5| Step: 6
Training loss: 2.7005689586641717
Validation loss: 2.467294505633339

Epoch: 5| Step: 7
Training loss: 2.983683401130823
Validation loss: 2.468566977052524

Epoch: 5| Step: 8
Training loss: 2.5953590274064466
Validation loss: 2.4894984522549115

Epoch: 5| Step: 9
Training loss: 3.3430045179221857
Validation loss: 2.508485986991206

Epoch: 5| Step: 10
Training loss: 2.012750275965918
Validation loss: 2.503246923507861

Epoch: 119| Step: 0
Training loss: 2.521454779157981
Validation loss: 2.495734517768823

Epoch: 5| Step: 1
Training loss: 2.764812026713625
Validation loss: 2.4887737205964053

Epoch: 5| Step: 2
Training loss: 3.1348489815630725
Validation loss: 2.491449821480972

Epoch: 5| Step: 3
Training loss: 2.8911020246176107
Validation loss: 2.480282070792054

Epoch: 5| Step: 4
Training loss: 2.331464075481329
Validation loss: 2.4818999280530964

Epoch: 5| Step: 5
Training loss: 2.7809969326140913
Validation loss: 2.491667800388894

Epoch: 5| Step: 6
Training loss: 3.2258616279682317
Validation loss: 2.4985132575226983

Epoch: 5| Step: 7
Training loss: 2.782518247697055
Validation loss: 2.4856222345593806

Epoch: 5| Step: 8
Training loss: 2.9748926159367466
Validation loss: 2.485859205771165

Epoch: 5| Step: 9
Training loss: 2.5070367011239525
Validation loss: 2.4761335770682105

Epoch: 5| Step: 10
Training loss: 2.5306727375135907
Validation loss: 2.4747641628695773

Epoch: 120| Step: 0
Training loss: 2.5921539543607186
Validation loss: 2.4820873903636835

Epoch: 5| Step: 1
Training loss: 3.5702895282699174
Validation loss: 2.4744681309214327

Epoch: 5| Step: 2
Training loss: 2.889306009778066
Validation loss: 2.4863495438453254

Epoch: 5| Step: 3
Training loss: 2.9949301159686734
Validation loss: 2.487050139338954

Epoch: 5| Step: 4
Training loss: 1.9328743260948666
Validation loss: 2.4998365276993355

Epoch: 5| Step: 5
Training loss: 2.77910085216033
Validation loss: 2.484270172683391

Epoch: 5| Step: 6
Training loss: 3.064809434452138
Validation loss: 2.4672771373435896

Epoch: 5| Step: 7
Training loss: 2.4733768997913828
Validation loss: 2.470889044232175

Epoch: 5| Step: 8
Training loss: 2.7288041395757094
Validation loss: 2.471694150256083

Epoch: 5| Step: 9
Training loss: 2.826090634225602
Validation loss: 2.4681423296610445

Epoch: 5| Step: 10
Training loss: 2.3181927692610254
Validation loss: 2.459540817425469

Epoch: 121| Step: 0
Training loss: 3.183073972618471
Validation loss: 2.4592733543003185

Epoch: 5| Step: 1
Training loss: 3.0127910679170733
Validation loss: 2.480512507237368

Epoch: 5| Step: 2
Training loss: 2.4171046375356586
Validation loss: 2.493166329829742

Epoch: 5| Step: 3
Training loss: 3.086101904244075
Validation loss: 2.506295022945453

Epoch: 5| Step: 4
Training loss: 2.8150254672915915
Validation loss: 2.5070865589761837

Epoch: 5| Step: 5
Training loss: 2.4399800521785617
Validation loss: 2.4957918764530334

Epoch: 5| Step: 6
Training loss: 2.5178785951235803
Validation loss: 2.4725528668147763

Epoch: 5| Step: 7
Training loss: 2.97046667960048
Validation loss: 2.467545240946465

Epoch: 5| Step: 8
Training loss: 2.6519139521693935
Validation loss: 2.465311244552761

Epoch: 5| Step: 9
Training loss: 2.7564436241182033
Validation loss: 2.457255659271802

Epoch: 5| Step: 10
Training loss: 2.510211023373624
Validation loss: 2.4593769240939585

Epoch: 122| Step: 0
Training loss: 2.489060499977127
Validation loss: 2.4638587938153327

Epoch: 5| Step: 1
Training loss: 2.699291355244114
Validation loss: 2.464089560306331

Epoch: 5| Step: 2
Training loss: 2.699795739959989
Validation loss: 2.4658032306545294

Epoch: 5| Step: 3
Training loss: 3.154760632510413
Validation loss: 2.4548175387062297

Epoch: 5| Step: 4
Training loss: 3.2932062210489446
Validation loss: 2.4653320047331513

Epoch: 5| Step: 5
Training loss: 3.019877701360894
Validation loss: 2.4663830562363733

Epoch: 5| Step: 6
Training loss: 2.4459522129609113
Validation loss: 2.480635253444224

Epoch: 5| Step: 7
Training loss: 2.571781561858725
Validation loss: 2.503857635798616

Epoch: 5| Step: 8
Training loss: 2.6005837372080443
Validation loss: 2.528086031003178

Epoch: 5| Step: 9
Training loss: 2.8070791773920796
Validation loss: 2.498831010097785

Epoch: 5| Step: 10
Training loss: 2.487433703895325
Validation loss: 2.4847553003632075

Epoch: 123| Step: 0
Training loss: 2.777019154483616
Validation loss: 2.4667205111517063

Epoch: 5| Step: 1
Training loss: 2.894393691116045
Validation loss: 2.4700092714124144

Epoch: 5| Step: 2
Training loss: 2.6419813295638863
Validation loss: 2.4743338910691435

Epoch: 5| Step: 3
Training loss: 2.943480065800703
Validation loss: 2.47487809256051

Epoch: 5| Step: 4
Training loss: 2.5678286159938604
Validation loss: 2.4694003723975366

Epoch: 5| Step: 5
Training loss: 2.7332184879862913
Validation loss: 2.473153969916025

Epoch: 5| Step: 6
Training loss: 2.7159505001551874
Validation loss: 2.47766242059566

Epoch: 5| Step: 7
Training loss: 2.7361160403065785
Validation loss: 2.48112445097387

Epoch: 5| Step: 8
Training loss: 2.797357613465741
Validation loss: 2.471759394447302

Epoch: 5| Step: 9
Training loss: 2.850166376176522
Validation loss: 2.4635277859823295

Epoch: 5| Step: 10
Training loss: 2.609015982593901
Validation loss: 2.4641332973254513

Epoch: 124| Step: 0
Training loss: 3.1374972886761503
Validation loss: 2.482835532727398

Epoch: 5| Step: 1
Training loss: 2.5559379480438267
Validation loss: 2.486334146587831

Epoch: 5| Step: 2
Training loss: 2.7717059680616685
Validation loss: 2.498774632227947

Epoch: 5| Step: 3
Training loss: 2.4244421366408555
Validation loss: 2.493257324656399

Epoch: 5| Step: 4
Training loss: 2.5620978435263253
Validation loss: 2.468837426515721

Epoch: 5| Step: 5
Training loss: 2.9936854345570616
Validation loss: 2.4650927903530953

Epoch: 5| Step: 6
Training loss: 3.002215203365564
Validation loss: 2.45128362198522

Epoch: 5| Step: 7
Training loss: 2.5859682017921126
Validation loss: 2.4567084228581906

Epoch: 5| Step: 8
Training loss: 2.3975298527836966
Validation loss: 2.4584473370925117

Epoch: 5| Step: 9
Training loss: 3.1558213651067697
Validation loss: 2.4669867880985734

Epoch: 5| Step: 10
Training loss: 2.575979368755106
Validation loss: 2.4696779066232604

Epoch: 125| Step: 0
Training loss: 2.867376752630934
Validation loss: 2.499506812516945

Epoch: 5| Step: 1
Training loss: 2.924490181598431
Validation loss: 2.536765754826846

Epoch: 5| Step: 2
Training loss: 2.7807696495579397
Validation loss: 2.569097723640853

Epoch: 5| Step: 3
Training loss: 2.8944047290162382
Validation loss: 2.52292757054724

Epoch: 5| Step: 4
Training loss: 3.3462654705637602
Validation loss: 2.5000704929708872

Epoch: 5| Step: 5
Training loss: 2.5791105294062695
Validation loss: 2.4756332087131185

Epoch: 5| Step: 6
Training loss: 2.5805554580095333
Validation loss: 2.4752997372559524

Epoch: 5| Step: 7
Training loss: 2.162104853872588
Validation loss: 2.4698341878912946

Epoch: 5| Step: 8
Training loss: 3.0202136927909704
Validation loss: 2.4675236017317514

Epoch: 5| Step: 9
Training loss: 2.3793012920533414
Validation loss: 2.4604964197454104

Epoch: 5| Step: 10
Training loss: 2.688002428507843
Validation loss: 2.464414785806104

Epoch: 126| Step: 0
Training loss: 2.9727499266613133
Validation loss: 2.4624589937347046

Epoch: 5| Step: 1
Training loss: 2.778076590254632
Validation loss: 2.4670557917305302

Epoch: 5| Step: 2
Training loss: 2.7737165283824115
Validation loss: 2.4653289277368846

Epoch: 5| Step: 3
Training loss: 2.1829347110688646
Validation loss: 2.480253544066961

Epoch: 5| Step: 4
Training loss: 2.502848814016047
Validation loss: 2.4980091556280235

Epoch: 5| Step: 5
Training loss: 2.4889486187435863
Validation loss: 2.526421913592994

Epoch: 5| Step: 6
Training loss: 3.166376167491414
Validation loss: 2.549202679785858

Epoch: 5| Step: 7
Training loss: 2.6804805727558687
Validation loss: 2.4997997419074753

Epoch: 5| Step: 8
Training loss: 2.687997284059061
Validation loss: 2.4789528775673335

Epoch: 5| Step: 9
Training loss: 3.1664049308090796
Validation loss: 2.460942048203549

Epoch: 5| Step: 10
Training loss: 3.0927466104378016
Validation loss: 2.460570440802417

Epoch: 127| Step: 0
Training loss: 2.64231294935338
Validation loss: 2.458278792707694

Epoch: 5| Step: 1
Training loss: 2.47302301226937
Validation loss: 2.466417009090837

Epoch: 5| Step: 2
Training loss: 2.937599180454564
Validation loss: 2.4641241076115734

Epoch: 5| Step: 3
Training loss: 2.937212828539035
Validation loss: 2.4598035276399592

Epoch: 5| Step: 4
Training loss: 3.2077531826742893
Validation loss: 2.4624114425457337

Epoch: 5| Step: 5
Training loss: 3.0860929425842887
Validation loss: 2.4686904044361535

Epoch: 5| Step: 6
Training loss: 2.93383024153911
Validation loss: 2.466600968994528

Epoch: 5| Step: 7
Training loss: 2.2839638231689294
Validation loss: 2.4862456154046226

Epoch: 5| Step: 8
Training loss: 2.759656943133806
Validation loss: 2.482488478192156

Epoch: 5| Step: 9
Training loss: 2.93770679801084
Validation loss: 2.4946393303392864

Epoch: 5| Step: 10
Training loss: 1.9181015061934348
Validation loss: 2.497703830860681

Epoch: 128| Step: 0
Training loss: 2.8972053479387685
Validation loss: 2.494974705135116

Epoch: 5| Step: 1
Training loss: 2.245032549072022
Validation loss: 2.5081369591817757

Epoch: 5| Step: 2
Training loss: 2.75629580020696
Validation loss: 2.509070636586996

Epoch: 5| Step: 3
Training loss: 2.832137996371851
Validation loss: 2.501771386481651

Epoch: 5| Step: 4
Training loss: 2.786889434455402
Validation loss: 2.5009227680159367

Epoch: 5| Step: 5
Training loss: 2.911383248568272
Validation loss: 2.4967650187267276

Epoch: 5| Step: 6
Training loss: 3.0311250955862534
Validation loss: 2.5076712276338875

Epoch: 5| Step: 7
Training loss: 2.355717735985307
Validation loss: 2.501072549962191

Epoch: 5| Step: 8
Training loss: 2.401894628209821
Validation loss: 2.502507001807967

Epoch: 5| Step: 9
Training loss: 2.662748667248808
Validation loss: 2.4858723742726205

Epoch: 5| Step: 10
Training loss: 3.1551838197676276
Validation loss: 2.475591584452598

Epoch: 129| Step: 0
Training loss: 3.018004906359022
Validation loss: 2.4678194995749023

Epoch: 5| Step: 1
Training loss: 2.9876885518223664
Validation loss: 2.472570299655324

Epoch: 5| Step: 2
Training loss: 3.0091476845774214
Validation loss: 2.470990096266641

Epoch: 5| Step: 3
Training loss: 2.834025429363213
Validation loss: 2.475561224552425

Epoch: 5| Step: 4
Training loss: 2.1012375591030055
Validation loss: 2.489592500466307

Epoch: 5| Step: 5
Training loss: 2.628898813313683
Validation loss: 2.4894051450508163

Epoch: 5| Step: 6
Training loss: 2.841258372249595
Validation loss: 2.5001395319895865

Epoch: 5| Step: 7
Training loss: 2.663760528901664
Validation loss: 2.5156192523429755

Epoch: 5| Step: 8
Training loss: 2.5978924866147324
Validation loss: 2.5179731023749303

Epoch: 5| Step: 9
Training loss: 3.1348264694250947
Validation loss: 2.520619399504086

Epoch: 5| Step: 10
Training loss: 1.9248128626633847
Validation loss: 2.497228314484997

Epoch: 130| Step: 0
Training loss: 1.996466734316936
Validation loss: 2.485931693025877

Epoch: 5| Step: 1
Training loss: 3.103924598898854
Validation loss: 2.4622185569110906

Epoch: 5| Step: 2
Training loss: 2.406786573950592
Validation loss: 2.4725157072424224

Epoch: 5| Step: 3
Training loss: 2.54981964819912
Validation loss: 2.4639211209500687

Epoch: 5| Step: 4
Training loss: 3.0367213942798656
Validation loss: 2.4731351537070845

Epoch: 5| Step: 5
Training loss: 2.9932183862831323
Validation loss: 2.4740668132596895

Epoch: 5| Step: 6
Training loss: 2.686846808964238
Validation loss: 2.4811725920438037

Epoch: 5| Step: 7
Training loss: 2.3985959475986
Validation loss: 2.4775328870872237

Epoch: 5| Step: 8
Training loss: 2.7079456540941407
Validation loss: 2.476119805452229

Epoch: 5| Step: 9
Training loss: 3.009718887788077
Validation loss: 2.4741210559293436

Epoch: 5| Step: 10
Training loss: 2.8609804742940823
Validation loss: 2.496888684718564

Epoch: 131| Step: 0
Training loss: 2.900031379003776
Validation loss: 2.5017754167421904

Epoch: 5| Step: 1
Training loss: 2.8586469880406513
Validation loss: 2.513728608177215

Epoch: 5| Step: 2
Training loss: 2.124509754850707
Validation loss: 2.493924666287408

Epoch: 5| Step: 3
Training loss: 3.133296634242717
Validation loss: 2.4761465658946356

Epoch: 5| Step: 4
Training loss: 2.622395267631725
Validation loss: 2.4809082479051194

Epoch: 5| Step: 5
Training loss: 2.969489397026488
Validation loss: 2.480373167238071

Epoch: 5| Step: 6
Training loss: 2.8413969931820104
Validation loss: 2.4820885089472573

Epoch: 5| Step: 7
Training loss: 2.393982766888513
Validation loss: 2.481994971722569

Epoch: 5| Step: 8
Training loss: 2.7572074420912083
Validation loss: 2.4836263232162503

Epoch: 5| Step: 9
Training loss: 2.4972892369872994
Validation loss: 2.48159908410611

Epoch: 5| Step: 10
Training loss: 2.5908603427870087
Validation loss: 2.500878657500224

Epoch: 132| Step: 0
Training loss: 2.9754929911435246
Validation loss: 2.4886531450500655

Epoch: 5| Step: 1
Training loss: 2.1526485718814943
Validation loss: 2.4739792332092954

Epoch: 5| Step: 2
Training loss: 2.9578674021127864
Validation loss: 2.474848621495898

Epoch: 5| Step: 3
Training loss: 2.615816856284583
Validation loss: 2.473520210646295

Epoch: 5| Step: 4
Training loss: 2.337165127190758
Validation loss: 2.4754746610136453

Epoch: 5| Step: 5
Training loss: 2.569425760378794
Validation loss: 2.471992543956664

Epoch: 5| Step: 6
Training loss: 3.002938738553433
Validation loss: 2.4804703984809393

Epoch: 5| Step: 7
Training loss: 3.1857913056226637
Validation loss: 2.485756858488761

Epoch: 5| Step: 8
Training loss: 2.5791257823195424
Validation loss: 2.5028199831860856

Epoch: 5| Step: 9
Training loss: 2.5360180252650006
Validation loss: 2.521672778160567

Epoch: 5| Step: 10
Training loss: 2.913052708650158
Validation loss: 2.5079190654498618

Epoch: 133| Step: 0
Training loss: 2.3877161816892176
Validation loss: 2.490334233359492

Epoch: 5| Step: 1
Training loss: 3.4479386404822048
Validation loss: 2.4827815072944053

Epoch: 5| Step: 2
Training loss: 2.639070403119411
Validation loss: 2.4810820539867837

Epoch: 5| Step: 3
Training loss: 2.5794233347470605
Validation loss: 2.4802886326469484

Epoch: 5| Step: 4
Training loss: 2.0773067154009426
Validation loss: 2.4731830335872176

Epoch: 5| Step: 5
Training loss: 3.0506827794007405
Validation loss: 2.475521085162766

Epoch: 5| Step: 6
Training loss: 2.3879651001084454
Validation loss: 2.482264812280966

Epoch: 5| Step: 7
Training loss: 3.1840924767526295
Validation loss: 2.4875303242158817

Epoch: 5| Step: 8
Training loss: 2.1416264996553154
Validation loss: 2.478306944319788

Epoch: 5| Step: 9
Training loss: 2.8866895124428535
Validation loss: 2.4876270489921235

Epoch: 5| Step: 10
Training loss: 2.6631509334408947
Validation loss: 2.4924867409013527

Epoch: 134| Step: 0
Training loss: 2.3837301519694813
Validation loss: 2.5182596640388026

Epoch: 5| Step: 1
Training loss: 2.6337561119091957
Validation loss: 2.5246182009188427

Epoch: 5| Step: 2
Training loss: 2.276805467279482
Validation loss: 2.5513037757716486

Epoch: 5| Step: 3
Training loss: 3.1264022732713728
Validation loss: 2.563908275779712

Epoch: 5| Step: 4
Training loss: 2.9256870473611287
Validation loss: 2.512938171145949

Epoch: 5| Step: 5
Training loss: 2.542822017626081
Validation loss: 2.4950122186426227

Epoch: 5| Step: 6
Training loss: 3.260958755489692
Validation loss: 2.478025497596676

Epoch: 5| Step: 7
Training loss: 2.8190579569671836
Validation loss: 2.4796396515918713

Epoch: 5| Step: 8
Training loss: 2.99537588419585
Validation loss: 2.476374985928299

Epoch: 5| Step: 9
Training loss: 2.25534926422714
Validation loss: 2.4933461518172293

Epoch: 5| Step: 10
Training loss: 2.4336439099967073
Validation loss: 2.5079436752334585

Epoch: 135| Step: 0
Training loss: 2.888993416223785
Validation loss: 2.5193448999326065

Epoch: 5| Step: 1
Training loss: 2.567611620295839
Validation loss: 2.5308655943593745

Epoch: 5| Step: 2
Training loss: 3.0949404189086156
Validation loss: 2.527690032395552

Epoch: 5| Step: 3
Training loss: 2.747393152799097
Validation loss: 2.5259598538075356

Epoch: 5| Step: 4
Training loss: 2.311553658343057
Validation loss: 2.4949910914835205

Epoch: 5| Step: 5
Training loss: 2.1912890724228236
Validation loss: 2.5130248101876846

Epoch: 5| Step: 6
Training loss: 2.757663106789311
Validation loss: 2.524821217089307

Epoch: 5| Step: 7
Training loss: 3.0169436087037065
Validation loss: 2.521959253880356

Epoch: 5| Step: 8
Training loss: 3.08138261552216
Validation loss: 2.5214115961993357

Epoch: 5| Step: 9
Training loss: 2.409474379967491
Validation loss: 2.505844151843861

Epoch: 5| Step: 10
Training loss: 2.529832325230373
Validation loss: 2.4891471183723306

Epoch: 136| Step: 0
Training loss: 2.5191945405461795
Validation loss: 2.4745216851685234

Epoch: 5| Step: 1
Training loss: 2.644892567866725
Validation loss: 2.451338112572201

Epoch: 5| Step: 2
Training loss: 2.727261079416544
Validation loss: 2.436630070648614

Epoch: 5| Step: 3
Training loss: 2.978232248302523
Validation loss: 2.4409791986211364

Epoch: 5| Step: 4
Training loss: 3.1042232294924457
Validation loss: 2.4326762451593997

Epoch: 5| Step: 5
Training loss: 2.9703878602848053
Validation loss: 2.4382339478996435

Epoch: 5| Step: 6
Training loss: 2.809999668487855
Validation loss: 2.4401142903175272

Epoch: 5| Step: 7
Training loss: 1.9418526026990646
Validation loss: 2.449568349697902

Epoch: 5| Step: 8
Training loss: 2.8089266647375357
Validation loss: 2.470788381826457

Epoch: 5| Step: 9
Training loss: 2.649205999363392
Validation loss: 2.4759683975244435

Epoch: 5| Step: 10
Training loss: 2.729024393192805
Validation loss: 2.4910528955203417

Epoch: 137| Step: 0
Training loss: 2.9127691840339853
Validation loss: 2.5212545332003407

Epoch: 5| Step: 1
Training loss: 2.484216169162453
Validation loss: 2.559052531123853

Epoch: 5| Step: 2
Training loss: 3.0190137096395735
Validation loss: 2.5703198229316406

Epoch: 5| Step: 3
Training loss: 3.151030956071458
Validation loss: 2.5113529906161123

Epoch: 5| Step: 4
Training loss: 2.655048233140086
Validation loss: 2.4905057994918467

Epoch: 5| Step: 5
Training loss: 3.114245103993747
Validation loss: 2.46158031031745

Epoch: 5| Step: 6
Training loss: 3.0006315838058826
Validation loss: 2.444650316549598

Epoch: 5| Step: 7
Training loss: 2.2187245327199827
Validation loss: 2.4353220401393143

Epoch: 5| Step: 8
Training loss: 2.614622857958978
Validation loss: 2.445222573761438

Epoch: 5| Step: 9
Training loss: 2.3943908550680475
Validation loss: 2.4519913468472105

Epoch: 5| Step: 10
Training loss: 2.502283102843506
Validation loss: 2.4494137729590855

Epoch: 138| Step: 0
Training loss: 3.2268409147056443
Validation loss: 2.4611564032329154

Epoch: 5| Step: 1
Training loss: 2.2802096568301704
Validation loss: 2.463224398429082

Epoch: 5| Step: 2
Training loss: 2.930370688571076
Validation loss: 2.467919844189389

Epoch: 5| Step: 3
Training loss: 2.726308379040147
Validation loss: 2.4718348672937887

Epoch: 5| Step: 4
Training loss: 2.3955316989483784
Validation loss: 2.4768252078292217

Epoch: 5| Step: 5
Training loss: 2.460506922277439
Validation loss: 2.4866492120137402

Epoch: 5| Step: 6
Training loss: 2.63651086058352
Validation loss: 2.4745559873747354

Epoch: 5| Step: 7
Training loss: 2.9721799611764177
Validation loss: 2.460220526761699

Epoch: 5| Step: 8
Training loss: 2.8598382293192697
Validation loss: 2.4600546643212686

Epoch: 5| Step: 9
Training loss: 2.595905465419395
Validation loss: 2.4677213740619885

Epoch: 5| Step: 10
Training loss: 2.4654932874109705
Validation loss: 2.4775983448517147

Epoch: 139| Step: 0
Training loss: 2.541629561690181
Validation loss: 2.482286179434288

Epoch: 5| Step: 1
Training loss: 2.773510397369443
Validation loss: 2.4790716555485655

Epoch: 5| Step: 2
Training loss: 2.063877916998584
Validation loss: 2.4919794210318598

Epoch: 5| Step: 3
Training loss: 2.9798832989569966
Validation loss: 2.478327352549675

Epoch: 5| Step: 4
Training loss: 2.768904212807545
Validation loss: 2.4773044418744345

Epoch: 5| Step: 5
Training loss: 2.2806250356275366
Validation loss: 2.478928583931983

Epoch: 5| Step: 6
Training loss: 2.5547369622624747
Validation loss: 2.483148497159468

Epoch: 5| Step: 7
Training loss: 2.3971842619757577
Validation loss: 2.4920318047746908

Epoch: 5| Step: 8
Training loss: 2.8886018838714795
Validation loss: 2.502827275173212

Epoch: 5| Step: 9
Training loss: 2.859605123296159
Validation loss: 2.507714276106807

Epoch: 5| Step: 10
Training loss: 3.294243652874941
Validation loss: 2.529738335000265

Epoch: 140| Step: 0
Training loss: 2.4871515077856965
Validation loss: 2.51546206411917

Epoch: 5| Step: 1
Training loss: 2.9106710298685785
Validation loss: 2.504504989066434

Epoch: 5| Step: 2
Training loss: 2.098231629181117
Validation loss: 2.5087188094044195

Epoch: 5| Step: 3
Training loss: 3.086350039177516
Validation loss: 2.513949630782435

Epoch: 5| Step: 4
Training loss: 2.5232754587400743
Validation loss: 2.5131833871844105

Epoch: 5| Step: 5
Training loss: 2.9414568284994056
Validation loss: 2.5247659729710037

Epoch: 5| Step: 6
Training loss: 2.706351939477292
Validation loss: 2.5264419037302095

Epoch: 5| Step: 7
Training loss: 2.4647813598668384
Validation loss: 2.5040840158900712

Epoch: 5| Step: 8
Training loss: 2.6993708477973137
Validation loss: 2.495426845638435

Epoch: 5| Step: 9
Training loss: 2.4322051224161427
Validation loss: 2.5114278437163766

Epoch: 5| Step: 10
Training loss: 3.163843670094783
Validation loss: 2.5362324254096453

Epoch: 141| Step: 0
Training loss: 2.2766898575807564
Validation loss: 2.545586816926902

Epoch: 5| Step: 1
Training loss: 2.5084528120444896
Validation loss: 2.559001139634267

Epoch: 5| Step: 2
Training loss: 2.851204293105022
Validation loss: 2.5521216250056815

Epoch: 5| Step: 3
Training loss: 2.0633545463511003
Validation loss: 2.5044793321074943

Epoch: 5| Step: 4
Training loss: 3.209193440532578
Validation loss: 2.5024023716180914

Epoch: 5| Step: 5
Training loss: 2.804005574497009
Validation loss: 2.4883203531569085

Epoch: 5| Step: 6
Training loss: 2.5289313917586638
Validation loss: 2.4761320882485536

Epoch: 5| Step: 7
Training loss: 2.41842129467401
Validation loss: 2.4635711344176

Epoch: 5| Step: 8
Training loss: 2.8570775876083188
Validation loss: 2.4557502618749933

Epoch: 5| Step: 9
Training loss: 3.1542578727271384
Validation loss: 2.4542660577657935

Epoch: 5| Step: 10
Training loss: 2.495955342498504
Validation loss: 2.447535439895346

Epoch: 142| Step: 0
Training loss: 2.975314141365098
Validation loss: 2.449659707129334

Epoch: 5| Step: 1
Training loss: 2.2453558995267433
Validation loss: 2.4516262986163166

Epoch: 5| Step: 2
Training loss: 2.9538925223042893
Validation loss: 2.4588922150714354

Epoch: 5| Step: 3
Training loss: 2.8146981867903613
Validation loss: 2.4686447553111055

Epoch: 5| Step: 4
Training loss: 2.2783680308708334
Validation loss: 2.49397975683483

Epoch: 5| Step: 5
Training loss: 2.644228040253625
Validation loss: 2.519577835108944

Epoch: 5| Step: 6
Training loss: 3.2068761678874584
Validation loss: 2.5412217977550884

Epoch: 5| Step: 7
Training loss: 2.293290019883096
Validation loss: 2.5399633392528567

Epoch: 5| Step: 8
Training loss: 2.4601840364420022
Validation loss: 2.5650557871623967

Epoch: 5| Step: 9
Training loss: 2.725377740839099
Validation loss: 2.5513981501871097

Epoch: 5| Step: 10
Training loss: 2.500432358548276
Validation loss: 2.5328959920843603

Epoch: 143| Step: 0
Training loss: 1.9440484287014552
Validation loss: 2.501053261639796

Epoch: 5| Step: 1
Training loss: 2.718724743955967
Validation loss: 2.4834096442477867

Epoch: 5| Step: 2
Training loss: 2.827801006157616
Validation loss: 2.490050057706441

Epoch: 5| Step: 3
Training loss: 2.0477593528059868
Validation loss: 2.486725184498677

Epoch: 5| Step: 4
Training loss: 2.54147477806615
Validation loss: 2.503510283152189

Epoch: 5| Step: 5
Training loss: 2.359574063221297
Validation loss: 2.5189451893937234

Epoch: 5| Step: 6
Training loss: 3.034768176706837
Validation loss: 2.5195084740207947

Epoch: 5| Step: 7
Training loss: 2.8928382442334732
Validation loss: 2.5087769503195623

Epoch: 5| Step: 8
Training loss: 3.138285358512683
Validation loss: 2.505819496886942

Epoch: 5| Step: 9
Training loss: 2.7818975659125598
Validation loss: 2.4963044534628107

Epoch: 5| Step: 10
Training loss: 2.5321283582540914
Validation loss: 2.4996944886853347

Epoch: 144| Step: 0
Training loss: 2.228295010237407
Validation loss: 2.499957652399863

Epoch: 5| Step: 1
Training loss: 2.5989429012189524
Validation loss: 2.506326484510444

Epoch: 5| Step: 2
Training loss: 3.3872903343714387
Validation loss: 2.508360578869857

Epoch: 5| Step: 3
Training loss: 2.638592180224614
Validation loss: 2.4887122728803455

Epoch: 5| Step: 4
Training loss: 2.8787745700571135
Validation loss: 2.473608396140585

Epoch: 5| Step: 5
Training loss: 2.179650966105677
Validation loss: 2.456494433187536

Epoch: 5| Step: 6
Training loss: 2.590676014286336
Validation loss: 2.457624443409441

Epoch: 5| Step: 7
Training loss: 2.394739636661715
Validation loss: 2.464916569254418

Epoch: 5| Step: 8
Training loss: 2.721089814167095
Validation loss: 2.475940377120177

Epoch: 5| Step: 9
Training loss: 2.6589956118291744
Validation loss: 2.491449512273838

Epoch: 5| Step: 10
Training loss: 2.8391567485409546
Validation loss: 2.4788829547717794

Epoch: 145| Step: 0
Training loss: 2.566805037777359
Validation loss: 2.476984089286214

Epoch: 5| Step: 1
Training loss: 2.4664533531468846
Validation loss: 2.4792238382096756

Epoch: 5| Step: 2
Training loss: 2.8691708723516234
Validation loss: 2.4726075535351635

Epoch: 5| Step: 3
Training loss: 2.4313407743713356
Validation loss: 2.4878774420794465

Epoch: 5| Step: 4
Training loss: 2.5918735932621613
Validation loss: 2.4805917836124243

Epoch: 5| Step: 5
Training loss: 2.5741390048049757
Validation loss: 2.4899015360153065

Epoch: 5| Step: 6
Training loss: 2.712065096678737
Validation loss: 2.496195211297751

Epoch: 5| Step: 7
Training loss: 3.0042954528829036
Validation loss: 2.4954669247572117

Epoch: 5| Step: 8
Training loss: 2.5799997622467643
Validation loss: 2.508942095215555

Epoch: 5| Step: 9
Training loss: 2.5880642814671555
Validation loss: 2.501114492260741

Epoch: 5| Step: 10
Training loss: 2.5772115302882272
Validation loss: 2.512014931509446

Epoch: 146| Step: 0
Training loss: 1.9971901109201158
Validation loss: 2.496589549395375

Epoch: 5| Step: 1
Training loss: 2.887774077119503
Validation loss: 2.4947314439553714

Epoch: 5| Step: 2
Training loss: 2.2470089847264534
Validation loss: 2.5067740688794538

Epoch: 5| Step: 3
Training loss: 2.8192322582793787
Validation loss: 2.5039488574248385

Epoch: 5| Step: 4
Training loss: 2.8296936068792813
Validation loss: 2.5099743610996548

Epoch: 5| Step: 5
Training loss: 3.1508832571181995
Validation loss: 2.507069304789661

Epoch: 5| Step: 6
Training loss: 2.686209879096733
Validation loss: 2.5227204803932075

Epoch: 5| Step: 7
Training loss: 2.780050297563413
Validation loss: 2.53421904903428

Epoch: 5| Step: 8
Training loss: 2.576654373113299
Validation loss: 2.5310276591655074

Epoch: 5| Step: 9
Training loss: 2.583286182424467
Validation loss: 2.536784967159507

Epoch: 5| Step: 10
Training loss: 2.07128019929003
Validation loss: 2.520743287513134

Epoch: 147| Step: 0
Training loss: 2.6997406340460532
Validation loss: 2.5019216217608795

Epoch: 5| Step: 1
Training loss: 2.36537418220037
Validation loss: 2.4903630234400596

Epoch: 5| Step: 2
Training loss: 2.460699257596147
Validation loss: 2.463477567402371

Epoch: 5| Step: 3
Training loss: 2.502041269457521
Validation loss: 2.4624149099594153

Epoch: 5| Step: 4
Training loss: 2.6269606579527216
Validation loss: 2.451204777233538

Epoch: 5| Step: 5
Training loss: 2.6998125187809174
Validation loss: 2.451810816187657

Epoch: 5| Step: 6
Training loss: 2.885604044388067
Validation loss: 2.443143603312565

Epoch: 5| Step: 7
Training loss: 2.61785588625943
Validation loss: 2.470286825441158

Epoch: 5| Step: 8
Training loss: 2.4943086691505347
Validation loss: 2.4850609842847975

Epoch: 5| Step: 9
Training loss: 2.78832382550151
Validation loss: 2.5339538097987617

Epoch: 5| Step: 10
Training loss: 2.805318862280611
Validation loss: 2.5874698030995393

Epoch: 148| Step: 0
Training loss: 2.7452392985225065
Validation loss: 2.5943582896134427

Epoch: 5| Step: 1
Training loss: 2.273307770373724
Validation loss: 2.559739561632044

Epoch: 5| Step: 2
Training loss: 2.266028532725638
Validation loss: 2.5270709622664334

Epoch: 5| Step: 3
Training loss: 2.183906764761635
Validation loss: 2.4958507663437697

Epoch: 5| Step: 4
Training loss: 2.6560164405015185
Validation loss: 2.4899158620409216

Epoch: 5| Step: 5
Training loss: 2.930375732963323
Validation loss: 2.484742126973297

Epoch: 5| Step: 6
Training loss: 3.0435505263118894
Validation loss: 2.476314469242024

Epoch: 5| Step: 7
Training loss: 2.976262595619872
Validation loss: 2.4676082863629136

Epoch: 5| Step: 8
Training loss: 2.6667474098697226
Validation loss: 2.4698198766886073

Epoch: 5| Step: 9
Training loss: 2.2099771199832836
Validation loss: 2.4715704932419578

Epoch: 5| Step: 10
Training loss: 2.8649559379771086
Validation loss: 2.4753882611877325

Epoch: 149| Step: 0
Training loss: 2.5620478719665427
Validation loss: 2.4925477988384532

Epoch: 5| Step: 1
Training loss: 2.8749844094558594
Validation loss: 2.5131977906307443

Epoch: 5| Step: 2
Training loss: 2.6977177157498984
Validation loss: 2.5356399001723746

Epoch: 5| Step: 3
Training loss: 2.5622424484708883
Validation loss: 2.551293760556444

Epoch: 5| Step: 4
Training loss: 2.756014402531832
Validation loss: 2.557602298473985

Epoch: 5| Step: 5
Training loss: 3.0464513239588267
Validation loss: 2.536731333756519

Epoch: 5| Step: 6
Training loss: 2.1977089396539884
Validation loss: 2.5121154109606088

Epoch: 5| Step: 7
Training loss: 2.3584685952944624
Validation loss: 2.508155734607257

Epoch: 5| Step: 8
Training loss: 2.3022804233422733
Validation loss: 2.4927116123503215

Epoch: 5| Step: 9
Training loss: 2.623007426813848
Validation loss: 2.4985717077405583

Epoch: 5| Step: 10
Training loss: 2.7029600589241345
Validation loss: 2.4816797136421793

Epoch: 150| Step: 0
Training loss: 2.4007698175497603
Validation loss: 2.4677789163764223

Epoch: 5| Step: 1
Training loss: 2.2560207556926346
Validation loss: 2.488583631818448

Epoch: 5| Step: 2
Training loss: 3.2735630639514173
Validation loss: 2.485414711171535

Epoch: 5| Step: 3
Training loss: 2.066816379395246
Validation loss: 2.497748458289142

Epoch: 5| Step: 4
Training loss: 2.1144303390202612
Validation loss: 2.5093668486848006

Epoch: 5| Step: 5
Training loss: 2.783268485389341
Validation loss: 2.499737704268597

Epoch: 5| Step: 6
Training loss: 2.7758091202337125
Validation loss: 2.505330737670311

Epoch: 5| Step: 7
Training loss: 2.8652991123076004
Validation loss: 2.510858374278142

Epoch: 5| Step: 8
Training loss: 2.4987207000525964
Validation loss: 2.500705348770312

Epoch: 5| Step: 9
Training loss: 2.287591559240141
Validation loss: 2.4960824677090097

Epoch: 5| Step: 10
Training loss: 3.009696390295103
Validation loss: 2.5073859209417284

Epoch: 151| Step: 0
Training loss: 2.2125988437103725
Validation loss: 2.5052589774835603

Epoch: 5| Step: 1
Training loss: 1.9357680917037554
Validation loss: 2.4980059649416293

Epoch: 5| Step: 2
Training loss: 2.3375368288780143
Validation loss: 2.5029153069050905

Epoch: 5| Step: 3
Training loss: 2.9823801453674434
Validation loss: 2.48606063630517

Epoch: 5| Step: 4
Training loss: 2.791118387688967
Validation loss: 2.4896362240030423

Epoch: 5| Step: 5
Training loss: 2.4475112146387543
Validation loss: 2.4877013314380316

Epoch: 5| Step: 6
Training loss: 2.637565962703319
Validation loss: 2.477912658756476

Epoch: 5| Step: 7
Training loss: 2.7404162128392624
Validation loss: 2.484165131964716

Epoch: 5| Step: 8
Training loss: 2.781544359038926
Validation loss: 2.480032452113961

Epoch: 5| Step: 9
Training loss: 2.7505155426901036
Validation loss: 2.511535185665888

Epoch: 5| Step: 10
Training loss: 2.626242661390986
Validation loss: 2.5032295522198225

Epoch: 152| Step: 0
Training loss: 2.27341579151604
Validation loss: 2.5260419917679937

Epoch: 5| Step: 1
Training loss: 2.5150004494213514
Validation loss: 2.5364121131773287

Epoch: 5| Step: 2
Training loss: 2.602142361006284
Validation loss: 2.554354913918815

Epoch: 5| Step: 3
Training loss: 2.570093580390195
Validation loss: 2.576570907449012

Epoch: 5| Step: 4
Training loss: 2.479531611233944
Validation loss: 2.5674651609723607

Epoch: 5| Step: 5
Training loss: 2.6688202466809634
Validation loss: 2.565118283901883

Epoch: 5| Step: 6
Training loss: 2.413460073023453
Validation loss: 2.539637342178838

Epoch: 5| Step: 7
Training loss: 2.6753509398235216
Validation loss: 2.529449069350956

Epoch: 5| Step: 8
Training loss: 2.112098010035946
Validation loss: 2.5069167815536084

Epoch: 5| Step: 9
Training loss: 2.980773830173626
Validation loss: 2.514828475781753

Epoch: 5| Step: 10
Training loss: 2.9090713424458077
Validation loss: 2.509888672903631

Epoch: 153| Step: 0
Training loss: 2.410496717050782
Validation loss: 2.504380256826272

Epoch: 5| Step: 1
Training loss: 2.0501609227357127
Validation loss: 2.47509112309984

Epoch: 5| Step: 2
Training loss: 2.2477285787847023
Validation loss: 2.4599128179811074

Epoch: 5| Step: 3
Training loss: 2.794023477366938
Validation loss: 2.4563157750250633

Epoch: 5| Step: 4
Training loss: 2.814018941369527
Validation loss: 2.461490264967779

Epoch: 5| Step: 5
Training loss: 2.8297138282397825
Validation loss: 2.48263705767672

Epoch: 5| Step: 6
Training loss: 2.1315807097132127
Validation loss: 2.4950246956197564

Epoch: 5| Step: 7
Training loss: 2.9143638966328607
Validation loss: 2.5179786807393176

Epoch: 5| Step: 8
Training loss: 2.5935352650192436
Validation loss: 2.5383596078740696

Epoch: 5| Step: 9
Training loss: 2.7914650023389953
Validation loss: 2.55113250987791

Epoch: 5| Step: 10
Training loss: 2.572845324146246
Validation loss: 2.572990450964186

Epoch: 154| Step: 0
Training loss: 2.9760592778670283
Validation loss: 2.5797873568507774

Epoch: 5| Step: 1
Training loss: 2.539629875760102
Validation loss: 2.5540111567544046

Epoch: 5| Step: 2
Training loss: 2.4410450904741654
Validation loss: 2.514489003698658

Epoch: 5| Step: 3
Training loss: 2.3438484679836153
Validation loss: 2.4986291408326275

Epoch: 5| Step: 4
Training loss: 2.5984386671181796
Validation loss: 2.46846278752418

Epoch: 5| Step: 5
Training loss: 2.4361972751069496
Validation loss: 2.4574319519356616

Epoch: 5| Step: 6
Training loss: 2.479300636924533
Validation loss: 2.43379080870695

Epoch: 5| Step: 7
Training loss: 2.6948772576571813
Validation loss: 2.4278386170643946

Epoch: 5| Step: 8
Training loss: 2.936281966242057
Validation loss: 2.4343224515896806

Epoch: 5| Step: 9
Training loss: 2.626358135018003
Validation loss: 2.432143270056002

Epoch: 5| Step: 10
Training loss: 2.4734164209967746
Validation loss: 2.44118915575438

Epoch: 155| Step: 0
Training loss: 2.1755022455623383
Validation loss: 2.438580451547526

Epoch: 5| Step: 1
Training loss: 2.586860791554662
Validation loss: 2.4581024450126483

Epoch: 5| Step: 2
Training loss: 2.5345758323259515
Validation loss: 2.471105772211092

Epoch: 5| Step: 3
Training loss: 2.466613714405839
Validation loss: 2.487813843771733

Epoch: 5| Step: 4
Training loss: 3.0210372505202185
Validation loss: 2.515196775312875

Epoch: 5| Step: 5
Training loss: 2.239294438617822
Validation loss: 2.5329294379683414

Epoch: 5| Step: 6
Training loss: 1.9868643457943642
Validation loss: 2.5484150992994556

Epoch: 5| Step: 7
Training loss: 2.842827783639748
Validation loss: 2.54509924898345

Epoch: 5| Step: 8
Training loss: 2.806808307393058
Validation loss: 2.5319195586862726

Epoch: 5| Step: 9
Training loss: 2.499056638114745
Validation loss: 2.5477201055059644

Epoch: 5| Step: 10
Training loss: 2.746844301714039
Validation loss: 2.5404316537414005

Epoch: 156| Step: 0
Training loss: 3.190181427104389
Validation loss: 2.5427441934562323

Epoch: 5| Step: 1
Training loss: 2.5305576083913217
Validation loss: 2.538458764780131

Epoch: 5| Step: 2
Training loss: 2.3344605538701404
Validation loss: 2.556221477254041

Epoch: 5| Step: 3
Training loss: 2.103867638620006
Validation loss: 2.5702607381873555

Epoch: 5| Step: 4
Training loss: 2.7916515311974313
Validation loss: 2.5794861184590268

Epoch: 5| Step: 5
Training loss: 2.654209475169553
Validation loss: 2.6055899949125654

Epoch: 5| Step: 6
Training loss: 2.609299253175237
Validation loss: 2.6236441060332907

Epoch: 5| Step: 7
Training loss: 2.3541236693470107
Validation loss: 2.5797102572918904

Epoch: 5| Step: 8
Training loss: 2.2728808793264257
Validation loss: 2.5507012092610344

Epoch: 5| Step: 9
Training loss: 2.5170430043077667
Validation loss: 2.543529155571961

Epoch: 5| Step: 10
Training loss: 2.493042037015749
Validation loss: 2.5298079339515014

Epoch: 157| Step: 0
Training loss: 2.762122053296104
Validation loss: 2.5234831596298983

Epoch: 5| Step: 1
Training loss: 2.446227271238065
Validation loss: 2.5227048478225793

Epoch: 5| Step: 2
Training loss: 2.87637826805133
Validation loss: 2.5388670547774472

Epoch: 5| Step: 3
Training loss: 2.4685216870544218
Validation loss: 2.5483933087923933

Epoch: 5| Step: 4
Training loss: 2.101439972322643
Validation loss: 2.545003204548374

Epoch: 5| Step: 5
Training loss: 2.6045950778795453
Validation loss: 2.547547737283023

Epoch: 5| Step: 6
Training loss: 2.4983611457231776
Validation loss: 2.5408671332083697

Epoch: 5| Step: 7
Training loss: 2.1872922526211407
Validation loss: 2.5411791358248585

Epoch: 5| Step: 8
Training loss: 2.2121921389774033
Validation loss: 2.548086316566329

Epoch: 5| Step: 9
Training loss: 3.124638803588835
Validation loss: 2.531830844956505

Epoch: 5| Step: 10
Training loss: 1.9741695831178523
Validation loss: 2.5481328031921113

Epoch: 158| Step: 0
Training loss: 2.4503408778750853
Validation loss: 2.535159541570234

Epoch: 5| Step: 1
Training loss: 2.357353506542786
Validation loss: 2.527886535478697

Epoch: 5| Step: 2
Training loss: 2.648138428852748
Validation loss: 2.534505549544462

Epoch: 5| Step: 3
Training loss: 2.7200274919074214
Validation loss: 2.530052023108

Epoch: 5| Step: 4
Training loss: 2.27747230755817
Validation loss: 2.5216462080593334

Epoch: 5| Step: 5
Training loss: 2.4592977237799927
Validation loss: 2.518128119085674

Epoch: 5| Step: 6
Training loss: 2.601885251481595
Validation loss: 2.524489729168106

Epoch: 5| Step: 7
Training loss: 2.0256878332216823
Validation loss: 2.526258464441294

Epoch: 5| Step: 8
Training loss: 2.6121130186694157
Validation loss: 2.5246708639884075

Epoch: 5| Step: 9
Training loss: 2.518814434429486
Validation loss: 2.5487543355887428

Epoch: 5| Step: 10
Training loss: 2.6081370997930953
Validation loss: 2.5646418012602066

Epoch: 159| Step: 0
Training loss: 2.8045392435571914
Validation loss: 2.5964217437863675

Epoch: 5| Step: 1
Training loss: 2.4587219922439467
Validation loss: 2.6224822213147143

Epoch: 5| Step: 2
Training loss: 2.343506050129726
Validation loss: 2.643775478474836

Epoch: 5| Step: 3
Training loss: 2.7713737438829305
Validation loss: 2.6479206960951176

Epoch: 5| Step: 4
Training loss: 3.057626856420356
Validation loss: 2.6318531378952716

Epoch: 5| Step: 5
Training loss: 2.5453262768976157
Validation loss: 2.6204157625572284

Epoch: 5| Step: 6
Training loss: 1.9760119006767674
Validation loss: 2.5901004177361076

Epoch: 5| Step: 7
Training loss: 2.0485130918800007
Validation loss: 2.579440653070699

Epoch: 5| Step: 8
Training loss: 2.078367634999785
Validation loss: 2.559395989798949

Epoch: 5| Step: 9
Training loss: 2.6545016649750792
Validation loss: 2.543561603920348

Epoch: 5| Step: 10
Training loss: 2.792126593968842
Validation loss: 2.540653376438537

Epoch: 160| Step: 0
Training loss: 2.3479004794772584
Validation loss: 2.5282031293416147

Epoch: 5| Step: 1
Training loss: 2.2541594734946773
Validation loss: 2.497130073626849

Epoch: 5| Step: 2
Training loss: 2.3643599641358644
Validation loss: 2.503252432276363

Epoch: 5| Step: 3
Training loss: 2.2503840860392
Validation loss: 2.4827872483656237

Epoch: 5| Step: 4
Training loss: 2.764051604047295
Validation loss: 2.4937008890953876

Epoch: 5| Step: 5
Training loss: 2.7911169355409977
Validation loss: 2.503827281776136

Epoch: 5| Step: 6
Training loss: 2.816801723274499
Validation loss: 2.5122798016901493

Epoch: 5| Step: 7
Training loss: 2.1219736876874307
Validation loss: 2.5379747739978695

Epoch: 5| Step: 8
Training loss: 2.7800118765817436
Validation loss: 2.5782234458983484

Epoch: 5| Step: 9
Training loss: 2.513278601410537
Validation loss: 2.598800969738266

Epoch: 5| Step: 10
Training loss: 2.6284307131953475
Validation loss: 2.581495239109783

Epoch: 161| Step: 0
Training loss: 2.8977066311296547
Validation loss: 2.5558478788406394

Epoch: 5| Step: 1
Training loss: 2.5421113005731972
Validation loss: 2.5250797011009665

Epoch: 5| Step: 2
Training loss: 2.495573798575583
Validation loss: 2.5260392322957768

Epoch: 5| Step: 3
Training loss: 1.8392207878917526
Validation loss: 2.5194434681435727

Epoch: 5| Step: 4
Training loss: 2.5327880331054335
Validation loss: 2.520550643771146

Epoch: 5| Step: 5
Training loss: 2.4505877159685605
Validation loss: 2.530241740753398

Epoch: 5| Step: 6
Training loss: 2.813260293557829
Validation loss: 2.5530459063908224

Epoch: 5| Step: 7
Training loss: 2.5428826805350915
Validation loss: 2.56259637506845

Epoch: 5| Step: 8
Training loss: 2.4701844888583895
Validation loss: 2.560448022800912

Epoch: 5| Step: 9
Training loss: 2.6619789724114176
Validation loss: 2.5618935334317885

Epoch: 5| Step: 10
Training loss: 2.269538708672931
Validation loss: 2.5702336460044886

Epoch: 162| Step: 0
Training loss: 2.6948487698334667
Validation loss: 2.540836844970972

Epoch: 5| Step: 1
Training loss: 1.9966940378447497
Validation loss: 2.5668397387097834

Epoch: 5| Step: 2
Training loss: 2.2578873671424393
Validation loss: 2.588360140761974

Epoch: 5| Step: 3
Training loss: 2.396911931157484
Validation loss: 2.605131669610757

Epoch: 5| Step: 4
Training loss: 2.992344944250388
Validation loss: 2.6022855564438157

Epoch: 5| Step: 5
Training loss: 2.278750264999031
Validation loss: 2.6026487813744734

Epoch: 5| Step: 6
Training loss: 2.2772693131126545
Validation loss: 2.6024547730482968

Epoch: 5| Step: 7
Training loss: 2.352380958650529
Validation loss: 2.556420043212619

Epoch: 5| Step: 8
Training loss: 2.8196445001576507
Validation loss: 2.5102527277070723

Epoch: 5| Step: 9
Training loss: 2.801504384941715
Validation loss: 2.4823386840765727

Epoch: 5| Step: 10
Training loss: 2.51645689294231
Validation loss: 2.4742906897479715

Epoch: 163| Step: 0
Training loss: 2.5482261209865147
Validation loss: 2.4710291389816943

Epoch: 5| Step: 1
Training loss: 2.851699783992
Validation loss: 2.492388582637706

Epoch: 5| Step: 2
Training loss: 2.4612041026224594
Validation loss: 2.4829841874655205

Epoch: 5| Step: 3
Training loss: 2.9477111600993107
Validation loss: 2.479039429270551

Epoch: 5| Step: 4
Training loss: 2.7710126565446633
Validation loss: 2.4912975876334267

Epoch: 5| Step: 5
Training loss: 2.5259020789731803
Validation loss: 2.475407369927778

Epoch: 5| Step: 6
Training loss: 2.4720840153537025
Validation loss: 2.491128913799108

Epoch: 5| Step: 7
Training loss: 2.099772658985107
Validation loss: 2.534293116498554

Epoch: 5| Step: 8
Training loss: 2.2407461178869506
Validation loss: 2.5373694826735824

Epoch: 5| Step: 9
Training loss: 2.5484931345655006
Validation loss: 2.5493220814536692

Epoch: 5| Step: 10
Training loss: 1.9796630906043142
Validation loss: 2.5417297418663183

Epoch: 164| Step: 0
Training loss: 2.6405607136682843
Validation loss: 2.5165100079729013

Epoch: 5| Step: 1
Training loss: 2.3525743303707607
Validation loss: 2.518370502682703

Epoch: 5| Step: 2
Training loss: 1.9521034315683412
Validation loss: 2.4967759888725656

Epoch: 5| Step: 3
Training loss: 2.9054137636804147
Validation loss: 2.4922015464608807

Epoch: 5| Step: 4
Training loss: 2.3515298530618973
Validation loss: 2.516674000610453

Epoch: 5| Step: 5
Training loss: 2.6667350720532856
Validation loss: 2.530467997422007

Epoch: 5| Step: 6
Training loss: 2.302367617169831
Validation loss: 2.549034279857314

Epoch: 5| Step: 7
Training loss: 2.093821737853934
Validation loss: 2.5735852038598104

Epoch: 5| Step: 8
Training loss: 2.188532449399363
Validation loss: 2.595829497393286

Epoch: 5| Step: 9
Training loss: 2.8683650537658276
Validation loss: 2.5999675250174796

Epoch: 5| Step: 10
Training loss: 2.6018383349571206
Validation loss: 2.61283793472905

Epoch: 165| Step: 0
Training loss: 2.3161830955431997
Validation loss: 2.6293066931724307

Epoch: 5| Step: 1
Training loss: 2.3570271108538505
Validation loss: 2.6412341560898116

Epoch: 5| Step: 2
Training loss: 2.9594732604587115
Validation loss: 2.666583958491684

Epoch: 5| Step: 3
Training loss: 2.5122813874594923
Validation loss: 2.6915956402546546

Epoch: 5| Step: 4
Training loss: 1.8853494481140376
Validation loss: 2.686496359294661

Epoch: 5| Step: 5
Training loss: 2.5769020647972627
Validation loss: 2.6848651688533205

Epoch: 5| Step: 6
Training loss: 2.217236499634737
Validation loss: 2.648973032401058

Epoch: 5| Step: 7
Training loss: 2.2912519484291596
Validation loss: 2.6077310572161965

Epoch: 5| Step: 8
Training loss: 2.5585110017630526
Validation loss: 2.5464932198155497

Epoch: 5| Step: 9
Training loss: 2.5499610224718117
Validation loss: 2.5101945408023703

Epoch: 5| Step: 10
Training loss: 2.662119226584394
Validation loss: 2.471778234612236

Epoch: 166| Step: 0
Training loss: 2.8361335455438588
Validation loss: 2.4639350278579406

Epoch: 5| Step: 1
Training loss: 2.220727388623493
Validation loss: 2.4655549296018826

Epoch: 5| Step: 2
Training loss: 2.480297268924902
Validation loss: 2.4715001323475256

Epoch: 5| Step: 3
Training loss: 2.0092498740338227
Validation loss: 2.4976531780711744

Epoch: 5| Step: 4
Training loss: 2.225984839745074
Validation loss: 2.515924288036962

Epoch: 5| Step: 5
Training loss: 2.053581259093834
Validation loss: 2.5321038164689362

Epoch: 5| Step: 6
Training loss: 2.6839429691981085
Validation loss: 2.5488515059868515

Epoch: 5| Step: 7
Training loss: 2.3331503682835635
Validation loss: 2.5593265398692875

Epoch: 5| Step: 8
Training loss: 2.98795858398904
Validation loss: 2.55260752019474

Epoch: 5| Step: 9
Training loss: 2.525736891985026
Validation loss: 2.5572356075542193

Epoch: 5| Step: 10
Training loss: 2.598565285316731
Validation loss: 2.560505067206123

Epoch: 167| Step: 0
Training loss: 2.3324208405402476
Validation loss: 2.559958359238019

Epoch: 5| Step: 1
Training loss: 1.6351676637968373
Validation loss: 2.5840847634034976

Epoch: 5| Step: 2
Training loss: 2.3851217118082593
Validation loss: 2.590804055801711

Epoch: 5| Step: 3
Training loss: 2.9886199958635244
Validation loss: 2.607181238243068

Epoch: 5| Step: 4
Training loss: 2.6786580680277496
Validation loss: 2.605711033477232

Epoch: 5| Step: 5
Training loss: 2.34038678779113
Validation loss: 2.5943474949330487

Epoch: 5| Step: 6
Training loss: 2.3098940213155825
Validation loss: 2.578462783298354

Epoch: 5| Step: 7
Training loss: 2.414906770790311
Validation loss: 2.5683780500579214

Epoch: 5| Step: 8
Training loss: 2.004444667175198
Validation loss: 2.563844393153027

Epoch: 5| Step: 9
Training loss: 2.5227274648680367
Validation loss: 2.574704956704294

Epoch: 5| Step: 10
Training loss: 2.9339709896533472
Validation loss: 2.597035890173399

Epoch: 168| Step: 0
Training loss: 2.3941913008714355
Validation loss: 2.595974783081296

Epoch: 5| Step: 1
Training loss: 2.236448059863898
Validation loss: 2.5855490441041464

Epoch: 5| Step: 2
Training loss: 2.5448319367262036
Validation loss: 2.5910817692076433

Epoch: 5| Step: 3
Training loss: 2.407230920381451
Validation loss: 2.5662256125048617

Epoch: 5| Step: 4
Training loss: 2.6492867247608167
Validation loss: 2.5764501198218475

Epoch: 5| Step: 5
Training loss: 2.5916249405751373
Validation loss: 2.5843637246089792

Epoch: 5| Step: 6
Training loss: 1.898624363874449
Validation loss: 2.5760831153264236

Epoch: 5| Step: 7
Training loss: 2.8078864510827484
Validation loss: 2.5669607448534353

Epoch: 5| Step: 8
Training loss: 2.4673818346231635
Validation loss: 2.5528386183535248

Epoch: 5| Step: 9
Training loss: 2.057573851213667
Validation loss: 2.537911765413781

Epoch: 5| Step: 10
Training loss: 2.152439676075282
Validation loss: 2.5396346151442413

Epoch: 169| Step: 0
Training loss: 2.6147055629007374
Validation loss: 2.528819842055419

Epoch: 5| Step: 1
Training loss: 2.2268423874935093
Validation loss: 2.510181320147604

Epoch: 5| Step: 2
Training loss: 2.253173180010776
Validation loss: 2.5186530779745033

Epoch: 5| Step: 3
Training loss: 2.509471879089
Validation loss: 2.549130124138982

Epoch: 5| Step: 4
Training loss: 2.122751617254913
Validation loss: 2.5514645011829846

Epoch: 5| Step: 5
Training loss: 1.9974419208433405
Validation loss: 2.5491713974184207

Epoch: 5| Step: 6
Training loss: 2.8784258789782107
Validation loss: 2.5596840565695156

Epoch: 5| Step: 7
Training loss: 2.6123563444074804
Validation loss: 2.5618925767796585

Epoch: 5| Step: 8
Training loss: 2.6150800276230175
Validation loss: 2.5738691387300565

Epoch: 5| Step: 9
Training loss: 2.269049115600535
Validation loss: 2.5608090469793763

Epoch: 5| Step: 10
Training loss: 2.114428422136263
Validation loss: 2.553046346208414

Epoch: 170| Step: 0
Training loss: 2.198630001747115
Validation loss: 2.553242392878633

Epoch: 5| Step: 1
Training loss: 2.571386976511157
Validation loss: 2.556377290441312

Epoch: 5| Step: 2
Training loss: 2.4885197260195326
Validation loss: 2.5450594458001756

Epoch: 5| Step: 3
Training loss: 2.4043115511584974
Validation loss: 2.5442799137585004

Epoch: 5| Step: 4
Training loss: 2.2840488978628213
Validation loss: 2.544050812841903

Epoch: 5| Step: 5
Training loss: 2.2155793867271787
Validation loss: 2.5385680216493416

Epoch: 5| Step: 6
Training loss: 2.1311304635004675
Validation loss: 2.5449183069448917

Epoch: 5| Step: 7
Training loss: 2.689530160281298
Validation loss: 2.542791984559923

Epoch: 5| Step: 8
Training loss: 2.349078720176837
Validation loss: 2.5379393905122902

Epoch: 5| Step: 9
Training loss: 2.3143561878104237
Validation loss: 2.554945505061665

Epoch: 5| Step: 10
Training loss: 2.125767288807058
Validation loss: 2.55764051821093

Epoch: 171| Step: 0
Training loss: 2.0578917839284823
Validation loss: 2.579147256519094

Epoch: 5| Step: 1
Training loss: 2.2022066840273653
Validation loss: 2.5892371919083152

Epoch: 5| Step: 2
Training loss: 2.7025679527018274
Validation loss: 2.592646757936424

Epoch: 5| Step: 3
Training loss: 1.9452486449029662
Validation loss: 2.5824924584735762

Epoch: 5| Step: 4
Training loss: 2.2563688421255708
Validation loss: 2.5784351757675905

Epoch: 5| Step: 5
Training loss: 2.416718339915693
Validation loss: 2.586968290133268

Epoch: 5| Step: 6
Training loss: 2.1617125825066745
Validation loss: 2.5930275393344315

Epoch: 5| Step: 7
Training loss: 2.270262713585432
Validation loss: 2.5989612840152416

Epoch: 5| Step: 8
Training loss: 2.438348671305826
Validation loss: 2.5964070762966585

Epoch: 5| Step: 9
Training loss: 2.2247239402361836
Validation loss: 2.5664922347990045

Epoch: 5| Step: 10
Training loss: 3.0462802404280955
Validation loss: 2.561641027915901

Epoch: 172| Step: 0
Training loss: 2.3017911653687713
Validation loss: 2.571761458618414

Epoch: 5| Step: 1
Training loss: 2.4209126190841177
Validation loss: 2.5669099910810256

Epoch: 5| Step: 2
Training loss: 2.169434198194407
Validation loss: 2.5568764550860656

Epoch: 5| Step: 3
Training loss: 2.808194828485493
Validation loss: 2.532962579777253

Epoch: 5| Step: 4
Training loss: 2.2977939765481343
Validation loss: 2.5338658173405624

Epoch: 5| Step: 5
Training loss: 1.613631979292849
Validation loss: 2.5169368990048007

Epoch: 5| Step: 6
Training loss: 2.2935764215884022
Validation loss: 2.4977380384512546

Epoch: 5| Step: 7
Training loss: 2.114059558762043
Validation loss: 2.5001229302115706

Epoch: 5| Step: 8
Training loss: 2.9729172219853104
Validation loss: 2.5041025207137824

Epoch: 5| Step: 9
Training loss: 1.8738433449202416
Validation loss: 2.525904751564168

Epoch: 5| Step: 10
Training loss: 2.1909819003410482
Validation loss: 2.5569319759770432

Epoch: 173| Step: 0
Training loss: 2.7087824718041174
Validation loss: 2.5594792623216716

Epoch: 5| Step: 1
Training loss: 2.1597228900326444
Validation loss: 2.596101950022836

Epoch: 5| Step: 2
Training loss: 2.222971272058572
Validation loss: 2.6036878484433745

Epoch: 5| Step: 3
Training loss: 2.4404723799849655
Validation loss: 2.608374080623403

Epoch: 5| Step: 4
Training loss: 2.2784280959958
Validation loss: 2.6000829942139543

Epoch: 5| Step: 5
Training loss: 2.527380351961581
Validation loss: 2.606345372237747

Epoch: 5| Step: 6
Training loss: 2.0527396016004467
Validation loss: 2.5697988114074217

Epoch: 5| Step: 7
Training loss: 2.3630988436837614
Validation loss: 2.5824021048003147

Epoch: 5| Step: 8
Training loss: 2.24218473533965
Validation loss: 2.5491173598598653

Epoch: 5| Step: 9
Training loss: 2.1904996740867304
Validation loss: 2.540183437591013

Epoch: 5| Step: 10
Training loss: 2.0869395388814054
Validation loss: 2.5210448579478286

Epoch: 174| Step: 0
Training loss: 2.4301429640547134
Validation loss: 2.5167835767348423

Epoch: 5| Step: 1
Training loss: 2.4087807364054292
Validation loss: 2.5000639568884777

Epoch: 5| Step: 2
Training loss: 2.468368597386188
Validation loss: 2.501438424366462

Epoch: 5| Step: 3
Training loss: 2.1767408354051394
Validation loss: 2.4962152278234737

Epoch: 5| Step: 4
Training loss: 1.826080352611329
Validation loss: 2.5213976494260653

Epoch: 5| Step: 5
Training loss: 2.101819331134915
Validation loss: 2.5511132739527413

Epoch: 5| Step: 6
Training loss: 1.9577277917948008
Validation loss: 2.5814841999686666

Epoch: 5| Step: 7
Training loss: 2.509729336131131
Validation loss: 2.5889376769061387

Epoch: 5| Step: 8
Training loss: 1.9210568679303557
Validation loss: 2.6187556621178896

Epoch: 5| Step: 9
Training loss: 2.7026709908480773
Validation loss: 2.644852336638136

Epoch: 5| Step: 10
Training loss: 2.2494274046597345
Validation loss: 2.640807654504018

Epoch: 175| Step: 0
Training loss: 2.1682534520620855
Validation loss: 2.6171855095733485

Epoch: 5| Step: 1
Training loss: 2.5624833455358655
Validation loss: 2.56865448083129

Epoch: 5| Step: 2
Training loss: 2.2295390260766523
Validation loss: 2.5357175430316876

Epoch: 5| Step: 3
Training loss: 2.3388989918244696
Validation loss: 2.503224441789651

Epoch: 5| Step: 4
Training loss: 2.410650415936837
Validation loss: 2.474806115958936

Epoch: 5| Step: 5
Training loss: 2.1918867539786
Validation loss: 2.4651741609968614

Epoch: 5| Step: 6
Training loss: 2.838660412092412
Validation loss: 2.4584981339244116

Epoch: 5| Step: 7
Training loss: 2.30870549017068
Validation loss: 2.472023364584047

Epoch: 5| Step: 8
Training loss: 1.485856050170407
Validation loss: 2.4723162964036103

Epoch: 5| Step: 9
Training loss: 1.2172755590275501
Validation loss: 2.491935731407467

Epoch: 5| Step: 10
Training loss: 2.625328497541064
Validation loss: 2.534627559248552

Epoch: 176| Step: 0
Training loss: 2.47826800901838
Validation loss: 2.534561100261558

Epoch: 5| Step: 1
Training loss: 2.1377562073755865
Validation loss: 2.560907641983451

Epoch: 5| Step: 2
Training loss: 1.5034024274022149
Validation loss: 2.5761552730974064

Epoch: 5| Step: 3
Training loss: 2.02019485402522
Validation loss: 2.60295054204897

Epoch: 5| Step: 4
Training loss: 2.2170354101427114
Validation loss: 2.588229181174452

Epoch: 5| Step: 5
Training loss: 2.2145232653314104
Validation loss: 2.5896225988594472

Epoch: 5| Step: 6
Training loss: 2.149284722866258
Validation loss: 2.5644519193818107

Epoch: 5| Step: 7
Training loss: 2.3835915214455636
Validation loss: 2.5367371922435433

Epoch: 5| Step: 8
Training loss: 2.321577863818269
Validation loss: 2.5090101840739254

Epoch: 5| Step: 9
Training loss: 2.7024329738439206
Validation loss: 2.4840055874558953

Epoch: 5| Step: 10
Training loss: 2.02439498340322
Validation loss: 2.491506625421681

Epoch: 177| Step: 0
Training loss: 2.299872486062746
Validation loss: 2.4829136962232976

Epoch: 5| Step: 1
Training loss: 1.9342782090333868
Validation loss: 2.479842185888314

Epoch: 5| Step: 2
Training loss: 2.064064588408529
Validation loss: 2.497693297932258

Epoch: 5| Step: 3
Training loss: 2.275625951819678
Validation loss: 2.484548077572086

Epoch: 5| Step: 4
Training loss: 1.8899794177796585
Validation loss: 2.48806646015673

Epoch: 5| Step: 5
Training loss: 2.324565547426755
Validation loss: 2.507495150981359

Epoch: 5| Step: 6
Training loss: 1.8682451006257084
Validation loss: 2.520931571145285

Epoch: 5| Step: 7
Training loss: 2.463240644735498
Validation loss: 2.526943379151491

Epoch: 5| Step: 8
Training loss: 2.253761855447047
Validation loss: 2.541370216368052

Epoch: 5| Step: 9
Training loss: 2.448439965554209
Validation loss: 2.547704487468418

Epoch: 5| Step: 10
Training loss: 2.327341856864474
Validation loss: 2.5588207608517166

Epoch: 178| Step: 0
Training loss: 1.8601474599938987
Validation loss: 2.564742872796872

Epoch: 5| Step: 1
Training loss: 2.4006953344790043
Validation loss: 2.5687364611872554

Epoch: 5| Step: 2
Training loss: 2.2245770084481484
Validation loss: 2.570904375322834

Epoch: 5| Step: 3
Training loss: 1.7745687095085514
Validation loss: 2.574110004400554

Epoch: 5| Step: 4
Training loss: 2.2558097008194276
Validation loss: 2.563668611597689

Epoch: 5| Step: 5
Training loss: 2.0994402866143456
Validation loss: 2.5514255910823103

Epoch: 5| Step: 6
Training loss: 2.0632053671839152
Validation loss: 2.5089995157119747

Epoch: 5| Step: 7
Training loss: 2.1343141516393933
Validation loss: 2.480100618316628

Epoch: 5| Step: 8
Training loss: 2.6088020472322286
Validation loss: 2.4618629388787863

Epoch: 5| Step: 9
Training loss: 2.155175978164356
Validation loss: 2.4744829130537522

Epoch: 5| Step: 10
Training loss: 2.433238779695674
Validation loss: 2.4738094811382485

Epoch: 179| Step: 0
Training loss: 1.9496457047040239
Validation loss: 2.475575407809625

Epoch: 5| Step: 1
Training loss: 1.7405153469427137
Validation loss: 2.484126884467549

Epoch: 5| Step: 2
Training loss: 1.8322332144806495
Validation loss: 2.4936770331607163

Epoch: 5| Step: 3
Training loss: 2.5423203445922367
Validation loss: 2.500457567979746

Epoch: 5| Step: 4
Training loss: 2.219486812695889
Validation loss: 2.50227035470096

Epoch: 5| Step: 5
Training loss: 1.4735067729503044
Validation loss: 2.5085529446566515

Epoch: 5| Step: 6
Training loss: 2.5149509640533783
Validation loss: 2.51732671238687

Epoch: 5| Step: 7
Training loss: 1.7495221439256439
Validation loss: 2.5191273741965707

Epoch: 5| Step: 8
Training loss: 2.2686870009237503
Validation loss: 2.529280879668968

Epoch: 5| Step: 9
Training loss: 2.5528457021918145
Validation loss: 2.548795758786293

Epoch: 5| Step: 10
Training loss: 2.71362154227424
Validation loss: 2.5829075827324686

Epoch: 180| Step: 0
Training loss: 2.1593368107334996
Validation loss: 2.5764041252258045

Epoch: 5| Step: 1
Training loss: 2.3622041628053454
Validation loss: 2.579134352538562

Epoch: 5| Step: 2
Training loss: 2.2205098654363145
Validation loss: 2.583938697069732

Epoch: 5| Step: 3
Training loss: 1.9277599762025326
Validation loss: 2.6001678111315547

Epoch: 5| Step: 4
Training loss: 2.171625575830595
Validation loss: 2.583011099664809

Epoch: 5| Step: 5
Training loss: 2.3208674014574173
Validation loss: 2.59201964861774

Epoch: 5| Step: 6
Training loss: 1.9862605470697814
Validation loss: 2.553036701332655

Epoch: 5| Step: 7
Training loss: 2.169443979180493
Validation loss: 2.534892185401664

Epoch: 5| Step: 8
Training loss: 2.0037834620641517
Validation loss: 2.491469265953675

Epoch: 5| Step: 9
Training loss: 2.212499168094112
Validation loss: 2.4711156642459895

Epoch: 5| Step: 10
Training loss: 2.3446786693684816
Validation loss: 2.487707604756494

Epoch: 181| Step: 0
Training loss: 2.0334104346160586
Validation loss: 2.4842669148176073

Epoch: 5| Step: 1
Training loss: 2.041264890206498
Validation loss: 2.4947167591953776

Epoch: 5| Step: 2
Training loss: 1.9848268249842358
Validation loss: 2.470739250368095

Epoch: 5| Step: 3
Training loss: 2.129722844570119
Validation loss: 2.4660896774533962

Epoch: 5| Step: 4
Training loss: 2.060913863201974
Validation loss: 2.476718599412634

Epoch: 5| Step: 5
Training loss: 2.393901499443552
Validation loss: 2.4597891335861197

Epoch: 5| Step: 6
Training loss: 2.211525343533909
Validation loss: 2.4810331051896317

Epoch: 5| Step: 7
Training loss: 2.2962786880055046
Validation loss: 2.509415672856434

Epoch: 5| Step: 8
Training loss: 2.312723716018258
Validation loss: 2.5345339440835106

Epoch: 5| Step: 9
Training loss: 1.899054281880153
Validation loss: 2.5432278793905034

Epoch: 5| Step: 10
Training loss: 2.461049685872971
Validation loss: 2.5692568569630927

Epoch: 182| Step: 0
Training loss: 1.734821227809686
Validation loss: 2.56318868191206

Epoch: 5| Step: 1
Training loss: 2.178563310040751
Validation loss: 2.5559636722053085

Epoch: 5| Step: 2
Training loss: 2.0272400228612613
Validation loss: 2.5602144302558147

Epoch: 5| Step: 3
Training loss: 1.5799006679552574
Validation loss: 2.565294722133699

Epoch: 5| Step: 4
Training loss: 1.5508099992907405
Validation loss: 2.5551343769532977

Epoch: 5| Step: 5
Training loss: 2.3027781708025112
Validation loss: 2.5553227879347107

Epoch: 5| Step: 6
Training loss: 2.6669974618620036
Validation loss: 2.5565120065815155

Epoch: 5| Step: 7
Training loss: 2.5903862892673963
Validation loss: 2.5577826930240652

Epoch: 5| Step: 8
Training loss: 2.0726661978093586
Validation loss: 2.552917996588453

Epoch: 5| Step: 9
Training loss: 2.5507346086195675
Validation loss: 2.5363130339384554

Epoch: 5| Step: 10
Training loss: 1.4785934286672497
Validation loss: 2.521763680660454

Epoch: 183| Step: 0
Training loss: 2.133945038635597
Validation loss: 2.533051218954238

Epoch: 5| Step: 1
Training loss: 2.2461560580691913
Validation loss: 2.533343257935885

Epoch: 5| Step: 2
Training loss: 2.0553178291779517
Validation loss: 2.544552913427729

Epoch: 5| Step: 3
Training loss: 2.2952669703964865
Validation loss: 2.5393695412793433

Epoch: 5| Step: 4
Training loss: 2.2321385214627254
Validation loss: 2.527676592894689

Epoch: 5| Step: 5
Training loss: 2.3875627040118506
Validation loss: 2.5197099911462035

Epoch: 5| Step: 6
Training loss: 1.9654971300995494
Validation loss: 2.528156654493056

Epoch: 5| Step: 7
Training loss: 2.0381383445885435
Validation loss: 2.494844807598698

Epoch: 5| Step: 8
Training loss: 1.8593730766222327
Validation loss: 2.506805434437031

Epoch: 5| Step: 9
Training loss: 2.116378685992465
Validation loss: 2.483705118294653

Epoch: 5| Step: 10
Training loss: 2.0421049724502067
Validation loss: 2.4937286729271

Epoch: 184| Step: 0
Training loss: 2.593321983227576
Validation loss: 2.477689508928756

Epoch: 5| Step: 1
Training loss: 2.047940857577199
Validation loss: 2.455751408114008

Epoch: 5| Step: 2
Training loss: 2.2840381462666235
Validation loss: 2.449142203384584

Epoch: 5| Step: 3
Training loss: 2.129997771535075
Validation loss: 2.4547740336040147

Epoch: 5| Step: 4
Training loss: 2.2892089380287426
Validation loss: 2.4580259518538248

Epoch: 5| Step: 5
Training loss: 2.1181775695454546
Validation loss: 2.4628087172510735

Epoch: 5| Step: 6
Training loss: 2.2680901106302995
Validation loss: 2.4665241168115513

Epoch: 5| Step: 7
Training loss: 1.8969813284068182
Validation loss: 2.463250025081305

Epoch: 5| Step: 8
Training loss: 2.0103518091785526
Validation loss: 2.4805844386630898

Epoch: 5| Step: 9
Training loss: 1.822331957821036
Validation loss: 2.514888259374598

Epoch: 5| Step: 10
Training loss: 1.6948895608037513
Validation loss: 2.516647134779928

Epoch: 185| Step: 0
Training loss: 2.0434570895870663
Validation loss: 2.5412510186227686

Epoch: 5| Step: 1
Training loss: 1.944406627862523
Validation loss: 2.5510428192038654

Epoch: 5| Step: 2
Training loss: 1.840579976954425
Validation loss: 2.5721463265860955

Epoch: 5| Step: 3
Training loss: 2.455655099204194
Validation loss: 2.58083889622428

Epoch: 5| Step: 4
Training loss: 2.4354318501369274
Validation loss: 2.5662375933962616

Epoch: 5| Step: 5
Training loss: 1.8837452710857407
Validation loss: 2.5488029795885048

Epoch: 5| Step: 6
Training loss: 1.6744810097438543
Validation loss: 2.5368006251383797

Epoch: 5| Step: 7
Training loss: 2.434070228234297
Validation loss: 2.5184751056842263

Epoch: 5| Step: 8
Training loss: 1.7634573264176105
Validation loss: 2.537333362271849

Epoch: 5| Step: 9
Training loss: 2.1700164746832518
Validation loss: 2.528700127226838

Epoch: 5| Step: 10
Training loss: 2.221909114184092
Validation loss: 2.5038170024237303

Epoch: 186| Step: 0
Training loss: 1.7808881693305105
Validation loss: 2.491021702110392

Epoch: 5| Step: 1
Training loss: 1.1669808997721618
Validation loss: 2.479864053590853

Epoch: 5| Step: 2
Training loss: 2.396527054460268
Validation loss: 2.4597164877174773

Epoch: 5| Step: 3
Training loss: 2.4029468802725584
Validation loss: 2.4827553274283263

Epoch: 5| Step: 4
Training loss: 2.514894177919869
Validation loss: 2.4941286380059084

Epoch: 5| Step: 5
Training loss: 2.5737827609081347
Validation loss: 2.4953579736557847

Epoch: 5| Step: 6
Training loss: 1.7961249071283534
Validation loss: 2.502629703875757

Epoch: 5| Step: 7
Training loss: 1.998422477373413
Validation loss: 2.4874219710986765

Epoch: 5| Step: 8
Training loss: 1.9538118909330466
Validation loss: 2.4836736757072133

Epoch: 5| Step: 9
Training loss: 1.7689761876497727
Validation loss: 2.4969389366843013

Epoch: 5| Step: 10
Training loss: 2.2852852026916906
Validation loss: 2.5280299546788756

Epoch: 187| Step: 0
Training loss: 2.083496723125784
Validation loss: 2.5254482054649516

Epoch: 5| Step: 1
Training loss: 2.1063528381054706
Validation loss: 2.5425514370365367

Epoch: 5| Step: 2
Training loss: 2.2821062127285656
Validation loss: 2.538153423319027

Epoch: 5| Step: 3
Training loss: 2.073166862481446
Validation loss: 2.5322778383053426

Epoch: 5| Step: 4
Training loss: 1.982483149741914
Validation loss: 2.5301180057582235

Epoch: 5| Step: 5
Training loss: 1.728261120696828
Validation loss: 2.520966731662078

Epoch: 5| Step: 6
Training loss: 2.0336968576420036
Validation loss: 2.5057764179084794

Epoch: 5| Step: 7
Training loss: 2.216483664547311
Validation loss: 2.508118644599531

Epoch: 5| Step: 8
Training loss: 1.7922336509236663
Validation loss: 2.494532675466645

Epoch: 5| Step: 9
Training loss: 2.1804685663040724
Validation loss: 2.483499723769099

Epoch: 5| Step: 10
Training loss: 2.225975200093358
Validation loss: 2.482411388763855

Epoch: 188| Step: 0
Training loss: 2.0873385521137044
Validation loss: 2.479280448681605

Epoch: 5| Step: 1
Training loss: 2.0939555280785114
Validation loss: 2.482685233954111

Epoch: 5| Step: 2
Training loss: 1.4470344801606083
Validation loss: 2.498330023039046

Epoch: 5| Step: 3
Training loss: 2.6113443766439874
Validation loss: 2.5062405621431707

Epoch: 5| Step: 4
Training loss: 2.3909712397346565
Validation loss: 2.4985127834799523

Epoch: 5| Step: 5
Training loss: 1.7409163828691872
Validation loss: 2.4939389599512722

Epoch: 5| Step: 6
Training loss: 1.2443195495819643
Validation loss: 2.4876004130819585

Epoch: 5| Step: 7
Training loss: 1.8588370819318505
Validation loss: 2.49577190686444

Epoch: 5| Step: 8
Training loss: 1.89229472177067
Validation loss: 2.5019400093721265

Epoch: 5| Step: 9
Training loss: 2.669385586884837
Validation loss: 2.50806131944023

Epoch: 5| Step: 10
Training loss: 1.968032706244772
Validation loss: 2.5053960565124864

Epoch: 189| Step: 0
Training loss: 2.0933452613555525
Validation loss: 2.517494470564355

Epoch: 5| Step: 1
Training loss: 1.8599012896278726
Validation loss: 2.540789713297681

Epoch: 5| Step: 2
Training loss: 1.941917674440134
Validation loss: 2.56440098249515

Epoch: 5| Step: 3
Training loss: 2.001912156593002
Validation loss: 2.5615962966358192

Epoch: 5| Step: 4
Training loss: 1.8869999583193275
Validation loss: 2.569305814243885

Epoch: 5| Step: 5
Training loss: 2.3429961963253105
Validation loss: 2.5479877355525766

Epoch: 5| Step: 6
Training loss: 2.196588871475062
Validation loss: 2.544945825767813

Epoch: 5| Step: 7
Training loss: 1.996633438041891
Validation loss: 2.5472102072655196

Epoch: 5| Step: 8
Training loss: 2.3373586356923712
Validation loss: 2.537800092221841

Epoch: 5| Step: 9
Training loss: 1.9887770238894888
Validation loss: 2.540155786939666

Epoch: 5| Step: 10
Training loss: 1.3595740073972697
Validation loss: 2.5387411611208277

Epoch: 190| Step: 0
Training loss: 2.101540490925064
Validation loss: 2.524315462919885

Epoch: 5| Step: 1
Training loss: 1.7265653998579296
Validation loss: 2.505898617169175

Epoch: 5| Step: 2
Training loss: 1.7251883860012516
Validation loss: 2.503413159777572

Epoch: 5| Step: 3
Training loss: 1.869144898093829
Validation loss: 2.4971376127081277

Epoch: 5| Step: 4
Training loss: 1.781676994141544
Validation loss: 2.466237668496907

Epoch: 5| Step: 5
Training loss: 2.032990399609596
Validation loss: 2.465339490792181

Epoch: 5| Step: 6
Training loss: 2.0905703413451118
Validation loss: 2.45630681385693

Epoch: 5| Step: 7
Training loss: 2.2137220122228314
Validation loss: 2.4849346694220564

Epoch: 5| Step: 8
Training loss: 1.4663919227644027
Validation loss: 2.502843308456345

Epoch: 5| Step: 9
Training loss: 2.250707938825274
Validation loss: 2.5038631667725895

Epoch: 5| Step: 10
Training loss: 2.6017946248556933
Validation loss: 2.5087740962386658

Epoch: 191| Step: 0
Training loss: 1.7482303800110637
Validation loss: 2.5181344932385943

Epoch: 5| Step: 1
Training loss: 2.003855565194175
Validation loss: 2.495341674474688

Epoch: 5| Step: 2
Training loss: 1.9176670932704099
Validation loss: 2.505771235428919

Epoch: 5| Step: 3
Training loss: 2.2399063468837395
Validation loss: 2.477084445579677

Epoch: 5| Step: 4
Training loss: 1.9756180387746605
Validation loss: 2.4798537984449505

Epoch: 5| Step: 5
Training loss: 2.2149492403504647
Validation loss: 2.470319055895936

Epoch: 5| Step: 6
Training loss: 1.7368793449333784
Validation loss: 2.4819138147887756

Epoch: 5| Step: 7
Training loss: 1.2252865125395282
Validation loss: 2.4757587327654367

Epoch: 5| Step: 8
Training loss: 1.9645528710741917
Validation loss: 2.4746011576096154

Epoch: 5| Step: 9
Training loss: 2.1800009662731026
Validation loss: 2.492774779229324

Epoch: 5| Step: 10
Training loss: 2.6795079474170245
Validation loss: 2.4923960049166434

Epoch: 192| Step: 0
Training loss: 2.085186312284755
Validation loss: 2.505234318814347

Epoch: 5| Step: 1
Training loss: 1.8739566443200493
Validation loss: 2.5009200566834466

Epoch: 5| Step: 2
Training loss: 2.21503599701644
Validation loss: 2.51827941152822

Epoch: 5| Step: 3
Training loss: 1.8838748704698756
Validation loss: 2.5418749780552865

Epoch: 5| Step: 4
Training loss: 2.1716009831638328
Validation loss: 2.52343498455138

Epoch: 5| Step: 5
Training loss: 1.9668532423107552
Validation loss: 2.5386337304446096

Epoch: 5| Step: 6
Training loss: 2.0126655794822854
Validation loss: 2.534361343121418

Epoch: 5| Step: 7
Training loss: 1.6489108883877346
Validation loss: 2.5272438308641028

Epoch: 5| Step: 8
Training loss: 1.7408591368086634
Validation loss: 2.520029620400021

Epoch: 5| Step: 9
Training loss: 1.9153359050319645
Validation loss: 2.5270067160050416

Epoch: 5| Step: 10
Training loss: 2.0076994511583752
Validation loss: 2.523310711054394

Epoch: 193| Step: 0
Training loss: 1.741899338228146
Validation loss: 2.503622869397453

Epoch: 5| Step: 1
Training loss: 2.2634314079365954
Validation loss: 2.510439436117456

Epoch: 5| Step: 2
Training loss: 1.9931422918795112
Validation loss: 2.502104997938555

Epoch: 5| Step: 3
Training loss: 2.1063416322420987
Validation loss: 2.5014588590976725

Epoch: 5| Step: 4
Training loss: 2.0118015901860566
Validation loss: 2.4928870625813624

Epoch: 5| Step: 5
Training loss: 1.7879539286845825
Validation loss: 2.4801270381084364

Epoch: 5| Step: 6
Training loss: 1.6319919696498095
Validation loss: 2.489251732072042

Epoch: 5| Step: 7
Training loss: 1.9812708327103663
Validation loss: 2.51386029666418

Epoch: 5| Step: 8
Training loss: 1.8489842229472278
Validation loss: 2.5534623084336374

Epoch: 5| Step: 9
Training loss: 2.00399631349906
Validation loss: 2.533983825199839

Epoch: 5| Step: 10
Training loss: 1.9428490050029221
Validation loss: 2.536572620911289

Epoch: 194| Step: 0
Training loss: 1.8247017394599812
Validation loss: 2.530362008773997

Epoch: 5| Step: 1
Training loss: 1.8006830747243543
Validation loss: 2.543559594178795

Epoch: 5| Step: 2
Training loss: 2.398325765287199
Validation loss: 2.5057771166804437

Epoch: 5| Step: 3
Training loss: 1.795699356934845
Validation loss: 2.481074591661834

Epoch: 5| Step: 4
Training loss: 1.6483784886504989
Validation loss: 2.487442205603503

Epoch: 5| Step: 5
Training loss: 2.016479074669892
Validation loss: 2.467094604710956

Epoch: 5| Step: 6
Training loss: 1.8982070971418072
Validation loss: 2.4421628332475813

Epoch: 5| Step: 7
Training loss: 1.6795310014076343
Validation loss: 2.4391190016724713

Epoch: 5| Step: 8
Training loss: 2.326993321584996
Validation loss: 2.452827159116448

Epoch: 5| Step: 9
Training loss: 1.710000465236846
Validation loss: 2.4282110844733897

Epoch: 5| Step: 10
Training loss: 2.037809257206401
Validation loss: 2.447154526331757

Epoch: 195| Step: 0
Training loss: 2.0717798179523585
Validation loss: 2.477041733123349

Epoch: 5| Step: 1
Training loss: 1.5187726713772498
Validation loss: 2.494524198951546

Epoch: 5| Step: 2
Training loss: 2.022306501753909
Validation loss: 2.5178022257615393

Epoch: 5| Step: 3
Training loss: 1.6181966240783185
Validation loss: 2.5304720275675523

Epoch: 5| Step: 4
Training loss: 1.8194441791304508
Validation loss: 2.537287003129762

Epoch: 5| Step: 5
Training loss: 2.0174709413461263
Validation loss: 2.537900991261018

Epoch: 5| Step: 6
Training loss: 1.7133785583721861
Validation loss: 2.531350072424276

Epoch: 5| Step: 7
Training loss: 2.1674368540927533
Validation loss: 2.5226754502382858

Epoch: 5| Step: 8
Training loss: 1.6031472901696435
Validation loss: 2.53147575336905

Epoch: 5| Step: 9
Training loss: 2.3777111039167407
Validation loss: 2.5367607089252293

Epoch: 5| Step: 10
Training loss: 2.031593059033582
Validation loss: 2.522593838846275

Epoch: 196| Step: 0
Training loss: 2.0842659070978633
Validation loss: 2.5061956726721117

Epoch: 5| Step: 1
Training loss: 1.471394856208209
Validation loss: 2.4921388444224797

Epoch: 5| Step: 2
Training loss: 1.7295130723567842
Validation loss: 2.453036828511029

Epoch: 5| Step: 3
Training loss: 1.7688942408973285
Validation loss: 2.4601706918830053

Epoch: 5| Step: 4
Training loss: 1.826673534663485
Validation loss: 2.4323014692182023

Epoch: 5| Step: 5
Training loss: 2.451227316666325
Validation loss: 2.4368647622423776

Epoch: 5| Step: 6
Training loss: 1.8452621982834359
Validation loss: 2.457656748127624

Epoch: 5| Step: 7
Training loss: 2.0348439040993522
Validation loss: 2.4608959511568216

Epoch: 5| Step: 8
Training loss: 1.5125882115137859
Validation loss: 2.4865846574954515

Epoch: 5| Step: 9
Training loss: 1.9476676686576126
Validation loss: 2.471910290128906

Epoch: 5| Step: 10
Training loss: 2.5200429470701735
Validation loss: 2.472405102393222

Epoch: 197| Step: 0
Training loss: 1.5842264651283637
Validation loss: 2.4528185280225134

Epoch: 5| Step: 1
Training loss: 1.714379736615298
Validation loss: 2.426131824098619

Epoch: 5| Step: 2
Training loss: 2.2941796713711136
Validation loss: 2.421506616452788

Epoch: 5| Step: 3
Training loss: 1.583720419230374
Validation loss: 2.4222639191693744

Epoch: 5| Step: 4
Training loss: 1.8510200575077242
Validation loss: 2.4545049590647707

Epoch: 5| Step: 5
Training loss: 1.7859724920787996
Validation loss: 2.4456426806506153

Epoch: 5| Step: 6
Training loss: 2.1663498891438575
Validation loss: 2.481258243890017

Epoch: 5| Step: 7
Training loss: 1.832052787865635
Validation loss: 2.499857519047877

Epoch: 5| Step: 8
Training loss: 2.594368366847775
Validation loss: 2.494876084736377

Epoch: 5| Step: 9
Training loss: 1.855247082770557
Validation loss: 2.511989104789852

Epoch: 5| Step: 10
Training loss: 2.3110239627904763
Validation loss: 2.554762097435175

Epoch: 198| Step: 0
Training loss: 2.2300335514640843
Validation loss: 2.5732694910949956

Epoch: 5| Step: 1
Training loss: 1.648810032698061
Validation loss: 2.590346593097675

Epoch: 5| Step: 2
Training loss: 2.1750505682668213
Validation loss: 2.6308148812416574

Epoch: 5| Step: 3
Training loss: 1.696224617708425
Validation loss: 2.622555525757216

Epoch: 5| Step: 4
Training loss: 1.8045107932503903
Validation loss: 2.6011950037351306

Epoch: 5| Step: 5
Training loss: 2.1983515111920235
Validation loss: 2.5768139063155355

Epoch: 5| Step: 6
Training loss: 2.269994061500075
Validation loss: 2.5182420939570855

Epoch: 5| Step: 7
Training loss: 1.6632947986601039
Validation loss: 2.4985359191236047

Epoch: 5| Step: 8
Training loss: 1.978757099806386
Validation loss: 2.473908665692252

Epoch: 5| Step: 9
Training loss: 1.9915347956118086
Validation loss: 2.4453040772219965

Epoch: 5| Step: 10
Training loss: 1.4446726439428201
Validation loss: 2.4262811841362475

Epoch: 199| Step: 0
Training loss: 1.6253202562930045
Validation loss: 2.4271247758477945

Epoch: 5| Step: 1
Training loss: 1.8865808788021687
Validation loss: 2.4270395141797776

Epoch: 5| Step: 2
Training loss: 1.605896978511019
Validation loss: 2.4003628341569403

Epoch: 5| Step: 3
Training loss: 1.8016575069471077
Validation loss: 2.414229896445118

Epoch: 5| Step: 4
Training loss: 1.294848685979613
Validation loss: 2.4354144151461545

Epoch: 5| Step: 5
Training loss: 2.372786645003617
Validation loss: 2.4748226752118043

Epoch: 5| Step: 6
Training loss: 2.175535999769138
Validation loss: 2.535834623595965

Epoch: 5| Step: 7
Training loss: 1.6333924500153696
Validation loss: 2.558343992150614

Epoch: 5| Step: 8
Training loss: 2.485622644536027
Validation loss: 2.6010355091843027

Epoch: 5| Step: 9
Training loss: 2.0371420282542965
Validation loss: 2.5398535857409805

Epoch: 5| Step: 10
Training loss: 1.8015961034309163
Validation loss: 2.4892782926397845

Epoch: 200| Step: 0
Training loss: 1.9992119309375023
Validation loss: 2.4627488441510583

Epoch: 5| Step: 1
Training loss: 2.011993567204288
Validation loss: 2.458784133668613

Epoch: 5| Step: 2
Training loss: 1.687436915030859
Validation loss: 2.4565963476298736

Epoch: 5| Step: 3
Training loss: 1.6334755021457252
Validation loss: 2.4558790078962627

Epoch: 5| Step: 4
Training loss: 1.8247440733504354
Validation loss: 2.440184089046146

Epoch: 5| Step: 5
Training loss: 2.056975624500105
Validation loss: 2.4570595935125974

Epoch: 5| Step: 6
Training loss: 1.9476205393321029
Validation loss: 2.4673588214273776

Epoch: 5| Step: 7
Training loss: 1.7029399246308883
Validation loss: 2.45214823258843

Epoch: 5| Step: 8
Training loss: 1.58853748091683
Validation loss: 2.4670014654178027

Epoch: 5| Step: 9
Training loss: 2.149976255596253
Validation loss: 2.453122284956104

Epoch: 5| Step: 10
Training loss: 1.6941476502909445
Validation loss: 2.496634029366943

Epoch: 201| Step: 0
Training loss: 1.3712619776102684
Validation loss: 2.560146372395774

Epoch: 5| Step: 1
Training loss: 2.057216234071671
Validation loss: 2.6087548600531627

Epoch: 5| Step: 2
Training loss: 1.8430332795117448
Validation loss: 2.6425500561199406

Epoch: 5| Step: 3
Training loss: 1.6684222353108162
Validation loss: 2.624701284199371

Epoch: 5| Step: 4
Training loss: 1.7558489195583453
Validation loss: 2.548120774399991

Epoch: 5| Step: 5
Training loss: 1.8572908148671792
Validation loss: 2.5055197958187643

Epoch: 5| Step: 6
Training loss: 1.5030360490964356
Validation loss: 2.47544936286197

Epoch: 5| Step: 7
Training loss: 2.006571464096742
Validation loss: 2.4553438258678923

Epoch: 5| Step: 8
Training loss: 2.356537078449162
Validation loss: 2.4518211164810912

Epoch: 5| Step: 9
Training loss: 2.3542593766133386
Validation loss: 2.4486758641230946

Epoch: 5| Step: 10
Training loss: 1.4808113285562883
Validation loss: 2.4626191008342

Epoch: 202| Step: 0
Training loss: 1.8614790736151072
Validation loss: 2.4735163105417897

Epoch: 5| Step: 1
Training loss: 1.7975954021449383
Validation loss: 2.4581860650614282

Epoch: 5| Step: 2
Training loss: 1.8908529853500062
Validation loss: 2.490736548861804

Epoch: 5| Step: 3
Training loss: 1.642986668640028
Validation loss: 2.5386258707657143

Epoch: 5| Step: 4
Training loss: 1.6247835748774822
Validation loss: 2.5322252585211076

Epoch: 5| Step: 5
Training loss: 1.5107886634587169
Validation loss: 2.551455787783467

Epoch: 5| Step: 6
Training loss: 1.7277792531273293
Validation loss: 2.529740628326831

Epoch: 5| Step: 7
Training loss: 2.1266770196780262
Validation loss: 2.4943314285627673

Epoch: 5| Step: 8
Training loss: 1.7322207982501483
Validation loss: 2.4836376135771525

Epoch: 5| Step: 9
Training loss: 2.2194021636581085
Validation loss: 2.5114006497213524

Epoch: 5| Step: 10
Training loss: 1.9964928871828662
Validation loss: 2.506368935210016

Epoch: 203| Step: 0
Training loss: 2.4367347885538417
Validation loss: 2.4686892122817405

Epoch: 5| Step: 1
Training loss: 1.3310854062337076
Validation loss: 2.4602205663591015

Epoch: 5| Step: 2
Training loss: 1.4023211804117168
Validation loss: 2.447406324094517

Epoch: 5| Step: 3
Training loss: 1.7584104072106623
Validation loss: 2.4404262713125866

Epoch: 5| Step: 4
Training loss: 1.7462136997608695
Validation loss: 2.4503683268311054

Epoch: 5| Step: 5
Training loss: 1.9873833268186274
Validation loss: 2.444017331673899

Epoch: 5| Step: 6
Training loss: 1.8721213177103957
Validation loss: 2.428112993754284

Epoch: 5| Step: 7
Training loss: 1.9240334648108797
Validation loss: 2.436652037351884

Epoch: 5| Step: 8
Training loss: 1.9370490749210107
Validation loss: 2.4651133017407774

Epoch: 5| Step: 9
Training loss: 1.6247104240043166
Validation loss: 2.4596077462812884

Epoch: 5| Step: 10
Training loss: 1.8267134082805165
Validation loss: 2.4589461700639084

Epoch: 204| Step: 0
Training loss: 1.7725687461832556
Validation loss: 2.4796818799092293

Epoch: 5| Step: 1
Training loss: 2.043942862927044
Validation loss: 2.492438742248494

Epoch: 5| Step: 2
Training loss: 1.5648832075274162
Validation loss: 2.4974417723244775

Epoch: 5| Step: 3
Training loss: 1.48332080550029
Validation loss: 2.5065185328547814

Epoch: 5| Step: 4
Training loss: 1.5547126499614632
Validation loss: 2.5120837463553065

Epoch: 5| Step: 5
Training loss: 1.8492277853470647
Validation loss: 2.5321599939246404

Epoch: 5| Step: 6
Training loss: 1.5894533470005527
Validation loss: 2.536182442549235

Epoch: 5| Step: 7
Training loss: 2.149072726581621
Validation loss: 2.5580472679277224

Epoch: 5| Step: 8
Training loss: 1.8642246888836416
Validation loss: 2.5322332524681066

Epoch: 5| Step: 9
Training loss: 1.8433544575180423
Validation loss: 2.5459127877738337

Epoch: 5| Step: 10
Training loss: 1.5072823022192539
Validation loss: 2.515867658888539

Epoch: 205| Step: 0
Training loss: 1.6976989263234212
Validation loss: 2.5149165196401393

Epoch: 5| Step: 1
Training loss: 1.5700955217301837
Validation loss: 2.510879705881313

Epoch: 5| Step: 2
Training loss: 2.050634992924519
Validation loss: 2.469694825686058

Epoch: 5| Step: 3
Training loss: 1.6084716631972706
Validation loss: 2.4674187909829772

Epoch: 5| Step: 4
Training loss: 1.6844924687630205
Validation loss: 2.466478285196397

Epoch: 5| Step: 5
Training loss: 1.5138585129392002
Validation loss: 2.4740519229476754

Epoch: 5| Step: 6
Training loss: 1.8790675230861553
Validation loss: 2.475828504602781

Epoch: 5| Step: 7
Training loss: 1.905759529427227
Validation loss: 2.4856329336384793

Epoch: 5| Step: 8
Training loss: 1.9479586822819954
Validation loss: 2.451410014281223

Epoch: 5| Step: 9
Training loss: 1.256463221584386
Validation loss: 2.4374126874096

Epoch: 5| Step: 10
Training loss: 2.006829284508437
Validation loss: 2.433621004400666

Epoch: 206| Step: 0
Training loss: 1.4669329177611299
Validation loss: 2.451807457159657

Epoch: 5| Step: 1
Training loss: 1.966313261941162
Validation loss: 2.443122292569852

Epoch: 5| Step: 2
Training loss: 2.016987421468418
Validation loss: 2.4491943979914685

Epoch: 5| Step: 3
Training loss: 1.347637850870778
Validation loss: 2.461597339192301

Epoch: 5| Step: 4
Training loss: 1.4168988018956161
Validation loss: 2.478275626685459

Epoch: 5| Step: 5
Training loss: 1.7799819314232483
Validation loss: 2.4786036363840287

Epoch: 5| Step: 6
Training loss: 1.3839951969405164
Validation loss: 2.4975283135493425

Epoch: 5| Step: 7
Training loss: 2.198907155920615
Validation loss: 2.513954084097093

Epoch: 5| Step: 8
Training loss: 1.4316273021208188
Validation loss: 2.5095208135894467

Epoch: 5| Step: 9
Training loss: 2.221546184175628
Validation loss: 2.4890375625917103

Epoch: 5| Step: 10
Training loss: 1.571998336533887
Validation loss: 2.4905884633715685

Epoch: 207| Step: 0
Training loss: 1.4212293731078376
Validation loss: 2.531057660649412

Epoch: 5| Step: 1
Training loss: 1.6492523059837523
Validation loss: 2.55575444612851

Epoch: 5| Step: 2
Training loss: 1.670276055504903
Validation loss: 2.5882583343925747

Epoch: 5| Step: 3
Training loss: 1.2322579590719744
Validation loss: 2.598018194002958

Epoch: 5| Step: 4
Training loss: 2.215532683479014
Validation loss: 2.6235847515712125

Epoch: 5| Step: 5
Training loss: 1.7818245881227324
Validation loss: 2.5708516661255794

Epoch: 5| Step: 6
Training loss: 1.947158489130562
Validation loss: 2.5237890387451323

Epoch: 5| Step: 7
Training loss: 1.8133456789442617
Validation loss: 2.425077953889207

Epoch: 5| Step: 8
Training loss: 1.8662440258628032
Validation loss: 2.4325100306505085

Epoch: 5| Step: 9
Training loss: 1.8223024550597178
Validation loss: 2.437938511909891

Epoch: 5| Step: 10
Training loss: 1.8747427445996303
Validation loss: 2.445868416780699

Epoch: 208| Step: 0
Training loss: 2.0978842385850127
Validation loss: 2.461010117117841

Epoch: 5| Step: 1
Training loss: 1.882448596531165
Validation loss: 2.4329406044046227

Epoch: 5| Step: 2
Training loss: 1.9550254425968916
Validation loss: 2.42747004283358

Epoch: 5| Step: 3
Training loss: 1.6594070000445567
Validation loss: 2.43798725126698

Epoch: 5| Step: 4
Training loss: 1.7056920015979395
Validation loss: 2.4517897501700707

Epoch: 5| Step: 5
Training loss: 1.7221732987185383
Validation loss: 2.4952237865659144

Epoch: 5| Step: 6
Training loss: 1.418449887702537
Validation loss: 2.538488436060486

Epoch: 5| Step: 7
Training loss: 1.731420939575706
Validation loss: 2.6002847029723783

Epoch: 5| Step: 8
Training loss: 1.8204813866589664
Validation loss: 2.5546488808374073

Epoch: 5| Step: 9
Training loss: 1.5761384452290519
Validation loss: 2.5169044012634467

Epoch: 5| Step: 10
Training loss: 1.61983144860515
Validation loss: 2.487491975415695

Epoch: 209| Step: 0
Training loss: 1.5097258292378035
Validation loss: 2.450031308821027

Epoch: 5| Step: 1
Training loss: 1.5378799155174638
Validation loss: 2.4663979949262647

Epoch: 5| Step: 2
Training loss: 1.6669516399259112
Validation loss: 2.432707841050771

Epoch: 5| Step: 3
Training loss: 1.7575108248077467
Validation loss: 2.417228964996096

Epoch: 5| Step: 4
Training loss: 1.5798387192849865
Validation loss: 2.3768192268746815

Epoch: 5| Step: 5
Training loss: 1.5708420652893917
Validation loss: 2.387872724318919

Epoch: 5| Step: 6
Training loss: 1.9624068389939806
Validation loss: 2.379433242601026

Epoch: 5| Step: 7
Training loss: 1.6431588360889113
Validation loss: 2.3838376980538816

Epoch: 5| Step: 8
Training loss: 1.6738721381046104
Validation loss: 2.393450675676496

Epoch: 5| Step: 9
Training loss: 1.8318900438235675
Validation loss: 2.4200797602510677

Epoch: 5| Step: 10
Training loss: 1.8910570517960539
Validation loss: 2.4332096477056284

Epoch: 210| Step: 0
Training loss: 1.7578714318463364
Validation loss: 2.451133422785281

Epoch: 5| Step: 1
Training loss: 1.6774823284781772
Validation loss: 2.4710768210526823

Epoch: 5| Step: 2
Training loss: 1.8013916305145967
Validation loss: 2.5003473430239374

Epoch: 5| Step: 3
Training loss: 1.7422488077777885
Validation loss: 2.495562229377438

Epoch: 5| Step: 4
Training loss: 1.6593059920565159
Validation loss: 2.4738576360566085

Epoch: 5| Step: 5
Training loss: 1.6856632833408536
Validation loss: 2.4709337897171517

Epoch: 5| Step: 6
Training loss: 1.5939115554606094
Validation loss: 2.462145864023518

Epoch: 5| Step: 7
Training loss: 1.5352106836971962
Validation loss: 2.437819864569458

Epoch: 5| Step: 8
Training loss: 1.5694791186092953
Validation loss: 2.4405456879656118

Epoch: 5| Step: 9
Training loss: 1.7237200922926803
Validation loss: 2.410972587399192

Epoch: 5| Step: 10
Training loss: 1.502035825756726
Validation loss: 2.436617652379673

Epoch: 211| Step: 0
Training loss: 1.2932917718665553
Validation loss: 2.437754771020526

Epoch: 5| Step: 1
Training loss: 2.0004708212755573
Validation loss: 2.4637679660129765

Epoch: 5| Step: 2
Training loss: 1.5364080474728168
Validation loss: 2.4862007830462867

Epoch: 5| Step: 3
Training loss: 1.3347469624372073
Validation loss: 2.516071811608578

Epoch: 5| Step: 4
Training loss: 1.6612588250447498
Validation loss: 2.5401739245292703

Epoch: 5| Step: 5
Training loss: 1.990987857821814
Validation loss: 2.572999773945528

Epoch: 5| Step: 6
Training loss: 1.4988635844633502
Validation loss: 2.5180004178142723

Epoch: 5| Step: 7
Training loss: 1.8390548537361955
Validation loss: 2.490466371394723

Epoch: 5| Step: 8
Training loss: 1.6032867082384508
Validation loss: 2.494533688782356

Epoch: 5| Step: 9
Training loss: 1.9808907143970975
Validation loss: 2.4711733806530307

Epoch: 5| Step: 10
Training loss: 1.3617509270180421
Validation loss: 2.455434530951293

Epoch: 212| Step: 0
Training loss: 1.8372695311212703
Validation loss: 2.464584708543467

Epoch: 5| Step: 1
Training loss: 1.745998849359332
Validation loss: 2.417950251824927

Epoch: 5| Step: 2
Training loss: 1.8647209699186356
Validation loss: 2.4216726789539664

Epoch: 5| Step: 3
Training loss: 1.6349961130871782
Validation loss: 2.416887329651051

Epoch: 5| Step: 4
Training loss: 1.4266383273141339
Validation loss: 2.4270741853660858

Epoch: 5| Step: 5
Training loss: 1.4375763748446038
Validation loss: 2.425547401147975

Epoch: 5| Step: 6
Training loss: 1.5811586587329887
Validation loss: 2.4267280253756143

Epoch: 5| Step: 7
Training loss: 1.3397516602656974
Validation loss: 2.4562381250939365

Epoch: 5| Step: 8
Training loss: 1.9938576672221373
Validation loss: 2.4618390030018698

Epoch: 5| Step: 9
Training loss: 1.738988153971182
Validation loss: 2.462879506003969

Epoch: 5| Step: 10
Training loss: 1.3718735523259686
Validation loss: 2.5017972577106584

Epoch: 213| Step: 0
Training loss: 1.2464405402375178
Validation loss: 2.5009483692052177

Epoch: 5| Step: 1
Training loss: 1.4194240195755539
Validation loss: 2.5138158492056664

Epoch: 5| Step: 2
Training loss: 1.0791391219425028
Validation loss: 2.5163930771193934

Epoch: 5| Step: 3
Training loss: 1.5192338902590896
Validation loss: 2.520033946997683

Epoch: 5| Step: 4
Training loss: 1.78634170136672
Validation loss: 2.4994031060253783

Epoch: 5| Step: 5
Training loss: 1.5961921530856313
Validation loss: 2.4859875402559313

Epoch: 5| Step: 6
Training loss: 1.8440058902389884
Validation loss: 2.4620091456862365

Epoch: 5| Step: 7
Training loss: 1.5509346758762759
Validation loss: 2.483713653409323

Epoch: 5| Step: 8
Training loss: 1.8117120279612655
Validation loss: 2.4933526623257274

Epoch: 5| Step: 9
Training loss: 1.6663611926833874
Validation loss: 2.5138448527299677

Epoch: 5| Step: 10
Training loss: 2.080455305261606
Validation loss: 2.5152988091151203

Epoch: 214| Step: 0
Training loss: 1.8653601479192463
Validation loss: 2.47287259398524

Epoch: 5| Step: 1
Training loss: 1.3855900859090446
Validation loss: 2.4310698739029277

Epoch: 5| Step: 2
Training loss: 1.2023165079442553
Validation loss: 2.441115574093789

Epoch: 5| Step: 3
Training loss: 1.5269256565905214
Validation loss: 2.439072734980539

Epoch: 5| Step: 4
Training loss: 1.7534526416789014
Validation loss: 2.4513777192724375

Epoch: 5| Step: 5
Training loss: 1.6536328492943961
Validation loss: 2.4664471946725275

Epoch: 5| Step: 6
Training loss: 1.8522436120531565
Validation loss: 2.497308743782258

Epoch: 5| Step: 7
Training loss: 1.2074419329090098
Validation loss: 2.49384451642907

Epoch: 5| Step: 8
Training loss: 1.731860356897064
Validation loss: 2.519792716394518

Epoch: 5| Step: 9
Training loss: 1.941781880749227
Validation loss: 2.551979658186173

Epoch: 5| Step: 10
Training loss: 1.278170863217077
Validation loss: 2.5699335566917823

Epoch: 215| Step: 0
Training loss: 1.3283478045104073
Validation loss: 2.5758843204580146

Epoch: 5| Step: 1
Training loss: 1.680554826944717
Validation loss: 2.597456784839753

Epoch: 5| Step: 2
Training loss: 1.403574029316186
Validation loss: 2.584304315154614

Epoch: 5| Step: 3
Training loss: 1.603592418918022
Validation loss: 2.563454492992557

Epoch: 5| Step: 4
Training loss: 1.8907081018264706
Validation loss: 2.53376835452837

Epoch: 5| Step: 5
Training loss: 1.5386416251895667
Validation loss: 2.4747426064598295

Epoch: 5| Step: 6
Training loss: 1.351062395480432
Validation loss: 2.40403501462557

Epoch: 5| Step: 7
Training loss: 1.81088553247939
Validation loss: 2.377104288454802

Epoch: 5| Step: 8
Training loss: 1.4942149025399707
Validation loss: 2.3798809532296854

Epoch: 5| Step: 9
Training loss: 1.519740386927467
Validation loss: 2.3580750886624187

Epoch: 5| Step: 10
Training loss: 1.9688605625654243
Validation loss: 2.356382082418518

Epoch: 216| Step: 0
Training loss: 1.7615429437379768
Validation loss: 2.370174582474674

Epoch: 5| Step: 1
Training loss: 1.720053854476244
Validation loss: 2.364207508172284

Epoch: 5| Step: 2
Training loss: 1.5559219750010795
Validation loss: 2.367176041936975

Epoch: 5| Step: 3
Training loss: 1.068043217438225
Validation loss: 2.4164541898622756

Epoch: 5| Step: 4
Training loss: 1.564060957352433
Validation loss: 2.4259568265921816

Epoch: 5| Step: 5
Training loss: 1.8982344153769406
Validation loss: 2.4787000046471204

Epoch: 5| Step: 6
Training loss: 1.5673450120782586
Validation loss: 2.5216157438509

Epoch: 5| Step: 7
Training loss: 1.4484769254090253
Validation loss: 2.5404911244478714

Epoch: 5| Step: 8
Training loss: 1.709746063517939
Validation loss: 2.563165154656396

Epoch: 5| Step: 9
Training loss: 1.805644652621813
Validation loss: 2.5550232686338865

Epoch: 5| Step: 10
Training loss: 1.6873319330233507
Validation loss: 2.526225420390773

Epoch: 217| Step: 0
Training loss: 1.6704490498751405
Validation loss: 2.520129559553004

Epoch: 5| Step: 1
Training loss: 1.738124128805777
Validation loss: 2.4874784413738795

Epoch: 5| Step: 2
Training loss: 1.4545696009994198
Validation loss: 2.4899918676722006

Epoch: 5| Step: 3
Training loss: 1.528840017467894
Validation loss: 2.484823069788539

Epoch: 5| Step: 4
Training loss: 1.2917521304907928
Validation loss: 2.4665749650539683

Epoch: 5| Step: 5
Training loss: 1.7465398504481628
Validation loss: 2.457226134911195

Epoch: 5| Step: 6
Training loss: 1.5688843566989965
Validation loss: 2.4799524414730234

Epoch: 5| Step: 7
Training loss: 1.7827424606486928
Validation loss: 2.4545668020090408

Epoch: 5| Step: 8
Training loss: 1.8067809014375706
Validation loss: 2.47748353496967

Epoch: 5| Step: 9
Training loss: 1.1960230691209541
Validation loss: 2.4712707860928127

Epoch: 5| Step: 10
Training loss: 1.3849951549817114
Validation loss: 2.511113226714196

Epoch: 218| Step: 0
Training loss: 0.9246930515216769
Validation loss: 2.5172844597152375

Epoch: 5| Step: 1
Training loss: 1.5968811094760667
Validation loss: 2.497272060369551

Epoch: 5| Step: 2
Training loss: 1.56912475000527
Validation loss: 2.509436753661374

Epoch: 5| Step: 3
Training loss: 1.5002888560324088
Validation loss: 2.5073937711899976

Epoch: 5| Step: 4
Training loss: 1.9045172148167113
Validation loss: 2.5039902007284613

Epoch: 5| Step: 5
Training loss: 1.3029513199877003
Validation loss: 2.497009901078548

Epoch: 5| Step: 6
Training loss: 1.5271034929819223
Validation loss: 2.4973087386494512

Epoch: 5| Step: 7
Training loss: 1.7135954812671483
Validation loss: 2.5063240388323615

Epoch: 5| Step: 8
Training loss: 1.476510667648042
Validation loss: 2.4881839705814595

Epoch: 5| Step: 9
Training loss: 1.5685404937789746
Validation loss: 2.4857655830266507

Epoch: 5| Step: 10
Training loss: 1.4285362903496954
Validation loss: 2.467686870884719

Epoch: 219| Step: 0
Training loss: 1.4220136637721994
Validation loss: 2.438072908194638

Epoch: 5| Step: 1
Training loss: 1.7458550548188483
Validation loss: 2.437509513586098

Epoch: 5| Step: 2
Training loss: 1.4668938291078308
Validation loss: 2.4507228255493443

Epoch: 5| Step: 3
Training loss: 1.2661641703190176
Validation loss: 2.450295265642766

Epoch: 5| Step: 4
Training loss: 1.3279999618013216
Validation loss: 2.4617336503035614

Epoch: 5| Step: 5
Training loss: 1.4342077951483554
Validation loss: 2.453562452769043

Epoch: 5| Step: 6
Training loss: 1.55050595239741
Validation loss: 2.4660789710332445

Epoch: 5| Step: 7
Training loss: 1.8030000534269184
Validation loss: 2.475742746711794

Epoch: 5| Step: 8
Training loss: 1.419038647432516
Validation loss: 2.4712862429687754

Epoch: 5| Step: 9
Training loss: 1.667293510177008
Validation loss: 2.484103416478136

Epoch: 5| Step: 10
Training loss: 1.437861521498118
Validation loss: 2.4942833071258903

Epoch: 220| Step: 0
Training loss: 1.1962726202632814
Validation loss: 2.5028594963037594

Epoch: 5| Step: 1
Training loss: 1.5602729184497202
Validation loss: 2.496348825035575

Epoch: 5| Step: 2
Training loss: 1.4072174135502387
Validation loss: 2.503206024695933

Epoch: 5| Step: 3
Training loss: 1.041555411437435
Validation loss: 2.5035033116251038

Epoch: 5| Step: 4
Training loss: 1.4703090590660703
Validation loss: 2.511286864565902

Epoch: 5| Step: 5
Training loss: 1.508130133976203
Validation loss: 2.5145345913262402

Epoch: 5| Step: 6
Training loss: 1.5437203037633536
Validation loss: 2.521131151797694

Epoch: 5| Step: 7
Training loss: 1.8627688425084088
Validation loss: 2.497949026565403

Epoch: 5| Step: 8
Training loss: 1.4961845031782208
Validation loss: 2.4989473608401243

Epoch: 5| Step: 9
Training loss: 1.4436274422814752
Validation loss: 2.4933483141058126

Epoch: 5| Step: 10
Training loss: 1.7440213528953303
Validation loss: 2.477088431141075

Epoch: 221| Step: 0
Training loss: 0.9778525110033743
Validation loss: 2.4836769126750453

Epoch: 5| Step: 1
Training loss: 1.3706336485680761
Validation loss: 2.486514150272926

Epoch: 5| Step: 2
Training loss: 1.7409656841877403
Validation loss: 2.453293363427589

Epoch: 5| Step: 3
Training loss: 1.4447417910914135
Validation loss: 2.4687584933592666

Epoch: 5| Step: 4
Training loss: 1.5746667569946686
Validation loss: 2.4596405492191495

Epoch: 5| Step: 5
Training loss: 1.6660932587650865
Validation loss: 2.4894309985620784

Epoch: 5| Step: 6
Training loss: 1.388966031581261
Validation loss: 2.4938505877150154

Epoch: 5| Step: 7
Training loss: 1.6619190147398744
Validation loss: 2.4892953380103284

Epoch: 5| Step: 8
Training loss: 1.1698077469374708
Validation loss: 2.4840629279991124

Epoch: 5| Step: 9
Training loss: 1.651100141610909
Validation loss: 2.514298478762369

Epoch: 5| Step: 10
Training loss: 1.6216723041625927
Validation loss: 2.5073988179112536

Epoch: 222| Step: 0
Training loss: 1.6331601297576217
Validation loss: 2.4816698415058482

Epoch: 5| Step: 1
Training loss: 0.7977767404983717
Validation loss: 2.500591578785516

Epoch: 5| Step: 2
Training loss: 1.729880549435935
Validation loss: 2.5140696452109688

Epoch: 5| Step: 3
Training loss: 1.4624500298725656
Validation loss: 2.5004503808365155

Epoch: 5| Step: 4
Training loss: 1.2584670360008179
Validation loss: 2.499153271715919

Epoch: 5| Step: 5
Training loss: 1.3519137593081934
Validation loss: 2.5149137449024472

Epoch: 5| Step: 6
Training loss: 1.7353865963947437
Validation loss: 2.504371287477703

Epoch: 5| Step: 7
Training loss: 1.465785911202123
Validation loss: 2.5064188109482273

Epoch: 5| Step: 8
Training loss: 1.2108180817818175
Validation loss: 2.5139166732553777

Epoch: 5| Step: 9
Training loss: 1.9374456705659266
Validation loss: 2.5259048659986

Epoch: 5| Step: 10
Training loss: 1.2801813460573994
Validation loss: 2.5135113001541707

Epoch: 223| Step: 0
Training loss: 1.4149110892841372
Validation loss: 2.501406365309629

Epoch: 5| Step: 1
Training loss: 1.359088867591329
Validation loss: 2.50703961444705

Epoch: 5| Step: 2
Training loss: 1.1442180113768547
Validation loss: 2.4891385318534045

Epoch: 5| Step: 3
Training loss: 1.314685636591152
Validation loss: 2.4794497439910654

Epoch: 5| Step: 4
Training loss: 1.9891391544599548
Validation loss: 2.4669719174035865

Epoch: 5| Step: 5
Training loss: 1.1919797423836749
Validation loss: 2.466145528057045

Epoch: 5| Step: 6
Training loss: 1.4910617596367446
Validation loss: 2.45767546482954

Epoch: 5| Step: 7
Training loss: 1.6622472183679309
Validation loss: 2.475575756797917

Epoch: 5| Step: 8
Training loss: 1.2875265970538368
Validation loss: 2.4774531972195786

Epoch: 5| Step: 9
Training loss: 1.5562388285653408
Validation loss: 2.5111358766982836

Epoch: 5| Step: 10
Training loss: 1.613308885536228
Validation loss: 2.4928210909914896

Epoch: 224| Step: 0
Training loss: 1.6187140589667637
Validation loss: 2.5343016714175253

Epoch: 5| Step: 1
Training loss: 1.2341344574857909
Validation loss: 2.5248567833983557

Epoch: 5| Step: 2
Training loss: 1.6119030106097554
Validation loss: 2.552980482178093

Epoch: 5| Step: 3
Training loss: 2.007148365658996
Validation loss: 2.570199828750542

Epoch: 5| Step: 4
Training loss: 1.3666844777753175
Validation loss: 2.587251770452247

Epoch: 5| Step: 5
Training loss: 1.0839337861224523
Validation loss: 2.580455432026545

Epoch: 5| Step: 6
Training loss: 1.2696485729291984
Validation loss: 2.60223959683774

Epoch: 5| Step: 7
Training loss: 1.1655342475804904
Validation loss: 2.5757284381965078

Epoch: 5| Step: 8
Training loss: 1.6751428201622942
Validation loss: 2.5466720416640416

Epoch: 5| Step: 9
Training loss: 0.955334806372134
Validation loss: 2.495186433436678

Epoch: 5| Step: 10
Training loss: 1.6394951699323317
Validation loss: 2.5176689920539626

Epoch: 225| Step: 0
Training loss: 1.3213954299099455
Validation loss: 2.4903296719227552

Epoch: 5| Step: 1
Training loss: 1.2402374027245278
Validation loss: 2.469804921328317

Epoch: 5| Step: 2
Training loss: 1.8207794376430724
Validation loss: 2.4671149809954844

Epoch: 5| Step: 3
Training loss: 1.023444663452238
Validation loss: 2.4694185048897186

Epoch: 5| Step: 4
Training loss: 1.056397246079934
Validation loss: 2.466261331437509

Epoch: 5| Step: 5
Training loss: 1.8736352404162446
Validation loss: 2.4596486529532955

Epoch: 5| Step: 6
Training loss: 1.393111288722846
Validation loss: 2.468521840757265

Epoch: 5| Step: 7
Training loss: 1.2065321004417422
Validation loss: 2.474193221870841

Epoch: 5| Step: 8
Training loss: 1.534001738914091
Validation loss: 2.5032099533049497

Epoch: 5| Step: 9
Training loss: 1.8901487649165674
Validation loss: 2.5256110746731206

Epoch: 5| Step: 10
Training loss: 0.9610617952673541
Validation loss: 2.5232025873253483

Epoch: 226| Step: 0
Training loss: 1.3892155480361335
Validation loss: 2.513899733131485

Epoch: 5| Step: 1
Training loss: 1.0190818643938104
Validation loss: 2.498914878956508

Epoch: 5| Step: 2
Training loss: 1.6929689725093229
Validation loss: 2.5030725597020482

Epoch: 5| Step: 3
Training loss: 1.5451258779066062
Validation loss: 2.503682108569958

Epoch: 5| Step: 4
Training loss: 1.6396703940143214
Validation loss: 2.50743796850833

Epoch: 5| Step: 5
Training loss: 1.5708269633493692
Validation loss: 2.49378399499497

Epoch: 5| Step: 6
Training loss: 1.6576752198642537
Validation loss: 2.4744529441258925

Epoch: 5| Step: 7
Training loss: 1.3339883963439112
Validation loss: 2.473565073324894

Epoch: 5| Step: 8
Training loss: 1.0359450304036728
Validation loss: 2.4854827122271916

Epoch: 5| Step: 9
Training loss: 1.045466828179863
Validation loss: 2.4863240346425513

Epoch: 5| Step: 10
Training loss: 1.4301441901544643
Validation loss: 2.4642710681791633

Epoch: 227| Step: 0
Training loss: 1.4782317883101768
Validation loss: 2.457808070504797

Epoch: 5| Step: 1
Training loss: 1.457918362387105
Validation loss: 2.466830244338693

Epoch: 5| Step: 2
Training loss: 1.4116622195723625
Validation loss: 2.4697296973368372

Epoch: 5| Step: 3
Training loss: 1.207833723940303
Validation loss: 2.468893296992309

Epoch: 5| Step: 4
Training loss: 1.360918944064801
Validation loss: 2.4700477452981997

Epoch: 5| Step: 5
Training loss: 1.2849614421833635
Validation loss: 2.4820325419673828

Epoch: 5| Step: 6
Training loss: 1.0567687797745777
Validation loss: 2.50371244284981

Epoch: 5| Step: 7
Training loss: 1.337326532327265
Validation loss: 2.507980885380974

Epoch: 5| Step: 8
Training loss: 1.337653725248186
Validation loss: 2.525407561642005

Epoch: 5| Step: 9
Training loss: 2.010801472838974
Validation loss: 2.5317252930903624

Epoch: 5| Step: 10
Training loss: 1.2295874936688287
Validation loss: 2.5443240401228975

Epoch: 228| Step: 0
Training loss: 1.0724436016414953
Validation loss: 2.5305924173544185

Epoch: 5| Step: 1
Training loss: 1.7321628518839611
Validation loss: 2.5277006289722177

Epoch: 5| Step: 2
Training loss: 1.4463007666959737
Validation loss: 2.5107392856206543

Epoch: 5| Step: 3
Training loss: 1.4620764061861626
Validation loss: 2.520406890518129

Epoch: 5| Step: 4
Training loss: 1.1235737767020486
Validation loss: 2.5238404951140287

Epoch: 5| Step: 5
Training loss: 1.4807122264335382
Validation loss: 2.5037177191850826

Epoch: 5| Step: 6
Training loss: 1.2834363287099988
Validation loss: 2.5246932836911404

Epoch: 5| Step: 7
Training loss: 0.978408228906351
Validation loss: 2.5107766748845854

Epoch: 5| Step: 8
Training loss: 1.878692170634448
Validation loss: 2.48775712451474

Epoch: 5| Step: 9
Training loss: 1.3626687496571257
Validation loss: 2.4670086606392587

Epoch: 5| Step: 10
Training loss: 1.1620919875439004
Validation loss: 2.446553278465522

Epoch: 229| Step: 0
Training loss: 1.4069966771073676
Validation loss: 2.4446643928569314

Epoch: 5| Step: 1
Training loss: 1.8972131996380854
Validation loss: 2.4604335901202576

Epoch: 5| Step: 2
Training loss: 1.2077708524602722
Validation loss: 2.4473948121209763

Epoch: 5| Step: 3
Training loss: 1.2933108519700933
Validation loss: 2.4635848044802597

Epoch: 5| Step: 4
Training loss: 1.5531140517035047
Validation loss: 2.459314591248484

Epoch: 5| Step: 5
Training loss: 1.2694763171708987
Validation loss: 2.48551960058005

Epoch: 5| Step: 6
Training loss: 1.3481931197526928
Validation loss: 2.4870563426598524

Epoch: 5| Step: 7
Training loss: 1.4518431885904868
Validation loss: 2.5388337073093887

Epoch: 5| Step: 8
Training loss: 1.1687093574678742
Validation loss: 2.5259354784184613

Epoch: 5| Step: 9
Training loss: 1.141612213581087
Validation loss: 2.5238337290631647

Epoch: 5| Step: 10
Training loss: 1.4212907701749138
Validation loss: 2.5352741573467474

Epoch: 230| Step: 0
Training loss: 1.2637433322236304
Validation loss: 2.5628805783310926

Epoch: 5| Step: 1
Training loss: 1.300645380112521
Validation loss: 2.568644073164978

Epoch: 5| Step: 2
Training loss: 1.3632711940274267
Validation loss: 2.5618343784356084

Epoch: 5| Step: 3
Training loss: 1.743012579311691
Validation loss: 2.5464632320611558

Epoch: 5| Step: 4
Training loss: 1.5664333426779522
Validation loss: 2.5444714888839024

Epoch: 5| Step: 5
Training loss: 1.6738586779090552
Validation loss: 2.5208769811195486

Epoch: 5| Step: 6
Training loss: 0.9074944797589676
Validation loss: 2.5177185675712956

Epoch: 5| Step: 7
Training loss: 0.9850790745321183
Validation loss: 2.5057483737676716

Epoch: 5| Step: 8
Training loss: 1.2264099026170086
Validation loss: 2.4996433044611477

Epoch: 5| Step: 9
Training loss: 1.5237220694005986
Validation loss: 2.497224114683722

Epoch: 5| Step: 10
Training loss: 1.3795259720285156
Validation loss: 2.467757361280257

Epoch: 231| Step: 0
Training loss: 1.1402555416033573
Validation loss: 2.459621521233744

Epoch: 5| Step: 1
Training loss: 0.8684824648236055
Validation loss: 2.450653168496776

Epoch: 5| Step: 2
Training loss: 1.2537240820018989
Validation loss: 2.4452993783182997

Epoch: 5| Step: 3
Training loss: 1.8033298157935584
Validation loss: 2.452848708498857

Epoch: 5| Step: 4
Training loss: 1.418483336002867
Validation loss: 2.4731821203641418

Epoch: 5| Step: 5
Training loss: 1.3008795807018183
Validation loss: 2.4786427086284673

Epoch: 5| Step: 6
Training loss: 1.2445689471630543
Validation loss: 2.499466079179756

Epoch: 5| Step: 7
Training loss: 1.3523467770723856
Validation loss: 2.4990793009432912

Epoch: 5| Step: 8
Training loss: 1.673411153804992
Validation loss: 2.5438336219979987

Epoch: 5| Step: 9
Training loss: 1.1968613606365517
Validation loss: 2.5615308335974425

Epoch: 5| Step: 10
Training loss: 1.6053104368987072
Validation loss: 2.5508141327309968

Epoch: 232| Step: 0
Training loss: 1.7525737773042278
Validation loss: 2.556780081993671

Epoch: 5| Step: 1
Training loss: 1.5593986249521594
Validation loss: 2.5293640287442565

Epoch: 5| Step: 2
Training loss: 1.0276494604776452
Validation loss: 2.5052456693843506

Epoch: 5| Step: 3
Training loss: 1.367237242747442
Validation loss: 2.466848484057682

Epoch: 5| Step: 4
Training loss: 1.2391547843365118
Validation loss: 2.4674315986653257

Epoch: 5| Step: 5
Training loss: 0.9467680577987921
Validation loss: 2.4533666509069763

Epoch: 5| Step: 6
Training loss: 1.0737395171252158
Validation loss: 2.4608718334629565

Epoch: 5| Step: 7
Training loss: 1.0770697474160855
Validation loss: 2.45276161984069

Epoch: 5| Step: 8
Training loss: 1.7909549216130483
Validation loss: 2.475422511772566

Epoch: 5| Step: 9
Training loss: 1.792004893411188
Validation loss: 2.4585960081689864

Epoch: 5| Step: 10
Training loss: 1.2530363398744748
Validation loss: 2.485853368665427

Epoch: 233| Step: 0
Training loss: 0.9385472488378444
Validation loss: 2.5102104095813185

Epoch: 5| Step: 1
Training loss: 1.3746144014154424
Validation loss: 2.5229703312718215

Epoch: 5| Step: 2
Training loss: 1.354216291056322
Validation loss: 2.5414579252976415

Epoch: 5| Step: 3
Training loss: 1.217818956052109
Validation loss: 2.557889649188759

Epoch: 5| Step: 4
Training loss: 1.358021292310265
Validation loss: 2.5687207583521623

Epoch: 5| Step: 5
Training loss: 1.3606064578866286
Validation loss: 2.5628027348205458

Epoch: 5| Step: 6
Training loss: 1.526634734679079
Validation loss: 2.54332611066616

Epoch: 5| Step: 7
Training loss: 1.25630002278045
Validation loss: 2.530954566789651

Epoch: 5| Step: 8
Training loss: 1.4573028556752299
Validation loss: 2.517115054912338

Epoch: 5| Step: 9
Training loss: 1.5053938209087592
Validation loss: 2.4810294721195794

Epoch: 5| Step: 10
Training loss: 1.2929467144612563
Validation loss: 2.4809956841066203

Epoch: 234| Step: 0
Training loss: 1.3657713176635409
Validation loss: 2.472695434365587

Epoch: 5| Step: 1
Training loss: 1.625187716278929
Validation loss: 2.4777216275685277

Epoch: 5| Step: 2
Training loss: 1.3978342641240078
Validation loss: 2.4692947681769803

Epoch: 5| Step: 3
Training loss: 1.260358945717638
Validation loss: 2.4800894503682054

Epoch: 5| Step: 4
Training loss: 1.180638012468511
Validation loss: 2.462547538901857

Epoch: 5| Step: 5
Training loss: 1.32204175037127
Validation loss: 2.4822072029826523

Epoch: 5| Step: 6
Training loss: 0.9088899374028039
Validation loss: 2.472396532387217

Epoch: 5| Step: 7
Training loss: 1.2697861635601575
Validation loss: 2.503177893893221

Epoch: 5| Step: 8
Training loss: 1.3082250274893223
Validation loss: 2.504289182459715

Epoch: 5| Step: 9
Training loss: 1.1299973860853902
Validation loss: 2.5125753824133823

Epoch: 5| Step: 10
Training loss: 1.6586785415631153
Validation loss: 2.53479016583289

Epoch: 235| Step: 0
Training loss: 1.3488027809428895
Validation loss: 2.5746271383764463

Epoch: 5| Step: 1
Training loss: 1.499448833929491
Validation loss: 2.580258045079226

Epoch: 5| Step: 2
Training loss: 1.0711035485240288
Validation loss: 2.5791620509895083

Epoch: 5| Step: 3
Training loss: 1.4820947097600512
Validation loss: 2.5553625145216072

Epoch: 5| Step: 4
Training loss: 1.322265985621258
Validation loss: 2.530103323731336

Epoch: 5| Step: 5
Training loss: 1.2761109729032913
Validation loss: 2.5035278726547356

Epoch: 5| Step: 6
Training loss: 1.2171480948615638
Validation loss: 2.5392929621276497

Epoch: 5| Step: 7
Training loss: 0.9677374685861185
Validation loss: 2.5224577513184627

Epoch: 5| Step: 8
Training loss: 1.2928390207352833
Validation loss: 2.5075943071517806

Epoch: 5| Step: 9
Training loss: 1.939042984390109
Validation loss: 2.5303131156256535

Epoch: 5| Step: 10
Training loss: 0.8139519556005753
Validation loss: 2.5214278102303287

Epoch: 236| Step: 0
Training loss: 1.4663668839094528
Validation loss: 2.5370056241775245

Epoch: 5| Step: 1
Training loss: 1.35911285679007
Validation loss: 2.536391716461918

Epoch: 5| Step: 2
Training loss: 1.8908828685599552
Validation loss: 2.52635513524069

Epoch: 5| Step: 3
Training loss: 0.8404817154170268
Validation loss: 2.515977385780986

Epoch: 5| Step: 4
Training loss: 0.7079111598898769
Validation loss: 2.514762135798689

Epoch: 5| Step: 5
Training loss: 0.8206466357595934
Validation loss: 2.4981215413387514

Epoch: 5| Step: 6
Training loss: 1.877382798886116
Validation loss: 2.484263648691936

Epoch: 5| Step: 7
Training loss: 1.3755611228410805
Validation loss: 2.494342199743992

Epoch: 5| Step: 8
Training loss: 1.155998099441022
Validation loss: 2.4606613605854006

Epoch: 5| Step: 9
Training loss: 1.1638413289554037
Validation loss: 2.470738256346479

Epoch: 5| Step: 10
Training loss: 0.9668882692853009
Validation loss: 2.4865323332383973

Epoch: 237| Step: 0
Training loss: 0.9643911929696334
Validation loss: 2.4911132147074597

Epoch: 5| Step: 1
Training loss: 1.3440782900044383
Validation loss: 2.5025081010199957

Epoch: 5| Step: 2
Training loss: 1.6116926670968719
Validation loss: 2.5158304456566465

Epoch: 5| Step: 3
Training loss: 1.7868163155162025
Validation loss: 2.526442046806256

Epoch: 5| Step: 4
Training loss: 1.0809912245126923
Validation loss: 2.5377063920466005

Epoch: 5| Step: 5
Training loss: 1.02361977388215
Validation loss: 2.5195809811803955

Epoch: 5| Step: 6
Training loss: 1.3113438191410793
Validation loss: 2.518223346904075

Epoch: 5| Step: 7
Training loss: 1.463178089454582
Validation loss: 2.544392166034851

Epoch: 5| Step: 8
Training loss: 1.4370079857080718
Validation loss: 2.523216569842982

Epoch: 5| Step: 9
Training loss: 0.8338474992195221
Validation loss: 2.5222988436662046

Epoch: 5| Step: 10
Training loss: 0.6427110575077765
Validation loss: 2.5147044676462174

Epoch: 238| Step: 0
Training loss: 1.359104743488705
Validation loss: 2.504090044945579

Epoch: 5| Step: 1
Training loss: 1.093250869213276
Validation loss: 2.517261080868446

Epoch: 5| Step: 2
Training loss: 1.2365322818298208
Validation loss: 2.5088094629052486

Epoch: 5| Step: 3
Training loss: 1.3196919805769993
Validation loss: 2.524769375565174

Epoch: 5| Step: 4
Training loss: 1.6894471273150402
Validation loss: 2.5240515561165884

Epoch: 5| Step: 5
Training loss: 1.3840985540955315
Validation loss: 2.521349958138154

Epoch: 5| Step: 6
Training loss: 1.2388611407420322
Validation loss: 2.5444387468523586

Epoch: 5| Step: 7
Training loss: 1.299828441010182
Validation loss: 2.544889229426178

Epoch: 5| Step: 8
Training loss: 1.008754910595368
Validation loss: 2.5350482451930016

Epoch: 5| Step: 9
Training loss: 1.1884187858285706
Validation loss: 2.5095591434670768

Epoch: 5| Step: 10
Training loss: 1.0868382183254346
Validation loss: 2.486196518730624

Epoch: 239| Step: 0
Training loss: 1.2992655770309598
Validation loss: 2.4742035248283294

Epoch: 5| Step: 1
Training loss: 0.7297661406067314
Validation loss: 2.4671995965250826

Epoch: 5| Step: 2
Training loss: 1.138477132119432
Validation loss: 2.449880089482201

Epoch: 5| Step: 3
Training loss: 0.851518297360602
Validation loss: 2.4723772116585305

Epoch: 5| Step: 4
Training loss: 1.7158144069824026
Validation loss: 2.4806119539488707

Epoch: 5| Step: 5
Training loss: 1.3082115867890105
Validation loss: 2.5046017696837217

Epoch: 5| Step: 6
Training loss: 1.4660073503463518
Validation loss: 2.49335144700468

Epoch: 5| Step: 7
Training loss: 1.191182800350949
Validation loss: 2.542961862453096

Epoch: 5| Step: 8
Training loss: 1.3134966653753208
Validation loss: 2.540889081083235

Epoch: 5| Step: 9
Training loss: 1.5305426384545584
Validation loss: 2.580736415669868

Epoch: 5| Step: 10
Training loss: 1.1277519581464217
Validation loss: 2.5692395498197955

Epoch: 240| Step: 0
Training loss: 1.0970384481433237
Validation loss: 2.558217183018671

Epoch: 5| Step: 1
Training loss: 1.0935861737310006
Validation loss: 2.545955985124169

Epoch: 5| Step: 2
Training loss: 0.5970063758985666
Validation loss: 2.5082282612768116

Epoch: 5| Step: 3
Training loss: 1.2722765539377463
Validation loss: 2.522530573617522

Epoch: 5| Step: 4
Training loss: 1.5553052432132577
Validation loss: 2.503927317806125

Epoch: 5| Step: 5
Training loss: 1.1059855409025408
Validation loss: 2.4922278194565095

Epoch: 5| Step: 6
Training loss: 1.126199771298748
Validation loss: 2.4867191896310663

Epoch: 5| Step: 7
Training loss: 1.2127425983417766
Validation loss: 2.5044978626715673

Epoch: 5| Step: 8
Training loss: 1.3988494266357077
Validation loss: 2.4683260301142074

Epoch: 5| Step: 9
Training loss: 1.8194008046256094
Validation loss: 2.517871327381084

Epoch: 5| Step: 10
Training loss: 1.065953029138092
Validation loss: 2.5017870104938713

Epoch: 241| Step: 0
Training loss: 1.7411152229809619
Validation loss: 2.5207254570950957

Epoch: 5| Step: 1
Training loss: 1.1366051685965517
Validation loss: 2.5122160522193098

Epoch: 5| Step: 2
Training loss: 1.088186665496147
Validation loss: 2.5001742609879165

Epoch: 5| Step: 3
Training loss: 1.0701362297646135
Validation loss: 2.5225656401988354

Epoch: 5| Step: 4
Training loss: 1.330799103433819
Validation loss: 2.5050068524552893

Epoch: 5| Step: 5
Training loss: 1.0083040916259218
Validation loss: 2.4964849253569037

Epoch: 5| Step: 6
Training loss: 1.3875636146327526
Validation loss: 2.5235286660493768

Epoch: 5| Step: 7
Training loss: 1.1486442016597354
Validation loss: 2.4964316435628433

Epoch: 5| Step: 8
Training loss: 1.6419892224969885
Validation loss: 2.5361821393012414

Epoch: 5| Step: 9
Training loss: 0.9781542203883421
Validation loss: 2.546330404623905

Epoch: 5| Step: 10
Training loss: 0.8805987190239865
Validation loss: 2.545141643247042

Epoch: 242| Step: 0
Training loss: 0.8897105424561434
Validation loss: 2.5330315451302465

Epoch: 5| Step: 1
Training loss: 0.9470746349221132
Validation loss: 2.5684457325922607

Epoch: 5| Step: 2
Training loss: 1.3175727362343015
Validation loss: 2.576365628598303

Epoch: 5| Step: 3
Training loss: 1.7989542996601178
Validation loss: 2.5572876390221975

Epoch: 5| Step: 4
Training loss: 0.9978345432349557
Validation loss: 2.544265198082865

Epoch: 5| Step: 5
Training loss: 1.173835437009256
Validation loss: 2.541207596022708

Epoch: 5| Step: 6
Training loss: 1.0528700817164927
Validation loss: 2.527672480196386

Epoch: 5| Step: 7
Training loss: 1.1431643815971333
Validation loss: 2.527834882575362

Epoch: 5| Step: 8
Training loss: 1.3204047266784538
Validation loss: 2.526171418690795

Epoch: 5| Step: 9
Training loss: 1.537701542368183
Validation loss: 2.4937603891506672

Epoch: 5| Step: 10
Training loss: 1.0069141968024335
Validation loss: 2.5064768436113427

Epoch: 243| Step: 0
Training loss: 1.0564349921031477
Validation loss: 2.5085032002629957

Epoch: 5| Step: 1
Training loss: 1.4784771650948516
Validation loss: 2.486006496369641

Epoch: 5| Step: 2
Training loss: 1.23039332567384
Validation loss: 2.506309479275724

Epoch: 5| Step: 3
Training loss: 0.6666181864595014
Validation loss: 2.4567495051141734

Epoch: 5| Step: 4
Training loss: 1.109926167429654
Validation loss: 2.4817302751202797

Epoch: 5| Step: 5
Training loss: 1.087668267747981
Validation loss: 2.4897907891638518

Epoch: 5| Step: 6
Training loss: 1.153075835877902
Validation loss: 2.502183316643577

Epoch: 5| Step: 7
Training loss: 1.5673968828466975
Validation loss: 2.4867799252704663

Epoch: 5| Step: 8
Training loss: 1.1181539343495999
Validation loss: 2.5188593315795544

Epoch: 5| Step: 9
Training loss: 1.5762458415207246
Validation loss: 2.512555864562283

Epoch: 5| Step: 10
Training loss: 1.169691671353321
Validation loss: 2.4940551030839475

Epoch: 244| Step: 0
Training loss: 0.9507240322076513
Validation loss: 2.5191484327561664

Epoch: 5| Step: 1
Training loss: 1.3280744655195227
Validation loss: 2.511758770224601

Epoch: 5| Step: 2
Training loss: 1.5912235655165876
Validation loss: 2.542742026794683

Epoch: 5| Step: 3
Training loss: 1.512175498389753
Validation loss: 2.527851050335604

Epoch: 5| Step: 4
Training loss: 1.090571662888387
Validation loss: 2.561713753609485

Epoch: 5| Step: 5
Training loss: 1.482212539387356
Validation loss: 2.5494506533347012

Epoch: 5| Step: 6
Training loss: 0.8247104642445384
Validation loss: 2.526627444230893

Epoch: 5| Step: 7
Training loss: 0.8878598705894764
Validation loss: 2.5208798448879843

Epoch: 5| Step: 8
Training loss: 1.1312256320415341
Validation loss: 2.507927279982257

Epoch: 5| Step: 9
Training loss: 1.464825846244754
Validation loss: 2.4904013774416183

Epoch: 5| Step: 10
Training loss: 0.788108626822546
Validation loss: 2.466592621509522

Epoch: 245| Step: 0
Training loss: 1.0506040288952856
Validation loss: 2.495592041886064

Epoch: 5| Step: 1
Training loss: 1.222352498991253
Validation loss: 2.4881764713423737

Epoch: 5| Step: 2
Training loss: 1.1360560317291082
Validation loss: 2.4795702144543545

Epoch: 5| Step: 3
Training loss: 1.0927787828357314
Validation loss: 2.4987135951222053

Epoch: 5| Step: 4
Training loss: 0.650523083461253
Validation loss: 2.5233606964119746

Epoch: 5| Step: 5
Training loss: 1.2474211794429055
Validation loss: 2.5423159429828623

Epoch: 5| Step: 6
Training loss: 1.248734501159224
Validation loss: 2.540751924187238

Epoch: 5| Step: 7
Training loss: 1.1410280325586197
Validation loss: 2.5459977287424964

Epoch: 5| Step: 8
Training loss: 1.105066772273174
Validation loss: 2.526094872781527

Epoch: 5| Step: 9
Training loss: 1.4448260339207928
Validation loss: 2.5335570476107088

Epoch: 5| Step: 10
Training loss: 1.8136058590779611
Validation loss: 2.5172926487781537

Epoch: 246| Step: 0
Training loss: 1.1780918268445917
Validation loss: 2.51757956690723

Epoch: 5| Step: 1
Training loss: 1.0137267933928036
Validation loss: 2.5130706906281035

Epoch: 5| Step: 2
Training loss: 1.4687547074912093
Validation loss: 2.500486904843429

Epoch: 5| Step: 3
Training loss: 0.9745124355871261
Validation loss: 2.5111895034423712

Epoch: 5| Step: 4
Training loss: 1.5200209429201603
Validation loss: 2.5095960272874156

Epoch: 5| Step: 5
Training loss: 0.9354904571915036
Validation loss: 2.521131422791209

Epoch: 5| Step: 6
Training loss: 1.1163899168897948
Validation loss: 2.5010572013179995

Epoch: 5| Step: 7
Training loss: 1.140895550138703
Validation loss: 2.5020850085508965

Epoch: 5| Step: 8
Training loss: 0.9946272882327598
Validation loss: 2.51674963717839

Epoch: 5| Step: 9
Training loss: 1.2721602698728813
Validation loss: 2.4945300517375397

Epoch: 5| Step: 10
Training loss: 1.4258106803469408
Validation loss: 2.4954165311685

Epoch: 247| Step: 0
Training loss: 1.0471090937546255
Validation loss: 2.492599398232396

Epoch: 5| Step: 1
Training loss: 1.8121798660109631
Validation loss: 2.505762300984962

Epoch: 5| Step: 2
Training loss: 0.8097456315438898
Validation loss: 2.5065321635323143

Epoch: 5| Step: 3
Training loss: 1.1478290632897892
Validation loss: 2.5034655812771685

Epoch: 5| Step: 4
Training loss: 1.4809282943397613
Validation loss: 2.507974263094544

Epoch: 5| Step: 5
Training loss: 1.3237660402185274
Validation loss: 2.531778210829113

Epoch: 5| Step: 6
Training loss: 1.017007678847829
Validation loss: 2.5386753955259964

Epoch: 5| Step: 7
Training loss: 0.9392961144842835
Validation loss: 2.5480547674549903

Epoch: 5| Step: 8
Training loss: 0.8526177823318096
Validation loss: 2.549732175125793

Epoch: 5| Step: 9
Training loss: 0.9598846249987657
Validation loss: 2.541953710293715

Epoch: 5| Step: 10
Training loss: 1.3020791575046973
Validation loss: 2.547684144934089

Epoch: 248| Step: 0
Training loss: 1.08519620773758
Validation loss: 2.5513373199750244

Epoch: 5| Step: 1
Training loss: 0.7532439410994349
Validation loss: 2.5313915282496176

Epoch: 5| Step: 2
Training loss: 1.360196008161429
Validation loss: 2.522149331238488

Epoch: 5| Step: 3
Training loss: 1.1841883409106244
Validation loss: 2.527114406620845

Epoch: 5| Step: 4
Training loss: 1.6809858405329854
Validation loss: 2.5172056667570373

Epoch: 5| Step: 5
Training loss: 1.1470499284681301
Validation loss: 2.5375655453473382

Epoch: 5| Step: 6
Training loss: 1.283489224432133
Validation loss: 2.540315729644074

Epoch: 5| Step: 7
Training loss: 0.8472656193720465
Validation loss: 2.512207284327409

Epoch: 5| Step: 8
Training loss: 1.3575769130071118
Validation loss: 2.508338037713396

Epoch: 5| Step: 9
Training loss: 0.7178018369700602
Validation loss: 2.4942640675415175

Epoch: 5| Step: 10
Training loss: 1.3072573542049728
Validation loss: 2.513238956286136

Epoch: 249| Step: 0
Training loss: 1.416617766639623
Validation loss: 2.5171909583020566

Epoch: 5| Step: 1
Training loss: 1.5335081926791785
Validation loss: 2.5208976731970756

Epoch: 5| Step: 2
Training loss: 0.9876250248242592
Validation loss: 2.5086398434717316

Epoch: 5| Step: 3
Training loss: 1.1672425324770397
Validation loss: 2.525406694712836

Epoch: 5| Step: 4
Training loss: 1.0027221940492919
Validation loss: 2.5292884278236545

Epoch: 5| Step: 5
Training loss: 0.899933639040155
Validation loss: 2.5495941123795345

Epoch: 5| Step: 6
Training loss: 0.9925471577623303
Validation loss: 2.5221397654021303

Epoch: 5| Step: 7
Training loss: 1.6766435587575461
Validation loss: 2.5235179056645753

Epoch: 5| Step: 8
Training loss: 1.063104850044343
Validation loss: 2.52540640844342

Epoch: 5| Step: 9
Training loss: 0.9074507683675205
Validation loss: 2.5313321982259134

Epoch: 5| Step: 10
Training loss: 0.922037789147543
Validation loss: 2.533830761958162

Epoch: 250| Step: 0
Training loss: 1.118230479570864
Validation loss: 2.5142547997034184

Epoch: 5| Step: 1
Training loss: 1.3495745288639804
Validation loss: 2.4913293029064913

Epoch: 5| Step: 2
Training loss: 0.6220069505649694
Validation loss: 2.4983645629866915

Epoch: 5| Step: 3
Training loss: 0.8753333478553792
Validation loss: 2.5354796832357787

Epoch: 5| Step: 4
Training loss: 1.165473952746538
Validation loss: 2.5144252434567678

Epoch: 5| Step: 5
Training loss: 1.1913342063258778
Validation loss: 2.520543740734755

Epoch: 5| Step: 6
Training loss: 1.2422745392253256
Validation loss: 2.5058997363773545

Epoch: 5| Step: 7
Training loss: 0.767307612384375
Validation loss: 2.52176664101602

Epoch: 5| Step: 8
Training loss: 1.190082502550513
Validation loss: 2.4919763296159263

Epoch: 5| Step: 9
Training loss: 1.5744125966258218
Validation loss: 2.527278153422395

Epoch: 5| Step: 10
Training loss: 1.438469352626407
Validation loss: 2.5064182258893344

Epoch: 251| Step: 0
Training loss: 1.2299238179037695
Validation loss: 2.510329713278415

Epoch: 5| Step: 1
Training loss: 1.1238357029229435
Validation loss: 2.5122225949529717

Epoch: 5| Step: 2
Training loss: 0.8325197818341815
Validation loss: 2.520943714926284

Epoch: 5| Step: 3
Training loss: 1.0826932899281967
Validation loss: 2.513990165138755

Epoch: 5| Step: 4
Training loss: 1.0777003239682403
Validation loss: 2.4965389094252712

Epoch: 5| Step: 5
Training loss: 1.0029390774800815
Validation loss: 2.5050510499277667

Epoch: 5| Step: 6
Training loss: 1.5478855261701607
Validation loss: 2.520575509598483

Epoch: 5| Step: 7
Training loss: 1.1874859457690123
Validation loss: 2.520989782254492

Epoch: 5| Step: 8
Training loss: 1.612054612505405
Validation loss: 2.507408612774816

Epoch: 5| Step: 9
Training loss: 1.08023782001348
Validation loss: 2.516725385481113

Epoch: 5| Step: 10
Training loss: 0.7115580606636212
Validation loss: 2.520089690571597

Epoch: 252| Step: 0
Training loss: 0.9961011100945913
Validation loss: 2.536432108470098

Epoch: 5| Step: 1
Training loss: 1.2663921338941349
Validation loss: 2.5163095824642654

Epoch: 5| Step: 2
Training loss: 1.4586232669175037
Validation loss: 2.507907642134914

Epoch: 5| Step: 3
Training loss: 0.7381573931428118
Validation loss: 2.5039560928849967

Epoch: 5| Step: 4
Training loss: 1.4173579305940927
Validation loss: 2.4858049510981632

Epoch: 5| Step: 5
Training loss: 1.00079993201514
Validation loss: 2.4837009916196706

Epoch: 5| Step: 6
Training loss: 1.1119550334565886
Validation loss: 2.4773233723289123

Epoch: 5| Step: 7
Training loss: 0.8154191250602402
Validation loss: 2.4864029813741557

Epoch: 5| Step: 8
Training loss: 1.2724168583926856
Validation loss: 2.4734351708049043

Epoch: 5| Step: 9
Training loss: 1.3523087398376106
Validation loss: 2.472494173740974

Epoch: 5| Step: 10
Training loss: 1.1399880812674419
Validation loss: 2.535002316031737

Epoch: 253| Step: 0
Training loss: 0.8867643235380401
Validation loss: 2.531664454981094

Epoch: 5| Step: 1
Training loss: 1.1653870592844648
Validation loss: 2.542301216443315

Epoch: 5| Step: 2
Training loss: 1.442987004253954
Validation loss: 2.5507037380231714

Epoch: 5| Step: 3
Training loss: 1.419614063255408
Validation loss: 2.5606336192139763

Epoch: 5| Step: 4
Training loss: 1.1005022072949733
Validation loss: 2.5508844578697922

Epoch: 5| Step: 5
Training loss: 1.2307704979404015
Validation loss: 2.5514420303582424

Epoch: 5| Step: 6
Training loss: 1.1550641035480926
Validation loss: 2.564309508493356

Epoch: 5| Step: 7
Training loss: 0.9707102477888824
Validation loss: 2.551802380692229

Epoch: 5| Step: 8
Training loss: 1.1274539357014108
Validation loss: 2.5471925611101973

Epoch: 5| Step: 9
Training loss: 0.890407401824957
Validation loss: 2.538220695240638

Epoch: 5| Step: 10
Training loss: 1.1498421104513807
Validation loss: 2.5430470421120077

Epoch: 254| Step: 0
Training loss: 1.573909984816338
Validation loss: 2.5455707386491038

Epoch: 5| Step: 1
Training loss: 0.7186986656101206
Validation loss: 2.558806634253522

Epoch: 5| Step: 2
Training loss: 0.7972698355474312
Validation loss: 2.5573830156021624

Epoch: 5| Step: 3
Training loss: 0.9542868989601809
Validation loss: 2.542293786587371

Epoch: 5| Step: 4
Training loss: 1.5044165600058708
Validation loss: 2.5508110201561562

Epoch: 5| Step: 5
Training loss: 0.8116965356013832
Validation loss: 2.535347048849124

Epoch: 5| Step: 6
Training loss: 1.2789021822259397
Validation loss: 2.5308554435657546

Epoch: 5| Step: 7
Training loss: 1.2862000560054017
Validation loss: 2.508360052520066

Epoch: 5| Step: 8
Training loss: 1.114678506560924
Validation loss: 2.515852682258009

Epoch: 5| Step: 9
Training loss: 1.2368646454919816
Validation loss: 2.5186136731842375

Epoch: 5| Step: 10
Training loss: 1.0353275948992018
Validation loss: 2.5180987383182085

Epoch: 255| Step: 0
Training loss: 1.6962532210969525
Validation loss: 2.5325473770910647

Epoch: 5| Step: 1
Training loss: 1.3815568729778733
Validation loss: 2.540468651419361

Epoch: 5| Step: 2
Training loss: 0.9023869822000279
Validation loss: 2.5180350664256177

Epoch: 5| Step: 3
Training loss: 0.9290222223906917
Validation loss: 2.52360626655012

Epoch: 5| Step: 4
Training loss: 1.4906366887623965
Validation loss: 2.5333000519589737

Epoch: 5| Step: 5
Training loss: 0.8726647754823064
Validation loss: 2.528018695253207

Epoch: 5| Step: 6
Training loss: 0.8039073310155246
Validation loss: 2.537284012383841

Epoch: 5| Step: 7
Training loss: 1.0635845034967797
Validation loss: 2.545032388547241

Epoch: 5| Step: 8
Training loss: 0.9102462593070899
Validation loss: 2.5476673644347816

Epoch: 5| Step: 9
Training loss: 1.207512176404891
Validation loss: 2.5304955264909914

Epoch: 5| Step: 10
Training loss: 0.7679897689659405
Validation loss: 2.5414426526003115

Epoch: 256| Step: 0
Training loss: 1.1887518658708596
Validation loss: 2.5423722900659107

Epoch: 5| Step: 1
Training loss: 0.8483793979933776
Validation loss: 2.519658527242212

Epoch: 5| Step: 2
Training loss: 1.0948464483655491
Validation loss: 2.5421963736009805

Epoch: 5| Step: 3
Training loss: 1.0243765330463177
Validation loss: 2.5352386562845317

Epoch: 5| Step: 4
Training loss: 0.7962884427167152
Validation loss: 2.529125420378201

Epoch: 5| Step: 5
Training loss: 1.1404051895502534
Validation loss: 2.549927036899174

Epoch: 5| Step: 6
Training loss: 0.8841421528461142
Validation loss: 2.533048377042914

Epoch: 5| Step: 7
Training loss: 0.8511081848545196
Validation loss: 2.5129946699294248

Epoch: 5| Step: 8
Training loss: 1.0646615200607064
Validation loss: 2.5174196873574113

Epoch: 5| Step: 9
Training loss: 1.550157320591092
Validation loss: 2.523392003111901

Epoch: 5| Step: 10
Training loss: 1.7190778939716467
Validation loss: 2.5311251333154634

Epoch: 257| Step: 0
Training loss: 1.0063008645038138
Validation loss: 2.525733756626445

Epoch: 5| Step: 1
Training loss: 1.3982524216574848
Validation loss: 2.5215451293182856

Epoch: 5| Step: 2
Training loss: 1.487532940668123
Validation loss: 2.514376264721517

Epoch: 5| Step: 3
Training loss: 0.8358068631494916
Validation loss: 2.530553465930742

Epoch: 5| Step: 4
Training loss: 1.102584256782421
Validation loss: 2.5208040129108045

Epoch: 5| Step: 5
Training loss: 0.9433461695787366
Validation loss: 2.5086161055850837

Epoch: 5| Step: 6
Training loss: 1.4404233150017938
Validation loss: 2.5247045477929277

Epoch: 5| Step: 7
Training loss: 1.1138843709632615
Validation loss: 2.534755726531638

Epoch: 5| Step: 8
Training loss: 1.124268293846474
Validation loss: 2.5314811804545836

Epoch: 5| Step: 9
Training loss: 1.212788305712108
Validation loss: 2.525057775209474

Epoch: 5| Step: 10
Training loss: 1.1949472305585633
Validation loss: 2.528775348330787

Epoch: 258| Step: 0
Training loss: 1.1003247063568329
Validation loss: 2.5285288744595538

Epoch: 5| Step: 1
Training loss: 0.8784977281374966
Validation loss: 2.5342354739823545

Epoch: 5| Step: 2
Training loss: 1.4353586916941776
Validation loss: 2.524014751496202

Epoch: 5| Step: 3
Training loss: 0.9345240726013554
Validation loss: 2.551375141708491

Epoch: 5| Step: 4
Training loss: 0.7251542913751139
Validation loss: 2.5570175143910894

Epoch: 5| Step: 5
Training loss: 1.7082524939537964
Validation loss: 2.5601691453343283

Epoch: 5| Step: 6
Training loss: 1.1768467026690208
Validation loss: 2.556173689511249

Epoch: 5| Step: 7
Training loss: 1.4743168622852758
Validation loss: 2.5367048208259515

Epoch: 5| Step: 8
Training loss: 0.858248475117583
Validation loss: 2.541728402417987

Epoch: 5| Step: 9
Training loss: 0.7764520562766631
Validation loss: 2.5163696507677926

Epoch: 5| Step: 10
Training loss: 1.181407205525529
Validation loss: 2.5555032591293685

Epoch: 259| Step: 0
Training loss: 0.9680833676315669
Validation loss: 2.532018346630509

Epoch: 5| Step: 1
Training loss: 0.9914327439059
Validation loss: 2.5279850474947736

Epoch: 5| Step: 2
Training loss: 0.9275656135053927
Validation loss: 2.5463831190204287

Epoch: 5| Step: 3
Training loss: 0.8414042324938091
Validation loss: 2.529663291505768

Epoch: 5| Step: 4
Training loss: 0.8986711612868706
Validation loss: 2.515900724344047

Epoch: 5| Step: 5
Training loss: 1.4491103303973465
Validation loss: 2.512875669251322

Epoch: 5| Step: 6
Training loss: 1.0666173928522755
Validation loss: 2.549526096811063

Epoch: 5| Step: 7
Training loss: 1.649658040533189
Validation loss: 2.5447487550968746

Epoch: 5| Step: 8
Training loss: 1.0644570446817168
Validation loss: 2.5509452644604402

Epoch: 5| Step: 9
Training loss: 0.9954358490066599
Validation loss: 2.5635824970911028

Epoch: 5| Step: 10
Training loss: 1.1853882936502378
Validation loss: 2.556638926361311

Epoch: 260| Step: 0
Training loss: 1.1755430671010114
Validation loss: 2.5605673331068872

Epoch: 5| Step: 1
Training loss: 0.9260856675177779
Validation loss: 2.551148610382486

Epoch: 5| Step: 2
Training loss: 0.8740357126407567
Validation loss: 2.551282109416343

Epoch: 5| Step: 3
Training loss: 1.0778765737722702
Validation loss: 2.5654578277077444

Epoch: 5| Step: 4
Training loss: 2.0129483215247714
Validation loss: 2.5485084942737033

Epoch: 5| Step: 5
Training loss: 1.0820954782310934
Validation loss: 2.5400344843482014

Epoch: 5| Step: 6
Training loss: 0.7032883560306447
Validation loss: 2.54595093226326

Epoch: 5| Step: 7
Training loss: 0.4591760600347117
Validation loss: 2.546528752234898

Epoch: 5| Step: 8
Training loss: 0.872848215051917
Validation loss: 2.537968925438406

Epoch: 5| Step: 9
Training loss: 1.2271487056155703
Validation loss: 2.5384909295229456

Epoch: 5| Step: 10
Training loss: 1.1159023015077596
Validation loss: 2.518206274391724

Epoch: 261| Step: 0
Training loss: 0.864194085309394
Validation loss: 2.536252233099673

Epoch: 5| Step: 1
Training loss: 1.591806610639323
Validation loss: 2.5137013192382165

Epoch: 5| Step: 2
Training loss: 1.1385282291737382
Validation loss: 2.5169613508454463

Epoch: 5| Step: 3
Training loss: 0.8689108212588624
Validation loss: 2.5141817463669995

Epoch: 5| Step: 4
Training loss: 1.6591084842772361
Validation loss: 2.5058242196512697

Epoch: 5| Step: 5
Training loss: 1.0722282694995793
Validation loss: 2.5052995097012807

Epoch: 5| Step: 6
Training loss: 0.8665569177854273
Validation loss: 2.515914426467274

Epoch: 5| Step: 7
Training loss: 0.9859319212161711
Validation loss: 2.4983458912440155

Epoch: 5| Step: 8
Training loss: 0.7737069094218846
Validation loss: 2.5294440240563247

Epoch: 5| Step: 9
Training loss: 0.9998710966476361
Validation loss: 2.5474155400246277

Epoch: 5| Step: 10
Training loss: 0.7655604199012104
Validation loss: 2.5610776756106732

Epoch: 262| Step: 0
Training loss: 1.4252984052386468
Validation loss: 2.5709255108509597

Epoch: 5| Step: 1
Training loss: 0.63907678117161
Validation loss: 2.5477841242711965

Epoch: 5| Step: 2
Training loss: 0.8458623229697968
Validation loss: 2.5343513464298977

Epoch: 5| Step: 3
Training loss: 0.8294604348145055
Validation loss: 2.539452411508228

Epoch: 5| Step: 4
Training loss: 0.5052188957394887
Validation loss: 2.5137627282404282

Epoch: 5| Step: 5
Training loss: 1.3617696607027288
Validation loss: 2.505694008512299

Epoch: 5| Step: 6
Training loss: 0.9549808569682173
Validation loss: 2.5010205298337462

Epoch: 5| Step: 7
Training loss: 1.2132282370771768
Validation loss: 2.5094335984477314

Epoch: 5| Step: 8
Training loss: 1.013212184272814
Validation loss: 2.515034644988891

Epoch: 5| Step: 9
Training loss: 0.8340469801406796
Validation loss: 2.527065897006805

Epoch: 5| Step: 10
Training loss: 1.8139083915130647
Validation loss: 2.5278358064791377

Epoch: 263| Step: 0
Training loss: 0.9064250974203157
Validation loss: 2.482619139450332

Epoch: 5| Step: 1
Training loss: 1.1674613743668043
Validation loss: 2.4746516197464157

Epoch: 5| Step: 2
Training loss: 0.8976312751715354
Validation loss: 2.472553408563389

Epoch: 5| Step: 3
Training loss: 1.0503691251518514
Validation loss: 2.4816106357556293

Epoch: 5| Step: 4
Training loss: 0.6296441624118403
Validation loss: 2.476763099844812

Epoch: 5| Step: 5
Training loss: 0.9801751111218224
Validation loss: 2.501423776930459

Epoch: 5| Step: 6
Training loss: 1.2354228244175587
Validation loss: 2.4699412273488863

Epoch: 5| Step: 7
Training loss: 1.0338980459643266
Validation loss: 2.4949845426084205

Epoch: 5| Step: 8
Training loss: 1.3420275804951598
Validation loss: 2.5078817480728293

Epoch: 5| Step: 9
Training loss: 1.4001211335365753
Validation loss: 2.5013903310151426

Epoch: 5| Step: 10
Training loss: 0.9801204716339801
Validation loss: 2.5300317377506314

Epoch: 264| Step: 0
Training loss: 0.5993734883596633
Validation loss: 2.540091529488477

Epoch: 5| Step: 1
Training loss: 1.1448551800192275
Validation loss: 2.5269719164906497

Epoch: 5| Step: 2
Training loss: 0.5103292455220885
Validation loss: 2.51763512145686

Epoch: 5| Step: 3
Training loss: 0.8472504941117733
Validation loss: 2.537501533475912

Epoch: 5| Step: 4
Training loss: 1.7572468843691607
Validation loss: 2.515772535007545

Epoch: 5| Step: 5
Training loss: 1.55368799639824
Validation loss: 2.5239974073511746

Epoch: 5| Step: 6
Training loss: 0.819389368799827
Validation loss: 2.5319565050742927

Epoch: 5| Step: 7
Training loss: 0.9782732513008126
Validation loss: 2.5349936117821623

Epoch: 5| Step: 8
Training loss: 0.8610637371472171
Validation loss: 2.539189159178011

Epoch: 5| Step: 9
Training loss: 1.1549141358169985
Validation loss: 2.553491820434168

Epoch: 5| Step: 10
Training loss: 0.9002912222384656
Validation loss: 2.5602042506309344

Epoch: 265| Step: 0
Training loss: 0.936893203181876
Validation loss: 2.5819323555251033

Epoch: 5| Step: 1
Training loss: 0.9225747636928762
Validation loss: 2.6123938160763718

Epoch: 5| Step: 2
Training loss: 1.1076723384025102
Validation loss: 2.5544240785057575

Epoch: 5| Step: 3
Training loss: 0.7631601243367312
Validation loss: 2.5661808062924303

Epoch: 5| Step: 4
Training loss: 0.8602552587364496
Validation loss: 2.527170680786039

Epoch: 5| Step: 5
Training loss: 0.83652112320556
Validation loss: 2.5360663151217695

Epoch: 5| Step: 6
Training loss: 1.520572883913885
Validation loss: 2.5406070223790045

Epoch: 5| Step: 7
Training loss: 1.5341781334532232
Validation loss: 2.4986687581849885

Epoch: 5| Step: 8
Training loss: 1.0971838861252199
Validation loss: 2.4857938190908158

Epoch: 5| Step: 9
Training loss: 0.5694782216694734
Validation loss: 2.4929982549533087

Epoch: 5| Step: 10
Training loss: 1.2162813469198286
Validation loss: 2.488585975432552

Epoch: 266| Step: 0
Training loss: 0.9647955631470394
Validation loss: 2.5026712748680757

Epoch: 5| Step: 1
Training loss: 0.7077603874643523
Validation loss: 2.4910471395371325

Epoch: 5| Step: 2
Training loss: 0.7140976811596645
Validation loss: 2.5293982591865087

Epoch: 5| Step: 3
Training loss: 1.3364675262364936
Validation loss: 2.554712902588928

Epoch: 5| Step: 4
Training loss: 0.8543280394791114
Validation loss: 2.554107279004217

Epoch: 5| Step: 5
Training loss: 1.6678563243132292
Validation loss: 2.5384123817540236

Epoch: 5| Step: 6
Training loss: 0.986960361405568
Validation loss: 2.549528592550546

Epoch: 5| Step: 7
Training loss: 1.0611059917428538
Validation loss: 2.5379821811437324

Epoch: 5| Step: 8
Training loss: 1.1769458667975716
Validation loss: 2.536762000466795

Epoch: 5| Step: 9
Training loss: 0.6311529793161376
Validation loss: 2.521254970937659

Epoch: 5| Step: 10
Training loss: 1.1822319631864395
Validation loss: 2.5303798726021647

Epoch: 267| Step: 0
Training loss: 0.5873275036910407
Validation loss: 2.5235605517502844

Epoch: 5| Step: 1
Training loss: 1.4654001222048396
Validation loss: 2.5178590745998806

Epoch: 5| Step: 2
Training loss: 1.1588216484165046
Validation loss: 2.5093589954143978

Epoch: 5| Step: 3
Training loss: 0.9336327261350329
Validation loss: 2.489427420999988

Epoch: 5| Step: 4
Training loss: 0.7525871477325738
Validation loss: 2.52290472666273

Epoch: 5| Step: 5
Training loss: 0.9258565429458778
Validation loss: 2.550143554466261

Epoch: 5| Step: 6
Training loss: 1.090799056540187
Validation loss: 2.548082931023063

Epoch: 5| Step: 7
Training loss: 1.1872858557107366
Validation loss: 2.572090470298554

Epoch: 5| Step: 8
Training loss: 0.7831676979328756
Validation loss: 2.554036895303653

Epoch: 5| Step: 9
Training loss: 1.0709414896293796
Validation loss: 2.5620737329032393

Epoch: 5| Step: 10
Training loss: 1.6467990054235264
Validation loss: 2.56615139826256

Epoch: 268| Step: 0
Training loss: 0.8247647036617474
Validation loss: 2.55304374922502

Epoch: 5| Step: 1
Training loss: 1.021366382443474
Validation loss: 2.542832990711999

Epoch: 5| Step: 2
Training loss: 0.7929477031150846
Validation loss: 2.5213149575172236

Epoch: 5| Step: 3
Training loss: 1.7287601621250517
Validation loss: 2.530287586619556

Epoch: 5| Step: 4
Training loss: 0.5426092535747024
Validation loss: 2.534615283796167

Epoch: 5| Step: 5
Training loss: 0.9850821301547282
Validation loss: 2.542154799506178

Epoch: 5| Step: 6
Training loss: 0.6868989875013504
Validation loss: 2.5494748139520484

Epoch: 5| Step: 7
Training loss: 1.1326689530548435
Validation loss: 2.5397293727061374

Epoch: 5| Step: 8
Training loss: 0.6931460200047104
Validation loss: 2.5662098563437374

Epoch: 5| Step: 9
Training loss: 1.1810153284039069
Validation loss: 2.558575757015148

Epoch: 5| Step: 10
Training loss: 1.5454766474637638
Validation loss: 2.5807514265251976

Epoch: 269| Step: 0
Training loss: 0.7037690709580792
Validation loss: 2.545401303783338

Epoch: 5| Step: 1
Training loss: 1.3072536609895313
Validation loss: 2.5611185941918357

Epoch: 5| Step: 2
Training loss: 0.9836043414090293
Validation loss: 2.5369700306303464

Epoch: 5| Step: 3
Training loss: 1.703823541298098
Validation loss: 2.5284450135240224

Epoch: 5| Step: 4
Training loss: 0.7913422840172467
Validation loss: 2.5319038214136285

Epoch: 5| Step: 5
Training loss: 1.0453109444690758
Validation loss: 2.5108708909507427

Epoch: 5| Step: 6
Training loss: 0.9466375412008855
Validation loss: 2.535389543488467

Epoch: 5| Step: 7
Training loss: 1.2340829721096902
Validation loss: 2.509493521289147

Epoch: 5| Step: 8
Training loss: 0.7551576180803822
Validation loss: 2.52252324153107

Epoch: 5| Step: 9
Training loss: 0.9943948057301415
Validation loss: 2.5503108241524726

Epoch: 5| Step: 10
Training loss: 0.6969168081700413
Validation loss: 2.5356896905116217

Epoch: 270| Step: 0
Training loss: 1.2177937008075055
Validation loss: 2.543839678282469

Epoch: 5| Step: 1
Training loss: 1.536872195954497
Validation loss: 2.5299474316252843

Epoch: 5| Step: 2
Training loss: 1.147124181801391
Validation loss: 2.5529847037287063

Epoch: 5| Step: 3
Training loss: 1.4759155147739618
Validation loss: 2.513660497206446

Epoch: 5| Step: 4
Training loss: 1.0563966254315107
Validation loss: 2.4858795189985456

Epoch: 5| Step: 5
Training loss: 0.969437785719332
Validation loss: 2.516803568558359

Epoch: 5| Step: 6
Training loss: 0.8530007911222307
Validation loss: 2.4898615217556475

Epoch: 5| Step: 7
Training loss: 0.9312350111913603
Validation loss: 2.529815487627222

Epoch: 5| Step: 8
Training loss: 0.5570927707678278
Validation loss: 2.532158897966409

Epoch: 5| Step: 9
Training loss: 0.5141858912273893
Validation loss: 2.5339978564786425

Epoch: 5| Step: 10
Training loss: 0.9288344115638829
Validation loss: 2.536109356207044

Epoch: 271| Step: 0
Training loss: 0.698162837288084
Validation loss: 2.5474824264715474

Epoch: 5| Step: 1
Training loss: 1.013804638350911
Validation loss: 2.5446209239011894

Epoch: 5| Step: 2
Training loss: 1.008617345887029
Validation loss: 2.529245091763926

Epoch: 5| Step: 3
Training loss: 0.9683919060195123
Validation loss: 2.525566925373373

Epoch: 5| Step: 4
Training loss: 0.4723275831044585
Validation loss: 2.492794427278448

Epoch: 5| Step: 5
Training loss: 1.3590590011049914
Validation loss: 2.503710129265952

Epoch: 5| Step: 6
Training loss: 1.533430376644626
Validation loss: 2.4948151485195975

Epoch: 5| Step: 7
Training loss: 0.9619367103040536
Validation loss: 2.517985097013937

Epoch: 5| Step: 8
Training loss: 0.6064666400298167
Validation loss: 2.5224806195771796

Epoch: 5| Step: 9
Training loss: 1.2029441103014096
Validation loss: 2.5300779841155743

Epoch: 5| Step: 10
Training loss: 1.1004353702048124
Validation loss: 2.5325240890348013

Epoch: 272| Step: 0
Training loss: 0.7115177678927629
Validation loss: 2.555885235121204

Epoch: 5| Step: 1
Training loss: 0.8007547141539897
Validation loss: 2.5548399538896027

Epoch: 5| Step: 2
Training loss: 1.4830357985391098
Validation loss: 2.546332891414019

Epoch: 5| Step: 3
Training loss: 0.8376185546772758
Validation loss: 2.5471942257900846

Epoch: 5| Step: 4
Training loss: 1.4344705919646543
Validation loss: 2.5254936419630587

Epoch: 5| Step: 5
Training loss: 0.8004610491443069
Validation loss: 2.5292654518477895

Epoch: 5| Step: 6
Training loss: 0.9224368823822392
Validation loss: 2.5235344668042488

Epoch: 5| Step: 7
Training loss: 1.2124316442039385
Validation loss: 2.526730157115785

Epoch: 5| Step: 8
Training loss: 1.0394541640421633
Validation loss: 2.5285889120344263

Epoch: 5| Step: 9
Training loss: 1.070205460368117
Validation loss: 2.5323369619238845

Epoch: 5| Step: 10
Training loss: 0.5363413920918301
Validation loss: 2.5076221006221515

Epoch: 273| Step: 0
Training loss: 1.310237341994523
Validation loss: 2.514513661330757

Epoch: 5| Step: 1
Training loss: 0.8691105183733987
Validation loss: 2.541126545512088

Epoch: 5| Step: 2
Training loss: 1.1387504956174206
Validation loss: 2.5114708232046343

Epoch: 5| Step: 3
Training loss: 1.026547257355236
Validation loss: 2.5263860679381502

Epoch: 5| Step: 4
Training loss: 0.2538225769676505
Validation loss: 2.5303804541470827

Epoch: 5| Step: 5
Training loss: 1.7088780658898954
Validation loss: 2.5344032104454812

Epoch: 5| Step: 6
Training loss: 0.8393231929944694
Validation loss: 2.5455392061977653

Epoch: 5| Step: 7
Training loss: 0.9986853600831277
Validation loss: 2.5307770498265647

Epoch: 5| Step: 8
Training loss: 1.025574179069604
Validation loss: 2.540468687747722

Epoch: 5| Step: 9
Training loss: 0.7275509826912534
Validation loss: 2.5110336285616337

Epoch: 5| Step: 10
Training loss: 0.541275430262513
Validation loss: 2.5270823030141942

Epoch: 274| Step: 0
Training loss: 0.8995602765352346
Validation loss: 2.5011570888194457

Epoch: 5| Step: 1
Training loss: 0.890873088080457
Validation loss: 2.5194996602802355

Epoch: 5| Step: 2
Training loss: 0.9625578454210194
Validation loss: 2.514550469418885

Epoch: 5| Step: 3
Training loss: 0.7620015719690404
Validation loss: 2.511193559423015

Epoch: 5| Step: 4
Training loss: 1.576306570128538
Validation loss: 2.5199791477955005

Epoch: 5| Step: 5
Training loss: 0.8120157559421212
Validation loss: 2.5226378836756322

Epoch: 5| Step: 6
Training loss: 0.7467688656656554
Validation loss: 2.53205402649025

Epoch: 5| Step: 7
Training loss: 0.7630888135048863
Validation loss: 2.54394752146959

Epoch: 5| Step: 8
Training loss: 0.8820856528656353
Validation loss: 2.553001561744671

Epoch: 5| Step: 9
Training loss: 1.546219349636772
Validation loss: 2.5463653886042636

Epoch: 5| Step: 10
Training loss: 0.942741491812969
Validation loss: 2.5143007474261294

Epoch: 275| Step: 0
Training loss: 0.74381383093037
Validation loss: 2.551392374599693

Epoch: 5| Step: 1
Training loss: 1.4091962679854433
Validation loss: 2.537968090073113

Epoch: 5| Step: 2
Training loss: 0.9270219175305243
Validation loss: 2.5525112540878077

Epoch: 5| Step: 3
Training loss: 0.7965448855117062
Validation loss: 2.559663182268308

Epoch: 5| Step: 4
Training loss: 0.9703588047742439
Validation loss: 2.5453197673861383

Epoch: 5| Step: 5
Training loss: 0.9848977169433742
Validation loss: 2.5516720073454886

Epoch: 5| Step: 6
Training loss: 1.5774271715766843
Validation loss: 2.5572383143153923

Epoch: 5| Step: 7
Training loss: 0.6355304511913489
Validation loss: 2.5676687456742746

Epoch: 5| Step: 8
Training loss: 0.7890542662540321
Validation loss: 2.572147351186454

Epoch: 5| Step: 9
Training loss: 0.8725257359291493
Validation loss: 2.581919114466605

Epoch: 5| Step: 10
Training loss: 0.9377933361176289
Validation loss: 2.5671445452291977

Epoch: 276| Step: 0
Training loss: 1.967261947907749
Validation loss: 2.5543076442683827

Epoch: 5| Step: 1
Training loss: 0.9777692739039833
Validation loss: 2.5340576886053725

Epoch: 5| Step: 2
Training loss: 1.0947027144271833
Validation loss: 2.5300323502807247

Epoch: 5| Step: 3
Training loss: 0.7262037068121376
Validation loss: 2.5386567271617992

Epoch: 5| Step: 4
Training loss: 1.0417753099370075
Validation loss: 2.523445798118056

Epoch: 5| Step: 5
Training loss: 0.7451442648591098
Validation loss: 2.5517446574909926

Epoch: 5| Step: 6
Training loss: 0.5397647485188966
Validation loss: 2.5368978168436334

Epoch: 5| Step: 7
Training loss: 0.8759298833106932
Validation loss: 2.5144742146108783

Epoch: 5| Step: 8
Training loss: 0.996952748630017
Validation loss: 2.547967727812625

Epoch: 5| Step: 9
Training loss: 0.7385079979227785
Validation loss: 2.5327094673880612

Epoch: 5| Step: 10
Training loss: 0.5762325448890727
Validation loss: 2.5525940622405487

Epoch: 277| Step: 0
Training loss: 1.6374427086512036
Validation loss: 2.5421530760614326

Epoch: 5| Step: 1
Training loss: 1.3399951282099514
Validation loss: 2.526753462554104

Epoch: 5| Step: 2
Training loss: 0.759709373294178
Validation loss: 2.5216917760942046

Epoch: 5| Step: 3
Training loss: 1.0037146359457363
Validation loss: 2.515076543022848

Epoch: 5| Step: 4
Training loss: 0.9252802140859046
Validation loss: 2.520216572391059

Epoch: 5| Step: 5
Training loss: 0.6987526474904249
Validation loss: 2.5215207183692647

Epoch: 5| Step: 6
Training loss: 0.8330877339527112
Validation loss: 2.5380332154174092

Epoch: 5| Step: 7
Training loss: 0.850948462329849
Validation loss: 2.5337524228382122

Epoch: 5| Step: 8
Training loss: 0.9170404488535534
Validation loss: 2.506945581119362

Epoch: 5| Step: 9
Training loss: 0.9415296418299304
Validation loss: 2.5109620864893403

Epoch: 5| Step: 10
Training loss: 0.5778908642062747
Validation loss: 2.5114969921053993

Epoch: 278| Step: 0
Training loss: 0.8201737422752894
Validation loss: 2.5394811787690124

Epoch: 5| Step: 1
Training loss: 1.020313357576299
Validation loss: 2.518649511384398

Epoch: 5| Step: 2
Training loss: 0.5469859691839317
Validation loss: 2.532455333583916

Epoch: 5| Step: 3
Training loss: 0.7230644516583453
Validation loss: 2.5250009351347065

Epoch: 5| Step: 4
Training loss: 1.5297022412596095
Validation loss: 2.509921774226787

Epoch: 5| Step: 5
Training loss: 0.9636467060193334
Validation loss: 2.5129487646370876

Epoch: 5| Step: 6
Training loss: 0.7528837711963967
Validation loss: 2.5338774301890346

Epoch: 5| Step: 7
Training loss: 0.6670972705014966
Validation loss: 2.513018990274287

Epoch: 5| Step: 8
Training loss: 1.611742223068511
Validation loss: 2.525286739909665

Epoch: 5| Step: 9
Training loss: 0.6326996031472782
Validation loss: 2.5299676918192264

Epoch: 5| Step: 10
Training loss: 1.0153599906844262
Validation loss: 2.5137819807426807

Epoch: 279| Step: 0
Training loss: 0.9229836667083917
Validation loss: 2.5287241926070543

Epoch: 5| Step: 1
Training loss: 0.8571247811341504
Validation loss: 2.540680209399785

Epoch: 5| Step: 2
Training loss: 0.8026682879863515
Validation loss: 2.5467371890431316

Epoch: 5| Step: 3
Training loss: 0.8527659041219761
Validation loss: 2.5322064398441184

Epoch: 5| Step: 4
Training loss: 0.6948793540841508
Validation loss: 2.5262136353664033

Epoch: 5| Step: 5
Training loss: 0.7316281913845443
Validation loss: 2.521826680993975

Epoch: 5| Step: 6
Training loss: 0.8627964574530663
Validation loss: 2.5167557688236593

Epoch: 5| Step: 7
Training loss: 0.8559454021109982
Validation loss: 2.496756118539298

Epoch: 5| Step: 8
Training loss: 1.9822868714614523
Validation loss: 2.5255010156733233

Epoch: 5| Step: 9
Training loss: 0.78520551688267
Validation loss: 2.5309441697071833

Epoch: 5| Step: 10
Training loss: 0.8430910009452948
Validation loss: 2.5235868604264278

Epoch: 280| Step: 0
Training loss: 0.7228936707488033
Validation loss: 2.537507263897381

Epoch: 5| Step: 1
Training loss: 1.474202525621175
Validation loss: 2.5292092394948416

Epoch: 5| Step: 2
Training loss: 0.9973804017841122
Validation loss: 2.5285903953143425

Epoch: 5| Step: 3
Training loss: 0.5105080003830732
Validation loss: 2.5445069931143385

Epoch: 5| Step: 4
Training loss: 0.8274915899903889
Validation loss: 2.5226546416470947

Epoch: 5| Step: 5
Training loss: 0.86620784100965
Validation loss: 2.511261795491475

Epoch: 5| Step: 6
Training loss: 1.582088516517543
Validation loss: 2.506264478009349

Epoch: 5| Step: 7
Training loss: 0.9519144406478953
Validation loss: 2.499600939536146

Epoch: 5| Step: 8
Training loss: 0.7058793690503856
Validation loss: 2.5167674896519765

Epoch: 5| Step: 9
Training loss: 1.0208903056744603
Validation loss: 2.5425919812434996

Epoch: 5| Step: 10
Training loss: 0.6440400534933309
Validation loss: 2.546271553573971

Epoch: 281| Step: 0
Training loss: 0.8191149371498443
Validation loss: 2.5444628286137134

Epoch: 5| Step: 1
Training loss: 1.015199718933277
Validation loss: 2.543781242774362

Epoch: 5| Step: 2
Training loss: 0.5502699785414259
Validation loss: 2.526519813526811

Epoch: 5| Step: 3
Training loss: 1.3272060131976104
Validation loss: 2.527707179800753

Epoch: 5| Step: 4
Training loss: 0.5959038818270709
Validation loss: 2.5286960638427254

Epoch: 5| Step: 5
Training loss: 0.9563894805908835
Validation loss: 2.535485331271823

Epoch: 5| Step: 6
Training loss: 1.8059731399972032
Validation loss: 2.524605466043412

Epoch: 5| Step: 7
Training loss: 0.7450903091482408
Validation loss: 2.5282691805239894

Epoch: 5| Step: 8
Training loss: 0.5916539135977812
Validation loss: 2.505249379900319

Epoch: 5| Step: 9
Training loss: 0.9960157176849612
Validation loss: 2.5268797505496936

Epoch: 5| Step: 10
Training loss: 0.7092792328708665
Validation loss: 2.5164072823811354

Epoch: 282| Step: 0
Training loss: 0.8946253298132175
Validation loss: 2.5234718519792345

Epoch: 5| Step: 1
Training loss: 0.9900849058367096
Validation loss: 2.5543074390211675

Epoch: 5| Step: 2
Training loss: 0.9703662372150706
Validation loss: 2.530410796625003

Epoch: 5| Step: 3
Training loss: 0.2130393375032775
Validation loss: 2.5335205935738556

Epoch: 5| Step: 4
Training loss: 1.636619983688425
Validation loss: 2.532414929775043

Epoch: 5| Step: 5
Training loss: 0.769548987169673
Validation loss: 2.5278378561042008

Epoch: 5| Step: 6
Training loss: 0.7700552148962778
Validation loss: 2.527933286064686

Epoch: 5| Step: 7
Training loss: 0.8887566159266344
Validation loss: 2.5238835613492063

Epoch: 5| Step: 8
Training loss: 0.9274730434767566
Validation loss: 2.5391956975311385

Epoch: 5| Step: 9
Training loss: 0.6363187130020628
Validation loss: 2.514864196664661

Epoch: 5| Step: 10
Training loss: 1.4273855719992876
Validation loss: 2.510665946194679

Epoch: 283| Step: 0
Training loss: 0.7580531416611077
Validation loss: 2.5029537819810947

Epoch: 5| Step: 1
Training loss: 0.9187412988159863
Validation loss: 2.539098579648925

Epoch: 5| Step: 2
Training loss: 0.7636791336221933
Validation loss: 2.535429792715415

Epoch: 5| Step: 3
Training loss: 0.9586914609621686
Validation loss: 2.529457987781565

Epoch: 5| Step: 4
Training loss: 0.7528811586328569
Validation loss: 2.4976257052813535

Epoch: 5| Step: 5
Training loss: 0.702582892078612
Validation loss: 2.5150351709611405

Epoch: 5| Step: 6
Training loss: 0.835049772834964
Validation loss: 2.5169289333766898

Epoch: 5| Step: 7
Training loss: 1.0186151941894535
Validation loss: 2.506715463221388

Epoch: 5| Step: 8
Training loss: 1.461292325753736
Validation loss: 2.5358836225853767

Epoch: 5| Step: 9
Training loss: 1.3773058716774225
Validation loss: 2.496755602064596

Epoch: 5| Step: 10
Training loss: 0.6836844465852048
Validation loss: 2.524348137932652

Epoch: 284| Step: 0
Training loss: 1.5985898598765407
Validation loss: 2.538309587112473

Epoch: 5| Step: 1
Training loss: 0.9588480617502211
Validation loss: 2.546845820003291

Epoch: 5| Step: 2
Training loss: 0.8016844703127555
Validation loss: 2.560150778397404

Epoch: 5| Step: 3
Training loss: 0.7306326208051658
Validation loss: 2.5830575393532285

Epoch: 5| Step: 4
Training loss: 0.7244019738507986
Validation loss: 2.591701338488964

Epoch: 5| Step: 5
Training loss: 0.8599449348563589
Validation loss: 2.585494734647667

Epoch: 5| Step: 6
Training loss: 0.8649666675584042
Validation loss: 2.5793586024452795

Epoch: 5| Step: 7
Training loss: 0.7048705368685416
Validation loss: 2.5704517129191076

Epoch: 5| Step: 8
Training loss: 1.5193734761288908
Validation loss: 2.5716317213034405

Epoch: 5| Step: 9
Training loss: 0.6263031249060796
Validation loss: 2.5664348749600414

Epoch: 5| Step: 10
Training loss: 0.8520674302187876
Validation loss: 2.553390280451772

Epoch: 285| Step: 0
Training loss: 1.0141105511159243
Validation loss: 2.5553406939691126

Epoch: 5| Step: 1
Training loss: 0.843056464382424
Validation loss: 2.5504095023367905

Epoch: 5| Step: 2
Training loss: 1.2771415433742803
Validation loss: 2.54340865542958

Epoch: 5| Step: 3
Training loss: 0.5713171797133908
Validation loss: 2.56293235690929

Epoch: 5| Step: 4
Training loss: 0.7113683882938787
Validation loss: 2.5355959411640154

Epoch: 5| Step: 5
Training loss: 0.7990154615632151
Validation loss: 2.537623088984621

Epoch: 5| Step: 6
Training loss: 1.4737933800082619
Validation loss: 2.48908002388235

Epoch: 5| Step: 7
Training loss: 1.134366515156774
Validation loss: 2.4752074245767166

Epoch: 5| Step: 8
Training loss: 0.8716523983543117
Validation loss: 2.48112720512041

Epoch: 5| Step: 9
Training loss: 1.0529543729933577
Validation loss: 2.473029652991991

Epoch: 5| Step: 10
Training loss: 0.5584772428641971
Validation loss: 2.508759857463624

Epoch: 286| Step: 0
Training loss: 1.0305736520166013
Validation loss: 2.515491709066099

Epoch: 5| Step: 1
Training loss: 0.7165163827022768
Validation loss: 2.4920357684879524

Epoch: 5| Step: 2
Training loss: 0.752856813854943
Validation loss: 2.534971333742702

Epoch: 5| Step: 3
Training loss: 0.9556966077921786
Validation loss: 2.5344486881999932

Epoch: 5| Step: 4
Training loss: 0.7696196219730497
Validation loss: 2.5316495652184785

Epoch: 5| Step: 5
Training loss: 1.6814188705777513
Validation loss: 2.5443461294671774

Epoch: 5| Step: 6
Training loss: 0.8591237134275844
Validation loss: 2.5400628766287396

Epoch: 5| Step: 7
Training loss: 0.6572569886826695
Validation loss: 2.506201657265332

Epoch: 5| Step: 8
Training loss: 0.6182959296908617
Validation loss: 2.4761095819074477

Epoch: 5| Step: 9
Training loss: 1.3983405734948162
Validation loss: 2.4851553561965654

Epoch: 5| Step: 10
Training loss: 0.9787064478551795
Validation loss: 2.4555089530790872

Epoch: 287| Step: 0
Training loss: 0.8497815538649289
Validation loss: 2.47045594710122

Epoch: 5| Step: 1
Training loss: 0.6910240711927288
Validation loss: 2.484967540377854

Epoch: 5| Step: 2
Training loss: 0.6820858700828786
Validation loss: 2.5134303708888814

Epoch: 5| Step: 3
Training loss: 1.5261877812380964
Validation loss: 2.503112391705793

Epoch: 5| Step: 4
Training loss: 0.8174339287565603
Validation loss: 2.529301838488469

Epoch: 5| Step: 5
Training loss: 0.8294640996429173
Validation loss: 2.5389850412169714

Epoch: 5| Step: 6
Training loss: 1.120212753728926
Validation loss: 2.5660549688894143

Epoch: 5| Step: 7
Training loss: 0.8210345405695908
Validation loss: 2.5584954125228685

Epoch: 5| Step: 8
Training loss: 1.5095817977107078
Validation loss: 2.513343068029455

Epoch: 5| Step: 9
Training loss: 0.7899445994785719
Validation loss: 2.4977220001091354

Epoch: 5| Step: 10
Training loss: 0.9862897808817628
Validation loss: 2.503118450754397

Epoch: 288| Step: 0
Training loss: 0.848445191181652
Validation loss: 2.493098206210999

Epoch: 5| Step: 1
Training loss: 0.7312230993686281
Validation loss: 2.493848618095255

Epoch: 5| Step: 2
Training loss: 0.7177216180274123
Validation loss: 2.4781396435651506

Epoch: 5| Step: 3
Training loss: 0.9964576804347488
Validation loss: 2.512907239202078

Epoch: 5| Step: 4
Training loss: 0.636354189924934
Validation loss: 2.493136358751663

Epoch: 5| Step: 5
Training loss: 1.404933652431233
Validation loss: 2.522024007876271

Epoch: 5| Step: 6
Training loss: 1.517911778596681
Validation loss: 2.513695029201576

Epoch: 5| Step: 7
Training loss: 0.8147319801166171
Validation loss: 2.5484432815195754

Epoch: 5| Step: 8
Training loss: 0.8147669491732891
Validation loss: 2.5450875704928237

Epoch: 5| Step: 9
Training loss: 0.8516053355231255
Validation loss: 2.5460299623708273

Epoch: 5| Step: 10
Training loss: 0.9359988910493232
Validation loss: 2.548455959644608

Epoch: 289| Step: 0
Training loss: 0.8388729783592141
Validation loss: 2.558289979989101

Epoch: 5| Step: 1
Training loss: 0.7129780336904609
Validation loss: 2.535425234552374

Epoch: 5| Step: 2
Training loss: 0.6716715704318461
Validation loss: 2.555248927226318

Epoch: 5| Step: 3
Training loss: 0.7470312968519173
Validation loss: 2.559893426149276

Epoch: 5| Step: 4
Training loss: 0.8792153387171312
Validation loss: 2.5339706042223056

Epoch: 5| Step: 5
Training loss: 0.8052412183460995
Validation loss: 2.5520874632818087

Epoch: 5| Step: 6
Training loss: 0.28179033350616234
Validation loss: 2.5475684950026896

Epoch: 5| Step: 7
Training loss: 1.632771030611249
Validation loss: 2.5386840073754264

Epoch: 5| Step: 8
Training loss: 1.3851214168362125
Validation loss: 2.5001914597076826

Epoch: 5| Step: 9
Training loss: 0.9770514523009627
Validation loss: 2.4955400410626787

Epoch: 5| Step: 10
Training loss: 0.8689140453102134
Validation loss: 2.49526226311543

Epoch: 290| Step: 0
Training loss: 0.5671339424845855
Validation loss: 2.4979293944296366

Epoch: 5| Step: 1
Training loss: 0.8533372146982593
Validation loss: 2.4972951849231384

Epoch: 5| Step: 2
Training loss: 0.7894006136908995
Validation loss: 2.530940375310952

Epoch: 5| Step: 3
Training loss: 0.5164388245250858
Validation loss: 2.501926951056821

Epoch: 5| Step: 4
Training loss: 1.616732325973869
Validation loss: 2.5273321497332812

Epoch: 5| Step: 5
Training loss: 0.7157910849730984
Validation loss: 2.5216170848328114

Epoch: 5| Step: 6
Training loss: 1.283203496599071
Validation loss: 2.506400217873471

Epoch: 5| Step: 7
Training loss: 0.9379622909066776
Validation loss: 2.498237291970413

Epoch: 5| Step: 8
Training loss: 0.697876521042429
Validation loss: 2.487200216605894

Epoch: 5| Step: 9
Training loss: 0.875098052661705
Validation loss: 2.513370781353604

Epoch: 5| Step: 10
Training loss: 0.9825078725620746
Validation loss: 2.4955709509675894

Epoch: 291| Step: 0
Training loss: 1.6054561271078431
Validation loss: 2.511364551892163

Epoch: 5| Step: 1
Training loss: 0.7417677244351512
Validation loss: 2.503387429672433

Epoch: 5| Step: 2
Training loss: 0.8104764609027956
Validation loss: 2.497767041867691

Epoch: 5| Step: 3
Training loss: 0.819906152262789
Validation loss: 2.5099236571817807

Epoch: 5| Step: 4
Training loss: 0.9113412436707304
Validation loss: 2.4944578071511785

Epoch: 5| Step: 5
Training loss: 0.6209805703356264
Validation loss: 2.48096797984527

Epoch: 5| Step: 6
Training loss: 0.573889865241503
Validation loss: 2.482921911915538

Epoch: 5| Step: 7
Training loss: 1.4783809706371498
Validation loss: 2.4986998797279565

Epoch: 5| Step: 8
Training loss: 0.8834176816495168
Validation loss: 2.478604358848362

Epoch: 5| Step: 9
Training loss: 0.48829885832508374
Validation loss: 2.523748563236947

Epoch: 5| Step: 10
Training loss: 0.6182266372418956
Validation loss: 2.4991789607855717

Epoch: 292| Step: 0
Training loss: 0.9249868727087605
Validation loss: 2.4982215051705463

Epoch: 5| Step: 1
Training loss: 1.3800205558821534
Validation loss: 2.508462241005615

Epoch: 5| Step: 2
Training loss: 0.729140190370439
Validation loss: 2.4963882896193175

Epoch: 5| Step: 3
Training loss: 0.7715702057426994
Validation loss: 2.505808227693318

Epoch: 5| Step: 4
Training loss: 0.6379743961380551
Validation loss: 2.4917998337547775

Epoch: 5| Step: 5
Training loss: 0.6901002391967337
Validation loss: 2.5244360376502266

Epoch: 5| Step: 6
Training loss: 0.8895003596493282
Validation loss: 2.5121570301033858

Epoch: 5| Step: 7
Training loss: 0.6588388875966341
Validation loss: 2.5187998198464605

Epoch: 5| Step: 8
Training loss: 0.697221129464268
Validation loss: 2.491894323907294

Epoch: 5| Step: 9
Training loss: 1.6391549927076476
Validation loss: 2.5073107493269506

Epoch: 5| Step: 10
Training loss: 0.4806680653578627
Validation loss: 2.4896412359269546

Epoch: 293| Step: 0
Training loss: 0.9842342094373647
Validation loss: 2.4953501307476436

Epoch: 5| Step: 1
Training loss: 0.6833204758605256
Validation loss: 2.4977194798035307

Epoch: 5| Step: 2
Training loss: 0.5967469622307349
Validation loss: 2.5258955224482316

Epoch: 5| Step: 3
Training loss: 0.7806622010553121
Validation loss: 2.518760042285801

Epoch: 5| Step: 4
Training loss: 0.3544858401232052
Validation loss: 2.51183928641247

Epoch: 5| Step: 5
Training loss: 0.6021605899659738
Validation loss: 2.5312543043806173

Epoch: 5| Step: 6
Training loss: 0.7670606659816244
Validation loss: 2.5102621984174607

Epoch: 5| Step: 7
Training loss: 0.6271465157735125
Validation loss: 2.5005938316915106

Epoch: 5| Step: 8
Training loss: 1.557592237505896
Validation loss: 2.4978526445271436

Epoch: 5| Step: 9
Training loss: 1.580419402169997
Validation loss: 2.4977414429676856

Epoch: 5| Step: 10
Training loss: 0.742197377992448
Validation loss: 2.4951023313679968

Epoch: 294| Step: 0
Training loss: 0.6487653202386823
Validation loss: 2.5067852243043394

Epoch: 5| Step: 1
Training loss: 1.4439012390452663
Validation loss: 2.499973102137753

Epoch: 5| Step: 2
Training loss: 0.9046035477288878
Validation loss: 2.522388848522929

Epoch: 5| Step: 3
Training loss: 0.7263660780674339
Validation loss: 2.503193044675377

Epoch: 5| Step: 4
Training loss: 0.6080653961391843
Validation loss: 2.504337640362144

Epoch: 5| Step: 5
Training loss: 0.9562987969607635
Validation loss: 2.5150729265112397

Epoch: 5| Step: 6
Training loss: 1.4495314597445985
Validation loss: 2.505027891560556

Epoch: 5| Step: 7
Training loss: 0.6210217224197996
Validation loss: 2.4970126366771246

Epoch: 5| Step: 8
Training loss: 0.8409003420147363
Validation loss: 2.505485194122879

Epoch: 5| Step: 9
Training loss: 0.5987097486931047
Validation loss: 2.4708178172772306

Epoch: 5| Step: 10
Training loss: 0.8041190945351976
Validation loss: 2.4812473993795843

Epoch: 295| Step: 0
Training loss: 0.7991939537102196
Validation loss: 2.4858636537190386

Epoch: 5| Step: 1
Training loss: 0.5908502492334854
Validation loss: 2.465986063676191

Epoch: 5| Step: 2
Training loss: 0.9774296077153768
Validation loss: 2.4979497367636694

Epoch: 5| Step: 3
Training loss: 0.5445756530171493
Validation loss: 2.4851348204160306

Epoch: 5| Step: 4
Training loss: 0.8367746386130248
Validation loss: 2.533439636637979

Epoch: 5| Step: 5
Training loss: 0.8280934381768352
Validation loss: 2.519497480752013

Epoch: 5| Step: 6
Training loss: 1.2646286892913943
Validation loss: 2.5363176632816153

Epoch: 5| Step: 7
Training loss: 0.7582030715431379
Validation loss: 2.5791361004740763

Epoch: 5| Step: 8
Training loss: 1.6098095205422873
Validation loss: 2.5505535396774888

Epoch: 5| Step: 9
Training loss: 0.7398900260269538
Validation loss: 2.523845397213712

Epoch: 5| Step: 10
Training loss: 0.6627256737816533
Validation loss: 2.526908215560807

Epoch: 296| Step: 0
Training loss: 0.7845673131564915
Validation loss: 2.5026239463484874

Epoch: 5| Step: 1
Training loss: 0.8103156437869863
Validation loss: 2.4968307372297445

Epoch: 5| Step: 2
Training loss: 0.8100626406761102
Validation loss: 2.505551397062482

Epoch: 5| Step: 3
Training loss: 0.8105862895160915
Validation loss: 2.5072132736790356

Epoch: 5| Step: 4
Training loss: 0.9094523052902991
Validation loss: 2.4832231200524197

Epoch: 5| Step: 5
Training loss: 0.8695851764254252
Validation loss: 2.52146942258024

Epoch: 5| Step: 6
Training loss: 1.5499454427162036
Validation loss: 2.505669371517605

Epoch: 5| Step: 7
Training loss: 1.4008499732873974
Validation loss: 2.541904261508538

Epoch: 5| Step: 8
Training loss: 0.7993057800220477
Validation loss: 2.544581704632497

Epoch: 5| Step: 9
Training loss: 0.6617663009474736
Validation loss: 2.5274311905210687

Epoch: 5| Step: 10
Training loss: 0.6319403112600048
Validation loss: 2.550306517757483

Epoch: 297| Step: 0
Training loss: 1.0382295295686885
Validation loss: 2.525182711459063

Epoch: 5| Step: 1
Training loss: 0.7256353061151131
Validation loss: 2.504432754817188

Epoch: 5| Step: 2
Training loss: 0.6096198494830305
Validation loss: 2.4901345105769908

Epoch: 5| Step: 3
Training loss: 0.720374303719116
Validation loss: 2.4846119740891406

Epoch: 5| Step: 4
Training loss: 0.6117187324611617
Validation loss: 2.501267357524258

Epoch: 5| Step: 5
Training loss: 0.7815657549778492
Validation loss: 2.4925857078197944

Epoch: 5| Step: 6
Training loss: 0.859702134723682
Validation loss: 2.4897742187731926

Epoch: 5| Step: 7
Training loss: 0.8980722763099652
Validation loss: 2.4783356362010975

Epoch: 5| Step: 8
Training loss: 1.8900719456375938
Validation loss: 2.504414414170042

Epoch: 5| Step: 9
Training loss: 0.5992844039580175
Validation loss: 2.479499908935281

Epoch: 5| Step: 10
Training loss: 0.6995559603834368
Validation loss: 2.4911055436764498

Epoch: 298| Step: 0
Training loss: 0.6020942666096153
Validation loss: 2.501819441766493

Epoch: 5| Step: 1
Training loss: 0.8251932539152392
Validation loss: 2.5109141663626113

Epoch: 5| Step: 2
Training loss: 0.44813190508088707
Validation loss: 2.4778016481660377

Epoch: 5| Step: 3
Training loss: 1.6195966678846079
Validation loss: 2.5025073168198513

Epoch: 5| Step: 4
Training loss: 0.660436153324935
Validation loss: 2.472438450995348

Epoch: 5| Step: 5
Training loss: 1.021576040323492
Validation loss: 2.480982831748585

Epoch: 5| Step: 6
Training loss: 0.6042021023015759
Validation loss: 2.507403809411224

Epoch: 5| Step: 7
Training loss: 0.7642458346661734
Validation loss: 2.517662284259873

Epoch: 5| Step: 8
Training loss: 0.9126304428717835
Validation loss: 2.518217865795253

Epoch: 5| Step: 9
Training loss: 1.4311540929652822
Validation loss: 2.513524403849869

Epoch: 5| Step: 10
Training loss: 0.2741323769764424
Validation loss: 2.542184883462879

Epoch: 299| Step: 0
Training loss: 0.7077021919173422
Validation loss: 2.5131802157629357

Epoch: 5| Step: 1
Training loss: 0.6351111308045485
Validation loss: 2.531214310832367

Epoch: 5| Step: 2
Training loss: 0.5058639702901196
Validation loss: 2.505129880821382

Epoch: 5| Step: 3
Training loss: 1.884306319014715
Validation loss: 2.5017677604712922

Epoch: 5| Step: 4
Training loss: 0.993796178356614
Validation loss: 2.4954909346281826

Epoch: 5| Step: 5
Training loss: 0.9535422115534122
Validation loss: 2.4994271678327906

Epoch: 5| Step: 6
Training loss: 0.7748350752421647
Validation loss: 2.511469954016604

Epoch: 5| Step: 7
Training loss: 0.7447882209822616
Validation loss: 2.4694950220004763

Epoch: 5| Step: 8
Training loss: 0.5720683724581147
Validation loss: 2.5017419386372444

Epoch: 5| Step: 9
Training loss: 0.883031935975101
Validation loss: 2.491499388277531

Epoch: 5| Step: 10
Training loss: 0.49181724427378554
Validation loss: 2.5042874140174787

Epoch: 300| Step: 0
Training loss: 0.5506058271536209
Validation loss: 2.484120834824997

Epoch: 5| Step: 1
Training loss: 0.799916353919186
Validation loss: 2.47751003233838

Epoch: 5| Step: 2
Training loss: 1.4746154380825272
Validation loss: 2.4806949299515417

Epoch: 5| Step: 3
Training loss: 1.4502769370178996
Validation loss: 2.4816923160156246

Epoch: 5| Step: 4
Training loss: 0.8085063942424604
Validation loss: 2.482986647356655

Epoch: 5| Step: 5
Training loss: 0.9063305654559487
Validation loss: 2.490407772119732

Epoch: 5| Step: 6
Training loss: 0.6142866312856579
Validation loss: 2.525125816327186

Epoch: 5| Step: 7
Training loss: 0.8166483834873504
Validation loss: 2.511953761968732

Epoch: 5| Step: 8
Training loss: 0.6510952406139078
Validation loss: 2.532618343326775

Epoch: 5| Step: 9
Training loss: 0.7065566772733914
Validation loss: 2.511933381996658

Epoch: 5| Step: 10
Training loss: 1.0116263682484492
Validation loss: 2.509928491472022

Epoch: 301| Step: 0
Training loss: 0.5352392758752132
Validation loss: 2.5206100872148043

Epoch: 5| Step: 1
Training loss: 0.47379407202114787
Validation loss: 2.488252807769901

Epoch: 5| Step: 2
Training loss: 0.7113760968141039
Validation loss: 2.5015010357566627

Epoch: 5| Step: 3
Training loss: 1.5576675454731856
Validation loss: 2.508577935540724

Epoch: 5| Step: 4
Training loss: 0.6346527938331677
Validation loss: 2.499266593782967

Epoch: 5| Step: 5
Training loss: 0.8346187135609062
Validation loss: 2.4891336319524258

Epoch: 5| Step: 6
Training loss: 1.4727268353856526
Validation loss: 2.50737116510769

Epoch: 5| Step: 7
Training loss: 0.8330667705176008
Validation loss: 2.5180464163078238

Epoch: 5| Step: 8
Training loss: 0.695719332026982
Validation loss: 2.505620613495279

Epoch: 5| Step: 9
Training loss: 0.7505330337355185
Validation loss: 2.5313648444440022

Epoch: 5| Step: 10
Training loss: 0.6318857919165706
Validation loss: 2.526788879408037

Epoch: 302| Step: 0
Training loss: 0.7953578119166859
Validation loss: 2.5150957120784376

Epoch: 5| Step: 1
Training loss: 0.8120459608426758
Validation loss: 2.519351708057408

Epoch: 5| Step: 2
Training loss: 0.5398030653554514
Validation loss: 2.5283395687285983

Epoch: 5| Step: 3
Training loss: 1.2683004193456942
Validation loss: 2.4933330279294106

Epoch: 5| Step: 4
Training loss: 0.8340223603006918
Validation loss: 2.4991613909388968

Epoch: 5| Step: 5
Training loss: 0.5774262303552098
Validation loss: 2.4759931136558078

Epoch: 5| Step: 6
Training loss: 0.9336821701762813
Validation loss: 2.486991251343973

Epoch: 5| Step: 7
Training loss: 0.664560647256393
Validation loss: 2.4908738018492596

Epoch: 5| Step: 8
Training loss: 1.4499864215872766
Validation loss: 2.4877797181856183

Epoch: 5| Step: 9
Training loss: 0.7449066544624616
Validation loss: 2.5011718034156893

Epoch: 5| Step: 10
Training loss: 0.5350281777938444
Validation loss: 2.4932012700972006

Epoch: 303| Step: 0
Training loss: 0.7069628561249979
Validation loss: 2.491641586308634

Epoch: 5| Step: 1
Training loss: 0.870104891329451
Validation loss: 2.49837318526484

Epoch: 5| Step: 2
Training loss: 0.5334071233734305
Validation loss: 2.506387956065123

Epoch: 5| Step: 3
Training loss: 1.3400133653942112
Validation loss: 2.5273242031749645

Epoch: 5| Step: 4
Training loss: 0.9083433637735984
Validation loss: 2.488910887150861

Epoch: 5| Step: 5
Training loss: 0.7300290911247286
Validation loss: 2.5011550101553777

Epoch: 5| Step: 6
Training loss: 0.5532390864761475
Validation loss: 2.5266044542036443

Epoch: 5| Step: 7
Training loss: 0.8498933865499141
Validation loss: 2.474666639570079

Epoch: 5| Step: 8
Training loss: 0.6554311912060581
Validation loss: 2.49525618704503

Epoch: 5| Step: 9
Training loss: 0.7132361006052652
Validation loss: 2.5007738802461557

Epoch: 5| Step: 10
Training loss: 1.3835816911099725
Validation loss: 2.4923882545181573

Epoch: 304| Step: 0
Training loss: 0.8059492126773388
Validation loss: 2.5012694714552457

Epoch: 5| Step: 1
Training loss: 1.222045502144842
Validation loss: 2.485418236747141

Epoch: 5| Step: 2
Training loss: 0.6870754621767005
Validation loss: 2.5095351828928396

Epoch: 5| Step: 3
Training loss: 0.6434330919438049
Validation loss: 2.504382206902941

Epoch: 5| Step: 4
Training loss: 0.7583594953474604
Validation loss: 2.483426419176452

Epoch: 5| Step: 5
Training loss: 0.4368441127123665
Validation loss: 2.4831261772716116

Epoch: 5| Step: 6
Training loss: 0.7479722107758794
Validation loss: 2.4745657469958977

Epoch: 5| Step: 7
Training loss: 0.6351760241819244
Validation loss: 2.48707986215589

Epoch: 5| Step: 8
Training loss: 0.6076624844526268
Validation loss: 2.4864030607660834

Epoch: 5| Step: 9
Training loss: 1.5699725945625969
Validation loss: 2.5097691602918624

Epoch: 5| Step: 10
Training loss: 0.9944559133183245
Validation loss: 2.475903294275155

Epoch: 305| Step: 0
Training loss: 0.6683670774781842
Validation loss: 2.516842746530656

Epoch: 5| Step: 1
Training loss: 1.440290810307285
Validation loss: 2.5183237293068124

Epoch: 5| Step: 2
Training loss: 0.6812601858654955
Validation loss: 2.508868026801555

Epoch: 5| Step: 3
Training loss: 0.9584622020044419
Validation loss: 2.512464123835396

Epoch: 5| Step: 4
Training loss: 0.8669918286313566
Validation loss: 2.5094857286883836

Epoch: 5| Step: 5
Training loss: 1.2340842761748099
Validation loss: 2.4921198747751148

Epoch: 5| Step: 6
Training loss: 0.5087921962531702
Validation loss: 2.5252940309789023

Epoch: 5| Step: 7
Training loss: 0.5457887215134307
Validation loss: 2.497380906922856

Epoch: 5| Step: 8
Training loss: 0.6158052490405265
Validation loss: 2.5047101574884354

Epoch: 5| Step: 9
Training loss: 0.8552457266162488
Validation loss: 2.5181860346104092

Epoch: 5| Step: 10
Training loss: 0.8145012052326874
Validation loss: 2.50580905536437

Epoch: 306| Step: 0
Training loss: 1.4997292910120748
Validation loss: 2.490206087881916

Epoch: 5| Step: 1
Training loss: 0.6570198901778582
Validation loss: 2.4927927113584243

Epoch: 5| Step: 2
Training loss: 0.6311959942292309
Validation loss: 2.5124069896614594

Epoch: 5| Step: 3
Training loss: 0.680252673313842
Validation loss: 2.4988973175121507

Epoch: 5| Step: 4
Training loss: 0.5864307870262127
Validation loss: 2.506707364375194

Epoch: 5| Step: 5
Training loss: 0.7998152325765271
Validation loss: 2.4998622856356616

Epoch: 5| Step: 6
Training loss: 0.7575817346698327
Validation loss: 2.492222340323844

Epoch: 5| Step: 7
Training loss: 0.6222523852494573
Validation loss: 2.483137917976797

Epoch: 5| Step: 8
Training loss: 0.6399662538661659
Validation loss: 2.461553565445919

Epoch: 5| Step: 9
Training loss: 1.4007631708139026
Validation loss: 2.483159977591669

Epoch: 5| Step: 10
Training loss: 0.6266970482860961
Validation loss: 2.4707140583336464

Epoch: 307| Step: 0
Training loss: 0.9335156651486582
Validation loss: 2.504802406355978

Epoch: 5| Step: 1
Training loss: 0.734403000967381
Validation loss: 2.4851799438232987

Epoch: 5| Step: 2
Training loss: 1.452643201797508
Validation loss: 2.4990208072013202

Epoch: 5| Step: 3
Training loss: 0.45406497274671953
Validation loss: 2.4849561074997917

Epoch: 5| Step: 4
Training loss: 0.5472743892035975
Validation loss: 2.47190923590729

Epoch: 5| Step: 5
Training loss: 0.725156592854158
Validation loss: 2.492376469957648

Epoch: 5| Step: 6
Training loss: 0.3878396099614355
Validation loss: 2.470161755007218

Epoch: 5| Step: 7
Training loss: 1.2990140165229112
Validation loss: 2.480870597598863

Epoch: 5| Step: 8
Training loss: 0.6995357455513239
Validation loss: 2.4981291708142934

Epoch: 5| Step: 9
Training loss: 0.7522944876921575
Validation loss: 2.4947086696951457

Epoch: 5| Step: 10
Training loss: 0.4743522921066419
Validation loss: 2.475034778819216

Epoch: 308| Step: 0
Training loss: 0.5374741304071607
Validation loss: 2.489529385168622

Epoch: 5| Step: 1
Training loss: 0.47208979057055095
Validation loss: 2.495879697193569

Epoch: 5| Step: 2
Training loss: 0.7704127341280629
Validation loss: 2.4702933552114636

Epoch: 5| Step: 3
Training loss: 0.6876401541641393
Validation loss: 2.4779804663409615

Epoch: 5| Step: 4
Training loss: 0.28893817341499317
Validation loss: 2.4886259061570932

Epoch: 5| Step: 5
Training loss: 0.7593002659321307
Validation loss: 2.480921023665535

Epoch: 5| Step: 6
Training loss: 0.5200571825608096
Validation loss: 2.494249245385382

Epoch: 5| Step: 7
Training loss: 1.2985556868876444
Validation loss: 2.491102723892545

Epoch: 5| Step: 8
Training loss: 1.5404053846831252
Validation loss: 2.4790439127224047

Epoch: 5| Step: 9
Training loss: 0.8987152002147034
Validation loss: 2.4693127083394217

Epoch: 5| Step: 10
Training loss: 0.44730035572054916
Validation loss: 2.47617082211649

Epoch: 309| Step: 0
Training loss: 0.46495534054299803
Validation loss: 2.4458314754504675

Epoch: 5| Step: 1
Training loss: 0.4303420716418421
Validation loss: 2.4604482721472625

Epoch: 5| Step: 2
Training loss: 0.8606105938428056
Validation loss: 2.449110088871078

Epoch: 5| Step: 3
Training loss: 0.30501721954984146
Validation loss: 2.4607499631441

Epoch: 5| Step: 4
Training loss: 1.5693951864398918
Validation loss: 2.431873126807642

Epoch: 5| Step: 5
Training loss: 0.7053511664152895
Validation loss: 2.458245023625912

Epoch: 5| Step: 6
Training loss: 0.8618320366411912
Validation loss: 2.4304505338309967

Epoch: 5| Step: 7
Training loss: 0.46476381079338436
Validation loss: 2.447050114463227

Epoch: 5| Step: 8
Training loss: 0.25185265127190964
Validation loss: 2.4523184622007155

Epoch: 5| Step: 9
Training loss: 0.80886648250193
Validation loss: 2.4606282211897286

Epoch: 5| Step: 10
Training loss: 1.4300680852567296
Validation loss: 2.4145465846936482

Epoch: 310| Step: 0
Training loss: 0.9032895964477903
Validation loss: 2.4403430837821487

Epoch: 5| Step: 1
Training loss: 1.2809616322604531
Validation loss: 2.411489844534367

Epoch: 5| Step: 2
Training loss: 0.579904292612359
Validation loss: 2.4381012029209086

Epoch: 5| Step: 3
Training loss: 1.4855857328458058
Validation loss: 2.466540185478731

Epoch: 5| Step: 4
Training loss: 0.6321627495409072
Validation loss: 2.4626575048769594

Epoch: 5| Step: 5
Training loss: 0.7995076542023302
Validation loss: 2.464804775723683

Epoch: 5| Step: 6
Training loss: 0.353209874409916
Validation loss: 2.4704804488373706

Epoch: 5| Step: 7
Training loss: 0.5632087692631955
Validation loss: 2.4647584264025304

Epoch: 5| Step: 8
Training loss: 0.8417771197698242
Validation loss: 2.4664969952415348

Epoch: 5| Step: 9
Training loss: 0.871690964502977
Validation loss: 2.4460674662758883

Epoch: 5| Step: 10
Training loss: 0.5016275084485345
Validation loss: 2.4539297934067386

Epoch: 311| Step: 0
Training loss: 0.5480370301105351
Validation loss: 2.4628728837134304

Epoch: 5| Step: 1
Training loss: 0.7246297334756934
Validation loss: 2.4732748719421873

Epoch: 5| Step: 2
Training loss: 0.7342525948312049
Validation loss: 2.490560242035704

Epoch: 5| Step: 3
Training loss: 0.7606467112418008
Validation loss: 2.4961383415107434

Epoch: 5| Step: 4
Training loss: 1.2350943678350597
Validation loss: 2.4826071355500394

Epoch: 5| Step: 5
Training loss: 0.797932278718596
Validation loss: 2.4796534041761

Epoch: 5| Step: 6
Training loss: 0.8091803371860512
Validation loss: 2.467175346659995

Epoch: 5| Step: 7
Training loss: 0.514520792178612
Validation loss: 2.5026593594642588

Epoch: 5| Step: 8
Training loss: 0.6990804695340238
Validation loss: 2.505407666253462

Epoch: 5| Step: 9
Training loss: 1.5096348635563
Validation loss: 2.4972769781790944

Epoch: 5| Step: 10
Training loss: 0.5520681403126876
Validation loss: 2.46552409310214

Epoch: 312| Step: 0
Training loss: 0.5726002310588183
Validation loss: 2.467613421725177

Epoch: 5| Step: 1
Training loss: 0.9306036978615561
Validation loss: 2.5017767432529157

Epoch: 5| Step: 2
Training loss: 0.8612651153146049
Validation loss: 2.4931526795480923

Epoch: 5| Step: 3
Training loss: 0.6267389424812795
Validation loss: 2.474922898513674

Epoch: 5| Step: 4
Training loss: 0.5547064657058323
Validation loss: 2.4685510804720696

Epoch: 5| Step: 5
Training loss: 0.7908275993013341
Validation loss: 2.5002309097791056

Epoch: 5| Step: 6
Training loss: 0.8056503757123415
Validation loss: 2.4995345430944425

Epoch: 5| Step: 7
Training loss: 0.4970601948306078
Validation loss: 2.503607157516154

Epoch: 5| Step: 8
Training loss: 0.9181530706530351
Validation loss: 2.4757376613481763

Epoch: 5| Step: 9
Training loss: 1.5066140110947874
Validation loss: 2.4715879560901635

Epoch: 5| Step: 10
Training loss: 0.5799100998560899
Validation loss: 2.4755993335873794

Epoch: 313| Step: 0
Training loss: 0.6658043400400421
Validation loss: 2.4431468289216123

Epoch: 5| Step: 1
Training loss: 0.8104129542745437
Validation loss: 2.4777131059572426

Epoch: 5| Step: 2
Training loss: 0.8604113139123805
Validation loss: 2.471221548555455

Epoch: 5| Step: 3
Training loss: 0.7191013223909907
Validation loss: 2.5128226855251348

Epoch: 5| Step: 4
Training loss: 0.39987068842799023
Validation loss: 2.5260213235624374

Epoch: 5| Step: 5
Training loss: 0.680496917737249
Validation loss: 2.5201763075514436

Epoch: 5| Step: 6
Training loss: 0.7010535350170919
Validation loss: 2.549127913626264

Epoch: 5| Step: 7
Training loss: 0.9513719728146274
Validation loss: 2.5591296008958633

Epoch: 5| Step: 8
Training loss: 0.6361606468831651
Validation loss: 2.5468610074536953

Epoch: 5| Step: 9
Training loss: 1.3896904280236881
Validation loss: 2.536703965337309

Epoch: 5| Step: 10
Training loss: 1.0250574351710615
Validation loss: 2.5313355798406896

Epoch: 314| Step: 0
Training loss: 0.6224771364065448
Validation loss: 2.5206004301025886

Epoch: 5| Step: 1
Training loss: 0.6954209746708655
Validation loss: 2.507238724235653

Epoch: 5| Step: 2
Training loss: 0.6257931206919098
Validation loss: 2.4983239544296176

Epoch: 5| Step: 3
Training loss: 0.8206354141446147
Validation loss: 2.470562470097431

Epoch: 5| Step: 4
Training loss: 0.9520542822035973
Validation loss: 2.4892295214937032

Epoch: 5| Step: 5
Training loss: 0.8331930439800144
Validation loss: 2.450564207678494

Epoch: 5| Step: 6
Training loss: 0.6733256802580355
Validation loss: 2.452805183108365

Epoch: 5| Step: 7
Training loss: 1.3990537681417872
Validation loss: 2.4218319849699053

Epoch: 5| Step: 8
Training loss: 0.6498388750939528
Validation loss: 2.4047924987137854

Epoch: 5| Step: 9
Training loss: 0.7339827118794356
Validation loss: 2.416391910985082

Epoch: 5| Step: 10
Training loss: 0.6891040945149842
Validation loss: 2.4441965972037907

Epoch: 315| Step: 0
Training loss: 1.0528792527534205
Validation loss: 2.423555240505628

Epoch: 5| Step: 1
Training loss: 0.6223961951176271
Validation loss: 2.4328856796306235

Epoch: 5| Step: 2
Training loss: 0.6994830223501762
Validation loss: 2.4357841795747635

Epoch: 5| Step: 3
Training loss: 1.3573400239486026
Validation loss: 2.4487864634930943

Epoch: 5| Step: 4
Training loss: 0.7223824884620946
Validation loss: 2.442849588056513

Epoch: 5| Step: 5
Training loss: 0.6031955993918067
Validation loss: 2.4693604557373763

Epoch: 5| Step: 6
Training loss: 0.6076368092698129
Validation loss: 2.4381095696177097

Epoch: 5| Step: 7
Training loss: 0.534237148953268
Validation loss: 2.4383836548041202

Epoch: 5| Step: 8
Training loss: 0.7938162498160295
Validation loss: 2.450903930060119

Epoch: 5| Step: 9
Training loss: 0.900409756206901
Validation loss: 2.452179447950486

Epoch: 5| Step: 10
Training loss: 0.6455943962812962
Validation loss: 2.4396293984530324

Epoch: 316| Step: 0
Training loss: 0.5856110998842948
Validation loss: 2.4635522507399834

Epoch: 5| Step: 1
Training loss: 1.3556542173466979
Validation loss: 2.4481156714473653

Epoch: 5| Step: 2
Training loss: 0.602159228925737
Validation loss: 2.4644560672752323

Epoch: 5| Step: 3
Training loss: 0.7973149898783521
Validation loss: 2.4821337362776394

Epoch: 5| Step: 4
Training loss: 1.0219558007262353
Validation loss: 2.4647722516177697

Epoch: 5| Step: 5
Training loss: 0.6579453051105839
Validation loss: 2.4814958064369126

Epoch: 5| Step: 6
Training loss: 0.5654604150727545
Validation loss: 2.450130978821488

Epoch: 5| Step: 7
Training loss: 0.6961902692777222
Validation loss: 2.450476363044035

Epoch: 5| Step: 8
Training loss: 0.9216763557168536
Validation loss: 2.4520380671401645

Epoch: 5| Step: 9
Training loss: 0.3262317511142735
Validation loss: 2.4469645229616335

Epoch: 5| Step: 10
Training loss: 0.4499101873682469
Validation loss: 2.441163596812227

Epoch: 317| Step: 0
Training loss: 0.8230116986478048
Validation loss: 2.448881465171872

Epoch: 5| Step: 1
Training loss: 0.640833309080159
Validation loss: 2.4298414852813064

Epoch: 5| Step: 2
Training loss: 1.0987565034537161
Validation loss: 2.450857926635862

Epoch: 5| Step: 3
Training loss: 0.4809451029116465
Validation loss: 2.406730607055199

Epoch: 5| Step: 4
Training loss: 0.6016784902936049
Validation loss: 2.4545942841286363

Epoch: 5| Step: 5
Training loss: 0.42495626617257015
Validation loss: 2.46066681779092

Epoch: 5| Step: 6
Training loss: 1.4242654346006725
Validation loss: 2.4582775720397545

Epoch: 5| Step: 7
Training loss: 0.5471610547292206
Validation loss: 2.445055336383784

Epoch: 5| Step: 8
Training loss: 0.4403928584836823
Validation loss: 2.4633554461383347

Epoch: 5| Step: 9
Training loss: 0.6309415214603133
Validation loss: 2.4705630179897113

Epoch: 5| Step: 10
Training loss: 0.8321540276288114
Validation loss: 2.436727636501555

Epoch: 318| Step: 0
Training loss: 0.6031390746851159
Validation loss: 2.4564449015569125

Epoch: 5| Step: 1
Training loss: 0.5951262385422162
Validation loss: 2.4508051502933865

Epoch: 5| Step: 2
Training loss: 0.6274017440194043
Validation loss: 2.450020412940145

Epoch: 5| Step: 3
Training loss: 1.042534612817447
Validation loss: 2.406555896796862

Epoch: 5| Step: 4
Training loss: 1.3608588089731792
Validation loss: 2.4231958551162402

Epoch: 5| Step: 5
Training loss: 0.737642122572557
Validation loss: 2.419308919163201

Epoch: 5| Step: 6
Training loss: 0.6238291263273703
Validation loss: 2.416866810997015

Epoch: 5| Step: 7
Training loss: 0.43451354266769965
Validation loss: 2.4536334596972584

Epoch: 5| Step: 8
Training loss: 0.6982371296732789
Validation loss: 2.461830907519166

Epoch: 5| Step: 9
Training loss: 0.6167764622872162
Validation loss: 2.456306763759462

Epoch: 5| Step: 10
Training loss: 0.5877729025548236
Validation loss: 2.431815535024411

Epoch: 319| Step: 0
Training loss: 0.7546088546939126
Validation loss: 2.433942176080089

Epoch: 5| Step: 1
Training loss: 1.2300461785246521
Validation loss: 2.4092228975694985

Epoch: 5| Step: 2
Training loss: 0.7927727668498102
Validation loss: 2.4198433517514535

Epoch: 5| Step: 3
Training loss: 1.0768647499061588
Validation loss: 2.4036999665038685

Epoch: 5| Step: 4
Training loss: 0.7030368961660791
Validation loss: 2.424119585739994

Epoch: 5| Step: 5
Training loss: 0.3940251758817323
Validation loss: 2.4223484070161425

Epoch: 5| Step: 6
Training loss: 0.42016330254857465
Validation loss: 2.4401165622890963

Epoch: 5| Step: 7
Training loss: 0.561619440247767
Validation loss: 2.4386438610207435

Epoch: 5| Step: 8
Training loss: 0.4440514964083317
Validation loss: 2.425796771626096

Epoch: 5| Step: 9
Training loss: 0.8232017136078655
Validation loss: 2.4508415877857925

Epoch: 5| Step: 10
Training loss: 0.644245569900007
Validation loss: 2.447087059920867

Epoch: 320| Step: 0
Training loss: 1.4103647854539996
Validation loss: 2.4704239802005756

Epoch: 5| Step: 1
Training loss: 0.5824244150557927
Validation loss: 2.4756773413666857

Epoch: 5| Step: 2
Training loss: 0.9400848358505691
Validation loss: 2.4836940491289794

Epoch: 5| Step: 3
Training loss: 0.5979739074245392
Validation loss: 2.4921853243602015

Epoch: 5| Step: 4
Training loss: 0.7583014100729846
Validation loss: 2.4964827847827142

Epoch: 5| Step: 5
Training loss: 0.8328718497079179
Validation loss: 2.470109712848457

Epoch: 5| Step: 6
Training loss: 0.5034093846829671
Validation loss: 2.4610091743768083

Epoch: 5| Step: 7
Training loss: 0.6875094066323139
Validation loss: 2.458773768706141

Epoch: 5| Step: 8
Training loss: 0.6123575677502656
Validation loss: 2.470391163750069

Epoch: 5| Step: 9
Training loss: 0.5932344155641753
Validation loss: 2.455737423543899

Epoch: 5| Step: 10
Training loss: 0.8589097584317414
Validation loss: 2.4974505509940848

Epoch: 321| Step: 0
Training loss: 0.578565429769093
Validation loss: 2.444990193256556

Epoch: 5| Step: 1
Training loss: 0.6274462985430621
Validation loss: 2.4438347978757564

Epoch: 5| Step: 2
Training loss: 1.3852487428856008
Validation loss: 2.441519173715723

Epoch: 5| Step: 3
Training loss: 0.6461862066646893
Validation loss: 2.4730599724431075

Epoch: 5| Step: 4
Training loss: 0.964164402057051
Validation loss: 2.445764467291795

Epoch: 5| Step: 5
Training loss: 0.6111146596844073
Validation loss: 2.4807099297199766

Epoch: 5| Step: 6
Training loss: 0.7834072845803965
Validation loss: 2.4256206375592138

Epoch: 5| Step: 7
Training loss: 0.6049252932113364
Validation loss: 2.4557668864640507

Epoch: 5| Step: 8
Training loss: 0.9482184582932246
Validation loss: 2.426813368236591

Epoch: 5| Step: 9
Training loss: 0.42587681668999466
Validation loss: 2.4578224709453167

Epoch: 5| Step: 10
Training loss: 0.8542969224438787
Validation loss: 2.470760375826878

Epoch: 322| Step: 0
Training loss: 0.7603967785956159
Validation loss: 2.522378982752895

Epoch: 5| Step: 1
Training loss: 1.2779827794271443
Validation loss: 2.539391119478673

Epoch: 5| Step: 2
Training loss: 0.7435218060264506
Validation loss: 2.5243997606254074

Epoch: 5| Step: 3
Training loss: 0.6395931540324407
Validation loss: 2.526929135216995

Epoch: 5| Step: 4
Training loss: 0.4950278538275028
Validation loss: 2.4891756034243606

Epoch: 5| Step: 5
Training loss: 0.49838631226594055
Validation loss: 2.486846037019529

Epoch: 5| Step: 6
Training loss: 0.8085614995007393
Validation loss: 2.4910250921356574

Epoch: 5| Step: 7
Training loss: 0.8967675653103355
Validation loss: 2.4490652063534455

Epoch: 5| Step: 8
Training loss: 0.7343141652334385
Validation loss: 2.4330665250218173

Epoch: 5| Step: 9
Training loss: 0.7826488179078446
Validation loss: 2.430969609055143

Epoch: 5| Step: 10
Training loss: 0.661488965343958
Validation loss: 2.4301889165488335

Epoch: 323| Step: 0
Training loss: 0.7410660955266729
Validation loss: 2.457541042094449

Epoch: 5| Step: 1
Training loss: 0.7901224250335087
Validation loss: 2.4732222085701774

Epoch: 5| Step: 2
Training loss: 0.500046131866907
Validation loss: 2.427200694448261

Epoch: 5| Step: 3
Training loss: 0.6385834658965801
Validation loss: 2.4615876947877373

Epoch: 5| Step: 4
Training loss: 0.7297499276684225
Validation loss: 2.46042912537464

Epoch: 5| Step: 5
Training loss: 0.7805472073913666
Validation loss: 2.4826742397523858

Epoch: 5| Step: 6
Training loss: 0.6402507479647283
Validation loss: 2.46204414806124

Epoch: 5| Step: 7
Training loss: 0.702691241091438
Validation loss: 2.4525183690559915

Epoch: 5| Step: 8
Training loss: 0.621475198559296
Validation loss: 2.4139829333720617

Epoch: 5| Step: 9
Training loss: 0.7019518708402015
Validation loss: 2.396598404493499

Epoch: 5| Step: 10
Training loss: 1.38912149653752
Validation loss: 2.428553609684846

Epoch: 324| Step: 0
Training loss: 0.6827733593858903
Validation loss: 2.430029338668168

Epoch: 5| Step: 1
Training loss: 0.7100372483328466
Validation loss: 2.442768291308903

Epoch: 5| Step: 2
Training loss: 0.524919518478107
Validation loss: 2.4624222846391146

Epoch: 5| Step: 3
Training loss: 0.651138700247725
Validation loss: 2.472196576849334

Epoch: 5| Step: 4
Training loss: 0.7521734534149798
Validation loss: 2.463100440058614

Epoch: 5| Step: 5
Training loss: 0.7517423656419764
Validation loss: 2.4586005826012913

Epoch: 5| Step: 6
Training loss: 0.6604902336790457
Validation loss: 2.470039964216173

Epoch: 5| Step: 7
Training loss: 1.2699217210509655
Validation loss: 2.424881225322656

Epoch: 5| Step: 8
Training loss: 0.5004551723042574
Validation loss: 2.3976323083311004

Epoch: 5| Step: 9
Training loss: 0.5054094825206785
Validation loss: 2.4017542602268467

Epoch: 5| Step: 10
Training loss: 0.642971926897991
Validation loss: 2.387682505511039

Epoch: 325| Step: 0
Training loss: 0.689490168713694
Validation loss: 2.3840644246768163

Epoch: 5| Step: 1
Training loss: 0.5976331868427772
Validation loss: 2.4211013590362516

Epoch: 5| Step: 2
Training loss: 1.1607499064754174
Validation loss: 2.390246140970633

Epoch: 5| Step: 3
Training loss: 0.6813294976772517
Validation loss: 2.407215894602949

Epoch: 5| Step: 4
Training loss: 0.43907568087087095
Validation loss: 2.4267305507429757

Epoch: 5| Step: 5
Training loss: 0.8162854483999459
Validation loss: 2.41599997580711

Epoch: 5| Step: 6
Training loss: 0.37488212322248454
Validation loss: 2.3634232228489234

Epoch: 5| Step: 7
Training loss: 0.7641656162444715
Validation loss: 2.376417078373078

Epoch: 5| Step: 8
Training loss: 0.8567027071658353
Validation loss: 2.407241671279591

Epoch: 5| Step: 9
Training loss: 0.5709996721296822
Validation loss: 2.3883817408973727

Epoch: 5| Step: 10
Training loss: 0.7783190489104196
Validation loss: 2.374473497226946

Epoch: 326| Step: 0
Training loss: 0.49822052564976305
Validation loss: 2.379540556790212

Epoch: 5| Step: 1
Training loss: 0.6807943955457479
Validation loss: 2.4030227921991583

Epoch: 5| Step: 2
Training loss: 0.6779617016266124
Validation loss: 2.3868920230591666

Epoch: 5| Step: 3
Training loss: 1.18239933593561
Validation loss: 2.4406476223897298

Epoch: 5| Step: 4
Training loss: 0.636298924684133
Validation loss: 2.394973674129985

Epoch: 5| Step: 5
Training loss: 0.5441806085688421
Validation loss: 2.432649106635716

Epoch: 5| Step: 6
Training loss: 0.6232989288676456
Validation loss: 2.449897245203177

Epoch: 5| Step: 7
Training loss: 0.821433400501249
Validation loss: 2.4548838768112615

Epoch: 5| Step: 8
Training loss: 0.6996170273558799
Validation loss: 2.471154604346803

Epoch: 5| Step: 9
Training loss: 0.3436732856806519
Validation loss: 2.494578454624876

Epoch: 5| Step: 10
Training loss: 0.7010385285562807
Validation loss: 2.467811161925207

Epoch: 327| Step: 0
Training loss: 0.5753415865696621
Validation loss: 2.445526882119075

Epoch: 5| Step: 1
Training loss: 1.1795380352399658
Validation loss: 2.436433728754577

Epoch: 5| Step: 2
Training loss: 0.6103723629268167
Validation loss: 2.429722127069884

Epoch: 5| Step: 3
Training loss: 0.5929864189722053
Validation loss: 2.431903034865107

Epoch: 5| Step: 4
Training loss: 0.5867824311625188
Validation loss: 2.416998434861455

Epoch: 5| Step: 5
Training loss: 0.4100627065889745
Validation loss: 2.424211335390698

Epoch: 5| Step: 6
Training loss: 0.30067605495139355
Validation loss: 2.3968336413105322

Epoch: 5| Step: 7
Training loss: 0.5133066365599066
Validation loss: 2.427154025233496

Epoch: 5| Step: 8
Training loss: 0.7874879896671022
Validation loss: 2.4212172648162396

Epoch: 5| Step: 9
Training loss: 0.8578375501744598
Validation loss: 2.406290857026528

Epoch: 5| Step: 10
Training loss: 0.5251315587829837
Validation loss: 2.431099702208124

Epoch: 328| Step: 0
Training loss: 0.6385601074227693
Validation loss: 2.4284842166905896

Epoch: 5| Step: 1
Training loss: 0.36233516266760796
Validation loss: 2.4461306743317697

Epoch: 5| Step: 2
Training loss: 0.618065993498292
Validation loss: 2.436732691756928

Epoch: 5| Step: 3
Training loss: 1.1873984544403107
Validation loss: 2.440721201352108

Epoch: 5| Step: 4
Training loss: 0.6161409026910923
Validation loss: 2.4444448234359557

Epoch: 5| Step: 5
Training loss: 0.5168199564305576
Validation loss: 2.427605237270041

Epoch: 5| Step: 6
Training loss: 0.6363965020579336
Validation loss: 2.447833642924041

Epoch: 5| Step: 7
Training loss: 0.7578859195340982
Validation loss: 2.4558165862676655

Epoch: 5| Step: 8
Training loss: 0.3423614199320802
Validation loss: 2.4482588546946533

Epoch: 5| Step: 9
Training loss: 0.7852609289429553
Validation loss: 2.4507638491413584

Epoch: 5| Step: 10
Training loss: 0.22350090001018924
Validation loss: 2.4298436149290166

Epoch: 329| Step: 0
Training loss: 0.48502507732389366
Validation loss: 2.4234695039041565

Epoch: 5| Step: 1
Training loss: 0.5227118059177025
Validation loss: 2.439227802035375

Epoch: 5| Step: 2
Training loss: 0.6114494276508394
Validation loss: 2.425958136967327

Epoch: 5| Step: 3
Training loss: 1.0363420711978
Validation loss: 2.4173927856999224

Epoch: 5| Step: 4
Training loss: 0.6986011356107544
Validation loss: 2.4212990945724284

Epoch: 5| Step: 5
Training loss: 0.5451960267118786
Validation loss: 2.4079115518888616

Epoch: 5| Step: 6
Training loss: 0.7220132802655937
Validation loss: 2.439613756243177

Epoch: 5| Step: 7
Training loss: 0.6057741440933564
Validation loss: 2.3948442133839865

Epoch: 5| Step: 8
Training loss: 0.6062843981550474
Validation loss: 2.4034627649777054

Epoch: 5| Step: 9
Training loss: 0.45879569538075105
Validation loss: 2.425726520336467

Epoch: 5| Step: 10
Training loss: 0.6917468595168085
Validation loss: 2.428795106612396

Epoch: 330| Step: 0
Training loss: 1.1330364137540232
Validation loss: 2.4084951492513422

Epoch: 5| Step: 1
Training loss: 0.4503413561351762
Validation loss: 2.424256306870229

Epoch: 5| Step: 2
Training loss: 0.6169664977142258
Validation loss: 2.40984679111301

Epoch: 5| Step: 3
Training loss: 0.5013948594152007
Validation loss: 2.4360368811042177

Epoch: 5| Step: 4
Training loss: 0.5978145015860519
Validation loss: 2.4062629233776214

Epoch: 5| Step: 5
Training loss: 0.4183694042211124
Validation loss: 2.413506196570814

Epoch: 5| Step: 6
Training loss: 0.5574862832575841
Validation loss: 2.4043841282648857

Epoch: 5| Step: 7
Training loss: 0.4589131076756248
Validation loss: 2.410112777974466

Epoch: 5| Step: 8
Training loss: 0.6703424051367418
Validation loss: 2.445901395596976

Epoch: 5| Step: 9
Training loss: 0.6506666680221024
Validation loss: 2.41519134504329

Epoch: 5| Step: 10
Training loss: 0.6710720365162343
Validation loss: 2.4088594159327115

Epoch: 331| Step: 0
Training loss: 0.34536048374533934
Validation loss: 2.427716503516918

Epoch: 5| Step: 1
Training loss: 0.45952073270350974
Validation loss: 2.4042593887587094

Epoch: 5| Step: 2
Training loss: 0.4974644265803241
Validation loss: 2.392849318416348

Epoch: 5| Step: 3
Training loss: 0.6287313182474661
Validation loss: 2.4161848580519534

Epoch: 5| Step: 4
Training loss: 1.0633715252808862
Validation loss: 2.4281184317286866

Epoch: 5| Step: 5
Training loss: 0.5595775290884318
Validation loss: 2.394946381338236

Epoch: 5| Step: 6
Training loss: 0.6659260127393868
Validation loss: 2.4122623940593626

Epoch: 5| Step: 7
Training loss: 0.6128854142326741
Validation loss: 2.406050941385103

Epoch: 5| Step: 8
Training loss: 0.655855219034338
Validation loss: 2.3915385839009264

Epoch: 5| Step: 9
Training loss: 0.5829125970376184
Validation loss: 2.4192839073906014

Epoch: 5| Step: 10
Training loss: 0.5876298497139256
Validation loss: 2.4258887653680556

Epoch: 332| Step: 0
Training loss: 0.9486075423269565
Validation loss: 2.4340454908487947

Epoch: 5| Step: 1
Training loss: 0.7593793499982909
Validation loss: 2.4384357106746672

Epoch: 5| Step: 2
Training loss: 0.5762794782086821
Validation loss: 2.401137720411622

Epoch: 5| Step: 3
Training loss: 0.5270739960377426
Validation loss: 2.4189179966088648

Epoch: 5| Step: 4
Training loss: 0.4917106589205299
Validation loss: 2.4253702643668182

Epoch: 5| Step: 5
Training loss: 0.4589780441821537
Validation loss: 2.40502347291766

Epoch: 5| Step: 6
Training loss: 0.6780650187039561
Validation loss: 2.4099703872140217

Epoch: 5| Step: 7
Training loss: 0.5061240074767906
Validation loss: 2.4050781002278283

Epoch: 5| Step: 8
Training loss: 0.6704193359102164
Validation loss: 2.3915280598820017

Epoch: 5| Step: 9
Training loss: 0.40299540587970556
Validation loss: 2.390034507431213

Epoch: 5| Step: 10
Training loss: 0.6620609412018748
Validation loss: 2.3788210501336704

Epoch: 333| Step: 0
Training loss: 0.4400802545616164
Validation loss: 2.39028612448534

Epoch: 5| Step: 1
Training loss: 0.385916330166179
Validation loss: 2.418988748731299

Epoch: 5| Step: 2
Training loss: 0.986065245995981
Validation loss: 2.3758194162350743

Epoch: 5| Step: 3
Training loss: 0.6655584427416777
Validation loss: 2.4059561805875815

Epoch: 5| Step: 4
Training loss: 0.5785636268910518
Validation loss: 2.4084417926823503

Epoch: 5| Step: 5
Training loss: 0.5658814992006886
Validation loss: 2.396354201000395

Epoch: 5| Step: 6
Training loss: 0.604632261251965
Validation loss: 2.417435888203451

Epoch: 5| Step: 7
Training loss: 0.6268988137176603
Validation loss: 2.4222291547873565

Epoch: 5| Step: 8
Training loss: 0.4612778037822258
Validation loss: 2.4128231057285547

Epoch: 5| Step: 9
Training loss: 0.7704416689023051
Validation loss: 2.4412656262004053

Epoch: 5| Step: 10
Training loss: 0.44817469801444404
Validation loss: 2.437838154662642

Epoch: 334| Step: 0
Training loss: 0.6567181325324616
Validation loss: 2.4428935636785845

Epoch: 5| Step: 1
Training loss: 0.45329005425156443
Validation loss: 2.4275961854331367

Epoch: 5| Step: 2
Training loss: 0.4578821786707758
Validation loss: 2.447117048132054

Epoch: 5| Step: 3
Training loss: 0.4492758009798317
Validation loss: 2.440769302202787

Epoch: 5| Step: 4
Training loss: 0.5839974902667373
Validation loss: 2.4270309677787893

Epoch: 5| Step: 5
Training loss: 0.8037776061874548
Validation loss: 2.446023775149988

Epoch: 5| Step: 6
Training loss: 0.3102662239835438
Validation loss: 2.423529479461655

Epoch: 5| Step: 7
Training loss: 0.5047775247313941
Validation loss: 2.4633212465827325

Epoch: 5| Step: 8
Training loss: 1.0648810130349315
Validation loss: 2.4586570141501634

Epoch: 5| Step: 9
Training loss: 0.5433685696863969
Validation loss: 2.4348150299880316

Epoch: 5| Step: 10
Training loss: 0.4769594696647673
Validation loss: 2.434512777414422

Epoch: 335| Step: 0
Training loss: 0.41349162928862326
Validation loss: 2.4354047138981834

Epoch: 5| Step: 1
Training loss: 0.46400545970606766
Validation loss: 2.440036497785363

Epoch: 5| Step: 2
Training loss: 0.6822750341897283
Validation loss: 2.406447450558944

Epoch: 5| Step: 3
Training loss: 0.6219697927947215
Validation loss: 2.4153849771232

Epoch: 5| Step: 4
Training loss: 0.9986095298173316
Validation loss: 2.444461561618821

Epoch: 5| Step: 5
Training loss: 0.7161930045573724
Validation loss: 2.41797246668796

Epoch: 5| Step: 6
Training loss: 0.5138373452905476
Validation loss: 2.393856336016609

Epoch: 5| Step: 7
Training loss: 0.45175168321461634
Validation loss: 2.406921969426427

Epoch: 5| Step: 8
Training loss: 0.6729601148233347
Validation loss: 2.4233680825225212

Epoch: 5| Step: 9
Training loss: 0.360822788191625
Validation loss: 2.4210025577477015

Epoch: 5| Step: 10
Training loss: 0.3204691085367043
Validation loss: 2.419696846958253

Epoch: 336| Step: 0
Training loss: 0.3675803457065353
Validation loss: 2.420068706214103

Epoch: 5| Step: 1
Training loss: 0.46537216990099867
Validation loss: 2.410586606703137

Epoch: 5| Step: 2
Training loss: 0.720919734172081
Validation loss: 2.4180549602104895

Epoch: 5| Step: 3
Training loss: 0.5117728517775819
Validation loss: 2.4260267055862794

Epoch: 5| Step: 4
Training loss: 0.502985712282648
Validation loss: 2.42592642674688

Epoch: 5| Step: 5
Training loss: 0.5253935746461114
Validation loss: 2.4146898028542405

Epoch: 5| Step: 6
Training loss: 1.0604312053850407
Validation loss: 2.4134964832089847

Epoch: 5| Step: 7
Training loss: 0.5301288667594928
Validation loss: 2.40401291091026

Epoch: 5| Step: 8
Training loss: 0.6011062229291304
Validation loss: 2.4075946649140327

Epoch: 5| Step: 9
Training loss: 0.4111726428964654
Validation loss: 2.4020817396759537

Epoch: 5| Step: 10
Training loss: 0.47543030058423436
Validation loss: 2.3868662559310168

Epoch: 337| Step: 0
Training loss: 0.5069253949138174
Validation loss: 2.4055609002007747

Epoch: 5| Step: 1
Training loss: 0.5796205661925763
Validation loss: 2.4198639455462194

Epoch: 5| Step: 2
Training loss: 0.34023786032782455
Validation loss: 2.396320458460703

Epoch: 5| Step: 3
Training loss: 0.3159567265268269
Validation loss: 2.4229782761839083

Epoch: 5| Step: 4
Training loss: 0.356726464995586
Validation loss: 2.4358046983242976

Epoch: 5| Step: 5
Training loss: 1.0288005406698641
Validation loss: 2.419066620411502

Epoch: 5| Step: 6
Training loss: 0.5472352884666906
Validation loss: 2.443278046424138

Epoch: 5| Step: 7
Training loss: 0.7176239065518444
Validation loss: 2.420353589758784

Epoch: 5| Step: 8
Training loss: 0.5418094636297607
Validation loss: 2.4541558871025613

Epoch: 5| Step: 9
Training loss: 0.6637810278858427
Validation loss: 2.422348498032402

Epoch: 5| Step: 10
Training loss: 0.4972489641129879
Validation loss: 2.4162469046017097

Epoch: 338| Step: 0
Training loss: 0.7783459284646207
Validation loss: 2.4254362441478996

Epoch: 5| Step: 1
Training loss: 0.5813952305566312
Validation loss: 2.4282543834653985

Epoch: 5| Step: 2
Training loss: 0.3906573854373
Validation loss: 2.395317288144122

Epoch: 5| Step: 3
Training loss: 0.3135421185263148
Validation loss: 2.3948794689553345

Epoch: 5| Step: 4
Training loss: 0.41055558156400696
Validation loss: 2.406549148278692

Epoch: 5| Step: 5
Training loss: 0.9541733401424687
Validation loss: 2.4267344108894715

Epoch: 5| Step: 6
Training loss: 0.409269973881493
Validation loss: 2.4496996151522255

Epoch: 5| Step: 7
Training loss: 0.32334347431675825
Validation loss: 2.4305643473132656

Epoch: 5| Step: 8
Training loss: 0.5601362259396859
Validation loss: 2.4126563023537484

Epoch: 5| Step: 9
Training loss: 0.7148226542043881
Validation loss: 2.41561073477623

Epoch: 5| Step: 10
Training loss: 0.7270762360307487
Validation loss: 2.407837295061188

Epoch: 339| Step: 0
Training loss: 0.9722945678375579
Validation loss: 2.4211365652730463

Epoch: 5| Step: 1
Training loss: 0.616658575632095
Validation loss: 2.3843675036368897

Epoch: 5| Step: 2
Training loss: 0.603228108580745
Validation loss: 2.403985921761018

Epoch: 5| Step: 3
Training loss: 0.5256052819544011
Validation loss: 2.4185743940300055

Epoch: 5| Step: 4
Training loss: 0.3399945505490877
Validation loss: 2.396811501666928

Epoch: 5| Step: 5
Training loss: 0.4173221220912799
Validation loss: 2.3889724646554162

Epoch: 5| Step: 6
Training loss: 0.35495060056519256
Validation loss: 2.3870548831758294

Epoch: 5| Step: 7
Training loss: 0.6174490410708569
Validation loss: 2.414387280436384

Epoch: 5| Step: 8
Training loss: 0.648943531261487
Validation loss: 2.3947852086904136

Epoch: 5| Step: 9
Training loss: 0.4671249513633729
Validation loss: 2.403082373669734

Epoch: 5| Step: 10
Training loss: 0.38610567760684755
Validation loss: 2.4403347426019395

Epoch: 340| Step: 0
Training loss: 0.49477888057317043
Validation loss: 2.45418957456303

Epoch: 5| Step: 1
Training loss: 0.630788084554888
Validation loss: 2.4240338460964272

Epoch: 5| Step: 2
Training loss: 0.5203954063554377
Validation loss: 2.4426761356313884

Epoch: 5| Step: 3
Training loss: 0.4032998807225428
Validation loss: 2.434266306856025

Epoch: 5| Step: 4
Training loss: 0.45975138108220803
Validation loss: 2.4284376365384603

Epoch: 5| Step: 5
Training loss: 0.43378914906493604
Validation loss: 2.4428761415393607

Epoch: 5| Step: 6
Training loss: 0.693357440784604
Validation loss: 2.4495479478100863

Epoch: 5| Step: 7
Training loss: 0.9662691776203356
Validation loss: 2.426095924247471

Epoch: 5| Step: 8
Training loss: 0.47622553059151224
Validation loss: 2.4153563451741187

Epoch: 5| Step: 9
Training loss: 0.2289553755556706
Validation loss: 2.429756352707586

Epoch: 5| Step: 10
Training loss: 0.5357081776225329
Validation loss: 2.4108192594397626

Epoch: 341| Step: 0
Training loss: 0.5526890011553172
Validation loss: 2.392554473726569

Epoch: 5| Step: 1
Training loss: 0.6495498171151478
Validation loss: 2.4077490175410974

Epoch: 5| Step: 2
Training loss: 0.3333918574733635
Validation loss: 2.399950980169523

Epoch: 5| Step: 3
Training loss: 0.5759322880608977
Validation loss: 2.425570394612316

Epoch: 5| Step: 4
Training loss: 0.5937467374210065
Validation loss: 2.4176509194439753

Epoch: 5| Step: 5
Training loss: 0.4590987691970377
Validation loss: 2.42059167581299

Epoch: 5| Step: 6
Training loss: 0.6757459686418722
Validation loss: 2.428492524678408

Epoch: 5| Step: 7
Training loss: 0.4317640930619074
Validation loss: 2.421047130857864

Epoch: 5| Step: 8
Training loss: 0.4304846218942364
Validation loss: 2.421614151164411

Epoch: 5| Step: 9
Training loss: 0.422719110972237
Validation loss: 2.4373251392379753

Epoch: 5| Step: 10
Training loss: 0.9746337153695904
Validation loss: 2.39849084718172

Epoch: 342| Step: 0
Training loss: 0.6834202573508494
Validation loss: 2.3870013690163736

Epoch: 5| Step: 1
Training loss: 0.6196146934087668
Validation loss: 2.4112643565166327

Epoch: 5| Step: 2
Training loss: 0.837731192832765
Validation loss: 2.3983342076758

Epoch: 5| Step: 3
Training loss: 0.3655181231343434
Validation loss: 2.389503272135172

Epoch: 5| Step: 4
Training loss: 0.5061956046751229
Validation loss: 2.3877734628485228

Epoch: 5| Step: 5
Training loss: 0.49489078198248176
Validation loss: 2.437516449314564

Epoch: 5| Step: 6
Training loss: 0.5965929733174601
Validation loss: 2.4295219884929304

Epoch: 5| Step: 7
Training loss: 0.5228403870418168
Validation loss: 2.4319061520455176

Epoch: 5| Step: 8
Training loss: 0.4975001756629442
Validation loss: 2.3950639745841826

Epoch: 5| Step: 9
Training loss: 0.33115416975988793
Validation loss: 2.391268251201671

Epoch: 5| Step: 10
Training loss: 0.5565633084325043
Validation loss: 2.405843421521069

Epoch: 343| Step: 0
Training loss: 0.3874197107628852
Validation loss: 2.4069889501709145

Epoch: 5| Step: 1
Training loss: 0.5091250842118
Validation loss: 2.3965405159244697

Epoch: 5| Step: 2
Training loss: 0.500338856790913
Validation loss: 2.4052577844984353

Epoch: 5| Step: 3
Training loss: 0.6530871467024696
Validation loss: 2.4107413606240424

Epoch: 5| Step: 4
Training loss: 0.6300683509744949
Validation loss: 2.3903363728065496

Epoch: 5| Step: 5
Training loss: 0.29851096282648826
Validation loss: 2.4215223084018094

Epoch: 5| Step: 6
Training loss: 0.40869550805443305
Validation loss: 2.4254186960816906

Epoch: 5| Step: 7
Training loss: 0.5757899683547192
Validation loss: 2.4076318809423953

Epoch: 5| Step: 8
Training loss: 0.8147534153021895
Validation loss: 2.4058523149116393

Epoch: 5| Step: 9
Training loss: 0.537033214371268
Validation loss: 2.3921030167092807

Epoch: 5| Step: 10
Training loss: 0.37080619110830687
Validation loss: 2.423417076834623

Epoch: 344| Step: 0
Training loss: 0.6465487952275638
Validation loss: 2.409602143957353

Epoch: 5| Step: 1
Training loss: 0.520682700944946
Validation loss: 2.4397956696119656

Epoch: 5| Step: 2
Training loss: 0.2982988844505063
Validation loss: 2.464421757121776

Epoch: 5| Step: 3
Training loss: 0.4981553352289647
Validation loss: 2.4298580602954636

Epoch: 5| Step: 4
Training loss: 0.728641407107656
Validation loss: 2.45089921992655

Epoch: 5| Step: 5
Training loss: 0.3983308986099937
Validation loss: 2.443416278159095

Epoch: 5| Step: 6
Training loss: 0.6201711315811713
Validation loss: 2.419801722908116

Epoch: 5| Step: 7
Training loss: 0.3682861125820864
Validation loss: 2.445505042307761

Epoch: 5| Step: 8
Training loss: 0.5511390660048984
Validation loss: 2.40623580711088

Epoch: 5| Step: 9
Training loss: 0.4504877824365024
Validation loss: 2.4179373092737024

Epoch: 5| Step: 10
Training loss: 0.7343798292285323
Validation loss: 2.437081436976349

Epoch: 345| Step: 0
Training loss: 0.3776103797489143
Validation loss: 2.4396703852854054

Epoch: 5| Step: 1
Training loss: 0.7171372273429867
Validation loss: 2.439556572081496

Epoch: 5| Step: 2
Training loss: 0.3808049480967249
Validation loss: 2.428615977817199

Epoch: 5| Step: 3
Training loss: 0.48720217679607003
Validation loss: 2.437029069202596

Epoch: 5| Step: 4
Training loss: 0.648696916462788
Validation loss: 2.4370974925408184

Epoch: 5| Step: 5
Training loss: 0.3783553926966047
Validation loss: 2.444810662946707

Epoch: 5| Step: 6
Training loss: 0.6250641789863403
Validation loss: 2.4205586534824457

Epoch: 5| Step: 7
Training loss: 0.45208357475496985
Validation loss: 2.416817089345601

Epoch: 5| Step: 8
Training loss: 0.41322144073785
Validation loss: 2.4271299968657485

Epoch: 5| Step: 9
Training loss: 0.8149472939819705
Validation loss: 2.419457924776173

Epoch: 5| Step: 10
Training loss: 0.33831403366409324
Validation loss: 2.414628205211616

Epoch: 346| Step: 0
Training loss: 0.503698912555035
Validation loss: 2.413096035504749

Epoch: 5| Step: 1
Training loss: 0.6561503788855761
Validation loss: 2.407411988600379

Epoch: 5| Step: 2
Training loss: 0.5195384491156375
Validation loss: 2.4446761064473033

Epoch: 5| Step: 3
Training loss: 0.44472258795971314
Validation loss: 2.436699138552535

Epoch: 5| Step: 4
Training loss: 0.5381028022130976
Validation loss: 2.41630849280893

Epoch: 5| Step: 5
Training loss: 0.5246874276138992
Validation loss: 2.423340965648058

Epoch: 5| Step: 6
Training loss: 0.4165181988212552
Validation loss: 2.4326373509409427

Epoch: 5| Step: 7
Training loss: 0.3525356810346832
Validation loss: 2.4340188457692262

Epoch: 5| Step: 8
Training loss: 0.4614472237908018
Validation loss: 2.4318760247564826

Epoch: 5| Step: 9
Training loss: 0.8110672349000118
Validation loss: 2.4498206831617706

Epoch: 5| Step: 10
Training loss: 0.5966130295900727
Validation loss: 2.446264678183151

Epoch: 347| Step: 0
Training loss: 0.42648240200242515
Validation loss: 2.4319959076282704

Epoch: 5| Step: 1
Training loss: 0.5123173946618224
Validation loss: 2.4177093183790763

Epoch: 5| Step: 2
Training loss: 0.42596060798637453
Validation loss: 2.405367929968035

Epoch: 5| Step: 3
Training loss: 0.30031869669543804
Validation loss: 2.4434218698821484

Epoch: 5| Step: 4
Training loss: 0.4180349671862363
Validation loss: 2.387782533053587

Epoch: 5| Step: 5
Training loss: 0.4270550982128198
Validation loss: 2.4111791549355344

Epoch: 5| Step: 6
Training loss: 0.7380886734979638
Validation loss: 2.414151834768454

Epoch: 5| Step: 7
Training loss: 0.43712596572058066
Validation loss: 2.4313700805875382

Epoch: 5| Step: 8
Training loss: 0.43127056155736676
Validation loss: 2.4283421383101538

Epoch: 5| Step: 9
Training loss: 0.8573260416684366
Validation loss: 2.447440254247847

Epoch: 5| Step: 10
Training loss: 0.5268681960384938
Validation loss: 2.4409159958033704

Epoch: 348| Step: 0
Training loss: 0.5105314677101928
Validation loss: 2.436601568402072

Epoch: 5| Step: 1
Training loss: 0.4598935152760801
Validation loss: 2.4268954799061007

Epoch: 5| Step: 2
Training loss: 0.826151529697405
Validation loss: 2.45509784605168

Epoch: 5| Step: 3
Training loss: 0.40958189941082807
Validation loss: 2.4034449956792403

Epoch: 5| Step: 4
Training loss: 0.4549489636146219
Validation loss: 2.418591161266491

Epoch: 5| Step: 5
Training loss: 0.4322934284710506
Validation loss: 2.4125598542783178

Epoch: 5| Step: 6
Training loss: 0.42537282901246903
Validation loss: 2.418638511904028

Epoch: 5| Step: 7
Training loss: 0.4062026986681416
Validation loss: 2.4365175158713352

Epoch: 5| Step: 8
Training loss: 0.48308971063943784
Validation loss: 2.4338490320927226

Epoch: 5| Step: 9
Training loss: 0.5507301144501268
Validation loss: 2.431975656646291

Epoch: 5| Step: 10
Training loss: 0.6321344157025544
Validation loss: 2.4291511447202114

Epoch: 349| Step: 0
Training loss: 0.5847312208718048
Validation loss: 2.430867307293094

Epoch: 5| Step: 1
Training loss: 0.449699476346353
Validation loss: 2.428780727755226

Epoch: 5| Step: 2
Training loss: 0.22189688440308591
Validation loss: 2.4395483837403913

Epoch: 5| Step: 3
Training loss: 0.5009721008459036
Validation loss: 2.4269209450985962

Epoch: 5| Step: 4
Training loss: 0.42874461673882575
Validation loss: 2.4296231936116244

Epoch: 5| Step: 5
Training loss: 0.5591926298732262
Validation loss: 2.453862502827445

Epoch: 5| Step: 6
Training loss: 0.3844345333547398
Validation loss: 2.4150539854671957

Epoch: 5| Step: 7
Training loss: 0.45145737503412436
Validation loss: 2.430351158509238

Epoch: 5| Step: 8
Training loss: 0.471202537919028
Validation loss: 2.437954366240914

Epoch: 5| Step: 9
Training loss: 0.6529982932172146
Validation loss: 2.4400596840263833

Epoch: 5| Step: 10
Training loss: 0.7750905799230299
Validation loss: 2.43507271444936

Epoch: 350| Step: 0
Training loss: 0.5942866259478818
Validation loss: 2.463227973458299

Epoch: 5| Step: 1
Training loss: 0.4132260925753025
Validation loss: 2.4718018382892155

Epoch: 5| Step: 2
Training loss: 0.44096943670012145
Validation loss: 2.4307773671309243

Epoch: 5| Step: 3
Training loss: 0.5022695412411181
Validation loss: 2.454671195455117

Epoch: 5| Step: 4
Training loss: 0.39260742685461125
Validation loss: 2.4497999778063466

Epoch: 5| Step: 5
Training loss: 0.46683743033347186
Validation loss: 2.475183294077562

Epoch: 5| Step: 6
Training loss: 0.22340052838988728
Validation loss: 2.4394794574578964

Epoch: 5| Step: 7
Training loss: 0.7414366286779996
Validation loss: 2.4368673638967677

Epoch: 5| Step: 8
Training loss: 0.45088678906254526
Validation loss: 2.4382887332734384

Epoch: 5| Step: 9
Training loss: 0.6800425249014108
Validation loss: 2.454109051477618

Epoch: 5| Step: 10
Training loss: 0.47664389931329904
Validation loss: 2.4479920162071007

Epoch: 351| Step: 0
Training loss: 0.42025431403964564
Validation loss: 2.434401870501944

Epoch: 5| Step: 1
Training loss: 0.2905962181195711
Validation loss: 2.425671575948596

Epoch: 5| Step: 2
Training loss: 0.5236614374562981
Validation loss: 2.4385434371335495

Epoch: 5| Step: 3
Training loss: 0.5346565976958638
Validation loss: 2.4155962599277436

Epoch: 5| Step: 4
Training loss: 0.5375896456725363
Validation loss: 2.4414766013889335

Epoch: 5| Step: 5
Training loss: 0.3233787386493418
Validation loss: 2.4314941963103816

Epoch: 5| Step: 6
Training loss: 0.6333737415883174
Validation loss: 2.4349756802995284

Epoch: 5| Step: 7
Training loss: 0.5301418527570213
Validation loss: 2.4394311935038098

Epoch: 5| Step: 8
Training loss: 0.7574681551695003
Validation loss: 2.4571082154652446

Epoch: 5| Step: 9
Training loss: 0.41089284240818313
Validation loss: 2.437662605907374

Epoch: 5| Step: 10
Training loss: 0.2950531875621113
Validation loss: 2.4168529053306202

Epoch: 352| Step: 0
Training loss: 0.3995827875773363
Validation loss: 2.4146570156666227

Epoch: 5| Step: 1
Training loss: 0.5837997604007628
Validation loss: 2.450274520354467

Epoch: 5| Step: 2
Training loss: 0.28378255039837524
Validation loss: 2.4351846401380124

Epoch: 5| Step: 3
Training loss: 0.5601556722087354
Validation loss: 2.454319394768641

Epoch: 5| Step: 4
Training loss: 0.49111268594750873
Validation loss: 2.4415760273629017

Epoch: 5| Step: 5
Training loss: 0.23472471372625714
Validation loss: 2.418621155128376

Epoch: 5| Step: 6
Training loss: 0.3364236330536799
Validation loss: 2.463926331107488

Epoch: 5| Step: 7
Training loss: 0.7204673402069667
Validation loss: 2.432335738137445

Epoch: 5| Step: 8
Training loss: 0.5262910862194818
Validation loss: 2.4166592529601827

Epoch: 5| Step: 9
Training loss: 0.4160411629875138
Validation loss: 2.414178222851792

Epoch: 5| Step: 10
Training loss: 0.5625022782173645
Validation loss: 2.4424173949862555

Epoch: 353| Step: 0
Training loss: 0.3137951001963936
Validation loss: 2.4243350424919394

Epoch: 5| Step: 1
Training loss: 0.477356889609443
Validation loss: 2.4349045462082572

Epoch: 5| Step: 2
Training loss: 0.4855345874069406
Validation loss: 2.4533100412395776

Epoch: 5| Step: 3
Training loss: 0.6089273911805495
Validation loss: 2.436926042931938

Epoch: 5| Step: 4
Training loss: 0.49669528146161035
Validation loss: 2.4478166890111615

Epoch: 5| Step: 5
Training loss: 0.45638240499870236
Validation loss: 2.4378331222059546

Epoch: 5| Step: 6
Training loss: 0.5888078953893245
Validation loss: 2.4434052237272006

Epoch: 5| Step: 7
Training loss: 0.49509700756594077
Validation loss: 2.4169355468477356

Epoch: 5| Step: 8
Training loss: 0.5267109217439687
Validation loss: 2.4239704478696202

Epoch: 5| Step: 9
Training loss: 0.5596890415104394
Validation loss: 2.432098727434886

Epoch: 5| Step: 10
Training loss: 0.2180352711092831
Validation loss: 2.4506407553829113

Epoch: 354| Step: 0
Training loss: 0.395411764656502
Validation loss: 2.4399439042823197

Epoch: 5| Step: 1
Training loss: 0.4127010238548336
Validation loss: 2.444150844085992

Epoch: 5| Step: 2
Training loss: 0.23473430748368293
Validation loss: 2.4450352543799103

Epoch: 5| Step: 3
Training loss: 0.3517671095632444
Validation loss: 2.437562113460353

Epoch: 5| Step: 4
Training loss: 0.6164841325919183
Validation loss: 2.450444792251114

Epoch: 5| Step: 5
Training loss: 0.37312815315026093
Validation loss: 2.448227027029263

Epoch: 5| Step: 6
Training loss: 0.4336980402163574
Validation loss: 2.4695846197699627

Epoch: 5| Step: 7
Training loss: 0.6220075734358178
Validation loss: 2.4393364356979585

Epoch: 5| Step: 8
Training loss: 0.44241935797973486
Validation loss: 2.443542668225467

Epoch: 5| Step: 9
Training loss: 0.6267839245038995
Validation loss: 2.455248126414657

Epoch: 5| Step: 10
Training loss: 0.5289458627671885
Validation loss: 2.4621861818947592

Epoch: 355| Step: 0
Training loss: 0.5166340693322231
Validation loss: 2.4340816220713206

Epoch: 5| Step: 1
Training loss: 0.35176917464965
Validation loss: 2.4397501612806773

Epoch: 5| Step: 2
Training loss: 0.48560070497478924
Validation loss: 2.432883933574862

Epoch: 5| Step: 3
Training loss: 0.3506897796450707
Validation loss: 2.4534581772421395

Epoch: 5| Step: 4
Training loss: 0.42545043272668226
Validation loss: 2.468696042238728

Epoch: 5| Step: 5
Training loss: 0.5278474733138798
Validation loss: 2.425023704690352

Epoch: 5| Step: 6
Training loss: 0.4996316715422084
Validation loss: 2.4466187257583267

Epoch: 5| Step: 7
Training loss: 0.7156322278986234
Validation loss: 2.433969117969476

Epoch: 5| Step: 8
Training loss: 0.28984267396547203
Validation loss: 2.436722937892673

Epoch: 5| Step: 9
Training loss: 0.417847321599255
Validation loss: 2.4206335510748653

Epoch: 5| Step: 10
Training loss: 0.5883714097681154
Validation loss: 2.448355659773367

Epoch: 356| Step: 0
Training loss: 0.4794668746451108
Validation loss: 2.458058423382567

Epoch: 5| Step: 1
Training loss: 0.7839571778465215
Validation loss: 2.4156490116777647

Epoch: 5| Step: 2
Training loss: 0.20263837331073384
Validation loss: 2.444909922927696

Epoch: 5| Step: 3
Training loss: 0.32597022761822886
Validation loss: 2.4420185094178617

Epoch: 5| Step: 4
Training loss: 0.4182777688498233
Validation loss: 2.429175612174735

Epoch: 5| Step: 5
Training loss: 0.5680540910120052
Validation loss: 2.408923310293831

Epoch: 5| Step: 6
Training loss: 0.4206967678315861
Validation loss: 2.4423979399706934

Epoch: 5| Step: 7
Training loss: 0.6131633475129914
Validation loss: 2.4583771710235314

Epoch: 5| Step: 8
Training loss: 0.3892101222260803
Validation loss: 2.4209831890203586

Epoch: 5| Step: 9
Training loss: 0.5120100109734685
Validation loss: 2.4325582801664765

Epoch: 5| Step: 10
Training loss: 0.4452478462265674
Validation loss: 2.420629001269912

Epoch: 357| Step: 0
Training loss: 0.5665410637732268
Validation loss: 2.429748678939076

Epoch: 5| Step: 1
Training loss: 0.6622345392532852
Validation loss: 2.427495254346876

Epoch: 5| Step: 2
Training loss: 0.38642135899085783
Validation loss: 2.4147406920788437

Epoch: 5| Step: 3
Training loss: 0.4322972373909868
Validation loss: 2.4255840690408634

Epoch: 5| Step: 4
Training loss: 0.31609519927993235
Validation loss: 2.4264955308370797

Epoch: 5| Step: 5
Training loss: 0.41044330542745466
Validation loss: 2.419283450408217

Epoch: 5| Step: 6
Training loss: 0.6889611452950983
Validation loss: 2.4305533704928544

Epoch: 5| Step: 7
Training loss: 0.5352990175810773
Validation loss: 2.440826393883073

Epoch: 5| Step: 8
Training loss: 0.3551747500111228
Validation loss: 2.417701387938633

Epoch: 5| Step: 9
Training loss: 0.5210740550378493
Validation loss: 2.435314838672227

Epoch: 5| Step: 10
Training loss: 0.3767962549352003
Validation loss: 2.415335105559343

Epoch: 358| Step: 0
Training loss: 0.6686293921049146
Validation loss: 2.413035543521986

Epoch: 5| Step: 1
Training loss: 0.3881069467556823
Validation loss: 2.4305748083130476

Epoch: 5| Step: 2
Training loss: 0.389549376627928
Validation loss: 2.4503307282956794

Epoch: 5| Step: 3
Training loss: 0.4557948219598574
Validation loss: 2.4310270764052166

Epoch: 5| Step: 4
Training loss: 0.7382834298237909
Validation loss: 2.4540747382132566

Epoch: 5| Step: 5
Training loss: 0.46561523337650124
Validation loss: 2.4407207055812257

Epoch: 5| Step: 6
Training loss: 0.27623443650295093
Validation loss: 2.4486547135524734

Epoch: 5| Step: 7
Training loss: 0.35827214565097015
Validation loss: 2.4744349464325586

Epoch: 5| Step: 8
Training loss: 0.6480727031359655
Validation loss: 2.465921892453502

Epoch: 5| Step: 9
Training loss: 0.3367429215679182
Validation loss: 2.438934919804462

Epoch: 5| Step: 10
Training loss: 0.2863032513648367
Validation loss: 2.4312947867083605

Epoch: 359| Step: 0
Training loss: 0.5492028419936482
Validation loss: 2.4110948918678567

Epoch: 5| Step: 1
Training loss: 0.5069713080994813
Validation loss: 2.4400411064865186

Epoch: 5| Step: 2
Training loss: 0.44606683653233087
Validation loss: 2.410894590923769

Epoch: 5| Step: 3
Training loss: 0.1870417956675204
Validation loss: 2.429271592630502

Epoch: 5| Step: 4
Training loss: 0.4665879775728733
Validation loss: 2.4102809486367245

Epoch: 5| Step: 5
Training loss: 0.36202395685758343
Validation loss: 2.4465452413808015

Epoch: 5| Step: 6
Training loss: 0.2677208735476516
Validation loss: 2.439744483909818

Epoch: 5| Step: 7
Training loss: 0.5517304270201926
Validation loss: 2.4196505511121424

Epoch: 5| Step: 8
Training loss: 0.6773158603369075
Validation loss: 2.4305100238557054

Epoch: 5| Step: 9
Training loss: 0.6123556453545215
Validation loss: 2.4270494896961483

Epoch: 5| Step: 10
Training loss: 0.2959037377414701
Validation loss: 2.4445895409551417

Epoch: 360| Step: 0
Training loss: 0.38024859237034153
Validation loss: 2.448564243123067

Epoch: 5| Step: 1
Training loss: 0.45064933869852886
Validation loss: 2.4259343450941637

Epoch: 5| Step: 2
Training loss: 0.4947165348499048
Validation loss: 2.446463584360642

Epoch: 5| Step: 3
Training loss: 0.6795138433195747
Validation loss: 2.402700797539217

Epoch: 5| Step: 4
Training loss: 0.4104046387370298
Validation loss: 2.4249691212646765

Epoch: 5| Step: 5
Training loss: 0.33912395017133085
Validation loss: 2.407955696059038

Epoch: 5| Step: 6
Training loss: 0.5797503794577978
Validation loss: 2.4136759181016054

Epoch: 5| Step: 7
Training loss: 0.49966267293263283
Validation loss: 2.421917230434382

Epoch: 5| Step: 8
Training loss: 0.5628102559537911
Validation loss: 2.424406905707891

Epoch: 5| Step: 9
Training loss: 0.38524522276013723
Validation loss: 2.437984242283975

Epoch: 5| Step: 10
Training loss: 0.4250289851009744
Validation loss: 2.4161239791918154

Epoch: 361| Step: 0
Training loss: 0.34415602546725443
Validation loss: 2.4423804518419794

Epoch: 5| Step: 1
Training loss: 0.6053029725561253
Validation loss: 2.416835503909153

Epoch: 5| Step: 2
Training loss: 0.4554556561742279
Validation loss: 2.4384125283760834

Epoch: 5| Step: 3
Training loss: 0.36028777180735455
Validation loss: 2.4332288342947392

Epoch: 5| Step: 4
Training loss: 0.49409644491039667
Validation loss: 2.436546115899991

Epoch: 5| Step: 5
Training loss: 0.20649267716158665
Validation loss: 2.42154653956957

Epoch: 5| Step: 6
Training loss: 0.5435083575830028
Validation loss: 2.412958302726651

Epoch: 5| Step: 7
Training loss: 0.44093260207453455
Validation loss: 2.399635509296242

Epoch: 5| Step: 8
Training loss: 0.5273299886532717
Validation loss: 2.4499900427576824

Epoch: 5| Step: 9
Training loss: 0.6288163731012782
Validation loss: 2.4115043796446987

Epoch: 5| Step: 10
Training loss: 0.36453506513513034
Validation loss: 2.4157867619024858

Epoch: 362| Step: 0
Training loss: 0.4461386529399742
Validation loss: 2.4191602424241623

Epoch: 5| Step: 1
Training loss: 0.4018115996544868
Validation loss: 2.4313187612630127

Epoch: 5| Step: 2
Training loss: 0.4955875788123493
Validation loss: 2.438807003240816

Epoch: 5| Step: 3
Training loss: 0.3979004250785166
Validation loss: 2.450568001513211

Epoch: 5| Step: 4
Training loss: 0.41516298127092355
Validation loss: 2.400522789706388

Epoch: 5| Step: 5
Training loss: 0.5766704406596411
Validation loss: 2.419788781784138

Epoch: 5| Step: 6
Training loss: 0.41518570048573766
Validation loss: 2.4452279521928895

Epoch: 5| Step: 7
Training loss: 0.3678504559323139
Validation loss: 2.428052778763308

Epoch: 5| Step: 8
Training loss: 0.2434040861250293
Validation loss: 2.4152524596990097

Epoch: 5| Step: 9
Training loss: 0.735930722604309
Validation loss: 2.402044075850525

Epoch: 5| Step: 10
Training loss: 0.43190094705633725
Validation loss: 2.431838584130076

Epoch: 363| Step: 0
Training loss: 0.2622155839885529
Validation loss: 2.39552285392705

Epoch: 5| Step: 1
Training loss: 0.5730199431765138
Validation loss: 2.410560721689883

Epoch: 5| Step: 2
Training loss: 0.4557315899012491
Validation loss: 2.412031558238273

Epoch: 5| Step: 3
Training loss: 0.4347222908955697
Validation loss: 2.4180598276194214

Epoch: 5| Step: 4
Training loss: 0.4861847080043152
Validation loss: 2.4484161816833807

Epoch: 5| Step: 5
Training loss: 0.4829840376972688
Validation loss: 2.456063012869609

Epoch: 5| Step: 6
Training loss: 0.37342324169822966
Validation loss: 2.43393767748543

Epoch: 5| Step: 7
Training loss: 0.3885821905130893
Validation loss: 2.4513154622551694

Epoch: 5| Step: 8
Training loss: 0.7098547267044132
Validation loss: 2.440401221226433

Epoch: 5| Step: 9
Training loss: 0.3806104188703752
Validation loss: 2.4195346094837435

Epoch: 5| Step: 10
Training loss: 0.4682794752523288
Validation loss: 2.4087408081804313

Epoch: 364| Step: 0
Training loss: 0.3055177161539701
Validation loss: 2.4378159920051736

Epoch: 5| Step: 1
Training loss: 0.4931923886464007
Validation loss: 2.4359688715660446

Epoch: 5| Step: 2
Training loss: 0.3572132356304984
Validation loss: 2.4074234047785814

Epoch: 5| Step: 3
Training loss: 0.6192025716219342
Validation loss: 2.413425814921623

Epoch: 5| Step: 4
Training loss: 0.749207634390912
Validation loss: 2.4307755446799097

Epoch: 5| Step: 5
Training loss: 0.3613068651697955
Validation loss: 2.396565788057476

Epoch: 5| Step: 6
Training loss: 0.5841578350360924
Validation loss: 2.4313873753491646

Epoch: 5| Step: 7
Training loss: 0.4463015832125451
Validation loss: 2.424530461935161

Epoch: 5| Step: 8
Training loss: 0.3434549604390886
Validation loss: 2.448799573817827

Epoch: 5| Step: 9
Training loss: 0.26227017571140604
Validation loss: 2.445368580871456

Epoch: 5| Step: 10
Training loss: 0.3270860868791628
Validation loss: 2.457638485045503

Epoch: 365| Step: 0
Training loss: 0.5390222506769582
Validation loss: 2.4568980639794575

Epoch: 5| Step: 1
Training loss: 0.3805406263633706
Validation loss: 2.451682933567891

Epoch: 5| Step: 2
Training loss: 0.4984091693874712
Validation loss: 2.4072790418586787

Epoch: 5| Step: 3
Training loss: 0.5245025389639875
Validation loss: 2.4143793386859573

Epoch: 5| Step: 4
Training loss: 0.2900488238506279
Validation loss: 2.407580032194836

Epoch: 5| Step: 5
Training loss: 0.3982893350408373
Validation loss: 2.4086196912120026

Epoch: 5| Step: 6
Training loss: 0.26955344620130745
Validation loss: 2.4369641286337003

Epoch: 5| Step: 7
Training loss: 0.43753559104019774
Validation loss: 2.4553747709035965

Epoch: 5| Step: 8
Training loss: 0.5096507619016961
Validation loss: 2.406524026793409

Epoch: 5| Step: 9
Training loss: 0.36021462089532924
Validation loss: 2.4214700170373966

Epoch: 5| Step: 10
Training loss: 0.5032937223066812
Validation loss: 2.4029038336701904

Epoch: 366| Step: 0
Training loss: 0.6678649420133479
Validation loss: 2.4171856519879213

Epoch: 5| Step: 1
Training loss: 0.3120844462230144
Validation loss: 2.4057881583676917

Epoch: 5| Step: 2
Training loss: 0.5897082747947664
Validation loss: 2.42188925684326

Epoch: 5| Step: 3
Training loss: 0.5173305567168333
Validation loss: 2.3946718347545377

Epoch: 5| Step: 4
Training loss: 0.3251173137796091
Validation loss: 2.4009664065186063

Epoch: 5| Step: 5
Training loss: 0.4098142196889135
Validation loss: 2.3880346662396463

Epoch: 5| Step: 6
Training loss: 0.3597777224814839
Validation loss: 2.405882711070427

Epoch: 5| Step: 7
Training loss: 0.3330441116730217
Validation loss: 2.410605050250245

Epoch: 5| Step: 8
Training loss: 0.35955217389258687
Validation loss: 2.413509344947188

Epoch: 5| Step: 9
Training loss: 0.3680785304922018
Validation loss: 2.3805929464569537

Epoch: 5| Step: 10
Training loss: 0.35291074143577134
Validation loss: 2.3810398350020123

Epoch: 367| Step: 0
Training loss: 0.47306424651628026
Validation loss: 2.412993868944824

Epoch: 5| Step: 1
Training loss: 0.310470067728411
Validation loss: 2.4095965923801854

Epoch: 5| Step: 2
Training loss: 0.3087531897152294
Validation loss: 2.405240198998144

Epoch: 5| Step: 3
Training loss: 0.39562432727485336
Validation loss: 2.4266556902592344

Epoch: 5| Step: 4
Training loss: 0.5961031961754998
Validation loss: 2.440448252693191

Epoch: 5| Step: 5
Training loss: 0.14550111742426264
Validation loss: 2.4204158350161

Epoch: 5| Step: 6
Training loss: 0.5329082637876994
Validation loss: 2.424055302972089

Epoch: 5| Step: 7
Training loss: 0.532734619668663
Validation loss: 2.435092070070851

Epoch: 5| Step: 8
Training loss: 0.4305289266240771
Validation loss: 2.399592708308957

Epoch: 5| Step: 9
Training loss: 0.28352169666321886
Validation loss: 2.4366170453000886

Epoch: 5| Step: 10
Training loss: 0.5223796175122567
Validation loss: 2.431452815968886

Epoch: 368| Step: 0
Training loss: 0.5651620287358511
Validation loss: 2.4413928658067268

Epoch: 5| Step: 1
Training loss: 0.39775781065262944
Validation loss: 2.4523596911743044

Epoch: 5| Step: 2
Training loss: 0.39484183672919576
Validation loss: 2.419373589241353

Epoch: 5| Step: 3
Training loss: 0.4426502657188567
Validation loss: 2.4192365047440156

Epoch: 5| Step: 4
Training loss: 0.3514092641237275
Validation loss: 2.4194681021453524

Epoch: 5| Step: 5
Training loss: 0.4485920722741377
Validation loss: 2.42640426059889

Epoch: 5| Step: 6
Training loss: 0.3034497821730396
Validation loss: 2.3910894305388553

Epoch: 5| Step: 7
Training loss: 0.3505403388076934
Validation loss: 2.411480800775866

Epoch: 5| Step: 8
Training loss: 0.5641881723498176
Validation loss: 2.44680492750417

Epoch: 5| Step: 9
Training loss: 0.4127186073123318
Validation loss: 2.4354429439177365

Epoch: 5| Step: 10
Training loss: 0.5464407422832247
Validation loss: 2.423751112854699

Epoch: 369| Step: 0
Training loss: 0.5654621279672114
Validation loss: 2.4428170444950768

Epoch: 5| Step: 1
Training loss: 0.49553032667159774
Validation loss: 2.4197346301370315

Epoch: 5| Step: 2
Training loss: 0.2816773717348887
Validation loss: 2.42136992640412

Epoch: 5| Step: 3
Training loss: 0.46240269823070823
Validation loss: 2.409950149543754

Epoch: 5| Step: 4
Training loss: 0.35596940132907356
Validation loss: 2.4081825163848443

Epoch: 5| Step: 5
Training loss: 0.5196371042357305
Validation loss: 2.4052615959699986

Epoch: 5| Step: 6
Training loss: 0.568159533627197
Validation loss: 2.4140522902837276

Epoch: 5| Step: 7
Training loss: 0.6418695456283292
Validation loss: 2.3724676933376725

Epoch: 5| Step: 8
Training loss: 0.43744044239108154
Validation loss: 2.4040082885927307

Epoch: 5| Step: 9
Training loss: 0.45225546705021336
Validation loss: 2.432186378356824

Epoch: 5| Step: 10
Training loss: 0.5449146830860109
Validation loss: 2.434334505604154

Epoch: 370| Step: 0
Training loss: 0.6712036993087903
Validation loss: 2.422005228119826

Epoch: 5| Step: 1
Training loss: 0.4766060699807518
Validation loss: 2.4446030880220064

Epoch: 5| Step: 2
Training loss: 0.5449455009999243
Validation loss: 2.448403305942719

Epoch: 5| Step: 3
Training loss: 0.5124750445267956
Validation loss: 2.426881241908646

Epoch: 5| Step: 4
Training loss: 0.31592967794377713
Validation loss: 2.4248480459963586

Epoch: 5| Step: 5
Training loss: 0.7600719158127975
Validation loss: 2.419809727512213

Epoch: 5| Step: 6
Training loss: 0.6387949833641898
Validation loss: 2.4176951646612963

Epoch: 5| Step: 7
Training loss: 0.6542972849374882
Validation loss: 2.4224590559207333

Epoch: 5| Step: 8
Training loss: 0.6568692101641722
Validation loss: 2.4073602208427483

Epoch: 5| Step: 9
Training loss: 0.3179075978965912
Validation loss: 2.3983043609517662

Epoch: 5| Step: 10
Training loss: 0.5430273669320752
Validation loss: 2.4232086140620774

Epoch: 371| Step: 0
Training loss: 0.5617168325675316
Validation loss: 2.422009889654972

Epoch: 5| Step: 1
Training loss: 0.3218560592856141
Validation loss: 2.4310594709238726

Epoch: 5| Step: 2
Training loss: 0.7136105599291329
Validation loss: 2.438523800348048

Epoch: 5| Step: 3
Training loss: 0.6062808835136785
Validation loss: 2.450372011638581

Epoch: 5| Step: 4
Training loss: 0.5136693221924447
Validation loss: 2.464948670240701

Epoch: 5| Step: 5
Training loss: 0.4852311965624548
Validation loss: 2.4308929117434848

Epoch: 5| Step: 6
Training loss: 0.3559737757549965
Validation loss: 2.408802273808567

Epoch: 5| Step: 7
Training loss: 0.5877460542771118
Validation loss: 2.4354997730937997

Epoch: 5| Step: 8
Training loss: 0.6357378043918724
Validation loss: 2.4424502241208024

Epoch: 5| Step: 9
Training loss: 0.8448897187652082
Validation loss: 2.462557335183966

Epoch: 5| Step: 10
Training loss: 0.4555798821945102
Validation loss: 2.4739845817654427

Epoch: 372| Step: 0
Training loss: 0.5349163993687795
Validation loss: 2.4893961855957

Epoch: 5| Step: 1
Training loss: 0.47535085644976366
Validation loss: 2.4390143241175632

Epoch: 5| Step: 2
Training loss: 0.550221991171482
Validation loss: 2.4676104286092033

Epoch: 5| Step: 3
Training loss: 0.6377073932338774
Validation loss: 2.4692689493758913

Epoch: 5| Step: 4
Training loss: 0.448660810873188
Validation loss: 2.4896169068021536

Epoch: 5| Step: 5
Training loss: 0.7582391933723799
Validation loss: 2.4809205002776045

Epoch: 5| Step: 6
Training loss: 0.4498572580125339
Validation loss: 2.429032701933828

Epoch: 5| Step: 7
Training loss: 0.5173324577737475
Validation loss: 2.4290882684371993

Epoch: 5| Step: 8
Training loss: 0.3952750945958917
Validation loss: 2.4511962575647197

Epoch: 5| Step: 9
Training loss: 0.43229146367570026
Validation loss: 2.447739796913163

Epoch: 5| Step: 10
Training loss: 0.44872684913146715
Validation loss: 2.440482352067023

Epoch: 373| Step: 0
Training loss: 0.4792570170623598
Validation loss: 2.425123112264777

Epoch: 5| Step: 1
Training loss: 0.5122340570671152
Validation loss: 2.418539999022403

Epoch: 5| Step: 2
Training loss: 0.40772112995715293
Validation loss: 2.44907550746485

Epoch: 5| Step: 3
Training loss: 0.5033277991392717
Validation loss: 2.4371346567221206

Epoch: 5| Step: 4
Training loss: 0.4220135425975414
Validation loss: 2.447755361534208

Epoch: 5| Step: 5
Training loss: 0.48432900610332064
Validation loss: 2.4399496032537358

Epoch: 5| Step: 6
Training loss: 0.7327331288509427
Validation loss: 2.4431894340536053

Epoch: 5| Step: 7
Training loss: 0.6156734534622567
Validation loss: 2.4176905913004028

Epoch: 5| Step: 8
Training loss: 0.463915033382576
Validation loss: 2.4197087460427267

Epoch: 5| Step: 9
Training loss: 0.6088644725709418
Validation loss: 2.4091734874346997

Epoch: 5| Step: 10
Training loss: 0.465430266347534
Validation loss: 2.4021511894104597

Epoch: 374| Step: 0
Training loss: 0.7098943582035746
Validation loss: 2.394362447460036

Epoch: 5| Step: 1
Training loss: 0.3576840549125116
Validation loss: 2.4493212110532134

Epoch: 5| Step: 2
Training loss: 0.4318722064842933
Validation loss: 2.4385212214870977

Epoch: 5| Step: 3
Training loss: 0.5289980618508066
Validation loss: 2.4492785126651095

Epoch: 5| Step: 4
Training loss: 0.4655272803717655
Validation loss: 2.4552304948804995

Epoch: 5| Step: 5
Training loss: 0.5477011843108724
Validation loss: 2.4077937284636515

Epoch: 5| Step: 6
Training loss: 0.6389835542075868
Validation loss: 2.414837743105338

Epoch: 5| Step: 7
Training loss: 0.3451388975610781
Validation loss: 2.420737897699456

Epoch: 5| Step: 8
Training loss: 0.5537563890643987
Validation loss: 2.3998473555977844

Epoch: 5| Step: 9
Training loss: 0.51948231631555
Validation loss: 2.3647944092487045

Epoch: 5| Step: 10
Training loss: 0.49534252689454356
Validation loss: 2.377500912009347

Epoch: 375| Step: 0
Training loss: 0.5917952886881199
Validation loss: 2.377816617154483

Epoch: 5| Step: 1
Training loss: 0.5181528319555583
Validation loss: 2.3929747812580526

Epoch: 5| Step: 2
Training loss: 0.49681451957216327
Validation loss: 2.3808786351272686

Epoch: 5| Step: 3
Training loss: 0.4963372001136521
Validation loss: 2.414654208530977

Epoch: 5| Step: 4
Training loss: 0.49157934612259396
Validation loss: 2.446286886910693

Epoch: 5| Step: 5
Training loss: 0.44384419824912913
Validation loss: 2.459461462908395

Epoch: 5| Step: 6
Training loss: 0.35904193039051746
Validation loss: 2.499763672436076

Epoch: 5| Step: 7
Training loss: 0.6278192354774226
Validation loss: 2.4950725386950734

Epoch: 5| Step: 8
Training loss: 0.7356902984962583
Validation loss: 2.532221821399613

Epoch: 5| Step: 9
Training loss: 0.5486680472749804
Validation loss: 2.529297666604593

Epoch: 5| Step: 10
Training loss: 0.4418062237763124
Validation loss: 2.5181541052891094

Epoch: 376| Step: 0
Training loss: 0.5254820846875666
Validation loss: 2.4862546388005216

Epoch: 5| Step: 1
Training loss: 0.418329475395808
Validation loss: 2.4729613841444404

Epoch: 5| Step: 2
Training loss: 0.4263935411236036
Validation loss: 2.4807781408612954

Epoch: 5| Step: 3
Training loss: 0.5821010624536892
Validation loss: 2.4680709985083342

Epoch: 5| Step: 4
Training loss: 0.4535454246594268
Validation loss: 2.4267147044286523

Epoch: 5| Step: 5
Training loss: 0.47131475701858405
Validation loss: 2.416899527369469

Epoch: 5| Step: 6
Training loss: 0.5620539804273386
Validation loss: 2.4375864276019765

Epoch: 5| Step: 7
Training loss: 0.3121444348252996
Validation loss: 2.427353068441385

Epoch: 5| Step: 8
Training loss: 0.412618981888089
Validation loss: 2.4107357457378753

Epoch: 5| Step: 9
Training loss: 0.49592061663651593
Validation loss: 2.419371329049684

Epoch: 5| Step: 10
Training loss: 0.3680322142863138
Validation loss: 2.411712159688264

Epoch: 377| Step: 0
Training loss: 0.43173032147987367
Validation loss: 2.421309567014576

Epoch: 5| Step: 1
Training loss: 0.40259975325652175
Validation loss: 2.39172285419207

Epoch: 5| Step: 2
Training loss: 0.39169266704062605
Validation loss: 2.3878221578931864

Epoch: 5| Step: 3
Training loss: 0.41143631775622563
Validation loss: 2.40133477675845

Epoch: 5| Step: 4
Training loss: 0.4470355012405529
Validation loss: 2.3760733324440872

Epoch: 5| Step: 5
Training loss: 0.35749144997409477
Validation loss: 2.344295134777256

Epoch: 5| Step: 6
Training loss: 0.38518582553552183
Validation loss: 2.324948734296474

Epoch: 5| Step: 7
Training loss: 0.3045118143290588
Validation loss: 2.3604158217629685

Epoch: 5| Step: 8
Training loss: 0.5656285965525898
Validation loss: 2.3274200554831888

Epoch: 5| Step: 9
Training loss: 0.7355683147853059
Validation loss: 2.3481883193974626

Epoch: 5| Step: 10
Training loss: 0.484988208976449
Validation loss: 2.390743597173157

Epoch: 378| Step: 0
Training loss: 0.6150299701521327
Validation loss: 2.403158792570464

Epoch: 5| Step: 1
Training loss: 0.47194296240067135
Validation loss: 2.386234998731752

Epoch: 5| Step: 2
Training loss: 0.49573129644522235
Validation loss: 2.4457651108840803

Epoch: 5| Step: 3
Training loss: 0.5176744191544551
Validation loss: 2.4072281370678033

Epoch: 5| Step: 4
Training loss: 0.3204608434169541
Validation loss: 2.4331608284513497

Epoch: 5| Step: 5
Training loss: 0.3681955096426342
Validation loss: 2.41168222021709

Epoch: 5| Step: 6
Training loss: 0.24859642367840318
Validation loss: 2.4214825352219327

Epoch: 5| Step: 7
Training loss: 0.16352904535801585
Validation loss: 2.4364019097076937

Epoch: 5| Step: 8
Training loss: 0.4440250021439711
Validation loss: 2.392710406238012

Epoch: 5| Step: 9
Training loss: 0.2731979137923957
Validation loss: 2.4110128311496517

Epoch: 5| Step: 10
Training loss: 0.3985095613426246
Validation loss: 2.4079352812243093

Epoch: 379| Step: 0
Training loss: 0.38124630175813595
Validation loss: 2.3946371114142284

Epoch: 5| Step: 1
Training loss: 0.3982187493402187
Validation loss: 2.4107892046662074

Epoch: 5| Step: 2
Training loss: 0.2850667865408304
Validation loss: 2.4068060233723023

Epoch: 5| Step: 3
Training loss: 0.4887599277219774
Validation loss: 2.418453111780351

Epoch: 5| Step: 4
Training loss: 0.5211022223337178
Validation loss: 2.3909522512276595

Epoch: 5| Step: 5
Training loss: 0.32048272052669075
Validation loss: 2.4276837137975087

Epoch: 5| Step: 6
Training loss: 0.2854294970104417
Validation loss: 2.3988407692908127

Epoch: 5| Step: 7
Training loss: 0.48996584403436994
Validation loss: 2.4354115677244055

Epoch: 5| Step: 8
Training loss: 0.2677249227324034
Validation loss: 2.3969053833034706

Epoch: 5| Step: 9
Training loss: 0.4678060245511691
Validation loss: 2.4170795536337497

Epoch: 5| Step: 10
Training loss: 0.5094051036247308
Validation loss: 2.4210177086839613

Epoch: 380| Step: 0
Training loss: 0.23387153114272466
Validation loss: 2.405418074259697

Epoch: 5| Step: 1
Training loss: 0.5159767569400705
Validation loss: 2.437175068575895

Epoch: 5| Step: 2
Training loss: 0.45161347019059983
Validation loss: 2.396321293458026

Epoch: 5| Step: 3
Training loss: 0.16544871868210634
Validation loss: 2.4092826446660953

Epoch: 5| Step: 4
Training loss: 0.3890713503033953
Validation loss: 2.423873616555897

Epoch: 5| Step: 5
Training loss: 0.4433661809054386
Validation loss: 2.4101385289870967

Epoch: 5| Step: 6
Training loss: 0.427729532571494
Validation loss: 2.3927314657931618

Epoch: 5| Step: 7
Training loss: 0.4824794009115443
Validation loss: 2.392126167675873

Epoch: 5| Step: 8
Training loss: 0.32206353295514256
Validation loss: 2.4079003089059987

Epoch: 5| Step: 9
Training loss: 0.29876562474703017
Validation loss: 2.404156642474989

Epoch: 5| Step: 10
Training loss: 0.4603870629017933
Validation loss: 2.402264185816027

Epoch: 381| Step: 0
Training loss: 0.41862425695463285
Validation loss: 2.423095179810595

Epoch: 5| Step: 1
Training loss: 0.2909100232122936
Validation loss: 2.423290566999408

Epoch: 5| Step: 2
Training loss: 0.264037070093833
Validation loss: 2.396456880111953

Epoch: 5| Step: 3
Training loss: 0.40599400450831913
Validation loss: 2.4140052659862676

Epoch: 5| Step: 4
Training loss: 0.5044197305180518
Validation loss: 2.41063067795879

Epoch: 5| Step: 5
Training loss: 0.2872215882120528
Validation loss: 2.4328493425504285

Epoch: 5| Step: 6
Training loss: 0.3969856438383217
Validation loss: 2.4483556985155746

Epoch: 5| Step: 7
Training loss: 0.2592225672444824
Validation loss: 2.4458460166325438

Epoch: 5| Step: 8
Training loss: 0.39544456823985763
Validation loss: 2.4032892241654427

Epoch: 5| Step: 9
Training loss: 0.45292945457146544
Validation loss: 2.401860780453257

Epoch: 5| Step: 10
Training loss: 0.30035567210493286
Validation loss: 2.4135148354763216

Epoch: 382| Step: 0
Training loss: 0.35815733405803646
Validation loss: 2.4144894003786943

Epoch: 5| Step: 1
Training loss: 0.30894330905636586
Validation loss: 2.4205579189887585

Epoch: 5| Step: 2
Training loss: 0.3547899031170605
Validation loss: 2.435626630803402

Epoch: 5| Step: 3
Training loss: 0.44071651685222385
Validation loss: 2.398634593278564

Epoch: 5| Step: 4
Training loss: 0.30687161874947755
Validation loss: 2.4087667675620232

Epoch: 5| Step: 5
Training loss: 0.31826278765938726
Validation loss: 2.397307733467192

Epoch: 5| Step: 6
Training loss: 0.32788447238184115
Validation loss: 2.390995931430426

Epoch: 5| Step: 7
Training loss: 0.35820729826281816
Validation loss: 2.3982667329411544

Epoch: 5| Step: 8
Training loss: 0.3824711659727068
Validation loss: 2.386806633507448

Epoch: 5| Step: 9
Training loss: 0.18461814139559082
Validation loss: 2.402055333436649

Epoch: 5| Step: 10
Training loss: 0.6090038342942424
Validation loss: 2.3980042448153784

Epoch: 383| Step: 0
Training loss: 0.4113999900819724
Validation loss: 2.38529053848207

Epoch: 5| Step: 1
Training loss: 0.5267285750114105
Validation loss: 2.39497001113149

Epoch: 5| Step: 2
Training loss: 0.2554515179529821
Validation loss: 2.4099152585905492

Epoch: 5| Step: 3
Training loss: 0.38501576459488973
Validation loss: 2.3930857518549398

Epoch: 5| Step: 4
Training loss: 0.23342880147279824
Validation loss: 2.4014211250758573

Epoch: 5| Step: 5
Training loss: 0.2739706563655909
Validation loss: 2.397497562323931

Epoch: 5| Step: 6
Training loss: 0.43405264550070666
Validation loss: 2.3928262323011995

Epoch: 5| Step: 7
Training loss: 0.4748717473705183
Validation loss: 2.418096885232842

Epoch: 5| Step: 8
Training loss: 0.3602003281569588
Validation loss: 2.3796949660747027

Epoch: 5| Step: 9
Training loss: 0.3649706168627964
Validation loss: 2.3917409656851008

Epoch: 5| Step: 10
Training loss: 0.18006390041679313
Validation loss: 2.420510694866246

Epoch: 384| Step: 0
Training loss: 0.2114809153780807
Validation loss: 2.4047398776721267

Epoch: 5| Step: 1
Training loss: 0.5416938029118744
Validation loss: 2.426269833971106

Epoch: 5| Step: 2
Training loss: 0.39420539316236025
Validation loss: 2.4228566837413315

Epoch: 5| Step: 3
Training loss: 0.2683372449565089
Validation loss: 2.428789828481321

Epoch: 5| Step: 4
Training loss: 0.2662891611661724
Validation loss: 2.4468030431245014

Epoch: 5| Step: 5
Training loss: 0.36103062109643547
Validation loss: 2.4440742394438844

Epoch: 5| Step: 6
Training loss: 0.15574399554310844
Validation loss: 2.4422638483456702

Epoch: 5| Step: 7
Training loss: 0.2920840830029178
Validation loss: 2.437893518887425

Epoch: 5| Step: 8
Training loss: 0.36307072435737814
Validation loss: 2.390320333484733

Epoch: 5| Step: 9
Training loss: 0.45350653929238327
Validation loss: 2.402885188580471

Epoch: 5| Step: 10
Training loss: 0.48170058966947626
Validation loss: 2.4085094352675527

Epoch: 385| Step: 0
Training loss: 0.35866517994854985
Validation loss: 2.411626545525228

Epoch: 5| Step: 1
Training loss: 0.28308238382426354
Validation loss: 2.437246590802404

Epoch: 5| Step: 2
Training loss: 0.27038800171883204
Validation loss: 2.416054795287611

Epoch: 5| Step: 3
Training loss: 0.3180326645932032
Validation loss: 2.434892556872271

Epoch: 5| Step: 4
Training loss: 0.1563461842131073
Validation loss: 2.427615297584434

Epoch: 5| Step: 5
Training loss: 0.34158751479022603
Validation loss: 2.433336239207723

Epoch: 5| Step: 6
Training loss: 0.26836410695975066
Validation loss: 2.441937997314768

Epoch: 5| Step: 7
Training loss: 0.4562336245955588
Validation loss: 2.4344629825672195

Epoch: 5| Step: 8
Training loss: 0.5818555425879676
Validation loss: 2.4327978758144164

Epoch: 5| Step: 9
Training loss: 0.34001648557890723
Validation loss: 2.4383198753067234

Epoch: 5| Step: 10
Training loss: 0.27708383927024216
Validation loss: 2.4516720628036626

Epoch: 386| Step: 0
Training loss: 0.31207487276082774
Validation loss: 2.3954069763152774

Epoch: 5| Step: 1
Training loss: 0.4245239908933679
Validation loss: 2.4311196610058183

Epoch: 5| Step: 2
Training loss: 0.3509260774963169
Validation loss: 2.4521268526902458

Epoch: 5| Step: 3
Training loss: 0.3270329399630227
Validation loss: 2.449283919870879

Epoch: 5| Step: 4
Training loss: 0.24999316772423263
Validation loss: 2.41428853953393

Epoch: 5| Step: 5
Training loss: 0.3107864487425595
Validation loss: 2.3899231787421256

Epoch: 5| Step: 6
Training loss: 0.44865378636784237
Validation loss: 2.437614646468303

Epoch: 5| Step: 7
Training loss: 0.46372225454777266
Validation loss: 2.4036244511310136

Epoch: 5| Step: 8
Training loss: 0.27584962942690744
Validation loss: 2.437363677818143

Epoch: 5| Step: 9
Training loss: 0.4009179713071313
Validation loss: 2.410004318399211

Epoch: 5| Step: 10
Training loss: 0.3476102991490081
Validation loss: 2.386363782413462

Epoch: 387| Step: 0
Training loss: 0.24312057259409278
Validation loss: 2.3925360876546233

Epoch: 5| Step: 1
Training loss: 0.2994973038972366
Validation loss: 2.401021926930781

Epoch: 5| Step: 2
Training loss: 0.32901086887636316
Validation loss: 2.416358495999065

Epoch: 5| Step: 3
Training loss: 0.26486436544207265
Validation loss: 2.413033092533659

Epoch: 5| Step: 4
Training loss: 0.3197460282819496
Validation loss: 2.414252129082084

Epoch: 5| Step: 5
Training loss: 0.45219167416115047
Validation loss: 2.397407396306506

Epoch: 5| Step: 6
Training loss: 0.4514325862502494
Validation loss: 2.399254021279293

Epoch: 5| Step: 7
Training loss: 0.28993302792823017
Validation loss: 2.4013819776446206

Epoch: 5| Step: 8
Training loss: 0.34330492032675625
Validation loss: 2.413491624123432

Epoch: 5| Step: 9
Training loss: 0.22018308896928593
Validation loss: 2.423891476181907

Epoch: 5| Step: 10
Training loss: 0.4985102722951897
Validation loss: 2.424790644977857

Epoch: 388| Step: 0
Training loss: 0.2301783105568019
Validation loss: 2.422087503320276

Epoch: 5| Step: 1
Training loss: 0.2550563732879871
Validation loss: 2.4023105606039477

Epoch: 5| Step: 2
Training loss: 0.2869804897497086
Validation loss: 2.418054915151659

Epoch: 5| Step: 3
Training loss: 0.4637424020067675
Validation loss: 2.447045874115062

Epoch: 5| Step: 4
Training loss: 0.29754325043419216
Validation loss: 2.4434580119658205

Epoch: 5| Step: 5
Training loss: 0.1650130234440917
Validation loss: 2.39518452580562

Epoch: 5| Step: 6
Training loss: 0.5191074162662038
Validation loss: 2.4291185136764932

Epoch: 5| Step: 7
Training loss: 0.26450950945559887
Validation loss: 2.394945047037407

Epoch: 5| Step: 8
Training loss: 0.3828207910379458
Validation loss: 2.4241134286449304

Epoch: 5| Step: 9
Training loss: 0.42773754519328544
Validation loss: 2.4427137501852

Epoch: 5| Step: 10
Training loss: 0.24882811571776944
Validation loss: 2.4375645744914074

Epoch: 389| Step: 0
Training loss: 0.26430276346032083
Validation loss: 2.406345113582578

Epoch: 5| Step: 1
Training loss: 0.2183019528439023
Validation loss: 2.4233850794739706

Epoch: 5| Step: 2
Training loss: 0.36485705545411884
Validation loss: 2.397071204710443

Epoch: 5| Step: 3
Training loss: 0.3257510274137512
Validation loss: 2.4446769841778218

Epoch: 5| Step: 4
Training loss: 0.19255459082610277
Validation loss: 2.411274460555067

Epoch: 5| Step: 5
Training loss: 0.29304821208342713
Validation loss: 2.4378516903474328

Epoch: 5| Step: 6
Training loss: 0.43785162827791346
Validation loss: 2.4542760291638475

Epoch: 5| Step: 7
Training loss: 0.308958104074144
Validation loss: 2.4436785082775114

Epoch: 5| Step: 8
Training loss: 0.41933169031857365
Validation loss: 2.426399553621452

Epoch: 5| Step: 9
Training loss: 0.48104818806689137
Validation loss: 2.4157690896210036

Epoch: 5| Step: 10
Training loss: 0.25756167724041046
Validation loss: 2.415127960963038

Epoch: 390| Step: 0
Training loss: 0.42249766069814226
Validation loss: 2.419826074599731

Epoch: 5| Step: 1
Training loss: 0.3552478900634689
Validation loss: 2.428253945855094

Epoch: 5| Step: 2
Training loss: 0.32635870739314293
Validation loss: 2.4140242271470442

Epoch: 5| Step: 3
Training loss: 0.49075836507204196
Validation loss: 2.4054441515639824

Epoch: 5| Step: 4
Training loss: 0.2990035495834421
Validation loss: 2.393226784661156

Epoch: 5| Step: 5
Training loss: 0.226566816157302
Validation loss: 2.3937919760384654

Epoch: 5| Step: 6
Training loss: 0.25205908624563483
Validation loss: 2.430027927099957

Epoch: 5| Step: 7
Training loss: 0.2086591685863552
Validation loss: 2.395343636486439

Epoch: 5| Step: 8
Training loss: 0.209858234925305
Validation loss: 2.4177119984358

Epoch: 5| Step: 9
Training loss: 0.28644699449928407
Validation loss: 2.418694411004623

Epoch: 5| Step: 10
Training loss: 0.41827062596881875
Validation loss: 2.4059885162885366

Epoch: 391| Step: 0
Training loss: 0.3697644971439031
Validation loss: 2.4262624365764722

Epoch: 5| Step: 1
Training loss: 0.2956054042265374
Validation loss: 2.427217047209087

Epoch: 5| Step: 2
Training loss: 0.38418069906251867
Validation loss: 2.413519678051043

Epoch: 5| Step: 3
Training loss: 0.24705539251217934
Validation loss: 2.4250680178343034

Epoch: 5| Step: 4
Training loss: 0.3039056331755745
Validation loss: 2.4325762862797626

Epoch: 5| Step: 5
Training loss: 0.4616616428385362
Validation loss: 2.437347209591675

Epoch: 5| Step: 6
Training loss: 0.3133501766607597
Validation loss: 2.4303314439277375

Epoch: 5| Step: 7
Training loss: 0.2716908253101398
Validation loss: 2.4480421367074823

Epoch: 5| Step: 8
Training loss: 0.4256270593153644
Validation loss: 2.403940363120931

Epoch: 5| Step: 9
Training loss: 0.2263339468352393
Validation loss: 2.4158349241294994

Epoch: 5| Step: 10
Training loss: 0.1947479481178873
Validation loss: 2.4173977122391705

Epoch: 392| Step: 0
Training loss: 0.4229734038205098
Validation loss: 2.4140372740425815

Epoch: 5| Step: 1
Training loss: 0.36154512642255776
Validation loss: 2.409087966618904

Epoch: 5| Step: 2
Training loss: 0.30814800180464774
Validation loss: 2.399605040413365

Epoch: 5| Step: 3
Training loss: 0.32514444589154884
Validation loss: 2.4194299015583094

Epoch: 5| Step: 4
Training loss: 0.21598577413855724
Validation loss: 2.436865988902254

Epoch: 5| Step: 5
Training loss: 0.422046785347614
Validation loss: 2.418471297111857

Epoch: 5| Step: 6
Training loss: 0.2550679845970395
Validation loss: 2.398529855822469

Epoch: 5| Step: 7
Training loss: 0.25921095520771853
Validation loss: 2.389464657944216

Epoch: 5| Step: 8
Training loss: 0.18282886211825997
Validation loss: 2.4200235382694046

Epoch: 5| Step: 9
Training loss: 0.4353600002752968
Validation loss: 2.3910225764099127

Epoch: 5| Step: 10
Training loss: 0.3551781692823169
Validation loss: 2.419060999414704

Epoch: 393| Step: 0
Training loss: 0.23106348757781717
Validation loss: 2.393823416358453

Epoch: 5| Step: 1
Training loss: 0.410315509939085
Validation loss: 2.425275338782694

Epoch: 5| Step: 2
Training loss: 0.47333229205303545
Validation loss: 2.4251610233815444

Epoch: 5| Step: 3
Training loss: 0.4841722402426912
Validation loss: 2.4416784962453613

Epoch: 5| Step: 4
Training loss: 0.3273844195209146
Validation loss: 2.419076727363274

Epoch: 5| Step: 5
Training loss: 0.30547229247709895
Validation loss: 2.4192840170663605

Epoch: 5| Step: 6
Training loss: 0.17115806476869982
Validation loss: 2.40882275632663

Epoch: 5| Step: 7
Training loss: 0.20029131750563497
Validation loss: 2.4051467897937466

Epoch: 5| Step: 8
Training loss: 0.2413029900474867
Validation loss: 2.417913112974051

Epoch: 5| Step: 9
Training loss: 0.14637412054553464
Validation loss: 2.39120433912692

Epoch: 5| Step: 10
Training loss: 0.4410020277091313
Validation loss: 2.406543163546982

Epoch: 394| Step: 0
Training loss: 0.25155652791392014
Validation loss: 2.3995897724404025

Epoch: 5| Step: 1
Training loss: 0.42195669019069093
Validation loss: 2.3721642925176774

Epoch: 5| Step: 2
Training loss: 0.26445970456659523
Validation loss: 2.399262201821691

Epoch: 5| Step: 3
Training loss: 0.46157689117951656
Validation loss: 2.4005689236769197

Epoch: 5| Step: 4
Training loss: 0.35828670246352384
Validation loss: 2.4049305786983877

Epoch: 5| Step: 5
Training loss: 0.38023223105101084
Validation loss: 2.3828703272308553

Epoch: 5| Step: 6
Training loss: 0.3383923482495654
Validation loss: 2.400040487705046

Epoch: 5| Step: 7
Training loss: 0.32303627808613616
Validation loss: 2.413299341155583

Epoch: 5| Step: 8
Training loss: 0.25275403260278784
Validation loss: 2.4168472144802697

Epoch: 5| Step: 9
Training loss: 0.2857477637351132
Validation loss: 2.3946694838029305

Epoch: 5| Step: 10
Training loss: 0.27662576501381125
Validation loss: 2.4190093203924135

Epoch: 395| Step: 0
Training loss: 0.3583824299659822
Validation loss: 2.437097401549416

Epoch: 5| Step: 1
Training loss: 0.4441338383433737
Validation loss: 2.421703563051407

Epoch: 5| Step: 2
Training loss: 0.2782121414655991
Validation loss: 2.406669402225619

Epoch: 5| Step: 3
Training loss: 0.2567379405533426
Validation loss: 2.390052977373093

Epoch: 5| Step: 4
Training loss: 0.20646017412666756
Validation loss: 2.39152275149247

Epoch: 5| Step: 5
Training loss: 0.35806110940597613
Validation loss: 2.409622811713452

Epoch: 5| Step: 6
Training loss: 0.4153467630930447
Validation loss: 2.411396316485311

Epoch: 5| Step: 7
Training loss: 0.3486334963666262
Validation loss: 2.3907065407459704

Epoch: 5| Step: 8
Training loss: 0.3233399027389708
Validation loss: 2.42621445017268

Epoch: 5| Step: 9
Training loss: 0.38309044381851304
Validation loss: 2.4143783878243408

Epoch: 5| Step: 10
Training loss: 0.31841471840449537
Validation loss: 2.4227805570664054

Epoch: 396| Step: 0
Training loss: 0.2565889948175604
Validation loss: 2.4248234738188423

Epoch: 5| Step: 1
Training loss: 0.3790104909441324
Validation loss: 2.4590716232776035

Epoch: 5| Step: 2
Training loss: 0.476615824608334
Validation loss: 2.4251451340413084

Epoch: 5| Step: 3
Training loss: 0.4168111510902047
Validation loss: 2.4092848648430154

Epoch: 5| Step: 4
Training loss: 0.2733096505048617
Validation loss: 2.407988489320677

Epoch: 5| Step: 5
Training loss: 0.3042491180004353
Validation loss: 2.3997411423379207

Epoch: 5| Step: 6
Training loss: 0.32383889616387984
Validation loss: 2.4051909825758

Epoch: 5| Step: 7
Training loss: 0.3324086792923349
Validation loss: 2.384257420775887

Epoch: 5| Step: 8
Training loss: 0.24869675993858412
Validation loss: 2.3826480081804813

Epoch: 5| Step: 9
Training loss: 0.3197404358591431
Validation loss: 2.4004056411703756

Epoch: 5| Step: 10
Training loss: 0.4013069089004869
Validation loss: 2.3887933444240903

Epoch: 397| Step: 0
Training loss: 0.18526357807496674
Validation loss: 2.397404866249681

Epoch: 5| Step: 1
Training loss: 0.18388844234491408
Validation loss: 2.3905387668229596

Epoch: 5| Step: 2
Training loss: 0.2027717048807624
Validation loss: 2.40297253844612

Epoch: 5| Step: 3
Training loss: 0.3935962020900618
Validation loss: 2.3968706618374833

Epoch: 5| Step: 4
Training loss: 0.35323388902069947
Validation loss: 2.4121490189624644

Epoch: 5| Step: 5
Training loss: 0.2546481810099022
Validation loss: 2.4161282854800423

Epoch: 5| Step: 6
Training loss: 0.3462973084304411
Validation loss: 2.3686319922518546

Epoch: 5| Step: 7
Training loss: 0.32991776718772864
Validation loss: 2.409001302485297

Epoch: 5| Step: 8
Training loss: 0.5847445742195156
Validation loss: 2.4124605246482047

Epoch: 5| Step: 9
Training loss: 0.41912636923744084
Validation loss: 2.4123610432114573

Epoch: 5| Step: 10
Training loss: 0.29591500516027736
Validation loss: 2.40882309370057

Epoch: 398| Step: 0
Training loss: 0.37765431783589865
Validation loss: 2.381184812753852

Epoch: 5| Step: 1
Training loss: 0.4102751060117041
Validation loss: 2.3991673224844265

Epoch: 5| Step: 2
Training loss: 0.32020784622276116
Validation loss: 2.4228999929798105

Epoch: 5| Step: 3
Training loss: 0.2771626136170522
Validation loss: 2.410385345650571

Epoch: 5| Step: 4
Training loss: 0.36892601112133583
Validation loss: 2.4200063068969087

Epoch: 5| Step: 5
Training loss: 0.374873974604411
Validation loss: 2.4500614791608397

Epoch: 5| Step: 6
Training loss: 0.26201200424787313
Validation loss: 2.4073740040337595

Epoch: 5| Step: 7
Training loss: 0.34187882667087544
Validation loss: 2.398136935771815

Epoch: 5| Step: 8
Training loss: 0.2925090107181955
Validation loss: 2.4180092425594375

Epoch: 5| Step: 9
Training loss: 0.21630315149491908
Validation loss: 2.4202355558905992

Epoch: 5| Step: 10
Training loss: 0.39003369399775834
Validation loss: 2.4420005136125353

Epoch: 399| Step: 0
Training loss: 0.40877203106201254
Validation loss: 2.457853869787999

Epoch: 5| Step: 1
Training loss: 0.28857793660358855
Validation loss: 2.417049432455512

Epoch: 5| Step: 2
Training loss: 0.33789664467096525
Validation loss: 2.4144074024732514

Epoch: 5| Step: 3
Training loss: 0.25798153393294493
Validation loss: 2.420128357160515

Epoch: 5| Step: 4
Training loss: 0.42181897674440055
Validation loss: 2.393563187416908

Epoch: 5| Step: 5
Training loss: 0.30476257426346776
Validation loss: 2.4047368281536503

Epoch: 5| Step: 6
Training loss: 0.23961773483722798
Validation loss: 2.3861938799553233

Epoch: 5| Step: 7
Training loss: 0.4599599817999045
Validation loss: 2.4022565693630455

Epoch: 5| Step: 8
Training loss: 0.25361422838600456
Validation loss: 2.370092551679086

Epoch: 5| Step: 9
Training loss: 0.44800920602480454
Validation loss: 2.3900772980440452

Epoch: 5| Step: 10
Training loss: 0.23807460391800706
Validation loss: 2.383459072387437

Epoch: 400| Step: 0
Training loss: 0.43111062631069097
Validation loss: 2.3835679735243613

Epoch: 5| Step: 1
Training loss: 0.25765490772737426
Validation loss: 2.4043516616961487

Epoch: 5| Step: 2
Training loss: 0.38074110102006825
Validation loss: 2.3836938587357808

Epoch: 5| Step: 3
Training loss: 0.23525688831407637
Validation loss: 2.3789724855368677

Epoch: 5| Step: 4
Training loss: 0.3334340363119711
Validation loss: 2.4001587969448215

Epoch: 5| Step: 5
Training loss: 0.4134326859278245
Validation loss: 2.4402315260165786

Epoch: 5| Step: 6
Training loss: 0.3829836560091189
Validation loss: 2.4170879061247104

Epoch: 5| Step: 7
Training loss: 0.3323503419538896
Validation loss: 2.445223204915215

Epoch: 5| Step: 8
Training loss: 0.4452496869141272
Validation loss: 2.3950372501319244

Epoch: 5| Step: 9
Training loss: 0.253865722943161
Validation loss: 2.405445660688191

Epoch: 5| Step: 10
Training loss: 0.20057602944274538
Validation loss: 2.395700741202439

Epoch: 401| Step: 0
Training loss: 0.3198085984936418
Validation loss: 2.3917428307419906

Epoch: 5| Step: 1
Training loss: 0.3954879567377961
Validation loss: 2.3930318888715414

Epoch: 5| Step: 2
Training loss: 0.4821524543412539
Validation loss: 2.42396732048403

Epoch: 5| Step: 3
Training loss: 0.2960247361972491
Validation loss: 2.374096332037568

Epoch: 5| Step: 4
Training loss: 0.2763437995854521
Validation loss: 2.385771619717884

Epoch: 5| Step: 5
Training loss: 0.3748490109060569
Validation loss: 2.3693394325566515

Epoch: 5| Step: 6
Training loss: 0.40680310304085576
Validation loss: 2.3725252956454077

Epoch: 5| Step: 7
Training loss: 0.3436253061414613
Validation loss: 2.3963376114190527

Epoch: 5| Step: 8
Training loss: 0.1619494810122259
Validation loss: 2.3701233821096213

Epoch: 5| Step: 9
Training loss: 0.24752625323745914
Validation loss: 2.367263444545761

Epoch: 5| Step: 10
Training loss: 0.29150896690998235
Validation loss: 2.386038402611373

Epoch: 402| Step: 0
Training loss: 0.4143628884180957
Validation loss: 2.3810328192827686

Epoch: 5| Step: 1
Training loss: 0.22734550298427889
Validation loss: 2.3883780924767595

Epoch: 5| Step: 2
Training loss: 0.37134354867330216
Validation loss: 2.3774727651820244

Epoch: 5| Step: 3
Training loss: 0.4096101485904808
Validation loss: 2.4063311284695432

Epoch: 5| Step: 4
Training loss: 0.4140904255213139
Validation loss: 2.419563934731502

Epoch: 5| Step: 5
Training loss: 0.28908359605257294
Validation loss: 2.405163798531033

Epoch: 5| Step: 6
Training loss: 0.2895375935476661
Validation loss: 2.4280652999639067

Epoch: 5| Step: 7
Training loss: 0.2859006858014891
Validation loss: 2.3996792955855515

Epoch: 5| Step: 8
Training loss: 0.29398950136912055
Validation loss: 2.3757978425836486

Epoch: 5| Step: 9
Training loss: 0.23922807936911447
Validation loss: 2.402125206561111

Epoch: 5| Step: 10
Training loss: 0.21188765682124414
Validation loss: 2.436857929335796

Epoch: 403| Step: 0
Training loss: 0.3315372831730716
Validation loss: 2.4125526050560198

Epoch: 5| Step: 1
Training loss: 0.3107788131487913
Validation loss: 2.4305970438528313

Epoch: 5| Step: 2
Training loss: 0.2981346785975592
Validation loss: 2.4364558050786145

Epoch: 5| Step: 3
Training loss: 0.2217718932516327
Validation loss: 2.432167186442766

Epoch: 5| Step: 4
Training loss: 0.2366508455736104
Validation loss: 2.451273166740523

Epoch: 5| Step: 5
Training loss: 0.5003689954074833
Validation loss: 2.4382173982815964

Epoch: 5| Step: 6
Training loss: 0.3562412043372416
Validation loss: 2.463060601365506

Epoch: 5| Step: 7
Training loss: 0.35368269455296597
Validation loss: 2.446125334566633

Epoch: 5| Step: 8
Training loss: 0.2865465577411523
Validation loss: 2.457554736832365

Epoch: 5| Step: 9
Training loss: 0.24558089571328673
Validation loss: 2.4441924772451444

Epoch: 5| Step: 10
Training loss: 0.15445864321701863
Validation loss: 2.4193405253831233

Epoch: 404| Step: 0
Training loss: 0.4939193531725139
Validation loss: 2.4087181425836794

Epoch: 5| Step: 1
Training loss: 0.21913798019526728
Validation loss: 2.4164610889507516

Epoch: 5| Step: 2
Training loss: 0.12656299361379933
Validation loss: 2.4134947215326883

Epoch: 5| Step: 3
Training loss: 0.37209672408590533
Validation loss: 2.404002808343638

Epoch: 5| Step: 4
Training loss: 0.2786716719557929
Validation loss: 2.427850785632947

Epoch: 5| Step: 5
Training loss: 0.23527927000672105
Validation loss: 2.410045460683379

Epoch: 5| Step: 6
Training loss: 0.4469192362945069
Validation loss: 2.430300743313422

Epoch: 5| Step: 7
Training loss: 0.20229742300451833
Validation loss: 2.411643364788047

Epoch: 5| Step: 8
Training loss: 0.3120334002822344
Validation loss: 2.4145814034150437

Epoch: 5| Step: 9
Training loss: 0.23741559392184167
Validation loss: 2.4126190867917106

Epoch: 5| Step: 10
Training loss: 0.3796575903395121
Validation loss: 2.38692433347728

Epoch: 405| Step: 0
Training loss: 0.43708251720615315
Validation loss: 2.4336452488887033

Epoch: 5| Step: 1
Training loss: 0.29009139747984836
Validation loss: 2.3962968574967576

Epoch: 5| Step: 2
Training loss: 0.26795294189535845
Validation loss: 2.4220469963826066

Epoch: 5| Step: 3
Training loss: 0.42697201030038967
Validation loss: 2.4181552272806552

Epoch: 5| Step: 4
Training loss: 0.2773075617431562
Validation loss: 2.3870618672342108

Epoch: 5| Step: 5
Training loss: 0.32344879508452307
Validation loss: 2.377130321550085

Epoch: 5| Step: 6
Training loss: 0.20336299488540377
Validation loss: 2.385859054581456

Epoch: 5| Step: 7
Training loss: 0.24930212844386843
Validation loss: 2.43024141483856

Epoch: 5| Step: 8
Training loss: 0.2796094385889391
Validation loss: 2.3979536485498802

Epoch: 5| Step: 9
Training loss: 0.28270518495600566
Validation loss: 2.3840282182577464

Epoch: 5| Step: 10
Training loss: 0.30632418201168893
Validation loss: 2.4133524352375844

Epoch: 406| Step: 0
Training loss: 0.2439775303623522
Validation loss: 2.38813882699676

Epoch: 5| Step: 1
Training loss: 0.269721710249826
Validation loss: 2.399826379318854

Epoch: 5| Step: 2
Training loss: 0.31223894182297846
Validation loss: 2.365999345240006

Epoch: 5| Step: 3
Training loss: 0.30071647987036093
Validation loss: 2.4207378849910635

Epoch: 5| Step: 4
Training loss: 0.33386487105532137
Validation loss: 2.3905607801070623

Epoch: 5| Step: 5
Training loss: 0.408503754808639
Validation loss: 2.3674456729280653

Epoch: 5| Step: 6
Training loss: 0.29459668856719484
Validation loss: 2.41139151536135

Epoch: 5| Step: 7
Training loss: 0.2560249840961277
Validation loss: 2.401286744343101

Epoch: 5| Step: 8
Training loss: 0.2554143573590212
Validation loss: 2.408937687422263

Epoch: 5| Step: 9
Training loss: 0.4517437336892938
Validation loss: 2.4266402549460255

Epoch: 5| Step: 10
Training loss: 0.2651327424427388
Validation loss: 2.418483942649988

Epoch: 407| Step: 0
Training loss: 0.2787378892919192
Validation loss: 2.416352211441092

Epoch: 5| Step: 1
Training loss: 0.2537140045098102
Validation loss: 2.4132722906733273

Epoch: 5| Step: 2
Training loss: 0.21864835898212948
Validation loss: 2.412580370245708

Epoch: 5| Step: 3
Training loss: 0.3058950386350537
Validation loss: 2.415773616212114

Epoch: 5| Step: 4
Training loss: 0.3397380620670992
Validation loss: 2.4566517357511573

Epoch: 5| Step: 5
Training loss: 0.3276381172798428
Validation loss: 2.4309991854955935

Epoch: 5| Step: 6
Training loss: 0.36811326382230153
Validation loss: 2.4322222304735304

Epoch: 5| Step: 7
Training loss: 0.44782515263701506
Validation loss: 2.436027543829685

Epoch: 5| Step: 8
Training loss: 0.2966570179397993
Validation loss: 2.4184343936413453

Epoch: 5| Step: 9
Training loss: 0.14654872116803438
Validation loss: 2.4453530178325606

Epoch: 5| Step: 10
Training loss: 0.31520276720679746
Validation loss: 2.4294932076410456

Epoch: 408| Step: 0
Training loss: 0.4204381740684317
Validation loss: 2.4382576544535035

Epoch: 5| Step: 1
Training loss: 0.34366986034138397
Validation loss: 2.4227317784449376

Epoch: 5| Step: 2
Training loss: 0.4418257686162145
Validation loss: 2.4229925926634652

Epoch: 5| Step: 3
Training loss: 0.2548533747835958
Validation loss: 2.41546253885452

Epoch: 5| Step: 4
Training loss: 0.330664322971843
Validation loss: 2.3781188074327524

Epoch: 5| Step: 5
Training loss: 0.1991386158910295
Validation loss: 2.386270082297792

Epoch: 5| Step: 6
Training loss: 0.2909386040065318
Validation loss: 2.4023362245065822

Epoch: 5| Step: 7
Training loss: 0.32062502478065913
Validation loss: 2.380218141431955

Epoch: 5| Step: 8
Training loss: 0.17521590874084317
Validation loss: 2.377509046631618

Epoch: 5| Step: 9
Training loss: 0.27100128993645844
Validation loss: 2.383800662251443

Epoch: 5| Step: 10
Training loss: 0.3046779508806041
Validation loss: 2.4198150236416427

Epoch: 409| Step: 0
Training loss: 0.27309307477024886
Validation loss: 2.385292847088645

Epoch: 5| Step: 1
Training loss: 0.1840540007035958
Validation loss: 2.399642552890087

Epoch: 5| Step: 2
Training loss: 0.16538710265627599
Validation loss: 2.3880504428692158

Epoch: 5| Step: 3
Training loss: 0.18032811865770623
Validation loss: 2.4210805330180873

Epoch: 5| Step: 4
Training loss: 0.31985368665681824
Validation loss: 2.3953493019013923

Epoch: 5| Step: 5
Training loss: 0.1097894844582368
Validation loss: 2.3986380807431975

Epoch: 5| Step: 6
Training loss: 0.435537688838411
Validation loss: 2.4219303036136868

Epoch: 5| Step: 7
Training loss: 0.42671254002994746
Validation loss: 2.4127029576707755

Epoch: 5| Step: 8
Training loss: 0.21024183955384732
Validation loss: 2.416341883553882

Epoch: 5| Step: 9
Training loss: 0.33283223420499525
Validation loss: 2.420302056969302

Epoch: 5| Step: 10
Training loss: 0.3520541250464252
Validation loss: 2.4322760066037077

Epoch: 410| Step: 0
Training loss: 0.3952674606358429
Validation loss: 2.428519555528251

Epoch: 5| Step: 1
Training loss: 0.33400130647272436
Validation loss: 2.4357070507694236

Epoch: 5| Step: 2
Training loss: 0.37155215410181264
Validation loss: 2.4706488041773453

Epoch: 5| Step: 3
Training loss: 0.26480313386305193
Validation loss: 2.4516040755157773

Epoch: 5| Step: 4
Training loss: 0.4291167022576213
Validation loss: 2.441546083445062

Epoch: 5| Step: 5
Training loss: 0.1368129541913227
Validation loss: 2.431741260683668

Epoch: 5| Step: 6
Training loss: 0.24205914295399
Validation loss: 2.445711422493786

Epoch: 5| Step: 7
Training loss: 0.3331489375819877
Validation loss: 2.476692448618207

Epoch: 5| Step: 8
Training loss: 0.23489010156093423
Validation loss: 2.4417993005179706

Epoch: 5| Step: 9
Training loss: 0.2810892466915402
Validation loss: 2.4387753486607853

Epoch: 5| Step: 10
Training loss: 0.23466829386421506
Validation loss: 2.425251762194194

Epoch: 411| Step: 0
Training loss: 0.3783474764231975
Validation loss: 2.4473119997353234

Epoch: 5| Step: 1
Training loss: 0.42139799914063814
Validation loss: 2.42269414465148

Epoch: 5| Step: 2
Training loss: 0.1951789399296746
Validation loss: 2.436721809530816

Epoch: 5| Step: 3
Training loss: 0.16355771792865778
Validation loss: 2.411263822793427

Epoch: 5| Step: 4
Training loss: 0.2502229411752143
Validation loss: 2.4154675945691877

Epoch: 5| Step: 5
Training loss: 0.2086754056859646
Validation loss: 2.4247450004041866

Epoch: 5| Step: 6
Training loss: 0.3478113749880903
Validation loss: 2.432087878760048

Epoch: 5| Step: 7
Training loss: 0.3478211108441645
Validation loss: 2.429217042915811

Epoch: 5| Step: 8
Training loss: 0.3972435621588582
Validation loss: 2.4100225914170426

Epoch: 5| Step: 9
Training loss: 0.305016450106119
Validation loss: 2.419942214139965

Epoch: 5| Step: 10
Training loss: 0.28634675916376806
Validation loss: 2.445513365328911

Epoch: 412| Step: 0
Training loss: 0.2594786184226765
Validation loss: 2.3794475727360287

Epoch: 5| Step: 1
Training loss: 0.24115506965355266
Validation loss: 2.4221652399200257

Epoch: 5| Step: 2
Training loss: 0.314373385347501
Validation loss: 2.4087306780814206

Epoch: 5| Step: 3
Training loss: 0.3517523676711909
Validation loss: 2.397054398705645

Epoch: 5| Step: 4
Training loss: 0.2700748076606213
Validation loss: 2.4045875734578313

Epoch: 5| Step: 5
Training loss: 0.33983211935902874
Validation loss: 2.3873541741209725

Epoch: 5| Step: 6
Training loss: 0.29872565912500737
Validation loss: 2.4097644299078183

Epoch: 5| Step: 7
Training loss: 0.33783431493526844
Validation loss: 2.428587174616598

Epoch: 5| Step: 8
Training loss: 0.2261691542941093
Validation loss: 2.424416945720756

Epoch: 5| Step: 9
Training loss: 0.4014797748896724
Validation loss: 2.402558278542018

Epoch: 5| Step: 10
Training loss: 0.21315497862936258
Validation loss: 2.388493056372159

Epoch: 413| Step: 0
Training loss: 0.10223493433173599
Validation loss: 2.4233069911074088

Epoch: 5| Step: 1
Training loss: 0.3001792630414337
Validation loss: 2.4132774248067856

Epoch: 5| Step: 2
Training loss: 0.25451968989339574
Validation loss: 2.409286958394024

Epoch: 5| Step: 3
Training loss: 0.41593683419005933
Validation loss: 2.392487274782257

Epoch: 5| Step: 4
Training loss: 0.29070739295981973
Validation loss: 2.407308113853201

Epoch: 5| Step: 5
Training loss: 0.30849787272936313
Validation loss: 2.3878739235393973

Epoch: 5| Step: 6
Training loss: 0.40356879165634313
Validation loss: 2.4224710917123997

Epoch: 5| Step: 7
Training loss: 0.3072182263154607
Validation loss: 2.4202683172903594

Epoch: 5| Step: 8
Training loss: 0.14716191320484584
Validation loss: 2.4104589975262054

Epoch: 5| Step: 9
Training loss: 0.23625064399419538
Validation loss: 2.4246907738891723

Epoch: 5| Step: 10
Training loss: 0.2013403640626964
Validation loss: 2.4501871733147174

Epoch: 414| Step: 0
Training loss: 0.31075727185190477
Validation loss: 2.428079981329876

Epoch: 5| Step: 1
Training loss: 0.25014175925854587
Validation loss: 2.4432536092348602

Epoch: 5| Step: 2
Training loss: 0.44952073934530234
Validation loss: 2.4182281442474727

Epoch: 5| Step: 3
Training loss: 0.17755870731389153
Validation loss: 2.416003212189055

Epoch: 5| Step: 4
Training loss: 0.2617396161316005
Validation loss: 2.4224707858709005

Epoch: 5| Step: 5
Training loss: 0.29760354143574835
Validation loss: 2.4204452544441626

Epoch: 5| Step: 6
Training loss: 0.3450587565898376
Validation loss: 2.4319245561893785

Epoch: 5| Step: 7
Training loss: 0.2922862941568123
Validation loss: 2.412125449052108

Epoch: 5| Step: 8
Training loss: 0.27118993476465714
Validation loss: 2.4414482155751447

Epoch: 5| Step: 9
Training loss: 0.2656879630918198
Validation loss: 2.4070128377117617

Epoch: 5| Step: 10
Training loss: 0.1833944659468303
Validation loss: 2.4419383093792555

Epoch: 415| Step: 0
Training loss: 0.37074827877913274
Validation loss: 2.4089369696054947

Epoch: 5| Step: 1
Training loss: 0.18864633888887447
Validation loss: 2.4200279239550997

Epoch: 5| Step: 2
Training loss: 0.2930061316483282
Validation loss: 2.4312271828216967

Epoch: 5| Step: 3
Training loss: 0.4088514919153018
Validation loss: 2.4144138678224354

Epoch: 5| Step: 4
Training loss: 0.469288405520894
Validation loss: 2.431458290229833

Epoch: 5| Step: 5
Training loss: 0.28098813422780716
Validation loss: 2.4134118867731784

Epoch: 5| Step: 6
Training loss: 0.21856748255416486
Validation loss: 2.448128859190805

Epoch: 5| Step: 7
Training loss: 0.15600268938309375
Validation loss: 2.442711651174019

Epoch: 5| Step: 8
Training loss: 0.23996355717610876
Validation loss: 2.4315901506132858

Epoch: 5| Step: 9
Training loss: 0.16820890424680487
Validation loss: 2.44982351697523

Epoch: 5| Step: 10
Training loss: 0.15514195471424375
Validation loss: 2.44521383614407

Epoch: 416| Step: 0
Training loss: 0.2037846601002278
Validation loss: 2.410584448344261

Epoch: 5| Step: 1
Training loss: 0.3341623690836967
Validation loss: 2.4135451898361415

Epoch: 5| Step: 2
Training loss: 0.20347357148879308
Validation loss: 2.4252493584348045

Epoch: 5| Step: 3
Training loss: 0.30432750758287513
Validation loss: 2.418867189969031

Epoch: 5| Step: 4
Training loss: 0.38321633350189327
Validation loss: 2.4314425105759505

Epoch: 5| Step: 5
Training loss: 0.3355240384414318
Validation loss: 2.444588368508451

Epoch: 5| Step: 6
Training loss: 0.2295933683020193
Validation loss: 2.4072128924179457

Epoch: 5| Step: 7
Training loss: 0.29618106852928383
Validation loss: 2.4259830329038676

Epoch: 5| Step: 8
Training loss: 0.3336890069006179
Validation loss: 2.421025374123629

Epoch: 5| Step: 9
Training loss: 0.2330374779566635
Validation loss: 2.4300190293484274

Epoch: 5| Step: 10
Training loss: 0.31852514245730906
Validation loss: 2.3975001810346175

Epoch: 417| Step: 0
Training loss: 0.2611864855094609
Validation loss: 2.440726106537399

Epoch: 5| Step: 1
Training loss: 0.27757485928642267
Validation loss: 2.413928380136257

Epoch: 5| Step: 2
Training loss: 0.2946387694228024
Validation loss: 2.4205994283883574

Epoch: 5| Step: 3
Training loss: 0.32770915019609936
Validation loss: 2.4174991948052527

Epoch: 5| Step: 4
Training loss: 0.30860083608096867
Validation loss: 2.4032151013354963

Epoch: 5| Step: 5
Training loss: 0.4673688727857428
Validation loss: 2.415511470107646

Epoch: 5| Step: 6
Training loss: 0.20475196332886827
Validation loss: 2.4177238325340333

Epoch: 5| Step: 7
Training loss: 0.18175562427875175
Validation loss: 2.376028556010892

Epoch: 5| Step: 8
Training loss: 0.20438710913234365
Validation loss: 2.3932124400888597

Epoch: 5| Step: 9
Training loss: 0.2405740228754017
Validation loss: 2.4010347065446456

Epoch: 5| Step: 10
Training loss: 0.2586434152397679
Validation loss: 2.389768838704162

Epoch: 418| Step: 0
Training loss: 0.13347201824406957
Validation loss: 2.405943592274484

Epoch: 5| Step: 1
Training loss: 0.39515116117013094
Validation loss: 2.375122507559375

Epoch: 5| Step: 2
Training loss: 0.2614151774020381
Validation loss: 2.4086003655335113

Epoch: 5| Step: 3
Training loss: 0.19603362472496902
Validation loss: 2.4027569924700565

Epoch: 5| Step: 4
Training loss: 0.340782600655518
Validation loss: 2.3810199172392865

Epoch: 5| Step: 5
Training loss: 0.27073976233016334
Validation loss: 2.4041865527688246

Epoch: 5| Step: 6
Training loss: 0.1496516999516638
Validation loss: 2.4096397752913337

Epoch: 5| Step: 7
Training loss: 0.41273183954352954
Validation loss: 2.3831013192962964

Epoch: 5| Step: 8
Training loss: 0.31991974081182273
Validation loss: 2.4187641277887932

Epoch: 5| Step: 9
Training loss: 0.23081171250538238
Validation loss: 2.3990562223181318

Epoch: 5| Step: 10
Training loss: 0.2379301721057206
Validation loss: 2.4161218963397846

Epoch: 419| Step: 0
Training loss: 0.25429481704746437
Validation loss: 2.390997215665044

Epoch: 5| Step: 1
Training loss: 0.24816072659597407
Validation loss: 2.3942156137693607

Epoch: 5| Step: 2
Training loss: 0.2068274772722085
Validation loss: 2.4111808433459108

Epoch: 5| Step: 3
Training loss: 0.2323477330280088
Validation loss: 2.392689704360888

Epoch: 5| Step: 4
Training loss: 0.23157492762587853
Validation loss: 2.3739284770861886

Epoch: 5| Step: 5
Training loss: 0.37880961178797445
Validation loss: 2.3995202923746417

Epoch: 5| Step: 6
Training loss: 0.3090099111968977
Validation loss: 2.379499869104563

Epoch: 5| Step: 7
Training loss: 0.3002877707923158
Validation loss: 2.4094770324765364

Epoch: 5| Step: 8
Training loss: 0.29928818985085565
Validation loss: 2.3946520967526514

Epoch: 5| Step: 9
Training loss: 0.3167900065889872
Validation loss: 2.42259024631576

Epoch: 5| Step: 10
Training loss: 0.2145877353130283
Validation loss: 2.396174612968814

Epoch: 420| Step: 0
Training loss: 0.2412873814953322
Validation loss: 2.3804744735830914

Epoch: 5| Step: 1
Training loss: 0.3438113981380812
Validation loss: 2.4102220585959833

Epoch: 5| Step: 2
Training loss: 0.13668955082394885
Validation loss: 2.3763429663772944

Epoch: 5| Step: 3
Training loss: 0.36299682065265004
Validation loss: 2.4146960168902276

Epoch: 5| Step: 4
Training loss: 0.24492770922707172
Validation loss: 2.396255512322681

Epoch: 5| Step: 5
Training loss: 0.24297847329705044
Validation loss: 2.416776013013338

Epoch: 5| Step: 6
Training loss: 0.20195765868360807
Validation loss: 2.4187705661240306

Epoch: 5| Step: 7
Training loss: 0.37887761902541073
Validation loss: 2.430830341272037

Epoch: 5| Step: 8
Training loss: 0.4127693315700495
Validation loss: 2.420431999540537

Epoch: 5| Step: 9
Training loss: 0.20976603133235058
Validation loss: 2.405120818521048

Epoch: 5| Step: 10
Training loss: 0.15602887122703465
Validation loss: 2.4129988915843947

Epoch: 421| Step: 0
Training loss: 0.3451769213101005
Validation loss: 2.4248448438857295

Epoch: 5| Step: 1
Training loss: 0.22254492670454604
Validation loss: 2.430126958542122

Epoch: 5| Step: 2
Training loss: 0.21431109549150337
Validation loss: 2.4450951717215728

Epoch: 5| Step: 3
Training loss: 0.2576392487514573
Validation loss: 2.425398185125392

Epoch: 5| Step: 4
Training loss: 0.38713965966314895
Validation loss: 2.4226947118345987

Epoch: 5| Step: 5
Training loss: 0.2780686428534492
Validation loss: 2.4452299358141345

Epoch: 5| Step: 6
Training loss: 0.2392045097921481
Validation loss: 2.4435510949766535

Epoch: 5| Step: 7
Training loss: 0.3168345954536438
Validation loss: 2.4493013189345705

Epoch: 5| Step: 8
Training loss: 0.22326920446815152
Validation loss: 2.396323502107453

Epoch: 5| Step: 9
Training loss: 0.28893514353562527
Validation loss: 2.4394023382946823

Epoch: 5| Step: 10
Training loss: 0.33117700528263194
Validation loss: 2.4530574783282355

Epoch: 422| Step: 0
Training loss: 0.3615147701401213
Validation loss: 2.4504830659134584

Epoch: 5| Step: 1
Training loss: 0.22603306900467535
Validation loss: 2.433228278522684

Epoch: 5| Step: 2
Training loss: 0.25583336967339604
Validation loss: 2.4563327537710955

Epoch: 5| Step: 3
Training loss: 0.3148394989029579
Validation loss: 2.453597987051866

Epoch: 5| Step: 4
Training loss: 0.24795977497504382
Validation loss: 2.4763359281130644

Epoch: 5| Step: 5
Training loss: 0.2515468722873685
Validation loss: 2.4620617089344514

Epoch: 5| Step: 6
Training loss: 0.2930592079384465
Validation loss: 2.4327936290658965

Epoch: 5| Step: 7
Training loss: 0.34845923796445133
Validation loss: 2.444470078541181

Epoch: 5| Step: 8
Training loss: 0.2876122281539238
Validation loss: 2.4429763012711

Epoch: 5| Step: 9
Training loss: 0.17454341991140784
Validation loss: 2.423025654298191

Epoch: 5| Step: 10
Training loss: 0.19872772252390272
Validation loss: 2.4308791743726963

Epoch: 423| Step: 0
Training loss: 0.24223158804237543
Validation loss: 2.4302167007184585

Epoch: 5| Step: 1
Training loss: 0.25666881969609895
Validation loss: 2.455076215121655

Epoch: 5| Step: 2
Training loss: 0.16258538689588162
Validation loss: 2.429027312444663

Epoch: 5| Step: 3
Training loss: 0.15281888643231925
Validation loss: 2.4586667696280777

Epoch: 5| Step: 4
Training loss: 0.32617863630950605
Validation loss: 2.416745237593538

Epoch: 5| Step: 5
Training loss: 0.19864892809823742
Validation loss: 2.4139862552938034

Epoch: 5| Step: 6
Training loss: 0.203999060120825
Validation loss: 2.423890765702141

Epoch: 5| Step: 7
Training loss: 0.3632443111877354
Validation loss: 2.4360872133700293

Epoch: 5| Step: 8
Training loss: 0.4123229788477469
Validation loss: 2.432113559430389

Epoch: 5| Step: 9
Training loss: 0.2365288473151633
Validation loss: 2.421885662604501

Epoch: 5| Step: 10
Training loss: 0.24248894266845525
Validation loss: 2.4319152126131702

Epoch: 424| Step: 0
Training loss: 0.3087242309341718
Validation loss: 2.4077670244546034

Epoch: 5| Step: 1
Training loss: 0.3073952616086577
Validation loss: 2.4275340684501354

Epoch: 5| Step: 2
Training loss: 0.1920999878230034
Validation loss: 2.4269743570150157

Epoch: 5| Step: 3
Training loss: 0.25522867757453377
Validation loss: 2.421699319078499

Epoch: 5| Step: 4
Training loss: 0.29397193813450423
Validation loss: 2.4446396064210423

Epoch: 5| Step: 5
Training loss: 0.35741720561328355
Validation loss: 2.410320169574577

Epoch: 5| Step: 6
Training loss: 0.30653508307749333
Validation loss: 2.402606979103173

Epoch: 5| Step: 7
Training loss: 0.19172714543012065
Validation loss: 2.4331505339802546

Epoch: 5| Step: 8
Training loss: 0.17861091441176113
Validation loss: 2.4168174043885653

Epoch: 5| Step: 9
Training loss: 0.34122691998665106
Validation loss: 2.4306137946007853

Epoch: 5| Step: 10
Training loss: 0.18563705060035107
Validation loss: 2.443565144043658

Epoch: 425| Step: 0
Training loss: 0.33658629243887467
Validation loss: 2.4353373956887805

Epoch: 5| Step: 1
Training loss: 0.23875984219041954
Validation loss: 2.420624273530566

Epoch: 5| Step: 2
Training loss: 0.3655153101846874
Validation loss: 2.4309405026011297

Epoch: 5| Step: 3
Training loss: 0.3523030640314841
Validation loss: 2.408286108047938

Epoch: 5| Step: 4
Training loss: 0.2799267502109193
Validation loss: 2.4191446866948563

Epoch: 5| Step: 5
Training loss: 0.19878509483043355
Validation loss: 2.416267362738406

Epoch: 5| Step: 6
Training loss: 0.2322600626864883
Validation loss: 2.4015979990289433

Epoch: 5| Step: 7
Training loss: 0.2546330540038247
Validation loss: 2.3854456830511235

Epoch: 5| Step: 8
Training loss: 0.18182792031287362
Validation loss: 2.424108177070427

Epoch: 5| Step: 9
Training loss: 0.1762098491367021
Validation loss: 2.394608773639376

Epoch: 5| Step: 10
Training loss: 0.15752337262459207
Validation loss: 2.393362512345788

Epoch: 426| Step: 0
Training loss: 0.1925271552922377
Validation loss: 2.419678376827241

Epoch: 5| Step: 1
Training loss: 0.2194344422511158
Validation loss: 2.387645221192072

Epoch: 5| Step: 2
Training loss: 0.16827271924227974
Validation loss: 2.4211343580818383

Epoch: 5| Step: 3
Training loss: 0.4302908389554904
Validation loss: 2.441151696763945

Epoch: 5| Step: 4
Training loss: 0.37875388709991314
Validation loss: 2.431118873813779

Epoch: 5| Step: 5
Training loss: 0.2722990587413657
Validation loss: 2.4205345813551977

Epoch: 5| Step: 6
Training loss: 0.2771569415367825
Validation loss: 2.4323521670427253

Epoch: 5| Step: 7
Training loss: 0.14190457250111407
Validation loss: 2.4314548951773074

Epoch: 5| Step: 8
Training loss: 0.22199269182079784
Validation loss: 2.439312326597655

Epoch: 5| Step: 9
Training loss: 0.2967532184180452
Validation loss: 2.417142701992152

Epoch: 5| Step: 10
Training loss: 0.14670003909807391
Validation loss: 2.39157006670809

Epoch: 427| Step: 0
Training loss: 0.339153015342731
Validation loss: 2.396469756813253

Epoch: 5| Step: 1
Training loss: 0.28719804653108383
Validation loss: 2.410728053960653

Epoch: 5| Step: 2
Training loss: 0.4079509302847525
Validation loss: 2.4166169088953375

Epoch: 5| Step: 3
Training loss: 0.2128479153549403
Validation loss: 2.368917758746004

Epoch: 5| Step: 4
Training loss: 0.22942132058557588
Validation loss: 2.4257789313118483

Epoch: 5| Step: 5
Training loss: 0.23793487700992305
Validation loss: 2.4347661929088935

Epoch: 5| Step: 6
Training loss: 0.36026551994947253
Validation loss: 2.4270559446065887

Epoch: 5| Step: 7
Training loss: 0.18199394072936598
Validation loss: 2.432855188279998

Epoch: 5| Step: 8
Training loss: 0.15975353736199643
Validation loss: 2.4581708543274305

Epoch: 5| Step: 9
Training loss: 0.24203796538708303
Validation loss: 2.4177473505182476

Epoch: 5| Step: 10
Training loss: 0.19795276392136635
Validation loss: 2.4320786322609393

Epoch: 428| Step: 0
Training loss: 0.2149867968746886
Validation loss: 2.4456365777417477

Epoch: 5| Step: 1
Training loss: 0.3365487481604454
Validation loss: 2.458771814779138

Epoch: 5| Step: 2
Training loss: 0.3581575004782805
Validation loss: 2.4269510932298117

Epoch: 5| Step: 3
Training loss: 0.22942266019756816
Validation loss: 2.432291295482216

Epoch: 5| Step: 4
Training loss: 0.22600246963428108
Validation loss: 2.4304239260769913

Epoch: 5| Step: 5
Training loss: 0.22080937925163902
Validation loss: 2.408649257912125

Epoch: 5| Step: 6
Training loss: 0.3268321999780346
Validation loss: 2.4298047835140526

Epoch: 5| Step: 7
Training loss: 0.15267594505204649
Validation loss: 2.4240234610421156

Epoch: 5| Step: 8
Training loss: 0.25191040564042033
Validation loss: 2.405190846143386

Epoch: 5| Step: 9
Training loss: 0.32851129454163713
Validation loss: 2.408505409134764

Epoch: 5| Step: 10
Training loss: 0.2728116092907675
Validation loss: 2.406594738492015

Epoch: 429| Step: 0
Training loss: 0.3900830132827364
Validation loss: 2.4271827902536467

Epoch: 5| Step: 1
Training loss: 0.18798845959939794
Validation loss: 2.4092086131236927

Epoch: 5| Step: 2
Training loss: 0.20599577726045232
Validation loss: 2.4321085388453496

Epoch: 5| Step: 3
Training loss: 0.35319401142637014
Validation loss: 2.400681179764612

Epoch: 5| Step: 4
Training loss: 0.3737797354029719
Validation loss: 2.4196179318001434

Epoch: 5| Step: 5
Training loss: 0.16413229638403054
Validation loss: 2.3717392231765166

Epoch: 5| Step: 6
Training loss: 0.2650192590678789
Validation loss: 2.402877151068267

Epoch: 5| Step: 7
Training loss: 0.2519595271043826
Validation loss: 2.3802190386237756

Epoch: 5| Step: 8
Training loss: 0.22452340346597963
Validation loss: 2.38905199398241

Epoch: 5| Step: 9
Training loss: 0.25512464604406926
Validation loss: 2.382286916752149

Epoch: 5| Step: 10
Training loss: 0.23652577607741496
Validation loss: 2.4122685367675705

Epoch: 430| Step: 0
Training loss: 0.2174057443729962
Validation loss: 2.4021523164019194

Epoch: 5| Step: 1
Training loss: 0.3613979993736844
Validation loss: 2.458422611409813

Epoch: 5| Step: 2
Training loss: 0.25826211218020345
Validation loss: 2.441481392702819

Epoch: 5| Step: 3
Training loss: 0.22527365103563163
Validation loss: 2.4473060895457226

Epoch: 5| Step: 4
Training loss: 0.23664924778408702
Validation loss: 2.423393281171828

Epoch: 5| Step: 5
Training loss: 0.16699413387658932
Validation loss: 2.4411722712140795

Epoch: 5| Step: 6
Training loss: 0.24595925273693267
Validation loss: 2.4507249135147706

Epoch: 5| Step: 7
Training loss: 0.32547129699179267
Validation loss: 2.4400353115936877

Epoch: 5| Step: 8
Training loss: 0.26134029468431164
Validation loss: 2.4491256942429698

Epoch: 5| Step: 9
Training loss: 0.4125545140571135
Validation loss: 2.4599644943447574

Epoch: 5| Step: 10
Training loss: 0.16336521631722375
Validation loss: 2.445062986752409

Epoch: 431| Step: 0
Training loss: 0.1918260194812502
Validation loss: 2.4291017383695754

Epoch: 5| Step: 1
Training loss: 0.33172670871424775
Validation loss: 2.467790217949033

Epoch: 5| Step: 2
Training loss: 0.2062660778165808
Validation loss: 2.451124366319784

Epoch: 5| Step: 3
Training loss: 0.25804675181631626
Validation loss: 2.4486098195469705

Epoch: 5| Step: 4
Training loss: 0.27607854860659636
Validation loss: 2.4293096753935592

Epoch: 5| Step: 5
Training loss: 0.2431729326583646
Validation loss: 2.4582823353005803

Epoch: 5| Step: 6
Training loss: 0.28542004754971495
Validation loss: 2.448373042397882

Epoch: 5| Step: 7
Training loss: 0.37456920834063406
Validation loss: 2.436043171707711

Epoch: 5| Step: 8
Training loss: 0.2445557155496734
Validation loss: 2.465324040306735

Epoch: 5| Step: 9
Training loss: 0.20686934096038365
Validation loss: 2.4386627541325105

Epoch: 5| Step: 10
Training loss: 0.31777738253366755
Validation loss: 2.4523048239440017

Epoch: 432| Step: 0
Training loss: 0.2902032920242525
Validation loss: 2.45338077751865

Epoch: 5| Step: 1
Training loss: 0.16815021604095315
Validation loss: 2.4339847832892163

Epoch: 5| Step: 2
Training loss: 0.26624647534414897
Validation loss: 2.455987067355825

Epoch: 5| Step: 3
Training loss: 0.3300339144380733
Validation loss: 2.4571089072107246

Epoch: 5| Step: 4
Training loss: 0.16039333008623247
Validation loss: 2.4529035301187485

Epoch: 5| Step: 5
Training loss: 0.14992449717889775
Validation loss: 2.4298439773434892

Epoch: 5| Step: 6
Training loss: 0.273291112679278
Validation loss: 2.4402654865935314

Epoch: 5| Step: 7
Training loss: 0.30417141856222346
Validation loss: 2.409556439350412

Epoch: 5| Step: 8
Training loss: 0.2698889307876491
Validation loss: 2.4343488922018683

Epoch: 5| Step: 9
Training loss: 0.14039023326591984
Validation loss: 2.4225566580859805

Epoch: 5| Step: 10
Training loss: 0.3688927681191039
Validation loss: 2.4247825325878067

Epoch: 433| Step: 0
Training loss: 0.2082212633459013
Validation loss: 2.395639333766554

Epoch: 5| Step: 1
Training loss: 0.2947755159912045
Validation loss: 2.4182648849573085

Epoch: 5| Step: 2
Training loss: 0.2596305122919843
Validation loss: 2.4504274944184883

Epoch: 5| Step: 3
Training loss: 0.18537334559339647
Validation loss: 2.436696741877399

Epoch: 5| Step: 4
Training loss: 0.28795230158226987
Validation loss: 2.449871607587421

Epoch: 5| Step: 5
Training loss: 0.3577380007018386
Validation loss: 2.4315603778774917

Epoch: 5| Step: 6
Training loss: 0.11710342729312787
Validation loss: 2.4258850423148726

Epoch: 5| Step: 7
Training loss: 0.28929018384266003
Validation loss: 2.4459208510453045

Epoch: 5| Step: 8
Training loss: 0.2033880895828921
Validation loss: 2.4603780547768666

Epoch: 5| Step: 9
Training loss: 0.3389682783888635
Validation loss: 2.4480139139443393

Epoch: 5| Step: 10
Training loss: 0.3387657695351379
Validation loss: 2.4703877921082698

Epoch: 434| Step: 0
Training loss: 0.2962140832729181
Validation loss: 2.4652625556077985

Epoch: 5| Step: 1
Training loss: 0.30040743747287196
Validation loss: 2.4530282639956336

Epoch: 5| Step: 2
Training loss: 0.16579904453582656
Validation loss: 2.474088323747732

Epoch: 5| Step: 3
Training loss: 0.25532747264461475
Validation loss: 2.4760179496455246

Epoch: 5| Step: 4
Training loss: 0.2147910833828761
Validation loss: 2.445569197345033

Epoch: 5| Step: 5
Training loss: 0.29718167376498167
Validation loss: 2.4194276785054654

Epoch: 5| Step: 6
Training loss: 0.2560945987512792
Validation loss: 2.4373438974210435

Epoch: 5| Step: 7
Training loss: 0.20733090972525187
Validation loss: 2.4284112228812202

Epoch: 5| Step: 8
Training loss: 0.2917217162951472
Validation loss: 2.4350882242258614

Epoch: 5| Step: 9
Training loss: 0.3056147355811368
Validation loss: 2.4309279951555043

Epoch: 5| Step: 10
Training loss: 0.31727590080703255
Validation loss: 2.44783779288637

Epoch: 435| Step: 0
Training loss: 0.2839264019504514
Validation loss: 2.4364971225474963

Epoch: 5| Step: 1
Training loss: 0.23538716628619366
Validation loss: 2.456094639831424

Epoch: 5| Step: 2
Training loss: 0.3963939582443671
Validation loss: 2.4686468250028395

Epoch: 5| Step: 3
Training loss: 0.20828620655775626
Validation loss: 2.4548444697514196

Epoch: 5| Step: 4
Training loss: 0.2308537935979692
Validation loss: 2.4500316996404004

Epoch: 5| Step: 5
Training loss: 0.28976040436131817
Validation loss: 2.454559880514612

Epoch: 5| Step: 6
Training loss: 0.22641076564563659
Validation loss: 2.3969784472278057

Epoch: 5| Step: 7
Training loss: 0.29336244198025146
Validation loss: 2.4510280701441394

Epoch: 5| Step: 8
Training loss: 0.17113980278779575
Validation loss: 2.4436780209747875

Epoch: 5| Step: 9
Training loss: 0.21699649624533887
Validation loss: 2.4368354663491427

Epoch: 5| Step: 10
Training loss: 0.34975471885161813
Validation loss: 2.406349293013626

Epoch: 436| Step: 0
Training loss: 0.22569028084329743
Validation loss: 2.3998073385614243

Epoch: 5| Step: 1
Training loss: 0.2335590145350182
Validation loss: 2.3943286356286926

Epoch: 5| Step: 2
Training loss: 0.3110538399203474
Validation loss: 2.423115400798037

Epoch: 5| Step: 3
Training loss: 0.3335031868891028
Validation loss: 2.4123150954365884

Epoch: 5| Step: 4
Training loss: 0.3012093803910683
Validation loss: 2.419200077097533

Epoch: 5| Step: 5
Training loss: 0.29922497645739843
Validation loss: 2.3967874557650335

Epoch: 5| Step: 6
Training loss: 0.16370758768639873
Validation loss: 2.418935803798472

Epoch: 5| Step: 7
Training loss: 0.2489824223868222
Validation loss: 2.414335181360431

Epoch: 5| Step: 8
Training loss: 0.20286065103117365
Validation loss: 2.3796496641851617

Epoch: 5| Step: 9
Training loss: 0.2067754803014441
Validation loss: 2.4251987647721247

Epoch: 5| Step: 10
Training loss: 0.30270324054712466
Validation loss: 2.4236657494293015

Epoch: 437| Step: 0
Training loss: 0.30690799889213327
Validation loss: 2.4048619469183197

Epoch: 5| Step: 1
Training loss: 0.16116270886131545
Validation loss: 2.455944148216463

Epoch: 5| Step: 2
Training loss: 0.25888032563559943
Validation loss: 2.425451844084015

Epoch: 5| Step: 3
Training loss: 0.20413574589571382
Validation loss: 2.4431142358035927

Epoch: 5| Step: 4
Training loss: 0.20703709792029182
Validation loss: 2.426446800483839

Epoch: 5| Step: 5
Training loss: 0.3326960135937692
Validation loss: 2.4387517464786774

Epoch: 5| Step: 6
Training loss: 0.2893772602404982
Validation loss: 2.4345152539012385

Epoch: 5| Step: 7
Training loss: 0.19774071920248482
Validation loss: 2.4266826567904225

Epoch: 5| Step: 8
Training loss: 0.24935828491112264
Validation loss: 2.443588819859337

Epoch: 5| Step: 9
Training loss: 0.31415769073875416
Validation loss: 2.4314374791159357

Epoch: 5| Step: 10
Training loss: 0.19740789778352166
Validation loss: 2.454040220760187

Epoch: 438| Step: 0
Training loss: 0.21686461825078635
Validation loss: 2.452405920449585

Epoch: 5| Step: 1
Training loss: 0.34007629024221875
Validation loss: 2.4635731938031102

Epoch: 5| Step: 2
Training loss: 0.14060424942990685
Validation loss: 2.429651977671901

Epoch: 5| Step: 3
Training loss: 0.21131342485953764
Validation loss: 2.4517643351962777

Epoch: 5| Step: 4
Training loss: 0.14626026812396595
Validation loss: 2.4473242087046256

Epoch: 5| Step: 5
Training loss: 0.2664208830453153
Validation loss: 2.410345843121928

Epoch: 5| Step: 6
Training loss: 0.1286471102981923
Validation loss: 2.428544330727962

Epoch: 5| Step: 7
Training loss: 0.3057679679180831
Validation loss: 2.4502835778685443

Epoch: 5| Step: 8
Training loss: 0.32144120854747843
Validation loss: 2.4421142895507653

Epoch: 5| Step: 9
Training loss: 0.4029618117765744
Validation loss: 2.442518762189448

Epoch: 5| Step: 10
Training loss: 0.17546277335799831
Validation loss: 2.422011654134713

Epoch: 439| Step: 0
Training loss: 0.20618843872154954
Validation loss: 2.4325606324402855

Epoch: 5| Step: 1
Training loss: 0.39759149679948547
Validation loss: 2.441100788917548

Epoch: 5| Step: 2
Training loss: 0.1616396878889676
Validation loss: 2.424859938040528

Epoch: 5| Step: 3
Training loss: 0.2107313349548308
Validation loss: 2.420133976737568

Epoch: 5| Step: 4
Training loss: 0.16675630160853822
Validation loss: 2.3934658676676768

Epoch: 5| Step: 5
Training loss: 0.20960719449746443
Validation loss: 2.404180696779575

Epoch: 5| Step: 6
Training loss: 0.3383031763102449
Validation loss: 2.3945550573290615

Epoch: 5| Step: 7
Training loss: 0.31027353601071117
Validation loss: 2.427460492013472

Epoch: 5| Step: 8
Training loss: 0.14526637739979834
Validation loss: 2.4255790190869724

Epoch: 5| Step: 9
Training loss: 0.24572885800048883
Validation loss: 2.407303860475877

Epoch: 5| Step: 10
Training loss: 0.30051008609658914
Validation loss: 2.3994531971641266

Epoch: 440| Step: 0
Training loss: 0.29178990019973944
Validation loss: 2.4082217752241992

Epoch: 5| Step: 1
Training loss: 0.28825867210404965
Validation loss: 2.4287958871689526

Epoch: 5| Step: 2
Training loss: 0.18262675459173586
Validation loss: 2.4559489207002367

Epoch: 5| Step: 3
Training loss: 0.30454502687171864
Validation loss: 2.4466303189225953

Epoch: 5| Step: 4
Training loss: 0.2747319372598665
Validation loss: 2.4335649398746733

Epoch: 5| Step: 5
Training loss: 0.16384085942712004
Validation loss: 2.444726304366505

Epoch: 5| Step: 6
Training loss: 0.27969565299740534
Validation loss: 2.463292948580113

Epoch: 5| Step: 7
Training loss: 0.2878887212682588
Validation loss: 2.471437334545566

Epoch: 5| Step: 8
Training loss: 0.1346764822544801
Validation loss: 2.4651677039822597

Epoch: 5| Step: 9
Training loss: 0.21501872133651165
Validation loss: 2.456980676911603

Epoch: 5| Step: 10
Training loss: 0.12315818883317843
Validation loss: 2.454650586367789

Epoch: 441| Step: 0
Training loss: 0.19023049524882377
Validation loss: 2.4425088509011452

Epoch: 5| Step: 1
Training loss: 0.08934678624395462
Validation loss: 2.421385660000823

Epoch: 5| Step: 2
Training loss: 0.1728384907408051
Validation loss: 2.4081040553384327

Epoch: 5| Step: 3
Training loss: 0.2624078759255144
Validation loss: 2.422585310229707

Epoch: 5| Step: 4
Training loss: 0.21937352110698435
Validation loss: 2.4157116328539128

Epoch: 5| Step: 5
Training loss: 0.21123886656061514
Validation loss: 2.396484413511022

Epoch: 5| Step: 6
Training loss: 0.2677840115986511
Validation loss: 2.418742791969807

Epoch: 5| Step: 7
Training loss: 0.28795322012047175
Validation loss: 2.4254751819676517

Epoch: 5| Step: 8
Training loss: 0.3021701230414995
Validation loss: 2.38308671529696

Epoch: 5| Step: 9
Training loss: 0.37792048085750807
Validation loss: 2.3905751341561925

Epoch: 5| Step: 10
Training loss: 0.15137262642225666
Validation loss: 2.4179414548842

Epoch: 442| Step: 0
Training loss: 0.16700065323636218
Validation loss: 2.416496493281881

Epoch: 5| Step: 1
Training loss: 0.23695030752809237
Validation loss: 2.4119797392321245

Epoch: 5| Step: 2
Training loss: 0.3648976492430492
Validation loss: 2.4060030127109164

Epoch: 5| Step: 3
Training loss: 0.17597023024264147
Validation loss: 2.4083092737669105

Epoch: 5| Step: 4
Training loss: 0.2572682879067141
Validation loss: 2.3907968833451005

Epoch: 5| Step: 5
Training loss: 0.2707648450501311
Validation loss: 2.4195439463031483

Epoch: 5| Step: 6
Training loss: 0.2962428439760873
Validation loss: 2.404732973740129

Epoch: 5| Step: 7
Training loss: 0.20510281913673722
Validation loss: 2.397890378663725

Epoch: 5| Step: 8
Training loss: 0.1538821755861979
Validation loss: 2.405725129693098

Epoch: 5| Step: 9
Training loss: 0.3113658590196307
Validation loss: 2.4216389774268205

Epoch: 5| Step: 10
Training loss: 0.1091525677077075
Validation loss: 2.407252612758523

Epoch: 443| Step: 0
Training loss: 0.15620066936921273
Validation loss: 2.4520553170183916

Epoch: 5| Step: 1
Training loss: 0.18141321076896746
Validation loss: 2.4369528408484586

Epoch: 5| Step: 2
Training loss: 0.1875319255034173
Validation loss: 2.4085633443509424

Epoch: 5| Step: 3
Training loss: 0.18867389448834485
Validation loss: 2.432283832607436

Epoch: 5| Step: 4
Training loss: 0.25654158749769423
Validation loss: 2.4664417585718366

Epoch: 5| Step: 5
Training loss: 0.19329359881673017
Validation loss: 2.4709654068674087

Epoch: 5| Step: 6
Training loss: 0.3130301865541259
Validation loss: 2.452377442658408

Epoch: 5| Step: 7
Training loss: 0.2715943340215789
Validation loss: 2.448855536098035

Epoch: 5| Step: 8
Training loss: 0.2032696868868325
Validation loss: 2.475361443871338

Epoch: 5| Step: 9
Training loss: 0.2592252833512831
Validation loss: 2.466955049292211

Epoch: 5| Step: 10
Training loss: 0.3630516803539179
Validation loss: 2.464602726158685

Epoch: 444| Step: 0
Training loss: 0.3337104410129637
Validation loss: 2.426950249228781

Epoch: 5| Step: 1
Training loss: 0.3134497277488506
Validation loss: 2.425790932665585

Epoch: 5| Step: 2
Training loss: 0.23361974463106053
Validation loss: 2.446908308939315

Epoch: 5| Step: 3
Training loss: 0.30788332613250446
Validation loss: 2.4294503058640613

Epoch: 5| Step: 4
Training loss: 0.22618742841565026
Validation loss: 2.406728524595452

Epoch: 5| Step: 5
Training loss: 0.16862236423567448
Validation loss: 2.4346647651184083

Epoch: 5| Step: 6
Training loss: 0.1609021587825941
Validation loss: 2.4147598624499547

Epoch: 5| Step: 7
Training loss: 0.11352438567342286
Validation loss: 2.402464781069337

Epoch: 5| Step: 8
Training loss: 0.28816403122537576
Validation loss: 2.4257344557175022

Epoch: 5| Step: 9
Training loss: 0.19136173353426053
Validation loss: 2.4225653303279002

Epoch: 5| Step: 10
Training loss: 0.18126445704385483
Validation loss: 2.417771661932323

Epoch: 445| Step: 0
Training loss: 0.1257103020923002
Validation loss: 2.4217096860463583

Epoch: 5| Step: 1
Training loss: 0.2842475967280468
Validation loss: 2.423377757903911

Epoch: 5| Step: 2
Training loss: 0.25598760114479946
Validation loss: 2.430967025344153

Epoch: 5| Step: 3
Training loss: 0.27842565851687706
Validation loss: 2.428662066872179

Epoch: 5| Step: 4
Training loss: 0.1704236984337249
Validation loss: 2.4122535381170396

Epoch: 5| Step: 5
Training loss: 0.31163549052245443
Validation loss: 2.4139655749822135

Epoch: 5| Step: 6
Training loss: 0.1787776093068102
Validation loss: 2.4286577395290334

Epoch: 5| Step: 7
Training loss: 0.14636680971518864
Validation loss: 2.4175294673245427

Epoch: 5| Step: 8
Training loss: 0.2655812676276299
Validation loss: 2.407318350042435

Epoch: 5| Step: 9
Training loss: 0.2478085446733577
Validation loss: 2.4081605843408567

Epoch: 5| Step: 10
Training loss: 0.2759543121720154
Validation loss: 2.425147704926916

Epoch: 446| Step: 0
Training loss: 0.25157021101986304
Validation loss: 2.3873956551943896

Epoch: 5| Step: 1
Training loss: 0.32222650463905145
Validation loss: 2.429998072978723

Epoch: 5| Step: 2
Training loss: 0.18952602281776246
Validation loss: 2.4287642762749364

Epoch: 5| Step: 3
Training loss: 0.07741710202086906
Validation loss: 2.419024907196009

Epoch: 5| Step: 4
Training loss: 0.302193188697581
Validation loss: 2.4092858645338002

Epoch: 5| Step: 5
Training loss: 0.2866214186814398
Validation loss: 2.433909053125722

Epoch: 5| Step: 6
Training loss: 0.17064758418555792
Validation loss: 2.426098661082991

Epoch: 5| Step: 7
Training loss: 0.31096382460988486
Validation loss: 2.430048469661999

Epoch: 5| Step: 8
Training loss: 0.17107915315241579
Validation loss: 2.4038857551472703

Epoch: 5| Step: 9
Training loss: 0.2154118223555629
Validation loss: 2.4124719334072298

Epoch: 5| Step: 10
Training loss: 0.16614231436738822
Validation loss: 2.398307342754753

Epoch: 447| Step: 0
Training loss: 0.13293498365830123
Validation loss: 2.435462222912762

Epoch: 5| Step: 1
Training loss: 0.15803226027185582
Validation loss: 2.449122708627133

Epoch: 5| Step: 2
Training loss: 0.18884950020466165
Validation loss: 2.428753850226194

Epoch: 5| Step: 3
Training loss: 0.20095247508024666
Validation loss: 2.4171383269806217

Epoch: 5| Step: 4
Training loss: 0.2518995361114871
Validation loss: 2.42753749419975

Epoch: 5| Step: 5
Training loss: 0.16613271735229207
Validation loss: 2.4136235366715764

Epoch: 5| Step: 6
Training loss: 0.2838438218824444
Validation loss: 2.443346941618674

Epoch: 5| Step: 7
Training loss: 0.333135619486293
Validation loss: 2.4300765603217167

Epoch: 5| Step: 8
Training loss: 0.3063665489375921
Validation loss: 2.4035621742007702

Epoch: 5| Step: 9
Training loss: 0.18701904919951007
Validation loss: 2.3906992070289714

Epoch: 5| Step: 10
Training loss: 0.2947743154054032
Validation loss: 2.4063707999761452

Epoch: 448| Step: 0
Training loss: 0.2407221842484557
Validation loss: 2.4088463393962485

Epoch: 5| Step: 1
Training loss: 0.21170179221733015
Validation loss: 2.4279754006612007

Epoch: 5| Step: 2
Training loss: 0.18427932851396728
Validation loss: 2.406983458601793

Epoch: 5| Step: 3
Training loss: 0.14149727763044098
Validation loss: 2.403007585681581

Epoch: 5| Step: 4
Training loss: 0.3296245980482721
Validation loss: 2.4197601087107876

Epoch: 5| Step: 5
Training loss: 0.11898500801138456
Validation loss: 2.4061623578517404

Epoch: 5| Step: 6
Training loss: 0.23470300927961507
Validation loss: 2.425274872622992

Epoch: 5| Step: 7
Training loss: 0.20001965701838004
Validation loss: 2.424546002142332

Epoch: 5| Step: 8
Training loss: 0.34113798666318945
Validation loss: 2.450937892334223

Epoch: 5| Step: 9
Training loss: 0.296797227711178
Validation loss: 2.4639294402890406

Epoch: 5| Step: 10
Training loss: 0.22769782458438062
Validation loss: 2.437909488658333

Epoch: 449| Step: 0
Training loss: 0.21459466192902485
Validation loss: 2.4278156207952923

Epoch: 5| Step: 1
Training loss: 0.1932464616718072
Validation loss: 2.4111587397489935

Epoch: 5| Step: 2
Training loss: 0.15664178486344676
Validation loss: 2.388980137410703

Epoch: 5| Step: 3
Training loss: 0.39147300227144116
Validation loss: 2.394830041214202

Epoch: 5| Step: 4
Training loss: 0.3714681844462302
Validation loss: 2.4051282974619865

Epoch: 5| Step: 5
Training loss: 0.13682673140998072
Validation loss: 2.383843509647984

Epoch: 5| Step: 6
Training loss: 0.1928692684811525
Validation loss: 2.372406174052187

Epoch: 5| Step: 7
Training loss: 0.24688054513136057
Validation loss: 2.3996510082735933

Epoch: 5| Step: 8
Training loss: 0.23378836807746978
Validation loss: 2.395448675392579

Epoch: 5| Step: 9
Training loss: 0.271229768649
Validation loss: 2.4066294421673433

Epoch: 5| Step: 10
Training loss: 0.12088965320874505
Validation loss: 2.3972222224567026

Epoch: 450| Step: 0
Training loss: 0.14567244260358841
Validation loss: 2.406414661864967

Epoch: 5| Step: 1
Training loss: 0.29037091828464945
Validation loss: 2.421907998560503

Epoch: 5| Step: 2
Training loss: 0.19079923718362946
Validation loss: 2.430628071380505

Epoch: 5| Step: 3
Training loss: 0.30190161331023047
Validation loss: 2.3936006226796427

Epoch: 5| Step: 4
Training loss: 0.10511680001194873
Validation loss: 2.4157020106061164

Epoch: 5| Step: 5
Training loss: 0.11943508718060628
Validation loss: 2.395654834519921

Epoch: 5| Step: 6
Training loss: 0.15890220139933933
Validation loss: 2.4131206445

Epoch: 5| Step: 7
Training loss: 0.22820275235823126
Validation loss: 2.443925508419147

Epoch: 5| Step: 8
Training loss: 0.3989624790975572
Validation loss: 2.4033345860753106

Epoch: 5| Step: 9
Training loss: 0.17400462587280338
Validation loss: 2.3952900859606387

Epoch: 5| Step: 10
Training loss: 0.3404923421310901
Validation loss: 2.3908282306249697

Epoch: 451| Step: 0
Training loss: 0.1397305360633782
Validation loss: 2.4009236767729556

Epoch: 5| Step: 1
Training loss: 0.30335027739513887
Validation loss: 2.3941746352684374

Epoch: 5| Step: 2
Training loss: 0.2588864700966601
Validation loss: 2.3951606273322197

Epoch: 5| Step: 3
Training loss: 0.2707936398444596
Validation loss: 2.387514370904713

Epoch: 5| Step: 4
Training loss: 0.14357793710538364
Validation loss: 2.402028587511564

Epoch: 5| Step: 5
Training loss: 0.21976765566259596
Validation loss: 2.4184999075540716

Epoch: 5| Step: 6
Training loss: 0.3122812339846079
Validation loss: 2.4000786315947362

Epoch: 5| Step: 7
Training loss: 0.28092606751430166
Validation loss: 2.4050374464475817

Epoch: 5| Step: 8
Training loss: 0.18821474776556413
Validation loss: 2.4165601406303714

Epoch: 5| Step: 9
Training loss: 0.29053183159447366
Validation loss: 2.40270963854316

Epoch: 5| Step: 10
Training loss: 0.1237489561557094
Validation loss: 2.3894646847665486

Epoch: 452| Step: 0
Training loss: 0.2839460297188574
Validation loss: 2.3914539900604965

Epoch: 5| Step: 1
Training loss: 0.18046833467642154
Validation loss: 2.4054692448939963

Epoch: 5| Step: 2
Training loss: 0.2923287967994487
Validation loss: 2.434221528206862

Epoch: 5| Step: 3
Training loss: 0.2916039657749244
Validation loss: 2.4099050930042307

Epoch: 5| Step: 4
Training loss: 0.25629902696302
Validation loss: 2.409347035350393

Epoch: 5| Step: 5
Training loss: 0.16508662085960138
Validation loss: 2.4116598182549973

Epoch: 5| Step: 6
Training loss: 0.3404117966906279
Validation loss: 2.411656401708942

Epoch: 5| Step: 7
Training loss: 0.20575306950709468
Validation loss: 2.4060202665895454

Epoch: 5| Step: 8
Training loss: 0.22643842259260422
Validation loss: 2.413912633511795

Epoch: 5| Step: 9
Training loss: 0.19231311871823026
Validation loss: 2.4435986711636346

Epoch: 5| Step: 10
Training loss: 0.17569286455563193
Validation loss: 2.389136715793627

Epoch: 453| Step: 0
Training loss: 0.2053754014285826
Validation loss: 2.403008061495148

Epoch: 5| Step: 1
Training loss: 0.1496091703209336
Validation loss: 2.4098337401470333

Epoch: 5| Step: 2
Training loss: 0.2824269411679971
Validation loss: 2.4501751481133582

Epoch: 5| Step: 3
Training loss: 0.18998980457156311
Validation loss: 2.4191027008804893

Epoch: 5| Step: 4
Training loss: 0.13925020082063766
Validation loss: 2.461906710769009

Epoch: 5| Step: 5
Training loss: 0.19739673525386953
Validation loss: 2.4507532588293297

Epoch: 5| Step: 6
Training loss: 0.1951943421583045
Validation loss: 2.4470200159514874

Epoch: 5| Step: 7
Training loss: 0.35515461130431275
Validation loss: 2.4583834206254966

Epoch: 5| Step: 8
Training loss: 0.15541478087718902
Validation loss: 2.4552694039555876

Epoch: 5| Step: 9
Training loss: 0.35623149991101904
Validation loss: 2.4519733677764246

Epoch: 5| Step: 10
Training loss: 0.21018713366113295
Validation loss: 2.463903277833228

Epoch: 454| Step: 0
Training loss: 0.3141696552599073
Validation loss: 2.435383517547456

Epoch: 5| Step: 1
Training loss: 0.29592016662784526
Validation loss: 2.4467679112532648

Epoch: 5| Step: 2
Training loss: 0.17263018445862482
Validation loss: 2.4199245933927895

Epoch: 5| Step: 3
Training loss: 0.36114788199343295
Validation loss: 2.4045575340828025

Epoch: 5| Step: 4
Training loss: 0.2253481615021156
Validation loss: 2.4400594834185223

Epoch: 5| Step: 5
Training loss: 0.17311097200140624
Validation loss: 2.385669424212119

Epoch: 5| Step: 6
Training loss: 0.2432738519718522
Validation loss: 2.4153971118470796

Epoch: 5| Step: 7
Training loss: 0.24435141047114933
Validation loss: 2.4288965742227693

Epoch: 5| Step: 8
Training loss: 0.12682209589050938
Validation loss: 2.4200585514979878

Epoch: 5| Step: 9
Training loss: 0.11090424636993647
Validation loss: 2.4265137483400494

Epoch: 5| Step: 10
Training loss: 0.24189752477550006
Validation loss: 2.430350637152678

Epoch: 455| Step: 0
Training loss: 0.20532830736340724
Validation loss: 2.4155889863871116

Epoch: 5| Step: 1
Training loss: 0.19128250481627548
Validation loss: 2.424551400006866

Epoch: 5| Step: 2
Training loss: 0.26882739006281253
Validation loss: 2.4164743163038045

Epoch: 5| Step: 3
Training loss: 0.32690732810657047
Validation loss: 2.419982591047919

Epoch: 5| Step: 4
Training loss: 0.18944590839916958
Validation loss: 2.413123424735499

Epoch: 5| Step: 5
Training loss: 0.2789763765836285
Validation loss: 2.426738951360441

Epoch: 5| Step: 6
Training loss: 0.21896979665526495
Validation loss: 2.4176138481021043

Epoch: 5| Step: 7
Training loss: 0.11536648822644055
Validation loss: 2.390499536625611

Epoch: 5| Step: 8
Training loss: 0.34271132077516053
Validation loss: 2.4025166932583613

Epoch: 5| Step: 9
Training loss: 0.19830952520150041
Validation loss: 2.4108731115567763

Epoch: 5| Step: 10
Training loss: 0.3136441385968117
Validation loss: 2.4074496946344937

Epoch: 456| Step: 0
Training loss: 0.30178530422764877
Validation loss: 2.411392340355873

Epoch: 5| Step: 1
Training loss: 0.29273517198253063
Validation loss: 2.4006312366095566

Epoch: 5| Step: 2
Training loss: 0.20280237435631165
Validation loss: 2.411260069716555

Epoch: 5| Step: 3
Training loss: 0.2258526847452819
Validation loss: 2.3888527299943045

Epoch: 5| Step: 4
Training loss: 0.26835148840008677
Validation loss: 2.413430278986662

Epoch: 5| Step: 5
Training loss: 0.19750593674464892
Validation loss: 2.410415291657952

Epoch: 5| Step: 6
Training loss: 0.2519245870825505
Validation loss: 2.415468203249562

Epoch: 5| Step: 7
Training loss: 0.1882565652328126
Validation loss: 2.4102613735602696

Epoch: 5| Step: 8
Training loss: 0.2930443856833527
Validation loss: 2.4327891557458527

Epoch: 5| Step: 9
Training loss: 0.19985708181786285
Validation loss: 2.4115373372642455

Epoch: 5| Step: 10
Training loss: 0.22069423792677811
Validation loss: 2.4237244000867535

Epoch: 457| Step: 0
Training loss: 0.2755429137647938
Validation loss: 2.403961949754921

Epoch: 5| Step: 1
Training loss: 0.27147715716749843
Validation loss: 2.4060551554229934

Epoch: 5| Step: 2
Training loss: 0.17541118981286571
Validation loss: 2.4170143597264215

Epoch: 5| Step: 3
Training loss: 0.2164027265406467
Validation loss: 2.385668228181892

Epoch: 5| Step: 4
Training loss: 0.11245575571262677
Validation loss: 2.398508162581707

Epoch: 5| Step: 5
Training loss: 0.26425752942844744
Validation loss: 2.4087211929154217

Epoch: 5| Step: 6
Training loss: 0.22899590256619246
Validation loss: 2.411506422898385

Epoch: 5| Step: 7
Training loss: 0.18054591259107675
Validation loss: 2.426035393955419

Epoch: 5| Step: 8
Training loss: 0.2612637079785789
Validation loss: 2.4270074531375534

Epoch: 5| Step: 9
Training loss: 0.29225931101129854
Validation loss: 2.4288602360431333

Epoch: 5| Step: 10
Training loss: 0.29081584806583016
Validation loss: 2.413831863937484

Epoch: 458| Step: 0
Training loss: 0.2912817640542515
Validation loss: 2.3876316038150898

Epoch: 5| Step: 1
Training loss: 0.19596124670938614
Validation loss: 2.41178482819628

Epoch: 5| Step: 2
Training loss: 0.1399745401473854
Validation loss: 2.421924638454492

Epoch: 5| Step: 3
Training loss: 0.282180756016237
Validation loss: 2.410628731802417

Epoch: 5| Step: 4
Training loss: 0.34561649681102835
Validation loss: 2.3899928514591045

Epoch: 5| Step: 5
Training loss: 0.1766699156166275
Validation loss: 2.401873135067762

Epoch: 5| Step: 6
Training loss: 0.32449077776263635
Validation loss: 2.414506092991602

Epoch: 5| Step: 7
Training loss: 0.21374041139835243
Validation loss: 2.445689050520166

Epoch: 5| Step: 8
Training loss: 0.10661079946821733
Validation loss: 2.4391559316776146

Epoch: 5| Step: 9
Training loss: 0.16593205648678355
Validation loss: 2.4349079511910237

Epoch: 5| Step: 10
Training loss: 0.138050406064877
Validation loss: 2.4284774077086055

Epoch: 459| Step: 0
Training loss: 0.12731463239838153
Validation loss: 2.4196949515328408

Epoch: 5| Step: 1
Training loss: 0.16416824429822222
Validation loss: 2.425719858971726

Epoch: 5| Step: 2
Training loss: 0.15559269215457303
Validation loss: 2.43925602345859

Epoch: 5| Step: 3
Training loss: 0.25946520879737117
Validation loss: 2.4308858669476496

Epoch: 5| Step: 4
Training loss: 0.3088491807163137
Validation loss: 2.46449375197997

Epoch: 5| Step: 5
Training loss: 0.3082042602208725
Validation loss: 2.4280620068067726

Epoch: 5| Step: 6
Training loss: 0.2250498143656816
Validation loss: 2.4457402045776524

Epoch: 5| Step: 7
Training loss: 0.2668152117257409
Validation loss: 2.454307578876733

Epoch: 5| Step: 8
Training loss: 0.12440580837709894
Validation loss: 2.4300602072866515

Epoch: 5| Step: 9
Training loss: 0.18564796705442813
Validation loss: 2.462457268388235

Epoch: 5| Step: 10
Training loss: 0.29365026678144335
Validation loss: 2.4570668147174928

Epoch: 460| Step: 0
Training loss: 0.23186818053713054
Validation loss: 2.437926691285988

Epoch: 5| Step: 1
Training loss: 0.1901321434093552
Validation loss: 2.465633588925892

Epoch: 5| Step: 2
Training loss: 0.20910475285385755
Validation loss: 2.4568437144461845

Epoch: 5| Step: 3
Training loss: 0.23366092940661642
Validation loss: 2.429544502215146

Epoch: 5| Step: 4
Training loss: 0.1537933523710044
Validation loss: 2.4478505590165973

Epoch: 5| Step: 5
Training loss: 0.2583988630849227
Validation loss: 2.422604885728038

Epoch: 5| Step: 6
Training loss: 0.12719826871802245
Validation loss: 2.4425593179687133

Epoch: 5| Step: 7
Training loss: 0.15464051525292843
Validation loss: 2.4369086796477495

Epoch: 5| Step: 8
Training loss: 0.2640722837272128
Validation loss: 2.4405380250122453

Epoch: 5| Step: 9
Training loss: 0.3023718108726136
Validation loss: 2.4201249536289917

Epoch: 5| Step: 10
Training loss: 0.308471522691609
Validation loss: 2.4349090598624925

Epoch: 461| Step: 0
Training loss: 0.15751290162544399
Validation loss: 2.4124317543790545

Epoch: 5| Step: 1
Training loss: 0.41826465863057033
Validation loss: 2.422161083016496

Epoch: 5| Step: 2
Training loss: 0.16637810795974264
Validation loss: 2.411365739456023

Epoch: 5| Step: 3
Training loss: 0.19959860472167573
Validation loss: 2.438713623518322

Epoch: 5| Step: 4
Training loss: 0.16778593316578938
Validation loss: 2.444348510585567

Epoch: 5| Step: 5
Training loss: 0.20819872838973189
Validation loss: 2.4173389202765327

Epoch: 5| Step: 6
Training loss: 0.19305097665910195
Validation loss: 2.4398434414397667

Epoch: 5| Step: 7
Training loss: 0.21224385629732878
Validation loss: 2.434223333860205

Epoch: 5| Step: 8
Training loss: 0.15474469952796002
Validation loss: 2.3903072799391745

Epoch: 5| Step: 9
Training loss: 0.17898407372025135
Validation loss: 2.4061189351306904

Epoch: 5| Step: 10
Training loss: 0.3176333333693359
Validation loss: 2.3861731446413748

Epoch: 462| Step: 0
Training loss: 0.1661022016630403
Validation loss: 2.402693313709587

Epoch: 5| Step: 1
Training loss: 0.13385766073656327
Validation loss: 2.395773531545044

Epoch: 5| Step: 2
Training loss: 0.1849492638357248
Validation loss: 2.4172568069206104

Epoch: 5| Step: 3
Training loss: 0.24629669298638268
Validation loss: 2.4103014201845734

Epoch: 5| Step: 4
Training loss: 0.15102531218503584
Validation loss: 2.3843209793094924

Epoch: 5| Step: 5
Training loss: 0.18327567772553313
Validation loss: 2.427662323311922

Epoch: 5| Step: 6
Training loss: 0.1697259244478829
Validation loss: 2.4416239824889576

Epoch: 5| Step: 7
Training loss: 0.3472729616709635
Validation loss: 2.4494708944569212

Epoch: 5| Step: 8
Training loss: 0.23226242045255452
Validation loss: 2.431912598281815

Epoch: 5| Step: 9
Training loss: 0.22041867923779243
Validation loss: 2.423087808696318

Epoch: 5| Step: 10
Training loss: 0.284966444834252
Validation loss: 2.445223029827722

Epoch: 463| Step: 0
Training loss: 0.3279350843774994
Validation loss: 2.4288429122040815

Epoch: 5| Step: 1
Training loss: 0.15300017543545807
Validation loss: 2.445184253405468

Epoch: 5| Step: 2
Training loss: 0.23964334683036273
Validation loss: 2.4184151421524422

Epoch: 5| Step: 3
Training loss: 0.3018573485716701
Validation loss: 2.418781453861597

Epoch: 5| Step: 4
Training loss: 0.20648223128200072
Validation loss: 2.4201802082537958

Epoch: 5| Step: 5
Training loss: 0.1202962711151599
Validation loss: 2.4382051163736307

Epoch: 5| Step: 6
Training loss: 0.20152296521345364
Validation loss: 2.415185063817076

Epoch: 5| Step: 7
Training loss: 0.1588347154705112
Validation loss: 2.4142056566166503

Epoch: 5| Step: 8
Training loss: 0.19468481291605022
Validation loss: 2.446584774781131

Epoch: 5| Step: 9
Training loss: 0.15915828397115173
Validation loss: 2.4469036476906654

Epoch: 5| Step: 10
Training loss: 0.196116851114622
Validation loss: 2.417541855862259

Epoch: 464| Step: 0
Training loss: 0.17533489884033743
Validation loss: 2.428525848977575

Epoch: 5| Step: 1
Training loss: 0.13586793193664742
Validation loss: 2.430807813356564

Epoch: 5| Step: 2
Training loss: 0.26060479362518707
Validation loss: 2.4398817505871353

Epoch: 5| Step: 3
Training loss: 0.3387621076292261
Validation loss: 2.421093282992816

Epoch: 5| Step: 4
Training loss: 0.2271058374738937
Validation loss: 2.4204941130369018

Epoch: 5| Step: 5
Training loss: 0.32730250360470753
Validation loss: 2.4250140913771783

Epoch: 5| Step: 6
Training loss: 0.20856772092515216
Validation loss: 2.388446676270378

Epoch: 5| Step: 7
Training loss: 0.20351978597945192
Validation loss: 2.4071623669676114

Epoch: 5| Step: 8
Training loss: 0.11596561632057398
Validation loss: 2.4109410751086906

Epoch: 5| Step: 9
Training loss: 0.13311890711295768
Validation loss: 2.3890038229971657

Epoch: 5| Step: 10
Training loss: 0.13762095317079248
Validation loss: 2.3624931744230953

Epoch: 465| Step: 0
Training loss: 0.1717537647435779
Validation loss: 2.3886326323869107

Epoch: 5| Step: 1
Training loss: 0.1552796752444492
Validation loss: 2.4058064761961337

Epoch: 5| Step: 2
Training loss: 0.15428977660256732
Validation loss: 2.3908902854247995

Epoch: 5| Step: 3
Training loss: 0.25215613887499344
Validation loss: 2.4129706100828754

Epoch: 5| Step: 4
Training loss: 0.22206519967318905
Validation loss: 2.4252259105566387

Epoch: 5| Step: 5
Training loss: 0.2934187929245595
Validation loss: 2.4196172929077435

Epoch: 5| Step: 6
Training loss: 0.212829799887201
Validation loss: 2.4167531915252294

Epoch: 5| Step: 7
Training loss: 0.24550311798001687
Validation loss: 2.394946223983905

Epoch: 5| Step: 8
Training loss: 0.19353267340473118
Validation loss: 2.4216450783537176

Epoch: 5| Step: 9
Training loss: 0.26533742371977354
Validation loss: 2.4118050871435495

Epoch: 5| Step: 10
Training loss: 0.12927827470798367
Validation loss: 2.4132787314436004

Epoch: 466| Step: 0
Training loss: 0.23472723718432909
Validation loss: 2.401959399726104

Epoch: 5| Step: 1
Training loss: 0.1975010703758014
Validation loss: 2.4053327092903025

Epoch: 5| Step: 2
Training loss: 0.2481243733366925
Validation loss: 2.418593384028249

Epoch: 5| Step: 3
Training loss: 0.2912369468940111
Validation loss: 2.4268623431712135

Epoch: 5| Step: 4
Training loss: 0.16758370067861894
Validation loss: 2.4101940529738335

Epoch: 5| Step: 5
Training loss: 0.25440967243845986
Validation loss: 2.4028340514709057

Epoch: 5| Step: 6
Training loss: 0.24550392979333754
Validation loss: 2.4360436968447665

Epoch: 5| Step: 7
Training loss: 0.18166295806426988
Validation loss: 2.44468476104521

Epoch: 5| Step: 8
Training loss: 0.1466497250976418
Validation loss: 2.41972085908322

Epoch: 5| Step: 9
Training loss: 0.157251521907501
Validation loss: 2.4081156518764395

Epoch: 5| Step: 10
Training loss: 0.15475611008035053
Validation loss: 2.4411748441239562

Epoch: 467| Step: 0
Training loss: 0.1257972846265574
Validation loss: 2.4195843234999863

Epoch: 5| Step: 1
Training loss: 0.22666413395328006
Validation loss: 2.4308609220895225

Epoch: 5| Step: 2
Training loss: 0.29155700046712824
Validation loss: 2.4354750765439523

Epoch: 5| Step: 3
Training loss: 0.2260156394913659
Validation loss: 2.463554228452074

Epoch: 5| Step: 4
Training loss: 0.2320507917941171
Validation loss: 2.40977884191233

Epoch: 5| Step: 5
Training loss: 0.2866534811044405
Validation loss: 2.414560100711171

Epoch: 5| Step: 6
Training loss: 0.19920709987309845
Validation loss: 2.413652628902722

Epoch: 5| Step: 7
Training loss: 0.21711526293764813
Validation loss: 2.4156531113360025

Epoch: 5| Step: 8
Training loss: 0.2787263017254322
Validation loss: 2.404342800073731

Epoch: 5| Step: 9
Training loss: 0.22874676190101204
Validation loss: 2.4206154153489208

Epoch: 5| Step: 10
Training loss: 0.16021992417841446
Validation loss: 2.4167010075382054

Epoch: 468| Step: 0
Training loss: 0.16174920988479505
Validation loss: 2.3883005520236873

Epoch: 5| Step: 1
Training loss: 0.20909156902283535
Validation loss: 2.416319134355334

Epoch: 5| Step: 2
Training loss: 0.16521360546369102
Validation loss: 2.426690977020538

Epoch: 5| Step: 3
Training loss: 0.22926775732812119
Validation loss: 2.4082876569070675

Epoch: 5| Step: 4
Training loss: 0.277833693889879
Validation loss: 2.405237019546431

Epoch: 5| Step: 5
Training loss: 0.15030912568990012
Validation loss: 2.414964389487098

Epoch: 5| Step: 6
Training loss: 0.18722732903530345
Validation loss: 2.44277239215523

Epoch: 5| Step: 7
Training loss: 0.16404386823307424
Validation loss: 2.4133706621907183

Epoch: 5| Step: 8
Training loss: 0.11799301425285783
Validation loss: 2.41909100970598

Epoch: 5| Step: 9
Training loss: 0.385953550738574
Validation loss: 2.415981303390287

Epoch: 5| Step: 10
Training loss: 0.1661625996912275
Validation loss: 2.3767358667793546

Epoch: 469| Step: 0
Training loss: 0.43060181182970936
Validation loss: 2.3983141256880156

Epoch: 5| Step: 1
Training loss: 0.15165333311866905
Validation loss: 2.3993553587727523

Epoch: 5| Step: 2
Training loss: 0.23873127199787017
Validation loss: 2.4118410083823467

Epoch: 5| Step: 3
Training loss: 0.18883945928228738
Validation loss: 2.3957896418999285

Epoch: 5| Step: 4
Training loss: 0.1791184266615275
Validation loss: 2.4103319221705215

Epoch: 5| Step: 5
Training loss: 0.21152683336344613
Validation loss: 2.384866184444766

Epoch: 5| Step: 6
Training loss: 0.19963330724470738
Validation loss: 2.4052590315409703

Epoch: 5| Step: 7
Training loss: 0.1553835328575605
Validation loss: 2.40713706124409

Epoch: 5| Step: 8
Training loss: 0.1275507870436013
Validation loss: 2.451693508361833

Epoch: 5| Step: 9
Training loss: 0.12713751973099593
Validation loss: 2.4012729582400327

Epoch: 5| Step: 10
Training loss: 0.17161834584358077
Validation loss: 2.3875384554380346

Epoch: 470| Step: 0
Training loss: 0.1790245930756961
Validation loss: 2.3924673371304492

Epoch: 5| Step: 1
Training loss: 0.15876890197621693
Validation loss: 2.3790130604726656

Epoch: 5| Step: 2
Training loss: 0.3259258484517944
Validation loss: 2.410120604677573

Epoch: 5| Step: 3
Training loss: 0.16136474678633442
Validation loss: 2.4208505157961704

Epoch: 5| Step: 4
Training loss: 0.16016186727581774
Validation loss: 2.407201004516653

Epoch: 5| Step: 5
Training loss: 0.33153027157635084
Validation loss: 2.4058868534770146

Epoch: 5| Step: 6
Training loss: 0.12666628049987144
Validation loss: 2.4031644059578565

Epoch: 5| Step: 7
Training loss: 0.09171166421855963
Validation loss: 2.4348654433143766

Epoch: 5| Step: 8
Training loss: 0.1943427424940685
Validation loss: 2.421886015095241

Epoch: 5| Step: 9
Training loss: 0.24522802423066253
Validation loss: 2.4421775211919785

Epoch: 5| Step: 10
Training loss: 0.26200529325940297
Validation loss: 2.4272738102117253

Epoch: 471| Step: 0
Training loss: 0.21297749663014787
Validation loss: 2.4492184820402523

Epoch: 5| Step: 1
Training loss: 0.11334682901258515
Validation loss: 2.4431594343594605

Epoch: 5| Step: 2
Training loss: 0.1391159054186215
Validation loss: 2.4457587252671336

Epoch: 5| Step: 3
Training loss: 0.18356980512589244
Validation loss: 2.4328653707223147

Epoch: 5| Step: 4
Training loss: 0.2349336800179709
Validation loss: 2.457948093634945

Epoch: 5| Step: 5
Training loss: 0.27981869428321005
Validation loss: 2.4307634255568407

Epoch: 5| Step: 6
Training loss: 0.32787651916948934
Validation loss: 2.422878125118496

Epoch: 5| Step: 7
Training loss: 0.33856645151036135
Validation loss: 2.4215278516945378

Epoch: 5| Step: 8
Training loss: 0.12342675922840705
Validation loss: 2.4134154718556773

Epoch: 5| Step: 9
Training loss: 0.1451165616418581
Validation loss: 2.403629104583952

Epoch: 5| Step: 10
Training loss: 0.15722916879330015
Validation loss: 2.42240423849883

Epoch: 472| Step: 0
Training loss: 0.1710784998938494
Validation loss: 2.401796901546278

Epoch: 5| Step: 1
Training loss: 0.2618438364846678
Validation loss: 2.416538001366963

Epoch: 5| Step: 2
Training loss: 0.18477230019638943
Validation loss: 2.4347818078245362

Epoch: 5| Step: 3
Training loss: 0.24547274512834483
Validation loss: 2.4267706097641577

Epoch: 5| Step: 4
Training loss: 0.13853891472724422
Validation loss: 2.4263803082752777

Epoch: 5| Step: 5
Training loss: 0.14178343307213515
Validation loss: 2.4240028526137816

Epoch: 5| Step: 6
Training loss: 0.19544207089748203
Validation loss: 2.417851483997309

Epoch: 5| Step: 7
Training loss: 0.18772588474920182
Validation loss: 2.415044395629609

Epoch: 5| Step: 8
Training loss: 0.18720020725506736
Validation loss: 2.4277889559166743

Epoch: 5| Step: 9
Training loss: 0.34511938218529126
Validation loss: 2.441428334913551

Epoch: 5| Step: 10
Training loss: 0.21031268618605195
Validation loss: 2.4325317984861674

Epoch: 473| Step: 0
Training loss: 0.22236041442872617
Validation loss: 2.4432614664425807

Epoch: 5| Step: 1
Training loss: 0.23413077186368036
Validation loss: 2.433199146406911

Epoch: 5| Step: 2
Training loss: 0.23245711820731207
Validation loss: 2.4227626056574834

Epoch: 5| Step: 3
Training loss: 0.11322213143014345
Validation loss: 2.4481029904752036

Epoch: 5| Step: 4
Training loss: 0.2056742949082231
Validation loss: 2.4108253856206776

Epoch: 5| Step: 5
Training loss: 0.13976061923432748
Validation loss: 2.3918910206733615

Epoch: 5| Step: 6
Training loss: 0.22468567257218933
Validation loss: 2.404038998658007

Epoch: 5| Step: 7
Training loss: 0.12908949254526927
Validation loss: 2.4756368745554975

Epoch: 5| Step: 8
Training loss: 0.2189892244159282
Validation loss: 2.4501322490633455

Epoch: 5| Step: 9
Training loss: 0.2579399285254136
Validation loss: 2.4267600985607243

Epoch: 5| Step: 10
Training loss: 0.19473812524256978
Validation loss: 2.437413371071496

Epoch: 474| Step: 0
Training loss: 0.16429986698874582
Validation loss: 2.439789780092903

Epoch: 5| Step: 1
Training loss: 0.1128211295903498
Validation loss: 2.4430051258100494

Epoch: 5| Step: 2
Training loss: 0.34730148430654556
Validation loss: 2.428802068281387

Epoch: 5| Step: 3
Training loss: 0.15068699999140497
Validation loss: 2.4104916493149986

Epoch: 5| Step: 4
Training loss: 0.30880199118179763
Validation loss: 2.41971458166886

Epoch: 5| Step: 5
Training loss: 0.1155713456261835
Validation loss: 2.4116770167809394

Epoch: 5| Step: 6
Training loss: 0.16176496250883188
Validation loss: 2.4377714562850192

Epoch: 5| Step: 7
Training loss: 0.14173308216960823
Validation loss: 2.4326376987122

Epoch: 5| Step: 8
Training loss: 0.11196382042240473
Validation loss: 2.44592728183248

Epoch: 5| Step: 9
Training loss: 0.1562184421141754
Validation loss: 2.4323542644539202

Epoch: 5| Step: 10
Training loss: 0.28513503322316097
Validation loss: 2.4327272639634328

Epoch: 475| Step: 0
Training loss: 0.14048920140945534
Validation loss: 2.451829856692085

Epoch: 5| Step: 1
Training loss: 0.13711977454629112
Validation loss: 2.4127430498356484

Epoch: 5| Step: 2
Training loss: 0.21400510791282085
Validation loss: 2.402985741630062

Epoch: 5| Step: 3
Training loss: 0.1494393233842543
Validation loss: 2.4314502074665563

Epoch: 5| Step: 4
Training loss: 0.2946650795482993
Validation loss: 2.4039205225917075

Epoch: 5| Step: 5
Training loss: 0.20150542153360632
Validation loss: 2.3905901755200545

Epoch: 5| Step: 6
Training loss: 0.32073552412889383
Validation loss: 2.40244101050597

Epoch: 5| Step: 7
Training loss: 0.2141833298474512
Validation loss: 2.374366233128481

Epoch: 5| Step: 8
Training loss: 0.2704627484956515
Validation loss: 2.3874690810159365

Epoch: 5| Step: 9
Training loss: 0.17592798572345517
Validation loss: 2.3788368587711144

Epoch: 5| Step: 10
Training loss: 0.11464413110030926
Validation loss: 2.420215804987336

Epoch: 476| Step: 0
Training loss: 0.29336279754064437
Validation loss: 2.402498427176237

Epoch: 5| Step: 1
Training loss: 0.1517850583827649
Validation loss: 2.42395650098906

Epoch: 5| Step: 2
Training loss: 0.11662815036867953
Validation loss: 2.4070578743689177

Epoch: 5| Step: 3
Training loss: 0.11478550822457338
Validation loss: 2.435886322199313

Epoch: 5| Step: 4
Training loss: 0.27044313394325986
Validation loss: 2.4173229784601906

Epoch: 5| Step: 5
Training loss: 0.3298229834065333
Validation loss: 2.4049312492082766

Epoch: 5| Step: 6
Training loss: 0.16870896118553944
Validation loss: 2.4237671996058623

Epoch: 5| Step: 7
Training loss: 0.29032001951681286
Validation loss: 2.396249152574356

Epoch: 5| Step: 8
Training loss: 0.1457926375509494
Validation loss: 2.427270082153752

Epoch: 5| Step: 9
Training loss: 0.1848715387868928
Validation loss: 2.4110991220768607

Epoch: 5| Step: 10
Training loss: 0.1876365343325056
Validation loss: 2.416927916168519

Epoch: 477| Step: 0
Training loss: 0.2509635001616592
Validation loss: 2.4226655248792395

Epoch: 5| Step: 1
Training loss: 0.2294116832675383
Validation loss: 2.4163315476652993

Epoch: 5| Step: 2
Training loss: 0.15625246761280853
Validation loss: 2.4331205079712714

Epoch: 5| Step: 3
Training loss: 0.18760302812469803
Validation loss: 2.4448854713786394

Epoch: 5| Step: 4
Training loss: 0.25483858155904077
Validation loss: 2.4264751071663753

Epoch: 5| Step: 5
Training loss: 0.1847011566599373
Validation loss: 2.4550348103899453

Epoch: 5| Step: 6
Training loss: 0.12541099127441127
Validation loss: 2.399059555291121

Epoch: 5| Step: 7
Training loss: 0.22335695969248723
Validation loss: 2.420544515896104

Epoch: 5| Step: 8
Training loss: 0.2695108212455304
Validation loss: 2.420000595918828

Epoch: 5| Step: 9
Training loss: 0.24240336488553704
Validation loss: 2.4292368736570342

Epoch: 5| Step: 10
Training loss: 0.1302084461847452
Validation loss: 2.439170651392045

Epoch: 478| Step: 0
Training loss: 0.18082999779735037
Validation loss: 2.4274148295232965

Epoch: 5| Step: 1
Training loss: 0.2457940608042881
Validation loss: 2.4214212543649465

Epoch: 5| Step: 2
Training loss: 0.17022574319265463
Validation loss: 2.405072010572157

Epoch: 5| Step: 3
Training loss: 0.3521911087460513
Validation loss: 2.4159574875462075

Epoch: 5| Step: 4
Training loss: 0.1645261480078346
Validation loss: 2.426256007291334

Epoch: 5| Step: 5
Training loss: 0.16012896910199434
Validation loss: 2.4053236594347456

Epoch: 5| Step: 6
Training loss: 0.16814402927248867
Validation loss: 2.427685666345776

Epoch: 5| Step: 7
Training loss: 0.31580613764445103
Validation loss: 2.396031924056276

Epoch: 5| Step: 8
Training loss: 0.1357176985022497
Validation loss: 2.3868517404856577

Epoch: 5| Step: 9
Training loss: 0.1839515668932154
Validation loss: 2.3581571553684073

Epoch: 5| Step: 10
Training loss: 0.19431219483072754
Validation loss: 2.38238297519335

Epoch: 479| Step: 0
Training loss: 0.1330540648044827
Validation loss: 2.3907673274827426

Epoch: 5| Step: 1
Training loss: 0.18361311668353725
Validation loss: 2.418602709641631

Epoch: 5| Step: 2
Training loss: 0.25340635534000405
Validation loss: 2.409568015067278

Epoch: 5| Step: 3
Training loss: 0.19315066778105566
Validation loss: 2.421198501340365

Epoch: 5| Step: 4
Training loss: 0.28321393748722234
Validation loss: 2.435152301548718

Epoch: 5| Step: 5
Training loss: 0.2695155070033311
Validation loss: 2.456480524857434

Epoch: 5| Step: 6
Training loss: 0.30763606664459997
Validation loss: 2.46449878200759

Epoch: 5| Step: 7
Training loss: 0.23981645720823094
Validation loss: 2.4385836958078224

Epoch: 5| Step: 8
Training loss: 0.31524948310809675
Validation loss: 2.4339969390359966

Epoch: 5| Step: 9
Training loss: 0.2904855650025417
Validation loss: 2.440393344567325

Epoch: 5| Step: 10
Training loss: 0.1923782328723782
Validation loss: 2.4313252575600455

Epoch: 480| Step: 0
Training loss: 0.2783943613159944
Validation loss: 2.4415607992497206

Epoch: 5| Step: 1
Training loss: 0.0881035609494337
Validation loss: 2.4353004356741668

Epoch: 5| Step: 2
Training loss: 0.24475406635265246
Validation loss: 2.4383299728964336

Epoch: 5| Step: 3
Training loss: 0.12595509190899365
Validation loss: 2.4444311454447853

Epoch: 5| Step: 4
Training loss: 0.1278549514750254
Validation loss: 2.409929800538291

Epoch: 5| Step: 5
Training loss: 0.17725879844341896
Validation loss: 2.397522852170242

Epoch: 5| Step: 6
Training loss: 0.2976080352301219
Validation loss: 2.4229077939832044

Epoch: 5| Step: 7
Training loss: 0.30070051125202923
Validation loss: 2.4309206994673698

Epoch: 5| Step: 8
Training loss: 0.2664237914365189
Validation loss: 2.4364637807472764

Epoch: 5| Step: 9
Training loss: 0.16853371685322766
Validation loss: 2.44195572613639

Epoch: 5| Step: 10
Training loss: 0.2241700810768594
Validation loss: 2.444005521569576

Epoch: 481| Step: 0
Training loss: 0.2661823568024136
Validation loss: 2.4266323177729916

Epoch: 5| Step: 1
Training loss: 0.23469267614678238
Validation loss: 2.4348310204768384

Epoch: 5| Step: 2
Training loss: 0.1856373817154755
Validation loss: 2.4414810640418776

Epoch: 5| Step: 3
Training loss: 0.17558329880442805
Validation loss: 2.4375456586694284

Epoch: 5| Step: 4
Training loss: 0.06080947733524031
Validation loss: 2.4346271999527427

Epoch: 5| Step: 5
Training loss: 0.26604182132566095
Validation loss: 2.44878168123787

Epoch: 5| Step: 6
Training loss: 0.1503962354728197
Validation loss: 2.449595146933192

Epoch: 5| Step: 7
Training loss: 0.2465688569732509
Validation loss: 2.4552488406112882

Epoch: 5| Step: 8
Training loss: 0.3370971513921183
Validation loss: 2.4333509277531395

Epoch: 5| Step: 9
Training loss: 0.10254578795402526
Validation loss: 2.448217131520105

Epoch: 5| Step: 10
Training loss: 0.16713421899523528
Validation loss: 2.4151609170338966

Epoch: 482| Step: 0
Training loss: 0.30053864640587363
Validation loss: 2.4423828481880094

Epoch: 5| Step: 1
Training loss: 0.21056924570170257
Validation loss: 2.4245155359677746

Epoch: 5| Step: 2
Training loss: 0.12066739149061444
Validation loss: 2.4128191585130594

Epoch: 5| Step: 3
Training loss: 0.05525920056085958
Validation loss: 2.4099395202974496

Epoch: 5| Step: 4
Training loss: 0.2429337847410601
Validation loss: 2.4434451845906304

Epoch: 5| Step: 5
Training loss: 0.12567973097620652
Validation loss: 2.404135419613695

Epoch: 5| Step: 6
Training loss: 0.23356462890373397
Validation loss: 2.411280996500977

Epoch: 5| Step: 7
Training loss: 0.14644449962839096
Validation loss: 2.43728036997976

Epoch: 5| Step: 8
Training loss: 0.23124727395744882
Validation loss: 2.442044262022352

Epoch: 5| Step: 9
Training loss: 0.19491446945402982
Validation loss: 2.4208533845806417

Epoch: 5| Step: 10
Training loss: 0.18511685181599577
Validation loss: 2.3988712655142805

Epoch: 483| Step: 0
Training loss: 0.22298679578182265
Validation loss: 2.4230525006739225

Epoch: 5| Step: 1
Training loss: 0.16151416618188033
Validation loss: 2.426483638620779

Epoch: 5| Step: 2
Training loss: 0.28747579327553563
Validation loss: 2.4212378747190813

Epoch: 5| Step: 3
Training loss: 0.14023842925265287
Validation loss: 2.4273222203161335

Epoch: 5| Step: 4
Training loss: 0.22287269579005967
Validation loss: 2.4517296534641106

Epoch: 5| Step: 5
Training loss: 0.29914299576169334
Validation loss: 2.418034520378675

Epoch: 5| Step: 6
Training loss: 0.13323628608520316
Validation loss: 2.4083400173401786

Epoch: 5| Step: 7
Training loss: 0.0925304946217983
Validation loss: 2.413309097271455

Epoch: 5| Step: 8
Training loss: 0.1923630602615827
Validation loss: 2.3938938917236783

Epoch: 5| Step: 9
Training loss: 0.15587031008189253
Validation loss: 2.4016839781572177

Epoch: 5| Step: 10
Training loss: 0.1490959321124004
Validation loss: 2.4274987024610235

Epoch: 484| Step: 0
Training loss: 0.2708892474166151
Validation loss: 2.4124958208530245

Epoch: 5| Step: 1
Training loss: 0.15387659537536516
Validation loss: 2.4250864966015984

Epoch: 5| Step: 2
Training loss: 0.14650742031653752
Validation loss: 2.420541862805748

Epoch: 5| Step: 3
Training loss: 0.2494797284844005
Validation loss: 2.400081226126289

Epoch: 5| Step: 4
Training loss: 0.2523419388980652
Validation loss: 2.422915299492381

Epoch: 5| Step: 5
Training loss: 0.17646701349086652
Validation loss: 2.4149316564525054

Epoch: 5| Step: 6
Training loss: 0.2601139629924343
Validation loss: 2.419022596338829

Epoch: 5| Step: 7
Training loss: 0.1183799277297564
Validation loss: 2.434167464355932

Epoch: 5| Step: 8
Training loss: 0.10440320834433672
Validation loss: 2.4294335866655263

Epoch: 5| Step: 9
Training loss: 0.1206965160720988
Validation loss: 2.4534499558840164

Epoch: 5| Step: 10
Training loss: 0.263437760580348
Validation loss: 2.4138095286568864

Epoch: 485| Step: 0
Training loss: 0.23996528814048956
Validation loss: 2.4432856173677617

Epoch: 5| Step: 1
Training loss: 0.11704101944447154
Validation loss: 2.446168357336056

Epoch: 5| Step: 2
Training loss: 0.1915899193479875
Validation loss: 2.4087956183229604

Epoch: 5| Step: 3
Training loss: 0.1434288186726908
Validation loss: 2.405863195577577

Epoch: 5| Step: 4
Training loss: 0.11726792277982784
Validation loss: 2.4379361048859716

Epoch: 5| Step: 5
Training loss: 0.15141785911759012
Validation loss: 2.414235627445346

Epoch: 5| Step: 6
Training loss: 0.2559913847980516
Validation loss: 2.411639644192674

Epoch: 5| Step: 7
Training loss: 0.31502284689958276
Validation loss: 2.4481457591066067

Epoch: 5| Step: 8
Training loss: 0.10175712900060326
Validation loss: 2.4171997736898776

Epoch: 5| Step: 9
Training loss: 0.24376839299375958
Validation loss: 2.4172918718898404

Epoch: 5| Step: 10
Training loss: 0.1786653012232712
Validation loss: 2.432389481193322

Epoch: 486| Step: 0
Training loss: 0.25669947142604177
Validation loss: 2.4136982835613843

Epoch: 5| Step: 1
Training loss: 0.31423485330057116
Validation loss: 2.3909456323687763

Epoch: 5| Step: 2
Training loss: 0.23213188930162665
Validation loss: 2.422180776779936

Epoch: 5| Step: 3
Training loss: 0.1516735422253602
Validation loss: 2.390376831531096

Epoch: 5| Step: 4
Training loss: 0.11531989108798722
Validation loss: 2.4118454684715993

Epoch: 5| Step: 5
Training loss: 0.2028266292581815
Validation loss: 2.409758196771615

Epoch: 5| Step: 6
Training loss: 0.20729543815868742
Validation loss: 2.417574098636197

Epoch: 5| Step: 7
Training loss: 0.16680985808933485
Validation loss: 2.4159596342076153

Epoch: 5| Step: 8
Training loss: 0.08402119982482871
Validation loss: 2.447923790566353

Epoch: 5| Step: 9
Training loss: 0.15143579958403058
Validation loss: 2.424815679771423

Epoch: 5| Step: 10
Training loss: 0.10520874310955027
Validation loss: 2.4126961115897045

Epoch: 487| Step: 0
Training loss: 0.23336276176761211
Validation loss: 2.421589637216934

Epoch: 5| Step: 1
Training loss: 0.1728705810601335
Validation loss: 2.4143529777538344

Epoch: 5| Step: 2
Training loss: 0.12869108912431343
Validation loss: 2.4341824996487857

Epoch: 5| Step: 3
Training loss: 0.1742365571402719
Validation loss: 2.4275162946314834

Epoch: 5| Step: 4
Training loss: 0.1900141755575692
Validation loss: 2.436649379179318

Epoch: 5| Step: 5
Training loss: 0.11840952449729848
Validation loss: 2.435585353301421

Epoch: 5| Step: 6
Training loss: 0.14025983818332477
Validation loss: 2.4095105657696863

Epoch: 5| Step: 7
Training loss: 0.24501064158216948
Validation loss: 2.4155456068267562

Epoch: 5| Step: 8
Training loss: 0.23840080451321546
Validation loss: 2.392903962239088

Epoch: 5| Step: 9
Training loss: 0.18521881213508132
Validation loss: 2.4123220488717076

Epoch: 5| Step: 10
Training loss: 0.28228631096623985
Validation loss: 2.412856450144873

Epoch: 488| Step: 0
Training loss: 0.1900183906564074
Validation loss: 2.4110055421867336

Epoch: 5| Step: 1
Training loss: 0.3131747947244252
Validation loss: 2.413770940069575

Epoch: 5| Step: 2
Training loss: 0.19406947361430144
Validation loss: 2.422411162973464

Epoch: 5| Step: 3
Training loss: 0.18613354141396843
Validation loss: 2.4001089924585735

Epoch: 5| Step: 4
Training loss: 0.12964760126371183
Validation loss: 2.4177418923982894

Epoch: 5| Step: 5
Training loss: 0.1832224764496194
Validation loss: 2.439301163183752

Epoch: 5| Step: 6
Training loss: 0.273752507912457
Validation loss: 2.437880369366934

Epoch: 5| Step: 7
Training loss: 0.1498655839512205
Validation loss: 2.416842450172789

Epoch: 5| Step: 8
Training loss: 0.1189922166683674
Validation loss: 2.4139980726110246

Epoch: 5| Step: 9
Training loss: 0.2078686548670784
Validation loss: 2.3971907235131913

Epoch: 5| Step: 10
Training loss: 0.0907965752129438
Validation loss: 2.400503734181645

Epoch: 489| Step: 0
Training loss: 0.1322589234571291
Validation loss: 2.4207548463997433

Epoch: 5| Step: 1
Training loss: 0.16378837345123007
Validation loss: 2.419925456794381

Epoch: 5| Step: 2
Training loss: 0.2665063597222685
Validation loss: 2.4324872882736286

Epoch: 5| Step: 3
Training loss: 0.11425000759104906
Validation loss: 2.419169148322939

Epoch: 5| Step: 4
Training loss: 0.20759972313162361
Validation loss: 2.4111370197826067

Epoch: 5| Step: 5
Training loss: 0.17303979721405932
Validation loss: 2.413674667176194

Epoch: 5| Step: 6
Training loss: 0.171505780719696
Validation loss: 2.412612691546104

Epoch: 5| Step: 7
Training loss: 0.16869040646686845
Validation loss: 2.385687904576003

Epoch: 5| Step: 8
Training loss: 0.224275091449471
Validation loss: 2.3632038670244633

Epoch: 5| Step: 9
Training loss: 0.29651797309054717
Validation loss: 2.3912655045206677

Epoch: 5| Step: 10
Training loss: 0.13764806031363203
Validation loss: 2.421090811572016

Epoch: 490| Step: 0
Training loss: 0.09978843470780398
Validation loss: 2.414387992518187

Epoch: 5| Step: 1
Training loss: 0.3261821082788424
Validation loss: 2.378306090630799

Epoch: 5| Step: 2
Training loss: 0.25775596692405556
Validation loss: 2.4010844763476062

Epoch: 5| Step: 3
Training loss: 0.22748898294779732
Validation loss: 2.40321900192033

Epoch: 5| Step: 4
Training loss: 0.1033704117024242
Validation loss: 2.414961366680091

Epoch: 5| Step: 5
Training loss: 0.17472565851760172
Validation loss: 2.3960510619548776

Epoch: 5| Step: 6
Training loss: 0.17853322599690657
Validation loss: 2.4247264957739656

Epoch: 5| Step: 7
Training loss: 0.23938298746183972
Validation loss: 2.4208028843698894

Epoch: 5| Step: 8
Training loss: 0.09288696570604028
Validation loss: 2.4366190075238485

Epoch: 5| Step: 9
Training loss: 0.13770266438871062
Validation loss: 2.4188095015501103

Epoch: 5| Step: 10
Training loss: 0.22189449204534442
Validation loss: 2.437079939026657

Epoch: 491| Step: 0
Training loss: 0.20369992139514667
Validation loss: 2.427895178638838

Epoch: 5| Step: 1
Training loss: 0.1890603053540936
Validation loss: 2.4458351293590335

Epoch: 5| Step: 2
Training loss: 0.08451582792186867
Validation loss: 2.457876661155904

Epoch: 5| Step: 3
Training loss: 0.25408216397996536
Validation loss: 2.4558979829343146

Epoch: 5| Step: 4
Training loss: 0.21299542463620316
Validation loss: 2.434317805207164

Epoch: 5| Step: 5
Training loss: 0.22810254705011276
Validation loss: 2.421004049761219

Epoch: 5| Step: 6
Training loss: 0.15270256311197516
Validation loss: 2.4028618841486926

Epoch: 5| Step: 7
Training loss: 0.19393463489531837
Validation loss: 2.4383828620718733

Epoch: 5| Step: 8
Training loss: 0.1840976839974303
Validation loss: 2.430924041877081

Epoch: 5| Step: 9
Training loss: 0.1723197741617895
Validation loss: 2.4216165145982895

Epoch: 5| Step: 10
Training loss: 0.23729176741227537
Validation loss: 2.434816010773324

Epoch: 492| Step: 0
Training loss: 0.11528498944292534
Validation loss: 2.4257974723004128

Epoch: 5| Step: 1
Training loss: 0.35071293647826784
Validation loss: 2.4234409865117312

Epoch: 5| Step: 2
Training loss: 0.2485650874553061
Validation loss: 2.457978204348101

Epoch: 5| Step: 3
Training loss: 0.17076842676098689
Validation loss: 2.4260060682072155

Epoch: 5| Step: 4
Training loss: 0.17235440887871584
Validation loss: 2.446458799660529

Epoch: 5| Step: 5
Training loss: 0.10004303535160419
Validation loss: 2.426933390273115

Epoch: 5| Step: 6
Training loss: 0.1638763086465309
Validation loss: 2.4258766545922286

Epoch: 5| Step: 7
Training loss: 0.13869138365512884
Validation loss: 2.4392574070902824

Epoch: 5| Step: 8
Training loss: 0.2911524355053925
Validation loss: 2.4490875830767984

Epoch: 5| Step: 9
Training loss: 0.16150192984735937
Validation loss: 2.447071239616387

Epoch: 5| Step: 10
Training loss: 0.11441578093072112
Validation loss: 2.466137337559818

Epoch: 493| Step: 0
Training loss: 0.19864116414834962
Validation loss: 2.440325035701419

Epoch: 5| Step: 1
Training loss: 0.11931142133751722
Validation loss: 2.4183925725255353

Epoch: 5| Step: 2
Training loss: 0.1486756773004905
Validation loss: 2.406129125236741

Epoch: 5| Step: 3
Training loss: 0.17458245733442682
Validation loss: 2.4244530882596598

Epoch: 5| Step: 4
Training loss: 0.13150885237968915
Validation loss: 2.400151759138434

Epoch: 5| Step: 5
Training loss: 0.2641074503499167
Validation loss: 2.4111623792170747

Epoch: 5| Step: 6
Training loss: 0.2812335618831423
Validation loss: 2.4080201866359334

Epoch: 5| Step: 7
Training loss: 0.1338486016881782
Validation loss: 2.412724349025362

Epoch: 5| Step: 8
Training loss: 0.175724375318781
Validation loss: 2.3896549784184535

Epoch: 5| Step: 9
Training loss: 0.22758336925128006
Validation loss: 2.417829884590977

Epoch: 5| Step: 10
Training loss: 0.14455680363519507
Validation loss: 2.397442348458199

Epoch: 494| Step: 0
Training loss: 0.10602227412929095
Validation loss: 2.3977561512792027

Epoch: 5| Step: 1
Training loss: 0.21668787097486544
Validation loss: 2.3975546568394757

Epoch: 5| Step: 2
Training loss: 0.12977183770931022
Validation loss: 2.379064300123886

Epoch: 5| Step: 3
Training loss: 0.16992708176275903
Validation loss: 2.4035846601674944

Epoch: 5| Step: 4
Training loss: 0.24762264529133568
Validation loss: 2.4095240770535193

Epoch: 5| Step: 5
Training loss: 0.17027098867253015
Validation loss: 2.4077477728529444

Epoch: 5| Step: 6
Training loss: 0.15037467178346958
Validation loss: 2.4321960766310466

Epoch: 5| Step: 7
Training loss: 0.24333193549289228
Validation loss: 2.452927086535918

Epoch: 5| Step: 8
Training loss: 0.17917975961913676
Validation loss: 2.4136061905672537

Epoch: 5| Step: 9
Training loss: 0.26180465199466096
Validation loss: 2.4343593106109207

Epoch: 5| Step: 10
Training loss: 0.22202861733322066
Validation loss: 2.3973948368899545

Epoch: 495| Step: 0
Training loss: 0.21498464819248048
Validation loss: 2.3884689879047616

Epoch: 5| Step: 1
Training loss: 0.17749217581966154
Validation loss: 2.372733154247724

Epoch: 5| Step: 2
Training loss: 0.2204489130062127
Validation loss: 2.4049096616807586

Epoch: 5| Step: 3
Training loss: 0.16132465271064825
Validation loss: 2.4245434665693

Epoch: 5| Step: 4
Training loss: 0.14001990976068282
Validation loss: 2.393235348408028

Epoch: 5| Step: 5
Training loss: 0.1487319748339476
Validation loss: 2.392771257780287

Epoch: 5| Step: 6
Training loss: 0.27302415122895823
Validation loss: 2.4017669334738407

Epoch: 5| Step: 7
Training loss: 0.2496956149442839
Validation loss: 2.389750794331246

Epoch: 5| Step: 8
Training loss: 0.11610952327925683
Validation loss: 2.4363861162999307

Epoch: 5| Step: 9
Training loss: 0.23885566234466923
Validation loss: 2.4336722024924473

Epoch: 5| Step: 10
Training loss: 0.19359619396166466
Validation loss: 2.4574978543498363

Epoch: 496| Step: 0
Training loss: 0.1880508913087502
Validation loss: 2.457351107363272

Epoch: 5| Step: 1
Training loss: 0.33598587885414827
Validation loss: 2.443258547372065

Epoch: 5| Step: 2
Training loss: 0.19944754720106322
Validation loss: 2.417532212797525

Epoch: 5| Step: 3
Training loss: 0.255907592889167
Validation loss: 2.4261985745996273

Epoch: 5| Step: 4
Training loss: 0.10568953734086065
Validation loss: 2.415865470061437

Epoch: 5| Step: 5
Training loss: 0.23584829437721988
Validation loss: 2.4215577975366176

Epoch: 5| Step: 6
Training loss: 0.26749023330541966
Validation loss: 2.4213261432594932

Epoch: 5| Step: 7
Training loss: 0.28789873668158955
Validation loss: 2.404893422137991

Epoch: 5| Step: 8
Training loss: 0.21315341444021157
Validation loss: 2.4082633721715943

Epoch: 5| Step: 9
Training loss: 0.19060158429398014
Validation loss: 2.412200008551347

Epoch: 5| Step: 10
Training loss: 0.10484592776587931
Validation loss: 2.3950338098735653

Epoch: 497| Step: 0
Training loss: 0.16889902814905378
Validation loss: 2.4195781151312885

Epoch: 5| Step: 1
Training loss: 0.17673013270185775
Validation loss: 2.400704059529388

Epoch: 5| Step: 2
Training loss: 0.12649440051773408
Validation loss: 2.4437970977710326

Epoch: 5| Step: 3
Training loss: 0.18145576422311013
Validation loss: 2.475964926830132

Epoch: 5| Step: 4
Training loss: 0.29177335366020024
Validation loss: 2.4644010012365323

Epoch: 5| Step: 5
Training loss: 0.2745827397415815
Validation loss: 2.4382567660007477

Epoch: 5| Step: 6
Training loss: 0.17807825587784043
Validation loss: 2.4026464277440294

Epoch: 5| Step: 7
Training loss: 0.2164846095948065
Validation loss: 2.3906562680344283

Epoch: 5| Step: 8
Training loss: 0.2934237189911156
Validation loss: 2.391999267576435

Epoch: 5| Step: 9
Training loss: 0.17288028349115453
Validation loss: 2.371699683097557

Epoch: 5| Step: 10
Training loss: 0.34117589944257043
Validation loss: 2.4309335623477226

Epoch: 498| Step: 0
Training loss: 0.2849249097339795
Validation loss: 2.377689788947565

Epoch: 5| Step: 1
Training loss: 0.19385222038065475
Validation loss: 2.417631939539356

Epoch: 5| Step: 2
Training loss: 0.2677378769292965
Validation loss: 2.425480244821281

Epoch: 5| Step: 3
Training loss: 0.2019268332361682
Validation loss: 2.398235607959208

Epoch: 5| Step: 4
Training loss: 0.3071893168654707
Validation loss: 2.434224622144864

Epoch: 5| Step: 5
Training loss: 0.25178125714740834
Validation loss: 2.3917754218404443

Epoch: 5| Step: 6
Training loss: 0.3111981933252017
Validation loss: 2.3964490360627315

Epoch: 5| Step: 7
Training loss: 0.19288507724723927
Validation loss: 2.394405907526764

Epoch: 5| Step: 8
Training loss: 0.21044622715640324
Validation loss: 2.37858634163776

Epoch: 5| Step: 9
Training loss: 0.2491106217298168
Validation loss: 2.3942760919154136

Epoch: 5| Step: 10
Training loss: 0.18849663306386294
Validation loss: 2.402091549890241

Epoch: 499| Step: 0
Training loss: 0.2688094439302878
Validation loss: 2.403525937241958

Epoch: 5| Step: 1
Training loss: 0.20377556533676555
Validation loss: 2.3942971724978936

Epoch: 5| Step: 2
Training loss: 0.28388281190622705
Validation loss: 2.4221436837443875

Epoch: 5| Step: 3
Training loss: 0.1869373920833183
Validation loss: 2.4057880944308736

Epoch: 5| Step: 4
Training loss: 0.12209651665766418
Validation loss: 2.3974405509252876

Epoch: 5| Step: 5
Training loss: 0.2898040358693795
Validation loss: 2.394368900819766

Epoch: 5| Step: 6
Training loss: 0.2249348148653112
Validation loss: 2.403401112927735

Epoch: 5| Step: 7
Training loss: 0.2081334804548393
Validation loss: 2.401213703679249

Epoch: 5| Step: 8
Training loss: 0.18732738496572335
Validation loss: 2.4113419917839405

Epoch: 5| Step: 9
Training loss: 0.20965170155332125
Validation loss: 2.397504001096425

Epoch: 5| Step: 10
Training loss: 0.27143048362174893
Validation loss: 2.3947819629030063

Epoch: 500| Step: 0
Training loss: 0.13366887339483144
Validation loss: 2.4241861552913067

Epoch: 5| Step: 1
Training loss: 0.20809578266631892
Validation loss: 2.422707385062313

Epoch: 5| Step: 2
Training loss: 0.2886872046172437
Validation loss: 2.4417930011207796

Epoch: 5| Step: 3
Training loss: 0.1614467106501791
Validation loss: 2.3839322820300866

Epoch: 5| Step: 4
Training loss: 0.16516215344527413
Validation loss: 2.427046206779785

Epoch: 5| Step: 5
Training loss: 0.16747560855497526
Validation loss: 2.4114967062654986

Epoch: 5| Step: 6
Training loss: 0.2206355388085651
Validation loss: 2.4199437195197997

Epoch: 5| Step: 7
Training loss: 0.3111651880885198
Validation loss: 2.4251372057173803

Epoch: 5| Step: 8
Training loss: 0.2172670249660672
Validation loss: 2.4541046964033044

Epoch: 5| Step: 9
Training loss: 0.24654270273946902
Validation loss: 2.4476710981582808

Epoch: 5| Step: 10
Training loss: 0.13713290971661152
Validation loss: 2.4497060449149997

Testing loss: 2.6721676374356056
