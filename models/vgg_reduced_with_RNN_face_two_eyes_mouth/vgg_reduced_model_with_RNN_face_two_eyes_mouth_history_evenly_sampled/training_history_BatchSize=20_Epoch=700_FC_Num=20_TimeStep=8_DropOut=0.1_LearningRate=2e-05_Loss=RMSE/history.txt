Epoch: 1| Step: 0
Training loss: 5.546336660991258
Validation loss: 5.696781266762643

Epoch: 5| Step: 1
Training loss: 5.180059221142737
Validation loss: 5.673025437334647

Epoch: 5| Step: 2
Training loss: 4.911012901045303
Validation loss: 5.649893438227475

Epoch: 5| Step: 3
Training loss: 5.839947284303794
Validation loss: 5.625408432145778

Epoch: 5| Step: 4
Training loss: 5.87436688846824
Validation loss: 5.5978087275005475

Epoch: 5| Step: 5
Training loss: 6.3142851769731285
Validation loss: 5.5660064308430295

Epoch: 5| Step: 6
Training loss: 5.091067303948648
Validation loss: 5.530414228711185

Epoch: 5| Step: 7
Training loss: 5.362376092933109
Validation loss: 5.488964412594149

Epoch: 5| Step: 8
Training loss: 5.795906582371067
Validation loss: 5.443077204041335

Epoch: 5| Step: 9
Training loss: 5.406836505453453
Validation loss: 5.391224391452624

Epoch: 5| Step: 10
Training loss: 6.008272190638244
Validation loss: 5.33570651096405

Epoch: 2| Step: 0
Training loss: 5.178871976652978
Validation loss: 5.27481040860767

Epoch: 5| Step: 1
Training loss: 6.028156969807332
Validation loss: 5.2107958511720485

Epoch: 5| Step: 2
Training loss: 4.159142427082747
Validation loss: 5.143302405009721

Epoch: 5| Step: 3
Training loss: 5.512156144055184
Validation loss: 5.076988223477992

Epoch: 5| Step: 4
Training loss: 5.244254828830956
Validation loss: 5.010007038435318

Epoch: 5| Step: 5
Training loss: 6.063036078908044
Validation loss: 4.942108574685354

Epoch: 5| Step: 6
Training loss: 4.804249614827717
Validation loss: 4.871452069096658

Epoch: 5| Step: 7
Training loss: 3.563107355111245
Validation loss: 4.80025244924025

Epoch: 5| Step: 8
Training loss: 4.206325744581754
Validation loss: 4.73302179025051

Epoch: 5| Step: 9
Training loss: 5.169312363721184
Validation loss: 4.669040686224306

Epoch: 5| Step: 10
Training loss: 4.695646607354223
Validation loss: 4.604762521203324

Epoch: 3| Step: 0
Training loss: 4.2636047721471755
Validation loss: 4.543269704370563

Epoch: 5| Step: 1
Training loss: 5.521208705976543
Validation loss: 4.492441962883326

Epoch: 5| Step: 2
Training loss: 5.00670784179444
Validation loss: 4.445038493681033

Epoch: 5| Step: 3
Training loss: 4.965891849748977
Validation loss: 4.410305100792298

Epoch: 5| Step: 4
Training loss: 4.098939591025223
Validation loss: 4.379060069029678

Epoch: 5| Step: 5
Training loss: 3.4905433966268564
Validation loss: 4.35061834568238

Epoch: 5| Step: 6
Training loss: 4.228539757076058
Validation loss: 4.32607637471884

Epoch: 5| Step: 7
Training loss: 4.4013484449137765
Validation loss: 4.301857255456223

Epoch: 5| Step: 8
Training loss: 3.816208958284839
Validation loss: 4.275627168999909

Epoch: 5| Step: 9
Training loss: 4.541584305789313
Validation loss: 4.247247668503807

Epoch: 5| Step: 10
Training loss: 4.715076557723155
Validation loss: 4.220258098509424

Epoch: 4| Step: 0
Training loss: 4.254429248224656
Validation loss: 4.1928665505285085

Epoch: 5| Step: 1
Training loss: 4.746724254030228
Validation loss: 4.161809907825297

Epoch: 5| Step: 2
Training loss: 4.178676818152072
Validation loss: 4.129171289085608

Epoch: 5| Step: 3
Training loss: 4.037606838454383
Validation loss: 4.101883727980359

Epoch: 5| Step: 4
Training loss: 4.388052081290198
Validation loss: 4.0755772052813315

Epoch: 5| Step: 5
Training loss: 3.7139684887495754
Validation loss: 4.053113072267457

Epoch: 5| Step: 6
Training loss: 4.017041620716465
Validation loss: 4.038239047600885

Epoch: 5| Step: 7
Training loss: 4.864430045980845
Validation loss: 4.023212023608781

Epoch: 5| Step: 8
Training loss: 3.787102449911474
Validation loss: 4.003061728903537

Epoch: 5| Step: 9
Training loss: 3.5758393162719013
Validation loss: 3.9879034624597667

Epoch: 5| Step: 10
Training loss: 4.666435417621885
Validation loss: 3.9727180764846723

Epoch: 5| Step: 0
Training loss: 4.761250874265639
Validation loss: 3.951424295722248

Epoch: 5| Step: 1
Training loss: 3.8854438569427434
Validation loss: 3.936380091990023

Epoch: 5| Step: 2
Training loss: 4.400735854258917
Validation loss: 3.9265993029489428

Epoch: 5| Step: 3
Training loss: 4.135752679480493
Validation loss: 3.910478442661701

Epoch: 5| Step: 4
Training loss: 3.690471163393221
Validation loss: 3.897712458761842

Epoch: 5| Step: 5
Training loss: 3.98601088506779
Validation loss: 3.8891830740804827

Epoch: 5| Step: 6
Training loss: 3.2663173397931495
Validation loss: 3.8730085338541307

Epoch: 5| Step: 7
Training loss: 3.833049736036654
Validation loss: 3.858710379365477

Epoch: 5| Step: 8
Training loss: 4.231946861322877
Validation loss: 3.844030845367151

Epoch: 5| Step: 9
Training loss: 3.7640996985776716
Validation loss: 3.8285405683271834

Epoch: 5| Step: 10
Training loss: 4.48751412817131
Validation loss: 3.814464428126009

Epoch: 6| Step: 0
Training loss: 3.7410535268943783
Validation loss: 3.8017739141257434

Epoch: 5| Step: 1
Training loss: 3.718306442863411
Validation loss: 3.7884854278892033

Epoch: 5| Step: 2
Training loss: 4.220882074815873
Validation loss: 3.7758427963532775

Epoch: 5| Step: 3
Training loss: 3.0759613643248733
Validation loss: 3.7666125736241898

Epoch: 5| Step: 4
Training loss: 3.5212884341719723
Validation loss: 3.7513064498025406

Epoch: 5| Step: 5
Training loss: 4.42386046138844
Validation loss: 3.7399829179479966

Epoch: 5| Step: 6
Training loss: 4.075035591204092
Validation loss: 3.7226785101461375

Epoch: 5| Step: 7
Training loss: 4.452800538138475
Validation loss: 3.7096443725423005

Epoch: 5| Step: 8
Training loss: 3.743998493487715
Validation loss: 3.695923071684873

Epoch: 5| Step: 9
Training loss: 3.913006242169481
Validation loss: 3.683224253685847

Epoch: 5| Step: 10
Training loss: 4.002240030589267
Validation loss: 3.6735536011615855

Epoch: 7| Step: 0
Training loss: 4.409800512598397
Validation loss: 3.658325730765621

Epoch: 5| Step: 1
Training loss: 3.5853463809749018
Validation loss: 3.6445923739781776

Epoch: 5| Step: 2
Training loss: 4.0179707247710486
Validation loss: 3.6305560290364776

Epoch: 5| Step: 3
Training loss: 3.4989179573481595
Validation loss: 3.618336789472383

Epoch: 5| Step: 4
Training loss: 4.118439746337667
Validation loss: 3.6004709836375732

Epoch: 5| Step: 5
Training loss: 2.8474166204152995
Validation loss: 3.588312379110675

Epoch: 5| Step: 6
Training loss: 4.074744449395674
Validation loss: 3.5910403415299803

Epoch: 5| Step: 7
Training loss: 3.167490366836026
Validation loss: 3.5711881747987326

Epoch: 5| Step: 8
Training loss: 3.052674081198402
Validation loss: 3.5657243887181105

Epoch: 5| Step: 9
Training loss: 4.662934286637442
Validation loss: 3.558649304576324

Epoch: 5| Step: 10
Training loss: 3.9442100873166765
Validation loss: 3.5466688055626765

Epoch: 8| Step: 0
Training loss: 3.4830831690367026
Validation loss: 3.5426400692184647

Epoch: 5| Step: 1
Training loss: 4.0061662352757015
Validation loss: 3.5238464262235243

Epoch: 5| Step: 2
Training loss: 2.754788477924479
Validation loss: 3.511767481715657

Epoch: 5| Step: 3
Training loss: 4.335307527433535
Validation loss: 3.5062456629132606

Epoch: 5| Step: 4
Training loss: 3.2714438546930893
Validation loss: 3.4974361542546175

Epoch: 5| Step: 5
Training loss: 3.3443638603525376
Validation loss: 3.48930820096139

Epoch: 5| Step: 6
Training loss: 3.544960076412621
Validation loss: 3.4816798701717033

Epoch: 5| Step: 7
Training loss: 3.4524716410760106
Validation loss: 3.4756446407472366

Epoch: 5| Step: 8
Training loss: 4.689675601891517
Validation loss: 3.46474986345636

Epoch: 5| Step: 9
Training loss: 3.7681887434887305
Validation loss: 3.4542849646192164

Epoch: 5| Step: 10
Training loss: 3.6600894168708153
Validation loss: 3.447869683472773

Epoch: 9| Step: 0
Training loss: 3.9917427905209864
Validation loss: 3.433324036992318

Epoch: 5| Step: 1
Training loss: 3.865294330241801
Validation loss: 3.4228190282375204

Epoch: 5| Step: 2
Training loss: 2.2982219457525153
Validation loss: 3.418291177428547

Epoch: 5| Step: 3
Training loss: 3.99977421123302
Validation loss: 3.4152176278102595

Epoch: 5| Step: 4
Training loss: 3.536812646090047
Validation loss: 3.3963939843866484

Epoch: 5| Step: 5
Training loss: 2.4278484879280406
Validation loss: 3.3864540670086933

Epoch: 5| Step: 6
Training loss: 3.8197878611912985
Validation loss: 3.380689148056838

Epoch: 5| Step: 7
Training loss: 3.748841806211685
Validation loss: 3.362285981124415

Epoch: 5| Step: 8
Training loss: 3.9112549723431735
Validation loss: 3.3554107879900816

Epoch: 5| Step: 9
Training loss: 3.6518490379777746
Validation loss: 3.3513658751146256

Epoch: 5| Step: 10
Training loss: 4.054198954114844
Validation loss: 3.34460719302238

Epoch: 10| Step: 0
Training loss: 3.7783181670402928
Validation loss: 3.3470602378568675

Epoch: 5| Step: 1
Training loss: 3.359455622215706
Validation loss: 3.3260859108126324

Epoch: 5| Step: 2
Training loss: 4.031415832420615
Validation loss: 3.332876154608809

Epoch: 5| Step: 3
Training loss: 3.2871201096267084
Validation loss: 3.3313979611322

Epoch: 5| Step: 4
Training loss: 3.9949417318169727
Validation loss: 3.3377888501853543

Epoch: 5| Step: 5
Training loss: 2.9300525488714277
Validation loss: 3.331485490425655

Epoch: 5| Step: 6
Training loss: 3.6100690430355207
Validation loss: 3.3368227035587603

Epoch: 5| Step: 7
Training loss: 3.256063966324281
Validation loss: 3.3255954742759837

Epoch: 5| Step: 8
Training loss: 3.955529247034524
Validation loss: 3.310519554554696

Epoch: 5| Step: 9
Training loss: 3.030922468914908
Validation loss: 3.2983963024501253

Epoch: 5| Step: 10
Training loss: 3.8019429359468035
Validation loss: 3.2946305618398766

Epoch: 11| Step: 0
Training loss: 3.2917959131547487
Validation loss: 3.2867978746190993

Epoch: 5| Step: 1
Training loss: 3.08882967467539
Validation loss: 3.2837962875514934

Epoch: 5| Step: 2
Training loss: 3.6259766940058555
Validation loss: 3.2832974344850694

Epoch: 5| Step: 3
Training loss: 3.4137810562715782
Validation loss: 3.2696054673932737

Epoch: 5| Step: 4
Training loss: 4.1046547123500154
Validation loss: 3.287403283969116

Epoch: 5| Step: 5
Training loss: 3.160220679532866
Validation loss: 3.2647143024030565

Epoch: 5| Step: 6
Training loss: 3.364358868901307
Validation loss: 3.2551666293846537

Epoch: 5| Step: 7
Training loss: 3.7758127007179954
Validation loss: 3.253537954011822

Epoch: 5| Step: 8
Training loss: 3.405665496232565
Validation loss: 3.253926773832837

Epoch: 5| Step: 9
Training loss: 3.431378827343067
Validation loss: 3.2510524131202825

Epoch: 5| Step: 10
Training loss: 3.9713507113415636
Validation loss: 3.244398154665388

Epoch: 12| Step: 0
Training loss: 3.3093259467360907
Validation loss: 3.2358075188058586

Epoch: 5| Step: 1
Training loss: 3.2942701417623206
Validation loss: 3.226582174398334

Epoch: 5| Step: 2
Training loss: 2.8704703763633566
Validation loss: 3.2198786562215376

Epoch: 5| Step: 3
Training loss: 3.3971209902863397
Validation loss: 3.210902254850157

Epoch: 5| Step: 4
Training loss: 3.3214270303139575
Validation loss: 3.2066672982461775

Epoch: 5| Step: 5
Training loss: 3.673800219399932
Validation loss: 3.2002982026919646

Epoch: 5| Step: 6
Training loss: 3.6385252304135474
Validation loss: 3.192299668515833

Epoch: 5| Step: 7
Training loss: 3.4560562051865134
Validation loss: 3.1890552819373967

Epoch: 5| Step: 8
Training loss: 3.8807507573187032
Validation loss: 3.1843401282262005

Epoch: 5| Step: 9
Training loss: 4.229890708142709
Validation loss: 3.1806266054763137

Epoch: 5| Step: 10
Training loss: 2.6012580395583016
Validation loss: 3.177698335611438

Epoch: 13| Step: 0
Training loss: 3.037333096914754
Validation loss: 3.1728760219582055

Epoch: 5| Step: 1
Training loss: 3.147067166988979
Validation loss: 3.1645581220715826

Epoch: 5| Step: 2
Training loss: 3.479256466983904
Validation loss: 3.1629879189023886

Epoch: 5| Step: 3
Training loss: 3.3423236407230132
Validation loss: 3.1573216826049477

Epoch: 5| Step: 4
Training loss: 3.782111203822682
Validation loss: 3.1534827760524924

Epoch: 5| Step: 5
Training loss: 3.006399164444755
Validation loss: 3.1490924487522127

Epoch: 5| Step: 6
Training loss: 4.058847986653327
Validation loss: 3.1570335154002973

Epoch: 5| Step: 7
Training loss: 3.3035569297442904
Validation loss: 3.14051550670889

Epoch: 5| Step: 8
Training loss: 3.6553241829148546
Validation loss: 3.1393588619903436

Epoch: 5| Step: 9
Training loss: 3.0945558365459314
Validation loss: 3.1411364155344175

Epoch: 5| Step: 10
Training loss: 3.5888093904784806
Validation loss: 3.136478476627009

Epoch: 14| Step: 0
Training loss: 3.8085446711581357
Validation loss: 3.1254120618627512

Epoch: 5| Step: 1
Training loss: 2.9334494076506745
Validation loss: 3.122914285604223

Epoch: 5| Step: 2
Training loss: 3.242371335620237
Validation loss: 3.1223764296907213

Epoch: 5| Step: 3
Training loss: 3.231730536435833
Validation loss: 3.1232320300483405

Epoch: 5| Step: 4
Training loss: 3.4912834618778295
Validation loss: 3.119463004286646

Epoch: 5| Step: 5
Training loss: 3.0422127290139027
Validation loss: 3.1182453207915195

Epoch: 5| Step: 6
Training loss: 3.5851169553271234
Validation loss: 3.114716587939943

Epoch: 5| Step: 7
Training loss: 3.4195166695806645
Validation loss: 3.1104155384640246

Epoch: 5| Step: 8
Training loss: 3.352120448622811
Validation loss: 3.10683672754229

Epoch: 5| Step: 9
Training loss: 3.322961230960762
Validation loss: 3.1078648318679405

Epoch: 5| Step: 10
Training loss: 3.8834051221070442
Validation loss: 3.1280494626976973

Epoch: 15| Step: 0
Training loss: 3.4293034714347366
Validation loss: 3.1016883517702314

Epoch: 5| Step: 1
Training loss: 3.6038267089216447
Validation loss: 3.104106153972111

Epoch: 5| Step: 2
Training loss: 2.7419243928152954
Validation loss: 3.116484276992673

Epoch: 5| Step: 3
Training loss: 3.7779765185893104
Validation loss: 3.12876445821838

Epoch: 5| Step: 4
Training loss: 3.712945976828004
Validation loss: 3.117507434157217

Epoch: 5| Step: 5
Training loss: 2.9823582410737624
Validation loss: 3.101993594373668

Epoch: 5| Step: 6
Training loss: 3.328134169588307
Validation loss: 3.120929551935582

Epoch: 5| Step: 7
Training loss: 2.794085939422308
Validation loss: 3.100308383219959

Epoch: 5| Step: 8
Training loss: 3.866372378978104
Validation loss: 3.096724757937336

Epoch: 5| Step: 9
Training loss: 3.60914313822543
Validation loss: 3.0947209907436304

Epoch: 5| Step: 10
Training loss: 3.1537332604047545
Validation loss: 3.093231865452246

Epoch: 16| Step: 0
Training loss: 3.25524567035879
Validation loss: 3.0933133394407055

Epoch: 5| Step: 1
Training loss: 3.0809929359402104
Validation loss: 3.0906853460577355

Epoch: 5| Step: 2
Training loss: 3.156637186908396
Validation loss: 3.0896700874348184

Epoch: 5| Step: 3
Training loss: 3.7503031290244144
Validation loss: 3.0871904850489607

Epoch: 5| Step: 4
Training loss: 3.37853846670724
Validation loss: 3.084844701612952

Epoch: 5| Step: 5
Training loss: 3.589522022528867
Validation loss: 3.0837008920397975

Epoch: 5| Step: 6
Training loss: 3.062132677120245
Validation loss: 3.0820545969381

Epoch: 5| Step: 7
Training loss: 3.47188296038164
Validation loss: 3.0783674262184646

Epoch: 5| Step: 8
Training loss: 3.854882347399526
Validation loss: 3.0728591184961274

Epoch: 5| Step: 9
Training loss: 2.964813031224672
Validation loss: 3.074068691467329

Epoch: 5| Step: 10
Training loss: 3.350708468094349
Validation loss: 3.070261317146946

Epoch: 17| Step: 0
Training loss: 2.986027764234093
Validation loss: 3.071685913850719

Epoch: 5| Step: 1
Training loss: 3.899773561799837
Validation loss: 3.0711810572658322

Epoch: 5| Step: 2
Training loss: 2.8098371827819304
Validation loss: 3.0703889386973056

Epoch: 5| Step: 3
Training loss: 2.733382388194219
Validation loss: 3.0664618127660312

Epoch: 5| Step: 4
Training loss: 3.160407623365251
Validation loss: 3.0673019360333047

Epoch: 5| Step: 5
Training loss: 3.7319577106643385
Validation loss: 3.066083006225238

Epoch: 5| Step: 6
Training loss: 3.3416040968011607
Validation loss: 3.0937247243681316

Epoch: 5| Step: 7
Training loss: 3.969241855210056
Validation loss: 3.062213374493899

Epoch: 5| Step: 8
Training loss: 2.864427615470501
Validation loss: 3.062657703577455

Epoch: 5| Step: 9
Training loss: 4.0346428839097515
Validation loss: 3.0728241650879844

Epoch: 5| Step: 10
Training loss: 2.910317804345436
Validation loss: 3.0769059044072407

Epoch: 18| Step: 0
Training loss: 3.467825826616025
Validation loss: 3.082034826747749

Epoch: 5| Step: 1
Training loss: 3.542636977773283
Validation loss: 3.0632235534725964

Epoch: 5| Step: 2
Training loss: 2.8970126122439455
Validation loss: 3.0560565640910538

Epoch: 5| Step: 3
Training loss: 2.884554700946735
Validation loss: 3.0528038471058614

Epoch: 5| Step: 4
Training loss: 3.8342517637114564
Validation loss: 3.0534997305183995

Epoch: 5| Step: 5
Training loss: 3.0048115609951056
Validation loss: 3.051767387417775

Epoch: 5| Step: 6
Training loss: 3.2374393118689757
Validation loss: 3.0509174229297145

Epoch: 5| Step: 7
Training loss: 3.370241979180424
Validation loss: 3.0481561559289796

Epoch: 5| Step: 8
Training loss: 3.48442919222852
Validation loss: 3.0502678839415456

Epoch: 5| Step: 9
Training loss: 3.456515619649626
Validation loss: 3.0465055878589764

Epoch: 5| Step: 10
Training loss: 3.4456028545629094
Validation loss: 3.0440542251255462

Epoch: 19| Step: 0
Training loss: 3.562689123654923
Validation loss: 3.0444584613787056

Epoch: 5| Step: 1
Training loss: 3.313833867828086
Validation loss: 3.0417041554306126

Epoch: 5| Step: 2
Training loss: 3.6759005941704483
Validation loss: 3.0400361210960645

Epoch: 5| Step: 3
Training loss: 2.9142845416934864
Validation loss: 3.036664887180088

Epoch: 5| Step: 4
Training loss: 3.420559983167918
Validation loss: 3.036578664845726

Epoch: 5| Step: 5
Training loss: 3.246608872287621
Validation loss: 3.0359235602312835

Epoch: 5| Step: 6
Training loss: 4.160724726417675
Validation loss: 3.0347259250634955

Epoch: 5| Step: 7
Training loss: 3.3588080349143614
Validation loss: 3.039575005655644

Epoch: 5| Step: 8
Training loss: 2.504121530118648
Validation loss: 3.0396369652428104

Epoch: 5| Step: 9
Training loss: 3.063182209868439
Validation loss: 3.0495313719787784

Epoch: 5| Step: 10
Training loss: 3.030434567602156
Validation loss: 3.0526095619174067

Epoch: 20| Step: 0
Training loss: 3.182572389365214
Validation loss: 3.0562818382502734

Epoch: 5| Step: 1
Training loss: 3.2567987488506467
Validation loss: 3.027697121025455

Epoch: 5| Step: 2
Training loss: 3.3463572382139763
Validation loss: 3.0248364061842614

Epoch: 5| Step: 3
Training loss: 3.181608102724742
Validation loss: 3.0259534330768116

Epoch: 5| Step: 4
Training loss: 3.1300913724877217
Validation loss: 3.0266167638505577

Epoch: 5| Step: 5
Training loss: 3.2898673117180484
Validation loss: 3.0311329155837763

Epoch: 5| Step: 6
Training loss: 3.2887390412597877
Validation loss: 3.0272101852798396

Epoch: 5| Step: 7
Training loss: 4.071916436242905
Validation loss: 3.0258847924326737

Epoch: 5| Step: 8
Training loss: 3.139707212951017
Validation loss: 3.024736587498704

Epoch: 5| Step: 9
Training loss: 3.393273088586173
Validation loss: 3.02547834569174

Epoch: 5| Step: 10
Training loss: 3.1018407586333225
Validation loss: 3.0245718354747555

Epoch: 21| Step: 0
Training loss: 3.6385243130472196
Validation loss: 3.024724185152502

Epoch: 5| Step: 1
Training loss: 3.070882263897974
Validation loss: 3.0254600598123584

Epoch: 5| Step: 2
Training loss: 3.9337472137547977
Validation loss: 3.023420607641082

Epoch: 5| Step: 3
Training loss: 3.0707600585255976
Validation loss: 3.0247960143135115

Epoch: 5| Step: 4
Training loss: 3.5748555934524244
Validation loss: 3.0196691666571542

Epoch: 5| Step: 5
Training loss: 2.8852041191470432
Validation loss: 3.016362962769854

Epoch: 5| Step: 6
Training loss: 3.0234662037356785
Validation loss: 3.0184509835138797

Epoch: 5| Step: 7
Training loss: 3.6341412483019786
Validation loss: 3.017770538583221

Epoch: 5| Step: 8
Training loss: 2.8895756646906925
Validation loss: 3.01690431951716

Epoch: 5| Step: 9
Training loss: 3.0926662820381483
Validation loss: 3.0236976466887784

Epoch: 5| Step: 10
Training loss: 3.4609924725371037
Validation loss: 3.047509472386657

Epoch: 22| Step: 0
Training loss: 3.223957774583874
Validation loss: 3.072719161477297

Epoch: 5| Step: 1
Training loss: 3.0351685041379075
Validation loss: 3.047882815381293

Epoch: 5| Step: 2
Training loss: 3.2508265104583223
Validation loss: 3.0125658314957766

Epoch: 5| Step: 3
Training loss: 3.2254725501850223
Validation loss: 3.0088371041395403

Epoch: 5| Step: 4
Training loss: 3.7370741279401627
Validation loss: 3.0101688909103

Epoch: 5| Step: 5
Training loss: 3.8040748431908717
Validation loss: 3.0138296438080348

Epoch: 5| Step: 6
Training loss: 2.9794697818520057
Validation loss: 3.0140988258666597

Epoch: 5| Step: 7
Training loss: 3.5368596983593945
Validation loss: 3.015396822781537

Epoch: 5| Step: 8
Training loss: 3.552121084838604
Validation loss: 3.00899890843756

Epoch: 5| Step: 9
Training loss: 3.2097083939102613
Validation loss: 3.0070489138708942

Epoch: 5| Step: 10
Training loss: 2.436744768567006
Validation loss: 3.002446851686268

Epoch: 23| Step: 0
Training loss: 3.7528742901031062
Validation loss: 3.026656292872314

Epoch: 5| Step: 1
Training loss: 2.610568841353462
Validation loss: 3.0412895574586187

Epoch: 5| Step: 2
Training loss: 3.405827487324202
Validation loss: 3.0712196654622117

Epoch: 5| Step: 3
Training loss: 3.7750922892828114
Validation loss: 3.0509438699502183

Epoch: 5| Step: 4
Training loss: 3.8338250522089323
Validation loss: 3.0052811768818266

Epoch: 5| Step: 5
Training loss: 2.770218735607196
Validation loss: 3.0035721557488997

Epoch: 5| Step: 6
Training loss: 3.603576494235232
Validation loss: 3.012337877011811

Epoch: 5| Step: 7
Training loss: 2.9617934788861064
Validation loss: 3.0095769672909944

Epoch: 5| Step: 8
Training loss: 3.282862820936389
Validation loss: 2.9985912477984056

Epoch: 5| Step: 9
Training loss: 3.3438402680663866
Validation loss: 2.996215653545609

Epoch: 5| Step: 10
Training loss: 2.7016459040125382
Validation loss: 3.0016893215993594

Epoch: 24| Step: 0
Training loss: 2.8809206164041488
Validation loss: 3.0304187598647543

Epoch: 5| Step: 1
Training loss: 3.5513550281132926
Validation loss: 3.0384946717010615

Epoch: 5| Step: 2
Training loss: 4.082655221075472
Validation loss: 3.008294554725111

Epoch: 5| Step: 3
Training loss: 3.606243938791348
Validation loss: 2.9952860314588317

Epoch: 5| Step: 4
Training loss: 3.2924813015000614
Validation loss: 2.992763581530925

Epoch: 5| Step: 5
Training loss: 2.85791478628373
Validation loss: 3.001085768527357

Epoch: 5| Step: 6
Training loss: 3.4770777631242287
Validation loss: 3.021776204245483

Epoch: 5| Step: 7
Training loss: 3.3944753416174103
Validation loss: 3.003589717942436

Epoch: 5| Step: 8
Training loss: 3.2488650761207234
Validation loss: 2.9896913059959043

Epoch: 5| Step: 9
Training loss: 2.37046873599945
Validation loss: 2.989608730811265

Epoch: 5| Step: 10
Training loss: 3.2417252176549116
Validation loss: 2.997647441477653

Epoch: 25| Step: 0
Training loss: 2.9784650354310283
Validation loss: 3.0113005182470522

Epoch: 5| Step: 1
Training loss: 3.395077080954145
Validation loss: 3.019547135111347

Epoch: 5| Step: 2
Training loss: 3.3547450607471534
Validation loss: 3.0134059471883017

Epoch: 5| Step: 3
Training loss: 3.5153287635608095
Validation loss: 3.01378812703864

Epoch: 5| Step: 4
Training loss: 3.6157009950925265
Validation loss: 3.0116763690711594

Epoch: 5| Step: 5
Training loss: 3.1971645071250427
Validation loss: 3.003867734202906

Epoch: 5| Step: 6
Training loss: 3.541310924540518
Validation loss: 2.9975145206224405

Epoch: 5| Step: 7
Training loss: 3.676912269539569
Validation loss: 2.9929466941218834

Epoch: 5| Step: 8
Training loss: 3.1872802359424246
Validation loss: 2.9874078730999383

Epoch: 5| Step: 9
Training loss: 3.0270202070052594
Validation loss: 2.9839588096923273

Epoch: 5| Step: 10
Training loss: 2.235634935382013
Validation loss: 2.982232397866772

Epoch: 26| Step: 0
Training loss: 3.103750384450175
Validation loss: 2.979099374176491

Epoch: 5| Step: 1
Training loss: 3.566682201125876
Validation loss: 2.9791203059306612

Epoch: 5| Step: 2
Training loss: 3.6057805911154173
Validation loss: 2.9807666005109468

Epoch: 5| Step: 3
Training loss: 3.525561045915467
Validation loss: 2.980681482514245

Epoch: 5| Step: 4
Training loss: 3.38113213578726
Validation loss: 2.975472449158986

Epoch: 5| Step: 5
Training loss: 2.7374801007945417
Validation loss: 2.977334746989572

Epoch: 5| Step: 6
Training loss: 3.2329511226471985
Validation loss: 2.9779778663037897

Epoch: 5| Step: 7
Training loss: 3.02437764220685
Validation loss: 2.9823975143041035

Epoch: 5| Step: 8
Training loss: 3.5558960589310518
Validation loss: 2.9886991389489976

Epoch: 5| Step: 9
Training loss: 3.052640341142101
Validation loss: 2.975734280349326

Epoch: 5| Step: 10
Training loss: 2.937007294585716
Validation loss: 2.971188016610423

Epoch: 27| Step: 0
Training loss: 3.1253445244654943
Validation loss: 2.9795586961765363

Epoch: 5| Step: 1
Training loss: 3.876241546592118
Validation loss: 2.9812954531718043

Epoch: 5| Step: 2
Training loss: 3.222380729225973
Validation loss: 2.9730369939905343

Epoch: 5| Step: 3
Training loss: 3.167975372796715
Validation loss: 2.9703431272395227

Epoch: 5| Step: 4
Training loss: 3.2713932764834905
Validation loss: 2.968108381053478

Epoch: 5| Step: 5
Training loss: 3.5624755055438766
Validation loss: 2.9675227255246983

Epoch: 5| Step: 6
Training loss: 2.953952088160529
Validation loss: 2.9682965435866535

Epoch: 5| Step: 7
Training loss: 3.4661679667227836
Validation loss: 2.9667169246815597

Epoch: 5| Step: 8
Training loss: 3.057697656937761
Validation loss: 2.963480369051726

Epoch: 5| Step: 9
Training loss: 2.9082557565859526
Validation loss: 2.9651545376933117

Epoch: 5| Step: 10
Training loss: 2.9562384123302894
Validation loss: 2.964478362204165

Epoch: 28| Step: 0
Training loss: 2.609379933975032
Validation loss: 2.9701907691830143

Epoch: 5| Step: 1
Training loss: 3.714149257752346
Validation loss: 2.9758208717161105

Epoch: 5| Step: 2
Training loss: 3.638927407744349
Validation loss: 2.9689169041812513

Epoch: 5| Step: 3
Training loss: 2.8526258184449276
Validation loss: 2.9597624314192013

Epoch: 5| Step: 4
Training loss: 3.7308392884939208
Validation loss: 2.972411505101152

Epoch: 5| Step: 5
Training loss: 3.4398231285667515
Validation loss: 2.963946752809287

Epoch: 5| Step: 6
Training loss: 3.0209747456742275
Validation loss: 2.961739736866275

Epoch: 5| Step: 7
Training loss: 3.2911421120444437
Validation loss: 2.972157231288849

Epoch: 5| Step: 8
Training loss: 3.0753681985877344
Validation loss: 2.957344862920122

Epoch: 5| Step: 9
Training loss: 3.5812221932122226
Validation loss: 2.9549500494211474

Epoch: 5| Step: 10
Training loss: 2.474140414848946
Validation loss: 2.9572807778168095

Epoch: 29| Step: 0
Training loss: 2.389743218453917
Validation loss: 2.9754418056514718

Epoch: 5| Step: 1
Training loss: 3.511553903684442
Validation loss: 2.9943001694878073

Epoch: 5| Step: 2
Training loss: 3.2637646500409514
Validation loss: 2.991351709357747

Epoch: 5| Step: 3
Training loss: 3.1765934467450063
Validation loss: 2.979708321935329

Epoch: 5| Step: 4
Training loss: 3.769323028980371
Validation loss: 2.9659252412975023

Epoch: 5| Step: 5
Training loss: 3.640335791892607
Validation loss: 2.966825997112598

Epoch: 5| Step: 6
Training loss: 3.4026056795434623
Validation loss: 2.9664073351545164

Epoch: 5| Step: 7
Training loss: 3.5405898009096823
Validation loss: 2.9726880416150023

Epoch: 5| Step: 8
Training loss: 2.8326009664023064
Validation loss: 2.9460489346788092

Epoch: 5| Step: 9
Training loss: 2.7650828719179863
Validation loss: 2.946531387649687

Epoch: 5| Step: 10
Training loss: 3.1123995232354615
Validation loss: 2.952434102398896

Epoch: 30| Step: 0
Training loss: 3.0253589448692355
Validation loss: 2.968573063584655

Epoch: 5| Step: 1
Training loss: 3.243899856075264
Validation loss: 3.0127328406810463

Epoch: 5| Step: 2
Training loss: 3.469339269125237
Validation loss: 2.9954604562651377

Epoch: 5| Step: 3
Training loss: 3.109630018348354
Validation loss: 2.958228547180011

Epoch: 5| Step: 4
Training loss: 3.3171661908134156
Validation loss: 2.9488896816088657

Epoch: 5| Step: 5
Training loss: 2.9934745391073863
Validation loss: 2.946813513427816

Epoch: 5| Step: 6
Training loss: 3.5968613134632497
Validation loss: 2.9459722554711325

Epoch: 5| Step: 7
Training loss: 3.4859703072680204
Validation loss: 2.950501826870358

Epoch: 5| Step: 8
Training loss: 2.9074191131230163
Validation loss: 2.942076813348083

Epoch: 5| Step: 9
Training loss: 3.339756372212264
Validation loss: 2.943778849396088

Epoch: 5| Step: 10
Training loss: 3.085313796741789
Validation loss: 2.94559594009621

Epoch: 31| Step: 0
Training loss: 3.2443697651523427
Validation loss: 2.958492341217476

Epoch: 5| Step: 1
Training loss: 3.0270302887111016
Validation loss: 2.9501708143060767

Epoch: 5| Step: 2
Training loss: 3.0660351960015264
Validation loss: 2.9568100314399404

Epoch: 5| Step: 3
Training loss: 3.2584166481182812
Validation loss: 2.9373166147701504

Epoch: 5| Step: 4
Training loss: 3.2159565775962173
Validation loss: 2.932069652046391

Epoch: 5| Step: 5
Training loss: 3.227076454885863
Validation loss: 2.9309792231728538

Epoch: 5| Step: 6
Training loss: 2.9746718922969118
Validation loss: 2.932204266620089

Epoch: 5| Step: 7
Training loss: 3.3738829565544814
Validation loss: 2.930459447960288

Epoch: 5| Step: 8
Training loss: 3.3161449891110237
Validation loss: 2.929691527004961

Epoch: 5| Step: 9
Training loss: 3.283111189735657
Validation loss: 2.9293964900480756

Epoch: 5| Step: 10
Training loss: 3.446178232358229
Validation loss: 2.928231422993547

Epoch: 32| Step: 0
Training loss: 2.2525923947300486
Validation loss: 2.923350729823969

Epoch: 5| Step: 1
Training loss: 3.2082038622076956
Validation loss: 2.9214344369207064

Epoch: 5| Step: 2
Training loss: 2.710028504225256
Validation loss: 2.9202693984683936

Epoch: 5| Step: 3
Training loss: 3.0733793438372503
Validation loss: 2.9182304239405523

Epoch: 5| Step: 4
Training loss: 3.101082483616073
Validation loss: 2.9168174482007436

Epoch: 5| Step: 5
Training loss: 3.636133394755083
Validation loss: 2.9158547204439125

Epoch: 5| Step: 6
Training loss: 3.7698578529981104
Validation loss: 2.91471042218905

Epoch: 5| Step: 7
Training loss: 3.6147543713707906
Validation loss: 2.9109809626926735

Epoch: 5| Step: 8
Training loss: 3.289945579009142
Validation loss: 2.909430485540815

Epoch: 5| Step: 9
Training loss: 3.2257413026937383
Validation loss: 2.9117500094059316

Epoch: 5| Step: 10
Training loss: 3.0870625050812173
Validation loss: 2.910640354142728

Epoch: 33| Step: 0
Training loss: 3.5103783006392106
Validation loss: 2.908526023896021

Epoch: 5| Step: 1
Training loss: 3.168926503459203
Validation loss: 2.9111450832192114

Epoch: 5| Step: 2
Training loss: 2.5211398881461946
Validation loss: 2.922850325785106

Epoch: 5| Step: 3
Training loss: 3.5111781500869403
Validation loss: 2.921505673778469

Epoch: 5| Step: 4
Training loss: 3.208767717027959
Validation loss: 2.9048733202243273

Epoch: 5| Step: 5
Training loss: 3.0246268995985113
Validation loss: 2.9044636301708446

Epoch: 5| Step: 6
Training loss: 2.7865048603677383
Validation loss: 2.9081446372905866

Epoch: 5| Step: 7
Training loss: 3.0001484516289394
Validation loss: 2.9244018748432627

Epoch: 5| Step: 8
Training loss: 3.459035932263277
Validation loss: 2.956711405223595

Epoch: 5| Step: 9
Training loss: 3.096904495052608
Validation loss: 3.0154571375967985

Epoch: 5| Step: 10
Training loss: 3.9121320460058273
Validation loss: 2.9775827911582664

Epoch: 34| Step: 0
Training loss: 2.5271329954026234
Validation loss: 2.924345893107056

Epoch: 5| Step: 1
Training loss: 2.670382791289324
Validation loss: 2.9034616398763546

Epoch: 5| Step: 2
Training loss: 3.149297629872959
Validation loss: 2.901971135066676

Epoch: 5| Step: 3
Training loss: 3.1715634949408478
Validation loss: 2.905705230990566

Epoch: 5| Step: 4
Training loss: 3.4491969072248643
Validation loss: 2.9070686521951368

Epoch: 5| Step: 5
Training loss: 2.611442066979364
Validation loss: 2.9079149681224714

Epoch: 5| Step: 6
Training loss: 3.1175530776191223
Validation loss: 2.9197834226394073

Epoch: 5| Step: 7
Training loss: 3.717271270385286
Validation loss: 2.908567517451419

Epoch: 5| Step: 8
Training loss: 3.4006923868113677
Validation loss: 2.913308520890634

Epoch: 5| Step: 9
Training loss: 3.789497146059767
Validation loss: 2.9101956695377678

Epoch: 5| Step: 10
Training loss: 3.348711557427518
Validation loss: 2.900193175592298

Epoch: 35| Step: 0
Training loss: 2.575657721656198
Validation loss: 2.897685349264443

Epoch: 5| Step: 1
Training loss: 2.7248244552764778
Validation loss: 2.898277197572196

Epoch: 5| Step: 2
Training loss: 2.989346981120652
Validation loss: 2.9015505953263627

Epoch: 5| Step: 3
Training loss: 3.314263791918482
Validation loss: 2.9081330899985693

Epoch: 5| Step: 4
Training loss: 2.782500339586866
Validation loss: 2.9170086222182823

Epoch: 5| Step: 5
Training loss: 3.40442181443854
Validation loss: 2.942788321173597

Epoch: 5| Step: 6
Training loss: 3.4698136906806205
Validation loss: 2.9675905719400433

Epoch: 5| Step: 7
Training loss: 3.7701859454128095
Validation loss: 2.91969358006036

Epoch: 5| Step: 8
Training loss: 3.4778128786384186
Validation loss: 2.8900002950532

Epoch: 5| Step: 9
Training loss: 3.044350541732549
Validation loss: 2.8897089213057643

Epoch: 5| Step: 10
Training loss: 3.3717095618191517
Validation loss: 2.8893073566778282

Epoch: 36| Step: 0
Training loss: 3.6452107506461098
Validation loss: 2.8898876115476972

Epoch: 5| Step: 1
Training loss: 3.25828640278794
Validation loss: 2.8959817719203995

Epoch: 5| Step: 2
Training loss: 3.485067940135928
Validation loss: 2.8971372920388925

Epoch: 5| Step: 3
Training loss: 2.8912900417406675
Validation loss: 2.897805149398515

Epoch: 5| Step: 4
Training loss: 2.678848624645646
Validation loss: 2.8928200725930644

Epoch: 5| Step: 5
Training loss: 3.2799899633765763
Validation loss: 2.886206334956853

Epoch: 5| Step: 6
Training loss: 3.6392539393712955
Validation loss: 2.8846025524900476

Epoch: 5| Step: 7
Training loss: 3.7097785505230494
Validation loss: 2.8841535653333787

Epoch: 5| Step: 8
Training loss: 2.248621836429826
Validation loss: 2.885864640327914

Epoch: 5| Step: 9
Training loss: 2.717262299502364
Validation loss: 2.886728987781855

Epoch: 5| Step: 10
Training loss: 3.1187267661901514
Validation loss: 2.8824173335518193

Epoch: 37| Step: 0
Training loss: 3.306967956240071
Validation loss: 2.8838089009855477

Epoch: 5| Step: 1
Training loss: 3.6411146890607613
Validation loss: 2.8855437881604096

Epoch: 5| Step: 2
Training loss: 2.364060757290336
Validation loss: 2.88546985899858

Epoch: 5| Step: 3
Training loss: 2.8889438998861596
Validation loss: 2.8842215311692594

Epoch: 5| Step: 4
Training loss: 3.1098330366449107
Validation loss: 2.888664466301333

Epoch: 5| Step: 5
Training loss: 2.539112548334865
Validation loss: 2.8967600266517417

Epoch: 5| Step: 6
Training loss: 3.3801662322931056
Validation loss: 2.9225152909727727

Epoch: 5| Step: 7
Training loss: 3.088699225298234
Validation loss: 2.8759572395940114

Epoch: 5| Step: 8
Training loss: 2.9968655423998642
Validation loss: 2.8781100274179177

Epoch: 5| Step: 9
Training loss: 3.892789307649465
Validation loss: 2.88480367457762

Epoch: 5| Step: 10
Training loss: 3.538596149901422
Validation loss: 2.8872027181219306

Epoch: 38| Step: 0
Training loss: 3.272714612435408
Validation loss: 2.8815662433544844

Epoch: 5| Step: 1
Training loss: 3.645089093494385
Validation loss: 2.878473330094104

Epoch: 5| Step: 2
Training loss: 2.746478079630061
Validation loss: 2.876698401138743

Epoch: 5| Step: 3
Training loss: 3.006842598035819
Validation loss: 2.872742894444663

Epoch: 5| Step: 4
Training loss: 3.3233103424266712
Validation loss: 2.8701390132014106

Epoch: 5| Step: 5
Training loss: 3.403270293077548
Validation loss: 2.865057257474728

Epoch: 5| Step: 6
Training loss: 3.070905400072801
Validation loss: 2.8639598471451277

Epoch: 5| Step: 7
Training loss: 2.8770989758514918
Validation loss: 2.856650958515622

Epoch: 5| Step: 8
Training loss: 3.198343122214531
Validation loss: 2.856069755059334

Epoch: 5| Step: 9
Training loss: 3.2934763959424216
Validation loss: 2.8520898025482353

Epoch: 5| Step: 10
Training loss: 2.88283052929872
Validation loss: 2.8493599047458678

Epoch: 39| Step: 0
Training loss: 2.7814396997114827
Validation loss: 2.8443104307679734

Epoch: 5| Step: 1
Training loss: 3.000150676758078
Validation loss: 2.844843549044225

Epoch: 5| Step: 2
Training loss: 2.86014100534127
Validation loss: 2.846507013750791

Epoch: 5| Step: 3
Training loss: 3.1191346628876175
Validation loss: 2.8436806701985957

Epoch: 5| Step: 4
Training loss: 3.749090084309273
Validation loss: 2.8391561607149294

Epoch: 5| Step: 5
Training loss: 3.1985873203567956
Validation loss: 2.8395978889426017

Epoch: 5| Step: 6
Training loss: 2.7317721812654314
Validation loss: 2.835222481875301

Epoch: 5| Step: 7
Training loss: 3.2666449163322624
Validation loss: 2.8392734733889426

Epoch: 5| Step: 8
Training loss: 3.3143273837190144
Validation loss: 2.8378739109595434

Epoch: 5| Step: 9
Training loss: 3.0916252160871
Validation loss: 2.8361545543976407

Epoch: 5| Step: 10
Training loss: 3.4422228187553405
Validation loss: 2.836132527728644

Epoch: 40| Step: 0
Training loss: 2.673378504643395
Validation loss: 2.833952203392467

Epoch: 5| Step: 1
Training loss: 2.674638534794764
Validation loss: 2.8301080225888664

Epoch: 5| Step: 2
Training loss: 3.768101301398695
Validation loss: 2.8294990594990757

Epoch: 5| Step: 3
Training loss: 2.919702875096234
Validation loss: 2.8327074360912325

Epoch: 5| Step: 4
Training loss: 2.7897816647105866
Validation loss: 2.8295996571953843

Epoch: 5| Step: 5
Training loss: 3.223852465015501
Validation loss: 2.8313230087913093

Epoch: 5| Step: 6
Training loss: 3.076304715633706
Validation loss: 2.8307865010715942

Epoch: 5| Step: 7
Training loss: 2.7371841387788507
Validation loss: 2.8334344647387018

Epoch: 5| Step: 8
Training loss: 3.3229887823971076
Validation loss: 2.826095499176757

Epoch: 5| Step: 9
Training loss: 3.4737798291298674
Validation loss: 2.82890632826205

Epoch: 5| Step: 10
Training loss: 3.666231404103546
Validation loss: 2.830131479361052

Epoch: 41| Step: 0
Training loss: 3.6163450376415156
Validation loss: 2.8192161747370856

Epoch: 5| Step: 1
Training loss: 2.5058040003259068
Validation loss: 2.8192383490320574

Epoch: 5| Step: 2
Training loss: 3.067079506603815
Validation loss: 2.8195036413751096

Epoch: 5| Step: 3
Training loss: 3.2549765705255713
Validation loss: 2.8203277801089746

Epoch: 5| Step: 4
Training loss: 3.7007242782617324
Validation loss: 2.816018632379797

Epoch: 5| Step: 5
Training loss: 3.457409302465913
Validation loss: 2.8147037199241183

Epoch: 5| Step: 6
Training loss: 3.013047772382992
Validation loss: 2.8145118254035624

Epoch: 5| Step: 7
Training loss: 3.252635913914862
Validation loss: 2.815338583681399

Epoch: 5| Step: 8
Training loss: 3.002699273426452
Validation loss: 2.8101516244238844

Epoch: 5| Step: 9
Training loss: 2.8178817122184485
Validation loss: 2.8114411670505257

Epoch: 5| Step: 10
Training loss: 2.3007386597089945
Validation loss: 2.809671954940386

Epoch: 42| Step: 0
Training loss: 3.0088418363494935
Validation loss: 2.8127160065717134

Epoch: 5| Step: 1
Training loss: 2.9154659706240267
Validation loss: 2.8106949878561376

Epoch: 5| Step: 2
Training loss: 2.9456207356947175
Validation loss: 2.8121835473617667

Epoch: 5| Step: 3
Training loss: 2.7868121816737657
Validation loss: 2.8105502827907376

Epoch: 5| Step: 4
Training loss: 2.8993818281931647
Validation loss: 2.8077548780665516

Epoch: 5| Step: 5
Training loss: 3.688047853279376
Validation loss: 2.808811192391132

Epoch: 5| Step: 6
Training loss: 3.158428686576361
Validation loss: 2.809099226435708

Epoch: 5| Step: 7
Training loss: 3.4343416443195087
Validation loss: 2.81504588781927

Epoch: 5| Step: 8
Training loss: 2.8982792320123103
Validation loss: 2.8100997517951436

Epoch: 5| Step: 9
Training loss: 3.4789386301441954
Validation loss: 2.80658534064595

Epoch: 5| Step: 10
Training loss: 2.973288189441229
Validation loss: 2.811729197915858

Epoch: 43| Step: 0
Training loss: 2.918010747114527
Validation loss: 2.8050692348750985

Epoch: 5| Step: 1
Training loss: 2.5416417563629987
Validation loss: 2.8040580032793168

Epoch: 5| Step: 2
Training loss: 2.761354327944313
Validation loss: 2.8033841577318874

Epoch: 5| Step: 3
Training loss: 3.1174001214884264
Validation loss: 2.8019791432110406

Epoch: 5| Step: 4
Training loss: 3.328003643850019
Validation loss: 2.802344749203024

Epoch: 5| Step: 5
Training loss: 3.241871278347735
Validation loss: 2.80340732874746

Epoch: 5| Step: 6
Training loss: 3.4025843783755505
Validation loss: 2.802840909061882

Epoch: 5| Step: 7
Training loss: 2.5205762958054008
Validation loss: 2.805059188010078

Epoch: 5| Step: 8
Training loss: 3.6447799614108463
Validation loss: 2.8043702901041283

Epoch: 5| Step: 9
Training loss: 3.1191465871009862
Validation loss: 2.8017009640884196

Epoch: 5| Step: 10
Training loss: 3.489750705330047
Validation loss: 2.8002598694656853

Epoch: 44| Step: 0
Training loss: 3.21688210815095
Validation loss: 2.801031757445314

Epoch: 5| Step: 1
Training loss: 3.1242146840394587
Validation loss: 2.7989784122916492

Epoch: 5| Step: 2
Training loss: 3.5343727550280226
Validation loss: 2.7971940350447286

Epoch: 5| Step: 3
Training loss: 3.0199459131715334
Validation loss: 2.7968074487716263

Epoch: 5| Step: 4
Training loss: 2.501474136612277
Validation loss: 2.7951857020228315

Epoch: 5| Step: 5
Training loss: 2.819372554127692
Validation loss: 2.792838834206004

Epoch: 5| Step: 6
Training loss: 3.2364330286256964
Validation loss: 2.796195607597524

Epoch: 5| Step: 7
Training loss: 3.8438482504592444
Validation loss: 2.7956509620545265

Epoch: 5| Step: 8
Training loss: 2.6579228238683643
Validation loss: 2.791399066082203

Epoch: 5| Step: 9
Training loss: 3.022212605912985
Validation loss: 2.7929960185701237

Epoch: 5| Step: 10
Training loss: 2.959343715288869
Validation loss: 2.7906484116675054

Epoch: 45| Step: 0
Training loss: 3.0377238250024154
Validation loss: 2.790311030249512

Epoch: 5| Step: 1
Training loss: 2.6259771072540343
Validation loss: 2.7910997172887004

Epoch: 5| Step: 2
Training loss: 3.06532157617377
Validation loss: 2.7901272904566206

Epoch: 5| Step: 3
Training loss: 3.1833690727850663
Validation loss: 2.7890340660500033

Epoch: 5| Step: 4
Training loss: 3.141366747664933
Validation loss: 2.7870470343810183

Epoch: 5| Step: 5
Training loss: 3.1000799291827588
Validation loss: 2.7909098814498154

Epoch: 5| Step: 6
Training loss: 3.576302143184793
Validation loss: 2.788001947409542

Epoch: 5| Step: 7
Training loss: 2.5880876804398043
Validation loss: 2.788535992897629

Epoch: 5| Step: 8
Training loss: 3.4527109855915272
Validation loss: 2.7925418999435103

Epoch: 5| Step: 9
Training loss: 3.4671308157826983
Validation loss: 2.7866607511224246

Epoch: 5| Step: 10
Training loss: 2.572963008900851
Validation loss: 2.788217122932379

Epoch: 46| Step: 0
Training loss: 2.462927313583543
Validation loss: 2.7935272996117404

Epoch: 5| Step: 1
Training loss: 3.819697980075988
Validation loss: 2.79385935504739

Epoch: 5| Step: 2
Training loss: 3.3451446761931067
Validation loss: 2.8018545787857874

Epoch: 5| Step: 3
Training loss: 2.8911548025882836
Validation loss: 2.801263644406363

Epoch: 5| Step: 4
Training loss: 2.8894022236902415
Validation loss: 2.7935038603490634

Epoch: 5| Step: 5
Training loss: 2.7033566061477057
Validation loss: 2.782349117091631

Epoch: 5| Step: 6
Training loss: 3.1724656029678493
Validation loss: 2.784117232477977

Epoch: 5| Step: 7
Training loss: 2.9198542660442017
Validation loss: 2.7818186391685873

Epoch: 5| Step: 8
Training loss: 3.7132100103869417
Validation loss: 2.781371426117971

Epoch: 5| Step: 9
Training loss: 2.8405329354687847
Validation loss: 2.78048855464246

Epoch: 5| Step: 10
Training loss: 2.982324504949088
Validation loss: 2.7821003175268055

Epoch: 47| Step: 0
Training loss: 3.0389578440868847
Validation loss: 2.7798496918418047

Epoch: 5| Step: 1
Training loss: 3.4547140340420124
Validation loss: 2.781413673672051

Epoch: 5| Step: 2
Training loss: 3.2634877781335945
Validation loss: 2.7814305537113544

Epoch: 5| Step: 3
Training loss: 2.5676206273284548
Validation loss: 2.778233867002342

Epoch: 5| Step: 4
Training loss: 3.8077248858678745
Validation loss: 2.78158168052442

Epoch: 5| Step: 5
Training loss: 2.712779274200805
Validation loss: 2.788438018802347

Epoch: 5| Step: 6
Training loss: 2.6622419205355907
Validation loss: 2.7773514888811315

Epoch: 5| Step: 7
Training loss: 3.15686331351622
Validation loss: 2.7755039501363474

Epoch: 5| Step: 8
Training loss: 2.8881437632634968
Validation loss: 2.7741366715883453

Epoch: 5| Step: 9
Training loss: 2.82737173934621
Validation loss: 2.7733356249717365

Epoch: 5| Step: 10
Training loss: 3.4461851506985965
Validation loss: 2.7729091604954688

Epoch: 48| Step: 0
Training loss: 2.9613556981737195
Validation loss: 2.770754269373911

Epoch: 5| Step: 1
Training loss: 3.2908898575746197
Validation loss: 2.7702814299333194

Epoch: 5| Step: 2
Training loss: 3.335617443159784
Validation loss: 2.766339561477168

Epoch: 5| Step: 3
Training loss: 3.1861003719977714
Validation loss: 2.767303122672195

Epoch: 5| Step: 4
Training loss: 2.677970313787268
Validation loss: 2.765980891299267

Epoch: 5| Step: 5
Training loss: 2.424536049104191
Validation loss: 2.7641110372089384

Epoch: 5| Step: 6
Training loss: 2.8418967108214943
Validation loss: 2.7658743500573464

Epoch: 5| Step: 7
Training loss: 3.2235405096032563
Validation loss: 2.7668065019520887

Epoch: 5| Step: 8
Training loss: 3.294178225857827
Validation loss: 2.764823763675839

Epoch: 5| Step: 9
Training loss: 3.4179637276748815
Validation loss: 2.7631690919665517

Epoch: 5| Step: 10
Training loss: 3.0754359548787606
Validation loss: 2.760818380394685

Epoch: 49| Step: 0
Training loss: 3.053617558334036
Validation loss: 2.772484390072964

Epoch: 5| Step: 1
Training loss: 3.4380255557492387
Validation loss: 2.779969559770859

Epoch: 5| Step: 2
Training loss: 2.811859736149947
Validation loss: 2.7849245039284773

Epoch: 5| Step: 3
Training loss: 2.741234942671878
Validation loss: 2.7878376453177864

Epoch: 5| Step: 4
Training loss: 3.0975278656993837
Validation loss: 2.7804670385138492

Epoch: 5| Step: 5
Training loss: 3.3652329580488893
Validation loss: 2.7929020515783014

Epoch: 5| Step: 6
Training loss: 3.4066875771654033
Validation loss: 2.756665255379098

Epoch: 5| Step: 7
Training loss: 3.006757120039171
Validation loss: 2.7552426854772305

Epoch: 5| Step: 8
Training loss: 2.815521905601452
Validation loss: 2.759432889513004

Epoch: 5| Step: 9
Training loss: 3.476959685878823
Validation loss: 2.7634024379974007

Epoch: 5| Step: 10
Training loss: 2.467931684244056
Validation loss: 2.7692513379608

Epoch: 50| Step: 0
Training loss: 3.710774821681003
Validation loss: 2.780730276941895

Epoch: 5| Step: 1
Training loss: 2.8962612979357387
Validation loss: 2.7606611580440545

Epoch: 5| Step: 2
Training loss: 3.178735088953949
Validation loss: 2.759056303740213

Epoch: 5| Step: 3
Training loss: 2.326235112916927
Validation loss: 2.756214764204965

Epoch: 5| Step: 4
Training loss: 2.776212695342173
Validation loss: 2.756969048810001

Epoch: 5| Step: 5
Training loss: 3.0684524609427988
Validation loss: 2.7533788144096203

Epoch: 5| Step: 6
Training loss: 2.8505968104772936
Validation loss: 2.7540781996529433

Epoch: 5| Step: 7
Training loss: 2.7916195044637866
Validation loss: 2.752956824656421

Epoch: 5| Step: 8
Training loss: 3.1104326605891295
Validation loss: 2.753457931626784

Epoch: 5| Step: 9
Training loss: 3.491624756943154
Validation loss: 2.757838347186432

Epoch: 5| Step: 10
Training loss: 3.476552624634851
Validation loss: 2.756869619046055

Epoch: 51| Step: 0
Training loss: 3.1405437705699506
Validation loss: 2.755596723819882

Epoch: 5| Step: 1
Training loss: 3.3007757604429204
Validation loss: 2.7564823271018275

Epoch: 5| Step: 2
Training loss: 3.342513381600253
Validation loss: 2.75347439461962

Epoch: 5| Step: 3
Training loss: 2.9228119189489092
Validation loss: 2.749429616571805

Epoch: 5| Step: 4
Training loss: 3.2777560569201545
Validation loss: 2.7506052602195936

Epoch: 5| Step: 5
Training loss: 3.208934595484636
Validation loss: 2.7513643312888867

Epoch: 5| Step: 6
Training loss: 2.733486183668868
Validation loss: 2.7469894397100374

Epoch: 5| Step: 7
Training loss: 2.7259171823472315
Validation loss: 2.7485539576865565

Epoch: 5| Step: 8
Training loss: 3.275523975184996
Validation loss: 2.746243243274338

Epoch: 5| Step: 9
Training loss: 2.9198549192783174
Validation loss: 2.7430440553986837

Epoch: 5| Step: 10
Training loss: 2.7654116273456375
Validation loss: 2.745122480789911

Epoch: 52| Step: 0
Training loss: 3.185635339197389
Validation loss: 2.742804143213402

Epoch: 5| Step: 1
Training loss: 3.086654386667606
Validation loss: 2.7455575855107117

Epoch: 5| Step: 2
Training loss: 2.853369738474304
Validation loss: 2.74546963780595

Epoch: 5| Step: 3
Training loss: 2.922375967560705
Validation loss: 2.7411114299489827

Epoch: 5| Step: 4
Training loss: 2.9650500882888995
Validation loss: 2.7434917487534576

Epoch: 5| Step: 5
Training loss: 3.03334036256863
Validation loss: 2.745738716953318

Epoch: 5| Step: 6
Training loss: 3.4291507935340086
Validation loss: 2.7459285741662893

Epoch: 5| Step: 7
Training loss: 2.772809368515697
Validation loss: 2.7519380185978344

Epoch: 5| Step: 8
Training loss: 3.1656197942331334
Validation loss: 2.7551025152264144

Epoch: 5| Step: 9
Training loss: 2.9364924224646627
Validation loss: 2.760497788119372

Epoch: 5| Step: 10
Training loss: 3.361112207529889
Validation loss: 2.761604016264025

Epoch: 53| Step: 0
Training loss: 2.995091236998355
Validation loss: 2.7571669082635197

Epoch: 5| Step: 1
Training loss: 3.2412528655675423
Validation loss: 2.7470261583683677

Epoch: 5| Step: 2
Training loss: 3.169367207566666
Validation loss: 2.743439998731796

Epoch: 5| Step: 3
Training loss: 3.545901261488479
Validation loss: 2.734076550862867

Epoch: 5| Step: 4
Training loss: 3.3907915065682857
Validation loss: 2.7320287536119676

Epoch: 5| Step: 5
Training loss: 2.9165816885058335
Validation loss: 2.7323345769176837

Epoch: 5| Step: 6
Training loss: 2.854482331652075
Validation loss: 2.7301778506782575

Epoch: 5| Step: 7
Training loss: 2.471821769208721
Validation loss: 2.731181960819954

Epoch: 5| Step: 8
Training loss: 2.727680578224384
Validation loss: 2.7301415998217093

Epoch: 5| Step: 9
Training loss: 3.4776558860432063
Validation loss: 2.732506593056171

Epoch: 5| Step: 10
Training loss: 2.593302952491216
Validation loss: 2.729442662011678

Epoch: 54| Step: 0
Training loss: 3.0551616954311096
Validation loss: 2.727513092669192

Epoch: 5| Step: 1
Training loss: 3.0736646528522527
Validation loss: 2.729583325800652

Epoch: 5| Step: 2
Training loss: 2.9175105009568276
Validation loss: 2.732878477225476

Epoch: 5| Step: 3
Training loss: 3.019815014611515
Validation loss: 2.7253438582296083

Epoch: 5| Step: 4
Training loss: 2.941888493575236
Validation loss: 2.7251872359901643

Epoch: 5| Step: 5
Training loss: 3.0390315900078955
Validation loss: 2.7264433474893672

Epoch: 5| Step: 6
Training loss: 2.7015418559885767
Validation loss: 2.7323736711234528

Epoch: 5| Step: 7
Training loss: 3.2920579476523013
Validation loss: 2.734092470447847

Epoch: 5| Step: 8
Training loss: 2.9605103841431024
Validation loss: 2.735862683975087

Epoch: 5| Step: 9
Training loss: 3.733879918436089
Validation loss: 2.73688853442517

Epoch: 5| Step: 10
Training loss: 2.70187763694901
Validation loss: 2.7296606692460688

Epoch: 55| Step: 0
Training loss: 3.110045854285637
Validation loss: 2.7340247304621714

Epoch: 5| Step: 1
Training loss: 2.96439934215649
Validation loss: 2.7289419738460996

Epoch: 5| Step: 2
Training loss: 3.555804066781567
Validation loss: 2.7263745034699047

Epoch: 5| Step: 3
Training loss: 3.051385446032472
Validation loss: 2.7216828043553907

Epoch: 5| Step: 4
Training loss: 3.4772273767316664
Validation loss: 2.7241293710864976

Epoch: 5| Step: 5
Training loss: 2.3712258718466575
Validation loss: 2.727305592077573

Epoch: 5| Step: 6
Training loss: 3.392594429113097
Validation loss: 2.729961567568798

Epoch: 5| Step: 7
Training loss: 2.96865619712004
Validation loss: 2.723963207834296

Epoch: 5| Step: 8
Training loss: 3.043064336291556
Validation loss: 2.7232638238593854

Epoch: 5| Step: 9
Training loss: 2.3925472335378193
Validation loss: 2.7213799044960125

Epoch: 5| Step: 10
Training loss: 2.9791003844528254
Validation loss: 2.7225052299145314

Epoch: 56| Step: 0
Training loss: 2.845896822294254
Validation loss: 2.7221253116722917

Epoch: 5| Step: 1
Training loss: 2.6902054764220322
Validation loss: 2.719007527723176

Epoch: 5| Step: 2
Training loss: 2.9481187802819897
Validation loss: 2.718222938889811

Epoch: 5| Step: 3
Training loss: 2.724765043016064
Validation loss: 2.715299227545305

Epoch: 5| Step: 4
Training loss: 3.3314962729052895
Validation loss: 2.7203598093833885

Epoch: 5| Step: 5
Training loss: 3.3054341223572514
Validation loss: 2.7310443982413295

Epoch: 5| Step: 6
Training loss: 3.4967786405785044
Validation loss: 2.7377542351918303

Epoch: 5| Step: 7
Training loss: 3.3616828975055557
Validation loss: 2.7354492121334255

Epoch: 5| Step: 8
Training loss: 2.7236884854474965
Validation loss: 2.7127416761734024

Epoch: 5| Step: 9
Training loss: 3.102294066892761
Validation loss: 2.712981702059391

Epoch: 5| Step: 10
Training loss: 2.9570020626346025
Validation loss: 2.719013088699691

Epoch: 57| Step: 0
Training loss: 2.6263070258549694
Validation loss: 2.7232954834056597

Epoch: 5| Step: 1
Training loss: 3.719334660578799
Validation loss: 2.7266476878157997

Epoch: 5| Step: 2
Training loss: 3.16734840349442
Validation loss: 2.7253811535338834

Epoch: 5| Step: 3
Training loss: 2.998849012196049
Validation loss: 2.718355009876633

Epoch: 5| Step: 4
Training loss: 3.1795031894812413
Validation loss: 2.7153149871952436

Epoch: 5| Step: 5
Training loss: 2.688469556639301
Validation loss: 2.7145170810686023

Epoch: 5| Step: 6
Training loss: 2.788200009980327
Validation loss: 2.71373364071774

Epoch: 5| Step: 7
Training loss: 3.3889428813642484
Validation loss: 2.7147317823868056

Epoch: 5| Step: 8
Training loss: 3.2053825052565696
Validation loss: 2.7160003150887686

Epoch: 5| Step: 9
Training loss: 2.359984464432612
Validation loss: 2.7234020241927843

Epoch: 5| Step: 10
Training loss: 3.2598985904296556
Validation loss: 2.724298960839013

Epoch: 58| Step: 0
Training loss: 2.967704829897586
Validation loss: 2.724287907505871

Epoch: 5| Step: 1
Training loss: 3.5927295065182454
Validation loss: 2.725867477166382

Epoch: 5| Step: 2
Training loss: 2.7480429708294496
Validation loss: 2.71849923114186

Epoch: 5| Step: 3
Training loss: 3.2745907010867104
Validation loss: 2.727868667064189

Epoch: 5| Step: 4
Training loss: 2.6510358009698174
Validation loss: 2.733047302711072

Epoch: 5| Step: 5
Training loss: 2.9426271860642745
Validation loss: 2.7596762768057475

Epoch: 5| Step: 6
Training loss: 3.0732614269933203
Validation loss: 2.7581972945258

Epoch: 5| Step: 7
Training loss: 3.154402692691003
Validation loss: 2.7291441628972497

Epoch: 5| Step: 8
Training loss: 2.9977106259931734
Validation loss: 2.7157656695642842

Epoch: 5| Step: 9
Training loss: 3.2757720270261292
Validation loss: 2.708168540339458

Epoch: 5| Step: 10
Training loss: 2.578336487389846
Validation loss: 2.705986506167799

Epoch: 59| Step: 0
Training loss: 2.821349991364629
Validation loss: 2.702384825105038

Epoch: 5| Step: 1
Training loss: 3.2667041802360792
Validation loss: 2.704885492410601

Epoch: 5| Step: 2
Training loss: 3.4022075218493826
Validation loss: 2.702773350666964

Epoch: 5| Step: 3
Training loss: 2.731113865163539
Validation loss: 2.703206241943844

Epoch: 5| Step: 4
Training loss: 2.655201155088012
Validation loss: 2.704359728671425

Epoch: 5| Step: 5
Training loss: 3.442176827835391
Validation loss: 2.70498897396254

Epoch: 5| Step: 6
Training loss: 3.51506180384688
Validation loss: 2.701957073337853

Epoch: 5| Step: 7
Training loss: 2.9160813607166958
Validation loss: 2.702775274269384

Epoch: 5| Step: 8
Training loss: 2.6515111501258946
Validation loss: 2.7014239524464223

Epoch: 5| Step: 9
Training loss: 2.927271953401727
Validation loss: 2.7040435000620944

Epoch: 5| Step: 10
Training loss: 2.9181452318618897
Validation loss: 2.703776685790405

Epoch: 60| Step: 0
Training loss: 3.127238883043029
Validation loss: 2.703947548257368

Epoch: 5| Step: 1
Training loss: 2.7372785574475267
Validation loss: 2.701377583152912

Epoch: 5| Step: 2
Training loss: 2.8492388729538574
Validation loss: 2.6977912470465606

Epoch: 5| Step: 3
Training loss: 2.99423362950792
Validation loss: 2.7004775170808846

Epoch: 5| Step: 4
Training loss: 2.8060763434902487
Validation loss: 2.697923583696774

Epoch: 5| Step: 5
Training loss: 2.7600203799448986
Validation loss: 2.698123272274644

Epoch: 5| Step: 6
Training loss: 3.23100067888617
Validation loss: 2.6995101022811596

Epoch: 5| Step: 7
Training loss: 3.2025672985334346
Validation loss: 2.7127550881021087

Epoch: 5| Step: 8
Training loss: 3.195874451559672
Validation loss: 2.7423781415254753

Epoch: 5| Step: 9
Training loss: 3.0538719239724745
Validation loss: 2.7515166576030996

Epoch: 5| Step: 10
Training loss: 3.5146435533273928
Validation loss: 2.8030197116647373

Epoch: 61| Step: 0
Training loss: 3.1407537481383847
Validation loss: 2.802404874178607

Epoch: 5| Step: 1
Training loss: 2.963293582519486
Validation loss: 2.7846009513583394

Epoch: 5| Step: 2
Training loss: 2.965496167358124
Validation loss: 2.7711590876040098

Epoch: 5| Step: 3
Training loss: 2.7977209250424115
Validation loss: 2.7614295170870546

Epoch: 5| Step: 4
Training loss: 3.174322377381036
Validation loss: 2.760152224974745

Epoch: 5| Step: 5
Training loss: 3.472975073683478
Validation loss: 2.758816865909236

Epoch: 5| Step: 6
Training loss: 3.171123697534664
Validation loss: 2.7595609286185616

Epoch: 5| Step: 7
Training loss: 3.087150547776812
Validation loss: 2.7611478394801154

Epoch: 5| Step: 8
Training loss: 3.1973349739062016
Validation loss: 2.7570379090218484

Epoch: 5| Step: 9
Training loss: 3.066548221484531
Validation loss: 2.75782330183872

Epoch: 5| Step: 10
Training loss: 2.7783414226460748
Validation loss: 2.7530280322291154

Epoch: 62| Step: 0
Training loss: 2.9136101829338297
Validation loss: 2.754216315155966

Epoch: 5| Step: 1
Training loss: 2.660220062790051
Validation loss: 2.750705876375115

Epoch: 5| Step: 2
Training loss: 3.325509059629258
Validation loss: 2.751336474931386

Epoch: 5| Step: 3
Training loss: 3.240078674585678
Validation loss: 2.7507609119184107

Epoch: 5| Step: 4
Training loss: 3.2766856099923527
Validation loss: 2.7545598616125018

Epoch: 5| Step: 5
Training loss: 2.8303559497969983
Validation loss: 2.75827412839315

Epoch: 5| Step: 6
Training loss: 2.9979320392298456
Validation loss: 2.7556939677069154

Epoch: 5| Step: 7
Training loss: 3.125087126470983
Validation loss: 2.7559813467974785

Epoch: 5| Step: 8
Training loss: 3.29598538658458
Validation loss: 2.755086209448547

Epoch: 5| Step: 9
Training loss: 3.0038351340736584
Validation loss: 2.747986947003748

Epoch: 5| Step: 10
Training loss: 3.051026474869401
Validation loss: 2.748794595390139

Epoch: 63| Step: 0
Training loss: 3.1553190765811023
Validation loss: 2.75422145319942

Epoch: 5| Step: 1
Training loss: 2.270512432790998
Validation loss: 2.7520230217724544

Epoch: 5| Step: 2
Training loss: 3.231343345843271
Validation loss: 2.746766203595911

Epoch: 5| Step: 3
Training loss: 3.562796864772645
Validation loss: 2.741967931618179

Epoch: 5| Step: 4
Training loss: 2.8406309692185805
Validation loss: 2.742718633733473

Epoch: 5| Step: 5
Training loss: 3.2110779817390873
Validation loss: 2.737570388809755

Epoch: 5| Step: 6
Training loss: 3.027652296524471
Validation loss: 2.734979587171381

Epoch: 5| Step: 7
Training loss: 2.803702348771023
Validation loss: 2.735126320184029

Epoch: 5| Step: 8
Training loss: 3.038140713655587
Validation loss: 2.738089291436116

Epoch: 5| Step: 9
Training loss: 2.8077091527057685
Validation loss: 2.740366175659549

Epoch: 5| Step: 10
Training loss: 3.598280331702912
Validation loss: 2.738564526926717

Epoch: 64| Step: 0
Training loss: 2.6838618648474664
Validation loss: 2.755398241751932

Epoch: 5| Step: 1
Training loss: 3.3416433382686597
Validation loss: 2.781409262392302

Epoch: 5| Step: 2
Training loss: 2.8490830602779544
Validation loss: 2.7743260583759914

Epoch: 5| Step: 3
Training loss: 3.129209353735284
Validation loss: 2.75421130555437

Epoch: 5| Step: 4
Training loss: 2.353226488009522
Validation loss: 2.741624171579772

Epoch: 5| Step: 5
Training loss: 3.3448641338040024
Validation loss: 2.7492618838054175

Epoch: 5| Step: 6
Training loss: 2.389225668664826
Validation loss: 2.7544946548552742

Epoch: 5| Step: 7
Training loss: 3.4576477535560066
Validation loss: 2.7440605889063208

Epoch: 5| Step: 8
Training loss: 3.250963948421007
Validation loss: 2.7296137671710086

Epoch: 5| Step: 9
Training loss: 2.9813907742002437
Validation loss: 2.726202269679543

Epoch: 5| Step: 10
Training loss: 3.6026217874328874
Validation loss: 2.726050332578762

Epoch: 65| Step: 0
Training loss: 3.267527632884692
Validation loss: 2.723236914226544

Epoch: 5| Step: 1
Training loss: 3.2472734017785503
Validation loss: 2.7303948940866603

Epoch: 5| Step: 2
Training loss: 3.0498046875
Validation loss: 2.723529237345809

Epoch: 5| Step: 3
Training loss: 2.767273320095576
Validation loss: 2.7285897694859447

Epoch: 5| Step: 4
Training loss: 2.9034523573025077
Validation loss: 2.7237135486326314

Epoch: 5| Step: 5
Training loss: 2.8788191265862175
Validation loss: 2.724713444457995

Epoch: 5| Step: 6
Training loss: 3.149379239148563
Validation loss: 2.726539279575481

Epoch: 5| Step: 7
Training loss: 2.9156620657017283
Validation loss: 2.7244426218596725

Epoch: 5| Step: 8
Training loss: 3.073477087265305
Validation loss: 2.725074008938762

Epoch: 5| Step: 9
Training loss: 3.2619216581721786
Validation loss: 2.7238578381783527

Epoch: 5| Step: 10
Training loss: 2.9870130453319748
Validation loss: 2.7241187377324496

Epoch: 66| Step: 0
Training loss: 2.8057386718347286
Validation loss: 2.7156009128438368

Epoch: 5| Step: 1
Training loss: 2.4576241607191167
Validation loss: 2.6967508509547566

Epoch: 5| Step: 2
Training loss: 2.3819084078253394
Validation loss: 2.694759812177809

Epoch: 5| Step: 3
Training loss: 3.427859433927694
Validation loss: 2.693175631719462

Epoch: 5| Step: 4
Training loss: 2.8515327347547546
Validation loss: 2.6953041650786784

Epoch: 5| Step: 5
Training loss: 3.2043552920243434
Validation loss: 2.689824245152077

Epoch: 5| Step: 6
Training loss: 3.4906507690899193
Validation loss: 2.6835968786099795

Epoch: 5| Step: 7
Training loss: 2.9257727751462705
Validation loss: 2.674799994972123

Epoch: 5| Step: 8
Training loss: 3.5713564892715364
Validation loss: 2.666780218147362

Epoch: 5| Step: 9
Training loss: 3.0071216929415523
Validation loss: 2.665731672475601

Epoch: 5| Step: 10
Training loss: 2.9660489292854773
Validation loss: 2.664608398182093

Epoch: 67| Step: 0
Training loss: 3.06267266857183
Validation loss: 2.6680492882086817

Epoch: 5| Step: 1
Training loss: 2.4668975833683517
Validation loss: 2.674783883513714

Epoch: 5| Step: 2
Training loss: 2.4040582756938584
Validation loss: 2.6827634551599493

Epoch: 5| Step: 3
Training loss: 3.2294679726753204
Validation loss: 2.6975615418093093

Epoch: 5| Step: 4
Training loss: 3.5384034475769868
Validation loss: 2.6940576010791126

Epoch: 5| Step: 5
Training loss: 2.8250970806894093
Validation loss: 2.672548113450974

Epoch: 5| Step: 6
Training loss: 3.2927790504560233
Validation loss: 2.662836845828079

Epoch: 5| Step: 7
Training loss: 3.413495677971524
Validation loss: 2.659602725271389

Epoch: 5| Step: 8
Training loss: 2.714001773381058
Validation loss: 2.6625509270790872

Epoch: 5| Step: 9
Training loss: 2.9729568389623497
Validation loss: 2.662222027570303

Epoch: 5| Step: 10
Training loss: 2.9597005953019244
Validation loss: 2.658498573073116

Epoch: 68| Step: 0
Training loss: 2.6478418451198285
Validation loss: 2.660835569078559

Epoch: 5| Step: 1
Training loss: 2.8778662284634886
Validation loss: 2.6686793436974416

Epoch: 5| Step: 2
Training loss: 2.577032794215265
Validation loss: 2.6733399094391346

Epoch: 5| Step: 3
Training loss: 3.158167492648402
Validation loss: 2.667860883394179

Epoch: 5| Step: 4
Training loss: 3.3670671268905976
Validation loss: 2.6618587212873956

Epoch: 5| Step: 5
Training loss: 3.013734214864788
Validation loss: 2.6680021735988695

Epoch: 5| Step: 6
Training loss: 2.9586694732395986
Validation loss: 2.6648058990952457

Epoch: 5| Step: 7
Training loss: 2.1529266620411587
Validation loss: 2.670316849073439

Epoch: 5| Step: 8
Training loss: 3.3021597066204027
Validation loss: 2.6740899511170446

Epoch: 5| Step: 9
Training loss: 2.762420867200794
Validation loss: 2.6825996034993786

Epoch: 5| Step: 10
Training loss: 3.923929231213563
Validation loss: 2.6736282806917693

Epoch: 69| Step: 0
Training loss: 2.9590572134186854
Validation loss: 2.671031199552964

Epoch: 5| Step: 1
Training loss: 2.788792188351798
Validation loss: 2.6572801246494824

Epoch: 5| Step: 2
Training loss: 3.0082660283584444
Validation loss: 2.6545515330562295

Epoch: 5| Step: 3
Training loss: 2.8812311068430523
Validation loss: 2.6499103324333144

Epoch: 5| Step: 4
Training loss: 3.1313835557182164
Validation loss: 2.6522660164375833

Epoch: 5| Step: 5
Training loss: 2.969285615488213
Validation loss: 2.651603800787663

Epoch: 5| Step: 6
Training loss: 3.063683417416578
Validation loss: 2.649732597281194

Epoch: 5| Step: 7
Training loss: 2.9114572778653236
Validation loss: 2.6562489895031507

Epoch: 5| Step: 8
Training loss: 3.0398225986016416
Validation loss: 2.645942477093114

Epoch: 5| Step: 9
Training loss: 3.096570203392155
Validation loss: 2.6510699873204353

Epoch: 5| Step: 10
Training loss: 3.0911058628462187
Validation loss: 2.653656546521887

Epoch: 70| Step: 0
Training loss: 2.5309547911502075
Validation loss: 2.6608728725269586

Epoch: 5| Step: 1
Training loss: 3.0167193230798195
Validation loss: 2.6629680834278155

Epoch: 5| Step: 2
Training loss: 2.652207114024769
Validation loss: 2.660703281080983

Epoch: 5| Step: 3
Training loss: 3.069062344879591
Validation loss: 2.6569814921027066

Epoch: 5| Step: 4
Training loss: 2.954620789854566
Validation loss: 2.6528665529752615

Epoch: 5| Step: 5
Training loss: 3.4413705016410874
Validation loss: 2.6499631311472025

Epoch: 5| Step: 6
Training loss: 3.1738479566688103
Validation loss: 2.6496789860871894

Epoch: 5| Step: 7
Training loss: 2.4831495801629386
Validation loss: 2.652941066978822

Epoch: 5| Step: 8
Training loss: 2.897235631459619
Validation loss: 2.649149684343394

Epoch: 5| Step: 9
Training loss: 3.7720611147091168
Validation loss: 2.6482687656293313

Epoch: 5| Step: 10
Training loss: 2.814891053119139
Validation loss: 2.6481137540184454

Epoch: 71| Step: 0
Training loss: 2.6615411455642106
Validation loss: 2.647326982758813

Epoch: 5| Step: 1
Training loss: 3.3165033009485514
Validation loss: 2.6400622589629426

Epoch: 5| Step: 2
Training loss: 2.9375725595156683
Validation loss: 2.641862793105126

Epoch: 5| Step: 3
Training loss: 2.8979748462035544
Validation loss: 2.641336647928195

Epoch: 5| Step: 4
Training loss: 3.0233830883245822
Validation loss: 2.6432225455449676

Epoch: 5| Step: 5
Training loss: 3.293895079803382
Validation loss: 2.6494208784453304

Epoch: 5| Step: 6
Training loss: 2.767643595952837
Validation loss: 2.6552172704756964

Epoch: 5| Step: 7
Training loss: 3.1631219666923807
Validation loss: 2.6607485882928352

Epoch: 5| Step: 8
Training loss: 3.241218146223906
Validation loss: 2.645182631200435

Epoch: 5| Step: 9
Training loss: 2.7971304664938557
Validation loss: 2.6417255373960122

Epoch: 5| Step: 10
Training loss: 2.63723094345239
Validation loss: 2.6399259836803437

Epoch: 72| Step: 0
Training loss: 2.88314643724544
Validation loss: 2.6416732693739085

Epoch: 5| Step: 1
Training loss: 2.965976101800248
Validation loss: 2.6395637023596192

Epoch: 5| Step: 2
Training loss: 3.161702950496801
Validation loss: 2.643348341435005

Epoch: 5| Step: 3
Training loss: 2.8122680568422274
Validation loss: 2.6406103168818866

Epoch: 5| Step: 4
Training loss: 2.785027499653841
Validation loss: 2.6392479369114645

Epoch: 5| Step: 5
Training loss: 2.495703724938543
Validation loss: 2.640116986948296

Epoch: 5| Step: 6
Training loss: 3.369110337273281
Validation loss: 2.6407513642540823

Epoch: 5| Step: 7
Training loss: 3.2871602916343994
Validation loss: 2.6387684564863143

Epoch: 5| Step: 8
Training loss: 2.570552177037659
Validation loss: 2.647029818048795

Epoch: 5| Step: 9
Training loss: 3.2334587531655403
Validation loss: 2.662885407353126

Epoch: 5| Step: 10
Training loss: 3.224434582728559
Validation loss: 2.6632191159608958

Epoch: 73| Step: 0
Training loss: 3.3159265609358015
Validation loss: 2.667713518035116

Epoch: 5| Step: 1
Training loss: 2.7830256248223746
Validation loss: 2.6500122004247664

Epoch: 5| Step: 2
Training loss: 2.852445617210871
Validation loss: 2.643303250973361

Epoch: 5| Step: 3
Training loss: 2.8537430460473785
Validation loss: 2.6407653243168867

Epoch: 5| Step: 4
Training loss: 3.556270037495725
Validation loss: 2.638975864963929

Epoch: 5| Step: 5
Training loss: 2.2460171097658272
Validation loss: 2.642603295836962

Epoch: 5| Step: 6
Training loss: 2.5246414760961025
Validation loss: 2.6400202081446946

Epoch: 5| Step: 7
Training loss: 3.2054128524365515
Validation loss: 2.649942632299166

Epoch: 5| Step: 8
Training loss: 3.012059292669411
Validation loss: 2.6352528925662524

Epoch: 5| Step: 9
Training loss: 3.1259797658430166
Validation loss: 2.6289697857094123

Epoch: 5| Step: 10
Training loss: 3.1529992614416145
Validation loss: 2.6303044715318893

Epoch: 74| Step: 0
Training loss: 3.091557660370419
Validation loss: 2.63016384935526

Epoch: 5| Step: 1
Training loss: 3.154701079461703
Validation loss: 2.629671002724872

Epoch: 5| Step: 2
Training loss: 2.9756957066129077
Validation loss: 2.6300592241123035

Epoch: 5| Step: 3
Training loss: 3.010360312456871
Validation loss: 2.6313151130261296

Epoch: 5| Step: 4
Training loss: 2.898071101388579
Validation loss: 2.626601035145737

Epoch: 5| Step: 5
Training loss: 2.8450785457448307
Validation loss: 2.631505435857036

Epoch: 5| Step: 6
Training loss: 3.169177933488255
Validation loss: 2.626511001694525

Epoch: 5| Step: 7
Training loss: 2.797229595189341
Validation loss: 2.627592895201347

Epoch: 5| Step: 8
Training loss: 2.9528467763800124
Validation loss: 2.633346524393115

Epoch: 5| Step: 9
Training loss: 2.945998053866674
Validation loss: 2.6343723448965735

Epoch: 5| Step: 10
Training loss: 2.8772782959693095
Validation loss: 2.638042096655017

Epoch: 75| Step: 0
Training loss: 2.901911789387512
Validation loss: 2.652660370245697

Epoch: 5| Step: 1
Training loss: 2.9834745157034694
Validation loss: 2.6605630674117604

Epoch: 5| Step: 2
Training loss: 3.2499989729659586
Validation loss: 2.6894027296903733

Epoch: 5| Step: 3
Training loss: 2.859364660692543
Validation loss: 2.7049078552244494

Epoch: 5| Step: 4
Training loss: 2.4998979547654985
Validation loss: 2.7293343948441224

Epoch: 5| Step: 5
Training loss: 2.92476066849179
Validation loss: 2.661687437290279

Epoch: 5| Step: 6
Training loss: 3.002337339951767
Validation loss: 2.630211309388454

Epoch: 5| Step: 7
Training loss: 2.748940523838425
Validation loss: 2.6298161930220236

Epoch: 5| Step: 8
Training loss: 2.5325590916449197
Validation loss: 2.630493291580925

Epoch: 5| Step: 9
Training loss: 3.3947708870570854
Validation loss: 2.637931478603272

Epoch: 5| Step: 10
Training loss: 3.52793188250776
Validation loss: 2.6435782983903326

Epoch: 76| Step: 0
Training loss: 2.744890234164843
Validation loss: 2.6301697151389236

Epoch: 5| Step: 1
Training loss: 2.8805087842815618
Validation loss: 2.630275888630335

Epoch: 5| Step: 2
Training loss: 2.9994339408893933
Validation loss: 2.6304618878120047

Epoch: 5| Step: 3
Training loss: 3.0092782548701567
Validation loss: 2.6275485461438053

Epoch: 5| Step: 4
Training loss: 2.808465394972112
Validation loss: 2.6297805517857

Epoch: 5| Step: 5
Training loss: 3.302140934358528
Validation loss: 2.6269564537890004

Epoch: 5| Step: 6
Training loss: 3.3268355616299967
Validation loss: 2.6251979270808814

Epoch: 5| Step: 7
Training loss: 2.6120947637615686
Validation loss: 2.626639923785447

Epoch: 5| Step: 8
Training loss: 3.064729462922984
Validation loss: 2.6341159919438693

Epoch: 5| Step: 9
Training loss: 2.6750687813160483
Validation loss: 2.6532625562427556

Epoch: 5| Step: 10
Training loss: 3.2155827614963846
Validation loss: 2.6703010648266092

Epoch: 77| Step: 0
Training loss: 2.931567105382269
Validation loss: 2.658379385396882

Epoch: 5| Step: 1
Training loss: 3.1715474077001513
Validation loss: 2.6507536287636304

Epoch: 5| Step: 2
Training loss: 2.782773232972802
Validation loss: 2.6396294309432373

Epoch: 5| Step: 3
Training loss: 3.562744935299049
Validation loss: 2.6378089202493045

Epoch: 5| Step: 4
Training loss: 2.9565748620931505
Validation loss: 2.6418042341939194

Epoch: 5| Step: 5
Training loss: 2.708733886051174
Validation loss: 2.658391611552944

Epoch: 5| Step: 6
Training loss: 2.93870227640296
Validation loss: 2.6814724407178225

Epoch: 5| Step: 7
Training loss: 2.746828244172653
Validation loss: 2.6411445680781482

Epoch: 5| Step: 8
Training loss: 2.6648573598567276
Validation loss: 2.6241981211314243

Epoch: 5| Step: 9
Training loss: 3.0718817740876956
Validation loss: 2.61797341411485

Epoch: 5| Step: 10
Training loss: 3.0703845610182223
Validation loss: 2.6216702611291893

Epoch: 78| Step: 0
Training loss: 2.417506652949113
Validation loss: 2.6178771465635164

Epoch: 5| Step: 1
Training loss: 2.7883304094602126
Validation loss: 2.6165099700646044

Epoch: 5| Step: 2
Training loss: 2.865395133846515
Validation loss: 2.618659229483704

Epoch: 5| Step: 3
Training loss: 3.7513974446979006
Validation loss: 2.6161545521247427

Epoch: 5| Step: 4
Training loss: 3.3622371811949647
Validation loss: 2.6159868665320793

Epoch: 5| Step: 5
Training loss: 2.4577982907572617
Validation loss: 2.6234735923330192

Epoch: 5| Step: 6
Training loss: 2.5484713366780545
Validation loss: 2.617911135271381

Epoch: 5| Step: 7
Training loss: 2.4967613222983296
Validation loss: 2.626641346815304

Epoch: 5| Step: 8
Training loss: 3.1969961193778285
Validation loss: 2.632117533315432

Epoch: 5| Step: 9
Training loss: 3.5029616767862595
Validation loss: 2.63871654522692

Epoch: 5| Step: 10
Training loss: 2.841553395121524
Validation loss: 2.6384198254584845

Epoch: 79| Step: 0
Training loss: 3.3407776357896064
Validation loss: 2.6249349921049014

Epoch: 5| Step: 1
Training loss: 2.9455951585397298
Validation loss: 2.636722358145119

Epoch: 5| Step: 2
Training loss: 2.7411411821481853
Validation loss: 2.6223718130663722

Epoch: 5| Step: 3
Training loss: 2.2763647785607697
Validation loss: 2.6088561132288066

Epoch: 5| Step: 4
Training loss: 2.9390777246789686
Validation loss: 2.6125982089551085

Epoch: 5| Step: 5
Training loss: 2.8361915495604912
Validation loss: 2.6117762598639724

Epoch: 5| Step: 6
Training loss: 3.426546157123019
Validation loss: 2.6108698800750227

Epoch: 5| Step: 7
Training loss: 3.3295949635743924
Validation loss: 2.6143617247244975

Epoch: 5| Step: 8
Training loss: 2.446497036132015
Validation loss: 2.6169208663225523

Epoch: 5| Step: 9
Training loss: 3.1516522449127806
Validation loss: 2.6104439396733086

Epoch: 5| Step: 10
Training loss: 3.0900562468906214
Validation loss: 2.609405719786745

Epoch: 80| Step: 0
Training loss: 3.055470397995592
Validation loss: 2.6102318784153917

Epoch: 5| Step: 1
Training loss: 2.5268364563747303
Validation loss: 2.6082443018722308

Epoch: 5| Step: 2
Training loss: 3.266436024393044
Validation loss: 2.6057918106185034

Epoch: 5| Step: 3
Training loss: 2.733716874621811
Validation loss: 2.6060837401155212

Epoch: 5| Step: 4
Training loss: 3.1820564911513465
Validation loss: 2.6225393572733062

Epoch: 5| Step: 5
Training loss: 3.397175311137842
Validation loss: 2.657776834708078

Epoch: 5| Step: 6
Training loss: 2.9144116721728692
Validation loss: 2.670150754107029

Epoch: 5| Step: 7
Training loss: 2.6859813213934514
Validation loss: 2.6922465402648688

Epoch: 5| Step: 8
Training loss: 2.893044608633601
Validation loss: 2.6707412846564544

Epoch: 5| Step: 9
Training loss: 3.076842374843695
Validation loss: 2.6441799398273007

Epoch: 5| Step: 10
Training loss: 2.789048651652857
Validation loss: 2.612315482561104

Epoch: 81| Step: 0
Training loss: 3.109550279440526
Validation loss: 2.59835095913769

Epoch: 5| Step: 1
Training loss: 3.392437709610366
Validation loss: 2.6003578208008857

Epoch: 5| Step: 2
Training loss: 2.55495626453211
Validation loss: 2.604061319168729

Epoch: 5| Step: 3
Training loss: 2.9963001642654965
Validation loss: 2.596331279945584

Epoch: 5| Step: 4
Training loss: 3.444680499803652
Validation loss: 2.6003496360126688

Epoch: 5| Step: 5
Training loss: 2.2316066424858816
Validation loss: 2.5981756448055933

Epoch: 5| Step: 6
Training loss: 2.3730644570786423
Validation loss: 2.597338153916864

Epoch: 5| Step: 7
Training loss: 2.8617252217520837
Validation loss: 2.5952451498165043

Epoch: 5| Step: 8
Training loss: 3.128729768840809
Validation loss: 2.5936761186546704

Epoch: 5| Step: 9
Training loss: 2.8783167076256517
Validation loss: 2.598821870992339

Epoch: 5| Step: 10
Training loss: 3.3326409733481297
Validation loss: 2.599608852333138

Epoch: 82| Step: 0
Training loss: 2.4741974618018205
Validation loss: 2.603505502427002

Epoch: 5| Step: 1
Training loss: 3.166736367780315
Validation loss: 2.6089496399716356

Epoch: 5| Step: 2
Training loss: 3.1670953226249403
Validation loss: 2.621531195202461

Epoch: 5| Step: 3
Training loss: 2.9180913079809323
Validation loss: 2.611756622505231

Epoch: 5| Step: 4
Training loss: 2.989521322814572
Validation loss: 2.6052704123852273

Epoch: 5| Step: 5
Training loss: 3.324731950782749
Validation loss: 2.593437843204555

Epoch: 5| Step: 6
Training loss: 2.791018785671102
Validation loss: 2.5978305079396096

Epoch: 5| Step: 7
Training loss: 2.83585376458249
Validation loss: 2.5975305704953477

Epoch: 5| Step: 8
Training loss: 3.1969251224172086
Validation loss: 2.6027768238924316

Epoch: 5| Step: 9
Training loss: 2.4486105618542666
Validation loss: 2.616982311567569

Epoch: 5| Step: 10
Training loss: 3.078423655007061
Validation loss: 2.6092979248327643

Epoch: 83| Step: 0
Training loss: 3.1139906167224005
Validation loss: 2.594025367088495

Epoch: 5| Step: 1
Training loss: 2.859326805167181
Validation loss: 2.591529098975711

Epoch: 5| Step: 2
Training loss: 2.4036671040683184
Validation loss: 2.5967851037749297

Epoch: 5| Step: 3
Training loss: 3.27073364753837
Validation loss: 2.598057559818376

Epoch: 5| Step: 4
Training loss: 3.5955197164742647
Validation loss: 2.5955106401100085

Epoch: 5| Step: 5
Training loss: 3.1171189685449128
Validation loss: 2.5977673790774385

Epoch: 5| Step: 6
Training loss: 2.41021303082173
Validation loss: 2.598816429658823

Epoch: 5| Step: 7
Training loss: 2.9199150161917773
Validation loss: 2.599799565508369

Epoch: 5| Step: 8
Training loss: 3.060793342720286
Validation loss: 2.5985477096904304

Epoch: 5| Step: 9
Training loss: 2.7685088730777183
Validation loss: 2.6000763457142932

Epoch: 5| Step: 10
Training loss: 2.8058239857724043
Validation loss: 2.598547608074058

Epoch: 84| Step: 0
Training loss: 3.4228349845800397
Validation loss: 2.5875420128889814

Epoch: 5| Step: 1
Training loss: 2.947879552888381
Validation loss: 2.591618476131851

Epoch: 5| Step: 2
Training loss: 2.9157361499006393
Validation loss: 2.6035831931513074

Epoch: 5| Step: 3
Training loss: 3.1516832607510916
Validation loss: 2.626242963025303

Epoch: 5| Step: 4
Training loss: 3.037877967457879
Validation loss: 2.639095091593774

Epoch: 5| Step: 5
Training loss: 2.254307226944857
Validation loss: 2.63341751223696

Epoch: 5| Step: 6
Training loss: 3.203932051053604
Validation loss: 2.62936798742558

Epoch: 5| Step: 7
Training loss: 3.2617129023151175
Validation loss: 2.619866014492789

Epoch: 5| Step: 8
Training loss: 2.2445457896190883
Validation loss: 2.595885464069381

Epoch: 5| Step: 9
Training loss: 3.0923541995119606
Validation loss: 2.5903700803189986

Epoch: 5| Step: 10
Training loss: 2.697184921261648
Validation loss: 2.5883101225666834

Epoch: 85| Step: 0
Training loss: 2.9421640258436073
Validation loss: 2.588969413544488

Epoch: 5| Step: 1
Training loss: 2.292703382482965
Validation loss: 2.5880881930514548

Epoch: 5| Step: 2
Training loss: 3.291633670174725
Validation loss: 2.586034948603871

Epoch: 5| Step: 3
Training loss: 2.627290453045553
Validation loss: 2.586893189902151

Epoch: 5| Step: 4
Training loss: 3.053526518705782
Validation loss: 2.5937500098839155

Epoch: 5| Step: 5
Training loss: 2.9808747701206104
Validation loss: 2.5967978193479255

Epoch: 5| Step: 6
Training loss: 3.0451902769173285
Validation loss: 2.5990624472393935

Epoch: 5| Step: 7
Training loss: 2.751563148130203
Validation loss: 2.6014483253508827

Epoch: 5| Step: 8
Training loss: 3.0057327808990104
Validation loss: 2.6173196033484607

Epoch: 5| Step: 9
Training loss: 3.3823845220393913
Validation loss: 2.630785593491791

Epoch: 5| Step: 10
Training loss: 2.920089420882886
Validation loss: 2.6001992529505102

Epoch: 86| Step: 0
Training loss: 3.033326686250998
Validation loss: 2.5864116225507026

Epoch: 5| Step: 1
Training loss: 3.1551390855120447
Validation loss: 2.5919263042230196

Epoch: 5| Step: 2
Training loss: 2.8820594693149495
Validation loss: 2.5916664709001362

Epoch: 5| Step: 3
Training loss: 2.497225366104103
Validation loss: 2.5867428302741984

Epoch: 5| Step: 4
Training loss: 2.6235917264716884
Validation loss: 2.592672676551154

Epoch: 5| Step: 5
Training loss: 3.2131619138884493
Validation loss: 2.591041468270911

Epoch: 5| Step: 6
Training loss: 2.5097747446332366
Validation loss: 2.5939470520957295

Epoch: 5| Step: 7
Training loss: 3.021771901215185
Validation loss: 2.597031282195069

Epoch: 5| Step: 8
Training loss: 3.052613005174877
Validation loss: 2.600210756873808

Epoch: 5| Step: 9
Training loss: 3.2190246464857357
Validation loss: 2.607630556690769

Epoch: 5| Step: 10
Training loss: 3.1178456617895227
Validation loss: 2.6084059385308684

Epoch: 87| Step: 0
Training loss: 2.55288903629606
Validation loss: 2.6099338965774495

Epoch: 5| Step: 1
Training loss: 2.847060404161859
Validation loss: 2.6077615977864745

Epoch: 5| Step: 2
Training loss: 3.6426522173262166
Validation loss: 2.6108431621527135

Epoch: 5| Step: 3
Training loss: 3.046131688928827
Validation loss: 2.610187577157422

Epoch: 5| Step: 4
Training loss: 3.156310732417706
Validation loss: 2.6058540062484563

Epoch: 5| Step: 5
Training loss: 2.7757323321158367
Validation loss: 2.6053952363870327

Epoch: 5| Step: 6
Training loss: 3.0191237950753584
Validation loss: 2.614116504624425

Epoch: 5| Step: 7
Training loss: 3.003453809697646
Validation loss: 2.6121042847915197

Epoch: 5| Step: 8
Training loss: 2.9757410552979966
Validation loss: 2.6223456390605535

Epoch: 5| Step: 9
Training loss: 2.5130310901702657
Validation loss: 2.6328842870449045

Epoch: 5| Step: 10
Training loss: 2.688041809824078
Validation loss: 2.6259736996106775

Epoch: 88| Step: 0
Training loss: 2.7947894797433284
Validation loss: 2.6491868233209455

Epoch: 5| Step: 1
Training loss: 2.29161070553048
Validation loss: 2.6421643356627684

Epoch: 5| Step: 2
Training loss: 3.512640741861353
Validation loss: 2.6435349972119333

Epoch: 5| Step: 3
Training loss: 2.776742947993378
Validation loss: 2.6256805412813238

Epoch: 5| Step: 4
Training loss: 2.4857617232771263
Validation loss: 2.618105728482344

Epoch: 5| Step: 5
Training loss: 3.1543850062668684
Validation loss: 2.610946091912542

Epoch: 5| Step: 6
Training loss: 2.9440674110552227
Validation loss: 2.6032970986555886

Epoch: 5| Step: 7
Training loss: 3.1568522870098805
Validation loss: 2.5970092905354822

Epoch: 5| Step: 8
Training loss: 3.001201071318514
Validation loss: 2.5999342907331866

Epoch: 5| Step: 9
Training loss: 3.1314517749945012
Validation loss: 2.5991716924708452

Epoch: 5| Step: 10
Training loss: 2.9617628894717667
Validation loss: 2.5992978153545634

Epoch: 89| Step: 0
Training loss: 3.196510743152807
Validation loss: 2.59698426810829

Epoch: 5| Step: 1
Training loss: 3.225892817202489
Validation loss: 2.5988384809968785

Epoch: 5| Step: 2
Training loss: 2.4839526123281312
Validation loss: 2.5965555858625278

Epoch: 5| Step: 3
Training loss: 3.2701381908462896
Validation loss: 2.595338623767273

Epoch: 5| Step: 4
Training loss: 3.2459393589656784
Validation loss: 2.609653339421675

Epoch: 5| Step: 5
Training loss: 2.962874209434585
Validation loss: 2.630032802504957

Epoch: 5| Step: 6
Training loss: 2.2896959905934238
Validation loss: 2.680881307628635

Epoch: 5| Step: 7
Training loss: 3.037094930632854
Validation loss: 2.6965894596866153

Epoch: 5| Step: 8
Training loss: 2.948918490251298
Validation loss: 2.6362275362815653

Epoch: 5| Step: 9
Training loss: 2.776081898429351
Validation loss: 2.5927048025379635

Epoch: 5| Step: 10
Training loss: 2.8585599144045806
Validation loss: 2.5914111721259885

Epoch: 90| Step: 0
Training loss: 3.6192964869214155
Validation loss: 2.594832332779814

Epoch: 5| Step: 1
Training loss: 2.9002027046129446
Validation loss: 2.5972480872076056

Epoch: 5| Step: 2
Training loss: 2.9997701556850114
Validation loss: 2.6014593664960963

Epoch: 5| Step: 3
Training loss: 3.045081447019428
Validation loss: 2.605860911535451

Epoch: 5| Step: 4
Training loss: 2.1669693026337797
Validation loss: 2.603462906444886

Epoch: 5| Step: 5
Training loss: 3.301101217618509
Validation loss: 2.5927943675686107

Epoch: 5| Step: 6
Training loss: 2.6829207685660106
Validation loss: 2.59182295839567

Epoch: 5| Step: 7
Training loss: 2.4679125560559028
Validation loss: 2.5942419213025443

Epoch: 5| Step: 8
Training loss: 3.055500049279571
Validation loss: 2.6269228797675264

Epoch: 5| Step: 9
Training loss: 2.8464766624642497
Validation loss: 2.6507110386306203

Epoch: 5| Step: 10
Training loss: 3.320744313602853
Validation loss: 2.7109642934141536

Epoch: 91| Step: 0
Training loss: 2.4372746290041873
Validation loss: 2.6210121269348825

Epoch: 5| Step: 1
Training loss: 2.9724050408187255
Validation loss: 2.594112595754607

Epoch: 5| Step: 2
Training loss: 3.504956822585128
Validation loss: 2.5922678332478886

Epoch: 5| Step: 3
Training loss: 3.323491412515968
Validation loss: 2.590256975099892

Epoch: 5| Step: 4
Training loss: 2.9874925557446805
Validation loss: 2.6121829779502597

Epoch: 5| Step: 5
Training loss: 2.8363151193795266
Validation loss: 2.5983141897123656

Epoch: 5| Step: 6
Training loss: 2.7201238208524705
Validation loss: 2.594667705506382

Epoch: 5| Step: 7
Training loss: 2.9927389966325717
Validation loss: 2.5917318997935794

Epoch: 5| Step: 8
Training loss: 3.031605807786314
Validation loss: 2.592852817212702

Epoch: 5| Step: 9
Training loss: 2.9811393413359495
Validation loss: 2.5908828101392305

Epoch: 5| Step: 10
Training loss: 2.3800190544968474
Validation loss: 2.589804027696154

Epoch: 92| Step: 0
Training loss: 2.7347460685720555
Validation loss: 2.589811107433681

Epoch: 5| Step: 1
Training loss: 2.956746459308574
Validation loss: 2.593536656789425

Epoch: 5| Step: 2
Training loss: 2.9808616529197822
Validation loss: 2.5974361746196126

Epoch: 5| Step: 3
Training loss: 3.617116577244093
Validation loss: 2.594519487070554

Epoch: 5| Step: 4
Training loss: 2.9243749032099022
Validation loss: 2.5923248776204684

Epoch: 5| Step: 5
Training loss: 2.5328659739135593
Validation loss: 2.589939845996399

Epoch: 5| Step: 6
Training loss: 2.660943585588773
Validation loss: 2.584622815168244

Epoch: 5| Step: 7
Training loss: 2.3928422805389644
Validation loss: 2.5922136121409323

Epoch: 5| Step: 8
Training loss: 3.2388270600315296
Validation loss: 2.5990313507113907

Epoch: 5| Step: 9
Training loss: 3.091312411457621
Validation loss: 2.59396471720445

Epoch: 5| Step: 10
Training loss: 2.865053801772026
Validation loss: 2.6013063226253705

Epoch: 93| Step: 0
Training loss: 2.470299246726535
Validation loss: 2.6057019997091673

Epoch: 5| Step: 1
Training loss: 2.9080875289211465
Validation loss: 2.59373543699772

Epoch: 5| Step: 2
Training loss: 3.3163195487507338
Validation loss: 2.6121561252632337

Epoch: 5| Step: 3
Training loss: 2.6282580910094318
Validation loss: 2.593751754394444

Epoch: 5| Step: 4
Training loss: 2.958404181979717
Validation loss: 2.6134638007112025

Epoch: 5| Step: 5
Training loss: 2.7027366226877216
Validation loss: 2.6187433977567833

Epoch: 5| Step: 6
Training loss: 2.9068409308711227
Validation loss: 2.6570972440208367

Epoch: 5| Step: 7
Training loss: 3.2408757876964147
Validation loss: 2.604411906518505

Epoch: 5| Step: 8
Training loss: 2.7725469314551887
Validation loss: 2.567281884838614

Epoch: 5| Step: 9
Training loss: 3.0543286046859515
Validation loss: 2.556435032386383

Epoch: 5| Step: 10
Training loss: 3.0754944070471533
Validation loss: 2.561359716061808

Epoch: 94| Step: 0
Training loss: 2.710940314299692
Validation loss: 2.5657453667654164

Epoch: 5| Step: 1
Training loss: 2.175831217166374
Validation loss: 2.5701713943435998

Epoch: 5| Step: 2
Training loss: 3.451866783727689
Validation loss: 2.5766124475958136

Epoch: 5| Step: 3
Training loss: 3.106666957571428
Validation loss: 2.576610894454113

Epoch: 5| Step: 4
Training loss: 3.360334676241719
Validation loss: 2.582164026074931

Epoch: 5| Step: 5
Training loss: 2.9141261525910873
Validation loss: 2.578096709681939

Epoch: 5| Step: 6
Training loss: 3.0592824421208555
Validation loss: 2.5798968647919214

Epoch: 5| Step: 7
Training loss: 2.712731199475523
Validation loss: 2.577421299272446

Epoch: 5| Step: 8
Training loss: 2.7062171493545097
Validation loss: 2.579466295902675

Epoch: 5| Step: 9
Training loss: 2.953123223844125
Validation loss: 2.581132772899799

Epoch: 5| Step: 10
Training loss: 3.149579089668592
Validation loss: 2.6055235955584606

Epoch: 95| Step: 0
Training loss: 2.6403507790018237
Validation loss: 2.597883561839803

Epoch: 5| Step: 1
Training loss: 2.613441998337502
Validation loss: 2.582795817265454

Epoch: 5| Step: 2
Training loss: 2.9644509760212596
Validation loss: 2.5752745411812867

Epoch: 5| Step: 3
Training loss: 2.228133226462395
Validation loss: 2.569739026321348

Epoch: 5| Step: 4
Training loss: 2.7474571088613846
Validation loss: 2.5724412650682615

Epoch: 5| Step: 5
Training loss: 2.7779823566972297
Validation loss: 2.581401235082064

Epoch: 5| Step: 6
Training loss: 2.9627562399999583
Validation loss: 2.6031649543644475

Epoch: 5| Step: 7
Training loss: 3.311373105091827
Validation loss: 2.646164074464248

Epoch: 5| Step: 8
Training loss: 3.274270618549434
Validation loss: 2.587082038069024

Epoch: 5| Step: 9
Training loss: 3.112730736203888
Validation loss: 2.5666736745585528

Epoch: 5| Step: 10
Training loss: 3.4908455610816187
Validation loss: 2.562277855537083

Epoch: 96| Step: 0
Training loss: 3.2825157993747007
Validation loss: 2.548178857366796

Epoch: 5| Step: 1
Training loss: 3.234039584104557
Validation loss: 2.5515921914741435

Epoch: 5| Step: 2
Training loss: 2.5258167494436368
Validation loss: 2.5536812945130327

Epoch: 5| Step: 3
Training loss: 2.5117602307823286
Validation loss: 2.558053052542105

Epoch: 5| Step: 4
Training loss: 3.006836254668707
Validation loss: 2.560053869644901

Epoch: 5| Step: 5
Training loss: 2.665850623757313
Validation loss: 2.5730637854581597

Epoch: 5| Step: 6
Training loss: 2.7212270217226755
Validation loss: 2.583099790000484

Epoch: 5| Step: 7
Training loss: 2.9982189613681682
Validation loss: 2.565472956439366

Epoch: 5| Step: 8
Training loss: 3.3348093738436515
Validation loss: 2.5691083959011554

Epoch: 5| Step: 9
Training loss: 2.8186767568609157
Validation loss: 2.5645755272852098

Epoch: 5| Step: 10
Training loss: 2.8022113378469524
Validation loss: 2.5546472882510494

Epoch: 97| Step: 0
Training loss: 2.83072572279191
Validation loss: 2.5505401573271738

Epoch: 5| Step: 1
Training loss: 2.9105180144271032
Validation loss: 2.558663101590265

Epoch: 5| Step: 2
Training loss: 2.992273075483613
Validation loss: 2.562097541344455

Epoch: 5| Step: 3
Training loss: 3.333287922231975
Validation loss: 2.558213060293617

Epoch: 5| Step: 4
Training loss: 3.559768030774247
Validation loss: 2.5891348249429758

Epoch: 5| Step: 5
Training loss: 2.94889116299441
Validation loss: 2.5894118995941486

Epoch: 5| Step: 6
Training loss: 2.288425916876592
Validation loss: 2.5867654503342004

Epoch: 5| Step: 7
Training loss: 2.632469992616046
Validation loss: 2.5591963154200394

Epoch: 5| Step: 8
Training loss: 3.193220204345059
Validation loss: 2.5558468647579087

Epoch: 5| Step: 9
Training loss: 2.3959353439064617
Validation loss: 2.554398610820256

Epoch: 5| Step: 10
Training loss: 2.715936454585766
Validation loss: 2.554104646212358

Epoch: 98| Step: 0
Training loss: 3.0691956485895924
Validation loss: 2.5547416063875854

Epoch: 5| Step: 1
Training loss: 3.010020052820876
Validation loss: 2.5571393502568376

Epoch: 5| Step: 2
Training loss: 2.0488814209732764
Validation loss: 2.5547255516072105

Epoch: 5| Step: 3
Training loss: 3.263686047106049
Validation loss: 2.5595562761759343

Epoch: 5| Step: 4
Training loss: 2.497658777698029
Validation loss: 2.5504393562411054

Epoch: 5| Step: 5
Training loss: 2.7108996825644844
Validation loss: 2.554193374720855

Epoch: 5| Step: 6
Training loss: 3.1224554765152095
Validation loss: 2.555319656773605

Epoch: 5| Step: 7
Training loss: 2.8346801997256756
Validation loss: 2.5600222862623334

Epoch: 5| Step: 8
Training loss: 2.9399856439875736
Validation loss: 2.5804724751846333

Epoch: 5| Step: 9
Training loss: 3.613584895391779
Validation loss: 2.5768493758101196

Epoch: 5| Step: 10
Training loss: 2.521289111672331
Validation loss: 2.585340086303777

Epoch: 99| Step: 0
Training loss: 2.864558956158114
Validation loss: 2.5923680739385553

Epoch: 5| Step: 1
Training loss: 2.9195070514283477
Validation loss: 2.5798427791821283

Epoch: 5| Step: 2
Training loss: 3.3506477014490907
Validation loss: 2.5600590488858974

Epoch: 5| Step: 3
Training loss: 2.7071515561628
Validation loss: 2.5493801239781697

Epoch: 5| Step: 4
Training loss: 2.985027142118572
Validation loss: 2.5487187225470236

Epoch: 5| Step: 5
Training loss: 2.6798435532754032
Validation loss: 2.5439069777040144

Epoch: 5| Step: 6
Training loss: 2.6388921525723092
Validation loss: 2.5472364865553647

Epoch: 5| Step: 7
Training loss: 2.786814919350468
Validation loss: 2.5522343590663232

Epoch: 5| Step: 8
Training loss: 3.3640369802340646
Validation loss: 2.5524058493335122

Epoch: 5| Step: 9
Training loss: 2.394767214426384
Validation loss: 2.556327898026171

Epoch: 5| Step: 10
Training loss: 3.098063842588449
Validation loss: 2.5662735926763767

Epoch: 100| Step: 0
Training loss: 3.4394944387247604
Validation loss: 2.563199869860012

Epoch: 5| Step: 1
Training loss: 3.02306953182127
Validation loss: 2.562662657210631

Epoch: 5| Step: 2
Training loss: 2.8752731525194473
Validation loss: 2.551492750197396

Epoch: 5| Step: 3
Training loss: 2.2767923777079377
Validation loss: 2.5440051051634422

Epoch: 5| Step: 4
Training loss: 3.349997415114587
Validation loss: 2.542285075033454

Epoch: 5| Step: 5
Training loss: 2.9378605073516915
Validation loss: 2.545708275391547

Epoch: 5| Step: 6
Training loss: 2.4495715992903837
Validation loss: 2.5407883143276284

Epoch: 5| Step: 7
Training loss: 2.9201284482217162
Validation loss: 2.547275815913233

Epoch: 5| Step: 8
Training loss: 2.6683052710876907
Validation loss: 2.544671524811181

Epoch: 5| Step: 9
Training loss: 2.6391818826435727
Validation loss: 2.579295866319845

Epoch: 5| Step: 10
Training loss: 3.0720725414135375
Validation loss: 2.623612627610463

Epoch: 101| Step: 0
Training loss: 3.166092285131814
Validation loss: 2.7312128968728273

Epoch: 5| Step: 1
Training loss: 3.641645034853821
Validation loss: 2.744734134659935

Epoch: 5| Step: 2
Training loss: 3.0537498186184004
Validation loss: 2.649119022859659

Epoch: 5| Step: 3
Training loss: 2.5273715788592965
Validation loss: 2.617996351878409

Epoch: 5| Step: 4
Training loss: 2.2410428518124474
Validation loss: 2.6275744400156804

Epoch: 5| Step: 5
Training loss: 3.008535164555127
Validation loss: 2.6070495042153197

Epoch: 5| Step: 6
Training loss: 2.966294407437785
Validation loss: 2.5603082319019737

Epoch: 5| Step: 7
Training loss: 2.5472249919784318
Validation loss: 2.5410499330507856

Epoch: 5| Step: 8
Training loss: 3.1728350309280007
Validation loss: 2.551099015237143

Epoch: 5| Step: 9
Training loss: 2.5716928410593876
Validation loss: 2.5475560997636957

Epoch: 5| Step: 10
Training loss: 2.7725132221426043
Validation loss: 2.5535957226516457

Epoch: 102| Step: 0
Training loss: 3.130957913052826
Validation loss: 2.548974256169364

Epoch: 5| Step: 1
Training loss: 3.3508486398762987
Validation loss: 2.5558173744342185

Epoch: 5| Step: 2
Training loss: 3.15257850349569
Validation loss: 2.5616671901886514

Epoch: 5| Step: 3
Training loss: 2.8095694639054156
Validation loss: 2.560951110955434

Epoch: 5| Step: 4
Training loss: 2.239245887588178
Validation loss: 2.568121123464372

Epoch: 5| Step: 5
Training loss: 2.707924083209052
Validation loss: 2.6144273593177227

Epoch: 5| Step: 6
Training loss: 2.2702149298666208
Validation loss: 2.6481540983374345

Epoch: 5| Step: 7
Training loss: 2.4911511218502485
Validation loss: 2.6858871114966725

Epoch: 5| Step: 8
Training loss: 3.185298982537479
Validation loss: 2.627002214207243

Epoch: 5| Step: 9
Training loss: 2.8568457585225495
Validation loss: 2.5729715059881246

Epoch: 5| Step: 10
Training loss: 3.493060453060518
Validation loss: 2.5466465326946905

Epoch: 103| Step: 0
Training loss: 3.186667838581886
Validation loss: 2.541757785395036

Epoch: 5| Step: 1
Training loss: 2.7485838625020236
Validation loss: 2.5480871606877082

Epoch: 5| Step: 2
Training loss: 2.4297400956425457
Validation loss: 2.557029956504882

Epoch: 5| Step: 3
Training loss: 2.6695153597346795
Validation loss: 2.5491305495468057

Epoch: 5| Step: 4
Training loss: 2.736191064749712
Validation loss: 2.543679552003977

Epoch: 5| Step: 5
Training loss: 2.8087632681206856
Validation loss: 2.5355539762494974

Epoch: 5| Step: 6
Training loss: 3.3764648084440525
Validation loss: 2.5311477115836833

Epoch: 5| Step: 7
Training loss: 3.2801112060768545
Validation loss: 2.5346694853896663

Epoch: 5| Step: 8
Training loss: 2.583499554444502
Validation loss: 2.538567637896176

Epoch: 5| Step: 9
Training loss: 3.0139739107092542
Validation loss: 2.549135606162024

Epoch: 5| Step: 10
Training loss: 2.9769341344444142
Validation loss: 2.6031553671550385

Epoch: 104| Step: 0
Training loss: 2.9148625561616925
Validation loss: 2.6411847179535175

Epoch: 5| Step: 1
Training loss: 2.6468389407317225
Validation loss: 2.637509645064253

Epoch: 5| Step: 2
Training loss: 3.171299172735547
Validation loss: 2.5983214613522314

Epoch: 5| Step: 3
Training loss: 2.879585589687336
Validation loss: 2.5437211807971507

Epoch: 5| Step: 4
Training loss: 3.190609182230778
Validation loss: 2.529696360575109

Epoch: 5| Step: 5
Training loss: 3.060117300689948
Validation loss: 2.5339377487624835

Epoch: 5| Step: 6
Training loss: 2.4923131068035915
Validation loss: 2.5354577320130995

Epoch: 5| Step: 7
Training loss: 2.908159674530599
Validation loss: 2.538455037162151

Epoch: 5| Step: 8
Training loss: 2.532627813911635
Validation loss: 2.543744486778388

Epoch: 5| Step: 9
Training loss: 2.929101992273423
Validation loss: 2.5442910654523057

Epoch: 5| Step: 10
Training loss: 3.303249903169684
Validation loss: 2.549945921850265

Epoch: 105| Step: 0
Training loss: 2.803992905318009
Validation loss: 2.53570646433898

Epoch: 5| Step: 1
Training loss: 3.0139837196381225
Validation loss: 2.52776853353568

Epoch: 5| Step: 2
Training loss: 2.844598161580419
Validation loss: 2.529405040758543

Epoch: 5| Step: 3
Training loss: 2.4315682641718364
Validation loss: 2.5454691677112335

Epoch: 5| Step: 4
Training loss: 2.6096445275634186
Validation loss: 2.5521490561130222

Epoch: 5| Step: 5
Training loss: 2.6363806387672932
Validation loss: 2.550542432954865

Epoch: 5| Step: 6
Training loss: 2.421196134851365
Validation loss: 2.5443096526755613

Epoch: 5| Step: 7
Training loss: 3.072248396973708
Validation loss: 2.543205864000427

Epoch: 5| Step: 8
Training loss: 3.339629441908958
Validation loss: 2.540487322110186

Epoch: 5| Step: 9
Training loss: 3.4715895843616846
Validation loss: 2.5473900807684267

Epoch: 5| Step: 10
Training loss: 3.026159830242988
Validation loss: 2.542399323194249

Epoch: 106| Step: 0
Training loss: 2.5897421148043693
Validation loss: 2.5592212705607404

Epoch: 5| Step: 1
Training loss: 2.7076413566623985
Validation loss: 2.58032575131621

Epoch: 5| Step: 2
Training loss: 2.879386706484726
Validation loss: 2.5776099611920715

Epoch: 5| Step: 3
Training loss: 2.984642136686077
Validation loss: 2.5828195637250877

Epoch: 5| Step: 4
Training loss: 2.8468619286648496
Validation loss: 2.571597079052224

Epoch: 5| Step: 5
Training loss: 3.2138210445164423
Validation loss: 2.555900463143044

Epoch: 5| Step: 6
Training loss: 2.922149971655826
Validation loss: 2.548110553503984

Epoch: 5| Step: 7
Training loss: 3.171513729474094
Validation loss: 2.5503492054310435

Epoch: 5| Step: 8
Training loss: 2.7247904180722253
Validation loss: 2.553880850991749

Epoch: 5| Step: 9
Training loss: 2.50565794613141
Validation loss: 2.5638652939066398

Epoch: 5| Step: 10
Training loss: 3.06541568768705
Validation loss: 2.5704529566145573

Epoch: 107| Step: 0
Training loss: 3.1555481687498124
Validation loss: 2.5677618571822807

Epoch: 5| Step: 1
Training loss: 2.4719829395902977
Validation loss: 2.5584871599466776

Epoch: 5| Step: 2
Training loss: 2.363111152517552
Validation loss: 2.5514658355201356

Epoch: 5| Step: 3
Training loss: 3.2544633587643967
Validation loss: 2.551516933677451

Epoch: 5| Step: 4
Training loss: 2.930053850792248
Validation loss: 2.557049093781396

Epoch: 5| Step: 5
Training loss: 2.4388062327210984
Validation loss: 2.5429615277533273

Epoch: 5| Step: 6
Training loss: 3.178071682313022
Validation loss: 2.5444100023927394

Epoch: 5| Step: 7
Training loss: 3.6407828235389528
Validation loss: 2.5324675197936033

Epoch: 5| Step: 8
Training loss: 2.3720811676367513
Validation loss: 2.53035027239719

Epoch: 5| Step: 9
Training loss: 3.0078483282159953
Validation loss: 2.5317593387058683

Epoch: 5| Step: 10
Training loss: 2.55140414380219
Validation loss: 2.538005826693542

Epoch: 108| Step: 0
Training loss: 2.7915346958983944
Validation loss: 2.5418866239036704

Epoch: 5| Step: 1
Training loss: 3.6193713193389563
Validation loss: 2.5431920710195146

Epoch: 5| Step: 2
Training loss: 2.5743948104922265
Validation loss: 2.5334697800657735

Epoch: 5| Step: 3
Training loss: 2.9278180884671223
Validation loss: 2.5290873110148944

Epoch: 5| Step: 4
Training loss: 2.5934457255755996
Validation loss: 2.526199551718284

Epoch: 5| Step: 5
Training loss: 2.952983227106987
Validation loss: 2.5257736654210783

Epoch: 5| Step: 6
Training loss: 2.8463833531974174
Validation loss: 2.529237527262275

Epoch: 5| Step: 7
Training loss: 2.670364041888472
Validation loss: 2.5476597026852836

Epoch: 5| Step: 8
Training loss: 3.0576873644533693
Validation loss: 2.564881955225637

Epoch: 5| Step: 9
Training loss: 2.7573910139858673
Validation loss: 2.579459973921228

Epoch: 5| Step: 10
Training loss: 2.9123237065345373
Validation loss: 2.6098885313640747

Epoch: 109| Step: 0
Training loss: 3.0682552521520106
Validation loss: 2.5919856131578616

Epoch: 5| Step: 1
Training loss: 3.0532630662731433
Validation loss: 2.5629110979477527

Epoch: 5| Step: 2
Training loss: 2.569828068960278
Validation loss: 2.54847916498693

Epoch: 5| Step: 3
Training loss: 2.7100837528476367
Validation loss: 2.523003559193424

Epoch: 5| Step: 4
Training loss: 2.6729110582926645
Validation loss: 2.518674752229399

Epoch: 5| Step: 5
Training loss: 3.378513061931766
Validation loss: 2.515885697470773

Epoch: 5| Step: 6
Training loss: 2.5948449087378673
Validation loss: 2.515409250038635

Epoch: 5| Step: 7
Training loss: 3.06453263694449
Validation loss: 2.5219930064296543

Epoch: 5| Step: 8
Training loss: 3.0238066849553986
Validation loss: 2.5239828969260496

Epoch: 5| Step: 9
Training loss: 2.625244855814123
Validation loss: 2.5372047674470113

Epoch: 5| Step: 10
Training loss: 2.726102423996014
Validation loss: 2.5529078742308715

Epoch: 110| Step: 0
Training loss: 2.197922102452889
Validation loss: 2.5765774663593493

Epoch: 5| Step: 1
Training loss: 2.8661277537971728
Validation loss: 2.5853532686900715

Epoch: 5| Step: 2
Training loss: 3.077790372832686
Validation loss: 2.608062003127095

Epoch: 5| Step: 3
Training loss: 3.060063385400449
Validation loss: 2.5700002346515127

Epoch: 5| Step: 4
Training loss: 2.9755322533206994
Validation loss: 2.553301860391843

Epoch: 5| Step: 5
Training loss: 2.6202706012321784
Validation loss: 2.5388168046964594

Epoch: 5| Step: 6
Training loss: 2.9278148311785266
Validation loss: 2.527461536961505

Epoch: 5| Step: 7
Training loss: 2.764108705538759
Validation loss: 2.5169909791524137

Epoch: 5| Step: 8
Training loss: 3.0024237378652563
Validation loss: 2.5219390543838736

Epoch: 5| Step: 9
Training loss: 3.394899548040292
Validation loss: 2.508751164352322

Epoch: 5| Step: 10
Training loss: 2.419439949774068
Validation loss: 2.5160790300376963

Epoch: 111| Step: 0
Training loss: 2.7705635761703884
Validation loss: 2.5157083803133053

Epoch: 5| Step: 1
Training loss: 2.9802319593847524
Validation loss: 2.5131328265580213

Epoch: 5| Step: 2
Training loss: 2.438396386847735
Validation loss: 2.5118973244824043

Epoch: 5| Step: 3
Training loss: 3.004498923062966
Validation loss: 2.5160581317395923

Epoch: 5| Step: 4
Training loss: 3.04781088516191
Validation loss: 2.526603672916494

Epoch: 5| Step: 5
Training loss: 3.3706030284038864
Validation loss: 2.5529691625838646

Epoch: 5| Step: 6
Training loss: 2.5360421864824434
Validation loss: 2.5569897605392637

Epoch: 5| Step: 7
Training loss: 2.118043620869794
Validation loss: 2.556650626288971

Epoch: 5| Step: 8
Training loss: 3.258564887311114
Validation loss: 2.562097279186645

Epoch: 5| Step: 9
Training loss: 3.384135703294563
Validation loss: 2.577824712016207

Epoch: 5| Step: 10
Training loss: 2.3140017813805107
Validation loss: 2.5299520138439937

Epoch: 112| Step: 0
Training loss: 3.1537710595986996
Validation loss: 2.5187982066290555

Epoch: 5| Step: 1
Training loss: 2.8303038913140584
Validation loss: 2.512620929258071

Epoch: 5| Step: 2
Training loss: 2.204879495005089
Validation loss: 2.508402215343469

Epoch: 5| Step: 3
Training loss: 2.856724579030077
Validation loss: 2.5171363594640574

Epoch: 5| Step: 4
Training loss: 3.1394272982968574
Validation loss: 2.511171299940886

Epoch: 5| Step: 5
Training loss: 2.3178157024302277
Validation loss: 2.5091977563231174

Epoch: 5| Step: 6
Training loss: 3.3509304633329493
Validation loss: 2.5129578482345267

Epoch: 5| Step: 7
Training loss: 2.4952039490786238
Validation loss: 2.512820683845924

Epoch: 5| Step: 8
Training loss: 3.0025750870411736
Validation loss: 2.5210176354927714

Epoch: 5| Step: 9
Training loss: 3.150284369817711
Validation loss: 2.5361622198719656

Epoch: 5| Step: 10
Training loss: 2.9133378424125826
Validation loss: 2.5446679725243326

Epoch: 113| Step: 0
Training loss: 2.8971869143363125
Validation loss: 2.552763990820797

Epoch: 5| Step: 1
Training loss: 2.751579784575139
Validation loss: 2.555306376133349

Epoch: 5| Step: 2
Training loss: 2.3710832925531338
Validation loss: 2.557121375610875

Epoch: 5| Step: 3
Training loss: 2.826293858319014
Validation loss: 2.578990684788886

Epoch: 5| Step: 4
Training loss: 3.499972752056324
Validation loss: 2.608769423724418

Epoch: 5| Step: 5
Training loss: 3.041429240396827
Validation loss: 2.575861700389351

Epoch: 5| Step: 6
Training loss: 2.6745386955869406
Validation loss: 2.5740604482982787

Epoch: 5| Step: 7
Training loss: 2.8998891480404647
Validation loss: 2.547830548994895

Epoch: 5| Step: 8
Training loss: 2.6087245473090697
Validation loss: 2.5345133208514965

Epoch: 5| Step: 9
Training loss: 2.792515089631186
Validation loss: 2.525522103310147

Epoch: 5| Step: 10
Training loss: 3.0582340657462947
Validation loss: 2.5218446337473552

Epoch: 114| Step: 0
Training loss: 2.922709136867791
Validation loss: 2.5222407755909386

Epoch: 5| Step: 1
Training loss: 3.048142233215762
Validation loss: 2.5305911297554933

Epoch: 5| Step: 2
Training loss: 3.2255653891167317
Validation loss: 2.529195620547157

Epoch: 5| Step: 3
Training loss: 2.8871767664070997
Validation loss: 2.5291388988077097

Epoch: 5| Step: 4
Training loss: 3.331656431558016
Validation loss: 2.5285075219251634

Epoch: 5| Step: 5
Training loss: 2.7711913563498825
Validation loss: 2.5238807040362543

Epoch: 5| Step: 6
Training loss: 3.0128352251749804
Validation loss: 2.5256830970559427

Epoch: 5| Step: 7
Training loss: 2.6740366796575645
Validation loss: 2.5171047906127573

Epoch: 5| Step: 8
Training loss: 2.7982931111549947
Validation loss: 2.5114362795114498

Epoch: 5| Step: 9
Training loss: 2.412968359830272
Validation loss: 2.512137089575692

Epoch: 5| Step: 10
Training loss: 2.551469461738582
Validation loss: 2.507160399335835

Epoch: 115| Step: 0
Training loss: 2.2612197668143152
Validation loss: 2.532701494176237

Epoch: 5| Step: 1
Training loss: 3.538286069200047
Validation loss: 2.569049076731438

Epoch: 5| Step: 2
Training loss: 2.648002296181689
Validation loss: 2.574792586010578

Epoch: 5| Step: 3
Training loss: 2.7822711227345964
Validation loss: 2.5697514567217636

Epoch: 5| Step: 4
Training loss: 2.7010435348329707
Validation loss: 2.567832045389283

Epoch: 5| Step: 5
Training loss: 2.4423207271697125
Validation loss: 2.5427621043871103

Epoch: 5| Step: 6
Training loss: 3.1693165048878122
Validation loss: 2.5366122864097322

Epoch: 5| Step: 7
Training loss: 2.9862249742036546
Validation loss: 2.5350554783545483

Epoch: 5| Step: 8
Training loss: 3.073047148094878
Validation loss: 2.524436162560419

Epoch: 5| Step: 9
Training loss: 2.8451514511155915
Validation loss: 2.5206528984411087

Epoch: 5| Step: 10
Training loss: 2.7834644716934043
Validation loss: 2.514088770958322

Epoch: 116| Step: 0
Training loss: 2.8559761901098057
Validation loss: 2.5079081052018473

Epoch: 5| Step: 1
Training loss: 2.601768966592476
Validation loss: 2.5030176746612143

Epoch: 5| Step: 2
Training loss: 3.128299192290727
Validation loss: 2.505880615649744

Epoch: 5| Step: 3
Training loss: 3.273540049109679
Validation loss: 2.5040346946200476

Epoch: 5| Step: 4
Training loss: 2.6589330249914873
Validation loss: 2.4995438097998255

Epoch: 5| Step: 5
Training loss: 2.6722314607967665
Validation loss: 2.511318203364316

Epoch: 5| Step: 6
Training loss: 2.9766086364534683
Validation loss: 2.501652907447317

Epoch: 5| Step: 7
Training loss: 2.892135637787979
Validation loss: 2.512775751747346

Epoch: 5| Step: 8
Training loss: 3.1674750116171
Validation loss: 2.527083470665001

Epoch: 5| Step: 9
Training loss: 2.4467271119463345
Validation loss: 2.534635588099599

Epoch: 5| Step: 10
Training loss: 2.4894507996676825
Validation loss: 2.562346199956605

Epoch: 117| Step: 0
Training loss: 3.091955107388915
Validation loss: 2.6179538643698193

Epoch: 5| Step: 1
Training loss: 2.852569318726479
Validation loss: 2.6331431501126015

Epoch: 5| Step: 2
Training loss: 2.9587336166437512
Validation loss: 2.6689243149154938

Epoch: 5| Step: 3
Training loss: 3.3813593256229146
Validation loss: 2.5699427296586594

Epoch: 5| Step: 4
Training loss: 2.9480864315328486
Validation loss: 2.506773166870982

Epoch: 5| Step: 5
Training loss: 2.633654632362546
Validation loss: 2.5304113325718753

Epoch: 5| Step: 6
Training loss: 2.8924017317291804
Validation loss: 2.5821576491430362

Epoch: 5| Step: 7
Training loss: 2.9407283817486727
Validation loss: 2.6343094494321138

Epoch: 5| Step: 8
Training loss: 2.626983438196386
Validation loss: 2.608342173183726

Epoch: 5| Step: 9
Training loss: 3.0881034106990164
Validation loss: 2.572087239943863

Epoch: 5| Step: 10
Training loss: 2.918010583702801
Validation loss: 2.545947165770839

Epoch: 118| Step: 0
Training loss: 3.077509474813346
Validation loss: 2.5243295702820916

Epoch: 5| Step: 1
Training loss: 2.893599675601586
Validation loss: 2.5096102296508693

Epoch: 5| Step: 2
Training loss: 2.535079508179767
Validation loss: 2.5053006798297903

Epoch: 5| Step: 3
Training loss: 3.395286625264529
Validation loss: 2.526207972689827

Epoch: 5| Step: 4
Training loss: 2.944070650362136
Validation loss: 2.5568679235613936

Epoch: 5| Step: 5
Training loss: 2.75069184703769
Validation loss: 2.6349298904001337

Epoch: 5| Step: 6
Training loss: 2.9601769590320406
Validation loss: 2.692373991463986

Epoch: 5| Step: 7
Training loss: 3.4633483067893454
Validation loss: 2.7130573662387394

Epoch: 5| Step: 8
Training loss: 2.4993984452350153
Validation loss: 2.5685978539540186

Epoch: 5| Step: 9
Training loss: 2.8066163297595814
Validation loss: 2.514493543738971

Epoch: 5| Step: 10
Training loss: 2.565034310927507
Validation loss: 2.494523065390178

Epoch: 119| Step: 0
Training loss: 2.950246871704791
Validation loss: 2.526328970569097

Epoch: 5| Step: 1
Training loss: 2.771506827588096
Validation loss: 2.5434695129886427

Epoch: 5| Step: 2
Training loss: 2.396143409455698
Validation loss: 2.5318557701079536

Epoch: 5| Step: 3
Training loss: 2.3924435947509695
Validation loss: 2.5153003499191513

Epoch: 5| Step: 4
Training loss: 3.1379828275328583
Validation loss: 2.508381377263471

Epoch: 5| Step: 5
Training loss: 2.9242994072624353
Validation loss: 2.503710581333955

Epoch: 5| Step: 6
Training loss: 3.3100615829316973
Validation loss: 2.495296415821565

Epoch: 5| Step: 7
Training loss: 2.9498610447630655
Validation loss: 2.499887698737832

Epoch: 5| Step: 8
Training loss: 3.371393890987595
Validation loss: 2.5045131636162123

Epoch: 5| Step: 9
Training loss: 2.755855654924181
Validation loss: 2.5214007159536544

Epoch: 5| Step: 10
Training loss: 2.3931021229449247
Validation loss: 2.541798512713784

Epoch: 120| Step: 0
Training loss: 2.433103165997681
Validation loss: 2.559158143961931

Epoch: 5| Step: 1
Training loss: 3.142754283683321
Validation loss: 2.6020609720445758

Epoch: 5| Step: 2
Training loss: 3.0406579387327373
Validation loss: 2.581939689188513

Epoch: 5| Step: 3
Training loss: 2.41674911972224
Validation loss: 2.5453743690111454

Epoch: 5| Step: 4
Training loss: 2.7639260111178956
Validation loss: 2.520427455243257

Epoch: 5| Step: 5
Training loss: 3.3172819062148293
Validation loss: 2.5011665739835576

Epoch: 5| Step: 6
Training loss: 3.0833418734320515
Validation loss: 2.4986067140116255

Epoch: 5| Step: 7
Training loss: 3.253588822395929
Validation loss: 2.50515686249028

Epoch: 5| Step: 8
Training loss: 2.5682412936258845
Validation loss: 2.5064917867687595

Epoch: 5| Step: 9
Training loss: 2.550037409938086
Validation loss: 2.510259394024708

Epoch: 5| Step: 10
Training loss: 3.0343308670496003
Validation loss: 2.519734617017809

Epoch: 121| Step: 0
Training loss: 2.7576501382468996
Validation loss: 2.520570453661721

Epoch: 5| Step: 1
Training loss: 2.92675439110786
Validation loss: 2.520110362664293

Epoch: 5| Step: 2
Training loss: 2.935483849331742
Validation loss: 2.5166601080572337

Epoch: 5| Step: 3
Training loss: 3.018488181944898
Validation loss: 2.5126970449266404

Epoch: 5| Step: 4
Training loss: 2.7962538386366735
Validation loss: 2.5114775505975326

Epoch: 5| Step: 5
Training loss: 3.335906624930306
Validation loss: 2.5167527847479745

Epoch: 5| Step: 6
Training loss: 2.935640111522508
Validation loss: 2.533594971354468

Epoch: 5| Step: 7
Training loss: 2.7321500608917355
Validation loss: 2.6193255910173026

Epoch: 5| Step: 8
Training loss: 3.071491044381828
Validation loss: 2.6792798351214855

Epoch: 5| Step: 9
Training loss: 2.462126139033441
Validation loss: 2.6817951278429395

Epoch: 5| Step: 10
Training loss: 2.6365839266745676
Validation loss: 2.691834812658072

Epoch: 122| Step: 0
Training loss: 2.6304439225142566
Validation loss: 2.6722056470853555

Epoch: 5| Step: 1
Training loss: 2.8718599503779707
Validation loss: 2.6483960642253197

Epoch: 5| Step: 2
Training loss: 2.988099974076859
Validation loss: 2.583685803920869

Epoch: 5| Step: 3
Training loss: 3.4316742514893455
Validation loss: 2.5464651770928977

Epoch: 5| Step: 4
Training loss: 2.5717267722594492
Validation loss: 2.515590804304617

Epoch: 5| Step: 5
Training loss: 2.986986545508177
Validation loss: 2.495372061343144

Epoch: 5| Step: 6
Training loss: 2.6911888533049537
Validation loss: 2.500669673728919

Epoch: 5| Step: 7
Training loss: 3.2115376971932252
Validation loss: 2.5262995735513183

Epoch: 5| Step: 8
Training loss: 2.999175594225039
Validation loss: 2.5254812332919

Epoch: 5| Step: 9
Training loss: 2.4098299816514666
Validation loss: 2.531131956851548

Epoch: 5| Step: 10
Training loss: 2.964493923130199
Validation loss: 2.554988612908631

Epoch: 123| Step: 0
Training loss: 2.888575966914871
Validation loss: 2.552218955485676

Epoch: 5| Step: 1
Training loss: 2.8932850738168856
Validation loss: 2.5623321838412614

Epoch: 5| Step: 2
Training loss: 2.345715118555413
Validation loss: 2.5726372278650116

Epoch: 5| Step: 3
Training loss: 2.240592681779379
Validation loss: 2.5976812856921736

Epoch: 5| Step: 4
Training loss: 3.025258858694471
Validation loss: 2.632468944749259

Epoch: 5| Step: 5
Training loss: 3.1249079881473643
Validation loss: 2.655106721063393

Epoch: 5| Step: 6
Training loss: 3.073949004654328
Validation loss: 2.6383436969317247

Epoch: 5| Step: 7
Training loss: 3.209381691870914
Validation loss: 2.6255384567779827

Epoch: 5| Step: 8
Training loss: 3.063418192333225
Validation loss: 2.5639381164907133

Epoch: 5| Step: 9
Training loss: 2.960724110827791
Validation loss: 2.5413020255858774

Epoch: 5| Step: 10
Training loss: 2.8023901751298927
Validation loss: 2.539867781922664

Epoch: 124| Step: 0
Training loss: 2.756411620784051
Validation loss: 2.5506149655135486

Epoch: 5| Step: 1
Training loss: 3.36060356917952
Validation loss: 2.5465375851781373

Epoch: 5| Step: 2
Training loss: 3.397862037080768
Validation loss: 2.5567548944656457

Epoch: 5| Step: 3
Training loss: 2.6117267176044145
Validation loss: 2.548155039606958

Epoch: 5| Step: 4
Training loss: 3.030207818587386
Validation loss: 2.546100785907745

Epoch: 5| Step: 5
Training loss: 3.169380748204198
Validation loss: 2.539180942798711

Epoch: 5| Step: 6
Training loss: 2.702665080375689
Validation loss: 2.5377886629940023

Epoch: 5| Step: 7
Training loss: 2.8957350643325737
Validation loss: 2.5364712728316157

Epoch: 5| Step: 8
Training loss: 2.372107903224686
Validation loss: 2.535839265944056

Epoch: 5| Step: 9
Training loss: 2.917100728751431
Validation loss: 2.5428132080709798

Epoch: 5| Step: 10
Training loss: 2.48247949997043
Validation loss: 2.547751347331255

Epoch: 125| Step: 0
Training loss: 2.7820525136690457
Validation loss: 2.5540920754218934

Epoch: 5| Step: 1
Training loss: 3.0743232912855505
Validation loss: 2.574455180536084

Epoch: 5| Step: 2
Training loss: 3.074875874068769
Validation loss: 2.60168985103589

Epoch: 5| Step: 3
Training loss: 2.8260337727304385
Validation loss: 2.60843559844925

Epoch: 5| Step: 4
Training loss: 2.7518112979943385
Validation loss: 2.6025005347959698

Epoch: 5| Step: 5
Training loss: 2.7953808592214777
Validation loss: 2.587657837415355

Epoch: 5| Step: 6
Training loss: 3.13562327028485
Validation loss: 2.5779704207003586

Epoch: 5| Step: 7
Training loss: 2.873477366732514
Validation loss: 2.551653773152378

Epoch: 5| Step: 8
Training loss: 2.6141610482126825
Validation loss: 2.527739557419548

Epoch: 5| Step: 9
Training loss: 3.080441295666873
Validation loss: 2.5237529931659672

Epoch: 5| Step: 10
Training loss: 2.5047662124116714
Validation loss: 2.5225236378880798

Epoch: 126| Step: 0
Training loss: 3.0638670692193353
Validation loss: 2.5209281501508207

Epoch: 5| Step: 1
Training loss: 2.313059971000181
Validation loss: 2.527258061359381

Epoch: 5| Step: 2
Training loss: 2.8282459717901167
Validation loss: 2.5249432449679583

Epoch: 5| Step: 3
Training loss: 3.159083237273816
Validation loss: 2.5251645804057063

Epoch: 5| Step: 4
Training loss: 3.0554382494362677
Validation loss: 2.5183887640872786

Epoch: 5| Step: 5
Training loss: 2.2025290691003225
Validation loss: 2.521229275475853

Epoch: 5| Step: 6
Training loss: 2.8345935674173552
Validation loss: 2.521439691845086

Epoch: 5| Step: 7
Training loss: 3.1646944898345652
Validation loss: 2.518910851504471

Epoch: 5| Step: 8
Training loss: 3.0092719166372652
Validation loss: 2.5314205400368595

Epoch: 5| Step: 9
Training loss: 2.6934528514417053
Validation loss: 2.5546047546888833

Epoch: 5| Step: 10
Training loss: 3.053062533595637
Validation loss: 2.599365891591535

Epoch: 127| Step: 0
Training loss: 2.785701318508052
Validation loss: 2.641969365149053

Epoch: 5| Step: 1
Training loss: 3.131837003283651
Validation loss: 2.6652090244441715

Epoch: 5| Step: 2
Training loss: 2.522723779043267
Validation loss: 2.7377759971055964

Epoch: 5| Step: 3
Training loss: 3.585021190713691
Validation loss: 2.8494637167361074

Epoch: 5| Step: 4
Training loss: 2.4798791860563094
Validation loss: 2.7977767125985067

Epoch: 5| Step: 5
Training loss: 3.1143522825413488
Validation loss: 2.712247997910062

Epoch: 5| Step: 6
Training loss: 2.80194935720614
Validation loss: 2.603983821889777

Epoch: 5| Step: 7
Training loss: 2.8063494930174375
Validation loss: 2.57610295097851

Epoch: 5| Step: 8
Training loss: 2.9160198766085883
Validation loss: 2.562827835901702

Epoch: 5| Step: 9
Training loss: 3.1358492395499558
Validation loss: 2.552638672073508

Epoch: 5| Step: 10
Training loss: 2.7085193765759463
Validation loss: 2.5538358743711376

Epoch: 128| Step: 0
Training loss: 3.1839039282849506
Validation loss: 2.548100457323224

Epoch: 5| Step: 1
Training loss: 3.1716738482053364
Validation loss: 2.548920842035001

Epoch: 5| Step: 2
Training loss: 3.1033015912567032
Validation loss: 2.5625448360567433

Epoch: 5| Step: 3
Training loss: 2.7696956698703796
Validation loss: 2.560239926203368

Epoch: 5| Step: 4
Training loss: 2.3450967606873037
Validation loss: 2.5600823393184773

Epoch: 5| Step: 5
Training loss: 3.2544031393476742
Validation loss: 2.5571242178369937

Epoch: 5| Step: 6
Training loss: 2.708828592256092
Validation loss: 2.5487161586221743

Epoch: 5| Step: 7
Training loss: 2.558840953736628
Validation loss: 2.541555087180299

Epoch: 5| Step: 8
Training loss: 2.9964460939128514
Validation loss: 2.5404701075807563

Epoch: 5| Step: 9
Training loss: 2.677814418450589
Validation loss: 2.53824325281242

Epoch: 5| Step: 10
Training loss: 3.1111937144833215
Validation loss: 2.536066334328354

Epoch: 129| Step: 0
Training loss: 2.8945327326349948
Validation loss: 2.536625694738077

Epoch: 5| Step: 1
Training loss: 2.896750563301709
Validation loss: 2.5398696734623716

Epoch: 5| Step: 2
Training loss: 2.9340660639465055
Validation loss: 2.55083011062239

Epoch: 5| Step: 3
Training loss: 3.0533106986571443
Validation loss: 2.5594147457848133

Epoch: 5| Step: 4
Training loss: 2.96461294931902
Validation loss: 2.550854359680368

Epoch: 5| Step: 5
Training loss: 2.6079951309790532
Validation loss: 2.5698673897566566

Epoch: 5| Step: 6
Training loss: 2.641811668515895
Validation loss: 2.5779259886736074

Epoch: 5| Step: 7
Training loss: 2.4576075716428547
Validation loss: 2.6048674177543947

Epoch: 5| Step: 8
Training loss: 3.51987657959183
Validation loss: 2.6142302613293222

Epoch: 5| Step: 9
Training loss: 2.8775096388720853
Validation loss: 2.6165372199520083

Epoch: 5| Step: 10
Training loss: 2.484653673197217
Validation loss: 2.6131225569145977

Epoch: 130| Step: 0
Training loss: 2.3166913376553393
Validation loss: 2.6140690603227172

Epoch: 5| Step: 1
Training loss: 2.9704135450165805
Validation loss: 2.6013100784411787

Epoch: 5| Step: 2
Training loss: 3.1801289619831064
Validation loss: 2.597510558958873

Epoch: 5| Step: 3
Training loss: 2.7941911489899014
Validation loss: 2.6059127591394757

Epoch: 5| Step: 4
Training loss: 2.8310184746196367
Validation loss: 2.585990141617276

Epoch: 5| Step: 5
Training loss: 2.9461485791623763
Validation loss: 2.587191969521454

Epoch: 5| Step: 6
Training loss: 3.2342825613771926
Validation loss: 2.5788061977847754

Epoch: 5| Step: 7
Training loss: 2.1844297388555627
Validation loss: 2.5682261926812617

Epoch: 5| Step: 8
Training loss: 2.6778922337051085
Validation loss: 2.5557987249552325

Epoch: 5| Step: 9
Training loss: 3.3701562384545674
Validation loss: 2.554667975740065

Epoch: 5| Step: 10
Training loss: 2.9572736068842396
Validation loss: 2.5531631271478195

Epoch: 131| Step: 0
Training loss: 3.2496534309468523
Validation loss: 2.5627112412841324

Epoch: 5| Step: 1
Training loss: 2.5798136411680472
Validation loss: 2.5493983744332183

Epoch: 5| Step: 2
Training loss: 2.9714211744174484
Validation loss: 2.5350966753794273

Epoch: 5| Step: 3
Training loss: 2.225014881555746
Validation loss: 2.5332577388356747

Epoch: 5| Step: 4
Training loss: 2.694210014981735
Validation loss: 2.52731337069966

Epoch: 5| Step: 5
Training loss: 3.4797992854497517
Validation loss: 2.5198954158858986

Epoch: 5| Step: 6
Training loss: 3.1729191907612577
Validation loss: 2.520069793484075

Epoch: 5| Step: 7
Training loss: 2.582989444198631
Validation loss: 2.524319631866387

Epoch: 5| Step: 8
Training loss: 3.2256693123307305
Validation loss: 2.5372422042158713

Epoch: 5| Step: 9
Training loss: 2.7951079172718103
Validation loss: 2.544907421424567

Epoch: 5| Step: 10
Training loss: 2.273146777883846
Validation loss: 2.572531682084486

Epoch: 132| Step: 0
Training loss: 2.89475198951664
Validation loss: 2.6088511969338377

Epoch: 5| Step: 1
Training loss: 2.992859608037579
Validation loss: 2.6129116107968686

Epoch: 5| Step: 2
Training loss: 2.6280240396709424
Validation loss: 2.6097698208940936

Epoch: 5| Step: 3
Training loss: 3.3590485170204474
Validation loss: 2.6254868883531577

Epoch: 5| Step: 4
Training loss: 2.8120772997784393
Validation loss: 2.60096133998989

Epoch: 5| Step: 5
Training loss: 2.8874228396984747
Validation loss: 2.5722520765459675

Epoch: 5| Step: 6
Training loss: 3.1689406478682924
Validation loss: 2.5548501669294432

Epoch: 5| Step: 7
Training loss: 2.8025837183212676
Validation loss: 2.510267357838333

Epoch: 5| Step: 8
Training loss: 3.3184948781835963
Validation loss: 2.5157281896101615

Epoch: 5| Step: 9
Training loss: 2.1573600675924904
Validation loss: 2.4826021313692075

Epoch: 5| Step: 10
Training loss: 1.9612106193833831
Validation loss: 2.4745984992800567

Epoch: 133| Step: 0
Training loss: 3.070599646887768
Validation loss: 2.472777442286498

Epoch: 5| Step: 1
Training loss: 2.6712657389982652
Validation loss: 2.481971312629331

Epoch: 5| Step: 2
Training loss: 2.8487093094266847
Validation loss: 2.481496685090815

Epoch: 5| Step: 3
Training loss: 2.65906016977441
Validation loss: 2.476257308519571

Epoch: 5| Step: 4
Training loss: 2.728015064589445
Validation loss: 2.4963686647214933

Epoch: 5| Step: 5
Training loss: 2.7616441600606105
Validation loss: 2.501770294119044

Epoch: 5| Step: 6
Training loss: 3.014534708688506
Validation loss: 2.5640585736830954

Epoch: 5| Step: 7
Training loss: 2.589107449037199
Validation loss: 2.5866501329384324

Epoch: 5| Step: 8
Training loss: 3.0544172786989257
Validation loss: 2.598750205467687

Epoch: 5| Step: 9
Training loss: 2.9791696899683267
Validation loss: 2.5765999090093734

Epoch: 5| Step: 10
Training loss: 2.645275557790123
Validation loss: 2.5245692706603737

Epoch: 134| Step: 0
Training loss: 2.6336399668415327
Validation loss: 2.4796829540881653

Epoch: 5| Step: 1
Training loss: 2.906408818325165
Validation loss: 2.4755295791095735

Epoch: 5| Step: 2
Training loss: 3.1481877457449223
Validation loss: 2.4800680952997824

Epoch: 5| Step: 3
Training loss: 2.343492519222664
Validation loss: 2.489164143012808

Epoch: 5| Step: 4
Training loss: 3.0335657771272597
Validation loss: 2.4871032299057823

Epoch: 5| Step: 5
Training loss: 2.703507148322618
Validation loss: 2.4871523220809917

Epoch: 5| Step: 6
Training loss: 2.872545604426798
Validation loss: 2.4893943010165533

Epoch: 5| Step: 7
Training loss: 2.9562184112345076
Validation loss: 2.4828362245327806

Epoch: 5| Step: 8
Training loss: 3.094854908933314
Validation loss: 2.483077654904565

Epoch: 5| Step: 9
Training loss: 3.105966511306964
Validation loss: 2.486184092315305

Epoch: 5| Step: 10
Training loss: 2.20347700621101
Validation loss: 2.4779936808497

Epoch: 135| Step: 0
Training loss: 2.5188645064685438
Validation loss: 2.482303520682009

Epoch: 5| Step: 1
Training loss: 2.643431126187419
Validation loss: 2.4901678091148676

Epoch: 5| Step: 2
Training loss: 3.183012102972349
Validation loss: 2.4933650591834877

Epoch: 5| Step: 3
Training loss: 3.2607949781871457
Validation loss: 2.5108845449674133

Epoch: 5| Step: 4
Training loss: 2.6212176366144293
Validation loss: 2.531189507992542

Epoch: 5| Step: 5
Training loss: 2.7353746603195175
Validation loss: 2.561070847775559

Epoch: 5| Step: 6
Training loss: 2.7914616713532494
Validation loss: 2.5538133631772095

Epoch: 5| Step: 7
Training loss: 2.771796372254272
Validation loss: 2.5279852442310102

Epoch: 5| Step: 8
Training loss: 2.689517129151716
Validation loss: 2.5287241495202166

Epoch: 5| Step: 9
Training loss: 2.7007886900287583
Validation loss: 2.5275029247074663

Epoch: 5| Step: 10
Training loss: 3.0843814065203854
Validation loss: 2.5136732334781837

Epoch: 136| Step: 0
Training loss: 2.1034079464808646
Validation loss: 2.5084663249019052

Epoch: 5| Step: 1
Training loss: 2.367527499819663
Validation loss: 2.4934064515129672

Epoch: 5| Step: 2
Training loss: 3.117681554969693
Validation loss: 2.50109885072232

Epoch: 5| Step: 3
Training loss: 2.408178572208575
Validation loss: 2.480751322905817

Epoch: 5| Step: 4
Training loss: 3.196221481154239
Validation loss: 2.4824898991729727

Epoch: 5| Step: 5
Training loss: 3.039329850467271
Validation loss: 2.475176326660293

Epoch: 5| Step: 6
Training loss: 3.0187486668301435
Validation loss: 2.478041019932366

Epoch: 5| Step: 7
Training loss: 2.76503251620552
Validation loss: 2.4725606441361117

Epoch: 5| Step: 8
Training loss: 3.0257211188209983
Validation loss: 2.472835614423319

Epoch: 5| Step: 9
Training loss: 2.983736778840465
Validation loss: 2.4792056605835775

Epoch: 5| Step: 10
Training loss: 2.384436582317507
Validation loss: 2.4805696484507758

Epoch: 137| Step: 0
Training loss: 2.7659427438741635
Validation loss: 2.4850759891642373

Epoch: 5| Step: 1
Training loss: 2.545103802915462
Validation loss: 2.486094964915777

Epoch: 5| Step: 2
Training loss: 3.167381975463523
Validation loss: 2.4932678974034164

Epoch: 5| Step: 3
Training loss: 2.8938913397329973
Validation loss: 2.51021187001867

Epoch: 5| Step: 4
Training loss: 2.80517845850884
Validation loss: 2.5324351003780654

Epoch: 5| Step: 5
Training loss: 2.3935343672638063
Validation loss: 2.557079659187873

Epoch: 5| Step: 6
Training loss: 2.7478557376503128
Validation loss: 2.5708453598561523

Epoch: 5| Step: 7
Training loss: 2.8213332592970772
Validation loss: 2.5663668721777406

Epoch: 5| Step: 8
Training loss: 2.780850842582429
Validation loss: 2.55581013784066

Epoch: 5| Step: 9
Training loss: 2.849229501003675
Validation loss: 2.5432558449108926

Epoch: 5| Step: 10
Training loss: 2.8174921447590244
Validation loss: 2.527427272174453

Epoch: 138| Step: 0
Training loss: 2.280311914156106
Validation loss: 2.5152493263045903

Epoch: 5| Step: 1
Training loss: 2.8176718737111375
Validation loss: 2.4931459150474913

Epoch: 5| Step: 2
Training loss: 2.345777321435318
Validation loss: 2.479233895356539

Epoch: 5| Step: 3
Training loss: 3.0890056568216213
Validation loss: 2.4723685067566565

Epoch: 5| Step: 4
Training loss: 2.578974635833344
Validation loss: 2.4762588122756144

Epoch: 5| Step: 5
Training loss: 3.1789329439562595
Validation loss: 2.480297712340193

Epoch: 5| Step: 6
Training loss: 2.3315558020752833
Validation loss: 2.4847728482665996

Epoch: 5| Step: 7
Training loss: 2.565370208317914
Validation loss: 2.506882357649229

Epoch: 5| Step: 8
Training loss: 3.0904433950175525
Validation loss: 2.5154612110879886

Epoch: 5| Step: 9
Training loss: 2.6242773787095173
Validation loss: 2.524968654389676

Epoch: 5| Step: 10
Training loss: 3.590221364414123
Validation loss: 2.517878971848243

Epoch: 139| Step: 0
Training loss: 2.771874043530081
Validation loss: 2.510913990750792

Epoch: 5| Step: 1
Training loss: 2.414904500048449
Validation loss: 2.493107825892974

Epoch: 5| Step: 2
Training loss: 3.0028664881560947
Validation loss: 2.4836872273852815

Epoch: 5| Step: 3
Training loss: 2.6898974880553235
Validation loss: 2.501492370711634

Epoch: 5| Step: 4
Training loss: 2.860722458829272
Validation loss: 2.5131232111001345

Epoch: 5| Step: 5
Training loss: 2.6628648857136277
Validation loss: 2.5185336545131416

Epoch: 5| Step: 6
Training loss: 3.1549900675041442
Validation loss: 2.5270658361384126

Epoch: 5| Step: 7
Training loss: 2.7911196689953717
Validation loss: 2.5189367186985385

Epoch: 5| Step: 8
Training loss: 2.7741322681436813
Validation loss: 2.5275567164041486

Epoch: 5| Step: 9
Training loss: 2.49925907599734
Validation loss: 2.522969869953295

Epoch: 5| Step: 10
Training loss: 2.7731902536139237
Validation loss: 2.514792683031758

Epoch: 140| Step: 0
Training loss: 3.0913821319958084
Validation loss: 2.4953701422375234

Epoch: 5| Step: 1
Training loss: 2.566265595876924
Validation loss: 2.4970507237623742

Epoch: 5| Step: 2
Training loss: 2.679126558453508
Validation loss: 2.500649880468675

Epoch: 5| Step: 3
Training loss: 2.528443369959381
Validation loss: 2.4969377682841922

Epoch: 5| Step: 4
Training loss: 2.359358326429857
Validation loss: 2.5038315319348126

Epoch: 5| Step: 5
Training loss: 2.881833786480475
Validation loss: 2.5057610387373703

Epoch: 5| Step: 6
Training loss: 3.066198645689261
Validation loss: 2.5038261785357436

Epoch: 5| Step: 7
Training loss: 2.936428442770523
Validation loss: 2.530957519940217

Epoch: 5| Step: 8
Training loss: 2.778065690908282
Validation loss: 2.5402730580477217

Epoch: 5| Step: 9
Training loss: 2.795407469635718
Validation loss: 2.5640889925435855

Epoch: 5| Step: 10
Training loss: 2.7448383788176085
Validation loss: 2.5533212354553303

Epoch: 141| Step: 0
Training loss: 2.8440008367223353
Validation loss: 2.5295582086307813

Epoch: 5| Step: 1
Training loss: 2.6337629917369303
Validation loss: 2.5134659550771645

Epoch: 5| Step: 2
Training loss: 2.7243871892213143
Validation loss: 2.5001602921320303

Epoch: 5| Step: 3
Training loss: 2.617042924673988
Validation loss: 2.487852923361268

Epoch: 5| Step: 4
Training loss: 3.168933124254296
Validation loss: 2.4872016905543917

Epoch: 5| Step: 5
Training loss: 2.298661866897003
Validation loss: 2.4822473829756633

Epoch: 5| Step: 6
Training loss: 2.658574781145597
Validation loss: 2.4829883148155756

Epoch: 5| Step: 7
Training loss: 2.8844702278196985
Validation loss: 2.484729430186004

Epoch: 5| Step: 8
Training loss: 2.398947298126967
Validation loss: 2.4818473015364524

Epoch: 5| Step: 9
Training loss: 2.9198652076963625
Validation loss: 2.488300663598061

Epoch: 5| Step: 10
Training loss: 3.552373447298274
Validation loss: 2.507837298923637

Epoch: 142| Step: 0
Training loss: 2.698039303696214
Validation loss: 2.538157523074715

Epoch: 5| Step: 1
Training loss: 2.7029756714251354
Validation loss: 2.5539124962700677

Epoch: 5| Step: 2
Training loss: 2.824123016887572
Validation loss: 2.5979792183569805

Epoch: 5| Step: 3
Training loss: 2.580219042594984
Validation loss: 2.614317124737869

Epoch: 5| Step: 4
Training loss: 2.126833293190876
Validation loss: 2.6245137031320644

Epoch: 5| Step: 5
Training loss: 3.336452185348927
Validation loss: 2.604739076442427

Epoch: 5| Step: 6
Training loss: 2.676759950177001
Validation loss: 2.528069914435153

Epoch: 5| Step: 7
Training loss: 3.2057106560865525
Validation loss: 2.4961976453322836

Epoch: 5| Step: 8
Training loss: 2.9303270786244537
Validation loss: 2.4774039594131745

Epoch: 5| Step: 9
Training loss: 2.4015650533887185
Validation loss: 2.4812930460174396

Epoch: 5| Step: 10
Training loss: 2.912974627545715
Validation loss: 2.4707057148877154

Epoch: 143| Step: 0
Training loss: 3.0367213942798656
Validation loss: 2.4823690065275166

Epoch: 5| Step: 1
Training loss: 2.936940728373656
Validation loss: 2.48762618126326

Epoch: 5| Step: 2
Training loss: 2.5426929048859064
Validation loss: 2.4930442005964175

Epoch: 5| Step: 3
Training loss: 2.9090133163551255
Validation loss: 2.4839773460294294

Epoch: 5| Step: 4
Training loss: 2.654212259792298
Validation loss: 2.487417306410284

Epoch: 5| Step: 5
Training loss: 2.780757817641579
Validation loss: 2.48093734680347

Epoch: 5| Step: 6
Training loss: 2.8812181979925366
Validation loss: 2.4748701842333234

Epoch: 5| Step: 7
Training loss: 2.8098624683811555
Validation loss: 2.4818338673825853

Epoch: 5| Step: 8
Training loss: 2.7457160527175564
Validation loss: 2.4980336608668066

Epoch: 5| Step: 9
Training loss: 2.9280387613305265
Validation loss: 2.5393174253455375

Epoch: 5| Step: 10
Training loss: 2.554466494645335
Validation loss: 2.5712629004190872

Epoch: 144| Step: 0
Training loss: 3.1799724179397253
Validation loss: 2.577661184563226

Epoch: 5| Step: 1
Training loss: 2.24384291942598
Validation loss: 2.5541530206948075

Epoch: 5| Step: 2
Training loss: 3.0087429440538043
Validation loss: 2.479706781821291

Epoch: 5| Step: 3
Training loss: 2.663116376567882
Validation loss: 2.46079818609921

Epoch: 5| Step: 4
Training loss: 2.8526642643590865
Validation loss: 2.4515368967817226

Epoch: 5| Step: 5
Training loss: 2.771843164512741
Validation loss: 2.451653137144046

Epoch: 5| Step: 6
Training loss: 2.583149124058703
Validation loss: 2.4578844849161867

Epoch: 5| Step: 7
Training loss: 2.3539971709773226
Validation loss: 2.447575482059627

Epoch: 5| Step: 8
Training loss: 2.986264254957932
Validation loss: 2.451011532651433

Epoch: 5| Step: 9
Training loss: 2.759090743322683
Validation loss: 2.477816371095086

Epoch: 5| Step: 10
Training loss: 3.1427609596149346
Validation loss: 2.521978610520463

Epoch: 145| Step: 0
Training loss: 3.235609325822663
Validation loss: 2.5613273760843374

Epoch: 5| Step: 1
Training loss: 2.713203911924403
Validation loss: 2.559109322132732

Epoch: 5| Step: 2
Training loss: 2.303165566903638
Validation loss: 2.5707495293821077

Epoch: 5| Step: 3
Training loss: 2.384450180848304
Validation loss: 2.5435251380518076

Epoch: 5| Step: 4
Training loss: 3.0672205141518734
Validation loss: 2.499818519445112

Epoch: 5| Step: 5
Training loss: 2.7837412103206716
Validation loss: 2.4762017532818903

Epoch: 5| Step: 6
Training loss: 2.606718527122707
Validation loss: 2.4649096216993596

Epoch: 5| Step: 7
Training loss: 2.791228321638713
Validation loss: 2.4546066438277916

Epoch: 5| Step: 8
Training loss: 2.9206631845353206
Validation loss: 2.449412436406633

Epoch: 5| Step: 9
Training loss: 2.8134983410136347
Validation loss: 2.4469906876315073

Epoch: 5| Step: 10
Training loss: 2.735803547035794
Validation loss: 2.4496871051129463

Epoch: 146| Step: 0
Training loss: 2.2583708287278306
Validation loss: 2.4613741220258274

Epoch: 5| Step: 1
Training loss: 3.0492861866121665
Validation loss: 2.4593871739363444

Epoch: 5| Step: 2
Training loss: 2.6397326163510644
Validation loss: 2.4591445206721834

Epoch: 5| Step: 3
Training loss: 2.2106651974194977
Validation loss: 2.4630339423044525

Epoch: 5| Step: 4
Training loss: 2.5476232260418095
Validation loss: 2.4733533702262394

Epoch: 5| Step: 5
Training loss: 2.8668583569273323
Validation loss: 2.4786432568032333

Epoch: 5| Step: 6
Training loss: 2.8654497165797674
Validation loss: 2.5180858737528418

Epoch: 5| Step: 7
Training loss: 2.974476160684593
Validation loss: 2.5365945311553917

Epoch: 5| Step: 8
Training loss: 3.181880560176789
Validation loss: 2.5385753674816547

Epoch: 5| Step: 9
Training loss: 2.288588855681138
Validation loss: 2.5431646239443646

Epoch: 5| Step: 10
Training loss: 3.0207989043981374
Validation loss: 2.5685931181071786

Epoch: 147| Step: 0
Training loss: 2.516076562762715
Validation loss: 2.5694071064055812

Epoch: 5| Step: 1
Training loss: 2.5231277700904604
Validation loss: 2.5622582950645048

Epoch: 5| Step: 2
Training loss: 2.3628044214855985
Validation loss: 2.5732295966254317

Epoch: 5| Step: 3
Training loss: 2.8793615346088206
Validation loss: 2.566618170624325

Epoch: 5| Step: 4
Training loss: 2.78795099416213
Validation loss: 2.5316412757629045

Epoch: 5| Step: 5
Training loss: 2.5181199490289883
Validation loss: 2.5286977903762438

Epoch: 5| Step: 6
Training loss: 3.0989796528229805
Validation loss: 2.539547832035312

Epoch: 5| Step: 7
Training loss: 2.2180417501993603
Validation loss: 2.5436060194080574

Epoch: 5| Step: 8
Training loss: 3.4907491226462923
Validation loss: 2.5460796612908583

Epoch: 5| Step: 9
Training loss: 2.415779367427291
Validation loss: 2.5167361626839044

Epoch: 5| Step: 10
Training loss: 3.156686431624164
Validation loss: 2.503221288986996

Epoch: 148| Step: 0
Training loss: 2.527349221460944
Validation loss: 2.4725308172863003

Epoch: 5| Step: 1
Training loss: 2.4532837057104393
Validation loss: 2.469036992687912

Epoch: 5| Step: 2
Training loss: 3.105741899101638
Validation loss: 2.4702258098603833

Epoch: 5| Step: 3
Training loss: 2.76692608762237
Validation loss: 2.465150420023582

Epoch: 5| Step: 4
Training loss: 2.583035687763104
Validation loss: 2.466417353138493

Epoch: 5| Step: 5
Training loss: 2.6130340869839395
Validation loss: 2.463115316433265

Epoch: 5| Step: 6
Training loss: 3.1860487382971994
Validation loss: 2.4741444191411683

Epoch: 5| Step: 7
Training loss: 2.5207867473574743
Validation loss: 2.5008638878738623

Epoch: 5| Step: 8
Training loss: 2.8251372514989654
Validation loss: 2.5267844553087904

Epoch: 5| Step: 9
Training loss: 2.8903255823074194
Validation loss: 2.572651643236573

Epoch: 5| Step: 10
Training loss: 2.416751290078419
Validation loss: 2.5777274662120893

Epoch: 149| Step: 0
Training loss: 2.9402002139265333
Validation loss: 2.6159817568598944

Epoch: 5| Step: 1
Training loss: 2.7799894069222812
Validation loss: 2.584496470128958

Epoch: 5| Step: 2
Training loss: 3.0507524906614996
Validation loss: 2.546851406595856

Epoch: 5| Step: 3
Training loss: 2.1851735414073854
Validation loss: 2.523969745448094

Epoch: 5| Step: 4
Training loss: 2.773424433287881
Validation loss: 2.504714449137089

Epoch: 5| Step: 5
Training loss: 2.1883340607889115
Validation loss: 2.483597027700532

Epoch: 5| Step: 6
Training loss: 2.655985920064443
Validation loss: 2.4763854884084338

Epoch: 5| Step: 7
Training loss: 2.757750772536433
Validation loss: 2.473010941575218

Epoch: 5| Step: 8
Training loss: 3.0194421831543834
Validation loss: 2.470869401489599

Epoch: 5| Step: 9
Training loss: 3.0234874947921564
Validation loss: 2.4814312599079535

Epoch: 5| Step: 10
Training loss: 2.2269851015823336
Validation loss: 2.486463934038294

Epoch: 150| Step: 0
Training loss: 3.067713134623701
Validation loss: 2.5023089534142566

Epoch: 5| Step: 1
Training loss: 2.4343998096068598
Validation loss: 2.51560775698953

Epoch: 5| Step: 2
Training loss: 2.9853854241414575
Validation loss: 2.540252412783061

Epoch: 5| Step: 3
Training loss: 2.737892547750431
Validation loss: 2.6014604465627658

Epoch: 5| Step: 4
Training loss: 2.692410529446787
Validation loss: 2.582548038660195

Epoch: 5| Step: 5
Training loss: 2.6805725415558546
Validation loss: 2.552931610493589

Epoch: 5| Step: 6
Training loss: 2.9979748248162346
Validation loss: 2.5188900769508926

Epoch: 5| Step: 7
Training loss: 2.785677867693275
Validation loss: 2.505151599931271

Epoch: 5| Step: 8
Training loss: 2.3282192134355704
Validation loss: 2.502075836811675

Epoch: 5| Step: 9
Training loss: 2.6077055016035193
Validation loss: 2.4930401479944004

Epoch: 5| Step: 10
Training loss: 2.265451990296178
Validation loss: 2.507929789518583

Epoch: 151| Step: 0
Training loss: 2.2277876846059375
Validation loss: 2.5036238165717135

Epoch: 5| Step: 1
Training loss: 2.449394158952504
Validation loss: 2.5246644149487705

Epoch: 5| Step: 2
Training loss: 2.658720236657848
Validation loss: 2.5540080581134994

Epoch: 5| Step: 3
Training loss: 2.8212846681343415
Validation loss: 2.5830222742073743

Epoch: 5| Step: 4
Training loss: 2.7859494228824633
Validation loss: 2.635478295785883

Epoch: 5| Step: 5
Training loss: 2.5648938604334695
Validation loss: 2.5855120053629586

Epoch: 5| Step: 6
Training loss: 2.3843889868489767
Validation loss: 2.567662622787524

Epoch: 5| Step: 7
Training loss: 3.0171727769315653
Validation loss: 2.53137380220501

Epoch: 5| Step: 8
Training loss: 3.064812546142613
Validation loss: 2.5032400741427963

Epoch: 5| Step: 9
Training loss: 2.865960547250858
Validation loss: 2.4753417206236943

Epoch: 5| Step: 10
Training loss: 2.761814315415809
Validation loss: 2.473183912602981

Epoch: 152| Step: 0
Training loss: 2.621089201921818
Validation loss: 2.4655126922390065

Epoch: 5| Step: 1
Training loss: 2.764863248757934
Validation loss: 2.4647027170304745

Epoch: 5| Step: 2
Training loss: 2.5686048963267663
Validation loss: 2.4619285659638455

Epoch: 5| Step: 3
Training loss: 2.795139562844984
Validation loss: 2.4612340000739357

Epoch: 5| Step: 4
Training loss: 2.4196058902922926
Validation loss: 2.4743112222811505

Epoch: 5| Step: 5
Training loss: 2.7208792580841865
Validation loss: 2.481438601317608

Epoch: 5| Step: 6
Training loss: 2.8164277519008447
Validation loss: 2.5219861215724477

Epoch: 5| Step: 7
Training loss: 2.7457144897243104
Validation loss: 2.5248699607165963

Epoch: 5| Step: 8
Training loss: 2.7432508010160848
Validation loss: 2.553461872703638

Epoch: 5| Step: 9
Training loss: 2.5367334570427533
Validation loss: 2.5731248921207044

Epoch: 5| Step: 10
Training loss: 2.884456837527404
Validation loss: 2.5808341679397593

Epoch: 153| Step: 0
Training loss: 2.546497246747314
Validation loss: 2.6353873593692834

Epoch: 5| Step: 1
Training loss: 2.256058166464236
Validation loss: 2.665521679363326

Epoch: 5| Step: 2
Training loss: 2.7817510089311908
Validation loss: 2.709370981476426

Epoch: 5| Step: 3
Training loss: 2.013690582099696
Validation loss: 2.7036817409910205

Epoch: 5| Step: 4
Training loss: 2.595063761550701
Validation loss: 2.6736504562019285

Epoch: 5| Step: 5
Training loss: 2.4460789268529424
Validation loss: 2.6422893727572063

Epoch: 5| Step: 6
Training loss: 2.918076601295002
Validation loss: 2.6038304173773934

Epoch: 5| Step: 7
Training loss: 3.0480619808313048
Validation loss: 2.60477664686516

Epoch: 5| Step: 8
Training loss: 2.4873463837236844
Validation loss: 2.575589905647318

Epoch: 5| Step: 9
Training loss: 3.25612269059326
Validation loss: 2.562197224407193

Epoch: 5| Step: 10
Training loss: 3.142321228186393
Validation loss: 2.5425973694776878

Epoch: 154| Step: 0
Training loss: 2.7632443801710913
Validation loss: 2.529364915601639

Epoch: 5| Step: 1
Training loss: 2.4688060126408793
Validation loss: 2.5171025641973417

Epoch: 5| Step: 2
Training loss: 2.4083602371385044
Validation loss: 2.4956652387594014

Epoch: 5| Step: 3
Training loss: 2.942826980404502
Validation loss: 2.488514185667756

Epoch: 5| Step: 4
Training loss: 2.6710353669767506
Validation loss: 2.494465507954766

Epoch: 5| Step: 5
Training loss: 2.6807743459782616
Validation loss: 2.500944208453191

Epoch: 5| Step: 6
Training loss: 2.748159746510397
Validation loss: 2.519479430889102

Epoch: 5| Step: 7
Training loss: 2.975504048707054
Validation loss: 2.517117722319715

Epoch: 5| Step: 8
Training loss: 2.3357915418054795
Validation loss: 2.5601919801538338

Epoch: 5| Step: 9
Training loss: 2.6002664172785095
Validation loss: 2.5719672823698736

Epoch: 5| Step: 10
Training loss: 3.034219290355483
Validation loss: 2.591440905864008

Epoch: 155| Step: 0
Training loss: 2.438056099863484
Validation loss: 2.5640678721503476

Epoch: 5| Step: 1
Training loss: 2.601553152256573
Validation loss: 2.569756734136823

Epoch: 5| Step: 2
Training loss: 2.2849750153492407
Validation loss: 2.5744240904987894

Epoch: 5| Step: 3
Training loss: 2.8027173616643903
Validation loss: 2.565879430194899

Epoch: 5| Step: 4
Training loss: 2.84870529213372
Validation loss: 2.4994070303548903

Epoch: 5| Step: 5
Training loss: 2.762977324109353
Validation loss: 2.469182095163002

Epoch: 5| Step: 6
Training loss: 2.943862841603831
Validation loss: 2.444776619749022

Epoch: 5| Step: 7
Training loss: 2.8496165703623175
Validation loss: 2.4462998796354483

Epoch: 5| Step: 8
Training loss: 2.7792216416106545
Validation loss: 2.4653245280103064

Epoch: 5| Step: 9
Training loss: 2.3336254913347543
Validation loss: 2.4922470181847123

Epoch: 5| Step: 10
Training loss: 2.757701320406327
Validation loss: 2.522763247676568

Epoch: 156| Step: 0
Training loss: 2.609685182694859
Validation loss: 2.58416913914825

Epoch: 5| Step: 1
Training loss: 2.560423032557678
Validation loss: 2.658984099023751

Epoch: 5| Step: 2
Training loss: 2.7873981542755932
Validation loss: 2.725708566111811

Epoch: 5| Step: 3
Training loss: 2.7415333372430633
Validation loss: 2.777597560027003

Epoch: 5| Step: 4
Training loss: 3.268566504264194
Validation loss: 2.7901378394744363

Epoch: 5| Step: 5
Training loss: 2.375623320047276
Validation loss: 2.665385457312865

Epoch: 5| Step: 6
Training loss: 2.7188426034875692
Validation loss: 2.5627554779395445

Epoch: 5| Step: 7
Training loss: 2.2140964545834434
Validation loss: 2.5164106157948725

Epoch: 5| Step: 8
Training loss: 2.9227600389216333
Validation loss: 2.4989390562612632

Epoch: 5| Step: 9
Training loss: 2.7170592564595997
Validation loss: 2.4945882941746444

Epoch: 5| Step: 10
Training loss: 3.1504552542483437
Validation loss: 2.5068995747736755

Epoch: 157| Step: 0
Training loss: 2.8779379718662574
Validation loss: 2.5041500552167024

Epoch: 5| Step: 1
Training loss: 3.0156245256334633
Validation loss: 2.5043659480282865

Epoch: 5| Step: 2
Training loss: 2.7609702556849647
Validation loss: 2.4925899987452746

Epoch: 5| Step: 3
Training loss: 3.1840679166633374
Validation loss: 2.492084904429616

Epoch: 5| Step: 4
Training loss: 2.5122012895494397
Validation loss: 2.5005282469477215

Epoch: 5| Step: 5
Training loss: 2.6288960925695304
Validation loss: 2.5047110203222753

Epoch: 5| Step: 6
Training loss: 2.723370976820175
Validation loss: 2.513782833323861

Epoch: 5| Step: 7
Training loss: 2.6065553518301776
Validation loss: 2.5370001988047313

Epoch: 5| Step: 8
Training loss: 2.38553871164632
Validation loss: 2.553014586765241

Epoch: 5| Step: 9
Training loss: 2.359284253933157
Validation loss: 2.6127408548922206

Epoch: 5| Step: 10
Training loss: 2.35890465905062
Validation loss: 2.661209228357744

Epoch: 158| Step: 0
Training loss: 3.068546165642406
Validation loss: 2.7187228957595413

Epoch: 5| Step: 1
Training loss: 2.607331715142998
Validation loss: 2.730974218935478

Epoch: 5| Step: 2
Training loss: 2.623601086567466
Validation loss: 2.722404512244474

Epoch: 5| Step: 3
Training loss: 2.759457192325486
Validation loss: 2.675436722422816

Epoch: 5| Step: 4
Training loss: 2.666529701609688
Validation loss: 2.601704918364315

Epoch: 5| Step: 5
Training loss: 2.498678907382068
Validation loss: 2.532179285749146

Epoch: 5| Step: 6
Training loss: 2.58888265920971
Validation loss: 2.4911753765618405

Epoch: 5| Step: 7
Training loss: 2.7496006415567544
Validation loss: 2.460047379981277

Epoch: 5| Step: 8
Training loss: 2.4240575984557595
Validation loss: 2.4585628670025583

Epoch: 5| Step: 9
Training loss: 2.9682446501426707
Validation loss: 2.471305624094825

Epoch: 5| Step: 10
Training loss: 2.3460016243320054
Validation loss: 2.4877232825732265

Epoch: 159| Step: 0
Training loss: 2.6830182520373174
Validation loss: 2.5045866852554215

Epoch: 5| Step: 1
Training loss: 2.246297651240808
Validation loss: 2.5328419251122014

Epoch: 5| Step: 2
Training loss: 3.0317410730001035
Validation loss: 2.545147918017523

Epoch: 5| Step: 3
Training loss: 2.4290490001449085
Validation loss: 2.5643445561096025

Epoch: 5| Step: 4
Training loss: 2.900907466576394
Validation loss: 2.5854230864213945

Epoch: 5| Step: 5
Training loss: 2.6358095763256775
Validation loss: 2.580727434545265

Epoch: 5| Step: 6
Training loss: 2.918655988661796
Validation loss: 2.5778177843362213

Epoch: 5| Step: 7
Training loss: 2.343409195599441
Validation loss: 2.541971984820567

Epoch: 5| Step: 8
Training loss: 2.9950119512507403
Validation loss: 2.5360994189704735

Epoch: 5| Step: 9
Training loss: 2.1790377834662897
Validation loss: 2.506949234409472

Epoch: 5| Step: 10
Training loss: 2.770008126808116
Validation loss: 2.4952723583596454

Epoch: 160| Step: 0
Training loss: 2.7672300691954357
Validation loss: 2.4897214415550253

Epoch: 5| Step: 1
Training loss: 2.5641982801007472
Validation loss: 2.4608065548026343

Epoch: 5| Step: 2
Training loss: 2.5229172303135874
Validation loss: 2.4478095840006473

Epoch: 5| Step: 3
Training loss: 3.078522787193483
Validation loss: 2.4395466308937808

Epoch: 5| Step: 4
Training loss: 2.8630557524395415
Validation loss: 2.455088345799922

Epoch: 5| Step: 5
Training loss: 2.707038295896314
Validation loss: 2.469772099247245

Epoch: 5| Step: 6
Training loss: 1.6324030896758397
Validation loss: 2.4767047611803

Epoch: 5| Step: 7
Training loss: 2.7015792749081564
Validation loss: 2.5200070259379133

Epoch: 5| Step: 8
Training loss: 2.8071770205233664
Validation loss: 2.546578746450662

Epoch: 5| Step: 9
Training loss: 3.0091937968206253
Validation loss: 2.589429484757156

Epoch: 5| Step: 10
Training loss: 2.1461457947821105
Validation loss: 2.5904080600472796

Epoch: 161| Step: 0
Training loss: 2.5996614675941463
Validation loss: 2.5933626303011903

Epoch: 5| Step: 1
Training loss: 2.7642228187314166
Validation loss: 2.593107975041476

Epoch: 5| Step: 2
Training loss: 2.802405488924297
Validation loss: 2.5753498443464946

Epoch: 5| Step: 3
Training loss: 2.676701163437407
Validation loss: 2.5516586579878404

Epoch: 5| Step: 4
Training loss: 2.0914490995695036
Validation loss: 2.5513407172769607

Epoch: 5| Step: 5
Training loss: 2.3435447094337127
Validation loss: 2.570114759991491

Epoch: 5| Step: 6
Training loss: 2.5388336548012966
Validation loss: 2.5771534769422657

Epoch: 5| Step: 7
Training loss: 2.875945889320726
Validation loss: 2.5854515722281635

Epoch: 5| Step: 8
Training loss: 2.4702726087057725
Validation loss: 2.5306835799218312

Epoch: 5| Step: 9
Training loss: 2.95512863085764
Validation loss: 2.498595326100076

Epoch: 5| Step: 10
Training loss: 2.5499659779092885
Validation loss: 2.4788819195454863

Epoch: 162| Step: 0
Training loss: 2.4218532438223908
Validation loss: 2.4678254956843317

Epoch: 5| Step: 1
Training loss: 2.5517483757419748
Validation loss: 2.4708466521515295

Epoch: 5| Step: 2
Training loss: 2.129455159668448
Validation loss: 2.4700323014299648

Epoch: 5| Step: 3
Training loss: 2.6155880723759752
Validation loss: 2.468629660943851

Epoch: 5| Step: 4
Training loss: 2.903563211175032
Validation loss: 2.482187581640311

Epoch: 5| Step: 5
Training loss: 2.6276192993897793
Validation loss: 2.4760644402257506

Epoch: 5| Step: 6
Training loss: 2.4307532227080992
Validation loss: 2.472764312907912

Epoch: 5| Step: 7
Training loss: 2.675681720748163
Validation loss: 2.489672163205238

Epoch: 5| Step: 8
Training loss: 2.4987250891966117
Validation loss: 2.528583822441222

Epoch: 5| Step: 9
Training loss: 2.655168919191568
Validation loss: 2.56144585825689

Epoch: 5| Step: 10
Training loss: 2.9659257806609323
Validation loss: 2.6115204139313963

Epoch: 163| Step: 0
Training loss: 2.616684048183888
Validation loss: 2.613606093370533

Epoch: 5| Step: 1
Training loss: 2.2739345361149104
Validation loss: 2.5590823212656826

Epoch: 5| Step: 2
Training loss: 2.799764068064041
Validation loss: 2.526838656965949

Epoch: 5| Step: 3
Training loss: 2.7325624398429365
Validation loss: 2.483724655396196

Epoch: 5| Step: 4
Training loss: 2.290919881577833
Validation loss: 2.4822939871934757

Epoch: 5| Step: 5
Training loss: 3.401143016541605
Validation loss: 2.4756240544389563

Epoch: 5| Step: 6
Training loss: 3.1771169858724035
Validation loss: 2.478249025781171

Epoch: 5| Step: 7
Training loss: 2.4269957519795855
Validation loss: 2.491279743530873

Epoch: 5| Step: 8
Training loss: 2.584887519027269
Validation loss: 2.4999411001752896

Epoch: 5| Step: 9
Training loss: 2.2879072275026657
Validation loss: 2.5247413068184996

Epoch: 5| Step: 10
Training loss: 1.618663906326538
Validation loss: 2.527113564624109

Epoch: 164| Step: 0
Training loss: 2.6721929171412153
Validation loss: 2.546919069828016

Epoch: 5| Step: 1
Training loss: 2.6396089664490185
Validation loss: 2.5775870986684457

Epoch: 5| Step: 2
Training loss: 2.517007578144631
Validation loss: 2.5777455060224956

Epoch: 5| Step: 3
Training loss: 2.481993583511063
Validation loss: 2.5888969365925143

Epoch: 5| Step: 4
Training loss: 2.5339060847003667
Validation loss: 2.5897745374906433

Epoch: 5| Step: 5
Training loss: 2.701088728214604
Validation loss: 2.6099225612416324

Epoch: 5| Step: 6
Training loss: 2.338137811963695
Validation loss: 2.6125251059531114

Epoch: 5| Step: 7
Training loss: 2.400800901134542
Validation loss: 2.6355476630560983

Epoch: 5| Step: 8
Training loss: 2.1217978417099976
Validation loss: 2.6226531660318226

Epoch: 5| Step: 9
Training loss: 2.6609253072767305
Validation loss: 2.622236532674323

Epoch: 5| Step: 10
Training loss: 3.2241525586383952
Validation loss: 2.583505579763051

Epoch: 165| Step: 0
Training loss: 2.6996562950926366
Validation loss: 2.534702561967562

Epoch: 5| Step: 1
Training loss: 2.4634004408591688
Validation loss: 2.5025239386345843

Epoch: 5| Step: 2
Training loss: 2.878999830197604
Validation loss: 2.4872933601886014

Epoch: 5| Step: 3
Training loss: 2.263773615528028
Validation loss: 2.4691873155035813

Epoch: 5| Step: 4
Training loss: 2.5060949415533127
Validation loss: 2.4649051213789184

Epoch: 5| Step: 5
Training loss: 2.074320127951589
Validation loss: 2.458855471493263

Epoch: 5| Step: 6
Training loss: 2.113929522181323
Validation loss: 2.4595652222995885

Epoch: 5| Step: 7
Training loss: 2.9672481552762373
Validation loss: 2.488976241384142

Epoch: 5| Step: 8
Training loss: 2.6222170655510553
Validation loss: 2.526887643720308

Epoch: 5| Step: 9
Training loss: 2.3560227585553086
Validation loss: 2.543468617946153

Epoch: 5| Step: 10
Training loss: 2.9050644948500337
Validation loss: 2.5607588690658782

Epoch: 166| Step: 0
Training loss: 2.2106071737626007
Validation loss: 2.594810173297443

Epoch: 5| Step: 1
Training loss: 2.4226350637602527
Validation loss: 2.5798201113420864

Epoch: 5| Step: 2
Training loss: 2.531024122167671
Validation loss: 2.5512983285525235

Epoch: 5| Step: 3
Training loss: 2.8981857807432134
Validation loss: 2.534104373396087

Epoch: 5| Step: 4
Training loss: 3.0367083612867387
Validation loss: 2.5059985561922713

Epoch: 5| Step: 5
Training loss: 2.931918096150399
Validation loss: 2.504934402405025

Epoch: 5| Step: 6
Training loss: 2.6814737399990407
Validation loss: 2.5005008923797356

Epoch: 5| Step: 7
Training loss: 2.1623552659832943
Validation loss: 2.5185806947494647

Epoch: 5| Step: 8
Training loss: 2.5051983194025484
Validation loss: 2.54644183661394

Epoch: 5| Step: 9
Training loss: 1.8610973555339636
Validation loss: 2.5612261777723133

Epoch: 5| Step: 10
Training loss: 2.218684773090799
Validation loss: 2.567683669681548

Epoch: 167| Step: 0
Training loss: 2.752089400264301
Validation loss: 2.60023630924402

Epoch: 5| Step: 1
Training loss: 2.0865751856209314
Validation loss: 2.582680376226378

Epoch: 5| Step: 2
Training loss: 2.370151288479185
Validation loss: 2.571006684402002

Epoch: 5| Step: 3
Training loss: 2.537677093489783
Validation loss: 2.555912677993156

Epoch: 5| Step: 4
Training loss: 2.7081757915354916
Validation loss: 2.5629880086806263

Epoch: 5| Step: 5
Training loss: 2.3732646826484083
Validation loss: 2.5540175688312585

Epoch: 5| Step: 6
Training loss: 2.1765396193638757
Validation loss: 2.5542097369650736

Epoch: 5| Step: 7
Training loss: 2.505440704502762
Validation loss: 2.5551732714617317

Epoch: 5| Step: 8
Training loss: 2.873434386840262
Validation loss: 2.5388569440531588

Epoch: 5| Step: 9
Training loss: 2.7315994562892287
Validation loss: 2.52479829083048

Epoch: 5| Step: 10
Training loss: 2.4309869462121365
Validation loss: 2.5007384019867387

Epoch: 168| Step: 0
Training loss: 2.6994142144144284
Validation loss: 2.4854513070836326

Epoch: 5| Step: 1
Training loss: 2.8804332974111655
Validation loss: 2.476292073262294

Epoch: 5| Step: 2
Training loss: 3.090182935614253
Validation loss: 2.469972500159145

Epoch: 5| Step: 3
Training loss: 2.3075609817795386
Validation loss: 2.488200002402358

Epoch: 5| Step: 4
Training loss: 2.276915940265614
Validation loss: 2.486170091256143

Epoch: 5| Step: 5
Training loss: 2.4897375231975207
Validation loss: 2.502698436695876

Epoch: 5| Step: 6
Training loss: 1.853096563883354
Validation loss: 2.5186858671595598

Epoch: 5| Step: 7
Training loss: 2.5591535348989023
Validation loss: 2.5192036952457793

Epoch: 5| Step: 8
Training loss: 2.4959657543718565
Validation loss: 2.5206478924953295

Epoch: 5| Step: 9
Training loss: 2.3092513075805545
Validation loss: 2.5292519021273407

Epoch: 5| Step: 10
Training loss: 2.3164705778971033
Validation loss: 2.52410008405103

Epoch: 169| Step: 0
Training loss: 2.6921115609925668
Validation loss: 2.515782759905665

Epoch: 5| Step: 1
Training loss: 2.616075330682055
Validation loss: 2.5163631651716436

Epoch: 5| Step: 2
Training loss: 2.8654234238075666
Validation loss: 2.5235335098329976

Epoch: 5| Step: 3
Training loss: 2.0128978643984894
Validation loss: 2.5376928126389395

Epoch: 5| Step: 4
Training loss: 1.9579835809364063
Validation loss: 2.5357965715901445

Epoch: 5| Step: 5
Training loss: 2.676439814030011
Validation loss: 2.566766739764035

Epoch: 5| Step: 6
Training loss: 2.5100572468585898
Validation loss: 2.592103476290852

Epoch: 5| Step: 7
Training loss: 2.6234637715226685
Validation loss: 2.5742887551882183

Epoch: 5| Step: 8
Training loss: 2.432043570717968
Validation loss: 2.5734527940686225

Epoch: 5| Step: 9
Training loss: 2.6975248683175566
Validation loss: 2.522641186498707

Epoch: 5| Step: 10
Training loss: 1.7227253110713867
Validation loss: 2.5151974444572818

Epoch: 170| Step: 0
Training loss: 2.4851338888899384
Validation loss: 2.5069851534584084

Epoch: 5| Step: 1
Training loss: 2.3354779560124346
Validation loss: 2.4996481894014884

Epoch: 5| Step: 2
Training loss: 2.448124545313754
Validation loss: 2.507141093940951

Epoch: 5| Step: 3
Training loss: 2.727445617888881
Validation loss: 2.5022245743695657

Epoch: 5| Step: 4
Training loss: 2.5941056157113356
Validation loss: 2.514593169714777

Epoch: 5| Step: 5
Training loss: 2.5559644395029086
Validation loss: 2.529149765023317

Epoch: 5| Step: 6
Training loss: 2.346083128273439
Validation loss: 2.5605644541539707

Epoch: 5| Step: 7
Training loss: 2.184766096431873
Validation loss: 2.5564876773145007

Epoch: 5| Step: 8
Training loss: 2.4637946119290275
Validation loss: 2.558152013322048

Epoch: 5| Step: 9
Training loss: 2.441204288521528
Validation loss: 2.539094046246078

Epoch: 5| Step: 10
Training loss: 2.5420839144394423
Validation loss: 2.5248788328774854

Epoch: 171| Step: 0
Training loss: 2.756844239825437
Validation loss: 2.5242418212295337

Epoch: 5| Step: 1
Training loss: 2.183276103873683
Validation loss: 2.523423961655281

Epoch: 5| Step: 2
Training loss: 2.6049450944323804
Validation loss: 2.506906885573184

Epoch: 5| Step: 3
Training loss: 2.702551279207861
Validation loss: 2.501863602300186

Epoch: 5| Step: 4
Training loss: 2.229071237773447
Validation loss: 2.489382357076854

Epoch: 5| Step: 5
Training loss: 2.3390499545304326
Validation loss: 2.4973745685949114

Epoch: 5| Step: 6
Training loss: 2.4867454112712295
Validation loss: 2.502784250195861

Epoch: 5| Step: 7
Training loss: 2.3464293360268247
Validation loss: 2.5139749759215686

Epoch: 5| Step: 8
Training loss: 2.2243690796334135
Validation loss: 2.541704830835986

Epoch: 5| Step: 9
Training loss: 2.7321794687306005
Validation loss: 2.5678395391264868

Epoch: 5| Step: 10
Training loss: 2.265779792496331
Validation loss: 2.520565251253923

Epoch: 172| Step: 0
Training loss: 2.404519982603747
Validation loss: 2.5026493390902096

Epoch: 5| Step: 1
Training loss: 2.0445256619054555
Validation loss: 2.484479032487129

Epoch: 5| Step: 2
Training loss: 2.745293491147907
Validation loss: 2.4891648124609014

Epoch: 5| Step: 3
Training loss: 2.7066044987114517
Validation loss: 2.484542807991381

Epoch: 5| Step: 4
Training loss: 2.750041354475322
Validation loss: 2.474333097421589

Epoch: 5| Step: 5
Training loss: 2.5899208022863323
Validation loss: 2.478736377524922

Epoch: 5| Step: 6
Training loss: 2.8189413272182215
Validation loss: 2.4705796041257737

Epoch: 5| Step: 7
Training loss: 2.0643424849875824
Validation loss: 2.4881570665635175

Epoch: 5| Step: 8
Training loss: 1.6377299605942748
Validation loss: 2.493252382980711

Epoch: 5| Step: 9
Training loss: 2.4234555901074195
Validation loss: 2.5007698329944232

Epoch: 5| Step: 10
Training loss: 2.5693946753370036
Validation loss: 2.5223845971095034

Epoch: 173| Step: 0
Training loss: 2.177722003713459
Validation loss: 2.548049761516078

Epoch: 5| Step: 1
Training loss: 2.508757416201484
Validation loss: 2.6024048553286283

Epoch: 5| Step: 2
Training loss: 2.3481386929869976
Validation loss: 2.610123757116606

Epoch: 5| Step: 3
Training loss: 2.943036482527492
Validation loss: 2.563625699706828

Epoch: 5| Step: 4
Training loss: 1.9338964360229973
Validation loss: 2.537211107820123

Epoch: 5| Step: 5
Training loss: 2.746748909860896
Validation loss: 2.5158348823950223

Epoch: 5| Step: 6
Training loss: 2.5121374181772773
Validation loss: 2.504944420802302

Epoch: 5| Step: 7
Training loss: 2.5170346687848273
Validation loss: 2.501557650915635

Epoch: 5| Step: 8
Training loss: 2.5269281673569943
Validation loss: 2.505130182199817

Epoch: 5| Step: 9
Training loss: 2.7239101155221417
Validation loss: 2.495341902037262

Epoch: 5| Step: 10
Training loss: 2.15000054115466
Validation loss: 2.498691315776268

Epoch: 174| Step: 0
Training loss: 2.6710534868444213
Validation loss: 2.50668410676524

Epoch: 5| Step: 1
Training loss: 2.1566328731564064
Validation loss: 2.500423867173685

Epoch: 5| Step: 2
Training loss: 2.5702425590669384
Validation loss: 2.4973693604677485

Epoch: 5| Step: 3
Training loss: 2.3169028150372197
Validation loss: 2.505444366638175

Epoch: 5| Step: 4
Training loss: 2.5580961952106915
Validation loss: 2.536855072597328

Epoch: 5| Step: 5
Training loss: 2.5709071065827116
Validation loss: 2.5596345236446614

Epoch: 5| Step: 6
Training loss: 2.694097184114035
Validation loss: 2.57614201428717

Epoch: 5| Step: 7
Training loss: 2.543744368863258
Validation loss: 2.571363037733216

Epoch: 5| Step: 8
Training loss: 2.2007865670071887
Validation loss: 2.570420450785695

Epoch: 5| Step: 9
Training loss: 2.218304656560141
Validation loss: 2.5338941998253306

Epoch: 5| Step: 10
Training loss: 2.2660067532633175
Validation loss: 2.5168212143823783

Epoch: 175| Step: 0
Training loss: 2.331131088864996
Validation loss: 2.5259283333208313

Epoch: 5| Step: 1
Training loss: 2.247848541764197
Validation loss: 2.505424273430879

Epoch: 5| Step: 2
Training loss: 2.2550854961486904
Validation loss: 2.50478478588727

Epoch: 5| Step: 3
Training loss: 2.440863709248274
Validation loss: 2.4956591051174337

Epoch: 5| Step: 4
Training loss: 2.199807123919342
Validation loss: 2.516847305752764

Epoch: 5| Step: 5
Training loss: 2.657467282686849
Validation loss: 2.50562473118301

Epoch: 5| Step: 6
Training loss: 2.907068444956973
Validation loss: 2.5000623572171334

Epoch: 5| Step: 7
Training loss: 2.8855876848973843
Validation loss: 2.4895901464725263

Epoch: 5| Step: 8
Training loss: 2.6811616362836372
Validation loss: 2.4746236901012835

Epoch: 5| Step: 9
Training loss: 1.4975976780286542
Validation loss: 2.473776499224568

Epoch: 5| Step: 10
Training loss: 2.139879528469373
Validation loss: 2.474616517539357

Epoch: 176| Step: 0
Training loss: 2.280720479466202
Validation loss: 2.4848589909098164

Epoch: 5| Step: 1
Training loss: 2.204713938315964
Validation loss: 2.5028885315331357

Epoch: 5| Step: 2
Training loss: 2.3201788147712725
Validation loss: 2.5409793152972493

Epoch: 5| Step: 3
Training loss: 2.7652362614935204
Validation loss: 2.55542990825343

Epoch: 5| Step: 4
Training loss: 2.749517485162551
Validation loss: 2.5784436637700376

Epoch: 5| Step: 5
Training loss: 2.462463583894807
Validation loss: 2.5426341632297396

Epoch: 5| Step: 6
Training loss: 2.609660058811989
Validation loss: 2.5135128616878677

Epoch: 5| Step: 7
Training loss: 2.1871904426617044
Validation loss: 2.4949509959868976

Epoch: 5| Step: 8
Training loss: 2.525192264753024
Validation loss: 2.473323590250839

Epoch: 5| Step: 9
Training loss: 2.393794134544895
Validation loss: 2.48429548626848

Epoch: 5| Step: 10
Training loss: 1.703308725509014
Validation loss: 2.4771247397137235

Epoch: 177| Step: 0
Training loss: 2.492267667144688
Validation loss: 2.478640093936595

Epoch: 5| Step: 1
Training loss: 2.654870426730286
Validation loss: 2.4870483045218985

Epoch: 5| Step: 2
Training loss: 2.123527577716271
Validation loss: 2.511848129073499

Epoch: 5| Step: 3
Training loss: 2.135830598735907
Validation loss: 2.525537827056843

Epoch: 5| Step: 4
Training loss: 2.375919766262694
Validation loss: 2.556234071671261

Epoch: 5| Step: 5
Training loss: 2.616179223631969
Validation loss: 2.570923423282173

Epoch: 5| Step: 6
Training loss: 2.3027238141853887
Validation loss: 2.5981131074880643

Epoch: 5| Step: 7
Training loss: 2.18079471154051
Validation loss: 2.603124585425115

Epoch: 5| Step: 8
Training loss: 2.0464075151614183
Validation loss: 2.5888087399649637

Epoch: 5| Step: 9
Training loss: 2.627679093461165
Validation loss: 2.611469109602223

Epoch: 5| Step: 10
Training loss: 2.8015164696507
Validation loss: 2.5703931608116295

Epoch: 178| Step: 0
Training loss: 2.7369572245077927
Validation loss: 2.534401907586499

Epoch: 5| Step: 1
Training loss: 2.5837877448157403
Validation loss: 2.50643847784848

Epoch: 5| Step: 2
Training loss: 2.078821510098837
Validation loss: 2.5081151948850957

Epoch: 5| Step: 3
Training loss: 2.088334781233196
Validation loss: 2.499243358223477

Epoch: 5| Step: 4
Training loss: 1.8888273914772948
Validation loss: 2.4895158678667735

Epoch: 5| Step: 5
Training loss: 2.7288061491099302
Validation loss: 2.5054165152425356

Epoch: 5| Step: 6
Training loss: 2.9499644972394403
Validation loss: 2.533341250207552

Epoch: 5| Step: 7
Training loss: 2.494173317069906
Validation loss: 2.541268546644243

Epoch: 5| Step: 8
Training loss: 2.1786579722383133
Validation loss: 2.561003379257465

Epoch: 5| Step: 9
Training loss: 1.9783849946078869
Validation loss: 2.580732533555027

Epoch: 5| Step: 10
Training loss: 2.286133438234109
Validation loss: 2.591353852398886

Epoch: 179| Step: 0
Training loss: 2.294114510575764
Validation loss: 2.541735962021118

Epoch: 5| Step: 1
Training loss: 1.85920175979485
Validation loss: 2.521723689087986

Epoch: 5| Step: 2
Training loss: 2.495969479710487
Validation loss: 2.477193986675026

Epoch: 5| Step: 3
Training loss: 2.70099913512989
Validation loss: 2.4764434971155507

Epoch: 5| Step: 4
Training loss: 2.332546669185468
Validation loss: 2.4619500929536553

Epoch: 5| Step: 5
Training loss: 1.9995051010078215
Validation loss: 2.4712085665210446

Epoch: 5| Step: 6
Training loss: 2.486134032339731
Validation loss: 2.4680961707786526

Epoch: 5| Step: 7
Training loss: 2.1651777017448377
Validation loss: 2.46483553853567

Epoch: 5| Step: 8
Training loss: 2.1813129667358826
Validation loss: 2.481392487275956

Epoch: 5| Step: 9
Training loss: 2.7146261224036055
Validation loss: 2.500776534329412

Epoch: 5| Step: 10
Training loss: 2.4723193284107334
Validation loss: 2.494399060121041

Epoch: 180| Step: 0
Training loss: 2.7109552652178173
Validation loss: 2.5209874921534476

Epoch: 5| Step: 1
Training loss: 2.2420516022759305
Validation loss: 2.537759000705332

Epoch: 5| Step: 2
Training loss: 2.477719875860393
Validation loss: 2.538773780732743

Epoch: 5| Step: 3
Training loss: 2.0475901744767007
Validation loss: 2.543699883226839

Epoch: 5| Step: 4
Training loss: 2.413376596530199
Validation loss: 2.539339250322809

Epoch: 5| Step: 5
Training loss: 2.0596261087007033
Validation loss: 2.5413169364704102

Epoch: 5| Step: 6
Training loss: 2.312796805639974
Validation loss: 2.5619809955446247

Epoch: 5| Step: 7
Training loss: 2.1327144614243383
Validation loss: 2.5603758368883787

Epoch: 5| Step: 8
Training loss: 1.920689845431995
Validation loss: 2.572352792256763

Epoch: 5| Step: 9
Training loss: 2.6603983182182267
Validation loss: 2.6075117151571794

Epoch: 5| Step: 10
Training loss: 2.571848401735135
Validation loss: 2.6084240010662185

Epoch: 181| Step: 0
Training loss: 1.5108519442141959
Validation loss: 2.596930292565416

Epoch: 5| Step: 1
Training loss: 2.7537481600789464
Validation loss: 2.568407740520258

Epoch: 5| Step: 2
Training loss: 2.7971878303030717
Validation loss: 2.575072947097194

Epoch: 5| Step: 3
Training loss: 2.574559375877634
Validation loss: 2.5738710092662433

Epoch: 5| Step: 4
Training loss: 2.169455738285162
Validation loss: 2.5688908017539296

Epoch: 5| Step: 5
Training loss: 2.3451475935567863
Validation loss: 2.564348148120797

Epoch: 5| Step: 6
Training loss: 1.9607622896621812
Validation loss: 2.5681203288529955

Epoch: 5| Step: 7
Training loss: 1.842979787524242
Validation loss: 2.5540014974542014

Epoch: 5| Step: 8
Training loss: 2.7792835784829952
Validation loss: 2.559654496778176

Epoch: 5| Step: 9
Training loss: 1.828633881517809
Validation loss: 2.5390251688267718

Epoch: 5| Step: 10
Training loss: 2.520932303343259
Validation loss: 2.5269969372499075

Epoch: 182| Step: 0
Training loss: 2.520843873645615
Validation loss: 2.5216850266440463

Epoch: 5| Step: 1
Training loss: 2.645846649697102
Validation loss: 2.533705674395103

Epoch: 5| Step: 2
Training loss: 1.958127261202201
Validation loss: 2.521745630752474

Epoch: 5| Step: 3
Training loss: 2.323824501259204
Validation loss: 2.513704737319626

Epoch: 5| Step: 4
Training loss: 1.599870560297814
Validation loss: 2.4644217222730487

Epoch: 5| Step: 5
Training loss: 1.8173774337893942
Validation loss: 2.4531156363255304

Epoch: 5| Step: 6
Training loss: 2.102605624635834
Validation loss: 2.4698211041077913

Epoch: 5| Step: 7
Training loss: 3.103098299309221
Validation loss: 2.482653566762596

Epoch: 5| Step: 8
Training loss: 2.602842273905976
Validation loss: 2.479388122580943

Epoch: 5| Step: 9
Training loss: 2.67266084592012
Validation loss: 2.5031317937191186

Epoch: 5| Step: 10
Training loss: 1.5971418452655717
Validation loss: 2.5284585036918843

Epoch: 183| Step: 0
Training loss: 2.4193209070471893
Validation loss: 2.5488643601074745

Epoch: 5| Step: 1
Training loss: 2.304074377197216
Validation loss: 2.5783814318555476

Epoch: 5| Step: 2
Training loss: 2.268251987580436
Validation loss: 2.577977011849844

Epoch: 5| Step: 3
Training loss: 1.9075323075624515
Validation loss: 2.5799191712480365

Epoch: 5| Step: 4
Training loss: 2.4811549401510846
Validation loss: 2.5764236071579045

Epoch: 5| Step: 5
Training loss: 2.5135562517417758
Validation loss: 2.5626034819534818

Epoch: 5| Step: 6
Training loss: 2.6097638417240576
Validation loss: 2.5835670387972556

Epoch: 5| Step: 7
Training loss: 1.8178182384707953
Validation loss: 2.599895576520914

Epoch: 5| Step: 8
Training loss: 1.9582348318555935
Validation loss: 2.595032325674643

Epoch: 5| Step: 9
Training loss: 2.314462705181913
Validation loss: 2.600812770514361

Epoch: 5| Step: 10
Training loss: 2.539966973818435
Validation loss: 2.581273454148753

Epoch: 184| Step: 0
Training loss: 2.377807162847005
Validation loss: 2.538727639758332

Epoch: 5| Step: 1
Training loss: 2.359462610096028
Validation loss: 2.5200962291399938

Epoch: 5| Step: 2
Training loss: 2.086168940702457
Validation loss: 2.496020724892062

Epoch: 5| Step: 3
Training loss: 2.548654975709969
Validation loss: 2.4888515569991063

Epoch: 5| Step: 4
Training loss: 2.8150905122993373
Validation loss: 2.483732970591016

Epoch: 5| Step: 5
Training loss: 1.9705689519720742
Validation loss: 2.4850926538103693

Epoch: 5| Step: 6
Training loss: 2.4610186851068043
Validation loss: 2.482602396758333

Epoch: 5| Step: 7
Training loss: 2.075464366749399
Validation loss: 2.502119483600195

Epoch: 5| Step: 8
Training loss: 2.311890599140673
Validation loss: 2.5265732938495695

Epoch: 5| Step: 9
Training loss: 2.253087256931567
Validation loss: 2.56386244215496

Epoch: 5| Step: 10
Training loss: 1.7552651491411981
Validation loss: 2.5754510829488915

Epoch: 185| Step: 0
Training loss: 2.3934556745254274
Validation loss: 2.6026379787239584

Epoch: 5| Step: 1
Training loss: 2.083546500426544
Validation loss: 2.588013803867185

Epoch: 5| Step: 2
Training loss: 2.574245423799589
Validation loss: 2.5385872688159448

Epoch: 5| Step: 3
Training loss: 2.230338765914763
Validation loss: 2.497347890365959

Epoch: 5| Step: 4
Training loss: 2.28025974049018
Validation loss: 2.4867951847197953

Epoch: 5| Step: 5
Training loss: 1.9853644720090309
Validation loss: 2.4688549411453815

Epoch: 5| Step: 6
Training loss: 1.7285536250016156
Validation loss: 2.4853590738731106

Epoch: 5| Step: 7
Training loss: 2.027432889944814
Validation loss: 2.4806721591076397

Epoch: 5| Step: 8
Training loss: 2.8193103140342797
Validation loss: 2.500570746869853

Epoch: 5| Step: 9
Training loss: 2.7455968285115473
Validation loss: 2.519483216090078

Epoch: 5| Step: 10
Training loss: 2.210061374864998
Validation loss: 2.5533031074206183

Epoch: 186| Step: 0
Training loss: 2.2637588708072887
Validation loss: 2.5820247595518704

Epoch: 5| Step: 1
Training loss: 2.39866572483985
Validation loss: 2.60468622910814

Epoch: 5| Step: 2
Training loss: 1.6325414697307463
Validation loss: 2.642920228410526

Epoch: 5| Step: 3
Training loss: 2.1678253401328864
Validation loss: 2.6569950629587935

Epoch: 5| Step: 4
Training loss: 2.191015851338239
Validation loss: 2.657006758057587

Epoch: 5| Step: 5
Training loss: 2.419840493423242
Validation loss: 2.6546416864828273

Epoch: 5| Step: 6
Training loss: 2.1365613025072174
Validation loss: 2.6174830527414703

Epoch: 5| Step: 7
Training loss: 2.453570768832576
Validation loss: 2.5693447479119316

Epoch: 5| Step: 8
Training loss: 2.689329988075008
Validation loss: 2.5180979503196554

Epoch: 5| Step: 9
Training loss: 2.011098821730091
Validation loss: 2.4961484219143864

Epoch: 5| Step: 10
Training loss: 2.432733325490667
Validation loss: 2.486150245460084

Epoch: 187| Step: 0
Training loss: 2.017630119429259
Validation loss: 2.4691449918038533

Epoch: 5| Step: 1
Training loss: 2.5773056115331916
Validation loss: 2.459601156873757

Epoch: 5| Step: 2
Training loss: 2.326235522881606
Validation loss: 2.476537564919013

Epoch: 5| Step: 3
Training loss: 2.36900929262296
Validation loss: 2.4967930395295808

Epoch: 5| Step: 4
Training loss: 1.2449090761281456
Validation loss: 2.525695314925923

Epoch: 5| Step: 5
Training loss: 2.219859316036853
Validation loss: 2.5656890443870077

Epoch: 5| Step: 6
Training loss: 2.1451401810089705
Validation loss: 2.5972592552780527

Epoch: 5| Step: 7
Training loss: 2.037659611915288
Validation loss: 2.5966453438752093

Epoch: 5| Step: 8
Training loss: 2.6608771917079914
Validation loss: 2.5985318476226347

Epoch: 5| Step: 9
Training loss: 2.4563247319857453
Validation loss: 2.6029397593639527

Epoch: 5| Step: 10
Training loss: 2.565978503760835
Validation loss: 2.6002562455776435

Epoch: 188| Step: 0
Training loss: 2.5420413340427674
Validation loss: 2.590973218829552

Epoch: 5| Step: 1
Training loss: 2.244150505342969
Validation loss: 2.590459905198661

Epoch: 5| Step: 2
Training loss: 2.324583598759849
Validation loss: 2.5841569814727263

Epoch: 5| Step: 3
Training loss: 2.4303818474109895
Validation loss: 2.616336911174635

Epoch: 5| Step: 4
Training loss: 2.0351902232199186
Validation loss: 2.6129700489986774

Epoch: 5| Step: 5
Training loss: 2.564468186182448
Validation loss: 2.6268328788181448

Epoch: 5| Step: 6
Training loss: 1.7069366219347102
Validation loss: 2.6209208470543754

Epoch: 5| Step: 7
Training loss: 2.307205221538746
Validation loss: 2.6127187334779602

Epoch: 5| Step: 8
Training loss: 1.9197704919098184
Validation loss: 2.599880329104154

Epoch: 5| Step: 9
Training loss: 1.9190055080611081
Validation loss: 2.605255619556466

Epoch: 5| Step: 10
Training loss: 1.9947951659594354
Validation loss: 2.608060696271248

Epoch: 189| Step: 0
Training loss: 2.3313418700087634
Validation loss: 2.610952020508552

Epoch: 5| Step: 1
Training loss: 2.8311107744422657
Validation loss: 2.6120591962589566

Epoch: 5| Step: 2
Training loss: 2.3693183398283097
Validation loss: 2.594668849658751

Epoch: 5| Step: 3
Training loss: 2.4736663538981394
Validation loss: 2.594837232164545

Epoch: 5| Step: 4
Training loss: 2.148308212551668
Validation loss: 2.575732368660991

Epoch: 5| Step: 5
Training loss: 1.9697261388548442
Validation loss: 2.567529025901013

Epoch: 5| Step: 6
Training loss: 1.7545003245960282
Validation loss: 2.5538169418930994

Epoch: 5| Step: 7
Training loss: 1.6299615821523532
Validation loss: 2.5379285144535593

Epoch: 5| Step: 8
Training loss: 2.1391500696128607
Validation loss: 2.530405158538077

Epoch: 5| Step: 9
Training loss: 2.2633479810679886
Validation loss: 2.548978698580185

Epoch: 5| Step: 10
Training loss: 1.9835218262525716
Validation loss: 2.5806597100381006

Epoch: 190| Step: 0
Training loss: 2.1858647365061885
Validation loss: 2.5731365350210473

Epoch: 5| Step: 1
Training loss: 1.8175709261691202
Validation loss: 2.5730425992445847

Epoch: 5| Step: 2
Training loss: 1.883292425887286
Validation loss: 2.571138090468234

Epoch: 5| Step: 3
Training loss: 2.393805488760016
Validation loss: 2.5730608970733417

Epoch: 5| Step: 4
Training loss: 2.505344495555921
Validation loss: 2.5900911087983767

Epoch: 5| Step: 5
Training loss: 1.5914706966663816
Validation loss: 2.594065329139587

Epoch: 5| Step: 6
Training loss: 2.459479781248986
Validation loss: 2.583229307633284

Epoch: 5| Step: 7
Training loss: 2.3348231895208817
Validation loss: 2.60767424270325

Epoch: 5| Step: 8
Training loss: 2.5007249734654584
Validation loss: 2.616057621334005

Epoch: 5| Step: 9
Training loss: 1.7217807058557157
Validation loss: 2.6327372512490093

Epoch: 5| Step: 10
Training loss: 2.264757819122955
Validation loss: 2.6488957080255817

Epoch: 191| Step: 0
Training loss: 2.1687763531317756
Validation loss: 2.6487144078376628

Epoch: 5| Step: 1
Training loss: 2.328605243895361
Validation loss: 2.633561617934429

Epoch: 5| Step: 2
Training loss: 1.927057675027577
Validation loss: 2.6232619432856956

Epoch: 5| Step: 3
Training loss: 2.180133623525072
Validation loss: 2.6127208695836615

Epoch: 5| Step: 4
Training loss: 1.724942029448847
Validation loss: 2.6145392669414353

Epoch: 5| Step: 5
Training loss: 2.1596435159104868
Validation loss: 2.5942810222697243

Epoch: 5| Step: 6
Training loss: 1.9646082105575122
Validation loss: 2.586666360241819

Epoch: 5| Step: 7
Training loss: 2.3405149385578174
Validation loss: 2.5787937096297258

Epoch: 5| Step: 8
Training loss: 2.4089193029446556
Validation loss: 2.5997095061705617

Epoch: 5| Step: 9
Training loss: 2.657253659189755
Validation loss: 2.6231950911604764

Epoch: 5| Step: 10
Training loss: 1.654434864905157
Validation loss: 2.6344484665445127

Epoch: 192| Step: 0
Training loss: 2.4611721350818634
Validation loss: 2.632677822320502

Epoch: 5| Step: 1
Training loss: 2.223129677927127
Validation loss: 2.611463762357338

Epoch: 5| Step: 2
Training loss: 2.6559090788227566
Validation loss: 2.592451367224232

Epoch: 5| Step: 3
Training loss: 1.617195313660547
Validation loss: 2.5761887952369613

Epoch: 5| Step: 4
Training loss: 1.8897879773252777
Validation loss: 2.5477177408198766

Epoch: 5| Step: 5
Training loss: 2.389830912430531
Validation loss: 2.5633050792897754

Epoch: 5| Step: 6
Training loss: 2.0599272894758314
Validation loss: 2.5467556778832194

Epoch: 5| Step: 7
Training loss: 1.406688028568096
Validation loss: 2.578496786477378

Epoch: 5| Step: 8
Training loss: 1.9990222448243877
Validation loss: 2.5937606350714932

Epoch: 5| Step: 9
Training loss: 1.8484647566655203
Validation loss: 2.6050227008903

Epoch: 5| Step: 10
Training loss: 2.706533499089852
Validation loss: 2.6073676779906387

Epoch: 193| Step: 0
Training loss: 1.7361161024233807
Validation loss: 2.605426882759998

Epoch: 5| Step: 1
Training loss: 2.454518402316591
Validation loss: 2.6204414436868735

Epoch: 5| Step: 2
Training loss: 1.6749246181777133
Validation loss: 2.6309281819560373

Epoch: 5| Step: 3
Training loss: 2.0346312330759484
Validation loss: 2.6464907422356374

Epoch: 5| Step: 4
Training loss: 1.756622657743372
Validation loss: 2.6457685430834883

Epoch: 5| Step: 5
Training loss: 1.8710183146328114
Validation loss: 2.6308396208776132

Epoch: 5| Step: 6
Training loss: 2.6323906535074424
Validation loss: 2.628071333495147

Epoch: 5| Step: 7
Training loss: 2.2626513730830258
Validation loss: 2.642422864937221

Epoch: 5| Step: 8
Training loss: 2.071442148323853
Validation loss: 2.6418474201216324

Epoch: 5| Step: 9
Training loss: 2.3674383754423967
Validation loss: 2.6521303788577018

Epoch: 5| Step: 10
Training loss: 2.234279497146319
Validation loss: 2.6110526072309415

Epoch: 194| Step: 0
Training loss: 1.7475957703986034
Validation loss: 2.555217769045155

Epoch: 5| Step: 1
Training loss: 1.5451567383305491
Validation loss: 2.516515609955059

Epoch: 5| Step: 2
Training loss: 2.1123860661407368
Validation loss: 2.5171151975000505

Epoch: 5| Step: 3
Training loss: 2.5976400962843598
Validation loss: 2.498286515277955

Epoch: 5| Step: 4
Training loss: 2.15081566707899
Validation loss: 2.5195461564331745

Epoch: 5| Step: 5
Training loss: 2.189951803295414
Validation loss: 2.524069493045272

Epoch: 5| Step: 6
Training loss: 2.439716993710421
Validation loss: 2.5426354326308993

Epoch: 5| Step: 7
Training loss: 2.2685825380675806
Validation loss: 2.559207272391599

Epoch: 5| Step: 8
Training loss: 1.9961747901426126
Validation loss: 2.5744392277820656

Epoch: 5| Step: 9
Training loss: 1.3022653172793726
Validation loss: 2.5809256845332396

Epoch: 5| Step: 10
Training loss: 2.5268604223230433
Validation loss: 2.6208062666001664

Epoch: 195| Step: 0
Training loss: 2.29091478208768
Validation loss: 2.6059207739696215

Epoch: 5| Step: 1
Training loss: 2.341657900086778
Validation loss: 2.607660413204206

Epoch: 5| Step: 2
Training loss: 2.1835720218130157
Validation loss: 2.5942051667651893

Epoch: 5| Step: 3
Training loss: 1.7480659696931962
Validation loss: 2.5918812548746195

Epoch: 5| Step: 4
Training loss: 2.472257223369651
Validation loss: 2.592389298019596

Epoch: 5| Step: 5
Training loss: 2.0746746819340505
Validation loss: 2.5795665048423895

Epoch: 5| Step: 6
Training loss: 2.210885845969319
Validation loss: 2.5678182429183996

Epoch: 5| Step: 7
Training loss: 1.4596501354481555
Validation loss: 2.577726958004565

Epoch: 5| Step: 8
Training loss: 2.134028608550461
Validation loss: 2.5777407442170066

Epoch: 5| Step: 9
Training loss: 1.8861376892387056
Validation loss: 2.581079725303347

Epoch: 5| Step: 10
Training loss: 1.7625269082903414
Validation loss: 2.5669469117310584

Epoch: 196| Step: 0
Training loss: 1.8190794603756044
Validation loss: 2.538076985247167

Epoch: 5| Step: 1
Training loss: 2.2609971761571974
Validation loss: 2.5434171766640974

Epoch: 5| Step: 2
Training loss: 2.042283010547784
Validation loss: 2.533097482555105

Epoch: 5| Step: 3
Training loss: 2.2475179121175666
Validation loss: 2.5482181430045387

Epoch: 5| Step: 4
Training loss: 1.6353412375903835
Validation loss: 2.571870823850311

Epoch: 5| Step: 5
Training loss: 2.277930470391006
Validation loss: 2.5722098619998968

Epoch: 5| Step: 6
Training loss: 1.8243508137964932
Validation loss: 2.598172383733681

Epoch: 5| Step: 7
Training loss: 2.141715113268758
Validation loss: 2.6260016484036823

Epoch: 5| Step: 8
Training loss: 2.033386280850463
Validation loss: 2.6314807424236935

Epoch: 5| Step: 9
Training loss: 2.3459152392582165
Validation loss: 2.6116698751651

Epoch: 5| Step: 10
Training loss: 1.9921301739990465
Validation loss: 2.6153747657659454

Epoch: 197| Step: 0
Training loss: 2.0389836906315906
Validation loss: 2.598381694808888

Epoch: 5| Step: 1
Training loss: 1.853917937436822
Validation loss: 2.6108877684598317

Epoch: 5| Step: 2
Training loss: 2.2401621107636878
Validation loss: 2.5985990215043886

Epoch: 5| Step: 3
Training loss: 2.4359183437335594
Validation loss: 2.5869245581957343

Epoch: 5| Step: 4
Training loss: 2.314309623551025
Validation loss: 2.5886983869616467

Epoch: 5| Step: 5
Training loss: 2.1028101737873635
Validation loss: 2.5811728978070168

Epoch: 5| Step: 6
Training loss: 2.0902278368937997
Validation loss: 2.5932541912143834

Epoch: 5| Step: 7
Training loss: 1.868857048311268
Validation loss: 2.614359530142892

Epoch: 5| Step: 8
Training loss: 1.7104475460757593
Validation loss: 2.6355355877261006

Epoch: 5| Step: 9
Training loss: 1.701869186632396
Validation loss: 2.6618117995225594

Epoch: 5| Step: 10
Training loss: 2.0559928431775996
Validation loss: 2.683936459658853

Epoch: 198| Step: 0
Training loss: 1.8313383894800674
Validation loss: 2.671734532548212

Epoch: 5| Step: 1
Training loss: 1.4910006771482673
Validation loss: 2.677544485901274

Epoch: 5| Step: 2
Training loss: 2.0461538660657275
Validation loss: 2.6646611221323195

Epoch: 5| Step: 3
Training loss: 2.21093944104652
Validation loss: 2.612570917982655

Epoch: 5| Step: 4
Training loss: 2.3105704015338584
Validation loss: 2.589091684590331

Epoch: 5| Step: 5
Training loss: 1.9751755141483716
Validation loss: 2.568141866128396

Epoch: 5| Step: 6
Training loss: 1.9309118919322854
Validation loss: 2.533309424869862

Epoch: 5| Step: 7
Training loss: 1.8219144263998854
Validation loss: 2.547959086468901

Epoch: 5| Step: 8
Training loss: 2.5877781336105157
Validation loss: 2.5426800155334845

Epoch: 5| Step: 9
Training loss: 1.856250863123221
Validation loss: 2.556642100027131

Epoch: 5| Step: 10
Training loss: 1.863375615383473
Validation loss: 2.573444507770468

Epoch: 199| Step: 0
Training loss: 1.8047978090864776
Validation loss: 2.59942884750518

Epoch: 5| Step: 1
Training loss: 2.164325464019421
Validation loss: 2.5923234624541895

Epoch: 5| Step: 2
Training loss: 2.0459550726797078
Validation loss: 2.583500612250126

Epoch: 5| Step: 3
Training loss: 2.4139640318901856
Validation loss: 2.5685586664299973

Epoch: 5| Step: 4
Training loss: 2.0203002410068303
Validation loss: 2.534416409947203

Epoch: 5| Step: 5
Training loss: 1.0980338536551995
Validation loss: 2.493025989029421

Epoch: 5| Step: 6
Training loss: 2.542476108254975
Validation loss: 2.4770964705505243

Epoch: 5| Step: 7
Training loss: 1.5065134411657555
Validation loss: 2.4923209921844327

Epoch: 5| Step: 8
Training loss: 2.4741481239734964
Validation loss: 2.4856106618447846

Epoch: 5| Step: 9
Training loss: 2.1618600372475996
Validation loss: 2.5351663906518342

Epoch: 5| Step: 10
Training loss: 0.792949845412836
Validation loss: 2.5578085439633633

Epoch: 200| Step: 0
Training loss: 1.8963576489585692
Validation loss: 2.6200692941350345

Epoch: 5| Step: 1
Training loss: 1.6840032446823212
Validation loss: 2.6174999527463485

Epoch: 5| Step: 2
Training loss: 1.4126590065369633
Validation loss: 2.6365852033490196

Epoch: 5| Step: 3
Training loss: 2.252333702358735
Validation loss: 2.626860617915535

Epoch: 5| Step: 4
Training loss: 1.694074679853223
Validation loss: 2.6252685210303417

Epoch: 5| Step: 5
Training loss: 2.4956370429883616
Validation loss: 2.6203296990988623

Epoch: 5| Step: 6
Training loss: 2.3743550278119114
Validation loss: 2.5870629663856337

Epoch: 5| Step: 7
Training loss: 1.9400055589301308
Validation loss: 2.578451152517416

Epoch: 5| Step: 8
Training loss: 1.8278034286026084
Validation loss: 2.548929917125877

Epoch: 5| Step: 9
Training loss: 1.7500895068575606
Validation loss: 2.552994434657449

Epoch: 5| Step: 10
Training loss: 1.816053655713985
Validation loss: 2.565801982159422

Epoch: 201| Step: 0
Training loss: 1.918176457176951
Validation loss: 2.572569744795383

Epoch: 5| Step: 1
Training loss: 2.246935346745343
Validation loss: 2.582573332487975

Epoch: 5| Step: 2
Training loss: 1.8590857016275752
Validation loss: 2.6251671342824476

Epoch: 5| Step: 3
Training loss: 2.0086021206539284
Validation loss: 2.611463780027708

Epoch: 5| Step: 4
Training loss: 1.6072639026168134
Validation loss: 2.6250970952388113

Epoch: 5| Step: 5
Training loss: 2.0416616193228894
Validation loss: 2.646871126014726

Epoch: 5| Step: 6
Training loss: 2.07430311703128
Validation loss: 2.6239495028561683

Epoch: 5| Step: 7
Training loss: 1.6767845440501672
Validation loss: 2.618826556008792

Epoch: 5| Step: 8
Training loss: 2.0260565462195284
Validation loss: 2.594271073161209

Epoch: 5| Step: 9
Training loss: 2.146085915622361
Validation loss: 2.609162849898273

Epoch: 5| Step: 10
Training loss: 1.3396890623253943
Validation loss: 2.59815560370257

Epoch: 202| Step: 0
Training loss: 1.6220462069250376
Validation loss: 2.580988041341339

Epoch: 5| Step: 1
Training loss: 2.303996975141765
Validation loss: 2.575220179301343

Epoch: 5| Step: 2
Training loss: 2.0220322608223027
Validation loss: 2.5530264720008717

Epoch: 5| Step: 3
Training loss: 1.965425924581667
Validation loss: 2.5460997473016262

Epoch: 5| Step: 4
Training loss: 2.1801371230300224
Validation loss: 2.5512680747209595

Epoch: 5| Step: 5
Training loss: 2.227151571952543
Validation loss: 2.576310419044252

Epoch: 5| Step: 6
Training loss: 1.7854356275847705
Validation loss: 2.573988517648356

Epoch: 5| Step: 7
Training loss: 1.4624047077140743
Validation loss: 2.575666466649058

Epoch: 5| Step: 8
Training loss: 1.5425147052478176
Validation loss: 2.592656104172095

Epoch: 5| Step: 9
Training loss: 1.6220922129861852
Validation loss: 2.6082554754437783

Epoch: 5| Step: 10
Training loss: 1.9877198031778611
Validation loss: 2.6134415039416043

Epoch: 203| Step: 0
Training loss: 1.869685078791014
Validation loss: 2.568248060473305

Epoch: 5| Step: 1
Training loss: 1.9503168288850472
Validation loss: 2.5134640406071096

Epoch: 5| Step: 2
Training loss: 1.3961191833604443
Validation loss: 2.50356037763193

Epoch: 5| Step: 3
Training loss: 1.8117771022491296
Validation loss: 2.512108390857752

Epoch: 5| Step: 4
Training loss: 2.2449381368223
Validation loss: 2.537318396655725

Epoch: 5| Step: 5
Training loss: 1.7623400892937864
Validation loss: 2.5385528936516595

Epoch: 5| Step: 6
Training loss: 1.8739834891032634
Validation loss: 2.5685358281407336

Epoch: 5| Step: 7
Training loss: 2.086149854959176
Validation loss: 2.5956035741126446

Epoch: 5| Step: 8
Training loss: 1.4023328690385666
Validation loss: 2.6208735787489035

Epoch: 5| Step: 9
Training loss: 1.9092060370224526
Validation loss: 2.689776191905345

Epoch: 5| Step: 10
Training loss: 2.5705907607261915
Validation loss: 2.6965515322971165

Epoch: 204| Step: 0
Training loss: 1.6722579232323447
Validation loss: 2.6831503198125035

Epoch: 5| Step: 1
Training loss: 1.5937354143260654
Validation loss: 2.6590030366511197

Epoch: 5| Step: 2
Training loss: 2.4176184873529207
Validation loss: 2.6210364094045984

Epoch: 5| Step: 3
Training loss: 1.7674352767295267
Validation loss: 2.5889556376137173

Epoch: 5| Step: 4
Training loss: 1.9062568164140743
Validation loss: 2.5373041937881142

Epoch: 5| Step: 5
Training loss: 2.1041595408504676
Validation loss: 2.531267260015706

Epoch: 5| Step: 6
Training loss: 1.9733044456395126
Validation loss: 2.515829803684208

Epoch: 5| Step: 7
Training loss: 1.8563338983244586
Validation loss: 2.502673820405639

Epoch: 5| Step: 8
Training loss: 1.8150935854573742
Validation loss: 2.4856503072317397

Epoch: 5| Step: 9
Training loss: 1.553602980933782
Validation loss: 2.490394127306182

Epoch: 5| Step: 10
Training loss: 1.7922075771015382
Validation loss: 2.4967287750100478

Epoch: 205| Step: 0
Training loss: 1.5824518092141409
Validation loss: 2.459755266424579

Epoch: 5| Step: 1
Training loss: 1.6727621273934674
Validation loss: 2.4877529097547955

Epoch: 5| Step: 2
Training loss: 2.0888617088813146
Validation loss: 2.5032014406281897

Epoch: 5| Step: 3
Training loss: 1.082246394062622
Validation loss: 2.536282377972221

Epoch: 5| Step: 4
Training loss: 1.8683836868175048
Validation loss: 2.578301276988677

Epoch: 5| Step: 5
Training loss: 1.4879705149744156
Validation loss: 2.5856919399595775

Epoch: 5| Step: 6
Training loss: 2.31440512048054
Validation loss: 2.614013163244051

Epoch: 5| Step: 7
Training loss: 1.4642744662022302
Validation loss: 2.6210259828178355

Epoch: 5| Step: 8
Training loss: 2.331676360303985
Validation loss: 2.621181126341461

Epoch: 5| Step: 9
Training loss: 2.3295493665099865
Validation loss: 2.6297473160267564

Epoch: 5| Step: 10
Training loss: 1.6252812362272184
Validation loss: 2.585996793617322

Epoch: 206| Step: 0
Training loss: 2.021519285628502
Validation loss: 2.6123352639041246

Epoch: 5| Step: 1
Training loss: 1.5254719769890024
Validation loss: 2.6276164260946255

Epoch: 5| Step: 2
Training loss: 1.2824692391169898
Validation loss: 2.6824754227702945

Epoch: 5| Step: 3
Training loss: 1.4905178455409303
Validation loss: 2.697263965497916

Epoch: 5| Step: 4
Training loss: 1.8415175678203406
Validation loss: 2.676157347868598

Epoch: 5| Step: 5
Training loss: 1.9116654314182928
Validation loss: 2.655278956236578

Epoch: 5| Step: 6
Training loss: 2.56186305247804
Validation loss: 2.6395594036633305

Epoch: 5| Step: 7
Training loss: 1.7509064370456355
Validation loss: 2.625769854356039

Epoch: 5| Step: 8
Training loss: 1.7136225425240121
Validation loss: 2.6107926938928134

Epoch: 5| Step: 9
Training loss: 1.9135704809465282
Validation loss: 2.592378042217436

Epoch: 5| Step: 10
Training loss: 1.9557910271083487
Validation loss: 2.5716811946135576

Epoch: 207| Step: 0
Training loss: 1.8290196373429157
Validation loss: 2.5731813725476953

Epoch: 5| Step: 1
Training loss: 1.7013281346414078
Validation loss: 2.5518628672907355

Epoch: 5| Step: 2
Training loss: 1.9306134307504805
Validation loss: 2.539031145203552

Epoch: 5| Step: 3
Training loss: 1.550439446205132
Validation loss: 2.5589824482397616

Epoch: 5| Step: 4
Training loss: 1.887477303677958
Validation loss: 2.5716774423792557

Epoch: 5| Step: 5
Training loss: 1.5321524160228586
Validation loss: 2.6084670000706445

Epoch: 5| Step: 6
Training loss: 1.3163538166776296
Validation loss: 2.624797510481265

Epoch: 5| Step: 7
Training loss: 2.583289412668606
Validation loss: 2.6531807990754

Epoch: 5| Step: 8
Training loss: 1.7345395396771355
Validation loss: 2.6824324063872815

Epoch: 5| Step: 9
Training loss: 1.9591683846156114
Validation loss: 2.6686590894827855

Epoch: 5| Step: 10
Training loss: 1.7316619685858599
Validation loss: 2.666571738171119

Epoch: 208| Step: 0
Training loss: 1.9465520502123212
Validation loss: 2.622095952004407

Epoch: 5| Step: 1
Training loss: 1.1123193701360279
Validation loss: 2.603456440869643

Epoch: 5| Step: 2
Training loss: 1.3899049502059464
Validation loss: 2.5959802145703983

Epoch: 5| Step: 3
Training loss: 1.4216481122098925
Validation loss: 2.595020645669294

Epoch: 5| Step: 4
Training loss: 1.7504572952060522
Validation loss: 2.610664120470283

Epoch: 5| Step: 5
Training loss: 2.0935698474413797
Validation loss: 2.6120437622098445

Epoch: 5| Step: 6
Training loss: 2.2883123529208222
Validation loss: 2.6274582856211675

Epoch: 5| Step: 7
Training loss: 1.7829558920804092
Validation loss: 2.555994455201876

Epoch: 5| Step: 8
Training loss: 1.6789774968795967
Validation loss: 2.551140300878738

Epoch: 5| Step: 9
Training loss: 2.260501830669186
Validation loss: 2.532971520754741

Epoch: 5| Step: 10
Training loss: 1.632989755162692
Validation loss: 2.5294084056926325

Epoch: 209| Step: 0
Training loss: 1.5072125442009188
Validation loss: 2.521811103877959

Epoch: 5| Step: 1
Training loss: 1.786090097391096
Validation loss: 2.55441659559298

Epoch: 5| Step: 2
Training loss: 1.9287739803779012
Validation loss: 2.5525761329214958

Epoch: 5| Step: 3
Training loss: 1.8240543920412906
Validation loss: 2.5264586506756888

Epoch: 5| Step: 4
Training loss: 1.0393066693001964
Validation loss: 2.552041155173808

Epoch: 5| Step: 5
Training loss: 1.8758670073912345
Validation loss: 2.574485079236087

Epoch: 5| Step: 6
Training loss: 1.9771399577975572
Validation loss: 2.600546598128238

Epoch: 5| Step: 7
Training loss: 1.8854790636840983
Validation loss: 2.619744007430013

Epoch: 5| Step: 8
Training loss: 1.7600109678706968
Validation loss: 2.662083782859419

Epoch: 5| Step: 9
Training loss: 2.004101243672923
Validation loss: 2.6096505937009167

Epoch: 5| Step: 10
Training loss: 1.8508612999083462
Validation loss: 2.5919004562833323

Epoch: 210| Step: 0
Training loss: 2.087192343694667
Validation loss: 2.5513285096778806

Epoch: 5| Step: 1
Training loss: 1.4902245357483588
Validation loss: 2.547536802618867

Epoch: 5| Step: 2
Training loss: 1.4097510096341228
Validation loss: 2.5054708742405234

Epoch: 5| Step: 3
Training loss: 1.6427668078684143
Validation loss: 2.507623968435366

Epoch: 5| Step: 4
Training loss: 1.575895642131844
Validation loss: 2.511250153604665

Epoch: 5| Step: 5
Training loss: 1.7586689536827165
Validation loss: 2.51084670091105

Epoch: 5| Step: 6
Training loss: 2.2542839593274415
Validation loss: 2.5018759867019593

Epoch: 5| Step: 7
Training loss: 1.817004558509227
Validation loss: 2.5335740935836437

Epoch: 5| Step: 8
Training loss: 1.7874824843182058
Validation loss: 2.557333509283614

Epoch: 5| Step: 9
Training loss: 1.6602816904585056
Validation loss: 2.567177352179693

Epoch: 5| Step: 10
Training loss: 1.5715189991359906
Validation loss: 2.59930721065987

Epoch: 211| Step: 0
Training loss: 1.7622532340377375
Validation loss: 2.6079608832823715

Epoch: 5| Step: 1
Training loss: 2.1709591697884205
Validation loss: 2.6397305603741428

Epoch: 5| Step: 2
Training loss: 1.9832781065403007
Validation loss: 2.622662911677941

Epoch: 5| Step: 3
Training loss: 1.4425289258254967
Validation loss: 2.578677204616044

Epoch: 5| Step: 4
Training loss: 1.746630763141098
Validation loss: 2.5875680787389

Epoch: 5| Step: 5
Training loss: 1.0103478293549943
Validation loss: 2.575489497688047

Epoch: 5| Step: 6
Training loss: 2.0169884853157294
Validation loss: 2.556362306946062

Epoch: 5| Step: 7
Training loss: 2.088333639564502
Validation loss: 2.550466516959352

Epoch: 5| Step: 8
Training loss: 1.5672671266448475
Validation loss: 2.547440483770435

Epoch: 5| Step: 9
Training loss: 1.2362963535270182
Validation loss: 2.530882944109751

Epoch: 5| Step: 10
Training loss: 1.9304836345177518
Validation loss: 2.5511615554280023

Epoch: 212| Step: 0
Training loss: 1.7073331867015875
Validation loss: 2.553941636682347

Epoch: 5| Step: 1
Training loss: 1.67502468432557
Validation loss: 2.6044271165777615

Epoch: 5| Step: 2
Training loss: 1.513937019998471
Validation loss: 2.5929407546743852

Epoch: 5| Step: 3
Training loss: 1.361049147361067
Validation loss: 2.6006543624961656

Epoch: 5| Step: 4
Training loss: 1.9735778468734588
Validation loss: 2.6085616350897394

Epoch: 5| Step: 5
Training loss: 1.4036528021569261
Validation loss: 2.6272123753616508

Epoch: 5| Step: 6
Training loss: 1.6215999686131524
Validation loss: 2.6139726911536316

Epoch: 5| Step: 7
Training loss: 1.5501530910075634
Validation loss: 2.603742554779567

Epoch: 5| Step: 8
Training loss: 1.8238753785927817
Validation loss: 2.6216876181825617

Epoch: 5| Step: 9
Training loss: 2.0022177321317463
Validation loss: 2.5975843154528753

Epoch: 5| Step: 10
Training loss: 2.1104462340663326
Validation loss: 2.555681975171336

Epoch: 213| Step: 0
Training loss: 2.0918777977315237
Validation loss: 2.5353819861966436

Epoch: 5| Step: 1
Training loss: 1.5856521424890078
Validation loss: 2.532911838069497

Epoch: 5| Step: 2
Training loss: 1.6345647873103089
Validation loss: 2.534844868355631

Epoch: 5| Step: 3
Training loss: 1.5599908900606259
Validation loss: 2.5533938085559704

Epoch: 5| Step: 4
Training loss: 1.384221582113784
Validation loss: 2.5839805691980704

Epoch: 5| Step: 5
Training loss: 1.5142658864699943
Validation loss: 2.604176083127297

Epoch: 5| Step: 6
Training loss: 1.9662858588943621
Validation loss: 2.6307489801788466

Epoch: 5| Step: 7
Training loss: 1.8043009686717808
Validation loss: 2.6432585670916917

Epoch: 5| Step: 8
Training loss: 1.579571504795977
Validation loss: 2.6900714897338607

Epoch: 5| Step: 9
Training loss: 1.7480852687604516
Validation loss: 2.6694229811739008

Epoch: 5| Step: 10
Training loss: 1.7300273254750222
Validation loss: 2.6404177230060797

Epoch: 214| Step: 0
Training loss: 1.7615386803197293
Validation loss: 2.6234492747667693

Epoch: 5| Step: 1
Training loss: 1.206203633736621
Validation loss: 2.605232470229604

Epoch: 5| Step: 2
Training loss: 1.408453423084402
Validation loss: 2.5737538570927834

Epoch: 5| Step: 3
Training loss: 1.5941006891716116
Validation loss: 2.6153107547065444

Epoch: 5| Step: 4
Training loss: 1.9322695118198687
Validation loss: 2.5794236935381876

Epoch: 5| Step: 5
Training loss: 1.6361502522721603
Validation loss: 2.6232902791363935

Epoch: 5| Step: 6
Training loss: 1.945721625389642
Validation loss: 2.600622107982463

Epoch: 5| Step: 7
Training loss: 1.5777237637024397
Validation loss: 2.5892676436830606

Epoch: 5| Step: 8
Training loss: 1.4685126579552208
Validation loss: 2.6029608243631897

Epoch: 5| Step: 9
Training loss: 1.9559508975561
Validation loss: 2.5910866173091236

Epoch: 5| Step: 10
Training loss: 1.913324517430233
Validation loss: 2.6091260608916405

Epoch: 215| Step: 0
Training loss: 1.6069731335106232
Validation loss: 2.584297643918016

Epoch: 5| Step: 1
Training loss: 2.2397190023330205
Validation loss: 2.579227076471778

Epoch: 5| Step: 2
Training loss: 1.590797307062975
Validation loss: 2.589510380710926

Epoch: 5| Step: 3
Training loss: 1.6092283311694393
Validation loss: 2.5714127505024567

Epoch: 5| Step: 4
Training loss: 1.5012896874460018
Validation loss: 2.5483188790388316

Epoch: 5| Step: 5
Training loss: 1.4545171488370243
Validation loss: 2.5439715781529024

Epoch: 5| Step: 6
Training loss: 1.4578639864645795
Validation loss: 2.537343430569782

Epoch: 5| Step: 7
Training loss: 1.8375271671907831
Validation loss: 2.5464053465519014

Epoch: 5| Step: 8
Training loss: 1.5987530140553832
Validation loss: 2.585842181247952

Epoch: 5| Step: 9
Training loss: 1.8869645805612905
Validation loss: 2.5835581081965584

Epoch: 5| Step: 10
Training loss: 1.5252712071133525
Validation loss: 2.614361267765298

Epoch: 216| Step: 0
Training loss: 2.156934325497482
Validation loss: 2.6015034872487366

Epoch: 5| Step: 1
Training loss: 1.6842191379885356
Validation loss: 2.622182835443655

Epoch: 5| Step: 2
Training loss: 1.5043114054494933
Validation loss: 2.5877629713234693

Epoch: 5| Step: 3
Training loss: 1.5945711451412616
Validation loss: 2.616016619835393

Epoch: 5| Step: 4
Training loss: 1.7150458909726263
Validation loss: 2.5858817433286245

Epoch: 5| Step: 5
Training loss: 1.0952022175905056
Validation loss: 2.591662339066202

Epoch: 5| Step: 6
Training loss: 1.865523742279313
Validation loss: 2.582461195675062

Epoch: 5| Step: 7
Training loss: 1.2886681155693118
Validation loss: 2.589048189527195

Epoch: 5| Step: 8
Training loss: 1.3069674278496852
Validation loss: 2.584329648832721

Epoch: 5| Step: 9
Training loss: 1.865304228588087
Validation loss: 2.594388957960528

Epoch: 5| Step: 10
Training loss: 1.3078473140043343
Validation loss: 2.5924207333115463

Epoch: 217| Step: 0
Training loss: 1.5621801430425386
Validation loss: 2.5734254236807947

Epoch: 5| Step: 1
Training loss: 1.6304761607683016
Validation loss: 2.5618857901431005

Epoch: 5| Step: 2
Training loss: 1.9220943170720586
Validation loss: 2.5349361368932315

Epoch: 5| Step: 3
Training loss: 1.6267555730526968
Validation loss: 2.5251036735701597

Epoch: 5| Step: 4
Training loss: 0.8163717527265074
Validation loss: 2.522246894395319

Epoch: 5| Step: 5
Training loss: 1.5709892067444382
Validation loss: 2.5448245726877814

Epoch: 5| Step: 6
Training loss: 1.9498043059920243
Validation loss: 2.557444914945699

Epoch: 5| Step: 7
Training loss: 1.68726870046594
Validation loss: 2.5981142530833474

Epoch: 5| Step: 8
Training loss: 1.2477956886219466
Validation loss: 2.630735987261142

Epoch: 5| Step: 9
Training loss: 1.3046760787007103
Validation loss: 2.6246882388788904

Epoch: 5| Step: 10
Training loss: 1.8774883289202982
Validation loss: 2.664125289660601

Epoch: 218| Step: 0
Training loss: 1.9888591413682624
Validation loss: 2.7008505247856154

Epoch: 5| Step: 1
Training loss: 1.6460814791938518
Validation loss: 2.7379119002766785

Epoch: 5| Step: 2
Training loss: 1.6077792209632533
Validation loss: 2.714959499499943

Epoch: 5| Step: 3
Training loss: 1.678071562131084
Validation loss: 2.6901758908660143

Epoch: 5| Step: 4
Training loss: 1.6270006775060368
Validation loss: 2.6586519946890106

Epoch: 5| Step: 5
Training loss: 1.7679488831203283
Validation loss: 2.651181509101547

Epoch: 5| Step: 6
Training loss: 1.6827508006566498
Validation loss: 2.609723983514874

Epoch: 5| Step: 7
Training loss: 1.4707419503040482
Validation loss: 2.5928412648238757

Epoch: 5| Step: 8
Training loss: 1.1659245798933353
Validation loss: 2.6008484321812544

Epoch: 5| Step: 9
Training loss: 1.1250786753800743
Validation loss: 2.5420302042473506

Epoch: 5| Step: 10
Training loss: 1.2852388952517901
Validation loss: 2.5542173931184333

Epoch: 219| Step: 0
Training loss: 1.8728919576755443
Validation loss: 2.5733041706066038

Epoch: 5| Step: 1
Training loss: 1.9219108516171401
Validation loss: 2.568599953892584

Epoch: 5| Step: 2
Training loss: 1.3171491026796778
Validation loss: 2.601080759732015

Epoch: 5| Step: 3
Training loss: 1.5069754851738761
Validation loss: 2.6087833804997462

Epoch: 5| Step: 4
Training loss: 1.7405448662274432
Validation loss: 2.639753519825234

Epoch: 5| Step: 5
Training loss: 1.6352015635285115
Validation loss: 2.6503373898498017

Epoch: 5| Step: 6
Training loss: 1.2156302797649041
Validation loss: 2.6108174239235695

Epoch: 5| Step: 7
Training loss: 1.6155810647151878
Validation loss: 2.62029248376103

Epoch: 5| Step: 8
Training loss: 1.533798121759904
Validation loss: 2.5992056427090158

Epoch: 5| Step: 9
Training loss: 1.3045214701560195
Validation loss: 2.5653707809315334

Epoch: 5| Step: 10
Training loss: 0.9582554674995268
Validation loss: 2.579036904626436

Epoch: 220| Step: 0
Training loss: 1.4810409044210215
Validation loss: 2.573721475628849

Epoch: 5| Step: 1
Training loss: 1.3287543656859717
Validation loss: 2.5894646864057798

Epoch: 5| Step: 2
Training loss: 1.64180894548189
Validation loss: 2.601705448493044

Epoch: 5| Step: 3
Training loss: 1.161441181324212
Validation loss: 2.5956215528938946

Epoch: 5| Step: 4
Training loss: 1.2180724583700764
Validation loss: 2.599780627549312

Epoch: 5| Step: 5
Training loss: 1.8131151799616856
Validation loss: 2.605583186313971

Epoch: 5| Step: 6
Training loss: 1.644184791876216
Validation loss: 2.6436985916666353

Epoch: 5| Step: 7
Training loss: 1.5475698124386306
Validation loss: 2.633589292973364

Epoch: 5| Step: 8
Training loss: 1.493009011580603
Validation loss: 2.6695317267479846

Epoch: 5| Step: 9
Training loss: 1.7168545067740655
Validation loss: 2.65708350773544

Epoch: 5| Step: 10
Training loss: 1.507846021526664
Validation loss: 2.672174369919468

Epoch: 221| Step: 0
Training loss: 1.6189931473330732
Validation loss: 2.6415041946312265

Epoch: 5| Step: 1
Training loss: 1.6754065319185771
Validation loss: 2.6285882197437505

Epoch: 5| Step: 2
Training loss: 1.7787308530654926
Validation loss: 2.615302886282381

Epoch: 5| Step: 3
Training loss: 1.5175066407009667
Validation loss: 2.597700094376841

Epoch: 5| Step: 4
Training loss: 1.4983115229789021
Validation loss: 2.60842293567692

Epoch: 5| Step: 5
Training loss: 1.2673030137400618
Validation loss: 2.605951620063328

Epoch: 5| Step: 6
Training loss: 1.1890300129727078
Validation loss: 2.611051085375682

Epoch: 5| Step: 7
Training loss: 1.6551217608881463
Validation loss: 2.6295865027543535

Epoch: 5| Step: 8
Training loss: 1.2856511145921932
Validation loss: 2.6375261766676017

Epoch: 5| Step: 9
Training loss: 1.6757134555005753
Validation loss: 2.636137887041936

Epoch: 5| Step: 10
Training loss: 1.0692954138475954
Validation loss: 2.656823726416962

Epoch: 222| Step: 0
Training loss: 1.624288403153785
Validation loss: 2.6153733954191045

Epoch: 5| Step: 1
Training loss: 0.9739292194822526
Validation loss: 2.6291726266961675

Epoch: 5| Step: 2
Training loss: 1.5587689676484402
Validation loss: 2.6063140055474263

Epoch: 5| Step: 3
Training loss: 1.2681854156947763
Validation loss: 2.5743448575523424

Epoch: 5| Step: 4
Training loss: 1.7734532292546539
Validation loss: 2.5865077935288032

Epoch: 5| Step: 5
Training loss: 1.9476952112419375
Validation loss: 2.603565477113132

Epoch: 5| Step: 6
Training loss: 1.3436191850018795
Validation loss: 2.578512198121457

Epoch: 5| Step: 7
Training loss: 0.8315937521766323
Validation loss: 2.5925453562330887

Epoch: 5| Step: 8
Training loss: 1.3854901956344177
Validation loss: 2.607545569589383

Epoch: 5| Step: 9
Training loss: 1.5925088425275518
Validation loss: 2.622238318847991

Epoch: 5| Step: 10
Training loss: 1.57031166494167
Validation loss: 2.6374131146833895

Epoch: 223| Step: 0
Training loss: 1.1677685824438608
Validation loss: 2.6457915402510097

Epoch: 5| Step: 1
Training loss: 1.5959565091051442
Validation loss: 2.6543361710982576

Epoch: 5| Step: 2
Training loss: 1.7056296593758644
Validation loss: 2.677715341985584

Epoch: 5| Step: 3
Training loss: 1.1676261680114477
Validation loss: 2.657592684056864

Epoch: 5| Step: 4
Training loss: 1.5776933136272124
Validation loss: 2.6530431055918675

Epoch: 5| Step: 5
Training loss: 1.2065739428914466
Validation loss: 2.625712943934833

Epoch: 5| Step: 6
Training loss: 1.1627255128731513
Validation loss: 2.6301780683509737

Epoch: 5| Step: 7
Training loss: 1.566539730178206
Validation loss: 2.629125477494341

Epoch: 5| Step: 8
Training loss: 1.3690152403357256
Validation loss: 2.6294254271266113

Epoch: 5| Step: 9
Training loss: 1.7354384589992682
Validation loss: 2.595203706395251

Epoch: 5| Step: 10
Training loss: 1.6760787166327735
Validation loss: 2.5901863038518615

Epoch: 224| Step: 0
Training loss: 1.5544748592165785
Validation loss: 2.5886086722885504

Epoch: 5| Step: 1
Training loss: 1.2609528853790744
Validation loss: 2.57028724460267

Epoch: 5| Step: 2
Training loss: 1.383782859901413
Validation loss: 2.584883498346623

Epoch: 5| Step: 3
Training loss: 1.4878510581814925
Validation loss: 2.592463406397209

Epoch: 5| Step: 4
Training loss: 1.1683559732696895
Validation loss: 2.6234779168980977

Epoch: 5| Step: 5
Training loss: 1.521035046025098
Validation loss: 2.689025955079142

Epoch: 5| Step: 6
Training loss: 1.1667960413089171
Validation loss: 2.729873989840175

Epoch: 5| Step: 7
Training loss: 1.4244239512824335
Validation loss: 2.7091487325971175

Epoch: 5| Step: 8
Training loss: 1.0460456865592156
Validation loss: 2.7019891751439307

Epoch: 5| Step: 9
Training loss: 2.1226944477349594
Validation loss: 2.707201708194419

Epoch: 5| Step: 10
Training loss: 1.6187449156928027
Validation loss: 2.6944881634480846

Epoch: 225| Step: 0
Training loss: 1.4397255628061585
Validation loss: 2.671072170939648

Epoch: 5| Step: 1
Training loss: 1.455766143966114
Validation loss: 2.6348648521471114

Epoch: 5| Step: 2
Training loss: 1.6257134118653636
Validation loss: 2.616419784356128

Epoch: 5| Step: 3
Training loss: 1.4481921402765212
Validation loss: 2.600827819267118

Epoch: 5| Step: 4
Training loss: 1.4475866623204217
Validation loss: 2.608272214087804

Epoch: 5| Step: 5
Training loss: 1.5342692756355716
Validation loss: 2.600019678470489

Epoch: 5| Step: 6
Training loss: 1.4012397947458728
Validation loss: 2.6233887989288873

Epoch: 5| Step: 7
Training loss: 1.3840703039063427
Validation loss: 2.6114609449134587

Epoch: 5| Step: 8
Training loss: 1.4830185967049123
Validation loss: 2.6395432907742262

Epoch: 5| Step: 9
Training loss: 1.1197375558007083
Validation loss: 2.646508804448894

Epoch: 5| Step: 10
Training loss: 1.2783100544493877
Validation loss: 2.6736090698220187

Epoch: 226| Step: 0
Training loss: 1.5139766263278764
Validation loss: 2.6946311428317085

Epoch: 5| Step: 1
Training loss: 1.2501259740294148
Validation loss: 2.670460039736396

Epoch: 5| Step: 2
Training loss: 1.2847851620398083
Validation loss: 2.696355649287827

Epoch: 5| Step: 3
Training loss: 1.3306404079192011
Validation loss: 2.711877594445528

Epoch: 5| Step: 4
Training loss: 1.3882734153582303
Validation loss: 2.6783266860243655

Epoch: 5| Step: 5
Training loss: 1.2026034624316022
Validation loss: 2.691602412245854

Epoch: 5| Step: 6
Training loss: 1.715620416798402
Validation loss: 2.664795507156324

Epoch: 5| Step: 7
Training loss: 0.8467062271692929
Validation loss: 2.663601935663825

Epoch: 5| Step: 8
Training loss: 1.5044623597679732
Validation loss: 2.665367627859615

Epoch: 5| Step: 9
Training loss: 1.9358549825525442
Validation loss: 2.6457415041508225

Epoch: 5| Step: 10
Training loss: 1.1911175487492216
Validation loss: 2.645160414745367

Epoch: 227| Step: 0
Training loss: 1.8079176230104614
Validation loss: 2.625054061497027

Epoch: 5| Step: 1
Training loss: 1.1669965799799658
Validation loss: 2.6303828360754493

Epoch: 5| Step: 2
Training loss: 1.353145576302984
Validation loss: 2.614945000385573

Epoch: 5| Step: 3
Training loss: 1.5197201491278054
Validation loss: 2.613758425878079

Epoch: 5| Step: 4
Training loss: 1.4543834692262119
Validation loss: 2.6364225910811254

Epoch: 5| Step: 5
Training loss: 1.3921553945211007
Validation loss: 2.6270051252576176

Epoch: 5| Step: 6
Training loss: 0.9128838136914273
Validation loss: 2.638966095044492

Epoch: 5| Step: 7
Training loss: 0.988176453352825
Validation loss: 2.651524731576524

Epoch: 5| Step: 8
Training loss: 1.7309186707887965
Validation loss: 2.6358329983658058

Epoch: 5| Step: 9
Training loss: 1.5455314889919183
Validation loss: 2.656094380886528

Epoch: 5| Step: 10
Training loss: 1.208591674723998
Validation loss: 2.652819590543345

Epoch: 228| Step: 0
Training loss: 1.1206409457040813
Validation loss: 2.626044486989569

Epoch: 5| Step: 1
Training loss: 1.831209433565218
Validation loss: 2.590463169052107

Epoch: 5| Step: 2
Training loss: 1.2445909771952177
Validation loss: 2.5814075056327606

Epoch: 5| Step: 3
Training loss: 1.2950339060288276
Validation loss: 2.5861098373303797

Epoch: 5| Step: 4
Training loss: 1.677890828024226
Validation loss: 2.5878018610988063

Epoch: 5| Step: 5
Training loss: 1.294406379750353
Validation loss: 2.584965781213091

Epoch: 5| Step: 6
Training loss: 1.17831700022779
Validation loss: 2.6248174409528486

Epoch: 5| Step: 7
Training loss: 1.2439124169045264
Validation loss: 2.62984857493927

Epoch: 5| Step: 8
Training loss: 0.7790862829049375
Validation loss: 2.602238723979612

Epoch: 5| Step: 9
Training loss: 1.5418275113441027
Validation loss: 2.6346530312983085

Epoch: 5| Step: 10
Training loss: 1.7570539406023247
Validation loss: 2.617343455801255

Epoch: 229| Step: 0
Training loss: 1.770361093121873
Validation loss: 2.6191193681002836

Epoch: 5| Step: 1
Training loss: 1.4839129080035083
Validation loss: 2.618737113815792

Epoch: 5| Step: 2
Training loss: 1.0183694585104144
Validation loss: 2.648411246253802

Epoch: 5| Step: 3
Training loss: 1.2885810184046391
Validation loss: 2.6098632463787315

Epoch: 5| Step: 4
Training loss: 1.7430400045578454
Validation loss: 2.6275614894528663

Epoch: 5| Step: 5
Training loss: 1.5819144500190125
Validation loss: 2.6130980792515563

Epoch: 5| Step: 6
Training loss: 1.1769822282608113
Validation loss: 2.610109489767961

Epoch: 5| Step: 7
Training loss: 0.8804727792859224
Validation loss: 2.618695102850166

Epoch: 5| Step: 8
Training loss: 1.1937593829200641
Validation loss: 2.6039310448812953

Epoch: 5| Step: 9
Training loss: 1.2427843207602642
Validation loss: 2.6158521605159155

Epoch: 5| Step: 10
Training loss: 1.4151608748358824
Validation loss: 2.62433772270742

Epoch: 230| Step: 0
Training loss: 1.5145373817130032
Validation loss: 2.623442085479681

Epoch: 5| Step: 1
Training loss: 1.530609853411772
Validation loss: 2.6022015297055554

Epoch: 5| Step: 2
Training loss: 1.48086252737955
Validation loss: 2.575533342666496

Epoch: 5| Step: 3
Training loss: 1.5713857143304772
Validation loss: 2.623898386835435

Epoch: 5| Step: 4
Training loss: 1.2113650643855745
Validation loss: 2.616947275327281

Epoch: 5| Step: 5
Training loss: 1.0361297060877679
Validation loss: 2.6267650118021058

Epoch: 5| Step: 6
Training loss: 1.2362414385399816
Validation loss: 2.601128591733873

Epoch: 5| Step: 7
Training loss: 1.322320889060454
Validation loss: 2.58158563197057

Epoch: 5| Step: 8
Training loss: 1.2143126673071247
Validation loss: 2.5854518320179114

Epoch: 5| Step: 9
Training loss: 1.2596105672348825
Validation loss: 2.631534599665613

Epoch: 5| Step: 10
Training loss: 1.5594578692293963
Validation loss: 2.606045726184471

Epoch: 231| Step: 0
Training loss: 2.236976869261468
Validation loss: 2.628311257381207

Epoch: 5| Step: 1
Training loss: 0.8989850573289755
Validation loss: 2.652097885241035

Epoch: 5| Step: 2
Training loss: 1.318679070034136
Validation loss: 2.6612078873926572

Epoch: 5| Step: 3
Training loss: 1.4591429597390986
Validation loss: 2.6247852294223892

Epoch: 5| Step: 4
Training loss: 1.4641878414341727
Validation loss: 2.5801827858019895

Epoch: 5| Step: 5
Training loss: 1.1388473244709274
Validation loss: 2.5680676313946647

Epoch: 5| Step: 6
Training loss: 0.9899084092649016
Validation loss: 2.586804891261697

Epoch: 5| Step: 7
Training loss: 1.3781934414085448
Validation loss: 2.5917924179475405

Epoch: 5| Step: 8
Training loss: 1.2913693219101492
Validation loss: 2.6181685285130865

Epoch: 5| Step: 9
Training loss: 1.3190976484650077
Validation loss: 2.6231367683603555

Epoch: 5| Step: 10
Training loss: 0.9634916275365385
Validation loss: 2.6667337223307728

Epoch: 232| Step: 0
Training loss: 1.7223622596713035
Validation loss: 2.63436382008483

Epoch: 5| Step: 1
Training loss: 0.91086943357381
Validation loss: 2.630714569709736

Epoch: 5| Step: 2
Training loss: 1.0562426369314484
Validation loss: 2.6295644645596234

Epoch: 5| Step: 3
Training loss: 1.4652256989025156
Validation loss: 2.6296322222794495

Epoch: 5| Step: 4
Training loss: 1.5699537636089782
Validation loss: 2.588369514361366

Epoch: 5| Step: 5
Training loss: 0.9704191533197821
Validation loss: 2.561825299022474

Epoch: 5| Step: 6
Training loss: 1.5779487586990764
Validation loss: 2.5779273908598337

Epoch: 5| Step: 7
Training loss: 0.7896528018865717
Validation loss: 2.5516927119233985

Epoch: 5| Step: 8
Training loss: 1.2452890314932503
Validation loss: 2.572098984222274

Epoch: 5| Step: 9
Training loss: 1.239223085943459
Validation loss: 2.6018661474066795

Epoch: 5| Step: 10
Training loss: 1.8014815617532798
Validation loss: 2.5840702649822846

Epoch: 233| Step: 0
Training loss: 1.039071219271452
Validation loss: 2.589142018397393

Epoch: 5| Step: 1
Training loss: 1.8307917128867313
Validation loss: 2.591335958768411

Epoch: 5| Step: 2
Training loss: 1.5586464473831336
Validation loss: 2.590425138174652

Epoch: 5| Step: 3
Training loss: 1.5493106355027653
Validation loss: 2.574785291730642

Epoch: 5| Step: 4
Training loss: 1.175382730363048
Validation loss: 2.584751486822852

Epoch: 5| Step: 5
Training loss: 1.3973863369844985
Validation loss: 2.5955152280704827

Epoch: 5| Step: 6
Training loss: 1.2137383341204062
Validation loss: 2.5841583862303237

Epoch: 5| Step: 7
Training loss: 1.1451919263210695
Validation loss: 2.5892903199036947

Epoch: 5| Step: 8
Training loss: 0.9283686025986416
Validation loss: 2.5963353786767285

Epoch: 5| Step: 9
Training loss: 1.218666807416397
Validation loss: 2.6277845939412487

Epoch: 5| Step: 10
Training loss: 1.391151328619307
Validation loss: 2.609108300936348

Epoch: 234| Step: 0
Training loss: 1.588723127496508
Validation loss: 2.66547765937353

Epoch: 5| Step: 1
Training loss: 1.7193504671754507
Validation loss: 2.6451581294143165

Epoch: 5| Step: 2
Training loss: 1.738554515147363
Validation loss: 2.6385379200217343

Epoch: 5| Step: 3
Training loss: 1.0523651551333166
Validation loss: 2.646168642418019

Epoch: 5| Step: 4
Training loss: 1.014537170007478
Validation loss: 2.5708609893840837

Epoch: 5| Step: 5
Training loss: 1.4092786176589982
Validation loss: 2.578420086800263

Epoch: 5| Step: 6
Training loss: 1.3205190643702325
Validation loss: 2.586992852016601

Epoch: 5| Step: 7
Training loss: 1.2462393935659972
Validation loss: 2.632661601096276

Epoch: 5| Step: 8
Training loss: 1.0590836070758216
Validation loss: 2.674115035292912

Epoch: 5| Step: 9
Training loss: 1.252884207633745
Validation loss: 2.6733845537033414

Epoch: 5| Step: 10
Training loss: 1.1152895831925207
Validation loss: 2.693450177821443

Epoch: 235| Step: 0
Training loss: 1.2154238870375962
Validation loss: 2.6743677956847915

Epoch: 5| Step: 1
Training loss: 1.256803593667694
Validation loss: 2.696267745404939

Epoch: 5| Step: 2
Training loss: 1.355461274491949
Validation loss: 2.685768691581673

Epoch: 5| Step: 3
Training loss: 1.7748296038009046
Validation loss: 2.6933574751315454

Epoch: 5| Step: 4
Training loss: 1.344896182552459
Validation loss: 2.6579765658533407

Epoch: 5| Step: 5
Training loss: 0.9918877456701848
Validation loss: 2.6329553438243627

Epoch: 5| Step: 6
Training loss: 1.5681115663697272
Validation loss: 2.657952294853995

Epoch: 5| Step: 7
Training loss: 1.1530659626886999
Validation loss: 2.5887535432550353

Epoch: 5| Step: 8
Training loss: 1.1165008035051296
Validation loss: 2.5762703915518737

Epoch: 5| Step: 9
Training loss: 0.9335898235669426
Validation loss: 2.591035593059905

Epoch: 5| Step: 10
Training loss: 1.5568770895522408
Validation loss: 2.5945584519455585

Epoch: 236| Step: 0
Training loss: 1.1886375399722466
Validation loss: 2.5957008692113086

Epoch: 5| Step: 1
Training loss: 1.8834269300625945
Validation loss: 2.621552809040912

Epoch: 5| Step: 2
Training loss: 1.2179968047076626
Validation loss: 2.6453923345659787

Epoch: 5| Step: 3
Training loss: 1.3429905275506449
Validation loss: 2.6603471980991924

Epoch: 5| Step: 4
Training loss: 1.0767248155896054
Validation loss: 2.682987025912247

Epoch: 5| Step: 5
Training loss: 1.2226103752719406
Validation loss: 2.659301952154458

Epoch: 5| Step: 6
Training loss: 1.046666935983449
Validation loss: 2.669889853327363

Epoch: 5| Step: 7
Training loss: 1.12951042085377
Validation loss: 2.6793594956054014

Epoch: 5| Step: 8
Training loss: 1.0866987455543866
Validation loss: 2.6325513967618277

Epoch: 5| Step: 9
Training loss: 1.7931719230610033
Validation loss: 2.637195410201998

Epoch: 5| Step: 10
Training loss: 1.000304295018494
Validation loss: 2.612231894256993

Epoch: 237| Step: 0
Training loss: 0.8705184816045165
Validation loss: 2.594402326088263

Epoch: 5| Step: 1
Training loss: 1.2260841360112653
Validation loss: 2.5880502946802553

Epoch: 5| Step: 2
Training loss: 1.108961323723257
Validation loss: 2.578024900102165

Epoch: 5| Step: 3
Training loss: 0.8258678697613427
Validation loss: 2.5946046034375603

Epoch: 5| Step: 4
Training loss: 1.0938364812176073
Validation loss: 2.609051243252771

Epoch: 5| Step: 5
Training loss: 1.4851536364986375
Validation loss: 2.6072078589810417

Epoch: 5| Step: 6
Training loss: 1.4406483215959869
Validation loss: 2.6439390037504555

Epoch: 5| Step: 7
Training loss: 1.6766706476233806
Validation loss: 2.657595192139667

Epoch: 5| Step: 8
Training loss: 1.428166148054124
Validation loss: 2.6351303035148375

Epoch: 5| Step: 9
Training loss: 1.1269348248825577
Validation loss: 2.609157981343901

Epoch: 5| Step: 10
Training loss: 1.5961881948528034
Validation loss: 2.5893231343789718

Epoch: 238| Step: 0
Training loss: 1.3332039601423686
Validation loss: 2.601617624002526

Epoch: 5| Step: 1
Training loss: 1.1643538142522631
Validation loss: 2.5883960086604394

Epoch: 5| Step: 2
Training loss: 1.4951534653042815
Validation loss: 2.5746816471989518

Epoch: 5| Step: 3
Training loss: 1.1372828181930512
Validation loss: 2.5850027692683213

Epoch: 5| Step: 4
Training loss: 1.3965717848517993
Validation loss: 2.5665103445910815

Epoch: 5| Step: 5
Training loss: 0.9155630526890266
Validation loss: 2.5490925371164144

Epoch: 5| Step: 6
Training loss: 0.9802240925142629
Validation loss: 2.5630619364345106

Epoch: 5| Step: 7
Training loss: 1.6938843930687564
Validation loss: 2.5983945456293704

Epoch: 5| Step: 8
Training loss: 1.2883144635788055
Validation loss: 2.6007028539205743

Epoch: 5| Step: 9
Training loss: 1.0640465196034086
Validation loss: 2.639647634313069

Epoch: 5| Step: 10
Training loss: 1.3379571383015938
Validation loss: 2.661127926311239

Epoch: 239| Step: 0
Training loss: 1.2794639420073919
Validation loss: 2.6449660586007315

Epoch: 5| Step: 1
Training loss: 1.0255591263151522
Validation loss: 2.6655464383044696

Epoch: 5| Step: 2
Training loss: 1.4024034662734834
Validation loss: 2.6466502755748786

Epoch: 5| Step: 3
Training loss: 1.3649685536769174
Validation loss: 2.6336815393804907

Epoch: 5| Step: 4
Training loss: 1.612572465791221
Validation loss: 2.6399880442157495

Epoch: 5| Step: 5
Training loss: 1.073084728571751
Validation loss: 2.5893627997056927

Epoch: 5| Step: 6
Training loss: 1.235422004229298
Validation loss: 2.586759815158994

Epoch: 5| Step: 7
Training loss: 1.3342997456040677
Validation loss: 2.564245438409105

Epoch: 5| Step: 8
Training loss: 1.0178879981754028
Validation loss: 2.591472913570735

Epoch: 5| Step: 9
Training loss: 1.3935206836168703
Validation loss: 2.610603609673241

Epoch: 5| Step: 10
Training loss: 1.0040329433902873
Validation loss: 2.5813977263874848

Epoch: 240| Step: 0
Training loss: 0.8366012789972511
Validation loss: 2.609884906749307

Epoch: 5| Step: 1
Training loss: 0.8294694531376711
Validation loss: 2.600024214104098

Epoch: 5| Step: 2
Training loss: 1.2822644009494535
Validation loss: 2.634103467222151

Epoch: 5| Step: 3
Training loss: 1.1788201080055722
Validation loss: 2.6323948041937246

Epoch: 5| Step: 4
Training loss: 1.5425220470614922
Validation loss: 2.629018338968893

Epoch: 5| Step: 5
Training loss: 1.2184801536543581
Validation loss: 2.5834112182081035

Epoch: 5| Step: 6
Training loss: 1.6293593400876492
Validation loss: 2.605816375605256

Epoch: 5| Step: 7
Training loss: 1.625925094202309
Validation loss: 2.6234591669668874

Epoch: 5| Step: 8
Training loss: 1.3540484547981597
Validation loss: 2.617786402738467

Epoch: 5| Step: 9
Training loss: 0.9552277055867721
Validation loss: 2.6395862611736147

Epoch: 5| Step: 10
Training loss: 0.870185789407294
Validation loss: 2.626757507567462

Epoch: 241| Step: 0
Training loss: 1.0087738183670931
Validation loss: 2.6112967543483605

Epoch: 5| Step: 1
Training loss: 1.106078394279258
Validation loss: 2.5850498663879677

Epoch: 5| Step: 2
Training loss: 0.9399002819230101
Validation loss: 2.5818630332064854

Epoch: 5| Step: 3
Training loss: 1.351460623898228
Validation loss: 2.571838720711675

Epoch: 5| Step: 4
Training loss: 1.459862461405006
Validation loss: 2.5426854892816335

Epoch: 5| Step: 5
Training loss: 1.3115337084540584
Validation loss: 2.545971646109828

Epoch: 5| Step: 6
Training loss: 1.331949270639879
Validation loss: 2.564356423823514

Epoch: 5| Step: 7
Training loss: 1.227799150564742
Validation loss: 2.5817591912138966

Epoch: 5| Step: 8
Training loss: 1.3121831602318685
Validation loss: 2.564603944764607

Epoch: 5| Step: 9
Training loss: 1.0400380309193828
Validation loss: 2.5871687140563817

Epoch: 5| Step: 10
Training loss: 1.3775048848115743
Validation loss: 2.591404511765431

Epoch: 242| Step: 0
Training loss: 1.1157189166717965
Validation loss: 2.5833612679338334

Epoch: 5| Step: 1
Training loss: 1.2160496261847689
Validation loss: 2.60694532707895

Epoch: 5| Step: 2
Training loss: 1.183310647979852
Validation loss: 2.6275610533270273

Epoch: 5| Step: 3
Training loss: 1.13753063663684
Validation loss: 2.6123233717598193

Epoch: 5| Step: 4
Training loss: 1.1524530391269239
Validation loss: 2.654695147239372

Epoch: 5| Step: 5
Training loss: 1.2492764286087825
Validation loss: 2.637322192489134

Epoch: 5| Step: 6
Training loss: 1.1832403278515673
Validation loss: 2.6350475907093407

Epoch: 5| Step: 7
Training loss: 0.7350205364083071
Validation loss: 2.6436108501764686

Epoch: 5| Step: 8
Training loss: 1.6049335265134745
Validation loss: 2.61737056723109

Epoch: 5| Step: 9
Training loss: 1.280824078733474
Validation loss: 2.6211765627660943

Epoch: 5| Step: 10
Training loss: 1.449553088670991
Validation loss: 2.6011141666306687

Epoch: 243| Step: 0
Training loss: 1.46558485484502
Validation loss: 2.607844776901564

Epoch: 5| Step: 1
Training loss: 1.0895477221026226
Validation loss: 2.624606248004588

Epoch: 5| Step: 2
Training loss: 1.3842253713926311
Validation loss: 2.629249284029072

Epoch: 5| Step: 3
Training loss: 0.9561381318223776
Validation loss: 2.625346444624728

Epoch: 5| Step: 4
Training loss: 1.2002722371764194
Validation loss: 2.6391726458033142

Epoch: 5| Step: 5
Training loss: 1.1766205387061295
Validation loss: 2.626045554992148

Epoch: 5| Step: 6
Training loss: 1.1687458221850464
Validation loss: 2.6340269112547543

Epoch: 5| Step: 7
Training loss: 1.1789113200731507
Validation loss: 2.6091511466839283

Epoch: 5| Step: 8
Training loss: 0.81630169504689
Validation loss: 2.587545663847702

Epoch: 5| Step: 9
Training loss: 1.5105231236616998
Validation loss: 2.56791725765579

Epoch: 5| Step: 10
Training loss: 1.1655399240327036
Validation loss: 2.5701572423560877

Epoch: 244| Step: 0
Training loss: 1.0751079416419733
Validation loss: 2.5598949744118653

Epoch: 5| Step: 1
Training loss: 0.8862080720956136
Validation loss: 2.552935823087279

Epoch: 5| Step: 2
Training loss: 1.3843780534766559
Validation loss: 2.557148449315522

Epoch: 5| Step: 3
Training loss: 1.1699554998950255
Validation loss: 2.5720123984369208

Epoch: 5| Step: 4
Training loss: 1.1742053449300842
Validation loss: 2.5578180971784166

Epoch: 5| Step: 5
Training loss: 1.0557957231004662
Validation loss: 2.589169037487172

Epoch: 5| Step: 6
Training loss: 1.1568086666336532
Validation loss: 2.5839147981818535

Epoch: 5| Step: 7
Training loss: 1.7672514049736523
Validation loss: 2.6334069029766383

Epoch: 5| Step: 8
Training loss: 1.0213428056400506
Validation loss: 2.6266083758548966

Epoch: 5| Step: 9
Training loss: 1.2974409683852275
Validation loss: 2.615157945027945

Epoch: 5| Step: 10
Training loss: 1.0621824912087527
Validation loss: 2.6406149963822414

Epoch: 245| Step: 0
Training loss: 0.908820977830128
Validation loss: 2.6257379425328393

Epoch: 5| Step: 1
Training loss: 0.9955267395651148
Validation loss: 2.597838753953769

Epoch: 5| Step: 2
Training loss: 1.0464975616091312
Validation loss: 2.600748336974523

Epoch: 5| Step: 3
Training loss: 1.531943650685936
Validation loss: 2.60934795728895

Epoch: 5| Step: 4
Training loss: 1.0387773050697118
Validation loss: 2.556157148279336

Epoch: 5| Step: 5
Training loss: 1.7259318723350277
Validation loss: 2.576091905648042

Epoch: 5| Step: 6
Training loss: 0.7902251638572393
Validation loss: 2.5849951864427703

Epoch: 5| Step: 7
Training loss: 1.1499997885330668
Validation loss: 2.601432181385694

Epoch: 5| Step: 8
Training loss: 0.9295124241725505
Validation loss: 2.609466892034486

Epoch: 5| Step: 9
Training loss: 1.2044194181731032
Validation loss: 2.617395291430983

Epoch: 5| Step: 10
Training loss: 1.3800244430782185
Validation loss: 2.6655355962575094

Epoch: 246| Step: 0
Training loss: 1.133228094226269
Validation loss: 2.6784468161157764

Epoch: 5| Step: 1
Training loss: 1.0033161492212144
Validation loss: 2.652883331455779

Epoch: 5| Step: 2
Training loss: 0.903766155019387
Validation loss: 2.620223501222988

Epoch: 5| Step: 3
Training loss: 1.4164589654840936
Validation loss: 2.60780529438359

Epoch: 5| Step: 4
Training loss: 1.3137864211793173
Validation loss: 2.6015312244432645

Epoch: 5| Step: 5
Training loss: 1.61295838161729
Validation loss: 2.5433574951677382

Epoch: 5| Step: 6
Training loss: 1.2436684471498654
Validation loss: 2.555975177633129

Epoch: 5| Step: 7
Training loss: 1.078590513708329
Validation loss: 2.564559593046485

Epoch: 5| Step: 8
Training loss: 1.092503464036421
Validation loss: 2.558774673789643

Epoch: 5| Step: 9
Training loss: 0.8252472449218838
Validation loss: 2.557057347489751

Epoch: 5| Step: 10
Training loss: 1.1420268497651058
Validation loss: 2.607594636794395

Epoch: 247| Step: 0
Training loss: 1.161554181487619
Validation loss: 2.5850132171873086

Epoch: 5| Step: 1
Training loss: 1.222348012857027
Validation loss: 2.5984767183407596

Epoch: 5| Step: 2
Training loss: 0.9772294475456261
Validation loss: 2.571655144683766

Epoch: 5| Step: 3
Training loss: 0.9788777790967851
Validation loss: 2.592564647652218

Epoch: 5| Step: 4
Training loss: 1.4834715653777877
Validation loss: 2.6018099970295845

Epoch: 5| Step: 5
Training loss: 1.083271844048067
Validation loss: 2.638469890612199

Epoch: 5| Step: 6
Training loss: 0.8959108733101436
Validation loss: 2.604577053753588

Epoch: 5| Step: 7
Training loss: 1.179788597777009
Validation loss: 2.585570475862636

Epoch: 5| Step: 8
Training loss: 1.0268929076069921
Validation loss: 2.5810257767193585

Epoch: 5| Step: 9
Training loss: 1.6267116042220104
Validation loss: 2.5832039939292746

Epoch: 5| Step: 10
Training loss: 0.9924093884440285
Validation loss: 2.5796735690019053

Epoch: 248| Step: 0
Training loss: 1.3300341180139617
Validation loss: 2.6452875208192124

Epoch: 5| Step: 1
Training loss: 1.0552998213476592
Validation loss: 2.6565626477965534

Epoch: 5| Step: 2
Training loss: 1.2754929225490501
Validation loss: 2.6196351190587057

Epoch: 5| Step: 3
Training loss: 1.0523157083446923
Validation loss: 2.597809771407526

Epoch: 5| Step: 4
Training loss: 0.8674451428089133
Validation loss: 2.5768464817198145

Epoch: 5| Step: 5
Training loss: 1.1868053211330725
Validation loss: 2.577434973729925

Epoch: 5| Step: 6
Training loss: 1.022594016959528
Validation loss: 2.6162567300635815

Epoch: 5| Step: 7
Training loss: 1.5274136812635069
Validation loss: 2.6128809155494483

Epoch: 5| Step: 8
Training loss: 1.5274790828290332
Validation loss: 2.657761494934569

Epoch: 5| Step: 9
Training loss: 1.0360005516323256
Validation loss: 2.6781250322019585

Epoch: 5| Step: 10
Training loss: 0.9316252061379666
Validation loss: 2.672581013590307

Epoch: 249| Step: 0
Training loss: 0.7170017375845185
Validation loss: 2.684378579577696

Epoch: 5| Step: 1
Training loss: 1.5549563074873134
Validation loss: 2.697225625583005

Epoch: 5| Step: 2
Training loss: 0.9136926603786704
Validation loss: 2.692277558059027

Epoch: 5| Step: 3
Training loss: 1.2333190844116535
Validation loss: 2.6881267639981865

Epoch: 5| Step: 4
Training loss: 1.3876549797451758
Validation loss: 2.6677384632445755

Epoch: 5| Step: 5
Training loss: 1.1462485283662258
Validation loss: 2.646400942745659

Epoch: 5| Step: 6
Training loss: 0.7585156904419559
Validation loss: 2.6354621851823357

Epoch: 5| Step: 7
Training loss: 1.2548201133412322
Validation loss: 2.588483148725786

Epoch: 5| Step: 8
Training loss: 1.2674249165584364
Validation loss: 2.574783485581695

Epoch: 5| Step: 9
Training loss: 1.1172444255704304
Validation loss: 2.5692958941463

Epoch: 5| Step: 10
Training loss: 1.2185345972884063
Validation loss: 2.551083962553519

Epoch: 250| Step: 0
Training loss: 0.78063563031914
Validation loss: 2.5680023712578137

Epoch: 5| Step: 1
Training loss: 0.9806864219476294
Validation loss: 2.544738529724065

Epoch: 5| Step: 2
Training loss: 1.3804932018417986
Validation loss: 2.5387471836074242

Epoch: 5| Step: 3
Training loss: 1.0004873876162736
Validation loss: 2.542892424413352

Epoch: 5| Step: 4
Training loss: 0.8838192086320924
Validation loss: 2.5996576615684774

Epoch: 5| Step: 5
Training loss: 1.0144549158643823
Validation loss: 2.621733911571059

Epoch: 5| Step: 6
Training loss: 1.503446117210709
Validation loss: 2.644696882444877

Epoch: 5| Step: 7
Training loss: 1.193396884559719
Validation loss: 2.6521932257862155

Epoch: 5| Step: 8
Training loss: 0.918167871833694
Validation loss: 2.648300569555272

Epoch: 5| Step: 9
Training loss: 1.6195871729012368
Validation loss: 2.6435002382199593

Epoch: 5| Step: 10
Training loss: 0.9379296272045541
Validation loss: 2.62893860216866

Epoch: 251| Step: 0
Training loss: 1.3414674046239279
Validation loss: 2.60118164144243

Epoch: 5| Step: 1
Training loss: 0.8949048457363292
Validation loss: 2.599757158291221

Epoch: 5| Step: 2
Training loss: 1.4236604149610521
Validation loss: 2.5854241097264876

Epoch: 5| Step: 3
Training loss: 0.9717561777957305
Validation loss: 2.5969412838170927

Epoch: 5| Step: 4
Training loss: 1.1207069500618214
Validation loss: 2.6056266783910873

Epoch: 5| Step: 5
Training loss: 0.9525391701281144
Validation loss: 2.576262345179638

Epoch: 5| Step: 6
Training loss: 1.2743333812912847
Validation loss: 2.586115920011097

Epoch: 5| Step: 7
Training loss: 1.1924801848422704
Validation loss: 2.6214259506109534

Epoch: 5| Step: 8
Training loss: 0.8112074768254164
Validation loss: 2.6508465853944623

Epoch: 5| Step: 9
Training loss: 1.2355704976759412
Validation loss: 2.631014672393652

Epoch: 5| Step: 10
Training loss: 1.0037643985499414
Validation loss: 2.61542473588463

Epoch: 252| Step: 0
Training loss: 1.2495235011747872
Validation loss: 2.616733276152165

Epoch: 5| Step: 1
Training loss: 1.0710287551581472
Validation loss: 2.6006195567831947

Epoch: 5| Step: 2
Training loss: 1.3358541094536034
Validation loss: 2.5784773052956935

Epoch: 5| Step: 3
Training loss: 1.3270987191897816
Validation loss: 2.5988665218528584

Epoch: 5| Step: 4
Training loss: 0.976026952762223
Validation loss: 2.5848499897865747

Epoch: 5| Step: 5
Training loss: 0.8629211088833991
Validation loss: 2.5829811597115424

Epoch: 5| Step: 6
Training loss: 0.7050339957082709
Validation loss: 2.5513972167292778

Epoch: 5| Step: 7
Training loss: 1.407240582302972
Validation loss: 2.560711570962171

Epoch: 5| Step: 8
Training loss: 1.2742714988506976
Validation loss: 2.5523787072435273

Epoch: 5| Step: 9
Training loss: 0.8146011986362847
Validation loss: 2.5505111529476143

Epoch: 5| Step: 10
Training loss: 0.927734342876233
Validation loss: 2.544198547485767

Epoch: 253| Step: 0
Training loss: 1.1433087482719277
Validation loss: 2.5358231582133635

Epoch: 5| Step: 1
Training loss: 0.7617444938808713
Validation loss: 2.5828286755422085

Epoch: 5| Step: 2
Training loss: 1.0112061251257136
Validation loss: 2.5658325247277443

Epoch: 5| Step: 3
Training loss: 0.4337135527465878
Validation loss: 2.5658305074517034

Epoch: 5| Step: 4
Training loss: 1.754447802428423
Validation loss: 2.6301711859689676

Epoch: 5| Step: 5
Training loss: 1.2342025539805102
Validation loss: 2.60289979862742

Epoch: 5| Step: 6
Training loss: 1.1883846802249511
Validation loss: 2.6019736984955433

Epoch: 5| Step: 7
Training loss: 1.1509782880132207
Validation loss: 2.605191811543075

Epoch: 5| Step: 8
Training loss: 0.910469950695958
Validation loss: 2.627561415301722

Epoch: 5| Step: 9
Training loss: 1.1100131066725578
Validation loss: 2.623671733253587

Epoch: 5| Step: 10
Training loss: 0.9030664035570978
Validation loss: 2.6472502242794307

Epoch: 254| Step: 0
Training loss: 1.0956427953638237
Validation loss: 2.632968331632217

Epoch: 5| Step: 1
Training loss: 1.1560937930603472
Validation loss: 2.6523412466169525

Epoch: 5| Step: 2
Training loss: 0.8744222572868006
Validation loss: 2.6235368306307745

Epoch: 5| Step: 3
Training loss: 1.2338013583608203
Validation loss: 2.638372798755594

Epoch: 5| Step: 4
Training loss: 1.050578555159012
Validation loss: 2.603596208336423

Epoch: 5| Step: 5
Training loss: 1.073924020736457
Validation loss: 2.586560503821728

Epoch: 5| Step: 6
Training loss: 0.8867382770018316
Validation loss: 2.582426097105366

Epoch: 5| Step: 7
Training loss: 1.5900674048717314
Validation loss: 2.574049857322989

Epoch: 5| Step: 8
Training loss: 0.7485369080723956
Validation loss: 2.573244104320255

Epoch: 5| Step: 9
Training loss: 0.9912787052534482
Validation loss: 2.5659055432577014

Epoch: 5| Step: 10
Training loss: 1.1432398778924857
Validation loss: 2.6003251357175228

Epoch: 255| Step: 0
Training loss: 1.2997654336437467
Validation loss: 2.5438013172035108

Epoch: 5| Step: 1
Training loss: 1.1986368364176743
Validation loss: 2.5733568076531044

Epoch: 5| Step: 2
Training loss: 0.9370864591861582
Validation loss: 2.5522370630957987

Epoch: 5| Step: 3
Training loss: 0.9057694838363242
Validation loss: 2.5893700737119834

Epoch: 5| Step: 4
Training loss: 1.1837179288779462
Validation loss: 2.5825926611711947

Epoch: 5| Step: 5
Training loss: 0.8944654815350763
Validation loss: 2.573124075143005

Epoch: 5| Step: 6
Training loss: 1.0144098495166172
Validation loss: 2.5845933858641885

Epoch: 5| Step: 7
Training loss: 0.8979629590226271
Validation loss: 2.5725845043456754

Epoch: 5| Step: 8
Training loss: 0.9232323885099661
Validation loss: 2.582897275177796

Epoch: 5| Step: 9
Training loss: 1.0354477957658452
Validation loss: 2.584580590410079

Epoch: 5| Step: 10
Training loss: 1.4767119316901882
Validation loss: 2.6122118029882833

Epoch: 256| Step: 0
Training loss: 1.4909902033288915
Validation loss: 2.577996238259929

Epoch: 5| Step: 1
Training loss: 0.790875834604917
Validation loss: 2.5729020304166217

Epoch: 5| Step: 2
Training loss: 1.0098819628755358
Validation loss: 2.585518895570779

Epoch: 5| Step: 3
Training loss: 0.665585846264274
Validation loss: 2.59096477286339

Epoch: 5| Step: 4
Training loss: 1.0280618224980396
Validation loss: 2.5999531018537096

Epoch: 5| Step: 5
Training loss: 0.9843819633116498
Validation loss: 2.611427101971977

Epoch: 5| Step: 6
Training loss: 1.7019886110330416
Validation loss: 2.6452042398022266

Epoch: 5| Step: 7
Training loss: 1.0021912289994048
Validation loss: 2.620515876451178

Epoch: 5| Step: 8
Training loss: 0.9921331916423803
Validation loss: 2.646484252944215

Epoch: 5| Step: 9
Training loss: 0.8465256072292886
Validation loss: 2.60922681134574

Epoch: 5| Step: 10
Training loss: 0.8033466092736685
Validation loss: 2.6287345299286455

Epoch: 257| Step: 0
Training loss: 1.099558312431466
Validation loss: 2.6388997048755596

Epoch: 5| Step: 1
Training loss: 1.0423218510402656
Validation loss: 2.6125563833530077

Epoch: 5| Step: 2
Training loss: 0.815932323391176
Validation loss: 2.633501750077118

Epoch: 5| Step: 3
Training loss: 1.5629011020819314
Validation loss: 2.6295927549190314

Epoch: 5| Step: 4
Training loss: 0.9205953153756649
Validation loss: 2.641426018815456

Epoch: 5| Step: 5
Training loss: 0.9906995233849785
Validation loss: 2.6226027285575912

Epoch: 5| Step: 6
Training loss: 0.831843789344161
Validation loss: 2.613196559491214

Epoch: 5| Step: 7
Training loss: 0.7707531904537502
Validation loss: 2.60550570330706

Epoch: 5| Step: 8
Training loss: 1.2866865050972176
Validation loss: 2.584909788367209

Epoch: 5| Step: 9
Training loss: 1.1203607695115327
Validation loss: 2.577282002268962

Epoch: 5| Step: 10
Training loss: 1.0226258415439726
Validation loss: 2.570922376256349

Epoch: 258| Step: 0
Training loss: 1.3989325984236163
Validation loss: 2.5885288425307067

Epoch: 5| Step: 1
Training loss: 0.7454597215779375
Validation loss: 2.59084884583129

Epoch: 5| Step: 2
Training loss: 0.9773623128541513
Validation loss: 2.619066508469678

Epoch: 5| Step: 3
Training loss: 0.9719956080922247
Validation loss: 2.5965723505633105

Epoch: 5| Step: 4
Training loss: 0.5045198652271268
Validation loss: 2.639233286443556

Epoch: 5| Step: 5
Training loss: 0.9808467121286761
Validation loss: 2.5993239793116523

Epoch: 5| Step: 6
Training loss: 1.4493320143207302
Validation loss: 2.6051064388320917

Epoch: 5| Step: 7
Training loss: 0.9943769732347207
Validation loss: 2.6433950138885933

Epoch: 5| Step: 8
Training loss: 0.9960062923558184
Validation loss: 2.6040506631588993

Epoch: 5| Step: 9
Training loss: 1.0520403950808044
Validation loss: 2.6237072972285422

Epoch: 5| Step: 10
Training loss: 1.1554138665773506
Validation loss: 2.6203964942072697

Epoch: 259| Step: 0
Training loss: 1.4461481101660594
Validation loss: 2.6314811399053406

Epoch: 5| Step: 1
Training loss: 0.9628352522645748
Validation loss: 2.6172974432533778

Epoch: 5| Step: 2
Training loss: 1.2935765154709127
Validation loss: 2.5902276810702536

Epoch: 5| Step: 3
Training loss: 0.878886379441179
Validation loss: 2.571630813134121

Epoch: 5| Step: 4
Training loss: 0.5894613226237745
Validation loss: 2.5792409908373566

Epoch: 5| Step: 5
Training loss: 1.1327252584603977
Validation loss: 2.56279930969879

Epoch: 5| Step: 6
Training loss: 0.7145626161498982
Validation loss: 2.60059399339176

Epoch: 5| Step: 7
Training loss: 0.9410001899970387
Validation loss: 2.5662421517745897

Epoch: 5| Step: 8
Training loss: 1.127535082996561
Validation loss: 2.6168934058866573

Epoch: 5| Step: 9
Training loss: 1.0838368908325484
Validation loss: 2.5975416736930685

Epoch: 5| Step: 10
Training loss: 0.9925453261684066
Validation loss: 2.647658401645388

Epoch: 260| Step: 0
Training loss: 1.4704065923146605
Validation loss: 2.6225379046464736

Epoch: 5| Step: 1
Training loss: 1.0025751217024474
Validation loss: 2.608213057784114

Epoch: 5| Step: 2
Training loss: 0.801127103226916
Validation loss: 2.6277919596361827

Epoch: 5| Step: 3
Training loss: 1.0256266004513859
Validation loss: 2.5834875652889497

Epoch: 5| Step: 4
Training loss: 0.8991193423104445
Validation loss: 2.6124359946131457

Epoch: 5| Step: 5
Training loss: 1.0788807086283068
Validation loss: 2.593801058817576

Epoch: 5| Step: 6
Training loss: 0.4833583930797724
Validation loss: 2.6089811253158985

Epoch: 5| Step: 7
Training loss: 0.9993388851623162
Validation loss: 2.5787193769152026

Epoch: 5| Step: 8
Training loss: 0.9538328950187622
Validation loss: 2.5971278209886988

Epoch: 5| Step: 9
Training loss: 1.2770667286094681
Validation loss: 2.6248449835489533

Epoch: 5| Step: 10
Training loss: 1.0934593904522085
Validation loss: 2.620231565227297

Epoch: 261| Step: 0
Training loss: 1.0256006225627194
Validation loss: 2.627321346831527

Epoch: 5| Step: 1
Training loss: 0.7966988312707054
Validation loss: 2.605201899026522

Epoch: 5| Step: 2
Training loss: 1.1048502994991147
Validation loss: 2.56615187379679

Epoch: 5| Step: 3
Training loss: 1.0552458238986737
Validation loss: 2.5611174565724237

Epoch: 5| Step: 4
Training loss: 0.7689811948156089
Validation loss: 2.5884366290941063

Epoch: 5| Step: 5
Training loss: 1.1252104774251728
Validation loss: 2.5740746505345298

Epoch: 5| Step: 6
Training loss: 1.16623832582312
Validation loss: 2.5864814067576907

Epoch: 5| Step: 7
Training loss: 1.0254249784981908
Validation loss: 2.5968284929434353

Epoch: 5| Step: 8
Training loss: 0.9061617643876106
Validation loss: 2.5854794479158896

Epoch: 5| Step: 9
Training loss: 0.7565674927147709
Validation loss: 2.6254793472661504

Epoch: 5| Step: 10
Training loss: 1.4263918888481872
Validation loss: 2.6613331252699104

Epoch: 262| Step: 0
Training loss: 0.848689912514615
Validation loss: 2.682719461025807

Epoch: 5| Step: 1
Training loss: 1.3207101618058341
Validation loss: 2.7033960406989603

Epoch: 5| Step: 2
Training loss: 0.911536059017352
Validation loss: 2.672997641386904

Epoch: 5| Step: 3
Training loss: 0.7386058517636392
Validation loss: 2.6692288808979874

Epoch: 5| Step: 4
Training loss: 1.1867526362831626
Validation loss: 2.644373797274442

Epoch: 5| Step: 5
Training loss: 0.9419956499068132
Validation loss: 2.6323351294145425

Epoch: 5| Step: 6
Training loss: 1.4118759363314026
Validation loss: 2.6169193958823396

Epoch: 5| Step: 7
Training loss: 1.0935168971573286
Validation loss: 2.6590357129487208

Epoch: 5| Step: 8
Training loss: 0.8906825866820673
Validation loss: 2.6391561653116367

Epoch: 5| Step: 9
Training loss: 1.2398844067470247
Validation loss: 2.6207879802942133

Epoch: 5| Step: 10
Training loss: 0.6337886392976967
Validation loss: 2.618174165607525

Epoch: 263| Step: 0
Training loss: 0.9022332986716538
Validation loss: 2.6279356928942064

Epoch: 5| Step: 1
Training loss: 1.002768677264829
Validation loss: 2.647110081027

Epoch: 5| Step: 2
Training loss: 0.8718451094887341
Validation loss: 2.6596481225600166

Epoch: 5| Step: 3
Training loss: 1.0924487956986586
Validation loss: 2.661977025107057

Epoch: 5| Step: 4
Training loss: 1.1588400622020298
Validation loss: 2.6884296246965094

Epoch: 5| Step: 5
Training loss: 1.3571335740238006
Validation loss: 2.678581073233824

Epoch: 5| Step: 6
Training loss: 1.2549866392176723
Validation loss: 2.660884455200058

Epoch: 5| Step: 7
Training loss: 0.858963364937906
Validation loss: 2.6291087058491867

Epoch: 5| Step: 8
Training loss: 1.031736779200575
Validation loss: 2.6246576168929243

Epoch: 5| Step: 9
Training loss: 0.8151060638568156
Validation loss: 2.5758544598950994

Epoch: 5| Step: 10
Training loss: 0.8938010954756478
Validation loss: 2.555022643532608

Epoch: 264| Step: 0
Training loss: 0.9529000313834006
Validation loss: 2.5934919102133116

Epoch: 5| Step: 1
Training loss: 0.9707142389839424
Validation loss: 2.5844025147568668

Epoch: 5| Step: 2
Training loss: 1.368042770988683
Validation loss: 2.5919564598268683

Epoch: 5| Step: 3
Training loss: 0.951038609750827
Validation loss: 2.596845915834512

Epoch: 5| Step: 4
Training loss: 1.035931106478609
Validation loss: 2.6035219289404568

Epoch: 5| Step: 5
Training loss: 0.9546696388084704
Validation loss: 2.589319686913294

Epoch: 5| Step: 6
Training loss: 1.1152148670955542
Validation loss: 2.595952295607945

Epoch: 5| Step: 7
Training loss: 0.9438329735969164
Validation loss: 2.5981342708239668

Epoch: 5| Step: 8
Training loss: 1.0114164747749401
Validation loss: 2.5879628894179163

Epoch: 5| Step: 9
Training loss: 0.8619701388866882
Validation loss: 2.6464210050103962

Epoch: 5| Step: 10
Training loss: 1.1331057990962254
Validation loss: 2.6656856700044824

Epoch: 265| Step: 0
Training loss: 1.2069584105405102
Validation loss: 2.6518549742651674

Epoch: 5| Step: 1
Training loss: 0.5982941856789079
Validation loss: 2.6111965167294082

Epoch: 5| Step: 2
Training loss: 1.3270239810257183
Validation loss: 2.6083496085248266

Epoch: 5| Step: 3
Training loss: 0.6700093070494033
Validation loss: 2.568147556131595

Epoch: 5| Step: 4
Training loss: 1.0049019117551452
Validation loss: 2.5538471896218615

Epoch: 5| Step: 5
Training loss: 0.9914992340708211
Validation loss: 2.5146757289043884

Epoch: 5| Step: 6
Training loss: 1.3196574736279207
Validation loss: 2.516108730377295

Epoch: 5| Step: 7
Training loss: 0.989210393132527
Validation loss: 2.5484814882256015

Epoch: 5| Step: 8
Training loss: 0.9651203762833503
Validation loss: 2.5570258479070387

Epoch: 5| Step: 9
Training loss: 1.2393526081595947
Validation loss: 2.5940857131458803

Epoch: 5| Step: 10
Training loss: 0.7819930167288823
Validation loss: 2.624428594602147

Epoch: 266| Step: 0
Training loss: 1.0644508851753958
Validation loss: 2.6551171287159483

Epoch: 5| Step: 1
Training loss: 1.3728844233167505
Validation loss: 2.683189969165084

Epoch: 5| Step: 2
Training loss: 0.7611686872329215
Validation loss: 2.6908200278606604

Epoch: 5| Step: 3
Training loss: 1.204623836908257
Validation loss: 2.67594204916428

Epoch: 5| Step: 4
Training loss: 1.3316021001406764
Validation loss: 2.6917241385012955

Epoch: 5| Step: 5
Training loss: 1.0664984135747844
Validation loss: 2.6595042119260475

Epoch: 5| Step: 6
Training loss: 1.069676565325584
Validation loss: 2.6547278504879763

Epoch: 5| Step: 7
Training loss: 0.6664195471954135
Validation loss: 2.634014623590426

Epoch: 5| Step: 8
Training loss: 1.0628641850758982
Validation loss: 2.6127538224969094

Epoch: 5| Step: 9
Training loss: 0.8248481697474276
Validation loss: 2.6089388231225152

Epoch: 5| Step: 10
Training loss: 0.9039222485075215
Validation loss: 2.5853104708074777

Epoch: 267| Step: 0
Training loss: 1.1240634198538968
Validation loss: 2.5835351117576715

Epoch: 5| Step: 1
Training loss: 1.238245051965006
Validation loss: 2.608689953439774

Epoch: 5| Step: 2
Training loss: 1.0337882161024368
Validation loss: 2.5747773482502265

Epoch: 5| Step: 3
Training loss: 1.0289964038278152
Validation loss: 2.5957310436795518

Epoch: 5| Step: 4
Training loss: 1.0493007284194074
Validation loss: 2.5808172602783785

Epoch: 5| Step: 5
Training loss: 1.0120063873624707
Validation loss: 2.5847198372526927

Epoch: 5| Step: 6
Training loss: 0.7946114648707662
Validation loss: 2.5636995170741415

Epoch: 5| Step: 7
Training loss: 1.4677823714278175
Validation loss: 2.5763582332952697

Epoch: 5| Step: 8
Training loss: 0.699976100683946
Validation loss: 2.581315747901826

Epoch: 5| Step: 9
Training loss: 0.8885945045410302
Validation loss: 2.5985899866892597

Epoch: 5| Step: 10
Training loss: 0.858417289448759
Validation loss: 2.6411264594731767

Epoch: 268| Step: 0
Training loss: 0.8295317164146907
Validation loss: 2.6491796487203314

Epoch: 5| Step: 1
Training loss: 0.5916249746310134
Validation loss: 2.6832893345682254

Epoch: 5| Step: 2
Training loss: 1.2414285032415615
Validation loss: 2.7164261801390035

Epoch: 5| Step: 3
Training loss: 0.46077811184781753
Validation loss: 2.695681430700772

Epoch: 5| Step: 4
Training loss: 1.3482439169609453
Validation loss: 2.7572611893587986

Epoch: 5| Step: 5
Training loss: 1.2381071335313667
Validation loss: 2.7270568273554057

Epoch: 5| Step: 6
Training loss: 0.988760308116706
Validation loss: 2.674087168019702

Epoch: 5| Step: 7
Training loss: 0.6560333893553484
Validation loss: 2.668910263443315

Epoch: 5| Step: 8
Training loss: 0.9174974895723595
Validation loss: 2.6635149518548773

Epoch: 5| Step: 9
Training loss: 1.3427565251065614
Validation loss: 2.5870898962038127

Epoch: 5| Step: 10
Training loss: 0.8744497271897526
Validation loss: 2.5632410606110083

Epoch: 269| Step: 0
Training loss: 0.9895545085255903
Validation loss: 2.5422938662507084

Epoch: 5| Step: 1
Training loss: 0.9862028136768481
Validation loss: 2.533941983827349

Epoch: 5| Step: 2
Training loss: 1.270792642577729
Validation loss: 2.54915435919775

Epoch: 5| Step: 3
Training loss: 0.7343515432953892
Validation loss: 2.5470799169210525

Epoch: 5| Step: 4
Training loss: 0.5544747226567338
Validation loss: 2.522046272205561

Epoch: 5| Step: 5
Training loss: 0.9505814868265537
Validation loss: 2.527261362202024

Epoch: 5| Step: 6
Training loss: 0.7836545941509946
Validation loss: 2.5529363512928147

Epoch: 5| Step: 7
Training loss: 0.7271287413866943
Validation loss: 2.5603610580248843

Epoch: 5| Step: 8
Training loss: 1.1764773719255428
Validation loss: 2.571702057095933

Epoch: 5| Step: 9
Training loss: 1.3863951399474193
Validation loss: 2.609983973321305

Epoch: 5| Step: 10
Training loss: 0.918465597547771
Validation loss: 2.6247786835378837

Epoch: 270| Step: 0
Training loss: 1.154636855815047
Validation loss: 2.651226862996716

Epoch: 5| Step: 1
Training loss: 0.9769161041944964
Validation loss: 2.642257515881527

Epoch: 5| Step: 2
Training loss: 0.9277127233287588
Validation loss: 2.6726827340232093

Epoch: 5| Step: 3
Training loss: 0.8630066862234085
Validation loss: 2.6753251044656707

Epoch: 5| Step: 4
Training loss: 0.7493422325930565
Validation loss: 2.6828215557823274

Epoch: 5| Step: 5
Training loss: 1.478573917665881
Validation loss: 2.729135135661683

Epoch: 5| Step: 6
Training loss: 0.73481875059742
Validation loss: 2.7092341519118683

Epoch: 5| Step: 7
Training loss: 1.3774836823454093
Validation loss: 2.6850685477919587

Epoch: 5| Step: 8
Training loss: 0.6057819171830017
Validation loss: 2.68591858070334

Epoch: 5| Step: 9
Training loss: 0.5508315962919393
Validation loss: 2.665631033224771

Epoch: 5| Step: 10
Training loss: 0.7388499254655049
Validation loss: 2.637634296319496

Epoch: 271| Step: 0
Training loss: 0.9200796975984533
Validation loss: 2.605887358841663

Epoch: 5| Step: 1
Training loss: 0.7490214878738276
Validation loss: 2.6031017175234554

Epoch: 5| Step: 2
Training loss: 0.6662937825186662
Validation loss: 2.6305390811078038

Epoch: 5| Step: 3
Training loss: 0.885543582272392
Validation loss: 2.5716077648657607

Epoch: 5| Step: 4
Training loss: 0.9538166475820129
Validation loss: 2.602394517621869

Epoch: 5| Step: 5
Training loss: 0.8413800404609765
Validation loss: 2.6108869161671895

Epoch: 5| Step: 6
Training loss: 1.3328377527883406
Validation loss: 2.5822452608323117

Epoch: 5| Step: 7
Training loss: 0.9930560898205106
Validation loss: 2.5945067287122385

Epoch: 5| Step: 8
Training loss: 1.0327336014290862
Validation loss: 2.6042070611261434

Epoch: 5| Step: 9
Training loss: 0.547156670103261
Validation loss: 2.599931002285876

Epoch: 5| Step: 10
Training loss: 1.1425601794797988
Validation loss: 2.6209318726816826

Epoch: 272| Step: 0
Training loss: 0.9868964040608189
Validation loss: 2.6335872078644864

Epoch: 5| Step: 1
Training loss: 0.9306922419986138
Validation loss: 2.6016900993504266

Epoch: 5| Step: 2
Training loss: 0.7282241770117259
Validation loss: 2.631004979120448

Epoch: 5| Step: 3
Training loss: 0.6013754021138361
Validation loss: 2.577803359068583

Epoch: 5| Step: 4
Training loss: 0.8503151954347395
Validation loss: 2.595483385284621

Epoch: 5| Step: 5
Training loss: 0.9609915865431592
Validation loss: 2.6017145897478344

Epoch: 5| Step: 6
Training loss: 1.1610092469503468
Validation loss: 2.622575342278203

Epoch: 5| Step: 7
Training loss: 0.8366675709406715
Validation loss: 2.614018591577919

Epoch: 5| Step: 8
Training loss: 0.9520323384246039
Validation loss: 2.617776411735517

Epoch: 5| Step: 9
Training loss: 0.9275482954833681
Validation loss: 2.635437809949604

Epoch: 5| Step: 10
Training loss: 1.13503631147201
Validation loss: 2.629047076935119

Epoch: 273| Step: 0
Training loss: 0.970098541307901
Validation loss: 2.6485803209701806

Epoch: 5| Step: 1
Training loss: 1.2595189999021459
Validation loss: 2.6668292808045138

Epoch: 5| Step: 2
Training loss: 1.035468461079958
Validation loss: 2.6681428798216666

Epoch: 5| Step: 3
Training loss: 0.8446638668365662
Validation loss: 2.681302555470888

Epoch: 5| Step: 4
Training loss: 0.7964411657866134
Validation loss: 2.6570616937469507

Epoch: 5| Step: 5
Training loss: 1.0825823540669306
Validation loss: 2.7054380902442223

Epoch: 5| Step: 6
Training loss: 0.6740988146214234
Validation loss: 2.7354856180447435

Epoch: 5| Step: 7
Training loss: 1.0077257340806967
Validation loss: 2.7382749042762504

Epoch: 5| Step: 8
Training loss: 0.5472926588549246
Validation loss: 2.7094847450531234

Epoch: 5| Step: 9
Training loss: 1.0853448801348071
Validation loss: 2.6773157160540344

Epoch: 5| Step: 10
Training loss: 0.9590266387390056
Validation loss: 2.6271277855767026

Epoch: 274| Step: 0
Training loss: 0.879393853457887
Validation loss: 2.6352903718529173

Epoch: 5| Step: 1
Training loss: 1.0327844474549301
Validation loss: 2.6015438163047246

Epoch: 5| Step: 2
Training loss: 0.6916933702768001
Validation loss: 2.5890591137370094

Epoch: 5| Step: 3
Training loss: 1.1500836984610647
Validation loss: 2.6146950649862584

Epoch: 5| Step: 4
Training loss: 1.0778097714649237
Validation loss: 2.607622669024369

Epoch: 5| Step: 5
Training loss: 0.8251563068628969
Validation loss: 2.5818168421173384

Epoch: 5| Step: 6
Training loss: 0.707294731152225
Validation loss: 2.6166216328386818

Epoch: 5| Step: 7
Training loss: 0.9556726582770325
Validation loss: 2.572559800412184

Epoch: 5| Step: 8
Training loss: 0.6956245922077146
Validation loss: 2.6089956611934895

Epoch: 5| Step: 9
Training loss: 1.027966444781482
Validation loss: 2.624292474607961

Epoch: 5| Step: 10
Training loss: 0.8424908461483787
Validation loss: 2.648901368768664

Epoch: 275| Step: 0
Training loss: 0.7565166759833881
Validation loss: 2.655142037783111

Epoch: 5| Step: 1
Training loss: 0.7129124468246177
Validation loss: 2.6340004301718403

Epoch: 5| Step: 2
Training loss: 0.7721137075390451
Validation loss: 2.651588462041992

Epoch: 5| Step: 3
Training loss: 0.9049856969324843
Validation loss: 2.6223513360973407

Epoch: 5| Step: 4
Training loss: 0.9820482518098341
Validation loss: 2.608419767025734

Epoch: 5| Step: 5
Training loss: 1.3180040572976628
Validation loss: 2.5830666150978643

Epoch: 5| Step: 6
Training loss: 0.4887429000504653
Validation loss: 2.615929747198775

Epoch: 5| Step: 7
Training loss: 0.9341046200467199
Validation loss: 2.61614497723993

Epoch: 5| Step: 8
Training loss: 0.7589192125400532
Validation loss: 2.59100850933243

Epoch: 5| Step: 9
Training loss: 1.2226247082624018
Validation loss: 2.6233252311503037

Epoch: 5| Step: 10
Training loss: 0.6525806293875629
Validation loss: 2.575749273869712

Epoch: 276| Step: 0
Training loss: 0.8248814815585109
Validation loss: 2.5708077717163764

Epoch: 5| Step: 1
Training loss: 0.7277002757627723
Validation loss: 2.597378304842613

Epoch: 5| Step: 2
Training loss: 0.7187339946789192
Validation loss: 2.5819782238417512

Epoch: 5| Step: 3
Training loss: 0.7779811756852549
Validation loss: 2.621470645777379

Epoch: 5| Step: 4
Training loss: 1.1045520337904624
Validation loss: 2.6154391908614683

Epoch: 5| Step: 5
Training loss: 0.567561293875542
Validation loss: 2.661821486552498

Epoch: 5| Step: 6
Training loss: 1.0999533079814705
Validation loss: 2.6144951073083567

Epoch: 5| Step: 7
Training loss: 1.0001448287991137
Validation loss: 2.6122194520563395

Epoch: 5| Step: 8
Training loss: 0.7709550031229855
Validation loss: 2.601573061254147

Epoch: 5| Step: 9
Training loss: 1.0030076573270705
Validation loss: 2.614655428042256

Epoch: 5| Step: 10
Training loss: 0.9013425218176815
Validation loss: 2.596800500667326

Epoch: 277| Step: 0
Training loss: 0.8293639937060755
Validation loss: 2.5890387079787422

Epoch: 5| Step: 1
Training loss: 0.6713767311046884
Validation loss: 2.6057799653500977

Epoch: 5| Step: 2
Training loss: 1.1252245149165194
Validation loss: 2.610631186351609

Epoch: 5| Step: 3
Training loss: 1.028617388496974
Validation loss: 2.5950839598954287

Epoch: 5| Step: 4
Training loss: 0.8454633553480355
Validation loss: 2.5758420604392187

Epoch: 5| Step: 5
Training loss: 0.9514661956310799
Validation loss: 2.5898725722442077

Epoch: 5| Step: 6
Training loss: 0.7334257036974404
Validation loss: 2.57312749200106

Epoch: 5| Step: 7
Training loss: 0.6473402828608943
Validation loss: 2.5767879545374264

Epoch: 5| Step: 8
Training loss: 0.7567561544389243
Validation loss: 2.5940153972336284

Epoch: 5| Step: 9
Training loss: 0.8173803696316729
Validation loss: 2.6036738254612133

Epoch: 5| Step: 10
Training loss: 0.980238138867947
Validation loss: 2.5790032574778503

Epoch: 278| Step: 0
Training loss: 0.7584156114007636
Validation loss: 2.6087620505074924

Epoch: 5| Step: 1
Training loss: 0.9104895574922981
Validation loss: 2.593710072626811

Epoch: 5| Step: 2
Training loss: 1.1236889405258554
Validation loss: 2.6205310214103634

Epoch: 5| Step: 3
Training loss: 1.0191002881280002
Validation loss: 2.6103954445692596

Epoch: 5| Step: 4
Training loss: 0.647659156341842
Validation loss: 2.571791460406447

Epoch: 5| Step: 5
Training loss: 0.7306847890337481
Validation loss: 2.59953232438809

Epoch: 5| Step: 6
Training loss: 0.7803069717400833
Validation loss: 2.63512406351582

Epoch: 5| Step: 7
Training loss: 0.9951247944040401
Validation loss: 2.6109727999447307

Epoch: 5| Step: 8
Training loss: 0.7629191403545929
Validation loss: 2.59665330635267

Epoch: 5| Step: 9
Training loss: 0.7486059425362735
Validation loss: 2.628952205641297

Epoch: 5| Step: 10
Training loss: 0.8622695725614936
Validation loss: 2.6452575491814154

Epoch: 279| Step: 0
Training loss: 0.7734397734021
Validation loss: 2.6558601460054394

Epoch: 5| Step: 1
Training loss: 0.6339054794250424
Validation loss: 2.662362428302227

Epoch: 5| Step: 2
Training loss: 0.8512748442397942
Validation loss: 2.6472391552563908

Epoch: 5| Step: 3
Training loss: 0.7687581627885351
Validation loss: 2.625343968229382

Epoch: 5| Step: 4
Training loss: 1.0586344017866216
Validation loss: 2.622625760728936

Epoch: 5| Step: 5
Training loss: 0.507945468806752
Validation loss: 2.5918197437327217

Epoch: 5| Step: 6
Training loss: 1.0504550356567603
Validation loss: 2.6211239705564813

Epoch: 5| Step: 7
Training loss: 1.149056974703255
Validation loss: 2.604867227808965

Epoch: 5| Step: 8
Training loss: 0.7028882157794417
Validation loss: 2.6169847341595482

Epoch: 5| Step: 9
Training loss: 0.6162194978388417
Validation loss: 2.6563277670510868

Epoch: 5| Step: 10
Training loss: 1.0768123873742068
Validation loss: 2.6295223940543524

Epoch: 280| Step: 0
Training loss: 0.9445084233834795
Validation loss: 2.6198445511340807

Epoch: 5| Step: 1
Training loss: 0.8056100908176838
Validation loss: 2.6559079745660186

Epoch: 5| Step: 2
Training loss: 0.9478955563440769
Validation loss: 2.667566109937615

Epoch: 5| Step: 3
Training loss: 0.86455852212503
Validation loss: 2.6664795499059113

Epoch: 5| Step: 4
Training loss: 0.8613265333788086
Validation loss: 2.684280225788872

Epoch: 5| Step: 5
Training loss: 0.9830164541572953
Validation loss: 2.708823014157313

Epoch: 5| Step: 6
Training loss: 0.8091661574116239
Validation loss: 2.6710912916008174

Epoch: 5| Step: 7
Training loss: 0.6476912283108633
Validation loss: 2.6529869580249144

Epoch: 5| Step: 8
Training loss: 0.6057288564832641
Validation loss: 2.6504087457551186

Epoch: 5| Step: 9
Training loss: 0.8741589318640254
Validation loss: 2.643130856175975

Epoch: 5| Step: 10
Training loss: 0.8288860782394392
Validation loss: 2.642309647187239

Epoch: 281| Step: 0
Training loss: 0.9872812028727365
Validation loss: 2.651491031622256

Epoch: 5| Step: 1
Training loss: 0.6875119208256052
Validation loss: 2.634470224496886

Epoch: 5| Step: 2
Training loss: 0.6346483092837082
Validation loss: 2.6326997672634347

Epoch: 5| Step: 3
Training loss: 0.5731150601522432
Validation loss: 2.627630961325937

Epoch: 5| Step: 4
Training loss: 0.6565336795020927
Validation loss: 2.6134172367375315

Epoch: 5| Step: 5
Training loss: 1.3643319963780598
Validation loss: 2.605663863128114

Epoch: 5| Step: 6
Training loss: 0.574791628980572
Validation loss: 2.605227442788562

Epoch: 5| Step: 7
Training loss: 0.6923676611529811
Validation loss: 2.5834331876871786

Epoch: 5| Step: 8
Training loss: 0.91791141412115
Validation loss: 2.6106623862790364

Epoch: 5| Step: 9
Training loss: 1.0490270671025286
Validation loss: 2.629818840676441

Epoch: 5| Step: 10
Training loss: 0.6373164408211124
Validation loss: 2.6352240710004575

Epoch: 282| Step: 0
Training loss: 0.9275411625491138
Validation loss: 2.62204706817191

Epoch: 5| Step: 1
Training loss: 0.9359952931081988
Validation loss: 2.621841186428988

Epoch: 5| Step: 2
Training loss: 0.7631002955456505
Validation loss: 2.6103162221763356

Epoch: 5| Step: 3
Training loss: 0.9074448239811052
Validation loss: 2.630489225607052

Epoch: 5| Step: 4
Training loss: 0.7205560218770637
Validation loss: 2.6157840017425964

Epoch: 5| Step: 5
Training loss: 0.9708047119036493
Validation loss: 2.5863577004352227

Epoch: 5| Step: 6
Training loss: 0.8179528585528003
Validation loss: 2.566347402808004

Epoch: 5| Step: 7
Training loss: 0.6814726045871845
Validation loss: 2.6065406528454425

Epoch: 5| Step: 8
Training loss: 0.7835810408317473
Validation loss: 2.5985993707420803

Epoch: 5| Step: 9
Training loss: 0.8301829911356318
Validation loss: 2.627442115108689

Epoch: 5| Step: 10
Training loss: 0.6522375694251324
Validation loss: 2.648201634800659

Epoch: 283| Step: 0
Training loss: 0.6840229539867874
Validation loss: 2.6506481270605775

Epoch: 5| Step: 1
Training loss: 0.6749955830606128
Validation loss: 2.6285173901703365

Epoch: 5| Step: 2
Training loss: 0.6074719914310072
Validation loss: 2.6399724291968014

Epoch: 5| Step: 3
Training loss: 0.8668539419552463
Validation loss: 2.6489866200902377

Epoch: 5| Step: 4
Training loss: 0.7121826837233705
Validation loss: 2.6483851355115657

Epoch: 5| Step: 5
Training loss: 0.8602955136352536
Validation loss: 2.6468393417183966

Epoch: 5| Step: 6
Training loss: 0.8819540795895434
Validation loss: 2.5910428663277485

Epoch: 5| Step: 7
Training loss: 0.8565056147817237
Validation loss: 2.632328847728885

Epoch: 5| Step: 8
Training loss: 1.1792061941757974
Validation loss: 2.622662591059467

Epoch: 5| Step: 9
Training loss: 0.8004630224085169
Validation loss: 2.619818048037113

Epoch: 5| Step: 10
Training loss: 0.7262909084229521
Validation loss: 2.605063013845112

Epoch: 284| Step: 0
Training loss: 0.6643152765612064
Validation loss: 2.6315250446960508

Epoch: 5| Step: 1
Training loss: 0.8306913735971939
Validation loss: 2.612652560434518

Epoch: 5| Step: 2
Training loss: 1.014644090424699
Validation loss: 2.613818975451559

Epoch: 5| Step: 3
Training loss: 0.8770673036054365
Validation loss: 2.627162154225642

Epoch: 5| Step: 4
Training loss: 0.48680428477417853
Validation loss: 2.645696708349825

Epoch: 5| Step: 5
Training loss: 0.6584508412751681
Validation loss: 2.6146848734289803

Epoch: 5| Step: 6
Training loss: 0.7053623841661797
Validation loss: 2.6251855365678423

Epoch: 5| Step: 7
Training loss: 0.9161089623893007
Validation loss: 2.6281214299563698

Epoch: 5| Step: 8
Training loss: 0.611369146853678
Validation loss: 2.5993698652145865

Epoch: 5| Step: 9
Training loss: 1.1327839288725914
Validation loss: 2.625637234437814

Epoch: 5| Step: 10
Training loss: 0.8032530433912944
Validation loss: 2.6423201920802946

Epoch: 285| Step: 0
Training loss: 0.6721798626524812
Validation loss: 2.6350141402122382

Epoch: 5| Step: 1
Training loss: 0.9475129424044111
Validation loss: 2.6341824009767434

Epoch: 5| Step: 2
Training loss: 0.9601552306775858
Validation loss: 2.655499773527596

Epoch: 5| Step: 3
Training loss: 0.9271025744952452
Validation loss: 2.63584802856978

Epoch: 5| Step: 4
Training loss: 0.490446082980132
Validation loss: 2.6709938210605295

Epoch: 5| Step: 5
Training loss: 0.7745345456082289
Validation loss: 2.673348794239356

Epoch: 5| Step: 6
Training loss: 0.7651029091225909
Validation loss: 2.67117313784748

Epoch: 5| Step: 7
Training loss: 0.8325852891116754
Validation loss: 2.670843132748097

Epoch: 5| Step: 8
Training loss: 0.9758389959054301
Validation loss: 2.6700392560295616

Epoch: 5| Step: 9
Training loss: 0.5926754161854335
Validation loss: 2.6450963762693376

Epoch: 5| Step: 10
Training loss: 0.5648653577626122
Validation loss: 2.639386867289927

Epoch: 286| Step: 0
Training loss: 0.6970970313289582
Validation loss: 2.673660793587729

Epoch: 5| Step: 1
Training loss: 1.043965581227903
Validation loss: 2.6599387492152564

Epoch: 5| Step: 2
Training loss: 0.6004289375346653
Validation loss: 2.6519544764836316

Epoch: 5| Step: 3
Training loss: 0.8347361122522995
Validation loss: 2.6591188480774437

Epoch: 5| Step: 4
Training loss: 0.77899301671239
Validation loss: 2.6346925123753886

Epoch: 5| Step: 5
Training loss: 0.7043411968754788
Validation loss: 2.6250731442872355

Epoch: 5| Step: 6
Training loss: 0.7747942651423179
Validation loss: 2.6233986571543055

Epoch: 5| Step: 7
Training loss: 0.8654175299718374
Validation loss: 2.601990076548937

Epoch: 5| Step: 8
Training loss: 0.9162690029801817
Validation loss: 2.5816081989069857

Epoch: 5| Step: 9
Training loss: 0.8171313410584856
Validation loss: 2.588696922277467

Epoch: 5| Step: 10
Training loss: 0.4300408730930935
Validation loss: 2.6274716255116557

Epoch: 287| Step: 0
Training loss: 0.8691231715132212
Validation loss: 2.614152158384762

Epoch: 5| Step: 1
Training loss: 0.9087551941126337
Validation loss: 2.6026459553731205

Epoch: 5| Step: 2
Training loss: 0.5054307690461514
Validation loss: 2.6191194121470835

Epoch: 5| Step: 3
Training loss: 0.8854036031021106
Validation loss: 2.596194810523381

Epoch: 5| Step: 4
Training loss: 0.6401196324027127
Validation loss: 2.607318497373959

Epoch: 5| Step: 5
Training loss: 0.8275947672696483
Validation loss: 2.622106776661181

Epoch: 5| Step: 6
Training loss: 1.1111717717513234
Validation loss: 2.578661659744539

Epoch: 5| Step: 7
Training loss: 0.7663448997463733
Validation loss: 2.5676077852333408

Epoch: 5| Step: 8
Training loss: 0.7952936975920829
Validation loss: 2.6059222358593894

Epoch: 5| Step: 9
Training loss: 0.6061656018136696
Validation loss: 2.6068681417222423

Epoch: 5| Step: 10
Training loss: 0.37851417549099836
Validation loss: 2.61941794923654

Epoch: 288| Step: 0
Training loss: 0.6918118682563441
Validation loss: 2.6069718587716797

Epoch: 5| Step: 1
Training loss: 0.7004725334410778
Validation loss: 2.654642956404356

Epoch: 5| Step: 2
Training loss: 0.9645175768613675
Validation loss: 2.640892371087654

Epoch: 5| Step: 3
Training loss: 0.668850924104741
Validation loss: 2.654396465322342

Epoch: 5| Step: 4
Training loss: 0.7890203861291072
Validation loss: 2.664202194152756

Epoch: 5| Step: 5
Training loss: 0.5202668224366419
Validation loss: 2.6586318178843227

Epoch: 5| Step: 6
Training loss: 1.1069207243303774
Validation loss: 2.656506688493137

Epoch: 5| Step: 7
Training loss: 0.8899106289428693
Validation loss: 2.6518276319622895

Epoch: 5| Step: 8
Training loss: 0.7549083157632025
Validation loss: 2.6364248762052567

Epoch: 5| Step: 9
Training loss: 0.6190605713507598
Validation loss: 2.6537165499475432

Epoch: 5| Step: 10
Training loss: 0.6208029492088197
Validation loss: 2.6508935291063

Epoch: 289| Step: 0
Training loss: 0.5652013657006019
Validation loss: 2.6405397340595678

Epoch: 5| Step: 1
Training loss: 0.6982684150518335
Validation loss: 2.634097655941269

Epoch: 5| Step: 2
Training loss: 0.830759428583228
Validation loss: 2.6118709227006947

Epoch: 5| Step: 3
Training loss: 0.6920919950916586
Validation loss: 2.617892396881654

Epoch: 5| Step: 4
Training loss: 0.6230358493510987
Validation loss: 2.59802528688005

Epoch: 5| Step: 5
Training loss: 0.8532177647610552
Validation loss: 2.600370607139447

Epoch: 5| Step: 6
Training loss: 0.4304876506830743
Validation loss: 2.6017320464301736

Epoch: 5| Step: 7
Training loss: 1.0713138768704848
Validation loss: 2.6032911112663673

Epoch: 5| Step: 8
Training loss: 0.40717739842166895
Validation loss: 2.5825330888745026

Epoch: 5| Step: 9
Training loss: 0.9083143268719862
Validation loss: 2.6087392192479273

Epoch: 5| Step: 10
Training loss: 1.0585175659242978
Validation loss: 2.5938505807295957

Epoch: 290| Step: 0
Training loss: 0.7514637332979937
Validation loss: 2.620957308133973

Epoch: 5| Step: 1
Training loss: 0.5851013830153922
Validation loss: 2.619600267051791

Epoch: 5| Step: 2
Training loss: 0.3584439615134504
Validation loss: 2.614203886658459

Epoch: 5| Step: 3
Training loss: 0.9335935584670633
Validation loss: 2.6229754745405636

Epoch: 5| Step: 4
Training loss: 0.8917029365994289
Validation loss: 2.620991998312555

Epoch: 5| Step: 5
Training loss: 0.9949266065912623
Validation loss: 2.6316807363029433

Epoch: 5| Step: 6
Training loss: 0.6668615255093908
Validation loss: 2.6373125121921284

Epoch: 5| Step: 7
Training loss: 0.501509741506922
Validation loss: 2.6371943199818513

Epoch: 5| Step: 8
Training loss: 1.0979348368772837
Validation loss: 2.6429967004032355

Epoch: 5| Step: 9
Training loss: 0.5863648445682834
Validation loss: 2.64187572353738

Epoch: 5| Step: 10
Training loss: 0.702374142168495
Validation loss: 2.6123727859240207

Epoch: 291| Step: 0
Training loss: 1.03232431805987
Validation loss: 2.6219636806024664

Epoch: 5| Step: 1
Training loss: 0.7984931075408367
Validation loss: 2.606501106312944

Epoch: 5| Step: 2
Training loss: 0.6264865363060322
Validation loss: 2.615050490122152

Epoch: 5| Step: 3
Training loss: 0.8445322860725534
Validation loss: 2.6096914255615697

Epoch: 5| Step: 4
Training loss: 0.954774086579707
Validation loss: 2.6189783998623937

Epoch: 5| Step: 5
Training loss: 0.6452845477314997
Validation loss: 2.622855485841838

Epoch: 5| Step: 6
Training loss: 0.39452819067647005
Validation loss: 2.644170772802069

Epoch: 5| Step: 7
Training loss: 0.6819349380429656
Validation loss: 2.650000171657502

Epoch: 5| Step: 8
Training loss: 0.8244008952275227
Validation loss: 2.6389565038375276

Epoch: 5| Step: 9
Training loss: 0.7892708456109828
Validation loss: 2.643545244830413

Epoch: 5| Step: 10
Training loss: 0.5867610484392651
Validation loss: 2.6409104191703214

Epoch: 292| Step: 0
Training loss: 0.9008805603177565
Validation loss: 2.6303213690794602

Epoch: 5| Step: 1
Training loss: 0.8204157446421306
Validation loss: 2.6750063716792227

Epoch: 5| Step: 2
Training loss: 0.7583607528955383
Validation loss: 2.6550606754736794

Epoch: 5| Step: 3
Training loss: 0.7809439250289433
Validation loss: 2.651114877027221

Epoch: 5| Step: 4
Training loss: 0.7186583584952215
Validation loss: 2.626316365536029

Epoch: 5| Step: 5
Training loss: 0.7450536298330221
Validation loss: 2.65859363393872

Epoch: 5| Step: 6
Training loss: 0.7415434602848379
Validation loss: 2.6445711429465133

Epoch: 5| Step: 7
Training loss: 0.40276163121814024
Validation loss: 2.6459950526931326

Epoch: 5| Step: 8
Training loss: 0.7738034317105161
Validation loss: 2.6767697612497274

Epoch: 5| Step: 9
Training loss: 0.712671575467208
Validation loss: 2.6405133619821375

Epoch: 5| Step: 10
Training loss: 0.886592032499029
Validation loss: 2.6394127144697244

Epoch: 293| Step: 0
Training loss: 0.6431408537086738
Validation loss: 2.62763998214392

Epoch: 5| Step: 1
Training loss: 0.81108788508935
Validation loss: 2.656347332111556

Epoch: 5| Step: 2
Training loss: 0.7724228571054753
Validation loss: 2.625004138933504

Epoch: 5| Step: 3
Training loss: 0.6950843736835678
Validation loss: 2.6253489317591856

Epoch: 5| Step: 4
Training loss: 0.9744639010977749
Validation loss: 2.661539336642805

Epoch: 5| Step: 5
Training loss: 0.5181896699458063
Validation loss: 2.6482885891597556

Epoch: 5| Step: 6
Training loss: 0.9352387177603363
Validation loss: 2.647206559958922

Epoch: 5| Step: 7
Training loss: 0.7964328960640968
Validation loss: 2.6365794276805397

Epoch: 5| Step: 8
Training loss: 0.6559614273657728
Validation loss: 2.642474175615514

Epoch: 5| Step: 9
Training loss: 0.6276094322986174
Validation loss: 2.6735038894215104

Epoch: 5| Step: 10
Training loss: 0.6205348973401172
Validation loss: 2.6572367013599756

Epoch: 294| Step: 0
Training loss: 1.0041234712820575
Validation loss: 2.6262115645617436

Epoch: 5| Step: 1
Training loss: 0.7164664273379321
Validation loss: 2.6479981505969925

Epoch: 5| Step: 2
Training loss: 0.5498093491351556
Validation loss: 2.632377470019597

Epoch: 5| Step: 3
Training loss: 0.9469230740369651
Validation loss: 2.640029722657351

Epoch: 5| Step: 4
Training loss: 0.5589931633962847
Validation loss: 2.6356001498281567

Epoch: 5| Step: 5
Training loss: 0.8109939261560619
Validation loss: 2.6089606346317815

Epoch: 5| Step: 6
Training loss: 0.5928844115499311
Validation loss: 2.6421617323988

Epoch: 5| Step: 7
Training loss: 0.7025768898734934
Validation loss: 2.642205578085472

Epoch: 5| Step: 8
Training loss: 0.687845446756395
Validation loss: 2.6441938051955582

Epoch: 5| Step: 9
Training loss: 0.6892149300340755
Validation loss: 2.608622069426028

Epoch: 5| Step: 10
Training loss: 0.6248691898784746
Validation loss: 2.6535124317070746

Epoch: 295| Step: 0
Training loss: 0.33212934054868143
Validation loss: 2.6731857330753104

Epoch: 5| Step: 1
Training loss: 0.8074417754047611
Validation loss: 2.6792717459885904

Epoch: 5| Step: 2
Training loss: 0.7750453612680762
Validation loss: 2.656712278884267

Epoch: 5| Step: 3
Training loss: 0.6539584978712478
Validation loss: 2.665840438801864

Epoch: 5| Step: 4
Training loss: 0.8160669086971485
Validation loss: 2.659861889159771

Epoch: 5| Step: 5
Training loss: 0.5330765123219643
Validation loss: 2.6138810737446856

Epoch: 5| Step: 6
Training loss: 0.8343901529257758
Validation loss: 2.5822745630156465

Epoch: 5| Step: 7
Training loss: 0.8785978327138504
Validation loss: 2.621408362003692

Epoch: 5| Step: 8
Training loss: 0.7107034654334491
Validation loss: 2.584621287669639

Epoch: 5| Step: 9
Training loss: 0.7907113702813588
Validation loss: 2.5962281904340805

Epoch: 5| Step: 10
Training loss: 0.8027008123876316
Validation loss: 2.5702538938523816

Epoch: 296| Step: 0
Training loss: 0.6433854987764787
Validation loss: 2.6047405262005388

Epoch: 5| Step: 1
Training loss: 1.0183174244646822
Validation loss: 2.6292029240536148

Epoch: 5| Step: 2
Training loss: 0.8919663617843497
Validation loss: 2.6011346757603167

Epoch: 5| Step: 3
Training loss: 0.9744417279525913
Validation loss: 2.647998819583659

Epoch: 5| Step: 4
Training loss: 0.5102504310307044
Validation loss: 2.639332755524193

Epoch: 5| Step: 5
Training loss: 0.3304376957328019
Validation loss: 2.6718462247030015

Epoch: 5| Step: 6
Training loss: 0.5272762679262178
Validation loss: 2.6248062939327763

Epoch: 5| Step: 7
Training loss: 0.7135571016373239
Validation loss: 2.656002930280463

Epoch: 5| Step: 8
Training loss: 0.739435252735888
Validation loss: 2.647189942574998

Epoch: 5| Step: 9
Training loss: 0.6866619464178095
Validation loss: 2.6412046693919287

Epoch: 5| Step: 10
Training loss: 0.6983418000132106
Validation loss: 2.6345780365429547

Epoch: 297| Step: 0
Training loss: 0.8189695355148877
Validation loss: 2.624663546750067

Epoch: 5| Step: 1
Training loss: 0.6861398203008977
Validation loss: 2.640471722243406

Epoch: 5| Step: 2
Training loss: 0.35678673683231626
Validation loss: 2.6345412511518287

Epoch: 5| Step: 3
Training loss: 0.7106063406850617
Validation loss: 2.6365590941153396

Epoch: 5| Step: 4
Training loss: 0.7195076473643512
Validation loss: 2.621123307425477

Epoch: 5| Step: 5
Training loss: 1.0408752804853478
Validation loss: 2.6063857935863894

Epoch: 5| Step: 6
Training loss: 0.6190678887707995
Validation loss: 2.603968718522116

Epoch: 5| Step: 7
Training loss: 0.9829314410069665
Validation loss: 2.617592972807868

Epoch: 5| Step: 8
Training loss: 0.5003632775486182
Validation loss: 2.61329538917944

Epoch: 5| Step: 9
Training loss: 0.6647468854939529
Validation loss: 2.626102480658265

Epoch: 5| Step: 10
Training loss: 0.413536565478529
Validation loss: 2.6070939384472007

Epoch: 298| Step: 0
Training loss: 0.6630413506732719
Validation loss: 2.6242651294079713

Epoch: 5| Step: 1
Training loss: 0.6105821097781552
Validation loss: 2.6593201278698273

Epoch: 5| Step: 2
Training loss: 0.7753191706021806
Validation loss: 2.6819943335023955

Epoch: 5| Step: 3
Training loss: 0.7804297528151602
Validation loss: 2.6533859766371792

Epoch: 5| Step: 4
Training loss: 0.874642707901687
Validation loss: 2.614452906588993

Epoch: 5| Step: 5
Training loss: 0.8035916394008131
Validation loss: 2.622523191622356

Epoch: 5| Step: 6
Training loss: 0.6952784240602131
Validation loss: 2.620631192531118

Epoch: 5| Step: 7
Training loss: 0.7761748453514423
Validation loss: 2.6094659695246087

Epoch: 5| Step: 8
Training loss: 0.7778600004044346
Validation loss: 2.6140869493714547

Epoch: 5| Step: 9
Training loss: 0.7014949341249163
Validation loss: 2.623373701739269

Epoch: 5| Step: 10
Training loss: 0.465961842658992
Validation loss: 2.6034193841286575

Epoch: 299| Step: 0
Training loss: 0.3870461936840892
Validation loss: 2.637337179698176

Epoch: 5| Step: 1
Training loss: 0.6440227236396432
Validation loss: 2.6082208242417897

Epoch: 5| Step: 2
Training loss: 0.659103954344532
Validation loss: 2.632148201948206

Epoch: 5| Step: 3
Training loss: 0.8693058499794898
Validation loss: 2.6287559957948234

Epoch: 5| Step: 4
Training loss: 0.8146293687292084
Validation loss: 2.619166863824148

Epoch: 5| Step: 5
Training loss: 0.572100983458782
Validation loss: 2.632851695628315

Epoch: 5| Step: 6
Training loss: 0.49415380286938404
Validation loss: 2.637478031777877

Epoch: 5| Step: 7
Training loss: 0.47025231581467025
Validation loss: 2.5993631793856666

Epoch: 5| Step: 8
Training loss: 1.074328219297923
Validation loss: 2.636116412238446

Epoch: 5| Step: 9
Training loss: 0.6395628427791432
Validation loss: 2.645665080003282

Epoch: 5| Step: 10
Training loss: 0.8502981266151383
Validation loss: 2.627307005040809

Epoch: 300| Step: 0
Training loss: 0.7577601149238519
Validation loss: 2.6172450943769907

Epoch: 5| Step: 1
Training loss: 0.4309759416370869
Validation loss: 2.6292492586778597

Epoch: 5| Step: 2
Training loss: 0.6041662418977845
Validation loss: 2.653089224848845

Epoch: 5| Step: 3
Training loss: 0.8493982864006008
Validation loss: 2.630704128858193

Epoch: 5| Step: 4
Training loss: 0.5101831122390431
Validation loss: 2.5914787116174276

Epoch: 5| Step: 5
Training loss: 0.6267195887573077
Validation loss: 2.6379322084531056

Epoch: 5| Step: 6
Training loss: 0.9172383101002508
Validation loss: 2.5917000129969874

Epoch: 5| Step: 7
Training loss: 0.5544696971259794
Validation loss: 2.614919143706983

Epoch: 5| Step: 8
Training loss: 0.7605878210580749
Validation loss: 2.59614951579455

Epoch: 5| Step: 9
Training loss: 0.7966687552638854
Validation loss: 2.620142861771751

Epoch: 5| Step: 10
Training loss: 0.7134147911785319
Validation loss: 2.5907845781064194

Epoch: 301| Step: 0
Training loss: 0.6380261764821641
Validation loss: 2.6005619490910625

Epoch: 5| Step: 1
Training loss: 0.5755180658012119
Validation loss: 2.5709645361590914

Epoch: 5| Step: 2
Training loss: 0.5825176382873424
Validation loss: 2.606218863480006

Epoch: 5| Step: 3
Training loss: 0.9223660922878518
Validation loss: 2.6194530356194834

Epoch: 5| Step: 4
Training loss: 0.8569819336214316
Validation loss: 2.5949484701116483

Epoch: 5| Step: 5
Training loss: 0.6161901648839406
Validation loss: 2.60907473306245

Epoch: 5| Step: 6
Training loss: 0.5641392557856308
Validation loss: 2.6030801651793647

Epoch: 5| Step: 7
Training loss: 0.5376185829739295
Validation loss: 2.6198231883906797

Epoch: 5| Step: 8
Training loss: 0.776531542769248
Validation loss: 2.6341613676486815

Epoch: 5| Step: 9
Training loss: 0.7728270616713593
Validation loss: 2.6251743237281286

Epoch: 5| Step: 10
Training loss: 0.5637699203185909
Validation loss: 2.6264175712668227

Epoch: 302| Step: 0
Training loss: 0.6022870790413949
Validation loss: 2.638180369013606

Epoch: 5| Step: 1
Training loss: 0.6197069147543837
Validation loss: 2.6136739676005822

Epoch: 5| Step: 2
Training loss: 0.9251739505929376
Validation loss: 2.63197260730889

Epoch: 5| Step: 3
Training loss: 0.5128720514750581
Validation loss: 2.6316707697987827

Epoch: 5| Step: 4
Training loss: 0.5347866257639375
Validation loss: 2.627010751197322

Epoch: 5| Step: 5
Training loss: 0.9151109078943674
Validation loss: 2.6376532705997984

Epoch: 5| Step: 6
Training loss: 0.778902302907051
Validation loss: 2.6495761386861054

Epoch: 5| Step: 7
Training loss: 0.30905510422022225
Validation loss: 2.5908544523228256

Epoch: 5| Step: 8
Training loss: 0.7723888262282759
Validation loss: 2.626270566811368

Epoch: 5| Step: 9
Training loss: 0.7497324863816539
Validation loss: 2.5954883560385147

Epoch: 5| Step: 10
Training loss: 0.5879258053414264
Validation loss: 2.6372765858628293

Epoch: 303| Step: 0
Training loss: 0.6004487912277925
Validation loss: 2.626252082810254

Epoch: 5| Step: 1
Training loss: 0.7260332538513212
Validation loss: 2.624732542500348

Epoch: 5| Step: 2
Training loss: 0.6134670972169807
Validation loss: 2.653218894244078

Epoch: 5| Step: 3
Training loss: 0.8555379343144793
Validation loss: 2.6627999126362303

Epoch: 5| Step: 4
Training loss: 0.7682951473199513
Validation loss: 2.654076488887832

Epoch: 5| Step: 5
Training loss: 0.47346040399625605
Validation loss: 2.632047718182991

Epoch: 5| Step: 6
Training loss: 0.5904827824681874
Validation loss: 2.6346450717636656

Epoch: 5| Step: 7
Training loss: 0.6392212584266128
Validation loss: 2.6107405317602317

Epoch: 5| Step: 8
Training loss: 0.6827485663469838
Validation loss: 2.6187117165160143

Epoch: 5| Step: 9
Training loss: 0.8645781359841881
Validation loss: 2.622944339953939

Epoch: 5| Step: 10
Training loss: 0.5582856615790649
Validation loss: 2.616475020581037

Epoch: 304| Step: 0
Training loss: 0.7009880653812922
Validation loss: 2.6099743969175853

Epoch: 5| Step: 1
Training loss: 0.7721117390202058
Validation loss: 2.603089341985233

Epoch: 5| Step: 2
Training loss: 0.6287810159469222
Validation loss: 2.6199283956007955

Epoch: 5| Step: 3
Training loss: 0.6318090984416311
Validation loss: 2.5996629458236264

Epoch: 5| Step: 4
Training loss: 0.3147962368688725
Validation loss: 2.6171921919938432

Epoch: 5| Step: 5
Training loss: 0.6160272484688436
Validation loss: 2.6312989379612595

Epoch: 5| Step: 6
Training loss: 0.9054033665587923
Validation loss: 2.6382340064059373

Epoch: 5| Step: 7
Training loss: 0.7460641106115742
Validation loss: 2.605078790876989

Epoch: 5| Step: 8
Training loss: 0.8031279998010801
Validation loss: 2.6292954779196127

Epoch: 5| Step: 9
Training loss: 0.27433372489061914
Validation loss: 2.6416779969699835

Epoch: 5| Step: 10
Training loss: 0.737930133624177
Validation loss: 2.623490500653004

Epoch: 305| Step: 0
Training loss: 0.6780825992811691
Validation loss: 2.589817078472435

Epoch: 5| Step: 1
Training loss: 0.5668794956891204
Validation loss: 2.6464413044576047

Epoch: 5| Step: 2
Training loss: 0.48414849553613626
Validation loss: 2.599076522719899

Epoch: 5| Step: 3
Training loss: 0.6214910711842424
Validation loss: 2.598903586298278

Epoch: 5| Step: 4
Training loss: 0.8145430627284991
Validation loss: 2.581844637894652

Epoch: 5| Step: 5
Training loss: 0.6738562536588146
Validation loss: 2.6088937874831095

Epoch: 5| Step: 6
Training loss: 0.47607418744991886
Validation loss: 2.5886600652425895

Epoch: 5| Step: 7
Training loss: 0.605211757140288
Validation loss: 2.576113985314881

Epoch: 5| Step: 8
Training loss: 0.9227869081807842
Validation loss: 2.5798699413738726

Epoch: 5| Step: 9
Training loss: 0.9780253630764236
Validation loss: 2.6021031505833996

Epoch: 5| Step: 10
Training loss: 0.5188602617578847
Validation loss: 2.5727655264161124

Epoch: 306| Step: 0
Training loss: 0.5042319908330416
Validation loss: 2.6183230531615926

Epoch: 5| Step: 1
Training loss: 0.6750794443427288
Validation loss: 2.623267178526963

Epoch: 5| Step: 2
Training loss: 0.7204065720700541
Validation loss: 2.645053969333792

Epoch: 5| Step: 3
Training loss: 0.571504914024833
Validation loss: 2.6213736098547487

Epoch: 5| Step: 4
Training loss: 0.8503913875886567
Validation loss: 2.6501835110772674

Epoch: 5| Step: 5
Training loss: 0.5992195527271529
Validation loss: 2.6562714095100364

Epoch: 5| Step: 6
Training loss: 0.715439178462162
Validation loss: 2.677497907002179

Epoch: 5| Step: 7
Training loss: 0.6909699005991039
Validation loss: 2.657490069607397

Epoch: 5| Step: 8
Training loss: 0.7254042879378072
Validation loss: 2.6568005043851226

Epoch: 5| Step: 9
Training loss: 0.8057722169356096
Validation loss: 2.6492531008477793

Epoch: 5| Step: 10
Training loss: 0.45357868896247466
Validation loss: 2.6221555640563268

Epoch: 307| Step: 0
Training loss: 0.6587988537474425
Validation loss: 2.5925593405238554

Epoch: 5| Step: 1
Training loss: 0.6505696734706229
Validation loss: 2.585587030200422

Epoch: 5| Step: 2
Training loss: 0.7153861067711403
Validation loss: 2.5837535637099496

Epoch: 5| Step: 3
Training loss: 0.44547287244973227
Validation loss: 2.620997589231662

Epoch: 5| Step: 4
Training loss: 0.5728123107427023
Validation loss: 2.594091494481836

Epoch: 5| Step: 5
Training loss: 0.45567111235919294
Validation loss: 2.6331831639895222

Epoch: 5| Step: 6
Training loss: 0.8067882116492954
Validation loss: 2.660976415326266

Epoch: 5| Step: 7
Training loss: 0.5746128779757714
Validation loss: 2.6378078472906776

Epoch: 5| Step: 8
Training loss: 1.1077607458855079
Validation loss: 2.6439292579887415

Epoch: 5| Step: 9
Training loss: 0.5404912562673194
Validation loss: 2.6153998239702636

Epoch: 5| Step: 10
Training loss: 0.5493237846726687
Validation loss: 2.6210438067786663

Epoch: 308| Step: 0
Training loss: 0.7267942571690256
Validation loss: 2.6328880922635434

Epoch: 5| Step: 1
Training loss: 0.6510899080841033
Validation loss: 2.623222672290793

Epoch: 5| Step: 2
Training loss: 0.6810919184527764
Validation loss: 2.6391814086115435

Epoch: 5| Step: 3
Training loss: 0.7803561628696539
Validation loss: 2.6290069786533374

Epoch: 5| Step: 4
Training loss: 0.7308869822031921
Validation loss: 2.61989620713454

Epoch: 5| Step: 5
Training loss: 0.5905766008114528
Validation loss: 2.6052512967243526

Epoch: 5| Step: 6
Training loss: 0.5033009464326264
Validation loss: 2.6080751375080546

Epoch: 5| Step: 7
Training loss: 0.5511535576602509
Validation loss: 2.615867739190739

Epoch: 5| Step: 8
Training loss: 0.724560759113938
Validation loss: 2.628517958780738

Epoch: 5| Step: 9
Training loss: 0.637765153270457
Validation loss: 2.59916908066808

Epoch: 5| Step: 10
Training loss: 0.542155363246301
Validation loss: 2.6085947235880713

Epoch: 309| Step: 0
Training loss: 0.5803446815536242
Validation loss: 2.6008308838121756

Epoch: 5| Step: 1
Training loss: 0.5523151384899059
Validation loss: 2.6095700823827253

Epoch: 5| Step: 2
Training loss: 0.5048393658772614
Validation loss: 2.5989502450807804

Epoch: 5| Step: 3
Training loss: 0.7893366195880402
Validation loss: 2.5939333500397774

Epoch: 5| Step: 4
Training loss: 0.618619705700144
Validation loss: 2.5938430341474246

Epoch: 5| Step: 5
Training loss: 0.6561784251099955
Validation loss: 2.609737390479649

Epoch: 5| Step: 6
Training loss: 0.5224451936150059
Validation loss: 2.6317524334284994

Epoch: 5| Step: 7
Training loss: 0.5941449658638449
Validation loss: 2.6706735207198884

Epoch: 5| Step: 8
Training loss: 0.6914738767493065
Validation loss: 2.6734219726077826

Epoch: 5| Step: 9
Training loss: 0.9397490861994305
Validation loss: 2.6655511855933285

Epoch: 5| Step: 10
Training loss: 0.7447910620057824
Validation loss: 2.6483895447544725

Epoch: 310| Step: 0
Training loss: 0.5211196652764085
Validation loss: 2.6650879869483335

Epoch: 5| Step: 1
Training loss: 0.7930112179062531
Validation loss: 2.655574597383268

Epoch: 5| Step: 2
Training loss: 0.5759547454851756
Validation loss: 2.624096431201071

Epoch: 5| Step: 3
Training loss: 0.850796626348761
Validation loss: 2.6389173119364826

Epoch: 5| Step: 4
Training loss: 0.6721896166836847
Validation loss: 2.6664026611013996

Epoch: 5| Step: 5
Training loss: 0.48152488066462507
Validation loss: 2.66036699908298

Epoch: 5| Step: 6
Training loss: 0.3696153000780209
Validation loss: 2.6022393840416544

Epoch: 5| Step: 7
Training loss: 0.6425219572152322
Validation loss: 2.640401194942832

Epoch: 5| Step: 8
Training loss: 0.5359876536933026
Validation loss: 2.6235230114608172

Epoch: 5| Step: 9
Training loss: 0.9265890982864483
Validation loss: 2.605032195609777

Epoch: 5| Step: 10
Training loss: 0.5785916738861772
Validation loss: 2.610836574930184

Epoch: 311| Step: 0
Training loss: 0.4363095230877473
Validation loss: 2.6098913603282012

Epoch: 5| Step: 1
Training loss: 0.6715078459627137
Validation loss: 2.579031216779214

Epoch: 5| Step: 2
Training loss: 0.820135551623141
Validation loss: 2.6103545706874236

Epoch: 5| Step: 3
Training loss: 0.3647934399047372
Validation loss: 2.570885786424647

Epoch: 5| Step: 4
Training loss: 0.39400390280083136
Validation loss: 2.619627974107232

Epoch: 5| Step: 5
Training loss: 0.6097953031601129
Validation loss: 2.6179047501813706

Epoch: 5| Step: 6
Training loss: 0.6666016894702808
Validation loss: 2.6082528334213295

Epoch: 5| Step: 7
Training loss: 0.6518116911285879
Validation loss: 2.630360167628928

Epoch: 5| Step: 8
Training loss: 0.8124370183742987
Validation loss: 2.6219656498022457

Epoch: 5| Step: 9
Training loss: 0.9670804927465908
Validation loss: 2.6221010693159923

Epoch: 5| Step: 10
Training loss: 0.4432249831806468
Validation loss: 2.6578021345787475

Epoch: 312| Step: 0
Training loss: 0.6599506757829711
Validation loss: 2.6200178421359848

Epoch: 5| Step: 1
Training loss: 0.6334866594341554
Validation loss: 2.619808436635081

Epoch: 5| Step: 2
Training loss: 0.6807331285504894
Validation loss: 2.6373344210005074

Epoch: 5| Step: 3
Training loss: 0.7336648388625652
Validation loss: 2.6365716081442314

Epoch: 5| Step: 4
Training loss: 0.608543782759969
Validation loss: 2.618300871206411

Epoch: 5| Step: 5
Training loss: 0.8138335727957173
Validation loss: 2.6199820842410615

Epoch: 5| Step: 6
Training loss: 0.4603459554920706
Validation loss: 2.6012154580219042

Epoch: 5| Step: 7
Training loss: 0.5861447539951476
Validation loss: 2.617644126752374

Epoch: 5| Step: 8
Training loss: 0.6058734648669143
Validation loss: 2.634744725252065

Epoch: 5| Step: 9
Training loss: 0.4948147333356619
Validation loss: 2.6203502701348036

Epoch: 5| Step: 10
Training loss: 0.69225255173984
Validation loss: 2.652064253469359

Epoch: 313| Step: 0
Training loss: 0.44506842633621957
Validation loss: 2.659962572239557

Epoch: 5| Step: 1
Training loss: 0.27231812921798987
Validation loss: 2.6307655055416546

Epoch: 5| Step: 2
Training loss: 0.6611879852578729
Validation loss: 2.598866330482391

Epoch: 5| Step: 3
Training loss: 0.47732540725952766
Validation loss: 2.635896140499748

Epoch: 5| Step: 4
Training loss: 0.5402015593320167
Validation loss: 2.616104499911564

Epoch: 5| Step: 5
Training loss: 0.6182266131388231
Validation loss: 2.587934298511515

Epoch: 5| Step: 6
Training loss: 0.6355608844209488
Validation loss: 2.607792589227896

Epoch: 5| Step: 7
Training loss: 0.9219570446682643
Validation loss: 2.59637756235084

Epoch: 5| Step: 8
Training loss: 0.9203362635084917
Validation loss: 2.595535112760434

Epoch: 5| Step: 9
Training loss: 0.7330822625024654
Validation loss: 2.6006903427622303

Epoch: 5| Step: 10
Training loss: 0.3645249274564383
Validation loss: 2.6041322493381007

Epoch: 314| Step: 0
Training loss: 0.5443686408055795
Validation loss: 2.614018599423741

Epoch: 5| Step: 1
Training loss: 0.789332277617307
Validation loss: 2.607130571265008

Epoch: 5| Step: 2
Training loss: 0.6916153155265345
Validation loss: 2.6419144348838968

Epoch: 5| Step: 3
Training loss: 0.6287373381111409
Validation loss: 2.63288702119437

Epoch: 5| Step: 4
Training loss: 0.6398040815080707
Validation loss: 2.624647576835766

Epoch: 5| Step: 5
Training loss: 0.634391110784096
Validation loss: 2.6334121462813096

Epoch: 5| Step: 6
Training loss: 0.5478100004427475
Validation loss: 2.6420744560774327

Epoch: 5| Step: 7
Training loss: 0.6175041352260985
Validation loss: 2.622174728556247

Epoch: 5| Step: 8
Training loss: 0.6218645842556919
Validation loss: 2.634624132623646

Epoch: 5| Step: 9
Training loss: 0.6508580724611346
Validation loss: 2.6535944288770477

Epoch: 5| Step: 10
Training loss: 0.3866707550475322
Validation loss: 2.660641791419175

Epoch: 315| Step: 0
Training loss: 0.5900536220639458
Validation loss: 2.6446263127211607

Epoch: 5| Step: 1
Training loss: 0.37901341997181337
Validation loss: 2.626974055995979

Epoch: 5| Step: 2
Training loss: 0.6471688142341835
Validation loss: 2.6122092395542547

Epoch: 5| Step: 3
Training loss: 0.4797136529509189
Validation loss: 2.6128571371548275

Epoch: 5| Step: 4
Training loss: 0.4790881721500825
Validation loss: 2.6057681190440127

Epoch: 5| Step: 5
Training loss: 0.6286904574919204
Validation loss: 2.604694521330724

Epoch: 5| Step: 6
Training loss: 0.7210076161827532
Validation loss: 2.5962230991466018

Epoch: 5| Step: 7
Training loss: 0.7564078221485022
Validation loss: 2.597332524900725

Epoch: 5| Step: 8
Training loss: 0.6480104119986105
Validation loss: 2.594560089693596

Epoch: 5| Step: 9
Training loss: 0.7422527083812933
Validation loss: 2.622219409982253

Epoch: 5| Step: 10
Training loss: 0.6784308205393911
Validation loss: 2.6409445579773347

Epoch: 316| Step: 0
Training loss: 0.8492907397964731
Validation loss: 2.690207585307228

Epoch: 5| Step: 1
Training loss: 0.6520057305013959
Validation loss: 2.655635490972983

Epoch: 5| Step: 2
Training loss: 0.4608066987480006
Validation loss: 2.6160304913974888

Epoch: 5| Step: 3
Training loss: 0.34282557859831647
Validation loss: 2.6474810779137843

Epoch: 5| Step: 4
Training loss: 0.577366666635819
Validation loss: 2.6674419760993664

Epoch: 5| Step: 5
Training loss: 0.7489690847955963
Validation loss: 2.627385611690012

Epoch: 5| Step: 6
Training loss: 0.7113112839910539
Validation loss: 2.662425354827818

Epoch: 5| Step: 7
Training loss: 0.601756820009299
Validation loss: 2.68682365845171

Epoch: 5| Step: 8
Training loss: 0.600015856612805
Validation loss: 2.649399899327542

Epoch: 5| Step: 9
Training loss: 0.5115672462350397
Validation loss: 2.6844323563286037

Epoch: 5| Step: 10
Training loss: 0.5996083809412566
Validation loss: 2.64805565378892

Epoch: 317| Step: 0
Training loss: 0.5322485682986504
Validation loss: 2.6492836494973537

Epoch: 5| Step: 1
Training loss: 0.8112330462266821
Validation loss: 2.6480103317430705

Epoch: 5| Step: 2
Training loss: 0.5368778909021422
Validation loss: 2.6203245822413845

Epoch: 5| Step: 3
Training loss: 0.5449341803361119
Validation loss: 2.606194108503537

Epoch: 5| Step: 4
Training loss: 0.4572563758069789
Validation loss: 2.597217106159266

Epoch: 5| Step: 5
Training loss: 0.7335941952510048
Validation loss: 2.597753146499562

Epoch: 5| Step: 6
Training loss: 0.6523720284003434
Validation loss: 2.5811068526270033

Epoch: 5| Step: 7
Training loss: 0.6496615977809657
Validation loss: 2.552041210423792

Epoch: 5| Step: 8
Training loss: 0.6060775649251983
Validation loss: 2.6166322795385524

Epoch: 5| Step: 9
Training loss: 0.6728332694214809
Validation loss: 2.6039623959729887

Epoch: 5| Step: 10
Training loss: 0.5429877682655265
Validation loss: 2.600317945594739

Epoch: 318| Step: 0
Training loss: 0.3531331580409679
Validation loss: 2.5836779820681928

Epoch: 5| Step: 1
Training loss: 0.4103667672638972
Validation loss: 2.6015151731312827

Epoch: 5| Step: 2
Training loss: 0.5978645510230006
Validation loss: 2.587007661078007

Epoch: 5| Step: 3
Training loss: 0.654310129515351
Validation loss: 2.6114152140364824

Epoch: 5| Step: 4
Training loss: 0.7566816406476861
Validation loss: 2.6200557922904997

Epoch: 5| Step: 5
Training loss: 0.5774608095916357
Validation loss: 2.631915869973355

Epoch: 5| Step: 6
Training loss: 0.7948616623627072
Validation loss: 2.6368104533022017

Epoch: 5| Step: 7
Training loss: 0.5445540085446492
Validation loss: 2.6347986680491555

Epoch: 5| Step: 8
Training loss: 0.6147309680923142
Validation loss: 2.6444481235433863

Epoch: 5| Step: 9
Training loss: 0.6874997182325306
Validation loss: 2.632136392502061

Epoch: 5| Step: 10
Training loss: 0.5764562906997202
Validation loss: 2.631341163225768

Epoch: 319| Step: 0
Training loss: 0.46000266240220206
Validation loss: 2.6344373130792933

Epoch: 5| Step: 1
Training loss: 0.5918040007612329
Validation loss: 2.6074632795683623

Epoch: 5| Step: 2
Training loss: 0.43076148628776884
Validation loss: 2.5929452591878683

Epoch: 5| Step: 3
Training loss: 0.2115273000658613
Validation loss: 2.5543740029899635

Epoch: 5| Step: 4
Training loss: 0.56829377415187
Validation loss: 2.5766096696504848

Epoch: 5| Step: 5
Training loss: 0.5613189590332235
Validation loss: 2.569895601079747

Epoch: 5| Step: 6
Training loss: 0.9708837882152883
Validation loss: 2.589711666628946

Epoch: 5| Step: 7
Training loss: 0.41807904080691494
Validation loss: 2.545518086991663

Epoch: 5| Step: 8
Training loss: 0.6314511667883437
Validation loss: 2.5700346390739304

Epoch: 5| Step: 9
Training loss: 0.8459050595982822
Validation loss: 2.5762052486502314

Epoch: 5| Step: 10
Training loss: 0.5306943905124384
Validation loss: 2.5746800142312485

Epoch: 320| Step: 0
Training loss: 0.2672297723134336
Validation loss: 2.6060128792933295

Epoch: 5| Step: 1
Training loss: 0.615215967296547
Validation loss: 2.621194533387469

Epoch: 5| Step: 2
Training loss: 0.4919665612743506
Validation loss: 2.617665852014277

Epoch: 5| Step: 3
Training loss: 0.44966995136092497
Validation loss: 2.6290609089988624

Epoch: 5| Step: 4
Training loss: 0.5544160796710462
Validation loss: 2.6226263882897247

Epoch: 5| Step: 5
Training loss: 0.8285329641553848
Validation loss: 2.589867469947356

Epoch: 5| Step: 6
Training loss: 0.7988995657689147
Validation loss: 2.6220062722842368

Epoch: 5| Step: 7
Training loss: 0.7335887514701744
Validation loss: 2.608025823768019

Epoch: 5| Step: 8
Training loss: 0.6552711861993857
Validation loss: 2.6268612893575294

Epoch: 5| Step: 9
Training loss: 0.4656502595232897
Validation loss: 2.5813133593685413

Epoch: 5| Step: 10
Training loss: 0.4554536277131937
Validation loss: 2.6028482544481744

Epoch: 321| Step: 0
Training loss: 0.6956026993267558
Validation loss: 2.5965271725082095

Epoch: 5| Step: 1
Training loss: 0.6854565117993263
Validation loss: 2.602033862186676

Epoch: 5| Step: 2
Training loss: 0.6368540520634285
Validation loss: 2.6087841946631416

Epoch: 5| Step: 3
Training loss: 0.6479489657783158
Validation loss: 2.6122915174650427

Epoch: 5| Step: 4
Training loss: 0.30130081385304114
Validation loss: 2.576119970188594

Epoch: 5| Step: 5
Training loss: 0.559659354962831
Validation loss: 2.57639324835495

Epoch: 5| Step: 6
Training loss: 0.7042628512254359
Validation loss: 2.604671288277254

Epoch: 5| Step: 7
Training loss: 0.5119557887263735
Validation loss: 2.5880176314743157

Epoch: 5| Step: 8
Training loss: 0.40237654394924266
Validation loss: 2.615781095845664

Epoch: 5| Step: 9
Training loss: 0.6617077534920489
Validation loss: 2.615607345763959

Epoch: 5| Step: 10
Training loss: 0.6327824055615315
Validation loss: 2.613444978444126

Epoch: 322| Step: 0
Training loss: 0.6470118327245353
Validation loss: 2.6271798536117026

Epoch: 5| Step: 1
Training loss: 0.7352619901818928
Validation loss: 2.62621246361826

Epoch: 5| Step: 2
Training loss: 0.3469399777974892
Validation loss: 2.6248627513001486

Epoch: 5| Step: 3
Training loss: 0.5417687307692395
Validation loss: 2.629270286936968

Epoch: 5| Step: 4
Training loss: 0.6698723377118645
Validation loss: 2.636671564127364

Epoch: 5| Step: 5
Training loss: 0.6146547523855379
Validation loss: 2.6260645105013047

Epoch: 5| Step: 6
Training loss: 0.3558878052929679
Validation loss: 2.6240326602549207

Epoch: 5| Step: 7
Training loss: 0.6565098475133861
Validation loss: 2.628880695444994

Epoch: 5| Step: 8
Training loss: 0.6824147111050484
Validation loss: 2.612905637589829

Epoch: 5| Step: 9
Training loss: 0.4867355907092284
Validation loss: 2.6084114345555167

Epoch: 5| Step: 10
Training loss: 0.7127581329550701
Validation loss: 2.617900208069404

Epoch: 323| Step: 0
Training loss: 0.7317577148202847
Validation loss: 2.6074598683766985

Epoch: 5| Step: 1
Training loss: 0.52810348602355
Validation loss: 2.61992447566463

Epoch: 5| Step: 2
Training loss: 0.22329629958136488
Validation loss: 2.6014230253418686

Epoch: 5| Step: 3
Training loss: 0.547538708794689
Validation loss: 2.6181061182026237

Epoch: 5| Step: 4
Training loss: 0.5654537215585067
Validation loss: 2.611537686286448

Epoch: 5| Step: 5
Training loss: 0.8279293836920186
Validation loss: 2.608794103163619

Epoch: 5| Step: 6
Training loss: 0.5602952079849212
Validation loss: 2.619114172530293

Epoch: 5| Step: 7
Training loss: 0.5032533363481836
Validation loss: 2.616903431609504

Epoch: 5| Step: 8
Training loss: 0.4381869066664499
Validation loss: 2.607466156390606

Epoch: 5| Step: 9
Training loss: 0.723465008140577
Validation loss: 2.596740777471942

Epoch: 5| Step: 10
Training loss: 0.6454089806133732
Validation loss: 2.6039161390985983

Epoch: 324| Step: 0
Training loss: 0.5733527575665983
Validation loss: 2.601034080523253

Epoch: 5| Step: 1
Training loss: 0.6676578355837759
Validation loss: 2.642993705118842

Epoch: 5| Step: 2
Training loss: 0.656718314055199
Validation loss: 2.639716133528358

Epoch: 5| Step: 3
Training loss: 0.43446431099440985
Validation loss: 2.60766152314538

Epoch: 5| Step: 4
Training loss: 0.4124832807389319
Validation loss: 2.622440918479274

Epoch: 5| Step: 5
Training loss: 0.6892546457210875
Validation loss: 2.6432278838256327

Epoch: 5| Step: 6
Training loss: 0.681992688569118
Validation loss: 2.6299538187780507

Epoch: 5| Step: 7
Training loss: 0.6362985499881528
Validation loss: 2.6409128969861553

Epoch: 5| Step: 8
Training loss: 0.5029358502353002
Validation loss: 2.6371113409005256

Epoch: 5| Step: 9
Training loss: 0.4464258197290902
Validation loss: 2.647830225725404

Epoch: 5| Step: 10
Training loss: 0.5020213693025776
Validation loss: 2.6267829851816087

Epoch: 325| Step: 0
Training loss: 0.4703184273178357
Validation loss: 2.6385177842143794

Epoch: 5| Step: 1
Training loss: 0.554646154662678
Validation loss: 2.6371118328031695

Epoch: 5| Step: 2
Training loss: 0.7093654060555245
Validation loss: 2.6382189859081975

Epoch: 5| Step: 3
Training loss: 0.7067769473173819
Validation loss: 2.663642441926402

Epoch: 5| Step: 4
Training loss: 0.5417593791063529
Validation loss: 2.6642461264834507

Epoch: 5| Step: 5
Training loss: 0.6049641875630916
Validation loss: 2.65851831935956

Epoch: 5| Step: 6
Training loss: 0.3871688342886972
Validation loss: 2.644255916809474

Epoch: 5| Step: 7
Training loss: 0.5408514992651446
Validation loss: 2.6378986273769582

Epoch: 5| Step: 8
Training loss: 0.5813440708208114
Validation loss: 2.6403891369548975

Epoch: 5| Step: 9
Training loss: 0.6456061676395518
Validation loss: 2.631670171670952

Epoch: 5| Step: 10
Training loss: 0.40611477582043104
Validation loss: 2.605175903332069

Epoch: 326| Step: 0
Training loss: 0.553904773618724
Validation loss: 2.604453916068671

Epoch: 5| Step: 1
Training loss: 0.3226950125698076
Validation loss: 2.5777210832774364

Epoch: 5| Step: 2
Training loss: 0.7208942273682856
Validation loss: 2.595906823328995

Epoch: 5| Step: 3
Training loss: 0.4850610827049387
Validation loss: 2.586904225781534

Epoch: 5| Step: 4
Training loss: 0.3092878479012433
Validation loss: 2.5680992845393544

Epoch: 5| Step: 5
Training loss: 0.7140215955909067
Validation loss: 2.560059074922272

Epoch: 5| Step: 6
Training loss: 0.6759699298981845
Validation loss: 2.5730652062354284

Epoch: 5| Step: 7
Training loss: 0.7116008639977428
Validation loss: 2.5561407874685176

Epoch: 5| Step: 8
Training loss: 0.20941545465707864
Validation loss: 2.5641261942674256

Epoch: 5| Step: 9
Training loss: 0.32308987489297464
Validation loss: 2.548036096374602

Epoch: 5| Step: 10
Training loss: 0.7594739260815578
Validation loss: 2.544527305635661

Epoch: 327| Step: 0
Training loss: 0.5964565577887533
Validation loss: 2.56288308282239

Epoch: 5| Step: 1
Training loss: 0.5485932197014123
Validation loss: 2.5670240730564213

Epoch: 5| Step: 2
Training loss: 0.4087196622900017
Validation loss: 2.6137228844474922

Epoch: 5| Step: 3
Training loss: 0.4128046904524756
Validation loss: 2.6018149098787764

Epoch: 5| Step: 4
Training loss: 0.8892999462700324
Validation loss: 2.5987971678779656

Epoch: 5| Step: 5
Training loss: 0.462771034083143
Validation loss: 2.596536826646167

Epoch: 5| Step: 6
Training loss: 0.5158743977673738
Validation loss: 2.610309355192654

Epoch: 5| Step: 7
Training loss: 0.5785512126354393
Validation loss: 2.6170571532442013

Epoch: 5| Step: 8
Training loss: 0.32377820935941837
Validation loss: 2.5938348164474525

Epoch: 5| Step: 9
Training loss: 0.6403461174915787
Validation loss: 2.610737955098068

Epoch: 5| Step: 10
Training loss: 0.6818109425247115
Validation loss: 2.5966454850576013

Epoch: 328| Step: 0
Training loss: 0.3025875473820757
Validation loss: 2.60634535158183

Epoch: 5| Step: 1
Training loss: 0.6703271557466203
Validation loss: 2.57632632538409

Epoch: 5| Step: 2
Training loss: 0.6021645740842565
Validation loss: 2.5807428050539425

Epoch: 5| Step: 3
Training loss: 0.6275202482687747
Validation loss: 2.6206798166403855

Epoch: 5| Step: 4
Training loss: 0.7984371954213735
Validation loss: 2.6099653464741026

Epoch: 5| Step: 5
Training loss: 0.6283103536540525
Validation loss: 2.651950556517979

Epoch: 5| Step: 6
Training loss: 0.5928270796459468
Validation loss: 2.6442588534628904

Epoch: 5| Step: 7
Training loss: 0.4679365411287238
Validation loss: 2.627396493100429

Epoch: 5| Step: 8
Training loss: 0.40426224638578656
Validation loss: 2.6375033115509448

Epoch: 5| Step: 9
Training loss: 0.3338382468194471
Validation loss: 2.6642447947448056

Epoch: 5| Step: 10
Training loss: 0.6015389425445865
Validation loss: 2.6851567839317765

Epoch: 329| Step: 0
Training loss: 0.6197163405177992
Validation loss: 2.6686152451715257

Epoch: 5| Step: 1
Training loss: 0.5808114961389494
Validation loss: 2.613815334709505

Epoch: 5| Step: 2
Training loss: 0.48331951691622066
Validation loss: 2.6218455337315154

Epoch: 5| Step: 3
Training loss: 0.5064494399473725
Validation loss: 2.6193220822294427

Epoch: 5| Step: 4
Training loss: 0.5219470197128981
Validation loss: 2.57951460423441

Epoch: 5| Step: 5
Training loss: 0.4989342507169713
Validation loss: 2.6087429181751487

Epoch: 5| Step: 6
Training loss: 0.6014241146091436
Validation loss: 2.576879778982451

Epoch: 5| Step: 7
Training loss: 0.6214889372748678
Validation loss: 2.6200461181599595

Epoch: 5| Step: 8
Training loss: 0.7314101084652418
Validation loss: 2.641111505414729

Epoch: 5| Step: 9
Training loss: 0.47303693589243734
Validation loss: 2.6111365985200976

Epoch: 5| Step: 10
Training loss: 0.5076575409604815
Validation loss: 2.6522610829829856

Epoch: 330| Step: 0
Training loss: 0.5637694709866344
Validation loss: 2.6709158912108357

Epoch: 5| Step: 1
Training loss: 0.6351264045713315
Validation loss: 2.679655261135652

Epoch: 5| Step: 2
Training loss: 0.7721914407219673
Validation loss: 2.6395524204522207

Epoch: 5| Step: 3
Training loss: 0.5308180904545441
Validation loss: 2.6604657030734993

Epoch: 5| Step: 4
Training loss: 0.5120426637915735
Validation loss: 2.630770929517694

Epoch: 5| Step: 5
Training loss: 0.5009324796143068
Validation loss: 2.620589126331164

Epoch: 5| Step: 6
Training loss: 0.5877740180374659
Validation loss: 2.6159184251040632

Epoch: 5| Step: 7
Training loss: 0.500428195230845
Validation loss: 2.5939448580322026

Epoch: 5| Step: 8
Training loss: 0.5559917750676453
Validation loss: 2.5781492787122535

Epoch: 5| Step: 9
Training loss: 0.39173493052518493
Validation loss: 2.6026164875512414

Epoch: 5| Step: 10
Training loss: 0.5259387762334143
Validation loss: 2.6289112989577728

Epoch: 331| Step: 0
Training loss: 0.6498778099972242
Validation loss: 2.6140544751801618

Epoch: 5| Step: 1
Training loss: 0.616741502147406
Validation loss: 2.611626222614325

Epoch: 5| Step: 2
Training loss: 0.5268767938549416
Validation loss: 2.580647614308699

Epoch: 5| Step: 3
Training loss: 0.46081722436012285
Validation loss: 2.634014481491161

Epoch: 5| Step: 4
Training loss: 0.4980705704381626
Validation loss: 2.6137469678507226

Epoch: 5| Step: 5
Training loss: 0.576875444579444
Validation loss: 2.676884363485351

Epoch: 5| Step: 6
Training loss: 0.4613723966204155
Validation loss: 2.6655962286342327

Epoch: 5| Step: 7
Training loss: 0.4772043127509361
Validation loss: 2.6498061143820473

Epoch: 5| Step: 8
Training loss: 0.5078219192805057
Validation loss: 2.6383402532756337

Epoch: 5| Step: 9
Training loss: 0.6016518415022948
Validation loss: 2.633039007396404

Epoch: 5| Step: 10
Training loss: 0.5379026346521201
Validation loss: 2.6279082656124846

Epoch: 332| Step: 0
Training loss: 0.41787848879481465
Validation loss: 2.5981791717908647

Epoch: 5| Step: 1
Training loss: 0.7688202647530397
Validation loss: 2.5934160785824765

Epoch: 5| Step: 2
Training loss: 0.5279052570658628
Validation loss: 2.5721432318519897

Epoch: 5| Step: 3
Training loss: 0.6626019741246563
Validation loss: 2.597779684243649

Epoch: 5| Step: 4
Training loss: 0.30946403628641056
Validation loss: 2.582287560509876

Epoch: 5| Step: 5
Training loss: 0.520945753044745
Validation loss: 2.5663325354622755

Epoch: 5| Step: 6
Training loss: 0.7087464997543208
Validation loss: 2.6023809319568016

Epoch: 5| Step: 7
Training loss: 0.6038820703558836
Validation loss: 2.608486524110032

Epoch: 5| Step: 8
Training loss: 0.4989511695087388
Validation loss: 2.6293072518618876

Epoch: 5| Step: 9
Training loss: 0.5159891749843395
Validation loss: 2.642901660547259

Epoch: 5| Step: 10
Training loss: 0.4625969611161276
Validation loss: 2.611378008606176

Epoch: 333| Step: 0
Training loss: 0.6223454607979075
Validation loss: 2.6044543718131568

Epoch: 5| Step: 1
Training loss: 0.5446196507595498
Validation loss: 2.6092574827687844

Epoch: 5| Step: 2
Training loss: 0.547247623471554
Validation loss: 2.6302089730555096

Epoch: 5| Step: 3
Training loss: 0.34684717135447957
Validation loss: 2.620569140222934

Epoch: 5| Step: 4
Training loss: 0.42160205488654234
Validation loss: 2.6683293528010017

Epoch: 5| Step: 5
Training loss: 0.5257088077060582
Validation loss: 2.63501533008509

Epoch: 5| Step: 6
Training loss: 0.6866094283055808
Validation loss: 2.650704928156877

Epoch: 5| Step: 7
Training loss: 0.2984247414622881
Validation loss: 2.6249688278980368

Epoch: 5| Step: 8
Training loss: 0.3816359989194339
Validation loss: 2.6364373801749523

Epoch: 5| Step: 9
Training loss: 0.6060326442219558
Validation loss: 2.6412209371523296

Epoch: 5| Step: 10
Training loss: 0.703910473674334
Validation loss: 2.6129498451796924

Epoch: 334| Step: 0
Training loss: 0.46166464461160356
Validation loss: 2.623595520739405

Epoch: 5| Step: 1
Training loss: 0.5018883451822882
Validation loss: 2.6105011014574893

Epoch: 5| Step: 2
Training loss: 0.5546740409400225
Validation loss: 2.6248157571336983

Epoch: 5| Step: 3
Training loss: 0.24680316942380892
Validation loss: 2.6119549877889696

Epoch: 5| Step: 4
Training loss: 0.5558746421577773
Validation loss: 2.595964979708471

Epoch: 5| Step: 5
Training loss: 0.6407726164289441
Validation loss: 2.5887213325819523

Epoch: 5| Step: 6
Training loss: 0.7474853160781022
Validation loss: 2.5902970526913376

Epoch: 5| Step: 7
Training loss: 0.6118593193281542
Validation loss: 2.5773853701550324

Epoch: 5| Step: 8
Training loss: 0.5684758751882806
Validation loss: 2.602437446320581

Epoch: 5| Step: 9
Training loss: 0.3522936212273775
Validation loss: 2.6094817277955014

Epoch: 5| Step: 10
Training loss: 0.3076817520444671
Validation loss: 2.6159518169594924

Epoch: 335| Step: 0
Training loss: 0.5254508058477
Validation loss: 2.5865052650808034

Epoch: 5| Step: 1
Training loss: 0.49271928729353853
Validation loss: 2.650501673857863

Epoch: 5| Step: 2
Training loss: 0.5703887365937176
Validation loss: 2.598538653978923

Epoch: 5| Step: 3
Training loss: 0.537424695484043
Validation loss: 2.6745002062702743

Epoch: 5| Step: 4
Training loss: 0.414938198623954
Validation loss: 2.6578545691419087

Epoch: 5| Step: 5
Training loss: 0.5855578146046841
Validation loss: 2.624923412438231

Epoch: 5| Step: 6
Training loss: 0.4307781941911184
Validation loss: 2.611768552566728

Epoch: 5| Step: 7
Training loss: 0.7447608905827028
Validation loss: 2.604076919157689

Epoch: 5| Step: 8
Training loss: 0.5422063181137189
Validation loss: 2.5753682044226758

Epoch: 5| Step: 9
Training loss: 0.39112613956874254
Validation loss: 2.593271163109602

Epoch: 5| Step: 10
Training loss: 0.25752817717335497
Validation loss: 2.6010961696351695

Epoch: 336| Step: 0
Training loss: 0.45338028260869534
Validation loss: 2.574059242200132

Epoch: 5| Step: 1
Training loss: 0.5947164149428695
Validation loss: 2.575790327635038

Epoch: 5| Step: 2
Training loss: 0.42353300727789855
Validation loss: 2.6039611092112662

Epoch: 5| Step: 3
Training loss: 0.5483766375296155
Validation loss: 2.5973498086953

Epoch: 5| Step: 4
Training loss: 0.3947641044329226
Validation loss: 2.598328703372251

Epoch: 5| Step: 5
Training loss: 0.5201334797122807
Validation loss: 2.6152994465963113

Epoch: 5| Step: 6
Training loss: 0.48910043282915744
Validation loss: 2.583590489415437

Epoch: 5| Step: 7
Training loss: 0.3387753035008775
Validation loss: 2.5979497558224334

Epoch: 5| Step: 8
Training loss: 0.6738104334181131
Validation loss: 2.6209615013799215

Epoch: 5| Step: 9
Training loss: 0.613900085014366
Validation loss: 2.6223899407108813

Epoch: 5| Step: 10
Training loss: 0.502150797235619
Validation loss: 2.644329688937381

Epoch: 337| Step: 0
Training loss: 0.29566726215136646
Validation loss: 2.6297243150329694

Epoch: 5| Step: 1
Training loss: 0.5695434506212308
Validation loss: 2.6277817842402578

Epoch: 5| Step: 2
Training loss: 0.5236479208167089
Validation loss: 2.6332796887948464

Epoch: 5| Step: 3
Training loss: 0.36780356406844056
Validation loss: 2.637389420410963

Epoch: 5| Step: 4
Training loss: 0.6010992074415751
Validation loss: 2.6279340052198332

Epoch: 5| Step: 5
Training loss: 0.6200172163511085
Validation loss: 2.6161953275518215

Epoch: 5| Step: 6
Training loss: 0.38233645676553996
Validation loss: 2.61663268637894

Epoch: 5| Step: 7
Training loss: 0.6319081001403687
Validation loss: 2.5997258166402486

Epoch: 5| Step: 8
Training loss: 0.4062164732963665
Validation loss: 2.598948225890752

Epoch: 5| Step: 9
Training loss: 0.4921053863329831
Validation loss: 2.607314319058337

Epoch: 5| Step: 10
Training loss: 0.6046885478087028
Validation loss: 2.584599446820554

Epoch: 338| Step: 0
Training loss: 0.5581548607197419
Validation loss: 2.6149555188649503

Epoch: 5| Step: 1
Training loss: 0.21695409692828865
Validation loss: 2.6180291796360837

Epoch: 5| Step: 2
Training loss: 0.5544661496650811
Validation loss: 2.6001375974431413

Epoch: 5| Step: 3
Training loss: 0.3780059737460082
Validation loss: 2.6345556635196656

Epoch: 5| Step: 4
Training loss: 0.5262132182371666
Validation loss: 2.6190808493793107

Epoch: 5| Step: 5
Training loss: 0.30862303486225817
Validation loss: 2.637203356206645

Epoch: 5| Step: 6
Training loss: 0.6361958749753711
Validation loss: 2.634659048126172

Epoch: 5| Step: 7
Training loss: 0.6502657475454767
Validation loss: 2.6561328743887493

Epoch: 5| Step: 8
Training loss: 0.2605206695143286
Validation loss: 2.6432848681360714

Epoch: 5| Step: 9
Training loss: 0.5221776176261739
Validation loss: 2.6478969690164953

Epoch: 5| Step: 10
Training loss: 0.672544567127503
Validation loss: 2.6163289302128807

Epoch: 339| Step: 0
Training loss: 0.34506716665253706
Validation loss: 2.600181254059253

Epoch: 5| Step: 1
Training loss: 0.6316495027785201
Validation loss: 2.606774574719573

Epoch: 5| Step: 2
Training loss: 0.4236030860133773
Validation loss: 2.5950988514556124

Epoch: 5| Step: 3
Training loss: 0.3089344100002728
Validation loss: 2.586175542610008

Epoch: 5| Step: 4
Training loss: 0.7896270243316977
Validation loss: 2.5992066280394823

Epoch: 5| Step: 5
Training loss: 0.3967974136387939
Validation loss: 2.622864872511794

Epoch: 5| Step: 6
Training loss: 0.4995679478772431
Validation loss: 2.625677311441172

Epoch: 5| Step: 7
Training loss: 0.6642078913678475
Validation loss: 2.6359821396937075

Epoch: 5| Step: 8
Training loss: 0.3820170682681453
Validation loss: 2.6234370528692756

Epoch: 5| Step: 9
Training loss: 0.3443043963201767
Validation loss: 2.6315631045990986

Epoch: 5| Step: 10
Training loss: 0.49145259183812845
Validation loss: 2.666074789668546

Epoch: 340| Step: 0
Training loss: 0.4410645166399372
Validation loss: 2.6504171280375313

Epoch: 5| Step: 1
Training loss: 0.17871842082047168
Validation loss: 2.6496059666527385

Epoch: 5| Step: 2
Training loss: 0.3396043153240675
Validation loss: 2.665670551738468

Epoch: 5| Step: 3
Training loss: 0.3926043145852617
Validation loss: 2.6549744643340265

Epoch: 5| Step: 4
Training loss: 0.3136873813848581
Validation loss: 2.6601743427814357

Epoch: 5| Step: 5
Training loss: 0.6702418105547485
Validation loss: 2.6865981559376566

Epoch: 5| Step: 6
Training loss: 0.5587103395232803
Validation loss: 2.6758237409769596

Epoch: 5| Step: 7
Training loss: 0.5764387644084161
Validation loss: 2.6506760903606263

Epoch: 5| Step: 8
Training loss: 0.6645488528770929
Validation loss: 2.6614614747996566

Epoch: 5| Step: 9
Training loss: 0.5400031355484245
Validation loss: 2.6584902210933006

Epoch: 5| Step: 10
Training loss: 0.47831407311615853
Validation loss: 2.6605069682155538

Epoch: 341| Step: 0
Training loss: 0.21844380952184264
Validation loss: 2.6551124429117525

Epoch: 5| Step: 1
Training loss: 0.6596972884658616
Validation loss: 2.62234023431846

Epoch: 5| Step: 2
Training loss: 0.5947969642398789
Validation loss: 2.614930933850802

Epoch: 5| Step: 3
Training loss: 0.5156918684631406
Validation loss: 2.598135658157105

Epoch: 5| Step: 4
Training loss: 0.5291618653577718
Validation loss: 2.6103439884913695

Epoch: 5| Step: 5
Training loss: 0.3856177600137675
Validation loss: 2.5787893106274153

Epoch: 5| Step: 6
Training loss: 0.4231761541111843
Validation loss: 2.5967270654760797

Epoch: 5| Step: 7
Training loss: 0.586311068658451
Validation loss: 2.6022724568763045

Epoch: 5| Step: 8
Training loss: 0.38189160265629035
Validation loss: 2.6175773652251038

Epoch: 5| Step: 9
Training loss: 0.3987738180969394
Validation loss: 2.615190468255326

Epoch: 5| Step: 10
Training loss: 0.4970795156529996
Validation loss: 2.6451946053106488

Epoch: 342| Step: 0
Training loss: 0.38325949282501093
Validation loss: 2.628530323832086

Epoch: 5| Step: 1
Training loss: 0.5578937011941637
Validation loss: 2.608880453813167

Epoch: 5| Step: 2
Training loss: 0.5039086748404896
Validation loss: 2.608469838930383

Epoch: 5| Step: 3
Training loss: 0.3076663386723563
Validation loss: 2.6438672608773293

Epoch: 5| Step: 4
Training loss: 0.5257930136465672
Validation loss: 2.6413948367448956

Epoch: 5| Step: 5
Training loss: 0.5332607475696379
Validation loss: 2.608622650235132

Epoch: 5| Step: 6
Training loss: 0.3246351348901843
Validation loss: 2.6366283648885007

Epoch: 5| Step: 7
Training loss: 0.6186619060111557
Validation loss: 2.644936324666879

Epoch: 5| Step: 8
Training loss: 0.32902568995259446
Validation loss: 2.643913955198973

Epoch: 5| Step: 9
Training loss: 0.6276845260605881
Validation loss: 2.6225148756137373

Epoch: 5| Step: 10
Training loss: 0.45133184924379405
Validation loss: 2.662800871546286

Epoch: 343| Step: 0
Training loss: 0.6582514125419091
Validation loss: 2.640424918501965

Epoch: 5| Step: 1
Training loss: 0.4093731989347718
Validation loss: 2.645585893864387

Epoch: 5| Step: 2
Training loss: 0.5480266977893213
Validation loss: 2.639516244889074

Epoch: 5| Step: 3
Training loss: 0.2942266037146504
Validation loss: 2.663839350410953

Epoch: 5| Step: 4
Training loss: 0.4893191179253592
Validation loss: 2.6522987554371804

Epoch: 5| Step: 5
Training loss: 0.18499118513293827
Validation loss: 2.6300889751522027

Epoch: 5| Step: 6
Training loss: 0.2951927456927796
Validation loss: 2.645888223257149

Epoch: 5| Step: 7
Training loss: 0.40034622318348667
Validation loss: 2.6113256902880697

Epoch: 5| Step: 8
Training loss: 0.6995333384776002
Validation loss: 2.6424200523676444

Epoch: 5| Step: 9
Training loss: 0.29670125494911104
Validation loss: 2.6068685606582083

Epoch: 5| Step: 10
Training loss: 0.7162643242114335
Validation loss: 2.6091624372260047

Epoch: 344| Step: 0
Training loss: 0.2721274327593006
Validation loss: 2.622549834540451

Epoch: 5| Step: 1
Training loss: 0.48702156847869904
Validation loss: 2.619892382067527

Epoch: 5| Step: 2
Training loss: 0.6783917232129983
Validation loss: 2.5765903960798426

Epoch: 5| Step: 3
Training loss: 0.44062935982569545
Validation loss: 2.6079931876014126

Epoch: 5| Step: 4
Training loss: 0.5628347989948962
Validation loss: 2.608404794015695

Epoch: 5| Step: 5
Training loss: 0.6027099020953244
Validation loss: 2.5902153815963316

Epoch: 5| Step: 6
Training loss: 0.44514942529494067
Validation loss: 2.5969680727004367

Epoch: 5| Step: 7
Training loss: 0.5825301470752485
Validation loss: 2.5703861502675323

Epoch: 5| Step: 8
Training loss: 0.24051298097822396
Validation loss: 2.5508106864863

Epoch: 5| Step: 9
Training loss: 0.38072949664740435
Validation loss: 2.579338792823745

Epoch: 5| Step: 10
Training loss: 0.3290238783977317
Validation loss: 2.5977879077214645

Epoch: 345| Step: 0
Training loss: 0.3781578695970111
Validation loss: 2.564537555851178

Epoch: 5| Step: 1
Training loss: 0.46580897223466106
Validation loss: 2.604196478560249

Epoch: 5| Step: 2
Training loss: 0.6296724189864431
Validation loss: 2.612734616368186

Epoch: 5| Step: 3
Training loss: 0.49428773280986876
Validation loss: 2.6395265989217283

Epoch: 5| Step: 4
Training loss: 0.2654153613672742
Validation loss: 2.6725758039649334

Epoch: 5| Step: 5
Training loss: 0.476974715510394
Validation loss: 2.641032850099632

Epoch: 5| Step: 6
Training loss: 0.5595064243240998
Validation loss: 2.6203069187334562

Epoch: 5| Step: 7
Training loss: 0.43832275819652816
Validation loss: 2.6180023526399445

Epoch: 5| Step: 8
Training loss: 0.5217999421469472
Validation loss: 2.6042965091617263

Epoch: 5| Step: 9
Training loss: 0.50433786522585
Validation loss: 2.615935993783156

Epoch: 5| Step: 10
Training loss: 0.5045201015097192
Validation loss: 2.5941883363672495

Epoch: 346| Step: 0
Training loss: 0.4814694226400703
Validation loss: 2.581658294318218

Epoch: 5| Step: 1
Training loss: 0.6413261019665176
Validation loss: 2.5860535639248337

Epoch: 5| Step: 2
Training loss: 0.24546396566496276
Validation loss: 2.6196939132152828

Epoch: 5| Step: 3
Training loss: 0.5927384191787135
Validation loss: 2.6054055129890696

Epoch: 5| Step: 4
Training loss: 0.42509308594994843
Validation loss: 2.617958439438443

Epoch: 5| Step: 5
Training loss: 0.3656981680276792
Validation loss: 2.622145629786141

Epoch: 5| Step: 6
Training loss: 0.5766495615658573
Validation loss: 2.6365021248768064

Epoch: 5| Step: 7
Training loss: 0.5151400163734796
Validation loss: 2.6793515703281763

Epoch: 5| Step: 8
Training loss: 0.19175768721874228
Validation loss: 2.6378506428400694

Epoch: 5| Step: 9
Training loss: 0.6529602518325102
Validation loss: 2.6824530220343017

Epoch: 5| Step: 10
Training loss: 0.4791360375386741
Validation loss: 2.67038161333545

Epoch: 347| Step: 0
Training loss: 0.46653971910911973
Validation loss: 2.6671367716060184

Epoch: 5| Step: 1
Training loss: 0.32385282663849485
Validation loss: 2.667816351377303

Epoch: 5| Step: 2
Training loss: 0.595646239519445
Validation loss: 2.6437458698177703

Epoch: 5| Step: 3
Training loss: 0.5056972759444266
Validation loss: 2.6410375133202124

Epoch: 5| Step: 4
Training loss: 0.5233891023494767
Validation loss: 2.6360887724831827

Epoch: 5| Step: 5
Training loss: 0.38560444750802997
Validation loss: 2.644264344773041

Epoch: 5| Step: 6
Training loss: 0.2998541005322532
Validation loss: 2.627210607206766

Epoch: 5| Step: 7
Training loss: 0.6005193657924678
Validation loss: 2.642555716874427

Epoch: 5| Step: 8
Training loss: 0.6127010686894021
Validation loss: 2.6158350416052962

Epoch: 5| Step: 9
Training loss: 0.3616786184767883
Validation loss: 2.624956323013204

Epoch: 5| Step: 10
Training loss: 0.44490388895844346
Validation loss: 2.6250445395820705

Epoch: 348| Step: 0
Training loss: 0.3932773190083272
Validation loss: 2.63790857909774

Epoch: 5| Step: 1
Training loss: 0.5201749041195454
Validation loss: 2.610925361358287

Epoch: 5| Step: 2
Training loss: 0.5050929091695018
Validation loss: 2.640982773347675

Epoch: 5| Step: 3
Training loss: 0.5026070457995343
Validation loss: 2.624107578305718

Epoch: 5| Step: 4
Training loss: 0.3526134993568514
Validation loss: 2.6644683183330313

Epoch: 5| Step: 5
Training loss: 0.3641434559019447
Validation loss: 2.656088234537749

Epoch: 5| Step: 6
Training loss: 0.7009262674888321
Validation loss: 2.650930143676716

Epoch: 5| Step: 7
Training loss: 0.3697165583059587
Validation loss: 2.6399809038519413

Epoch: 5| Step: 8
Training loss: 0.5052201639999052
Validation loss: 2.669420604250707

Epoch: 5| Step: 9
Training loss: 0.4536261910858873
Validation loss: 2.621492184814302

Epoch: 5| Step: 10
Training loss: 0.3745669407523216
Validation loss: 2.638512850315735

Epoch: 349| Step: 0
Training loss: 0.6882403462235572
Validation loss: 2.6330647615946674

Epoch: 5| Step: 1
Training loss: 0.3512694939196272
Validation loss: 2.62713917158323

Epoch: 5| Step: 2
Training loss: 0.4546533001494567
Validation loss: 2.626749581690425

Epoch: 5| Step: 3
Training loss: 0.5955322771061028
Validation loss: 2.624186575824904

Epoch: 5| Step: 4
Training loss: 0.4551907183150892
Validation loss: 2.598215421659805

Epoch: 5| Step: 5
Training loss: 0.6144301956467427
Validation loss: 2.650130609860315

Epoch: 5| Step: 6
Training loss: 0.3932792134889625
Validation loss: 2.5897444589367224

Epoch: 5| Step: 7
Training loss: 0.3725529941522994
Validation loss: 2.5944641435811953

Epoch: 5| Step: 8
Training loss: 0.4522126813361012
Validation loss: 2.6415437106363084

Epoch: 5| Step: 9
Training loss: 0.18466940747633093
Validation loss: 2.6284156708125908

Epoch: 5| Step: 10
Training loss: 0.3287623210599736
Validation loss: 2.6106988443142765

Epoch: 350| Step: 0
Training loss: 0.47242538867197026
Validation loss: 2.638598769567677

Epoch: 5| Step: 1
Training loss: 0.5370754716750085
Validation loss: 2.61650072079338

Epoch: 5| Step: 2
Training loss: 0.4970808196690399
Validation loss: 2.6327983351551256

Epoch: 5| Step: 3
Training loss: 0.7115024794979682
Validation loss: 2.667188759296027

Epoch: 5| Step: 4
Training loss: 0.5322648060908668
Validation loss: 2.6689616878117284

Epoch: 5| Step: 5
Training loss: 0.23726390755100563
Validation loss: 2.6523900645765446

Epoch: 5| Step: 6
Training loss: 0.3887937920059549
Validation loss: 2.649313417859004

Epoch: 5| Step: 7
Training loss: 0.43264460422965034
Validation loss: 2.6640602765933945

Epoch: 5| Step: 8
Training loss: 0.3749459744319359
Validation loss: 2.652970862427592

Epoch: 5| Step: 9
Training loss: 0.5425966483484023
Validation loss: 2.6316762347715286

Epoch: 5| Step: 10
Training loss: 0.19065391837099435
Validation loss: 2.616337134092493

Epoch: 351| Step: 0
Training loss: 0.5892648445496259
Validation loss: 2.59850249297209

Epoch: 5| Step: 1
Training loss: 0.30085492160763067
Validation loss: 2.631828679557952

Epoch: 5| Step: 2
Training loss: 0.4357584281298912
Validation loss: 2.590233830290447

Epoch: 5| Step: 3
Training loss: 0.6493161694162929
Validation loss: 2.5812849858076254

Epoch: 5| Step: 4
Training loss: 0.5114544193042956
Validation loss: 2.56094604763849

Epoch: 5| Step: 5
Training loss: 0.5670672013255963
Validation loss: 2.5787194773246154

Epoch: 5| Step: 6
Training loss: 0.22575484388695102
Validation loss: 2.579284593136334

Epoch: 5| Step: 7
Training loss: 0.41653068429566625
Validation loss: 2.5795589979656794

Epoch: 5| Step: 8
Training loss: 0.3685840871918056
Validation loss: 2.567178457654377

Epoch: 5| Step: 9
Training loss: 0.37167958646964355
Validation loss: 2.5717127893257477

Epoch: 5| Step: 10
Training loss: 0.4653430308976284
Validation loss: 2.5822766369403998

Epoch: 352| Step: 0
Training loss: 0.3516485850584359
Validation loss: 2.5851633704906702

Epoch: 5| Step: 1
Training loss: 0.5631782363470094
Validation loss: 2.609169611818861

Epoch: 5| Step: 2
Training loss: 0.4882889098520279
Validation loss: 2.5729994162513448

Epoch: 5| Step: 3
Training loss: 0.5136585596483716
Validation loss: 2.568659550910459

Epoch: 5| Step: 4
Training loss: 0.49664256759342845
Validation loss: 2.5851689332828856

Epoch: 5| Step: 5
Training loss: 0.4619921563812036
Validation loss: 2.5986869904308407

Epoch: 5| Step: 6
Training loss: 0.4805059186003271
Validation loss: 2.5618954607445135

Epoch: 5| Step: 7
Training loss: 0.5929640034723102
Validation loss: 2.5607764597790976

Epoch: 5| Step: 8
Training loss: 0.2527227844221918
Validation loss: 2.5625099023867244

Epoch: 5| Step: 9
Training loss: 0.4043680395621002
Validation loss: 2.567117008218094

Epoch: 5| Step: 10
Training loss: 0.38421118432128215
Validation loss: 2.5736004217830937

Epoch: 353| Step: 0
Training loss: 0.47694786312565557
Validation loss: 2.574650998014741

Epoch: 5| Step: 1
Training loss: 0.5002890883620468
Validation loss: 2.5899752960851363

Epoch: 5| Step: 2
Training loss: 0.4425887918828204
Validation loss: 2.5829367741790246

Epoch: 5| Step: 3
Training loss: 0.46124422245490687
Validation loss: 2.6266399481858285

Epoch: 5| Step: 4
Training loss: 0.4973951376332582
Validation loss: 2.6341806652371917

Epoch: 5| Step: 5
Training loss: 0.39115143588642604
Validation loss: 2.651576260593796

Epoch: 5| Step: 6
Training loss: 0.5313811140388436
Validation loss: 2.630765395424885

Epoch: 5| Step: 7
Training loss: 0.5180228284220423
Validation loss: 2.5980935780203085

Epoch: 5| Step: 8
Training loss: 0.3908985515253902
Validation loss: 2.5897340395095476

Epoch: 5| Step: 9
Training loss: 0.35259248534799625
Validation loss: 2.5663329869881197

Epoch: 5| Step: 10
Training loss: 0.4705014885160309
Validation loss: 2.5936887466743332

Epoch: 354| Step: 0
Training loss: 0.3067281075836541
Validation loss: 2.6177358949974563

Epoch: 5| Step: 1
Training loss: 0.1893954435021467
Validation loss: 2.611745119377218

Epoch: 5| Step: 2
Training loss: 0.5437532698872782
Validation loss: 2.574035202783342

Epoch: 5| Step: 3
Training loss: 0.5059847878781707
Validation loss: 2.606207129339633

Epoch: 5| Step: 4
Training loss: 0.44968882305382735
Validation loss: 2.5828952364904683

Epoch: 5| Step: 5
Training loss: 0.3380666946585332
Validation loss: 2.66805637075027

Epoch: 5| Step: 6
Training loss: 0.46957003073084497
Validation loss: 2.64232345396904

Epoch: 5| Step: 7
Training loss: 0.4927512376693286
Validation loss: 2.645509129444422

Epoch: 5| Step: 8
Training loss: 0.5452238497228548
Validation loss: 2.67352985840505

Epoch: 5| Step: 9
Training loss: 0.47610184026942176
Validation loss: 2.685896836255847

Epoch: 5| Step: 10
Training loss: 0.42784415103591805
Validation loss: 2.6331298418758653

Epoch: 355| Step: 0
Training loss: 0.49653121103049747
Validation loss: 2.6410639510237743

Epoch: 5| Step: 1
Training loss: 0.303091023694123
Validation loss: 2.674802268395562

Epoch: 5| Step: 2
Training loss: 0.7025233343599926
Validation loss: 2.6472298429085956

Epoch: 5| Step: 3
Training loss: 0.49392961060050483
Validation loss: 2.671888580604384

Epoch: 5| Step: 4
Training loss: 0.4782324439603759
Validation loss: 2.6515914423000266

Epoch: 5| Step: 5
Training loss: 0.36058888464429845
Validation loss: 2.64436406377936

Epoch: 5| Step: 6
Training loss: 0.2442196374829471
Validation loss: 2.65182879785629

Epoch: 5| Step: 7
Training loss: 0.561246534986781
Validation loss: 2.672688480591756

Epoch: 5| Step: 8
Training loss: 0.43981045923902023
Validation loss: 2.6474869334108866

Epoch: 5| Step: 9
Training loss: 0.32384825990152555
Validation loss: 2.668657154738055

Epoch: 5| Step: 10
Training loss: 0.30299838459729944
Validation loss: 2.653810687604432

Epoch: 356| Step: 0
Training loss: 0.4717036018074752
Validation loss: 2.6347850636260395

Epoch: 5| Step: 1
Training loss: 0.13337867333484982
Validation loss: 2.614003489797662

Epoch: 5| Step: 2
Training loss: 0.2517272025026473
Validation loss: 2.5968159912547706

Epoch: 5| Step: 3
Training loss: 0.4360504147720857
Validation loss: 2.5980416414730447

Epoch: 5| Step: 4
Training loss: 0.34044369544548975
Validation loss: 2.635399518064009

Epoch: 5| Step: 5
Training loss: 0.19948359257109946
Validation loss: 2.575304627471931

Epoch: 5| Step: 6
Training loss: 0.6849855477834184
Validation loss: 2.596054832204784

Epoch: 5| Step: 7
Training loss: 0.5221855221978565
Validation loss: 2.6223423909375145

Epoch: 5| Step: 8
Training loss: 0.5904638807343802
Validation loss: 2.6220366964459494

Epoch: 5| Step: 9
Training loss: 0.4749503931694279
Validation loss: 2.5977549465470013

Epoch: 5| Step: 10
Training loss: 0.3147763196615315
Validation loss: 2.612225405241614

Epoch: 357| Step: 0
Training loss: 0.5319496484318764
Validation loss: 2.61321008206033

Epoch: 5| Step: 1
Training loss: 0.43933375114764506
Validation loss: 2.6012917270262297

Epoch: 5| Step: 2
Training loss: 0.6133948056972789
Validation loss: 2.6045481122307703

Epoch: 5| Step: 3
Training loss: 0.3321530511386037
Validation loss: 2.6001034690803126

Epoch: 5| Step: 4
Training loss: 0.2946244944696374
Validation loss: 2.6252642829079362

Epoch: 5| Step: 5
Training loss: 0.4558601372850545
Validation loss: 2.599560328667361

Epoch: 5| Step: 6
Training loss: 0.39030697274245835
Validation loss: 2.591803230193591

Epoch: 5| Step: 7
Training loss: 0.4816916495194318
Validation loss: 2.578121432155553

Epoch: 5| Step: 8
Training loss: 0.1964080886178156
Validation loss: 2.58652077272414

Epoch: 5| Step: 9
Training loss: 0.17980971533827103
Validation loss: 2.609160943744868

Epoch: 5| Step: 10
Training loss: 0.5887175159442424
Validation loss: 2.5769704630681396

Epoch: 358| Step: 0
Training loss: 0.5026198534584628
Validation loss: 2.5585098965513766

Epoch: 5| Step: 1
Training loss: 0.4280564650094709
Validation loss: 2.5824314518619906

Epoch: 5| Step: 2
Training loss: 0.5017287944214749
Validation loss: 2.618874189195853

Epoch: 5| Step: 3
Training loss: 0.294588936840559
Validation loss: 2.6121513692635028

Epoch: 5| Step: 4
Training loss: 0.21498246483210992
Validation loss: 2.6369416902604064

Epoch: 5| Step: 5
Training loss: 0.5464523862320496
Validation loss: 2.643277222161011

Epoch: 5| Step: 6
Training loss: 0.44604007778867655
Validation loss: 2.66379025385705

Epoch: 5| Step: 7
Training loss: 0.33236680745791125
Validation loss: 2.659915589075691

Epoch: 5| Step: 8
Training loss: 0.42882117589823227
Validation loss: 2.6596712710521926

Epoch: 5| Step: 9
Training loss: 0.5911073602152651
Validation loss: 2.6624437855700993

Epoch: 5| Step: 10
Training loss: 0.40339345938354687
Validation loss: 2.6786635720830536

Epoch: 359| Step: 0
Training loss: 0.33902891625589093
Validation loss: 2.678160133446779

Epoch: 5| Step: 1
Training loss: 0.30911348734240623
Validation loss: 2.6462191538697866

Epoch: 5| Step: 2
Training loss: 0.424790568500775
Validation loss: 2.6342687208253555

Epoch: 5| Step: 3
Training loss: 0.4287259527196836
Validation loss: 2.6437244194796787

Epoch: 5| Step: 4
Training loss: 0.501188207465768
Validation loss: 2.632109339174416

Epoch: 5| Step: 5
Training loss: 0.5318737575547873
Validation loss: 2.6306446734899795

Epoch: 5| Step: 6
Training loss: 0.5021692842172002
Validation loss: 2.630851959425866

Epoch: 5| Step: 7
Training loss: 0.19262137362639364
Validation loss: 2.648999326065016

Epoch: 5| Step: 8
Training loss: 0.5232141217390052
Validation loss: 2.600688803999945

Epoch: 5| Step: 9
Training loss: 0.5417935118952459
Validation loss: 2.6147285861983587

Epoch: 5| Step: 10
Training loss: 0.09743884205000995
Validation loss: 2.6273502975339884

Epoch: 360| Step: 0
Training loss: 0.32329863087175126
Validation loss: 2.636094450030187

Epoch: 5| Step: 1
Training loss: 0.44935078546386
Validation loss: 2.6135312823487693

Epoch: 5| Step: 2
Training loss: 0.2505317486680359
Validation loss: 2.622129733506787

Epoch: 5| Step: 3
Training loss: 0.6075713289637883
Validation loss: 2.6362568977724052

Epoch: 5| Step: 4
Training loss: 0.3326722185236047
Validation loss: 2.613180879541285

Epoch: 5| Step: 5
Training loss: 0.3528643135360681
Validation loss: 2.621934086695583

Epoch: 5| Step: 6
Training loss: 0.46091057003685765
Validation loss: 2.6293669566038744

Epoch: 5| Step: 7
Training loss: 0.5475448048778933
Validation loss: 2.6108377920235313

Epoch: 5| Step: 8
Training loss: 0.3846087063154552
Validation loss: 2.6117917833438296

Epoch: 5| Step: 9
Training loss: 0.39025838814321956
Validation loss: 2.633023371613156

Epoch: 5| Step: 10
Training loss: 0.4661376639845499
Validation loss: 2.645754443726845

Epoch: 361| Step: 0
Training loss: 0.4784101408866805
Validation loss: 2.630770139212143

Epoch: 5| Step: 1
Training loss: 0.3294940498448661
Validation loss: 2.6111067140091726

Epoch: 5| Step: 2
Training loss: 0.3722282935334555
Validation loss: 2.617774858533633

Epoch: 5| Step: 3
Training loss: 0.476328526578524
Validation loss: 2.6483757149047573

Epoch: 5| Step: 4
Training loss: 0.4817028478818196
Validation loss: 2.6249871407470753

Epoch: 5| Step: 5
Training loss: 0.36373178170977094
Validation loss: 2.624231697774985

Epoch: 5| Step: 6
Training loss: 0.48241327254930566
Validation loss: 2.6011324631199146

Epoch: 5| Step: 7
Training loss: 0.3766869905074987
Validation loss: 2.61652636441549

Epoch: 5| Step: 8
Training loss: 0.37965280193760387
Validation loss: 2.610083001019314

Epoch: 5| Step: 9
Training loss: 0.4249445893125093
Validation loss: 2.6032618398251794

Epoch: 5| Step: 10
Training loss: 0.33094287210558293
Validation loss: 2.604375965854697

Epoch: 362| Step: 0
Training loss: 0.354429444364279
Validation loss: 2.6152249918210315

Epoch: 5| Step: 1
Training loss: 0.6567795297368098
Validation loss: 2.6456528362176077

Epoch: 5| Step: 2
Training loss: 0.4554599748031123
Validation loss: 2.6016420638417257

Epoch: 5| Step: 3
Training loss: 0.30866356554869756
Validation loss: 2.6492219644547337

Epoch: 5| Step: 4
Training loss: 0.372103091420539
Validation loss: 2.6048231630475063

Epoch: 5| Step: 5
Training loss: 0.3918652110725198
Validation loss: 2.6101764059637347

Epoch: 5| Step: 6
Training loss: 0.5500035849367696
Validation loss: 2.6427043687006377

Epoch: 5| Step: 7
Training loss: 0.3906144140716487
Validation loss: 2.6365074612068766

Epoch: 5| Step: 8
Training loss: 0.30397157432802546
Validation loss: 2.6319192402144105

Epoch: 5| Step: 9
Training loss: 0.34323494428287965
Validation loss: 2.5996132772471907

Epoch: 5| Step: 10
Training loss: 0.36360558009030935
Validation loss: 2.5994715204393803

Epoch: 363| Step: 0
Training loss: 0.36097613536593554
Validation loss: 2.60401602098085

Epoch: 5| Step: 1
Training loss: 0.3379495933101615
Validation loss: 2.617646079614288

Epoch: 5| Step: 2
Training loss: 0.28915661491124484
Validation loss: 2.616094765111805

Epoch: 5| Step: 3
Training loss: 0.4923716609286696
Validation loss: 2.619311810311603

Epoch: 5| Step: 4
Training loss: 0.430528788178898
Validation loss: 2.648267088008583

Epoch: 5| Step: 5
Training loss: 0.5850668733227761
Validation loss: 2.633394014683003

Epoch: 5| Step: 6
Training loss: 0.48176669213517
Validation loss: 2.6241570226177218

Epoch: 5| Step: 7
Training loss: 0.381886764226536
Validation loss: 2.649748475026919

Epoch: 5| Step: 8
Training loss: 0.36006005961712345
Validation loss: 2.630866378362057

Epoch: 5| Step: 9
Training loss: 0.3299743331153605
Validation loss: 2.638014049481017

Epoch: 5| Step: 10
Training loss: 0.3553777515346452
Validation loss: 2.6750380747855766

Epoch: 364| Step: 0
Training loss: 0.23150719245979773
Validation loss: 2.6488385260028617

Epoch: 5| Step: 1
Training loss: 0.3996996802710256
Validation loss: 2.6565040037448235

Epoch: 5| Step: 2
Training loss: 0.5961913312682309
Validation loss: 2.6860294864346836

Epoch: 5| Step: 3
Training loss: 0.36910003358199495
Validation loss: 2.6453529327442347

Epoch: 5| Step: 4
Training loss: 0.3225518775954479
Validation loss: 2.637834521456955

Epoch: 5| Step: 5
Training loss: 0.36087506732735236
Validation loss: 2.651253304975857

Epoch: 5| Step: 6
Training loss: 0.44369903862835924
Validation loss: 2.625722757309115

Epoch: 5| Step: 7
Training loss: 0.49832552426363774
Validation loss: 2.597741345499766

Epoch: 5| Step: 8
Training loss: 0.42530782434947145
Validation loss: 2.5865221107818117

Epoch: 5| Step: 9
Training loss: 0.35311276575011186
Validation loss: 2.5913201851244887

Epoch: 5| Step: 10
Training loss: 0.4296267206381204
Validation loss: 2.5933545119102535

Epoch: 365| Step: 0
Training loss: 0.33084682814622823
Validation loss: 2.574975884102916

Epoch: 5| Step: 1
Training loss: 0.28932726822724325
Validation loss: 2.595467234343137

Epoch: 5| Step: 2
Training loss: 0.29779850221382786
Validation loss: 2.5983761992754686

Epoch: 5| Step: 3
Training loss: 0.23368615010237154
Validation loss: 2.6195010713942204

Epoch: 5| Step: 4
Training loss: 0.2752234580576231
Validation loss: 2.565436368828688

Epoch: 5| Step: 5
Training loss: 0.4161077943523834
Validation loss: 2.584208998660982

Epoch: 5| Step: 6
Training loss: 0.7123833928976797
Validation loss: 2.58911153544024

Epoch: 5| Step: 7
Training loss: 0.40872943295639097
Validation loss: 2.5792970391574794

Epoch: 5| Step: 8
Training loss: 0.32483259942466214
Validation loss: 2.5733838789103802

Epoch: 5| Step: 9
Training loss: 0.5448577733774557
Validation loss: 2.609579145985802

Epoch: 5| Step: 10
Training loss: 0.5020550576105622
Validation loss: 2.5659049697643033

Epoch: 366| Step: 0
Training loss: 0.42403487686899066
Validation loss: 2.5394281651263593

Epoch: 5| Step: 1
Training loss: 0.5347735017763438
Validation loss: 2.5924928615662957

Epoch: 5| Step: 2
Training loss: 0.40342578016967945
Validation loss: 2.6001772161106067

Epoch: 5| Step: 3
Training loss: 0.40984856099872824
Validation loss: 2.6157688724219366

Epoch: 5| Step: 4
Training loss: 0.320583937936085
Validation loss: 2.5954454995796166

Epoch: 5| Step: 5
Training loss: 0.4657340139746686
Validation loss: 2.5963194961809277

Epoch: 5| Step: 6
Training loss: 0.23884156277593527
Validation loss: 2.5926496828411376

Epoch: 5| Step: 7
Training loss: 0.6172329849672881
Validation loss: 2.5747248905948585

Epoch: 5| Step: 8
Training loss: 0.2890349452314266
Validation loss: 2.608895797992983

Epoch: 5| Step: 9
Training loss: 0.2933756482198841
Validation loss: 2.5893408122217587

Epoch: 5| Step: 10
Training loss: 0.4472411869485739
Validation loss: 2.5996467515716755

Epoch: 367| Step: 0
Training loss: 0.32439151435224106
Validation loss: 2.6164634078822724

Epoch: 5| Step: 1
Training loss: 0.5213832971575282
Validation loss: 2.6262683880380364

Epoch: 5| Step: 2
Training loss: 0.3192615480716679
Validation loss: 2.6480562946855315

Epoch: 5| Step: 3
Training loss: 0.46478214977728494
Validation loss: 2.6457036840642165

Epoch: 5| Step: 4
Training loss: 0.2890575124980477
Validation loss: 2.629652003994944

Epoch: 5| Step: 5
Training loss: 0.40814635689719536
Validation loss: 2.646845437870635

Epoch: 5| Step: 6
Training loss: 0.3595921648089529
Validation loss: 2.673150404434798

Epoch: 5| Step: 7
Training loss: 0.4094932829349054
Validation loss: 2.6454174941314643

Epoch: 5| Step: 8
Training loss: 0.4740013497782051
Validation loss: 2.6207061256486632

Epoch: 5| Step: 9
Training loss: 0.4651245102770882
Validation loss: 2.6217608138127346

Epoch: 5| Step: 10
Training loss: 0.3850961611225798
Validation loss: 2.6009944123195976

Epoch: 368| Step: 0
Training loss: 0.4413647421166385
Validation loss: 2.617063022935447

Epoch: 5| Step: 1
Training loss: 0.38610394089640615
Validation loss: 2.628414739835254

Epoch: 5| Step: 2
Training loss: 0.325646371158428
Validation loss: 2.5896342547034017

Epoch: 5| Step: 3
Training loss: 0.24157759563757403
Validation loss: 2.5896008779047768

Epoch: 5| Step: 4
Training loss: 0.2214519490451875
Validation loss: 2.6192123903548143

Epoch: 5| Step: 5
Training loss: 0.36511905910068976
Validation loss: 2.616100302800306

Epoch: 5| Step: 6
Training loss: 0.47327859748709095
Validation loss: 2.6401763882508726

Epoch: 5| Step: 7
Training loss: 0.6344722598078885
Validation loss: 2.6218970759977465

Epoch: 5| Step: 8
Training loss: 0.4171027722562211
Validation loss: 2.622290565111567

Epoch: 5| Step: 9
Training loss: 0.1844219236954784
Validation loss: 2.6257576608341333

Epoch: 5| Step: 10
Training loss: 0.46023115898722095
Validation loss: 2.6518412620625247

Epoch: 369| Step: 0
Training loss: 0.45455409645947054
Validation loss: 2.6178549578921477

Epoch: 5| Step: 1
Training loss: 0.257750893948334
Validation loss: 2.600261383686626

Epoch: 5| Step: 2
Training loss: 0.4972390748372975
Validation loss: 2.6430950414256036

Epoch: 5| Step: 3
Training loss: 0.36215221147542737
Validation loss: 2.6219521156793766

Epoch: 5| Step: 4
Training loss: 0.39442400843927317
Validation loss: 2.6352471650511866

Epoch: 5| Step: 5
Training loss: 0.41955838106822274
Validation loss: 2.6244485102923916

Epoch: 5| Step: 6
Training loss: 0.5096706141066802
Validation loss: 2.6194836714707255

Epoch: 5| Step: 7
Training loss: 0.3804331228193363
Validation loss: 2.6242872677881133

Epoch: 5| Step: 8
Training loss: 0.29869335850655276
Validation loss: 2.6126858262398662

Epoch: 5| Step: 9
Training loss: 0.3645069814387557
Validation loss: 2.5897450083424354

Epoch: 5| Step: 10
Training loss: 0.3056188434144553
Validation loss: 2.5870216317007593

Epoch: 370| Step: 0
Training loss: 0.12719589642686552
Validation loss: 2.5908248583014557

Epoch: 5| Step: 1
Training loss: 0.28467049442171943
Validation loss: 2.5915929090264633

Epoch: 5| Step: 2
Training loss: 0.5503375112383456
Validation loss: 2.5996902608680714

Epoch: 5| Step: 3
Training loss: 0.41926427405618844
Validation loss: 2.604749111547211

Epoch: 5| Step: 4
Training loss: 0.38089397957901955
Validation loss: 2.609210132865094

Epoch: 5| Step: 5
Training loss: 0.47338014135598183
Validation loss: 2.615329135182573

Epoch: 5| Step: 6
Training loss: 0.34359189212118096
Validation loss: 2.628762105601113

Epoch: 5| Step: 7
Training loss: 0.27125965395681123
Validation loss: 2.6196811864508

Epoch: 5| Step: 8
Training loss: 0.3476829947139095
Validation loss: 2.6280684528903286

Epoch: 5| Step: 9
Training loss: 0.5707902083384432
Validation loss: 2.62008661482828

Epoch: 5| Step: 10
Training loss: 0.2965169554489222
Validation loss: 2.6388279211762184

Epoch: 371| Step: 0
Training loss: 0.5513340225542152
Validation loss: 2.6400358811448132

Epoch: 5| Step: 1
Training loss: 0.38327337276358897
Validation loss: 2.627526947476834

Epoch: 5| Step: 2
Training loss: 0.443865717991447
Validation loss: 2.6021056441706882

Epoch: 5| Step: 3
Training loss: 0.3005049042912443
Validation loss: 2.634057051557665

Epoch: 5| Step: 4
Training loss: 0.40095491420542423
Validation loss: 2.6191299207136347

Epoch: 5| Step: 5
Training loss: 0.27247428177727434
Validation loss: 2.6275711817699463

Epoch: 5| Step: 6
Training loss: 0.4268990115035196
Validation loss: 2.632028391319833

Epoch: 5| Step: 7
Training loss: 0.29585987255214763
Validation loss: 2.6214334852662375

Epoch: 5| Step: 8
Training loss: 0.40112456996486934
Validation loss: 2.6236028552006663

Epoch: 5| Step: 9
Training loss: 0.4462312122471849
Validation loss: 2.629767431251607

Epoch: 5| Step: 10
Training loss: 0.15962629328467434
Validation loss: 2.5917607594000645

Epoch: 372| Step: 0
Training loss: 0.3420509157238789
Validation loss: 2.658972619913627

Epoch: 5| Step: 1
Training loss: 0.3399113226173005
Validation loss: 2.615760905408229

Epoch: 5| Step: 2
Training loss: 0.37298102072197925
Validation loss: 2.612824834101903

Epoch: 5| Step: 3
Training loss: 0.35064091158443333
Validation loss: 2.618205558625886

Epoch: 5| Step: 4
Training loss: 0.49621688636205447
Validation loss: 2.6117546524791377

Epoch: 5| Step: 5
Training loss: 0.25675989337903776
Validation loss: 2.6025554832927513

Epoch: 5| Step: 6
Training loss: 0.42972587067335377
Validation loss: 2.5848684390865735

Epoch: 5| Step: 7
Training loss: 0.3405803393037199
Validation loss: 2.5753103364908143

Epoch: 5| Step: 8
Training loss: 0.4691123515557727
Validation loss: 2.582034080692094

Epoch: 5| Step: 9
Training loss: 0.5275803211945429
Validation loss: 2.5831543542532533

Epoch: 5| Step: 10
Training loss: 0.14418925599557209
Validation loss: 2.616172934511856

Epoch: 373| Step: 0
Training loss: 0.35498991354193005
Validation loss: 2.607685771653754

Epoch: 5| Step: 1
Training loss: 0.2647830297130471
Validation loss: 2.6029531283896845

Epoch: 5| Step: 2
Training loss: 0.5002198332079371
Validation loss: 2.6045795656423176

Epoch: 5| Step: 3
Training loss: 0.34557027473196816
Validation loss: 2.6047309438060977

Epoch: 5| Step: 4
Training loss: 0.4097361093078621
Validation loss: 2.603747186818407

Epoch: 5| Step: 5
Training loss: 0.36665776776583486
Validation loss: 2.6336943347674002

Epoch: 5| Step: 6
Training loss: 0.39655677247176163
Validation loss: 2.623882325307441

Epoch: 5| Step: 7
Training loss: 0.34026100588788916
Validation loss: 2.6046475953689265

Epoch: 5| Step: 8
Training loss: 0.4372408985196165
Validation loss: 2.6433350283263723

Epoch: 5| Step: 9
Training loss: 0.452027586900022
Validation loss: 2.6057879008988216

Epoch: 5| Step: 10
Training loss: 0.30711032344232064
Validation loss: 2.6422268510685925

Epoch: 374| Step: 0
Training loss: 0.3788826531996812
Validation loss: 2.6445618934241604

Epoch: 5| Step: 1
Training loss: 0.46897966798437507
Validation loss: 2.6409817909842794

Epoch: 5| Step: 2
Training loss: 0.4853079332970753
Validation loss: 2.638396047918583

Epoch: 5| Step: 3
Training loss: 0.4195943220240764
Validation loss: 2.6558819066376738

Epoch: 5| Step: 4
Training loss: 0.2102283637676936
Validation loss: 2.6630923439804173

Epoch: 5| Step: 5
Training loss: 0.37153406623121427
Validation loss: 2.635827555141732

Epoch: 5| Step: 6
Training loss: 0.5102973298938319
Validation loss: 2.6110132046396877

Epoch: 5| Step: 7
Training loss: 0.25200890507650286
Validation loss: 2.6037966830037904

Epoch: 5| Step: 8
Training loss: 0.4326473423628771
Validation loss: 2.599334640890838

Epoch: 5| Step: 9
Training loss: 0.28487252791563644
Validation loss: 2.5820827798261092

Epoch: 5| Step: 10
Training loss: 0.4183896165134641
Validation loss: 2.5932407464841516

Epoch: 375| Step: 0
Training loss: 0.3020283618873776
Validation loss: 2.62318895910342

Epoch: 5| Step: 1
Training loss: 0.4612418963849877
Validation loss: 2.6228273622841844

Epoch: 5| Step: 2
Training loss: 0.40332363764613716
Validation loss: 2.625169469243126

Epoch: 5| Step: 3
Training loss: 0.44671653792376315
Validation loss: 2.6170617269416665

Epoch: 5| Step: 4
Training loss: 0.37692778507111296
Validation loss: 2.6736439829702308

Epoch: 5| Step: 5
Training loss: 0.5255112350035968
Validation loss: 2.6708293049413845

Epoch: 5| Step: 6
Training loss: 0.1846484165340934
Validation loss: 2.6630826509840047

Epoch: 5| Step: 7
Training loss: 0.3458456187574747
Validation loss: 2.6820063301346906

Epoch: 5| Step: 8
Training loss: 0.23028699529207697
Validation loss: 2.670731109712645

Epoch: 5| Step: 9
Training loss: 0.550080685766019
Validation loss: 2.6584111734785574

Epoch: 5| Step: 10
Training loss: 0.2941263851452533
Validation loss: 2.6424176608564913

Epoch: 376| Step: 0
Training loss: 0.4227841259612316
Validation loss: 2.6588771212401103

Epoch: 5| Step: 1
Training loss: 0.46630041304996855
Validation loss: 2.6445239920015258

Epoch: 5| Step: 2
Training loss: 0.34695904718750664
Validation loss: 2.6074940405581994

Epoch: 5| Step: 3
Training loss: 0.37266764913274775
Validation loss: 2.5789674020905964

Epoch: 5| Step: 4
Training loss: 0.30705768626698915
Validation loss: 2.594787957310047

Epoch: 5| Step: 5
Training loss: 0.40511009877338466
Validation loss: 2.5819180962263455

Epoch: 5| Step: 6
Training loss: 0.2806042967935345
Validation loss: 2.5741250688363073

Epoch: 5| Step: 7
Training loss: 0.5193888533634795
Validation loss: 2.5859233113641826

Epoch: 5| Step: 8
Training loss: 0.46350803324662593
Validation loss: 2.5878128465421257

Epoch: 5| Step: 9
Training loss: 0.24410650396328218
Validation loss: 2.567127572371023

Epoch: 5| Step: 10
Training loss: 0.19228810917886083
Validation loss: 2.582279991552356

Epoch: 377| Step: 0
Training loss: 0.4924434420259451
Validation loss: 2.571945591728825

Epoch: 5| Step: 1
Training loss: 0.4258799657215847
Validation loss: 2.5929393952114697

Epoch: 5| Step: 2
Training loss: 0.5832501136364359
Validation loss: 2.592773647612309

Epoch: 5| Step: 3
Training loss: 0.27488850750159366
Validation loss: 2.615206467491838

Epoch: 5| Step: 4
Training loss: 0.4833784157045602
Validation loss: 2.623475704046741

Epoch: 5| Step: 5
Training loss: 0.2505037328999696
Validation loss: 2.633695680007205

Epoch: 5| Step: 6
Training loss: 0.2706200267079288
Validation loss: 2.616189791044373

Epoch: 5| Step: 7
Training loss: 0.1798360148638138
Validation loss: 2.6067377657756445

Epoch: 5| Step: 8
Training loss: 0.4521286138221902
Validation loss: 2.6266300250200767

Epoch: 5| Step: 9
Training loss: 0.2179087316950814
Validation loss: 2.6231148616700564

Epoch: 5| Step: 10
Training loss: 0.2975049237436873
Validation loss: 2.6294486072049748

Epoch: 378| Step: 0
Training loss: 0.37891667145230656
Validation loss: 2.6508983413192704

Epoch: 5| Step: 1
Training loss: 0.3441004267411938
Validation loss: 2.6799008179811246

Epoch: 5| Step: 2
Training loss: 0.6606040429045574
Validation loss: 2.649136624901772

Epoch: 5| Step: 3
Training loss: 0.3719394684055031
Validation loss: 2.633279783229607

Epoch: 5| Step: 4
Training loss: 0.2711501499838241
Validation loss: 2.6573059280259854

Epoch: 5| Step: 5
Training loss: 0.21232139535696504
Validation loss: 2.6244218671126958

Epoch: 5| Step: 6
Training loss: 0.4176776085903463
Validation loss: 2.5967240661832958

Epoch: 5| Step: 7
Training loss: 0.45782261990243206
Validation loss: 2.624947576199558

Epoch: 5| Step: 8
Training loss: 0.3588918257369416
Validation loss: 2.595707388672308

Epoch: 5| Step: 9
Training loss: 0.23732905007722735
Validation loss: 2.605709270409296

Epoch: 5| Step: 10
Training loss: 0.37639036320041386
Validation loss: 2.6038995457312883

Epoch: 379| Step: 0
Training loss: 0.34728982452761387
Validation loss: 2.603493006706249

Epoch: 5| Step: 1
Training loss: 0.44697548063393067
Validation loss: 2.631880501663146

Epoch: 5| Step: 2
Training loss: 0.21591428721656705
Validation loss: 2.6433101772371583

Epoch: 5| Step: 3
Training loss: 0.3649033867332541
Validation loss: 2.614143064544954

Epoch: 5| Step: 4
Training loss: 0.39910974078065875
Validation loss: 2.638024144593275

Epoch: 5| Step: 5
Training loss: 0.51291740330143
Validation loss: 2.640314332313194

Epoch: 5| Step: 6
Training loss: 0.3897983769250903
Validation loss: 2.630499332054956

Epoch: 5| Step: 7
Training loss: 0.3395446908452323
Validation loss: 2.596075589667243

Epoch: 5| Step: 8
Training loss: 0.4657427645257947
Validation loss: 2.598864422695618

Epoch: 5| Step: 9
Training loss: 0.19357900957482305
Validation loss: 2.6170279995309063

Epoch: 5| Step: 10
Training loss: 0.29532509832403975
Validation loss: 2.5996771294864476

Epoch: 380| Step: 0
Training loss: 0.32936644718567704
Validation loss: 2.6205780581743476

Epoch: 5| Step: 1
Training loss: 0.4032795033348713
Validation loss: 2.5926814284253004

Epoch: 5| Step: 2
Training loss: 0.2597479850114461
Validation loss: 2.590383828934097

Epoch: 5| Step: 3
Training loss: 0.3043065991396594
Validation loss: 2.611319469490604

Epoch: 5| Step: 4
Training loss: 0.408127718444697
Validation loss: 2.5897653976464547

Epoch: 5| Step: 5
Training loss: 0.20169825344126202
Validation loss: 2.6081411829200385

Epoch: 5| Step: 6
Training loss: 0.38232254281291755
Validation loss: 2.61966208591269

Epoch: 5| Step: 7
Training loss: 0.5261955476800863
Validation loss: 2.6181058900498035

Epoch: 5| Step: 8
Training loss: 0.3671393464350246
Validation loss: 2.6266966589394944

Epoch: 5| Step: 9
Training loss: 0.47454376709136276
Validation loss: 2.639087205684002

Epoch: 5| Step: 10
Training loss: 0.4085620050881014
Validation loss: 2.651808321164133

Epoch: 381| Step: 0
Training loss: 0.45664952304547446
Validation loss: 2.6425266320121

Epoch: 5| Step: 1
Training loss: 0.35065376666918135
Validation loss: 2.6844026020939293

Epoch: 5| Step: 2
Training loss: 0.33660573810892835
Validation loss: 2.664581173758468

Epoch: 5| Step: 3
Training loss: 0.3309190522906608
Validation loss: 2.676386872873418

Epoch: 5| Step: 4
Training loss: 0.38486270357605007
Validation loss: 2.6996294369296523

Epoch: 5| Step: 5
Training loss: 0.3794226126668183
Validation loss: 2.679639131034205

Epoch: 5| Step: 6
Training loss: 0.2539259976263674
Validation loss: 2.6467416250873392

Epoch: 5| Step: 7
Training loss: 0.4887082331096789
Validation loss: 2.7021767914427355

Epoch: 5| Step: 8
Training loss: 0.44564649538091416
Validation loss: 2.6964507455628386

Epoch: 5| Step: 9
Training loss: 0.314781810924735
Validation loss: 2.637524363911592

Epoch: 5| Step: 10
Training loss: 0.32148716856993054
Validation loss: 2.6236430136020346

Epoch: 382| Step: 0
Training loss: 0.23430191330995495
Validation loss: 2.641805320085616

Epoch: 5| Step: 1
Training loss: 0.4105982986896199
Validation loss: 2.620905166853965

Epoch: 5| Step: 2
Training loss: 0.4290307487914432
Validation loss: 2.6364693316856638

Epoch: 5| Step: 3
Training loss: 0.26984842960119126
Validation loss: 2.6525037683010537

Epoch: 5| Step: 4
Training loss: 0.38231024588705687
Validation loss: 2.6614026506769144

Epoch: 5| Step: 5
Training loss: 0.5363679519613423
Validation loss: 2.670252973229446

Epoch: 5| Step: 6
Training loss: 0.433478176763299
Validation loss: 2.652179707689077

Epoch: 5| Step: 7
Training loss: 0.3614114819851776
Validation loss: 2.6277788984400714

Epoch: 5| Step: 8
Training loss: 0.2648767000704579
Validation loss: 2.637868878894009

Epoch: 5| Step: 9
Training loss: 0.1794038586379896
Validation loss: 2.6335598258123145

Epoch: 5| Step: 10
Training loss: 0.32406511458369414
Validation loss: 2.6258361947539712

Epoch: 383| Step: 0
Training loss: 0.31283172643608187
Validation loss: 2.6620162988403524

Epoch: 5| Step: 1
Training loss: 0.3384699072956724
Validation loss: 2.6226589738352213

Epoch: 5| Step: 2
Training loss: 0.2839646984561491
Validation loss: 2.6402280678699914

Epoch: 5| Step: 3
Training loss: 0.22871833352787083
Validation loss: 2.6177353955365095

Epoch: 5| Step: 4
Training loss: 0.4695606850840725
Validation loss: 2.6443470746728197

Epoch: 5| Step: 5
Training loss: 0.3774042543038045
Validation loss: 2.6178827441349015

Epoch: 5| Step: 6
Training loss: 0.3145603210461672
Validation loss: 2.6203881284022796

Epoch: 5| Step: 7
Training loss: 0.29948452930901237
Validation loss: 2.5861771564237586

Epoch: 5| Step: 8
Training loss: 0.37828335244225963
Validation loss: 2.5935207433157896

Epoch: 5| Step: 9
Training loss: 0.473636257513043
Validation loss: 2.622082923053289

Epoch: 5| Step: 10
Training loss: 0.4596636189858112
Validation loss: 2.6260570628388185

Epoch: 384| Step: 0
Training loss: 0.15700618629279642
Validation loss: 2.6365933446864864

Epoch: 5| Step: 1
Training loss: 0.39181037339512526
Validation loss: 2.6235659716230186

Epoch: 5| Step: 2
Training loss: 0.4150128165529512
Validation loss: 2.6284849967300596

Epoch: 5| Step: 3
Training loss: 0.2654032342457134
Validation loss: 2.6418416365495774

Epoch: 5| Step: 4
Training loss: 0.3681867476134933
Validation loss: 2.645822038756404

Epoch: 5| Step: 5
Training loss: 0.30180007984218465
Validation loss: 2.6307800316571703

Epoch: 5| Step: 6
Training loss: 0.4710085024653437
Validation loss: 2.612862270107801

Epoch: 5| Step: 7
Training loss: 0.4360379585270045
Validation loss: 2.6072488697053373

Epoch: 5| Step: 8
Training loss: 0.2678070898633507
Validation loss: 2.57775163280628

Epoch: 5| Step: 9
Training loss: 0.5015006493671659
Validation loss: 2.5773835399667733

Epoch: 5| Step: 10
Training loss: 0.3204842200188427
Validation loss: 2.5862799199874247

Epoch: 385| Step: 0
Training loss: 0.34164686998529925
Validation loss: 2.5833966564656903

Epoch: 5| Step: 1
Training loss: 0.5333820084870614
Validation loss: 2.6022748537563

Epoch: 5| Step: 2
Training loss: 0.1820211731082079
Validation loss: 2.636857141336572

Epoch: 5| Step: 3
Training loss: 0.2578013302088424
Validation loss: 2.6414021567224366

Epoch: 5| Step: 4
Training loss: 0.5197862845265144
Validation loss: 2.646673817198597

Epoch: 5| Step: 5
Training loss: 0.4097742936169269
Validation loss: 2.6551880462375723

Epoch: 5| Step: 6
Training loss: 0.26363104044875013
Validation loss: 2.6550844027437366

Epoch: 5| Step: 7
Training loss: 0.36064987447226904
Validation loss: 2.6695919370561496

Epoch: 5| Step: 8
Training loss: 0.333099498041033
Validation loss: 2.640599146240253

Epoch: 5| Step: 9
Training loss: 0.2802132864281516
Validation loss: 2.649544295887152

Epoch: 5| Step: 10
Training loss: 0.31335656076602236
Validation loss: 2.667037759873507

Epoch: 386| Step: 0
Training loss: 0.2462051230410839
Validation loss: 2.6623323768601446

Epoch: 5| Step: 1
Training loss: 0.3635014922598074
Validation loss: 2.680407446499545

Epoch: 5| Step: 2
Training loss: 0.3167682272567517
Validation loss: 2.6242961379365592

Epoch: 5| Step: 3
Training loss: 0.3226254159820488
Validation loss: 2.6177043425891595

Epoch: 5| Step: 4
Training loss: 0.4327957267127636
Validation loss: 2.622884920785908

Epoch: 5| Step: 5
Training loss: 0.5030453447110401
Validation loss: 2.6619987419964115

Epoch: 5| Step: 6
Training loss: 0.30706751320502834
Validation loss: 2.678021069741399

Epoch: 5| Step: 7
Training loss: 0.3317733436182093
Validation loss: 2.644434172258286

Epoch: 5| Step: 8
Training loss: 0.3562106679653282
Validation loss: 2.6493694555560654

Epoch: 5| Step: 9
Training loss: 0.2320161531976574
Validation loss: 2.6396804861101755

Epoch: 5| Step: 10
Training loss: 0.4386419311521384
Validation loss: 2.62446225132723

Epoch: 387| Step: 0
Training loss: 0.22533728366684197
Validation loss: 2.639074087705518

Epoch: 5| Step: 1
Training loss: 0.29861556078801565
Validation loss: 2.640075158400783

Epoch: 5| Step: 2
Training loss: 0.5470916863719204
Validation loss: 2.646096997781153

Epoch: 5| Step: 3
Training loss: 0.4647897961503501
Validation loss: 2.644757570901247

Epoch: 5| Step: 4
Training loss: 0.3624408599689879
Validation loss: 2.633231303677593

Epoch: 5| Step: 5
Training loss: 0.22735606353552454
Validation loss: 2.6010840230712207

Epoch: 5| Step: 6
Training loss: 0.3455548480306618
Validation loss: 2.624700904737348

Epoch: 5| Step: 7
Training loss: 0.3004915898648892
Validation loss: 2.617173067413388

Epoch: 5| Step: 8
Training loss: 0.4163351309557809
Validation loss: 2.6293823023748497

Epoch: 5| Step: 9
Training loss: 0.3123896165445223
Validation loss: 2.608603338017397

Epoch: 5| Step: 10
Training loss: 0.208569632075324
Validation loss: 2.614301607917971

Epoch: 388| Step: 0
Training loss: 0.2451122632994864
Validation loss: 2.6208431068490023

Epoch: 5| Step: 1
Training loss: 0.3279930939528851
Validation loss: 2.6130603655424487

Epoch: 5| Step: 2
Training loss: 0.3832428129061004
Validation loss: 2.615600934222181

Epoch: 5| Step: 3
Training loss: 0.46283251562631256
Validation loss: 2.595017463616942

Epoch: 5| Step: 4
Training loss: 0.13941171228892063
Validation loss: 2.601532867163348

Epoch: 5| Step: 5
Training loss: 0.2350628138101152
Validation loss: 2.6091408887650336

Epoch: 5| Step: 6
Training loss: 0.36863083934589347
Validation loss: 2.622513651231494

Epoch: 5| Step: 7
Training loss: 0.4284798383765774
Validation loss: 2.610693206790511

Epoch: 5| Step: 8
Training loss: 0.2632477351287762
Validation loss: 2.6102846881154336

Epoch: 5| Step: 9
Training loss: 0.2269828448640207
Validation loss: 2.5975116229022053

Epoch: 5| Step: 10
Training loss: 0.5609953412170219
Validation loss: 2.5798872368254684

Epoch: 389| Step: 0
Training loss: 0.1655286603216965
Validation loss: 2.6023711054309056

Epoch: 5| Step: 1
Training loss: 0.4498967072034638
Validation loss: 2.598485411202888

Epoch: 5| Step: 2
Training loss: 0.4009947522288524
Validation loss: 2.5935637101624422

Epoch: 5| Step: 3
Training loss: 0.23268851844868005
Validation loss: 2.6043814713681512

Epoch: 5| Step: 4
Training loss: 0.45731765380682954
Validation loss: 2.6294232285428483

Epoch: 5| Step: 5
Training loss: 0.2725797004686977
Validation loss: 2.636592777817631

Epoch: 5| Step: 6
Training loss: 0.3891108348803578
Validation loss: 2.617359885579684

Epoch: 5| Step: 7
Training loss: 0.24188550455609728
Validation loss: 2.6127868819442726

Epoch: 5| Step: 8
Training loss: 0.3891111603912555
Validation loss: 2.64095678427681

Epoch: 5| Step: 9
Training loss: 0.24805355813942934
Validation loss: 2.6257457630889496

Epoch: 5| Step: 10
Training loss: 0.45247837494448745
Validation loss: 2.657707989269772

Epoch: 390| Step: 0
Training loss: 0.258550022496385
Validation loss: 2.6235523734456048

Epoch: 5| Step: 1
Training loss: 0.5547095818221033
Validation loss: 2.655058026920358

Epoch: 5| Step: 2
Training loss: 0.24810355582645066
Validation loss: 2.6206770497013188

Epoch: 5| Step: 3
Training loss: 0.18933117274385827
Validation loss: 2.619210897710271

Epoch: 5| Step: 4
Training loss: 0.3134689211285428
Validation loss: 2.649073576747378

Epoch: 5| Step: 5
Training loss: 0.35191810425207215
Validation loss: 2.6417268067334576

Epoch: 5| Step: 6
Training loss: 0.2381842525233769
Validation loss: 2.6411623358613108

Epoch: 5| Step: 7
Training loss: 0.4023835616183013
Validation loss: 2.6097509073966845

Epoch: 5| Step: 8
Training loss: 0.2703348563987648
Validation loss: 2.6361443240028906

Epoch: 5| Step: 9
Training loss: 0.4536788449573965
Validation loss: 2.642530010063575

Epoch: 5| Step: 10
Training loss: 0.4073969898322881
Validation loss: 2.625303298765311

Epoch: 391| Step: 0
Training loss: 0.22875636209176822
Validation loss: 2.645825416476228

Epoch: 5| Step: 1
Training loss: 0.3131931009684354
Validation loss: 2.650276415156287

Epoch: 5| Step: 2
Training loss: 0.3500863130612604
Validation loss: 2.658182387345578

Epoch: 5| Step: 3
Training loss: 0.24981667084990292
Validation loss: 2.652791200948288

Epoch: 5| Step: 4
Training loss: 0.3054187753291454
Validation loss: 2.640345127113359

Epoch: 5| Step: 5
Training loss: 0.517500846419817
Validation loss: 2.654370571850296

Epoch: 5| Step: 6
Training loss: 0.313491785268069
Validation loss: 2.64251278409024

Epoch: 5| Step: 7
Training loss: 0.3974054471207524
Validation loss: 2.619014743113298

Epoch: 5| Step: 8
Training loss: 0.48308818378297935
Validation loss: 2.6556632371657383

Epoch: 5| Step: 9
Training loss: 0.299874685857369
Validation loss: 2.655704156044518

Epoch: 5| Step: 10
Training loss: 0.31589591702554454
Validation loss: 2.645233448350187

Epoch: 392| Step: 0
Training loss: 0.2290886516786876
Validation loss: 2.6312608946974954

Epoch: 5| Step: 1
Training loss: 0.3734076986831477
Validation loss: 2.623685041586507

Epoch: 5| Step: 2
Training loss: 0.4705224699569433
Validation loss: 2.6084078899551093

Epoch: 5| Step: 3
Training loss: 0.34639213349138076
Validation loss: 2.613289175523243

Epoch: 5| Step: 4
Training loss: 0.201245192713216
Validation loss: 2.56726206990604

Epoch: 5| Step: 5
Training loss: 0.23812721307732365
Validation loss: 2.5875951499301375

Epoch: 5| Step: 6
Training loss: 0.265139866032195
Validation loss: 2.6082883511004686

Epoch: 5| Step: 7
Training loss: 0.4823224509639903
Validation loss: 2.615011006599192

Epoch: 5| Step: 8
Training loss: 0.4170009603180565
Validation loss: 2.6268187295502816

Epoch: 5| Step: 9
Training loss: 0.3645353921523298
Validation loss: 2.625006078506987

Epoch: 5| Step: 10
Training loss: 0.5320848188725552
Validation loss: 2.6386318540004594

Epoch: 393| Step: 0
Training loss: 0.3895179893479737
Validation loss: 2.6497659413080745

Epoch: 5| Step: 1
Training loss: 0.3775678770670351
Validation loss: 2.6219420828619455

Epoch: 5| Step: 2
Training loss: 0.42468368736279183
Validation loss: 2.6288735268625483

Epoch: 5| Step: 3
Training loss: 0.4065723424155551
Validation loss: 2.6320669421469383

Epoch: 5| Step: 4
Training loss: 0.470137798775117
Validation loss: 2.640921790408639

Epoch: 5| Step: 5
Training loss: 0.36615345821698353
Validation loss: 2.6186556982651696

Epoch: 5| Step: 6
Training loss: 0.34112601792926933
Validation loss: 2.6462043758483245

Epoch: 5| Step: 7
Training loss: 0.23329220033867223
Validation loss: 2.674955169897039

Epoch: 5| Step: 8
Training loss: 0.3462084831900568
Validation loss: 2.6617016338033057

Epoch: 5| Step: 9
Training loss: 0.4433017306727955
Validation loss: 2.6798559971958404

Epoch: 5| Step: 10
Training loss: 0.23136178452976092
Validation loss: 2.722237744586022

Epoch: 394| Step: 0
Training loss: 0.5062120894377676
Validation loss: 2.673044594098994

Epoch: 5| Step: 1
Training loss: 0.43554252998682275
Validation loss: 2.7439400721185057

Epoch: 5| Step: 2
Training loss: 0.27867433218037113
Validation loss: 2.710656641648733

Epoch: 5| Step: 3
Training loss: 0.5142480787724429
Validation loss: 2.6890908798460362

Epoch: 5| Step: 4
Training loss: 0.494838207130718
Validation loss: 2.6363603163103027

Epoch: 5| Step: 5
Training loss: 0.3231923621001348
Validation loss: 2.6782391811171435

Epoch: 5| Step: 6
Training loss: 0.2954809435058724
Validation loss: 2.619174047227803

Epoch: 5| Step: 7
Training loss: 0.39726357398539885
Validation loss: 2.613231153544626

Epoch: 5| Step: 8
Training loss: 0.31163955485556344
Validation loss: 2.611931692702164

Epoch: 5| Step: 9
Training loss: 0.3147971244156275
Validation loss: 2.5709056537003994

Epoch: 5| Step: 10
Training loss: 0.2520364431377135
Validation loss: 2.5806495122174278

Epoch: 395| Step: 0
Training loss: 0.40775117084140944
Validation loss: 2.5743562768468014

Epoch: 5| Step: 1
Training loss: 0.3828927364730914
Validation loss: 2.537523865073552

Epoch: 5| Step: 2
Training loss: 0.4512396922479657
Validation loss: 2.5774364139798793

Epoch: 5| Step: 3
Training loss: 0.2848380809016814
Validation loss: 2.5850906236954487

Epoch: 5| Step: 4
Training loss: 0.3221401317048865
Validation loss: 2.6028181211219317

Epoch: 5| Step: 5
Training loss: 0.2929804100259433
Validation loss: 2.600306235106763

Epoch: 5| Step: 6
Training loss: 0.419845787074631
Validation loss: 2.5989318641792525

Epoch: 5| Step: 7
Training loss: 0.4089094922320196
Validation loss: 2.6264903744707073

Epoch: 5| Step: 8
Training loss: 0.42362157121713184
Validation loss: 2.665412208001843

Epoch: 5| Step: 9
Training loss: 0.3897992752789708
Validation loss: 2.642414129371561

Epoch: 5| Step: 10
Training loss: 0.315546279948222
Validation loss: 2.674700579687438

Epoch: 396| Step: 0
Training loss: 0.21237565673145062
Validation loss: 2.663412194997342

Epoch: 5| Step: 1
Training loss: 0.30925012148898673
Validation loss: 2.6593229447379025

Epoch: 5| Step: 2
Training loss: 0.36071572859905815
Validation loss: 2.672492026499186

Epoch: 5| Step: 3
Training loss: 0.4102796641370063
Validation loss: 2.6707868189748996

Epoch: 5| Step: 4
Training loss: 0.30121238574576636
Validation loss: 2.6842123165565095

Epoch: 5| Step: 5
Training loss: 0.3383760658574307
Validation loss: 2.676563535355029

Epoch: 5| Step: 6
Training loss: 0.4554191588531087
Validation loss: 2.7049928559245773

Epoch: 5| Step: 7
Training loss: 0.34064905624135733
Validation loss: 2.6710226189777546

Epoch: 5| Step: 8
Training loss: 0.28173883659532845
Validation loss: 2.6760197320539225

Epoch: 5| Step: 9
Training loss: 0.40796880978452726
Validation loss: 2.661149033580457

Epoch: 5| Step: 10
Training loss: 0.3981080469627123
Validation loss: 2.690664152906911

Epoch: 397| Step: 0
Training loss: 0.2727816208779974
Validation loss: 2.6535425071948553

Epoch: 5| Step: 1
Training loss: 0.3719579972683375
Validation loss: 2.684181494955169

Epoch: 5| Step: 2
Training loss: 0.5228283312327926
Validation loss: 2.6656956814807797

Epoch: 5| Step: 3
Training loss: 0.31573691036520135
Validation loss: 2.6450214168924386

Epoch: 5| Step: 4
Training loss: 0.36073892340967323
Validation loss: 2.63380787857028

Epoch: 5| Step: 5
Training loss: 0.2635661160332038
Validation loss: 2.6382272533873063

Epoch: 5| Step: 6
Training loss: 0.28410026253127874
Validation loss: 2.64826050820131

Epoch: 5| Step: 7
Training loss: 0.3295989536863103
Validation loss: 2.6124229439806936

Epoch: 5| Step: 8
Training loss: 0.21438070161761053
Validation loss: 2.6225379662316115

Epoch: 5| Step: 9
Training loss: 0.4236910198317
Validation loss: 2.6262263823600382

Epoch: 5| Step: 10
Training loss: 0.25290239400409315
Validation loss: 2.627964304175334

Epoch: 398| Step: 0
Training loss: 0.4076499293383066
Validation loss: 2.6476697226006176

Epoch: 5| Step: 1
Training loss: 0.2575060583762996
Validation loss: 2.618800135608414

Epoch: 5| Step: 2
Training loss: 0.3420789481128597
Validation loss: 2.6433785267474406

Epoch: 5| Step: 3
Training loss: 0.3100284711968742
Validation loss: 2.6328720524702267

Epoch: 5| Step: 4
Training loss: 0.3993553360947061
Validation loss: 2.6619941135691283

Epoch: 5| Step: 5
Training loss: 0.305166015468745
Validation loss: 2.6290133033809995

Epoch: 5| Step: 6
Training loss: 0.46075849775073247
Validation loss: 2.658022787585891

Epoch: 5| Step: 7
Training loss: 0.39560253751483826
Validation loss: 2.6648804529977475

Epoch: 5| Step: 8
Training loss: 0.31760839808318453
Validation loss: 2.648037113705827

Epoch: 5| Step: 9
Training loss: 0.2869007883967872
Validation loss: 2.649535479302212

Epoch: 5| Step: 10
Training loss: 0.37858257036316256
Validation loss: 2.6435791818429735

Epoch: 399| Step: 0
Training loss: 0.3652518773092685
Validation loss: 2.630973235057199

Epoch: 5| Step: 1
Training loss: 0.23659433393818236
Validation loss: 2.6769160409984796

Epoch: 5| Step: 2
Training loss: 0.32153472089010965
Validation loss: 2.6712322458664786

Epoch: 5| Step: 3
Training loss: 0.3100646731764352
Validation loss: 2.682042530475392

Epoch: 5| Step: 4
Training loss: 0.4803153933038975
Validation loss: 2.6549326892966842

Epoch: 5| Step: 5
Training loss: 0.3290419708542957
Validation loss: 2.676642517158461

Epoch: 5| Step: 6
Training loss: 0.4226137510075871
Validation loss: 2.6747585640792644

Epoch: 5| Step: 7
Training loss: 0.30204736835316504
Validation loss: 2.6760364362582636

Epoch: 5| Step: 8
Training loss: 0.29117815228433874
Validation loss: 2.642140745126712

Epoch: 5| Step: 9
Training loss: 0.26139646585945897
Validation loss: 2.642700536872919

Epoch: 5| Step: 10
Training loss: 0.3256476752793434
Validation loss: 2.632766150186482

Epoch: 400| Step: 0
Training loss: 0.24891859353225054
Validation loss: 2.675629640336099

Epoch: 5| Step: 1
Training loss: 0.46482528521624894
Validation loss: 2.6695369980131334

Epoch: 5| Step: 2
Training loss: 0.3207302974104062
Validation loss: 2.6878877547486475

Epoch: 5| Step: 3
Training loss: 0.31343337382436987
Validation loss: 2.6507108838862865

Epoch: 5| Step: 4
Training loss: 0.44761224500459296
Validation loss: 2.637110528191609

Epoch: 5| Step: 5
Training loss: 0.2022022599517993
Validation loss: 2.644931290306691

Epoch: 5| Step: 6
Training loss: 0.3172596501753222
Validation loss: 2.615735275353674

Epoch: 5| Step: 7
Training loss: 0.5088458185152122
Validation loss: 2.6402722728869557

Epoch: 5| Step: 8
Training loss: 0.2580239844614259
Validation loss: 2.599075289762144

Epoch: 5| Step: 9
Training loss: 0.22745199543276173
Validation loss: 2.6029356661079257

Epoch: 5| Step: 10
Training loss: 0.29157518189581644
Validation loss: 2.628190321273495

Epoch: 401| Step: 0
Training loss: 0.2716007120620315
Validation loss: 2.6105096275951096

Epoch: 5| Step: 1
Training loss: 0.2372328881171473
Validation loss: 2.6336874664411587

Epoch: 5| Step: 2
Training loss: 0.3711654393066328
Validation loss: 2.6464436245229015

Epoch: 5| Step: 3
Training loss: 0.2807335482852857
Validation loss: 2.5934344012085804

Epoch: 5| Step: 4
Training loss: 0.207879255084945
Validation loss: 2.624187111181246

Epoch: 5| Step: 5
Training loss: 0.30988382535264253
Validation loss: 2.593758464571596

Epoch: 5| Step: 6
Training loss: 0.5303731582199653
Validation loss: 2.6616529225780337

Epoch: 5| Step: 7
Training loss: 0.3606610920065979
Validation loss: 2.594071345729036

Epoch: 5| Step: 8
Training loss: 0.2621803625315177
Validation loss: 2.6288226528675125

Epoch: 5| Step: 9
Training loss: 0.21168641198855423
Validation loss: 2.637233969584303

Epoch: 5| Step: 10
Training loss: 0.4185570471586287
Validation loss: 2.6326184660591494

Epoch: 402| Step: 0
Training loss: 0.395277865404182
Validation loss: 2.6312199444995934

Epoch: 5| Step: 1
Training loss: 0.39998602544692224
Validation loss: 2.6590926785800244

Epoch: 5| Step: 2
Training loss: 0.4834724600788089
Validation loss: 2.6404668055884937

Epoch: 5| Step: 3
Training loss: 0.20994269713192043
Validation loss: 2.6078130654963614

Epoch: 5| Step: 4
Training loss: 0.20151901848080098
Validation loss: 2.607171396377387

Epoch: 5| Step: 5
Training loss: 0.3165572947971381
Validation loss: 2.652278595545375

Epoch: 5| Step: 6
Training loss: 0.28402393700402684
Validation loss: 2.6313507159402376

Epoch: 5| Step: 7
Training loss: 0.2297268986160318
Validation loss: 2.610100064592484

Epoch: 5| Step: 8
Training loss: 0.39267524542744703
Validation loss: 2.6241431647052105

Epoch: 5| Step: 9
Training loss: 0.23703929990553682
Validation loss: 2.5995355092964996

Epoch: 5| Step: 10
Training loss: 0.296741894948741
Validation loss: 2.612955659833712

Epoch: 403| Step: 0
Training loss: 0.19421289852531357
Validation loss: 2.598431329703383

Epoch: 5| Step: 1
Training loss: 0.3359543552162367
Validation loss: 2.619311458941809

Epoch: 5| Step: 2
Training loss: 0.26719873917793996
Validation loss: 2.604936992947795

Epoch: 5| Step: 3
Training loss: 0.3972649805894575
Validation loss: 2.622318632835917

Epoch: 5| Step: 4
Training loss: 0.399643512658573
Validation loss: 2.622724328942681

Epoch: 5| Step: 5
Training loss: 0.3134024107508942
Validation loss: 2.66012085336367

Epoch: 5| Step: 6
Training loss: 0.2755380195468794
Validation loss: 2.6364294192206246

Epoch: 5| Step: 7
Training loss: 0.2820907846947639
Validation loss: 2.6575110456338433

Epoch: 5| Step: 8
Training loss: 0.32739032514168165
Validation loss: 2.669834499836456

Epoch: 5| Step: 9
Training loss: 0.3680399880425843
Validation loss: 2.641894049223579

Epoch: 5| Step: 10
Training loss: 0.3054966452854537
Validation loss: 2.6480948232267005

Epoch: 404| Step: 0
Training loss: 0.24738072131664643
Validation loss: 2.670349554934065

Epoch: 5| Step: 1
Training loss: 0.2961326025079109
Validation loss: 2.6635569897960285

Epoch: 5| Step: 2
Training loss: 0.24730363014391626
Validation loss: 2.6554391017708614

Epoch: 5| Step: 3
Training loss: 0.4906775154873375
Validation loss: 2.666474691782048

Epoch: 5| Step: 4
Training loss: 0.3083091461622506
Validation loss: 2.67847306547025

Epoch: 5| Step: 5
Training loss: 0.306313090734996
Validation loss: 2.6439821451134162

Epoch: 5| Step: 6
Training loss: 0.28869066293407947
Validation loss: 2.615757078214396

Epoch: 5| Step: 7
Training loss: 0.3367505879407648
Validation loss: 2.627619001816064

Epoch: 5| Step: 8
Training loss: 0.2362202800242449
Validation loss: 2.5937181716193667

Epoch: 5| Step: 9
Training loss: 0.3789826542224087
Validation loss: 2.614550285161542

Epoch: 5| Step: 10
Training loss: 0.29162131394003754
Validation loss: 2.641489597924635

Epoch: 405| Step: 0
Training loss: 0.3392904754534062
Validation loss: 2.6157996028746973

Epoch: 5| Step: 1
Training loss: 0.23982118724103385
Validation loss: 2.609672840341335

Epoch: 5| Step: 2
Training loss: 0.3964615613265065
Validation loss: 2.615441167914204

Epoch: 5| Step: 3
Training loss: 0.20027830683080863
Validation loss: 2.6229371463506808

Epoch: 5| Step: 4
Training loss: 0.29122319595458623
Validation loss: 2.629795066281999

Epoch: 5| Step: 5
Training loss: 0.3317715695231767
Validation loss: 2.62308467480135

Epoch: 5| Step: 6
Training loss: 0.30780397829371875
Validation loss: 2.630224125555911

Epoch: 5| Step: 7
Training loss: 0.4881732058197275
Validation loss: 2.6532099555622675

Epoch: 5| Step: 8
Training loss: 0.22404703982072
Validation loss: 2.622211377510355

Epoch: 5| Step: 9
Training loss: 0.3179796212327293
Validation loss: 2.6375169427768124

Epoch: 5| Step: 10
Training loss: 0.23582396838855144
Validation loss: 2.629092452365287

Epoch: 406| Step: 0
Training loss: 0.2966506260694735
Validation loss: 2.6141767360128743

Epoch: 5| Step: 1
Training loss: 0.3105519012428289
Validation loss: 2.6459817969853505

Epoch: 5| Step: 2
Training loss: 0.20321092255505654
Validation loss: 2.6474523289490746

Epoch: 5| Step: 3
Training loss: 0.24883486021499193
Validation loss: 2.628499698815448

Epoch: 5| Step: 4
Training loss: 0.2995522769199929
Validation loss: 2.6463322542505114

Epoch: 5| Step: 5
Training loss: 0.327689449427465
Validation loss: 2.6166935613329203

Epoch: 5| Step: 6
Training loss: 0.46615654029128784
Validation loss: 2.650624109578268

Epoch: 5| Step: 7
Training loss: 0.41006590438543594
Validation loss: 2.6254401279916553

Epoch: 5| Step: 8
Training loss: 0.32743119503474344
Validation loss: 2.6132431200393738

Epoch: 5| Step: 9
Training loss: 0.37998553066563406
Validation loss: 2.6227522092396622

Epoch: 5| Step: 10
Training loss: 0.2384859284757294
Validation loss: 2.618049831907642

Epoch: 407| Step: 0
Training loss: 0.32340736433053385
Validation loss: 2.6437214211409406

Epoch: 5| Step: 1
Training loss: 0.19866205485949387
Validation loss: 2.619214592615702

Epoch: 5| Step: 2
Training loss: 0.4073747689947905
Validation loss: 2.5905759802632105

Epoch: 5| Step: 3
Training loss: 0.21996787489619296
Validation loss: 2.611951817533618

Epoch: 5| Step: 4
Training loss: 0.21104950050702936
Validation loss: 2.6518932711899366

Epoch: 5| Step: 5
Training loss: 0.4094896257970481
Validation loss: 2.627738744708911

Epoch: 5| Step: 6
Training loss: 0.41713292339962843
Validation loss: 2.6459919697284664

Epoch: 5| Step: 7
Training loss: 0.4433442840024427
Validation loss: 2.6209727205050934

Epoch: 5| Step: 8
Training loss: 0.14171656838223576
Validation loss: 2.673103619496947

Epoch: 5| Step: 9
Training loss: 0.21942408617080794
Validation loss: 2.673710826890628

Epoch: 5| Step: 10
Training loss: 0.23530320901500282
Validation loss: 2.673202410394448

Epoch: 408| Step: 0
Training loss: 0.2030773748906561
Validation loss: 2.6598514856154183

Epoch: 5| Step: 1
Training loss: 0.24637335832911103
Validation loss: 2.656406526821567

Epoch: 5| Step: 2
Training loss: 0.2267956684854434
Validation loss: 2.6617566815967515

Epoch: 5| Step: 3
Training loss: 0.2981419133041102
Validation loss: 2.6606924713289453

Epoch: 5| Step: 4
Training loss: 0.37314037329666594
Validation loss: 2.6344578026636234

Epoch: 5| Step: 5
Training loss: 0.4484573379807291
Validation loss: 2.6561606482015527

Epoch: 5| Step: 6
Training loss: 0.400189530650606
Validation loss: 2.665506473606656

Epoch: 5| Step: 7
Training loss: 0.1925759580385806
Validation loss: 2.616562702043557

Epoch: 5| Step: 8
Training loss: 0.33956529456283574
Validation loss: 2.605075069033395

Epoch: 5| Step: 9
Training loss: 0.3119365141831422
Validation loss: 2.608427222785084

Epoch: 5| Step: 10
Training loss: 0.3918664469234233
Validation loss: 2.639723061920415

Epoch: 409| Step: 0
Training loss: 0.3245871186229525
Validation loss: 2.598303043936128

Epoch: 5| Step: 1
Training loss: 0.16558413811219147
Validation loss: 2.643072014006421

Epoch: 5| Step: 2
Training loss: 0.3775158373245281
Validation loss: 2.6290626885858472

Epoch: 5| Step: 3
Training loss: 0.2604485333336764
Validation loss: 2.614125615228317

Epoch: 5| Step: 4
Training loss: 0.22545550650485474
Validation loss: 2.627675399726153

Epoch: 5| Step: 5
Training loss: 0.3257991808706832
Validation loss: 2.631095178383163

Epoch: 5| Step: 6
Training loss: 0.4746111646076889
Validation loss: 2.653514428699113

Epoch: 5| Step: 7
Training loss: 0.2789135416397382
Validation loss: 2.655608897140327

Epoch: 5| Step: 8
Training loss: 0.30351011499536396
Validation loss: 2.626080727569305

Epoch: 5| Step: 9
Training loss: 0.32007046603535944
Validation loss: 2.6165163945656387

Epoch: 5| Step: 10
Training loss: 0.321740039752783
Validation loss: 2.6610119653247573

Epoch: 410| Step: 0
Training loss: 0.19212121169215382
Validation loss: 2.6607170333653842

Epoch: 5| Step: 1
Training loss: 0.3622514423410096
Validation loss: 2.611725306079922

Epoch: 5| Step: 2
Training loss: 0.2320178230331043
Validation loss: 2.621793357802875

Epoch: 5| Step: 3
Training loss: 0.3090488361774916
Validation loss: 2.6195106638612575

Epoch: 5| Step: 4
Training loss: 0.4551191516113856
Validation loss: 2.632997737256872

Epoch: 5| Step: 5
Training loss: 0.2873951663781161
Validation loss: 2.629032834757773

Epoch: 5| Step: 6
Training loss: 0.3737708850115878
Validation loss: 2.6435777485354666

Epoch: 5| Step: 7
Training loss: 0.3469579305404048
Validation loss: 2.644304138010181

Epoch: 5| Step: 8
Training loss: 0.30476105853553814
Validation loss: 2.6599853021242006

Epoch: 5| Step: 9
Training loss: 0.29675811424104453
Validation loss: 2.6427558446445256

Epoch: 5| Step: 10
Training loss: 0.32972915530894187
Validation loss: 2.678113918482779

Epoch: 411| Step: 0
Training loss: 0.31821377472976387
Validation loss: 2.6674123562312975

Epoch: 5| Step: 1
Training loss: 0.36173790042680637
Validation loss: 2.6660809110712966

Epoch: 5| Step: 2
Training loss: 0.27892301119066026
Validation loss: 2.663726105052464

Epoch: 5| Step: 3
Training loss: 0.32169768254729286
Validation loss: 2.6466858349307953

Epoch: 5| Step: 4
Training loss: 0.19601905813665782
Validation loss: 2.6523527215641627

Epoch: 5| Step: 5
Training loss: 0.2807987089253765
Validation loss: 2.589740477474178

Epoch: 5| Step: 6
Training loss: 0.2381097536012058
Validation loss: 2.581943837574324

Epoch: 5| Step: 7
Training loss: 0.48328688133848774
Validation loss: 2.550257168102955

Epoch: 5| Step: 8
Training loss: 0.33021666649653625
Validation loss: 2.558635106582641

Epoch: 5| Step: 9
Training loss: 0.2692042592510914
Validation loss: 2.582533870117106

Epoch: 5| Step: 10
Training loss: 0.3541455846944544
Validation loss: 2.5763146630663325

Epoch: 412| Step: 0
Training loss: 0.4203509423072592
Validation loss: 2.569185404499764

Epoch: 5| Step: 1
Training loss: 0.24154055232908078
Validation loss: 2.5662262228893247

Epoch: 5| Step: 2
Training loss: 0.43934167084370507
Validation loss: 2.5618746034612645

Epoch: 5| Step: 3
Training loss: 0.367628137508313
Validation loss: 2.585152537911393

Epoch: 5| Step: 4
Training loss: 0.21790882572110806
Validation loss: 2.5838277610245135

Epoch: 5| Step: 5
Training loss: 0.21537573580635563
Validation loss: 2.5819997319054653

Epoch: 5| Step: 6
Training loss: 0.3287196221113853
Validation loss: 2.6006902663663025

Epoch: 5| Step: 7
Training loss: 0.20953876723673362
Validation loss: 2.598818334521435

Epoch: 5| Step: 8
Training loss: 0.430560196788274
Validation loss: 2.6117746716835937

Epoch: 5| Step: 9
Training loss: 0.3014026761868972
Validation loss: 2.6650006533890926

Epoch: 5| Step: 10
Training loss: 0.1765663311129129
Validation loss: 2.6355789571047783

Epoch: 413| Step: 0
Training loss: 0.2820008507193253
Validation loss: 2.6315125850922194

Epoch: 5| Step: 1
Training loss: 0.16088655322797116
Validation loss: 2.6486397512120337

Epoch: 5| Step: 2
Training loss: 0.29162839087743947
Validation loss: 2.6655554688216747

Epoch: 5| Step: 3
Training loss: 0.3807003765292719
Validation loss: 2.641145917288493

Epoch: 5| Step: 4
Training loss: 0.22885659040459122
Validation loss: 2.6076798562772283

Epoch: 5| Step: 5
Training loss: 0.18517545367098165
Validation loss: 2.625357136747299

Epoch: 5| Step: 6
Training loss: 0.25474781539137514
Validation loss: 2.6002592151623523

Epoch: 5| Step: 7
Training loss: 0.35919394285903056
Validation loss: 2.596494224949762

Epoch: 5| Step: 8
Training loss: 0.3653938231003011
Validation loss: 2.5971004089084833

Epoch: 5| Step: 9
Training loss: 0.22933857423270132
Validation loss: 2.601379605880949

Epoch: 5| Step: 10
Training loss: 0.543052118062324
Validation loss: 2.5863190937480995

Epoch: 414| Step: 0
Training loss: 0.3098214511667167
Validation loss: 2.599718112076238

Epoch: 5| Step: 1
Training loss: 0.20648411663095545
Validation loss: 2.600699092299086

Epoch: 5| Step: 2
Training loss: 0.39675743584494344
Validation loss: 2.6012351394787605

Epoch: 5| Step: 3
Training loss: 0.41883016217573643
Validation loss: 2.6297265845304945

Epoch: 5| Step: 4
Training loss: 0.35823627098088573
Validation loss: 2.624267023613455

Epoch: 5| Step: 5
Training loss: 0.18758134269576066
Validation loss: 2.6145905482865057

Epoch: 5| Step: 6
Training loss: 0.2787301108402298
Validation loss: 2.6218010610534748

Epoch: 5| Step: 7
Training loss: 0.3674263684474329
Validation loss: 2.61696342154276

Epoch: 5| Step: 8
Training loss: 0.3062777224468833
Validation loss: 2.629212547915863

Epoch: 5| Step: 9
Training loss: 0.24453040479325058
Validation loss: 2.6608097112906943

Epoch: 5| Step: 10
Training loss: 0.24695965395934155
Validation loss: 2.640781629732133

Epoch: 415| Step: 0
Training loss: 0.20827791649167618
Validation loss: 2.6404549490299885

Epoch: 5| Step: 1
Training loss: 0.2518533908481678
Validation loss: 2.6273348933020535

Epoch: 5| Step: 2
Training loss: 0.358229885952867
Validation loss: 2.68088879232674

Epoch: 5| Step: 3
Training loss: 0.3532556557948363
Validation loss: 2.6504557194684213

Epoch: 5| Step: 4
Training loss: 0.3891881265005764
Validation loss: 2.648756357408448

Epoch: 5| Step: 5
Training loss: 0.4176157592714761
Validation loss: 2.6123104373476442

Epoch: 5| Step: 6
Training loss: 0.21427083354041868
Validation loss: 2.6359072809840614

Epoch: 5| Step: 7
Training loss: 0.35626036143711226
Validation loss: 2.6435521796729975

Epoch: 5| Step: 8
Training loss: 0.472714349628
Validation loss: 2.6626676375049616

Epoch: 5| Step: 9
Training loss: 0.21508879125538596
Validation loss: 2.6547622297480884

Epoch: 5| Step: 10
Training loss: 0.26309771720268516
Validation loss: 2.6565854386165735

Epoch: 416| Step: 0
Training loss: 0.4778908679881093
Validation loss: 2.6500553715826602

Epoch: 5| Step: 1
Training loss: 0.2850816446193161
Validation loss: 2.6408781117337434

Epoch: 5| Step: 2
Training loss: 0.2788967654541591
Validation loss: 2.6148523711861666

Epoch: 5| Step: 3
Training loss: 0.2724219810500949
Validation loss: 2.643360770951245

Epoch: 5| Step: 4
Training loss: 0.18417442087711808
Validation loss: 2.6483988017206923

Epoch: 5| Step: 5
Training loss: 0.3536249697696353
Validation loss: 2.6311200683570477

Epoch: 5| Step: 6
Training loss: 0.40005780785789824
Validation loss: 2.641022620882932

Epoch: 5| Step: 7
Training loss: 0.22163987327343324
Validation loss: 2.6503383029699017

Epoch: 5| Step: 8
Training loss: 0.31505821486716284
Validation loss: 2.637991740584185

Epoch: 5| Step: 9
Training loss: 0.2904031439980119
Validation loss: 2.631636308062167

Epoch: 5| Step: 10
Training loss: 0.32137860844595667
Validation loss: 2.626873551927133

Epoch: 417| Step: 0
Training loss: 0.34753844590511296
Validation loss: 2.6103032444262526

Epoch: 5| Step: 1
Training loss: 0.2332909468202363
Validation loss: 2.636366334590006

Epoch: 5| Step: 2
Training loss: 0.27486763662231034
Validation loss: 2.6396305546356573

Epoch: 5| Step: 3
Training loss: 0.2471807029696269
Validation loss: 2.6355484268816003

Epoch: 5| Step: 4
Training loss: 0.2936814096196392
Validation loss: 2.6045859772470026

Epoch: 5| Step: 5
Training loss: 0.11566262357976874
Validation loss: 2.6271638521540535

Epoch: 5| Step: 6
Training loss: 0.18929583125312777
Validation loss: 2.622440350017586

Epoch: 5| Step: 7
Training loss: 0.3000163843727306
Validation loss: 2.6209776815536747

Epoch: 5| Step: 8
Training loss: 0.3131483980676595
Validation loss: 2.60773605623636

Epoch: 5| Step: 9
Training loss: 0.320252273293913
Validation loss: 2.6266049392616586

Epoch: 5| Step: 10
Training loss: 0.5016856092961756
Validation loss: 2.61976640517417

Epoch: 418| Step: 0
Training loss: 0.2747694273493864
Validation loss: 2.620034721876813

Epoch: 5| Step: 1
Training loss: 0.359561291384112
Validation loss: 2.6125345263049664

Epoch: 5| Step: 2
Training loss: 0.21746039878212484
Validation loss: 2.568988169502203

Epoch: 5| Step: 3
Training loss: 0.39253883734586614
Validation loss: 2.608728921383333

Epoch: 5| Step: 4
Training loss: 0.23074913749347647
Validation loss: 2.607586793260948

Epoch: 5| Step: 5
Training loss: 0.1746140778098135
Validation loss: 2.5907182109458553

Epoch: 5| Step: 6
Training loss: 0.35327293959860306
Validation loss: 2.6126400569468897

Epoch: 5| Step: 7
Training loss: 0.3356988635912385
Validation loss: 2.5885311481464077

Epoch: 5| Step: 8
Training loss: 0.32011693706584116
Validation loss: 2.582477438380368

Epoch: 5| Step: 9
Training loss: 0.26296797148781387
Validation loss: 2.6141825415636237

Epoch: 5| Step: 10
Training loss: 0.3211306845405735
Validation loss: 2.5998474782739045

Epoch: 419| Step: 0
Training loss: 0.26631897142681327
Validation loss: 2.6293202201515995

Epoch: 5| Step: 1
Training loss: 0.17426695776797177
Validation loss: 2.621746662595274

Epoch: 5| Step: 2
Training loss: 0.28032484480298087
Validation loss: 2.637479114590718

Epoch: 5| Step: 3
Training loss: 0.34603417704035055
Validation loss: 2.6206134352203563

Epoch: 5| Step: 4
Training loss: 0.32562685447940914
Validation loss: 2.632905833974166

Epoch: 5| Step: 5
Training loss: 0.35562983206229987
Validation loss: 2.6247246837630867

Epoch: 5| Step: 6
Training loss: 0.3443245313013468
Validation loss: 2.637741288014751

Epoch: 5| Step: 7
Training loss: 0.3517377416634222
Validation loss: 2.6351533487713668

Epoch: 5| Step: 8
Training loss: 0.21010008348561351
Validation loss: 2.6097763771646436

Epoch: 5| Step: 9
Training loss: 0.22907521128025987
Validation loss: 2.6473019139706406

Epoch: 5| Step: 10
Training loss: 0.2586271967391266
Validation loss: 2.643028912590583

Epoch: 420| Step: 0
Training loss: 0.3368645894312183
Validation loss: 2.6546961959899913

Epoch: 5| Step: 1
Training loss: 0.2196920155811316
Validation loss: 2.6499399766956127

Epoch: 5| Step: 2
Training loss: 0.20342542366362512
Validation loss: 2.6737771906944783

Epoch: 5| Step: 3
Training loss: 0.3018972081057505
Validation loss: 2.6488688277992036

Epoch: 5| Step: 4
Training loss: 0.34235160498267236
Validation loss: 2.634272346924074

Epoch: 5| Step: 5
Training loss: 0.2477930752981069
Validation loss: 2.6598555674259323

Epoch: 5| Step: 6
Training loss: 0.19958992581506257
Validation loss: 2.599708054592968

Epoch: 5| Step: 7
Training loss: 0.39072962313511556
Validation loss: 2.6154878276892743

Epoch: 5| Step: 8
Training loss: 0.40412248545300056
Validation loss: 2.581698828616516

Epoch: 5| Step: 9
Training loss: 0.13631384700999874
Validation loss: 2.5878511084900135

Epoch: 5| Step: 10
Training loss: 0.33424831022464574
Validation loss: 2.6145741922940817

Epoch: 421| Step: 0
Training loss: 0.2403356292219677
Validation loss: 2.595703183271223

Epoch: 5| Step: 1
Training loss: 0.37682087213804755
Validation loss: 2.612843234027888

Epoch: 5| Step: 2
Training loss: 0.25397933494990566
Validation loss: 2.5943036536813717

Epoch: 5| Step: 3
Training loss: 0.17849608049310212
Validation loss: 2.6034047590175833

Epoch: 5| Step: 4
Training loss: 0.3378102973315675
Validation loss: 2.6215089000607237

Epoch: 5| Step: 5
Training loss: 0.36489309593928615
Validation loss: 2.654238527633337

Epoch: 5| Step: 6
Training loss: 0.4139668696111633
Validation loss: 2.630855553204745

Epoch: 5| Step: 7
Training loss: 0.24975405456547156
Validation loss: 2.6175266448354666

Epoch: 5| Step: 8
Training loss: 0.22251368860934803
Validation loss: 2.58962278695315

Epoch: 5| Step: 9
Training loss: 0.22585578565935369
Validation loss: 2.6542403917554336

Epoch: 5| Step: 10
Training loss: 0.270627996965513
Validation loss: 2.635042622098863

Epoch: 422| Step: 0
Training loss: 0.2058688767790082
Validation loss: 2.603485112412667

Epoch: 5| Step: 1
Training loss: 0.25961933462420167
Validation loss: 2.633566370313187

Epoch: 5| Step: 2
Training loss: 0.42867518734299653
Validation loss: 2.6244975056856017

Epoch: 5| Step: 3
Training loss: 0.31318316886356795
Validation loss: 2.6377383071726537

Epoch: 5| Step: 4
Training loss: 0.3106100390033925
Validation loss: 2.659838712929629

Epoch: 5| Step: 5
Training loss: 0.19426179554620512
Validation loss: 2.690742817041763

Epoch: 5| Step: 6
Training loss: 0.23587839826330326
Validation loss: 2.6757734434670972

Epoch: 5| Step: 7
Training loss: 0.31081496368941386
Validation loss: 2.6711822275612103

Epoch: 5| Step: 8
Training loss: 0.18338295827588488
Validation loss: 2.678636546498277

Epoch: 5| Step: 9
Training loss: 0.24634331204787854
Validation loss: 2.660552223846713

Epoch: 5| Step: 10
Training loss: 0.38711831614680137
Validation loss: 2.698803641407107

Epoch: 423| Step: 0
Training loss: 0.32910792404048383
Validation loss: 2.632554979456354

Epoch: 5| Step: 1
Training loss: 0.2529598497942117
Validation loss: 2.6502268820999566

Epoch: 5| Step: 2
Training loss: 0.40043074244046817
Validation loss: 2.679639622305336

Epoch: 5| Step: 3
Training loss: 0.20894185640846824
Validation loss: 2.65738583914423

Epoch: 5| Step: 4
Training loss: 0.28005261644214874
Validation loss: 2.626830323796658

Epoch: 5| Step: 5
Training loss: 0.3220572636114029
Validation loss: 2.6294335106841893

Epoch: 5| Step: 6
Training loss: 0.37159546515784586
Validation loss: 2.6162855812600214

Epoch: 5| Step: 7
Training loss: 0.30266825046095164
Validation loss: 2.6125447022093797

Epoch: 5| Step: 8
Training loss: 0.21069198908531533
Validation loss: 2.6150322750819486

Epoch: 5| Step: 9
Training loss: 0.13593521390286112
Validation loss: 2.6312888209444694

Epoch: 5| Step: 10
Training loss: 0.19416424820550757
Validation loss: 2.624982371859487

Epoch: 424| Step: 0
Training loss: 0.2848304298036001
Validation loss: 2.617563171802854

Epoch: 5| Step: 1
Training loss: 0.2056062709545924
Validation loss: 2.5856392387305784

Epoch: 5| Step: 2
Training loss: 0.22786904012772022
Validation loss: 2.6052618553250957

Epoch: 5| Step: 3
Training loss: 0.3460817149805934
Validation loss: 2.590608251991455

Epoch: 5| Step: 4
Training loss: 0.14962137711990142
Validation loss: 2.601669671459081

Epoch: 5| Step: 5
Training loss: 0.2509495019239692
Validation loss: 2.6129589701531937

Epoch: 5| Step: 6
Training loss: 0.22437298816320883
Validation loss: 2.598845779776916

Epoch: 5| Step: 7
Training loss: 0.29039939819909366
Validation loss: 2.6437993598735874

Epoch: 5| Step: 8
Training loss: 0.38264331192941853
Validation loss: 2.647453504516622

Epoch: 5| Step: 9
Training loss: 0.34752736220591884
Validation loss: 2.632847637678298

Epoch: 5| Step: 10
Training loss: 0.26532984210737454
Validation loss: 2.615378425901984

Epoch: 425| Step: 0
Training loss: 0.5016802331710137
Validation loss: 2.611240188244906

Epoch: 5| Step: 1
Training loss: 0.4081920640532863
Validation loss: 2.634684673616374

Epoch: 5| Step: 2
Training loss: 0.26410506655914956
Validation loss: 2.658013523627986

Epoch: 5| Step: 3
Training loss: 0.2529511755575344
Validation loss: 2.616524324006581

Epoch: 5| Step: 4
Training loss: 0.2557238154165436
Validation loss: 2.614434033098822

Epoch: 5| Step: 5
Training loss: 0.20283427891521302
Validation loss: 2.6419827637374698

Epoch: 5| Step: 6
Training loss: 0.23830561435145167
Validation loss: 2.613839888042475

Epoch: 5| Step: 7
Training loss: 0.2510913927576479
Validation loss: 2.610387637441129

Epoch: 5| Step: 8
Training loss: 0.2738385393064208
Validation loss: 2.5888642741659247

Epoch: 5| Step: 9
Training loss: 0.16723512523803255
Validation loss: 2.6261643441385307

Epoch: 5| Step: 10
Training loss: 0.15150091355429193
Validation loss: 2.598787117188575

Epoch: 426| Step: 0
Training loss: 0.37853525620643175
Validation loss: 2.652045404526945

Epoch: 5| Step: 1
Training loss: 0.20478329127840025
Validation loss: 2.627262066662717

Epoch: 5| Step: 2
Training loss: 0.41330356141062036
Validation loss: 2.6418501294684815

Epoch: 5| Step: 3
Training loss: 0.23739586950376892
Validation loss: 2.6419457767535035

Epoch: 5| Step: 4
Training loss: 0.3876100153260934
Validation loss: 2.644114290427509

Epoch: 5| Step: 5
Training loss: 0.20410068639539838
Validation loss: 2.6150011206748234

Epoch: 5| Step: 6
Training loss: 0.35882098575585275
Validation loss: 2.6230655345418445

Epoch: 5| Step: 7
Training loss: 0.2724337547169077
Validation loss: 2.5721759232190338

Epoch: 5| Step: 8
Training loss: 0.15221220842032626
Validation loss: 2.587806313136375

Epoch: 5| Step: 9
Training loss: 0.23374769981037918
Validation loss: 2.559936356039377

Epoch: 5| Step: 10
Training loss: 0.29807257035309914
Validation loss: 2.5924426699512586

Epoch: 427| Step: 0
Training loss: 0.25326368747562894
Validation loss: 2.5945441963303684

Epoch: 5| Step: 1
Training loss: 0.34343606528554343
Validation loss: 2.596903941605259

Epoch: 5| Step: 2
Training loss: 0.17385385622892402
Validation loss: 2.6397437663803487

Epoch: 5| Step: 3
Training loss: 0.2995123043247366
Validation loss: 2.645255140852638

Epoch: 5| Step: 4
Training loss: 0.2283419576783119
Validation loss: 2.6550147150224106

Epoch: 5| Step: 5
Training loss: 0.29371839617088835
Validation loss: 2.6453144151469794

Epoch: 5| Step: 6
Training loss: 0.23340211649912046
Validation loss: 2.639278645563057

Epoch: 5| Step: 7
Training loss: 0.43313884068953373
Validation loss: 2.6289851759737357

Epoch: 5| Step: 8
Training loss: 0.19685050986117122
Validation loss: 2.6305171571225334

Epoch: 5| Step: 9
Training loss: 0.3652445337851275
Validation loss: 2.5939703703300916

Epoch: 5| Step: 10
Training loss: 0.4308438952821965
Validation loss: 2.5865974066317463

Epoch: 428| Step: 0
Training loss: 0.527415969989614
Validation loss: 2.6142184886191737

Epoch: 5| Step: 1
Training loss: 0.2046453723798074
Validation loss: 2.563279319288615

Epoch: 5| Step: 2
Training loss: 0.25062414578223263
Validation loss: 2.5772747946114363

Epoch: 5| Step: 3
Training loss: 0.4438381886495402
Validation loss: 2.5972124254589812

Epoch: 5| Step: 4
Training loss: 0.18134216686480023
Validation loss: 2.5860562444882924

Epoch: 5| Step: 5
Training loss: 0.2403353579654036
Validation loss: 2.592761438822967

Epoch: 5| Step: 6
Training loss: 0.3120783225834171
Validation loss: 2.6047823080203796

Epoch: 5| Step: 7
Training loss: 0.33964448326577396
Validation loss: 2.622474923799477

Epoch: 5| Step: 8
Training loss: 0.5787899729393349
Validation loss: 2.6384967533829653

Epoch: 5| Step: 9
Training loss: 0.2752218743982142
Validation loss: 2.602877595545548

Epoch: 5| Step: 10
Training loss: 0.30254137593635266
Validation loss: 2.6053968766708313

Epoch: 429| Step: 0
Training loss: 0.24859182315082062
Validation loss: 2.630305645991466

Epoch: 5| Step: 1
Training loss: 0.4633526327324099
Validation loss: 2.614157302034056

Epoch: 5| Step: 2
Training loss: 0.4065537051071325
Validation loss: 2.6167972377191138

Epoch: 5| Step: 3
Training loss: 0.2981334165668613
Validation loss: 2.6593487282931405

Epoch: 5| Step: 4
Training loss: 0.3793447454477007
Validation loss: 2.6116923284101983

Epoch: 5| Step: 5
Training loss: 0.21474901191286494
Validation loss: 2.6078129799700087

Epoch: 5| Step: 6
Training loss: 0.35863381122549354
Validation loss: 2.587849737437572

Epoch: 5| Step: 7
Training loss: 0.2668583370474227
Validation loss: 2.577008987468387

Epoch: 5| Step: 8
Training loss: 0.41538292496543067
Validation loss: 2.5768734317529325

Epoch: 5| Step: 9
Training loss: 0.22733715414854788
Validation loss: 2.59303519061669

Epoch: 5| Step: 10
Training loss: 0.3239608106283344
Validation loss: 2.6097524997556296

Epoch: 430| Step: 0
Training loss: 0.2945033001981966
Validation loss: 2.5738007935052063

Epoch: 5| Step: 1
Training loss: 0.2602568549298688
Validation loss: 2.597879563246486

Epoch: 5| Step: 2
Training loss: 0.41734813355115
Validation loss: 2.6393656078409666

Epoch: 5| Step: 3
Training loss: 0.3399529665258282
Validation loss: 2.6061182347966394

Epoch: 5| Step: 4
Training loss: 0.34860949611965203
Validation loss: 2.6154090830159955

Epoch: 5| Step: 5
Training loss: 0.3066932973148564
Validation loss: 2.582809489075056

Epoch: 5| Step: 6
Training loss: 0.34715801069139546
Validation loss: 2.649205083917609

Epoch: 5| Step: 7
Training loss: 0.35628307255938835
Validation loss: 2.6292952122240623

Epoch: 5| Step: 8
Training loss: 0.4611296172558454
Validation loss: 2.6671993149215525

Epoch: 5| Step: 9
Training loss: 0.3013469281312346
Validation loss: 2.66409103796391

Epoch: 5| Step: 10
Training loss: 0.2585882019185388
Validation loss: 2.6402046736533222

Epoch: 431| Step: 0
Training loss: 0.3463675799915572
Validation loss: 2.685101879791169

Epoch: 5| Step: 1
Training loss: 0.3029905527384191
Validation loss: 2.6181200540916874

Epoch: 5| Step: 2
Training loss: 0.43964263220758387
Validation loss: 2.5603214740809053

Epoch: 5| Step: 3
Training loss: 0.3185804336780765
Validation loss: 2.5787537574662154

Epoch: 5| Step: 4
Training loss: 0.36986051733367453
Validation loss: 2.5471582849685963

Epoch: 5| Step: 5
Training loss: 0.42483706296124457
Validation loss: 2.5539473538055133

Epoch: 5| Step: 6
Training loss: 0.28000672040691077
Validation loss: 2.5244612744611556

Epoch: 5| Step: 7
Training loss: 0.2205698995297536
Validation loss: 2.5762886624752013

Epoch: 5| Step: 8
Training loss: 0.26298851185989325
Validation loss: 2.606214519621307

Epoch: 5| Step: 9
Training loss: 0.4198463549460381
Validation loss: 2.612360113777076

Epoch: 5| Step: 10
Training loss: 0.35658111075695004
Validation loss: 2.615296251967893

Epoch: 432| Step: 0
Training loss: 0.3238373546872568
Validation loss: 2.594493193638062

Epoch: 5| Step: 1
Training loss: 0.3183516987068218
Validation loss: 2.584602368433508

Epoch: 5| Step: 2
Training loss: 0.1591690914161176
Validation loss: 2.5777117992518743

Epoch: 5| Step: 3
Training loss: 0.2309646685831539
Validation loss: 2.5530368338809084

Epoch: 5| Step: 4
Training loss: 0.35563594952103506
Validation loss: 2.5519070860573505

Epoch: 5| Step: 5
Training loss: 0.38592250810300416
Validation loss: 2.5077709385844824

Epoch: 5| Step: 6
Training loss: 0.30193093034470353
Validation loss: 2.541544315359338

Epoch: 5| Step: 7
Training loss: 0.4740316068859317
Validation loss: 2.5235854844277483

Epoch: 5| Step: 8
Training loss: 0.2747973551581954
Validation loss: 2.529093238905482

Epoch: 5| Step: 9
Training loss: 0.2626234757571174
Validation loss: 2.5501028051047543

Epoch: 5| Step: 10
Training loss: 0.2931216031916786
Validation loss: 2.5656044535814475

Epoch: 433| Step: 0
Training loss: 0.19360913416441364
Validation loss: 2.609300313294225

Epoch: 5| Step: 1
Training loss: 0.3578374146029005
Validation loss: 2.643103239336276

Epoch: 5| Step: 2
Training loss: 0.26140356300737866
Validation loss: 2.6626545355664746

Epoch: 5| Step: 3
Training loss: 0.33791696302484825
Validation loss: 2.645779746161078

Epoch: 5| Step: 4
Training loss: 0.3813982550233551
Validation loss: 2.655200277433331

Epoch: 5| Step: 5
Training loss: 0.17301834809916286
Validation loss: 2.603291459874604

Epoch: 5| Step: 6
Training loss: 0.31850612511127385
Validation loss: 2.5855980518246153

Epoch: 5| Step: 7
Training loss: 0.357615871624945
Validation loss: 2.5994805595872252

Epoch: 5| Step: 8
Training loss: 0.370091580836246
Validation loss: 2.5954736235160847

Epoch: 5| Step: 9
Training loss: 0.2584361567110625
Validation loss: 2.5735885996848826

Epoch: 5| Step: 10
Training loss: 0.4059089549587798
Validation loss: 2.6266405708834815

Epoch: 434| Step: 0
Training loss: 0.2988415260052681
Validation loss: 2.635011851918866

Epoch: 5| Step: 1
Training loss: 0.49893596800796275
Validation loss: 2.629307472217557

Epoch: 5| Step: 2
Training loss: 0.24923146852189595
Validation loss: 2.595890885869605

Epoch: 5| Step: 3
Training loss: 0.5033510091448462
Validation loss: 2.6198382130784608

Epoch: 5| Step: 4
Training loss: 0.3323106375673115
Validation loss: 2.6038789737077743

Epoch: 5| Step: 5
Training loss: 0.24210859366897405
Validation loss: 2.595908896238353

Epoch: 5| Step: 6
Training loss: 0.32798612017019807
Validation loss: 2.565709540927856

Epoch: 5| Step: 7
Training loss: 0.2916327084913597
Validation loss: 2.5808584122263065

Epoch: 5| Step: 8
Training loss: 0.37102337220056375
Validation loss: 2.6020672696568483

Epoch: 5| Step: 9
Training loss: 0.2741959135757233
Validation loss: 2.626064361138246

Epoch: 5| Step: 10
Training loss: 0.21940905200737634
Validation loss: 2.5977726469470515

Epoch: 435| Step: 0
Training loss: 0.20879423101181752
Validation loss: 2.605296044036539

Epoch: 5| Step: 1
Training loss: 0.23517307462101797
Validation loss: 2.601860849397885

Epoch: 5| Step: 2
Training loss: 0.24431173050681912
Validation loss: 2.6047054227335664

Epoch: 5| Step: 3
Training loss: 0.3085667441417937
Validation loss: 2.574323089350847

Epoch: 5| Step: 4
Training loss: 0.29965223480790326
Validation loss: 2.5745735673956003

Epoch: 5| Step: 5
Training loss: 0.32987818785294687
Validation loss: 2.567189808964447

Epoch: 5| Step: 6
Training loss: 0.2206702925305185
Validation loss: 2.5761964532421606

Epoch: 5| Step: 7
Training loss: 0.33312359807791236
Validation loss: 2.5519763270319187

Epoch: 5| Step: 8
Training loss: 0.429538007220268
Validation loss: 2.534344630694626

Epoch: 5| Step: 9
Training loss: 0.3206970651033149
Validation loss: 2.5527359838438515

Epoch: 5| Step: 10
Training loss: 0.3093373237171273
Validation loss: 2.5854794766709346

Epoch: 436| Step: 0
Training loss: 0.3053966607887728
Validation loss: 2.5408155353314417

Epoch: 5| Step: 1
Training loss: 0.19814605449092895
Validation loss: 2.548266144324172

Epoch: 5| Step: 2
Training loss: 0.3210663414833557
Validation loss: 2.547578666248741

Epoch: 5| Step: 3
Training loss: 0.46972748246767043
Validation loss: 2.5653167768089347

Epoch: 5| Step: 4
Training loss: 0.18840163723108688
Validation loss: 2.5416130851720644

Epoch: 5| Step: 5
Training loss: 0.3127289172002917
Validation loss: 2.563713462715908

Epoch: 5| Step: 6
Training loss: 0.21666504743930784
Validation loss: 2.556914151270518

Epoch: 5| Step: 7
Training loss: 0.2714585216479601
Validation loss: 2.5826298122580718

Epoch: 5| Step: 8
Training loss: 0.35409052348196596
Validation loss: 2.582629028066547

Epoch: 5| Step: 9
Training loss: 0.2764206015794875
Validation loss: 2.602253037436718

Epoch: 5| Step: 10
Training loss: 0.22201568079138354
Validation loss: 2.619133819815695

Epoch: 437| Step: 0
Training loss: 0.151402463186521
Validation loss: 2.5922627717625693

Epoch: 5| Step: 1
Training loss: 0.395850967549824
Validation loss: 2.594222565275628

Epoch: 5| Step: 2
Training loss: 0.28000856969695925
Validation loss: 2.5915649141119883

Epoch: 5| Step: 3
Training loss: 0.13689470548832294
Validation loss: 2.5595932688452825

Epoch: 5| Step: 4
Training loss: 0.23585319086378462
Validation loss: 2.5518806659990143

Epoch: 5| Step: 5
Training loss: 0.2705419222813236
Validation loss: 2.583745332772191

Epoch: 5| Step: 6
Training loss: 0.3067196057891178
Validation loss: 2.6022437995568644

Epoch: 5| Step: 7
Training loss: 0.2404508623208448
Validation loss: 2.5941884500130716

Epoch: 5| Step: 8
Training loss: 0.15365209943849648
Validation loss: 2.607620810901802

Epoch: 5| Step: 9
Training loss: 0.3638737881154434
Validation loss: 2.625980080945211

Epoch: 5| Step: 10
Training loss: 0.3508961508484359
Validation loss: 2.631327381145394

Epoch: 438| Step: 0
Training loss: 0.3330547042452598
Validation loss: 2.638893311552074

Epoch: 5| Step: 1
Training loss: 0.25656964091168377
Validation loss: 2.625826566815821

Epoch: 5| Step: 2
Training loss: 0.24808878056538822
Validation loss: 2.654314914034705

Epoch: 5| Step: 3
Training loss: 0.12299961741778528
Validation loss: 2.628455187546011

Epoch: 5| Step: 4
Training loss: 0.17759706621901633
Validation loss: 2.602176038996272

Epoch: 5| Step: 5
Training loss: 0.2602195072879998
Validation loss: 2.6335816835834516

Epoch: 5| Step: 6
Training loss: 0.17806059902872898
Validation loss: 2.622752188224229

Epoch: 5| Step: 7
Training loss: 0.17954163228318895
Validation loss: 2.6336085222329784

Epoch: 5| Step: 8
Training loss: 0.2196353977544998
Validation loss: 2.6062511707019103

Epoch: 5| Step: 9
Training loss: 0.29940304272423623
Validation loss: 2.6323027642079584

Epoch: 5| Step: 10
Training loss: 0.4471896077818816
Validation loss: 2.6340596793770814

Epoch: 439| Step: 0
Training loss: 0.35374957189095946
Validation loss: 2.6128327354991003

Epoch: 5| Step: 1
Training loss: 0.19220764395739512
Validation loss: 2.6422240809817437

Epoch: 5| Step: 2
Training loss: 0.3609918421341329
Validation loss: 2.628162403071473

Epoch: 5| Step: 3
Training loss: 0.26552382112939393
Validation loss: 2.598674743819396

Epoch: 5| Step: 4
Training loss: 0.13390847605988207
Validation loss: 2.6257312281616505

Epoch: 5| Step: 5
Training loss: 0.3550341537997487
Validation loss: 2.6093570098738206

Epoch: 5| Step: 6
Training loss: 0.1514856859104199
Validation loss: 2.61434452986353

Epoch: 5| Step: 7
Training loss: 0.2661184887857731
Validation loss: 2.594556900159813

Epoch: 5| Step: 8
Training loss: 0.17020465625559855
Validation loss: 2.619567141410526

Epoch: 5| Step: 9
Training loss: 0.22498923812401253
Validation loss: 2.616957979724804

Epoch: 5| Step: 10
Training loss: 0.2397634107624828
Validation loss: 2.61877880448192

Epoch: 440| Step: 0
Training loss: 0.2338790733027542
Validation loss: 2.6118433090530875

Epoch: 5| Step: 1
Training loss: 0.3845655434207649
Validation loss: 2.6076158372222356

Epoch: 5| Step: 2
Training loss: 0.2428351479600861
Validation loss: 2.6223630048413895

Epoch: 5| Step: 3
Training loss: 0.26654956296538973
Validation loss: 2.6301607712269273

Epoch: 5| Step: 4
Training loss: 0.3021872344504041
Validation loss: 2.631366042104533

Epoch: 5| Step: 5
Training loss: 0.2874716594452192
Validation loss: 2.619602959773147

Epoch: 5| Step: 6
Training loss: 0.1425405282917171
Validation loss: 2.616135964802263

Epoch: 5| Step: 7
Training loss: 0.19114172426080883
Validation loss: 2.6168618844659903

Epoch: 5| Step: 8
Training loss: 0.27127982742486745
Validation loss: 2.6228418888680385

Epoch: 5| Step: 9
Training loss: 0.1981901936866801
Validation loss: 2.6475780158551654

Epoch: 5| Step: 10
Training loss: 0.25431604327782453
Validation loss: 2.628873390336506

Epoch: 441| Step: 0
Training loss: 0.20692827254794643
Validation loss: 2.643646881948052

Epoch: 5| Step: 1
Training loss: 0.21207164583403607
Validation loss: 2.591661717361627

Epoch: 5| Step: 2
Training loss: 0.3651023462914957
Validation loss: 2.6194742795353108

Epoch: 5| Step: 3
Training loss: 0.1881753560407607
Validation loss: 2.6359795089280147

Epoch: 5| Step: 4
Training loss: 0.1691917430287857
Validation loss: 2.658666798018497

Epoch: 5| Step: 5
Training loss: 0.254663848363821
Validation loss: 2.6109316739193296

Epoch: 5| Step: 6
Training loss: 0.33395760412170283
Validation loss: 2.6226776600853627

Epoch: 5| Step: 7
Training loss: 0.204629580114416
Validation loss: 2.631666508865635

Epoch: 5| Step: 8
Training loss: 0.2130721219738861
Validation loss: 2.6304034225416775

Epoch: 5| Step: 9
Training loss: 0.32504051121069233
Validation loss: 2.5965120820451677

Epoch: 5| Step: 10
Training loss: 0.3026581699072147
Validation loss: 2.5869818254340875

Epoch: 442| Step: 0
Training loss: 0.31570913496482494
Validation loss: 2.606454690893387

Epoch: 5| Step: 1
Training loss: 0.258607577619771
Validation loss: 2.622713349461004

Epoch: 5| Step: 2
Training loss: 0.2608418077904079
Validation loss: 2.598057468050362

Epoch: 5| Step: 3
Training loss: 0.1241423869983231
Validation loss: 2.5820397122807455

Epoch: 5| Step: 4
Training loss: 0.1655729337942045
Validation loss: 2.612069940807998

Epoch: 5| Step: 5
Training loss: 0.34819258348899823
Validation loss: 2.598479294335508

Epoch: 5| Step: 6
Training loss: 0.39686907816396205
Validation loss: 2.5884905004744048

Epoch: 5| Step: 7
Training loss: 0.20362029761065206
Validation loss: 2.6055625774040747

Epoch: 5| Step: 8
Training loss: 0.25430212703971083
Validation loss: 2.6165903619028796

Epoch: 5| Step: 9
Training loss: 0.22377345397765902
Validation loss: 2.592456369997138

Epoch: 5| Step: 10
Training loss: 0.177010624114121
Validation loss: 2.6038804510197853

Epoch: 443| Step: 0
Training loss: 0.2164809098202136
Validation loss: 2.5656794230566216

Epoch: 5| Step: 1
Training loss: 0.18075672556999664
Validation loss: 2.5840287812303

Epoch: 5| Step: 2
Training loss: 0.2646316297761072
Validation loss: 2.585379403211764

Epoch: 5| Step: 3
Training loss: 0.21272209916575202
Validation loss: 2.5729305078809146

Epoch: 5| Step: 4
Training loss: 0.1850929530311905
Validation loss: 2.6042287104609256

Epoch: 5| Step: 5
Training loss: 0.29789520944448683
Validation loss: 2.5830190510728928

Epoch: 5| Step: 6
Training loss: 0.25484486732261363
Validation loss: 2.607005610077441

Epoch: 5| Step: 7
Training loss: 0.19656180416523772
Validation loss: 2.579910296584772

Epoch: 5| Step: 8
Training loss: 0.2656956466524194
Validation loss: 2.58500074612583

Epoch: 5| Step: 9
Training loss: 0.29386668880511096
Validation loss: 2.5756241060094216

Epoch: 5| Step: 10
Training loss: 0.36325142850811565
Validation loss: 2.571138719628157

Epoch: 444| Step: 0
Training loss: 0.2805244305523201
Validation loss: 2.573098513573131

Epoch: 5| Step: 1
Training loss: 0.3134330410321644
Validation loss: 2.6087519934964165

Epoch: 5| Step: 2
Training loss: 0.25978666234696557
Validation loss: 2.5764420660506624

Epoch: 5| Step: 3
Training loss: 0.16287916175153846
Validation loss: 2.6101355924939655

Epoch: 5| Step: 4
Training loss: 0.2899061470010995
Validation loss: 2.607627533563316

Epoch: 5| Step: 5
Training loss: 0.16482644803876262
Validation loss: 2.6280611689357833

Epoch: 5| Step: 6
Training loss: 0.21438891208593555
Validation loss: 2.650548067531841

Epoch: 5| Step: 7
Training loss: 0.23463535153595885
Validation loss: 2.6408611147628736

Epoch: 5| Step: 8
Training loss: 0.3761905804159556
Validation loss: 2.655746301212737

Epoch: 5| Step: 9
Training loss: 0.10081336319306122
Validation loss: 2.6583259861959303

Epoch: 5| Step: 10
Training loss: 0.37408000627821175
Validation loss: 2.6590526139919444

Epoch: 445| Step: 0
Training loss: 0.25833961757327867
Validation loss: 2.650932018828895

Epoch: 5| Step: 1
Training loss: 0.23240708055613252
Validation loss: 2.643076819121112

Epoch: 5| Step: 2
Training loss: 0.13037554415418276
Validation loss: 2.6360420883455262

Epoch: 5| Step: 3
Training loss: 0.2009456992664162
Validation loss: 2.6308890263686884

Epoch: 5| Step: 4
Training loss: 0.1444444975950936
Validation loss: 2.6438268782927485

Epoch: 5| Step: 5
Training loss: 0.2565867734756699
Validation loss: 2.638261210221525

Epoch: 5| Step: 6
Training loss: 0.2598071244440539
Validation loss: 2.6561375361937074

Epoch: 5| Step: 7
Training loss: 0.34644064385372464
Validation loss: 2.64954198724516

Epoch: 5| Step: 8
Training loss: 0.269352259151756
Validation loss: 2.6411393071218754

Epoch: 5| Step: 9
Training loss: 0.30818128182058774
Validation loss: 2.6154789198268387

Epoch: 5| Step: 10
Training loss: 0.4201699699468466
Validation loss: 2.613817694522955

Epoch: 446| Step: 0
Training loss: 0.3720611210686487
Validation loss: 2.5899023018694205

Epoch: 5| Step: 1
Training loss: 0.20955610947061964
Validation loss: 2.595061811452753

Epoch: 5| Step: 2
Training loss: 0.2834564917193966
Validation loss: 2.594971030499163

Epoch: 5| Step: 3
Training loss: 0.2753673435407389
Validation loss: 2.578544517434869

Epoch: 5| Step: 4
Training loss: 0.19902665095407018
Validation loss: 2.602630652162968

Epoch: 5| Step: 5
Training loss: 0.26681624491626466
Validation loss: 2.5458088338135063

Epoch: 5| Step: 6
Training loss: 0.2923320973457892
Validation loss: 2.5937871691870704

Epoch: 5| Step: 7
Training loss: 0.166873700229712
Validation loss: 2.5834111279045158

Epoch: 5| Step: 8
Training loss: 0.23013460052300164
Validation loss: 2.572492048233581

Epoch: 5| Step: 9
Training loss: 0.21930972084443537
Validation loss: 2.5873678348714253

Epoch: 5| Step: 10
Training loss: 0.2693897649962477
Validation loss: 2.6025860383001582

Epoch: 447| Step: 0
Training loss: 0.17618707329095196
Validation loss: 2.604028221798245

Epoch: 5| Step: 1
Training loss: 0.20448950808572297
Validation loss: 2.6112593052253925

Epoch: 5| Step: 2
Training loss: 0.19344058402565698
Validation loss: 2.613494488131767

Epoch: 5| Step: 3
Training loss: 0.3193449316595523
Validation loss: 2.585834407557592

Epoch: 5| Step: 4
Training loss: 0.2475045199655812
Validation loss: 2.598590958441466

Epoch: 5| Step: 5
Training loss: 0.17950241258986924
Validation loss: 2.578465791901809

Epoch: 5| Step: 6
Training loss: 0.2133188927097988
Validation loss: 2.6081171588258827

Epoch: 5| Step: 7
Training loss: 0.36708416397803234
Validation loss: 2.5836512250606147

Epoch: 5| Step: 8
Training loss: 0.26014598448149107
Validation loss: 2.6033950358138376

Epoch: 5| Step: 9
Training loss: 0.4223538612682369
Validation loss: 2.605999614501516

Epoch: 5| Step: 10
Training loss: 0.1258151772750044
Validation loss: 2.5633288127864056

Epoch: 448| Step: 0
Training loss: 0.1686198125321266
Validation loss: 2.626084813059748

Epoch: 5| Step: 1
Training loss: 0.19571882896842016
Validation loss: 2.618268309263644

Epoch: 5| Step: 2
Training loss: 0.2862767843558795
Validation loss: 2.618523222732893

Epoch: 5| Step: 3
Training loss: 0.30779462268635993
Validation loss: 2.6290110166904386

Epoch: 5| Step: 4
Training loss: 0.30421268929281525
Validation loss: 2.6197693624292953

Epoch: 5| Step: 5
Training loss: 0.2559119454459407
Validation loss: 2.6264919430160605

Epoch: 5| Step: 6
Training loss: 0.20169075463573738
Validation loss: 2.624846449549248

Epoch: 5| Step: 7
Training loss: 0.17762353605959708
Validation loss: 2.6340575206722865

Epoch: 5| Step: 8
Training loss: 0.23894472462306
Validation loss: 2.651294093692976

Epoch: 5| Step: 9
Training loss: 0.22179577850360993
Validation loss: 2.6690843793855565

Epoch: 5| Step: 10
Training loss: 0.36017087215770344
Validation loss: 2.627389260948528

Epoch: 449| Step: 0
Training loss: 0.3028913644619766
Validation loss: 2.6551140167558316

Epoch: 5| Step: 1
Training loss: 0.15312715986246658
Validation loss: 2.6364156754082835

Epoch: 5| Step: 2
Training loss: 0.22134453060643167
Validation loss: 2.644338130238584

Epoch: 5| Step: 3
Training loss: 0.20207114285310063
Validation loss: 2.622758117990832

Epoch: 5| Step: 4
Training loss: 0.2796380553414429
Validation loss: 2.603933060207454

Epoch: 5| Step: 5
Training loss: 0.21314401158643762
Validation loss: 2.6059603617729983

Epoch: 5| Step: 6
Training loss: 0.22325448764079694
Validation loss: 2.6252658121482844

Epoch: 5| Step: 7
Training loss: 0.16840345111091823
Validation loss: 2.5821688581565385

Epoch: 5| Step: 8
Training loss: 0.4208380529718162
Validation loss: 2.6174918959972735

Epoch: 5| Step: 9
Training loss: 0.23688569775734622
Validation loss: 2.5866430524780593

Epoch: 5| Step: 10
Training loss: 0.20702546489478194
Validation loss: 2.565685480232373

Epoch: 450| Step: 0
Training loss: 0.2902878102417398
Validation loss: 2.5937307085015884

Epoch: 5| Step: 1
Training loss: 0.2030231513929529
Validation loss: 2.5795239155621013

Epoch: 5| Step: 2
Training loss: 0.18971806121309048
Validation loss: 2.563403994828601

Epoch: 5| Step: 3
Training loss: 0.3803177723954031
Validation loss: 2.5779693944365816

Epoch: 5| Step: 4
Training loss: 0.21725618833687663
Validation loss: 2.5880116443968957

Epoch: 5| Step: 5
Training loss: 0.21206404832184225
Validation loss: 2.5873907903097537

Epoch: 5| Step: 6
Training loss: 0.32001611907415717
Validation loss: 2.596469271610566

Epoch: 5| Step: 7
Training loss: 0.18667496522980004
Validation loss: 2.6149376377189495

Epoch: 5| Step: 8
Training loss: 0.19097199126913575
Validation loss: 2.590799600009818

Epoch: 5| Step: 9
Training loss: 0.19624990575630208
Validation loss: 2.588158530826842

Epoch: 5| Step: 10
Training loss: 0.28778659333259926
Validation loss: 2.604719948024095

Epoch: 451| Step: 0
Training loss: 0.16291696394976968
Validation loss: 2.5725917101962286

Epoch: 5| Step: 1
Training loss: 0.1963426317592642
Validation loss: 2.5990937988624467

Epoch: 5| Step: 2
Training loss: 0.2693292441307506
Validation loss: 2.6037509952352824

Epoch: 5| Step: 3
Training loss: 0.24792102564791654
Validation loss: 2.587697239973761

Epoch: 5| Step: 4
Training loss: 0.37055428092387177
Validation loss: 2.6255399194617963

Epoch: 5| Step: 5
Training loss: 0.24252017307188886
Validation loss: 2.5960685151634766

Epoch: 5| Step: 6
Training loss: 0.22347601345230186
Validation loss: 2.5910441159702704

Epoch: 5| Step: 7
Training loss: 0.10968571618659274
Validation loss: 2.610256382956214

Epoch: 5| Step: 8
Training loss: 0.2601448245589672
Validation loss: 2.6065907106877204

Epoch: 5| Step: 9
Training loss: 0.29015430254634467
Validation loss: 2.598362726783055

Epoch: 5| Step: 10
Training loss: 0.19968278919627194
Validation loss: 2.5909957707897435

Epoch: 452| Step: 0
Training loss: 0.2184617152455822
Validation loss: 2.609194828361647

Epoch: 5| Step: 1
Training loss: 0.27684855242235856
Validation loss: 2.609589559364741

Epoch: 5| Step: 2
Training loss: 0.1401143471541879
Validation loss: 2.609205073786769

Epoch: 5| Step: 3
Training loss: 0.26387139295139284
Validation loss: 2.6318780859639186

Epoch: 5| Step: 4
Training loss: 0.303132896222177
Validation loss: 2.6190403812075647

Epoch: 5| Step: 5
Training loss: 0.2997813013753347
Validation loss: 2.6118879699310407

Epoch: 5| Step: 6
Training loss: 0.1653030361069793
Validation loss: 2.5901441717697153

Epoch: 5| Step: 7
Training loss: 0.2556961062802856
Validation loss: 2.6158573537445116

Epoch: 5| Step: 8
Training loss: 0.2256905449424411
Validation loss: 2.565160606158555

Epoch: 5| Step: 9
Training loss: 0.17314449639489457
Validation loss: 2.6028695802091177

Epoch: 5| Step: 10
Training loss: 0.26075280271488677
Validation loss: 2.6187818578098554

Epoch: 453| Step: 0
Training loss: 0.2923589081252081
Validation loss: 2.598787873322176

Epoch: 5| Step: 1
Training loss: 0.21071227730239547
Validation loss: 2.619105810459964

Epoch: 5| Step: 2
Training loss: 0.25022600806066847
Validation loss: 2.620563021097645

Epoch: 5| Step: 3
Training loss: 0.2134137419802845
Validation loss: 2.605646828306515

Epoch: 5| Step: 4
Training loss: 0.18669208671419155
Validation loss: 2.6048835502711136

Epoch: 5| Step: 5
Training loss: 0.26909786432798066
Validation loss: 2.6232477053702357

Epoch: 5| Step: 6
Training loss: 0.13450855809189152
Validation loss: 2.5997438418583014

Epoch: 5| Step: 7
Training loss: 0.2780644093638926
Validation loss: 2.585256127581669

Epoch: 5| Step: 8
Training loss: 0.2697497877857268
Validation loss: 2.61656466746987

Epoch: 5| Step: 9
Training loss: 0.16569558879615762
Validation loss: 2.617185525246005

Epoch: 5| Step: 10
Training loss: 0.20749914630174246
Validation loss: 2.5817941121718384

Epoch: 454| Step: 0
Training loss: 0.28859625407869
Validation loss: 2.5994996935217154

Epoch: 5| Step: 1
Training loss: 0.2540939370960302
Validation loss: 2.5717792761161578

Epoch: 5| Step: 2
Training loss: 0.17644732166098154
Validation loss: 2.5759435409430456

Epoch: 5| Step: 3
Training loss: 0.29156213686757915
Validation loss: 2.6094698899437256

Epoch: 5| Step: 4
Training loss: 0.41441797795955376
Validation loss: 2.5843247711914707

Epoch: 5| Step: 5
Training loss: 0.19418756773265766
Validation loss: 2.591218187362156

Epoch: 5| Step: 6
Training loss: 0.12222796368915873
Validation loss: 2.5626715465863406

Epoch: 5| Step: 7
Training loss: 0.20040200890818577
Validation loss: 2.5905196979851297

Epoch: 5| Step: 8
Training loss: 0.17412480207549744
Validation loss: 2.581201372912914

Epoch: 5| Step: 9
Training loss: 0.18357115464464407
Validation loss: 2.6023897299907603

Epoch: 5| Step: 10
Training loss: 0.11445119989618378
Validation loss: 2.586938569898034

Epoch: 455| Step: 0
Training loss: 0.22860125217134433
Validation loss: 2.618129243297234

Epoch: 5| Step: 1
Training loss: 0.2962143599523635
Validation loss: 2.589851909587415

Epoch: 5| Step: 2
Training loss: 0.19753996025305387
Validation loss: 2.586993828125038

Epoch: 5| Step: 3
Training loss: 0.1945553599970468
Validation loss: 2.5939078178582307

Epoch: 5| Step: 4
Training loss: 0.2408317798319104
Validation loss: 2.606084666773791

Epoch: 5| Step: 5
Training loss: 0.2918525029973552
Validation loss: 2.616687922028564

Epoch: 5| Step: 6
Training loss: 0.20733591371056964
Validation loss: 2.591355530260482

Epoch: 5| Step: 7
Training loss: 0.328334196705982
Validation loss: 2.6197265973769803

Epoch: 5| Step: 8
Training loss: 0.21260673072523528
Validation loss: 2.5643063273213738

Epoch: 5| Step: 9
Training loss: 0.21444474361974747
Validation loss: 2.576141077355866

Epoch: 5| Step: 10
Training loss: 0.12544034346535157
Validation loss: 2.6011983753427637

Epoch: 456| Step: 0
Training loss: 0.23280994490687093
Validation loss: 2.6085672644440616

Epoch: 5| Step: 1
Training loss: 0.2520325262057493
Validation loss: 2.6028002757719686

Epoch: 5| Step: 2
Training loss: 0.40013073185560505
Validation loss: 2.6078864214971578

Epoch: 5| Step: 3
Training loss: 0.1848117319206555
Validation loss: 2.6054845117837955

Epoch: 5| Step: 4
Training loss: 0.15647925605152604
Validation loss: 2.6247450338005245

Epoch: 5| Step: 5
Training loss: 0.2519033515913919
Validation loss: 2.610853631368961

Epoch: 5| Step: 6
Training loss: 0.30171381064766944
Validation loss: 2.652338990670515

Epoch: 5| Step: 7
Training loss: 0.2383422382662406
Validation loss: 2.6343282364831198

Epoch: 5| Step: 8
Training loss: 0.13077729768375373
Validation loss: 2.6114713311549376

Epoch: 5| Step: 9
Training loss: 0.17108152119380882
Validation loss: 2.63876318302049

Epoch: 5| Step: 10
Training loss: 0.16526396511254512
Validation loss: 2.6350431173063975

Epoch: 457| Step: 0
Training loss: 0.2501024691868228
Validation loss: 2.6519943708673943

Epoch: 5| Step: 1
Training loss: 0.19420711522380887
Validation loss: 2.6409233489265174

Epoch: 5| Step: 2
Training loss: 0.20812316167724063
Validation loss: 2.653505372178422

Epoch: 5| Step: 3
Training loss: 0.19412805950249476
Validation loss: 2.6291762959010274

Epoch: 5| Step: 4
Training loss: 0.2362445021297417
Validation loss: 2.619307016409909

Epoch: 5| Step: 5
Training loss: 0.1656083440502911
Validation loss: 2.645038541236248

Epoch: 5| Step: 6
Training loss: 0.17741812352220954
Validation loss: 2.6454702681641034

Epoch: 5| Step: 7
Training loss: 0.2489533718497924
Validation loss: 2.610010622933529

Epoch: 5| Step: 8
Training loss: 0.3369538988528618
Validation loss: 2.616013821994633

Epoch: 5| Step: 9
Training loss: 0.30842820084920686
Validation loss: 2.638747375189763

Epoch: 5| Step: 10
Training loss: 0.22681562490089702
Validation loss: 2.624748311670371

Epoch: 458| Step: 0
Training loss: 0.29403215057124854
Validation loss: 2.615220007116046

Epoch: 5| Step: 1
Training loss: 0.18544249359198423
Validation loss: 2.623860644677872

Epoch: 5| Step: 2
Training loss: 0.1785136107950915
Validation loss: 2.631026376768827

Epoch: 5| Step: 3
Training loss: 0.23085066299653106
Validation loss: 2.5954180104658118

Epoch: 5| Step: 4
Training loss: 0.1976151438703733
Validation loss: 2.6232224875836

Epoch: 5| Step: 5
Training loss: 0.274518166340467
Validation loss: 2.606959072850278

Epoch: 5| Step: 6
Training loss: 0.2490680355452424
Validation loss: 2.611617291764198

Epoch: 5| Step: 7
Training loss: 0.16567625251432988
Validation loss: 2.588500283625758

Epoch: 5| Step: 8
Training loss: 0.17738238262568815
Validation loss: 2.599286683165845

Epoch: 5| Step: 9
Training loss: 0.19800683318374004
Validation loss: 2.5823433967705713

Epoch: 5| Step: 10
Training loss: 0.3603182728181702
Validation loss: 2.596375554983536

Epoch: 459| Step: 0
Training loss: 0.27975342522348934
Validation loss: 2.578919818130459

Epoch: 5| Step: 1
Training loss: 0.1833682501570617
Validation loss: 2.5884591660139016

Epoch: 5| Step: 2
Training loss: 0.2532147748715866
Validation loss: 2.606798819677035

Epoch: 5| Step: 3
Training loss: 0.19265169630214707
Validation loss: 2.6088915779840347

Epoch: 5| Step: 4
Training loss: 0.22183628684780626
Validation loss: 2.6050654091416576

Epoch: 5| Step: 5
Training loss: 0.25744246891057954
Validation loss: 2.6075871462106286

Epoch: 5| Step: 6
Training loss: 0.1165499270947669
Validation loss: 2.6056645055966814

Epoch: 5| Step: 7
Training loss: 0.17156778318751065
Validation loss: 2.614966235337243

Epoch: 5| Step: 8
Training loss: 0.30626917165965367
Validation loss: 2.613615115512747

Epoch: 5| Step: 9
Training loss: 0.21110529760009283
Validation loss: 2.6232937694235763

Epoch: 5| Step: 10
Training loss: 0.20060638464665756
Validation loss: 2.6013727064373424

Epoch: 460| Step: 0
Training loss: 0.16694619287104034
Validation loss: 2.600373951718577

Epoch: 5| Step: 1
Training loss: 0.24896457200766098
Validation loss: 2.594155100185833

Epoch: 5| Step: 2
Training loss: 0.13308143034822317
Validation loss: 2.5915950496852163

Epoch: 5| Step: 3
Training loss: 0.3048588808724448
Validation loss: 2.566027862274026

Epoch: 5| Step: 4
Training loss: 0.20161832879057145
Validation loss: 2.6093457083838443

Epoch: 5| Step: 5
Training loss: 0.2699687834195543
Validation loss: 2.6254483761471556

Epoch: 5| Step: 6
Training loss: 0.1915505118609415
Validation loss: 2.5942862072935737

Epoch: 5| Step: 7
Training loss: 0.1882284735477045
Validation loss: 2.5739788048347694

Epoch: 5| Step: 8
Training loss: 0.19881640738863057
Validation loss: 2.601052641228297

Epoch: 5| Step: 9
Training loss: 0.31574357656965957
Validation loss: 2.6140836081171672

Epoch: 5| Step: 10
Training loss: 0.2476614262614538
Validation loss: 2.5949301487908327

Epoch: 461| Step: 0
Training loss: 0.2047005947670917
Validation loss: 2.6172410822651275

Epoch: 5| Step: 1
Training loss: 0.20560091684933432
Validation loss: 2.632820157378047

Epoch: 5| Step: 2
Training loss: 0.20877774442536892
Validation loss: 2.626613354563793

Epoch: 5| Step: 3
Training loss: 0.3126625711048936
Validation loss: 2.6129761653018564

Epoch: 5| Step: 4
Training loss: 0.14080436843787664
Validation loss: 2.6451909156816567

Epoch: 5| Step: 5
Training loss: 0.2252528551335652
Validation loss: 2.6107245346141963

Epoch: 5| Step: 6
Training loss: 0.18175988742768007
Validation loss: 2.5995497543051047

Epoch: 5| Step: 7
Training loss: 0.22077626729581395
Validation loss: 2.6161670687031227

Epoch: 5| Step: 8
Training loss: 0.3228820800204369
Validation loss: 2.594362933960467

Epoch: 5| Step: 9
Training loss: 0.2722155515360037
Validation loss: 2.614943124917334

Epoch: 5| Step: 10
Training loss: 0.21151372124643048
Validation loss: 2.6156207225722095

Epoch: 462| Step: 0
Training loss: 0.2533113553030493
Validation loss: 2.5851794519304483

Epoch: 5| Step: 1
Training loss: 0.1756846586389165
Validation loss: 2.550797521567586

Epoch: 5| Step: 2
Training loss: 0.1316113713980446
Validation loss: 2.5679688355954906

Epoch: 5| Step: 3
Training loss: 0.13684983100455583
Validation loss: 2.5775688250138393

Epoch: 5| Step: 4
Training loss: 0.2501955012991533
Validation loss: 2.5455639850371745

Epoch: 5| Step: 5
Training loss: 0.2605764312222463
Validation loss: 2.571333757765457

Epoch: 5| Step: 6
Training loss: 0.3368965144355854
Validation loss: 2.587153975280661

Epoch: 5| Step: 7
Training loss: 0.3108900800804573
Validation loss: 2.5824582810705112

Epoch: 5| Step: 8
Training loss: 0.15010208465853855
Validation loss: 2.5843856770631826

Epoch: 5| Step: 9
Training loss: 0.30007764338042786
Validation loss: 2.599866539990357

Epoch: 5| Step: 10
Training loss: 0.19026317652564573
Validation loss: 2.5960966985130915

Epoch: 463| Step: 0
Training loss: 0.1510205267768317
Validation loss: 2.5768272099204257

Epoch: 5| Step: 1
Training loss: 0.11934905112804868
Validation loss: 2.584019250012542

Epoch: 5| Step: 2
Training loss: 0.17668354202272787
Validation loss: 2.549291159560921

Epoch: 5| Step: 3
Training loss: 0.3443619201689338
Validation loss: 2.5583290532423604

Epoch: 5| Step: 4
Training loss: 0.12258679798726894
Validation loss: 2.5901202061698583

Epoch: 5| Step: 5
Training loss: 0.32334868183690174
Validation loss: 2.5671688708662126

Epoch: 5| Step: 6
Training loss: 0.18434788658116869
Validation loss: 2.5941860132973176

Epoch: 5| Step: 7
Training loss: 0.2821872116163434
Validation loss: 2.6057248939831563

Epoch: 5| Step: 8
Training loss: 0.18547789646724808
Validation loss: 2.6161641642116042

Epoch: 5| Step: 9
Training loss: 0.21955385838362812
Validation loss: 2.591171430408878

Epoch: 5| Step: 10
Training loss: 0.26142432604652976
Validation loss: 2.629377263583995

Epoch: 464| Step: 0
Training loss: 0.2311426267849889
Validation loss: 2.635112643909662

Epoch: 5| Step: 1
Training loss: 0.2967567710361079
Validation loss: 2.6073389527846134

Epoch: 5| Step: 2
Training loss: 0.17095951623722
Validation loss: 2.611213488347417

Epoch: 5| Step: 3
Training loss: 0.16874936487820102
Validation loss: 2.63551690071801

Epoch: 5| Step: 4
Training loss: 0.15062929387719245
Validation loss: 2.6164848362695152

Epoch: 5| Step: 5
Training loss: 0.2795239172624601
Validation loss: 2.631179132019438

Epoch: 5| Step: 6
Training loss: 0.3008049918378463
Validation loss: 2.5882874758918373

Epoch: 5| Step: 7
Training loss: 0.15208900990299815
Validation loss: 2.612545270861692

Epoch: 5| Step: 8
Training loss: 0.20387206795897805
Validation loss: 2.618777912173324

Epoch: 5| Step: 9
Training loss: 0.17407606423019942
Validation loss: 2.595698254903836

Epoch: 5| Step: 10
Training loss: 0.1717598377565589
Validation loss: 2.605432686160481

Epoch: 465| Step: 0
Training loss: 0.18890406496095286
Validation loss: 2.6143155763450885

Epoch: 5| Step: 1
Training loss: 0.1974232110301718
Validation loss: 2.5755318456108873

Epoch: 5| Step: 2
Training loss: 0.2414073221868019
Validation loss: 2.574096592138326

Epoch: 5| Step: 3
Training loss: 0.19729129699751619
Validation loss: 2.598267550094668

Epoch: 5| Step: 4
Training loss: 0.1553458099125061
Validation loss: 2.596756460928875

Epoch: 5| Step: 5
Training loss: 0.2691993466612
Validation loss: 2.5995479737449347

Epoch: 5| Step: 6
Training loss: 0.20867397751457692
Validation loss: 2.575524926196613

Epoch: 5| Step: 7
Training loss: 0.17197387733870778
Validation loss: 2.5978780415689324

Epoch: 5| Step: 8
Training loss: 0.19352566667975868
Validation loss: 2.6161995264704543

Epoch: 5| Step: 9
Training loss: 0.25096908142577157
Validation loss: 2.5899936969981447

Epoch: 5| Step: 10
Training loss: 0.284118881799132
Validation loss: 2.5930728544882484

Epoch: 466| Step: 0
Training loss: 0.21507057873685406
Validation loss: 2.601347840300507

Epoch: 5| Step: 1
Training loss: 0.27620143435431715
Validation loss: 2.5877700685331178

Epoch: 5| Step: 2
Training loss: 0.19715845388322556
Validation loss: 2.5958951768856164

Epoch: 5| Step: 3
Training loss: 0.17475684273062875
Validation loss: 2.625078392030223

Epoch: 5| Step: 4
Training loss: 0.26882790279185237
Validation loss: 2.5616298036365324

Epoch: 5| Step: 5
Training loss: 0.17273438247929096
Validation loss: 2.60095927997809

Epoch: 5| Step: 6
Training loss: 0.10200947285969332
Validation loss: 2.6123297339361797

Epoch: 5| Step: 7
Training loss: 0.2421268648721724
Validation loss: 2.610700886821189

Epoch: 5| Step: 8
Training loss: 0.13159789741827146
Validation loss: 2.6067291864869335

Epoch: 5| Step: 9
Training loss: 0.11759608486426373
Validation loss: 2.5854928586392663

Epoch: 5| Step: 10
Training loss: 0.33372720778073117
Validation loss: 2.601453393601063

Epoch: 467| Step: 0
Training loss: 0.22993065361350623
Validation loss: 2.568144777015818

Epoch: 5| Step: 1
Training loss: 0.16987490827040058
Validation loss: 2.571168533256504

Epoch: 5| Step: 2
Training loss: 0.14724443976407783
Validation loss: 2.5846568265754355

Epoch: 5| Step: 3
Training loss: 0.14895678338220364
Validation loss: 2.5971936398938404

Epoch: 5| Step: 4
Training loss: 0.28108965753584036
Validation loss: 2.5777242807139573

Epoch: 5| Step: 5
Training loss: 0.22185323030833803
Validation loss: 2.5962576478191637

Epoch: 5| Step: 6
Training loss: 0.2676453610335863
Validation loss: 2.587295361607028

Epoch: 5| Step: 7
Training loss: 0.29973295764024216
Validation loss: 2.582231809415451

Epoch: 5| Step: 8
Training loss: 0.2023499907632151
Validation loss: 2.5857468153583234

Epoch: 5| Step: 9
Training loss: 0.1214997844490545
Validation loss: 2.641552280697753

Epoch: 5| Step: 10
Training loss: 0.20221938394792885
Validation loss: 2.627266451832947

Epoch: 468| Step: 0
Training loss: 0.20757017527422852
Validation loss: 2.612283517274282

Epoch: 5| Step: 1
Training loss: 0.09297868711593771
Validation loss: 2.618125122381457

Epoch: 5| Step: 2
Training loss: 0.38656308672898215
Validation loss: 2.6034283608259523

Epoch: 5| Step: 3
Training loss: 0.14990177837849217
Validation loss: 2.6279683296695024

Epoch: 5| Step: 4
Training loss: 0.17777179491780026
Validation loss: 2.628952031088223

Epoch: 5| Step: 5
Training loss: 0.1804276336962663
Validation loss: 2.6216328328194103

Epoch: 5| Step: 6
Training loss: 0.23737138823312148
Validation loss: 2.6217290037791825

Epoch: 5| Step: 7
Training loss: 0.18969680412953135
Validation loss: 2.6058122740782568

Epoch: 5| Step: 8
Training loss: 0.29570572623919084
Validation loss: 2.6496294104170475

Epoch: 5| Step: 9
Training loss: 0.10559486866505474
Validation loss: 2.5947873951401497

Epoch: 5| Step: 10
Training loss: 0.15632457741520564
Validation loss: 2.594022250030534

Epoch: 469| Step: 0
Training loss: 0.16675247030129836
Validation loss: 2.6094926897584934

Epoch: 5| Step: 1
Training loss: 0.20126231484615195
Validation loss: 2.5889843123014273

Epoch: 5| Step: 2
Training loss: 0.2784643235649439
Validation loss: 2.5944570780230256

Epoch: 5| Step: 3
Training loss: 0.19265987564536424
Validation loss: 2.604417267257525

Epoch: 5| Step: 4
Training loss: 0.19938736679922164
Validation loss: 2.5984658638147278

Epoch: 5| Step: 5
Training loss: 0.18789834187099833
Validation loss: 2.587273178197491

Epoch: 5| Step: 6
Training loss: 0.2662772697041119
Validation loss: 2.6021652895541396

Epoch: 5| Step: 7
Training loss: 0.2416638743442048
Validation loss: 2.604234506687349

Epoch: 5| Step: 8
Training loss: 0.23369989120695514
Validation loss: 2.6475709734250543

Epoch: 5| Step: 9
Training loss: 0.19248365286366406
Validation loss: 2.6331436846215457

Epoch: 5| Step: 10
Training loss: 0.1498976529658003
Validation loss: 2.6446818012327373

Epoch: 470| Step: 0
Training loss: 0.12149376326956864
Validation loss: 2.611060117328197

Epoch: 5| Step: 1
Training loss: 0.36437928984065027
Validation loss: 2.57988462438003

Epoch: 5| Step: 2
Training loss: 0.16752162461041958
Validation loss: 2.6083548736967113

Epoch: 5| Step: 3
Training loss: 0.15646789378287537
Validation loss: 2.6389028641295247

Epoch: 5| Step: 4
Training loss: 0.1556658434795891
Validation loss: 2.6021471254476727

Epoch: 5| Step: 5
Training loss: 0.1920613056776338
Validation loss: 2.621569325875431

Epoch: 5| Step: 6
Training loss: 0.1138598120707047
Validation loss: 2.6392460481154445

Epoch: 5| Step: 7
Training loss: 0.18565643489104797
Validation loss: 2.60565851577639

Epoch: 5| Step: 8
Training loss: 0.2110960152855325
Validation loss: 2.6208011428476228

Epoch: 5| Step: 9
Training loss: 0.27521202031268877
Validation loss: 2.6155862787204596

Epoch: 5| Step: 10
Training loss: 0.23244169294991748
Validation loss: 2.604665879832825

Epoch: 471| Step: 0
Training loss: 0.22062501115771907
Validation loss: 2.6090680514682347

Epoch: 5| Step: 1
Training loss: 0.11548015278790838
Validation loss: 2.585624574522227

Epoch: 5| Step: 2
Training loss: 0.25652956366684687
Validation loss: 2.6073551870140417

Epoch: 5| Step: 3
Training loss: 0.16616026243696141
Validation loss: 2.604237096182773

Epoch: 5| Step: 4
Training loss: 0.36717337723214505
Validation loss: 2.6369977837890164

Epoch: 5| Step: 5
Training loss: 0.19914828718611563
Validation loss: 2.6172713267370926

Epoch: 5| Step: 6
Training loss: 0.17826871929881946
Validation loss: 2.609676025153523

Epoch: 5| Step: 7
Training loss: 0.09068449694060259
Validation loss: 2.596904920898713

Epoch: 5| Step: 8
Training loss: 0.1625390104547228
Validation loss: 2.61679503734256

Epoch: 5| Step: 9
Training loss: 0.21107343426295033
Validation loss: 2.6014463889081423

Epoch: 5| Step: 10
Training loss: 0.20750936146668555
Validation loss: 2.5999568118017864

Epoch: 472| Step: 0
Training loss: 0.16268541642553666
Validation loss: 2.6301627201562883

Epoch: 5| Step: 1
Training loss: 0.2022771932064594
Validation loss: 2.618638016647129

Epoch: 5| Step: 2
Training loss: 0.20527666563041935
Validation loss: 2.6164733549085453

Epoch: 5| Step: 3
Training loss: 0.32807610919564023
Validation loss: 2.607108542863065

Epoch: 5| Step: 4
Training loss: 0.13446429329813128
Validation loss: 2.5922542034108513

Epoch: 5| Step: 5
Training loss: 0.10033025466358934
Validation loss: 2.5988449501693514

Epoch: 5| Step: 6
Training loss: 0.2127170204875739
Validation loss: 2.62662158268674

Epoch: 5| Step: 7
Training loss: 0.2598067229608029
Validation loss: 2.601707514811612

Epoch: 5| Step: 8
Training loss: 0.2025062416727727
Validation loss: 2.589676511895178

Epoch: 5| Step: 9
Training loss: 0.10173705579400825
Validation loss: 2.6040899121858323

Epoch: 5| Step: 10
Training loss: 0.22668396226085485
Validation loss: 2.575045385855776

Epoch: 473| Step: 0
Training loss: 0.29477839737717715
Validation loss: 2.6026004857813487

Epoch: 5| Step: 1
Training loss: 0.19890094165655814
Validation loss: 2.609858994045063

Epoch: 5| Step: 2
Training loss: 0.17773343180311846
Validation loss: 2.6113860802911866

Epoch: 5| Step: 3
Training loss: 0.26242607528990985
Validation loss: 2.6086594276690795

Epoch: 5| Step: 4
Training loss: 0.2518349599604793
Validation loss: 2.615154682585853

Epoch: 5| Step: 5
Training loss: 0.19309171781814863
Validation loss: 2.6307982124543066

Epoch: 5| Step: 6
Training loss: 0.24027235614779488
Validation loss: 2.633875442446173

Epoch: 5| Step: 7
Training loss: 0.09962918514653146
Validation loss: 2.627905246301488

Epoch: 5| Step: 8
Training loss: 0.1362467520221682
Validation loss: 2.6169465729323194

Epoch: 5| Step: 9
Training loss: 0.1032867510538187
Validation loss: 2.607794185731826

Epoch: 5| Step: 10
Training loss: 0.16837569774973046
Validation loss: 2.612533611747296

Epoch: 474| Step: 0
Training loss: 0.27393328814496487
Validation loss: 2.6203640375523367

Epoch: 5| Step: 1
Training loss: 0.1780425847278562
Validation loss: 2.609514179316437

Epoch: 5| Step: 2
Training loss: 0.12224239427265382
Validation loss: 2.62794242992342

Epoch: 5| Step: 3
Training loss: 0.24780207290936962
Validation loss: 2.623207464688333

Epoch: 5| Step: 4
Training loss: 0.12476453732283367
Validation loss: 2.602200843034005

Epoch: 5| Step: 5
Training loss: 0.11960382782564116
Validation loss: 2.606973170598555

Epoch: 5| Step: 6
Training loss: 0.25429512468664417
Validation loss: 2.591934974545238

Epoch: 5| Step: 7
Training loss: 0.09169329216830897
Validation loss: 2.5959258892923454

Epoch: 5| Step: 8
Training loss: 0.27249180882068136
Validation loss: 2.5946279562727717

Epoch: 5| Step: 9
Training loss: 0.18393583082516926
Validation loss: 2.5950138775054543

Epoch: 5| Step: 10
Training loss: 0.2507100601402038
Validation loss: 2.5640812248903084

Epoch: 475| Step: 0
Training loss: 0.23073993504168944
Validation loss: 2.5881252806064188

Epoch: 5| Step: 1
Training loss: 0.17962152887134908
Validation loss: 2.5912722195585225

Epoch: 5| Step: 2
Training loss: 0.1516799402934799
Validation loss: 2.6069622088584934

Epoch: 5| Step: 3
Training loss: 0.13605609795591975
Validation loss: 2.591029262698073

Epoch: 5| Step: 4
Training loss: 0.2381390397370922
Validation loss: 2.5767138703984758

Epoch: 5| Step: 5
Training loss: 0.34290220010323635
Validation loss: 2.597363524312693

Epoch: 5| Step: 6
Training loss: 0.15876087722159207
Validation loss: 2.593198729275699

Epoch: 5| Step: 7
Training loss: 0.18965413549567264
Validation loss: 2.6085825819657433

Epoch: 5| Step: 8
Training loss: 0.18796206204763602
Validation loss: 2.609121501777721

Epoch: 5| Step: 9
Training loss: 0.17047792743031376
Validation loss: 2.594970757831436

Epoch: 5| Step: 10
Training loss: 0.07828217431624872
Validation loss: 2.601147468628725

Epoch: 476| Step: 0
Training loss: 0.13761371196696853
Validation loss: 2.6029308686382047

Epoch: 5| Step: 1
Training loss: 0.21503891316892895
Validation loss: 2.616207717527103

Epoch: 5| Step: 2
Training loss: 0.12551551553006018
Validation loss: 2.6178661129670973

Epoch: 5| Step: 3
Training loss: 0.18958005880490242
Validation loss: 2.648779274435226

Epoch: 5| Step: 4
Training loss: 0.2188704533684783
Validation loss: 2.6123504700289217

Epoch: 5| Step: 5
Training loss: 0.1502992178824247
Validation loss: 2.6231319726530753

Epoch: 5| Step: 6
Training loss: 0.25527413973022167
Validation loss: 2.5998656525305854

Epoch: 5| Step: 7
Training loss: 0.15092999479143177
Validation loss: 2.619819416059093

Epoch: 5| Step: 8
Training loss: 0.21668951280130505
Validation loss: 2.615687282153637

Epoch: 5| Step: 9
Training loss: 0.3066690638286947
Validation loss: 2.624206028337772

Epoch: 5| Step: 10
Training loss: 0.1403588982694705
Validation loss: 2.6248416584306598

Epoch: 477| Step: 0
Training loss: 0.17113273907946988
Validation loss: 2.6182850935583484

Epoch: 5| Step: 1
Training loss: 0.17431707408787783
Validation loss: 2.6164923836839162

Epoch: 5| Step: 2
Training loss: 0.14951589642050703
Validation loss: 2.6025314834860844

Epoch: 5| Step: 3
Training loss: 0.240962344421251
Validation loss: 2.6207969967873774

Epoch: 5| Step: 4
Training loss: 0.35874282131921226
Validation loss: 2.6223963117030316

Epoch: 5| Step: 5
Training loss: 0.1383357810673783
Validation loss: 2.6077171739480858

Epoch: 5| Step: 6
Training loss: 0.13337253553666287
Validation loss: 2.6202518562343906

Epoch: 5| Step: 7
Training loss: 0.23981988241371666
Validation loss: 2.635114806128035

Epoch: 5| Step: 8
Training loss: 0.17237004058811464
Validation loss: 2.6060868407796907

Epoch: 5| Step: 9
Training loss: 0.20864601909104177
Validation loss: 2.6255061906250594

Epoch: 5| Step: 10
Training loss: 0.11913527414156555
Validation loss: 2.6279073681116785

Epoch: 478| Step: 0
Training loss: 0.17277210370488386
Validation loss: 2.628542248473338

Epoch: 5| Step: 1
Training loss: 0.17911585810027342
Validation loss: 2.613429871877806

Epoch: 5| Step: 2
Training loss: 0.13902080987867885
Validation loss: 2.6032027981377666

Epoch: 5| Step: 3
Training loss: 0.2374465737985062
Validation loss: 2.6129026843401735

Epoch: 5| Step: 4
Training loss: 0.2819970461533441
Validation loss: 2.588059742703657

Epoch: 5| Step: 5
Training loss: 0.20035964919750304
Validation loss: 2.570316752928244

Epoch: 5| Step: 6
Training loss: 0.24881908035009173
Validation loss: 2.586127510372886

Epoch: 5| Step: 7
Training loss: 0.12209624205809895
Validation loss: 2.5680871855531966

Epoch: 5| Step: 8
Training loss: 0.24169755414909744
Validation loss: 2.5685465256917706

Epoch: 5| Step: 9
Training loss: 0.10557947704267506
Validation loss: 2.584073371226768

Epoch: 5| Step: 10
Training loss: 0.20104996218556465
Validation loss: 2.5700652066527683

Epoch: 479| Step: 0
Training loss: 0.08824601641297777
Validation loss: 2.5660673312172655

Epoch: 5| Step: 1
Training loss: 0.19168568668807565
Validation loss: 2.57908141293975

Epoch: 5| Step: 2
Training loss: 0.23790948038276868
Validation loss: 2.590781109826379

Epoch: 5| Step: 3
Training loss: 0.1665423508278438
Validation loss: 2.619851397038906

Epoch: 5| Step: 4
Training loss: 0.24275215528260125
Validation loss: 2.5959540504891407

Epoch: 5| Step: 5
Training loss: 0.26680770003111004
Validation loss: 2.607529040611531

Epoch: 5| Step: 6
Training loss: 0.2509910193409673
Validation loss: 2.596316212041915

Epoch: 5| Step: 7
Training loss: 0.1830261669094641
Validation loss: 2.6286153897709927

Epoch: 5| Step: 8
Training loss: 0.17813779299790022
Validation loss: 2.6105454091793057

Epoch: 5| Step: 9
Training loss: 0.22023752776585873
Validation loss: 2.6194153683869703

Epoch: 5| Step: 10
Training loss: 0.17777148058557501
Validation loss: 2.5923063918882776

Epoch: 480| Step: 0
Training loss: 0.1992013213069787
Validation loss: 2.5883547606333797

Epoch: 5| Step: 1
Training loss: 0.16311879312465066
Validation loss: 2.6231983015790847

Epoch: 5| Step: 2
Training loss: 0.18764304625205097
Validation loss: 2.626790431761868

Epoch: 5| Step: 3
Training loss: 0.21479035494268492
Validation loss: 2.6369460369730686

Epoch: 5| Step: 4
Training loss: 0.166395773132477
Validation loss: 2.641997697339012

Epoch: 5| Step: 5
Training loss: 0.11226180958087977
Validation loss: 2.620502507021666

Epoch: 5| Step: 6
Training loss: 0.2418814771484821
Validation loss: 2.6241908567187266

Epoch: 5| Step: 7
Training loss: 0.2115164247514465
Validation loss: 2.6334587105743066

Epoch: 5| Step: 8
Training loss: 0.2373077486570741
Validation loss: 2.6122240602311915

Epoch: 5| Step: 9
Training loss: 0.13748315605033334
Validation loss: 2.600302886989881

Epoch: 5| Step: 10
Training loss: 0.3086706500269268
Validation loss: 2.6191688801514577

Epoch: 481| Step: 0
Training loss: 0.252638424519965
Validation loss: 2.602808354358734

Epoch: 5| Step: 1
Training loss: 0.21228536256433903
Validation loss: 2.5828067128320766

Epoch: 5| Step: 2
Training loss: 0.18205346598148064
Validation loss: 2.563878097752632

Epoch: 5| Step: 3
Training loss: 0.0996096601669119
Validation loss: 2.565131000540642

Epoch: 5| Step: 4
Training loss: 0.2035500773667498
Validation loss: 2.5628530457705128

Epoch: 5| Step: 5
Training loss: 0.19007326663166535
Validation loss: 2.573184977628643

Epoch: 5| Step: 6
Training loss: 0.2357553050161338
Validation loss: 2.526329643360936

Epoch: 5| Step: 7
Training loss: 0.12572479224898037
Validation loss: 2.5808855960119956

Epoch: 5| Step: 8
Training loss: 0.27395478773300547
Validation loss: 2.5767841612380944

Epoch: 5| Step: 9
Training loss: 0.15003282540488816
Validation loss: 2.5592467463509285

Epoch: 5| Step: 10
Training loss: 0.2829446073077196
Validation loss: 2.577004717729796

Epoch: 482| Step: 0
Training loss: 0.1580298617035902
Validation loss: 2.55250382382046

Epoch: 5| Step: 1
Training loss: 0.16581117719416666
Validation loss: 2.5425451896361255

Epoch: 5| Step: 2
Training loss: 0.34027200878317637
Validation loss: 2.5689375066798945

Epoch: 5| Step: 3
Training loss: 0.12509269555624472
Validation loss: 2.5814950851818175

Epoch: 5| Step: 4
Training loss: 0.24322973077015672
Validation loss: 2.5598120228717436

Epoch: 5| Step: 5
Training loss: 0.1651257958569865
Validation loss: 2.592795183786448

Epoch: 5| Step: 6
Training loss: 0.2079449948300794
Validation loss: 2.5509733071770335

Epoch: 5| Step: 7
Training loss: 0.2101374217111243
Validation loss: 2.598710468367238

Epoch: 5| Step: 8
Training loss: 0.22094310103227227
Validation loss: 2.6289520964237325

Epoch: 5| Step: 9
Training loss: 0.23904010443409396
Validation loss: 2.618553345192334

Epoch: 5| Step: 10
Training loss: 0.11933429017623479
Validation loss: 2.5697813911937026

Epoch: 483| Step: 0
Training loss: 0.2446465247961269
Validation loss: 2.6232561490331796

Epoch: 5| Step: 1
Training loss: 0.24987823531034756
Validation loss: 2.5767756267294493

Epoch: 5| Step: 2
Training loss: 0.17986601793583049
Validation loss: 2.6022097461057463

Epoch: 5| Step: 3
Training loss: 0.26316725869521873
Validation loss: 2.5980552646302923

Epoch: 5| Step: 4
Training loss: 0.12439254218302247
Validation loss: 2.5630931142828035

Epoch: 5| Step: 5
Training loss: 0.14308795180843842
Validation loss: 2.5859401757268863

Epoch: 5| Step: 6
Training loss: 0.25602446027776515
Validation loss: 2.5686143450128185

Epoch: 5| Step: 7
Training loss: 0.14718036612050447
Validation loss: 2.595222561189168

Epoch: 5| Step: 8
Training loss: 0.23260798335983546
Validation loss: 2.537460803869775

Epoch: 5| Step: 9
Training loss: 0.2581534154598052
Validation loss: 2.584972547916654

Epoch: 5| Step: 10
Training loss: 0.12887932033724928
Validation loss: 2.570969994559526

Epoch: 484| Step: 0
Training loss: 0.15898034421042856
Validation loss: 2.5862003514156706

Epoch: 5| Step: 1
Training loss: 0.33249145478905745
Validation loss: 2.5759350058885446

Epoch: 5| Step: 2
Training loss: 0.2142782050332672
Validation loss: 2.606752711481178

Epoch: 5| Step: 3
Training loss: 0.10171659407257312
Validation loss: 2.599580225807252

Epoch: 5| Step: 4
Training loss: 0.2527947084086584
Validation loss: 2.6146916294029627

Epoch: 5| Step: 5
Training loss: 0.1669905088016838
Validation loss: 2.580964602835701

Epoch: 5| Step: 6
Training loss: 0.18504064669181575
Validation loss: 2.62090088108248

Epoch: 5| Step: 7
Training loss: 0.19866979924181502
Validation loss: 2.638366972586438

Epoch: 5| Step: 8
Training loss: 0.21076550359140594
Validation loss: 2.6097369945979567

Epoch: 5| Step: 9
Training loss: 0.18837467463730403
Validation loss: 2.631986943644239

Epoch: 5| Step: 10
Training loss: 0.15948228217166646
Validation loss: 2.6032217195719225

Epoch: 485| Step: 0
Training loss: 0.18206198846186633
Validation loss: 2.5699730190206114

Epoch: 5| Step: 1
Training loss: 0.2135934514934516
Validation loss: 2.598155271179395

Epoch: 5| Step: 2
Training loss: 0.2649521861711271
Validation loss: 2.6201053952539834

Epoch: 5| Step: 3
Training loss: 0.24966835584761943
Validation loss: 2.569035529276331

Epoch: 5| Step: 4
Training loss: 0.14401943855124358
Validation loss: 2.5995483514545605

Epoch: 5| Step: 5
Training loss: 0.15186109256450142
Validation loss: 2.6130848465020016

Epoch: 5| Step: 6
Training loss: 0.24305932727036816
Validation loss: 2.6260231893264194

Epoch: 5| Step: 7
Training loss: 0.20770494144224816
Validation loss: 2.5916393898088157

Epoch: 5| Step: 8
Training loss: 0.2153213567531625
Validation loss: 2.607678165324517

Epoch: 5| Step: 9
Training loss: 0.16099323816716035
Validation loss: 2.5950944467515766

Epoch: 5| Step: 10
Training loss: 0.27284510337922985
Validation loss: 2.5996386106473435

Epoch: 486| Step: 0
Training loss: 0.27288900949877465
Validation loss: 2.6211885790556875

Epoch: 5| Step: 1
Training loss: 0.16019033441480574
Validation loss: 2.595751268436096

Epoch: 5| Step: 2
Training loss: 0.19664490173381327
Validation loss: 2.604651466445822

Epoch: 5| Step: 3
Training loss: 0.1251616847897772
Validation loss: 2.5834744309374775

Epoch: 5| Step: 4
Training loss: 0.1912309564041311
Validation loss: 2.5846988219620513

Epoch: 5| Step: 5
Training loss: 0.28090628177881566
Validation loss: 2.5913227464684567

Epoch: 5| Step: 6
Training loss: 0.22733462239979726
Validation loss: 2.5982673488133528

Epoch: 5| Step: 7
Training loss: 0.15206021430927483
Validation loss: 2.609427799532891

Epoch: 5| Step: 8
Training loss: 0.19215346476939824
Validation loss: 2.5975006044549707

Epoch: 5| Step: 9
Training loss: 0.20691542714457348
Validation loss: 2.593275318083101

Epoch: 5| Step: 10
Training loss: 0.28544459722577403
Validation loss: 2.598500993364181

Epoch: 487| Step: 0
Training loss: 0.11579277232207204
Validation loss: 2.6600033131838705

Epoch: 5| Step: 1
Training loss: 0.18676288075243272
Validation loss: 2.622588875139897

Epoch: 5| Step: 2
Training loss: 0.33193297334205085
Validation loss: 2.6409801922161926

Epoch: 5| Step: 3
Training loss: 0.24773525578328132
Validation loss: 2.5963798170579113

Epoch: 5| Step: 4
Training loss: 0.19703715851748171
Validation loss: 2.6160464698170998

Epoch: 5| Step: 5
Training loss: 0.21488587226623979
Validation loss: 2.5714311960153715

Epoch: 5| Step: 6
Training loss: 0.1567660749754621
Validation loss: 2.5802843663308703

Epoch: 5| Step: 7
Training loss: 0.25915098972885964
Validation loss: 2.5962667835694035

Epoch: 5| Step: 8
Training loss: 0.22471955955358489
Validation loss: 2.5845986151199125

Epoch: 5| Step: 9
Training loss: 0.26471519332097776
Validation loss: 2.6008113372952715

Epoch: 5| Step: 10
Training loss: 0.271841240025488
Validation loss: 2.59546147187545

Epoch: 488| Step: 0
Training loss: 0.2693941762918122
Validation loss: 2.588857934533675

Epoch: 5| Step: 1
Training loss: 0.23641392435046055
Validation loss: 2.568656688512662

Epoch: 5| Step: 2
Training loss: 0.29938335821155204
Validation loss: 2.5861723992389325

Epoch: 5| Step: 3
Training loss: 0.22088831331104292
Validation loss: 2.555956563909269

Epoch: 5| Step: 4
Training loss: 0.1567452806472651
Validation loss: 2.517730338393043

Epoch: 5| Step: 5
Training loss: 0.18086250335426546
Validation loss: 2.5346833500335264

Epoch: 5| Step: 6
Training loss: 0.30812411244324533
Validation loss: 2.555827417562373

Epoch: 5| Step: 7
Training loss: 0.24165568874900223
Validation loss: 2.5471032575918926

Epoch: 5| Step: 8
Training loss: 0.15867395158288813
Validation loss: 2.578156201524012

Epoch: 5| Step: 9
Training loss: 0.15105139492758346
Validation loss: 2.56086741478325

Epoch: 5| Step: 10
Training loss: 0.24787636400589072
Validation loss: 2.593825300507132

Epoch: 489| Step: 0
Training loss: 0.2661765487076946
Validation loss: 2.60518657097619

Epoch: 5| Step: 1
Training loss: 0.1874223886238747
Validation loss: 2.600312515279039

Epoch: 5| Step: 2
Training loss: 0.206613668331245
Validation loss: 2.5515785915218325

Epoch: 5| Step: 3
Training loss: 0.18576234052335633
Validation loss: 2.602128406049132

Epoch: 5| Step: 4
Training loss: 0.10563972090526234
Validation loss: 2.608795370835764

Epoch: 5| Step: 5
Training loss: 0.18164223495918422
Validation loss: 2.623274002795348

Epoch: 5| Step: 6
Training loss: 0.2423211467293308
Validation loss: 2.621587631178686

Epoch: 5| Step: 7
Training loss: 0.2596732384016802
Validation loss: 2.6336294976771124

Epoch: 5| Step: 8
Training loss: 0.3354727835339434
Validation loss: 2.6557519019838938

Epoch: 5| Step: 9
Training loss: 0.16833296920560728
Validation loss: 2.648096748307897

Epoch: 5| Step: 10
Training loss: 0.2696141930820876
Validation loss: 2.6625566021186327

Epoch: 490| Step: 0
Training loss: 0.2407768606321768
Validation loss: 2.660948031827961

Epoch: 5| Step: 1
Training loss: 0.25997013273535163
Validation loss: 2.6532070693983862

Epoch: 5| Step: 2
Training loss: 0.1477769408893471
Validation loss: 2.6569406705690573

Epoch: 5| Step: 3
Training loss: 0.1748764487500335
Validation loss: 2.639709056527117

Epoch: 5| Step: 4
Training loss: 0.15860201738917196
Validation loss: 2.608794759601675

Epoch: 5| Step: 5
Training loss: 0.2528277747840971
Validation loss: 2.6375603106792633

Epoch: 5| Step: 6
Training loss: 0.2003968689598256
Validation loss: 2.6221478750459513

Epoch: 5| Step: 7
Training loss: 0.28273336979017205
Validation loss: 2.631788560340159

Epoch: 5| Step: 8
Training loss: 0.1556401929658826
Validation loss: 2.5954184080377143

Epoch: 5| Step: 9
Training loss: 0.11443578276239037
Validation loss: 2.6776714362880982

Epoch: 5| Step: 10
Training loss: 0.27649410824594794
Validation loss: 2.6284256862351905

Epoch: 491| Step: 0
Training loss: 0.12972124706245994
Validation loss: 2.6249751008274336

Epoch: 5| Step: 1
Training loss: 0.18443452795459245
Validation loss: 2.595560103723864

Epoch: 5| Step: 2
Training loss: 0.24302548362500162
Validation loss: 2.599823868609508

Epoch: 5| Step: 3
Training loss: 0.2143567287260316
Validation loss: 2.5940997612757375

Epoch: 5| Step: 4
Training loss: 0.18233870625977228
Validation loss: 2.5910473177436093

Epoch: 5| Step: 5
Training loss: 0.23463630415014383
Validation loss: 2.613003329403188

Epoch: 5| Step: 6
Training loss: 0.26573399102858464
Validation loss: 2.572872660848739

Epoch: 5| Step: 7
Training loss: 0.22790160377952068
Validation loss: 2.5794772815633396

Epoch: 5| Step: 8
Training loss: 0.1651727823123004
Validation loss: 2.5833421390104183

Epoch: 5| Step: 9
Training loss: 0.177743377038378
Validation loss: 2.5890476978995376

Epoch: 5| Step: 10
Training loss: 0.21225571229805423
Validation loss: 2.5743101671638398

Epoch: 492| Step: 0
Training loss: 0.19163006717292827
Validation loss: 2.5560587782414563

Epoch: 5| Step: 1
Training loss: 0.2039147302172258
Validation loss: 2.555276935755202

Epoch: 5| Step: 2
Training loss: 0.168097424567859
Validation loss: 2.5760443392306835

Epoch: 5| Step: 3
Training loss: 0.14545190620423962
Validation loss: 2.6083517855572382

Epoch: 5| Step: 4
Training loss: 0.2677215692882206
Validation loss: 2.59407784260217

Epoch: 5| Step: 5
Training loss: 0.2692975537651501
Validation loss: 2.55767392518119

Epoch: 5| Step: 6
Training loss: 0.2236038422456155
Validation loss: 2.5845774718805

Epoch: 5| Step: 7
Training loss: 0.13748476827309208
Validation loss: 2.5662631024288003

Epoch: 5| Step: 8
Training loss: 0.17152480732790623
Validation loss: 2.56636473445016

Epoch: 5| Step: 9
Training loss: 0.26249674556622127
Validation loss: 2.5573382830236313

Epoch: 5| Step: 10
Training loss: 0.14691020107494285
Validation loss: 2.5527288645514834

Epoch: 493| Step: 0
Training loss: 0.1753750930144892
Validation loss: 2.569101307010617

Epoch: 5| Step: 1
Training loss: 0.23974335896161697
Validation loss: 2.577787293770302

Epoch: 5| Step: 2
Training loss: 0.19094897162382019
Validation loss: 2.5622465051801724

Epoch: 5| Step: 3
Training loss: 0.20637840226082096
Validation loss: 2.5922300330693964

Epoch: 5| Step: 4
Training loss: 0.12376302126811384
Validation loss: 2.61671170382137

Epoch: 5| Step: 5
Training loss: 0.14806216873044933
Validation loss: 2.5832232439584017

Epoch: 5| Step: 6
Training loss: 0.3154300418060486
Validation loss: 2.5761106485476932

Epoch: 5| Step: 7
Training loss: 0.17951602632203964
Validation loss: 2.6108213143283665

Epoch: 5| Step: 8
Training loss: 0.22897225590277848
Validation loss: 2.613859231206441

Epoch: 5| Step: 9
Training loss: 0.15229539225983574
Validation loss: 2.5834512481877163

Epoch: 5| Step: 10
Training loss: 0.14846868563871246
Validation loss: 2.5864091267181837

Epoch: 494| Step: 0
Training loss: 0.13672739410321866
Validation loss: 2.6137406571848607

Epoch: 5| Step: 1
Training loss: 0.14150030527739063
Validation loss: 2.6135192438500208

Epoch: 5| Step: 2
Training loss: 0.28572945921703624
Validation loss: 2.637283329164782

Epoch: 5| Step: 3
Training loss: 0.22091253018136986
Validation loss: 2.6053784187446554

Epoch: 5| Step: 4
Training loss: 0.18410492812815032
Validation loss: 2.6071001078690537

Epoch: 5| Step: 5
Training loss: 0.18454546483626424
Validation loss: 2.625472905639391

Epoch: 5| Step: 6
Training loss: 0.2727690837610442
Validation loss: 2.6045564496783085

Epoch: 5| Step: 7
Training loss: 0.2008510920843187
Validation loss: 2.600920069461556

Epoch: 5| Step: 8
Training loss: 0.16730760600741712
Validation loss: 2.5724179400338216

Epoch: 5| Step: 9
Training loss: 0.17735876490347127
Validation loss: 2.576272424535589

Epoch: 5| Step: 10
Training loss: 0.1828301559790551
Validation loss: 2.582630126927262

Epoch: 495| Step: 0
Training loss: 0.1503008413452755
Validation loss: 2.5673790749530174

Epoch: 5| Step: 1
Training loss: 0.14474192291991647
Validation loss: 2.5744594271186445

Epoch: 5| Step: 2
Training loss: 0.21371622723639566
Validation loss: 2.5905582613686833

Epoch: 5| Step: 3
Training loss: 0.17813487569302502
Validation loss: 2.5666355124240727

Epoch: 5| Step: 4
Training loss: 0.1976231649097654
Validation loss: 2.576473954120619

Epoch: 5| Step: 5
Training loss: 0.16261489593482004
Validation loss: 2.569598008895285

Epoch: 5| Step: 6
Training loss: 0.18199355181207008
Validation loss: 2.5849783744279535

Epoch: 5| Step: 7
Training loss: 0.17951934658791163
Validation loss: 2.5699437511473717

Epoch: 5| Step: 8
Training loss: 0.31390854967109466
Validation loss: 2.5744447544964277

Epoch: 5| Step: 9
Training loss: 0.2486795706581358
Validation loss: 2.5857366252073715

Epoch: 5| Step: 10
Training loss: 0.11048870932199578
Validation loss: 2.606617845932499

Epoch: 496| Step: 0
Training loss: 0.18948114325604076
Validation loss: 2.609928166787445

Epoch: 5| Step: 1
Training loss: 0.16165077881889442
Validation loss: 2.594789672470879

Epoch: 5| Step: 2
Training loss: 0.08639652220288718
Validation loss: 2.603650678809219

Epoch: 5| Step: 3
Training loss: 0.1824134567409487
Validation loss: 2.621824497257326

Epoch: 5| Step: 4
Training loss: 0.21519623364805182
Validation loss: 2.5929366337693316

Epoch: 5| Step: 5
Training loss: 0.09522966122872642
Validation loss: 2.6125127161761315

Epoch: 5| Step: 6
Training loss: 0.19776406909589475
Validation loss: 2.595364967901374

Epoch: 5| Step: 7
Training loss: 0.11301608950976859
Validation loss: 2.6090172354191226

Epoch: 5| Step: 8
Training loss: 0.23293876872063893
Validation loss: 2.586662852742553

Epoch: 5| Step: 9
Training loss: 0.282893544381919
Validation loss: 2.5931206720662012

Epoch: 5| Step: 10
Training loss: 0.15434716407111004
Validation loss: 2.581021838423598

Epoch: 497| Step: 0
Training loss: 0.1556864768993493
Validation loss: 2.5880168380189548

Epoch: 5| Step: 1
Training loss: 0.20397657920816586
Validation loss: 2.5953920871646727

Epoch: 5| Step: 2
Training loss: 0.14816015459132226
Validation loss: 2.5873271198765915

Epoch: 5| Step: 3
Training loss: 0.13751008040150547
Validation loss: 2.584732976185854

Epoch: 5| Step: 4
Training loss: 0.09200155489905941
Validation loss: 2.614198381727519

Epoch: 5| Step: 5
Training loss: 0.17297224368639344
Validation loss: 2.580119626565335

Epoch: 5| Step: 6
Training loss: 0.1599296443731002
Validation loss: 2.569146039338456

Epoch: 5| Step: 7
Training loss: 0.09283295780026884
Validation loss: 2.5986399441473162

Epoch: 5| Step: 8
Training loss: 0.32738063030928916
Validation loss: 2.575470925459551

Epoch: 5| Step: 9
Training loss: 0.10555014295340182
Validation loss: 2.6099740931575512

Epoch: 5| Step: 10
Training loss: 0.30026608478570294
Validation loss: 2.591957523577352

Epoch: 498| Step: 0
Training loss: 0.16700991040150706
Validation loss: 2.5801872032938706

Epoch: 5| Step: 1
Training loss: 0.21597840918091088
Validation loss: 2.6076465248901424

Epoch: 5| Step: 2
Training loss: 0.1713370987663767
Validation loss: 2.6154767663700658

Epoch: 5| Step: 3
Training loss: 0.19801240203409015
Validation loss: 2.608428222323045

Epoch: 5| Step: 4
Training loss: 0.18825187533104354
Validation loss: 2.5753956039351045

Epoch: 5| Step: 5
Training loss: 0.221341568457433
Validation loss: 2.5735265566860956

Epoch: 5| Step: 6
Training loss: 0.16557390689003762
Validation loss: 2.6081176974807194

Epoch: 5| Step: 7
Training loss: 0.2159076272393539
Validation loss: 2.603812576996105

Epoch: 5| Step: 8
Training loss: 0.23606026657558885
Validation loss: 2.593714867383696

Epoch: 5| Step: 9
Training loss: 0.1266837048900757
Validation loss: 2.6043000529594376

Epoch: 5| Step: 10
Training loss: 0.16306367025434285
Validation loss: 2.633451668352198

Epoch: 499| Step: 0
Training loss: 0.2336452727127549
Validation loss: 2.598830940513855

Epoch: 5| Step: 1
Training loss: 0.22389488190024942
Validation loss: 2.6289960063946634

Epoch: 5| Step: 2
Training loss: 0.10847086677529995
Validation loss: 2.620662526769416

Epoch: 5| Step: 3
Training loss: 0.17206789701327338
Validation loss: 2.6268230764227223

Epoch: 5| Step: 4
Training loss: 0.2331969696459412
Validation loss: 2.612251407822499

Epoch: 5| Step: 5
Training loss: 0.1185036500678478
Validation loss: 2.59306653799778

Epoch: 5| Step: 6
Training loss: 0.22240535922647278
Validation loss: 2.6257112411627426

Epoch: 5| Step: 7
Training loss: 0.1849751850670916
Validation loss: 2.6013937723000704

Epoch: 5| Step: 8
Training loss: 0.18095074152218749
Validation loss: 2.5874595622681245

Epoch: 5| Step: 9
Training loss: 0.17717997050560247
Validation loss: 2.606911628096392

Epoch: 5| Step: 10
Training loss: 0.12743525289244687
Validation loss: 2.5921630551240726

Epoch: 500| Step: 0
Training loss: 0.2316791383398787
Validation loss: 2.61034542727971

Epoch: 5| Step: 1
Training loss: 0.19070297585012314
Validation loss: 2.5960978963480468

Epoch: 5| Step: 2
Training loss: 0.11275558347526701
Validation loss: 2.596619706802681

Epoch: 5| Step: 3
Training loss: 0.15818701768045737
Validation loss: 2.5782703059152685

Epoch: 5| Step: 4
Training loss: 0.25225389256607206
Validation loss: 2.594004259176383

Epoch: 5| Step: 5
Training loss: 0.1643235706602484
Validation loss: 2.564305312084796

Epoch: 5| Step: 6
Training loss: 0.11516963627313227
Validation loss: 2.596855894566634

Epoch: 5| Step: 7
Training loss: 0.1394775385283222
Validation loss: 2.594261181329954

Epoch: 5| Step: 8
Training loss: 0.10452208581448624
Validation loss: 2.6075152644169357

Epoch: 5| Step: 9
Training loss: 0.1472316247358726
Validation loss: 2.5898405279309236

Epoch: 5| Step: 10
Training loss: 0.23072511347934166
Validation loss: 2.5993444187336205

Epoch: 501| Step: 0
Training loss: 0.12353238189356262
Validation loss: 2.609284621720705

Epoch: 5| Step: 1
Training loss: 0.2271959968431447
Validation loss: 2.588662850063079

Epoch: 5| Step: 2
Training loss: 0.18591174339966873
Validation loss: 2.6132220439916916

Epoch: 5| Step: 3
Training loss: 0.22719868590458026
Validation loss: 2.599985012164274

Epoch: 5| Step: 4
Training loss: 0.18976354239001422
Validation loss: 2.5953364476725485

Epoch: 5| Step: 5
Training loss: 0.23876761219212983
Validation loss: 2.601397450136233

Epoch: 5| Step: 6
Training loss: 0.1377718827560346
Validation loss: 2.5902982660744436

Epoch: 5| Step: 7
Training loss: 0.1262770624710185
Validation loss: 2.600395396357772

Epoch: 5| Step: 8
Training loss: 0.13155733977321374
Validation loss: 2.592705899105865

Epoch: 5| Step: 9
Training loss: 0.16749940770670804
Validation loss: 2.5656306583739386

Epoch: 5| Step: 10
Training loss: 0.2543337231262673
Validation loss: 2.57412061405102

Epoch: 502| Step: 0
Training loss: 0.11822770903090704
Validation loss: 2.595975062556376

Epoch: 5| Step: 1
Training loss: 0.23014805189346615
Validation loss: 2.570755913670729

Epoch: 5| Step: 2
Training loss: 0.144257763558655
Validation loss: 2.623363089972464

Epoch: 5| Step: 3
Training loss: 0.23962303623923065
Validation loss: 2.5952780658173418

Epoch: 5| Step: 4
Training loss: 0.17136970935545906
Validation loss: 2.588112488746136

Epoch: 5| Step: 5
Training loss: 0.15517891099869296
Validation loss: 2.605181503592365

Epoch: 5| Step: 6
Training loss: 0.1272540048290367
Validation loss: 2.6261027698619435

Epoch: 5| Step: 7
Training loss: 0.15464396008482373
Validation loss: 2.6167170315246717

Epoch: 5| Step: 8
Training loss: 0.27125119411188087
Validation loss: 2.58613319847362

Epoch: 5| Step: 9
Training loss: 0.2194835505811886
Validation loss: 2.5945344409091216

Epoch: 5| Step: 10
Training loss: 0.18540563729161003
Validation loss: 2.6256591840360515

Epoch: 503| Step: 0
Training loss: 0.2862060244901167
Validation loss: 2.5874963918181915

Epoch: 5| Step: 1
Training loss: 0.11659325293703644
Validation loss: 2.5947913125429647

Epoch: 5| Step: 2
Training loss: 0.20299841531125612
Validation loss: 2.6007324912857364

Epoch: 5| Step: 3
Training loss: 0.11270284148243653
Validation loss: 2.5926107154827394

Epoch: 5| Step: 4
Training loss: 0.14446900934925933
Validation loss: 2.620443196842813

Epoch: 5| Step: 5
Training loss: 0.16457222479038128
Validation loss: 2.5815932109082462

Epoch: 5| Step: 6
Training loss: 0.18925798335426894
Validation loss: 2.58713653319758

Epoch: 5| Step: 7
Training loss: 0.13116291057542767
Validation loss: 2.6065835948926552

Epoch: 5| Step: 8
Training loss: 0.2097178626782798
Validation loss: 2.5888007454374087

Epoch: 5| Step: 9
Training loss: 0.2418027097524949
Validation loss: 2.609463357218512

Epoch: 5| Step: 10
Training loss: 0.14039161309227283
Validation loss: 2.604735660206781

Epoch: 504| Step: 0
Training loss: 0.09577529482662932
Validation loss: 2.607573562529197

Epoch: 5| Step: 1
Training loss: 0.11506929939311461
Validation loss: 2.585958618240417

Epoch: 5| Step: 2
Training loss: 0.1831493375997153
Validation loss: 2.5816118145636997

Epoch: 5| Step: 3
Training loss: 0.1583711297217923
Validation loss: 2.599274681021133

Epoch: 5| Step: 4
Training loss: 0.20077019004194893
Validation loss: 2.631412958259832

Epoch: 5| Step: 5
Training loss: 0.24648395514112403
Validation loss: 2.5730587629145565

Epoch: 5| Step: 6
Training loss: 0.1940669589674498
Validation loss: 2.594729951404929

Epoch: 5| Step: 7
Training loss: 0.22362990564847537
Validation loss: 2.5845642111444795

Epoch: 5| Step: 8
Training loss: 0.14117349178272928
Validation loss: 2.5625230461502895

Epoch: 5| Step: 9
Training loss: 0.21191894947517045
Validation loss: 2.550702700788767

Epoch: 5| Step: 10
Training loss: 0.1271808049832259
Validation loss: 2.582641041060468

Epoch: 505| Step: 0
Training loss: 0.11556443129401331
Validation loss: 2.597495794972978

Epoch: 5| Step: 1
Training loss: 0.21643050915088047
Validation loss: 2.5926215737572575

Epoch: 5| Step: 2
Training loss: 0.16765014239133663
Validation loss: 2.5734411864696325

Epoch: 5| Step: 3
Training loss: 0.10366062589096894
Validation loss: 2.588956050536227

Epoch: 5| Step: 4
Training loss: 0.13337596407991462
Validation loss: 2.5746953859923085

Epoch: 5| Step: 5
Training loss: 0.19058973971211954
Validation loss: 2.5840565279160392

Epoch: 5| Step: 6
Training loss: 0.07659308421142462
Validation loss: 2.579380486925679

Epoch: 5| Step: 7
Training loss: 0.16291468303132167
Validation loss: 2.5876936130058152

Epoch: 5| Step: 8
Training loss: 0.2267627078110319
Validation loss: 2.5747840112966243

Epoch: 5| Step: 9
Training loss: 0.23415120089158029
Validation loss: 2.568273756163733

Epoch: 5| Step: 10
Training loss: 0.1355364770776273
Validation loss: 2.5468979077089378

Epoch: 506| Step: 0
Training loss: 0.21386650816927105
Validation loss: 2.5610914168113985

Epoch: 5| Step: 1
Training loss: 0.09596027159931488
Validation loss: 2.5392715537160773

Epoch: 5| Step: 2
Training loss: 0.10743418536307488
Validation loss: 2.551411617463768

Epoch: 5| Step: 3
Training loss: 0.1426939950710396
Validation loss: 2.558590156924009

Epoch: 5| Step: 4
Training loss: 0.1807265508684133
Validation loss: 2.518328182012434

Epoch: 5| Step: 5
Training loss: 0.25870656551933224
Validation loss: 2.5617913047254284

Epoch: 5| Step: 6
Training loss: 0.19270794885614206
Validation loss: 2.5939058083325626

Epoch: 5| Step: 7
Training loss: 0.11478081441667319
Validation loss: 2.5360805410957745

Epoch: 5| Step: 8
Training loss: 0.21052484414761125
Validation loss: 2.532526568123893

Epoch: 5| Step: 9
Training loss: 0.16100535698272794
Validation loss: 2.5350945284745667

Epoch: 5| Step: 10
Training loss: 0.15621323152895705
Validation loss: 2.5288248946779706

Epoch: 507| Step: 0
Training loss: 0.11225394885746698
Validation loss: 2.5472890402960413

Epoch: 5| Step: 1
Training loss: 0.2681594159195344
Validation loss: 2.5477929488373054

Epoch: 5| Step: 2
Training loss: 0.1708777605899762
Validation loss: 2.5552629821947046

Epoch: 5| Step: 3
Training loss: 0.13559106606620505
Validation loss: 2.565612275577654

Epoch: 5| Step: 4
Training loss: 0.13453199342085845
Validation loss: 2.5771194301752547

Epoch: 5| Step: 5
Training loss: 0.21649602687264688
Validation loss: 2.5941458127157744

Epoch: 5| Step: 6
Training loss: 0.22975076757734506
Validation loss: 2.571572265941421

Epoch: 5| Step: 7
Training loss: 0.08257420551305898
Validation loss: 2.586846478158187

Epoch: 5| Step: 8
Training loss: 0.11404124545287976
Validation loss: 2.5899328255067613

Epoch: 5| Step: 9
Training loss: 0.17923716421403804
Validation loss: 2.602171409579245

Epoch: 5| Step: 10
Training loss: 0.11055874154256522
Validation loss: 2.5987520354056683

Epoch: 508| Step: 0
Training loss: 0.08333620020534513
Validation loss: 2.5944714709710666

Epoch: 5| Step: 1
Training loss: 0.10094715276717182
Validation loss: 2.5969128756699624

Epoch: 5| Step: 2
Training loss: 0.20570100016063336
Validation loss: 2.602605617784749

Epoch: 5| Step: 3
Training loss: 0.12721962466837639
Validation loss: 2.5923305689347744

Epoch: 5| Step: 4
Training loss: 0.23557535192319015
Validation loss: 2.5932711136808977

Epoch: 5| Step: 5
Training loss: 0.09985651417452743
Validation loss: 2.5950036279170607

Epoch: 5| Step: 6
Training loss: 0.10482446034721507
Validation loss: 2.5746961058879245

Epoch: 5| Step: 7
Training loss: 0.26095006992421743
Validation loss: 2.598942082492977

Epoch: 5| Step: 8
Training loss: 0.13085725412500507
Validation loss: 2.6014504618417598

Epoch: 5| Step: 9
Training loss: 0.22150113985907166
Validation loss: 2.5901368187761937

Epoch: 5| Step: 10
Training loss: 0.1729314533244304
Validation loss: 2.6354744515063846

Epoch: 509| Step: 0
Training loss: 0.20267673694759866
Validation loss: 2.5948068418006494

Epoch: 5| Step: 1
Training loss: 0.1489894355690603
Validation loss: 2.5925265749211857

Epoch: 5| Step: 2
Training loss: 0.14722078232565886
Validation loss: 2.609682967480501

Epoch: 5| Step: 3
Training loss: 0.2082840245227355
Validation loss: 2.5876765133834545

Epoch: 5| Step: 4
Training loss: 0.16283582021563256
Validation loss: 2.57168227821474

Epoch: 5| Step: 5
Training loss: 0.2491328429199629
Validation loss: 2.6004792833032386

Epoch: 5| Step: 6
Training loss: 0.18490461319686824
Validation loss: 2.591440374130107

Epoch: 5| Step: 7
Training loss: 0.13948557767267294
Validation loss: 2.583374523928716

Epoch: 5| Step: 8
Training loss: 0.153204886607732
Validation loss: 2.5977497516698564

Epoch: 5| Step: 9
Training loss: 0.11847743733652513
Validation loss: 2.587277292269227

Epoch: 5| Step: 10
Training loss: 0.22407424869353942
Validation loss: 2.5965460478052718

Epoch: 510| Step: 0
Training loss: 0.16638205983740895
Validation loss: 2.5519589549317407

Epoch: 5| Step: 1
Training loss: 0.12679359242579014
Validation loss: 2.57626230935601

Epoch: 5| Step: 2
Training loss: 0.18888875134040772
Validation loss: 2.5641598151790954

Epoch: 5| Step: 3
Training loss: 0.10319547358441175
Validation loss: 2.5858354515196633

Epoch: 5| Step: 4
Training loss: 0.17014708338410198
Validation loss: 2.5713745839268523

Epoch: 5| Step: 5
Training loss: 0.2371579803849027
Validation loss: 2.603115042384635

Epoch: 5| Step: 6
Training loss: 0.23109370697825807
Validation loss: 2.5673709637683544

Epoch: 5| Step: 7
Training loss: 0.12401664144563967
Validation loss: 2.607837825748929

Epoch: 5| Step: 8
Training loss: 0.2094651245328154
Validation loss: 2.584440582181698

Epoch: 5| Step: 9
Training loss: 0.15195080012526296
Validation loss: 2.593148254736803

Epoch: 5| Step: 10
Training loss: 0.08038970469901693
Validation loss: 2.595216161025881

Epoch: 511| Step: 0
Training loss: 0.14136871398202824
Validation loss: 2.606210252973157

Epoch: 5| Step: 1
Training loss: 0.2322917301380316
Validation loss: 2.5940967510391912

Epoch: 5| Step: 2
Training loss: 0.1003600983276623
Validation loss: 2.593592240000517

Epoch: 5| Step: 3
Training loss: 0.17620548342173137
Validation loss: 2.6031116959107616

Epoch: 5| Step: 4
Training loss: 0.16100500413273358
Validation loss: 2.594054757578629

Epoch: 5| Step: 5
Training loss: 0.07124706559768315
Validation loss: 2.592524923527805

Epoch: 5| Step: 6
Training loss: 0.18452339989020472
Validation loss: 2.574789574110707

Epoch: 5| Step: 7
Training loss: 0.1821106295581286
Validation loss: 2.612057050288237

Epoch: 5| Step: 8
Training loss: 0.23146847315282837
Validation loss: 2.5986265874605454

Epoch: 5| Step: 9
Training loss: 0.1129902769421893
Validation loss: 2.5729312153172774

Epoch: 5| Step: 10
Training loss: 0.22597374547522994
Validation loss: 2.5851797643059586

Epoch: 512| Step: 0
Training loss: 0.28371250776643914
Validation loss: 2.595641809121378

Epoch: 5| Step: 1
Training loss: 0.14633179029160417
Validation loss: 2.5976657459851245

Epoch: 5| Step: 2
Training loss: 0.19283793683486314
Validation loss: 2.564348679973961

Epoch: 5| Step: 3
Training loss: 0.11545020839219886
Validation loss: 2.58092122857316

Epoch: 5| Step: 4
Training loss: 0.15413772245788113
Validation loss: 2.5893514723333104

Epoch: 5| Step: 5
Training loss: 0.13210302777554664
Validation loss: 2.568169553365738

Epoch: 5| Step: 6
Training loss: 0.26700633973549437
Validation loss: 2.5896757793348257

Epoch: 5| Step: 7
Training loss: 0.16434948661556897
Validation loss: 2.567977217929873

Epoch: 5| Step: 8
Training loss: 0.2611027057556817
Validation loss: 2.563444263729416

Epoch: 5| Step: 9
Training loss: 0.15320525742232907
Validation loss: 2.569999770303375

Epoch: 5| Step: 10
Training loss: 0.1936082779249311
Validation loss: 2.5935161152532626

Epoch: 513| Step: 0
Training loss: 0.1584855079053771
Validation loss: 2.607829961319705

Epoch: 5| Step: 1
Training loss: 0.18265853250609487
Validation loss: 2.6081171411328383

Epoch: 5| Step: 2
Training loss: 0.26865013507141716
Validation loss: 2.588662770836364

Epoch: 5| Step: 3
Training loss: 0.10129910021739587
Validation loss: 2.6057038326358892

Epoch: 5| Step: 4
Training loss: 0.18576483723783602
Validation loss: 2.6003987621011038

Epoch: 5| Step: 5
Training loss: 0.1568635992166689
Validation loss: 2.5923709239999817

Epoch: 5| Step: 6
Training loss: 0.25879902370643126
Validation loss: 2.5697917383879156

Epoch: 5| Step: 7
Training loss: 0.18080184425222007
Validation loss: 2.595686344808627

Epoch: 5| Step: 8
Training loss: 0.20635900579058292
Validation loss: 2.6023814540669137

Epoch: 5| Step: 9
Training loss: 0.12266696834505517
Validation loss: 2.583298309464532

Epoch: 5| Step: 10
Training loss: 0.1953900183386462
Validation loss: 2.588916295797713

Epoch: 514| Step: 0
Training loss: 0.2144777040692619
Validation loss: 2.584495379997211

Epoch: 5| Step: 1
Training loss: 0.14969325316369264
Validation loss: 2.585969166390931

Epoch: 5| Step: 2
Training loss: 0.16296118116129682
Validation loss: 2.57247827923645

Epoch: 5| Step: 3
Training loss: 0.16949045288084513
Validation loss: 2.593855073779551

Epoch: 5| Step: 4
Training loss: 0.13729729178033173
Validation loss: 2.575903691868954

Epoch: 5| Step: 5
Training loss: 0.12345667747419109
Validation loss: 2.5767705994819727

Epoch: 5| Step: 6
Training loss: 0.11325551842434867
Validation loss: 2.5625377004967977

Epoch: 5| Step: 7
Training loss: 0.23194368039333366
Validation loss: 2.6163381830309933

Epoch: 5| Step: 8
Training loss: 0.22729942899142203
Validation loss: 2.601763459492169

Epoch: 5| Step: 9
Training loss: 0.23494234558521493
Validation loss: 2.568503466729596

Epoch: 5| Step: 10
Training loss: 0.09960484026890083
Validation loss: 2.5561728959497723

Epoch: 515| Step: 0
Training loss: 0.19205619466867035
Validation loss: 2.5807024931595803

Epoch: 5| Step: 1
Training loss: 0.14074610422800352
Validation loss: 2.616898329604866

Epoch: 5| Step: 2
Training loss: 0.11698297295558796
Validation loss: 2.632215332164293

Epoch: 5| Step: 3
Training loss: 0.3498165433185509
Validation loss: 2.6139344898761663

Epoch: 5| Step: 4
Training loss: 0.22853740360128824
Validation loss: 2.601485615142664

Epoch: 5| Step: 5
Training loss: 0.11733400802834312
Validation loss: 2.5914983245691676

Epoch: 5| Step: 6
Training loss: 0.15683487265903506
Validation loss: 2.6006410131979703

Epoch: 5| Step: 7
Training loss: 0.2109573672793191
Validation loss: 2.594491699617663

Epoch: 5| Step: 8
Training loss: 0.1618876204394559
Validation loss: 2.5921194953886415

Epoch: 5| Step: 9
Training loss: 0.11998978503032805
Validation loss: 2.5700994077155994

Epoch: 5| Step: 10
Training loss: 0.201119805050789
Validation loss: 2.5916151860356256

Epoch: 516| Step: 0
Training loss: 0.21395301838401834
Validation loss: 2.5883857402946564

Epoch: 5| Step: 1
Training loss: 0.17893307330684818
Validation loss: 2.5895933243830185

Epoch: 5| Step: 2
Training loss: 0.22991286334965855
Validation loss: 2.6022743572388003

Epoch: 5| Step: 3
Training loss: 0.14545953192836714
Validation loss: 2.604856997307981

Epoch: 5| Step: 4
Training loss: 0.23105155671837044
Validation loss: 2.592804832539558

Epoch: 5| Step: 5
Training loss: 0.1296350367264514
Validation loss: 2.5871002603831705

Epoch: 5| Step: 6
Training loss: 0.27786471907026317
Validation loss: 2.6112845835650247

Epoch: 5| Step: 7
Training loss: 0.19504967171502766
Validation loss: 2.5937202986632553

Epoch: 5| Step: 8
Training loss: 0.13700802037419674
Validation loss: 2.606996150079517

Epoch: 5| Step: 9
Training loss: 0.15251916176761832
Validation loss: 2.5869736419294163

Epoch: 5| Step: 10
Training loss: 0.14650759195081195
Validation loss: 2.594594617529146

Epoch: 517| Step: 0
Training loss: 0.18534729915495177
Validation loss: 2.598453375923403

Epoch: 5| Step: 1
Training loss: 0.20778373504841668
Validation loss: 2.584406861550276

Epoch: 5| Step: 2
Training loss: 0.2743476705908671
Validation loss: 2.582381539222716

Epoch: 5| Step: 3
Training loss: 0.12857917269637867
Validation loss: 2.5953594926502217

Epoch: 5| Step: 4
Training loss: 0.17218748859398555
Validation loss: 2.6126298995669806

Epoch: 5| Step: 5
Training loss: 0.16629557847027718
Validation loss: 2.619089221317625

Epoch: 5| Step: 6
Training loss: 0.08561898397452276
Validation loss: 2.644579019289413

Epoch: 5| Step: 7
Training loss: 0.17752755886364252
Validation loss: 2.6164352146375847

Epoch: 5| Step: 8
Training loss: 0.10799434019088967
Validation loss: 2.626251607908667

Epoch: 5| Step: 9
Training loss: 0.21962157390290885
Validation loss: 2.610074819962535

Epoch: 5| Step: 10
Training loss: 0.14782984484631825
Validation loss: 2.6070379262334598

Epoch: 518| Step: 0
Training loss: 0.1594985506393986
Validation loss: 2.6130437860936495

Epoch: 5| Step: 1
Training loss: 0.15778896491496328
Validation loss: 2.6228638300931353

Epoch: 5| Step: 2
Training loss: 0.22649211447927975
Validation loss: 2.6024537692459107

Epoch: 5| Step: 3
Training loss: 0.20639585662305932
Validation loss: 2.5917147199849215

Epoch: 5| Step: 4
Training loss: 0.13116597795664128
Validation loss: 2.601515996467404

Epoch: 5| Step: 5
Training loss: 0.17029145486978878
Validation loss: 2.5749451289038863

Epoch: 5| Step: 6
Training loss: 0.16967007736383538
Validation loss: 2.570011389954388

Epoch: 5| Step: 7
Training loss: 0.23776251188582706
Validation loss: 2.586344849775941

Epoch: 5| Step: 8
Training loss: 0.19545333553006758
Validation loss: 2.570308073516085

Epoch: 5| Step: 9
Training loss: 0.12295323926610335
Validation loss: 2.5533866579652114

Epoch: 5| Step: 10
Training loss: 0.19068673220842164
Validation loss: 2.588557107969773

Epoch: 519| Step: 0
Training loss: 0.1197510776655449
Validation loss: 2.5707371466890163

Epoch: 5| Step: 1
Training loss: 0.19541955874735628
Validation loss: 2.6123564700205097

Epoch: 5| Step: 2
Training loss: 0.19179479904760563
Validation loss: 2.5739567357359032

Epoch: 5| Step: 3
Training loss: 0.12804434639398996
Validation loss: 2.552636893941971

Epoch: 5| Step: 4
Training loss: 0.2274486050873065
Validation loss: 2.5780358740054883

Epoch: 5| Step: 5
Training loss: 0.08869260365027108
Validation loss: 2.570610514097963

Epoch: 5| Step: 6
Training loss: 0.2015596559604817
Validation loss: 2.5652895874415114

Epoch: 5| Step: 7
Training loss: 0.1457983610817221
Validation loss: 2.5824545281152216

Epoch: 5| Step: 8
Training loss: 0.14766159678673532
Validation loss: 2.5875510317879673

Epoch: 5| Step: 9
Training loss: 0.20912819664057355
Validation loss: 2.5654681443741962

Epoch: 5| Step: 10
Training loss: 0.15297290293712934
Validation loss: 2.575138843392029

Epoch: 520| Step: 0
Training loss: 0.20886988489518488
Validation loss: 2.5652547316240684

Epoch: 5| Step: 1
Training loss: 0.20885858582619873
Validation loss: 2.5828593458015465

Epoch: 5| Step: 2
Training loss: 0.20774629656960011
Validation loss: 2.5645775345524267

Epoch: 5| Step: 3
Training loss: 0.1514575934381091
Validation loss: 2.602170770189015

Epoch: 5| Step: 4
Training loss: 0.09023281525423926
Validation loss: 2.5794841605597645

Epoch: 5| Step: 5
Training loss: 0.13292715789334067
Validation loss: 2.5773979307815633

Epoch: 5| Step: 6
Training loss: 0.1638077165355689
Validation loss: 2.5500944952091777

Epoch: 5| Step: 7
Training loss: 0.24152533701804152
Validation loss: 2.6039878544278534

Epoch: 5| Step: 8
Training loss: 0.14640187165340357
Validation loss: 2.599452743803454

Epoch: 5| Step: 9
Training loss: 0.11316322064308786
Validation loss: 2.5781535386003442

Epoch: 5| Step: 10
Training loss: 0.1437566983694071
Validation loss: 2.5753527284221045

Epoch: 521| Step: 0
Training loss: 0.2558029199880571
Validation loss: 2.567506916839497

Epoch: 5| Step: 1
Training loss: 0.14375522775058935
Validation loss: 2.5915695278529816

Epoch: 5| Step: 2
Training loss: 0.16464381884593832
Validation loss: 2.5825680360967884

Epoch: 5| Step: 3
Training loss: 0.16759979401387437
Validation loss: 2.5912959798537867

Epoch: 5| Step: 4
Training loss: 0.14699867246394915
Validation loss: 2.5862815535609602

Epoch: 5| Step: 5
Training loss: 0.29471539222779203
Validation loss: 2.5738132027949785

Epoch: 5| Step: 6
Training loss: 0.15249856394146327
Validation loss: 2.5668957412139704

Epoch: 5| Step: 7
Training loss: 0.13168033317921374
Validation loss: 2.54714100783091

Epoch: 5| Step: 8
Training loss: 0.11473752253559513
Validation loss: 2.589842540363477

Epoch: 5| Step: 9
Training loss: 0.2070768234187846
Validation loss: 2.579696930791512

Epoch: 5| Step: 10
Training loss: 0.1245422400671078
Validation loss: 2.607676400145677

Epoch: 522| Step: 0
Training loss: 0.23204991686194193
Validation loss: 2.5666272560559698

Epoch: 5| Step: 1
Training loss: 0.12596532490606124
Validation loss: 2.564210487416341

Epoch: 5| Step: 2
Training loss: 0.19138106355585466
Validation loss: 2.571596039279024

Epoch: 5| Step: 3
Training loss: 0.18358978307780582
Validation loss: 2.565058000939417

Epoch: 5| Step: 4
Training loss: 0.1771191228902429
Validation loss: 2.6103044244475906

Epoch: 5| Step: 5
Training loss: 0.09315702543732522
Validation loss: 2.5406936522612225

Epoch: 5| Step: 6
Training loss: 0.2304060656760102
Validation loss: 2.560658062017582

Epoch: 5| Step: 7
Training loss: 0.08802075025123798
Validation loss: 2.5582652562682227

Epoch: 5| Step: 8
Training loss: 0.16593276929487763
Validation loss: 2.5712967116678773

Epoch: 5| Step: 9
Training loss: 0.1398250623289372
Validation loss: 2.5925210274218884

Epoch: 5| Step: 10
Training loss: 0.21158680939576605
Validation loss: 2.594902330169208

Epoch: 523| Step: 0
Training loss: 0.1886929964204464
Validation loss: 2.601846722963884

Epoch: 5| Step: 1
Training loss: 0.16389009522465076
Validation loss: 2.6011461952582025

Epoch: 5| Step: 2
Training loss: 0.12980275088669901
Validation loss: 2.6091312198535057

Epoch: 5| Step: 3
Training loss: 0.14323784772979023
Validation loss: 2.5854394711531055

Epoch: 5| Step: 4
Training loss: 0.09823405514648799
Validation loss: 2.6072208383727844

Epoch: 5| Step: 5
Training loss: 0.1393601436138289
Validation loss: 2.6216903483632583

Epoch: 5| Step: 6
Training loss: 0.20596895649129418
Validation loss: 2.5925816146674645

Epoch: 5| Step: 7
Training loss: 0.2022245788919047
Validation loss: 2.626993263414648

Epoch: 5| Step: 8
Training loss: 0.19726239570013984
Validation loss: 2.613736347405232

Epoch: 5| Step: 9
Training loss: 0.2875631729463009
Validation loss: 2.6279616166070325

Epoch: 5| Step: 10
Training loss: 0.25251343988776465
Validation loss: 2.630401178480926

Epoch: 524| Step: 0
Training loss: 0.2823967997709027
Validation loss: 2.649289393598903

Epoch: 5| Step: 1
Training loss: 0.2049082279351295
Validation loss: 2.615326043270299

Epoch: 5| Step: 2
Training loss: 0.17813770934824655
Validation loss: 2.6253426480050406

Epoch: 5| Step: 3
Training loss: 0.18322018907864432
Validation loss: 2.6220350993255663

Epoch: 5| Step: 4
Training loss: 0.17120576200989776
Validation loss: 2.601018469676644

Epoch: 5| Step: 5
Training loss: 0.17033302507175102
Validation loss: 2.618589273855235

Epoch: 5| Step: 6
Training loss: 0.21917521497847087
Validation loss: 2.589886584825

Epoch: 5| Step: 7
Training loss: 0.17959049965270404
Validation loss: 2.6041238760765326

Epoch: 5| Step: 8
Training loss: 0.1935129519059662
Validation loss: 2.6095280952679434

Epoch: 5| Step: 9
Training loss: 0.18877878812697982
Validation loss: 2.5803672210803277

Epoch: 5| Step: 10
Training loss: 0.13590218699195872
Validation loss: 2.5638330645283935

Epoch: 525| Step: 0
Training loss: 0.16024444059304002
Validation loss: 2.5607035212524094

Epoch: 5| Step: 1
Training loss: 0.16498708188538425
Validation loss: 2.5666401549963584

Epoch: 5| Step: 2
Training loss: 0.1130335417940449
Validation loss: 2.5576278217137527

Epoch: 5| Step: 3
Training loss: 0.18817077300064125
Validation loss: 2.570058576260185

Epoch: 5| Step: 4
Training loss: 0.19488713675430794
Validation loss: 2.5561037453353395

Epoch: 5| Step: 5
Training loss: 0.2123298609038933
Validation loss: 2.561163202187898

Epoch: 5| Step: 6
Training loss: 0.20236170847377027
Validation loss: 2.5553314580506314

Epoch: 5| Step: 7
Training loss: 0.1703188523149066
Validation loss: 2.57484292429261

Epoch: 5| Step: 8
Training loss: 0.15746706581350625
Validation loss: 2.595142161387291

Epoch: 5| Step: 9
Training loss: 0.16973349114817984
Validation loss: 2.5999170359523625

Epoch: 5| Step: 10
Training loss: 0.16214172201418717
Validation loss: 2.618389914635427

Epoch: 526| Step: 0
Training loss: 0.1621376955043963
Validation loss: 2.608174726440733

Epoch: 5| Step: 1
Training loss: 0.14101646164199458
Validation loss: 2.603059630998823

Epoch: 5| Step: 2
Training loss: 0.1528181002669181
Validation loss: 2.6066530062590263

Epoch: 5| Step: 3
Training loss: 0.07050842234699126
Validation loss: 2.6230050244449097

Epoch: 5| Step: 4
Training loss: 0.11944947702464806
Validation loss: 2.596129518793486

Epoch: 5| Step: 5
Training loss: 0.15465969572739852
Validation loss: 2.5921877730000524

Epoch: 5| Step: 6
Training loss: 0.14748245360178389
Validation loss: 2.6373877387860656

Epoch: 5| Step: 7
Training loss: 0.20638434990579088
Validation loss: 2.6133393542498924

Epoch: 5| Step: 8
Training loss: 0.27360664313331867
Validation loss: 2.6151802712764813

Epoch: 5| Step: 9
Training loss: 0.15918341439219638
Validation loss: 2.601413635707111

Epoch: 5| Step: 10
Training loss: 0.25369851344041067
Validation loss: 2.5902549164722375

Epoch: 527| Step: 0
Training loss: 0.13744899687054063
Validation loss: 2.612368579873235

Epoch: 5| Step: 1
Training loss: 0.16765227555739515
Validation loss: 2.5946307554370933

Epoch: 5| Step: 2
Training loss: 0.22072315969089917
Validation loss: 2.596019277505259

Epoch: 5| Step: 3
Training loss: 0.14005418666533642
Validation loss: 2.5857270784727935

Epoch: 5| Step: 4
Training loss: 0.19223367167433086
Validation loss: 2.616958165853778

Epoch: 5| Step: 5
Training loss: 0.19046907262172397
Validation loss: 2.6026520333900085

Epoch: 5| Step: 6
Training loss: 0.16078113556830928
Validation loss: 2.6048531285048826

Epoch: 5| Step: 7
Training loss: 0.1996857181732246
Validation loss: 2.6151726499842205

Epoch: 5| Step: 8
Training loss: 0.17767228100329138
Validation loss: 2.6334596285733958

Epoch: 5| Step: 9
Training loss: 0.17073574496480914
Validation loss: 2.5971615590679122

Epoch: 5| Step: 10
Training loss: 0.10515322996907056
Validation loss: 2.6202753354015855

Epoch: 528| Step: 0
Training loss: 0.11490969256850758
Validation loss: 2.6040898127546614

Epoch: 5| Step: 1
Training loss: 0.1291392921914373
Validation loss: 2.616383003324593

Epoch: 5| Step: 2
Training loss: 0.20097623960359695
Validation loss: 2.623618822679914

Epoch: 5| Step: 3
Training loss: 0.13601652731204497
Validation loss: 2.588073824533193

Epoch: 5| Step: 4
Training loss: 0.24346735626740326
Validation loss: 2.6008067793773186

Epoch: 5| Step: 5
Training loss: 0.14431843683794382
Validation loss: 2.600352136210887

Epoch: 5| Step: 6
Training loss: 0.16834688317318572
Validation loss: 2.5938320688072802

Epoch: 5| Step: 7
Training loss: 0.10820919994143222
Validation loss: 2.5905246144328222

Epoch: 5| Step: 8
Training loss: 0.25061962706973356
Validation loss: 2.5592622598930452

Epoch: 5| Step: 9
Training loss: 0.1877700629029283
Validation loss: 2.6179209602642484

Epoch: 5| Step: 10
Training loss: 0.1471831060166735
Validation loss: 2.594220001853668

Epoch: 529| Step: 0
Training loss: 0.2167278042299755
Validation loss: 2.5988101754651827

Epoch: 5| Step: 1
Training loss: 0.20717686804222352
Validation loss: 2.589715410552256

Epoch: 5| Step: 2
Training loss: 0.1186164322812527
Validation loss: 2.588016974719147

Epoch: 5| Step: 3
Training loss: 0.18979509695647112
Validation loss: 2.5695337065143584

Epoch: 5| Step: 4
Training loss: 0.10582254374346038
Validation loss: 2.585572659185175

Epoch: 5| Step: 5
Training loss: 0.18436744682552084
Validation loss: 2.5808292330318867

Epoch: 5| Step: 6
Training loss: 0.1566675388968398
Validation loss: 2.593587832490681

Epoch: 5| Step: 7
Training loss: 0.1733255837176046
Validation loss: 2.58018232477676

Epoch: 5| Step: 8
Training loss: 0.17502932260286763
Validation loss: 2.5606662813168475

Epoch: 5| Step: 9
Training loss: 0.19897071506925254
Validation loss: 2.5854562861189985

Epoch: 5| Step: 10
Training loss: 0.18707073266584964
Validation loss: 2.563070396330232

Epoch: 530| Step: 0
Training loss: 0.21146494654632433
Validation loss: 2.6029751190762203

Epoch: 5| Step: 1
Training loss: 0.061364249885150976
Validation loss: 2.5804396296250385

Epoch: 5| Step: 2
Training loss: 0.20378691773239296
Validation loss: 2.6021054944175876

Epoch: 5| Step: 3
Training loss: 0.1269513790303993
Validation loss: 2.5803032357568747

Epoch: 5| Step: 4
Training loss: 0.19673599300911357
Validation loss: 2.5969462912674603

Epoch: 5| Step: 5
Training loss: 0.13572069725240055
Validation loss: 2.6199263475669805

Epoch: 5| Step: 6
Training loss: 0.20967751824602038
Validation loss: 2.5997158060276484

Epoch: 5| Step: 7
Training loss: 0.1263514640141158
Validation loss: 2.5980821407017056

Epoch: 5| Step: 8
Training loss: 0.14567518528858917
Validation loss: 2.585798685558728

Epoch: 5| Step: 9
Training loss: 0.1611450364071161
Validation loss: 2.603287942277486

Epoch: 5| Step: 10
Training loss: 0.22175139893151818
Validation loss: 2.5933665805008492

Epoch: 531| Step: 0
Training loss: 0.2390387096285853
Validation loss: 2.5809760345596

Epoch: 5| Step: 1
Training loss: 0.07579864555462126
Validation loss: 2.6156612779550796

Epoch: 5| Step: 2
Training loss: 0.22242802919932178
Validation loss: 2.6001023825341023

Epoch: 5| Step: 3
Training loss: 0.13093696969682833
Validation loss: 2.6038605960928956

Epoch: 5| Step: 4
Training loss: 0.19634940515170177
Validation loss: 2.6029233734974158

Epoch: 5| Step: 5
Training loss: 0.17488368076963542
Validation loss: 2.6113351748526696

Epoch: 5| Step: 6
Training loss: 0.1308305338491208
Validation loss: 2.6216142870272887

Epoch: 5| Step: 7
Training loss: 0.14824221966608675
Validation loss: 2.622614748087914

Epoch: 5| Step: 8
Training loss: 0.13429844083644316
Validation loss: 2.5960871237135645

Epoch: 5| Step: 9
Training loss: 0.182024212320523
Validation loss: 2.6381888601145507

Epoch: 5| Step: 10
Training loss: 0.10460105020305166
Validation loss: 2.6068044036660365

Epoch: 532| Step: 0
Training loss: 0.16331922098747123
Validation loss: 2.621908659741363

Epoch: 5| Step: 1
Training loss: 0.14815858310350166
Validation loss: 2.619853622247685

Epoch: 5| Step: 2
Training loss: 0.10105207449443702
Validation loss: 2.586264091716626

Epoch: 5| Step: 3
Training loss: 0.17109668676912893
Validation loss: 2.5929958612631014

Epoch: 5| Step: 4
Training loss: 0.20972679744941056
Validation loss: 2.5833858293789183

Epoch: 5| Step: 5
Training loss: 0.22371584587647367
Validation loss: 2.5729309502777618

Epoch: 5| Step: 6
Training loss: 0.19122966094105015
Validation loss: 2.598858292910025

Epoch: 5| Step: 7
Training loss: 0.20670640399652496
Validation loss: 2.614136084538071

Epoch: 5| Step: 8
Training loss: 0.15415304457778717
Validation loss: 2.631208189346466

Epoch: 5| Step: 9
Training loss: 0.25909838633816956
Validation loss: 2.6338107879387613

Epoch: 5| Step: 10
Training loss: 0.06591038483685349
Validation loss: 2.61120869381392

Epoch: 533| Step: 0
Training loss: 0.21731587739283248
Validation loss: 2.615992895422827

Epoch: 5| Step: 1
Training loss: 0.2201096141632724
Validation loss: 2.603169902571863

Epoch: 5| Step: 2
Training loss: 0.1221970167624696
Validation loss: 2.641139228498649

Epoch: 5| Step: 3
Training loss: 0.25969261921818704
Validation loss: 2.6370402172286074

Epoch: 5| Step: 4
Training loss: 0.17024142265174272
Validation loss: 2.6615152089042184

Epoch: 5| Step: 5
Training loss: 0.22121260922430272
Validation loss: 2.6150187651217527

Epoch: 5| Step: 6
Training loss: 0.17120203571646725
Validation loss: 2.6486209330702786

Epoch: 5| Step: 7
Training loss: 0.14302970623819314
Validation loss: 2.598364287642217

Epoch: 5| Step: 8
Training loss: 0.11757601073889347
Validation loss: 2.5886869021913275

Epoch: 5| Step: 9
Training loss: 0.11393276668631211
Validation loss: 2.560091736344191

Epoch: 5| Step: 10
Training loss: 0.09566414292169745
Validation loss: 2.5934865466614077

Epoch: 534| Step: 0
Training loss: 0.13925248145215868
Validation loss: 2.5923125020591464

Epoch: 5| Step: 1
Training loss: 0.11270817959217344
Validation loss: 2.6001384670627585

Epoch: 5| Step: 2
Training loss: 0.25206029815620173
Validation loss: 2.628710025995633

Epoch: 5| Step: 3
Training loss: 0.1651603208128598
Validation loss: 2.6158313610371313

Epoch: 5| Step: 4
Training loss: 0.07198260599562278
Validation loss: 2.5999402907830045

Epoch: 5| Step: 5
Training loss: 0.22111905832647885
Validation loss: 2.598497983293325

Epoch: 5| Step: 6
Training loss: 0.15742732788751315
Validation loss: 2.5930208885633115

Epoch: 5| Step: 7
Training loss: 0.15665735550191115
Validation loss: 2.588333671847712

Epoch: 5| Step: 8
Training loss: 0.1643260473889148
Validation loss: 2.5952486694244272

Epoch: 5| Step: 9
Training loss: 0.14854390948083954
Validation loss: 2.5979275824717827

Epoch: 5| Step: 10
Training loss: 0.13736852461485152
Validation loss: 2.627794210803065

Epoch: 535| Step: 0
Training loss: 0.14405844653751038
Validation loss: 2.576222881171162

Epoch: 5| Step: 1
Training loss: 0.12332079310621075
Validation loss: 2.5807221010874923

Epoch: 5| Step: 2
Training loss: 0.26838188854326434
Validation loss: 2.59385057282277

Epoch: 5| Step: 3
Training loss: 0.14700614192881312
Validation loss: 2.6088542451753836

Epoch: 5| Step: 4
Training loss: 0.09431873603039861
Validation loss: 2.594434070483708

Epoch: 5| Step: 5
Training loss: 0.12303176666027259
Validation loss: 2.5641845750452457

Epoch: 5| Step: 6
Training loss: 0.1707636983233795
Validation loss: 2.5630578875173375

Epoch: 5| Step: 7
Training loss: 0.14099381349481763
Validation loss: 2.5342277766821546

Epoch: 5| Step: 8
Training loss: 0.11520995673397677
Validation loss: 2.591448852675993

Epoch: 5| Step: 9
Training loss: 0.1831528869265474
Validation loss: 2.5828836991176467

Epoch: 5| Step: 10
Training loss: 0.13829093645943588
Validation loss: 2.5851329184660994

Epoch: 536| Step: 0
Training loss: 0.15971225742570366
Validation loss: 2.5833913642433446

Epoch: 5| Step: 1
Training loss: 0.09656205872400928
Validation loss: 2.5633283347282134

Epoch: 5| Step: 2
Training loss: 0.24896151202791514
Validation loss: 2.5434995693001765

Epoch: 5| Step: 3
Training loss: 0.20927827437029692
Validation loss: 2.5995861487666447

Epoch: 5| Step: 4
Training loss: 0.11062995009877584
Validation loss: 2.5703240309647777

Epoch: 5| Step: 5
Training loss: 0.16918860541237282
Validation loss: 2.584398120341676

Epoch: 5| Step: 6
Training loss: 0.11686290848627245
Validation loss: 2.5806290970835555

Epoch: 5| Step: 7
Training loss: 0.12934983399168185
Validation loss: 2.5648569652040543

Epoch: 5| Step: 8
Training loss: 0.09391109711900182
Validation loss: 2.5451582308882537

Epoch: 5| Step: 9
Training loss: 0.12974899970938775
Validation loss: 2.5572553267450235

Epoch: 5| Step: 10
Training loss: 0.1328628528735996
Validation loss: 2.549909104913478

Epoch: 537| Step: 0
Training loss: 0.08915633018950003
Validation loss: 2.534743745511762

Epoch: 5| Step: 1
Training loss: 0.09769140087748328
Validation loss: 2.553797196152745

Epoch: 5| Step: 2
Training loss: 0.1751538152040556
Validation loss: 2.5521216471049786

Epoch: 5| Step: 3
Training loss: 0.1971523979730976
Validation loss: 2.545563555004911

Epoch: 5| Step: 4
Training loss: 0.17516470442929444
Validation loss: 2.5352722441769635

Epoch: 5| Step: 5
Training loss: 0.16255593552181144
Validation loss: 2.552974531426719

Epoch: 5| Step: 6
Training loss: 0.22246736746614437
Validation loss: 2.5876170878495826

Epoch: 5| Step: 7
Training loss: 0.0867804883154911
Validation loss: 2.591819886661667

Epoch: 5| Step: 8
Training loss: 0.22624834247108405
Validation loss: 2.573996805183145

Epoch: 5| Step: 9
Training loss: 0.12731967242041917
Validation loss: 2.588737680593401

Epoch: 5| Step: 10
Training loss: 0.12973783762796282
Validation loss: 2.593988487921774

Epoch: 538| Step: 0
Training loss: 0.12883947550298241
Validation loss: 2.6028634500064265

Epoch: 5| Step: 1
Training loss: 0.1531995492096729
Validation loss: 2.6109431433196164

Epoch: 5| Step: 2
Training loss: 0.23465309334040335
Validation loss: 2.608684723339845

Epoch: 5| Step: 3
Training loss: 0.09218503172851404
Validation loss: 2.594435949908118

Epoch: 5| Step: 4
Training loss: 0.15780471744798635
Validation loss: 2.6085539684163828

Epoch: 5| Step: 5
Training loss: 0.19122339778899206
Validation loss: 2.6182394950922765

Epoch: 5| Step: 6
Training loss: 0.20496444276022846
Validation loss: 2.604370774340736

Epoch: 5| Step: 7
Training loss: 0.13066287018783623
Validation loss: 2.5878228531714798

Epoch: 5| Step: 8
Training loss: 0.10592618836155392
Validation loss: 2.5841971616036323

Epoch: 5| Step: 9
Training loss: 0.07641509546085432
Validation loss: 2.578052469764022

Epoch: 5| Step: 10
Training loss: 0.12332096302681347
Validation loss: 2.566490913268634

Epoch: 539| Step: 0
Training loss: 0.12059346421146855
Validation loss: 2.5513064546617166

Epoch: 5| Step: 1
Training loss: 0.12134079958462456
Validation loss: 2.55967780391189

Epoch: 5| Step: 2
Training loss: 0.14023261162119388
Validation loss: 2.5808512433633903

Epoch: 5| Step: 3
Training loss: 0.11486284525411827
Validation loss: 2.578294285958611

Epoch: 5| Step: 4
Training loss: 0.18951646001774783
Validation loss: 2.5635534762687064

Epoch: 5| Step: 5
Training loss: 0.15418433056516836
Validation loss: 2.5480168139324277

Epoch: 5| Step: 6
Training loss: 0.09626340350111079
Validation loss: 2.5707379604363223

Epoch: 5| Step: 7
Training loss: 0.11311119568359732
Validation loss: 2.5565998864398383

Epoch: 5| Step: 8
Training loss: 0.20953238464890273
Validation loss: 2.550412362597204

Epoch: 5| Step: 9
Training loss: 0.19501312199482332
Validation loss: 2.5600875525490654

Epoch: 5| Step: 10
Training loss: 0.15534387945984363
Validation loss: 2.5860830043692564

Epoch: 540| Step: 0
Training loss: 0.10091416960324649
Validation loss: 2.543049671230231

Epoch: 5| Step: 1
Training loss: 0.14128240594431082
Validation loss: 2.5623411884212777

Epoch: 5| Step: 2
Training loss: 0.2548240067618605
Validation loss: 2.562311427163271

Epoch: 5| Step: 3
Training loss: 0.16363718898928092
Validation loss: 2.5617426261480576

Epoch: 5| Step: 4
Training loss: 0.15587477930568805
Validation loss: 2.527395435763384

Epoch: 5| Step: 5
Training loss: 0.1560777489591478
Validation loss: 2.53540043246085

Epoch: 5| Step: 6
Training loss: 0.19014192014690887
Validation loss: 2.5760156031040937

Epoch: 5| Step: 7
Training loss: 0.19840220865930489
Validation loss: 2.565098369303044

Epoch: 5| Step: 8
Training loss: 0.10062782563513024
Validation loss: 2.5680332734950104

Epoch: 5| Step: 9
Training loss: 0.16308805041743285
Validation loss: 2.59408207238001

Epoch: 5| Step: 10
Training loss: 0.13398947636537933
Validation loss: 2.5723629995484583

Epoch: 541| Step: 0
Training loss: 0.10802911441436729
Validation loss: 2.6080184012656003

Epoch: 5| Step: 1
Training loss: 0.1764175501550008
Validation loss: 2.5969632493990225

Epoch: 5| Step: 2
Training loss: 0.20962661029649843
Validation loss: 2.6103336041480425

Epoch: 5| Step: 3
Training loss: 0.20005300162284287
Validation loss: 2.628220948919688

Epoch: 5| Step: 4
Training loss: 0.12849094217610432
Validation loss: 2.613215844631274

Epoch: 5| Step: 5
Training loss: 0.16262102388744828
Validation loss: 2.6226073463472277

Epoch: 5| Step: 6
Training loss: 0.14034946919978897
Validation loss: 2.642657436674081

Epoch: 5| Step: 7
Training loss: 0.1463110152250299
Validation loss: 2.6418333051753278

Epoch: 5| Step: 8
Training loss: 0.08664452086547883
Validation loss: 2.6337133632276357

Epoch: 5| Step: 9
Training loss: 0.17534724805745688
Validation loss: 2.640055475177284

Epoch: 5| Step: 10
Training loss: 0.3095231486593342
Validation loss: 2.6263392167686432

Epoch: 542| Step: 0
Training loss: 0.10941687701853434
Validation loss: 2.6169310085169184

Epoch: 5| Step: 1
Training loss: 0.23315506380763915
Validation loss: 2.603968564938109

Epoch: 5| Step: 2
Training loss: 0.2668814116071829
Validation loss: 2.6227719841989545

Epoch: 5| Step: 3
Training loss: 0.37087843822457955
Validation loss: 2.613579587337151

Epoch: 5| Step: 4
Training loss: 0.257582041300192
Validation loss: 2.601724598089239

Epoch: 5| Step: 5
Training loss: 0.190762117193483
Validation loss: 2.588982650726907

Epoch: 5| Step: 6
Training loss: 0.3387777886658548
Validation loss: 2.5835773238341435

Epoch: 5| Step: 7
Training loss: 0.3602927141803366
Validation loss: 2.586277426010304

Epoch: 5| Step: 8
Training loss: 0.2719085590434175
Validation loss: 2.6461511184837483

Epoch: 5| Step: 9
Training loss: 0.23403664643500222
Validation loss: 2.636410542123644

Epoch: 5| Step: 10
Training loss: 0.43510508690242733
Validation loss: 2.641267750082814

Epoch: 543| Step: 0
Training loss: 0.28396615464477093
Validation loss: 2.6412669405940306

Epoch: 5| Step: 1
Training loss: 0.20823048596125612
Validation loss: 2.637052745501091

Epoch: 5| Step: 2
Training loss: 0.22997471828520155
Validation loss: 2.595784582942012

Epoch: 5| Step: 3
Training loss: 0.32674866348290965
Validation loss: 2.5852141620729334

Epoch: 5| Step: 4
Training loss: 0.30761756291442244
Validation loss: 2.567004224175706

Epoch: 5| Step: 5
Training loss: 0.2873238132523992
Validation loss: 2.574914204081816

Epoch: 5| Step: 6
Training loss: 0.18641352785584642
Validation loss: 2.604103171938365

Epoch: 5| Step: 7
Training loss: 0.3112980855619442
Validation loss: 2.586287600153055

Epoch: 5| Step: 8
Training loss: 0.20429254567389457
Validation loss: 2.5795083569100017

Epoch: 5| Step: 9
Training loss: 0.15786814251630343
Validation loss: 2.5666361666597033

Epoch: 5| Step: 10
Training loss: 0.23104796121695
Validation loss: 2.6002666627712343

Epoch: 544| Step: 0
Training loss: 0.22567417021108965
Validation loss: 2.5797083800582326

Epoch: 5| Step: 1
Training loss: 0.2735339267189641
Validation loss: 2.58180994997336

Epoch: 5| Step: 2
Training loss: 0.24863689566089026
Validation loss: 2.562377925779325

Epoch: 5| Step: 3
Training loss: 0.3753608318656759
Validation loss: 2.582262900756729

Epoch: 5| Step: 4
Training loss: 0.3700378051014826
Validation loss: 2.584070659835671

Epoch: 5| Step: 5
Training loss: 0.2215802225818346
Validation loss: 2.612980590144926

Epoch: 5| Step: 6
Training loss: 0.16669784505107155
Validation loss: 2.590209371886055

Epoch: 5| Step: 7
Training loss: 0.25966398502204885
Validation loss: 2.580473431903024

Epoch: 5| Step: 8
Training loss: 0.2473452248592589
Validation loss: 2.6128995240650013

Epoch: 5| Step: 9
Training loss: 0.3786984296506764
Validation loss: 2.6100672706883654

Epoch: 5| Step: 10
Training loss: 0.23561905661152452
Validation loss: 2.650355222718904

Epoch: 545| Step: 0
Training loss: 0.206634744585734
Validation loss: 2.6486629702646116

Epoch: 5| Step: 1
Training loss: 0.14442954480090953
Validation loss: 2.6273541712640465

Epoch: 5| Step: 2
Training loss: 0.33505183285079665
Validation loss: 2.639971757933422

Epoch: 5| Step: 3
Training loss: 0.18596050937518208
Validation loss: 2.653046913301834

Epoch: 5| Step: 4
Training loss: 0.21036519012653293
Validation loss: 2.64627305506871

Epoch: 5| Step: 5
Training loss: 0.28282031791376994
Validation loss: 2.655531998649977

Epoch: 5| Step: 6
Training loss: 0.2629400906780876
Validation loss: 2.6880757019765706

Epoch: 5| Step: 7
Training loss: 0.31862817427699097
Validation loss: 2.6681169295086167

Epoch: 5| Step: 8
Training loss: 0.1834054651020965
Validation loss: 2.6311105654717286

Epoch: 5| Step: 9
Training loss: 0.22535638565665395
Validation loss: 2.6590163764037897

Epoch: 5| Step: 10
Training loss: 0.22275969126947961
Validation loss: 2.633590707381014

Epoch: 546| Step: 0
Training loss: 0.2597853144017194
Validation loss: 2.6128206268164575

Epoch: 5| Step: 1
Training loss: 0.2716939652268
Validation loss: 2.6228398675449465

Epoch: 5| Step: 2
Training loss: 0.2354364914620603
Validation loss: 2.584255846368764

Epoch: 5| Step: 3
Training loss: 0.19397490238224607
Validation loss: 2.55378535867384

Epoch: 5| Step: 4
Training loss: 0.25375044517290124
Validation loss: 2.5160780340597535

Epoch: 5| Step: 5
Training loss: 0.2632050938927508
Validation loss: 2.529217675785952

Epoch: 5| Step: 6
Training loss: 0.42425914241918455
Validation loss: 2.4989876040587955

Epoch: 5| Step: 7
Training loss: 0.22713367220645997
Validation loss: 2.5602536693970914

Epoch: 5| Step: 8
Training loss: 0.23125815570471156
Validation loss: 2.557507914426646

Epoch: 5| Step: 9
Training loss: 0.4880031251357805
Validation loss: 2.5705175720985656

Epoch: 5| Step: 10
Training loss: 0.3125218860591622
Validation loss: 2.564637302013327

Epoch: 547| Step: 0
Training loss: 0.17311976256177541
Validation loss: 2.5954803672693405

Epoch: 5| Step: 1
Training loss: 0.25076819650302623
Validation loss: 2.627712995383966

Epoch: 5| Step: 2
Training loss: 0.35807236642506257
Validation loss: 2.6309232776734217

Epoch: 5| Step: 3
Training loss: 0.29211044468445363
Validation loss: 2.628080019187277

Epoch: 5| Step: 4
Training loss: 0.31039014496035244
Validation loss: 2.62762178144595

Epoch: 5| Step: 5
Training loss: 0.2538308545192162
Validation loss: 2.6285360732978162

Epoch: 5| Step: 6
Training loss: 0.40352617971939003
Validation loss: 2.6233269418232372

Epoch: 5| Step: 7
Training loss: 0.33953013144746413
Validation loss: 2.5754702246932424

Epoch: 5| Step: 8
Training loss: 0.44703260123546323
Validation loss: 2.6002991918311453

Epoch: 5| Step: 9
Training loss: 0.44661807363794137
Validation loss: 2.614479455737927

Epoch: 5| Step: 10
Training loss: 0.33772578104747614
Validation loss: 2.6651224884371953

Epoch: 548| Step: 0
Training loss: 0.2973033424941451
Validation loss: 2.609977215475055

Epoch: 5| Step: 1
Training loss: 0.3171056505592118
Validation loss: 2.617257638064006

Epoch: 5| Step: 2
Training loss: 0.3590253082283099
Validation loss: 2.5945391738690122

Epoch: 5| Step: 3
Training loss: 0.2229465048345338
Validation loss: 2.5704285722946523

Epoch: 5| Step: 4
Training loss: 0.2882554153817055
Validation loss: 2.573492734886749

Epoch: 5| Step: 5
Training loss: 0.3484000275651831
Validation loss: 2.59904202828666

Epoch: 5| Step: 6
Training loss: 0.2583691194702052
Validation loss: 2.5998429945939505

Epoch: 5| Step: 7
Training loss: 0.3716816712174672
Validation loss: 2.6077569487927237

Epoch: 5| Step: 8
Training loss: 0.23065139516081434
Validation loss: 2.646896415352911

Epoch: 5| Step: 9
Training loss: 0.3014924323751743
Validation loss: 2.6651626531983257

Epoch: 5| Step: 10
Training loss: 0.4125079356499486
Validation loss: 2.6837214994040335

Epoch: 549| Step: 0
Training loss: 0.34170679267716153
Validation loss: 2.695220004993346

Epoch: 5| Step: 1
Training loss: 0.3590275494636057
Validation loss: 2.6626643143672744

Epoch: 5| Step: 2
Training loss: 0.2581203674334821
Validation loss: 2.650746158590637

Epoch: 5| Step: 3
Training loss: 0.25608555064362265
Validation loss: 2.617273535528797

Epoch: 5| Step: 4
Training loss: 0.28943961262534285
Validation loss: 2.6200979238034687

Epoch: 5| Step: 5
Training loss: 0.24160565964132052
Validation loss: 2.618506420383629

Epoch: 5| Step: 6
Training loss: 0.3462480248556713
Validation loss: 2.6362545570726983

Epoch: 5| Step: 7
Training loss: 0.31300037378526496
Validation loss: 2.6436911015585034

Epoch: 5| Step: 8
Training loss: 0.29136168622399106
Validation loss: 2.627739684218402

Epoch: 5| Step: 9
Training loss: 0.29057877029336626
Validation loss: 2.6248027338695157

Epoch: 5| Step: 10
Training loss: 0.2149929308976691
Validation loss: 2.6427729031537974

Epoch: 550| Step: 0
Training loss: 0.3802167508312675
Validation loss: 2.660121319327514

Epoch: 5| Step: 1
Training loss: 0.3458996230481518
Validation loss: 2.6993619489265384

Epoch: 5| Step: 2
Training loss: 0.2891045488240159
Validation loss: 2.622533895255385

Epoch: 5| Step: 3
Training loss: 0.33004433272699657
Validation loss: 2.620498210808612

Epoch: 5| Step: 4
Training loss: 0.20338075382555124
Validation loss: 2.5951980164425845

Epoch: 5| Step: 5
Training loss: 0.2956049127387623
Validation loss: 2.5899704072998775

Epoch: 5| Step: 6
Training loss: 0.45482558090629127
Validation loss: 2.5898181198391894

Epoch: 5| Step: 7
Training loss: 0.27393543681978544
Validation loss: 2.5385574381197156

Epoch: 5| Step: 8
Training loss: 0.3224544434381604
Validation loss: 2.512423425065765

Epoch: 5| Step: 9
Training loss: 0.29758343744681176
Validation loss: 2.487060152983803

Epoch: 5| Step: 10
Training loss: 0.3683898799882397
Validation loss: 2.5121142598242847

Epoch: 551| Step: 0
Training loss: 0.22295003883321268
Validation loss: 2.5609099814764225

Epoch: 5| Step: 1
Training loss: 0.37350605371336365
Validation loss: 2.539594160506411

Epoch: 5| Step: 2
Training loss: 0.30826949938707443
Validation loss: 2.584470069766337

Epoch: 5| Step: 3
Training loss: 0.24207460941023962
Validation loss: 2.572289886261776

Epoch: 5| Step: 4
Training loss: 0.2441981362315256
Validation loss: 2.570080844416304

Epoch: 5| Step: 5
Training loss: 0.3025718745052158
Validation loss: 2.554697233975991

Epoch: 5| Step: 6
Training loss: 0.37484318712899045
Validation loss: 2.585800236156141

Epoch: 5| Step: 7
Training loss: 0.3266747874816486
Validation loss: 2.6010440870478426

Epoch: 5| Step: 8
Training loss: 0.27167586564557716
Validation loss: 2.5971156025610282

Epoch: 5| Step: 9
Training loss: 0.39564481646428684
Validation loss: 2.643326806888216

Epoch: 5| Step: 10
Training loss: 0.3564230297909915
Validation loss: 2.6435752077584094

Epoch: 552| Step: 0
Training loss: 0.27414527299908126
Validation loss: 2.642089303773601

Epoch: 5| Step: 1
Training loss: 0.30768544484300037
Validation loss: 2.6170947447055517

Epoch: 5| Step: 2
Training loss: 0.2963209126301529
Validation loss: 2.5753225336901053

Epoch: 5| Step: 3
Training loss: 0.25098809538589717
Validation loss: 2.5660241956856806

Epoch: 5| Step: 4
Training loss: 0.2437472187397078
Validation loss: 2.5247045660705245

Epoch: 5| Step: 5
Training loss: 0.2556468867513209
Validation loss: 2.5258140323543334

Epoch: 5| Step: 6
Training loss: 0.26127494362113357
Validation loss: 2.529392375592993

Epoch: 5| Step: 7
Training loss: 0.23324820339997188
Validation loss: 2.5447297056476432

Epoch: 5| Step: 8
Training loss: 0.2772623130619882
Validation loss: 2.5368822443506533

Epoch: 5| Step: 9
Training loss: 0.27904416368994545
Validation loss: 2.554619337044797

Epoch: 5| Step: 10
Training loss: 0.3474835063086907
Validation loss: 2.5613813762417754

Epoch: 553| Step: 0
Training loss: 0.24981416560513225
Validation loss: 2.569487211222007

Epoch: 5| Step: 1
Training loss: 0.2241152926755958
Validation loss: 2.592735696109315

Epoch: 5| Step: 2
Training loss: 0.22724373934665057
Validation loss: 2.5752659053564666

Epoch: 5| Step: 3
Training loss: 0.20982843698229411
Validation loss: 2.5704002630946663

Epoch: 5| Step: 4
Training loss: 0.15738626626382274
Validation loss: 2.5884845125099107

Epoch: 5| Step: 5
Training loss: 0.2605771317421605
Validation loss: 2.5639166068964188

Epoch: 5| Step: 6
Training loss: 0.1907963084621014
Validation loss: 2.547284179286596

Epoch: 5| Step: 7
Training loss: 0.22263886567897864
Validation loss: 2.583952571181545

Epoch: 5| Step: 8
Training loss: 0.2295382027452673
Validation loss: 2.542589523059514

Epoch: 5| Step: 9
Training loss: 0.2158850835898069
Validation loss: 2.5549914795817545

Epoch: 5| Step: 10
Training loss: 0.2177934252542852
Validation loss: 2.5839894834568127

Epoch: 554| Step: 0
Training loss: 0.23819416831278264
Validation loss: 2.581313368306924

Epoch: 5| Step: 1
Training loss: 0.2610634242948536
Validation loss: 2.595196839924774

Epoch: 5| Step: 2
Training loss: 0.15633324551334166
Validation loss: 2.6110709023163388

Epoch: 5| Step: 3
Training loss: 0.23790244181180797
Validation loss: 2.6268611683418337

Epoch: 5| Step: 4
Training loss: 0.1979179737817533
Validation loss: 2.618125313323403

Epoch: 5| Step: 5
Training loss: 0.1471708235435295
Validation loss: 2.605614102324856

Epoch: 5| Step: 6
Training loss: 0.20655258192412324
Validation loss: 2.6177679611701246

Epoch: 5| Step: 7
Training loss: 0.24817453688642388
Validation loss: 2.637168574032331

Epoch: 5| Step: 8
Training loss: 0.19521159426497411
Validation loss: 2.595164571913083

Epoch: 5| Step: 9
Training loss: 0.1784826185568639
Validation loss: 2.6000194467585596

Epoch: 5| Step: 10
Training loss: 0.24304418404786848
Validation loss: 2.6016318058773424

Epoch: 555| Step: 0
Training loss: 0.14902014322501955
Validation loss: 2.6289276325501034

Epoch: 5| Step: 1
Training loss: 0.1952584764152366
Validation loss: 2.5907310587135197

Epoch: 5| Step: 2
Training loss: 0.20754770424282365
Validation loss: 2.621798898122233

Epoch: 5| Step: 3
Training loss: 0.20719122553909358
Validation loss: 2.5971463676584166

Epoch: 5| Step: 4
Training loss: 0.233670431328398
Validation loss: 2.6013489026744034

Epoch: 5| Step: 5
Training loss: 0.26047539366708744
Validation loss: 2.618253011198827

Epoch: 5| Step: 6
Training loss: 0.15458835762548226
Validation loss: 2.5988274879044355

Epoch: 5| Step: 7
Training loss: 0.2275508255435207
Validation loss: 2.6222362296014943

Epoch: 5| Step: 8
Training loss: 0.28096765014820113
Validation loss: 2.646451485605853

Epoch: 5| Step: 9
Training loss: 0.15419264786039444
Validation loss: 2.6346728385640064

Epoch: 5| Step: 10
Training loss: 0.22466284074082013
Validation loss: 2.6169837227056285

Epoch: 556| Step: 0
Training loss: 0.2697667875687433
Validation loss: 2.617684104307217

Epoch: 5| Step: 1
Training loss: 0.2242175706971952
Validation loss: 2.604743171785563

Epoch: 5| Step: 2
Training loss: 0.2682942462721495
Validation loss: 2.6306725478073845

Epoch: 5| Step: 3
Training loss: 0.20083695837432067
Validation loss: 2.638138097733604

Epoch: 5| Step: 4
Training loss: 0.211068448287605
Validation loss: 2.609091627593609

Epoch: 5| Step: 5
Training loss: 0.30221548834484246
Validation loss: 2.6247447261337467

Epoch: 5| Step: 6
Training loss: 0.1951595470434
Validation loss: 2.6335635434178846

Epoch: 5| Step: 7
Training loss: 0.250151930777094
Validation loss: 2.646401021212563

Epoch: 5| Step: 8
Training loss: 0.2206807589380522
Validation loss: 2.643648183333993

Epoch: 5| Step: 9
Training loss: 0.26965008755736763
Validation loss: 2.6672171427034232

Epoch: 5| Step: 10
Training loss: 0.18826159141133342
Validation loss: 2.668510917022903

Epoch: 557| Step: 0
Training loss: 0.22803105222639342
Validation loss: 2.6420010023209017

Epoch: 5| Step: 1
Training loss: 0.4286360968607616
Validation loss: 2.631693344641334

Epoch: 5| Step: 2
Training loss: 0.24680538825760082
Validation loss: 2.6613866661807513

Epoch: 5| Step: 3
Training loss: 0.3302825430185051
Validation loss: 2.678426479269486

Epoch: 5| Step: 4
Training loss: 0.24531976148463833
Validation loss: 2.6367789954591565

Epoch: 5| Step: 5
Training loss: 0.2908005271519536
Validation loss: 2.629339638097028

Epoch: 5| Step: 6
Training loss: 0.30045823922422743
Validation loss: 2.6382119204386054

Epoch: 5| Step: 7
Training loss: 0.3183261994470426
Validation loss: 2.599096611957972

Epoch: 5| Step: 8
Training loss: 0.3226954281645926
Validation loss: 2.5598266416621733

Epoch: 5| Step: 9
Training loss: 0.26614256531462677
Validation loss: 2.5289820942201438

Epoch: 5| Step: 10
Training loss: 0.17234929706157898
Validation loss: 2.5600022463995358

Epoch: 558| Step: 0
Training loss: 0.27694864740235964
Validation loss: 2.5602820036744776

Epoch: 5| Step: 1
Training loss: 0.38953105334335486
Validation loss: 2.5932680906195635

Epoch: 5| Step: 2
Training loss: 0.24698735529371535
Validation loss: 2.5907466934509356

Epoch: 5| Step: 3
Training loss: 0.2430110128020589
Validation loss: 2.592684311761392

Epoch: 5| Step: 4
Training loss: 0.2117914908895139
Validation loss: 2.631720551287334

Epoch: 5| Step: 5
Training loss: 0.24435493218545437
Validation loss: 2.6657062372483034

Epoch: 5| Step: 6
Training loss: 0.30611361025863937
Validation loss: 2.6979955548527634

Epoch: 5| Step: 7
Training loss: 0.2147309961081583
Validation loss: 2.739741185415965

Epoch: 5| Step: 8
Training loss: 0.43238927895799584
Validation loss: 2.7784842233400644

Epoch: 5| Step: 9
Training loss: 0.2141380075950946
Validation loss: 2.74608277319091

Epoch: 5| Step: 10
Training loss: 0.2883046112312671
Validation loss: 2.746457285566909

Epoch: 559| Step: 0
Training loss: 0.26622359762783343
Validation loss: 2.7309740565356138

Epoch: 5| Step: 1
Training loss: 0.2827716170841392
Validation loss: 2.7475746381590023

Epoch: 5| Step: 2
Training loss: 0.2989649988997559
Validation loss: 2.7216554495652883

Epoch: 5| Step: 3
Training loss: 0.27152885786125175
Validation loss: 2.6381652937924054

Epoch: 5| Step: 4
Training loss: 0.2533931536275761
Validation loss: 2.632418390524428

Epoch: 5| Step: 5
Training loss: 0.28792784927686016
Validation loss: 2.621598645200678

Epoch: 5| Step: 6
Training loss: 0.3360252598416891
Validation loss: 2.601860667115449

Epoch: 5| Step: 7
Training loss: 0.2677064852273483
Validation loss: 2.5832086389783044

Epoch: 5| Step: 8
Training loss: 0.24030185155008366
Validation loss: 2.5877772826226977

Epoch: 5| Step: 9
Training loss: 0.14667111256166473
Validation loss: 2.5946820281234957

Epoch: 5| Step: 10
Training loss: 0.2685517328273186
Validation loss: 2.5818472592792783

Epoch: 560| Step: 0
Training loss: 0.26271536371220605
Validation loss: 2.5894856115374587

Epoch: 5| Step: 1
Training loss: 0.23783668100630356
Validation loss: 2.549040947839505

Epoch: 5| Step: 2
Training loss: 0.1780388916756687
Validation loss: 2.5735643556469343

Epoch: 5| Step: 3
Training loss: 0.23213624633687585
Validation loss: 2.538357363742863

Epoch: 5| Step: 4
Training loss: 0.13634249138759372
Validation loss: 2.5407396263602102

Epoch: 5| Step: 5
Training loss: 0.23893080181658646
Validation loss: 2.5604924587538207

Epoch: 5| Step: 6
Training loss: 0.20189981328743986
Validation loss: 2.5655505223269723

Epoch: 5| Step: 7
Training loss: 0.1532577399112545
Validation loss: 2.5743716664742267

Epoch: 5| Step: 8
Training loss: 0.24560455868137182
Validation loss: 2.593213513771766

Epoch: 5| Step: 9
Training loss: 0.2092256223106861
Validation loss: 2.5871624317056114

Epoch: 5| Step: 10
Training loss: 0.19595066716853685
Validation loss: 2.5830426103811526

Epoch: 561| Step: 0
Training loss: 0.133990637129646
Validation loss: 2.6246394531423793

Epoch: 5| Step: 1
Training loss: 0.23143026246661116
Validation loss: 2.617384298899834

Epoch: 5| Step: 2
Training loss: 0.265619754739471
Validation loss: 2.6243642309576116

Epoch: 5| Step: 3
Training loss: 0.27824830579370435
Validation loss: 2.648830508439331

Epoch: 5| Step: 4
Training loss: 0.20274865609145765
Validation loss: 2.625671266708495

Epoch: 5| Step: 5
Training loss: 0.2240408128221145
Validation loss: 2.58944421998631

Epoch: 5| Step: 6
Training loss: 0.18782520900195773
Validation loss: 2.5695533018953354

Epoch: 5| Step: 7
Training loss: 0.24945693338403924
Validation loss: 2.5576808803594897

Epoch: 5| Step: 8
Training loss: 0.1458355457841984
Validation loss: 2.5664591923399884

Epoch: 5| Step: 9
Training loss: 0.19280098715342475
Validation loss: 2.576673479055143

Epoch: 5| Step: 10
Training loss: 0.20957058838099998
Validation loss: 2.5767817951178613

Epoch: 562| Step: 0
Training loss: 0.18896864855186196
Validation loss: 2.5999440820974016

Epoch: 5| Step: 1
Training loss: 0.19597693911830458
Validation loss: 2.5834472213024346

Epoch: 5| Step: 2
Training loss: 0.1856469837971864
Validation loss: 2.6016045299405173

Epoch: 5| Step: 3
Training loss: 0.22568258056677304
Validation loss: 2.6021988460699443

Epoch: 5| Step: 4
Training loss: 0.13852974498575782
Validation loss: 2.5833126058021505

Epoch: 5| Step: 5
Training loss: 0.25508717496044353
Validation loss: 2.6003190645853995

Epoch: 5| Step: 6
Training loss: 0.26422226998789083
Validation loss: 2.598091582832992

Epoch: 5| Step: 7
Training loss: 0.21478806554314367
Validation loss: 2.6025309914503008

Epoch: 5| Step: 8
Training loss: 0.27333716867874897
Validation loss: 2.5902199254902167

Epoch: 5| Step: 9
Training loss: 0.1958146506555766
Validation loss: 2.580331914695264

Epoch: 5| Step: 10
Training loss: 0.2127372644279346
Validation loss: 2.598867036777449

Epoch: 563| Step: 0
Training loss: 0.20257939826338633
Validation loss: 2.597389406717218

Epoch: 5| Step: 1
Training loss: 0.17420727922969492
Validation loss: 2.5791124572721356

Epoch: 5| Step: 2
Training loss: 0.24166711921622117
Validation loss: 2.5520291789580996

Epoch: 5| Step: 3
Training loss: 0.24912181481795742
Validation loss: 2.5738238012183565

Epoch: 5| Step: 4
Training loss: 0.14659286296350854
Validation loss: 2.5822733905375834

Epoch: 5| Step: 5
Training loss: 0.15822397494970286
Validation loss: 2.5744856089951016

Epoch: 5| Step: 6
Training loss: 0.12873661555004834
Validation loss: 2.5742761604696325

Epoch: 5| Step: 7
Training loss: 0.23572526442775607
Validation loss: 2.593515314583769

Epoch: 5| Step: 8
Training loss: 0.263615199461718
Validation loss: 2.604079113052465

Epoch: 5| Step: 9
Training loss: 0.19384595548330466
Validation loss: 2.5761235427953073

Epoch: 5| Step: 10
Training loss: 0.2595889415614789
Validation loss: 2.5912603158323364

Epoch: 564| Step: 0
Training loss: 0.22444368138746842
Validation loss: 2.5940122762105204

Epoch: 5| Step: 1
Training loss: 0.15287457200081675
Validation loss: 2.6258440765250546

Epoch: 5| Step: 2
Training loss: 0.1674943812516799
Validation loss: 2.612706979468676

Epoch: 5| Step: 3
Training loss: 0.15578561557671355
Validation loss: 2.614237468104234

Epoch: 5| Step: 4
Training loss: 0.15642897964734234
Validation loss: 2.5989101835444774

Epoch: 5| Step: 5
Training loss: 0.21172135024215935
Validation loss: 2.6115190832828787

Epoch: 5| Step: 6
Training loss: 0.16452413846991548
Validation loss: 2.569012542546268

Epoch: 5| Step: 7
Training loss: 0.23171320030784442
Validation loss: 2.5792294699189635

Epoch: 5| Step: 8
Training loss: 0.26646348500634076
Validation loss: 2.5735380612961585

Epoch: 5| Step: 9
Training loss: 0.19877910721764433
Validation loss: 2.585124212934151

Epoch: 5| Step: 10
Training loss: 0.17931184685389692
Validation loss: 2.5741436597383234

Epoch: 565| Step: 0
Training loss: 0.16633116523576535
Validation loss: 2.570174571248609

Epoch: 5| Step: 1
Training loss: 0.18712556725124901
Validation loss: 2.6175701000672986

Epoch: 5| Step: 2
Training loss: 0.18877601553194534
Validation loss: 2.603332636678439

Epoch: 5| Step: 3
Training loss: 0.0974993876444098
Validation loss: 2.603139252980579

Epoch: 5| Step: 4
Training loss: 0.24383567074800247
Validation loss: 2.608856332363865

Epoch: 5| Step: 5
Training loss: 0.14542095741137412
Validation loss: 2.6010031864601095

Epoch: 5| Step: 6
Training loss: 0.22971403072524085
Validation loss: 2.5847941888283454

Epoch: 5| Step: 7
Training loss: 0.1799402636010706
Validation loss: 2.6017280054689125

Epoch: 5| Step: 8
Training loss: 0.24327822383843375
Validation loss: 2.576121595277443

Epoch: 5| Step: 9
Training loss: 0.16719168185414138
Validation loss: 2.585244987485861

Epoch: 5| Step: 10
Training loss: 0.18113892497825715
Validation loss: 2.556553869646925

Epoch: 566| Step: 0
Training loss: 0.16648240943475168
Validation loss: 2.586593793979612

Epoch: 5| Step: 1
Training loss: 0.09141339188575823
Validation loss: 2.5987852788902464

Epoch: 5| Step: 2
Training loss: 0.14523210583248458
Validation loss: 2.600547709134048

Epoch: 5| Step: 3
Training loss: 0.12169026532432865
Validation loss: 2.5918210681743394

Epoch: 5| Step: 4
Training loss: 0.19139910704071592
Validation loss: 2.5912829805511666

Epoch: 5| Step: 5
Training loss: 0.1677331936123469
Validation loss: 2.5737105924011683

Epoch: 5| Step: 6
Training loss: 0.24988923003003483
Validation loss: 2.6013019193161737

Epoch: 5| Step: 7
Training loss: 0.13922314473161163
Validation loss: 2.5797034718161838

Epoch: 5| Step: 8
Training loss: 0.15394115487877502
Validation loss: 2.5677413625468404

Epoch: 5| Step: 9
Training loss: 0.24523359171586423
Validation loss: 2.6105260277124196

Epoch: 5| Step: 10
Training loss: 0.12918636924182345
Validation loss: 2.6162493005362446

Epoch: 567| Step: 0
Training loss: 0.1166496450880201
Validation loss: 2.5753895128570674

Epoch: 5| Step: 1
Training loss: 0.18242190113925133
Validation loss: 2.586348600555398

Epoch: 5| Step: 2
Training loss: 0.0937266221303417
Validation loss: 2.6023987289567665

Epoch: 5| Step: 3
Training loss: 0.20031375637642382
Validation loss: 2.578549230530666

Epoch: 5| Step: 4
Training loss: 0.19018512573979068
Validation loss: 2.5980357189395535

Epoch: 5| Step: 5
Training loss: 0.16430414659894388
Validation loss: 2.6124038109821024

Epoch: 5| Step: 6
Training loss: 0.12662588639716363
Validation loss: 2.610679961851383

Epoch: 5| Step: 7
Training loss: 0.16728823336628848
Validation loss: 2.5743389442359765

Epoch: 5| Step: 8
Training loss: 0.1443224636081324
Validation loss: 2.6012077174622177

Epoch: 5| Step: 9
Training loss: 0.13193455292686945
Validation loss: 2.6113725011541398

Epoch: 5| Step: 10
Training loss: 0.08878342380232332
Validation loss: 2.593863879976751

Epoch: 568| Step: 0
Training loss: 0.10867493394102007
Validation loss: 2.5934995013106157

Epoch: 5| Step: 1
Training loss: 0.15225862301012727
Validation loss: 2.622644141746274

Epoch: 5| Step: 2
Training loss: 0.24700637412244386
Validation loss: 2.597269378012335

Epoch: 5| Step: 3
Training loss: 0.13453621619226153
Validation loss: 2.61204046741549

Epoch: 5| Step: 4
Training loss: 0.16792420972189767
Validation loss: 2.597623543753548

Epoch: 5| Step: 5
Training loss: 0.13527184928558744
Validation loss: 2.5786416449382634

Epoch: 5| Step: 6
Training loss: 0.12731970167976142
Validation loss: 2.582641849071771

Epoch: 5| Step: 7
Training loss: 0.09662848860505487
Validation loss: 2.577640388214096

Epoch: 5| Step: 8
Training loss: 0.12595594222582435
Validation loss: 2.577165240907909

Epoch: 5| Step: 9
Training loss: 0.1547046777069181
Validation loss: 2.5608908049789125

Epoch: 5| Step: 10
Training loss: 0.18875501747599224
Validation loss: 2.571351591686357

Epoch: 569| Step: 0
Training loss: 0.0899982471593396
Validation loss: 2.610643518282381

Epoch: 5| Step: 1
Training loss: 0.25458545805413335
Validation loss: 2.5855091363380693

Epoch: 5| Step: 2
Training loss: 0.10414093911823996
Validation loss: 2.565945716450998

Epoch: 5| Step: 3
Training loss: 0.2261905412103206
Validation loss: 2.612934125975566

Epoch: 5| Step: 4
Training loss: 0.19561360990253412
Validation loss: 2.5959179314966354

Epoch: 5| Step: 5
Training loss: 0.159263898655066
Validation loss: 2.5614565323729646

Epoch: 5| Step: 6
Training loss: 0.11727970390129125
Validation loss: 2.573834550498067

Epoch: 5| Step: 7
Training loss: 0.13186955906278844
Validation loss: 2.618515727187073

Epoch: 5| Step: 8
Training loss: 0.1307183972389738
Validation loss: 2.6037152620624315

Epoch: 5| Step: 9
Training loss: 0.10958174766531302
Validation loss: 2.599911257709976

Epoch: 5| Step: 10
Training loss: 0.11237688646281899
Validation loss: 2.601333152789102

Epoch: 570| Step: 0
Training loss: 0.11375353049862037
Validation loss: 2.630383814112891

Epoch: 5| Step: 1
Training loss: 0.07714414584620699
Validation loss: 2.630779264254624

Epoch: 5| Step: 2
Training loss: 0.1281031095598972
Validation loss: 2.636542104305686

Epoch: 5| Step: 3
Training loss: 0.14255066176033088
Validation loss: 2.6157802255460556

Epoch: 5| Step: 4
Training loss: 0.17172941631203506
Validation loss: 2.630773249759868

Epoch: 5| Step: 5
Training loss: 0.17088492203811112
Validation loss: 2.6376455893470467

Epoch: 5| Step: 6
Training loss: 0.21332083987897482
Validation loss: 2.6158628929156404

Epoch: 5| Step: 7
Training loss: 0.17455584112907094
Validation loss: 2.610238242743099

Epoch: 5| Step: 8
Training loss: 0.11527548880902615
Validation loss: 2.589826981338586

Epoch: 5| Step: 9
Training loss: 0.15561373625825076
Validation loss: 2.615890428851112

Epoch: 5| Step: 10
Training loss: 0.23183905833199772
Validation loss: 2.583356026249775

Epoch: 571| Step: 0
Training loss: 0.14730245397832378
Validation loss: 2.6220419331558515

Epoch: 5| Step: 1
Training loss: 0.12614355182737036
Validation loss: 2.6041423350192163

Epoch: 5| Step: 2
Training loss: 0.15828430777229344
Validation loss: 2.5633075981182287

Epoch: 5| Step: 3
Training loss: 0.13035682000019455
Validation loss: 2.580482147660774

Epoch: 5| Step: 4
Training loss: 0.1614415592022215
Validation loss: 2.6054114856795945

Epoch: 5| Step: 5
Training loss: 0.17552038545485346
Validation loss: 2.60165895884754

Epoch: 5| Step: 6
Training loss: 0.20183673729284962
Validation loss: 2.6346993936500773

Epoch: 5| Step: 7
Training loss: 0.11429861350963441
Validation loss: 2.5904843275899316

Epoch: 5| Step: 8
Training loss: 0.09861101721742724
Validation loss: 2.6108196848170175

Epoch: 5| Step: 9
Training loss: 0.15229471346690163
Validation loss: 2.597124594136953

Epoch: 5| Step: 10
Training loss: 0.08059611206339205
Validation loss: 2.6520374382250966

Epoch: 572| Step: 0
Training loss: 0.11964321829371755
Validation loss: 2.6002155465450696

Epoch: 5| Step: 1
Training loss: 0.11185903028303695
Validation loss: 2.587714707007693

Epoch: 5| Step: 2
Training loss: 0.1232687637341956
Validation loss: 2.6053084346768243

Epoch: 5| Step: 3
Training loss: 0.16158599702940682
Validation loss: 2.6083026441367276

Epoch: 5| Step: 4
Training loss: 0.21261142656327922
Validation loss: 2.6085320493309396

Epoch: 5| Step: 5
Training loss: 0.12959982942055584
Validation loss: 2.593052057664608

Epoch: 5| Step: 6
Training loss: 0.07888309308924288
Validation loss: 2.5965858135862345

Epoch: 5| Step: 7
Training loss: 0.09294152341995675
Validation loss: 2.576028181356666

Epoch: 5| Step: 8
Training loss: 0.24088476885459328
Validation loss: 2.6024030289443143

Epoch: 5| Step: 9
Training loss: 0.1894296356269066
Validation loss: 2.6068781430624837

Epoch: 5| Step: 10
Training loss: 0.1423242280995939
Validation loss: 2.6148717414197984

Epoch: 573| Step: 0
Training loss: 0.12694115215477636
Validation loss: 2.5849442432817082

Epoch: 5| Step: 1
Training loss: 0.10160290391235213
Validation loss: 2.5404646865792864

Epoch: 5| Step: 2
Training loss: 0.09783530985463273
Validation loss: 2.566796745000047

Epoch: 5| Step: 3
Training loss: 0.19730531651999486
Validation loss: 2.5873473325441227

Epoch: 5| Step: 4
Training loss: 0.1492363739590731
Validation loss: 2.5680862911044327

Epoch: 5| Step: 5
Training loss: 0.16283775907940826
Validation loss: 2.54027304190054

Epoch: 5| Step: 6
Training loss: 0.10090970273695474
Validation loss: 2.582818474870717

Epoch: 5| Step: 7
Training loss: 0.13965503970458476
Validation loss: 2.589068107547666

Epoch: 5| Step: 8
Training loss: 0.10829387381345071
Validation loss: 2.599220473914989

Epoch: 5| Step: 9
Training loss: 0.1708685440076607
Validation loss: 2.558952224644716

Epoch: 5| Step: 10
Training loss: 0.17661584769771063
Validation loss: 2.5507906300336893

Epoch: 574| Step: 0
Training loss: 0.10214113497479105
Validation loss: 2.537870513070584

Epoch: 5| Step: 1
Training loss: 0.18326275999718036
Validation loss: 2.5778410525554136

Epoch: 5| Step: 2
Training loss: 0.15603650527850343
Validation loss: 2.558796461050744

Epoch: 5| Step: 3
Training loss: 0.18429661191668456
Validation loss: 2.573980941716662

Epoch: 5| Step: 4
Training loss: 0.10586412373410209
Validation loss: 2.577368442853393

Epoch: 5| Step: 5
Training loss: 0.08283260872803062
Validation loss: 2.565902245668912

Epoch: 5| Step: 6
Training loss: 0.10724094065171128
Validation loss: 2.555347403683438

Epoch: 5| Step: 7
Training loss: 0.18827579854457246
Validation loss: 2.578818379692115

Epoch: 5| Step: 8
Training loss: 0.15863208542323465
Validation loss: 2.571693474071066

Epoch: 5| Step: 9
Training loss: 0.1129083951077961
Validation loss: 2.6065386346177144

Epoch: 5| Step: 10
Training loss: 0.1468885314065059
Validation loss: 2.5958749730019286

Epoch: 575| Step: 0
Training loss: 0.0982415682733333
Validation loss: 2.6036728240980613

Epoch: 5| Step: 1
Training loss: 0.11284925451853241
Validation loss: 2.5950904522576956

Epoch: 5| Step: 2
Training loss: 0.14334237364280147
Validation loss: 2.6278960732329377

Epoch: 5| Step: 3
Training loss: 0.16292832233384738
Validation loss: 2.6095455851510256

Epoch: 5| Step: 4
Training loss: 0.1957207323479794
Validation loss: 2.6075242171819952

Epoch: 5| Step: 5
Training loss: 0.17519702251369532
Validation loss: 2.6391519650331254

Epoch: 5| Step: 6
Training loss: 0.08321108052452116
Validation loss: 2.625272556029002

Epoch: 5| Step: 7
Training loss: 0.1027831759418805
Validation loss: 2.634632443494203

Epoch: 5| Step: 8
Training loss: 0.13149291022709914
Validation loss: 2.6219785688503148

Epoch: 5| Step: 9
Training loss: 0.14802418436780185
Validation loss: 2.627440551033447

Epoch: 5| Step: 10
Training loss: 0.20119229925972323
Validation loss: 2.6200299400610936

Epoch: 576| Step: 0
Training loss: 0.15459062283308167
Validation loss: 2.622172009634344

Epoch: 5| Step: 1
Training loss: 0.19169479147355245
Validation loss: 2.6094722590902752

Epoch: 5| Step: 2
Training loss: 0.11796125631341739
Validation loss: 2.581248634737474

Epoch: 5| Step: 3
Training loss: 0.18249870985698616
Validation loss: 2.589214857804896

Epoch: 5| Step: 4
Training loss: 0.2096059592896786
Validation loss: 2.60664340237356

Epoch: 5| Step: 5
Training loss: 0.1910896602451862
Validation loss: 2.588610290527542

Epoch: 5| Step: 6
Training loss: 0.11473347208934599
Validation loss: 2.611615256845405

Epoch: 5| Step: 7
Training loss: 0.08482682670942515
Validation loss: 2.5995498356654823

Epoch: 5| Step: 8
Training loss: 0.15022616869353933
Validation loss: 2.622687391466914

Epoch: 5| Step: 9
Training loss: 0.06812885107302057
Validation loss: 2.6047909365342314

Epoch: 5| Step: 10
Training loss: 0.13039168720258407
Validation loss: 2.6165248834657966

Epoch: 577| Step: 0
Training loss: 0.19146682792708694
Validation loss: 2.600717571113787

Epoch: 5| Step: 1
Training loss: 0.10045428131833573
Validation loss: 2.595407208833707

Epoch: 5| Step: 2
Training loss: 0.12019924524349171
Validation loss: 2.559035399406265

Epoch: 5| Step: 3
Training loss: 0.17058269215495758
Validation loss: 2.5503473789608906

Epoch: 5| Step: 4
Training loss: 0.15674961203621426
Validation loss: 2.5989389407529533

Epoch: 5| Step: 5
Training loss: 0.156355005981468
Validation loss: 2.5898817582339593

Epoch: 5| Step: 6
Training loss: 0.12003880168391158
Validation loss: 2.5660456566424

Epoch: 5| Step: 7
Training loss: 0.09141824635417602
Validation loss: 2.58235779270617

Epoch: 5| Step: 8
Training loss: 0.1581904382681489
Validation loss: 2.6019802712080535

Epoch: 5| Step: 9
Training loss: 0.1760878379408144
Validation loss: 2.577833279599282

Epoch: 5| Step: 10
Training loss: 0.14047227619569821
Validation loss: 2.5894456659321516

Epoch: 578| Step: 0
Training loss: 0.10942860124383448
Validation loss: 2.582380382677115

Epoch: 5| Step: 1
Training loss: 0.24614519005501842
Validation loss: 2.6280233338957206

Epoch: 5| Step: 2
Training loss: 0.18509101080489804
Validation loss: 2.5925203549969242

Epoch: 5| Step: 3
Training loss: 0.09071405408993813
Validation loss: 2.619888154818898

Epoch: 5| Step: 4
Training loss: 0.09097715391537638
Validation loss: 2.6063661411876033

Epoch: 5| Step: 5
Training loss: 0.11067786122964984
Validation loss: 2.5923249700858833

Epoch: 5| Step: 6
Training loss: 0.10998743459610935
Validation loss: 2.5921161366973258

Epoch: 5| Step: 7
Training loss: 0.09567465650685203
Validation loss: 2.5996643037428284

Epoch: 5| Step: 8
Training loss: 0.10431415775420602
Validation loss: 2.6009495086989416

Epoch: 5| Step: 9
Training loss: 0.1290210588301188
Validation loss: 2.593769457403472

Epoch: 5| Step: 10
Training loss: 0.09049227651581647
Validation loss: 2.60449270524962

Epoch: 579| Step: 0
Training loss: 0.12218038936447301
Validation loss: 2.5934998774299056

Epoch: 5| Step: 1
Training loss: 0.09114572718023749
Validation loss: 2.588627627607149

Epoch: 5| Step: 2
Training loss: 0.09823209263258802
Validation loss: 2.584680981445059

Epoch: 5| Step: 3
Training loss: 0.1184104919212385
Validation loss: 2.585625550527521

Epoch: 5| Step: 4
Training loss: 0.1787136577961987
Validation loss: 2.621538307585134

Epoch: 5| Step: 5
Training loss: 0.12220704622346318
Validation loss: 2.5960626982360755

Epoch: 5| Step: 6
Training loss: 0.13440092468798664
Validation loss: 2.584632383835396

Epoch: 5| Step: 7
Training loss: 0.09326866882950548
Validation loss: 2.5978648102391224

Epoch: 5| Step: 8
Training loss: 0.1317186540329517
Validation loss: 2.5986410875372847

Epoch: 5| Step: 9
Training loss: 0.13790053772349495
Validation loss: 2.619823302881592

Epoch: 5| Step: 10
Training loss: 0.23197405813496472
Validation loss: 2.5952737965006603

Epoch: 580| Step: 0
Training loss: 0.10956642735575002
Validation loss: 2.6013181582065568

Epoch: 5| Step: 1
Training loss: 0.16062491160883866
Validation loss: 2.64823741582351

Epoch: 5| Step: 2
Training loss: 0.1772349750825102
Validation loss: 2.619154443800971

Epoch: 5| Step: 3
Training loss: 0.16398141764699736
Validation loss: 2.6231677130200604

Epoch: 5| Step: 4
Training loss: 0.1636036974406617
Validation loss: 2.5880923806143237

Epoch: 5| Step: 5
Training loss: 0.1681880960336966
Validation loss: 2.6123513714024336

Epoch: 5| Step: 6
Training loss: 0.11318199149998016
Validation loss: 2.594198001185474

Epoch: 5| Step: 7
Training loss: 0.1085157447001358
Validation loss: 2.6145924906825018

Epoch: 5| Step: 8
Training loss: 0.1926680449737045
Validation loss: 2.6437227258841696

Epoch: 5| Step: 9
Training loss: 0.13287586916274113
Validation loss: 2.597132488022002

Epoch: 5| Step: 10
Training loss: 0.08209953701505697
Validation loss: 2.622494477966414

Epoch: 581| Step: 0
Training loss: 0.21903726754866573
Validation loss: 2.605998990806736

Epoch: 5| Step: 1
Training loss: 0.1067470290428901
Validation loss: 2.6140816682851575

Epoch: 5| Step: 2
Training loss: 0.11991298189023632
Validation loss: 2.6141319230034976

Epoch: 5| Step: 3
Training loss: 0.08076231286269722
Validation loss: 2.6144277299748335

Epoch: 5| Step: 4
Training loss: 0.17784957505926888
Validation loss: 2.5987693906509874

Epoch: 5| Step: 5
Training loss: 0.22650413748033724
Validation loss: 2.6155133680329063

Epoch: 5| Step: 6
Training loss: 0.13669267814545297
Validation loss: 2.6079533770393946

Epoch: 5| Step: 7
Training loss: 0.18408189970866798
Validation loss: 2.620480424714901

Epoch: 5| Step: 8
Training loss: 0.23749856132774289
Validation loss: 2.619044047967026

Epoch: 5| Step: 9
Training loss: 0.16261150541694153
Validation loss: 2.596945081484131

Epoch: 5| Step: 10
Training loss: 0.19733500440885804
Validation loss: 2.6138675845607997

Epoch: 582| Step: 0
Training loss: 0.12614474787377652
Validation loss: 2.5872952000972744

Epoch: 5| Step: 1
Training loss: 0.17471040815199768
Validation loss: 2.580671142119197

Epoch: 5| Step: 2
Training loss: 0.13434297518252725
Validation loss: 2.622428534980299

Epoch: 5| Step: 3
Training loss: 0.2315944561291905
Validation loss: 2.607794378413269

Epoch: 5| Step: 4
Training loss: 0.17910387792723376
Validation loss: 2.6363752370289744

Epoch: 5| Step: 5
Training loss: 0.19539129575105563
Validation loss: 2.5833543173909925

Epoch: 5| Step: 6
Training loss: 0.12042889816564979
Validation loss: 2.6186328397020926

Epoch: 5| Step: 7
Training loss: 0.12959522302267362
Validation loss: 2.626046814336496

Epoch: 5| Step: 8
Training loss: 0.22097588453885095
Validation loss: 2.613091622800496

Epoch: 5| Step: 9
Training loss: 0.14788360525641514
Validation loss: 2.6080286999697404

Epoch: 5| Step: 10
Training loss: 0.12316134970980634
Validation loss: 2.6060376477960845

Epoch: 583| Step: 0
Training loss: 0.13337983941474998
Validation loss: 2.6002433655069708

Epoch: 5| Step: 1
Training loss: 0.1620148877459938
Validation loss: 2.5897003279133273

Epoch: 5| Step: 2
Training loss: 0.17394446647981424
Validation loss: 2.5763491563079275

Epoch: 5| Step: 3
Training loss: 0.1368757164296252
Validation loss: 2.5777758349765043

Epoch: 5| Step: 4
Training loss: 0.20028071558990104
Validation loss: 2.5776336164350746

Epoch: 5| Step: 5
Training loss: 0.164016427655476
Validation loss: 2.601452680617214

Epoch: 5| Step: 6
Training loss: 0.12116297158513828
Validation loss: 2.5890121063836085

Epoch: 5| Step: 7
Training loss: 0.11415740026927777
Validation loss: 2.5679691216125913

Epoch: 5| Step: 8
Training loss: 0.1742072418072706
Validation loss: 2.5358383156383004

Epoch: 5| Step: 9
Training loss: 0.12282641658363992
Validation loss: 2.5566109051778763

Epoch: 5| Step: 10
Training loss: 0.21473313865425062
Validation loss: 2.5587438581142194

Epoch: 584| Step: 0
Training loss: 0.10799592264826711
Validation loss: 2.5603293953243504

Epoch: 5| Step: 1
Training loss: 0.1234130859375
Validation loss: 2.53166161050043

Epoch: 5| Step: 2
Training loss: 0.12212902564453654
Validation loss: 2.5392423125933075

Epoch: 5| Step: 3
Training loss: 0.14487132452958923
Validation loss: 2.5467739853969946

Epoch: 5| Step: 4
Training loss: 0.11482447118548102
Validation loss: 2.5405847108186195

Epoch: 5| Step: 5
Training loss: 0.16037210014676972
Validation loss: 2.561870590693822

Epoch: 5| Step: 6
Training loss: 0.22971109541541274
Validation loss: 2.571393774959833

Epoch: 5| Step: 7
Training loss: 0.12465508005463909
Validation loss: 2.584538067387754

Epoch: 5| Step: 8
Training loss: 0.18899870970704385
Validation loss: 2.55397069796492

Epoch: 5| Step: 9
Training loss: 0.11504082670300064
Validation loss: 2.5848375328145656

Epoch: 5| Step: 10
Training loss: 0.1973532680291146
Validation loss: 2.5720221196730555

Epoch: 585| Step: 0
Training loss: 0.19054569721053427
Validation loss: 2.579798618893685

Epoch: 5| Step: 1
Training loss: 0.10526881871326806
Validation loss: 2.5844092988066403

Epoch: 5| Step: 2
Training loss: 0.15529706763153764
Validation loss: 2.5980643526159404

Epoch: 5| Step: 3
Training loss: 0.0823360412000493
Validation loss: 2.5723448093729937

Epoch: 5| Step: 4
Training loss: 0.12234307904016856
Validation loss: 2.596904178531129

Epoch: 5| Step: 5
Training loss: 0.08680469618477879
Validation loss: 2.5916883852379407

Epoch: 5| Step: 6
Training loss: 0.16796939871906716
Validation loss: 2.567774350567896

Epoch: 5| Step: 7
Training loss: 0.11956875125547427
Validation loss: 2.6009262702841807

Epoch: 5| Step: 8
Training loss: 0.14561010132039573
Validation loss: 2.58686987922703

Epoch: 5| Step: 9
Training loss: 0.2304964210579948
Validation loss: 2.578112977149949

Epoch: 5| Step: 10
Training loss: 0.11116739432258438
Validation loss: 2.5896087056268176

Epoch: 586| Step: 0
Training loss: 0.11794913267766367
Validation loss: 2.609418137087992

Epoch: 5| Step: 1
Training loss: 0.1262621414960661
Validation loss: 2.6066178252787413

Epoch: 5| Step: 2
Training loss: 0.1800758270646644
Validation loss: 2.6071704838716236

Epoch: 5| Step: 3
Training loss: 0.15233291685272118
Validation loss: 2.606099702791067

Epoch: 5| Step: 4
Training loss: 0.08811054266710451
Validation loss: 2.6153256720053233

Epoch: 5| Step: 5
Training loss: 0.11256933542627477
Validation loss: 2.6029915834076127

Epoch: 5| Step: 6
Training loss: 0.1389889517250892
Validation loss: 2.6065673922482535

Epoch: 5| Step: 7
Training loss: 0.12758945036386218
Validation loss: 2.619512397088049

Epoch: 5| Step: 8
Training loss: 0.10635141290732475
Validation loss: 2.56950139458654

Epoch: 5| Step: 9
Training loss: 0.15922486067960623
Validation loss: 2.5794812097940585

Epoch: 5| Step: 10
Training loss: 0.19290932385090384
Validation loss: 2.5882004030315984

Epoch: 587| Step: 0
Training loss: 0.13142613190235533
Validation loss: 2.5879959703528086

Epoch: 5| Step: 1
Training loss: 0.12031151009437259
Validation loss: 2.57664648116284

Epoch: 5| Step: 2
Training loss: 0.1299464636271037
Validation loss: 2.579893297410461

Epoch: 5| Step: 3
Training loss: 0.12438143477495402
Validation loss: 2.598832838460622

Epoch: 5| Step: 4
Training loss: 0.11826796731734723
Validation loss: 2.5710152766995544

Epoch: 5| Step: 5
Training loss: 0.19507020226134425
Validation loss: 2.600850455810203

Epoch: 5| Step: 6
Training loss: 0.14357673060576265
Validation loss: 2.597713826895552

Epoch: 5| Step: 7
Training loss: 0.1208965711187652
Validation loss: 2.631057495615642

Epoch: 5| Step: 8
Training loss: 0.21462385889037708
Validation loss: 2.6058840419984106

Epoch: 5| Step: 9
Training loss: 0.13147137002440165
Validation loss: 2.6215816601375654

Epoch: 5| Step: 10
Training loss: 0.10472804483590419
Validation loss: 2.593411078155139

Epoch: 588| Step: 0
Training loss: 0.09345396309881637
Validation loss: 2.616918835527824

Epoch: 5| Step: 1
Training loss: 0.15653780418819707
Validation loss: 2.6146671125024192

Epoch: 5| Step: 2
Training loss: 0.10383328694069031
Validation loss: 2.625225358265583

Epoch: 5| Step: 3
Training loss: 0.09191667571691732
Validation loss: 2.6024310786772915

Epoch: 5| Step: 4
Training loss: 0.06943821415503891
Validation loss: 2.6044854626514797

Epoch: 5| Step: 5
Training loss: 0.1616889718876786
Validation loss: 2.6035714284235283

Epoch: 5| Step: 6
Training loss: 0.13529798842841054
Validation loss: 2.6394678939666467

Epoch: 5| Step: 7
Training loss: 0.21477360013639465
Validation loss: 2.619020269733488

Epoch: 5| Step: 8
Training loss: 0.12490625889825586
Validation loss: 2.6134647463333023

Epoch: 5| Step: 9
Training loss: 0.11683733599714427
Validation loss: 2.623815164603021

Epoch: 5| Step: 10
Training loss: 0.12978593181668283
Validation loss: 2.627463776918403

Epoch: 589| Step: 0
Training loss: 0.11512774852335868
Validation loss: 2.6130061608817328

Epoch: 5| Step: 1
Training loss: 0.11875957776645997
Validation loss: 2.6288354377721803

Epoch: 5| Step: 2
Training loss: 0.1455406049605395
Validation loss: 2.6160600986802245

Epoch: 5| Step: 3
Training loss: 0.11350088367716828
Validation loss: 2.578409084206874

Epoch: 5| Step: 4
Training loss: 0.12730023541644114
Validation loss: 2.580238317874229

Epoch: 5| Step: 5
Training loss: 0.10705151000711804
Validation loss: 2.5826459665505

Epoch: 5| Step: 6
Training loss: 0.07490903061085041
Validation loss: 2.595719280893409

Epoch: 5| Step: 7
Training loss: 0.10021637644959017
Validation loss: 2.595308534626164

Epoch: 5| Step: 8
Training loss: 0.2334937854558618
Validation loss: 2.593414524630405

Epoch: 5| Step: 9
Training loss: 0.1492897089661171
Validation loss: 2.5654456513098562

Epoch: 5| Step: 10
Training loss: 0.12452664753295564
Validation loss: 2.586104571477892

Epoch: 590| Step: 0
Training loss: 0.08563592132387102
Validation loss: 2.5917619701196086

Epoch: 5| Step: 1
Training loss: 0.08441448137866961
Validation loss: 2.58034829847188

Epoch: 5| Step: 2
Training loss: 0.11815117931280876
Validation loss: 2.579435800970171

Epoch: 5| Step: 3
Training loss: 0.16847377638588296
Validation loss: 2.567857054378991

Epoch: 5| Step: 4
Training loss: 0.12639007420065557
Validation loss: 2.5723945410397078

Epoch: 5| Step: 5
Training loss: 0.10368979843856169
Validation loss: 2.570689776378926

Epoch: 5| Step: 6
Training loss: 0.13148285951607985
Validation loss: 2.5542187571318107

Epoch: 5| Step: 7
Training loss: 0.1189466484195247
Validation loss: 2.5721504798031165

Epoch: 5| Step: 8
Training loss: 0.17786061341605985
Validation loss: 2.5668241471187283

Epoch: 5| Step: 9
Training loss: 0.17209243026069426
Validation loss: 2.574120472380156

Epoch: 5| Step: 10
Training loss: 0.0896926158100603
Validation loss: 2.58420640100097

Epoch: 591| Step: 0
Training loss: 0.16025457620335398
Validation loss: 2.5751416398480935

Epoch: 5| Step: 1
Training loss: 0.12126318936653868
Validation loss: 2.569148828347558

Epoch: 5| Step: 2
Training loss: 0.10239830346716085
Validation loss: 2.587314849716068

Epoch: 5| Step: 3
Training loss: 0.16595384906969646
Validation loss: 2.5775777833279117

Epoch: 5| Step: 4
Training loss: 0.1707585061626392
Validation loss: 2.594987569323916

Epoch: 5| Step: 5
Training loss: 0.08342634600654353
Validation loss: 2.5598825557372202

Epoch: 5| Step: 6
Training loss: 0.11512603354274861
Validation loss: 2.57299703793249

Epoch: 5| Step: 7
Training loss: 0.06274648209295934
Validation loss: 2.576063848763164

Epoch: 5| Step: 8
Training loss: 0.11516818877539002
Validation loss: 2.5774333982069537

Epoch: 5| Step: 9
Training loss: 0.09167844153046395
Validation loss: 2.5696261882573723

Epoch: 5| Step: 10
Training loss: 0.13284901509679023
Validation loss: 2.555565718624219

Epoch: 592| Step: 0
Training loss: 0.10175542663881694
Validation loss: 2.566434363517437

Epoch: 5| Step: 1
Training loss: 0.13709877875265497
Validation loss: 2.5564285892686693

Epoch: 5| Step: 2
Training loss: 0.22684877494956704
Validation loss: 2.572120853973021

Epoch: 5| Step: 3
Training loss: 0.10179334777845785
Validation loss: 2.552262378076772

Epoch: 5| Step: 4
Training loss: 0.06334600593899828
Validation loss: 2.5673628176088084

Epoch: 5| Step: 5
Training loss: 0.09142127708255181
Validation loss: 2.579003765930894

Epoch: 5| Step: 6
Training loss: 0.06470997163774135
Validation loss: 2.5497846236369788

Epoch: 5| Step: 7
Training loss: 0.1651959097168835
Validation loss: 2.566828412818063

Epoch: 5| Step: 8
Training loss: 0.11208880863884943
Validation loss: 2.574541059821679

Epoch: 5| Step: 9
Training loss: 0.17547893488666866
Validation loss: 2.5821233893702824

Epoch: 5| Step: 10
Training loss: 0.131928192638016
Validation loss: 2.5936424805364635

Epoch: 593| Step: 0
Training loss: 0.12167448718499028
Validation loss: 2.599996910456233

Epoch: 5| Step: 1
Training loss: 0.14410192285349444
Validation loss: 2.5921616804183336

Epoch: 5| Step: 2
Training loss: 0.11180938465443872
Validation loss: 2.5678056883460934

Epoch: 5| Step: 3
Training loss: 0.08295943589561947
Validation loss: 2.5728937273986157

Epoch: 5| Step: 4
Training loss: 0.10987583512530229
Validation loss: 2.5850377098794186

Epoch: 5| Step: 5
Training loss: 0.09683449709868541
Validation loss: 2.6121635782094894

Epoch: 5| Step: 6
Training loss: 0.11669211984534393
Validation loss: 2.6086794322998603

Epoch: 5| Step: 7
Training loss: 0.0831122302611798
Validation loss: 2.6151583195027084

Epoch: 5| Step: 8
Training loss: 0.1599792223157495
Validation loss: 2.5866278785818326

Epoch: 5| Step: 9
Training loss: 0.2213140067900562
Validation loss: 2.5700451767700923

Epoch: 5| Step: 10
Training loss: 0.11999482225632149
Validation loss: 2.5776258555342326

Epoch: 594| Step: 0
Training loss: 0.09584980059549746
Validation loss: 2.6039659407176594

Epoch: 5| Step: 1
Training loss: 0.09438404116522732
Validation loss: 2.6110162709761537

Epoch: 5| Step: 2
Training loss: 0.11258418092713317
Validation loss: 2.5777968450467434

Epoch: 5| Step: 3
Training loss: 0.10402675610476195
Validation loss: 2.564861812899462

Epoch: 5| Step: 4
Training loss: 0.0878285294628484
Validation loss: 2.5657098616689917

Epoch: 5| Step: 5
Training loss: 0.07898903719785218
Validation loss: 2.599539514218365

Epoch: 5| Step: 6
Training loss: 0.11014441653195381
Validation loss: 2.572802291293474

Epoch: 5| Step: 7
Training loss: 0.21185301855159247
Validation loss: 2.5779586902423617

Epoch: 5| Step: 8
Training loss: 0.11203922742109701
Validation loss: 2.584838179467775

Epoch: 5| Step: 9
Training loss: 0.1751484979535572
Validation loss: 2.5777395398408327

Epoch: 5| Step: 10
Training loss: 0.12956133473539816
Validation loss: 2.556179031063669

Epoch: 595| Step: 0
Training loss: 0.08338641609368921
Validation loss: 2.6034635917988593

Epoch: 5| Step: 1
Training loss: 0.14279081862412746
Validation loss: 2.591318357852834

Epoch: 5| Step: 2
Training loss: 0.08141345743610276
Validation loss: 2.57921973608938

Epoch: 5| Step: 3
Training loss: 0.2042822061235923
Validation loss: 2.5800558457527343

Epoch: 5| Step: 4
Training loss: 0.10351980848675782
Validation loss: 2.562227936515122

Epoch: 5| Step: 5
Training loss: 0.08332230512343969
Validation loss: 2.5864714296295577

Epoch: 5| Step: 6
Training loss: 0.09897891309552855
Validation loss: 2.582074952620978

Epoch: 5| Step: 7
Training loss: 0.11614245312166877
Validation loss: 2.584601668159239

Epoch: 5| Step: 8
Training loss: 0.19101276629596445
Validation loss: 2.5899815241010984

Epoch: 5| Step: 9
Training loss: 0.10145327306572423
Validation loss: 2.5776058108042523

Epoch: 5| Step: 10
Training loss: 0.11617670436536122
Validation loss: 2.571563407333702

Epoch: 596| Step: 0
Training loss: 0.12983348454683694
Validation loss: 2.5682293210836122

Epoch: 5| Step: 1
Training loss: 0.10342786325557078
Validation loss: 2.5754100934558832

Epoch: 5| Step: 2
Training loss: 0.16467882376007775
Validation loss: 2.5553777592021

Epoch: 5| Step: 3
Training loss: 0.21092260272791177
Validation loss: 2.587051411429772

Epoch: 5| Step: 4
Training loss: 0.09607320872235582
Validation loss: 2.573436403749051

Epoch: 5| Step: 5
Training loss: 0.09049476708153406
Validation loss: 2.601413791412918

Epoch: 5| Step: 6
Training loss: 0.08990829160524899
Validation loss: 2.577729000779407

Epoch: 5| Step: 7
Training loss: 0.09875551466391944
Validation loss: 2.5826531473065213

Epoch: 5| Step: 8
Training loss: 0.09784732245968883
Validation loss: 2.565508241477127

Epoch: 5| Step: 9
Training loss: 0.09466555685784417
Validation loss: 2.586661590576847

Epoch: 5| Step: 10
Training loss: 0.13117221190390566
Validation loss: 2.5995909519158635

Epoch: 597| Step: 0
Training loss: 0.08430144428423554
Validation loss: 2.5891225598838283

Epoch: 5| Step: 1
Training loss: 0.12296759609713458
Validation loss: 2.5966659682705737

Epoch: 5| Step: 2
Training loss: 0.0689470101814793
Validation loss: 2.6238309764147507

Epoch: 5| Step: 3
Training loss: 0.1834397684798597
Validation loss: 2.6069062233165035

Epoch: 5| Step: 4
Training loss: 0.08886219890971145
Validation loss: 2.6180264960675363

Epoch: 5| Step: 5
Training loss: 0.1684096836501708
Validation loss: 2.5948861069480165

Epoch: 5| Step: 6
Training loss: 0.10885135863376835
Validation loss: 2.5984833521880084

Epoch: 5| Step: 7
Training loss: 0.15611157842437856
Validation loss: 2.6036836007933615

Epoch: 5| Step: 8
Training loss: 0.09897242046357775
Validation loss: 2.6332191797558226

Epoch: 5| Step: 9
Training loss: 0.11606925052522371
Validation loss: 2.613735423459744

Epoch: 5| Step: 10
Training loss: 0.10787072475355733
Validation loss: 2.5900964942283133

Epoch: 598| Step: 0
Training loss: 0.155950252789335
Validation loss: 2.579948544565865

Epoch: 5| Step: 1
Training loss: 0.19486711264119724
Validation loss: 2.5942391770581654

Epoch: 5| Step: 2
Training loss: 0.1115962697590952
Validation loss: 2.58236388670659

Epoch: 5| Step: 3
Training loss: 0.1174400271079859
Validation loss: 2.6099802628926265

Epoch: 5| Step: 4
Training loss: 0.09323422291255647
Validation loss: 2.6310618072281917

Epoch: 5| Step: 5
Training loss: 0.10621186125880765
Validation loss: 2.5843124758639644

Epoch: 5| Step: 6
Training loss: 0.06701538557328697
Validation loss: 2.5940332516273923

Epoch: 5| Step: 7
Training loss: 0.11080856974350653
Validation loss: 2.5751821955861582

Epoch: 5| Step: 8
Training loss: 0.18977386813205
Validation loss: 2.6095161500515314

Epoch: 5| Step: 9
Training loss: 0.07929511291444061
Validation loss: 2.5918560879851666

Epoch: 5| Step: 10
Training loss: 0.10064898986830652
Validation loss: 2.5509787782043527

Epoch: 599| Step: 0
Training loss: 0.17140107488687423
Validation loss: 2.5857918402152387

Epoch: 5| Step: 1
Training loss: 0.08530237386678625
Validation loss: 2.591281125551945

Epoch: 5| Step: 2
Training loss: 0.09094057017318442
Validation loss: 2.5720159612996465

Epoch: 5| Step: 3
Training loss: 0.18034344653862722
Validation loss: 2.5692358219586224

Epoch: 5| Step: 4
Training loss: 0.09462580779113808
Validation loss: 2.5684514458773386

Epoch: 5| Step: 5
Training loss: 0.12171518166322311
Validation loss: 2.5483141638539015

Epoch: 5| Step: 6
Training loss: 0.16225566353156146
Validation loss: 2.588993568281809

Epoch: 5| Step: 7
Training loss: 0.09084846203901786
Validation loss: 2.5959149500327654

Epoch: 5| Step: 8
Training loss: 0.13325874308518212
Validation loss: 2.5757126615363743

Epoch: 5| Step: 9
Training loss: 0.14622224878640563
Validation loss: 2.6121018429514598

Epoch: 5| Step: 10
Training loss: 0.10849396903552497
Validation loss: 2.588172237701731

Epoch: 600| Step: 0
Training loss: 0.07578019468319895
Validation loss: 2.5635694302614715

Epoch: 5| Step: 1
Training loss: 0.08359444553317623
Validation loss: 2.581822974630499

Epoch: 5| Step: 2
Training loss: 0.20566527464999396
Validation loss: 2.574652079370291

Epoch: 5| Step: 3
Training loss: 0.09826473921438607
Validation loss: 2.5852723725596785

Epoch: 5| Step: 4
Training loss: 0.1039183941176287
Validation loss: 2.561855003884653

Epoch: 5| Step: 5
Training loss: 0.13468750472411747
Validation loss: 2.540985052000461

Epoch: 5| Step: 6
Training loss: 0.1043270535330479
Validation loss: 2.571156919831965

Epoch: 5| Step: 7
Training loss: 0.10089871469652333
Validation loss: 2.586629077085006

Epoch: 5| Step: 8
Training loss: 0.13749205690979532
Validation loss: 2.574498131988474

Epoch: 5| Step: 9
Training loss: 0.16736557692610363
Validation loss: 2.5402409713770058

Epoch: 5| Step: 10
Training loss: 0.17268233986765047
Validation loss: 2.560223849827398

Epoch: 601| Step: 0
Training loss: 0.11780482059083928
Validation loss: 2.6147630276220744

Epoch: 5| Step: 1
Training loss: 0.10029323358695806
Validation loss: 2.5880875031306303

Epoch: 5| Step: 2
Training loss: 0.18183040958774538
Validation loss: 2.6151607633903575

Epoch: 5| Step: 3
Training loss: 0.2251013881680159
Validation loss: 2.6032418309848038

Epoch: 5| Step: 4
Training loss: 0.18994440699072682
Validation loss: 2.6188568027277825

Epoch: 5| Step: 5
Training loss: 0.17156917282843928
Validation loss: 2.624522633076987

Epoch: 5| Step: 6
Training loss: 0.12558261872885404
Validation loss: 2.6102599206268318

Epoch: 5| Step: 7
Training loss: 0.09717014444493664
Validation loss: 2.631306931974847

Epoch: 5| Step: 8
Training loss: 0.205653781398419
Validation loss: 2.63713451174855

Epoch: 5| Step: 9
Training loss: 0.16461009645960234
Validation loss: 2.637348971688697

Epoch: 5| Step: 10
Training loss: 0.16456580164241721
Validation loss: 2.64649343617326

Epoch: 602| Step: 0
Training loss: 0.13830698388085236
Validation loss: 2.6429075635355908

Epoch: 5| Step: 1
Training loss: 0.23020400989724626
Validation loss: 2.6236083672703017

Epoch: 5| Step: 2
Training loss: 0.20972420409580514
Validation loss: 2.6050883444374193

Epoch: 5| Step: 3
Training loss: 0.14718369448656407
Validation loss: 2.629386402722782

Epoch: 5| Step: 4
Training loss: 0.12374571621228325
Validation loss: 2.6268349761200214

Epoch: 5| Step: 5
Training loss: 0.08630364619013882
Validation loss: 2.6198428288910574

Epoch: 5| Step: 6
Training loss: 0.1621711165269565
Validation loss: 2.6160291351137714

Epoch: 5| Step: 7
Training loss: 0.14186455212366858
Validation loss: 2.599083153063493

Epoch: 5| Step: 8
Training loss: 0.12072481590108053
Validation loss: 2.5958335672887807

Epoch: 5| Step: 9
Training loss: 0.13553110355231193
Validation loss: 2.582561666118528

Epoch: 5| Step: 10
Training loss: 0.1455914365887996
Validation loss: 2.5412891170734078

Epoch: 603| Step: 0
Training loss: 0.12866847911029253
Validation loss: 2.562498027121452

Epoch: 5| Step: 1
Training loss: 0.18420913719741605
Validation loss: 2.547644814835864

Epoch: 5| Step: 2
Training loss: 0.16735391868199523
Validation loss: 2.5474811343270454

Epoch: 5| Step: 3
Training loss: 0.145060273429501
Validation loss: 2.5437669923429516

Epoch: 5| Step: 4
Training loss: 0.12481621553194364
Validation loss: 2.554914603064749

Epoch: 5| Step: 5
Training loss: 0.17104999906043147
Validation loss: 2.5588605493489003

Epoch: 5| Step: 6
Training loss: 0.16110261576368204
Validation loss: 2.561622935740391

Epoch: 5| Step: 7
Training loss: 0.0861675694030669
Validation loss: 2.557640399934104

Epoch: 5| Step: 8
Training loss: 0.13351640972266218
Validation loss: 2.5742827610778383

Epoch: 5| Step: 9
Training loss: 0.18871068496071294
Validation loss: 2.5552167376563095

Epoch: 5| Step: 10
Training loss: 0.10346464035141502
Validation loss: 2.586222764088986

Epoch: 604| Step: 0
Training loss: 0.1741711628503118
Validation loss: 2.5617303350187695

Epoch: 5| Step: 1
Training loss: 0.1381455089265369
Validation loss: 2.573356338431407

Epoch: 5| Step: 2
Training loss: 0.09322027214161825
Validation loss: 2.5870772840345295

Epoch: 5| Step: 3
Training loss: 0.11868239442160143
Validation loss: 2.541167727847763

Epoch: 5| Step: 4
Training loss: 0.10097536606513317
Validation loss: 2.550061195036568

Epoch: 5| Step: 5
Training loss: 0.09302765498809039
Validation loss: 2.544366710280153

Epoch: 5| Step: 6
Training loss: 0.1583752755141628
Validation loss: 2.542795841926822

Epoch: 5| Step: 7
Training loss: 0.1619776282334533
Validation loss: 2.541931855320052

Epoch: 5| Step: 8
Training loss: 0.14523090666209826
Validation loss: 2.5484090306252405

Epoch: 5| Step: 9
Training loss: 0.18404083398072543
Validation loss: 2.5619091470247897

Epoch: 5| Step: 10
Training loss: 0.08969114653388294
Validation loss: 2.5007795190164295

Epoch: 605| Step: 0
Training loss: 0.10849890048622467
Validation loss: 2.538149748784896

Epoch: 5| Step: 1
Training loss: 0.14971512027991335
Validation loss: 2.5477845438664226

Epoch: 5| Step: 2
Training loss: 0.09366833587082013
Validation loss: 2.5355073899372553

Epoch: 5| Step: 3
Training loss: 0.1207219113850137
Validation loss: 2.5596525257126594

Epoch: 5| Step: 4
Training loss: 0.09953232197206725
Validation loss: 2.554820431296466

Epoch: 5| Step: 5
Training loss: 0.12632020020737977
Validation loss: 2.5526234326275383

Epoch: 5| Step: 6
Training loss: 0.1289249897831278
Validation loss: 2.542180034879281

Epoch: 5| Step: 7
Training loss: 0.1796886091612708
Validation loss: 2.5468346779859594

Epoch: 5| Step: 8
Training loss: 0.1217454172482117
Validation loss: 2.561328178808537

Epoch: 5| Step: 9
Training loss: 0.09978521944747001
Validation loss: 2.5544003551078878

Epoch: 5| Step: 10
Training loss: 0.20680005281872416
Validation loss: 2.556953420003128

Epoch: 606| Step: 0
Training loss: 0.1277539013744657
Validation loss: 2.572143273713152

Epoch: 5| Step: 1
Training loss: 0.10579746290428638
Validation loss: 2.5644807261038554

Epoch: 5| Step: 2
Training loss: 0.1380042000110703
Validation loss: 2.5750360732673463

Epoch: 5| Step: 3
Training loss: 0.13924010138754056
Validation loss: 2.569652148015452

Epoch: 5| Step: 4
Training loss: 0.10375878277481425
Validation loss: 2.5828771333925373

Epoch: 5| Step: 5
Training loss: 0.1059322372116726
Validation loss: 2.570910117047978

Epoch: 5| Step: 6
Training loss: 0.12853627140504514
Validation loss: 2.55278944299175

Epoch: 5| Step: 7
Training loss: 0.11009755904521783
Validation loss: 2.5711517036199614

Epoch: 5| Step: 8
Training loss: 0.17423419456277597
Validation loss: 2.6060765432551523

Epoch: 5| Step: 9
Training loss: 0.10062970903437038
Validation loss: 2.577100899536398

Epoch: 5| Step: 10
Training loss: 0.18725307417766526
Validation loss: 2.5694001799760424

Epoch: 607| Step: 0
Training loss: 0.09922601755814171
Validation loss: 2.568580135154982

Epoch: 5| Step: 1
Training loss: 0.19329761713372848
Validation loss: 2.5733591408094036

Epoch: 5| Step: 2
Training loss: 0.1702913236139344
Validation loss: 2.561476239086429

Epoch: 5| Step: 3
Training loss: 0.18240402142481996
Validation loss: 2.5713683886092973

Epoch: 5| Step: 4
Training loss: 0.0990621222224087
Validation loss: 2.5670480712717714

Epoch: 5| Step: 5
Training loss: 0.0884710327003512
Validation loss: 2.600686929094251

Epoch: 5| Step: 6
Training loss: 0.11246773038424744
Validation loss: 2.5767509560128756

Epoch: 5| Step: 7
Training loss: 0.14457172394140552
Validation loss: 2.593849748536031

Epoch: 5| Step: 8
Training loss: 0.14483937076833042
Validation loss: 2.5825652764696754

Epoch: 5| Step: 9
Training loss: 0.17658095706410024
Validation loss: 2.5651797967087395

Epoch: 5| Step: 10
Training loss: 0.07891045549724114
Validation loss: 2.5545929038918356

Epoch: 608| Step: 0
Training loss: 0.1760418443754153
Validation loss: 2.5817346545098756

Epoch: 5| Step: 1
Training loss: 0.11544390395606872
Validation loss: 2.54649749943707

Epoch: 5| Step: 2
Training loss: 0.08449685020385043
Validation loss: 2.5706900017591967

Epoch: 5| Step: 3
Training loss: 0.12168710067602194
Validation loss: 2.5798551653718023

Epoch: 5| Step: 4
Training loss: 0.16917405051487366
Validation loss: 2.5786648659565206

Epoch: 5| Step: 5
Training loss: 0.1812400913818624
Validation loss: 2.569993957216202

Epoch: 5| Step: 6
Training loss: 0.1377385862813416
Validation loss: 2.5855864362846503

Epoch: 5| Step: 7
Training loss: 0.0931417932425912
Validation loss: 2.5515690496089474

Epoch: 5| Step: 8
Training loss: 0.18236931895335906
Validation loss: 2.565245547390111

Epoch: 5| Step: 9
Training loss: 0.11594217942606183
Validation loss: 2.5853151527280582

Epoch: 5| Step: 10
Training loss: 0.17314812709734226
Validation loss: 2.580385704915104

Epoch: 609| Step: 0
Training loss: 0.0909795441963985
Validation loss: 2.5821088868859787

Epoch: 5| Step: 1
Training loss: 0.12879640060220818
Validation loss: 2.5842928247448653

Epoch: 5| Step: 2
Training loss: 0.13601524004588683
Validation loss: 2.588841728642009

Epoch: 5| Step: 3
Training loss: 0.09578794496421206
Validation loss: 2.571953450258942

Epoch: 5| Step: 4
Training loss: 0.09770485145431984
Validation loss: 2.601394238435542

Epoch: 5| Step: 5
Training loss: 0.08436385076646498
Validation loss: 2.561437458551996

Epoch: 5| Step: 6
Training loss: 0.14617284709213685
Validation loss: 2.5741811438947897

Epoch: 5| Step: 7
Training loss: 0.1399046408360696
Validation loss: 2.5414367661238892

Epoch: 5| Step: 8
Training loss: 0.2102640138031297
Validation loss: 2.5502208296407347

Epoch: 5| Step: 9
Training loss: 0.0874925419702919
Validation loss: 2.5601320803757956

Epoch: 5| Step: 10
Training loss: 0.1805594889098258
Validation loss: 2.5658075419660475

Epoch: 610| Step: 0
Training loss: 0.14691557678805434
Validation loss: 2.5826739727757637

Epoch: 5| Step: 1
Training loss: 0.15415395684840133
Validation loss: 2.5852907910799274

Epoch: 5| Step: 2
Training loss: 0.14381391773163332
Validation loss: 2.585274511510538

Epoch: 5| Step: 3
Training loss: 0.08025849776456795
Validation loss: 2.593103545947136

Epoch: 5| Step: 4
Training loss: 0.17086249382231966
Validation loss: 2.589540719383303

Epoch: 5| Step: 5
Training loss: 0.13301965041843203
Validation loss: 2.600993885495683

Epoch: 5| Step: 6
Training loss: 0.1124173262923831
Validation loss: 2.616141512202874

Epoch: 5| Step: 7
Training loss: 0.12074101510739078
Validation loss: 2.5837442041230854

Epoch: 5| Step: 8
Training loss: 0.09494790536608745
Validation loss: 2.5680994043310115

Epoch: 5| Step: 9
Training loss: 0.105320154698581
Validation loss: 2.581845342888506

Epoch: 5| Step: 10
Training loss: 0.1887621223428499
Validation loss: 2.5944355161189034

Epoch: 611| Step: 0
Training loss: 0.11310303580200735
Validation loss: 2.6131420574522366

Epoch: 5| Step: 1
Training loss: 0.191503947489966
Validation loss: 2.612994068700545

Epoch: 5| Step: 2
Training loss: 0.13631299298314042
Validation loss: 2.5949346972720884

Epoch: 5| Step: 3
Training loss: 0.10432344698219645
Validation loss: 2.587827619210131

Epoch: 5| Step: 4
Training loss: 0.13937135029833886
Validation loss: 2.5599360470929526

Epoch: 5| Step: 5
Training loss: 0.17000361920809762
Validation loss: 2.578357993020446

Epoch: 5| Step: 6
Training loss: 0.1501658233345638
Validation loss: 2.5563009209325718

Epoch: 5| Step: 7
Training loss: 0.1711423767785209
Validation loss: 2.5605262259979553

Epoch: 5| Step: 8
Training loss: 0.09122159965000255
Validation loss: 2.5685035470771878

Epoch: 5| Step: 9
Training loss: 0.07945676513461529
Validation loss: 2.543387188424372

Epoch: 5| Step: 10
Training loss: 0.1818307373909505
Validation loss: 2.553526638533916

Epoch: 612| Step: 0
Training loss: 0.09170078260004344
Validation loss: 2.5436716081389465

Epoch: 5| Step: 1
Training loss: 0.1788045710846087
Validation loss: 2.533449192695417

Epoch: 5| Step: 2
Training loss: 0.1308050042687236
Validation loss: 2.526431826488422

Epoch: 5| Step: 3
Training loss: 0.07702268540278011
Validation loss: 2.542696959009296

Epoch: 5| Step: 4
Training loss: 0.15958849360943336
Validation loss: 2.537947675558911

Epoch: 5| Step: 5
Training loss: 0.12456387941933644
Validation loss: 2.535762548838459

Epoch: 5| Step: 6
Training loss: 0.11150390567535652
Validation loss: 2.5029175464525997

Epoch: 5| Step: 7
Training loss: 0.18942714788355203
Validation loss: 2.5306954444192256

Epoch: 5| Step: 8
Training loss: 0.12273388367766412
Validation loss: 2.544833302747951

Epoch: 5| Step: 9
Training loss: 0.13078014622841203
Validation loss: 2.5136097163161475

Epoch: 5| Step: 10
Training loss: 0.1753078815630443
Validation loss: 2.561461773833088

Epoch: 613| Step: 0
Training loss: 0.08856577638476071
Validation loss: 2.5326309599681154

Epoch: 5| Step: 1
Training loss: 0.1519801066844317
Validation loss: 2.553543266580453

Epoch: 5| Step: 2
Training loss: 0.09031523471044561
Validation loss: 2.5279132666485755

Epoch: 5| Step: 3
Training loss: 0.15561449633047167
Validation loss: 2.5588795454480686

Epoch: 5| Step: 4
Training loss: 0.13051965371481986
Validation loss: 2.5312789597317527

Epoch: 5| Step: 5
Training loss: 0.13339822302782905
Validation loss: 2.5736528515564285

Epoch: 5| Step: 6
Training loss: 0.09205667782389555
Validation loss: 2.60087493045746

Epoch: 5| Step: 7
Training loss: 0.09654944731321043
Validation loss: 2.6035716529266986

Epoch: 5| Step: 8
Training loss: 0.09433119151811753
Validation loss: 2.5432563060778204

Epoch: 5| Step: 9
Training loss: 0.11557482681168608
Validation loss: 2.5417690959149795

Epoch: 5| Step: 10
Training loss: 0.17681098896822417
Validation loss: 2.569036509213975

Epoch: 614| Step: 0
Training loss: 0.11918569322130768
Validation loss: 2.5738352656542607

Epoch: 5| Step: 1
Training loss: 0.10652433314574637
Validation loss: 2.5605362942094363

Epoch: 5| Step: 2
Training loss: 0.09143115299435359
Validation loss: 2.547529914340018

Epoch: 5| Step: 3
Training loss: 0.11441180456505075
Validation loss: 2.5717789257284895

Epoch: 5| Step: 4
Training loss: 0.15379339476072426
Validation loss: 2.564439382318606

Epoch: 5| Step: 5
Training loss: 0.14140859148816226
Validation loss: 2.573882230462775

Epoch: 5| Step: 6
Training loss: 0.12985488763500222
Validation loss: 2.5579252197370006

Epoch: 5| Step: 7
Training loss: 0.17089480804948995
Validation loss: 2.5507274365032555

Epoch: 5| Step: 8
Training loss: 0.10570125647963535
Validation loss: 2.5587585541427944

Epoch: 5| Step: 9
Training loss: 0.1876687542150327
Validation loss: 2.5734982725992777

Epoch: 5| Step: 10
Training loss: 0.1639892664448354
Validation loss: 2.5648205422263435

Epoch: 615| Step: 0
Training loss: 0.16261471839256347
Validation loss: 2.5599795763753814

Epoch: 5| Step: 1
Training loss: 0.061853744505689735
Validation loss: 2.601967670620786

Epoch: 5| Step: 2
Training loss: 0.13167495789205827
Validation loss: 2.556854669512139

Epoch: 5| Step: 3
Training loss: 0.13428160920737597
Validation loss: 2.5884367400211974

Epoch: 5| Step: 4
Training loss: 0.16078965029815948
Validation loss: 2.5621076043818

Epoch: 5| Step: 5
Training loss: 0.11019905067088381
Validation loss: 2.560460357131716

Epoch: 5| Step: 6
Training loss: 0.12901136418629777
Validation loss: 2.545172489646212

Epoch: 5| Step: 7
Training loss: 0.15338312065292908
Validation loss: 2.543448258668244

Epoch: 5| Step: 8
Training loss: 0.16945142954413012
Validation loss: 2.5415324162720907

Epoch: 5| Step: 9
Training loss: 0.11865850518951564
Validation loss: 2.5257563374143537

Epoch: 5| Step: 10
Training loss: 0.13696357740478227
Validation loss: 2.535791934218804

Epoch: 616| Step: 0
Training loss: 0.08701204552466002
Validation loss: 2.5508893914133997

Epoch: 5| Step: 1
Training loss: 0.14312824175840658
Validation loss: 2.531080136460578

Epoch: 5| Step: 2
Training loss: 0.13180574141946963
Validation loss: 2.5246491589594786

Epoch: 5| Step: 3
Training loss: 0.13256778330528468
Validation loss: 2.5139564183364995

Epoch: 5| Step: 4
Training loss: 0.12799567784662003
Validation loss: 2.5437999596977834

Epoch: 5| Step: 5
Training loss: 0.16936090102758933
Validation loss: 2.5574000210545655

Epoch: 5| Step: 6
Training loss: 0.11938196502708275
Validation loss: 2.563526397205052

Epoch: 5| Step: 7
Training loss: 0.13447732079310465
Validation loss: 2.533125995094255

Epoch: 5| Step: 8
Training loss: 0.15754548891837353
Validation loss: 2.544637911879121

Epoch: 5| Step: 9
Training loss: 0.13071355238851354
Validation loss: 2.5603993126773306

Epoch: 5| Step: 10
Training loss: 0.11546254602059446
Validation loss: 2.57591347704335

Epoch: 617| Step: 0
Training loss: 0.07628922409708513
Validation loss: 2.5529267702700884

Epoch: 5| Step: 1
Training loss: 0.131359971897806
Validation loss: 2.5380081554788867

Epoch: 5| Step: 2
Training loss: 0.11974448634611697
Validation loss: 2.5641907487279134

Epoch: 5| Step: 3
Training loss: 0.14381073156029622
Validation loss: 2.5342234571198237

Epoch: 5| Step: 4
Training loss: 0.14729583415210679
Validation loss: 2.5776092341536145

Epoch: 5| Step: 5
Training loss: 0.18176212144175694
Validation loss: 2.5404804147173192

Epoch: 5| Step: 6
Training loss: 0.07842943361873747
Validation loss: 2.553635626693977

Epoch: 5| Step: 7
Training loss: 0.13609880490556128
Validation loss: 2.580736007392456

Epoch: 5| Step: 8
Training loss: 0.16455676919699547
Validation loss: 2.5863027552297124

Epoch: 5| Step: 9
Training loss: 0.09095793725451878
Validation loss: 2.547724712109411

Epoch: 5| Step: 10
Training loss: 0.10625640923438934
Validation loss: 2.5651079938123025

Epoch: 618| Step: 0
Training loss: 0.10097358134755482
Validation loss: 2.556260358481199

Epoch: 5| Step: 1
Training loss: 0.12395931072878248
Validation loss: 2.5546135617152514

Epoch: 5| Step: 2
Training loss: 0.10143881841268135
Validation loss: 2.5746710117314078

Epoch: 5| Step: 3
Training loss: 0.12183243271023632
Validation loss: 2.564338496766207

Epoch: 5| Step: 4
Training loss: 0.13093115133403535
Validation loss: 2.5812517327076367

Epoch: 5| Step: 5
Training loss: 0.16208361800221088
Validation loss: 2.585986701604579

Epoch: 5| Step: 6
Training loss: 0.17884952612092392
Validation loss: 2.5738895392541608

Epoch: 5| Step: 7
Training loss: 0.14782202008500353
Validation loss: 2.5739937624727753

Epoch: 5| Step: 8
Training loss: 0.13513099511633594
Validation loss: 2.5875295738308393

Epoch: 5| Step: 9
Training loss: 0.0831917995705634
Validation loss: 2.5683855866198453

Epoch: 5| Step: 10
Training loss: 0.09793549191406976
Validation loss: 2.5756035520045755

Epoch: 619| Step: 0
Training loss: 0.10770488219140016
Validation loss: 2.560895541054581

Epoch: 5| Step: 1
Training loss: 0.14706277460687875
Validation loss: 2.5682366928781657

Epoch: 5| Step: 2
Training loss: 0.11275277515652185
Validation loss: 2.561103200001222

Epoch: 5| Step: 3
Training loss: 0.12492722389502522
Validation loss: 2.5676598591218327

Epoch: 5| Step: 4
Training loss: 0.11558755400372672
Validation loss: 2.58509427315779

Epoch: 5| Step: 5
Training loss: 0.12000862115448839
Validation loss: 2.5669817265946255

Epoch: 5| Step: 6
Training loss: 0.0863580815739655
Validation loss: 2.5616596663859204

Epoch: 5| Step: 7
Training loss: 0.07466708467894616
Validation loss: 2.59160428100853

Epoch: 5| Step: 8
Training loss: 0.14042512941987803
Validation loss: 2.5362641038926377

Epoch: 5| Step: 9
Training loss: 0.1399672210905391
Validation loss: 2.562427362652569

Epoch: 5| Step: 10
Training loss: 0.1298310528065923
Validation loss: 2.552310566499515

Epoch: 620| Step: 0
Training loss: 0.14094459456626793
Validation loss: 2.526154782488276

Epoch: 5| Step: 1
Training loss: 0.08733158870543432
Validation loss: 2.541752290485427

Epoch: 5| Step: 2
Training loss: 0.15635114019015994
Validation loss: 2.556425764319954

Epoch: 5| Step: 3
Training loss: 0.16710697935651228
Validation loss: 2.5558676107442184

Epoch: 5| Step: 4
Training loss: 0.07693925396080503
Validation loss: 2.5665380444345565

Epoch: 5| Step: 5
Training loss: 0.11854414068125388
Validation loss: 2.588820765874443

Epoch: 5| Step: 6
Training loss: 0.17009918783376343
Validation loss: 2.5773733948317097

Epoch: 5| Step: 7
Training loss: 0.11664659917904431
Validation loss: 2.594856290179299

Epoch: 5| Step: 8
Training loss: 0.07786778187747383
Validation loss: 2.569269371516652

Epoch: 5| Step: 9
Training loss: 0.13447950923303792
Validation loss: 2.594039847424049

Epoch: 5| Step: 10
Training loss: 0.0788507754002077
Validation loss: 2.6134418492339875

Epoch: 621| Step: 0
Training loss: 0.08733336161268043
Validation loss: 2.6209411063154224

Epoch: 5| Step: 1
Training loss: 0.1089567891282574
Validation loss: 2.6199554837063137

Epoch: 5| Step: 2
Training loss: 0.11435168640370819
Validation loss: 2.613960687788071

Epoch: 5| Step: 3
Training loss: 0.10132893886254023
Validation loss: 2.5943540405227123

Epoch: 5| Step: 4
Training loss: 0.16095990816611228
Validation loss: 2.6137565515200807

Epoch: 5| Step: 5
Training loss: 0.12412169836753932
Validation loss: 2.5898094681673176

Epoch: 5| Step: 6
Training loss: 0.12395910411750015
Validation loss: 2.616770678286335

Epoch: 5| Step: 7
Training loss: 0.11789161231737931
Validation loss: 2.5887134873219653

Epoch: 5| Step: 8
Training loss: 0.11087268813253935
Validation loss: 2.58217962928762

Epoch: 5| Step: 9
Training loss: 0.10953471749676545
Validation loss: 2.5818651322853405

Epoch: 5| Step: 10
Training loss: 0.19908060632280136
Validation loss: 2.60866651912973

Epoch: 622| Step: 0
Training loss: 0.07704559243429919
Validation loss: 2.5922794979658916

Epoch: 5| Step: 1
Training loss: 0.15234139024912072
Validation loss: 2.5804868775837813

Epoch: 5| Step: 2
Training loss: 0.12871435360579161
Validation loss: 2.5746254077922948

Epoch: 5| Step: 3
Training loss: 0.09797622236170432
Validation loss: 2.569234874027322

Epoch: 5| Step: 4
Training loss: 0.08642364219130509
Validation loss: 2.562154435958858

Epoch: 5| Step: 5
Training loss: 0.1862144507334196
Validation loss: 2.56928440945521

Epoch: 5| Step: 6
Training loss: 0.07476435126591852
Validation loss: 2.5621062005419333

Epoch: 5| Step: 7
Training loss: 0.060869040456218486
Validation loss: 2.5714239545111055

Epoch: 5| Step: 8
Training loss: 0.11388892756325109
Validation loss: 2.540603354925308

Epoch: 5| Step: 9
Training loss: 0.09965085119765793
Validation loss: 2.544631396073096

Epoch: 5| Step: 10
Training loss: 0.09873027046855332
Validation loss: 2.522611294267965

Epoch: 623| Step: 0
Training loss: 0.2246142013694689
Validation loss: 2.5519665937278817

Epoch: 5| Step: 1
Training loss: 0.08191283512060024
Validation loss: 2.5586728094204916

Epoch: 5| Step: 2
Training loss: 0.07233135674917113
Validation loss: 2.551116203767759

Epoch: 5| Step: 3
Training loss: 0.11251643991221583
Validation loss: 2.569290096928109

Epoch: 5| Step: 4
Training loss: 0.15067548526053157
Validation loss: 2.5522413592021156

Epoch: 5| Step: 5
Training loss: 0.11211788979204652
Validation loss: 2.5757212923797357

Epoch: 5| Step: 6
Training loss: 0.09073480046420346
Validation loss: 2.5626357112896825

Epoch: 5| Step: 7
Training loss: 0.08957828299107402
Validation loss: 2.5455193750970433

Epoch: 5| Step: 8
Training loss: 0.10480277081392263
Validation loss: 2.5731426463768847

Epoch: 5| Step: 9
Training loss: 0.09964216851852496
Validation loss: 2.545260625047595

Epoch: 5| Step: 10
Training loss: 0.08486442729759941
Validation loss: 2.570862508604831

Epoch: 624| Step: 0
Training loss: 0.09837777146000552
Validation loss: 2.558423987177318

Epoch: 5| Step: 1
Training loss: 0.16774486436103114
Validation loss: 2.536325489682504

Epoch: 5| Step: 2
Training loss: 0.08180363331595385
Validation loss: 2.543546247600072

Epoch: 5| Step: 3
Training loss: 0.06683491396162061
Validation loss: 2.5459352338928705

Epoch: 5| Step: 4
Training loss: 0.07453563138991177
Validation loss: 2.567055152849586

Epoch: 5| Step: 5
Training loss: 0.12292047093317965
Validation loss: 2.5505060307093594

Epoch: 5| Step: 6
Training loss: 0.10868227801246147
Validation loss: 2.555339555282292

Epoch: 5| Step: 7
Training loss: 0.07636455167919244
Validation loss: 2.5629844597747238

Epoch: 5| Step: 8
Training loss: 0.09994893073852515
Validation loss: 2.542995372532236

Epoch: 5| Step: 9
Training loss: 0.1018809269354067
Validation loss: 2.537600419822516

Epoch: 5| Step: 10
Training loss: 0.1758481640082932
Validation loss: 2.5585725271319673

Epoch: 625| Step: 0
Training loss: 0.05703388364798743
Validation loss: 2.575328456942416

Epoch: 5| Step: 1
Training loss: 0.13231544183993327
Validation loss: 2.5848832137052056

Epoch: 5| Step: 2
Training loss: 0.07475612934345356
Validation loss: 2.5754938356348687

Epoch: 5| Step: 3
Training loss: 0.10325950300546248
Validation loss: 2.5830464701668725

Epoch: 5| Step: 4
Training loss: 0.1442954679027081
Validation loss: 2.606032411389456

Epoch: 5| Step: 5
Training loss: 0.08874056776892357
Validation loss: 2.5864492857388663

Epoch: 5| Step: 6
Training loss: 0.1310755239827278
Validation loss: 2.59695122812529

Epoch: 5| Step: 7
Training loss: 0.109644871943564
Validation loss: 2.628085776466487

Epoch: 5| Step: 8
Training loss: 0.14866052988197218
Validation loss: 2.601922856215078

Epoch: 5| Step: 9
Training loss: 0.1251056120678095
Validation loss: 2.6166587475459

Epoch: 5| Step: 10
Training loss: 0.07072649050677002
Validation loss: 2.602428362770239

Epoch: 626| Step: 0
Training loss: 0.0739025451092437
Validation loss: 2.583387297570467

Epoch: 5| Step: 1
Training loss: 0.11821091330007842
Validation loss: 2.5918450929727967

Epoch: 5| Step: 2
Training loss: 0.10815412034823303
Validation loss: 2.5964034096581297

Epoch: 5| Step: 3
Training loss: 0.06922632942832058
Validation loss: 2.591097025855537

Epoch: 5| Step: 4
Training loss: 0.18804613684591376
Validation loss: 2.5753810132955146

Epoch: 5| Step: 5
Training loss: 0.07974843448975319
Validation loss: 2.5430144521110574

Epoch: 5| Step: 6
Training loss: 0.1530468196196989
Validation loss: 2.5749058926178723

Epoch: 5| Step: 7
Training loss: 0.09863456875587744
Validation loss: 2.56702336798686

Epoch: 5| Step: 8
Training loss: 0.1124582401891598
Validation loss: 2.5306337934044567

Epoch: 5| Step: 9
Training loss: 0.12668397689742106
Validation loss: 2.575657057768093

Epoch: 5| Step: 10
Training loss: 0.11965462544400174
Validation loss: 2.561482438312734

Epoch: 627| Step: 0
Training loss: 0.09212868155702125
Validation loss: 2.5266192037435897

Epoch: 5| Step: 1
Training loss: 0.1245113784187004
Validation loss: 2.5614773560291835

Epoch: 5| Step: 2
Training loss: 0.08474215751785279
Validation loss: 2.550652662773399

Epoch: 5| Step: 3
Training loss: 0.15229725739601402
Validation loss: 2.5651999545271176

Epoch: 5| Step: 4
Training loss: 0.13195022291850897
Validation loss: 2.567937193821098

Epoch: 5| Step: 5
Training loss: 0.11716208579734885
Validation loss: 2.571083675030541

Epoch: 5| Step: 6
Training loss: 0.0798832510957126
Validation loss: 2.6100091466357203

Epoch: 5| Step: 7
Training loss: 0.10876405760736253
Validation loss: 2.589668479458586

Epoch: 5| Step: 8
Training loss: 0.10435379079090498
Validation loss: 2.5992164497615957

Epoch: 5| Step: 9
Training loss: 0.08408191195755314
Validation loss: 2.594225005168734

Epoch: 5| Step: 10
Training loss: 0.13631219360915306
Validation loss: 2.615544431310024

Epoch: 628| Step: 0
Training loss: 0.11331932480337914
Validation loss: 2.5714401253647243

Epoch: 5| Step: 1
Training loss: 0.10503139147937647
Validation loss: 2.5940188404352593

Epoch: 5| Step: 2
Training loss: 0.159667373796107
Validation loss: 2.5808833535951843

Epoch: 5| Step: 3
Training loss: 0.1899322174124703
Validation loss: 2.5622252310228277

Epoch: 5| Step: 4
Training loss: 0.07426823986292864
Validation loss: 2.5941196172856285

Epoch: 5| Step: 5
Training loss: 0.0766375380758615
Validation loss: 2.57522588900519

Epoch: 5| Step: 6
Training loss: 0.09336822978527919
Validation loss: 2.5910714714142373

Epoch: 5| Step: 7
Training loss: 0.05125264162068013
Validation loss: 2.5997245011563423

Epoch: 5| Step: 8
Training loss: 0.07260909165166408
Validation loss: 2.601367506958822

Epoch: 5| Step: 9
Training loss: 0.0794785605051683
Validation loss: 2.5860868447473226

Epoch: 5| Step: 10
Training loss: 0.17136039966524902
Validation loss: 2.6232499101070705

Epoch: 629| Step: 0
Training loss: 0.07128421884568722
Validation loss: 2.598594719168409

Epoch: 5| Step: 1
Training loss: 0.14982546472012703
Validation loss: 2.5693565895369117

Epoch: 5| Step: 2
Training loss: 0.08479477539366165
Validation loss: 2.5403182536067335

Epoch: 5| Step: 3
Training loss: 0.09307648202926291
Validation loss: 2.5710604942267627

Epoch: 5| Step: 4
Training loss: 0.0737822079541789
Validation loss: 2.5470386268611978

Epoch: 5| Step: 5
Training loss: 0.14966502337449228
Validation loss: 2.5490822285971024

Epoch: 5| Step: 6
Training loss: 0.09687184013320048
Validation loss: 2.565624458678948

Epoch: 5| Step: 7
Training loss: 0.10817222791016605
Validation loss: 2.557764763993371

Epoch: 5| Step: 8
Training loss: 0.13721994088146341
Validation loss: 2.5463136202373167

Epoch: 5| Step: 9
Training loss: 0.10077676448894342
Validation loss: 2.541443913013635

Epoch: 5| Step: 10
Training loss: 0.13232286741122715
Validation loss: 2.562563540983717

Epoch: 630| Step: 0
Training loss: 0.0966083041521521
Validation loss: 2.5459220075127305

Epoch: 5| Step: 1
Training loss: 0.11051893201232818
Validation loss: 2.570611795114888

Epoch: 5| Step: 2
Training loss: 0.1393170392647634
Validation loss: 2.543714415723691

Epoch: 5| Step: 3
Training loss: 0.1051384424787223
Validation loss: 2.5557439879360206

Epoch: 5| Step: 4
Training loss: 0.11506851835999865
Validation loss: 2.5593994309942616

Epoch: 5| Step: 5
Training loss: 0.1285189242649664
Validation loss: 2.5593936088556917

Epoch: 5| Step: 6
Training loss: 0.07474161419728842
Validation loss: 2.575723357149081

Epoch: 5| Step: 7
Training loss: 0.09086360207332904
Validation loss: 2.5924306635627263

Epoch: 5| Step: 8
Training loss: 0.10226373492972099
Validation loss: 2.595076379854232

Epoch: 5| Step: 9
Training loss: 0.20978837129668462
Validation loss: 2.5877272561334146

Epoch: 5| Step: 10
Training loss: 0.09938823705508348
Validation loss: 2.614306769414687

Epoch: 631| Step: 0
Training loss: 0.09821393040803326
Validation loss: 2.596028635299744

Epoch: 5| Step: 1
Training loss: 0.1330409889464774
Validation loss: 2.5961187220967226

Epoch: 5| Step: 2
Training loss: 0.14255976885379087
Validation loss: 2.5687684114796014

Epoch: 5| Step: 3
Training loss: 0.13308427856101077
Validation loss: 2.5818477835558844

Epoch: 5| Step: 4
Training loss: 0.10681155395507376
Validation loss: 2.584211887482034

Epoch: 5| Step: 5
Training loss: 0.06971419275445506
Validation loss: 2.592285664075821

Epoch: 5| Step: 6
Training loss: 0.08667624007285013
Validation loss: 2.5896979193950522

Epoch: 5| Step: 7
Training loss: 0.10597761894652828
Validation loss: 2.58120291236731

Epoch: 5| Step: 8
Training loss: 0.0771928430070949
Validation loss: 2.5800187062908653

Epoch: 5| Step: 9
Training loss: 0.09734621902843138
Validation loss: 2.586368876873627

Epoch: 5| Step: 10
Training loss: 0.10428083739400554
Validation loss: 2.558318479312531

Epoch: 632| Step: 0
Training loss: 0.11141775939844703
Validation loss: 2.5729910457947196

Epoch: 5| Step: 1
Training loss: 0.07666872061737187
Validation loss: 2.5534298764650543

Epoch: 5| Step: 2
Training loss: 0.09611963121274532
Validation loss: 2.5706405592369084

Epoch: 5| Step: 3
Training loss: 0.0891444419057034
Validation loss: 2.5791714520540636

Epoch: 5| Step: 4
Training loss: 0.07972540164421985
Validation loss: 2.5709458494757746

Epoch: 5| Step: 5
Training loss: 0.12094828112795397
Validation loss: 2.5748465785719747

Epoch: 5| Step: 6
Training loss: 0.10042272214204277
Validation loss: 2.607534084261491

Epoch: 5| Step: 7
Training loss: 0.0913632785014738
Validation loss: 2.58286403067641

Epoch: 5| Step: 8
Training loss: 0.14046205908865766
Validation loss: 2.5856512317900684

Epoch: 5| Step: 9
Training loss: 0.08408669404537736
Validation loss: 2.569404986173803

Epoch: 5| Step: 10
Training loss: 0.16718574371484954
Validation loss: 2.578083210765236

Epoch: 633| Step: 0
Training loss: 0.09119175253790303
Validation loss: 2.602632393675973

Epoch: 5| Step: 1
Training loss: 0.08264927286129226
Validation loss: 2.5981834289331665

Epoch: 5| Step: 2
Training loss: 0.07643582388965477
Validation loss: 2.575345187611503

Epoch: 5| Step: 3
Training loss: 0.142176873470236
Validation loss: 2.58588556368194

Epoch: 5| Step: 4
Training loss: 0.09412410717802895
Validation loss: 2.581217945339525

Epoch: 5| Step: 5
Training loss: 0.16290857184178947
Validation loss: 2.614346658757212

Epoch: 5| Step: 6
Training loss: 0.13130602123549792
Validation loss: 2.5985640244927115

Epoch: 5| Step: 7
Training loss: 0.09770230637736174
Validation loss: 2.581162212857138

Epoch: 5| Step: 8
Training loss: 0.12576215077749742
Validation loss: 2.593445944035755

Epoch: 5| Step: 9
Training loss: 0.11127567728942496
Validation loss: 2.6068688969870335

Epoch: 5| Step: 10
Training loss: 0.06414357904561774
Validation loss: 2.577781503714397

Epoch: 634| Step: 0
Training loss: 0.0978004201995198
Validation loss: 2.5877029310635877

Epoch: 5| Step: 1
Training loss: 0.07708736005889144
Validation loss: 2.589465970470821

Epoch: 5| Step: 2
Training loss: 0.09004718098480063
Validation loss: 2.591978061640343

Epoch: 5| Step: 3
Training loss: 0.07945358571619462
Validation loss: 2.58591737991237

Epoch: 5| Step: 4
Training loss: 0.18577468339112518
Validation loss: 2.5719427608977856

Epoch: 5| Step: 5
Training loss: 0.08158568160164786
Validation loss: 2.581428214033118

Epoch: 5| Step: 6
Training loss: 0.06125080920677478
Validation loss: 2.5639341309500914

Epoch: 5| Step: 7
Training loss: 0.12705124217953295
Validation loss: 2.5756551915150068

Epoch: 5| Step: 8
Training loss: 0.08069941782676368
Validation loss: 2.5750975363259427

Epoch: 5| Step: 9
Training loss: 0.08553345751378853
Validation loss: 2.558755204762197

Epoch: 5| Step: 10
Training loss: 0.09193792565122105
Validation loss: 2.577142784280535

Epoch: 635| Step: 0
Training loss: 0.07852782764313239
Validation loss: 2.5808078662023286

Epoch: 5| Step: 1
Training loss: 0.155535345095651
Validation loss: 2.5831565619479453

Epoch: 5| Step: 2
Training loss: 0.09620495037635181
Validation loss: 2.5651428316353693

Epoch: 5| Step: 3
Training loss: 0.07592569207391665
Validation loss: 2.600050680354425

Epoch: 5| Step: 4
Training loss: 0.07796601271076717
Validation loss: 2.5999199625384875

Epoch: 5| Step: 5
Training loss: 0.16350121648325697
Validation loss: 2.6060666539338757

Epoch: 5| Step: 6
Training loss: 0.10560678791303779
Validation loss: 2.6064671438919604

Epoch: 5| Step: 7
Training loss: 0.07856527485722982
Validation loss: 2.5907367352226056

Epoch: 5| Step: 8
Training loss: 0.08504247041776779
Validation loss: 2.5990988411268785

Epoch: 5| Step: 9
Training loss: 0.0811873952449757
Validation loss: 2.5875192866697185

Epoch: 5| Step: 10
Training loss: 0.13600729022270078
Validation loss: 2.6161591225005525

Epoch: 636| Step: 0
Training loss: 0.09131126093921309
Validation loss: 2.5975694216103484

Epoch: 5| Step: 1
Training loss: 0.06677684037319243
Validation loss: 2.5958013284257766

Epoch: 5| Step: 2
Training loss: 0.10108161751761635
Validation loss: 2.6267577857193434

Epoch: 5| Step: 3
Training loss: 0.14618622637524578
Validation loss: 2.6135749638962267

Epoch: 5| Step: 4
Training loss: 0.09029495921943534
Validation loss: 2.604489785770379

Epoch: 5| Step: 5
Training loss: 0.09986734177951195
Validation loss: 2.6086489417849243

Epoch: 5| Step: 6
Training loss: 0.10479599469134927
Validation loss: 2.6005150185507713

Epoch: 5| Step: 7
Training loss: 0.14993938025789916
Validation loss: 2.5874966256423484

Epoch: 5| Step: 8
Training loss: 0.11039574337895813
Validation loss: 2.6177668418035815

Epoch: 5| Step: 9
Training loss: 0.08469782570146067
Validation loss: 2.622844844610414

Epoch: 5| Step: 10
Training loss: 0.09351402625531448
Validation loss: 2.610460361808721

Epoch: 637| Step: 0
Training loss: 0.11811402735383185
Validation loss: 2.60144544901843

Epoch: 5| Step: 1
Training loss: 0.10740516272503144
Validation loss: 2.611083508555584

Epoch: 5| Step: 2
Training loss: 0.06672703175658323
Validation loss: 2.601117001195389

Epoch: 5| Step: 3
Training loss: 0.14560115303792115
Validation loss: 2.591623832174033

Epoch: 5| Step: 4
Training loss: 0.07376333476799704
Validation loss: 2.5957781308330055

Epoch: 5| Step: 5
Training loss: 0.14839020402223405
Validation loss: 2.6093600879813175

Epoch: 5| Step: 6
Training loss: 0.08009680088259012
Validation loss: 2.578419572763645

Epoch: 5| Step: 7
Training loss: 0.11089499609654031
Validation loss: 2.598526041142398

Epoch: 5| Step: 8
Training loss: 0.11076661350182075
Validation loss: 2.5833700781467273

Epoch: 5| Step: 9
Training loss: 0.09758917889469525
Validation loss: 2.568309454399813

Epoch: 5| Step: 10
Training loss: 0.13211868483429318
Validation loss: 2.578183724538463

Epoch: 638| Step: 0
Training loss: 0.08155005818232051
Validation loss: 2.5788478351352806

Epoch: 5| Step: 1
Training loss: 0.11350673809431783
Validation loss: 2.619552734167893

Epoch: 5| Step: 2
Training loss: 0.1582393192755462
Validation loss: 2.5830247733124194

Epoch: 5| Step: 3
Training loss: 0.05734775472710098
Validation loss: 2.5790066392105797

Epoch: 5| Step: 4
Training loss: 0.1347824721932138
Validation loss: 2.6074342850343744

Epoch: 5| Step: 5
Training loss: 0.08803069027281629
Validation loss: 2.596761844382466

Epoch: 5| Step: 6
Training loss: 0.10794007417373679
Validation loss: 2.597926314430655

Epoch: 5| Step: 7
Training loss: 0.09665009016653435
Validation loss: 2.6368698824247536

Epoch: 5| Step: 8
Training loss: 0.12139315277381443
Validation loss: 2.6217193407120196

Epoch: 5| Step: 9
Training loss: 0.15366438508507785
Validation loss: 2.608648375722875

Epoch: 5| Step: 10
Training loss: 0.1955590027703389
Validation loss: 2.608168153857445

Epoch: 639| Step: 0
Training loss: 0.09775793503605984
Validation loss: 2.6220486599075197

Epoch: 5| Step: 1
Training loss: 0.07206146294450569
Validation loss: 2.585488464094174

Epoch: 5| Step: 2
Training loss: 0.1493283630633435
Validation loss: 2.592302151796038

Epoch: 5| Step: 3
Training loss: 0.0972011116667376
Validation loss: 2.6081567929090084

Epoch: 5| Step: 4
Training loss: 0.06171634305715117
Validation loss: 2.5889476108623493

Epoch: 5| Step: 5
Training loss: 0.10889607119915891
Validation loss: 2.5928021797169243

Epoch: 5| Step: 6
Training loss: 0.08826820543008161
Validation loss: 2.58112872004985

Epoch: 5| Step: 7
Training loss: 0.1728146454348532
Validation loss: 2.585431580238026

Epoch: 5| Step: 8
Training loss: 0.10808481779025182
Validation loss: 2.584223248295041

Epoch: 5| Step: 9
Training loss: 0.09875093129177608
Validation loss: 2.586724135672058

Epoch: 5| Step: 10
Training loss: 0.1317529134351328
Validation loss: 2.593390878149429

Epoch: 640| Step: 0
Training loss: 0.08326138865230734
Validation loss: 2.608148628909209

Epoch: 5| Step: 1
Training loss: 0.11433939995978816
Validation loss: 2.578085035484811

Epoch: 5| Step: 2
Training loss: 0.11855937313768689
Validation loss: 2.6107491278167543

Epoch: 5| Step: 3
Training loss: 0.17275250824081742
Validation loss: 2.5965923485969107

Epoch: 5| Step: 4
Training loss: 0.11353676851743148
Validation loss: 2.618661124807242

Epoch: 5| Step: 5
Training loss: 0.12561552669144452
Validation loss: 2.607581760527575

Epoch: 5| Step: 6
Training loss: 0.11273235492390049
Validation loss: 2.5836991242344087

Epoch: 5| Step: 7
Training loss: 0.12424701153252536
Validation loss: 2.607944223247113

Epoch: 5| Step: 8
Training loss: 0.16698815524938368
Validation loss: 2.5496594455158617

Epoch: 5| Step: 9
Training loss: 0.08427725777560874
Validation loss: 2.5626687695350756

Epoch: 5| Step: 10
Training loss: 0.08188371504107973
Validation loss: 2.5771152620863322

Epoch: 641| Step: 0
Training loss: 0.13470247419983514
Validation loss: 2.554742764407095

Epoch: 5| Step: 1
Training loss: 0.1183263436735821
Validation loss: 2.56209578328565

Epoch: 5| Step: 2
Training loss: 0.10847812163812559
Validation loss: 2.5535649418608903

Epoch: 5| Step: 3
Training loss: 0.09634402797385423
Validation loss: 2.5524056434311664

Epoch: 5| Step: 4
Training loss: 0.07783717840829549
Validation loss: 2.5436007683662702

Epoch: 5| Step: 5
Training loss: 0.09348379029077263
Validation loss: 2.5556713632051937

Epoch: 5| Step: 6
Training loss: 0.1141767173286808
Validation loss: 2.5493521301065742

Epoch: 5| Step: 7
Training loss: 0.09552624959402907
Validation loss: 2.5703320869502155

Epoch: 5| Step: 8
Training loss: 0.11677720245490592
Validation loss: 2.559267517867612

Epoch: 5| Step: 9
Training loss: 0.16640179543062425
Validation loss: 2.548766916612139

Epoch: 5| Step: 10
Training loss: 0.09397893014675261
Validation loss: 2.5653314941443064

Epoch: 642| Step: 0
Training loss: 0.14602974596316373
Validation loss: 2.573287763400372

Epoch: 5| Step: 1
Training loss: 0.08307832359737201
Validation loss: 2.597200990182508

Epoch: 5| Step: 2
Training loss: 0.10974483038478404
Validation loss: 2.596923845277315

Epoch: 5| Step: 3
Training loss: 0.08480278180800035
Validation loss: 2.5713438085846705

Epoch: 5| Step: 4
Training loss: 0.12038926579910599
Validation loss: 2.5573513591360797

Epoch: 5| Step: 5
Training loss: 0.08642488953297396
Validation loss: 2.5680559195923154

Epoch: 5| Step: 6
Training loss: 0.11135577393901229
Validation loss: 2.5670326856752057

Epoch: 5| Step: 7
Training loss: 0.10311333742084917
Validation loss: 2.5550808826490115

Epoch: 5| Step: 8
Training loss: 0.10466899352400398
Validation loss: 2.5708531818616556

Epoch: 5| Step: 9
Training loss: 0.11100314206378037
Validation loss: 2.5710743919653356

Epoch: 5| Step: 10
Training loss: 0.15008324012200983
Validation loss: 2.5913579090429404

Epoch: 643| Step: 0
Training loss: 0.08232270699829154
Validation loss: 2.547223514517447

Epoch: 5| Step: 1
Training loss: 0.07686287506169893
Validation loss: 2.5772840314705916

Epoch: 5| Step: 2
Training loss: 0.146709066361894
Validation loss: 2.571411335791006

Epoch: 5| Step: 3
Training loss: 0.07870288741450965
Validation loss: 2.5519073166125703

Epoch: 5| Step: 4
Training loss: 0.09014429223841014
Validation loss: 2.5551671502368323

Epoch: 5| Step: 5
Training loss: 0.13271645972339632
Validation loss: 2.5630246437450643

Epoch: 5| Step: 6
Training loss: 0.10983426028644606
Validation loss: 2.5816333673873184

Epoch: 5| Step: 7
Training loss: 0.05143383356793017
Validation loss: 2.5790879982679376

Epoch: 5| Step: 8
Training loss: 0.0776524617769776
Validation loss: 2.5722736240758137

Epoch: 5| Step: 9
Training loss: 0.09437284596618628
Validation loss: 2.562283250399207

Epoch: 5| Step: 10
Training loss: 0.14194795399654586
Validation loss: 2.5808419556978834

Epoch: 644| Step: 0
Training loss: 0.1444547940699869
Validation loss: 2.556733642295868

Epoch: 5| Step: 1
Training loss: 0.07252222011994598
Validation loss: 2.5741667301170787

Epoch: 5| Step: 2
Training loss: 0.13778070412819893
Validation loss: 2.602671964516855

Epoch: 5| Step: 3
Training loss: 0.1195600584008177
Validation loss: 2.5778337102153

Epoch: 5| Step: 4
Training loss: 0.09340212274234647
Validation loss: 2.590887073828181

Epoch: 5| Step: 5
Training loss: 0.10252713179434696
Validation loss: 2.5663095325128658

Epoch: 5| Step: 6
Training loss: 0.09413551993397985
Validation loss: 2.576589781185793

Epoch: 5| Step: 7
Training loss: 0.13502859636156644
Validation loss: 2.606205027241843

Epoch: 5| Step: 8
Training loss: 0.12293638082052052
Validation loss: 2.5868281014367396

Epoch: 5| Step: 9
Training loss: 0.07447276440804404
Validation loss: 2.5758303775164544

Epoch: 5| Step: 10
Training loss: 0.08389878347232982
Validation loss: 2.58170129573702

Epoch: 645| Step: 0
Training loss: 0.07456173199484324
Validation loss: 2.5875528270434667

Epoch: 5| Step: 1
Training loss: 0.10218587630553896
Validation loss: 2.563119801343502

Epoch: 5| Step: 2
Training loss: 0.09879616627732331
Validation loss: 2.5827559766397346

Epoch: 5| Step: 3
Training loss: 0.09572799515171651
Validation loss: 2.5309626913639924

Epoch: 5| Step: 4
Training loss: 0.13656800679074496
Validation loss: 2.5203130604318065

Epoch: 5| Step: 5
Training loss: 0.16980494937740515
Validation loss: 2.5346847382131616

Epoch: 5| Step: 6
Training loss: 0.08358150430363367
Validation loss: 2.5496013399702635

Epoch: 5| Step: 7
Training loss: 0.07799061900436624
Validation loss: 2.513365113456822

Epoch: 5| Step: 8
Training loss: 0.12144909527354482
Validation loss: 2.58342226003071

Epoch: 5| Step: 9
Training loss: 0.17519577859839927
Validation loss: 2.5782722945660637

Epoch: 5| Step: 10
Training loss: 0.10216351264740886
Validation loss: 2.564267109205032

Epoch: 646| Step: 0
Training loss: 0.1257599587516544
Validation loss: 2.5659274058494663

Epoch: 5| Step: 1
Training loss: 0.13490927683244888
Validation loss: 2.5793686716898425

Epoch: 5| Step: 2
Training loss: 0.09146540736713706
Validation loss: 2.599647018571669

Epoch: 5| Step: 3
Training loss: 0.10911725960122315
Validation loss: 2.57008837149622

Epoch: 5| Step: 4
Training loss: 0.11204913128985697
Validation loss: 2.5532680222042283

Epoch: 5| Step: 5
Training loss: 0.10345828069444091
Validation loss: 2.562883332896275

Epoch: 5| Step: 6
Training loss: 0.13061013612868827
Validation loss: 2.5757583808393165

Epoch: 5| Step: 7
Training loss: 0.17811655518105715
Validation loss: 2.545177712263976

Epoch: 5| Step: 8
Training loss: 0.10094293185579142
Validation loss: 2.5592422326107402

Epoch: 5| Step: 9
Training loss: 0.10046114633984793
Validation loss: 2.585698638334365

Epoch: 5| Step: 10
Training loss: 0.12647135360635559
Validation loss: 2.5598192065900447

Epoch: 647| Step: 0
Training loss: 0.10649518498289487
Validation loss: 2.563595251348618

Epoch: 5| Step: 1
Training loss: 0.09862132052712305
Validation loss: 2.580653829072937

Epoch: 5| Step: 2
Training loss: 0.10368632690899689
Validation loss: 2.5949389078703495

Epoch: 5| Step: 3
Training loss: 0.10051162530136315
Validation loss: 2.6097621383690486

Epoch: 5| Step: 4
Training loss: 0.13285869608399098
Validation loss: 2.5515061456370773

Epoch: 5| Step: 5
Training loss: 0.1564531852941493
Validation loss: 2.5840755255554266

Epoch: 5| Step: 6
Training loss: 0.08817071260851837
Validation loss: 2.604035384940124

Epoch: 5| Step: 7
Training loss: 0.0876302624409902
Validation loss: 2.598034870324852

Epoch: 5| Step: 8
Training loss: 0.14884196565004207
Validation loss: 2.578473139401769

Epoch: 5| Step: 9
Training loss: 0.18464395779509313
Validation loss: 2.578427870912845

Epoch: 5| Step: 10
Training loss: 0.09731316859904364
Validation loss: 2.6085704162088876

Epoch: 648| Step: 0
Training loss: 0.10923280583884613
Validation loss: 2.602425570022817

Epoch: 5| Step: 1
Training loss: 0.10127603956918803
Validation loss: 2.602295449297528

Epoch: 5| Step: 2
Training loss: 0.14831666671174268
Validation loss: 2.622302409121751

Epoch: 5| Step: 3
Training loss: 0.16668692232267146
Validation loss: 2.633998811593636

Epoch: 5| Step: 4
Training loss: 0.14529047486320842
Validation loss: 2.6419255106903234

Epoch: 5| Step: 5
Training loss: 0.12128728352346231
Validation loss: 2.6232665491649287

Epoch: 5| Step: 6
Training loss: 0.14316271772182398
Validation loss: 2.6097065832387343

Epoch: 5| Step: 7
Training loss: 0.10240289184115141
Validation loss: 2.617374218209642

Epoch: 5| Step: 8
Training loss: 0.19040411753033987
Validation loss: 2.626742671293818

Epoch: 5| Step: 9
Training loss: 0.1330430050083795
Validation loss: 2.6205816259333785

Epoch: 5| Step: 10
Training loss: 0.11024689563394309
Validation loss: 2.605158135144858

Epoch: 649| Step: 0
Training loss: 0.1578996715001983
Validation loss: 2.6222922471304697

Epoch: 5| Step: 1
Training loss: 0.19602262149212363
Validation loss: 2.601010160806358

Epoch: 5| Step: 2
Training loss: 0.11229283228787058
Validation loss: 2.6201895738201655

Epoch: 5| Step: 3
Training loss: 0.12421992274396544
Validation loss: 2.578412956894431

Epoch: 5| Step: 4
Training loss: 0.15574425865539426
Validation loss: 2.617368254207435

Epoch: 5| Step: 5
Training loss: 0.12272242883739558
Validation loss: 2.566357784825342

Epoch: 5| Step: 6
Training loss: 0.12852649671723382
Validation loss: 2.5573122506444905

Epoch: 5| Step: 7
Training loss: 0.10503172399464426
Validation loss: 2.5460551633626576

Epoch: 5| Step: 8
Training loss: 0.10575623097364052
Validation loss: 2.579695076405019

Epoch: 5| Step: 9
Training loss: 0.1564303192116772
Validation loss: 2.555833945449129

Epoch: 5| Step: 10
Training loss: 0.0861144628030584
Validation loss: 2.559046307978842

Epoch: 650| Step: 0
Training loss: 0.10341028485736682
Validation loss: 2.564141017916939

Epoch: 5| Step: 1
Training loss: 0.08283703852069925
Validation loss: 2.559988254002958

Epoch: 5| Step: 2
Training loss: 0.16857656577797578
Validation loss: 2.5339708500675586

Epoch: 5| Step: 3
Training loss: 0.11604959042095551
Validation loss: 2.580654365512882

Epoch: 5| Step: 4
Training loss: 0.1013055356654239
Validation loss: 2.582961410625806

Epoch: 5| Step: 5
Training loss: 0.10007265290391366
Validation loss: 2.5823983870055245

Epoch: 5| Step: 6
Training loss: 0.18147387079654037
Validation loss: 2.5780418802723357

Epoch: 5| Step: 7
Training loss: 0.14112467208347793
Validation loss: 2.5917555406384323

Epoch: 5| Step: 8
Training loss: 0.1738340130355237
Validation loss: 2.587598130082033

Epoch: 5| Step: 9
Training loss: 0.11201341838927382
Validation loss: 2.5888840341712456

Epoch: 5| Step: 10
Training loss: 0.10333050964167304
Validation loss: 2.5723396817772812

Epoch: 651| Step: 0
Training loss: 0.15392369398994526
Validation loss: 2.5742923811252707

Epoch: 5| Step: 1
Training loss: 0.11784476102219774
Validation loss: 2.570907933239474

Epoch: 5| Step: 2
Training loss: 0.11157778302663662
Validation loss: 2.5933538619436094

Epoch: 5| Step: 3
Training loss: 0.20639666883768576
Validation loss: 2.5741672778680007

Epoch: 5| Step: 4
Training loss: 0.1110609428906272
Validation loss: 2.5940660387183723

Epoch: 5| Step: 5
Training loss: 0.07598287720413024
Validation loss: 2.579054135088804

Epoch: 5| Step: 6
Training loss: 0.149375274709824
Validation loss: 2.579344537639592

Epoch: 5| Step: 7
Training loss: 0.15148783766874693
Validation loss: 2.587144224693092

Epoch: 5| Step: 8
Training loss: 0.13450377359822152
Validation loss: 2.5830323356213176

Epoch: 5| Step: 9
Training loss: 0.12893838192984383
Validation loss: 2.61991157877884

Epoch: 5| Step: 10
Training loss: 0.09617457750925229
Validation loss: 2.585907015949036

Epoch: 652| Step: 0
Training loss: 0.133544880031879
Validation loss: 2.6107245670190475

Epoch: 5| Step: 1
Training loss: 0.14564523032471965
Validation loss: 2.606643065032137

Epoch: 5| Step: 2
Training loss: 0.08521390120505028
Validation loss: 2.6186331549399613

Epoch: 5| Step: 3
Training loss: 0.08258902992021135
Validation loss: 2.637602655368383

Epoch: 5| Step: 4
Training loss: 0.12369015736252842
Validation loss: 2.614549139413932

Epoch: 5| Step: 5
Training loss: 0.15616632843854558
Validation loss: 2.6384819782613262

Epoch: 5| Step: 6
Training loss: 0.16130348183609997
Validation loss: 2.6052203754240337

Epoch: 5| Step: 7
Training loss: 0.09837203914629003
Validation loss: 2.603941192382166

Epoch: 5| Step: 8
Training loss: 0.07368356273714982
Validation loss: 2.596772104801435

Epoch: 5| Step: 9
Training loss: 0.10401791939333019
Validation loss: 2.5937428954316624

Epoch: 5| Step: 10
Training loss: 0.14266652149646308
Validation loss: 2.602721567828482

Epoch: 653| Step: 0
Training loss: 0.14115908978088362
Validation loss: 2.5744215133378194

Epoch: 5| Step: 1
Training loss: 0.1909439869198608
Validation loss: 2.570823561524393

Epoch: 5| Step: 2
Training loss: 0.12903534320640722
Validation loss: 2.562467015111901

Epoch: 5| Step: 3
Training loss: 0.10791477348840729
Validation loss: 2.5397557354578932

Epoch: 5| Step: 4
Training loss: 0.1494469201354804
Validation loss: 2.522706866048481

Epoch: 5| Step: 5
Training loss: 0.1368014698466
Validation loss: 2.576583206387175

Epoch: 5| Step: 6
Training loss: 0.18069592787696256
Validation loss: 2.5650737501837226

Epoch: 5| Step: 7
Training loss: 0.0698596590973161
Validation loss: 2.5813975039283417

Epoch: 5| Step: 8
Training loss: 0.11589214934032786
Validation loss: 2.5898572222638374

Epoch: 5| Step: 9
Training loss: 0.09254526891221244
Validation loss: 2.585655201702599

Epoch: 5| Step: 10
Training loss: 0.11048275820310208
Validation loss: 2.603632169610442

Epoch: 654| Step: 0
Training loss: 0.1074560024496917
Validation loss: 2.6156363477110482

Epoch: 5| Step: 1
Training loss: 0.09751924441001449
Validation loss: 2.600466026760987

Epoch: 5| Step: 2
Training loss: 0.19729695213016069
Validation loss: 2.598075639040723

Epoch: 5| Step: 3
Training loss: 0.0850581922423109
Validation loss: 2.6138784074946058

Epoch: 5| Step: 4
Training loss: 0.16470373951289102
Validation loss: 2.62141793624491

Epoch: 5| Step: 5
Training loss: 0.10820937637834539
Validation loss: 2.626356283317759

Epoch: 5| Step: 6
Training loss: 0.10269526437008826
Validation loss: 2.6140745110967663

Epoch: 5| Step: 7
Training loss: 0.14085187095419158
Validation loss: 2.6222745382182286

Epoch: 5| Step: 8
Training loss: 0.07434892531938149
Validation loss: 2.633931323880833

Epoch: 5| Step: 9
Training loss: 0.10953779962169594
Validation loss: 2.6186211288820846

Epoch: 5| Step: 10
Training loss: 0.06089438990501245
Validation loss: 2.6140776277811026

Epoch: 655| Step: 0
Training loss: 0.13889661227712996
Validation loss: 2.6260910052258573

Epoch: 5| Step: 1
Training loss: 0.15483382509837504
Validation loss: 2.606092724850363

Epoch: 5| Step: 2
Training loss: 0.10600480966913646
Validation loss: 2.6057105346629315

Epoch: 5| Step: 3
Training loss: 0.135933953271834
Validation loss: 2.6086055138552937

Epoch: 5| Step: 4
Training loss: 0.10071424522735459
Validation loss: 2.5850670547882193

Epoch: 5| Step: 5
Training loss: 0.10751016629740645
Validation loss: 2.5978598208418875

Epoch: 5| Step: 6
Training loss: 0.1400899244063113
Validation loss: 2.5750631388175216

Epoch: 5| Step: 7
Training loss: 0.10145494377883005
Validation loss: 2.596986232557208

Epoch: 5| Step: 8
Training loss: 0.09331333270023971
Validation loss: 2.599112853283754

Epoch: 5| Step: 9
Training loss: 0.09204946423516598
Validation loss: 2.5924334564467433

Epoch: 5| Step: 10
Training loss: 0.07999494931549693
Validation loss: 2.605517814990798

Epoch: 656| Step: 0
Training loss: 0.06626145972810868
Validation loss: 2.60419641161923

Epoch: 5| Step: 1
Training loss: 0.09452507869816308
Validation loss: 2.5818219548628853

Epoch: 5| Step: 2
Training loss: 0.09936529529766493
Validation loss: 2.5953363992709657

Epoch: 5| Step: 3
Training loss: 0.1017308856680338
Validation loss: 2.5779551639345333

Epoch: 5| Step: 4
Training loss: 0.07115417613712706
Validation loss: 2.5863223320989794

Epoch: 5| Step: 5
Training loss: 0.10123347667837786
Validation loss: 2.5821407561047223

Epoch: 5| Step: 6
Training loss: 0.13847176795051916
Validation loss: 2.5866694415646023

Epoch: 5| Step: 7
Training loss: 0.1303564556347729
Validation loss: 2.577643512152716

Epoch: 5| Step: 8
Training loss: 0.13646634508472452
Validation loss: 2.5754204528757296

Epoch: 5| Step: 9
Training loss: 0.12621322107920416
Validation loss: 2.58155186014448

Epoch: 5| Step: 10
Training loss: 0.0738056885469802
Validation loss: 2.5738961846785187

Epoch: 657| Step: 0
Training loss: 0.0645374555582813
Validation loss: 2.566843238839669

Epoch: 5| Step: 1
Training loss: 0.08022818229459874
Validation loss: 2.5780871038302338

Epoch: 5| Step: 2
Training loss: 0.154880404122907
Validation loss: 2.5813107950446925

Epoch: 5| Step: 3
Training loss: 0.12863646076078405
Validation loss: 2.6160328100138335

Epoch: 5| Step: 4
Training loss: 0.11454904153320672
Validation loss: 2.583225931428502

Epoch: 5| Step: 5
Training loss: 0.09728816280685706
Validation loss: 2.595292968858263

Epoch: 5| Step: 6
Training loss: 0.13502087814650313
Validation loss: 2.597252808066258

Epoch: 5| Step: 7
Training loss: 0.0534209682068818
Validation loss: 2.5771737698986343

Epoch: 5| Step: 8
Training loss: 0.15163303533130174
Validation loss: 2.590918566925299

Epoch: 5| Step: 9
Training loss: 0.07407160339361196
Validation loss: 2.5908508545121443

Epoch: 5| Step: 10
Training loss: 0.08934651001592879
Validation loss: 2.569736610067995

Epoch: 658| Step: 0
Training loss: 0.1317050354606649
Validation loss: 2.5780118557591436

Epoch: 5| Step: 1
Training loss: 0.13036856488121842
Validation loss: 2.5911007141020526

Epoch: 5| Step: 2
Training loss: 0.14507274101057513
Validation loss: 2.590635672402231

Epoch: 5| Step: 3
Training loss: 0.10078805689779086
Validation loss: 2.581287871942075

Epoch: 5| Step: 4
Training loss: 0.07372055871312394
Validation loss: 2.584852069579317

Epoch: 5| Step: 5
Training loss: 0.04633985963422562
Validation loss: 2.5745695774082424

Epoch: 5| Step: 6
Training loss: 0.08171829346133579
Validation loss: 2.5760778876931063

Epoch: 5| Step: 7
Training loss: 0.07460884735659817
Validation loss: 2.5660539893117535

Epoch: 5| Step: 8
Training loss: 0.08171312202453491
Validation loss: 2.595348168731341

Epoch: 5| Step: 9
Training loss: 0.055124208096462485
Validation loss: 2.568806650209582

Epoch: 5| Step: 10
Training loss: 0.13821286811362138
Validation loss: 2.576748967182874

Epoch: 659| Step: 0
Training loss: 0.13261372754129955
Validation loss: 2.5763493334298895

Epoch: 5| Step: 1
Training loss: 0.16037824411076904
Validation loss: 2.563887161897024

Epoch: 5| Step: 2
Training loss: 0.06658499517247315
Validation loss: 2.577288881653894

Epoch: 5| Step: 3
Training loss: 0.11860042582131103
Validation loss: 2.5879341068279462

Epoch: 5| Step: 4
Training loss: 0.09157666720063276
Validation loss: 2.581868622968277

Epoch: 5| Step: 5
Training loss: 0.05854863575791364
Validation loss: 2.6005755501734615

Epoch: 5| Step: 6
Training loss: 0.07681420210802371
Validation loss: 2.5794391244910586

Epoch: 5| Step: 7
Training loss: 0.07168168875891522
Validation loss: 2.5884940064875432

Epoch: 5| Step: 8
Training loss: 0.06282992380489623
Validation loss: 2.5963675659820016

Epoch: 5| Step: 9
Training loss: 0.0790642456052341
Validation loss: 2.5885566583397663

Epoch: 5| Step: 10
Training loss: 0.11701291510451595
Validation loss: 2.594295546634764

Epoch: 660| Step: 0
Training loss: 0.09422196360622465
Validation loss: 2.6093631975244636

Epoch: 5| Step: 1
Training loss: 0.10732786660073741
Validation loss: 2.6123799870283797

Epoch: 5| Step: 2
Training loss: 0.09238659365055478
Validation loss: 2.5970696639963555

Epoch: 5| Step: 3
Training loss: 0.13504045906702003
Validation loss: 2.5816855724581496

Epoch: 5| Step: 4
Training loss: 0.08718948978115586
Validation loss: 2.5571058520880308

Epoch: 5| Step: 5
Training loss: 0.09599501996298387
Validation loss: 2.5799483875645817

Epoch: 5| Step: 6
Training loss: 0.08514431095422936
Validation loss: 2.575676113378878

Epoch: 5| Step: 7
Training loss: 0.16006735334929106
Validation loss: 2.572190194664502

Epoch: 5| Step: 8
Training loss: 0.07783507552947992
Validation loss: 2.5775946853847196

Epoch: 5| Step: 9
Training loss: 0.0767600417116772
Validation loss: 2.548363190485978

Epoch: 5| Step: 10
Training loss: 0.16488752800751305
Validation loss: 2.563171066496054

Epoch: 661| Step: 0
Training loss: 0.10999957213941723
Validation loss: 2.5563730574448282

Epoch: 5| Step: 1
Training loss: 0.09206206488296072
Validation loss: 2.5656949986225195

Epoch: 5| Step: 2
Training loss: 0.10754366819452094
Validation loss: 2.5907107210444305

Epoch: 5| Step: 3
Training loss: 0.06887178809734563
Validation loss: 2.597014653968779

Epoch: 5| Step: 4
Training loss: 0.08499485193994517
Validation loss: 2.555405487924653

Epoch: 5| Step: 5
Training loss: 0.07385856666873127
Validation loss: 2.5731292360465554

Epoch: 5| Step: 6
Training loss: 0.09466434185335995
Validation loss: 2.5696076544628252

Epoch: 5| Step: 7
Training loss: 0.09271130740113696
Validation loss: 2.5865783819227435

Epoch: 5| Step: 8
Training loss: 0.0826085924858636
Validation loss: 2.5895161539465974

Epoch: 5| Step: 9
Training loss: 0.06061153650719713
Validation loss: 2.60520292538715

Epoch: 5| Step: 10
Training loss: 0.18572611934824176
Validation loss: 2.6048387801259456

Epoch: 662| Step: 0
Training loss: 0.09575812063628979
Validation loss: 2.602377034844806

Epoch: 5| Step: 1
Training loss: 0.08435995378382266
Validation loss: 2.617215043548831

Epoch: 5| Step: 2
Training loss: 0.07435564541626632
Validation loss: 2.619989718451699

Epoch: 5| Step: 3
Training loss: 0.07928014247509392
Validation loss: 2.631888118893771

Epoch: 5| Step: 4
Training loss: 0.11006805832792663
Validation loss: 2.6209956320200845

Epoch: 5| Step: 5
Training loss: 0.17169204641390368
Validation loss: 2.639955033102377

Epoch: 5| Step: 6
Training loss: 0.11353527559293482
Validation loss: 2.628971203577544

Epoch: 5| Step: 7
Training loss: 0.1648378556449677
Validation loss: 2.6392338673156366

Epoch: 5| Step: 8
Training loss: 0.1222578134570261
Validation loss: 2.620585850106834

Epoch: 5| Step: 9
Training loss: 0.06351885487085086
Validation loss: 2.6229535430458646

Epoch: 5| Step: 10
Training loss: 0.08375668711618325
Validation loss: 2.612992918346113

Epoch: 663| Step: 0
Training loss: 0.0648684378529529
Validation loss: 2.5889610318420346

Epoch: 5| Step: 1
Training loss: 0.09078017752862524
Validation loss: 2.59448404077339

Epoch: 5| Step: 2
Training loss: 0.07952528072562912
Validation loss: 2.58090771860348

Epoch: 5| Step: 3
Training loss: 0.13658517715800175
Validation loss: 2.5718266971328325

Epoch: 5| Step: 4
Training loss: 0.17232894015035094
Validation loss: 2.5760249437487865

Epoch: 5| Step: 5
Training loss: 0.13280348887447663
Validation loss: 2.567222916915119

Epoch: 5| Step: 6
Training loss: 0.1178209865167068
Validation loss: 2.574436617276733

Epoch: 5| Step: 7
Training loss: 0.1005645099519636
Validation loss: 2.5749579732340346

Epoch: 5| Step: 8
Training loss: 0.12487692287184629
Validation loss: 2.576598639426834

Epoch: 5| Step: 9
Training loss: 0.0951793457763444
Validation loss: 2.5755986429075777

Epoch: 5| Step: 10
Training loss: 0.07441457525462113
Validation loss: 2.571934048597004

Epoch: 664| Step: 0
Training loss: 0.08219850892953896
Validation loss: 2.5830181940509305

Epoch: 5| Step: 1
Training loss: 0.058133162782841814
Validation loss: 2.5643506454303737

Epoch: 5| Step: 2
Training loss: 0.08880282785806445
Validation loss: 2.578040976847165

Epoch: 5| Step: 3
Training loss: 0.1485432511631248
Validation loss: 2.5971467397947205

Epoch: 5| Step: 4
Training loss: 0.10294339977183058
Validation loss: 2.5860700874130536

Epoch: 5| Step: 5
Training loss: 0.17483219271312173
Validation loss: 2.5946161963902354

Epoch: 5| Step: 6
Training loss: 0.061856274004826815
Validation loss: 2.5743723077896923

Epoch: 5| Step: 7
Training loss: 0.09868384919863774
Validation loss: 2.60148880110881

Epoch: 5| Step: 8
Training loss: 0.10034721712569268
Validation loss: 2.5966289449451367

Epoch: 5| Step: 9
Training loss: 0.14358910647533285
Validation loss: 2.607986322365012

Epoch: 5| Step: 10
Training loss: 0.1689718424082128
Validation loss: 2.6035455671042187

Epoch: 665| Step: 0
Training loss: 0.13327017631903515
Validation loss: 2.592682607073363

Epoch: 5| Step: 1
Training loss: 0.0718407707496793
Validation loss: 2.5728971042082835

Epoch: 5| Step: 2
Training loss: 0.06358929673566588
Validation loss: 2.5688600465540623

Epoch: 5| Step: 3
Training loss: 0.08603670344006152
Validation loss: 2.5830518941038885

Epoch: 5| Step: 4
Training loss: 0.09094677600874214
Validation loss: 2.581892685267687

Epoch: 5| Step: 5
Training loss: 0.06067762178515007
Validation loss: 2.5747957114130338

Epoch: 5| Step: 6
Training loss: 0.22426507517794347
Validation loss: 2.5934054989380866

Epoch: 5| Step: 7
Training loss: 0.11888163197707069
Validation loss: 2.618454879909588

Epoch: 5| Step: 8
Training loss: 0.06025711643007869
Validation loss: 2.608813192865147

Epoch: 5| Step: 9
Training loss: 0.11213300269889555
Validation loss: 2.60720695435436

Epoch: 5| Step: 10
Training loss: 0.1288151346762722
Validation loss: 2.582118894770487

Epoch: 666| Step: 0
Training loss: 0.12214360516379558
Validation loss: 2.584782825565673

Epoch: 5| Step: 1
Training loss: 0.1460633904230402
Validation loss: 2.57874730350535

Epoch: 5| Step: 2
Training loss: 0.0784347028205049
Validation loss: 2.5574512141616936

Epoch: 5| Step: 3
Training loss: 0.16485421138490286
Validation loss: 2.614304214899205

Epoch: 5| Step: 4
Training loss: 0.24227602171524507
Validation loss: 2.619198008077508

Epoch: 5| Step: 5
Training loss: 0.08614917986708999
Validation loss: 2.568497304910213

Epoch: 5| Step: 6
Training loss: 0.10155994613811066
Validation loss: 2.5768040976983637

Epoch: 5| Step: 7
Training loss: 0.17261975040678346
Validation loss: 2.574117736811354

Epoch: 5| Step: 8
Training loss: 0.10367502679180575
Validation loss: 2.5642270341848876

Epoch: 5| Step: 9
Training loss: 0.16310807608913017
Validation loss: 2.593423869581956

Epoch: 5| Step: 10
Training loss: 0.10848284347751974
Validation loss: 2.584336823918525

Epoch: 667| Step: 0
Training loss: 0.143340125597583
Validation loss: 2.5855748583701375

Epoch: 5| Step: 1
Training loss: 0.11378786651475194
Validation loss: 2.600093395340008

Epoch: 5| Step: 2
Training loss: 0.15847850309429184
Validation loss: 2.604390425062298

Epoch: 5| Step: 3
Training loss: 0.1353452697546151
Validation loss: 2.601008374839315

Epoch: 5| Step: 4
Training loss: 0.09752644972552438
Validation loss: 2.575297868216124

Epoch: 5| Step: 5
Training loss: 0.18181679498891345
Validation loss: 2.5859735363263967

Epoch: 5| Step: 6
Training loss: 0.16121581858406098
Validation loss: 2.6052731272975813

Epoch: 5| Step: 7
Training loss: 0.1491392075904406
Validation loss: 2.617794084483479

Epoch: 5| Step: 8
Training loss: 0.10774011721809607
Validation loss: 2.613673913653442

Epoch: 5| Step: 9
Training loss: 0.1388620630491083
Validation loss: 2.6205047825491703

Epoch: 5| Step: 10
Training loss: 0.16154410150495394
Validation loss: 2.5859658244956454

Epoch: 668| Step: 0
Training loss: 0.11621151451159928
Validation loss: 2.5757592487368157

Epoch: 5| Step: 1
Training loss: 0.13665036807431152
Validation loss: 2.595506894668879

Epoch: 5| Step: 2
Training loss: 0.13845304900179017
Validation loss: 2.561375941446493

Epoch: 5| Step: 3
Training loss: 0.13831875394876578
Validation loss: 2.567014369844148

Epoch: 5| Step: 4
Training loss: 0.14976971502793504
Validation loss: 2.5661473742004635

Epoch: 5| Step: 5
Training loss: 0.12265101212051067
Validation loss: 2.5224849907540023

Epoch: 5| Step: 6
Training loss: 0.09131199529503124
Validation loss: 2.5662206554983316

Epoch: 5| Step: 7
Training loss: 0.1634859843484322
Validation loss: 2.5587087007194547

Epoch: 5| Step: 8
Training loss: 0.13568201721162867
Validation loss: 2.5901556857099632

Epoch: 5| Step: 9
Training loss: 0.12366580086115908
Validation loss: 2.575655870333619

Epoch: 5| Step: 10
Training loss: 0.18957901734026006
Validation loss: 2.5885854523292853

Epoch: 669| Step: 0
Training loss: 0.11043736826819188
Validation loss: 2.5982078241135853

Epoch: 5| Step: 1
Training loss: 0.11455878939527184
Validation loss: 2.5984376055276477

Epoch: 5| Step: 2
Training loss: 0.1272405085944461
Validation loss: 2.635918862486128

Epoch: 5| Step: 3
Training loss: 0.15316817151886292
Validation loss: 2.6245625864428432

Epoch: 5| Step: 4
Training loss: 0.1387518396985891
Validation loss: 2.6497473662678006

Epoch: 5| Step: 5
Training loss: 0.12884383424482754
Validation loss: 2.6066537202792057

Epoch: 5| Step: 6
Training loss: 0.14000310742173835
Validation loss: 2.6166848476424396

Epoch: 5| Step: 7
Training loss: 0.07239837632012533
Validation loss: 2.589115266369102

Epoch: 5| Step: 8
Training loss: 0.16376439895731443
Validation loss: 2.5841070595030295

Epoch: 5| Step: 9
Training loss: 0.09455998019594573
Validation loss: 2.5870999066203946

Epoch: 5| Step: 10
Training loss: 0.10638013208994318
Validation loss: 2.5897881120746047

Epoch: 670| Step: 0
Training loss: 0.1596452247682784
Validation loss: 2.6186474698320046

Epoch: 5| Step: 1
Training loss: 0.08319109149111523
Validation loss: 2.5571474648221932

Epoch: 5| Step: 2
Training loss: 0.09937157950422601
Validation loss: 2.584431744867492

Epoch: 5| Step: 3
Training loss: 0.10007381155201524
Validation loss: 2.586235814598825

Epoch: 5| Step: 4
Training loss: 0.15417684038740728
Validation loss: 2.580026233193457

Epoch: 5| Step: 5
Training loss: 0.14994057903928704
Validation loss: 2.5699854323287616

Epoch: 5| Step: 6
Training loss: 0.09337739610917001
Validation loss: 2.5774360121422655

Epoch: 5| Step: 7
Training loss: 0.11007245813352882
Validation loss: 2.56235693235315

Epoch: 5| Step: 8
Training loss: 0.1132837492568456
Validation loss: 2.5701874932817326

Epoch: 5| Step: 9
Training loss: 0.14085169904024003
Validation loss: 2.5618964043867156

Epoch: 5| Step: 10
Training loss: 0.11090743318965461
Validation loss: 2.5725201879220023

Epoch: 671| Step: 0
Training loss: 0.1467271890437477
Validation loss: 2.5288745039205343

Epoch: 5| Step: 1
Training loss: 0.10784974715996172
Validation loss: 2.543585927815376

Epoch: 5| Step: 2
Training loss: 0.10155260973237741
Validation loss: 2.5506932148987405

Epoch: 5| Step: 3
Training loss: 0.09124464968124053
Validation loss: 2.534917264514047

Epoch: 5| Step: 4
Training loss: 0.09397584315963449
Validation loss: 2.5455091558412013

Epoch: 5| Step: 5
Training loss: 0.13413126542370482
Validation loss: 2.5269358726891804

Epoch: 5| Step: 6
Training loss: 0.1427583535154449
Validation loss: 2.574186026315876

Epoch: 5| Step: 7
Training loss: 0.08374979281577773
Validation loss: 2.5541943410316206

Epoch: 5| Step: 8
Training loss: 0.08677356862440957
Validation loss: 2.548390754599988

Epoch: 5| Step: 9
Training loss: 0.14638214358661333
Validation loss: 2.583218947771626

Epoch: 5| Step: 10
Training loss: 0.185667711362933
Validation loss: 2.5856039165866

Epoch: 672| Step: 0
Training loss: 0.19715219012264637
Validation loss: 2.5815164314272336

Epoch: 5| Step: 1
Training loss: 0.12151646282299132
Validation loss: 2.612484782538135

Epoch: 5| Step: 2
Training loss: 0.14680812662641712
Validation loss: 2.5881550768572517

Epoch: 5| Step: 3
Training loss: 0.11500703887285371
Validation loss: 2.582146907705257

Epoch: 5| Step: 4
Training loss: 0.07172245080495762
Validation loss: 2.636002876454325

Epoch: 5| Step: 5
Training loss: 0.08667783566732047
Validation loss: 2.6059778903570425

Epoch: 5| Step: 6
Training loss: 0.09231374186866594
Validation loss: 2.6060213345299448

Epoch: 5| Step: 7
Training loss: 0.12248877326089636
Validation loss: 2.6164524712047355

Epoch: 5| Step: 8
Training loss: 0.11047972772972411
Validation loss: 2.6086729801451036

Epoch: 5| Step: 9
Training loss: 0.11140603969655778
Validation loss: 2.584717802978441

Epoch: 5| Step: 10
Training loss: 0.1804757038444621
Validation loss: 2.5790454025768317

Epoch: 673| Step: 0
Training loss: 0.1326758438979503
Validation loss: 2.6115044932246922

Epoch: 5| Step: 1
Training loss: 0.14239914647354537
Validation loss: 2.5947064364632033

Epoch: 5| Step: 2
Training loss: 0.12224808908428793
Validation loss: 2.60425475597086

Epoch: 5| Step: 3
Training loss: 0.08919601596722934
Validation loss: 2.5761700160858174

Epoch: 5| Step: 4
Training loss: 0.09402967499668691
Validation loss: 2.5824856986730986

Epoch: 5| Step: 5
Training loss: 0.14395359952304562
Validation loss: 2.5698534924737064

Epoch: 5| Step: 6
Training loss: 0.1402751425031585
Validation loss: 2.54859423493259

Epoch: 5| Step: 7
Training loss: 0.1977928500035275
Validation loss: 2.595322547491066

Epoch: 5| Step: 8
Training loss: 0.07833985943295976
Validation loss: 2.5570785638844926

Epoch: 5| Step: 9
Training loss: 0.14001434246319144
Validation loss: 2.592437659240779

Epoch: 5| Step: 10
Training loss: 0.08221924617864824
Validation loss: 2.547116747073535

Epoch: 674| Step: 0
Training loss: 0.08834141784469933
Validation loss: 2.575013823073381

Epoch: 5| Step: 1
Training loss: 0.0867765388734776
Validation loss: 2.575755693540159

Epoch: 5| Step: 2
Training loss: 0.15888128218584652
Validation loss: 2.566889357811157

Epoch: 5| Step: 3
Training loss: 0.08376002842373899
Validation loss: 2.581644121885073

Epoch: 5| Step: 4
Training loss: 0.16577065851064818
Validation loss: 2.5667537315932

Epoch: 5| Step: 5
Training loss: 0.1648627812577163
Validation loss: 2.573293103300458

Epoch: 5| Step: 6
Training loss: 0.13329429750428884
Validation loss: 2.591535258957195

Epoch: 5| Step: 7
Training loss: 0.15480138892125464
Validation loss: 2.5701351224879176

Epoch: 5| Step: 8
Training loss: 0.0964827796093705
Validation loss: 2.586679223674686

Epoch: 5| Step: 9
Training loss: 0.1305733444207875
Validation loss: 2.5988179749552955

Epoch: 5| Step: 10
Training loss: 0.09242046871066655
Validation loss: 2.613929058425361

Epoch: 675| Step: 0
Training loss: 0.07762749935087061
Validation loss: 2.576253999255987

Epoch: 5| Step: 1
Training loss: 0.09972193846570704
Validation loss: 2.59269986056073

Epoch: 5| Step: 2
Training loss: 0.1713661714066763
Validation loss: 2.584506317995277

Epoch: 5| Step: 3
Training loss: 0.1130132217378484
Validation loss: 2.59577772985953

Epoch: 5| Step: 4
Training loss: 0.24003526918969514
Validation loss: 2.6093105730426216

Epoch: 5| Step: 5
Training loss: 0.14820281725998832
Validation loss: 2.5775828776278567

Epoch: 5| Step: 6
Training loss: 0.13769362834143958
Validation loss: 2.5850282607280484

Epoch: 5| Step: 7
Training loss: 0.1361993870433943
Validation loss: 2.58472902370185

Epoch: 5| Step: 8
Training loss: 0.16581616480731862
Validation loss: 2.5872667970135512

Epoch: 5| Step: 9
Training loss: 0.12081511033973412
Validation loss: 2.5850113239700003

Epoch: 5| Step: 10
Training loss: 0.13784780918242465
Validation loss: 2.5702356388785654

Epoch: 676| Step: 0
Training loss: 0.16790156351439842
Validation loss: 2.5992409876304996

Epoch: 5| Step: 1
Training loss: 0.12049654625111966
Validation loss: 2.601103141760907

Epoch: 5| Step: 2
Training loss: 0.14038834261644326
Validation loss: 2.599940959316868

Epoch: 5| Step: 3
Training loss: 0.13733557113667166
Validation loss: 2.5795372678022526

Epoch: 5| Step: 4
Training loss: 0.18473069221654234
Validation loss: 2.5759414758525785

Epoch: 5| Step: 5
Training loss: 0.10744164024928078
Validation loss: 2.5602596222548266

Epoch: 5| Step: 6
Training loss: 0.09911594471453375
Validation loss: 2.577606458277127

Epoch: 5| Step: 7
Training loss: 0.14846557426990545
Validation loss: 2.590263332092173

Epoch: 5| Step: 8
Training loss: 0.14751992088093688
Validation loss: 2.5840928037717936

Epoch: 5| Step: 9
Training loss: 0.1087992064165812
Validation loss: 2.573861697408901

Epoch: 5| Step: 10
Training loss: 0.10463869661801714
Validation loss: 2.5680860475268132

Epoch: 677| Step: 0
Training loss: 0.15061611758748997
Validation loss: 2.5667732458222896

Epoch: 5| Step: 1
Training loss: 0.10548103225682369
Validation loss: 2.5506621392658997

Epoch: 5| Step: 2
Training loss: 0.1610723324181062
Validation loss: 2.55269566603176

Epoch: 5| Step: 3
Training loss: 0.1381598003917502
Validation loss: 2.538008249923183

Epoch: 5| Step: 4
Training loss: 0.1171389717711998
Validation loss: 2.5506159696151185

Epoch: 5| Step: 5
Training loss: 0.10584620203776937
Validation loss: 2.5466796097455786

Epoch: 5| Step: 6
Training loss: 0.09614095962580255
Validation loss: 2.547114760770091

Epoch: 5| Step: 7
Training loss: 0.13550115358382434
Validation loss: 2.5205216024769572

Epoch: 5| Step: 8
Training loss: 0.12029159878339174
Validation loss: 2.5171799243582758

Epoch: 5| Step: 9
Training loss: 0.08965772568201938
Validation loss: 2.5735320415295533

Epoch: 5| Step: 10
Training loss: 0.07573267975399892
Validation loss: 2.53933910898301

Epoch: 678| Step: 0
Training loss: 0.07507960284819905
Validation loss: 2.5506932802286824

Epoch: 5| Step: 1
Training loss: 0.09138623165123909
Validation loss: 2.572656695224231

Epoch: 5| Step: 2
Training loss: 0.12113117593338144
Validation loss: 2.5800083553976703

Epoch: 5| Step: 3
Training loss: 0.15042533721616586
Validation loss: 2.6043961165875835

Epoch: 5| Step: 4
Training loss: 0.1270706439783491
Validation loss: 2.5765650529706456

Epoch: 5| Step: 5
Training loss: 0.14662059172542713
Validation loss: 2.567221287191881

Epoch: 5| Step: 6
Training loss: 0.15574455166628032
Validation loss: 2.5816375520143917

Epoch: 5| Step: 7
Training loss: 0.09198797402583095
Validation loss: 2.5854923777383734

Epoch: 5| Step: 8
Training loss: 0.0988377104698117
Validation loss: 2.585137537736283

Epoch: 5| Step: 9
Training loss: 0.12238914813053167
Validation loss: 2.5746880207416436

Epoch: 5| Step: 10
Training loss: 0.16712539223358874
Validation loss: 2.614562271112424

Epoch: 679| Step: 0
Training loss: 0.17234743277764222
Validation loss: 2.6246215070849237

Epoch: 5| Step: 1
Training loss: 0.14359380228085236
Validation loss: 2.6097392770564665

Epoch: 5| Step: 2
Training loss: 0.13863834459279534
Validation loss: 2.602492372507688

Epoch: 5| Step: 3
Training loss: 0.15879775958390532
Validation loss: 2.606460550036135

Epoch: 5| Step: 4
Training loss: 0.1139495228044135
Validation loss: 2.604307908360506

Epoch: 5| Step: 5
Training loss: 0.14598919140884137
Validation loss: 2.6048987998953694

Epoch: 5| Step: 6
Training loss: 0.15724339602374568
Validation loss: 2.6335045215508974

Epoch: 5| Step: 7
Training loss: 0.09742259683777511
Validation loss: 2.59343046791695

Epoch: 5| Step: 8
Training loss: 0.1327027119529384
Validation loss: 2.5774095533847032

Epoch: 5| Step: 9
Training loss: 0.11662571878865906
Validation loss: 2.5785167954484502

Epoch: 5| Step: 10
Training loss: 0.11173875269517826
Validation loss: 2.5999323945765194

Epoch: 680| Step: 0
Training loss: 0.08143443176717399
Validation loss: 2.593133762502115

Epoch: 5| Step: 1
Training loss: 0.10022191034834817
Validation loss: 2.5956294908570614

Epoch: 5| Step: 2
Training loss: 0.1234113842161071
Validation loss: 2.6204828205935295

Epoch: 5| Step: 3
Training loss: 0.13177221665642624
Validation loss: 2.609213228831474

Epoch: 5| Step: 4
Training loss: 0.1448881536770976
Validation loss: 2.6058066500862087

Epoch: 5| Step: 5
Training loss: 0.09714680350125512
Validation loss: 2.5827968753592994

Epoch: 5| Step: 6
Training loss: 0.1864926577431845
Validation loss: 2.5818661262194347

Epoch: 5| Step: 7
Training loss: 0.09766019336368174
Validation loss: 2.6015872675145295

Epoch: 5| Step: 8
Training loss: 0.11687876245236038
Validation loss: 2.5954471910939088

Epoch: 5| Step: 9
Training loss: 0.13113861750667544
Validation loss: 2.5642740614966826

Epoch: 5| Step: 10
Training loss: 0.17025187117539803
Validation loss: 2.582950691388499

Epoch: 681| Step: 0
Training loss: 0.09853616076922408
Validation loss: 2.6094155571551165

Epoch: 5| Step: 1
Training loss: 0.1723598933764988
Validation loss: 2.590426636024917

Epoch: 5| Step: 2
Training loss: 0.16212239270624765
Validation loss: 2.572933686361076

Epoch: 5| Step: 3
Training loss: 0.09625114483585945
Validation loss: 2.588074504056794

Epoch: 5| Step: 4
Training loss: 0.14196968241332286
Validation loss: 2.5672479627951272

Epoch: 5| Step: 5
Training loss: 0.10627453780128712
Validation loss: 2.5554952236108455

Epoch: 5| Step: 6
Training loss: 0.0639728075267808
Validation loss: 2.5621217137802503

Epoch: 5| Step: 7
Training loss: 0.17252998287569588
Validation loss: 2.5564457464780013

Epoch: 5| Step: 8
Training loss: 0.1239606630850356
Validation loss: 2.5577191239800725

Epoch: 5| Step: 9
Training loss: 0.1052502647332013
Validation loss: 2.5298924838736627

Epoch: 5| Step: 10
Training loss: 0.0782849730341073
Validation loss: 2.5397480135024306

Epoch: 682| Step: 0
Training loss: 0.10185818545118977
Validation loss: 2.5522946948050635

Epoch: 5| Step: 1
Training loss: 0.13177931240630286
Validation loss: 2.533482840740368

Epoch: 5| Step: 2
Training loss: 0.08922940100445297
Validation loss: 2.5325368924055316

Epoch: 5| Step: 3
Training loss: 0.11868242973392372
Validation loss: 2.549871116154271

Epoch: 5| Step: 4
Training loss: 0.07443820356529775
Validation loss: 2.5668986445259327

Epoch: 5| Step: 5
Training loss: 0.09299166761552802
Validation loss: 2.5469137450914356

Epoch: 5| Step: 6
Training loss: 0.082863648831133
Validation loss: 2.5531324054050675

Epoch: 5| Step: 7
Training loss: 0.10111489145648482
Validation loss: 2.5484515575669233

Epoch: 5| Step: 8
Training loss: 0.12738310550958976
Validation loss: 2.5650996335838387

Epoch: 5| Step: 9
Training loss: 0.12933508749140749
Validation loss: 2.5725574894512095

Epoch: 5| Step: 10
Training loss: 0.13018897548467567
Validation loss: 2.551374261999456

Epoch: 683| Step: 0
Training loss: 0.1378344651102344
Validation loss: 2.561306008714793

Epoch: 5| Step: 1
Training loss: 0.0760276817363656
Validation loss: 2.55990970989911

Epoch: 5| Step: 2
Training loss: 0.08665448172137692
Validation loss: 2.563695197169721

Epoch: 5| Step: 3
Training loss: 0.12766396976600874
Validation loss: 2.551122661809798

Epoch: 5| Step: 4
Training loss: 0.1348277791755212
Validation loss: 2.542723222433961

Epoch: 5| Step: 5
Training loss: 0.06750484832155751
Validation loss: 2.55037435469636

Epoch: 5| Step: 6
Training loss: 0.15762710492818244
Validation loss: 2.5229790058734247

Epoch: 5| Step: 7
Training loss: 0.11745364643197871
Validation loss: 2.546621272623905

Epoch: 5| Step: 8
Training loss: 0.08137768137505368
Validation loss: 2.5544644362785203

Epoch: 5| Step: 9
Training loss: 0.11162147021292733
Validation loss: 2.5673716178165717

Epoch: 5| Step: 10
Training loss: 0.07379845459467324
Validation loss: 2.5587010600088607

Epoch: 684| Step: 0
Training loss: 0.11705799496842174
Validation loss: 2.554359289764762

Epoch: 5| Step: 1
Training loss: 0.10370212075639676
Validation loss: 2.5563995784912636

Epoch: 5| Step: 2
Training loss: 0.15705239974356044
Validation loss: 2.5543958508690388

Epoch: 5| Step: 3
Training loss: 0.057476994519323116
Validation loss: 2.5529233585095237

Epoch: 5| Step: 4
Training loss: 0.11161273831577985
Validation loss: 2.5559495980207534

Epoch: 5| Step: 5
Training loss: 0.11452879113320004
Validation loss: 2.5649011268710042

Epoch: 5| Step: 6
Training loss: 0.1246422289345461
Validation loss: 2.5588520915648223

Epoch: 5| Step: 7
Training loss: 0.13931996722679413
Validation loss: 2.57598529024828

Epoch: 5| Step: 8
Training loss: 0.11497916636078472
Validation loss: 2.5717133196558386

Epoch: 5| Step: 9
Training loss: 0.09178590201679522
Validation loss: 2.56143193229681

Epoch: 5| Step: 10
Training loss: 0.0794689277998705
Validation loss: 2.576082230620141

Epoch: 685| Step: 0
Training loss: 0.0760276817363656
Validation loss: 2.6021940812306608

Epoch: 5| Step: 1
Training loss: 0.10927189497194079
Validation loss: 2.6029198248706678

Epoch: 5| Step: 2
Training loss: 0.0561831182653218
Validation loss: 2.57622352501114

Epoch: 5| Step: 3
Training loss: 0.12734111771466586
Validation loss: 2.6074141607308308

Epoch: 5| Step: 4
Training loss: 0.13476752542454976
Validation loss: 2.598315818679863

Epoch: 5| Step: 5
Training loss: 0.06560863392977577
Validation loss: 2.578721919956361

Epoch: 5| Step: 6
Training loss: 0.07572847696700369
Validation loss: 2.6168117096064285

Epoch: 5| Step: 7
Training loss: 0.08539193004054141
Validation loss: 2.596359657922531

Epoch: 5| Step: 8
Training loss: 0.14232123106784486
Validation loss: 2.599300052241166

Epoch: 5| Step: 9
Training loss: 0.10176615287295945
Validation loss: 2.5903585792079453

Epoch: 5| Step: 10
Training loss: 0.08082963539399564
Validation loss: 2.585436549990316

Epoch: 686| Step: 0
Training loss: 0.07747734553949308
Validation loss: 2.563873492175096

Epoch: 5| Step: 1
Training loss: 0.10275569466109662
Validation loss: 2.5638537998881237

Epoch: 5| Step: 2
Training loss: 0.11495299657628076
Validation loss: 2.5714248109108975

Epoch: 5| Step: 3
Training loss: 0.04435968540260414
Validation loss: 2.5905993318096963

Epoch: 5| Step: 4
Training loss: 0.10832994462254936
Validation loss: 2.585284431776876

Epoch: 5| Step: 5
Training loss: 0.09644372639794525
Validation loss: 2.600769072748398

Epoch: 5| Step: 6
Training loss: 0.09763558169040688
Validation loss: 2.5678375204320463

Epoch: 5| Step: 7
Training loss: 0.0766181040794896
Validation loss: 2.579868950645556

Epoch: 5| Step: 8
Training loss: 0.09575007221372336
Validation loss: 2.586627606025731

Epoch: 5| Step: 9
Training loss: 0.0748932238551083
Validation loss: 2.611355012708051

Epoch: 5| Step: 10
Training loss: 0.14043165531822352
Validation loss: 2.58339513667709

Epoch: 687| Step: 0
Training loss: 0.08785545917178668
Validation loss: 2.584228291797486

Epoch: 5| Step: 1
Training loss: 0.050581926017390755
Validation loss: 2.5839875716311784

Epoch: 5| Step: 2
Training loss: 0.09633685989717877
Validation loss: 2.5844464982997972

Epoch: 5| Step: 3
Training loss: 0.13807294344700924
Validation loss: 2.5729330446870273

Epoch: 5| Step: 4
Training loss: 0.1179554255962694
Validation loss: 2.5702383030236287

Epoch: 5| Step: 5
Training loss: 0.06450368603119133
Validation loss: 2.593393226397672

Epoch: 5| Step: 6
Training loss: 0.09983414179877126
Validation loss: 2.5870828823489633

Epoch: 5| Step: 7
Training loss: 0.13332583293332725
Validation loss: 2.582395528916118

Epoch: 5| Step: 8
Training loss: 0.09663159686747314
Validation loss: 2.5703807265328598

Epoch: 5| Step: 9
Training loss: 0.12202696221227043
Validation loss: 2.5963902236387018

Epoch: 5| Step: 10
Training loss: 0.08124097420921537
Validation loss: 2.5893572751303

Epoch: 688| Step: 0
Training loss: 0.14175925846156032
Validation loss: 2.592243415792028

Epoch: 5| Step: 1
Training loss: 0.10349370616398419
Validation loss: 2.5977373170813074

Epoch: 5| Step: 2
Training loss: 0.13784168796082322
Validation loss: 2.58636780834655

Epoch: 5| Step: 3
Training loss: 0.08154937010896908
Validation loss: 2.6033706872712967

Epoch: 5| Step: 4
Training loss: 0.09763764204125554
Validation loss: 2.5837548421794554

Epoch: 5| Step: 5
Training loss: 0.1046547293969736
Validation loss: 2.583089708503635

Epoch: 5| Step: 6
Training loss: 0.0698936690548777
Validation loss: 2.5926055760550075

Epoch: 5| Step: 7
Training loss: 0.06583550911652312
Validation loss: 2.59249426081818

Epoch: 5| Step: 8
Training loss: 0.0904258601571326
Validation loss: 2.605801941034987

Epoch: 5| Step: 9
Training loss: 0.08604591748314604
Validation loss: 2.5857268811725795

Epoch: 5| Step: 10
Training loss: 0.1163239930894102
Validation loss: 2.588372231153746

Epoch: 689| Step: 0
Training loss: 0.0781321611698627
Validation loss: 2.5714929600786363

Epoch: 5| Step: 1
Training loss: 0.08559685351071476
Validation loss: 2.578064095382757

Epoch: 5| Step: 2
Training loss: 0.1540134881714931
Validation loss: 2.562347754741176

Epoch: 5| Step: 3
Training loss: 0.08283875303422349
Validation loss: 2.580572859138361

Epoch: 5| Step: 4
Training loss: 0.06839681009070003
Validation loss: 2.58656754585376

Epoch: 5| Step: 5
Training loss: 0.09048694009361302
Validation loss: 2.5806126624382397

Epoch: 5| Step: 6
Training loss: 0.0606018747203889
Validation loss: 2.58055781942788

Epoch: 5| Step: 7
Training loss: 0.0774414467781413
Validation loss: 2.584983920262765

Epoch: 5| Step: 8
Training loss: 0.0906194753031636
Validation loss: 2.580430501423956

Epoch: 5| Step: 9
Training loss: 0.08965600652884356
Validation loss: 2.6051837570762424

Epoch: 5| Step: 10
Training loss: 0.07937117241187605
Validation loss: 2.5824141367189926

Epoch: 690| Step: 0
Training loss: 0.08339035857152521
Validation loss: 2.5956525608876886

Epoch: 5| Step: 1
Training loss: 0.14017761776728166
Validation loss: 2.561757600190464

Epoch: 5| Step: 2
Training loss: 0.06253381648747143
Validation loss: 2.575233353760622

Epoch: 5| Step: 3
Training loss: 0.09689852482740187
Validation loss: 2.584232244055309

Epoch: 5| Step: 4
Training loss: 0.10382298507052203
Validation loss: 2.5937838581206454

Epoch: 5| Step: 5
Training loss: 0.060715597932047616
Validation loss: 2.584417386275373

Epoch: 5| Step: 6
Training loss: 0.07302742944035447
Validation loss: 2.556558060227676

Epoch: 5| Step: 7
Training loss: 0.08825909412497233
Validation loss: 2.5595471776641565

Epoch: 5| Step: 8
Training loss: 0.05932770048142307
Validation loss: 2.5822183231803244

Epoch: 5| Step: 9
Training loss: 0.12554430916852005
Validation loss: 2.5883884952019027

Epoch: 5| Step: 10
Training loss: 0.08507735672823671
Validation loss: 2.5720769607906933

Epoch: 691| Step: 0
Training loss: 0.14397741862903665
Validation loss: 2.6032961508173407

Epoch: 5| Step: 1
Training loss: 0.10545429377912124
Validation loss: 2.57787755709103

Epoch: 5| Step: 2
Training loss: 0.11549461204173654
Validation loss: 2.5844385149532005

Epoch: 5| Step: 3
Training loss: 0.06279879167768253
Validation loss: 2.572329505288346

Epoch: 5| Step: 4
Training loss: 0.08511215761439087
Validation loss: 2.5838293048672174

Epoch: 5| Step: 5
Training loss: 0.10222184750853165
Validation loss: 2.6018581466899686

Epoch: 5| Step: 6
Training loss: 0.09311200652906489
Validation loss: 2.6033727916576797

Epoch: 5| Step: 7
Training loss: 0.08444013134797344
Validation loss: 2.6023411217373615

Epoch: 5| Step: 8
Training loss: 0.11545659718162637
Validation loss: 2.6080771515978936

Epoch: 5| Step: 9
Training loss: 0.11294361886910903
Validation loss: 2.576414740354732

Epoch: 5| Step: 10
Training loss: 0.07890936673023714
Validation loss: 2.5642361125922486

Epoch: 692| Step: 0
Training loss: 0.11045747923379906
Validation loss: 2.573652940210193

Epoch: 5| Step: 1
Training loss: 0.09800748603799878
Validation loss: 2.5907829483617117

Epoch: 5| Step: 2
Training loss: 0.11141705307472066
Validation loss: 2.5714503103581863

Epoch: 5| Step: 3
Training loss: 0.14401568784833432
Validation loss: 2.592949478948887

Epoch: 5| Step: 4
Training loss: 0.06217831475807967
Validation loss: 2.567411610301758

Epoch: 5| Step: 5
Training loss: 0.1695834494798514
Validation loss: 2.609057918994476

Epoch: 5| Step: 6
Training loss: 0.17871401216123753
Validation loss: 2.5683152099116016

Epoch: 5| Step: 7
Training loss: 0.08852514528891753
Validation loss: 2.5859067651275223

Epoch: 5| Step: 8
Training loss: 0.08160036602485278
Validation loss: 2.60113083295959

Epoch: 5| Step: 9
Training loss: 0.07482790673750411
Validation loss: 2.5613609821879915

Epoch: 5| Step: 10
Training loss: 0.06765050856542022
Validation loss: 2.5743557769363052

Epoch: 693| Step: 0
Training loss: 0.09128522318845285
Validation loss: 2.592374327851333

Epoch: 5| Step: 1
Training loss: 0.10060339378064133
Validation loss: 2.5594752197564796

Epoch: 5| Step: 2
Training loss: 0.08704322957215206
Validation loss: 2.557071556438172

Epoch: 5| Step: 3
Training loss: 0.06688933456729314
Validation loss: 2.571394765962582

Epoch: 5| Step: 4
Training loss: 0.12371241626753049
Validation loss: 2.557392070688836

Epoch: 5| Step: 5
Training loss: 0.08619465608086675
Validation loss: 2.544533401073204

Epoch: 5| Step: 6
Training loss: 0.12231183382378209
Validation loss: 2.569474046461434

Epoch: 5| Step: 7
Training loss: 0.12342226199968231
Validation loss: 2.5873284590035213

Epoch: 5| Step: 8
Training loss: 0.10403612022997456
Validation loss: 2.5645085078494008

Epoch: 5| Step: 9
Training loss: 0.1416926058403289
Validation loss: 2.5557356512433893

Epoch: 5| Step: 10
Training loss: 0.07964481900719916
Validation loss: 2.562190001330196

Epoch: 694| Step: 0
Training loss: 0.14775763593304236
Validation loss: 2.5670450582746938

Epoch: 5| Step: 1
Training loss: 0.09002291395966554
Validation loss: 2.588939104815667

Epoch: 5| Step: 2
Training loss: 0.0989863743915067
Validation loss: 2.584493277598971

Epoch: 5| Step: 3
Training loss: 0.06351490696598543
Validation loss: 2.584373471799416

Epoch: 5| Step: 4
Training loss: 0.1025345120101478
Validation loss: 2.5369078444275517

Epoch: 5| Step: 5
Training loss: 0.10389065284831901
Validation loss: 2.564286092495825

Epoch: 5| Step: 6
Training loss: 0.11700718040114733
Validation loss: 2.5778162349042426

Epoch: 5| Step: 7
Training loss: 0.0674947451658717
Validation loss: 2.574576417240534

Epoch: 5| Step: 8
Training loss: 0.11964358025685118
Validation loss: 2.5604099250730803

Epoch: 5| Step: 9
Training loss: 0.08869061902101527
Validation loss: 2.5490274242885094

Epoch: 5| Step: 10
Training loss: 0.0683395220674552
Validation loss: 2.5623135577670713

Epoch: 695| Step: 0
Training loss: 0.14232046544044336
Validation loss: 2.5456466949037853

Epoch: 5| Step: 1
Training loss: 0.08112396014705053
Validation loss: 2.536842366307322

Epoch: 5| Step: 2
Training loss: 0.07632887994125431
Validation loss: 2.5715490865511907

Epoch: 5| Step: 3
Training loss: 0.06458055297317035
Validation loss: 2.573328801144511

Epoch: 5| Step: 4
Training loss: 0.12058225014389996
Validation loss: 2.547395860398166

Epoch: 5| Step: 5
Training loss: 0.06195607091470763
Validation loss: 2.5676845792469405

Epoch: 5| Step: 6
Training loss: 0.0750652774214365
Validation loss: 2.552916792552189

Epoch: 5| Step: 7
Training loss: 0.1184302122760125
Validation loss: 2.561640951356184

Epoch: 5| Step: 8
Training loss: 0.11748067422977276
Validation loss: 2.532352256636373

Epoch: 5| Step: 9
Training loss: 0.13143054658161957
Validation loss: 2.5819986973143134

Epoch: 5| Step: 10
Training loss: 0.08049762274970423
Validation loss: 2.5576151206429456

Epoch: 696| Step: 0
Training loss: 0.11158437684016115
Validation loss: 2.5666318322206907

Epoch: 5| Step: 1
Training loss: 0.06596993411359883
Validation loss: 2.5781166849657935

Epoch: 5| Step: 2
Training loss: 0.12039377189226698
Validation loss: 2.5484070027007353

Epoch: 5| Step: 3
Training loss: 0.09294961463922469
Validation loss: 2.5546987462512

Epoch: 5| Step: 4
Training loss: 0.0641862553447499
Validation loss: 2.56908489292083

Epoch: 5| Step: 5
Training loss: 0.07439843499298716
Validation loss: 2.5708612002900697

Epoch: 5| Step: 6
Training loss: 0.1148291023800394
Validation loss: 2.5602299219130007

Epoch: 5| Step: 7
Training loss: 0.09237635612105344
Validation loss: 2.5587257038737565

Epoch: 5| Step: 8
Training loss: 0.08868740571758321
Validation loss: 2.571082553287063

Epoch: 5| Step: 9
Training loss: 0.1421175139971125
Validation loss: 2.567247621774958

Epoch: 5| Step: 10
Training loss: 0.07119782370487071
Validation loss: 2.5748346466996774

Epoch: 697| Step: 0
Training loss: 0.0772093158464008
Validation loss: 2.5617875660257203

Epoch: 5| Step: 1
Training loss: 0.07993466040069182
Validation loss: 2.573597153478428

Epoch: 5| Step: 2
Training loss: 0.13370816367479266
Validation loss: 2.549257786544783

Epoch: 5| Step: 3
Training loss: 0.06741970890340516
Validation loss: 2.5688297420729667

Epoch: 5| Step: 4
Training loss: 0.0862195496217883
Validation loss: 2.581169363971824

Epoch: 5| Step: 5
Training loss: 0.0612181343084894
Validation loss: 2.5683062826740946

Epoch: 5| Step: 6
Training loss: 0.06455659508313298
Validation loss: 2.5739510406466395

Epoch: 5| Step: 7
Training loss: 0.07381828081005935
Validation loss: 2.5590722433266646

Epoch: 5| Step: 8
Training loss: 0.12171065179918747
Validation loss: 2.5766086259302803

Epoch: 5| Step: 9
Training loss: 0.09696726462289626
Validation loss: 2.5645232518157104

Epoch: 5| Step: 10
Training loss: 0.1291225309555951
Validation loss: 2.561104626412656

Epoch: 698| Step: 0
Training loss: 0.08839151387360296
Validation loss: 2.5523427178917255

Epoch: 5| Step: 1
Training loss: 0.060559865496257456
Validation loss: 2.5731904198616284

Epoch: 5| Step: 2
Training loss: 0.056972865207931024
Validation loss: 2.5755022322984638

Epoch: 5| Step: 3
Training loss: 0.11870390552682412
Validation loss: 2.579142534576228

Epoch: 5| Step: 4
Training loss: 0.09803314910802671
Validation loss: 2.5613631491139603

Epoch: 5| Step: 5
Training loss: 0.07899308714091656
Validation loss: 2.5730541249490013

Epoch: 5| Step: 6
Training loss: 0.07780598536091778
Validation loss: 2.597445803665333

Epoch: 5| Step: 7
Training loss: 0.08466403428454139
Validation loss: 2.5603494251169114

Epoch: 5| Step: 8
Training loss: 0.13253954579529142
Validation loss: 2.5694535560043565

Epoch: 5| Step: 9
Training loss: 0.07990833634848003
Validation loss: 2.5568442779846676

Epoch: 5| Step: 10
Training loss: 0.09016594955258472
Validation loss: 2.5471062035940926

Epoch: 699| Step: 0
Training loss: 0.10280684065678389
Validation loss: 2.5792049548714013

Epoch: 5| Step: 1
Training loss: 0.049296781204303676
Validation loss: 2.580911519996849

Epoch: 5| Step: 2
Training loss: 0.0879214179879787
Validation loss: 2.5709578602224545

Epoch: 5| Step: 3
Training loss: 0.07848018729011472
Validation loss: 2.5828336989387513

Epoch: 5| Step: 4
Training loss: 0.060705110834722326
Validation loss: 2.579984919915815

Epoch: 5| Step: 5
Training loss: 0.12294763392850319
Validation loss: 2.5702845665445246

Epoch: 5| Step: 6
Training loss: 0.09445312203406495
Validation loss: 2.5866291258973004

Epoch: 5| Step: 7
Training loss: 0.1488884112889791
Validation loss: 2.604434340635755

Epoch: 5| Step: 8
Training loss: 0.08129468970319113
Validation loss: 2.564751165218134

Epoch: 5| Step: 9
Training loss: 0.09389447960421878
Validation loss: 2.5908630332196627

Epoch: 5| Step: 10
Training loss: 0.07521554748950844
Validation loss: 2.578982219461884

Epoch: 700| Step: 0
Training loss: 0.06477969334903966
Validation loss: 2.5703601729879804

Epoch: 5| Step: 1
Training loss: 0.11805696205122541
Validation loss: 2.5737045082922725

Epoch: 5| Step: 2
Training loss: 0.07489402593013336
Validation loss: 2.584437544823326

Epoch: 5| Step: 3
Training loss: 0.057491484606240977
Validation loss: 2.592899582900326

Epoch: 5| Step: 4
Training loss: 0.09367239243250733
Validation loss: 2.582131767454186

Epoch: 5| Step: 5
Training loss: 0.08751309160660002
Validation loss: 2.58862162609496

Epoch: 5| Step: 6
Training loss: 0.07098342751037111
Validation loss: 2.596145366902249

Epoch: 5| Step: 7
Training loss: 0.05486742716952403
Validation loss: 2.5827233963618927

Epoch: 5| Step: 8
Training loss: 0.11908055573447605
Validation loss: 2.5631001377732017

Epoch: 5| Step: 9
Training loss: 0.1098454694084288
Validation loss: 2.6056495910366784

Epoch: 5| Step: 10
Training loss: 0.12245508207349179
Validation loss: 2.570004347445644

Testing loss: 2.899290395203406
