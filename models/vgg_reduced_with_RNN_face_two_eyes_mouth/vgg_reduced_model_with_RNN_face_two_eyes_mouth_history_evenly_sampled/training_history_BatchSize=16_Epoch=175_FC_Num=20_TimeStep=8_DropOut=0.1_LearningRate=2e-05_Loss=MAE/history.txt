Epoch: 1| Step: 0
Training loss: 4.677679061889648
Validation loss: 5.139916763510755

Epoch: 6| Step: 1
Training loss: 4.169437885284424
Validation loss: 5.118326448625134

Epoch: 6| Step: 2
Training loss: 5.0589470863342285
Validation loss: 5.099393865113617

Epoch: 6| Step: 3
Training loss: 3.8281431198120117
Validation loss: 5.080191068751837

Epoch: 6| Step: 4
Training loss: 5.138463020324707
Validation loss: 5.058979711224956

Epoch: 6| Step: 5
Training loss: 3.9101998805999756
Validation loss: 5.034594423027449

Epoch: 6| Step: 6
Training loss: 5.552019119262695
Validation loss: 5.006359300305767

Epoch: 6| Step: 7
Training loss: 5.044707298278809
Validation loss: 4.9745965875605105

Epoch: 6| Step: 8
Training loss: 5.602642059326172
Validation loss: 4.9386156861500075

Epoch: 6| Step: 9
Training loss: 4.687227725982666
Validation loss: 4.898757832024687

Epoch: 6| Step: 10
Training loss: 6.163371562957764
Validation loss: 4.853909451474426

Epoch: 6| Step: 11
Training loss: 5.015834808349609
Validation loss: 4.80409227391725

Epoch: 6| Step: 12
Training loss: 3.3149561882019043
Validation loss: 4.749904237767701

Epoch: 6| Step: 13
Training loss: 4.273049831390381
Validation loss: 4.690744261587819

Epoch: 2| Step: 0
Training loss: 5.278501510620117
Validation loss: 4.628682474936208

Epoch: 6| Step: 1
Training loss: 3.7834601402282715
Validation loss: 4.564315411352342

Epoch: 6| Step: 2
Training loss: 3.9908690452575684
Validation loss: 4.498375938784692

Epoch: 6| Step: 3
Training loss: 4.967343330383301
Validation loss: 4.433108155445386

Epoch: 6| Step: 4
Training loss: 5.277082443237305
Validation loss: 4.368864218393962

Epoch: 6| Step: 5
Training loss: 2.8882243633270264
Validation loss: 4.306291605836602

Epoch: 6| Step: 6
Training loss: 3.1111316680908203
Validation loss: 4.246089022646668

Epoch: 6| Step: 7
Training loss: 4.080686569213867
Validation loss: 4.190974497026013

Epoch: 6| Step: 8
Training loss: 3.393080234527588
Validation loss: 4.13860571768976

Epoch: 6| Step: 9
Training loss: 4.232170104980469
Validation loss: 4.0898712629913

Epoch: 6| Step: 10
Training loss: 4.169665813446045
Validation loss: 4.043633045688752

Epoch: 6| Step: 11
Training loss: 4.120202541351318
Validation loss: 3.9994346018760436

Epoch: 6| Step: 12
Training loss: 4.033875465393066
Validation loss: 3.9499810459793254

Epoch: 6| Step: 13
Training loss: 3.212090015411377
Validation loss: 3.89948094788418

Epoch: 3| Step: 0
Training loss: 3.0595703125
Validation loss: 3.852412341743387

Epoch: 6| Step: 1
Training loss: 4.025665760040283
Validation loss: 3.817260480696155

Epoch: 6| Step: 2
Training loss: 3.4577345848083496
Validation loss: 3.7749844904868834

Epoch: 6| Step: 3
Training loss: 4.5670342445373535
Validation loss: 3.737588800409789

Epoch: 6| Step: 4
Training loss: 2.971569061279297
Validation loss: 3.708145167237969

Epoch: 6| Step: 5
Training loss: 3.307993173599243
Validation loss: 3.680591998561736

Epoch: 6| Step: 6
Training loss: 3.7392237186431885
Validation loss: 3.654301643371582

Epoch: 6| Step: 7
Training loss: 3.127681016921997
Validation loss: 3.6225531844682592

Epoch: 6| Step: 8
Training loss: 3.419975757598877
Validation loss: 3.6019669835285475

Epoch: 6| Step: 9
Training loss: 3.5298683643341064
Validation loss: 3.583172516156268

Epoch: 6| Step: 10
Training loss: 3.324254035949707
Validation loss: 3.5633804490489345

Epoch: 6| Step: 11
Training loss: 4.181034564971924
Validation loss: 3.538837566170641

Epoch: 6| Step: 12
Training loss: 3.175251007080078
Validation loss: 3.5138229195789625

Epoch: 6| Step: 13
Training loss: 4.3011932373046875
Validation loss: 3.488669621047153

Epoch: 4| Step: 0
Training loss: 3.6355977058410645
Validation loss: 3.4631671290243826

Epoch: 6| Step: 1
Training loss: 3.232560634613037
Validation loss: 3.436483347287742

Epoch: 6| Step: 2
Training loss: 2.948719024658203
Validation loss: 3.4229720074643373

Epoch: 6| Step: 3
Training loss: 3.2761495113372803
Validation loss: 3.4188972852563344

Epoch: 6| Step: 4
Training loss: 3.0538554191589355
Validation loss: 3.3939027350435973

Epoch: 6| Step: 5
Training loss: 3.3897652626037598
Validation loss: 3.374920122085079

Epoch: 6| Step: 6
Training loss: 3.9167776107788086
Validation loss: 3.3553468514514226

Epoch: 6| Step: 7
Training loss: 3.194906711578369
Validation loss: 3.3286122301573395

Epoch: 6| Step: 8
Training loss: 3.711378574371338
Validation loss: 3.307073231666319

Epoch: 6| Step: 9
Training loss: 3.4883322715759277
Validation loss: 3.285600285376272

Epoch: 6| Step: 10
Training loss: 3.064744472503662
Validation loss: 3.262124958858695

Epoch: 6| Step: 11
Training loss: 3.5943470001220703
Validation loss: 3.2485499356382634

Epoch: 6| Step: 12
Training loss: 3.083122491836548
Validation loss: 3.2348745176869054

Epoch: 6| Step: 13
Training loss: 2.266500234603882
Validation loss: 3.226305164316649

Epoch: 5| Step: 0
Training loss: 3.5441975593566895
Validation loss: 3.2220678585831837

Epoch: 6| Step: 1
Training loss: 2.9871814250946045
Validation loss: 3.2062566588001866

Epoch: 6| Step: 2
Training loss: 2.139223575592041
Validation loss: 3.195269471855574

Epoch: 6| Step: 3
Training loss: 2.903961420059204
Validation loss: 3.180516630090693

Epoch: 6| Step: 4
Training loss: 3.06595778465271
Validation loss: 3.1527010189589633

Epoch: 6| Step: 5
Training loss: 3.2464137077331543
Validation loss: 3.1462740052130913

Epoch: 6| Step: 6
Training loss: 3.601254940032959
Validation loss: 3.141159562654393

Epoch: 6| Step: 7
Training loss: 2.9549925327301025
Validation loss: 3.1221754576570246

Epoch: 6| Step: 8
Training loss: 3.079888343811035
Validation loss: 3.103434342210011

Epoch: 6| Step: 9
Training loss: 3.875753402709961
Validation loss: 3.090805520293533

Epoch: 6| Step: 10
Training loss: 2.840496063232422
Validation loss: 3.0881107391849643

Epoch: 6| Step: 11
Training loss: 3.1620805263519287
Validation loss: 3.1053435110276744

Epoch: 6| Step: 12
Training loss: 3.350320339202881
Validation loss: 3.087207922371485

Epoch: 6| Step: 13
Training loss: 3.6611523628234863
Validation loss: 3.0385595342164398

Epoch: 6| Step: 0
Training loss: 3.5250067710876465
Validation loss: 3.031891971506098

Epoch: 6| Step: 1
Training loss: 2.9651966094970703
Validation loss: 3.0308041418752363

Epoch: 6| Step: 2
Training loss: 3.014402151107788
Validation loss: 3.047914679332446

Epoch: 6| Step: 3
Training loss: 3.4028539657592773
Validation loss: 3.0383555786584013

Epoch: 6| Step: 4
Training loss: 2.3723411560058594
Validation loss: 3.0261175017203055

Epoch: 6| Step: 5
Training loss: 3.9306492805480957
Validation loss: 3.005890582197456

Epoch: 6| Step: 6
Training loss: 2.6413609981536865
Validation loss: 2.9956134211632515

Epoch: 6| Step: 7
Training loss: 4.192440032958984
Validation loss: 2.9905188288739932

Epoch: 6| Step: 8
Training loss: 3.4427261352539062
Validation loss: 2.9800735878688034

Epoch: 6| Step: 9
Training loss: 2.917865753173828
Validation loss: 2.9658121421772945

Epoch: 6| Step: 10
Training loss: 2.1842451095581055
Validation loss: 2.958859879483459

Epoch: 6| Step: 11
Training loss: 3.0827085971832275
Validation loss: 2.9537886470876713

Epoch: 6| Step: 12
Training loss: 3.0147745609283447
Validation loss: 2.9483886226530998

Epoch: 6| Step: 13
Training loss: 1.3882273435592651
Validation loss: 2.951635963173323

Epoch: 7| Step: 0
Training loss: 4.181002616882324
Validation loss: 2.9474250603747625

Epoch: 6| Step: 1
Training loss: 2.3370795249938965
Validation loss: 2.92618977895347

Epoch: 6| Step: 2
Training loss: 2.571194648742676
Validation loss: 2.920128373689549

Epoch: 6| Step: 3
Training loss: 2.8520617485046387
Validation loss: 2.9122518031827864

Epoch: 6| Step: 4
Training loss: 3.461557149887085
Validation loss: 2.9038173255100044

Epoch: 6| Step: 5
Training loss: 3.9467790126800537
Validation loss: 2.900091914720433

Epoch: 6| Step: 6
Training loss: 2.3178834915161133
Validation loss: 2.8930735434255292

Epoch: 6| Step: 7
Training loss: 2.6681580543518066
Validation loss: 2.888667780865905

Epoch: 6| Step: 8
Training loss: 2.829996109008789
Validation loss: 2.881993337344098

Epoch: 6| Step: 9
Training loss: 3.703751802444458
Validation loss: 2.8817280851384646

Epoch: 6| Step: 10
Training loss: 2.64125919342041
Validation loss: 2.875353136370259

Epoch: 6| Step: 11
Training loss: 2.806399345397949
Validation loss: 2.8715817313040457

Epoch: 6| Step: 12
Training loss: 2.622594118118286
Validation loss: 2.8640504114089476

Epoch: 6| Step: 13
Training loss: 2.998476505279541
Validation loss: 2.863468416275517

Epoch: 8| Step: 0
Training loss: 2.9907169342041016
Validation loss: 2.856850790721114

Epoch: 6| Step: 1
Training loss: 3.7787554264068604
Validation loss: 2.8457278077320387

Epoch: 6| Step: 2
Training loss: 2.3858871459960938
Validation loss: 2.837110424554476

Epoch: 6| Step: 3
Training loss: 3.4638962745666504
Validation loss: 2.8310606505281184

Epoch: 6| Step: 4
Training loss: 3.058361768722534
Validation loss: 2.8242020427539782

Epoch: 6| Step: 5
Training loss: 2.232231616973877
Validation loss: 2.8186509045221473

Epoch: 6| Step: 6
Training loss: 3.01835560798645
Validation loss: 2.813922502661264

Epoch: 6| Step: 7
Training loss: 3.9257798194885254
Validation loss: 2.8043129726122786

Epoch: 6| Step: 8
Training loss: 3.2128872871398926
Validation loss: 2.7988475958506265

Epoch: 6| Step: 9
Training loss: 1.8530383110046387
Validation loss: 2.7987602705596597

Epoch: 6| Step: 10
Training loss: 2.2893800735473633
Validation loss: 2.8006653862614788

Epoch: 6| Step: 11
Training loss: 3.3794984817504883
Validation loss: 2.8057518056643906

Epoch: 6| Step: 12
Training loss: 2.533933162689209
Validation loss: 2.7912261357871433

Epoch: 6| Step: 13
Training loss: 3.147916078567505
Validation loss: 2.8005618561980543

Epoch: 9| Step: 0
Training loss: 3.1553823947906494
Validation loss: 2.7826274748771422

Epoch: 6| Step: 1
Training loss: 2.4012975692749023
Validation loss: 2.770161356977237

Epoch: 6| Step: 2
Training loss: 3.0246195793151855
Validation loss: 2.768631540318971

Epoch: 6| Step: 3
Training loss: 3.222200632095337
Validation loss: 2.783667008082072

Epoch: 6| Step: 4
Training loss: 2.4991514682769775
Validation loss: 2.762854365892308

Epoch: 6| Step: 5
Training loss: 2.66719651222229
Validation loss: 2.767385777606759

Epoch: 6| Step: 6
Training loss: 2.534183979034424
Validation loss: 2.77683517753437

Epoch: 6| Step: 7
Training loss: 2.3159427642822266
Validation loss: 2.7909769447900916

Epoch: 6| Step: 8
Training loss: 3.6738474369049072
Validation loss: 2.811867872873942

Epoch: 6| Step: 9
Training loss: 2.8508143424987793
Validation loss: 2.7900737254850325

Epoch: 6| Step: 10
Training loss: 2.867706537246704
Validation loss: 2.7831666969483897

Epoch: 6| Step: 11
Training loss: 3.13535737991333
Validation loss: 2.7562419676011607

Epoch: 6| Step: 12
Training loss: 2.9331517219543457
Validation loss: 2.7524267191527994

Epoch: 6| Step: 13
Training loss: 3.8866398334503174
Validation loss: 2.7544640264203473

Epoch: 10| Step: 0
Training loss: 3.1392853260040283
Validation loss: 2.739065803507323

Epoch: 6| Step: 1
Training loss: 2.907284736633301
Validation loss: 2.7255964714993715

Epoch: 6| Step: 2
Training loss: 2.7847912311553955
Validation loss: 2.7236619021302912

Epoch: 6| Step: 3
Training loss: 2.5045504570007324
Validation loss: 2.7120075456557737

Epoch: 6| Step: 4
Training loss: 2.4264907836914062
Validation loss: 2.726016172798731

Epoch: 6| Step: 5
Training loss: 3.669562339782715
Validation loss: 2.730661653703259

Epoch: 6| Step: 6
Training loss: 3.1530871391296387
Validation loss: 2.7049515939527944

Epoch: 6| Step: 7
Training loss: 3.3529775142669678
Validation loss: 2.690518448429723

Epoch: 6| Step: 8
Training loss: 2.8328418731689453
Validation loss: 2.685271857887186

Epoch: 6| Step: 9
Training loss: 2.5106420516967773
Validation loss: 2.6871799692030875

Epoch: 6| Step: 10
Training loss: 2.9162392616271973
Validation loss: 2.6828197022920013

Epoch: 6| Step: 11
Training loss: 2.738574981689453
Validation loss: 2.6817204362602642

Epoch: 6| Step: 12
Training loss: 2.5230836868286133
Validation loss: 2.693572957028625

Epoch: 6| Step: 13
Training loss: 2.555905342102051
Validation loss: 2.6812665231766237

Epoch: 11| Step: 0
Training loss: 2.3888816833496094
Validation loss: 2.676294470346102

Epoch: 6| Step: 1
Training loss: 2.4339599609375
Validation loss: 2.662829214526761

Epoch: 6| Step: 2
Training loss: 2.5339250564575195
Validation loss: 2.6654068757128972

Epoch: 6| Step: 3
Training loss: 3.348907709121704
Validation loss: 2.6606687012539116

Epoch: 6| Step: 4
Training loss: 3.599057674407959
Validation loss: 2.6507956827840498

Epoch: 6| Step: 5
Training loss: 3.3134961128234863
Validation loss: 2.6443172577888734

Epoch: 6| Step: 6
Training loss: 3.0064516067504883
Validation loss: 2.6422738080383628

Epoch: 6| Step: 7
Training loss: 3.252375602722168
Validation loss: 2.6329664132928334

Epoch: 6| Step: 8
Training loss: 3.085038185119629
Validation loss: 2.6296999428861882

Epoch: 6| Step: 9
Training loss: 2.9270408153533936
Validation loss: 2.6298298989572833

Epoch: 6| Step: 10
Training loss: 2.3325815200805664
Validation loss: 2.660442529186126

Epoch: 6| Step: 11
Training loss: 2.794980525970459
Validation loss: 2.734356026495657

Epoch: 6| Step: 12
Training loss: 2.383059501647949
Validation loss: 2.7384947833194526

Epoch: 6| Step: 13
Training loss: 1.7905510663986206
Validation loss: 2.6171930272092103

Epoch: 12| Step: 0
Training loss: 2.7011404037475586
Validation loss: 2.6474059397174465

Epoch: 6| Step: 1
Training loss: 3.158298969268799
Validation loss: 2.7235388858343965

Epoch: 6| Step: 2
Training loss: 4.14622688293457
Validation loss: 2.7219458651799027

Epoch: 6| Step: 3
Training loss: 3.7151434421539307
Validation loss: 2.662421549520185

Epoch: 6| Step: 4
Training loss: 3.0736451148986816
Validation loss: 2.6202712059020996

Epoch: 6| Step: 5
Training loss: 2.850778579711914
Validation loss: 2.6187921288192912

Epoch: 6| Step: 6
Training loss: 2.6605849266052246
Validation loss: 2.6552226902336202

Epoch: 6| Step: 7
Training loss: 2.833691358566284
Validation loss: 2.6914096852784515

Epoch: 6| Step: 8
Training loss: 2.9475796222686768
Validation loss: 2.6849834585702546

Epoch: 6| Step: 9
Training loss: 2.74351167678833
Validation loss: 2.6330584813189764

Epoch: 6| Step: 10
Training loss: 2.0223309993743896
Validation loss: 2.6142873738401677

Epoch: 6| Step: 11
Training loss: 2.1739346981048584
Validation loss: 2.6100703029222387

Epoch: 6| Step: 12
Training loss: 2.5827736854553223
Validation loss: 2.6098753303609867

Epoch: 6| Step: 13
Training loss: 1.338828444480896
Validation loss: 2.610255705412998

Epoch: 13| Step: 0
Training loss: 2.6357805728912354
Validation loss: 2.619425415992737

Epoch: 6| Step: 1
Training loss: 2.75010085105896
Validation loss: 2.6315440490681636

Epoch: 6| Step: 2
Training loss: 2.6784000396728516
Validation loss: 2.6217224136475594

Epoch: 6| Step: 3
Training loss: 3.4284911155700684
Validation loss: 2.607640051072644

Epoch: 6| Step: 4
Training loss: 2.854198455810547
Validation loss: 2.612405130940099

Epoch: 6| Step: 5
Training loss: 1.9091323614120483
Validation loss: 2.6048756414844143

Epoch: 6| Step: 6
Training loss: 2.9082775115966797
Validation loss: 2.5960455402251212

Epoch: 6| Step: 7
Training loss: 2.2970452308654785
Validation loss: 2.5954415593096005

Epoch: 6| Step: 8
Training loss: 2.563108205795288
Validation loss: 2.596493641535441

Epoch: 6| Step: 9
Training loss: 3.4811387062072754
Validation loss: 2.603106762773247

Epoch: 6| Step: 10
Training loss: 3.143893241882324
Validation loss: 2.5888943261997674

Epoch: 6| Step: 11
Training loss: 3.070549488067627
Validation loss: 2.578225989495554

Epoch: 6| Step: 12
Training loss: 3.1996281147003174
Validation loss: 2.5715405992282334

Epoch: 6| Step: 13
Training loss: 1.7591757774353027
Validation loss: 2.574476270265477

Epoch: 14| Step: 0
Training loss: 2.7164227962493896
Validation loss: 2.57486213919937

Epoch: 6| Step: 1
Training loss: 2.3399806022644043
Validation loss: 2.586865027745565

Epoch: 6| Step: 2
Training loss: 2.614201068878174
Validation loss: 2.5680866036363827

Epoch: 6| Step: 3
Training loss: 3.938481330871582
Validation loss: 2.563053382340298

Epoch: 6| Step: 4
Training loss: 1.6770427227020264
Validation loss: 2.559092516540199

Epoch: 6| Step: 5
Training loss: 2.636270761489868
Validation loss: 2.5580036665803645

Epoch: 6| Step: 6
Training loss: 2.717012882232666
Validation loss: 2.569996423618768

Epoch: 6| Step: 7
Training loss: 2.8940186500549316
Validation loss: 2.5514397416063535

Epoch: 6| Step: 8
Training loss: 2.275989055633545
Validation loss: 2.5448752705768873

Epoch: 6| Step: 9
Training loss: 3.522817373275757
Validation loss: 2.545297348371116

Epoch: 6| Step: 10
Training loss: 2.595280170440674
Validation loss: 2.5422100277357202

Epoch: 6| Step: 11
Training loss: 2.837061643600464
Validation loss: 2.5447744015724427

Epoch: 6| Step: 12
Training loss: 3.0283780097961426
Validation loss: 2.5514297946806876

Epoch: 6| Step: 13
Training loss: 2.759796619415283
Validation loss: 2.5489615137859056

Epoch: 15| Step: 0
Training loss: 2.8563830852508545
Validation loss: 2.5421537891510995

Epoch: 6| Step: 1
Training loss: 3.205662250518799
Validation loss: 2.528599269928471

Epoch: 6| Step: 2
Training loss: 2.5301103591918945
Validation loss: 2.5235652410855858

Epoch: 6| Step: 3
Training loss: 2.578190326690674
Validation loss: 2.5176735308862503

Epoch: 6| Step: 4
Training loss: 2.2301108837127686
Validation loss: 2.523378436283399

Epoch: 6| Step: 5
Training loss: 3.198300838470459
Validation loss: 2.5338702458207325

Epoch: 6| Step: 6
Training loss: 2.162306785583496
Validation loss: 2.5120164117505475

Epoch: 6| Step: 7
Training loss: 2.9230246543884277
Validation loss: 2.505023579443655

Epoch: 6| Step: 8
Training loss: 2.5876126289367676
Validation loss: 2.5067704416090444

Epoch: 6| Step: 9
Training loss: 2.7242798805236816
Validation loss: 2.5028616689866587

Epoch: 6| Step: 10
Training loss: 2.4999642372131348
Validation loss: 2.502614821157148

Epoch: 6| Step: 11
Training loss: 3.138962507247925
Validation loss: 2.5024121845922163

Epoch: 6| Step: 12
Training loss: 2.4293160438537598
Validation loss: 2.5248133585017216

Epoch: 6| Step: 13
Training loss: 3.3505969047546387
Validation loss: 2.5923433867833947

Epoch: 16| Step: 0
Training loss: 2.8985233306884766
Validation loss: 2.587147112815611

Epoch: 6| Step: 1
Training loss: 2.693563461303711
Validation loss: 2.6542601277751308

Epoch: 6| Step: 2
Training loss: 3.3985166549682617
Validation loss: 2.6692178095540693

Epoch: 6| Step: 3
Training loss: 3.0928964614868164
Validation loss: 2.620949391395815

Epoch: 6| Step: 4
Training loss: 2.256943702697754
Validation loss: 2.505187552462342

Epoch: 6| Step: 5
Training loss: 2.4874489307403564
Validation loss: 2.4927197989597114

Epoch: 6| Step: 6
Training loss: 2.3537511825561523
Validation loss: 2.5183250878446843

Epoch: 6| Step: 7
Training loss: 3.105351448059082
Validation loss: 2.5834644430427143

Epoch: 6| Step: 8
Training loss: 2.3314270973205566
Validation loss: 2.619542437215005

Epoch: 6| Step: 9
Training loss: 2.8995823860168457
Validation loss: 2.7749122983665875

Epoch: 6| Step: 10
Training loss: 2.9728527069091797
Validation loss: 2.80841278260754

Epoch: 6| Step: 11
Training loss: 2.706943988800049
Validation loss: 2.7755246213687363

Epoch: 6| Step: 12
Training loss: 2.8414158821105957
Validation loss: 2.726784957352505

Epoch: 6| Step: 13
Training loss: 3.4078500270843506
Validation loss: 2.6421589236105643

Epoch: 17| Step: 0
Training loss: 3.206244468688965
Validation loss: 2.7032333291986936

Epoch: 6| Step: 1
Training loss: 3.1377949714660645
Validation loss: 2.7222358513903875

Epoch: 6| Step: 2
Training loss: 3.1269350051879883
Validation loss: 2.6991478858455533

Epoch: 6| Step: 3
Training loss: 2.306345224380493
Validation loss: 2.696465817830896

Epoch: 6| Step: 4
Training loss: 2.553391695022583
Validation loss: 2.6453367381967525

Epoch: 6| Step: 5
Training loss: 1.9990754127502441
Validation loss: 2.575075921191964

Epoch: 6| Step: 6
Training loss: 2.692056655883789
Validation loss: 2.5491317010694936

Epoch: 6| Step: 7
Training loss: 2.0814208984375
Validation loss: 2.5523408023259972

Epoch: 6| Step: 8
Training loss: 3.144850730895996
Validation loss: 2.5680658637836413

Epoch: 6| Step: 9
Training loss: 2.9062445163726807
Validation loss: 2.583774415395593

Epoch: 6| Step: 10
Training loss: 2.727052688598633
Validation loss: 2.5709198033937843

Epoch: 6| Step: 11
Training loss: 3.004307270050049
Validation loss: 2.571760633940338

Epoch: 6| Step: 12
Training loss: 3.0306143760681152
Validation loss: 2.556307828554543

Epoch: 6| Step: 13
Training loss: 3.5736422538757324
Validation loss: 2.5441026943986134

Epoch: 18| Step: 0
Training loss: 2.443337917327881
Validation loss: 2.528704550958449

Epoch: 6| Step: 1
Training loss: 3.093735694885254
Validation loss: 2.5120025475819907

Epoch: 6| Step: 2
Training loss: 2.2702994346618652
Validation loss: 2.503104830300936

Epoch: 6| Step: 3
Training loss: 2.2708189487457275
Validation loss: 2.50833462643367

Epoch: 6| Step: 4
Training loss: 1.7166306972503662
Validation loss: 2.515913768481183

Epoch: 6| Step: 5
Training loss: 2.32167911529541
Validation loss: 2.5169315620135237

Epoch: 6| Step: 6
Training loss: 2.341207981109619
Validation loss: 2.5146103776911253

Epoch: 6| Step: 7
Training loss: 3.1210684776306152
Validation loss: 2.493873498773062

Epoch: 6| Step: 8
Training loss: 3.136873722076416
Validation loss: 2.481242900253624

Epoch: 6| Step: 9
Training loss: 3.0842556953430176
Validation loss: 2.476894037697905

Epoch: 6| Step: 10
Training loss: 2.633582592010498
Validation loss: 2.4747206523854244

Epoch: 6| Step: 11
Training loss: 3.5213305950164795
Validation loss: 2.4787082415755077

Epoch: 6| Step: 12
Training loss: 3.1357836723327637
Validation loss: 2.4753614881987214

Epoch: 6| Step: 13
Training loss: 2.965636730194092
Validation loss: 2.4715213134724605

Epoch: 19| Step: 0
Training loss: 2.861619472503662
Validation loss: 2.461365246003674

Epoch: 6| Step: 1
Training loss: 3.346479892730713
Validation loss: 2.4567502570408646

Epoch: 6| Step: 2
Training loss: 2.5625691413879395
Validation loss: 2.451600141422723

Epoch: 6| Step: 3
Training loss: 2.291332244873047
Validation loss: 2.4514289543192875

Epoch: 6| Step: 4
Training loss: 2.6935505867004395
Validation loss: 2.4592517088818293

Epoch: 6| Step: 5
Training loss: 2.71012544631958
Validation loss: 2.4672501369189193

Epoch: 6| Step: 6
Training loss: 2.503798484802246
Validation loss: 2.4774494735143517

Epoch: 6| Step: 7
Training loss: 2.5374600887298584
Validation loss: 2.5090963699484385

Epoch: 6| Step: 8
Training loss: 2.718994140625
Validation loss: 2.5121551559817408

Epoch: 6| Step: 9
Training loss: 2.2446727752685547
Validation loss: 2.472476359336607

Epoch: 6| Step: 10
Training loss: 3.4824905395507812
Validation loss: 2.4609080001872075

Epoch: 6| Step: 11
Training loss: 2.723330020904541
Validation loss: 2.4521882405845066

Epoch: 6| Step: 12
Training loss: 2.0614519119262695
Validation loss: 2.4405487378438315

Epoch: 6| Step: 13
Training loss: 2.8282248973846436
Validation loss: 2.4381417843603317

Epoch: 20| Step: 0
Training loss: 2.360151767730713
Validation loss: 2.4406024179150982

Epoch: 6| Step: 1
Training loss: 2.365048408508301
Validation loss: 2.442137731018887

Epoch: 6| Step: 2
Training loss: 3.7128958702087402
Validation loss: 2.4419143174284246

Epoch: 6| Step: 3
Training loss: 2.5907115936279297
Validation loss: 2.4406981519473496

Epoch: 6| Step: 4
Training loss: 2.2676169872283936
Validation loss: 2.4365725671091387

Epoch: 6| Step: 5
Training loss: 2.8087821006774902
Validation loss: 2.4412358166069112

Epoch: 6| Step: 6
Training loss: 3.1398661136627197
Validation loss: 2.449209984912667

Epoch: 6| Step: 7
Training loss: 2.777383804321289
Validation loss: 2.4523072627282914

Epoch: 6| Step: 8
Training loss: 3.486274242401123
Validation loss: 2.450351820197157

Epoch: 6| Step: 9
Training loss: 2.674325942993164
Validation loss: 2.440800407881378

Epoch: 6| Step: 10
Training loss: 2.378325939178467
Validation loss: 2.4400420727268344

Epoch: 6| Step: 11
Training loss: 2.5211079120635986
Validation loss: 2.4330066814217517

Epoch: 6| Step: 12
Training loss: 1.6656262874603271
Validation loss: 2.428582073539816

Epoch: 6| Step: 13
Training loss: 2.6955974102020264
Validation loss: 2.423631170744537

Epoch: 21| Step: 0
Training loss: 2.8173766136169434
Validation loss: 2.421285847181915

Epoch: 6| Step: 1
Training loss: 3.1840898990631104
Validation loss: 2.4218134828793105

Epoch: 6| Step: 2
Training loss: 3.178422212600708
Validation loss: 2.4249912897745767

Epoch: 6| Step: 3
Training loss: 2.1894145011901855
Validation loss: 2.4331499991878385

Epoch: 6| Step: 4
Training loss: 2.99039888381958
Validation loss: 2.433543171933902

Epoch: 6| Step: 5
Training loss: 3.2553181648254395
Validation loss: 2.4298082577284945

Epoch: 6| Step: 6
Training loss: 2.1681013107299805
Validation loss: 2.4270759628665064

Epoch: 6| Step: 7
Training loss: 2.680349588394165
Validation loss: 2.422465255183558

Epoch: 6| Step: 8
Training loss: 2.4899463653564453
Validation loss: 2.4149952421906176

Epoch: 6| Step: 9
Training loss: 2.6289868354797363
Validation loss: 2.4090476138617403

Epoch: 6| Step: 10
Training loss: 2.3491010665893555
Validation loss: 2.413124253672938

Epoch: 6| Step: 11
Training loss: 1.986616611480713
Validation loss: 2.4302220062542985

Epoch: 6| Step: 12
Training loss: 2.8248391151428223
Validation loss: 2.480348802381946

Epoch: 6| Step: 13
Training loss: 2.8732550144195557
Validation loss: 2.4901626161349717

Epoch: 22| Step: 0
Training loss: 2.7631475925445557
Validation loss: 2.4405053969352477

Epoch: 6| Step: 1
Training loss: 2.2433059215545654
Validation loss: 2.4091922877937235

Epoch: 6| Step: 2
Training loss: 3.800656318664551
Validation loss: 2.404121350216609

Epoch: 6| Step: 3
Training loss: 2.607821226119995
Validation loss: 2.407547620034987

Epoch: 6| Step: 4
Training loss: 2.5503525733947754
Validation loss: 2.417940861435347

Epoch: 6| Step: 5
Training loss: 2.1400396823883057
Validation loss: 2.436036935416601

Epoch: 6| Step: 6
Training loss: 2.776209831237793
Validation loss: 2.437461212117185

Epoch: 6| Step: 7
Training loss: 2.9460041522979736
Validation loss: 2.441727307534987

Epoch: 6| Step: 8
Training loss: 2.7894506454467773
Validation loss: 2.4370863335106963

Epoch: 6| Step: 9
Training loss: 2.4741930961608887
Validation loss: 2.425321703316063

Epoch: 6| Step: 10
Training loss: 2.5772743225097656
Validation loss: 2.419326364353139

Epoch: 6| Step: 11
Training loss: 2.2626380920410156
Validation loss: 2.4155651215584046

Epoch: 6| Step: 12
Training loss: 2.847288131713867
Validation loss: 2.413419428692069

Epoch: 6| Step: 13
Training loss: 2.55497145652771
Validation loss: 2.4258409033539476

Epoch: 23| Step: 0
Training loss: 2.7412047386169434
Validation loss: 2.4534310294735815

Epoch: 6| Step: 1
Training loss: 2.6144826412200928
Validation loss: 2.4944269170043287

Epoch: 6| Step: 2
Training loss: 2.985837697982788
Validation loss: 2.4762225638153734

Epoch: 6| Step: 3
Training loss: 2.1635661125183105
Validation loss: 2.426324139359177

Epoch: 6| Step: 4
Training loss: 2.6473121643066406
Validation loss: 2.4028739467743905

Epoch: 6| Step: 5
Training loss: 3.031567335128784
Validation loss: 2.3912650923575125

Epoch: 6| Step: 6
Training loss: 2.7297067642211914
Validation loss: 2.3833545202850015

Epoch: 6| Step: 7
Training loss: 3.0121660232543945
Validation loss: 2.403401995217928

Epoch: 6| Step: 8
Training loss: 2.6537933349609375
Validation loss: 2.380427957862936

Epoch: 6| Step: 9
Training loss: 2.448775053024292
Validation loss: 2.372704077792424

Epoch: 6| Step: 10
Training loss: 2.498483657836914
Validation loss: 2.3683705432440645

Epoch: 6| Step: 11
Training loss: 2.647705554962158
Validation loss: 2.3691327161686395

Epoch: 6| Step: 12
Training loss: 2.0802979469299316
Validation loss: 2.3640262721687235

Epoch: 6| Step: 13
Training loss: 3.0550482273101807
Validation loss: 2.367214120844359

Epoch: 24| Step: 0
Training loss: 2.7867164611816406
Validation loss: 2.3663300006620345

Epoch: 6| Step: 1
Training loss: 2.7951464653015137
Validation loss: 2.3659542760541363

Epoch: 6| Step: 2
Training loss: 2.6342263221740723
Validation loss: 2.3661327362060547

Epoch: 6| Step: 3
Training loss: 3.048905611038208
Validation loss: 2.364431268425398

Epoch: 6| Step: 4
Training loss: 2.7108354568481445
Validation loss: 2.3668786300125944

Epoch: 6| Step: 5
Training loss: 1.793620228767395
Validation loss: 2.3665170028645504

Epoch: 6| Step: 6
Training loss: 2.770185947418213
Validation loss: 2.3662161929633028

Epoch: 6| Step: 7
Training loss: 2.33797025680542
Validation loss: 2.365470899048672

Epoch: 6| Step: 8
Training loss: 1.9536030292510986
Validation loss: 2.3698184054384948

Epoch: 6| Step: 9
Training loss: 3.1330008506774902
Validation loss: 2.370317102760397

Epoch: 6| Step: 10
Training loss: 2.8266968727111816
Validation loss: 2.395264440967191

Epoch: 6| Step: 11
Training loss: 2.2668282985687256
Validation loss: 2.4063561616405362

Epoch: 6| Step: 12
Training loss: 3.3044989109039307
Validation loss: 2.442902975184943

Epoch: 6| Step: 13
Training loss: 2.301469326019287
Validation loss: 2.4213063178523893

Epoch: 25| Step: 0
Training loss: 2.322632074356079
Validation loss: 2.39643116663861

Epoch: 6| Step: 1
Training loss: 2.7200145721435547
Validation loss: 2.3774402295389483

Epoch: 6| Step: 2
Training loss: 2.954033374786377
Validation loss: 2.3671745638693533

Epoch: 6| Step: 3
Training loss: 2.718766212463379
Validation loss: 2.3587411936893257

Epoch: 6| Step: 4
Training loss: 2.562732458114624
Validation loss: 2.3507553172367874

Epoch: 6| Step: 5
Training loss: 1.7936714887619019
Validation loss: 2.3519037590231946

Epoch: 6| Step: 6
Training loss: 3.3468642234802246
Validation loss: 2.347468178759339

Epoch: 6| Step: 7
Training loss: 2.84946870803833
Validation loss: 2.354010025660197

Epoch: 6| Step: 8
Training loss: 2.2251291275024414
Validation loss: 2.3594141647379887

Epoch: 6| Step: 9
Training loss: 2.7354722023010254
Validation loss: 2.3586578087140153

Epoch: 6| Step: 10
Training loss: 2.6500895023345947
Validation loss: 2.349845588848155

Epoch: 6| Step: 11
Training loss: 2.3180904388427734
Validation loss: 2.3481385348945536

Epoch: 6| Step: 12
Training loss: 2.6571767330169678
Validation loss: 2.3479927560334564

Epoch: 6| Step: 13
Training loss: 3.0493505001068115
Validation loss: 2.346010108147898

Epoch: 26| Step: 0
Training loss: 2.490222454071045
Validation loss: 2.3499301518163374

Epoch: 6| Step: 1
Training loss: 2.0594053268432617
Validation loss: 2.3505147451995523

Epoch: 6| Step: 2
Training loss: 2.612889289855957
Validation loss: 2.3552487716879895

Epoch: 6| Step: 3
Training loss: 2.1262340545654297
Validation loss: 2.3549600621705413

Epoch: 6| Step: 4
Training loss: 2.492593765258789
Validation loss: 2.3581558248048187

Epoch: 6| Step: 5
Training loss: 2.896599769592285
Validation loss: 2.3522317230060534

Epoch: 6| Step: 6
Training loss: 3.3805904388427734
Validation loss: 2.3444391091664634

Epoch: 6| Step: 7
Training loss: 2.64241361618042
Validation loss: 2.344824396153932

Epoch: 6| Step: 8
Training loss: 2.5846543312072754
Validation loss: 2.341468366243506

Epoch: 6| Step: 9
Training loss: 2.1375644207000732
Validation loss: 2.3367909000765894

Epoch: 6| Step: 10
Training loss: 2.4104554653167725
Validation loss: 2.3382748903766757

Epoch: 6| Step: 11
Training loss: 3.3704113960266113
Validation loss: 2.3484187485069357

Epoch: 6| Step: 12
Training loss: 3.0014777183532715
Validation loss: 2.355441624118436

Epoch: 6| Step: 13
Training loss: 2.230463743209839
Validation loss: 2.3809654763949815

Epoch: 27| Step: 0
Training loss: 2.191436767578125
Validation loss: 2.389261886637698

Epoch: 6| Step: 1
Training loss: 2.3153085708618164
Validation loss: 2.361752197306643

Epoch: 6| Step: 2
Training loss: 2.804891586303711
Validation loss: 2.3600953753276537

Epoch: 6| Step: 3
Training loss: 2.473330020904541
Validation loss: 2.3506350786455217

Epoch: 6| Step: 4
Training loss: 2.6945645809173584
Validation loss: 2.3415830853164836

Epoch: 6| Step: 5
Training loss: 2.9262681007385254
Validation loss: 2.336060979033029

Epoch: 6| Step: 6
Training loss: 2.058131217956543
Validation loss: 2.333267504169095

Epoch: 6| Step: 7
Training loss: 3.1225180625915527
Validation loss: 2.3351859020930466

Epoch: 6| Step: 8
Training loss: 3.5308890342712402
Validation loss: 2.3347941188402075

Epoch: 6| Step: 9
Training loss: 2.3324944972991943
Validation loss: 2.3427936133518013

Epoch: 6| Step: 10
Training loss: 2.597838878631592
Validation loss: 2.349296001977818

Epoch: 6| Step: 11
Training loss: 2.096970558166504
Validation loss: 2.3478198769272014

Epoch: 6| Step: 12
Training loss: 2.68742036819458
Validation loss: 2.3504657540270077

Epoch: 6| Step: 13
Training loss: 3.028735637664795
Validation loss: 2.3436974248578473

Epoch: 28| Step: 0
Training loss: 2.878714084625244
Validation loss: 2.332245949775942

Epoch: 6| Step: 1
Training loss: 1.9294929504394531
Validation loss: 2.328353379362373

Epoch: 6| Step: 2
Training loss: 1.912291407585144
Validation loss: 2.3327005781153196

Epoch: 6| Step: 3
Training loss: 3.514235019683838
Validation loss: 2.349538526227397

Epoch: 6| Step: 4
Training loss: 3.41532039642334
Validation loss: 2.3942532334276425

Epoch: 6| Step: 5
Training loss: 2.318326473236084
Validation loss: 2.466411263711991

Epoch: 6| Step: 6
Training loss: 2.335005760192871
Validation loss: 2.4902026012379634

Epoch: 6| Step: 7
Training loss: 2.205432415008545
Validation loss: 2.4655291341966197

Epoch: 6| Step: 8
Training loss: 2.6755118370056152
Validation loss: 2.4333530446534515

Epoch: 6| Step: 9
Training loss: 2.7818238735198975
Validation loss: 2.376118060081236

Epoch: 6| Step: 10
Training loss: 1.828836441040039
Validation loss: 2.332251005275275

Epoch: 6| Step: 11
Training loss: 3.4288411140441895
Validation loss: 2.320593564741073

Epoch: 6| Step: 12
Training loss: 2.448253631591797
Validation loss: 2.3293209306655394

Epoch: 6| Step: 13
Training loss: 3.4763481616973877
Validation loss: 2.334894167479648

Epoch: 29| Step: 0
Training loss: 2.384979248046875
Validation loss: 2.339287106708814

Epoch: 6| Step: 1
Training loss: 3.137058734893799
Validation loss: 2.357886909156717

Epoch: 6| Step: 2
Training loss: 2.3746442794799805
Validation loss: 2.3816637787767636

Epoch: 6| Step: 3
Training loss: 3.0659542083740234
Validation loss: 2.404355425988474

Epoch: 6| Step: 4
Training loss: 2.7507591247558594
Validation loss: 2.371531378838324

Epoch: 6| Step: 5
Training loss: 1.9461179971694946
Validation loss: 2.332768378719207

Epoch: 6| Step: 6
Training loss: 2.3357419967651367
Validation loss: 2.338432051802194

Epoch: 6| Step: 7
Training loss: 3.1234278678894043
Validation loss: 2.358851786582701

Epoch: 6| Step: 8
Training loss: 2.0269646644592285
Validation loss: 2.39117859255883

Epoch: 6| Step: 9
Training loss: 2.9845237731933594
Validation loss: 2.4288479128191547

Epoch: 6| Step: 10
Training loss: 2.9156744480133057
Validation loss: 2.452739854012766

Epoch: 6| Step: 11
Training loss: 3.0707693099975586
Validation loss: 2.446695540540962

Epoch: 6| Step: 12
Training loss: 2.415104627609253
Validation loss: 2.4478428261254424

Epoch: 6| Step: 13
Training loss: 2.346248149871826
Validation loss: 2.4551902612050376

Epoch: 30| Step: 0
Training loss: 2.8489816188812256
Validation loss: 2.4856665390793995

Epoch: 6| Step: 1
Training loss: 3.1598007678985596
Validation loss: 2.483731985092163

Epoch: 6| Step: 2
Training loss: 1.43800687789917
Validation loss: 2.448516176592919

Epoch: 6| Step: 3
Training loss: 3.249784469604492
Validation loss: 2.4635581457486717

Epoch: 6| Step: 4
Training loss: 2.935271739959717
Validation loss: 2.418872130814419

Epoch: 6| Step: 5
Training loss: 2.7570340633392334
Validation loss: 2.367758230496478

Epoch: 6| Step: 6
Training loss: 2.3043160438537598
Validation loss: 2.3202313530829644

Epoch: 6| Step: 7
Training loss: 2.906165599822998
Validation loss: 2.3258122013461207

Epoch: 6| Step: 8
Training loss: 2.989908218383789
Validation loss: 2.345850513827416

Epoch: 6| Step: 9
Training loss: 3.2149524688720703
Validation loss: 2.3661702397049114

Epoch: 6| Step: 10
Training loss: 2.438538074493408
Validation loss: 2.4093237769219185

Epoch: 6| Step: 11
Training loss: 1.9926095008850098
Validation loss: 2.4105325078451507

Epoch: 6| Step: 12
Training loss: 2.201242446899414
Validation loss: 2.4544952684833157

Epoch: 6| Step: 13
Training loss: 2.7466373443603516
Validation loss: 2.4351938129753194

Epoch: 31| Step: 0
Training loss: 2.429452657699585
Validation loss: 2.398475229099233

Epoch: 6| Step: 1
Training loss: 2.8383193016052246
Validation loss: 2.3673760096232095

Epoch: 6| Step: 2
Training loss: 2.9048562049865723
Validation loss: 2.3514047438098538

Epoch: 6| Step: 3
Training loss: 2.8142430782318115
Validation loss: 2.3488625403373473

Epoch: 6| Step: 4
Training loss: 2.80716609954834
Validation loss: 2.361272652943929

Epoch: 6| Step: 5
Training loss: 2.9228811264038086
Validation loss: 2.3917854857701126

Epoch: 6| Step: 6
Training loss: 2.7590644359588623
Validation loss: 2.3680433432261148

Epoch: 6| Step: 7
Training loss: 3.024331569671631
Validation loss: 2.3496295713609263

Epoch: 6| Step: 8
Training loss: 2.002349853515625
Validation loss: 2.329019364490304

Epoch: 6| Step: 9
Training loss: 2.2163870334625244
Validation loss: 2.3083671587769703

Epoch: 6| Step: 10
Training loss: 2.507963180541992
Validation loss: 2.309116214834234

Epoch: 6| Step: 11
Training loss: 2.9354302883148193
Validation loss: 2.3111294623344176

Epoch: 6| Step: 12
Training loss: 2.197019577026367
Validation loss: 2.314370519371443

Epoch: 6| Step: 13
Training loss: 2.2591657638549805
Validation loss: 2.3170858198596584

Epoch: 32| Step: 0
Training loss: 2.208871841430664
Validation loss: 2.3125738738685526

Epoch: 6| Step: 1
Training loss: 2.844256639480591
Validation loss: 2.3076948786294587

Epoch: 6| Step: 2
Training loss: 2.3688957691192627
Validation loss: 2.305402668573523

Epoch: 6| Step: 3
Training loss: 2.5136475563049316
Validation loss: 2.3119807986802954

Epoch: 6| Step: 4
Training loss: 2.1596813201904297
Validation loss: 2.3229092756907144

Epoch: 6| Step: 5
Training loss: 1.9956908226013184
Validation loss: 2.341694075574157

Epoch: 6| Step: 6
Training loss: 2.7647480964660645
Validation loss: 2.3640710666615474

Epoch: 6| Step: 7
Training loss: 2.6865224838256836
Validation loss: 2.3826102031174528

Epoch: 6| Step: 8
Training loss: 3.121171474456787
Validation loss: 2.3642334938049316

Epoch: 6| Step: 9
Training loss: 3.150277853012085
Validation loss: 2.32325424942919

Epoch: 6| Step: 10
Training loss: 2.5428085327148438
Validation loss: 2.2994516818754134

Epoch: 6| Step: 11
Training loss: 2.280085325241089
Validation loss: 2.2932883911235358

Epoch: 6| Step: 12
Training loss: 2.678708553314209
Validation loss: 2.2974344722686277

Epoch: 6| Step: 13
Training loss: 3.555732250213623
Validation loss: 2.2939359962299304

Epoch: 33| Step: 0
Training loss: 2.089630603790283
Validation loss: 2.2938596792118524

Epoch: 6| Step: 1
Training loss: 2.822749137878418
Validation loss: 2.298591157441498

Epoch: 6| Step: 2
Training loss: 2.6999759674072266
Validation loss: 2.2951861043130197

Epoch: 6| Step: 3
Training loss: 2.415464401245117
Validation loss: 2.295820551533853

Epoch: 6| Step: 4
Training loss: 2.833129405975342
Validation loss: 2.293129259540189

Epoch: 6| Step: 5
Training loss: 2.1582388877868652
Validation loss: 2.294177088686215

Epoch: 6| Step: 6
Training loss: 2.581171989440918
Validation loss: 2.294668354013915

Epoch: 6| Step: 7
Training loss: 1.848698616027832
Validation loss: 2.292264820427023

Epoch: 6| Step: 8
Training loss: 2.5188891887664795
Validation loss: 2.2911176091881207

Epoch: 6| Step: 9
Training loss: 3.592487335205078
Validation loss: 2.289541203488586

Epoch: 6| Step: 10
Training loss: 2.53049898147583
Validation loss: 2.290984874130577

Epoch: 6| Step: 11
Training loss: 2.548463821411133
Validation loss: 2.2985298479757

Epoch: 6| Step: 12
Training loss: 2.8982696533203125
Validation loss: 2.3031512473219182

Epoch: 6| Step: 13
Training loss: 2.666313409805298
Validation loss: 2.3094793417120494

Epoch: 34| Step: 0
Training loss: 2.913839340209961
Validation loss: 2.298751176044505

Epoch: 6| Step: 1
Training loss: 2.3672900199890137
Validation loss: 2.3098324998732536

Epoch: 6| Step: 2
Training loss: 2.5309207439422607
Validation loss: 2.3139149322304675

Epoch: 6| Step: 3
Training loss: 3.2622408866882324
Validation loss: 2.31113927595077

Epoch: 6| Step: 4
Training loss: 2.585019826889038
Validation loss: 2.314582760616015

Epoch: 6| Step: 5
Training loss: 2.798633337020874
Validation loss: 2.3341839005870204

Epoch: 6| Step: 6
Training loss: 2.680753231048584
Validation loss: 2.3214554940500567

Epoch: 6| Step: 7
Training loss: 2.3521125316619873
Validation loss: 2.305514825287686

Epoch: 6| Step: 8
Training loss: 1.6756868362426758
Validation loss: 2.3028795462782665

Epoch: 6| Step: 9
Training loss: 2.722384452819824
Validation loss: 2.2866122620080107

Epoch: 6| Step: 10
Training loss: 2.4473233222961426
Validation loss: 2.283637459560107

Epoch: 6| Step: 11
Training loss: 2.1124863624572754
Validation loss: 2.2763859764222176

Epoch: 6| Step: 12
Training loss: 2.3841075897216797
Validation loss: 2.2724472399680846

Epoch: 6| Step: 13
Training loss: 3.284709930419922
Validation loss: 2.2789501195312827

Epoch: 35| Step: 0
Training loss: 2.4529852867126465
Validation loss: 2.279818711742278

Epoch: 6| Step: 1
Training loss: 3.3010854721069336
Validation loss: 2.2721358704310592

Epoch: 6| Step: 2
Training loss: 3.038107395172119
Validation loss: 2.272179954795427

Epoch: 6| Step: 3
Training loss: 2.363971471786499
Validation loss: 2.2710569289422806

Epoch: 6| Step: 4
Training loss: 3.0730671882629395
Validation loss: 2.2727506442736556

Epoch: 6| Step: 5
Training loss: 2.4671030044555664
Validation loss: 2.2776691657240673

Epoch: 6| Step: 6
Training loss: 2.17587947845459
Validation loss: 2.281943121264058

Epoch: 6| Step: 7
Training loss: 3.1157548427581787
Validation loss: 2.3095282277753277

Epoch: 6| Step: 8
Training loss: 2.4461536407470703
Validation loss: 2.3185546039253153

Epoch: 6| Step: 9
Training loss: 2.505693197250366
Validation loss: 2.3269753891934633

Epoch: 6| Step: 10
Training loss: 2.3348519802093506
Validation loss: 2.3302654694485407

Epoch: 6| Step: 11
Training loss: 1.9442503452301025
Validation loss: 2.3387478474647767

Epoch: 6| Step: 12
Training loss: 2.648447036743164
Validation loss: 2.327042536068988

Epoch: 6| Step: 13
Training loss: 1.9911240339279175
Validation loss: 2.2907676901868594

Epoch: 36| Step: 0
Training loss: 2.663841962814331
Validation loss: 2.3028392099565074

Epoch: 6| Step: 1
Training loss: 2.7235090732574463
Validation loss: 2.295178008335893

Epoch: 6| Step: 2
Training loss: 2.238543748855591
Validation loss: 2.2893982830867974

Epoch: 6| Step: 3
Training loss: 3.3340892791748047
Validation loss: 2.301039570121355

Epoch: 6| Step: 4
Training loss: 2.7745437622070312
Validation loss: 2.3139279709067395

Epoch: 6| Step: 5
Training loss: 2.5360934734344482
Validation loss: 2.307015365169894

Epoch: 6| Step: 6
Training loss: 2.1484920978546143
Validation loss: 2.3097505223366523

Epoch: 6| Step: 7
Training loss: 2.579881191253662
Validation loss: 2.2989584630535496

Epoch: 6| Step: 8
Training loss: 2.1593260765075684
Validation loss: 2.2879130840301514

Epoch: 6| Step: 9
Training loss: 2.095313549041748
Validation loss: 2.2780872839753346

Epoch: 6| Step: 10
Training loss: 2.8263931274414062
Validation loss: 2.2804548509659304

Epoch: 6| Step: 11
Training loss: 2.746009349822998
Validation loss: 2.269457055676368

Epoch: 6| Step: 12
Training loss: 3.0896849632263184
Validation loss: 2.27432684488194

Epoch: 6| Step: 13
Training loss: 1.4824117422103882
Validation loss: 2.283067833992743

Epoch: 37| Step: 0
Training loss: 2.805751323699951
Validation loss: 2.265584231704794

Epoch: 6| Step: 1
Training loss: 2.7348732948303223
Validation loss: 2.258356942925402

Epoch: 6| Step: 2
Training loss: 2.8043060302734375
Validation loss: 2.2541354138364076

Epoch: 6| Step: 3
Training loss: 2.4802939891815186
Validation loss: 2.253027960818301

Epoch: 6| Step: 4
Training loss: 2.375652313232422
Validation loss: 2.25017608622069

Epoch: 6| Step: 5
Training loss: 2.3616952896118164
Validation loss: 2.2488095709072646

Epoch: 6| Step: 6
Training loss: 2.5561575889587402
Validation loss: 2.2480187762168145

Epoch: 6| Step: 7
Training loss: 1.6684353351593018
Validation loss: 2.2619971408638904

Epoch: 6| Step: 8
Training loss: 2.800507068634033
Validation loss: 2.273592754076886

Epoch: 6| Step: 9
Training loss: 3.0545060634613037
Validation loss: 2.2793513074997933

Epoch: 6| Step: 10
Training loss: 2.240208387374878
Validation loss: 2.26870140593539

Epoch: 6| Step: 11
Training loss: 2.648928165435791
Validation loss: 2.2577185169343026

Epoch: 6| Step: 12
Training loss: 2.7482032775878906
Validation loss: 2.2498193812626663

Epoch: 6| Step: 13
Training loss: 2.347214937210083
Validation loss: 2.2420151195218487

Epoch: 38| Step: 0
Training loss: 2.6740283966064453
Validation loss: 2.263298346150306

Epoch: 6| Step: 1
Training loss: 2.366633415222168
Validation loss: 2.274552209402925

Epoch: 6| Step: 2
Training loss: 2.847510814666748
Validation loss: 2.298942294172061

Epoch: 6| Step: 3
Training loss: 2.7647595405578613
Validation loss: 2.297289679127355

Epoch: 6| Step: 4
Training loss: 1.941786527633667
Validation loss: 2.2430925958900043

Epoch: 6| Step: 5
Training loss: 2.74100399017334
Validation loss: 2.2438688560198714

Epoch: 6| Step: 6
Training loss: 2.787047863006592
Validation loss: 2.247437471984535

Epoch: 6| Step: 7
Training loss: 2.5132806301116943
Validation loss: 2.2502188323646464

Epoch: 6| Step: 8
Training loss: 2.4608421325683594
Validation loss: 2.2548505311371176

Epoch: 6| Step: 9
Training loss: 2.4562830924987793
Validation loss: 2.2684459558097263

Epoch: 6| Step: 10
Training loss: 2.8974084854125977
Validation loss: 2.2879322459620814

Epoch: 6| Step: 11
Training loss: 2.3575730323791504
Validation loss: 2.3185492279709026

Epoch: 6| Step: 12
Training loss: 1.7348883152008057
Validation loss: 2.330951039509107

Epoch: 6| Step: 13
Training loss: 3.6060383319854736
Validation loss: 2.338723567224318

Epoch: 39| Step: 0
Training loss: 2.0418171882629395
Validation loss: 2.3695796023132982

Epoch: 6| Step: 1
Training loss: 2.0620462894439697
Validation loss: 2.389872053618072

Epoch: 6| Step: 2
Training loss: 1.9492287635803223
Validation loss: 2.387778256529121

Epoch: 6| Step: 3
Training loss: 2.6178746223449707
Validation loss: 2.3231363963055354

Epoch: 6| Step: 4
Training loss: 2.8070132732391357
Validation loss: 2.274282686171993

Epoch: 6| Step: 5
Training loss: 2.9340226650238037
Validation loss: 2.257317651984512

Epoch: 6| Step: 6
Training loss: 2.267508029937744
Validation loss: 2.270524142890848

Epoch: 6| Step: 7
Training loss: 3.042860507965088
Validation loss: 2.298293835373335

Epoch: 6| Step: 8
Training loss: 2.057936668395996
Validation loss: 2.3097677717926683

Epoch: 6| Step: 9
Training loss: 2.9424262046813965
Validation loss: 2.296735689204226

Epoch: 6| Step: 10
Training loss: 2.713430643081665
Validation loss: 2.282904722357309

Epoch: 6| Step: 11
Training loss: 2.4501638412475586
Validation loss: 2.2668083765173472

Epoch: 6| Step: 12
Training loss: 2.7123899459838867
Validation loss: 2.228424387593423

Epoch: 6| Step: 13
Training loss: 4.443809509277344
Validation loss: 2.224082144357825

Epoch: 40| Step: 0
Training loss: 2.7590932846069336
Validation loss: 2.2296724998822777

Epoch: 6| Step: 1
Training loss: 2.0263466835021973
Validation loss: 2.2376914588353967

Epoch: 6| Step: 2
Training loss: 2.19288969039917
Validation loss: 2.2499345374363724

Epoch: 6| Step: 3
Training loss: 3.5569677352905273
Validation loss: 2.253103304934758

Epoch: 6| Step: 4
Training loss: 2.859581470489502
Validation loss: 2.265283884540681

Epoch: 6| Step: 5
Training loss: 2.722323179244995
Validation loss: 2.2698074566420687

Epoch: 6| Step: 6
Training loss: 3.1125106811523438
Validation loss: 2.2719105084737143

Epoch: 6| Step: 7
Training loss: 2.0644824504852295
Validation loss: 2.2554789256024104

Epoch: 6| Step: 8
Training loss: 2.096827507019043
Validation loss: 2.237511732245004

Epoch: 6| Step: 9
Training loss: 2.5557868480682373
Validation loss: 2.223107432806364

Epoch: 6| Step: 10
Training loss: 2.2624640464782715
Validation loss: 2.222142086234144

Epoch: 6| Step: 11
Training loss: 2.452455759048462
Validation loss: 2.2154327118268577

Epoch: 6| Step: 12
Training loss: 2.105499267578125
Validation loss: 2.211051292316888

Epoch: 6| Step: 13
Training loss: 3.168914318084717
Validation loss: 2.2112887636307748

Epoch: 41| Step: 0
Training loss: 2.597268581390381
Validation loss: 2.2204355244995444

Epoch: 6| Step: 1
Training loss: 2.8812828063964844
Validation loss: 2.2317107262149936

Epoch: 6| Step: 2
Training loss: 1.8911635875701904
Validation loss: 2.2673289878394014

Epoch: 6| Step: 3
Training loss: 2.622892379760742
Validation loss: 2.3558332381709928

Epoch: 6| Step: 4
Training loss: 2.6248414516448975
Validation loss: 2.45520519697538

Epoch: 6| Step: 5
Training loss: 2.413649559020996
Validation loss: 2.490219026483515

Epoch: 6| Step: 6
Training loss: 3.0805015563964844
Validation loss: 2.368570384158883

Epoch: 6| Step: 7
Training loss: 2.5942373275756836
Validation loss: 2.3194402674193024

Epoch: 6| Step: 8
Training loss: 3.291355609893799
Validation loss: 2.2724986819810766

Epoch: 6| Step: 9
Training loss: 2.1923270225524902
Validation loss: 2.2216079004349245

Epoch: 6| Step: 10
Training loss: 2.2997090816497803
Validation loss: 2.231769161839639

Epoch: 6| Step: 11
Training loss: 2.5355451107025146
Validation loss: 2.2514625416007092

Epoch: 6| Step: 12
Training loss: 2.6352295875549316
Validation loss: 2.2639775917094243

Epoch: 6| Step: 13
Training loss: 2.333091974258423
Validation loss: 2.2754414440483175

Epoch: 42| Step: 0
Training loss: 2.5089898109436035
Validation loss: 2.277147344363633

Epoch: 6| Step: 1
Training loss: 2.071356773376465
Validation loss: 2.2644777579974105

Epoch: 6| Step: 2
Training loss: 2.470254898071289
Validation loss: 2.2615830334283973

Epoch: 6| Step: 3
Training loss: 2.3286149501800537
Validation loss: 2.2701756749101865

Epoch: 6| Step: 4
Training loss: 2.7693862915039062
Validation loss: 2.302661026677778

Epoch: 6| Step: 5
Training loss: 2.3354551792144775
Validation loss: 2.378765506129111

Epoch: 6| Step: 6
Training loss: 2.6101269721984863
Validation loss: 2.4235843945575017

Epoch: 6| Step: 7
Training loss: 2.2976138591766357
Validation loss: 2.4387885626926216

Epoch: 6| Step: 8
Training loss: 3.5203566551208496
Validation loss: 2.4073163668314614

Epoch: 6| Step: 9
Training loss: 2.5437750816345215
Validation loss: 2.347437450962682

Epoch: 6| Step: 10
Training loss: 2.535182476043701
Validation loss: 2.3517958528252056

Epoch: 6| Step: 11
Training loss: 2.342857837677002
Validation loss: 2.324385432786839

Epoch: 6| Step: 12
Training loss: 2.8593955039978027
Validation loss: 2.2639871335798696

Epoch: 6| Step: 13
Training loss: 2.7314906120300293
Validation loss: 2.2078490462354434

Epoch: 43| Step: 0
Training loss: 1.8882137537002563
Validation loss: 2.1932387864717873

Epoch: 6| Step: 1
Training loss: 2.985731363296509
Validation loss: 2.1959404894100722

Epoch: 6| Step: 2
Training loss: 3.2824692726135254
Validation loss: 2.2040218191762126

Epoch: 6| Step: 3
Training loss: 2.603130578994751
Validation loss: 2.207042973528626

Epoch: 6| Step: 4
Training loss: 2.905163049697876
Validation loss: 2.212350049326497

Epoch: 6| Step: 5
Training loss: 2.0988128185272217
Validation loss: 2.216213298100297

Epoch: 6| Step: 6
Training loss: 3.3880434036254883
Validation loss: 2.2119035131187847

Epoch: 6| Step: 7
Training loss: 1.7626203298568726
Validation loss: 2.2046513044705955

Epoch: 6| Step: 8
Training loss: 2.751709461212158
Validation loss: 2.207892123089042

Epoch: 6| Step: 9
Training loss: 2.3589320182800293
Validation loss: 2.1992471551382415

Epoch: 6| Step: 10
Training loss: 2.3037149906158447
Validation loss: 2.2045630037143664

Epoch: 6| Step: 11
Training loss: 2.1303811073303223
Validation loss: 2.2127815138909126

Epoch: 6| Step: 12
Training loss: 2.031182050704956
Validation loss: 2.2136850062236992

Epoch: 6| Step: 13
Training loss: 3.610356330871582
Validation loss: 2.2261312853905464

Epoch: 44| Step: 0
Training loss: 2.0122241973876953
Validation loss: 2.2511123175262124

Epoch: 6| Step: 1
Training loss: 3.4022698402404785
Validation loss: 2.2700388931458995

Epoch: 6| Step: 2
Training loss: 2.236365556716919
Validation loss: 2.2908287125249065

Epoch: 6| Step: 3
Training loss: 2.339308500289917
Validation loss: 2.2594645664256108

Epoch: 6| Step: 4
Training loss: 3.012772560119629
Validation loss: 2.2505707074237127

Epoch: 6| Step: 5
Training loss: 2.2123892307281494
Validation loss: 2.255948951167445

Epoch: 6| Step: 6
Training loss: 3.001345157623291
Validation loss: 2.2396200036489837

Epoch: 6| Step: 7
Training loss: 2.5799736976623535
Validation loss: 2.239363096093619

Epoch: 6| Step: 8
Training loss: 2.3164000511169434
Validation loss: 2.2231755243834628

Epoch: 6| Step: 9
Training loss: 1.6631813049316406
Validation loss: 2.1958859812828804

Epoch: 6| Step: 10
Training loss: 3.086671829223633
Validation loss: 2.1795006170067737

Epoch: 6| Step: 11
Training loss: 2.237588882446289
Validation loss: 2.1746853090101674

Epoch: 6| Step: 12
Training loss: 2.455953598022461
Validation loss: 2.17535114031966

Epoch: 6| Step: 13
Training loss: 3.1085195541381836
Validation loss: 2.1700982816757692

Epoch: 45| Step: 0
Training loss: 2.8962717056274414
Validation loss: 2.1685207710471204

Epoch: 6| Step: 1
Training loss: 2.3129324913024902
Validation loss: 2.166001122484925

Epoch: 6| Step: 2
Training loss: 2.921931505203247
Validation loss: 2.1649703928219375

Epoch: 6| Step: 3
Training loss: 2.310122489929199
Validation loss: 2.1696113283916185

Epoch: 6| Step: 4
Training loss: 2.409351348876953
Validation loss: 2.1733882145215104

Epoch: 6| Step: 5
Training loss: 2.229241371154785
Validation loss: 2.183149230095648

Epoch: 6| Step: 6
Training loss: 1.7681806087493896
Validation loss: 2.193193402341617

Epoch: 6| Step: 7
Training loss: 2.585782766342163
Validation loss: 2.187823203302199

Epoch: 6| Step: 8
Training loss: 2.448910713195801
Validation loss: 2.190500456799743

Epoch: 6| Step: 9
Training loss: 2.589460849761963
Validation loss: 2.187904809110908

Epoch: 6| Step: 10
Training loss: 2.505923271179199
Validation loss: 2.1759330572620517

Epoch: 6| Step: 11
Training loss: 2.549020290374756
Validation loss: 2.1674877366712018

Epoch: 6| Step: 12
Training loss: 2.5905823707580566
Validation loss: 2.1719793222283803

Epoch: 6| Step: 13
Training loss: 3.2290329933166504
Validation loss: 2.178520102654734

Epoch: 46| Step: 0
Training loss: 2.889349937438965
Validation loss: 2.1919804414113364

Epoch: 6| Step: 1
Training loss: 2.6405837535858154
Validation loss: 2.199176647329843

Epoch: 6| Step: 2
Training loss: 1.973731517791748
Validation loss: 2.195806141822569

Epoch: 6| Step: 3
Training loss: 3.187379837036133
Validation loss: 2.195594972179782

Epoch: 6| Step: 4
Training loss: 2.260413885116577
Validation loss: 2.188911743061517

Epoch: 6| Step: 5
Training loss: 2.6410975456237793
Validation loss: 2.2194030951428156

Epoch: 6| Step: 6
Training loss: 2.7652206420898438
Validation loss: 2.1897031568711802

Epoch: 6| Step: 7
Training loss: 2.104862928390503
Validation loss: 2.149276198879365

Epoch: 6| Step: 8
Training loss: 1.7765446901321411
Validation loss: 2.1331351662194855

Epoch: 6| Step: 9
Training loss: 3.024373769760132
Validation loss: 2.138921355688444

Epoch: 6| Step: 10
Training loss: 2.578293800354004
Validation loss: 2.1386716545269056

Epoch: 6| Step: 11
Training loss: 2.7567992210388184
Validation loss: 2.15635956487348

Epoch: 6| Step: 12
Training loss: 2.59181547164917
Validation loss: 2.161326516059137

Epoch: 6| Step: 13
Training loss: 1.2706007957458496
Validation loss: 2.1487756031815723

Epoch: 47| Step: 0
Training loss: 1.862783670425415
Validation loss: 2.1364238108358076

Epoch: 6| Step: 1
Training loss: 2.223633289337158
Validation loss: 2.128978926648376

Epoch: 6| Step: 2
Training loss: 2.3330600261688232
Validation loss: 2.1319486351423365

Epoch: 6| Step: 3
Training loss: 3.1215054988861084
Validation loss: 2.1616686621019916

Epoch: 6| Step: 4
Training loss: 2.4682393074035645
Validation loss: 2.1872469866147606

Epoch: 6| Step: 5
Training loss: 2.6853270530700684
Validation loss: 2.2180832124525502

Epoch: 6| Step: 6
Training loss: 2.294778823852539
Validation loss: 2.23998067455907

Epoch: 6| Step: 7
Training loss: 3.0832133293151855
Validation loss: 2.262042409630232

Epoch: 6| Step: 8
Training loss: 2.2006237506866455
Validation loss: 2.242329643618676

Epoch: 6| Step: 9
Training loss: 2.7398815155029297
Validation loss: 2.251438538233439

Epoch: 6| Step: 10
Training loss: 2.666708469390869
Validation loss: 2.237822676217684

Epoch: 6| Step: 11
Training loss: 2.5218138694763184
Validation loss: 2.2257983030811435

Epoch: 6| Step: 12
Training loss: 2.3136773109436035
Validation loss: 2.204363303799783

Epoch: 6| Step: 13
Training loss: 2.870222806930542
Validation loss: 2.1872968442978395

Epoch: 48| Step: 0
Training loss: 2.5584750175476074
Validation loss: 2.173461006533715

Epoch: 6| Step: 1
Training loss: 2.3011202812194824
Validation loss: 2.1593713709103164

Epoch: 6| Step: 2
Training loss: 2.706512689590454
Validation loss: 2.1504826366260485

Epoch: 6| Step: 3
Training loss: 2.977020025253296
Validation loss: 2.1494059126864196

Epoch: 6| Step: 4
Training loss: 3.075310230255127
Validation loss: 2.1438772498920398

Epoch: 6| Step: 5
Training loss: 2.2941503524780273
Validation loss: 2.1370980444774834

Epoch: 6| Step: 6
Training loss: 2.384580612182617
Validation loss: 2.134848360092409

Epoch: 6| Step: 7
Training loss: 2.2202095985412598
Validation loss: 2.135542397857994

Epoch: 6| Step: 8
Training loss: 2.7634758949279785
Validation loss: 2.125398620482414

Epoch: 6| Step: 9
Training loss: 2.4613542556762695
Validation loss: 2.1283137157399166

Epoch: 6| Step: 10
Training loss: 2.133078098297119
Validation loss: 2.1251014535145094

Epoch: 6| Step: 11
Training loss: 2.1347599029541016
Validation loss: 2.119947789817728

Epoch: 6| Step: 12
Training loss: 2.079714059829712
Validation loss: 2.1195174801734185

Epoch: 6| Step: 13
Training loss: 2.9013421535491943
Validation loss: 2.1184421726452407

Epoch: 49| Step: 0
Training loss: 2.1959643363952637
Validation loss: 2.117745332820441

Epoch: 6| Step: 1
Training loss: 2.899397134780884
Validation loss: 2.1191742240741687

Epoch: 6| Step: 2
Training loss: 2.3613243103027344
Validation loss: 2.115837001031445

Epoch: 6| Step: 3
Training loss: 2.3981969356536865
Validation loss: 2.1196380328106623

Epoch: 6| Step: 4
Training loss: 2.2352614402770996
Validation loss: 2.1181015250503377

Epoch: 6| Step: 5
Training loss: 2.3786158561706543
Validation loss: 2.1210471481405277

Epoch: 6| Step: 6
Training loss: 2.362277030944824
Validation loss: 2.1281602075023036

Epoch: 6| Step: 7
Training loss: 2.099916934967041
Validation loss: 2.146935639842864

Epoch: 6| Step: 8
Training loss: 2.546516180038452
Validation loss: 2.16136025228808

Epoch: 6| Step: 9
Training loss: 2.147313117980957
Validation loss: 2.179204979250508

Epoch: 6| Step: 10
Training loss: 2.4758310317993164
Validation loss: 2.219795714142502

Epoch: 6| Step: 11
Training loss: 3.257568359375
Validation loss: 2.229253912484774

Epoch: 6| Step: 12
Training loss: 2.448122501373291
Validation loss: 2.228600848105646

Epoch: 6| Step: 13
Training loss: 3.3318724632263184
Validation loss: 2.222287493367349

Epoch: 50| Step: 0
Training loss: 2.4925711154937744
Validation loss: 2.216414149089526

Epoch: 6| Step: 1
Training loss: 2.2582831382751465
Validation loss: 2.178463707688034

Epoch: 6| Step: 2
Training loss: 2.021817207336426
Validation loss: 2.1238251860423754

Epoch: 6| Step: 3
Training loss: 1.8890838623046875
Validation loss: 2.104179431033391

Epoch: 6| Step: 4
Training loss: 2.6285197734832764
Validation loss: 2.100189490984845

Epoch: 6| Step: 5
Training loss: 2.1302623748779297
Validation loss: 2.0997314286488358

Epoch: 6| Step: 6
Training loss: 2.754148006439209
Validation loss: 2.0978170082133305

Epoch: 6| Step: 7
Training loss: 2.5628838539123535
Validation loss: 2.101282504297072

Epoch: 6| Step: 8
Training loss: 3.000363349914551
Validation loss: 2.1063807625924387

Epoch: 6| Step: 9
Training loss: 2.649280071258545
Validation loss: 2.1070840051097255

Epoch: 6| Step: 10
Training loss: 2.344350576400757
Validation loss: 2.12110460189081

Epoch: 6| Step: 11
Training loss: 2.677302837371826
Validation loss: 2.1082050710596065

Epoch: 6| Step: 12
Training loss: 2.8930251598358154
Validation loss: 2.0997654866146784

Epoch: 6| Step: 13
Training loss: 2.71768856048584
Validation loss: 2.0983263843802997

Epoch: 51| Step: 0
Training loss: 2.936415433883667
Validation loss: 2.10016708220205

Epoch: 6| Step: 1
Training loss: 2.3465542793273926
Validation loss: 2.1193907260894775

Epoch: 6| Step: 2
Training loss: 2.0994620323181152
Validation loss: 2.147718446229094

Epoch: 6| Step: 3
Training loss: 2.0675296783447266
Validation loss: 2.163553052051093

Epoch: 6| Step: 4
Training loss: 2.145634174346924
Validation loss: 2.1877409976015807

Epoch: 6| Step: 5
Training loss: 2.657496929168701
Validation loss: 2.211745685146701

Epoch: 6| Step: 6
Training loss: 2.11838436126709
Validation loss: 2.251269212333105

Epoch: 6| Step: 7
Training loss: 3.031102180480957
Validation loss: 2.261664657182591

Epoch: 6| Step: 8
Training loss: 2.6070632934570312
Validation loss: 2.3038214893751245

Epoch: 6| Step: 9
Training loss: 2.455554485321045
Validation loss: 2.288077744104529

Epoch: 6| Step: 10
Training loss: 2.7500507831573486
Validation loss: 2.2590376074596117

Epoch: 6| Step: 11
Training loss: 2.681154251098633
Validation loss: 2.2071576015923613

Epoch: 6| Step: 12
Training loss: 2.31917142868042
Validation loss: 2.1627740065256753

Epoch: 6| Step: 13
Training loss: 2.254469156265259
Validation loss: 2.1261783107634513

Epoch: 52| Step: 0
Training loss: 2.869719982147217
Validation loss: 2.094049511417266

Epoch: 6| Step: 1
Training loss: 2.357445240020752
Validation loss: 2.0997575021559194

Epoch: 6| Step: 2
Training loss: 2.58756685256958
Validation loss: 2.110643735495947

Epoch: 6| Step: 3
Training loss: 2.4875998497009277
Validation loss: 2.126593379564183

Epoch: 6| Step: 4
Training loss: 2.683800458908081
Validation loss: 2.1582630603544173

Epoch: 6| Step: 5
Training loss: 2.637242317199707
Validation loss: 2.189781709383893

Epoch: 6| Step: 6
Training loss: 2.3139474391937256
Validation loss: 2.23884347433685

Epoch: 6| Step: 7
Training loss: 2.1845717430114746
Validation loss: 2.2491588464347263

Epoch: 6| Step: 8
Training loss: 2.5730340480804443
Validation loss: 2.2584931106977564

Epoch: 6| Step: 9
Training loss: 3.3662917613983154
Validation loss: 2.194701163999496

Epoch: 6| Step: 10
Training loss: 2.669823408126831
Validation loss: 2.138953560142107

Epoch: 6| Step: 11
Training loss: 2.353618860244751
Validation loss: 2.1170440732791858

Epoch: 6| Step: 12
Training loss: 2.2713775634765625
Validation loss: 2.0984198329269246

Epoch: 6| Step: 13
Training loss: 2.352898597717285
Validation loss: 2.0970808562412055

Epoch: 53| Step: 0
Training loss: 2.3584747314453125
Validation loss: 2.1277807604882026

Epoch: 6| Step: 1
Training loss: 3.225281238555908
Validation loss: 2.1929004038533857

Epoch: 6| Step: 2
Training loss: 2.765113592147827
Validation loss: 2.279864902137428

Epoch: 6| Step: 3
Training loss: 2.618816614151001
Validation loss: 2.315359489892119

Epoch: 6| Step: 4
Training loss: 1.9495506286621094
Validation loss: 2.303667281263618

Epoch: 6| Step: 5
Training loss: 2.9427390098571777
Validation loss: 2.218794758601855

Epoch: 6| Step: 6
Training loss: 1.7156100273132324
Validation loss: 2.168827541412846

Epoch: 6| Step: 7
Training loss: 2.617335319519043
Validation loss: 2.118220293393699

Epoch: 6| Step: 8
Training loss: 2.4346303939819336
Validation loss: 2.098185654609434

Epoch: 6| Step: 9
Training loss: 2.142333507537842
Validation loss: 2.082636007698633

Epoch: 6| Step: 10
Training loss: 2.647559881210327
Validation loss: 2.083325796229865

Epoch: 6| Step: 11
Training loss: 2.6461691856384277
Validation loss: 2.085158448065481

Epoch: 6| Step: 12
Training loss: 1.7904471158981323
Validation loss: 2.0829071229504

Epoch: 6| Step: 13
Training loss: 2.9587316513061523
Validation loss: 2.0879536469777427

Epoch: 54| Step: 0
Training loss: 2.6057910919189453
Validation loss: 2.0849036144953903

Epoch: 6| Step: 1
Training loss: 2.2116775512695312
Validation loss: 2.0884846448898315

Epoch: 6| Step: 2
Training loss: 2.165459632873535
Validation loss: 2.091876276077763

Epoch: 6| Step: 3
Training loss: 2.8642354011535645
Validation loss: 2.0974951226224183

Epoch: 6| Step: 4
Training loss: 2.3373875617980957
Validation loss: 2.1016480230516

Epoch: 6| Step: 5
Training loss: 2.7979259490966797
Validation loss: 2.100369522648473

Epoch: 6| Step: 6
Training loss: 2.641117572784424
Validation loss: 2.09498078848726

Epoch: 6| Step: 7
Training loss: 2.8624494075775146
Validation loss: 2.08695702527159

Epoch: 6| Step: 8
Training loss: 2.4544849395751953
Validation loss: 2.0893093206549205

Epoch: 6| Step: 9
Training loss: 2.661228895187378
Validation loss: 2.0843320072338147

Epoch: 6| Step: 10
Training loss: 1.9248309135437012
Validation loss: 2.078707404034112

Epoch: 6| Step: 11
Training loss: 1.8760583400726318
Validation loss: 2.0799836061334096

Epoch: 6| Step: 12
Training loss: 3.1142778396606445
Validation loss: 2.074396338514102

Epoch: 6| Step: 13
Training loss: 2.33268141746521
Validation loss: 2.086548638600175

Epoch: 55| Step: 0
Training loss: 1.938405990600586
Validation loss: 2.102302330796437

Epoch: 6| Step: 1
Training loss: 2.493548631668091
Validation loss: 2.125656174075219

Epoch: 6| Step: 2
Training loss: 2.599132537841797
Validation loss: 2.1061415672302246

Epoch: 6| Step: 3
Training loss: 2.2004120349884033
Validation loss: 2.100706720864901

Epoch: 6| Step: 4
Training loss: 1.9451870918273926
Validation loss: 2.0959337936934603

Epoch: 6| Step: 5
Training loss: 3.0311288833618164
Validation loss: 2.100052100355907

Epoch: 6| Step: 6
Training loss: 2.529534339904785
Validation loss: 2.0777881504386984

Epoch: 6| Step: 7
Training loss: 2.6304268836975098
Validation loss: 2.0788745072580155

Epoch: 6| Step: 8
Training loss: 2.5032618045806885
Validation loss: 2.076805007073187

Epoch: 6| Step: 9
Training loss: 2.599579334259033
Validation loss: 2.082227119835474

Epoch: 6| Step: 10
Training loss: 2.3309335708618164
Validation loss: 2.0806467097292662

Epoch: 6| Step: 11
Training loss: 3.2723772525787354
Validation loss: 2.0765775724123885

Epoch: 6| Step: 12
Training loss: 2.2990193367004395
Validation loss: 2.0710625571589314

Epoch: 6| Step: 13
Training loss: 1.3592665195465088
Validation loss: 2.072951275815246

Epoch: 56| Step: 0
Training loss: 1.8249144554138184
Validation loss: 2.0834920406341553

Epoch: 6| Step: 1
Training loss: 2.942129611968994
Validation loss: 2.1053160198273195

Epoch: 6| Step: 2
Training loss: 2.881110668182373
Validation loss: 2.1267353898735455

Epoch: 6| Step: 3
Training loss: 2.032756805419922
Validation loss: 2.172408265452231

Epoch: 6| Step: 4
Training loss: 2.6768641471862793
Validation loss: 2.1552311861386864

Epoch: 6| Step: 5
Training loss: 2.589437246322632
Validation loss: 2.0952589870781027

Epoch: 6| Step: 6
Training loss: 1.9791488647460938
Validation loss: 2.0771053632100425

Epoch: 6| Step: 7
Training loss: 2.6241559982299805
Validation loss: 2.0757592749852005

Epoch: 6| Step: 8
Training loss: 2.778371810913086
Validation loss: 2.0713049545082995

Epoch: 6| Step: 9
Training loss: 1.443488359451294
Validation loss: 2.065089802588186

Epoch: 6| Step: 10
Training loss: 2.840662956237793
Validation loss: 2.068356094821807

Epoch: 6| Step: 11
Training loss: 2.5065345764160156
Validation loss: 2.0633316040039062

Epoch: 6| Step: 12
Training loss: 2.736269474029541
Validation loss: 2.066075937722319

Epoch: 6| Step: 13
Training loss: 2.2887144088745117
Validation loss: 2.065338200138461

Epoch: 57| Step: 0
Training loss: 2.277406692504883
Validation loss: 2.0641566271423013

Epoch: 6| Step: 1
Training loss: 2.101073741912842
Validation loss: 2.0636052239325737

Epoch: 6| Step: 2
Training loss: 2.2778754234313965
Validation loss: 2.076425120394717

Epoch: 6| Step: 3
Training loss: 3.0005712509155273
Validation loss: 2.0814848728077386

Epoch: 6| Step: 4
Training loss: 1.8318029642105103
Validation loss: 2.1103836746626

Epoch: 6| Step: 5
Training loss: 2.6498990058898926
Validation loss: 2.1411209106445312

Epoch: 6| Step: 6
Training loss: 2.3343639373779297
Validation loss: 2.1451568013878277

Epoch: 6| Step: 7
Training loss: 2.3282785415649414
Validation loss: 2.15704055242641

Epoch: 6| Step: 8
Training loss: 1.9713900089263916
Validation loss: 2.156116934232814

Epoch: 6| Step: 9
Training loss: 1.6385891437530518
Validation loss: 2.126478100335726

Epoch: 6| Step: 10
Training loss: 2.887239456176758
Validation loss: 2.1077429697077763

Epoch: 6| Step: 11
Training loss: 3.010396957397461
Validation loss: 2.0858175767365323

Epoch: 6| Step: 12
Training loss: 3.0737462043762207
Validation loss: 2.0630487780417166

Epoch: 6| Step: 13
Training loss: 2.813307762145996
Validation loss: 2.0594738747483943

Epoch: 58| Step: 0
Training loss: 2.545215606689453
Validation loss: 2.059615529993529

Epoch: 6| Step: 1
Training loss: 2.2282626628875732
Validation loss: 2.0534233431662283

Epoch: 6| Step: 2
Training loss: 2.39939022064209
Validation loss: 2.058612269739951

Epoch: 6| Step: 3
Training loss: 2.4898135662078857
Validation loss: 2.055431124984577

Epoch: 6| Step: 4
Training loss: 2.773665189743042
Validation loss: 2.0592178016580562

Epoch: 6| Step: 5
Training loss: 2.127819299697876
Validation loss: 2.065134620153776

Epoch: 6| Step: 6
Training loss: 1.8246417045593262
Validation loss: 2.074616579599278

Epoch: 6| Step: 7
Training loss: 2.004037380218506
Validation loss: 2.1221825666325067

Epoch: 6| Step: 8
Training loss: 2.5624661445617676
Validation loss: 2.1453626412217335

Epoch: 6| Step: 9
Training loss: 3.3663759231567383
Validation loss: 2.198680776421742

Epoch: 6| Step: 10
Training loss: 2.2948198318481445
Validation loss: 2.2599489099235943

Epoch: 6| Step: 11
Training loss: 1.7210074663162231
Validation loss: 2.3293439829221336

Epoch: 6| Step: 12
Training loss: 2.539900064468384
Validation loss: 2.4038049328711724

Epoch: 6| Step: 13
Training loss: 3.409304618835449
Validation loss: 2.391010207514609

Epoch: 59| Step: 0
Training loss: 2.336169719696045
Validation loss: 2.333569134435346

Epoch: 6| Step: 1
Training loss: 2.098198890686035
Validation loss: 2.160307134351423

Epoch: 6| Step: 2
Training loss: 2.2398605346679688
Validation loss: 2.0778243362262683

Epoch: 6| Step: 3
Training loss: 3.024611473083496
Validation loss: 2.0647993241586993

Epoch: 6| Step: 4
Training loss: 2.508493185043335
Validation loss: 2.083126647498018

Epoch: 6| Step: 5
Training loss: 2.881196975708008
Validation loss: 2.111959376642781

Epoch: 6| Step: 6
Training loss: 2.4492759704589844
Validation loss: 2.1406614985517276

Epoch: 6| Step: 7
Training loss: 1.9732439517974854
Validation loss: 2.194451014200846

Epoch: 6| Step: 8
Training loss: 2.99503755569458
Validation loss: 2.2262450584801297

Epoch: 6| Step: 9
Training loss: 2.662491798400879
Validation loss: 2.2450754129758446

Epoch: 6| Step: 10
Training loss: 2.811887264251709
Validation loss: 2.2883542442834504

Epoch: 6| Step: 11
Training loss: 2.698284149169922
Validation loss: 2.221822036209927

Epoch: 6| Step: 12
Training loss: 2.3823399543762207
Validation loss: 2.1597963866367134

Epoch: 6| Step: 13
Training loss: 2.843214988708496
Validation loss: 2.121739664385396

Epoch: 60| Step: 0
Training loss: 2.5844385623931885
Validation loss: 2.1018292057898735

Epoch: 6| Step: 1
Training loss: 2.709885835647583
Validation loss: 2.092005855293684

Epoch: 6| Step: 2
Training loss: 2.3171117305755615
Validation loss: 2.0632745835088913

Epoch: 6| Step: 3
Training loss: 2.0317697525024414
Validation loss: 2.047394561511214

Epoch: 6| Step: 4
Training loss: 2.4586472511291504
Validation loss: 2.065497677813294

Epoch: 6| Step: 5
Training loss: 2.380171060562134
Validation loss: 2.116707686455019

Epoch: 6| Step: 6
Training loss: 2.774397850036621
Validation loss: 2.236786489845604

Epoch: 6| Step: 7
Training loss: 2.556365489959717
Validation loss: 2.4003570618168

Epoch: 6| Step: 8
Training loss: 2.5322961807250977
Validation loss: 2.4661529243633313

Epoch: 6| Step: 9
Training loss: 2.174558639526367
Validation loss: 2.444261130466256

Epoch: 6| Step: 10
Training loss: 2.527318000793457
Validation loss: 2.419306714047668

Epoch: 6| Step: 11
Training loss: 2.3665568828582764
Validation loss: 2.350931341930102

Epoch: 6| Step: 12
Training loss: 2.445542335510254
Validation loss: 2.2032839816103698

Epoch: 6| Step: 13
Training loss: 3.299631118774414
Validation loss: 2.105923121975314

Epoch: 61| Step: 0
Training loss: 2.3293867111206055
Validation loss: 2.045754612133067

Epoch: 6| Step: 1
Training loss: 2.0717885494232178
Validation loss: 2.0482430355523222

Epoch: 6| Step: 2
Training loss: 2.975644111633301
Validation loss: 2.0632452477690992

Epoch: 6| Step: 3
Training loss: 2.3280112743377686
Validation loss: 2.0797060869073354

Epoch: 6| Step: 4
Training loss: 2.3096818923950195
Validation loss: 2.109866690892045

Epoch: 6| Step: 5
Training loss: 2.9056649208068848
Validation loss: 2.1439197742810814

Epoch: 6| Step: 6
Training loss: 2.308358669281006
Validation loss: 2.1487545838920017

Epoch: 6| Step: 7
Training loss: 2.492258071899414
Validation loss: 2.137979879174181

Epoch: 6| Step: 8
Training loss: 2.211796998977661
Validation loss: 2.128794800850653

Epoch: 6| Step: 9
Training loss: 2.968749761581421
Validation loss: 2.1236996932696273

Epoch: 6| Step: 10
Training loss: 2.689563751220703
Validation loss: 2.1083101303346696

Epoch: 6| Step: 11
Training loss: 2.8840537071228027
Validation loss: 2.1039351237717496

Epoch: 6| Step: 12
Training loss: 2.34616756439209
Validation loss: 2.100502388451689

Epoch: 6| Step: 13
Training loss: 2.54242205619812
Validation loss: 2.0980096094069944

Epoch: 62| Step: 0
Training loss: 2.7427964210510254
Validation loss: 2.1212833722432456

Epoch: 6| Step: 1
Training loss: 2.0975775718688965
Validation loss: 2.1431619839001725

Epoch: 6| Step: 2
Training loss: 2.530649185180664
Validation loss: 2.135169444545623

Epoch: 6| Step: 3
Training loss: 2.421520709991455
Validation loss: 2.1184200163810485

Epoch: 6| Step: 4
Training loss: 2.5531153678894043
Validation loss: 2.1047753313536286

Epoch: 6| Step: 5
Training loss: 2.7132997512817383
Validation loss: 2.1056538756175707

Epoch: 6| Step: 6
Training loss: 2.4387593269348145
Validation loss: 2.110409736633301

Epoch: 6| Step: 7
Training loss: 1.7063883543014526
Validation loss: 2.113043551803917

Epoch: 6| Step: 8
Training loss: 1.8812897205352783
Validation loss: 2.1234800841218684

Epoch: 6| Step: 9
Training loss: 2.4986066818237305
Validation loss: 2.1501464125930623

Epoch: 6| Step: 10
Training loss: 2.9560885429382324
Validation loss: 2.1897094454816592

Epoch: 6| Step: 11
Training loss: 2.858693838119507
Validation loss: 2.211183113436545

Epoch: 6| Step: 12
Training loss: 2.520218849182129
Validation loss: 2.223124260543495

Epoch: 6| Step: 13
Training loss: 2.772310495376587
Validation loss: 2.2668805148011897

Epoch: 63| Step: 0
Training loss: 2.6414008140563965
Validation loss: 2.220865839271135

Epoch: 6| Step: 1
Training loss: 2.75345516204834
Validation loss: 2.1645872387834775

Epoch: 6| Step: 2
Training loss: 2.179964542388916
Validation loss: 2.1124267911398285

Epoch: 6| Step: 3
Training loss: 2.8939266204833984
Validation loss: 2.0917526547626784

Epoch: 6| Step: 4
Training loss: 2.666689872741699
Validation loss: 2.0698086779604674

Epoch: 6| Step: 5
Training loss: 2.250966787338257
Validation loss: 2.050517753888202

Epoch: 6| Step: 6
Training loss: 2.9572911262512207
Validation loss: 2.0374444723129272

Epoch: 6| Step: 7
Training loss: 1.7154903411865234
Validation loss: 2.0360136365377777

Epoch: 6| Step: 8
Training loss: 1.6415982246398926
Validation loss: 2.0323150106655654

Epoch: 6| Step: 9
Training loss: 2.776109218597412
Validation loss: 2.031496783738495

Epoch: 6| Step: 10
Training loss: 2.6840033531188965
Validation loss: 2.0371537721285256

Epoch: 6| Step: 11
Training loss: 2.8283443450927734
Validation loss: 2.0395481983820596

Epoch: 6| Step: 12
Training loss: 2.0599141120910645
Validation loss: 2.034549017106333

Epoch: 6| Step: 13
Training loss: 1.7315516471862793
Validation loss: 2.0379932900910736

Epoch: 64| Step: 0
Training loss: 2.1450729370117188
Validation loss: 2.047419162206752

Epoch: 6| Step: 1
Training loss: 2.096187114715576
Validation loss: 2.0510273223282187

Epoch: 6| Step: 2
Training loss: 2.1404268741607666
Validation loss: 2.063938912524972

Epoch: 6| Step: 3
Training loss: 2.367861747741699
Validation loss: 2.0843101111791467

Epoch: 6| Step: 4
Training loss: 2.3538355827331543
Validation loss: 2.1341720524654595

Epoch: 6| Step: 5
Training loss: 1.7609630823135376
Validation loss: 2.215730251804475

Epoch: 6| Step: 6
Training loss: 2.9960737228393555
Validation loss: 2.2895843803241687

Epoch: 6| Step: 7
Training loss: 2.9771728515625
Validation loss: 2.332246615040687

Epoch: 6| Step: 8
Training loss: 2.684128761291504
Validation loss: 2.385512141771214

Epoch: 6| Step: 9
Training loss: 3.052764654159546
Validation loss: 2.3839996501963627

Epoch: 6| Step: 10
Training loss: 2.798900604248047
Validation loss: 2.2999377404489825

Epoch: 6| Step: 11
Training loss: 2.745119333267212
Validation loss: 2.210681858883109

Epoch: 6| Step: 12
Training loss: 1.9914159774780273
Validation loss: 2.140423551682503

Epoch: 6| Step: 13
Training loss: 2.5566163063049316
Validation loss: 2.0585467071943384

Epoch: 65| Step: 0
Training loss: 2.2818074226379395
Validation loss: 2.0334224547109296

Epoch: 6| Step: 1
Training loss: 2.3480687141418457
Validation loss: 2.0304568480419856

Epoch: 6| Step: 2
Training loss: 2.1782419681549072
Validation loss: 2.045174639712098

Epoch: 6| Step: 3
Training loss: 2.822737216949463
Validation loss: 2.0568623619694866

Epoch: 6| Step: 4
Training loss: 2.4930553436279297
Validation loss: 2.080900658843338

Epoch: 6| Step: 5
Training loss: 2.996239185333252
Validation loss: 2.100482694564327

Epoch: 6| Step: 6
Training loss: 2.406759738922119
Validation loss: 2.1204975048700967

Epoch: 6| Step: 7
Training loss: 2.9896914958953857
Validation loss: 2.1410689212942637

Epoch: 6| Step: 8
Training loss: 2.2969164848327637
Validation loss: 2.1315196816639235

Epoch: 6| Step: 9
Training loss: 2.8475699424743652
Validation loss: 2.0840259239237797

Epoch: 6| Step: 10
Training loss: 2.3357620239257812
Validation loss: 2.0598999813038814

Epoch: 6| Step: 11
Training loss: 1.980419397354126
Validation loss: 2.0507832111850863

Epoch: 6| Step: 12
Training loss: 2.494509696960449
Validation loss: 2.044125477472941

Epoch: 6| Step: 13
Training loss: 2.7236504554748535
Validation loss: 2.049551507478119

Epoch: 66| Step: 0
Training loss: 2.2258758544921875
Validation loss: 2.061910129362537

Epoch: 6| Step: 1
Training loss: 2.8874194622039795
Validation loss: 2.076717670245837

Epoch: 6| Step: 2
Training loss: 1.962836503982544
Validation loss: 2.0851822745415474

Epoch: 6| Step: 3
Training loss: 2.581977605819702
Validation loss: 2.0762390808392595

Epoch: 6| Step: 4
Training loss: 2.4400382041931152
Validation loss: 2.0657195237375077

Epoch: 6| Step: 5
Training loss: 2.3225936889648438
Validation loss: 2.0551093252756263

Epoch: 6| Step: 6
Training loss: 2.3698415756225586
Validation loss: 2.070238733804354

Epoch: 6| Step: 7
Training loss: 2.6782636642456055
Validation loss: 2.0834957412494126

Epoch: 6| Step: 8
Training loss: 2.140775203704834
Validation loss: 2.0911430505014237

Epoch: 6| Step: 9
Training loss: 2.926283836364746
Validation loss: 2.1103160919681674

Epoch: 6| Step: 10
Training loss: 2.3355813026428223
Validation loss: 2.142131504192147

Epoch: 6| Step: 11
Training loss: 2.6023051738739014
Validation loss: 2.18210962254514

Epoch: 6| Step: 12
Training loss: 1.8908708095550537
Validation loss: 2.250551639064666

Epoch: 6| Step: 13
Training loss: 2.7824466228485107
Validation loss: 2.2156228109072615

Epoch: 67| Step: 0
Training loss: 2.301164150238037
Validation loss: 2.2216476061010875

Epoch: 6| Step: 1
Training loss: 1.9940972328186035
Validation loss: 2.1880061395706667

Epoch: 6| Step: 2
Training loss: 2.2878172397613525
Validation loss: 2.1424703418567614

Epoch: 6| Step: 3
Training loss: 2.229339122772217
Validation loss: 2.081187303348254

Epoch: 6| Step: 4
Training loss: 2.692826986312866
Validation loss: 2.0560080748732372

Epoch: 6| Step: 5
Training loss: 2.660452127456665
Validation loss: 2.0512016511732534

Epoch: 6| Step: 6
Training loss: 1.8380045890808105
Validation loss: 2.0565519743068243

Epoch: 6| Step: 7
Training loss: 2.758913516998291
Validation loss: 2.0411935647328696

Epoch: 6| Step: 8
Training loss: 2.6527795791625977
Validation loss: 2.0383894058965866

Epoch: 6| Step: 9
Training loss: 2.50831937789917
Validation loss: 2.036127483972939

Epoch: 6| Step: 10
Training loss: 2.6117634773254395
Validation loss: 2.041814422094694

Epoch: 6| Step: 11
Training loss: 2.3857789039611816
Validation loss: 2.036849429530482

Epoch: 6| Step: 12
Training loss: 2.120863437652588
Validation loss: 2.0494654255528606

Epoch: 6| Step: 13
Training loss: 2.495137929916382
Validation loss: 2.0469387679971676

Epoch: 68| Step: 0
Training loss: 2.2833995819091797
Validation loss: 2.040909427468495

Epoch: 6| Step: 1
Training loss: 1.800734043121338
Validation loss: 2.0600334649444907

Epoch: 6| Step: 2
Training loss: 2.5804948806762695
Validation loss: 2.0636705660050914

Epoch: 6| Step: 3
Training loss: 2.0725183486938477
Validation loss: 2.077138322655873

Epoch: 6| Step: 4
Training loss: 2.786384105682373
Validation loss: 2.0808106930025163

Epoch: 6| Step: 5
Training loss: 3.1400578022003174
Validation loss: 2.0866152548020884

Epoch: 6| Step: 6
Training loss: 2.752932548522949
Validation loss: 2.087950985918763

Epoch: 6| Step: 7
Training loss: 2.3565478324890137
Validation loss: 2.1019900511669856

Epoch: 6| Step: 8
Training loss: 1.6511828899383545
Validation loss: 2.120314859574841

Epoch: 6| Step: 9
Training loss: 2.254946708679199
Validation loss: 2.1340504666810394

Epoch: 6| Step: 10
Training loss: 1.835453987121582
Validation loss: 2.145132021237445

Epoch: 6| Step: 11
Training loss: 3.1940979957580566
Validation loss: 2.122435792799919

Epoch: 6| Step: 12
Training loss: 2.4847822189331055
Validation loss: 2.1050450507030694

Epoch: 6| Step: 13
Training loss: 2.790534734725952
Validation loss: 2.0824726294445735

Epoch: 69| Step: 0
Training loss: 2.499429702758789
Validation loss: 2.079838134909189

Epoch: 6| Step: 1
Training loss: 2.3406639099121094
Validation loss: 2.0660674456627137

Epoch: 6| Step: 2
Training loss: 2.6787586212158203
Validation loss: 2.053146041849608

Epoch: 6| Step: 3
Training loss: 1.629118800163269
Validation loss: 2.0483940186039096

Epoch: 6| Step: 4
Training loss: 3.236323833465576
Validation loss: 2.0436066760811755

Epoch: 6| Step: 5
Training loss: 2.410269021987915
Validation loss: 2.03704361889952

Epoch: 6| Step: 6
Training loss: 2.8337249755859375
Validation loss: 2.0354100786229616

Epoch: 6| Step: 7
Training loss: 2.73649001121521
Validation loss: 2.0333009778812365

Epoch: 6| Step: 8
Training loss: 2.0436058044433594
Validation loss: 2.0389689117349605

Epoch: 6| Step: 9
Training loss: 2.4356656074523926
Validation loss: 2.0402622889446955

Epoch: 6| Step: 10
Training loss: 2.10542893409729
Validation loss: 2.0439360526300248

Epoch: 6| Step: 11
Training loss: 2.2710213661193848
Validation loss: 2.049376103185838

Epoch: 6| Step: 12
Training loss: 2.3769266605377197
Validation loss: 2.0632643853464434

Epoch: 6| Step: 13
Training loss: 1.7712960243225098
Validation loss: 2.082087411675402

Epoch: 70| Step: 0
Training loss: 2.982558250427246
Validation loss: 2.1014298033970658

Epoch: 6| Step: 1
Training loss: 1.7002003192901611
Validation loss: 2.0831003765906058

Epoch: 6| Step: 2
Training loss: 2.273669719696045
Validation loss: 2.0666661826513146

Epoch: 6| Step: 3
Training loss: 2.6211628913879395
Validation loss: 2.053064424504516

Epoch: 6| Step: 4
Training loss: 2.7526681423187256
Validation loss: 2.045977477104433

Epoch: 6| Step: 5
Training loss: 2.430746078491211
Validation loss: 2.0349666277567544

Epoch: 6| Step: 6
Training loss: 2.060476064682007
Validation loss: 2.0362672651967695

Epoch: 6| Step: 7
Training loss: 2.7930421829223633
Validation loss: 2.027222684634629

Epoch: 6| Step: 8
Training loss: 2.001941204071045
Validation loss: 2.021806632318804

Epoch: 6| Step: 9
Training loss: 1.9356129169464111
Validation loss: 2.0396249589099678

Epoch: 6| Step: 10
Training loss: 2.2272720336914062
Validation loss: 2.039861112512568

Epoch: 6| Step: 11
Training loss: 2.459350347518921
Validation loss: 2.0465460182518087

Epoch: 6| Step: 12
Training loss: 2.6047661304473877
Validation loss: 2.0456470943266347

Epoch: 6| Step: 13
Training loss: 3.050342559814453
Validation loss: 2.044824542537812

Epoch: 71| Step: 0
Training loss: 1.9474711418151855
Validation loss: 2.0481496882695023

Epoch: 6| Step: 1
Training loss: 2.3281826972961426
Validation loss: 2.067492591437473

Epoch: 6| Step: 2
Training loss: 1.9697624444961548
Validation loss: 2.077545274970352

Epoch: 6| Step: 3
Training loss: 1.8824810981750488
Validation loss: 2.0780087888881726

Epoch: 6| Step: 4
Training loss: 2.5411698818206787
Validation loss: 2.0881814905392226

Epoch: 6| Step: 5
Training loss: 2.8131942749023438
Validation loss: 2.0803633505298245

Epoch: 6| Step: 6
Training loss: 2.211941957473755
Validation loss: 2.0911597769747496

Epoch: 6| Step: 7
Training loss: 2.8078103065490723
Validation loss: 2.068727357413179

Epoch: 6| Step: 8
Training loss: 2.7886781692504883
Validation loss: 2.068830277330132

Epoch: 6| Step: 9
Training loss: 2.52915620803833
Validation loss: 2.06225706941338

Epoch: 6| Step: 10
Training loss: 2.2588329315185547
Validation loss: 2.0487586272660123

Epoch: 6| Step: 11
Training loss: 2.935880184173584
Validation loss: 2.043289630643783

Epoch: 6| Step: 12
Training loss: 2.1459994316101074
Validation loss: 2.0382417991597164

Epoch: 6| Step: 13
Training loss: 2.3748250007629395
Validation loss: 2.0320735157177015

Epoch: 72| Step: 0
Training loss: 2.3886778354644775
Validation loss: 2.0302784019900906

Epoch: 6| Step: 1
Training loss: 2.6509242057800293
Validation loss: 2.022525638662359

Epoch: 6| Step: 2
Training loss: 2.3994903564453125
Validation loss: 2.0142226603723343

Epoch: 6| Step: 3
Training loss: 2.417405605316162
Validation loss: 2.0151172196993263

Epoch: 6| Step: 4
Training loss: 2.320321798324585
Validation loss: 2.015835392859674

Epoch: 6| Step: 5
Training loss: 2.1405441761016846
Validation loss: 2.0289108189203406

Epoch: 6| Step: 6
Training loss: 2.2426090240478516
Validation loss: 2.034230047656644

Epoch: 6| Step: 7
Training loss: 2.3972434997558594
Validation loss: 2.0588523072581135

Epoch: 6| Step: 8
Training loss: 2.0877685546875
Validation loss: 2.1281933579393613

Epoch: 6| Step: 9
Training loss: 2.32759428024292
Validation loss: 2.1554544843653196

Epoch: 6| Step: 10
Training loss: 2.0736238956451416
Validation loss: 2.1609633353448685

Epoch: 6| Step: 11
Training loss: 2.590265989303589
Validation loss: 2.1946594458754345

Epoch: 6| Step: 12
Training loss: 3.158839702606201
Validation loss: 2.2125986417134604

Epoch: 6| Step: 13
Training loss: 2.419382333755493
Validation loss: 2.2052116406861173

Epoch: 73| Step: 0
Training loss: 2.475386619567871
Validation loss: 2.131544448996103

Epoch: 6| Step: 1
Training loss: 2.1678686141967773
Validation loss: 2.0892418033333233

Epoch: 6| Step: 2
Training loss: 2.368568181991577
Validation loss: 2.0609633999486126

Epoch: 6| Step: 3
Training loss: 1.7960333824157715
Validation loss: 2.041713922254501

Epoch: 6| Step: 4
Training loss: 2.158193588256836
Validation loss: 2.0347500437049457

Epoch: 6| Step: 5
Training loss: 2.411447525024414
Validation loss: 2.0331177634577595

Epoch: 6| Step: 6
Training loss: 2.19944167137146
Validation loss: 2.0461214050169914

Epoch: 6| Step: 7
Training loss: 2.4695751667022705
Validation loss: 2.0557769985609156

Epoch: 6| Step: 8
Training loss: 2.066105842590332
Validation loss: 2.0706103565872356

Epoch: 6| Step: 9
Training loss: 2.5500428676605225
Validation loss: 2.0700949263829056

Epoch: 6| Step: 10
Training loss: 2.275637626647949
Validation loss: 2.084122432175503

Epoch: 6| Step: 11
Training loss: 2.7192349433898926
Validation loss: 2.0743620780206498

Epoch: 6| Step: 12
Training loss: 2.9803576469421387
Validation loss: 2.0704073931581233

Epoch: 6| Step: 13
Training loss: 2.778853416442871
Validation loss: 2.0514015754063926

Epoch: 74| Step: 0
Training loss: 2.9054009914398193
Validation loss: 2.0400743869043167

Epoch: 6| Step: 1
Training loss: 3.044193744659424
Validation loss: 2.025389366252448

Epoch: 6| Step: 2
Training loss: 1.9002217054367065
Validation loss: 2.021685366989464

Epoch: 6| Step: 3
Training loss: 2.468604564666748
Validation loss: 2.0197408019855456

Epoch: 6| Step: 4
Training loss: 2.55586576461792
Validation loss: 2.017217956563478

Epoch: 6| Step: 5
Training loss: 1.9166115522384644
Validation loss: 2.0199332775608188

Epoch: 6| Step: 6
Training loss: 2.245506763458252
Validation loss: 2.0183376266110327

Epoch: 6| Step: 7
Training loss: 1.5750277042388916
Validation loss: 2.013594445361886

Epoch: 6| Step: 8
Training loss: 2.774008274078369
Validation loss: 2.0144999796344387

Epoch: 6| Step: 9
Training loss: 2.298325538635254
Validation loss: 2.021281812780647

Epoch: 6| Step: 10
Training loss: 2.5407462120056152
Validation loss: 2.014987950683922

Epoch: 6| Step: 11
Training loss: 1.9048700332641602
Validation loss: 2.020076333835561

Epoch: 6| Step: 12
Training loss: 2.6369941234588623
Validation loss: 2.018052536954162

Epoch: 6| Step: 13
Training loss: 2.389274835586548
Validation loss: 2.0322840367594073

Epoch: 75| Step: 0
Training loss: 2.7573065757751465
Validation loss: 2.074561990717406

Epoch: 6| Step: 1
Training loss: 2.353891134262085
Validation loss: 2.1220799184614614

Epoch: 6| Step: 2
Training loss: 2.828094959259033
Validation loss: 2.1178280691946707

Epoch: 6| Step: 3
Training loss: 2.3484504222869873
Validation loss: 2.116372328932567

Epoch: 6| Step: 4
Training loss: 1.884429693222046
Validation loss: 2.0614324462029243

Epoch: 6| Step: 5
Training loss: 2.23260498046875
Validation loss: 2.0384666688980593

Epoch: 6| Step: 6
Training loss: 2.45763897895813
Validation loss: 2.0124430605160293

Epoch: 6| Step: 7
Training loss: 1.9227802753448486
Validation loss: 2.000163370563138

Epoch: 6| Step: 8
Training loss: 2.801435947418213
Validation loss: 1.9901179921242498

Epoch: 6| Step: 9
Training loss: 1.9749031066894531
Validation loss: 1.9919356043620775

Epoch: 6| Step: 10
Training loss: 2.0966105461120605
Validation loss: 1.9961416875162432

Epoch: 6| Step: 11
Training loss: 2.6836602687835693
Validation loss: 2.0001362241724485

Epoch: 6| Step: 12
Training loss: 2.75502872467041
Validation loss: 2.001026672701682

Epoch: 6| Step: 13
Training loss: 2.9188966751098633
Validation loss: 2.0005761807964695

Epoch: 76| Step: 0
Training loss: 1.8740191459655762
Validation loss: 2.000656129211508

Epoch: 6| Step: 1
Training loss: 2.628761053085327
Validation loss: 1.9957213683794903

Epoch: 6| Step: 2
Training loss: 1.9857865571975708
Validation loss: 1.9923708003054383

Epoch: 6| Step: 3
Training loss: 2.197094440460205
Validation loss: 1.9937148299268497

Epoch: 6| Step: 4
Training loss: 1.6267520189285278
Validation loss: 2.0004405154976794

Epoch: 6| Step: 5
Training loss: 2.427642822265625
Validation loss: 2.0185310327878563

Epoch: 6| Step: 6
Training loss: 2.910158634185791
Validation loss: 2.029497887498589

Epoch: 6| Step: 7
Training loss: 2.881993293762207
Validation loss: 2.051091804299303

Epoch: 6| Step: 8
Training loss: 2.26369571685791
Validation loss: 2.1212396442249255

Epoch: 6| Step: 9
Training loss: 2.9155843257904053
Validation loss: 2.221944711541617

Epoch: 6| Step: 10
Training loss: 2.1237640380859375
Validation loss: 2.1930954815239034

Epoch: 6| Step: 11
Training loss: 2.7524452209472656
Validation loss: 2.154555400212606

Epoch: 6| Step: 12
Training loss: 2.481065273284912
Validation loss: 2.130824878651609

Epoch: 6| Step: 13
Training loss: 2.2533812522888184
Validation loss: 2.0899830684866956

Epoch: 77| Step: 0
Training loss: 3.067117691040039
Validation loss: 2.051155477441767

Epoch: 6| Step: 1
Training loss: 2.284334659576416
Validation loss: 2.0379086630318755

Epoch: 6| Step: 2
Training loss: 2.8576226234436035
Validation loss: 2.0276807687615834

Epoch: 6| Step: 3
Training loss: 2.7451350688934326
Validation loss: 2.003053431869835

Epoch: 6| Step: 4
Training loss: 1.775820255279541
Validation loss: 2.0051155218514065

Epoch: 6| Step: 5
Training loss: 2.6185061931610107
Validation loss: 2.0081077429556076

Epoch: 6| Step: 6
Training loss: 2.709975481033325
Validation loss: 2.013793271075013

Epoch: 6| Step: 7
Training loss: 2.471367835998535
Validation loss: 2.022611395005257

Epoch: 6| Step: 8
Training loss: 2.2289862632751465
Validation loss: 2.0225517134512625

Epoch: 6| Step: 9
Training loss: 2.048692464828491
Validation loss: 2.028971500294183

Epoch: 6| Step: 10
Training loss: 1.9022822380065918
Validation loss: 2.041228327699887

Epoch: 6| Step: 11
Training loss: 2.151667594909668
Validation loss: 2.033347228521942

Epoch: 6| Step: 12
Training loss: 2.5880966186523438
Validation loss: 2.0441062732409407

Epoch: 6| Step: 13
Training loss: 1.739766001701355
Validation loss: 2.046408550713652

Epoch: 78| Step: 0
Training loss: 2.150786876678467
Validation loss: 2.0482342294467393

Epoch: 6| Step: 1
Training loss: 2.456695079803467
Validation loss: 2.041242398241515

Epoch: 6| Step: 2
Training loss: 2.360194206237793
Validation loss: 2.052269161388438

Epoch: 6| Step: 3
Training loss: 3.189876079559326
Validation loss: 2.047622311499811

Epoch: 6| Step: 4
Training loss: 2.487015724182129
Validation loss: 2.0500505483278664

Epoch: 6| Step: 5
Training loss: 1.8513340950012207
Validation loss: 2.05891203752128

Epoch: 6| Step: 6
Training loss: 2.176729202270508
Validation loss: 2.0704660005466913

Epoch: 6| Step: 7
Training loss: 1.91303288936615
Validation loss: 2.0819310834330897

Epoch: 6| Step: 8
Training loss: 2.5770678520202637
Validation loss: 2.118226653786116

Epoch: 6| Step: 9
Training loss: 2.7823915481567383
Validation loss: 2.146916627883911

Epoch: 6| Step: 10
Training loss: 2.110767364501953
Validation loss: 2.1369374144461846

Epoch: 6| Step: 11
Training loss: 2.337164878845215
Validation loss: 2.1336953306710846

Epoch: 6| Step: 12
Training loss: 2.324197769165039
Validation loss: 2.1336732551615727

Epoch: 6| Step: 13
Training loss: 2.926039695739746
Validation loss: 2.108223295980884

Epoch: 79| Step: 0
Training loss: 1.7421846389770508
Validation loss: 2.0985676857732956

Epoch: 6| Step: 1
Training loss: 1.4777830839157104
Validation loss: 2.0696160639486005

Epoch: 6| Step: 2
Training loss: 2.415874481201172
Validation loss: 2.077570548621557

Epoch: 6| Step: 3
Training loss: 2.4739885330200195
Validation loss: 2.0792340232479956

Epoch: 6| Step: 4
Training loss: 2.1897313594818115
Validation loss: 2.0979506174723306

Epoch: 6| Step: 5
Training loss: 2.7185537815093994
Validation loss: 2.110743417534777

Epoch: 6| Step: 6
Training loss: 2.3851208686828613
Validation loss: 2.1003131763909453

Epoch: 6| Step: 7
Training loss: 2.360959529876709
Validation loss: 2.0830215792502127

Epoch: 6| Step: 8
Training loss: 2.1128618717193604
Validation loss: 2.0742809413581766

Epoch: 6| Step: 9
Training loss: 2.8118579387664795
Validation loss: 2.0673182625924387

Epoch: 6| Step: 10
Training loss: 1.7642840147018433
Validation loss: 2.070615339022811

Epoch: 6| Step: 11
Training loss: 3.3943686485290527
Validation loss: 2.0379521513497956

Epoch: 6| Step: 12
Training loss: 2.814544677734375
Validation loss: 2.0347782668247016

Epoch: 6| Step: 13
Training loss: 2.4930076599121094
Validation loss: 2.026241465281415

Epoch: 80| Step: 0
Training loss: 2.187812328338623
Validation loss: 2.0189516005977506

Epoch: 6| Step: 1
Training loss: 1.657611608505249
Validation loss: 2.0111642114577757

Epoch: 6| Step: 2
Training loss: 2.2597293853759766
Validation loss: 2.006100103419314

Epoch: 6| Step: 3
Training loss: 2.4779775142669678
Validation loss: 2.0137270317282727

Epoch: 6| Step: 4
Training loss: 3.0245561599731445
Validation loss: 2.0154127997736775

Epoch: 6| Step: 5
Training loss: 2.420931816101074
Validation loss: 2.01786530786945

Epoch: 6| Step: 6
Training loss: 2.4155850410461426
Validation loss: 2.0496220665593303

Epoch: 6| Step: 7
Training loss: 2.3051352500915527
Validation loss: 2.066623792853407

Epoch: 6| Step: 8
Training loss: 2.3479695320129395
Validation loss: 2.0880759223814933

Epoch: 6| Step: 9
Training loss: 2.807354211807251
Validation loss: 2.1369065520583943

Epoch: 6| Step: 10
Training loss: 2.1501519680023193
Validation loss: 2.0992427884891467

Epoch: 6| Step: 11
Training loss: 2.5858187675476074
Validation loss: 2.0740254873870523

Epoch: 6| Step: 12
Training loss: 1.9326095581054688
Validation loss: 2.0801967959250174

Epoch: 6| Step: 13
Training loss: 2.277188301086426
Validation loss: 2.0879189839927097

Epoch: 81| Step: 0
Training loss: 2.676990270614624
Validation loss: 2.106220386361563

Epoch: 6| Step: 1
Training loss: 2.4343361854553223
Validation loss: 2.0945058471413067

Epoch: 6| Step: 2
Training loss: 2.531275987625122
Validation loss: 2.071065810418898

Epoch: 6| Step: 3
Training loss: 1.6945738792419434
Validation loss: 2.0547185969609085

Epoch: 6| Step: 4
Training loss: 2.9186058044433594
Validation loss: 2.036828961423648

Epoch: 6| Step: 5
Training loss: 1.9997758865356445
Validation loss: 2.0172400166911464

Epoch: 6| Step: 6
Training loss: 2.237325668334961
Validation loss: 2.0157455808372906

Epoch: 6| Step: 7
Training loss: 2.1142168045043945
Validation loss: 2.0098241298429427

Epoch: 6| Step: 8
Training loss: 2.5215344429016113
Validation loss: 2.0096679413190452

Epoch: 6| Step: 9
Training loss: 2.100803852081299
Validation loss: 1.9998363935819237

Epoch: 6| Step: 10
Training loss: 2.7615671157836914
Validation loss: 2.003445589414207

Epoch: 6| Step: 11
Training loss: 2.3608832359313965
Validation loss: 1.9991326203910254

Epoch: 6| Step: 12
Training loss: 2.3865580558776855
Validation loss: 1.9962822032231156

Epoch: 6| Step: 13
Training loss: 2.154157876968384
Validation loss: 1.9991526270425448

Epoch: 82| Step: 0
Training loss: 2.071824073791504
Validation loss: 2.00265601629852

Epoch: 6| Step: 1
Training loss: 2.87290620803833
Validation loss: 2.004674726916898

Epoch: 6| Step: 2
Training loss: 2.0642662048339844
Validation loss: 2.015891877553796

Epoch: 6| Step: 3
Training loss: 1.9402647018432617
Validation loss: 2.0288669934836765

Epoch: 6| Step: 4
Training loss: 1.5451412200927734
Validation loss: 2.018950537968707

Epoch: 6| Step: 5
Training loss: 2.1610732078552246
Validation loss: 2.010841537547368

Epoch: 6| Step: 6
Training loss: 2.6975150108337402
Validation loss: 1.9985749913800148

Epoch: 6| Step: 7
Training loss: 2.1031370162963867
Validation loss: 2.0047831381520917

Epoch: 6| Step: 8
Training loss: 2.580385684967041
Validation loss: 1.995493649154581

Epoch: 6| Step: 9
Training loss: 2.4964611530303955
Validation loss: 1.9925422412092968

Epoch: 6| Step: 10
Training loss: 1.9443702697753906
Validation loss: 2.0163251148757113

Epoch: 6| Step: 11
Training loss: 3.449049472808838
Validation loss: 2.0197872513084003

Epoch: 6| Step: 12
Training loss: 2.3933422565460205
Validation loss: 2.014370515782346

Epoch: 6| Step: 13
Training loss: 2.277454137802124
Validation loss: 2.012033047214631

Epoch: 83| Step: 0
Training loss: 1.7472670078277588
Validation loss: 2.044404827138429

Epoch: 6| Step: 1
Training loss: 3.00399112701416
Validation loss: 2.050149304892427

Epoch: 6| Step: 2
Training loss: 2.6144611835479736
Validation loss: 2.062346073888963

Epoch: 6| Step: 3
Training loss: 2.186591148376465
Validation loss: 2.054438019311556

Epoch: 6| Step: 4
Training loss: 2.6295816898345947
Validation loss: 2.027903920860701

Epoch: 6| Step: 5
Training loss: 2.523597240447998
Validation loss: 2.0158377488454184

Epoch: 6| Step: 6
Training loss: 2.8585333824157715
Validation loss: 2.0111463915917183

Epoch: 6| Step: 7
Training loss: 2.034013032913208
Validation loss: 1.9902060416436964

Epoch: 6| Step: 8
Training loss: 2.4028782844543457
Validation loss: 1.9833584959788988

Epoch: 6| Step: 9
Training loss: 1.9847769737243652
Validation loss: 1.9800765706646828

Epoch: 6| Step: 10
Training loss: 1.9929407835006714
Validation loss: 1.9749184628968597

Epoch: 6| Step: 11
Training loss: 2.1192524433135986
Validation loss: 1.9691218406923356

Epoch: 6| Step: 12
Training loss: 2.202505588531494
Validation loss: 1.9701507194067842

Epoch: 6| Step: 13
Training loss: 2.6369996070861816
Validation loss: 1.9893988819532498

Epoch: 84| Step: 0
Training loss: 2.0520946979522705
Validation loss: 1.9910329721307243

Epoch: 6| Step: 1
Training loss: 2.393423080444336
Validation loss: 1.992747309387371

Epoch: 6| Step: 2
Training loss: 3.027275323867798
Validation loss: 2.008313412307411

Epoch: 6| Step: 3
Training loss: 2.118459939956665
Validation loss: 2.023064869706349

Epoch: 6| Step: 4
Training loss: 2.4941627979278564
Validation loss: 2.0395711096384193

Epoch: 6| Step: 5
Training loss: 2.635126829147339
Validation loss: 2.031974623280187

Epoch: 6| Step: 6
Training loss: 2.2239909172058105
Validation loss: 2.029226387700727

Epoch: 6| Step: 7
Training loss: 1.9766993522644043
Validation loss: 2.0172319117412774

Epoch: 6| Step: 8
Training loss: 2.59432315826416
Validation loss: 2.0131180773499193

Epoch: 6| Step: 9
Training loss: 2.4031925201416016
Validation loss: 1.9997648731354745

Epoch: 6| Step: 10
Training loss: 2.1460256576538086
Validation loss: 1.9999704604507775

Epoch: 6| Step: 11
Training loss: 1.7733731269836426
Validation loss: 2.009719699941656

Epoch: 6| Step: 12
Training loss: 2.0575525760650635
Validation loss: 2.000707120023748

Epoch: 6| Step: 13
Training loss: 2.9613113403320312
Validation loss: 2.010713804152704

Epoch: 85| Step: 0
Training loss: 2.1069390773773193
Validation loss: 2.0015743547870266

Epoch: 6| Step: 1
Training loss: 2.112677812576294
Validation loss: 2.0084177588903778

Epoch: 6| Step: 2
Training loss: 2.3223717212677
Validation loss: 2.0178239204550303

Epoch: 6| Step: 3
Training loss: 2.4696550369262695
Validation loss: 2.0062440479955366

Epoch: 6| Step: 4
Training loss: 2.4273507595062256
Validation loss: 1.9894712407101867

Epoch: 6| Step: 5
Training loss: 1.957485318183899
Validation loss: 1.9891177685030046

Epoch: 6| Step: 6
Training loss: 2.368790626525879
Validation loss: 1.9667779578957507

Epoch: 6| Step: 7
Training loss: 1.9329335689544678
Validation loss: 1.9710228084236063

Epoch: 6| Step: 8
Training loss: 2.453190326690674
Validation loss: 1.975419872550554

Epoch: 6| Step: 9
Training loss: 2.788844585418701
Validation loss: 1.9652736033162763

Epoch: 6| Step: 10
Training loss: 2.556333303451538
Validation loss: 1.973589804864699

Epoch: 6| Step: 11
Training loss: 2.604912519454956
Validation loss: 1.9731702163655271

Epoch: 6| Step: 12
Training loss: 2.5730204582214355
Validation loss: 1.996641214175891

Epoch: 6| Step: 13
Training loss: 1.5644296407699585
Validation loss: 1.9984079932653775

Epoch: 86| Step: 0
Training loss: 2.9205546379089355
Validation loss: 1.984906634976787

Epoch: 6| Step: 1
Training loss: 2.590404510498047
Validation loss: 1.9858208061546407

Epoch: 6| Step: 2
Training loss: 2.297459602355957
Validation loss: 1.9856348755539104

Epoch: 6| Step: 3
Training loss: 2.1140551567077637
Validation loss: 1.989436311106528

Epoch: 6| Step: 4
Training loss: 2.1559550762176514
Validation loss: 1.9962073141528713

Epoch: 6| Step: 5
Training loss: 2.3296637535095215
Validation loss: 2.007906083137758

Epoch: 6| Step: 6
Training loss: 2.622058868408203
Validation loss: 1.9981314136135964

Epoch: 6| Step: 7
Training loss: 2.0067763328552246
Validation loss: 1.9844485623862154

Epoch: 6| Step: 8
Training loss: 1.9595892429351807
Validation loss: 1.9687151139782322

Epoch: 6| Step: 9
Training loss: 2.130431890487671
Validation loss: 1.9665140182741228

Epoch: 6| Step: 10
Training loss: 2.675835371017456
Validation loss: 1.9729421125945223

Epoch: 6| Step: 11
Training loss: 1.7374207973480225
Validation loss: 1.9724786127767255

Epoch: 6| Step: 12
Training loss: 2.0470924377441406
Validation loss: 1.9682553429757395

Epoch: 6| Step: 13
Training loss: 3.3907041549682617
Validation loss: 1.9650801817576091

Epoch: 87| Step: 0
Training loss: 1.9991101026535034
Validation loss: 1.968000888824463

Epoch: 6| Step: 1
Training loss: 2.5905189514160156
Validation loss: 1.9763701551703996

Epoch: 6| Step: 2
Training loss: 2.104607105255127
Validation loss: 1.9699473842497794

Epoch: 6| Step: 3
Training loss: 2.2438478469848633
Validation loss: 1.9934664336583947

Epoch: 6| Step: 4
Training loss: 2.1671953201293945
Validation loss: 2.0471849620983167

Epoch: 6| Step: 5
Training loss: 2.231044292449951
Validation loss: 2.114742079088765

Epoch: 6| Step: 6
Training loss: 2.438436508178711
Validation loss: 2.1988316812822895

Epoch: 6| Step: 7
Training loss: 2.336163282394409
Validation loss: 2.2287387668445544

Epoch: 6| Step: 8
Training loss: 2.518272638320923
Validation loss: 2.2128744458639495

Epoch: 6| Step: 9
Training loss: 2.764406442642212
Validation loss: 2.1990095338513775

Epoch: 6| Step: 10
Training loss: 2.2987656593322754
Validation loss: 2.1242400625700593

Epoch: 6| Step: 11
Training loss: 2.0457558631896973
Validation loss: 2.0803860413130892

Epoch: 6| Step: 12
Training loss: 2.756129741668701
Validation loss: 2.073792549871629

Epoch: 6| Step: 13
Training loss: 2.406886100769043
Validation loss: 2.039622006877776

Epoch: 88| Step: 0
Training loss: 1.8725769519805908
Validation loss: 2.021623980614447

Epoch: 6| Step: 1
Training loss: 1.6346728801727295
Validation loss: 2.038744162487727

Epoch: 6| Step: 2
Training loss: 2.6396942138671875
Validation loss: 2.03412563185538

Epoch: 6| Step: 3
Training loss: 1.851081371307373
Validation loss: 2.01679221276314

Epoch: 6| Step: 4
Training loss: 2.264507293701172
Validation loss: 2.0229345765165103

Epoch: 6| Step: 5
Training loss: 2.398930549621582
Validation loss: 2.0387666686888664

Epoch: 6| Step: 6
Training loss: 1.7270176410675049
Validation loss: 2.053532096647447

Epoch: 6| Step: 7
Training loss: 2.924650192260742
Validation loss: 2.0459262453099734

Epoch: 6| Step: 8
Training loss: 2.172128915786743
Validation loss: 2.0568111096659014

Epoch: 6| Step: 9
Training loss: 2.9651832580566406
Validation loss: 2.0778655928950154

Epoch: 6| Step: 10
Training loss: 1.9705601930618286
Validation loss: 2.053360962098645

Epoch: 6| Step: 11
Training loss: 3.506693124771118
Validation loss: 2.0168441931406655

Epoch: 6| Step: 12
Training loss: 2.830965518951416
Validation loss: 2.009140888849894

Epoch: 6| Step: 13
Training loss: 1.618348240852356
Validation loss: 2.0047351506448563

Epoch: 89| Step: 0
Training loss: 3.0654494762420654
Validation loss: 2.005393171823153

Epoch: 6| Step: 1
Training loss: 2.058011531829834
Validation loss: 1.99467993679867

Epoch: 6| Step: 2
Training loss: 2.0125842094421387
Validation loss: 1.9877253783646451

Epoch: 6| Step: 3
Training loss: 2.3659610748291016
Validation loss: 2.0056667456062893

Epoch: 6| Step: 4
Training loss: 2.275725841522217
Validation loss: 2.0247592054387575

Epoch: 6| Step: 5
Training loss: 3.236747980117798
Validation loss: 2.014540664611324

Epoch: 6| Step: 6
Training loss: 1.5960986614227295
Validation loss: 2.021823042182512

Epoch: 6| Step: 7
Training loss: 2.275756597518921
Validation loss: 2.0039075036202707

Epoch: 6| Step: 8
Training loss: 2.2928366661071777
Validation loss: 1.986906087526711

Epoch: 6| Step: 9
Training loss: 1.9553414583206177
Validation loss: 1.9870395724491408

Epoch: 6| Step: 10
Training loss: 2.645542860031128
Validation loss: 1.984374253980575

Epoch: 6| Step: 11
Training loss: 2.1656651496887207
Validation loss: 1.9844494147967267

Epoch: 6| Step: 12
Training loss: 2.0286998748779297
Validation loss: 2.0086927965123165

Epoch: 6| Step: 13
Training loss: 2.3495819568634033
Validation loss: 2.032766347290367

Epoch: 90| Step: 0
Training loss: 2.159820318222046
Validation loss: 2.087921973197691

Epoch: 6| Step: 1
Training loss: 2.377504348754883
Validation loss: 2.1400431484304447

Epoch: 6| Step: 2
Training loss: 2.2162444591522217
Validation loss: 2.148367771538355

Epoch: 6| Step: 3
Training loss: 2.2536349296569824
Validation loss: 2.1571342740007626

Epoch: 6| Step: 4
Training loss: 3.34340763092041
Validation loss: 2.154522242084626

Epoch: 6| Step: 5
Training loss: 2.139129400253296
Validation loss: 2.1404101694783857

Epoch: 6| Step: 6
Training loss: 2.611534595489502
Validation loss: 2.123306361577844

Epoch: 6| Step: 7
Training loss: 1.8823747634887695
Validation loss: 2.10341400741249

Epoch: 6| Step: 8
Training loss: 2.3243556022644043
Validation loss: 2.0893419660547727

Epoch: 6| Step: 9
Training loss: 2.438453435897827
Validation loss: 2.09103956273807

Epoch: 6| Step: 10
Training loss: 2.234452962875366
Validation loss: 2.109761522662255

Epoch: 6| Step: 11
Training loss: 2.5966014862060547
Validation loss: 2.1243392293171217

Epoch: 6| Step: 12
Training loss: 2.0251388549804688
Validation loss: 2.117766582837669

Epoch: 6| Step: 13
Training loss: 2.741281747817993
Validation loss: 2.0937858499506468

Epoch: 91| Step: 0
Training loss: 2.0993380546569824
Validation loss: 2.043899734814962

Epoch: 6| Step: 1
Training loss: 2.2846174240112305
Validation loss: 2.0106040957153484

Epoch: 6| Step: 2
Training loss: 2.4599955081939697
Validation loss: 1.9920704595504268

Epoch: 6| Step: 3
Training loss: 2.5154504776000977
Validation loss: 1.985376242668398

Epoch: 6| Step: 4
Training loss: 1.86418879032135
Validation loss: 1.9971092388194094

Epoch: 6| Step: 5
Training loss: 3.303696632385254
Validation loss: 1.9929981513689923

Epoch: 6| Step: 6
Training loss: 2.1475157737731934
Validation loss: 1.9999045915501092

Epoch: 6| Step: 7
Training loss: 2.2365336418151855
Validation loss: 1.9968349061986452

Epoch: 6| Step: 8
Training loss: 2.196363925933838
Validation loss: 1.9883602280770578

Epoch: 6| Step: 9
Training loss: 2.3921449184417725
Validation loss: 1.981194580754926

Epoch: 6| Step: 10
Training loss: 2.2458555698394775
Validation loss: 1.9806621741223078

Epoch: 6| Step: 11
Training loss: 2.5618510246276855
Validation loss: 1.9941077950180217

Epoch: 6| Step: 12
Training loss: 1.9564710855484009
Validation loss: 1.999383029117379

Epoch: 6| Step: 13
Training loss: 2.6137990951538086
Validation loss: 1.990288851081684

Epoch: 92| Step: 0
Training loss: 2.4050886631011963
Validation loss: 2.0073356692508986

Epoch: 6| Step: 1
Training loss: 2.3676259517669678
Validation loss: 2.0508045650297597

Epoch: 6| Step: 2
Training loss: 2.0140414237976074
Validation loss: 2.0935302754884124

Epoch: 6| Step: 3
Training loss: 1.7621088027954102
Validation loss: 2.105552129848029

Epoch: 6| Step: 4
Training loss: 3.001478672027588
Validation loss: 2.0980078443404166

Epoch: 6| Step: 5
Training loss: 2.4582934379577637
Validation loss: 2.0510467124241654

Epoch: 6| Step: 6
Training loss: 2.9481875896453857
Validation loss: 2.0081266626234977

Epoch: 6| Step: 7
Training loss: 1.8891890048980713
Validation loss: 1.9908211564504972

Epoch: 6| Step: 8
Training loss: 2.1370201110839844
Validation loss: 1.9852672033412482

Epoch: 6| Step: 9
Training loss: 2.015740394592285
Validation loss: 1.9815753121529855

Epoch: 6| Step: 10
Training loss: 2.3036246299743652
Validation loss: 1.9729580058846423

Epoch: 6| Step: 11
Training loss: 1.9903216361999512
Validation loss: 1.9825790107891124

Epoch: 6| Step: 12
Training loss: 2.3288064002990723
Validation loss: 1.9779192439971431

Epoch: 6| Step: 13
Training loss: 2.933997392654419
Validation loss: 1.9739645052981634

Epoch: 93| Step: 0
Training loss: 2.0978243350982666
Validation loss: 1.97643445896846

Epoch: 6| Step: 1
Training loss: 2.4646918773651123
Validation loss: 1.9663109958812754

Epoch: 6| Step: 2
Training loss: 2.1857476234436035
Validation loss: 1.967436017528657

Epoch: 6| Step: 3
Training loss: 2.615086078643799
Validation loss: 1.9648262249526156

Epoch: 6| Step: 4
Training loss: 2.8098762035369873
Validation loss: 1.9666007616186654

Epoch: 6| Step: 5
Training loss: 2.279017448425293
Validation loss: 1.9631265183930755

Epoch: 6| Step: 6
Training loss: 1.9693882465362549
Validation loss: 1.9573154693008752

Epoch: 6| Step: 7
Training loss: 2.666884422302246
Validation loss: 1.9541449431450135

Epoch: 6| Step: 8
Training loss: 2.4046695232391357
Validation loss: 1.9665357156466412

Epoch: 6| Step: 9
Training loss: 2.225018262863159
Validation loss: 1.9759496899061306

Epoch: 6| Step: 10
Training loss: 2.0954031944274902
Validation loss: 1.9841192409556399

Epoch: 6| Step: 11
Training loss: 2.5257315635681152
Validation loss: 1.9968862482296523

Epoch: 6| Step: 12
Training loss: 1.887965440750122
Validation loss: 2.0019520123799643

Epoch: 6| Step: 13
Training loss: 1.8532897233963013
Validation loss: 1.9987898924017464

Epoch: 94| Step: 0
Training loss: 2.417506217956543
Validation loss: 2.0086020449156403

Epoch: 6| Step: 1
Training loss: 1.685624122619629
Validation loss: 2.0173521195688555

Epoch: 6| Step: 2
Training loss: 2.5447998046875
Validation loss: 2.005654345276535

Epoch: 6| Step: 3
Training loss: 2.384598731994629
Validation loss: 2.01652196914919

Epoch: 6| Step: 4
Training loss: 2.772184133529663
Validation loss: 2.013587504304865

Epoch: 6| Step: 5
Training loss: 2.64675235748291
Validation loss: 1.9952415061253372

Epoch: 6| Step: 6
Training loss: 2.465245485305786
Validation loss: 2.003167957387945

Epoch: 6| Step: 7
Training loss: 2.3045456409454346
Validation loss: 2.001151310500278

Epoch: 6| Step: 8
Training loss: 2.3532752990722656
Validation loss: 1.999543051565847

Epoch: 6| Step: 9
Training loss: 1.7025772333145142
Validation loss: 1.9934358699347383

Epoch: 6| Step: 10
Training loss: 2.7742159366607666
Validation loss: 1.974082512240256

Epoch: 6| Step: 11
Training loss: 2.549696922302246
Validation loss: 1.9652091508270593

Epoch: 6| Step: 12
Training loss: 1.2746970653533936
Validation loss: 1.9524602838741836

Epoch: 6| Step: 13
Training loss: 2.334094524383545
Validation loss: 1.9642212544718096

Epoch: 95| Step: 0
Training loss: 3.0867433547973633
Validation loss: 1.9579302021252212

Epoch: 6| Step: 1
Training loss: 2.382810592651367
Validation loss: 1.958482030899294

Epoch: 6| Step: 2
Training loss: 1.5522902011871338
Validation loss: 1.962738754928753

Epoch: 6| Step: 3
Training loss: 2.594200611114502
Validation loss: 1.962768930260853

Epoch: 6| Step: 4
Training loss: 2.5284643173217773
Validation loss: 1.9722797204089422

Epoch: 6| Step: 5
Training loss: 2.295431613922119
Validation loss: 2.0082703867266254

Epoch: 6| Step: 6
Training loss: 2.2816572189331055
Validation loss: 2.04052706174953

Epoch: 6| Step: 7
Training loss: 2.5239429473876953
Validation loss: 2.052236100678803

Epoch: 6| Step: 8
Training loss: 1.7271727323532104
Validation loss: 2.046296327344833

Epoch: 6| Step: 9
Training loss: 2.6096129417419434
Validation loss: 2.013867570507911

Epoch: 6| Step: 10
Training loss: 2.3794171810150146
Validation loss: 2.0024866045162244

Epoch: 6| Step: 11
Training loss: 2.1866400241851807
Validation loss: 2.0109151947882866

Epoch: 6| Step: 12
Training loss: 1.936832308769226
Validation loss: 2.0057744236402613

Epoch: 6| Step: 13
Training loss: 1.9951528310775757
Validation loss: 2.0044611269427883

Epoch: 96| Step: 0
Training loss: 2.1595005989074707
Validation loss: 1.9813187840164348

Epoch: 6| Step: 1
Training loss: 2.586148738861084
Validation loss: 1.9826714582340692

Epoch: 6| Step: 2
Training loss: 2.197598934173584
Validation loss: 1.9817547003428142

Epoch: 6| Step: 3
Training loss: 2.2603206634521484
Validation loss: 1.98309794164473

Epoch: 6| Step: 4
Training loss: 1.749727725982666
Validation loss: 1.97620020245993

Epoch: 6| Step: 5
Training loss: 2.616934061050415
Validation loss: 1.985045471499043

Epoch: 6| Step: 6
Training loss: 2.8852338790893555
Validation loss: 1.9768274830233665

Epoch: 6| Step: 7
Training loss: 2.1996219158172607
Validation loss: 1.9806858147344282

Epoch: 6| Step: 8
Training loss: 1.6713616847991943
Validation loss: 1.991695459171008

Epoch: 6| Step: 9
Training loss: 2.540215492248535
Validation loss: 1.998783032099406

Epoch: 6| Step: 10
Training loss: 2.0087172985076904
Validation loss: 1.9900000685004777

Epoch: 6| Step: 11
Training loss: 2.393467903137207
Validation loss: 1.9956467177278252

Epoch: 6| Step: 12
Training loss: 2.356449604034424
Validation loss: 2.013159674982871

Epoch: 6| Step: 13
Training loss: 2.0660290718078613
Validation loss: 2.009973100436631

Epoch: 97| Step: 0
Training loss: 1.6402435302734375
Validation loss: 1.9900139531781595

Epoch: 6| Step: 1
Training loss: 2.319570541381836
Validation loss: 1.984899818256337

Epoch: 6| Step: 2
Training loss: 2.3684544563293457
Validation loss: 1.9845745948053175

Epoch: 6| Step: 3
Training loss: 2.6864545345306396
Validation loss: 1.9929680209006033

Epoch: 6| Step: 4
Training loss: 2.768134117126465
Validation loss: 2.007138790622834

Epoch: 6| Step: 5
Training loss: 2.568382978439331
Validation loss: 2.0065492468495525

Epoch: 6| Step: 6
Training loss: 2.0942203998565674
Validation loss: 2.0053983349953928

Epoch: 6| Step: 7
Training loss: 2.261789083480835
Validation loss: 1.9994941167933966

Epoch: 6| Step: 8
Training loss: 2.2790632247924805
Validation loss: 1.9913653635209607

Epoch: 6| Step: 9
Training loss: 2.2875354290008545
Validation loss: 2.008628511941561

Epoch: 6| Step: 10
Training loss: 2.2183661460876465
Validation loss: 2.0158472830249416

Epoch: 6| Step: 11
Training loss: 1.8966528177261353
Validation loss: 2.028771464542676

Epoch: 6| Step: 12
Training loss: 2.0509636402130127
Validation loss: 2.0362302846806024

Epoch: 6| Step: 13
Training loss: 2.3850107192993164
Validation loss: 2.057072365155784

Epoch: 98| Step: 0
Training loss: 2.3248088359832764
Validation loss: 2.0385709847173383

Epoch: 6| Step: 1
Training loss: 1.9339468479156494
Validation loss: 2.0273904185141287

Epoch: 6| Step: 2
Training loss: 2.3511080741882324
Validation loss: 2.007693103564683

Epoch: 6| Step: 3
Training loss: 1.7452852725982666
Validation loss: 1.9979532149530226

Epoch: 6| Step: 4
Training loss: 2.0004377365112305
Validation loss: 1.9923940832896898

Epoch: 6| Step: 5
Training loss: 2.1946115493774414
Validation loss: 1.984123827308737

Epoch: 6| Step: 6
Training loss: 1.6626060009002686
Validation loss: 1.9893429176781767

Epoch: 6| Step: 7
Training loss: 2.750112771987915
Validation loss: 1.980045413458219

Epoch: 6| Step: 8
Training loss: 2.7297511100769043
Validation loss: 1.9834688043081632

Epoch: 6| Step: 9
Training loss: 2.8057079315185547
Validation loss: 1.9903310011791926

Epoch: 6| Step: 10
Training loss: 2.560713052749634
Validation loss: 1.9862541421767204

Epoch: 6| Step: 11
Training loss: 2.406582832336426
Validation loss: 1.9763410975856166

Epoch: 6| Step: 12
Training loss: 2.2607297897338867
Validation loss: 1.9781069371008104

Epoch: 6| Step: 13
Training loss: 1.8139605522155762
Validation loss: 1.98240485114436

Epoch: 99| Step: 0
Training loss: 2.707897663116455
Validation loss: 1.9871315251114547

Epoch: 6| Step: 1
Training loss: 2.124786853790283
Validation loss: 1.9883787170533211

Epoch: 6| Step: 2
Training loss: 2.159595012664795
Validation loss: 1.986010507870746

Epoch: 6| Step: 3
Training loss: 2.19718861579895
Validation loss: 2.005620869257117

Epoch: 6| Step: 4
Training loss: 2.187849283218384
Validation loss: 2.0104359003805343

Epoch: 6| Step: 5
Training loss: 2.442783832550049
Validation loss: 2.0053920169030466

Epoch: 6| Step: 6
Training loss: 1.737605094909668
Validation loss: 1.9937874655569754

Epoch: 6| Step: 7
Training loss: 1.7140889167785645
Validation loss: 1.989994102908719

Epoch: 6| Step: 8
Training loss: 2.0268568992614746
Validation loss: 1.9989204816920783

Epoch: 6| Step: 9
Training loss: 2.866407871246338
Validation loss: 1.9775210401063323

Epoch: 6| Step: 10
Training loss: 2.5148913860321045
Validation loss: 1.9844842392911193

Epoch: 6| Step: 11
Training loss: 2.4071083068847656
Validation loss: 1.9800716933383737

Epoch: 6| Step: 12
Training loss: 2.5101943016052246
Validation loss: 1.9999488976693922

Epoch: 6| Step: 13
Training loss: 1.750404953956604
Validation loss: 1.9758754109823575

Epoch: 100| Step: 0
Training loss: 1.8842235803604126
Validation loss: 1.975450211955655

Epoch: 6| Step: 1
Training loss: 2.660310745239258
Validation loss: 1.9734471908179663

Epoch: 6| Step: 2
Training loss: 2.016328811645508
Validation loss: 1.9722704477207635

Epoch: 6| Step: 3
Training loss: 2.4069294929504395
Validation loss: 1.9714154351142146

Epoch: 6| Step: 4
Training loss: 2.202120542526245
Validation loss: 1.9778904376491424

Epoch: 6| Step: 5
Training loss: 1.3732491731643677
Validation loss: 1.9744960159383795

Epoch: 6| Step: 6
Training loss: 1.9196113348007202
Validation loss: 1.967762690718456

Epoch: 6| Step: 7
Training loss: 2.012298107147217
Validation loss: 1.9709603286558581

Epoch: 6| Step: 8
Training loss: 2.8832266330718994
Validation loss: 1.9790155067238757

Epoch: 6| Step: 9
Training loss: 2.902580738067627
Validation loss: 1.9727836834487094

Epoch: 6| Step: 10
Training loss: 2.1457996368408203
Validation loss: 1.9811967752313102

Epoch: 6| Step: 11
Training loss: 2.75203013420105
Validation loss: 1.9711937827448691

Epoch: 6| Step: 12
Training loss: 2.0575308799743652
Validation loss: 1.9630291013307468

Epoch: 6| Step: 13
Training loss: 1.9054780006408691
Validation loss: 1.9617854305492934

Epoch: 101| Step: 0
Training loss: 2.401341199874878
Validation loss: 1.9583370583031767

Epoch: 6| Step: 1
Training loss: 2.648514747619629
Validation loss: 1.9633687747422086

Epoch: 6| Step: 2
Training loss: 2.6312856674194336
Validation loss: 1.9640759357842066

Epoch: 6| Step: 3
Training loss: 2.5124900341033936
Validation loss: 1.9480807294127762

Epoch: 6| Step: 4
Training loss: 2.136962890625
Validation loss: 1.9448892044764694

Epoch: 6| Step: 5
Training loss: 2.5021920204162598
Validation loss: 1.9476876143486268

Epoch: 6| Step: 6
Training loss: 2.0286478996276855
Validation loss: 1.9667970903458134

Epoch: 6| Step: 7
Training loss: 2.56333327293396
Validation loss: 1.9910013060415945

Epoch: 6| Step: 8
Training loss: 1.8023995161056519
Validation loss: 2.0231792016695906

Epoch: 6| Step: 9
Training loss: 2.5629866123199463
Validation loss: 2.0295417872808312

Epoch: 6| Step: 10
Training loss: 2.0024449825286865
Validation loss: 2.0406360421129452

Epoch: 6| Step: 11
Training loss: 2.5261616706848145
Validation loss: 2.0356492611669723

Epoch: 6| Step: 12
Training loss: 1.302198052406311
Validation loss: 2.030886603939918

Epoch: 6| Step: 13
Training loss: 2.214200735092163
Validation loss: 2.0184517368193595

Epoch: 102| Step: 0
Training loss: 1.9150488376617432
Validation loss: 2.0264812964265064

Epoch: 6| Step: 1
Training loss: 2.8457541465759277
Validation loss: 2.0464616924203853

Epoch: 6| Step: 2
Training loss: 2.6947033405303955
Validation loss: 2.05865450315578

Epoch: 6| Step: 3
Training loss: 2.584371566772461
Validation loss: 2.066318163307764

Epoch: 6| Step: 4
Training loss: 1.9184004068374634
Validation loss: 2.05526033524544

Epoch: 6| Step: 5
Training loss: 1.9696109294891357
Validation loss: 2.033718750041018

Epoch: 6| Step: 6
Training loss: 2.7631216049194336
Validation loss: 2.0032045892489854

Epoch: 6| Step: 7
Training loss: 2.359469413757324
Validation loss: 1.9764740749072003

Epoch: 6| Step: 8
Training loss: 2.372776508331299
Validation loss: 1.9822141149992585

Epoch: 6| Step: 9
Training loss: 1.59893798828125
Validation loss: 1.969412774168035

Epoch: 6| Step: 10
Training loss: 2.5296926498413086
Validation loss: 1.9734010837411369

Epoch: 6| Step: 11
Training loss: 2.5876078605651855
Validation loss: 1.968072396452709

Epoch: 6| Step: 12
Training loss: 1.2465556859970093
Validation loss: 1.9793691276222147

Epoch: 6| Step: 13
Training loss: 2.016462802886963
Validation loss: 1.962834978616366

Epoch: 103| Step: 0
Training loss: 2.127011299133301
Validation loss: 1.9729980653332126

Epoch: 6| Step: 1
Training loss: 2.1363539695739746
Validation loss: 1.974027333721038

Epoch: 6| Step: 2
Training loss: 2.6900885105133057
Validation loss: 1.9705979567702099

Epoch: 6| Step: 3
Training loss: 2.1476025581359863
Validation loss: 1.962031884859967

Epoch: 6| Step: 4
Training loss: 1.375295639038086
Validation loss: 1.9730561523027317

Epoch: 6| Step: 5
Training loss: 2.0100250244140625
Validation loss: 1.9827783979395384

Epoch: 6| Step: 6
Training loss: 1.6499801874160767
Validation loss: 1.9901678831346574

Epoch: 6| Step: 7
Training loss: 2.5787272453308105
Validation loss: 2.02247126384448

Epoch: 6| Step: 8
Training loss: 2.259617328643799
Validation loss: 2.060442300253017

Epoch: 6| Step: 9
Training loss: 2.571103572845459
Validation loss: 2.0617252229362406

Epoch: 6| Step: 10
Training loss: 2.38779616355896
Validation loss: 2.062050845033379

Epoch: 6| Step: 11
Training loss: 2.39552640914917
Validation loss: 2.05740632805773

Epoch: 6| Step: 12
Training loss: 2.6653761863708496
Validation loss: 2.0506525296036915

Epoch: 6| Step: 13
Training loss: 2.4881489276885986
Validation loss: 2.029730135394681

Epoch: 104| Step: 0
Training loss: 2.0694451332092285
Validation loss: 1.9918261843342935

Epoch: 6| Step: 1
Training loss: 1.9788737297058105
Validation loss: 1.9653649740321661

Epoch: 6| Step: 2
Training loss: 1.6805720329284668
Validation loss: 1.9598827849152267

Epoch: 6| Step: 3
Training loss: 2.421800136566162
Validation loss: 1.9689329131957023

Epoch: 6| Step: 4
Training loss: 2.4088850021362305
Validation loss: 1.9717341340998167

Epoch: 6| Step: 5
Training loss: 2.59212589263916
Validation loss: 1.9788051946188814

Epoch: 6| Step: 6
Training loss: 2.0468201637268066
Validation loss: 1.9779412477247176

Epoch: 6| Step: 7
Training loss: 2.258296489715576
Validation loss: 1.9814396455723753

Epoch: 6| Step: 8
Training loss: 2.210831642150879
Validation loss: 1.9796540890970538

Epoch: 6| Step: 9
Training loss: 2.595956802368164
Validation loss: 1.975225240953507

Epoch: 6| Step: 10
Training loss: 1.9776431322097778
Validation loss: 1.9827065839562366

Epoch: 6| Step: 11
Training loss: 2.214754343032837
Validation loss: 2.044106334768316

Epoch: 6| Step: 12
Training loss: 2.206510066986084
Validation loss: 2.0837906868227067

Epoch: 6| Step: 13
Training loss: 2.8781163692474365
Validation loss: 2.0993993692500617

Epoch: 105| Step: 0
Training loss: 2.022719383239746
Validation loss: 2.068770045875221

Epoch: 6| Step: 1
Training loss: 1.8137727975845337
Validation loss: 2.0128831517311836

Epoch: 6| Step: 2
Training loss: 1.9149659872055054
Validation loss: 1.9924041225064186

Epoch: 6| Step: 3
Training loss: 2.0560414791107178
Validation loss: 1.9953915201207644

Epoch: 6| Step: 4
Training loss: 2.4634504318237305
Validation loss: 2.0036378342618226

Epoch: 6| Step: 5
Training loss: 2.3383278846740723
Validation loss: 2.002427311353786

Epoch: 6| Step: 6
Training loss: 2.276383876800537
Validation loss: 2.037190709062802

Epoch: 6| Step: 7
Training loss: 2.068775177001953
Validation loss: 2.0223708627044514

Epoch: 6| Step: 8
Training loss: 2.3139867782592773
Validation loss: 1.9885084667513448

Epoch: 6| Step: 9
Training loss: 2.703754425048828
Validation loss: 1.9802012981907013

Epoch: 6| Step: 10
Training loss: 2.393674850463867
Validation loss: 1.9798976272665045

Epoch: 6| Step: 11
Training loss: 2.2041091918945312
Validation loss: 2.0028349122693463

Epoch: 6| Step: 12
Training loss: 2.858031749725342
Validation loss: 2.016387460052326

Epoch: 6| Step: 13
Training loss: 1.6738946437835693
Validation loss: 2.021338601266184

Epoch: 106| Step: 0
Training loss: 2.379051923751831
Validation loss: 2.0262179400331233

Epoch: 6| Step: 1
Training loss: 2.0541224479675293
Validation loss: 2.009653388812978

Epoch: 6| Step: 2
Training loss: 1.8783353567123413
Validation loss: 2.00197458523576

Epoch: 6| Step: 3
Training loss: 2.617033004760742
Validation loss: 1.9787784943016626

Epoch: 6| Step: 4
Training loss: 2.104339599609375
Validation loss: 1.9823005622433079

Epoch: 6| Step: 5
Training loss: 2.6862382888793945
Validation loss: 1.9744861190037062

Epoch: 6| Step: 6
Training loss: 1.8160114288330078
Validation loss: 1.9887555952995055

Epoch: 6| Step: 7
Training loss: 2.218007802963257
Validation loss: 2.0044337088061916

Epoch: 6| Step: 8
Training loss: 2.302473306655884
Validation loss: 2.006948641551438

Epoch: 6| Step: 9
Training loss: 2.7184274196624756
Validation loss: 2.0023311209935013

Epoch: 6| Step: 10
Training loss: 1.5394487380981445
Validation loss: 2.0085943437391713

Epoch: 6| Step: 11
Training loss: 2.3548660278320312
Validation loss: 2.0205865316493536

Epoch: 6| Step: 12
Training loss: 2.1923093795776367
Validation loss: 2.030893423224008

Epoch: 6| Step: 13
Training loss: 2.6089794635772705
Validation loss: 2.0223781370347544

Epoch: 107| Step: 0
Training loss: 1.8573808670043945
Validation loss: 2.004620066253088

Epoch: 6| Step: 1
Training loss: 2.714794874191284
Validation loss: 2.0030666833282798

Epoch: 6| Step: 2
Training loss: 1.7281379699707031
Validation loss: 1.9935339996891637

Epoch: 6| Step: 3
Training loss: 1.8940279483795166
Validation loss: 1.9865225873967653

Epoch: 6| Step: 4
Training loss: 3.0194387435913086
Validation loss: 2.0008810335589993

Epoch: 6| Step: 5
Training loss: 1.6478271484375
Validation loss: 2.010565802615176

Epoch: 6| Step: 6
Training loss: 2.127746105194092
Validation loss: 2.0059563959798505

Epoch: 6| Step: 7
Training loss: 2.4927499294281006
Validation loss: 2.017290061519992

Epoch: 6| Step: 8
Training loss: 2.4697060585021973
Validation loss: 2.0238120350786435

Epoch: 6| Step: 9
Training loss: 2.3102729320526123
Validation loss: 2.0216223732117684

Epoch: 6| Step: 10
Training loss: 2.3539681434631348
Validation loss: 2.0595589350628596

Epoch: 6| Step: 11
Training loss: 2.389580726623535
Validation loss: 2.1003659617516304

Epoch: 6| Step: 12
Training loss: 2.0505075454711914
Validation loss: 2.159000301873812

Epoch: 6| Step: 13
Training loss: 2.438723564147949
Validation loss: 2.16063698645561

Epoch: 108| Step: 0
Training loss: 2.222608804702759
Validation loss: 2.1543618338082426

Epoch: 6| Step: 1
Training loss: 2.5663604736328125
Validation loss: 2.137477074899981

Epoch: 6| Step: 2
Training loss: 2.470674991607666
Validation loss: 2.139576001833844

Epoch: 6| Step: 3
Training loss: 2.435698986053467
Validation loss: 2.1073112231428905

Epoch: 6| Step: 4
Training loss: 2.0840561389923096
Validation loss: 2.095930435324228

Epoch: 6| Step: 5
Training loss: 2.8139591217041016
Validation loss: 2.0923474488719815

Epoch: 6| Step: 6
Training loss: 2.3298211097717285
Validation loss: 2.089307608142976

Epoch: 6| Step: 7
Training loss: 2.640719175338745
Validation loss: 2.0800215582693777

Epoch: 6| Step: 8
Training loss: 2.725891351699829
Validation loss: 2.0567144142684115

Epoch: 6| Step: 9
Training loss: 1.4633350372314453
Validation loss: 2.057290131045926

Epoch: 6| Step: 10
Training loss: 1.233579158782959
Validation loss: 2.053041946503424

Epoch: 6| Step: 11
Training loss: 2.6077117919921875
Validation loss: 2.0623549056309525

Epoch: 6| Step: 12
Training loss: 1.7932239770889282
Validation loss: 2.044543820042764

Epoch: 6| Step: 13
Training loss: 2.036752939224243
Validation loss: 2.0478536390489146

Epoch: 109| Step: 0
Training loss: 1.7309229373931885
Validation loss: 2.0375538641406643

Epoch: 6| Step: 1
Training loss: 2.2208402156829834
Validation loss: 2.032203535879812

Epoch: 6| Step: 2
Training loss: 1.9869379997253418
Validation loss: 2.022290911725772

Epoch: 6| Step: 3
Training loss: 2.0351085662841797
Validation loss: 2.03033015548542

Epoch: 6| Step: 4
Training loss: 2.221299648284912
Validation loss: 2.0404932986023607

Epoch: 6| Step: 5
Training loss: 2.50278377532959
Validation loss: 2.047685569332492

Epoch: 6| Step: 6
Training loss: 1.625230073928833
Validation loss: 2.027416641994189

Epoch: 6| Step: 7
Training loss: 2.605804443359375
Validation loss: 2.0242707101247643

Epoch: 6| Step: 8
Training loss: 3.1477837562561035
Validation loss: 2.010701539695904

Epoch: 6| Step: 9
Training loss: 1.8500449657440186
Validation loss: 2.0008423956491614

Epoch: 6| Step: 10
Training loss: 2.6578569412231445
Validation loss: 2.0040713048750356

Epoch: 6| Step: 11
Training loss: 2.1951115131378174
Validation loss: 2.0064181896948043

Epoch: 6| Step: 12
Training loss: 2.0778818130493164
Validation loss: 2.0195871553113385

Epoch: 6| Step: 13
Training loss: 1.7825071811676025
Validation loss: 2.0256122530147596

Epoch: 110| Step: 0
Training loss: 2.4681310653686523
Validation loss: 2.0242699320598314

Epoch: 6| Step: 1
Training loss: 1.297351598739624
Validation loss: 2.02553367358382

Epoch: 6| Step: 2
Training loss: 2.0123062133789062
Validation loss: 2.0112024750760806

Epoch: 6| Step: 3
Training loss: 2.379983425140381
Validation loss: 2.012191164878107

Epoch: 6| Step: 4
Training loss: 2.344815731048584
Validation loss: 2.016676591288659

Epoch: 6| Step: 5
Training loss: 2.6032626628875732
Validation loss: 2.012918842736111

Epoch: 6| Step: 6
Training loss: 2.7194252014160156
Validation loss: 2.0343212004630797

Epoch: 6| Step: 7
Training loss: 2.3417251110076904
Validation loss: 2.026843788803265

Epoch: 6| Step: 8
Training loss: 2.081437110900879
Validation loss: 2.0071422771740983

Epoch: 6| Step: 9
Training loss: 2.5634422302246094
Validation loss: 1.993737264346051

Epoch: 6| Step: 10
Training loss: 1.479222297668457
Validation loss: 2.0012339904744136

Epoch: 6| Step: 11
Training loss: 2.052450656890869
Validation loss: 2.011332914393435

Epoch: 6| Step: 12
Training loss: 2.4907045364379883
Validation loss: 2.0123885728979625

Epoch: 6| Step: 13
Training loss: 1.9293276071548462
Validation loss: 2.029467375047745

Epoch: 111| Step: 0
Training loss: 2.3641762733459473
Validation loss: 2.032063900783498

Epoch: 6| Step: 1
Training loss: 1.8929574489593506
Validation loss: 2.043030668330449

Epoch: 6| Step: 2
Training loss: 2.3292741775512695
Validation loss: 2.0286866746922976

Epoch: 6| Step: 3
Training loss: 2.574267864227295
Validation loss: 2.025564953845034

Epoch: 6| Step: 4
Training loss: 2.234450340270996
Validation loss: 2.016114159296918

Epoch: 6| Step: 5
Training loss: 1.8379559516906738
Validation loss: 2.0008174245075514

Epoch: 6| Step: 6
Training loss: 1.9006016254425049
Validation loss: 2.00769381882042

Epoch: 6| Step: 7
Training loss: 2.3310084342956543
Validation loss: 2.0062909305736585

Epoch: 6| Step: 8
Training loss: 1.7057949304580688
Validation loss: 2.01148287967969

Epoch: 6| Step: 9
Training loss: 1.9864914417266846
Validation loss: 2.032607591280373

Epoch: 6| Step: 10
Training loss: 2.870285987854004
Validation loss: 2.039658993803045

Epoch: 6| Step: 11
Training loss: 2.249506950378418
Validation loss: 2.0439569616830475

Epoch: 6| Step: 12
Training loss: 2.285946846008301
Validation loss: 2.02736638181953

Epoch: 6| Step: 13
Training loss: 2.15105938911438
Validation loss: 2.0002450994265977

Epoch: 112| Step: 0
Training loss: 1.6645092964172363
Validation loss: 2.002585267507902

Epoch: 6| Step: 1
Training loss: 1.530774712562561
Validation loss: 1.991930741135792

Epoch: 6| Step: 2
Training loss: 2.3307199478149414
Validation loss: 2.0155269625366374

Epoch: 6| Step: 3
Training loss: 1.8883672952651978
Validation loss: 2.022811169265419

Epoch: 6| Step: 4
Training loss: 2.6706340312957764
Validation loss: 2.0470781890294885

Epoch: 6| Step: 5
Training loss: 2.311587333679199
Validation loss: 2.061657469759705

Epoch: 6| Step: 6
Training loss: 2.1999547481536865
Validation loss: 2.0619728167851767

Epoch: 6| Step: 7
Training loss: 2.379819869995117
Validation loss: 2.0342364811128184

Epoch: 6| Step: 8
Training loss: 1.887317180633545
Validation loss: 2.0158633814063123

Epoch: 6| Step: 9
Training loss: 2.4919650554656982
Validation loss: 2.023136144043297

Epoch: 6| Step: 10
Training loss: 2.465998888015747
Validation loss: 2.0218208323242846

Epoch: 6| Step: 11
Training loss: 2.573823928833008
Validation loss: 2.0066354864387104

Epoch: 6| Step: 12
Training loss: 2.211277484893799
Validation loss: 1.9950482396669285

Epoch: 6| Step: 13
Training loss: 2.0020864009857178
Validation loss: 1.9865567325263895

Epoch: 113| Step: 0
Training loss: 3.3869547843933105
Validation loss: 1.979200300349984

Epoch: 6| Step: 1
Training loss: 2.100794792175293
Validation loss: 1.986418229277416

Epoch: 6| Step: 2
Training loss: 2.716642141342163
Validation loss: 1.9934617768051803

Epoch: 6| Step: 3
Training loss: 1.6118682622909546
Validation loss: 1.9876431726640271

Epoch: 6| Step: 4
Training loss: 1.6716519594192505
Validation loss: 1.9938532485756824

Epoch: 6| Step: 5
Training loss: 2.2680459022521973
Validation loss: 2.000333639883226

Epoch: 6| Step: 6
Training loss: 2.252063512802124
Validation loss: 1.9857838576839817

Epoch: 6| Step: 7
Training loss: 1.9418865442276
Validation loss: 1.9727027493138467

Epoch: 6| Step: 8
Training loss: 2.3955183029174805
Validation loss: 1.976268817019719

Epoch: 6| Step: 9
Training loss: 1.3663113117218018
Validation loss: 1.9741217526056434

Epoch: 6| Step: 10
Training loss: 1.49784517288208
Validation loss: 1.9697774994757868

Epoch: 6| Step: 11
Training loss: 2.5315802097320557
Validation loss: 1.9640268330932946

Epoch: 6| Step: 12
Training loss: 2.014918088912964
Validation loss: 1.963013038840345

Epoch: 6| Step: 13
Training loss: 2.4043989181518555
Validation loss: 1.976132131391956

Epoch: 114| Step: 0
Training loss: 1.5928752422332764
Validation loss: 1.986889014961899

Epoch: 6| Step: 1
Training loss: 2.5805649757385254
Validation loss: 1.98946633262019

Epoch: 6| Step: 2
Training loss: 1.9381895065307617
Validation loss: 2.0066312307952554

Epoch: 6| Step: 3
Training loss: 2.7881078720092773
Validation loss: 2.0063511966377177

Epoch: 6| Step: 4
Training loss: 2.3944180011749268
Validation loss: 2.0060688167489986

Epoch: 6| Step: 5
Training loss: 2.051679849624634
Validation loss: 1.9975046073236773

Epoch: 6| Step: 6
Training loss: 1.6156532764434814
Validation loss: 2.00079337755839

Epoch: 6| Step: 7
Training loss: 2.426676034927368
Validation loss: 1.98964137031186

Epoch: 6| Step: 8
Training loss: 2.8211426734924316
Validation loss: 2.0003152560162287

Epoch: 6| Step: 9
Training loss: 1.5129557847976685
Validation loss: 2.005056283807242

Epoch: 6| Step: 10
Training loss: 1.7675215005874634
Validation loss: 1.9946389531576505

Epoch: 6| Step: 11
Training loss: 2.470630645751953
Validation loss: 2.004336746790076

Epoch: 6| Step: 12
Training loss: 2.0751447677612305
Validation loss: 2.0111090303749166

Epoch: 6| Step: 13
Training loss: 1.50435209274292
Validation loss: 2.0423216101943806

Epoch: 115| Step: 0
Training loss: 2.500311851501465
Validation loss: 2.066953969258134

Epoch: 6| Step: 1
Training loss: 1.9439144134521484
Validation loss: 2.089652556245045

Epoch: 6| Step: 2
Training loss: 2.46187162399292
Validation loss: 2.1106767449327695

Epoch: 6| Step: 3
Training loss: 2.53102445602417
Validation loss: 2.112592178006326

Epoch: 6| Step: 4
Training loss: 1.6990171670913696
Validation loss: 2.1163504328778995

Epoch: 6| Step: 5
Training loss: 1.9408864974975586
Validation loss: 2.120546305051414

Epoch: 6| Step: 6
Training loss: 2.592473030090332
Validation loss: 2.133322231231197

Epoch: 6| Step: 7
Training loss: 2.1856420040130615
Validation loss: 2.1273138318010556

Epoch: 6| Step: 8
Training loss: 2.170225143432617
Validation loss: 2.114442627917054

Epoch: 6| Step: 9
Training loss: 1.6178382635116577
Validation loss: 2.0734220884179555

Epoch: 6| Step: 10
Training loss: 2.1538777351379395
Validation loss: 2.0621778631723053

Epoch: 6| Step: 11
Training loss: 2.2492523193359375
Validation loss: 2.0369659828883346

Epoch: 6| Step: 12
Training loss: 2.2630934715270996
Validation loss: 2.0321970601235666

Epoch: 6| Step: 13
Training loss: 1.4522345066070557
Validation loss: 2.0315878929630404

Epoch: 116| Step: 0
Training loss: 2.7600512504577637
Validation loss: 2.0098181886057698

Epoch: 6| Step: 1
Training loss: 1.8162065744400024
Validation loss: 2.0322326844738376

Epoch: 6| Step: 2
Training loss: 1.8405758142471313
Validation loss: 2.061684581541246

Epoch: 6| Step: 3
Training loss: 2.0943188667297363
Validation loss: 2.0951468842003935

Epoch: 6| Step: 4
Training loss: 2.3481783866882324
Validation loss: 2.1198226149364183

Epoch: 6| Step: 5
Training loss: 1.6466753482818604
Validation loss: 2.1154731935070408

Epoch: 6| Step: 6
Training loss: 1.9932669401168823
Validation loss: 2.1300927054497505

Epoch: 6| Step: 7
Training loss: 2.632636785507202
Validation loss: 2.1250666444019606

Epoch: 6| Step: 8
Training loss: 2.572629451751709
Validation loss: 2.10265847175352

Epoch: 6| Step: 9
Training loss: 1.2426807880401611
Validation loss: 2.0752613326554656

Epoch: 6| Step: 10
Training loss: 2.2994797229766846
Validation loss: 2.0455464393861833

Epoch: 6| Step: 11
Training loss: 2.6859893798828125
Validation loss: 2.023518516171363

Epoch: 6| Step: 12
Training loss: 1.5966782569885254
Validation loss: 2.0235965431377454

Epoch: 6| Step: 13
Training loss: 2.3469419479370117
Validation loss: 2.011252046913229

Epoch: 117| Step: 0
Training loss: 2.0975260734558105
Validation loss: 2.0364875896002657

Epoch: 6| Step: 1
Training loss: 2.5081887245178223
Validation loss: 2.035474369602819

Epoch: 6| Step: 2
Training loss: 2.137439489364624
Validation loss: 2.0298771794124315

Epoch: 6| Step: 3
Training loss: 1.800510287284851
Validation loss: 2.02702138885375

Epoch: 6| Step: 4
Training loss: 2.891484260559082
Validation loss: 2.013169639854021

Epoch: 6| Step: 5
Training loss: 2.2414419651031494
Validation loss: 2.002096773475729

Epoch: 6| Step: 6
Training loss: 2.0231642723083496
Validation loss: 2.00540905357689

Epoch: 6| Step: 7
Training loss: 1.4254944324493408
Validation loss: 2.001868696622951

Epoch: 6| Step: 8
Training loss: 2.106316566467285
Validation loss: 1.9954288249374719

Epoch: 6| Step: 9
Training loss: 2.1930904388427734
Validation loss: 2.000027584773238

Epoch: 6| Step: 10
Training loss: 1.5762850046157837
Validation loss: 1.9938479751668952

Epoch: 6| Step: 11
Training loss: 1.4880704879760742
Validation loss: 1.9873747030893962

Epoch: 6| Step: 12
Training loss: 3.064011573791504
Validation loss: 1.989657268729261

Epoch: 6| Step: 13
Training loss: 2.548759937286377
Validation loss: 1.9794312189984065

Epoch: 118| Step: 0
Training loss: 1.8806116580963135
Validation loss: 1.9946933484846545

Epoch: 6| Step: 1
Training loss: 1.6184875965118408
Validation loss: 2.0002310711850404

Epoch: 6| Step: 2
Training loss: 2.3580751419067383
Validation loss: 1.9969279484082294

Epoch: 6| Step: 3
Training loss: 2.581432342529297
Validation loss: 2.0294271566534556

Epoch: 6| Step: 4
Training loss: 2.0216588973999023
Validation loss: 2.036026293231595

Epoch: 6| Step: 5
Training loss: 1.740939974784851
Validation loss: 2.0392058075115247

Epoch: 6| Step: 6
Training loss: 1.8643600940704346
Validation loss: 2.0367303868775726

Epoch: 6| Step: 7
Training loss: 2.5608019828796387
Validation loss: 2.0392928533656622

Epoch: 6| Step: 8
Training loss: 2.2572994232177734
Validation loss: 2.049430795895156

Epoch: 6| Step: 9
Training loss: 2.5439720153808594
Validation loss: 2.0438745047456477

Epoch: 6| Step: 10
Training loss: 1.6258902549743652
Validation loss: 2.014902112304523

Epoch: 6| Step: 11
Training loss: 2.351134777069092
Validation loss: 1.9799102737057594

Epoch: 6| Step: 12
Training loss: 2.639601707458496
Validation loss: 1.986014211049644

Epoch: 6| Step: 13
Training loss: 1.3855046033859253
Validation loss: 2.0051413095125588

Epoch: 119| Step: 0
Training loss: 2.072162389755249
Validation loss: 2.036017423034996

Epoch: 6| Step: 1
Training loss: 2.0068578720092773
Validation loss: 2.050127634438135

Epoch: 6| Step: 2
Training loss: 2.8629086017608643
Validation loss: 2.052241935524889

Epoch: 6| Step: 3
Training loss: 2.3046913146972656
Validation loss: 2.0457012550805205

Epoch: 6| Step: 4
Training loss: 2.2853212356567383
Validation loss: 2.028187233914611

Epoch: 6| Step: 5
Training loss: 1.5866189002990723
Validation loss: 2.015224708023892

Epoch: 6| Step: 6
Training loss: 2.5055341720581055
Validation loss: 2.017274473303108

Epoch: 6| Step: 7
Training loss: 2.375410556793213
Validation loss: 2.0439352822560135

Epoch: 6| Step: 8
Training loss: 2.231811046600342
Validation loss: 2.1034768601899505

Epoch: 6| Step: 9
Training loss: 2.2479753494262695
Validation loss: 2.14156053655891

Epoch: 6| Step: 10
Training loss: 2.090353488922119
Validation loss: 2.1584050117000455

Epoch: 6| Step: 11
Training loss: 1.9607568979263306
Validation loss: 2.178003611103181

Epoch: 6| Step: 12
Training loss: 2.4293463230133057
Validation loss: 2.1728873329777874

Epoch: 6| Step: 13
Training loss: 1.6217981576919556
Validation loss: 2.162126648810602

Epoch: 120| Step: 0
Training loss: 2.339726448059082
Validation loss: 2.114959321996217

Epoch: 6| Step: 1
Training loss: 1.9553472995758057
Validation loss: 2.0853701663273636

Epoch: 6| Step: 2
Training loss: 2.1791815757751465
Validation loss: 2.0505265343573784

Epoch: 6| Step: 3
Training loss: 2.201432943344116
Validation loss: 2.0606644281777005

Epoch: 6| Step: 4
Training loss: 1.9735451936721802
Validation loss: 2.0732688634626326

Epoch: 6| Step: 5
Training loss: 1.8116079568862915
Validation loss: 2.1010664022097023

Epoch: 6| Step: 6
Training loss: 1.6691535711288452
Validation loss: 2.139553164923063

Epoch: 6| Step: 7
Training loss: 1.5621308088302612
Validation loss: 2.163872141991892

Epoch: 6| Step: 8
Training loss: 3.168984889984131
Validation loss: 2.210214263649397

Epoch: 6| Step: 9
Training loss: 2.2087957859039307
Validation loss: 2.247505244388375

Epoch: 6| Step: 10
Training loss: 1.9134421348571777
Validation loss: 2.270216016359227

Epoch: 6| Step: 11
Training loss: 2.9141011238098145
Validation loss: 2.241582055245676

Epoch: 6| Step: 12
Training loss: 2.8928136825561523
Validation loss: 2.2042683452688236

Epoch: 6| Step: 13
Training loss: 2.551596164703369
Validation loss: 2.179451342551939

Epoch: 121| Step: 0
Training loss: 2.267796039581299
Validation loss: 2.121271558987197

Epoch: 6| Step: 1
Training loss: 2.053039789199829
Validation loss: 2.115268755984563

Epoch: 6| Step: 2
Training loss: 2.439767360687256
Validation loss: 2.1090179489504908

Epoch: 6| Step: 3
Training loss: 1.742872953414917
Validation loss: 2.082749225760019

Epoch: 6| Step: 4
Training loss: 1.6725289821624756
Validation loss: 2.060757424241753

Epoch: 6| Step: 5
Training loss: 2.8918826580047607
Validation loss: 2.0621282797987743

Epoch: 6| Step: 6
Training loss: 1.6918420791625977
Validation loss: 2.04835150318761

Epoch: 6| Step: 7
Training loss: 2.507009506225586
Validation loss: 2.0498467850428757

Epoch: 6| Step: 8
Training loss: 2.0539684295654297
Validation loss: 2.0685182002282914

Epoch: 6| Step: 9
Training loss: 2.26442551612854
Validation loss: 2.0695861154986965

Epoch: 6| Step: 10
Training loss: 2.2795324325561523
Validation loss: 2.093731411041752

Epoch: 6| Step: 11
Training loss: 2.00917911529541
Validation loss: 2.095501458773049

Epoch: 6| Step: 12
Training loss: 2.1475515365600586
Validation loss: 2.0672753677573255

Epoch: 6| Step: 13
Training loss: 1.602161169052124
Validation loss: 2.055297661853093

Epoch: 122| Step: 0
Training loss: 2.765026092529297
Validation loss: 2.0157321768422283

Epoch: 6| Step: 1
Training loss: 1.801818609237671
Validation loss: 2.0140098166722122

Epoch: 6| Step: 2
Training loss: 2.132915735244751
Validation loss: 2.0144917516298193

Epoch: 6| Step: 3
Training loss: 2.173643112182617
Validation loss: 2.011893441600184

Epoch: 6| Step: 4
Training loss: 1.9431712627410889
Validation loss: 2.0170977884723293

Epoch: 6| Step: 5
Training loss: 2.0641582012176514
Validation loss: 2.0115187885940715

Epoch: 6| Step: 6
Training loss: 2.2310075759887695
Validation loss: 1.9976204851622223

Epoch: 6| Step: 7
Training loss: 2.4387919902801514
Validation loss: 1.997780619129058

Epoch: 6| Step: 8
Training loss: 2.3415567874908447
Validation loss: 1.9952313002719675

Epoch: 6| Step: 9
Training loss: 2.0019006729125977
Validation loss: 1.9940650565649873

Epoch: 6| Step: 10
Training loss: 2.5410542488098145
Validation loss: 1.995779937313449

Epoch: 6| Step: 11
Training loss: 1.463879108428955
Validation loss: 2.014156960671948

Epoch: 6| Step: 12
Training loss: 2.033254623413086
Validation loss: 2.0033756584249516

Epoch: 6| Step: 13
Training loss: 1.1921700239181519
Validation loss: 2.020893576324627

Epoch: 123| Step: 0
Training loss: 1.4092806577682495
Validation loss: 2.0227005327901533

Epoch: 6| Step: 1
Training loss: 2.320005416870117
Validation loss: 2.053395508438028

Epoch: 6| Step: 2
Training loss: 1.2896442413330078
Validation loss: 2.0625273566092215

Epoch: 6| Step: 3
Training loss: 2.455108165740967
Validation loss: 2.0780259306712816

Epoch: 6| Step: 4
Training loss: 2.74092173576355
Validation loss: 2.0834664375551286

Epoch: 6| Step: 5
Training loss: 2.6152501106262207
Validation loss: 2.0758351228570424

Epoch: 6| Step: 6
Training loss: 2.437704563140869
Validation loss: 2.0595389361022622

Epoch: 6| Step: 7
Training loss: 2.143275737762451
Validation loss: 2.0461258901062833

Epoch: 6| Step: 8
Training loss: 1.832956075668335
Validation loss: 2.0377776481771983

Epoch: 6| Step: 9
Training loss: 1.6344482898712158
Validation loss: 2.0436322253237487

Epoch: 6| Step: 10
Training loss: 2.1690893173217773
Validation loss: 2.05066147799133

Epoch: 6| Step: 11
Training loss: 2.3647780418395996
Validation loss: 2.043013905966154

Epoch: 6| Step: 12
Training loss: 2.0991218090057373
Validation loss: 2.0462917435553765

Epoch: 6| Step: 13
Training loss: 2.013542652130127
Validation loss: 2.047382741846064

Epoch: 124| Step: 0
Training loss: 1.1397857666015625
Validation loss: 2.0570827504639984

Epoch: 6| Step: 1
Training loss: 2.655449151992798
Validation loss: 2.059779833721858

Epoch: 6| Step: 2
Training loss: 2.579369068145752
Validation loss: 2.061653378189251

Epoch: 6| Step: 3
Training loss: 2.292466640472412
Validation loss: 2.065158203083982

Epoch: 6| Step: 4
Training loss: 1.9181690216064453
Validation loss: 2.0626137333531536

Epoch: 6| Step: 5
Training loss: 1.7351073026657104
Validation loss: 2.0721599107147544

Epoch: 6| Step: 6
Training loss: 2.064633846282959
Validation loss: 2.0796986241494455

Epoch: 6| Step: 7
Training loss: 2.439075469970703
Validation loss: 2.074119931908064

Epoch: 6| Step: 8
Training loss: 1.9709746837615967
Validation loss: 2.0634600859816357

Epoch: 6| Step: 9
Training loss: 1.7873519659042358
Validation loss: 2.0732455253601074

Epoch: 6| Step: 10
Training loss: 1.6298108100891113
Validation loss: 2.0667266563702653

Epoch: 6| Step: 11
Training loss: 1.8906289339065552
Validation loss: 2.07337793227165

Epoch: 6| Step: 12
Training loss: 2.153446674346924
Validation loss: 2.074419113897508

Epoch: 6| Step: 13
Training loss: 2.319617748260498
Validation loss: 2.056029840182233

Epoch: 125| Step: 0
Training loss: 2.2419843673706055
Validation loss: 2.0491246331122612

Epoch: 6| Step: 1
Training loss: 2.019618034362793
Validation loss: 2.04718513898952

Epoch: 6| Step: 2
Training loss: 1.5901753902435303
Validation loss: 2.0577335870394142

Epoch: 6| Step: 3
Training loss: 1.8156862258911133
Validation loss: 2.0474733485970447

Epoch: 6| Step: 4
Training loss: 2.01643705368042
Validation loss: 2.0831615976108018

Epoch: 6| Step: 5
Training loss: 1.9334028959274292
Validation loss: 2.097845754315776

Epoch: 6| Step: 6
Training loss: 1.942529559135437
Validation loss: 2.103572254539818

Epoch: 6| Step: 7
Training loss: 2.412724733352661
Validation loss: 2.0805380293118056

Epoch: 6| Step: 8
Training loss: 2.089855670928955
Validation loss: 2.0437029971871326

Epoch: 6| Step: 9
Training loss: 2.298365354537964
Validation loss: 2.0370805263519287

Epoch: 6| Step: 10
Training loss: 1.9802780151367188
Validation loss: 2.0414843713083575

Epoch: 6| Step: 11
Training loss: 2.1620829105377197
Validation loss: 2.02385458125863

Epoch: 6| Step: 12
Training loss: 1.9287925958633423
Validation loss: 2.0320098964116906

Epoch: 6| Step: 13
Training loss: 2.0042502880096436
Validation loss: 2.0366896070459837

Epoch: 126| Step: 0
Training loss: 1.8430354595184326
Validation loss: 2.03252508050652

Epoch: 6| Step: 1
Training loss: 2.6624112129211426
Validation loss: 2.0570595507980673

Epoch: 6| Step: 2
Training loss: 1.843540906906128
Validation loss: 2.0820097936097013

Epoch: 6| Step: 3
Training loss: 2.0150792598724365
Validation loss: 2.0823961714262604

Epoch: 6| Step: 4
Training loss: 2.0069994926452637
Validation loss: 2.091914984487718

Epoch: 6| Step: 5
Training loss: 1.7056808471679688
Validation loss: 2.0918772220611572

Epoch: 6| Step: 6
Training loss: 1.8623453378677368
Validation loss: 2.0838467664616083

Epoch: 6| Step: 7
Training loss: 1.8675633668899536
Validation loss: 2.073426515825333

Epoch: 6| Step: 8
Training loss: 1.8219408988952637
Validation loss: 2.0545485327320714

Epoch: 6| Step: 9
Training loss: 1.8556621074676514
Validation loss: 2.055496137629273

Epoch: 6| Step: 10
Training loss: 2.468622922897339
Validation loss: 2.040228964180075

Epoch: 6| Step: 11
Training loss: 1.9913907051086426
Validation loss: 2.048655994476811

Epoch: 6| Step: 12
Training loss: 1.9323279857635498
Validation loss: 2.0642399608447985

Epoch: 6| Step: 13
Training loss: 2.609219551086426
Validation loss: 2.0608613593603975

Epoch: 127| Step: 0
Training loss: 2.0754737854003906
Validation loss: 2.0723386067216114

Epoch: 6| Step: 1
Training loss: 1.5718599557876587
Validation loss: 2.0916907684777373

Epoch: 6| Step: 2
Training loss: 2.1674766540527344
Validation loss: 2.0872849187543316

Epoch: 6| Step: 3
Training loss: 2.1627063751220703
Validation loss: 2.0898913324520154

Epoch: 6| Step: 4
Training loss: 1.893572211265564
Validation loss: 2.0965820499645766

Epoch: 6| Step: 5
Training loss: 2.2024526596069336
Validation loss: 2.1019050562253563

Epoch: 6| Step: 6
Training loss: 1.9822332859039307
Validation loss: 2.10378505850351

Epoch: 6| Step: 7
Training loss: 1.6356135606765747
Validation loss: 2.0960656340404222

Epoch: 6| Step: 8
Training loss: 1.5017495155334473
Validation loss: 2.1090567111968994

Epoch: 6| Step: 9
Training loss: 2.5450000762939453
Validation loss: 2.093584991270496

Epoch: 6| Step: 10
Training loss: 2.2357969284057617
Validation loss: 2.0946095976778256

Epoch: 6| Step: 11
Training loss: 2.0468475818634033
Validation loss: 2.0800225427073817

Epoch: 6| Step: 12
Training loss: 1.530785083770752
Validation loss: 2.0728319588527886

Epoch: 6| Step: 13
Training loss: 2.810704469680786
Validation loss: 2.0954905133093558

Epoch: 128| Step: 0
Training loss: 1.4633543491363525
Validation loss: 2.1220213444002214

Epoch: 6| Step: 1
Training loss: 2.3387610912323
Validation loss: 2.1418714677133868

Epoch: 6| Step: 2
Training loss: 2.3940792083740234
Validation loss: 2.1597819943581857

Epoch: 6| Step: 3
Training loss: 1.766772747039795
Validation loss: 2.1577059991898073

Epoch: 6| Step: 4
Training loss: 1.5785982608795166
Validation loss: 2.143422644625428

Epoch: 6| Step: 5
Training loss: 1.9148613214492798
Validation loss: 2.139849232089135

Epoch: 6| Step: 6
Training loss: 2.4538426399230957
Validation loss: 2.1233217857217275

Epoch: 6| Step: 7
Training loss: 2.30426025390625
Validation loss: 2.1122168610172887

Epoch: 6| Step: 8
Training loss: 2.2008063793182373
Validation loss: 2.105455146040968

Epoch: 6| Step: 9
Training loss: 1.7763690948486328
Validation loss: 2.1067133975285355

Epoch: 6| Step: 10
Training loss: 2.1714577674865723
Validation loss: 2.082483585162829

Epoch: 6| Step: 11
Training loss: 1.3239003419876099
Validation loss: 2.0756642164722567

Epoch: 6| Step: 12
Training loss: 2.26289701461792
Validation loss: 2.0509128673102266

Epoch: 6| Step: 13
Training loss: 2.142538070678711
Validation loss: 2.042019492836409

Epoch: 129| Step: 0
Training loss: 2.1442770957946777
Validation loss: 2.0361097025614914

Epoch: 6| Step: 1
Training loss: 2.0276899337768555
Validation loss: 2.0483178836043163

Epoch: 6| Step: 2
Training loss: 1.917659044265747
Validation loss: 2.057344618663993

Epoch: 6| Step: 3
Training loss: 2.2751693725585938
Validation loss: 2.0683683041603333

Epoch: 6| Step: 4
Training loss: 2.627636432647705
Validation loss: 2.0794536605958016

Epoch: 6| Step: 5
Training loss: 2.2060015201568604
Validation loss: 2.054090048677178

Epoch: 6| Step: 6
Training loss: 1.6620633602142334
Validation loss: 2.0453780748510875

Epoch: 6| Step: 7
Training loss: 1.5672261714935303
Validation loss: 2.065805724872056

Epoch: 6| Step: 8
Training loss: 2.1936092376708984
Validation loss: 2.055803386113977

Epoch: 6| Step: 9
Training loss: 1.434623122215271
Validation loss: 2.0817185371152815

Epoch: 6| Step: 10
Training loss: 2.052042007446289
Validation loss: 2.112773090280512

Epoch: 6| Step: 11
Training loss: 2.3074193000793457
Validation loss: 2.1036290558435584

Epoch: 6| Step: 12
Training loss: 1.8336458206176758
Validation loss: 2.1323671161487536

Epoch: 6| Step: 13
Training loss: 1.5120893716812134
Validation loss: 2.134564492010301

Epoch: 130| Step: 0
Training loss: 1.694472074508667
Validation loss: 2.1178818505297423

Epoch: 6| Step: 1
Training loss: 2.2827045917510986
Validation loss: 2.092802575839463

Epoch: 6| Step: 2
Training loss: 1.782078742980957
Validation loss: 2.090475982235324

Epoch: 6| Step: 3
Training loss: 2.5582518577575684
Validation loss: 2.0893012900506296

Epoch: 6| Step: 4
Training loss: 1.682266116142273
Validation loss: 2.0932570862513717

Epoch: 6| Step: 5
Training loss: 2.4249980449676514
Validation loss: 2.0998207625522407

Epoch: 6| Step: 6
Training loss: 1.5025843381881714
Validation loss: 2.0927756345400246

Epoch: 6| Step: 7
Training loss: 2.0766472816467285
Validation loss: 2.093570437482608

Epoch: 6| Step: 8
Training loss: 2.3557066917419434
Validation loss: 2.0648878723062496

Epoch: 6| Step: 9
Training loss: 1.8766692876815796
Validation loss: 2.0874216838549544

Epoch: 6| Step: 10
Training loss: 1.837422251701355
Validation loss: 2.073293765385946

Epoch: 6| Step: 11
Training loss: 1.5587475299835205
Validation loss: 2.079382468295354

Epoch: 6| Step: 12
Training loss: 1.8265974521636963
Validation loss: 2.088190755536479

Epoch: 6| Step: 13
Training loss: 1.6631044149398804
Validation loss: 2.0882290832458006

Epoch: 131| Step: 0
Training loss: 1.603041172027588
Validation loss: 2.1112051163950274

Epoch: 6| Step: 1
Training loss: 2.07631778717041
Validation loss: 2.103165385543659

Epoch: 6| Step: 2
Training loss: 2.1499834060668945
Validation loss: 2.0960043976383824

Epoch: 6| Step: 3
Training loss: 1.6110213994979858
Validation loss: 2.093094677053472

Epoch: 6| Step: 4
Training loss: 1.862546682357788
Validation loss: 2.076972146188059

Epoch: 6| Step: 5
Training loss: 1.7874044179916382
Validation loss: 2.0642130913272982

Epoch: 6| Step: 6
Training loss: 1.9486379623413086
Validation loss: 2.0607383328099407

Epoch: 6| Step: 7
Training loss: 2.558561325073242
Validation loss: 2.043958084557646

Epoch: 6| Step: 8
Training loss: 2.676450729370117
Validation loss: 2.0609540349693707

Epoch: 6| Step: 9
Training loss: 1.9021682739257812
Validation loss: 2.048828160890969

Epoch: 6| Step: 10
Training loss: 1.7989516258239746
Validation loss: 2.0649851650320072

Epoch: 6| Step: 11
Training loss: 1.2290431261062622
Validation loss: 2.062165717924795

Epoch: 6| Step: 12
Training loss: 1.9039392471313477
Validation loss: 2.0637507592478106

Epoch: 6| Step: 13
Training loss: 2.0200424194335938
Validation loss: 2.0808335299132974

Epoch: 132| Step: 0
Training loss: 1.7442662715911865
Validation loss: 2.0784561505881687

Epoch: 6| Step: 1
Training loss: 1.7405309677124023
Validation loss: 2.059616829759331

Epoch: 6| Step: 2
Training loss: 1.9717516899108887
Validation loss: 2.0816569559035765

Epoch: 6| Step: 3
Training loss: 1.8273890018463135
Validation loss: 2.0687303286726757

Epoch: 6| Step: 4
Training loss: 1.6539642810821533
Validation loss: 2.0629443122494604

Epoch: 6| Step: 5
Training loss: 1.9914700984954834
Validation loss: 2.058074379480013

Epoch: 6| Step: 6
Training loss: 2.0114264488220215
Validation loss: 2.054377982693334

Epoch: 6| Step: 7
Training loss: 2.483412027359009
Validation loss: 2.0441620721611926

Epoch: 6| Step: 8
Training loss: 2.355734348297119
Validation loss: 2.0394273701534478

Epoch: 6| Step: 9
Training loss: 1.891871690750122
Validation loss: 2.0434767687192528

Epoch: 6| Step: 10
Training loss: 1.6426606178283691
Validation loss: 2.0590725637251333

Epoch: 6| Step: 11
Training loss: 1.6670691967010498
Validation loss: 2.0527196520118305

Epoch: 6| Step: 12
Training loss: 1.363749384880066
Validation loss: 2.0573580905955327

Epoch: 6| Step: 13
Training loss: 2.484870672225952
Validation loss: 2.0696085806815856

Epoch: 133| Step: 0
Training loss: 1.8644006252288818
Validation loss: 2.090363194865565

Epoch: 6| Step: 1
Training loss: 1.4345381259918213
Validation loss: 2.1427422313280005

Epoch: 6| Step: 2
Training loss: 2.0522706508636475
Validation loss: 2.1310839960652013

Epoch: 6| Step: 3
Training loss: 3.064730405807495
Validation loss: 2.130582191610849

Epoch: 6| Step: 4
Training loss: 1.953657627105713
Validation loss: 2.1240753409683064

Epoch: 6| Step: 5
Training loss: 2.379157781600952
Validation loss: 2.103464000968523

Epoch: 6| Step: 6
Training loss: 1.6239553689956665
Validation loss: 2.107406529047156

Epoch: 6| Step: 7
Training loss: 1.9007205963134766
Validation loss: 2.103223741695445

Epoch: 6| Step: 8
Training loss: 1.6674200296401978
Validation loss: 2.101310068561185

Epoch: 6| Step: 9
Training loss: 1.7230335474014282
Validation loss: 2.070589403952322

Epoch: 6| Step: 10
Training loss: 1.6662030220031738
Validation loss: 2.056467071656258

Epoch: 6| Step: 11
Training loss: 1.626298189163208
Validation loss: 2.0759826731938187

Epoch: 6| Step: 12
Training loss: 1.668251395225525
Validation loss: 2.084571202596029

Epoch: 6| Step: 13
Training loss: 2.0822036266326904
Validation loss: 2.096906800423899

Epoch: 134| Step: 0
Training loss: 1.747971773147583
Validation loss: 2.1171707286629626

Epoch: 6| Step: 1
Training loss: 1.5747063159942627
Validation loss: 2.113696103454918

Epoch: 6| Step: 2
Training loss: 1.208068609237671
Validation loss: 2.087931522759058

Epoch: 6| Step: 3
Training loss: 1.5044209957122803
Validation loss: 2.0813936264284196

Epoch: 6| Step: 4
Training loss: 1.9330273866653442
Validation loss: 2.0804654090635237

Epoch: 6| Step: 5
Training loss: 2.6911349296569824
Validation loss: 2.087287941286641

Epoch: 6| Step: 6
Training loss: 1.5466699600219727
Validation loss: 2.069493134816488

Epoch: 6| Step: 7
Training loss: 2.180920124053955
Validation loss: 2.059902629544658

Epoch: 6| Step: 8
Training loss: 1.5362151861190796
Validation loss: 2.0524974382051857

Epoch: 6| Step: 9
Training loss: 2.032778739929199
Validation loss: 2.049458166604401

Epoch: 6| Step: 10
Training loss: 2.8554487228393555
Validation loss: 2.058648838791796

Epoch: 6| Step: 11
Training loss: 1.5649371147155762
Validation loss: 2.060185078651674

Epoch: 6| Step: 12
Training loss: 1.7050435543060303
Validation loss: 2.039993906533846

Epoch: 6| Step: 13
Training loss: 2.4388272762298584
Validation loss: 2.0528617994759673

Epoch: 135| Step: 0
Training loss: 1.975020408630371
Validation loss: 2.052341197126655

Epoch: 6| Step: 1
Training loss: 2.457413673400879
Validation loss: 2.0955626041658464

Epoch: 6| Step: 2
Training loss: 1.952722430229187
Validation loss: 2.1317165308101202

Epoch: 6| Step: 3
Training loss: 2.011920928955078
Validation loss: 2.1441118332647506

Epoch: 6| Step: 4
Training loss: 1.8240793943405151
Validation loss: 2.154901612189508

Epoch: 6| Step: 5
Training loss: 1.8102073669433594
Validation loss: 2.113599338839131

Epoch: 6| Step: 6
Training loss: 2.3686180114746094
Validation loss: 2.1109625344635337

Epoch: 6| Step: 7
Training loss: 2.0636913776397705
Validation loss: 2.1574239346288864

Epoch: 6| Step: 8
Training loss: 2.2146153450012207
Validation loss: 2.1927909799801406

Epoch: 6| Step: 9
Training loss: 1.926065444946289
Validation loss: 2.176278373246552

Epoch: 6| Step: 10
Training loss: 1.5279099941253662
Validation loss: 2.160333974387056

Epoch: 6| Step: 11
Training loss: 0.7837446928024292
Validation loss: 2.1194924436589724

Epoch: 6| Step: 12
Training loss: 2.654366970062256
Validation loss: 2.072018087551158

Epoch: 6| Step: 13
Training loss: 1.062641978263855
Validation loss: 2.0770912247319377

Epoch: 136| Step: 0
Training loss: 2.078479528427124
Validation loss: 2.078472670688424

Epoch: 6| Step: 1
Training loss: 2.384178638458252
Validation loss: 2.0644695015363794

Epoch: 6| Step: 2
Training loss: 1.2460901737213135
Validation loss: 2.0675967777929

Epoch: 6| Step: 3
Training loss: 2.0904922485351562
Validation loss: 2.066990170427548

Epoch: 6| Step: 4
Training loss: 1.472590446472168
Validation loss: 2.0675055057771745

Epoch: 6| Step: 5
Training loss: 2.2106385231018066
Validation loss: 2.067342463360038

Epoch: 6| Step: 6
Training loss: 2.506256103515625
Validation loss: 2.037479980017549

Epoch: 6| Step: 7
Training loss: 2.032252788543701
Validation loss: 2.021567565138622

Epoch: 6| Step: 8
Training loss: 1.8533354997634888
Validation loss: 2.020977689373878

Epoch: 6| Step: 9
Training loss: 2.4606831073760986
Validation loss: 2.0261476642342022

Epoch: 6| Step: 10
Training loss: 1.6588289737701416
Validation loss: 2.03497475962485

Epoch: 6| Step: 11
Training loss: 1.2845439910888672
Validation loss: 2.0247660631774576

Epoch: 6| Step: 12
Training loss: 1.694390058517456
Validation loss: 2.035681446393331

Epoch: 6| Step: 13
Training loss: 1.3956952095031738
Validation loss: 2.05050899136451

Epoch: 137| Step: 0
Training loss: 0.9415087699890137
Validation loss: 2.053702759486373

Epoch: 6| Step: 1
Training loss: 2.392075538635254
Validation loss: 2.0583632351249777

Epoch: 6| Step: 2
Training loss: 2.2293272018432617
Validation loss: 2.0678792640727055

Epoch: 6| Step: 3
Training loss: 1.7441391944885254
Validation loss: 2.056356458253758

Epoch: 6| Step: 4
Training loss: 1.4178955554962158
Validation loss: 2.0456685686624176

Epoch: 6| Step: 5
Training loss: 1.8153921365737915
Validation loss: 2.051311436519828

Epoch: 6| Step: 6
Training loss: 1.7680689096450806
Validation loss: 2.0466774907163394

Epoch: 6| Step: 7
Training loss: 1.4822531938552856
Validation loss: 2.0480228906036704

Epoch: 6| Step: 8
Training loss: 2.1263465881347656
Validation loss: 2.0232483289575063

Epoch: 6| Step: 9
Training loss: 1.7578728199005127
Validation loss: 2.0328445716570784

Epoch: 6| Step: 10
Training loss: 2.5181593894958496
Validation loss: 2.0324072325101463

Epoch: 6| Step: 11
Training loss: 2.0195255279541016
Validation loss: 2.0348436294063443

Epoch: 6| Step: 12
Training loss: 1.5451958179473877
Validation loss: 2.029168559658912

Epoch: 6| Step: 13
Training loss: 2.172269582748413
Validation loss: 2.053735330540647

Epoch: 138| Step: 0
Training loss: 2.0260798931121826
Validation loss: 2.056121455725803

Epoch: 6| Step: 1
Training loss: 1.4850871562957764
Validation loss: 2.0499851652370986

Epoch: 6| Step: 2
Training loss: 1.6879208087921143
Validation loss: 2.0554365240117556

Epoch: 6| Step: 3
Training loss: 1.5426112413406372
Validation loss: 2.0536533196767173

Epoch: 6| Step: 4
Training loss: 2.0847280025482178
Validation loss: 2.053605451378771

Epoch: 6| Step: 5
Training loss: 2.9184489250183105
Validation loss: 2.0527299834835913

Epoch: 6| Step: 6
Training loss: 1.3946770429611206
Validation loss: 2.058724104717214

Epoch: 6| Step: 7
Training loss: 1.9330329895019531
Validation loss: 2.064816928678943

Epoch: 6| Step: 8
Training loss: 1.7953088283538818
Validation loss: 2.0637194379683463

Epoch: 6| Step: 9
Training loss: 1.1699800491333008
Validation loss: 2.065001098058557

Epoch: 6| Step: 10
Training loss: 1.737007737159729
Validation loss: 2.0645588905580583

Epoch: 6| Step: 11
Training loss: 1.9271782636642456
Validation loss: 2.0649483716616066

Epoch: 6| Step: 12
Training loss: 1.8762952089309692
Validation loss: 2.0423880187414025

Epoch: 6| Step: 13
Training loss: 1.9695167541503906
Validation loss: 2.059261811676846

Epoch: 139| Step: 0
Training loss: 1.5220824480056763
Validation loss: 2.0386666892677225

Epoch: 6| Step: 1
Training loss: 1.8787330389022827
Validation loss: 2.0361601665455806

Epoch: 6| Step: 2
Training loss: 1.3078460693359375
Validation loss: 2.0212925775076753

Epoch: 6| Step: 3
Training loss: 2.2516584396362305
Validation loss: 2.0045751628055366

Epoch: 6| Step: 4
Training loss: 1.9255256652832031
Validation loss: 2.007014573261302

Epoch: 6| Step: 5
Training loss: 2.268598794937134
Validation loss: 2.033606667672434

Epoch: 6| Step: 6
Training loss: 1.4722027778625488
Validation loss: 2.024989733131983

Epoch: 6| Step: 7
Training loss: 1.9145281314849854
Validation loss: 2.013973254029469

Epoch: 6| Step: 8
Training loss: 2.014098882675171
Validation loss: 2.0393291570807017

Epoch: 6| Step: 9
Training loss: 2.219255208969116
Validation loss: 2.0406508356012325

Epoch: 6| Step: 10
Training loss: 1.9512369632720947
Validation loss: 2.0312196657221806

Epoch: 6| Step: 11
Training loss: 1.4197547435760498
Validation loss: 2.0275795716111378

Epoch: 6| Step: 12
Training loss: 1.4377769231796265
Validation loss: 2.0433355287839006

Epoch: 6| Step: 13
Training loss: 2.4426498413085938
Validation loss: 2.053143219281268

Epoch: 140| Step: 0
Training loss: 1.5542230606079102
Validation loss: 2.0633690113662393

Epoch: 6| Step: 1
Training loss: 2.2542238235473633
Validation loss: 2.0760302261639665

Epoch: 6| Step: 2
Training loss: 1.7295773029327393
Validation loss: 2.0936572846545967

Epoch: 6| Step: 3
Training loss: 1.3811360597610474
Validation loss: 2.1124403861261185

Epoch: 6| Step: 4
Training loss: 2.3741931915283203
Validation loss: 2.1082826301615727

Epoch: 6| Step: 5
Training loss: 1.20689857006073
Validation loss: 2.097814816300587

Epoch: 6| Step: 6
Training loss: 1.8432198762893677
Validation loss: 2.072469981767798

Epoch: 6| Step: 7
Training loss: 2.137331008911133
Validation loss: 2.0551361448021344

Epoch: 6| Step: 8
Training loss: 2.012946844100952
Validation loss: 2.0282154749798518

Epoch: 6| Step: 9
Training loss: 1.4844753742218018
Validation loss: 2.0207191936431395

Epoch: 6| Step: 10
Training loss: 2.105619430541992
Validation loss: 2.0135549742688417

Epoch: 6| Step: 11
Training loss: 1.658054232597351
Validation loss: 2.001933979731734

Epoch: 6| Step: 12
Training loss: 1.590315818786621
Validation loss: 2.0125109418745963

Epoch: 6| Step: 13
Training loss: 2.6304383277893066
Validation loss: 2.0130108402621363

Epoch: 141| Step: 0
Training loss: 1.876173973083496
Validation loss: 2.0148596866156465

Epoch: 6| Step: 1
Training loss: 1.8341076374053955
Validation loss: 2.01389382859712

Epoch: 6| Step: 2
Training loss: 2.2034647464752197
Validation loss: 2.0248882027082544

Epoch: 6| Step: 3
Training loss: 1.4474318027496338
Validation loss: 2.047676340226204

Epoch: 6| Step: 4
Training loss: 1.9022624492645264
Validation loss: 2.0603331442802184

Epoch: 6| Step: 5
Training loss: 1.7596524953842163
Validation loss: 2.068063424479577

Epoch: 6| Step: 6
Training loss: 1.8860702514648438
Validation loss: 2.080036606839908

Epoch: 6| Step: 7
Training loss: 1.1374541521072388
Validation loss: 2.068282991327265

Epoch: 6| Step: 8
Training loss: 1.502992033958435
Validation loss: 2.0856814769006546

Epoch: 6| Step: 9
Training loss: 1.9368796348571777
Validation loss: 2.0911519347980456

Epoch: 6| Step: 10
Training loss: 1.9850624799728394
Validation loss: 2.1094784339269004

Epoch: 6| Step: 11
Training loss: 1.2115817070007324
Validation loss: 2.1099423913545508

Epoch: 6| Step: 12
Training loss: 2.664736747741699
Validation loss: 2.1000574224738666

Epoch: 6| Step: 13
Training loss: 1.457110047340393
Validation loss: 2.0949921428516345

Epoch: 142| Step: 0
Training loss: 1.4916009902954102
Validation loss: 2.1167499173072075

Epoch: 6| Step: 1
Training loss: 1.8468213081359863
Validation loss: 2.1240039615220923

Epoch: 6| Step: 2
Training loss: 1.9961260557174683
Validation loss: 2.119610840274442

Epoch: 6| Step: 3
Training loss: 2.032135486602783
Validation loss: 2.125006560356386

Epoch: 6| Step: 4
Training loss: 1.690889835357666
Validation loss: 2.1093526117263304

Epoch: 6| Step: 5
Training loss: 1.8709509372711182
Validation loss: 2.1063270594484065

Epoch: 6| Step: 6
Training loss: 2.3449339866638184
Validation loss: 2.0753133707149054

Epoch: 6| Step: 7
Training loss: 1.7104241847991943
Validation loss: 2.062444281834428

Epoch: 6| Step: 8
Training loss: 2.6053295135498047
Validation loss: 2.040522147250432

Epoch: 6| Step: 9
Training loss: 1.61018705368042
Validation loss: 2.019653179312265

Epoch: 6| Step: 10
Training loss: 1.6904168128967285
Validation loss: 2.0381474174479

Epoch: 6| Step: 11
Training loss: 1.1392676830291748
Validation loss: 2.014618530068346

Epoch: 6| Step: 12
Training loss: 1.4789842367172241
Validation loss: 2.006608965576336

Epoch: 6| Step: 13
Training loss: 2.194735050201416
Validation loss: 1.9993693700400732

Epoch: 143| Step: 0
Training loss: 1.8401274681091309
Validation loss: 2.000574855394261

Epoch: 6| Step: 1
Training loss: 1.8562541007995605
Validation loss: 2.002987882142426

Epoch: 6| Step: 2
Training loss: 1.213832139968872
Validation loss: 2.0148338322998374

Epoch: 6| Step: 3
Training loss: 1.7754606008529663
Validation loss: 2.008279210777693

Epoch: 6| Step: 4
Training loss: 1.4959447383880615
Validation loss: 2.0115930918724305

Epoch: 6| Step: 5
Training loss: 2.239210605621338
Validation loss: 2.028453419285436

Epoch: 6| Step: 6
Training loss: 1.9808201789855957
Validation loss: 2.0418963047765915

Epoch: 6| Step: 7
Training loss: 2.1900410652160645
Validation loss: 2.044852372138731

Epoch: 6| Step: 8
Training loss: 1.6245794296264648
Validation loss: 2.082642586000504

Epoch: 6| Step: 9
Training loss: 2.3732352256774902
Validation loss: 2.055873945195188

Epoch: 6| Step: 10
Training loss: 1.4154682159423828
Validation loss: 2.0620442923679145

Epoch: 6| Step: 11
Training loss: 1.3490662574768066
Validation loss: 2.071737817538682

Epoch: 6| Step: 12
Training loss: 1.7156072854995728
Validation loss: 2.0732289052778676

Epoch: 6| Step: 13
Training loss: 2.0210351943969727
Validation loss: 2.078925815961694

Epoch: 144| Step: 0
Training loss: 1.492365837097168
Validation loss: 2.096277115165546

Epoch: 6| Step: 1
Training loss: 1.9903066158294678
Validation loss: 2.1251771808952413

Epoch: 6| Step: 2
Training loss: 2.567119836807251
Validation loss: 2.138780647708524

Epoch: 6| Step: 3
Training loss: 2.1328015327453613
Validation loss: 2.13156638350538

Epoch: 6| Step: 4
Training loss: 2.1027050018310547
Validation loss: 2.1410207979140745

Epoch: 6| Step: 5
Training loss: 1.7572321891784668
Validation loss: 2.1263812408652356

Epoch: 6| Step: 6
Training loss: 1.613905906677246
Validation loss: 2.1388508517255067

Epoch: 6| Step: 7
Training loss: 1.6110846996307373
Validation loss: 2.1288113183872674

Epoch: 6| Step: 8
Training loss: 2.205329418182373
Validation loss: 2.1196607492303334

Epoch: 6| Step: 9
Training loss: 1.0983030796051025
Validation loss: 2.0984572684893044

Epoch: 6| Step: 10
Training loss: 1.9824824333190918
Validation loss: 2.0830645022853727

Epoch: 6| Step: 11
Training loss: 1.8114979267120361
Validation loss: 2.0546957677410496

Epoch: 6| Step: 12
Training loss: 1.5761646032333374
Validation loss: 2.055170382222822

Epoch: 6| Step: 13
Training loss: 1.5171103477478027
Validation loss: 2.0485497777180006

Epoch: 145| Step: 0
Training loss: 2.0809004306793213
Validation loss: 2.020523678871893

Epoch: 6| Step: 1
Training loss: 1.6210687160491943
Validation loss: 2.0243108849371634

Epoch: 6| Step: 2
Training loss: 1.3667166233062744
Validation loss: 2.028505382999297

Epoch: 6| Step: 3
Training loss: 1.7499843835830688
Validation loss: 2.0378373207584506

Epoch: 6| Step: 4
Training loss: 1.767989993095398
Validation loss: 2.0488372925789125

Epoch: 6| Step: 5
Training loss: 1.728290319442749
Validation loss: 2.058367265168057

Epoch: 6| Step: 6
Training loss: 2.01013445854187
Validation loss: 2.06961997350057

Epoch: 6| Step: 7
Training loss: 1.8179726600646973
Validation loss: 2.0832509417687692

Epoch: 6| Step: 8
Training loss: 1.7628681659698486
Validation loss: 2.0949402727106565

Epoch: 6| Step: 9
Training loss: 2.0080509185791016
Validation loss: 2.089060955150153

Epoch: 6| Step: 10
Training loss: 1.3196690082550049
Validation loss: 2.0909822743426085

Epoch: 6| Step: 11
Training loss: 2.3426437377929688
Validation loss: 2.118520405984694

Epoch: 6| Step: 12
Training loss: 1.6017563343048096
Validation loss: 2.119296130313668

Epoch: 6| Step: 13
Training loss: 2.150942802429199
Validation loss: 2.1125992728817846

Epoch: 146| Step: 0
Training loss: 1.4779412746429443
Validation loss: 2.1190118405126754

Epoch: 6| Step: 1
Training loss: 1.911475419998169
Validation loss: 2.140890593169838

Epoch: 6| Step: 2
Training loss: 2.1636879444122314
Validation loss: 2.1179192220011065

Epoch: 6| Step: 3
Training loss: 1.6218373775482178
Validation loss: 2.088745453024423

Epoch: 6| Step: 4
Training loss: 1.644005298614502
Validation loss: 2.0788177905544156

Epoch: 6| Step: 5
Training loss: 1.6156377792358398
Validation loss: 2.067716715156391

Epoch: 6| Step: 6
Training loss: 1.9979321956634521
Validation loss: 2.0453148170184066

Epoch: 6| Step: 7
Training loss: 1.8875584602355957
Validation loss: 2.058203876659434

Epoch: 6| Step: 8
Training loss: 1.2209858894348145
Validation loss: 2.0466153903674056

Epoch: 6| Step: 9
Training loss: 1.8800934553146362
Validation loss: 2.024577863754765

Epoch: 6| Step: 10
Training loss: 1.827701210975647
Validation loss: 2.03468668589028

Epoch: 6| Step: 11
Training loss: 1.5700609683990479
Validation loss: 2.0215532574602353

Epoch: 6| Step: 12
Training loss: 1.7008471488952637
Validation loss: 2.0405414437734954

Epoch: 6| Step: 13
Training loss: 2.841313600540161
Validation loss: 2.0553790676978325

Epoch: 147| Step: 0
Training loss: 1.6840380430221558
Validation loss: 2.0769134080538185

Epoch: 6| Step: 1
Training loss: 1.8814984560012817
Validation loss: 2.090365143232448

Epoch: 6| Step: 2
Training loss: 1.0808260440826416
Validation loss: 2.0797060125617572

Epoch: 6| Step: 3
Training loss: 2.0373449325561523
Validation loss: 2.056670770850233

Epoch: 6| Step: 4
Training loss: 1.8309904336929321
Validation loss: 2.0370109568360033

Epoch: 6| Step: 5
Training loss: 1.6864523887634277
Validation loss: 2.0373181066205426

Epoch: 6| Step: 6
Training loss: 1.9126865863800049
Validation loss: 2.0633605167429936

Epoch: 6| Step: 7
Training loss: 1.7026302814483643
Validation loss: 2.065741782547325

Epoch: 6| Step: 8
Training loss: 1.2272107601165771
Validation loss: 2.0735715691761305

Epoch: 6| Step: 9
Training loss: 1.9628897905349731
Validation loss: 2.0769103957760717

Epoch: 6| Step: 10
Training loss: 2.0569944381713867
Validation loss: 2.0751783232535086

Epoch: 6| Step: 11
Training loss: 2.1376566886901855
Validation loss: 2.0831518660309496

Epoch: 6| Step: 12
Training loss: 2.0871477127075195
Validation loss: 2.094176218073855

Epoch: 6| Step: 13
Training loss: 1.8406437635421753
Validation loss: 2.0937190248120214

Epoch: 148| Step: 0
Training loss: 1.4853260517120361
Validation loss: 2.125738400284962

Epoch: 6| Step: 1
Training loss: 2.1074347496032715
Validation loss: 2.1025585154051423

Epoch: 6| Step: 2
Training loss: 1.0999207496643066
Validation loss: 2.107522787586335

Epoch: 6| Step: 3
Training loss: 1.7701061964035034
Validation loss: 2.113457928421677

Epoch: 6| Step: 4
Training loss: 2.4738428592681885
Validation loss: 2.0958914526047243

Epoch: 6| Step: 5
Training loss: 1.3335269689559937
Validation loss: 2.0840291438564176

Epoch: 6| Step: 6
Training loss: 1.82183039188385
Validation loss: 2.091385672169347

Epoch: 6| Step: 7
Training loss: 2.5323233604431152
Validation loss: 2.078828534772319

Epoch: 6| Step: 8
Training loss: 1.2201749086380005
Validation loss: 2.0614780328607045

Epoch: 6| Step: 9
Training loss: 2.014719009399414
Validation loss: 2.0476858026237896

Epoch: 6| Step: 10
Training loss: 1.5427541732788086
Validation loss: 2.045935061670119

Epoch: 6| Step: 11
Training loss: 1.4976052045822144
Validation loss: 2.043151270958685

Epoch: 6| Step: 12
Training loss: 1.4624043703079224
Validation loss: 2.0340038371342484

Epoch: 6| Step: 13
Training loss: 2.1022913455963135
Validation loss: 2.037494359477874

Epoch: 149| Step: 0
Training loss: 1.8721855878829956
Validation loss: 2.030380050341288

Epoch: 6| Step: 1
Training loss: 1.8427296876907349
Validation loss: 2.0329278284503567

Epoch: 6| Step: 2
Training loss: 1.7224855422973633
Validation loss: 2.041814798949867

Epoch: 6| Step: 3
Training loss: 1.7572131156921387
Validation loss: 2.0528272557002243

Epoch: 6| Step: 4
Training loss: 2.0604963302612305
Validation loss: 2.073518645378851

Epoch: 6| Step: 5
Training loss: 2.3918142318725586
Validation loss: 2.086533740002622

Epoch: 6| Step: 6
Training loss: 1.1755741834640503
Validation loss: 2.1034733544113817

Epoch: 6| Step: 7
Training loss: 1.234776258468628
Validation loss: 2.0933586551297094

Epoch: 6| Step: 8
Training loss: 2.1275882720947266
Validation loss: 2.1012224997243574

Epoch: 6| Step: 9
Training loss: 1.3343591690063477
Validation loss: 2.1175832902231524

Epoch: 6| Step: 10
Training loss: 1.5067418813705444
Validation loss: 2.1094450104621147

Epoch: 6| Step: 11
Training loss: 2.011289119720459
Validation loss: 2.1135797116064254

Epoch: 6| Step: 12
Training loss: 1.8058561086654663
Validation loss: 2.1085794228379444

Epoch: 6| Step: 13
Training loss: 1.2389687299728394
Validation loss: 2.109525780523977

Epoch: 150| Step: 0
Training loss: 1.716009259223938
Validation loss: 2.0890582940911733

Epoch: 6| Step: 1
Training loss: 1.809882402420044
Validation loss: 2.1050942508123254

Epoch: 6| Step: 2
Training loss: 1.4556723833084106
Validation loss: 2.101905685599132

Epoch: 6| Step: 3
Training loss: 1.8087103366851807
Validation loss: 2.0843360693224016

Epoch: 6| Step: 4
Training loss: 1.455342173576355
Validation loss: 2.071033203473655

Epoch: 6| Step: 5
Training loss: 2.0047409534454346
Validation loss: 2.0787359335089244

Epoch: 6| Step: 6
Training loss: 1.5243682861328125
Validation loss: 2.081803201347269

Epoch: 6| Step: 7
Training loss: 1.7426438331604004
Validation loss: 2.0767902174303607

Epoch: 6| Step: 8
Training loss: 2.1128153800964355
Validation loss: 2.0767818830346547

Epoch: 6| Step: 9
Training loss: 1.099845290184021
Validation loss: 2.0682370842144056

Epoch: 6| Step: 10
Training loss: 2.048170566558838
Validation loss: 2.0564293963934785

Epoch: 6| Step: 11
Training loss: 1.654293179512024
Validation loss: 2.05054001397984

Epoch: 6| Step: 12
Training loss: 1.501053810119629
Validation loss: 2.061866521835327

Epoch: 6| Step: 13
Training loss: 1.8812637329101562
Validation loss: 2.0593324681764007

Epoch: 151| Step: 0
Training loss: 1.4300575256347656
Validation loss: 2.057213170554048

Epoch: 6| Step: 1
Training loss: 1.7348021268844604
Validation loss: 2.056190158731194

Epoch: 6| Step: 2
Training loss: 1.3407247066497803
Validation loss: 2.0655064967370804

Epoch: 6| Step: 3
Training loss: 1.102156162261963
Validation loss: 2.0527002785795476

Epoch: 6| Step: 4
Training loss: 1.497544765472412
Validation loss: 2.048168159300281

Epoch: 6| Step: 5
Training loss: 2.503164291381836
Validation loss: 2.0292608827672978

Epoch: 6| Step: 6
Training loss: 1.8477654457092285
Validation loss: 2.0320011056879514

Epoch: 6| Step: 7
Training loss: 1.5052993297576904
Validation loss: 2.0129789998454433

Epoch: 6| Step: 8
Training loss: 1.264291763305664
Validation loss: 2.0349205604163547

Epoch: 6| Step: 9
Training loss: 1.3314673900604248
Validation loss: 2.0524888948727678

Epoch: 6| Step: 10
Training loss: 2.5430262088775635
Validation loss: 2.0835907574622863

Epoch: 6| Step: 11
Training loss: 2.2240662574768066
Validation loss: 2.0967431247875257

Epoch: 6| Step: 12
Training loss: 1.8708093166351318
Validation loss: 2.0948389807055072

Epoch: 6| Step: 13
Training loss: 1.6668758392333984
Validation loss: 2.0957462223627235

Epoch: 152| Step: 0
Training loss: 2.060232400894165
Validation loss: 2.0940455236742572

Epoch: 6| Step: 1
Training loss: 1.6129982471466064
Validation loss: 2.0816156043801257

Epoch: 6| Step: 2
Training loss: 1.0944077968597412
Validation loss: 2.084271918060959

Epoch: 6| Step: 3
Training loss: 1.4193304777145386
Validation loss: 2.0914915325821086

Epoch: 6| Step: 4
Training loss: 1.6837248802185059
Validation loss: 2.1134677702380764

Epoch: 6| Step: 5
Training loss: 1.5228785276412964
Validation loss: 2.107411721701263

Epoch: 6| Step: 6
Training loss: 1.9007377624511719
Validation loss: 2.071124615207795

Epoch: 6| Step: 7
Training loss: 1.7320932149887085
Validation loss: 2.0462542554383636

Epoch: 6| Step: 8
Training loss: 2.1179490089416504
Validation loss: 2.067744944685249

Epoch: 6| Step: 9
Training loss: 1.2955400943756104
Validation loss: 2.0677048570366314

Epoch: 6| Step: 10
Training loss: 1.7351866960525513
Validation loss: 2.0571058975752963

Epoch: 6| Step: 11
Training loss: 2.535486936569214
Validation loss: 2.052546114049932

Epoch: 6| Step: 12
Training loss: 2.02614688873291
Validation loss: 2.0230911803501908

Epoch: 6| Step: 13
Training loss: 0.4317021667957306
Validation loss: 2.0092103122383036

Epoch: 153| Step: 0
Training loss: 1.955373764038086
Validation loss: 2.0354623025463474

Epoch: 6| Step: 1
Training loss: 1.8804049491882324
Validation loss: 2.056017344997775

Epoch: 6| Step: 2
Training loss: 1.2792954444885254
Validation loss: 2.0758646406153196

Epoch: 6| Step: 3
Training loss: 2.1318867206573486
Validation loss: 2.114978808228688

Epoch: 6| Step: 4
Training loss: 1.2022018432617188
Validation loss: 2.1028246751395603

Epoch: 6| Step: 5
Training loss: 1.3228225708007812
Validation loss: 2.1083177751110447

Epoch: 6| Step: 6
Training loss: 1.6988059282302856
Validation loss: 2.104729844677833

Epoch: 6| Step: 7
Training loss: 1.255525827407837
Validation loss: 2.0702255438732844

Epoch: 6| Step: 8
Training loss: 1.5927684307098389
Validation loss: 2.0487293863809235

Epoch: 6| Step: 9
Training loss: 1.9226500988006592
Validation loss: 2.0758572778394146

Epoch: 6| Step: 10
Training loss: 2.327460765838623
Validation loss: 2.0931922146069106

Epoch: 6| Step: 11
Training loss: 1.7958227396011353
Validation loss: 2.0949477585413123

Epoch: 6| Step: 12
Training loss: 1.8252902030944824
Validation loss: 2.0846885609370407

Epoch: 6| Step: 13
Training loss: 1.4271986484527588
Validation loss: 2.0595228351572508

Epoch: 154| Step: 0
Training loss: 2.068589687347412
Validation loss: 2.046267000577783

Epoch: 6| Step: 1
Training loss: 1.464411735534668
Validation loss: 2.0585736497755973

Epoch: 6| Step: 2
Training loss: 1.7975404262542725
Validation loss: 2.0697229369994132

Epoch: 6| Step: 3
Training loss: 2.291860342025757
Validation loss: 2.10414045856845

Epoch: 6| Step: 4
Training loss: 1.7784769535064697
Validation loss: 2.1122425371600735

Epoch: 6| Step: 5
Training loss: 1.9656949043273926
Validation loss: 2.09609656564651

Epoch: 6| Step: 6
Training loss: 1.3064643144607544
Validation loss: 2.0565996605862855

Epoch: 6| Step: 7
Training loss: 1.6228551864624023
Validation loss: 2.0134101003728886

Epoch: 6| Step: 8
Training loss: 1.476095199584961
Validation loss: 2.0017266914408696

Epoch: 6| Step: 9
Training loss: 0.9933907389640808
Validation loss: 2.038734092507311

Epoch: 6| Step: 10
Training loss: 2.561556339263916
Validation loss: 2.082443073231687

Epoch: 6| Step: 11
Training loss: 1.5201202630996704
Validation loss: 2.0944351688508065

Epoch: 6| Step: 12
Training loss: 1.714176058769226
Validation loss: 2.0968519359506588

Epoch: 6| Step: 13
Training loss: 1.3729734420776367
Validation loss: 2.0757719496245026

Epoch: 155| Step: 0
Training loss: 1.3439764976501465
Validation loss: 2.0709288145906184

Epoch: 6| Step: 1
Training loss: 1.7373292446136475
Validation loss: 2.0521788366379274

Epoch: 6| Step: 2
Training loss: 1.6444032192230225
Validation loss: 2.0635791773437173

Epoch: 6| Step: 3
Training loss: 1.3980109691619873
Validation loss: 2.0721390426799817

Epoch: 6| Step: 4
Training loss: 1.709882378578186
Validation loss: 2.0948596564672326

Epoch: 6| Step: 5
Training loss: 1.869706630706787
Validation loss: 2.0728851595232562

Epoch: 6| Step: 6
Training loss: 1.204480528831482
Validation loss: 2.0377693663361254

Epoch: 6| Step: 7
Training loss: 2.027470111846924
Validation loss: 2.0102615997355473

Epoch: 6| Step: 8
Training loss: 1.8728117942810059
Validation loss: 1.9893178786000898

Epoch: 6| Step: 9
Training loss: 0.9644025564193726
Validation loss: 2.0236012205000846

Epoch: 6| Step: 10
Training loss: 2.5874216556549072
Validation loss: 2.062014123444916

Epoch: 6| Step: 11
Training loss: 1.686767816543579
Validation loss: 2.1056233554758053

Epoch: 6| Step: 12
Training loss: 2.40378999710083
Validation loss: 2.088640486040423

Epoch: 6| Step: 13
Training loss: 1.9387378692626953
Validation loss: 2.069619119808238

Epoch: 156| Step: 0
Training loss: 2.164463758468628
Validation loss: 2.0549390610828193

Epoch: 6| Step: 1
Training loss: 1.8540050983428955
Validation loss: 2.0463353626189695

Epoch: 6| Step: 2
Training loss: 0.9267406463623047
Validation loss: 2.0139873514893236

Epoch: 6| Step: 3
Training loss: 1.5661230087280273
Validation loss: 2.024981830709724

Epoch: 6| Step: 4
Training loss: 1.8286709785461426
Validation loss: 2.0413468499337473

Epoch: 6| Step: 5
Training loss: 1.3514572381973267
Validation loss: 2.0771417348615584

Epoch: 6| Step: 6
Training loss: 2.1732239723205566
Validation loss: 2.104438263882873

Epoch: 6| Step: 7
Training loss: 1.4602415561676025
Validation loss: 2.10924102926767

Epoch: 6| Step: 8
Training loss: 1.6365622282028198
Validation loss: 2.125262233518785

Epoch: 6| Step: 9
Training loss: 1.3856284618377686
Validation loss: 2.134167630185363

Epoch: 6| Step: 10
Training loss: 1.8533047437667847
Validation loss: 2.148307036328059

Epoch: 6| Step: 11
Training loss: 1.9887046813964844
Validation loss: 2.141746155677303

Epoch: 6| Step: 12
Training loss: 1.3596391677856445
Validation loss: 2.12975969365848

Epoch: 6| Step: 13
Training loss: 2.3467440605163574
Validation loss: 2.120113459966516

Epoch: 157| Step: 0
Training loss: 2.043445587158203
Validation loss: 2.085818024091823

Epoch: 6| Step: 1
Training loss: 1.720341444015503
Validation loss: 2.078028558402933

Epoch: 6| Step: 2
Training loss: 1.293855905532837
Validation loss: 2.0618983878884265

Epoch: 6| Step: 3
Training loss: 1.027552843093872
Validation loss: 2.060315403887021

Epoch: 6| Step: 4
Training loss: 1.4747846126556396
Validation loss: 2.0604063157112367

Epoch: 6| Step: 5
Training loss: 1.425450325012207
Validation loss: 2.067849209231715

Epoch: 6| Step: 6
Training loss: 1.6093660593032837
Validation loss: 2.0429083531902683

Epoch: 6| Step: 7
Training loss: 1.5038378238677979
Validation loss: 2.0333963581310806

Epoch: 6| Step: 8
Training loss: 2.0097830295562744
Validation loss: 2.030690393140239

Epoch: 6| Step: 9
Training loss: 1.56268310546875
Validation loss: 2.0282784892666723

Epoch: 6| Step: 10
Training loss: 2.451582431793213
Validation loss: 2.0154475076224214

Epoch: 6| Step: 11
Training loss: 1.5761467218399048
Validation loss: 2.0332694130559124

Epoch: 6| Step: 12
Training loss: 1.581512689590454
Validation loss: 2.029252503507881

Epoch: 6| Step: 13
Training loss: 1.600571870803833
Validation loss: 2.0563285094435497

Epoch: 158| Step: 0
Training loss: 1.3291850090026855
Validation loss: 2.0752505410102104

Epoch: 6| Step: 1
Training loss: 1.708178997039795
Validation loss: 2.065745304989558

Epoch: 6| Step: 2
Training loss: 1.5307972431182861
Validation loss: 2.0931543380983415

Epoch: 6| Step: 3
Training loss: 1.7414590120315552
Validation loss: 2.089911332694433

Epoch: 6| Step: 4
Training loss: 1.8131999969482422
Validation loss: 2.100798285135659

Epoch: 6| Step: 5
Training loss: 1.812943696975708
Validation loss: 2.098418010178433

Epoch: 6| Step: 6
Training loss: 1.348466396331787
Validation loss: 2.1013849781405542

Epoch: 6| Step: 7
Training loss: 1.4657062292099
Validation loss: 2.119665433001775

Epoch: 6| Step: 8
Training loss: 1.4599335193634033
Validation loss: 2.1217520211332586

Epoch: 6| Step: 9
Training loss: 1.579011082649231
Validation loss: 2.1035107451100505

Epoch: 6| Step: 10
Training loss: 1.5458345413208008
Validation loss: 2.10804122237749

Epoch: 6| Step: 11
Training loss: 1.7937836647033691
Validation loss: 2.107614750503212

Epoch: 6| Step: 12
Training loss: 1.7104454040527344
Validation loss: 2.1011492949660107

Epoch: 6| Step: 13
Training loss: 1.5526881217956543
Validation loss: 2.092763452119725

Epoch: 159| Step: 0
Training loss: 1.8912843465805054
Validation loss: 2.09475387296369

Epoch: 6| Step: 1
Training loss: 1.2249186038970947
Validation loss: 2.0656125699320147

Epoch: 6| Step: 2
Training loss: 2.074589729309082
Validation loss: 2.054948168416177

Epoch: 6| Step: 3
Training loss: 1.6529631614685059
Validation loss: 2.073848816656297

Epoch: 6| Step: 4
Training loss: 1.655415415763855
Validation loss: 2.053172319166122

Epoch: 6| Step: 5
Training loss: 1.712559461593628
Validation loss: 2.0592831462942143

Epoch: 6| Step: 6
Training loss: 1.1888511180877686
Validation loss: 2.0773314404231247

Epoch: 6| Step: 7
Training loss: 1.0517573356628418
Validation loss: 2.0886657289279404

Epoch: 6| Step: 8
Training loss: 1.3617819547653198
Validation loss: 2.0979989651710755

Epoch: 6| Step: 9
Training loss: 1.5516629219055176
Validation loss: 2.1023892356503393

Epoch: 6| Step: 10
Training loss: 1.62940514087677
Validation loss: 2.0965435133185437

Epoch: 6| Step: 11
Training loss: 1.4280805587768555
Validation loss: 2.1128821321713027

Epoch: 6| Step: 12
Training loss: 2.2673213481903076
Validation loss: 2.1411097754714308

Epoch: 6| Step: 13
Training loss: 1.011427640914917
Validation loss: 2.120756795329432

Epoch: 160| Step: 0
Training loss: 1.5476757287979126
Validation loss: 2.1231945150641987

Epoch: 6| Step: 1
Training loss: 1.500089168548584
Validation loss: 2.1168946860938944

Epoch: 6| Step: 2
Training loss: 1.5191656351089478
Validation loss: 2.1228128415282055

Epoch: 6| Step: 3
Training loss: 1.641467809677124
Validation loss: 2.1096151977457027

Epoch: 6| Step: 4
Training loss: 1.6034893989562988
Validation loss: 2.0987112291397585

Epoch: 6| Step: 5
Training loss: 2.0937447547912598
Validation loss: 2.1139089471550396

Epoch: 6| Step: 6
Training loss: 1.6447865962982178
Validation loss: 2.104659426596857

Epoch: 6| Step: 7
Training loss: 1.7727861404418945
Validation loss: 2.0805477288461502

Epoch: 6| Step: 8
Training loss: 1.1220226287841797
Validation loss: 2.0758456222472654

Epoch: 6| Step: 9
Training loss: 0.8054991960525513
Validation loss: 2.061649089218468

Epoch: 6| Step: 10
Training loss: 0.9710727334022522
Validation loss: 2.057948548306701

Epoch: 6| Step: 11
Training loss: 2.075869560241699
Validation loss: 2.03399944689966

Epoch: 6| Step: 12
Training loss: 1.9164137840270996
Validation loss: 2.034245878137568

Epoch: 6| Step: 13
Training loss: 0.9723587036132812
Validation loss: 2.036308468029063

Epoch: 161| Step: 0
Training loss: 2.2317256927490234
Validation loss: 2.0334866046905518

Epoch: 6| Step: 1
Training loss: 1.8862050771713257
Validation loss: 2.045373965335149

Epoch: 6| Step: 2
Training loss: 1.8580031394958496
Validation loss: 2.048045401932091

Epoch: 6| Step: 3
Training loss: 1.7285096645355225
Validation loss: 2.068435292090139

Epoch: 6| Step: 4
Training loss: 1.7552582025527954
Validation loss: 2.1007078360485774

Epoch: 6| Step: 5
Training loss: 1.4131892919540405
Validation loss: 2.0822475059058076

Epoch: 6| Step: 6
Training loss: 1.6649110317230225
Validation loss: 2.1212464327453286

Epoch: 6| Step: 7
Training loss: 1.540327787399292
Validation loss: 2.113509601162326

Epoch: 6| Step: 8
Training loss: 1.5203113555908203
Validation loss: 2.1250964467243483

Epoch: 6| Step: 9
Training loss: 1.0334198474884033
Validation loss: 2.1096051226380053

Epoch: 6| Step: 10
Training loss: 1.0276479721069336
Validation loss: 2.092203691441526

Epoch: 6| Step: 11
Training loss: 1.407520055770874
Validation loss: 2.076286715845908

Epoch: 6| Step: 12
Training loss: 1.0249637365341187
Validation loss: 2.096997554584216

Epoch: 6| Step: 13
Training loss: 1.299669861793518
Validation loss: 2.11323255749159

Epoch: 162| Step: 0
Training loss: 1.4213783740997314
Validation loss: 2.0986398189298567

Epoch: 6| Step: 1
Training loss: 1.808523178100586
Validation loss: 2.0893811231018393

Epoch: 6| Step: 2
Training loss: 1.139122486114502
Validation loss: 2.116847571506295

Epoch: 6| Step: 3
Training loss: 1.4768753051757812
Validation loss: 2.0865711063467045

Epoch: 6| Step: 4
Training loss: 1.332951307296753
Validation loss: 2.054786197600826

Epoch: 6| Step: 5
Training loss: 2.2926979064941406
Validation loss: 2.0385889494290916

Epoch: 6| Step: 6
Training loss: 1.2425493001937866
Validation loss: 2.0627225598981305

Epoch: 6| Step: 7
Training loss: 1.2183399200439453
Validation loss: 2.0828903644315657

Epoch: 6| Step: 8
Training loss: 1.4902989864349365
Validation loss: 2.0729636184630857

Epoch: 6| Step: 9
Training loss: 1.1876006126403809
Validation loss: 2.080562472343445

Epoch: 6| Step: 10
Training loss: 2.015714645385742
Validation loss: 2.089848559389832

Epoch: 6| Step: 11
Training loss: 1.2895344495773315
Validation loss: 2.081885043010917

Epoch: 6| Step: 12
Training loss: 2.1600704193115234
Validation loss: 2.0892171193194646

Epoch: 6| Step: 13
Training loss: 1.143892765045166
Validation loss: 2.1057558034055974

Epoch: 163| Step: 0
Training loss: 1.335603952407837
Validation loss: 2.101600323953936

Epoch: 6| Step: 1
Training loss: 0.9727743864059448
Validation loss: 2.090087336878623

Epoch: 6| Step: 2
Training loss: 1.1932824850082397
Validation loss: 2.0880837440490723

Epoch: 6| Step: 3
Training loss: 1.074432611465454
Validation loss: 2.0797944030454083

Epoch: 6| Step: 4
Training loss: 1.5442163944244385
Validation loss: 2.078132821667579

Epoch: 6| Step: 5
Training loss: 1.9449236392974854
Validation loss: 2.0829342129409953

Epoch: 6| Step: 6
Training loss: 1.554386019706726
Validation loss: 2.0708807860651324

Epoch: 6| Step: 7
Training loss: 2.0093464851379395
Validation loss: 2.0635980303569506

Epoch: 6| Step: 8
Training loss: 1.7815186977386475
Validation loss: 2.0489453884863083

Epoch: 6| Step: 9
Training loss: 1.465996265411377
Validation loss: 2.0461742083231607

Epoch: 6| Step: 10
Training loss: 1.3372726440429688
Validation loss: 2.0682434010249313

Epoch: 6| Step: 11
Training loss: 1.9570274353027344
Validation loss: 2.0713108047362296

Epoch: 6| Step: 12
Training loss: 1.2891159057617188
Validation loss: 2.067787011464437

Epoch: 6| Step: 13
Training loss: 1.900529384613037
Validation loss: 2.0795483563535955

Epoch: 164| Step: 0
Training loss: 1.0946619510650635
Validation loss: 2.072633845831758

Epoch: 6| Step: 1
Training loss: 1.870621681213379
Validation loss: 2.090904653713267

Epoch: 6| Step: 2
Training loss: 0.6288694143295288
Validation loss: 2.0913876269453313

Epoch: 6| Step: 3
Training loss: 1.618051528930664
Validation loss: 2.0952741305033364

Epoch: 6| Step: 4
Training loss: 1.5570238828659058
Validation loss: 2.1074514107037614

Epoch: 6| Step: 5
Training loss: 1.2849526405334473
Validation loss: 2.0894190957469325

Epoch: 6| Step: 6
Training loss: 1.3927242755889893
Validation loss: 2.0776764513343893

Epoch: 6| Step: 7
Training loss: 1.231187343597412
Validation loss: 2.082144555225167

Epoch: 6| Step: 8
Training loss: 2.0895299911499023
Validation loss: 2.0635031935989216

Epoch: 6| Step: 9
Training loss: 1.940014362335205
Validation loss: 2.055557143303656

Epoch: 6| Step: 10
Training loss: 1.6046249866485596
Validation loss: 2.048964508118168

Epoch: 6| Step: 11
Training loss: 1.3798418045043945
Validation loss: 2.046621859714549

Epoch: 6| Step: 12
Training loss: 1.393387794494629
Validation loss: 2.0398240115052912

Epoch: 6| Step: 13
Training loss: 1.5897988080978394
Validation loss: 2.036645422699631

Epoch: 165| Step: 0
Training loss: 1.5515693426132202
Validation loss: 2.0481347127627303

Epoch: 6| Step: 1
Training loss: 1.7865643501281738
Validation loss: 2.0484210944944814

Epoch: 6| Step: 2
Training loss: 1.3253341913223267
Validation loss: 2.0604636438431276

Epoch: 6| Step: 3
Training loss: 1.6968097686767578
Validation loss: 2.0678614288248043

Epoch: 6| Step: 4
Training loss: 1.6752384901046753
Validation loss: 2.0623645039014917

Epoch: 6| Step: 5
Training loss: 1.715564250946045
Validation loss: 2.0627368932129233

Epoch: 6| Step: 6
Training loss: 1.3460838794708252
Validation loss: 2.056630588346912

Epoch: 6| Step: 7
Training loss: 1.365125060081482
Validation loss: 2.0605967121739543

Epoch: 6| Step: 8
Training loss: 1.3881882429122925
Validation loss: 2.051760611995574

Epoch: 6| Step: 9
Training loss: 1.3233587741851807
Validation loss: 2.041768817491429

Epoch: 6| Step: 10
Training loss: 1.1685028076171875
Validation loss: 2.0484104669222267

Epoch: 6| Step: 11
Training loss: 1.5546367168426514
Validation loss: 2.052838376773301

Epoch: 6| Step: 12
Training loss: 1.4514238834381104
Validation loss: 2.057550791771181

Epoch: 6| Step: 13
Training loss: 1.124708652496338
Validation loss: 2.066182849227741

Epoch: 166| Step: 0
Training loss: 1.4747157096862793
Validation loss: 2.06525013267353

Epoch: 6| Step: 1
Training loss: 0.9467044472694397
Validation loss: 2.0760857315473658

Epoch: 6| Step: 2
Training loss: 1.8316212892532349
Validation loss: 2.0488168385721024

Epoch: 6| Step: 3
Training loss: 1.5526865720748901
Validation loss: 2.073364600058525

Epoch: 6| Step: 4
Training loss: 1.4506747722625732
Validation loss: 2.071047748288801

Epoch: 6| Step: 5
Training loss: 1.3749111890792847
Validation loss: 2.0620052096664265

Epoch: 6| Step: 6
Training loss: 1.2032017707824707
Validation loss: 2.061480011991275

Epoch: 6| Step: 7
Training loss: 1.5291634798049927
Validation loss: 2.0489332137569303

Epoch: 6| Step: 8
Training loss: 1.4324047565460205
Validation loss: 2.0635879860129407

Epoch: 6| Step: 9
Training loss: 1.396793246269226
Validation loss: 2.057414262525497

Epoch: 6| Step: 10
Training loss: 1.478851318359375
Validation loss: 2.0650236734779934

Epoch: 6| Step: 11
Training loss: 1.589965581893921
Validation loss: 2.0690157054572977

Epoch: 6| Step: 12
Training loss: 1.4047776460647583
Validation loss: 2.074213320209134

Epoch: 6| Step: 13
Training loss: 1.4444735050201416
Validation loss: 2.1110257307688394

Epoch: 167| Step: 0
Training loss: 1.4936065673828125
Validation loss: 2.107604921505015

Epoch: 6| Step: 1
Training loss: 1.5797173976898193
Validation loss: 2.114488552975398

Epoch: 6| Step: 2
Training loss: 1.4234806299209595
Validation loss: 2.091286169585361

Epoch: 6| Step: 3
Training loss: 1.566396713256836
Validation loss: 2.0851669337159846

Epoch: 6| Step: 4
Training loss: 1.8491480350494385
Validation loss: 2.0792088893152054

Epoch: 6| Step: 5
Training loss: 0.8512900471687317
Validation loss: 2.0637071465933197

Epoch: 6| Step: 6
Training loss: 1.1803104877471924
Validation loss: 2.0654406291182323

Epoch: 6| Step: 7
Training loss: 0.8736296892166138
Validation loss: 2.05648575931467

Epoch: 6| Step: 8
Training loss: 2.2638096809387207
Validation loss: 2.06845139175333

Epoch: 6| Step: 9
Training loss: 1.4074077606201172
Validation loss: 2.032088159233011

Epoch: 6| Step: 10
Training loss: 1.100852370262146
Validation loss: 2.0315186823568037

Epoch: 6| Step: 11
Training loss: 1.5296790599822998
Validation loss: 2.0381978481046614

Epoch: 6| Step: 12
Training loss: 1.3721956014633179
Validation loss: 2.0577578236979823

Epoch: 6| Step: 13
Training loss: 1.7908164262771606
Validation loss: 2.07095903735007

Epoch: 168| Step: 0
Training loss: 1.5106490850448608
Validation loss: 2.0627251466115317

Epoch: 6| Step: 1
Training loss: 1.2811368703842163
Validation loss: 2.0809753043677217

Epoch: 6| Step: 2
Training loss: 0.7933647632598877
Validation loss: 2.056411556018296

Epoch: 6| Step: 3
Training loss: 1.5046188831329346
Validation loss: 2.071219559638731

Epoch: 6| Step: 4
Training loss: 1.0920042991638184
Validation loss: 2.081872437589912

Epoch: 6| Step: 5
Training loss: 1.2050857543945312
Validation loss: 2.0754316596574682

Epoch: 6| Step: 6
Training loss: 1.868804931640625
Validation loss: 2.08157967880208

Epoch: 6| Step: 7
Training loss: 1.6806676387786865
Validation loss: 2.097752772351747

Epoch: 6| Step: 8
Training loss: 1.5569169521331787
Validation loss: 2.1265006924188263

Epoch: 6| Step: 9
Training loss: 1.6887831687927246
Validation loss: 2.1574786196472826

Epoch: 6| Step: 10
Training loss: 1.9127527475357056
Validation loss: 2.1723858284693893

Epoch: 6| Step: 11
Training loss: 1.227973461151123
Validation loss: 2.1567512763443815

Epoch: 6| Step: 12
Training loss: 1.3251523971557617
Validation loss: 2.1340193030654744

Epoch: 6| Step: 13
Training loss: 1.477170705795288
Validation loss: 2.108755866686503

Epoch: 169| Step: 0
Training loss: 1.2321243286132812
Validation loss: 2.0827213846227175

Epoch: 6| Step: 1
Training loss: 1.4479575157165527
Validation loss: 2.0679119761272142

Epoch: 6| Step: 2
Training loss: 0.8942996263504028
Validation loss: 2.0455581449693248

Epoch: 6| Step: 3
Training loss: 1.4329959154129028
Validation loss: 2.020224363573136

Epoch: 6| Step: 4
Training loss: 0.8799876570701599
Validation loss: 2.029699356325211

Epoch: 6| Step: 5
Training loss: 1.0414936542510986
Validation loss: 2.004271707227153

Epoch: 6| Step: 6
Training loss: 2.2262630462646484
Validation loss: 2.0268367823734077

Epoch: 6| Step: 7
Training loss: 1.891765832901001
Validation loss: 2.014686838273079

Epoch: 6| Step: 8
Training loss: 0.9433019161224365
Validation loss: 2.012852253452424

Epoch: 6| Step: 9
Training loss: 1.466926097869873
Validation loss: 2.028700597824589

Epoch: 6| Step: 10
Training loss: 1.8090791702270508
Validation loss: 2.0573459440662014

Epoch: 6| Step: 11
Training loss: 1.4687861204147339
Validation loss: 2.057106292375954

Epoch: 6| Step: 12
Training loss: 1.6348825693130493
Validation loss: 2.068261813091975

Epoch: 6| Step: 13
Training loss: 1.3094744682312012
Validation loss: 2.0937298805482927

Epoch: 170| Step: 0
Training loss: 1.705188274383545
Validation loss: 2.1046324647882932

Epoch: 6| Step: 1
Training loss: 1.552795171737671
Validation loss: 2.099756069080804

Epoch: 6| Step: 2
Training loss: 1.0303575992584229
Validation loss: 2.1025147232958066

Epoch: 6| Step: 3
Training loss: 1.173863172531128
Validation loss: 2.1070110464608796

Epoch: 6| Step: 4
Training loss: 1.2221932411193848
Validation loss: 2.1278589733185305

Epoch: 6| Step: 5
Training loss: 1.222201943397522
Validation loss: 2.1365368930242394

Epoch: 6| Step: 6
Training loss: 1.6554014682769775
Validation loss: 2.116483783209196

Epoch: 6| Step: 7
Training loss: 1.5076930522918701
Validation loss: 2.1037145609496744

Epoch: 6| Step: 8
Training loss: 1.332231044769287
Validation loss: 2.064900508490942

Epoch: 6| Step: 9
Training loss: 1.0682923793792725
Validation loss: 2.059486614760532

Epoch: 6| Step: 10
Training loss: 1.360379934310913
Validation loss: 2.052263912334237

Epoch: 6| Step: 11
Training loss: 1.4519346952438354
Validation loss: 2.071839545362739

Epoch: 6| Step: 12
Training loss: 1.955426573753357
Validation loss: 2.0493840837991364

Epoch: 6| Step: 13
Training loss: 1.2802705764770508
Validation loss: 2.0549132926489717

Epoch: 171| Step: 0
Training loss: 2.1297080516815186
Validation loss: 2.0537965733517884

Epoch: 6| Step: 1
Training loss: 1.7675433158874512
Validation loss: 2.06875023277857

Epoch: 6| Step: 2
Training loss: 1.3054559230804443
Validation loss: 2.081631168242424

Epoch: 6| Step: 3
Training loss: 1.271978735923767
Validation loss: 2.062666534095682

Epoch: 6| Step: 4
Training loss: 0.9182819128036499
Validation loss: 2.080136875952444

Epoch: 6| Step: 5
Training loss: 1.0903531312942505
Validation loss: 2.1064719025806715

Epoch: 6| Step: 6
Training loss: 1.1677474975585938
Validation loss: 2.1598290576729724

Epoch: 6| Step: 7
Training loss: 1.363690733909607
Validation loss: 2.1576174151512886

Epoch: 6| Step: 8
Training loss: 1.8325109481811523
Validation loss: 2.1528755413588656

Epoch: 6| Step: 9
Training loss: 1.6894772052764893
Validation loss: 2.11440194806745

Epoch: 6| Step: 10
Training loss: 1.3234164714813232
Validation loss: 2.115505360787915

Epoch: 6| Step: 11
Training loss: 0.9614837765693665
Validation loss: 2.0943392604909916

Epoch: 6| Step: 12
Training loss: 1.6256203651428223
Validation loss: 2.0805533983374156

Epoch: 6| Step: 13
Training loss: 1.4149216413497925
Validation loss: 2.0837430851433867

Epoch: 172| Step: 0
Training loss: 2.0573081970214844
Validation loss: 2.0914212170467583

Epoch: 6| Step: 1
Training loss: 1.6204185485839844
Validation loss: 2.1156651409723426

Epoch: 6| Step: 2
Training loss: 1.5120062828063965
Validation loss: 2.1337113200977282

Epoch: 6| Step: 3
Training loss: 1.210127592086792
Validation loss: 2.136129028053694

Epoch: 6| Step: 4
Training loss: 1.415218472480774
Validation loss: 2.1181587762730096

Epoch: 6| Step: 5
Training loss: 1.1028616428375244
Validation loss: 2.0985796387477587

Epoch: 6| Step: 6
Training loss: 1.795413851737976
Validation loss: 2.083928854234757

Epoch: 6| Step: 7
Training loss: 1.9271595478057861
Validation loss: 2.069116271952147

Epoch: 6| Step: 8
Training loss: 1.3966206312179565
Validation loss: 2.058927059173584

Epoch: 6| Step: 9
Training loss: 0.7977432012557983
Validation loss: 2.0615953758198726

Epoch: 6| Step: 10
Training loss: 1.4849154949188232
Validation loss: 2.0618006016618464

Epoch: 6| Step: 11
Training loss: 1.1896717548370361
Validation loss: 2.0842993156884306

Epoch: 6| Step: 12
Training loss: 1.4765031337738037
Validation loss: 2.071799141104503

Epoch: 6| Step: 13
Training loss: 1.1027944087982178
Validation loss: 2.0898885009109334

Epoch: 173| Step: 0
Training loss: 1.760450839996338
Validation loss: 2.077705075663905

Epoch: 6| Step: 1
Training loss: 1.0557448863983154
Validation loss: 2.0946187383385113

Epoch: 6| Step: 2
Training loss: 2.0329182147979736
Validation loss: 2.0717148691095333

Epoch: 6| Step: 3
Training loss: 1.652745246887207
Validation loss: 2.076320908402884

Epoch: 6| Step: 4
Training loss: 1.1271965503692627
Validation loss: 2.0931725168740876

Epoch: 6| Step: 5
Training loss: 1.091572642326355
Validation loss: 2.0853760575735443

Epoch: 6| Step: 6
Training loss: 1.1425049304962158
Validation loss: 2.1225277505895144

Epoch: 6| Step: 7
Training loss: 1.6504048109054565
Validation loss: 2.109456798081757

Epoch: 6| Step: 8
Training loss: 1.93135666847229
Validation loss: 2.1272547219389226

Epoch: 6| Step: 9
Training loss: 0.7871354818344116
Validation loss: 2.151129132957869

Epoch: 6| Step: 10
Training loss: 1.1259894371032715
Validation loss: 2.1567644765300136

Epoch: 6| Step: 11
Training loss: 1.0290205478668213
Validation loss: 2.1687388086831696

Epoch: 6| Step: 12
Training loss: 1.2984833717346191
Validation loss: 2.178111422446466

Epoch: 6| Step: 13
Training loss: 1.3469318151474
Validation loss: 2.1553178756467757

Epoch: 174| Step: 0
Training loss: 1.3909971714019775
Validation loss: 2.1090899359795356

Epoch: 6| Step: 1
Training loss: 0.8292170763015747
Validation loss: 2.0998218828631985

Epoch: 6| Step: 2
Training loss: 1.871412992477417
Validation loss: 2.069832835146176

Epoch: 6| Step: 3
Training loss: 1.2902193069458008
Validation loss: 2.0566384202690533

Epoch: 6| Step: 4
Training loss: 1.056504249572754
Validation loss: 2.044414815082345

Epoch: 6| Step: 5
Training loss: 1.4299225807189941
Validation loss: 2.0509163923161005

Epoch: 6| Step: 6
Training loss: 0.7745628952980042
Validation loss: 2.073880159726707

Epoch: 6| Step: 7
Training loss: 1.4306780099868774
Validation loss: 2.0690616125701577

Epoch: 6| Step: 8
Training loss: 0.547583281993866
Validation loss: 2.0556846318706388

Epoch: 6| Step: 9
Training loss: 2.0829720497131348
Validation loss: 2.030937571679392

Epoch: 6| Step: 10
Training loss: 1.3177217245101929
Validation loss: 2.031722237986903

Epoch: 6| Step: 11
Training loss: 1.7817349433898926
Validation loss: 2.0081352136468373

Epoch: 6| Step: 12
Training loss: 1.6325185298919678
Validation loss: 2.022837508109308

Epoch: 6| Step: 13
Training loss: 1.3489106893539429
Validation loss: 2.0256994770419214

Epoch: 175| Step: 0
Training loss: 1.126239538192749
Validation loss: 2.0244886208606023

Epoch: 6| Step: 1
Training loss: 1.6803313493728638
Validation loss: 2.0454208568860124

Epoch: 6| Step: 2
Training loss: 1.5878113508224487
Validation loss: 2.0241761207580566

Epoch: 6| Step: 3
Training loss: 1.3898303508758545
Validation loss: 2.0360947450002036

Epoch: 6| Step: 4
Training loss: 1.0320711135864258
Validation loss: 2.0355329962186914

Epoch: 6| Step: 5
Training loss: 0.9689750671386719
Validation loss: 2.046461409138095

Epoch: 6| Step: 6
Training loss: 1.7805237770080566
Validation loss: 2.0446487203721078

Epoch: 6| Step: 7
Training loss: 1.4865787029266357
Validation loss: 2.082719786192781

Epoch: 6| Step: 8
Training loss: 1.4502159357070923
Validation loss: 2.092372122631278

Epoch: 6| Step: 9
Training loss: 0.8041295409202576
Validation loss: 2.0887487703754055

Epoch: 6| Step: 10
Training loss: 1.282875895500183
Validation loss: 2.0850592992639028

Epoch: 6| Step: 11
Training loss: 1.4574790000915527
Validation loss: 2.0939017829074653

Epoch: 6| Step: 12
Training loss: 1.2852870225906372
Validation loss: 2.080935175700854

Epoch: 6| Step: 13
Training loss: 1.05337393283844
Validation loss: 2.088628037001497

Testing loss: 2.2738879680633546
