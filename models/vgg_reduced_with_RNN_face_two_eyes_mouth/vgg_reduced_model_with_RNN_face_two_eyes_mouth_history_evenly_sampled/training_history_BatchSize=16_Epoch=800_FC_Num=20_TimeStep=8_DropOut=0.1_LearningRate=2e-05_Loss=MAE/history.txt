Epoch: 1| Step: 0
Training loss: 4.20914363861084
Validation loss: 5.178927513860887

Epoch: 6| Step: 1
Training loss: 6.117783069610596
Validation loss: 5.152126819856705

Epoch: 6| Step: 2
Training loss: 4.4717817306518555
Validation loss: 5.1294063342514855

Epoch: 6| Step: 3
Training loss: 4.549966812133789
Validation loss: 5.105615990136259

Epoch: 6| Step: 4
Training loss: 5.335153579711914
Validation loss: 5.079534669076243

Epoch: 6| Step: 5
Training loss: 5.507088661193848
Validation loss: 5.049560039274154

Epoch: 6| Step: 6
Training loss: 4.437835693359375
Validation loss: 5.015538077200612

Epoch: 6| Step: 7
Training loss: 4.767092704772949
Validation loss: 4.976482083720546

Epoch: 6| Step: 8
Training loss: 4.311559200286865
Validation loss: 4.932299767771075

Epoch: 6| Step: 9
Training loss: 5.304025650024414
Validation loss: 4.8836434630937475

Epoch: 6| Step: 10
Training loss: 4.159344673156738
Validation loss: 4.82908821105957

Epoch: 6| Step: 11
Training loss: 4.613056182861328
Validation loss: 4.767912680102933

Epoch: 6| Step: 12
Training loss: 4.3890485763549805
Validation loss: 4.70341399920884

Epoch: 6| Step: 13
Training loss: 4.480964183807373
Validation loss: 4.636522144399663

Epoch: 2| Step: 0
Training loss: 4.886678695678711
Validation loss: 4.564712303940968

Epoch: 6| Step: 1
Training loss: 4.297572612762451
Validation loss: 4.490479346244566

Epoch: 6| Step: 2
Training loss: 4.288248538970947
Validation loss: 4.409411932832452

Epoch: 6| Step: 3
Training loss: 5.087144374847412
Validation loss: 4.327823526115828

Epoch: 6| Step: 4
Training loss: 3.3715603351593018
Validation loss: 4.249471756719774

Epoch: 6| Step: 5
Training loss: 3.7605478763580322
Validation loss: 4.168567354961108

Epoch: 6| Step: 6
Training loss: 4.0415496826171875
Validation loss: 4.09028140447473

Epoch: 6| Step: 7
Training loss: 3.945709228515625
Validation loss: 4.012771806409282

Epoch: 6| Step: 8
Training loss: 3.123368978500366
Validation loss: 3.935904554141465

Epoch: 6| Step: 9
Training loss: 3.7385923862457275
Validation loss: 3.870609032210483

Epoch: 6| Step: 10
Training loss: 3.4558863639831543
Validation loss: 3.806794656220303

Epoch: 6| Step: 11
Training loss: 3.4909324645996094
Validation loss: 3.751501014155726

Epoch: 6| Step: 12
Training loss: 3.756488561630249
Validation loss: 3.701979511527605

Epoch: 6| Step: 13
Training loss: 3.455049991607666
Validation loss: 3.6575887280125774

Epoch: 3| Step: 0
Training loss: 3.7454946041107178
Validation loss: 3.622785768201274

Epoch: 6| Step: 1
Training loss: 4.198891639709473
Validation loss: 3.585587845053724

Epoch: 6| Step: 2
Training loss: 3.735750675201416
Validation loss: 3.553327980861869

Epoch: 6| Step: 3
Training loss: 3.143500566482544
Validation loss: 3.530594297634658

Epoch: 6| Step: 4
Training loss: 4.689517021179199
Validation loss: 3.507964418780419

Epoch: 6| Step: 5
Training loss: 3.8334901332855225
Validation loss: 3.4891617631399505

Epoch: 6| Step: 6
Training loss: 3.8164584636688232
Validation loss: 3.47458968880356

Epoch: 6| Step: 7
Training loss: 3.4170994758605957
Validation loss: 3.459637898270802

Epoch: 6| Step: 8
Training loss: 3.695002794265747
Validation loss: 3.44356700681871

Epoch: 6| Step: 9
Training loss: 2.959920883178711
Validation loss: 3.4235272151167675

Epoch: 6| Step: 10
Training loss: 2.0804262161254883
Validation loss: 3.408373104628696

Epoch: 6| Step: 11
Training loss: 3.051424026489258
Validation loss: 3.39525705511852

Epoch: 6| Step: 12
Training loss: 2.3661136627197266
Validation loss: 3.3825622374011624

Epoch: 6| Step: 13
Training loss: 3.0499095916748047
Validation loss: 3.3657283577867734

Epoch: 4| Step: 0
Training loss: 2.99269437789917
Validation loss: 3.3499272151659896

Epoch: 6| Step: 1
Training loss: 3.3855557441711426
Validation loss: 3.330755046618882

Epoch: 6| Step: 2
Training loss: 3.7024166584014893
Validation loss: 3.3105512947164555

Epoch: 6| Step: 3
Training loss: 2.2850430011749268
Validation loss: 3.2975356860827376

Epoch: 6| Step: 4
Training loss: 2.846597194671631
Validation loss: 3.3142960609928256

Epoch: 6| Step: 5
Training loss: 4.22674036026001
Validation loss: 3.262492379834575

Epoch: 6| Step: 6
Training loss: 2.5422134399414062
Validation loss: 3.2590091766849643

Epoch: 6| Step: 7
Training loss: 3.4649853706359863
Validation loss: 3.2612687413410475

Epoch: 6| Step: 8
Training loss: 3.7809624671936035
Validation loss: 3.247250049344955

Epoch: 6| Step: 9
Training loss: 3.5031352043151855
Validation loss: 3.229130914134364

Epoch: 6| Step: 10
Training loss: 2.9565980434417725
Validation loss: 3.2107562890616794

Epoch: 6| Step: 11
Training loss: 2.8732588291168213
Validation loss: 3.1932941175276235

Epoch: 6| Step: 12
Training loss: 3.2676262855529785
Validation loss: 3.1821725958137104

Epoch: 6| Step: 13
Training loss: 3.8154666423797607
Validation loss: 3.174942967712238

Epoch: 5| Step: 0
Training loss: 2.697103261947632
Validation loss: 3.1640038387749785

Epoch: 6| Step: 1
Training loss: 3.7196006774902344
Validation loss: 3.143050686005623

Epoch: 6| Step: 2
Training loss: 2.936573028564453
Validation loss: 3.1496244092141428

Epoch: 6| Step: 3
Training loss: 2.456937313079834
Validation loss: 3.1285890097259195

Epoch: 6| Step: 4
Training loss: 2.7148494720458984
Validation loss: 3.1063202555461595

Epoch: 6| Step: 5
Training loss: 4.6431379318237305
Validation loss: 3.0913581745598906

Epoch: 6| Step: 6
Training loss: 3.191460609436035
Validation loss: 3.0810124720296552

Epoch: 6| Step: 7
Training loss: 3.697299003601074
Validation loss: 3.058137063057192

Epoch: 6| Step: 8
Training loss: 2.575714588165283
Validation loss: 3.047972407392276

Epoch: 6| Step: 9
Training loss: 3.0363211631774902
Validation loss: 3.035450812309019

Epoch: 6| Step: 10
Training loss: 3.113675594329834
Validation loss: 3.0273942973024104

Epoch: 6| Step: 11
Training loss: 2.52945613861084
Validation loss: 3.024175282447569

Epoch: 6| Step: 12
Training loss: 3.9236178398132324
Validation loss: 3.0120596885681152

Epoch: 6| Step: 13
Training loss: 1.8390250205993652
Validation loss: 3.003368898104596

Epoch: 6| Step: 0
Training loss: 2.883566379547119
Validation loss: 3.02378987496899

Epoch: 6| Step: 1
Training loss: 3.60428524017334
Validation loss: 3.009862333215693

Epoch: 6| Step: 2
Training loss: 3.366697311401367
Validation loss: 2.9649416349267446

Epoch: 6| Step: 3
Training loss: 2.7559814453125
Validation loss: 2.96420197333059

Epoch: 6| Step: 4
Training loss: 3.3115968704223633
Validation loss: 2.9620863006960962

Epoch: 6| Step: 5
Training loss: 2.463433265686035
Validation loss: 2.9511518119483866

Epoch: 6| Step: 6
Training loss: 3.11800479888916
Validation loss: 2.9414278179086666

Epoch: 6| Step: 7
Training loss: 3.7086102962493896
Validation loss: 2.939428867832307

Epoch: 6| Step: 8
Training loss: 2.915388584136963
Validation loss: 2.9274466601751183

Epoch: 6| Step: 9
Training loss: 3.095966100692749
Validation loss: 2.9188467379539245

Epoch: 6| Step: 10
Training loss: 2.3821022510528564
Validation loss: 2.921935373736966

Epoch: 6| Step: 11
Training loss: 3.0711193084716797
Validation loss: 2.9435882978541876

Epoch: 6| Step: 12
Training loss: 2.1614253520965576
Validation loss: 2.929321522353798

Epoch: 6| Step: 13
Training loss: 4.139822959899902
Validation loss: 2.9020828329106814

Epoch: 7| Step: 0
Training loss: 3.631140947341919
Validation loss: 2.8926838136488393

Epoch: 6| Step: 1
Training loss: 3.2298390865325928
Validation loss: 2.884404915635304

Epoch: 6| Step: 2
Training loss: 2.9958548545837402
Validation loss: 2.870567931923815

Epoch: 6| Step: 3
Training loss: 2.33302640914917
Validation loss: 2.864475037461968

Epoch: 6| Step: 4
Training loss: 3.198345422744751
Validation loss: 2.863751575510989

Epoch: 6| Step: 5
Training loss: 2.5720343589782715
Validation loss: 2.864273202034735

Epoch: 6| Step: 6
Training loss: 3.15037202835083
Validation loss: 2.8703253499923216

Epoch: 6| Step: 7
Training loss: 3.623408079147339
Validation loss: 2.891435677005399

Epoch: 6| Step: 8
Training loss: 2.6011343002319336
Validation loss: 2.8463176604240172

Epoch: 6| Step: 9
Training loss: 2.5597338676452637
Validation loss: 2.836945269697456

Epoch: 6| Step: 10
Training loss: 2.5893633365631104
Validation loss: 2.8421434330683883

Epoch: 6| Step: 11
Training loss: 3.1541800498962402
Validation loss: 2.8382267644328456

Epoch: 6| Step: 12
Training loss: 3.5237526893615723
Validation loss: 2.829724132373769

Epoch: 6| Step: 13
Training loss: 2.085754156112671
Validation loss: 2.8198834721760084

Epoch: 8| Step: 0
Training loss: 3.6271095275878906
Validation loss: 2.8034164418456373

Epoch: 6| Step: 1
Training loss: 3.535956621170044
Validation loss: 2.8040208303800194

Epoch: 6| Step: 2
Training loss: 3.5979623794555664
Validation loss: 2.796918425508725

Epoch: 6| Step: 3
Training loss: 2.8805813789367676
Validation loss: 2.786333745525729

Epoch: 6| Step: 4
Training loss: 3.065138578414917
Validation loss: 2.7800742144225747

Epoch: 6| Step: 5
Training loss: 2.4666433334350586
Validation loss: 2.7749583669888076

Epoch: 6| Step: 6
Training loss: 2.3174614906311035
Validation loss: 2.772722516008603

Epoch: 6| Step: 7
Training loss: 3.0952377319335938
Validation loss: 2.7698868731016755

Epoch: 6| Step: 8
Training loss: 2.8771119117736816
Validation loss: 2.7678795271022345

Epoch: 6| Step: 9
Training loss: 2.8724567890167236
Validation loss: 2.7544121178247596

Epoch: 6| Step: 10
Training loss: 2.7158093452453613
Validation loss: 2.746218576226183

Epoch: 6| Step: 11
Training loss: 2.7802319526672363
Validation loss: 2.7381971959144837

Epoch: 6| Step: 12
Training loss: 1.9334192276000977
Validation loss: 2.7322029093260407

Epoch: 6| Step: 13
Training loss: 3.106826066970825
Validation loss: 2.727739610979634

Epoch: 9| Step: 0
Training loss: 3.550126552581787
Validation loss: 2.7224087022965953

Epoch: 6| Step: 1
Training loss: 2.3886895179748535
Validation loss: 2.713698528146231

Epoch: 6| Step: 2
Training loss: 3.208808660507202
Validation loss: 2.705493473237561

Epoch: 6| Step: 3
Training loss: 2.4206225872039795
Validation loss: 2.7150175699623684

Epoch: 6| Step: 4
Training loss: 2.644178628921509
Validation loss: 2.697819548268472

Epoch: 6| Step: 5
Training loss: 2.723656177520752
Validation loss: 2.692487460310741

Epoch: 6| Step: 6
Training loss: 2.937291145324707
Validation loss: 2.6905914993696314

Epoch: 6| Step: 7
Training loss: 3.1063499450683594
Validation loss: 2.7101809517029793

Epoch: 6| Step: 8
Training loss: 2.874434471130371
Validation loss: 2.683126505985055

Epoch: 6| Step: 9
Training loss: 2.6763358116149902
Validation loss: 2.6729665315279396

Epoch: 6| Step: 10
Training loss: 3.2379581928253174
Validation loss: 2.6824889388135684

Epoch: 6| Step: 11
Training loss: 2.565248966217041
Validation loss: 2.679433068921489

Epoch: 6| Step: 12
Training loss: 2.8059966564178467
Validation loss: 2.676171656577818

Epoch: 6| Step: 13
Training loss: 3.0778188705444336
Validation loss: 2.6729296997029293

Epoch: 10| Step: 0
Training loss: 2.2675223350524902
Validation loss: 2.6580231625546693

Epoch: 6| Step: 1
Training loss: 3.3020360469818115
Validation loss: 2.6542283463221725

Epoch: 6| Step: 2
Training loss: 2.7002594470977783
Validation loss: 2.6430924989843882

Epoch: 6| Step: 3
Training loss: 2.3177785873413086
Validation loss: 2.6402738504512335

Epoch: 6| Step: 4
Training loss: 3.0104219913482666
Validation loss: 2.6319011975360174

Epoch: 6| Step: 5
Training loss: 3.2292094230651855
Validation loss: 2.6266469596534647

Epoch: 6| Step: 6
Training loss: 2.7219581604003906
Validation loss: 2.6216171492812452

Epoch: 6| Step: 7
Training loss: 2.8663060665130615
Validation loss: 2.617396475166403

Epoch: 6| Step: 8
Training loss: 2.873044490814209
Validation loss: 2.617549611676124

Epoch: 6| Step: 9
Training loss: 3.1321730613708496
Validation loss: 2.6099071297594296

Epoch: 6| Step: 10
Training loss: 2.6742000579833984
Validation loss: 2.60433389038168

Epoch: 6| Step: 11
Training loss: 2.3280014991760254
Validation loss: 2.6062625403045327

Epoch: 6| Step: 12
Training loss: 2.8917574882507324
Validation loss: 2.589720123557634

Epoch: 6| Step: 13
Training loss: 3.4023473262786865
Validation loss: 2.60491846453759

Epoch: 11| Step: 0
Training loss: 2.7882261276245117
Validation loss: 2.6511654700002363

Epoch: 6| Step: 1
Training loss: 2.37264084815979
Validation loss: 2.634113191276468

Epoch: 6| Step: 2
Training loss: 3.0439071655273438
Validation loss: 2.5778183962709162

Epoch: 6| Step: 3
Training loss: 2.5000576972961426
Validation loss: 2.5797911895218717

Epoch: 6| Step: 4
Training loss: 2.6408631801605225
Validation loss: 2.5981988342859412

Epoch: 6| Step: 5
Training loss: 2.703176498413086
Validation loss: 2.564835525328113

Epoch: 6| Step: 6
Training loss: 3.1748292446136475
Validation loss: 2.5607321775087746

Epoch: 6| Step: 7
Training loss: 3.1072962284088135
Validation loss: 2.5627728495546567

Epoch: 6| Step: 8
Training loss: 3.3238003253936768
Validation loss: 2.570804193455686

Epoch: 6| Step: 9
Training loss: 2.7677180767059326
Validation loss: 2.600251761815881

Epoch: 6| Step: 10
Training loss: 3.161944627761841
Validation loss: 2.570915701568768

Epoch: 6| Step: 11
Training loss: 2.7005977630615234
Validation loss: 2.549242329853837

Epoch: 6| Step: 12
Training loss: 2.6553924083709717
Validation loss: 2.539633407387682

Epoch: 6| Step: 13
Training loss: 1.592719554901123
Validation loss: 2.5744811463099655

Epoch: 12| Step: 0
Training loss: 3.0348081588745117
Validation loss: 2.59460235411121

Epoch: 6| Step: 1
Training loss: 2.8201451301574707
Validation loss: 2.563355281788816

Epoch: 6| Step: 2
Training loss: 2.646843433380127
Validation loss: 2.558526903070429

Epoch: 6| Step: 3
Training loss: 3.5570950508117676
Validation loss: 2.5485446427458074

Epoch: 6| Step: 4
Training loss: 3.370335817337036
Validation loss: 2.533862039607058

Epoch: 6| Step: 5
Training loss: 2.895719289779663
Validation loss: 2.5295658829391643

Epoch: 6| Step: 6
Training loss: 2.039206027984619
Validation loss: 2.5408042707750873

Epoch: 6| Step: 7
Training loss: 3.0027472972869873
Validation loss: 2.555888847638202

Epoch: 6| Step: 8
Training loss: 3.3206121921539307
Validation loss: 2.5650789007063834

Epoch: 6| Step: 9
Training loss: 2.5691981315612793
Validation loss: 2.5723907562994186

Epoch: 6| Step: 10
Training loss: 2.543181896209717
Validation loss: 2.538510767362451

Epoch: 6| Step: 11
Training loss: 2.5797462463378906
Validation loss: 2.518098464576147

Epoch: 6| Step: 12
Training loss: 1.8047661781311035
Validation loss: 2.5135262909755913

Epoch: 6| Step: 13
Training loss: 2.3807694911956787
Validation loss: 2.515964933620986

Epoch: 13| Step: 0
Training loss: 2.385977268218994
Validation loss: 2.511602270987726

Epoch: 6| Step: 1
Training loss: 2.825350761413574
Validation loss: 2.513834015015633

Epoch: 6| Step: 2
Training loss: 2.574267864227295
Validation loss: 2.5089229999050016

Epoch: 6| Step: 3
Training loss: 2.6167969703674316
Validation loss: 2.498866001764933

Epoch: 6| Step: 4
Training loss: 2.8459837436676025
Validation loss: 2.4922790783707813

Epoch: 6| Step: 5
Training loss: 2.3522818088531494
Validation loss: 2.4897167708284114

Epoch: 6| Step: 6
Training loss: 3.4944090843200684
Validation loss: 2.5093744852209605

Epoch: 6| Step: 7
Training loss: 2.8726963996887207
Validation loss: 2.5104598563204528

Epoch: 6| Step: 8
Training loss: 2.534486770629883
Validation loss: 2.5577699740727744

Epoch: 6| Step: 9
Training loss: 2.4442262649536133
Validation loss: 2.541822871854228

Epoch: 6| Step: 10
Training loss: 2.388827323913574
Validation loss: 2.5386797997259323

Epoch: 6| Step: 11
Training loss: 3.454409122467041
Validation loss: 2.5426429215297905

Epoch: 6| Step: 12
Training loss: 2.9109296798706055
Validation loss: 2.4860739861765215

Epoch: 6| Step: 13
Training loss: 2.8775219917297363
Validation loss: 2.4746483141376125

Epoch: 14| Step: 0
Training loss: 2.828463077545166
Validation loss: 2.481063178790513

Epoch: 6| Step: 1
Training loss: 1.9538376331329346
Validation loss: 2.489731204125189

Epoch: 6| Step: 2
Training loss: 2.201063632965088
Validation loss: 2.4965635986738306

Epoch: 6| Step: 3
Training loss: 2.921159505844116
Validation loss: 2.4976469829518306

Epoch: 6| Step: 4
Training loss: 2.7308268547058105
Validation loss: 2.510196647336406

Epoch: 6| Step: 5
Training loss: 2.282731533050537
Validation loss: 2.537718308869229

Epoch: 6| Step: 6
Training loss: 2.850022792816162
Validation loss: 2.5244264089933006

Epoch: 6| Step: 7
Training loss: 2.8010387420654297
Validation loss: 2.5075412232388734

Epoch: 6| Step: 8
Training loss: 2.860224962234497
Validation loss: 2.5089738804806947

Epoch: 6| Step: 9
Training loss: 2.402918577194214
Validation loss: 2.523010079578687

Epoch: 6| Step: 10
Training loss: 3.898571491241455
Validation loss: 2.504991736463321

Epoch: 6| Step: 11
Training loss: 3.0092225074768066
Validation loss: 2.464542463261594

Epoch: 6| Step: 12
Training loss: 2.832616090774536
Validation loss: 2.49208342131748

Epoch: 6| Step: 13
Training loss: 2.958554267883301
Validation loss: 2.5268612151504843

Epoch: 15| Step: 0
Training loss: 2.6333436965942383
Validation loss: 2.618527635451286

Epoch: 6| Step: 1
Training loss: 2.588779926300049
Validation loss: 2.6570687729825258

Epoch: 6| Step: 2
Training loss: 3.093904972076416
Validation loss: 2.6037082543937107

Epoch: 6| Step: 3
Training loss: 2.6748926639556885
Validation loss: 2.5088145271424325

Epoch: 6| Step: 4
Training loss: 2.6076526641845703
Validation loss: 2.472782242682672

Epoch: 6| Step: 5
Training loss: 1.9258519411087036
Validation loss: 2.4832966737849738

Epoch: 6| Step: 6
Training loss: 2.811398506164551
Validation loss: 2.5276727804573635

Epoch: 6| Step: 7
Training loss: 2.9980125427246094
Validation loss: 2.558663160570206

Epoch: 6| Step: 8
Training loss: 3.3774309158325195
Validation loss: 2.521168560110113

Epoch: 6| Step: 9
Training loss: 3.097273826599121
Validation loss: 2.508336892691992

Epoch: 6| Step: 10
Training loss: 3.4026057720184326
Validation loss: 2.4868378895585255

Epoch: 6| Step: 11
Training loss: 2.7345292568206787
Validation loss: 2.467593926255421

Epoch: 6| Step: 12
Training loss: 1.8941371440887451
Validation loss: 2.4519443768326954

Epoch: 6| Step: 13
Training loss: 2.9394235610961914
Validation loss: 2.4555866667019424

Epoch: 16| Step: 0
Training loss: 2.5848917961120605
Validation loss: 2.4626773506082515

Epoch: 6| Step: 1
Training loss: 2.626840591430664
Validation loss: 2.464732298287012

Epoch: 6| Step: 2
Training loss: 2.179952621459961
Validation loss: 2.4590444334091677

Epoch: 6| Step: 3
Training loss: 2.6972599029541016
Validation loss: 2.4495805360937632

Epoch: 6| Step: 4
Training loss: 3.7058510780334473
Validation loss: 2.450226563279347

Epoch: 6| Step: 5
Training loss: 3.299886703491211
Validation loss: 2.440140701109363

Epoch: 6| Step: 6
Training loss: 2.442148208618164
Validation loss: 2.4376058424672773

Epoch: 6| Step: 7
Training loss: 1.7346227169036865
Validation loss: 2.459900217671548

Epoch: 6| Step: 8
Training loss: 2.3259403705596924
Validation loss: 2.5065108191582466

Epoch: 6| Step: 9
Training loss: 3.102548837661743
Validation loss: 2.546340580909483

Epoch: 6| Step: 10
Training loss: 3.216919422149658
Validation loss: 2.5552616273203204

Epoch: 6| Step: 11
Training loss: 3.3352081775665283
Validation loss: 2.5486284789218696

Epoch: 6| Step: 12
Training loss: 1.9993138313293457
Validation loss: 2.5347334672045965

Epoch: 6| Step: 13
Training loss: 2.820615768432617
Validation loss: 2.4999051940056587

Epoch: 17| Step: 0
Training loss: 2.337697982788086
Validation loss: 2.482182482237457

Epoch: 6| Step: 1
Training loss: 2.780825614929199
Validation loss: 2.461275613436135

Epoch: 6| Step: 2
Training loss: 3.6179299354553223
Validation loss: 2.4461595550660165

Epoch: 6| Step: 3
Training loss: 3.4835493564605713
Validation loss: 2.447368606444328

Epoch: 6| Step: 4
Training loss: 2.153874397277832
Validation loss: 2.4452215856121433

Epoch: 6| Step: 5
Training loss: 2.7863008975982666
Validation loss: 2.4647472802028862

Epoch: 6| Step: 6
Training loss: 2.455838203430176
Validation loss: 2.4704515600717194

Epoch: 6| Step: 7
Training loss: 2.395092725753784
Validation loss: 2.4601157660125406

Epoch: 6| Step: 8
Training loss: 2.1254310607910156
Validation loss: 2.4858202998356154

Epoch: 6| Step: 9
Training loss: 2.95988130569458
Validation loss: 2.5598243462142123

Epoch: 6| Step: 10
Training loss: 2.2737176418304443
Validation loss: 2.603784648321008

Epoch: 6| Step: 11
Training loss: 3.086158275604248
Validation loss: 2.6298929568259948

Epoch: 6| Step: 12
Training loss: 2.862093925476074
Validation loss: 2.5380058634665703

Epoch: 6| Step: 13
Training loss: 2.6431777477264404
Validation loss: 2.465111638910027

Epoch: 18| Step: 0
Training loss: 2.249913215637207
Validation loss: 2.421294555869154

Epoch: 6| Step: 1
Training loss: 2.8191981315612793
Validation loss: 2.4185952640348867

Epoch: 6| Step: 2
Training loss: 2.508733034133911
Validation loss: 2.4243122736612954

Epoch: 6| Step: 3
Training loss: 2.689944267272949
Validation loss: 2.458442675170078

Epoch: 6| Step: 4
Training loss: 2.9752860069274902
Validation loss: 2.4771812577401437

Epoch: 6| Step: 5
Training loss: 2.9523401260375977
Validation loss: 2.461372270379015

Epoch: 6| Step: 6
Training loss: 2.328348398208618
Validation loss: 2.4607160322127806

Epoch: 6| Step: 7
Training loss: 2.9345240592956543
Validation loss: 2.452998322825278

Epoch: 6| Step: 8
Training loss: 2.737442970275879
Validation loss: 2.419575359231682

Epoch: 6| Step: 9
Training loss: 2.859553813934326
Validation loss: 2.4340707089311335

Epoch: 6| Step: 10
Training loss: 2.123351812362671
Validation loss: 2.4574863731220202

Epoch: 6| Step: 11
Training loss: 3.1546103954315186
Validation loss: 2.4836655047632035

Epoch: 6| Step: 12
Training loss: 2.7845144271850586
Validation loss: 2.4962490912406676

Epoch: 6| Step: 13
Training loss: 2.416464328765869
Validation loss: 2.505167955993324

Epoch: 19| Step: 0
Training loss: 3.533060073852539
Validation loss: 2.4962487323309785

Epoch: 6| Step: 1
Training loss: 2.470249652862549
Validation loss: 2.462033612753755

Epoch: 6| Step: 2
Training loss: 2.3339505195617676
Validation loss: 2.4321016098863337

Epoch: 6| Step: 3
Training loss: 1.8653745651245117
Validation loss: 2.4230652342560473

Epoch: 6| Step: 4
Training loss: 2.332909107208252
Validation loss: 2.4255946323435795

Epoch: 6| Step: 5
Training loss: 2.6110613346099854
Validation loss: 2.414135035648141

Epoch: 6| Step: 6
Training loss: 2.4668877124786377
Validation loss: 2.4197194524990615

Epoch: 6| Step: 7
Training loss: 3.0490713119506836
Validation loss: 2.446252388338889

Epoch: 6| Step: 8
Training loss: 2.589407444000244
Validation loss: 2.4765096146573304

Epoch: 6| Step: 9
Training loss: 2.4206643104553223
Validation loss: 2.5009903830866658

Epoch: 6| Step: 10
Training loss: 2.635136604309082
Validation loss: 2.5307130582870974

Epoch: 6| Step: 11
Training loss: 2.6644630432128906
Validation loss: 2.5794430753236175

Epoch: 6| Step: 12
Training loss: 3.631476402282715
Validation loss: 2.5698048658268426

Epoch: 6| Step: 13
Training loss: 3.434807777404785
Validation loss: 2.5439648910235335

Epoch: 20| Step: 0
Training loss: 2.230365037918091
Validation loss: 2.4944511485356156

Epoch: 6| Step: 1
Training loss: 2.8290791511535645
Validation loss: 2.456027005308418

Epoch: 6| Step: 2
Training loss: 2.5473480224609375
Validation loss: 2.4416276613871255

Epoch: 6| Step: 3
Training loss: 3.1931610107421875
Validation loss: 2.432157357533773

Epoch: 6| Step: 4
Training loss: 2.692014694213867
Validation loss: 2.4204554327072634

Epoch: 6| Step: 5
Training loss: 2.787252902984619
Validation loss: 2.416637506536258

Epoch: 6| Step: 6
Training loss: 2.76456880569458
Validation loss: 2.4142120153673234

Epoch: 6| Step: 7
Training loss: 2.9195642471313477
Validation loss: 2.4192400337547384

Epoch: 6| Step: 8
Training loss: 2.3908865451812744
Validation loss: 2.4049381133048766

Epoch: 6| Step: 9
Training loss: 2.557421922683716
Validation loss: 2.4056062442000195

Epoch: 6| Step: 10
Training loss: 2.2614917755126953
Validation loss: 2.4213369225942962

Epoch: 6| Step: 11
Training loss: 2.3596765995025635
Validation loss: 2.4168746984133156

Epoch: 6| Step: 12
Training loss: 3.36462664604187
Validation loss: 2.417438804462392

Epoch: 6| Step: 13
Training loss: 1.9367948770523071
Validation loss: 2.4226748328055105

Epoch: 21| Step: 0
Training loss: 2.8870346546173096
Validation loss: 2.4269634703154206

Epoch: 6| Step: 1
Training loss: 2.176424741744995
Validation loss: 2.4247324287250476

Epoch: 6| Step: 2
Training loss: 2.931199073791504
Validation loss: 2.4131208030126428

Epoch: 6| Step: 3
Training loss: 3.1770589351654053
Validation loss: 2.4031293981818744

Epoch: 6| Step: 4
Training loss: 2.383755683898926
Validation loss: 2.4094020064159105

Epoch: 6| Step: 5
Training loss: 2.513669729232788
Validation loss: 2.430195580246628

Epoch: 6| Step: 6
Training loss: 2.7475926876068115
Validation loss: 2.3908328446008826

Epoch: 6| Step: 7
Training loss: 3.091529369354248
Validation loss: 2.3662663890469458

Epoch: 6| Step: 8
Training loss: 2.3540589809417725
Validation loss: 2.3469585462283065

Epoch: 6| Step: 9
Training loss: 2.064263343811035
Validation loss: 2.360095818837484

Epoch: 6| Step: 10
Training loss: 2.490739583969116
Validation loss: 2.3762753740433724

Epoch: 6| Step: 11
Training loss: 2.390894889831543
Validation loss: 2.401378559809859

Epoch: 6| Step: 12
Training loss: 2.875674247741699
Validation loss: 2.4245300241695937

Epoch: 6| Step: 13
Training loss: 3.324742317199707
Validation loss: 2.4384767624639694

Epoch: 22| Step: 0
Training loss: 2.5460336208343506
Validation loss: 2.41763573820873

Epoch: 6| Step: 1
Training loss: 2.373786687850952
Validation loss: 2.416689060067618

Epoch: 6| Step: 2
Training loss: 2.8193774223327637
Validation loss: 2.42555679557144

Epoch: 6| Step: 3
Training loss: 1.8745813369750977
Validation loss: 2.4248501895576395

Epoch: 6| Step: 4
Training loss: 2.6628148555755615
Validation loss: 2.4384376925806843

Epoch: 6| Step: 5
Training loss: 2.9628353118896484
Validation loss: 2.454418877119659

Epoch: 6| Step: 6
Training loss: 2.688965082168579
Validation loss: 2.4594470172800045

Epoch: 6| Step: 7
Training loss: 3.0677499771118164
Validation loss: 2.453327214846047

Epoch: 6| Step: 8
Training loss: 2.8486104011535645
Validation loss: 2.420191336703557

Epoch: 6| Step: 9
Training loss: 2.881619691848755
Validation loss: 2.400076086803149

Epoch: 6| Step: 10
Training loss: 2.37937068939209
Validation loss: 2.388078861339118

Epoch: 6| Step: 11
Training loss: 2.708847999572754
Validation loss: 2.381221858404016

Epoch: 6| Step: 12
Training loss: 2.8509039878845215
Validation loss: 2.395366008563708

Epoch: 6| Step: 13
Training loss: 2.542296886444092
Validation loss: 2.4198587607311945

Epoch: 23| Step: 0
Training loss: 2.773224115371704
Validation loss: 2.4246930306957615

Epoch: 6| Step: 1
Training loss: 2.861842632293701
Validation loss: 2.4247177390642065

Epoch: 6| Step: 2
Training loss: 2.101543664932251
Validation loss: 2.4091289248517764

Epoch: 6| Step: 3
Training loss: 2.8021469116210938
Validation loss: 2.392698435373204

Epoch: 6| Step: 4
Training loss: 3.068814277648926
Validation loss: 2.374699851518036

Epoch: 6| Step: 5
Training loss: 2.729320526123047
Validation loss: 2.3733124809880413

Epoch: 6| Step: 6
Training loss: 2.6793646812438965
Validation loss: 2.364716256818464

Epoch: 6| Step: 7
Training loss: 2.51326847076416
Validation loss: 2.3605387236482356

Epoch: 6| Step: 8
Training loss: 2.33255672454834
Validation loss: 2.3621893928896998

Epoch: 6| Step: 9
Training loss: 2.24993896484375
Validation loss: 2.368101214849821

Epoch: 6| Step: 10
Training loss: 3.17118239402771
Validation loss: 2.368907610575358

Epoch: 6| Step: 11
Training loss: 2.2585630416870117
Validation loss: 2.375399174228791

Epoch: 6| Step: 12
Training loss: 3.0119402408599854
Validation loss: 2.3766309394631335

Epoch: 6| Step: 13
Training loss: 2.5032527446746826
Validation loss: 2.380613434699274

Epoch: 24| Step: 0
Training loss: 2.2494800090789795
Validation loss: 2.3715874994954755

Epoch: 6| Step: 1
Training loss: 2.9780383110046387
Validation loss: 2.3696944405955653

Epoch: 6| Step: 2
Training loss: 3.090301275253296
Validation loss: 2.3721234234430457

Epoch: 6| Step: 3
Training loss: 2.2090115547180176
Validation loss: 2.370862783924226

Epoch: 6| Step: 4
Training loss: 2.1702542304992676
Validation loss: 2.3752934804526706

Epoch: 6| Step: 5
Training loss: 2.979097604751587
Validation loss: 2.377096255620321

Epoch: 6| Step: 6
Training loss: 2.2135748863220215
Validation loss: 2.377936896457467

Epoch: 6| Step: 7
Training loss: 2.3688924312591553
Validation loss: 2.3852011465257212

Epoch: 6| Step: 8
Training loss: 3.37599515914917
Validation loss: 2.3873771493152907

Epoch: 6| Step: 9
Training loss: 2.7737810611724854
Validation loss: 2.3856954548948552

Epoch: 6| Step: 10
Training loss: 3.161287307739258
Validation loss: 2.365393128446353

Epoch: 6| Step: 11
Training loss: 2.1211326122283936
Validation loss: 2.3604365215506604

Epoch: 6| Step: 12
Training loss: 2.3256454467773438
Validation loss: 2.3472178520694857

Epoch: 6| Step: 13
Training loss: 2.752122640609741
Validation loss: 2.3341956728248188

Epoch: 25| Step: 0
Training loss: 2.673764705657959
Validation loss: 2.320279295726489

Epoch: 6| Step: 1
Training loss: 2.8579976558685303
Validation loss: 2.3288236664187525

Epoch: 6| Step: 2
Training loss: 2.2976462841033936
Validation loss: 2.3408222429213987

Epoch: 6| Step: 3
Training loss: 2.858574151992798
Validation loss: 2.3523520064610306

Epoch: 6| Step: 4
Training loss: 2.256895065307617
Validation loss: 2.370761209918607

Epoch: 6| Step: 5
Training loss: 2.707122325897217
Validation loss: 2.391525863319315

Epoch: 6| Step: 6
Training loss: 2.7036876678466797
Validation loss: 2.413285650232787

Epoch: 6| Step: 7
Training loss: 2.8626456260681152
Validation loss: 2.4262630580573954

Epoch: 6| Step: 8
Training loss: 2.3398146629333496
Validation loss: 2.4531724658063663

Epoch: 6| Step: 9
Training loss: 3.0297739505767822
Validation loss: 2.446381030544158

Epoch: 6| Step: 10
Training loss: 2.746257781982422
Validation loss: 2.4180015697274158

Epoch: 6| Step: 11
Training loss: 2.3833794593811035
Validation loss: 2.4099269541361

Epoch: 6| Step: 12
Training loss: 2.483940362930298
Validation loss: 2.398367012700727

Epoch: 6| Step: 13
Training loss: 3.0437698364257812
Validation loss: 2.381458931071784

Epoch: 26| Step: 0
Training loss: 2.3510594367980957
Validation loss: 2.3719811618969007

Epoch: 6| Step: 1
Training loss: 3.0919437408447266
Validation loss: 2.375282218379359

Epoch: 6| Step: 2
Training loss: 2.832402467727661
Validation loss: 2.3802402480956046

Epoch: 6| Step: 3
Training loss: 2.305610179901123
Validation loss: 2.375186953493344

Epoch: 6| Step: 4
Training loss: 2.174696922302246
Validation loss: 2.3765403211757703

Epoch: 6| Step: 5
Training loss: 2.514279365539551
Validation loss: 2.3811882824026127

Epoch: 6| Step: 6
Training loss: 3.266819715499878
Validation loss: 2.378635250112062

Epoch: 6| Step: 7
Training loss: 2.2844724655151367
Validation loss: 2.36299116124389

Epoch: 6| Step: 8
Training loss: 2.6959166526794434
Validation loss: 2.3678087188351538

Epoch: 6| Step: 9
Training loss: 2.490969181060791
Validation loss: 2.3525533804329495

Epoch: 6| Step: 10
Training loss: 2.1845006942749023
Validation loss: 2.3365415450065368

Epoch: 6| Step: 11
Training loss: 2.8303565979003906
Validation loss: 2.322059667238625

Epoch: 6| Step: 12
Training loss: 2.8555550575256348
Validation loss: 2.32303019749221

Epoch: 6| Step: 13
Training loss: 2.7795755863189697
Validation loss: 2.3090321043486237

Epoch: 27| Step: 0
Training loss: 3.146587371826172
Validation loss: 2.3043130802851852

Epoch: 6| Step: 1
Training loss: 2.5054144859313965
Validation loss: 2.301864439441312

Epoch: 6| Step: 2
Training loss: 2.7641124725341797
Validation loss: 2.3029661537498556

Epoch: 6| Step: 3
Training loss: 2.3047022819519043
Validation loss: 2.3095382823739

Epoch: 6| Step: 4
Training loss: 2.978740930557251
Validation loss: 2.3146429625890588

Epoch: 6| Step: 5
Training loss: 2.324215888977051
Validation loss: 2.315009593963623

Epoch: 6| Step: 6
Training loss: 2.5208141803741455
Validation loss: 2.322397796056604

Epoch: 6| Step: 7
Training loss: 2.371042490005493
Validation loss: 2.3470403943010556

Epoch: 6| Step: 8
Training loss: 1.6391961574554443
Validation loss: 2.3840571270194104

Epoch: 6| Step: 9
Training loss: 2.363593816757202
Validation loss: 2.4106671348694833

Epoch: 6| Step: 10
Training loss: 2.9180469512939453
Validation loss: 2.4463050673084874

Epoch: 6| Step: 11
Training loss: 2.584554672241211
Validation loss: 2.464513058303505

Epoch: 6| Step: 12
Training loss: 2.9650542736053467
Validation loss: 2.4587032077133015

Epoch: 6| Step: 13
Training loss: 4.054354667663574
Validation loss: 2.425038993999522

Epoch: 28| Step: 0
Training loss: 2.5026283264160156
Validation loss: 2.374200109512575

Epoch: 6| Step: 1
Training loss: 2.6440629959106445
Validation loss: 2.361831631711734

Epoch: 6| Step: 2
Training loss: 2.8912429809570312
Validation loss: 2.3877545390077817

Epoch: 6| Step: 3
Training loss: 2.838724374771118
Validation loss: 2.3872537971824728

Epoch: 6| Step: 4
Training loss: 2.010854721069336
Validation loss: 2.392533782989748

Epoch: 6| Step: 5
Training loss: 3.0616042613983154
Validation loss: 2.394263170098746

Epoch: 6| Step: 6
Training loss: 2.645350933074951
Validation loss: 2.397035583373039

Epoch: 6| Step: 7
Training loss: 2.698444366455078
Validation loss: 2.404020360721055

Epoch: 6| Step: 8
Training loss: 2.6957907676696777
Validation loss: 2.4090855839431926

Epoch: 6| Step: 9
Training loss: 2.3313004970550537
Validation loss: 2.4449390211412982

Epoch: 6| Step: 10
Training loss: 2.3498754501342773
Validation loss: 2.470413589990267

Epoch: 6| Step: 11
Training loss: 3.0355241298675537
Validation loss: 2.4957637838138047

Epoch: 6| Step: 12
Training loss: 2.5444979667663574
Validation loss: 2.501663295171594

Epoch: 6| Step: 13
Training loss: 2.7057039737701416
Validation loss: 2.5160454832097536

Epoch: 29| Step: 0
Training loss: 2.7815463542938232
Validation loss: 2.5223065114790395

Epoch: 6| Step: 1
Training loss: 2.4628474712371826
Validation loss: 2.516503967264647

Epoch: 6| Step: 2
Training loss: 2.9671199321746826
Validation loss: 2.4975524640852407

Epoch: 6| Step: 3
Training loss: 2.5325582027435303
Validation loss: 2.483912423092832

Epoch: 6| Step: 4
Training loss: 2.639533281326294
Validation loss: 2.5043420740353164

Epoch: 6| Step: 5
Training loss: 3.506363868713379
Validation loss: 2.4863342803011657

Epoch: 6| Step: 6
Training loss: 2.3388290405273438
Validation loss: 2.4694257372169086

Epoch: 6| Step: 7
Training loss: 2.581109046936035
Validation loss: 2.4655666248772734

Epoch: 6| Step: 8
Training loss: 2.91996431350708
Validation loss: 2.4367721208962063

Epoch: 6| Step: 9
Training loss: 2.3062987327575684
Validation loss: 2.4015755679017756

Epoch: 6| Step: 10
Training loss: 2.9036598205566406
Validation loss: 2.3840326391240603

Epoch: 6| Step: 11
Training loss: 3.067842483520508
Validation loss: 2.3766100124646257

Epoch: 6| Step: 12
Training loss: 1.6561963558197021
Validation loss: 2.3757338241864274

Epoch: 6| Step: 13
Training loss: 2.3823039531707764
Validation loss: 2.3779281544429

Epoch: 30| Step: 0
Training loss: 3.1353774070739746
Validation loss: 2.380153714969594

Epoch: 6| Step: 1
Training loss: 2.580038547515869
Validation loss: 2.3946897291368052

Epoch: 6| Step: 2
Training loss: 2.3323183059692383
Validation loss: 2.4065599313346286

Epoch: 6| Step: 3
Training loss: 2.8430936336517334
Validation loss: 2.4027229355227564

Epoch: 6| Step: 4
Training loss: 3.1843366622924805
Validation loss: 2.40115628703948

Epoch: 6| Step: 5
Training loss: 2.106968402862549
Validation loss: 2.395953652679279

Epoch: 6| Step: 6
Training loss: 2.8148550987243652
Validation loss: 2.3931180482269614

Epoch: 6| Step: 7
Training loss: 2.677669048309326
Validation loss: 2.378005455898982

Epoch: 6| Step: 8
Training loss: 2.52170991897583
Validation loss: 2.3645917292564147

Epoch: 6| Step: 9
Training loss: 2.4391326904296875
Validation loss: 2.3559833111301547

Epoch: 6| Step: 10
Training loss: 2.9146173000335693
Validation loss: 2.345973837760187

Epoch: 6| Step: 11
Training loss: 2.1605138778686523
Validation loss: 2.3319568685306016

Epoch: 6| Step: 12
Training loss: 2.474961280822754
Validation loss: 2.3170658439718266

Epoch: 6| Step: 13
Training loss: 2.6126034259796143
Validation loss: 2.301191032573741

Epoch: 31| Step: 0
Training loss: 2.7643723487854004
Validation loss: 2.2908594121215162

Epoch: 6| Step: 1
Training loss: 1.9461777210235596
Validation loss: 2.2973717592095815

Epoch: 6| Step: 2
Training loss: 2.116313934326172
Validation loss: 2.3058096131970807

Epoch: 6| Step: 3
Training loss: 2.8871922492980957
Validation loss: 2.3295315055436987

Epoch: 6| Step: 4
Training loss: 2.402611255645752
Validation loss: 2.3226563494692565

Epoch: 6| Step: 5
Training loss: 2.6776461601257324
Validation loss: 2.3198203207344137

Epoch: 6| Step: 6
Training loss: 2.5296456813812256
Validation loss: 2.3018784574283067

Epoch: 6| Step: 7
Training loss: 2.439004898071289
Validation loss: 2.2650557179604807

Epoch: 6| Step: 8
Training loss: 2.615614891052246
Validation loss: 2.260922719073552

Epoch: 6| Step: 9
Training loss: 2.3461432456970215
Validation loss: 2.242349300333249

Epoch: 6| Step: 10
Training loss: 3.128714084625244
Validation loss: 2.2379468692246305

Epoch: 6| Step: 11
Training loss: 2.3716139793395996
Validation loss: 2.2397197369606263

Epoch: 6| Step: 12
Training loss: 3.3842055797576904
Validation loss: 2.2382873553101734

Epoch: 6| Step: 13
Training loss: 2.488473415374756
Validation loss: 2.241978291542299

Epoch: 32| Step: 0
Training loss: 2.1711502075195312
Validation loss: 2.2552809484543337

Epoch: 6| Step: 1
Training loss: 2.768322706222534
Validation loss: 2.2604196251079602

Epoch: 6| Step: 2
Training loss: 3.015651226043701
Validation loss: 2.245877746612795

Epoch: 6| Step: 3
Training loss: 2.3317079544067383
Validation loss: 2.23465024271319

Epoch: 6| Step: 4
Training loss: 2.3632524013519287
Validation loss: 2.231433258261732

Epoch: 6| Step: 5
Training loss: 2.2700672149658203
Validation loss: 2.234933490394264

Epoch: 6| Step: 6
Training loss: 2.309539794921875
Validation loss: 2.2469427970147904

Epoch: 6| Step: 7
Training loss: 1.9292898178100586
Validation loss: 2.266133177664972

Epoch: 6| Step: 8
Training loss: 2.7919692993164062
Validation loss: 2.2802237515808432

Epoch: 6| Step: 9
Training loss: 2.484983444213867
Validation loss: 2.302302993753905

Epoch: 6| Step: 10
Training loss: 3.058820962905884
Validation loss: 2.347942767604705

Epoch: 6| Step: 11
Training loss: 2.662513256072998
Validation loss: 2.4223690058595393

Epoch: 6| Step: 12
Training loss: 2.906060218811035
Validation loss: 2.464211716446825

Epoch: 6| Step: 13
Training loss: 3.221837043762207
Validation loss: 2.4846011259222545

Epoch: 33| Step: 0
Training loss: 2.6221933364868164
Validation loss: 2.3757089337994977

Epoch: 6| Step: 1
Training loss: 2.545731544494629
Validation loss: 2.302518370330975

Epoch: 6| Step: 2
Training loss: 2.4347848892211914
Validation loss: 2.2738658587137857

Epoch: 6| Step: 3
Training loss: 2.311786413192749
Validation loss: 2.24736600793818

Epoch: 6| Step: 4
Training loss: 2.4366888999938965
Validation loss: 2.2437133122515935

Epoch: 6| Step: 5
Training loss: 3.132373809814453
Validation loss: 2.246703160706387

Epoch: 6| Step: 6
Training loss: 2.8224339485168457
Validation loss: 2.2536082754852953

Epoch: 6| Step: 7
Training loss: 2.600353717803955
Validation loss: 2.257630632769677

Epoch: 6| Step: 8
Training loss: 2.9631187915802
Validation loss: 2.2579278048648628

Epoch: 6| Step: 9
Training loss: 1.8646513223648071
Validation loss: 2.269931536848827

Epoch: 6| Step: 10
Training loss: 2.700986862182617
Validation loss: 2.2686571844162478

Epoch: 6| Step: 11
Training loss: 2.5330605506896973
Validation loss: 2.2771171933861187

Epoch: 6| Step: 12
Training loss: 2.5014407634735107
Validation loss: 2.2827551621262745

Epoch: 6| Step: 13
Training loss: 2.604630708694458
Validation loss: 2.302257917260611

Epoch: 34| Step: 0
Training loss: 2.7558460235595703
Validation loss: 2.299219657016057

Epoch: 6| Step: 1
Training loss: 2.854135513305664
Validation loss: 2.3269008385237826

Epoch: 6| Step: 2
Training loss: 2.405362129211426
Validation loss: 2.349151090909076

Epoch: 6| Step: 3
Training loss: 2.7280075550079346
Validation loss: 2.3679746812389744

Epoch: 6| Step: 4
Training loss: 2.881441831588745
Validation loss: 2.36454874725752

Epoch: 6| Step: 5
Training loss: 2.7123570442199707
Validation loss: 2.368433484467127

Epoch: 6| Step: 6
Training loss: 2.7585339546203613
Validation loss: 2.352955792539863

Epoch: 6| Step: 7
Training loss: 2.53450345993042
Validation loss: 2.3395120328472507

Epoch: 6| Step: 8
Training loss: 2.490644693374634
Validation loss: 2.344615231278122

Epoch: 6| Step: 9
Training loss: 2.441657304763794
Validation loss: 2.3495188938674105

Epoch: 6| Step: 10
Training loss: 3.005181312561035
Validation loss: 2.3491311970577446

Epoch: 6| Step: 11
Training loss: 1.99858558177948
Validation loss: 2.341203679320633

Epoch: 6| Step: 12
Training loss: 2.678971767425537
Validation loss: 2.3377009617385043

Epoch: 6| Step: 13
Training loss: 2.321812868118286
Validation loss: 2.3336066802342734

Epoch: 35| Step: 0
Training loss: 2.510603904724121
Validation loss: 2.3397507026631343

Epoch: 6| Step: 1
Training loss: 2.373105525970459
Validation loss: 2.343451661448325

Epoch: 6| Step: 2
Training loss: 2.9860587120056152
Validation loss: 2.3485111062244703

Epoch: 6| Step: 3
Training loss: 2.4662764072418213
Validation loss: 2.3512464710461196

Epoch: 6| Step: 4
Training loss: 2.68597412109375
Validation loss: 2.348409911637665

Epoch: 6| Step: 5
Training loss: 2.4686386585235596
Validation loss: 2.3377803884526736

Epoch: 6| Step: 6
Training loss: 2.516852378845215
Validation loss: 2.3229598024839997

Epoch: 6| Step: 7
Training loss: 3.2564187049865723
Validation loss: 2.3179828992453952

Epoch: 6| Step: 8
Training loss: 2.719266176223755
Validation loss: 2.3027178369542605

Epoch: 6| Step: 9
Training loss: 2.937382221221924
Validation loss: 2.28773239351088

Epoch: 6| Step: 10
Training loss: 1.9576611518859863
Validation loss: 2.277435823153424

Epoch: 6| Step: 11
Training loss: 1.9864578247070312
Validation loss: 2.261685455999067

Epoch: 6| Step: 12
Training loss: 2.77726149559021
Validation loss: 2.25697462789474

Epoch: 6| Step: 13
Training loss: 2.554680109024048
Validation loss: 2.2557817735979633

Epoch: 36| Step: 0
Training loss: 2.5862276554107666
Validation loss: 2.254196810465987

Epoch: 6| Step: 1
Training loss: 2.2493059635162354
Validation loss: 2.2662729909343104

Epoch: 6| Step: 2
Training loss: 2.591845989227295
Validation loss: 2.27681109469424

Epoch: 6| Step: 3
Training loss: 2.1702589988708496
Validation loss: 2.2837317528263217

Epoch: 6| Step: 4
Training loss: 2.5934972763061523
Validation loss: 2.284816175378779

Epoch: 6| Step: 5
Training loss: 1.892593264579773
Validation loss: 2.265781000096311

Epoch: 6| Step: 6
Training loss: 2.525629997253418
Validation loss: 2.2493492121337564

Epoch: 6| Step: 7
Training loss: 3.0763652324676514
Validation loss: 2.242593626822195

Epoch: 6| Step: 8
Training loss: 2.7082619667053223
Validation loss: 2.2273585129809637

Epoch: 6| Step: 9
Training loss: 1.9362963438034058
Validation loss: 2.2123797914033294

Epoch: 6| Step: 10
Training loss: 3.593911647796631
Validation loss: 2.209947575805008

Epoch: 6| Step: 11
Training loss: 2.163151979446411
Validation loss: 2.1976598783205916

Epoch: 6| Step: 12
Training loss: 2.80825138092041
Validation loss: 2.1919559894069547

Epoch: 6| Step: 13
Training loss: 2.7663471698760986
Validation loss: 2.193804120504728

Epoch: 37| Step: 0
Training loss: 2.8881747722625732
Validation loss: 2.1981577975775606

Epoch: 6| Step: 1
Training loss: 2.7645263671875
Validation loss: 2.1984810303616267

Epoch: 6| Step: 2
Training loss: 1.7571380138397217
Validation loss: 2.2002571808394564

Epoch: 6| Step: 3
Training loss: 3.0500757694244385
Validation loss: 2.1986345706447477

Epoch: 6| Step: 4
Training loss: 1.8918111324310303
Validation loss: 2.1993582607597433

Epoch: 6| Step: 5
Training loss: 1.7022874355316162
Validation loss: 2.2267268216738136

Epoch: 6| Step: 6
Training loss: 2.2752387523651123
Validation loss: 2.2292986185319963

Epoch: 6| Step: 7
Training loss: 2.845681667327881
Validation loss: 2.211854229691208

Epoch: 6| Step: 8
Training loss: 2.3994696140289307
Validation loss: 2.2002908401591803

Epoch: 6| Step: 9
Training loss: 3.0124218463897705
Validation loss: 2.2042180492031958

Epoch: 6| Step: 10
Training loss: 2.3806116580963135
Validation loss: 2.194767088018438

Epoch: 6| Step: 11
Training loss: 2.8414039611816406
Validation loss: 2.1903620458418325

Epoch: 6| Step: 12
Training loss: 3.090761423110962
Validation loss: 2.1936420676528767

Epoch: 6| Step: 13
Training loss: 2.542815685272217
Validation loss: 2.184846983161024

Epoch: 38| Step: 0
Training loss: 2.459784984588623
Validation loss: 2.1830010439759944

Epoch: 6| Step: 1
Training loss: 2.2555997371673584
Validation loss: 2.1906561466955368

Epoch: 6| Step: 2
Training loss: 2.339182138442993
Validation loss: 2.193068794024888

Epoch: 6| Step: 3
Training loss: 3.162135124206543
Validation loss: 2.198974196628858

Epoch: 6| Step: 4
Training loss: 2.994840383529663
Validation loss: 2.198657968992828

Epoch: 6| Step: 5
Training loss: 3.3192381858825684
Validation loss: 2.216610224016251

Epoch: 6| Step: 6
Training loss: 2.58052134513855
Validation loss: 2.2180789747545795

Epoch: 6| Step: 7
Training loss: 2.529911756515503
Validation loss: 2.205767760994614

Epoch: 6| Step: 8
Training loss: 1.862769603729248
Validation loss: 2.1962611893171906

Epoch: 6| Step: 9
Training loss: 1.9196250438690186
Validation loss: 2.183516643380606

Epoch: 6| Step: 10
Training loss: 2.9366376399993896
Validation loss: 2.1786904668295257

Epoch: 6| Step: 11
Training loss: 2.0806691646575928
Validation loss: 2.1768417460944063

Epoch: 6| Step: 12
Training loss: 2.2366414070129395
Validation loss: 2.1747065846638014

Epoch: 6| Step: 13
Training loss: 2.6857824325561523
Validation loss: 2.17526811938132

Epoch: 39| Step: 0
Training loss: 2.6625263690948486
Validation loss: 2.1752370865114274

Epoch: 6| Step: 1
Training loss: 2.0646305084228516
Validation loss: 2.184272545640187

Epoch: 6| Step: 2
Training loss: 2.337459087371826
Validation loss: 2.203217326953847

Epoch: 6| Step: 3
Training loss: 3.5437655448913574
Validation loss: 2.2189237738168366

Epoch: 6| Step: 4
Training loss: 2.0111653804779053
Validation loss: 2.219691471386981

Epoch: 6| Step: 5
Training loss: 2.6504883766174316
Validation loss: 2.232275083500852

Epoch: 6| Step: 6
Training loss: 2.444446086883545
Validation loss: 2.2368931949779554

Epoch: 6| Step: 7
Training loss: 2.5663976669311523
Validation loss: 2.2436183434660717

Epoch: 6| Step: 8
Training loss: 2.50327730178833
Validation loss: 2.2460612738004295

Epoch: 6| Step: 9
Training loss: 3.0436558723449707
Validation loss: 2.2471881656236548

Epoch: 6| Step: 10
Training loss: 2.2687323093414307
Validation loss: 2.2421872282540924

Epoch: 6| Step: 11
Training loss: 2.8530795574188232
Validation loss: 2.222009861341087

Epoch: 6| Step: 12
Training loss: 1.8819559812545776
Validation loss: 2.2027961131065124

Epoch: 6| Step: 13
Training loss: 2.2916784286499023
Validation loss: 2.2093974723610827

Epoch: 40| Step: 0
Training loss: 2.4363765716552734
Validation loss: 2.2101720302335677

Epoch: 6| Step: 1
Training loss: 2.5273561477661133
Validation loss: 2.235575963092107

Epoch: 6| Step: 2
Training loss: 2.650033950805664
Validation loss: 2.2583711736945697

Epoch: 6| Step: 3
Training loss: 2.738826036453247
Validation loss: 2.2731134430054696

Epoch: 6| Step: 4
Training loss: 2.095026731491089
Validation loss: 2.265890949515886

Epoch: 6| Step: 5
Training loss: 1.7710545063018799
Validation loss: 2.256784249377507

Epoch: 6| Step: 6
Training loss: 2.847074508666992
Validation loss: 2.2282103389822026

Epoch: 6| Step: 7
Training loss: 2.360987663269043
Validation loss: 2.203749933550435

Epoch: 6| Step: 8
Training loss: 2.8049442768096924
Validation loss: 2.1926763634527884

Epoch: 6| Step: 9
Training loss: 2.6789488792419434
Validation loss: 2.224660247884771

Epoch: 6| Step: 10
Training loss: 2.456333637237549
Validation loss: 2.245785995196271

Epoch: 6| Step: 11
Training loss: 2.634589433670044
Validation loss: 2.2534324123013403

Epoch: 6| Step: 12
Training loss: 3.137941598892212
Validation loss: 2.263058308632143

Epoch: 6| Step: 13
Training loss: 2.633509635925293
Validation loss: 2.2645070655371553

Epoch: 41| Step: 0
Training loss: 2.4712390899658203
Validation loss: 2.2522999419960925

Epoch: 6| Step: 1
Training loss: 2.727271556854248
Validation loss: 2.2511316089219946

Epoch: 6| Step: 2
Training loss: 2.9702394008636475
Validation loss: 2.2262199463382846

Epoch: 6| Step: 3
Training loss: 2.588716506958008
Validation loss: 2.20764131956203

Epoch: 6| Step: 4
Training loss: 2.103275775909424
Validation loss: 2.1931341386610463

Epoch: 6| Step: 5
Training loss: 2.642918109893799
Validation loss: 2.1923240948748846

Epoch: 6| Step: 6
Training loss: 2.7543013095855713
Validation loss: 2.1991886579862205

Epoch: 6| Step: 7
Training loss: 2.552126407623291
Validation loss: 2.2222725345242407

Epoch: 6| Step: 8
Training loss: 2.828461170196533
Validation loss: 2.20836313052844

Epoch: 6| Step: 9
Training loss: 2.559755802154541
Validation loss: 2.2261802227266374

Epoch: 6| Step: 10
Training loss: 1.870681881904602
Validation loss: 2.2414109040332097

Epoch: 6| Step: 11
Training loss: 2.8226423263549805
Validation loss: 2.251859995626634

Epoch: 6| Step: 12
Training loss: 2.3208446502685547
Validation loss: 2.2747509325704267

Epoch: 6| Step: 13
Training loss: 2.145231008529663
Validation loss: 2.312658509900493

Epoch: 42| Step: 0
Training loss: 2.1949026584625244
Validation loss: 2.2481186543741534

Epoch: 6| Step: 1
Training loss: 2.5519490242004395
Validation loss: 2.199292205995129

Epoch: 6| Step: 2
Training loss: 3.263899803161621
Validation loss: 2.171145495548043

Epoch: 6| Step: 3
Training loss: 2.7958474159240723
Validation loss: 2.1750832885824223

Epoch: 6| Step: 4
Training loss: 2.5630745887756348
Validation loss: 2.1737260408298944

Epoch: 6| Step: 5
Training loss: 2.217453956604004
Validation loss: 2.181382413833372

Epoch: 6| Step: 6
Training loss: 2.0316123962402344
Validation loss: 2.2075659331455024

Epoch: 6| Step: 7
Training loss: 1.8210687637329102
Validation loss: 2.218538917520995

Epoch: 6| Step: 8
Training loss: 2.5843684673309326
Validation loss: 2.256800202913182

Epoch: 6| Step: 9
Training loss: 2.3518874645233154
Validation loss: 2.2195485984125445

Epoch: 6| Step: 10
Training loss: 2.881929397583008
Validation loss: 2.1821295420328775

Epoch: 6| Step: 11
Training loss: 2.645378351211548
Validation loss: 2.174757642130698

Epoch: 6| Step: 12
Training loss: 2.458488702774048
Validation loss: 2.1721046329826437

Epoch: 6| Step: 13
Training loss: 3.734262228012085
Validation loss: 2.176644955911944

Epoch: 43| Step: 0
Training loss: 2.157395601272583
Validation loss: 2.1792061149433093

Epoch: 6| Step: 1
Training loss: 3.2302448749542236
Validation loss: 2.1853899443021385

Epoch: 6| Step: 2
Training loss: 2.331517457962036
Validation loss: 2.1866083427142073

Epoch: 6| Step: 3
Training loss: 2.8751087188720703
Validation loss: 2.180869371660294

Epoch: 6| Step: 4
Training loss: 2.4238882064819336
Validation loss: 2.172673145929972

Epoch: 6| Step: 5
Training loss: 1.9181361198425293
Validation loss: 2.1755677346260316

Epoch: 6| Step: 6
Training loss: 2.584571361541748
Validation loss: 2.17571601816403

Epoch: 6| Step: 7
Training loss: 1.6608617305755615
Validation loss: 2.1845177219760035

Epoch: 6| Step: 8
Training loss: 3.204562187194824
Validation loss: 2.2024570806052095

Epoch: 6| Step: 9
Training loss: 2.552100658416748
Validation loss: 2.2228178606238416

Epoch: 6| Step: 10
Training loss: 3.4191224575042725
Validation loss: 2.2498305382267123

Epoch: 6| Step: 11
Training loss: 2.676893711090088
Validation loss: 2.2595081995892268

Epoch: 6| Step: 12
Training loss: 1.722886562347412
Validation loss: 2.2696850735654115

Epoch: 6| Step: 13
Training loss: 2.257452964782715
Validation loss: 2.2568895483529694

Epoch: 44| Step: 0
Training loss: 2.3645782470703125
Validation loss: 2.2612964158417075

Epoch: 6| Step: 1
Training loss: 2.5974204540252686
Validation loss: 2.232005662815545

Epoch: 6| Step: 2
Training loss: 2.35878849029541
Validation loss: 2.171822711985598

Epoch: 6| Step: 3
Training loss: 2.8289833068847656
Validation loss: 2.1451174725768385

Epoch: 6| Step: 4
Training loss: 1.9985485076904297
Validation loss: 2.1339316598830687

Epoch: 6| Step: 5
Training loss: 3.1772451400756836
Validation loss: 2.140901844988587

Epoch: 6| Step: 6
Training loss: 2.1768734455108643
Validation loss: 2.139586535833215

Epoch: 6| Step: 7
Training loss: 2.4905588626861572
Validation loss: 2.145522379106091

Epoch: 6| Step: 8
Training loss: 2.624507427215576
Validation loss: 2.1493914037622432

Epoch: 6| Step: 9
Training loss: 3.126375198364258
Validation loss: 2.1583359600395284

Epoch: 6| Step: 10
Training loss: 2.4104480743408203
Validation loss: 2.163120408211985

Epoch: 6| Step: 11
Training loss: 2.106964111328125
Validation loss: 2.1828233144616567

Epoch: 6| Step: 12
Training loss: 2.5239691734313965
Validation loss: 2.2113938626422676

Epoch: 6| Step: 13
Training loss: 2.449345350265503
Validation loss: 2.221265930001454

Epoch: 45| Step: 0
Training loss: 2.877103805541992
Validation loss: 2.2437077722241803

Epoch: 6| Step: 1
Training loss: 2.0787320137023926
Validation loss: 2.2358722866222425

Epoch: 6| Step: 2
Training loss: 2.6513209342956543
Validation loss: 2.2377535950753

Epoch: 6| Step: 3
Training loss: 2.433485984802246
Validation loss: 2.2293501746269966

Epoch: 6| Step: 4
Training loss: 2.793785333633423
Validation loss: 2.226688910556096

Epoch: 6| Step: 5
Training loss: 2.673358678817749
Validation loss: 2.2169443048456663

Epoch: 6| Step: 6
Training loss: 1.7862372398376465
Validation loss: 2.2153651329778854

Epoch: 6| Step: 7
Training loss: 2.862187147140503
Validation loss: 2.216013364894416

Epoch: 6| Step: 8
Training loss: 3.0632123947143555
Validation loss: 2.215090213283416

Epoch: 6| Step: 9
Training loss: 1.9821529388427734
Validation loss: 2.2019470994190504

Epoch: 6| Step: 10
Training loss: 2.362149715423584
Validation loss: 2.1965950304462063

Epoch: 6| Step: 11
Training loss: 2.7219502925872803
Validation loss: 2.2023004588260444

Epoch: 6| Step: 12
Training loss: 2.7464513778686523
Validation loss: 2.203512345590899

Epoch: 6| Step: 13
Training loss: 1.9702227115631104
Validation loss: 2.196253425331526

Epoch: 46| Step: 0
Training loss: 1.9291470050811768
Validation loss: 2.2015778069855063

Epoch: 6| Step: 1
Training loss: 2.462900161743164
Validation loss: 2.199517975571335

Epoch: 6| Step: 2
Training loss: 2.841007947921753
Validation loss: 2.2114738854028846

Epoch: 6| Step: 3
Training loss: 2.473970890045166
Validation loss: 2.2055613892052763

Epoch: 6| Step: 4
Training loss: 1.9149737358093262
Validation loss: 2.193645311940101

Epoch: 6| Step: 5
Training loss: 2.7444422245025635
Validation loss: 2.1919135919181247

Epoch: 6| Step: 6
Training loss: 2.924811601638794
Validation loss: 2.194346497135778

Epoch: 6| Step: 7
Training loss: 3.2284626960754395
Validation loss: 2.1816980518320555

Epoch: 6| Step: 8
Training loss: 2.4054665565490723
Validation loss: 2.1733572508699153

Epoch: 6| Step: 9
Training loss: 2.125135898590088
Validation loss: 2.1833030293064732

Epoch: 6| Step: 10
Training loss: 2.6612510681152344
Validation loss: 2.1997403508873394

Epoch: 6| Step: 11
Training loss: 2.847424030303955
Validation loss: 2.222273143388892

Epoch: 6| Step: 12
Training loss: 2.507652997970581
Validation loss: 2.2500377316628732

Epoch: 6| Step: 13
Training loss: 1.5796183347702026
Validation loss: 2.2312487222815074

Epoch: 47| Step: 0
Training loss: 3.3920364379882812
Validation loss: 2.2032471369671565

Epoch: 6| Step: 1
Training loss: 2.277769088745117
Validation loss: 2.1698348983641593

Epoch: 6| Step: 2
Training loss: 2.570739269256592
Validation loss: 2.162752100216445

Epoch: 6| Step: 3
Training loss: 2.349207878112793
Validation loss: 2.164596575562672

Epoch: 6| Step: 4
Training loss: 1.848846197128296
Validation loss: 2.16816819355052

Epoch: 6| Step: 5
Training loss: 2.315186023712158
Validation loss: 2.16602603338098

Epoch: 6| Step: 6
Training loss: 2.94979190826416
Validation loss: 2.157405294397826

Epoch: 6| Step: 7
Training loss: 2.720487117767334
Validation loss: 2.1581014330669115

Epoch: 6| Step: 8
Training loss: 2.0395123958587646
Validation loss: 2.14536944384216

Epoch: 6| Step: 9
Training loss: 2.1923253536224365
Validation loss: 2.143051270515688

Epoch: 6| Step: 10
Training loss: 1.9363996982574463
Validation loss: 2.134634082035352

Epoch: 6| Step: 11
Training loss: 2.8727734088897705
Validation loss: 2.130169906923848

Epoch: 6| Step: 12
Training loss: 2.6870341300964355
Validation loss: 2.1321769529773342

Epoch: 6| Step: 13
Training loss: 3.252864360809326
Validation loss: 2.150754410733459

Epoch: 48| Step: 0
Training loss: 2.8119559288024902
Validation loss: 2.1486240112653343

Epoch: 6| Step: 1
Training loss: 2.920689582824707
Validation loss: 2.1524034751358854

Epoch: 6| Step: 2
Training loss: 2.7338032722473145
Validation loss: 2.1747104621702626

Epoch: 6| Step: 3
Training loss: 2.5707149505615234
Validation loss: 2.192660931617983

Epoch: 6| Step: 4
Training loss: 2.478081226348877
Validation loss: 2.2444003346145793

Epoch: 6| Step: 5
Training loss: 2.93831729888916
Validation loss: 2.240730586872306

Epoch: 6| Step: 6
Training loss: 2.627281665802002
Validation loss: 2.240687926610311

Epoch: 6| Step: 7
Training loss: 2.0018832683563232
Validation loss: 2.246112310758201

Epoch: 6| Step: 8
Training loss: 2.600803852081299
Validation loss: 2.2576700692535727

Epoch: 6| Step: 9
Training loss: 2.23166561126709
Validation loss: 2.2509263971800446

Epoch: 6| Step: 10
Training loss: 1.8809287548065186
Validation loss: 2.2358588813453593

Epoch: 6| Step: 11
Training loss: 2.0935206413269043
Validation loss: 2.2116050745851252

Epoch: 6| Step: 12
Training loss: 2.990642786026001
Validation loss: 2.1864356584446405

Epoch: 6| Step: 13
Training loss: 2.097414493560791
Validation loss: 2.175559800158265

Epoch: 49| Step: 0
Training loss: 1.9677543640136719
Validation loss: 2.1524457341881207

Epoch: 6| Step: 1
Training loss: 2.3744049072265625
Validation loss: 2.1515314040645475

Epoch: 6| Step: 2
Training loss: 2.6515936851501465
Validation loss: 2.1492995626182965

Epoch: 6| Step: 3
Training loss: 2.9407238960266113
Validation loss: 2.14855718869035

Epoch: 6| Step: 4
Training loss: 1.9293456077575684
Validation loss: 2.1458616641259964

Epoch: 6| Step: 5
Training loss: 2.0168309211730957
Validation loss: 2.162253543894778

Epoch: 6| Step: 6
Training loss: 2.8035340309143066
Validation loss: 2.179713732452803

Epoch: 6| Step: 7
Training loss: 2.622466564178467
Validation loss: 2.1796436963542813

Epoch: 6| Step: 8
Training loss: 2.223454236984253
Validation loss: 2.1877434445965673

Epoch: 6| Step: 9
Training loss: 2.455656051635742
Validation loss: 2.1949780397517706

Epoch: 6| Step: 10
Training loss: 2.4286375045776367
Validation loss: 2.172191322490733

Epoch: 6| Step: 11
Training loss: 2.7000532150268555
Validation loss: 2.1813574837100123

Epoch: 6| Step: 12
Training loss: 2.631537914276123
Validation loss: 2.174751122792562

Epoch: 6| Step: 13
Training loss: 3.2986631393432617
Validation loss: 2.1801149050394693

Epoch: 50| Step: 0
Training loss: 2.7465336322784424
Validation loss: 2.1773418508550173

Epoch: 6| Step: 1
Training loss: 2.1932497024536133
Validation loss: 2.161022586207236

Epoch: 6| Step: 2
Training loss: 1.7401129007339478
Validation loss: 2.1595471700032554

Epoch: 6| Step: 3
Training loss: 2.087127685546875
Validation loss: 2.166060327201761

Epoch: 6| Step: 4
Training loss: 2.7057437896728516
Validation loss: 2.167955211413804

Epoch: 6| Step: 5
Training loss: 2.3747401237487793
Validation loss: 2.188200168712165

Epoch: 6| Step: 6
Training loss: 2.5526814460754395
Validation loss: 2.171283837287657

Epoch: 6| Step: 7
Training loss: 3.1502649784088135
Validation loss: 2.1540109547235633

Epoch: 6| Step: 8
Training loss: 2.0504159927368164
Validation loss: 2.1212552862782634

Epoch: 6| Step: 9
Training loss: 2.875194549560547
Validation loss: 2.094546964091639

Epoch: 6| Step: 10
Training loss: 2.1327168941497803
Validation loss: 2.0962785341406382

Epoch: 6| Step: 11
Training loss: 3.0596702098846436
Validation loss: 2.0942426125208535

Epoch: 6| Step: 12
Training loss: 2.3034439086914062
Validation loss: 2.0869365020464827

Epoch: 6| Step: 13
Training loss: 2.483429431915283
Validation loss: 2.0879713219981038

Epoch: 51| Step: 0
Training loss: 1.8349164724349976
Validation loss: 2.098032864191199

Epoch: 6| Step: 1
Training loss: 2.2521190643310547
Validation loss: 2.118601293974025

Epoch: 6| Step: 2
Training loss: 2.822641372680664
Validation loss: 2.1420877146464523

Epoch: 6| Step: 3
Training loss: 1.7709108591079712
Validation loss: 2.185109688389686

Epoch: 6| Step: 4
Training loss: 2.883847236633301
Validation loss: 2.2319489730301725

Epoch: 6| Step: 5
Training loss: 2.4445903301239014
Validation loss: 2.2535227960155857

Epoch: 6| Step: 6
Training loss: 3.0855798721313477
Validation loss: 2.2628073077048025

Epoch: 6| Step: 7
Training loss: 3.0024328231811523
Validation loss: 2.2113681480448735

Epoch: 6| Step: 8
Training loss: 2.547064781188965
Validation loss: 2.155852012736823

Epoch: 6| Step: 9
Training loss: 2.7353591918945312
Validation loss: 2.1336338699504895

Epoch: 6| Step: 10
Training loss: 1.9632701873779297
Validation loss: 2.100091129220942

Epoch: 6| Step: 11
Training loss: 2.6925878524780273
Validation loss: 2.0856568569778116

Epoch: 6| Step: 12
Training loss: 1.9966267347335815
Validation loss: 2.074792669665429

Epoch: 6| Step: 13
Training loss: 2.322669744491577
Validation loss: 2.0905767128031743

Epoch: 52| Step: 0
Training loss: 2.295806407928467
Validation loss: 2.092643674983773

Epoch: 6| Step: 1
Training loss: 2.2014384269714355
Validation loss: 2.103642245774628

Epoch: 6| Step: 2
Training loss: 3.1447336673736572
Validation loss: 2.108146366252694

Epoch: 6| Step: 3
Training loss: 2.558610439300537
Validation loss: 2.105442841847738

Epoch: 6| Step: 4
Training loss: 2.7213144302368164
Validation loss: 2.105539637227212

Epoch: 6| Step: 5
Training loss: 2.075148105621338
Validation loss: 2.1011878675030125

Epoch: 6| Step: 6
Training loss: 2.452087879180908
Validation loss: 2.092755115160378

Epoch: 6| Step: 7
Training loss: 2.6395010948181152
Validation loss: 2.096236055897128

Epoch: 6| Step: 8
Training loss: 2.639812707901001
Validation loss: 2.0948089425281813

Epoch: 6| Step: 9
Training loss: 2.298581600189209
Validation loss: 2.1080075310122584

Epoch: 6| Step: 10
Training loss: 2.572564125061035
Validation loss: 2.1236240376708326

Epoch: 6| Step: 11
Training loss: 1.7617748975753784
Validation loss: 2.1361814596319713

Epoch: 6| Step: 12
Training loss: 3.5005922317504883
Validation loss: 2.1851503131210164

Epoch: 6| Step: 13
Training loss: 1.7948201894760132
Validation loss: 2.1741216080163115

Epoch: 53| Step: 0
Training loss: 2.3325982093811035
Validation loss: 2.1747082715393393

Epoch: 6| Step: 1
Training loss: 1.9390695095062256
Validation loss: 2.1726013409194125

Epoch: 6| Step: 2
Training loss: 2.771869421005249
Validation loss: 2.184766318208428

Epoch: 6| Step: 3
Training loss: 2.463958740234375
Validation loss: 2.204601651878767

Epoch: 6| Step: 4
Training loss: 2.807382822036743
Validation loss: 2.2001011730522237

Epoch: 6| Step: 5
Training loss: 2.7232582569122314
Validation loss: 2.182246838846514

Epoch: 6| Step: 6
Training loss: 2.0016489028930664
Validation loss: 2.1523901031863306

Epoch: 6| Step: 7
Training loss: 2.784480094909668
Validation loss: 2.1549873480232815

Epoch: 6| Step: 8
Training loss: 2.7234508991241455
Validation loss: 2.1526004499004734

Epoch: 6| Step: 9
Training loss: 2.7855591773986816
Validation loss: 2.1307551604445263

Epoch: 6| Step: 10
Training loss: 2.343268871307373
Validation loss: 2.115093832374901

Epoch: 6| Step: 11
Training loss: 1.5179316997528076
Validation loss: 2.102776760696083

Epoch: 6| Step: 12
Training loss: 2.7771010398864746
Validation loss: 2.0907904922321277

Epoch: 6| Step: 13
Training loss: 2.5559680461883545
Validation loss: 2.0896803896914244

Epoch: 54| Step: 0
Training loss: 2.1209726333618164
Validation loss: 2.0802202468277304

Epoch: 6| Step: 1
Training loss: 2.217160701751709
Validation loss: 2.0738331297392487

Epoch: 6| Step: 2
Training loss: 2.3452553749084473
Validation loss: 2.076895883006434

Epoch: 6| Step: 3
Training loss: 1.9947772026062012
Validation loss: 2.0808308444997317

Epoch: 6| Step: 4
Training loss: 2.2700917720794678
Validation loss: 2.099953979574224

Epoch: 6| Step: 5
Training loss: 2.2201285362243652
Validation loss: 2.119670009100309

Epoch: 6| Step: 6
Training loss: 1.9443475008010864
Validation loss: 2.144100753209924

Epoch: 6| Step: 7
Training loss: 1.9148807525634766
Validation loss: 2.141530518890709

Epoch: 6| Step: 8
Training loss: 2.4945952892303467
Validation loss: 2.155707831023842

Epoch: 6| Step: 9
Training loss: 2.6490683555603027
Validation loss: 2.1929240816382953

Epoch: 6| Step: 10
Training loss: 3.0088605880737305
Validation loss: 2.222130475505706

Epoch: 6| Step: 11
Training loss: 3.6834330558776855
Validation loss: 2.223492419847878

Epoch: 6| Step: 12
Training loss: 2.7546744346618652
Validation loss: 2.2128976263025755

Epoch: 6| Step: 13
Training loss: 3.2061173915863037
Validation loss: 2.204372990515924

Epoch: 55| Step: 0
Training loss: 2.7663469314575195
Validation loss: 2.189788205649263

Epoch: 6| Step: 1
Training loss: 1.6842334270477295
Validation loss: 2.1639644356184107

Epoch: 6| Step: 2
Training loss: 2.4380970001220703
Validation loss: 2.132617355674826

Epoch: 6| Step: 3
Training loss: 2.3728222846984863
Validation loss: 2.110544353403071

Epoch: 6| Step: 4
Training loss: 3.892599105834961
Validation loss: 2.1074894218034643

Epoch: 6| Step: 5
Training loss: 2.0301387310028076
Validation loss: 2.101849866169755

Epoch: 6| Step: 6
Training loss: 2.7346253395080566
Validation loss: 2.0945204650202105

Epoch: 6| Step: 7
Training loss: 2.3940396308898926
Validation loss: 2.064308351086032

Epoch: 6| Step: 8
Training loss: 2.0688633918762207
Validation loss: 2.055322249730428

Epoch: 6| Step: 9
Training loss: 2.1295762062072754
Validation loss: 2.0489467715704315

Epoch: 6| Step: 10
Training loss: 2.105435848236084
Validation loss: 2.050798898102135

Epoch: 6| Step: 11
Training loss: 2.4804320335388184
Validation loss: 2.051206777172704

Epoch: 6| Step: 12
Training loss: 3.0190300941467285
Validation loss: 2.0523312937828804

Epoch: 6| Step: 13
Training loss: 2.351201295852661
Validation loss: 2.058065696429181

Epoch: 56| Step: 0
Training loss: 3.1887927055358887
Validation loss: 2.057338527453843

Epoch: 6| Step: 1
Training loss: 3.0134999752044678
Validation loss: 2.0597128791193806

Epoch: 6| Step: 2
Training loss: 2.3139469623565674
Validation loss: 2.06096399471324

Epoch: 6| Step: 3
Training loss: 2.6226110458374023
Validation loss: 2.067034613701605

Epoch: 6| Step: 4
Training loss: 3.0779471397399902
Validation loss: 2.067853428984201

Epoch: 6| Step: 5
Training loss: 2.060699224472046
Validation loss: 2.0658889252652406

Epoch: 6| Step: 6
Training loss: 2.1742405891418457
Validation loss: 2.0772953597448205

Epoch: 6| Step: 7
Training loss: 1.6567268371582031
Validation loss: 2.069175559987304

Epoch: 6| Step: 8
Training loss: 2.486767292022705
Validation loss: 2.079421204905356

Epoch: 6| Step: 9
Training loss: 2.19571852684021
Validation loss: 2.076040949872745

Epoch: 6| Step: 10
Training loss: 2.8177871704101562
Validation loss: 2.0938606685207737

Epoch: 6| Step: 11
Training loss: 1.7307897806167603
Validation loss: 2.103925411419202

Epoch: 6| Step: 12
Training loss: 2.2355360984802246
Validation loss: 2.1177086881411973

Epoch: 6| Step: 13
Training loss: 2.481213092803955
Validation loss: 2.1070961183117283

Epoch: 57| Step: 0
Training loss: 2.6069164276123047
Validation loss: 2.125512166689801

Epoch: 6| Step: 1
Training loss: 2.864515781402588
Validation loss: 2.1345678657613774

Epoch: 6| Step: 2
Training loss: 2.4140377044677734
Validation loss: 2.147833164020251

Epoch: 6| Step: 3
Training loss: 1.8152416944503784
Validation loss: 2.1518177165780017

Epoch: 6| Step: 4
Training loss: 2.5914573669433594
Validation loss: 2.155752012806554

Epoch: 6| Step: 5
Training loss: 1.997687578201294
Validation loss: 2.150024280753187

Epoch: 6| Step: 6
Training loss: 2.0647435188293457
Validation loss: 2.1387421956626316

Epoch: 6| Step: 7
Training loss: 3.2170026302337646
Validation loss: 2.138343882817094

Epoch: 6| Step: 8
Training loss: 2.09940767288208
Validation loss: 2.1181253463991228

Epoch: 6| Step: 9
Training loss: 2.2808573246002197
Validation loss: 2.0979152699952484

Epoch: 6| Step: 10
Training loss: 2.562549114227295
Validation loss: 2.0811407489161335

Epoch: 6| Step: 11
Training loss: 2.0786824226379395
Validation loss: 2.0751214258132444

Epoch: 6| Step: 12
Training loss: 2.55946683883667
Validation loss: 2.070976347051641

Epoch: 6| Step: 13
Training loss: 3.0128674507141113
Validation loss: 2.0681769745324248

Epoch: 58| Step: 0
Training loss: 3.057270050048828
Validation loss: 2.0605876445770264

Epoch: 6| Step: 1
Training loss: 2.4894347190856934
Validation loss: 2.064296181483935

Epoch: 6| Step: 2
Training loss: 2.854807138442993
Validation loss: 2.0676424862236105

Epoch: 6| Step: 3
Training loss: 2.760666608810425
Validation loss: 2.0635452757599535

Epoch: 6| Step: 4
Training loss: 2.801964282989502
Validation loss: 2.0653266778556247

Epoch: 6| Step: 5
Training loss: 1.734654426574707
Validation loss: 2.069195580738847

Epoch: 6| Step: 6
Training loss: 1.5921907424926758
Validation loss: 2.069694293442593

Epoch: 6| Step: 7
Training loss: 1.9117045402526855
Validation loss: 2.071727632194437

Epoch: 6| Step: 8
Training loss: 1.4105467796325684
Validation loss: 2.090092799996817

Epoch: 6| Step: 9
Training loss: 3.0272068977355957
Validation loss: 2.0950814395822506

Epoch: 6| Step: 10
Training loss: 3.0878443717956543
Validation loss: 2.113021319912326

Epoch: 6| Step: 11
Training loss: 2.2876415252685547
Validation loss: 2.0968516526683683

Epoch: 6| Step: 12
Training loss: 2.2147207260131836
Validation loss: 2.0928855544777325

Epoch: 6| Step: 13
Training loss: 2.4680585861206055
Validation loss: 2.0921460761818835

Epoch: 59| Step: 0
Training loss: 2.4074316024780273
Validation loss: 2.0937441754084762

Epoch: 6| Step: 1
Training loss: 2.214294195175171
Validation loss: 2.090295732662242

Epoch: 6| Step: 2
Training loss: 2.2157795429229736
Validation loss: 2.100136923533614

Epoch: 6| Step: 3
Training loss: 2.7416558265686035
Validation loss: 2.0946888026370796

Epoch: 6| Step: 4
Training loss: 2.5729143619537354
Validation loss: 2.0991599329056276

Epoch: 6| Step: 5
Training loss: 2.694819927215576
Validation loss: 2.1032548732655023

Epoch: 6| Step: 6
Training loss: 2.598459243774414
Validation loss: 2.093599129748601

Epoch: 6| Step: 7
Training loss: 1.7600260972976685
Validation loss: 2.0881660702408

Epoch: 6| Step: 8
Training loss: 2.581165313720703
Validation loss: 2.094929251619565

Epoch: 6| Step: 9
Training loss: 2.054602861404419
Validation loss: 2.1016091890232538

Epoch: 6| Step: 10
Training loss: 2.5243093967437744
Validation loss: 2.1046716038898756

Epoch: 6| Step: 11
Training loss: 2.2078797817230225
Validation loss: 2.116811454937022

Epoch: 6| Step: 12
Training loss: 2.6984915733337402
Validation loss: 2.124766360047043

Epoch: 6| Step: 13
Training loss: 2.459202289581299
Validation loss: 2.139540115992228

Epoch: 60| Step: 0
Training loss: 3.0533008575439453
Validation loss: 2.126778946127943

Epoch: 6| Step: 1
Training loss: 1.9864927530288696
Validation loss: 2.09086174349631

Epoch: 6| Step: 2
Training loss: 2.926243305206299
Validation loss: 2.0953915772899503

Epoch: 6| Step: 3
Training loss: 2.9884257316589355
Validation loss: 2.0769347926621795

Epoch: 6| Step: 4
Training loss: 2.521073579788208
Validation loss: 2.0776785291651243

Epoch: 6| Step: 5
Training loss: 2.5776357650756836
Validation loss: 2.0688833267458024

Epoch: 6| Step: 6
Training loss: 2.1035008430480957
Validation loss: 2.067872239697364

Epoch: 6| Step: 7
Training loss: 2.7179369926452637
Validation loss: 2.065327808421145

Epoch: 6| Step: 8
Training loss: 1.9852232933044434
Validation loss: 2.0697208117413264

Epoch: 6| Step: 9
Training loss: 1.9304699897766113
Validation loss: 2.0526243922530965

Epoch: 6| Step: 10
Training loss: 2.1741576194763184
Validation loss: 2.0351345923639115

Epoch: 6| Step: 11
Training loss: 2.372934341430664
Validation loss: 2.032737713988109

Epoch: 6| Step: 12
Training loss: 2.2746262550354004
Validation loss: 2.0273647051985546

Epoch: 6| Step: 13
Training loss: 1.1574219465255737
Validation loss: 2.0262707074483237

Epoch: 61| Step: 0
Training loss: 2.923978805541992
Validation loss: 2.029040972391764

Epoch: 6| Step: 1
Training loss: 3.074435234069824
Validation loss: 2.0274878548037623

Epoch: 6| Step: 2
Training loss: 2.5503902435302734
Validation loss: 2.0268262996468493

Epoch: 6| Step: 3
Training loss: 3.0401601791381836
Validation loss: 2.024525519340269

Epoch: 6| Step: 4
Training loss: 1.830784797668457
Validation loss: 2.0241871546673518

Epoch: 6| Step: 5
Training loss: 2.770869493484497
Validation loss: 2.030627199398574

Epoch: 6| Step: 6
Training loss: 2.7243993282318115
Validation loss: 2.042334025905978

Epoch: 6| Step: 7
Training loss: 2.6562952995300293
Validation loss: 2.0467825781914497

Epoch: 6| Step: 8
Training loss: 2.0108799934387207
Validation loss: 2.053403604415155

Epoch: 6| Step: 9
Training loss: 2.0562586784362793
Validation loss: 2.0664384365081787

Epoch: 6| Step: 10
Training loss: 1.8586269617080688
Validation loss: 2.06518357030807

Epoch: 6| Step: 11
Training loss: 1.7791922092437744
Validation loss: 2.085763580055647

Epoch: 6| Step: 12
Training loss: 2.1861605644226074
Validation loss: 2.1314984265194146

Epoch: 6| Step: 13
Training loss: 1.4619227647781372
Validation loss: 2.1912112338568575

Epoch: 62| Step: 0
Training loss: 2.774707794189453
Validation loss: 2.2431382979116132

Epoch: 6| Step: 1
Training loss: 2.593787670135498
Validation loss: 2.2926623616167294

Epoch: 6| Step: 2
Training loss: 2.7887558937072754
Validation loss: 2.2033405547500937

Epoch: 6| Step: 3
Training loss: 2.370356559753418
Validation loss: 2.0940829207820277

Epoch: 6| Step: 4
Training loss: 2.0495617389678955
Validation loss: 2.039576047210283

Epoch: 6| Step: 5
Training loss: 1.8811533451080322
Validation loss: 2.026115163680046

Epoch: 6| Step: 6
Training loss: 2.7301928997039795
Validation loss: 2.0279940892291326

Epoch: 6| Step: 7
Training loss: 1.9233832359313965
Validation loss: 2.043628672117828

Epoch: 6| Step: 8
Training loss: 2.525662422180176
Validation loss: 2.0367394583199614

Epoch: 6| Step: 9
Training loss: 3.1707606315612793
Validation loss: 2.0234096716809016

Epoch: 6| Step: 10
Training loss: 2.284687042236328
Validation loss: 2.0183423693462084

Epoch: 6| Step: 11
Training loss: 2.070906162261963
Validation loss: 2.00972609109776

Epoch: 6| Step: 12
Training loss: 2.679450511932373
Validation loss: 2.0060019877649125

Epoch: 6| Step: 13
Training loss: 1.7782092094421387
Validation loss: 2.0020582573388213

Epoch: 63| Step: 0
Training loss: 2.437498092651367
Validation loss: 2.0066981930886545

Epoch: 6| Step: 1
Training loss: 2.672506809234619
Validation loss: 2.0055539056818974

Epoch: 6| Step: 2
Training loss: 2.289417266845703
Validation loss: 2.0051104419974872

Epoch: 6| Step: 3
Training loss: 2.7425661087036133
Validation loss: 2.0064858685257616

Epoch: 6| Step: 4
Training loss: 2.1204001903533936
Validation loss: 2.005108973031403

Epoch: 6| Step: 5
Training loss: 2.8242664337158203
Validation loss: 2.0008770599160144

Epoch: 6| Step: 6
Training loss: 2.612196445465088
Validation loss: 2.0014520819469164

Epoch: 6| Step: 7
Training loss: 2.5436832904815674
Validation loss: 2.0251733256924536

Epoch: 6| Step: 8
Training loss: 2.3680219650268555
Validation loss: 2.031653583690684

Epoch: 6| Step: 9
Training loss: 1.8611252307891846
Validation loss: 2.050183844822709

Epoch: 6| Step: 10
Training loss: 2.6050496101379395
Validation loss: 2.0767246318119827

Epoch: 6| Step: 11
Training loss: 2.089897632598877
Validation loss: 2.1168697521250737

Epoch: 6| Step: 12
Training loss: 2.339545726776123
Validation loss: 2.13116471229061

Epoch: 6| Step: 13
Training loss: 1.5202999114990234
Validation loss: 2.1375007962667816

Epoch: 64| Step: 0
Training loss: 2.6670124530792236
Validation loss: 2.1344704243444625

Epoch: 6| Step: 1
Training loss: 1.7590887546539307
Validation loss: 2.114636969822709

Epoch: 6| Step: 2
Training loss: 2.606560707092285
Validation loss: 2.0811243005978164

Epoch: 6| Step: 3
Training loss: 2.4369523525238037
Validation loss: 2.058245648619949

Epoch: 6| Step: 4
Training loss: 2.1517786979675293
Validation loss: 2.030765171973936

Epoch: 6| Step: 5
Training loss: 2.3683857917785645
Validation loss: 2.0153786238803657

Epoch: 6| Step: 6
Training loss: 2.357292652130127
Validation loss: 1.99789975279121

Epoch: 6| Step: 7
Training loss: 1.6926939487457275
Validation loss: 1.99722929411037

Epoch: 6| Step: 8
Training loss: 2.4572901725769043
Validation loss: 2.003790286279494

Epoch: 6| Step: 9
Training loss: 2.542367935180664
Validation loss: 2.0123845146548365

Epoch: 6| Step: 10
Training loss: 2.3779125213623047
Validation loss: 2.0234573733422065

Epoch: 6| Step: 11
Training loss: 2.8160698413848877
Validation loss: 2.056847390308175

Epoch: 6| Step: 12
Training loss: 2.549776077270508
Validation loss: 2.053172403766263

Epoch: 6| Step: 13
Training loss: 3.3530735969543457
Validation loss: 2.0443573767139065

Epoch: 65| Step: 0
Training loss: 2.614786148071289
Validation loss: 2.0390945685807096

Epoch: 6| Step: 1
Training loss: 2.4802393913269043
Validation loss: 2.034048770063667

Epoch: 6| Step: 2
Training loss: 2.342656135559082
Validation loss: 2.0490744472831808

Epoch: 6| Step: 3
Training loss: 2.5683231353759766
Validation loss: 2.057247172119797

Epoch: 6| Step: 4
Training loss: 2.7170634269714355
Validation loss: 2.071350512966033

Epoch: 6| Step: 5
Training loss: 2.2281551361083984
Validation loss: 2.062616587967001

Epoch: 6| Step: 6
Training loss: 2.2745988368988037
Validation loss: 2.052040615389424

Epoch: 6| Step: 7
Training loss: 2.055771827697754
Validation loss: 2.0436547353703487

Epoch: 6| Step: 8
Training loss: 2.613471031188965
Validation loss: 2.0539096850220875

Epoch: 6| Step: 9
Training loss: 1.7927947044372559
Validation loss: 2.047097753452998

Epoch: 6| Step: 10
Training loss: 2.1058566570281982
Validation loss: 2.0437895726132136

Epoch: 6| Step: 11
Training loss: 2.6423001289367676
Validation loss: 2.0421012063180246

Epoch: 6| Step: 12
Training loss: 2.259481906890869
Validation loss: 2.0413236669314805

Epoch: 6| Step: 13
Training loss: 2.3796589374542236
Validation loss: 2.0220753928666473

Epoch: 66| Step: 0
Training loss: 3.1690802574157715
Validation loss: 2.009480268724503

Epoch: 6| Step: 1
Training loss: 2.0316734313964844
Validation loss: 2.003725536407963

Epoch: 6| Step: 2
Training loss: 2.5879249572753906
Validation loss: 2.009000330842951

Epoch: 6| Step: 3
Training loss: 2.9398245811462402
Validation loss: 2.013044713645853

Epoch: 6| Step: 4
Training loss: 2.1642045974731445
Validation loss: 2.0232706787765666

Epoch: 6| Step: 5
Training loss: 1.7355449199676514
Validation loss: 2.023242906857562

Epoch: 6| Step: 6
Training loss: 2.4524192810058594
Validation loss: 2.0339882630173878

Epoch: 6| Step: 7
Training loss: 2.616502285003662
Validation loss: 2.057857596746055

Epoch: 6| Step: 8
Training loss: 2.1853504180908203
Validation loss: 2.0446720277109454

Epoch: 6| Step: 9
Training loss: 2.091451406478882
Validation loss: 2.0179556415927027

Epoch: 6| Step: 10
Training loss: 2.5497920513153076
Validation loss: 2.00836415701015

Epoch: 6| Step: 11
Training loss: 2.3863649368286133
Validation loss: 2.0149252517248994

Epoch: 6| Step: 12
Training loss: 2.345895528793335
Validation loss: 2.0264708072908464

Epoch: 6| Step: 13
Training loss: 1.5210528373718262
Validation loss: 2.0461660662005023

Epoch: 67| Step: 0
Training loss: 2.9997711181640625
Validation loss: 2.062875199061568

Epoch: 6| Step: 1
Training loss: 2.20243239402771
Validation loss: 2.068580855605423

Epoch: 6| Step: 2
Training loss: 1.5606627464294434
Validation loss: 2.0570991321276595

Epoch: 6| Step: 3
Training loss: 2.9280738830566406
Validation loss: 2.0652579710047734

Epoch: 6| Step: 4
Training loss: 2.6719603538513184
Validation loss: 2.0606462891383837

Epoch: 6| Step: 5
Training loss: 2.1159186363220215
Validation loss: 2.0552791921041345

Epoch: 6| Step: 6
Training loss: 2.394470453262329
Validation loss: 2.0400188212753623

Epoch: 6| Step: 7
Training loss: 2.3220016956329346
Validation loss: 2.0402998026981147

Epoch: 6| Step: 8
Training loss: 2.194316864013672
Validation loss: 2.0376857711422827

Epoch: 6| Step: 9
Training loss: 1.9922490119934082
Validation loss: 2.028881517789697

Epoch: 6| Step: 10
Training loss: 2.2854714393615723
Validation loss: 2.008145493845786

Epoch: 6| Step: 11
Training loss: 2.2540476322174072
Validation loss: 2.0014057672151955

Epoch: 6| Step: 12
Training loss: 2.459198474884033
Validation loss: 1.9963330273987145

Epoch: 6| Step: 13
Training loss: 2.315232992172241
Validation loss: 1.9918594001441874

Epoch: 68| Step: 0
Training loss: 2.33786678314209
Validation loss: 1.9943404684784591

Epoch: 6| Step: 1
Training loss: 2.4228873252868652
Validation loss: 1.9970693101165116

Epoch: 6| Step: 2
Training loss: 2.5594677925109863
Validation loss: 2.0066198341308104

Epoch: 6| Step: 3
Training loss: 2.640634059906006
Validation loss: 2.0134066817581013

Epoch: 6| Step: 4
Training loss: 2.7531542778015137
Validation loss: 2.020089287911692

Epoch: 6| Step: 5
Training loss: 2.636500835418701
Validation loss: 2.007038172855172

Epoch: 6| Step: 6
Training loss: 2.624135971069336
Validation loss: 1.9972389372446204

Epoch: 6| Step: 7
Training loss: 1.8908965587615967
Validation loss: 1.991827041872086

Epoch: 6| Step: 8
Training loss: 2.05972957611084
Validation loss: 1.9958982929106681

Epoch: 6| Step: 9
Training loss: 1.956647276878357
Validation loss: 2.010949137390301

Epoch: 6| Step: 10
Training loss: 2.06117582321167
Validation loss: 2.0281585980487127

Epoch: 6| Step: 11
Training loss: 1.9434939622879028
Validation loss: 2.080498521045972

Epoch: 6| Step: 12
Training loss: 2.5277061462402344
Validation loss: 2.133605143075348

Epoch: 6| Step: 13
Training loss: 2.428734540939331
Validation loss: 2.1858740698906685

Epoch: 69| Step: 0
Training loss: 2.9234719276428223
Validation loss: 2.19258221503227

Epoch: 6| Step: 1
Training loss: 1.6528297662734985
Validation loss: 2.1633347708691835

Epoch: 6| Step: 2
Training loss: 2.3027825355529785
Validation loss: 2.1500435824035318

Epoch: 6| Step: 3
Training loss: 1.7879973649978638
Validation loss: 2.155969468496179

Epoch: 6| Step: 4
Training loss: 2.657900810241699
Validation loss: 2.0984430364383164

Epoch: 6| Step: 5
Training loss: 2.2191498279571533
Validation loss: 2.0639856425664758

Epoch: 6| Step: 6
Training loss: 2.7120237350463867
Validation loss: 2.0352949967948337

Epoch: 6| Step: 7
Training loss: 2.16683292388916
Validation loss: 2.021643089991744

Epoch: 6| Step: 8
Training loss: 2.318737030029297
Validation loss: 2.0065065763329946

Epoch: 6| Step: 9
Training loss: 2.3943448066711426
Validation loss: 1.9980799510914793

Epoch: 6| Step: 10
Training loss: 2.8770809173583984
Validation loss: 1.986705405737764

Epoch: 6| Step: 11
Training loss: 2.563755512237549
Validation loss: 1.9758924386834587

Epoch: 6| Step: 12
Training loss: 2.166529655456543
Validation loss: 1.9801475988921298

Epoch: 6| Step: 13
Training loss: 2.5294506549835205
Validation loss: 1.9871116069055372

Epoch: 70| Step: 0
Training loss: 2.1761369705200195
Validation loss: 2.0037237085321897

Epoch: 6| Step: 1
Training loss: 2.1194570064544678
Validation loss: 2.034227758325556

Epoch: 6| Step: 2
Training loss: 2.0773537158966064
Validation loss: 2.041833403289959

Epoch: 6| Step: 3
Training loss: 3.143646478652954
Validation loss: 2.072980629500522

Epoch: 6| Step: 4
Training loss: 2.560634136199951
Validation loss: 2.096975780302478

Epoch: 6| Step: 5
Training loss: 2.5929837226867676
Validation loss: 2.072300769949472

Epoch: 6| Step: 6
Training loss: 2.034371852874756
Validation loss: 2.065858725578554

Epoch: 6| Step: 7
Training loss: 2.261756420135498
Validation loss: 2.061204882078273

Epoch: 6| Step: 8
Training loss: 2.266573667526245
Validation loss: 2.029063888775405

Epoch: 6| Step: 9
Training loss: 2.625408172607422
Validation loss: 1.9829497926978654

Epoch: 6| Step: 10
Training loss: 2.1724228858947754
Validation loss: 1.9775769159358034

Epoch: 6| Step: 11
Training loss: 1.8748013973236084
Validation loss: 1.9643219965760426

Epoch: 6| Step: 12
Training loss: 2.504988670349121
Validation loss: 1.965128388456119

Epoch: 6| Step: 13
Training loss: 2.1193785667419434
Validation loss: 1.9642871707998297

Epoch: 71| Step: 0
Training loss: 2.3610308170318604
Validation loss: 1.9687425064784225

Epoch: 6| Step: 1
Training loss: 1.8996564149856567
Validation loss: 1.9741214270232825

Epoch: 6| Step: 2
Training loss: 2.552643299102783
Validation loss: 1.992827444948176

Epoch: 6| Step: 3
Training loss: 2.382110595703125
Validation loss: 2.004857442712271

Epoch: 6| Step: 4
Training loss: 2.5834712982177734
Validation loss: 2.0154842612563924

Epoch: 6| Step: 5
Training loss: 2.103304862976074
Validation loss: 2.014763039927329

Epoch: 6| Step: 6
Training loss: 2.770193576812744
Validation loss: 2.0004363213815997

Epoch: 6| Step: 7
Training loss: 2.2924656867980957
Validation loss: 1.988013280335293

Epoch: 6| Step: 8
Training loss: 1.9267337322235107
Validation loss: 1.9952219699018745

Epoch: 6| Step: 9
Training loss: 2.7215914726257324
Validation loss: 1.9847417467383928

Epoch: 6| Step: 10
Training loss: 1.8475260734558105
Validation loss: 1.9997545929365261

Epoch: 6| Step: 11
Training loss: 2.3823156356811523
Validation loss: 2.0063631047484694

Epoch: 6| Step: 12
Training loss: 2.548295021057129
Validation loss: 2.008868141840863

Epoch: 6| Step: 13
Training loss: 2.454632043838501
Validation loss: 1.9948776819372689

Epoch: 72| Step: 0
Training loss: 2.9276161193847656
Validation loss: 1.994115662831132

Epoch: 6| Step: 1
Training loss: 2.3080575466156006
Validation loss: 1.9894402821858723

Epoch: 6| Step: 2
Training loss: 2.286865472793579
Validation loss: 1.9735348147730674

Epoch: 6| Step: 3
Training loss: 2.4481959342956543
Validation loss: 1.969992826061864

Epoch: 6| Step: 4
Training loss: 2.8972110748291016
Validation loss: 1.9727401374488749

Epoch: 6| Step: 5
Training loss: 1.4981770515441895
Validation loss: 1.9723627836473527

Epoch: 6| Step: 6
Training loss: 2.5287468433380127
Validation loss: 1.9727083354867914

Epoch: 6| Step: 7
Training loss: 2.302243947982788
Validation loss: 1.9873866881093671

Epoch: 6| Step: 8
Training loss: 2.035743236541748
Validation loss: 1.987414780483451

Epoch: 6| Step: 9
Training loss: 2.6308445930480957
Validation loss: 2.005160390689809

Epoch: 6| Step: 10
Training loss: 1.8019654750823975
Validation loss: 2.0331470979157316

Epoch: 6| Step: 11
Training loss: 2.2798235416412354
Validation loss: 2.0081596976967266

Epoch: 6| Step: 12
Training loss: 2.4148201942443848
Validation loss: 1.9963822159715878

Epoch: 6| Step: 13
Training loss: 2.2501821517944336
Validation loss: 1.975992618068572

Epoch: 73| Step: 0
Training loss: 2.1710703372955322
Validation loss: 1.9741701695226854

Epoch: 6| Step: 1
Training loss: 1.8481651544570923
Validation loss: 1.9724951649224887

Epoch: 6| Step: 2
Training loss: 2.083272933959961
Validation loss: 1.9727696936617616

Epoch: 6| Step: 3
Training loss: 2.428905963897705
Validation loss: 1.9902398176090692

Epoch: 6| Step: 4
Training loss: 1.5530474185943604
Validation loss: 1.9974152093292565

Epoch: 6| Step: 5
Training loss: 2.645312547683716
Validation loss: 1.9957503323913903

Epoch: 6| Step: 6
Training loss: 2.492865800857544
Validation loss: 2.0149763143190773

Epoch: 6| Step: 7
Training loss: 1.842015027999878
Validation loss: 2.062235233604267

Epoch: 6| Step: 8
Training loss: 2.944302558898926
Validation loss: 2.0934348734476234

Epoch: 6| Step: 9
Training loss: 2.241971969604492
Validation loss: 2.091791283699774

Epoch: 6| Step: 10
Training loss: 2.0704421997070312
Validation loss: 2.0938041504993232

Epoch: 6| Step: 11
Training loss: 2.794778823852539
Validation loss: 2.129242202287079

Epoch: 6| Step: 12
Training loss: 2.995556354522705
Validation loss: 2.1021420827475925

Epoch: 6| Step: 13
Training loss: 3.29095721244812
Validation loss: 2.0556231314136135

Epoch: 74| Step: 0
Training loss: 2.5790722370147705
Validation loss: 2.0037298266605665

Epoch: 6| Step: 1
Training loss: 2.1107354164123535
Validation loss: 1.976801774835074

Epoch: 6| Step: 2
Training loss: 2.2570066452026367
Validation loss: 1.9846946103598482

Epoch: 6| Step: 3
Training loss: 2.6291251182556152
Validation loss: 1.9869669278462727

Epoch: 6| Step: 4
Training loss: 1.8917582035064697
Validation loss: 1.9915446350651402

Epoch: 6| Step: 5
Training loss: 2.7748050689697266
Validation loss: 1.9853941266254713

Epoch: 6| Step: 6
Training loss: 2.230123519897461
Validation loss: 1.9861447144580144

Epoch: 6| Step: 7
Training loss: 2.4682531356811523
Validation loss: 1.9889173738418087

Epoch: 6| Step: 8
Training loss: 2.723022937774658
Validation loss: 1.9828447731592322

Epoch: 6| Step: 9
Training loss: 2.381974697113037
Validation loss: 1.985015307703326

Epoch: 6| Step: 10
Training loss: 2.5494625568389893
Validation loss: 1.9870049633005613

Epoch: 6| Step: 11
Training loss: 2.189894199371338
Validation loss: 1.9811051404604347

Epoch: 6| Step: 12
Training loss: 1.6903655529022217
Validation loss: 1.9800868367636075

Epoch: 6| Step: 13
Training loss: 3.0073063373565674
Validation loss: 1.9929976155680995

Epoch: 75| Step: 0
Training loss: 2.734895944595337
Validation loss: 2.0260027467563586

Epoch: 6| Step: 1
Training loss: 2.9466681480407715
Validation loss: 2.0523375195841633

Epoch: 6| Step: 2
Training loss: 3.096060276031494
Validation loss: 2.078760664950135

Epoch: 6| Step: 3
Training loss: 1.1159613132476807
Validation loss: 2.0783754317991194

Epoch: 6| Step: 4
Training loss: 2.694797992706299
Validation loss: 2.069858948389689

Epoch: 6| Step: 5
Training loss: 1.9360591173171997
Validation loss: 2.056063719975051

Epoch: 6| Step: 6
Training loss: 2.521876335144043
Validation loss: 2.053520869183284

Epoch: 6| Step: 7
Training loss: 2.5744142532348633
Validation loss: 2.048809818042222

Epoch: 6| Step: 8
Training loss: 1.869206428527832
Validation loss: 2.0221390596000095

Epoch: 6| Step: 9
Training loss: 1.99452805519104
Validation loss: 2.001732858278418

Epoch: 6| Step: 10
Training loss: 2.347128391265869
Validation loss: 1.9974092360465758

Epoch: 6| Step: 11
Training loss: 2.4228549003601074
Validation loss: 1.9978852784761818

Epoch: 6| Step: 12
Training loss: 2.2293639183044434
Validation loss: 1.9899696098860873

Epoch: 6| Step: 13
Training loss: 1.7649874687194824
Validation loss: 1.98620544966831

Epoch: 76| Step: 0
Training loss: 1.7291494607925415
Validation loss: 1.9822055460304342

Epoch: 6| Step: 1
Training loss: 2.531785488128662
Validation loss: 1.9757865423797278

Epoch: 6| Step: 2
Training loss: 2.0857534408569336
Validation loss: 1.9696210020331926

Epoch: 6| Step: 3
Training loss: 2.3311126232147217
Validation loss: 1.9802890823733421

Epoch: 6| Step: 4
Training loss: 2.3751931190490723
Validation loss: 1.9913784457791237

Epoch: 6| Step: 5
Training loss: 2.5384879112243652
Validation loss: 1.9858490344016784

Epoch: 6| Step: 6
Training loss: 2.996581554412842
Validation loss: 1.976804050066138

Epoch: 6| Step: 7
Training loss: 1.7524669170379639
Validation loss: 1.9696711122348745

Epoch: 6| Step: 8
Training loss: 3.043553113937378
Validation loss: 1.9730587364524923

Epoch: 6| Step: 9
Training loss: 1.9593267440795898
Validation loss: 1.9646227500771964

Epoch: 6| Step: 10
Training loss: 1.978374719619751
Validation loss: 1.9577541710228048

Epoch: 6| Step: 11
Training loss: 1.8498374223709106
Validation loss: 1.9507369456752655

Epoch: 6| Step: 12
Training loss: 2.3975512981414795
Validation loss: 1.951622901424285

Epoch: 6| Step: 13
Training loss: 3.0342917442321777
Validation loss: 1.9498918184670069

Epoch: 77| Step: 0
Training loss: 2.6319522857666016
Validation loss: 1.9430394813578615

Epoch: 6| Step: 1
Training loss: 1.4865472316741943
Validation loss: 1.9489603196420977

Epoch: 6| Step: 2
Training loss: 2.252017021179199
Validation loss: 1.9507744722468878

Epoch: 6| Step: 3
Training loss: 1.5645298957824707
Validation loss: 1.954221917736915

Epoch: 6| Step: 4
Training loss: 3.235401153564453
Validation loss: 1.9469137089226836

Epoch: 6| Step: 5
Training loss: 2.9562315940856934
Validation loss: 1.9568661874340427

Epoch: 6| Step: 6
Training loss: 2.308875322341919
Validation loss: 1.948385041247132

Epoch: 6| Step: 7
Training loss: 2.8057963848114014
Validation loss: 1.946517293171216

Epoch: 6| Step: 8
Training loss: 2.083259344100952
Validation loss: 1.9475383604726484

Epoch: 6| Step: 9
Training loss: 2.662062644958496
Validation loss: 1.9488939290405602

Epoch: 6| Step: 10
Training loss: 2.237093687057495
Validation loss: 1.9535928849251039

Epoch: 6| Step: 11
Training loss: 1.7463010549545288
Validation loss: 1.9653314082853255

Epoch: 6| Step: 12
Training loss: 2.178335666656494
Validation loss: 1.978506677894182

Epoch: 6| Step: 13
Training loss: 1.5259634256362915
Validation loss: 2.002098716715331

Epoch: 78| Step: 0
Training loss: 2.250004529953003
Validation loss: 1.9795922181939567

Epoch: 6| Step: 1
Training loss: 2.709400177001953
Validation loss: 1.9902430349780666

Epoch: 6| Step: 2
Training loss: 2.0055177211761475
Validation loss: 1.994901377667663

Epoch: 6| Step: 3
Training loss: 2.496861219406128
Validation loss: 1.9674438071507279

Epoch: 6| Step: 4
Training loss: 2.2490451335906982
Validation loss: 1.960907713059456

Epoch: 6| Step: 5
Training loss: 2.4552133083343506
Validation loss: 1.9538023189831806

Epoch: 6| Step: 6
Training loss: 2.3952906131744385
Validation loss: 1.9534703134208597

Epoch: 6| Step: 7
Training loss: 2.4229702949523926
Validation loss: 1.9528037373737623

Epoch: 6| Step: 8
Training loss: 1.8190362453460693
Validation loss: 1.9379947134243545

Epoch: 6| Step: 9
Training loss: 2.5042917728424072
Validation loss: 1.9355347374434113

Epoch: 6| Step: 10
Training loss: 1.6364893913269043
Validation loss: 1.933537785724927

Epoch: 6| Step: 11
Training loss: 2.868379592895508
Validation loss: 1.9392411606286162

Epoch: 6| Step: 12
Training loss: 2.0422844886779785
Validation loss: 1.9420171117269864

Epoch: 6| Step: 13
Training loss: 2.388000965118408
Validation loss: 1.95675019807713

Epoch: 79| Step: 0
Training loss: 2.6149678230285645
Validation loss: 1.9771682767457859

Epoch: 6| Step: 1
Training loss: 1.5093739032745361
Validation loss: 1.9991164515095372

Epoch: 6| Step: 2
Training loss: 2.409317970275879
Validation loss: 2.017244408207555

Epoch: 6| Step: 3
Training loss: 2.1433095932006836
Validation loss: 2.020154253129036

Epoch: 6| Step: 4
Training loss: 2.3682591915130615
Validation loss: 1.9733349712946082

Epoch: 6| Step: 5
Training loss: 2.274482250213623
Validation loss: 1.9571519436374787

Epoch: 6| Step: 6
Training loss: 2.5798497200012207
Validation loss: 1.928485631942749

Epoch: 6| Step: 7
Training loss: 2.442887306213379
Validation loss: 1.931782550709222

Epoch: 6| Step: 8
Training loss: 2.6926562786102295
Validation loss: 1.9290065342380154

Epoch: 6| Step: 9
Training loss: 2.307649612426758
Validation loss: 1.9327875414202291

Epoch: 6| Step: 10
Training loss: 2.308817148208618
Validation loss: 1.9267409757901264

Epoch: 6| Step: 11
Training loss: 2.5402958393096924
Validation loss: 1.9280568117736487

Epoch: 6| Step: 12
Training loss: 2.1268773078918457
Validation loss: 1.9417896834752892

Epoch: 6| Step: 13
Training loss: 1.8054900169372559
Validation loss: 1.9428004269958825

Epoch: 80| Step: 0
Training loss: 1.7653766870498657
Validation loss: 1.9509522671340613

Epoch: 6| Step: 1
Training loss: 1.6768696308135986
Validation loss: 1.9519446075603526

Epoch: 6| Step: 2
Training loss: 1.8245643377304077
Validation loss: 1.9626583668493456

Epoch: 6| Step: 3
Training loss: 1.7248589992523193
Validation loss: 1.9607422377473565

Epoch: 6| Step: 4
Training loss: 2.2724080085754395
Validation loss: 1.9664357310982161

Epoch: 6| Step: 5
Training loss: 2.766382932662964
Validation loss: 1.9595227164606894

Epoch: 6| Step: 6
Training loss: 3.0189402103424072
Validation loss: 1.9538687557302497

Epoch: 6| Step: 7
Training loss: 2.2064619064331055
Validation loss: 1.9472209997074579

Epoch: 6| Step: 8
Training loss: 2.0662803649902344
Validation loss: 1.9318748417721

Epoch: 6| Step: 9
Training loss: 2.1122636795043945
Validation loss: 1.9385485918291154

Epoch: 6| Step: 10
Training loss: 1.653067708015442
Validation loss: 1.9392075179725565

Epoch: 6| Step: 11
Training loss: 3.0051584243774414
Validation loss: 1.9400185103057532

Epoch: 6| Step: 12
Training loss: 3.2322635650634766
Validation loss: 1.9430872137828539

Epoch: 6| Step: 13
Training loss: 2.3912363052368164
Validation loss: 1.9383683832742835

Epoch: 81| Step: 0
Training loss: 2.551910161972046
Validation loss: 1.9388780529781053

Epoch: 6| Step: 1
Training loss: 2.396069049835205
Validation loss: 1.9405251318408596

Epoch: 6| Step: 2
Training loss: 2.909050941467285
Validation loss: 1.939304183888179

Epoch: 6| Step: 3
Training loss: 1.8079748153686523
Validation loss: 1.9323034850499963

Epoch: 6| Step: 4
Training loss: 1.8320578336715698
Validation loss: 1.9394458980970486

Epoch: 6| Step: 5
Training loss: 2.2335286140441895
Validation loss: 1.9489454684718963

Epoch: 6| Step: 6
Training loss: 2.1009130477905273
Validation loss: 1.9477394191167687

Epoch: 6| Step: 7
Training loss: 2.3303298950195312
Validation loss: 1.943912471494367

Epoch: 6| Step: 8
Training loss: 2.44804048538208
Validation loss: 1.9482516140066168

Epoch: 6| Step: 9
Training loss: 3.0240068435668945
Validation loss: 1.9410161561863397

Epoch: 6| Step: 10
Training loss: 2.0790350437164307
Validation loss: 1.9520477735868065

Epoch: 6| Step: 11
Training loss: 1.7808090448379517
Validation loss: 1.9472235325844056

Epoch: 6| Step: 12
Training loss: 1.9366846084594727
Validation loss: 1.9455174951143162

Epoch: 6| Step: 13
Training loss: 2.023963451385498
Validation loss: 1.9417633446314002

Epoch: 82| Step: 0
Training loss: 2.892601728439331
Validation loss: 1.950808637885637

Epoch: 6| Step: 1
Training loss: 3.055176258087158
Validation loss: 1.9727727495213991

Epoch: 6| Step: 2
Training loss: 2.357602119445801
Validation loss: 1.9776876152202647

Epoch: 6| Step: 3
Training loss: 2.1429429054260254
Validation loss: 1.9898833651696481

Epoch: 6| Step: 4
Training loss: 1.9763414859771729
Validation loss: 1.9847627468006586

Epoch: 6| Step: 5
Training loss: 1.6642388105392456
Validation loss: 1.9675996124103505

Epoch: 6| Step: 6
Training loss: 1.891005277633667
Validation loss: 1.951762976184968

Epoch: 6| Step: 7
Training loss: 2.080217123031616
Validation loss: 1.9455673848429034

Epoch: 6| Step: 8
Training loss: 2.7669711112976074
Validation loss: 1.9392294781182402

Epoch: 6| Step: 9
Training loss: 1.7729957103729248
Validation loss: 1.9396026352400422

Epoch: 6| Step: 10
Training loss: 1.9283828735351562
Validation loss: 1.9312366529177594

Epoch: 6| Step: 11
Training loss: 1.815872073173523
Validation loss: 1.937986796902072

Epoch: 6| Step: 12
Training loss: 2.6449689865112305
Validation loss: 1.9325516749453802

Epoch: 6| Step: 13
Training loss: 2.985231876373291
Validation loss: 1.9311180499292189

Epoch: 83| Step: 0
Training loss: 2.2614893913269043
Validation loss: 1.935455656820728

Epoch: 6| Step: 1
Training loss: 2.6312437057495117
Validation loss: 1.92917638568468

Epoch: 6| Step: 2
Training loss: 2.9902167320251465
Validation loss: 1.932810232203494

Epoch: 6| Step: 3
Training loss: 1.1866364479064941
Validation loss: 1.9422444502512615

Epoch: 6| Step: 4
Training loss: 2.576352119445801
Validation loss: 1.9437646994026758

Epoch: 6| Step: 5
Training loss: 1.999772310256958
Validation loss: 1.9623332754258187

Epoch: 6| Step: 6
Training loss: 2.3875365257263184
Validation loss: 1.9750802478482645

Epoch: 6| Step: 7
Training loss: 2.1413445472717285
Validation loss: 1.9806088952608005

Epoch: 6| Step: 8
Training loss: 1.8495566844940186
Validation loss: 1.962975291795628

Epoch: 6| Step: 9
Training loss: 2.574599027633667
Validation loss: 1.942773679251312

Epoch: 6| Step: 10
Training loss: 2.4784719944000244
Validation loss: 1.9331410469547394

Epoch: 6| Step: 11
Training loss: 2.6893773078918457
Validation loss: 1.929383336856801

Epoch: 6| Step: 12
Training loss: 1.4632384777069092
Validation loss: 1.9204257149850168

Epoch: 6| Step: 13
Training loss: 2.6212267875671387
Validation loss: 1.9258089065551758

Epoch: 84| Step: 0
Training loss: 1.8502936363220215
Validation loss: 1.9310001942419237

Epoch: 6| Step: 1
Training loss: 3.1007330417633057
Validation loss: 1.9258099179114065

Epoch: 6| Step: 2
Training loss: 3.095852851867676
Validation loss: 1.9249435509404829

Epoch: 6| Step: 3
Training loss: 2.8144288063049316
Validation loss: 1.9279737344352148

Epoch: 6| Step: 4
Training loss: 2.268831253051758
Validation loss: 1.9283660201616184

Epoch: 6| Step: 5
Training loss: 1.9806793928146362
Validation loss: 1.927886906490531

Epoch: 6| Step: 6
Training loss: 2.0142271518707275
Validation loss: 1.9293491391725437

Epoch: 6| Step: 7
Training loss: 1.7843527793884277
Validation loss: 1.934066685297156

Epoch: 6| Step: 8
Training loss: 2.074204921722412
Validation loss: 1.9613407170900734

Epoch: 6| Step: 9
Training loss: 1.6055079698562622
Validation loss: 1.9854546387990315

Epoch: 6| Step: 10
Training loss: 2.240663528442383
Validation loss: 2.013234676853303

Epoch: 6| Step: 11
Training loss: 2.4878554344177246
Validation loss: 2.008957803890269

Epoch: 6| Step: 12
Training loss: 1.9898191690444946
Validation loss: 2.014302279359551

Epoch: 6| Step: 13
Training loss: 2.015204429626465
Validation loss: 2.0081990162531533

Epoch: 85| Step: 0
Training loss: 2.2944703102111816
Validation loss: 1.985477760273923

Epoch: 6| Step: 1
Training loss: 2.3661813735961914
Validation loss: 1.963048945191086

Epoch: 6| Step: 2
Training loss: 1.754512071609497
Validation loss: 1.9472518685043498

Epoch: 6| Step: 3
Training loss: 1.9740082025527954
Validation loss: 1.936755593105029

Epoch: 6| Step: 4
Training loss: 2.4394168853759766
Validation loss: 1.927388975697179

Epoch: 6| Step: 5
Training loss: 2.180955410003662
Validation loss: 1.9284331798553467

Epoch: 6| Step: 6
Training loss: 2.3262417316436768
Validation loss: 1.931561957123459

Epoch: 6| Step: 7
Training loss: 1.8053805828094482
Validation loss: 1.9341069036914456

Epoch: 6| Step: 8
Training loss: 2.8430538177490234
Validation loss: 1.9251223187292776

Epoch: 6| Step: 9
Training loss: 1.9042117595672607
Validation loss: 1.9274572685200682

Epoch: 6| Step: 10
Training loss: 2.1491081714630127
Validation loss: 1.9260034484248008

Epoch: 6| Step: 11
Training loss: 2.7751355171203613
Validation loss: 1.9265178762456423

Epoch: 6| Step: 12
Training loss: 2.0128045082092285
Validation loss: 1.9430872522374636

Epoch: 6| Step: 13
Training loss: 2.6541178226470947
Validation loss: 1.9567755806830622

Epoch: 86| Step: 0
Training loss: 2.2456960678100586
Validation loss: 1.9618822246469476

Epoch: 6| Step: 1
Training loss: 2.599146842956543
Validation loss: 1.9534605831228278

Epoch: 6| Step: 2
Training loss: 2.351907253265381
Validation loss: 1.9655665325862106

Epoch: 6| Step: 3
Training loss: 1.9623544216156006
Validation loss: 1.9567394128409765

Epoch: 6| Step: 4
Training loss: 1.8094877004623413
Validation loss: 1.9473227300951559

Epoch: 6| Step: 5
Training loss: 2.3871984481811523
Validation loss: 1.929038525909506

Epoch: 6| Step: 6
Training loss: 2.003654956817627
Validation loss: 1.917153008522526

Epoch: 6| Step: 7
Training loss: 1.5264687538146973
Validation loss: 1.9204026652920632

Epoch: 6| Step: 8
Training loss: 2.6907596588134766
Validation loss: 1.9204542547143915

Epoch: 6| Step: 9
Training loss: 2.3247032165527344
Validation loss: 1.9233627678245626

Epoch: 6| Step: 10
Training loss: 2.3364980220794678
Validation loss: 1.9209133489157564

Epoch: 6| Step: 11
Training loss: 2.359856128692627
Validation loss: 1.9236391885306245

Epoch: 6| Step: 12
Training loss: 2.9682211875915527
Validation loss: 1.942518953354128

Epoch: 6| Step: 13
Training loss: 1.6527647972106934
Validation loss: 1.9434913255835091

Epoch: 87| Step: 0
Training loss: 2.342890739440918
Validation loss: 1.948565427974988

Epoch: 6| Step: 1
Training loss: 2.124809980392456
Validation loss: 1.9553466035473732

Epoch: 6| Step: 2
Training loss: 2.596595287322998
Validation loss: 1.948825272180701

Epoch: 6| Step: 3
Training loss: 2.261291027069092
Validation loss: 1.9495908957655712

Epoch: 6| Step: 4
Training loss: 2.0862674713134766
Validation loss: 1.9436855854526642

Epoch: 6| Step: 5
Training loss: 2.51168155670166
Validation loss: 1.9468071255632626

Epoch: 6| Step: 6
Training loss: 2.194568157196045
Validation loss: 1.9596652676982265

Epoch: 6| Step: 7
Training loss: 2.0046706199645996
Validation loss: 1.9809788606500114

Epoch: 6| Step: 8
Training loss: 2.2180094718933105
Validation loss: 2.014656138676469

Epoch: 6| Step: 9
Training loss: 1.6298482418060303
Validation loss: 2.0221405888116486

Epoch: 6| Step: 10
Training loss: 2.399261951446533
Validation loss: 1.993729760569911

Epoch: 6| Step: 11
Training loss: 1.8463504314422607
Validation loss: 1.9651677557217178

Epoch: 6| Step: 12
Training loss: 2.823758125305176
Validation loss: 1.9413985231871247

Epoch: 6| Step: 13
Training loss: 2.50476336479187
Validation loss: 1.9426608277905373

Epoch: 88| Step: 0
Training loss: 2.802077293395996
Validation loss: 1.9441139954392628

Epoch: 6| Step: 1
Training loss: 3.019713878631592
Validation loss: 1.9488652213927238

Epoch: 6| Step: 2
Training loss: 1.7361228466033936
Validation loss: 1.964712586454166

Epoch: 6| Step: 3
Training loss: 2.9664878845214844
Validation loss: 1.9727641638889108

Epoch: 6| Step: 4
Training loss: 2.1655616760253906
Validation loss: 1.9673851997621599

Epoch: 6| Step: 5
Training loss: 1.5750575065612793
Validation loss: 1.9564839357970862

Epoch: 6| Step: 6
Training loss: 2.4289584159851074
Validation loss: 1.9462156475231212

Epoch: 6| Step: 7
Training loss: 2.478384017944336
Validation loss: 1.9475455399482482

Epoch: 6| Step: 8
Training loss: 2.2140183448791504
Validation loss: 1.9869404095475391

Epoch: 6| Step: 9
Training loss: 2.436534881591797
Validation loss: 2.025124757520614

Epoch: 6| Step: 10
Training loss: 1.7853467464447021
Validation loss: 2.0694859566227084

Epoch: 6| Step: 11
Training loss: 2.0485520362854004
Validation loss: 2.1152455755459365

Epoch: 6| Step: 12
Training loss: 2.184779644012451
Validation loss: 2.097071563043902

Epoch: 6| Step: 13
Training loss: 2.0533854961395264
Validation loss: 2.0859697172718663

Epoch: 89| Step: 0
Training loss: 2.130128860473633
Validation loss: 2.0822103356802337

Epoch: 6| Step: 1
Training loss: 2.1250791549682617
Validation loss: 2.0591809890603505

Epoch: 6| Step: 2
Training loss: 1.8874969482421875
Validation loss: 2.0304590502092914

Epoch: 6| Step: 3
Training loss: 1.9288737773895264
Validation loss: 1.9945845257851385

Epoch: 6| Step: 4
Training loss: 2.6616668701171875
Validation loss: 1.9577144192111107

Epoch: 6| Step: 5
Training loss: 2.0864346027374268
Validation loss: 1.9498725668076546

Epoch: 6| Step: 6
Training loss: 1.8886280059814453
Validation loss: 1.9569418763601651

Epoch: 6| Step: 7
Training loss: 2.3138394355773926
Validation loss: 1.9631534776379984

Epoch: 6| Step: 8
Training loss: 2.742197275161743
Validation loss: 1.9678878681634062

Epoch: 6| Step: 9
Training loss: 1.8444581031799316
Validation loss: 1.9658721928955407

Epoch: 6| Step: 10
Training loss: 2.4321160316467285
Validation loss: 1.9571338110072638

Epoch: 6| Step: 11
Training loss: 2.733670234680176
Validation loss: 1.9571481558584398

Epoch: 6| Step: 12
Training loss: 2.9588208198547363
Validation loss: 1.952321651161358

Epoch: 6| Step: 13
Training loss: 1.7159295082092285
Validation loss: 1.9496396126285676

Epoch: 90| Step: 0
Training loss: 1.7737319469451904
Validation loss: 1.9500089486440022

Epoch: 6| Step: 1
Training loss: 2.864133834838867
Validation loss: 1.9545794661327074

Epoch: 6| Step: 2
Training loss: 2.4493701457977295
Validation loss: 1.9704780783704532

Epoch: 6| Step: 3
Training loss: 2.6036205291748047
Validation loss: 1.9833018959209483

Epoch: 6| Step: 4
Training loss: 2.8511099815368652
Validation loss: 1.9842476306423065

Epoch: 6| Step: 5
Training loss: 1.6621475219726562
Validation loss: 1.9827513694763184

Epoch: 6| Step: 6
Training loss: 2.289681911468506
Validation loss: 1.9940736550156788

Epoch: 6| Step: 7
Training loss: 2.412102460861206
Validation loss: 2.001756509145101

Epoch: 6| Step: 8
Training loss: 1.6534589529037476
Validation loss: 1.9977674304798085

Epoch: 6| Step: 9
Training loss: 2.151533842086792
Validation loss: 1.9950983755050167

Epoch: 6| Step: 10
Training loss: 1.9388301372528076
Validation loss: 1.998183406809325

Epoch: 6| Step: 11
Training loss: 1.8728444576263428
Validation loss: 1.988066896315544

Epoch: 6| Step: 12
Training loss: 2.4800186157226562
Validation loss: 1.9905315240224202

Epoch: 6| Step: 13
Training loss: 1.6716761589050293
Validation loss: 1.981568891515014

Epoch: 91| Step: 0
Training loss: 2.266413450241089
Validation loss: 1.9776434321557321

Epoch: 6| Step: 1
Training loss: 2.5528533458709717
Validation loss: 1.968649491187065

Epoch: 6| Step: 2
Training loss: 1.2966300249099731
Validation loss: 1.9650001307969451

Epoch: 6| Step: 3
Training loss: 2.1651463508605957
Validation loss: 1.9657955861860705

Epoch: 6| Step: 4
Training loss: 2.563876152038574
Validation loss: 1.9686347079533402

Epoch: 6| Step: 5
Training loss: 2.582188129425049
Validation loss: 1.9670834848957677

Epoch: 6| Step: 6
Training loss: 2.4674630165100098
Validation loss: 1.9699406752022364

Epoch: 6| Step: 7
Training loss: 1.9583990573883057
Validation loss: 1.9605552842540126

Epoch: 6| Step: 8
Training loss: 2.6167969703674316
Validation loss: 1.9731825192769368

Epoch: 6| Step: 9
Training loss: 1.979251742362976
Validation loss: 1.9971469422822357

Epoch: 6| Step: 10
Training loss: 2.465916633605957
Validation loss: 2.0372709881874824

Epoch: 6| Step: 11
Training loss: 2.336077928543091
Validation loss: 2.041849310680102

Epoch: 6| Step: 12
Training loss: 2.122466802597046
Validation loss: 2.050087075079641

Epoch: 6| Step: 13
Training loss: 1.7373549938201904
Validation loss: 2.0369613029623546

Epoch: 92| Step: 0
Training loss: 3.0569376945495605
Validation loss: 2.007717514550814

Epoch: 6| Step: 1
Training loss: 1.966871976852417
Validation loss: 1.9820222111158474

Epoch: 6| Step: 2
Training loss: 2.33492112159729
Validation loss: 1.9833643372340868

Epoch: 6| Step: 3
Training loss: 2.3050858974456787
Validation loss: 1.9756439808876283

Epoch: 6| Step: 4
Training loss: 1.6681950092315674
Validation loss: 1.9962365999016711

Epoch: 6| Step: 5
Training loss: 2.391439199447632
Validation loss: 2.006927195415702

Epoch: 6| Step: 6
Training loss: 2.4969563484191895
Validation loss: 2.0257494834161576

Epoch: 6| Step: 7
Training loss: 2.0515527725219727
Validation loss: 2.0311523381099907

Epoch: 6| Step: 8
Training loss: 2.223583459854126
Validation loss: 2.042306366787162

Epoch: 6| Step: 9
Training loss: 1.6042873859405518
Validation loss: 2.0432112857859623

Epoch: 6| Step: 10
Training loss: 1.8357298374176025
Validation loss: 2.052556607031053

Epoch: 6| Step: 11
Training loss: 2.2751970291137695
Validation loss: 2.054258260675656

Epoch: 6| Step: 12
Training loss: 2.7824645042419434
Validation loss: 2.043188641148229

Epoch: 6| Step: 13
Training loss: 2.2432050704956055
Validation loss: 1.987699221539241

Epoch: 93| Step: 0
Training loss: 1.4971222877502441
Validation loss: 1.9716831612330612

Epoch: 6| Step: 1
Training loss: 2.260286808013916
Validation loss: 1.964306895450879

Epoch: 6| Step: 2
Training loss: 1.8389912843704224
Validation loss: 1.9686283116699548

Epoch: 6| Step: 3
Training loss: 2.2208614349365234
Validation loss: 1.9870429961912093

Epoch: 6| Step: 4
Training loss: 1.8575990200042725
Validation loss: 1.9751104782986384

Epoch: 6| Step: 5
Training loss: 2.6004905700683594
Validation loss: 1.9776328071471183

Epoch: 6| Step: 6
Training loss: 2.3775737285614014
Validation loss: 1.9641770855073006

Epoch: 6| Step: 7
Training loss: 2.021364212036133
Validation loss: 1.9731211123927948

Epoch: 6| Step: 8
Training loss: 2.885636329650879
Validation loss: 1.9605008837997273

Epoch: 6| Step: 9
Training loss: 2.208441734313965
Validation loss: 1.96601221253795

Epoch: 6| Step: 10
Training loss: 2.5114758014678955
Validation loss: 1.9603002276471866

Epoch: 6| Step: 11
Training loss: 2.2445266246795654
Validation loss: 1.9633361113968717

Epoch: 6| Step: 12
Training loss: 2.1531336307525635
Validation loss: 1.9690341795644453

Epoch: 6| Step: 13
Training loss: 1.8531347513198853
Validation loss: 1.97134873431216

Epoch: 94| Step: 0
Training loss: 2.2618062496185303
Validation loss: 1.9594873651381461

Epoch: 6| Step: 1
Training loss: 2.1863133907318115
Validation loss: 1.962359659133419

Epoch: 6| Step: 2
Training loss: 2.513693332672119
Validation loss: 1.9480827085433468

Epoch: 6| Step: 3
Training loss: 1.664428949356079
Validation loss: 1.9336197350614814

Epoch: 6| Step: 4
Training loss: 2.007791042327881
Validation loss: 1.9311695380877423

Epoch: 6| Step: 5
Training loss: 2.0316555500030518
Validation loss: 1.927496107675696

Epoch: 6| Step: 6
Training loss: 1.5307083129882812
Validation loss: 1.9364420355007212

Epoch: 6| Step: 7
Training loss: 2.0639376640319824
Validation loss: 1.9382334409221527

Epoch: 6| Step: 8
Training loss: 2.0004401206970215
Validation loss: 1.9406163756565382

Epoch: 6| Step: 9
Training loss: 2.5860157012939453
Validation loss: 1.9290827807559763

Epoch: 6| Step: 10
Training loss: 2.2502002716064453
Validation loss: 1.9263576897241736

Epoch: 6| Step: 11
Training loss: 2.312628984451294
Validation loss: 1.918665611615745

Epoch: 6| Step: 12
Training loss: 2.993863105773926
Validation loss: 1.9231106645317488

Epoch: 6| Step: 13
Training loss: 2.336045265197754
Validation loss: 1.9132461112032655

Epoch: 95| Step: 0
Training loss: 2.486392021179199
Validation loss: 1.9171932640896048

Epoch: 6| Step: 1
Training loss: 2.6839609146118164
Validation loss: 1.9219006235881517

Epoch: 6| Step: 2
Training loss: 1.8249824047088623
Validation loss: 1.9198000174696728

Epoch: 6| Step: 3
Training loss: 1.8192996978759766
Validation loss: 1.9087803620164112

Epoch: 6| Step: 4
Training loss: 2.037081718444824
Validation loss: 1.9140430099220687

Epoch: 6| Step: 5
Training loss: 2.024271011352539
Validation loss: 1.9215553845128706

Epoch: 6| Step: 6
Training loss: 2.6723434925079346
Validation loss: 1.9290889783572125

Epoch: 6| Step: 7
Training loss: 1.602640151977539
Validation loss: 1.9278672536214192

Epoch: 6| Step: 8
Training loss: 2.2676753997802734
Validation loss: 1.9311229336646296

Epoch: 6| Step: 9
Training loss: 2.736602544784546
Validation loss: 1.9502096637602775

Epoch: 6| Step: 10
Training loss: 2.0175187587738037
Validation loss: 1.9658929840210946

Epoch: 6| Step: 11
Training loss: 1.9336425065994263
Validation loss: 1.991092687012047

Epoch: 6| Step: 12
Training loss: 2.2573397159576416
Validation loss: 1.9924567643032278

Epoch: 6| Step: 13
Training loss: 2.4143009185791016
Validation loss: 2.018902676079863

Epoch: 96| Step: 0
Training loss: 2.1410810947418213
Validation loss: 2.0234603215289373

Epoch: 6| Step: 1
Training loss: 2.3584322929382324
Validation loss: 2.0090527175575175

Epoch: 6| Step: 2
Training loss: 2.5641002655029297
Validation loss: 2.001340176469536

Epoch: 6| Step: 3
Training loss: 3.093665599822998
Validation loss: 1.9929062063976

Epoch: 6| Step: 4
Training loss: 2.419649839401245
Validation loss: 2.0093853845391223

Epoch: 6| Step: 5
Training loss: 1.4973102807998657
Validation loss: 1.9923667843623827

Epoch: 6| Step: 6
Training loss: 2.2289371490478516
Validation loss: 1.9855000293383034

Epoch: 6| Step: 7
Training loss: 2.419450521469116
Validation loss: 1.947930815399334

Epoch: 6| Step: 8
Training loss: 1.4696359634399414
Validation loss: 1.9503849398705266

Epoch: 6| Step: 9
Training loss: 2.0716476440429688
Validation loss: 1.9401468794832948

Epoch: 6| Step: 10
Training loss: 1.9693742990493774
Validation loss: 1.940481117976609

Epoch: 6| Step: 11
Training loss: 1.7921282052993774
Validation loss: 1.9398040092119606

Epoch: 6| Step: 12
Training loss: 2.2512221336364746
Validation loss: 1.9291971550192883

Epoch: 6| Step: 13
Training loss: 2.2526397705078125
Validation loss: 1.9312945488960511

Epoch: 97| Step: 0
Training loss: 2.0846424102783203
Validation loss: 1.9203191341892365

Epoch: 6| Step: 1
Training loss: 2.2421998977661133
Validation loss: 1.9307984523875739

Epoch: 6| Step: 2
Training loss: 2.072094678878784
Validation loss: 1.964954032692858

Epoch: 6| Step: 3
Training loss: 2.1232056617736816
Validation loss: 1.9916213225292903

Epoch: 6| Step: 4
Training loss: 3.034658908843994
Validation loss: 2.001945762224095

Epoch: 6| Step: 5
Training loss: 2.626837968826294
Validation loss: 1.9995150168736775

Epoch: 6| Step: 6
Training loss: 1.939786672592163
Validation loss: 1.9887993758724583

Epoch: 6| Step: 7
Training loss: 1.662717342376709
Validation loss: 1.9835610287163847

Epoch: 6| Step: 8
Training loss: 2.096700429916382
Validation loss: 1.9699231591275943

Epoch: 6| Step: 9
Training loss: 1.8309836387634277
Validation loss: 1.9518815163643128

Epoch: 6| Step: 10
Training loss: 2.117610454559326
Validation loss: 1.9374801112759499

Epoch: 6| Step: 11
Training loss: 1.9168260097503662
Validation loss: 1.9409582819989932

Epoch: 6| Step: 12
Training loss: 2.0879323482513428
Validation loss: 1.9353487030152352

Epoch: 6| Step: 13
Training loss: 3.258281946182251
Validation loss: 1.9331388012055428

Epoch: 98| Step: 0
Training loss: 1.7877235412597656
Validation loss: 1.9339228419847385

Epoch: 6| Step: 1
Training loss: 2.307952404022217
Validation loss: 1.9403511721600768

Epoch: 6| Step: 2
Training loss: 1.9267724752426147
Validation loss: 1.958800656821138

Epoch: 6| Step: 3
Training loss: 2.119915008544922
Validation loss: 1.9586572518912695

Epoch: 6| Step: 4
Training loss: 2.1323585510253906
Validation loss: 1.9468467312474405

Epoch: 6| Step: 5
Training loss: 2.1515164375305176
Validation loss: 1.9300719358587777

Epoch: 6| Step: 6
Training loss: 2.074474573135376
Validation loss: 1.9264036199097991

Epoch: 6| Step: 7
Training loss: 2.3806819915771484
Validation loss: 1.9176272730673514

Epoch: 6| Step: 8
Training loss: 2.9841036796569824
Validation loss: 1.9210741994201497

Epoch: 6| Step: 9
Training loss: 2.294297218322754
Validation loss: 1.9333644733634046

Epoch: 6| Step: 10
Training loss: 2.147810220718384
Validation loss: 1.9504961659831386

Epoch: 6| Step: 11
Training loss: 2.227073907852173
Validation loss: 1.9802336474900604

Epoch: 6| Step: 12
Training loss: 2.3570446968078613
Validation loss: 1.9983605607863395

Epoch: 6| Step: 13
Training loss: 1.3772512674331665
Validation loss: 1.9905231306629796

Epoch: 99| Step: 0
Training loss: 2.113591432571411
Validation loss: 1.967617460476455

Epoch: 6| Step: 1
Training loss: 3.089787721633911
Validation loss: 1.9538812278419413

Epoch: 6| Step: 2
Training loss: 2.6721901893615723
Validation loss: 1.9524196309428061

Epoch: 6| Step: 3
Training loss: 1.888732671737671
Validation loss: 1.9346665195239487

Epoch: 6| Step: 4
Training loss: 1.7382564544677734
Validation loss: 1.9398033542017783

Epoch: 6| Step: 5
Training loss: 2.344977855682373
Validation loss: 1.941633855142901

Epoch: 6| Step: 6
Training loss: 1.4843580722808838
Validation loss: 1.9556114314704813

Epoch: 6| Step: 7
Training loss: 2.5353684425354004
Validation loss: 1.9422689689102994

Epoch: 6| Step: 8
Training loss: 2.525886058807373
Validation loss: 1.9333340301308581

Epoch: 6| Step: 9
Training loss: 1.8131929636001587
Validation loss: 1.9371965367306945

Epoch: 6| Step: 10
Training loss: 2.625046730041504
Validation loss: 1.9317494566722582

Epoch: 6| Step: 11
Training loss: 1.7349281311035156
Validation loss: 1.9473456336605934

Epoch: 6| Step: 12
Training loss: 1.6929866075515747
Validation loss: 1.9704856257284842

Epoch: 6| Step: 13
Training loss: 1.8174176216125488
Validation loss: 1.965314616439163

Epoch: 100| Step: 0
Training loss: 2.516533851623535
Validation loss: 1.983339645529306

Epoch: 6| Step: 1
Training loss: 2.1782681941986084
Validation loss: 1.9823360494388047

Epoch: 6| Step: 2
Training loss: 1.7651786804199219
Validation loss: 1.9972131816289758

Epoch: 6| Step: 3
Training loss: 1.8249696493148804
Validation loss: 2.0149998767401582

Epoch: 6| Step: 4
Training loss: 2.3722496032714844
Validation loss: 2.021660248438517

Epoch: 6| Step: 5
Training loss: 1.992954134941101
Validation loss: 2.016174019023936

Epoch: 6| Step: 6
Training loss: 1.9329469203948975
Validation loss: 2.002611585842666

Epoch: 6| Step: 7
Training loss: 1.3654701709747314
Validation loss: 1.9901942822241014

Epoch: 6| Step: 8
Training loss: 2.7049496173858643
Validation loss: 1.9646607393859534

Epoch: 6| Step: 9
Training loss: 2.235379934310913
Validation loss: 1.9856033889196252

Epoch: 6| Step: 10
Training loss: 1.9842755794525146
Validation loss: 1.9952887322313042

Epoch: 6| Step: 11
Training loss: 2.430410385131836
Validation loss: 2.0158254664431334

Epoch: 6| Step: 12
Training loss: 2.4217684268951416
Validation loss: 2.028082166948626

Epoch: 6| Step: 13
Training loss: 2.451632499694824
Validation loss: 2.0269438361608856

Epoch: 101| Step: 0
Training loss: 2.048856019973755
Validation loss: 2.0213313000176543

Epoch: 6| Step: 1
Training loss: 2.213076114654541
Validation loss: 2.013346040120689

Epoch: 6| Step: 2
Training loss: 2.238691568374634
Validation loss: 1.9954311886141378

Epoch: 6| Step: 3
Training loss: 2.299051284790039
Validation loss: 1.9871190722270677

Epoch: 6| Step: 4
Training loss: 2.767202377319336
Validation loss: 1.991028993360458

Epoch: 6| Step: 5
Training loss: 2.1065146923065186
Validation loss: 1.9998911990914294

Epoch: 6| Step: 6
Training loss: 2.096677541732788
Validation loss: 2.0113944263868433

Epoch: 6| Step: 7
Training loss: 2.3723011016845703
Validation loss: 2.002605438232422

Epoch: 6| Step: 8
Training loss: 2.103761672973633
Validation loss: 1.9916257319911834

Epoch: 6| Step: 9
Training loss: 1.9779579639434814
Validation loss: 1.9765760411498368

Epoch: 6| Step: 10
Training loss: 1.674278736114502
Validation loss: 1.9705522970486713

Epoch: 6| Step: 11
Training loss: 1.9471367597579956
Validation loss: 1.9595342220798615

Epoch: 6| Step: 12
Training loss: 2.031116485595703
Validation loss: 1.9337928730954406

Epoch: 6| Step: 13
Training loss: 2.3933093547821045
Validation loss: 1.938658074666095

Epoch: 102| Step: 0
Training loss: 2.4656829833984375
Validation loss: 1.9409993976675055

Epoch: 6| Step: 1
Training loss: 2.3677260875701904
Validation loss: 1.961473273974593

Epoch: 6| Step: 2
Training loss: 2.1578598022460938
Validation loss: 1.9839151213246007

Epoch: 6| Step: 3
Training loss: 1.900315523147583
Validation loss: 1.9812412044053436

Epoch: 6| Step: 4
Training loss: 1.809988260269165
Validation loss: 1.9543573689717118

Epoch: 6| Step: 5
Training loss: 2.0890755653381348
Validation loss: 1.931853872473522

Epoch: 6| Step: 6
Training loss: 2.637136459350586
Validation loss: 1.9302001819815686

Epoch: 6| Step: 7
Training loss: 1.7430295944213867
Validation loss: 1.9181226325291458

Epoch: 6| Step: 8
Training loss: 2.4063897132873535
Validation loss: 1.9137503549616823

Epoch: 6| Step: 9
Training loss: 2.658217191696167
Validation loss: 1.9103126859152189

Epoch: 6| Step: 10
Training loss: 1.7689272165298462
Validation loss: 1.9079101367663311

Epoch: 6| Step: 11
Training loss: 2.308762550354004
Validation loss: 1.9094371603381248

Epoch: 6| Step: 12
Training loss: 1.9848392009735107
Validation loss: 1.9062170559360134

Epoch: 6| Step: 13
Training loss: 1.4703547954559326
Validation loss: 1.8926127367122199

Epoch: 103| Step: 0
Training loss: 1.6446518898010254
Validation loss: 1.903225096323157

Epoch: 6| Step: 1
Training loss: 2.962876796722412
Validation loss: 1.914769914842421

Epoch: 6| Step: 2
Training loss: 2.2817554473876953
Validation loss: 1.9479015578505814

Epoch: 6| Step: 3
Training loss: 1.8633556365966797
Validation loss: 1.990357852751209

Epoch: 6| Step: 4
Training loss: 2.5684969425201416
Validation loss: 2.0173630035051735

Epoch: 6| Step: 5
Training loss: 1.9863888025283813
Validation loss: 2.018734029544297

Epoch: 6| Step: 6
Training loss: 2.858898162841797
Validation loss: 2.006992649006587

Epoch: 6| Step: 7
Training loss: 1.6724216938018799
Validation loss: 1.9965546861771615

Epoch: 6| Step: 8
Training loss: 2.261178970336914
Validation loss: 1.947067303042258

Epoch: 6| Step: 9
Training loss: 2.1165080070495605
Validation loss: 1.920004544719573

Epoch: 6| Step: 10
Training loss: 1.786789894104004
Validation loss: 1.9098706886332522

Epoch: 6| Step: 11
Training loss: 2.746410846710205
Validation loss: 1.92037110687584

Epoch: 6| Step: 12
Training loss: 1.714156150817871
Validation loss: 1.9458082875897806

Epoch: 6| Step: 13
Training loss: 1.8661795854568481
Validation loss: 1.9641656734610116

Epoch: 104| Step: 0
Training loss: 2.2421159744262695
Validation loss: 1.971548536772369

Epoch: 6| Step: 1
Training loss: 1.4449102878570557
Validation loss: 1.9732110141426005

Epoch: 6| Step: 2
Training loss: 2.490610122680664
Validation loss: 1.986541776246922

Epoch: 6| Step: 3
Training loss: 1.8207365274429321
Validation loss: 1.9808658669071812

Epoch: 6| Step: 4
Training loss: 2.129793167114258
Validation loss: 1.9797904875970656

Epoch: 6| Step: 5
Training loss: 2.340627670288086
Validation loss: 1.9773345314046389

Epoch: 6| Step: 6
Training loss: 2.9244437217712402
Validation loss: 1.9902979045785882

Epoch: 6| Step: 7
Training loss: 2.181149482727051
Validation loss: 1.9961073257589852

Epoch: 6| Step: 8
Training loss: 1.8552281856536865
Validation loss: 1.9923050711231847

Epoch: 6| Step: 9
Training loss: 2.1976475715637207
Validation loss: 1.9772963241864276

Epoch: 6| Step: 10
Training loss: 2.0362043380737305
Validation loss: 1.9716395665240545

Epoch: 6| Step: 11
Training loss: 2.4961624145507812
Validation loss: 1.9682758879917923

Epoch: 6| Step: 12
Training loss: 1.7262654304504395
Validation loss: 1.975256735278714

Epoch: 6| Step: 13
Training loss: 1.9933571815490723
Validation loss: 1.9655176362683695

Epoch: 105| Step: 0
Training loss: 1.9380561113357544
Validation loss: 1.9561949570973713

Epoch: 6| Step: 1
Training loss: 2.73881459236145
Validation loss: 1.9540175378963511

Epoch: 6| Step: 2
Training loss: 1.7031898498535156
Validation loss: 1.9360256528341642

Epoch: 6| Step: 3
Training loss: 2.5453150272369385
Validation loss: 1.9403091476809593

Epoch: 6| Step: 4
Training loss: 1.8125938177108765
Validation loss: 1.9353046904328048

Epoch: 6| Step: 5
Training loss: 2.0421299934387207
Validation loss: 1.9329375015792025

Epoch: 6| Step: 6
Training loss: 1.671467900276184
Validation loss: 1.93432270326922

Epoch: 6| Step: 7
Training loss: 1.2285382747650146
Validation loss: 1.9378950608673917

Epoch: 6| Step: 8
Training loss: 2.267434597015381
Validation loss: 1.942785660425822

Epoch: 6| Step: 9
Training loss: 2.660470962524414
Validation loss: 1.9385983802938973

Epoch: 6| Step: 10
Training loss: 2.2197654247283936
Validation loss: 1.9572585372514621

Epoch: 6| Step: 11
Training loss: 2.07635235786438
Validation loss: 1.955436534779046

Epoch: 6| Step: 12
Training loss: 2.0705859661102295
Validation loss: 1.9376498550497077

Epoch: 6| Step: 13
Training loss: 2.8672611713409424
Validation loss: 1.933879651049132

Epoch: 106| Step: 0
Training loss: 2.922377586364746
Validation loss: 1.9531435838309668

Epoch: 6| Step: 1
Training loss: 2.471309185028076
Validation loss: 1.956059378962363

Epoch: 6| Step: 2
Training loss: 2.0255074501037598
Validation loss: 1.9642720735201271

Epoch: 6| Step: 3
Training loss: 2.0911643505096436
Validation loss: 1.9755741960258895

Epoch: 6| Step: 4
Training loss: 1.872694969177246
Validation loss: 1.965799141955632

Epoch: 6| Step: 5
Training loss: 1.7817058563232422
Validation loss: 1.9744607940796883

Epoch: 6| Step: 6
Training loss: 2.0689845085144043
Validation loss: 1.9677848598008514

Epoch: 6| Step: 7
Training loss: 1.7187185287475586
Validation loss: 1.9634476272008752

Epoch: 6| Step: 8
Training loss: 1.6513214111328125
Validation loss: 1.9811543290333082

Epoch: 6| Step: 9
Training loss: 1.7520577907562256
Validation loss: 1.9759417426201604

Epoch: 6| Step: 10
Training loss: 2.0287089347839355
Validation loss: 1.9693513685657131

Epoch: 6| Step: 11
Training loss: 2.238471031188965
Validation loss: 1.9628145438368603

Epoch: 6| Step: 12
Training loss: 1.9090867042541504
Validation loss: 1.9418901256335679

Epoch: 6| Step: 13
Training loss: 2.631012439727783
Validation loss: 1.936074964461788

Epoch: 107| Step: 0
Training loss: 1.8534828424453735
Validation loss: 1.942531519038703

Epoch: 6| Step: 1
Training loss: 2.2635204792022705
Validation loss: 1.9377273808243454

Epoch: 6| Step: 2
Training loss: 2.7866697311401367
Validation loss: 1.9374321378687376

Epoch: 6| Step: 3
Training loss: 1.7275904417037964
Validation loss: 1.9538714026892057

Epoch: 6| Step: 4
Training loss: 2.5182900428771973
Validation loss: 1.9416769832693122

Epoch: 6| Step: 5
Training loss: 2.15382719039917
Validation loss: 1.942014915968782

Epoch: 6| Step: 6
Training loss: 2.140291452407837
Validation loss: 1.928902131254955

Epoch: 6| Step: 7
Training loss: 1.4049768447875977
Validation loss: 1.9351586936622538

Epoch: 6| Step: 8
Training loss: 1.5976662635803223
Validation loss: 1.9315416787260322

Epoch: 6| Step: 9
Training loss: 1.5060443878173828
Validation loss: 1.9366972600260088

Epoch: 6| Step: 10
Training loss: 1.881392002105713
Validation loss: 1.987276433616556

Epoch: 6| Step: 11
Training loss: 3.1711220741271973
Validation loss: 2.0030220964903473

Epoch: 6| Step: 12
Training loss: 2.05301570892334
Validation loss: 2.013824893582252

Epoch: 6| Step: 13
Training loss: 2.4191153049468994
Validation loss: 1.9805171797352452

Epoch: 108| Step: 0
Training loss: 2.5461068153381348
Validation loss: 1.9518617750495992

Epoch: 6| Step: 1
Training loss: 1.4832122325897217
Validation loss: 1.9324604234387797

Epoch: 6| Step: 2
Training loss: 2.1934518814086914
Validation loss: 1.9362825424440446

Epoch: 6| Step: 3
Training loss: 1.5198028087615967
Validation loss: 1.9591159884647658

Epoch: 6| Step: 4
Training loss: 1.971323013305664
Validation loss: 1.9896298890472741

Epoch: 6| Step: 5
Training loss: 2.3803882598876953
Validation loss: 2.0312528456411054

Epoch: 6| Step: 6
Training loss: 2.0441009998321533
Validation loss: 2.040735683133525

Epoch: 6| Step: 7
Training loss: 2.48757266998291
Validation loss: 2.0573802122505764

Epoch: 6| Step: 8
Training loss: 2.0194668769836426
Validation loss: 2.065387741211922

Epoch: 6| Step: 9
Training loss: 2.700399398803711
Validation loss: 2.0284704662138417

Epoch: 6| Step: 10
Training loss: 2.1018831729888916
Validation loss: 1.981437558768898

Epoch: 6| Step: 11
Training loss: 2.169668674468994
Validation loss: 1.9714472447672198

Epoch: 6| Step: 12
Training loss: 2.028764247894287
Validation loss: 1.9664840839242423

Epoch: 6| Step: 13
Training loss: 2.939265251159668
Validation loss: 1.9887515139836136

Epoch: 109| Step: 0
Training loss: 2.1847453117370605
Validation loss: 1.9635757412961734

Epoch: 6| Step: 1
Training loss: 2.07222318649292
Validation loss: 1.9588026180062243

Epoch: 6| Step: 2
Training loss: 1.8135278224945068
Validation loss: 1.9448528212885703

Epoch: 6| Step: 3
Training loss: 1.992962121963501
Validation loss: 1.9178590953990977

Epoch: 6| Step: 4
Training loss: 2.302738666534424
Validation loss: 1.907532238191174

Epoch: 6| Step: 5
Training loss: 1.843351125717163
Validation loss: 1.903236545542235

Epoch: 6| Step: 6
Training loss: 2.3797366619110107
Validation loss: 1.8930750739189885

Epoch: 6| Step: 7
Training loss: 2.778489589691162
Validation loss: 1.8994530016376125

Epoch: 6| Step: 8
Training loss: 2.293720245361328
Validation loss: 1.8936440034579205

Epoch: 6| Step: 9
Training loss: 2.2906289100646973
Validation loss: 1.891532685167046

Epoch: 6| Step: 10
Training loss: 1.8014118671417236
Validation loss: 1.8879416732377903

Epoch: 6| Step: 11
Training loss: 1.7491034269332886
Validation loss: 1.8919004189070834

Epoch: 6| Step: 12
Training loss: 1.8714102506637573
Validation loss: 1.8869716275122859

Epoch: 6| Step: 13
Training loss: 2.14865779876709
Validation loss: 1.8858131157454623

Epoch: 110| Step: 0
Training loss: 2.347179889678955
Validation loss: 1.8822379778790217

Epoch: 6| Step: 1
Training loss: 1.264810562133789
Validation loss: 1.8929484134079309

Epoch: 6| Step: 2
Training loss: 2.0915796756744385
Validation loss: 1.8966945063683294

Epoch: 6| Step: 3
Training loss: 2.1273252964019775
Validation loss: 1.9021718386680848

Epoch: 6| Step: 4
Training loss: 2.5661559104919434
Validation loss: 1.9026828171104513

Epoch: 6| Step: 5
Training loss: 2.7780327796936035
Validation loss: 1.9009023815072992

Epoch: 6| Step: 6
Training loss: 1.7082672119140625
Validation loss: 1.908595387653638

Epoch: 6| Step: 7
Training loss: 1.388143539428711
Validation loss: 1.9136227689763552

Epoch: 6| Step: 8
Training loss: 1.932798147201538
Validation loss: 1.9382600784301758

Epoch: 6| Step: 9
Training loss: 1.7469112873077393
Validation loss: 1.9388131582608787

Epoch: 6| Step: 10
Training loss: 1.9768965244293213
Validation loss: 1.9429854193041403

Epoch: 6| Step: 11
Training loss: 1.9269859790802002
Validation loss: 1.9385427595466695

Epoch: 6| Step: 12
Training loss: 2.5913572311401367
Validation loss: 1.9442532818804505

Epoch: 6| Step: 13
Training loss: 2.477008819580078
Validation loss: 1.9588049624555854

Epoch: 111| Step: 0
Training loss: 1.7259272336959839
Validation loss: 1.9492115436061737

Epoch: 6| Step: 1
Training loss: 2.0301151275634766
Validation loss: 1.944546599541941

Epoch: 6| Step: 2
Training loss: 2.3407034873962402
Validation loss: 1.9262589716142224

Epoch: 6| Step: 3
Training loss: 1.9048948287963867
Validation loss: 1.9063671494043002

Epoch: 6| Step: 4
Training loss: 1.7956602573394775
Validation loss: 1.9055893164809032

Epoch: 6| Step: 5
Training loss: 1.9296318292617798
Validation loss: 1.8971441740630774

Epoch: 6| Step: 6
Training loss: 2.104630470275879
Validation loss: 1.8879098840939101

Epoch: 6| Step: 7
Training loss: 2.4631505012512207
Validation loss: 1.887618572481217

Epoch: 6| Step: 8
Training loss: 2.408322811126709
Validation loss: 1.894362998265092

Epoch: 6| Step: 9
Training loss: 1.8424235582351685
Validation loss: 1.8923650659540647

Epoch: 6| Step: 10
Training loss: 1.806204915046692
Validation loss: 1.8909062749596053

Epoch: 6| Step: 11
Training loss: 2.3162431716918945
Validation loss: 1.9008299214865572

Epoch: 6| Step: 12
Training loss: 2.217818021774292
Validation loss: 1.9183496454710602

Epoch: 6| Step: 13
Training loss: 1.8123327493667603
Validation loss: 1.962310721797328

Epoch: 112| Step: 0
Training loss: 1.839839220046997
Validation loss: 1.9753003607514084

Epoch: 6| Step: 1
Training loss: 1.4427037239074707
Validation loss: 1.985366585434124

Epoch: 6| Step: 2
Training loss: 2.003666639328003
Validation loss: 2.00950026512146

Epoch: 6| Step: 3
Training loss: 2.0460472106933594
Validation loss: 2.009532563148006

Epoch: 6| Step: 4
Training loss: 2.0045483112335205
Validation loss: 1.994062034032678

Epoch: 6| Step: 5
Training loss: 2.399749279022217
Validation loss: 1.9944063412245883

Epoch: 6| Step: 6
Training loss: 2.273113965988159
Validation loss: 1.998335305080619

Epoch: 6| Step: 7
Training loss: 2.1289682388305664
Validation loss: 1.9975595833152853

Epoch: 6| Step: 8
Training loss: 2.005526542663574
Validation loss: 2.005706197472029

Epoch: 6| Step: 9
Training loss: 2.7808587551116943
Validation loss: 2.002499116364346

Epoch: 6| Step: 10
Training loss: 1.5378217697143555
Validation loss: 2.0009122484473774

Epoch: 6| Step: 11
Training loss: 1.607936143875122
Validation loss: 2.0143646476089314

Epoch: 6| Step: 12
Training loss: 2.7833170890808105
Validation loss: 2.007901303229793

Epoch: 6| Step: 13
Training loss: 1.8522300720214844
Validation loss: 1.9869732600386425

Epoch: 113| Step: 0
Training loss: 2.2332358360290527
Validation loss: 1.959211503305743

Epoch: 6| Step: 1
Training loss: 2.4126858711242676
Validation loss: 1.9230284165310603

Epoch: 6| Step: 2
Training loss: 2.1087255477905273
Validation loss: 1.9068829039091706

Epoch: 6| Step: 3
Training loss: 1.8613728284835815
Validation loss: 1.9266737327780774

Epoch: 6| Step: 4
Training loss: 1.8774367570877075
Validation loss: 1.9113245484649495

Epoch: 6| Step: 5
Training loss: 2.5116050243377686
Validation loss: 1.922906893555836

Epoch: 6| Step: 6
Training loss: 2.42734432220459
Validation loss: 1.9253747540135537

Epoch: 6| Step: 7
Training loss: 2.729616641998291
Validation loss: 1.9481979070171234

Epoch: 6| Step: 8
Training loss: 2.067610740661621
Validation loss: 1.9780758555217455

Epoch: 6| Step: 9
Training loss: 1.8424046039581299
Validation loss: 1.9733089272693922

Epoch: 6| Step: 10
Training loss: 1.64211106300354
Validation loss: 1.943046522396867

Epoch: 6| Step: 11
Training loss: 1.4807456731796265
Validation loss: 1.9447137117385864

Epoch: 6| Step: 12
Training loss: 2.179664134979248
Validation loss: 1.9372024574587423

Epoch: 6| Step: 13
Training loss: 1.5973800420761108
Validation loss: 1.9118528058451991

Epoch: 114| Step: 0
Training loss: 1.8713918924331665
Validation loss: 1.891556268097252

Epoch: 6| Step: 1
Training loss: 2.5809149742126465
Validation loss: 1.8914505794484129

Epoch: 6| Step: 2
Training loss: 1.7786134481430054
Validation loss: 1.8823557669116604

Epoch: 6| Step: 3
Training loss: 1.9158387184143066
Validation loss: 1.8992230610180927

Epoch: 6| Step: 4
Training loss: 2.866995096206665
Validation loss: 1.8892980826798307

Epoch: 6| Step: 5
Training loss: 1.9275519847869873
Validation loss: 1.9056134582847677

Epoch: 6| Step: 6
Training loss: 2.5764870643615723
Validation loss: 1.8892774556272773

Epoch: 6| Step: 7
Training loss: 1.15016770362854
Validation loss: 1.9042270234836045

Epoch: 6| Step: 8
Training loss: 2.041384220123291
Validation loss: 1.9114132081308672

Epoch: 6| Step: 9
Training loss: 1.9012277126312256
Validation loss: 1.9113426362314532

Epoch: 6| Step: 10
Training loss: 2.1592774391174316
Validation loss: 1.9234732427904684

Epoch: 6| Step: 11
Training loss: 1.6487975120544434
Validation loss: 1.9229223241088211

Epoch: 6| Step: 12
Training loss: 2.555647373199463
Validation loss: 1.9287770486647082

Epoch: 6| Step: 13
Training loss: 1.4622191190719604
Validation loss: 1.9179949862982637

Epoch: 115| Step: 0
Training loss: 2.551283836364746
Validation loss: 1.9054878142572218

Epoch: 6| Step: 1
Training loss: 1.7163710594177246
Validation loss: 1.9032460361398675

Epoch: 6| Step: 2
Training loss: 1.5787990093231201
Validation loss: 1.9031174900711223

Epoch: 6| Step: 3
Training loss: 2.5316362380981445
Validation loss: 1.9145629380338935

Epoch: 6| Step: 4
Training loss: 1.341927409172058
Validation loss: 1.9142474500081872

Epoch: 6| Step: 5
Training loss: 2.021169662475586
Validation loss: 1.9340500639330955

Epoch: 6| Step: 6
Training loss: 2.3978145122528076
Validation loss: 1.9436635650614256

Epoch: 6| Step: 7
Training loss: 3.003239631652832
Validation loss: 1.9537458368526992

Epoch: 6| Step: 8
Training loss: 1.4070773124694824
Validation loss: 1.9510837601077171

Epoch: 6| Step: 9
Training loss: 2.1973354816436768
Validation loss: 1.9463853323331444

Epoch: 6| Step: 10
Training loss: 2.082650661468506
Validation loss: 1.934439759100637

Epoch: 6| Step: 11
Training loss: 2.205853223800659
Validation loss: 1.920804440334279

Epoch: 6| Step: 12
Training loss: 1.6203970909118652
Validation loss: 1.939956126674529

Epoch: 6| Step: 13
Training loss: 1.6305060386657715
Validation loss: 1.9381348779124599

Epoch: 116| Step: 0
Training loss: 1.995382308959961
Validation loss: 1.9336123287036855

Epoch: 6| Step: 1
Training loss: 2.169135570526123
Validation loss: 1.9380440147974158

Epoch: 6| Step: 2
Training loss: 1.801998257637024
Validation loss: 1.9500219745020713

Epoch: 6| Step: 3
Training loss: 2.3177573680877686
Validation loss: 1.9583424675849177

Epoch: 6| Step: 4
Training loss: 1.824594259262085
Validation loss: 1.966669209541813

Epoch: 6| Step: 5
Training loss: 2.608936309814453
Validation loss: 1.970503557112909

Epoch: 6| Step: 6
Training loss: 2.258366584777832
Validation loss: 1.9556779220540037

Epoch: 6| Step: 7
Training loss: 2.0528621673583984
Validation loss: 1.9289359379840154

Epoch: 6| Step: 8
Training loss: 2.2559597492218018
Validation loss: 1.9114203786337247

Epoch: 6| Step: 9
Training loss: 1.6951271295547485
Validation loss: 1.9342580969615648

Epoch: 6| Step: 10
Training loss: 2.2944936752319336
Validation loss: 1.9607103255487257

Epoch: 6| Step: 11
Training loss: 2.435153007507324
Validation loss: 1.9857992536278182

Epoch: 6| Step: 12
Training loss: 1.3676300048828125
Validation loss: 1.9916452976965136

Epoch: 6| Step: 13
Training loss: 1.2187265157699585
Validation loss: 1.9903661768923524

Epoch: 117| Step: 0
Training loss: 2.3891265392303467
Validation loss: 1.982879223362092

Epoch: 6| Step: 1
Training loss: 2.1592392921447754
Validation loss: 1.9615103737000497

Epoch: 6| Step: 2
Training loss: 1.7598907947540283
Validation loss: 1.9401299799642255

Epoch: 6| Step: 3
Training loss: 1.5962711572647095
Validation loss: 1.9174643229412776

Epoch: 6| Step: 4
Training loss: 2.1856400966644287
Validation loss: 1.9159684963123773

Epoch: 6| Step: 5
Training loss: 1.815699577331543
Validation loss: 1.922006280191483

Epoch: 6| Step: 6
Training loss: 1.4440159797668457
Validation loss: 1.9327311925990607

Epoch: 6| Step: 7
Training loss: 2.2726662158966064
Validation loss: 1.924714724222819

Epoch: 6| Step: 8
Training loss: 2.4797632694244385
Validation loss: 1.940849898963846

Epoch: 6| Step: 9
Training loss: 2.570068836212158
Validation loss: 1.9359670467274164

Epoch: 6| Step: 10
Training loss: 1.8376575708389282
Validation loss: 1.9344167337622693

Epoch: 6| Step: 11
Training loss: 2.300724983215332
Validation loss: 1.938711856001167

Epoch: 6| Step: 12
Training loss: 1.1082953214645386
Validation loss: 1.9509014801312519

Epoch: 6| Step: 13
Training loss: 2.6189932823181152
Validation loss: 1.9670547721206502

Epoch: 118| Step: 0
Training loss: 1.5605132579803467
Validation loss: 1.967236513732582

Epoch: 6| Step: 1
Training loss: 2.3533310890197754
Validation loss: 1.9671353306821597

Epoch: 6| Step: 2
Training loss: 2.2087278366088867
Validation loss: 1.9631854270094184

Epoch: 6| Step: 3
Training loss: 2.3896727561950684
Validation loss: 1.9533982212825487

Epoch: 6| Step: 4
Training loss: 1.859673261642456
Validation loss: 1.9558727869423487

Epoch: 6| Step: 5
Training loss: 2.153170585632324
Validation loss: 1.9450774987538655

Epoch: 6| Step: 6
Training loss: 2.470832347869873
Validation loss: 1.9455036142820954

Epoch: 6| Step: 7
Training loss: 2.381834030151367
Validation loss: 1.9382146994272869

Epoch: 6| Step: 8
Training loss: 2.361090898513794
Validation loss: 1.9315526254715458

Epoch: 6| Step: 9
Training loss: 1.3433549404144287
Validation loss: 1.9089982509613037

Epoch: 6| Step: 10
Training loss: 1.3531761169433594
Validation loss: 1.9099713640828286

Epoch: 6| Step: 11
Training loss: 1.5596470832824707
Validation loss: 1.9051742476801719

Epoch: 6| Step: 12
Training loss: 1.9832289218902588
Validation loss: 1.901225354081841

Epoch: 6| Step: 13
Training loss: 2.1432180404663086
Validation loss: 1.8985968559019026

Epoch: 119| Step: 0
Training loss: 2.0610060691833496
Validation loss: 1.8891339378972207

Epoch: 6| Step: 1
Training loss: 1.6757652759552002
Validation loss: 1.866816778336802

Epoch: 6| Step: 2
Training loss: 1.9321948289871216
Validation loss: 1.867272852569498

Epoch: 6| Step: 3
Training loss: 2.3330769538879395
Validation loss: 1.8586342206565283

Epoch: 6| Step: 4
Training loss: 2.290437698364258
Validation loss: 1.873068041698907

Epoch: 6| Step: 5
Training loss: 1.8467895984649658
Validation loss: 1.883701027080577

Epoch: 6| Step: 6
Training loss: 2.2770097255706787
Validation loss: 1.8857026805159867

Epoch: 6| Step: 7
Training loss: 1.8170619010925293
Validation loss: 1.8807429023968276

Epoch: 6| Step: 8
Training loss: 2.2027018070220947
Validation loss: 1.8830405742891374

Epoch: 6| Step: 9
Training loss: 1.8093210458755493
Validation loss: 1.8852085887744863

Epoch: 6| Step: 10
Training loss: 2.103639602661133
Validation loss: 1.8838176265839608

Epoch: 6| Step: 11
Training loss: 1.6243550777435303
Validation loss: 1.9146076389538345

Epoch: 6| Step: 12
Training loss: 2.495959520339966
Validation loss: 1.9466279219555598

Epoch: 6| Step: 13
Training loss: 1.720003604888916
Validation loss: 1.9797969248987013

Epoch: 120| Step: 0
Training loss: 2.7451062202453613
Validation loss: 1.978739946119247

Epoch: 6| Step: 1
Training loss: 1.7956331968307495
Validation loss: 1.9759434602593864

Epoch: 6| Step: 2
Training loss: 1.359358787536621
Validation loss: 1.9739522792959725

Epoch: 6| Step: 3
Training loss: 1.995231032371521
Validation loss: 1.9721789308773574

Epoch: 6| Step: 4
Training loss: 1.802201747894287
Validation loss: 1.9766305941407398

Epoch: 6| Step: 5
Training loss: 1.5059213638305664
Validation loss: 1.9564276062032229

Epoch: 6| Step: 6
Training loss: 1.8196110725402832
Validation loss: 1.9565182103905627

Epoch: 6| Step: 7
Training loss: 2.213832378387451
Validation loss: 1.9604643083387805

Epoch: 6| Step: 8
Training loss: 2.036532402038574
Validation loss: 1.9516007618237567

Epoch: 6| Step: 9
Training loss: 2.677424907684326
Validation loss: 1.9618796328062653

Epoch: 6| Step: 10
Training loss: 2.4778151512145996
Validation loss: 1.9730332090008644

Epoch: 6| Step: 11
Training loss: 2.139878273010254
Validation loss: 1.977046379479029

Epoch: 6| Step: 12
Training loss: 1.7207794189453125
Validation loss: 1.9874215100401191

Epoch: 6| Step: 13
Training loss: 1.3726533651351929
Validation loss: 1.9767384606022989

Epoch: 121| Step: 0
Training loss: 1.8987783193588257
Validation loss: 1.96728729432629

Epoch: 6| Step: 1
Training loss: 2.127375364303589
Validation loss: 1.946827534706362

Epoch: 6| Step: 2
Training loss: 2.1389365196228027
Validation loss: 1.9489337346887077

Epoch: 6| Step: 3
Training loss: 1.7273136377334595
Validation loss: 1.9480116341703682

Epoch: 6| Step: 4
Training loss: 2.6394803524017334
Validation loss: 1.940573125757197

Epoch: 6| Step: 5
Training loss: 1.2650115489959717
Validation loss: 1.9418929187200402

Epoch: 6| Step: 6
Training loss: 1.499969482421875
Validation loss: 1.9455559279329033

Epoch: 6| Step: 7
Training loss: 1.9123820066452026
Validation loss: 1.95912613150894

Epoch: 6| Step: 8
Training loss: 1.3731117248535156
Validation loss: 1.958028644643804

Epoch: 6| Step: 9
Training loss: 2.2163500785827637
Validation loss: 1.9570318704010339

Epoch: 6| Step: 10
Training loss: 2.5660884380340576
Validation loss: 1.9588630096886748

Epoch: 6| Step: 11
Training loss: 2.5559544563293457
Validation loss: 1.9570378744474022

Epoch: 6| Step: 12
Training loss: 1.7572855949401855
Validation loss: 1.9402408548580703

Epoch: 6| Step: 13
Training loss: 1.760075330734253
Validation loss: 1.9508932854539605

Epoch: 122| Step: 0
Training loss: 2.191136360168457
Validation loss: 1.956469610173215

Epoch: 6| Step: 1
Training loss: 2.4246010780334473
Validation loss: 1.9874138293727752

Epoch: 6| Step: 2
Training loss: 1.9062459468841553
Validation loss: 2.004851006692456

Epoch: 6| Step: 3
Training loss: 2.0416903495788574
Validation loss: 2.007792506166684

Epoch: 6| Step: 4
Training loss: 2.155154228210449
Validation loss: 2.005634207879343

Epoch: 6| Step: 5
Training loss: 1.8656868934631348
Validation loss: 1.9905685558114001

Epoch: 6| Step: 6
Training loss: 2.454636812210083
Validation loss: 1.9619552678959344

Epoch: 6| Step: 7
Training loss: 2.488973617553711
Validation loss: 1.963843281551074

Epoch: 6| Step: 8
Training loss: 1.537904977798462
Validation loss: 1.9581145009686869

Epoch: 6| Step: 9
Training loss: 1.266864538192749
Validation loss: 1.946397086625458

Epoch: 6| Step: 10
Training loss: 2.148393154144287
Validation loss: 1.9536770184834797

Epoch: 6| Step: 11
Training loss: 1.6258575916290283
Validation loss: 1.9593775208278368

Epoch: 6| Step: 12
Training loss: 2.018827438354492
Validation loss: 1.9560021815761444

Epoch: 6| Step: 13
Training loss: 1.794920802116394
Validation loss: 1.9618748721256052

Epoch: 123| Step: 0
Training loss: 2.1163651943206787
Validation loss: 1.950619561697847

Epoch: 6| Step: 1
Training loss: 1.7876204252243042
Validation loss: 1.9548503557840984

Epoch: 6| Step: 2
Training loss: 3.021951198577881
Validation loss: 1.9377854229301534

Epoch: 6| Step: 3
Training loss: 1.9947681427001953
Validation loss: 1.9324413217524046

Epoch: 6| Step: 4
Training loss: 1.9718437194824219
Validation loss: 1.9136702873373543

Epoch: 6| Step: 5
Training loss: 1.5183792114257812
Validation loss: 1.9216083301010953

Epoch: 6| Step: 6
Training loss: 2.456979990005493
Validation loss: 1.9331152849299933

Epoch: 6| Step: 7
Training loss: 0.9688314199447632
Validation loss: 1.9382857199638122

Epoch: 6| Step: 8
Training loss: 1.7300770282745361
Validation loss: 1.9285040465734338

Epoch: 6| Step: 9
Training loss: 2.891641139984131
Validation loss: 1.9212315056913642

Epoch: 6| Step: 10
Training loss: 1.121683120727539
Validation loss: 1.9262946280100013

Epoch: 6| Step: 11
Training loss: 2.162304639816284
Validation loss: 1.941976067840412

Epoch: 6| Step: 12
Training loss: 1.7348651885986328
Validation loss: 1.9466697144251999

Epoch: 6| Step: 13
Training loss: 2.218623638153076
Validation loss: 1.9503186107963644

Epoch: 124| Step: 0
Training loss: 1.640122890472412
Validation loss: 1.954055893805719

Epoch: 6| Step: 1
Training loss: 1.7435588836669922
Validation loss: 1.947603484635712

Epoch: 6| Step: 2
Training loss: 2.1200478076934814
Validation loss: 1.9309773496402207

Epoch: 6| Step: 3
Training loss: 1.7500011920928955
Validation loss: 1.9375637590244252

Epoch: 6| Step: 4
Training loss: 1.756317138671875
Validation loss: 1.9324729211868779

Epoch: 6| Step: 5
Training loss: 1.8599343299865723
Validation loss: 1.9407617020350632

Epoch: 6| Step: 6
Training loss: 1.7341735363006592
Validation loss: 1.9450334195167787

Epoch: 6| Step: 7
Training loss: 2.496265411376953
Validation loss: 1.9580255528931976

Epoch: 6| Step: 8
Training loss: 1.519559383392334
Validation loss: 1.969298125595175

Epoch: 6| Step: 9
Training loss: 2.478085994720459
Validation loss: 1.9878472051312845

Epoch: 6| Step: 10
Training loss: 2.268977642059326
Validation loss: 1.9943272823928504

Epoch: 6| Step: 11
Training loss: 1.7363314628601074
Validation loss: 2.005192638725363

Epoch: 6| Step: 12
Training loss: 2.2934370040893555
Validation loss: 2.012216220619858

Epoch: 6| Step: 13
Training loss: 2.8193726539611816
Validation loss: 1.9992188445983394

Epoch: 125| Step: 0
Training loss: 2.089848518371582
Validation loss: 1.9956006849965742

Epoch: 6| Step: 1
Training loss: 2.230910539627075
Validation loss: 2.005515356217661

Epoch: 6| Step: 2
Training loss: 1.788087248802185
Validation loss: 1.994633484912175

Epoch: 6| Step: 3
Training loss: 2.1877026557922363
Validation loss: 2.0182606327918267

Epoch: 6| Step: 4
Training loss: 1.9188461303710938
Validation loss: 2.0314222356324554

Epoch: 6| Step: 5
Training loss: 2.3325347900390625
Validation loss: 2.0499382531771095

Epoch: 6| Step: 6
Training loss: 1.456711769104004
Validation loss: 2.0172425098316644

Epoch: 6| Step: 7
Training loss: 1.7183059453964233
Validation loss: 1.971513996842087

Epoch: 6| Step: 8
Training loss: 2.074936866760254
Validation loss: 1.9350607574626963

Epoch: 6| Step: 9
Training loss: 2.138310432434082
Validation loss: 1.8769912130089217

Epoch: 6| Step: 10
Training loss: 1.5587046146392822
Validation loss: 1.8654937128866873

Epoch: 6| Step: 11
Training loss: 1.8107441663742065
Validation loss: 1.8729658819014026

Epoch: 6| Step: 12
Training loss: 2.572995185852051
Validation loss: 1.8859112775453957

Epoch: 6| Step: 13
Training loss: 2.0828664302825928
Validation loss: 1.882306163029004

Epoch: 126| Step: 0
Training loss: 1.5170035362243652
Validation loss: 1.8841058310642038

Epoch: 6| Step: 1
Training loss: 1.9314374923706055
Validation loss: 1.8953416270594443

Epoch: 6| Step: 2
Training loss: 2.383200168609619
Validation loss: 1.9022050544779787

Epoch: 6| Step: 3
Training loss: 1.5649561882019043
Validation loss: 1.9018019066062024

Epoch: 6| Step: 4
Training loss: 2.0272014141082764
Validation loss: 1.9035893447937504

Epoch: 6| Step: 5
Training loss: 1.694231629371643
Validation loss: 1.9049269512135496

Epoch: 6| Step: 6
Training loss: 1.6953877210617065
Validation loss: 1.9034309335934219

Epoch: 6| Step: 7
Training loss: 1.5631978511810303
Validation loss: 1.903335384143296

Epoch: 6| Step: 8
Training loss: 2.2831296920776367
Validation loss: 1.9153244944028958

Epoch: 6| Step: 9
Training loss: 2.7142834663391113
Validation loss: 1.9297289591963573

Epoch: 6| Step: 10
Training loss: 2.2565512657165527
Validation loss: 1.9198983330880441

Epoch: 6| Step: 11
Training loss: 1.8165397644042969
Validation loss: 1.9300822237486481

Epoch: 6| Step: 12
Training loss: 2.0918445587158203
Validation loss: 1.9594447382034794

Epoch: 6| Step: 13
Training loss: 1.4495718479156494
Validation loss: 1.9773069812405495

Epoch: 127| Step: 0
Training loss: 1.3451597690582275
Validation loss: 1.9681948256748978

Epoch: 6| Step: 1
Training loss: 2.095958948135376
Validation loss: 1.9775854951591902

Epoch: 6| Step: 2
Training loss: 1.6363712549209595
Validation loss: 1.962634103272551

Epoch: 6| Step: 3
Training loss: 1.6369504928588867
Validation loss: 1.966769132562863

Epoch: 6| Step: 4
Training loss: 1.5844838619232178
Validation loss: 1.9793293078740437

Epoch: 6| Step: 5
Training loss: 2.5119471549987793
Validation loss: 1.9884781632372128

Epoch: 6| Step: 6
Training loss: 1.201744794845581
Validation loss: 1.9739727076663767

Epoch: 6| Step: 7
Training loss: 2.2719593048095703
Validation loss: 1.9854660751999065

Epoch: 6| Step: 8
Training loss: 1.6777682304382324
Validation loss: 1.9677465295278898

Epoch: 6| Step: 9
Training loss: 2.585202693939209
Validation loss: 1.960322497993387

Epoch: 6| Step: 10
Training loss: 2.882603883743286
Validation loss: 1.9518595023821759

Epoch: 6| Step: 11
Training loss: 1.5806254148483276
Validation loss: 1.9702165229346162

Epoch: 6| Step: 12
Training loss: 1.7079150676727295
Validation loss: 1.936809661567852

Epoch: 6| Step: 13
Training loss: 1.9757366180419922
Validation loss: 1.924806748667071

Epoch: 128| Step: 0
Training loss: 2.5150704383850098
Validation loss: 1.9100708038576188

Epoch: 6| Step: 1
Training loss: 1.825223684310913
Validation loss: 1.8851545023661789

Epoch: 6| Step: 2
Training loss: 2.4089858531951904
Validation loss: 1.8867556382251043

Epoch: 6| Step: 3
Training loss: 1.7421693801879883
Validation loss: 1.9100991449048441

Epoch: 6| Step: 4
Training loss: 1.6932344436645508
Validation loss: 1.935916059760637

Epoch: 6| Step: 5
Training loss: 1.646470546722412
Validation loss: 1.9383454489451584

Epoch: 6| Step: 6
Training loss: 2.188962936401367
Validation loss: 1.9504017624803769

Epoch: 6| Step: 7
Training loss: 1.6759943962097168
Validation loss: 1.942874575173983

Epoch: 6| Step: 8
Training loss: 1.441500186920166
Validation loss: 1.9396529787330217

Epoch: 6| Step: 9
Training loss: 1.97334885597229
Validation loss: 1.9425594101669967

Epoch: 6| Step: 10
Training loss: 2.1015357971191406
Validation loss: 1.939942729088568

Epoch: 6| Step: 11
Training loss: 1.7587487697601318
Validation loss: 1.9383452041174776

Epoch: 6| Step: 12
Training loss: 2.010868549346924
Validation loss: 1.9367878552406066

Epoch: 6| Step: 13
Training loss: 1.811981201171875
Validation loss: 1.9859496944694108

Epoch: 129| Step: 0
Training loss: 2.3956704139709473
Validation loss: 2.0044481062120005

Epoch: 6| Step: 1
Training loss: 1.9477490186691284
Validation loss: 1.9840265345829788

Epoch: 6| Step: 2
Training loss: 1.8305962085723877
Validation loss: 1.9535728090552873

Epoch: 6| Step: 3
Training loss: 2.04398250579834
Validation loss: 1.917134000409034

Epoch: 6| Step: 4
Training loss: 1.3508579730987549
Validation loss: 1.8998596014515046

Epoch: 6| Step: 5
Training loss: 1.426066279411316
Validation loss: 1.9245077781779791

Epoch: 6| Step: 6
Training loss: 1.7225509881973267
Validation loss: 1.9429535071055095

Epoch: 6| Step: 7
Training loss: 1.8708117008209229
Validation loss: 1.9654551090732697

Epoch: 6| Step: 8
Training loss: 1.6172308921813965
Validation loss: 1.9682606599664176

Epoch: 6| Step: 9
Training loss: 2.556039571762085
Validation loss: 1.966921289761861

Epoch: 6| Step: 10
Training loss: 2.2616689205169678
Validation loss: 1.9565642110763057

Epoch: 6| Step: 11
Training loss: 2.0034561157226562
Validation loss: 1.9474941556171705

Epoch: 6| Step: 12
Training loss: 2.347013473510742
Validation loss: 1.9411372766699841

Epoch: 6| Step: 13
Training loss: 1.7381738424301147
Validation loss: 1.95355861930437

Epoch: 130| Step: 0
Training loss: 1.4019551277160645
Validation loss: 1.9444711541616788

Epoch: 6| Step: 1
Training loss: 2.1796154975891113
Validation loss: 1.9481334711915703

Epoch: 6| Step: 2
Training loss: 1.5188372135162354
Validation loss: 1.947642252009402

Epoch: 6| Step: 3
Training loss: 1.8936781883239746
Validation loss: 1.9429988322719451

Epoch: 6| Step: 4
Training loss: 2.1706466674804688
Validation loss: 1.9305021903848136

Epoch: 6| Step: 5
Training loss: 1.6094105243682861
Validation loss: 1.9278941692844513

Epoch: 6| Step: 6
Training loss: 2.054814577102661
Validation loss: 1.9439434492459862

Epoch: 6| Step: 7
Training loss: 1.6455624103546143
Validation loss: 1.9443463945901522

Epoch: 6| Step: 8
Training loss: 1.6054048538208008
Validation loss: 1.9420000609531198

Epoch: 6| Step: 9
Training loss: 1.9463998079299927
Validation loss: 1.9583698626487487

Epoch: 6| Step: 10
Training loss: 1.8142497539520264
Validation loss: 1.9863951052388837

Epoch: 6| Step: 11
Training loss: 2.211867332458496
Validation loss: 1.9784035259677517

Epoch: 6| Step: 12
Training loss: 2.4727301597595215
Validation loss: 1.9693436520074004

Epoch: 6| Step: 13
Training loss: 2.2780003547668457
Validation loss: 1.943329514995698

Epoch: 131| Step: 0
Training loss: 1.5915732383728027
Validation loss: 1.9145659759480467

Epoch: 6| Step: 1
Training loss: 1.4598578214645386
Validation loss: 1.9091971561472902

Epoch: 6| Step: 2
Training loss: 2.393221378326416
Validation loss: 1.9154869164189985

Epoch: 6| Step: 3
Training loss: 2.4582014083862305
Validation loss: 1.925621368551767

Epoch: 6| Step: 4
Training loss: 1.6496987342834473
Validation loss: 1.9423417878407303

Epoch: 6| Step: 5
Training loss: 1.2616156339645386
Validation loss: 1.9523372047690934

Epoch: 6| Step: 6
Training loss: 1.9675592184066772
Validation loss: 1.9763770334182247

Epoch: 6| Step: 7
Training loss: 1.732486367225647
Validation loss: 1.9684940102279826

Epoch: 6| Step: 8
Training loss: 1.827828288078308
Validation loss: 1.9338633757765575

Epoch: 6| Step: 9
Training loss: 2.518244504928589
Validation loss: 1.9120765206634358

Epoch: 6| Step: 10
Training loss: 2.197878837585449
Validation loss: 1.8827568407981627

Epoch: 6| Step: 11
Training loss: 2.1442184448242188
Validation loss: 1.8792156122064079

Epoch: 6| Step: 12
Training loss: 1.9082612991333008
Validation loss: 1.864995752611468

Epoch: 6| Step: 13
Training loss: 2.13671875
Validation loss: 1.8707657462807112

Epoch: 132| Step: 0
Training loss: 1.7037880420684814
Validation loss: 1.8771672428295176

Epoch: 6| Step: 1
Training loss: 2.182976722717285
Validation loss: 1.887377969680294

Epoch: 6| Step: 2
Training loss: 2.0612785816192627
Validation loss: 1.9233635869077457

Epoch: 6| Step: 3
Training loss: 1.3430052995681763
Validation loss: 1.9270258616375666

Epoch: 6| Step: 4
Training loss: 2.0949783325195312
Validation loss: 1.9329004172355897

Epoch: 6| Step: 5
Training loss: 2.3066935539245605
Validation loss: 1.943410240193849

Epoch: 6| Step: 6
Training loss: 2.1601991653442383
Validation loss: 1.9487514239485546

Epoch: 6| Step: 7
Training loss: 1.0206618309020996
Validation loss: 1.9398597081502278

Epoch: 6| Step: 8
Training loss: 1.5683728456497192
Validation loss: 1.9597013535038117

Epoch: 6| Step: 9
Training loss: 2.263542652130127
Validation loss: 1.9781083445395193

Epoch: 6| Step: 10
Training loss: 2.2170934677124023
Validation loss: 2.0033204875966555

Epoch: 6| Step: 11
Training loss: 1.6989474296569824
Validation loss: 2.0251913403951995

Epoch: 6| Step: 12
Training loss: 1.965017318725586
Validation loss: 2.0171951299072592

Epoch: 6| Step: 13
Training loss: 2.262784481048584
Validation loss: 2.0266811232413016

Epoch: 133| Step: 0
Training loss: 1.928800106048584
Validation loss: 2.032077799561203

Epoch: 6| Step: 1
Training loss: 2.186065673828125
Validation loss: 2.002191420524351

Epoch: 6| Step: 2
Training loss: 2.0338611602783203
Validation loss: 1.9865226514877812

Epoch: 6| Step: 3
Training loss: 1.9382699728012085
Validation loss: 1.9511103912066388

Epoch: 6| Step: 4
Training loss: 1.7827773094177246
Validation loss: 1.9241605817630727

Epoch: 6| Step: 5
Training loss: 1.709031343460083
Validation loss: 1.9144051510800597

Epoch: 6| Step: 6
Training loss: 1.6413177251815796
Validation loss: 1.8913682583839662

Epoch: 6| Step: 7
Training loss: 1.636413812637329
Validation loss: 1.8800284144698933

Epoch: 6| Step: 8
Training loss: 2.0550365447998047
Validation loss: 1.8735129217947684

Epoch: 6| Step: 9
Training loss: 1.5132744312286377
Validation loss: 1.8729846708236202

Epoch: 6| Step: 10
Training loss: 2.1768176555633545
Validation loss: 1.889993695802586

Epoch: 6| Step: 11
Training loss: 1.863507866859436
Validation loss: 1.8850837369118967

Epoch: 6| Step: 12
Training loss: 1.8338558673858643
Validation loss: 1.9021296206340994

Epoch: 6| Step: 13
Training loss: 1.7506471872329712
Validation loss: 1.9112196135264572

Epoch: 134| Step: 0
Training loss: 1.7823858261108398
Validation loss: 1.9276569017799952

Epoch: 6| Step: 1
Training loss: 2.069653034210205
Validation loss: 1.9454184719311294

Epoch: 6| Step: 2
Training loss: 1.617600917816162
Validation loss: 1.949255512606713

Epoch: 6| Step: 3
Training loss: 1.5200892686843872
Validation loss: 1.939115176918686

Epoch: 6| Step: 4
Training loss: 1.900285005569458
Validation loss: 1.9432975271696686

Epoch: 6| Step: 5
Training loss: 1.760899305343628
Validation loss: 1.9574269389593473

Epoch: 6| Step: 6
Training loss: 2.1610498428344727
Validation loss: 1.9615984642377464

Epoch: 6| Step: 7
Training loss: 1.8265209197998047
Validation loss: 1.9694478973265617

Epoch: 6| Step: 8
Training loss: 2.143742084503174
Validation loss: 1.9767702651280228

Epoch: 6| Step: 9
Training loss: 1.9611680507659912
Validation loss: 1.9706819557374524

Epoch: 6| Step: 10
Training loss: 1.846134901046753
Validation loss: 1.9818266655809136

Epoch: 6| Step: 11
Training loss: 1.3495817184448242
Validation loss: 1.9893393836995608

Epoch: 6| Step: 12
Training loss: 2.5934033393859863
Validation loss: 2.00955686261577

Epoch: 6| Step: 13
Training loss: 1.002342700958252
Validation loss: 2.0263331987524547

Epoch: 135| Step: 0
Training loss: 1.929748296737671
Validation loss: 2.0386711782024753

Epoch: 6| Step: 1
Training loss: 1.3910658359527588
Validation loss: 2.0430370812774985

Epoch: 6| Step: 2
Training loss: 2.4735007286071777
Validation loss: 2.030570637795233

Epoch: 6| Step: 3
Training loss: 1.9543753862380981
Validation loss: 2.0252390164200977

Epoch: 6| Step: 4
Training loss: 2.3844027519226074
Validation loss: 2.0183822096035047

Epoch: 6| Step: 5
Training loss: 1.6074215173721313
Validation loss: 2.0123500003609607

Epoch: 6| Step: 6
Training loss: 1.5656800270080566
Validation loss: 2.001097233064713

Epoch: 6| Step: 7
Training loss: 2.1679701805114746
Validation loss: 1.96705703068805

Epoch: 6| Step: 8
Training loss: 1.270190715789795
Validation loss: 1.939811042560044

Epoch: 6| Step: 9
Training loss: 1.8488584756851196
Validation loss: 1.9030777203139437

Epoch: 6| Step: 10
Training loss: 1.4231362342834473
Validation loss: 1.908748080653529

Epoch: 6| Step: 11
Training loss: 1.7781999111175537
Validation loss: 1.9109141647174794

Epoch: 6| Step: 12
Training loss: 1.9862651824951172
Validation loss: 1.9176265283297467

Epoch: 6| Step: 13
Training loss: 2.185805320739746
Validation loss: 1.9131358438922512

Epoch: 136| Step: 0
Training loss: 1.757651925086975
Validation loss: 1.9207913734579598

Epoch: 6| Step: 1
Training loss: 1.9630166292190552
Validation loss: 1.9134469903925413

Epoch: 6| Step: 2
Training loss: 2.130208969116211
Validation loss: 1.9162694087592504

Epoch: 6| Step: 3
Training loss: 1.5286710262298584
Validation loss: 1.9200261100645988

Epoch: 6| Step: 4
Training loss: 2.0080056190490723
Validation loss: 1.9365951438103952

Epoch: 6| Step: 5
Training loss: 1.7619363069534302
Validation loss: 1.9387573324224001

Epoch: 6| Step: 6
Training loss: 1.775862216949463
Validation loss: 1.9532532973956036

Epoch: 6| Step: 7
Training loss: 2.0804243087768555
Validation loss: 1.9750800248115294

Epoch: 6| Step: 8
Training loss: 1.317396879196167
Validation loss: 1.973632941963852

Epoch: 6| Step: 9
Training loss: 2.3817477226257324
Validation loss: 1.9555821559762443

Epoch: 6| Step: 10
Training loss: 2.040809154510498
Validation loss: 1.9530426981628581

Epoch: 6| Step: 11
Training loss: 1.3377165794372559
Validation loss: 1.9408517165850567

Epoch: 6| Step: 12
Training loss: 1.920922875404358
Validation loss: 1.9257511605498612

Epoch: 6| Step: 13
Training loss: 0.9178858995437622
Validation loss: 1.927342027746221

Epoch: 137| Step: 0
Training loss: 1.4553592205047607
Validation loss: 1.908467904213936

Epoch: 6| Step: 1
Training loss: 1.7741053104400635
Validation loss: 1.9039553506399995

Epoch: 6| Step: 2
Training loss: 2.021131753921509
Validation loss: 1.9080166175801268

Epoch: 6| Step: 3
Training loss: 1.8820419311523438
Validation loss: 1.9168534842870568

Epoch: 6| Step: 4
Training loss: 1.8017210960388184
Validation loss: 1.9332205403235652

Epoch: 6| Step: 5
Training loss: 1.9077919721603394
Validation loss: 1.950977410039594

Epoch: 6| Step: 6
Training loss: 1.8050322532653809
Validation loss: 1.969723725831637

Epoch: 6| Step: 7
Training loss: 1.4915196895599365
Validation loss: 1.978616209440334

Epoch: 6| Step: 8
Training loss: 2.3208413124084473
Validation loss: 1.9800331310559345

Epoch: 6| Step: 9
Training loss: 1.2627124786376953
Validation loss: 1.9271161710062334

Epoch: 6| Step: 10
Training loss: 1.4646440744400024
Validation loss: 1.902442575782858

Epoch: 6| Step: 11
Training loss: 1.9738842248916626
Validation loss: 1.8959930583994875

Epoch: 6| Step: 12
Training loss: 1.7260321378707886
Validation loss: 1.9039960420259865

Epoch: 6| Step: 13
Training loss: 2.228698253631592
Validation loss: 1.919321383199384

Epoch: 138| Step: 0
Training loss: 1.895050048828125
Validation loss: 1.9203367758822698

Epoch: 6| Step: 1
Training loss: 2.0555901527404785
Validation loss: 1.9135000423718524

Epoch: 6| Step: 2
Training loss: 1.4663383960723877
Validation loss: 1.921303814457309

Epoch: 6| Step: 3
Training loss: 1.6847009658813477
Validation loss: 1.936289188682392

Epoch: 6| Step: 4
Training loss: 1.4289848804473877
Validation loss: 1.9415535426908923

Epoch: 6| Step: 5
Training loss: 2.116312026977539
Validation loss: 1.949708577125303

Epoch: 6| Step: 6
Training loss: 1.18911874294281
Validation loss: 1.944315084847071

Epoch: 6| Step: 7
Training loss: 1.3221092224121094
Validation loss: 1.9333813446824268

Epoch: 6| Step: 8
Training loss: 2.050565719604492
Validation loss: 1.9267240301255257

Epoch: 6| Step: 9
Training loss: 1.6139990091323853
Validation loss: 1.9118556079044138

Epoch: 6| Step: 10
Training loss: 1.8332111835479736
Validation loss: 1.889423462652391

Epoch: 6| Step: 11
Training loss: 1.4038941860198975
Validation loss: 1.905640056056361

Epoch: 6| Step: 12
Training loss: 2.6871237754821777
Validation loss: 1.948028197852514

Epoch: 6| Step: 13
Training loss: 2.3504018783569336
Validation loss: 1.9812781605669247

Epoch: 139| Step: 0
Training loss: 2.574566125869751
Validation loss: 1.9985522916240077

Epoch: 6| Step: 1
Training loss: 1.2013204097747803
Validation loss: 2.009620210175873

Epoch: 6| Step: 2
Training loss: 1.7909581661224365
Validation loss: 1.9860900422578216

Epoch: 6| Step: 3
Training loss: 2.1315321922302246
Validation loss: 1.9615197373974709

Epoch: 6| Step: 4
Training loss: 1.2961958646774292
Validation loss: 1.9320505626739994

Epoch: 6| Step: 5
Training loss: 2.129096508026123
Validation loss: 1.9196988639011179

Epoch: 6| Step: 6
Training loss: 2.0829172134399414
Validation loss: 1.9071159965248519

Epoch: 6| Step: 7
Training loss: 1.518514633178711
Validation loss: 1.9112222169035225

Epoch: 6| Step: 8
Training loss: 2.458878517150879
Validation loss: 1.903086680237965

Epoch: 6| Step: 9
Training loss: 1.2705531120300293
Validation loss: 1.9124498264763945

Epoch: 6| Step: 10
Training loss: 2.0607776641845703
Validation loss: 1.8948086102803547

Epoch: 6| Step: 11
Training loss: 1.223419189453125
Validation loss: 1.8858125376444992

Epoch: 6| Step: 12
Training loss: 2.0943522453308105
Validation loss: 1.9040061504610124

Epoch: 6| Step: 13
Training loss: 1.5463913679122925
Validation loss: 1.9369989966833463

Epoch: 140| Step: 0
Training loss: 2.2561278343200684
Validation loss: 1.9509998495860765

Epoch: 6| Step: 1
Training loss: 1.0914294719696045
Validation loss: 1.9833733266399753

Epoch: 6| Step: 2
Training loss: 1.4352898597717285
Validation loss: 1.9625575401449715

Epoch: 6| Step: 3
Training loss: 1.4291709661483765
Validation loss: 1.9602457118290726

Epoch: 6| Step: 4
Training loss: 1.5918961763381958
Validation loss: 1.9537484081842567

Epoch: 6| Step: 5
Training loss: 1.9595648050308228
Validation loss: 1.9586398498986357

Epoch: 6| Step: 6
Training loss: 1.9643466472625732
Validation loss: 1.9561000113846154

Epoch: 6| Step: 7
Training loss: 0.9862637519836426
Validation loss: 1.9461467522446827

Epoch: 6| Step: 8
Training loss: 2.662276268005371
Validation loss: 1.9453086058298747

Epoch: 6| Step: 9
Training loss: 1.790177822113037
Validation loss: 1.922204230421333

Epoch: 6| Step: 10
Training loss: 2.48933744430542
Validation loss: 1.91316258522772

Epoch: 6| Step: 11
Training loss: 1.8133995532989502
Validation loss: 1.9280911850672897

Epoch: 6| Step: 12
Training loss: 2.07468843460083
Validation loss: 1.944068726672921

Epoch: 6| Step: 13
Training loss: 1.5321860313415527
Validation loss: 1.954457667566115

Epoch: 141| Step: 0
Training loss: 1.5757310390472412
Validation loss: 2.0013352888886646

Epoch: 6| Step: 1
Training loss: 2.445094347000122
Validation loss: 2.012459611379972

Epoch: 6| Step: 2
Training loss: 1.7156227827072144
Validation loss: 2.030876589077775

Epoch: 6| Step: 3
Training loss: 1.9326298236846924
Validation loss: 2.0403918386787496

Epoch: 6| Step: 4
Training loss: 1.8483922481536865
Validation loss: 2.062499955136289

Epoch: 6| Step: 5
Training loss: 1.9609451293945312
Validation loss: 2.041531332077519

Epoch: 6| Step: 6
Training loss: 1.5984885692596436
Validation loss: 2.0172139726659304

Epoch: 6| Step: 7
Training loss: 1.949974775314331
Validation loss: 2.005090464827835

Epoch: 6| Step: 8
Training loss: 2.226538896560669
Validation loss: 1.99156557103639

Epoch: 6| Step: 9
Training loss: 1.5568134784698486
Validation loss: 1.9694849778247137

Epoch: 6| Step: 10
Training loss: 1.6981263160705566
Validation loss: 1.9663877717910274

Epoch: 6| Step: 11
Training loss: 2.113473892211914
Validation loss: 1.9675079314939437

Epoch: 6| Step: 12
Training loss: 0.8826559782028198
Validation loss: 1.9668575384283578

Epoch: 6| Step: 13
Training loss: 1.8065003156661987
Validation loss: 1.978069156728765

Epoch: 142| Step: 0
Training loss: 2.594209671020508
Validation loss: 1.9791441963564964

Epoch: 6| Step: 1
Training loss: 2.01932430267334
Validation loss: 1.9836690041326708

Epoch: 6| Step: 2
Training loss: 1.0927708148956299
Validation loss: 2.008533652110766

Epoch: 6| Step: 3
Training loss: 1.6095564365386963
Validation loss: 1.9956895279627975

Epoch: 6| Step: 4
Training loss: 2.348933696746826
Validation loss: 1.9872246134665705

Epoch: 6| Step: 5
Training loss: 1.3599567413330078
Validation loss: 1.9713232517242432

Epoch: 6| Step: 6
Training loss: 1.7262977361679077
Validation loss: 1.9678008915275655

Epoch: 6| Step: 7
Training loss: 1.3989962339401245
Validation loss: 1.964439622817501

Epoch: 6| Step: 8
Training loss: 2.4374961853027344
Validation loss: 1.9749390720039286

Epoch: 6| Step: 9
Training loss: 1.809140682220459
Validation loss: 2.0053051235855266

Epoch: 6| Step: 10
Training loss: 1.7749837636947632
Validation loss: 2.0321830895639237

Epoch: 6| Step: 11
Training loss: 2.0911192893981934
Validation loss: 2.018888214583038

Epoch: 6| Step: 12
Training loss: 0.7627284526824951
Validation loss: 2.0187390696617866

Epoch: 6| Step: 13
Training loss: 1.906197190284729
Validation loss: 1.9825026847982918

Epoch: 143| Step: 0
Training loss: 2.0622987747192383
Validation loss: 1.9397865405646704

Epoch: 6| Step: 1
Training loss: 2.1315999031066895
Validation loss: 1.9524364009980233

Epoch: 6| Step: 2
Training loss: 1.2286932468414307
Validation loss: 1.9696548318350187

Epoch: 6| Step: 3
Training loss: 1.5404635667800903
Validation loss: 1.9886223398229128

Epoch: 6| Step: 4
Training loss: 1.553466796875
Validation loss: 1.9691909115801576

Epoch: 6| Step: 5
Training loss: 1.6835975646972656
Validation loss: 1.9580698064578477

Epoch: 6| Step: 6
Training loss: 2.129152536392212
Validation loss: 1.9401618742173719

Epoch: 6| Step: 7
Training loss: 1.858577013015747
Validation loss: 1.9424251766615017

Epoch: 6| Step: 8
Training loss: 2.1076908111572266
Validation loss: 1.9250960555127872

Epoch: 6| Step: 9
Training loss: 2.334312677383423
Validation loss: 1.920233731628746

Epoch: 6| Step: 10
Training loss: 1.3101248741149902
Validation loss: 1.9202481059617893

Epoch: 6| Step: 11
Training loss: 1.9176833629608154
Validation loss: 1.9313944501261557

Epoch: 6| Step: 12
Training loss: 1.2916607856750488
Validation loss: 1.9365352635742517

Epoch: 6| Step: 13
Training loss: 2.0209202766418457
Validation loss: 1.9333215593009867

Epoch: 144| Step: 0
Training loss: 2.294771671295166
Validation loss: 1.958201301995144

Epoch: 6| Step: 1
Training loss: 2.056331157684326
Validation loss: 1.9774492286866712

Epoch: 6| Step: 2
Training loss: 1.7781773805618286
Validation loss: 1.9994268237903554

Epoch: 6| Step: 3
Training loss: 2.25042462348938
Validation loss: 2.0295783281326294

Epoch: 6| Step: 4
Training loss: 0.9862328171730042
Validation loss: 2.0408750323839087

Epoch: 6| Step: 5
Training loss: 1.900675654411316
Validation loss: 2.063860741994714

Epoch: 6| Step: 6
Training loss: 1.0548661947250366
Validation loss: 2.0466161543323147

Epoch: 6| Step: 7
Training loss: 1.0282444953918457
Validation loss: 2.017553917823299

Epoch: 6| Step: 8
Training loss: 1.775686264038086
Validation loss: 2.014127213467834

Epoch: 6| Step: 9
Training loss: 2.0885300636291504
Validation loss: 2.0086212876022502

Epoch: 6| Step: 10
Training loss: 1.3286948204040527
Validation loss: 2.0120438965418006

Epoch: 6| Step: 11
Training loss: 2.5226082801818848
Validation loss: 1.9856103620221537

Epoch: 6| Step: 12
Training loss: 1.804741621017456
Validation loss: 1.9667515139425955

Epoch: 6| Step: 13
Training loss: 1.602372407913208
Validation loss: 1.9696294556381881

Epoch: 145| Step: 0
Training loss: 2.1065514087677
Validation loss: 1.9677954502003168

Epoch: 6| Step: 1
Training loss: 2.0452051162719727
Validation loss: 1.935860344158706

Epoch: 6| Step: 2
Training loss: 1.4166133403778076
Validation loss: 1.9099508152213147

Epoch: 6| Step: 3
Training loss: 1.6085604429244995
Validation loss: 1.8807303367122528

Epoch: 6| Step: 4
Training loss: 1.0930602550506592
Validation loss: 1.888261277188537

Epoch: 6| Step: 5
Training loss: 1.9128038883209229
Validation loss: 1.8731206950320993

Epoch: 6| Step: 6
Training loss: 1.9692986011505127
Validation loss: 1.8908017348217707

Epoch: 6| Step: 7
Training loss: 2.1033518314361572
Validation loss: 1.892587100305865

Epoch: 6| Step: 8
Training loss: 1.4790102243423462
Validation loss: 1.899559033814297

Epoch: 6| Step: 9
Training loss: 2.626370668411255
Validation loss: 1.9038555468282392

Epoch: 6| Step: 10
Training loss: 1.5433359146118164
Validation loss: 1.930592812517638

Epoch: 6| Step: 11
Training loss: 1.2535841464996338
Validation loss: 1.929425706145584

Epoch: 6| Step: 12
Training loss: 1.9085156917572021
Validation loss: 1.9433478309262184

Epoch: 6| Step: 13
Training loss: 1.265541911125183
Validation loss: 1.9486114389152938

Epoch: 146| Step: 0
Training loss: 1.5020673274993896
Validation loss: 1.9819586302644463

Epoch: 6| Step: 1
Training loss: 1.6989399194717407
Validation loss: 1.9905824148526756

Epoch: 6| Step: 2
Training loss: 1.2774865627288818
Validation loss: 2.0218094010506906

Epoch: 6| Step: 3
Training loss: 2.328974485397339
Validation loss: 2.046502362015427

Epoch: 6| Step: 4
Training loss: 1.699225902557373
Validation loss: 2.0795945608487694

Epoch: 6| Step: 5
Training loss: 2.261899709701538
Validation loss: 2.087306764818007

Epoch: 6| Step: 6
Training loss: 1.61962890625
Validation loss: 2.0494368486506964

Epoch: 6| Step: 7
Training loss: 1.2393004894256592
Validation loss: 1.9496445143094627

Epoch: 6| Step: 8
Training loss: 1.6996064186096191
Validation loss: 1.9007770528075516

Epoch: 6| Step: 9
Training loss: 1.5591893196105957
Validation loss: 1.8921310324822702

Epoch: 6| Step: 10
Training loss: 2.265251636505127
Validation loss: 1.8758831562534455

Epoch: 6| Step: 11
Training loss: 2.5126736164093018
Validation loss: 1.8616863630151237

Epoch: 6| Step: 12
Training loss: 1.9194631576538086
Validation loss: 1.8637030509210402

Epoch: 6| Step: 13
Training loss: 1.3745325803756714
Validation loss: 1.8685355263371621

Epoch: 147| Step: 0
Training loss: 1.238481044769287
Validation loss: 1.8656394571386359

Epoch: 6| Step: 1
Training loss: 1.887738823890686
Validation loss: 1.8779677742271013

Epoch: 6| Step: 2
Training loss: 2.3922672271728516
Validation loss: 1.8909833149243427

Epoch: 6| Step: 3
Training loss: 1.9160411357879639
Validation loss: 1.8996053088095881

Epoch: 6| Step: 4
Training loss: 1.6754343509674072
Validation loss: 1.9064082663546327

Epoch: 6| Step: 5
Training loss: 2.0204904079437256
Validation loss: 1.9247041979143698

Epoch: 6| Step: 6
Training loss: 1.9100385904312134
Validation loss: 1.954747712740334

Epoch: 6| Step: 7
Training loss: 1.522752046585083
Validation loss: 1.9620187282562256

Epoch: 6| Step: 8
Training loss: 1.819162130355835
Validation loss: 1.975723712675033

Epoch: 6| Step: 9
Training loss: 1.6438885927200317
Validation loss: 1.9908598212785618

Epoch: 6| Step: 10
Training loss: 1.8910239934921265
Validation loss: 2.0160121097359607

Epoch: 6| Step: 11
Training loss: 1.8911161422729492
Validation loss: 2.0755740955311763

Epoch: 6| Step: 12
Training loss: 2.096879720687866
Validation loss: 2.0720463183618363

Epoch: 6| Step: 13
Training loss: 1.2299025058746338
Validation loss: 2.0631098055070445

Epoch: 148| Step: 0
Training loss: 1.322216510772705
Validation loss: 2.0248826139716694

Epoch: 6| Step: 1
Training loss: 1.456324815750122
Validation loss: 2.012307911790827

Epoch: 6| Step: 2
Training loss: 1.6511980295181274
Validation loss: 2.016802475016604

Epoch: 6| Step: 3
Training loss: 1.1695055961608887
Validation loss: 1.9945402491477229

Epoch: 6| Step: 4
Training loss: 2.042430877685547
Validation loss: 1.9816489399120372

Epoch: 6| Step: 5
Training loss: 1.7404980659484863
Validation loss: 1.9552978161842591

Epoch: 6| Step: 6
Training loss: 2.2670645713806152
Validation loss: 1.922492964293367

Epoch: 6| Step: 7
Training loss: 1.836907982826233
Validation loss: 1.900228274765835

Epoch: 6| Step: 8
Training loss: 1.9080946445465088
Validation loss: 1.8839718346954675

Epoch: 6| Step: 9
Training loss: 1.8577065467834473
Validation loss: 1.8663122333506101

Epoch: 6| Step: 10
Training loss: 1.9870634078979492
Validation loss: 1.8491195863293064

Epoch: 6| Step: 11
Training loss: 1.4542772769927979
Validation loss: 1.8294183272187428

Epoch: 6| Step: 12
Training loss: 2.303457260131836
Validation loss: 1.843160225499061

Epoch: 6| Step: 13
Training loss: 1.4225118160247803
Validation loss: 1.8599366308540426

Epoch: 149| Step: 0
Training loss: 2.346057891845703
Validation loss: 1.8596497838215162

Epoch: 6| Step: 1
Training loss: 1.8452893495559692
Validation loss: 1.8717909859072777

Epoch: 6| Step: 2
Training loss: 2.0673470497131348
Validation loss: 1.8845727353967645

Epoch: 6| Step: 3
Training loss: 1.5257256031036377
Validation loss: 1.9197800518364034

Epoch: 6| Step: 4
Training loss: 1.4981565475463867
Validation loss: 1.9603208867452477

Epoch: 6| Step: 5
Training loss: 1.27293062210083
Validation loss: 1.991600231457782

Epoch: 6| Step: 6
Training loss: 1.7352855205535889
Validation loss: 2.029690028518759

Epoch: 6| Step: 7
Training loss: 2.1186656951904297
Validation loss: 2.040146376497002

Epoch: 6| Step: 8
Training loss: 1.7465440034866333
Validation loss: 2.0396868310948855

Epoch: 6| Step: 9
Training loss: 1.5056099891662598
Validation loss: 2.0295860818637315

Epoch: 6| Step: 10
Training loss: 1.996093511581421
Validation loss: 1.9950349638538976

Epoch: 6| Step: 11
Training loss: 1.6078801155090332
Validation loss: 1.9450987615892965

Epoch: 6| Step: 12
Training loss: 1.7332466840744019
Validation loss: 1.93103991528993

Epoch: 6| Step: 13
Training loss: 1.0667319297790527
Validation loss: 1.9214900398767123

Epoch: 150| Step: 0
Training loss: 1.8414465188980103
Validation loss: 1.9047840667027298

Epoch: 6| Step: 1
Training loss: 1.7022738456726074
Validation loss: 1.900283746821906

Epoch: 6| Step: 2
Training loss: 1.6497682332992554
Validation loss: 1.890687581031553

Epoch: 6| Step: 3
Training loss: 1.924021601676941
Validation loss: 1.8576462204738329

Epoch: 6| Step: 4
Training loss: 1.742912769317627
Validation loss: 1.8307695158066288

Epoch: 6| Step: 5
Training loss: 1.6454963684082031
Validation loss: 1.8473888263907483

Epoch: 6| Step: 6
Training loss: 1.3803026676177979
Validation loss: 1.8773629832011398

Epoch: 6| Step: 7
Training loss: 2.309621810913086
Validation loss: 1.9079573000631025

Epoch: 6| Step: 8
Training loss: 1.3763172626495361
Validation loss: 1.9556549390157063

Epoch: 6| Step: 9
Training loss: 2.2337546348571777
Validation loss: 1.994043714256697

Epoch: 6| Step: 10
Training loss: 1.9426181316375732
Validation loss: 1.999259530857045

Epoch: 6| Step: 11
Training loss: 1.5465797185897827
Validation loss: 2.0189579327901206

Epoch: 6| Step: 12
Training loss: 1.7253221273422241
Validation loss: 2.0060249708032094

Epoch: 6| Step: 13
Training loss: 1.904977798461914
Validation loss: 1.9690366586049397

Epoch: 151| Step: 0
Training loss: 2.3825106620788574
Validation loss: 1.9276683894536828

Epoch: 6| Step: 1
Training loss: 1.9917899370193481
Validation loss: 1.9130082566251037

Epoch: 6| Step: 2
Training loss: 1.9969117641448975
Validation loss: 1.924300362986903

Epoch: 6| Step: 3
Training loss: 1.1424914598464966
Validation loss: 1.945463550988064

Epoch: 6| Step: 4
Training loss: 1.4917330741882324
Validation loss: 1.9653384903425812

Epoch: 6| Step: 5
Training loss: 1.5518519878387451
Validation loss: 1.9805588568410566

Epoch: 6| Step: 6
Training loss: 1.4465460777282715
Validation loss: 1.9895405692438926

Epoch: 6| Step: 7
Training loss: 1.6166082620620728
Validation loss: 1.99019802770307

Epoch: 6| Step: 8
Training loss: 1.514941692352295
Validation loss: 2.0091026393316125

Epoch: 6| Step: 9
Training loss: 1.53810453414917
Validation loss: 2.012911841433535

Epoch: 6| Step: 10
Training loss: 1.3460993766784668
Validation loss: 2.020441021970523

Epoch: 6| Step: 11
Training loss: 2.3010683059692383
Validation loss: 2.0429361122910694

Epoch: 6| Step: 12
Training loss: 1.8095908164978027
Validation loss: 2.0421396070911038

Epoch: 6| Step: 13
Training loss: 1.7443089485168457
Validation loss: 2.0255301293506416

Epoch: 152| Step: 0
Training loss: 2.4293456077575684
Validation loss: 2.021763414464971

Epoch: 6| Step: 1
Training loss: 1.7660725116729736
Validation loss: 1.9865636441015428

Epoch: 6| Step: 2
Training loss: 1.4952349662780762
Validation loss: 1.9595944419983895

Epoch: 6| Step: 3
Training loss: 2.2212862968444824
Validation loss: 1.947396759063967

Epoch: 6| Step: 4
Training loss: 1.0966014862060547
Validation loss: 1.9362338563447357

Epoch: 6| Step: 5
Training loss: 1.0473823547363281
Validation loss: 1.9134050184680569

Epoch: 6| Step: 6
Training loss: 1.3847081661224365
Validation loss: 1.9061062489786456

Epoch: 6| Step: 7
Training loss: 1.3596965074539185
Validation loss: 1.9130477033635622

Epoch: 6| Step: 8
Training loss: 2.202694892883301
Validation loss: 1.913343237292382

Epoch: 6| Step: 9
Training loss: 1.7171986103057861
Validation loss: 1.9268488217425603

Epoch: 6| Step: 10
Training loss: 2.3575215339660645
Validation loss: 1.9497842737423476

Epoch: 6| Step: 11
Training loss: 1.1336562633514404
Validation loss: 1.9688132321962746

Epoch: 6| Step: 12
Training loss: 1.4104695320129395
Validation loss: 1.9962279655600106

Epoch: 6| Step: 13
Training loss: 2.455502510070801
Validation loss: 2.0029543035773822

Epoch: 153| Step: 0
Training loss: 1.9788470268249512
Validation loss: 2.003269205811203

Epoch: 6| Step: 1
Training loss: 1.6917731761932373
Validation loss: 2.0007713648580734

Epoch: 6| Step: 2
Training loss: 2.0137853622436523
Validation loss: 1.987973374705161

Epoch: 6| Step: 3
Training loss: 1.448349952697754
Validation loss: 1.9587760663801623

Epoch: 6| Step: 4
Training loss: 1.6945518255233765
Validation loss: 1.9603095695536623

Epoch: 6| Step: 5
Training loss: 1.2291710376739502
Validation loss: 1.9560980719904746

Epoch: 6| Step: 6
Training loss: 1.1631202697753906
Validation loss: 1.9421258818718694

Epoch: 6| Step: 7
Training loss: 1.975742220878601
Validation loss: 1.9731506442510953

Epoch: 6| Step: 8
Training loss: 1.8127888441085815
Validation loss: 1.9717799822489421

Epoch: 6| Step: 9
Training loss: 2.1268367767333984
Validation loss: 1.9771152670665453

Epoch: 6| Step: 10
Training loss: 2.0334928035736084
Validation loss: 1.9632712166796449

Epoch: 6| Step: 11
Training loss: 0.878131628036499
Validation loss: 1.9568688164475143

Epoch: 6| Step: 12
Training loss: 1.1457815170288086
Validation loss: 1.948157746304748

Epoch: 6| Step: 13
Training loss: 2.7912933826446533
Validation loss: 1.9469068332384991

Epoch: 154| Step: 0
Training loss: 1.5608147382736206
Validation loss: 1.9321744198440223

Epoch: 6| Step: 1
Training loss: 1.5966113805770874
Validation loss: 1.9242707093556721

Epoch: 6| Step: 2
Training loss: 0.9021360874176025
Validation loss: 1.937890725751077

Epoch: 6| Step: 3
Training loss: 2.061276912689209
Validation loss: 1.9610418504284275

Epoch: 6| Step: 4
Training loss: 1.6952919960021973
Validation loss: 1.9880334895144227

Epoch: 6| Step: 5
Training loss: 1.4616591930389404
Validation loss: 1.998863107414656

Epoch: 6| Step: 6
Training loss: 1.8202086687088013
Validation loss: 1.9977370692837624

Epoch: 6| Step: 7
Training loss: 1.318051815032959
Validation loss: 1.9989342612604941

Epoch: 6| Step: 8
Training loss: 1.0581563711166382
Validation loss: 1.9764008752761348

Epoch: 6| Step: 9
Training loss: 2.3567867279052734
Validation loss: 1.9568540152683054

Epoch: 6| Step: 10
Training loss: 1.9146764278411865
Validation loss: 1.9388817125751125

Epoch: 6| Step: 11
Training loss: 2.409349203109741
Validation loss: 1.922078347975208

Epoch: 6| Step: 12
Training loss: 1.5503156185150146
Validation loss: 1.9134793102100331

Epoch: 6| Step: 13
Training loss: 1.567870020866394
Validation loss: 1.894630588510985

Epoch: 155| Step: 0
Training loss: 1.901151180267334
Validation loss: 1.9080157690150763

Epoch: 6| Step: 1
Training loss: 1.2213925123214722
Validation loss: 1.891642391040761

Epoch: 6| Step: 2
Training loss: 1.8881616592407227
Validation loss: 1.8962041767694617

Epoch: 6| Step: 3
Training loss: 1.8419864177703857
Validation loss: 1.8783677752299974

Epoch: 6| Step: 4
Training loss: 1.9680618047714233
Validation loss: 1.8894707272129674

Epoch: 6| Step: 5
Training loss: 1.3197067975997925
Validation loss: 1.895845426026211

Epoch: 6| Step: 6
Training loss: 1.2591990232467651
Validation loss: 1.9135417374231483

Epoch: 6| Step: 7
Training loss: 1.6892566680908203
Validation loss: 1.904734435901847

Epoch: 6| Step: 8
Training loss: 1.335460901260376
Validation loss: 1.911256879888555

Epoch: 6| Step: 9
Training loss: 1.251371145248413
Validation loss: 1.9309967922908005

Epoch: 6| Step: 10
Training loss: 1.420823574066162
Validation loss: 1.9506665199033675

Epoch: 6| Step: 11
Training loss: 1.613063097000122
Validation loss: 1.965371903552804

Epoch: 6| Step: 12
Training loss: 2.20711088180542
Validation loss: 1.982631971759181

Epoch: 6| Step: 13
Training loss: 2.36358642578125
Validation loss: 1.9931830988135388

Epoch: 156| Step: 0
Training loss: 2.0153121948242188
Validation loss: 2.012457119521274

Epoch: 6| Step: 1
Training loss: 2.276411533355713
Validation loss: 1.9932359803107478

Epoch: 6| Step: 2
Training loss: 1.0359634160995483
Validation loss: 1.9762012561162312

Epoch: 6| Step: 3
Training loss: 1.9058361053466797
Validation loss: 1.980201587882093

Epoch: 6| Step: 4
Training loss: 1.8003220558166504
Validation loss: 2.0022451582775322

Epoch: 6| Step: 5
Training loss: 1.0807862281799316
Validation loss: 1.9827406073129306

Epoch: 6| Step: 6
Training loss: 1.9012291431427002
Validation loss: 1.9575777899834417

Epoch: 6| Step: 7
Training loss: 1.0974643230438232
Validation loss: 1.9406340814405871

Epoch: 6| Step: 8
Training loss: 1.888677954673767
Validation loss: 1.9191395582691315

Epoch: 6| Step: 9
Training loss: 1.6737020015716553
Validation loss: 1.9071499545087096

Epoch: 6| Step: 10
Training loss: 2.0935182571411133
Validation loss: 1.8961917264487154

Epoch: 6| Step: 11
Training loss: 1.9138705730438232
Validation loss: 1.8921354637351087

Epoch: 6| Step: 12
Training loss: 1.1207717657089233
Validation loss: 1.881070254951395

Epoch: 6| Step: 13
Training loss: 1.0483719110488892
Validation loss: 1.8755936789256271

Epoch: 157| Step: 0
Training loss: 1.1826133728027344
Validation loss: 1.8817264610721218

Epoch: 6| Step: 1
Training loss: 1.2604548931121826
Validation loss: 1.8696239148416827

Epoch: 6| Step: 2
Training loss: 2.3306760787963867
Validation loss: 1.888198890993672

Epoch: 6| Step: 3
Training loss: 1.318009853363037
Validation loss: 1.8985771325326735

Epoch: 6| Step: 4
Training loss: 1.4529638290405273
Validation loss: 1.9304366598847091

Epoch: 6| Step: 5
Training loss: 2.0109615325927734
Validation loss: 1.925879502809176

Epoch: 6| Step: 6
Training loss: 2.452253580093384
Validation loss: 1.9428060964871479

Epoch: 6| Step: 7
Training loss: 1.5299787521362305
Validation loss: 1.9551953410589566

Epoch: 6| Step: 8
Training loss: 1.3494739532470703
Validation loss: 1.951365775959466

Epoch: 6| Step: 9
Training loss: 1.0546345710754395
Validation loss: 1.9406071888503207

Epoch: 6| Step: 10
Training loss: 2.0417580604553223
Validation loss: 1.956582639807014

Epoch: 6| Step: 11
Training loss: 1.1912808418273926
Validation loss: 1.9684851759223527

Epoch: 6| Step: 12
Training loss: 1.6765912771224976
Validation loss: 1.975953878894929

Epoch: 6| Step: 13
Training loss: 1.6252824068069458
Validation loss: 1.9810526486366027

Epoch: 158| Step: 0
Training loss: 1.5290720462799072
Validation loss: 1.9620479383776266

Epoch: 6| Step: 1
Training loss: 1.5103453397750854
Validation loss: 1.9458751229829685

Epoch: 6| Step: 2
Training loss: 1.9423199892044067
Validation loss: 1.9333718310120285

Epoch: 6| Step: 3
Training loss: 1.6856507062911987
Validation loss: 1.9064553988877164

Epoch: 6| Step: 4
Training loss: 1.3986809253692627
Validation loss: 1.8985476545108262

Epoch: 6| Step: 5
Training loss: 1.118128776550293
Validation loss: 1.8995225211625457

Epoch: 6| Step: 6
Training loss: 1.182319164276123
Validation loss: 1.9082730611165364

Epoch: 6| Step: 7
Training loss: 2.2022502422332764
Validation loss: 1.9216511775088567

Epoch: 6| Step: 8
Training loss: 0.9118130207061768
Validation loss: 1.930402022536083

Epoch: 6| Step: 9
Training loss: 0.7392071485519409
Validation loss: 1.9229783934931601

Epoch: 6| Step: 10
Training loss: 1.6439814567565918
Validation loss: 1.9247219190802625

Epoch: 6| Step: 11
Training loss: 1.8435509204864502
Validation loss: 1.917411078688919

Epoch: 6| Step: 12
Training loss: 2.1556172370910645
Validation loss: 1.9242984812746766

Epoch: 6| Step: 13
Training loss: 2.4593913555145264
Validation loss: 1.9211336771647136

Epoch: 159| Step: 0
Training loss: 1.2715903520584106
Validation loss: 1.9095817586427093

Epoch: 6| Step: 1
Training loss: 1.3725996017456055
Validation loss: 1.9149879370966265

Epoch: 6| Step: 2
Training loss: 1.2406442165374756
Validation loss: 1.9279835198515205

Epoch: 6| Step: 3
Training loss: 1.664526104927063
Validation loss: 1.9262346657373572

Epoch: 6| Step: 4
Training loss: 1.882645845413208
Validation loss: 1.9306696204728977

Epoch: 6| Step: 5
Training loss: 1.355696439743042
Validation loss: 1.9462611931626514

Epoch: 6| Step: 6
Training loss: 1.0011695623397827
Validation loss: 1.9287797417691959

Epoch: 6| Step: 7
Training loss: 1.608941912651062
Validation loss: 1.9383527271209224

Epoch: 6| Step: 8
Training loss: 1.784345030784607
Validation loss: 1.9259315818868659

Epoch: 6| Step: 9
Training loss: 1.5609685182571411
Validation loss: 1.940714213155931

Epoch: 6| Step: 10
Training loss: 1.6528171300888062
Validation loss: 1.9462158295416063

Epoch: 6| Step: 11
Training loss: 1.7343777418136597
Validation loss: 1.9390355399859849

Epoch: 6| Step: 12
Training loss: 1.7143267393112183
Validation loss: 1.935399140081098

Epoch: 6| Step: 13
Training loss: 2.239386796951294
Validation loss: 1.9216941120803996

Epoch: 160| Step: 0
Training loss: 1.3919867277145386
Validation loss: 1.9325751502026793

Epoch: 6| Step: 1
Training loss: 1.3485188484191895
Validation loss: 1.9512615203857422

Epoch: 6| Step: 2
Training loss: 1.715141773223877
Validation loss: 1.9558412028897194

Epoch: 6| Step: 3
Training loss: 1.598214864730835
Validation loss: 1.9550901984655729

Epoch: 6| Step: 4
Training loss: 1.2568535804748535
Validation loss: 1.9607318216754543

Epoch: 6| Step: 5
Training loss: 1.6761596202850342
Validation loss: 1.957004129245717

Epoch: 6| Step: 6
Training loss: 0.8235285878181458
Validation loss: 1.9575522868863997

Epoch: 6| Step: 7
Training loss: 1.3202548027038574
Validation loss: 1.9454622499404415

Epoch: 6| Step: 8
Training loss: 1.349902868270874
Validation loss: 1.9339070871312132

Epoch: 6| Step: 9
Training loss: 1.8525183200836182
Validation loss: 1.923411746178904

Epoch: 6| Step: 10
Training loss: 2.332069158554077
Validation loss: 1.944374160100055

Epoch: 6| Step: 11
Training loss: 1.3738386631011963
Validation loss: 1.9434302596635715

Epoch: 6| Step: 12
Training loss: 1.9704649448394775
Validation loss: 1.9286151137403262

Epoch: 6| Step: 13
Training loss: 1.7965480089187622
Validation loss: 1.9226959969407769

Epoch: 161| Step: 0
Training loss: 1.6597115993499756
Validation loss: 1.913964113881511

Epoch: 6| Step: 1
Training loss: 1.6684763431549072
Validation loss: 1.8978368031081332

Epoch: 6| Step: 2
Training loss: 1.3513041734695435
Validation loss: 1.8869429198644494

Epoch: 6| Step: 3
Training loss: 1.8365951776504517
Validation loss: 1.9051888424863097

Epoch: 6| Step: 4
Training loss: 1.5295814275741577
Validation loss: 1.943605899810791

Epoch: 6| Step: 5
Training loss: 1.5973773002624512
Validation loss: 1.9735938605441843

Epoch: 6| Step: 6
Training loss: 1.3422138690948486
Validation loss: 2.0422516471596173

Epoch: 6| Step: 7
Training loss: 1.4147669076919556
Validation loss: 2.086258437043877

Epoch: 6| Step: 8
Training loss: 1.9521746635437012
Validation loss: 2.0941030594610397

Epoch: 6| Step: 9
Training loss: 1.8769636154174805
Validation loss: 2.0784155655932683

Epoch: 6| Step: 10
Training loss: 2.027376890182495
Validation loss: 2.0470360043228313

Epoch: 6| Step: 11
Training loss: 0.8806846737861633
Validation loss: 2.0126524715013403

Epoch: 6| Step: 12
Training loss: 1.3044865131378174
Validation loss: 1.9839993805013678

Epoch: 6| Step: 13
Training loss: 1.9676647186279297
Validation loss: 1.95814944723601

Epoch: 162| Step: 0
Training loss: 1.9756935834884644
Validation loss: 1.938547416399884

Epoch: 6| Step: 1
Training loss: 1.1996618509292603
Validation loss: 1.9138736263398202

Epoch: 6| Step: 2
Training loss: 1.4660755395889282
Validation loss: 1.8946187906367804

Epoch: 6| Step: 3
Training loss: 1.3572982549667358
Validation loss: 1.8668721914291382

Epoch: 6| Step: 4
Training loss: 1.147080421447754
Validation loss: 1.8431925235256073

Epoch: 6| Step: 5
Training loss: 1.7539726495742798
Validation loss: 1.8570761193511307

Epoch: 6| Step: 6
Training loss: 2.062933921813965
Validation loss: 1.8637188378200735

Epoch: 6| Step: 7
Training loss: 2.1493306159973145
Validation loss: 1.8738877427193426

Epoch: 6| Step: 8
Training loss: 1.6894537210464478
Validation loss: 1.8939814798293575

Epoch: 6| Step: 9
Training loss: 1.3906359672546387
Validation loss: 1.9075464433239353

Epoch: 6| Step: 10
Training loss: 1.8197518587112427
Validation loss: 1.926744266222882

Epoch: 6| Step: 11
Training loss: 1.2111366987228394
Validation loss: 1.9206911979183074

Epoch: 6| Step: 12
Training loss: 1.605463981628418
Validation loss: 1.9086865430237145

Epoch: 6| Step: 13
Training loss: 1.034205675125122
Validation loss: 1.9000986852953512

Epoch: 163| Step: 0
Training loss: 1.843351125717163
Validation loss: 1.9081191375691404

Epoch: 6| Step: 1
Training loss: 2.151733875274658
Validation loss: 1.925147726971616

Epoch: 6| Step: 2
Training loss: 1.208070993423462
Validation loss: 1.9437666452059181

Epoch: 6| Step: 3
Training loss: 1.6463209390640259
Validation loss: 1.9744591533496816

Epoch: 6| Step: 4
Training loss: 1.7377355098724365
Validation loss: 1.9538431539330432

Epoch: 6| Step: 5
Training loss: 1.7410271167755127
Validation loss: 1.9523702359968615

Epoch: 6| Step: 6
Training loss: 1.0309616327285767
Validation loss: 1.943567459301282

Epoch: 6| Step: 7
Training loss: 1.9215962886810303
Validation loss: 1.949562729045909

Epoch: 6| Step: 8
Training loss: 1.3240846395492554
Validation loss: 1.9605650594157558

Epoch: 6| Step: 9
Training loss: 1.539743185043335
Validation loss: 1.9443492402312577

Epoch: 6| Step: 10
Training loss: 1.2910351753234863
Validation loss: 1.9283949739189559

Epoch: 6| Step: 11
Training loss: 1.1978307962417603
Validation loss: 1.8984952460053146

Epoch: 6| Step: 12
Training loss: 1.5592622756958008
Validation loss: 1.8995194332574004

Epoch: 6| Step: 13
Training loss: 1.3549304008483887
Validation loss: 1.8829924893635575

Epoch: 164| Step: 0
Training loss: 2.4222350120544434
Validation loss: 1.8979783750349475

Epoch: 6| Step: 1
Training loss: 1.0996415615081787
Validation loss: 1.8927547008760515

Epoch: 6| Step: 2
Training loss: 2.0785775184631348
Validation loss: 1.8913201901220507

Epoch: 6| Step: 3
Training loss: 1.672983169555664
Validation loss: 1.890377369619185

Epoch: 6| Step: 4
Training loss: 1.35489821434021
Validation loss: 1.9074713965897918

Epoch: 6| Step: 5
Training loss: 1.0822592973709106
Validation loss: 1.9105036476606965

Epoch: 6| Step: 6
Training loss: 1.207280158996582
Validation loss: 1.9066427599999212

Epoch: 6| Step: 7
Training loss: 1.0053143501281738
Validation loss: 1.9438823987078924

Epoch: 6| Step: 8
Training loss: 1.5753004550933838
Validation loss: 1.978044589360555

Epoch: 6| Step: 9
Training loss: 1.4968993663787842
Validation loss: 1.9980469211455314

Epoch: 6| Step: 10
Training loss: 1.1602442264556885
Validation loss: 2.033207006351922

Epoch: 6| Step: 11
Training loss: 1.250058889389038
Validation loss: 2.064677252564379

Epoch: 6| Step: 12
Training loss: 1.7502704858779907
Validation loss: 2.0533350616373043

Epoch: 6| Step: 13
Training loss: 2.655989408493042
Validation loss: 2.0455752265068794

Epoch: 165| Step: 0
Training loss: 1.4542535543441772
Validation loss: 2.0221968466235745

Epoch: 6| Step: 1
Training loss: 1.0522409677505493
Validation loss: 1.9742823339277698

Epoch: 6| Step: 2
Training loss: 1.2348487377166748
Validation loss: 1.9825168630128265

Epoch: 6| Step: 3
Training loss: 1.5583512783050537
Validation loss: 1.9947917640850108

Epoch: 6| Step: 4
Training loss: 1.5896106958389282
Validation loss: 1.962671367071008

Epoch: 6| Step: 5
Training loss: 1.0693429708480835
Validation loss: 1.9359614105634793

Epoch: 6| Step: 6
Training loss: 1.798825979232788
Validation loss: 1.8948598215656896

Epoch: 6| Step: 7
Training loss: 1.5771095752716064
Validation loss: 1.8708002926200948

Epoch: 6| Step: 8
Training loss: 1.9200555086135864
Validation loss: 1.8972633692526049

Epoch: 6| Step: 9
Training loss: 1.4885706901550293
Validation loss: 1.9169133555504583

Epoch: 6| Step: 10
Training loss: 1.5701820850372314
Validation loss: 1.940899036263907

Epoch: 6| Step: 11
Training loss: 1.6776883602142334
Validation loss: 1.9705052734703146

Epoch: 6| Step: 12
Training loss: 2.171534538269043
Validation loss: 1.9489608400611467

Epoch: 6| Step: 13
Training loss: 1.5963194370269775
Validation loss: 1.9102030646416448

Epoch: 166| Step: 0
Training loss: 1.6182503700256348
Validation loss: 1.8707813203975718

Epoch: 6| Step: 1
Training loss: 0.7989090085029602
Validation loss: 1.8704299772939375

Epoch: 6| Step: 2
Training loss: 1.6500030755996704
Validation loss: 1.8911753469897854

Epoch: 6| Step: 3
Training loss: 1.323367714881897
Validation loss: 1.9219585195664437

Epoch: 6| Step: 4
Training loss: 1.2683541774749756
Validation loss: 1.9508234429103073

Epoch: 6| Step: 5
Training loss: 1.546777367591858
Validation loss: 1.9537751059378348

Epoch: 6| Step: 6
Training loss: 1.0271010398864746
Validation loss: 1.9564044578101045

Epoch: 6| Step: 7
Training loss: 1.6254098415374756
Validation loss: 1.942324702457715

Epoch: 6| Step: 8
Training loss: 1.5712857246398926
Validation loss: 1.935479712742631

Epoch: 6| Step: 9
Training loss: 2.0176596641540527
Validation loss: 1.945000438280003

Epoch: 6| Step: 10
Training loss: 1.4158658981323242
Validation loss: 1.9417188270117647

Epoch: 6| Step: 11
Training loss: 1.6410945653915405
Validation loss: 1.9484752813975017

Epoch: 6| Step: 12
Training loss: 1.7078826427459717
Validation loss: 1.980123669870438

Epoch: 6| Step: 13
Training loss: 2.3337161540985107
Validation loss: 1.9849671189503004

Epoch: 167| Step: 0
Training loss: 0.873566746711731
Validation loss: 1.9850600791233841

Epoch: 6| Step: 1
Training loss: 1.5136891603469849
Validation loss: 1.9813383997127574

Epoch: 6| Step: 2
Training loss: 1.826768398284912
Validation loss: 1.9504791100819905

Epoch: 6| Step: 3
Training loss: 2.0703046321868896
Validation loss: 1.9446373652386408

Epoch: 6| Step: 4
Training loss: 1.4706679582595825
Validation loss: 1.950229258947475

Epoch: 6| Step: 5
Training loss: 1.3638968467712402
Validation loss: 1.9540359102269655

Epoch: 6| Step: 6
Training loss: 1.6471353769302368
Validation loss: 1.9850293038993754

Epoch: 6| Step: 7
Training loss: 0.826116144657135
Validation loss: 2.0220384546505508

Epoch: 6| Step: 8
Training loss: 1.9495267868041992
Validation loss: 2.030919027584855

Epoch: 6| Step: 9
Training loss: 1.4951276779174805
Validation loss: 2.013712836850074

Epoch: 6| Step: 10
Training loss: 1.1992816925048828
Validation loss: 2.0055655946013746

Epoch: 6| Step: 11
Training loss: 1.9459047317504883
Validation loss: 1.9872952353569768

Epoch: 6| Step: 12
Training loss: 1.3180286884307861
Validation loss: 1.982871837513421

Epoch: 6| Step: 13
Training loss: 1.748167872428894
Validation loss: 1.9948504176191104

Epoch: 168| Step: 0
Training loss: 1.5035042762756348
Validation loss: 1.991981972930252

Epoch: 6| Step: 1
Training loss: 1.7307121753692627
Validation loss: 1.9653116644069712

Epoch: 6| Step: 2
Training loss: 2.041411876678467
Validation loss: 1.9657886951200423

Epoch: 6| Step: 3
Training loss: 1.5059354305267334
Validation loss: 1.925160720784177

Epoch: 6| Step: 4
Training loss: 1.2173817157745361
Validation loss: 1.9100472747638662

Epoch: 6| Step: 5
Training loss: 1.3665525913238525
Validation loss: 1.8732696604985062

Epoch: 6| Step: 6
Training loss: 1.6146326065063477
Validation loss: 1.8624721880882018

Epoch: 6| Step: 7
Training loss: 1.081615924835205
Validation loss: 1.848486062019102

Epoch: 6| Step: 8
Training loss: 1.7174646854400635
Validation loss: 1.8317717288130073

Epoch: 6| Step: 9
Training loss: 1.3507957458496094
Validation loss: 1.8482657196701213

Epoch: 6| Step: 10
Training loss: 1.662560224533081
Validation loss: 1.849328576877553

Epoch: 6| Step: 11
Training loss: 1.335350751876831
Validation loss: 1.8889534934874503

Epoch: 6| Step: 12
Training loss: 0.9743970632553101
Validation loss: 1.9181338689660514

Epoch: 6| Step: 13
Training loss: 1.4619755744934082
Validation loss: 1.9535189674746605

Epoch: 169| Step: 0
Training loss: 1.1346032619476318
Validation loss: 1.9832572924193514

Epoch: 6| Step: 1
Training loss: 1.5409469604492188
Validation loss: 1.993113640815981

Epoch: 6| Step: 2
Training loss: 1.9034068584442139
Validation loss: 2.004584503430192

Epoch: 6| Step: 3
Training loss: 1.7176040410995483
Validation loss: 1.9859021030446535

Epoch: 6| Step: 4
Training loss: 1.4702825546264648
Validation loss: 1.9727624513769662

Epoch: 6| Step: 5
Training loss: 2.0238096714019775
Validation loss: 1.9587627867216706

Epoch: 6| Step: 6
Training loss: 1.5033015012741089
Validation loss: 1.9294275186395133

Epoch: 6| Step: 7
Training loss: 1.4781426191329956
Validation loss: 1.9363716956107848

Epoch: 6| Step: 8
Training loss: 1.29388427734375
Validation loss: 1.9394225446126794

Epoch: 6| Step: 9
Training loss: 1.1363422870635986
Validation loss: 1.9352968136469524

Epoch: 6| Step: 10
Training loss: 1.1640872955322266
Validation loss: 1.9230189746425999

Epoch: 6| Step: 11
Training loss: 0.9843049645423889
Validation loss: 1.8892856644045921

Epoch: 6| Step: 12
Training loss: 1.1492528915405273
Validation loss: 1.8720289327765023

Epoch: 6| Step: 13
Training loss: 1.4679627418518066
Validation loss: 1.8822578845485565

Epoch: 170| Step: 0
Training loss: 0.9474939703941345
Validation loss: 1.876604595491963

Epoch: 6| Step: 1
Training loss: 1.3323769569396973
Validation loss: 1.8646616012819353

Epoch: 6| Step: 2
Training loss: 1.5561672449111938
Validation loss: 1.8757665285500147

Epoch: 6| Step: 3
Training loss: 1.947096824645996
Validation loss: 1.876162685373778

Epoch: 6| Step: 4
Training loss: 1.5605876445770264
Validation loss: 1.856897589980915

Epoch: 6| Step: 5
Training loss: 1.019783616065979
Validation loss: 1.8581051083021267

Epoch: 6| Step: 6
Training loss: 1.3668278455734253
Validation loss: 1.860253813446209

Epoch: 6| Step: 7
Training loss: 1.3538824319839478
Validation loss: 1.84691793816064

Epoch: 6| Step: 8
Training loss: 1.31503164768219
Validation loss: 1.8855887869352936

Epoch: 6| Step: 9
Training loss: 1.2588541507720947
Validation loss: 1.9261683264086324

Epoch: 6| Step: 10
Training loss: 1.7483383417129517
Validation loss: 1.9832766081697197

Epoch: 6| Step: 11
Training loss: 1.8910048007965088
Validation loss: 2.017964042643065

Epoch: 6| Step: 12
Training loss: 1.772208571434021
Validation loss: 2.0101258844457646

Epoch: 6| Step: 13
Training loss: 0.7131863832473755
Validation loss: 1.9843546741752214

Epoch: 171| Step: 0
Training loss: 1.4836552143096924
Validation loss: 1.9294805680551836

Epoch: 6| Step: 1
Training loss: 1.1264996528625488
Validation loss: 1.9190157562173822

Epoch: 6| Step: 2
Training loss: 1.315622329711914
Validation loss: 1.920381902366556

Epoch: 6| Step: 3
Training loss: 1.0576982498168945
Validation loss: 1.9244567463474889

Epoch: 6| Step: 4
Training loss: 1.6296310424804688
Validation loss: 1.9031753719493907

Epoch: 6| Step: 5
Training loss: 1.7880449295043945
Validation loss: 1.8706970586571643

Epoch: 6| Step: 6
Training loss: 1.4747984409332275
Validation loss: 1.871886489211872

Epoch: 6| Step: 7
Training loss: 1.628416895866394
Validation loss: 1.8595667026376212

Epoch: 6| Step: 8
Training loss: 1.387075424194336
Validation loss: 1.8856255136510378

Epoch: 6| Step: 9
Training loss: 1.418121337890625
Validation loss: 1.9060929334291847

Epoch: 6| Step: 10
Training loss: 1.4723379611968994
Validation loss: 1.9276096487558017

Epoch: 6| Step: 11
Training loss: 1.5501916408538818
Validation loss: 1.9371913812493766

Epoch: 6| Step: 12
Training loss: 0.869792640209198
Validation loss: 1.9152242316994617

Epoch: 6| Step: 13
Training loss: 1.4688761234283447
Validation loss: 1.9214070689293645

Epoch: 172| Step: 0
Training loss: 1.053027868270874
Validation loss: 1.9223765967994608

Epoch: 6| Step: 1
Training loss: 1.072408676147461
Validation loss: 1.9089322705422678

Epoch: 6| Step: 2
Training loss: 1.2009203433990479
Validation loss: 1.9081090957887712

Epoch: 6| Step: 3
Training loss: 1.7314205169677734
Validation loss: 1.882808498156968

Epoch: 6| Step: 4
Training loss: 1.2954261302947998
Validation loss: 1.905286842776883

Epoch: 6| Step: 5
Training loss: 1.049992322921753
Validation loss: 1.8827830001872072

Epoch: 6| Step: 6
Training loss: 1.6998283863067627
Validation loss: 1.8966394598766039

Epoch: 6| Step: 7
Training loss: 1.689346194267273
Validation loss: 1.9107839061367897

Epoch: 6| Step: 8
Training loss: 1.1019526720046997
Validation loss: 1.8969044185453845

Epoch: 6| Step: 9
Training loss: 1.0411096811294556
Validation loss: 1.8795664618092198

Epoch: 6| Step: 10
Training loss: 1.522120714187622
Validation loss: 1.873464289531913

Epoch: 6| Step: 11
Training loss: 2.1039209365844727
Validation loss: 1.878390541640661

Epoch: 6| Step: 12
Training loss: 1.6163241863250732
Validation loss: 1.890422221153013

Epoch: 6| Step: 13
Training loss: 0.9978617429733276
Validation loss: 1.912986829716672

Epoch: 173| Step: 0
Training loss: 1.470536470413208
Validation loss: 1.9223443000547347

Epoch: 6| Step: 1
Training loss: 1.5993269681930542
Validation loss: 1.941150926774548

Epoch: 6| Step: 2
Training loss: 1.3792574405670166
Validation loss: 1.9356899133292578

Epoch: 6| Step: 3
Training loss: 1.7811164855957031
Validation loss: 1.9786278945143505

Epoch: 6| Step: 4
Training loss: 1.3875318765640259
Validation loss: 1.980583372936454

Epoch: 6| Step: 5
Training loss: 1.375124216079712
Validation loss: 1.9945044581608107

Epoch: 6| Step: 6
Training loss: 1.5815509557724
Validation loss: 1.9524378571459042

Epoch: 6| Step: 7
Training loss: 1.3188257217407227
Validation loss: 1.9194924280207644

Epoch: 6| Step: 8
Training loss: 1.222461223602295
Validation loss: 1.9223907788594563

Epoch: 6| Step: 9
Training loss: 0.9977251291275024
Validation loss: 1.9123007277006745

Epoch: 6| Step: 10
Training loss: 1.0235339403152466
Validation loss: 1.9010164481337353

Epoch: 6| Step: 11
Training loss: 1.309438705444336
Validation loss: 1.9029387774006012

Epoch: 6| Step: 12
Training loss: 1.1346259117126465
Validation loss: 1.8987116018931072

Epoch: 6| Step: 13
Training loss: 1.141203761100769
Validation loss: 1.9077530676318752

Epoch: 174| Step: 0
Training loss: 0.6576364636421204
Validation loss: 1.903129175145139

Epoch: 6| Step: 1
Training loss: 1.7567639350891113
Validation loss: 1.9076537842391639

Epoch: 6| Step: 2
Training loss: 1.6227433681488037
Validation loss: 1.8951035186808596

Epoch: 6| Step: 3
Training loss: 0.8452602624893188
Validation loss: 1.8837218053879277

Epoch: 6| Step: 4
Training loss: 1.2362697124481201
Validation loss: 1.8932543300813245

Epoch: 6| Step: 5
Training loss: 1.3753056526184082
Validation loss: 1.8970407593634822

Epoch: 6| Step: 6
Training loss: 1.8700286149978638
Validation loss: 1.8799491518287248

Epoch: 6| Step: 7
Training loss: 1.1660356521606445
Validation loss: 1.9040084718376078

Epoch: 6| Step: 8
Training loss: 1.22273850440979
Validation loss: 1.9126017939659856

Epoch: 6| Step: 9
Training loss: 1.028975009918213
Validation loss: 1.9044552259547736

Epoch: 6| Step: 10
Training loss: 2.0440049171447754
Validation loss: 1.9197554190953572

Epoch: 6| Step: 11
Training loss: 1.4010303020477295
Validation loss: 1.8973411360094625

Epoch: 6| Step: 12
Training loss: 1.074636697769165
Validation loss: 1.9042001808843305

Epoch: 6| Step: 13
Training loss: 0.9825184941291809
Validation loss: 1.8933903299352175

Epoch: 175| Step: 0
Training loss: 1.1200220584869385
Validation loss: 1.8715691374194237

Epoch: 6| Step: 1
Training loss: 1.3928442001342773
Validation loss: 1.8713059027989705

Epoch: 6| Step: 2
Training loss: 0.9843869209289551
Validation loss: 1.865441910682186

Epoch: 6| Step: 3
Training loss: 1.4638514518737793
Validation loss: 1.8742354582714778

Epoch: 6| Step: 4
Training loss: 1.3850586414337158
Validation loss: 1.8796254101619925

Epoch: 6| Step: 5
Training loss: 1.4109381437301636
Validation loss: 1.8922849957660963

Epoch: 6| Step: 6
Training loss: 1.1270880699157715
Validation loss: 1.8960219865204186

Epoch: 6| Step: 7
Training loss: 1.2150754928588867
Validation loss: 1.9110834752359698

Epoch: 6| Step: 8
Training loss: 2.0567851066589355
Validation loss: 1.923111654097034

Epoch: 6| Step: 9
Training loss: 1.2030797004699707
Validation loss: 1.9496172346094602

Epoch: 6| Step: 10
Training loss: 1.111793041229248
Validation loss: 1.9927542953081028

Epoch: 6| Step: 11
Training loss: 1.5395042896270752
Validation loss: 2.0296823055513444

Epoch: 6| Step: 12
Training loss: 0.9512545466423035
Validation loss: 2.0129300317456646

Epoch: 6| Step: 13
Training loss: 1.5789517164230347
Validation loss: 1.9908952507921445

Epoch: 176| Step: 0
Training loss: 1.1963629722595215
Validation loss: 1.9649112378397295

Epoch: 6| Step: 1
Training loss: 1.0646926164627075
Validation loss: 1.9024952150160266

Epoch: 6| Step: 2
Training loss: 1.175437569618225
Validation loss: 1.856407683382752

Epoch: 6| Step: 3
Training loss: 1.6881167888641357
Validation loss: 1.8180513676776682

Epoch: 6| Step: 4
Training loss: 1.7282403707504272
Validation loss: 1.8095394334485453

Epoch: 6| Step: 5
Training loss: 1.5888876914978027
Validation loss: 1.8149893206934775

Epoch: 6| Step: 6
Training loss: 0.8693739771842957
Validation loss: 1.8297392052988852

Epoch: 6| Step: 7
Training loss: 1.181649088859558
Validation loss: 1.8225984317000195

Epoch: 6| Step: 8
Training loss: 1.1198339462280273
Validation loss: 1.8370546551160916

Epoch: 6| Step: 9
Training loss: 1.4726918935775757
Validation loss: 1.828287677098346

Epoch: 6| Step: 10
Training loss: 1.4850716590881348
Validation loss: 1.848927556827504

Epoch: 6| Step: 11
Training loss: 1.3197882175445557
Validation loss: 1.8637820751436296

Epoch: 6| Step: 12
Training loss: 1.3262845277786255
Validation loss: 1.8779430838041409

Epoch: 6| Step: 13
Training loss: 0.761734127998352
Validation loss: 1.9034323576957948

Epoch: 177| Step: 0
Training loss: 0.8228866457939148
Validation loss: 1.9394228304586103

Epoch: 6| Step: 1
Training loss: 1.152464747428894
Validation loss: 1.9396515584761096

Epoch: 6| Step: 2
Training loss: 1.0265581607818604
Validation loss: 1.9765999676078878

Epoch: 6| Step: 3
Training loss: 1.3909751176834106
Validation loss: 1.959484210578344

Epoch: 6| Step: 4
Training loss: 1.6407663822174072
Validation loss: 1.9250401758378552

Epoch: 6| Step: 5
Training loss: 1.4181925058364868
Validation loss: 1.858774294135391

Epoch: 6| Step: 6
Training loss: 1.1533100605010986
Validation loss: 1.8098890486583914

Epoch: 6| Step: 7
Training loss: 1.1074974536895752
Validation loss: 1.7966374581859959

Epoch: 6| Step: 8
Training loss: 1.4199885129928589
Validation loss: 1.7757568897739533

Epoch: 6| Step: 9
Training loss: 0.9034296274185181
Validation loss: 1.77078031211771

Epoch: 6| Step: 10
Training loss: 1.1555582284927368
Validation loss: 1.79373336351046

Epoch: 6| Step: 11
Training loss: 1.2118306159973145
Validation loss: 1.8158255956506217

Epoch: 6| Step: 12
Training loss: 1.9407336711883545
Validation loss: 1.8443090851588915

Epoch: 6| Step: 13
Training loss: 1.333046793937683
Validation loss: 1.8691659165966896

Epoch: 178| Step: 0
Training loss: 1.270787239074707
Validation loss: 1.9005517805776289

Epoch: 6| Step: 1
Training loss: 0.7697702646255493
Validation loss: 1.9110236860090686

Epoch: 6| Step: 2
Training loss: 1.2171962261199951
Validation loss: 1.9156240865748415

Epoch: 6| Step: 3
Training loss: 1.669663906097412
Validation loss: 1.9106873517395349

Epoch: 6| Step: 4
Training loss: 0.7846957445144653
Validation loss: 1.9104337000077771

Epoch: 6| Step: 5
Training loss: 0.7827974557876587
Validation loss: 1.8923653235999487

Epoch: 6| Step: 6
Training loss: 1.45511794090271
Validation loss: 1.8964653092045938

Epoch: 6| Step: 7
Training loss: 1.5868936777114868
Validation loss: 1.8606044682123328

Epoch: 6| Step: 8
Training loss: 0.5837855339050293
Validation loss: 1.8447466511880197

Epoch: 6| Step: 9
Training loss: 1.2966727018356323
Validation loss: 1.8262184986504175

Epoch: 6| Step: 10
Training loss: 1.180851697921753
Validation loss: 1.8198393211569837

Epoch: 6| Step: 11
Training loss: 1.418483018875122
Validation loss: 1.8353329422653362

Epoch: 6| Step: 12
Training loss: 1.7204418182373047
Validation loss: 1.825302872606503

Epoch: 6| Step: 13
Training loss: 1.7506953477859497
Validation loss: 1.8204360828604749

Epoch: 179| Step: 0
Training loss: 1.456583023071289
Validation loss: 1.7982230109553183

Epoch: 6| Step: 1
Training loss: 0.6688964366912842
Validation loss: 1.7906348256654636

Epoch: 6| Step: 2
Training loss: 0.7742069959640503
Validation loss: 1.7976898608669158

Epoch: 6| Step: 3
Training loss: 1.3997957706451416
Validation loss: 1.8232462316431024

Epoch: 6| Step: 4
Training loss: 1.3679265975952148
Validation loss: 1.8326648332739388

Epoch: 6| Step: 5
Training loss: 1.2720513343811035
Validation loss: 1.8567015752997449

Epoch: 6| Step: 6
Training loss: 1.706390380859375
Validation loss: 1.879428425142842

Epoch: 6| Step: 7
Training loss: 1.1898701190948486
Validation loss: 1.8953524302410822

Epoch: 6| Step: 8
Training loss: 1.129603385925293
Validation loss: 1.9044840412755166

Epoch: 6| Step: 9
Training loss: 0.750022292137146
Validation loss: 1.8825697437409432

Epoch: 6| Step: 10
Training loss: 1.1088757514953613
Validation loss: 1.8642331836044148

Epoch: 6| Step: 11
Training loss: 1.3499839305877686
Validation loss: 1.8204809568261588

Epoch: 6| Step: 12
Training loss: 1.331234335899353
Validation loss: 1.8103127607735254

Epoch: 6| Step: 13
Training loss: 1.5900835990905762
Validation loss: 1.7998850666066653

Epoch: 180| Step: 0
Training loss: 1.5469746589660645
Validation loss: 1.7851454378456197

Epoch: 6| Step: 1
Training loss: 1.360990285873413
Validation loss: 1.7969681601370535

Epoch: 6| Step: 2
Training loss: 1.0846103429794312
Validation loss: 1.7868172366132018

Epoch: 6| Step: 3
Training loss: 1.0457676649093628
Validation loss: 1.7930572904566282

Epoch: 6| Step: 4
Training loss: 1.240640640258789
Validation loss: 1.817399481291412

Epoch: 6| Step: 5
Training loss: 1.029034972190857
Validation loss: 1.8311967093457457

Epoch: 6| Step: 6
Training loss: 0.9281667470932007
Validation loss: 1.840133487537343

Epoch: 6| Step: 7
Training loss: 0.9598857164382935
Validation loss: 1.8460919491706356

Epoch: 6| Step: 8
Training loss: 1.112412929534912
Validation loss: 1.8423109234020274

Epoch: 6| Step: 9
Training loss: 0.7959456443786621
Validation loss: 1.8245245359277213

Epoch: 6| Step: 10
Training loss: 1.1523067951202393
Validation loss: 1.834239762316468

Epoch: 6| Step: 11
Training loss: 1.6292532682418823
Validation loss: 1.8453319111178

Epoch: 6| Step: 12
Training loss: 0.8814173936843872
Validation loss: 1.845076343064667

Epoch: 6| Step: 13
Training loss: 1.7587473392486572
Validation loss: 1.831015322798042

Epoch: 181| Step: 0
Training loss: 1.038987159729004
Validation loss: 1.817253649875682

Epoch: 6| Step: 1
Training loss: 1.4064215421676636
Validation loss: 1.8236992384797783

Epoch: 6| Step: 2
Training loss: 1.4048378467559814
Validation loss: 1.8185978076791252

Epoch: 6| Step: 3
Training loss: 1.2746282815933228
Validation loss: 1.8351606271600212

Epoch: 6| Step: 4
Training loss: 1.1056361198425293
Validation loss: 1.8666423533552436

Epoch: 6| Step: 5
Training loss: 1.8367674350738525
Validation loss: 1.8653519102322158

Epoch: 6| Step: 6
Training loss: 0.862437903881073
Validation loss: 1.8711817008192821

Epoch: 6| Step: 7
Training loss: 1.1833497285842896
Validation loss: 1.8376915736864972

Epoch: 6| Step: 8
Training loss: 1.2644206285476685
Validation loss: 1.8119809037895613

Epoch: 6| Step: 9
Training loss: 0.5724054574966431
Validation loss: 1.8043223811734108

Epoch: 6| Step: 10
Training loss: 1.3123022317886353
Validation loss: 1.7985920508702595

Epoch: 6| Step: 11
Training loss: 0.8955762982368469
Validation loss: 1.8015160291425643

Epoch: 6| Step: 12
Training loss: 1.028066635131836
Validation loss: 1.8192205544440978

Epoch: 6| Step: 13
Training loss: 0.7648401856422424
Validation loss: 1.822153228585438

Epoch: 182| Step: 0
Training loss: 0.983036994934082
Validation loss: 1.8311688194992721

Epoch: 6| Step: 1
Training loss: 1.8061424493789673
Validation loss: 1.8303752970951859

Epoch: 6| Step: 2
Training loss: 1.0173523426055908
Validation loss: 1.8810440199349516

Epoch: 6| Step: 3
Training loss: 1.5239243507385254
Validation loss: 1.8978729735138595

Epoch: 6| Step: 4
Training loss: 1.169245719909668
Validation loss: 1.9089181192459599

Epoch: 6| Step: 5
Training loss: 0.9335706233978271
Validation loss: 1.8916991615808139

Epoch: 6| Step: 6
Training loss: 1.3723231554031372
Validation loss: 1.879763671146926

Epoch: 6| Step: 7
Training loss: 0.7888792753219604
Validation loss: 1.8968856398777296

Epoch: 6| Step: 8
Training loss: 1.3607393503189087
Validation loss: 1.8958770139243013

Epoch: 6| Step: 9
Training loss: 1.4416383504867554
Validation loss: 1.8830278047951319

Epoch: 6| Step: 10
Training loss: 0.9400763511657715
Validation loss: 1.8818632620637135

Epoch: 6| Step: 11
Training loss: 0.6466966867446899
Validation loss: 1.8717047219635339

Epoch: 6| Step: 12
Training loss: 0.8684549331665039
Validation loss: 1.827059967543489

Epoch: 6| Step: 13
Training loss: 1.6726813316345215
Validation loss: 1.846551368313451

Epoch: 183| Step: 0
Training loss: 1.9017467498779297
Validation loss: 1.853944109332177

Epoch: 6| Step: 1
Training loss: 1.2971829175949097
Validation loss: 1.8292553271016767

Epoch: 6| Step: 2
Training loss: 0.6677138805389404
Validation loss: 1.8266918633573799

Epoch: 6| Step: 3
Training loss: 0.6694220304489136
Validation loss: 1.8115541627330165

Epoch: 6| Step: 4
Training loss: 0.5495700240135193
Validation loss: 1.7987601590412918

Epoch: 6| Step: 5
Training loss: 1.5097486972808838
Validation loss: 1.8006278340534498

Epoch: 6| Step: 6
Training loss: 1.820508599281311
Validation loss: 1.7914258010925785

Epoch: 6| Step: 7
Training loss: 0.677574872970581
Validation loss: 1.795155466243785

Epoch: 6| Step: 8
Training loss: 0.877281904220581
Validation loss: 1.7793564565720097

Epoch: 6| Step: 9
Training loss: 1.0680325031280518
Validation loss: 1.8008077247168428

Epoch: 6| Step: 10
Training loss: 0.9646562933921814
Validation loss: 1.8313177157473821

Epoch: 6| Step: 11
Training loss: 1.387352466583252
Validation loss: 1.8535599195829002

Epoch: 6| Step: 12
Training loss: 1.3670291900634766
Validation loss: 1.841863364301702

Epoch: 6| Step: 13
Training loss: 1.3376938104629517
Validation loss: 1.8669828291862243

Epoch: 184| Step: 0
Training loss: 1.8711965084075928
Validation loss: 1.855119812873102

Epoch: 6| Step: 1
Training loss: 0.8948131799697876
Validation loss: 1.8676099751585273

Epoch: 6| Step: 2
Training loss: 0.7957477569580078
Validation loss: 1.8869978304832213

Epoch: 6| Step: 3
Training loss: 1.3072452545166016
Validation loss: 1.8800552455327844

Epoch: 6| Step: 4
Training loss: 1.4126787185668945
Validation loss: 1.8462657774648359

Epoch: 6| Step: 5
Training loss: 1.1775360107421875
Validation loss: 1.8148839640361007

Epoch: 6| Step: 6
Training loss: 1.130678653717041
Validation loss: 1.8136532063125281

Epoch: 6| Step: 7
Training loss: 0.44792667031288147
Validation loss: 1.8001435341373566

Epoch: 6| Step: 8
Training loss: 0.800029993057251
Validation loss: 1.7982623833481983

Epoch: 6| Step: 9
Training loss: 1.203550100326538
Validation loss: 1.7904903491338093

Epoch: 6| Step: 10
Training loss: 1.2733714580535889
Validation loss: 1.8078087055554954

Epoch: 6| Step: 11
Training loss: 1.2894675731658936
Validation loss: 1.8121482121047152

Epoch: 6| Step: 12
Training loss: 1.0571564435958862
Validation loss: 1.7882979275077902

Epoch: 6| Step: 13
Training loss: 1.3266879320144653
Validation loss: 1.7977310842083347

Epoch: 185| Step: 0
Training loss: 1.1264548301696777
Validation loss: 1.7748669988365584

Epoch: 6| Step: 1
Training loss: 0.6142248511314392
Validation loss: 1.7654871863703574

Epoch: 6| Step: 2
Training loss: 1.5633065700531006
Validation loss: 1.7715837391473914

Epoch: 6| Step: 3
Training loss: 1.4388153553009033
Validation loss: 1.7906128078378656

Epoch: 6| Step: 4
Training loss: 1.0064985752105713
Validation loss: 1.7818658121170536

Epoch: 6| Step: 5
Training loss: 1.4412811994552612
Validation loss: 1.7788590692704724

Epoch: 6| Step: 6
Training loss: 1.3477425575256348
Validation loss: 1.7961086688503143

Epoch: 6| Step: 7
Training loss: 0.747778058052063
Validation loss: 1.8173626648482455

Epoch: 6| Step: 8
Training loss: 1.0558348894119263
Validation loss: 1.8421549104875135

Epoch: 6| Step: 9
Training loss: 1.0713742971420288
Validation loss: 1.8436921463217786

Epoch: 6| Step: 10
Training loss: 1.0908925533294678
Validation loss: 1.8413580694506246

Epoch: 6| Step: 11
Training loss: 1.3844261169433594
Validation loss: 1.8488923298415316

Epoch: 6| Step: 12
Training loss: 0.7181200981140137
Validation loss: 1.8487923170930596

Epoch: 6| Step: 13
Training loss: 0.984465479850769
Validation loss: 1.8354785839716594

Epoch: 186| Step: 0
Training loss: 1.2598927021026611
Validation loss: 1.8348984615777129

Epoch: 6| Step: 1
Training loss: 1.639358401298523
Validation loss: 1.8261311054229736

Epoch: 6| Step: 2
Training loss: 1.164321780204773
Validation loss: 1.8157566093629407

Epoch: 6| Step: 3
Training loss: 0.8000891804695129
Validation loss: 1.8084646630030807

Epoch: 6| Step: 4
Training loss: 0.7051472663879395
Validation loss: 1.810749368001056

Epoch: 6| Step: 5
Training loss: 0.6077352166175842
Validation loss: 1.7892366878447994

Epoch: 6| Step: 6
Training loss: 0.9233034253120422
Validation loss: 1.779662424518216

Epoch: 6| Step: 7
Training loss: 1.4362285137176514
Validation loss: 1.78549886134363

Epoch: 6| Step: 8
Training loss: 0.9430472254753113
Validation loss: 1.7924200732220885

Epoch: 6| Step: 9
Training loss: 1.4007515907287598
Validation loss: 1.7818682193756104

Epoch: 6| Step: 10
Training loss: 0.9260733127593994
Validation loss: 1.7818858277413152

Epoch: 6| Step: 11
Training loss: 1.2221081256866455
Validation loss: 1.7823791452633437

Epoch: 6| Step: 12
Training loss: 1.2278878688812256
Validation loss: 1.7749480855080388

Epoch: 6| Step: 13
Training loss: 0.619867742061615
Validation loss: 1.7785543651990994

Epoch: 187| Step: 0
Training loss: 1.1098017692565918
Validation loss: 1.7692715698672878

Epoch: 6| Step: 1
Training loss: 1.328298807144165
Validation loss: 1.7712238821932065

Epoch: 6| Step: 2
Training loss: 1.264542579650879
Validation loss: 1.7717503450250114

Epoch: 6| Step: 3
Training loss: 1.0905382633209229
Validation loss: 1.7994149654142317

Epoch: 6| Step: 4
Training loss: 1.0555498600006104
Validation loss: 1.7842929940069876

Epoch: 6| Step: 5
Training loss: 0.7738971710205078
Validation loss: 1.7769764046515188

Epoch: 6| Step: 6
Training loss: 0.5757166147232056
Validation loss: 1.8100090488310783

Epoch: 6| Step: 7
Training loss: 0.8137685656547546
Validation loss: 1.799217418957782

Epoch: 6| Step: 8
Training loss: 1.1165790557861328
Validation loss: 1.8141612673318515

Epoch: 6| Step: 9
Training loss: 1.0076816082000732
Validation loss: 1.812173742119984

Epoch: 6| Step: 10
Training loss: 1.0723191499710083
Validation loss: 1.7922172238749843

Epoch: 6| Step: 11
Training loss: 0.9082835912704468
Validation loss: 1.8055131307212255

Epoch: 6| Step: 12
Training loss: 1.2046854496002197
Validation loss: 1.78360927233132

Epoch: 6| Step: 13
Training loss: 1.68285071849823
Validation loss: 1.8171459859417332

Epoch: 188| Step: 0
Training loss: 1.248645544052124
Validation loss: 1.8506616905171385

Epoch: 6| Step: 1
Training loss: 0.9500312805175781
Validation loss: 1.845729515116702

Epoch: 6| Step: 2
Training loss: 1.0174764394760132
Validation loss: 1.8630459334260674

Epoch: 6| Step: 3
Training loss: 1.2685606479644775
Validation loss: 1.8527145103741718

Epoch: 6| Step: 4
Training loss: 0.7981138229370117
Validation loss: 1.829857862123879

Epoch: 6| Step: 5
Training loss: 1.2874648571014404
Validation loss: 1.8157924362408218

Epoch: 6| Step: 6
Training loss: 1.2942163944244385
Validation loss: 1.8291988218984296

Epoch: 6| Step: 7
Training loss: 0.7112852334976196
Validation loss: 1.8129930996125745

Epoch: 6| Step: 8
Training loss: 1.0154825448989868
Validation loss: 1.7967871812082106

Epoch: 6| Step: 9
Training loss: 1.4456878900527954
Validation loss: 1.8182418615587297

Epoch: 6| Step: 10
Training loss: 0.6260823607444763
Validation loss: 1.8163031506282028

Epoch: 6| Step: 11
Training loss: 0.8652161359786987
Validation loss: 1.79897694049343

Epoch: 6| Step: 12
Training loss: 1.0335111618041992
Validation loss: 1.7827049134879984

Epoch: 6| Step: 13
Training loss: 0.92070472240448
Validation loss: 1.7746791813963203

Epoch: 189| Step: 0
Training loss: 1.1903103590011597
Validation loss: 1.7562117615053732

Epoch: 6| Step: 1
Training loss: 1.137757420539856
Validation loss: 1.7471922879577966

Epoch: 6| Step: 2
Training loss: 0.912141740322113
Validation loss: 1.750644108300568

Epoch: 6| Step: 3
Training loss: 1.448052167892456
Validation loss: 1.767699001937784

Epoch: 6| Step: 4
Training loss: 1.4160659313201904
Validation loss: 1.7677969214736775

Epoch: 6| Step: 5
Training loss: 0.8849067687988281
Validation loss: 1.7990577195280342

Epoch: 6| Step: 6
Training loss: 1.1617186069488525
Validation loss: 1.80881820442856

Epoch: 6| Step: 7
Training loss: 0.8644469976425171
Validation loss: 1.8004722210668749

Epoch: 6| Step: 8
Training loss: 0.7267969846725464
Validation loss: 1.812926725674701

Epoch: 6| Step: 9
Training loss: 1.1497052907943726
Validation loss: 1.774385476625094

Epoch: 6| Step: 10
Training loss: 1.0448765754699707
Validation loss: 1.7576350576134139

Epoch: 6| Step: 11
Training loss: 0.8434807062149048
Validation loss: 1.7204153460841025

Epoch: 6| Step: 12
Training loss: 0.5234498381614685
Validation loss: 1.7125808551747312

Epoch: 6| Step: 13
Training loss: 0.9663782119750977
Validation loss: 1.7174430457494592

Epoch: 190| Step: 0
Training loss: 1.4390275478363037
Validation loss: 1.730108904582198

Epoch: 6| Step: 1
Training loss: 0.7170796990394592
Validation loss: 1.7207130385983376

Epoch: 6| Step: 2
Training loss: 0.8050703406333923
Validation loss: 1.732353320685766

Epoch: 6| Step: 3
Training loss: 0.8646542429924011
Validation loss: 1.7332941434716667

Epoch: 6| Step: 4
Training loss: 0.8948345184326172
Validation loss: 1.7519098892006824

Epoch: 6| Step: 5
Training loss: 1.0743858814239502
Validation loss: 1.7591881072649391

Epoch: 6| Step: 6
Training loss: 0.7935328483581543
Validation loss: 1.7677672934788529

Epoch: 6| Step: 7
Training loss: 0.8946781158447266
Validation loss: 1.7652544539461854

Epoch: 6| Step: 8
Training loss: 1.5590009689331055
Validation loss: 1.7858147992882678

Epoch: 6| Step: 9
Training loss: 1.367144227027893
Validation loss: 1.825147081446904

Epoch: 6| Step: 10
Training loss: 1.178911566734314
Validation loss: 1.8182571626478625

Epoch: 6| Step: 11
Training loss: 1.013051152229309
Validation loss: 1.8205999046243646

Epoch: 6| Step: 12
Training loss: 0.6433708667755127
Validation loss: 1.8035436855849398

Epoch: 6| Step: 13
Training loss: 0.8554064035415649
Validation loss: 1.8022032835150277

Epoch: 191| Step: 0
Training loss: 0.6580896973609924
Validation loss: 1.7917040189107258

Epoch: 6| Step: 1
Training loss: 1.2051626443862915
Validation loss: 1.8030021857189875

Epoch: 6| Step: 2
Training loss: 0.8556297421455383
Validation loss: 1.820027728234568

Epoch: 6| Step: 3
Training loss: 1.1207947731018066
Validation loss: 1.8434760134707215

Epoch: 6| Step: 4
Training loss: 0.9575730562210083
Validation loss: 1.843856692314148

Epoch: 6| Step: 5
Training loss: 0.7648864984512329
Validation loss: 1.8371484151450537

Epoch: 6| Step: 6
Training loss: 1.0906193256378174
Validation loss: 1.8074329719748548

Epoch: 6| Step: 7
Training loss: 1.074072241783142
Validation loss: 1.7889224470302623

Epoch: 6| Step: 8
Training loss: 0.9653732776641846
Validation loss: 1.7756486528663225

Epoch: 6| Step: 9
Training loss: 1.3216886520385742
Validation loss: 1.7569876409346057

Epoch: 6| Step: 10
Training loss: 0.9982963800430298
Validation loss: 1.7619835074229906

Epoch: 6| Step: 11
Training loss: 0.8704468607902527
Validation loss: 1.7394952633047616

Epoch: 6| Step: 12
Training loss: 1.0212560892105103
Validation loss: 1.7238337980803622

Epoch: 6| Step: 13
Training loss: 0.8585342764854431
Validation loss: 1.7320011354261828

Epoch: 192| Step: 0
Training loss: 0.5909957885742188
Validation loss: 1.7365402688262284

Epoch: 6| Step: 1
Training loss: 1.0932905673980713
Validation loss: 1.7381518169115948

Epoch: 6| Step: 2
Training loss: 1.4013681411743164
Validation loss: 1.7424378625808223

Epoch: 6| Step: 3
Training loss: 1.0215284824371338
Validation loss: 1.7405697786679832

Epoch: 6| Step: 4
Training loss: 1.0565968751907349
Validation loss: 1.7480415349365563

Epoch: 6| Step: 5
Training loss: 0.48248910903930664
Validation loss: 1.7555357845880653

Epoch: 6| Step: 6
Training loss: 1.0957242250442505
Validation loss: 1.752691891885573

Epoch: 6| Step: 7
Training loss: 1.2156715393066406
Validation loss: 1.755572521558372

Epoch: 6| Step: 8
Training loss: 0.5813871622085571
Validation loss: 1.7747630585906327

Epoch: 6| Step: 9
Training loss: 0.9910953044891357
Validation loss: 1.8030509320638513

Epoch: 6| Step: 10
Training loss: 1.0400278568267822
Validation loss: 1.7926458556164977

Epoch: 6| Step: 11
Training loss: 0.8139166831970215
Validation loss: 1.7669722803177372

Epoch: 6| Step: 12
Training loss: 1.2350776195526123
Validation loss: 1.7726553716967184

Epoch: 6| Step: 13
Training loss: 0.8995646238327026
Validation loss: 1.7594574907774567

Epoch: 193| Step: 0
Training loss: 0.681032657623291
Validation loss: 1.7647352808265275

Epoch: 6| Step: 1
Training loss: 0.6040235161781311
Validation loss: 1.768404318440345

Epoch: 6| Step: 2
Training loss: 1.4981211423873901
Validation loss: 1.8108651150939286

Epoch: 6| Step: 3
Training loss: 1.1452109813690186
Validation loss: 1.7881669882805116

Epoch: 6| Step: 4
Training loss: 0.7878036499023438
Validation loss: 1.7666201437673261

Epoch: 6| Step: 5
Training loss: 0.5878043174743652
Validation loss: 1.7490991853898572

Epoch: 6| Step: 6
Training loss: 1.6068310737609863
Validation loss: 1.7607878190214916

Epoch: 6| Step: 7
Training loss: 0.9225149154663086
Validation loss: 1.7730288902918498

Epoch: 6| Step: 8
Training loss: 1.050145149230957
Validation loss: 1.761873581076181

Epoch: 6| Step: 9
Training loss: 0.5885133743286133
Validation loss: 1.7333066412197646

Epoch: 6| Step: 10
Training loss: 1.1249998807907104
Validation loss: 1.7163803115967782

Epoch: 6| Step: 11
Training loss: 1.0102312564849854
Validation loss: 1.7220906865212224

Epoch: 6| Step: 12
Training loss: 0.8230332732200623
Validation loss: 1.700193400024086

Epoch: 6| Step: 13
Training loss: 1.492258071899414
Validation loss: 1.7161795759713778

Epoch: 194| Step: 0
Training loss: 0.987460732460022
Validation loss: 1.722036571912868

Epoch: 6| Step: 1
Training loss: 0.6816465854644775
Validation loss: 1.7600695708746552

Epoch: 6| Step: 2
Training loss: 0.5840541124343872
Validation loss: 1.7407277527675833

Epoch: 6| Step: 3
Training loss: 0.8460869789123535
Validation loss: 1.7509086029503935

Epoch: 6| Step: 4
Training loss: 1.0129777193069458
Validation loss: 1.7531578950984503

Epoch: 6| Step: 5
Training loss: 1.2457685470581055
Validation loss: 1.7623250189647879

Epoch: 6| Step: 6
Training loss: 0.8991481065750122
Validation loss: 1.8066797102651289

Epoch: 6| Step: 7
Training loss: 1.2184243202209473
Validation loss: 1.827683953828709

Epoch: 6| Step: 8
Training loss: 1.1574387550354004
Validation loss: 1.8417877933030486

Epoch: 6| Step: 9
Training loss: 1.2642649412155151
Validation loss: 1.8282208981052521

Epoch: 6| Step: 10
Training loss: 0.7049431204795837
Validation loss: 1.8113148161160049

Epoch: 6| Step: 11
Training loss: 0.7517956495285034
Validation loss: 1.7907226982937063

Epoch: 6| Step: 12
Training loss: 1.0452946424484253
Validation loss: 1.7923796561456495

Epoch: 6| Step: 13
Training loss: 0.8427683115005493
Validation loss: 1.7864873050361552

Epoch: 195| Step: 0
Training loss: 1.1171696186065674
Validation loss: 1.7769419595759401

Epoch: 6| Step: 1
Training loss: 0.5437003970146179
Validation loss: 1.7675199636849024

Epoch: 6| Step: 2
Training loss: 0.97818922996521
Validation loss: 1.760059029825272

Epoch: 6| Step: 3
Training loss: 1.1280765533447266
Validation loss: 1.7694795887957337

Epoch: 6| Step: 4
Training loss: 0.7632366418838501
Validation loss: 1.792831213243546

Epoch: 6| Step: 5
Training loss: 1.1381480693817139
Validation loss: 1.7771000567302908

Epoch: 6| Step: 6
Training loss: 0.46358031034469604
Validation loss: 1.7972846159370996

Epoch: 6| Step: 7
Training loss: 0.9421648383140564
Validation loss: 1.8276389119445637

Epoch: 6| Step: 8
Training loss: 1.1630172729492188
Validation loss: 1.816277568058301

Epoch: 6| Step: 9
Training loss: 0.5700044631958008
Validation loss: 1.7980610862854989

Epoch: 6| Step: 10
Training loss: 1.236255407333374
Validation loss: 1.7745059536349388

Epoch: 6| Step: 11
Training loss: 1.3714700937271118
Validation loss: 1.7474701519935363

Epoch: 6| Step: 12
Training loss: 1.2988790273666382
Validation loss: 1.7438472701657204

Epoch: 6| Step: 13
Training loss: 0.6830446720123291
Validation loss: 1.7388160908094017

Epoch: 196| Step: 0
Training loss: 0.8105455636978149
Validation loss: 1.7290458576653593

Epoch: 6| Step: 1
Training loss: 0.7567404508590698
Validation loss: 1.7424122518108738

Epoch: 6| Step: 2
Training loss: 0.7267422080039978
Validation loss: 1.753324882958525

Epoch: 6| Step: 3
Training loss: 0.709308922290802
Validation loss: 1.7390971901596233

Epoch: 6| Step: 4
Training loss: 1.206622838973999
Validation loss: 1.7423476455032185

Epoch: 6| Step: 5
Training loss: 0.9273022413253784
Validation loss: 1.7688034144780969

Epoch: 6| Step: 6
Training loss: 1.665734887123108
Validation loss: 1.7545804054506364

Epoch: 6| Step: 7
Training loss: 0.7142438888549805
Validation loss: 1.7534359270526516

Epoch: 6| Step: 8
Training loss: 0.9111335277557373
Validation loss: 1.7762533195557133

Epoch: 6| Step: 9
Training loss: 1.280827522277832
Validation loss: 1.7619846174793858

Epoch: 6| Step: 10
Training loss: 0.6801738142967224
Validation loss: 1.7506456144394413

Epoch: 6| Step: 11
Training loss: 0.9240633845329285
Validation loss: 1.728888544985043

Epoch: 6| Step: 12
Training loss: 0.8942591547966003
Validation loss: 1.706760689776431

Epoch: 6| Step: 13
Training loss: 1.051990270614624
Validation loss: 1.6883400268452142

Epoch: 197| Step: 0
Training loss: 1.285498023033142
Validation loss: 1.6843960849187707

Epoch: 6| Step: 1
Training loss: 0.7428597211837769
Validation loss: 1.7048520465050974

Epoch: 6| Step: 2
Training loss: 0.9783161282539368
Validation loss: 1.7253795541742796

Epoch: 6| Step: 3
Training loss: 0.641432523727417
Validation loss: 1.7324682512590963

Epoch: 6| Step: 4
Training loss: 0.7373840808868408
Validation loss: 1.7257033112228557

Epoch: 6| Step: 5
Training loss: 1.579538106918335
Validation loss: 1.730913016103929

Epoch: 6| Step: 6
Training loss: 0.6056678295135498
Validation loss: 1.7498826634499334

Epoch: 6| Step: 7
Training loss: 0.8699721097946167
Validation loss: 1.7689826052675965

Epoch: 6| Step: 8
Training loss: 1.2922310829162598
Validation loss: 1.8064874256810834

Epoch: 6| Step: 9
Training loss: 0.8791589140892029
Validation loss: 1.7901897597056564

Epoch: 6| Step: 10
Training loss: 0.7930634021759033
Validation loss: 1.7902217167679981

Epoch: 6| Step: 11
Training loss: 0.7127163410186768
Validation loss: 1.7705991857795305

Epoch: 6| Step: 12
Training loss: 1.1108014583587646
Validation loss: 1.78995124114457

Epoch: 6| Step: 13
Training loss: 0.5924777984619141
Validation loss: 1.8046561415477465

Epoch: 198| Step: 0
Training loss: 0.8417862057685852
Validation loss: 1.7665209475383963

Epoch: 6| Step: 1
Training loss: 1.1029682159423828
Validation loss: 1.7531865489098333

Epoch: 6| Step: 2
Training loss: 0.8526086807250977
Validation loss: 1.7125099775611714

Epoch: 6| Step: 3
Training loss: 0.7616389393806458
Validation loss: 1.715775502625332

Epoch: 6| Step: 4
Training loss: 0.8229742050170898
Validation loss: 1.7011528156136955

Epoch: 6| Step: 5
Training loss: 0.7692627310752869
Validation loss: 1.7119953427263486

Epoch: 6| Step: 6
Training loss: 0.9944557547569275
Validation loss: 1.7248316605885823

Epoch: 6| Step: 7
Training loss: 1.031476616859436
Validation loss: 1.7486309902642363

Epoch: 6| Step: 8
Training loss: 0.9626436233520508
Validation loss: 1.7895240450418124

Epoch: 6| Step: 9
Training loss: 0.9850070476531982
Validation loss: 1.848359679663053

Epoch: 6| Step: 10
Training loss: 1.2183847427368164
Validation loss: 1.8624155867484309

Epoch: 6| Step: 11
Training loss: 0.8473430275917053
Validation loss: 1.8789508291470107

Epoch: 6| Step: 12
Training loss: 0.7773698568344116
Validation loss: 1.8770061577520063

Epoch: 6| Step: 13
Training loss: 1.2636560201644897
Validation loss: 1.864150990722

Epoch: 199| Step: 0
Training loss: 0.7188107967376709
Validation loss: 1.813231711746544

Epoch: 6| Step: 1
Training loss: 0.6110763549804688
Validation loss: 1.7793106532865954

Epoch: 6| Step: 2
Training loss: 1.3346138000488281
Validation loss: 1.7667909822156351

Epoch: 6| Step: 3
Training loss: 0.6869083046913147
Validation loss: 1.741387148057261

Epoch: 6| Step: 4
Training loss: 0.9492353200912476
Validation loss: 1.7288009658936532

Epoch: 6| Step: 5
Training loss: 0.9391996264457703
Validation loss: 1.7445891057291338

Epoch: 6| Step: 6
Training loss: 0.6704664826393127
Validation loss: 1.7553336786967453

Epoch: 6| Step: 7
Training loss: 1.1418659687042236
Validation loss: 1.7399576043569913

Epoch: 6| Step: 8
Training loss: 0.9618320465087891
Validation loss: 1.744752522437803

Epoch: 6| Step: 9
Training loss: 0.9943808913230896
Validation loss: 1.755835545960293

Epoch: 6| Step: 10
Training loss: 1.1392176151275635
Validation loss: 1.74325224661058

Epoch: 6| Step: 11
Training loss: 0.7947472333908081
Validation loss: 1.7473187485048849

Epoch: 6| Step: 12
Training loss: 0.9664119482040405
Validation loss: 1.7319818389031194

Epoch: 6| Step: 13
Training loss: 1.0069258213043213
Validation loss: 1.7311430643963557

Epoch: 200| Step: 0
Training loss: 0.5977680683135986
Validation loss: 1.7229047142049319

Epoch: 6| Step: 1
Training loss: 0.4445568323135376
Validation loss: 1.7036538739358225

Epoch: 6| Step: 2
Training loss: 0.9243801236152649
Validation loss: 1.7111071489190544

Epoch: 6| Step: 3
Training loss: 0.7564228773117065
Validation loss: 1.698979466192184

Epoch: 6| Step: 4
Training loss: 1.0218459367752075
Validation loss: 1.716589831536816

Epoch: 6| Step: 5
Training loss: 0.7615714073181152
Validation loss: 1.7333127965209305

Epoch: 6| Step: 6
Training loss: 1.032963514328003
Validation loss: 1.7438183510175316

Epoch: 6| Step: 7
Training loss: 1.1400624513626099
Validation loss: 1.7359028708550237

Epoch: 6| Step: 8
Training loss: 1.0368313789367676
Validation loss: 1.764953483817398

Epoch: 6| Step: 9
Training loss: 0.9972360134124756
Validation loss: 1.7669716394075783

Epoch: 6| Step: 10
Training loss: 0.9096792936325073
Validation loss: 1.749005502270114

Epoch: 6| Step: 11
Training loss: 1.0317866802215576
Validation loss: 1.7668595506298927

Epoch: 6| Step: 12
Training loss: 0.8126118183135986
Validation loss: 1.7729843316539642

Epoch: 6| Step: 13
Training loss: 0.6109371185302734
Validation loss: 1.7752723283665155

Epoch: 201| Step: 0
Training loss: 0.6044055223464966
Validation loss: 1.7747670681245866

Epoch: 6| Step: 1
Training loss: 0.8753606677055359
Validation loss: 1.8006447079361125

Epoch: 6| Step: 2
Training loss: 1.1154685020446777
Validation loss: 1.7813878546478927

Epoch: 6| Step: 3
Training loss: 0.4786221385002136
Validation loss: 1.7505049526050527

Epoch: 6| Step: 4
Training loss: 0.7290215492248535
Validation loss: 1.7686111004121843

Epoch: 6| Step: 5
Training loss: 0.812024712562561
Validation loss: 1.7361878759117537

Epoch: 6| Step: 6
Training loss: 0.9241976737976074
Validation loss: 1.7338408988009217

Epoch: 6| Step: 7
Training loss: 1.4184026718139648
Validation loss: 1.7254055033447921

Epoch: 6| Step: 8
Training loss: 0.987915575504303
Validation loss: 1.7097797329707811

Epoch: 6| Step: 9
Training loss: 0.972607433795929
Validation loss: 1.7207354037992415

Epoch: 6| Step: 10
Training loss: 0.8111867308616638
Validation loss: 1.728474445240472

Epoch: 6| Step: 11
Training loss: 0.8401596546173096
Validation loss: 1.7266305146678802

Epoch: 6| Step: 12
Training loss: 0.9022654891014099
Validation loss: 1.7386768428228234

Epoch: 6| Step: 13
Training loss: 1.2204397916793823
Validation loss: 1.7490389218894384

Epoch: 202| Step: 0
Training loss: 0.8534650802612305
Validation loss: 1.7465851409460909

Epoch: 6| Step: 1
Training loss: 0.8948506116867065
Validation loss: 1.739468478387402

Epoch: 6| Step: 2
Training loss: 0.939594030380249
Validation loss: 1.710590483039938

Epoch: 6| Step: 3
Training loss: 1.01115083694458
Validation loss: 1.7192233031795872

Epoch: 6| Step: 4
Training loss: 1.1340018510818481
Validation loss: 1.7210760757487307

Epoch: 6| Step: 5
Training loss: 0.636902928352356
Validation loss: 1.6998321625494188

Epoch: 6| Step: 6
Training loss: 0.6471631526947021
Validation loss: 1.718977875606988

Epoch: 6| Step: 7
Training loss: 0.5854244828224182
Validation loss: 1.7088720862583449

Epoch: 6| Step: 8
Training loss: 0.7383562326431274
Validation loss: 1.7136109875094505

Epoch: 6| Step: 9
Training loss: 0.4714146852493286
Validation loss: 1.7158210636467062

Epoch: 6| Step: 10
Training loss: 0.8643356561660767
Validation loss: 1.6926925438706593

Epoch: 6| Step: 11
Training loss: 1.2403790950775146
Validation loss: 1.6865181871639785

Epoch: 6| Step: 12
Training loss: 0.704654335975647
Validation loss: 1.6926516461116012

Epoch: 6| Step: 13
Training loss: 1.2104045152664185
Validation loss: 1.688846367661671

Epoch: 203| Step: 0
Training loss: 1.1999180316925049
Validation loss: 1.6698059112794938

Epoch: 6| Step: 1
Training loss: 1.1665241718292236
Validation loss: 1.6670131426985546

Epoch: 6| Step: 2
Training loss: 0.6061631441116333
Validation loss: 1.6686403956464542

Epoch: 6| Step: 3
Training loss: 0.8079574108123779
Validation loss: 1.674449215653122

Epoch: 6| Step: 4
Training loss: 0.8656999468803406
Validation loss: 1.6887796642959758

Epoch: 6| Step: 5
Training loss: 0.5513515472412109
Validation loss: 1.6937335703962593

Epoch: 6| Step: 6
Training loss: 0.8667728304862976
Validation loss: 1.6898250913107267

Epoch: 6| Step: 7
Training loss: 0.556513786315918
Validation loss: 1.6935341114638953

Epoch: 6| Step: 8
Training loss: 0.7620623111724854
Validation loss: 1.7099342833283127

Epoch: 6| Step: 9
Training loss: 0.6624284386634827
Validation loss: 1.704075478738354

Epoch: 6| Step: 10
Training loss: 0.694069504737854
Validation loss: 1.6919385989507039

Epoch: 6| Step: 11
Training loss: 1.0678908824920654
Validation loss: 1.6940146684646606

Epoch: 6| Step: 12
Training loss: 1.0258114337921143
Validation loss: 1.6902104398255706

Epoch: 6| Step: 13
Training loss: 0.6033602952957153
Validation loss: 1.6790631971051615

Epoch: 204| Step: 0
Training loss: 0.6395044326782227
Validation loss: 1.6979509963784167

Epoch: 6| Step: 1
Training loss: 1.1955310106277466
Validation loss: 1.724917357967746

Epoch: 6| Step: 2
Training loss: 0.9620540142059326
Validation loss: 1.7409061296011812

Epoch: 6| Step: 3
Training loss: 1.1814782619476318
Validation loss: 1.766733346446868

Epoch: 6| Step: 4
Training loss: 0.90770024061203
Validation loss: 1.7722337733032882

Epoch: 6| Step: 5
Training loss: 0.7256394028663635
Validation loss: 1.7929937557507587

Epoch: 6| Step: 6
Training loss: 0.8466736078262329
Validation loss: 1.7694595808623939

Epoch: 6| Step: 7
Training loss: 0.7549943327903748
Validation loss: 1.7760044285046157

Epoch: 6| Step: 8
Training loss: 0.38679105043411255
Validation loss: 1.7473510080768215

Epoch: 6| Step: 9
Training loss: 0.6976826190948486
Validation loss: 1.7497507192755257

Epoch: 6| Step: 10
Training loss: 0.6684626936912537
Validation loss: 1.7355929587476997

Epoch: 6| Step: 11
Training loss: 0.4821534752845764
Validation loss: 1.6950196784029725

Epoch: 6| Step: 12
Training loss: 1.0357794761657715
Validation loss: 1.6894681248613583

Epoch: 6| Step: 13
Training loss: 0.766277551651001
Validation loss: 1.6784902875141432

Epoch: 205| Step: 0
Training loss: 0.541421115398407
Validation loss: 1.6559523177403275

Epoch: 6| Step: 1
Training loss: 0.8641030788421631
Validation loss: 1.6696806082161524

Epoch: 6| Step: 2
Training loss: 1.1405320167541504
Validation loss: 1.6637322338678504

Epoch: 6| Step: 3
Training loss: 0.9021551012992859
Validation loss: 1.6904176024980442

Epoch: 6| Step: 4
Training loss: 0.832120418548584
Validation loss: 1.718703839086717

Epoch: 6| Step: 5
Training loss: 0.6196324825286865
Validation loss: 1.7261420437084731

Epoch: 6| Step: 6
Training loss: 0.6782269477844238
Validation loss: 1.727239151154795

Epoch: 6| Step: 7
Training loss: 1.041623592376709
Validation loss: 1.7168495590968798

Epoch: 6| Step: 8
Training loss: 0.7336214780807495
Validation loss: 1.7176146276535527

Epoch: 6| Step: 9
Training loss: 0.9060391187667847
Validation loss: 1.7223881598441833

Epoch: 6| Step: 10
Training loss: 1.0707929134368896
Validation loss: 1.698316648442258

Epoch: 6| Step: 11
Training loss: 0.6458512544631958
Validation loss: 1.69660900356949

Epoch: 6| Step: 12
Training loss: 0.4506872296333313
Validation loss: 1.6943685957180556

Epoch: 6| Step: 13
Training loss: 0.289936900138855
Validation loss: 1.6912623156783402

Epoch: 206| Step: 0
Training loss: 1.0762526988983154
Validation loss: 1.707384080015203

Epoch: 6| Step: 1
Training loss: 0.6019632816314697
Validation loss: 1.7136451505845594

Epoch: 6| Step: 2
Training loss: 0.8264937400817871
Validation loss: 1.7297971235808505

Epoch: 6| Step: 3
Training loss: 0.5991851091384888
Validation loss: 1.7115113094288816

Epoch: 6| Step: 4
Training loss: 0.6049149036407471
Validation loss: 1.7202596972065587

Epoch: 6| Step: 5
Training loss: 0.7419286966323853
Validation loss: 1.7068047959317443

Epoch: 6| Step: 6
Training loss: 0.7451730370521545
Validation loss: 1.728352269818706

Epoch: 6| Step: 7
Training loss: 1.1771868467330933
Validation loss: 1.7099985819990917

Epoch: 6| Step: 8
Training loss: 0.5289055109024048
Validation loss: 1.7196315014234154

Epoch: 6| Step: 9
Training loss: 0.9475314617156982
Validation loss: 1.7234919430107198

Epoch: 6| Step: 10
Training loss: 0.9484756588935852
Validation loss: 1.7023400414374568

Epoch: 6| Step: 11
Training loss: 0.5516759753227234
Validation loss: 1.6906428824188888

Epoch: 6| Step: 12
Training loss: 0.7382612824440002
Validation loss: 1.6721082874523696

Epoch: 6| Step: 13
Training loss: 0.5707561373710632
Validation loss: 1.6739701788912538

Epoch: 207| Step: 0
Training loss: 0.5854300856590271
Validation loss: 1.6784861126253683

Epoch: 6| Step: 1
Training loss: 0.6870445013046265
Validation loss: 1.6579554132235947

Epoch: 6| Step: 2
Training loss: 0.7024420499801636
Validation loss: 1.6703048675291

Epoch: 6| Step: 3
Training loss: 0.5675761699676514
Validation loss: 1.6530483961105347

Epoch: 6| Step: 4
Training loss: 1.0168232917785645
Validation loss: 1.6612086834446076

Epoch: 6| Step: 5
Training loss: 0.7832850217819214
Validation loss: 1.691178592302466

Epoch: 6| Step: 6
Training loss: 0.6588108539581299
Validation loss: 1.6480374361879082

Epoch: 6| Step: 7
Training loss: 0.8566007614135742
Validation loss: 1.6717783738208074

Epoch: 6| Step: 8
Training loss: 0.8415570259094238
Validation loss: 1.6762841260561379

Epoch: 6| Step: 9
Training loss: 0.5224243402481079
Validation loss: 1.6582170929960025

Epoch: 6| Step: 10
Training loss: 0.7655998468399048
Validation loss: 1.654034694035848

Epoch: 6| Step: 11
Training loss: 0.6313931345939636
Validation loss: 1.6783324531329575

Epoch: 6| Step: 12
Training loss: 0.7526740431785583
Validation loss: 1.6701162976603354

Epoch: 6| Step: 13
Training loss: 1.1881577968597412
Validation loss: 1.6833337224939817

Epoch: 208| Step: 0
Training loss: 1.2104231119155884
Validation loss: 1.6742106419737621

Epoch: 6| Step: 1
Training loss: 0.45414382219314575
Validation loss: 1.6743720936518844

Epoch: 6| Step: 2
Training loss: 0.46376386284828186
Validation loss: 1.6804805032668575

Epoch: 6| Step: 3
Training loss: 0.83393394947052
Validation loss: 1.6964751033372776

Epoch: 6| Step: 4
Training loss: 0.5108366012573242
Validation loss: 1.6851213901273665

Epoch: 6| Step: 5
Training loss: 0.569360077381134
Validation loss: 1.6689202657309912

Epoch: 6| Step: 6
Training loss: 0.6852068901062012
Validation loss: 1.685821828021798

Epoch: 6| Step: 7
Training loss: 0.5090054273605347
Validation loss: 1.693300562520181

Epoch: 6| Step: 8
Training loss: 1.2083497047424316
Validation loss: 1.6832706364252235

Epoch: 6| Step: 9
Training loss: 0.7014594078063965
Validation loss: 1.6692650830873879

Epoch: 6| Step: 10
Training loss: 0.7669651508331299
Validation loss: 1.6387760882736535

Epoch: 6| Step: 11
Training loss: 0.7281015515327454
Validation loss: 1.6536443259126397

Epoch: 6| Step: 12
Training loss: 0.7483929395675659
Validation loss: 1.6631906109471475

Epoch: 6| Step: 13
Training loss: 0.7968816757202148
Validation loss: 1.655729587360095

Epoch: 209| Step: 0
Training loss: 0.7998424768447876
Validation loss: 1.6746634949919998

Epoch: 6| Step: 1
Training loss: 0.8057654500007629
Validation loss: 1.6746539185124059

Epoch: 6| Step: 2
Training loss: 0.7776284217834473
Validation loss: 1.6771271280063096

Epoch: 6| Step: 3
Training loss: 0.591209888458252
Validation loss: 1.708038664633228

Epoch: 6| Step: 4
Training loss: 0.95264732837677
Validation loss: 1.6938401947739303

Epoch: 6| Step: 5
Training loss: 0.8333143591880798
Validation loss: 1.7034795258634834

Epoch: 6| Step: 6
Training loss: 0.8282120823860168
Validation loss: 1.726150490904367

Epoch: 6| Step: 7
Training loss: 0.42629942297935486
Validation loss: 1.7336939688651793

Epoch: 6| Step: 8
Training loss: 0.6738801002502441
Validation loss: 1.7444711436507523

Epoch: 6| Step: 9
Training loss: 0.7401424646377563
Validation loss: 1.7254344212111605

Epoch: 6| Step: 10
Training loss: 0.7236893773078918
Validation loss: 1.7368108969862743

Epoch: 6| Step: 11
Training loss: 0.63346266746521
Validation loss: 1.7376076989276434

Epoch: 6| Step: 12
Training loss: 1.114886999130249
Validation loss: 1.7256517717915196

Epoch: 6| Step: 13
Training loss: 0.9267418384552002
Validation loss: 1.6817478492695799

Epoch: 210| Step: 0
Training loss: 0.8993314504623413
Validation loss: 1.7069817371265863

Epoch: 6| Step: 1
Training loss: 0.6155877113342285
Validation loss: 1.691712135909706

Epoch: 6| Step: 2
Training loss: 0.6028615236282349
Validation loss: 1.6865428955324235

Epoch: 6| Step: 3
Training loss: 0.5795037746429443
Validation loss: 1.6905637928234634

Epoch: 6| Step: 4
Training loss: 0.7596949338912964
Validation loss: 1.700145939345001

Epoch: 6| Step: 5
Training loss: 0.8192932605743408
Validation loss: 1.6926835929193804

Epoch: 6| Step: 6
Training loss: 0.5912216901779175
Validation loss: 1.7039869241817023

Epoch: 6| Step: 7
Training loss: 0.6027106642723083
Validation loss: 1.7073797974535214

Epoch: 6| Step: 8
Training loss: 1.1738297939300537
Validation loss: 1.7236849595141668

Epoch: 6| Step: 9
Training loss: 0.8090614080429077
Validation loss: 1.7247107528871106

Epoch: 6| Step: 10
Training loss: 1.059889316558838
Validation loss: 1.7140024938891012

Epoch: 6| Step: 11
Training loss: 0.4656483232975006
Validation loss: 1.6933355587784962

Epoch: 6| Step: 12
Training loss: 0.5414783358573914
Validation loss: 1.705162891777613

Epoch: 6| Step: 13
Training loss: 0.6327537894248962
Validation loss: 1.6969164827818513

Epoch: 211| Step: 0
Training loss: 0.7859926819801331
Validation loss: 1.7149616056872952

Epoch: 6| Step: 1
Training loss: 0.7569093108177185
Validation loss: 1.6979913852548087

Epoch: 6| Step: 2
Training loss: 0.7369722723960876
Validation loss: 1.6833525524344495

Epoch: 6| Step: 3
Training loss: 0.6419734954833984
Validation loss: 1.6798568220548733

Epoch: 6| Step: 4
Training loss: 0.5980172157287598
Validation loss: 1.68500381131326

Epoch: 6| Step: 5
Training loss: 0.25657087564468384
Validation loss: 1.661665375514697

Epoch: 6| Step: 6
Training loss: 0.5277435183525085
Validation loss: 1.6501702313782067

Epoch: 6| Step: 7
Training loss: 0.9318810701370239
Validation loss: 1.6524916143827542

Epoch: 6| Step: 8
Training loss: 0.779117226600647
Validation loss: 1.6603844306802238

Epoch: 6| Step: 9
Training loss: 1.1461443901062012
Validation loss: 1.6484511526682044

Epoch: 6| Step: 10
Training loss: 0.4196973145008087
Validation loss: 1.6238245541049587

Epoch: 6| Step: 11
Training loss: 1.406019926071167
Validation loss: 1.6378491950291458

Epoch: 6| Step: 12
Training loss: 0.6926463842391968
Validation loss: 1.623195678957047

Epoch: 6| Step: 13
Training loss: 1.2319486141204834
Validation loss: 1.6477622716657576

Epoch: 212| Step: 0
Training loss: 0.46438324451446533
Validation loss: 1.6318868052574895

Epoch: 6| Step: 1
Training loss: 0.6860619783401489
Validation loss: 1.6382367482749365

Epoch: 6| Step: 2
Training loss: 0.4610622525215149
Validation loss: 1.6728019791264688

Epoch: 6| Step: 3
Training loss: 0.6436566114425659
Validation loss: 1.6802784140392015

Epoch: 6| Step: 4
Training loss: 0.3366374373435974
Validation loss: 1.6869621097400624

Epoch: 6| Step: 5
Training loss: 0.670167863368988
Validation loss: 1.676133979392308

Epoch: 6| Step: 6
Training loss: 0.6095094680786133
Validation loss: 1.6889712682334326

Epoch: 6| Step: 7
Training loss: 0.8366016745567322
Validation loss: 1.7052001901852187

Epoch: 6| Step: 8
Training loss: 0.5925325751304626
Validation loss: 1.7050155580684703

Epoch: 6| Step: 9
Training loss: 1.1243691444396973
Validation loss: 1.7335661636885775

Epoch: 6| Step: 10
Training loss: 0.6923171281814575
Validation loss: 1.7240386304034983

Epoch: 6| Step: 11
Training loss: 1.0431864261627197
Validation loss: 1.7523607182246383

Epoch: 6| Step: 12
Training loss: 0.7240153551101685
Validation loss: 1.7430847947315504

Epoch: 6| Step: 13
Training loss: 1.4603164196014404
Validation loss: 1.722877428095828

Epoch: 213| Step: 0
Training loss: 0.7397007346153259
Validation loss: 1.7421797757507653

Epoch: 6| Step: 1
Training loss: 0.9514174461364746
Validation loss: 1.7221594702812932

Epoch: 6| Step: 2
Training loss: 0.7729220986366272
Validation loss: 1.7164432002652077

Epoch: 6| Step: 3
Training loss: 1.1152544021606445
Validation loss: 1.7158611256589171

Epoch: 6| Step: 4
Training loss: 0.5522190928459167
Validation loss: 1.7144044483861616

Epoch: 6| Step: 5
Training loss: 0.46350574493408203
Validation loss: 1.6967574550259499

Epoch: 6| Step: 6
Training loss: 0.5730634927749634
Validation loss: 1.6862420446129256

Epoch: 6| Step: 7
Training loss: 0.5947778224945068
Validation loss: 1.683622141038218

Epoch: 6| Step: 8
Training loss: 0.7565749883651733
Validation loss: 1.6716643841035905

Epoch: 6| Step: 9
Training loss: 0.6607106924057007
Validation loss: 1.6743104855219524

Epoch: 6| Step: 10
Training loss: 0.615504264831543
Validation loss: 1.6889254534116356

Epoch: 6| Step: 11
Training loss: 0.8938431143760681
Validation loss: 1.6876942496145926

Epoch: 6| Step: 12
Training loss: 0.7834885120391846
Validation loss: 1.682330410967591

Epoch: 6| Step: 13
Training loss: 0.4739578664302826
Validation loss: 1.7210311351283905

Epoch: 214| Step: 0
Training loss: 0.25989606976509094
Validation loss: 1.7074709079598869

Epoch: 6| Step: 1
Training loss: 0.4714564085006714
Validation loss: 1.6973023517157442

Epoch: 6| Step: 2
Training loss: 0.5625239014625549
Validation loss: 1.708077105142737

Epoch: 6| Step: 3
Training loss: 0.875386118888855
Validation loss: 1.716078422402823

Epoch: 6| Step: 4
Training loss: 1.0755503177642822
Validation loss: 1.7045809350987917

Epoch: 6| Step: 5
Training loss: 0.8264331817626953
Validation loss: 1.7035987646349016

Epoch: 6| Step: 6
Training loss: 0.8915809392929077
Validation loss: 1.7003460750784924

Epoch: 6| Step: 7
Training loss: 0.42955464124679565
Validation loss: 1.702635221583869

Epoch: 6| Step: 8
Training loss: 0.5435899496078491
Validation loss: 1.6952245273897726

Epoch: 6| Step: 9
Training loss: 0.8369890451431274
Validation loss: 1.686044080283052

Epoch: 6| Step: 10
Training loss: 0.7087975740432739
Validation loss: 1.7050816166785456

Epoch: 6| Step: 11
Training loss: 0.5373477935791016
Validation loss: 1.6846407190445931

Epoch: 6| Step: 12
Training loss: 0.9958509802818298
Validation loss: 1.680424912001497

Epoch: 6| Step: 13
Training loss: 0.96745365858078
Validation loss: 1.672141928826609

Epoch: 215| Step: 0
Training loss: 0.7466222643852234
Validation loss: 1.6701922109050136

Epoch: 6| Step: 1
Training loss: 0.6432785987854004
Validation loss: 1.654090432710545

Epoch: 6| Step: 2
Training loss: 0.5209877490997314
Validation loss: 1.6472249031066895

Epoch: 6| Step: 3
Training loss: 0.5540886521339417
Validation loss: 1.6750946685832033

Epoch: 6| Step: 4
Training loss: 0.7269147634506226
Validation loss: 1.682449245965609

Epoch: 6| Step: 5
Training loss: 0.2674802541732788
Validation loss: 1.6677804300861974

Epoch: 6| Step: 6
Training loss: 0.9718009233474731
Validation loss: 1.6658453576026424

Epoch: 6| Step: 7
Training loss: 1.337207555770874
Validation loss: 1.6563905451887397

Epoch: 6| Step: 8
Training loss: 0.732774019241333
Validation loss: 1.6496062791475685

Epoch: 6| Step: 9
Training loss: 0.7836387753486633
Validation loss: 1.6473400592803955

Epoch: 6| Step: 10
Training loss: 0.5706268548965454
Validation loss: 1.6411480903625488

Epoch: 6| Step: 11
Training loss: 0.6249070167541504
Validation loss: 1.6349685435654016

Epoch: 6| Step: 12
Training loss: 0.6144962906837463
Validation loss: 1.6306046619210193

Epoch: 6| Step: 13
Training loss: 0.3542977273464203
Validation loss: 1.6399775282029183

Epoch: 216| Step: 0
Training loss: 0.8901670575141907
Validation loss: 1.640991541647142

Epoch: 6| Step: 1
Training loss: 0.5426605939865112
Validation loss: 1.6897162506657262

Epoch: 6| Step: 2
Training loss: 0.38433992862701416
Validation loss: 1.680459709577663

Epoch: 6| Step: 3
Training loss: 1.1214690208435059
Validation loss: 1.697722146587987

Epoch: 6| Step: 4
Training loss: 0.6514221429824829
Validation loss: 1.6983207118126653

Epoch: 6| Step: 5
Training loss: 0.4546254873275757
Validation loss: 1.7108246639210691

Epoch: 6| Step: 6
Training loss: 0.5431127548217773
Validation loss: 1.6998898329273346

Epoch: 6| Step: 7
Training loss: 0.44575533270835876
Validation loss: 1.6778805666072394

Epoch: 6| Step: 8
Training loss: 0.7528756856918335
Validation loss: 1.691164961425207

Epoch: 6| Step: 9
Training loss: 0.5169470906257629
Validation loss: 1.6597453291698168

Epoch: 6| Step: 10
Training loss: 0.7646356821060181
Validation loss: 1.6426286582023866

Epoch: 6| Step: 11
Training loss: 0.681134045124054
Validation loss: 1.626044483594997

Epoch: 6| Step: 12
Training loss: 0.4338158369064331
Validation loss: 1.6396908285797283

Epoch: 6| Step: 13
Training loss: 1.010380744934082
Validation loss: 1.6247704849448255

Epoch: 217| Step: 0
Training loss: 0.4682832658290863
Validation loss: 1.6040329080755993

Epoch: 6| Step: 1
Training loss: 0.9187405705451965
Validation loss: 1.5950717759388748

Epoch: 6| Step: 2
Training loss: 0.5161885023117065
Validation loss: 1.6131519835482362

Epoch: 6| Step: 3
Training loss: 0.752021849155426
Validation loss: 1.6176986412335468

Epoch: 6| Step: 4
Training loss: 1.0160621404647827
Validation loss: 1.6385628536183348

Epoch: 6| Step: 5
Training loss: 0.634527862071991
Validation loss: 1.6297988583964687

Epoch: 6| Step: 6
Training loss: 0.8949989080429077
Validation loss: 1.637679414082599

Epoch: 6| Step: 7
Training loss: 0.529543399810791
Validation loss: 1.6312306029822237

Epoch: 6| Step: 8
Training loss: 0.43581610918045044
Validation loss: 1.6381298675332019

Epoch: 6| Step: 9
Training loss: 0.3822784423828125
Validation loss: 1.6537516681096887

Epoch: 6| Step: 10
Training loss: 0.5051894187927246
Validation loss: 1.6522815791509484

Epoch: 6| Step: 11
Training loss: 0.6006523966789246
Validation loss: 1.6659490049526255

Epoch: 6| Step: 12
Training loss: 0.6024618744850159
Validation loss: 1.695642117531069

Epoch: 6| Step: 13
Training loss: 0.6105603575706482
Validation loss: 1.704869811252881

Epoch: 218| Step: 0
Training loss: 0.6476371884346008
Validation loss: 1.6844568483291134

Epoch: 6| Step: 1
Training loss: 0.5008577704429626
Validation loss: 1.6665936721268522

Epoch: 6| Step: 2
Training loss: 0.46614474058151245
Validation loss: 1.6649971008300781

Epoch: 6| Step: 3
Training loss: 0.6996695399284363
Validation loss: 1.6558323688404535

Epoch: 6| Step: 4
Training loss: 0.5000399351119995
Validation loss: 1.6359207809612315

Epoch: 6| Step: 5
Training loss: 0.7758740186691284
Validation loss: 1.6111352982059601

Epoch: 6| Step: 6
Training loss: 0.8228859901428223
Validation loss: 1.5822906083958124

Epoch: 6| Step: 7
Training loss: 0.4558147192001343
Validation loss: 1.6027768235052786

Epoch: 6| Step: 8
Training loss: 0.9811631441116333
Validation loss: 1.6263956049437165

Epoch: 6| Step: 9
Training loss: 0.9893507361412048
Validation loss: 1.627822668321671

Epoch: 6| Step: 10
Training loss: 0.6044816374778748
Validation loss: 1.6283470405045377

Epoch: 6| Step: 11
Training loss: 0.7702038884162903
Validation loss: 1.6354228937497703

Epoch: 6| Step: 12
Training loss: 0.42819827795028687
Validation loss: 1.6074878900281844

Epoch: 6| Step: 13
Training loss: 0.6314297318458557
Validation loss: 1.6104520341401458

Epoch: 219| Step: 0
Training loss: 0.3626742959022522
Validation loss: 1.616899060946639

Epoch: 6| Step: 1
Training loss: 0.8438040018081665
Validation loss: 1.6393531701898063

Epoch: 6| Step: 2
Training loss: 0.6228275299072266
Validation loss: 1.6411286425846878

Epoch: 6| Step: 3
Training loss: 0.5437799692153931
Validation loss: 1.6434100084407355

Epoch: 6| Step: 4
Training loss: 0.5397578477859497
Validation loss: 1.632833473144039

Epoch: 6| Step: 5
Training loss: 0.7279335260391235
Validation loss: 1.6698928815062328

Epoch: 6| Step: 6
Training loss: 0.5754618644714355
Validation loss: 1.6715049500106482

Epoch: 6| Step: 7
Training loss: 0.7061538696289062
Validation loss: 1.6845536001266972

Epoch: 6| Step: 8
Training loss: 0.5078139305114746
Validation loss: 1.7068334330794632

Epoch: 6| Step: 9
Training loss: 0.6536415219306946
Validation loss: 1.6982533893277567

Epoch: 6| Step: 10
Training loss: 0.8675590753555298
Validation loss: 1.688826576355965

Epoch: 6| Step: 11
Training loss: 0.8429437279701233
Validation loss: 1.6810927442325059

Epoch: 6| Step: 12
Training loss: 0.6682350635528564
Validation loss: 1.6572445438754173

Epoch: 6| Step: 13
Training loss: 1.0463025569915771
Validation loss: 1.664932297122094

Epoch: 220| Step: 0
Training loss: 0.6936275959014893
Validation loss: 1.677202099113054

Epoch: 6| Step: 1
Training loss: 0.7136624455451965
Validation loss: 1.683708481891181

Epoch: 6| Step: 2
Training loss: 0.6610878705978394
Validation loss: 1.6675052642822266

Epoch: 6| Step: 3
Training loss: 0.5740320682525635
Validation loss: 1.6568594465973556

Epoch: 6| Step: 4
Training loss: 0.44268277287483215
Validation loss: 1.6338875960278254

Epoch: 6| Step: 5
Training loss: 0.5952908396720886
Validation loss: 1.6158008062711327

Epoch: 6| Step: 6
Training loss: 0.6704834699630737
Validation loss: 1.6145363212913595

Epoch: 6| Step: 7
Training loss: 0.5059459209442139
Validation loss: 1.6048508369794456

Epoch: 6| Step: 8
Training loss: 0.4703972041606903
Validation loss: 1.597307594873572

Epoch: 6| Step: 9
Training loss: 0.9464551210403442
Validation loss: 1.6080658410185127

Epoch: 6| Step: 10
Training loss: 0.897529661655426
Validation loss: 1.6254629204350133

Epoch: 6| Step: 11
Training loss: 0.47298452258110046
Validation loss: 1.6348061318038611

Epoch: 6| Step: 12
Training loss: 0.5215104818344116
Validation loss: 1.6800529315907469

Epoch: 6| Step: 13
Training loss: 0.513629138469696
Validation loss: 1.683817971137262

Epoch: 221| Step: 0
Training loss: 0.6001964807510376
Validation loss: 1.6813313089391237

Epoch: 6| Step: 1
Training loss: 0.7941537499427795
Validation loss: 1.6523752186888008

Epoch: 6| Step: 2
Training loss: 0.7846479415893555
Validation loss: 1.6541809651159471

Epoch: 6| Step: 3
Training loss: 0.673198938369751
Validation loss: 1.6613129390183317

Epoch: 6| Step: 4
Training loss: 0.44767841696739197
Validation loss: 1.6541487375895183

Epoch: 6| Step: 5
Training loss: 0.5179345011711121
Validation loss: 1.6300826803330453

Epoch: 6| Step: 6
Training loss: 0.3908585011959076
Validation loss: 1.629625097397835

Epoch: 6| Step: 7
Training loss: 0.3932359218597412
Validation loss: 1.6340883265259445

Epoch: 6| Step: 8
Training loss: 0.500382661819458
Validation loss: 1.6399592468815465

Epoch: 6| Step: 9
Training loss: 0.6029564738273621
Validation loss: 1.644339693489895

Epoch: 6| Step: 10
Training loss: 0.2841111421585083
Validation loss: 1.64901497415317

Epoch: 6| Step: 11
Training loss: 0.819562554359436
Validation loss: 1.6543504371437976

Epoch: 6| Step: 12
Training loss: 0.8863860368728638
Validation loss: 1.650532043108376

Epoch: 6| Step: 13
Training loss: 0.8221538066864014
Validation loss: 1.655921571998186

Epoch: 222| Step: 0
Training loss: 0.2780393660068512
Validation loss: 1.657381239757743

Epoch: 6| Step: 1
Training loss: 0.5923333168029785
Validation loss: 1.6390167423473891

Epoch: 6| Step: 2
Training loss: 0.5708780288696289
Validation loss: 1.6353124251929663

Epoch: 6| Step: 3
Training loss: 0.341779500246048
Validation loss: 1.6418867636752386

Epoch: 6| Step: 4
Training loss: 0.7091357707977295
Validation loss: 1.6448541943744948

Epoch: 6| Step: 5
Training loss: 0.616844892501831
Validation loss: 1.6429033830601683

Epoch: 6| Step: 6
Training loss: 0.3947369456291199
Validation loss: 1.6075901574985956

Epoch: 6| Step: 7
Training loss: 0.3424447476863861
Validation loss: 1.5928142147679483

Epoch: 6| Step: 8
Training loss: 0.7575688362121582
Validation loss: 1.5985055392788303

Epoch: 6| Step: 9
Training loss: 0.6732667684555054
Validation loss: 1.6150645953352734

Epoch: 6| Step: 10
Training loss: 0.7163429856300354
Validation loss: 1.6128629612666305

Epoch: 6| Step: 11
Training loss: 0.5670145153999329
Validation loss: 1.6191735806003693

Epoch: 6| Step: 12
Training loss: 0.6712245345115662
Validation loss: 1.6221043364976042

Epoch: 6| Step: 13
Training loss: 0.6755020618438721
Validation loss: 1.5938910156167962

Epoch: 223| Step: 0
Training loss: 0.6140909194946289
Validation loss: 1.608809272448222

Epoch: 6| Step: 1
Training loss: 0.8705227971076965
Validation loss: 1.6191340966891217

Epoch: 6| Step: 2
Training loss: 0.6924058794975281
Validation loss: 1.6129756409634826

Epoch: 6| Step: 3
Training loss: 0.484064519405365
Validation loss: 1.6336813863887583

Epoch: 6| Step: 4
Training loss: 0.6471298933029175
Validation loss: 1.6173191403829923

Epoch: 6| Step: 5
Training loss: 0.9136207103729248
Validation loss: 1.62826907250189

Epoch: 6| Step: 6
Training loss: 0.23716136813163757
Validation loss: 1.6201133510117889

Epoch: 6| Step: 7
Training loss: 0.4328257739543915
Validation loss: 1.6115610702063448

Epoch: 6| Step: 8
Training loss: 0.528113603591919
Validation loss: 1.6053334538654616

Epoch: 6| Step: 9
Training loss: 0.37612205743789673
Validation loss: 1.6264409647193006

Epoch: 6| Step: 10
Training loss: 0.2426941990852356
Validation loss: 1.6395855840816294

Epoch: 6| Step: 11
Training loss: 0.4300472140312195
Validation loss: 1.6388241911447177

Epoch: 6| Step: 12
Training loss: 0.4282442331314087
Validation loss: 1.649736496710008

Epoch: 6| Step: 13
Training loss: 0.6586059927940369
Validation loss: 1.6555543958499868

Epoch: 224| Step: 0
Training loss: 0.47680115699768066
Validation loss: 1.674060288295951

Epoch: 6| Step: 1
Training loss: 0.6879390478134155
Validation loss: 1.6523065188879609

Epoch: 6| Step: 2
Training loss: 0.48844313621520996
Validation loss: 1.6499812231268933

Epoch: 6| Step: 3
Training loss: 0.284505695104599
Validation loss: 1.6106427792579896

Epoch: 6| Step: 4
Training loss: 0.42117464542388916
Validation loss: 1.6273232672804145

Epoch: 6| Step: 5
Training loss: 0.7080342173576355
Validation loss: 1.611601366791674

Epoch: 6| Step: 6
Training loss: 0.7513692378997803
Validation loss: 1.5725936966557656

Epoch: 6| Step: 7
Training loss: 0.3858241140842438
Validation loss: 1.5970376063418645

Epoch: 6| Step: 8
Training loss: 0.3471272587776184
Validation loss: 1.5824185981545398

Epoch: 6| Step: 9
Training loss: 0.6664864420890808
Validation loss: 1.5786357560465414

Epoch: 6| Step: 10
Training loss: 0.7673320770263672
Validation loss: 1.608615893189625

Epoch: 6| Step: 11
Training loss: 0.9332310557365417
Validation loss: 1.646098752175608

Epoch: 6| Step: 12
Training loss: 0.4922545850276947
Validation loss: 1.6488735393811298

Epoch: 6| Step: 13
Training loss: 0.15361849963665009
Validation loss: 1.6839097840811617

Epoch: 225| Step: 0
Training loss: 0.3652001619338989
Validation loss: 1.7058400043877222

Epoch: 6| Step: 1
Training loss: 0.2832930386066437
Validation loss: 1.694861642775997

Epoch: 6| Step: 2
Training loss: 0.8053739070892334
Validation loss: 1.6809558432589295

Epoch: 6| Step: 3
Training loss: 0.596082866191864
Validation loss: 1.6858007728412587

Epoch: 6| Step: 4
Training loss: 0.4463965892791748
Validation loss: 1.6854202439708095

Epoch: 6| Step: 5
Training loss: 0.713886559009552
Validation loss: 1.6924476905535626

Epoch: 6| Step: 6
Training loss: 0.5534660220146179
Validation loss: 1.6655869381402129

Epoch: 6| Step: 7
Training loss: 0.35983362793922424
Validation loss: 1.6400617950706071

Epoch: 6| Step: 8
Training loss: 0.23966097831726074
Validation loss: 1.6130405087624826

Epoch: 6| Step: 9
Training loss: 0.34010544419288635
Validation loss: 1.5869561395337504

Epoch: 6| Step: 10
Training loss: 0.9166043996810913
Validation loss: 1.586853019652828

Epoch: 6| Step: 11
Training loss: 0.6200987100601196
Validation loss: 1.5989266941624303

Epoch: 6| Step: 12
Training loss: 0.8371357917785645
Validation loss: 1.583427800927111

Epoch: 6| Step: 13
Training loss: 0.47992855310440063
Validation loss: 1.600252087398242

Epoch: 226| Step: 0
Training loss: 0.2572154700756073
Validation loss: 1.5860611443878503

Epoch: 6| Step: 1
Training loss: 0.5964462757110596
Validation loss: 1.5952957522484563

Epoch: 6| Step: 2
Training loss: 0.40131598711013794
Validation loss: 1.5971597984272947

Epoch: 6| Step: 3
Training loss: 0.6701245307922363
Validation loss: 1.5847549720477032

Epoch: 6| Step: 4
Training loss: 0.39520972967147827
Validation loss: 1.600795925304454

Epoch: 6| Step: 5
Training loss: 0.5641173124313354
Validation loss: 1.6150720145112725

Epoch: 6| Step: 6
Training loss: 0.5975196361541748
Validation loss: 1.601986615888534

Epoch: 6| Step: 7
Training loss: 0.6845347881317139
Validation loss: 1.6326053706548547

Epoch: 6| Step: 8
Training loss: 0.6814038753509521
Validation loss: 1.6428366899490356

Epoch: 6| Step: 9
Training loss: 0.5833005309104919
Validation loss: 1.6390080977511663

Epoch: 6| Step: 10
Training loss: 0.5788024663925171
Validation loss: 1.63299322512842

Epoch: 6| Step: 11
Training loss: 0.2932107150554657
Validation loss: 1.6303253801920081

Epoch: 6| Step: 12
Training loss: 0.445095419883728
Validation loss: 1.633869432633923

Epoch: 6| Step: 13
Training loss: 0.7424089908599854
Validation loss: 1.6221897960990987

Epoch: 227| Step: 0
Training loss: 0.35722607374191284
Validation loss: 1.619696932454263

Epoch: 6| Step: 1
Training loss: 0.4527231752872467
Validation loss: 1.6043963034947712

Epoch: 6| Step: 2
Training loss: 0.695252537727356
Validation loss: 1.6012086740104101

Epoch: 6| Step: 3
Training loss: 0.6123656630516052
Validation loss: 1.5878692544916624

Epoch: 6| Step: 4
Training loss: 0.27969545125961304
Validation loss: 1.5964672552642

Epoch: 6| Step: 5
Training loss: 0.5949483513832092
Validation loss: 1.5812789714464577

Epoch: 6| Step: 6
Training loss: 0.8454541563987732
Validation loss: 1.613217120529503

Epoch: 6| Step: 7
Training loss: 0.5561147332191467
Validation loss: 1.6114395267219954

Epoch: 6| Step: 8
Training loss: 0.4740734398365021
Validation loss: 1.6201131100295691

Epoch: 6| Step: 9
Training loss: 0.4717015326023102
Validation loss: 1.646864547524401

Epoch: 6| Step: 10
Training loss: 0.369962215423584
Validation loss: 1.6622473129662134

Epoch: 6| Step: 11
Training loss: 0.7424508333206177
Validation loss: 1.665953766915106

Epoch: 6| Step: 12
Training loss: 0.541934609413147
Validation loss: 1.659049496855787

Epoch: 6| Step: 13
Training loss: 0.4010494351387024
Validation loss: 1.6164393399351387

Epoch: 228| Step: 0
Training loss: 0.4221697747707367
Validation loss: 1.6032070716222127

Epoch: 6| Step: 1
Training loss: 0.4656330347061157
Validation loss: 1.5731089038233603

Epoch: 6| Step: 2
Training loss: 0.38019222021102905
Validation loss: 1.5758395682099045

Epoch: 6| Step: 3
Training loss: 0.6804623007774353
Validation loss: 1.6010054798536404

Epoch: 6| Step: 4
Training loss: 0.6688740253448486
Validation loss: 1.5979653840423913

Epoch: 6| Step: 5
Training loss: 0.5373719930648804
Validation loss: 1.595290631376287

Epoch: 6| Step: 6
Training loss: 0.5448621511459351
Validation loss: 1.605491190828303

Epoch: 6| Step: 7
Training loss: 0.4067060947418213
Validation loss: 1.5808034532813615

Epoch: 6| Step: 8
Training loss: 0.4547621011734009
Validation loss: 1.6079474194075472

Epoch: 6| Step: 9
Training loss: 0.48243477940559387
Validation loss: 1.6044011603119552

Epoch: 6| Step: 10
Training loss: 0.4964835047721863
Validation loss: 1.6047941215576664

Epoch: 6| Step: 11
Training loss: 0.6153618097305298
Validation loss: 1.6067064885170228

Epoch: 6| Step: 12
Training loss: 0.6311848163604736
Validation loss: 1.5920235623595536

Epoch: 6| Step: 13
Training loss: 0.8182452321052551
Validation loss: 1.6175454944692633

Epoch: 229| Step: 0
Training loss: 0.4042227864265442
Validation loss: 1.6062796167148057

Epoch: 6| Step: 1
Training loss: 0.37297365069389343
Validation loss: 1.6347358701049641

Epoch: 6| Step: 2
Training loss: 0.4630635380744934
Validation loss: 1.6348778868234286

Epoch: 6| Step: 3
Training loss: 0.45642149448394775
Validation loss: 1.6397005704141432

Epoch: 6| Step: 4
Training loss: 0.4934540092945099
Validation loss: 1.6463588565908454

Epoch: 6| Step: 5
Training loss: 0.5787634253501892
Validation loss: 1.6334924338966288

Epoch: 6| Step: 6
Training loss: 0.781083345413208
Validation loss: 1.6745079153327531

Epoch: 6| Step: 7
Training loss: 0.36982083320617676
Validation loss: 1.6683015041453864

Epoch: 6| Step: 8
Training loss: 0.4612581133842468
Validation loss: 1.6806843306428643

Epoch: 6| Step: 9
Training loss: 0.40003687143325806
Validation loss: 1.6656975194972048

Epoch: 6| Step: 10
Training loss: 0.9054270386695862
Validation loss: 1.6486490157342726

Epoch: 6| Step: 11
Training loss: 0.8445058465003967
Validation loss: 1.645358811142624

Epoch: 6| Step: 12
Training loss: 0.42391252517700195
Validation loss: 1.6318241396257955

Epoch: 6| Step: 13
Training loss: 0.7301276922225952
Validation loss: 1.6126668863399054

Epoch: 230| Step: 0
Training loss: 0.5966874361038208
Validation loss: 1.6030181325891966

Epoch: 6| Step: 1
Training loss: 0.3836713433265686
Validation loss: 1.623159932833846

Epoch: 6| Step: 2
Training loss: 0.23928549885749817
Validation loss: 1.6066968543555147

Epoch: 6| Step: 3
Training loss: 0.4958789646625519
Validation loss: 1.5621330327885126

Epoch: 6| Step: 4
Training loss: 0.4849829375743866
Validation loss: 1.5829379212471746

Epoch: 6| Step: 5
Training loss: 0.3624705672264099
Validation loss: 1.57464381828103

Epoch: 6| Step: 6
Training loss: 0.23787489533424377
Validation loss: 1.5740836794658373

Epoch: 6| Step: 7
Training loss: 0.9613478183746338
Validation loss: 1.5869615385609288

Epoch: 6| Step: 8
Training loss: 0.598203718662262
Validation loss: 1.5799523463813208

Epoch: 6| Step: 9
Training loss: 0.4839926064014435
Validation loss: 1.5981920226927726

Epoch: 6| Step: 10
Training loss: 0.5655744671821594
Validation loss: 1.6034730839472946

Epoch: 6| Step: 11
Training loss: 0.6227138042449951
Validation loss: 1.592261871983928

Epoch: 6| Step: 12
Training loss: 0.5637115240097046
Validation loss: 1.5888440096250145

Epoch: 6| Step: 13
Training loss: 0.46791309118270874
Validation loss: 1.6070954056196316

Epoch: 231| Step: 0
Training loss: 0.2469562590122223
Validation loss: 1.5896742818176106

Epoch: 6| Step: 1
Training loss: 0.34988272190093994
Validation loss: 1.6097390600430068

Epoch: 6| Step: 2
Training loss: 0.23267501592636108
Validation loss: 1.5815047679408905

Epoch: 6| Step: 3
Training loss: 0.3560526967048645
Validation loss: 1.6206653720589095

Epoch: 6| Step: 4
Training loss: 0.45374739170074463
Validation loss: 1.6258389321706628

Epoch: 6| Step: 5
Training loss: 0.6713148355484009
Validation loss: 1.6074444504194363

Epoch: 6| Step: 6
Training loss: 0.318484365940094
Validation loss: 1.6341928923001854

Epoch: 6| Step: 7
Training loss: 0.5944797992706299
Validation loss: 1.6221296018169773

Epoch: 6| Step: 8
Training loss: 0.690706729888916
Validation loss: 1.6031500504862877

Epoch: 6| Step: 9
Training loss: 0.5830521583557129
Validation loss: 1.6132192650148947

Epoch: 6| Step: 10
Training loss: 0.5644948482513428
Validation loss: 1.5947356941879436

Epoch: 6| Step: 11
Training loss: 0.5795536041259766
Validation loss: 1.5879224090165989

Epoch: 6| Step: 12
Training loss: 0.5246726274490356
Validation loss: 1.5738874917389245

Epoch: 6| Step: 13
Training loss: 0.539023220539093
Validation loss: 1.5697534263774913

Epoch: 232| Step: 0
Training loss: 0.4018644690513611
Validation loss: 1.5349622977677213

Epoch: 6| Step: 1
Training loss: 0.38915959000587463
Validation loss: 1.5663692156473796

Epoch: 6| Step: 2
Training loss: 0.4586232900619507
Validation loss: 1.5392854969988587

Epoch: 6| Step: 3
Training loss: 0.45738542079925537
Validation loss: 1.535672999197437

Epoch: 6| Step: 4
Training loss: 0.132798969745636
Validation loss: 1.5520802749100553

Epoch: 6| Step: 5
Training loss: 0.421308696269989
Validation loss: 1.5364053351904756

Epoch: 6| Step: 6
Training loss: 0.8172495365142822
Validation loss: 1.5677084345971384

Epoch: 6| Step: 7
Training loss: 0.6548348665237427
Validation loss: 1.5550508447872695

Epoch: 6| Step: 8
Training loss: 0.5927888751029968
Validation loss: 1.5929672423229422

Epoch: 6| Step: 9
Training loss: 0.4280250072479248
Validation loss: 1.5877318055399003

Epoch: 6| Step: 10
Training loss: 0.3628191351890564
Validation loss: 1.607644925835312

Epoch: 6| Step: 11
Training loss: 0.4623904824256897
Validation loss: 1.6096180613322923

Epoch: 6| Step: 12
Training loss: 0.6083090305328369
Validation loss: 1.6257840869247273

Epoch: 6| Step: 13
Training loss: 0.7478398084640503
Validation loss: 1.5946364075906816

Epoch: 233| Step: 0
Training loss: 0.5049945116043091
Validation loss: 1.5918202105388846

Epoch: 6| Step: 1
Training loss: 0.5067816972732544
Validation loss: 1.6024921850491596

Epoch: 6| Step: 2
Training loss: 0.2713298201560974
Validation loss: 1.5419839876954273

Epoch: 6| Step: 3
Training loss: 0.4036599099636078
Validation loss: 1.546985162201748

Epoch: 6| Step: 4
Training loss: 0.5240725874900818
Validation loss: 1.5604749533437914

Epoch: 6| Step: 5
Training loss: 0.29416996240615845
Validation loss: 1.562739876008803

Epoch: 6| Step: 6
Training loss: 0.39937663078308105
Validation loss: 1.5675774992153209

Epoch: 6| Step: 7
Training loss: 0.6485553979873657
Validation loss: 1.5931372014425134

Epoch: 6| Step: 8
Training loss: 0.5133058428764343
Validation loss: 1.6280026217942596

Epoch: 6| Step: 9
Training loss: 0.6178737878799438
Validation loss: 1.6165925174631097

Epoch: 6| Step: 10
Training loss: 0.5525754690170288
Validation loss: 1.622587606471072

Epoch: 6| Step: 11
Training loss: 0.4761221706867218
Validation loss: 1.6078492608121646

Epoch: 6| Step: 12
Training loss: 0.6998364925384521
Validation loss: 1.6378293127141974

Epoch: 6| Step: 13
Training loss: 0.8331024646759033
Validation loss: 1.6128700369147844

Epoch: 234| Step: 0
Training loss: 0.5676565170288086
Validation loss: 1.6100757493767688

Epoch: 6| Step: 1
Training loss: 0.2343655824661255
Validation loss: 1.6078888075326079

Epoch: 6| Step: 2
Training loss: 0.697198748588562
Validation loss: 1.6214592732408994

Epoch: 6| Step: 3
Training loss: 0.3326541781425476
Validation loss: 1.6087837821693831

Epoch: 6| Step: 4
Training loss: 0.33389365673065186
Validation loss: 1.5856391191482544

Epoch: 6| Step: 5
Training loss: 0.6054157018661499
Validation loss: 1.6056078095589914

Epoch: 6| Step: 6
Training loss: 0.38261353969573975
Validation loss: 1.5868268025818693

Epoch: 6| Step: 7
Training loss: 0.39262107014656067
Validation loss: 1.6030237879804385

Epoch: 6| Step: 8
Training loss: 0.43226736783981323
Validation loss: 1.5842829212065666

Epoch: 6| Step: 9
Training loss: 0.4847148656845093
Validation loss: 1.626045879497323

Epoch: 6| Step: 10
Training loss: 0.49219417572021484
Validation loss: 1.6202390655394523

Epoch: 6| Step: 11
Training loss: 0.5115952491760254
Validation loss: 1.597698667997955

Epoch: 6| Step: 12
Training loss: 0.4173649251461029
Validation loss: 1.5960591070113643

Epoch: 6| Step: 13
Training loss: 0.4502300024032593
Validation loss: 1.59334276312141

Epoch: 235| Step: 0
Training loss: 0.39251944422721863
Validation loss: 1.5846513561023179

Epoch: 6| Step: 1
Training loss: 0.3594263792037964
Validation loss: 1.5555148073422012

Epoch: 6| Step: 2
Training loss: 0.6791906356811523
Validation loss: 1.557173490524292

Epoch: 6| Step: 3
Training loss: 0.3466595709323883
Validation loss: 1.5392242426513343

Epoch: 6| Step: 4
Training loss: 0.3552713990211487
Validation loss: 1.5221825709906958

Epoch: 6| Step: 5
Training loss: 0.856731653213501
Validation loss: 1.5384890007716354

Epoch: 6| Step: 6
Training loss: 0.35935938358306885
Validation loss: 1.530813979846175

Epoch: 6| Step: 7
Training loss: 0.4583739638328552
Validation loss: 1.5410000316558345

Epoch: 6| Step: 8
Training loss: 0.41374337673187256
Validation loss: 1.5473082629583215

Epoch: 6| Step: 9
Training loss: 0.571454644203186
Validation loss: 1.5714965635730374

Epoch: 6| Step: 10
Training loss: 0.3616116940975189
Validation loss: 1.5515113697257092

Epoch: 6| Step: 11
Training loss: 0.36063051223754883
Validation loss: 1.5729353953433294

Epoch: 6| Step: 12
Training loss: 0.5715261101722717
Validation loss: 1.5704133254225536

Epoch: 6| Step: 13
Training loss: 0.4208223521709442
Validation loss: 1.6170165718242686

Epoch: 236| Step: 0
Training loss: 0.4467177391052246
Validation loss: 1.609975645619054

Epoch: 6| Step: 1
Training loss: 0.5723047256469727
Validation loss: 1.610162450421241

Epoch: 6| Step: 2
Training loss: 0.3819202780723572
Validation loss: 1.602690714661793

Epoch: 6| Step: 3
Training loss: 0.5020283460617065
Validation loss: 1.6104337823006414

Epoch: 6| Step: 4
Training loss: 0.48764872550964355
Validation loss: 1.6029979810919812

Epoch: 6| Step: 5
Training loss: 0.7204444408416748
Validation loss: 1.6222453848008187

Epoch: 6| Step: 6
Training loss: 0.15715233981609344
Validation loss: 1.6189485147435179

Epoch: 6| Step: 7
Training loss: 0.5067239999771118
Validation loss: 1.5997370481491089

Epoch: 6| Step: 8
Training loss: 0.28646016120910645
Validation loss: 1.5920455084052136

Epoch: 6| Step: 9
Training loss: 0.22799256443977356
Validation loss: 1.5884743300817346

Epoch: 6| Step: 10
Training loss: 0.6142604351043701
Validation loss: 1.595494633079857

Epoch: 6| Step: 11
Training loss: 0.367206335067749
Validation loss: 1.6101071514109129

Epoch: 6| Step: 12
Training loss: 0.4812542796134949
Validation loss: 1.6097275749329598

Epoch: 6| Step: 13
Training loss: 0.5408020615577698
Validation loss: 1.6136757481482722

Epoch: 237| Step: 0
Training loss: 0.38350021839141846
Validation loss: 1.576807342549806

Epoch: 6| Step: 1
Training loss: 0.3903768062591553
Validation loss: 1.5656861130909254

Epoch: 6| Step: 2
Training loss: 0.4146348237991333
Validation loss: 1.5858394817639423

Epoch: 6| Step: 3
Training loss: 0.4042524993419647
Validation loss: 1.5870106566336848

Epoch: 6| Step: 4
Training loss: 0.4170554578304291
Validation loss: 1.5723933199400544

Epoch: 6| Step: 5
Training loss: 0.32654809951782227
Validation loss: 1.6062818445185179

Epoch: 6| Step: 6
Training loss: 0.4543343484401703
Validation loss: 1.6115009143788328

Epoch: 6| Step: 7
Training loss: 0.4051644802093506
Validation loss: 1.6089381107719996

Epoch: 6| Step: 8
Training loss: 0.7528191804885864
Validation loss: 1.6231649178330616

Epoch: 6| Step: 9
Training loss: 0.4427124559879303
Validation loss: 1.6350300132587392

Epoch: 6| Step: 10
Training loss: 0.6199653744697571
Validation loss: 1.641819728318081

Epoch: 6| Step: 11
Training loss: 0.3921639919281006
Validation loss: 1.6236861175106418

Epoch: 6| Step: 12
Training loss: 0.31327491998672485
Validation loss: 1.6228530881225423

Epoch: 6| Step: 13
Training loss: 0.3229166865348816
Validation loss: 1.6196969427088255

Epoch: 238| Step: 0
Training loss: 0.43816623091697693
Validation loss: 1.6147496136285926

Epoch: 6| Step: 1
Training loss: 0.44583308696746826
Validation loss: 1.6058976932238507

Epoch: 6| Step: 2
Training loss: 0.4233773648738861
Validation loss: 1.5832462387700235

Epoch: 6| Step: 3
Training loss: 0.31017443537712097
Validation loss: 1.5920616875412643

Epoch: 6| Step: 4
Training loss: 0.5437823534011841
Validation loss: 1.5839435349228561

Epoch: 6| Step: 5
Training loss: 0.467050164937973
Validation loss: 1.5719017117254195

Epoch: 6| Step: 6
Training loss: 0.7527492642402649
Validation loss: 1.5754215358405985

Epoch: 6| Step: 7
Training loss: 0.4625902771949768
Validation loss: 1.575855024399296

Epoch: 6| Step: 8
Training loss: 0.4655953645706177
Validation loss: 1.5756399426408993

Epoch: 6| Step: 9
Training loss: 0.3250311017036438
Validation loss: 1.559207627850194

Epoch: 6| Step: 10
Training loss: 0.43010565638542175
Validation loss: 1.5646457249118435

Epoch: 6| Step: 11
Training loss: 0.34012168645858765
Validation loss: 1.5717761567843858

Epoch: 6| Step: 12
Training loss: 0.2124268114566803
Validation loss: 1.5642475223028531

Epoch: 6| Step: 13
Training loss: 0.3347110152244568
Validation loss: 1.5949720881318534

Epoch: 239| Step: 0
Training loss: 0.419408917427063
Validation loss: 1.5577470320527271

Epoch: 6| Step: 1
Training loss: 0.4259968400001526
Validation loss: 1.580520461964351

Epoch: 6| Step: 2
Training loss: 0.48626774549484253
Validation loss: 1.5584468892825547

Epoch: 6| Step: 3
Training loss: 0.4005415439605713
Validation loss: 1.5764399677194574

Epoch: 6| Step: 4
Training loss: 0.37831205129623413
Validation loss: 1.5972318264745897

Epoch: 6| Step: 5
Training loss: 0.36999446153640747
Validation loss: 1.5629143458540722

Epoch: 6| Step: 6
Training loss: 0.3951733112335205
Validation loss: 1.5591930843168689

Epoch: 6| Step: 7
Training loss: 0.34629496932029724
Validation loss: 1.560700116618987

Epoch: 6| Step: 8
Training loss: 0.37755388021469116
Validation loss: 1.584221432285924

Epoch: 6| Step: 9
Training loss: 0.4203173518180847
Validation loss: 1.573308757556382

Epoch: 6| Step: 10
Training loss: 0.3009123206138611
Validation loss: 1.5837208083880845

Epoch: 6| Step: 11
Training loss: 0.6600659489631653
Validation loss: 1.5679032392399286

Epoch: 6| Step: 12
Training loss: 0.32379651069641113
Validation loss: 1.6023436374561761

Epoch: 6| Step: 13
Training loss: 0.2933560311794281
Validation loss: 1.5780553663930585

Epoch: 240| Step: 0
Training loss: 0.44686785340309143
Validation loss: 1.627901634862346

Epoch: 6| Step: 1
Training loss: 0.46284008026123047
Validation loss: 1.6163131178066295

Epoch: 6| Step: 2
Training loss: 0.365986168384552
Validation loss: 1.5965268470907723

Epoch: 6| Step: 3
Training loss: 0.3510875701904297
Validation loss: 1.5674821151200162

Epoch: 6| Step: 4
Training loss: 0.5751962661743164
Validation loss: 1.522405074488732

Epoch: 6| Step: 5
Training loss: 0.3877888023853302
Validation loss: 1.5361618303483533

Epoch: 6| Step: 6
Training loss: 0.48375403881073
Validation loss: 1.5167137435687486

Epoch: 6| Step: 7
Training loss: 0.27424463629722595
Validation loss: 1.5295933074848627

Epoch: 6| Step: 8
Training loss: 0.5684220790863037
Validation loss: 1.518104519895328

Epoch: 6| Step: 9
Training loss: 0.3280268907546997
Validation loss: 1.5028710217886074

Epoch: 6| Step: 10
Training loss: 0.19907140731811523
Validation loss: 1.524393258556243

Epoch: 6| Step: 11
Training loss: 0.6329466700553894
Validation loss: 1.5056670532431653

Epoch: 6| Step: 12
Training loss: 0.2710782587528229
Validation loss: 1.5178762507695023

Epoch: 6| Step: 13
Training loss: 0.6018335819244385
Validation loss: 1.5139755279787126

Epoch: 241| Step: 0
Training loss: 0.5719479322433472
Validation loss: 1.5110739264436948

Epoch: 6| Step: 1
Training loss: 0.5242858529090881
Validation loss: 1.5414259138927664

Epoch: 6| Step: 2
Training loss: 0.7097240686416626
Validation loss: 1.5509498747446204

Epoch: 6| Step: 3
Training loss: 0.38200902938842773
Validation loss: 1.5583313626627768

Epoch: 6| Step: 4
Training loss: 0.30345165729522705
Validation loss: 1.589811526319032

Epoch: 6| Step: 5
Training loss: 0.3292016386985779
Validation loss: 1.6055883899811776

Epoch: 6| Step: 6
Training loss: 0.4881249666213989
Validation loss: 1.574207728908908

Epoch: 6| Step: 7
Training loss: 0.3071146309375763
Validation loss: 1.557962643202915

Epoch: 6| Step: 8
Training loss: 0.4134669899940491
Validation loss: 1.5406330811080111

Epoch: 6| Step: 9
Training loss: 0.3759661912918091
Validation loss: 1.53880355435033

Epoch: 6| Step: 10
Training loss: 0.3400630056858063
Validation loss: 1.524224119801675

Epoch: 6| Step: 11
Training loss: 0.5126321315765381
Validation loss: 1.5268428799926594

Epoch: 6| Step: 12
Training loss: 0.22367754578590393
Validation loss: 1.5334311108435354

Epoch: 6| Step: 13
Training loss: 0.25922322273254395
Validation loss: 1.528385187989922

Epoch: 242| Step: 0
Training loss: 0.7300734519958496
Validation loss: 1.5413165220650293

Epoch: 6| Step: 1
Training loss: 0.31675463914871216
Validation loss: 1.5461615747021091

Epoch: 6| Step: 2
Training loss: 0.41222333908081055
Validation loss: 1.6007296000757525

Epoch: 6| Step: 3
Training loss: 0.2776145040988922
Validation loss: 1.622852171621015

Epoch: 6| Step: 4
Training loss: 0.3938210606575012
Validation loss: 1.6349476101577922

Epoch: 6| Step: 5
Training loss: 0.6581337451934814
Validation loss: 1.65839333047149

Epoch: 6| Step: 6
Training loss: 0.3480987846851349
Validation loss: 1.66556921697432

Epoch: 6| Step: 7
Training loss: 0.5938429236412048
Validation loss: 1.6471942740101968

Epoch: 6| Step: 8
Training loss: 0.4420962333679199
Validation loss: 1.6275250463075535

Epoch: 6| Step: 9
Training loss: 0.3318461775779724
Validation loss: 1.609348322755547

Epoch: 6| Step: 10
Training loss: 0.39268597960472107
Validation loss: 1.5885466350022184

Epoch: 6| Step: 11
Training loss: 0.3477296829223633
Validation loss: 1.5554947840270175

Epoch: 6| Step: 12
Training loss: 0.24167832732200623
Validation loss: 1.547228318388744

Epoch: 6| Step: 13
Training loss: 0.29931122064590454
Validation loss: 1.5469431582317557

Epoch: 243| Step: 0
Training loss: 0.2980613112449646
Validation loss: 1.5347531700647006

Epoch: 6| Step: 1
Training loss: 0.4225772023200989
Validation loss: 1.508925013644721

Epoch: 6| Step: 2
Training loss: 0.277365118265152
Validation loss: 1.5508241422714726

Epoch: 6| Step: 3
Training loss: 0.5470462441444397
Validation loss: 1.5287494326150546

Epoch: 6| Step: 4
Training loss: 0.30282360315322876
Validation loss: 1.5533748877945768

Epoch: 6| Step: 5
Training loss: 0.47838133573532104
Validation loss: 1.5614749385464577

Epoch: 6| Step: 6
Training loss: 0.24315086007118225
Validation loss: 1.548092206319173

Epoch: 6| Step: 7
Training loss: 0.3080637454986572
Validation loss: 1.5615812591327134

Epoch: 6| Step: 8
Training loss: 0.3288862109184265
Validation loss: 1.5870246118114841

Epoch: 6| Step: 9
Training loss: 0.4815475642681122
Validation loss: 1.5768535790904876

Epoch: 6| Step: 10
Training loss: 0.5945797562599182
Validation loss: 1.5789243841683993

Epoch: 6| Step: 11
Training loss: 0.3560165762901306
Validation loss: 1.5846078459934523

Epoch: 6| Step: 12
Training loss: 0.3460330367088318
Validation loss: 1.5597137699845016

Epoch: 6| Step: 13
Training loss: 0.33550992608070374
Validation loss: 1.557791445844917

Epoch: 244| Step: 0
Training loss: 0.5031551122665405
Validation loss: 1.553521881821335

Epoch: 6| Step: 1
Training loss: 0.7578257918357849
Validation loss: 1.5330008563174997

Epoch: 6| Step: 2
Training loss: 0.3337988257408142
Validation loss: 1.5468796517259331

Epoch: 6| Step: 3
Training loss: 0.21798866987228394
Validation loss: 1.5473197249956028

Epoch: 6| Step: 4
Training loss: 0.35533806681632996
Validation loss: 1.5578409587183306

Epoch: 6| Step: 5
Training loss: 0.31643837690353394
Validation loss: 1.5712210670594247

Epoch: 6| Step: 6
Training loss: 0.13137459754943848
Validation loss: 1.5776005227078673

Epoch: 6| Step: 7
Training loss: 0.35899412631988525
Validation loss: 1.601051857394557

Epoch: 6| Step: 8
Training loss: 0.5241432189941406
Validation loss: 1.6169988173310474

Epoch: 6| Step: 9
Training loss: 0.3302777409553528
Validation loss: 1.6570472883921799

Epoch: 6| Step: 10
Training loss: 0.33943092823028564
Validation loss: 1.6269238687330676

Epoch: 6| Step: 11
Training loss: 0.43466368317604065
Validation loss: 1.6396737688331193

Epoch: 6| Step: 12
Training loss: 0.4689742624759674
Validation loss: 1.598244305579893

Epoch: 6| Step: 13
Training loss: 0.7978155016899109
Validation loss: 1.5886758412084272

Epoch: 245| Step: 0
Training loss: 0.38191449642181396
Validation loss: 1.5703206062316895

Epoch: 6| Step: 1
Training loss: 0.6973702907562256
Validation loss: 1.5960666236057077

Epoch: 6| Step: 2
Training loss: 0.2692672610282898
Validation loss: 1.5644190311431885

Epoch: 6| Step: 3
Training loss: 0.3524194657802582
Validation loss: 1.550487551637875

Epoch: 6| Step: 4
Training loss: 0.3711732029914856
Validation loss: 1.5630794571292015

Epoch: 6| Step: 5
Training loss: 0.4395354390144348
Validation loss: 1.5229216160312775

Epoch: 6| Step: 6
Training loss: 0.5423675179481506
Validation loss: 1.537380072378343

Epoch: 6| Step: 7
Training loss: 0.3900589942932129
Validation loss: 1.5122286068495883

Epoch: 6| Step: 8
Training loss: 0.45375439524650574
Validation loss: 1.5118749449329991

Epoch: 6| Step: 9
Training loss: 0.41587239503860474
Validation loss: 1.5053143501281738

Epoch: 6| Step: 10
Training loss: 0.33927977085113525
Validation loss: 1.55572308007107

Epoch: 6| Step: 11
Training loss: 0.4005240797996521
Validation loss: 1.573659699450257

Epoch: 6| Step: 12
Training loss: 0.49469876289367676
Validation loss: 1.6091999533355876

Epoch: 6| Step: 13
Training loss: 0.4516850709915161
Validation loss: 1.602382561211945

Epoch: 246| Step: 0
Training loss: 0.5081287026405334
Validation loss: 1.6276620664904196

Epoch: 6| Step: 1
Training loss: 0.5550572872161865
Validation loss: 1.6101898890669628

Epoch: 6| Step: 2
Training loss: 0.3218279480934143
Validation loss: 1.5608494922678957

Epoch: 6| Step: 3
Training loss: 0.42099425196647644
Validation loss: 1.5297381160079793

Epoch: 6| Step: 4
Training loss: 0.32131898403167725
Validation loss: 1.5222424525086597

Epoch: 6| Step: 5
Training loss: 0.543768048286438
Validation loss: 1.516153814972088

Epoch: 6| Step: 6
Training loss: 0.37068355083465576
Validation loss: 1.510291007898187

Epoch: 6| Step: 7
Training loss: 0.3989717364311218
Validation loss: 1.498576674410092

Epoch: 6| Step: 8
Training loss: 0.3920426368713379
Validation loss: 1.5268979969845022

Epoch: 6| Step: 9
Training loss: 0.485460489988327
Validation loss: 1.5491725296102545

Epoch: 6| Step: 10
Training loss: 0.4337109327316284
Validation loss: 1.5275774771167385

Epoch: 6| Step: 11
Training loss: 0.3954665958881378
Validation loss: 1.5191965442831799

Epoch: 6| Step: 12
Training loss: 0.11752445250749588
Validation loss: 1.4978552313261135

Epoch: 6| Step: 13
Training loss: 0.7299313545227051
Validation loss: 1.5126798614378898

Epoch: 247| Step: 0
Training loss: 0.3214797377586365
Validation loss: 1.519079093010195

Epoch: 6| Step: 1
Training loss: 0.49544525146484375
Validation loss: 1.5129619862443657

Epoch: 6| Step: 2
Training loss: 0.6445029377937317
Validation loss: 1.519557519625592

Epoch: 6| Step: 3
Training loss: 0.4757062494754791
Validation loss: 1.5046524757980018

Epoch: 6| Step: 4
Training loss: 0.3893156349658966
Validation loss: 1.4697756382726854

Epoch: 6| Step: 5
Training loss: 0.4703477621078491
Validation loss: 1.492863339762534

Epoch: 6| Step: 6
Training loss: 0.7214043140411377
Validation loss: 1.548480099247348

Epoch: 6| Step: 7
Training loss: 0.47713834047317505
Validation loss: 1.5805583884639125

Epoch: 6| Step: 8
Training loss: 0.48253974318504333
Validation loss: 1.537127976135541

Epoch: 6| Step: 9
Training loss: 0.32331007719039917
Validation loss: 1.5215728552110734

Epoch: 6| Step: 10
Training loss: 0.6021528244018555
Validation loss: 1.5015168164366035

Epoch: 6| Step: 11
Training loss: 0.3445110619068146
Validation loss: 1.514443120648784

Epoch: 6| Step: 12
Training loss: 0.49120253324508667
Validation loss: 1.5045109109211994

Epoch: 6| Step: 13
Training loss: 0.11878883838653564
Validation loss: 1.5548074027543426

Epoch: 248| Step: 0
Training loss: 0.6805567741394043
Validation loss: 1.5449566994943926

Epoch: 6| Step: 1
Training loss: 0.3133549988269806
Validation loss: 1.5558566957391717

Epoch: 6| Step: 2
Training loss: 0.21173395216464996
Validation loss: 1.5581465344275198

Epoch: 6| Step: 3
Training loss: 0.5054880976676941
Validation loss: 1.6036642905204528

Epoch: 6| Step: 4
Training loss: 0.6056920886039734
Validation loss: 1.5844366447899931

Epoch: 6| Step: 5
Training loss: 0.2795449495315552
Validation loss: 1.5774936599116172

Epoch: 6| Step: 6
Training loss: 0.37017369270324707
Validation loss: 1.5970776811722787

Epoch: 6| Step: 7
Training loss: 0.20918980240821838
Validation loss: 1.5948579221643426

Epoch: 6| Step: 8
Training loss: 0.4111406207084656
Validation loss: 1.6080626646677654

Epoch: 6| Step: 9
Training loss: 0.47137850522994995
Validation loss: 1.5861037726043372

Epoch: 6| Step: 10
Training loss: 0.39114314317703247
Validation loss: 1.575480648266372

Epoch: 6| Step: 11
Training loss: 0.6380729079246521
Validation loss: 1.5595308772979244

Epoch: 6| Step: 12
Training loss: 0.23453481495380402
Validation loss: 1.5759555511577155

Epoch: 6| Step: 13
Training loss: 0.3651222884654999
Validation loss: 1.532348773812735

Epoch: 249| Step: 0
Training loss: 0.2704969644546509
Validation loss: 1.5263214367692188

Epoch: 6| Step: 1
Training loss: 0.29419052600860596
Validation loss: 1.5076353870412356

Epoch: 6| Step: 2
Training loss: 0.3867946267127991
Validation loss: 1.5286512041604647

Epoch: 6| Step: 3
Training loss: 0.3563845753669739
Validation loss: 1.5295590098186205

Epoch: 6| Step: 4
Training loss: 0.37047508358955383
Validation loss: 1.5327362962948379

Epoch: 6| Step: 5
Training loss: 0.39316537976264954
Validation loss: 1.5145710091437063

Epoch: 6| Step: 6
Training loss: 0.3691134452819824
Validation loss: 1.519706404337319

Epoch: 6| Step: 7
Training loss: 0.28872162103652954
Validation loss: 1.5014777311714746

Epoch: 6| Step: 8
Training loss: 0.5953555107116699
Validation loss: 1.539408194121494

Epoch: 6| Step: 9
Training loss: 0.4101712107658386
Validation loss: 1.5164105212816628

Epoch: 6| Step: 10
Training loss: 0.4413192868232727
Validation loss: 1.5339968614680792

Epoch: 6| Step: 11
Training loss: 0.4149300754070282
Validation loss: 1.5130668147917716

Epoch: 6| Step: 12
Training loss: 0.15988074243068695
Validation loss: 1.501734575917644

Epoch: 6| Step: 13
Training loss: 0.4557549059391022
Validation loss: 1.4841357020921604

Epoch: 250| Step: 0
Training loss: 0.4109509587287903
Validation loss: 1.4895982088581208

Epoch: 6| Step: 1
Training loss: 0.2185038924217224
Validation loss: 1.4720324918787966

Epoch: 6| Step: 2
Training loss: 0.43353739380836487
Validation loss: 1.4820264424047163

Epoch: 6| Step: 3
Training loss: 0.21083027124404907
Validation loss: 1.4966608490995181

Epoch: 6| Step: 4
Training loss: 0.16857117414474487
Validation loss: 1.4698016784524406

Epoch: 6| Step: 5
Training loss: 0.3070356249809265
Validation loss: 1.4985045912445232

Epoch: 6| Step: 6
Training loss: 0.32338500022888184
Validation loss: 1.4790175281545168

Epoch: 6| Step: 7
Training loss: 0.3449079990386963
Validation loss: 1.5061697620217518

Epoch: 6| Step: 8
Training loss: 0.4079712927341461
Validation loss: 1.495810797778509

Epoch: 6| Step: 9
Training loss: 0.5754883289337158
Validation loss: 1.5524522963390555

Epoch: 6| Step: 10
Training loss: 0.5396865606307983
Validation loss: 1.53780799142776

Epoch: 6| Step: 11
Training loss: 0.2595639228820801
Validation loss: 1.5344037958370742

Epoch: 6| Step: 12
Training loss: 0.3056941628456116
Validation loss: 1.545306424940786

Epoch: 6| Step: 13
Training loss: 0.35346633195877075
Validation loss: 1.562505555409257

Epoch: 251| Step: 0
Training loss: 0.46849656105041504
Validation loss: 1.5305027256729782

Epoch: 6| Step: 1
Training loss: 0.35404348373413086
Validation loss: 1.5368752620553459

Epoch: 6| Step: 2
Training loss: 0.3195975422859192
Validation loss: 1.533959770715365

Epoch: 6| Step: 3
Training loss: 0.4805794358253479
Validation loss: 1.531235589775988

Epoch: 6| Step: 4
Training loss: 0.2500619888305664
Validation loss: 1.4969451337732294

Epoch: 6| Step: 5
Training loss: 0.5820478796958923
Validation loss: 1.489818863971259

Epoch: 6| Step: 6
Training loss: 0.43982335925102234
Validation loss: 1.4820883927806732

Epoch: 6| Step: 7
Training loss: 0.28603595495224
Validation loss: 1.4915250783325524

Epoch: 6| Step: 8
Training loss: 0.25480157136917114
Validation loss: 1.509903295065767

Epoch: 6| Step: 9
Training loss: 0.289069265127182
Validation loss: 1.50038952724908

Epoch: 6| Step: 10
Training loss: 0.5788482427597046
Validation loss: 1.4859062394788187

Epoch: 6| Step: 11
Training loss: 0.28265249729156494
Validation loss: 1.4777852258374613

Epoch: 6| Step: 12
Training loss: 0.33226072788238525
Validation loss: 1.493245950309179

Epoch: 6| Step: 13
Training loss: 0.34649014472961426
Validation loss: 1.5086103049657678

Epoch: 252| Step: 0
Training loss: 0.4299682676792145
Validation loss: 1.5233594909791024

Epoch: 6| Step: 1
Training loss: 0.4730771481990814
Validation loss: 1.5410081827512352

Epoch: 6| Step: 2
Training loss: 0.1799466907978058
Validation loss: 1.5431538333175003

Epoch: 6| Step: 3
Training loss: 0.3105464577674866
Validation loss: 1.546643772432881

Epoch: 6| Step: 4
Training loss: 0.2645224332809448
Validation loss: 1.5188414890279052

Epoch: 6| Step: 5
Training loss: 0.6341482400894165
Validation loss: 1.5489462370513587

Epoch: 6| Step: 6
Training loss: 0.4205297827720642
Validation loss: 1.530039297637119

Epoch: 6| Step: 7
Training loss: 0.3549228310585022
Validation loss: 1.5363729051364365

Epoch: 6| Step: 8
Training loss: 0.2452774941921234
Validation loss: 1.5176773930108676

Epoch: 6| Step: 9
Training loss: 0.3511635959148407
Validation loss: 1.5525565608855216

Epoch: 6| Step: 10
Training loss: 0.6044989824295044
Validation loss: 1.548561079527742

Epoch: 6| Step: 11
Training loss: 0.3630422353744507
Validation loss: 1.577153423781036

Epoch: 6| Step: 12
Training loss: 0.35870182514190674
Validation loss: 1.5526585130281345

Epoch: 6| Step: 13
Training loss: 0.3409411907196045
Validation loss: 1.539418403820325

Epoch: 253| Step: 0
Training loss: 0.3416796326637268
Validation loss: 1.5523028578809512

Epoch: 6| Step: 1
Training loss: 0.3132724165916443
Validation loss: 1.5912227822888283

Epoch: 6| Step: 2
Training loss: 0.2971319556236267
Validation loss: 1.5641299114432385

Epoch: 6| Step: 3
Training loss: 0.1543656885623932
Validation loss: 1.59339500370846

Epoch: 6| Step: 4
Training loss: 0.34869807958602905
Validation loss: 1.601707532841672

Epoch: 6| Step: 5
Training loss: 0.4272691607475281
Validation loss: 1.5738188489790885

Epoch: 6| Step: 6
Training loss: 0.3683411478996277
Validation loss: 1.575955871612795

Epoch: 6| Step: 7
Training loss: 0.7427245378494263
Validation loss: 1.5662441830481253

Epoch: 6| Step: 8
Training loss: 0.2917982041835785
Validation loss: 1.580165550272952

Epoch: 6| Step: 9
Training loss: 0.349686861038208
Validation loss: 1.5665090583985852

Epoch: 6| Step: 10
Training loss: 0.3896353840827942
Validation loss: 1.5461182543026504

Epoch: 6| Step: 11
Training loss: 0.3890978693962097
Validation loss: 1.5307728500776394

Epoch: 6| Step: 12
Training loss: 0.19624586403369904
Validation loss: 1.5191688665779688

Epoch: 6| Step: 13
Training loss: 0.364576518535614
Validation loss: 1.5100197689507597

Epoch: 254| Step: 0
Training loss: 0.18909798562526703
Validation loss: 1.5109213808531403

Epoch: 6| Step: 1
Training loss: 0.17420481145381927
Validation loss: 1.5041908756379159

Epoch: 6| Step: 2
Training loss: 0.29327768087387085
Validation loss: 1.4806300196596371

Epoch: 6| Step: 3
Training loss: 0.23773181438446045
Validation loss: 1.4914675502366916

Epoch: 6| Step: 4
Training loss: 0.20965488255023956
Validation loss: 1.505637695712428

Epoch: 6| Step: 5
Training loss: 0.47166505455970764
Validation loss: 1.5126110994687645

Epoch: 6| Step: 6
Training loss: 0.3552331030368805
Validation loss: 1.5034435910563315

Epoch: 6| Step: 7
Training loss: 0.1650916039943695
Validation loss: 1.5253049007026098

Epoch: 6| Step: 8
Training loss: 0.3640429377555847
Validation loss: 1.4978846196205384

Epoch: 6| Step: 9
Training loss: 0.21434849500656128
Validation loss: 1.511376065592612

Epoch: 6| Step: 10
Training loss: 0.7775759696960449
Validation loss: 1.5133242376389042

Epoch: 6| Step: 11
Training loss: 0.5341535806655884
Validation loss: 1.5207112963481615

Epoch: 6| Step: 12
Training loss: 0.4129578471183777
Validation loss: 1.515483735710062

Epoch: 6| Step: 13
Training loss: 0.15736094117164612
Validation loss: 1.505315073074833

Epoch: 255| Step: 0
Training loss: 0.39514094591140747
Validation loss: 1.5301759114829443

Epoch: 6| Step: 1
Training loss: 0.4149232506752014
Validation loss: 1.5117246566280242

Epoch: 6| Step: 2
Training loss: 0.3151453137397766
Validation loss: 1.5120773212884062

Epoch: 6| Step: 3
Training loss: 0.26741647720336914
Validation loss: 1.5375077070728425

Epoch: 6| Step: 4
Training loss: 0.42480266094207764
Validation loss: 1.5576947107109973

Epoch: 6| Step: 5
Training loss: 0.30811285972595215
Validation loss: 1.5453025871707546

Epoch: 6| Step: 6
Training loss: 0.17090441286563873
Validation loss: 1.5654888973441174

Epoch: 6| Step: 7
Training loss: 0.4956269860267639
Validation loss: 1.5526056751128166

Epoch: 6| Step: 8
Training loss: 0.2847992181777954
Validation loss: 1.5688202381134033

Epoch: 6| Step: 9
Training loss: 0.3742903172969818
Validation loss: 1.5829819671569332

Epoch: 6| Step: 10
Training loss: 0.46511006355285645
Validation loss: 1.5795869724724882

Epoch: 6| Step: 11
Training loss: 0.34723421931266785
Validation loss: 1.5945131624898603

Epoch: 6| Step: 12
Training loss: 0.27021554112434387
Validation loss: 1.5824955214736283

Epoch: 6| Step: 13
Training loss: 0.2895481288433075
Validation loss: 1.546394166126046

Epoch: 256| Step: 0
Training loss: 0.16233128309249878
Validation loss: 1.5495258185171312

Epoch: 6| Step: 1
Training loss: 0.5029608607292175
Validation loss: 1.5628167890733289

Epoch: 6| Step: 2
Training loss: 0.3195537328720093
Validation loss: 1.5708364799458494

Epoch: 6| Step: 3
Training loss: 0.6630120873451233
Validation loss: 1.5787801627189881

Epoch: 6| Step: 4
Training loss: 0.2943687438964844
Validation loss: 1.5225736518060007

Epoch: 6| Step: 5
Training loss: 0.3735342025756836
Validation loss: 1.5071864890795883

Epoch: 6| Step: 6
Training loss: 0.5085505247116089
Validation loss: 1.5037920680097354

Epoch: 6| Step: 7
Training loss: 0.3255154490470886
Validation loss: 1.4972365043496574

Epoch: 6| Step: 8
Training loss: 0.36188703775405884
Validation loss: 1.4971354187175792

Epoch: 6| Step: 9
Training loss: 0.3464878499507904
Validation loss: 1.5050170908692062

Epoch: 6| Step: 10
Training loss: 0.5380657911300659
Validation loss: 1.5038951212360012

Epoch: 6| Step: 11
Training loss: 0.36845603585243225
Validation loss: 1.526298031371127

Epoch: 6| Step: 12
Training loss: 0.24560466408729553
Validation loss: 1.5061048487181306

Epoch: 6| Step: 13
Training loss: 0.2575663924217224
Validation loss: 1.5193714723792127

Epoch: 257| Step: 0
Training loss: 0.2772003710269928
Validation loss: 1.5092561411601242

Epoch: 6| Step: 1
Training loss: 0.3295952379703522
Validation loss: 1.5160279299623223

Epoch: 6| Step: 2
Training loss: 0.4952404797077179
Validation loss: 1.5396566442264024

Epoch: 6| Step: 3
Training loss: 0.31886228919029236
Validation loss: 1.5646198449596282

Epoch: 6| Step: 4
Training loss: 0.3500426411628723
Validation loss: 1.5473092166326379

Epoch: 6| Step: 5
Training loss: 0.3591475486755371
Validation loss: 1.547774625080888

Epoch: 6| Step: 6
Training loss: 0.27720320224761963
Validation loss: 1.5463662967886975

Epoch: 6| Step: 7
Training loss: 0.27594512701034546
Validation loss: 1.5569956841007355

Epoch: 6| Step: 8
Training loss: 0.46990489959716797
Validation loss: 1.5586113558020642

Epoch: 6| Step: 9
Training loss: 0.54891037940979
Validation loss: 1.5401268133553125

Epoch: 6| Step: 10
Training loss: 0.39555734395980835
Validation loss: 1.5470785902392479

Epoch: 6| Step: 11
Training loss: 0.43426382541656494
Validation loss: 1.5415736680389733

Epoch: 6| Step: 12
Training loss: 0.21918053925037384
Validation loss: 1.5313557911944646

Epoch: 6| Step: 13
Training loss: 0.48756545782089233
Validation loss: 1.5307611906400291

Epoch: 258| Step: 0
Training loss: 0.3601309359073639
Validation loss: 1.5446108502726401

Epoch: 6| Step: 1
Training loss: 0.3820136785507202
Validation loss: 1.5463537170040993

Epoch: 6| Step: 2
Training loss: 0.37111830711364746
Validation loss: 1.5343448756843485

Epoch: 6| Step: 3
Training loss: 0.4843920171260834
Validation loss: 1.4999666534444338

Epoch: 6| Step: 4
Training loss: 0.5362147092819214
Validation loss: 1.4985342641030588

Epoch: 6| Step: 5
Training loss: 0.4010452330112457
Validation loss: 1.510124901289581

Epoch: 6| Step: 6
Training loss: 0.42609497904777527
Validation loss: 1.4718761892728909

Epoch: 6| Step: 7
Training loss: 0.27834439277648926
Validation loss: 1.4791443322294502

Epoch: 6| Step: 8
Training loss: 0.15459106862545013
Validation loss: 1.4957309243499592

Epoch: 6| Step: 9
Training loss: 0.5390691757202148
Validation loss: 1.4868210739986871

Epoch: 6| Step: 10
Training loss: 0.328612744808197
Validation loss: 1.525130279602543

Epoch: 6| Step: 11
Training loss: 0.18056336045265198
Validation loss: 1.5357493200609762

Epoch: 6| Step: 12
Training loss: 0.28897643089294434
Validation loss: 1.527010924072676

Epoch: 6| Step: 13
Training loss: 0.41783204674720764
Validation loss: 1.552149902107895

Epoch: 259| Step: 0
Training loss: 0.2887997627258301
Validation loss: 1.563937428177044

Epoch: 6| Step: 1
Training loss: 0.3600427508354187
Validation loss: 1.5663819313049316

Epoch: 6| Step: 2
Training loss: 0.2882373332977295
Validation loss: 1.5760244746362009

Epoch: 6| Step: 3
Training loss: 0.2723156213760376
Validation loss: 1.5785487697970482

Epoch: 6| Step: 4
Training loss: 0.42634016275405884
Validation loss: 1.578589443237551

Epoch: 6| Step: 5
Training loss: 0.4908549189567566
Validation loss: 1.5748480468667962

Epoch: 6| Step: 6
Training loss: 0.30924516916275024
Validation loss: 1.5844891250774424

Epoch: 6| Step: 7
Training loss: 0.3278619349002838
Validation loss: 1.5801096705980198

Epoch: 6| Step: 8
Training loss: 0.3880600035190582
Validation loss: 1.554415693847082

Epoch: 6| Step: 9
Training loss: 0.45553871989250183
Validation loss: 1.5433610895628571

Epoch: 6| Step: 10
Training loss: 0.3315492868423462
Validation loss: 1.4931612450589415

Epoch: 6| Step: 11
Training loss: 0.38798999786376953
Validation loss: 1.5176840123309885

Epoch: 6| Step: 12
Training loss: 0.298618882894516
Validation loss: 1.4930025044307913

Epoch: 6| Step: 13
Training loss: 0.37503576278686523
Validation loss: 1.4758604239392024

Epoch: 260| Step: 0
Training loss: 0.21328994631767273
Validation loss: 1.4934851866896435

Epoch: 6| Step: 1
Training loss: 0.24825209379196167
Validation loss: 1.4797820698830388

Epoch: 6| Step: 2
Training loss: 0.2196081280708313
Validation loss: 1.4923190404010076

Epoch: 6| Step: 3
Training loss: 0.48823082447052
Validation loss: 1.4960594036245858

Epoch: 6| Step: 4
Training loss: 0.24685364961624146
Validation loss: 1.505220285025976

Epoch: 6| Step: 5
Training loss: 0.3504573404788971
Validation loss: 1.492078568345757

Epoch: 6| Step: 6
Training loss: 0.41037294268608093
Validation loss: 1.5050599408406082

Epoch: 6| Step: 7
Training loss: 0.448993444442749
Validation loss: 1.4830889548024824

Epoch: 6| Step: 8
Training loss: 0.2452966570854187
Validation loss: 1.4885469828882525

Epoch: 6| Step: 9
Training loss: 0.2145073115825653
Validation loss: 1.5017596380684965

Epoch: 6| Step: 10
Training loss: 0.33112961053848267
Validation loss: 1.5275828825530184

Epoch: 6| Step: 11
Training loss: 0.4158913493156433
Validation loss: 1.5450499993498608

Epoch: 6| Step: 12
Training loss: 0.26468557119369507
Validation loss: 1.5417439553045458

Epoch: 6| Step: 13
Training loss: 0.2659291625022888
Validation loss: 1.5416641196896952

Epoch: 261| Step: 0
Training loss: 0.1948430836200714
Validation loss: 1.565321623638112

Epoch: 6| Step: 1
Training loss: 0.2992784380912781
Validation loss: 1.5509131544379777

Epoch: 6| Step: 2
Training loss: 0.30265185236930847
Validation loss: 1.558580308191238

Epoch: 6| Step: 3
Training loss: 0.455075204372406
Validation loss: 1.5152812375817248

Epoch: 6| Step: 4
Training loss: 0.18768513202667236
Validation loss: 1.5117982561870287

Epoch: 6| Step: 5
Training loss: 0.3023132085800171
Validation loss: 1.491269532070365

Epoch: 6| Step: 6
Training loss: 0.27289873361587524
Validation loss: 1.5192999839782715

Epoch: 6| Step: 7
Training loss: 0.21655333042144775
Validation loss: 1.4903233897301458

Epoch: 6| Step: 8
Training loss: 0.21082893013954163
Validation loss: 1.511860337308658

Epoch: 6| Step: 9
Training loss: 0.3158543109893799
Validation loss: 1.5155571801688081

Epoch: 6| Step: 10
Training loss: 0.3993971645832062
Validation loss: 1.5169542822786557

Epoch: 6| Step: 11
Training loss: 0.2828364372253418
Validation loss: 1.4979018780492968

Epoch: 6| Step: 12
Training loss: 0.46226757764816284
Validation loss: 1.514461450679328

Epoch: 6| Step: 13
Training loss: 0.31073105335235596
Validation loss: 1.4930289547930482

Epoch: 262| Step: 0
Training loss: 0.22304406762123108
Validation loss: 1.4934291019234607

Epoch: 6| Step: 1
Training loss: 0.2902984619140625
Validation loss: 1.4947154701396983

Epoch: 6| Step: 2
Training loss: 0.30649060010910034
Validation loss: 1.4796857455725312

Epoch: 6| Step: 3
Training loss: 0.17679762840270996
Validation loss: 1.4705377483880648

Epoch: 6| Step: 4
Training loss: 0.13178643584251404
Validation loss: 1.4855343808409989

Epoch: 6| Step: 5
Training loss: 0.21477192640304565
Validation loss: 1.4837949045242802

Epoch: 6| Step: 6
Training loss: 0.427849143743515
Validation loss: 1.4924664734512247

Epoch: 6| Step: 7
Training loss: 0.4410695731639862
Validation loss: 1.5009899293222735

Epoch: 6| Step: 8
Training loss: 0.48889583349227905
Validation loss: 1.4958911980352094

Epoch: 6| Step: 9
Training loss: 0.32427656650543213
Validation loss: 1.5012051084990143

Epoch: 6| Step: 10
Training loss: 0.4326219856739044
Validation loss: 1.4971994815334198

Epoch: 6| Step: 11
Training loss: 0.18020159006118774
Validation loss: 1.512217826740716

Epoch: 6| Step: 12
Training loss: 0.25854358077049255
Validation loss: 1.5201556483904521

Epoch: 6| Step: 13
Training loss: 0.25522857904434204
Validation loss: 1.498974960337403

Epoch: 263| Step: 0
Training loss: 0.21118566393852234
Validation loss: 1.5190654800784202

Epoch: 6| Step: 1
Training loss: 0.265610009431839
Validation loss: 1.5188188399038007

Epoch: 6| Step: 2
Training loss: 0.31280845403671265
Validation loss: 1.5400228000456286

Epoch: 6| Step: 3
Training loss: 0.20240965485572815
Validation loss: 1.55290715348336

Epoch: 6| Step: 4
Training loss: 0.5048447251319885
Validation loss: 1.5464822746092273

Epoch: 6| Step: 5
Training loss: 0.49306851625442505
Validation loss: 1.5446513968129312

Epoch: 6| Step: 6
Training loss: 0.27268433570861816
Validation loss: 1.5172632368662025

Epoch: 6| Step: 7
Training loss: 0.23474615812301636
Validation loss: 1.5117573251006424

Epoch: 6| Step: 8
Training loss: 0.25798630714416504
Validation loss: 1.5348331543707079

Epoch: 6| Step: 9
Training loss: 0.4142392873764038
Validation loss: 1.5217733716451993

Epoch: 6| Step: 10
Training loss: 0.21641874313354492
Validation loss: 1.522488304363784

Epoch: 6| Step: 11
Training loss: 0.3454766273498535
Validation loss: 1.5336276350482818

Epoch: 6| Step: 12
Training loss: 0.4045756757259369
Validation loss: 1.5150491101767427

Epoch: 6| Step: 13
Training loss: 0.17466306686401367
Validation loss: 1.518257994805613

Epoch: 264| Step: 0
Training loss: 0.3018171489238739
Validation loss: 1.5332893517709547

Epoch: 6| Step: 1
Training loss: 0.5728851556777954
Validation loss: 1.5175201623670516

Epoch: 6| Step: 2
Training loss: 0.36788657307624817
Validation loss: 1.5118818699672658

Epoch: 6| Step: 3
Training loss: 0.2333391308784485
Validation loss: 1.5029920352402555

Epoch: 6| Step: 4
Training loss: 0.2980669438838959
Validation loss: 1.4948542746164466

Epoch: 6| Step: 5
Training loss: 0.13037502765655518
Validation loss: 1.488778878283757

Epoch: 6| Step: 6
Training loss: 0.23361928761005402
Validation loss: 1.5016704528562483

Epoch: 6| Step: 7
Training loss: 0.13617074489593506
Validation loss: 1.4938913519664476

Epoch: 6| Step: 8
Training loss: 0.2114749550819397
Validation loss: 1.5052481825633715

Epoch: 6| Step: 9
Training loss: 0.488337904214859
Validation loss: 1.5089249277627597

Epoch: 6| Step: 10
Training loss: 0.6838877201080322
Validation loss: 1.4865054443318357

Epoch: 6| Step: 11
Training loss: 0.1719026267528534
Validation loss: 1.4717350595740861

Epoch: 6| Step: 12
Training loss: 0.32823359966278076
Validation loss: 1.5107602547573786

Epoch: 6| Step: 13
Training loss: 0.0879553034901619
Validation loss: 1.4805840574285036

Epoch: 265| Step: 0
Training loss: 0.5830034017562866
Validation loss: 1.5063451038252922

Epoch: 6| Step: 1
Training loss: 0.46988970041275024
Validation loss: 1.4968222289957025

Epoch: 6| Step: 2
Training loss: 0.2601894736289978
Validation loss: 1.486345709011119

Epoch: 6| Step: 3
Training loss: 0.35094207525253296
Validation loss: 1.4827023334400629

Epoch: 6| Step: 4
Training loss: 0.22594961524009705
Validation loss: 1.4808741513118948

Epoch: 6| Step: 5
Training loss: 0.212815061211586
Validation loss: 1.4791397958673456

Epoch: 6| Step: 6
Training loss: 0.2194591462612152
Validation loss: 1.4560578792325911

Epoch: 6| Step: 7
Training loss: 0.20430350303649902
Validation loss: 1.4332057968262704

Epoch: 6| Step: 8
Training loss: 0.21146100759506226
Validation loss: 1.4719891573793145

Epoch: 6| Step: 9
Training loss: 0.22788898646831512
Validation loss: 1.4589536895034134

Epoch: 6| Step: 10
Training loss: 0.3245431184768677
Validation loss: 1.4497404886830239

Epoch: 6| Step: 11
Training loss: 0.314913809299469
Validation loss: 1.4559524956569876

Epoch: 6| Step: 12
Training loss: 0.5135513544082642
Validation loss: 1.4739335358783763

Epoch: 6| Step: 13
Training loss: 0.34702205657958984
Validation loss: 1.4719596319301154

Epoch: 266| Step: 0
Training loss: 0.40268123149871826
Validation loss: 1.4800273064644105

Epoch: 6| Step: 1
Training loss: 0.23829618096351624
Validation loss: 1.4704379240671794

Epoch: 6| Step: 2
Training loss: 0.2552526891231537
Validation loss: 1.5214067056614866

Epoch: 6| Step: 3
Training loss: 0.2772737145423889
Validation loss: 1.5296845666823848

Epoch: 6| Step: 4
Training loss: 0.4357544183731079
Validation loss: 1.5185037825697212

Epoch: 6| Step: 5
Training loss: 0.22112758457660675
Validation loss: 1.5417111971045052

Epoch: 6| Step: 6
Training loss: 0.2687981128692627
Validation loss: 1.5221644383604809

Epoch: 6| Step: 7
Training loss: 0.27347803115844727
Validation loss: 1.525239121529364

Epoch: 6| Step: 8
Training loss: 0.14897160232067108
Validation loss: 1.5038170147967596

Epoch: 6| Step: 9
Training loss: 0.29145634174346924
Validation loss: 1.4890910951040124

Epoch: 6| Step: 10
Training loss: 0.4514409303665161
Validation loss: 1.4969526042220413

Epoch: 6| Step: 11
Training loss: 0.2361069917678833
Validation loss: 1.4897173258566088

Epoch: 6| Step: 12
Training loss: 0.21921604871749878
Validation loss: 1.5299043334940428

Epoch: 6| Step: 13
Training loss: 0.4304140508174896
Validation loss: 1.5111648382679108

Epoch: 267| Step: 0
Training loss: 0.14767037332057953
Validation loss: 1.5359713057036042

Epoch: 6| Step: 1
Training loss: 0.19293609261512756
Validation loss: 1.504573590012007

Epoch: 6| Step: 2
Training loss: 0.1525588184595108
Validation loss: 1.5223245325908865

Epoch: 6| Step: 3
Training loss: 0.3112436830997467
Validation loss: 1.4948171736091695

Epoch: 6| Step: 4
Training loss: 0.26070070266723633
Validation loss: 1.5186218638573923

Epoch: 6| Step: 5
Training loss: 0.328948050737381
Validation loss: 1.4986217585943078

Epoch: 6| Step: 6
Training loss: 0.4269579350948334
Validation loss: 1.4981668585090226

Epoch: 6| Step: 7
Training loss: 0.3395732641220093
Validation loss: 1.5010741090261808

Epoch: 6| Step: 8
Training loss: 0.3361464738845825
Validation loss: 1.4935745013657438

Epoch: 6| Step: 9
Training loss: 0.2897937595844269
Validation loss: 1.4917737360923522

Epoch: 6| Step: 10
Training loss: 0.33678972721099854
Validation loss: 1.4731503314869379

Epoch: 6| Step: 11
Training loss: 0.38869065046310425
Validation loss: 1.4533230168845064

Epoch: 6| Step: 12
Training loss: 0.40744203329086304
Validation loss: 1.4426872640527704

Epoch: 6| Step: 13
Training loss: 0.1226068064570427
Validation loss: 1.3938008021282893

Epoch: 268| Step: 0
Training loss: 0.25346240401268005
Validation loss: 1.4243260263114847

Epoch: 6| Step: 1
Training loss: 0.4747694730758667
Validation loss: 1.4209657330666818

Epoch: 6| Step: 2
Training loss: 0.40645915269851685
Validation loss: 1.464816003717402

Epoch: 6| Step: 3
Training loss: 0.5260814428329468
Validation loss: 1.4837397683051325

Epoch: 6| Step: 4
Training loss: 0.3579570949077606
Validation loss: 1.455571013112222

Epoch: 6| Step: 5
Training loss: 0.24007436633110046
Validation loss: 1.4631146538642146

Epoch: 6| Step: 6
Training loss: 0.30376917123794556
Validation loss: 1.4637140894448886

Epoch: 6| Step: 7
Training loss: 0.2599823474884033
Validation loss: 1.4583399295806885

Epoch: 6| Step: 8
Training loss: 0.2067951261997223
Validation loss: 1.458241524875805

Epoch: 6| Step: 9
Training loss: 0.36875808238983154
Validation loss: 1.458081228758699

Epoch: 6| Step: 10
Training loss: 0.2570444345474243
Validation loss: 1.46564527480833

Epoch: 6| Step: 11
Training loss: 0.2516031563282013
Validation loss: 1.4694591081270607

Epoch: 6| Step: 12
Training loss: 0.12061707675457001
Validation loss: 1.4686814828585553

Epoch: 6| Step: 13
Training loss: 0.21327060461044312
Validation loss: 1.4680141954011814

Epoch: 269| Step: 0
Training loss: 0.5327925682067871
Validation loss: 1.46957556791203

Epoch: 6| Step: 1
Training loss: 0.28540369868278503
Validation loss: 1.4841184564816055

Epoch: 6| Step: 2
Training loss: 0.27149248123168945
Validation loss: 1.4398503675255725

Epoch: 6| Step: 3
Training loss: 0.2223154455423355
Validation loss: 1.474055455576989

Epoch: 6| Step: 4
Training loss: 0.14626780152320862
Validation loss: 1.4550131315826087

Epoch: 6| Step: 5
Training loss: 0.21953509747982025
Validation loss: 1.4663859580152778

Epoch: 6| Step: 6
Training loss: 0.2225634902715683
Validation loss: 1.444884910378405

Epoch: 6| Step: 7
Training loss: 0.20960529148578644
Validation loss: 1.4333055314197336

Epoch: 6| Step: 8
Training loss: 0.12909626960754395
Validation loss: 1.4227108250382126

Epoch: 6| Step: 9
Training loss: 0.3397639989852905
Validation loss: 1.4257342456489481

Epoch: 6| Step: 10
Training loss: 0.3542020320892334
Validation loss: 1.4453512378918227

Epoch: 6| Step: 11
Training loss: 0.37365618348121643
Validation loss: 1.43129514878796

Epoch: 6| Step: 12
Training loss: 0.23310798406600952
Validation loss: 1.4396864406524166

Epoch: 6| Step: 13
Training loss: 0.15643872320652008
Validation loss: 1.4419916611845776

Epoch: 270| Step: 0
Training loss: 0.34660255908966064
Validation loss: 1.4228965249112857

Epoch: 6| Step: 1
Training loss: 0.3157932162284851
Validation loss: 1.4507067498340402

Epoch: 6| Step: 2
Training loss: 0.13748016953468323
Validation loss: 1.4422792362910446

Epoch: 6| Step: 3
Training loss: 0.4105958044528961
Validation loss: 1.48735547578463

Epoch: 6| Step: 4
Training loss: 0.32181209325790405
Validation loss: 1.4701464893997356

Epoch: 6| Step: 5
Training loss: 0.16525690257549286
Validation loss: 1.4639177976116058

Epoch: 6| Step: 6
Training loss: 0.24224701523780823
Validation loss: 1.4786395244700934

Epoch: 6| Step: 7
Training loss: 0.16744258999824524
Validation loss: 1.4977116687323457

Epoch: 6| Step: 8
Training loss: 0.1763039529323578
Validation loss: 1.4960917708694295

Epoch: 6| Step: 9
Training loss: 0.25450071692466736
Validation loss: 1.5153503571787188

Epoch: 6| Step: 10
Training loss: 0.25472891330718994
Validation loss: 1.5040855676897111

Epoch: 6| Step: 11
Training loss: 0.1911838948726654
Validation loss: 1.49791290426767

Epoch: 6| Step: 12
Training loss: 0.4614534378051758
Validation loss: 1.5099064137346

Epoch: 6| Step: 13
Training loss: 0.19678254425525665
Validation loss: 1.5044284789792952

Epoch: 271| Step: 0
Training loss: 0.16278231143951416
Validation loss: 1.4870580088707708

Epoch: 6| Step: 1
Training loss: 0.35671478509902954
Validation loss: 1.5059102940303024

Epoch: 6| Step: 2
Training loss: 0.33967918157577515
Validation loss: 1.503066385945966

Epoch: 6| Step: 3
Training loss: 0.14164958894252777
Validation loss: 1.5180085019398761

Epoch: 6| Step: 4
Training loss: 0.21529701352119446
Validation loss: 1.5377431825924945

Epoch: 6| Step: 5
Training loss: 0.1957024335861206
Validation loss: 1.5287922505409486

Epoch: 6| Step: 6
Training loss: 0.3943186104297638
Validation loss: 1.536663596348096

Epoch: 6| Step: 7
Training loss: 0.6052474975585938
Validation loss: 1.5052860295900734

Epoch: 6| Step: 8
Training loss: 0.22505606710910797
Validation loss: 1.4996251380571755

Epoch: 6| Step: 9
Training loss: 0.439862996339798
Validation loss: 1.487336366407333

Epoch: 6| Step: 10
Training loss: 0.21990419924259186
Validation loss: 1.446780623287283

Epoch: 6| Step: 11
Training loss: 0.25014153122901917
Validation loss: 1.450443099903804

Epoch: 6| Step: 12
Training loss: 0.3542991280555725
Validation loss: 1.4339195733429284

Epoch: 6| Step: 13
Training loss: 0.3881979286670685
Validation loss: 1.4177169748531875

Epoch: 272| Step: 0
Training loss: 0.23627620935440063
Validation loss: 1.430025339126587

Epoch: 6| Step: 1
Training loss: 0.3328177034854889
Validation loss: 1.4287335975195772

Epoch: 6| Step: 2
Training loss: 0.35432520508766174
Validation loss: 1.422532577668467

Epoch: 6| Step: 3
Training loss: 0.21644996106624603
Validation loss: 1.419553666986445

Epoch: 6| Step: 4
Training loss: 0.4413493871688843
Validation loss: 1.4380480192040885

Epoch: 6| Step: 5
Training loss: 0.3896322250366211
Validation loss: 1.4480528805845527

Epoch: 6| Step: 6
Training loss: 0.245774507522583
Validation loss: 1.4678587323875838

Epoch: 6| Step: 7
Training loss: 0.1592618227005005
Validation loss: 1.4713208598475302

Epoch: 6| Step: 8
Training loss: 0.3475961983203888
Validation loss: 1.4843205098182923

Epoch: 6| Step: 9
Training loss: 0.27161580324172974
Validation loss: 1.4670911232630413

Epoch: 6| Step: 10
Training loss: 0.10829702019691467
Validation loss: 1.4810057077356564

Epoch: 6| Step: 11
Training loss: 0.4934694170951843
Validation loss: 1.4890138603025866

Epoch: 6| Step: 12
Training loss: 0.257408082485199
Validation loss: 1.4902179869272376

Epoch: 6| Step: 13
Training loss: 0.19948512315750122
Validation loss: 1.4893447532448718

Epoch: 273| Step: 0
Training loss: 0.10806726664304733
Validation loss: 1.4859860122844737

Epoch: 6| Step: 1
Training loss: 0.2510574460029602
Validation loss: 1.4779459097052132

Epoch: 6| Step: 2
Training loss: 0.36258870363235474
Validation loss: 1.518708417492528

Epoch: 6| Step: 3
Training loss: 0.47845155000686646
Validation loss: 1.5105947499634118

Epoch: 6| Step: 4
Training loss: 0.20855386555194855
Validation loss: 1.5139533563326764

Epoch: 6| Step: 5
Training loss: 0.27947309613227844
Validation loss: 1.5168760566301243

Epoch: 6| Step: 6
Training loss: 0.2994561195373535
Validation loss: 1.5309997181738577

Epoch: 6| Step: 7
Training loss: 0.295787513256073
Validation loss: 1.5140352543964182

Epoch: 6| Step: 8
Training loss: 0.2642703950405121
Validation loss: 1.5023353574096516

Epoch: 6| Step: 9
Training loss: 0.3527257442474365
Validation loss: 1.497542142868042

Epoch: 6| Step: 10
Training loss: 0.2915990352630615
Validation loss: 1.4795601803769347

Epoch: 6| Step: 11
Training loss: 0.2735668122768402
Validation loss: 1.5025811272282754

Epoch: 6| Step: 12
Training loss: 0.22203479707241058
Validation loss: 1.4621917329808718

Epoch: 6| Step: 13
Training loss: 0.2818843424320221
Validation loss: 1.487977926449109

Epoch: 274| Step: 0
Training loss: 0.3326878547668457
Validation loss: 1.4761414745802521

Epoch: 6| Step: 1
Training loss: 0.2273668348789215
Validation loss: 1.4637425407286613

Epoch: 6| Step: 2
Training loss: 0.48919573426246643
Validation loss: 1.4589755099306825

Epoch: 6| Step: 3
Training loss: 0.25644350051879883
Validation loss: 1.4458115049587783

Epoch: 6| Step: 4
Training loss: 0.24597012996673584
Validation loss: 1.4382938672137517

Epoch: 6| Step: 5
Training loss: 0.34105706214904785
Validation loss: 1.4512380758921306

Epoch: 6| Step: 6
Training loss: 0.23027057945728302
Validation loss: 1.4705281539629864

Epoch: 6| Step: 7
Training loss: 0.3411523699760437
Validation loss: 1.4765040643753544

Epoch: 6| Step: 8
Training loss: 0.4119519293308258
Validation loss: 1.490013837814331

Epoch: 6| Step: 9
Training loss: 0.2542957365512848
Validation loss: 1.5085216837544595

Epoch: 6| Step: 10
Training loss: 0.14923110604286194
Validation loss: 1.5129493744142595

Epoch: 6| Step: 11
Training loss: 0.3172278106212616
Validation loss: 1.5164496680741668

Epoch: 6| Step: 12
Training loss: 0.18479806184768677
Validation loss: 1.5019093662179925

Epoch: 6| Step: 13
Training loss: 0.47361502051353455
Validation loss: 1.5093909617393249

Epoch: 275| Step: 0
Training loss: 0.3389117419719696
Validation loss: 1.4738167306428314

Epoch: 6| Step: 1
Training loss: 0.3030751943588257
Validation loss: 1.4715198752700642

Epoch: 6| Step: 2
Training loss: 0.157956063747406
Validation loss: 1.5039288010648502

Epoch: 6| Step: 3
Training loss: 0.301707923412323
Validation loss: 1.4787441581808112

Epoch: 6| Step: 4
Training loss: 0.2252504974603653
Validation loss: 1.4853856845568585

Epoch: 6| Step: 5
Training loss: 0.39430785179138184
Validation loss: 1.483940012993351

Epoch: 6| Step: 6
Training loss: 0.19869472086429596
Validation loss: 1.4790848634576286

Epoch: 6| Step: 7
Training loss: 0.2777842879295349
Validation loss: 1.4803515441956059

Epoch: 6| Step: 8
Training loss: 0.33142197132110596
Validation loss: 1.4894304506240352

Epoch: 6| Step: 9
Training loss: 0.35387033224105835
Validation loss: 1.485097392912834

Epoch: 6| Step: 10
Training loss: 0.36663419008255005
Validation loss: 1.4882503401848577

Epoch: 6| Step: 11
Training loss: 0.21199055016040802
Validation loss: 1.5211136648731847

Epoch: 6| Step: 12
Training loss: 0.20209243893623352
Validation loss: 1.5346163921458746

Epoch: 6| Step: 13
Training loss: 0.2959747016429901
Validation loss: 1.530753275399567

Epoch: 276| Step: 0
Training loss: 0.33583763241767883
Validation loss: 1.5476313714058167

Epoch: 6| Step: 1
Training loss: 0.4184604287147522
Validation loss: 1.5373609271100772

Epoch: 6| Step: 2
Training loss: 0.30923962593078613
Validation loss: 1.5343933977106565

Epoch: 6| Step: 3
Training loss: 0.3452300727367401
Validation loss: 1.5456824533400997

Epoch: 6| Step: 4
Training loss: 0.2851930260658264
Validation loss: 1.5203856870692263

Epoch: 6| Step: 5
Training loss: 0.29063335061073303
Validation loss: 1.5328776695395028

Epoch: 6| Step: 6
Training loss: 0.4190519154071808
Validation loss: 1.5067513732499973

Epoch: 6| Step: 7
Training loss: 0.2573498785495758
Validation loss: 1.5382126089065307

Epoch: 6| Step: 8
Training loss: 0.2846788763999939
Validation loss: 1.504688032211796

Epoch: 6| Step: 9
Training loss: 0.3770565688610077
Validation loss: 1.5064689933612783

Epoch: 6| Step: 10
Training loss: 0.4947047233581543
Validation loss: 1.52943512188491

Epoch: 6| Step: 11
Training loss: 0.37408047914505005
Validation loss: 1.500145968570504

Epoch: 6| Step: 12
Training loss: 0.19040557742118835
Validation loss: 1.465127824455179

Epoch: 6| Step: 13
Training loss: 0.10783979296684265
Validation loss: 1.4617498279899679

Epoch: 277| Step: 0
Training loss: 0.26211977005004883
Validation loss: 1.457633436367076

Epoch: 6| Step: 1
Training loss: 0.42797553539276123
Validation loss: 1.4752968280546126

Epoch: 6| Step: 2
Training loss: 0.43706178665161133
Validation loss: 1.4555526369361467

Epoch: 6| Step: 3
Training loss: 0.2768530249595642
Validation loss: 1.4993090386031775

Epoch: 6| Step: 4
Training loss: 0.20234592258930206
Validation loss: 1.4821182168940061

Epoch: 6| Step: 5
Training loss: 0.4202764332294464
Validation loss: 1.4867778317902678

Epoch: 6| Step: 6
Training loss: 0.2969282865524292
Validation loss: 1.4902630467568674

Epoch: 6| Step: 7
Training loss: 0.14612999558448792
Validation loss: 1.4760368024149249

Epoch: 6| Step: 8
Training loss: 0.19246086478233337
Validation loss: 1.4930227129690108

Epoch: 6| Step: 9
Training loss: 0.2849002480506897
Validation loss: 1.4954772200635684

Epoch: 6| Step: 10
Training loss: 0.15437696874141693
Validation loss: 1.49994509643124

Epoch: 6| Step: 11
Training loss: 0.23007257282733917
Validation loss: 1.4962549645413634

Epoch: 6| Step: 12
Training loss: 0.13897258043289185
Validation loss: 1.5051741241126932

Epoch: 6| Step: 13
Training loss: 0.36293819546699524
Validation loss: 1.5108980722324823

Epoch: 278| Step: 0
Training loss: 0.24424514174461365
Validation loss: 1.5312546965896443

Epoch: 6| Step: 1
Training loss: 0.3001661002635956
Validation loss: 1.5340178269211964

Epoch: 6| Step: 2
Training loss: 0.26711341738700867
Validation loss: 1.5351351730285152

Epoch: 6| Step: 3
Training loss: 0.3407246768474579
Validation loss: 1.5078927727155789

Epoch: 6| Step: 4
Training loss: 0.196569561958313
Validation loss: 1.5309698043331024

Epoch: 6| Step: 5
Training loss: 0.2074892371892929
Validation loss: 1.5037584253536758

Epoch: 6| Step: 6
Training loss: 0.1582615077495575
Validation loss: 1.5054160311657896

Epoch: 6| Step: 7
Training loss: 0.19507762789726257
Validation loss: 1.5015282579647597

Epoch: 6| Step: 8
Training loss: 0.2774166762828827
Validation loss: 1.4743931806215675

Epoch: 6| Step: 9
Training loss: 0.5124874114990234
Validation loss: 1.5148589450825927

Epoch: 6| Step: 10
Training loss: 0.18379852175712585
Validation loss: 1.497000568656511

Epoch: 6| Step: 11
Training loss: 0.4736846089363098
Validation loss: 1.4740626440253308

Epoch: 6| Step: 12
Training loss: 0.21093593537807465
Validation loss: 1.4804835447701075

Epoch: 6| Step: 13
Training loss: 0.20400263369083405
Validation loss: 1.4770915110905964

Epoch: 279| Step: 0
Training loss: 0.38883453607559204
Validation loss: 1.4573130787059825

Epoch: 6| Step: 1
Training loss: 0.20874184370040894
Validation loss: 1.4679383872657694

Epoch: 6| Step: 2
Training loss: 0.24710921943187714
Validation loss: 1.4777724537798154

Epoch: 6| Step: 3
Training loss: 0.36098796129226685
Validation loss: 1.4678206482241232

Epoch: 6| Step: 4
Training loss: 0.45224636793136597
Validation loss: 1.4695645686118834

Epoch: 6| Step: 5
Training loss: 0.23147444427013397
Validation loss: 1.4517142875220186

Epoch: 6| Step: 6
Training loss: 0.37792903184890747
Validation loss: 1.4257683984694942

Epoch: 6| Step: 7
Training loss: 0.19018900394439697
Validation loss: 1.4227315187454224

Epoch: 6| Step: 8
Training loss: 0.3965911865234375
Validation loss: 1.4140340333343835

Epoch: 6| Step: 9
Training loss: 0.17818832397460938
Validation loss: 1.4376038453912223

Epoch: 6| Step: 10
Training loss: 0.13354909420013428
Validation loss: 1.408079816449073

Epoch: 6| Step: 11
Training loss: 0.23765119910240173
Validation loss: 1.4116347361636419

Epoch: 6| Step: 12
Training loss: 0.22777128219604492
Validation loss: 1.4287864213348718

Epoch: 6| Step: 13
Training loss: 0.3898337185382843
Validation loss: 1.43532738249789

Epoch: 280| Step: 0
Training loss: 0.2207186371088028
Validation loss: 1.4554614469569216

Epoch: 6| Step: 1
Training loss: 0.19828398525714874
Validation loss: 1.497117603337893

Epoch: 6| Step: 2
Training loss: 0.25479447841644287
Validation loss: 1.5041290636985534

Epoch: 6| Step: 3
Training loss: 0.2833976149559021
Validation loss: 1.5190114974975586

Epoch: 6| Step: 4
Training loss: 0.30731046199798584
Validation loss: 1.5291191813766316

Epoch: 6| Step: 5
Training loss: 0.27694910764694214
Validation loss: 1.512532744356381

Epoch: 6| Step: 6
Training loss: 0.4746354818344116
Validation loss: 1.480521334114895

Epoch: 6| Step: 7
Training loss: 0.331520140171051
Validation loss: 1.512650974335209

Epoch: 6| Step: 8
Training loss: 0.21329492330551147
Validation loss: 1.4999455534001833

Epoch: 6| Step: 9
Training loss: 0.2580746114253998
Validation loss: 1.5052511551046883

Epoch: 6| Step: 10
Training loss: 0.1432940810918808
Validation loss: 1.491564852896557

Epoch: 6| Step: 11
Training loss: 0.23886525630950928
Validation loss: 1.4763999837701038

Epoch: 6| Step: 12
Training loss: 0.2679673433303833
Validation loss: 1.463182944123463

Epoch: 6| Step: 13
Training loss: 0.1877714991569519
Validation loss: 1.4438683050934986

Epoch: 281| Step: 0
Training loss: 0.3311576247215271
Validation loss: 1.4294492185756724

Epoch: 6| Step: 1
Training loss: 0.13232959806919098
Validation loss: 1.4320721305826658

Epoch: 6| Step: 2
Training loss: 0.3813103437423706
Validation loss: 1.4331760919222267

Epoch: 6| Step: 3
Training loss: 0.30473148822784424
Validation loss: 1.416823394836918

Epoch: 6| Step: 4
Training loss: 0.348211407661438
Validation loss: 1.411465843518575

Epoch: 6| Step: 5
Training loss: 0.4945560395717621
Validation loss: 1.4153175847504729

Epoch: 6| Step: 6
Training loss: 0.38660159707069397
Validation loss: 1.4082581855917489

Epoch: 6| Step: 7
Training loss: 0.22978521883487701
Validation loss: 1.4259416223854147

Epoch: 6| Step: 8
Training loss: 0.1550249457359314
Validation loss: 1.412951059238885

Epoch: 6| Step: 9
Training loss: 0.16718974709510803
Validation loss: 1.4543499715866581

Epoch: 6| Step: 10
Training loss: 0.18249179422855377
Validation loss: 1.4354613058028682

Epoch: 6| Step: 11
Training loss: 0.1611137092113495
Validation loss: 1.4575258096059163

Epoch: 6| Step: 12
Training loss: 0.1695706844329834
Validation loss: 1.4749177245683567

Epoch: 6| Step: 13
Training loss: 0.2745296359062195
Validation loss: 1.506948588996805

Epoch: 282| Step: 0
Training loss: 0.2970064878463745
Validation loss: 1.5181996681356942

Epoch: 6| Step: 1
Training loss: 0.24186459183692932
Validation loss: 1.5491882190909436

Epoch: 6| Step: 2
Training loss: 0.3791591227054596
Validation loss: 1.515408923549037

Epoch: 6| Step: 3
Training loss: 0.384022057056427
Validation loss: 1.5026249295921736

Epoch: 6| Step: 4
Training loss: 0.15575741231441498
Validation loss: 1.4626100960598196

Epoch: 6| Step: 5
Training loss: 0.16239063441753387
Validation loss: 1.4487982578175043

Epoch: 6| Step: 6
Training loss: 0.21392060816287994
Validation loss: 1.4234683923823859

Epoch: 6| Step: 7
Training loss: 0.2429075688123703
Validation loss: 1.4333622699142785

Epoch: 6| Step: 8
Training loss: 0.28279030323028564
Validation loss: 1.431122051772251

Epoch: 6| Step: 9
Training loss: 0.17896535992622375
Validation loss: 1.412061677184156

Epoch: 6| Step: 10
Training loss: 0.34373074769973755
Validation loss: 1.4166546124283985

Epoch: 6| Step: 11
Training loss: 0.4053225517272949
Validation loss: 1.4510994957339378

Epoch: 6| Step: 12
Training loss: 0.23153063654899597
Validation loss: 1.4272901550416024

Epoch: 6| Step: 13
Training loss: 0.4150749444961548
Validation loss: 1.459934801183721

Epoch: 283| Step: 0
Training loss: 0.4247412383556366
Validation loss: 1.4589915980574906

Epoch: 6| Step: 1
Training loss: 0.14521944522857666
Validation loss: 1.4546112834766347

Epoch: 6| Step: 2
Training loss: 0.25652411580085754
Validation loss: 1.5040069901815025

Epoch: 6| Step: 3
Training loss: 0.20474077761173248
Validation loss: 1.5080505891512799

Epoch: 6| Step: 4
Training loss: 0.21518361568450928
Validation loss: 1.5181641399219472

Epoch: 6| Step: 5
Training loss: 0.20907250046730042
Validation loss: 1.5206055269446423

Epoch: 6| Step: 6
Training loss: 0.2119680494070053
Validation loss: 1.5324591949421873

Epoch: 6| Step: 7
Training loss: 0.4255140423774719
Validation loss: 1.5365789449343117

Epoch: 6| Step: 8
Training loss: 0.1740894615650177
Validation loss: 1.4828393343956239

Epoch: 6| Step: 9
Training loss: 0.20024943351745605
Validation loss: 1.4794971519900906

Epoch: 6| Step: 10
Training loss: 0.2004876434803009
Validation loss: 1.4604281276784918

Epoch: 6| Step: 11
Training loss: 0.22910843789577484
Validation loss: 1.4566917496342813

Epoch: 6| Step: 12
Training loss: 0.40887004137039185
Validation loss: 1.4629275696251982

Epoch: 6| Step: 13
Training loss: 0.507858395576477
Validation loss: 1.4817556758080759

Epoch: 284| Step: 0
Training loss: 0.20203232765197754
Validation loss: 1.4700575836243168

Epoch: 6| Step: 1
Training loss: 0.16799548268318176
Validation loss: 1.4478162462993334

Epoch: 6| Step: 2
Training loss: 0.256479948759079
Validation loss: 1.4912656379002396

Epoch: 6| Step: 3
Training loss: 0.11010520905256271
Validation loss: 1.4748747797422512

Epoch: 6| Step: 4
Training loss: 0.19603553414344788
Validation loss: 1.4718096692075011

Epoch: 6| Step: 5
Training loss: 0.3812050521373749
Validation loss: 1.4842980151535363

Epoch: 6| Step: 6
Training loss: 0.2663126289844513
Validation loss: 1.4670497704577703

Epoch: 6| Step: 7
Training loss: 0.33760833740234375
Validation loss: 1.4547513582373177

Epoch: 6| Step: 8
Training loss: 0.37138161063194275
Validation loss: 1.465376091259782

Epoch: 6| Step: 9
Training loss: 0.1935848593711853
Validation loss: 1.4543908167910833

Epoch: 6| Step: 10
Training loss: 0.2982828617095947
Validation loss: 1.4586500185792164

Epoch: 6| Step: 11
Training loss: 0.45173272490501404
Validation loss: 1.473234131772031

Epoch: 6| Step: 12
Training loss: 0.15198490023612976
Validation loss: 1.450083182704064

Epoch: 6| Step: 13
Training loss: 0.2514711022377014
Validation loss: 1.4638118513168827

Epoch: 285| Step: 0
Training loss: 0.20659655332565308
Validation loss: 1.4402887718651884

Epoch: 6| Step: 1
Training loss: 0.19441434741020203
Validation loss: 1.444474361917024

Epoch: 6| Step: 2
Training loss: 0.40296995639801025
Validation loss: 1.4417323681616014

Epoch: 6| Step: 3
Training loss: 0.1666027158498764
Validation loss: 1.4294484930653726

Epoch: 6| Step: 4
Training loss: 0.22316625714302063
Validation loss: 1.4545567138220674

Epoch: 6| Step: 5
Training loss: 0.273145854473114
Validation loss: 1.4347150236047723

Epoch: 6| Step: 6
Training loss: 0.16453784704208374
Validation loss: 1.4411267042160034

Epoch: 6| Step: 7
Training loss: 0.3565356433391571
Validation loss: 1.4414367034871092

Epoch: 6| Step: 8
Training loss: 0.22147801518440247
Validation loss: 1.4513727170164867

Epoch: 6| Step: 9
Training loss: 0.2239876687526703
Validation loss: 1.4465188883966016

Epoch: 6| Step: 10
Training loss: 0.1403319090604782
Validation loss: 1.499740864640923

Epoch: 6| Step: 11
Training loss: 0.2759529948234558
Validation loss: 1.4849146937811246

Epoch: 6| Step: 12
Training loss: 0.2716546654701233
Validation loss: 1.4999582254758446

Epoch: 6| Step: 13
Training loss: 0.24571572244167328
Validation loss: 1.4845075530390586

Epoch: 286| Step: 0
Training loss: 0.14752086997032166
Validation loss: 1.5097199543829887

Epoch: 6| Step: 1
Training loss: 0.18234750628471375
Validation loss: 1.497667080612593

Epoch: 6| Step: 2
Training loss: 0.2554529905319214
Validation loss: 1.4993723041267806

Epoch: 6| Step: 3
Training loss: 0.18454931676387787
Validation loss: 1.4890525943489485

Epoch: 6| Step: 4
Training loss: 0.1614992469549179
Validation loss: 1.4986923625392299

Epoch: 6| Step: 5
Training loss: 0.27275550365448
Validation loss: 1.4642145890061573

Epoch: 6| Step: 6
Training loss: 0.3873750567436218
Validation loss: 1.4727779280754827

Epoch: 6| Step: 7
Training loss: 0.37032389640808105
Validation loss: 1.4604224658781482

Epoch: 6| Step: 8
Training loss: 0.18125112354755402
Validation loss: 1.4551520783414122

Epoch: 6| Step: 9
Training loss: 0.2858676314353943
Validation loss: 1.448171628418789

Epoch: 6| Step: 10
Training loss: 0.2543012797832489
Validation loss: 1.449898007095501

Epoch: 6| Step: 11
Training loss: 0.2300986498594284
Validation loss: 1.449527004072743

Epoch: 6| Step: 12
Training loss: 0.1922082006931305
Validation loss: 1.4700424055899344

Epoch: 6| Step: 13
Training loss: 0.25166451930999756
Validation loss: 1.4621402807133173

Epoch: 287| Step: 0
Training loss: 0.24114234745502472
Validation loss: 1.4836276718365249

Epoch: 6| Step: 1
Training loss: 0.27498355507850647
Validation loss: 1.4601677476718862

Epoch: 6| Step: 2
Training loss: 0.27401846647262573
Validation loss: 1.455904790150222

Epoch: 6| Step: 3
Training loss: 0.42637908458709717
Validation loss: 1.4635837065276278

Epoch: 6| Step: 4
Training loss: 0.16695000231266022
Validation loss: 1.4832136246465868

Epoch: 6| Step: 5
Training loss: 0.12149456143379211
Validation loss: 1.4794319252814017

Epoch: 6| Step: 6
Training loss: 0.16151010990142822
Validation loss: 1.472010988061146

Epoch: 6| Step: 7
Training loss: 0.19834186136722565
Validation loss: 1.4723526406031784

Epoch: 6| Step: 8
Training loss: 0.3122800886631012
Validation loss: 1.4631053504123483

Epoch: 6| Step: 9
Training loss: 0.171208918094635
Validation loss: 1.4597358549794843

Epoch: 6| Step: 10
Training loss: 0.2576965093612671
Validation loss: 1.4716186946438206

Epoch: 6| Step: 11
Training loss: 0.14924423396587372
Validation loss: 1.4480859951306415

Epoch: 6| Step: 12
Training loss: 0.33239486813545227
Validation loss: 1.4521157549273582

Epoch: 6| Step: 13
Training loss: 0.1384190320968628
Validation loss: 1.480015585499425

Epoch: 288| Step: 0
Training loss: 0.2038136124610901
Validation loss: 1.4626638940585557

Epoch: 6| Step: 1
Training loss: 0.2543964385986328
Validation loss: 1.454443254778462

Epoch: 6| Step: 2
Training loss: 0.15653574466705322
Validation loss: 1.4743889365144955

Epoch: 6| Step: 3
Training loss: 0.2758353352546692
Validation loss: 1.4958441706113919

Epoch: 6| Step: 4
Training loss: 0.27937185764312744
Validation loss: 1.4903925080453195

Epoch: 6| Step: 5
Training loss: 0.1280764490365982
Validation loss: 1.480882393416538

Epoch: 6| Step: 6
Training loss: 0.21259954571723938
Validation loss: 1.4584368172512259

Epoch: 6| Step: 7
Training loss: 0.222639262676239
Validation loss: 1.4453768704527168

Epoch: 6| Step: 8
Training loss: 0.3718913197517395
Validation loss: 1.461458908614292

Epoch: 6| Step: 9
Training loss: 0.24458599090576172
Validation loss: 1.4511006109176143

Epoch: 6| Step: 10
Training loss: 0.34830164909362793
Validation loss: 1.4319037442566247

Epoch: 6| Step: 11
Training loss: 0.13933929800987244
Validation loss: 1.43576362440663

Epoch: 6| Step: 12
Training loss: 0.2910824418067932
Validation loss: 1.4495267752678163

Epoch: 6| Step: 13
Training loss: 0.1297537088394165
Validation loss: 1.4337709385861632

Epoch: 289| Step: 0
Training loss: 0.28892403841018677
Validation loss: 1.434654410167407

Epoch: 6| Step: 1
Training loss: 0.31414318084716797
Validation loss: 1.4423769122810775

Epoch: 6| Step: 2
Training loss: 0.2814437747001648
Validation loss: 1.4305378877988426

Epoch: 6| Step: 3
Training loss: 0.20289380848407745
Validation loss: 1.4374408388650546

Epoch: 6| Step: 4
Training loss: 0.2315511256456375
Validation loss: 1.4476778904596965

Epoch: 6| Step: 5
Training loss: 0.25127047300338745
Validation loss: 1.4441085451392717

Epoch: 6| Step: 6
Training loss: 0.21361392736434937
Validation loss: 1.459554700441258

Epoch: 6| Step: 7
Training loss: 0.11575740575790405
Validation loss: 1.4498119713157736

Epoch: 6| Step: 8
Training loss: 0.3282397389411926
Validation loss: 1.4580434663321382

Epoch: 6| Step: 9
Training loss: 0.2460031509399414
Validation loss: 1.4483442575700822

Epoch: 6| Step: 10
Training loss: 0.14792364835739136
Validation loss: 1.4513270226857995

Epoch: 6| Step: 11
Training loss: 0.2447071671485901
Validation loss: 1.4288743054994972

Epoch: 6| Step: 12
Training loss: 0.2714465856552124
Validation loss: 1.446057491405036

Epoch: 6| Step: 13
Training loss: 0.3215344548225403
Validation loss: 1.4446858436830583

Epoch: 290| Step: 0
Training loss: 0.24537622928619385
Validation loss: 1.4354525701974028

Epoch: 6| Step: 1
Training loss: 0.17823350429534912
Validation loss: 1.4386055725877003

Epoch: 6| Step: 2
Training loss: 0.22089959681034088
Validation loss: 1.4514712197806245

Epoch: 6| Step: 3
Training loss: 0.19109345972537994
Validation loss: 1.4492364968022993

Epoch: 6| Step: 4
Training loss: 0.22126537561416626
Validation loss: 1.444618526325431

Epoch: 6| Step: 5
Training loss: 0.2947801947593689
Validation loss: 1.4496238052204091

Epoch: 6| Step: 6
Training loss: 0.14511583745479584
Validation loss: 1.4529012672362789

Epoch: 6| Step: 7
Training loss: 0.1315292865037918
Validation loss: 1.4598313749477427

Epoch: 6| Step: 8
Training loss: 0.13135500252246857
Validation loss: 1.435400353964939

Epoch: 6| Step: 9
Training loss: 0.14007434248924255
Validation loss: 1.4511263819151028

Epoch: 6| Step: 10
Training loss: 0.25752174854278564
Validation loss: 1.4477813795048704

Epoch: 6| Step: 11
Training loss: 0.18361534178256989
Validation loss: 1.4663623840578142

Epoch: 6| Step: 12
Training loss: 0.1513669192790985
Validation loss: 1.4501780989349529

Epoch: 6| Step: 13
Training loss: 0.28543418645858765
Validation loss: 1.4550982380426059

Epoch: 291| Step: 0
Training loss: 0.26437950134277344
Validation loss: 1.4802969668501167

Epoch: 6| Step: 1
Training loss: 0.11504662036895752
Validation loss: 1.4495600167141165

Epoch: 6| Step: 2
Training loss: 0.3465993106365204
Validation loss: 1.447017841441657

Epoch: 6| Step: 3
Training loss: 0.1917358934879303
Validation loss: 1.4024338683774393

Epoch: 6| Step: 4
Training loss: 0.2177220582962036
Validation loss: 1.4255150800110192

Epoch: 6| Step: 5
Training loss: 0.16484075784683228
Validation loss: 1.4436953651007784

Epoch: 6| Step: 6
Training loss: 0.079845130443573
Validation loss: 1.412809366820961

Epoch: 6| Step: 7
Training loss: 0.1960260272026062
Validation loss: 1.3968421233597623

Epoch: 6| Step: 8
Training loss: 0.47027716040611267
Validation loss: 1.4175498934202297

Epoch: 6| Step: 9
Training loss: 0.20610328018665314
Validation loss: 1.4176029902632519

Epoch: 6| Step: 10
Training loss: 0.10429954528808594
Validation loss: 1.43463215520305

Epoch: 6| Step: 11
Training loss: 0.11371240019798279
Validation loss: 1.4388196852899366

Epoch: 6| Step: 12
Training loss: 0.21691623330116272
Validation loss: 1.4666856693965133

Epoch: 6| Step: 13
Training loss: 0.2268086075782776
Validation loss: 1.4218748743816088

Epoch: 292| Step: 0
Training loss: 0.17594768106937408
Validation loss: 1.4552942104237054

Epoch: 6| Step: 1
Training loss: 0.17924942076206207
Validation loss: 1.4415584956446001

Epoch: 6| Step: 2
Training loss: 0.3265339732170105
Validation loss: 1.4562300841013591

Epoch: 6| Step: 3
Training loss: 0.18491247296333313
Validation loss: 1.495459536711375

Epoch: 6| Step: 4
Training loss: 0.2280818223953247
Validation loss: 1.4900480752350183

Epoch: 6| Step: 5
Training loss: 0.17086161673069
Validation loss: 1.4943666535039102

Epoch: 6| Step: 6
Training loss: 0.20917059481143951
Validation loss: 1.4787835587737381

Epoch: 6| Step: 7
Training loss: 0.2687789797782898
Validation loss: 1.4745664955467306

Epoch: 6| Step: 8
Training loss: 0.20211493968963623
Validation loss: 1.4769036949321788

Epoch: 6| Step: 9
Training loss: 0.13392069935798645
Validation loss: 1.467159048203499

Epoch: 6| Step: 10
Training loss: 0.1600187122821808
Validation loss: 1.4702002168983541

Epoch: 6| Step: 11
Training loss: 0.291686475276947
Validation loss: 1.447827519909028

Epoch: 6| Step: 12
Training loss: 0.1376594603061676
Validation loss: 1.4634563538335985

Epoch: 6| Step: 13
Training loss: 0.13338197767734528
Validation loss: 1.4426402955926874

Epoch: 293| Step: 0
Training loss: 0.2828415036201477
Validation loss: 1.466429619378941

Epoch: 6| Step: 1
Training loss: 0.14562363922595978
Validation loss: 1.4735219094061083

Epoch: 6| Step: 2
Training loss: 0.19081033766269684
Validation loss: 1.4567478331186439

Epoch: 6| Step: 3
Training loss: 0.2749309241771698
Validation loss: 1.471933582777618

Epoch: 6| Step: 4
Training loss: 0.25460711121559143
Validation loss: 1.4635418679124566

Epoch: 6| Step: 5
Training loss: 0.22771896421909332
Validation loss: 1.4585712430297688

Epoch: 6| Step: 6
Training loss: 0.25392621755599976
Validation loss: 1.4334773453333045

Epoch: 6| Step: 7
Training loss: 0.19001510739326477
Validation loss: 1.4383037859393704

Epoch: 6| Step: 8
Training loss: 0.19316112995147705
Validation loss: 1.448446516067751

Epoch: 6| Step: 9
Training loss: 0.09403391182422638
Validation loss: 1.4552356158533404

Epoch: 6| Step: 10
Training loss: 0.20416049659252167
Validation loss: 1.4630798011697748

Epoch: 6| Step: 11
Training loss: 0.1397918164730072
Validation loss: 1.4742567193123601

Epoch: 6| Step: 12
Training loss: 0.27058687806129456
Validation loss: 1.4485368606864766

Epoch: 6| Step: 13
Training loss: 0.19361726939678192
Validation loss: 1.4721394072296798

Epoch: 294| Step: 0
Training loss: 0.26013562083244324
Validation loss: 1.4478215120171989

Epoch: 6| Step: 1
Training loss: 0.12790018320083618
Validation loss: 1.4733353814771097

Epoch: 6| Step: 2
Training loss: 0.26058095693588257
Validation loss: 1.4547917586500927

Epoch: 6| Step: 3
Training loss: 0.20404770970344543
Validation loss: 1.4565769344247796

Epoch: 6| Step: 4
Training loss: 0.14081327617168427
Validation loss: 1.4101741557480187

Epoch: 6| Step: 5
Training loss: 0.18338105082511902
Validation loss: 1.430191038116332

Epoch: 6| Step: 6
Training loss: 0.15142710506916046
Validation loss: 1.4201518822741765

Epoch: 6| Step: 7
Training loss: 0.2882693409919739
Validation loss: 1.4152865948215607

Epoch: 6| Step: 8
Training loss: 0.20398733019828796
Validation loss: 1.4258995953426565

Epoch: 6| Step: 9
Training loss: 0.15052300691604614
Validation loss: 1.465643262350431

Epoch: 6| Step: 10
Training loss: 0.1787562370300293
Validation loss: 1.4508730737111901

Epoch: 6| Step: 11
Training loss: 0.1314542591571808
Validation loss: 1.4705251301488569

Epoch: 6| Step: 12
Training loss: 0.21702039241790771
Validation loss: 1.4701025229628368

Epoch: 6| Step: 13
Training loss: 0.11614011228084564
Validation loss: 1.4748647174527567

Epoch: 295| Step: 0
Training loss: 0.24235275387763977
Validation loss: 1.4539212629359255

Epoch: 6| Step: 1
Training loss: 0.1351969838142395
Validation loss: 1.4528852983187603

Epoch: 6| Step: 2
Training loss: 0.3780285716056824
Validation loss: 1.463097131700926

Epoch: 6| Step: 3
Training loss: 0.11426331102848053
Validation loss: 1.4562720393621793

Epoch: 6| Step: 4
Training loss: 0.12418562918901443
Validation loss: 1.480542709750514

Epoch: 6| Step: 5
Training loss: 0.17776833474636078
Validation loss: 1.4800726149671821

Epoch: 6| Step: 6
Training loss: 0.1673010140657425
Validation loss: 1.4596847475215953

Epoch: 6| Step: 7
Training loss: 0.14299482107162476
Validation loss: 1.433724477726926

Epoch: 6| Step: 8
Training loss: 0.3455738425254822
Validation loss: 1.4507770999785392

Epoch: 6| Step: 9
Training loss: 0.35441893339157104
Validation loss: 1.4762938958342358

Epoch: 6| Step: 10
Training loss: 0.1859646439552307
Validation loss: 1.4494586529270295

Epoch: 6| Step: 11
Training loss: 0.16577476263046265
Validation loss: 1.4292459641733477

Epoch: 6| Step: 12
Training loss: 0.12026716768741608
Validation loss: 1.4278447986930929

Epoch: 6| Step: 13
Training loss: 0.18153204023838043
Validation loss: 1.4371996823177542

Epoch: 296| Step: 0
Training loss: 0.1676059067249298
Validation loss: 1.4441748203769806

Epoch: 6| Step: 1
Training loss: 0.22026440501213074
Validation loss: 1.470816009788103

Epoch: 6| Step: 2
Training loss: 0.2243204116821289
Validation loss: 1.4799403272649294

Epoch: 6| Step: 3
Training loss: 0.22801411151885986
Validation loss: 1.4835160022140832

Epoch: 6| Step: 4
Training loss: 0.12156377732753754
Validation loss: 1.4808508619185416

Epoch: 6| Step: 5
Training loss: 0.1381261944770813
Validation loss: 1.4872254530588787

Epoch: 6| Step: 6
Training loss: 0.22360923886299133
Validation loss: 1.4649614749416229

Epoch: 6| Step: 7
Training loss: 0.20115149021148682
Validation loss: 1.452243326812662

Epoch: 6| Step: 8
Training loss: 0.22558176517486572
Validation loss: 1.4662913071211947

Epoch: 6| Step: 9
Training loss: 0.15558627247810364
Validation loss: 1.4748561164384246

Epoch: 6| Step: 10
Training loss: 0.25570112466812134
Validation loss: 1.4551974214533323

Epoch: 6| Step: 11
Training loss: 0.29176706075668335
Validation loss: 1.4730558139021679

Epoch: 6| Step: 12
Training loss: 0.26236915588378906
Validation loss: 1.4654404860670849

Epoch: 6| Step: 13
Training loss: 0.27362000942230225
Validation loss: 1.4537356566357356

Epoch: 297| Step: 0
Training loss: 0.2087814211845398
Validation loss: 1.4620443024942953

Epoch: 6| Step: 1
Training loss: 0.16191676259040833
Validation loss: 1.4532505677592369

Epoch: 6| Step: 2
Training loss: 0.17718419432640076
Validation loss: 1.47667028955234

Epoch: 6| Step: 3
Training loss: 0.20623168349266052
Validation loss: 1.479797697836353

Epoch: 6| Step: 4
Training loss: 0.4046407639980316
Validation loss: 1.4495027360095774

Epoch: 6| Step: 5
Training loss: 0.16808640956878662
Validation loss: 1.4703476262348953

Epoch: 6| Step: 6
Training loss: 0.1766558438539505
Validation loss: 1.4543750580920969

Epoch: 6| Step: 7
Training loss: 0.18239936232566833
Validation loss: 1.457563046486147

Epoch: 6| Step: 8
Training loss: 0.24703416228294373
Validation loss: 1.4595524393102175

Epoch: 6| Step: 9
Training loss: 0.3331693708896637
Validation loss: 1.4166118867935673

Epoch: 6| Step: 10
Training loss: 0.13064590096473694
Validation loss: 1.4072242936780375

Epoch: 6| Step: 11
Training loss: 0.17172540724277496
Validation loss: 1.3887214019734373

Epoch: 6| Step: 12
Training loss: 0.19865621626377106
Validation loss: 1.4111183035758235

Epoch: 6| Step: 13
Training loss: 0.12615007162094116
Validation loss: 1.3963934208757134

Epoch: 298| Step: 0
Training loss: 0.15843218564987183
Validation loss: 1.4058192596640637

Epoch: 6| Step: 1
Training loss: 0.2794177532196045
Validation loss: 1.413209948488461

Epoch: 6| Step: 2
Training loss: 0.30122584104537964
Validation loss: 1.4042508653415147

Epoch: 6| Step: 3
Training loss: 0.33751481771469116
Validation loss: 1.4212203743637248

Epoch: 6| Step: 4
Training loss: 0.27699705958366394
Validation loss: 1.4195284728080995

Epoch: 6| Step: 5
Training loss: 0.3280610144138336
Validation loss: 1.4342766872016333

Epoch: 6| Step: 6
Training loss: 0.3588860034942627
Validation loss: 1.419093575528873

Epoch: 6| Step: 7
Training loss: 0.09303021430969238
Validation loss: 1.441277132239393

Epoch: 6| Step: 8
Training loss: 0.17078183591365814
Validation loss: 1.4421560956585793

Epoch: 6| Step: 9
Training loss: 0.18054834008216858
Validation loss: 1.4606471382161623

Epoch: 6| Step: 10
Training loss: 0.1140194982290268
Validation loss: 1.4477600436056814

Epoch: 6| Step: 11
Training loss: 0.30067670345306396
Validation loss: 1.4710855663463633

Epoch: 6| Step: 12
Training loss: 0.14413394033908844
Validation loss: 1.478549785511468

Epoch: 6| Step: 13
Training loss: 0.15976311266422272
Validation loss: 1.4717195572391633

Epoch: 299| Step: 0
Training loss: 0.18767049908638
Validation loss: 1.469015815565663

Epoch: 6| Step: 1
Training loss: 0.1596277505159378
Validation loss: 1.4559860742220314

Epoch: 6| Step: 2
Training loss: 0.19404113292694092
Validation loss: 1.4563644611707298

Epoch: 6| Step: 3
Training loss: 0.2057909071445465
Validation loss: 1.459352449704242

Epoch: 6| Step: 4
Training loss: 0.17254161834716797
Validation loss: 1.4376641191462034

Epoch: 6| Step: 5
Training loss: 0.11812224239110947
Validation loss: 1.4582133978925726

Epoch: 6| Step: 6
Training loss: 0.19030168652534485
Validation loss: 1.4339496897112938

Epoch: 6| Step: 7
Training loss: 0.09457440674304962
Validation loss: 1.4244977671612975

Epoch: 6| Step: 8
Training loss: 0.1633845865726471
Validation loss: 1.442390380367156

Epoch: 6| Step: 9
Training loss: 0.35755082964897156
Validation loss: 1.4391137419208404

Epoch: 6| Step: 10
Training loss: 0.22457624971866608
Validation loss: 1.4260311280527422

Epoch: 6| Step: 11
Training loss: 0.36363452672958374
Validation loss: 1.439364098092561

Epoch: 6| Step: 12
Training loss: 0.1658293902873993
Validation loss: 1.4435659595715102

Epoch: 6| Step: 13
Training loss: 0.2848970592021942
Validation loss: 1.4777515677995579

Epoch: 300| Step: 0
Training loss: 0.1654062420129776
Validation loss: 1.4580139921557518

Epoch: 6| Step: 1
Training loss: 0.20343440771102905
Validation loss: 1.477774925129388

Epoch: 6| Step: 2
Training loss: 0.23611953854560852
Validation loss: 1.466141931472286

Epoch: 6| Step: 3
Training loss: 0.16740024089813232
Validation loss: 1.4885796090608001

Epoch: 6| Step: 4
Training loss: 0.26614266633987427
Validation loss: 1.4780509420620498

Epoch: 6| Step: 5
Training loss: 0.13224482536315918
Validation loss: 1.4467161887435502

Epoch: 6| Step: 6
Training loss: 0.22368788719177246
Validation loss: 1.4720395739360521

Epoch: 6| Step: 7
Training loss: 0.17347852885723114
Validation loss: 1.4450336015352638

Epoch: 6| Step: 8
Training loss: 0.3303055763244629
Validation loss: 1.4725203116734822

Epoch: 6| Step: 9
Training loss: 0.20858927071094513
Validation loss: 1.478402103147199

Epoch: 6| Step: 10
Training loss: 0.28007474541664124
Validation loss: 1.5001033262539936

Epoch: 6| Step: 11
Training loss: 0.2689325213432312
Validation loss: 1.4933569418486727

Epoch: 6| Step: 12
Training loss: 0.2497933804988861
Validation loss: 1.4953128906988329

Epoch: 6| Step: 13
Training loss: 0.14313265681266785
Validation loss: 1.4804869159575431

Epoch: 301| Step: 0
Training loss: 0.13218781352043152
Validation loss: 1.4892715215682983

Epoch: 6| Step: 1
Training loss: 0.19172024726867676
Validation loss: 1.4948456287384033

Epoch: 6| Step: 2
Training loss: 0.20944951474666595
Validation loss: 1.4729595427872033

Epoch: 6| Step: 3
Training loss: 0.1707383543252945
Validation loss: 1.5043999943681943

Epoch: 6| Step: 4
Training loss: 0.14316615462303162
Validation loss: 1.505506125829553

Epoch: 6| Step: 5
Training loss: 0.3152259290218353
Validation loss: 1.506218264179845

Epoch: 6| Step: 6
Training loss: 0.21466322243213654
Validation loss: 1.5027576082496232

Epoch: 6| Step: 7
Training loss: 0.2986704111099243
Validation loss: 1.4871893608441917

Epoch: 6| Step: 8
Training loss: 0.27379319071769714
Validation loss: 1.4704139194180887

Epoch: 6| Step: 9
Training loss: 0.2508161664009094
Validation loss: 1.4719362515275196

Epoch: 6| Step: 10
Training loss: 0.16060511767864227
Validation loss: 1.4680892934081375

Epoch: 6| Step: 11
Training loss: 0.1534007340669632
Validation loss: 1.4572811613800705

Epoch: 6| Step: 12
Training loss: 0.13772104680538177
Validation loss: 1.4252958810457619

Epoch: 6| Step: 13
Training loss: 0.14305029809474945
Validation loss: 1.4306557921953098

Epoch: 302| Step: 0
Training loss: 0.1912846863269806
Validation loss: 1.4299444049917243

Epoch: 6| Step: 1
Training loss: 0.24367724359035492
Validation loss: 1.4225248540601423

Epoch: 6| Step: 2
Training loss: 0.27012205123901367
Validation loss: 1.4172605071016537

Epoch: 6| Step: 3
Training loss: 0.15050578117370605
Validation loss: 1.428818033587548

Epoch: 6| Step: 4
Training loss: 0.13016554713249207
Validation loss: 1.4132858066148655

Epoch: 6| Step: 5
Training loss: 0.24192257225513458
Validation loss: 1.4372677098038376

Epoch: 6| Step: 6
Training loss: 0.12048862874507904
Validation loss: 1.4369904571963894

Epoch: 6| Step: 7
Training loss: 0.11405506730079651
Validation loss: 1.4546620589430614

Epoch: 6| Step: 8
Training loss: 0.1860424131155014
Validation loss: 1.437920617800887

Epoch: 6| Step: 9
Training loss: 0.17817218601703644
Validation loss: 1.4394599519750124

Epoch: 6| Step: 10
Training loss: 0.29015761613845825
Validation loss: 1.4415288631634047

Epoch: 6| Step: 11
Training loss: 0.14946205914020538
Validation loss: 1.4388767852578113

Epoch: 6| Step: 12
Training loss: 0.19623225927352905
Validation loss: 1.4442510271585116

Epoch: 6| Step: 13
Training loss: 0.1639764904975891
Validation loss: 1.4461943769967684

Epoch: 303| Step: 0
Training loss: 0.1825718879699707
Validation loss: 1.4311889345927904

Epoch: 6| Step: 1
Training loss: 0.2868940830230713
Validation loss: 1.442151951533492

Epoch: 6| Step: 2
Training loss: 0.3424893319606781
Validation loss: 1.4545553807289369

Epoch: 6| Step: 3
Training loss: 0.10159073770046234
Validation loss: 1.438447658733655

Epoch: 6| Step: 4
Training loss: 0.1756925880908966
Validation loss: 1.4426506142462454

Epoch: 6| Step: 5
Training loss: 0.11549919843673706
Validation loss: 1.4339496833021923

Epoch: 6| Step: 6
Training loss: 0.17073023319244385
Validation loss: 1.4589693648840791

Epoch: 6| Step: 7
Training loss: 0.13259440660476685
Validation loss: 1.444978824225805

Epoch: 6| Step: 8
Training loss: 0.14563187956809998
Validation loss: 1.4446709181672783

Epoch: 6| Step: 9
Training loss: 0.1459648162126541
Validation loss: 1.4425286259702457

Epoch: 6| Step: 10
Training loss: 0.10220471024513245
Validation loss: 1.4329107153800227

Epoch: 6| Step: 11
Training loss: 0.1793271154165268
Validation loss: 1.4452817811760852

Epoch: 6| Step: 12
Training loss: 0.1468060314655304
Validation loss: 1.443920986626738

Epoch: 6| Step: 13
Training loss: 0.2543685734272003
Validation loss: 1.448150860366001

Epoch: 304| Step: 0
Training loss: 0.11327949911355972
Validation loss: 1.4547650250055457

Epoch: 6| Step: 1
Training loss: 0.20482420921325684
Validation loss: 1.460080433917302

Epoch: 6| Step: 2
Training loss: 0.10616961866617203
Validation loss: 1.4783952236175537

Epoch: 6| Step: 3
Training loss: 0.23905573785305023
Validation loss: 1.4735771853436705

Epoch: 6| Step: 4
Training loss: 0.22512876987457275
Validation loss: 1.4627554352565477

Epoch: 6| Step: 5
Training loss: 0.15701588988304138
Validation loss: 1.4658267408288934

Epoch: 6| Step: 6
Training loss: 0.23640429973602295
Validation loss: 1.464789100872573

Epoch: 6| Step: 7
Training loss: 0.15807873010635376
Validation loss: 1.450643809892798

Epoch: 6| Step: 8
Training loss: 0.1484559178352356
Validation loss: 1.4462658487340456

Epoch: 6| Step: 9
Training loss: 0.17804309725761414
Validation loss: 1.4249776281336302

Epoch: 6| Step: 10
Training loss: 0.13622450828552246
Validation loss: 1.4333813177642

Epoch: 6| Step: 11
Training loss: 0.35636723041534424
Validation loss: 1.4119441291337371

Epoch: 6| Step: 12
Training loss: 0.15319690108299255
Validation loss: 1.4193366624975716

Epoch: 6| Step: 13
Training loss: 0.11082185059785843
Validation loss: 1.4204209376406927

Epoch: 305| Step: 0
Training loss: 0.24234504997730255
Validation loss: 1.4543270949394471

Epoch: 6| Step: 1
Training loss: 0.12637436389923096
Validation loss: 1.421999430143705

Epoch: 6| Step: 2
Training loss: 0.11885489523410797
Validation loss: 1.4371989619347356

Epoch: 6| Step: 3
Training loss: 0.11169645935297012
Validation loss: 1.4297139362622333

Epoch: 6| Step: 4
Training loss: 0.20353034138679504
Validation loss: 1.4566908036508868

Epoch: 6| Step: 5
Training loss: 0.20053568482398987
Validation loss: 1.4452127487428728

Epoch: 6| Step: 6
Training loss: 0.11416825652122498
Validation loss: 1.4532204161408127

Epoch: 6| Step: 7
Training loss: 0.19910137355327606
Validation loss: 1.470299950209997

Epoch: 6| Step: 8
Training loss: 0.18070128560066223
Validation loss: 1.4883597787990366

Epoch: 6| Step: 9
Training loss: 0.2501732110977173
Validation loss: 1.4849975923056244

Epoch: 6| Step: 10
Training loss: 0.24642309546470642
Validation loss: 1.4694094927080217

Epoch: 6| Step: 11
Training loss: 0.14681556820869446
Validation loss: 1.454707816082944

Epoch: 6| Step: 12
Training loss: 0.15400832891464233
Validation loss: 1.4446091985189786

Epoch: 6| Step: 13
Training loss: 0.06992055475711823
Validation loss: 1.4249623001262706

Epoch: 306| Step: 0
Training loss: 0.13810165226459503
Validation loss: 1.4179224657115115

Epoch: 6| Step: 1
Training loss: 0.1930038034915924
Validation loss: 1.3974916255602272

Epoch: 6| Step: 2
Training loss: 0.16237209737300873
Validation loss: 1.366488613749063

Epoch: 6| Step: 3
Training loss: 0.2448951154947281
Validation loss: 1.3749165208108964

Epoch: 6| Step: 4
Training loss: 0.12309478968381882
Validation loss: 1.364222990569248

Epoch: 6| Step: 5
Training loss: 0.17492415010929108
Validation loss: 1.3582431616321686

Epoch: 6| Step: 6
Training loss: 0.18834607303142548
Validation loss: 1.3560084386538434

Epoch: 6| Step: 7
Training loss: 0.1972886025905609
Validation loss: 1.3493633693264377

Epoch: 6| Step: 8
Training loss: 0.17459464073181152
Validation loss: 1.3655034316483365

Epoch: 6| Step: 9
Training loss: 0.26459425687789917
Validation loss: 1.3575627547438427

Epoch: 6| Step: 10
Training loss: 0.15145087242126465
Validation loss: 1.3730823929591844

Epoch: 6| Step: 11
Training loss: 0.11806488037109375
Validation loss: 1.3690546263930619

Epoch: 6| Step: 12
Training loss: 0.2893080413341522
Validation loss: 1.3702836331500803

Epoch: 6| Step: 13
Training loss: 0.2746056020259857
Validation loss: 1.3772931778302757

Epoch: 307| Step: 0
Training loss: 0.26297998428344727
Validation loss: 1.3846233813993392

Epoch: 6| Step: 1
Training loss: 0.17647233605384827
Validation loss: 1.3890746972894157

Epoch: 6| Step: 2
Training loss: 0.16331985592842102
Validation loss: 1.3907395460272347

Epoch: 6| Step: 3
Training loss: 0.27934229373931885
Validation loss: 1.3992152547323575

Epoch: 6| Step: 4
Training loss: 0.21313251554965973
Validation loss: 1.3952147358207292

Epoch: 6| Step: 5
Training loss: 0.1712970733642578
Validation loss: 1.3821148205828924

Epoch: 6| Step: 6
Training loss: 0.19720327854156494
Validation loss: 1.3818196994002148

Epoch: 6| Step: 7
Training loss: 0.1414860188961029
Validation loss: 1.380058838475135

Epoch: 6| Step: 8
Training loss: 0.3221301734447479
Validation loss: 1.3947324829716836

Epoch: 6| Step: 9
Training loss: 0.1850840151309967
Validation loss: 1.405158942745578

Epoch: 6| Step: 10
Training loss: 0.2150687277317047
Validation loss: 1.422885279501638

Epoch: 6| Step: 11
Training loss: 0.10647449642419815
Validation loss: 1.4115622184609855

Epoch: 6| Step: 12
Training loss: 0.10898850113153458
Validation loss: 1.4196242696495467

Epoch: 6| Step: 13
Training loss: 0.24442145228385925
Validation loss: 1.4039457139148508

Epoch: 308| Step: 0
Training loss: 0.250022828578949
Validation loss: 1.3896658535926574

Epoch: 6| Step: 1
Training loss: 0.1330277919769287
Validation loss: 1.410501866571365

Epoch: 6| Step: 2
Training loss: 0.21596315503120422
Validation loss: 1.4244159113976262

Epoch: 6| Step: 3
Training loss: 0.11005870252847672
Validation loss: 1.4089210417962843

Epoch: 6| Step: 4
Training loss: 0.13836626708507538
Validation loss: 1.4092409354384228

Epoch: 6| Step: 5
Training loss: 0.15790611505508423
Validation loss: 1.4064857408564577

Epoch: 6| Step: 6
Training loss: 0.2637951076030731
Validation loss: 1.400214623379451

Epoch: 6| Step: 7
Training loss: 0.23598454892635345
Validation loss: 1.4128141044288554

Epoch: 6| Step: 8
Training loss: 0.12368789315223694
Validation loss: 1.4152302126730643

Epoch: 6| Step: 9
Training loss: 0.12162818759679794
Validation loss: 1.430191409844224

Epoch: 6| Step: 10
Training loss: 0.2221662700176239
Validation loss: 1.4341367752321306

Epoch: 6| Step: 11
Training loss: 0.18703696131706238
Validation loss: 1.4067370199388074

Epoch: 6| Step: 12
Training loss: 0.15726566314697266
Validation loss: 1.4266245095960555

Epoch: 6| Step: 13
Training loss: 0.4194145202636719
Validation loss: 1.4234519440640685

Epoch: 309| Step: 0
Training loss: 0.11151475459337234
Validation loss: 1.4295650387323031

Epoch: 6| Step: 1
Training loss: 0.17045734822750092
Validation loss: 1.465948143313008

Epoch: 6| Step: 2
Training loss: 0.14832094311714172
Validation loss: 1.4595514164176038

Epoch: 6| Step: 3
Training loss: 0.2577413022518158
Validation loss: 1.4707220215951242

Epoch: 6| Step: 4
Training loss: 0.18520088493824005
Validation loss: 1.4617282754631453

Epoch: 6| Step: 5
Training loss: 0.2071095108985901
Validation loss: 1.4858564689595213

Epoch: 6| Step: 6
Training loss: 0.19390657544136047
Validation loss: 1.4702258327955842

Epoch: 6| Step: 7
Training loss: 0.15098083019256592
Validation loss: 1.4542024468862882

Epoch: 6| Step: 8
Training loss: 0.2554096579551697
Validation loss: 1.4556874869972147

Epoch: 6| Step: 9
Training loss: 0.126440167427063
Validation loss: 1.464704223858413

Epoch: 6| Step: 10
Training loss: 0.1544879823923111
Validation loss: 1.4473292084150418

Epoch: 6| Step: 11
Training loss: 0.07788486778736115
Validation loss: 1.4579002062479656

Epoch: 6| Step: 12
Training loss: 0.2224218100309372
Validation loss: 1.4347848514074921

Epoch: 6| Step: 13
Training loss: 0.26564231514930725
Validation loss: 1.4228510561809744

Epoch: 310| Step: 0
Training loss: 0.16397100687026978
Validation loss: 1.4406400547232678

Epoch: 6| Step: 1
Training loss: 0.159500390291214
Validation loss: 1.4222626058004235

Epoch: 6| Step: 2
Training loss: 0.2288695126771927
Validation loss: 1.4547276817342287

Epoch: 6| Step: 3
Training loss: 0.24768853187561035
Validation loss: 1.4232835115924958

Epoch: 6| Step: 4
Training loss: 0.18313637375831604
Validation loss: 1.4405010413098078

Epoch: 6| Step: 5
Training loss: 0.14356990158557892
Validation loss: 1.4239666916990792

Epoch: 6| Step: 6
Training loss: 0.11107910424470901
Validation loss: 1.4382943107235817

Epoch: 6| Step: 7
Training loss: 0.1406172215938568
Validation loss: 1.4130284440132879

Epoch: 6| Step: 8
Training loss: 0.10117600113153458
Validation loss: 1.4174281140809417

Epoch: 6| Step: 9
Training loss: 0.19244278967380524
Validation loss: 1.4500487004556963

Epoch: 6| Step: 10
Training loss: 0.205399289727211
Validation loss: 1.4290708880270682

Epoch: 6| Step: 11
Training loss: 0.2574115991592407
Validation loss: 1.4299554260828162

Epoch: 6| Step: 12
Training loss: 0.10342437028884888
Validation loss: 1.4475935825737574

Epoch: 6| Step: 13
Training loss: 0.07862301915884018
Validation loss: 1.4657516351310156

Epoch: 311| Step: 0
Training loss: 0.13725349307060242
Validation loss: 1.4621305722062305

Epoch: 6| Step: 1
Training loss: 0.16960567235946655
Validation loss: 1.4841266857680453

Epoch: 6| Step: 2
Training loss: 0.17235016822814941
Validation loss: 1.4635507534908991

Epoch: 6| Step: 3
Training loss: 0.14758369326591492
Validation loss: 1.449969837742467

Epoch: 6| Step: 4
Training loss: 0.11760146170854568
Validation loss: 1.4464618557242936

Epoch: 6| Step: 5
Training loss: 0.14267823100090027
Validation loss: 1.4430065180665703

Epoch: 6| Step: 6
Training loss: 0.21730878949165344
Validation loss: 1.4140292611173404

Epoch: 6| Step: 7
Training loss: 0.22758182883262634
Validation loss: 1.4132933296183103

Epoch: 6| Step: 8
Training loss: 0.21736028790473938
Validation loss: 1.4309755730372604

Epoch: 6| Step: 9
Training loss: 0.2872296869754791
Validation loss: 1.4255586888200493

Epoch: 6| Step: 10
Training loss: 0.10295719653367996
Validation loss: 1.3950846400312198

Epoch: 6| Step: 11
Training loss: 0.2430911809206009
Validation loss: 1.4116139072243885

Epoch: 6| Step: 12
Training loss: 0.1724928617477417
Validation loss: 1.4155692887562576

Epoch: 6| Step: 13
Training loss: 0.23457182943820953
Validation loss: 1.44165002786985

Epoch: 312| Step: 0
Training loss: 0.17453020811080933
Validation loss: 1.4353594139058103

Epoch: 6| Step: 1
Training loss: 0.14811129868030548
Validation loss: 1.421517320858535

Epoch: 6| Step: 2
Training loss: 0.35294899344444275
Validation loss: 1.450267889166391

Epoch: 6| Step: 3
Training loss: 0.1483825445175171
Validation loss: 1.4554608701377787

Epoch: 6| Step: 4
Training loss: 0.2499862015247345
Validation loss: 1.448844599467452

Epoch: 6| Step: 5
Training loss: 0.15013322234153748
Validation loss: 1.444344957669576

Epoch: 6| Step: 6
Training loss: 0.10138295590877533
Validation loss: 1.435874273700099

Epoch: 6| Step: 7
Training loss: 0.2128714919090271
Validation loss: 1.4129358722317604

Epoch: 6| Step: 8
Training loss: 0.08626388013362885
Validation loss: 1.410591536311693

Epoch: 6| Step: 9
Training loss: 0.19850070774555206
Validation loss: 1.4264963865280151

Epoch: 6| Step: 10
Training loss: 0.10912946611642838
Validation loss: 1.4081558963303924

Epoch: 6| Step: 11
Training loss: 0.11676925420761108
Validation loss: 1.4112094128003685

Epoch: 6| Step: 12
Training loss: 0.2003936618566513
Validation loss: 1.4123135202674455

Epoch: 6| Step: 13
Training loss: 0.24132166802883148
Validation loss: 1.4001892728190268

Epoch: 313| Step: 0
Training loss: 0.1270563304424286
Validation loss: 1.3874334532727477

Epoch: 6| Step: 1
Training loss: 0.09511780738830566
Validation loss: 1.403745473072093

Epoch: 6| Step: 2
Training loss: 0.15669995546340942
Validation loss: 1.3906877002408427

Epoch: 6| Step: 3
Training loss: 0.1461552083492279
Validation loss: 1.4042469762986707

Epoch: 6| Step: 4
Training loss: 0.12297606468200684
Validation loss: 1.4051454118503037

Epoch: 6| Step: 5
Training loss: 0.16447803378105164
Validation loss: 1.3817900714053903

Epoch: 6| Step: 6
Training loss: 0.14257031679153442
Validation loss: 1.4026262401252665

Epoch: 6| Step: 7
Training loss: 0.12367457151412964
Validation loss: 1.420146188428325

Epoch: 6| Step: 8
Training loss: 0.16109097003936768
Validation loss: 1.4127639724362282

Epoch: 6| Step: 9
Training loss: 0.3681914508342743
Validation loss: 1.3984029677606398

Epoch: 6| Step: 10
Training loss: 0.1437498778104782
Validation loss: 1.4009964081548876

Epoch: 6| Step: 11
Training loss: 0.1709158718585968
Validation loss: 1.4183099026321082

Epoch: 6| Step: 12
Training loss: 0.20613406598567963
Validation loss: 1.3984703517729236

Epoch: 6| Step: 13
Training loss: 0.16665925085544586
Validation loss: 1.401544596559258

Epoch: 314| Step: 0
Training loss: 0.0899430364370346
Validation loss: 1.3996699215263448

Epoch: 6| Step: 1
Training loss: 0.15331509709358215
Validation loss: 1.416230301703176

Epoch: 6| Step: 2
Training loss: 0.19736650586128235
Validation loss: 1.4124981690478582

Epoch: 6| Step: 3
Training loss: 0.27662813663482666
Validation loss: 1.4139822356162532

Epoch: 6| Step: 4
Training loss: 0.1222439780831337
Validation loss: 1.4162838356469267

Epoch: 6| Step: 5
Training loss: 0.19560016691684723
Validation loss: 1.4322635640380204

Epoch: 6| Step: 6
Training loss: 0.15306946635246277
Validation loss: 1.4453978987150295

Epoch: 6| Step: 7
Training loss: 0.1466389149427414
Validation loss: 1.4552605998131536

Epoch: 6| Step: 8
Training loss: 0.17494527995586395
Validation loss: 1.4478903252591369

Epoch: 6| Step: 9
Training loss: 0.1942535787820816
Validation loss: 1.4496050188618321

Epoch: 6| Step: 10
Training loss: 0.09174409508705139
Validation loss: 1.4316527407656434

Epoch: 6| Step: 11
Training loss: 0.13343225419521332
Validation loss: 1.419839641099335

Epoch: 6| Step: 12
Training loss: 0.18013843894004822
Validation loss: 1.4230423050542031

Epoch: 6| Step: 13
Training loss: 0.2753494679927826
Validation loss: 1.4434958158000823

Epoch: 315| Step: 0
Training loss: 0.1345355361700058
Validation loss: 1.4359363471308062

Epoch: 6| Step: 1
Training loss: 0.1119052916765213
Validation loss: 1.4343528510421835

Epoch: 6| Step: 2
Training loss: 0.1998431533575058
Validation loss: 1.4369827111562092

Epoch: 6| Step: 3
Training loss: 0.1322731375694275
Validation loss: 1.4413869034859441

Epoch: 6| Step: 4
Training loss: 0.14737573266029358
Validation loss: 1.461621319094012

Epoch: 6| Step: 5
Training loss: 0.17926278710365295
Validation loss: 1.4628190148261286

Epoch: 6| Step: 6
Training loss: 0.19631624221801758
Validation loss: 1.4917106013144217

Epoch: 6| Step: 7
Training loss: 0.15419317781925201
Validation loss: 1.5044618857804166

Epoch: 6| Step: 8
Training loss: 0.30727946758270264
Validation loss: 1.4714623221787073

Epoch: 6| Step: 9
Training loss: 0.15891112387180328
Validation loss: 1.4741287167354296

Epoch: 6| Step: 10
Training loss: 0.13219736516475677
Validation loss: 1.4644588142312982

Epoch: 6| Step: 11
Training loss: 0.16348618268966675
Validation loss: 1.4730524670693181

Epoch: 6| Step: 12
Training loss: 0.1888040006160736
Validation loss: 1.4792526031053195

Epoch: 6| Step: 13
Training loss: 0.3744882345199585
Validation loss: 1.483077520965248

Epoch: 316| Step: 0
Training loss: 0.26046115159988403
Validation loss: 1.4567250064624253

Epoch: 6| Step: 1
Training loss: 0.28995028138160706
Validation loss: 1.45672744576649

Epoch: 6| Step: 2
Training loss: 0.14052392542362213
Validation loss: 1.4497108280017812

Epoch: 6| Step: 3
Training loss: 0.09832540154457092
Validation loss: 1.4543920268294632

Epoch: 6| Step: 4
Training loss: 0.11834872514009476
Validation loss: 1.473074472078713

Epoch: 6| Step: 5
Training loss: 0.12994033098220825
Validation loss: 1.4469259092884679

Epoch: 6| Step: 6
Training loss: 0.23010879755020142
Validation loss: 1.4623257703678583

Epoch: 6| Step: 7
Training loss: 0.1651441603899002
Validation loss: 1.4447406991835563

Epoch: 6| Step: 8
Training loss: 0.25390559434890747
Validation loss: 1.4622561764973465

Epoch: 6| Step: 9
Training loss: 0.14524045586585999
Validation loss: 1.4620789802202614

Epoch: 6| Step: 10
Training loss: 0.060363031923770905
Validation loss: 1.4525689027642692

Epoch: 6| Step: 11
Training loss: 0.157368004322052
Validation loss: 1.4673644611912389

Epoch: 6| Step: 12
Training loss: 0.13382546603679657
Validation loss: 1.4535574836115683

Epoch: 6| Step: 13
Training loss: 0.09612879902124405
Validation loss: 1.4354408633324407

Epoch: 317| Step: 0
Training loss: 0.14193254709243774
Validation loss: 1.4443014334606867

Epoch: 6| Step: 1
Training loss: 0.11427146196365356
Validation loss: 1.430278653739601

Epoch: 6| Step: 2
Training loss: 0.3382275700569153
Validation loss: 1.430171283342505

Epoch: 6| Step: 3
Training loss: 0.1965026557445526
Validation loss: 1.4251347023953673

Epoch: 6| Step: 4
Training loss: 0.19431868195533752
Validation loss: 1.4344459451654905

Epoch: 6| Step: 5
Training loss: 0.0904717817902565
Validation loss: 1.4424950051051315

Epoch: 6| Step: 6
Training loss: 0.10219338536262512
Validation loss: 1.4185644388198853

Epoch: 6| Step: 7
Training loss: 0.08503567427396774
Validation loss: 1.3973011470610095

Epoch: 6| Step: 8
Training loss: 0.1697162240743637
Validation loss: 1.391320029894511

Epoch: 6| Step: 9
Training loss: 0.1475590169429779
Validation loss: 1.4188384932856406

Epoch: 6| Step: 10
Training loss: 0.17405429482460022
Validation loss: 1.4183210070415209

Epoch: 6| Step: 11
Training loss: 0.11093143373727798
Validation loss: 1.4189014037450154

Epoch: 6| Step: 12
Training loss: 0.16816410422325134
Validation loss: 1.4209072589874268

Epoch: 6| Step: 13
Training loss: 0.1770205944776535
Validation loss: 1.4420041679054179

Epoch: 318| Step: 0
Training loss: 0.16808557510375977
Validation loss: 1.4155070127979401

Epoch: 6| Step: 1
Training loss: 0.08109180629253387
Validation loss: 1.4209708065114997

Epoch: 6| Step: 2
Training loss: 0.14247502386569977
Validation loss: 1.4340633525643298

Epoch: 6| Step: 3
Training loss: 0.17601880431175232
Validation loss: 1.4456476652494041

Epoch: 6| Step: 4
Training loss: 0.20347601175308228
Validation loss: 1.4348612587939027

Epoch: 6| Step: 5
Training loss: 0.15223631262779236
Validation loss: 1.424291512017609

Epoch: 6| Step: 6
Training loss: 0.1343669891357422
Validation loss: 1.4356786845832743

Epoch: 6| Step: 7
Training loss: 0.11894610524177551
Validation loss: 1.415523257306827

Epoch: 6| Step: 8
Training loss: 0.0810452550649643
Validation loss: 1.4443375961754912

Epoch: 6| Step: 9
Training loss: 0.1293065845966339
Validation loss: 1.4450934702350247

Epoch: 6| Step: 10
Training loss: 0.15109404921531677
Validation loss: 1.4306034477808143

Epoch: 6| Step: 11
Training loss: 0.1892874836921692
Validation loss: 1.4218948976967924

Epoch: 6| Step: 12
Training loss: 0.22690719366073608
Validation loss: 1.404885377935184

Epoch: 6| Step: 13
Training loss: 0.2061091959476471
Validation loss: 1.4106948260338075

Epoch: 319| Step: 0
Training loss: 0.11983329057693481
Validation loss: 1.416691118671048

Epoch: 6| Step: 1
Training loss: 0.14045965671539307
Validation loss: 1.400988326277784

Epoch: 6| Step: 2
Training loss: 0.16601890325546265
Validation loss: 1.3664147533396238

Epoch: 6| Step: 3
Training loss: 0.2573174238204956
Validation loss: 1.3932065092107302

Epoch: 6| Step: 4
Training loss: 0.27842438220977783
Validation loss: 1.3874134754621854

Epoch: 6| Step: 5
Training loss: 0.13541428744792938
Validation loss: 1.3800560255204477

Epoch: 6| Step: 6
Training loss: 0.13653810322284698
Validation loss: 1.4112993081410725

Epoch: 6| Step: 7
Training loss: 0.3007583022117615
Validation loss: 1.3966563324774466

Epoch: 6| Step: 8
Training loss: 0.12678588926792145
Validation loss: 1.4006514856892247

Epoch: 6| Step: 9
Training loss: 0.10857774317264557
Validation loss: 1.4022549954793786

Epoch: 6| Step: 10
Training loss: 0.14716389775276184
Validation loss: 1.4222060006151918

Epoch: 6| Step: 11
Training loss: 0.116299107670784
Validation loss: 1.4148836449910236

Epoch: 6| Step: 12
Training loss: 0.09697843343019485
Validation loss: 1.4399226057913996

Epoch: 6| Step: 13
Training loss: 0.2053891122341156
Validation loss: 1.4295612124986545

Epoch: 320| Step: 0
Training loss: 0.17628774046897888
Validation loss: 1.424714583222584

Epoch: 6| Step: 1
Training loss: 0.06498904526233673
Validation loss: 1.4401077314089703

Epoch: 6| Step: 2
Training loss: 0.11437271535396576
Validation loss: 1.451293847894156

Epoch: 6| Step: 3
Training loss: 0.1520499438047409
Validation loss: 1.4246706206311461

Epoch: 6| Step: 4
Training loss: 0.15479514002799988
Validation loss: 1.4206239664426414

Epoch: 6| Step: 5
Training loss: 0.2044113278388977
Validation loss: 1.4375498602467198

Epoch: 6| Step: 6
Training loss: 0.08614317327737808
Validation loss: 1.4389178035079793

Epoch: 6| Step: 7
Training loss: 0.16986165940761566
Validation loss: 1.4308207727247668

Epoch: 6| Step: 8
Training loss: 0.1805727779865265
Validation loss: 1.4485813430560532

Epoch: 6| Step: 9
Training loss: 0.11816857010126114
Validation loss: 1.4126962634824938

Epoch: 6| Step: 10
Training loss: 0.12089693546295166
Validation loss: 1.4129766187360209

Epoch: 6| Step: 11
Training loss: 0.1514086127281189
Validation loss: 1.4274847417749383

Epoch: 6| Step: 12
Training loss: 0.14242106676101685
Validation loss: 1.4132587954562197

Epoch: 6| Step: 13
Training loss: 0.10281206667423248
Validation loss: 1.4136227817945584

Epoch: 321| Step: 0
Training loss: 0.13183292746543884
Validation loss: 1.3958746758840417

Epoch: 6| Step: 1
Training loss: 0.15925663709640503
Validation loss: 1.4165575683757823

Epoch: 6| Step: 2
Training loss: 0.13542473316192627
Validation loss: 1.4091937388143232

Epoch: 6| Step: 3
Training loss: 0.11754997074604034
Validation loss: 1.3979573083180252

Epoch: 6| Step: 4
Training loss: 0.08010921627283096
Validation loss: 1.4130611829860236

Epoch: 6| Step: 5
Training loss: 0.12316138297319412
Validation loss: 1.4106178975874377

Epoch: 6| Step: 6
Training loss: 0.13754765689373016
Validation loss: 1.4020570990859822

Epoch: 6| Step: 7
Training loss: 0.17498666048049927
Validation loss: 1.4245114993023615

Epoch: 6| Step: 8
Training loss: 0.09963834285736084
Validation loss: 1.4067454363710137

Epoch: 6| Step: 9
Training loss: 0.15755310654640198
Validation loss: 1.406239568546254

Epoch: 6| Step: 10
Training loss: 0.14288410544395447
Validation loss: 1.3918671447743651

Epoch: 6| Step: 11
Training loss: 0.09710583835840225
Validation loss: 1.3903419253646687

Epoch: 6| Step: 12
Training loss: 0.19000117480754852
Validation loss: 1.4037060096699705

Epoch: 6| Step: 13
Training loss: 0.09940363466739655
Validation loss: 1.3884932892296904

Epoch: 322| Step: 0
Training loss: 0.09306985139846802
Validation loss: 1.3773884696345176

Epoch: 6| Step: 1
Training loss: 0.13369064033031464
Validation loss: 1.4205047648440126

Epoch: 6| Step: 2
Training loss: 0.14250251650810242
Validation loss: 1.3721672591342722

Epoch: 6| Step: 3
Training loss: 0.17624369263648987
Validation loss: 1.405272009552166

Epoch: 6| Step: 4
Training loss: 0.1322009265422821
Validation loss: 1.393942645801011

Epoch: 6| Step: 5
Training loss: 0.13049468398094177
Validation loss: 1.3975398143132527

Epoch: 6| Step: 6
Training loss: 0.11476440727710724
Validation loss: 1.392505907243298

Epoch: 6| Step: 7
Training loss: 0.0924944058060646
Validation loss: 1.4182422731512336

Epoch: 6| Step: 8
Training loss: 0.10726988315582275
Validation loss: 1.3944586246244368

Epoch: 6| Step: 9
Training loss: 0.1526559442281723
Validation loss: 1.425202629899466

Epoch: 6| Step: 10
Training loss: 0.15606600046157837
Validation loss: 1.4260188687232234

Epoch: 6| Step: 11
Training loss: 0.12422849237918854
Validation loss: 1.4524371233037723

Epoch: 6| Step: 12
Training loss: 0.13575392961502075
Validation loss: 1.426814749676694

Epoch: 6| Step: 13
Training loss: 0.3709448575973511
Validation loss: 1.45490296617631

Epoch: 323| Step: 0
Training loss: 0.11402253806591034
Validation loss: 1.4616634576551375

Epoch: 6| Step: 1
Training loss: 0.11375068128108978
Validation loss: 1.4614671532825758

Epoch: 6| Step: 2
Training loss: 0.1814691424369812
Validation loss: 1.4463787360857892

Epoch: 6| Step: 3
Training loss: 0.1707582175731659
Validation loss: 1.4785959541156728

Epoch: 6| Step: 4
Training loss: 0.08484571427106857
Validation loss: 1.4790593244696175

Epoch: 6| Step: 5
Training loss: 0.18765078485012054
Validation loss: 1.4743026071979153

Epoch: 6| Step: 6
Training loss: 0.15500210225582123
Validation loss: 1.4732890846908733

Epoch: 6| Step: 7
Training loss: 0.08368859440088272
Validation loss: 1.4998020215701031

Epoch: 6| Step: 8
Training loss: 0.342201292514801
Validation loss: 1.4761892672507995

Epoch: 6| Step: 9
Training loss: 0.20729652047157288
Validation loss: 1.4655135959707282

Epoch: 6| Step: 10
Training loss: 0.19679787755012512
Validation loss: 1.4486757901407057

Epoch: 6| Step: 11
Training loss: 0.09596097469329834
Validation loss: 1.4321565538324335

Epoch: 6| Step: 12
Training loss: 0.113507479429245
Validation loss: 1.429029680067493

Epoch: 6| Step: 13
Training loss: 0.12712572515010834
Validation loss: 1.4114558337837138

Epoch: 324| Step: 0
Training loss: 0.08194692432880402
Validation loss: 1.404361355048354

Epoch: 6| Step: 1
Training loss: 0.09909262508153915
Validation loss: 1.4216574815011793

Epoch: 6| Step: 2
Training loss: 0.1460587978363037
Validation loss: 1.4168208183780793

Epoch: 6| Step: 3
Training loss: 0.2407899647951126
Validation loss: 1.3986190442116029

Epoch: 6| Step: 4
Training loss: 0.14060445129871368
Validation loss: 1.4197437711941299

Epoch: 6| Step: 5
Training loss: 0.16844502091407776
Validation loss: 1.4289842190281037

Epoch: 6| Step: 6
Training loss: 0.17571738362312317
Validation loss: 1.429553824086343

Epoch: 6| Step: 7
Training loss: 0.09219124913215637
Validation loss: 1.4182581504185994

Epoch: 6| Step: 8
Training loss: 0.17373442649841309
Validation loss: 1.4047551488363614

Epoch: 6| Step: 9
Training loss: 0.10491429269313812
Validation loss: 1.4180034501578218

Epoch: 6| Step: 10
Training loss: 0.10451154410839081
Validation loss: 1.3903468949820406

Epoch: 6| Step: 11
Training loss: 0.20926299691200256
Validation loss: 1.4247337836091236

Epoch: 6| Step: 12
Training loss: 0.21795383095741272
Validation loss: 1.4210588009126726

Epoch: 6| Step: 13
Training loss: 0.0796869695186615
Validation loss: 1.4222483211948025

Epoch: 325| Step: 0
Training loss: 0.20058654248714447
Validation loss: 1.4162227992088563

Epoch: 6| Step: 1
Training loss: 0.14748020470142365
Validation loss: 1.4382587978916783

Epoch: 6| Step: 2
Training loss: 0.11512696743011475
Validation loss: 1.4560710230181295

Epoch: 6| Step: 3
Training loss: 0.1150229275226593
Validation loss: 1.4533744563338578

Epoch: 6| Step: 4
Training loss: 0.10911348462104797
Validation loss: 1.4419782328349289

Epoch: 6| Step: 5
Training loss: 0.23570512235164642
Validation loss: 1.4467083356713737

Epoch: 6| Step: 6
Training loss: 0.10973489284515381
Validation loss: 1.4336175764760664

Epoch: 6| Step: 7
Training loss: 0.08441926538944244
Validation loss: 1.450239678864838

Epoch: 6| Step: 8
Training loss: 0.09330399334430695
Validation loss: 1.438887337202667

Epoch: 6| Step: 9
Training loss: 0.18945921957492828
Validation loss: 1.4343999041024076

Epoch: 6| Step: 10
Training loss: 0.13570049405097961
Validation loss: 1.4229381020351122

Epoch: 6| Step: 11
Training loss: 0.13942882418632507
Validation loss: 1.436897704678197

Epoch: 6| Step: 12
Training loss: 0.06951695680618286
Validation loss: 1.436464508374532

Epoch: 6| Step: 13
Training loss: 0.13379043340682983
Validation loss: 1.4063308418437999

Epoch: 326| Step: 0
Training loss: 0.07233971357345581
Validation loss: 1.3990881481478292

Epoch: 6| Step: 1
Training loss: 0.08564406633377075
Validation loss: 1.4031519300194197

Epoch: 6| Step: 2
Training loss: 0.09830763936042786
Validation loss: 1.4179644841019825

Epoch: 6| Step: 3
Training loss: 0.1850486695766449
Validation loss: 1.4254429526226495

Epoch: 6| Step: 4
Training loss: 0.1277446150779724
Validation loss: 1.420586375780003

Epoch: 6| Step: 5
Training loss: 0.13187822699546814
Validation loss: 1.4322514623724005

Epoch: 6| Step: 6
Training loss: 0.10723479092121124
Validation loss: 1.433766080487159

Epoch: 6| Step: 7
Training loss: 0.10009519755840302
Validation loss: 1.4184130680176519

Epoch: 6| Step: 8
Training loss: 0.14412929117679596
Validation loss: 1.4139303545798025

Epoch: 6| Step: 9
Training loss: 0.18936346471309662
Validation loss: 1.4092466254388132

Epoch: 6| Step: 10
Training loss: 0.16128787398338318
Validation loss: 1.407562037949921

Epoch: 6| Step: 11
Training loss: 0.11143164336681366
Validation loss: 1.42058386213036

Epoch: 6| Step: 12
Training loss: 0.1328071653842926
Validation loss: 1.38602517561246

Epoch: 6| Step: 13
Training loss: 0.20598812401294708
Validation loss: 1.408313871711813

Epoch: 327| Step: 0
Training loss: 0.1734934002161026
Validation loss: 1.4150404532750447

Epoch: 6| Step: 1
Training loss: 0.11107124388217926
Validation loss: 1.3987574615786154

Epoch: 6| Step: 2
Training loss: 0.1543044149875641
Validation loss: 1.3943889153900968

Epoch: 6| Step: 3
Training loss: 0.06282234936952591
Validation loss: 1.3963071364228443

Epoch: 6| Step: 4
Training loss: 0.13957622647285461
Validation loss: 1.3924834574422529

Epoch: 6| Step: 5
Training loss: 0.10384930670261383
Validation loss: 1.3743685804387575

Epoch: 6| Step: 6
Training loss: 0.17184913158416748
Validation loss: 1.3802907466888428

Epoch: 6| Step: 7
Training loss: 0.17304223775863647
Validation loss: 1.4053171962820075

Epoch: 6| Step: 8
Training loss: 0.13844546675682068
Validation loss: 1.3959627177125664

Epoch: 6| Step: 9
Training loss: 0.13022294640541077
Validation loss: 1.4091702366387973

Epoch: 6| Step: 10
Training loss: 0.1689792424440384
Validation loss: 1.3980294748019146

Epoch: 6| Step: 11
Training loss: 0.2133529633283615
Validation loss: 1.4173637987464986

Epoch: 6| Step: 12
Training loss: 0.1629398763179779
Validation loss: 1.44991768944648

Epoch: 6| Step: 13
Training loss: 0.123496413230896
Validation loss: 1.4333632223067745

Epoch: 328| Step: 0
Training loss: 0.18955376744270325
Validation loss: 1.4520393382477503

Epoch: 6| Step: 1
Training loss: 0.15026786923408508
Validation loss: 1.4300679724703553

Epoch: 6| Step: 2
Training loss: 0.11712181568145752
Validation loss: 1.442682175226109

Epoch: 6| Step: 3
Training loss: 0.1544606238603592
Validation loss: 1.4548084428233485

Epoch: 6| Step: 4
Training loss: 0.12353899329900742
Validation loss: 1.4455291314791607

Epoch: 6| Step: 5
Training loss: 0.15284568071365356
Validation loss: 1.4028423922036284

Epoch: 6| Step: 6
Training loss: 0.13529866933822632
Validation loss: 1.426337412608567

Epoch: 6| Step: 7
Training loss: 0.129904106259346
Validation loss: 1.4220366292102362

Epoch: 6| Step: 8
Training loss: 0.11701604723930359
Validation loss: 1.4384062700374152

Epoch: 6| Step: 9
Training loss: 0.20778775215148926
Validation loss: 1.402485600081823

Epoch: 6| Step: 10
Training loss: 0.18545570969581604
Validation loss: 1.4458219748671337

Epoch: 6| Step: 11
Training loss: 0.23818418383598328
Validation loss: 1.4454182232579877

Epoch: 6| Step: 12
Training loss: 0.11823593080043793
Validation loss: 1.4182640967830535

Epoch: 6| Step: 13
Training loss: 0.07174023985862732
Validation loss: 1.4183374310052523

Epoch: 329| Step: 0
Training loss: 0.09733806550502777
Validation loss: 1.3954819889478787

Epoch: 6| Step: 1
Training loss: 0.1508622169494629
Validation loss: 1.4319813700132473

Epoch: 6| Step: 2
Training loss: 0.17811229825019836
Validation loss: 1.4221657911936443

Epoch: 6| Step: 3
Training loss: 0.0729234591126442
Validation loss: 1.440168857574463

Epoch: 6| Step: 4
Training loss: 0.06437747180461884
Validation loss: 1.42943484744718

Epoch: 6| Step: 5
Training loss: 0.14425164461135864
Validation loss: 1.4515991723665627

Epoch: 6| Step: 6
Training loss: 0.12350787222385406
Validation loss: 1.4389937244435793

Epoch: 6| Step: 7
Training loss: 0.12610775232315063
Validation loss: 1.4315535240275885

Epoch: 6| Step: 8
Training loss: 0.22007697820663452
Validation loss: 1.4404142108014835

Epoch: 6| Step: 9
Training loss: 0.1608557403087616
Validation loss: 1.4646396662599297

Epoch: 6| Step: 10
Training loss: 0.1520826518535614
Validation loss: 1.4658377260290167

Epoch: 6| Step: 11
Training loss: 0.17040801048278809
Validation loss: 1.4577933434517152

Epoch: 6| Step: 12
Training loss: 0.1742335557937622
Validation loss: 1.4750135329461866

Epoch: 6| Step: 13
Training loss: 0.10477806627750397
Validation loss: 1.4467179980329288

Epoch: 330| Step: 0
Training loss: 0.17021241784095764
Validation loss: 1.45707687511239

Epoch: 6| Step: 1
Training loss: 0.20668265223503113
Validation loss: 1.4606203020259898

Epoch: 6| Step: 2
Training loss: 0.1744615137577057
Validation loss: 1.4587635173592517

Epoch: 6| Step: 3
Training loss: 0.12906087934970856
Validation loss: 1.4469603851277342

Epoch: 6| Step: 4
Training loss: 0.17374631762504578
Validation loss: 1.4493256358690159

Epoch: 6| Step: 5
Training loss: 0.10977392643690109
Validation loss: 1.4193118977290329

Epoch: 6| Step: 6
Training loss: 0.16230501234531403
Validation loss: 1.4627326432094778

Epoch: 6| Step: 7
Training loss: 0.10827933251857758
Validation loss: 1.4539521137873332

Epoch: 6| Step: 8
Training loss: 0.177231103181839
Validation loss: 1.4916465590077062

Epoch: 6| Step: 9
Training loss: 0.1507587730884552
Validation loss: 1.4859118589790918

Epoch: 6| Step: 10
Training loss: 0.1369679868221283
Validation loss: 1.467756148307554

Epoch: 6| Step: 11
Training loss: 0.17993837594985962
Validation loss: 1.4587137968309465

Epoch: 6| Step: 12
Training loss: 0.13444754481315613
Validation loss: 1.4332671947376703

Epoch: 6| Step: 13
Training loss: 0.16400779783725739
Validation loss: 1.4129489608990249

Epoch: 331| Step: 0
Training loss: 0.0864051878452301
Validation loss: 1.4104705766964984

Epoch: 6| Step: 1
Training loss: 0.10247860848903656
Validation loss: 1.417073662563037

Epoch: 6| Step: 2
Training loss: 0.1710645854473114
Validation loss: 1.4469802661608624

Epoch: 6| Step: 3
Training loss: 0.16802942752838135
Validation loss: 1.4266601954737017

Epoch: 6| Step: 4
Training loss: 0.19447322189807892
Validation loss: 1.4330292106956564

Epoch: 6| Step: 5
Training loss: 0.1344548463821411
Validation loss: 1.432203185173773

Epoch: 6| Step: 6
Training loss: 0.12752601504325867
Validation loss: 1.4332677613022506

Epoch: 6| Step: 7
Training loss: 0.13728442788124084
Validation loss: 1.446097013770893

Epoch: 6| Step: 8
Training loss: 0.17035168409347534
Validation loss: 1.413819238703738

Epoch: 6| Step: 9
Training loss: 0.12928913533687592
Validation loss: 1.4386331624882196

Epoch: 6| Step: 10
Training loss: 0.3162517845630646
Validation loss: 1.4290722621384488

Epoch: 6| Step: 11
Training loss: 0.17203542590141296
Validation loss: 1.4077419337405954

Epoch: 6| Step: 12
Training loss: 0.1251407414674759
Validation loss: 1.4217602463178738

Epoch: 6| Step: 13
Training loss: 0.18309378623962402
Validation loss: 1.4151792872336604

Epoch: 332| Step: 0
Training loss: 0.07532675564289093
Validation loss: 1.4229199168502644

Epoch: 6| Step: 1
Training loss: 0.10373968631029129
Validation loss: 1.394908102609778

Epoch: 6| Step: 2
Training loss: 0.15698450803756714
Validation loss: 1.4200736630347468

Epoch: 6| Step: 3
Training loss: 0.16597667336463928
Validation loss: 1.404999194606658

Epoch: 6| Step: 4
Training loss: 0.1406906247138977
Validation loss: 1.4028356075286865

Epoch: 6| Step: 5
Training loss: 0.15031570196151733
Validation loss: 1.3987751308307852

Epoch: 6| Step: 6
Training loss: 0.08351369202136993
Validation loss: 1.4028559628353323

Epoch: 6| Step: 7
Training loss: 0.1784166544675827
Validation loss: 1.3897611697514851

Epoch: 6| Step: 8
Training loss: 0.14463001489639282
Validation loss: 1.4121299712888655

Epoch: 6| Step: 9
Training loss: 0.12341831624507904
Validation loss: 1.4009427242381598

Epoch: 6| Step: 10
Training loss: 0.17140847444534302
Validation loss: 1.4334746836334147

Epoch: 6| Step: 11
Training loss: 0.20694205164909363
Validation loss: 1.4204160833871493

Epoch: 6| Step: 12
Training loss: 0.08102619647979736
Validation loss: 1.4393079203944052

Epoch: 6| Step: 13
Training loss: 0.09376451373100281
Validation loss: 1.4370712029036654

Epoch: 333| Step: 0
Training loss: 0.15729451179504395
Validation loss: 1.4560825619646298

Epoch: 6| Step: 1
Training loss: 0.15111055970191956
Validation loss: 1.4443495735045402

Epoch: 6| Step: 2
Training loss: 0.14167520403862
Validation loss: 1.4385484066060794

Epoch: 6| Step: 3
Training loss: 0.11661431938409805
Validation loss: 1.4192507190089072

Epoch: 6| Step: 4
Training loss: 0.08781927824020386
Validation loss: 1.4362736927565707

Epoch: 6| Step: 5
Training loss: 0.0724865049123764
Validation loss: 1.4491045885188605

Epoch: 6| Step: 6
Training loss: 0.13575904071331024
Validation loss: 1.4349784799801406

Epoch: 6| Step: 7
Training loss: 0.11388017982244492
Validation loss: 1.4107939235625728

Epoch: 6| Step: 8
Training loss: 0.12939870357513428
Validation loss: 1.391578778143852

Epoch: 6| Step: 9
Training loss: 0.17878548800945282
Validation loss: 1.4034015837536062

Epoch: 6| Step: 10
Training loss: 0.15705013275146484
Validation loss: 1.3905972947356522

Epoch: 6| Step: 11
Training loss: 0.17935267090797424
Validation loss: 1.3846646624226724

Epoch: 6| Step: 12
Training loss: 0.16595102846622467
Validation loss: 1.3552820618434618

Epoch: 6| Step: 13
Training loss: 0.24257948994636536
Validation loss: 1.3826219497188446

Epoch: 334| Step: 0
Training loss: 0.1165485754609108
Validation loss: 1.3807797662673458

Epoch: 6| Step: 1
Training loss: 0.08148893713951111
Validation loss: 1.3868355456218924

Epoch: 6| Step: 2
Training loss: 0.12948687374591827
Validation loss: 1.395295496909849

Epoch: 6| Step: 3
Training loss: 0.12972083687782288
Validation loss: 1.395004008405952

Epoch: 6| Step: 4
Training loss: 0.08541183173656464
Validation loss: 1.4166204839624383

Epoch: 6| Step: 5
Training loss: 0.2680205702781677
Validation loss: 1.4412636571033026

Epoch: 6| Step: 6
Training loss: 0.11992109566926956
Validation loss: 1.4273006480227235

Epoch: 6| Step: 7
Training loss: 0.17354992032051086
Validation loss: 1.423068009397035

Epoch: 6| Step: 8
Training loss: 0.10297973453998566
Validation loss: 1.4191648639658445

Epoch: 6| Step: 9
Training loss: 0.09089279919862747
Validation loss: 1.4129124636291175

Epoch: 6| Step: 10
Training loss: 0.3014836311340332
Validation loss: 1.4235924200345111

Epoch: 6| Step: 11
Training loss: 0.17012760043144226
Validation loss: 1.4387506874658729

Epoch: 6| Step: 12
Training loss: 0.1385786235332489
Validation loss: 1.4424139562473501

Epoch: 6| Step: 13
Training loss: 0.13428246974945068
Validation loss: 1.4243310510471303

Epoch: 335| Step: 0
Training loss: 0.08494959771633148
Validation loss: 1.4155552720510831

Epoch: 6| Step: 1
Training loss: 0.05812644958496094
Validation loss: 1.4261018973524853

Epoch: 6| Step: 2
Training loss: 0.1678912341594696
Validation loss: 1.3931660165068924

Epoch: 6| Step: 3
Training loss: 0.11801116168498993
Validation loss: 1.4258446424238143

Epoch: 6| Step: 4
Training loss: 0.12141857296228409
Validation loss: 1.4150735344938052

Epoch: 6| Step: 5
Training loss: 0.1666397750377655
Validation loss: 1.3975723610129407

Epoch: 6| Step: 6
Training loss: 0.12979882955551147
Validation loss: 1.3981062327661822

Epoch: 6| Step: 7
Training loss: 0.1597166359424591
Validation loss: 1.3902604938835226

Epoch: 6| Step: 8
Training loss: 0.21021917462348938
Validation loss: 1.3606147907113517

Epoch: 6| Step: 9
Training loss: 0.14197349548339844
Validation loss: 1.3722880604446575

Epoch: 6| Step: 10
Training loss: 0.16588985919952393
Validation loss: 1.3856323829261206

Epoch: 6| Step: 11
Training loss: 0.18743416666984558
Validation loss: 1.3738502481932282

Epoch: 6| Step: 12
Training loss: 0.16742828488349915
Validation loss: 1.4001589193139026

Epoch: 6| Step: 13
Training loss: 0.15396592020988464
Validation loss: 1.3692440916133184

Epoch: 336| Step: 0
Training loss: 0.13995835185050964
Validation loss: 1.388536662183782

Epoch: 6| Step: 1
Training loss: 0.10494953393936157
Validation loss: 1.3890422351898686

Epoch: 6| Step: 2
Training loss: 0.09815438091754913
Validation loss: 1.4173487059531673

Epoch: 6| Step: 3
Training loss: 0.08122830092906952
Validation loss: 1.3863531876635808

Epoch: 6| Step: 4
Training loss: 0.15596339106559753
Validation loss: 1.3809636555692202

Epoch: 6| Step: 5
Training loss: 0.11537856608629227
Validation loss: 1.385906627742193

Epoch: 6| Step: 6
Training loss: 0.09915699809789658
Validation loss: 1.394408954087124

Epoch: 6| Step: 7
Training loss: 0.16220906376838684
Validation loss: 1.406704560402901

Epoch: 6| Step: 8
Training loss: 0.17001017928123474
Validation loss: 1.3920233634210402

Epoch: 6| Step: 9
Training loss: 0.09658903628587723
Validation loss: 1.4141049961889944

Epoch: 6| Step: 10
Training loss: 0.19188883900642395
Validation loss: 1.4247750671960975

Epoch: 6| Step: 11
Training loss: 0.13386374711990356
Validation loss: 1.4292099001587077

Epoch: 6| Step: 12
Training loss: 0.1558515429496765
Validation loss: 1.4507654302863664

Epoch: 6| Step: 13
Training loss: 0.16332632303237915
Validation loss: 1.4516153444526017

Epoch: 337| Step: 0
Training loss: 0.12081806361675262
Validation loss: 1.4727648124899915

Epoch: 6| Step: 1
Training loss: 0.18252763152122498
Validation loss: 1.449360732109316

Epoch: 6| Step: 2
Training loss: 0.1361677050590515
Validation loss: 1.458675738303892

Epoch: 6| Step: 3
Training loss: 0.18532878160476685
Validation loss: 1.4558166214214858

Epoch: 6| Step: 4
Training loss: 0.13042810559272766
Validation loss: 1.4488787163970291

Epoch: 6| Step: 5
Training loss: 0.096342071890831
Validation loss: 1.4493214468802176

Epoch: 6| Step: 6
Training loss: 0.09464909136295319
Validation loss: 1.4391760518473964

Epoch: 6| Step: 7
Training loss: 0.07593771070241928
Validation loss: 1.4540814584301365

Epoch: 6| Step: 8
Training loss: 0.1859818696975708
Validation loss: 1.4232211715431624

Epoch: 6| Step: 9
Training loss: 0.07753841578960419
Validation loss: 1.4255370029839136

Epoch: 6| Step: 10
Training loss: 0.1544162482023239
Validation loss: 1.4063135667513775

Epoch: 6| Step: 11
Training loss: 0.19634497165679932
Validation loss: 1.4076648027666154

Epoch: 6| Step: 12
Training loss: 0.11766604334115982
Validation loss: 1.4140748381614685

Epoch: 6| Step: 13
Training loss: 0.17892250418663025
Validation loss: 1.3884976910006614

Epoch: 338| Step: 0
Training loss: 0.12574955821037292
Validation loss: 1.4008263657169957

Epoch: 6| Step: 1
Training loss: 0.09430453181266785
Validation loss: 1.380041330091415

Epoch: 6| Step: 2
Training loss: 0.08742445707321167
Validation loss: 1.3895222051169283

Epoch: 6| Step: 3
Training loss: 0.17771252989768982
Validation loss: 1.3862227124552573

Epoch: 6| Step: 4
Training loss: 0.15814104676246643
Validation loss: 1.407192300724727

Epoch: 6| Step: 5
Training loss: 0.18592530488967896
Validation loss: 1.3964931375236922

Epoch: 6| Step: 6
Training loss: 0.16350355744361877
Validation loss: 1.3856186866760254

Epoch: 6| Step: 7
Training loss: 0.08091241121292114
Validation loss: 1.4239355441062682

Epoch: 6| Step: 8
Training loss: 0.10331398993730545
Validation loss: 1.405998021043757

Epoch: 6| Step: 9
Training loss: 0.12013480067253113
Validation loss: 1.4143068873754112

Epoch: 6| Step: 10
Training loss: 0.267999529838562
Validation loss: 1.4309529207086051

Epoch: 6| Step: 11
Training loss: 0.23620161414146423
Validation loss: 1.443871848044857

Epoch: 6| Step: 12
Training loss: 0.09305281192064285
Validation loss: 1.4563038272242392

Epoch: 6| Step: 13
Training loss: 0.09896600246429443
Validation loss: 1.4566547127180203

Epoch: 339| Step: 0
Training loss: 0.09713589400053024
Validation loss: 1.4746595300653929

Epoch: 6| Step: 1
Training loss: 0.09140220284461975
Validation loss: 1.4785773241391746

Epoch: 6| Step: 2
Training loss: 0.16064836084842682
Validation loss: 1.4642196150236233

Epoch: 6| Step: 3
Training loss: 0.1461809277534485
Validation loss: 1.4610709310859762

Epoch: 6| Step: 4
Training loss: 0.1682484745979309
Validation loss: 1.436765988667806

Epoch: 6| Step: 5
Training loss: 0.10807592421770096
Validation loss: 1.46572369657537

Epoch: 6| Step: 6
Training loss: 0.14279773831367493
Validation loss: 1.453261589491239

Epoch: 6| Step: 7
Training loss: 0.22909468412399292
Validation loss: 1.467198512887442

Epoch: 6| Step: 8
Training loss: 0.14358603954315186
Validation loss: 1.4511916086237917

Epoch: 6| Step: 9
Training loss: 0.12983471155166626
Validation loss: 1.4855160879832443

Epoch: 6| Step: 10
Training loss: 0.15636420249938965
Validation loss: 1.4251252143613753

Epoch: 6| Step: 11
Training loss: 0.12161286175251007
Validation loss: 1.4735865150728533

Epoch: 6| Step: 12
Training loss: 0.0715971365571022
Validation loss: 1.4462486274780766

Epoch: 6| Step: 13
Training loss: 0.38973596692085266
Validation loss: 1.4666623370621794

Epoch: 340| Step: 0
Training loss: 0.14829830825328827
Validation loss: 1.466283211144068

Epoch: 6| Step: 1
Training loss: 0.12911641597747803
Validation loss: 1.4643382410849295

Epoch: 6| Step: 2
Training loss: 0.16066604852676392
Validation loss: 1.4539479119803316

Epoch: 6| Step: 3
Training loss: 0.12103985249996185
Validation loss: 1.46666036241798

Epoch: 6| Step: 4
Training loss: 0.10214804112911224
Validation loss: 1.4475263087980208

Epoch: 6| Step: 5
Training loss: 0.16402468085289001
Validation loss: 1.4628450985877746

Epoch: 6| Step: 6
Training loss: 0.08603470027446747
Validation loss: 1.4425034881919943

Epoch: 6| Step: 7
Training loss: 0.13166075944900513
Validation loss: 1.4575362128596152

Epoch: 6| Step: 8
Training loss: 0.09885355830192566
Validation loss: 1.4473178168778777

Epoch: 6| Step: 9
Training loss: 0.13490812480449677
Validation loss: 1.4291386386399627

Epoch: 6| Step: 10
Training loss: 0.19393837451934814
Validation loss: 1.4005049185086322

Epoch: 6| Step: 11
Training loss: 0.11039245873689651
Validation loss: 1.410741453529686

Epoch: 6| Step: 12
Training loss: 0.17309455573558807
Validation loss: 1.3848665542499994

Epoch: 6| Step: 13
Training loss: 0.1271829605102539
Validation loss: 1.4080383867345831

Epoch: 341| Step: 0
Training loss: 0.1083216518163681
Validation loss: 1.404470092506819

Epoch: 6| Step: 1
Training loss: 0.10928691923618317
Validation loss: 1.3947736435039069

Epoch: 6| Step: 2
Training loss: 0.13432665169239044
Validation loss: 1.4135445253823393

Epoch: 6| Step: 3
Training loss: 0.15818795561790466
Validation loss: 1.411095517937855

Epoch: 6| Step: 4
Training loss: 0.13014361262321472
Validation loss: 1.3920263705715057

Epoch: 6| Step: 5
Training loss: 0.16551782190799713
Validation loss: 1.4000893645389105

Epoch: 6| Step: 6
Training loss: 0.16969943046569824
Validation loss: 1.4105554729379632

Epoch: 6| Step: 7
Training loss: 0.11022364348173141
Validation loss: 1.4037298925461308

Epoch: 6| Step: 8
Training loss: 0.16482940316200256
Validation loss: 1.41142919371205

Epoch: 6| Step: 9
Training loss: 0.12161466479301453
Validation loss: 1.4247217370617775

Epoch: 6| Step: 10
Training loss: 0.13765586912631989
Validation loss: 1.4083739839574343

Epoch: 6| Step: 11
Training loss: 0.09973932057619095
Validation loss: 1.4346287391519035

Epoch: 6| Step: 12
Training loss: 0.1639229953289032
Validation loss: 1.4406311294083953

Epoch: 6| Step: 13
Training loss: 0.10400697588920593
Validation loss: 1.4442918044264599

Epoch: 342| Step: 0
Training loss: 0.1305205374956131
Validation loss: 1.458164539388431

Epoch: 6| Step: 1
Training loss: 0.1140241026878357
Validation loss: 1.4547781969911309

Epoch: 6| Step: 2
Training loss: 0.23009894788265228
Validation loss: 1.45257177019632

Epoch: 6| Step: 3
Training loss: 0.11468181759119034
Validation loss: 1.4507576496370378

Epoch: 6| Step: 4
Training loss: 0.15170907974243164
Validation loss: 1.4519208720935288

Epoch: 6| Step: 5
Training loss: 0.169483482837677
Validation loss: 1.4504461878089494

Epoch: 6| Step: 6
Training loss: 0.152508944272995
Validation loss: 1.4439623471229308

Epoch: 6| Step: 7
Training loss: 0.0918722003698349
Validation loss: 1.4334895213445027

Epoch: 6| Step: 8
Training loss: 0.12939906120300293
Validation loss: 1.430996988409309

Epoch: 6| Step: 9
Training loss: 0.09713010489940643
Validation loss: 1.4099353436500794

Epoch: 6| Step: 10
Training loss: 0.0865408405661583
Validation loss: 1.4149310050472137

Epoch: 6| Step: 11
Training loss: 0.13840392231941223
Validation loss: 1.3732646152537356

Epoch: 6| Step: 12
Training loss: 0.17836320400238037
Validation loss: 1.3659841578493837

Epoch: 6| Step: 13
Training loss: 0.1945895403623581
Validation loss: 1.3729491112052754

Epoch: 343| Step: 0
Training loss: 0.2266000360250473
Validation loss: 1.36980934937795

Epoch: 6| Step: 1
Training loss: 0.13579529523849487
Validation loss: 1.355062727005251

Epoch: 6| Step: 2
Training loss: 0.1432092785835266
Validation loss: 1.3689849799679172

Epoch: 6| Step: 3
Training loss: 0.1367863416671753
Validation loss: 1.3766686019077097

Epoch: 6| Step: 4
Training loss: 0.11611957848072052
Validation loss: 1.3886570283161697

Epoch: 6| Step: 5
Training loss: 0.14591358602046967
Validation loss: 1.3944571729629271

Epoch: 6| Step: 6
Training loss: 0.1415751874446869
Validation loss: 1.4020755367894326

Epoch: 6| Step: 7
Training loss: 0.1403486132621765
Validation loss: 1.3882327816819633

Epoch: 6| Step: 8
Training loss: 0.1477702558040619
Validation loss: 1.4295771275797198

Epoch: 6| Step: 9
Training loss: 0.09843936562538147
Validation loss: 1.415839038869386

Epoch: 6| Step: 10
Training loss: 0.15961752831935883
Validation loss: 1.3903268101394817

Epoch: 6| Step: 11
Training loss: 0.1762051284313202
Validation loss: 1.4274634058757494

Epoch: 6| Step: 12
Training loss: 0.12783589959144592
Validation loss: 1.444246551041962

Epoch: 6| Step: 13
Training loss: 0.1441507339477539
Validation loss: 1.455301320681008

Epoch: 344| Step: 0
Training loss: 0.12855367362499237
Validation loss: 1.4391683314436226

Epoch: 6| Step: 1
Training loss: 0.16978046298027039
Validation loss: 1.4805998097183883

Epoch: 6| Step: 2
Training loss: 0.08845047652721405
Validation loss: 1.4649575884624193

Epoch: 6| Step: 3
Training loss: 0.0965019166469574
Validation loss: 1.470394710058807

Epoch: 6| Step: 4
Training loss: 0.07627230137586594
Validation loss: 1.4678619061746905

Epoch: 6| Step: 5
Training loss: 0.21512293815612793
Validation loss: 1.4678464371670958

Epoch: 6| Step: 6
Training loss: 0.07975946366786957
Validation loss: 1.4932393771345898

Epoch: 6| Step: 7
Training loss: 0.11222409456968307
Validation loss: 1.4795539276574248

Epoch: 6| Step: 8
Training loss: 0.08343453705310822
Validation loss: 1.4489659468332927

Epoch: 6| Step: 9
Training loss: 0.08824450522661209
Validation loss: 1.4511578916221537

Epoch: 6| Step: 10
Training loss: 0.17492111027240753
Validation loss: 1.4296628082952192

Epoch: 6| Step: 11
Training loss: 0.17281390726566315
Validation loss: 1.4522822441593293

Epoch: 6| Step: 12
Training loss: 0.18682877719402313
Validation loss: 1.4281698708893151

Epoch: 6| Step: 13
Training loss: 0.21791213750839233
Validation loss: 1.4284181556394022

Epoch: 345| Step: 0
Training loss: 0.11425387114286423
Validation loss: 1.404480932861246

Epoch: 6| Step: 1
Training loss: 0.1323266327381134
Validation loss: 1.4137135013457267

Epoch: 6| Step: 2
Training loss: 0.12491282820701599
Validation loss: 1.3931136951651624

Epoch: 6| Step: 3
Training loss: 0.0876866951584816
Validation loss: 1.3690012680586947

Epoch: 6| Step: 4
Training loss: 0.14050397276878357
Validation loss: 1.390509375961878

Epoch: 6| Step: 5
Training loss: 0.11196839064359665
Validation loss: 1.39995159897753

Epoch: 6| Step: 6
Training loss: 0.08255352824926376
Validation loss: 1.3973733968632196

Epoch: 6| Step: 7
Training loss: 0.17597341537475586
Validation loss: 1.3817903431512977

Epoch: 6| Step: 8
Training loss: 0.1350390911102295
Validation loss: 1.3856735716583908

Epoch: 6| Step: 9
Training loss: 0.17725199460983276
Validation loss: 1.3846274896334576

Epoch: 6| Step: 10
Training loss: 0.20223645865917206
Validation loss: 1.381757801578891

Epoch: 6| Step: 11
Training loss: 0.11239436268806458
Validation loss: 1.4084289843036282

Epoch: 6| Step: 12
Training loss: 0.14219337701797485
Validation loss: 1.4305908551780127

Epoch: 6| Step: 13
Training loss: 0.13981133699417114
Validation loss: 1.4198756397411387

Epoch: 346| Step: 0
Training loss: 0.12773378193378448
Validation loss: 1.4513065661153486

Epoch: 6| Step: 1
Training loss: 0.1601267158985138
Validation loss: 1.4604605590143511

Epoch: 6| Step: 2
Training loss: 0.2332979142665863
Validation loss: 1.4549479208966738

Epoch: 6| Step: 3
Training loss: 0.09577210247516632
Validation loss: 1.449803436956098

Epoch: 6| Step: 4
Training loss: 0.09794089943170547
Validation loss: 1.4371973481229556

Epoch: 6| Step: 5
Training loss: 0.07536202669143677
Validation loss: 1.46829173257274

Epoch: 6| Step: 6
Training loss: 0.06455767154693604
Validation loss: 1.434314291964295

Epoch: 6| Step: 7
Training loss: 0.14160260558128357
Validation loss: 1.4164384398409116

Epoch: 6| Step: 8
Training loss: 0.12907284498214722
Validation loss: 1.4172229202844764

Epoch: 6| Step: 9
Training loss: 0.13843999803066254
Validation loss: 1.4170634797824326

Epoch: 6| Step: 10
Training loss: 0.10760711133480072
Validation loss: 1.3974766282625095

Epoch: 6| Step: 11
Training loss: 0.13576796650886536
Validation loss: 1.3979962128464893

Epoch: 6| Step: 12
Training loss: 0.16593122482299805
Validation loss: 1.3938175042470295

Epoch: 6| Step: 13
Training loss: 0.10545173287391663
Validation loss: 1.3775703637830672

Epoch: 347| Step: 0
Training loss: 0.10155961662530899
Validation loss: 1.3885772587150655

Epoch: 6| Step: 1
Training loss: 0.13276374340057373
Validation loss: 1.396411685533421

Epoch: 6| Step: 2
Training loss: 0.10265977680683136
Validation loss: 1.396984754070159

Epoch: 6| Step: 3
Training loss: 0.15575575828552246
Validation loss: 1.3872104306374826

Epoch: 6| Step: 4
Training loss: 0.08316457271575928
Validation loss: 1.3874077271389704

Epoch: 6| Step: 5
Training loss: 0.10520745068788528
Validation loss: 1.4000108908581477

Epoch: 6| Step: 6
Training loss: 0.1942402422428131
Validation loss: 1.3953914488515546

Epoch: 6| Step: 7
Training loss: 0.0965077131986618
Validation loss: 1.3923551036465553

Epoch: 6| Step: 8
Training loss: 0.13005098700523376
Validation loss: 1.380449866735807

Epoch: 6| Step: 9
Training loss: 0.1365806609392166
Validation loss: 1.3883563139105355

Epoch: 6| Step: 10
Training loss: 0.10435804724693298
Validation loss: 1.389147686701949

Epoch: 6| Step: 11
Training loss: 0.10292580723762512
Validation loss: 1.3642963453005719

Epoch: 6| Step: 12
Training loss: 0.15591779351234436
Validation loss: 1.3702515350875033

Epoch: 6| Step: 13
Training loss: 0.16226205229759216
Validation loss: 1.3697570626453688

Epoch: 348| Step: 0
Training loss: 0.18842709064483643
Validation loss: 1.398302822984675

Epoch: 6| Step: 1
Training loss: 0.10105791687965393
Validation loss: 1.3874121853100356

Epoch: 6| Step: 2
Training loss: 0.12371493130922318
Validation loss: 1.4078441255836076

Epoch: 6| Step: 3
Training loss: 0.08749836683273315
Validation loss: 1.3861600686145086

Epoch: 6| Step: 4
Training loss: 0.07808226346969604
Validation loss: 1.3819906198850243

Epoch: 6| Step: 5
Training loss: 0.08670967817306519
Validation loss: 1.4116080332827825

Epoch: 6| Step: 6
Training loss: 0.12224380671977997
Validation loss: 1.3846687450203845

Epoch: 6| Step: 7
Training loss: 0.16272205114364624
Validation loss: 1.3793464142789122

Epoch: 6| Step: 8
Training loss: 0.16735005378723145
Validation loss: 1.4254326128190564

Epoch: 6| Step: 9
Training loss: 0.10927952826023102
Validation loss: 1.4114094344518517

Epoch: 6| Step: 10
Training loss: 0.08745092898607254
Validation loss: 1.4002051379090996

Epoch: 6| Step: 11
Training loss: 0.11812315881252289
Validation loss: 1.4126684101678992

Epoch: 6| Step: 12
Training loss: 0.13994747400283813
Validation loss: 1.4227313995361328

Epoch: 6| Step: 13
Training loss: 0.11287625879049301
Validation loss: 1.4227244430972683

Epoch: 349| Step: 0
Training loss: 0.07566387951374054
Validation loss: 1.421015542040589

Epoch: 6| Step: 1
Training loss: 0.10790599882602692
Validation loss: 1.4169869910004318

Epoch: 6| Step: 2
Training loss: 0.12292436510324478
Validation loss: 1.4222418339021745

Epoch: 6| Step: 3
Training loss: 0.13166145980358124
Validation loss: 1.411761987593866

Epoch: 6| Step: 4
Training loss: 0.11282902956008911
Validation loss: 1.4207306267112814

Epoch: 6| Step: 5
Training loss: 0.07149214297533035
Validation loss: 1.3971719395729802

Epoch: 6| Step: 6
Training loss: 0.15404221415519714
Validation loss: 1.3807540350062872

Epoch: 6| Step: 7
Training loss: 0.16402298212051392
Validation loss: 1.397300794560422

Epoch: 6| Step: 8
Training loss: 0.10493426769971848
Validation loss: 1.4041454945841143

Epoch: 6| Step: 9
Training loss: 0.0887530967593193
Validation loss: 1.4018054034120293

Epoch: 6| Step: 10
Training loss: 0.16050714254379272
Validation loss: 1.4117078691400506

Epoch: 6| Step: 11
Training loss: 0.09068676829338074
Validation loss: 1.4070918201118388

Epoch: 6| Step: 12
Training loss: 0.2254607230424881
Validation loss: 1.4144504698373939

Epoch: 6| Step: 13
Training loss: 0.13388024270534515
Validation loss: 1.3999781544490526

Epoch: 350| Step: 0
Training loss: 0.12246120721101761
Validation loss: 1.408403064614983

Epoch: 6| Step: 1
Training loss: 0.10260602086782455
Validation loss: 1.4083583662586827

Epoch: 6| Step: 2
Training loss: 0.15817219018936157
Validation loss: 1.4129798059822412

Epoch: 6| Step: 3
Training loss: 0.14308935403823853
Validation loss: 1.4266062193019415

Epoch: 6| Step: 4
Training loss: 0.1261102557182312
Validation loss: 1.4212420935271888

Epoch: 6| Step: 5
Training loss: 0.09258126467466354
Validation loss: 1.4081396928397558

Epoch: 6| Step: 6
Training loss: 0.07555386424064636
Validation loss: 1.4286055693062403

Epoch: 6| Step: 7
Training loss: 0.17786453664302826
Validation loss: 1.4358624130166986

Epoch: 6| Step: 8
Training loss: 0.08639214932918549
Validation loss: 1.4485155908010339

Epoch: 6| Step: 9
Training loss: 0.14214719831943512
Validation loss: 1.4447038679994562

Epoch: 6| Step: 10
Training loss: 0.08910328149795532
Validation loss: 1.447255693456178

Epoch: 6| Step: 11
Training loss: 0.09762515127658844
Validation loss: 1.45425400939039

Epoch: 6| Step: 12
Training loss: 0.11537641286849976
Validation loss: 1.4544721008628927

Epoch: 6| Step: 13
Training loss: 0.08018817007541656
Validation loss: 1.4469416840102083

Epoch: 351| Step: 0
Training loss: 0.08458453416824341
Validation loss: 1.4498057826872794

Epoch: 6| Step: 1
Training loss: 0.08029568195343018
Validation loss: 1.4362929931250952

Epoch: 6| Step: 2
Training loss: 0.17631465196609497
Validation loss: 1.437791439794725

Epoch: 6| Step: 3
Training loss: 0.10167301446199417
Validation loss: 1.427373993781305

Epoch: 6| Step: 4
Training loss: 0.1213260143995285
Validation loss: 1.4357212692178705

Epoch: 6| Step: 5
Training loss: 0.0963074266910553
Validation loss: 1.4344009032813452

Epoch: 6| Step: 6
Training loss: 0.10327300429344177
Validation loss: 1.4148452769043625

Epoch: 6| Step: 7
Training loss: 0.0876065045595169
Validation loss: 1.4167213157940937

Epoch: 6| Step: 8
Training loss: 0.13709062337875366
Validation loss: 1.398988223844959

Epoch: 6| Step: 9
Training loss: 0.1010759249329567
Validation loss: 1.4379941199415474

Epoch: 6| Step: 10
Training loss: 0.13057635724544525
Validation loss: 1.3960894397509995

Epoch: 6| Step: 11
Training loss: 0.20079472661018372
Validation loss: 1.4214649238894064

Epoch: 6| Step: 12
Training loss: 0.07660718262195587
Validation loss: 1.4061207271391345

Epoch: 6| Step: 13
Training loss: 0.2279384881258011
Validation loss: 1.3967184533355057

Epoch: 352| Step: 0
Training loss: 0.13662396371364594
Validation loss: 1.4250327374345513

Epoch: 6| Step: 1
Training loss: 0.18264788389205933
Validation loss: 1.4228786281360093

Epoch: 6| Step: 2
Training loss: 0.09224291145801544
Validation loss: 1.4449453943519182

Epoch: 6| Step: 3
Training loss: 0.15249395370483398
Validation loss: 1.422325406023251

Epoch: 6| Step: 4
Training loss: 0.15174919366836548
Validation loss: 1.4123172824100783

Epoch: 6| Step: 5
Training loss: 0.08919799327850342
Validation loss: 1.3979721146245156

Epoch: 6| Step: 6
Training loss: 0.10397703945636749
Validation loss: 1.4240225027966242

Epoch: 6| Step: 7
Training loss: 0.1818307340145111
Validation loss: 1.4144165708172707

Epoch: 6| Step: 8
Training loss: 0.0814909040927887
Validation loss: 1.4028757990047496

Epoch: 6| Step: 9
Training loss: 0.12525293231010437
Validation loss: 1.407965665222496

Epoch: 6| Step: 10
Training loss: 0.13584446907043457
Validation loss: 1.38762487775536

Epoch: 6| Step: 11
Training loss: 0.09809581190347672
Validation loss: 1.3831371825228456

Epoch: 6| Step: 12
Training loss: 0.08772537112236023
Validation loss: 1.4009204154373498

Epoch: 6| Step: 13
Training loss: 0.09671391546726227
Validation loss: 1.4002937783477127

Epoch: 353| Step: 0
Training loss: 0.16268403828144073
Validation loss: 1.3970384123504802

Epoch: 6| Step: 1
Training loss: 0.15654706954956055
Validation loss: 1.3954519507705525

Epoch: 6| Step: 2
Training loss: 0.10531183332204819
Validation loss: 1.4190281719289801

Epoch: 6| Step: 3
Training loss: 0.08783737570047379
Validation loss: 1.4054737449974142

Epoch: 6| Step: 4
Training loss: 0.13915112614631653
Validation loss: 1.3792002175443916

Epoch: 6| Step: 5
Training loss: 0.08195905387401581
Validation loss: 1.3939694268729097

Epoch: 6| Step: 6
Training loss: 0.11437592655420303
Validation loss: 1.3911198954428396

Epoch: 6| Step: 7
Training loss: 0.11162955313920975
Validation loss: 1.4066965926078059

Epoch: 6| Step: 8
Training loss: 0.1878887414932251
Validation loss: 1.4078611225210211

Epoch: 6| Step: 9
Training loss: 0.13378314673900604
Validation loss: 1.3879229407156668

Epoch: 6| Step: 10
Training loss: 0.1251729130744934
Validation loss: 1.3690063991854269

Epoch: 6| Step: 11
Training loss: 0.07969684153795242
Validation loss: 1.3836464984442598

Epoch: 6| Step: 12
Training loss: 0.07636552304029465
Validation loss: 1.3828068587087816

Epoch: 6| Step: 13
Training loss: 0.132409006357193
Validation loss: 1.3880616259831253

Epoch: 354| Step: 0
Training loss: 0.0909547284245491
Validation loss: 1.3813582357539926

Epoch: 6| Step: 1
Training loss: 0.13387688994407654
Validation loss: 1.3781762789654475

Epoch: 6| Step: 2
Training loss: 0.07951819151639938
Validation loss: 1.4011856003474163

Epoch: 6| Step: 3
Training loss: 0.1234385073184967
Validation loss: 1.3545786116712837

Epoch: 6| Step: 4
Training loss: 0.17767375707626343
Validation loss: 1.4055004959465356

Epoch: 6| Step: 5
Training loss: 0.10257364809513092
Validation loss: 1.373216482900804

Epoch: 6| Step: 6
Training loss: 0.18232329189777374
Validation loss: 1.3649074416006766

Epoch: 6| Step: 7
Training loss: 0.16949757933616638
Validation loss: 1.3648004749769806

Epoch: 6| Step: 8
Training loss: 0.12190191447734833
Validation loss: 1.3779069005802114

Epoch: 6| Step: 9
Training loss: 0.15174253284931183
Validation loss: 1.3734528108309674

Epoch: 6| Step: 10
Training loss: 0.119200199842453
Validation loss: 1.3818121533240042

Epoch: 6| Step: 11
Training loss: 0.14500673115253448
Validation loss: 1.375278135781647

Epoch: 6| Step: 12
Training loss: 0.17129144072532654
Validation loss: 1.3977208906604397

Epoch: 6| Step: 13
Training loss: 0.08043548464775085
Validation loss: 1.4072910213983187

Epoch: 355| Step: 0
Training loss: 0.16398581862449646
Validation loss: 1.3986512050833753

Epoch: 6| Step: 1
Training loss: 0.12909021973609924
Validation loss: 1.4023883842652844

Epoch: 6| Step: 2
Training loss: 0.09968289732933044
Validation loss: 1.383374560263849

Epoch: 6| Step: 3
Training loss: 0.07929292321205139
Validation loss: 1.3742451603694628

Epoch: 6| Step: 4
Training loss: 0.09946450591087341
Validation loss: 1.3699605061161904

Epoch: 6| Step: 5
Training loss: 0.10205575078725815
Validation loss: 1.3692954624852827

Epoch: 6| Step: 6
Training loss: 0.11879157274961472
Validation loss: 1.3706203852930376

Epoch: 6| Step: 7
Training loss: 0.10437598079442978
Validation loss: 1.37648594251243

Epoch: 6| Step: 8
Training loss: 0.09783916175365448
Validation loss: 1.3802356655879686

Epoch: 6| Step: 9
Training loss: 0.1012381836771965
Validation loss: 1.3959180039744223

Epoch: 6| Step: 10
Training loss: 0.21772977709770203
Validation loss: 1.3781759206966688

Epoch: 6| Step: 11
Training loss: 0.1489650011062622
Validation loss: 1.3680241107940674

Epoch: 6| Step: 12
Training loss: 0.1370658576488495
Validation loss: 1.3839359450083908

Epoch: 6| Step: 13
Training loss: 0.07483381778001785
Validation loss: 1.3873255406656573

Epoch: 356| Step: 0
Training loss: 0.1379775106906891
Validation loss: 1.3979560149613248

Epoch: 6| Step: 1
Training loss: 0.09256459772586823
Validation loss: 1.390681670558068

Epoch: 6| Step: 2
Training loss: 0.0886375680565834
Validation loss: 1.3888399844528527

Epoch: 6| Step: 3
Training loss: 0.10558803379535675
Validation loss: 1.3921609206866192

Epoch: 6| Step: 4
Training loss: 0.09352411329746246
Validation loss: 1.402437456833419

Epoch: 6| Step: 5
Training loss: 0.09130297601222992
Validation loss: 1.4089567481830556

Epoch: 6| Step: 6
Training loss: 0.11694175004959106
Validation loss: 1.4098017023455711

Epoch: 6| Step: 7
Training loss: 0.15048958361148834
Validation loss: 1.4046905835469563

Epoch: 6| Step: 8
Training loss: 0.14911779761314392
Validation loss: 1.4283976888143888

Epoch: 6| Step: 9
Training loss: 0.03670518845319748
Validation loss: 1.4386196610748128

Epoch: 6| Step: 10
Training loss: 0.11799062788486481
Validation loss: 1.442787028128101

Epoch: 6| Step: 11
Training loss: 0.19626429677009583
Validation loss: 1.4598103838582193

Epoch: 6| Step: 12
Training loss: 0.17699021100997925
Validation loss: 1.4613292678709953

Epoch: 6| Step: 13
Training loss: 0.10919806361198425
Validation loss: 1.447601778532869

Epoch: 357| Step: 0
Training loss: 0.10231338441371918
Validation loss: 1.4671733712637296

Epoch: 6| Step: 1
Training loss: 0.11968620121479034
Validation loss: 1.4510704932674285

Epoch: 6| Step: 2
Training loss: 0.1735064834356308
Validation loss: 1.4563143484054073

Epoch: 6| Step: 3
Training loss: 0.0858239233493805
Validation loss: 1.4391061170126802

Epoch: 6| Step: 4
Training loss: 0.18518885970115662
Validation loss: 1.4336135233602216

Epoch: 6| Step: 5
Training loss: 0.11855457723140717
Validation loss: 1.403103930975801

Epoch: 6| Step: 6
Training loss: 0.11399662494659424
Validation loss: 1.416717856161056

Epoch: 6| Step: 7
Training loss: 0.08720453083515167
Validation loss: 1.3946817049416163

Epoch: 6| Step: 8
Training loss: 0.1433783769607544
Validation loss: 1.3947392323965668

Epoch: 6| Step: 9
Training loss: 0.12028829008340836
Validation loss: 1.394826614728538

Epoch: 6| Step: 10
Training loss: 0.04552498459815979
Validation loss: 1.3998844867111535

Epoch: 6| Step: 11
Training loss: 0.11616027355194092
Validation loss: 1.3908934029199744

Epoch: 6| Step: 12
Training loss: 0.1623477041721344
Validation loss: 1.3999956519373002

Epoch: 6| Step: 13
Training loss: 0.13005410134792328
Validation loss: 1.397187235534832

Epoch: 358| Step: 0
Training loss: 0.07408583164215088
Validation loss: 1.378787140051524

Epoch: 6| Step: 1
Training loss: 0.11628293246030807
Validation loss: 1.3909603165042015

Epoch: 6| Step: 2
Training loss: 0.10473319888114929
Validation loss: 1.4018319358107865

Epoch: 6| Step: 3
Training loss: 0.09954946488142014
Validation loss: 1.3946576413287912

Epoch: 6| Step: 4
Training loss: 0.06455354392528534
Validation loss: 1.3697132833542363

Epoch: 6| Step: 5
Training loss: 0.09098778665065765
Validation loss: 1.379550153209317

Epoch: 6| Step: 6
Training loss: 0.12352226674556732
Validation loss: 1.3597989082336426

Epoch: 6| Step: 7
Training loss: 0.12156034260988235
Validation loss: 1.3668540043215598

Epoch: 6| Step: 8
Training loss: 0.07353390008211136
Validation loss: 1.3646622806467035

Epoch: 6| Step: 9
Training loss: 0.0863851010799408
Validation loss: 1.3792743503406484

Epoch: 6| Step: 10
Training loss: 0.10926245152950287
Validation loss: 1.3903221699499315

Epoch: 6| Step: 11
Training loss: 0.1755339503288269
Validation loss: 1.391896124809019

Epoch: 6| Step: 12
Training loss: 0.12191910296678543
Validation loss: 1.382513105228383

Epoch: 6| Step: 13
Training loss: 0.266133189201355
Validation loss: 1.4029355741316272

Epoch: 359| Step: 0
Training loss: 0.09817412495613098
Validation loss: 1.4244384522079139

Epoch: 6| Step: 1
Training loss: 0.06752672046422958
Validation loss: 1.41346832500991

Epoch: 6| Step: 2
Training loss: 0.09316998720169067
Validation loss: 1.4152601765048118

Epoch: 6| Step: 3
Training loss: 0.14768058061599731
Validation loss: 1.418317033398536

Epoch: 6| Step: 4
Training loss: 0.18752025067806244
Validation loss: 1.4097303985267557

Epoch: 6| Step: 5
Training loss: 0.12016095221042633
Validation loss: 1.3984439808835265

Epoch: 6| Step: 6
Training loss: 0.071837417781353
Validation loss: 1.413039542013599

Epoch: 6| Step: 7
Training loss: 0.14384080469608307
Validation loss: 1.3903091831873822

Epoch: 6| Step: 8
Training loss: 0.13964471220970154
Validation loss: 1.4217304773228143

Epoch: 6| Step: 9
Training loss: 0.18423983454704285
Validation loss: 1.4246524521099624

Epoch: 6| Step: 10
Training loss: 0.16578073799610138
Validation loss: 1.3912477057467225

Epoch: 6| Step: 11
Training loss: 0.18687152862548828
Validation loss: 1.4136259299452587

Epoch: 6| Step: 12
Training loss: 0.09879444539546967
Validation loss: 1.3796345213408112

Epoch: 6| Step: 13
Training loss: 0.11837486177682877
Validation loss: 1.3804404043382215

Epoch: 360| Step: 0
Training loss: 0.10516036301851273
Validation loss: 1.377357586737602

Epoch: 6| Step: 1
Training loss: 0.11977767199277878
Validation loss: 1.3748495412129227

Epoch: 6| Step: 2
Training loss: 0.15366888046264648
Validation loss: 1.3632624495413996

Epoch: 6| Step: 3
Training loss: 0.21903753280639648
Validation loss: 1.3554092761008971

Epoch: 6| Step: 4
Training loss: 0.124810129404068
Validation loss: 1.3734797146371616

Epoch: 6| Step: 5
Training loss: 0.08207138627767563
Validation loss: 1.3615348723626906

Epoch: 6| Step: 6
Training loss: 0.13198482990264893
Validation loss: 1.3769805572366203

Epoch: 6| Step: 7
Training loss: 0.1332635134458542
Validation loss: 1.39313252382381

Epoch: 6| Step: 8
Training loss: 0.13975447416305542
Validation loss: 1.4093472810201748

Epoch: 6| Step: 9
Training loss: 0.14799849689006805
Validation loss: 1.4160313144806893

Epoch: 6| Step: 10
Training loss: 0.11908503621816635
Validation loss: 1.449604792620546

Epoch: 6| Step: 11
Training loss: 0.10360586643218994
Validation loss: 1.4398152443670458

Epoch: 6| Step: 12
Training loss: 0.1317477524280548
Validation loss: 1.447933840495284

Epoch: 6| Step: 13
Training loss: 0.2160445898771286
Validation loss: 1.462744931379954

Epoch: 361| Step: 0
Training loss: 0.19404539465904236
Validation loss: 1.4559948572548487

Epoch: 6| Step: 1
Training loss: 0.09512220323085785
Validation loss: 1.4499270544257215

Epoch: 6| Step: 2
Training loss: 0.19285430014133453
Validation loss: 1.446368134149941

Epoch: 6| Step: 3
Training loss: 0.04952830448746681
Validation loss: 1.4402422520422167

Epoch: 6| Step: 4
Training loss: 0.09353566914796829
Validation loss: 1.4304114336608558

Epoch: 6| Step: 5
Training loss: 0.13119828701019287
Validation loss: 1.4315708510337337

Epoch: 6| Step: 6
Training loss: 0.09754876792430878
Validation loss: 1.434891467453331

Epoch: 6| Step: 7
Training loss: 0.062064290046691895
Validation loss: 1.3976496214507728

Epoch: 6| Step: 8
Training loss: 0.0655801072716713
Validation loss: 1.414178176592755

Epoch: 6| Step: 9
Training loss: 0.14845570921897888
Validation loss: 1.3903026298810077

Epoch: 6| Step: 10
Training loss: 0.1380545198917389
Validation loss: 1.408931242522373

Epoch: 6| Step: 11
Training loss: 0.1034734696149826
Validation loss: 1.4184096936256654

Epoch: 6| Step: 12
Training loss: 0.07616902142763138
Validation loss: 1.3802756878637499

Epoch: 6| Step: 13
Training loss: 0.10154101252555847
Validation loss: 1.3957599709110875

Epoch: 362| Step: 0
Training loss: 0.09398098289966583
Validation loss: 1.3929227757197555

Epoch: 6| Step: 1
Training loss: 0.07272085547447205
Validation loss: 1.400590197373462

Epoch: 6| Step: 2
Training loss: 0.10841552913188934
Validation loss: 1.3709314664204915

Epoch: 6| Step: 3
Training loss: 0.15534523129463196
Validation loss: 1.4023671022025488

Epoch: 6| Step: 4
Training loss: 0.15213003754615784
Validation loss: 1.4158999304617605

Epoch: 6| Step: 5
Training loss: 0.23551370203495026
Validation loss: 1.4091489738033665

Epoch: 6| Step: 6
Training loss: 0.16149626672267914
Validation loss: 1.40830272500233

Epoch: 6| Step: 7
Training loss: 0.09487418085336685
Validation loss: 1.3905237836222495

Epoch: 6| Step: 8
Training loss: 0.13914737105369568
Validation loss: 1.3733982398945799

Epoch: 6| Step: 9
Training loss: 0.10900858044624329
Validation loss: 1.3964299251956325

Epoch: 6| Step: 10
Training loss: 0.15339228510856628
Validation loss: 1.3751743096177296

Epoch: 6| Step: 11
Training loss: 0.12465888261795044
Validation loss: 1.3745193462218008

Epoch: 6| Step: 12
Training loss: 0.11616845428943634
Validation loss: 1.3805340823306833

Epoch: 6| Step: 13
Training loss: 0.11969998478889465
Validation loss: 1.3901141497396654

Epoch: 363| Step: 0
Training loss: 0.15213711559772491
Validation loss: 1.386697808901469

Epoch: 6| Step: 1
Training loss: 0.14164505898952484
Validation loss: 1.3893471917798441

Epoch: 6| Step: 2
Training loss: 0.09474058449268341
Validation loss: 1.4070777559793124

Epoch: 6| Step: 3
Training loss: 0.08607514947652817
Validation loss: 1.3991125104247883

Epoch: 6| Step: 4
Training loss: 0.12368855625391006
Validation loss: 1.3757370915464175

Epoch: 6| Step: 5
Training loss: 0.095828577876091
Validation loss: 1.3875236729139924

Epoch: 6| Step: 6
Training loss: 0.14044567942619324
Validation loss: 1.40300718943278

Epoch: 6| Step: 7
Training loss: 0.16680145263671875
Validation loss: 1.4075746395254647

Epoch: 6| Step: 8
Training loss: 0.088516965508461
Validation loss: 1.4197544026118454

Epoch: 6| Step: 9
Training loss: 0.13594679534435272
Validation loss: 1.3973623744903072

Epoch: 6| Step: 10
Training loss: 0.15291468799114227
Validation loss: 1.4042280130488898

Epoch: 6| Step: 11
Training loss: 0.12156877666711807
Validation loss: 1.4073353762267737

Epoch: 6| Step: 12
Training loss: 0.12881135940551758
Validation loss: 1.4024921412109046

Epoch: 6| Step: 13
Training loss: 0.11507299542427063
Validation loss: 1.383789840564933

Epoch: 364| Step: 0
Training loss: 0.04978874325752258
Validation loss: 1.3780041535695393

Epoch: 6| Step: 1
Training loss: 0.09690497070550919
Validation loss: 1.3993390798568726

Epoch: 6| Step: 2
Training loss: 0.17454639077186584
Validation loss: 1.3892897752023512

Epoch: 6| Step: 3
Training loss: 0.1135990172624588
Validation loss: 1.4067194070867313

Epoch: 6| Step: 4
Training loss: 0.14708949625492096
Validation loss: 1.3916678838832404

Epoch: 6| Step: 5
Training loss: 0.1226099282503128
Validation loss: 1.4073775147878995

Epoch: 6| Step: 6
Training loss: 0.11977501213550568
Validation loss: 1.3979070878797961

Epoch: 6| Step: 7
Training loss: 0.10447297990322113
Validation loss: 1.3989632360396846

Epoch: 6| Step: 8
Training loss: 0.11155740916728973
Validation loss: 1.3941191498951246

Epoch: 6| Step: 9
Training loss: 0.10632921010255814
Validation loss: 1.404846429824829

Epoch: 6| Step: 10
Training loss: 0.1096767857670784
Validation loss: 1.394798642845564

Epoch: 6| Step: 11
Training loss: 0.10183443129062653
Validation loss: 1.3808640356986754

Epoch: 6| Step: 12
Training loss: 0.15727639198303223
Validation loss: 1.3974787817206433

Epoch: 6| Step: 13
Training loss: 0.07758037000894547
Validation loss: 1.3945191291070753

Epoch: 365| Step: 0
Training loss: 0.15371903777122498
Validation loss: 1.3956108952081332

Epoch: 6| Step: 1
Training loss: 0.09067372232675552
Validation loss: 1.3914457630085688

Epoch: 6| Step: 2
Training loss: 0.12528762221336365
Validation loss: 1.4040709810872232

Epoch: 6| Step: 3
Training loss: 0.11147839576005936
Validation loss: 1.38435806446178

Epoch: 6| Step: 4
Training loss: 0.08917149901390076
Validation loss: 1.3827702358204832

Epoch: 6| Step: 5
Training loss: 0.16087079048156738
Validation loss: 1.381612987928493

Epoch: 6| Step: 6
Training loss: 0.12079393863677979
Validation loss: 1.3643521032025736

Epoch: 6| Step: 7
Training loss: 0.057730890810489655
Validation loss: 1.3781571740745215

Epoch: 6| Step: 8
Training loss: 0.09080596268177032
Validation loss: 1.3839586165643507

Epoch: 6| Step: 9
Training loss: 0.08475226908922195
Validation loss: 1.3711276861929125

Epoch: 6| Step: 10
Training loss: 0.1004921942949295
Validation loss: 1.384888901505419

Epoch: 6| Step: 11
Training loss: 0.1428833305835724
Validation loss: 1.3950529598420667

Epoch: 6| Step: 12
Training loss: 0.12733224034309387
Validation loss: 1.3884967962900798

Epoch: 6| Step: 13
Training loss: 0.07724916934967041
Validation loss: 1.3760644671737507

Epoch: 366| Step: 0
Training loss: 0.07540813088417053
Validation loss: 1.3927211582019765

Epoch: 6| Step: 1
Training loss: 0.22590845823287964
Validation loss: 1.4062754889970184

Epoch: 6| Step: 2
Training loss: 0.10897192358970642
Validation loss: 1.3865431970165623

Epoch: 6| Step: 3
Training loss: 0.10531210154294968
Validation loss: 1.387752386831468

Epoch: 6| Step: 4
Training loss: 0.10256491601467133
Validation loss: 1.3986021011106429

Epoch: 6| Step: 5
Training loss: 0.10523352026939392
Validation loss: 1.4126550548820085

Epoch: 6| Step: 6
Training loss: 0.12981998920440674
Validation loss: 1.4118212282016713

Epoch: 6| Step: 7
Training loss: 0.12152071297168732
Validation loss: 1.3873146157110892

Epoch: 6| Step: 8
Training loss: 0.11874380707740784
Validation loss: 1.3948555543858518

Epoch: 6| Step: 9
Training loss: 0.13140681385993958
Validation loss: 1.3968114096631286

Epoch: 6| Step: 10
Training loss: 0.16651569306850433
Validation loss: 1.4037090334841

Epoch: 6| Step: 11
Training loss: 0.16230502724647522
Validation loss: 1.413791802621657

Epoch: 6| Step: 12
Training loss: 0.08761121332645416
Validation loss: 1.4024176046412478

Epoch: 6| Step: 13
Training loss: 0.07374373078346252
Validation loss: 1.3940772958981094

Epoch: 367| Step: 0
Training loss: 0.10816246271133423
Validation loss: 1.3926704378538235

Epoch: 6| Step: 1
Training loss: 0.16848930716514587
Validation loss: 1.3776068277256464

Epoch: 6| Step: 2
Training loss: 0.13152751326560974
Validation loss: 1.366367652852048

Epoch: 6| Step: 3
Training loss: 0.09296898543834686
Validation loss: 1.37800036386777

Epoch: 6| Step: 4
Training loss: 0.12654659152030945
Validation loss: 1.3791671414529123

Epoch: 6| Step: 5
Training loss: 0.10691869258880615
Validation loss: 1.3851234656508251

Epoch: 6| Step: 6
Training loss: 0.08333883434534073
Validation loss: 1.3877595855343727

Epoch: 6| Step: 7
Training loss: 0.10975323617458344
Validation loss: 1.401645806527907

Epoch: 6| Step: 8
Training loss: 0.12145713716745377
Validation loss: 1.4180498046259726

Epoch: 6| Step: 9
Training loss: 0.1614593267440796
Validation loss: 1.4173732944714126

Epoch: 6| Step: 10
Training loss: 0.10502038896083832
Validation loss: 1.4283332452979138

Epoch: 6| Step: 11
Training loss: 0.10402615368366241
Validation loss: 1.4348764419555664

Epoch: 6| Step: 12
Training loss: 0.1017865389585495
Validation loss: 1.4304616810173116

Epoch: 6| Step: 13
Training loss: 0.1329057812690735
Validation loss: 1.4320322198252524

Epoch: 368| Step: 0
Training loss: 0.08627204596996307
Validation loss: 1.4286816363693566

Epoch: 6| Step: 1
Training loss: 0.07940270751714706
Validation loss: 1.4356214013150943

Epoch: 6| Step: 2
Training loss: 0.11822795867919922
Validation loss: 1.4161015813068678

Epoch: 6| Step: 3
Training loss: 0.08495193719863892
Validation loss: 1.4013616013270553

Epoch: 6| Step: 4
Training loss: 0.14957651495933533
Validation loss: 1.4302722125925043

Epoch: 6| Step: 5
Training loss: 0.14610157907009125
Validation loss: 1.4206383997394192

Epoch: 6| Step: 6
Training loss: 0.10006285458803177
Validation loss: 1.4189130388280398

Epoch: 6| Step: 7
Training loss: 0.10218818485736847
Validation loss: 1.4290297377494074

Epoch: 6| Step: 8
Training loss: 0.09619515389204025
Validation loss: 1.4230167583752704

Epoch: 6| Step: 9
Training loss: 0.11626637727022171
Validation loss: 1.4416000868684502

Epoch: 6| Step: 10
Training loss: 0.06547622382640839
Validation loss: 1.404074929093802

Epoch: 6| Step: 11
Training loss: 0.1134846955537796
Validation loss: 1.4092313781861336

Epoch: 6| Step: 12
Training loss: 0.1905767172574997
Validation loss: 1.4033758505698173

Epoch: 6| Step: 13
Training loss: 0.09121004492044449
Validation loss: 1.3849314681945308

Epoch: 369| Step: 0
Training loss: 0.11589056998491287
Validation loss: 1.3896968838989094

Epoch: 6| Step: 1
Training loss: 0.11012651026248932
Validation loss: 1.4096992682385188

Epoch: 6| Step: 2
Training loss: 0.10027000308036804
Validation loss: 1.3897767836047756

Epoch: 6| Step: 3
Training loss: 0.052962057292461395
Validation loss: 1.3965715041724585

Epoch: 6| Step: 4
Training loss: 0.10360170900821686
Validation loss: 1.3964737743459723

Epoch: 6| Step: 5
Training loss: 0.09464482963085175
Validation loss: 1.4063650984917917

Epoch: 6| Step: 6
Training loss: 0.11912079155445099
Validation loss: 1.4116049646049418

Epoch: 6| Step: 7
Training loss: 0.2085474133491516
Validation loss: 1.4223211247433898

Epoch: 6| Step: 8
Training loss: 0.12324271351099014
Validation loss: 1.3993585571166007

Epoch: 6| Step: 9
Training loss: 0.07158282399177551
Validation loss: 1.39612671636766

Epoch: 6| Step: 10
Training loss: 0.11962291598320007
Validation loss: 1.389143027285094

Epoch: 6| Step: 11
Training loss: 0.07743443548679352
Validation loss: 1.3797417113216974

Epoch: 6| Step: 12
Training loss: 0.15234661102294922
Validation loss: 1.3701312606052687

Epoch: 6| Step: 13
Training loss: 0.11948389559984207
Validation loss: 1.3937823310975106

Epoch: 370| Step: 0
Training loss: 0.16137923300266266
Validation loss: 1.3811042545944132

Epoch: 6| Step: 1
Training loss: 0.06405217945575714
Validation loss: 1.380876938501994

Epoch: 6| Step: 2
Training loss: 0.14729800820350647
Validation loss: 1.3915817929852394

Epoch: 6| Step: 3
Training loss: 0.11940129101276398
Validation loss: 1.3904451516366774

Epoch: 6| Step: 4
Training loss: 0.1060573011636734
Validation loss: 1.3850947580029886

Epoch: 6| Step: 5
Training loss: 0.0753142237663269
Validation loss: 1.3811492368739138

Epoch: 6| Step: 6
Training loss: 0.19891569018363953
Validation loss: 1.3920253758789392

Epoch: 6| Step: 7
Training loss: 0.1188722625374794
Validation loss: 1.377434875375481

Epoch: 6| Step: 8
Training loss: 0.0957413911819458
Validation loss: 1.4050145995232366

Epoch: 6| Step: 9
Training loss: 0.10878415405750275
Validation loss: 1.3957772402353184

Epoch: 6| Step: 10
Training loss: 0.1590060144662857
Validation loss: 1.3913730812329117

Epoch: 6| Step: 11
Training loss: 0.084610715508461
Validation loss: 1.416600670865787

Epoch: 6| Step: 12
Training loss: 0.08713673055171967
Validation loss: 1.3988849514274186

Epoch: 6| Step: 13
Training loss: 0.10319508612155914
Validation loss: 1.414984550527347

Epoch: 371| Step: 0
Training loss: 0.1571638137102127
Validation loss: 1.408670413237746

Epoch: 6| Step: 1
Training loss: 0.06865990906953812
Validation loss: 1.4178628972781602

Epoch: 6| Step: 2
Training loss: 0.12173902988433838
Validation loss: 1.4193346936215636

Epoch: 6| Step: 3
Training loss: 0.10904190689325333
Validation loss: 1.4099002820189281

Epoch: 6| Step: 4
Training loss: 0.12730206549167633
Validation loss: 1.4058258648841613

Epoch: 6| Step: 5
Training loss: 0.06495324522256851
Validation loss: 1.413876320726128

Epoch: 6| Step: 6
Training loss: 0.14575955271720886
Validation loss: 1.4180315322773431

Epoch: 6| Step: 7
Training loss: 0.12132735550403595
Validation loss: 1.4091840678004808

Epoch: 6| Step: 8
Training loss: 0.09136535227298737
Validation loss: 1.4054147210172427

Epoch: 6| Step: 9
Training loss: 0.16523952782154083
Validation loss: 1.4186564773641608

Epoch: 6| Step: 10
Training loss: 0.10652550309896469
Validation loss: 1.4154014965539337

Epoch: 6| Step: 11
Training loss: 0.06585325300693512
Validation loss: 1.4279772620047293

Epoch: 6| Step: 12
Training loss: 0.11658009141683578
Validation loss: 1.4423337847955766

Epoch: 6| Step: 13
Training loss: 0.08717457205057144
Validation loss: 1.4286481424044537

Epoch: 372| Step: 0
Training loss: 0.11127170920372009
Validation loss: 1.4337571590177474

Epoch: 6| Step: 1
Training loss: 0.17521929740905762
Validation loss: 1.430030183766478

Epoch: 6| Step: 2
Training loss: 0.13778385519981384
Validation loss: 1.4295040702307096

Epoch: 6| Step: 3
Training loss: 0.09465505182743073
Validation loss: 1.4087164081552976

Epoch: 6| Step: 4
Training loss: 0.06882688403129578
Validation loss: 1.4228735893003401

Epoch: 6| Step: 5
Training loss: 0.09862123429775238
Validation loss: 1.4008709762686042

Epoch: 6| Step: 6
Training loss: 0.10231974720954895
Validation loss: 1.4091342283833412

Epoch: 6| Step: 7
Training loss: 0.12695874273777008
Validation loss: 1.3906554227234216

Epoch: 6| Step: 8
Training loss: 0.09487800300121307
Validation loss: 1.3866830820678382

Epoch: 6| Step: 9
Training loss: 0.21513134241104126
Validation loss: 1.3781722450769076

Epoch: 6| Step: 10
Training loss: 0.1160331666469574
Validation loss: 1.41064904966662

Epoch: 6| Step: 11
Training loss: 0.12778884172439575
Validation loss: 1.41431257032579

Epoch: 6| Step: 12
Training loss: 0.10276515781879425
Validation loss: 1.4167958280091644

Epoch: 6| Step: 13
Training loss: 0.13373897969722748
Validation loss: 1.4412297651331911

Epoch: 373| Step: 0
Training loss: 0.18106234073638916
Validation loss: 1.4394840553242674

Epoch: 6| Step: 1
Training loss: 0.12282338738441467
Validation loss: 1.4460326715182232

Epoch: 6| Step: 2
Training loss: 0.09638106822967529
Validation loss: 1.461746866985034

Epoch: 6| Step: 3
Training loss: 0.1184970960021019
Validation loss: 1.4267502792419926

Epoch: 6| Step: 4
Training loss: 0.04383142665028572
Validation loss: 1.4043591048127861

Epoch: 6| Step: 5
Training loss: 0.1254948377609253
Validation loss: 1.3932524919509888

Epoch: 6| Step: 6
Training loss: 0.1443825662136078
Validation loss: 1.3857841248153357

Epoch: 6| Step: 7
Training loss: 0.11779700964689255
Validation loss: 1.366785781357878

Epoch: 6| Step: 8
Training loss: 0.16994178295135498
Validation loss: 1.391230260172198

Epoch: 6| Step: 9
Training loss: 0.11519099026918411
Validation loss: 1.3827305634816487

Epoch: 6| Step: 10
Training loss: 0.05933872610330582
Validation loss: 1.3751928421758837

Epoch: 6| Step: 11
Training loss: 0.11055631935596466
Validation loss: 1.3855698586151164

Epoch: 6| Step: 12
Training loss: 0.09640216827392578
Validation loss: 1.381089727083842

Epoch: 6| Step: 13
Training loss: 0.08576134592294693
Validation loss: 1.3796477074264197

Epoch: 374| Step: 0
Training loss: 0.13851308822631836
Validation loss: 1.3735646111990816

Epoch: 6| Step: 1
Training loss: 0.09197195619344711
Validation loss: 1.3898825504446541

Epoch: 6| Step: 2
Training loss: 0.07957762479782104
Validation loss: 1.3759067032926826

Epoch: 6| Step: 3
Training loss: 0.10188458859920502
Validation loss: 1.3616959856402489

Epoch: 6| Step: 4
Training loss: 0.0944877564907074
Validation loss: 1.3758556368530437

Epoch: 6| Step: 5
Training loss: 0.090894415974617
Validation loss: 1.3755767935065812

Epoch: 6| Step: 6
Training loss: 0.21465259790420532
Validation loss: 1.3762770199006604

Epoch: 6| Step: 7
Training loss: 0.14325961470603943
Validation loss: 1.375323841648717

Epoch: 6| Step: 8
Training loss: 0.06994514167308807
Validation loss: 1.372316204091554

Epoch: 6| Step: 9
Training loss: 0.08054963499307632
Validation loss: 1.3570488742602769

Epoch: 6| Step: 10
Training loss: 0.08728615194559097
Validation loss: 1.378089713793929

Epoch: 6| Step: 11
Training loss: 0.11247546225786209
Validation loss: 1.3757271279570877

Epoch: 6| Step: 12
Training loss: 0.07752648741006851
Validation loss: 1.3630519778497758

Epoch: 6| Step: 13
Training loss: 0.12699012458324432
Validation loss: 1.3786823595723798

Epoch: 375| Step: 0
Training loss: 0.15709710121154785
Validation loss: 1.3574391834197506

Epoch: 6| Step: 1
Training loss: 0.048500142991542816
Validation loss: 1.3701927758032275

Epoch: 6| Step: 2
Training loss: 0.14181232452392578
Validation loss: 1.375603384869073

Epoch: 6| Step: 3
Training loss: 0.1187041774392128
Validation loss: 1.3997777431241927

Epoch: 6| Step: 4
Training loss: 0.1113739013671875
Validation loss: 1.3853615099383938

Epoch: 6| Step: 5
Training loss: 0.10668380558490753
Validation loss: 1.3809916107885298

Epoch: 6| Step: 6
Training loss: 0.13797199726104736
Validation loss: 1.3900669890065347

Epoch: 6| Step: 7
Training loss: 0.08094325661659241
Validation loss: 1.3818921171208864

Epoch: 6| Step: 8
Training loss: 0.10417695343494415
Validation loss: 1.3860491514205933

Epoch: 6| Step: 9
Training loss: 0.08005262166261673
Validation loss: 1.3770943835217466

Epoch: 6| Step: 10
Training loss: 0.0785907655954361
Validation loss: 1.371085101558316

Epoch: 6| Step: 11
Training loss: 0.060135118663311005
Validation loss: 1.3677513586577548

Epoch: 6| Step: 12
Training loss: 0.1292128562927246
Validation loss: 1.3699056679202664

Epoch: 6| Step: 13
Training loss: 0.09812191873788834
Validation loss: 1.3603014058323317

Epoch: 376| Step: 0
Training loss: 0.09529780596494675
Validation loss: 1.369877185872806

Epoch: 6| Step: 1
Training loss: 0.09511502087116241
Validation loss: 1.3705903791612195

Epoch: 6| Step: 2
Training loss: 0.1277228593826294
Validation loss: 1.3722755024510045

Epoch: 6| Step: 3
Training loss: 0.10232076048851013
Validation loss: 1.3916984386341547

Epoch: 6| Step: 4
Training loss: 0.1697404682636261
Validation loss: 1.3901033465580275

Epoch: 6| Step: 5
Training loss: 0.11978230625391006
Validation loss: 1.3865160749804588

Epoch: 6| Step: 6
Training loss: 0.07064586877822876
Validation loss: 1.384435776741274

Epoch: 6| Step: 7
Training loss: 0.08645050972700119
Validation loss: 1.3586766078907957

Epoch: 6| Step: 8
Training loss: 0.09562254697084427
Validation loss: 1.3640891121279808

Epoch: 6| Step: 9
Training loss: 0.07233987003564835
Validation loss: 1.3772570933065107

Epoch: 6| Step: 10
Training loss: 0.07995416969060898
Validation loss: 1.3707741281037689

Epoch: 6| Step: 11
Training loss: 0.15140163898468018
Validation loss: 1.3774431918257026

Epoch: 6| Step: 12
Training loss: 0.12543727457523346
Validation loss: 1.3795161349799043

Epoch: 6| Step: 13
Training loss: 0.07246848940849304
Validation loss: 1.3671055839907738

Epoch: 377| Step: 0
Training loss: 0.05381999909877777
Validation loss: 1.3827050667937084

Epoch: 6| Step: 1
Training loss: 0.1467113494873047
Validation loss: 1.3856266826711676

Epoch: 6| Step: 2
Training loss: 0.07188763469457626
Validation loss: 1.3597653783777708

Epoch: 6| Step: 3
Training loss: 0.07175393402576447
Validation loss: 1.3871449001373783

Epoch: 6| Step: 4
Training loss: 0.1528046578168869
Validation loss: 1.3742765662490681

Epoch: 6| Step: 5
Training loss: 0.0653219223022461
Validation loss: 1.4046365394387195

Epoch: 6| Step: 6
Training loss: 0.12807723879814148
Validation loss: 1.3939458183062974

Epoch: 6| Step: 7
Training loss: 0.10661452263593674
Validation loss: 1.3807140037577639

Epoch: 6| Step: 8
Training loss: 0.125657856464386
Validation loss: 1.3860163554068534

Epoch: 6| Step: 9
Training loss: 0.0959993302822113
Validation loss: 1.3708712490656043

Epoch: 6| Step: 10
Training loss: 0.1326591521501541
Validation loss: 1.3731306611850698

Epoch: 6| Step: 11
Training loss: 0.12464188039302826
Validation loss: 1.400184977439142

Epoch: 6| Step: 12
Training loss: 0.1040167585015297
Validation loss: 1.4084493947285477

Epoch: 6| Step: 13
Training loss: 0.060363590717315674
Validation loss: 1.3965068888920609

Epoch: 378| Step: 0
Training loss: 0.07255434989929199
Validation loss: 1.3619360193129508

Epoch: 6| Step: 1
Training loss: 0.09880021214485168
Validation loss: 1.394713705585849

Epoch: 6| Step: 2
Training loss: 0.07562437653541565
Validation loss: 1.4065347102380568

Epoch: 6| Step: 3
Training loss: 0.074129119515419
Validation loss: 1.389225326558595

Epoch: 6| Step: 4
Training loss: 0.09820586442947388
Validation loss: 1.4120083111588673

Epoch: 6| Step: 5
Training loss: 0.15131087601184845
Validation loss: 1.3904605950078657

Epoch: 6| Step: 6
Training loss: 0.05597904324531555
Validation loss: 1.3988453675341863

Epoch: 6| Step: 7
Training loss: 0.14879080653190613
Validation loss: 1.3763097614370368

Epoch: 6| Step: 8
Training loss: 0.06839103996753693
Validation loss: 1.3799322228277884

Epoch: 6| Step: 9
Training loss: 0.07779860496520996
Validation loss: 1.4114673368392452

Epoch: 6| Step: 10
Training loss: 0.05259149521589279
Validation loss: 1.4096375178265315

Epoch: 6| Step: 11
Training loss: 0.1622510701417923
Validation loss: 1.407063473937332

Epoch: 6| Step: 12
Training loss: 0.06977584958076477
Validation loss: 1.4037468010379421

Epoch: 6| Step: 13
Training loss: 0.07672059535980225
Validation loss: 1.386171297360492

Epoch: 379| Step: 0
Training loss: 0.12956424057483673
Validation loss: 1.4089037013310257

Epoch: 6| Step: 1
Training loss: 0.10539490729570389
Validation loss: 1.3887178808130243

Epoch: 6| Step: 2
Training loss: 0.13040107488632202
Validation loss: 1.3866579160895398

Epoch: 6| Step: 3
Training loss: 0.16166695952415466
Validation loss: 1.3910066555905085

Epoch: 6| Step: 4
Training loss: 0.1300506293773651
Validation loss: 1.416780141092116

Epoch: 6| Step: 5
Training loss: 0.07941896468400955
Validation loss: 1.3888282532333045

Epoch: 6| Step: 6
Training loss: 0.08803403377532959
Validation loss: 1.3691035573200514

Epoch: 6| Step: 7
Training loss: 0.10866957902908325
Validation loss: 1.3472353271258775

Epoch: 6| Step: 8
Training loss: 0.09385944902896881
Validation loss: 1.354959850670189

Epoch: 6| Step: 9
Training loss: 0.12587721645832062
Validation loss: 1.3236633270017562

Epoch: 6| Step: 10
Training loss: 0.14180921018123627
Validation loss: 1.3194832942819084

Epoch: 6| Step: 11
Training loss: 0.11820164322853088
Validation loss: 1.340582311794322

Epoch: 6| Step: 12
Training loss: 0.13655857741832733
Validation loss: 1.3336435889685025

Epoch: 6| Step: 13
Training loss: 0.07163283228874207
Validation loss: 1.3282704417423536

Epoch: 380| Step: 0
Training loss: 0.09635724872350693
Validation loss: 1.3515114720149706

Epoch: 6| Step: 1
Training loss: 0.12114445865154266
Validation loss: 1.3455343797642698

Epoch: 6| Step: 2
Training loss: 0.23558999598026276
Validation loss: 1.3860391314311693

Epoch: 6| Step: 3
Training loss: 0.0855538472533226
Validation loss: 1.3914875099735875

Epoch: 6| Step: 4
Training loss: 0.24554142355918884
Validation loss: 1.375927230363251

Epoch: 6| Step: 5
Training loss: 0.0475858673453331
Validation loss: 1.3731358589664582

Epoch: 6| Step: 6
Training loss: 0.08111739158630371
Validation loss: 1.3918782793065554

Epoch: 6| Step: 7
Training loss: 0.11569297313690186
Validation loss: 1.397692790595434

Epoch: 6| Step: 8
Training loss: 0.06235586851835251
Validation loss: 1.3936438983486545

Epoch: 6| Step: 9
Training loss: 0.079905204474926
Validation loss: 1.3945316678734236

Epoch: 6| Step: 10
Training loss: 0.058559708297252655
Validation loss: 1.4183349237647107

Epoch: 6| Step: 11
Training loss: 0.1147974282503128
Validation loss: 1.4127982040887237

Epoch: 6| Step: 12
Training loss: 0.11595046520233154
Validation loss: 1.4220700962569124

Epoch: 6| Step: 13
Training loss: 0.08347213268280029
Validation loss: 1.418893737177695

Epoch: 381| Step: 0
Training loss: 0.0838010162115097
Validation loss: 1.4277381089425856

Epoch: 6| Step: 1
Training loss: 0.1065475270152092
Validation loss: 1.4370490325394498

Epoch: 6| Step: 2
Training loss: 0.07444670051336288
Validation loss: 1.4366741827739182

Epoch: 6| Step: 3
Training loss: 0.10415259748697281
Validation loss: 1.4607447116605696

Epoch: 6| Step: 4
Training loss: 0.09575533866882324
Validation loss: 1.4612984644469393

Epoch: 6| Step: 5
Training loss: 0.09975290298461914
Validation loss: 1.468604443534728

Epoch: 6| Step: 6
Training loss: 0.18788054585456848
Validation loss: 1.43840439345247

Epoch: 6| Step: 7
Training loss: 0.1140323355793953
Validation loss: 1.444638225340074

Epoch: 6| Step: 8
Training loss: 0.0926651656627655
Validation loss: 1.449580515584638

Epoch: 6| Step: 9
Training loss: 0.08931197226047516
Validation loss: 1.4280533534224316

Epoch: 6| Step: 10
Training loss: 0.1306203156709671
Validation loss: 1.4347664835632488

Epoch: 6| Step: 11
Training loss: 0.21901796758174896
Validation loss: 1.416040765341892

Epoch: 6| Step: 12
Training loss: 0.07368995994329453
Validation loss: 1.4226652101803852

Epoch: 6| Step: 13
Training loss: 0.13623765110969543
Validation loss: 1.4022466674927743

Epoch: 382| Step: 0
Training loss: 0.11680477857589722
Validation loss: 1.4090683191053328

Epoch: 6| Step: 1
Training loss: 0.17646047472953796
Validation loss: 1.383871284864282

Epoch: 6| Step: 2
Training loss: 0.10535146296024323
Validation loss: 1.4038104523894608

Epoch: 6| Step: 3
Training loss: 0.041572265326976776
Validation loss: 1.3845066742230487

Epoch: 6| Step: 4
Training loss: 0.08748293668031693
Validation loss: 1.3826684092962613

Epoch: 6| Step: 5
Training loss: 0.08237733691930771
Validation loss: 1.3911863116807834

Epoch: 6| Step: 6
Training loss: 0.11970415711402893
Validation loss: 1.400090068899175

Epoch: 6| Step: 7
Training loss: 0.08764290809631348
Validation loss: 1.4120542195535475

Epoch: 6| Step: 8
Training loss: 0.06636899709701538
Validation loss: 1.3999815820365824

Epoch: 6| Step: 9
Training loss: 0.07738682627677917
Validation loss: 1.3990586803805443

Epoch: 6| Step: 10
Training loss: 0.09112188965082169
Validation loss: 1.4106546422486663

Epoch: 6| Step: 11
Training loss: 0.1657751202583313
Validation loss: 1.3679227354705974

Epoch: 6| Step: 12
Training loss: 0.12939590215682983
Validation loss: 1.4026691272694578

Epoch: 6| Step: 13
Training loss: 0.22457429766654968
Validation loss: 1.381251089034542

Epoch: 383| Step: 0
Training loss: 0.11893077194690704
Validation loss: 1.3971915565511233

Epoch: 6| Step: 1
Training loss: 0.07643638551235199
Validation loss: 1.391047998141217

Epoch: 6| Step: 2
Training loss: 0.11473116278648376
Validation loss: 1.385166193849297

Epoch: 6| Step: 3
Training loss: 0.07295379042625427
Validation loss: 1.396969021007579

Epoch: 6| Step: 4
Training loss: 0.05727513134479523
Validation loss: 1.397910633394795

Epoch: 6| Step: 5
Training loss: 0.10873379558324814
Validation loss: 1.3894195402822187

Epoch: 6| Step: 6
Training loss: 0.08027646690607071
Validation loss: 1.3915540217071452

Epoch: 6| Step: 7
Training loss: 0.13099265098571777
Validation loss: 1.3966815984377297

Epoch: 6| Step: 8
Training loss: 0.08313173055648804
Validation loss: 1.3839435000573435

Epoch: 6| Step: 9
Training loss: 0.09549988806247711
Validation loss: 1.3868072212383311

Epoch: 6| Step: 10
Training loss: 0.0985972061753273
Validation loss: 1.385706978459512

Epoch: 6| Step: 11
Training loss: 0.09434439986944199
Validation loss: 1.3697674325717393

Epoch: 6| Step: 12
Training loss: 0.09580819308757782
Validation loss: 1.366775917750533

Epoch: 6| Step: 13
Training loss: 0.07612073421478271
Validation loss: 1.4006751519377514

Epoch: 384| Step: 0
Training loss: 0.14941200613975525
Validation loss: 1.3743355581837315

Epoch: 6| Step: 1
Training loss: 0.12284732609987259
Validation loss: 1.3640744968127179

Epoch: 6| Step: 2
Training loss: 0.0915982723236084
Validation loss: 1.3718293495075677

Epoch: 6| Step: 3
Training loss: 0.08458180725574493
Validation loss: 1.3808897502960698

Epoch: 6| Step: 4
Training loss: 0.12032055854797363
Validation loss: 1.3803079423084055

Epoch: 6| Step: 5
Training loss: 0.16297340393066406
Validation loss: 1.386362821825089

Epoch: 6| Step: 6
Training loss: 0.09175446629524231
Validation loss: 1.4070512030714302

Epoch: 6| Step: 7
Training loss: 0.11222054809331894
Validation loss: 1.409134188006001

Epoch: 6| Step: 8
Training loss: 0.125686377286911
Validation loss: 1.4079400980344383

Epoch: 6| Step: 9
Training loss: 0.0722401961684227
Validation loss: 1.409146035871198

Epoch: 6| Step: 10
Training loss: 0.08973749727010727
Validation loss: 1.4166630403969878

Epoch: 6| Step: 11
Training loss: 0.08551681041717529
Validation loss: 1.4249431574216453

Epoch: 6| Step: 12
Training loss: 0.07594553381204605
Validation loss: 1.4051387899665422

Epoch: 6| Step: 13
Training loss: 0.041665349155664444
Validation loss: 1.4182885103328253

Epoch: 385| Step: 0
Training loss: 0.07790254056453705
Validation loss: 1.4127927922433423

Epoch: 6| Step: 1
Training loss: 0.10024333745241165
Validation loss: 1.3949150641759236

Epoch: 6| Step: 2
Training loss: 0.09810607135295868
Validation loss: 1.421288008971881

Epoch: 6| Step: 3
Training loss: 0.09549620747566223
Validation loss: 1.4167241934807069

Epoch: 6| Step: 4
Training loss: 0.10051436722278595
Validation loss: 1.403811656018739

Epoch: 6| Step: 5
Training loss: 0.06758568435907364
Validation loss: 1.4011069869482389

Epoch: 6| Step: 6
Training loss: 0.09122273325920105
Validation loss: 1.425335826412324

Epoch: 6| Step: 7
Training loss: 0.09643010795116425
Validation loss: 1.4001534933684974

Epoch: 6| Step: 8
Training loss: 0.11201681196689606
Validation loss: 1.408209281582986

Epoch: 6| Step: 9
Training loss: 0.11319203674793243
Validation loss: 1.3973595749947332

Epoch: 6| Step: 10
Training loss: 0.0729578360915184
Validation loss: 1.4019520654473254

Epoch: 6| Step: 11
Training loss: 0.05934659764170647
Validation loss: 1.4039009809494019

Epoch: 6| Step: 12
Training loss: 0.1305692493915558
Validation loss: 1.3857297333337928

Epoch: 6| Step: 13
Training loss: 0.1364300549030304
Validation loss: 1.4048097082363662

Epoch: 386| Step: 0
Training loss: 0.1275915652513504
Validation loss: 1.4168438456391776

Epoch: 6| Step: 1
Training loss: 0.09505552053451538
Validation loss: 1.4109242423888175

Epoch: 6| Step: 2
Training loss: 0.07695714384317398
Validation loss: 1.3938439892184349

Epoch: 6| Step: 3
Training loss: 0.12015074491500854
Validation loss: 1.4110865913411623

Epoch: 6| Step: 4
Training loss: 0.06814512610435486
Validation loss: 1.389197232902691

Epoch: 6| Step: 5
Training loss: 0.06844066083431244
Validation loss: 1.3874118379367295

Epoch: 6| Step: 6
Training loss: 0.08660686016082764
Validation loss: 1.3845087430810417

Epoch: 6| Step: 7
Training loss: 0.0956328958272934
Validation loss: 1.3804237996378252

Epoch: 6| Step: 8
Training loss: 0.11006735265254974
Validation loss: 1.3665138649684128

Epoch: 6| Step: 9
Training loss: 0.13502177596092224
Validation loss: 1.3744872834092827

Epoch: 6| Step: 10
Training loss: 0.11816634237766266
Validation loss: 1.3729453638035765

Epoch: 6| Step: 11
Training loss: 0.15754057466983795
Validation loss: 1.374077558517456

Epoch: 6| Step: 12
Training loss: 0.15189653635025024
Validation loss: 1.3731897672017415

Epoch: 6| Step: 13
Training loss: 0.06899064034223557
Validation loss: 1.385222101724276

Epoch: 387| Step: 0
Training loss: 0.10610403120517731
Validation loss: 1.3845255080089773

Epoch: 6| Step: 1
Training loss: 0.09289447218179703
Validation loss: 1.382844316703017

Epoch: 6| Step: 2
Training loss: 0.11126858741044998
Validation loss: 1.4057695506721415

Epoch: 6| Step: 3
Training loss: 0.08415766060352325
Validation loss: 1.3929082283409693

Epoch: 6| Step: 4
Training loss: 0.15457823872566223
Validation loss: 1.3919776601176108

Epoch: 6| Step: 5
Training loss: 0.10772156715393066
Validation loss: 1.3838784758762648

Epoch: 6| Step: 6
Training loss: 0.09198541939258575
Validation loss: 1.3887742129705285

Epoch: 6| Step: 7
Training loss: 0.18235868215560913
Validation loss: 1.4006835299153482

Epoch: 6| Step: 8
Training loss: 0.11494535207748413
Validation loss: 1.3898329798893263

Epoch: 6| Step: 9
Training loss: 0.08658967912197113
Validation loss: 1.3864329143237042

Epoch: 6| Step: 10
Training loss: 0.0892292708158493
Validation loss: 1.3986683026436837

Epoch: 6| Step: 11
Training loss: 0.07269406318664551
Validation loss: 1.3797754888893456

Epoch: 6| Step: 12
Training loss: 0.13127373158931732
Validation loss: 1.407623944743987

Epoch: 6| Step: 13
Training loss: 0.1610812097787857
Validation loss: 1.3907850391121321

Epoch: 388| Step: 0
Training loss: 0.15121740102767944
Validation loss: 1.3944173544965766

Epoch: 6| Step: 1
Training loss: 0.16430726647377014
Validation loss: 1.3875533009088168

Epoch: 6| Step: 2
Training loss: 0.13566520810127258
Validation loss: 1.3937585757624718

Epoch: 6| Step: 3
Training loss: 0.12901200354099274
Validation loss: 1.4000126982247958

Epoch: 6| Step: 4
Training loss: 0.10643225163221359
Validation loss: 1.3943640660214167

Epoch: 6| Step: 5
Training loss: 0.14094068109989166
Validation loss: 1.3911960791516047

Epoch: 6| Step: 6
Training loss: 0.0733305811882019
Validation loss: 1.3836968816736692

Epoch: 6| Step: 7
Training loss: 0.10626859962940216
Validation loss: 1.3824032352816673

Epoch: 6| Step: 8
Training loss: 0.17757205665111542
Validation loss: 1.3782501771885862

Epoch: 6| Step: 9
Training loss: 0.08844362944364548
Validation loss: 1.3748786289204833

Epoch: 6| Step: 10
Training loss: 0.137643963098526
Validation loss: 1.3661554603166477

Epoch: 6| Step: 11
Training loss: 0.055126551538705826
Validation loss: 1.3850101232528687

Epoch: 6| Step: 12
Training loss: 0.07753876596689224
Validation loss: 1.3997880617777507

Epoch: 6| Step: 13
Training loss: 0.08083495497703552
Validation loss: 1.373947467855228

Epoch: 389| Step: 0
Training loss: 0.07324700057506561
Validation loss: 1.3943666373529742

Epoch: 6| Step: 1
Training loss: 0.08210459351539612
Validation loss: 1.399092351236651

Epoch: 6| Step: 2
Training loss: 0.10499537736177444
Validation loss: 1.4010518238108645

Epoch: 6| Step: 3
Training loss: 0.18826133012771606
Validation loss: 1.4120523352776804

Epoch: 6| Step: 4
Training loss: 0.11003981530666351
Validation loss: 1.401489680813205

Epoch: 6| Step: 5
Training loss: 0.1279274821281433
Validation loss: 1.4128744140748055

Epoch: 6| Step: 6
Training loss: 0.07519322633743286
Validation loss: 1.3972998396042855

Epoch: 6| Step: 7
Training loss: 0.06426709145307541
Validation loss: 1.400270672254665

Epoch: 6| Step: 8
Training loss: 0.10806901007890701
Validation loss: 1.395646882313554

Epoch: 6| Step: 9
Training loss: 0.14303530752658844
Validation loss: 1.3897409721087384

Epoch: 6| Step: 10
Training loss: 0.0555824376642704
Validation loss: 1.4061670207208203

Epoch: 6| Step: 11
Training loss: 0.07457199692726135
Validation loss: 1.3719313452320714

Epoch: 6| Step: 12
Training loss: 0.10629009455442429
Validation loss: 1.405736510471631

Epoch: 6| Step: 13
Training loss: 0.1498519778251648
Validation loss: 1.38246367567329

Epoch: 390| Step: 0
Training loss: 0.12959662079811096
Validation loss: 1.3865485524618497

Epoch: 6| Step: 1
Training loss: 0.13332946598529816
Validation loss: 1.362998983552379

Epoch: 6| Step: 2
Training loss: 0.09382539242506027
Validation loss: 1.3759567878579582

Epoch: 6| Step: 3
Training loss: 0.0729631781578064
Validation loss: 1.3714374810136774

Epoch: 6| Step: 4
Training loss: 0.09897404909133911
Validation loss: 1.3858417452022593

Epoch: 6| Step: 5
Training loss: 0.1296691596508026
Validation loss: 1.4133382484477053

Epoch: 6| Step: 6
Training loss: 0.11133087426424026
Validation loss: 1.383612576351371

Epoch: 6| Step: 7
Training loss: 0.09029939770698547
Validation loss: 1.405500212023335

Epoch: 6| Step: 8
Training loss: 0.08492761850357056
Validation loss: 1.4058426554485033

Epoch: 6| Step: 9
Training loss: 0.06191331148147583
Validation loss: 1.4100806918195499

Epoch: 6| Step: 10
Training loss: 0.07204827666282654
Validation loss: 1.4198685282020158

Epoch: 6| Step: 11
Training loss: 0.11173021793365479
Validation loss: 1.4081051170185048

Epoch: 6| Step: 12
Training loss: 0.07825053483247757
Validation loss: 1.422783117140493

Epoch: 6| Step: 13
Training loss: 0.09065636992454529
Validation loss: 1.3946411404558408

Epoch: 391| Step: 0
Training loss: 0.04662516713142395
Validation loss: 1.3973643036298855

Epoch: 6| Step: 1
Training loss: 0.07294836640357971
Validation loss: 1.4121770121717965

Epoch: 6| Step: 2
Training loss: 0.07809855788946152
Validation loss: 1.406476960387281

Epoch: 6| Step: 3
Training loss: 0.10358066111803055
Validation loss: 1.3837890650636406

Epoch: 6| Step: 4
Training loss: 0.08256983011960983
Validation loss: 1.3782749765662736

Epoch: 6| Step: 5
Training loss: 0.08848495036363602
Validation loss: 1.3704412675672961

Epoch: 6| Step: 6
Training loss: 0.12692388892173767
Validation loss: 1.3795227299454391

Epoch: 6| Step: 7
Training loss: 0.08940576016902924
Validation loss: 1.3887174058985967

Epoch: 6| Step: 8
Training loss: 0.1282268762588501
Validation loss: 1.386738892524473

Epoch: 6| Step: 9
Training loss: 0.17892223596572876
Validation loss: 1.3816478701048

Epoch: 6| Step: 10
Training loss: 0.09806181490421295
Validation loss: 1.4137866522676201

Epoch: 6| Step: 11
Training loss: 0.11427399516105652
Validation loss: 1.3965301949490783

Epoch: 6| Step: 12
Training loss: 0.12253379076719284
Validation loss: 1.4359574266659316

Epoch: 6| Step: 13
Training loss: 0.07361961156129837
Validation loss: 1.4105393937838975

Epoch: 392| Step: 0
Training loss: 0.11089211702346802
Validation loss: 1.4119440240244712

Epoch: 6| Step: 1
Training loss: 0.10336650907993317
Validation loss: 1.4195199012756348

Epoch: 6| Step: 2
Training loss: 0.1315157264471054
Validation loss: 1.4281011012292677

Epoch: 6| Step: 3
Training loss: 0.08612602204084396
Validation loss: 1.4202984302274642

Epoch: 6| Step: 4
Training loss: 0.09497979283332825
Validation loss: 1.4089327781431136

Epoch: 6| Step: 5
Training loss: 0.10888832807540894
Validation loss: 1.3978527213937493

Epoch: 6| Step: 6
Training loss: 0.07017850130796432
Validation loss: 1.4125410574738697

Epoch: 6| Step: 7
Training loss: 0.08272764086723328
Validation loss: 1.4047494049995177

Epoch: 6| Step: 8
Training loss: 0.06585961580276489
Validation loss: 1.384601935263603

Epoch: 6| Step: 9
Training loss: 0.12252621352672577
Validation loss: 1.3706929824685539

Epoch: 6| Step: 10
Training loss: 0.15017986297607422
Validation loss: 1.3740982317155408

Epoch: 6| Step: 11
Training loss: 0.11271017789840698
Validation loss: 1.3825669224544237

Epoch: 6| Step: 12
Training loss: 0.0945451483130455
Validation loss: 1.3680106824444187

Epoch: 6| Step: 13
Training loss: 0.0848020389676094
Validation loss: 1.3730044839202717

Epoch: 393| Step: 0
Training loss: 0.06854245066642761
Validation loss: 1.365966667411148

Epoch: 6| Step: 1
Training loss: 0.11462358385324478
Validation loss: 1.3863647445555656

Epoch: 6| Step: 2
Training loss: 0.06015694886445999
Validation loss: 1.3842926858573832

Epoch: 6| Step: 3
Training loss: 0.10611525177955627
Validation loss: 1.4005865281628025

Epoch: 6| Step: 4
Training loss: 0.12571361660957336
Validation loss: 1.3882446558244768

Epoch: 6| Step: 5
Training loss: 0.11683124303817749
Validation loss: 1.4051546858203026

Epoch: 6| Step: 6
Training loss: 0.07534099370241165
Validation loss: 1.3911411916055987

Epoch: 6| Step: 7
Training loss: 0.06589257717132568
Validation loss: 1.3873266353402087

Epoch: 6| Step: 8
Training loss: 0.07300630211830139
Validation loss: 1.3985977352306407

Epoch: 6| Step: 9
Training loss: 0.14621853828430176
Validation loss: 1.3882541438584686

Epoch: 6| Step: 10
Training loss: 0.09469239413738251
Validation loss: 1.412220117866352

Epoch: 6| Step: 11
Training loss: 0.06910298764705658
Validation loss: 1.4041242266214022

Epoch: 6| Step: 12
Training loss: 0.10431201756000519
Validation loss: 1.4104852702028008

Epoch: 6| Step: 13
Training loss: 0.09857671707868576
Validation loss: 1.3837635049255945

Epoch: 394| Step: 0
Training loss: 0.1371089369058609
Validation loss: 1.399639683385049

Epoch: 6| Step: 1
Training loss: 0.07682930678129196
Validation loss: 1.3828822489707702

Epoch: 6| Step: 2
Training loss: 0.13285548985004425
Validation loss: 1.4116789243554557

Epoch: 6| Step: 3
Training loss: 0.10220023989677429
Validation loss: 1.4064622937992055

Epoch: 6| Step: 4
Training loss: 0.0680084079504013
Validation loss: 1.395567350490119

Epoch: 6| Step: 5
Training loss: 0.08715714514255524
Validation loss: 1.3887914611447243

Epoch: 6| Step: 6
Training loss: 0.0846557468175888
Validation loss: 1.3991408066083026

Epoch: 6| Step: 7
Training loss: 0.1266980618238449
Validation loss: 1.3948131863788893

Epoch: 6| Step: 8
Training loss: 0.08800534904003143
Validation loss: 1.3940259641216648

Epoch: 6| Step: 9
Training loss: 0.08527003973722458
Validation loss: 1.4224670907502532

Epoch: 6| Step: 10
Training loss: 0.06977836787700653
Validation loss: 1.3815259010561052

Epoch: 6| Step: 11
Training loss: 0.11638350784778595
Validation loss: 1.378386870507271

Epoch: 6| Step: 12
Training loss: 0.07006141543388367
Validation loss: 1.3994066305057977

Epoch: 6| Step: 13
Training loss: 0.05356425419449806
Validation loss: 1.3809337885149064

Epoch: 395| Step: 0
Training loss: 0.09688815474510193
Validation loss: 1.3863904463347567

Epoch: 6| Step: 1
Training loss: 0.08318090438842773
Validation loss: 1.3673464123920729

Epoch: 6| Step: 2
Training loss: 0.15142661333084106
Validation loss: 1.3810729019103511

Epoch: 6| Step: 3
Training loss: 0.08355077356100082
Validation loss: 1.3810666786727084

Epoch: 6| Step: 4
Training loss: 0.08826148509979248
Validation loss: 1.3653372846623903

Epoch: 6| Step: 5
Training loss: 0.052364036440849304
Validation loss: 1.3725401973852547

Epoch: 6| Step: 6
Training loss: 0.09116284549236298
Validation loss: 1.3855089884932323

Epoch: 6| Step: 7
Training loss: 0.06368580460548401
Validation loss: 1.3870036089292137

Epoch: 6| Step: 8
Training loss: 0.07394682615995407
Validation loss: 1.385637935771737

Epoch: 6| Step: 9
Training loss: 0.10889814794063568
Validation loss: 1.3942882245586765

Epoch: 6| Step: 10
Training loss: 0.07888025045394897
Validation loss: 1.3626509815134027

Epoch: 6| Step: 11
Training loss: 0.06619247794151306
Validation loss: 1.3767157344407932

Epoch: 6| Step: 12
Training loss: 0.08867046982049942
Validation loss: 1.3993647598451184

Epoch: 6| Step: 13
Training loss: 0.041559502482414246
Validation loss: 1.3929717822741436

Epoch: 396| Step: 0
Training loss: 0.07377470284700394
Validation loss: 1.4041427976341658

Epoch: 6| Step: 1
Training loss: 0.050896041095256805
Validation loss: 1.4079341484654335

Epoch: 6| Step: 2
Training loss: 0.13015997409820557
Validation loss: 1.4204239050547283

Epoch: 6| Step: 3
Training loss: 0.10423118621110916
Validation loss: 1.420856216902374

Epoch: 6| Step: 4
Training loss: 0.15577208995819092
Validation loss: 1.434484443356914

Epoch: 6| Step: 5
Training loss: 0.10069741308689117
Validation loss: 1.411663402793228

Epoch: 6| Step: 6
Training loss: 0.11999563127756119
Validation loss: 1.4091617573973954

Epoch: 6| Step: 7
Training loss: 0.09615910798311234
Validation loss: 1.4047887248377646

Epoch: 6| Step: 8
Training loss: 0.09034755825996399
Validation loss: 1.4032887528019566

Epoch: 6| Step: 9
Training loss: 0.11513756215572357
Validation loss: 1.3779772353428665

Epoch: 6| Step: 10
Training loss: 0.17129042744636536
Validation loss: 1.3806474003740536

Epoch: 6| Step: 11
Training loss: 0.09355047345161438
Validation loss: 1.3764451729354037

Epoch: 6| Step: 12
Training loss: 0.11072492599487305
Validation loss: 1.373340679112301

Epoch: 6| Step: 13
Training loss: 0.0938655436038971
Validation loss: 1.358106404222468

Epoch: 397| Step: 0
Training loss: 0.07366560399532318
Validation loss: 1.3571150161886727

Epoch: 6| Step: 1
Training loss: 0.09996021538972855
Validation loss: 1.3827115553681568

Epoch: 6| Step: 2
Training loss: 0.07257764041423798
Validation loss: 1.3751879597222934

Epoch: 6| Step: 3
Training loss: 0.06123796105384827
Validation loss: 1.3459086546333887

Epoch: 6| Step: 4
Training loss: 0.1009628176689148
Validation loss: 1.349856589430122

Epoch: 6| Step: 5
Training loss: 0.11917325854301453
Validation loss: 1.3607387901634298

Epoch: 6| Step: 6
Training loss: 0.09472468495368958
Validation loss: 1.373170243796482

Epoch: 6| Step: 7
Training loss: 0.10912393778562546
Validation loss: 1.3705154311272405

Epoch: 6| Step: 8
Training loss: 0.08621847629547119
Validation loss: 1.3810858406046385

Epoch: 6| Step: 9
Training loss: 0.07864515483379364
Validation loss: 1.3758251878523058

Epoch: 6| Step: 10
Training loss: 0.14204908907413483
Validation loss: 1.3720266908727667

Epoch: 6| Step: 11
Training loss: 0.0806591659784317
Validation loss: 1.3765875344635339

Epoch: 6| Step: 12
Training loss: 0.09496897459030151
Validation loss: 1.3755165335311685

Epoch: 6| Step: 13
Training loss: 0.12316770106554031
Validation loss: 1.3507710502993675

Epoch: 398| Step: 0
Training loss: 0.06680485606193542
Validation loss: 1.361795404905914

Epoch: 6| Step: 1
Training loss: 0.11113758385181427
Validation loss: 1.3665119653107018

Epoch: 6| Step: 2
Training loss: 0.03569865971803665
Validation loss: 1.3708662935482558

Epoch: 6| Step: 3
Training loss: 0.07933789491653442
Validation loss: 1.3737376274601105

Epoch: 6| Step: 4
Training loss: 0.04992912337183952
Validation loss: 1.3632279672930319

Epoch: 6| Step: 5
Training loss: 0.071299709379673
Validation loss: 1.3868905728863132

Epoch: 6| Step: 6
Training loss: 0.15335363149642944
Validation loss: 1.357466754092965

Epoch: 6| Step: 7
Training loss: 0.09860875457525253
Validation loss: 1.3562616071393412

Epoch: 6| Step: 8
Training loss: 0.06682274490594864
Validation loss: 1.3587929535937566

Epoch: 6| Step: 9
Training loss: 0.10899892449378967
Validation loss: 1.3825285691086964

Epoch: 6| Step: 10
Training loss: 0.10037035495042801
Validation loss: 1.372505904525839

Epoch: 6| Step: 11
Training loss: 0.07406975328922272
Validation loss: 1.3675835658145208

Epoch: 6| Step: 12
Training loss: 0.118622787296772
Validation loss: 1.4176395426514328

Epoch: 6| Step: 13
Training loss: 0.10676555335521698
Validation loss: 1.400896950434613

Epoch: 399| Step: 0
Training loss: 0.09280689805746078
Validation loss: 1.4234972948669105

Epoch: 6| Step: 1
Training loss: 0.09298096597194672
Validation loss: 1.3977627914438966

Epoch: 6| Step: 2
Training loss: 0.09906740486621857
Validation loss: 1.412385000977465

Epoch: 6| Step: 3
Training loss: 0.08517065644264221
Validation loss: 1.4196120705655826

Epoch: 6| Step: 4
Training loss: 0.055440351366996765
Validation loss: 1.4160566015910077

Epoch: 6| Step: 5
Training loss: 0.11206535249948502
Validation loss: 1.4202843776313208

Epoch: 6| Step: 6
Training loss: 0.08070690184831619
Validation loss: 1.4014736465228501

Epoch: 6| Step: 7
Training loss: 0.08923104405403137
Validation loss: 1.4221923633288311

Epoch: 6| Step: 8
Training loss: 0.06019161641597748
Validation loss: 1.4278188245270842

Epoch: 6| Step: 9
Training loss: 0.06494173407554626
Validation loss: 1.4218433550609055

Epoch: 6| Step: 10
Training loss: 0.12059099972248077
Validation loss: 1.42885346053749

Epoch: 6| Step: 11
Training loss: 0.10670501738786697
Validation loss: 1.4225786642361713

Epoch: 6| Step: 12
Training loss: 0.1300155222415924
Validation loss: 1.443883551064358

Epoch: 6| Step: 13
Training loss: 0.07958212494850159
Validation loss: 1.413714986975475

Epoch: 400| Step: 0
Training loss: 0.07958412915468216
Validation loss: 1.421819479234757

Epoch: 6| Step: 1
Training loss: 0.11312945187091827
Validation loss: 1.4145033423618605

Epoch: 6| Step: 2
Training loss: 0.11521248519420624
Validation loss: 1.4005156890038521

Epoch: 6| Step: 3
Training loss: 0.07676499336957932
Validation loss: 1.4053461718302902

Epoch: 6| Step: 4
Training loss: 0.05003868415951729
Validation loss: 1.3946680074097009

Epoch: 6| Step: 5
Training loss: 0.1325853168964386
Validation loss: 1.3800997413614744

Epoch: 6| Step: 6
Training loss: 0.12770603597164154
Validation loss: 1.3919283792536745

Epoch: 6| Step: 7
Training loss: 0.0844779685139656
Validation loss: 1.404840959015713

Epoch: 6| Step: 8
Training loss: 0.06417655199766159
Validation loss: 1.3970498064512848

Epoch: 6| Step: 9
Training loss: 0.07118042558431625
Validation loss: 1.3872257406993578

Epoch: 6| Step: 10
Training loss: 0.07379462569952011
Validation loss: 1.389348139045059

Epoch: 6| Step: 11
Training loss: 0.07336464524269104
Validation loss: 1.3908317358263078

Epoch: 6| Step: 12
Training loss: 0.09221509099006653
Validation loss: 1.3791095915661062

Epoch: 6| Step: 13
Training loss: 0.13363149762153625
Validation loss: 1.3686619817569692

Epoch: 401| Step: 0
Training loss: 0.09276749193668365
Validation loss: 1.4090142852516585

Epoch: 6| Step: 1
Training loss: 0.05437023565173149
Validation loss: 1.3937731481367541

Epoch: 6| Step: 2
Training loss: 0.08760857582092285
Validation loss: 1.3929951476153506

Epoch: 6| Step: 3
Training loss: 0.08478590846061707
Validation loss: 1.4256301618391467

Epoch: 6| Step: 4
Training loss: 0.06945822387933731
Validation loss: 1.409848592614615

Epoch: 6| Step: 5
Training loss: 0.09228349477052689
Validation loss: 1.4163554765844857

Epoch: 6| Step: 6
Training loss: 0.13516291975975037
Validation loss: 1.4348224138700834

Epoch: 6| Step: 7
Training loss: 0.07084581255912781
Validation loss: 1.4401018747719385

Epoch: 6| Step: 8
Training loss: 0.12805837392807007
Validation loss: 1.4339726125040362

Epoch: 6| Step: 9
Training loss: 0.08688048273324966
Validation loss: 1.4072036102253904

Epoch: 6| Step: 10
Training loss: 0.1297004669904709
Validation loss: 1.4205131915307814

Epoch: 6| Step: 11
Training loss: 0.08761028200387955
Validation loss: 1.4279243202619656

Epoch: 6| Step: 12
Training loss: 0.09051661193370819
Validation loss: 1.3964797950560046

Epoch: 6| Step: 13
Training loss: 0.10169491171836853
Validation loss: 1.395717240148975

Epoch: 402| Step: 0
Training loss: 0.09812721610069275
Validation loss: 1.3997441799409929

Epoch: 6| Step: 1
Training loss: 0.1315530687570572
Validation loss: 1.3995476525316957

Epoch: 6| Step: 2
Training loss: 0.12953560054302216
Validation loss: 1.3840211181230442

Epoch: 6| Step: 3
Training loss: 0.07040350139141083
Validation loss: 1.4064490666953466

Epoch: 6| Step: 4
Training loss: 0.11325715482234955
Validation loss: 1.4015158805795895

Epoch: 6| Step: 5
Training loss: 0.05321261286735535
Validation loss: 1.4134030008828768

Epoch: 6| Step: 6
Training loss: 0.11153418570756912
Validation loss: 1.4102167397417047

Epoch: 6| Step: 7
Training loss: 0.07984218001365662
Validation loss: 1.4345061727749404

Epoch: 6| Step: 8
Training loss: 0.07074113190174103
Validation loss: 1.4257691855071692

Epoch: 6| Step: 9
Training loss: 0.11216837167739868
Validation loss: 1.409574918849494

Epoch: 6| Step: 10
Training loss: 0.090211421251297
Validation loss: 1.4123646008071078

Epoch: 6| Step: 11
Training loss: 0.10863178968429565
Validation loss: 1.4164203097743373

Epoch: 6| Step: 12
Training loss: 0.07287504523992538
Validation loss: 1.4033660029852262

Epoch: 6| Step: 13
Training loss: 0.06328749656677246
Validation loss: 1.388656634156422

Epoch: 403| Step: 0
Training loss: 0.06716896593570709
Validation loss: 1.382740439907197

Epoch: 6| Step: 1
Training loss: 0.08734828233718872
Validation loss: 1.3934310187575638

Epoch: 6| Step: 2
Training loss: 0.09314531832933426
Validation loss: 1.4063970632450555

Epoch: 6| Step: 3
Training loss: 0.05039975792169571
Validation loss: 1.3810122025910245

Epoch: 6| Step: 4
Training loss: 0.06686918437480927
Validation loss: 1.3724825792415167

Epoch: 6| Step: 5
Training loss: 0.07159506529569626
Validation loss: 1.3603621285448793

Epoch: 6| Step: 6
Training loss: 0.06542355567216873
Validation loss: 1.3956663557278213

Epoch: 6| Step: 7
Training loss: 0.1472276896238327
Validation loss: 1.3892745946043281

Epoch: 6| Step: 8
Training loss: 0.07659048587083817
Validation loss: 1.3987093612711916

Epoch: 6| Step: 9
Training loss: 0.07229888439178467
Validation loss: 1.4106813707659323

Epoch: 6| Step: 10
Training loss: 0.08060862123966217
Validation loss: 1.3987990566479263

Epoch: 6| Step: 11
Training loss: 0.09054888784885406
Validation loss: 1.3878877291115381

Epoch: 6| Step: 12
Training loss: 0.09486428648233414
Validation loss: 1.4032718661010906

Epoch: 6| Step: 13
Training loss: 0.032290004193782806
Validation loss: 1.40758575418944

Epoch: 404| Step: 0
Training loss: 0.05292285978794098
Validation loss: 1.412953531870278

Epoch: 6| Step: 1
Training loss: 0.0930405855178833
Validation loss: 1.3909081746173162

Epoch: 6| Step: 2
Training loss: 0.061798952519893646
Validation loss: 1.4022227384710824

Epoch: 6| Step: 3
Training loss: 0.09630176424980164
Validation loss: 1.4122500842617405

Epoch: 6| Step: 4
Training loss: 0.11017508059740067
Validation loss: 1.3872928580930155

Epoch: 6| Step: 5
Training loss: 0.10329324752092361
Validation loss: 1.4082897170897453

Epoch: 6| Step: 6
Training loss: 0.06669855117797852
Validation loss: 1.3920663249108098

Epoch: 6| Step: 7
Training loss: 0.0777943804860115
Validation loss: 1.3730522945363035

Epoch: 6| Step: 8
Training loss: 0.06105460226535797
Validation loss: 1.362547222004142

Epoch: 6| Step: 9
Training loss: 0.06557890772819519
Validation loss: 1.385174875938764

Epoch: 6| Step: 10
Training loss: 0.0918772965669632
Validation loss: 1.3500900268554688

Epoch: 6| Step: 11
Training loss: 0.09228849411010742
Validation loss: 1.379235964949413

Epoch: 6| Step: 12
Training loss: 0.11790011823177338
Validation loss: 1.357643642733174

Epoch: 6| Step: 13
Training loss: 0.11635696887969971
Validation loss: 1.3591252783293366

Epoch: 405| Step: 0
Training loss: 0.06536787003278732
Validation loss: 1.3695998807107248

Epoch: 6| Step: 1
Training loss: 0.10311463475227356
Validation loss: 1.344475580479509

Epoch: 6| Step: 2
Training loss: 0.06869454681873322
Validation loss: 1.353105479671109

Epoch: 6| Step: 3
Training loss: 0.08891892433166504
Validation loss: 1.333670425158675

Epoch: 6| Step: 4
Training loss: 0.08127495646476746
Validation loss: 1.334568150581852

Epoch: 6| Step: 5
Training loss: 0.09574534744024277
Validation loss: 1.3525678329570319

Epoch: 6| Step: 6
Training loss: 0.08236557245254517
Validation loss: 1.3464821045116713

Epoch: 6| Step: 7
Training loss: 0.07514648139476776
Validation loss: 1.3492971133160334

Epoch: 6| Step: 8
Training loss: 0.08740631490945816
Validation loss: 1.3536671925616521

Epoch: 6| Step: 9
Training loss: 0.06296107918024063
Validation loss: 1.3471633682968795

Epoch: 6| Step: 10
Training loss: 0.07569718360900879
Validation loss: 1.3472052979212936

Epoch: 6| Step: 11
Training loss: 0.09246362745761871
Validation loss: 1.3453639309893373

Epoch: 6| Step: 12
Training loss: 0.10853581130504608
Validation loss: 1.3716108472116533

Epoch: 6| Step: 13
Training loss: 0.05369942635297775
Validation loss: 1.3397600984060636

Epoch: 406| Step: 0
Training loss: 0.11599792540073395
Validation loss: 1.3625371327964209

Epoch: 6| Step: 1
Training loss: 0.06675177067518234
Validation loss: 1.3744695237887803

Epoch: 6| Step: 2
Training loss: 0.11366131901741028
Validation loss: 1.383786912887327

Epoch: 6| Step: 3
Training loss: 0.07345236092805862
Validation loss: 1.40079576482055

Epoch: 6| Step: 4
Training loss: 0.07249421626329422
Validation loss: 1.3964196200011878

Epoch: 6| Step: 5
Training loss: 0.0658862516283989
Validation loss: 1.3854994363682245

Epoch: 6| Step: 6
Training loss: 0.07571420073509216
Validation loss: 1.3909046419205204

Epoch: 6| Step: 7
Training loss: 0.1079399585723877
Validation loss: 1.4143377055404007

Epoch: 6| Step: 8
Training loss: 0.08680561929941177
Validation loss: 1.4137231214072115

Epoch: 6| Step: 9
Training loss: 0.13154542446136475
Validation loss: 1.4058764519230011

Epoch: 6| Step: 10
Training loss: 0.06002957001328468
Validation loss: 1.4241603100171654

Epoch: 6| Step: 11
Training loss: 0.044648975133895874
Validation loss: 1.4204691328028196

Epoch: 6| Step: 12
Training loss: 0.11277001351118088
Validation loss: 1.413885138368094

Epoch: 6| Step: 13
Training loss: 0.0877828299999237
Validation loss: 1.3934885737716511

Epoch: 407| Step: 0
Training loss: 0.11003116518259048
Validation loss: 1.4073564660164617

Epoch: 6| Step: 1
Training loss: 0.09203752875328064
Validation loss: 1.4027277846490183

Epoch: 6| Step: 2
Training loss: 0.11809705942869186
Validation loss: 1.4035857979969313

Epoch: 6| Step: 3
Training loss: 0.09629736840724945
Validation loss: 1.3994403987802484

Epoch: 6| Step: 4
Training loss: 0.0848088264465332
Validation loss: 1.3903566816801667

Epoch: 6| Step: 5
Training loss: 0.0834784209728241
Validation loss: 1.3939947825606152

Epoch: 6| Step: 6
Training loss: 0.05715402960777283
Validation loss: 1.3939742349809217

Epoch: 6| Step: 7
Training loss: 0.10270380973815918
Validation loss: 1.4006870459484797

Epoch: 6| Step: 8
Training loss: 0.09216408431529999
Validation loss: 1.3937122860262472

Epoch: 6| Step: 9
Training loss: 0.07746686786413193
Validation loss: 1.3776742335288756

Epoch: 6| Step: 10
Training loss: 0.06744322180747986
Validation loss: 1.3697541926496772

Epoch: 6| Step: 11
Training loss: 0.1133497878909111
Validation loss: 1.3697324132406583

Epoch: 6| Step: 12
Training loss: 0.1270969659090042
Validation loss: 1.370729705338837

Epoch: 6| Step: 13
Training loss: 0.17437748610973358
Validation loss: 1.3888748986746675

Epoch: 408| Step: 0
Training loss: 0.06523729860782623
Validation loss: 1.3837152693861274

Epoch: 6| Step: 1
Training loss: 0.08479247242212296
Validation loss: 1.3502269130881115

Epoch: 6| Step: 2
Training loss: 0.07518666237592697
Validation loss: 1.3547205168713805

Epoch: 6| Step: 3
Training loss: 0.10539218783378601
Validation loss: 1.381736974562368

Epoch: 6| Step: 4
Training loss: 0.085450679063797
Validation loss: 1.3522241897480463

Epoch: 6| Step: 5
Training loss: 0.11306132376194
Validation loss: 1.3900198616007322

Epoch: 6| Step: 6
Training loss: 0.11009062081575394
Validation loss: 1.3741790120319655

Epoch: 6| Step: 7
Training loss: 0.07220284640789032
Validation loss: 1.3699727032774238

Epoch: 6| Step: 8
Training loss: 0.09565272182226181
Validation loss: 1.382511487571142

Epoch: 6| Step: 9
Training loss: 0.14580506086349487
Validation loss: 1.3862509919751076

Epoch: 6| Step: 10
Training loss: 0.06554481387138367
Validation loss: 1.3745281991138254

Epoch: 6| Step: 11
Training loss: 0.07682018727064133
Validation loss: 1.3674480722796531

Epoch: 6| Step: 12
Training loss: 0.09516467899084091
Validation loss: 1.3798566505473147

Epoch: 6| Step: 13
Training loss: 0.06301448494195938
Validation loss: 1.3596861836730794

Epoch: 409| Step: 0
Training loss: 0.08221723884344101
Validation loss: 1.3728652487518966

Epoch: 6| Step: 1
Training loss: 0.131270170211792
Validation loss: 1.3796625682102737

Epoch: 6| Step: 2
Training loss: 0.07526829838752747
Validation loss: 1.3678950930154452

Epoch: 6| Step: 3
Training loss: 0.09473492950201035
Validation loss: 1.347329097409402

Epoch: 6| Step: 4
Training loss: 0.07666613906621933
Validation loss: 1.3787127835776216

Epoch: 6| Step: 5
Training loss: 0.05979916453361511
Validation loss: 1.3770538619769517

Epoch: 6| Step: 6
Training loss: 0.06465621292591095
Validation loss: 1.3838430527717835

Epoch: 6| Step: 7
Training loss: 0.06286737322807312
Validation loss: 1.387822446002755

Epoch: 6| Step: 8
Training loss: 0.0645797848701477
Validation loss: 1.3678044811371834

Epoch: 6| Step: 9
Training loss: 0.08503679931163788
Validation loss: 1.3690586884816487

Epoch: 6| Step: 10
Training loss: 0.07181553542613983
Validation loss: 1.375665404463327

Epoch: 6| Step: 11
Training loss: 0.06507942825555801
Validation loss: 1.3866977525013748

Epoch: 6| Step: 12
Training loss: 0.08721975237131119
Validation loss: 1.3939921868744718

Epoch: 6| Step: 13
Training loss: 0.07188884913921356
Validation loss: 1.3999991801477247

Epoch: 410| Step: 0
Training loss: 0.07134255766868591
Validation loss: 1.3999066205434902

Epoch: 6| Step: 1
Training loss: 0.08689001947641373
Validation loss: 1.415071528445008

Epoch: 6| Step: 2
Training loss: 0.13256186246871948
Validation loss: 1.4221734526336833

Epoch: 6| Step: 3
Training loss: 0.06065039336681366
Validation loss: 1.4137152997396325

Epoch: 6| Step: 4
Training loss: 0.10070712864398956
Validation loss: 1.397348560312743

Epoch: 6| Step: 5
Training loss: 0.08196499943733215
Validation loss: 1.3960163631746847

Epoch: 6| Step: 6
Training loss: 0.06099706143140793
Validation loss: 1.3896311662530387

Epoch: 6| Step: 7
Training loss: 0.07094945013523102
Validation loss: 1.3756677553217898

Epoch: 6| Step: 8
Training loss: 0.059807851910591125
Validation loss: 1.3932793909503567

Epoch: 6| Step: 9
Training loss: 0.07615114748477936
Validation loss: 1.3892897790478123

Epoch: 6| Step: 10
Training loss: 0.0602441243827343
Validation loss: 1.3741373996580801

Epoch: 6| Step: 11
Training loss: 0.10978198796510696
Validation loss: 1.3794676475627448

Epoch: 6| Step: 12
Training loss: 0.11758384853601456
Validation loss: 1.3771928997449978

Epoch: 6| Step: 13
Training loss: 0.1444886475801468
Validation loss: 1.382301119066054

Epoch: 411| Step: 0
Training loss: 0.11358755826950073
Validation loss: 1.4071697868326658

Epoch: 6| Step: 1
Training loss: 0.09725181013345718
Validation loss: 1.397564523963518

Epoch: 6| Step: 2
Training loss: 0.06895285099744797
Validation loss: 1.3928927298515075

Epoch: 6| Step: 3
Training loss: 0.11635954678058624
Validation loss: 1.389363977216905

Epoch: 6| Step: 4
Training loss: 0.06925411522388458
Validation loss: 1.3720975934818227

Epoch: 6| Step: 5
Training loss: 0.09541787207126617
Validation loss: 1.3543077053562287

Epoch: 6| Step: 6
Training loss: 0.13238608837127686
Validation loss: 1.3612785198355233

Epoch: 6| Step: 7
Training loss: 0.09372878074645996
Validation loss: 1.3564985593159993

Epoch: 6| Step: 8
Training loss: 0.08612128347158432
Validation loss: 1.3554587594924434

Epoch: 6| Step: 9
Training loss: 0.14178483188152313
Validation loss: 1.3397374358228458

Epoch: 6| Step: 10
Training loss: 0.054169364273548126
Validation loss: 1.349326495201357

Epoch: 6| Step: 11
Training loss: 0.0834730863571167
Validation loss: 1.37307390346322

Epoch: 6| Step: 12
Training loss: 0.09162559360265732
Validation loss: 1.361589768881439

Epoch: 6| Step: 13
Training loss: 0.0422276109457016
Validation loss: 1.3889467921308292

Epoch: 412| Step: 0
Training loss: 0.07488183677196503
Validation loss: 1.3728461624473653

Epoch: 6| Step: 1
Training loss: 0.10833199322223663
Validation loss: 1.368033959660479

Epoch: 6| Step: 2
Training loss: 0.10465292632579803
Validation loss: 1.411889123660262

Epoch: 6| Step: 3
Training loss: 0.12248700857162476
Validation loss: 1.4114548089683696

Epoch: 6| Step: 4
Training loss: 0.08434967696666718
Validation loss: 1.4092734686789974

Epoch: 6| Step: 5
Training loss: 0.10594339668750763
Validation loss: 1.4070687338870058

Epoch: 6| Step: 6
Training loss: 0.11463690549135208
Validation loss: 1.4359763578702045

Epoch: 6| Step: 7
Training loss: 0.07522715628147125
Validation loss: 1.4419150506296465

Epoch: 6| Step: 8
Training loss: 0.05406976118683815
Validation loss: 1.4190698887712212

Epoch: 6| Step: 9
Training loss: 0.08259651064872742
Validation loss: 1.4383690825072668

Epoch: 6| Step: 10
Training loss: 0.14832264184951782
Validation loss: 1.4301820916514243

Epoch: 6| Step: 11
Training loss: 0.15121394395828247
Validation loss: 1.4221015053410684

Epoch: 6| Step: 12
Training loss: 0.09147237241268158
Validation loss: 1.4169250560063187

Epoch: 6| Step: 13
Training loss: 0.0647977739572525
Validation loss: 1.407590409760834

Epoch: 413| Step: 0
Training loss: 0.08032718300819397
Validation loss: 1.4096727435306837

Epoch: 6| Step: 1
Training loss: 0.12042292952537537
Validation loss: 1.3977002386123902

Epoch: 6| Step: 2
Training loss: 0.09601258486509323
Validation loss: 1.4164448207424534

Epoch: 6| Step: 3
Training loss: 0.17129074037075043
Validation loss: 1.396560162626287

Epoch: 6| Step: 4
Training loss: 0.06472515314817429
Validation loss: 1.4450052938153666

Epoch: 6| Step: 5
Training loss: 0.08201530575752258
Validation loss: 1.4332652348344044

Epoch: 6| Step: 6
Training loss: 0.08446735143661499
Validation loss: 1.4186726129183205

Epoch: 6| Step: 7
Training loss: 0.06386109441518784
Validation loss: 1.4158416448100921

Epoch: 6| Step: 8
Training loss: 0.0905122235417366
Validation loss: 1.4047413320951565

Epoch: 6| Step: 9
Training loss: 0.08859630674123764
Validation loss: 1.383276803519136

Epoch: 6| Step: 10
Training loss: 0.09690600633621216
Validation loss: 1.3706908508013653

Epoch: 6| Step: 11
Training loss: 0.15821732580661774
Validation loss: 1.3750095136703984

Epoch: 6| Step: 12
Training loss: 0.1181129440665245
Validation loss: 1.381420107298

Epoch: 6| Step: 13
Training loss: 0.09925411641597748
Validation loss: 1.3395484570533998

Epoch: 414| Step: 0
Training loss: 0.11728338152170181
Validation loss: 1.3634373846874441

Epoch: 6| Step: 1
Training loss: 0.0946846455335617
Validation loss: 1.3743345276001961

Epoch: 6| Step: 2
Training loss: 0.08652336150407791
Validation loss: 1.3762995261017994

Epoch: 6| Step: 3
Training loss: 0.07048638164997101
Validation loss: 1.4201074774547289

Epoch: 6| Step: 4
Training loss: 0.10536466538906097
Validation loss: 1.39935222107877

Epoch: 6| Step: 5
Training loss: 0.10801099985837936
Validation loss: 1.391870969085283

Epoch: 6| Step: 6
Training loss: 0.08026102930307388
Validation loss: 1.3984398649584862

Epoch: 6| Step: 7
Training loss: 0.14966708421707153
Validation loss: 1.3944945630206858

Epoch: 6| Step: 8
Training loss: 0.09430345147848129
Validation loss: 1.3596050303469422

Epoch: 6| Step: 9
Training loss: 0.10145753622055054
Validation loss: 1.3536414465596598

Epoch: 6| Step: 10
Training loss: 0.10596878826618195
Validation loss: 1.3748816777301092

Epoch: 6| Step: 11
Training loss: 0.17216692864894867
Validation loss: 1.337141183114821

Epoch: 6| Step: 12
Training loss: 0.08161961287260056
Validation loss: 1.3568298124497937

Epoch: 6| Step: 13
Training loss: 0.12717628479003906
Validation loss: 1.339033289622235

Epoch: 415| Step: 0
Training loss: 0.09247152507305145
Validation loss: 1.3138150540731286

Epoch: 6| Step: 1
Training loss: 0.11554259061813354
Validation loss: 1.3408192184663588

Epoch: 6| Step: 2
Training loss: 0.08925525844097137
Validation loss: 1.3368217240097702

Epoch: 6| Step: 3
Training loss: 0.10856795310974121
Validation loss: 1.34253183872469

Epoch: 6| Step: 4
Training loss: 0.06065646559000015
Validation loss: 1.3487806550918087

Epoch: 6| Step: 5
Training loss: 0.12696205079555511
Validation loss: 1.364486862254399

Epoch: 6| Step: 6
Training loss: 0.08806288242340088
Validation loss: 1.3753884274472472

Epoch: 6| Step: 7
Training loss: 0.12069625407457352
Validation loss: 1.3605083829613143

Epoch: 6| Step: 8
Training loss: 0.08508298546075821
Validation loss: 1.3790428958913332

Epoch: 6| Step: 9
Training loss: 0.08829208463430405
Validation loss: 1.3768203578969485

Epoch: 6| Step: 10
Training loss: 0.11418306827545166
Validation loss: 1.3681283830314555

Epoch: 6| Step: 11
Training loss: 0.11112135648727417
Validation loss: 1.3808659456109489

Epoch: 6| Step: 12
Training loss: 0.075607530772686
Validation loss: 1.4013870198239562

Epoch: 6| Step: 13
Training loss: 0.127176895737648
Validation loss: 1.3975197102433892

Epoch: 416| Step: 0
Training loss: 0.13082724809646606
Validation loss: 1.4126537801117025

Epoch: 6| Step: 1
Training loss: 0.12398744374513626
Validation loss: 1.4027695143094627

Epoch: 6| Step: 2
Training loss: 0.05592421442270279
Validation loss: 1.403322337776102

Epoch: 6| Step: 3
Training loss: 0.09418192505836487
Validation loss: 1.3946136800191735

Epoch: 6| Step: 4
Training loss: 0.11863747239112854
Validation loss: 1.423619859962053

Epoch: 6| Step: 5
Training loss: 0.10312514752149582
Validation loss: 1.4206453279782367

Epoch: 6| Step: 6
Training loss: 0.14172513782978058
Validation loss: 1.4003466521539996

Epoch: 6| Step: 7
Training loss: 0.07594095915555954
Validation loss: 1.3476146741579937

Epoch: 6| Step: 8
Training loss: 0.09549736976623535
Validation loss: 1.3688899246595239

Epoch: 6| Step: 9
Training loss: 0.10665164142847061
Validation loss: 1.352898354812335

Epoch: 6| Step: 10
Training loss: 0.060127925127744675
Validation loss: 1.3638892263494513

Epoch: 6| Step: 11
Training loss: 0.06350183486938477
Validation loss: 1.3520128239867508

Epoch: 6| Step: 12
Training loss: 0.0753784105181694
Validation loss: 1.3633781536932914

Epoch: 6| Step: 13
Training loss: 0.08283005654811859
Validation loss: 1.3457607325687204

Epoch: 417| Step: 0
Training loss: 0.13599586486816406
Validation loss: 1.372562837857072

Epoch: 6| Step: 1
Training loss: 0.08779245615005493
Validation loss: 1.3569154841925508

Epoch: 6| Step: 2
Training loss: 0.07597345113754272
Validation loss: 1.3519240156296761

Epoch: 6| Step: 3
Training loss: 0.07292395085096359
Validation loss: 1.359419233055525

Epoch: 6| Step: 4
Training loss: 0.06948363780975342
Validation loss: 1.3423377333148834

Epoch: 6| Step: 5
Training loss: 0.0731533020734787
Validation loss: 1.3408143366536787

Epoch: 6| Step: 6
Training loss: 0.07547255605459213
Validation loss: 1.3727132927986883

Epoch: 6| Step: 7
Training loss: 0.10807471722364426
Validation loss: 1.3525149924780733

Epoch: 6| Step: 8
Training loss: 0.04602670669555664
Validation loss: 1.3659923050993232

Epoch: 6| Step: 9
Training loss: 0.13859757781028748
Validation loss: 1.3664934763344385

Epoch: 6| Step: 10
Training loss: 0.10044488310813904
Validation loss: 1.374559337092984

Epoch: 6| Step: 11
Training loss: 0.09937272220849991
Validation loss: 1.3833896101161998

Epoch: 6| Step: 12
Training loss: 0.0852147564291954
Validation loss: 1.3960382643566336

Epoch: 6| Step: 13
Training loss: 0.12549172341823578
Validation loss: 1.3946199250477616

Epoch: 418| Step: 0
Training loss: 0.055853743106126785
Validation loss: 1.3509944279988606

Epoch: 6| Step: 1
Training loss: 0.0618671216070652
Validation loss: 1.37048977164812

Epoch: 6| Step: 2
Training loss: 0.09129833430051804
Validation loss: 1.355055893621137

Epoch: 6| Step: 3
Training loss: 0.07418793439865112
Validation loss: 1.3567123759177424

Epoch: 6| Step: 4
Training loss: 0.09338654577732086
Validation loss: 1.3504816960262995

Epoch: 6| Step: 5
Training loss: 0.05740899220108986
Validation loss: 1.367740023520685

Epoch: 6| Step: 6
Training loss: 0.1056588739156723
Validation loss: 1.3554158326118224

Epoch: 6| Step: 7
Training loss: 0.07199692726135254
Validation loss: 1.3574960789372843

Epoch: 6| Step: 8
Training loss: 0.08929301798343658
Validation loss: 1.3710265236516153

Epoch: 6| Step: 9
Training loss: 0.047955144196748734
Validation loss: 1.3460381031036377

Epoch: 6| Step: 10
Training loss: 0.11235187947750092
Validation loss: 1.362781245221374

Epoch: 6| Step: 11
Training loss: 0.12701155245304108
Validation loss: 1.3545541449259686

Epoch: 6| Step: 12
Training loss: 0.10096147656440735
Validation loss: 1.3594252922201668

Epoch: 6| Step: 13
Training loss: 0.061536651104688644
Validation loss: 1.3433908583015524

Epoch: 419| Step: 0
Training loss: 0.1070074737071991
Validation loss: 1.352598367198821

Epoch: 6| Step: 1
Training loss: 0.0786903128027916
Validation loss: 1.3504478328971452

Epoch: 6| Step: 2
Training loss: 0.0715733990073204
Validation loss: 1.3326319533009683

Epoch: 6| Step: 3
Training loss: 0.15567266941070557
Validation loss: 1.331518457781884

Epoch: 6| Step: 4
Training loss: 0.11742697656154633
Validation loss: 1.3110900527687483

Epoch: 6| Step: 5
Training loss: 0.07146681100130081
Validation loss: 1.3240217906172558

Epoch: 6| Step: 6
Training loss: 0.10292542725801468
Validation loss: 1.3345176865977626

Epoch: 6| Step: 7
Training loss: 0.06862121820449829
Validation loss: 1.3099398164338962

Epoch: 6| Step: 8
Training loss: 0.06971247494220734
Validation loss: 1.3405697473915674

Epoch: 6| Step: 9
Training loss: 0.08242742717266083
Validation loss: 1.3275994023969095

Epoch: 6| Step: 10
Training loss: 0.06894087791442871
Validation loss: 1.3283240384952997

Epoch: 6| Step: 11
Training loss: 0.05829646438360214
Validation loss: 1.3313133498673797

Epoch: 6| Step: 12
Training loss: 0.08255422115325928
Validation loss: 1.3370089101535019

Epoch: 6| Step: 13
Training loss: 0.0762953907251358
Validation loss: 1.3307580428738748

Epoch: 420| Step: 0
Training loss: 0.08671681582927704
Validation loss: 1.3326439069163414

Epoch: 6| Step: 1
Training loss: 0.082781121134758
Validation loss: 1.3660483539745372

Epoch: 6| Step: 2
Training loss: 0.12173306941986084
Validation loss: 1.352649091392435

Epoch: 6| Step: 3
Training loss: 0.06890140473842621
Validation loss: 1.362024381596555

Epoch: 6| Step: 4
Training loss: 0.1384255439043045
Validation loss: 1.3656619338579075

Epoch: 6| Step: 5
Training loss: 0.07263703644275665
Validation loss: 1.3809910076920704

Epoch: 6| Step: 6
Training loss: 0.09062929451465607
Validation loss: 1.3640088073668941

Epoch: 6| Step: 7
Training loss: 0.09000222384929657
Validation loss: 1.3641202539526007

Epoch: 6| Step: 8
Training loss: 0.06238073483109474
Validation loss: 1.3612726478166477

Epoch: 6| Step: 9
Training loss: 0.07604505121707916
Validation loss: 1.367869129744909

Epoch: 6| Step: 10
Training loss: 0.06974361836910248
Validation loss: 1.343527591356667

Epoch: 6| Step: 11
Training loss: 0.10351651161909103
Validation loss: 1.3663862238648117

Epoch: 6| Step: 12
Training loss: 0.06863066554069519
Validation loss: 1.3635030600332445

Epoch: 6| Step: 13
Training loss: 0.10452508926391602
Validation loss: 1.3582165984697239

Epoch: 421| Step: 0
Training loss: 0.09461706876754761
Validation loss: 1.376026084987066

Epoch: 6| Step: 1
Training loss: 0.07184819877147675
Validation loss: 1.3940943569265387

Epoch: 6| Step: 2
Training loss: 0.11638028174638748
Validation loss: 1.4120566832121981

Epoch: 6| Step: 3
Training loss: 0.1451842039823532
Validation loss: 1.4216938223890079

Epoch: 6| Step: 4
Training loss: 0.10851732641458511
Validation loss: 1.4004102804327523

Epoch: 6| Step: 5
Training loss: 0.12520432472229004
Validation loss: 1.3998043383321455

Epoch: 6| Step: 6
Training loss: 0.055659182369709015
Validation loss: 1.3833022604706466

Epoch: 6| Step: 7
Training loss: 0.07328608632087708
Validation loss: 1.3603286755982267

Epoch: 6| Step: 8
Training loss: 0.13033227622509003
Validation loss: 1.3709662191329464

Epoch: 6| Step: 9
Training loss: 0.1468009501695633
Validation loss: 1.357086311104477

Epoch: 6| Step: 10
Training loss: 0.20141908526420593
Validation loss: 1.3611742475981354

Epoch: 6| Step: 11
Training loss: 0.07641346752643585
Validation loss: 1.3611745334440661

Epoch: 6| Step: 12
Training loss: 0.05510163679718971
Validation loss: 1.368180819737014

Epoch: 6| Step: 13
Training loss: 0.07822052389383316
Validation loss: 1.3899039773530857

Epoch: 422| Step: 0
Training loss: 0.1134771779179573
Validation loss: 1.3728122339453748

Epoch: 6| Step: 1
Training loss: 0.08129514008760452
Validation loss: 1.3834901971201743

Epoch: 6| Step: 2
Training loss: 0.1737636923789978
Validation loss: 1.3795376464884768

Epoch: 6| Step: 3
Training loss: 0.10451391339302063
Validation loss: 1.3786039147325742

Epoch: 6| Step: 4
Training loss: 0.09872390329837799
Validation loss: 1.3719704933063959

Epoch: 6| Step: 5
Training loss: 0.10141399502754211
Validation loss: 1.3550595775727303

Epoch: 6| Step: 6
Training loss: 0.06024518981575966
Validation loss: 1.3465277879468855

Epoch: 6| Step: 7
Training loss: 0.09844228625297546
Validation loss: 1.3739756243203276

Epoch: 6| Step: 8
Training loss: 0.08069606125354767
Validation loss: 1.3920879248649842

Epoch: 6| Step: 9
Training loss: 0.09592237323522568
Validation loss: 1.3594425051443038

Epoch: 6| Step: 10
Training loss: 0.08209739625453949
Validation loss: 1.3841245328226397

Epoch: 6| Step: 11
Training loss: 0.10443051159381866
Validation loss: 1.3795143506860221

Epoch: 6| Step: 12
Training loss: 0.06663243472576141
Validation loss: 1.374874613618338

Epoch: 6| Step: 13
Training loss: 0.12360731512308121
Validation loss: 1.3535329577743367

Epoch: 423| Step: 0
Training loss: 0.0714147686958313
Validation loss: 1.3622120394501636

Epoch: 6| Step: 1
Training loss: 0.08041086792945862
Validation loss: 1.3432757303278933

Epoch: 6| Step: 2
Training loss: 0.12674207985401154
Validation loss: 1.357153264425134

Epoch: 6| Step: 3
Training loss: 0.047049082815647125
Validation loss: 1.3358055289073656

Epoch: 6| Step: 4
Training loss: 0.11552010476589203
Validation loss: 1.3469324073483866

Epoch: 6| Step: 5
Training loss: 0.08631594479084015
Validation loss: 1.358700518967003

Epoch: 6| Step: 6
Training loss: 0.09512222558259964
Validation loss: 1.338861729509087

Epoch: 6| Step: 7
Training loss: 0.10611487925052643
Validation loss: 1.3349971399512341

Epoch: 6| Step: 8
Training loss: 0.11443521082401276
Validation loss: 1.349839803993061

Epoch: 6| Step: 9
Training loss: 0.10505218058824539
Validation loss: 1.371913907989379

Epoch: 6| Step: 10
Training loss: 0.09836311638355255
Validation loss: 1.3592460604124172

Epoch: 6| Step: 11
Training loss: 0.061387814581394196
Validation loss: 1.3872613394132225

Epoch: 6| Step: 12
Training loss: 0.12580181658267975
Validation loss: 1.3779594154768093

Epoch: 6| Step: 13
Training loss: 0.1534944772720337
Validation loss: 1.3758576018835909

Epoch: 424| Step: 0
Training loss: 0.1060926616191864
Validation loss: 1.3664778163356166

Epoch: 6| Step: 1
Training loss: 0.06538055837154388
Validation loss: 1.3419845578491048

Epoch: 6| Step: 2
Training loss: 0.07596191763877869
Validation loss: 1.360426527197643

Epoch: 6| Step: 3
Training loss: 0.09340059757232666
Validation loss: 1.340309489157892

Epoch: 6| Step: 4
Training loss: 0.10742608457803726
Validation loss: 1.3500259076395342

Epoch: 6| Step: 5
Training loss: 0.07104022800922394
Validation loss: 1.3231638913513513

Epoch: 6| Step: 6
Training loss: 0.09676946699619293
Validation loss: 1.3259268768372074

Epoch: 6| Step: 7
Training loss: 0.08498158305883408
Validation loss: 1.3285036163945352

Epoch: 6| Step: 8
Training loss: 0.09296441823244095
Validation loss: 1.3283899830233665

Epoch: 6| Step: 9
Training loss: 0.06665506958961487
Validation loss: 1.3197554349899292

Epoch: 6| Step: 10
Training loss: 0.10608388483524323
Validation loss: 1.3345275405914552

Epoch: 6| Step: 11
Training loss: 0.08882346004247665
Validation loss: 1.333267254214133

Epoch: 6| Step: 12
Training loss: 0.08440665900707245
Validation loss: 1.3202771230410504

Epoch: 6| Step: 13
Training loss: 0.13482266664505005
Validation loss: 1.3411120958225702

Epoch: 425| Step: 0
Training loss: 0.06231044977903366
Validation loss: 1.3408791070343347

Epoch: 6| Step: 1
Training loss: 0.08072154968976974
Validation loss: 1.3324734510913971

Epoch: 6| Step: 2
Training loss: 0.07740593701601028
Validation loss: 1.3363860986566032

Epoch: 6| Step: 3
Training loss: 0.05738305673003197
Validation loss: 1.3341401206549777

Epoch: 6| Step: 4
Training loss: 0.08810116350650787
Validation loss: 1.3364997730460217

Epoch: 6| Step: 5
Training loss: 0.10253530740737915
Validation loss: 1.3554560112696823

Epoch: 6| Step: 6
Training loss: 0.04176957160234451
Validation loss: 1.357844275812949

Epoch: 6| Step: 7
Training loss: 0.06767716258764267
Validation loss: 1.3409943875446115

Epoch: 6| Step: 8
Training loss: 0.07235825806856155
Validation loss: 1.361197365227566

Epoch: 6| Step: 9
Training loss: 0.09198638051748276
Validation loss: 1.3673473391481625

Epoch: 6| Step: 10
Training loss: 0.06391426920890808
Validation loss: 1.367973590409884

Epoch: 6| Step: 11
Training loss: 0.13579142093658447
Validation loss: 1.3713064847453948

Epoch: 6| Step: 12
Training loss: 0.07895898818969727
Validation loss: 1.365530910030488

Epoch: 6| Step: 13
Training loss: 0.1246027946472168
Validation loss: 1.3784824827665925

Epoch: 426| Step: 0
Training loss: 0.06193364039063454
Validation loss: 1.3722351199837142

Epoch: 6| Step: 1
Training loss: 0.1168486550450325
Validation loss: 1.3782927400322371

Epoch: 6| Step: 2
Training loss: 0.0696716234087944
Validation loss: 1.358631262215235

Epoch: 6| Step: 3
Training loss: 0.07818043977022171
Validation loss: 1.3599303441662942

Epoch: 6| Step: 4
Training loss: 0.06904909014701843
Validation loss: 1.3762156835166357

Epoch: 6| Step: 5
Training loss: 0.04895581677556038
Validation loss: 1.3928427170681696

Epoch: 6| Step: 6
Training loss: 0.08163227140903473
Validation loss: 1.3583367434881066

Epoch: 6| Step: 7
Training loss: 0.07754617184400558
Validation loss: 1.3855874922967726

Epoch: 6| Step: 8
Training loss: 0.07844698429107666
Validation loss: 1.381865066866721

Epoch: 6| Step: 9
Training loss: 0.10628560185432434
Validation loss: 1.3829033977241927

Epoch: 6| Step: 10
Training loss: 0.06352224946022034
Validation loss: 1.4133603021662722

Epoch: 6| Step: 11
Training loss: 0.0966266393661499
Validation loss: 1.3892032202853952

Epoch: 6| Step: 12
Training loss: 0.09691592305898666
Validation loss: 1.399417963079227

Epoch: 6| Step: 13
Training loss: 0.08341360092163086
Validation loss: 1.3692057145539152

Epoch: 427| Step: 0
Training loss: 0.07962802052497864
Validation loss: 1.3607747195869364

Epoch: 6| Step: 1
Training loss: 0.07257212698459625
Validation loss: 1.3592589798793997

Epoch: 6| Step: 2
Training loss: 0.0840453952550888
Validation loss: 1.3680812133255826

Epoch: 6| Step: 3
Training loss: 0.06570126116275787
Validation loss: 1.3631721465818343

Epoch: 6| Step: 4
Training loss: 0.10118745267391205
Validation loss: 1.3734214818605812

Epoch: 6| Step: 5
Training loss: 0.0811527892947197
Validation loss: 1.3778048965238756

Epoch: 6| Step: 6
Training loss: 0.11190694570541382
Validation loss: 1.3911560376485188

Epoch: 6| Step: 7
Training loss: 0.09092532098293304
Validation loss: 1.3933395660051735

Epoch: 6| Step: 8
Training loss: 0.10115034878253937
Validation loss: 1.3860308124173073

Epoch: 6| Step: 9
Training loss: 0.06631670892238617
Validation loss: 1.3814270893732707

Epoch: 6| Step: 10
Training loss: 0.09874336421489716
Validation loss: 1.3933399172239407

Epoch: 6| Step: 11
Training loss: 0.12446889281272888
Validation loss: 1.3966253213984992

Epoch: 6| Step: 12
Training loss: 0.10160881280899048
Validation loss: 1.3829702369628414

Epoch: 6| Step: 13
Training loss: 0.05613458901643753
Validation loss: 1.3960830748722117

Epoch: 428| Step: 0
Training loss: 0.05662751942873001
Validation loss: 1.3738834011939265

Epoch: 6| Step: 1
Training loss: 0.09395520389080048
Validation loss: 1.377704240942514

Epoch: 6| Step: 2
Training loss: 0.14266972243785858
Validation loss: 1.3781282171126334

Epoch: 6| Step: 3
Training loss: 0.09135912358760834
Validation loss: 1.3894694543653918

Epoch: 6| Step: 4
Training loss: 0.05925372242927551
Validation loss: 1.3731958045754382

Epoch: 6| Step: 5
Training loss: 0.06626468896865845
Validation loss: 1.4083565294101674

Epoch: 6| Step: 6
Training loss: 0.07794118672609329
Validation loss: 1.3936215280204691

Epoch: 6| Step: 7
Training loss: 0.07292137295007706
Validation loss: 1.4030800820678793

Epoch: 6| Step: 8
Training loss: 0.10854023694992065
Validation loss: 1.4001996619727022

Epoch: 6| Step: 9
Training loss: 0.08819615840911865
Validation loss: 1.3983275057167135

Epoch: 6| Step: 10
Training loss: 0.06887856125831604
Validation loss: 1.3848011980774582

Epoch: 6| Step: 11
Training loss: 0.0834825336933136
Validation loss: 1.387632437931594

Epoch: 6| Step: 12
Training loss: 0.07900755107402802
Validation loss: 1.3794551523782874

Epoch: 6| Step: 13
Training loss: 0.03436554968357086
Validation loss: 1.3836944487787062

Epoch: 429| Step: 0
Training loss: 0.0714985653758049
Validation loss: 1.3683223288546327

Epoch: 6| Step: 1
Training loss: 0.06889375299215317
Validation loss: 1.3562346376398557

Epoch: 6| Step: 2
Training loss: 0.04791094362735748
Validation loss: 1.3605515085240847

Epoch: 6| Step: 3
Training loss: 0.09886054694652557
Validation loss: 1.3437667098096622

Epoch: 6| Step: 4
Training loss: 0.09275147318840027
Validation loss: 1.3337812744161135

Epoch: 6| Step: 5
Training loss: 0.10280121862888336
Validation loss: 1.3558456705462547

Epoch: 6| Step: 6
Training loss: 0.11879178881645203
Validation loss: 1.3533341807703818

Epoch: 6| Step: 7
Training loss: 0.0973680168390274
Validation loss: 1.3786564360382736

Epoch: 6| Step: 8
Training loss: 0.16668297350406647
Validation loss: 1.3612276123416038

Epoch: 6| Step: 9
Training loss: 0.10707663744688034
Validation loss: 1.4098660522891628

Epoch: 6| Step: 10
Training loss: 0.09689243137836456
Validation loss: 1.4014519094139017

Epoch: 6| Step: 11
Training loss: 0.09423603862524033
Validation loss: 1.4125453002991215

Epoch: 6| Step: 12
Training loss: 0.06642933934926987
Validation loss: 1.3930906634176932

Epoch: 6| Step: 13
Training loss: 0.14120472967624664
Validation loss: 1.4106882426046556

Epoch: 430| Step: 0
Training loss: 0.10834434628486633
Validation loss: 1.4270214111574235

Epoch: 6| Step: 1
Training loss: 0.09641974419355392
Validation loss: 1.4218973998100526

Epoch: 6| Step: 2
Training loss: 0.06962612271308899
Validation loss: 1.4056635518227854

Epoch: 6| Step: 3
Training loss: 0.07774905115365982
Validation loss: 1.402031748525558

Epoch: 6| Step: 4
Training loss: 0.08911657333374023
Validation loss: 1.3984605407202115

Epoch: 6| Step: 5
Training loss: 0.04302731901407242
Validation loss: 1.3864778011075911

Epoch: 6| Step: 6
Training loss: 0.1143895760178566
Validation loss: 1.3881159219690549

Epoch: 6| Step: 7
Training loss: 0.11121058464050293
Validation loss: 1.4089430980784918

Epoch: 6| Step: 8
Training loss: 0.10957737267017365
Validation loss: 1.384521117133479

Epoch: 6| Step: 9
Training loss: 0.05944210663437843
Validation loss: 1.3858527393751248

Epoch: 6| Step: 10
Training loss: 0.08803309500217438
Validation loss: 1.3718503598243958

Epoch: 6| Step: 11
Training loss: 0.07982112467288971
Validation loss: 1.3834449642448015

Epoch: 6| Step: 12
Training loss: 0.09602797031402588
Validation loss: 1.3942720531135477

Epoch: 6| Step: 13
Training loss: 0.04174422845244408
Validation loss: 1.3890560775674798

Epoch: 431| Step: 0
Training loss: 0.07529182732105255
Validation loss: 1.389002409032596

Epoch: 6| Step: 1
Training loss: 0.11519414186477661
Validation loss: 1.3519794056492467

Epoch: 6| Step: 2
Training loss: 0.07769649475812912
Validation loss: 1.3897768265457564

Epoch: 6| Step: 3
Training loss: 0.04532891511917114
Validation loss: 1.3639267811211206

Epoch: 6| Step: 4
Training loss: 0.1344432532787323
Validation loss: 1.371236652456304

Epoch: 6| Step: 5
Training loss: 0.05310982093214989
Validation loss: 1.3723527737843093

Epoch: 6| Step: 6
Training loss: 0.06978736072778702
Validation loss: 1.3696504382676975

Epoch: 6| Step: 7
Training loss: 0.1286223977804184
Validation loss: 1.3828788329196233

Epoch: 6| Step: 8
Training loss: 0.09482920169830322
Validation loss: 1.3757955822893368

Epoch: 6| Step: 9
Training loss: 0.04836954176425934
Validation loss: 1.4076774376694874

Epoch: 6| Step: 10
Training loss: 0.06331051141023636
Validation loss: 1.386502085193511

Epoch: 6| Step: 11
Training loss: 0.07907460629940033
Validation loss: 1.4060110558745682

Epoch: 6| Step: 12
Training loss: 0.1317591667175293
Validation loss: 1.4125320026951451

Epoch: 6| Step: 13
Training loss: 0.08628955483436584
Validation loss: 1.4043075269268406

Epoch: 432| Step: 0
Training loss: 0.08602796494960785
Validation loss: 1.4011645970806

Epoch: 6| Step: 1
Training loss: 0.06733813881874084
Validation loss: 1.4028011393803421

Epoch: 6| Step: 2
Training loss: 0.07580453902482986
Validation loss: 1.394894120513752

Epoch: 6| Step: 3
Training loss: 0.055818356573581696
Validation loss: 1.393334875824631

Epoch: 6| Step: 4
Training loss: 0.09173507988452911
Validation loss: 1.3856901058586695

Epoch: 6| Step: 5
Training loss: 0.09064163267612457
Validation loss: 1.3832475985250166

Epoch: 6| Step: 6
Training loss: 0.06234239414334297
Validation loss: 1.4001436874430666

Epoch: 6| Step: 7
Training loss: 0.09163904190063477
Validation loss: 1.3928622622643747

Epoch: 6| Step: 8
Training loss: 0.10221686959266663
Validation loss: 1.3850663426101848

Epoch: 6| Step: 9
Training loss: 0.08310693502426147
Validation loss: 1.3885753821301203

Epoch: 6| Step: 10
Training loss: 0.10088694095611572
Validation loss: 1.3929507168390418

Epoch: 6| Step: 11
Training loss: 0.09904399514198303
Validation loss: 1.4075101729362243

Epoch: 6| Step: 12
Training loss: 0.06504102796316147
Validation loss: 1.374053314167966

Epoch: 6| Step: 13
Training loss: 0.07996626198291779
Validation loss: 1.3953196348682526

Epoch: 433| Step: 0
Training loss: 0.07593683898448944
Validation loss: 1.3824991154414352

Epoch: 6| Step: 1
Training loss: 0.07049550116062164
Validation loss: 1.3712918854528857

Epoch: 6| Step: 2
Training loss: 0.06636263430118561
Validation loss: 1.338606535747487

Epoch: 6| Step: 3
Training loss: 0.0662984549999237
Validation loss: 1.3541252625885831

Epoch: 6| Step: 4
Training loss: 0.044005073606967926
Validation loss: 1.3532211524184032

Epoch: 6| Step: 5
Training loss: 0.060522835701704025
Validation loss: 1.3542924875854163

Epoch: 6| Step: 6
Training loss: 0.09677217155694962
Validation loss: 1.3407298954584266

Epoch: 6| Step: 7
Training loss: 0.10263435542583466
Validation loss: 1.3135352185977403

Epoch: 6| Step: 8
Training loss: 0.12690585851669312
Validation loss: 1.3316776239743797

Epoch: 6| Step: 9
Training loss: 0.07638872414827347
Validation loss: 1.3140796954913805

Epoch: 6| Step: 10
Training loss: 0.07916882634162903
Validation loss: 1.3411159182107577

Epoch: 6| Step: 11
Training loss: 0.06434863060712814
Validation loss: 1.3284066389965754

Epoch: 6| Step: 12
Training loss: 0.12731564044952393
Validation loss: 1.3604640012146325

Epoch: 6| Step: 13
Training loss: 0.051508452743291855
Validation loss: 1.3599110329022972

Epoch: 434| Step: 0
Training loss: 0.07866373658180237
Validation loss: 1.3837575784293554

Epoch: 6| Step: 1
Training loss: 0.10610684007406235
Validation loss: 1.4020881601559219

Epoch: 6| Step: 2
Training loss: 0.06839102506637573
Validation loss: 1.3695764580080587

Epoch: 6| Step: 3
Training loss: 0.08251826465129852
Validation loss: 1.4208651857991372

Epoch: 6| Step: 4
Training loss: 0.054627951234579086
Validation loss: 1.379684918349789

Epoch: 6| Step: 5
Training loss: 0.0688309296965599
Validation loss: 1.3938934777372627

Epoch: 6| Step: 6
Training loss: 0.07317319512367249
Validation loss: 1.388863246287069

Epoch: 6| Step: 7
Training loss: 0.0719948410987854
Validation loss: 1.3953076575392036

Epoch: 6| Step: 8
Training loss: 0.06563149392604828
Validation loss: 1.3607624128300657

Epoch: 6| Step: 9
Training loss: 0.051568709313869476
Validation loss: 1.3891805615476382

Epoch: 6| Step: 10
Training loss: 0.06417281180620193
Validation loss: 1.3841497744283369

Epoch: 6| Step: 11
Training loss: 0.08392772078514099
Validation loss: 1.382572832927909

Epoch: 6| Step: 12
Training loss: 0.12868735194206238
Validation loss: 1.364041519421403

Epoch: 6| Step: 13
Training loss: 0.059862732887268066
Validation loss: 1.3763865142740228

Epoch: 435| Step: 0
Training loss: 0.06982427090406418
Validation loss: 1.3752391979258547

Epoch: 6| Step: 1
Training loss: 0.05598711222410202
Validation loss: 1.3564459034191665

Epoch: 6| Step: 2
Training loss: 0.08177420496940613
Validation loss: 1.354728223816041

Epoch: 6| Step: 3
Training loss: 0.0700526237487793
Validation loss: 1.334231113874784

Epoch: 6| Step: 4
Training loss: 0.08573240786790848
Validation loss: 1.3502747294723347

Epoch: 6| Step: 5
Training loss: 0.05561996251344681
Validation loss: 1.3450748914031572

Epoch: 6| Step: 6
Training loss: 0.0833958312869072
Validation loss: 1.3421237968629407

Epoch: 6| Step: 7
Training loss: 0.060965247452259064
Validation loss: 1.3435902685247443

Epoch: 6| Step: 8
Training loss: 0.07086887210607529
Validation loss: 1.3517103413099885

Epoch: 6| Step: 9
Training loss: 0.10421539098024368
Validation loss: 1.3392414277599705

Epoch: 6| Step: 10
Training loss: 0.09519712626934052
Validation loss: 1.3391158401325185

Epoch: 6| Step: 11
Training loss: 0.12198811024427414
Validation loss: 1.3466596270120272

Epoch: 6| Step: 12
Training loss: 0.11068280786275864
Validation loss: 1.3700906833012898

Epoch: 6| Step: 13
Training loss: 0.0610189288854599
Validation loss: 1.3414477084272651

Epoch: 436| Step: 0
Training loss: 0.08816450834274292
Validation loss: 1.3609400180078322

Epoch: 6| Step: 1
Training loss: 0.05091185122728348
Validation loss: 1.3419208462520311

Epoch: 6| Step: 2
Training loss: 0.06770183145999908
Validation loss: 1.348922670528453

Epoch: 6| Step: 3
Training loss: 0.08689449727535248
Validation loss: 1.35765552648934

Epoch: 6| Step: 4
Training loss: 0.12789389491081238
Validation loss: 1.3361958085849721

Epoch: 6| Step: 5
Training loss: 0.1012478768825531
Validation loss: 1.3476897132012151

Epoch: 6| Step: 6
Training loss: 0.08839461207389832
Validation loss: 1.36315526629007

Epoch: 6| Step: 7
Training loss: 0.11084825545549393
Validation loss: 1.3835671832484584

Epoch: 6| Step: 8
Training loss: 0.12162081897258759
Validation loss: 1.3841178468478623

Epoch: 6| Step: 9
Training loss: 0.09304280579090118
Validation loss: 1.3697780665530954

Epoch: 6| Step: 10
Training loss: 0.062372006475925446
Validation loss: 1.395202095790576

Epoch: 6| Step: 11
Training loss: 0.11823539435863495
Validation loss: 1.3900581213735765

Epoch: 6| Step: 12
Training loss: 0.08099418878555298
Validation loss: 1.3750027443773003

Epoch: 6| Step: 13
Training loss: 0.07801733911037445
Validation loss: 1.3937849613928026

Epoch: 437| Step: 0
Training loss: 0.08929711580276489
Validation loss: 1.4041092177873016

Epoch: 6| Step: 1
Training loss: 0.11521691828966141
Validation loss: 1.3946942052533549

Epoch: 6| Step: 2
Training loss: 0.09213424474000931
Validation loss: 1.411203553599696

Epoch: 6| Step: 3
Training loss: 0.13173232972621918
Validation loss: 1.401417637384066

Epoch: 6| Step: 4
Training loss: 0.09024545550346375
Validation loss: 1.412774525662904

Epoch: 6| Step: 5
Training loss: 0.061289232224226
Validation loss: 1.387432078520457

Epoch: 6| Step: 6
Training loss: 0.07122364640235901
Validation loss: 1.3945881769221316

Epoch: 6| Step: 7
Training loss: 0.086990125477314
Validation loss: 1.3797495301051805

Epoch: 6| Step: 8
Training loss: 0.07490967214107513
Validation loss: 1.387829016613704

Epoch: 6| Step: 9
Training loss: 0.1229603961110115
Validation loss: 1.3912137939083962

Epoch: 6| Step: 10
Training loss: 0.09262339770793915
Validation loss: 1.375178857516217

Epoch: 6| Step: 11
Training loss: 0.07921458780765533
Validation loss: 1.3665747296425603

Epoch: 6| Step: 12
Training loss: 0.06191161274909973
Validation loss: 1.377261168213301

Epoch: 6| Step: 13
Training loss: 0.0693555399775505
Validation loss: 1.3793741233887211

Epoch: 438| Step: 0
Training loss: 0.07184179127216339
Validation loss: 1.37395844920989

Epoch: 6| Step: 1
Training loss: 0.09839147329330444
Validation loss: 1.3805509408315022

Epoch: 6| Step: 2
Training loss: 0.11862573027610779
Validation loss: 1.4030850369443175

Epoch: 6| Step: 3
Training loss: 0.16160160303115845
Validation loss: 1.3811170516475555

Epoch: 6| Step: 4
Training loss: 0.1044268012046814
Validation loss: 1.370795403757403

Epoch: 6| Step: 5
Training loss: 0.07936759293079376
Validation loss: 1.3478050026842343

Epoch: 6| Step: 6
Training loss: 0.08331507444381714
Validation loss: 1.3504202288966025

Epoch: 6| Step: 7
Training loss: 0.0383060984313488
Validation loss: 1.3412603921787714

Epoch: 6| Step: 8
Training loss: 0.06293437629938126
Validation loss: 1.340462443649128

Epoch: 6| Step: 9
Training loss: 0.06959265470504761
Validation loss: 1.3463480216200634

Epoch: 6| Step: 10
Training loss: 0.07430262118577957
Validation loss: 1.3501338035829606

Epoch: 6| Step: 11
Training loss: 0.08602166175842285
Validation loss: 1.3649788223287111

Epoch: 6| Step: 12
Training loss: 0.06147981807589531
Validation loss: 1.3645616628790413

Epoch: 6| Step: 13
Training loss: 0.054505057632923126
Validation loss: 1.369099957968599

Epoch: 439| Step: 0
Training loss: 0.12628404796123505
Validation loss: 1.395337176579301

Epoch: 6| Step: 1
Training loss: 0.08198725432157516
Validation loss: 1.3982002260864421

Epoch: 6| Step: 2
Training loss: 0.0932733565568924
Validation loss: 1.3892802166682419

Epoch: 6| Step: 3
Training loss: 0.0733671486377716
Validation loss: 1.3978743527525215

Epoch: 6| Step: 4
Training loss: 0.07442542910575867
Validation loss: 1.3999261010077693

Epoch: 6| Step: 5
Training loss: 0.09432478249073029
Validation loss: 1.3938172068647159

Epoch: 6| Step: 6
Training loss: 0.08510444313287735
Validation loss: 1.3791934828604422

Epoch: 6| Step: 7
Training loss: 0.0889543741941452
Validation loss: 1.3590832269319923

Epoch: 6| Step: 8
Training loss: 0.0959952101111412
Validation loss: 1.3493208821101854

Epoch: 6| Step: 9
Training loss: 0.09128442406654358
Validation loss: 1.3555793082842262

Epoch: 6| Step: 10
Training loss: 0.17594145238399506
Validation loss: 1.3555892622599037

Epoch: 6| Step: 11
Training loss: 0.10783720016479492
Validation loss: 1.3408190755433933

Epoch: 6| Step: 12
Training loss: 0.05094029754400253
Validation loss: 1.3204114001284364

Epoch: 6| Step: 13
Training loss: 0.09988714754581451
Validation loss: 1.332050262599863

Epoch: 440| Step: 0
Training loss: 0.10568930208683014
Validation loss: 1.3346585586506834

Epoch: 6| Step: 1
Training loss: 0.08905794471502304
Validation loss: 1.3321350530911518

Epoch: 6| Step: 2
Training loss: 0.10098537057638168
Validation loss: 1.3231583731148833

Epoch: 6| Step: 3
Training loss: 0.07397085428237915
Validation loss: 1.3286954696460436

Epoch: 6| Step: 4
Training loss: 0.10330937802791595
Validation loss: 1.3331414986682195

Epoch: 6| Step: 5
Training loss: 0.09926418960094452
Validation loss: 1.3376042868501397

Epoch: 6| Step: 6
Training loss: 0.055734798312187195
Validation loss: 1.3373828459811468

Epoch: 6| Step: 7
Training loss: 0.12768301367759705
Validation loss: 1.338509525022199

Epoch: 6| Step: 8
Training loss: 0.08867441862821579
Validation loss: 1.3418604366240963

Epoch: 6| Step: 9
Training loss: 0.10404438525438309
Validation loss: 1.338391601398427

Epoch: 6| Step: 10
Training loss: 0.09131289273500443
Validation loss: 1.3655397020360476

Epoch: 6| Step: 11
Training loss: 0.07166556268930435
Validation loss: 1.3642464337810394

Epoch: 6| Step: 12
Training loss: 0.08188711106777191
Validation loss: 1.3914667214116743

Epoch: 6| Step: 13
Training loss: 0.13673140108585358
Validation loss: 1.3761463831829768

Epoch: 441| Step: 0
Training loss: 0.07586310803890228
Validation loss: 1.3983002606258597

Epoch: 6| Step: 1
Training loss: 0.13520447909832
Validation loss: 1.3943406202459847

Epoch: 6| Step: 2
Training loss: 0.11549284309148788
Validation loss: 1.403602623170422

Epoch: 6| Step: 3
Training loss: 0.0792473554611206
Validation loss: 1.420855442682902

Epoch: 6| Step: 4
Training loss: 0.05872303247451782
Validation loss: 1.4230568460238877

Epoch: 6| Step: 5
Training loss: 0.0828232541680336
Validation loss: 1.4122462862281389

Epoch: 6| Step: 6
Training loss: 0.13051387667655945
Validation loss: 1.4281387662374845

Epoch: 6| Step: 7
Training loss: 0.08704041689634323
Validation loss: 1.3988281642237017

Epoch: 6| Step: 8
Training loss: 0.1711641550064087
Validation loss: 1.391799581948147

Epoch: 6| Step: 9
Training loss: 0.07359958440065384
Validation loss: 1.4117323576763112

Epoch: 6| Step: 10
Training loss: 0.06805971264839172
Validation loss: 1.369241851632313

Epoch: 6| Step: 11
Training loss: 0.10340593755245209
Validation loss: 1.3941581954238236

Epoch: 6| Step: 12
Training loss: 0.10510068386793137
Validation loss: 1.3615177433977845

Epoch: 6| Step: 13
Training loss: 0.0945834070444107
Validation loss: 1.3658790421742264

Epoch: 442| Step: 0
Training loss: 0.07213424146175385
Validation loss: 1.3417234766867854

Epoch: 6| Step: 1
Training loss: 0.08201158046722412
Validation loss: 1.3453365436164282

Epoch: 6| Step: 2
Training loss: 0.08424601703882217
Validation loss: 1.3661013021264026

Epoch: 6| Step: 3
Training loss: 0.06674931943416595
Validation loss: 1.3762418993057743

Epoch: 6| Step: 4
Training loss: 0.06818188726902008
Validation loss: 1.362012385040201

Epoch: 6| Step: 5
Training loss: 0.08255887031555176
Validation loss: 1.3704427403788413

Epoch: 6| Step: 6
Training loss: 0.12592488527297974
Validation loss: 1.3743994582083918

Epoch: 6| Step: 7
Training loss: 0.12076465785503387
Validation loss: 1.3739200074185607

Epoch: 6| Step: 8
Training loss: 0.11975240707397461
Validation loss: 1.3749652607466585

Epoch: 6| Step: 9
Training loss: 0.08281247317790985
Validation loss: 1.3787747339535785

Epoch: 6| Step: 10
Training loss: 0.06140808388590813
Validation loss: 1.3878229125853507

Epoch: 6| Step: 11
Training loss: 0.06143023073673248
Validation loss: 1.3823326351822063

Epoch: 6| Step: 12
Training loss: 0.08066193759441376
Validation loss: 1.38505773005947

Epoch: 6| Step: 13
Training loss: 0.08614356070756912
Validation loss: 1.3997597745669785

Epoch: 443| Step: 0
Training loss: 0.10157553106546402
Validation loss: 1.398058315759064

Epoch: 6| Step: 1
Training loss: 0.1103338748216629
Validation loss: 1.3904086223212622

Epoch: 6| Step: 2
Training loss: 0.06997011601924896
Validation loss: 1.3854373026919622

Epoch: 6| Step: 3
Training loss: 0.11493364721536636
Validation loss: 1.3879962967288109

Epoch: 6| Step: 4
Training loss: 0.1497962772846222
Validation loss: 1.403599008437126

Epoch: 6| Step: 5
Training loss: 0.14342612028121948
Validation loss: 1.389059402609384

Epoch: 6| Step: 6
Training loss: 0.08786473423242569
Validation loss: 1.393817832393031

Epoch: 6| Step: 7
Training loss: 0.08339928835630417
Validation loss: 1.395356426956833

Epoch: 6| Step: 8
Training loss: 0.12498122453689575
Validation loss: 1.3780894567889552

Epoch: 6| Step: 9
Training loss: 0.04123644530773163
Validation loss: 1.375299387080695

Epoch: 6| Step: 10
Training loss: 0.08964616805315018
Validation loss: 1.3672954869526688

Epoch: 6| Step: 11
Training loss: 0.04585014656186104
Validation loss: 1.362177054087321

Epoch: 6| Step: 12
Training loss: 0.06480816006660461
Validation loss: 1.3926301617776193

Epoch: 6| Step: 13
Training loss: 0.0677831843495369
Validation loss: 1.3804163855891074

Epoch: 444| Step: 0
Training loss: 0.06656414270401001
Validation loss: 1.392002232613102

Epoch: 6| Step: 1
Training loss: 0.10039043426513672
Validation loss: 1.3668304207504436

Epoch: 6| Step: 2
Training loss: 0.1159031018614769
Validation loss: 1.3680559127561507

Epoch: 6| Step: 3
Training loss: 0.08949591964483261
Validation loss: 1.3824614222331713

Epoch: 6| Step: 4
Training loss: 0.06590217351913452
Validation loss: 1.3600213912225538

Epoch: 6| Step: 5
Training loss: 0.06609019637107849
Validation loss: 1.369664458818333

Epoch: 6| Step: 6
Training loss: 0.06754418462514877
Validation loss: 1.3514288599773119

Epoch: 6| Step: 7
Training loss: 0.08421078324317932
Validation loss: 1.3436832158796248

Epoch: 6| Step: 8
Training loss: 0.07104742527008057
Validation loss: 1.351533676988335

Epoch: 6| Step: 9
Training loss: 0.05682951956987381
Validation loss: 1.3702182218592653

Epoch: 6| Step: 10
Training loss: 0.08326587080955505
Validation loss: 1.3704916418239634

Epoch: 6| Step: 11
Training loss: 0.12308663129806519
Validation loss: 1.3793143764618905

Epoch: 6| Step: 12
Training loss: 0.07774930447340012
Validation loss: 1.3870566109175324

Epoch: 6| Step: 13
Training loss: 0.04949326813220978
Validation loss: 1.3668233117749613

Epoch: 445| Step: 0
Training loss: 0.10227826982736588
Validation loss: 1.3720125626492243

Epoch: 6| Step: 1
Training loss: 0.09926502406597137
Validation loss: 1.355766861669479

Epoch: 6| Step: 2
Training loss: 0.056709133088588715
Validation loss: 1.3760232181959255

Epoch: 6| Step: 3
Training loss: 0.0772472694516182
Validation loss: 1.3389747655519875

Epoch: 6| Step: 4
Training loss: 0.08875508606433868
Validation loss: 1.3575994891505088

Epoch: 6| Step: 5
Training loss: 0.11608658730983734
Validation loss: 1.3565714359283447

Epoch: 6| Step: 6
Training loss: 0.12076612561941147
Validation loss: 1.3464278431348904

Epoch: 6| Step: 7
Training loss: 0.13327059149742126
Validation loss: 1.3862837065932572

Epoch: 6| Step: 8
Training loss: 0.07146750390529633
Validation loss: 1.3546959905214206

Epoch: 6| Step: 9
Training loss: 0.05515371263027191
Validation loss: 1.3651468228268366

Epoch: 6| Step: 10
Training loss: 0.08777213096618652
Validation loss: 1.355424904054211

Epoch: 6| Step: 11
Training loss: 0.08143644779920578
Validation loss: 1.3761695290124545

Epoch: 6| Step: 12
Training loss: 0.10754075646400452
Validation loss: 1.3581791206072735

Epoch: 6| Step: 13
Training loss: 0.10622294992208481
Validation loss: 1.3572636137726486

Epoch: 446| Step: 0
Training loss: 0.10396981239318848
Validation loss: 1.3639344214111246

Epoch: 6| Step: 1
Training loss: 0.10132770985364914
Validation loss: 1.36256794967959

Epoch: 6| Step: 2
Training loss: 0.09351000189781189
Validation loss: 1.337522751541548

Epoch: 6| Step: 3
Training loss: 0.07303833961486816
Validation loss: 1.338758715378341

Epoch: 6| Step: 4
Training loss: 0.07878854125738144
Validation loss: 1.3305997643419492

Epoch: 6| Step: 5
Training loss: 0.09811072051525116
Validation loss: 1.3368285561120639

Epoch: 6| Step: 6
Training loss: 0.11300809681415558
Validation loss: 1.3286386510377288

Epoch: 6| Step: 7
Training loss: 0.1047365590929985
Validation loss: 1.341540236626902

Epoch: 6| Step: 8
Training loss: 0.09981533885002136
Validation loss: 1.340671379079101

Epoch: 6| Step: 9
Training loss: 0.09211115539073944
Validation loss: 1.3319720529740857

Epoch: 6| Step: 10
Training loss: 0.13415729999542236
Validation loss: 1.3167960220767605

Epoch: 6| Step: 11
Training loss: 0.1285324990749359
Validation loss: 1.3341450498950096

Epoch: 6| Step: 12
Training loss: 0.0894201248884201
Validation loss: 1.3234601879632601

Epoch: 6| Step: 13
Training loss: 0.04902948439121246
Validation loss: 1.3306346119091075

Epoch: 447| Step: 0
Training loss: 0.10166685283184052
Validation loss: 1.3510095214331022

Epoch: 6| Step: 1
Training loss: 0.08686782419681549
Validation loss: 1.3655459957738076

Epoch: 6| Step: 2
Training loss: 0.1113610565662384
Validation loss: 1.3789764155623734

Epoch: 6| Step: 3
Training loss: 0.10059258341789246
Validation loss: 1.3608908973714358

Epoch: 6| Step: 4
Training loss: 0.07240211963653564
Validation loss: 1.368711712539837

Epoch: 6| Step: 5
Training loss: 0.08078397810459137
Validation loss: 1.3877515042981794

Epoch: 6| Step: 6
Training loss: 0.07418499141931534
Validation loss: 1.3790244748515468

Epoch: 6| Step: 7
Training loss: 0.05753685534000397
Validation loss: 1.3836738326216256

Epoch: 6| Step: 8
Training loss: 0.12164679169654846
Validation loss: 1.3731937434083672

Epoch: 6| Step: 9
Training loss: 0.08531584590673447
Validation loss: 1.3612086375554402

Epoch: 6| Step: 10
Training loss: 0.06257383525371552
Validation loss: 1.3519128958384197

Epoch: 6| Step: 11
Training loss: 0.09045310318470001
Validation loss: 1.3743655963610577

Epoch: 6| Step: 12
Training loss: 0.09100671112537384
Validation loss: 1.3671031216139435

Epoch: 6| Step: 13
Training loss: 0.051541201770305634
Validation loss: 1.3641594456088157

Epoch: 448| Step: 0
Training loss: 0.07733453065156937
Validation loss: 1.349971587939929

Epoch: 6| Step: 1
Training loss: 0.10062311589717865
Validation loss: 1.3697834989076019

Epoch: 6| Step: 2
Training loss: 0.09255630522966385
Validation loss: 1.3467273481430546

Epoch: 6| Step: 3
Training loss: 0.08433390408754349
Validation loss: 1.3548008344506706

Epoch: 6| Step: 4
Training loss: 0.0915459468960762
Validation loss: 1.3571763487272366

Epoch: 6| Step: 5
Training loss: 0.08004108816385269
Validation loss: 1.3472616134151336

Epoch: 6| Step: 6
Training loss: 0.04746948555111885
Validation loss: 1.3358612092592383

Epoch: 6| Step: 7
Training loss: 0.07200132310390472
Validation loss: 1.3605097083635227

Epoch: 6| Step: 8
Training loss: 0.10570459812879562
Validation loss: 1.34209132066337

Epoch: 6| Step: 9
Training loss: 0.07587360590696335
Validation loss: 1.3512433889091655

Epoch: 6| Step: 10
Training loss: 0.12085616588592529
Validation loss: 1.361938427853328

Epoch: 6| Step: 11
Training loss: 0.12426669895648956
Validation loss: 1.4210901606467463

Epoch: 6| Step: 12
Training loss: 0.11045555770397186
Validation loss: 1.4079497386050481

Epoch: 6| Step: 13
Training loss: 0.11030285805463791
Validation loss: 1.390307024601967

Epoch: 449| Step: 0
Training loss: 0.07719536125659943
Validation loss: 1.3893274312378259

Epoch: 6| Step: 1
Training loss: 0.08352548629045486
Validation loss: 1.374449738892176

Epoch: 6| Step: 2
Training loss: 0.08119435608386993
Validation loss: 1.3648334337819008

Epoch: 6| Step: 3
Training loss: 0.07649767398834229
Validation loss: 1.3549036223401305

Epoch: 6| Step: 4
Training loss: 0.09366872906684875
Validation loss: 1.3568074716034757

Epoch: 6| Step: 5
Training loss: 0.14454755187034607
Validation loss: 1.3708156590820642

Epoch: 6| Step: 6
Training loss: 0.11669139564037323
Validation loss: 1.3618669420160272

Epoch: 6| Step: 7
Training loss: 0.09127059578895569
Validation loss: 1.3679525916294386

Epoch: 6| Step: 8
Training loss: 0.06557776033878326
Validation loss: 1.3582359155019124

Epoch: 6| Step: 9
Training loss: 0.11491990089416504
Validation loss: 1.3813361288398824

Epoch: 6| Step: 10
Training loss: 0.08695976436138153
Validation loss: 1.3451192225179365

Epoch: 6| Step: 11
Training loss: 0.1015729308128357
Validation loss: 1.3648095861557992

Epoch: 6| Step: 12
Training loss: 0.09254980832338333
Validation loss: 1.370713476211794

Epoch: 6| Step: 13
Training loss: 0.08070968091487885
Validation loss: 1.3773473898569744

Epoch: 450| Step: 0
Training loss: 0.08599204570055008
Validation loss: 1.3691195300830308

Epoch: 6| Step: 1
Training loss: 0.11533846706151962
Validation loss: 1.3675979830885445

Epoch: 6| Step: 2
Training loss: 0.0837593674659729
Validation loss: 1.363855449102258

Epoch: 6| Step: 3
Training loss: 0.0924220085144043
Validation loss: 1.3551714984319543

Epoch: 6| Step: 4
Training loss: 0.07097127288579941
Validation loss: 1.375121412738677

Epoch: 6| Step: 5
Training loss: 0.07232479006052017
Validation loss: 1.3635083090874456

Epoch: 6| Step: 6
Training loss: 0.062275875359773636
Validation loss: 1.377637710622562

Epoch: 6| Step: 7
Training loss: 0.08929380029439926
Validation loss: 1.3843163944059802

Epoch: 6| Step: 8
Training loss: 0.06009441614151001
Validation loss: 1.4031858482668478

Epoch: 6| Step: 9
Training loss: 0.06393339484930038
Validation loss: 1.3704902497670983

Epoch: 6| Step: 10
Training loss: 0.10549241304397583
Validation loss: 1.3679279640156736

Epoch: 6| Step: 11
Training loss: 0.07136457413434982
Validation loss: 1.3502791953343216

Epoch: 6| Step: 12
Training loss: 0.10234297811985016
Validation loss: 1.352822034589706

Epoch: 6| Step: 13
Training loss: 0.07382908463478088
Validation loss: 1.3761702468318324

Epoch: 451| Step: 0
Training loss: 0.0827430933713913
Validation loss: 1.3731361794215378

Epoch: 6| Step: 1
Training loss: 0.09142795205116272
Validation loss: 1.3482292275274954

Epoch: 6| Step: 2
Training loss: 0.08734629303216934
Validation loss: 1.3832359519056094

Epoch: 6| Step: 3
Training loss: 0.07458299398422241
Validation loss: 1.3665829191925705

Epoch: 6| Step: 4
Training loss: 0.11872898042201996
Validation loss: 1.3469264148384013

Epoch: 6| Step: 5
Training loss: 0.09888449311256409
Validation loss: 1.342302833193092

Epoch: 6| Step: 6
Training loss: 0.08027295023202896
Validation loss: 1.3512301701371388

Epoch: 6| Step: 7
Training loss: 0.13790112733840942
Validation loss: 1.354114382497726

Epoch: 6| Step: 8
Training loss: 0.15845687687397003
Validation loss: 1.3591993880528275

Epoch: 6| Step: 9
Training loss: 0.0412159189581871
Validation loss: 1.3454655857496365

Epoch: 6| Step: 10
Training loss: 0.08119640499353409
Validation loss: 1.3540273558708928

Epoch: 6| Step: 11
Training loss: 0.10752540081739426
Validation loss: 1.3493895790269297

Epoch: 6| Step: 12
Training loss: 0.08757966011762619
Validation loss: 1.3437685543490994

Epoch: 6| Step: 13
Training loss: 0.04427387937903404
Validation loss: 1.3541952627961353

Epoch: 452| Step: 0
Training loss: 0.09092456102371216
Validation loss: 1.3620229023759083

Epoch: 6| Step: 1
Training loss: 0.092166468501091
Validation loss: 1.376432297050312

Epoch: 6| Step: 2
Training loss: 0.06841583549976349
Validation loss: 1.366000581813115

Epoch: 6| Step: 3
Training loss: 0.07500304281711578
Validation loss: 1.3854101011829991

Epoch: 6| Step: 4
Training loss: 0.09607008099555969
Validation loss: 1.4025903491563694

Epoch: 6| Step: 5
Training loss: 0.12256068736314774
Validation loss: 1.3895270042521979

Epoch: 6| Step: 6
Training loss: 0.07915568351745605
Validation loss: 1.3828356746704347

Epoch: 6| Step: 7
Training loss: 0.06074986606836319
Validation loss: 1.3758257665941793

Epoch: 6| Step: 8
Training loss: 0.114281564950943
Validation loss: 1.383184790611267

Epoch: 6| Step: 9
Training loss: 0.07521196454763412
Validation loss: 1.3674323610080186

Epoch: 6| Step: 10
Training loss: 0.06845051050186157
Validation loss: 1.3775695728999313

Epoch: 6| Step: 11
Training loss: 0.10495088994503021
Validation loss: 1.369756443526155

Epoch: 6| Step: 12
Training loss: 0.06141243129968643
Validation loss: 1.3533429823895937

Epoch: 6| Step: 13
Training loss: 0.14382188022136688
Validation loss: 1.3640895530741701

Epoch: 453| Step: 0
Training loss: 0.08929383754730225
Validation loss: 1.3553161441638906

Epoch: 6| Step: 1
Training loss: 0.07572509348392487
Validation loss: 1.3504670204654816

Epoch: 6| Step: 2
Training loss: 0.08498845249414444
Validation loss: 1.3612648684491393

Epoch: 6| Step: 3
Training loss: 0.1266346275806427
Validation loss: 1.3828162377880466

Epoch: 6| Step: 4
Training loss: 0.07729239016771317
Validation loss: 1.3590102900740921

Epoch: 6| Step: 5
Training loss: 0.10143692791461945
Validation loss: 1.3696979944423964

Epoch: 6| Step: 6
Training loss: 0.08701412379741669
Validation loss: 1.3951891378689838

Epoch: 6| Step: 7
Training loss: 0.06493207812309265
Validation loss: 1.3868860833106502

Epoch: 6| Step: 8
Training loss: 0.04383394494652748
Validation loss: 1.3983457908835462

Epoch: 6| Step: 9
Training loss: 0.08106400072574615
Validation loss: 1.4061112416687833

Epoch: 6| Step: 10
Training loss: 0.07387115061283112
Validation loss: 1.3902923221229224

Epoch: 6| Step: 11
Training loss: 0.10289578139781952
Validation loss: 1.3936955736529442

Epoch: 6| Step: 12
Training loss: 0.11505356431007385
Validation loss: 1.4093984237281225

Epoch: 6| Step: 13
Training loss: 0.08520717918872833
Validation loss: 1.3992868315789007

Epoch: 454| Step: 0
Training loss: 0.10522858798503876
Validation loss: 1.4279152065195062

Epoch: 6| Step: 1
Training loss: 0.06577259302139282
Validation loss: 1.4261507103520055

Epoch: 6| Step: 2
Training loss: 0.06669402867555618
Validation loss: 1.410247609179507

Epoch: 6| Step: 3
Training loss: 0.07355611771345139
Validation loss: 1.408954688297805

Epoch: 6| Step: 4
Training loss: 0.08283273875713348
Validation loss: 1.3780929952539422

Epoch: 6| Step: 5
Training loss: 0.09626820683479309
Validation loss: 1.3899756221361057

Epoch: 6| Step: 6
Training loss: 0.0837307944893837
Validation loss: 1.4068293007471229

Epoch: 6| Step: 7
Training loss: 0.08482526242733002
Validation loss: 1.3984820740197295

Epoch: 6| Step: 8
Training loss: 0.06923834979534149
Validation loss: 1.3755953113238018

Epoch: 6| Step: 9
Training loss: 0.07133648544549942
Validation loss: 1.3918079009620092

Epoch: 6| Step: 10
Training loss: 0.07310579717159271
Validation loss: 1.389414188682392

Epoch: 6| Step: 11
Training loss: 0.10519245266914368
Validation loss: 1.3812101707663587

Epoch: 6| Step: 12
Training loss: 0.06185666099190712
Validation loss: 1.3681893374330254

Epoch: 6| Step: 13
Training loss: 0.05348498374223709
Validation loss: 1.3542139466090868

Epoch: 455| Step: 0
Training loss: 0.0761152133345604
Validation loss: 1.3825281038079211

Epoch: 6| Step: 1
Training loss: 0.0884237065911293
Validation loss: 1.3574130009579402

Epoch: 6| Step: 2
Training loss: 0.08200821280479431
Validation loss: 1.395184479733949

Epoch: 6| Step: 3
Training loss: 0.09385793656110764
Validation loss: 1.361763257493255

Epoch: 6| Step: 4
Training loss: 0.1019032895565033
Validation loss: 1.374292504402899

Epoch: 6| Step: 5
Training loss: 0.04551701247692108
Validation loss: 1.3809794597728278

Epoch: 6| Step: 6
Training loss: 0.10156729072332382
Validation loss: 1.4045334451942033

Epoch: 6| Step: 7
Training loss: 0.04930252581834793
Validation loss: 1.4025420411940543

Epoch: 6| Step: 8
Training loss: 0.08064784109592438
Validation loss: 1.3985694518653295

Epoch: 6| Step: 9
Training loss: 0.06862764805555344
Validation loss: 1.394784923522703

Epoch: 6| Step: 10
Training loss: 0.08473776280879974
Validation loss: 1.3803449638428227

Epoch: 6| Step: 11
Training loss: 0.06578705459833145
Validation loss: 1.4054425557454426

Epoch: 6| Step: 12
Training loss: 0.07470428198575974
Validation loss: 1.410644535095461

Epoch: 6| Step: 13
Training loss: 0.1407051682472229
Validation loss: 1.4029578201232418

Epoch: 456| Step: 0
Training loss: 0.07949786633253098
Validation loss: 1.4093926055457002

Epoch: 6| Step: 1
Training loss: 0.06086823344230652
Validation loss: 1.4089569199469782

Epoch: 6| Step: 2
Training loss: 0.07883372902870178
Validation loss: 1.3970381277863697

Epoch: 6| Step: 3
Training loss: 0.05269720405340195
Validation loss: 1.3806339220334125

Epoch: 6| Step: 4
Training loss: 0.09207005798816681
Validation loss: 1.3785191197549143

Epoch: 6| Step: 5
Training loss: 0.07328637689352036
Validation loss: 1.375216866052279

Epoch: 6| Step: 6
Training loss: 0.08913333714008331
Validation loss: 1.3426693748402339

Epoch: 6| Step: 7
Training loss: 0.08094105869531631
Validation loss: 1.3458699744234803

Epoch: 6| Step: 8
Training loss: 0.08473391830921173
Validation loss: 1.3419160240439958

Epoch: 6| Step: 9
Training loss: 0.10378170013427734
Validation loss: 1.3443378299795172

Epoch: 6| Step: 10
Training loss: 0.06765807420015335
Validation loss: 1.3470234537637362

Epoch: 6| Step: 11
Training loss: 0.05104098469018936
Validation loss: 1.3278773446236887

Epoch: 6| Step: 12
Training loss: 0.07365437597036362
Validation loss: 1.347100684719701

Epoch: 6| Step: 13
Training loss: 0.11197850108146667
Validation loss: 1.3487877166399391

Epoch: 457| Step: 0
Training loss: 0.09821046143770218
Validation loss: 1.3579116777707172

Epoch: 6| Step: 1
Training loss: 0.10030747950077057
Validation loss: 1.3436135527908162

Epoch: 6| Step: 2
Training loss: 0.08415626734495163
Validation loss: 1.34287832308841

Epoch: 6| Step: 3
Training loss: 0.053505390882492065
Validation loss: 1.357768294631794

Epoch: 6| Step: 4
Training loss: 0.05262934789061546
Validation loss: 1.3792942275283158

Epoch: 6| Step: 5
Training loss: 0.07730695605278015
Validation loss: 1.3736314222376833

Epoch: 6| Step: 6
Training loss: 0.08265258371829987
Validation loss: 1.3958503084798013

Epoch: 6| Step: 7
Training loss: 0.11911048740148544
Validation loss: 1.389905543737514

Epoch: 6| Step: 8
Training loss: 0.17169314622879028
Validation loss: 1.4067114540325698

Epoch: 6| Step: 9
Training loss: 0.05232221260666847
Validation loss: 1.4001066838541338

Epoch: 6| Step: 10
Training loss: 0.09164795279502869
Validation loss: 1.405482348575387

Epoch: 6| Step: 11
Training loss: 0.06040215864777565
Validation loss: 1.4164259946474465

Epoch: 6| Step: 12
Training loss: 0.0736219584941864
Validation loss: 1.3901695487319783

Epoch: 6| Step: 13
Training loss: 0.07863005250692368
Validation loss: 1.3964821753963348

Epoch: 458| Step: 0
Training loss: 0.06182599067687988
Validation loss: 1.409547741695117

Epoch: 6| Step: 1
Training loss: 0.11613814532756805
Validation loss: 1.3957167325481292

Epoch: 6| Step: 2
Training loss: 0.06498902291059494
Validation loss: 1.388368921895181

Epoch: 6| Step: 3
Training loss: 0.07804552465677261
Validation loss: 1.399738133594554

Epoch: 6| Step: 4
Training loss: 0.09052756428718567
Validation loss: 1.4012259219282417

Epoch: 6| Step: 5
Training loss: 0.06761667132377625
Validation loss: 1.3947030203316801

Epoch: 6| Step: 6
Training loss: 0.09356611222028732
Validation loss: 1.3905601424555625

Epoch: 6| Step: 7
Training loss: 0.05019058659672737
Validation loss: 1.3819922426695466

Epoch: 6| Step: 8
Training loss: 0.059109728783369064
Validation loss: 1.3717327156374532

Epoch: 6| Step: 9
Training loss: 0.04567260667681694
Validation loss: 1.3638785949317358

Epoch: 6| Step: 10
Training loss: 0.13919590413570404
Validation loss: 1.3477426382803148

Epoch: 6| Step: 11
Training loss: 0.07927557826042175
Validation loss: 1.3592946811388897

Epoch: 6| Step: 12
Training loss: 0.0766054168343544
Validation loss: 1.3340077771935412

Epoch: 6| Step: 13
Training loss: 0.050257179886102676
Validation loss: 1.3471287328709838

Epoch: 459| Step: 0
Training loss: 0.05858432874083519
Validation loss: 1.3142246020737516

Epoch: 6| Step: 1
Training loss: 0.06098834425210953
Validation loss: 1.335925849535132

Epoch: 6| Step: 2
Training loss: 0.11384174972772598
Validation loss: 1.319231016020621

Epoch: 6| Step: 3
Training loss: 0.06886540353298187
Validation loss: 1.339363391681384

Epoch: 6| Step: 4
Training loss: 0.058328308165073395
Validation loss: 1.344426978018976

Epoch: 6| Step: 5
Training loss: 0.060733065009117126
Validation loss: 1.3455098123960598

Epoch: 6| Step: 6
Training loss: 0.08599945157766342
Validation loss: 1.3376844711201166

Epoch: 6| Step: 7
Training loss: 0.06738397479057312
Validation loss: 1.3322412083225865

Epoch: 6| Step: 8
Training loss: 0.057795967906713486
Validation loss: 1.3303659333977649

Epoch: 6| Step: 9
Training loss: 0.0787544995546341
Validation loss: 1.3540737257208875

Epoch: 6| Step: 10
Training loss: 0.08202438056468964
Validation loss: 1.362064887759506

Epoch: 6| Step: 11
Training loss: 0.03134181722998619
Validation loss: 1.3611389219119985

Epoch: 6| Step: 12
Training loss: 0.09917055070400238
Validation loss: 1.3957305415984123

Epoch: 6| Step: 13
Training loss: 0.10619203001260757
Validation loss: 1.3948352772702453

Epoch: 460| Step: 0
Training loss: 0.09291423857212067
Validation loss: 1.40017835299174

Epoch: 6| Step: 1
Training loss: 0.0912678986787796
Validation loss: 1.3939512378426009

Epoch: 6| Step: 2
Training loss: 0.12284841388463974
Validation loss: 1.3922936326713973

Epoch: 6| Step: 3
Training loss: 0.08819369971752167
Validation loss: 1.4013019236185218

Epoch: 6| Step: 4
Training loss: 0.040073513984680176
Validation loss: 1.4170874780224216

Epoch: 6| Step: 5
Training loss: 0.058416083455085754
Validation loss: 1.4028673338633713

Epoch: 6| Step: 6
Training loss: 0.06635093688964844
Validation loss: 1.4019935400255266

Epoch: 6| Step: 7
Training loss: 0.0787058174610138
Validation loss: 1.4330197149707424

Epoch: 6| Step: 8
Training loss: 0.1280379742383957
Validation loss: 1.4053061469908683

Epoch: 6| Step: 9
Training loss: 0.11355702579021454
Validation loss: 1.393531241724568

Epoch: 6| Step: 10
Training loss: 0.0865854024887085
Validation loss: 1.4055307398560226

Epoch: 6| Step: 11
Training loss: 0.07717309147119522
Validation loss: 1.3734968548179955

Epoch: 6| Step: 12
Training loss: 0.08862416446208954
Validation loss: 1.3718944980252175

Epoch: 6| Step: 13
Training loss: 0.05979923903942108
Validation loss: 1.353350095851447

Epoch: 461| Step: 0
Training loss: 0.0976569876074791
Validation loss: 1.3532195937248968

Epoch: 6| Step: 1
Training loss: 0.07358664274215698
Validation loss: 1.3359553775479716

Epoch: 6| Step: 2
Training loss: 0.08535639941692352
Validation loss: 1.3285309960765224

Epoch: 6| Step: 3
Training loss: 0.111957848072052
Validation loss: 1.3553967680982364

Epoch: 6| Step: 4
Training loss: 0.09660406410694122
Validation loss: 1.354856808980306

Epoch: 6| Step: 5
Training loss: 0.07050595432519913
Validation loss: 1.361402960233791

Epoch: 6| Step: 6
Training loss: 0.0436248704791069
Validation loss: 1.3440348961020028

Epoch: 6| Step: 7
Training loss: 0.07080921530723572
Validation loss: 1.3506441885425198

Epoch: 6| Step: 8
Training loss: 0.0695914626121521
Validation loss: 1.351812647235009

Epoch: 6| Step: 9
Training loss: 0.07132074981927872
Validation loss: 1.376386534783148

Epoch: 6| Step: 10
Training loss: 0.09068790078163147
Validation loss: 1.3686614523651779

Epoch: 6| Step: 11
Training loss: 0.09304708987474442
Validation loss: 1.3738388079468922

Epoch: 6| Step: 12
Training loss: 0.07434524595737457
Validation loss: 1.35574007931576

Epoch: 6| Step: 13
Training loss: 0.07597196847200394
Validation loss: 1.3712485272397277

Epoch: 462| Step: 0
Training loss: 0.08419711142778397
Validation loss: 1.3660355267986175

Epoch: 6| Step: 1
Training loss: 0.0676840990781784
Validation loss: 1.3617980249466435

Epoch: 6| Step: 2
Training loss: 0.045793402940034866
Validation loss: 1.3654295552161433

Epoch: 6| Step: 3
Training loss: 0.06861612945795059
Validation loss: 1.3669777153640665

Epoch: 6| Step: 4
Training loss: 0.07733771950006485
Validation loss: 1.3756980447358982

Epoch: 6| Step: 5
Training loss: 0.10963104665279388
Validation loss: 1.3592210841435257

Epoch: 6| Step: 6
Training loss: 0.04621627926826477
Validation loss: 1.3608029106611848

Epoch: 6| Step: 7
Training loss: 0.07877734303474426
Validation loss: 1.3807642664960635

Epoch: 6| Step: 8
Training loss: 0.0851934403181076
Validation loss: 1.3678547925846551

Epoch: 6| Step: 9
Training loss: 0.08952054381370544
Validation loss: 1.3550523506697787

Epoch: 6| Step: 10
Training loss: 0.037563756108284
Validation loss: 1.3595568640257722

Epoch: 6| Step: 11
Training loss: 0.08445505797863007
Validation loss: 1.3499253552447084

Epoch: 6| Step: 12
Training loss: 0.08324205130338669
Validation loss: 1.361796643144341

Epoch: 6| Step: 13
Training loss: 0.08225766569375992
Validation loss: 1.3637407748929915

Epoch: 463| Step: 0
Training loss: 0.05371971055865288
Validation loss: 1.3540246473845614

Epoch: 6| Step: 1
Training loss: 0.0831521600484848
Validation loss: 1.3412870707050446

Epoch: 6| Step: 2
Training loss: 0.07169478386640549
Validation loss: 1.378798552738723

Epoch: 6| Step: 3
Training loss: 0.10973373800516129
Validation loss: 1.3835322459538777

Epoch: 6| Step: 4
Training loss: 0.047457434237003326
Validation loss: 1.4025254467482209

Epoch: 6| Step: 5
Training loss: 0.07994643598794937
Validation loss: 1.4049035708109539

Epoch: 6| Step: 6
Training loss: 0.07727636396884918
Validation loss: 1.392113326057311

Epoch: 6| Step: 7
Training loss: 0.06526955217123032
Validation loss: 1.404408395931285

Epoch: 6| Step: 8
Training loss: 0.08295857906341553
Validation loss: 1.4302237508117512

Epoch: 6| Step: 9
Training loss: 0.06089689955115318
Validation loss: 1.4089779059092205

Epoch: 6| Step: 10
Training loss: 0.03503376990556717
Validation loss: 1.3934880514298715

Epoch: 6| Step: 11
Training loss: 0.05961398035287857
Validation loss: 1.3786402504931214

Epoch: 6| Step: 12
Training loss: 0.06002635136246681
Validation loss: 1.375412787801476

Epoch: 6| Step: 13
Training loss: 0.07487615942955017
Validation loss: 1.361138302792785

Epoch: 464| Step: 0
Training loss: 0.05957113951444626
Validation loss: 1.3631190010296401

Epoch: 6| Step: 1
Training loss: 0.08689172565937042
Validation loss: 1.3525300320758615

Epoch: 6| Step: 2
Training loss: 0.06263178586959839
Validation loss: 1.3567976413234588

Epoch: 6| Step: 3
Training loss: 0.05570276454091072
Validation loss: 1.3354455809439383

Epoch: 6| Step: 4
Training loss: 0.06383316963911057
Validation loss: 1.332258544301474

Epoch: 6| Step: 5
Training loss: 0.054694704711437225
Validation loss: 1.34150065529731

Epoch: 6| Step: 6
Training loss: 0.07085203379392624
Validation loss: 1.3511438536387619

Epoch: 6| Step: 7
Training loss: 0.08378159254789352
Validation loss: 1.3570396618176532

Epoch: 6| Step: 8
Training loss: 0.06371867656707764
Validation loss: 1.3740576723570466

Epoch: 6| Step: 9
Training loss: 0.08577966690063477
Validation loss: 1.3802300127603675

Epoch: 6| Step: 10
Training loss: 0.0467742495238781
Validation loss: 1.4090417200519192

Epoch: 6| Step: 11
Training loss: 0.12251337617635727
Validation loss: 1.4124477819729877

Epoch: 6| Step: 12
Training loss: 0.059169985353946686
Validation loss: 1.403322390330735

Epoch: 6| Step: 13
Training loss: 0.048052072525024414
Validation loss: 1.3932527098604428

Epoch: 465| Step: 0
Training loss: 0.029468001797795296
Validation loss: 1.3950359808501376

Epoch: 6| Step: 1
Training loss: 0.04756857454776764
Validation loss: 1.3833109358305573

Epoch: 6| Step: 2
Training loss: 0.06411508470773697
Validation loss: 1.3894264672392158

Epoch: 6| Step: 3
Training loss: 0.09378010779619217
Validation loss: 1.348672077700656

Epoch: 6| Step: 4
Training loss: 0.08028574287891388
Validation loss: 1.3627809946255018

Epoch: 6| Step: 5
Training loss: 0.07963231205940247
Validation loss: 1.3709578398735291

Epoch: 6| Step: 6
Training loss: 0.09933194518089294
Validation loss: 1.3681215932292323

Epoch: 6| Step: 7
Training loss: 0.0728696808218956
Validation loss: 1.369338317583966

Epoch: 6| Step: 8
Training loss: 0.0965631753206253
Validation loss: 1.376813816767867

Epoch: 6| Step: 9
Training loss: 0.055159613490104675
Validation loss: 1.3818897162714312

Epoch: 6| Step: 10
Training loss: 0.08160315454006195
Validation loss: 1.3934485668777137

Epoch: 6| Step: 11
Training loss: 0.08431311696767807
Validation loss: 1.4050166010856628

Epoch: 6| Step: 12
Training loss: 0.0816064402461052
Validation loss: 1.398115215762969

Epoch: 6| Step: 13
Training loss: 0.04932357743382454
Validation loss: 1.4033750295639038

Epoch: 466| Step: 0
Training loss: 0.06663045287132263
Validation loss: 1.4060908581620903

Epoch: 6| Step: 1
Training loss: 0.07493817061185837
Validation loss: 1.3920334744197067

Epoch: 6| Step: 2
Training loss: 0.06522298604249954
Validation loss: 1.38688741319923

Epoch: 6| Step: 3
Training loss: 0.1047816276550293
Validation loss: 1.3743069697451848

Epoch: 6| Step: 4
Training loss: 0.060758788138628006
Validation loss: 1.3927028038168465

Epoch: 6| Step: 5
Training loss: 0.07592800259590149
Validation loss: 1.3895943267371065

Epoch: 6| Step: 6
Training loss: 0.07722678780555725
Validation loss: 1.402046436904579

Epoch: 6| Step: 7
Training loss: 0.05012257397174835
Validation loss: 1.402155235249509

Epoch: 6| Step: 8
Training loss: 0.0674038976430893
Validation loss: 1.4040046853403891

Epoch: 6| Step: 9
Training loss: 0.04736877232789993
Validation loss: 1.386809346496418

Epoch: 6| Step: 10
Training loss: 0.05773109570145607
Validation loss: 1.4138868072981476

Epoch: 6| Step: 11
Training loss: 0.076593779027462
Validation loss: 1.390827876265331

Epoch: 6| Step: 12
Training loss: 0.05370672792196274
Validation loss: 1.3954360536349717

Epoch: 6| Step: 13
Training loss: 0.10625386238098145
Validation loss: 1.4043035763566212

Epoch: 467| Step: 0
Training loss: 0.08680882304906845
Validation loss: 1.3909702749662503

Epoch: 6| Step: 1
Training loss: 0.05781778693199158
Validation loss: 1.3840662779346589

Epoch: 6| Step: 2
Training loss: 0.06316462904214859
Validation loss: 1.4022245830105198

Epoch: 6| Step: 3
Training loss: 0.08107413351535797
Validation loss: 1.3904662734718733

Epoch: 6| Step: 4
Training loss: 0.06980407238006592
Validation loss: 1.4005200747520692

Epoch: 6| Step: 5
Training loss: 0.1119309514760971
Validation loss: 1.3973273628501481

Epoch: 6| Step: 6
Training loss: 0.06566740572452545
Validation loss: 1.3915990065502863

Epoch: 6| Step: 7
Training loss: 0.0821773111820221
Validation loss: 1.4063608184937508

Epoch: 6| Step: 8
Training loss: 0.10282737761735916
Validation loss: 1.4089624965062706

Epoch: 6| Step: 9
Training loss: 0.12125984579324722
Validation loss: 1.4147892491791838

Epoch: 6| Step: 10
Training loss: 0.06500762701034546
Validation loss: 1.4054566044961252

Epoch: 6| Step: 11
Training loss: 0.08679567277431488
Validation loss: 1.3862761438533824

Epoch: 6| Step: 12
Training loss: 0.09778492897748947
Validation loss: 1.4108111217457762

Epoch: 6| Step: 13
Training loss: 0.07937970757484436
Validation loss: 1.3768930524908087

Epoch: 468| Step: 0
Training loss: 0.057152580469846725
Validation loss: 1.3656512114309496

Epoch: 6| Step: 1
Training loss: 0.045556358993053436
Validation loss: 1.3848941037731786

Epoch: 6| Step: 2
Training loss: 0.07823213934898376
Validation loss: 1.3547362025066088

Epoch: 6| Step: 3
Training loss: 0.056073278188705444
Validation loss: 1.3493254492359776

Epoch: 6| Step: 4
Training loss: 0.12225201725959778
Validation loss: 1.3446469640219083

Epoch: 6| Step: 5
Training loss: 0.07937359064817429
Validation loss: 1.352995478978721

Epoch: 6| Step: 6
Training loss: 0.08155152201652527
Validation loss: 1.3577187663765364

Epoch: 6| Step: 7
Training loss: 0.07860809564590454
Validation loss: 1.3698185900206208

Epoch: 6| Step: 8
Training loss: 0.10544632375240326
Validation loss: 1.3909344814156974

Epoch: 6| Step: 9
Training loss: 0.0759410560131073
Validation loss: 1.3631877835078905

Epoch: 6| Step: 10
Training loss: 0.07549649477005005
Validation loss: 1.3693679814697595

Epoch: 6| Step: 11
Training loss: 0.08962878584861755
Validation loss: 1.3755734530828332

Epoch: 6| Step: 12
Training loss: 0.060537226498126984
Validation loss: 1.3755294513958756

Epoch: 6| Step: 13
Training loss: 0.04513532668352127
Validation loss: 1.3669382756756199

Epoch: 469| Step: 0
Training loss: 0.0890374556183815
Validation loss: 1.3838793257231354

Epoch: 6| Step: 1
Training loss: 0.07377941906452179
Validation loss: 1.367277031303734

Epoch: 6| Step: 2
Training loss: 0.08002357184886932
Validation loss: 1.3871029756402458

Epoch: 6| Step: 3
Training loss: 0.056055471301078796
Validation loss: 1.3975998842588035

Epoch: 6| Step: 4
Training loss: 0.08320075273513794
Validation loss: 1.382405734831287

Epoch: 6| Step: 5
Training loss: 0.06672260165214539
Validation loss: 1.3990640255712694

Epoch: 6| Step: 6
Training loss: 0.06635937094688416
Validation loss: 1.3712656010863602

Epoch: 6| Step: 7
Training loss: 0.05711677670478821
Validation loss: 1.3855052686506701

Epoch: 6| Step: 8
Training loss: 0.04986342415213585
Validation loss: 1.4035042870429255

Epoch: 6| Step: 9
Training loss: 0.0848545953631401
Validation loss: 1.398407797659597

Epoch: 6| Step: 10
Training loss: 0.05997217074036598
Validation loss: 1.3738257269705496

Epoch: 6| Step: 11
Training loss: 0.06742236018180847
Validation loss: 1.3973648080261805

Epoch: 6| Step: 12
Training loss: 0.07672759145498276
Validation loss: 1.3808329118195402

Epoch: 6| Step: 13
Training loss: 0.04874373972415924
Validation loss: 1.3869981381200975

Epoch: 470| Step: 0
Training loss: 0.05492720380425453
Validation loss: 1.3716305699399722

Epoch: 6| Step: 1
Training loss: 0.0633976012468338
Validation loss: 1.3806088662916614

Epoch: 6| Step: 2
Training loss: 0.0398319736123085
Validation loss: 1.3693214462649437

Epoch: 6| Step: 3
Training loss: 0.08810651302337646
Validation loss: 1.3745412557355818

Epoch: 6| Step: 4
Training loss: 0.06024618446826935
Validation loss: 1.3530911553290583

Epoch: 6| Step: 5
Training loss: 0.10138757526874542
Validation loss: 1.3637583076312978

Epoch: 6| Step: 6
Training loss: 0.03623440861701965
Validation loss: 1.370995468990777

Epoch: 6| Step: 7
Training loss: 0.09440083056688309
Validation loss: 1.3687761496472102

Epoch: 6| Step: 8
Training loss: 0.042263153940439224
Validation loss: 1.3619414324401526

Epoch: 6| Step: 9
Training loss: 0.04876946657896042
Validation loss: 1.3737735004835232

Epoch: 6| Step: 10
Training loss: 0.049350984394550323
Validation loss: 1.36403037335283

Epoch: 6| Step: 11
Training loss: 0.06746978312730789
Validation loss: 1.3818127275795065

Epoch: 6| Step: 12
Training loss: 0.056097932159900665
Validation loss: 1.3842554848681214

Epoch: 6| Step: 13
Training loss: 0.07158281654119492
Validation loss: 1.3736308492640013

Epoch: 471| Step: 0
Training loss: 0.07360764592885971
Validation loss: 1.3752886915719638

Epoch: 6| Step: 1
Training loss: 0.06883513927459717
Validation loss: 1.3609980639591013

Epoch: 6| Step: 2
Training loss: 0.07066702097654343
Validation loss: 1.356735985766175

Epoch: 6| Step: 3
Training loss: 0.06474454700946808
Validation loss: 1.363096264100844

Epoch: 6| Step: 4
Training loss: 0.07689416408538818
Validation loss: 1.341778947461036

Epoch: 6| Step: 5
Training loss: 0.07656463980674744
Validation loss: 1.3579065402348836

Epoch: 6| Step: 6
Training loss: 0.04912136495113373
Validation loss: 1.3503100833585184

Epoch: 6| Step: 7
Training loss: 0.059214260429143906
Validation loss: 1.3735400515217935

Epoch: 6| Step: 8
Training loss: 0.09478969126939774
Validation loss: 1.3702901819700837

Epoch: 6| Step: 9
Training loss: 0.043362393975257874
Validation loss: 1.3685754326082045

Epoch: 6| Step: 10
Training loss: 0.06069290637969971
Validation loss: 1.3831930480977541

Epoch: 6| Step: 11
Training loss: 0.05463793873786926
Validation loss: 1.3752481117043445

Epoch: 6| Step: 12
Training loss: 0.08789921551942825
Validation loss: 1.386387219993017

Epoch: 6| Step: 13
Training loss: 0.050695061683654785
Validation loss: 1.4098689556121826

Epoch: 472| Step: 0
Training loss: 0.05987788736820221
Validation loss: 1.3859449676288071

Epoch: 6| Step: 1
Training loss: 0.07522140443325043
Validation loss: 1.3857623325881137

Epoch: 6| Step: 2
Training loss: 0.06579728424549103
Validation loss: 1.3780543816986905

Epoch: 6| Step: 3
Training loss: 0.0669538825750351
Validation loss: 1.394017702789717

Epoch: 6| Step: 4
Training loss: 0.12447920441627502
Validation loss: 1.3928959533091514

Epoch: 6| Step: 5
Training loss: 0.06611225008964539
Validation loss: 1.3868168182270502

Epoch: 6| Step: 6
Training loss: 0.10075175762176514
Validation loss: 1.3821061977776148

Epoch: 6| Step: 7
Training loss: 0.0838269516825676
Validation loss: 1.3831101912324146

Epoch: 6| Step: 8
Training loss: 0.06798994541168213
Validation loss: 1.3808623295958324

Epoch: 6| Step: 9
Training loss: 0.05469207838177681
Validation loss: 1.3795363915863859

Epoch: 6| Step: 10
Training loss: 0.10628165304660797
Validation loss: 1.3932120043744323

Epoch: 6| Step: 11
Training loss: 0.10237827897071838
Validation loss: 1.3954431728650165

Epoch: 6| Step: 12
Training loss: 0.07563360035419464
Validation loss: 1.4043841964455062

Epoch: 6| Step: 13
Training loss: 0.09400378912687302
Validation loss: 1.413345670187345

Epoch: 473| Step: 0
Training loss: 0.051203176379203796
Validation loss: 1.3889768033899286

Epoch: 6| Step: 1
Training loss: 0.09094208478927612
Validation loss: 1.3762333572551768

Epoch: 6| Step: 2
Training loss: 0.08064347505569458
Validation loss: 1.3812178302836675

Epoch: 6| Step: 3
Training loss: 0.08894848823547363
Validation loss: 1.3523903303248908

Epoch: 6| Step: 4
Training loss: 0.11238554120063782
Validation loss: 1.3676826966706144

Epoch: 6| Step: 5
Training loss: 0.05804977938532829
Validation loss: 1.369484402800119

Epoch: 6| Step: 6
Training loss: 0.10766293108463287
Validation loss: 1.3810634202854608

Epoch: 6| Step: 7
Training loss: 0.06520752608776093
Validation loss: 1.4073422762655443

Epoch: 6| Step: 8
Training loss: 0.06959757208824158
Validation loss: 1.3920715521740656

Epoch: 6| Step: 9
Training loss: 0.062225595116615295
Validation loss: 1.400188986973096

Epoch: 6| Step: 10
Training loss: 0.05191115289926529
Validation loss: 1.394784314658052

Epoch: 6| Step: 11
Training loss: 0.09631883352994919
Validation loss: 1.3942268099836124

Epoch: 6| Step: 12
Training loss: 0.10698893666267395
Validation loss: 1.3923517106681742

Epoch: 6| Step: 13
Training loss: 0.04213067516684532
Validation loss: 1.3864975437041251

Epoch: 474| Step: 0
Training loss: 0.06498561054468155
Validation loss: 1.380045416534588

Epoch: 6| Step: 1
Training loss: 0.09210910648107529
Validation loss: 1.375190096516763

Epoch: 6| Step: 2
Training loss: 0.07253760099411011
Validation loss: 1.3747158909356723

Epoch: 6| Step: 3
Training loss: 0.11202331632375717
Validation loss: 1.3880688516042565

Epoch: 6| Step: 4
Training loss: 0.04199867323040962
Validation loss: 1.364807108397125

Epoch: 6| Step: 5
Training loss: 0.05410907790064812
Validation loss: 1.381929066873366

Epoch: 6| Step: 6
Training loss: 0.07477270066738129
Validation loss: 1.3886969217690088

Epoch: 6| Step: 7
Training loss: 0.07962913811206818
Validation loss: 1.3866380183927474

Epoch: 6| Step: 8
Training loss: 0.08470641821622849
Validation loss: 1.4072608300434646

Epoch: 6| Step: 9
Training loss: 0.10420612245798111
Validation loss: 1.4141368827512186

Epoch: 6| Step: 10
Training loss: 0.10907232761383057
Validation loss: 1.420550133592339

Epoch: 6| Step: 11
Training loss: 0.060980506241321564
Validation loss: 1.3949523497653264

Epoch: 6| Step: 12
Training loss: 0.0692816972732544
Validation loss: 1.4134031047103226

Epoch: 6| Step: 13
Training loss: 0.03305642306804657
Validation loss: 1.4034321308135986

Epoch: 475| Step: 0
Training loss: 0.05899994075298309
Validation loss: 1.3831821590341546

Epoch: 6| Step: 1
Training loss: 0.06569501757621765
Validation loss: 1.384568937363163

Epoch: 6| Step: 2
Training loss: 0.09640812128782272
Validation loss: 1.3846976052048385

Epoch: 6| Step: 3
Training loss: 0.0634332001209259
Validation loss: 1.375398434618468

Epoch: 6| Step: 4
Training loss: 0.06412217766046524
Validation loss: 1.3772806159911617

Epoch: 6| Step: 5
Training loss: 0.06290780007839203
Validation loss: 1.389975373462964

Epoch: 6| Step: 6
Training loss: 0.06163778528571129
Validation loss: 1.3947533548519175

Epoch: 6| Step: 7
Training loss: 0.06132633239030838
Validation loss: 1.395828891185022

Epoch: 6| Step: 8
Training loss: 0.09885493665933609
Validation loss: 1.4019641478856404

Epoch: 6| Step: 9
Training loss: 0.06937822699546814
Validation loss: 1.3983463741117907

Epoch: 6| Step: 10
Training loss: 0.0654858723282814
Validation loss: 1.4036535486098258

Epoch: 6| Step: 11
Training loss: 0.034090299159288406
Validation loss: 1.409020806512525

Epoch: 6| Step: 12
Training loss: 0.08854127675294876
Validation loss: 1.4155684453184887

Epoch: 6| Step: 13
Training loss: 0.10637997090816498
Validation loss: 1.3990842732050086

Epoch: 476| Step: 0
Training loss: 0.05185622721910477
Validation loss: 1.4124611346952376

Epoch: 6| Step: 1
Training loss: 0.07007257640361786
Validation loss: 1.4221617573051042

Epoch: 6| Step: 2
Training loss: 0.07841682434082031
Validation loss: 1.429760633617319

Epoch: 6| Step: 3
Training loss: 0.04143594950437546
Validation loss: 1.413362128760225

Epoch: 6| Step: 4
Training loss: 0.05080078914761543
Validation loss: 1.4250325208069177

Epoch: 6| Step: 5
Training loss: 0.0841798335313797
Validation loss: 1.4323045220426334

Epoch: 6| Step: 6
Training loss: 0.06977617740631104
Validation loss: 1.4494914944453905

Epoch: 6| Step: 7
Training loss: 0.054256029427051544
Validation loss: 1.4189429949688654

Epoch: 6| Step: 8
Training loss: 0.12264180183410645
Validation loss: 1.4149204851478658

Epoch: 6| Step: 9
Training loss: 0.09676778316497803
Validation loss: 1.422923534147201

Epoch: 6| Step: 10
Training loss: 0.1007901281118393
Validation loss: 1.4169123903397591

Epoch: 6| Step: 11
Training loss: 0.05509335547685623
Validation loss: 1.4107875695792578

Epoch: 6| Step: 12
Training loss: 0.09970307350158691
Validation loss: 1.4320847244672879

Epoch: 6| Step: 13
Training loss: 0.07787758111953735
Validation loss: 1.4222871372776646

Epoch: 477| Step: 0
Training loss: 0.07707950472831726
Validation loss: 1.4075649335820188

Epoch: 6| Step: 1
Training loss: 0.12502506375312805
Validation loss: 1.4146281916608092

Epoch: 6| Step: 2
Training loss: 0.19502770900726318
Validation loss: 1.4343940301608014

Epoch: 6| Step: 3
Training loss: 0.1050591766834259
Validation loss: 1.3977576045579807

Epoch: 6| Step: 4
Training loss: 0.05238044261932373
Validation loss: 1.4016759190508115

Epoch: 6| Step: 5
Training loss: 0.08108747750520706
Validation loss: 1.3850857660334597

Epoch: 6| Step: 6
Training loss: 0.08504493534564972
Validation loss: 1.3845045874195714

Epoch: 6| Step: 7
Training loss: 0.11794604361057281
Validation loss: 1.387308741128573

Epoch: 6| Step: 8
Training loss: 0.21243397891521454
Validation loss: 1.398867384079964

Epoch: 6| Step: 9
Training loss: 0.14335677027702332
Validation loss: 1.389612336312571

Epoch: 6| Step: 10
Training loss: 0.07770553231239319
Validation loss: 1.4121049911745134

Epoch: 6| Step: 11
Training loss: 0.0632069781422615
Validation loss: 1.421231601827888

Epoch: 6| Step: 12
Training loss: 0.11068125814199448
Validation loss: 1.411228019704101

Epoch: 6| Step: 13
Training loss: 0.08548137545585632
Validation loss: 1.4233604977207799

Epoch: 478| Step: 0
Training loss: 0.07788604497909546
Validation loss: 1.4164355557451966

Epoch: 6| Step: 1
Training loss: 0.10262571275234222
Validation loss: 1.439711836076552

Epoch: 6| Step: 2
Training loss: 0.09000243991613388
Validation loss: 1.4231780408531107

Epoch: 6| Step: 3
Training loss: 0.12545599043369293
Validation loss: 1.4252082686270438

Epoch: 6| Step: 4
Training loss: 0.06741590797901154
Validation loss: 1.4382044499920261

Epoch: 6| Step: 5
Training loss: 0.08163215219974518
Validation loss: 1.4277028396565428

Epoch: 6| Step: 6
Training loss: 0.1425078958272934
Validation loss: 1.4433157277363602

Epoch: 6| Step: 7
Training loss: 0.1611451506614685
Validation loss: 1.4363306087832297

Epoch: 6| Step: 8
Training loss: 0.21430769562721252
Validation loss: 1.4154505127219743

Epoch: 6| Step: 9
Training loss: 0.07959164679050446
Validation loss: 1.4212823555033693

Epoch: 6| Step: 10
Training loss: 0.11632247269153595
Validation loss: 1.4172319019994428

Epoch: 6| Step: 11
Training loss: 0.10718301683664322
Validation loss: 1.410462858215455

Epoch: 6| Step: 12
Training loss: 0.14276766777038574
Validation loss: 1.4194190239393583

Epoch: 6| Step: 13
Training loss: 0.09966718405485153
Validation loss: 1.4089295146285847

Epoch: 479| Step: 0
Training loss: 0.15192611515522003
Validation loss: 1.4133318649825228

Epoch: 6| Step: 1
Training loss: 0.07721110433340073
Validation loss: 1.4145743661029364

Epoch: 6| Step: 2
Training loss: 0.10146121680736542
Validation loss: 1.4186311460310412

Epoch: 6| Step: 3
Training loss: 0.0716257244348526
Validation loss: 1.414791295605321

Epoch: 6| Step: 4
Training loss: 0.09286745637655258
Validation loss: 1.4369852581331808

Epoch: 6| Step: 5
Training loss: 0.09084544330835342
Validation loss: 1.4018853133724583

Epoch: 6| Step: 6
Training loss: 0.15438319742679596
Validation loss: 1.4218182051053612

Epoch: 6| Step: 7
Training loss: 0.16945037245750427
Validation loss: 1.4253851598308933

Epoch: 6| Step: 8
Training loss: 0.12189555913209915
Validation loss: 1.410850646675274

Epoch: 6| Step: 9
Training loss: 0.1746826469898224
Validation loss: 1.4129130007118307

Epoch: 6| Step: 10
Training loss: 0.1850643903017044
Validation loss: 1.404829050904961

Epoch: 6| Step: 11
Training loss: 0.12044436484575272
Validation loss: 1.417645885098365

Epoch: 6| Step: 12
Training loss: 0.13169220089912415
Validation loss: 1.4075866040363108

Epoch: 6| Step: 13
Training loss: 0.09286122769117355
Validation loss: 1.4468040030489686

Epoch: 480| Step: 0
Training loss: 0.08401820808649063
Validation loss: 1.4366609409291258

Epoch: 6| Step: 1
Training loss: 0.10213472694158554
Validation loss: 1.444293572056678

Epoch: 6| Step: 2
Training loss: 0.13811147212982178
Validation loss: 1.420897058261338

Epoch: 6| Step: 3
Training loss: 0.2181260585784912
Validation loss: 1.436295982330076

Epoch: 6| Step: 4
Training loss: 0.1051996648311615
Validation loss: 1.43467689201396

Epoch: 6| Step: 5
Training loss: 0.08728080987930298
Validation loss: 1.4350175421725038

Epoch: 6| Step: 6
Training loss: 0.0747540146112442
Validation loss: 1.4153798780133646

Epoch: 6| Step: 7
Training loss: 0.08912594616413116
Validation loss: 1.4238261548421716

Epoch: 6| Step: 8
Training loss: 0.16299355030059814
Validation loss: 1.4346583120284542

Epoch: 6| Step: 9
Training loss: 0.14133009314537048
Validation loss: 1.4245045313271143

Epoch: 6| Step: 10
Training loss: 0.09177560359239578
Validation loss: 1.4217111590088054

Epoch: 6| Step: 11
Training loss: 0.09928836673498154
Validation loss: 1.4286735070649015

Epoch: 6| Step: 12
Training loss: 0.07668103277683258
Validation loss: 1.4387780940660866

Epoch: 6| Step: 13
Training loss: 0.19603078067302704
Validation loss: 1.4298034996114752

Epoch: 481| Step: 0
Training loss: 0.08983969688415527
Validation loss: 1.4281760261904808

Epoch: 6| Step: 1
Training loss: 0.07721462845802307
Validation loss: 1.4218572314067552

Epoch: 6| Step: 2
Training loss: 0.10927934944629669
Validation loss: 1.4190534673711306

Epoch: 6| Step: 3
Training loss: 0.1117609366774559
Validation loss: 1.439661346456056

Epoch: 6| Step: 4
Training loss: 0.10991359502077103
Validation loss: 1.4130685496073898

Epoch: 6| Step: 5
Training loss: 0.08083529025316238
Validation loss: 1.43264945989014

Epoch: 6| Step: 6
Training loss: 0.10659521818161011
Validation loss: 1.438640490014066

Epoch: 6| Step: 7
Training loss: 0.09706355631351471
Validation loss: 1.4232869263618224

Epoch: 6| Step: 8
Training loss: 0.09920620918273926
Validation loss: 1.3957572521701935

Epoch: 6| Step: 9
Training loss: 0.06913921982049942
Validation loss: 1.406546054347869

Epoch: 6| Step: 10
Training loss: 0.039870645850896835
Validation loss: 1.3951819737752278

Epoch: 6| Step: 11
Training loss: 0.06581229716539383
Validation loss: 1.3914384918828164

Epoch: 6| Step: 12
Training loss: 0.0659293383359909
Validation loss: 1.3797486802583099

Epoch: 6| Step: 13
Training loss: 0.06036730110645294
Validation loss: 1.3873417146744267

Epoch: 482| Step: 0
Training loss: 0.05679478868842125
Validation loss: 1.37151881828103

Epoch: 6| Step: 1
Training loss: 0.06888532638549805
Validation loss: 1.363175925388131

Epoch: 6| Step: 2
Training loss: 0.07211486995220184
Validation loss: 1.3744241781132196

Epoch: 6| Step: 3
Training loss: 0.1005868911743164
Validation loss: 1.3748604430947253

Epoch: 6| Step: 4
Training loss: 0.08892413973808289
Validation loss: 1.3740143878485567

Epoch: 6| Step: 5
Training loss: 0.08456101268529892
Validation loss: 1.382791821674634

Epoch: 6| Step: 6
Training loss: 0.09950446337461472
Validation loss: 1.3943664207253406

Epoch: 6| Step: 7
Training loss: 0.0837370902299881
Validation loss: 1.3814050375774343

Epoch: 6| Step: 8
Training loss: 0.12071676552295685
Validation loss: 1.3812468558229425

Epoch: 6| Step: 9
Training loss: 0.08082672208547592
Validation loss: 1.3779006632425452

Epoch: 6| Step: 10
Training loss: 0.07942849397659302
Validation loss: 1.3757604334944038

Epoch: 6| Step: 11
Training loss: 0.08933909237384796
Validation loss: 1.386161781126453

Epoch: 6| Step: 12
Training loss: 0.08799348771572113
Validation loss: 1.4152746578698516

Epoch: 6| Step: 13
Training loss: 0.08535350859165192
Validation loss: 1.4229589668653344

Epoch: 483| Step: 0
Training loss: 0.08931422978639603
Validation loss: 1.3921105246390066

Epoch: 6| Step: 1
Training loss: 0.11804048717021942
Validation loss: 1.4139649983375304

Epoch: 6| Step: 2
Training loss: 0.09879601001739502
Validation loss: 1.394730866596263

Epoch: 6| Step: 3
Training loss: 0.06518135964870453
Validation loss: 1.386685029152901

Epoch: 6| Step: 4
Training loss: 0.11401069164276123
Validation loss: 1.36296126919408

Epoch: 6| Step: 5
Training loss: 0.07412013411521912
Validation loss: 1.3646172015897688

Epoch: 6| Step: 6
Training loss: 0.0735335573554039
Validation loss: 1.354465228255077

Epoch: 6| Step: 7
Training loss: 0.044564247131347656
Validation loss: 1.3377621378949893

Epoch: 6| Step: 8
Training loss: 0.06226664036512375
Validation loss: 1.3319239718939668

Epoch: 6| Step: 9
Training loss: 0.09486779570579529
Validation loss: 1.3412063211523078

Epoch: 6| Step: 10
Training loss: 0.10244184732437134
Validation loss: 1.3352395398642427

Epoch: 6| Step: 11
Training loss: 0.12785843014717102
Validation loss: 1.3315921124591623

Epoch: 6| Step: 12
Training loss: 0.16341453790664673
Validation loss: 1.343163800495927

Epoch: 6| Step: 13
Training loss: 0.11129425466060638
Validation loss: 1.3430329509960708

Epoch: 484| Step: 0
Training loss: 0.10320442169904709
Validation loss: 1.3451066350424161

Epoch: 6| Step: 1
Training loss: 0.1148681789636612
Validation loss: 1.3627152237840878

Epoch: 6| Step: 2
Training loss: 0.06098061054944992
Validation loss: 1.3374690676248202

Epoch: 6| Step: 3
Training loss: 0.11718516051769257
Validation loss: 1.3563585537736134

Epoch: 6| Step: 4
Training loss: 0.08118152618408203
Validation loss: 1.4031063010615688

Epoch: 6| Step: 5
Training loss: 0.08378268778324127
Validation loss: 1.3813292672557216

Epoch: 6| Step: 6
Training loss: 0.10637089610099792
Validation loss: 1.3893512551502516

Epoch: 6| Step: 7
Training loss: 0.07634896039962769
Validation loss: 1.38217975888201

Epoch: 6| Step: 8
Training loss: 0.08064815402030945
Validation loss: 1.3588323580321444

Epoch: 6| Step: 9
Training loss: 0.08614136278629303
Validation loss: 1.3786690619684034

Epoch: 6| Step: 10
Training loss: 0.09010817110538483
Validation loss: 1.369844356531738

Epoch: 6| Step: 11
Training loss: 0.11525891721248627
Validation loss: 1.394116424745129

Epoch: 6| Step: 12
Training loss: 0.0782715454697609
Validation loss: 1.3824123887605564

Epoch: 6| Step: 13
Training loss: 0.07321347296237946
Validation loss: 1.3855721283984441

Epoch: 485| Step: 0
Training loss: 0.09701181948184967
Validation loss: 1.4118258517275575

Epoch: 6| Step: 1
Training loss: 0.07984296977519989
Validation loss: 1.3846595684687297

Epoch: 6| Step: 2
Training loss: 0.06559545546770096
Validation loss: 1.405731285772016

Epoch: 6| Step: 3
Training loss: 0.07299640029668808
Validation loss: 1.4046331874785885

Epoch: 6| Step: 4
Training loss: 0.0699157565832138
Validation loss: 1.3928484109140211

Epoch: 6| Step: 5
Training loss: 0.10260030627250671
Validation loss: 1.376287583381899

Epoch: 6| Step: 6
Training loss: 0.05868464335799217
Validation loss: 1.3950430808528778

Epoch: 6| Step: 7
Training loss: 0.04234500229358673
Validation loss: 1.385570933741908

Epoch: 6| Step: 8
Training loss: 0.08095447719097137
Validation loss: 1.3632293888317641

Epoch: 6| Step: 9
Training loss: 0.07418696582317352
Validation loss: 1.3591787411320595

Epoch: 6| Step: 10
Training loss: 0.07646484673023224
Validation loss: 1.3828291111094977

Epoch: 6| Step: 11
Training loss: 0.08431839942932129
Validation loss: 1.3604616785562167

Epoch: 6| Step: 12
Training loss: 0.07104942202568054
Validation loss: 1.360180729178972

Epoch: 6| Step: 13
Training loss: 0.09471097588539124
Validation loss: 1.3614355287244242

Epoch: 486| Step: 0
Training loss: 0.04509127140045166
Validation loss: 1.3710190737119285

Epoch: 6| Step: 1
Training loss: 0.06359057128429413
Validation loss: 1.3902910326116829

Epoch: 6| Step: 2
Training loss: 0.07156594097614288
Validation loss: 1.3615775697974748

Epoch: 6| Step: 3
Training loss: 0.11757174879312515
Validation loss: 1.3727536932114632

Epoch: 6| Step: 4
Training loss: 0.05178156867623329
Validation loss: 1.3861929626875027

Epoch: 6| Step: 5
Training loss: 0.12817923724651337
Validation loss: 1.359785875966472

Epoch: 6| Step: 6
Training loss: 0.15275359153747559
Validation loss: 1.3990998819310179

Epoch: 6| Step: 7
Training loss: 0.07243401557207108
Validation loss: 1.4151865743821668

Epoch: 6| Step: 8
Training loss: 0.06323041766881943
Validation loss: 1.4148938502034833

Epoch: 6| Step: 9
Training loss: 0.0661129280924797
Validation loss: 1.4013708445333666

Epoch: 6| Step: 10
Training loss: 0.07414405047893524
Validation loss: 1.4082760028941657

Epoch: 6| Step: 11
Training loss: 0.0828709825873375
Validation loss: 1.4060417875166862

Epoch: 6| Step: 12
Training loss: 0.10969993472099304
Validation loss: 1.4103012969416957

Epoch: 6| Step: 13
Training loss: 0.047794897109270096
Validation loss: 1.413882274781504

Epoch: 487| Step: 0
Training loss: 0.056122586131095886
Validation loss: 1.4169508654584166

Epoch: 6| Step: 1
Training loss: 0.07967234402894974
Validation loss: 1.4290911638608543

Epoch: 6| Step: 2
Training loss: 0.05895175039768219
Validation loss: 1.4078980889371646

Epoch: 6| Step: 3
Training loss: 0.06029430031776428
Validation loss: 1.410399813805857

Epoch: 6| Step: 4
Training loss: 0.09244125336408615
Validation loss: 1.4097347464612735

Epoch: 6| Step: 5
Training loss: 0.050442613661289215
Validation loss: 1.3841033013918067

Epoch: 6| Step: 6
Training loss: 0.061468347907066345
Validation loss: 1.381804596352321

Epoch: 6| Step: 7
Training loss: 0.07507012039422989
Validation loss: 1.3722740623258776

Epoch: 6| Step: 8
Training loss: 0.0666813999414444
Validation loss: 1.366935165979529

Epoch: 6| Step: 9
Training loss: 0.07096700370311737
Validation loss: 1.3651969009830105

Epoch: 6| Step: 10
Training loss: 0.06789440661668777
Validation loss: 1.3542505105336506

Epoch: 6| Step: 11
Training loss: 0.07682403177022934
Validation loss: 1.3544311411278223

Epoch: 6| Step: 12
Training loss: 0.08935750275850296
Validation loss: 1.3502385872666554

Epoch: 6| Step: 13
Training loss: 0.10877997428178787
Validation loss: 1.3542909442737538

Epoch: 488| Step: 0
Training loss: 0.06431391835212708
Validation loss: 1.3671500657194404

Epoch: 6| Step: 1
Training loss: 0.051170434802770615
Validation loss: 1.3918810365020589

Epoch: 6| Step: 2
Training loss: 0.04457654803991318
Validation loss: 1.3758527527573288

Epoch: 6| Step: 3
Training loss: 0.06896734237670898
Validation loss: 1.3966963957714778

Epoch: 6| Step: 4
Training loss: 0.08602586388587952
Validation loss: 1.3931687185841222

Epoch: 6| Step: 5
Training loss: 0.07749444246292114
Validation loss: 1.3922744207484747

Epoch: 6| Step: 6
Training loss: 0.05693758279085159
Validation loss: 1.3899687163291439

Epoch: 6| Step: 7
Training loss: 0.06746148318052292
Validation loss: 1.4012145842275312

Epoch: 6| Step: 8
Training loss: 0.06358303129673004
Validation loss: 1.375312247583943

Epoch: 6| Step: 9
Training loss: 0.06907641142606735
Validation loss: 1.395027425340427

Epoch: 6| Step: 10
Training loss: 0.07637528330087662
Validation loss: 1.3915385603904724

Epoch: 6| Step: 11
Training loss: 0.05341459438204765
Validation loss: 1.3925393653172318

Epoch: 6| Step: 12
Training loss: 0.07009581476449966
Validation loss: 1.3807423319867862

Epoch: 6| Step: 13
Training loss: 0.034165576100349426
Validation loss: 1.378236407874733

Epoch: 489| Step: 0
Training loss: 0.04677871614694595
Validation loss: 1.394713257589648

Epoch: 6| Step: 1
Training loss: 0.07860685884952545
Validation loss: 1.377356840718177

Epoch: 6| Step: 2
Training loss: 0.07834576070308685
Validation loss: 1.3754781048784974

Epoch: 6| Step: 3
Training loss: 0.06348804384469986
Validation loss: 1.383104012858483

Epoch: 6| Step: 4
Training loss: 0.08098525553941727
Validation loss: 1.399867053954832

Epoch: 6| Step: 5
Training loss: 0.06150277331471443
Validation loss: 1.4058621801355833

Epoch: 6| Step: 6
Training loss: 0.05140192061662674
Validation loss: 1.3890789234510033

Epoch: 6| Step: 7
Training loss: 0.045508284121751785
Validation loss: 1.3996881900295135

Epoch: 6| Step: 8
Training loss: 0.07527630776166916
Validation loss: 1.3929906314419163

Epoch: 6| Step: 9
Training loss: 0.06459750235080719
Validation loss: 1.3806256568560036

Epoch: 6| Step: 10
Training loss: 0.07841359078884125
Validation loss: 1.4048848549524944

Epoch: 6| Step: 11
Training loss: 0.0455683097243309
Validation loss: 1.3834618599184099

Epoch: 6| Step: 12
Training loss: 0.08353406935930252
Validation loss: 1.4028524788477088

Epoch: 6| Step: 13
Training loss: 0.05394657328724861
Validation loss: 1.3957213291557886

Epoch: 490| Step: 0
Training loss: 0.057691656053066254
Validation loss: 1.378638675135951

Epoch: 6| Step: 1
Training loss: 0.05923573672771454
Validation loss: 1.3908787914501723

Epoch: 6| Step: 2
Training loss: 0.05305738002061844
Validation loss: 1.3943290761722031

Epoch: 6| Step: 3
Training loss: 0.07229157537221909
Validation loss: 1.3865908698369098

Epoch: 6| Step: 4
Training loss: 0.07561056315898895
Validation loss: 1.4015894205339494

Epoch: 6| Step: 5
Training loss: 0.058101825416088104
Validation loss: 1.3998985867346487

Epoch: 6| Step: 6
Training loss: 0.0798041895031929
Validation loss: 1.397778344410722

Epoch: 6| Step: 7
Training loss: 0.09385611116886139
Validation loss: 1.4022435872785506

Epoch: 6| Step: 8
Training loss: 0.07366862148046494
Validation loss: 1.3767698926310385

Epoch: 6| Step: 9
Training loss: 0.051811039447784424
Validation loss: 1.3545121774878552

Epoch: 6| Step: 10
Training loss: 0.07128090411424637
Validation loss: 1.3528896724024126

Epoch: 6| Step: 11
Training loss: 0.07419826835393906
Validation loss: 1.3525690891409432

Epoch: 6| Step: 12
Training loss: 0.049423255026340485
Validation loss: 1.3644950197589012

Epoch: 6| Step: 13
Training loss: 0.07971630990505219
Validation loss: 1.3560284081325735

Epoch: 491| Step: 0
Training loss: 0.056382790207862854
Validation loss: 1.3539996480429044

Epoch: 6| Step: 1
Training loss: 0.060611605644226074
Validation loss: 1.35413832049216

Epoch: 6| Step: 2
Training loss: 0.08353778719902039
Validation loss: 1.37061527082997

Epoch: 6| Step: 3
Training loss: 0.05726815387606621
Validation loss: 1.383307328788183

Epoch: 6| Step: 4
Training loss: 0.06335494667291641
Validation loss: 1.3494533890037126

Epoch: 6| Step: 5
Training loss: 0.07631443440914154
Validation loss: 1.357274172126606

Epoch: 6| Step: 6
Training loss: 0.06532174348831177
Validation loss: 1.3666775649593723

Epoch: 6| Step: 7
Training loss: 0.05375884473323822
Validation loss: 1.3577047035258303

Epoch: 6| Step: 8
Training loss: 0.06665007770061493
Validation loss: 1.3729613724575247

Epoch: 6| Step: 9
Training loss: 0.08858928829431534
Validation loss: 1.355928192215581

Epoch: 6| Step: 10
Training loss: 0.09033611416816711
Validation loss: 1.3766628965254752

Epoch: 6| Step: 11
Training loss: 0.10025046020746231
Validation loss: 1.356516650927964

Epoch: 6| Step: 12
Training loss: 0.12737034261226654
Validation loss: 1.3722157773151193

Epoch: 6| Step: 13
Training loss: 0.09135888516902924
Validation loss: 1.3694492431097134

Epoch: 492| Step: 0
Training loss: 0.06309778988361359
Validation loss: 1.3714633757068264

Epoch: 6| Step: 1
Training loss: 0.07501088082790375
Validation loss: 1.3724524321094635

Epoch: 6| Step: 2
Training loss: 0.1219591274857521
Validation loss: 1.3727379466897698

Epoch: 6| Step: 3
Training loss: 0.07386080920696259
Validation loss: 1.393513060385181

Epoch: 6| Step: 4
Training loss: 0.07642659544944763
Validation loss: 1.3801332724991666

Epoch: 6| Step: 5
Training loss: 0.05908463895320892
Validation loss: 1.3919674119641703

Epoch: 6| Step: 6
Training loss: 0.06426878273487091
Validation loss: 1.382449250067434

Epoch: 6| Step: 7
Training loss: 0.07929602265357971
Validation loss: 1.3858694107301774

Epoch: 6| Step: 8
Training loss: 0.06508693844079971
Validation loss: 1.3894881638147498

Epoch: 6| Step: 9
Training loss: 0.056813910603523254
Validation loss: 1.3964145805246087

Epoch: 6| Step: 10
Training loss: 0.08986477553844452
Validation loss: 1.3955740377467165

Epoch: 6| Step: 11
Training loss: 0.0847221240401268
Validation loss: 1.3971162431983537

Epoch: 6| Step: 12
Training loss: 0.0527777373790741
Validation loss: 1.4010543797605781

Epoch: 6| Step: 13
Training loss: 0.09522136300802231
Validation loss: 1.3931076411278016

Epoch: 493| Step: 0
Training loss: 0.09907938539981842
Validation loss: 1.4318888623227355

Epoch: 6| Step: 1
Training loss: 0.0823303759098053
Validation loss: 1.412236281620559

Epoch: 6| Step: 2
Training loss: 0.06084837019443512
Validation loss: 1.4001330380798669

Epoch: 6| Step: 3
Training loss: 0.07385849952697754
Validation loss: 1.4037192495920325

Epoch: 6| Step: 4
Training loss: 0.06371265649795532
Validation loss: 1.4167744280189596

Epoch: 6| Step: 5
Training loss: 0.09306596964597702
Validation loss: 1.4075517192963631

Epoch: 6| Step: 6
Training loss: 0.06660261750221252
Validation loss: 1.3854364131086616

Epoch: 6| Step: 7
Training loss: 0.07029976695775986
Validation loss: 1.3834489378877866

Epoch: 6| Step: 8
Training loss: 0.06801767647266388
Validation loss: 1.3605219253929712

Epoch: 6| Step: 9
Training loss: 0.04791604354977608
Validation loss: 1.3637661036624704

Epoch: 6| Step: 10
Training loss: 0.06438254565000534
Validation loss: 1.3619174418910858

Epoch: 6| Step: 11
Training loss: 0.09854264557361603
Validation loss: 1.3615118265151978

Epoch: 6| Step: 12
Training loss: 0.07157571613788605
Validation loss: 1.362091201607899

Epoch: 6| Step: 13
Training loss: 0.06799159944057465
Validation loss: 1.3813660721625052

Epoch: 494| Step: 0
Training loss: 0.040637992322444916
Validation loss: 1.3860857217542586

Epoch: 6| Step: 1
Training loss: 0.058112964034080505
Validation loss: 1.387236898945224

Epoch: 6| Step: 2
Training loss: 0.07063233852386475
Validation loss: 1.3985277465594712

Epoch: 6| Step: 3
Training loss: 0.08131479471921921
Validation loss: 1.402211041860683

Epoch: 6| Step: 4
Training loss: 0.07253627479076385
Validation loss: 1.3911706850092898

Epoch: 6| Step: 5
Training loss: 0.0614316388964653
Validation loss: 1.4105154557894635

Epoch: 6| Step: 6
Training loss: 0.04788527637720108
Validation loss: 1.4078519895512571

Epoch: 6| Step: 7
Training loss: 0.07577799260616302
Validation loss: 1.3778062507670412

Epoch: 6| Step: 8
Training loss: 0.04203489422798157
Validation loss: 1.3954493179116199

Epoch: 6| Step: 9
Training loss: 0.07734941691160202
Validation loss: 1.3937152278038762

Epoch: 6| Step: 10
Training loss: 0.048286281526088715
Validation loss: 1.4155749672202653

Epoch: 6| Step: 11
Training loss: 0.09491711854934692
Validation loss: 1.3948720911497712

Epoch: 6| Step: 12
Training loss: 0.09477802366018295
Validation loss: 1.3928058865249797

Epoch: 6| Step: 13
Training loss: 0.06456652283668518
Validation loss: 1.4268671504912838

Epoch: 495| Step: 0
Training loss: 0.06168036162853241
Validation loss: 1.4019388383434666

Epoch: 6| Step: 1
Training loss: 0.05679911747574806
Validation loss: 1.4055369977028138

Epoch: 6| Step: 2
Training loss: 0.058774448931217194
Validation loss: 1.4263421694437664

Epoch: 6| Step: 3
Training loss: 0.08899834007024765
Validation loss: 1.4087281842385568

Epoch: 6| Step: 4
Training loss: 0.058332659304142
Validation loss: 1.4093508387124667

Epoch: 6| Step: 5
Training loss: 0.07040806114673615
Validation loss: 1.4159509507558679

Epoch: 6| Step: 6
Training loss: 0.0807686597108841
Validation loss: 1.3956380018623926

Epoch: 6| Step: 7
Training loss: 0.06203646957874298
Validation loss: 1.4043405581546087

Epoch: 6| Step: 8
Training loss: 0.08476174622774124
Validation loss: 1.3857483158829391

Epoch: 6| Step: 9
Training loss: 0.08391276746988297
Validation loss: 1.397133490090729

Epoch: 6| Step: 10
Training loss: 0.06388436257839203
Validation loss: 1.3809110733770555

Epoch: 6| Step: 11
Training loss: 0.08361907303333282
Validation loss: 1.3758023221005675

Epoch: 6| Step: 12
Training loss: 0.03649749606847763
Validation loss: 1.355947034333342

Epoch: 6| Step: 13
Training loss: 0.053782906383275986
Validation loss: 1.387863173279711

Epoch: 496| Step: 0
Training loss: 0.054359070956707
Validation loss: 1.3762224515279133

Epoch: 6| Step: 1
Training loss: 0.07999584078788757
Validation loss: 1.356922371413118

Epoch: 6| Step: 2
Training loss: 0.04835886508226395
Validation loss: 1.3691232396710304

Epoch: 6| Step: 3
Training loss: 0.08720044791698456
Validation loss: 1.3532910520030605

Epoch: 6| Step: 4
Training loss: 0.08767645061016083
Validation loss: 1.3602984105387042

Epoch: 6| Step: 5
Training loss: 0.06831316649913788
Validation loss: 1.3622031096489198

Epoch: 6| Step: 6
Training loss: 0.05193410441279411
Validation loss: 1.3443537745424496

Epoch: 6| Step: 7
Training loss: 0.050983406603336334
Validation loss: 1.3252829172277962

Epoch: 6| Step: 8
Training loss: 0.06200063228607178
Validation loss: 1.3789384749627882

Epoch: 6| Step: 9
Training loss: 0.06317116320133209
Validation loss: 1.368383429704174

Epoch: 6| Step: 10
Training loss: 0.0640895739197731
Validation loss: 1.3829726326850154

Epoch: 6| Step: 11
Training loss: 0.06332068890333176
Validation loss: 1.3753823708462458

Epoch: 6| Step: 12
Training loss: 0.07360576093196869
Validation loss: 1.3773700485947311

Epoch: 6| Step: 13
Training loss: 0.06355787068605423
Validation loss: 1.3655024222148362

Epoch: 497| Step: 0
Training loss: 0.06196339428424835
Validation loss: 1.3692818431444065

Epoch: 6| Step: 1
Training loss: 0.09352420270442963
Validation loss: 1.373129790829074

Epoch: 6| Step: 2
Training loss: 0.09100383520126343
Validation loss: 1.3689677439710146

Epoch: 6| Step: 3
Training loss: 0.08561080694198608
Validation loss: 1.3695366703053957

Epoch: 6| Step: 4
Training loss: 0.07515977323055267
Validation loss: 1.3784270504469514

Epoch: 6| Step: 5
Training loss: 0.08960537612438202
Validation loss: 1.3682394130255586

Epoch: 6| Step: 6
Training loss: 0.04745498299598694
Validation loss: 1.3624988044461896

Epoch: 6| Step: 7
Training loss: 0.0630142018198967
Validation loss: 1.391144972975536

Epoch: 6| Step: 8
Training loss: 0.07159508764743805
Validation loss: 1.392181279838726

Epoch: 6| Step: 9
Training loss: 0.07628302276134491
Validation loss: 1.3875100138366863

Epoch: 6| Step: 10
Training loss: 0.054234832525253296
Validation loss: 1.3674852681416336

Epoch: 6| Step: 11
Training loss: 0.07602476328611374
Validation loss: 1.3558762842609036

Epoch: 6| Step: 12
Training loss: 0.08657575398683548
Validation loss: 1.3646068252542967

Epoch: 6| Step: 13
Training loss: 0.04764679819345474
Validation loss: 1.3457875841407365

Epoch: 498| Step: 0
Training loss: 0.06221790611743927
Validation loss: 1.35094674300122

Epoch: 6| Step: 1
Training loss: 0.06982367485761642
Validation loss: 1.3504387640183972

Epoch: 6| Step: 2
Training loss: 0.06985916197299957
Validation loss: 1.3231147489240092

Epoch: 6| Step: 3
Training loss: 0.09875525534152985
Validation loss: 1.340741112668027

Epoch: 6| Step: 4
Training loss: 0.049125734716653824
Validation loss: 1.337538569204269

Epoch: 6| Step: 5
Training loss: 0.06799817085266113
Validation loss: 1.3339726706986785

Epoch: 6| Step: 6
Training loss: 0.0515519380569458
Validation loss: 1.3477004164008684

Epoch: 6| Step: 7
Training loss: 0.058483488857746124
Validation loss: 1.339818936522289

Epoch: 6| Step: 8
Training loss: 0.08574812114238739
Validation loss: 1.3558972715049662

Epoch: 6| Step: 9
Training loss: 0.07266993075609207
Validation loss: 1.3645472039458573

Epoch: 6| Step: 10
Training loss: 0.059658233076334
Validation loss: 1.3691816624774729

Epoch: 6| Step: 11
Training loss: 0.06752227991819382
Validation loss: 1.3574515273494105

Epoch: 6| Step: 12
Training loss: 0.07674533128738403
Validation loss: 1.380061254706434

Epoch: 6| Step: 13
Training loss: 0.053616899996995926
Validation loss: 1.3827890042335755

Epoch: 499| Step: 0
Training loss: 0.052315887063741684
Validation loss: 1.3759615818659465

Epoch: 6| Step: 1
Training loss: 0.07907456159591675
Validation loss: 1.366791825140676

Epoch: 6| Step: 2
Training loss: 0.05586676299571991
Validation loss: 1.3703850507736206

Epoch: 6| Step: 3
Training loss: 0.0622757226228714
Validation loss: 1.4032569123852638

Epoch: 6| Step: 4
Training loss: 0.10063698887825012
Validation loss: 1.377866562976632

Epoch: 6| Step: 5
Training loss: 0.07825244218111038
Validation loss: 1.37917737871088

Epoch: 6| Step: 6
Training loss: 0.10516933351755142
Validation loss: 1.3674400602617571

Epoch: 6| Step: 7
Training loss: 0.045399174094200134
Validation loss: 1.3788349916858058

Epoch: 6| Step: 8
Training loss: 0.05273646116256714
Validation loss: 1.385757464234547

Epoch: 6| Step: 9
Training loss: 0.04133675619959831
Validation loss: 1.3803029393637052

Epoch: 6| Step: 10
Training loss: 0.08631446957588196
Validation loss: 1.3783234357833862

Epoch: 6| Step: 11
Training loss: 0.06993012130260468
Validation loss: 1.3795289839467695

Epoch: 6| Step: 12
Training loss: 0.03604983165860176
Validation loss: 1.3758263293132986

Epoch: 6| Step: 13
Training loss: 0.06936873495578766
Validation loss: 1.3756092953425583

Epoch: 500| Step: 0
Training loss: 0.06396760046482086
Validation loss: 1.379881997262278

Epoch: 6| Step: 1
Training loss: 0.04994945973157883
Validation loss: 1.3852682344375118

Epoch: 6| Step: 2
Training loss: 0.10931488126516342
Validation loss: 1.3807713626533427

Epoch: 6| Step: 3
Training loss: 0.07445809245109558
Validation loss: 1.3911277286468013

Epoch: 6| Step: 4
Training loss: 0.07195237278938293
Validation loss: 1.37732151375022

Epoch: 6| Step: 5
Training loss: 0.054445624351501465
Validation loss: 1.3820171740747267

Epoch: 6| Step: 6
Training loss: 0.0897972583770752
Validation loss: 1.3594914924713872

Epoch: 6| Step: 7
Training loss: 0.06291914731264114
Validation loss: 1.4043993347434587

Epoch: 6| Step: 8
Training loss: 0.06289812922477722
Validation loss: 1.3906365786829302

Epoch: 6| Step: 9
Training loss: 0.04240674898028374
Validation loss: 1.4160685167517713

Epoch: 6| Step: 10
Training loss: 0.04565679281949997
Validation loss: 1.3757959809354556

Epoch: 6| Step: 11
Training loss: 0.04643961787223816
Validation loss: 1.3907883615903958

Epoch: 6| Step: 12
Training loss: 0.08192306756973267
Validation loss: 1.4020090256967852

Epoch: 6| Step: 13
Training loss: 0.07913166284561157
Validation loss: 1.3838553351740683

Epoch: 501| Step: 0
Training loss: 0.04140639677643776
Validation loss: 1.3654769723133375

Epoch: 6| Step: 1
Training loss: 0.07698153704404831
Validation loss: 1.3817535350399632

Epoch: 6| Step: 2
Training loss: 0.07453103363513947
Validation loss: 1.3787051516194497

Epoch: 6| Step: 3
Training loss: 0.05557979643344879
Validation loss: 1.3823468467240692

Epoch: 6| Step: 4
Training loss: 0.06994936615228653
Validation loss: 1.3881174889943932

Epoch: 6| Step: 5
Training loss: 0.04947047680616379
Validation loss: 1.3713115299901655

Epoch: 6| Step: 6
Training loss: 0.061834417283535004
Validation loss: 1.3853018130025556

Epoch: 6| Step: 7
Training loss: 0.06803207844495773
Validation loss: 1.389967180067493

Epoch: 6| Step: 8
Training loss: 0.05065023526549339
Validation loss: 1.3818871244307487

Epoch: 6| Step: 9
Training loss: 0.04695965349674225
Validation loss: 1.3912125889972975

Epoch: 6| Step: 10
Training loss: 0.07130544632673264
Validation loss: 1.3622586970688195

Epoch: 6| Step: 11
Training loss: 0.055671922862529755
Validation loss: 1.3832379502634848

Epoch: 6| Step: 12
Training loss: 0.049284473061561584
Validation loss: 1.3730673610523183

Epoch: 6| Step: 13
Training loss: 0.03617048263549805
Validation loss: 1.3536136502860694

Epoch: 502| Step: 0
Training loss: 0.05911087244749069
Validation loss: 1.3462027965053436

Epoch: 6| Step: 1
Training loss: 0.08720970898866653
Validation loss: 1.3656872510910034

Epoch: 6| Step: 2
Training loss: 0.0835043415427208
Validation loss: 1.3647834479167897

Epoch: 6| Step: 3
Training loss: 0.056878432631492615
Validation loss: 1.3533175042880479

Epoch: 6| Step: 4
Training loss: 0.04524841532111168
Validation loss: 1.3412022167636501

Epoch: 6| Step: 5
Training loss: 0.07397280633449554
Validation loss: 1.3560740890041474

Epoch: 6| Step: 6
Training loss: 0.0818626806139946
Validation loss: 1.3553267371269964

Epoch: 6| Step: 7
Training loss: 0.06464030593633652
Validation loss: 1.3708115918661958

Epoch: 6| Step: 8
Training loss: 0.03956238180398941
Validation loss: 1.3646681013927664

Epoch: 6| Step: 9
Training loss: 0.04811568185687065
Validation loss: 1.3600360257651216

Epoch: 6| Step: 10
Training loss: 0.058940984308719635
Validation loss: 1.3558006145620858

Epoch: 6| Step: 11
Training loss: 0.07314006239175797
Validation loss: 1.356791264267378

Epoch: 6| Step: 12
Training loss: 0.05844160541892052
Validation loss: 1.3925987905071628

Epoch: 6| Step: 13
Training loss: 0.07045170664787292
Validation loss: 1.3959603053267284

Epoch: 503| Step: 0
Training loss: 0.0433795340359211
Validation loss: 1.3842860703827233

Epoch: 6| Step: 1
Training loss: 0.10204890370368958
Validation loss: 1.3883623807660994

Epoch: 6| Step: 2
Training loss: 0.06005224585533142
Validation loss: 1.3751008049134286

Epoch: 6| Step: 3
Training loss: 0.05269388109445572
Validation loss: 1.4002494324919998

Epoch: 6| Step: 4
Training loss: 0.06929311901330948
Validation loss: 1.3984426106176069

Epoch: 6| Step: 5
Training loss: 0.06199745833873749
Validation loss: 1.374938352133638

Epoch: 6| Step: 6
Training loss: 0.08489447832107544
Validation loss: 1.3725272788796374

Epoch: 6| Step: 7
Training loss: 0.058626338839530945
Validation loss: 1.3721229119967389

Epoch: 6| Step: 8
Training loss: 0.06687082350254059
Validation loss: 1.3834585925584197

Epoch: 6| Step: 9
Training loss: 0.05849362164735794
Validation loss: 1.3768048171074159

Epoch: 6| Step: 10
Training loss: 0.07591313123703003
Validation loss: 1.3759619651302215

Epoch: 6| Step: 11
Training loss: 0.05919327214360237
Validation loss: 1.3952638590207664

Epoch: 6| Step: 12
Training loss: 0.052527278661727905
Validation loss: 1.37900855336138

Epoch: 6| Step: 13
Training loss: 0.03882257640361786
Validation loss: 1.392025718124964

Epoch: 504| Step: 0
Training loss: 0.046913087368011475
Validation loss: 1.374307317118491

Epoch: 6| Step: 1
Training loss: 0.06431885808706284
Validation loss: 1.3943372900767992

Epoch: 6| Step: 2
Training loss: 0.047423385083675385
Validation loss: 1.3989949713471115

Epoch: 6| Step: 3
Training loss: 0.04737856984138489
Validation loss: 1.3715724919431953

Epoch: 6| Step: 4
Training loss: 0.05590875446796417
Validation loss: 1.3694118568974156

Epoch: 6| Step: 5
Training loss: 0.0513458289206028
Validation loss: 1.3854456537513322

Epoch: 6| Step: 6
Training loss: 0.09765162318944931
Validation loss: 1.369629083141204

Epoch: 6| Step: 7
Training loss: 0.07280237972736359
Validation loss: 1.3788780140620407

Epoch: 6| Step: 8
Training loss: 0.06660822778940201
Validation loss: 1.362816224816025

Epoch: 6| Step: 9
Training loss: 0.061767421662807465
Validation loss: 1.3772066696997611

Epoch: 6| Step: 10
Training loss: 0.07857845723628998
Validation loss: 1.35783887422213

Epoch: 6| Step: 11
Training loss: 0.05185072124004364
Validation loss: 1.376661709559861

Epoch: 6| Step: 12
Training loss: 0.07526493072509766
Validation loss: 1.36405857147709

Epoch: 6| Step: 13
Training loss: 0.09604477882385254
Validation loss: 1.3674376139076807

Epoch: 505| Step: 0
Training loss: 0.054854247719049454
Validation loss: 1.367811788794815

Epoch: 6| Step: 1
Training loss: 0.0367717482149601
Validation loss: 1.3777170296638244

Epoch: 6| Step: 2
Training loss: 0.06071871519088745
Validation loss: 1.3879690888107463

Epoch: 6| Step: 3
Training loss: 0.05071374028921127
Validation loss: 1.4069223775658557

Epoch: 6| Step: 4
Training loss: 0.05486432462930679
Validation loss: 1.3991746530737927

Epoch: 6| Step: 5
Training loss: 0.08715029060840607
Validation loss: 1.3897660842505835

Epoch: 6| Step: 6
Training loss: 0.06086570397019386
Validation loss: 1.398248839121993

Epoch: 6| Step: 7
Training loss: 0.0728718489408493
Validation loss: 1.391054432879212

Epoch: 6| Step: 8
Training loss: 0.04859267175197601
Validation loss: 1.4037355940829042

Epoch: 6| Step: 9
Training loss: 0.10841497778892517
Validation loss: 1.3904342728276406

Epoch: 6| Step: 10
Training loss: 0.07555010914802551
Validation loss: 1.3868531398875739

Epoch: 6| Step: 11
Training loss: 0.0605221763253212
Validation loss: 1.3881595942281908

Epoch: 6| Step: 12
Training loss: 0.08617155998945236
Validation loss: 1.3787141999890726

Epoch: 6| Step: 13
Training loss: 0.08876252174377441
Validation loss: 1.3978617011859853

Epoch: 506| Step: 0
Training loss: 0.07853401452302933
Validation loss: 1.3814314308986868

Epoch: 6| Step: 1
Training loss: 0.08107608556747437
Validation loss: 1.371575887485217

Epoch: 6| Step: 2
Training loss: 0.05714508891105652
Validation loss: 1.409065745210135

Epoch: 6| Step: 3
Training loss: 0.039643920958042145
Validation loss: 1.3723692752981698

Epoch: 6| Step: 4
Training loss: 0.07820110023021698
Validation loss: 1.4083290433370939

Epoch: 6| Step: 5
Training loss: 0.08321863412857056
Validation loss: 1.4090644813353015

Epoch: 6| Step: 6
Training loss: 0.06776098906993866
Validation loss: 1.3931731613733436

Epoch: 6| Step: 7
Training loss: 0.09074949473142624
Validation loss: 1.3811025850234493

Epoch: 6| Step: 8
Training loss: 0.04699312150478363
Validation loss: 1.3721276316591489

Epoch: 6| Step: 9
Training loss: 0.051564574241638184
Validation loss: 1.350707613011842

Epoch: 6| Step: 10
Training loss: 0.07677468657493591
Validation loss: 1.3554431738391999

Epoch: 6| Step: 11
Training loss: 0.09439273178577423
Validation loss: 1.354979121556846

Epoch: 6| Step: 12
Training loss: 0.05283327400684357
Validation loss: 1.3446030488578222

Epoch: 6| Step: 13
Training loss: 0.0944640040397644
Validation loss: 1.3444657351381035

Epoch: 507| Step: 0
Training loss: 0.06682951003313065
Validation loss: 1.3398835505208662

Epoch: 6| Step: 1
Training loss: 0.06053295359015465
Validation loss: 1.360767658038806

Epoch: 6| Step: 2
Training loss: 0.057175904512405396
Validation loss: 1.3668442009597697

Epoch: 6| Step: 3
Training loss: 0.07526400685310364
Validation loss: 1.3593743860080678

Epoch: 6| Step: 4
Training loss: 0.05791794881224632
Validation loss: 1.3754575765261086

Epoch: 6| Step: 5
Training loss: 0.09717727452516556
Validation loss: 1.3701930289627404

Epoch: 6| Step: 6
Training loss: 0.06240547075867653
Validation loss: 1.3754270025478896

Epoch: 6| Step: 7
Training loss: 0.06290224194526672
Validation loss: 1.3903348727892804

Epoch: 6| Step: 8
Training loss: 0.07655808329582214
Validation loss: 1.3993608669568134

Epoch: 6| Step: 9
Training loss: 0.10130739212036133
Validation loss: 1.399641900934199

Epoch: 6| Step: 10
Training loss: 0.08802981674671173
Validation loss: 1.3833277315221808

Epoch: 6| Step: 11
Training loss: 0.07823220640420914
Validation loss: 1.3981691393800961

Epoch: 6| Step: 12
Training loss: 0.07292395830154419
Validation loss: 1.4156368958052767

Epoch: 6| Step: 13
Training loss: 0.06218261271715164
Validation loss: 1.4246826582057501

Epoch: 508| Step: 0
Training loss: 0.04552305117249489
Validation loss: 1.4096276503737255

Epoch: 6| Step: 1
Training loss: 0.04883640259504318
Validation loss: 1.4183991173262238

Epoch: 6| Step: 2
Training loss: 0.05900444835424423
Validation loss: 1.4115330724306003

Epoch: 6| Step: 3
Training loss: 0.06820466369390488
Validation loss: 1.425546048148986

Epoch: 6| Step: 4
Training loss: 0.1075766310095787
Validation loss: 1.41539458305605

Epoch: 6| Step: 5
Training loss: 0.05847896635532379
Validation loss: 1.4251399399131857

Epoch: 6| Step: 6
Training loss: 0.07726091146469116
Validation loss: 1.4216278804245817

Epoch: 6| Step: 7
Training loss: 0.06588069349527359
Validation loss: 1.41236081751444

Epoch: 6| Step: 8
Training loss: 0.05437278002500534
Validation loss: 1.3840791172878717

Epoch: 6| Step: 9
Training loss: 0.061360955238342285
Validation loss: 1.3789266078702864

Epoch: 6| Step: 10
Training loss: 0.08537789434194565
Validation loss: 1.3807298880751415

Epoch: 6| Step: 11
Training loss: 0.08386321365833282
Validation loss: 1.397042183465855

Epoch: 6| Step: 12
Training loss: 0.05738407373428345
Validation loss: 1.3751221767035864

Epoch: 6| Step: 13
Training loss: 0.09032133221626282
Validation loss: 1.3873940603707426

Epoch: 509| Step: 0
Training loss: 0.0731276422739029
Validation loss: 1.3765142489505071

Epoch: 6| Step: 1
Training loss: 0.08437499403953552
Validation loss: 1.3988978382079833

Epoch: 6| Step: 2
Training loss: 0.06158315762877464
Validation loss: 1.3815409034811041

Epoch: 6| Step: 3
Training loss: 0.06830748915672302
Validation loss: 1.3804087626036776

Epoch: 6| Step: 4
Training loss: 0.08868460357189178
Validation loss: 1.3730635104640838

Epoch: 6| Step: 5
Training loss: 0.0964030921459198
Validation loss: 1.3701058055764885

Epoch: 6| Step: 6
Training loss: 0.05112539231777191
Validation loss: 1.3897856807196012

Epoch: 6| Step: 7
Training loss: 0.13552311062812805
Validation loss: 1.3946921466499247

Epoch: 6| Step: 8
Training loss: 0.09163226187229156
Validation loss: 1.388147291316781

Epoch: 6| Step: 9
Training loss: 0.11710456758737564
Validation loss: 1.3927361337087487

Epoch: 6| Step: 10
Training loss: 0.15231941640377045
Validation loss: 1.3979297594357563

Epoch: 6| Step: 11
Training loss: 0.060617681592702866
Validation loss: 1.4027916013553579

Epoch: 6| Step: 12
Training loss: 0.061300553381443024
Validation loss: 1.3914092227976809

Epoch: 6| Step: 13
Training loss: 0.12839286029338837
Validation loss: 1.3710240106428824

Epoch: 510| Step: 0
Training loss: 0.07986972481012344
Validation loss: 1.3995746950949393

Epoch: 6| Step: 1
Training loss: 0.08132857829332352
Validation loss: 1.3923119742383239

Epoch: 6| Step: 2
Training loss: 0.06459340453147888
Validation loss: 1.393824556822418

Epoch: 6| Step: 3
Training loss: 0.09838235378265381
Validation loss: 1.4060571065513037

Epoch: 6| Step: 4
Training loss: 0.08842410147190094
Validation loss: 1.4218947169601277

Epoch: 6| Step: 5
Training loss: 0.1152094230055809
Validation loss: 1.4144526245773479

Epoch: 6| Step: 6
Training loss: 0.06897445023059845
Validation loss: 1.4166481623085596

Epoch: 6| Step: 7
Training loss: 0.06449154019355774
Validation loss: 1.4181604795558478

Epoch: 6| Step: 8
Training loss: 0.07541059702634811
Validation loss: 1.3992191117296937

Epoch: 6| Step: 9
Training loss: 0.09000833332538605
Validation loss: 1.4037988762701712

Epoch: 6| Step: 10
Training loss: 0.09358714520931244
Validation loss: 1.409505263451607

Epoch: 6| Step: 11
Training loss: 0.1051798164844513
Validation loss: 1.43915988937501

Epoch: 6| Step: 12
Training loss: 0.05491965264081955
Validation loss: 1.4150582590410787

Epoch: 6| Step: 13
Training loss: 0.04525555670261383
Validation loss: 1.4148470560709636

Epoch: 511| Step: 0
Training loss: 0.0649118646979332
Validation loss: 1.404482986337395

Epoch: 6| Step: 1
Training loss: 0.04094266891479492
Validation loss: 1.3972142780980756

Epoch: 6| Step: 2
Training loss: 0.05505716800689697
Validation loss: 1.4089622279649139

Epoch: 6| Step: 3
Training loss: 0.11981853097677231
Validation loss: 1.3908446488841888

Epoch: 6| Step: 4
Training loss: 0.08830918371677399
Validation loss: 1.393397500438075

Epoch: 6| Step: 5
Training loss: 0.04893641546368599
Validation loss: 1.3757192293802898

Epoch: 6| Step: 6
Training loss: 0.059141721576452255
Validation loss: 1.3871601486718783

Epoch: 6| Step: 7
Training loss: 0.04539243504405022
Validation loss: 1.376498322333059

Epoch: 6| Step: 8
Training loss: 0.06982235610485077
Validation loss: 1.3720473563799294

Epoch: 6| Step: 9
Training loss: 0.0316980816423893
Validation loss: 1.3568568915449164

Epoch: 6| Step: 10
Training loss: 0.08990079909563065
Validation loss: 1.3670529165575582

Epoch: 6| Step: 11
Training loss: 0.047845855355262756
Validation loss: 1.3588369482307023

Epoch: 6| Step: 12
Training loss: 0.05777720361948013
Validation loss: 1.3506044034034974

Epoch: 6| Step: 13
Training loss: 0.04622530937194824
Validation loss: 1.3639804817015124

Epoch: 512| Step: 0
Training loss: 0.08300922065973282
Validation loss: 1.33877133810392

Epoch: 6| Step: 1
Training loss: 0.09856725484132767
Validation loss: 1.3569087328449372

Epoch: 6| Step: 2
Training loss: 0.09328633546829224
Validation loss: 1.3554005199863064

Epoch: 6| Step: 3
Training loss: 0.0680055320262909
Validation loss: 1.3497763513236918

Epoch: 6| Step: 4
Training loss: 0.07662398368120193
Validation loss: 1.3476191618109261

Epoch: 6| Step: 5
Training loss: 0.05431465804576874
Validation loss: 1.332867963980603

Epoch: 6| Step: 6
Training loss: 0.06646653264760971
Validation loss: 1.3526606764844669

Epoch: 6| Step: 7
Training loss: 0.04907061532139778
Validation loss: 1.3260170939148113

Epoch: 6| Step: 8
Training loss: 0.1109820157289505
Validation loss: 1.3511125618411648

Epoch: 6| Step: 9
Training loss: 0.0868358463048935
Validation loss: 1.3446835125646284

Epoch: 6| Step: 10
Training loss: 0.07047390937805176
Validation loss: 1.3418744533292708

Epoch: 6| Step: 11
Training loss: 0.0602298304438591
Validation loss: 1.3614552251754268

Epoch: 6| Step: 12
Training loss: 0.08640067279338837
Validation loss: 1.3678431523743497

Epoch: 6| Step: 13
Training loss: 0.10555317997932434
Validation loss: 1.3703291723805089

Epoch: 513| Step: 0
Training loss: 0.09271284937858582
Validation loss: 1.355617259138374

Epoch: 6| Step: 1
Training loss: 0.07097353041172028
Validation loss: 1.3605925639470418

Epoch: 6| Step: 2
Training loss: 0.1050320714712143
Validation loss: 1.3636519652540966

Epoch: 6| Step: 3
Training loss: 0.05023641884326935
Validation loss: 1.3690488556379914

Epoch: 6| Step: 4
Training loss: 0.0502706840634346
Validation loss: 1.3571997060570666

Epoch: 6| Step: 5
Training loss: 0.05605534836649895
Validation loss: 1.3784319559733074

Epoch: 6| Step: 6
Training loss: 0.07412385940551758
Validation loss: 1.3653328008549188

Epoch: 6| Step: 7
Training loss: 0.058360300958156586
Validation loss: 1.3787755363730974

Epoch: 6| Step: 8
Training loss: 0.08629938215017319
Validation loss: 1.368167737478851

Epoch: 6| Step: 9
Training loss: 0.07086105644702911
Validation loss: 1.3671661564098891

Epoch: 6| Step: 10
Training loss: 0.0725773498415947
Validation loss: 1.3699617462773477

Epoch: 6| Step: 11
Training loss: 0.08801555633544922
Validation loss: 1.3560812537388136

Epoch: 6| Step: 12
Training loss: 0.04778704047203064
Validation loss: 1.3550968939258206

Epoch: 6| Step: 13
Training loss: 0.09415360540151596
Validation loss: 1.363027129122006

Epoch: 514| Step: 0
Training loss: 0.06341397762298584
Validation loss: 1.3498937032556022

Epoch: 6| Step: 1
Training loss: 0.05955754220485687
Validation loss: 1.3650637454884027

Epoch: 6| Step: 2
Training loss: 0.06862618774175644
Validation loss: 1.3667015285902127

Epoch: 6| Step: 3
Training loss: 0.10619291663169861
Validation loss: 1.379092344673731

Epoch: 6| Step: 4
Training loss: 0.08550195395946503
Validation loss: 1.3715220074499808

Epoch: 6| Step: 5
Training loss: 0.09786764532327652
Validation loss: 1.370371425023643

Epoch: 6| Step: 6
Training loss: 0.0666286051273346
Validation loss: 1.380297104517619

Epoch: 6| Step: 7
Training loss: 0.10344274342060089
Validation loss: 1.3725454666281258

Epoch: 6| Step: 8
Training loss: 0.07022621482610703
Validation loss: 1.3637895840470509

Epoch: 6| Step: 9
Training loss: 0.07007881253957748
Validation loss: 1.381590852173426

Epoch: 6| Step: 10
Training loss: 0.06187025457620621
Validation loss: 1.38534011443456

Epoch: 6| Step: 11
Training loss: 0.06659349799156189
Validation loss: 1.3728053787703156

Epoch: 6| Step: 12
Training loss: 0.0790962427854538
Validation loss: 1.3774556831646991

Epoch: 6| Step: 13
Training loss: 0.07820865511894226
Validation loss: 1.3764726884903447

Epoch: 515| Step: 0
Training loss: 0.08759880065917969
Validation loss: 1.3748848489535752

Epoch: 6| Step: 1
Training loss: 0.11796410381793976
Validation loss: 1.403198105032726

Epoch: 6| Step: 2
Training loss: 0.12117897719144821
Validation loss: 1.3879328722594886

Epoch: 6| Step: 3
Training loss: 0.056152306497097015
Validation loss: 1.38751914552463

Epoch: 6| Step: 4
Training loss: 0.06414767354726791
Validation loss: 1.3839284527686335

Epoch: 6| Step: 5
Training loss: 0.0794973224401474
Validation loss: 1.3932694504337926

Epoch: 6| Step: 6
Training loss: 0.0840059369802475
Validation loss: 1.4125155979587185

Epoch: 6| Step: 7
Training loss: 0.06226246803998947
Validation loss: 1.4017328036728727

Epoch: 6| Step: 8
Training loss: 0.0838952511548996
Validation loss: 1.4036104627834853

Epoch: 6| Step: 9
Training loss: 0.06854542344808578
Validation loss: 1.4021711477669336

Epoch: 6| Step: 10
Training loss: 0.06860189139842987
Validation loss: 1.4037750574850267

Epoch: 6| Step: 11
Training loss: 0.04271594434976578
Validation loss: 1.3908956255964053

Epoch: 6| Step: 12
Training loss: 0.03222265467047691
Validation loss: 1.3977241041839763

Epoch: 6| Step: 13
Training loss: 0.07203909754753113
Validation loss: 1.3976879953056254

Epoch: 516| Step: 0
Training loss: 0.04616991803050041
Validation loss: 1.4000550880227038

Epoch: 6| Step: 1
Training loss: 0.07613445818424225
Validation loss: 1.4125775162891676

Epoch: 6| Step: 2
Training loss: 0.07282966375350952
Validation loss: 1.4011495305645851

Epoch: 6| Step: 3
Training loss: 0.06007229909300804
Validation loss: 1.3950604418272614

Epoch: 6| Step: 4
Training loss: 0.06254487484693527
Validation loss: 1.3798593026335522

Epoch: 6| Step: 5
Training loss: 0.059739746153354645
Validation loss: 1.399566109462451

Epoch: 6| Step: 6
Training loss: 0.05991270765662193
Validation loss: 1.3889996544007333

Epoch: 6| Step: 7
Training loss: 0.06092109531164169
Validation loss: 1.400058655328648

Epoch: 6| Step: 8
Training loss: 0.05567183345556259
Validation loss: 1.39608895778656

Epoch: 6| Step: 9
Training loss: 0.07070969045162201
Validation loss: 1.386464854722382

Epoch: 6| Step: 10
Training loss: 0.054007768630981445
Validation loss: 1.393462210573176

Epoch: 6| Step: 11
Training loss: 0.04723166674375534
Validation loss: 1.4068202382774764

Epoch: 6| Step: 12
Training loss: 0.07965047657489777
Validation loss: 1.388759918110345

Epoch: 6| Step: 13
Training loss: 0.07780180871486664
Validation loss: 1.4086071009277015

Epoch: 517| Step: 0
Training loss: 0.04872163012623787
Validation loss: 1.3913617146912443

Epoch: 6| Step: 1
Training loss: 0.05834607407450676
Validation loss: 1.4108315167888519

Epoch: 6| Step: 2
Training loss: 0.06083466112613678
Validation loss: 1.3929613892750075

Epoch: 6| Step: 3
Training loss: 0.03885531425476074
Validation loss: 1.3973202628474082

Epoch: 6| Step: 4
Training loss: 0.0583772286772728
Validation loss: 1.3871668769467262

Epoch: 6| Step: 5
Training loss: 0.055798519402742386
Validation loss: 1.384852514472059

Epoch: 6| Step: 6
Training loss: 0.05209881067276001
Validation loss: 1.3649239899009786

Epoch: 6| Step: 7
Training loss: 0.06782565265893936
Validation loss: 1.384747971770584

Epoch: 6| Step: 8
Training loss: 0.11438818275928497
Validation loss: 1.371344877827552

Epoch: 6| Step: 9
Training loss: 0.04120110720396042
Validation loss: 1.365912591257403

Epoch: 6| Step: 10
Training loss: 0.061680156737565994
Validation loss: 1.3576776827535322

Epoch: 6| Step: 11
Training loss: 0.07336810231208801
Validation loss: 1.3470836621458813

Epoch: 6| Step: 12
Training loss: 0.06067709997296333
Validation loss: 1.3680830283831524

Epoch: 6| Step: 13
Training loss: 0.07007551193237305
Validation loss: 1.3445089453010148

Epoch: 518| Step: 0
Training loss: 0.06777083873748779
Validation loss: 1.370069364065765

Epoch: 6| Step: 1
Training loss: 0.06386131793260574
Validation loss: 1.3491159728778306

Epoch: 6| Step: 2
Training loss: 0.07556572556495667
Validation loss: 1.3653453742304156

Epoch: 6| Step: 3
Training loss: 0.05275316536426544
Validation loss: 1.366598718909807

Epoch: 6| Step: 4
Training loss: 0.04599408060312271
Validation loss: 1.3694488284408406

Epoch: 6| Step: 5
Training loss: 0.033482640981674194
Validation loss: 1.36187732091514

Epoch: 6| Step: 6
Training loss: 0.06643448770046234
Validation loss: 1.3631994096181725

Epoch: 6| Step: 7
Training loss: 0.11521978676319122
Validation loss: 1.3743404265372985

Epoch: 6| Step: 8
Training loss: 0.04544109106063843
Validation loss: 1.3609322142857376

Epoch: 6| Step: 9
Training loss: 0.06499508023262024
Validation loss: 1.3672720988591511

Epoch: 6| Step: 10
Training loss: 0.04305771365761757
Validation loss: 1.3638822570923836

Epoch: 6| Step: 11
Training loss: 0.06545601785182953
Validation loss: 1.3560978654892213

Epoch: 6| Step: 12
Training loss: 0.07722395658493042
Validation loss: 1.3674939729834115

Epoch: 6| Step: 13
Training loss: 0.06778062880039215
Validation loss: 1.4013265717414118

Epoch: 519| Step: 0
Training loss: 0.07085016369819641
Validation loss: 1.37644515755356

Epoch: 6| Step: 1
Training loss: 0.05136649310588837
Validation loss: 1.388805498359024

Epoch: 6| Step: 2
Training loss: 0.04173443838953972
Validation loss: 1.39413587252299

Epoch: 6| Step: 3
Training loss: 0.10431443899869919
Validation loss: 1.3973399246892622

Epoch: 6| Step: 4
Training loss: 0.11118777841329575
Validation loss: 1.403881371662181

Epoch: 6| Step: 5
Training loss: 0.06938029825687408
Validation loss: 1.389551753638893

Epoch: 6| Step: 6
Training loss: 0.05047544091939926
Validation loss: 1.3734522391391057

Epoch: 6| Step: 7
Training loss: 0.060547903180122375
Validation loss: 1.3761106242415726

Epoch: 6| Step: 8
Training loss: 0.054710179567337036
Validation loss: 1.3661894375278103

Epoch: 6| Step: 9
Training loss: 0.0829489603638649
Validation loss: 1.3712133246083413

Epoch: 6| Step: 10
Training loss: 0.05233260244131088
Validation loss: 1.3639558015331146

Epoch: 6| Step: 11
Training loss: 0.05087115988135338
Validation loss: 1.3610665214959012

Epoch: 6| Step: 12
Training loss: 0.054967135190963745
Validation loss: 1.3582225473978187

Epoch: 6| Step: 13
Training loss: 0.12737411260604858
Validation loss: 1.354220280083277

Epoch: 520| Step: 0
Training loss: 0.06371894478797913
Validation loss: 1.3505875102935299

Epoch: 6| Step: 1
Training loss: 0.06559740751981735
Validation loss: 1.3579731846368441

Epoch: 6| Step: 2
Training loss: 0.11663268506526947
Validation loss: 1.3672517832889353

Epoch: 6| Step: 3
Training loss: 0.05841703340411186
Validation loss: 1.3449227271541473

Epoch: 6| Step: 4
Training loss: 0.0767616555094719
Validation loss: 1.3346601250351116

Epoch: 6| Step: 5
Training loss: 0.06593658030033112
Validation loss: 1.339647218745242

Epoch: 6| Step: 6
Training loss: 0.06839942187070847
Validation loss: 1.3501439966181272

Epoch: 6| Step: 7
Training loss: 0.08045466244220734
Validation loss: 1.3473467929388887

Epoch: 6| Step: 8
Training loss: 0.06904802471399307
Validation loss: 1.3633846775177987

Epoch: 6| Step: 9
Training loss: 0.08023134618997574
Validation loss: 1.3532820029925274

Epoch: 6| Step: 10
Training loss: 0.07889053970575333
Validation loss: 1.376946678084712

Epoch: 6| Step: 11
Training loss: 0.047582074999809265
Validation loss: 1.3820591421537503

Epoch: 6| Step: 12
Training loss: 0.06458143144845963
Validation loss: 1.369780005947236

Epoch: 6| Step: 13
Training loss: 0.05708067864179611
Validation loss: 1.3683981408355057

Epoch: 521| Step: 0
Training loss: 0.05411389842629433
Validation loss: 1.3913189339381393

Epoch: 6| Step: 1
Training loss: 0.03783092275261879
Validation loss: 1.4020411532412294

Epoch: 6| Step: 2
Training loss: 0.049418073147535324
Validation loss: 1.3853100397253548

Epoch: 6| Step: 3
Training loss: 0.0668036937713623
Validation loss: 1.3780826432730562

Epoch: 6| Step: 4
Training loss: 0.0381786972284317
Validation loss: 1.3907138814208329

Epoch: 6| Step: 5
Training loss: 0.051705583930015564
Validation loss: 1.3933967800550564

Epoch: 6| Step: 6
Training loss: 0.0709691047668457
Validation loss: 1.3660625616709392

Epoch: 6| Step: 7
Training loss: 0.0900178849697113
Validation loss: 1.3849299184737667

Epoch: 6| Step: 8
Training loss: 0.05567006766796112
Validation loss: 1.3844071626663208

Epoch: 6| Step: 9
Training loss: 0.04893842712044716
Validation loss: 1.3894480671933902

Epoch: 6| Step: 10
Training loss: 0.08567981421947479
Validation loss: 1.373976525440011

Epoch: 6| Step: 11
Training loss: 0.0650852844119072
Validation loss: 1.37723127231803

Epoch: 6| Step: 12
Training loss: 0.05144099146127701
Validation loss: 1.3913398224820372

Epoch: 6| Step: 13
Training loss: 0.09580355882644653
Validation loss: 1.3932018517166056

Epoch: 522| Step: 0
Training loss: 0.05948479101061821
Validation loss: 1.406802724766475

Epoch: 6| Step: 1
Training loss: 0.09104997664690018
Validation loss: 1.4108492962775692

Epoch: 6| Step: 2
Training loss: 0.09476153552532196
Validation loss: 1.4284131244946552

Epoch: 6| Step: 3
Training loss: 0.09804613888263702
Validation loss: 1.403068983426658

Epoch: 6| Step: 4
Training loss: 0.05794428288936615
Validation loss: 1.392731789619692

Epoch: 6| Step: 5
Training loss: 0.08945527672767639
Validation loss: 1.3949438105988246

Epoch: 6| Step: 6
Training loss: 0.053805071860551834
Validation loss: 1.4054575709886448

Epoch: 6| Step: 7
Training loss: 0.06854580342769623
Validation loss: 1.4056361606044154

Epoch: 6| Step: 8
Training loss: 0.05509882792830467
Validation loss: 1.3962178691740958

Epoch: 6| Step: 9
Training loss: 0.07342557609081268
Validation loss: 1.3978390309118456

Epoch: 6| Step: 10
Training loss: 0.05000999569892883
Validation loss: 1.387865230601321

Epoch: 6| Step: 11
Training loss: 0.05828692018985748
Validation loss: 1.4008724535665205

Epoch: 6| Step: 12
Training loss: 0.06764516979455948
Validation loss: 1.381520612265474

Epoch: 6| Step: 13
Training loss: 0.0654916912317276
Validation loss: 1.3982328458498883

Epoch: 523| Step: 0
Training loss: 0.07834798842668533
Validation loss: 1.3801122442368539

Epoch: 6| Step: 1
Training loss: 0.05345454812049866
Validation loss: 1.3869531468678546

Epoch: 6| Step: 2
Training loss: 0.06599798798561096
Validation loss: 1.393936304635899

Epoch: 6| Step: 3
Training loss: 0.07499253749847412
Validation loss: 1.41057046639022

Epoch: 6| Step: 4
Training loss: 0.06229650229215622
Validation loss: 1.395765116137843

Epoch: 6| Step: 5
Training loss: 0.031935274600982666
Validation loss: 1.405494833505282

Epoch: 6| Step: 6
Training loss: 0.057868845760822296
Validation loss: 1.394369581694244

Epoch: 6| Step: 7
Training loss: 0.07371143996715546
Validation loss: 1.3763250407352243

Epoch: 6| Step: 8
Training loss: 0.02535504475235939
Validation loss: 1.3983850594489806

Epoch: 6| Step: 9
Training loss: 0.0661909356713295
Validation loss: 1.385825849348499

Epoch: 6| Step: 10
Training loss: 0.05260798707604408
Validation loss: 1.4021018628151185

Epoch: 6| Step: 11
Training loss: 0.10628066211938858
Validation loss: 1.3752358613475677

Epoch: 6| Step: 12
Training loss: 0.12030777335166931
Validation loss: 1.3794385963870632

Epoch: 6| Step: 13
Training loss: 0.043133243918418884
Validation loss: 1.3766893981605448

Epoch: 524| Step: 0
Training loss: 0.08571978658437729
Validation loss: 1.3613468780312488

Epoch: 6| Step: 1
Training loss: 0.07302049547433853
Validation loss: 1.3521537242397186

Epoch: 6| Step: 2
Training loss: 0.051189906895160675
Validation loss: 1.3529740007974769

Epoch: 6| Step: 3
Training loss: 0.040467727929353714
Validation loss: 1.3441694680080618

Epoch: 6| Step: 4
Training loss: 0.04747626185417175
Validation loss: 1.3464011223085466

Epoch: 6| Step: 5
Training loss: 0.05271327123045921
Validation loss: 1.342824996158641

Epoch: 6| Step: 6
Training loss: 0.0806252658367157
Validation loss: 1.3446117748496353

Epoch: 6| Step: 7
Training loss: 0.10524599254131317
Validation loss: 1.3552257399405203

Epoch: 6| Step: 8
Training loss: 0.08998244255781174
Validation loss: 1.3305074245698991

Epoch: 6| Step: 9
Training loss: 0.06549331545829773
Validation loss: 1.3643083771069844

Epoch: 6| Step: 10
Training loss: 0.06698749959468842
Validation loss: 1.3490598547843196

Epoch: 6| Step: 11
Training loss: 0.045815546065568924
Validation loss: 1.3509299748687333

Epoch: 6| Step: 12
Training loss: 0.051069147884845734
Validation loss: 1.373670768673702

Epoch: 6| Step: 13
Training loss: 0.05352215841412544
Validation loss: 1.371547947647751

Epoch: 525| Step: 0
Training loss: 0.08854208886623383
Validation loss: 1.3674216020491816

Epoch: 6| Step: 1
Training loss: 0.06957129389047623
Validation loss: 1.3669009631679905

Epoch: 6| Step: 2
Training loss: 0.039116159081459045
Validation loss: 1.3695078985665434

Epoch: 6| Step: 3
Training loss: 0.053146637976169586
Validation loss: 1.3795423341053787

Epoch: 6| Step: 4
Training loss: 0.04562784358859062
Validation loss: 1.350813724020476

Epoch: 6| Step: 5
Training loss: 0.05100243538618088
Validation loss: 1.3475592802929621

Epoch: 6| Step: 6
Training loss: 0.05061565339565277
Validation loss: 1.3335005967847762

Epoch: 6| Step: 7
Training loss: 0.06473599374294281
Validation loss: 1.335346261660258

Epoch: 6| Step: 8
Training loss: 0.09450199455022812
Validation loss: 1.346045409479449

Epoch: 6| Step: 9
Training loss: 0.0793054923415184
Validation loss: 1.3335869562241338

Epoch: 6| Step: 10
Training loss: 0.08298727124929428
Validation loss: 1.3516316330561073

Epoch: 6| Step: 11
Training loss: 0.06931038200855255
Validation loss: 1.3515081303094023

Epoch: 6| Step: 12
Training loss: 0.05145088583230972
Validation loss: 1.3442476635338159

Epoch: 6| Step: 13
Training loss: 0.055538758635520935
Validation loss: 1.3660395132598055

Epoch: 526| Step: 0
Training loss: 0.07239188998937607
Validation loss: 1.3635289233217958

Epoch: 6| Step: 1
Training loss: 0.07884205877780914
Validation loss: 1.3496965849271385

Epoch: 6| Step: 2
Training loss: 0.046623893082141876
Validation loss: 1.3633159296486967

Epoch: 6| Step: 3
Training loss: 0.07565125823020935
Validation loss: 1.3629096848990327

Epoch: 6| Step: 4
Training loss: 0.05313052237033844
Validation loss: 1.3791084840733518

Epoch: 6| Step: 5
Training loss: 0.04933159053325653
Validation loss: 1.3600951894637077

Epoch: 6| Step: 6
Training loss: 0.0446639209985733
Validation loss: 1.377318323299449

Epoch: 6| Step: 7
Training loss: 0.10102885961532593
Validation loss: 1.3633802590831634

Epoch: 6| Step: 8
Training loss: 0.051232364028692245
Validation loss: 1.3742243500166043

Epoch: 6| Step: 9
Training loss: 0.06202200800180435
Validation loss: 1.3736445711505028

Epoch: 6| Step: 10
Training loss: 0.03953126072883606
Validation loss: 1.3540964703406058

Epoch: 6| Step: 11
Training loss: 0.05749250203371048
Validation loss: 1.3626649456639444

Epoch: 6| Step: 12
Training loss: 0.0429348424077034
Validation loss: 1.3716349191563104

Epoch: 6| Step: 13
Training loss: 0.04608853533864021
Validation loss: 1.3792207946059525

Epoch: 527| Step: 0
Training loss: 0.07017970085144043
Validation loss: 1.3492106340264762

Epoch: 6| Step: 1
Training loss: 0.053109310567379
Validation loss: 1.365903567242366

Epoch: 6| Step: 2
Training loss: 0.06831313669681549
Validation loss: 1.3891576695185837

Epoch: 6| Step: 3
Training loss: 0.05792172998189926
Validation loss: 1.3786805073420207

Epoch: 6| Step: 4
Training loss: 0.06407622247934341
Validation loss: 1.3958924598591302

Epoch: 6| Step: 5
Training loss: 0.08775512874126434
Validation loss: 1.3871532717058737

Epoch: 6| Step: 6
Training loss: 0.049913205206394196
Validation loss: 1.4039218874387844

Epoch: 6| Step: 7
Training loss: 0.11758679151535034
Validation loss: 1.3958418215474775

Epoch: 6| Step: 8
Training loss: 0.07789508253335953
Validation loss: 1.3917567140312606

Epoch: 6| Step: 9
Training loss: 0.05706097558140755
Validation loss: 1.409049440455693

Epoch: 6| Step: 10
Training loss: 0.05127599090337753
Validation loss: 1.4055145914836595

Epoch: 6| Step: 11
Training loss: 0.0502542182803154
Validation loss: 1.406345005958311

Epoch: 6| Step: 12
Training loss: 0.053006015717983246
Validation loss: 1.3859153204066779

Epoch: 6| Step: 13
Training loss: 0.06550603359937668
Validation loss: 1.379177426779142

Epoch: 528| Step: 0
Training loss: 0.07978051155805588
Validation loss: 1.367378838600651

Epoch: 6| Step: 1
Training loss: 0.05978746712207794
Validation loss: 1.3757033418583613

Epoch: 6| Step: 2
Training loss: 0.07423055171966553
Validation loss: 1.3733165289766045

Epoch: 6| Step: 3
Training loss: 0.06743335723876953
Validation loss: 1.4000667102875248

Epoch: 6| Step: 4
Training loss: 0.05578584969043732
Validation loss: 1.3793768485387166

Epoch: 6| Step: 5
Training loss: 0.039004988968372345
Validation loss: 1.3941151416429909

Epoch: 6| Step: 6
Training loss: 0.0639948695898056
Validation loss: 1.3942125446052962

Epoch: 6| Step: 7
Training loss: 0.09155406802892685
Validation loss: 1.3801511192834506

Epoch: 6| Step: 8
Training loss: 0.10401934385299683
Validation loss: 1.3738838908492879

Epoch: 6| Step: 9
Training loss: 0.06413345038890839
Validation loss: 1.3897135373084777

Epoch: 6| Step: 10
Training loss: 0.046341422945261
Validation loss: 1.3792442634541502

Epoch: 6| Step: 11
Training loss: 0.0653468668460846
Validation loss: 1.3999434414730276

Epoch: 6| Step: 12
Training loss: 0.09159547090530396
Validation loss: 1.3859795819046676

Epoch: 6| Step: 13
Training loss: 0.058980152010917664
Validation loss: 1.3891986147049935

Epoch: 529| Step: 0
Training loss: 0.028034863993525505
Validation loss: 1.3786848604038198

Epoch: 6| Step: 1
Training loss: 0.05384676903486252
Validation loss: 1.3745075906476667

Epoch: 6| Step: 2
Training loss: 0.07131627202033997
Validation loss: 1.393469629749175

Epoch: 6| Step: 3
Training loss: 0.06872646510601044
Validation loss: 1.4006201528733777

Epoch: 6| Step: 4
Training loss: 0.06488192826509476
Validation loss: 1.4050161351439774

Epoch: 6| Step: 5
Training loss: 0.06945395469665527
Validation loss: 1.4075104728821786

Epoch: 6| Step: 6
Training loss: 0.12740321457386017
Validation loss: 1.4199133778131137

Epoch: 6| Step: 7
Training loss: 0.05982556194067001
Validation loss: 1.4223686238770843

Epoch: 6| Step: 8
Training loss: 0.06976820528507233
Validation loss: 1.3858567642909225

Epoch: 6| Step: 9
Training loss: 0.05796282738447189
Validation loss: 1.4302823441002959

Epoch: 6| Step: 10
Training loss: 0.08133690059185028
Validation loss: 1.4406468714437177

Epoch: 6| Step: 11
Training loss: 0.06262065470218658
Validation loss: 1.434895908960732

Epoch: 6| Step: 12
Training loss: 0.05444972962141037
Validation loss: 1.4335574360303982

Epoch: 6| Step: 13
Training loss: 0.05409141257405281
Validation loss: 1.4182646941113215

Epoch: 530| Step: 0
Training loss: 0.06368105113506317
Validation loss: 1.414643879859678

Epoch: 6| Step: 1
Training loss: 0.044458553194999695
Validation loss: 1.4404165174371453

Epoch: 6| Step: 2
Training loss: 0.06947412341833115
Validation loss: 1.4453444198895526

Epoch: 6| Step: 3
Training loss: 0.08995891362428665
Validation loss: 1.441695927291788

Epoch: 6| Step: 4
Training loss: 0.05001390725374222
Validation loss: 1.4301481285402853

Epoch: 6| Step: 5
Training loss: 0.06925226002931595
Validation loss: 1.4297520678530458

Epoch: 6| Step: 6
Training loss: 0.049644939601421356
Validation loss: 1.4224891175505936

Epoch: 6| Step: 7
Training loss: 0.07961856573820114
Validation loss: 1.416475825412299

Epoch: 6| Step: 8
Training loss: 0.06786471605300903
Validation loss: 1.4150749835916745

Epoch: 6| Step: 9
Training loss: 0.06122330576181412
Validation loss: 1.3933107314571258

Epoch: 6| Step: 10
Training loss: 0.05801156163215637
Validation loss: 1.387249646648284

Epoch: 6| Step: 11
Training loss: 0.0898158848285675
Validation loss: 1.3935925909267959

Epoch: 6| Step: 12
Training loss: 0.06321357190608978
Validation loss: 1.3843806776949155

Epoch: 6| Step: 13
Training loss: 0.04700005054473877
Validation loss: 1.3934925256236907

Epoch: 531| Step: 0
Training loss: 0.05637924373149872
Validation loss: 1.3864438597873976

Epoch: 6| Step: 1
Training loss: 0.053759943693876266
Validation loss: 1.3692592376021928

Epoch: 6| Step: 2
Training loss: 0.05949341505765915
Validation loss: 1.384336265184546

Epoch: 6| Step: 3
Training loss: 0.08682365715503693
Validation loss: 1.3679811480224773

Epoch: 6| Step: 4
Training loss: 0.04981447011232376
Validation loss: 1.3769532352365472

Epoch: 6| Step: 5
Training loss: 0.03597279638051987
Validation loss: 1.3726036510159891

Epoch: 6| Step: 6
Training loss: 0.0810873731970787
Validation loss: 1.388063802514025

Epoch: 6| Step: 7
Training loss: 0.06337760388851166
Validation loss: 1.3756907242600636

Epoch: 6| Step: 8
Training loss: 0.07587514817714691
Validation loss: 1.3792029990944812

Epoch: 6| Step: 9
Training loss: 0.07505300641059875
Validation loss: 1.3905517042324107

Epoch: 6| Step: 10
Training loss: 0.035224128514528275
Validation loss: 1.3885770164510256

Epoch: 6| Step: 11
Training loss: 0.040201544761657715
Validation loss: 1.4167350312714935

Epoch: 6| Step: 12
Training loss: 0.05092304199934006
Validation loss: 1.4266151587168376

Epoch: 6| Step: 13
Training loss: 0.035595282912254333
Validation loss: 1.4205114982461418

Epoch: 532| Step: 0
Training loss: 0.042226530611515045
Validation loss: 1.4177526350944274

Epoch: 6| Step: 1
Training loss: 0.05683611333370209
Validation loss: 1.4355965968101256

Epoch: 6| Step: 2
Training loss: 0.06524784862995148
Validation loss: 1.4189283924718057

Epoch: 6| Step: 3
Training loss: 0.05771545320749283
Validation loss: 1.4266526878521006

Epoch: 6| Step: 4
Training loss: 0.058807529509067535
Validation loss: 1.4035649927713538

Epoch: 6| Step: 5
Training loss: 0.05457717925310135
Validation loss: 1.4067120039334862

Epoch: 6| Step: 6
Training loss: 0.04409797862172127
Validation loss: 1.3938934495372157

Epoch: 6| Step: 7
Training loss: 0.052579160779714584
Validation loss: 1.3731653985156809

Epoch: 6| Step: 8
Training loss: 0.05326766148209572
Validation loss: 1.3625222739352976

Epoch: 6| Step: 9
Training loss: 0.0474005863070488
Validation loss: 1.377124095475802

Epoch: 6| Step: 10
Training loss: 0.05600082129240036
Validation loss: 1.3835061596285911

Epoch: 6| Step: 11
Training loss: 0.05797545611858368
Validation loss: 1.3813297094837311

Epoch: 6| Step: 12
Training loss: 0.08283918350934982
Validation loss: 1.3820446172068197

Epoch: 6| Step: 13
Training loss: 0.04677038639783859
Validation loss: 1.3817113477696654

Epoch: 533| Step: 0
Training loss: 0.07662458717823029
Validation loss: 1.3783837979839695

Epoch: 6| Step: 1
Training loss: 0.07186061143875122
Validation loss: 1.3613723554918844

Epoch: 6| Step: 2
Training loss: 0.07725803554058075
Validation loss: 1.384308966257239

Epoch: 6| Step: 3
Training loss: 0.03565772622823715
Validation loss: 1.3946584911756619

Epoch: 6| Step: 4
Training loss: 0.053151875734329224
Validation loss: 1.4129861939337947

Epoch: 6| Step: 5
Training loss: 0.06429208815097809
Validation loss: 1.3742113132630625

Epoch: 6| Step: 6
Training loss: 0.09777500480413437
Validation loss: 1.3988848687500082

Epoch: 6| Step: 7
Training loss: 0.07838962972164154
Validation loss: 1.400524261177227

Epoch: 6| Step: 8
Training loss: 0.04754263162612915
Validation loss: 1.3925762317513908

Epoch: 6| Step: 9
Training loss: 0.08482909202575684
Validation loss: 1.4037553379612584

Epoch: 6| Step: 10
Training loss: 0.0702274888753891
Validation loss: 1.3948573091978669

Epoch: 6| Step: 11
Training loss: 0.06332030892372131
Validation loss: 1.406045953432719

Epoch: 6| Step: 12
Training loss: 0.06243068352341652
Validation loss: 1.3679077163819344

Epoch: 6| Step: 13
Training loss: 0.06262992322444916
Validation loss: 1.3865407243851693

Epoch: 534| Step: 0
Training loss: 0.07708282768726349
Validation loss: 1.3834221747613722

Epoch: 6| Step: 1
Training loss: 0.06774597615003586
Validation loss: 1.3787697553634644

Epoch: 6| Step: 2
Training loss: 0.05431675910949707
Validation loss: 1.3817311192071566

Epoch: 6| Step: 3
Training loss: 0.06137581169605255
Validation loss: 1.401636008293398

Epoch: 6| Step: 4
Training loss: 0.05253929644823074
Validation loss: 1.378236170737974

Epoch: 6| Step: 5
Training loss: 0.03687785565853119
Validation loss: 1.375531788795225

Epoch: 6| Step: 6
Training loss: 0.05250035226345062
Validation loss: 1.3683253385687386

Epoch: 6| Step: 7
Training loss: 0.062263600528240204
Validation loss: 1.370264555818291

Epoch: 6| Step: 8
Training loss: 0.07888606935739517
Validation loss: 1.3598375781889884

Epoch: 6| Step: 9
Training loss: 0.06807418912649155
Validation loss: 1.3658656138245777

Epoch: 6| Step: 10
Training loss: 0.06818966567516327
Validation loss: 1.3584295216427054

Epoch: 6| Step: 11
Training loss: 0.09413508325815201
Validation loss: 1.3778770034031202

Epoch: 6| Step: 12
Training loss: 0.056722208857536316
Validation loss: 1.3705323767918411

Epoch: 6| Step: 13
Training loss: 0.05377351865172386
Validation loss: 1.3959509147110807

Epoch: 535| Step: 0
Training loss: 0.05489583685994148
Validation loss: 1.3970732176175682

Epoch: 6| Step: 1
Training loss: 0.06477310508489609
Validation loss: 1.4251386427110242

Epoch: 6| Step: 2
Training loss: 0.06555718928575516
Validation loss: 1.4124023529791063

Epoch: 6| Step: 3
Training loss: 0.06306473910808563
Validation loss: 1.3985899007448586

Epoch: 6| Step: 4
Training loss: 0.07270137965679169
Validation loss: 1.397696743729294

Epoch: 6| Step: 5
Training loss: 0.05535561591386795
Validation loss: 1.3986663062085387

Epoch: 6| Step: 6
Training loss: 0.053533878177404404
Validation loss: 1.3766092690088416

Epoch: 6| Step: 7
Training loss: 0.06865790486335754
Validation loss: 1.382407694734553

Epoch: 6| Step: 8
Training loss: 0.06306584179401398
Validation loss: 1.3830442300406836

Epoch: 6| Step: 9
Training loss: 0.05993741750717163
Validation loss: 1.3795317757514216

Epoch: 6| Step: 10
Training loss: 0.038992948830127716
Validation loss: 1.3623769232021865

Epoch: 6| Step: 11
Training loss: 0.0636216253042221
Validation loss: 1.37822905407157

Epoch: 6| Step: 12
Training loss: 0.07480955123901367
Validation loss: 1.3885676681354482

Epoch: 6| Step: 13
Training loss: 0.06411441415548325
Validation loss: 1.389972153530326

Epoch: 536| Step: 0
Training loss: 0.062099769711494446
Validation loss: 1.4097669098966865

Epoch: 6| Step: 1
Training loss: 0.060239020735025406
Validation loss: 1.3704215275344027

Epoch: 6| Step: 2
Training loss: 0.07021026313304901
Validation loss: 1.4054436042744627

Epoch: 6| Step: 3
Training loss: 0.07452351599931717
Validation loss: 1.4015717384635762

Epoch: 6| Step: 4
Training loss: 0.038869649171829224
Validation loss: 1.3731123401272682

Epoch: 6| Step: 5
Training loss: 0.0357462503015995
Validation loss: 1.3805328364013343

Epoch: 6| Step: 6
Training loss: 0.06154350936412811
Validation loss: 1.369401926635414

Epoch: 6| Step: 7
Training loss: 0.05666549503803253
Validation loss: 1.3729342452941402

Epoch: 6| Step: 8
Training loss: 0.0810868963599205
Validation loss: 1.3762910430149367

Epoch: 6| Step: 9
Training loss: 0.04894272983074188
Validation loss: 1.3622187388840543

Epoch: 6| Step: 10
Training loss: 0.05701868236064911
Validation loss: 1.3811709560373777

Epoch: 6| Step: 11
Training loss: 0.06692512333393097
Validation loss: 1.3578304821445095

Epoch: 6| Step: 12
Training loss: 0.04645783454179764
Validation loss: 1.375685453414917

Epoch: 6| Step: 13
Training loss: 0.06648289412260056
Validation loss: 1.376812412533709

Epoch: 537| Step: 0
Training loss: 0.0758177638053894
Validation loss: 1.368456099622993

Epoch: 6| Step: 1
Training loss: 0.050717346370220184
Validation loss: 1.3890797463796472

Epoch: 6| Step: 2
Training loss: 0.04868515208363533
Validation loss: 1.3928329790792158

Epoch: 6| Step: 3
Training loss: 0.0521681010723114
Validation loss: 1.389483633861747

Epoch: 6| Step: 4
Training loss: 0.05563250929117203
Validation loss: 1.3755127742726316

Epoch: 6| Step: 5
Training loss: 0.0554850809276104
Validation loss: 1.3907806258047781

Epoch: 6| Step: 6
Training loss: 0.06091872602701187
Validation loss: 1.3932940575384325

Epoch: 6| Step: 7
Training loss: 0.03635411337018013
Validation loss: 1.3844600146816624

Epoch: 6| Step: 8
Training loss: 0.09600255638360977
Validation loss: 1.3779181434262184

Epoch: 6| Step: 9
Training loss: 0.04803624749183655
Validation loss: 1.3972875956566102

Epoch: 6| Step: 10
Training loss: 0.08545076847076416
Validation loss: 1.3768838990119197

Epoch: 6| Step: 11
Training loss: 0.04801149293780327
Validation loss: 1.3863117502581688

Epoch: 6| Step: 12
Training loss: 0.0659111887216568
Validation loss: 1.378884171926847

Epoch: 6| Step: 13
Training loss: 0.05756121873855591
Validation loss: 1.382886181595505

Epoch: 538| Step: 0
Training loss: 0.08690346777439117
Validation loss: 1.3541635159523255

Epoch: 6| Step: 1
Training loss: 0.07459275424480438
Validation loss: 1.346578686468063

Epoch: 6| Step: 2
Training loss: 0.07763059437274933
Validation loss: 1.3458019046373264

Epoch: 6| Step: 3
Training loss: 0.0577954538166523
Validation loss: 1.338747888483027

Epoch: 6| Step: 4
Training loss: 0.06487727910280228
Validation loss: 1.3528886225915724

Epoch: 6| Step: 5
Training loss: 0.05657430365681648
Validation loss: 1.3263911995836484

Epoch: 6| Step: 6
Training loss: 0.06822562962770462
Validation loss: 1.3438475490898214

Epoch: 6| Step: 7
Training loss: 0.05365303158760071
Validation loss: 1.348993150136804

Epoch: 6| Step: 8
Training loss: 0.08938800543546677
Validation loss: 1.356755942426702

Epoch: 6| Step: 9
Training loss: 0.04893963783979416
Validation loss: 1.3644731967679915

Epoch: 6| Step: 10
Training loss: 0.059786245226860046
Validation loss: 1.3633772230917407

Epoch: 6| Step: 11
Training loss: 0.05354125797748566
Validation loss: 1.3722540486243464

Epoch: 6| Step: 12
Training loss: 0.07314886152744293
Validation loss: 1.390029295798271

Epoch: 6| Step: 13
Training loss: 0.0800144150853157
Validation loss: 1.3703970063117243

Epoch: 539| Step: 0
Training loss: 0.04870441555976868
Validation loss: 1.3902448018391926

Epoch: 6| Step: 1
Training loss: 0.06704078614711761
Validation loss: 1.377983981563199

Epoch: 6| Step: 2
Training loss: 0.06745530664920807
Validation loss: 1.388605462607517

Epoch: 6| Step: 3
Training loss: 0.08734431862831116
Validation loss: 1.3761931721882155

Epoch: 6| Step: 4
Training loss: 0.052894238382577896
Validation loss: 1.3696806276998212

Epoch: 6| Step: 5
Training loss: 0.06139024347066879
Validation loss: 1.3706664885244062

Epoch: 6| Step: 6
Training loss: 0.052668895572423935
Validation loss: 1.3661271525967507

Epoch: 6| Step: 7
Training loss: 0.06004299595952034
Validation loss: 1.345721980576874

Epoch: 6| Step: 8
Training loss: 0.06047922372817993
Validation loss: 1.3421495755513508

Epoch: 6| Step: 9
Training loss: 0.06415214389562607
Validation loss: 1.3538635981980192

Epoch: 6| Step: 10
Training loss: 0.09198950231075287
Validation loss: 1.336542353835157

Epoch: 6| Step: 11
Training loss: 0.055638931691646576
Validation loss: 1.3438233867768319

Epoch: 6| Step: 12
Training loss: 0.040566585958004
Validation loss: 1.3491321597048032

Epoch: 6| Step: 13
Training loss: 0.07523410767316818
Validation loss: 1.3662129525215394

Epoch: 540| Step: 0
Training loss: 0.05728762969374657
Validation loss: 1.3795485240156933

Epoch: 6| Step: 1
Training loss: 0.09626580774784088
Validation loss: 1.387141909650577

Epoch: 6| Step: 2
Training loss: 0.05196325480937958
Validation loss: 1.3596997619957052

Epoch: 6| Step: 3
Training loss: 0.058006346225738525
Validation loss: 1.3640870586518319

Epoch: 6| Step: 4
Training loss: 0.06009777635335922
Validation loss: 1.3586772077827043

Epoch: 6| Step: 5
Training loss: 0.048498544842004776
Validation loss: 1.360125075104416

Epoch: 6| Step: 6
Training loss: 0.05886365473270416
Validation loss: 1.3530864766848985

Epoch: 6| Step: 7
Training loss: 0.10293953865766525
Validation loss: 1.3604264618248068

Epoch: 6| Step: 8
Training loss: 0.08347345888614655
Validation loss: 1.3585970735037198

Epoch: 6| Step: 9
Training loss: 0.0658828467130661
Validation loss: 1.3606786561268631

Epoch: 6| Step: 10
Training loss: 0.0793001651763916
Validation loss: 1.3638181327491679

Epoch: 6| Step: 11
Training loss: 0.09989216923713684
Validation loss: 1.3750130322671705

Epoch: 6| Step: 12
Training loss: 0.039064038544893265
Validation loss: 1.3771315569518714

Epoch: 6| Step: 13
Training loss: 0.05053223669528961
Validation loss: 1.3769403644787368

Epoch: 541| Step: 0
Training loss: 0.03983087092638016
Validation loss: 1.3751942284645573

Epoch: 6| Step: 1
Training loss: 0.12413855642080307
Validation loss: 1.38254068615616

Epoch: 6| Step: 2
Training loss: 0.051833342760801315
Validation loss: 1.3896242867233932

Epoch: 6| Step: 3
Training loss: 0.09850335866212845
Validation loss: 1.381310579597309

Epoch: 6| Step: 4
Training loss: 0.047924887388944626
Validation loss: 1.3832735861501386

Epoch: 6| Step: 5
Training loss: 0.054425351321697235
Validation loss: 1.3818697737109276

Epoch: 6| Step: 6
Training loss: 0.07566450536251068
Validation loss: 1.3663461413434757

Epoch: 6| Step: 7
Training loss: 0.07279542088508606
Validation loss: 1.3914602918009604

Epoch: 6| Step: 8
Training loss: 0.06565085053443909
Validation loss: 1.3880532556964504

Epoch: 6| Step: 9
Training loss: 0.0706043541431427
Validation loss: 1.390589278231385

Epoch: 6| Step: 10
Training loss: 0.04889777675271034
Validation loss: 1.3947601036358905

Epoch: 6| Step: 11
Training loss: 0.07279226928949356
Validation loss: 1.3801919721787976

Epoch: 6| Step: 12
Training loss: 0.0437958799302578
Validation loss: 1.392623318138943

Epoch: 6| Step: 13
Training loss: 0.05797191336750984
Validation loss: 1.395712843505285

Epoch: 542| Step: 0
Training loss: 0.06656187772750854
Validation loss: 1.3848354777982157

Epoch: 6| Step: 1
Training loss: 0.12981964647769928
Validation loss: 1.408367322978153

Epoch: 6| Step: 2
Training loss: 0.06928274035453796
Validation loss: 1.4164868067669611

Epoch: 6| Step: 3
Training loss: 0.06233304738998413
Validation loss: 1.4098232048814014

Epoch: 6| Step: 4
Training loss: 0.04662269353866577
Validation loss: 1.395496981759225

Epoch: 6| Step: 5
Training loss: 0.059817343950271606
Validation loss: 1.3711600630514083

Epoch: 6| Step: 6
Training loss: 0.08769341558218002
Validation loss: 1.387837367673074

Epoch: 6| Step: 7
Training loss: 0.06808727234601974
Validation loss: 1.3758549433882519

Epoch: 6| Step: 8
Training loss: 0.08251327276229858
Validation loss: 1.3686741744318316

Epoch: 6| Step: 9
Training loss: 0.07343600690364838
Validation loss: 1.3646707650153869

Epoch: 6| Step: 10
Training loss: 0.06315629929304123
Validation loss: 1.3649502620902112

Epoch: 6| Step: 11
Training loss: 0.09355735778808594
Validation loss: 1.3772870564973483

Epoch: 6| Step: 12
Training loss: 0.0727134644985199
Validation loss: 1.374403981752293

Epoch: 6| Step: 13
Training loss: 0.10353527963161469
Validation loss: 1.3825674537689454

Epoch: 543| Step: 0
Training loss: 0.05097116529941559
Validation loss: 1.3865067356376237

Epoch: 6| Step: 1
Training loss: 0.0690886378288269
Validation loss: 1.3935231303655973

Epoch: 6| Step: 2
Training loss: 0.04074998199939728
Validation loss: 1.393013136361235

Epoch: 6| Step: 3
Training loss: 0.052839092910289764
Validation loss: 1.4013886265857245

Epoch: 6| Step: 4
Training loss: 0.06880344450473785
Validation loss: 1.4115083576530538

Epoch: 6| Step: 5
Training loss: 0.07251055538654327
Validation loss: 1.4111252625783284

Epoch: 6| Step: 6
Training loss: 0.0876433253288269
Validation loss: 1.4095114789983278

Epoch: 6| Step: 7
Training loss: 0.061322908848524094
Validation loss: 1.384246144243466

Epoch: 6| Step: 8
Training loss: 0.08287639170885086
Validation loss: 1.3953855781144993

Epoch: 6| Step: 9
Training loss: 0.05154399573802948
Validation loss: 1.4034414022199568

Epoch: 6| Step: 10
Training loss: 0.04817292094230652
Validation loss: 1.4162119447544057

Epoch: 6| Step: 11
Training loss: 0.06322440505027771
Validation loss: 1.398505174985496

Epoch: 6| Step: 12
Training loss: 0.05305255949497223
Validation loss: 1.408842921257019

Epoch: 6| Step: 13
Training loss: 0.058367934077978134
Validation loss: 1.4062008306544314

Epoch: 544| Step: 0
Training loss: 0.09100540727376938
Validation loss: 1.4150633260767946

Epoch: 6| Step: 1
Training loss: 0.06743596494197845
Validation loss: 1.410344119994871

Epoch: 6| Step: 2
Training loss: 0.11839411407709122
Validation loss: 1.4150427464515931

Epoch: 6| Step: 3
Training loss: 0.06213553994894028
Validation loss: 1.3854012226545682

Epoch: 6| Step: 4
Training loss: 0.07374811917543411
Validation loss: 1.402017258828686

Epoch: 6| Step: 5
Training loss: 0.06141034513711929
Validation loss: 1.388207729144763

Epoch: 6| Step: 6
Training loss: 0.061288926750421524
Validation loss: 1.4023292500485656

Epoch: 6| Step: 7
Training loss: 0.049010396003723145
Validation loss: 1.4044376925755573

Epoch: 6| Step: 8
Training loss: 0.05727393925189972
Validation loss: 1.3837596729237547

Epoch: 6| Step: 9
Training loss: 0.0644465982913971
Validation loss: 1.3869130496055848

Epoch: 6| Step: 10
Training loss: 0.08486592024564743
Validation loss: 1.4027140499443136

Epoch: 6| Step: 11
Training loss: 0.06678581237792969
Validation loss: 1.3865181502475534

Epoch: 6| Step: 12
Training loss: 0.07296695560216904
Validation loss: 1.3966651039738809

Epoch: 6| Step: 13
Training loss: 0.023940030485391617
Validation loss: 1.3983502388000488

Epoch: 545| Step: 0
Training loss: 0.06580527126789093
Validation loss: 1.4074138486257164

Epoch: 6| Step: 1
Training loss: 0.07862141728401184
Validation loss: 1.4085088237639396

Epoch: 6| Step: 2
Training loss: 0.037512436509132385
Validation loss: 1.41157111173035

Epoch: 6| Step: 3
Training loss: 0.05703739449381828
Validation loss: 1.3919583687218287

Epoch: 6| Step: 4
Training loss: 0.05125533044338226
Validation loss: 1.3756342639205277

Epoch: 6| Step: 5
Training loss: 0.05590206757187843
Validation loss: 1.3874877550268685

Epoch: 6| Step: 6
Training loss: 0.048329487442970276
Validation loss: 1.37828048839364

Epoch: 6| Step: 7
Training loss: 0.04792911186814308
Validation loss: 1.3736279010772705

Epoch: 6| Step: 8
Training loss: 0.08465215563774109
Validation loss: 1.3993477039439703

Epoch: 6| Step: 9
Training loss: 0.06251987814903259
Validation loss: 1.384826100000771

Epoch: 6| Step: 10
Training loss: 0.08954191207885742
Validation loss: 1.3977553690633466

Epoch: 6| Step: 11
Training loss: 0.07549436390399933
Validation loss: 1.3830306594089796

Epoch: 6| Step: 12
Training loss: 0.036759063601493835
Validation loss: 1.387485570805047

Epoch: 6| Step: 13
Training loss: 0.06933917850255966
Validation loss: 1.4099211744082871

Epoch: 546| Step: 0
Training loss: 0.045042626559734344
Validation loss: 1.4099007421924221

Epoch: 6| Step: 1
Training loss: 0.06344787031412125
Validation loss: 1.4083624084790547

Epoch: 6| Step: 2
Training loss: 0.05610354244709015
Validation loss: 1.3983466727759248

Epoch: 6| Step: 3
Training loss: 0.07017435133457184
Validation loss: 1.4155764477227324

Epoch: 6| Step: 4
Training loss: 0.022816181182861328
Validation loss: 1.4176684758996452

Epoch: 6| Step: 5
Training loss: 0.03987404704093933
Validation loss: 1.4102454685395764

Epoch: 6| Step: 6
Training loss: 0.05463124066591263
Validation loss: 1.3925442400799002

Epoch: 6| Step: 7
Training loss: 0.0758194774389267
Validation loss: 1.3956518903855355

Epoch: 6| Step: 8
Training loss: 0.06970415264368057
Validation loss: 1.38467449526633

Epoch: 6| Step: 9
Training loss: 0.10379405319690704
Validation loss: 1.363572464194349

Epoch: 6| Step: 10
Training loss: 0.1190958321094513
Validation loss: 1.3827009277959024

Epoch: 6| Step: 11
Training loss: 0.12046518921852112
Validation loss: 1.3956626346034389

Epoch: 6| Step: 12
Training loss: 0.057713136076927185
Validation loss: 1.3859765080995456

Epoch: 6| Step: 13
Training loss: 0.05004687234759331
Validation loss: 1.3976797185918337

Epoch: 547| Step: 0
Training loss: 0.05367353558540344
Validation loss: 1.3947123596745152

Epoch: 6| Step: 1
Training loss: 0.058228425681591034
Validation loss: 1.4024922847747803

Epoch: 6| Step: 2
Training loss: 0.06507866084575653
Validation loss: 1.3925092527943272

Epoch: 6| Step: 3
Training loss: 0.01864987425506115
Validation loss: 1.3899466196695964

Epoch: 6| Step: 4
Training loss: 0.097610704600811
Validation loss: 1.410174867158295

Epoch: 6| Step: 5
Training loss: 0.046375613659620285
Validation loss: 1.4070720198333904

Epoch: 6| Step: 6
Training loss: 0.06433513760566711
Validation loss: 1.424166751164262

Epoch: 6| Step: 7
Training loss: 0.0744287446141243
Validation loss: 1.400505215890946

Epoch: 6| Step: 8
Training loss: 0.04794574901461601
Validation loss: 1.4124199292993034

Epoch: 6| Step: 9
Training loss: 0.05176340788602829
Validation loss: 1.4003471770594198

Epoch: 6| Step: 10
Training loss: 0.06042960286140442
Validation loss: 1.4028948923592925

Epoch: 6| Step: 11
Training loss: 0.05802121013402939
Validation loss: 1.396704925003872

Epoch: 6| Step: 12
Training loss: 0.036378901451826096
Validation loss: 1.3727419671191965

Epoch: 6| Step: 13
Training loss: 0.07896964997053146
Validation loss: 1.3826780191031836

Epoch: 548| Step: 0
Training loss: 0.07322520017623901
Validation loss: 1.370259513137161

Epoch: 6| Step: 1
Training loss: 0.07430898398160934
Validation loss: 1.3868680974488616

Epoch: 6| Step: 2
Training loss: 0.07915584743022919
Validation loss: 1.3855130967273508

Epoch: 6| Step: 3
Training loss: 0.07203373312950134
Validation loss: 1.3932476457088225

Epoch: 6| Step: 4
Training loss: 0.06686125695705414
Validation loss: 1.403592748026694

Epoch: 6| Step: 5
Training loss: 0.0972789078950882
Validation loss: 1.422923384174224

Epoch: 6| Step: 6
Training loss: 0.06659720093011856
Validation loss: 1.4127427621554303

Epoch: 6| Step: 7
Training loss: 0.08479034900665283
Validation loss: 1.4188070156240975

Epoch: 6| Step: 8
Training loss: 0.11053205281496048
Validation loss: 1.4054267009099324

Epoch: 6| Step: 9
Training loss: 0.03380770608782768
Validation loss: 1.396077194521504

Epoch: 6| Step: 10
Training loss: 0.06752397119998932
Validation loss: 1.4003128729840761

Epoch: 6| Step: 11
Training loss: 0.048028334975242615
Validation loss: 1.3915404632527342

Epoch: 6| Step: 12
Training loss: 0.059690408408641815
Validation loss: 1.36651518524334

Epoch: 6| Step: 13
Training loss: 0.06644662469625473
Validation loss: 1.3892080873571417

Epoch: 549| Step: 0
Training loss: 0.030936378985643387
Validation loss: 1.3908245858325754

Epoch: 6| Step: 1
Training loss: 0.06216764450073242
Validation loss: 1.3753720098926174

Epoch: 6| Step: 2
Training loss: 0.08253657817840576
Validation loss: 1.366555594628857

Epoch: 6| Step: 3
Training loss: 0.03857101500034332
Validation loss: 1.3638810598722069

Epoch: 6| Step: 4
Training loss: 0.08474726229906082
Validation loss: 1.377552915644902

Epoch: 6| Step: 5
Training loss: 0.09748025983572006
Validation loss: 1.3814486098545853

Epoch: 6| Step: 6
Training loss: 0.04234486445784569
Validation loss: 1.3735192642417005

Epoch: 6| Step: 7
Training loss: 0.09750081598758698
Validation loss: 1.374842042564064

Epoch: 6| Step: 8
Training loss: 0.05700230970978737
Validation loss: 1.3684168861758323

Epoch: 6| Step: 9
Training loss: 0.07478298246860504
Validation loss: 1.3552931354891868

Epoch: 6| Step: 10
Training loss: 0.0755796954035759
Validation loss: 1.3418433691865654

Epoch: 6| Step: 11
Training loss: 0.07997031509876251
Validation loss: 1.3408333306671472

Epoch: 6| Step: 12
Training loss: 0.06774462759494781
Validation loss: 1.3557217339033723

Epoch: 6| Step: 13
Training loss: 0.0546250194311142
Validation loss: 1.345565954844157

Epoch: 550| Step: 0
Training loss: 0.042571064084768295
Validation loss: 1.3380748866706766

Epoch: 6| Step: 1
Training loss: 0.06779330968856812
Validation loss: 1.3483015798753308

Epoch: 6| Step: 2
Training loss: 0.0945046991109848
Validation loss: 1.3641304572423298

Epoch: 6| Step: 3
Training loss: 0.0984792411327362
Validation loss: 1.3592154159340808

Epoch: 6| Step: 4
Training loss: 0.06685304641723633
Validation loss: 1.362758550592648

Epoch: 6| Step: 5
Training loss: 0.04455915093421936
Validation loss: 1.3797572242316378

Epoch: 6| Step: 6
Training loss: 0.04018554091453552
Validation loss: 1.3907899587385115

Epoch: 6| Step: 7
Training loss: 0.061257995665073395
Validation loss: 1.3845609298316381

Epoch: 6| Step: 8
Training loss: 0.05743033066391945
Validation loss: 1.3963305155436199

Epoch: 6| Step: 9
Training loss: 0.04006872698664665
Validation loss: 1.3820347709040488

Epoch: 6| Step: 10
Training loss: 0.0572897344827652
Validation loss: 1.401742172497575

Epoch: 6| Step: 11
Training loss: 0.045721955597400665
Validation loss: 1.3958622326133072

Epoch: 6| Step: 12
Training loss: 0.060184672474861145
Validation loss: 1.3927732251023734

Epoch: 6| Step: 13
Training loss: 0.08877599239349365
Validation loss: 1.3972090880076091

Epoch: 551| Step: 0
Training loss: 0.10085040330886841
Validation loss: 1.394103934687953

Epoch: 6| Step: 1
Training loss: 0.08119696378707886
Validation loss: 1.3885708637135004

Epoch: 6| Step: 2
Training loss: 0.048703089356422424
Validation loss: 1.3998912278042044

Epoch: 6| Step: 3
Training loss: 0.06739793717861176
Validation loss: 1.3961015978167135

Epoch: 6| Step: 4
Training loss: 0.056191205978393555
Validation loss: 1.3930795545219092

Epoch: 6| Step: 5
Training loss: 0.05929689481854439
Validation loss: 1.3906717941325197

Epoch: 6| Step: 6
Training loss: 0.06060940399765968
Validation loss: 1.388150336921856

Epoch: 6| Step: 7
Training loss: 0.08429639041423798
Validation loss: 1.3760086592807566

Epoch: 6| Step: 8
Training loss: 0.07243295013904572
Validation loss: 1.3993023454502065

Epoch: 6| Step: 9
Training loss: 0.06962908059358597
Validation loss: 1.391559450857101

Epoch: 6| Step: 10
Training loss: 0.07122060656547546
Validation loss: 1.3694916540576565

Epoch: 6| Step: 11
Training loss: 0.05777031183242798
Validation loss: 1.3779442489788096

Epoch: 6| Step: 12
Training loss: 0.050353486090898514
Validation loss: 1.3777977869074831

Epoch: 6| Step: 13
Training loss: 0.0655917078256607
Validation loss: 1.3861272181234052

Epoch: 552| Step: 0
Training loss: 0.05627358704805374
Validation loss: 1.391376204388116

Epoch: 6| Step: 1
Training loss: 0.08669339865446091
Validation loss: 1.3813747090678061

Epoch: 6| Step: 2
Training loss: 0.04694832116365433
Validation loss: 1.3888625547450075

Epoch: 6| Step: 3
Training loss: 0.04163990542292595
Validation loss: 1.4093809768717775

Epoch: 6| Step: 4
Training loss: 0.07800865918397903
Validation loss: 1.421151041343648

Epoch: 6| Step: 5
Training loss: 0.06503769755363464
Validation loss: 1.4254867863911453

Epoch: 6| Step: 6
Training loss: 0.051054906100034714
Validation loss: 1.4224003027844172

Epoch: 6| Step: 7
Training loss: 0.09454087913036346
Validation loss: 1.4383921264320292

Epoch: 6| Step: 8
Training loss: 0.05387458950281143
Validation loss: 1.4218159946062232

Epoch: 6| Step: 9
Training loss: 0.042293909937143326
Validation loss: 1.4249535965663132

Epoch: 6| Step: 10
Training loss: 0.0540756918489933
Validation loss: 1.4263373908176218

Epoch: 6| Step: 11
Training loss: 0.06278832256793976
Validation loss: 1.4021702197290236

Epoch: 6| Step: 12
Training loss: 0.06471177935600281
Validation loss: 1.4032609770374913

Epoch: 6| Step: 13
Training loss: 0.06760141253471375
Validation loss: 1.3915786050981092

Epoch: 553| Step: 0
Training loss: 0.08076032251119614
Validation loss: 1.3981657399926135

Epoch: 6| Step: 1
Training loss: 0.05325976014137268
Validation loss: 1.4064660610691193

Epoch: 6| Step: 2
Training loss: 0.056645940989255905
Validation loss: 1.3994094953742078

Epoch: 6| Step: 3
Training loss: 0.04307970404624939
Validation loss: 1.3894394629745073

Epoch: 6| Step: 4
Training loss: 0.06536506861448288
Validation loss: 1.3828336449079617

Epoch: 6| Step: 5
Training loss: 0.052114129066467285
Validation loss: 1.3756609411649807

Epoch: 6| Step: 6
Training loss: 0.06523674726486206
Validation loss: 1.39990609563807

Epoch: 6| Step: 7
Training loss: 0.05944139510393143
Validation loss: 1.3860914047046373

Epoch: 6| Step: 8
Training loss: 0.06444885581731796
Validation loss: 1.3925418494850077

Epoch: 6| Step: 9
Training loss: 0.060125529766082764
Validation loss: 1.3804808912738677

Epoch: 6| Step: 10
Training loss: 0.049744583666324615
Validation loss: 1.3797330997323478

Epoch: 6| Step: 11
Training loss: 0.05040638893842697
Validation loss: 1.3869961448895034

Epoch: 6| Step: 12
Training loss: 0.033526599407196045
Validation loss: 1.3831292730505749

Epoch: 6| Step: 13
Training loss: 0.08762192726135254
Validation loss: 1.3744755444988128

Epoch: 554| Step: 0
Training loss: 0.06167701631784439
Validation loss: 1.3828400770823162

Epoch: 6| Step: 1
Training loss: 0.0425402894616127
Validation loss: 1.401427968855827

Epoch: 6| Step: 2
Training loss: 0.053027138113975525
Validation loss: 1.4074798707039125

Epoch: 6| Step: 3
Training loss: 0.05765635892748833
Validation loss: 1.3928869167963664

Epoch: 6| Step: 4
Training loss: 0.04932725429534912
Validation loss: 1.3931563605544388

Epoch: 6| Step: 5
Training loss: 0.06065460667014122
Validation loss: 1.3919917524501841

Epoch: 6| Step: 6
Training loss: 0.04847998544573784
Validation loss: 1.3961608704700266

Epoch: 6| Step: 7
Training loss: 0.06398212164640427
Validation loss: 1.3902212291635492

Epoch: 6| Step: 8
Training loss: 0.06220795959234238
Validation loss: 1.378834137352564

Epoch: 6| Step: 9
Training loss: 0.09938496351242065
Validation loss: 1.3814194510059972

Epoch: 6| Step: 10
Training loss: 0.06556994467973709
Validation loss: 1.3859646756161925

Epoch: 6| Step: 11
Training loss: 0.0815952718257904
Validation loss: 1.40416221913471

Epoch: 6| Step: 12
Training loss: 0.09444727003574371
Validation loss: 1.407818148213048

Epoch: 6| Step: 13
Training loss: 0.05257890000939369
Validation loss: 1.3919908667123446

Epoch: 555| Step: 0
Training loss: 0.09561904519796371
Validation loss: 1.4253849393577986

Epoch: 6| Step: 1
Training loss: 0.05221731960773468
Validation loss: 1.4319042108392204

Epoch: 6| Step: 2
Training loss: 0.05545669049024582
Validation loss: 1.4054037973444948

Epoch: 6| Step: 3
Training loss: 0.054185427725315094
Validation loss: 1.4231123693527714

Epoch: 6| Step: 4
Training loss: 0.08356243371963501
Validation loss: 1.436714001881179

Epoch: 6| Step: 5
Training loss: 0.06810984760522842
Validation loss: 1.4129431363075011

Epoch: 6| Step: 6
Training loss: 0.05772422254085541
Validation loss: 1.3899470529248636

Epoch: 6| Step: 7
Training loss: 0.0566428005695343
Validation loss: 1.4167481532660864

Epoch: 6| Step: 8
Training loss: 0.06603620946407318
Validation loss: 1.4052004775693339

Epoch: 6| Step: 9
Training loss: 0.04925108328461647
Validation loss: 1.3879440138416905

Epoch: 6| Step: 10
Training loss: 0.04271135851740837
Validation loss: 1.3757713456307687

Epoch: 6| Step: 11
Training loss: 0.06725245714187622
Validation loss: 1.3869708475246225

Epoch: 6| Step: 12
Training loss: 0.06085198372602463
Validation loss: 1.3664260384857014

Epoch: 6| Step: 13
Training loss: 0.05932481959462166
Validation loss: 1.3544553595204507

Epoch: 556| Step: 0
Training loss: 0.03899023309350014
Validation loss: 1.3854013649366235

Epoch: 6| Step: 1
Training loss: 0.06914731860160828
Validation loss: 1.3728917901233961

Epoch: 6| Step: 2
Training loss: 0.04185986518859863
Validation loss: 1.3730893288889239

Epoch: 6| Step: 3
Training loss: 0.08589325845241547
Validation loss: 1.356356393906378

Epoch: 6| Step: 4
Training loss: 0.04774363338947296
Validation loss: 1.381325424358409

Epoch: 6| Step: 5
Training loss: 0.04995068907737732
Validation loss: 1.3796561257813567

Epoch: 6| Step: 6
Training loss: 0.04686161130666733
Validation loss: 1.3958876517511183

Epoch: 6| Step: 7
Training loss: 0.03383813798427582
Validation loss: 1.405835687473256

Epoch: 6| Step: 8
Training loss: 0.06444653123617172
Validation loss: 1.417858717262104

Epoch: 6| Step: 9
Training loss: 0.06697334349155426
Validation loss: 1.4268110605978197

Epoch: 6| Step: 10
Training loss: 0.08436387777328491
Validation loss: 1.4351001375464982

Epoch: 6| Step: 11
Training loss: 0.053114552050828934
Validation loss: 1.4254890821313346

Epoch: 6| Step: 12
Training loss: 0.07449512928724289
Validation loss: 1.4188095472192253

Epoch: 6| Step: 13
Training loss: 0.07257155328989029
Validation loss: 1.4202313750020918

Epoch: 557| Step: 0
Training loss: 0.11054255068302155
Validation loss: 1.3881393555671937

Epoch: 6| Step: 1
Training loss: 0.07508186995983124
Validation loss: 1.4064382994046776

Epoch: 6| Step: 2
Training loss: 0.05260409414768219
Validation loss: 1.4029612669380762

Epoch: 6| Step: 3
Training loss: 0.04143746942281723
Validation loss: 1.3866370519002278

Epoch: 6| Step: 4
Training loss: 0.08043385297060013
Validation loss: 1.3857341607411702

Epoch: 6| Step: 5
Training loss: 0.05994895100593567
Validation loss: 1.3889011875275643

Epoch: 6| Step: 6
Training loss: 0.05812131240963936
Validation loss: 1.3606203121523703

Epoch: 6| Step: 7
Training loss: 0.13350576162338257
Validation loss: 1.3865000958083777

Epoch: 6| Step: 8
Training loss: 0.08002927899360657
Validation loss: 1.3567885128400659

Epoch: 6| Step: 9
Training loss: 0.09638364613056183
Validation loss: 1.3786866549522645

Epoch: 6| Step: 10
Training loss: 0.044725801795721054
Validation loss: 1.3814613357667

Epoch: 6| Step: 11
Training loss: 0.04731083661317825
Validation loss: 1.3770431139135872

Epoch: 6| Step: 12
Training loss: 0.05627419427037239
Validation loss: 1.382141693945854

Epoch: 6| Step: 13
Training loss: 0.06562034040689468
Validation loss: 1.395584697364479

Epoch: 558| Step: 0
Training loss: 0.0747687816619873
Validation loss: 1.3854341468503397

Epoch: 6| Step: 1
Training loss: 0.06810939311981201
Validation loss: 1.378168902089519

Epoch: 6| Step: 2
Training loss: 0.10079384595155716
Validation loss: 1.3803378664037234

Epoch: 6| Step: 3
Training loss: 0.12461328506469727
Validation loss: 1.3775518030248664

Epoch: 6| Step: 4
Training loss: 0.098477303981781
Validation loss: 1.3861721997619958

Epoch: 6| Step: 5
Training loss: 0.06873369216918945
Validation loss: 1.3955533914668585

Epoch: 6| Step: 6
Training loss: 0.046758852899074554
Validation loss: 1.3886942748100526

Epoch: 6| Step: 7
Training loss: 0.09344582259654999
Validation loss: 1.3866249258800218

Epoch: 6| Step: 8
Training loss: 0.042350225150585175
Validation loss: 1.3881848396793488

Epoch: 6| Step: 9
Training loss: 0.06018257886171341
Validation loss: 1.4026799201965332

Epoch: 6| Step: 10
Training loss: 0.07501675188541412
Validation loss: 1.3827561819425194

Epoch: 6| Step: 11
Training loss: 0.09744569659233093
Validation loss: 1.3818831161786151

Epoch: 6| Step: 12
Training loss: 0.059128545224666595
Validation loss: 1.3713290460648075

Epoch: 6| Step: 13
Training loss: 0.06335140019655228
Validation loss: 1.3494785126819406

Epoch: 559| Step: 0
Training loss: 0.03754698112607002
Validation loss: 1.380284365787301

Epoch: 6| Step: 1
Training loss: 0.08620492368936539
Validation loss: 1.375412606423901

Epoch: 6| Step: 2
Training loss: 0.07611911743879318
Validation loss: 1.3574634111055763

Epoch: 6| Step: 3
Training loss: 0.03840119391679764
Validation loss: 1.3620419591985724

Epoch: 6| Step: 4
Training loss: 0.07469059526920319
Validation loss: 1.3615971258891526

Epoch: 6| Step: 5
Training loss: 0.05997936427593231
Validation loss: 1.3657173161865563

Epoch: 6| Step: 6
Training loss: 0.07585462927818298
Validation loss: 1.3506104817954443

Epoch: 6| Step: 7
Training loss: 0.06778351217508316
Validation loss: 1.3454121274332846

Epoch: 6| Step: 8
Training loss: 0.05772534757852554
Validation loss: 1.3409148980212469

Epoch: 6| Step: 9
Training loss: 0.0850922018289566
Validation loss: 1.3533374506940123

Epoch: 6| Step: 10
Training loss: 0.05545025318861008
Validation loss: 1.3927643459330323

Epoch: 6| Step: 11
Training loss: 0.060918767005205154
Validation loss: 1.3675490925388951

Epoch: 6| Step: 12
Training loss: 0.0572127141058445
Validation loss: 1.3681852356080086

Epoch: 6| Step: 13
Training loss: 0.056360892951488495
Validation loss: 1.3810891925647695

Epoch: 560| Step: 0
Training loss: 0.052439916878938675
Validation loss: 1.3795292864563644

Epoch: 6| Step: 1
Training loss: 0.047250062227249146
Validation loss: 1.4022023652189521

Epoch: 6| Step: 2
Training loss: 0.04586626589298248
Validation loss: 1.3910248728208645

Epoch: 6| Step: 3
Training loss: 0.03651028871536255
Validation loss: 1.3835671345392864

Epoch: 6| Step: 4
Training loss: 0.044305529445409775
Validation loss: 1.386910641065208

Epoch: 6| Step: 5
Training loss: 0.07464831322431564
Validation loss: 1.3793435865832913

Epoch: 6| Step: 6
Training loss: 0.05937384441494942
Validation loss: 1.4141890746290966

Epoch: 6| Step: 7
Training loss: 0.021806839853525162
Validation loss: 1.3893201812621085

Epoch: 6| Step: 8
Training loss: 0.07801634073257446
Validation loss: 1.3997131727075065

Epoch: 6| Step: 9
Training loss: 0.07234074175357819
Validation loss: 1.3971505857283069

Epoch: 6| Step: 10
Training loss: 0.10428136587142944
Validation loss: 1.3854569222337456

Epoch: 6| Step: 11
Training loss: 0.06932533532381058
Validation loss: 1.4068110668531029

Epoch: 6| Step: 12
Training loss: 0.05230580270290375
Validation loss: 1.3914270484319298

Epoch: 6| Step: 13
Training loss: 0.0805990993976593
Validation loss: 1.3980648684245285

Epoch: 561| Step: 0
Training loss: 0.08750510215759277
Validation loss: 1.4004460909674246

Epoch: 6| Step: 1
Training loss: 0.060736872255802155
Validation loss: 1.3851988482218918

Epoch: 6| Step: 2
Training loss: 0.06825393438339233
Validation loss: 1.3829252950606807

Epoch: 6| Step: 3
Training loss: 0.0551702082157135
Validation loss: 1.3809260770838747

Epoch: 6| Step: 4
Training loss: 0.0420817956328392
Validation loss: 1.3629106898461618

Epoch: 6| Step: 5
Training loss: 0.04101971536874771
Validation loss: 1.3625529363591184

Epoch: 6| Step: 6
Training loss: 0.07093018293380737
Validation loss: 1.3650738167506393

Epoch: 6| Step: 7
Training loss: 0.07507237046957016
Validation loss: 1.3633666487150295

Epoch: 6| Step: 8
Training loss: 0.060341011732816696
Validation loss: 1.3873176433706795

Epoch: 6| Step: 9
Training loss: 0.04095391556620598
Validation loss: 1.3922702445778796

Epoch: 6| Step: 10
Training loss: 0.05526590347290039
Validation loss: 1.3806152536023049

Epoch: 6| Step: 11
Training loss: 0.08207414299249649
Validation loss: 1.3830001687490812

Epoch: 6| Step: 12
Training loss: 0.05812995135784149
Validation loss: 1.3894749226108674

Epoch: 6| Step: 13
Training loss: 0.08553539961576462
Validation loss: 1.3850327204632502

Epoch: 562| Step: 0
Training loss: 0.07247605919837952
Validation loss: 1.3675299241978636

Epoch: 6| Step: 1
Training loss: 0.04024223983287811
Validation loss: 1.3894895609988962

Epoch: 6| Step: 2
Training loss: 0.032556623220443726
Validation loss: 1.4004329494250718

Epoch: 6| Step: 3
Training loss: 0.05113934725522995
Validation loss: 1.382414717828074

Epoch: 6| Step: 4
Training loss: 0.06117100641131401
Validation loss: 1.3865796404500161

Epoch: 6| Step: 5
Training loss: 0.037710946053266525
Validation loss: 1.400688152159414

Epoch: 6| Step: 6
Training loss: 0.055053845047950745
Validation loss: 1.3915234643925902

Epoch: 6| Step: 7
Training loss: 0.06237718462944031
Validation loss: 1.388540921672698

Epoch: 6| Step: 8
Training loss: 0.03671827167272568
Validation loss: 1.3915485483343883

Epoch: 6| Step: 9
Training loss: 0.03658537566661835
Validation loss: 1.3962958730677122

Epoch: 6| Step: 10
Training loss: 0.057173952460289
Validation loss: 1.3874040560055805

Epoch: 6| Step: 11
Training loss: 0.04181194305419922
Validation loss: 1.3757508647057317

Epoch: 6| Step: 12
Training loss: 0.06261579692363739
Validation loss: 1.3912018550339567

Epoch: 6| Step: 13
Training loss: 0.059920165687799454
Validation loss: 1.3782043546758673

Epoch: 563| Step: 0
Training loss: 0.040666837245225906
Validation loss: 1.3836780081513107

Epoch: 6| Step: 1
Training loss: 0.10172982513904572
Validation loss: 1.3827367059646114

Epoch: 6| Step: 2
Training loss: 0.07240208238363266
Validation loss: 1.3779897138636599

Epoch: 6| Step: 3
Training loss: 0.0436895415186882
Validation loss: 1.3642671133882256

Epoch: 6| Step: 4
Training loss: 0.02959417551755905
Validation loss: 1.3463596387576031

Epoch: 6| Step: 5
Training loss: 0.05765608698129654
Validation loss: 1.3724332009592364

Epoch: 6| Step: 6
Training loss: 0.07759706676006317
Validation loss: 1.373907289197368

Epoch: 6| Step: 7
Training loss: 0.0477571040391922
Validation loss: 1.3792378620434833

Epoch: 6| Step: 8
Training loss: 0.05015476793050766
Validation loss: 1.3858780822446268

Epoch: 6| Step: 9
Training loss: 0.05128775164484978
Validation loss: 1.3859062028187576

Epoch: 6| Step: 10
Training loss: 0.05389691889286041
Validation loss: 1.388963880077485

Epoch: 6| Step: 11
Training loss: 0.056186243891716
Validation loss: 1.3735288138030677

Epoch: 6| Step: 12
Training loss: 0.05152100324630737
Validation loss: 1.3562265685809556

Epoch: 6| Step: 13
Training loss: 0.05336527153849602
Validation loss: 1.3775527079900105

Epoch: 564| Step: 0
Training loss: 0.060888007283210754
Validation loss: 1.3505171242580618

Epoch: 6| Step: 1
Training loss: 0.055004797875881195
Validation loss: 1.3736123769514021

Epoch: 6| Step: 2
Training loss: 0.051788441836833954
Validation loss: 1.3815886487242997

Epoch: 6| Step: 3
Training loss: 0.039019253104925156
Validation loss: 1.3820171484383204

Epoch: 6| Step: 4
Training loss: 0.0452900156378746
Validation loss: 1.3860473222629999

Epoch: 6| Step: 5
Training loss: 0.05600766837596893
Validation loss: 1.3616127365378923

Epoch: 6| Step: 6
Training loss: 0.06383819878101349
Validation loss: 1.3691270492410148

Epoch: 6| Step: 7
Training loss: 0.05145338177680969
Validation loss: 1.3886618793651622

Epoch: 6| Step: 8
Training loss: 0.058372221887111664
Validation loss: 1.3766657806211902

Epoch: 6| Step: 9
Training loss: 0.03470248728990555
Validation loss: 1.3770987724745145

Epoch: 6| Step: 10
Training loss: 0.04268968850374222
Validation loss: 1.345929822614116

Epoch: 6| Step: 11
Training loss: 0.0733499675989151
Validation loss: 1.378830558510237

Epoch: 6| Step: 12
Training loss: 0.08837056159973145
Validation loss: 1.362259917361762

Epoch: 6| Step: 13
Training loss: 0.07175213098526001
Validation loss: 1.3614914660812707

Epoch: 565| Step: 0
Training loss: 0.05500692129135132
Validation loss: 1.3722116203718289

Epoch: 6| Step: 1
Training loss: 0.06259100139141083
Validation loss: 1.361229714526925

Epoch: 6| Step: 2
Training loss: 0.0670170858502388
Validation loss: 1.3698112913357314

Epoch: 6| Step: 3
Training loss: 0.08272166550159454
Validation loss: 1.3491129259909354

Epoch: 6| Step: 4
Training loss: 0.06280319392681122
Validation loss: 1.3590701177556028

Epoch: 6| Step: 5
Training loss: 0.04705878719687462
Validation loss: 1.3429040652449413

Epoch: 6| Step: 6
Training loss: 0.06564605236053467
Validation loss: 1.349892516289988

Epoch: 6| Step: 7
Training loss: 0.06118975579738617
Validation loss: 1.3600480941034132

Epoch: 6| Step: 8
Training loss: 0.08894264698028564
Validation loss: 1.3495324042535597

Epoch: 6| Step: 9
Training loss: 0.04633021354675293
Validation loss: 1.3667067276534213

Epoch: 6| Step: 10
Training loss: 0.03934934735298157
Validation loss: 1.3641881135202223

Epoch: 6| Step: 11
Training loss: 0.058114439249038696
Validation loss: 1.3432987864299486

Epoch: 6| Step: 12
Training loss: 0.07158855348825455
Validation loss: 1.3616259572326497

Epoch: 6| Step: 13
Training loss: 0.07274118065834045
Validation loss: 1.3540883493679825

Epoch: 566| Step: 0
Training loss: 0.047405485063791275
Validation loss: 1.3769963601584077

Epoch: 6| Step: 1
Training loss: 0.06849255412817001
Validation loss: 1.3590632023349885

Epoch: 6| Step: 2
Training loss: 0.0492352694272995
Validation loss: 1.3828212368872859

Epoch: 6| Step: 3
Training loss: 0.0690021961927414
Validation loss: 1.384598421794112

Epoch: 6| Step: 4
Training loss: 0.06285509467124939
Validation loss: 1.3730401518524333

Epoch: 6| Step: 5
Training loss: 0.05358099937438965
Validation loss: 1.3987861858901156

Epoch: 6| Step: 6
Training loss: 0.048236746340990067
Validation loss: 1.397785646941072

Epoch: 6| Step: 7
Training loss: 0.044416315853595734
Validation loss: 1.3943515157186857

Epoch: 6| Step: 8
Training loss: 0.06406386941671371
Validation loss: 1.3731296908470891

Epoch: 6| Step: 9
Training loss: 0.046834979206323624
Validation loss: 1.3967422810933923

Epoch: 6| Step: 10
Training loss: 0.025731805711984634
Validation loss: 1.3968775887643137

Epoch: 6| Step: 11
Training loss: 0.07496249675750732
Validation loss: 1.408142666662893

Epoch: 6| Step: 12
Training loss: 0.07779300212860107
Validation loss: 1.4002806217439714

Epoch: 6| Step: 13
Training loss: 0.06564947217702866
Validation loss: 1.3980584067683066

Epoch: 567| Step: 0
Training loss: 0.05512818321585655
Validation loss: 1.392000130427781

Epoch: 6| Step: 1
Training loss: 0.03589572012424469
Validation loss: 1.3731925013244792

Epoch: 6| Step: 2
Training loss: 0.0570637583732605
Validation loss: 1.37715172126729

Epoch: 6| Step: 3
Training loss: 0.04130049794912338
Validation loss: 1.3787394838948404

Epoch: 6| Step: 4
Training loss: 0.07071341574192047
Validation loss: 1.353134685947049

Epoch: 6| Step: 5
Training loss: 0.05249473825097084
Validation loss: 1.367116710191132

Epoch: 6| Step: 6
Training loss: 0.05843034386634827
Validation loss: 1.3723589348536667

Epoch: 6| Step: 7
Training loss: 0.07846643775701523
Validation loss: 1.3727185328801472

Epoch: 6| Step: 8
Training loss: 0.04095982015132904
Validation loss: 1.3874595190889092

Epoch: 6| Step: 9
Training loss: 0.037216104567050934
Validation loss: 1.421616159459596

Epoch: 6| Step: 10
Training loss: 0.07224162667989731
Validation loss: 1.4153970992693337

Epoch: 6| Step: 11
Training loss: 0.06273835897445679
Validation loss: 1.418736114296862

Epoch: 6| Step: 12
Training loss: 0.04552631825208664
Validation loss: 1.430485576711675

Epoch: 6| Step: 13
Training loss: 0.03597481921315193
Validation loss: 1.4204688623387327

Epoch: 568| Step: 0
Training loss: 0.043066516518592834
Validation loss: 1.4496920929160169

Epoch: 6| Step: 1
Training loss: 0.0678396224975586
Validation loss: 1.4464510845881637

Epoch: 6| Step: 2
Training loss: 0.05986228212714195
Validation loss: 1.4326501802731586

Epoch: 6| Step: 3
Training loss: 0.06295634806156158
Validation loss: 1.4296771005917621

Epoch: 6| Step: 4
Training loss: 0.057026274502277374
Validation loss: 1.4457232772663076

Epoch: 6| Step: 5
Training loss: 0.06297250837087631
Validation loss: 1.4210689272931827

Epoch: 6| Step: 6
Training loss: 0.06824246048927307
Validation loss: 1.4276527832913142

Epoch: 6| Step: 7
Training loss: 0.06272007524967194
Validation loss: 1.4269723706347968

Epoch: 6| Step: 8
Training loss: 0.044712215662002563
Validation loss: 1.4065897977480324

Epoch: 6| Step: 9
Training loss: 0.05751952528953552
Validation loss: 1.4093198699335898

Epoch: 6| Step: 10
Training loss: 0.0386284664273262
Validation loss: 1.3992352921475646

Epoch: 6| Step: 11
Training loss: 0.06417667120695114
Validation loss: 1.399147960447496

Epoch: 6| Step: 12
Training loss: 0.07955235242843628
Validation loss: 1.4010551642346125

Epoch: 6| Step: 13
Training loss: 0.04127999767661095
Validation loss: 1.4003710823674356

Epoch: 569| Step: 0
Training loss: 0.04285600036382675
Validation loss: 1.373015795984576

Epoch: 6| Step: 1
Training loss: 0.0655287355184555
Validation loss: 1.3805376406638854

Epoch: 6| Step: 2
Training loss: 0.0733301043510437
Validation loss: 1.3754235595785163

Epoch: 6| Step: 3
Training loss: 0.07542753219604492
Validation loss: 1.3600409537233331

Epoch: 6| Step: 4
Training loss: 0.049748532474040985
Validation loss: 1.362109730320592

Epoch: 6| Step: 5
Training loss: 0.05810200050473213
Validation loss: 1.3597977571589972

Epoch: 6| Step: 6
Training loss: 0.06470460444688797
Validation loss: 1.3613632789222143

Epoch: 6| Step: 7
Training loss: 0.0530838817358017
Validation loss: 1.3555638790130615

Epoch: 6| Step: 8
Training loss: 0.05974345654249191
Validation loss: 1.3780798078865133

Epoch: 6| Step: 9
Training loss: 0.04792030155658722
Validation loss: 1.3570244760923489

Epoch: 6| Step: 10
Training loss: 0.0982954353094101
Validation loss: 1.3567170552028123

Epoch: 6| Step: 11
Training loss: 0.06648889183998108
Validation loss: 1.3761867233501968

Epoch: 6| Step: 12
Training loss: 0.0667690560221672
Validation loss: 1.3827150630694565

Epoch: 6| Step: 13
Training loss: 0.0253597404807806
Validation loss: 1.3727136478629163

Epoch: 570| Step: 0
Training loss: 0.06555328518152237
Validation loss: 1.3923075122217978

Epoch: 6| Step: 1
Training loss: 0.05227319896221161
Validation loss: 1.3880930043035937

Epoch: 6| Step: 2
Training loss: 0.054321400821208954
Validation loss: 1.3675182743739056

Epoch: 6| Step: 3
Training loss: 0.06647181510925293
Validation loss: 1.3885180334891043

Epoch: 6| Step: 4
Training loss: 0.05757954344153404
Validation loss: 1.3875025395424134

Epoch: 6| Step: 5
Training loss: 0.05194432660937309
Validation loss: 1.393203350805467

Epoch: 6| Step: 6
Training loss: 0.049468252807855606
Validation loss: 1.4132977416438441

Epoch: 6| Step: 7
Training loss: 0.07057610154151917
Validation loss: 1.4263002846830635

Epoch: 6| Step: 8
Training loss: 0.05436963215470314
Validation loss: 1.409867436655106

Epoch: 6| Step: 9
Training loss: 0.0427192822098732
Validation loss: 1.4035856005966023

Epoch: 6| Step: 10
Training loss: 0.07066656649112701
Validation loss: 1.4193723765752648

Epoch: 6| Step: 11
Training loss: 0.03539508581161499
Validation loss: 1.3913126927550121

Epoch: 6| Step: 12
Training loss: 0.06060425192117691
Validation loss: 1.387412881338468

Epoch: 6| Step: 13
Training loss: 0.036495961248874664
Validation loss: 1.3865670465653943

Epoch: 571| Step: 0
Training loss: 0.05947581306099892
Validation loss: 1.3654306588634368

Epoch: 6| Step: 1
Training loss: 0.03321400284767151
Validation loss: 1.3820907659428094

Epoch: 6| Step: 2
Training loss: 0.039514146745204926
Validation loss: 1.3681421510634884

Epoch: 6| Step: 3
Training loss: 0.051270708441734314
Validation loss: 1.3700283233837416

Epoch: 6| Step: 4
Training loss: 0.0578131303191185
Validation loss: 1.37801226492851

Epoch: 6| Step: 5
Training loss: 0.045725543051958084
Validation loss: 1.3768567737712656

Epoch: 6| Step: 6
Training loss: 0.0719321221113205
Validation loss: 1.357692632623898

Epoch: 6| Step: 7
Training loss: 0.03716963902115822
Validation loss: 1.3667989905162523

Epoch: 6| Step: 8
Training loss: 0.05661529302597046
Validation loss: 1.373401818736907

Epoch: 6| Step: 9
Training loss: 0.09284251928329468
Validation loss: 1.3786116050135704

Epoch: 6| Step: 10
Training loss: 0.06398676335811615
Validation loss: 1.3919887709361252

Epoch: 6| Step: 11
Training loss: 0.06121218204498291
Validation loss: 1.3969043993180799

Epoch: 6| Step: 12
Training loss: 0.06707092374563217
Validation loss: 1.4059598644574482

Epoch: 6| Step: 13
Training loss: 0.06261789798736572
Validation loss: 1.4145451027859923

Epoch: 572| Step: 0
Training loss: 0.07544813305139542
Validation loss: 1.3992465901118454

Epoch: 6| Step: 1
Training loss: 0.07549457252025604
Validation loss: 1.382762901244625

Epoch: 6| Step: 2
Training loss: 0.06985221803188324
Validation loss: 1.3809038836468932

Epoch: 6| Step: 3
Training loss: 0.051800087094306946
Validation loss: 1.3843313609400103

Epoch: 6| Step: 4
Training loss: 0.05858302116394043
Validation loss: 1.3920231480752268

Epoch: 6| Step: 5
Training loss: 0.048507802188396454
Validation loss: 1.3937552475160169

Epoch: 6| Step: 6
Training loss: 0.04048746079206467
Validation loss: 1.38985659486504

Epoch: 6| Step: 7
Training loss: 0.055842235684394836
Validation loss: 1.394165390281267

Epoch: 6| Step: 8
Training loss: 0.05368397384881973
Validation loss: 1.4123072239660448

Epoch: 6| Step: 9
Training loss: 0.05737053230404854
Validation loss: 1.3790563947410994

Epoch: 6| Step: 10
Training loss: 0.061310045421123505
Validation loss: 1.3907374951147264

Epoch: 6| Step: 11
Training loss: 0.04180968552827835
Validation loss: 1.3866976653375933

Epoch: 6| Step: 12
Training loss: 0.10540100187063217
Validation loss: 1.4088142687274563

Epoch: 6| Step: 13
Training loss: 0.06867054849863052
Validation loss: 1.3871812384615663

Epoch: 573| Step: 0
Training loss: 0.058476630598306656
Validation loss: 1.3727136517083773

Epoch: 6| Step: 1
Training loss: 0.061039362102746964
Validation loss: 1.3702525682346796

Epoch: 6| Step: 2
Training loss: 0.06736230850219727
Validation loss: 1.365313103122096

Epoch: 6| Step: 3
Training loss: 0.06844963133335114
Validation loss: 1.3666056138212963

Epoch: 6| Step: 4
Training loss: 0.044353339821100235
Validation loss: 1.391074872785999

Epoch: 6| Step: 5
Training loss: 0.04510022699832916
Validation loss: 1.368372348047072

Epoch: 6| Step: 6
Training loss: 0.061491698026657104
Validation loss: 1.3913187493560135

Epoch: 6| Step: 7
Training loss: 0.07280855625867844
Validation loss: 1.3906868568030737

Epoch: 6| Step: 8
Training loss: 0.051822155714035034
Validation loss: 1.3943328421602967

Epoch: 6| Step: 9
Training loss: 0.05266213044524193
Validation loss: 1.3754174081228112

Epoch: 6| Step: 10
Training loss: 0.053311243653297424
Validation loss: 1.391692553797076

Epoch: 6| Step: 11
Training loss: 0.07780970633029938
Validation loss: 1.413186574494967

Epoch: 6| Step: 12
Training loss: 0.06086251512169838
Validation loss: 1.4137153112760155

Epoch: 6| Step: 13
Training loss: 0.03486945480108261
Validation loss: 1.4180148301586029

Epoch: 574| Step: 0
Training loss: 0.06813602149486542
Validation loss: 1.420525179114393

Epoch: 6| Step: 1
Training loss: 0.042866118252277374
Validation loss: 1.428780919762068

Epoch: 6| Step: 2
Training loss: 0.0815565437078476
Validation loss: 1.4388086590715634

Epoch: 6| Step: 3
Training loss: 0.06134004145860672
Validation loss: 1.4183593232144591

Epoch: 6| Step: 4
Training loss: 0.057950668036937714
Validation loss: 1.427740321364454

Epoch: 6| Step: 5
Training loss: 0.029112810268998146
Validation loss: 1.430927106129226

Epoch: 6| Step: 6
Training loss: 0.05546039715409279
Validation loss: 1.43641806802442

Epoch: 6| Step: 7
Training loss: 0.05742122605443001
Validation loss: 1.4268628986932899

Epoch: 6| Step: 8
Training loss: 0.06270290166139603
Validation loss: 1.434983168878863

Epoch: 6| Step: 9
Training loss: 0.04801640287041664
Validation loss: 1.4143627125729796

Epoch: 6| Step: 10
Training loss: 0.05408930778503418
Validation loss: 1.4078249380152712

Epoch: 6| Step: 11
Training loss: 0.06857674568891525
Validation loss: 1.4168565363012335

Epoch: 6| Step: 12
Training loss: 0.052547141909599304
Validation loss: 1.3993394913211945

Epoch: 6| Step: 13
Training loss: 0.07293695211410522
Validation loss: 1.3955355985190279

Epoch: 575| Step: 0
Training loss: 0.06885644793510437
Validation loss: 1.389994445667472

Epoch: 6| Step: 1
Training loss: 0.045628271996974945
Validation loss: 1.3935718741468204

Epoch: 6| Step: 2
Training loss: 0.053822554647922516
Validation loss: 1.3960772560488792

Epoch: 6| Step: 3
Training loss: 0.03672486171126366
Validation loss: 1.383130992612531

Epoch: 6| Step: 4
Training loss: 0.059850554913282394
Validation loss: 1.3797943925344816

Epoch: 6| Step: 5
Training loss: 0.05558977276086807
Validation loss: 1.3843331016520017

Epoch: 6| Step: 6
Training loss: 0.05440998077392578
Validation loss: 1.4053880873546805

Epoch: 6| Step: 7
Training loss: 0.06177566945552826
Validation loss: 1.3899721189211773

Epoch: 6| Step: 8
Training loss: 0.0824851542711258
Validation loss: 1.3810159339699695

Epoch: 6| Step: 9
Training loss: 0.048961885273456573
Validation loss: 1.3719816387340587

Epoch: 6| Step: 10
Training loss: 0.06247899681329727
Validation loss: 1.372021367472987

Epoch: 6| Step: 11
Training loss: 0.047639399766922
Validation loss: 1.3719027862753919

Epoch: 6| Step: 12
Training loss: 0.0797722339630127
Validation loss: 1.3561290848639704

Epoch: 6| Step: 13
Training loss: 0.06489380449056625
Validation loss: 1.3608218649382233

Epoch: 576| Step: 0
Training loss: 0.06419429183006287
Validation loss: 1.3609416049013856

Epoch: 6| Step: 1
Training loss: 0.0456186905503273
Validation loss: 1.3568932144872603

Epoch: 6| Step: 2
Training loss: 0.051632873713970184
Validation loss: 1.3516149879783712

Epoch: 6| Step: 3
Training loss: 0.06608940660953522
Validation loss: 1.3693633874257405

Epoch: 6| Step: 4
Training loss: 0.06700121611356735
Validation loss: 1.3625851087672736

Epoch: 6| Step: 5
Training loss: 0.046010442078113556
Validation loss: 1.3672182572785245

Epoch: 6| Step: 6
Training loss: 0.05350235849618912
Validation loss: 1.3968706848800823

Epoch: 6| Step: 7
Training loss: 0.05641303211450577
Validation loss: 1.396206646837214

Epoch: 6| Step: 8
Training loss: 0.04416497424244881
Validation loss: 1.4205370692796604

Epoch: 6| Step: 9
Training loss: 0.044884391129016876
Validation loss: 1.4234528926111036

Epoch: 6| Step: 10
Training loss: 0.07078488916158676
Validation loss: 1.408848713803035

Epoch: 6| Step: 11
Training loss: 0.05576739460229874
Validation loss: 1.3889811602971887

Epoch: 6| Step: 12
Training loss: 0.052877169102430344
Validation loss: 1.420703531593405

Epoch: 6| Step: 13
Training loss: 0.05798298120498657
Validation loss: 1.416292323861071

Epoch: 577| Step: 0
Training loss: 0.05746474117040634
Validation loss: 1.418941984894455

Epoch: 6| Step: 1
Training loss: 0.0797882080078125
Validation loss: 1.426198850395859

Epoch: 6| Step: 2
Training loss: 0.03137742727994919
Validation loss: 1.4237157221763366

Epoch: 6| Step: 3
Training loss: 0.09625837206840515
Validation loss: 1.4150100356789046

Epoch: 6| Step: 4
Training loss: 0.06541571766138077
Validation loss: 1.4105703510263914

Epoch: 6| Step: 5
Training loss: 0.04782926291227341
Validation loss: 1.40075941752362

Epoch: 6| Step: 6
Training loss: 0.05289853364229202
Validation loss: 1.4175486910727717

Epoch: 6| Step: 7
Training loss: 0.05421259254217148
Validation loss: 1.4099743314968642

Epoch: 6| Step: 8
Training loss: 0.06454427540302277
Validation loss: 1.3866280432670348

Epoch: 6| Step: 9
Training loss: 0.03774530068039894
Validation loss: 1.3983783709105624

Epoch: 6| Step: 10
Training loss: 0.08192451298236847
Validation loss: 1.4113952293190906

Epoch: 6| Step: 11
Training loss: 0.056128136813640594
Validation loss: 1.3987901544058194

Epoch: 6| Step: 12
Training loss: 0.07034338265657425
Validation loss: 1.3866315170000958

Epoch: 6| Step: 13
Training loss: 0.07187298685312271
Validation loss: 1.396507320865508

Epoch: 578| Step: 0
Training loss: 0.051676228642463684
Validation loss: 1.4183601320430796

Epoch: 6| Step: 1
Training loss: 0.06210411339998245
Validation loss: 1.3752968119036766

Epoch: 6| Step: 2
Training loss: 0.04068419709801674
Validation loss: 1.383486907969239

Epoch: 6| Step: 3
Training loss: 0.036565352231264114
Validation loss: 1.3763578790490345

Epoch: 6| Step: 4
Training loss: 0.06888598203659058
Validation loss: 1.3521064545518608

Epoch: 6| Step: 5
Training loss: 0.0620909109711647
Validation loss: 1.3491852283477783

Epoch: 6| Step: 6
Training loss: 0.04086941480636597
Validation loss: 1.362773237689849

Epoch: 6| Step: 7
Training loss: 0.047920212149620056
Validation loss: 1.3506559620621383

Epoch: 6| Step: 8
Training loss: 0.04666852578520775
Validation loss: 1.367822321512366

Epoch: 6| Step: 9
Training loss: 0.02545555680990219
Validation loss: 1.3490645641921668

Epoch: 6| Step: 10
Training loss: 0.03842437267303467
Validation loss: 1.3383245846276641

Epoch: 6| Step: 11
Training loss: 0.07353591173887253
Validation loss: 1.360724001802424

Epoch: 6| Step: 12
Training loss: 0.02494853362441063
Validation loss: 1.329422156016032

Epoch: 6| Step: 13
Training loss: 0.02721250057220459
Validation loss: 1.3334230799828806

Epoch: 579| Step: 0
Training loss: 0.0639595240354538
Validation loss: 1.3356344674223213

Epoch: 6| Step: 1
Training loss: 0.0493500679731369
Validation loss: 1.3435452349724308

Epoch: 6| Step: 2
Training loss: 0.07390838861465454
Validation loss: 1.339928762887114

Epoch: 6| Step: 3
Training loss: 0.054925113916397095
Validation loss: 1.3493022893064766

Epoch: 6| Step: 4
Training loss: 0.06002559885382652
Validation loss: 1.339753863632038

Epoch: 6| Step: 5
Training loss: 0.07579535245895386
Validation loss: 1.3710631849945232

Epoch: 6| Step: 6
Training loss: 0.05713930353522301
Validation loss: 1.3873476853934668

Epoch: 6| Step: 7
Training loss: 0.04469077289104462
Validation loss: 1.3643277447710755

Epoch: 6| Step: 8
Training loss: 0.07634356617927551
Validation loss: 1.3821464039946114

Epoch: 6| Step: 9
Training loss: 0.0529036708176136
Validation loss: 1.3852989917160363

Epoch: 6| Step: 10
Training loss: 0.06194663420319557
Validation loss: 1.3689049187526907

Epoch: 6| Step: 11
Training loss: 0.041624780744314194
Validation loss: 1.376230340491059

Epoch: 6| Step: 12
Training loss: 0.061355188488960266
Validation loss: 1.3885625049632082

Epoch: 6| Step: 13
Training loss: 0.059056203812360764
Validation loss: 1.3891995171064973

Epoch: 580| Step: 0
Training loss: 0.0842527374625206
Validation loss: 1.3972628719063216

Epoch: 6| Step: 1
Training loss: 0.05604321509599686
Validation loss: 1.3950743688050138

Epoch: 6| Step: 2
Training loss: 0.042939990758895874
Validation loss: 1.3973536260666386

Epoch: 6| Step: 3
Training loss: 0.04842960461974144
Validation loss: 1.3945141319305665

Epoch: 6| Step: 4
Training loss: 0.0481126569211483
Validation loss: 1.3904845432568622

Epoch: 6| Step: 5
Training loss: 0.042025864124298096
Validation loss: 1.3882038721474268

Epoch: 6| Step: 6
Training loss: 0.09283830970525742
Validation loss: 1.3824617138472937

Epoch: 6| Step: 7
Training loss: 0.0489983968436718
Validation loss: 1.395377879501671

Epoch: 6| Step: 8
Training loss: 0.12012127786874771
Validation loss: 1.3970677942358039

Epoch: 6| Step: 9
Training loss: 0.05489543080329895
Validation loss: 1.3875664895580662

Epoch: 6| Step: 10
Training loss: 0.07353650033473969
Validation loss: 1.4060403249597038

Epoch: 6| Step: 11
Training loss: 0.08051658421754837
Validation loss: 1.4105989574104227

Epoch: 6| Step: 12
Training loss: 0.045346684753894806
Validation loss: 1.3921731761706773

Epoch: 6| Step: 13
Training loss: 0.04103190451860428
Validation loss: 1.4285796432084934

Epoch: 581| Step: 0
Training loss: 0.05623381957411766
Validation loss: 1.400980398219119

Epoch: 6| Step: 1
Training loss: 0.05639062821865082
Validation loss: 1.3994125159837867

Epoch: 6| Step: 2
Training loss: 0.037751443684101105
Validation loss: 1.4006573192534908

Epoch: 6| Step: 3
Training loss: 0.07052027434110641
Validation loss: 1.4075564389587731

Epoch: 6| Step: 4
Training loss: 0.09075534343719482
Validation loss: 1.3956161263168498

Epoch: 6| Step: 5
Training loss: 0.049138426780700684
Validation loss: 1.3909329816859255

Epoch: 6| Step: 6
Training loss: 0.08510780334472656
Validation loss: 1.3931336531075098

Epoch: 6| Step: 7
Training loss: 0.04646701738238335
Validation loss: 1.3645017544428508

Epoch: 6| Step: 8
Training loss: 0.043543338775634766
Validation loss: 1.3745786387433288

Epoch: 6| Step: 9
Training loss: 0.07158422470092773
Validation loss: 1.3511485515102264

Epoch: 6| Step: 10
Training loss: 0.06497199833393097
Validation loss: 1.3608437789383756

Epoch: 6| Step: 11
Training loss: 0.06591136753559113
Validation loss: 1.3563055819080723

Epoch: 6| Step: 12
Training loss: 0.07696396857500076
Validation loss: 1.3514689450622888

Epoch: 6| Step: 13
Training loss: 0.08049261569976807
Validation loss: 1.3541548905834075

Epoch: 582| Step: 0
Training loss: 0.043097615242004395
Validation loss: 1.3761105075959237

Epoch: 6| Step: 1
Training loss: 0.0576588436961174
Validation loss: 1.3815538735799893

Epoch: 6| Step: 2
Training loss: 0.03725030645728111
Validation loss: 1.3659876162006008

Epoch: 6| Step: 3
Training loss: 0.07944121956825256
Validation loss: 1.3864885664755298

Epoch: 6| Step: 4
Training loss: 0.10070854425430298
Validation loss: 1.3671003131456272

Epoch: 6| Step: 5
Training loss: 0.06109265610575676
Validation loss: 1.3718935994691746

Epoch: 6| Step: 6
Training loss: 0.07981115579605103
Validation loss: 1.363614333573208

Epoch: 6| Step: 7
Training loss: 0.05746614933013916
Validation loss: 1.3777490085171116

Epoch: 6| Step: 8
Training loss: 0.05301288142800331
Validation loss: 1.395627522981295

Epoch: 6| Step: 9
Training loss: 0.07600828260183334
Validation loss: 1.3831205932042931

Epoch: 6| Step: 10
Training loss: 0.07564994692802429
Validation loss: 1.387174633882379

Epoch: 6| Step: 11
Training loss: 0.057051882147789
Validation loss: 1.375124394252736

Epoch: 6| Step: 12
Training loss: 0.053164634853601456
Validation loss: 1.402681968545401

Epoch: 6| Step: 13
Training loss: 0.050935208797454834
Validation loss: 1.374848347838207

Epoch: 583| Step: 0
Training loss: 0.05910288542509079
Validation loss: 1.393834565275459

Epoch: 6| Step: 1
Training loss: 0.08421587198972702
Validation loss: 1.4105138958141368

Epoch: 6| Step: 2
Training loss: 0.05368996411561966
Validation loss: 1.401293678950238

Epoch: 6| Step: 3
Training loss: 0.05139882490038872
Validation loss: 1.3984378403232944

Epoch: 6| Step: 4
Training loss: 0.056851424276828766
Validation loss: 1.413086591869272

Epoch: 6| Step: 5
Training loss: 0.04664536565542221
Validation loss: 1.4221578695440804

Epoch: 6| Step: 6
Training loss: 0.061033159494400024
Validation loss: 1.415255194710147

Epoch: 6| Step: 7
Training loss: 0.08117783069610596
Validation loss: 1.40426432060939

Epoch: 6| Step: 8
Training loss: 0.038543205708265305
Validation loss: 1.4075995132487307

Epoch: 6| Step: 9
Training loss: 0.06141863018274307
Validation loss: 1.4070439338684082

Epoch: 6| Step: 10
Training loss: 0.04431401193141937
Validation loss: 1.4090392153750184

Epoch: 6| Step: 11
Training loss: 0.05273929610848427
Validation loss: 1.4017081478590607

Epoch: 6| Step: 12
Training loss: 0.05019224435091019
Validation loss: 1.3993860508805962

Epoch: 6| Step: 13
Training loss: 0.043918874114751816
Validation loss: 1.3924194587174283

Epoch: 584| Step: 0
Training loss: 0.053822360932826996
Validation loss: 1.4097557003780077

Epoch: 6| Step: 1
Training loss: 0.0483115017414093
Validation loss: 1.3931984388700096

Epoch: 6| Step: 2
Training loss: 0.04516391456127167
Validation loss: 1.382465809904119

Epoch: 6| Step: 3
Training loss: 0.025667056441307068
Validation loss: 1.3767807035035984

Epoch: 6| Step: 4
Training loss: 0.046824343502521515
Validation loss: 1.3923433467906008

Epoch: 6| Step: 5
Training loss: 0.035914115607738495
Validation loss: 1.3799768955476823

Epoch: 6| Step: 6
Training loss: 0.041874658316373825
Validation loss: 1.3834526596530792

Epoch: 6| Step: 7
Training loss: 0.06176780164241791
Validation loss: 1.3720368243032885

Epoch: 6| Step: 8
Training loss: 0.07601313292980194
Validation loss: 1.3856920260255055

Epoch: 6| Step: 9
Training loss: 0.05629638954997063
Validation loss: 1.3721186640442058

Epoch: 6| Step: 10
Training loss: 0.05937509983778
Validation loss: 1.3779550957423385

Epoch: 6| Step: 11
Training loss: 0.05772142857313156
Validation loss: 1.3832188267861643

Epoch: 6| Step: 12
Training loss: 0.07327618449926376
Validation loss: 1.3713782743741108

Epoch: 6| Step: 13
Training loss: 0.05695901811122894
Validation loss: 1.3714499371026152

Epoch: 585| Step: 0
Training loss: 0.03889702260494232
Validation loss: 1.3838748252519997

Epoch: 6| Step: 1
Training loss: 0.062097206711769104
Validation loss: 1.3919500009987944

Epoch: 6| Step: 2
Training loss: 0.058780744671821594
Validation loss: 1.4024353193980392

Epoch: 6| Step: 3
Training loss: 0.07745672017335892
Validation loss: 1.4063640191990843

Epoch: 6| Step: 4
Training loss: 0.07573845237493515
Validation loss: 1.4326727544107745

Epoch: 6| Step: 5
Training loss: 0.06869490444660187
Validation loss: 1.4222480622670983

Epoch: 6| Step: 6
Training loss: 0.07682164013385773
Validation loss: 1.4089177013725362

Epoch: 6| Step: 7
Training loss: 0.06331388652324677
Validation loss: 1.3863609657492688

Epoch: 6| Step: 8
Training loss: 0.08697760105133057
Validation loss: 1.3990708192189534

Epoch: 6| Step: 9
Training loss: 0.056016407907009125
Validation loss: 1.370878424695743

Epoch: 6| Step: 10
Training loss: 0.05659405142068863
Validation loss: 1.3535266781366

Epoch: 6| Step: 11
Training loss: 0.10212261974811554
Validation loss: 1.359898123689877

Epoch: 6| Step: 12
Training loss: 0.07095381617546082
Validation loss: 1.3626939468486334

Epoch: 6| Step: 13
Training loss: 0.05627913028001785
Validation loss: 1.3760241962248279

Epoch: 586| Step: 0
Training loss: 0.05599043518304825
Validation loss: 1.3756920150531236

Epoch: 6| Step: 1
Training loss: 0.036215536296367645
Validation loss: 1.365503518812118

Epoch: 6| Step: 2
Training loss: 0.08501462638378143
Validation loss: 1.3545949202711864

Epoch: 6| Step: 3
Training loss: 0.047496311366558075
Validation loss: 1.373191216940521

Epoch: 6| Step: 4
Training loss: 0.04252469539642334
Validation loss: 1.3815625854717788

Epoch: 6| Step: 5
Training loss: 0.06630172580480576
Validation loss: 1.3515014315164218

Epoch: 6| Step: 6
Training loss: 0.06648188829421997
Validation loss: 1.3526146514441377

Epoch: 6| Step: 7
Training loss: 0.06106434762477875
Validation loss: 1.349282246123078

Epoch: 6| Step: 8
Training loss: 0.07481041550636292
Validation loss: 1.3348886787250478

Epoch: 6| Step: 9
Training loss: 0.1042720228433609
Validation loss: 1.3554230127283322

Epoch: 6| Step: 10
Training loss: 0.07760710269212723
Validation loss: 1.3638935204475158

Epoch: 6| Step: 11
Training loss: 0.05820649117231369
Validation loss: 1.3629294095500823

Epoch: 6| Step: 12
Training loss: 0.0787254273891449
Validation loss: 1.3642140088542816

Epoch: 6| Step: 13
Training loss: 0.06488104909658432
Validation loss: 1.3661403963642735

Epoch: 587| Step: 0
Training loss: 0.03814908489584923
Validation loss: 1.3905287250395744

Epoch: 6| Step: 1
Training loss: 0.06380167603492737
Validation loss: 1.3906332754319715

Epoch: 6| Step: 2
Training loss: 0.04935538023710251
Validation loss: 1.40756255836897

Epoch: 6| Step: 3
Training loss: 0.040576010942459106
Validation loss: 1.387849497538741

Epoch: 6| Step: 4
Training loss: 0.0568033829331398
Validation loss: 1.4033590324463383

Epoch: 6| Step: 5
Training loss: 0.08348976075649261
Validation loss: 1.4042298447701238

Epoch: 6| Step: 6
Training loss: 0.0739355981349945
Validation loss: 1.3929656782457907

Epoch: 6| Step: 7
Training loss: 0.04773525148630142
Validation loss: 1.4134034879745976

Epoch: 6| Step: 8
Training loss: 0.052510641515254974
Validation loss: 1.4126080838582848

Epoch: 6| Step: 9
Training loss: 0.07310827821493149
Validation loss: 1.4039310973177674

Epoch: 6| Step: 10
Training loss: 0.06470468640327454
Validation loss: 1.3940523593656478

Epoch: 6| Step: 11
Training loss: 0.15069669485092163
Validation loss: 1.3934501486439859

Epoch: 6| Step: 12
Training loss: 0.11874735355377197
Validation loss: 1.3973720317245812

Epoch: 6| Step: 13
Training loss: 0.09576406329870224
Validation loss: 1.3868231029920681

Epoch: 588| Step: 0
Training loss: 0.06964562088251114
Validation loss: 1.3647123100937053

Epoch: 6| Step: 1
Training loss: 0.05772462487220764
Validation loss: 1.3870679755364694

Epoch: 6| Step: 2
Training loss: 0.05979001894593239
Validation loss: 1.3575564180651019

Epoch: 6| Step: 3
Training loss: 0.06081749498844147
Validation loss: 1.3905053190005723

Epoch: 6| Step: 4
Training loss: 0.057615142315626144
Validation loss: 1.3722076454470236

Epoch: 6| Step: 5
Training loss: 0.10437165200710297
Validation loss: 1.370363926374784

Epoch: 6| Step: 6
Training loss: 0.07310554385185242
Validation loss: 1.3682050589592225

Epoch: 6| Step: 7
Training loss: 0.06549517810344696
Validation loss: 1.3669531935004777

Epoch: 6| Step: 8
Training loss: 0.07066109776496887
Validation loss: 1.3854211556014193

Epoch: 6| Step: 9
Training loss: 0.05925288051366806
Validation loss: 1.403871577273133

Epoch: 6| Step: 10
Training loss: 0.08092696219682693
Validation loss: 1.379803466540511

Epoch: 6| Step: 11
Training loss: 0.07765041291713715
Validation loss: 1.3975021057231451

Epoch: 6| Step: 12
Training loss: 0.06538906693458557
Validation loss: 1.408609248617644

Epoch: 6| Step: 13
Training loss: 0.03295432776212692
Validation loss: 1.400166247480659

Epoch: 589| Step: 0
Training loss: 0.08822944015264511
Validation loss: 1.4007001185929904

Epoch: 6| Step: 1
Training loss: 0.07203806936740875
Validation loss: 1.4066169454205422

Epoch: 6| Step: 2
Training loss: 0.07282266020774841
Validation loss: 1.4029339603198472

Epoch: 6| Step: 3
Training loss: 0.059928469359874725
Validation loss: 1.414095224872712

Epoch: 6| Step: 4
Training loss: 0.04104457050561905
Validation loss: 1.407683232779144

Epoch: 6| Step: 5
Training loss: 0.07747870683670044
Validation loss: 1.4053071237379504

Epoch: 6| Step: 6
Training loss: 0.05747201293706894
Validation loss: 1.415754973247487

Epoch: 6| Step: 7
Training loss: 0.04632623866200447
Validation loss: 1.401603812812477

Epoch: 6| Step: 8
Training loss: 0.06311377137899399
Validation loss: 1.396266286091138

Epoch: 6| Step: 9
Training loss: 0.06609532237052917
Validation loss: 1.3926669817457917

Epoch: 6| Step: 10
Training loss: 0.05908646434545517
Validation loss: 1.377411065563079

Epoch: 6| Step: 11
Training loss: 0.0422760546207428
Validation loss: 1.3745084263945138

Epoch: 6| Step: 12
Training loss: 0.09753425419330597
Validation loss: 1.364166675075408

Epoch: 6| Step: 13
Training loss: 0.06477305293083191
Validation loss: 1.3611556650489889

Epoch: 590| Step: 0
Training loss: 0.10439720749855042
Validation loss: 1.3770299368007208

Epoch: 6| Step: 1
Training loss: 0.10417069494724274
Validation loss: 1.367635057818505

Epoch: 6| Step: 2
Training loss: 0.05195019394159317
Validation loss: 1.3660289061966764

Epoch: 6| Step: 3
Training loss: 0.07881741225719452
Validation loss: 1.3629501750392299

Epoch: 6| Step: 4
Training loss: 0.05118371918797493
Validation loss: 1.372951167245065

Epoch: 6| Step: 5
Training loss: 0.05202413350343704
Validation loss: 1.380764247268759

Epoch: 6| Step: 6
Training loss: 0.04849231243133545
Validation loss: 1.3945729117239676

Epoch: 6| Step: 7
Training loss: 0.04917328804731369
Validation loss: 1.398903703176847

Epoch: 6| Step: 8
Training loss: 0.06933281570672989
Validation loss: 1.414846743306806

Epoch: 6| Step: 9
Training loss: 0.048544541001319885
Validation loss: 1.3987544518645092

Epoch: 6| Step: 10
Training loss: 0.05730326473712921
Validation loss: 1.4118353525797527

Epoch: 6| Step: 11
Training loss: 0.05729381740093231
Validation loss: 1.3968836492107761

Epoch: 6| Step: 12
Training loss: 0.058898989111185074
Validation loss: 1.4288837230333717

Epoch: 6| Step: 13
Training loss: 0.08230426907539368
Validation loss: 1.4146878719329834

Epoch: 591| Step: 0
Training loss: 0.07382672280073166
Validation loss: 1.4268136011656893

Epoch: 6| Step: 1
Training loss: 0.07751832157373428
Validation loss: 1.4261813573939826

Epoch: 6| Step: 2
Training loss: 0.04881707578897476
Validation loss: 1.4136173109854422

Epoch: 6| Step: 3
Training loss: 0.06845290958881378
Validation loss: 1.416616791038103

Epoch: 6| Step: 4
Training loss: 0.0412088967859745
Validation loss: 1.4263974889632194

Epoch: 6| Step: 5
Training loss: 0.06072380021214485
Validation loss: 1.410121085182313

Epoch: 6| Step: 6
Training loss: 0.047242578119039536
Validation loss: 1.4202852505509571

Epoch: 6| Step: 7
Training loss: 0.06225059553980827
Validation loss: 1.4162880938540223

Epoch: 6| Step: 8
Training loss: 0.0665745884180069
Validation loss: 1.3958498060062368

Epoch: 6| Step: 9
Training loss: 0.05434195697307587
Validation loss: 1.4010957338476693

Epoch: 6| Step: 10
Training loss: 0.0647696927189827
Validation loss: 1.4045368519521528

Epoch: 6| Step: 11
Training loss: 0.04154960811138153
Validation loss: 1.3976125870981524

Epoch: 6| Step: 12
Training loss: 0.04360887408256531
Validation loss: 1.3729817598096785

Epoch: 6| Step: 13
Training loss: 0.06094890832901001
Validation loss: 1.3955932804333266

Epoch: 592| Step: 0
Training loss: 0.06720060110092163
Validation loss: 1.3941385771638604

Epoch: 6| Step: 1
Training loss: 0.041706930845975876
Validation loss: 1.3920491030139308

Epoch: 6| Step: 2
Training loss: 0.07005472481250763
Validation loss: 1.3991410052904518

Epoch: 6| Step: 3
Training loss: 0.0647021010518074
Validation loss: 1.3887495558748963

Epoch: 6| Step: 4
Training loss: 0.04692055284976959
Validation loss: 1.3894528265922301

Epoch: 6| Step: 5
Training loss: 0.04683735966682434
Validation loss: 1.3980427576649574

Epoch: 6| Step: 6
Training loss: 0.05502369999885559
Validation loss: 1.3954451577637785

Epoch: 6| Step: 7
Training loss: 0.03106008656322956
Validation loss: 1.3550177671576058

Epoch: 6| Step: 8
Training loss: 0.0828065350651741
Validation loss: 1.3640708167065856

Epoch: 6| Step: 9
Training loss: 0.06548407673835754
Validation loss: 1.3525357554035802

Epoch: 6| Step: 10
Training loss: 0.04752444475889206
Validation loss: 1.3579180984086887

Epoch: 6| Step: 11
Training loss: 0.07712556421756744
Validation loss: 1.3589588185792327

Epoch: 6| Step: 12
Training loss: 0.05539568513631821
Validation loss: 1.3581852207901657

Epoch: 6| Step: 13
Training loss: 0.057919129729270935
Validation loss: 1.3424862661669332

Epoch: 593| Step: 0
Training loss: 0.04850594326853752
Validation loss: 1.3653940769933886

Epoch: 6| Step: 1
Training loss: 0.055394817143678665
Validation loss: 1.348141171598947

Epoch: 6| Step: 2
Training loss: 0.05290551483631134
Validation loss: 1.3471460624407696

Epoch: 6| Step: 3
Training loss: 0.061350177973508835
Validation loss: 1.3405240415244974

Epoch: 6| Step: 4
Training loss: 0.06108463183045387
Validation loss: 1.3493168969308176

Epoch: 6| Step: 5
Training loss: 0.06593851745128632
Validation loss: 1.3377631056693293

Epoch: 6| Step: 6
Training loss: 0.0366918221116066
Validation loss: 1.347965431469743

Epoch: 6| Step: 7
Training loss: 0.06497021019458771
Validation loss: 1.3753519397909924

Epoch: 6| Step: 8
Training loss: 0.0343119353055954
Validation loss: 1.349701387907869

Epoch: 6| Step: 9
Training loss: 0.06635063886642456
Validation loss: 1.3689010720099173

Epoch: 6| Step: 10
Training loss: 0.060999877750873566
Validation loss: 1.3736934008136872

Epoch: 6| Step: 11
Training loss: 0.034069765359163284
Validation loss: 1.394200905676811

Epoch: 6| Step: 12
Training loss: 0.06751274317502975
Validation loss: 1.3874445346093947

Epoch: 6| Step: 13
Training loss: 0.05574043467640877
Validation loss: 1.3902734024550325

Epoch: 594| Step: 0
Training loss: 0.03808069974184036
Validation loss: 1.3978919777818906

Epoch: 6| Step: 1
Training loss: 0.05657295137643814
Validation loss: 1.3942273304026613

Epoch: 6| Step: 2
Training loss: 0.03913310915231705
Validation loss: 1.3999965178069247

Epoch: 6| Step: 3
Training loss: 0.042953141033649445
Validation loss: 1.3875787360693819

Epoch: 6| Step: 4
Training loss: 0.07074412703514099
Validation loss: 1.3962364953051332

Epoch: 6| Step: 5
Training loss: 0.049910224974155426
Validation loss: 1.3813393917135013

Epoch: 6| Step: 6
Training loss: 0.07447810471057892
Validation loss: 1.3881793759202445

Epoch: 6| Step: 7
Training loss: 0.04870999604463577
Validation loss: 1.3732580600246307

Epoch: 6| Step: 8
Training loss: 0.05065995454788208
Validation loss: 1.3652878961255472

Epoch: 6| Step: 9
Training loss: 0.05488937348127365
Validation loss: 1.3837082783381145

Epoch: 6| Step: 10
Training loss: 0.051872674375772476
Validation loss: 1.386086017854752

Epoch: 6| Step: 11
Training loss: 0.052565112709999084
Validation loss: 1.3591906018154596

Epoch: 6| Step: 12
Training loss: 0.06437498331069946
Validation loss: 1.3854644298553467

Epoch: 6| Step: 13
Training loss: 0.06464125216007233
Validation loss: 1.3705681895696988

Epoch: 595| Step: 0
Training loss: 0.07418271899223328
Validation loss: 1.3536601976681781

Epoch: 6| Step: 1
Training loss: 0.04947195202112198
Validation loss: 1.36013953275578

Epoch: 6| Step: 2
Training loss: 0.053430091589689255
Validation loss: 1.3716793669167386

Epoch: 6| Step: 3
Training loss: 0.06748451292514801
Validation loss: 1.3780766071811799

Epoch: 6| Step: 4
Training loss: 0.06736822426319122
Validation loss: 1.3767969576261376

Epoch: 6| Step: 5
Training loss: 0.030742358416318893
Validation loss: 1.3803707643221783

Epoch: 6| Step: 6
Training loss: 0.04893527552485466
Validation loss: 1.3829793814689881

Epoch: 6| Step: 7
Training loss: 0.04167552292346954
Validation loss: 1.3836737473805745

Epoch: 6| Step: 8
Training loss: 0.036066584289073944
Validation loss: 1.396391526986194

Epoch: 6| Step: 9
Training loss: 0.040380317717790604
Validation loss: 1.4085008021323913

Epoch: 6| Step: 10
Training loss: 0.0631847009062767
Validation loss: 1.3875296679876183

Epoch: 6| Step: 11
Training loss: 0.055927444249391556
Validation loss: 1.3991030864818121

Epoch: 6| Step: 12
Training loss: 0.06852003931999207
Validation loss: 1.3822914618317799

Epoch: 6| Step: 13
Training loss: 0.06284530460834503
Validation loss: 1.3812428302662347

Epoch: 596| Step: 0
Training loss: 0.0425693616271019
Validation loss: 1.3794198548921974

Epoch: 6| Step: 1
Training loss: 0.06976249814033508
Validation loss: 1.3920039893478475

Epoch: 6| Step: 2
Training loss: 0.036254171282052994
Validation loss: 1.3896529905257686

Epoch: 6| Step: 3
Training loss: 0.03462276607751846
Validation loss: 1.3838687404509513

Epoch: 6| Step: 4
Training loss: 0.0658508911728859
Validation loss: 1.3914949086404615

Epoch: 6| Step: 5
Training loss: 0.05583357810974121
Validation loss: 1.3608316074135482

Epoch: 6| Step: 6
Training loss: 0.05150140821933746
Validation loss: 1.393137994632926

Epoch: 6| Step: 7
Training loss: 0.03956387937068939
Validation loss: 1.3797322268127112

Epoch: 6| Step: 8
Training loss: 0.03602391853928566
Validation loss: 1.3722925493794103

Epoch: 6| Step: 9
Training loss: 0.04514726996421814
Validation loss: 1.3609410998641804

Epoch: 6| Step: 10
Training loss: 0.040389373898506165
Validation loss: 1.361104957519039

Epoch: 6| Step: 11
Training loss: 0.03920400142669678
Validation loss: 1.3583616223386539

Epoch: 6| Step: 12
Training loss: 0.03435298800468445
Validation loss: 1.3737136958747782

Epoch: 6| Step: 13
Training loss: 0.06581196188926697
Validation loss: 1.3597003875240203

Epoch: 597| Step: 0
Training loss: 0.05413422733545303
Validation loss: 1.3775023452697261

Epoch: 6| Step: 1
Training loss: 0.05821109935641289
Validation loss: 1.3739457873887913

Epoch: 6| Step: 2
Training loss: 0.06929946690797806
Validation loss: 1.3691257789570799

Epoch: 6| Step: 3
Training loss: 0.06670604646205902
Validation loss: 1.3733500472960933

Epoch: 6| Step: 4
Training loss: 0.061943359673023224
Validation loss: 1.3830322065661032

Epoch: 6| Step: 5
Training loss: 0.05074611306190491
Validation loss: 1.3738497726378902

Epoch: 6| Step: 6
Training loss: 0.08712944388389587
Validation loss: 1.3788837155988138

Epoch: 6| Step: 7
Training loss: 0.07424388825893402
Validation loss: 1.3795234900648876

Epoch: 6| Step: 8
Training loss: 0.045470673590898514
Validation loss: 1.3825327619429557

Epoch: 6| Step: 9
Training loss: 0.09917902946472168
Validation loss: 1.3729204375256774

Epoch: 6| Step: 10
Training loss: 0.0520109087228775
Validation loss: 1.3604277141632573

Epoch: 6| Step: 11
Training loss: 0.04851783066987991
Validation loss: 1.3459362945249003

Epoch: 6| Step: 12
Training loss: 0.0401722714304924
Validation loss: 1.3537940684185232

Epoch: 6| Step: 13
Training loss: 0.06886884570121765
Validation loss: 1.3430105255496116

Epoch: 598| Step: 0
Training loss: 0.04284847527742386
Validation loss: 1.333179934050447

Epoch: 6| Step: 1
Training loss: 0.044391930103302
Validation loss: 1.3511713525300384

Epoch: 6| Step: 2
Training loss: 0.0710250735282898
Validation loss: 1.32265289368168

Epoch: 6| Step: 3
Training loss: 0.05887209624052048
Validation loss: 1.3470860565862348

Epoch: 6| Step: 4
Training loss: 0.06513849645853043
Validation loss: 1.3433307748968883

Epoch: 6| Step: 5
Training loss: 0.06008944660425186
Validation loss: 1.3438139371974493

Epoch: 6| Step: 6
Training loss: 0.05034014210104942
Validation loss: 1.343452181867374

Epoch: 6| Step: 7
Training loss: 0.05733296647667885
Validation loss: 1.369193737224866

Epoch: 6| Step: 8
Training loss: 0.039130471646785736
Validation loss: 1.3484535749240587

Epoch: 6| Step: 9
Training loss: 0.05789601057767868
Validation loss: 1.3711933410295876

Epoch: 6| Step: 10
Training loss: 0.03509489446878433
Validation loss: 1.3543220502074047

Epoch: 6| Step: 11
Training loss: 0.06074920669198036
Validation loss: 1.3773027094461585

Epoch: 6| Step: 12
Training loss: 0.07393354922533035
Validation loss: 1.3815206712292087

Epoch: 6| Step: 13
Training loss: 0.04060729220509529
Validation loss: 1.3903473590009956

Epoch: 599| Step: 0
Training loss: 0.03846638649702072
Validation loss: 1.3804047351242394

Epoch: 6| Step: 1
Training loss: 0.04184515401721001
Validation loss: 1.387806059211813

Epoch: 6| Step: 2
Training loss: 0.03725767880678177
Validation loss: 1.3918222868314354

Epoch: 6| Step: 3
Training loss: 0.05229467153549194
Validation loss: 1.3738434712092082

Epoch: 6| Step: 4
Training loss: 0.03777683153748512
Validation loss: 1.3591171612021744

Epoch: 6| Step: 5
Training loss: 0.055191777646541595
Validation loss: 1.3627903820365987

Epoch: 6| Step: 6
Training loss: 0.07829318940639496
Validation loss: 1.3532192143060828

Epoch: 6| Step: 7
Training loss: 0.03557830676436424
Validation loss: 1.3491305907567341

Epoch: 6| Step: 8
Training loss: 0.03862563893198967
Validation loss: 1.3441021801323019

Epoch: 6| Step: 9
Training loss: 0.049660928547382355
Validation loss: 1.3632675973317956

Epoch: 6| Step: 10
Training loss: 0.06403116881847382
Validation loss: 1.354692542424766

Epoch: 6| Step: 11
Training loss: 0.06028405576944351
Validation loss: 1.3633969086472706

Epoch: 6| Step: 12
Training loss: 0.04462357610464096
Validation loss: 1.3622612837822206

Epoch: 6| Step: 13
Training loss: 0.04424065351486206
Validation loss: 1.3477188476952173

Epoch: 600| Step: 0
Training loss: 0.044147565960884094
Validation loss: 1.346098845363945

Epoch: 6| Step: 1
Training loss: 0.048582106828689575
Validation loss: 1.332681006000888

Epoch: 6| Step: 2
Training loss: 0.05670163780450821
Validation loss: 1.3632252113793486

Epoch: 6| Step: 3
Training loss: 0.04741280525922775
Validation loss: 1.356398783704286

Epoch: 6| Step: 4
Training loss: 0.034762248396873474
Validation loss: 1.367383430081029

Epoch: 6| Step: 5
Training loss: 0.0732479989528656
Validation loss: 1.3707238833109539

Epoch: 6| Step: 6
Training loss: 0.051861610263586044
Validation loss: 1.3716452224280244

Epoch: 6| Step: 7
Training loss: 0.056930698454380035
Validation loss: 1.372333368947429

Epoch: 6| Step: 8
Training loss: 0.04919768124818802
Validation loss: 1.3740035808214577

Epoch: 6| Step: 9
Training loss: 0.06164248287677765
Validation loss: 1.3887579428252352

Epoch: 6| Step: 10
Training loss: 0.04322853684425354
Validation loss: 1.3838198274694464

Epoch: 6| Step: 11
Training loss: 0.09284132719039917
Validation loss: 1.3739980452804155

Epoch: 6| Step: 12
Training loss: 0.06448113918304443
Validation loss: 1.385464923356169

Epoch: 6| Step: 13
Training loss: 0.038931116461753845
Validation loss: 1.3655349157189811

Epoch: 601| Step: 0
Training loss: 0.07135919481515884
Validation loss: 1.3849152711129957

Epoch: 6| Step: 1
Training loss: 0.050199687480926514
Validation loss: 1.398015663187991

Epoch: 6| Step: 2
Training loss: 0.05116187036037445
Validation loss: 1.3913795627573484

Epoch: 6| Step: 3
Training loss: 0.04804246872663498
Validation loss: 1.3829860616755743

Epoch: 6| Step: 4
Training loss: 0.061506882309913635
Validation loss: 1.3786124080739997

Epoch: 6| Step: 5
Training loss: 0.06695906817913055
Validation loss: 1.3810666543181225

Epoch: 6| Step: 6
Training loss: 0.041462723165750504
Validation loss: 1.3669967023275231

Epoch: 6| Step: 7
Training loss: 0.038555413484573364
Validation loss: 1.3888201149561072

Epoch: 6| Step: 8
Training loss: 0.05806972086429596
Validation loss: 1.3883676657112696

Epoch: 6| Step: 9
Training loss: 0.043505147099494934
Validation loss: 1.3808120886484783

Epoch: 6| Step: 10
Training loss: 0.07069845497608185
Validation loss: 1.3765533354974562

Epoch: 6| Step: 11
Training loss: 0.06860281527042389
Validation loss: 1.3875042725634832

Epoch: 6| Step: 12
Training loss: 0.06296009570360184
Validation loss: 1.3878944702045892

Epoch: 6| Step: 13
Training loss: 0.06475526839494705
Validation loss: 1.3688947487902898

Epoch: 602| Step: 0
Training loss: 0.03689640015363693
Validation loss: 1.3877946721610201

Epoch: 6| Step: 1
Training loss: 0.028320826590061188
Validation loss: 1.4059568861479401

Epoch: 6| Step: 2
Training loss: 0.047909028828144073
Validation loss: 1.3878922142008299

Epoch: 6| Step: 3
Training loss: 0.03171543776988983
Validation loss: 1.3659575613596107

Epoch: 6| Step: 4
Training loss: 0.0598333515226841
Validation loss: 1.3723003159287155

Epoch: 6| Step: 5
Training loss: 0.07597102969884872
Validation loss: 1.368106339567451

Epoch: 6| Step: 6
Training loss: 0.047359660267829895
Validation loss: 1.3686916661518875

Epoch: 6| Step: 7
Training loss: 0.06267574429512024
Validation loss: 1.3679739288104478

Epoch: 6| Step: 8
Training loss: 0.06362602114677429
Validation loss: 1.3661236852727912

Epoch: 6| Step: 9
Training loss: 0.055775757879018784
Validation loss: 1.3581716117038523

Epoch: 6| Step: 10
Training loss: 0.04523654282093048
Validation loss: 1.3837780913999003

Epoch: 6| Step: 11
Training loss: 0.05171909183263779
Validation loss: 1.387515362231962

Epoch: 6| Step: 12
Training loss: 0.05771179124712944
Validation loss: 1.3783351157301216

Epoch: 6| Step: 13
Training loss: 0.04192536324262619
Validation loss: 1.387455036563258

Epoch: 603| Step: 0
Training loss: 0.03189454600214958
Validation loss: 1.415968645003534

Epoch: 6| Step: 1
Training loss: 0.03574632108211517
Validation loss: 1.4120777935110114

Epoch: 6| Step: 2
Training loss: 0.06642957776784897
Validation loss: 1.4171579601944133

Epoch: 6| Step: 3
Training loss: 0.051339760422706604
Validation loss: 1.4001078169832948

Epoch: 6| Step: 4
Training loss: 0.06036832928657532
Validation loss: 1.4239737231244323

Epoch: 6| Step: 5
Training loss: 0.04476860538125038
Validation loss: 1.4055442861331406

Epoch: 6| Step: 6
Training loss: 0.09381180256605148
Validation loss: 1.398128403130398

Epoch: 6| Step: 7
Training loss: 0.06795982271432877
Validation loss: 1.3939135715525637

Epoch: 6| Step: 8
Training loss: 0.0699269026517868
Validation loss: 1.4050098157698108

Epoch: 6| Step: 9
Training loss: 0.09120965003967285
Validation loss: 1.3472707130575692

Epoch: 6| Step: 10
Training loss: 0.06713300198316574
Validation loss: 1.356674462236384

Epoch: 6| Step: 11
Training loss: 0.06036674976348877
Validation loss: 1.3694187665498385

Epoch: 6| Step: 12
Training loss: 0.06599459052085876
Validation loss: 1.3552840486649544

Epoch: 6| Step: 13
Training loss: 0.03755854070186615
Validation loss: 1.3443648122972058

Epoch: 604| Step: 0
Training loss: 0.07571431994438171
Validation loss: 1.3401756722440001

Epoch: 6| Step: 1
Training loss: 0.04179418832063675
Validation loss: 1.3696791401473425

Epoch: 6| Step: 2
Training loss: 0.051898468285799026
Validation loss: 1.3767253942387079

Epoch: 6| Step: 3
Training loss: 0.061168644577264786
Validation loss: 1.3499921278287006

Epoch: 6| Step: 4
Training loss: 0.04573925957083702
Validation loss: 1.3404188053582304

Epoch: 6| Step: 5
Training loss: 0.05416565760970116
Validation loss: 1.3504154810341455

Epoch: 6| Step: 6
Training loss: 0.05444838106632233
Validation loss: 1.3577942079113376

Epoch: 6| Step: 7
Training loss: 0.04100651666522026
Validation loss: 1.3578321600473056

Epoch: 6| Step: 8
Training loss: 0.05387016758322716
Validation loss: 1.3643353613474036

Epoch: 6| Step: 9
Training loss: 0.0644984245300293
Validation loss: 1.3842625617980957

Epoch: 6| Step: 10
Training loss: 0.05723397433757782
Validation loss: 1.399233192525884

Epoch: 6| Step: 11
Training loss: 0.027708476409316063
Validation loss: 1.3942057778758388

Epoch: 6| Step: 12
Training loss: 0.042003802955150604
Validation loss: 1.3822441075437812

Epoch: 6| Step: 13
Training loss: 0.042171649634838104
Validation loss: 1.3817291285402031

Epoch: 605| Step: 0
Training loss: 0.05955071747303009
Validation loss: 1.3865419728781587

Epoch: 6| Step: 1
Training loss: 0.037845008075237274
Validation loss: 1.370993887224505

Epoch: 6| Step: 2
Training loss: 0.07598430663347244
Validation loss: 1.3729988118653655

Epoch: 6| Step: 3
Training loss: 0.04345814883708954
Validation loss: 1.3783205478422103

Epoch: 6| Step: 4
Training loss: 0.041099123656749725
Validation loss: 1.3872205352270475

Epoch: 6| Step: 5
Training loss: 0.05285529047250748
Validation loss: 1.40491053494074

Epoch: 6| Step: 6
Training loss: 0.06946339458227158
Validation loss: 1.39147691060138

Epoch: 6| Step: 7
Training loss: 0.07036364078521729
Validation loss: 1.4015893718247772

Epoch: 6| Step: 8
Training loss: 0.08846049755811691
Validation loss: 1.3773364623387654

Epoch: 6| Step: 9
Training loss: 0.05090803653001785
Validation loss: 1.3664379389055314

Epoch: 6| Step: 10
Training loss: 0.0762103796005249
Validation loss: 1.3736029248083792

Epoch: 6| Step: 11
Training loss: 0.04088682308793068
Validation loss: 1.3776267279860794

Epoch: 6| Step: 12
Training loss: 0.062255702912807465
Validation loss: 1.381185766189329

Epoch: 6| Step: 13
Training loss: 0.05655548349022865
Validation loss: 1.3452508308554207

Epoch: 606| Step: 0
Training loss: 0.06220746040344238
Validation loss: 1.34503185877236

Epoch: 6| Step: 1
Training loss: 0.08055081963539124
Validation loss: 1.341294519362911

Epoch: 6| Step: 2
Training loss: 0.061410997062921524
Validation loss: 1.350004557640322

Epoch: 6| Step: 3
Training loss: 0.08318465948104858
Validation loss: 1.3451715130959787

Epoch: 6| Step: 4
Training loss: 0.09310884773731232
Validation loss: 1.3630444042144283

Epoch: 6| Step: 5
Training loss: 0.06309562176465988
Validation loss: 1.3428517849214616

Epoch: 6| Step: 6
Training loss: 0.05423147231340408
Validation loss: 1.387796175736253

Epoch: 6| Step: 7
Training loss: 0.046338148415088654
Validation loss: 1.3601130400934527

Epoch: 6| Step: 8
Training loss: 0.03567022085189819
Validation loss: 1.378068067694223

Epoch: 6| Step: 9
Training loss: 0.04132881388068199
Validation loss: 1.3940077302276448

Epoch: 6| Step: 10
Training loss: 0.061978213489055634
Validation loss: 1.4094718681868685

Epoch: 6| Step: 11
Training loss: 0.03774496912956238
Validation loss: 1.4074965343680432

Epoch: 6| Step: 12
Training loss: 0.03625532612204552
Validation loss: 1.4013315798133932

Epoch: 6| Step: 13
Training loss: 0.05190648138523102
Validation loss: 1.4055668602707565

Epoch: 607| Step: 0
Training loss: 0.04745114594697952
Validation loss: 1.4021055749667588

Epoch: 6| Step: 1
Training loss: 0.06530407071113586
Validation loss: 1.3979022246535107

Epoch: 6| Step: 2
Training loss: 0.06704499572515488
Validation loss: 1.3883868148249965

Epoch: 6| Step: 3
Training loss: 0.04246550425887108
Validation loss: 1.3967531893842964

Epoch: 6| Step: 4
Training loss: 0.07788558304309845
Validation loss: 1.3785385047235796

Epoch: 6| Step: 5
Training loss: 0.027278339490294456
Validation loss: 1.3966671907773582

Epoch: 6| Step: 6
Training loss: 0.04418051615357399
Validation loss: 1.3870033346196657

Epoch: 6| Step: 7
Training loss: 0.05975622311234474
Validation loss: 1.387695308654539

Epoch: 6| Step: 8
Training loss: 0.07451744377613068
Validation loss: 1.3987921604546167

Epoch: 6| Step: 9
Training loss: 0.039959296584129333
Validation loss: 1.3785139168462446

Epoch: 6| Step: 10
Training loss: 0.04099151864647865
Validation loss: 1.3861666815255278

Epoch: 6| Step: 11
Training loss: 0.03590180724859238
Validation loss: 1.3959254603232107

Epoch: 6| Step: 12
Training loss: 0.048808351159095764
Validation loss: 1.3697854306108208

Epoch: 6| Step: 13
Training loss: 0.057492416352033615
Validation loss: 1.3909914326924149

Epoch: 608| Step: 0
Training loss: 0.04879482835531235
Validation loss: 1.3727563914432321

Epoch: 6| Step: 1
Training loss: 0.042215898633003235
Validation loss: 1.3997945952159103

Epoch: 6| Step: 2
Training loss: 0.05611720681190491
Validation loss: 1.395586226576118

Epoch: 6| Step: 3
Training loss: 0.040573544800281525
Validation loss: 1.3995324988518991

Epoch: 6| Step: 4
Training loss: 0.046379122883081436
Validation loss: 1.3985129133347542

Epoch: 6| Step: 5
Training loss: 0.06454730778932571
Validation loss: 1.3858329185875513

Epoch: 6| Step: 6
Training loss: 0.05108296871185303
Validation loss: 1.3973339847339097

Epoch: 6| Step: 7
Training loss: 0.062312014400959015
Validation loss: 1.3726626980689265

Epoch: 6| Step: 8
Training loss: 0.039669524878263474
Validation loss: 1.3922708495970695

Epoch: 6| Step: 9
Training loss: 0.03150874376296997
Validation loss: 1.4008643178529636

Epoch: 6| Step: 10
Training loss: 0.05384819209575653
Validation loss: 1.4073365311468802

Epoch: 6| Step: 11
Training loss: 0.061843469738960266
Validation loss: 1.375921122489437

Epoch: 6| Step: 12
Training loss: 0.04859830066561699
Validation loss: 1.3727527933736001

Epoch: 6| Step: 13
Training loss: 0.07584670186042786
Validation loss: 1.3757591119376562

Epoch: 609| Step: 0
Training loss: 0.06983557343482971
Validation loss: 1.3605436708337517

Epoch: 6| Step: 1
Training loss: 0.05099576339125633
Validation loss: 1.34321060744665

Epoch: 6| Step: 2
Training loss: 0.05909454822540283
Validation loss: 1.3362521407424763

Epoch: 6| Step: 3
Training loss: 0.04540673643350601
Validation loss: 1.3298066598112865

Epoch: 6| Step: 4
Training loss: 0.04511939361691475
Validation loss: 1.3536067265336231

Epoch: 6| Step: 5
Training loss: 0.047170720994472504
Validation loss: 1.346688929424491

Epoch: 6| Step: 6
Training loss: 0.04891675338149071
Validation loss: 1.3357836648982058

Epoch: 6| Step: 7
Training loss: 0.08612949401140213
Validation loss: 1.350221175019459

Epoch: 6| Step: 8
Training loss: 0.04686293751001358
Validation loss: 1.3405662454584593

Epoch: 6| Step: 9
Training loss: 0.03842245414853096
Validation loss: 1.3599948126782653

Epoch: 6| Step: 10
Training loss: 0.06810740381479263
Validation loss: 1.3673296551550589

Epoch: 6| Step: 11
Training loss: 0.04811416566371918
Validation loss: 1.3725583643041632

Epoch: 6| Step: 12
Training loss: 0.05049486458301544
Validation loss: 1.3939481999284478

Epoch: 6| Step: 13
Training loss: 0.04566195234656334
Validation loss: 1.3943176846350394

Epoch: 610| Step: 0
Training loss: 0.0667814314365387
Validation loss: 1.3952076537634737

Epoch: 6| Step: 1
Training loss: 0.06909579783678055
Validation loss: 1.3933708885664582

Epoch: 6| Step: 2
Training loss: 0.1056826114654541
Validation loss: 1.3993108054643035

Epoch: 6| Step: 3
Training loss: 0.0749208927154541
Validation loss: 1.4160550486656927

Epoch: 6| Step: 4
Training loss: 0.10836435854434967
Validation loss: 1.4074869053338164

Epoch: 6| Step: 5
Training loss: 0.07231064140796661
Validation loss: 1.3968724025193082

Epoch: 6| Step: 6
Training loss: 0.05011702701449394
Validation loss: 1.3831835818547074

Epoch: 6| Step: 7
Training loss: 0.06628881394863129
Validation loss: 1.3762131737124534

Epoch: 6| Step: 8
Training loss: 0.05622256547212601
Validation loss: 1.3877361025861514

Epoch: 6| Step: 9
Training loss: 0.07574266940355301
Validation loss: 1.387511791721467

Epoch: 6| Step: 10
Training loss: 0.09246598929166794
Validation loss: 1.3803650986763738

Epoch: 6| Step: 11
Training loss: 0.09238465130329132
Validation loss: 1.3889725733828802

Epoch: 6| Step: 12
Training loss: 0.06316360831260681
Validation loss: 1.3951627291658872

Epoch: 6| Step: 13
Training loss: 0.0525209903717041
Validation loss: 1.4163967922169676

Epoch: 611| Step: 0
Training loss: 0.05807715654373169
Validation loss: 1.4198247437836022

Epoch: 6| Step: 1
Training loss: 0.046636469662189484
Validation loss: 1.4174572883113739

Epoch: 6| Step: 2
Training loss: 0.06197482347488403
Validation loss: 1.4212979475657146

Epoch: 6| Step: 3
Training loss: 0.07098987698554993
Validation loss: 1.4019111510246032

Epoch: 6| Step: 4
Training loss: 0.06501604616641998
Validation loss: 1.400901811738168

Epoch: 6| Step: 5
Training loss: 0.06380704045295715
Validation loss: 1.3931458637278566

Epoch: 6| Step: 6
Training loss: 0.06526651978492737
Validation loss: 1.3825603159525062

Epoch: 6| Step: 7
Training loss: 0.052314549684524536
Validation loss: 1.3810146367678078

Epoch: 6| Step: 8
Training loss: 0.09317979961633682
Validation loss: 1.3933756389925558

Epoch: 6| Step: 9
Training loss: 0.053370151668787
Validation loss: 1.380057007394811

Epoch: 6| Step: 10
Training loss: 0.05039142444729805
Validation loss: 1.3750991629016014

Epoch: 6| Step: 11
Training loss: 0.06714529544115067
Validation loss: 1.365080746271277

Epoch: 6| Step: 12
Training loss: 0.038480572402477264
Validation loss: 1.3428972946700228

Epoch: 6| Step: 13
Training loss: 0.0734473168849945
Validation loss: 1.3665921072806082

Epoch: 612| Step: 0
Training loss: 0.0759153962135315
Validation loss: 1.3358793027939335

Epoch: 6| Step: 1
Training loss: 0.05108954384922981
Validation loss: 1.332339270140535

Epoch: 6| Step: 2
Training loss: 0.06696558743715286
Validation loss: 1.3143241302941435

Epoch: 6| Step: 3
Training loss: 0.09706014394760132
Validation loss: 1.3135495647307365

Epoch: 6| Step: 4
Training loss: 0.07252780348062515
Validation loss: 1.3072666942432363

Epoch: 6| Step: 5
Training loss: 0.07179862260818481
Validation loss: 1.2879225848823466

Epoch: 6| Step: 6
Training loss: 0.0778309553861618
Validation loss: 1.3045488044779787

Epoch: 6| Step: 7
Training loss: 0.07830321788787842
Validation loss: 1.315092102173836

Epoch: 6| Step: 8
Training loss: 0.047563131898641586
Validation loss: 1.3303408065149862

Epoch: 6| Step: 9
Training loss: 0.05960623547434807
Validation loss: 1.3345859178932764

Epoch: 6| Step: 10
Training loss: 0.07802209258079529
Validation loss: 1.349780512112443

Epoch: 6| Step: 11
Training loss: 0.06969265639781952
Validation loss: 1.3556640481436124

Epoch: 6| Step: 12
Training loss: 0.045573391020298004
Validation loss: 1.3623558180306548

Epoch: 6| Step: 13
Training loss: 0.035237867385149
Validation loss: 1.3581578295717958

Epoch: 613| Step: 0
Training loss: 0.061794668436050415
Validation loss: 1.36127088146825

Epoch: 6| Step: 1
Training loss: 0.067234568297863
Validation loss: 1.3709058486005312

Epoch: 6| Step: 2
Training loss: 0.06182932108640671
Validation loss: 1.371055136444748

Epoch: 6| Step: 3
Training loss: 0.052821945399045944
Validation loss: 1.3641754709264284

Epoch: 6| Step: 4
Training loss: 0.04382655769586563
Validation loss: 1.357647180557251

Epoch: 6| Step: 5
Training loss: 0.06700576841831207
Validation loss: 1.357024327401192

Epoch: 6| Step: 6
Training loss: 0.08762584626674652
Validation loss: 1.3795058727264404

Epoch: 6| Step: 7
Training loss: 0.07464306056499481
Validation loss: 1.3919239005734843

Epoch: 6| Step: 8
Training loss: 0.06786835193634033
Validation loss: 1.3722455834829679

Epoch: 6| Step: 9
Training loss: 0.05783588066697121
Validation loss: 1.3801476788777176

Epoch: 6| Step: 10
Training loss: 0.05283089727163315
Validation loss: 1.37344693240299

Epoch: 6| Step: 11
Training loss: 0.046178191900253296
Validation loss: 1.3560078695256224

Epoch: 6| Step: 12
Training loss: 0.05087192356586456
Validation loss: 1.3775970897366923

Epoch: 6| Step: 13
Training loss: 0.07970508933067322
Validation loss: 1.3572053819574335

Epoch: 614| Step: 0
Training loss: 0.07535040378570557
Validation loss: 1.3433702940581946

Epoch: 6| Step: 1
Training loss: 0.06228163465857506
Validation loss: 1.342982094774964

Epoch: 6| Step: 2
Training loss: 0.0572248175740242
Validation loss: 1.3506206286850797

Epoch: 6| Step: 3
Training loss: 0.061401039361953735
Validation loss: 1.345483410102065

Epoch: 6| Step: 4
Training loss: 0.06091327220201492
Validation loss: 1.3291040972996784

Epoch: 6| Step: 5
Training loss: 0.06848802417516708
Validation loss: 1.3401525533327492

Epoch: 6| Step: 6
Training loss: 0.06454690545797348
Validation loss: 1.3429104692192488

Epoch: 6| Step: 7
Training loss: 0.07231415808200836
Validation loss: 1.3538973690361105

Epoch: 6| Step: 8
Training loss: 0.0429888516664505
Validation loss: 1.3500483087314072

Epoch: 6| Step: 9
Training loss: 0.06203573942184448
Validation loss: 1.3758722633443854

Epoch: 6| Step: 10
Training loss: 0.07247886061668396
Validation loss: 1.3984894214137908

Epoch: 6| Step: 11
Training loss: 0.08883586525917053
Validation loss: 1.3852695136941888

Epoch: 6| Step: 12
Training loss: 0.058552201837301254
Validation loss: 1.3857906069806827

Epoch: 6| Step: 13
Training loss: 0.06481903046369553
Validation loss: 1.3896237618179732

Epoch: 615| Step: 0
Training loss: 0.04726666957139969
Validation loss: 1.385027995673559

Epoch: 6| Step: 1
Training loss: 0.05099507421255112
Validation loss: 1.3845624077704646

Epoch: 6| Step: 2
Training loss: 0.03391117602586746
Validation loss: 1.3826026224320935

Epoch: 6| Step: 3
Training loss: 0.060001641511917114
Validation loss: 1.3790048604370446

Epoch: 6| Step: 4
Training loss: 0.048551660031080246
Validation loss: 1.3567273616790771

Epoch: 6| Step: 5
Training loss: 0.061192773282527924
Validation loss: 1.3627734876448108

Epoch: 6| Step: 6
Training loss: 0.0540039949119091
Validation loss: 1.3623967773170882

Epoch: 6| Step: 7
Training loss: 0.11464376747608185
Validation loss: 1.3401757773532663

Epoch: 6| Step: 8
Training loss: 0.050114963203668594
Validation loss: 1.353212696249767

Epoch: 6| Step: 9
Training loss: 0.04472959041595459
Validation loss: 1.3363060528232205

Epoch: 6| Step: 10
Training loss: 0.05897732451558113
Validation loss: 1.3676095201123146

Epoch: 6| Step: 11
Training loss: 0.035308703780174255
Validation loss: 1.359001555750447

Epoch: 6| Step: 12
Training loss: 0.05983302742242813
Validation loss: 1.35393730414811

Epoch: 6| Step: 13
Training loss: 0.07198084145784378
Validation loss: 1.3742127046790173

Epoch: 616| Step: 0
Training loss: 0.048629581928253174
Validation loss: 1.3704870644436087

Epoch: 6| Step: 1
Training loss: 0.05366191640496254
Validation loss: 1.3812784020618727

Epoch: 6| Step: 2
Training loss: 0.06870929896831512
Validation loss: 1.354994329073096

Epoch: 6| Step: 3
Training loss: 0.0747816413640976
Validation loss: 1.3674725460749801

Epoch: 6| Step: 4
Training loss: 0.059528931975364685
Validation loss: 1.3488071336541125

Epoch: 6| Step: 5
Training loss: 0.06569068878889084
Validation loss: 1.3537520541939685

Epoch: 6| Step: 6
Training loss: 0.05445501208305359
Validation loss: 1.355828845372764

Epoch: 6| Step: 7
Training loss: 0.03744564577937126
Validation loss: 1.3585286550624396

Epoch: 6| Step: 8
Training loss: 0.06450153142213821
Validation loss: 1.3591465245011032

Epoch: 6| Step: 9
Training loss: 0.049719758331775665
Validation loss: 1.3483547523457518

Epoch: 6| Step: 10
Training loss: 0.05126045644283295
Validation loss: 1.3404847934681883

Epoch: 6| Step: 11
Training loss: 0.03972623124718666
Validation loss: 1.3591688140746085

Epoch: 6| Step: 12
Training loss: 0.07174868136644363
Validation loss: 1.3684423854274135

Epoch: 6| Step: 13
Training loss: 0.07965991646051407
Validation loss: 1.3398578833508235

Epoch: 617| Step: 0
Training loss: 0.050293199717998505
Validation loss: 1.361924623930326

Epoch: 6| Step: 1
Training loss: 0.054919660091400146
Validation loss: 1.3691422195844754

Epoch: 6| Step: 2
Training loss: 0.0512213297188282
Validation loss: 1.3801158967838492

Epoch: 6| Step: 3
Training loss: 0.06981329619884491
Validation loss: 1.382148950971583

Epoch: 6| Step: 4
Training loss: 0.06187780946493149
Validation loss: 1.3881798610892346

Epoch: 6| Step: 5
Training loss: 0.04279439523816109
Validation loss: 1.3986841837565105

Epoch: 6| Step: 6
Training loss: 0.0642833560705185
Validation loss: 1.3928292233456847

Epoch: 6| Step: 7
Training loss: 0.06741659343242645
Validation loss: 1.397430673722298

Epoch: 6| Step: 8
Training loss: 0.05651208013296127
Validation loss: 1.3909419044371574

Epoch: 6| Step: 9
Training loss: 0.045229118317365646
Validation loss: 1.3950588767246535

Epoch: 6| Step: 10
Training loss: 0.09150746464729309
Validation loss: 1.387610750813638

Epoch: 6| Step: 11
Training loss: 0.051525332033634186
Validation loss: 1.3753813171899447

Epoch: 6| Step: 12
Training loss: 0.06991741061210632
Validation loss: 1.3733078004211507

Epoch: 6| Step: 13
Training loss: 0.03629998490214348
Validation loss: 1.3847586083155807

Epoch: 618| Step: 0
Training loss: 0.03994120657444
Validation loss: 1.3815902253632903

Epoch: 6| Step: 1
Training loss: 0.055480457842350006
Validation loss: 1.360946032308763

Epoch: 6| Step: 2
Training loss: 0.08216937631368637
Validation loss: 1.3527729504851884

Epoch: 6| Step: 3
Training loss: 0.06583216041326523
Validation loss: 1.3496573509708527

Epoch: 6| Step: 4
Training loss: 0.07259169220924377
Validation loss: 1.3569708216574885

Epoch: 6| Step: 5
Training loss: 0.10467925667762756
Validation loss: 1.3410828600647628

Epoch: 6| Step: 6
Training loss: 0.04515402764081955
Validation loss: 1.3371640956530007

Epoch: 6| Step: 7
Training loss: 0.062118180096149445
Validation loss: 1.3425605194542998

Epoch: 6| Step: 8
Training loss: 0.036374691873788834
Validation loss: 1.3485638736396708

Epoch: 6| Step: 9
Training loss: 0.04291479289531708
Validation loss: 1.3461033823669597

Epoch: 6| Step: 10
Training loss: 0.04588079825043678
Validation loss: 1.3683195370499805

Epoch: 6| Step: 11
Training loss: 0.03721126168966293
Validation loss: 1.3648333241862636

Epoch: 6| Step: 12
Training loss: 0.03974205255508423
Validation loss: 1.3796188869783956

Epoch: 6| Step: 13
Training loss: 0.09608013182878494
Validation loss: 1.3855850863200363

Epoch: 619| Step: 0
Training loss: 0.06475207209587097
Validation loss: 1.3859037045509583

Epoch: 6| Step: 1
Training loss: 0.038013849407434464
Validation loss: 1.3998205482318837

Epoch: 6| Step: 2
Training loss: 0.06897494196891785
Validation loss: 1.3982171550873788

Epoch: 6| Step: 3
Training loss: 0.043926700949668884
Validation loss: 1.3933273387211624

Epoch: 6| Step: 4
Training loss: 0.054777637124061584
Validation loss: 1.414204474418394

Epoch: 6| Step: 5
Training loss: 0.05085740610957146
Validation loss: 1.407636844983665

Epoch: 6| Step: 6
Training loss: 0.03532181680202484
Validation loss: 1.4099749903525076

Epoch: 6| Step: 7
Training loss: 0.08615075051784515
Validation loss: 1.3920565196262893

Epoch: 6| Step: 8
Training loss: 0.035680029541254044
Validation loss: 1.4129775980467438

Epoch: 6| Step: 9
Training loss: 0.06482384353876114
Validation loss: 1.3974336654909196

Epoch: 6| Step: 10
Training loss: 0.03487081080675125
Validation loss: 1.387291572427237

Epoch: 6| Step: 11
Training loss: 0.08141843974590302
Validation loss: 1.3874082078215897

Epoch: 6| Step: 12
Training loss: 0.04309511557221413
Validation loss: 1.3818260879926785

Epoch: 6| Step: 13
Training loss: 0.04182805120944977
Validation loss: 1.3961144621654222

Epoch: 620| Step: 0
Training loss: 0.037529028952121735
Validation loss: 1.4037442540609708

Epoch: 6| Step: 1
Training loss: 0.08285510540008545
Validation loss: 1.3911996105665803

Epoch: 6| Step: 2
Training loss: 0.046128563582897186
Validation loss: 1.3876941178434639

Epoch: 6| Step: 3
Training loss: 0.06412464380264282
Validation loss: 1.3920975032673086

Epoch: 6| Step: 4
Training loss: 0.04646283760666847
Validation loss: 1.3976900628817979

Epoch: 6| Step: 5
Training loss: 0.07152846455574036
Validation loss: 1.3879236098258727

Epoch: 6| Step: 6
Training loss: 0.04411489516496658
Validation loss: 1.3782616687077347

Epoch: 6| Step: 7
Training loss: 0.05062045156955719
Validation loss: 1.3940841940141493

Epoch: 6| Step: 8
Training loss: 0.06905955821275711
Validation loss: 1.3700541014312415

Epoch: 6| Step: 9
Training loss: 0.02893950417637825
Validation loss: 1.3902428175813408

Epoch: 6| Step: 10
Training loss: 0.037014439702034
Validation loss: 1.3847921227896085

Epoch: 6| Step: 11
Training loss: 0.05173492804169655
Validation loss: 1.3662986268279373

Epoch: 6| Step: 12
Training loss: 0.04848838597536087
Validation loss: 1.3607443705681832

Epoch: 6| Step: 13
Training loss: 0.07977983355522156
Validation loss: 1.3726191994964436

Epoch: 621| Step: 0
Training loss: 0.05049063637852669
Validation loss: 1.3686218889810706

Epoch: 6| Step: 1
Training loss: 0.04626189172267914
Validation loss: 1.361734446658883

Epoch: 6| Step: 2
Training loss: 0.025972403585910797
Validation loss: 1.364681868142979

Epoch: 6| Step: 3
Training loss: 0.07859814167022705
Validation loss: 1.377764021196673

Epoch: 6| Step: 4
Training loss: 0.04104645177721977
Validation loss: 1.3637330121891473

Epoch: 6| Step: 5
Training loss: 0.03298846632242203
Validation loss: 1.3752207691951464

Epoch: 6| Step: 6
Training loss: 0.08643612265586853
Validation loss: 1.368756700587529

Epoch: 6| Step: 7
Training loss: 0.05914608761668205
Validation loss: 1.3715807020023305

Epoch: 6| Step: 8
Training loss: 0.056978147476911545
Validation loss: 1.3697647920218847

Epoch: 6| Step: 9
Training loss: 0.047640662640333176
Validation loss: 1.3896272323464836

Epoch: 6| Step: 10
Training loss: 0.04510209709405899
Validation loss: 1.3738170682743032

Epoch: 6| Step: 11
Training loss: 0.052228957414627075
Validation loss: 1.3688608613065494

Epoch: 6| Step: 12
Training loss: 0.07537610828876495
Validation loss: 1.3573076878824542

Epoch: 6| Step: 13
Training loss: 0.08964559435844421
Validation loss: 1.3441325541465514

Epoch: 622| Step: 0
Training loss: 0.0441758930683136
Validation loss: 1.3579238172500365

Epoch: 6| Step: 1
Training loss: 0.05364005267620087
Validation loss: 1.3802555594393002

Epoch: 6| Step: 2
Training loss: 0.03822031617164612
Validation loss: 1.3751941560417094

Epoch: 6| Step: 3
Training loss: 0.055617332458496094
Validation loss: 1.3798853928042996

Epoch: 6| Step: 4
Training loss: 0.0467953085899353
Validation loss: 1.3725415929671256

Epoch: 6| Step: 5
Training loss: 0.057678669691085815
Validation loss: 1.3674254135418964

Epoch: 6| Step: 6
Training loss: 0.06456054747104645
Validation loss: 1.3632923954276628

Epoch: 6| Step: 7
Training loss: 0.04425979405641556
Validation loss: 1.3459668133848457

Epoch: 6| Step: 8
Training loss: 0.0690019428730011
Validation loss: 1.3654634901272353

Epoch: 6| Step: 9
Training loss: 0.04604218900203705
Validation loss: 1.3666180667056833

Epoch: 6| Step: 10
Training loss: 0.06115026772022247
Validation loss: 1.3754196372083438

Epoch: 6| Step: 11
Training loss: 0.03909904882311821
Validation loss: 1.3756986228368615

Epoch: 6| Step: 12
Training loss: 0.050855983048677444
Validation loss: 1.378489722487747

Epoch: 6| Step: 13
Training loss: 0.020094342529773712
Validation loss: 1.383354784339987

Epoch: 623| Step: 0
Training loss: 0.04872885346412659
Validation loss: 1.3739304439995879

Epoch: 6| Step: 1
Training loss: 0.03916982561349869
Validation loss: 1.3797163745408416

Epoch: 6| Step: 2
Training loss: 0.04649566859006882
Validation loss: 1.4023620133758874

Epoch: 6| Step: 3
Training loss: 0.04409913346171379
Validation loss: 1.3923587517071796

Epoch: 6| Step: 4
Training loss: 0.07002104073762894
Validation loss: 1.3982395279792048

Epoch: 6| Step: 5
Training loss: 0.0791124552488327
Validation loss: 1.3946050072229037

Epoch: 6| Step: 6
Training loss: 0.0602622926235199
Validation loss: 1.3983013540185907

Epoch: 6| Step: 7
Training loss: 0.07151451706886292
Validation loss: 1.4019677921008038

Epoch: 6| Step: 8
Training loss: 0.062018826603889465
Validation loss: 1.3922765466474718

Epoch: 6| Step: 9
Training loss: 0.055395230650901794
Validation loss: 1.3934233291174776

Epoch: 6| Step: 10
Training loss: 0.044612664729356766
Validation loss: 1.39599335001361

Epoch: 6| Step: 11
Training loss: 0.062485259026288986
Validation loss: 1.399037762354779

Epoch: 6| Step: 12
Training loss: 0.06417959928512573
Validation loss: 1.401245694006643

Epoch: 6| Step: 13
Training loss: 0.07414272427558899
Validation loss: 1.3998845790022163

Epoch: 624| Step: 0
Training loss: 0.05536114424467087
Validation loss: 1.3824814160664876

Epoch: 6| Step: 1
Training loss: 0.07353989779949188
Validation loss: 1.4089712814618183

Epoch: 6| Step: 2
Training loss: 0.04829562082886696
Validation loss: 1.386433236060604

Epoch: 6| Step: 3
Training loss: 0.05879330635070801
Validation loss: 1.3652119405807988

Epoch: 6| Step: 4
Training loss: 0.04330408200621605
Validation loss: 1.3897397889885852

Epoch: 6| Step: 5
Training loss: 0.061162907630205154
Validation loss: 1.3855756341770131

Epoch: 6| Step: 6
Training loss: 0.04041559249162674
Validation loss: 1.3937487512506463

Epoch: 6| Step: 7
Training loss: 0.05138815566897392
Validation loss: 1.3716439918805194

Epoch: 6| Step: 8
Training loss: 0.06784951686859131
Validation loss: 1.379670528955357

Epoch: 6| Step: 9
Training loss: 0.05902472883462906
Validation loss: 1.3848835460601314

Epoch: 6| Step: 10
Training loss: 0.07927343249320984
Validation loss: 1.3834730655916276

Epoch: 6| Step: 11
Training loss: 0.05857359617948532
Validation loss: 1.3674836697116974

Epoch: 6| Step: 12
Training loss: 0.04859902337193489
Validation loss: 1.3895281860905309

Epoch: 6| Step: 13
Training loss: 0.0337473563849926
Validation loss: 1.3576243385191886

Epoch: 625| Step: 0
Training loss: 0.0637112557888031
Validation loss: 1.3818962702187159

Epoch: 6| Step: 1
Training loss: 0.06622456014156342
Validation loss: 1.3690486056830293

Epoch: 6| Step: 2
Training loss: 0.04643116891384125
Validation loss: 1.370746325421077

Epoch: 6| Step: 3
Training loss: 0.06858460605144501
Validation loss: 1.3586136987132411

Epoch: 6| Step: 4
Training loss: 0.05044405907392502
Validation loss: 1.3498725532203593

Epoch: 6| Step: 5
Training loss: 0.03779080510139465
Validation loss: 1.35554572010553

Epoch: 6| Step: 6
Training loss: 0.05806951969861984
Validation loss: 1.3681624704791653

Epoch: 6| Step: 7
Training loss: 0.08234131336212158
Validation loss: 1.3527735240997807

Epoch: 6| Step: 8
Training loss: 0.04247066378593445
Validation loss: 1.3563310587277977

Epoch: 6| Step: 9
Training loss: 0.04937805235385895
Validation loss: 1.3809034696189306

Epoch: 6| Step: 10
Training loss: 0.06402832269668579
Validation loss: 1.3722703969606789

Epoch: 6| Step: 11
Training loss: 0.05771559476852417
Validation loss: 1.3581070412871659

Epoch: 6| Step: 12
Training loss: 0.03493104875087738
Validation loss: 1.3704491405076877

Epoch: 6| Step: 13
Training loss: 0.039331141859292984
Validation loss: 1.3839194864355109

Epoch: 626| Step: 0
Training loss: 0.07394833862781525
Validation loss: 1.372789389343672

Epoch: 6| Step: 1
Training loss: 0.07569465786218643
Validation loss: 1.364933559971471

Epoch: 6| Step: 2
Training loss: 0.07113964855670929
Validation loss: 1.3779994659526373

Epoch: 6| Step: 3
Training loss: 0.05426851660013199
Validation loss: 1.3603943253076205

Epoch: 6| Step: 4
Training loss: 0.06412263214588165
Validation loss: 1.3628203458683465

Epoch: 6| Step: 5
Training loss: 0.058671049773693085
Validation loss: 1.363743535933956

Epoch: 6| Step: 6
Training loss: 0.04559308663010597
Validation loss: 1.3790181029227473

Epoch: 6| Step: 7
Training loss: 0.03459582477807999
Validation loss: 1.368837134812468

Epoch: 6| Step: 8
Training loss: 0.03686641901731491
Validation loss: 1.3699030555704588

Epoch: 6| Step: 9
Training loss: 0.04573819786310196
Validation loss: 1.3848479870826966

Epoch: 6| Step: 10
Training loss: 0.03330741450190544
Validation loss: 1.3964585681115427

Epoch: 6| Step: 11
Training loss: 0.033131781965494156
Validation loss: 1.3698298738848778

Epoch: 6| Step: 12
Training loss: 0.03577049821615219
Validation loss: 1.3824253556548909

Epoch: 6| Step: 13
Training loss: 0.060904450714588165
Validation loss: 1.3738381747276551

Epoch: 627| Step: 0
Training loss: 0.04531678184866905
Validation loss: 1.3928507989452732

Epoch: 6| Step: 1
Training loss: 0.06689000129699707
Validation loss: 1.3885326257316015

Epoch: 6| Step: 2
Training loss: 0.058935392647981644
Validation loss: 1.403381198965093

Epoch: 6| Step: 3
Training loss: 0.03791562095284462
Validation loss: 1.4078904601835436

Epoch: 6| Step: 4
Training loss: 0.05558508634567261
Validation loss: 1.4021205209916638

Epoch: 6| Step: 5
Training loss: 0.029731638729572296
Validation loss: 1.4069055511105446

Epoch: 6| Step: 6
Training loss: 0.04867326468229294
Validation loss: 1.4178726057852469

Epoch: 6| Step: 7
Training loss: 0.05111248418688774
Validation loss: 1.3979269022582679

Epoch: 6| Step: 8
Training loss: 0.062470145523548126
Validation loss: 1.4042531879999305

Epoch: 6| Step: 9
Training loss: 0.0433095246553421
Validation loss: 1.3974372520241687

Epoch: 6| Step: 10
Training loss: 0.058322273194789886
Validation loss: 1.3947581796235935

Epoch: 6| Step: 11
Training loss: 0.07415559142827988
Validation loss: 1.386967908951544

Epoch: 6| Step: 12
Training loss: 0.05880696326494217
Validation loss: 1.3780484622524631

Epoch: 6| Step: 13
Training loss: 0.0856597051024437
Validation loss: 1.3739614358512304

Epoch: 628| Step: 0
Training loss: 0.03597920387983322
Validation loss: 1.3637355143024075

Epoch: 6| Step: 1
Training loss: 0.06609372794628143
Validation loss: 1.3595520629677722

Epoch: 6| Step: 2
Training loss: 0.02728841081261635
Validation loss: 1.3464497955896522

Epoch: 6| Step: 3
Training loss: 0.04515302553772926
Validation loss: 1.3378297052075785

Epoch: 6| Step: 4
Training loss: 0.06596587598323822
Validation loss: 1.365802655937851

Epoch: 6| Step: 5
Training loss: 0.04442485794425011
Validation loss: 1.3545706566943918

Epoch: 6| Step: 6
Training loss: 0.05482642352581024
Validation loss: 1.354503269157102

Epoch: 6| Step: 7
Training loss: 0.05983218550682068
Validation loss: 1.3667013465717275

Epoch: 6| Step: 8
Training loss: 0.07643300294876099
Validation loss: 1.3404812973032716

Epoch: 6| Step: 9
Training loss: 0.067251056432724
Validation loss: 1.3459511072404924

Epoch: 6| Step: 10
Training loss: 0.04935324937105179
Validation loss: 1.3509090010837843

Epoch: 6| Step: 11
Training loss: 0.05224776268005371
Validation loss: 1.3417184314420145

Epoch: 6| Step: 12
Training loss: 0.04851238429546356
Validation loss: 1.3425299172760339

Epoch: 6| Step: 13
Training loss: 0.04326419159770012
Validation loss: 1.3409019324087328

Epoch: 629| Step: 0
Training loss: 0.04991115629673004
Validation loss: 1.3546478248411609

Epoch: 6| Step: 1
Training loss: 0.03341296315193176
Validation loss: 1.346809697407548

Epoch: 6| Step: 2
Training loss: 0.030002404004335403
Validation loss: 1.349130343365413

Epoch: 6| Step: 3
Training loss: 0.0796038806438446
Validation loss: 1.3446301914030505

Epoch: 6| Step: 4
Training loss: 0.04723440110683441
Validation loss: 1.360890862762287

Epoch: 6| Step: 5
Training loss: 0.04024259001016617
Validation loss: 1.3441608336664015

Epoch: 6| Step: 6
Training loss: 0.07081209868192673
Validation loss: 1.3411482854556012

Epoch: 6| Step: 7
Training loss: 0.05256277322769165
Validation loss: 1.31892139809106

Epoch: 6| Step: 8
Training loss: 0.05094850808382034
Validation loss: 1.3417220525844122

Epoch: 6| Step: 9
Training loss: 0.049221403896808624
Validation loss: 1.3350940135217482

Epoch: 6| Step: 10
Training loss: 0.06416034698486328
Validation loss: 1.341802465659316

Epoch: 6| Step: 11
Training loss: 0.04560708999633789
Validation loss: 1.3431489339438818

Epoch: 6| Step: 12
Training loss: 0.05618768185377121
Validation loss: 1.3480025190179066

Epoch: 6| Step: 13
Training loss: 0.052908752113580704
Validation loss: 1.3352554203361593

Epoch: 630| Step: 0
Training loss: 0.05540986359119415
Validation loss: 1.357974793962253

Epoch: 6| Step: 1
Training loss: 0.028269708156585693
Validation loss: 1.3344656267473776

Epoch: 6| Step: 2
Training loss: 0.05097191408276558
Validation loss: 1.356720131571575

Epoch: 6| Step: 3
Training loss: 0.05810777097940445
Validation loss: 1.365910671090567

Epoch: 6| Step: 4
Training loss: 0.05903781205415726
Validation loss: 1.3703264465896032

Epoch: 6| Step: 5
Training loss: 0.037169042974710464
Validation loss: 1.3471424284801687

Epoch: 6| Step: 6
Training loss: 0.08068451285362244
Validation loss: 1.3560981917124924

Epoch: 6| Step: 7
Training loss: 0.06250444054603577
Validation loss: 1.3632797848793767

Epoch: 6| Step: 8
Training loss: 0.06892675906419754
Validation loss: 1.3571021755536397

Epoch: 6| Step: 9
Training loss: 0.03816389665007591
Validation loss: 1.3560672037063106

Epoch: 6| Step: 10
Training loss: 0.06584121286869049
Validation loss: 1.3797924557039816

Epoch: 6| Step: 11
Training loss: 0.07352675497531891
Validation loss: 1.3558868060829818

Epoch: 6| Step: 12
Training loss: 0.043206293135881424
Validation loss: 1.3820481934855062

Epoch: 6| Step: 13
Training loss: 0.06198256462812424
Validation loss: 1.3639836593340802

Epoch: 631| Step: 0
Training loss: 0.05831843242049217
Validation loss: 1.3677658445091658

Epoch: 6| Step: 1
Training loss: 0.053117696195840836
Validation loss: 1.3797356403002174

Epoch: 6| Step: 2
Training loss: 0.06820634007453918
Validation loss: 1.3920418395791003

Epoch: 6| Step: 3
Training loss: 0.05525777116417885
Validation loss: 1.3782295783360798

Epoch: 6| Step: 4
Training loss: 0.07300126552581787
Validation loss: 1.3752340161672203

Epoch: 6| Step: 5
Training loss: 0.0650683343410492
Validation loss: 1.3566141461813321

Epoch: 6| Step: 6
Training loss: 0.04652968794107437
Validation loss: 1.3727493862951956

Epoch: 6| Step: 7
Training loss: 0.043786581605672836
Validation loss: 1.3663765986760457

Epoch: 6| Step: 8
Training loss: 0.04727533087134361
Validation loss: 1.3513529364780714

Epoch: 6| Step: 9
Training loss: 0.06219290941953659
Validation loss: 1.3501825717187697

Epoch: 6| Step: 10
Training loss: 0.05971771478652954
Validation loss: 1.3645917395109772

Epoch: 6| Step: 11
Training loss: 0.04962558299303055
Validation loss: 1.3485855953667754

Epoch: 6| Step: 12
Training loss: 0.08247978240251541
Validation loss: 1.357530136262217

Epoch: 6| Step: 13
Training loss: 0.0610492043197155
Validation loss: 1.326714769486458

Epoch: 632| Step: 0
Training loss: 0.039345964789390564
Validation loss: 1.3388656288064935

Epoch: 6| Step: 1
Training loss: 0.050815362483263016
Validation loss: 1.3364682133479784

Epoch: 6| Step: 2
Training loss: 0.05691302567720413
Validation loss: 1.3379290642276886

Epoch: 6| Step: 3
Training loss: 0.048217352479696274
Validation loss: 1.3421914782575382

Epoch: 6| Step: 4
Training loss: 0.04542744159698486
Validation loss: 1.3361466430848645

Epoch: 6| Step: 5
Training loss: 0.04063569754362106
Validation loss: 1.349746819465391

Epoch: 6| Step: 6
Training loss: 0.06015436351299286
Validation loss: 1.3070173942914574

Epoch: 6| Step: 7
Training loss: 0.04330871254205704
Validation loss: 1.3428992161186792

Epoch: 6| Step: 8
Training loss: 0.05613665282726288
Validation loss: 1.350786434065911

Epoch: 6| Step: 9
Training loss: 0.05212651938199997
Validation loss: 1.3641767335194412

Epoch: 6| Step: 10
Training loss: 0.042287763208150864
Validation loss: 1.349545503175387

Epoch: 6| Step: 11
Training loss: 0.05872967466711998
Validation loss: 1.354299004359912

Epoch: 6| Step: 12
Training loss: 0.0651971697807312
Validation loss: 1.3923145173698344

Epoch: 6| Step: 13
Training loss: 0.058855004608631134
Validation loss: 1.3632034864476932

Epoch: 633| Step: 0
Training loss: 0.03419328108429909
Validation loss: 1.3629157363727529

Epoch: 6| Step: 1
Training loss: 0.03703656792640686
Validation loss: 1.3609851765376266

Epoch: 6| Step: 2
Training loss: 0.04083027318120003
Validation loss: 1.367098166096595

Epoch: 6| Step: 3
Training loss: 0.05950911343097687
Validation loss: 1.3596885242769796

Epoch: 6| Step: 4
Training loss: 0.04630842059850693
Validation loss: 1.3495050796898462

Epoch: 6| Step: 5
Training loss: 0.04752776399254799
Validation loss: 1.3536740195366643

Epoch: 6| Step: 6
Training loss: 0.046392861753702164
Validation loss: 1.3396794123034323

Epoch: 6| Step: 7
Training loss: 0.060362499207258224
Validation loss: 1.3426645417367258

Epoch: 6| Step: 8
Training loss: 0.038080524653196335
Validation loss: 1.3547916258535078

Epoch: 6| Step: 9
Training loss: 0.06757058948278427
Validation loss: 1.337914466217

Epoch: 6| Step: 10
Training loss: 0.03741087019443512
Validation loss: 1.3487039375048813

Epoch: 6| Step: 11
Training loss: 0.057124063372612
Validation loss: 1.3372436172218733

Epoch: 6| Step: 12
Training loss: 0.06191515922546387
Validation loss: 1.3425668529284898

Epoch: 6| Step: 13
Training loss: 0.036990270018577576
Validation loss: 1.3549945533916514

Epoch: 634| Step: 0
Training loss: 0.048308804631233215
Validation loss: 1.370316441341113

Epoch: 6| Step: 1
Training loss: 0.05965333431959152
Validation loss: 1.3529382687742992

Epoch: 6| Step: 2
Training loss: 0.05690217763185501
Validation loss: 1.3638695375893706

Epoch: 6| Step: 3
Training loss: 0.05700533092021942
Validation loss: 1.3254134642180575

Epoch: 6| Step: 4
Training loss: 0.07413233816623688
Validation loss: 1.3426998751137846

Epoch: 6| Step: 5
Training loss: 0.04034915193915367
Validation loss: 1.3259298391239618

Epoch: 6| Step: 6
Training loss: 0.03290595859289169
Validation loss: 1.3135929915212816

Epoch: 6| Step: 7
Training loss: 0.058280326426029205
Validation loss: 1.319246966351745

Epoch: 6| Step: 8
Training loss: 0.050120580941438675
Validation loss: 1.3141995911957116

Epoch: 6| Step: 9
Training loss: 0.0853099450469017
Validation loss: 1.309272999404579

Epoch: 6| Step: 10
Training loss: 0.07893086969852448
Validation loss: 1.3035249594719178

Epoch: 6| Step: 11
Training loss: 0.05459663271903992
Validation loss: 1.312346528294266

Epoch: 6| Step: 12
Training loss: 0.05268200486898422
Validation loss: 1.3248123289436422

Epoch: 6| Step: 13
Training loss: 0.06484901905059814
Validation loss: 1.3284901348493432

Epoch: 635| Step: 0
Training loss: 0.08850175142288208
Validation loss: 1.3571053384452738

Epoch: 6| Step: 1
Training loss: 0.050725050270557404
Validation loss: 1.3329008035762335

Epoch: 6| Step: 2
Training loss: 0.04517218470573425
Validation loss: 1.3748465238078948

Epoch: 6| Step: 3
Training loss: 0.03865303099155426
Validation loss: 1.3742943079240861

Epoch: 6| Step: 4
Training loss: 0.047680631279945374
Validation loss: 1.380222543593376

Epoch: 6| Step: 5
Training loss: 0.05150359869003296
Validation loss: 1.3700227775881368

Epoch: 6| Step: 6
Training loss: 0.04477370157837868
Validation loss: 1.3787872342653171

Epoch: 6| Step: 7
Training loss: 0.08586452901363373
Validation loss: 1.372919572296963

Epoch: 6| Step: 8
Training loss: 0.05390823632478714
Validation loss: 1.3649591374140915

Epoch: 6| Step: 9
Training loss: 0.04621767997741699
Validation loss: 1.3839889880149596

Epoch: 6| Step: 10
Training loss: 0.04214806854724884
Validation loss: 1.359865807076936

Epoch: 6| Step: 11
Training loss: 0.05486828088760376
Validation loss: 1.3499499495311449

Epoch: 6| Step: 12
Training loss: 0.056374624371528625
Validation loss: 1.3350604529021888

Epoch: 6| Step: 13
Training loss: 0.08200106024742126
Validation loss: 1.3563506660922882

Epoch: 636| Step: 0
Training loss: 0.0427674874663353
Validation loss: 1.3527854924560876

Epoch: 6| Step: 1
Training loss: 0.04628407955169678
Validation loss: 1.353038340486506

Epoch: 6| Step: 2
Training loss: 0.04565183445811272
Validation loss: 1.3647665067385601

Epoch: 6| Step: 3
Training loss: 0.06243978440761566
Validation loss: 1.3589950402577717

Epoch: 6| Step: 4
Training loss: 0.05234171077609062
Validation loss: 1.344762489359866

Epoch: 6| Step: 5
Training loss: 0.06193871051073074
Validation loss: 1.3642771808050012

Epoch: 6| Step: 6
Training loss: 0.04122426360845566
Validation loss: 1.3946456575906405

Epoch: 6| Step: 7
Training loss: 0.08243288844823837
Validation loss: 1.3966704286554807

Epoch: 6| Step: 8
Training loss: 0.0423937663435936
Validation loss: 1.3701589107513428

Epoch: 6| Step: 9
Training loss: 0.05334576964378357
Validation loss: 1.3875531919540898

Epoch: 6| Step: 10
Training loss: 0.05400615185499191
Validation loss: 1.3946683304284209

Epoch: 6| Step: 11
Training loss: 0.03888062760233879
Validation loss: 1.3869152940729612

Epoch: 6| Step: 12
Training loss: 0.04977433383464813
Validation loss: 1.3819642015682754

Epoch: 6| Step: 13
Training loss: 0.024194061756134033
Validation loss: 1.364255533423475

Epoch: 637| Step: 0
Training loss: 0.0515846349298954
Validation loss: 1.3658438831247308

Epoch: 6| Step: 1
Training loss: 0.04304485395550728
Validation loss: 1.3641547156918434

Epoch: 6| Step: 2
Training loss: 0.0486106276512146
Validation loss: 1.379744056732424

Epoch: 6| Step: 3
Training loss: 0.07637346535921097
Validation loss: 1.3881748312263078

Epoch: 6| Step: 4
Training loss: 0.07795591652393341
Validation loss: 1.393347046708548

Epoch: 6| Step: 5
Training loss: 0.04802795872092247
Validation loss: 1.3880832477282452

Epoch: 6| Step: 6
Training loss: 0.04888905584812164
Validation loss: 1.3788073703806887

Epoch: 6| Step: 7
Training loss: 0.060552775859832764
Validation loss: 1.3910686354483328

Epoch: 6| Step: 8
Training loss: 0.05553172528743744
Validation loss: 1.3869652299470798

Epoch: 6| Step: 9
Training loss: 0.03483060747385025
Validation loss: 1.380481340551889

Epoch: 6| Step: 10
Training loss: 0.0754014328122139
Validation loss: 1.3805148986078077

Epoch: 6| Step: 11
Training loss: 0.03153682500123978
Validation loss: 1.362224184056764

Epoch: 6| Step: 12
Training loss: 0.05289967730641365
Validation loss: 1.3675654280570246

Epoch: 6| Step: 13
Training loss: 0.021529946476221085
Validation loss: 1.3570625435921453

Epoch: 638| Step: 0
Training loss: 0.02148846536874771
Validation loss: 1.3490859539278093

Epoch: 6| Step: 1
Training loss: 0.05100637301802635
Validation loss: 1.359214421241514

Epoch: 6| Step: 2
Training loss: 0.05974327772855759
Validation loss: 1.3655243048103907

Epoch: 6| Step: 3
Training loss: 0.038926512002944946
Validation loss: 1.3604273488444667

Epoch: 6| Step: 4
Training loss: 0.03404541313648224
Validation loss: 1.3469970277560654

Epoch: 6| Step: 5
Training loss: 0.060399167239665985
Validation loss: 1.3511043197365218

Epoch: 6| Step: 6
Training loss: 0.04825573042035103
Validation loss: 1.3763775902409707

Epoch: 6| Step: 7
Training loss: 0.06890954822301865
Validation loss: 1.3626078046778196

Epoch: 6| Step: 8
Training loss: 0.04146970808506012
Validation loss: 1.3594821024966497

Epoch: 6| Step: 9
Training loss: 0.0767158716917038
Validation loss: 1.3643637498219807

Epoch: 6| Step: 10
Training loss: 0.08217563480138779
Validation loss: 1.3565972043621926

Epoch: 6| Step: 11
Training loss: 0.045955412089824677
Validation loss: 1.3587853652174755

Epoch: 6| Step: 12
Training loss: 0.048017699271440506
Validation loss: 1.3427055907505814

Epoch: 6| Step: 13
Training loss: 0.053514786064624786
Validation loss: 1.3488205748219644

Epoch: 639| Step: 0
Training loss: 0.025681370869278908
Validation loss: 1.3274401375042495

Epoch: 6| Step: 1
Training loss: 0.055268995463848114
Validation loss: 1.359514727387377

Epoch: 6| Step: 2
Training loss: 0.04025297611951828
Validation loss: 1.3455916655960904

Epoch: 6| Step: 3
Training loss: 0.024234358221292496
Validation loss: 1.3573235504088863

Epoch: 6| Step: 4
Training loss: 0.061791807413101196
Validation loss: 1.3362860487353416

Epoch: 6| Step: 5
Training loss: 0.06034035608172417
Validation loss: 1.359697276546109

Epoch: 6| Step: 6
Training loss: 0.03216687589883804
Validation loss: 1.3586610671012633

Epoch: 6| Step: 7
Training loss: 0.048910416662693024
Validation loss: 1.3602191055974653

Epoch: 6| Step: 8
Training loss: 0.03150865063071251
Validation loss: 1.3711927039648897

Epoch: 6| Step: 9
Training loss: 0.06826962530612946
Validation loss: 1.37330872525451

Epoch: 6| Step: 10
Training loss: 0.0420844629406929
Validation loss: 1.3681105195835073

Epoch: 6| Step: 11
Training loss: 0.050697386264801025
Validation loss: 1.373572273920941

Epoch: 6| Step: 12
Training loss: 0.02731260471045971
Validation loss: 1.360020088893111

Epoch: 6| Step: 13
Training loss: 0.06289787590503693
Validation loss: 1.347748484662784

Epoch: 640| Step: 0
Training loss: 0.04614231735467911
Validation loss: 1.3625180016281784

Epoch: 6| Step: 1
Training loss: 0.04482252895832062
Validation loss: 1.3687347647964314

Epoch: 6| Step: 2
Training loss: 0.043535299599170685
Validation loss: 1.3726645374810824

Epoch: 6| Step: 3
Training loss: 0.04062601178884506
Validation loss: 1.377648695822685

Epoch: 6| Step: 4
Training loss: 0.03425312042236328
Validation loss: 1.3735696372165476

Epoch: 6| Step: 5
Training loss: 0.04553108662366867
Validation loss: 1.3625582200224682

Epoch: 6| Step: 6
Training loss: 0.02672606147825718
Validation loss: 1.359399954477946

Epoch: 6| Step: 7
Training loss: 0.043356750160455704
Validation loss: 1.358926168052099

Epoch: 6| Step: 8
Training loss: 0.043552517890930176
Validation loss: 1.371218026325267

Epoch: 6| Step: 9
Training loss: 0.08297951519489288
Validation loss: 1.3857454612690916

Epoch: 6| Step: 10
Training loss: 0.06822976469993591
Validation loss: 1.3675853834357312

Epoch: 6| Step: 11
Training loss: 0.03006533905863762
Validation loss: 1.3685888513442008

Epoch: 6| Step: 12
Training loss: 0.04478359594941139
Validation loss: 1.4149498439604236

Epoch: 6| Step: 13
Training loss: 0.052451636642217636
Validation loss: 1.3665169259553314

Epoch: 641| Step: 0
Training loss: 0.031161004677414894
Validation loss: 1.3824721215873637

Epoch: 6| Step: 1
Training loss: 0.07082932442426682
Validation loss: 1.3849200471754997

Epoch: 6| Step: 2
Training loss: 0.03541930019855499
Validation loss: 1.3955497139243669

Epoch: 6| Step: 3
Training loss: 0.028158247470855713
Validation loss: 1.395945918816392

Epoch: 6| Step: 4
Training loss: 0.06698111444711685
Validation loss: 1.376575287952218

Epoch: 6| Step: 5
Training loss: 0.08510999381542206
Validation loss: 1.3966049353281658

Epoch: 6| Step: 6
Training loss: 0.05845478177070618
Validation loss: 1.3860824928488782

Epoch: 6| Step: 7
Training loss: 0.040581993758678436
Validation loss: 1.3858675168406578

Epoch: 6| Step: 8
Training loss: 0.05225890502333641
Validation loss: 1.376916770012148

Epoch: 6| Step: 9
Training loss: 0.05526275187730789
Validation loss: 1.3806623156352709

Epoch: 6| Step: 10
Training loss: 0.05382286012172699
Validation loss: 1.388358986505898

Epoch: 6| Step: 11
Training loss: 0.07814721763134003
Validation loss: 1.3874780760016492

Epoch: 6| Step: 12
Training loss: 0.05627515912055969
Validation loss: 1.3990710871193999

Epoch: 6| Step: 13
Training loss: 0.04772698134183884
Validation loss: 1.3869056868296799

Epoch: 642| Step: 0
Training loss: 0.03265267238020897
Validation loss: 1.3764967956850607

Epoch: 6| Step: 1
Training loss: 0.04925796762108803
Validation loss: 1.4034809572722322

Epoch: 6| Step: 2
Training loss: 0.06031319126486778
Validation loss: 1.367838955053719

Epoch: 6| Step: 3
Training loss: 0.04702337831258774
Validation loss: 1.3933821237215431

Epoch: 6| Step: 4
Training loss: 0.07092227041721344
Validation loss: 1.3869076108419767

Epoch: 6| Step: 5
Training loss: 0.04604046791791916
Validation loss: 1.3689648643616708

Epoch: 6| Step: 6
Training loss: 0.02859586477279663
Validation loss: 1.3814310540435135

Epoch: 6| Step: 7
Training loss: 0.024058053269982338
Validation loss: 1.3842489309208368

Epoch: 6| Step: 8
Training loss: 0.03275081887841225
Validation loss: 1.3873159616224227

Epoch: 6| Step: 9
Training loss: 0.04138011485338211
Validation loss: 1.3867885040980514

Epoch: 6| Step: 10
Training loss: 0.05677753686904907
Validation loss: 1.400752894340023

Epoch: 6| Step: 11
Training loss: 0.06518923491239548
Validation loss: 1.3811668721578454

Epoch: 6| Step: 12
Training loss: 0.06868189573287964
Validation loss: 1.39750220570513

Epoch: 6| Step: 13
Training loss: 0.04157854616641998
Validation loss: 1.3799530357442877

Epoch: 643| Step: 0
Training loss: 0.04357530549168587
Validation loss: 1.3801374909698323

Epoch: 6| Step: 1
Training loss: 0.06844499707221985
Validation loss: 1.3751412053262033

Epoch: 6| Step: 2
Training loss: 0.05783601105213165
Validation loss: 1.3703485265854867

Epoch: 6| Step: 3
Training loss: 0.10849791020154953
Validation loss: 1.3649779058271838

Epoch: 6| Step: 4
Training loss: 0.06112613528966904
Validation loss: 1.3775988086577384

Epoch: 6| Step: 5
Training loss: 0.051999203860759735
Validation loss: 1.367468168658595

Epoch: 6| Step: 6
Training loss: 0.0745890736579895
Validation loss: 1.3764339813622095

Epoch: 6| Step: 7
Training loss: 0.04177433252334595
Validation loss: 1.3763988851219096

Epoch: 6| Step: 8
Training loss: 0.03787866234779358
Validation loss: 1.3837259623312181

Epoch: 6| Step: 9
Training loss: 0.09556837379932404
Validation loss: 1.3728732447470389

Epoch: 6| Step: 10
Training loss: 0.059746820479631424
Validation loss: 1.3775389732853058

Epoch: 6| Step: 11
Training loss: 0.06392806768417358
Validation loss: 1.3721257537923834

Epoch: 6| Step: 12
Training loss: 0.06798581779003143
Validation loss: 1.382226449187084

Epoch: 6| Step: 13
Training loss: 0.08780993521213531
Validation loss: 1.3888727170164867

Epoch: 644| Step: 0
Training loss: 0.050742194056510925
Validation loss: 1.3711107648828977

Epoch: 6| Step: 1
Training loss: 0.035995155572891235
Validation loss: 1.3879334285695066

Epoch: 6| Step: 2
Training loss: 0.06495492160320282
Validation loss: 1.385475379164501

Epoch: 6| Step: 3
Training loss: 0.06647267937660217
Validation loss: 1.3636682501403234

Epoch: 6| Step: 4
Training loss: 0.028062280267477036
Validation loss: 1.3606516007454164

Epoch: 6| Step: 5
Training loss: 0.05488497018814087
Validation loss: 1.355498952250327

Epoch: 6| Step: 6
Training loss: 0.05709492042660713
Validation loss: 1.3598823335862928

Epoch: 6| Step: 7
Training loss: 0.058856237679719925
Validation loss: 1.3632522257425452

Epoch: 6| Step: 8
Training loss: 0.04984802380204201
Validation loss: 1.3655778387541413

Epoch: 6| Step: 9
Training loss: 0.06329283118247986
Validation loss: 1.3584699874283166

Epoch: 6| Step: 10
Training loss: 0.04826761782169342
Validation loss: 1.335124413172404

Epoch: 6| Step: 11
Training loss: 0.055307481437921524
Validation loss: 1.3453766825378581

Epoch: 6| Step: 12
Training loss: 0.06145649403333664
Validation loss: 1.3563852463999102

Epoch: 6| Step: 13
Training loss: 0.04638998210430145
Validation loss: 1.3625283856545725

Epoch: 645| Step: 0
Training loss: 0.06172496825456619
Validation loss: 1.3632862196173718

Epoch: 6| Step: 1
Training loss: 0.06644582748413086
Validation loss: 1.3698476309417396

Epoch: 6| Step: 2
Training loss: 0.1146077886223793
Validation loss: 1.3806342501794138

Epoch: 6| Step: 3
Training loss: 0.08556558191776276
Validation loss: 1.3796977843007734

Epoch: 6| Step: 4
Training loss: 0.06394082307815552
Validation loss: 1.3844587290158836

Epoch: 6| Step: 5
Training loss: 0.06752662360668182
Validation loss: 1.3573827256438553

Epoch: 6| Step: 6
Training loss: 0.04484226554632187
Validation loss: 1.3888575171911588

Epoch: 6| Step: 7
Training loss: 0.04797693341970444
Validation loss: 1.3648381745943459

Epoch: 6| Step: 8
Training loss: 0.06290482729673386
Validation loss: 1.3627261871932654

Epoch: 6| Step: 9
Training loss: 0.0580245703458786
Validation loss: 1.3638295588954803

Epoch: 6| Step: 10
Training loss: 0.057199764996767044
Validation loss: 1.3764038214119532

Epoch: 6| Step: 11
Training loss: 0.05213850736618042
Validation loss: 1.3611996789132395

Epoch: 6| Step: 12
Training loss: 0.04180854558944702
Validation loss: 1.3757300235891854

Epoch: 6| Step: 13
Training loss: 0.0749768391251564
Validation loss: 1.374844665168434

Epoch: 646| Step: 0
Training loss: 0.04781356453895569
Validation loss: 1.380757975321944

Epoch: 6| Step: 1
Training loss: 0.03833456337451935
Validation loss: 1.40249805296621

Epoch: 6| Step: 2
Training loss: 0.05523892119526863
Validation loss: 1.3927606741587322

Epoch: 6| Step: 3
Training loss: 0.03015371784567833
Validation loss: 1.3932978363447293

Epoch: 6| Step: 4
Training loss: 0.0650782510638237
Validation loss: 1.384178687167424

Epoch: 6| Step: 5
Training loss: 0.05832965672016144
Validation loss: 1.3792877927903207

Epoch: 6| Step: 6
Training loss: 0.04376964271068573
Validation loss: 1.3802211541001514

Epoch: 6| Step: 7
Training loss: 0.04703090339899063
Validation loss: 1.370590740634549

Epoch: 6| Step: 8
Training loss: 0.050731316208839417
Validation loss: 1.3612421135748587

Epoch: 6| Step: 9
Training loss: 0.041247449815273285
Validation loss: 1.3701850137402933

Epoch: 6| Step: 10
Training loss: 0.05271439254283905
Validation loss: 1.3825812455146544

Epoch: 6| Step: 11
Training loss: 0.050820037722587585
Validation loss: 1.3504422890242709

Epoch: 6| Step: 12
Training loss: 0.04164322093129158
Validation loss: 1.363452201248497

Epoch: 6| Step: 13
Training loss: 0.07327622920274734
Validation loss: 1.3681514936108743

Epoch: 647| Step: 0
Training loss: 0.04948604106903076
Validation loss: 1.3795795107400546

Epoch: 6| Step: 1
Training loss: 0.08776268362998962
Validation loss: 1.3666882835408694

Epoch: 6| Step: 2
Training loss: 0.05356964096426964
Validation loss: 1.3999575555965464

Epoch: 6| Step: 3
Training loss: 0.039081037044525146
Validation loss: 1.3853163392313066

Epoch: 6| Step: 4
Training loss: 0.05979973077774048
Validation loss: 1.385586824468387

Epoch: 6| Step: 5
Training loss: 0.050933219492435455
Validation loss: 1.3967443422604633

Epoch: 6| Step: 6
Training loss: 0.046815209090709686
Validation loss: 1.3991398138384665

Epoch: 6| Step: 7
Training loss: 0.08463670313358307
Validation loss: 1.3823699156443279

Epoch: 6| Step: 8
Training loss: 0.04331783950328827
Validation loss: 1.3898044773327407

Epoch: 6| Step: 9
Training loss: 0.058428917080163956
Validation loss: 1.388145935150885

Epoch: 6| Step: 10
Training loss: 0.05580417811870575
Validation loss: 1.3790011444399435

Epoch: 6| Step: 11
Training loss: 0.06361008435487747
Validation loss: 1.3878022765600553

Epoch: 6| Step: 12
Training loss: 0.0577547550201416
Validation loss: 1.384413396158526

Epoch: 6| Step: 13
Training loss: 0.06888892501592636
Validation loss: 1.3732269617819017

Epoch: 648| Step: 0
Training loss: 0.051737915724515915
Validation loss: 1.3833086772631573

Epoch: 6| Step: 1
Training loss: 0.04206962510943413
Validation loss: 1.382360222519085

Epoch: 6| Step: 2
Training loss: 0.0465826615691185
Validation loss: 1.373382979823697

Epoch: 6| Step: 3
Training loss: 0.061790402978658676
Validation loss: 1.366082593958865

Epoch: 6| Step: 4
Training loss: 0.05966982990503311
Validation loss: 1.3466330433404574

Epoch: 6| Step: 5
Training loss: 0.06784848123788834
Validation loss: 1.3520744539076281

Epoch: 6| Step: 6
Training loss: 0.04351208731532097
Validation loss: 1.3445248706366426

Epoch: 6| Step: 7
Training loss: 0.04870128631591797
Validation loss: 1.3611557522127706

Epoch: 6| Step: 8
Training loss: 0.06472301483154297
Validation loss: 1.3630397973522064

Epoch: 6| Step: 9
Training loss: 0.06474635004997253
Validation loss: 1.345223412718824

Epoch: 6| Step: 10
Training loss: 0.04647766798734665
Validation loss: 1.3534959298308178

Epoch: 6| Step: 11
Training loss: 0.05707588046789169
Validation loss: 1.3604879404908867

Epoch: 6| Step: 12
Training loss: 0.11162643134593964
Validation loss: 1.3616036074135893

Epoch: 6| Step: 13
Training loss: 0.06093589588999748
Validation loss: 1.3733928101037138

Epoch: 649| Step: 0
Training loss: 0.06112535670399666
Validation loss: 1.3529728208818743

Epoch: 6| Step: 1
Training loss: 0.05917135626077652
Validation loss: 1.359329354378485

Epoch: 6| Step: 2
Training loss: 0.0591961033642292
Validation loss: 1.3533560781068699

Epoch: 6| Step: 3
Training loss: 0.045439429581165314
Validation loss: 1.3340880226704381

Epoch: 6| Step: 4
Training loss: 0.07348629832267761
Validation loss: 1.3152305605590984

Epoch: 6| Step: 5
Training loss: 0.051791876554489136
Validation loss: 1.3256948032686788

Epoch: 6| Step: 6
Training loss: 0.06540497392416
Validation loss: 1.3201197763924957

Epoch: 6| Step: 7
Training loss: 0.034893110394477844
Validation loss: 1.331556220208445

Epoch: 6| Step: 8
Training loss: 0.05266503244638443
Validation loss: 1.352923409913176

Epoch: 6| Step: 9
Training loss: 0.030535882338881493
Validation loss: 1.3258862251876502

Epoch: 6| Step: 10
Training loss: 0.04078337177634239
Validation loss: 1.3462221616057939

Epoch: 6| Step: 11
Training loss: 0.08789411187171936
Validation loss: 1.3357028179271246

Epoch: 6| Step: 12
Training loss: 0.07161322236061096
Validation loss: 1.3545716731779036

Epoch: 6| Step: 13
Training loss: 0.07504627108573914
Validation loss: 1.3613880372816516

Epoch: 650| Step: 0
Training loss: 0.05556025728583336
Validation loss: 1.3545427053205428

Epoch: 6| Step: 1
Training loss: 0.049158789217472076
Validation loss: 1.3746990580712595

Epoch: 6| Step: 2
Training loss: 0.030765350908041
Validation loss: 1.3632784774226527

Epoch: 6| Step: 3
Training loss: 0.04457936808466911
Validation loss: 1.3795016247739074

Epoch: 6| Step: 4
Training loss: 0.0859450101852417
Validation loss: 1.376870725744514

Epoch: 6| Step: 5
Training loss: 0.0697760134935379
Validation loss: 1.3738980113819081

Epoch: 6| Step: 6
Training loss: 0.05793232470750809
Validation loss: 1.3786354962215628

Epoch: 6| Step: 7
Training loss: 0.07202082872390747
Validation loss: 1.3692198209865118

Epoch: 6| Step: 8
Training loss: 0.053614720702171326
Validation loss: 1.3759794312138711

Epoch: 6| Step: 9
Training loss: 0.040847960859537125
Validation loss: 1.3787659034934094

Epoch: 6| Step: 10
Training loss: 0.05446380376815796
Validation loss: 1.3934169494977562

Epoch: 6| Step: 11
Training loss: 0.05627740919589996
Validation loss: 1.403111457824707

Epoch: 6| Step: 12
Training loss: 0.05549804866313934
Validation loss: 1.3829971859532018

Epoch: 6| Step: 13
Training loss: 0.06220291554927826
Validation loss: 1.3756037713378988

Epoch: 651| Step: 0
Training loss: 0.05217871442437172
Validation loss: 1.3899320556271462

Epoch: 6| Step: 1
Training loss: 0.039439305663108826
Validation loss: 1.3861185991635887

Epoch: 6| Step: 2
Training loss: 0.0346984937787056
Validation loss: 1.376981455792663

Epoch: 6| Step: 3
Training loss: 0.050395071506500244
Validation loss: 1.3995517005202591

Epoch: 6| Step: 4
Training loss: 0.039942990988492966
Validation loss: 1.3778656862115348

Epoch: 6| Step: 5
Training loss: 0.035141099244356155
Validation loss: 1.3599900930158553

Epoch: 6| Step: 6
Training loss: 0.06383238732814789
Validation loss: 1.3417843810973629

Epoch: 6| Step: 7
Training loss: 0.05675254017114639
Validation loss: 1.3413677074575936

Epoch: 6| Step: 8
Training loss: 0.046112656593322754
Validation loss: 1.3610432711980676

Epoch: 6| Step: 9
Training loss: 0.03666311502456665
Validation loss: 1.3635219835465955

Epoch: 6| Step: 10
Training loss: 0.03248479962348938
Validation loss: 1.3725217798704743

Epoch: 6| Step: 11
Training loss: 0.06304490566253662
Validation loss: 1.3590302723710255

Epoch: 6| Step: 12
Training loss: 0.07685396820306778
Validation loss: 1.3648786890891291

Epoch: 6| Step: 13
Training loss: 0.06159962713718414
Validation loss: 1.3777896652939499

Epoch: 652| Step: 0
Training loss: 0.06783771514892578
Validation loss: 1.3825669237362441

Epoch: 6| Step: 1
Training loss: 0.036778151988983154
Validation loss: 1.363886466590307

Epoch: 6| Step: 2
Training loss: 0.055262818932533264
Validation loss: 1.3658200226804262

Epoch: 6| Step: 3
Training loss: 0.06425454467535019
Validation loss: 1.3769160252745434

Epoch: 6| Step: 4
Training loss: 0.06798852235078812
Validation loss: 1.3782621032448226

Epoch: 6| Step: 5
Training loss: 0.03883872181177139
Validation loss: 1.3377805486802132

Epoch: 6| Step: 6
Training loss: 0.04635271430015564
Validation loss: 1.349175096839987

Epoch: 6| Step: 7
Training loss: 0.05616023391485214
Validation loss: 1.3512254812384163

Epoch: 6| Step: 8
Training loss: 0.04650308936834335
Validation loss: 1.3278041796017719

Epoch: 6| Step: 9
Training loss: 0.05435264855623245
Validation loss: 1.3274127578222623

Epoch: 6| Step: 10
Training loss: 0.06206032633781433
Validation loss: 1.3145950660910657

Epoch: 6| Step: 11
Training loss: 0.05129281431436539
Validation loss: 1.3194987620076826

Epoch: 6| Step: 12
Training loss: 0.054728858172893524
Validation loss: 1.3302777454417238

Epoch: 6| Step: 13
Training loss: 0.04268131032586098
Validation loss: 1.3067123255422037

Epoch: 653| Step: 0
Training loss: 0.05158182606101036
Validation loss: 1.3306006821252967

Epoch: 6| Step: 1
Training loss: 0.04571818187832832
Validation loss: 1.3057824334790629

Epoch: 6| Step: 2
Training loss: 0.042376402765512466
Validation loss: 1.31738236899017

Epoch: 6| Step: 3
Training loss: 0.037400320172309875
Validation loss: 1.3291083548658638

Epoch: 6| Step: 4
Training loss: 0.03714677691459656
Validation loss: 1.3323049891379573

Epoch: 6| Step: 5
Training loss: 0.04909020662307739
Validation loss: 1.330173251449421

Epoch: 6| Step: 6
Training loss: 0.049865998327732086
Validation loss: 1.3353427084543372

Epoch: 6| Step: 7
Training loss: 0.0702936053276062
Validation loss: 1.3363765401224936

Epoch: 6| Step: 8
Training loss: 0.036467380821704865
Validation loss: 1.3534186988748529

Epoch: 6| Step: 9
Training loss: 0.06991776078939438
Validation loss: 1.3420740776164557

Epoch: 6| Step: 10
Training loss: 0.04081869125366211
Validation loss: 1.341429284823838

Epoch: 6| Step: 11
Training loss: 0.04739756882190704
Validation loss: 1.3528758031065746

Epoch: 6| Step: 12
Training loss: 0.07562761753797531
Validation loss: 1.3612696977071865

Epoch: 6| Step: 13
Training loss: 0.06042014807462692
Validation loss: 1.3601485157525668

Epoch: 654| Step: 0
Training loss: 0.03470267355442047
Validation loss: 1.36855459918258

Epoch: 6| Step: 1
Training loss: 0.05042342096567154
Validation loss: 1.3721450092971965

Epoch: 6| Step: 2
Training loss: 0.04103226214647293
Validation loss: 1.3726657116284935

Epoch: 6| Step: 3
Training loss: 0.036842674016952515
Validation loss: 1.3618120519063805

Epoch: 6| Step: 4
Training loss: 0.04437326639890671
Validation loss: 1.352762496599587

Epoch: 6| Step: 5
Training loss: 0.03525236248970032
Validation loss: 1.3621829728926382

Epoch: 6| Step: 6
Training loss: 0.05102970078587532
Validation loss: 1.3748183981064828

Epoch: 6| Step: 7
Training loss: 0.054651565849781036
Validation loss: 1.344566898961221

Epoch: 6| Step: 8
Training loss: 0.042801208794116974
Validation loss: 1.352602965088301

Epoch: 6| Step: 9
Training loss: 0.047167956829071045
Validation loss: 1.3638699734082786

Epoch: 6| Step: 10
Training loss: 0.028819041326642036
Validation loss: 1.3339372565669398

Epoch: 6| Step: 11
Training loss: 0.0358433723449707
Validation loss: 1.3552642189046389

Epoch: 6| Step: 12
Training loss: 0.029050562530755997
Validation loss: 1.365619541496359

Epoch: 6| Step: 13
Training loss: 0.07335902750492096
Validation loss: 1.36613800192392

Epoch: 655| Step: 0
Training loss: 0.026134192943572998
Validation loss: 1.3594196509289485

Epoch: 6| Step: 1
Training loss: 0.03777827322483063
Validation loss: 1.3609735555546258

Epoch: 6| Step: 2
Training loss: 0.05251370370388031
Validation loss: 1.3542534894840692

Epoch: 6| Step: 3
Training loss: 0.07745952904224396
Validation loss: 1.3515816401409846

Epoch: 6| Step: 4
Training loss: 0.04078629985451698
Validation loss: 1.3664145937529943

Epoch: 6| Step: 5
Training loss: 0.05752391368150711
Validation loss: 1.3674696696701871

Epoch: 6| Step: 6
Training loss: 0.0379275381565094
Validation loss: 1.3452241574564288

Epoch: 6| Step: 7
Training loss: 0.0360286645591259
Validation loss: 1.3554049159890862

Epoch: 6| Step: 8
Training loss: 0.06689761579036713
Validation loss: 1.3527867332581551

Epoch: 6| Step: 9
Training loss: 0.056382402777671814
Validation loss: 1.3613660386813584

Epoch: 6| Step: 10
Training loss: 0.07443694770336151
Validation loss: 1.3638796626880605

Epoch: 6| Step: 11
Training loss: 0.06426691263914108
Validation loss: 1.3910650809605916

Epoch: 6| Step: 12
Training loss: 0.041302330791950226
Validation loss: 1.3663670055327877

Epoch: 6| Step: 13
Training loss: 0.05202198028564453
Validation loss: 1.394989449490783

Epoch: 656| Step: 0
Training loss: 0.06720733642578125
Validation loss: 1.3989239431196643

Epoch: 6| Step: 1
Training loss: 0.07097599655389786
Validation loss: 1.3909992851236814

Epoch: 6| Step: 2
Training loss: 0.03853435069322586
Validation loss: 1.374367820319309

Epoch: 6| Step: 3
Training loss: 0.04387796297669411
Validation loss: 1.3817467715150566

Epoch: 6| Step: 4
Training loss: 0.04675896465778351
Validation loss: 1.3811771920932236

Epoch: 6| Step: 5
Training loss: 0.05040806904435158
Validation loss: 1.3785287141799927

Epoch: 6| Step: 6
Training loss: 0.08266401290893555
Validation loss: 1.3661550296250211

Epoch: 6| Step: 7
Training loss: 0.058869048953056335
Validation loss: 1.3818391228234896

Epoch: 6| Step: 8
Training loss: 0.05234146863222122
Validation loss: 1.375552555566193

Epoch: 6| Step: 9
Training loss: 0.10975844413042068
Validation loss: 1.371617781218662

Epoch: 6| Step: 10
Training loss: 0.0686788260936737
Validation loss: 1.3664199562482937

Epoch: 6| Step: 11
Training loss: 0.07086268812417984
Validation loss: 1.3883734031390118

Epoch: 6| Step: 12
Training loss: 0.07508409023284912
Validation loss: 1.3849638751758042

Epoch: 6| Step: 13
Training loss: 0.04714876785874367
Validation loss: 1.3858261428853518

Epoch: 657| Step: 0
Training loss: 0.046806078404188156
Validation loss: 1.3923692684019766

Epoch: 6| Step: 1
Training loss: 0.08097733557224274
Validation loss: 1.4021945704696

Epoch: 6| Step: 2
Training loss: 0.07069195806980133
Validation loss: 1.4100944265242545

Epoch: 6| Step: 3
Training loss: 0.0663001611828804
Validation loss: 1.403869737860977

Epoch: 6| Step: 4
Training loss: 0.047520507127046585
Validation loss: 1.3950124158654162

Epoch: 6| Step: 5
Training loss: 0.06737059354782104
Validation loss: 1.3814882232296852

Epoch: 6| Step: 6
Training loss: 0.04602053761482239
Validation loss: 1.3635335314658381

Epoch: 6| Step: 7
Training loss: 0.05444931983947754
Validation loss: 1.370871486202363

Epoch: 6| Step: 8
Training loss: 0.08245037496089935
Validation loss: 1.3733817505580124

Epoch: 6| Step: 9
Training loss: 0.05276184156537056
Validation loss: 1.379039925913657

Epoch: 6| Step: 10
Training loss: 0.06789623200893402
Validation loss: 1.3737775382175241

Epoch: 6| Step: 11
Training loss: 0.09232787787914276
Validation loss: 1.3624701820394045

Epoch: 6| Step: 12
Training loss: 0.04413352161645889
Validation loss: 1.3625626820389942

Epoch: 6| Step: 13
Training loss: 0.03431249409914017
Validation loss: 1.369186742331392

Epoch: 658| Step: 0
Training loss: 0.05196299031376839
Validation loss: 1.3913760236514512

Epoch: 6| Step: 1
Training loss: 0.06051189824938774
Validation loss: 1.3903221353407829

Epoch: 6| Step: 2
Training loss: 0.05574957653880119
Validation loss: 1.3911780939307263

Epoch: 6| Step: 3
Training loss: 0.05187541991472244
Validation loss: 1.406210514166022

Epoch: 6| Step: 4
Training loss: 0.044920891523361206
Validation loss: 1.370029762227048

Epoch: 6| Step: 5
Training loss: 0.03775069862604141
Validation loss: 1.3850675282939788

Epoch: 6| Step: 6
Training loss: 0.04266967251896858
Validation loss: 1.3876648423492268

Epoch: 6| Step: 7
Training loss: 0.06399127095937729
Validation loss: 1.377907617758679

Epoch: 6| Step: 8
Training loss: 0.04910847172141075
Validation loss: 1.3692312599510275

Epoch: 6| Step: 9
Training loss: 0.05030268430709839
Validation loss: 1.356565026826756

Epoch: 6| Step: 10
Training loss: 0.056877501308918
Validation loss: 1.3537779623462307

Epoch: 6| Step: 11
Training loss: 0.036269016563892365
Validation loss: 1.3617983595017464

Epoch: 6| Step: 12
Training loss: 0.058715030550956726
Validation loss: 1.3469337929961502

Epoch: 6| Step: 13
Training loss: 0.045249488204717636
Validation loss: 1.3477215074723767

Epoch: 659| Step: 0
Training loss: 0.04639153927564621
Validation loss: 1.3763673779784993

Epoch: 6| Step: 1
Training loss: 0.036046747118234634
Validation loss: 1.3604731559753418

Epoch: 6| Step: 2
Training loss: 0.0479796826839447
Validation loss: 1.359760397224016

Epoch: 6| Step: 3
Training loss: 0.04387668892741203
Validation loss: 1.3599410236522715

Epoch: 6| Step: 4
Training loss: 0.03191369026899338
Validation loss: 1.3661005727706417

Epoch: 6| Step: 5
Training loss: 0.03750791400671005
Validation loss: 1.3618651128584338

Epoch: 6| Step: 6
Training loss: 0.0673629641532898
Validation loss: 1.3500914009668494

Epoch: 6| Step: 7
Training loss: 0.09323152154684067
Validation loss: 1.3695757273704774

Epoch: 6| Step: 8
Training loss: 0.055684156715869904
Validation loss: 1.364721211053992

Epoch: 6| Step: 9
Training loss: 0.04951319098472595
Validation loss: 1.3372656119767057

Epoch: 6| Step: 10
Training loss: 0.06869668513536453
Validation loss: 1.3605021866418983

Epoch: 6| Step: 11
Training loss: 0.055620260536670685
Validation loss: 1.3686441247181227

Epoch: 6| Step: 12
Training loss: 0.07454543560743332
Validation loss: 1.3636555133327362

Epoch: 6| Step: 13
Training loss: 0.04198824241757393
Validation loss: 1.3546538442693732

Epoch: 660| Step: 0
Training loss: 0.03171751648187637
Validation loss: 1.3587546938209123

Epoch: 6| Step: 1
Training loss: 0.02923680655658245
Validation loss: 1.3770933417222833

Epoch: 6| Step: 2
Training loss: 0.051695168018341064
Validation loss: 1.3497683796831357

Epoch: 6| Step: 3
Training loss: 0.05870983749628067
Validation loss: 1.3720652166233267

Epoch: 6| Step: 4
Training loss: 0.05229797214269638
Validation loss: 1.3561317478456805

Epoch: 6| Step: 5
Training loss: 0.06233680993318558
Validation loss: 1.3608967424720846

Epoch: 6| Step: 6
Training loss: 0.05551787465810776
Validation loss: 1.3699157968644173

Epoch: 6| Step: 7
Training loss: 0.056460052728652954
Validation loss: 1.3559979674636677

Epoch: 6| Step: 8
Training loss: 0.04554656147956848
Validation loss: 1.3618009936424993

Epoch: 6| Step: 9
Training loss: 0.0734538584947586
Validation loss: 1.367455704237825

Epoch: 6| Step: 10
Training loss: 0.05734141170978546
Validation loss: 1.3541609177025415

Epoch: 6| Step: 11
Training loss: 0.057357415556907654
Validation loss: 1.3702960219434512

Epoch: 6| Step: 12
Training loss: 0.05584314838051796
Validation loss: 1.3522404938615777

Epoch: 6| Step: 13
Training loss: 0.03942037746310234
Validation loss: 1.3481866390474382

Epoch: 661| Step: 0
Training loss: 0.059833016246557236
Validation loss: 1.3475821031037198

Epoch: 6| Step: 1
Training loss: 0.10426897555589676
Validation loss: 1.3581450728959934

Epoch: 6| Step: 2
Training loss: 0.02982502430677414
Validation loss: 1.3537901229755853

Epoch: 6| Step: 3
Training loss: 0.05649302154779434
Validation loss: 1.35288958139317

Epoch: 6| Step: 4
Training loss: 0.05478428304195404
Validation loss: 1.3702469448889456

Epoch: 6| Step: 5
Training loss: 0.03445567190647125
Validation loss: 1.3601838337477816

Epoch: 6| Step: 6
Training loss: 0.06174936890602112
Validation loss: 1.3504331778454524

Epoch: 6| Step: 7
Training loss: 0.02614230290055275
Validation loss: 1.3587450365866385

Epoch: 6| Step: 8
Training loss: 0.0591377429664135
Validation loss: 1.3499223660397273

Epoch: 6| Step: 9
Training loss: 0.06238101050257683
Validation loss: 1.356739040343992

Epoch: 6| Step: 10
Training loss: 0.041044607758522034
Validation loss: 1.3466617676519579

Epoch: 6| Step: 11
Training loss: 0.04725421965122223
Validation loss: 1.3430116048423193

Epoch: 6| Step: 12
Training loss: 0.04191572591662407
Validation loss: 1.3418508723217955

Epoch: 6| Step: 13
Training loss: 0.04736067354679108
Validation loss: 1.3272703898850309

Epoch: 662| Step: 0
Training loss: 0.04092390090227127
Validation loss: 1.3323360014987249

Epoch: 6| Step: 1
Training loss: 0.04562801867723465
Validation loss: 1.3285700915962138

Epoch: 6| Step: 2
Training loss: 0.04868480563163757
Validation loss: 1.3358449461639568

Epoch: 6| Step: 3
Training loss: 0.043817564845085144
Validation loss: 1.3134988559189664

Epoch: 6| Step: 4
Training loss: 0.051729634404182434
Validation loss: 1.3373994173542145

Epoch: 6| Step: 5
Training loss: 0.05205007269978523
Validation loss: 1.33603032301831

Epoch: 6| Step: 6
Training loss: 0.04958580806851387
Validation loss: 1.3243612640647477

Epoch: 6| Step: 7
Training loss: 0.03858160227537155
Validation loss: 1.3433658358871297

Epoch: 6| Step: 8
Training loss: 0.06667059659957886
Validation loss: 1.349138286805922

Epoch: 6| Step: 9
Training loss: 0.05996027588844299
Validation loss: 1.3472557561371916

Epoch: 6| Step: 10
Training loss: 0.0458206906914711
Validation loss: 1.3381962596729238

Epoch: 6| Step: 11
Training loss: 0.03074970841407776
Validation loss: 1.3488597305872108

Epoch: 6| Step: 12
Training loss: 0.04026734083890915
Validation loss: 1.3500753705219557

Epoch: 6| Step: 13
Training loss: 0.051526203751564026
Validation loss: 1.33270485554972

Epoch: 663| Step: 0
Training loss: 0.02540682628750801
Validation loss: 1.3297157979780627

Epoch: 6| Step: 1
Training loss: 0.031980350613594055
Validation loss: 1.322762800801185

Epoch: 6| Step: 2
Training loss: 0.04048415273427963
Validation loss: 1.342148457804034

Epoch: 6| Step: 3
Training loss: 0.038798343390226364
Validation loss: 1.3397704491051294

Epoch: 6| Step: 4
Training loss: 0.049042485654354095
Validation loss: 1.3399985990216654

Epoch: 6| Step: 5
Training loss: 0.066180519759655
Validation loss: 1.339150519140305

Epoch: 6| Step: 6
Training loss: 0.04038352891802788
Validation loss: 1.3478111079944077

Epoch: 6| Step: 7
Training loss: 0.03861384466290474
Validation loss: 1.3533826489602365

Epoch: 6| Step: 8
Training loss: 0.036423198878765106
Validation loss: 1.363674218936633

Epoch: 6| Step: 9
Training loss: 0.062182556837797165
Validation loss: 1.362465649522761

Epoch: 6| Step: 10
Training loss: 0.06119988113641739
Validation loss: 1.3528218461621193

Epoch: 6| Step: 11
Training loss: 0.07544387876987457
Validation loss: 1.3589820618270545

Epoch: 6| Step: 12
Training loss: 0.06310620158910751
Validation loss: 1.356592164244703

Epoch: 6| Step: 13
Training loss: 0.02183178998529911
Validation loss: 1.3793010160487185

Epoch: 664| Step: 0
Training loss: 0.06149199232459068
Validation loss: 1.3683268498348933

Epoch: 6| Step: 1
Training loss: 0.06908005475997925
Validation loss: 1.3939895668337423

Epoch: 6| Step: 2
Training loss: 0.04348118603229523
Validation loss: 1.367558281908753

Epoch: 6| Step: 3
Training loss: 0.03863052278757095
Validation loss: 1.360708394358235

Epoch: 6| Step: 4
Training loss: 0.05986848473548889
Validation loss: 1.3754902232077815

Epoch: 6| Step: 5
Training loss: 0.0580098032951355
Validation loss: 1.3606173889611357

Epoch: 6| Step: 6
Training loss: 0.06692174822092056
Validation loss: 1.3648760972484466

Epoch: 6| Step: 7
Training loss: 0.04569096863269806
Validation loss: 1.3585499371251752

Epoch: 6| Step: 8
Training loss: 0.051326148211956024
Validation loss: 1.3459182516221078

Epoch: 6| Step: 9
Training loss: 0.029363900423049927
Validation loss: 1.3500912753484582

Epoch: 6| Step: 10
Training loss: 0.06539091467857361
Validation loss: 1.3416644802657507

Epoch: 6| Step: 11
Training loss: 0.0392199382185936
Validation loss: 1.3468632980059552

Epoch: 6| Step: 12
Training loss: 0.05175038054585457
Validation loss: 1.3501972177977204

Epoch: 6| Step: 13
Training loss: 0.07337384670972824
Validation loss: 1.3553344203579811

Epoch: 665| Step: 0
Training loss: 0.04422402381896973
Validation loss: 1.3575093630821473

Epoch: 6| Step: 1
Training loss: 0.04692969471216202
Validation loss: 1.3542288951976325

Epoch: 6| Step: 2
Training loss: 0.028239306062459946
Validation loss: 1.3720739208241945

Epoch: 6| Step: 3
Training loss: 0.040002960711717606
Validation loss: 1.3779396587802517

Epoch: 6| Step: 4
Training loss: 0.03144672513008118
Validation loss: 1.3853463357494724

Epoch: 6| Step: 5
Training loss: 0.030195895582437515
Validation loss: 1.3859270029170538

Epoch: 6| Step: 6
Training loss: 0.06017433851957321
Validation loss: 1.3707568671113701

Epoch: 6| Step: 7
Training loss: 0.03858894854784012
Validation loss: 1.3654240792797459

Epoch: 6| Step: 8
Training loss: 0.039482470601797104
Validation loss: 1.35741279843033

Epoch: 6| Step: 9
Training loss: 0.051494624465703964
Validation loss: 1.356507118030261

Epoch: 6| Step: 10
Training loss: 0.05708841234445572
Validation loss: 1.3558392614446662

Epoch: 6| Step: 11
Training loss: 0.04045170545578003
Validation loss: 1.3520554419486754

Epoch: 6| Step: 12
Training loss: 0.04257877171039581
Validation loss: 1.3550672005581599

Epoch: 6| Step: 13
Training loss: 0.04469955340027809
Validation loss: 1.36046907465945

Epoch: 666| Step: 0
Training loss: 0.03742575645446777
Validation loss: 1.362678050994873

Epoch: 6| Step: 1
Training loss: 0.052151694893836975
Validation loss: 1.3633208915751467

Epoch: 6| Step: 2
Training loss: 0.048349782824516296
Validation loss: 1.369207719320892

Epoch: 6| Step: 3
Training loss: 0.033609434962272644
Validation loss: 1.3844011099107805

Epoch: 6| Step: 4
Training loss: 0.04568660631775856
Validation loss: 1.379685450625676

Epoch: 6| Step: 5
Training loss: 0.0682428702712059
Validation loss: 1.3703060957693285

Epoch: 6| Step: 6
Training loss: 0.05035856366157532
Validation loss: 1.3831486548146894

Epoch: 6| Step: 7
Training loss: 0.06302817910909653
Validation loss: 1.3722317616144817

Epoch: 6| Step: 8
Training loss: 0.04048367962241173
Validation loss: 1.3885315361843313

Epoch: 6| Step: 9
Training loss: 0.05965077877044678
Validation loss: 1.3729686634514922

Epoch: 6| Step: 10
Training loss: 0.04157476872205734
Validation loss: 1.39608621469108

Epoch: 6| Step: 11
Training loss: 0.043808553367853165
Validation loss: 1.3931444767982728

Epoch: 6| Step: 12
Training loss: 0.08098937571048737
Validation loss: 1.3899524577202336

Epoch: 6| Step: 13
Training loss: 0.03394070267677307
Validation loss: 1.4030578315898936

Epoch: 667| Step: 0
Training loss: 0.05578255280852318
Validation loss: 1.4086896578470867

Epoch: 6| Step: 1
Training loss: 0.046028926968574524
Validation loss: 1.3968308612864504

Epoch: 6| Step: 2
Training loss: 0.05679052323102951
Validation loss: 1.3806928921771306

Epoch: 6| Step: 3
Training loss: 0.0435660257935524
Validation loss: 1.394237946438533

Epoch: 6| Step: 4
Training loss: 0.04594115912914276
Validation loss: 1.3808985198697736

Epoch: 6| Step: 5
Training loss: 0.04203014820814133
Validation loss: 1.3893494926473147

Epoch: 6| Step: 6
Training loss: 0.08056249469518661
Validation loss: 1.40200819764086

Epoch: 6| Step: 7
Training loss: 0.032813094556331635
Validation loss: 1.3766486760108703

Epoch: 6| Step: 8
Training loss: 0.045964643359184265
Validation loss: 1.3925089272119666

Epoch: 6| Step: 9
Training loss: 0.04628944396972656
Validation loss: 1.3935241872264492

Epoch: 6| Step: 10
Training loss: 0.039848778396844864
Validation loss: 1.3908575055419758

Epoch: 6| Step: 11
Training loss: 0.0744495838880539
Validation loss: 1.3900411667362336

Epoch: 6| Step: 12
Training loss: 0.04946932941675186
Validation loss: 1.3979279366872643

Epoch: 6| Step: 13
Training loss: 0.05564679205417633
Validation loss: 1.3875320009005967

Epoch: 668| Step: 0
Training loss: 0.04568958282470703
Validation loss: 1.3839460470343148

Epoch: 6| Step: 1
Training loss: 0.06121402978897095
Validation loss: 1.3922660658436437

Epoch: 6| Step: 2
Training loss: 0.045327384024858475
Validation loss: 1.3762256048058952

Epoch: 6| Step: 3
Training loss: 0.06597760319709778
Validation loss: 1.3777043921973116

Epoch: 6| Step: 4
Training loss: 0.03758145868778229
Validation loss: 1.3968795653312438

Epoch: 6| Step: 5
Training loss: 0.04426739737391472
Validation loss: 1.3972936112393615

Epoch: 6| Step: 6
Training loss: 0.05158577114343643
Validation loss: 1.3748089087906705

Epoch: 6| Step: 7
Training loss: 0.05888727307319641
Validation loss: 1.3966690122440297

Epoch: 6| Step: 8
Training loss: 0.03961021080613136
Validation loss: 1.3942573762709094

Epoch: 6| Step: 9
Training loss: 0.10326458513736725
Validation loss: 1.3860889211777718

Epoch: 6| Step: 10
Training loss: 0.035533659160137177
Validation loss: 1.3777631880134664

Epoch: 6| Step: 11
Training loss: 0.04427304118871689
Validation loss: 1.3925117856712752

Epoch: 6| Step: 12
Training loss: 0.05698828771710396
Validation loss: 1.386368574634675

Epoch: 6| Step: 13
Training loss: 0.060269396752119064
Validation loss: 1.3712562207252748

Epoch: 669| Step: 0
Training loss: 0.05117738991975784
Validation loss: 1.3780182257134428

Epoch: 6| Step: 1
Training loss: 0.05351277440786362
Validation loss: 1.3875574584930175

Epoch: 6| Step: 2
Training loss: 0.06327372789382935
Validation loss: 1.3970608236969158

Epoch: 6| Step: 3
Training loss: 0.06257806718349457
Validation loss: 1.3653183060307656

Epoch: 6| Step: 4
Training loss: 0.04121262952685356
Validation loss: 1.3633477322516903

Epoch: 6| Step: 5
Training loss: 0.06117294728755951
Validation loss: 1.3644871429730487

Epoch: 6| Step: 6
Training loss: 0.05217582732439041
Validation loss: 1.3606777626981017

Epoch: 6| Step: 7
Training loss: 0.03548407554626465
Validation loss: 1.359846240730696

Epoch: 6| Step: 8
Training loss: 0.048085566610097885
Validation loss: 1.3690083680614349

Epoch: 6| Step: 9
Training loss: 0.04020658880472183
Validation loss: 1.35002988448707

Epoch: 6| Step: 10
Training loss: 0.07106070220470428
Validation loss: 1.3433343825801727

Epoch: 6| Step: 11
Training loss: 0.047586843371391296
Validation loss: 1.3528086036764166

Epoch: 6| Step: 12
Training loss: 0.04714617505669594
Validation loss: 1.336563979425738

Epoch: 6| Step: 13
Training loss: 0.0870417058467865
Validation loss: 1.3571300660410235

Epoch: 670| Step: 0
Training loss: 0.0607895664870739
Validation loss: 1.35068727308704

Epoch: 6| Step: 1
Training loss: 0.032767802476882935
Validation loss: 1.3646327667338873

Epoch: 6| Step: 2
Training loss: 0.03831209987401962
Validation loss: 1.3521668603343349

Epoch: 6| Step: 3
Training loss: 0.04661940038204193
Validation loss: 1.3737703472055414

Epoch: 6| Step: 4
Training loss: 0.06398849189281464
Validation loss: 1.3630301926725654

Epoch: 6| Step: 5
Training loss: 0.04687879979610443
Validation loss: 1.3777240450664232

Epoch: 6| Step: 6
Training loss: 0.07627738267183304
Validation loss: 1.3722789595204015

Epoch: 6| Step: 7
Training loss: 0.047782666981220245
Validation loss: 1.4008195970648079

Epoch: 6| Step: 8
Training loss: 0.0781000480055809
Validation loss: 1.3967578898194015

Epoch: 6| Step: 9
Training loss: 0.0768192708492279
Validation loss: 1.4032304594593663

Epoch: 6| Step: 10
Training loss: 0.06144999712705612
Validation loss: 1.397773145347513

Epoch: 6| Step: 11
Training loss: 0.07650800794363022
Validation loss: 1.3959402397114744

Epoch: 6| Step: 12
Training loss: 0.0772993266582489
Validation loss: 1.3818407994444653

Epoch: 6| Step: 13
Training loss: 0.0560259148478508
Validation loss: 1.377588015730663

Epoch: 671| Step: 0
Training loss: 0.06787806004285812
Validation loss: 1.3815807373292985

Epoch: 6| Step: 1
Training loss: 0.07674679160118103
Validation loss: 1.3715541849854171

Epoch: 6| Step: 2
Training loss: 0.08285333216190338
Validation loss: 1.3848285213593514

Epoch: 6| Step: 3
Training loss: 0.054133348166942596
Validation loss: 1.4057246126154417

Epoch: 6| Step: 4
Training loss: 0.06937671452760696
Validation loss: 1.3986816957432737

Epoch: 6| Step: 5
Training loss: 0.06493682414293289
Validation loss: 1.373546761851157

Epoch: 6| Step: 6
Training loss: 0.040725890547037125
Validation loss: 1.3680400867615976

Epoch: 6| Step: 7
Training loss: 0.06394866108894348
Validation loss: 1.3626679874235583

Epoch: 6| Step: 8
Training loss: 0.041670337319374084
Validation loss: 1.3648261677834295

Epoch: 6| Step: 9
Training loss: 0.07446682453155518
Validation loss: 1.3687882192673222

Epoch: 6| Step: 10
Training loss: 0.0370558425784111
Validation loss: 1.3582042192900052

Epoch: 6| Step: 11
Training loss: 0.040580783039331436
Validation loss: 1.3304064350743448

Epoch: 6| Step: 12
Training loss: 0.05310414731502533
Validation loss: 1.3579704915323565

Epoch: 6| Step: 13
Training loss: 0.03456290438771248
Validation loss: 1.3484619958426363

Epoch: 672| Step: 0
Training loss: 0.07515045255422592
Validation loss: 1.3429659790890192

Epoch: 6| Step: 1
Training loss: 0.042932067066431046
Validation loss: 1.3389243195133824

Epoch: 6| Step: 2
Training loss: 0.07195406407117844
Validation loss: 1.34431246788271

Epoch: 6| Step: 3
Training loss: 0.04115951806306839
Validation loss: 1.35121952590122

Epoch: 6| Step: 4
Training loss: 0.05527850612998009
Validation loss: 1.3441479526540285

Epoch: 6| Step: 5
Training loss: 0.05807080492377281
Validation loss: 1.3351975205124065

Epoch: 6| Step: 6
Training loss: 0.0567328967154026
Validation loss: 1.3370658582256687

Epoch: 6| Step: 7
Training loss: 0.07028008252382278
Validation loss: 1.3254155407669723

Epoch: 6| Step: 8
Training loss: 0.06285729259252548
Validation loss: 1.3454215590671827

Epoch: 6| Step: 9
Training loss: 0.06672552227973938
Validation loss: 1.3421159072588849

Epoch: 6| Step: 10
Training loss: 0.08599398285150528
Validation loss: 1.348488833314629

Epoch: 6| Step: 11
Training loss: 0.035691309720277786
Validation loss: 1.3518977870223343

Epoch: 6| Step: 12
Training loss: 0.06680095195770264
Validation loss: 1.3602019830416607

Epoch: 6| Step: 13
Training loss: 0.03513385355472565
Validation loss: 1.3691039495570685

Epoch: 673| Step: 0
Training loss: 0.06383276730775833
Validation loss: 1.3879434985499228

Epoch: 6| Step: 1
Training loss: 0.052428923547267914
Validation loss: 1.3969522624887445

Epoch: 6| Step: 2
Training loss: 0.06813229620456696
Validation loss: 1.3916721766994846

Epoch: 6| Step: 3
Training loss: 0.09347501397132874
Validation loss: 1.4103962734181394

Epoch: 6| Step: 4
Training loss: 0.07322528958320618
Validation loss: 1.37992621878142

Epoch: 6| Step: 5
Training loss: 0.040371306240558624
Validation loss: 1.3695315302059214

Epoch: 6| Step: 6
Training loss: 0.0746266320347786
Validation loss: 1.3561586000586068

Epoch: 6| Step: 7
Training loss: 0.04134367033839226
Validation loss: 1.3595667314785782

Epoch: 6| Step: 8
Training loss: 0.038075756281614304
Validation loss: 1.353120767942039

Epoch: 6| Step: 9
Training loss: 0.08042944967746735
Validation loss: 1.3589288175746959

Epoch: 6| Step: 10
Training loss: 0.06978100538253784
Validation loss: 1.3634458966152643

Epoch: 6| Step: 11
Training loss: 0.04797282814979553
Validation loss: 1.3512094860435815

Epoch: 6| Step: 12
Training loss: 0.06253955513238907
Validation loss: 1.3531916231237433

Epoch: 6| Step: 13
Training loss: 0.06298170238733292
Validation loss: 1.3229377961927844

Epoch: 674| Step: 0
Training loss: 0.0670182853937149
Validation loss: 1.3404924113263366

Epoch: 6| Step: 1
Training loss: 0.050910111516714096
Validation loss: 1.3668416712873726

Epoch: 6| Step: 2
Training loss: 0.03382236510515213
Validation loss: 1.3550202538890224

Epoch: 6| Step: 3
Training loss: 0.039745524525642395
Validation loss: 1.3904666208451795

Epoch: 6| Step: 4
Training loss: 0.04834403842687607
Validation loss: 1.3780981020260883

Epoch: 6| Step: 5
Training loss: 0.06200694665312767
Validation loss: 1.3728247047752462

Epoch: 6| Step: 6
Training loss: 0.0360463485121727
Validation loss: 1.3942921905107395

Epoch: 6| Step: 7
Training loss: 0.04243846237659454
Validation loss: 1.3933961647813038

Epoch: 6| Step: 8
Training loss: 0.03908611088991165
Validation loss: 1.4113359092384257

Epoch: 6| Step: 9
Training loss: 0.051740314811468124
Validation loss: 1.3859873099993634

Epoch: 6| Step: 10
Training loss: 0.07492932677268982
Validation loss: 1.4032718366192234

Epoch: 6| Step: 11
Training loss: 0.07315175980329514
Validation loss: 1.4128257766846688

Epoch: 6| Step: 12
Training loss: 0.08253344148397446
Validation loss: 1.4082247403360182

Epoch: 6| Step: 13
Training loss: 0.03301461040973663
Validation loss: 1.4063170866299701

Epoch: 675| Step: 0
Training loss: 0.05422372743487358
Validation loss: 1.3991170900483285

Epoch: 6| Step: 1
Training loss: 0.05014113336801529
Validation loss: 1.4083722176090363

Epoch: 6| Step: 2
Training loss: 0.03852829337120056
Validation loss: 1.4085284939376257

Epoch: 6| Step: 3
Training loss: 0.041757386177778244
Validation loss: 1.4174322966606385

Epoch: 6| Step: 4
Training loss: 0.040523987263441086
Validation loss: 1.406900454592961

Epoch: 6| Step: 5
Training loss: 0.034953292459249496
Validation loss: 1.3905465974602649

Epoch: 6| Step: 6
Training loss: 0.06755331158638
Validation loss: 1.4033855661269157

Epoch: 6| Step: 7
Training loss: 0.04241233319044113
Validation loss: 1.3930228884502123

Epoch: 6| Step: 8
Training loss: 0.062459319829940796
Validation loss: 1.4158552397963822

Epoch: 6| Step: 9
Training loss: 0.07904192060232162
Validation loss: 1.3990132385684597

Epoch: 6| Step: 10
Training loss: 0.03565126657485962
Validation loss: 1.386800807009461

Epoch: 6| Step: 11
Training loss: 0.03595787286758423
Validation loss: 1.3732956160781205

Epoch: 6| Step: 12
Training loss: 0.0474558025598526
Validation loss: 1.3873002721417336

Epoch: 6| Step: 13
Training loss: 0.06904397904872894
Validation loss: 1.383826433971364

Epoch: 676| Step: 0
Training loss: 0.04200492799282074
Validation loss: 1.398834506670634

Epoch: 6| Step: 1
Training loss: 0.06419721245765686
Validation loss: 1.3946222874426073

Epoch: 6| Step: 2
Training loss: 0.043794721364974976
Validation loss: 1.3723554675297072

Epoch: 6| Step: 3
Training loss: 0.05077314004302025
Validation loss: 1.3703147134473246

Epoch: 6| Step: 4
Training loss: 0.027294538915157318
Validation loss: 1.3618820739048783

Epoch: 6| Step: 5
Training loss: 0.03524712473154068
Validation loss: 1.3536698670797451

Epoch: 6| Step: 6
Training loss: 0.03264385089278221
Validation loss: 1.3531942149644256

Epoch: 6| Step: 7
Training loss: 0.08392679691314697
Validation loss: 1.3553718982204315

Epoch: 6| Step: 8
Training loss: 0.051045991480350494
Validation loss: 1.3422173876916208

Epoch: 6| Step: 9
Training loss: 0.06887339055538177
Validation loss: 1.3187788385216908

Epoch: 6| Step: 10
Training loss: 0.04258240759372711
Validation loss: 1.3341384062203028

Epoch: 6| Step: 11
Training loss: 0.04110457003116608
Validation loss: 1.336072890989242

Epoch: 6| Step: 12
Training loss: 0.05603978782892227
Validation loss: 1.3338247909340808

Epoch: 6| Step: 13
Training loss: 0.0714816004037857
Validation loss: 1.3415878729153705

Epoch: 677| Step: 0
Training loss: 0.04603387042880058
Validation loss: 1.3432435348469725

Epoch: 6| Step: 1
Training loss: 0.030857864767313004
Validation loss: 1.3471953484319872

Epoch: 6| Step: 2
Training loss: 0.05705799162387848
Validation loss: 1.3598389420458066

Epoch: 6| Step: 3
Training loss: 0.04089248552918434
Validation loss: 1.3561407628879751

Epoch: 6| Step: 4
Training loss: 0.057238198816776276
Validation loss: 1.343586992192012

Epoch: 6| Step: 5
Training loss: 0.05973631143569946
Validation loss: 1.3520856826536116

Epoch: 6| Step: 6
Training loss: 0.022096656262874603
Validation loss: 1.3549743762580297

Epoch: 6| Step: 7
Training loss: 0.020725026726722717
Validation loss: 1.353989621644379

Epoch: 6| Step: 8
Training loss: 0.0620868094265461
Validation loss: 1.3372671193973993

Epoch: 6| Step: 9
Training loss: 0.0791548639535904
Validation loss: 1.335919217396808

Epoch: 6| Step: 10
Training loss: 0.04601697996258736
Validation loss: 1.3343146097275518

Epoch: 6| Step: 11
Training loss: 0.04227198660373688
Validation loss: 1.328045222707974

Epoch: 6| Step: 12
Training loss: 0.06146400794386864
Validation loss: 1.3428662746183333

Epoch: 6| Step: 13
Training loss: 0.050122786313295364
Validation loss: 1.3215689377118183

Epoch: 678| Step: 0
Training loss: 0.06250423938035965
Validation loss: 1.3260871107860277

Epoch: 6| Step: 1
Training loss: 0.04390298202633858
Validation loss: 1.3280266677179644

Epoch: 6| Step: 2
Training loss: 0.04955117404460907
Validation loss: 1.3201310660249443

Epoch: 6| Step: 3
Training loss: 0.04434029012918472
Validation loss: 1.351948393288479

Epoch: 6| Step: 4
Training loss: 0.035065099596977234
Validation loss: 1.315528146682247

Epoch: 6| Step: 5
Training loss: 0.04920855164527893
Validation loss: 1.312957203516396

Epoch: 6| Step: 6
Training loss: 0.05735388398170471
Validation loss: 1.316455651355046

Epoch: 6| Step: 7
Training loss: 0.06588426232337952
Validation loss: 1.3286362860792427

Epoch: 6| Step: 8
Training loss: 0.05612597614526749
Validation loss: 1.323707733103024

Epoch: 6| Step: 9
Training loss: 0.05354832112789154
Validation loss: 1.3234980208899385

Epoch: 6| Step: 10
Training loss: 0.05791168659925461
Validation loss: 1.3226847110256073

Epoch: 6| Step: 11
Training loss: 0.04443445801734924
Validation loss: 1.3429902817613335

Epoch: 6| Step: 12
Training loss: 0.04340928792953491
Validation loss: 1.3273567768835253

Epoch: 6| Step: 13
Training loss: 0.04691587761044502
Validation loss: 1.3495680478311354

Epoch: 679| Step: 0
Training loss: 0.06958527863025665
Validation loss: 1.3295545629275742

Epoch: 6| Step: 1
Training loss: 0.043075814843177795
Validation loss: 1.3345238386943776

Epoch: 6| Step: 2
Training loss: 0.03980492800474167
Validation loss: 1.3375312025829027

Epoch: 6| Step: 3
Training loss: 0.0355813130736351
Validation loss: 1.3433863110439752

Epoch: 6| Step: 4
Training loss: 0.08327080309391022
Validation loss: 1.3585033775657736

Epoch: 6| Step: 5
Training loss: 0.03035152517259121
Validation loss: 1.3585757722136795

Epoch: 6| Step: 6
Training loss: 0.05318473279476166
Validation loss: 1.3524524332374654

Epoch: 6| Step: 7
Training loss: 0.06342774629592896
Validation loss: 1.3694608890882103

Epoch: 6| Step: 8
Training loss: 0.07485446333885193
Validation loss: 1.3593807015367734

Epoch: 6| Step: 9
Training loss: 0.06826792657375336
Validation loss: 1.3570678298191359

Epoch: 6| Step: 10
Training loss: 0.04388953372836113
Validation loss: 1.3723450283850394

Epoch: 6| Step: 11
Training loss: 0.030125543475151062
Validation loss: 1.3790408449788247

Epoch: 6| Step: 12
Training loss: 0.044347431510686874
Validation loss: 1.3818421748376661

Epoch: 6| Step: 13
Training loss: 0.06411363184452057
Validation loss: 1.3931323007870746

Epoch: 680| Step: 0
Training loss: 0.05871574208140373
Validation loss: 1.3828988946894163

Epoch: 6| Step: 1
Training loss: 0.05721275135874748
Validation loss: 1.4067468104823944

Epoch: 6| Step: 2
Training loss: 0.03311125934123993
Validation loss: 1.3830527849094842

Epoch: 6| Step: 3
Training loss: 0.02478584088385105
Validation loss: 1.3970746801745506

Epoch: 6| Step: 4
Training loss: 0.03538290411233902
Validation loss: 1.4185373578020322

Epoch: 6| Step: 5
Training loss: 0.060006074607372284
Validation loss: 1.3978062945027505

Epoch: 6| Step: 6
Training loss: 0.059452250599861145
Validation loss: 1.3922840677281862

Epoch: 6| Step: 7
Training loss: 0.04135264456272125
Validation loss: 1.3833931517857376

Epoch: 6| Step: 8
Training loss: 0.03698953241109848
Validation loss: 1.4010980706061087

Epoch: 6| Step: 9
Training loss: 0.043417371809482574
Validation loss: 1.3862809135067848

Epoch: 6| Step: 10
Training loss: 0.050518348813056946
Validation loss: 1.384467767130944

Epoch: 6| Step: 11
Training loss: 0.0551053062081337
Validation loss: 1.3814847546239053

Epoch: 6| Step: 12
Training loss: 0.051192447543144226
Validation loss: 1.3674745521237772

Epoch: 6| Step: 13
Training loss: 0.05300254374742508
Validation loss: 1.3890967445988809

Epoch: 681| Step: 0
Training loss: 0.052001893520355225
Validation loss: 1.3556806496394578

Epoch: 6| Step: 1
Training loss: 0.0584353506565094
Validation loss: 1.3563940153327039

Epoch: 6| Step: 2
Training loss: 0.027887549251317978
Validation loss: 1.3678824940035421

Epoch: 6| Step: 3
Training loss: 0.06225898861885071
Validation loss: 1.3609705612223635

Epoch: 6| Step: 4
Training loss: 0.04413094371557236
Validation loss: 1.3542057647499988

Epoch: 6| Step: 5
Training loss: 0.04270097613334656
Validation loss: 1.3581303960533553

Epoch: 6| Step: 6
Training loss: 0.06870423257350922
Validation loss: 1.3878222537297074

Epoch: 6| Step: 7
Training loss: 0.041707344353199005
Validation loss: 1.3797812384943808

Epoch: 6| Step: 8
Training loss: 0.040638215839862823
Validation loss: 1.3680166191952203

Epoch: 6| Step: 9
Training loss: 0.04334777593612671
Validation loss: 1.357554051183885

Epoch: 6| Step: 10
Training loss: 0.030899830162525177
Validation loss: 1.3795396345917896

Epoch: 6| Step: 11
Training loss: 0.05059169605374336
Validation loss: 1.3695328389444659

Epoch: 6| Step: 12
Training loss: 0.02537730522453785
Validation loss: 1.3707922402248587

Epoch: 6| Step: 13
Training loss: 0.027506284415721893
Validation loss: 1.361353196764505

Epoch: 682| Step: 0
Training loss: 0.047045040875673294
Validation loss: 1.3563371755743538

Epoch: 6| Step: 1
Training loss: 0.04738016799092293
Validation loss: 1.36898583878753

Epoch: 6| Step: 2
Training loss: 0.025093019008636475
Validation loss: 1.363594690958659

Epoch: 6| Step: 3
Training loss: 0.04432425647974014
Validation loss: 1.3604528109232585

Epoch: 6| Step: 4
Training loss: 0.07332360744476318
Validation loss: 1.3567891069637832

Epoch: 6| Step: 5
Training loss: 0.047987084835767746
Validation loss: 1.3753414705235472

Epoch: 6| Step: 6
Training loss: 0.04749288409948349
Validation loss: 1.3754281523407146

Epoch: 6| Step: 7
Training loss: 0.05595839396119118
Validation loss: 1.3712202169561898

Epoch: 6| Step: 8
Training loss: 0.04390557110309601
Validation loss: 1.3617975609276884

Epoch: 6| Step: 9
Training loss: 0.0562647208571434
Validation loss: 1.36019774406187

Epoch: 6| Step: 10
Training loss: 0.03594415634870529
Validation loss: 1.3741110121050188

Epoch: 6| Step: 11
Training loss: 0.03599021956324577
Validation loss: 1.3728261250321583

Epoch: 6| Step: 12
Training loss: 0.03855638951063156
Validation loss: 1.389688402093867

Epoch: 6| Step: 13
Training loss: 0.03798297420144081
Validation loss: 1.4012078700527069

Epoch: 683| Step: 0
Training loss: 0.030153393745422363
Validation loss: 1.3893708900738788

Epoch: 6| Step: 1
Training loss: 0.039936065673828125
Validation loss: 1.375337032861607

Epoch: 6| Step: 2
Training loss: 0.03617817908525467
Validation loss: 1.3989572012296287

Epoch: 6| Step: 3
Training loss: 0.03738166764378548
Validation loss: 1.3847578187142648

Epoch: 6| Step: 4
Training loss: 0.07725738734006882
Validation loss: 1.3902283458299534

Epoch: 6| Step: 5
Training loss: 0.04221131652593613
Validation loss: 1.3765020588392853

Epoch: 6| Step: 6
Training loss: 0.04851265251636505
Validation loss: 1.3859600431175643

Epoch: 6| Step: 7
Training loss: 0.032407864928245544
Validation loss: 1.3775152999867675

Epoch: 6| Step: 8
Training loss: 0.05157456547021866
Validation loss: 1.3739711770447351

Epoch: 6| Step: 9
Training loss: 0.030890755355358124
Validation loss: 1.377218763033549

Epoch: 6| Step: 10
Training loss: 0.035978689789772034
Validation loss: 1.3812458322894188

Epoch: 6| Step: 11
Training loss: 0.04005691409111023
Validation loss: 1.3577638479971117

Epoch: 6| Step: 12
Training loss: 0.03541097790002823
Validation loss: 1.3615817639135546

Epoch: 6| Step: 13
Training loss: 0.060247473418712616
Validation loss: 1.372052393933778

Epoch: 684| Step: 0
Training loss: 0.04143942520022392
Validation loss: 1.3723715530928744

Epoch: 6| Step: 1
Training loss: 0.049090757966041565
Validation loss: 1.3784967994177213

Epoch: 6| Step: 2
Training loss: 0.062314487993717194
Validation loss: 1.3918891760610765

Epoch: 6| Step: 3
Training loss: 0.04885627329349518
Validation loss: 1.390839768353329

Epoch: 6| Step: 4
Training loss: 0.06917592138051987
Validation loss: 1.3815353852446361

Epoch: 6| Step: 5
Training loss: 0.053660161793231964
Validation loss: 1.3726875769194735

Epoch: 6| Step: 6
Training loss: 0.04894927144050598
Validation loss: 1.3781738345341017

Epoch: 6| Step: 7
Training loss: 0.061419375240802765
Validation loss: 1.3730629272358392

Epoch: 6| Step: 8
Training loss: 0.0778435617685318
Validation loss: 1.3698126052015571

Epoch: 6| Step: 9
Training loss: 0.0464690700173378
Validation loss: 1.3635650950093423

Epoch: 6| Step: 10
Training loss: 0.04418319836258888
Validation loss: 1.3421331028784476

Epoch: 6| Step: 11
Training loss: 0.0780220478773117
Validation loss: 1.3446645582875898

Epoch: 6| Step: 12
Training loss: 0.0501786544919014
Validation loss: 1.3462945312582038

Epoch: 6| Step: 13
Training loss: 0.06182050704956055
Validation loss: 1.3364938971816853

Epoch: 685| Step: 0
Training loss: 0.08483000844717026
Validation loss: 1.3571124935662875

Epoch: 6| Step: 1
Training loss: 0.04129672795534134
Validation loss: 1.35893387691949

Epoch: 6| Step: 2
Training loss: 0.03288809210062027
Validation loss: 1.3679576657151664

Epoch: 6| Step: 3
Training loss: 0.031508516520261765
Validation loss: 1.3494980540326846

Epoch: 6| Step: 4
Training loss: 0.05249454453587532
Validation loss: 1.364828021295609

Epoch: 6| Step: 5
Training loss: 0.10530100762844086
Validation loss: 1.377826085654638

Epoch: 6| Step: 6
Training loss: 0.08339011669158936
Validation loss: 1.3842954943256993

Epoch: 6| Step: 7
Training loss: 0.04636843502521515
Validation loss: 1.3843794189473635

Epoch: 6| Step: 8
Training loss: 0.053354211151599884
Validation loss: 1.370519550897742

Epoch: 6| Step: 9
Training loss: 0.05120883882045746
Validation loss: 1.3806608120600383

Epoch: 6| Step: 10
Training loss: 0.061142534017562866
Validation loss: 1.371752110860681

Epoch: 6| Step: 11
Training loss: 0.06094083935022354
Validation loss: 1.362121396167304

Epoch: 6| Step: 12
Training loss: 0.06345362961292267
Validation loss: 1.3620170521479782

Epoch: 6| Step: 13
Training loss: 0.0745600163936615
Validation loss: 1.3781450307497414

Epoch: 686| Step: 0
Training loss: 0.05122561752796173
Validation loss: 1.39406664909855

Epoch: 6| Step: 1
Training loss: 0.03787809610366821
Validation loss: 1.3704636225136377

Epoch: 6| Step: 2
Training loss: 0.0631861463189125
Validation loss: 1.3521852634286369

Epoch: 6| Step: 3
Training loss: 0.058460257947444916
Validation loss: 1.3617200313075897

Epoch: 6| Step: 4
Training loss: 0.0641414225101471
Validation loss: 1.360374822411486

Epoch: 6| Step: 5
Training loss: 0.06621724367141724
Validation loss: 1.3571525575012289

Epoch: 6| Step: 6
Training loss: 0.050498053431510925
Validation loss: 1.3370666484678946

Epoch: 6| Step: 7
Training loss: 0.03241296112537384
Validation loss: 1.3717237582770727

Epoch: 6| Step: 8
Training loss: 0.03119829297065735
Validation loss: 1.3640651472153202

Epoch: 6| Step: 9
Training loss: 0.0640019029378891
Validation loss: 1.36463523808346

Epoch: 6| Step: 10
Training loss: 0.07405460625886917
Validation loss: 1.349022506385721

Epoch: 6| Step: 11
Training loss: 0.04905249923467636
Validation loss: 1.36432485811172

Epoch: 6| Step: 12
Training loss: 0.037451066076755524
Validation loss: 1.3621874387546251

Epoch: 6| Step: 13
Training loss: 0.04459621012210846
Validation loss: 1.3468539996813702

Epoch: 687| Step: 0
Training loss: 0.05544973909854889
Validation loss: 1.3588112560651635

Epoch: 6| Step: 1
Training loss: 0.05424116551876068
Validation loss: 1.3592777072742421

Epoch: 6| Step: 2
Training loss: 0.030360501259565353
Validation loss: 1.3341438308838875

Epoch: 6| Step: 3
Training loss: 0.03685494884848595
Validation loss: 1.3514062582805593

Epoch: 6| Step: 4
Training loss: 0.05245211720466614
Validation loss: 1.3304834596572384

Epoch: 6| Step: 5
Training loss: 0.043542005121707916
Validation loss: 1.3236368413894408

Epoch: 6| Step: 6
Training loss: 0.07779198884963989
Validation loss: 1.322927636484946

Epoch: 6| Step: 7
Training loss: 0.0345434695482254
Validation loss: 1.3427515696453791

Epoch: 6| Step: 8
Training loss: 0.06300990283489227
Validation loss: 1.326924430426731

Epoch: 6| Step: 9
Training loss: 0.07034771889448166
Validation loss: 1.3475096353920557

Epoch: 6| Step: 10
Training loss: 0.09252863377332687
Validation loss: 1.3445121716427546

Epoch: 6| Step: 11
Training loss: 0.03602563589811325
Validation loss: 1.354139631794345

Epoch: 6| Step: 12
Training loss: 0.09979253262281418
Validation loss: 1.3632969689625565

Epoch: 6| Step: 13
Training loss: 0.05734480917453766
Validation loss: 1.3422703858344787

Epoch: 688| Step: 0
Training loss: 0.045892082154750824
Validation loss: 1.367076907106625

Epoch: 6| Step: 1
Training loss: 0.0562153123319149
Validation loss: 1.3685499801430652

Epoch: 6| Step: 2
Training loss: 0.044170644134283066
Validation loss: 1.3863213575014504

Epoch: 6| Step: 3
Training loss: 0.05280466750264168
Validation loss: 1.3923637790064658

Epoch: 6| Step: 4
Training loss: 0.06732769310474396
Validation loss: 1.4025511869820215

Epoch: 6| Step: 5
Training loss: 0.09081276506185532
Validation loss: 1.4028966708849835

Epoch: 6| Step: 6
Training loss: 0.05179373174905777
Validation loss: 1.3942519182799964

Epoch: 6| Step: 7
Training loss: 0.049438752233982086
Validation loss: 1.3786524989271676

Epoch: 6| Step: 8
Training loss: 0.04146989807486534
Validation loss: 1.3753914179340485

Epoch: 6| Step: 9
Training loss: 0.05126513913273811
Validation loss: 1.3818976174118698

Epoch: 6| Step: 10
Training loss: 0.03942941874265671
Validation loss: 1.3686709416809903

Epoch: 6| Step: 11
Training loss: 0.037350982427597046
Validation loss: 1.3853589347613755

Epoch: 6| Step: 12
Training loss: 0.04281877726316452
Validation loss: 1.3783058402358845

Epoch: 6| Step: 13
Training loss: 0.07880386710166931
Validation loss: 1.3759785057396017

Epoch: 689| Step: 0
Training loss: 0.0425974577665329
Validation loss: 1.3840934025344027

Epoch: 6| Step: 1
Training loss: 0.046076640486717224
Validation loss: 1.3801910313226844

Epoch: 6| Step: 2
Training loss: 0.03173074126243591
Validation loss: 1.3616576246035996

Epoch: 6| Step: 3
Training loss: 0.07470577955245972
Validation loss: 1.3727016154155935

Epoch: 6| Step: 4
Training loss: 0.06178164854645729
Validation loss: 1.3512045606490104

Epoch: 6| Step: 5
Training loss: 0.044935449957847595
Validation loss: 1.3433989427422965

Epoch: 6| Step: 6
Training loss: 0.06400986015796661
Validation loss: 1.3487476777004939

Epoch: 6| Step: 7
Training loss: 0.048878639936447144
Validation loss: 1.3499097952278711

Epoch: 6| Step: 8
Training loss: 0.08189956843852997
Validation loss: 1.343627465668545

Epoch: 6| Step: 9
Training loss: 0.06728013604879379
Validation loss: 1.3573906216570126

Epoch: 6| Step: 10
Training loss: 0.041120000183582306
Validation loss: 1.3782060915423977

Epoch: 6| Step: 11
Training loss: 0.06221938878297806
Validation loss: 1.3764103151136828

Epoch: 6| Step: 12
Training loss: 0.0503927506506443
Validation loss: 1.358290180083244

Epoch: 6| Step: 13
Training loss: 0.0838758572936058
Validation loss: 1.3685685152648597

Epoch: 690| Step: 0
Training loss: 0.04475846141576767
Validation loss: 1.3581655410028273

Epoch: 6| Step: 1
Training loss: 0.055225174874067307
Validation loss: 1.3831564931459324

Epoch: 6| Step: 2
Training loss: 0.05595540255308151
Validation loss: 1.3777131297255074

Epoch: 6| Step: 3
Training loss: 0.05044745281338692
Validation loss: 1.381641613539829

Epoch: 6| Step: 4
Training loss: 0.03326552361249924
Validation loss: 1.3664367263035109

Epoch: 6| Step: 5
Training loss: 0.0563020184636116
Validation loss: 1.3866568252604494

Epoch: 6| Step: 6
Training loss: 0.04267615079879761
Validation loss: 1.3727873871403355

Epoch: 6| Step: 7
Training loss: 0.05710524320602417
Validation loss: 1.3625159917339202

Epoch: 6| Step: 8
Training loss: 0.05608031898736954
Validation loss: 1.3669451853280425

Epoch: 6| Step: 9
Training loss: 0.05924041196703911
Validation loss: 1.355703443609258

Epoch: 6| Step: 10
Training loss: 0.05739276111125946
Validation loss: 1.3504880102731849

Epoch: 6| Step: 11
Training loss: 0.045582354068756104
Validation loss: 1.3491484375410183

Epoch: 6| Step: 12
Training loss: 0.06704016029834747
Validation loss: 1.3343241624934699

Epoch: 6| Step: 13
Training loss: 0.07776942849159241
Validation loss: 1.3164052104437223

Epoch: 691| Step: 0
Training loss: 0.020396092906594276
Validation loss: 1.334564721712502

Epoch: 6| Step: 1
Training loss: 0.07332111895084381
Validation loss: 1.3382391532262166

Epoch: 6| Step: 2
Training loss: 0.055255889892578125
Validation loss: 1.3509724832350207

Epoch: 6| Step: 3
Training loss: 0.05972526967525482
Validation loss: 1.365621942345814

Epoch: 6| Step: 4
Training loss: 0.04920224845409393
Validation loss: 1.3648240066343738

Epoch: 6| Step: 5
Training loss: 0.04317309707403183
Validation loss: 1.3674419682513002

Epoch: 6| Step: 6
Training loss: 0.04687328636646271
Validation loss: 1.3860319276009836

Epoch: 6| Step: 7
Training loss: 0.045109305530786514
Validation loss: 1.373325595291712

Epoch: 6| Step: 8
Training loss: 0.04030393064022064
Validation loss: 1.37629029058641

Epoch: 6| Step: 9
Training loss: 0.04355326294898987
Validation loss: 1.3701513326296242

Epoch: 6| Step: 10
Training loss: 0.036086153239011765
Validation loss: 1.3723256895619054

Epoch: 6| Step: 11
Training loss: 0.07381835579872131
Validation loss: 1.3675860615186795

Epoch: 6| Step: 12
Training loss: 0.06827991455793381
Validation loss: 1.3684605321576517

Epoch: 6| Step: 13
Training loss: 0.051015179604291916
Validation loss: 1.3676280924068984

Epoch: 692| Step: 0
Training loss: 0.06596562266349792
Validation loss: 1.378134314731885

Epoch: 6| Step: 1
Training loss: 0.049118977040052414
Validation loss: 1.3862668750106648

Epoch: 6| Step: 2
Training loss: 0.044371020048856735
Validation loss: 1.3732233380758634

Epoch: 6| Step: 3
Training loss: 0.05185778811573982
Validation loss: 1.3834229669263285

Epoch: 6| Step: 4
Training loss: 0.0587434358894825
Validation loss: 1.3751865971472956

Epoch: 6| Step: 5
Training loss: 0.04075455293059349
Validation loss: 1.3782655808233446

Epoch: 6| Step: 6
Training loss: 0.04199744760990143
Validation loss: 1.3828863751503728

Epoch: 6| Step: 7
Training loss: 0.04137319326400757
Validation loss: 1.3848023171065955

Epoch: 6| Step: 8
Training loss: 0.03418869525194168
Validation loss: 1.3681080879703644

Epoch: 6| Step: 9
Training loss: 0.044296324253082275
Validation loss: 1.368519979138528

Epoch: 6| Step: 10
Training loss: 0.05522247403860092
Validation loss: 1.3478001561216129

Epoch: 6| Step: 11
Training loss: 0.03683236986398697
Validation loss: 1.358946414404018

Epoch: 6| Step: 12
Training loss: 0.04648258537054062
Validation loss: 1.3669800963453067

Epoch: 6| Step: 13
Training loss: 0.05724700167775154
Validation loss: 1.3670137325922649

Epoch: 693| Step: 0
Training loss: 0.04422254115343094
Validation loss: 1.3508533329092047

Epoch: 6| Step: 1
Training loss: 0.041610874235630035
Validation loss: 1.3466652144667923

Epoch: 6| Step: 2
Training loss: 0.03646570444107056
Validation loss: 1.3704360082585325

Epoch: 6| Step: 3
Training loss: 0.04448970407247543
Validation loss: 1.360308999656349

Epoch: 6| Step: 4
Training loss: 0.045828018337488174
Validation loss: 1.3773713919424242

Epoch: 6| Step: 5
Training loss: 0.046102024614810944
Validation loss: 1.3652530344583655

Epoch: 6| Step: 6
Training loss: 0.044229134917259216
Validation loss: 1.3621775937336746

Epoch: 6| Step: 7
Training loss: 0.03696241229772568
Validation loss: 1.3443210740243234

Epoch: 6| Step: 8
Training loss: 0.02636607736349106
Validation loss: 1.341806814234744

Epoch: 6| Step: 9
Training loss: 0.08245468139648438
Validation loss: 1.325256424565469

Epoch: 6| Step: 10
Training loss: 0.06169833615422249
Validation loss: 1.3352911023683445

Epoch: 6| Step: 11
Training loss: 0.048702433705329895
Validation loss: 1.3300872371401837

Epoch: 6| Step: 12
Training loss: 0.04512222111225128
Validation loss: 1.3453674188224218

Epoch: 6| Step: 13
Training loss: 0.019401073455810547
Validation loss: 1.3545277246864893

Epoch: 694| Step: 0
Training loss: 0.04864501953125
Validation loss: 1.3558609921445128

Epoch: 6| Step: 1
Training loss: 0.06486879289150238
Validation loss: 1.3619749007686492

Epoch: 6| Step: 2
Training loss: 0.03646630421280861
Validation loss: 1.3552513058467577

Epoch: 6| Step: 3
Training loss: 0.05159439891576767
Validation loss: 1.3957507802594094

Epoch: 6| Step: 4
Training loss: 0.04604409635066986
Validation loss: 1.3705574222790298

Epoch: 6| Step: 5
Training loss: 0.060507431626319885
Validation loss: 1.3714589905995194

Epoch: 6| Step: 6
Training loss: 0.05729761719703674
Validation loss: 1.3753035517149075

Epoch: 6| Step: 7
Training loss: 0.034792423248291016
Validation loss: 1.3603598251137683

Epoch: 6| Step: 8
Training loss: 0.08187538385391235
Validation loss: 1.3801175907093992

Epoch: 6| Step: 9
Training loss: 0.1585409939289093
Validation loss: 1.379211848781955

Epoch: 6| Step: 10
Training loss: 0.05283844470977783
Validation loss: 1.3496728879149242

Epoch: 6| Step: 11
Training loss: 0.03958921134471893
Validation loss: 1.3471622069676716

Epoch: 6| Step: 12
Training loss: 0.0448874831199646
Validation loss: 1.369699534549508

Epoch: 6| Step: 13
Training loss: 0.038233682513237
Validation loss: 1.355053977299762

Epoch: 695| Step: 0
Training loss: 0.0469600185751915
Validation loss: 1.353672291642876

Epoch: 6| Step: 1
Training loss: 0.054135724902153015
Validation loss: 1.3344224306844896

Epoch: 6| Step: 2
Training loss: 0.09364980459213257
Validation loss: 1.3376649451512161

Epoch: 6| Step: 3
Training loss: 0.07262854278087616
Validation loss: 1.330147966261833

Epoch: 6| Step: 4
Training loss: 0.046174533665180206
Validation loss: 1.3345648107990142

Epoch: 6| Step: 5
Training loss: 0.04945036768913269
Validation loss: 1.336832433618525

Epoch: 6| Step: 6
Training loss: 0.033861950039863586
Validation loss: 1.3240918933704335

Epoch: 6| Step: 7
Training loss: 0.05135824531316757
Validation loss: 1.3470051442423174

Epoch: 6| Step: 8
Training loss: 0.04342592507600784
Validation loss: 1.3561591332958591

Epoch: 6| Step: 9
Training loss: 0.02468450739979744
Validation loss: 1.3576905394113192

Epoch: 6| Step: 10
Training loss: 0.06744837015867233
Validation loss: 1.3511012331131966

Epoch: 6| Step: 11
Training loss: 0.09162287414073944
Validation loss: 1.3590754783281715

Epoch: 6| Step: 12
Training loss: 0.04734782874584198
Validation loss: 1.371328494882071

Epoch: 6| Step: 13
Training loss: 0.12279171496629715
Validation loss: 1.389908234278361

Epoch: 696| Step: 0
Training loss: 0.04532148316502571
Validation loss: 1.3751461493071688

Epoch: 6| Step: 1
Training loss: 0.032800234854221344
Validation loss: 1.387926055539039

Epoch: 6| Step: 2
Training loss: 0.039504274725914
Validation loss: 1.3726409981327672

Epoch: 6| Step: 3
Training loss: 0.030540000647306442
Validation loss: 1.349611702785697

Epoch: 6| Step: 4
Training loss: 0.09137389063835144
Validation loss: 1.3668830176835418

Epoch: 6| Step: 5
Training loss: 0.054746247828006744
Validation loss: 1.3594650799228298

Epoch: 6| Step: 6
Training loss: 0.11171568930149078
Validation loss: 1.336684351326317

Epoch: 6| Step: 7
Training loss: 0.05964452028274536
Validation loss: 1.3326091586902578

Epoch: 6| Step: 8
Training loss: 0.04362238943576813
Validation loss: 1.337820396628431

Epoch: 6| Step: 9
Training loss: 0.06400526314973831
Validation loss: 1.346417478335801

Epoch: 6| Step: 10
Training loss: 0.07088615000247955
Validation loss: 1.3531247588895983

Epoch: 6| Step: 11
Training loss: 0.04066033661365509
Validation loss: 1.370399458433992

Epoch: 6| Step: 12
Training loss: 0.05013372376561165
Validation loss: 1.3656685967599191

Epoch: 6| Step: 13
Training loss: 0.034444939345121384
Validation loss: 1.3600990926065752

Epoch: 697| Step: 0
Training loss: 0.05485020577907562
Validation loss: 1.3658086638296805

Epoch: 6| Step: 1
Training loss: 0.1234729215502739
Validation loss: 1.3587352665521766

Epoch: 6| Step: 2
Training loss: 0.07180671393871307
Validation loss: 1.3767806663308093

Epoch: 6| Step: 3
Training loss: 0.09797994792461395
Validation loss: 1.3721444734963038

Epoch: 6| Step: 4
Training loss: 0.09722290933132172
Validation loss: 1.3610308054954774

Epoch: 6| Step: 5
Training loss: 0.051860786974430084
Validation loss: 1.369203250254354

Epoch: 6| Step: 6
Training loss: 0.08644381165504456
Validation loss: 1.3569863598833802

Epoch: 6| Step: 7
Training loss: 0.08953140676021576
Validation loss: 1.3456695387440343

Epoch: 6| Step: 8
Training loss: 0.06674498319625854
Validation loss: 1.334080042377595

Epoch: 6| Step: 9
Training loss: 0.08264847099781036
Validation loss: 1.3535599324011034

Epoch: 6| Step: 10
Training loss: 0.055569835007190704
Validation loss: 1.3346194182672808

Epoch: 6| Step: 11
Training loss: 0.06420011818408966
Validation loss: 1.3493173526179405

Epoch: 6| Step: 12
Training loss: 0.02709750272333622
Validation loss: 1.3508012845952024

Epoch: 6| Step: 13
Training loss: 0.05992809310555458
Validation loss: 1.3543262680371602

Epoch: 698| Step: 0
Training loss: 0.05735789239406586
Validation loss: 1.3544750111077422

Epoch: 6| Step: 1
Training loss: 0.08750467747449875
Validation loss: 1.366633758750013

Epoch: 6| Step: 2
Training loss: 0.0933302491903305
Validation loss: 1.3776049844680294

Epoch: 6| Step: 3
Training loss: 0.09053410589694977
Validation loss: 1.370710131942585

Epoch: 6| Step: 4
Training loss: 0.06476415693759918
Validation loss: 1.369204072542088

Epoch: 6| Step: 5
Training loss: 0.08959616720676422
Validation loss: 1.3824553810140139

Epoch: 6| Step: 6
Training loss: 0.028374480083584785
Validation loss: 1.3769762951840636

Epoch: 6| Step: 7
Training loss: 0.054979562759399414
Validation loss: 1.3796120561579222

Epoch: 6| Step: 8
Training loss: 0.048321329057216644
Validation loss: 1.3926917852893952

Epoch: 6| Step: 9
Training loss: 0.07034696638584137
Validation loss: 1.3796576069247337

Epoch: 6| Step: 10
Training loss: 0.04635971784591675
Validation loss: 1.3651574471945405

Epoch: 6| Step: 11
Training loss: 0.0823187530040741
Validation loss: 1.3862025724944247

Epoch: 6| Step: 12
Training loss: 0.08712200820446014
Validation loss: 1.4024055786030267

Epoch: 6| Step: 13
Training loss: 0.07932552695274353
Validation loss: 1.3975393772125244

Epoch: 699| Step: 0
Training loss: 0.06096342206001282
Validation loss: 1.388025656823189

Epoch: 6| Step: 1
Training loss: 0.058556877076625824
Validation loss: 1.3812192473360287

Epoch: 6| Step: 2
Training loss: 0.06454512476921082
Validation loss: 1.3765742394231981

Epoch: 6| Step: 3
Training loss: 0.06252938508987427
Validation loss: 1.352574368958832

Epoch: 6| Step: 4
Training loss: 0.06581063568592072
Validation loss: 1.3539006517779442

Epoch: 6| Step: 5
Training loss: 0.053791679441928864
Validation loss: 1.3603683505007016

Epoch: 6| Step: 6
Training loss: 0.04516519978642464
Validation loss: 1.3732657227464902

Epoch: 6| Step: 7
Training loss: 0.06689746677875519
Validation loss: 1.3608808587956172

Epoch: 6| Step: 8
Training loss: 0.029966231435537338
Validation loss: 1.3616143118950628

Epoch: 6| Step: 9
Training loss: 0.05393543839454651
Validation loss: 1.3596399202141711

Epoch: 6| Step: 10
Training loss: 0.03886798024177551
Validation loss: 1.3521233309981644

Epoch: 6| Step: 11
Training loss: 0.07093235850334167
Validation loss: 1.3611471838848566

Epoch: 6| Step: 12
Training loss: 0.06237220764160156
Validation loss: 1.3646128119960907

Epoch: 6| Step: 13
Training loss: 0.04008077457547188
Validation loss: 1.342817901283182

Epoch: 700| Step: 0
Training loss: 0.04056306183338165
Validation loss: 1.348422368367513

Epoch: 6| Step: 1
Training loss: 0.055371515452861786
Validation loss: 1.339070781584709

Epoch: 6| Step: 2
Training loss: 0.05022518336772919
Validation loss: 1.3257491178410028

Epoch: 6| Step: 3
Training loss: 0.06323225796222687
Validation loss: 1.3481488830299788

Epoch: 6| Step: 4
Training loss: 0.04682912304997444
Validation loss: 1.3268170010659002

Epoch: 6| Step: 5
Training loss: 0.05373113602399826
Validation loss: 1.3075736133001183

Epoch: 6| Step: 6
Training loss: 0.06156877428293228
Validation loss: 1.3316602886364024

Epoch: 6| Step: 7
Training loss: 0.035675473511219025
Validation loss: 1.3347185619415776

Epoch: 6| Step: 8
Training loss: 0.047730445861816406
Validation loss: 1.3166709997320687

Epoch: 6| Step: 9
Training loss: 0.07259028404951096
Validation loss: 1.3313592480074974

Epoch: 6| Step: 10
Training loss: 0.06163837015628815
Validation loss: 1.3506181073445145

Epoch: 6| Step: 11
Training loss: 0.04240412265062332
Validation loss: 1.3497076188364336

Epoch: 6| Step: 12
Training loss: 0.04185974597930908
Validation loss: 1.3408107411476873

Epoch: 6| Step: 13
Training loss: 0.04442885145545006
Validation loss: 1.334545837935581

Epoch: 701| Step: 0
Training loss: 0.03447520360350609
Validation loss: 1.3474825889833513

Epoch: 6| Step: 1
Training loss: 0.04985034465789795
Validation loss: 1.3439746710561937

Epoch: 6| Step: 2
Training loss: 0.04635053873062134
Validation loss: 1.3364910079586891

Epoch: 6| Step: 3
Training loss: 0.04553844407200813
Validation loss: 1.3498517082583519

Epoch: 6| Step: 4
Training loss: 0.025707073509693146
Validation loss: 1.3615083976458477

Epoch: 6| Step: 5
Training loss: 0.05473494529724121
Validation loss: 1.3547756415541454

Epoch: 6| Step: 6
Training loss: 0.0442219004034996
Validation loss: 1.366787133037403

Epoch: 6| Step: 7
Training loss: 0.04371001571416855
Validation loss: 1.3399955764893563

Epoch: 6| Step: 8
Training loss: 0.05631005018949509
Validation loss: 1.3480538245170348

Epoch: 6| Step: 9
Training loss: 0.04630858451128006
Validation loss: 1.356103543312319

Epoch: 6| Step: 10
Training loss: 0.03900158405303955
Validation loss: 1.3488394028397017

Epoch: 6| Step: 11
Training loss: 0.04750669002532959
Validation loss: 1.3606807877940517

Epoch: 6| Step: 12
Training loss: 0.06453819572925568
Validation loss: 1.3616632466675134

Epoch: 6| Step: 13
Training loss: 0.05940546467900276
Validation loss: 1.3626746682710544

Epoch: 702| Step: 0
Training loss: 0.034960005432367325
Validation loss: 1.3837992414351432

Epoch: 6| Step: 1
Training loss: 0.03597678989171982
Validation loss: 1.3823676314405215

Epoch: 6| Step: 2
Training loss: 0.03220737725496292
Validation loss: 1.395759952965603

Epoch: 6| Step: 3
Training loss: 0.05491149425506592
Validation loss: 1.388337778788741

Epoch: 6| Step: 4
Training loss: 0.053348176181316376
Validation loss: 1.3893161986463813

Epoch: 6| Step: 5
Training loss: 0.03693601116538048
Validation loss: 1.4096515396589875

Epoch: 6| Step: 6
Training loss: 0.05960962921380997
Validation loss: 1.4032639200969408

Epoch: 6| Step: 7
Training loss: 0.03954731300473213
Validation loss: 1.3901122539274153

Epoch: 6| Step: 8
Training loss: 0.0346464067697525
Validation loss: 1.408628409908664

Epoch: 6| Step: 9
Training loss: 0.047475606203079224
Validation loss: 1.4019319754774853

Epoch: 6| Step: 10
Training loss: 0.07689368724822998
Validation loss: 1.4024783847152547

Epoch: 6| Step: 11
Training loss: 0.05461600795388222
Validation loss: 1.38261454977015

Epoch: 6| Step: 12
Training loss: 0.03745182603597641
Validation loss: 1.398176763647346

Epoch: 6| Step: 13
Training loss: 0.03755814954638481
Validation loss: 1.3744264212987756

Epoch: 703| Step: 0
Training loss: 0.02337307669222355
Validation loss: 1.3830085191675412

Epoch: 6| Step: 1
Training loss: 0.034666016697883606
Validation loss: 1.3571456299033215

Epoch: 6| Step: 2
Training loss: 0.046310827136039734
Validation loss: 1.3489872153087328

Epoch: 6| Step: 3
Training loss: 0.042634956538677216
Validation loss: 1.3604141050769436

Epoch: 6| Step: 4
Training loss: 0.04774371534585953
Validation loss: 1.3696648241371236

Epoch: 6| Step: 5
Training loss: 0.04150537773966789
Validation loss: 1.3632832175941878

Epoch: 6| Step: 6
Training loss: 0.03501206636428833
Validation loss: 1.357173083930887

Epoch: 6| Step: 7
Training loss: 0.030704470351338387
Validation loss: 1.3644512622587142

Epoch: 6| Step: 8
Training loss: 0.05360393226146698
Validation loss: 1.3616702300246044

Epoch: 6| Step: 9
Training loss: 0.05622702091932297
Validation loss: 1.368189142596337

Epoch: 6| Step: 10
Training loss: 0.033382344990968704
Validation loss: 1.3619773541727374

Epoch: 6| Step: 11
Training loss: 0.03424651175737381
Validation loss: 1.3764306255566177

Epoch: 6| Step: 12
Training loss: 0.03438472002744675
Validation loss: 1.3595738308404082

Epoch: 6| Step: 13
Training loss: 0.022295163944363594
Validation loss: 1.3767730689817859

Epoch: 704| Step: 0
Training loss: 0.03804231435060501
Validation loss: 1.3694401812809769

Epoch: 6| Step: 1
Training loss: 0.05425543338060379
Validation loss: 1.3748344734150877

Epoch: 6| Step: 2
Training loss: 0.047770656645298004
Validation loss: 1.3536918060753935

Epoch: 6| Step: 3
Training loss: 0.048645369708538055
Validation loss: 1.3613967421234294

Epoch: 6| Step: 4
Training loss: 0.04263214021921158
Validation loss: 1.3757026233980734

Epoch: 6| Step: 5
Training loss: 0.04709344357252121
Validation loss: 1.3737758372419624

Epoch: 6| Step: 6
Training loss: 0.05004964768886566
Validation loss: 1.354731382862214

Epoch: 6| Step: 7
Training loss: 0.05138175189495087
Validation loss: 1.3640542196971115

Epoch: 6| Step: 8
Training loss: 0.03980365768074989
Validation loss: 1.3776444850429412

Epoch: 6| Step: 9
Training loss: 0.041507504880428314
Validation loss: 1.3844909309059061

Epoch: 6| Step: 10
Training loss: 0.0513143427670002
Validation loss: 1.376389306078675

Epoch: 6| Step: 11
Training loss: 0.02928190305829048
Validation loss: 1.3620313412399703

Epoch: 6| Step: 12
Training loss: 0.03178951144218445
Validation loss: 1.3806982489042385

Epoch: 6| Step: 13
Training loss: 0.04920010268688202
Validation loss: 1.393309086881658

Epoch: 705| Step: 0
Training loss: 0.04296031594276428
Validation loss: 1.392303139932694

Epoch: 6| Step: 1
Training loss: 0.033205073326826096
Validation loss: 1.3812157454029206

Epoch: 6| Step: 2
Training loss: 0.050194524228572845
Validation loss: 1.4000588911835865

Epoch: 6| Step: 3
Training loss: 0.02280636690557003
Validation loss: 1.3796275508019231

Epoch: 6| Step: 4
Training loss: 0.04592188447713852
Validation loss: 1.3813443978627522

Epoch: 6| Step: 5
Training loss: 0.026386717334389687
Validation loss: 1.369229470529864

Epoch: 6| Step: 6
Training loss: 0.03747963905334473
Validation loss: 1.37588386061371

Epoch: 6| Step: 7
Training loss: 0.04102550446987152
Validation loss: 1.3776380708140712

Epoch: 6| Step: 8
Training loss: 0.029293641448020935
Validation loss: 1.3650953782502042

Epoch: 6| Step: 9
Training loss: 0.060853004455566406
Validation loss: 1.3905359263061194

Epoch: 6| Step: 10
Training loss: 0.05111975222826004
Validation loss: 1.3789061371998121

Epoch: 6| Step: 11
Training loss: 0.041700735688209534
Validation loss: 1.3922617768728605

Epoch: 6| Step: 12
Training loss: 0.04070384055376053
Validation loss: 1.3618386958235054

Epoch: 6| Step: 13
Training loss: 0.016379542648792267
Validation loss: 1.3816459486561437

Epoch: 706| Step: 0
Training loss: 0.026227593421936035
Validation loss: 1.38066868500043

Epoch: 6| Step: 1
Training loss: 0.04458171874284744
Validation loss: 1.3764632337836809

Epoch: 6| Step: 2
Training loss: 0.03855867311358452
Validation loss: 1.358062142966896

Epoch: 6| Step: 3
Training loss: 0.04329627752304077
Validation loss: 1.3473410798657326

Epoch: 6| Step: 4
Training loss: 0.04636198282241821
Validation loss: 1.35798926379091

Epoch: 6| Step: 5
Training loss: 0.029103761538863182
Validation loss: 1.355423652997581

Epoch: 6| Step: 6
Training loss: 0.04897197335958481
Validation loss: 1.364473376222836

Epoch: 6| Step: 7
Training loss: 0.035652074962854385
Validation loss: 1.3786831619918987

Epoch: 6| Step: 8
Training loss: 0.057981960475444794
Validation loss: 1.3756374415530954

Epoch: 6| Step: 9
Training loss: 0.037304725497961044
Validation loss: 1.3735656494735389

Epoch: 6| Step: 10
Training loss: 0.02982403337955475
Validation loss: 1.3579238384000716

Epoch: 6| Step: 11
Training loss: 0.04449427127838135
Validation loss: 1.3775977473105154

Epoch: 6| Step: 12
Training loss: 0.053174711763858795
Validation loss: 1.361362176556741

Epoch: 6| Step: 13
Training loss: 0.04408137500286102
Validation loss: 1.3804107878797798

Epoch: 707| Step: 0
Training loss: 0.02034590393304825
Validation loss: 1.3746277029796312

Epoch: 6| Step: 1
Training loss: 0.038753826171159744
Validation loss: 1.3673133516824374

Epoch: 6| Step: 2
Training loss: 0.042375169694423676
Validation loss: 1.3543821188711351

Epoch: 6| Step: 3
Training loss: 0.04814084246754646
Validation loss: 1.371735671515106

Epoch: 6| Step: 4
Training loss: 0.043019719421863556
Validation loss: 1.3747493810551141

Epoch: 6| Step: 5
Training loss: 0.04661906138062477
Validation loss: 1.3501728503934798

Epoch: 6| Step: 6
Training loss: 0.032906509935855865
Validation loss: 1.3627289930979412

Epoch: 6| Step: 7
Training loss: 0.04162872955203056
Validation loss: 1.3379393790357856

Epoch: 6| Step: 8
Training loss: 0.034846656024456024
Validation loss: 1.3361603957350536

Epoch: 6| Step: 9
Training loss: 0.03821384161710739
Validation loss: 1.359544579700757

Epoch: 6| Step: 10
Training loss: 0.041677653789520264
Validation loss: 1.3490439089395667

Epoch: 6| Step: 11
Training loss: 0.05244448035955429
Validation loss: 1.3422370726062405

Epoch: 6| Step: 12
Training loss: 0.03852180391550064
Validation loss: 1.3388166478885117

Epoch: 6| Step: 13
Training loss: 0.04754374921321869
Validation loss: 1.356761667036241

Epoch: 708| Step: 0
Training loss: 0.04696100205183029
Validation loss: 1.3595583361964072

Epoch: 6| Step: 1
Training loss: 0.028499796986579895
Validation loss: 1.370494080487118

Epoch: 6| Step: 2
Training loss: 0.024179060012102127
Validation loss: 1.3751100673470447

Epoch: 6| Step: 3
Training loss: 0.03805657476186752
Validation loss: 1.3886795620764456

Epoch: 6| Step: 4
Training loss: 0.02751668356359005
Validation loss: 1.3822760261515135

Epoch: 6| Step: 5
Training loss: 0.046194374561309814
Validation loss: 1.4121870084475445

Epoch: 6| Step: 6
Training loss: 0.02764832228422165
Validation loss: 1.3826091949657728

Epoch: 6| Step: 7
Training loss: 0.03469829633831978
Validation loss: 1.3996653531187324

Epoch: 6| Step: 8
Training loss: 0.04129545018076897
Validation loss: 1.4055930696507937

Epoch: 6| Step: 9
Training loss: 0.0608590729534626
Validation loss: 1.3919112464433074

Epoch: 6| Step: 10
Training loss: 0.034440137445926666
Validation loss: 1.4028746274209791

Epoch: 6| Step: 11
Training loss: 0.03320135176181793
Validation loss: 1.3951703169012581

Epoch: 6| Step: 12
Training loss: 0.0597454234957695
Validation loss: 1.396375358745616

Epoch: 6| Step: 13
Training loss: 0.03857085481286049
Validation loss: 1.406133089014279

Epoch: 709| Step: 0
Training loss: 0.04582410305738449
Validation loss: 1.3901840371470298

Epoch: 6| Step: 1
Training loss: 0.06479187309741974
Validation loss: 1.390535339232414

Epoch: 6| Step: 2
Training loss: 0.03173302859067917
Validation loss: 1.4014780367574384

Epoch: 6| Step: 3
Training loss: 0.029772654175758362
Validation loss: 1.3961307617925829

Epoch: 6| Step: 4
Training loss: 0.02077902853488922
Validation loss: 1.3972169032660864

Epoch: 6| Step: 5
Training loss: 0.03473180532455444
Validation loss: 1.3799386806385492

Epoch: 6| Step: 6
Training loss: 0.04629868268966675
Validation loss: 1.3982435528950026

Epoch: 6| Step: 7
Training loss: 0.028910724446177483
Validation loss: 1.385273983401637

Epoch: 6| Step: 8
Training loss: 0.038416579365730286
Validation loss: 1.362312944986487

Epoch: 6| Step: 9
Training loss: 0.038423627614974976
Validation loss: 1.3804337529725925

Epoch: 6| Step: 10
Training loss: 0.039493538439273834
Validation loss: 1.3879827248152865

Epoch: 6| Step: 11
Training loss: 0.03169311210513115
Validation loss: 1.3845952762070524

Epoch: 6| Step: 12
Training loss: 0.030201807618141174
Validation loss: 1.374754390408916

Epoch: 6| Step: 13
Training loss: 0.0405493825674057
Validation loss: 1.3840095971220283

Epoch: 710| Step: 0
Training loss: 0.03634490817785263
Validation loss: 1.3812614743427565

Epoch: 6| Step: 1
Training loss: 0.04360407590866089
Validation loss: 1.3736233634333457

Epoch: 6| Step: 2
Training loss: 0.03132595121860504
Validation loss: 1.3794316912210116

Epoch: 6| Step: 3
Training loss: 0.043362148106098175
Validation loss: 1.3801543251160653

Epoch: 6| Step: 4
Training loss: 0.08800127357244492
Validation loss: 1.3530599538997938

Epoch: 6| Step: 5
Training loss: 0.030515380203723907
Validation loss: 1.3733013804240892

Epoch: 6| Step: 6
Training loss: 0.03399208188056946
Validation loss: 1.3464241271377893

Epoch: 6| Step: 7
Training loss: 0.032236769795417786
Validation loss: 1.3660003574945594

Epoch: 6| Step: 8
Training loss: 0.03818267583847046
Validation loss: 1.3492570384856193

Epoch: 6| Step: 9
Training loss: 0.036121152341365814
Validation loss: 1.3748424040373934

Epoch: 6| Step: 10
Training loss: 0.03838307410478592
Validation loss: 1.3872324164195726

Epoch: 6| Step: 11
Training loss: 0.04561631754040718
Validation loss: 1.379790331727715

Epoch: 6| Step: 12
Training loss: 0.03724251687526703
Validation loss: 1.3748274221215198

Epoch: 6| Step: 13
Training loss: 0.05876157060265541
Validation loss: 1.3754806839009768

Epoch: 711| Step: 0
Training loss: 0.04387535899877548
Validation loss: 1.3833282660412531

Epoch: 6| Step: 1
Training loss: 0.03119424171745777
Validation loss: 1.4092696841045091

Epoch: 6| Step: 2
Training loss: 0.04091246426105499
Validation loss: 1.3836783593700779

Epoch: 6| Step: 3
Training loss: 0.04167050123214722
Validation loss: 1.4083386095621253

Epoch: 6| Step: 4
Training loss: 0.05287773162126541
Validation loss: 1.4088938287509385

Epoch: 6| Step: 5
Training loss: 0.032350312918424606
Validation loss: 1.3938763051904657

Epoch: 6| Step: 6
Training loss: 0.07651033252477646
Validation loss: 1.4069379529645365

Epoch: 6| Step: 7
Training loss: 0.04483256861567497
Validation loss: 1.3947953254945817

Epoch: 6| Step: 8
Training loss: 0.03910239040851593
Validation loss: 1.4129150618789017

Epoch: 6| Step: 9
Training loss: 0.053731951862573624
Validation loss: 1.4088390642596829

Epoch: 6| Step: 10
Training loss: 0.037276118993759155
Validation loss: 1.4176087046182284

Epoch: 6| Step: 11
Training loss: 0.02414630725979805
Validation loss: 1.3997777219741576

Epoch: 6| Step: 12
Training loss: 0.030295418575406075
Validation loss: 1.4029641343701271

Epoch: 6| Step: 13
Training loss: 0.06222952902317047
Validation loss: 1.383140827378919

Epoch: 712| Step: 0
Training loss: 0.028213918209075928
Validation loss: 1.4092070941002137

Epoch: 6| Step: 1
Training loss: 0.03600161522626877
Validation loss: 1.4011027889866983

Epoch: 6| Step: 2
Training loss: 0.051025789231061935
Validation loss: 1.4001358593663862

Epoch: 6| Step: 3
Training loss: 0.03954797983169556
Validation loss: 1.37625705042193

Epoch: 6| Step: 4
Training loss: 0.03459727019071579
Validation loss: 1.3893107060463197

Epoch: 6| Step: 5
Training loss: 0.04913777858018875
Validation loss: 1.376705567042033

Epoch: 6| Step: 6
Training loss: 0.05081477761268616
Validation loss: 1.3684399461233487

Epoch: 6| Step: 7
Training loss: 0.033772435039281845
Validation loss: 1.367887140602194

Epoch: 6| Step: 8
Training loss: 0.039709798991680145
Validation loss: 1.3807230213636994

Epoch: 6| Step: 9
Training loss: 0.041120897978544235
Validation loss: 1.3739116794319564

Epoch: 6| Step: 10
Training loss: 0.04335866868495941
Validation loss: 1.3678359639260076

Epoch: 6| Step: 11
Training loss: 0.07474212348461151
Validation loss: 1.3677757786166282

Epoch: 6| Step: 12
Training loss: 0.030260184779763222
Validation loss: 1.3840937434986074

Epoch: 6| Step: 13
Training loss: 0.03821754455566406
Validation loss: 1.3662149143475357

Epoch: 713| Step: 0
Training loss: 0.05178896337747574
Validation loss: 1.3680976834348453

Epoch: 6| Step: 1
Training loss: 0.06473053991794586
Validation loss: 1.3738298646865352

Epoch: 6| Step: 2
Training loss: 0.051906052976846695
Validation loss: 1.391793304874051

Epoch: 6| Step: 3
Training loss: 0.031357407569885254
Validation loss: 1.3768233881201795

Epoch: 6| Step: 4
Training loss: 0.0359317883849144
Validation loss: 1.383471312702343

Epoch: 6| Step: 5
Training loss: 0.030486050993204117
Validation loss: 1.402467889170493

Epoch: 6| Step: 6
Training loss: 0.045219868421554565
Validation loss: 1.4028711357424337

Epoch: 6| Step: 7
Training loss: 0.03995111957192421
Validation loss: 1.3825272078155189

Epoch: 6| Step: 8
Training loss: 0.052751410752534866
Validation loss: 1.3753395042111796

Epoch: 6| Step: 9
Training loss: 0.018612775951623917
Validation loss: 1.3863070216230167

Epoch: 6| Step: 10
Training loss: 0.044551461935043335
Validation loss: 1.364892340475513

Epoch: 6| Step: 11
Training loss: 0.05675263702869415
Validation loss: 1.3872505150815493

Epoch: 6| Step: 12
Training loss: 0.0371401309967041
Validation loss: 1.3858522817652712

Epoch: 6| Step: 13
Training loss: 0.025744862854480743
Validation loss: 1.378378568797983

Epoch: 714| Step: 0
Training loss: 0.04453299939632416
Validation loss: 1.3792242478298884

Epoch: 6| Step: 1
Training loss: 0.05396536365151405
Validation loss: 1.3863663263218378

Epoch: 6| Step: 2
Training loss: 0.02979850396513939
Validation loss: 1.3802921182365828

Epoch: 6| Step: 3
Training loss: 0.034605249762535095
Validation loss: 1.3822278732894568

Epoch: 6| Step: 4
Training loss: 0.06695850193500519
Validation loss: 1.3891887728885939

Epoch: 6| Step: 5
Training loss: 0.05259261652827263
Validation loss: 1.3850818225132522

Epoch: 6| Step: 6
Training loss: 0.04854726791381836
Validation loss: 1.394516892971531

Epoch: 6| Step: 7
Training loss: 0.02999953180551529
Validation loss: 1.3958052781320387

Epoch: 6| Step: 8
Training loss: 0.039575621485710144
Validation loss: 1.3936698846919562

Epoch: 6| Step: 9
Training loss: 0.06014346331357956
Validation loss: 1.406100042404667

Epoch: 6| Step: 10
Training loss: 0.04219149053096771
Validation loss: 1.4072020399955012

Epoch: 6| Step: 11
Training loss: 0.033738166093826294
Validation loss: 1.4100853243181783

Epoch: 6| Step: 12
Training loss: 0.02990913763642311
Validation loss: 1.4340807571206042

Epoch: 6| Step: 13
Training loss: 0.05237714946269989
Validation loss: 1.392467205242444

Epoch: 715| Step: 0
Training loss: 0.051727134734392166
Validation loss: 1.4134056939873645

Epoch: 6| Step: 1
Training loss: 0.049171607941389084
Validation loss: 1.3887495520294353

Epoch: 6| Step: 2
Training loss: 0.033082082867622375
Validation loss: 1.3747826199377737

Epoch: 6| Step: 3
Training loss: 0.02914135530591011
Validation loss: 1.3967244907092022

Epoch: 6| Step: 4
Training loss: 0.042069099843502045
Validation loss: 1.3852820986060685

Epoch: 6| Step: 5
Training loss: 0.02961767464876175
Validation loss: 1.380335097671837

Epoch: 6| Step: 6
Training loss: 0.03730887174606323
Validation loss: 1.3722423417593843

Epoch: 6| Step: 7
Training loss: 0.03485771268606186
Validation loss: 1.371042227232328

Epoch: 6| Step: 8
Training loss: 0.05962040647864342
Validation loss: 1.373729440473741

Epoch: 6| Step: 9
Training loss: 0.044508591294288635
Validation loss: 1.378100884857998

Epoch: 6| Step: 10
Training loss: 0.06854234635829926
Validation loss: 1.3656734099952124

Epoch: 6| Step: 11
Training loss: 0.04986207187175751
Validation loss: 1.3869747577175018

Epoch: 6| Step: 12
Training loss: 0.04386189207434654
Validation loss: 1.3927138928444154

Epoch: 6| Step: 13
Training loss: 0.05136642977595329
Validation loss: 1.396202306593618

Epoch: 716| Step: 0
Training loss: 0.038686446845531464
Validation loss: 1.390181851643388

Epoch: 6| Step: 1
Training loss: 0.05939074605703354
Validation loss: 1.3870741090466898

Epoch: 6| Step: 2
Training loss: 0.03210936486721039
Validation loss: 1.3868737656583068

Epoch: 6| Step: 3
Training loss: 0.027638062834739685
Validation loss: 1.3986599926025636

Epoch: 6| Step: 4
Training loss: 0.024029135704040527
Validation loss: 1.401417698270531

Epoch: 6| Step: 5
Training loss: 0.04113978147506714
Validation loss: 1.407257741497409

Epoch: 6| Step: 6
Training loss: 0.0560329407453537
Validation loss: 1.4066041797719977

Epoch: 6| Step: 7
Training loss: 0.04042559862136841
Validation loss: 1.4012896142980105

Epoch: 6| Step: 8
Training loss: 0.04733341559767723
Validation loss: 1.4130646439008816

Epoch: 6| Step: 9
Training loss: 0.05551791936159134
Validation loss: 1.4019048918959915

Epoch: 6| Step: 10
Training loss: 0.04726430028676987
Validation loss: 1.4076566298802693

Epoch: 6| Step: 11
Training loss: 0.04819059371948242
Validation loss: 1.4008716473015406

Epoch: 6| Step: 12
Training loss: 0.03055519610643387
Validation loss: 1.4240797373556322

Epoch: 6| Step: 13
Training loss: 0.018897702917456627
Validation loss: 1.4069396436855357

Epoch: 717| Step: 0
Training loss: 0.058322057127952576
Validation loss: 1.4185459831709504

Epoch: 6| Step: 1
Training loss: 0.03852164000272751
Validation loss: 1.4061216590225056

Epoch: 6| Step: 2
Training loss: 0.03686225041747093
Validation loss: 1.4010053309061195

Epoch: 6| Step: 3
Training loss: 0.02958347275853157
Validation loss: 1.4072392345756612

Epoch: 6| Step: 4
Training loss: 0.048556141555309296
Validation loss: 1.3826897144317627

Epoch: 6| Step: 5
Training loss: 0.04544462263584137
Validation loss: 1.3999813807907926

Epoch: 6| Step: 6
Training loss: 0.04541148245334625
Validation loss: 1.3982198430645851

Epoch: 6| Step: 7
Training loss: 0.034465380012989044
Validation loss: 1.3874625954576718

Epoch: 6| Step: 8
Training loss: 0.0317893885076046
Validation loss: 1.4034081812827819

Epoch: 6| Step: 9
Training loss: 0.04984431713819504
Validation loss: 1.3780174652735393

Epoch: 6| Step: 10
Training loss: 0.04171382263302803
Validation loss: 1.3820742740426013

Epoch: 6| Step: 11
Training loss: 0.03481524437665939
Validation loss: 1.3959398320926133

Epoch: 6| Step: 12
Training loss: 0.03171021491289139
Validation loss: 1.3791703203673005

Epoch: 6| Step: 13
Training loss: 0.02445288561284542
Validation loss: 1.3836632146630237

Epoch: 718| Step: 0
Training loss: 0.03391618654131889
Validation loss: 1.3943461064369447

Epoch: 6| Step: 1
Training loss: 0.053817249834537506
Validation loss: 1.4018518719621884

Epoch: 6| Step: 2
Training loss: 0.041383951902389526
Validation loss: 1.4050487940029432

Epoch: 6| Step: 3
Training loss: 0.04529671370983124
Validation loss: 1.4014614083433663

Epoch: 6| Step: 4
Training loss: 0.05029548704624176
Validation loss: 1.4140516250364241

Epoch: 6| Step: 5
Training loss: 0.038905948400497437
Validation loss: 1.4067321887580297

Epoch: 6| Step: 6
Training loss: 0.04890665039420128
Validation loss: 1.4040479557488554

Epoch: 6| Step: 7
Training loss: 0.03672930598258972
Validation loss: 1.3970889083800777

Epoch: 6| Step: 8
Training loss: 0.0326879620552063
Validation loss: 1.4092861683137956

Epoch: 6| Step: 9
Training loss: 0.028864828869700432
Validation loss: 1.3914655395733413

Epoch: 6| Step: 10
Training loss: 0.0661039650440216
Validation loss: 1.4108737655865249

Epoch: 6| Step: 11
Training loss: 0.04955168440937996
Validation loss: 1.4057998811045

Epoch: 6| Step: 12
Training loss: 0.05977615714073181
Validation loss: 1.4150031176946496

Epoch: 6| Step: 13
Training loss: 0.04336249828338623
Validation loss: 1.3973596275493663

Epoch: 719| Step: 0
Training loss: 0.03513891622424126
Validation loss: 1.409762743980654

Epoch: 6| Step: 1
Training loss: 0.03832360729575157
Validation loss: 1.404916267241201

Epoch: 6| Step: 2
Training loss: 0.07585518807172775
Validation loss: 1.399897567687496

Epoch: 6| Step: 3
Training loss: 0.0401606559753418
Validation loss: 1.4014236632213797

Epoch: 6| Step: 4
Training loss: 0.028983335942029953
Validation loss: 1.4029309429148191

Epoch: 6| Step: 5
Training loss: 0.02683696150779724
Validation loss: 1.4152185224717664

Epoch: 6| Step: 6
Training loss: 0.07728607207536697
Validation loss: 1.430064478228169

Epoch: 6| Step: 7
Training loss: 0.0523962676525116
Validation loss: 1.403393986404583

Epoch: 6| Step: 8
Training loss: 0.08822313696146011
Validation loss: 1.3840361256753244

Epoch: 6| Step: 9
Training loss: 0.0683298259973526
Validation loss: 1.3908105447728147

Epoch: 6| Step: 10
Training loss: 0.044169407337903976
Validation loss: 1.3926515438223397

Epoch: 6| Step: 11
Training loss: 0.02851150557398796
Validation loss: 1.3855536900540835

Epoch: 6| Step: 12
Training loss: 0.043236929923295975
Validation loss: 1.359427712296927

Epoch: 6| Step: 13
Training loss: 0.048543136566877365
Validation loss: 1.3348784497989121

Epoch: 720| Step: 0
Training loss: 0.03674770146608353
Validation loss: 1.3062229976859143

Epoch: 6| Step: 1
Training loss: 0.05807574465870857
Validation loss: 1.3055380922491833

Epoch: 6| Step: 2
Training loss: 0.059718552976846695
Validation loss: 1.2892207304636638

Epoch: 6| Step: 3
Training loss: 0.046586401760578156
Validation loss: 1.2968034334080194

Epoch: 6| Step: 4
Training loss: 0.030459141358733177
Validation loss: 1.2921182224827428

Epoch: 6| Step: 5
Training loss: 0.0517931804060936
Validation loss: 1.317736219334346

Epoch: 6| Step: 6
Training loss: 0.04506595432758331
Validation loss: 1.3160081883912444

Epoch: 6| Step: 7
Training loss: 0.06113211810588837
Validation loss: 1.3236361626655824

Epoch: 6| Step: 8
Training loss: 0.0499706044793129
Validation loss: 1.3149803825604018

Epoch: 6| Step: 9
Training loss: 0.061302170157432556
Validation loss: 1.3357099692026775

Epoch: 6| Step: 10
Training loss: 0.04362853616476059
Validation loss: 1.3399802593774692

Epoch: 6| Step: 11
Training loss: 0.03785519301891327
Validation loss: 1.3384979040391984

Epoch: 6| Step: 12
Training loss: 0.05235828086733818
Validation loss: 1.3502443041852725

Epoch: 6| Step: 13
Training loss: 0.051746539771556854
Validation loss: 1.3554352002759134

Epoch: 721| Step: 0
Training loss: 0.04508112370967865
Validation loss: 1.3526975506095475

Epoch: 6| Step: 1
Training loss: 0.02980506792664528
Validation loss: 1.3700715162420785

Epoch: 6| Step: 2
Training loss: 0.03162311017513275
Validation loss: 1.359272215956001

Epoch: 6| Step: 3
Training loss: 0.027248907834291458
Validation loss: 1.3797366452473465

Epoch: 6| Step: 4
Training loss: 0.039694301784038544
Validation loss: 1.383656814534177

Epoch: 6| Step: 5
Training loss: 0.0492984801530838
Validation loss: 1.3766112455757715

Epoch: 6| Step: 6
Training loss: 0.04664400592446327
Validation loss: 1.3813459104107273

Epoch: 6| Step: 7
Training loss: 0.04532458633184433
Validation loss: 1.3854761764567385

Epoch: 6| Step: 8
Training loss: 0.05024394392967224
Validation loss: 1.388269983312135

Epoch: 6| Step: 9
Training loss: 0.05305225029587746
Validation loss: 1.3515313299753333

Epoch: 6| Step: 10
Training loss: 0.05908294767141342
Validation loss: 1.3747169702283797

Epoch: 6| Step: 11
Training loss: 0.07180517911911011
Validation loss: 1.350142050814885

Epoch: 6| Step: 12
Training loss: 0.04550936073064804
Validation loss: 1.355440426898259

Epoch: 6| Step: 13
Training loss: 0.020420683547854424
Validation loss: 1.3729062003474082

Epoch: 722| Step: 0
Training loss: 0.04506365954875946
Validation loss: 1.37407333876497

Epoch: 6| Step: 1
Training loss: 0.028087642043828964
Validation loss: 1.3548163983129686

Epoch: 6| Step: 2
Training loss: 0.04088486731052399
Validation loss: 1.3728739792300808

Epoch: 6| Step: 3
Training loss: 0.03456299751996994
Validation loss: 1.3801010526636595

Epoch: 6| Step: 4
Training loss: 0.05875495821237564
Validation loss: 1.3643102440782773

Epoch: 6| Step: 5
Training loss: 0.040319763123989105
Validation loss: 1.3620985554110618

Epoch: 6| Step: 6
Training loss: 0.044173575937747955
Validation loss: 1.3721847329088437

Epoch: 6| Step: 7
Training loss: 0.030469682067632675
Validation loss: 1.3639981182672645

Epoch: 6| Step: 8
Training loss: 0.043763674795627594
Validation loss: 1.3745280465772074

Epoch: 6| Step: 9
Training loss: 0.047343660145998
Validation loss: 1.3860768015666673

Epoch: 6| Step: 10
Training loss: 0.05967547744512558
Validation loss: 1.3684157536875816

Epoch: 6| Step: 11
Training loss: 0.054878972470760345
Validation loss: 1.365964925417336

Epoch: 6| Step: 12
Training loss: 0.03177497163414955
Validation loss: 1.369520217500707

Epoch: 6| Step: 13
Training loss: 0.04274945706129074
Validation loss: 1.3774581250324045

Epoch: 723| Step: 0
Training loss: 0.04056145250797272
Validation loss: 1.3638328288191108

Epoch: 6| Step: 1
Training loss: 0.034473564475774765
Validation loss: 1.3765586473608529

Epoch: 6| Step: 2
Training loss: 0.04314092546701431
Validation loss: 1.3742877450040591

Epoch: 6| Step: 3
Training loss: 0.02874433994293213
Validation loss: 1.3853049675623577

Epoch: 6| Step: 4
Training loss: 0.07749821990728378
Validation loss: 1.3944679767854753

Epoch: 6| Step: 5
Training loss: 0.05594542622566223
Validation loss: 1.4071513017018635

Epoch: 6| Step: 6
Training loss: 0.055975474417209625
Validation loss: 1.403005079556537

Epoch: 6| Step: 7
Training loss: 0.06541894376277924
Validation loss: 1.3951884623496764

Epoch: 6| Step: 8
Training loss: 0.04280887171626091
Validation loss: 1.4149485390673402

Epoch: 6| Step: 9
Training loss: 0.040895409882068634
Validation loss: 1.3879175878340198

Epoch: 6| Step: 10
Training loss: 0.04397523030638695
Validation loss: 1.403640261260412

Epoch: 6| Step: 11
Training loss: 0.03314525634050369
Validation loss: 1.3953637230780818

Epoch: 6| Step: 12
Training loss: 0.029978511855006218
Validation loss: 1.3846155110225882

Epoch: 6| Step: 13
Training loss: 0.02257637493312359
Validation loss: 1.4038844352127404

Epoch: 724| Step: 0
Training loss: 0.03524918854236603
Validation loss: 1.3890695725717852

Epoch: 6| Step: 1
Training loss: 0.03138837218284607
Validation loss: 1.385680353769692

Epoch: 6| Step: 2
Training loss: 0.04080170392990112
Validation loss: 1.3865177669832784

Epoch: 6| Step: 3
Training loss: 0.05202484875917435
Validation loss: 1.3740035385213873

Epoch: 6| Step: 4
Training loss: 0.044845595955848694
Validation loss: 1.379126666694559

Epoch: 6| Step: 5
Training loss: 0.039622388780117035
Validation loss: 1.3640451956820745

Epoch: 6| Step: 6
Training loss: 0.042813051491975784
Validation loss: 1.3612836163531068

Epoch: 6| Step: 7
Training loss: 0.04935717582702637
Validation loss: 1.3637000027523245

Epoch: 6| Step: 8
Training loss: 0.06097347289323807
Validation loss: 1.3787402927234609

Epoch: 6| Step: 9
Training loss: 0.03957194834947586
Validation loss: 1.3675325378294914

Epoch: 6| Step: 10
Training loss: 0.04047442227602005
Validation loss: 1.3673354964102469

Epoch: 6| Step: 11
Training loss: 0.04099591076374054
Validation loss: 1.3878071718318488

Epoch: 6| Step: 12
Training loss: 0.047011494636535645
Validation loss: 1.400035987618149

Epoch: 6| Step: 13
Training loss: 0.06350970268249512
Validation loss: 1.3849517090987133

Epoch: 725| Step: 0
Training loss: 0.04538390785455704
Validation loss: 1.3883445429545578

Epoch: 6| Step: 1
Training loss: 0.03890325874090195
Validation loss: 1.3921938916688323

Epoch: 6| Step: 2
Training loss: 0.03174729272723198
Validation loss: 1.392667531967163

Epoch: 6| Step: 3
Training loss: 0.041642770171165466
Validation loss: 1.3893751534082557

Epoch: 6| Step: 4
Training loss: 0.0346396304666996
Validation loss: 1.3894467302547988

Epoch: 6| Step: 5
Training loss: 0.04750113934278488
Validation loss: 1.4056990114591454

Epoch: 6| Step: 6
Training loss: 0.038716137409210205
Validation loss: 1.3926736218954927

Epoch: 6| Step: 7
Training loss: 0.03492758423089981
Validation loss: 1.3863506804230392

Epoch: 6| Step: 8
Training loss: 0.03170771524310112
Validation loss: 1.3765406108671618

Epoch: 6| Step: 9
Training loss: 0.04835931956768036
Validation loss: 1.3841001179910475

Epoch: 6| Step: 10
Training loss: 0.031028375029563904
Validation loss: 1.367256749060846

Epoch: 6| Step: 11
Training loss: 0.03315988928079605
Validation loss: 1.3404475187742582

Epoch: 6| Step: 12
Training loss: 0.051698699593544006
Validation loss: 1.3456364267615861

Epoch: 6| Step: 13
Training loss: 0.04184640198945999
Validation loss: 1.3519307849227742

Epoch: 726| Step: 0
Training loss: 0.048256851732730865
Validation loss: 1.3466665103871336

Epoch: 6| Step: 1
Training loss: 0.05646207928657532
Validation loss: 1.3806066897607618

Epoch: 6| Step: 2
Training loss: 0.020747054368257523
Validation loss: 1.358388468783389

Epoch: 6| Step: 3
Training loss: 0.04917050153017044
Validation loss: 1.361870309358002

Epoch: 6| Step: 4
Training loss: 0.03152026608586311
Validation loss: 1.358869965358447

Epoch: 6| Step: 5
Training loss: 0.054589033126831055
Validation loss: 1.378405229378772

Epoch: 6| Step: 6
Training loss: 0.040983155369758606
Validation loss: 1.383414484480376

Epoch: 6| Step: 7
Training loss: 0.04324585944414139
Validation loss: 1.3710362013950144

Epoch: 6| Step: 8
Training loss: 0.050211768597364426
Validation loss: 1.377725721687399

Epoch: 6| Step: 9
Training loss: 0.04187634959816933
Validation loss: 1.361088031081743

Epoch: 6| Step: 10
Training loss: 0.041222475469112396
Validation loss: 1.3631684972393898

Epoch: 6| Step: 11
Training loss: 0.021133549511432648
Validation loss: 1.354695031078913

Epoch: 6| Step: 12
Training loss: 0.03706548362970352
Validation loss: 1.3764521537288543

Epoch: 6| Step: 13
Training loss: 0.05183111131191254
Validation loss: 1.381648181587137

Epoch: 727| Step: 0
Training loss: 0.022901063784956932
Validation loss: 1.3764133350823515

Epoch: 6| Step: 1
Training loss: 0.02545318938791752
Validation loss: 1.3619092754138413

Epoch: 6| Step: 2
Training loss: 0.03282443806529045
Validation loss: 1.3607077957481466

Epoch: 6| Step: 3
Training loss: 0.041512392461299896
Validation loss: 1.3630617267342025

Epoch: 6| Step: 4
Training loss: 0.032288096845149994
Validation loss: 1.3736497099681566

Epoch: 6| Step: 5
Training loss: 0.04193386435508728
Validation loss: 1.3729649205361643

Epoch: 6| Step: 6
Training loss: 0.03888558968901634
Validation loss: 1.3720740374698435

Epoch: 6| Step: 7
Training loss: 0.03512679785490036
Validation loss: 1.3833419097367154

Epoch: 6| Step: 8
Training loss: 0.0377279594540596
Validation loss: 1.3705604473749797

Epoch: 6| Step: 9
Training loss: 0.059475578367710114
Validation loss: 1.3815645735750917

Epoch: 6| Step: 10
Training loss: 0.03919311612844467
Validation loss: 1.3587598794250078

Epoch: 6| Step: 11
Training loss: 0.03962071239948273
Validation loss: 1.3595336406461653

Epoch: 6| Step: 12
Training loss: 0.0415693074464798
Validation loss: 1.3761411046469083

Epoch: 6| Step: 13
Training loss: 0.04984690248966217
Validation loss: 1.3666053113117014

Epoch: 728| Step: 0
Training loss: 0.05163359269499779
Validation loss: 1.3535409896604476

Epoch: 6| Step: 1
Training loss: 0.024753138422966003
Validation loss: 1.36522840428096

Epoch: 6| Step: 2
Training loss: 0.039985790848731995
Validation loss: 1.3604864458883963

Epoch: 6| Step: 3
Training loss: 0.04346317797899246
Validation loss: 1.3844003408185896

Epoch: 6| Step: 4
Training loss: 0.05009472370147705
Validation loss: 1.358495379006991

Epoch: 6| Step: 5
Training loss: 0.038768917322158813
Validation loss: 1.370111314199304

Epoch: 6| Step: 6
Training loss: 0.03137541562318802
Validation loss: 1.3866678425060806

Epoch: 6| Step: 7
Training loss: 0.04051084816455841
Validation loss: 1.38612352648089

Epoch: 6| Step: 8
Training loss: 0.038242824375629425
Validation loss: 1.379411175686826

Epoch: 6| Step: 9
Training loss: 0.030577201396226883
Validation loss: 1.3800758238761657

Epoch: 6| Step: 10
Training loss: 0.045268669724464417
Validation loss: 1.384448908029064

Epoch: 6| Step: 11
Training loss: 0.039249978959560394
Validation loss: 1.3644339987026748

Epoch: 6| Step: 12
Training loss: 0.03927665948867798
Validation loss: 1.382156313106578

Epoch: 6| Step: 13
Training loss: 0.03168562427163124
Validation loss: 1.3859765952633274

Epoch: 729| Step: 0
Training loss: 0.02928318828344345
Validation loss: 1.3752066089260964

Epoch: 6| Step: 1
Training loss: 0.049932386726140976
Validation loss: 1.3804616364099647

Epoch: 6| Step: 2
Training loss: 0.03332659602165222
Validation loss: 1.3750367113339004

Epoch: 6| Step: 3
Training loss: 0.043623186647892
Validation loss: 1.3852831176532212

Epoch: 6| Step: 4
Training loss: 0.01618475839495659
Validation loss: 1.3621630143093806

Epoch: 6| Step: 5
Training loss: 0.049367643892765045
Validation loss: 1.36101480068699

Epoch: 6| Step: 6
Training loss: 0.03917664289474487
Validation loss: 1.3493119298770864

Epoch: 6| Step: 7
Training loss: 0.04122398793697357
Validation loss: 1.3495965324422365

Epoch: 6| Step: 8
Training loss: 0.04956340044736862
Validation loss: 1.3771518789311892

Epoch: 6| Step: 9
Training loss: 0.04128126800060272
Validation loss: 1.3690272370974224

Epoch: 6| Step: 10
Training loss: 0.03520753234624863
Validation loss: 1.3695972452881515

Epoch: 6| Step: 11
Training loss: 0.037490688264369965
Validation loss: 1.3659953045588669

Epoch: 6| Step: 12
Training loss: 0.02086799219250679
Validation loss: 1.3616524486131565

Epoch: 6| Step: 13
Training loss: 0.03519728407263756
Validation loss: 1.351435471606511

Epoch: 730| Step: 0
Training loss: 0.03599820286035538
Validation loss: 1.360859037727438

Epoch: 6| Step: 1
Training loss: 0.03844562545418739
Validation loss: 1.3621835657345351

Epoch: 6| Step: 2
Training loss: 0.06416144967079163
Validation loss: 1.3526341710039365

Epoch: 6| Step: 3
Training loss: 0.03772580996155739
Validation loss: 1.3596758547649588

Epoch: 6| Step: 4
Training loss: 0.06061139702796936
Validation loss: 1.3740472011668707

Epoch: 6| Step: 5
Training loss: 0.04019448161125183
Validation loss: 1.345922677747665

Epoch: 6| Step: 6
Training loss: 0.04010161757469177
Validation loss: 1.3600075603813253

Epoch: 6| Step: 7
Training loss: 0.02173343300819397
Validation loss: 1.3623372047178206

Epoch: 6| Step: 8
Training loss: 0.029455116018652916
Validation loss: 1.3778137910750605

Epoch: 6| Step: 9
Training loss: 0.0365615040063858
Validation loss: 1.37669982705065

Epoch: 6| Step: 10
Training loss: 0.029277443885803223
Validation loss: 1.3757072200057328

Epoch: 6| Step: 11
Training loss: 0.05400317907333374
Validation loss: 1.4070366608199252

Epoch: 6| Step: 12
Training loss: 0.043154001235961914
Validation loss: 1.39235992329095

Epoch: 6| Step: 13
Training loss: 0.04171087220311165
Validation loss: 1.3854001196481849

Epoch: 731| Step: 0
Training loss: 0.03918398916721344
Validation loss: 1.377823660450597

Epoch: 6| Step: 1
Training loss: 0.03223948925733566
Validation loss: 1.4043160061682425

Epoch: 6| Step: 2
Training loss: 0.041178345680236816
Validation loss: 1.3861730265361007

Epoch: 6| Step: 3
Training loss: 0.05428300425410271
Validation loss: 1.3969600610835577

Epoch: 6| Step: 4
Training loss: 0.052167825400829315
Validation loss: 1.3941800273874754

Epoch: 6| Step: 5
Training loss: 0.04411930590867996
Validation loss: 1.3842201502092424

Epoch: 6| Step: 6
Training loss: 0.03802776336669922
Validation loss: 1.3944051240080146

Epoch: 6| Step: 7
Training loss: 0.04222554713487625
Validation loss: 1.410867259066592

Epoch: 6| Step: 8
Training loss: 0.037941932678222656
Validation loss: 1.388096103104212

Epoch: 6| Step: 9
Training loss: 0.04316478967666626
Validation loss: 1.3793497367571759

Epoch: 6| Step: 10
Training loss: 0.031669020652770996
Validation loss: 1.396727147922721

Epoch: 6| Step: 11
Training loss: 0.04372081905603409
Validation loss: 1.3801046661151353

Epoch: 6| Step: 12
Training loss: 0.05054246634244919
Validation loss: 1.377065255436846

Epoch: 6| Step: 13
Training loss: 0.04880407825112343
Validation loss: 1.3948933001487487

Epoch: 732| Step: 0
Training loss: 0.04065816476941109
Validation loss: 1.3855208562266441

Epoch: 6| Step: 1
Training loss: 0.042852915823459625
Validation loss: 1.3849052280508063

Epoch: 6| Step: 2
Training loss: 0.049508605152368546
Validation loss: 1.3872326330472065

Epoch: 6| Step: 3
Training loss: 0.04020296037197113
Validation loss: 1.3885111475503573

Epoch: 6| Step: 4
Training loss: 0.04374237358570099
Validation loss: 1.3630835022977603

Epoch: 6| Step: 5
Training loss: 0.026972398161888123
Validation loss: 1.3787362024348269

Epoch: 6| Step: 6
Training loss: 0.020677044987678528
Validation loss: 1.3754760796023953

Epoch: 6| Step: 7
Training loss: 0.04430416226387024
Validation loss: 1.3773734915641047

Epoch: 6| Step: 8
Training loss: 0.0391496866941452
Validation loss: 1.3634609932540565

Epoch: 6| Step: 9
Training loss: 0.032125748693943024
Validation loss: 1.3594323537682975

Epoch: 6| Step: 10
Training loss: 0.04547043889760971
Validation loss: 1.3515653943502774

Epoch: 6| Step: 11
Training loss: 0.05661133676767349
Validation loss: 1.3640131450468493

Epoch: 6| Step: 12
Training loss: 0.041799694299697876
Validation loss: 1.3505926414202618

Epoch: 6| Step: 13
Training loss: 0.022441016510128975
Validation loss: 1.3621937767151864

Epoch: 733| Step: 0
Training loss: 0.03586047887802124
Validation loss: 1.3548659009318198

Epoch: 6| Step: 1
Training loss: 0.03458097204566002
Validation loss: 1.3412161757869105

Epoch: 6| Step: 2
Training loss: 0.03700917214155197
Validation loss: 1.3431207415878132

Epoch: 6| Step: 3
Training loss: 0.03197993338108063
Validation loss: 1.3506793001646638

Epoch: 6| Step: 4
Training loss: 0.049547020345926285
Validation loss: 1.3415374070085504

Epoch: 6| Step: 5
Training loss: 0.03773139789700508
Validation loss: 1.3500447145072363

Epoch: 6| Step: 6
Training loss: 0.04198354482650757
Validation loss: 1.3372560624153382

Epoch: 6| Step: 7
Training loss: 0.04969999939203262
Validation loss: 1.343924169899315

Epoch: 6| Step: 8
Training loss: 0.047481078654527664
Validation loss: 1.354622935736051

Epoch: 6| Step: 9
Training loss: 0.034495338797569275
Validation loss: 1.3574165490365797

Epoch: 6| Step: 10
Training loss: 0.035049039870500565
Validation loss: 1.3627831064244753

Epoch: 6| Step: 11
Training loss: 0.028887443244457245
Validation loss: 1.3416987696001608

Epoch: 6| Step: 12
Training loss: 0.041885390877723694
Validation loss: 1.3564704477146108

Epoch: 6| Step: 13
Training loss: 0.025810910388827324
Validation loss: 1.3557407599623486

Epoch: 734| Step: 0
Training loss: 0.02650071494281292
Validation loss: 1.3686975868799354

Epoch: 6| Step: 1
Training loss: 0.04548477381467819
Validation loss: 1.3657668354690715

Epoch: 6| Step: 2
Training loss: 0.034781038761138916
Validation loss: 1.3505770583306589

Epoch: 6| Step: 3
Training loss: 0.04953242093324661
Validation loss: 1.348797821229504

Epoch: 6| Step: 4
Training loss: 0.04601723700761795
Validation loss: 1.3564530790493052

Epoch: 6| Step: 5
Training loss: 0.03112432360649109
Validation loss: 1.359349218107039

Epoch: 6| Step: 6
Training loss: 0.037208959460258484
Validation loss: 1.3527735728089527

Epoch: 6| Step: 7
Training loss: 0.03634696453809738
Validation loss: 1.3521696713662916

Epoch: 6| Step: 8
Training loss: 0.025562450289726257
Validation loss: 1.351072463937985

Epoch: 6| Step: 9
Training loss: 0.031784795224666595
Validation loss: 1.3538927051328844

Epoch: 6| Step: 10
Training loss: 0.03114353120326996
Validation loss: 1.3621496769689745

Epoch: 6| Step: 11
Training loss: 0.02484302967786789
Validation loss: 1.3591297890550347

Epoch: 6| Step: 12
Training loss: 0.03248430788516998
Validation loss: 1.3472826339865243

Epoch: 6| Step: 13
Training loss: 0.04273105040192604
Validation loss: 1.3511092009082917

Epoch: 735| Step: 0
Training loss: 0.039876293390989304
Validation loss: 1.3418836420582188

Epoch: 6| Step: 1
Training loss: 0.028465887531638145
Validation loss: 1.3514271974563599

Epoch: 6| Step: 2
Training loss: 0.031603530049324036
Validation loss: 1.3276751502867667

Epoch: 6| Step: 3
Training loss: 0.042719751596450806
Validation loss: 1.3571503611021145

Epoch: 6| Step: 4
Training loss: 0.026588721200823784
Validation loss: 1.3434066362278436

Epoch: 6| Step: 5
Training loss: 0.04828888177871704
Validation loss: 1.3342644617121706

Epoch: 6| Step: 6
Training loss: 0.040983736515045166
Validation loss: 1.3484158387748144

Epoch: 6| Step: 7
Training loss: 0.025221774354577065
Validation loss: 1.3611782141911086

Epoch: 6| Step: 8
Training loss: 0.04513855278491974
Validation loss: 1.3528136296938824

Epoch: 6| Step: 9
Training loss: 0.03464692831039429
Validation loss: 1.3753815261266564

Epoch: 6| Step: 10
Training loss: 0.0645553320646286
Validation loss: 1.3816459871107531

Epoch: 6| Step: 11
Training loss: 0.0597115084528923
Validation loss: 1.3566207879333085

Epoch: 6| Step: 12
Training loss: 0.022406157106161118
Validation loss: 1.3549672301097582

Epoch: 6| Step: 13
Training loss: 0.05093898996710777
Validation loss: 1.3733675966980636

Epoch: 736| Step: 0
Training loss: 0.03407604619860649
Validation loss: 1.3734299264928347

Epoch: 6| Step: 1
Training loss: 0.02085041254758835
Validation loss: 1.3551341141423872

Epoch: 6| Step: 2
Training loss: 0.04596775770187378
Validation loss: 1.3641560949305052

Epoch: 6| Step: 3
Training loss: 0.038379594683647156
Validation loss: 1.3686045010884602

Epoch: 6| Step: 4
Training loss: 0.02903987653553486
Validation loss: 1.3558738026567685

Epoch: 6| Step: 5
Training loss: 0.02296810783445835
Validation loss: 1.3802716994798312

Epoch: 6| Step: 6
Training loss: 0.017609689384698868
Validation loss: 1.3626201447620188

Epoch: 6| Step: 7
Training loss: 0.0492434948682785
Validation loss: 1.3687934529396795

Epoch: 6| Step: 8
Training loss: 0.04237931966781616
Validation loss: 1.3644582186975787

Epoch: 6| Step: 9
Training loss: 0.0783284604549408
Validation loss: 1.366981166665272

Epoch: 6| Step: 10
Training loss: 0.0319954976439476
Validation loss: 1.3732207321351575

Epoch: 6| Step: 11
Training loss: 0.04169207438826561
Validation loss: 1.3756265710758906

Epoch: 6| Step: 12
Training loss: 0.05061069875955582
Validation loss: 1.3667865863410376

Epoch: 6| Step: 13
Training loss: 0.04603695869445801
Validation loss: 1.3704168117174538

Epoch: 737| Step: 0
Training loss: 0.04352957382798195
Validation loss: 1.361099321355102

Epoch: 6| Step: 1
Training loss: 0.04141226410865784
Validation loss: 1.355566716963245

Epoch: 6| Step: 2
Training loss: 0.03653945028781891
Validation loss: 1.3684230260951544

Epoch: 6| Step: 3
Training loss: 0.04033280164003372
Validation loss: 1.3634698852416007

Epoch: 6| Step: 4
Training loss: 0.052010662853717804
Validation loss: 1.3692083704856135

Epoch: 6| Step: 5
Training loss: 0.030865639448165894
Validation loss: 1.3686649440437235

Epoch: 6| Step: 6
Training loss: 0.047008540481328964
Validation loss: 1.368479500534714

Epoch: 6| Step: 7
Training loss: 0.023642880842089653
Validation loss: 1.3915701011816661

Epoch: 6| Step: 8
Training loss: 0.044279322028160095
Validation loss: 1.3727049302029353

Epoch: 6| Step: 9
Training loss: 0.021177325397729874
Validation loss: 1.3666391231680428

Epoch: 6| Step: 10
Training loss: 0.043657053261995316
Validation loss: 1.3663002207715025

Epoch: 6| Step: 11
Training loss: 0.032202985137701035
Validation loss: 1.3866776721451872

Epoch: 6| Step: 12
Training loss: 0.04135967046022415
Validation loss: 1.364718766622646

Epoch: 6| Step: 13
Training loss: 0.03330068290233612
Validation loss: 1.3558693739675707

Epoch: 738| Step: 0
Training loss: 0.059774044901132584
Validation loss: 1.3537645891148558

Epoch: 6| Step: 1
Training loss: 0.026011154055595398
Validation loss: 1.3541000882784526

Epoch: 6| Step: 2
Training loss: 0.05132831633090973
Validation loss: 1.347639868336339

Epoch: 6| Step: 3
Training loss: 0.04721296578645706
Validation loss: 1.3586326517084593

Epoch: 6| Step: 4
Training loss: 0.07288803160190582
Validation loss: 1.3650114337603252

Epoch: 6| Step: 5
Training loss: 0.08742453157901764
Validation loss: 1.3512502742070023

Epoch: 6| Step: 6
Training loss: 0.061837367713451385
Validation loss: 1.3502197534807268

Epoch: 6| Step: 7
Training loss: 0.03265625983476639
Validation loss: 1.3494700193405151

Epoch: 6| Step: 8
Training loss: 0.036346301436424255
Validation loss: 1.3419938632237014

Epoch: 6| Step: 9
Training loss: 0.03805440291762352
Validation loss: 1.348398599573361

Epoch: 6| Step: 10
Training loss: 0.04149642959237099
Validation loss: 1.3390874798579881

Epoch: 6| Step: 11
Training loss: 0.0364447757601738
Validation loss: 1.3474338734021751

Epoch: 6| Step: 12
Training loss: 0.03934597223997116
Validation loss: 1.3331296020938503

Epoch: 6| Step: 13
Training loss: 0.04655546694993973
Validation loss: 1.3396890676149757

Epoch: 739| Step: 0
Training loss: 0.03739665821194649
Validation loss: 1.342686035940724

Epoch: 6| Step: 1
Training loss: 0.027916327118873596
Validation loss: 1.3404558371472102

Epoch: 6| Step: 2
Training loss: 0.04128354415297508
Validation loss: 1.3515974936946746

Epoch: 6| Step: 3
Training loss: 0.0332917645573616
Validation loss: 1.3419147037690686

Epoch: 6| Step: 4
Training loss: 0.04269397258758545
Validation loss: 1.3471114122739403

Epoch: 6| Step: 5
Training loss: 0.04439399391412735
Validation loss: 1.3426404947875648

Epoch: 6| Step: 6
Training loss: 0.02974054217338562
Validation loss: 1.3304302756504347

Epoch: 6| Step: 7
Training loss: 0.06713203340768814
Validation loss: 1.348344765683656

Epoch: 6| Step: 8
Training loss: 0.03709328547120094
Validation loss: 1.3458550604440833

Epoch: 6| Step: 9
Training loss: 0.044686026871204376
Validation loss: 1.3157324047498806

Epoch: 6| Step: 10
Training loss: 0.05342257767915726
Validation loss: 1.3397689698844828

Epoch: 6| Step: 11
Training loss: 0.038169313222169876
Validation loss: 1.330581122829068

Epoch: 6| Step: 12
Training loss: 0.032782722264528275
Validation loss: 1.3259416536618305

Epoch: 6| Step: 13
Training loss: 0.03000032901763916
Validation loss: 1.3297252046164645

Epoch: 740| Step: 0
Training loss: 0.04005161672830582
Validation loss: 1.326295393769459

Epoch: 6| Step: 1
Training loss: 0.03284618258476257
Validation loss: 1.338264730668837

Epoch: 6| Step: 2
Training loss: 0.03522025793790817
Validation loss: 1.3413613701379428

Epoch: 6| Step: 3
Training loss: 0.052569679915905
Validation loss: 1.3446767817261398

Epoch: 6| Step: 4
Training loss: 0.016882240772247314
Validation loss: 1.3594158304634916

Epoch: 6| Step: 5
Training loss: 0.01722458377480507
Validation loss: 1.3731168470075052

Epoch: 6| Step: 6
Training loss: 0.04692264646291733
Validation loss: 1.3472550543405677

Epoch: 6| Step: 7
Training loss: 0.046013448387384415
Validation loss: 1.351996870451076

Epoch: 6| Step: 8
Training loss: 0.03696238249540329
Validation loss: 1.3652659103434572

Epoch: 6| Step: 9
Training loss: 0.04876955971121788
Validation loss: 1.3621026085269066

Epoch: 6| Step: 10
Training loss: 0.05301101505756378
Validation loss: 1.3532874481652373

Epoch: 6| Step: 11
Training loss: 0.03148157149553299
Validation loss: 1.3806193535045912

Epoch: 6| Step: 12
Training loss: 0.050020039081573486
Validation loss: 1.3743825061346895

Epoch: 6| Step: 13
Training loss: 0.04929138720035553
Validation loss: 1.3831390450077672

Epoch: 741| Step: 0
Training loss: 0.059873756021261215
Validation loss: 1.3730572551809332

Epoch: 6| Step: 1
Training loss: 0.03323662281036377
Validation loss: 1.370490829149882

Epoch: 6| Step: 2
Training loss: 0.041918691247701645
Validation loss: 1.3738344273259562

Epoch: 6| Step: 3
Training loss: 0.05263689160346985
Validation loss: 1.3768954014265409

Epoch: 6| Step: 4
Training loss: 0.034527771174907684
Validation loss: 1.3847459875127321

Epoch: 6| Step: 5
Training loss: 0.05670478940010071
Validation loss: 1.374797151934716

Epoch: 6| Step: 6
Training loss: 0.03464091569185257
Validation loss: 1.3942215417021064

Epoch: 6| Step: 7
Training loss: 0.03908447548747063
Validation loss: 1.3933302215350571

Epoch: 6| Step: 8
Training loss: 0.03368980437517166
Validation loss: 1.4009468170904344

Epoch: 6| Step: 9
Training loss: 0.055782318115234375
Validation loss: 1.3910594089056856

Epoch: 6| Step: 10
Training loss: 0.03397892042994499
Validation loss: 1.3957353022790724

Epoch: 6| Step: 11
Training loss: 0.05620379000902176
Validation loss: 1.403599077655423

Epoch: 6| Step: 12
Training loss: 0.039806000888347626
Validation loss: 1.3956522403224823

Epoch: 6| Step: 13
Training loss: 0.04026789218187332
Validation loss: 1.400490241665994

Epoch: 742| Step: 0
Training loss: 0.04492980241775513
Validation loss: 1.4192405439192248

Epoch: 6| Step: 1
Training loss: 0.027208955958485603
Validation loss: 1.4101462671833653

Epoch: 6| Step: 2
Training loss: 0.040263831615448
Validation loss: 1.4128786722819011

Epoch: 6| Step: 3
Training loss: 0.06348932534456253
Validation loss: 1.4000747434554561

Epoch: 6| Step: 4
Training loss: 0.04885371774435043
Validation loss: 1.387907753708542

Epoch: 6| Step: 5
Training loss: 0.06459526717662811
Validation loss: 1.4088697279653242

Epoch: 6| Step: 6
Training loss: 0.05235715210437775
Validation loss: 1.3940298275281024

Epoch: 6| Step: 7
Training loss: 0.030998852103948593
Validation loss: 1.3818697993473341

Epoch: 6| Step: 8
Training loss: 0.04846654832363129
Validation loss: 1.3706710351410734

Epoch: 6| Step: 9
Training loss: 0.03696633130311966
Validation loss: 1.3693361615621915

Epoch: 6| Step: 10
Training loss: 0.039342090487480164
Validation loss: 1.3689619956477996

Epoch: 6| Step: 11
Training loss: 0.05022665858268738
Validation loss: 1.3621453174980738

Epoch: 6| Step: 12
Training loss: 0.032858021557331085
Validation loss: 1.3734916281956497

Epoch: 6| Step: 13
Training loss: 0.03260396793484688
Validation loss: 1.363810408499933

Epoch: 743| Step: 0
Training loss: 0.04411165788769722
Validation loss: 1.366125342666462

Epoch: 6| Step: 1
Training loss: 0.06354209035634995
Validation loss: 1.3497704152138001

Epoch: 6| Step: 2
Training loss: 0.03778054937720299
Validation loss: 1.3715594378850793

Epoch: 6| Step: 3
Training loss: 0.059468209743499756
Validation loss: 1.3564179815271848

Epoch: 6| Step: 4
Training loss: 0.037754423916339874
Validation loss: 1.365576086505767

Epoch: 6| Step: 5
Training loss: 0.032900966703891754
Validation loss: 1.358972450738312

Epoch: 6| Step: 6
Training loss: 0.048376135528087616
Validation loss: 1.3576415841297438

Epoch: 6| Step: 7
Training loss: 0.08105029165744781
Validation loss: 1.3521887717708465

Epoch: 6| Step: 8
Training loss: 0.053226131945848465
Validation loss: 1.3431936989548385

Epoch: 6| Step: 9
Training loss: 0.04254259169101715
Validation loss: 1.356181057550574

Epoch: 6| Step: 10
Training loss: 0.024488959461450577
Validation loss: 1.3656584191065964

Epoch: 6| Step: 11
Training loss: 0.02975825034081936
Validation loss: 1.3692742342590003

Epoch: 6| Step: 12
Training loss: 0.048435695469379425
Validation loss: 1.3787358422433176

Epoch: 6| Step: 13
Training loss: 0.07946675270795822
Validation loss: 1.3941193511409145

Epoch: 744| Step: 0
Training loss: 0.07368474453687668
Validation loss: 1.3934839531298606

Epoch: 6| Step: 1
Training loss: 0.0643690899014473
Validation loss: 1.3901549616167623

Epoch: 6| Step: 2
Training loss: 0.07321378588676453
Validation loss: 1.3949435680143294

Epoch: 6| Step: 3
Training loss: 0.06088635325431824
Validation loss: 1.3948121416953303

Epoch: 6| Step: 4
Training loss: 0.04075397551059723
Validation loss: 1.3798269699978571

Epoch: 6| Step: 5
Training loss: 0.04147417098283768
Validation loss: 1.3743872232334589

Epoch: 6| Step: 6
Training loss: 0.05552111566066742
Validation loss: 1.363434459573479

Epoch: 6| Step: 7
Training loss: 0.0497346930205822
Validation loss: 1.378571501342199

Epoch: 6| Step: 8
Training loss: 0.05658619850873947
Validation loss: 1.352122119677964

Epoch: 6| Step: 9
Training loss: 0.058896504342556
Validation loss: 1.3396079296706824

Epoch: 6| Step: 10
Training loss: 0.07495550811290741
Validation loss: 1.3545401096343994

Epoch: 6| Step: 11
Training loss: 0.04988092929124832
Validation loss: 1.3420261356138414

Epoch: 6| Step: 12
Training loss: 0.05520189553499222
Validation loss: 1.3763215477748583

Epoch: 6| Step: 13
Training loss: 0.03917491436004639
Validation loss: 1.3865786662665747

Epoch: 745| Step: 0
Training loss: 0.060993194580078125
Validation loss: 1.3751692554002166

Epoch: 6| Step: 1
Training loss: 0.054458290338516235
Validation loss: 1.381838616504464

Epoch: 6| Step: 2
Training loss: 0.042845726013183594
Validation loss: 1.3790890721864597

Epoch: 6| Step: 3
Training loss: 0.07494091987609863
Validation loss: 1.4069816656010126

Epoch: 6| Step: 4
Training loss: 0.059851549565792084
Validation loss: 1.396663991353845

Epoch: 6| Step: 5
Training loss: 0.04152003303170204
Validation loss: 1.4037715106882074

Epoch: 6| Step: 6
Training loss: 0.03438122570514679
Validation loss: 1.3965596011889878

Epoch: 6| Step: 7
Training loss: 0.041992828249931335
Validation loss: 1.4026038723607217

Epoch: 6| Step: 8
Training loss: 0.05028396099805832
Validation loss: 1.3961456591083157

Epoch: 6| Step: 9
Training loss: 0.027371348813176155
Validation loss: 1.3836608638045609

Epoch: 6| Step: 10
Training loss: 0.06697119772434235
Validation loss: 1.3719558844002344

Epoch: 6| Step: 11
Training loss: 0.038564134389162064
Validation loss: 1.3627928585134528

Epoch: 6| Step: 12
Training loss: 0.06701846420764923
Validation loss: 1.365704401846855

Epoch: 6| Step: 13
Training loss: 0.04876318573951721
Validation loss: 1.3838396585115822

Epoch: 746| Step: 0
Training loss: 0.02466449700295925
Validation loss: 1.3790395721312492

Epoch: 6| Step: 1
Training loss: 0.04630979895591736
Validation loss: 1.3846400540362123

Epoch: 6| Step: 2
Training loss: 0.045732565224170685
Validation loss: 1.37029884066633

Epoch: 6| Step: 3
Training loss: 0.047023750841617584
Validation loss: 1.3580712374820505

Epoch: 6| Step: 4
Training loss: 0.05419021472334862
Validation loss: 1.3500463443417703

Epoch: 6| Step: 5
Training loss: 0.05758360028266907
Validation loss: 1.3712022048170849

Epoch: 6| Step: 6
Training loss: 0.07314333319664001
Validation loss: 1.3675803830546718

Epoch: 6| Step: 7
Training loss: 0.04938137158751488
Validation loss: 1.375304091361261

Epoch: 6| Step: 8
Training loss: 0.04254244267940521
Validation loss: 1.361526903285775

Epoch: 6| Step: 9
Training loss: 0.043135009706020355
Validation loss: 1.3668996095657349

Epoch: 6| Step: 10
Training loss: 0.04465562477707863
Validation loss: 1.351799694440698

Epoch: 6| Step: 11
Training loss: 0.060500260442495346
Validation loss: 1.3652452371453727

Epoch: 6| Step: 12
Training loss: 0.036363162100315094
Validation loss: 1.3594817461506012

Epoch: 6| Step: 13
Training loss: 0.049824610352516174
Validation loss: 1.3573062855710265

Epoch: 747| Step: 0
Training loss: 0.05093054845929146
Validation loss: 1.3509395596801594

Epoch: 6| Step: 1
Training loss: 0.0804433673620224
Validation loss: 1.3662899803089839

Epoch: 6| Step: 2
Training loss: 0.06000487506389618
Validation loss: 1.3733361639002317

Epoch: 6| Step: 3
Training loss: 0.0778682604432106
Validation loss: 1.366648261265088

Epoch: 6| Step: 4
Training loss: 0.031606778502464294
Validation loss: 1.3855101235451237

Epoch: 6| Step: 5
Training loss: 0.03480450436472893
Validation loss: 1.3957976782193748

Epoch: 6| Step: 6
Training loss: 0.056493692100048065
Validation loss: 1.3879165623777656

Epoch: 6| Step: 7
Training loss: 0.027550581842660904
Validation loss: 1.3885577026233877

Epoch: 6| Step: 8
Training loss: 0.03773215785622597
Validation loss: 1.3896012319031583

Epoch: 6| Step: 9
Training loss: 0.04620350897312164
Validation loss: 1.37969010683798

Epoch: 6| Step: 10
Training loss: 0.03815489262342453
Validation loss: 1.3546354937297043

Epoch: 6| Step: 11
Training loss: 0.03947027400135994
Validation loss: 1.3734095141451845

Epoch: 6| Step: 12
Training loss: 0.03415684401988983
Validation loss: 1.3756383067818099

Epoch: 6| Step: 13
Training loss: 0.03901321440935135
Validation loss: 1.3552959401120421

Epoch: 748| Step: 0
Training loss: 0.05471644178032875
Validation loss: 1.3489351285401212

Epoch: 6| Step: 1
Training loss: 0.04718858748674393
Validation loss: 1.3537459514474357

Epoch: 6| Step: 2
Training loss: 0.08072592318058014
Validation loss: 1.350635866965017

Epoch: 6| Step: 3
Training loss: 0.05482611805200577
Validation loss: 1.3687874347932878

Epoch: 6| Step: 4
Training loss: 0.05569035932421684
Validation loss: 1.362072584449604

Epoch: 6| Step: 5
Training loss: 0.04543176293373108
Validation loss: 1.3648927493761944

Epoch: 6| Step: 6
Training loss: 0.040146373212337494
Validation loss: 1.386104763195079

Epoch: 6| Step: 7
Training loss: 0.050908949226140976
Validation loss: 1.3620612980217062

Epoch: 6| Step: 8
Training loss: 0.042359091341495514
Validation loss: 1.3820830340026526

Epoch: 6| Step: 9
Training loss: 0.04139145836234093
Validation loss: 1.3885566329443326

Epoch: 6| Step: 10
Training loss: 0.05537544935941696
Validation loss: 1.379300654575389

Epoch: 6| Step: 11
Training loss: 0.029704950749874115
Validation loss: 1.3649869413786038

Epoch: 6| Step: 12
Training loss: 0.02576277405023575
Validation loss: 1.3747354502319007

Epoch: 6| Step: 13
Training loss: 0.03007001429796219
Validation loss: 1.3735716906926965

Epoch: 749| Step: 0
Training loss: 0.05160843953490257
Validation loss: 1.3639353821354527

Epoch: 6| Step: 1
Training loss: 0.08235408365726471
Validation loss: 1.3678118118675806

Epoch: 6| Step: 2
Training loss: 0.023789655417203903
Validation loss: 1.3677667058924192

Epoch: 6| Step: 3
Training loss: 0.02295795828104019
Validation loss: 1.361765516701565

Epoch: 6| Step: 4
Training loss: 0.052817076444625854
Validation loss: 1.3641274577827864

Epoch: 6| Step: 5
Training loss: 0.02942940592765808
Validation loss: 1.3713066988093878

Epoch: 6| Step: 6
Training loss: 0.04551137238740921
Validation loss: 1.369252767614139

Epoch: 6| Step: 7
Training loss: 0.02629830874502659
Validation loss: 1.3550160546456613

Epoch: 6| Step: 8
Training loss: 0.050680890679359436
Validation loss: 1.3553048500450708

Epoch: 6| Step: 9
Training loss: 0.052596110850572586
Validation loss: 1.357071046547223

Epoch: 6| Step: 10
Training loss: 0.029011782258749008
Validation loss: 1.3503513002908358

Epoch: 6| Step: 11
Training loss: 0.04799468070268631
Validation loss: 1.3547485605362923

Epoch: 6| Step: 12
Training loss: 0.02361799031496048
Validation loss: 1.3688515027364094

Epoch: 6| Step: 13
Training loss: 0.029755553230643272
Validation loss: 1.351504801422037

Epoch: 750| Step: 0
Training loss: 0.03748705983161926
Validation loss: 1.3515887862892562

Epoch: 6| Step: 1
Training loss: 0.026429565623402596
Validation loss: 1.353666320923836

Epoch: 6| Step: 2
Training loss: 0.030438415706157684
Validation loss: 1.3374263317354265

Epoch: 6| Step: 3
Training loss: 0.03192751109600067
Validation loss: 1.3584127169783398

Epoch: 6| Step: 4
Training loss: 0.05408322811126709
Validation loss: 1.347161712185029

Epoch: 6| Step: 5
Training loss: 0.047943636775016785
Validation loss: 1.345540177437567

Epoch: 6| Step: 6
Training loss: 0.04506298154592514
Validation loss: 1.3444666849669589

Epoch: 6| Step: 7
Training loss: 0.04668445885181427
Validation loss: 1.3549713242438532

Epoch: 6| Step: 8
Training loss: 0.039764974266290665
Validation loss: 1.350333022814925

Epoch: 6| Step: 9
Training loss: 0.036064062267541885
Validation loss: 1.3344354514152772

Epoch: 6| Step: 10
Training loss: 0.03162883222103119
Validation loss: 1.3660344346877067

Epoch: 6| Step: 11
Training loss: 0.04142202064394951
Validation loss: 1.3607265090429654

Epoch: 6| Step: 12
Training loss: 0.043530724942684174
Validation loss: 1.3661698846406833

Epoch: 6| Step: 13
Training loss: 0.05922418087720871
Validation loss: 1.3727753418748097

Epoch: 751| Step: 0
Training loss: 0.038820017129182816
Validation loss: 1.3546157806150374

Epoch: 6| Step: 1
Training loss: 0.051880475133657455
Validation loss: 1.358235413669258

Epoch: 6| Step: 2
Training loss: 0.04784904047846794
Validation loss: 1.3607778113375428

Epoch: 6| Step: 3
Training loss: 0.023771358653903008
Validation loss: 1.352855952837134

Epoch: 6| Step: 4
Training loss: 0.03757653385400772
Validation loss: 1.3627306081915413

Epoch: 6| Step: 5
Training loss: 0.03800295293331146
Validation loss: 1.3409535359310847

Epoch: 6| Step: 6
Training loss: 0.04179222881793976
Validation loss: 1.3696883468217746

Epoch: 6| Step: 7
Training loss: 0.03656022623181343
Validation loss: 1.3681811927467264

Epoch: 6| Step: 8
Training loss: 0.02716163545846939
Validation loss: 1.3575555368136334

Epoch: 6| Step: 9
Training loss: 0.03797651082277298
Validation loss: 1.3523091064986361

Epoch: 6| Step: 10
Training loss: 0.03233569115400314
Validation loss: 1.3565816398589843

Epoch: 6| Step: 11
Training loss: 0.042340219020843506
Validation loss: 1.3700658518780944

Epoch: 6| Step: 12
Training loss: 0.05670199915766716
Validation loss: 1.3668187369582474

Epoch: 6| Step: 13
Training loss: 0.05082167685031891
Validation loss: 1.3842506677873674

Epoch: 752| Step: 0
Training loss: 0.035455942153930664
Validation loss: 1.3682939583255398

Epoch: 6| Step: 1
Training loss: 0.02532302960753441
Validation loss: 1.3807834438098374

Epoch: 6| Step: 2
Training loss: 0.038868822157382965
Validation loss: 1.3759332715824086

Epoch: 6| Step: 3
Training loss: 0.03145429491996765
Validation loss: 1.3705402151230843

Epoch: 6| Step: 4
Training loss: 0.03565560281276703
Validation loss: 1.379837215587657

Epoch: 6| Step: 5
Training loss: 0.03849421441555023
Validation loss: 1.369443198686005

Epoch: 6| Step: 6
Training loss: 0.04495304077863693
Validation loss: 1.3778266477328476

Epoch: 6| Step: 7
Training loss: 0.041979026049375534
Validation loss: 1.3720139636788318

Epoch: 6| Step: 8
Training loss: 0.04732149466872215
Validation loss: 1.3788506574528192

Epoch: 6| Step: 9
Training loss: 0.024148182943463326
Validation loss: 1.376071822258734

Epoch: 6| Step: 10
Training loss: 0.042528413236141205
Validation loss: 1.34860372671517

Epoch: 6| Step: 11
Training loss: 0.02832949534058571
Validation loss: 1.3805782577042938

Epoch: 6| Step: 12
Training loss: 0.038438763469457626
Validation loss: 1.3683601463994672

Epoch: 6| Step: 13
Training loss: 0.039912231266498566
Validation loss: 1.3811718174206313

Epoch: 753| Step: 0
Training loss: 0.03451113402843475
Validation loss: 1.39611949459199

Epoch: 6| Step: 1
Training loss: 0.02549539878964424
Validation loss: 1.396316587284047

Epoch: 6| Step: 2
Training loss: 0.05260191112756729
Validation loss: 1.383495875584182

Epoch: 6| Step: 3
Training loss: 0.03802584111690521
Validation loss: 1.3871374296885666

Epoch: 6| Step: 4
Training loss: 0.033623889088630676
Validation loss: 1.373481660760859

Epoch: 6| Step: 5
Training loss: 0.0353887602686882
Validation loss: 1.380880860872166

Epoch: 6| Step: 6
Training loss: 0.028936205431818962
Validation loss: 1.384418713149204

Epoch: 6| Step: 7
Training loss: 0.03495025262236595
Validation loss: 1.3749742136206677

Epoch: 6| Step: 8
Training loss: 0.038557201623916626
Validation loss: 1.3838493836823331

Epoch: 6| Step: 9
Training loss: 0.045489855110645294
Validation loss: 1.3840823199159356

Epoch: 6| Step: 10
Training loss: 0.03845898434519768
Validation loss: 1.3815204904925438

Epoch: 6| Step: 11
Training loss: 0.03520677611231804
Validation loss: 1.3863466901163901

Epoch: 6| Step: 12
Training loss: 0.04886773228645325
Validation loss: 1.3707749773097295

Epoch: 6| Step: 13
Training loss: 0.029613494873046875
Validation loss: 1.371007792411312

Epoch: 754| Step: 0
Training loss: 0.04178919643163681
Validation loss: 1.3685545972598496

Epoch: 6| Step: 1
Training loss: 0.048527106642723083
Validation loss: 1.349775424567602

Epoch: 6| Step: 2
Training loss: 0.032384924590587616
Validation loss: 1.3506539790861067

Epoch: 6| Step: 3
Training loss: 0.035105567425489426
Validation loss: 1.3501310438238165

Epoch: 6| Step: 4
Training loss: 0.04209991917014122
Validation loss: 1.354684042674239

Epoch: 6| Step: 5
Training loss: 0.07644858956336975
Validation loss: 1.361622057935243

Epoch: 6| Step: 6
Training loss: 0.05487048253417015
Validation loss: 1.3593265189919421

Epoch: 6| Step: 7
Training loss: 0.03127698600292206
Validation loss: 1.3542528690830353

Epoch: 6| Step: 8
Training loss: 0.04342706874012947
Validation loss: 1.3702226076074826

Epoch: 6| Step: 9
Training loss: 0.023082055151462555
Validation loss: 1.336478482010544

Epoch: 6| Step: 10
Training loss: 0.07091426104307175
Validation loss: 1.3618423144022624

Epoch: 6| Step: 11
Training loss: 0.029665343463420868
Validation loss: 1.3383428345444381

Epoch: 6| Step: 12
Training loss: 0.03815510869026184
Validation loss: 1.330045784673383

Epoch: 6| Step: 13
Training loss: 0.05268634855747223
Validation loss: 1.333418813443953

Epoch: 755| Step: 0
Training loss: 0.03596365824341774
Validation loss: 1.3569279806588286

Epoch: 6| Step: 1
Training loss: 0.03675632178783417
Validation loss: 1.3608507097408336

Epoch: 6| Step: 2
Training loss: 0.03893907368183136
Validation loss: 1.3562929431597393

Epoch: 6| Step: 3
Training loss: 0.0465506911277771
Validation loss: 1.373091402874198

Epoch: 6| Step: 4
Training loss: 0.040572311729192734
Validation loss: 1.376818193543342

Epoch: 6| Step: 5
Training loss: 0.05172701179981232
Validation loss: 1.3895347592651204

Epoch: 6| Step: 6
Training loss: 0.05864313989877701
Validation loss: 1.390969786592709

Epoch: 6| Step: 7
Training loss: 0.023890342563390732
Validation loss: 1.3872232373042772

Epoch: 6| Step: 8
Training loss: 0.038829345256090164
Validation loss: 1.3805126990041425

Epoch: 6| Step: 9
Training loss: 0.0303146131336689
Validation loss: 1.394488234673777

Epoch: 6| Step: 10
Training loss: 0.053394466638565063
Validation loss: 1.383243058317451

Epoch: 6| Step: 11
Training loss: 0.03350882977247238
Validation loss: 1.3865710919903171

Epoch: 6| Step: 12
Training loss: 0.042401812970638275
Validation loss: 1.391877414077841

Epoch: 6| Step: 13
Training loss: 0.054568931460380554
Validation loss: 1.3978794672155892

Epoch: 756| Step: 0
Training loss: 0.05919692665338516
Validation loss: 1.3760845904709191

Epoch: 6| Step: 1
Training loss: 0.05207578092813492
Validation loss: 1.371053211791541

Epoch: 6| Step: 2
Training loss: 0.04425536096096039
Validation loss: 1.3553146482795797

Epoch: 6| Step: 3
Training loss: 0.044277776032686234
Validation loss: 1.3598420043145456

Epoch: 6| Step: 4
Training loss: 0.04263172671198845
Validation loss: 1.3459929048374135

Epoch: 6| Step: 5
Training loss: 0.032394953072071075
Validation loss: 1.3545848592635124

Epoch: 6| Step: 6
Training loss: 0.05768824368715286
Validation loss: 1.3399774976955947

Epoch: 6| Step: 7
Training loss: 0.039571020752191544
Validation loss: 1.3407182449935584

Epoch: 6| Step: 8
Training loss: 0.08572635054588318
Validation loss: 1.3460452556610107

Epoch: 6| Step: 9
Training loss: 0.02702774852514267
Validation loss: 1.355106988901733

Epoch: 6| Step: 10
Training loss: 0.04100789502263069
Validation loss: 1.3690374717917493

Epoch: 6| Step: 11
Training loss: 0.03656730800867081
Validation loss: 1.3666882284225956

Epoch: 6| Step: 12
Training loss: 0.024964861571788788
Validation loss: 1.3590853855174074

Epoch: 6| Step: 13
Training loss: 0.073736771941185
Validation loss: 1.3670189496009582

Epoch: 757| Step: 0
Training loss: 0.03359691798686981
Validation loss: 1.3691539610585859

Epoch: 6| Step: 1
Training loss: 0.05193027853965759
Validation loss: 1.3635492491465744

Epoch: 6| Step: 2
Training loss: 0.03664691373705864
Validation loss: 1.3622115158265637

Epoch: 6| Step: 3
Training loss: 0.036673277616500854
Validation loss: 1.3668263048254035

Epoch: 6| Step: 4
Training loss: 0.037869893014431
Validation loss: 1.3624913410473896

Epoch: 6| Step: 5
Training loss: 0.028916848823428154
Validation loss: 1.3441482910545923

Epoch: 6| Step: 6
Training loss: 0.027032580226659775
Validation loss: 1.3343275580354916

Epoch: 6| Step: 7
Training loss: 0.022571299225091934
Validation loss: 1.3496332309579337

Epoch: 6| Step: 8
Training loss: 0.02623763307929039
Validation loss: 1.35965447848843

Epoch: 6| Step: 9
Training loss: 0.06319975107908249
Validation loss: 1.3716737307528013

Epoch: 6| Step: 10
Training loss: 0.03056042641401291
Validation loss: 1.3731763734612414

Epoch: 6| Step: 11
Training loss: 0.051798008382320404
Validation loss: 1.3813087876125048

Epoch: 6| Step: 12
Training loss: 0.034223251044750214
Validation loss: 1.390036170200635

Epoch: 6| Step: 13
Training loss: 0.040263112634420395
Validation loss: 1.3968813650069698

Epoch: 758| Step: 0
Training loss: 0.055557578802108765
Validation loss: 1.3868846149854763

Epoch: 6| Step: 1
Training loss: 0.013452485203742981
Validation loss: 1.4065271949255338

Epoch: 6| Step: 2
Training loss: 0.06452376395463943
Validation loss: 1.3935786908672703

Epoch: 6| Step: 3
Training loss: 0.03556623309850693
Validation loss: 1.40230909726953

Epoch: 6| Step: 4
Training loss: 0.04455873742699623
Validation loss: 1.3911621327041297

Epoch: 6| Step: 5
Training loss: 0.038572683930397034
Validation loss: 1.3858508999629686

Epoch: 6| Step: 6
Training loss: 0.03924398869276047
Validation loss: 1.388082645272696

Epoch: 6| Step: 7
Training loss: 0.04301602020859718
Validation loss: 1.3680153059703049

Epoch: 6| Step: 8
Training loss: 0.022415516898036003
Validation loss: 1.3754588352736605

Epoch: 6| Step: 9
Training loss: 0.047226790338754654
Validation loss: 1.3714556232575448

Epoch: 6| Step: 10
Training loss: 0.033974673599004745
Validation loss: 1.3499655018570602

Epoch: 6| Step: 11
Training loss: 0.02854086086153984
Validation loss: 1.378074405013874

Epoch: 6| Step: 12
Training loss: 0.03736981749534607
Validation loss: 1.3471665318294237

Epoch: 6| Step: 13
Training loss: 0.03369278460741043
Validation loss: 1.3223703965064018

Epoch: 759| Step: 0
Training loss: 0.05100632458925247
Validation loss: 1.3451241921353083

Epoch: 6| Step: 1
Training loss: 0.029167108237743378
Validation loss: 1.3394605690433132

Epoch: 6| Step: 2
Training loss: 0.03513035923242569
Validation loss: 1.3451102638757357

Epoch: 6| Step: 3
Training loss: 0.03937665373086929
Validation loss: 1.3465355352688861

Epoch: 6| Step: 4
Training loss: 0.06427502632141113
Validation loss: 1.354857314017511

Epoch: 6| Step: 5
Training loss: 0.026991527527570724
Validation loss: 1.3634769358942587

Epoch: 6| Step: 6
Training loss: 0.04002906382083893
Validation loss: 1.3475420718551965

Epoch: 6| Step: 7
Training loss: 0.04076094925403595
Validation loss: 1.3592190505355917

Epoch: 6| Step: 8
Training loss: 0.041970133781433105
Validation loss: 1.3612985700689337

Epoch: 6| Step: 9
Training loss: 0.030945872887969017
Validation loss: 1.3619731100656653

Epoch: 6| Step: 10
Training loss: 0.043660007417201996
Validation loss: 1.36866952847409

Epoch: 6| Step: 11
Training loss: 0.03739739581942558
Validation loss: 1.3604668253852474

Epoch: 6| Step: 12
Training loss: 0.03884018957614899
Validation loss: 1.3827072625519128

Epoch: 6| Step: 13
Training loss: 0.024779468774795532
Validation loss: 1.3809992228784869

Epoch: 760| Step: 0
Training loss: 0.06338142603635788
Validation loss: 1.3746956086927844

Epoch: 6| Step: 1
Training loss: 0.02517232671380043
Validation loss: 1.36946367192012

Epoch: 6| Step: 2
Training loss: 0.020629234611988068
Validation loss: 1.3921281009592035

Epoch: 6| Step: 3
Training loss: 0.03623935207724571
Validation loss: 1.3667721440715175

Epoch: 6| Step: 4
Training loss: 0.03464772552251816
Validation loss: 1.3693716122258095

Epoch: 6| Step: 5
Training loss: 0.04827611893415451
Validation loss: 1.3673443896796114

Epoch: 6| Step: 6
Training loss: 0.036490656435489655
Validation loss: 1.357989074081503

Epoch: 6| Step: 7
Training loss: 0.03333849459886551
Validation loss: 1.3762973200890325

Epoch: 6| Step: 8
Training loss: 0.019730664789676666
Validation loss: 1.3846910974030853

Epoch: 6| Step: 9
Training loss: 0.04741906747221947
Validation loss: 1.3781059442027923

Epoch: 6| Step: 10
Training loss: 0.031442344188690186
Validation loss: 1.3696511445506927

Epoch: 6| Step: 11
Training loss: 0.03700680285692215
Validation loss: 1.3753686297324397

Epoch: 6| Step: 12
Training loss: 0.04274273291230202
Validation loss: 1.3849786276458411

Epoch: 6| Step: 13
Training loss: 0.03692295029759407
Validation loss: 1.379231176068706

Epoch: 761| Step: 0
Training loss: 0.02542886510491371
Validation loss: 1.387281403746656

Epoch: 6| Step: 1
Training loss: 0.02492588758468628
Validation loss: 1.3827823477406656

Epoch: 6| Step: 2
Training loss: 0.03076549619436264
Validation loss: 1.4000229732964629

Epoch: 6| Step: 3
Training loss: 0.03976929187774658
Validation loss: 1.3865533849244476

Epoch: 6| Step: 4
Training loss: 0.02090214565396309
Validation loss: 1.3836898983165782

Epoch: 6| Step: 5
Training loss: 0.03801403194665909
Validation loss: 1.3990305674973356

Epoch: 6| Step: 6
Training loss: 0.024998929351568222
Validation loss: 1.3736318170383413

Epoch: 6| Step: 7
Training loss: 0.0243978314101696
Validation loss: 1.3774362174413537

Epoch: 6| Step: 8
Training loss: 0.04201316833496094
Validation loss: 1.3907873566432665

Epoch: 6| Step: 9
Training loss: 0.03447212651371956
Validation loss: 1.3960177693315732

Epoch: 6| Step: 10
Training loss: 0.038240134716033936
Validation loss: 1.3838127684849564

Epoch: 6| Step: 11
Training loss: 0.03953949362039566
Validation loss: 1.3922053126878635

Epoch: 6| Step: 12
Training loss: 0.04580235108733177
Validation loss: 1.3896275361378987

Epoch: 6| Step: 13
Training loss: 0.038526780903339386
Validation loss: 1.3966378614466677

Epoch: 762| Step: 0
Training loss: 0.023305116221308708
Validation loss: 1.3690805524908087

Epoch: 6| Step: 1
Training loss: 0.04053085297346115
Validation loss: 1.3767503282075286

Epoch: 6| Step: 2
Training loss: 0.030826494097709656
Validation loss: 1.3725980071611301

Epoch: 6| Step: 3
Training loss: 0.04472094774246216
Validation loss: 1.3612787262085946

Epoch: 6| Step: 4
Training loss: 0.022117003798484802
Validation loss: 1.3715787126171974

Epoch: 6| Step: 5
Training loss: 0.021438512951135635
Validation loss: 1.3470101138596893

Epoch: 6| Step: 6
Training loss: 0.034311600029468536
Validation loss: 1.3602722678133237

Epoch: 6| Step: 7
Training loss: 0.018410831689834595
Validation loss: 1.3574197035963818

Epoch: 6| Step: 8
Training loss: 0.021319635212421417
Validation loss: 1.3523085424976964

Epoch: 6| Step: 9
Training loss: 0.04825796186923981
Validation loss: 1.340991986054246

Epoch: 6| Step: 10
Training loss: 0.04164672642946243
Validation loss: 1.3437947034835815

Epoch: 6| Step: 11
Training loss: 0.03760918974876404
Validation loss: 1.3520335587122108

Epoch: 6| Step: 12
Training loss: 0.03019384667277336
Validation loss: 1.3483590720802225

Epoch: 6| Step: 13
Training loss: 0.05040273070335388
Validation loss: 1.3446559777823828

Epoch: 763| Step: 0
Training loss: 0.033616721630096436
Validation loss: 1.342780956657984

Epoch: 6| Step: 1
Training loss: 0.03222260624170303
Validation loss: 1.3514648329827093

Epoch: 6| Step: 2
Training loss: 0.046574823558330536
Validation loss: 1.358485189176375

Epoch: 6| Step: 3
Training loss: 0.029115155339241028
Validation loss: 1.3709104458491008

Epoch: 6| Step: 4
Training loss: 0.05615841597318649
Validation loss: 1.3582859590489378

Epoch: 6| Step: 5
Training loss: 0.03951290622353554
Validation loss: 1.3522542625345209

Epoch: 6| Step: 6
Training loss: 0.04142235964536667
Validation loss: 1.3475203565371934

Epoch: 6| Step: 7
Training loss: 0.025641700252890587
Validation loss: 1.3476912026764245

Epoch: 6| Step: 8
Training loss: 0.0342436358332634
Validation loss: 1.3549323722880373

Epoch: 6| Step: 9
Training loss: 0.024221079424023628
Validation loss: 1.3552335189875735

Epoch: 6| Step: 10
Training loss: 0.022734984755516052
Validation loss: 1.37313764133761

Epoch: 6| Step: 11
Training loss: 0.040714576840400696
Validation loss: 1.3613128380108905

Epoch: 6| Step: 12
Training loss: 0.042420703917741776
Validation loss: 1.369426663844816

Epoch: 6| Step: 13
Training loss: 0.07017949223518372
Validation loss: 1.3644421062161844

Epoch: 764| Step: 0
Training loss: 0.031770601868629456
Validation loss: 1.35110637000812

Epoch: 6| Step: 1
Training loss: 0.023143693804740906
Validation loss: 1.3486428235166816

Epoch: 6| Step: 2
Training loss: 0.05044223740696907
Validation loss: 1.3588634050020607

Epoch: 6| Step: 3
Training loss: 0.02815258502960205
Validation loss: 1.3478492447125014

Epoch: 6| Step: 4
Training loss: 0.0450148731470108
Validation loss: 1.3427694202751241

Epoch: 6| Step: 5
Training loss: 0.09430642426013947
Validation loss: 1.3507095318968578

Epoch: 6| Step: 6
Training loss: 0.053998835384845734
Validation loss: 1.3481271664301555

Epoch: 6| Step: 7
Training loss: 0.03698570281267166
Validation loss: 1.3480010571018342

Epoch: 6| Step: 8
Training loss: 0.04140518233180046
Validation loss: 1.3531040017322828

Epoch: 6| Step: 9
Training loss: 0.042147520929574966
Validation loss: 1.3681757283467118

Epoch: 6| Step: 10
Training loss: 0.033747732639312744
Validation loss: 1.3676758325228127

Epoch: 6| Step: 11
Training loss: 0.034569572657346725
Validation loss: 1.3714467184517973

Epoch: 6| Step: 12
Training loss: 0.03848896920681
Validation loss: 1.3737173811081917

Epoch: 6| Step: 13
Training loss: 0.02507261373102665
Validation loss: 1.3976324354448626

Epoch: 765| Step: 0
Training loss: 0.04536239057779312
Validation loss: 1.3830841433617376

Epoch: 6| Step: 1
Training loss: 0.05109826847910881
Validation loss: 1.3825447315810828

Epoch: 6| Step: 2
Training loss: 0.049460817128419876
Validation loss: 1.3851903305258801

Epoch: 6| Step: 3
Training loss: 0.04025449976325035
Validation loss: 1.3946157642590102

Epoch: 6| Step: 4
Training loss: 0.042682625353336334
Validation loss: 1.3887318526544878

Epoch: 6| Step: 5
Training loss: 0.03280586004257202
Validation loss: 1.3778218787203553

Epoch: 6| Step: 6
Training loss: 0.030933687463402748
Validation loss: 1.3892415582492788

Epoch: 6| Step: 7
Training loss: 0.04730822890996933
Validation loss: 1.3757062753041585

Epoch: 6| Step: 8
Training loss: 0.04430931434035301
Validation loss: 1.368808061845841

Epoch: 6| Step: 9
Training loss: 0.02701236680150032
Validation loss: 1.3720650147366267

Epoch: 6| Step: 10
Training loss: 0.047118522226810455
Validation loss: 1.3571288547208231

Epoch: 6| Step: 11
Training loss: 0.022314315661787987
Validation loss: 1.3481014467054797

Epoch: 6| Step: 12
Training loss: 0.043102215975522995
Validation loss: 1.347310568696709

Epoch: 6| Step: 13
Training loss: 0.03830742835998535
Validation loss: 1.367202490247706

Epoch: 766| Step: 0
Training loss: 0.03602314367890358
Validation loss: 1.3684245065976215

Epoch: 6| Step: 1
Training loss: 0.05270294100046158
Validation loss: 1.3649555918990925

Epoch: 6| Step: 2
Training loss: 0.025829628109931946
Validation loss: 1.3776834549442414

Epoch: 6| Step: 3
Training loss: 0.030115533620119095
Validation loss: 1.3459228495115876

Epoch: 6| Step: 4
Training loss: 0.038688719272613525
Validation loss: 1.3615520615731516

Epoch: 6| Step: 5
Training loss: 0.043984830379486084
Validation loss: 1.3659476798067811

Epoch: 6| Step: 6
Training loss: 0.04346446692943573
Validation loss: 1.3686205892152683

Epoch: 6| Step: 7
Training loss: 0.04915185272693634
Validation loss: 1.3784219603384695

Epoch: 6| Step: 8
Training loss: 0.0360700786113739
Validation loss: 1.3688305475378548

Epoch: 6| Step: 9
Training loss: 0.055112045258283615
Validation loss: 1.379581488588805

Epoch: 6| Step: 10
Training loss: 0.036564942449331284
Validation loss: 1.3898926652887815

Epoch: 6| Step: 11
Training loss: 0.040392953902482986
Validation loss: 1.3946914454942108

Epoch: 6| Step: 12
Training loss: 0.04818405210971832
Validation loss: 1.405069003502528

Epoch: 6| Step: 13
Training loss: 0.035788342356681824
Validation loss: 1.4078680507598385

Epoch: 767| Step: 0
Training loss: 0.03729431331157684
Validation loss: 1.4096569707316737

Epoch: 6| Step: 1
Training loss: 0.056197457015514374
Validation loss: 1.391759430208514

Epoch: 6| Step: 2
Training loss: 0.03960331901907921
Validation loss: 1.3838086628144788

Epoch: 6| Step: 3
Training loss: 0.03227617219090462
Validation loss: 1.3738288084665935

Epoch: 6| Step: 4
Training loss: 0.04052494466304779
Validation loss: 1.3679094340211602

Epoch: 6| Step: 5
Training loss: 0.026815462857484818
Validation loss: 1.3691180354805403

Epoch: 6| Step: 6
Training loss: 0.04442666843533516
Validation loss: 1.3674072552752752

Epoch: 6| Step: 7
Training loss: 0.049045026302337646
Validation loss: 1.372242002077

Epoch: 6| Step: 8
Training loss: 0.03876226395368576
Validation loss: 1.3660891049651689

Epoch: 6| Step: 9
Training loss: 0.04650610312819481
Validation loss: 1.3612701533943095

Epoch: 6| Step: 10
Training loss: 0.060525670647621155
Validation loss: 1.3582372767950899

Epoch: 6| Step: 11
Training loss: 0.08382619172334671
Validation loss: 1.3540362408084254

Epoch: 6| Step: 12
Training loss: 0.039239898324012756
Validation loss: 1.3482840381642824

Epoch: 6| Step: 13
Training loss: 0.04397372528910637
Validation loss: 1.3513868457527571

Epoch: 768| Step: 0
Training loss: 0.04878896847367287
Validation loss: 1.3488969854129258

Epoch: 6| Step: 1
Training loss: 0.02871943637728691
Validation loss: 1.377013450027794

Epoch: 6| Step: 2
Training loss: 0.04697547107934952
Validation loss: 1.38570858393946

Epoch: 6| Step: 3
Training loss: 0.045653216540813446
Validation loss: 1.369189130362644

Epoch: 6| Step: 4
Training loss: 0.04185850918292999
Validation loss: 1.3946376481363851

Epoch: 6| Step: 5
Training loss: 0.04084474593400955
Validation loss: 1.3633081579721102

Epoch: 6| Step: 6
Training loss: 0.027710778638720512
Validation loss: 1.3763395817049089

Epoch: 6| Step: 7
Training loss: 0.04618971049785614
Validation loss: 1.367677806526102

Epoch: 6| Step: 8
Training loss: 0.043556250631809235
Validation loss: 1.3753399759210565

Epoch: 6| Step: 9
Training loss: 0.05666892230510712
Validation loss: 1.3607348601023357

Epoch: 6| Step: 10
Training loss: 0.03601546585559845
Validation loss: 1.3641100096446213

Epoch: 6| Step: 11
Training loss: 0.06221410632133484
Validation loss: 1.3694606763060375

Epoch: 6| Step: 12
Training loss: 0.053808607161045074
Validation loss: 1.3780517719125236

Epoch: 6| Step: 13
Training loss: 0.04236014187335968
Validation loss: 1.3528449150823778

Epoch: 769| Step: 0
Training loss: 0.03778655081987381
Validation loss: 1.354749136073615

Epoch: 6| Step: 1
Training loss: 0.026736466214060783
Validation loss: 1.353419409003309

Epoch: 6| Step: 2
Training loss: 0.04889276996254921
Validation loss: 1.3560863207745295

Epoch: 6| Step: 3
Training loss: 0.050467900931835175
Validation loss: 1.3579737627378075

Epoch: 6| Step: 4
Training loss: 0.04566597193479538
Validation loss: 1.3725844531930902

Epoch: 6| Step: 5
Training loss: 0.036837443709373474
Validation loss: 1.3552503419178787

Epoch: 6| Step: 6
Training loss: 0.032496627420186996
Validation loss: 1.3817045906538605

Epoch: 6| Step: 7
Training loss: 0.04025097191333771
Validation loss: 1.3780841840210782

Epoch: 6| Step: 8
Training loss: 0.03725922480225563
Validation loss: 1.3796820089381228

Epoch: 6| Step: 9
Training loss: 0.04078400880098343
Validation loss: 1.3793427931365145

Epoch: 6| Step: 10
Training loss: 0.04816817119717598
Validation loss: 1.3792291533562444

Epoch: 6| Step: 11
Training loss: 0.028743429109454155
Validation loss: 1.3801561645282212

Epoch: 6| Step: 12
Training loss: 0.03063102439045906
Validation loss: 1.3829146251883557

Epoch: 6| Step: 13
Training loss: 0.031979434192180634
Validation loss: 1.3836051571753718

Epoch: 770| Step: 0
Training loss: 0.04590977355837822
Validation loss: 1.3823326146730812

Epoch: 6| Step: 1
Training loss: 0.038051679730415344
Validation loss: 1.3803904902550481

Epoch: 6| Step: 2
Training loss: 0.015044205822050571
Validation loss: 1.3669432196565854

Epoch: 6| Step: 3
Training loss: 0.031173910945653915
Validation loss: 1.3829590139850494

Epoch: 6| Step: 4
Training loss: 0.03617627173662186
Validation loss: 1.3562305486330422

Epoch: 6| Step: 5
Training loss: 0.03315609693527222
Validation loss: 1.353765993989924

Epoch: 6| Step: 6
Training loss: 0.04011675715446472
Validation loss: 1.3717551756930608

Epoch: 6| Step: 7
Training loss: 0.05707012116909027
Validation loss: 1.351230453419429

Epoch: 6| Step: 8
Training loss: 0.03963568061590195
Validation loss: 1.362819860058446

Epoch: 6| Step: 9
Training loss: 0.03159607946872711
Validation loss: 1.3668833214749572

Epoch: 6| Step: 10
Training loss: 0.029586277902126312
Validation loss: 1.3746985030430618

Epoch: 6| Step: 11
Training loss: 0.03572080284357071
Validation loss: 1.370331186120228

Epoch: 6| Step: 12
Training loss: 0.03194129467010498
Validation loss: 1.4027914219005133

Epoch: 6| Step: 13
Training loss: 0.04515908285975456
Validation loss: 1.3818464035628943

Epoch: 771| Step: 0
Training loss: 0.03364735096693039
Validation loss: 1.3777878002453876

Epoch: 6| Step: 1
Training loss: 0.0404510498046875
Validation loss: 1.3828696435497654

Epoch: 6| Step: 2
Training loss: 0.043728284537792206
Validation loss: 1.3683284636466735

Epoch: 6| Step: 3
Training loss: 0.028334621340036392
Validation loss: 1.3776128548447804

Epoch: 6| Step: 4
Training loss: 0.03601841628551483
Validation loss: 1.3780930183267082

Epoch: 6| Step: 5
Training loss: 0.03167375922203064
Validation loss: 1.3744128980944235

Epoch: 6| Step: 6
Training loss: 0.031837351620197296
Validation loss: 1.3687798893579872

Epoch: 6| Step: 7
Training loss: 0.026149652898311615
Validation loss: 1.3733590886157045

Epoch: 6| Step: 8
Training loss: 0.03684815391898155
Validation loss: 1.358712338632153

Epoch: 6| Step: 9
Training loss: 0.043596185743808746
Validation loss: 1.3546262620597758

Epoch: 6| Step: 10
Training loss: 0.029551168903708458
Validation loss: 1.3708743920890234

Epoch: 6| Step: 11
Training loss: 0.038438741117715836
Validation loss: 1.3692160575620589

Epoch: 6| Step: 12
Training loss: 0.02904680371284485
Validation loss: 1.3572302274806525

Epoch: 6| Step: 13
Training loss: 0.031938690692186356
Validation loss: 1.3504788516670145

Epoch: 772| Step: 0
Training loss: 0.021325882524251938
Validation loss: 1.3412794938651464

Epoch: 6| Step: 1
Training loss: 0.037875428795814514
Validation loss: 1.3431453384378904

Epoch: 6| Step: 2
Training loss: 0.047529011964797974
Validation loss: 1.3428340214554981

Epoch: 6| Step: 3
Training loss: 0.07249923050403595
Validation loss: 1.3551452493154874

Epoch: 6| Step: 4
Training loss: 0.03681357949972153
Validation loss: 1.3536958925185665

Epoch: 6| Step: 5
Training loss: 0.05528809130191803
Validation loss: 1.3628946619649087

Epoch: 6| Step: 6
Training loss: 0.03914690017700195
Validation loss: 1.3556810085491469

Epoch: 6| Step: 7
Training loss: 0.03837481886148453
Validation loss: 1.3657302266807967

Epoch: 6| Step: 8
Training loss: 0.028186988085508347
Validation loss: 1.3581655551028509

Epoch: 6| Step: 9
Training loss: 0.025227747857570648
Validation loss: 1.3756514351855043

Epoch: 6| Step: 10
Training loss: 0.04097902774810791
Validation loss: 1.3649102077689221

Epoch: 6| Step: 11
Training loss: 0.02793312817811966
Validation loss: 1.3595892062751196

Epoch: 6| Step: 12
Training loss: 0.04215151071548462
Validation loss: 1.3554596311302596

Epoch: 6| Step: 13
Training loss: 0.04175754263997078
Validation loss: 1.3777489636534004

Epoch: 773| Step: 0
Training loss: 0.03502311557531357
Validation loss: 1.3619105162159089

Epoch: 6| Step: 1
Training loss: 0.03644527494907379
Validation loss: 1.3613093027504541

Epoch: 6| Step: 2
Training loss: 0.031202200800180435
Validation loss: 1.375994647702863

Epoch: 6| Step: 3
Training loss: 0.03126835823059082
Validation loss: 1.3688827881249048

Epoch: 6| Step: 4
Training loss: 0.04337579756975174
Validation loss: 1.3599125967230847

Epoch: 6| Step: 5
Training loss: 0.05146953463554382
Validation loss: 1.3709702248214393

Epoch: 6| Step: 6
Training loss: 0.045633453875780106
Validation loss: 1.353145532710578

Epoch: 6| Step: 7
Training loss: 0.06134656071662903
Validation loss: 1.3740692625763595

Epoch: 6| Step: 8
Training loss: 0.029887057840824127
Validation loss: 1.376365698793883

Epoch: 6| Step: 9
Training loss: 0.027404751628637314
Validation loss: 1.3689355760492303

Epoch: 6| Step: 10
Training loss: 0.0346752293407917
Validation loss: 1.3597836199627127

Epoch: 6| Step: 11
Training loss: 0.02234044298529625
Validation loss: 1.3631679024747623

Epoch: 6| Step: 12
Training loss: 0.03809034824371338
Validation loss: 1.351848889422673

Epoch: 6| Step: 13
Training loss: 0.04036763682961464
Validation loss: 1.3564210207231584

Epoch: 774| Step: 0
Training loss: 0.057361580431461334
Validation loss: 1.362332590805587

Epoch: 6| Step: 1
Training loss: 0.03625357151031494
Validation loss: 1.3895449997276388

Epoch: 6| Step: 2
Training loss: 0.02706083096563816
Validation loss: 1.3597732878500415

Epoch: 6| Step: 3
Training loss: 0.05029873549938202
Validation loss: 1.3717960913976033

Epoch: 6| Step: 4
Training loss: 0.04264479875564575
Validation loss: 1.3852571748918103

Epoch: 6| Step: 5
Training loss: 0.03005770780146122
Validation loss: 1.3662734364950528

Epoch: 6| Step: 6
Training loss: 0.03381329029798508
Validation loss: 1.3568165340731222

Epoch: 6| Step: 7
Training loss: 0.031481869518756866
Validation loss: 1.3514414333528089

Epoch: 6| Step: 8
Training loss: 0.02436426840722561
Validation loss: 1.342913269996643

Epoch: 6| Step: 9
Training loss: 0.047777559608221054
Validation loss: 1.3462404704863025

Epoch: 6| Step: 10
Training loss: 0.048657771199941635
Validation loss: 1.359126188421762

Epoch: 6| Step: 11
Training loss: 0.03878168761730194
Validation loss: 1.3441879185297156

Epoch: 6| Step: 12
Training loss: 0.0471518412232399
Validation loss: 1.3250197043982885

Epoch: 6| Step: 13
Training loss: 0.032378606498241425
Validation loss: 1.3485830740262104

Epoch: 775| Step: 0
Training loss: 0.06588375568389893
Validation loss: 1.343519668425283

Epoch: 6| Step: 1
Training loss: 0.04110205918550491
Validation loss: 1.3614422332855962

Epoch: 6| Step: 2
Training loss: 0.03206703066825867
Validation loss: 1.36807087544472

Epoch: 6| Step: 3
Training loss: 0.034248873591423035
Validation loss: 1.3789220176717287

Epoch: 6| Step: 4
Training loss: 0.040040917694568634
Validation loss: 1.3834469843936223

Epoch: 6| Step: 5
Training loss: 0.051705315709114075
Validation loss: 1.3916056617613761

Epoch: 6| Step: 6
Training loss: 0.03309819847345352
Validation loss: 1.4048540515284385

Epoch: 6| Step: 7
Training loss: 0.027347363531589508
Validation loss: 1.4236719813398135

Epoch: 6| Step: 8
Training loss: 0.039796799421310425
Validation loss: 1.3974050911523963

Epoch: 6| Step: 9
Training loss: 0.037254396826028824
Validation loss: 1.411727951418969

Epoch: 6| Step: 10
Training loss: 0.043638452887535095
Validation loss: 1.4192189388377692

Epoch: 6| Step: 11
Training loss: 0.027751771733164787
Validation loss: 1.406287572717154

Epoch: 6| Step: 12
Training loss: 0.03680430352687836
Validation loss: 1.417157780739569

Epoch: 6| Step: 13
Training loss: 0.03179527819156647
Validation loss: 1.4052099290714468

Epoch: 776| Step: 0
Training loss: 0.027597736567258835
Validation loss: 1.4043486554135558

Epoch: 6| Step: 1
Training loss: 0.030228426679968834
Validation loss: 1.3898838976378083

Epoch: 6| Step: 2
Training loss: 0.041796255856752396
Validation loss: 1.4088557509965793

Epoch: 6| Step: 3
Training loss: 0.0409918911755085
Validation loss: 1.3843052810238254

Epoch: 6| Step: 4
Training loss: 0.030296793207526207
Validation loss: 1.3839097112737677

Epoch: 6| Step: 5
Training loss: 0.03599756956100464
Validation loss: 1.3733723817333099

Epoch: 6| Step: 6
Training loss: 0.0570870116353035
Validation loss: 1.3631565878468175

Epoch: 6| Step: 7
Training loss: 0.056331075727939606
Validation loss: 1.3764693506302372

Epoch: 6| Step: 8
Training loss: 0.028466638177633286
Validation loss: 1.3651118996322795

Epoch: 6| Step: 9
Training loss: 0.03651934117078781
Validation loss: 1.371396166022106

Epoch: 6| Step: 10
Training loss: 0.059924233704805374
Validation loss: 1.3847331731550154

Epoch: 6| Step: 11
Training loss: 0.054842762649059296
Validation loss: 1.374369691776973

Epoch: 6| Step: 12
Training loss: 0.05889853835105896
Validation loss: 1.3829998309894274

Epoch: 6| Step: 13
Training loss: 0.01611967943608761
Validation loss: 1.3842191209075272

Epoch: 777| Step: 0
Training loss: 0.0337752029299736
Validation loss: 1.3902496983928065

Epoch: 6| Step: 1
Training loss: 0.02207821235060692
Validation loss: 1.3790761559240279

Epoch: 6| Step: 2
Training loss: 0.03565213456749916
Validation loss: 1.3667308194662935

Epoch: 6| Step: 3
Training loss: 0.039728280156850815
Validation loss: 1.3735252447346205

Epoch: 6| Step: 4
Training loss: 0.030069580301642418
Validation loss: 1.3864145573749338

Epoch: 6| Step: 5
Training loss: 0.0407421737909317
Validation loss: 1.3955786817817277

Epoch: 6| Step: 6
Training loss: 0.037778060883283615
Validation loss: 1.3958323822226575

Epoch: 6| Step: 7
Training loss: 0.06172846257686615
Validation loss: 1.3875250739435996

Epoch: 6| Step: 8
Training loss: 0.05050311237573624
Validation loss: 1.4103229135595343

Epoch: 6| Step: 9
Training loss: 0.05356743931770325
Validation loss: 1.403110670787032

Epoch: 6| Step: 10
Training loss: 0.0547669380903244
Validation loss: 1.3952050990955804

Epoch: 6| Step: 11
Training loss: 0.04322424158453941
Validation loss: 1.4066378352462605

Epoch: 6| Step: 12
Training loss: 0.0256887748837471
Validation loss: 1.4116898787918912

Epoch: 6| Step: 13
Training loss: 0.030178755521774292
Validation loss: 1.3997909336961725

Epoch: 778| Step: 0
Training loss: 0.03761976212263107
Validation loss: 1.3849345919906453

Epoch: 6| Step: 1
Training loss: 0.029166724532842636
Validation loss: 1.3918445764049407

Epoch: 6| Step: 2
Training loss: 0.027863796800374985
Validation loss: 1.4011987742557321

Epoch: 6| Step: 3
Training loss: 0.039332639425992966
Validation loss: 1.4060359577978812

Epoch: 6| Step: 4
Training loss: 0.05921115353703499
Validation loss: 1.4061803971567461

Epoch: 6| Step: 5
Training loss: 0.03404219448566437
Validation loss: 1.3985938974606094

Epoch: 6| Step: 6
Training loss: 0.04667160287499428
Validation loss: 1.4044861998609317

Epoch: 6| Step: 7
Training loss: 0.054774485528469086
Validation loss: 1.3935017252481112

Epoch: 6| Step: 8
Training loss: 0.05436734855175018
Validation loss: 1.391958962845546

Epoch: 6| Step: 9
Training loss: 0.03154148906469345
Validation loss: 1.3883633498222596

Epoch: 6| Step: 10
Training loss: 0.03828175738453865
Validation loss: 1.3841589022708196

Epoch: 6| Step: 11
Training loss: 0.025538792833685875
Validation loss: 1.405033165408719

Epoch: 6| Step: 12
Training loss: 0.027405381202697754
Validation loss: 1.401372104562739

Epoch: 6| Step: 13
Training loss: 0.03611136972904205
Validation loss: 1.3842911540821035

Epoch: 779| Step: 0
Training loss: 0.04005160182714462
Validation loss: 1.387758594687267

Epoch: 6| Step: 1
Training loss: 0.027519524097442627
Validation loss: 1.3955384082691644

Epoch: 6| Step: 2
Training loss: 0.03816638141870499
Validation loss: 1.400188006380553

Epoch: 6| Step: 3
Training loss: 0.03714218735694885
Validation loss: 1.387295913952653

Epoch: 6| Step: 4
Training loss: 0.043284691870212555
Validation loss: 1.39979084204602

Epoch: 6| Step: 5
Training loss: 0.0503019243478775
Validation loss: 1.3906053035489974

Epoch: 6| Step: 6
Training loss: 0.03291107714176178
Validation loss: 1.3810352458748767

Epoch: 6| Step: 7
Training loss: 0.045755535364151
Validation loss: 1.3787095085267098

Epoch: 6| Step: 8
Training loss: 0.05507991835474968
Validation loss: 1.3786532571238856

Epoch: 6| Step: 9
Training loss: 0.017159629613161087
Validation loss: 1.3852539447046095

Epoch: 6| Step: 10
Training loss: 0.03203407675027847
Validation loss: 1.3852307886205695

Epoch: 6| Step: 11
Training loss: 0.0336124524474144
Validation loss: 1.37362588221027

Epoch: 6| Step: 12
Training loss: 0.0341365672647953
Validation loss: 1.3736111066674674

Epoch: 6| Step: 13
Training loss: 0.016099542379379272
Validation loss: 1.3998901882479269

Epoch: 780| Step: 0
Training loss: 0.023863399401307106
Validation loss: 1.3700645841578

Epoch: 6| Step: 1
Training loss: 0.027359262108802795
Validation loss: 1.3775978639561643

Epoch: 6| Step: 2
Training loss: 0.04733675718307495
Validation loss: 1.3695149396055488

Epoch: 6| Step: 3
Training loss: 0.03615453094244003
Validation loss: 1.3734333335712392

Epoch: 6| Step: 4
Training loss: 0.031203560531139374
Validation loss: 1.3762197648325274

Epoch: 6| Step: 5
Training loss: 0.047627002000808716
Validation loss: 1.370423832247334

Epoch: 6| Step: 6
Training loss: 0.0379597544670105
Validation loss: 1.3614618201409616

Epoch: 6| Step: 7
Training loss: 0.03797513246536255
Validation loss: 1.3619443549904773

Epoch: 6| Step: 8
Training loss: 0.03187084197998047
Validation loss: 1.3745023089070474

Epoch: 6| Step: 9
Training loss: 0.020614270120859146
Validation loss: 1.3741698027938924

Epoch: 6| Step: 10
Training loss: 0.034728407859802246
Validation loss: 1.387399386334163

Epoch: 6| Step: 11
Training loss: 0.03277479112148285
Validation loss: 1.3703510197260047

Epoch: 6| Step: 12
Training loss: 0.025699011981487274
Validation loss: 1.3960608231124056

Epoch: 6| Step: 13
Training loss: 0.03247014805674553
Validation loss: 1.390358998570391

Epoch: 781| Step: 0
Training loss: 0.032542966306209564
Validation loss: 1.3879839950992214

Epoch: 6| Step: 1
Training loss: 0.03745890408754349
Validation loss: 1.3995161533996623

Epoch: 6| Step: 2
Training loss: 0.03989206999540329
Validation loss: 1.3820191737144225

Epoch: 6| Step: 3
Training loss: 0.03951827436685562
Validation loss: 1.3877139604219826

Epoch: 6| Step: 4
Training loss: 0.035555943846702576
Validation loss: 1.3866154493824128

Epoch: 6| Step: 5
Training loss: 0.035949770361185074
Validation loss: 1.4076888753521828

Epoch: 6| Step: 6
Training loss: 0.036720629781484604
Validation loss: 1.3907893050101496

Epoch: 6| Step: 7
Training loss: 0.035193413496017456
Validation loss: 1.3836609439183307

Epoch: 6| Step: 8
Training loss: 0.02667565643787384
Validation loss: 1.379356966223768

Epoch: 6| Step: 9
Training loss: 0.044737230986356735
Validation loss: 1.3820591716356174

Epoch: 6| Step: 10
Training loss: 0.038866981863975525
Validation loss: 1.3731447240357757

Epoch: 6| Step: 11
Training loss: 0.04560019075870514
Validation loss: 1.3751881827590287

Epoch: 6| Step: 12
Training loss: 0.04098544269800186
Validation loss: 1.3597004926332863

Epoch: 6| Step: 13
Training loss: 0.03768152743577957
Validation loss: 1.3758562418722338

Epoch: 782| Step: 0
Training loss: 0.02739698812365532
Validation loss: 1.3871806436969387

Epoch: 6| Step: 1
Training loss: 0.038043852895498276
Validation loss: 1.380790372048655

Epoch: 6| Step: 2
Training loss: 0.02376696653664112
Validation loss: 1.3830001995127688

Epoch: 6| Step: 3
Training loss: 0.02522306703031063
Validation loss: 1.3784361782894339

Epoch: 6| Step: 4
Training loss: 0.043170567601919174
Validation loss: 1.393580525152145

Epoch: 6| Step: 5
Training loss: 0.03980948030948639
Validation loss: 1.396631117789976

Epoch: 6| Step: 6
Training loss: 0.049746446311473846
Validation loss: 1.4165653541523924

Epoch: 6| Step: 7
Training loss: 0.050363246351480484
Validation loss: 1.3955651816501413

Epoch: 6| Step: 8
Training loss: 0.03838018327951431
Validation loss: 1.3814981227279992

Epoch: 6| Step: 9
Training loss: 0.027021337300539017
Validation loss: 1.3752097237494685

Epoch: 6| Step: 10
Training loss: 0.03667794540524483
Validation loss: 1.3660952250162761

Epoch: 6| Step: 11
Training loss: 0.030834753066301346
Validation loss: 1.3667367369897905

Epoch: 6| Step: 12
Training loss: 0.05699620395898819
Validation loss: 1.3506180496626004

Epoch: 6| Step: 13
Training loss: 0.05427449941635132
Validation loss: 1.342799857098569

Epoch: 783| Step: 0
Training loss: 0.032160449773073196
Validation loss: 1.3590480986461844

Epoch: 6| Step: 1
Training loss: 0.033418476581573486
Validation loss: 1.356169331458307

Epoch: 6| Step: 2
Training loss: 0.031227098777890205
Validation loss: 1.3566600379123483

Epoch: 6| Step: 3
Training loss: 0.043048709630966187
Validation loss: 1.374132400558841

Epoch: 6| Step: 4
Training loss: 0.034351203590631485
Validation loss: 1.3653740600873066

Epoch: 6| Step: 5
Training loss: 0.039444699883461
Validation loss: 1.35838117138032

Epoch: 6| Step: 6
Training loss: 0.04006577655673027
Validation loss: 1.3522551187904932

Epoch: 6| Step: 7
Training loss: 0.026814132928848267
Validation loss: 1.3465072660035984

Epoch: 6| Step: 8
Training loss: 0.039160341024398804
Validation loss: 1.3251284809522732

Epoch: 6| Step: 9
Training loss: 0.03718084841966629
Validation loss: 1.3344152345452258

Epoch: 6| Step: 10
Training loss: 0.03483223915100098
Validation loss: 1.3341450075949393

Epoch: 6| Step: 11
Training loss: 0.05240644887089729
Validation loss: 1.3355759010520032

Epoch: 6| Step: 12
Training loss: 0.04443318769335747
Validation loss: 1.328173537408152

Epoch: 6| Step: 13
Training loss: 0.029164500534534454
Validation loss: 1.3367703101968254

Epoch: 784| Step: 0
Training loss: 0.05205404385924339
Validation loss: 1.339840599285659

Epoch: 6| Step: 1
Training loss: 0.022581059485673904
Validation loss: 1.3148361252200218

Epoch: 6| Step: 2
Training loss: 0.029730655252933502
Validation loss: 1.3315651493687783

Epoch: 6| Step: 3
Training loss: 0.02440633252263069
Validation loss: 1.3361028304664038

Epoch: 6| Step: 4
Training loss: 0.03594221547245979
Validation loss: 1.3424636753656531

Epoch: 6| Step: 5
Training loss: 0.03988354280591011
Validation loss: 1.3568461671952279

Epoch: 6| Step: 6
Training loss: 0.02553972415626049
Validation loss: 1.3433146066563104

Epoch: 6| Step: 7
Training loss: 0.0424371100962162
Validation loss: 1.333861663777341

Epoch: 6| Step: 8
Training loss: 0.02642582356929779
Validation loss: 1.3116979188816522

Epoch: 6| Step: 9
Training loss: 0.026684589684009552
Validation loss: 1.3452689878402218

Epoch: 6| Step: 10
Training loss: 0.025325533002614975
Validation loss: 1.3342724615527737

Epoch: 6| Step: 11
Training loss: 0.05282175913453102
Validation loss: 1.3383190119138328

Epoch: 6| Step: 12
Training loss: 0.029557526111602783
Validation loss: 1.3613817845621417

Epoch: 6| Step: 13
Training loss: 0.02098490111529827
Validation loss: 1.3517807209363548

Epoch: 785| Step: 0
Training loss: 0.025225332006812096
Validation loss: 1.3486239948580343

Epoch: 6| Step: 1
Training loss: 0.04207685589790344
Validation loss: 1.36343857806216

Epoch: 6| Step: 2
Training loss: 0.04206852614879608
Validation loss: 1.3569812428566717

Epoch: 6| Step: 3
Training loss: 0.05634023994207382
Validation loss: 1.3496221278303413

Epoch: 6| Step: 4
Training loss: 0.030101213604211807
Validation loss: 1.369438676423924

Epoch: 6| Step: 5
Training loss: 0.04202871769666672
Validation loss: 1.3624560320249168

Epoch: 6| Step: 6
Training loss: 0.01674157939851284
Validation loss: 1.377613462427611

Epoch: 6| Step: 7
Training loss: 0.044129274785518646
Validation loss: 1.3964181664169475

Epoch: 6| Step: 8
Training loss: 0.024416431784629822
Validation loss: 1.3819581196513226

Epoch: 6| Step: 9
Training loss: 0.0312553346157074
Validation loss: 1.3830668798056982

Epoch: 6| Step: 10
Training loss: 0.03385160118341446
Validation loss: 1.3765097215611448

Epoch: 6| Step: 11
Training loss: 0.03191978111863136
Validation loss: 1.388435790615697

Epoch: 6| Step: 12
Training loss: 0.032066620886325836
Validation loss: 1.4176139049632575

Epoch: 6| Step: 13
Training loss: 0.04460020735859871
Validation loss: 1.3823700771536878

Epoch: 786| Step: 0
Training loss: 0.024767771363258362
Validation loss: 1.383186307004703

Epoch: 6| Step: 1
Training loss: 0.029167432337999344
Validation loss: 1.397279130515232

Epoch: 6| Step: 2
Training loss: 0.029031872749328613
Validation loss: 1.3835703493446432

Epoch: 6| Step: 3
Training loss: 0.0390436053276062
Validation loss: 1.3670959126564763

Epoch: 6| Step: 4
Training loss: 0.037507057189941406
Validation loss: 1.3823727535945114

Epoch: 6| Step: 5
Training loss: 0.027520447969436646
Validation loss: 1.3880995230008197

Epoch: 6| Step: 6
Training loss: 0.039407260715961456
Validation loss: 1.382901471148255

Epoch: 6| Step: 7
Training loss: 0.037427712231874466
Validation loss: 1.3741355544777327

Epoch: 6| Step: 8
Training loss: 0.02956477180123329
Validation loss: 1.3686863209611626

Epoch: 6| Step: 9
Training loss: 0.032148271799087524
Validation loss: 1.3860329543390582

Epoch: 6| Step: 10
Training loss: 0.04080384969711304
Validation loss: 1.3931940370990383

Epoch: 6| Step: 11
Training loss: 0.04547230154275894
Validation loss: 1.391412358130178

Epoch: 6| Step: 12
Training loss: 0.027505051344633102
Validation loss: 1.3816811102692799

Epoch: 6| Step: 13
Training loss: 0.04042665287852287
Validation loss: 1.3913305087756085

Epoch: 787| Step: 0
Training loss: 0.02743464522063732
Validation loss: 1.3809955837906047

Epoch: 6| Step: 1
Training loss: 0.052448928356170654
Validation loss: 1.3802670894130584

Epoch: 6| Step: 2
Training loss: 0.023038849234580994
Validation loss: 1.3811755526450373

Epoch: 6| Step: 3
Training loss: 0.02617279253900051
Validation loss: 1.3703696573934248

Epoch: 6| Step: 4
Training loss: 0.03600935637950897
Validation loss: 1.3667552432706278

Epoch: 6| Step: 5
Training loss: 0.025790682062506676
Validation loss: 1.3660828298138035

Epoch: 6| Step: 6
Training loss: 0.04007913917303085
Validation loss: 1.3810056704346851

Epoch: 6| Step: 7
Training loss: 0.04347195476293564
Validation loss: 1.3589586429698493

Epoch: 6| Step: 8
Training loss: 0.026185518130660057
Validation loss: 1.3370889329141187

Epoch: 6| Step: 9
Training loss: 0.046643197536468506
Validation loss: 1.3425227070367465

Epoch: 6| Step: 10
Training loss: 0.038730498403310776
Validation loss: 1.3369760436396445

Epoch: 6| Step: 11
Training loss: 0.037933945655822754
Validation loss: 1.3305371563921693

Epoch: 6| Step: 12
Training loss: 0.0359315350651741
Validation loss: 1.3297580365211732

Epoch: 6| Step: 13
Training loss: 0.030765457078814507
Validation loss: 1.3257923465903088

Epoch: 788| Step: 0
Training loss: 0.050660379230976105
Validation loss: 1.339431663995148

Epoch: 6| Step: 1
Training loss: 0.024532344192266464
Validation loss: 1.3315362443206131

Epoch: 6| Step: 2
Training loss: 0.0342446006834507
Validation loss: 1.3279484920604254

Epoch: 6| Step: 3
Training loss: 0.0365251824259758
Validation loss: 1.3614223618661203

Epoch: 6| Step: 4
Training loss: 0.03128568083047867
Validation loss: 1.3544133119685675

Epoch: 6| Step: 5
Training loss: 0.053717873990535736
Validation loss: 1.3439518572181783

Epoch: 6| Step: 6
Training loss: 0.030841294676065445
Validation loss: 1.348210637287427

Epoch: 6| Step: 7
Training loss: 0.031772539019584656
Validation loss: 1.3485440868203358

Epoch: 6| Step: 8
Training loss: 0.030361875891685486
Validation loss: 1.3400140218837286

Epoch: 6| Step: 9
Training loss: 0.03997841849923134
Validation loss: 1.3409469922383626

Epoch: 6| Step: 10
Training loss: 0.054846420884132385
Validation loss: 1.3409686127016622

Epoch: 6| Step: 11
Training loss: 0.022481895983219147
Validation loss: 1.3432484570369925

Epoch: 6| Step: 12
Training loss: 0.0447925366461277
Validation loss: 1.3379500271171652

Epoch: 6| Step: 13
Training loss: 0.03861699998378754
Validation loss: 1.331315662271233

Epoch: 789| Step: 0
Training loss: 0.020766770467162132
Validation loss: 1.3450040958260978

Epoch: 6| Step: 1
Training loss: 0.050389476120471954
Validation loss: 1.3683975999073317

Epoch: 6| Step: 2
Training loss: 0.02210724540054798
Validation loss: 1.3457764951131677

Epoch: 6| Step: 3
Training loss: 0.03399031609296799
Validation loss: 1.364478204839973

Epoch: 6| Step: 4
Training loss: 0.04054132103919983
Validation loss: 1.357362228055154

Epoch: 6| Step: 5
Training loss: 0.039093293249607086
Validation loss: 1.3682209310993072

Epoch: 6| Step: 6
Training loss: 0.04161955043673515
Validation loss: 1.3458956326207807

Epoch: 6| Step: 7
Training loss: 0.03128429129719734
Validation loss: 1.356746180083162

Epoch: 6| Step: 8
Training loss: 0.0232296884059906
Validation loss: 1.3540425339052755

Epoch: 6| Step: 9
Training loss: 0.041561633348464966
Validation loss: 1.3488519281469367

Epoch: 6| Step: 10
Training loss: 0.035066843032836914
Validation loss: 1.3524751124843475

Epoch: 6| Step: 11
Training loss: 0.02033078670501709
Validation loss: 1.3451663601783015

Epoch: 6| Step: 12
Training loss: 0.0307491272687912
Validation loss: 1.334608026730117

Epoch: 6| Step: 13
Training loss: 0.01894897222518921
Validation loss: 1.332732254459012

Epoch: 790| Step: 0
Training loss: 0.05580131337046623
Validation loss: 1.3275682618541103

Epoch: 6| Step: 1
Training loss: 0.04751495271921158
Validation loss: 1.3433447576338244

Epoch: 6| Step: 2
Training loss: 0.02290942147374153
Validation loss: 1.3635793526967366

Epoch: 6| Step: 3
Training loss: 0.0326642245054245
Validation loss: 1.3675639103817683

Epoch: 6| Step: 4
Training loss: 0.054569393396377563
Validation loss: 1.3734083483296056

Epoch: 6| Step: 5
Training loss: 0.05930298566818237
Validation loss: 1.3646406755652478

Epoch: 6| Step: 6
Training loss: 0.048829615116119385
Validation loss: 1.362730073672469

Epoch: 6| Step: 7
Training loss: 0.0306084007024765
Validation loss: 1.3624317351207937

Epoch: 6| Step: 8
Training loss: 0.026305168867111206
Validation loss: 1.363414325380838

Epoch: 6| Step: 9
Training loss: 0.05448123812675476
Validation loss: 1.3809150316381966

Epoch: 6| Step: 10
Training loss: 0.03033345565199852
Validation loss: 1.3631086618669572

Epoch: 6| Step: 11
Training loss: 0.03874596953392029
Validation loss: 1.3725798684422688

Epoch: 6| Step: 12
Training loss: 0.035660549998283386
Validation loss: 1.3669474970909856

Epoch: 6| Step: 13
Training loss: 0.05726224184036255
Validation loss: 1.361788849676809

Epoch: 791| Step: 0
Training loss: 0.02170851267874241
Validation loss: 1.3692003680813698

Epoch: 6| Step: 1
Training loss: 0.03803608566522598
Validation loss: 1.3707874641623548

Epoch: 6| Step: 2
Training loss: 0.036084458231925964
Validation loss: 1.32845236345004

Epoch: 6| Step: 3
Training loss: 0.038447193801403046
Validation loss: 1.3622024520750968

Epoch: 6| Step: 4
Training loss: 0.03920190781354904
Validation loss: 1.331799284104378

Epoch: 6| Step: 5
Training loss: 0.032508399337530136
Validation loss: 1.3437632553039058

Epoch: 6| Step: 6
Training loss: 0.031069757416844368
Validation loss: 1.3385648740235196

Epoch: 6| Step: 7
Training loss: 0.03695354610681534
Validation loss: 1.3564425360771917

Epoch: 6| Step: 8
Training loss: 0.02895260788500309
Validation loss: 1.344969286713549

Epoch: 6| Step: 9
Training loss: 0.04155687242746353
Validation loss: 1.3676822544426046

Epoch: 6| Step: 10
Training loss: 0.0374792106449604
Validation loss: 1.3593987931487381

Epoch: 6| Step: 11
Training loss: 0.044081661850214005
Validation loss: 1.3856254046963108

Epoch: 6| Step: 12
Training loss: 0.041747819632291794
Validation loss: 1.3750748813793223

Epoch: 6| Step: 13
Training loss: 0.03915698081254959
Validation loss: 1.372628116479484

Epoch: 792| Step: 0
Training loss: 0.03926294296979904
Validation loss: 1.3820266518541562

Epoch: 6| Step: 1
Training loss: 0.04722803831100464
Validation loss: 1.371388586618567

Epoch: 6| Step: 2
Training loss: 0.05932071805000305
Validation loss: 1.3589727942661574

Epoch: 6| Step: 3
Training loss: 0.037568286061286926
Validation loss: 1.3664482562772688

Epoch: 6| Step: 4
Training loss: 0.0331898033618927
Validation loss: 1.3538132585505003

Epoch: 6| Step: 5
Training loss: 0.03263534605503082
Validation loss: 1.3391948643551077

Epoch: 6| Step: 6
Training loss: 0.035178523510694504
Validation loss: 1.3464657773253739

Epoch: 6| Step: 7
Training loss: 0.0242120660841465
Validation loss: 1.3587925382839736

Epoch: 6| Step: 8
Training loss: 0.020941920578479767
Validation loss: 1.3541076196137296

Epoch: 6| Step: 9
Training loss: 0.016482438892126083
Validation loss: 1.3421398798624675

Epoch: 6| Step: 10
Training loss: 0.023341353982686996
Validation loss: 1.3331293739298338

Epoch: 6| Step: 11
Training loss: 0.01995944231748581
Validation loss: 1.3530064039332892

Epoch: 6| Step: 12
Training loss: 0.02931646816432476
Validation loss: 1.3367910436404649

Epoch: 6| Step: 13
Training loss: 0.06209605187177658
Validation loss: 1.3424430380585373

Epoch: 793| Step: 0
Training loss: 0.0345444455742836
Validation loss: 1.345364703926989

Epoch: 6| Step: 1
Training loss: 0.05482478812336922
Validation loss: 1.3517826910941833

Epoch: 6| Step: 2
Training loss: 0.02085278369486332
Validation loss: 1.3511122413860854

Epoch: 6| Step: 3
Training loss: 0.040364980697631836
Validation loss: 1.3482564751819899

Epoch: 6| Step: 4
Training loss: 0.017997652292251587
Validation loss: 1.3467765354341077

Epoch: 6| Step: 5
Training loss: 0.04687200114130974
Validation loss: 1.3452371871599587

Epoch: 6| Step: 6
Training loss: 0.03067167103290558
Validation loss: 1.3545526919826385

Epoch: 6| Step: 7
Training loss: 0.028017239645123482
Validation loss: 1.3480218008000364

Epoch: 6| Step: 8
Training loss: 0.031421978026628494
Validation loss: 1.3667825293797318

Epoch: 6| Step: 9
Training loss: 0.03083888068795204
Validation loss: 1.3565695798525246

Epoch: 6| Step: 10
Training loss: 0.025937799364328384
Validation loss: 1.3586612170742405

Epoch: 6| Step: 11
Training loss: 0.04159730672836304
Validation loss: 1.353419638449146

Epoch: 6| Step: 12
Training loss: 0.044055454432964325
Validation loss: 1.3702083467155375

Epoch: 6| Step: 13
Training loss: 0.033257100731134415
Validation loss: 1.367164509270781

Epoch: 794| Step: 0
Training loss: 0.02419140934944153
Validation loss: 1.356846224556687

Epoch: 6| Step: 1
Training loss: 0.039115116000175476
Validation loss: 1.3634555185994794

Epoch: 6| Step: 2
Training loss: 0.03188329190015793
Validation loss: 1.3717866533546037

Epoch: 6| Step: 3
Training loss: 0.028165176510810852
Validation loss: 1.356814330623996

Epoch: 6| Step: 4
Training loss: 0.01732601597905159
Validation loss: 1.3671570849675003

Epoch: 6| Step: 5
Training loss: 0.027958832681179047
Validation loss: 1.3593569109516759

Epoch: 6| Step: 6
Training loss: 0.044922586530447006
Validation loss: 1.3509933410152313

Epoch: 6| Step: 7
Training loss: 0.05770371854305267
Validation loss: 1.3543378294155162

Epoch: 6| Step: 8
Training loss: 0.0471130833029747
Validation loss: 1.3614830111944547

Epoch: 6| Step: 9
Training loss: 0.038398683071136475
Validation loss: 1.3654709272487189

Epoch: 6| Step: 10
Training loss: 0.05040925741195679
Validation loss: 1.37836592940874

Epoch: 6| Step: 11
Training loss: 0.05831487476825714
Validation loss: 1.381514451837027

Epoch: 6| Step: 12
Training loss: 0.06925897300243378
Validation loss: 1.3941419304058116

Epoch: 6| Step: 13
Training loss: 0.02824137918651104
Validation loss: 1.3861035967385897

Epoch: 795| Step: 0
Training loss: 0.049784593284130096
Validation loss: 1.3785164574141144

Epoch: 6| Step: 1
Training loss: 0.03570607304573059
Validation loss: 1.3662684258594309

Epoch: 6| Step: 2
Training loss: 0.022738084197044373
Validation loss: 1.3477414141419113

Epoch: 6| Step: 3
Training loss: 0.033906616270542145
Validation loss: 1.3457512829893379

Epoch: 6| Step: 4
Training loss: 0.029106710106134415
Validation loss: 1.368967693339112

Epoch: 6| Step: 5
Training loss: 0.04232403635978699
Validation loss: 1.3542596473488757

Epoch: 6| Step: 6
Training loss: 0.055469613522291183
Validation loss: 1.3530754581574471

Epoch: 6| Step: 7
Training loss: 0.048167355358600616
Validation loss: 1.3561697967590824

Epoch: 6| Step: 8
Training loss: 0.047415681183338165
Validation loss: 1.3486965971608316

Epoch: 6| Step: 9
Training loss: 0.034619979560375214
Validation loss: 1.3595349827120382

Epoch: 6| Step: 10
Training loss: 0.03924819827079773
Validation loss: 1.3479036182485602

Epoch: 6| Step: 11
Training loss: 0.019973985850811005
Validation loss: 1.3521632891829296

Epoch: 6| Step: 12
Training loss: 0.027507856488227844
Validation loss: 1.3493357666077153

Epoch: 6| Step: 13
Training loss: 0.05633179843425751
Validation loss: 1.3626053282009658

Epoch: 796| Step: 0
Training loss: 0.046538546681404114
Validation loss: 1.353054263258493

Epoch: 6| Step: 1
Training loss: 0.04713550955057144
Validation loss: 1.3595360466229018

Epoch: 6| Step: 2
Training loss: 0.03477461636066437
Validation loss: 1.3341459843420214

Epoch: 6| Step: 3
Training loss: 0.04351921007037163
Validation loss: 1.3642339808966524

Epoch: 6| Step: 4
Training loss: 0.026207061484456062
Validation loss: 1.3439487590584704

Epoch: 6| Step: 5
Training loss: 0.05927322804927826
Validation loss: 1.353268410569878

Epoch: 6| Step: 6
Training loss: 0.03977716341614723
Validation loss: 1.3450439194197297

Epoch: 6| Step: 7
Training loss: 0.031156152486801147
Validation loss: 1.3428571608758741

Epoch: 6| Step: 8
Training loss: 0.03541731834411621
Validation loss: 1.353793417253802

Epoch: 6| Step: 9
Training loss: 0.03614433854818344
Validation loss: 1.361736205957269

Epoch: 6| Step: 10
Training loss: 0.029474906623363495
Validation loss: 1.3566922795388006

Epoch: 6| Step: 11
Training loss: 0.04160725697875023
Validation loss: 1.355348592163414

Epoch: 6| Step: 12
Training loss: 0.05927426740527153
Validation loss: 1.3522228284548687

Epoch: 6| Step: 13
Training loss: 0.0357823446393013
Validation loss: 1.3375152490472282

Epoch: 797| Step: 0
Training loss: 0.03383428603410721
Validation loss: 1.349416075214263

Epoch: 6| Step: 1
Training loss: 0.02975301444530487
Validation loss: 1.341902143211775

Epoch: 6| Step: 2
Training loss: 0.05168469250202179
Validation loss: 1.3428806803559745

Epoch: 6| Step: 3
Training loss: 0.03161598742008209
Validation loss: 1.3489344889117825

Epoch: 6| Step: 4
Training loss: 0.02931022271513939
Validation loss: 1.365456142733174

Epoch: 6| Step: 5
Training loss: 0.03820072114467621
Validation loss: 1.3528417195043256

Epoch: 6| Step: 6
Training loss: 0.048925887793302536
Validation loss: 1.33286714553833

Epoch: 6| Step: 7
Training loss: 0.04601634293794632
Validation loss: 1.3480508301847725

Epoch: 6| Step: 8
Training loss: 0.03590410202741623
Validation loss: 1.3597636633021857

Epoch: 6| Step: 9
Training loss: 0.029688268899917603
Validation loss: 1.3585470325203353

Epoch: 6| Step: 10
Training loss: 0.041867438703775406
Validation loss: 1.3554457951617498

Epoch: 6| Step: 11
Training loss: 0.03377313166856766
Validation loss: 1.3822595111785396

Epoch: 6| Step: 12
Training loss: 0.03531371429562569
Validation loss: 1.3645022774255404

Epoch: 6| Step: 13
Training loss: 0.032637689262628555
Validation loss: 1.3680087904776297

Epoch: 798| Step: 0
Training loss: 0.04589276760816574
Validation loss: 1.374503679172967

Epoch: 6| Step: 1
Training loss: 0.03934784233570099
Validation loss: 1.3592666246557747

Epoch: 6| Step: 2
Training loss: 0.055581800639629364
Validation loss: 1.3520812808826406

Epoch: 6| Step: 3
Training loss: 0.04451913386583328
Validation loss: 1.35642453675629

Epoch: 6| Step: 4
Training loss: 0.033327292650938034
Validation loss: 1.351420283317566

Epoch: 6| Step: 5
Training loss: 0.02779270149767399
Validation loss: 1.3412908777113883

Epoch: 6| Step: 6
Training loss: 0.0434006042778492
Validation loss: 1.35115800621689

Epoch: 6| Step: 7
Training loss: 0.033678289502859116
Validation loss: 1.338781436284383

Epoch: 6| Step: 8
Training loss: 0.046132124960422516
Validation loss: 1.365530881830441

Epoch: 6| Step: 9
Training loss: 0.030228955671191216
Validation loss: 1.3479132049827165

Epoch: 6| Step: 10
Training loss: 0.026321448385715485
Validation loss: 1.37004171007423

Epoch: 6| Step: 11
Training loss: 0.03922164440155029
Validation loss: 1.359795367845925

Epoch: 6| Step: 12
Training loss: 0.04479318857192993
Validation loss: 1.3579470649842293

Epoch: 6| Step: 13
Training loss: 0.06696600466966629
Validation loss: 1.3549425601959229

Epoch: 799| Step: 0
Training loss: 0.02132745087146759
Validation loss: 1.3590970193186114

Epoch: 6| Step: 1
Training loss: 0.03699244558811188
Validation loss: 1.3482310387396044

Epoch: 6| Step: 2
Training loss: 0.039913877844810486
Validation loss: 1.3538406382324875

Epoch: 6| Step: 3
Training loss: 0.0601491704583168
Validation loss: 1.363175001516137

Epoch: 6| Step: 4
Training loss: 0.04690784960985184
Validation loss: 1.3567724702178792

Epoch: 6| Step: 5
Training loss: 0.04832122102379799
Validation loss: 1.370027466486859

Epoch: 6| Step: 6
Training loss: 0.04289848357439041
Validation loss: 1.362830520958029

Epoch: 6| Step: 7
Training loss: 0.03216751664876938
Validation loss: 1.366714903103408

Epoch: 6| Step: 8
Training loss: 0.050359103828668594
Validation loss: 1.371673822402954

Epoch: 6| Step: 9
Training loss: 0.05703171342611313
Validation loss: 1.3675606096944501

Epoch: 6| Step: 10
Training loss: 0.02262227237224579
Validation loss: 1.3908917519354052

Epoch: 6| Step: 11
Training loss: 0.04949239641427994
Validation loss: 1.3662103055625834

Epoch: 6| Step: 12
Training loss: 0.03555125370621681
Validation loss: 1.3725521410665205

Epoch: 6| Step: 13
Training loss: 0.02214094065129757
Validation loss: 1.3504403598846928

Epoch: 800| Step: 0
Training loss: 0.037858206778764725
Validation loss: 1.370320418829559

Epoch: 6| Step: 1
Training loss: 0.03880700841546059
Validation loss: 1.3413595332894275

Epoch: 6| Step: 2
Training loss: 0.03414604067802429
Validation loss: 1.3610761409164758

Epoch: 6| Step: 3
Training loss: 0.03227195888757706
Validation loss: 1.3493211859016008

Epoch: 6| Step: 4
Training loss: 0.05001174658536911
Validation loss: 1.3379726358639297

Epoch: 6| Step: 5
Training loss: 0.04532668739557266
Validation loss: 1.3385603017704462

Epoch: 6| Step: 6
Training loss: 0.019971663132309914
Validation loss: 1.3335389988396757

Epoch: 6| Step: 7
Training loss: 0.026012668386101723
Validation loss: 1.3407072258251969

Epoch: 6| Step: 8
Training loss: 0.04343205690383911
Validation loss: 1.3513213985709733

Epoch: 6| Step: 9
Training loss: 0.04393361508846283
Validation loss: 1.331947289487367

Epoch: 6| Step: 10
Training loss: 0.015750713646411896
Validation loss: 1.3302363798182497

Epoch: 6| Step: 11
Training loss: 0.041094280779361725
Validation loss: 1.3538591092632664

Epoch: 6| Step: 12
Training loss: 0.04596838727593422
Validation loss: 1.3337734271121282

Epoch: 6| Step: 13
Training loss: 0.030637681484222412
Validation loss: 1.3488802973942091

Testing loss: 2.218494447072347
