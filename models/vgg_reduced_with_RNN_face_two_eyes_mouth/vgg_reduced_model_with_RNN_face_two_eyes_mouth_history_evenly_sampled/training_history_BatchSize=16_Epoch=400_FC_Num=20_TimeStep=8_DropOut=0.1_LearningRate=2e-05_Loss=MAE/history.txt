Epoch: 1| Step: 0
Training loss: 3.9906296730041504
Validation loss: 5.15248381194248

Epoch: 6| Step: 1
Training loss: 4.461171627044678
Validation loss: 5.134473854495633

Epoch: 6| Step: 2
Training loss: 5.779956817626953
Validation loss: 5.118805587932628

Epoch: 6| Step: 3
Training loss: 5.042680263519287
Validation loss: 5.1022284056550715

Epoch: 6| Step: 4
Training loss: 4.629372596740723
Validation loss: 5.083831838382188

Epoch: 6| Step: 5
Training loss: 4.848345756530762
Validation loss: 5.062743750951624

Epoch: 6| Step: 6
Training loss: 4.319864273071289
Validation loss: 5.039121950826337

Epoch: 6| Step: 7
Training loss: 3.440636157989502
Validation loss: 5.011310692756407

Epoch: 6| Step: 8
Training loss: 4.625456809997559
Validation loss: 4.979608510130195

Epoch: 6| Step: 9
Training loss: 5.658675670623779
Validation loss: 4.9449777808240665

Epoch: 6| Step: 10
Training loss: 4.429563045501709
Validation loss: 4.9039103959196355

Epoch: 6| Step: 11
Training loss: 5.252965927124023
Validation loss: 4.859515579797888

Epoch: 6| Step: 12
Training loss: 5.714907646179199
Validation loss: 4.8079559777372625

Epoch: 6| Step: 13
Training loss: 5.065474987030029
Validation loss: 4.75077094826647

Epoch: 2| Step: 0
Training loss: 3.742900848388672
Validation loss: 4.691276399038172

Epoch: 6| Step: 1
Training loss: 5.249367713928223
Validation loss: 4.628786774091823

Epoch: 6| Step: 2
Training loss: 4.443238735198975
Validation loss: 4.562527666809738

Epoch: 6| Step: 3
Training loss: 3.6719765663146973
Validation loss: 4.495504999673495

Epoch: 6| Step: 4
Training loss: 4.122682094573975
Validation loss: 4.429230718202488

Epoch: 6| Step: 5
Training loss: 4.708830833435059
Validation loss: 4.36415224177863

Epoch: 6| Step: 6
Training loss: 4.454495906829834
Validation loss: 4.304733337894563

Epoch: 6| Step: 7
Training loss: 4.128070831298828
Validation loss: 4.250067516039777

Epoch: 6| Step: 8
Training loss: 3.8623242378234863
Validation loss: 4.198879395761797

Epoch: 6| Step: 9
Training loss: 3.5536370277404785
Validation loss: 4.149229813647526

Epoch: 6| Step: 10
Training loss: 4.161090850830078
Validation loss: 4.099773727437501

Epoch: 6| Step: 11
Training loss: 3.8185641765594482
Validation loss: 4.0520376902754585

Epoch: 6| Step: 12
Training loss: 4.147573471069336
Validation loss: 4.013309445432437

Epoch: 6| Step: 13
Training loss: 3.497241973876953
Validation loss: 3.980393350765269

Epoch: 3| Step: 0
Training loss: 3.4893274307250977
Validation loss: 3.944261504757789

Epoch: 6| Step: 1
Training loss: 3.9805407524108887
Validation loss: 3.904540228587325

Epoch: 6| Step: 2
Training loss: 3.0128395557403564
Validation loss: 3.8742069275148454

Epoch: 6| Step: 3
Training loss: 4.221129417419434
Validation loss: 3.8502737578525337

Epoch: 6| Step: 4
Training loss: 3.3977174758911133
Validation loss: 3.824540379226849

Epoch: 6| Step: 5
Training loss: 3.9885940551757812
Validation loss: 3.798743842750467

Epoch: 6| Step: 6
Training loss: 3.516026496887207
Validation loss: 3.7713140800435054

Epoch: 6| Step: 7
Training loss: 4.0239996910095215
Validation loss: 3.7399269175785843

Epoch: 6| Step: 8
Training loss: 3.2941670417785645
Validation loss: 3.7042143883243686

Epoch: 6| Step: 9
Training loss: 3.6327803134918213
Validation loss: 3.6719832035803024

Epoch: 6| Step: 10
Training loss: 3.8670148849487305
Validation loss: 3.6424845931350545

Epoch: 6| Step: 11
Training loss: 3.1401519775390625
Validation loss: 3.6204233605374574

Epoch: 6| Step: 12
Training loss: 4.6551079750061035
Validation loss: 3.600817157376197

Epoch: 6| Step: 13
Training loss: 2.2614126205444336
Validation loss: 3.582637092118622

Epoch: 4| Step: 0
Training loss: 3.4509801864624023
Validation loss: 3.564541196310392

Epoch: 6| Step: 1
Training loss: 3.362973213195801
Validation loss: 3.510936693478656

Epoch: 6| Step: 2
Training loss: 2.528567314147949
Validation loss: 3.4922578488626788

Epoch: 6| Step: 3
Training loss: 3.3743174076080322
Validation loss: 3.474102948301582

Epoch: 6| Step: 4
Training loss: 3.8745977878570557
Validation loss: 3.456568620538199

Epoch: 6| Step: 5
Training loss: 2.819864273071289
Validation loss: 3.4416157404581704

Epoch: 6| Step: 6
Training loss: 3.212756395339966
Validation loss: 3.4279275581400883

Epoch: 6| Step: 7
Training loss: 3.9479479789733887
Validation loss: 3.413367045822964

Epoch: 6| Step: 8
Training loss: 4.046797752380371
Validation loss: 3.4001185150556665

Epoch: 6| Step: 9
Training loss: 3.827592372894287
Validation loss: 3.3869956693341656

Epoch: 6| Step: 10
Training loss: 3.8253278732299805
Validation loss: 3.3763535868737007

Epoch: 6| Step: 11
Training loss: 2.8841421604156494
Validation loss: 3.363713454174739

Epoch: 6| Step: 12
Training loss: 2.628349781036377
Validation loss: 3.355714697991648

Epoch: 6| Step: 13
Training loss: 3.598045825958252
Validation loss: 3.345430435672883

Epoch: 5| Step: 0
Training loss: 2.593018054962158
Validation loss: 3.3347197399344495

Epoch: 6| Step: 1
Training loss: 3.239184617996216
Validation loss: 3.325686962373795

Epoch: 6| Step: 2
Training loss: 5.046562194824219
Validation loss: 3.3142660484519055

Epoch: 6| Step: 3
Training loss: 1.7206333875656128
Validation loss: 3.3004184025590138

Epoch: 6| Step: 4
Training loss: 3.610970973968506
Validation loss: 3.2903145897773003

Epoch: 6| Step: 5
Training loss: 3.5765697956085205
Validation loss: 3.281127522068639

Epoch: 6| Step: 6
Training loss: 3.088261127471924
Validation loss: 3.2688549103275424

Epoch: 6| Step: 7
Training loss: 2.9547014236450195
Validation loss: 3.2626332980330273

Epoch: 6| Step: 8
Training loss: 2.9616317749023438
Validation loss: 3.2525888207138225

Epoch: 6| Step: 9
Training loss: 3.8567872047424316
Validation loss: 3.248774008084369

Epoch: 6| Step: 10
Training loss: 2.554718494415283
Validation loss: 3.2401622649162047

Epoch: 6| Step: 11
Training loss: 2.884615898132324
Validation loss: 3.2288595168821272

Epoch: 6| Step: 12
Training loss: 3.8429200649261475
Validation loss: 3.2168205271485033

Epoch: 6| Step: 13
Training loss: 3.7930331230163574
Validation loss: 3.205873627816477

Epoch: 6| Step: 0
Training loss: 3.0938663482666016
Validation loss: 3.197109478776173

Epoch: 6| Step: 1
Training loss: 2.5905826091766357
Validation loss: 3.1905430952707925

Epoch: 6| Step: 2
Training loss: 3.275219440460205
Validation loss: 3.181767007356049

Epoch: 6| Step: 3
Training loss: 3.693323850631714
Validation loss: 3.168542556865241

Epoch: 6| Step: 4
Training loss: 2.3320398330688477
Validation loss: 3.163139130479546

Epoch: 6| Step: 5
Training loss: 3.0468549728393555
Validation loss: 3.1591963255277244

Epoch: 6| Step: 6
Training loss: 3.274017572402954
Validation loss: 3.153128126616119

Epoch: 6| Step: 7
Training loss: 4.022164344787598
Validation loss: 3.1379071717621176

Epoch: 6| Step: 8
Training loss: 2.999523639678955
Validation loss: 3.1221675667711484

Epoch: 6| Step: 9
Training loss: 2.2825124263763428
Validation loss: 3.1115937284244004

Epoch: 6| Step: 10
Training loss: 2.750840187072754
Validation loss: 3.105197791130312

Epoch: 6| Step: 11
Training loss: 3.730236291885376
Validation loss: 3.0951860745747886

Epoch: 6| Step: 12
Training loss: 3.1936519145965576
Validation loss: 3.0863696734110513

Epoch: 6| Step: 13
Training loss: 4.455691337585449
Validation loss: 3.0791341591906805

Epoch: 7| Step: 0
Training loss: 3.8402628898620605
Validation loss: 3.0667978640525573

Epoch: 6| Step: 1
Training loss: 2.260509967803955
Validation loss: 3.059104170850528

Epoch: 6| Step: 2
Training loss: 2.0068633556365967
Validation loss: 3.048302299232893

Epoch: 6| Step: 3
Training loss: 3.780524730682373
Validation loss: 3.039813574924264

Epoch: 6| Step: 4
Training loss: 3.8069305419921875
Validation loss: 3.035345221078524

Epoch: 6| Step: 5
Training loss: 2.9502382278442383
Validation loss: 3.0258865048808437

Epoch: 6| Step: 6
Training loss: 2.5206661224365234
Validation loss: 3.0204151163819017

Epoch: 6| Step: 7
Training loss: 3.0890164375305176
Validation loss: 3.0117617755807857

Epoch: 6| Step: 8
Training loss: 3.118281602859497
Validation loss: 3.010181934602799

Epoch: 6| Step: 9
Training loss: 3.3859548568725586
Validation loss: 3.0019508997599282

Epoch: 6| Step: 10
Training loss: 4.2094950675964355
Validation loss: 2.994781632577219

Epoch: 6| Step: 11
Training loss: 3.147684335708618
Validation loss: 2.9905139605204263

Epoch: 6| Step: 12
Training loss: 2.572908878326416
Validation loss: 2.9863429479701544

Epoch: 6| Step: 13
Training loss: 1.8856040239334106
Validation loss: 2.979458398716424

Epoch: 8| Step: 0
Training loss: 2.6619715690612793
Validation loss: 2.972098901707639

Epoch: 6| Step: 1
Training loss: 2.7093143463134766
Validation loss: 2.964420736476939

Epoch: 6| Step: 2
Training loss: 2.0249032974243164
Validation loss: 2.9590070273286555

Epoch: 6| Step: 3
Training loss: 4.055798530578613
Validation loss: 2.9547319822413947

Epoch: 6| Step: 4
Training loss: 3.316193103790283
Validation loss: 2.9471303211745394

Epoch: 6| Step: 5
Training loss: 2.37857985496521
Validation loss: 2.9435246400935675

Epoch: 6| Step: 6
Training loss: 3.460815906524658
Validation loss: 2.940448389258436

Epoch: 6| Step: 7
Training loss: 4.280210494995117
Validation loss: 2.9345397398036015

Epoch: 6| Step: 8
Training loss: 2.7697360515594482
Validation loss: 2.92744872390583

Epoch: 6| Step: 9
Training loss: 2.484673023223877
Validation loss: 2.920007480088101

Epoch: 6| Step: 10
Training loss: 2.705176830291748
Validation loss: 2.915510869795276

Epoch: 6| Step: 11
Training loss: 2.9820175170898438
Validation loss: 2.9119434433598674

Epoch: 6| Step: 12
Training loss: 3.3073134422302246
Validation loss: 2.908165095954813

Epoch: 6| Step: 13
Training loss: 3.2326841354370117
Validation loss: 2.89570814307018

Epoch: 9| Step: 0
Training loss: 3.0448670387268066
Validation loss: 2.8958003879875265

Epoch: 6| Step: 1
Training loss: 3.320671796798706
Validation loss: 2.894972821717621

Epoch: 6| Step: 2
Training loss: 1.8424386978149414
Validation loss: 2.8900134614718858

Epoch: 6| Step: 3
Training loss: 3.5062384605407715
Validation loss: 2.878868461937033

Epoch: 6| Step: 4
Training loss: 2.77963924407959
Validation loss: 2.8704576953764884

Epoch: 6| Step: 5
Training loss: 2.8544998168945312
Validation loss: 2.863649909214307

Epoch: 6| Step: 6
Training loss: 3.0382895469665527
Validation loss: 2.8619813329430035

Epoch: 6| Step: 7
Training loss: 2.5709357261657715
Validation loss: 2.8564480735409643

Epoch: 6| Step: 8
Training loss: 2.662574529647827
Validation loss: 2.8477216433453303

Epoch: 6| Step: 9
Training loss: 4.157590866088867
Validation loss: 2.8409732849367204

Epoch: 6| Step: 10
Training loss: 2.960249423980713
Validation loss: 2.8344399506045925

Epoch: 6| Step: 11
Training loss: 2.9465837478637695
Validation loss: 2.827777390838951

Epoch: 6| Step: 12
Training loss: 3.4075675010681152
Validation loss: 2.823955423088484

Epoch: 6| Step: 13
Training loss: 2.236279249191284
Validation loss: 2.8154211121220745

Epoch: 10| Step: 0
Training loss: 3.2610573768615723
Validation loss: 2.85939424268661

Epoch: 6| Step: 1
Training loss: 2.4642558097839355
Validation loss: 2.8126267105020504

Epoch: 6| Step: 2
Training loss: 2.7325868606567383
Validation loss: 2.8071939329947195

Epoch: 6| Step: 3
Training loss: 2.5321030616760254
Validation loss: 2.8089986872929398

Epoch: 6| Step: 4
Training loss: 2.902700662612915
Validation loss: 2.816077493852185

Epoch: 6| Step: 5
Training loss: 2.79167103767395
Validation loss: 2.819001523397302

Epoch: 6| Step: 6
Training loss: 3.1119308471679688
Validation loss: 2.8412614663441977

Epoch: 6| Step: 7
Training loss: 2.714632034301758
Validation loss: 2.844245961917344

Epoch: 6| Step: 8
Training loss: 3.8162310123443604
Validation loss: 2.827848957430932

Epoch: 6| Step: 9
Training loss: 3.1685447692871094
Validation loss: 2.8047106624931417

Epoch: 6| Step: 10
Training loss: 2.2138373851776123
Validation loss: 2.808244876964118

Epoch: 6| Step: 11
Training loss: 2.91959810256958
Validation loss: 2.8145290625992643

Epoch: 6| Step: 12
Training loss: 3.509045362472534
Validation loss: 2.80890404793524

Epoch: 6| Step: 13
Training loss: 3.266268014907837
Validation loss: 2.7984272100592174

Epoch: 11| Step: 0
Training loss: 2.6697845458984375
Validation loss: 2.812143797515541

Epoch: 6| Step: 1
Training loss: 2.949162483215332
Validation loss: 2.8592305619229554

Epoch: 6| Step: 2
Training loss: 2.799419403076172
Validation loss: 2.854089988175259

Epoch: 6| Step: 3
Training loss: 2.469910144805908
Validation loss: 2.840782509055189

Epoch: 6| Step: 4
Training loss: 2.7976021766662598
Validation loss: 2.819965595840126

Epoch: 6| Step: 5
Training loss: 3.0142292976379395
Validation loss: 2.7765787878344135

Epoch: 6| Step: 6
Training loss: 2.5075855255126953
Validation loss: 2.78957438212569

Epoch: 6| Step: 7
Training loss: 2.67163348197937
Validation loss: 2.8005336176964546

Epoch: 6| Step: 8
Training loss: 3.4701027870178223
Validation loss: 2.799535087359849

Epoch: 6| Step: 9
Training loss: 3.584432601928711
Validation loss: 2.784267812646845

Epoch: 6| Step: 10
Training loss: 2.8140246868133545
Validation loss: 2.7527970447335193

Epoch: 6| Step: 11
Training loss: 3.1672251224517822
Validation loss: 2.7477562504429973

Epoch: 6| Step: 12
Training loss: 3.058291435241699
Validation loss: 2.76007241587485

Epoch: 6| Step: 13
Training loss: 3.038876533508301
Validation loss: 2.7652298301778813

Epoch: 12| Step: 0
Training loss: 2.992886543273926
Validation loss: 2.7813856396623837

Epoch: 6| Step: 1
Training loss: 4.0272536277771
Validation loss: 2.783983261354508

Epoch: 6| Step: 2
Training loss: 3.1745381355285645
Validation loss: 2.742095737047093

Epoch: 6| Step: 3
Training loss: 3.931708812713623
Validation loss: 2.734338996230915

Epoch: 6| Step: 4
Training loss: 2.544088840484619
Validation loss: 2.7261747083356305

Epoch: 6| Step: 5
Training loss: 2.5223324298858643
Validation loss: 2.7344212634589082

Epoch: 6| Step: 6
Training loss: 3.130826711654663
Validation loss: 2.7467551795385217

Epoch: 6| Step: 7
Training loss: 2.6787571907043457
Validation loss: 2.7363123586100917

Epoch: 6| Step: 8
Training loss: 2.906468391418457
Validation loss: 2.7175657672266804

Epoch: 6| Step: 9
Training loss: 2.5729479789733887
Validation loss: 2.719877262269297

Epoch: 6| Step: 10
Training loss: 2.0249805450439453
Validation loss: 2.707704374867101

Epoch: 6| Step: 11
Training loss: 2.6403162479400635
Validation loss: 2.698876529611567

Epoch: 6| Step: 12
Training loss: 2.014827251434326
Validation loss: 2.6970765308667253

Epoch: 6| Step: 13
Training loss: 3.7218432426452637
Validation loss: 2.699864697712724

Epoch: 13| Step: 0
Training loss: 2.443492889404297
Validation loss: 2.7093085883766093

Epoch: 6| Step: 1
Training loss: 2.9998621940612793
Validation loss: 2.699828573452529

Epoch: 6| Step: 2
Training loss: 1.9522316455841064
Validation loss: 2.6873101649745816

Epoch: 6| Step: 3
Training loss: 3.404932975769043
Validation loss: 2.6864687217179166

Epoch: 6| Step: 4
Training loss: 3.1557059288024902
Validation loss: 2.6845816719916558

Epoch: 6| Step: 5
Training loss: 3.4746081829071045
Validation loss: 2.681998481032669

Epoch: 6| Step: 6
Training loss: 3.310948133468628
Validation loss: 2.6789708650240334

Epoch: 6| Step: 7
Training loss: 3.2921907901763916
Validation loss: 2.675299523979105

Epoch: 6| Step: 8
Training loss: 2.5849952697753906
Validation loss: 2.6712533274004535

Epoch: 6| Step: 9
Training loss: 2.7629525661468506
Validation loss: 2.67248269050352

Epoch: 6| Step: 10
Training loss: 2.6996116638183594
Validation loss: 2.681984883482738

Epoch: 6| Step: 11
Training loss: 2.001952648162842
Validation loss: 2.7216655310764106

Epoch: 6| Step: 12
Training loss: 2.873577356338501
Validation loss: 2.700134538835095

Epoch: 6| Step: 13
Training loss: 3.106069326400757
Validation loss: 2.6596791128958426

Epoch: 14| Step: 0
Training loss: 2.7028307914733887
Validation loss: 2.6533268215835735

Epoch: 6| Step: 1
Training loss: 3.1956613063812256
Validation loss: 2.647988562942833

Epoch: 6| Step: 2
Training loss: 2.9945175647735596
Validation loss: 2.6456833244651876

Epoch: 6| Step: 3
Training loss: 2.763716220855713
Validation loss: 2.6392148720320834

Epoch: 6| Step: 4
Training loss: 1.9620877504348755
Validation loss: 2.639771371759394

Epoch: 6| Step: 5
Training loss: 2.047550678253174
Validation loss: 2.638485849544566

Epoch: 6| Step: 6
Training loss: 2.369065999984741
Validation loss: 2.6372981302199827

Epoch: 6| Step: 7
Training loss: 3.6242740154266357
Validation loss: 2.6438347549848658

Epoch: 6| Step: 8
Training loss: 2.8751533031463623
Validation loss: 2.630709404586464

Epoch: 6| Step: 9
Training loss: 2.8331310749053955
Validation loss: 2.642030615960398

Epoch: 6| Step: 10
Training loss: 2.81624174118042
Validation loss: 2.628587176722865

Epoch: 6| Step: 11
Training loss: 2.8364224433898926
Validation loss: 2.6197428677671697

Epoch: 6| Step: 12
Training loss: 3.5797982215881348
Validation loss: 2.626209666652064

Epoch: 6| Step: 13
Training loss: 2.8811538219451904
Validation loss: 2.6491235404886226

Epoch: 15| Step: 0
Training loss: 3.234156608581543
Validation loss: 2.73825490859247

Epoch: 6| Step: 1
Training loss: 3.152926445007324
Validation loss: 2.6827019645321752

Epoch: 6| Step: 2
Training loss: 3.387998580932617
Validation loss: 2.6219027837117515

Epoch: 6| Step: 3
Training loss: 1.749263048171997
Validation loss: 2.623679348217544

Epoch: 6| Step: 4
Training loss: 3.216911554336548
Validation loss: 2.6533594439106603

Epoch: 6| Step: 5
Training loss: 3.2075114250183105
Validation loss: 2.6495003213164625

Epoch: 6| Step: 6
Training loss: 2.7612850666046143
Validation loss: 2.6551671951047835

Epoch: 6| Step: 7
Training loss: 2.4258434772491455
Validation loss: 2.661711339027651

Epoch: 6| Step: 8
Training loss: 2.130577564239502
Validation loss: 2.6968547605699107

Epoch: 6| Step: 9
Training loss: 3.511981248855591
Validation loss: 2.685199405557366

Epoch: 6| Step: 10
Training loss: 2.7368059158325195
Validation loss: 2.6727322865557928

Epoch: 6| Step: 11
Training loss: 2.751401424407959
Validation loss: 2.659867766082928

Epoch: 6| Step: 12
Training loss: 2.5996570587158203
Validation loss: 2.6506719691779024

Epoch: 6| Step: 13
Training loss: 2.8984713554382324
Validation loss: 2.638936270949661

Epoch: 16| Step: 0
Training loss: 2.082566022872925
Validation loss: 2.635226506058888

Epoch: 6| Step: 1
Training loss: 3.3537392616271973
Validation loss: 2.6355167947789675

Epoch: 6| Step: 2
Training loss: 2.7247443199157715
Validation loss: 2.6218866327757477

Epoch: 6| Step: 3
Training loss: 3.7730026245117188
Validation loss: 2.6220187423049763

Epoch: 6| Step: 4
Training loss: 2.454540252685547
Validation loss: 2.606017005059027

Epoch: 6| Step: 5
Training loss: 2.4440155029296875
Validation loss: 2.6063878100405455

Epoch: 6| Step: 6
Training loss: 2.377896785736084
Validation loss: 2.624199980048723

Epoch: 6| Step: 7
Training loss: 2.1749777793884277
Validation loss: 2.6052755104598178

Epoch: 6| Step: 8
Training loss: 3.251546859741211
Validation loss: 2.596724412774527

Epoch: 6| Step: 9
Training loss: 3.7014822959899902
Validation loss: 2.6150713556556293

Epoch: 6| Step: 10
Training loss: 2.8036653995513916
Validation loss: 2.595915389317338

Epoch: 6| Step: 11
Training loss: 3.018293857574463
Validation loss: 2.59630847489962

Epoch: 6| Step: 12
Training loss: 2.0676615238189697
Validation loss: 2.591841161891978

Epoch: 6| Step: 13
Training loss: 2.946167230606079
Validation loss: 2.5882298715652956

Epoch: 17| Step: 0
Training loss: 3.1162285804748535
Validation loss: 2.588612899985365

Epoch: 6| Step: 1
Training loss: 2.4348974227905273
Validation loss: 2.583764247996833

Epoch: 6| Step: 2
Training loss: 2.682856559753418
Validation loss: 2.5814964232906217

Epoch: 6| Step: 3
Training loss: 2.849499225616455
Validation loss: 2.5773759400972756

Epoch: 6| Step: 4
Training loss: 2.073768138885498
Validation loss: 2.569322919332853

Epoch: 6| Step: 5
Training loss: 3.1935901641845703
Validation loss: 2.572501431229294

Epoch: 6| Step: 6
Training loss: 2.048346757888794
Validation loss: 2.579666083858859

Epoch: 6| Step: 7
Training loss: 2.9469826221466064
Validation loss: 2.588391022015643

Epoch: 6| Step: 8
Training loss: 3.7663750648498535
Validation loss: 2.575839666910069

Epoch: 6| Step: 9
Training loss: 2.7116167545318604
Validation loss: 2.5711233231329147

Epoch: 6| Step: 10
Training loss: 2.844618797302246
Validation loss: 2.56712112375485

Epoch: 6| Step: 11
Training loss: 2.699763774871826
Validation loss: 2.5615693112855316

Epoch: 6| Step: 12
Training loss: 2.8536806106567383
Validation loss: 2.5592216061007593

Epoch: 6| Step: 13
Training loss: 2.375067710876465
Validation loss: 2.559362990881807

Epoch: 18| Step: 0
Training loss: 2.754221200942993
Validation loss: 2.5629769243219847

Epoch: 6| Step: 1
Training loss: 2.8948559761047363
Validation loss: 2.5602226129142185

Epoch: 6| Step: 2
Training loss: 2.19533371925354
Validation loss: 2.5581654451226674

Epoch: 6| Step: 3
Training loss: 1.840423345565796
Validation loss: 2.5553793907165527

Epoch: 6| Step: 4
Training loss: 4.11151647567749
Validation loss: 2.5597087055124264

Epoch: 6| Step: 5
Training loss: 2.4823336601257324
Validation loss: 2.5617755459200953

Epoch: 6| Step: 6
Training loss: 2.315552234649658
Validation loss: 2.5897937948985765

Epoch: 6| Step: 7
Training loss: 3.208378314971924
Validation loss: 2.609500831173312

Epoch: 6| Step: 8
Training loss: 3.0707879066467285
Validation loss: 2.593120874897126

Epoch: 6| Step: 9
Training loss: 2.724987030029297
Validation loss: 2.557188231457946

Epoch: 6| Step: 10
Training loss: 2.5025534629821777
Validation loss: 2.5470565544661654

Epoch: 6| Step: 11
Training loss: 3.1785974502563477
Validation loss: 2.547308455231369

Epoch: 6| Step: 12
Training loss: 2.103851318359375
Validation loss: 2.553635422901441

Epoch: 6| Step: 13
Training loss: 3.8817341327667236
Validation loss: 2.554317843529486

Epoch: 19| Step: 0
Training loss: 3.6036181449890137
Validation loss: 2.5505720953787527

Epoch: 6| Step: 1
Training loss: 2.815828800201416
Validation loss: 2.545686073200677

Epoch: 6| Step: 2
Training loss: 2.387035369873047
Validation loss: 2.538488208606679

Epoch: 6| Step: 3
Training loss: 1.8287185430526733
Validation loss: 2.5401721205762637

Epoch: 6| Step: 4
Training loss: 3.0530521869659424
Validation loss: 2.568414242036881

Epoch: 6| Step: 5
Training loss: 2.946406841278076
Validation loss: 2.609780147511472

Epoch: 6| Step: 6
Training loss: 2.873621940612793
Validation loss: 2.648591741438835

Epoch: 6| Step: 7
Training loss: 2.8647420406341553
Validation loss: 2.705876632403302

Epoch: 6| Step: 8
Training loss: 3.0862135887145996
Validation loss: 2.740497053310435

Epoch: 6| Step: 9
Training loss: 2.701725482940674
Validation loss: 2.6508744378243723

Epoch: 6| Step: 10
Training loss: 3.294672727584839
Validation loss: 2.5836301926643617

Epoch: 6| Step: 11
Training loss: 2.4298672676086426
Validation loss: 2.5367778680657826

Epoch: 6| Step: 12
Training loss: 2.2647006511688232
Validation loss: 2.5305150862663024

Epoch: 6| Step: 13
Training loss: 2.671794891357422
Validation loss: 2.5423883520146853

Epoch: 20| Step: 0
Training loss: 2.673814535140991
Validation loss: 2.5755903772128526

Epoch: 6| Step: 1
Training loss: 2.7914485931396484
Validation loss: 2.580871843522595

Epoch: 6| Step: 2
Training loss: 3.165194511413574
Validation loss: 2.587014062430269

Epoch: 6| Step: 3
Training loss: 3.4079384803771973
Validation loss: 2.566838018355831

Epoch: 6| Step: 4
Training loss: 2.432905673980713
Validation loss: 2.547967654402538

Epoch: 6| Step: 5
Training loss: 2.824108600616455
Validation loss: 2.5368248595986316

Epoch: 6| Step: 6
Training loss: 2.5835518836975098
Validation loss: 2.529078455381496

Epoch: 6| Step: 7
Training loss: 1.858607292175293
Validation loss: 2.5274740085806897

Epoch: 6| Step: 8
Training loss: 2.8821845054626465
Validation loss: 2.530551936036797

Epoch: 6| Step: 9
Training loss: 2.9815773963928223
Validation loss: 2.5380028306796985

Epoch: 6| Step: 10
Training loss: 2.855184316635132
Validation loss: 2.53689302936677

Epoch: 6| Step: 11
Training loss: 2.7041988372802734
Validation loss: 2.532798203088904

Epoch: 6| Step: 12
Training loss: 3.5754785537719727
Validation loss: 2.5235911210378013

Epoch: 6| Step: 13
Training loss: 1.341252088546753
Validation loss: 2.518679549617152

Epoch: 21| Step: 0
Training loss: 3.464888095855713
Validation loss: 2.519471865828319

Epoch: 6| Step: 1
Training loss: 2.4484615325927734
Validation loss: 2.522538262028848

Epoch: 6| Step: 2
Training loss: 2.7928645610809326
Validation loss: 2.5191305119504213

Epoch: 6| Step: 3
Training loss: 3.7898943424224854
Validation loss: 2.521822770436605

Epoch: 6| Step: 4
Training loss: 2.1699867248535156
Validation loss: 2.5211565058718444

Epoch: 6| Step: 5
Training loss: 2.2112045288085938
Validation loss: 2.5169840730646604

Epoch: 6| Step: 6
Training loss: 2.809055805206299
Validation loss: 2.5188146970605336

Epoch: 6| Step: 7
Training loss: 1.990273118019104
Validation loss: 2.520052845760058

Epoch: 6| Step: 8
Training loss: 3.2389605045318604
Validation loss: 2.5394265113338346

Epoch: 6| Step: 9
Training loss: 2.3027353286743164
Validation loss: 2.5748390151608374

Epoch: 6| Step: 10
Training loss: 2.824044704437256
Validation loss: 2.6070650854418354

Epoch: 6| Step: 11
Training loss: 3.113375186920166
Validation loss: 2.603518016876713

Epoch: 6| Step: 12
Training loss: 2.031651496887207
Validation loss: 2.587001185263357

Epoch: 6| Step: 13
Training loss: 3.8440158367156982
Validation loss: 2.5447983972487913

Epoch: 22| Step: 0
Training loss: 2.936763286590576
Validation loss: 2.5142643708054737

Epoch: 6| Step: 1
Training loss: 2.1948013305664062
Validation loss: 2.5087486646508657

Epoch: 6| Step: 2
Training loss: 2.029088258743286
Validation loss: 2.516745239175776

Epoch: 6| Step: 3
Training loss: 3.210176467895508
Validation loss: 2.5247566417981218

Epoch: 6| Step: 4
Training loss: 2.573826313018799
Validation loss: 2.528241942005773

Epoch: 6| Step: 5
Training loss: 2.8391170501708984
Validation loss: 2.5264258371886386

Epoch: 6| Step: 6
Training loss: 2.8956570625305176
Validation loss: 2.525594775394727

Epoch: 6| Step: 7
Training loss: 2.207886219024658
Validation loss: 2.5554757041315876

Epoch: 6| Step: 8
Training loss: 3.455979108810425
Validation loss: 2.567335669712354

Epoch: 6| Step: 9
Training loss: 3.1288089752197266
Validation loss: 2.5676615545826573

Epoch: 6| Step: 10
Training loss: 2.1517386436462402
Validation loss: 2.5795137087504068

Epoch: 6| Step: 11
Training loss: 2.898362159729004
Validation loss: 2.6050756336540304

Epoch: 6| Step: 12
Training loss: 3.0731873512268066
Validation loss: 2.557557093199863

Epoch: 6| Step: 13
Training loss: 3.1410160064697266
Validation loss: 2.5200954150128108

Epoch: 23| Step: 0
Training loss: 2.84668231010437
Validation loss: 2.521354108728388

Epoch: 6| Step: 1
Training loss: 2.3358817100524902
Validation loss: 2.550347776823146

Epoch: 6| Step: 2
Training loss: 3.1785430908203125
Validation loss: 2.5704966001613165

Epoch: 6| Step: 3
Training loss: 3.175797462463379
Validation loss: 2.55465430085377

Epoch: 6| Step: 4
Training loss: 2.9521336555480957
Validation loss: 2.52786789401885

Epoch: 6| Step: 5
Training loss: 3.110605239868164
Validation loss: 2.512630012727553

Epoch: 6| Step: 6
Training loss: 2.6310274600982666
Validation loss: 2.50486155222821

Epoch: 6| Step: 7
Training loss: 2.6441588401794434
Validation loss: 2.496536813756471

Epoch: 6| Step: 8
Training loss: 2.874022960662842
Validation loss: 2.5017387226063716

Epoch: 6| Step: 9
Training loss: 2.62528133392334
Validation loss: 2.512008010700185

Epoch: 6| Step: 10
Training loss: 2.033794403076172
Validation loss: 2.5537348485762075

Epoch: 6| Step: 11
Training loss: 3.2666659355163574
Validation loss: 2.550889648416991

Epoch: 6| Step: 12
Training loss: 2.5423007011413574
Validation loss: 2.518397546583606

Epoch: 6| Step: 13
Training loss: 1.434926152229309
Validation loss: 2.498370075738558

Epoch: 24| Step: 0
Training loss: 2.640143632888794
Validation loss: 2.4908283064442296

Epoch: 6| Step: 1
Training loss: 3.0294010639190674
Validation loss: 2.4937708864929857

Epoch: 6| Step: 2
Training loss: 2.6592495441436768
Validation loss: 2.511129894564229

Epoch: 6| Step: 3
Training loss: 2.800297737121582
Validation loss: 2.5015099663888254

Epoch: 6| Step: 4
Training loss: 2.0924878120422363
Validation loss: 2.4859398731621365

Epoch: 6| Step: 5
Training loss: 2.7524707317352295
Validation loss: 2.481251121849142

Epoch: 6| Step: 6
Training loss: 2.1309008598327637
Validation loss: 2.4823331063793552

Epoch: 6| Step: 7
Training loss: 3.303001880645752
Validation loss: 2.4780968645567536

Epoch: 6| Step: 8
Training loss: 3.0298380851745605
Validation loss: 2.478020998739427

Epoch: 6| Step: 9
Training loss: 2.3997015953063965
Validation loss: 2.4740333505856094

Epoch: 6| Step: 10
Training loss: 2.9072937965393066
Validation loss: 2.4781820222895634

Epoch: 6| Step: 11
Training loss: 2.2973670959472656
Validation loss: 2.4774519781912527

Epoch: 6| Step: 12
Training loss: 3.212902069091797
Validation loss: 2.479451357677419

Epoch: 6| Step: 13
Training loss: 2.4842586517333984
Validation loss: 2.4803974397720827

Epoch: 25| Step: 0
Training loss: 2.756748676300049
Validation loss: 2.4736616380753054

Epoch: 6| Step: 1
Training loss: 3.09185791015625
Validation loss: 2.470466193332467

Epoch: 6| Step: 2
Training loss: 2.2109317779541016
Validation loss: 2.479925735022432

Epoch: 6| Step: 3
Training loss: 2.3337209224700928
Validation loss: 2.4875010957000074

Epoch: 6| Step: 4
Training loss: 2.58280611038208
Validation loss: 2.4881950398927093

Epoch: 6| Step: 5
Training loss: 2.4807016849517822
Validation loss: 2.4890997127820085

Epoch: 6| Step: 6
Training loss: 2.880284309387207
Validation loss: 2.4886222757318968

Epoch: 6| Step: 7
Training loss: 2.6084365844726562
Validation loss: 2.4861544050196165

Epoch: 6| Step: 8
Training loss: 3.12916898727417
Validation loss: 2.479497371181365

Epoch: 6| Step: 9
Training loss: 2.1642587184906006
Validation loss: 2.477883033854987

Epoch: 6| Step: 10
Training loss: 3.0140089988708496
Validation loss: 2.471515873427032

Epoch: 6| Step: 11
Training loss: 2.9306039810180664
Validation loss: 2.4688874419017504

Epoch: 6| Step: 12
Training loss: 2.896373748779297
Validation loss: 2.4715639109252603

Epoch: 6| Step: 13
Training loss: 3.0966877937316895
Validation loss: 2.4854879122908398

Epoch: 26| Step: 0
Training loss: 3.387050151824951
Validation loss: 2.5233032036853094

Epoch: 6| Step: 1
Training loss: 2.3186612129211426
Validation loss: 2.5435520038809827

Epoch: 6| Step: 2
Training loss: 2.887678384780884
Validation loss: 2.5171544192939677

Epoch: 6| Step: 3
Training loss: 2.8446907997131348
Validation loss: 2.5100566853759108

Epoch: 6| Step: 4
Training loss: 3.259613037109375
Validation loss: 2.489014248694143

Epoch: 6| Step: 5
Training loss: 2.759038209915161
Validation loss: 2.4804849727179414

Epoch: 6| Step: 6
Training loss: 2.243967056274414
Validation loss: 2.4803655891008276

Epoch: 6| Step: 7
Training loss: 2.363767147064209
Validation loss: 2.467903378189251

Epoch: 6| Step: 8
Training loss: 2.576073169708252
Validation loss: 2.465301177834952

Epoch: 6| Step: 9
Training loss: 2.274613618850708
Validation loss: 2.4628164742582586

Epoch: 6| Step: 10
Training loss: 2.897585391998291
Validation loss: 2.4624169283015753

Epoch: 6| Step: 11
Training loss: 2.886033535003662
Validation loss: 2.4655989062401558

Epoch: 6| Step: 12
Training loss: 2.5972652435302734
Validation loss: 2.4645181907120572

Epoch: 6| Step: 13
Training loss: 2.271886110305786
Validation loss: 2.4638180783999863

Epoch: 27| Step: 0
Training loss: 2.2021398544311523
Validation loss: 2.468126848179807

Epoch: 6| Step: 1
Training loss: 1.4053514003753662
Validation loss: 2.469328513709448

Epoch: 6| Step: 2
Training loss: 2.196329116821289
Validation loss: 2.464115191531438

Epoch: 6| Step: 3
Training loss: 2.3099822998046875
Validation loss: 2.4649079691979194

Epoch: 6| Step: 4
Training loss: 2.3341636657714844
Validation loss: 2.463481359584357

Epoch: 6| Step: 5
Training loss: 3.2447493076324463
Validation loss: 2.464122477398124

Epoch: 6| Step: 6
Training loss: 2.7977519035339355
Validation loss: 2.471546862715034

Epoch: 6| Step: 7
Training loss: 3.787428379058838
Validation loss: 2.4626507143820486

Epoch: 6| Step: 8
Training loss: 2.845735788345337
Validation loss: 2.456800204451366

Epoch: 6| Step: 9
Training loss: 2.7484350204467773
Validation loss: 2.4532225977989937

Epoch: 6| Step: 10
Training loss: 3.1375749111175537
Validation loss: 2.451015910794658

Epoch: 6| Step: 11
Training loss: 2.124840259552002
Validation loss: 2.4528807606748355

Epoch: 6| Step: 12
Training loss: 2.9805684089660645
Validation loss: 2.451795408802648

Epoch: 6| Step: 13
Training loss: 4.195235729217529
Validation loss: 2.456605827936562

Epoch: 28| Step: 0
Training loss: 3.2674808502197266
Validation loss: 2.4595305150555027

Epoch: 6| Step: 1
Training loss: 2.465714931488037
Validation loss: 2.466172479814099

Epoch: 6| Step: 2
Training loss: 2.5063529014587402
Validation loss: 2.4625129161342496

Epoch: 6| Step: 3
Training loss: 2.6179637908935547
Validation loss: 2.4598096134842082

Epoch: 6| Step: 4
Training loss: 3.3684253692626953
Validation loss: 2.462192243145358

Epoch: 6| Step: 5
Training loss: 3.310323476791382
Validation loss: 2.4583398808715162

Epoch: 6| Step: 6
Training loss: 3.1993701457977295
Validation loss: 2.4518965777530464

Epoch: 6| Step: 7
Training loss: 2.208613395690918
Validation loss: 2.449976310935072

Epoch: 6| Step: 8
Training loss: 2.451427459716797
Validation loss: 2.4475080608039774

Epoch: 6| Step: 9
Training loss: 2.9434242248535156
Validation loss: 2.4478210082618137

Epoch: 6| Step: 10
Training loss: 2.6504030227661133
Validation loss: 2.4467014612690097

Epoch: 6| Step: 11
Training loss: 2.582681655883789
Validation loss: 2.443234230882378

Epoch: 6| Step: 12
Training loss: 1.7003413438796997
Validation loss: 2.440208363276656

Epoch: 6| Step: 13
Training loss: 2.1125524044036865
Validation loss: 2.437570412953695

Epoch: 29| Step: 0
Training loss: 2.3994667530059814
Validation loss: 2.440407230008033

Epoch: 6| Step: 1
Training loss: 1.8285983800888062
Validation loss: 2.4435142765762987

Epoch: 6| Step: 2
Training loss: 2.3315420150756836
Validation loss: 2.4440366657831336

Epoch: 6| Step: 3
Training loss: 2.6775593757629395
Validation loss: 2.442017678291567

Epoch: 6| Step: 4
Training loss: 2.500676393508911
Validation loss: 2.443285670331729

Epoch: 6| Step: 5
Training loss: 3.559048652648926
Validation loss: 2.446449682276736

Epoch: 6| Step: 6
Training loss: 2.8576791286468506
Validation loss: 2.4444602279252905

Epoch: 6| Step: 7
Training loss: 2.5742053985595703
Validation loss: 2.4442704672454507

Epoch: 6| Step: 8
Training loss: 2.2802014350891113
Validation loss: 2.4389829789438555

Epoch: 6| Step: 9
Training loss: 3.6518771648406982
Validation loss: 2.4419034655376146

Epoch: 6| Step: 10
Training loss: 2.8222546577453613
Validation loss: 2.439364069251604

Epoch: 6| Step: 11
Training loss: 2.7343904972076416
Validation loss: 2.4451740941693707

Epoch: 6| Step: 12
Training loss: 2.3489413261413574
Validation loss: 2.450081950874739

Epoch: 6| Step: 13
Training loss: 2.9719624519348145
Validation loss: 2.5194887089472946

Epoch: 30| Step: 0
Training loss: 2.6648874282836914
Validation loss: 2.5572345974624797

Epoch: 6| Step: 1
Training loss: 3.6413002014160156
Validation loss: 2.5875484379388953

Epoch: 6| Step: 2
Training loss: 2.8917760848999023
Validation loss: 2.5872588080744587

Epoch: 6| Step: 3
Training loss: 2.5508925914764404
Validation loss: 2.569256818422707

Epoch: 6| Step: 4
Training loss: 2.435431957244873
Validation loss: 2.5276778718476653

Epoch: 6| Step: 5
Training loss: 2.8763365745544434
Validation loss: 2.455331628040601

Epoch: 6| Step: 6
Training loss: 2.9856276512145996
Validation loss: 2.4329852032405075

Epoch: 6| Step: 7
Training loss: 1.560176134109497
Validation loss: 2.433002805197111

Epoch: 6| Step: 8
Training loss: 2.8469748497009277
Validation loss: 2.430867184874832

Epoch: 6| Step: 9
Training loss: 3.047736644744873
Validation loss: 2.4321583291535736

Epoch: 6| Step: 10
Training loss: 2.424975633621216
Validation loss: 2.439108612716839

Epoch: 6| Step: 11
Training loss: 2.756762981414795
Validation loss: 2.446785706345753

Epoch: 6| Step: 12
Training loss: 2.7340574264526367
Validation loss: 2.4561705999476935

Epoch: 6| Step: 13
Training loss: 1.8094310760498047
Validation loss: 2.4600199986529607

Epoch: 31| Step: 0
Training loss: 2.393789768218994
Validation loss: 2.4737819420394076

Epoch: 6| Step: 1
Training loss: 2.5611112117767334
Validation loss: 2.481530035695722

Epoch: 6| Step: 2
Training loss: 3.258463144302368
Validation loss: 2.4884232680002847

Epoch: 6| Step: 3
Training loss: 2.4765613079071045
Validation loss: 2.494064892491987

Epoch: 6| Step: 4
Training loss: 2.920598030090332
Validation loss: 2.506995306220106

Epoch: 6| Step: 5
Training loss: 2.680497169494629
Validation loss: 2.5229266740942515

Epoch: 6| Step: 6
Training loss: 2.84898042678833
Validation loss: 2.5152761577278056

Epoch: 6| Step: 7
Training loss: 2.5617194175720215
Validation loss: 2.5170767948191655

Epoch: 6| Step: 8
Training loss: 2.1497702598571777
Validation loss: 2.5143159615096224

Epoch: 6| Step: 9
Training loss: 3.212635040283203
Validation loss: 2.5170814760269655

Epoch: 6| Step: 10
Training loss: 2.6155266761779785
Validation loss: 2.511978082759406

Epoch: 6| Step: 11
Training loss: 3.1982622146606445
Validation loss: 2.481736739476522

Epoch: 6| Step: 12
Training loss: 2.117558002471924
Validation loss: 2.457070476265364

Epoch: 6| Step: 13
Training loss: 2.8332836627960205
Validation loss: 2.438550813223726

Epoch: 32| Step: 0
Training loss: 2.6949150562286377
Validation loss: 2.43046909762967

Epoch: 6| Step: 1
Training loss: 2.7192282676696777
Validation loss: 2.423741004800284

Epoch: 6| Step: 2
Training loss: 3.4578795433044434
Validation loss: 2.421839790959512

Epoch: 6| Step: 3
Training loss: 2.4023776054382324
Validation loss: 2.4199902870321788

Epoch: 6| Step: 4
Training loss: 2.5605478286743164
Validation loss: 2.421635235509565

Epoch: 6| Step: 5
Training loss: 2.733400344848633
Validation loss: 2.4195130204641693

Epoch: 6| Step: 6
Training loss: 2.4302573204040527
Validation loss: 2.4192583791671263

Epoch: 6| Step: 7
Training loss: 2.922762393951416
Validation loss: 2.4142195306798464

Epoch: 6| Step: 8
Training loss: 2.590559244155884
Validation loss: 2.4173585561013993

Epoch: 6| Step: 9
Training loss: 2.9509496688842773
Validation loss: 2.413597422261392

Epoch: 6| Step: 10
Training loss: 2.1243162155151367
Validation loss: 2.4157810877728205

Epoch: 6| Step: 11
Training loss: 2.713297128677368
Validation loss: 2.4215535861189648

Epoch: 6| Step: 12
Training loss: 2.349339485168457
Validation loss: 2.4458765804126696

Epoch: 6| Step: 13
Training loss: 2.693816661834717
Validation loss: 2.4478411213044198

Epoch: 33| Step: 0
Training loss: 2.3475632667541504
Validation loss: 2.445241830682242

Epoch: 6| Step: 1
Training loss: 3.1187593936920166
Validation loss: 2.429889279027139

Epoch: 6| Step: 2
Training loss: 2.3326916694641113
Validation loss: 2.4196641906615226

Epoch: 6| Step: 3
Training loss: 2.471367359161377
Validation loss: 2.4103288009602535

Epoch: 6| Step: 4
Training loss: 2.8106141090393066
Validation loss: 2.4022095100854033

Epoch: 6| Step: 5
Training loss: 2.611902952194214
Validation loss: 2.4059641438145793

Epoch: 6| Step: 6
Training loss: 2.6083433628082275
Validation loss: 2.406907317458942

Epoch: 6| Step: 7
Training loss: 3.209747791290283
Validation loss: 2.4088971640474055

Epoch: 6| Step: 8
Training loss: 3.0088114738464355
Validation loss: 2.4151976826370403

Epoch: 6| Step: 9
Training loss: 3.214601755142212
Validation loss: 2.4202976688261955

Epoch: 6| Step: 10
Training loss: 3.0715668201446533
Validation loss: 2.4176218484037664

Epoch: 6| Step: 11
Training loss: 2.1708483695983887
Validation loss: 2.416945577949606

Epoch: 6| Step: 12
Training loss: 2.1409707069396973
Validation loss: 2.4127728862147175

Epoch: 6| Step: 13
Training loss: 2.1714258193969727
Validation loss: 2.407854328873337

Epoch: 34| Step: 0
Training loss: 2.7066845893859863
Validation loss: 2.3988375253574823

Epoch: 6| Step: 1
Training loss: 1.8030638694763184
Validation loss: 2.3985276222229004

Epoch: 6| Step: 2
Training loss: 2.255739688873291
Validation loss: 2.3966502502400386

Epoch: 6| Step: 3
Training loss: 2.8600106239318848
Validation loss: 2.4024627080527683

Epoch: 6| Step: 4
Training loss: 2.651785135269165
Validation loss: 2.415867305571033

Epoch: 6| Step: 5
Training loss: 2.674474000930786
Validation loss: 2.4218799350082234

Epoch: 6| Step: 6
Training loss: 2.9713010787963867
Validation loss: 2.4345734350142942

Epoch: 6| Step: 7
Training loss: 2.7960920333862305
Validation loss: 2.443167542898527

Epoch: 6| Step: 8
Training loss: 2.4299798011779785
Validation loss: 2.460535813403386

Epoch: 6| Step: 9
Training loss: 2.4723289012908936
Validation loss: 2.463754318093741

Epoch: 6| Step: 10
Training loss: 3.2347962856292725
Validation loss: 2.4431873380496936

Epoch: 6| Step: 11
Training loss: 3.6219918727874756
Validation loss: 2.427354745967414

Epoch: 6| Step: 12
Training loss: 2.127603769302368
Validation loss: 2.4132491132264495

Epoch: 6| Step: 13
Training loss: 2.2700984477996826
Validation loss: 2.3932949650672173

Epoch: 35| Step: 0
Training loss: 2.0725932121276855
Validation loss: 2.391927249969975

Epoch: 6| Step: 1
Training loss: 2.7791638374328613
Validation loss: 2.3972071383589055

Epoch: 6| Step: 2
Training loss: 3.0304481983184814
Validation loss: 2.400334458197317

Epoch: 6| Step: 3
Training loss: 1.9361494779586792
Validation loss: 2.4098387687436995

Epoch: 6| Step: 4
Training loss: 2.8512048721313477
Validation loss: 2.41221111307862

Epoch: 6| Step: 5
Training loss: 2.6360888481140137
Validation loss: 2.415968192520962

Epoch: 6| Step: 6
Training loss: 3.0077478885650635
Validation loss: 2.419541971657866

Epoch: 6| Step: 7
Training loss: 2.8661530017852783
Validation loss: 2.4198086492476927

Epoch: 6| Step: 8
Training loss: 2.3942809104919434
Validation loss: 2.417368156935579

Epoch: 6| Step: 9
Training loss: 3.3692991733551025
Validation loss: 2.4160713444473925

Epoch: 6| Step: 10
Training loss: 2.7462100982666016
Validation loss: 2.41405475524164

Epoch: 6| Step: 11
Training loss: 2.5099408626556396
Validation loss: 2.411787079226586

Epoch: 6| Step: 12
Training loss: 2.692686080932617
Validation loss: 2.408531019764562

Epoch: 6| Step: 13
Training loss: 2.4253525733947754
Validation loss: 2.3970523829101236

Epoch: 36| Step: 0
Training loss: 3.379807472229004
Validation loss: 2.3936897862342095

Epoch: 6| Step: 1
Training loss: 2.4442479610443115
Validation loss: 2.3983623930203017

Epoch: 6| Step: 2
Training loss: 3.4356558322906494
Validation loss: 2.4279315984377297

Epoch: 6| Step: 3
Training loss: 2.164916515350342
Validation loss: 2.4738751765220397

Epoch: 6| Step: 4
Training loss: 2.424923896789551
Validation loss: 2.4859811106035785

Epoch: 6| Step: 5
Training loss: 2.728447914123535
Validation loss: 2.4788603487835137

Epoch: 6| Step: 6
Training loss: 2.50350284576416
Validation loss: 2.4604594399852138

Epoch: 6| Step: 7
Training loss: 2.2556164264678955
Validation loss: 2.4364746309095815

Epoch: 6| Step: 8
Training loss: 2.2078371047973633
Validation loss: 2.4218373170462986

Epoch: 6| Step: 9
Training loss: 2.571192741394043
Validation loss: 2.4107680295103338

Epoch: 6| Step: 10
Training loss: 2.1128196716308594
Validation loss: 2.403603479426394

Epoch: 6| Step: 11
Training loss: 3.118481397628784
Validation loss: 2.395328757583454

Epoch: 6| Step: 12
Training loss: 2.9446067810058594
Validation loss: 2.3896814982096353

Epoch: 6| Step: 13
Training loss: 3.122850179672241
Validation loss: 2.3841440370005946

Epoch: 37| Step: 0
Training loss: 2.8192577362060547
Validation loss: 2.3849697292491956

Epoch: 6| Step: 1
Training loss: 2.6385905742645264
Validation loss: 2.3919585571494153

Epoch: 6| Step: 2
Training loss: 2.7466719150543213
Validation loss: 2.405904777588383

Epoch: 6| Step: 3
Training loss: 2.716904640197754
Validation loss: 2.404367826318228

Epoch: 6| Step: 4
Training loss: 2.6229248046875
Validation loss: 2.406849076670985

Epoch: 6| Step: 5
Training loss: 3.0631790161132812
Validation loss: 2.4038898380853797

Epoch: 6| Step: 6
Training loss: 2.849043846130371
Validation loss: 2.401012266835859

Epoch: 6| Step: 7
Training loss: 2.9655299186706543
Validation loss: 2.3995254526856127

Epoch: 6| Step: 8
Training loss: 2.3898797035217285
Validation loss: 2.3938950031034407

Epoch: 6| Step: 9
Training loss: 2.436659336090088
Validation loss: 2.384647733421736

Epoch: 6| Step: 10
Training loss: 2.5263829231262207
Validation loss: 2.3790201858807634

Epoch: 6| Step: 11
Training loss: 2.054668664932251
Validation loss: 2.377943436304728

Epoch: 6| Step: 12
Training loss: 2.7895212173461914
Validation loss: 2.3815728541343444

Epoch: 6| Step: 13
Training loss: 2.6152560710906982
Validation loss: 2.3871828304824008

Epoch: 38| Step: 0
Training loss: 2.836291790008545
Validation loss: 2.421279953372094

Epoch: 6| Step: 1
Training loss: 2.362163782119751
Validation loss: 2.476543108622233

Epoch: 6| Step: 2
Training loss: 3.5161805152893066
Validation loss: 2.559215335435765

Epoch: 6| Step: 3
Training loss: 1.9909961223602295
Validation loss: 2.623417715872488

Epoch: 6| Step: 4
Training loss: 2.396683692932129
Validation loss: 2.814451156123992

Epoch: 6| Step: 5
Training loss: 3.4531545639038086
Validation loss: 2.85013666460591

Epoch: 6| Step: 6
Training loss: 2.125891923904419
Validation loss: 2.674908043235861

Epoch: 6| Step: 7
Training loss: 2.6899349689483643
Validation loss: 2.5047180485981766

Epoch: 6| Step: 8
Training loss: 2.942223072052002
Validation loss: 2.4050466604130243

Epoch: 6| Step: 9
Training loss: 3.42966365814209
Validation loss: 2.374908621593188

Epoch: 6| Step: 10
Training loss: 3.2628884315490723
Validation loss: 2.4194176889234975

Epoch: 6| Step: 11
Training loss: 1.5880751609802246
Validation loss: 2.4866889561376264

Epoch: 6| Step: 12
Training loss: 2.5030713081359863
Validation loss: 2.5506115959536646

Epoch: 6| Step: 13
Training loss: 3.4662463665008545
Validation loss: 2.5938985681021087

Epoch: 39| Step: 0
Training loss: 3.1242754459381104
Validation loss: 2.5671229926488732

Epoch: 6| Step: 1
Training loss: 2.3911051750183105
Validation loss: 2.5368688901265464

Epoch: 6| Step: 2
Training loss: 2.7323997020721436
Validation loss: 2.5027316385699856

Epoch: 6| Step: 3
Training loss: 1.991881012916565
Validation loss: 2.463865554460915

Epoch: 6| Step: 4
Training loss: 2.659083604812622
Validation loss: 2.4407494170691377

Epoch: 6| Step: 5
Training loss: 2.254396438598633
Validation loss: 2.445445265821231

Epoch: 6| Step: 6
Training loss: 2.8233509063720703
Validation loss: 2.5009242373128093

Epoch: 6| Step: 7
Training loss: 2.6412460803985596
Validation loss: 2.5178897329556045

Epoch: 6| Step: 8
Training loss: 2.8787121772766113
Validation loss: 2.5460303496288996

Epoch: 6| Step: 9
Training loss: 2.7400946617126465
Validation loss: 2.553697201513475

Epoch: 6| Step: 10
Training loss: 3.235560894012451
Validation loss: 2.570105734691825

Epoch: 6| Step: 11
Training loss: 3.06357479095459
Validation loss: 2.563558599000336

Epoch: 6| Step: 12
Training loss: 3.027207612991333
Validation loss: 2.5378916558398994

Epoch: 6| Step: 13
Training loss: 3.4455440044403076
Validation loss: 2.5230398690828713

Epoch: 40| Step: 0
Training loss: 2.694906234741211
Validation loss: 2.4901624623165337

Epoch: 6| Step: 1
Training loss: 2.542881965637207
Validation loss: 2.499250315850781

Epoch: 6| Step: 2
Training loss: 2.217141628265381
Validation loss: 2.517412098505164

Epoch: 6| Step: 3
Training loss: 2.0695598125457764
Validation loss: 2.5266073032092025

Epoch: 6| Step: 4
Training loss: 3.2283754348754883
Validation loss: 2.5248428313962874

Epoch: 6| Step: 5
Training loss: 3.112048625946045
Validation loss: 2.4759170906518095

Epoch: 6| Step: 6
Training loss: 2.6419944763183594
Validation loss: 2.3834290709546817

Epoch: 6| Step: 7
Training loss: 2.878838300704956
Validation loss: 2.373070719421551

Epoch: 6| Step: 8
Training loss: 2.8798232078552246
Validation loss: 2.3805457392046527

Epoch: 6| Step: 9
Training loss: 2.596130847930908
Validation loss: 2.403020002508676

Epoch: 6| Step: 10
Training loss: 3.198563814163208
Validation loss: 2.440730397419263

Epoch: 6| Step: 11
Training loss: 2.0418500900268555
Validation loss: 2.470643771592007

Epoch: 6| Step: 12
Training loss: 3.657585382461548
Validation loss: 2.4901856991552536

Epoch: 6| Step: 13
Training loss: 1.5791115760803223
Validation loss: 2.475720677324521

Epoch: 41| Step: 0
Training loss: 2.6772332191467285
Validation loss: 2.484722255378641

Epoch: 6| Step: 1
Training loss: 1.921621561050415
Validation loss: 2.4844225888611167

Epoch: 6| Step: 2
Training loss: 2.145355701446533
Validation loss: 2.4894207216078237

Epoch: 6| Step: 3
Training loss: 3.4723119735717773
Validation loss: 2.498583391148557

Epoch: 6| Step: 4
Training loss: 2.9925291538238525
Validation loss: 2.482139866839173

Epoch: 6| Step: 5
Training loss: 2.7098283767700195
Validation loss: 2.455120094360844

Epoch: 6| Step: 6
Training loss: 2.13250732421875
Validation loss: 2.450203787895941

Epoch: 6| Step: 7
Training loss: 2.864189624786377
Validation loss: 2.433763127173147

Epoch: 6| Step: 8
Training loss: 2.1998894214630127
Validation loss: 2.4204288439084123

Epoch: 6| Step: 9
Training loss: 2.734219551086426
Validation loss: 2.3955480693488993

Epoch: 6| Step: 10
Training loss: 2.770885467529297
Validation loss: 2.376744329288442

Epoch: 6| Step: 11
Training loss: 2.8330609798431396
Validation loss: 2.368344295409418

Epoch: 6| Step: 12
Training loss: 2.1237986087799072
Validation loss: 2.3784603816206737

Epoch: 6| Step: 13
Training loss: 4.272027969360352
Validation loss: 2.4047024634576615

Epoch: 42| Step: 0
Training loss: 3.2048730850219727
Validation loss: 2.4178750181710846

Epoch: 6| Step: 1
Training loss: 3.021610736846924
Validation loss: 2.4472634407781784

Epoch: 6| Step: 2
Training loss: 2.6278538703918457
Validation loss: 2.5101146236542733

Epoch: 6| Step: 3
Training loss: 2.7774767875671387
Validation loss: 2.4648236228573706

Epoch: 6| Step: 4
Training loss: 2.9090476036071777
Validation loss: 2.445212007850729

Epoch: 6| Step: 5
Training loss: 2.7581591606140137
Validation loss: 2.413973655751956

Epoch: 6| Step: 6
Training loss: 1.9713718891143799
Validation loss: 2.386327361547819

Epoch: 6| Step: 7
Training loss: 2.6826553344726562
Validation loss: 2.3796392307486585

Epoch: 6| Step: 8
Training loss: 1.9255186319351196
Validation loss: 2.3759382001815306

Epoch: 6| Step: 9
Training loss: 2.5899744033813477
Validation loss: 2.379583442082969

Epoch: 6| Step: 10
Training loss: 3.676560401916504
Validation loss: 2.3878142346617994

Epoch: 6| Step: 11
Training loss: 2.3353004455566406
Validation loss: 2.40350781461244

Epoch: 6| Step: 12
Training loss: 2.4164910316467285
Validation loss: 2.4097587985377156

Epoch: 6| Step: 13
Training loss: 2.4649817943573
Validation loss: 2.4308292032569967

Epoch: 43| Step: 0
Training loss: 2.7148680686950684
Validation loss: 2.432199280749085

Epoch: 6| Step: 1
Training loss: 2.9935836791992188
Validation loss: 2.435985324203327

Epoch: 6| Step: 2
Training loss: 2.587709903717041
Validation loss: 2.430688278649443

Epoch: 6| Step: 3
Training loss: 2.9930338859558105
Validation loss: 2.416058632635301

Epoch: 6| Step: 4
Training loss: 2.2606847286224365
Validation loss: 2.4078137746421238

Epoch: 6| Step: 5
Training loss: 2.5031938552856445
Validation loss: 2.3917126822215256

Epoch: 6| Step: 6
Training loss: 2.914358615875244
Validation loss: 2.383960526476624

Epoch: 6| Step: 7
Training loss: 2.5448532104492188
Validation loss: 2.3830265845021894

Epoch: 6| Step: 8
Training loss: 2.77718448638916
Validation loss: 2.379335944370557

Epoch: 6| Step: 9
Training loss: 2.3673605918884277
Validation loss: 2.3787270361377346

Epoch: 6| Step: 10
Training loss: 3.2769813537597656
Validation loss: 2.376883970793857

Epoch: 6| Step: 11
Training loss: 2.287893295288086
Validation loss: 2.3753064114560365

Epoch: 6| Step: 12
Training loss: 2.425443649291992
Validation loss: 2.3722205674776466

Epoch: 6| Step: 13
Training loss: 2.1281936168670654
Validation loss: 2.3701004520539315

Epoch: 44| Step: 0
Training loss: 2.3391871452331543
Validation loss: 2.349780589021662

Epoch: 6| Step: 1
Training loss: 1.9318196773529053
Validation loss: 2.349526656571255

Epoch: 6| Step: 2
Training loss: 2.3584344387054443
Validation loss: 2.3426625062060613

Epoch: 6| Step: 3
Training loss: 3.056623697280884
Validation loss: 2.343260298493088

Epoch: 6| Step: 4
Training loss: 2.9303932189941406
Validation loss: 2.3419758504436863

Epoch: 6| Step: 5
Training loss: 2.471095561981201
Validation loss: 2.344690194693945

Epoch: 6| Step: 6
Training loss: 2.429993152618408
Validation loss: 2.348215221076883

Epoch: 6| Step: 7
Training loss: 2.473280429840088
Validation loss: 2.3514488922652377

Epoch: 6| Step: 8
Training loss: 2.5907199382781982
Validation loss: 2.3699391875215756

Epoch: 6| Step: 9
Training loss: 2.7317187786102295
Validation loss: 2.3772404604060675

Epoch: 6| Step: 10
Training loss: 3.418901205062866
Validation loss: 2.3846564292907715

Epoch: 6| Step: 11
Training loss: 2.10048246383667
Validation loss: 2.4114629530137583

Epoch: 6| Step: 12
Training loss: 2.6998729705810547
Validation loss: 2.4248834630494476

Epoch: 6| Step: 13
Training loss: 3.7864277362823486
Validation loss: 2.4181612460843978

Epoch: 45| Step: 0
Training loss: 2.538483142852783
Validation loss: 2.4024520215167793

Epoch: 6| Step: 1
Training loss: 2.236967086791992
Validation loss: 2.418350645290908

Epoch: 6| Step: 2
Training loss: 2.2342779636383057
Validation loss: 2.4284490052089898

Epoch: 6| Step: 3
Training loss: 2.2114744186401367
Validation loss: 2.3947806255791777

Epoch: 6| Step: 4
Training loss: 1.7229716777801514
Validation loss: 2.399639157838719

Epoch: 6| Step: 5
Training loss: 2.9413516521453857
Validation loss: 2.3796323396826304

Epoch: 6| Step: 6
Training loss: 2.856675624847412
Validation loss: 2.3605624116877073

Epoch: 6| Step: 7
Training loss: 3.094109058380127
Validation loss: 2.3478692500822005

Epoch: 6| Step: 8
Training loss: 3.0312340259552
Validation loss: 2.3382598969244186

Epoch: 6| Step: 9
Training loss: 3.011258363723755
Validation loss: 2.3331954633035967

Epoch: 6| Step: 10
Training loss: 2.548929214477539
Validation loss: 2.3252708988804973

Epoch: 6| Step: 11
Training loss: 2.4962587356567383
Validation loss: 2.3241897218970844

Epoch: 6| Step: 12
Training loss: 2.8907217979431152
Validation loss: 2.3242964206203336

Epoch: 6| Step: 13
Training loss: 2.633901357650757
Validation loss: 2.3237624142759588

Epoch: 46| Step: 0
Training loss: 3.0883588790893555
Validation loss: 2.331219328347073

Epoch: 6| Step: 1
Training loss: 2.9541215896606445
Validation loss: 2.340185119259742

Epoch: 6| Step: 2
Training loss: 3.109424591064453
Validation loss: 2.3282723324273222

Epoch: 6| Step: 3
Training loss: 2.1863152980804443
Validation loss: 2.3214690915999876

Epoch: 6| Step: 4
Training loss: 3.1520798206329346
Validation loss: 2.3207060188375492

Epoch: 6| Step: 5
Training loss: 2.340055465698242
Validation loss: 2.323987255814255

Epoch: 6| Step: 6
Training loss: 2.7496790885925293
Validation loss: 2.3271867421365555

Epoch: 6| Step: 7
Training loss: 2.6419577598571777
Validation loss: 2.332403629056869

Epoch: 6| Step: 8
Training loss: 2.1371397972106934
Validation loss: 2.335284702239498

Epoch: 6| Step: 9
Training loss: 3.049607276916504
Validation loss: 2.3464442299258326

Epoch: 6| Step: 10
Training loss: 2.6334354877471924
Validation loss: 2.351451760979109

Epoch: 6| Step: 11
Training loss: 2.0787081718444824
Validation loss: 2.3610388386634087

Epoch: 6| Step: 12
Training loss: 2.1553311347961426
Validation loss: 2.3651835264698153

Epoch: 6| Step: 13
Training loss: 2.166297197341919
Validation loss: 2.3469365412189114

Epoch: 47| Step: 0
Training loss: 2.737729549407959
Validation loss: 2.3372370504563853

Epoch: 6| Step: 1
Training loss: 2.733285427093506
Validation loss: 2.3368188719595633

Epoch: 6| Step: 2
Training loss: 2.5359890460968018
Validation loss: 2.3412320895861556

Epoch: 6| Step: 3
Training loss: 2.579160213470459
Validation loss: 2.3471391790656635

Epoch: 6| Step: 4
Training loss: 2.874058246612549
Validation loss: 2.338493647113923

Epoch: 6| Step: 5
Training loss: 2.934614658355713
Validation loss: 2.32965866468286

Epoch: 6| Step: 6
Training loss: 2.1516528129577637
Validation loss: 2.327341274548602

Epoch: 6| Step: 7
Training loss: 2.306589126586914
Validation loss: 2.322735809510754

Epoch: 6| Step: 8
Training loss: 2.7577500343322754
Validation loss: 2.32137176041962

Epoch: 6| Step: 9
Training loss: 2.715219020843506
Validation loss: 2.3183287497489684

Epoch: 6| Step: 10
Training loss: 2.0430331230163574
Validation loss: 2.314327824500299

Epoch: 6| Step: 11
Training loss: 3.202603816986084
Validation loss: 2.312439819817902

Epoch: 6| Step: 12
Training loss: 2.217118740081787
Validation loss: 2.313079172565091

Epoch: 6| Step: 13
Training loss: 2.6818742752075195
Validation loss: 2.317632931534962

Epoch: 48| Step: 0
Training loss: 2.3355352878570557
Validation loss: 2.316743948126352

Epoch: 6| Step: 1
Training loss: 3.3161094188690186
Validation loss: 2.3150804094088975

Epoch: 6| Step: 2
Training loss: 2.278956413269043
Validation loss: 2.314410650601951

Epoch: 6| Step: 3
Training loss: 2.2863516807556152
Validation loss: 2.3090707717403287

Epoch: 6| Step: 4
Training loss: 2.9908623695373535
Validation loss: 2.3089535492722706

Epoch: 6| Step: 5
Training loss: 3.0100598335266113
Validation loss: 2.3105106712669454

Epoch: 6| Step: 6
Training loss: 2.52953839302063
Validation loss: 2.3186396398851947

Epoch: 6| Step: 7
Training loss: 2.4936931133270264
Validation loss: 2.3246072953747166

Epoch: 6| Step: 8
Training loss: 2.4669880867004395
Validation loss: 2.3464100181415515

Epoch: 6| Step: 9
Training loss: 3.214818239212036
Validation loss: 2.34406102600918

Epoch: 6| Step: 10
Training loss: 2.6320443153381348
Validation loss: 2.3521438849869596

Epoch: 6| Step: 11
Training loss: 1.9847408533096313
Validation loss: 2.35839258855389

Epoch: 6| Step: 12
Training loss: 2.267849922180176
Validation loss: 2.3653518461411998

Epoch: 6| Step: 13
Training loss: 2.5227243900299072
Validation loss: 2.366357462380522

Epoch: 49| Step: 0
Training loss: 2.657437324523926
Validation loss: 2.3649368773224535

Epoch: 6| Step: 1
Training loss: 2.162102699279785
Validation loss: 2.362853410423443

Epoch: 6| Step: 2
Training loss: 3.005197048187256
Validation loss: 2.369156696463144

Epoch: 6| Step: 3
Training loss: 2.285306930541992
Validation loss: 2.3858883714163177

Epoch: 6| Step: 4
Training loss: 2.6905059814453125
Validation loss: 2.371972313491247

Epoch: 6| Step: 5
Training loss: 2.1391639709472656
Validation loss: 2.344359076151284

Epoch: 6| Step: 6
Training loss: 2.3966407775878906
Validation loss: 2.3360342415430213

Epoch: 6| Step: 7
Training loss: 2.7125563621520996
Validation loss: 2.33287952920442

Epoch: 6| Step: 8
Training loss: 2.8716225624084473
Validation loss: 2.3305048301655757

Epoch: 6| Step: 9
Training loss: 1.6204825639724731
Validation loss: 2.3236738892011743

Epoch: 6| Step: 10
Training loss: 3.301896572113037
Validation loss: 2.3219373713257494

Epoch: 6| Step: 11
Training loss: 3.0253405570983887
Validation loss: 2.3115963551305954

Epoch: 6| Step: 12
Training loss: 3.1187989711761475
Validation loss: 2.313717487037823

Epoch: 6| Step: 13
Training loss: 1.8224724531173706
Validation loss: 2.3111913845103276

Epoch: 50| Step: 0
Training loss: 2.210998296737671
Validation loss: 2.311338206773163

Epoch: 6| Step: 1
Training loss: 2.471693992614746
Validation loss: 2.3093940263153403

Epoch: 6| Step: 2
Training loss: 2.398603916168213
Validation loss: 2.3061457218662387

Epoch: 6| Step: 3
Training loss: 3.3650412559509277
Validation loss: 2.3024706635423886

Epoch: 6| Step: 4
Training loss: 2.8454525470733643
Validation loss: 2.3070085035857333

Epoch: 6| Step: 5
Training loss: 2.455030918121338
Validation loss: 2.3111952427894837

Epoch: 6| Step: 6
Training loss: 2.53718638420105
Validation loss: 2.312897164334533

Epoch: 6| Step: 7
Training loss: 2.033278226852417
Validation loss: 2.318870682870188

Epoch: 6| Step: 8
Training loss: 2.838529586791992
Validation loss: 2.3179950047564764

Epoch: 6| Step: 9
Training loss: 2.4216954708099365
Validation loss: 2.314906691992155

Epoch: 6| Step: 10
Training loss: 2.8736910820007324
Validation loss: 2.311851291246312

Epoch: 6| Step: 11
Training loss: 3.034578323364258
Validation loss: 2.316105468298799

Epoch: 6| Step: 12
Training loss: 2.108696460723877
Validation loss: 2.3154590219579716

Epoch: 6| Step: 13
Training loss: 2.7241458892822266
Validation loss: 2.321017947248233

Epoch: 51| Step: 0
Training loss: 2.107940912246704
Validation loss: 2.3367260732958393

Epoch: 6| Step: 1
Training loss: 2.564645767211914
Validation loss: 2.3694780680441085

Epoch: 6| Step: 2
Training loss: 2.3987925052642822
Validation loss: 2.3940099977677867

Epoch: 6| Step: 3
Training loss: 2.906148910522461
Validation loss: 2.444568887833626

Epoch: 6| Step: 4
Training loss: 3.2800750732421875
Validation loss: 2.4997168484554497

Epoch: 6| Step: 5
Training loss: 3.0702316761016846
Validation loss: 2.500618798758394

Epoch: 6| Step: 6
Training loss: 2.7834653854370117
Validation loss: 2.448363149037925

Epoch: 6| Step: 7
Training loss: 2.455048084259033
Validation loss: 2.3807987923263223

Epoch: 6| Step: 8
Training loss: 3.847139358520508
Validation loss: 2.3141003577939925

Epoch: 6| Step: 9
Training loss: 2.311762809753418
Validation loss: 2.293197777963454

Epoch: 6| Step: 10
Training loss: 2.570629596710205
Validation loss: 2.2957718987618723

Epoch: 6| Step: 11
Training loss: 2.328160285949707
Validation loss: 2.3145814018864788

Epoch: 6| Step: 12
Training loss: 1.8472695350646973
Validation loss: 2.360912505016532

Epoch: 6| Step: 13
Training loss: 1.9782557487487793
Validation loss: 2.4365143647757908

Epoch: 52| Step: 0
Training loss: 3.0670950412750244
Validation loss: 2.5757522595826017

Epoch: 6| Step: 1
Training loss: 3.1736557483673096
Validation loss: 2.720793213895572

Epoch: 6| Step: 2
Training loss: 2.62160587310791
Validation loss: 2.8506060210607385

Epoch: 6| Step: 3
Training loss: 2.5724782943725586
Validation loss: 2.8776514248181413

Epoch: 6| Step: 4
Training loss: 2.949591636657715
Validation loss: 2.8293211049931024

Epoch: 6| Step: 5
Training loss: 3.1057040691375732
Validation loss: 2.774751781135477

Epoch: 6| Step: 6
Training loss: 3.4364960193634033
Validation loss: 2.7078570781215543

Epoch: 6| Step: 7
Training loss: 2.8950791358947754
Validation loss: 2.638474561834848

Epoch: 6| Step: 8
Training loss: 2.2434957027435303
Validation loss: 2.544372440666281

Epoch: 6| Step: 9
Training loss: 2.85703182220459
Validation loss: 2.4298184302545365

Epoch: 6| Step: 10
Training loss: 2.6759114265441895
Validation loss: 2.343703439158778

Epoch: 6| Step: 11
Training loss: 2.1196773052215576
Validation loss: 2.2964728083661807

Epoch: 6| Step: 12
Training loss: 1.9893022775650024
Validation loss: 2.282324893500215

Epoch: 6| Step: 13
Training loss: 2.9582717418670654
Validation loss: 2.2870594762986705

Epoch: 53| Step: 0
Training loss: 2.324592113494873
Validation loss: 2.3221592608318535

Epoch: 6| Step: 1
Training loss: 2.251643180847168
Validation loss: 2.4000071697337653

Epoch: 6| Step: 2
Training loss: 2.950587749481201
Validation loss: 2.4843610486676617

Epoch: 6| Step: 3
Training loss: 2.929577112197876
Validation loss: 2.4580223368060206

Epoch: 6| Step: 4
Training loss: 2.150092601776123
Validation loss: 2.37324200137969

Epoch: 6| Step: 5
Training loss: 2.6359639167785645
Validation loss: 2.3216043544071976

Epoch: 6| Step: 6
Training loss: 2.0685479640960693
Validation loss: 2.319427013397217

Epoch: 6| Step: 7
Training loss: 3.032940149307251
Validation loss: 2.324312671538322

Epoch: 6| Step: 8
Training loss: 2.723842144012451
Validation loss: 2.3294836833912838

Epoch: 6| Step: 9
Training loss: 2.7316792011260986
Validation loss: 2.3330652636866414

Epoch: 6| Step: 10
Training loss: 2.878206729888916
Validation loss: 2.329337860948296

Epoch: 6| Step: 11
Training loss: 2.7989137172698975
Validation loss: 2.3131097849979194

Epoch: 6| Step: 12
Training loss: 2.2825050354003906
Validation loss: 2.2926451967608545

Epoch: 6| Step: 13
Training loss: 2.7090933322906494
Validation loss: 2.2929924970032065

Epoch: 54| Step: 0
Training loss: 2.822054624557495
Validation loss: 2.29097939819418

Epoch: 6| Step: 1
Training loss: 2.0647213459014893
Validation loss: 2.2844771569774998

Epoch: 6| Step: 2
Training loss: 2.7047677040100098
Validation loss: 2.2809448190914687

Epoch: 6| Step: 3
Training loss: 2.107886791229248
Validation loss: 2.2758399850578717

Epoch: 6| Step: 4
Training loss: 2.593078136444092
Validation loss: 2.2770946269394248

Epoch: 6| Step: 5
Training loss: 2.612919807434082
Validation loss: 2.269825691817909

Epoch: 6| Step: 6
Training loss: 2.522756576538086
Validation loss: 2.272918208952873

Epoch: 6| Step: 7
Training loss: 2.370378255844116
Validation loss: 2.2791120903466338

Epoch: 6| Step: 8
Training loss: 2.399198532104492
Validation loss: 2.2958287039110736

Epoch: 6| Step: 9
Training loss: 2.7518389225006104
Validation loss: 2.3026168243859404

Epoch: 6| Step: 10
Training loss: 2.365577220916748
Validation loss: 2.312260643128426

Epoch: 6| Step: 11
Training loss: 2.903441905975342
Validation loss: 2.3193744562005483

Epoch: 6| Step: 12
Training loss: 3.4071245193481445
Validation loss: 2.3247180907957015

Epoch: 6| Step: 13
Training loss: 2.931278944015503
Validation loss: 2.317184007295998

Epoch: 55| Step: 0
Training loss: 2.1072442531585693
Validation loss: 2.31125831860368

Epoch: 6| Step: 1
Training loss: 3.223201274871826
Validation loss: 2.3040103425261793

Epoch: 6| Step: 2
Training loss: 2.781014919281006
Validation loss: 2.2844211952660674

Epoch: 6| Step: 3
Training loss: 3.2415146827697754
Validation loss: 2.285748433041316

Epoch: 6| Step: 4
Training loss: 2.1395206451416016
Validation loss: 2.2801391591307936

Epoch: 6| Step: 5
Training loss: 2.3697729110717773
Validation loss: 2.277473831689486

Epoch: 6| Step: 6
Training loss: 3.2161262035369873
Validation loss: 2.275933914287116

Epoch: 6| Step: 7
Training loss: 2.086620330810547
Validation loss: 2.272689414280717

Epoch: 6| Step: 8
Training loss: 2.608132839202881
Validation loss: 2.2713963190714517

Epoch: 6| Step: 9
Training loss: 2.4652113914489746
Validation loss: 2.2704051028015795

Epoch: 6| Step: 10
Training loss: 2.4824609756469727
Validation loss: 2.2654728530555643

Epoch: 6| Step: 11
Training loss: 2.70635986328125
Validation loss: 2.264512769637569

Epoch: 6| Step: 12
Training loss: 2.205571174621582
Validation loss: 2.2641232859703804

Epoch: 6| Step: 13
Training loss: 2.024273157119751
Validation loss: 2.269098766388432

Epoch: 56| Step: 0
Training loss: 2.7235617637634277
Validation loss: 2.2758496858740367

Epoch: 6| Step: 1
Training loss: 2.903856039047241
Validation loss: 2.276991392976494

Epoch: 6| Step: 2
Training loss: 2.77180814743042
Validation loss: 2.283353952951329

Epoch: 6| Step: 3
Training loss: 2.910904884338379
Validation loss: 2.281443395922261

Epoch: 6| Step: 4
Training loss: 2.8857696056365967
Validation loss: 2.278258813324795

Epoch: 6| Step: 5
Training loss: 2.4035544395446777
Validation loss: 2.2686004369489607

Epoch: 6| Step: 6
Training loss: 2.7356250286102295
Validation loss: 2.2699774003797963

Epoch: 6| Step: 7
Training loss: 2.0105700492858887
Validation loss: 2.272104260742023

Epoch: 6| Step: 8
Training loss: 3.09519100189209
Validation loss: 2.2685537081892773

Epoch: 6| Step: 9
Training loss: 2.649885654449463
Validation loss: 2.268891913916475

Epoch: 6| Step: 10
Training loss: 2.619030475616455
Validation loss: 2.2664430961813977

Epoch: 6| Step: 11
Training loss: 2.110823392868042
Validation loss: 2.2655047062904603

Epoch: 6| Step: 12
Training loss: 2.017397403717041
Validation loss: 2.2614175658072195

Epoch: 6| Step: 13
Training loss: 1.4388833045959473
Validation loss: 2.261836349323232

Epoch: 57| Step: 0
Training loss: 2.2175960540771484
Validation loss: 2.259356742264122

Epoch: 6| Step: 1
Training loss: 2.6715586185455322
Validation loss: 2.2618410894947667

Epoch: 6| Step: 2
Training loss: 2.4391348361968994
Validation loss: 2.2671545808033278

Epoch: 6| Step: 3
Training loss: 2.2306742668151855
Validation loss: 2.274275364414338

Epoch: 6| Step: 4
Training loss: 2.1251368522644043
Validation loss: 2.289025560502083

Epoch: 6| Step: 5
Training loss: 2.5841336250305176
Validation loss: 2.305662844770698

Epoch: 6| Step: 6
Training loss: 2.9598395824432373
Validation loss: 2.33986424374324

Epoch: 6| Step: 7
Training loss: 2.4093565940856934
Validation loss: 2.363926556802565

Epoch: 6| Step: 8
Training loss: 2.6554758548736572
Validation loss: 2.361383899565666

Epoch: 6| Step: 9
Training loss: 2.872131109237671
Validation loss: 2.3423130640419583

Epoch: 6| Step: 10
Training loss: 2.1248440742492676
Validation loss: 2.310406924575888

Epoch: 6| Step: 11
Training loss: 2.8047120571136475
Validation loss: 2.2930203765951176

Epoch: 6| Step: 12
Training loss: 2.7128846645355225
Validation loss: 2.2739220921711256

Epoch: 6| Step: 13
Training loss: 3.1502139568328857
Validation loss: 2.2612195912227837

Epoch: 58| Step: 0
Training loss: 2.1119439601898193
Validation loss: 2.2499196644752257

Epoch: 6| Step: 1
Training loss: 2.4577078819274902
Validation loss: 2.2462483208666564

Epoch: 6| Step: 2
Training loss: 2.819596767425537
Validation loss: 2.2443356975432365

Epoch: 6| Step: 3
Training loss: 2.8415892124176025
Validation loss: 2.248024630290206

Epoch: 6| Step: 4
Training loss: 2.297276258468628
Validation loss: 2.2458856567259757

Epoch: 6| Step: 5
Training loss: 2.7248144149780273
Validation loss: 2.243007392011663

Epoch: 6| Step: 6
Training loss: 2.7883379459381104
Validation loss: 2.24074286799277

Epoch: 6| Step: 7
Training loss: 2.7639126777648926
Validation loss: 2.239487768501364

Epoch: 6| Step: 8
Training loss: 2.403580665588379
Validation loss: 2.2472718748995053

Epoch: 6| Step: 9
Training loss: 3.056027889251709
Validation loss: 2.246712233430596

Epoch: 6| Step: 10
Training loss: 2.5777223110198975
Validation loss: 2.2470263601631246

Epoch: 6| Step: 11
Training loss: 2.108919143676758
Validation loss: 2.244609227744482

Epoch: 6| Step: 12
Training loss: 2.5912606716156006
Validation loss: 2.247552212848458

Epoch: 6| Step: 13
Training loss: 2.0286078453063965
Validation loss: 2.246835857309321

Epoch: 59| Step: 0
Training loss: 1.8287123441696167
Validation loss: 2.2415095401066605

Epoch: 6| Step: 1
Training loss: 2.4220659732818604
Validation loss: 2.2425309611905004

Epoch: 6| Step: 2
Training loss: 3.108898162841797
Validation loss: 2.2393995651634793

Epoch: 6| Step: 3
Training loss: 2.550302028656006
Validation loss: 2.2371242353993077

Epoch: 6| Step: 4
Training loss: 2.700923204421997
Validation loss: 2.2403496260284097

Epoch: 6| Step: 5
Training loss: 2.4704878330230713
Validation loss: 2.23849089940389

Epoch: 6| Step: 6
Training loss: 1.772842526435852
Validation loss: 2.2394194346602245

Epoch: 6| Step: 7
Training loss: 2.323204517364502
Validation loss: 2.2400455910672425

Epoch: 6| Step: 8
Training loss: 2.1787850856781006
Validation loss: 2.245281031054835

Epoch: 6| Step: 9
Training loss: 2.1441242694854736
Validation loss: 2.2509779314840994

Epoch: 6| Step: 10
Training loss: 2.5414414405822754
Validation loss: 2.26009649743316

Epoch: 6| Step: 11
Training loss: 3.2450461387634277
Validation loss: 2.2856978524115776

Epoch: 6| Step: 12
Training loss: 2.925572395324707
Validation loss: 2.315093389121435

Epoch: 6| Step: 13
Training loss: 4.180551528930664
Validation loss: 2.321704451755811

Epoch: 60| Step: 0
Training loss: 3.088252067565918
Validation loss: 2.311681511581585

Epoch: 6| Step: 1
Training loss: 1.626934289932251
Validation loss: 2.326057841700892

Epoch: 6| Step: 2
Training loss: 2.7053451538085938
Validation loss: 2.3314561715690036

Epoch: 6| Step: 3
Training loss: 3.1639227867126465
Validation loss: 2.338170987303539

Epoch: 6| Step: 4
Training loss: 3.4324445724487305
Validation loss: 2.3429676999327955

Epoch: 6| Step: 5
Training loss: 2.0788772106170654
Validation loss: 2.347842442092075

Epoch: 6| Step: 6
Training loss: 2.889962673187256
Validation loss: 2.365036528597596

Epoch: 6| Step: 7
Training loss: 2.7152774333953857
Validation loss: 2.3300239860370593

Epoch: 6| Step: 8
Training loss: 2.1305954456329346
Validation loss: 2.3298916329619703

Epoch: 6| Step: 9
Training loss: 2.6456637382507324
Validation loss: 2.3025567993041007

Epoch: 6| Step: 10
Training loss: 2.149073600769043
Validation loss: 2.273104149808166

Epoch: 6| Step: 11
Training loss: 3.0982046127319336
Validation loss: 2.2590971890316216

Epoch: 6| Step: 12
Training loss: 1.2885589599609375
Validation loss: 2.26024995439796

Epoch: 6| Step: 13
Training loss: 2.9658539295196533
Validation loss: 2.2399857300584034

Epoch: 61| Step: 0
Training loss: 2.892159938812256
Validation loss: 2.23748952855346

Epoch: 6| Step: 1
Training loss: 2.9682676792144775
Validation loss: 2.2323773804531304

Epoch: 6| Step: 2
Training loss: 1.9209803342819214
Validation loss: 2.230752633463952

Epoch: 6| Step: 3
Training loss: 3.2725307941436768
Validation loss: 2.237919651052003

Epoch: 6| Step: 4
Training loss: 1.7560970783233643
Validation loss: 2.237053035407938

Epoch: 6| Step: 5
Training loss: 1.7928085327148438
Validation loss: 2.2483411681267524

Epoch: 6| Step: 6
Training loss: 2.7739953994750977
Validation loss: 2.267013519041

Epoch: 6| Step: 7
Training loss: 3.139727830886841
Validation loss: 2.2769963997666554

Epoch: 6| Step: 8
Training loss: 3.1876797676086426
Validation loss: 2.265817106411021

Epoch: 6| Step: 9
Training loss: 2.41422963142395
Validation loss: 2.2523136113279607

Epoch: 6| Step: 10
Training loss: 3.182856559753418
Validation loss: 2.239425971943845

Epoch: 6| Step: 11
Training loss: 2.471099376678467
Validation loss: 2.2360735221575667

Epoch: 6| Step: 12
Training loss: 1.846024990081787
Validation loss: 2.2337659456396617

Epoch: 6| Step: 13
Training loss: 1.8383890390396118
Validation loss: 2.2316242289799515

Epoch: 62| Step: 0
Training loss: 2.560926914215088
Validation loss: 2.2348899687490156

Epoch: 6| Step: 1
Training loss: 2.4647059440612793
Validation loss: 2.2508388129613732

Epoch: 6| Step: 2
Training loss: 2.414297580718994
Validation loss: 2.2540165865293114

Epoch: 6| Step: 3
Training loss: 2.046274185180664
Validation loss: 2.248541755060996

Epoch: 6| Step: 4
Training loss: 3.0655064582824707
Validation loss: 2.271833581309165

Epoch: 6| Step: 5
Training loss: 2.844735622406006
Validation loss: 2.315385195516771

Epoch: 6| Step: 6
Training loss: 2.355848789215088
Validation loss: 2.3505424248274935

Epoch: 6| Step: 7
Training loss: 2.2023820877075195
Validation loss: 2.3674181494661557

Epoch: 6| Step: 8
Training loss: 3.715696334838867
Validation loss: 2.352916056110013

Epoch: 6| Step: 9
Training loss: 1.9885618686676025
Validation loss: 2.3374880167745773

Epoch: 6| Step: 10
Training loss: 2.7250866889953613
Validation loss: 2.2996519329727336

Epoch: 6| Step: 11
Training loss: 2.1836276054382324
Validation loss: 2.273158568207936

Epoch: 6| Step: 12
Training loss: 2.78957462310791
Validation loss: 2.2590179084449686

Epoch: 6| Step: 13
Training loss: 2.1602697372436523
Validation loss: 2.2670257117158625

Epoch: 63| Step: 0
Training loss: 2.295865774154663
Validation loss: 2.2658512156496764

Epoch: 6| Step: 1
Training loss: 2.464313507080078
Validation loss: 2.2654407075656358

Epoch: 6| Step: 2
Training loss: 2.2817487716674805
Validation loss: 2.278161259107692

Epoch: 6| Step: 3
Training loss: 2.748039722442627
Validation loss: 2.2726901500455794

Epoch: 6| Step: 4
Training loss: 2.130302667617798
Validation loss: 2.254200156017016

Epoch: 6| Step: 5
Training loss: 2.5445756912231445
Validation loss: 2.2492410239352973

Epoch: 6| Step: 6
Training loss: 2.9222187995910645
Validation loss: 2.2293673125646447

Epoch: 6| Step: 7
Training loss: 2.618729829788208
Validation loss: 2.2133008587744927

Epoch: 6| Step: 8
Training loss: 2.488541603088379
Validation loss: 2.2156346203178487

Epoch: 6| Step: 9
Training loss: 2.398397207260132
Validation loss: 2.2106911341349282

Epoch: 6| Step: 10
Training loss: 2.681983232498169
Validation loss: 2.212667962556244

Epoch: 6| Step: 11
Training loss: 2.879758834838867
Validation loss: 2.2099253592952603

Epoch: 6| Step: 12
Training loss: 3.0337507724761963
Validation loss: 2.2117851267578783

Epoch: 6| Step: 13
Training loss: 1.8797528743743896
Validation loss: 2.214880202406196

Epoch: 64| Step: 0
Training loss: 2.3455591201782227
Validation loss: 2.21325300457657

Epoch: 6| Step: 1
Training loss: 2.600983142852783
Validation loss: 2.2083776356071554

Epoch: 6| Step: 2
Training loss: 2.1683621406555176
Validation loss: 2.204044190786218

Epoch: 6| Step: 3
Training loss: 2.2801246643066406
Validation loss: 2.2093848925764843

Epoch: 6| Step: 4
Training loss: 2.871093273162842
Validation loss: 2.209229697463333

Epoch: 6| Step: 5
Training loss: 3.3319716453552246
Validation loss: 2.2081196513227237

Epoch: 6| Step: 6
Training loss: 1.7692726850509644
Validation loss: 2.212577417332639

Epoch: 6| Step: 7
Training loss: 3.1485607624053955
Validation loss: 2.2331011910592355

Epoch: 6| Step: 8
Training loss: 2.685300827026367
Validation loss: 2.2417640609125935

Epoch: 6| Step: 9
Training loss: 2.8367209434509277
Validation loss: 2.2637253935619066

Epoch: 6| Step: 10
Training loss: 2.7265336513519287
Validation loss: 2.282323614243538

Epoch: 6| Step: 11
Training loss: 2.4343011379241943
Validation loss: 2.2920376869939987

Epoch: 6| Step: 12
Training loss: 1.8777586221694946
Validation loss: 2.3201925062364146

Epoch: 6| Step: 13
Training loss: 2.249660015106201
Validation loss: 2.347607348554878

Epoch: 65| Step: 0
Training loss: 1.849381446838379
Validation loss: 2.333199694592466

Epoch: 6| Step: 1
Training loss: 2.480835437774658
Validation loss: 2.2957670944993214

Epoch: 6| Step: 2
Training loss: 2.521117925643921
Validation loss: 2.268806649792579

Epoch: 6| Step: 3
Training loss: 2.186366081237793
Validation loss: 2.2440571784973145

Epoch: 6| Step: 4
Training loss: 2.384321451187134
Validation loss: 2.232739120401362

Epoch: 6| Step: 5
Training loss: 2.9584081172943115
Validation loss: 2.2174062498154177

Epoch: 6| Step: 6
Training loss: 2.0970563888549805
Validation loss: 2.212855403141309

Epoch: 6| Step: 7
Training loss: 3.10036563873291
Validation loss: 2.2047316592226744

Epoch: 6| Step: 8
Training loss: 2.40401291847229
Validation loss: 2.1976084247712167

Epoch: 6| Step: 9
Training loss: 2.291372537612915
Validation loss: 2.195692775070026

Epoch: 6| Step: 10
Training loss: 1.9971990585327148
Validation loss: 2.19089364364583

Epoch: 6| Step: 11
Training loss: 3.5842511653900146
Validation loss: 2.1949110133673555

Epoch: 6| Step: 12
Training loss: 2.791461706161499
Validation loss: 2.1929312341956684

Epoch: 6| Step: 13
Training loss: 2.5500197410583496
Validation loss: 2.1951133256317465

Epoch: 66| Step: 0
Training loss: 3.0630178451538086
Validation loss: 2.1985823441577215

Epoch: 6| Step: 1
Training loss: 2.7985033988952637
Validation loss: 2.199655399527601

Epoch: 6| Step: 2
Training loss: 2.437652826309204
Validation loss: 2.210147488501764

Epoch: 6| Step: 3
Training loss: 1.2577217817306519
Validation loss: 2.216829312744961

Epoch: 6| Step: 4
Training loss: 2.842298984527588
Validation loss: 2.2183905570737776

Epoch: 6| Step: 5
Training loss: 2.1909728050231934
Validation loss: 2.217623440168237

Epoch: 6| Step: 6
Training loss: 2.651486873626709
Validation loss: 2.229473957451441

Epoch: 6| Step: 7
Training loss: 2.1250643730163574
Validation loss: 2.227668446879233

Epoch: 6| Step: 8
Training loss: 2.965697765350342
Validation loss: 2.2102102464245212

Epoch: 6| Step: 9
Training loss: 2.1396524906158447
Validation loss: 2.208308958238171

Epoch: 6| Step: 10
Training loss: 2.3931338787078857
Validation loss: 2.2289814026125017

Epoch: 6| Step: 11
Training loss: 2.553831100463867
Validation loss: 2.253450983314104

Epoch: 6| Step: 12
Training loss: 2.89555287361145
Validation loss: 2.2644682468906527

Epoch: 6| Step: 13
Training loss: 2.9355218410491943
Validation loss: 2.2638681139997257

Epoch: 67| Step: 0
Training loss: 2.7771127223968506
Validation loss: 2.2510349929973645

Epoch: 6| Step: 1
Training loss: 2.896977186203003
Validation loss: 2.2152660790310112

Epoch: 6| Step: 2
Training loss: 3.092214822769165
Validation loss: 2.2057448029518127

Epoch: 6| Step: 3
Training loss: 1.9685299396514893
Validation loss: 2.186776679049256

Epoch: 6| Step: 4
Training loss: 1.9947513341903687
Validation loss: 2.1883263921224945

Epoch: 6| Step: 5
Training loss: 2.7655181884765625
Validation loss: 2.187108721784366

Epoch: 6| Step: 6
Training loss: 1.9355647563934326
Validation loss: 2.184931129537603

Epoch: 6| Step: 7
Training loss: 2.8218369483947754
Validation loss: 2.1879760116659184

Epoch: 6| Step: 8
Training loss: 3.004927158355713
Validation loss: 2.1979686008986605

Epoch: 6| Step: 9
Training loss: 2.3496060371398926
Validation loss: 2.2064892322786394

Epoch: 6| Step: 10
Training loss: 2.353663921356201
Validation loss: 2.2159071558265278

Epoch: 6| Step: 11
Training loss: 2.3934035301208496
Validation loss: 2.2143729168881654

Epoch: 6| Step: 12
Training loss: 2.481245517730713
Validation loss: 2.211250515394313

Epoch: 6| Step: 13
Training loss: 2.2170982360839844
Validation loss: 2.191723600510628

Epoch: 68| Step: 0
Training loss: 2.3898446559906006
Validation loss: 2.187470902678787

Epoch: 6| Step: 1
Training loss: 2.5417139530181885
Validation loss: 2.1855757492844776

Epoch: 6| Step: 2
Training loss: 2.510138988494873
Validation loss: 2.187617705714318

Epoch: 6| Step: 3
Training loss: 2.5891988277435303
Validation loss: 2.18766454855601

Epoch: 6| Step: 4
Training loss: 2.7482728958129883
Validation loss: 2.18704734053663

Epoch: 6| Step: 5
Training loss: 2.264678478240967
Validation loss: 2.1856454777461227

Epoch: 6| Step: 6
Training loss: 2.3002779483795166
Validation loss: 2.1816402225084204

Epoch: 6| Step: 7
Training loss: 2.2905073165893555
Validation loss: 2.1821515060240224

Epoch: 6| Step: 8
Training loss: 2.621415376663208
Validation loss: 2.1853815176153697

Epoch: 6| Step: 9
Training loss: 2.386812210083008
Validation loss: 2.187566316255959

Epoch: 6| Step: 10
Training loss: 3.1138603687286377
Validation loss: 2.2288558662578626

Epoch: 6| Step: 11
Training loss: 1.812668800354004
Validation loss: 2.264322906412104

Epoch: 6| Step: 12
Training loss: 2.333634376525879
Validation loss: 2.297816902078608

Epoch: 6| Step: 13
Training loss: 4.056161880493164
Validation loss: 2.326127352253083

Epoch: 69| Step: 0
Training loss: 2.476858139038086
Validation loss: 2.2443521689343195

Epoch: 6| Step: 1
Training loss: 1.485368013381958
Validation loss: 2.2032827254264586

Epoch: 6| Step: 2
Training loss: 2.896472692489624
Validation loss: 2.1921268022188576

Epoch: 6| Step: 3
Training loss: 2.9625167846679688
Validation loss: 2.1774719453627065

Epoch: 6| Step: 4
Training loss: 2.5121469497680664
Validation loss: 2.1771049089329217

Epoch: 6| Step: 5
Training loss: 3.048975944519043
Validation loss: 2.176603199333273

Epoch: 6| Step: 6
Training loss: 2.4551587104797363
Validation loss: 2.183460409923266

Epoch: 6| Step: 7
Training loss: 1.598473072052002
Validation loss: 2.1991073649416686

Epoch: 6| Step: 8
Training loss: 2.9487483501434326
Validation loss: 2.2163221707908054

Epoch: 6| Step: 9
Training loss: 2.6009864807128906
Validation loss: 2.2309652015727055

Epoch: 6| Step: 10
Training loss: 2.9127018451690674
Validation loss: 2.2231871927938154

Epoch: 6| Step: 11
Training loss: 2.472712516784668
Validation loss: 2.210216999053955

Epoch: 6| Step: 12
Training loss: 2.3600215911865234
Validation loss: 2.2036896033953597

Epoch: 6| Step: 13
Training loss: 2.4191408157348633
Validation loss: 2.198780270032985

Epoch: 70| Step: 0
Training loss: 2.8302762508392334
Validation loss: 2.2045201498975038

Epoch: 6| Step: 1
Training loss: 2.433633804321289
Validation loss: 2.1950839540009857

Epoch: 6| Step: 2
Training loss: 2.804492950439453
Validation loss: 2.194246135732179

Epoch: 6| Step: 3
Training loss: 2.1618611812591553
Validation loss: 2.185705646391838

Epoch: 6| Step: 4
Training loss: 2.617178201675415
Validation loss: 2.1705468752050914

Epoch: 6| Step: 5
Training loss: 3.0143918991088867
Validation loss: 2.1668350824745755

Epoch: 6| Step: 6
Training loss: 2.4675588607788086
Validation loss: 2.173970389109786

Epoch: 6| Step: 7
Training loss: 2.116481065750122
Validation loss: 2.177965698703643

Epoch: 6| Step: 8
Training loss: 1.8421289920806885
Validation loss: 2.17536509677928

Epoch: 6| Step: 9
Training loss: 2.2226016521453857
Validation loss: 2.1772340561753962

Epoch: 6| Step: 10
Training loss: 2.6349000930786133
Validation loss: 2.1825302544460503

Epoch: 6| Step: 11
Training loss: 2.8433876037597656
Validation loss: 2.1797999271782498

Epoch: 6| Step: 12
Training loss: 2.9591519832611084
Validation loss: 2.1905880025638047

Epoch: 6| Step: 13
Training loss: 1.5107626914978027
Validation loss: 2.201220925136279

Epoch: 71| Step: 0
Training loss: 1.8962864875793457
Validation loss: 2.185718438958609

Epoch: 6| Step: 1
Training loss: 2.328658103942871
Validation loss: 2.1615270606933104

Epoch: 6| Step: 2
Training loss: 2.4839508533477783
Validation loss: 2.163843229252805

Epoch: 6| Step: 3
Training loss: 2.4488697052001953
Validation loss: 2.1700709724938996

Epoch: 6| Step: 4
Training loss: 3.0444743633270264
Validation loss: 2.162933877719346

Epoch: 6| Step: 5
Training loss: 2.4262044429779053
Validation loss: 2.162855348279399

Epoch: 6| Step: 6
Training loss: 1.5288939476013184
Validation loss: 2.158636949395621

Epoch: 6| Step: 7
Training loss: 2.519209623336792
Validation loss: 2.1503389599502727

Epoch: 6| Step: 8
Training loss: 2.7148287296295166
Validation loss: 2.1559939653642717

Epoch: 6| Step: 9
Training loss: 2.0337517261505127
Validation loss: 2.1489942125094834

Epoch: 6| Step: 10
Training loss: 3.4358510971069336
Validation loss: 2.150067707543732

Epoch: 6| Step: 11
Training loss: 2.9681177139282227
Validation loss: 2.152012368684174

Epoch: 6| Step: 12
Training loss: 2.4440550804138184
Validation loss: 2.1540034150564544

Epoch: 6| Step: 13
Training loss: 2.3620035648345947
Validation loss: 2.1541661947004256

Epoch: 72| Step: 0
Training loss: 1.8873305320739746
Validation loss: 2.1770301890629593

Epoch: 6| Step: 1
Training loss: 2.183807373046875
Validation loss: 2.2366312498687417

Epoch: 6| Step: 2
Training loss: 2.6101150512695312
Validation loss: 2.276989890683082

Epoch: 6| Step: 3
Training loss: 3.0281822681427
Validation loss: 2.2949746859970914

Epoch: 6| Step: 4
Training loss: 3.0848019123077393
Validation loss: 2.2708520043280815

Epoch: 6| Step: 5
Training loss: 1.9942454099655151
Validation loss: 2.2277321418126426

Epoch: 6| Step: 6
Training loss: 2.3919031620025635
Validation loss: 2.1728710333506265

Epoch: 6| Step: 7
Training loss: 2.468053102493286
Validation loss: 2.147553038853471

Epoch: 6| Step: 8
Training loss: 2.0760507583618164
Validation loss: 2.1476262141299505

Epoch: 6| Step: 9
Training loss: 2.593437671661377
Validation loss: 2.144517542213522

Epoch: 6| Step: 10
Training loss: 2.0689308643341064
Validation loss: 2.1557420479354037

Epoch: 6| Step: 11
Training loss: 3.3446426391601562
Validation loss: 2.1548103594010874

Epoch: 6| Step: 12
Training loss: 2.117870330810547
Validation loss: 2.1583629192844516

Epoch: 6| Step: 13
Training loss: 3.6701202392578125
Validation loss: 2.154093365515432

Epoch: 73| Step: 0
Training loss: 2.4027578830718994
Validation loss: 2.1544601763448408

Epoch: 6| Step: 1
Training loss: 2.405632972717285
Validation loss: 2.1551797005438034

Epoch: 6| Step: 2
Training loss: 2.6923880577087402
Validation loss: 2.154589190278002

Epoch: 6| Step: 3
Training loss: 2.8222384452819824
Validation loss: 2.1563565987412647

Epoch: 6| Step: 4
Training loss: 1.8206207752227783
Validation loss: 2.154798048798756

Epoch: 6| Step: 5
Training loss: 2.0395562648773193
Validation loss: 2.1585360893639187

Epoch: 6| Step: 6
Training loss: 3.045107364654541
Validation loss: 2.169755804923273

Epoch: 6| Step: 7
Training loss: 2.2699646949768066
Validation loss: 2.1934881069326915

Epoch: 6| Step: 8
Training loss: 2.2351362705230713
Validation loss: 2.2335004806518555

Epoch: 6| Step: 9
Training loss: 2.1835215091705322
Validation loss: 2.2493182997549734

Epoch: 6| Step: 10
Training loss: 2.4017751216888428
Validation loss: 2.262765407562256

Epoch: 6| Step: 11
Training loss: 2.9216084480285645
Validation loss: 2.289605453450193

Epoch: 6| Step: 12
Training loss: 2.932694911956787
Validation loss: 2.299818677286948

Epoch: 6| Step: 13
Training loss: 3.4257099628448486
Validation loss: 2.3196377344028924

Epoch: 74| Step: 0
Training loss: 2.9962308406829834
Validation loss: 2.309255853776009

Epoch: 6| Step: 1
Training loss: 2.961442232131958
Validation loss: 2.298368020724225

Epoch: 6| Step: 2
Training loss: 2.808166027069092
Validation loss: 2.2542977127977597

Epoch: 6| Step: 3
Training loss: 1.7751964330673218
Validation loss: 2.2157050999262

Epoch: 6| Step: 4
Training loss: 2.8272910118103027
Validation loss: 2.199883666089786

Epoch: 6| Step: 5
Training loss: 2.0553367137908936
Validation loss: 2.1778941539026078

Epoch: 6| Step: 6
Training loss: 2.675365686416626
Validation loss: 2.1603706498299875

Epoch: 6| Step: 7
Training loss: 3.2003283500671387
Validation loss: 2.1551942312589256

Epoch: 6| Step: 8
Training loss: 2.4791860580444336
Validation loss: 2.1565559884553314

Epoch: 6| Step: 9
Training loss: 1.649537205696106
Validation loss: 2.156610124854631

Epoch: 6| Step: 10
Training loss: 2.194039821624756
Validation loss: 2.1555702852946457

Epoch: 6| Step: 11
Training loss: 2.2920892238616943
Validation loss: 2.156151981763942

Epoch: 6| Step: 12
Training loss: 2.5040502548217773
Validation loss: 2.1477150327415875

Epoch: 6| Step: 13
Training loss: 2.523237943649292
Validation loss: 2.1478499545845935

Epoch: 75| Step: 0
Training loss: 2.8705825805664062
Validation loss: 2.14693937506727

Epoch: 6| Step: 1
Training loss: 2.791919469833374
Validation loss: 2.151384604874478

Epoch: 6| Step: 2
Training loss: 1.9366437196731567
Validation loss: 2.1598350489011375

Epoch: 6| Step: 3
Training loss: 1.920601487159729
Validation loss: 2.1691042120738695

Epoch: 6| Step: 4
Training loss: 3.1166110038757324
Validation loss: 2.191370182139899

Epoch: 6| Step: 5
Training loss: 1.6636364459991455
Validation loss: 2.2162852594929356

Epoch: 6| Step: 6
Training loss: 2.551616668701172
Validation loss: 2.254552484840475

Epoch: 6| Step: 7
Training loss: 2.8281750679016113
Validation loss: 2.2693643928855978

Epoch: 6| Step: 8
Training loss: 2.89410138130188
Validation loss: 2.2624214874800814

Epoch: 6| Step: 9
Training loss: 2.8067264556884766
Validation loss: 2.2588126197937997

Epoch: 6| Step: 10
Training loss: 2.567558765411377
Validation loss: 2.21953155661142

Epoch: 6| Step: 11
Training loss: 2.9392762184143066
Validation loss: 2.187511985019971

Epoch: 6| Step: 12
Training loss: 1.593092441558838
Validation loss: 2.1660251155976327

Epoch: 6| Step: 13
Training loss: 2.4233226776123047
Validation loss: 2.1544606839456866

Epoch: 76| Step: 0
Training loss: 2.8680830001831055
Validation loss: 2.152438238102903

Epoch: 6| Step: 1
Training loss: 1.9927124977111816
Validation loss: 2.1524247123349096

Epoch: 6| Step: 2
Training loss: 2.2555813789367676
Validation loss: 2.149445131260862

Epoch: 6| Step: 3
Training loss: 3.0437848567962646
Validation loss: 2.1517798285330496

Epoch: 6| Step: 4
Training loss: 1.4672460556030273
Validation loss: 2.1490441189017346

Epoch: 6| Step: 5
Training loss: 2.3182151317596436
Validation loss: 2.155409812927246

Epoch: 6| Step: 6
Training loss: 2.413709878921509
Validation loss: 2.152240817264844

Epoch: 6| Step: 7
Training loss: 2.1849756240844727
Validation loss: 2.157730612703549

Epoch: 6| Step: 8
Training loss: 2.449420928955078
Validation loss: 2.1774306066574587

Epoch: 6| Step: 9
Training loss: 2.4267830848693848
Validation loss: 2.2031799183096936

Epoch: 6| Step: 10
Training loss: 3.5951762199401855
Validation loss: 2.24019254151211

Epoch: 6| Step: 11
Training loss: 2.244873046875
Validation loss: 2.2555495590291996

Epoch: 6| Step: 12
Training loss: 3.232532501220703
Validation loss: 2.2441450242073304

Epoch: 6| Step: 13
Training loss: 1.9994547367095947
Validation loss: 2.2208625373019966

Epoch: 77| Step: 0
Training loss: 2.2733206748962402
Validation loss: 2.194195009046985

Epoch: 6| Step: 1
Training loss: 2.4236397743225098
Validation loss: 2.177429101800406

Epoch: 6| Step: 2
Training loss: 2.339233160018921
Validation loss: 2.1564655637228363

Epoch: 6| Step: 3
Training loss: 2.0736286640167236
Validation loss: 2.143801937821091

Epoch: 6| Step: 4
Training loss: 2.5029749870300293
Validation loss: 2.1397088086733254

Epoch: 6| Step: 5
Training loss: 2.9050679206848145
Validation loss: 2.135065045408023

Epoch: 6| Step: 6
Training loss: 2.879167079925537
Validation loss: 2.131384026619696

Epoch: 6| Step: 7
Training loss: 3.0990138053894043
Validation loss: 2.126669333827111

Epoch: 6| Step: 8
Training loss: 2.3173954486846924
Validation loss: 2.1281988543848835

Epoch: 6| Step: 9
Training loss: 2.061530828475952
Validation loss: 2.118170125510103

Epoch: 6| Step: 10
Training loss: 2.390407085418701
Validation loss: 2.1175108391751527

Epoch: 6| Step: 11
Training loss: 2.437659502029419
Validation loss: 2.1176222562789917

Epoch: 6| Step: 12
Training loss: 2.046861171722412
Validation loss: 2.12673903793417

Epoch: 6| Step: 13
Training loss: 3.1772329807281494
Validation loss: 2.1405518888145365

Epoch: 78| Step: 0
Training loss: 2.672581434249878
Validation loss: 2.182299042260775

Epoch: 6| Step: 1
Training loss: 2.3867568969726562
Validation loss: 2.197215299452505

Epoch: 6| Step: 2
Training loss: 2.305683135986328
Validation loss: 2.209943755980461

Epoch: 6| Step: 3
Training loss: 2.81776762008667
Validation loss: 2.2288783596407984

Epoch: 6| Step: 4
Training loss: 2.800931692123413
Validation loss: 2.2114038236679567

Epoch: 6| Step: 5
Training loss: 2.106127977371216
Validation loss: 2.170124275709993

Epoch: 6| Step: 6
Training loss: 1.5026856660842896
Validation loss: 2.146735809182608

Epoch: 6| Step: 7
Training loss: 2.5506274700164795
Validation loss: 2.137982464605762

Epoch: 6| Step: 8
Training loss: 3.510446786880493
Validation loss: 2.1285512242265927

Epoch: 6| Step: 9
Training loss: 2.4302968978881836
Validation loss: 2.120816769138459

Epoch: 6| Step: 10
Training loss: 2.126028060913086
Validation loss: 2.119867850375432

Epoch: 6| Step: 11
Training loss: 2.8252434730529785
Validation loss: 2.119881244115932

Epoch: 6| Step: 12
Training loss: 2.0759353637695312
Validation loss: 2.1153596626814974

Epoch: 6| Step: 13
Training loss: 2.4275617599487305
Validation loss: 2.1220320988726873

Epoch: 79| Step: 0
Training loss: 2.923121213912964
Validation loss: 2.1173851015747234

Epoch: 6| Step: 1
Training loss: 2.352631092071533
Validation loss: 2.11623385132

Epoch: 6| Step: 2
Training loss: 2.158658266067505
Validation loss: 2.1114881295029835

Epoch: 6| Step: 3
Training loss: 2.4253108501434326
Validation loss: 2.116610397574722

Epoch: 6| Step: 4
Training loss: 2.46657133102417
Validation loss: 2.1172609406132854

Epoch: 6| Step: 5
Training loss: 3.087092638015747
Validation loss: 2.130072619325371

Epoch: 6| Step: 6
Training loss: 2.2642669677734375
Validation loss: 2.147538618374896

Epoch: 6| Step: 7
Training loss: 2.6579480171203613
Validation loss: 2.157635582390652

Epoch: 6| Step: 8
Training loss: 1.9895501136779785
Validation loss: 2.171479889141616

Epoch: 6| Step: 9
Training loss: 1.9712704420089722
Validation loss: 2.174721287142846

Epoch: 6| Step: 10
Training loss: 2.4025163650512695
Validation loss: 2.1642692858173

Epoch: 6| Step: 11
Training loss: 2.304183006286621
Validation loss: 2.1442941593867477

Epoch: 6| Step: 12
Training loss: 2.3511476516723633
Validation loss: 2.154787730145198

Epoch: 6| Step: 13
Training loss: 2.9462671279907227
Validation loss: 2.1732464041761173

Epoch: 80| Step: 0
Training loss: 2.405362606048584
Validation loss: 2.2001103534493396

Epoch: 6| Step: 1
Training loss: 2.9191720485687256
Validation loss: 2.2030817565097602

Epoch: 6| Step: 2
Training loss: 2.5591771602630615
Validation loss: 2.2036548224828576

Epoch: 6| Step: 3
Training loss: 2.393932819366455
Validation loss: 2.2053316921316166

Epoch: 6| Step: 4
Training loss: 2.8941524028778076
Validation loss: 2.192329392638258

Epoch: 6| Step: 5
Training loss: 2.692824125289917
Validation loss: 2.1856430935603317

Epoch: 6| Step: 6
Training loss: 2.4004290103912354
Validation loss: 2.157869815826416

Epoch: 6| Step: 7
Training loss: 1.9315929412841797
Validation loss: 2.1362018175022577

Epoch: 6| Step: 8
Training loss: 2.556988477706909
Validation loss: 2.1351030744532102

Epoch: 6| Step: 9
Training loss: 2.0122087001800537
Validation loss: 2.1239978882574264

Epoch: 6| Step: 10
Training loss: 2.7417712211608887
Validation loss: 2.122118293598134

Epoch: 6| Step: 11
Training loss: 1.999741792678833
Validation loss: 2.1243785735099547

Epoch: 6| Step: 12
Training loss: 2.525864362716675
Validation loss: 2.1255923983871297

Epoch: 6| Step: 13
Training loss: 1.6114565134048462
Validation loss: 2.1338782823213966

Epoch: 81| Step: 0
Training loss: 2.5633487701416016
Validation loss: 2.1479224671599684

Epoch: 6| Step: 1
Training loss: 2.294860363006592
Validation loss: 2.1612077477157756

Epoch: 6| Step: 2
Training loss: 2.7089319229125977
Validation loss: 2.1657627731241207

Epoch: 6| Step: 3
Training loss: 2.747831344604492
Validation loss: 2.1696400450121973

Epoch: 6| Step: 4
Training loss: 2.3803870677948
Validation loss: 2.173381890020063

Epoch: 6| Step: 5
Training loss: 2.5105037689208984
Validation loss: 2.1607089811755764

Epoch: 6| Step: 6
Training loss: 2.334477424621582
Validation loss: 2.1510870610513995

Epoch: 6| Step: 7
Training loss: 2.5592684745788574
Validation loss: 2.1316562493642173

Epoch: 6| Step: 8
Training loss: 1.9925798177719116
Validation loss: 2.1153359387510564

Epoch: 6| Step: 9
Training loss: 2.431081533432007
Validation loss: 2.111051413320726

Epoch: 6| Step: 10
Training loss: 2.077484130859375
Validation loss: 2.109335478915963

Epoch: 6| Step: 11
Training loss: 2.812842607498169
Validation loss: 2.119793894470379

Epoch: 6| Step: 12
Training loss: 2.1878437995910645
Validation loss: 2.113007563416676

Epoch: 6| Step: 13
Training loss: 2.3079371452331543
Validation loss: 2.1065226883016606

Epoch: 82| Step: 0
Training loss: 2.9661459922790527
Validation loss: 2.112255888600503

Epoch: 6| Step: 1
Training loss: 2.405237913131714
Validation loss: 2.136321096010106

Epoch: 6| Step: 2
Training loss: 2.161259412765503
Validation loss: 2.1549355035187094

Epoch: 6| Step: 3
Training loss: 2.823887586593628
Validation loss: 2.178328755081341

Epoch: 6| Step: 4
Training loss: 2.552853584289551
Validation loss: 2.1866560020754413

Epoch: 6| Step: 5
Training loss: 2.4665353298187256
Validation loss: 2.18838696582343

Epoch: 6| Step: 6
Training loss: 2.1386430263519287
Validation loss: 2.1805807813521354

Epoch: 6| Step: 7
Training loss: 2.344465732574463
Validation loss: 2.1612032357082573

Epoch: 6| Step: 8
Training loss: 1.8103184700012207
Validation loss: 2.1342268784840903

Epoch: 6| Step: 9
Training loss: 2.414274215698242
Validation loss: 2.1366941313589773

Epoch: 6| Step: 10
Training loss: 2.5040225982666016
Validation loss: 2.1339213258476666

Epoch: 6| Step: 11
Training loss: 2.313136100769043
Validation loss: 2.130294845950219

Epoch: 6| Step: 12
Training loss: 2.437105655670166
Validation loss: 2.1410355593568537

Epoch: 6| Step: 13
Training loss: 3.1016526222229004
Validation loss: 2.160838306591075

Epoch: 83| Step: 0
Training loss: 2.5167036056518555
Validation loss: 2.184720213695239

Epoch: 6| Step: 1
Training loss: 2.700269937515259
Validation loss: 2.173992896592745

Epoch: 6| Step: 2
Training loss: 1.8548963069915771
Validation loss: 2.1721524423168552

Epoch: 6| Step: 3
Training loss: 2.176772356033325
Validation loss: 2.162061256747092

Epoch: 6| Step: 4
Training loss: 2.3739418983459473
Validation loss: 2.1665213633609075

Epoch: 6| Step: 5
Training loss: 2.1794095039367676
Validation loss: 2.155418611341907

Epoch: 6| Step: 6
Training loss: 1.9554908275604248
Validation loss: 2.145184355397378

Epoch: 6| Step: 7
Training loss: 3.193657875061035
Validation loss: 2.118656309702063

Epoch: 6| Step: 8
Training loss: 2.4498884677886963
Validation loss: 2.103933906042448

Epoch: 6| Step: 9
Training loss: 2.3468871116638184
Validation loss: 2.1069501664048884

Epoch: 6| Step: 10
Training loss: 2.593289613723755
Validation loss: 2.1244707876636135

Epoch: 6| Step: 11
Training loss: 2.9578750133514404
Validation loss: 2.123499096080821

Epoch: 6| Step: 12
Training loss: 2.7329273223876953
Validation loss: 2.0984445489862913

Epoch: 6| Step: 13
Training loss: 2.0778958797454834
Validation loss: 2.098904025170111

Epoch: 84| Step: 0
Training loss: 3.438706874847412
Validation loss: 2.106348852957449

Epoch: 6| Step: 1
Training loss: 1.5983867645263672
Validation loss: 2.1107202832416823

Epoch: 6| Step: 2
Training loss: 2.8602752685546875
Validation loss: 2.12685400952575

Epoch: 6| Step: 3
Training loss: 2.1608664989471436
Validation loss: 2.138671580181327

Epoch: 6| Step: 4
Training loss: 2.2994508743286133
Validation loss: 2.1686452293908722

Epoch: 6| Step: 5
Training loss: 2.135251998901367
Validation loss: 2.177964307928598

Epoch: 6| Step: 6
Training loss: 2.9725875854492188
Validation loss: 2.18083599305922

Epoch: 6| Step: 7
Training loss: 1.9676929712295532
Validation loss: 2.151711792074224

Epoch: 6| Step: 8
Training loss: 3.236219882965088
Validation loss: 2.131172646758377

Epoch: 6| Step: 9
Training loss: 2.4219765663146973
Validation loss: 2.127694632417412

Epoch: 6| Step: 10
Training loss: 1.6137832403182983
Validation loss: 2.109352268198485

Epoch: 6| Step: 11
Training loss: 2.5638179779052734
Validation loss: 2.111440481678132

Epoch: 6| Step: 12
Training loss: 2.0598058700561523
Validation loss: 2.1075327088755946

Epoch: 6| Step: 13
Training loss: 2.3992879390716553
Validation loss: 2.101414707399184

Epoch: 85| Step: 0
Training loss: 2.8133726119995117
Validation loss: 2.090671238078866

Epoch: 6| Step: 1
Training loss: 2.4214651584625244
Validation loss: 2.08384346705611

Epoch: 6| Step: 2
Training loss: 2.271240234375
Validation loss: 2.0820709082388107

Epoch: 6| Step: 3
Training loss: 2.5255231857299805
Validation loss: 2.078349836411015

Epoch: 6| Step: 4
Training loss: 2.5572705268859863
Validation loss: 2.0766759123853458

Epoch: 6| Step: 5
Training loss: 2.387392044067383
Validation loss: 2.077802071007349

Epoch: 6| Step: 6
Training loss: 2.132594108581543
Validation loss: 2.083193517500354

Epoch: 6| Step: 7
Training loss: 2.123725414276123
Validation loss: 2.0852716866359917

Epoch: 6| Step: 8
Training loss: 3.3769474029541016
Validation loss: 2.08851445105768

Epoch: 6| Step: 9
Training loss: 1.3796818256378174
Validation loss: 2.0980673374668246

Epoch: 6| Step: 10
Training loss: 1.7633870840072632
Validation loss: 2.1010044518337456

Epoch: 6| Step: 11
Training loss: 3.1661698818206787
Validation loss: 2.1031394312458653

Epoch: 6| Step: 12
Training loss: 2.255953788757324
Validation loss: 2.0938285127762826

Epoch: 6| Step: 13
Training loss: 2.4500656127929688
Validation loss: 2.0887564177154214

Epoch: 86| Step: 0
Training loss: 2.537729501724243
Validation loss: 2.0867507611551592

Epoch: 6| Step: 1
Training loss: 2.8040127754211426
Validation loss: 2.0926099310639086

Epoch: 6| Step: 2
Training loss: 2.211516857147217
Validation loss: 2.090458736624769

Epoch: 6| Step: 3
Training loss: 2.0370945930480957
Validation loss: 2.0879830878268004

Epoch: 6| Step: 4
Training loss: 2.9364266395568848
Validation loss: 2.085672425967391

Epoch: 6| Step: 5
Training loss: 2.499765157699585
Validation loss: 2.088252698221514

Epoch: 6| Step: 6
Training loss: 2.133782148361206
Validation loss: 2.0808254723907798

Epoch: 6| Step: 7
Training loss: 2.329977512359619
Validation loss: 2.085854968717021

Epoch: 6| Step: 8
Training loss: 1.86125648021698
Validation loss: 2.0991925257508472

Epoch: 6| Step: 9
Training loss: 2.2487072944641113
Validation loss: 2.112423994207895

Epoch: 6| Step: 10
Training loss: 2.572542190551758
Validation loss: 2.1563498384209088

Epoch: 6| Step: 11
Training loss: 3.2167556285858154
Validation loss: 2.159537475596192

Epoch: 6| Step: 12
Training loss: 2.0689737796783447
Validation loss: 2.1341578332326745

Epoch: 6| Step: 13
Training loss: 1.9766483306884766
Validation loss: 2.0962071726399083

Epoch: 87| Step: 0
Training loss: 2.7339401245117188
Validation loss: 2.092874470577445

Epoch: 6| Step: 1
Training loss: 2.5013256072998047
Validation loss: 2.081226735986689

Epoch: 6| Step: 2
Training loss: 2.777193546295166
Validation loss: 2.0808723754780267

Epoch: 6| Step: 3
Training loss: 2.448723793029785
Validation loss: 2.077708628869826

Epoch: 6| Step: 4
Training loss: 2.2403786182403564
Validation loss: 2.078962866977979

Epoch: 6| Step: 5
Training loss: 2.535341739654541
Validation loss: 2.075514547286495

Epoch: 6| Step: 6
Training loss: 1.8905222415924072
Validation loss: 2.0778775625331427

Epoch: 6| Step: 7
Training loss: 1.9791021347045898
Validation loss: 2.087809958765584

Epoch: 6| Step: 8
Training loss: 1.974671721458435
Validation loss: 2.0867692347495788

Epoch: 6| Step: 9
Training loss: 2.405346632003784
Validation loss: 2.076340106225783

Epoch: 6| Step: 10
Training loss: 2.622927665710449
Validation loss: 2.074348583016344

Epoch: 6| Step: 11
Training loss: 2.3109614849090576
Validation loss: 2.0772739456545923

Epoch: 6| Step: 12
Training loss: 1.8836212158203125
Validation loss: 2.0777913626804145

Epoch: 6| Step: 13
Training loss: 3.406017780303955
Validation loss: 2.0917106341290217

Epoch: 88| Step: 0
Training loss: 2.321284294128418
Validation loss: 2.1097628672917685

Epoch: 6| Step: 1
Training loss: 2.1076889038085938
Validation loss: 2.14642091976699

Epoch: 6| Step: 2
Training loss: 2.138866662979126
Validation loss: 2.164826798182662

Epoch: 6| Step: 3
Training loss: 1.9605391025543213
Validation loss: 2.1801052631870395

Epoch: 6| Step: 4
Training loss: 2.171297550201416
Validation loss: 2.179289758846324

Epoch: 6| Step: 5
Training loss: 2.5215282440185547
Validation loss: 2.145188654622724

Epoch: 6| Step: 6
Training loss: 2.1554956436157227
Validation loss: 2.1131158362152758

Epoch: 6| Step: 7
Training loss: 2.8437724113464355
Validation loss: 2.0929484777553107

Epoch: 6| Step: 8
Training loss: 2.6876933574676514
Validation loss: 2.082753268621301

Epoch: 6| Step: 9
Training loss: 3.2173237800598145
Validation loss: 2.0853001020287953

Epoch: 6| Step: 10
Training loss: 2.1762900352478027
Validation loss: 2.0922711382630053

Epoch: 6| Step: 11
Training loss: 1.6641955375671387
Validation loss: 2.0893791234621437

Epoch: 6| Step: 12
Training loss: 3.5976858139038086
Validation loss: 2.0813533900886454

Epoch: 6| Step: 13
Training loss: 1.9042595624923706
Validation loss: 2.0793265809294996

Epoch: 89| Step: 0
Training loss: 1.8277761936187744
Validation loss: 2.0745445246337564

Epoch: 6| Step: 1
Training loss: 2.3648486137390137
Validation loss: 2.078699734903151

Epoch: 6| Step: 2
Training loss: 2.610644578933716
Validation loss: 2.082192487614129

Epoch: 6| Step: 3
Training loss: 2.92250394821167
Validation loss: 2.0906214842232327

Epoch: 6| Step: 4
Training loss: 2.699258327484131
Validation loss: 2.1114632378342333

Epoch: 6| Step: 5
Training loss: 2.319089412689209
Validation loss: 2.1776644145288775

Epoch: 6| Step: 6
Training loss: 2.840991973876953
Validation loss: 2.239227907631987

Epoch: 6| Step: 7
Training loss: 1.7309170961380005
Validation loss: 2.282051255626063

Epoch: 6| Step: 8
Training loss: 3.210287094116211
Validation loss: 2.3274374879816526

Epoch: 6| Step: 9
Training loss: 2.703587770462036
Validation loss: 2.3219456903396116

Epoch: 6| Step: 10
Training loss: 3.076474666595459
Validation loss: 2.3172645004846717

Epoch: 6| Step: 11
Training loss: 2.0222179889678955
Validation loss: 2.305168690220002

Epoch: 6| Step: 12
Training loss: 2.13040828704834
Validation loss: 2.2771172933681036

Epoch: 6| Step: 13
Training loss: 1.9550950527191162
Validation loss: 2.2456215427767847

Epoch: 90| Step: 0
Training loss: 2.71811580657959
Validation loss: 2.192040366511191

Epoch: 6| Step: 1
Training loss: 2.82542085647583
Validation loss: 2.15498701987728

Epoch: 6| Step: 2
Training loss: 2.815573215484619
Validation loss: 2.129960770248085

Epoch: 6| Step: 3
Training loss: 2.557913303375244
Validation loss: 2.1156166753461285

Epoch: 6| Step: 4
Training loss: 2.476250410079956
Validation loss: 2.1110547357989895

Epoch: 6| Step: 5
Training loss: 2.5794527530670166
Validation loss: 2.117423604893428

Epoch: 6| Step: 6
Training loss: 1.8342583179473877
Validation loss: 2.1072488087479786

Epoch: 6| Step: 7
Training loss: 1.8125433921813965
Validation loss: 2.0966630494722756

Epoch: 6| Step: 8
Training loss: 2.2794675827026367
Validation loss: 2.093018090853127

Epoch: 6| Step: 9
Training loss: 2.2841100692749023
Validation loss: 2.0952914030321184

Epoch: 6| Step: 10
Training loss: 2.7293927669525146
Validation loss: 2.1027297537813903

Epoch: 6| Step: 11
Training loss: 2.8367996215820312
Validation loss: 2.1033706126674527

Epoch: 6| Step: 12
Training loss: 1.921737551689148
Validation loss: 2.110609439111525

Epoch: 6| Step: 13
Training loss: 1.5493470430374146
Validation loss: 2.1075896934796403

Epoch: 91| Step: 0
Training loss: 1.6622543334960938
Validation loss: 2.094042785706059

Epoch: 6| Step: 1
Training loss: 1.6045558452606201
Validation loss: 2.0864621388014926

Epoch: 6| Step: 2
Training loss: 2.7262277603149414
Validation loss: 2.083843877238612

Epoch: 6| Step: 3
Training loss: 2.6616272926330566
Validation loss: 2.086861989831412

Epoch: 6| Step: 4
Training loss: 2.6202309131622314
Validation loss: 2.086452834067806

Epoch: 6| Step: 5
Training loss: 1.6530346870422363
Validation loss: 2.0899922283746863

Epoch: 6| Step: 6
Training loss: 2.179597854614258
Validation loss: 2.1108766781386508

Epoch: 6| Step: 7
Training loss: 2.734203815460205
Validation loss: 2.1335680715499388

Epoch: 6| Step: 8
Training loss: 2.8234641551971436
Validation loss: 2.1543217769233127

Epoch: 6| Step: 9
Training loss: 2.542975902557373
Validation loss: 2.1645252781529583

Epoch: 6| Step: 10
Training loss: 2.2657687664031982
Validation loss: 2.1665817896525064

Epoch: 6| Step: 11
Training loss: 2.6501424312591553
Validation loss: 2.155024973295068

Epoch: 6| Step: 12
Training loss: 3.0513620376586914
Validation loss: 2.134055717017061

Epoch: 6| Step: 13
Training loss: 2.3782219886779785
Validation loss: 2.132104399383709

Epoch: 92| Step: 0
Training loss: 2.8480961322784424
Validation loss: 2.12986114973663

Epoch: 6| Step: 1
Training loss: 2.1359100341796875
Validation loss: 2.1201749360689552

Epoch: 6| Step: 2
Training loss: 1.5680303573608398
Validation loss: 2.1083509229844615

Epoch: 6| Step: 3
Training loss: 2.8412389755249023
Validation loss: 2.09505021443931

Epoch: 6| Step: 4
Training loss: 2.5850753784179688
Validation loss: 2.0786349209406043

Epoch: 6| Step: 5
Training loss: 1.7715486288070679
Validation loss: 2.071803794112257

Epoch: 6| Step: 6
Training loss: 2.1970791816711426
Validation loss: 2.070901220844638

Epoch: 6| Step: 7
Training loss: 2.2393414974212646
Validation loss: 2.05088468264508

Epoch: 6| Step: 8
Training loss: 2.0685486793518066
Validation loss: 2.060288712542544

Epoch: 6| Step: 9
Training loss: 3.016995906829834
Validation loss: 2.0594280894084642

Epoch: 6| Step: 10
Training loss: 2.0944159030914307
Validation loss: 2.073905699996538

Epoch: 6| Step: 11
Training loss: 2.5214109420776367
Validation loss: 2.0981800376728015

Epoch: 6| Step: 12
Training loss: 3.0078020095825195
Validation loss: 2.1097628237098776

Epoch: 6| Step: 13
Training loss: 2.705202579498291
Validation loss: 2.117497564643942

Epoch: 93| Step: 0
Training loss: 3.2510266304016113
Validation loss: 2.1013980296350296

Epoch: 6| Step: 1
Training loss: 2.2238216400146484
Validation loss: 2.0923440302571943

Epoch: 6| Step: 2
Training loss: 2.734475612640381
Validation loss: 2.089125984458513

Epoch: 6| Step: 3
Training loss: 2.790658950805664
Validation loss: 2.0686876722561416

Epoch: 6| Step: 4
Training loss: 1.2414718866348267
Validation loss: 2.0600533203412126

Epoch: 6| Step: 5
Training loss: 2.494307279586792
Validation loss: 2.065282875491727

Epoch: 6| Step: 6
Training loss: 2.1131410598754883
Validation loss: 2.068707053379346

Epoch: 6| Step: 7
Training loss: 2.6480259895324707
Validation loss: 2.0757267270036923

Epoch: 6| Step: 8
Training loss: 2.3904170989990234
Validation loss: 2.065047082080636

Epoch: 6| Step: 9
Training loss: 2.081387519836426
Validation loss: 2.058107110761827

Epoch: 6| Step: 10
Training loss: 2.1039071083068848
Validation loss: 2.0520293251160653

Epoch: 6| Step: 11
Training loss: 2.0560617446899414
Validation loss: 2.051668636260494

Epoch: 6| Step: 12
Training loss: 2.7206575870513916
Validation loss: 2.0541718980317474

Epoch: 6| Step: 13
Training loss: 1.924399733543396
Validation loss: 2.0533557361172092

Epoch: 94| Step: 0
Training loss: 2.2898812294006348
Validation loss: 2.049098580114303

Epoch: 6| Step: 1
Training loss: 2.834592819213867
Validation loss: 2.0584889111980313

Epoch: 6| Step: 2
Training loss: 2.7366394996643066
Validation loss: 2.0505228555330666

Epoch: 6| Step: 3
Training loss: 2.7471699714660645
Validation loss: 2.0492639849262853

Epoch: 6| Step: 4
Training loss: 2.744356632232666
Validation loss: 2.066684689573062

Epoch: 6| Step: 5
Training loss: 1.641096591949463
Validation loss: 2.078498342985748

Epoch: 6| Step: 6
Training loss: 2.5913634300231934
Validation loss: 2.083862761015533

Epoch: 6| Step: 7
Training loss: 1.794284701347351
Validation loss: 2.097395820002402

Epoch: 6| Step: 8
Training loss: 2.653963565826416
Validation loss: 2.0828752274154336

Epoch: 6| Step: 9
Training loss: 2.616990327835083
Validation loss: 2.0833995367891047

Epoch: 6| Step: 10
Training loss: 2.2681617736816406
Validation loss: 2.0520604528406614

Epoch: 6| Step: 11
Training loss: 1.7308703660964966
Validation loss: 2.05358725465754

Epoch: 6| Step: 12
Training loss: 2.002211332321167
Validation loss: 2.0586855270529307

Epoch: 6| Step: 13
Training loss: 2.735732078552246
Validation loss: 2.073865036810598

Epoch: 95| Step: 0
Training loss: 2.7351105213165283
Validation loss: 2.084193439893825

Epoch: 6| Step: 1
Training loss: 2.2527589797973633
Validation loss: 2.0822961920051166

Epoch: 6| Step: 2
Training loss: 1.8442977666854858
Validation loss: 2.086481717325026

Epoch: 6| Step: 3
Training loss: 2.210008382797241
Validation loss: 2.07554304727944

Epoch: 6| Step: 4
Training loss: 3.0366406440734863
Validation loss: 2.0575128319442912

Epoch: 6| Step: 5
Training loss: 2.1600186824798584
Validation loss: 2.0495976376277145

Epoch: 6| Step: 6
Training loss: 2.078913688659668
Validation loss: 2.041988453557414

Epoch: 6| Step: 7
Training loss: 2.5198493003845215
Validation loss: 2.0404930255746327

Epoch: 6| Step: 8
Training loss: 1.9840960502624512
Validation loss: 2.0428395079028223

Epoch: 6| Step: 9
Training loss: 2.4436049461364746
Validation loss: 2.0365964879271803

Epoch: 6| Step: 10
Training loss: 2.271989345550537
Validation loss: 2.033508934000487

Epoch: 6| Step: 11
Training loss: 2.8035755157470703
Validation loss: 2.035418806537505

Epoch: 6| Step: 12
Training loss: 2.271569013595581
Validation loss: 2.033119399060485

Epoch: 6| Step: 13
Training loss: 2.2369227409362793
Validation loss: 2.039497948461963

Epoch: 96| Step: 0
Training loss: 1.9632766246795654
Validation loss: 2.0653449796861216

Epoch: 6| Step: 1
Training loss: 2.897420883178711
Validation loss: 2.0641735753705426

Epoch: 6| Step: 2
Training loss: 2.9019432067871094
Validation loss: 2.05789456828948

Epoch: 6| Step: 3
Training loss: 1.455437183380127
Validation loss: 2.0463149573213313

Epoch: 6| Step: 4
Training loss: 2.440033435821533
Validation loss: 2.0378411418648175

Epoch: 6| Step: 5
Training loss: 2.5888659954071045
Validation loss: 2.0380713657666276

Epoch: 6| Step: 6
Training loss: 2.2180964946746826
Validation loss: 2.032221794128418

Epoch: 6| Step: 7
Training loss: 2.8895304203033447
Validation loss: 2.026227499849053

Epoch: 6| Step: 8
Training loss: 2.1079845428466797
Validation loss: 2.0346638848704677

Epoch: 6| Step: 9
Training loss: 2.8011322021484375
Validation loss: 2.034548936351653

Epoch: 6| Step: 10
Training loss: 2.2789642810821533
Validation loss: 2.0415962870403

Epoch: 6| Step: 11
Training loss: 2.575681209564209
Validation loss: 2.0471503298769713

Epoch: 6| Step: 12
Training loss: 1.4942710399627686
Validation loss: 2.0565923234467864

Epoch: 6| Step: 13
Training loss: 1.9890267848968506
Validation loss: 2.067572260415682

Epoch: 97| Step: 0
Training loss: 2.0442051887512207
Validation loss: 2.0705949619252193

Epoch: 6| Step: 1
Training loss: 2.2085468769073486
Validation loss: 2.0635669462142454

Epoch: 6| Step: 2
Training loss: 2.7645225524902344
Validation loss: 2.045974771181742

Epoch: 6| Step: 3
Training loss: 2.578571319580078
Validation loss: 2.0324410392392065

Epoch: 6| Step: 4
Training loss: 1.6231865882873535
Validation loss: 2.0320894513078915

Epoch: 6| Step: 5
Training loss: 2.520052433013916
Validation loss: 2.0283815066019693

Epoch: 6| Step: 6
Training loss: 3.013122797012329
Validation loss: 2.0290399084809008

Epoch: 6| Step: 7
Training loss: 2.575997829437256
Validation loss: 2.0348246482110794

Epoch: 6| Step: 8
Training loss: 2.254587411880493
Validation loss: 2.0307685303431686

Epoch: 6| Step: 9
Training loss: 2.8705575466156006
Validation loss: 2.0252613688027985

Epoch: 6| Step: 10
Training loss: 1.9354735612869263
Validation loss: 2.0389341026224117

Epoch: 6| Step: 11
Training loss: 2.003793478012085
Validation loss: 2.0460506562263734

Epoch: 6| Step: 12
Training loss: 1.7777512073516846
Validation loss: 2.0577210098184566

Epoch: 6| Step: 13
Training loss: 2.3277101516723633
Validation loss: 2.0562013887589976

Epoch: 98| Step: 0
Training loss: 2.1056079864501953
Validation loss: 2.0543470895418556

Epoch: 6| Step: 1
Training loss: 2.320800304412842
Validation loss: 2.0523875426220637

Epoch: 6| Step: 2
Training loss: 2.606593608856201
Validation loss: 2.05007125741692

Epoch: 6| Step: 3
Training loss: 2.1328723430633545
Validation loss: 2.0337961245608587

Epoch: 6| Step: 4
Training loss: 1.5273818969726562
Validation loss: 2.036832171101724

Epoch: 6| Step: 5
Training loss: 2.8414976596832275
Validation loss: 2.043029882574594

Epoch: 6| Step: 6
Training loss: 2.35368013381958
Validation loss: 2.0295585906633766

Epoch: 6| Step: 7
Training loss: 2.2240841388702393
Validation loss: 2.02217262406503

Epoch: 6| Step: 8
Training loss: 2.4735138416290283
Validation loss: 2.026368216801715

Epoch: 6| Step: 9
Training loss: 2.2254562377929688
Validation loss: 2.02247388644885

Epoch: 6| Step: 10
Training loss: 2.10530424118042
Validation loss: 2.025457928257604

Epoch: 6| Step: 11
Training loss: 2.167503833770752
Validation loss: 2.03038130908884

Epoch: 6| Step: 12
Training loss: 2.1327438354492188
Validation loss: 2.0290226462066814

Epoch: 6| Step: 13
Training loss: 3.6363024711608887
Validation loss: 2.0277727406512023

Epoch: 99| Step: 0
Training loss: 2.3275463581085205
Validation loss: 2.0300656569901334

Epoch: 6| Step: 1
Training loss: 2.4147839546203613
Validation loss: 2.0335924369032665

Epoch: 6| Step: 2
Training loss: 2.7408828735351562
Validation loss: 2.029261906941732

Epoch: 6| Step: 3
Training loss: 2.275735855102539
Validation loss: 2.0257219050520208

Epoch: 6| Step: 4
Training loss: 2.7598233222961426
Validation loss: 2.033235619145055

Epoch: 6| Step: 5
Training loss: 2.840989112854004
Validation loss: 2.0318997213917394

Epoch: 6| Step: 6
Training loss: 2.1332972049713135
Validation loss: 2.0296769321605725

Epoch: 6| Step: 7
Training loss: 1.2791783809661865
Validation loss: 2.043131427098346

Epoch: 6| Step: 8
Training loss: 2.122636079788208
Validation loss: 2.0522364493339293

Epoch: 6| Step: 9
Training loss: 2.2968127727508545
Validation loss: 2.0347817790123726

Epoch: 6| Step: 10
Training loss: 2.037825584411621
Validation loss: 2.023921643534014

Epoch: 6| Step: 11
Training loss: 2.5019755363464355
Validation loss: 2.023536289891889

Epoch: 6| Step: 12
Training loss: 2.27308988571167
Validation loss: 2.0257120927174888

Epoch: 6| Step: 13
Training loss: 2.265321969985962
Validation loss: 2.019198392027168

Epoch: 100| Step: 0
Training loss: 2.134936571121216
Validation loss: 2.0264846894048874

Epoch: 6| Step: 1
Training loss: 2.412903308868408
Validation loss: 2.035461575754227

Epoch: 6| Step: 2
Training loss: 2.368056535720825
Validation loss: 2.043146465414314

Epoch: 6| Step: 3
Training loss: 2.2015485763549805
Validation loss: 2.05880767555647

Epoch: 6| Step: 4
Training loss: 2.115495443344116
Validation loss: 2.0735007973127466

Epoch: 6| Step: 5
Training loss: 2.2468535900115967
Validation loss: 2.0586001898652766

Epoch: 6| Step: 6
Training loss: 2.831594467163086
Validation loss: 2.0433905150300715

Epoch: 6| Step: 7
Training loss: 2.2683868408203125
Validation loss: 2.0365382330391997

Epoch: 6| Step: 8
Training loss: 2.6236414909362793
Validation loss: 2.0317636779559556

Epoch: 6| Step: 9
Training loss: 2.095545768737793
Validation loss: 2.025477824672576

Epoch: 6| Step: 10
Training loss: 2.359182834625244
Validation loss: 2.024874379557948

Epoch: 6| Step: 11
Training loss: 2.385286331176758
Validation loss: 2.026911615043558

Epoch: 6| Step: 12
Training loss: 2.358943462371826
Validation loss: 2.031446067235803

Epoch: 6| Step: 13
Training loss: 1.605997920036316
Validation loss: 2.0196899957554315

Epoch: 101| Step: 0
Training loss: 1.8449090719223022
Validation loss: 2.029036457820605

Epoch: 6| Step: 1
Training loss: 2.364633560180664
Validation loss: 2.0408062319601736

Epoch: 6| Step: 2
Training loss: 2.816626787185669
Validation loss: 2.0599539600392824

Epoch: 6| Step: 3
Training loss: 2.4350194931030273
Validation loss: 2.0820357517529557

Epoch: 6| Step: 4
Training loss: 2.6838483810424805
Validation loss: 2.078842257940641

Epoch: 6| Step: 5
Training loss: 1.8968921899795532
Validation loss: 2.0775618040433494

Epoch: 6| Step: 6
Training loss: 3.1598477363586426
Validation loss: 2.0560784224540956

Epoch: 6| Step: 7
Training loss: 2.266645908355713
Validation loss: 2.0270767288823284

Epoch: 6| Step: 8
Training loss: 1.8183693885803223
Validation loss: 2.015866069383519

Epoch: 6| Step: 9
Training loss: 1.9911565780639648
Validation loss: 2.0105570183005383

Epoch: 6| Step: 10
Training loss: 1.6404542922973633
Validation loss: 2.011831728360986

Epoch: 6| Step: 11
Training loss: 2.7529120445251465
Validation loss: 2.0112294920029177

Epoch: 6| Step: 12
Training loss: 2.535456657409668
Validation loss: 2.012154702217348

Epoch: 6| Step: 13
Training loss: 2.3128724098205566
Validation loss: 2.002815595237158

Epoch: 102| Step: 0
Training loss: 2.255868673324585
Validation loss: 1.999095493747342

Epoch: 6| Step: 1
Training loss: 2.775442600250244
Validation loss: 2.0025053678020353

Epoch: 6| Step: 2
Training loss: 2.5474181175231934
Validation loss: 2.017301074920162

Epoch: 6| Step: 3
Training loss: 2.553101062774658
Validation loss: 2.049867399277226

Epoch: 6| Step: 4
Training loss: 2.467942476272583
Validation loss: 2.0746843737940632

Epoch: 6| Step: 5
Training loss: 2.599883794784546
Validation loss: 2.065947971036357

Epoch: 6| Step: 6
Training loss: 2.298558235168457
Validation loss: 2.025973839144553

Epoch: 6| Step: 7
Training loss: 1.9972288608551025
Validation loss: 2.013920710932824

Epoch: 6| Step: 8
Training loss: 2.1067190170288086
Validation loss: 1.993414459689971

Epoch: 6| Step: 9
Training loss: 2.4089064598083496
Validation loss: 1.9978778580183625

Epoch: 6| Step: 10
Training loss: 1.7607181072235107
Validation loss: 1.9964106621280793

Epoch: 6| Step: 11
Training loss: 2.272540807723999
Validation loss: 2.0001881584044425

Epoch: 6| Step: 12
Training loss: 2.0833911895751953
Validation loss: 2.0040589212089457

Epoch: 6| Step: 13
Training loss: 2.6145710945129395
Validation loss: 2.0053669637249363

Epoch: 103| Step: 0
Training loss: 1.8672930002212524
Validation loss: 2.010230798875132

Epoch: 6| Step: 1
Training loss: 3.2643232345581055
Validation loss: 2.0072051081606137

Epoch: 6| Step: 2
Training loss: 2.047032356262207
Validation loss: 2.0245379017245386

Epoch: 6| Step: 3
Training loss: 2.289428949356079
Validation loss: 2.02898044355454

Epoch: 6| Step: 4
Training loss: 1.3688230514526367
Validation loss: 2.034470409475347

Epoch: 6| Step: 5
Training loss: 2.884826898574829
Validation loss: 2.052000111149203

Epoch: 6| Step: 6
Training loss: 2.782869815826416
Validation loss: 2.0696872139489777

Epoch: 6| Step: 7
Training loss: 2.7142820358276367
Validation loss: 2.0581873616864605

Epoch: 6| Step: 8
Training loss: 2.093552827835083
Validation loss: 2.072534438102476

Epoch: 6| Step: 9
Training loss: 1.876629114151001
Validation loss: 2.0311068616887575

Epoch: 6| Step: 10
Training loss: 2.5085630416870117
Validation loss: 2.0100038423333118

Epoch: 6| Step: 11
Training loss: 1.494135856628418
Validation loss: 2.001482008605875

Epoch: 6| Step: 12
Training loss: 2.1203579902648926
Validation loss: 1.9887500168174825

Epoch: 6| Step: 13
Training loss: 3.434021472930908
Validation loss: 1.9909381328090545

Epoch: 104| Step: 0
Training loss: 2.309429168701172
Validation loss: 1.9883986416683401

Epoch: 6| Step: 1
Training loss: 2.4681947231292725
Validation loss: 1.9934635367444766

Epoch: 6| Step: 2
Training loss: 2.5893750190734863
Validation loss: 1.9944218807323004

Epoch: 6| Step: 3
Training loss: 1.8999220132827759
Validation loss: 1.99316878216241

Epoch: 6| Step: 4
Training loss: 1.7373648881912231
Validation loss: 1.9986973360020628

Epoch: 6| Step: 5
Training loss: 1.7971336841583252
Validation loss: 1.9950984267778293

Epoch: 6| Step: 6
Training loss: 2.5831480026245117
Validation loss: 2.02429074241269

Epoch: 6| Step: 7
Training loss: 2.0979766845703125
Validation loss: 2.087622009297853

Epoch: 6| Step: 8
Training loss: 2.5245509147644043
Validation loss: 2.1391987210960797

Epoch: 6| Step: 9
Training loss: 2.6781134605407715
Validation loss: 2.18771102095163

Epoch: 6| Step: 10
Training loss: 2.9886388778686523
Validation loss: 2.1960837610306276

Epoch: 6| Step: 11
Training loss: 2.7298099994659424
Validation loss: 2.170726077530974

Epoch: 6| Step: 12
Training loss: 2.3152339458465576
Validation loss: 2.0934987221994708

Epoch: 6| Step: 13
Training loss: 2.3235952854156494
Validation loss: 2.0345598395152757

Epoch: 105| Step: 0
Training loss: 2.380012273788452
Validation loss: 2.0063395474546697

Epoch: 6| Step: 1
Training loss: 2.8668925762176514
Validation loss: 2.0071580820186163

Epoch: 6| Step: 2
Training loss: 1.9073193073272705
Validation loss: 2.0151239261832288

Epoch: 6| Step: 3
Training loss: 2.1991617679595947
Validation loss: 2.030474883253856

Epoch: 6| Step: 4
Training loss: 2.2827062606811523
Validation loss: 2.041894184645786

Epoch: 6| Step: 5
Training loss: 2.9150149822235107
Validation loss: 2.039828379948934

Epoch: 6| Step: 6
Training loss: 2.507479667663574
Validation loss: 2.0495157600730978

Epoch: 6| Step: 7
Training loss: 2.248645782470703
Validation loss: 2.0543396780567784

Epoch: 6| Step: 8
Training loss: 2.2525997161865234
Validation loss: 2.0566772799338064

Epoch: 6| Step: 9
Training loss: 2.2496235370635986
Validation loss: 2.0659988336665656

Epoch: 6| Step: 10
Training loss: 2.5984418392181396
Validation loss: 2.0573194398674914

Epoch: 6| Step: 11
Training loss: 2.419332265853882
Validation loss: 2.04167761341218

Epoch: 6| Step: 12
Training loss: 2.237090587615967
Validation loss: 2.0285740039681874

Epoch: 6| Step: 13
Training loss: 2.49686336517334
Validation loss: 2.0373911703786542

Epoch: 106| Step: 0
Training loss: 2.4734416007995605
Validation loss: 2.0164040121980893

Epoch: 6| Step: 1
Training loss: 2.5526373386383057
Validation loss: 2.032210218009128

Epoch: 6| Step: 2
Training loss: 2.185171365737915
Validation loss: 2.0886807851893927

Epoch: 6| Step: 3
Training loss: 2.2159981727600098
Validation loss: 2.1315064148236345

Epoch: 6| Step: 4
Training loss: 1.899500846862793
Validation loss: 2.1602066973204255

Epoch: 6| Step: 5
Training loss: 2.1830360889434814
Validation loss: 2.1764033738002984

Epoch: 6| Step: 6
Training loss: 2.074986457824707
Validation loss: 2.1558410057457547

Epoch: 6| Step: 7
Training loss: 2.2251968383789062
Validation loss: 2.1506933127680132

Epoch: 6| Step: 8
Training loss: 2.668668746948242
Validation loss: 2.1305629553333407

Epoch: 6| Step: 9
Training loss: 2.416431427001953
Validation loss: 2.08686549304634

Epoch: 6| Step: 10
Training loss: 1.4316904544830322
Validation loss: 2.049412804265176

Epoch: 6| Step: 11
Training loss: 2.4105215072631836
Validation loss: 2.014298713335427

Epoch: 6| Step: 12
Training loss: 3.212520122528076
Validation loss: 1.991836881124845

Epoch: 6| Step: 13
Training loss: 3.1490426063537598
Validation loss: 1.9883787875534387

Epoch: 107| Step: 0
Training loss: 2.9020235538482666
Validation loss: 1.9990934184802476

Epoch: 6| Step: 1
Training loss: 2.5483174324035645
Validation loss: 2.006809006455124

Epoch: 6| Step: 2
Training loss: 2.2070369720458984
Validation loss: 2.0095885851049937

Epoch: 6| Step: 3
Training loss: 1.9742459058761597
Validation loss: 1.9975648823604788

Epoch: 6| Step: 4
Training loss: 1.8722350597381592
Validation loss: 1.994818215729088

Epoch: 6| Step: 5
Training loss: 3.053647041320801
Validation loss: 1.9921369796158166

Epoch: 6| Step: 6
Training loss: 2.3501882553100586
Validation loss: 1.9781065115364649

Epoch: 6| Step: 7
Training loss: 2.51552152633667
Validation loss: 1.9792118636510705

Epoch: 6| Step: 8
Training loss: 2.1623454093933105
Validation loss: 1.9889154690568165

Epoch: 6| Step: 9
Training loss: 2.4340696334838867
Validation loss: 2.0268106486207698

Epoch: 6| Step: 10
Training loss: 2.2660903930664062
Validation loss: 2.0405500524787494

Epoch: 6| Step: 11
Training loss: 1.8826076984405518
Validation loss: 2.0314129526897142

Epoch: 6| Step: 12
Training loss: 2.1152522563934326
Validation loss: 2.0245225275716474

Epoch: 6| Step: 13
Training loss: 2.0950355529785156
Validation loss: 2.0216742305345434

Epoch: 108| Step: 0
Training loss: 2.353137254714966
Validation loss: 2.0234422017169256

Epoch: 6| Step: 1
Training loss: 1.8712855577468872
Validation loss: 2.0226354368271364

Epoch: 6| Step: 2
Training loss: 2.113523483276367
Validation loss: 2.013976861071843

Epoch: 6| Step: 3
Training loss: 2.329709768295288
Validation loss: 2.012301580880278

Epoch: 6| Step: 4
Training loss: 1.9634748697280884
Validation loss: 2.0140601204287623

Epoch: 6| Step: 5
Training loss: 2.479274272918701
Validation loss: 2.003053003741849

Epoch: 6| Step: 6
Training loss: 1.564430594444275
Validation loss: 2.009768163004229

Epoch: 6| Step: 7
Training loss: 1.9091434478759766
Validation loss: 2.011060045611474

Epoch: 6| Step: 8
Training loss: 1.9249786138534546
Validation loss: 2.0104197609809136

Epoch: 6| Step: 9
Training loss: 3.3450305461883545
Validation loss: 2.0057070665462042

Epoch: 6| Step: 10
Training loss: 2.5915608406066895
Validation loss: 2.0072201477584017

Epoch: 6| Step: 11
Training loss: 1.9373093843460083
Validation loss: 1.9942702170341247

Epoch: 6| Step: 12
Training loss: 2.4575650691986084
Validation loss: 1.9853930575873262

Epoch: 6| Step: 13
Training loss: 3.134005069732666
Validation loss: 1.9856358266645862

Epoch: 109| Step: 0
Training loss: 3.141834259033203
Validation loss: 1.9836477105335524

Epoch: 6| Step: 1
Training loss: 1.6198060512542725
Validation loss: 1.9857488703984085

Epoch: 6| Step: 2
Training loss: 2.1921119689941406
Validation loss: 1.9841098247035858

Epoch: 6| Step: 3
Training loss: 2.511040210723877
Validation loss: 1.9933720327192737

Epoch: 6| Step: 4
Training loss: 1.9018356800079346
Validation loss: 2.0093071576087707

Epoch: 6| Step: 5
Training loss: 2.284147262573242
Validation loss: 1.9939214926893993

Epoch: 6| Step: 6
Training loss: 2.825961112976074
Validation loss: 1.978673691390663

Epoch: 6| Step: 7
Training loss: 2.4908950328826904
Validation loss: 1.9791676177773425

Epoch: 6| Step: 8
Training loss: 2.756486654281616
Validation loss: 1.9987695806769914

Epoch: 6| Step: 9
Training loss: 1.9432399272918701
Validation loss: 2.020174595617479

Epoch: 6| Step: 10
Training loss: 2.0553817749023438
Validation loss: 2.0232612779063563

Epoch: 6| Step: 11
Training loss: 1.8131859302520752
Validation loss: 2.030764297772479

Epoch: 6| Step: 12
Training loss: 2.4906165599823
Validation loss: 2.013440897387843

Epoch: 6| Step: 13
Training loss: 3.093165874481201
Validation loss: 2.0019579805353636

Epoch: 110| Step: 0
Training loss: 2.638272762298584
Validation loss: 2.0007844381434943

Epoch: 6| Step: 1
Training loss: 2.3041601181030273
Validation loss: 1.9914896962463216

Epoch: 6| Step: 2
Training loss: 2.4760937690734863
Validation loss: 1.9731799043634886

Epoch: 6| Step: 3
Training loss: 2.524867296218872
Validation loss: 1.9674936109973538

Epoch: 6| Step: 4
Training loss: 2.1548266410827637
Validation loss: 1.954975124328367

Epoch: 6| Step: 5
Training loss: 2.5309557914733887
Validation loss: 1.9579154752915906

Epoch: 6| Step: 6
Training loss: 2.115119457244873
Validation loss: 1.950830663404157

Epoch: 6| Step: 7
Training loss: 1.5128626823425293
Validation loss: 1.9546701446656258

Epoch: 6| Step: 8
Training loss: 2.190695285797119
Validation loss: 1.9642090412878221

Epoch: 6| Step: 9
Training loss: 1.6247552633285522
Validation loss: 1.961115957588278

Epoch: 6| Step: 10
Training loss: 2.344407558441162
Validation loss: 1.9683528254109044

Epoch: 6| Step: 11
Training loss: 2.084632635116577
Validation loss: 1.9843730259967107

Epoch: 6| Step: 12
Training loss: 2.550762176513672
Validation loss: 2.01961802282641

Epoch: 6| Step: 13
Training loss: 2.7658872604370117
Validation loss: 2.0522188755773727

Epoch: 111| Step: 0
Training loss: 2.7545838356018066
Validation loss: 2.0831769089544974

Epoch: 6| Step: 1
Training loss: 2.214452028274536
Validation loss: 2.1372094987541117

Epoch: 6| Step: 2
Training loss: 2.4673635959625244
Validation loss: 2.1488422937290643

Epoch: 6| Step: 3
Training loss: 2.604951858520508
Validation loss: 2.1660394284033004

Epoch: 6| Step: 4
Training loss: 2.0589096546173096
Validation loss: 2.1867697623468216

Epoch: 6| Step: 5
Training loss: 2.4163076877593994
Validation loss: 2.141373643311121

Epoch: 6| Step: 6
Training loss: 2.1551313400268555
Validation loss: 2.1086827401191957

Epoch: 6| Step: 7
Training loss: 1.8060660362243652
Validation loss: 2.0840906327770603

Epoch: 6| Step: 8
Training loss: 2.322138547897339
Validation loss: 2.0190084954743743

Epoch: 6| Step: 9
Training loss: 1.8535449504852295
Validation loss: 1.980068201659828

Epoch: 6| Step: 10
Training loss: 2.6184091567993164
Validation loss: 1.9726924627057967

Epoch: 6| Step: 11
Training loss: 2.654696464538574
Validation loss: 1.9547199933759627

Epoch: 6| Step: 12
Training loss: 1.9564018249511719
Validation loss: 1.9597350064144339

Epoch: 6| Step: 13
Training loss: 3.266550064086914
Validation loss: 1.9553040535219255

Epoch: 112| Step: 0
Training loss: 1.677122712135315
Validation loss: 1.9694253244707662

Epoch: 6| Step: 1
Training loss: 2.2017576694488525
Validation loss: 1.9856016789713213

Epoch: 6| Step: 2
Training loss: 2.6192214488983154
Validation loss: 1.9915213264444822

Epoch: 6| Step: 3
Training loss: 2.124955654144287
Validation loss: 1.990390883978977

Epoch: 6| Step: 4
Training loss: 2.109347343444824
Validation loss: 2.0086324984027493

Epoch: 6| Step: 5
Training loss: 1.9814765453338623
Validation loss: 2.0312113441446775

Epoch: 6| Step: 6
Training loss: 2.051048755645752
Validation loss: 2.048213545994092

Epoch: 6| Step: 7
Training loss: 3.023629665374756
Validation loss: 2.058834816819878

Epoch: 6| Step: 8
Training loss: 2.2071337699890137
Validation loss: 2.070244360995549

Epoch: 6| Step: 9
Training loss: 2.89617919921875
Validation loss: 2.056144304172967

Epoch: 6| Step: 10
Training loss: 2.7766473293304443
Validation loss: 2.039251039105077

Epoch: 6| Step: 11
Training loss: 2.3290419578552246
Validation loss: 2.013645020864343

Epoch: 6| Step: 12
Training loss: 1.811711311340332
Validation loss: 1.9998044916378555

Epoch: 6| Step: 13
Training loss: 2.8379204273223877
Validation loss: 1.9985574663326304

Epoch: 113| Step: 0
Training loss: 2.600526809692383
Validation loss: 1.994959262109572

Epoch: 6| Step: 1
Training loss: 1.6519848108291626
Validation loss: 1.991611292285304

Epoch: 6| Step: 2
Training loss: 3.2510323524475098
Validation loss: 1.997442505692923

Epoch: 6| Step: 3
Training loss: 2.2568306922912598
Validation loss: 1.9948822746994674

Epoch: 6| Step: 4
Training loss: 1.7693769931793213
Validation loss: 1.986364895297635

Epoch: 6| Step: 5
Training loss: 2.14298677444458
Validation loss: 1.9856692129565823

Epoch: 6| Step: 6
Training loss: 2.210282564163208
Validation loss: 1.992548599038073

Epoch: 6| Step: 7
Training loss: 2.2580318450927734
Validation loss: 2.0091007268556984

Epoch: 6| Step: 8
Training loss: 2.1977651119232178
Validation loss: 2.0192116409219723

Epoch: 6| Step: 9
Training loss: 2.43125581741333
Validation loss: 2.0318055178529475

Epoch: 6| Step: 10
Training loss: 2.3966307640075684
Validation loss: 2.0197845428220687

Epoch: 6| Step: 11
Training loss: 2.5845344066619873
Validation loss: 2.0079311504158923

Epoch: 6| Step: 12
Training loss: 1.580823302268982
Validation loss: 1.992616795724438

Epoch: 6| Step: 13
Training loss: 3.086509943008423
Validation loss: 1.9819868367205384

Epoch: 114| Step: 0
Training loss: 2.26823353767395
Validation loss: 1.9877334051234747

Epoch: 6| Step: 1
Training loss: 2.1664609909057617
Validation loss: 1.983726752701626

Epoch: 6| Step: 2
Training loss: 2.1441609859466553
Validation loss: 1.9807756229113507

Epoch: 6| Step: 3
Training loss: 1.334789752960205
Validation loss: 1.9804834614517868

Epoch: 6| Step: 4
Training loss: 3.3865280151367188
Validation loss: 1.9875604183443132

Epoch: 6| Step: 5
Training loss: 2.28151273727417
Validation loss: 1.983544998271491

Epoch: 6| Step: 6
Training loss: 2.6345295906066895
Validation loss: 1.990655033819137

Epoch: 6| Step: 7
Training loss: 1.963866114616394
Validation loss: 1.9909586444977792

Epoch: 6| Step: 8
Training loss: 2.131934642791748
Validation loss: 1.9989647019294001

Epoch: 6| Step: 9
Training loss: 2.415874481201172
Validation loss: 2.0051407532025407

Epoch: 6| Step: 10
Training loss: 1.9098587036132812
Validation loss: 2.01096430132466

Epoch: 6| Step: 11
Training loss: 2.283369541168213
Validation loss: 2.006212742097916

Epoch: 6| Step: 12
Training loss: 2.1503634452819824
Validation loss: 2.018057850099379

Epoch: 6| Step: 13
Training loss: 3.097412347793579
Validation loss: 2.0325783375770814

Epoch: 115| Step: 0
Training loss: 1.887505292892456
Validation loss: 2.0159246460083993

Epoch: 6| Step: 1
Training loss: 2.671320915222168
Validation loss: 2.008787589688455

Epoch: 6| Step: 2
Training loss: 1.8701820373535156
Validation loss: 1.9944073794990458

Epoch: 6| Step: 3
Training loss: 2.4800102710723877
Validation loss: 1.9802658609164658

Epoch: 6| Step: 4
Training loss: 2.182070255279541
Validation loss: 1.9716435376033987

Epoch: 6| Step: 5
Training loss: 2.607881546020508
Validation loss: 1.955776273563344

Epoch: 6| Step: 6
Training loss: 1.9417564868927002
Validation loss: 1.9494411176250828

Epoch: 6| Step: 7
Training loss: 1.9407511949539185
Validation loss: 1.9453711689159434

Epoch: 6| Step: 8
Training loss: 2.9642319679260254
Validation loss: 1.9475145186147382

Epoch: 6| Step: 9
Training loss: 2.1520326137542725
Validation loss: 1.9475611179105696

Epoch: 6| Step: 10
Training loss: 2.012028694152832
Validation loss: 1.9548922046538322

Epoch: 6| Step: 11
Training loss: 2.1763694286346436
Validation loss: 1.9573334160671438

Epoch: 6| Step: 12
Training loss: 2.1901192665100098
Validation loss: 1.9570323600563952

Epoch: 6| Step: 13
Training loss: 2.1705822944641113
Validation loss: 1.9664295745152298

Epoch: 116| Step: 0
Training loss: 2.3040976524353027
Validation loss: 1.9782278230113368

Epoch: 6| Step: 1
Training loss: 2.196665048599243
Validation loss: 1.9749192755709413

Epoch: 6| Step: 2
Training loss: 2.2145862579345703
Validation loss: 1.964878423239595

Epoch: 6| Step: 3
Training loss: 1.9219470024108887
Validation loss: 1.9626349736285467

Epoch: 6| Step: 4
Training loss: 1.8672752380371094
Validation loss: 1.9615723471487723

Epoch: 6| Step: 5
Training loss: 2.3652195930480957
Validation loss: 1.9682699172727522

Epoch: 6| Step: 6
Training loss: 2.063497543334961
Validation loss: 1.980159692866828

Epoch: 6| Step: 7
Training loss: 2.7770509719848633
Validation loss: 1.978304455357213

Epoch: 6| Step: 8
Training loss: 2.1302881240844727
Validation loss: 1.9833653614085207

Epoch: 6| Step: 9
Training loss: 1.4528343677520752
Validation loss: 1.9574479928580664

Epoch: 6| Step: 10
Training loss: 2.180391311645508
Validation loss: 1.9513893204350625

Epoch: 6| Step: 11
Training loss: 2.581728935241699
Validation loss: 1.9454454157942085

Epoch: 6| Step: 12
Training loss: 3.3539605140686035
Validation loss: 1.9543578804180186

Epoch: 6| Step: 13
Training loss: 1.8229857683181763
Validation loss: 1.9630989848926503

Epoch: 117| Step: 0
Training loss: 2.1487555503845215
Validation loss: 1.9662728386540567

Epoch: 6| Step: 1
Training loss: 2.9601173400878906
Validation loss: 1.9586193074462235

Epoch: 6| Step: 2
Training loss: 2.3762259483337402
Validation loss: 1.9493627099580662

Epoch: 6| Step: 3
Training loss: 2.4591565132141113
Validation loss: 1.9547884874446417

Epoch: 6| Step: 4
Training loss: 1.6847248077392578
Validation loss: 1.9546338204414613

Epoch: 6| Step: 5
Training loss: 2.3202452659606934
Validation loss: 1.9587298080485354

Epoch: 6| Step: 6
Training loss: 1.1749191284179688
Validation loss: 1.9877063074419576

Epoch: 6| Step: 7
Training loss: 2.5298383235931396
Validation loss: 1.99911545425333

Epoch: 6| Step: 8
Training loss: 2.293738842010498
Validation loss: 1.9906532123524656

Epoch: 6| Step: 9
Training loss: 2.4848742485046387
Validation loss: 1.9764431702193392

Epoch: 6| Step: 10
Training loss: 2.4102821350097656
Validation loss: 1.959290309618878

Epoch: 6| Step: 11
Training loss: 2.2531585693359375
Validation loss: 1.9531679602079495

Epoch: 6| Step: 12
Training loss: 2.556680679321289
Validation loss: 1.9446709912310365

Epoch: 6| Step: 13
Training loss: 1.679189920425415
Validation loss: 1.9479911891363

Epoch: 118| Step: 0
Training loss: 2.7261617183685303
Validation loss: 1.9441641722956011

Epoch: 6| Step: 1
Training loss: 2.688373327255249
Validation loss: 1.9399713098361928

Epoch: 6| Step: 2
Training loss: 2.4664535522460938
Validation loss: 1.9534781735430482

Epoch: 6| Step: 3
Training loss: 1.5408923625946045
Validation loss: 1.9658738746437976

Epoch: 6| Step: 4
Training loss: 2.4095683097839355
Validation loss: 1.9666717437005812

Epoch: 6| Step: 5
Training loss: 2.3951892852783203
Validation loss: 1.969889945240431

Epoch: 6| Step: 6
Training loss: 1.8210899829864502
Validation loss: 1.9619650533122401

Epoch: 6| Step: 7
Training loss: 2.0878217220306396
Validation loss: 1.9699638799954486

Epoch: 6| Step: 8
Training loss: 2.3616247177124023
Validation loss: 1.9713487804576915

Epoch: 6| Step: 9
Training loss: 1.848429560661316
Validation loss: 1.966883336344073

Epoch: 6| Step: 10
Training loss: 2.200902223587036
Validation loss: 1.9591466175612582

Epoch: 6| Step: 11
Training loss: 1.3242931365966797
Validation loss: 1.9581462824216453

Epoch: 6| Step: 12
Training loss: 2.407667636871338
Validation loss: 1.9551331304734754

Epoch: 6| Step: 13
Training loss: 3.127243757247925
Validation loss: 1.951046428372783

Epoch: 119| Step: 0
Training loss: 2.4417357444763184
Validation loss: 1.9546788046436925

Epoch: 6| Step: 1
Training loss: 1.8929145336151123
Validation loss: 1.952852705473541

Epoch: 6| Step: 2
Training loss: 2.313168525695801
Validation loss: 1.9542501793112805

Epoch: 6| Step: 3
Training loss: 1.766838788986206
Validation loss: 1.9421899087967411

Epoch: 6| Step: 4
Training loss: 2.353572130203247
Validation loss: 1.9467545145301408

Epoch: 6| Step: 5
Training loss: 3.1138157844543457
Validation loss: 1.9435861418324132

Epoch: 6| Step: 6
Training loss: 2.550710678100586
Validation loss: 1.946270542760049

Epoch: 6| Step: 7
Training loss: 2.3059401512145996
Validation loss: 1.9439006479837562

Epoch: 6| Step: 8
Training loss: 1.862355351448059
Validation loss: 1.9423853581951511

Epoch: 6| Step: 9
Training loss: 1.683674693107605
Validation loss: 1.9488728841145833

Epoch: 6| Step: 10
Training loss: 2.3721346855163574
Validation loss: 1.9475169130550918

Epoch: 6| Step: 11
Training loss: 1.9961076974868774
Validation loss: 1.9472605169460337

Epoch: 6| Step: 12
Training loss: 2.092261791229248
Validation loss: 1.9434677529078659

Epoch: 6| Step: 13
Training loss: 1.7891902923583984
Validation loss: 1.9440192830178045

Epoch: 120| Step: 0
Training loss: 2.7024917602539062
Validation loss: 1.9358966376191826

Epoch: 6| Step: 1
Training loss: 2.094860076904297
Validation loss: 1.942298589214202

Epoch: 6| Step: 2
Training loss: 1.9992048740386963
Validation loss: 1.9415417563530706

Epoch: 6| Step: 3
Training loss: 2.724108934402466
Validation loss: 1.9335189737299436

Epoch: 6| Step: 4
Training loss: 1.775937557220459
Validation loss: 1.9452206152741627

Epoch: 6| Step: 5
Training loss: 2.0187039375305176
Validation loss: 1.9476309937815512

Epoch: 6| Step: 6
Training loss: 2.013550281524658
Validation loss: 1.963907616112822

Epoch: 6| Step: 7
Training loss: 2.4847354888916016
Validation loss: 1.9633805162163191

Epoch: 6| Step: 8
Training loss: 2.207821846008301
Validation loss: 1.9655520172529324

Epoch: 6| Step: 9
Training loss: 1.9395049810409546
Validation loss: 1.9442208851537397

Epoch: 6| Step: 10
Training loss: 2.2082173824310303
Validation loss: 1.943346631142401

Epoch: 6| Step: 11
Training loss: 1.987877607345581
Validation loss: 1.9489422998120707

Epoch: 6| Step: 12
Training loss: 2.316943407058716
Validation loss: 1.950215385806176

Epoch: 6| Step: 13
Training loss: 2.5009446144104004
Validation loss: 1.947770336622833

Epoch: 121| Step: 0
Training loss: 2.712210178375244
Validation loss: 1.948941776829381

Epoch: 6| Step: 1
Training loss: 2.2711141109466553
Validation loss: 1.9482065285405805

Epoch: 6| Step: 2
Training loss: 2.4017746448516846
Validation loss: 1.9342784074044996

Epoch: 6| Step: 3
Training loss: 2.1962099075317383
Validation loss: 1.92814423448296

Epoch: 6| Step: 4
Training loss: 1.7753403186798096
Validation loss: 1.960298156225553

Epoch: 6| Step: 5
Training loss: 2.5625860691070557
Validation loss: 2.0126248303280083

Epoch: 6| Step: 6
Training loss: 2.2120447158813477
Validation loss: 2.0306598127529187

Epoch: 6| Step: 7
Training loss: 3.252070903778076
Validation loss: 2.059926889275992

Epoch: 6| Step: 8
Training loss: 1.6187962293624878
Validation loss: 2.0616774071929274

Epoch: 6| Step: 9
Training loss: 2.16878080368042
Validation loss: 2.0568727716322868

Epoch: 6| Step: 10
Training loss: 2.390976667404175
Validation loss: 2.033509668483529

Epoch: 6| Step: 11
Training loss: 2.844309091567993
Validation loss: 2.0061019402678295

Epoch: 6| Step: 12
Training loss: 1.537354826927185
Validation loss: 1.969897908549155

Epoch: 6| Step: 13
Training loss: 1.6354432106018066
Validation loss: 1.948826002818282

Epoch: 122| Step: 0
Training loss: 2.239872694015503
Validation loss: 1.9450215780606834

Epoch: 6| Step: 1
Training loss: 2.1437036991119385
Validation loss: 1.9438840445651804

Epoch: 6| Step: 2
Training loss: 2.1135759353637695
Validation loss: 1.947589506385147

Epoch: 6| Step: 3
Training loss: 2.351055860519409
Validation loss: 1.9424137774334158

Epoch: 6| Step: 4
Training loss: 2.000843048095703
Validation loss: 1.9349472061280282

Epoch: 6| Step: 5
Training loss: 2.235485076904297
Validation loss: 1.9233161813469344

Epoch: 6| Step: 6
Training loss: 2.281113624572754
Validation loss: 1.9120280704190653

Epoch: 6| Step: 7
Training loss: 2.1026036739349365
Validation loss: 1.9085399822522235

Epoch: 6| Step: 8
Training loss: 1.864238977432251
Validation loss: 1.9066098325995988

Epoch: 6| Step: 9
Training loss: 2.420163154602051
Validation loss: 1.9332879563813568

Epoch: 6| Step: 10
Training loss: 2.167771577835083
Validation loss: 1.9607606318689161

Epoch: 6| Step: 11
Training loss: 2.459531784057617
Validation loss: 1.9609235076494114

Epoch: 6| Step: 12
Training loss: 2.0588455200195312
Validation loss: 1.947173995356406

Epoch: 6| Step: 13
Training loss: 2.5414037704467773
Validation loss: 1.941964808330741

Epoch: 123| Step: 0
Training loss: 2.0909342765808105
Validation loss: 1.9238014323737032

Epoch: 6| Step: 1
Training loss: 2.5148491859436035
Validation loss: 1.8997491123855754

Epoch: 6| Step: 2
Training loss: 1.6994755268096924
Validation loss: 1.9097375023749568

Epoch: 6| Step: 3
Training loss: 1.8780323266983032
Validation loss: 1.9177450826091151

Epoch: 6| Step: 4
Training loss: 2.3707785606384277
Validation loss: 1.9220611664556688

Epoch: 6| Step: 5
Training loss: 2.3480682373046875
Validation loss: 1.9112430567382483

Epoch: 6| Step: 6
Training loss: 2.064711809158325
Validation loss: 1.917359059856784

Epoch: 6| Step: 7
Training loss: 1.518543004989624
Validation loss: 1.909578610492009

Epoch: 6| Step: 8
Training loss: 2.8057894706726074
Validation loss: 1.8968471916772986

Epoch: 6| Step: 9
Training loss: 2.633284568786621
Validation loss: 1.9056397080421448

Epoch: 6| Step: 10
Training loss: 2.0891308784484863
Validation loss: 1.916931370253204

Epoch: 6| Step: 11
Training loss: 2.1424508094787598
Validation loss: 1.936419225508167

Epoch: 6| Step: 12
Training loss: 2.998319149017334
Validation loss: 1.9377894042640604

Epoch: 6| Step: 13
Training loss: 1.565132737159729
Validation loss: 1.9385661822493359

Epoch: 124| Step: 0
Training loss: 1.5647838115692139
Validation loss: 1.9359573010475404

Epoch: 6| Step: 1
Training loss: 1.8540817499160767
Validation loss: 1.9387695135608796

Epoch: 6| Step: 2
Training loss: 1.555849552154541
Validation loss: 1.9425893663078226

Epoch: 6| Step: 3
Training loss: 1.5542316436767578
Validation loss: 1.9302960647049772

Epoch: 6| Step: 4
Training loss: 2.910770893096924
Validation loss: 1.9227955443884737

Epoch: 6| Step: 5
Training loss: 2.480407238006592
Validation loss: 1.9079435422856321

Epoch: 6| Step: 6
Training loss: 2.539660692214966
Validation loss: 1.9013882144804923

Epoch: 6| Step: 7
Training loss: 2.3722424507141113
Validation loss: 1.900860140400548

Epoch: 6| Step: 8
Training loss: 2.3533830642700195
Validation loss: 1.9020866065896966

Epoch: 6| Step: 9
Training loss: 2.3022565841674805
Validation loss: 1.9121235096326439

Epoch: 6| Step: 10
Training loss: 2.2466506958007812
Validation loss: 1.9088885630330732

Epoch: 6| Step: 11
Training loss: 1.771485447883606
Validation loss: 1.9204570170371764

Epoch: 6| Step: 12
Training loss: 2.499509334564209
Validation loss: 1.9154378470554148

Epoch: 6| Step: 13
Training loss: 2.6508190631866455
Validation loss: 1.9181159016906575

Epoch: 125| Step: 0
Training loss: 2.6244750022888184
Validation loss: 1.9228220562781058

Epoch: 6| Step: 1
Training loss: 2.2453742027282715
Validation loss: 1.921065644551349

Epoch: 6| Step: 2
Training loss: 2.7654669284820557
Validation loss: 1.9317679405212402

Epoch: 6| Step: 3
Training loss: 2.4398698806762695
Validation loss: 1.9307713508605957

Epoch: 6| Step: 4
Training loss: 2.162991762161255
Validation loss: 1.912504332039946

Epoch: 6| Step: 5
Training loss: 2.01896071434021
Validation loss: 1.9114398059024607

Epoch: 6| Step: 6
Training loss: 2.9777748584747314
Validation loss: 1.9205803717336347

Epoch: 6| Step: 7
Training loss: 2.094465970993042
Validation loss: 1.9173991487872215

Epoch: 6| Step: 8
Training loss: 1.6963386535644531
Validation loss: 1.9195730147823211

Epoch: 6| Step: 9
Training loss: 1.209389567375183
Validation loss: 1.9170180700158561

Epoch: 6| Step: 10
Training loss: 1.9062957763671875
Validation loss: 1.9093005708468858

Epoch: 6| Step: 11
Training loss: 1.8943912982940674
Validation loss: 1.9138202410872265

Epoch: 6| Step: 12
Training loss: 2.3436100482940674
Validation loss: 1.9254437646558207

Epoch: 6| Step: 13
Training loss: 1.9364969730377197
Validation loss: 1.9258103768030803

Epoch: 126| Step: 0
Training loss: 1.394418716430664
Validation loss: 1.9499792181035525

Epoch: 6| Step: 1
Training loss: 2.541323184967041
Validation loss: 1.9516334918237501

Epoch: 6| Step: 2
Training loss: 2.230109930038452
Validation loss: 1.9255000852769422

Epoch: 6| Step: 3
Training loss: 2.1090896129608154
Validation loss: 1.9086166927891393

Epoch: 6| Step: 4
Training loss: 2.462613582611084
Validation loss: 1.90721389555162

Epoch: 6| Step: 5
Training loss: 2.4302685260772705
Validation loss: 1.908380998078213

Epoch: 6| Step: 6
Training loss: 2.4371337890625
Validation loss: 1.9091694380647393

Epoch: 6| Step: 7
Training loss: 1.230844497680664
Validation loss: 1.9022099638497958

Epoch: 6| Step: 8
Training loss: 2.23580265045166
Validation loss: 1.9055735962365263

Epoch: 6| Step: 9
Training loss: 2.569733142852783
Validation loss: 1.9091271508124568

Epoch: 6| Step: 10
Training loss: 2.1175010204315186
Validation loss: 1.9066237800864763

Epoch: 6| Step: 11
Training loss: 2.1382884979248047
Validation loss: 1.910226386080506

Epoch: 6| Step: 12
Training loss: 2.102541446685791
Validation loss: 1.9046973079763434

Epoch: 6| Step: 13
Training loss: 1.8296400308609009
Validation loss: 1.9070345842710106

Epoch: 127| Step: 0
Training loss: 2.586564540863037
Validation loss: 1.8971712537991103

Epoch: 6| Step: 1
Training loss: 2.438511371612549
Validation loss: 1.8936360100264191

Epoch: 6| Step: 2
Training loss: 1.9113401174545288
Validation loss: 1.8907777301726802

Epoch: 6| Step: 3
Training loss: 1.5290188789367676
Validation loss: 1.8937348909275507

Epoch: 6| Step: 4
Training loss: 1.7394977807998657
Validation loss: 1.8834238090822775

Epoch: 6| Step: 5
Training loss: 1.8339812755584717
Validation loss: 1.8959010993280718

Epoch: 6| Step: 6
Training loss: 2.0018792152404785
Validation loss: 1.904043641141666

Epoch: 6| Step: 7
Training loss: 2.289930820465088
Validation loss: 1.9105645700167584

Epoch: 6| Step: 8
Training loss: 2.525668144226074
Validation loss: 1.9081917193628126

Epoch: 6| Step: 9
Training loss: 2.295764923095703
Validation loss: 1.9145653760561379

Epoch: 6| Step: 10
Training loss: 2.2605488300323486
Validation loss: 1.922693112845062

Epoch: 6| Step: 11
Training loss: 1.9176113605499268
Validation loss: 1.9226181340473953

Epoch: 6| Step: 12
Training loss: 1.9416126012802124
Validation loss: 1.9203416557722195

Epoch: 6| Step: 13
Training loss: 2.9942028522491455
Validation loss: 1.9152465430639123

Epoch: 128| Step: 0
Training loss: 2.118527412414551
Validation loss: 1.9129097077154344

Epoch: 6| Step: 1
Training loss: 1.7162096500396729
Validation loss: 1.9084486294818181

Epoch: 6| Step: 2
Training loss: 2.2611124515533447
Validation loss: 1.9152518485182075

Epoch: 6| Step: 3
Training loss: 2.4543886184692383
Validation loss: 1.9137908579200826

Epoch: 6| Step: 4
Training loss: 2.33632230758667
Validation loss: 1.9094130262251823

Epoch: 6| Step: 5
Training loss: 2.1968576908111572
Validation loss: 1.9080667880273634

Epoch: 6| Step: 6
Training loss: 1.9447916746139526
Validation loss: 1.9049410409824823

Epoch: 6| Step: 7
Training loss: 2.003955841064453
Validation loss: 1.9235679872574345

Epoch: 6| Step: 8
Training loss: 1.5827302932739258
Validation loss: 1.92072557890287

Epoch: 6| Step: 9
Training loss: 2.403607130050659
Validation loss: 1.9292631533838087

Epoch: 6| Step: 10
Training loss: 2.5897481441497803
Validation loss: 1.9285665135229788

Epoch: 6| Step: 11
Training loss: 2.530486583709717
Validation loss: 1.9175826503384499

Epoch: 6| Step: 12
Training loss: 1.6637930870056152
Validation loss: 1.9104524235571585

Epoch: 6| Step: 13
Training loss: 2.0006442070007324
Validation loss: 1.9084291778584963

Epoch: 129| Step: 0
Training loss: 1.7741045951843262
Validation loss: 1.9498812306311823

Epoch: 6| Step: 1
Training loss: 2.253753185272217
Validation loss: 1.9872140358853083

Epoch: 6| Step: 2
Training loss: 1.898628830909729
Validation loss: 2.036364096467213

Epoch: 6| Step: 3
Training loss: 1.6454418897628784
Validation loss: 2.041719344354445

Epoch: 6| Step: 4
Training loss: 3.2782130241394043
Validation loss: 2.0418540764880437

Epoch: 6| Step: 5
Training loss: 0.8703708648681641
Validation loss: 2.016888442859855

Epoch: 6| Step: 6
Training loss: 2.2060651779174805
Validation loss: 1.9847621456269295

Epoch: 6| Step: 7
Training loss: 2.641267776489258
Validation loss: 1.9451403207676385

Epoch: 6| Step: 8
Training loss: 3.129929542541504
Validation loss: 1.9325843793089672

Epoch: 6| Step: 9
Training loss: 2.1561667919158936
Validation loss: 1.9208600508269442

Epoch: 6| Step: 10
Training loss: 2.3877108097076416
Validation loss: 1.9123908640235983

Epoch: 6| Step: 11
Training loss: 1.9708476066589355
Validation loss: 1.9076173433693506

Epoch: 6| Step: 12
Training loss: 2.4224109649658203
Validation loss: 1.9134566681359404

Epoch: 6| Step: 13
Training loss: 1.5857003927230835
Validation loss: 1.8985517947904524

Epoch: 130| Step: 0
Training loss: 2.145676851272583
Validation loss: 1.8790879134208924

Epoch: 6| Step: 1
Training loss: 2.3483996391296387
Validation loss: 1.9129564428842196

Epoch: 6| Step: 2
Training loss: 2.4881324768066406
Validation loss: 1.9473750334914013

Epoch: 6| Step: 3
Training loss: 2.1593620777130127
Validation loss: 1.9522923218306674

Epoch: 6| Step: 4
Training loss: 2.8211941719055176
Validation loss: 1.9603421764989053

Epoch: 6| Step: 5
Training loss: 2.2862296104431152
Validation loss: 1.9397089788990636

Epoch: 6| Step: 6
Training loss: 2.1959874629974365
Validation loss: 1.9140450710891395

Epoch: 6| Step: 7
Training loss: 1.9612246751785278
Validation loss: 1.9072656554560508

Epoch: 6| Step: 8
Training loss: 1.7886219024658203
Validation loss: 1.903040668015839

Epoch: 6| Step: 9
Training loss: 2.0816612243652344
Validation loss: 1.905978472002091

Epoch: 6| Step: 10
Training loss: 1.7924940586090088
Validation loss: 1.9148217542197115

Epoch: 6| Step: 11
Training loss: 2.2081141471862793
Validation loss: 1.9219753408944735

Epoch: 6| Step: 12
Training loss: 1.7708897590637207
Validation loss: 1.9232151200694423

Epoch: 6| Step: 13
Training loss: 1.8992173671722412
Validation loss: 1.923472168625042

Epoch: 131| Step: 0
Training loss: 1.846332311630249
Validation loss: 1.934069272010557

Epoch: 6| Step: 1
Training loss: 1.8073899745941162
Validation loss: 1.9338497038810485

Epoch: 6| Step: 2
Training loss: 2.7247369289398193
Validation loss: 1.9437395065061507

Epoch: 6| Step: 3
Training loss: 1.8058762550354004
Validation loss: 1.92543787212782

Epoch: 6| Step: 4
Training loss: 1.871433138847351
Validation loss: 1.9151137849336028

Epoch: 6| Step: 5
Training loss: 2.180131435394287
Validation loss: 1.921149779391545

Epoch: 6| Step: 6
Training loss: 1.9716575145721436
Validation loss: 1.9254223838929208

Epoch: 6| Step: 7
Training loss: 2.6394057273864746
Validation loss: 1.916169035819269

Epoch: 6| Step: 8
Training loss: 1.720688819885254
Validation loss: 1.9191081190621981

Epoch: 6| Step: 9
Training loss: 2.547006607055664
Validation loss: 1.9105280214740383

Epoch: 6| Step: 10
Training loss: 2.1129374504089355
Validation loss: 1.9232358676131054

Epoch: 6| Step: 11
Training loss: 1.6062953472137451
Validation loss: 1.9186560646180184

Epoch: 6| Step: 12
Training loss: 2.670161247253418
Validation loss: 1.9231162955684047

Epoch: 6| Step: 13
Training loss: 1.8785864114761353
Validation loss: 1.9131275633329987

Epoch: 132| Step: 0
Training loss: 2.020549774169922
Validation loss: 1.919516489069949

Epoch: 6| Step: 1
Training loss: 2.022904396057129
Validation loss: 1.9195042810132426

Epoch: 6| Step: 2
Training loss: 1.4667139053344727
Validation loss: 1.9197157967475154

Epoch: 6| Step: 3
Training loss: 1.9985957145690918
Validation loss: 1.90960548129133

Epoch: 6| Step: 4
Training loss: 1.788703441619873
Validation loss: 1.9043084857284382

Epoch: 6| Step: 5
Training loss: 1.9195805788040161
Validation loss: 1.9121795854260843

Epoch: 6| Step: 6
Training loss: 2.5756938457489014
Validation loss: 1.9128257728392077

Epoch: 6| Step: 7
Training loss: 2.5545878410339355
Validation loss: 1.913777111678995

Epoch: 6| Step: 8
Training loss: 2.5295372009277344
Validation loss: 1.9101298701378606

Epoch: 6| Step: 9
Training loss: 1.6835107803344727
Validation loss: 1.906551036783444

Epoch: 6| Step: 10
Training loss: 2.139686107635498
Validation loss: 1.8992458453742407

Epoch: 6| Step: 11
Training loss: 2.4820938110351562
Validation loss: 1.9166666692303074

Epoch: 6| Step: 12
Training loss: 1.640750527381897
Validation loss: 1.915534395043568

Epoch: 6| Step: 13
Training loss: 2.976027011871338
Validation loss: 1.9044197502956595

Epoch: 133| Step: 0
Training loss: 2.9874229431152344
Validation loss: 1.9071798016948085

Epoch: 6| Step: 1
Training loss: 1.7357800006866455
Validation loss: 1.8997287878426172

Epoch: 6| Step: 2
Training loss: 2.3092474937438965
Validation loss: 1.9060620825777772

Epoch: 6| Step: 3
Training loss: 1.9517674446105957
Validation loss: 1.9056499696546985

Epoch: 6| Step: 4
Training loss: 2.596841335296631
Validation loss: 1.91054198562458

Epoch: 6| Step: 5
Training loss: 2.5446999073028564
Validation loss: 1.9077180098461848

Epoch: 6| Step: 6
Training loss: 1.2809991836547852
Validation loss: 1.9088545371127386

Epoch: 6| Step: 7
Training loss: 1.4570949077606201
Validation loss: 1.9289144598027712

Epoch: 6| Step: 8
Training loss: 2.6386187076568604
Validation loss: 1.9463783874306628

Epoch: 6| Step: 9
Training loss: 2.055452823638916
Validation loss: 1.9656242004004858

Epoch: 6| Step: 10
Training loss: 2.7326018810272217
Validation loss: 1.9672196706136067

Epoch: 6| Step: 11
Training loss: 1.5897977352142334
Validation loss: 1.9570050867654945

Epoch: 6| Step: 12
Training loss: 1.5662318468093872
Validation loss: 1.9348276507469915

Epoch: 6| Step: 13
Training loss: 2.0387730598449707
Validation loss: 1.917631854293167

Epoch: 134| Step: 0
Training loss: 1.9084734916687012
Validation loss: 1.9009315313831452

Epoch: 6| Step: 1
Training loss: 2.4959800243377686
Validation loss: 1.910560909137931

Epoch: 6| Step: 2
Training loss: 1.7481296062469482
Validation loss: 1.90185893735578

Epoch: 6| Step: 3
Training loss: 2.0038111209869385
Validation loss: 1.896379106788225

Epoch: 6| Step: 4
Training loss: 2.790832757949829
Validation loss: 1.889275461114863

Epoch: 6| Step: 5
Training loss: 2.113976240158081
Validation loss: 1.887694299861949

Epoch: 6| Step: 6
Training loss: 2.134849786758423
Validation loss: 1.8981530948351788

Epoch: 6| Step: 7
Training loss: 1.6213963031768799
Validation loss: 1.9174293766739547

Epoch: 6| Step: 8
Training loss: 1.8141050338745117
Validation loss: 1.9161697997841785

Epoch: 6| Step: 9
Training loss: 1.7802324295043945
Validation loss: 1.9429003064350416

Epoch: 6| Step: 10
Training loss: 2.6120595932006836
Validation loss: 1.9481451434473838

Epoch: 6| Step: 11
Training loss: 2.370462417602539
Validation loss: 1.928416794346225

Epoch: 6| Step: 12
Training loss: 1.6425142288208008
Validation loss: 1.899202141710507

Epoch: 6| Step: 13
Training loss: 2.386570692062378
Validation loss: 1.881704920081682

Epoch: 135| Step: 0
Training loss: 2.4117846488952637
Validation loss: 1.8786921449886855

Epoch: 6| Step: 1
Training loss: 1.889779806137085
Validation loss: 1.8840908055664392

Epoch: 6| Step: 2
Training loss: 2.7622647285461426
Validation loss: 1.8835550098009006

Epoch: 6| Step: 3
Training loss: 1.3871268033981323
Validation loss: 1.889185869565574

Epoch: 6| Step: 4
Training loss: 1.5296388864517212
Validation loss: 1.873189777456304

Epoch: 6| Step: 5
Training loss: 1.9554529190063477
Validation loss: 1.8852894767638175

Epoch: 6| Step: 6
Training loss: 2.0745644569396973
Validation loss: 1.8801890034829416

Epoch: 6| Step: 7
Training loss: 2.362509250640869
Validation loss: 1.8928036356485018

Epoch: 6| Step: 8
Training loss: 2.5303430557250977
Validation loss: 1.8962516182212419

Epoch: 6| Step: 9
Training loss: 1.7821018695831299
Validation loss: 1.8876002104051652

Epoch: 6| Step: 10
Training loss: 2.621424674987793
Validation loss: 1.8826638357613676

Epoch: 6| Step: 11
Training loss: 2.304776668548584
Validation loss: 1.87688482833165

Epoch: 6| Step: 12
Training loss: 1.3317581415176392
Validation loss: 1.8836912506370134

Epoch: 6| Step: 13
Training loss: 2.1487627029418945
Validation loss: 1.8768487502169866

Epoch: 136| Step: 0
Training loss: 2.0499558448791504
Validation loss: 1.8844692501970517

Epoch: 6| Step: 1
Training loss: 2.234653949737549
Validation loss: 1.883797102077033

Epoch: 6| Step: 2
Training loss: 1.606597900390625
Validation loss: 1.8986408043933172

Epoch: 6| Step: 3
Training loss: 2.140836238861084
Validation loss: 1.884044481861976

Epoch: 6| Step: 4
Training loss: 1.9104739427566528
Validation loss: 1.8942453566417898

Epoch: 6| Step: 5
Training loss: 1.983591079711914
Validation loss: 1.8682823463152813

Epoch: 6| Step: 6
Training loss: 2.031198024749756
Validation loss: 1.858556746154703

Epoch: 6| Step: 7
Training loss: 1.9912538528442383
Validation loss: 1.8697109735140236

Epoch: 6| Step: 8
Training loss: 2.705460548400879
Validation loss: 1.8748420771732126

Epoch: 6| Step: 9
Training loss: 1.9525662660598755
Validation loss: 1.878382896864286

Epoch: 6| Step: 10
Training loss: 2.0361578464508057
Validation loss: 1.8834830381536996

Epoch: 6| Step: 11
Training loss: 1.7454559803009033
Validation loss: 1.892353880789972

Epoch: 6| Step: 12
Training loss: 1.4834833145141602
Validation loss: 1.8904774983723958

Epoch: 6| Step: 13
Training loss: 3.599914073944092
Validation loss: 1.887594465286501

Epoch: 137| Step: 0
Training loss: 1.665809154510498
Validation loss: 1.8743048226961525

Epoch: 6| Step: 1
Training loss: 2.618175506591797
Validation loss: 1.874106035437635

Epoch: 6| Step: 2
Training loss: 1.961082100868225
Validation loss: 1.8725419877677836

Epoch: 6| Step: 3
Training loss: 1.642815351486206
Validation loss: 1.873495101928711

Epoch: 6| Step: 4
Training loss: 1.9727282524108887
Validation loss: 1.8798483648607809

Epoch: 6| Step: 5
Training loss: 2.5545270442962646
Validation loss: 1.8767119274344495

Epoch: 6| Step: 6
Training loss: 1.821070909500122
Validation loss: 1.8775937006037722

Epoch: 6| Step: 7
Training loss: 2.265089511871338
Validation loss: 1.8608813644737325

Epoch: 6| Step: 8
Training loss: 2.7388041019439697
Validation loss: 1.867643984415198

Epoch: 6| Step: 9
Training loss: 2.405613899230957
Validation loss: 1.8677331760365476

Epoch: 6| Step: 10
Training loss: 1.5934900045394897
Validation loss: 1.858184814453125

Epoch: 6| Step: 11
Training loss: 1.8903815746307373
Validation loss: 1.8643594608511975

Epoch: 6| Step: 12
Training loss: 1.7576062679290771
Validation loss: 1.8629275278378559

Epoch: 6| Step: 13
Training loss: 1.4167914390563965
Validation loss: 1.8589928124540596

Epoch: 138| Step: 0
Training loss: 2.3073840141296387
Validation loss: 1.857045022390222

Epoch: 6| Step: 1
Training loss: 2.702601432800293
Validation loss: 1.8603253620927052

Epoch: 6| Step: 2
Training loss: 2.4663772583007812
Validation loss: 1.876085336490344

Epoch: 6| Step: 3
Training loss: 1.7327078580856323
Validation loss: 1.8642719637963079

Epoch: 6| Step: 4
Training loss: 2.47076153755188
Validation loss: 1.8640473081219582

Epoch: 6| Step: 5
Training loss: 2.57804012298584
Validation loss: 1.8599652192925895

Epoch: 6| Step: 6
Training loss: 1.3753710985183716
Validation loss: 1.8620610762667913

Epoch: 6| Step: 7
Training loss: 1.9775108098983765
Validation loss: 1.855150717560963

Epoch: 6| Step: 8
Training loss: 1.879542350769043
Validation loss: 1.8612565532807381

Epoch: 6| Step: 9
Training loss: 1.4696264266967773
Validation loss: 1.8714292075044365

Epoch: 6| Step: 10
Training loss: 1.7432972192764282
Validation loss: 1.8769078844337053

Epoch: 6| Step: 11
Training loss: 1.4963619709014893
Validation loss: 1.872409128373669

Epoch: 6| Step: 12
Training loss: 2.160734176635742
Validation loss: 1.879016104564872

Epoch: 6| Step: 13
Training loss: 2.1726980209350586
Validation loss: 1.9328872516591062

Epoch: 139| Step: 0
Training loss: 1.6626168489456177
Validation loss: 2.017293195570669

Epoch: 6| Step: 1
Training loss: 2.5382235050201416
Validation loss: 2.0292810599009194

Epoch: 6| Step: 2
Training loss: 2.7407891750335693
Validation loss: 2.0162150859832764

Epoch: 6| Step: 3
Training loss: 1.7994468212127686
Validation loss: 1.938773811504405

Epoch: 6| Step: 4
Training loss: 1.6683084964752197
Validation loss: 1.871839225933116

Epoch: 6| Step: 5
Training loss: 1.8534293174743652
Validation loss: 1.8520938273399108

Epoch: 6| Step: 6
Training loss: 1.7884489297866821
Validation loss: 1.8380759069996495

Epoch: 6| Step: 7
Training loss: 2.353804111480713
Validation loss: 1.8583352206855692

Epoch: 6| Step: 8
Training loss: 2.559950828552246
Validation loss: 1.8770497460519113

Epoch: 6| Step: 9
Training loss: 2.0238022804260254
Validation loss: 1.8912364334188483

Epoch: 6| Step: 10
Training loss: 2.3747830390930176
Validation loss: 1.888756021376579

Epoch: 6| Step: 11
Training loss: 1.9705227613449097
Validation loss: 1.8761852172113234

Epoch: 6| Step: 12
Training loss: 2.6230521202087402
Validation loss: 1.8630598360492336

Epoch: 6| Step: 13
Training loss: 1.90038001537323
Validation loss: 1.8584100405375164

Epoch: 140| Step: 0
Training loss: 2.451016426086426
Validation loss: 1.875296005638697

Epoch: 6| Step: 1
Training loss: 2.4936423301696777
Validation loss: 1.9034615998627038

Epoch: 6| Step: 2
Training loss: 2.191643714904785
Validation loss: 1.9329561571921072

Epoch: 6| Step: 3
Training loss: 2.3002824783325195
Validation loss: 1.9182843931259648

Epoch: 6| Step: 4
Training loss: 2.44407057762146
Validation loss: 1.9108472613878147

Epoch: 6| Step: 5
Training loss: 1.6739232540130615
Validation loss: 1.914624289799762

Epoch: 6| Step: 6
Training loss: 1.462266206741333
Validation loss: 1.8956897412576983

Epoch: 6| Step: 7
Training loss: 1.680912733078003
Validation loss: 1.8715108889405445

Epoch: 6| Step: 8
Training loss: 1.8105218410491943
Validation loss: 1.8707698288784231

Epoch: 6| Step: 9
Training loss: 2.443225860595703
Validation loss: 1.8681032375622821

Epoch: 6| Step: 10
Training loss: 1.6994367837905884
Validation loss: 1.8684237426327122

Epoch: 6| Step: 11
Training loss: 2.1025218963623047
Validation loss: 1.8610749462599396

Epoch: 6| Step: 12
Training loss: 2.289642095565796
Validation loss: 1.8650832791482248

Epoch: 6| Step: 13
Training loss: 1.152596354484558
Validation loss: 1.861818798126713

Epoch: 141| Step: 0
Training loss: 2.1008028984069824
Validation loss: 1.8510635822050032

Epoch: 6| Step: 1
Training loss: 2.4290168285369873
Validation loss: 1.8565332325555945

Epoch: 6| Step: 2
Training loss: 1.9990390539169312
Validation loss: 1.8813883950633388

Epoch: 6| Step: 3
Training loss: 2.415572166442871
Validation loss: 1.8912859962832542

Epoch: 6| Step: 4
Training loss: 1.9125878810882568
Validation loss: 1.901312098708204

Epoch: 6| Step: 5
Training loss: 1.3963401317596436
Validation loss: 1.871053231659756

Epoch: 6| Step: 6
Training loss: 2.9818954467773438
Validation loss: 1.8603291255171581

Epoch: 6| Step: 7
Training loss: 2.3575048446655273
Validation loss: 1.8749181557727117

Epoch: 6| Step: 8
Training loss: 2.1205673217773438
Validation loss: 1.9235684743491552

Epoch: 6| Step: 9
Training loss: 1.6093215942382812
Validation loss: 1.9756580552747172

Epoch: 6| Step: 10
Training loss: 2.201517105102539
Validation loss: 2.0302032629648843

Epoch: 6| Step: 11
Training loss: 2.0809478759765625
Validation loss: 2.050593165941136

Epoch: 6| Step: 12
Training loss: 1.4146673679351807
Validation loss: 2.069388536996739

Epoch: 6| Step: 13
Training loss: 2.199950695037842
Validation loss: 2.010282540834078

Epoch: 142| Step: 0
Training loss: 2.6904258728027344
Validation loss: 1.966268124118928

Epoch: 6| Step: 1
Training loss: 2.7172369956970215
Validation loss: 1.9191689862999866

Epoch: 6| Step: 2
Training loss: 1.9936118125915527
Validation loss: 1.9058703927583591

Epoch: 6| Step: 3
Training loss: 2.6321072578430176
Validation loss: 1.899541829221992

Epoch: 6| Step: 4
Training loss: 1.780918836593628
Validation loss: 1.8922424508679299

Epoch: 6| Step: 5
Training loss: 2.272021770477295
Validation loss: 1.890560075800906

Epoch: 6| Step: 6
Training loss: 1.5999674797058105
Validation loss: 1.888277353778962

Epoch: 6| Step: 7
Training loss: 1.6890366077423096
Validation loss: 1.883651005324497

Epoch: 6| Step: 8
Training loss: 1.9706995487213135
Validation loss: 1.8742168231676983

Epoch: 6| Step: 9
Training loss: 1.6009678840637207
Validation loss: 1.8679602479421964

Epoch: 6| Step: 10
Training loss: 2.4175102710723877
Validation loss: 1.8896190107509654

Epoch: 6| Step: 11
Training loss: 1.7175179719924927
Validation loss: 1.883638652422095

Epoch: 6| Step: 12
Training loss: 1.521113634109497
Validation loss: 1.8806845911087529

Epoch: 6| Step: 13
Training loss: 1.8082948923110962
Validation loss: 1.8687437080567884

Epoch: 143| Step: 0
Training loss: 1.9125245809555054
Validation loss: 1.8683057215905958

Epoch: 6| Step: 1
Training loss: 1.869513988494873
Validation loss: 1.8751049195566485

Epoch: 6| Step: 2
Training loss: 2.502730131149292
Validation loss: 1.870787315471198

Epoch: 6| Step: 3
Training loss: 1.248528242111206
Validation loss: 1.8611846085517638

Epoch: 6| Step: 4
Training loss: 1.1928389072418213
Validation loss: 1.8741274264550978

Epoch: 6| Step: 5
Training loss: 2.0919461250305176
Validation loss: 1.8732205283257268

Epoch: 6| Step: 6
Training loss: 1.294815182685852
Validation loss: 1.8720584736075452

Epoch: 6| Step: 7
Training loss: 2.1382741928100586
Validation loss: 1.8609989496969408

Epoch: 6| Step: 8
Training loss: 2.5011067390441895
Validation loss: 1.8744024999680058

Epoch: 6| Step: 9
Training loss: 2.431610107421875
Validation loss: 1.8791350959449686

Epoch: 6| Step: 10
Training loss: 2.1567084789276123
Validation loss: 1.8730324147849955

Epoch: 6| Step: 11
Training loss: 2.6109747886657715
Validation loss: 1.8691285694799116

Epoch: 6| Step: 12
Training loss: 2.0595712661743164
Validation loss: 1.868595327100446

Epoch: 6| Step: 13
Training loss: 2.453416347503662
Validation loss: 1.8762017949934928

Epoch: 144| Step: 0
Training loss: 2.2131011486053467
Validation loss: 1.8797028398001066

Epoch: 6| Step: 1
Training loss: 2.3894662857055664
Validation loss: 1.874462298167649

Epoch: 6| Step: 2
Training loss: 1.397183895111084
Validation loss: 1.8688462921368179

Epoch: 6| Step: 3
Training loss: 1.9681419134140015
Validation loss: 1.8884236402409051

Epoch: 6| Step: 4
Training loss: 1.5833014249801636
Validation loss: 1.8936181734966975

Epoch: 6| Step: 5
Training loss: 2.4318878650665283
Validation loss: 1.914602360417766

Epoch: 6| Step: 6
Training loss: 1.883062481880188
Validation loss: 1.915934011500369

Epoch: 6| Step: 7
Training loss: 1.7743031978607178
Validation loss: 1.8979957808730423

Epoch: 6| Step: 8
Training loss: 2.4663076400756836
Validation loss: 1.8611599168469828

Epoch: 6| Step: 9
Training loss: 1.9696613550186157
Validation loss: 1.8554564842613794

Epoch: 6| Step: 10
Training loss: 2.7504148483276367
Validation loss: 1.8557747628099175

Epoch: 6| Step: 11
Training loss: 1.5891532897949219
Validation loss: 1.8740889821001279

Epoch: 6| Step: 12
Training loss: 1.9061341285705566
Validation loss: 1.8810452056187454

Epoch: 6| Step: 13
Training loss: 2.0793490409851074
Validation loss: 1.885897039085306

Epoch: 145| Step: 0
Training loss: 2.3771462440490723
Validation loss: 1.8764980172598233

Epoch: 6| Step: 1
Training loss: 2.5018858909606934
Validation loss: 1.8768595521168043

Epoch: 6| Step: 2
Training loss: 2.0303895473480225
Validation loss: 1.881433940702869

Epoch: 6| Step: 3
Training loss: 2.1987452507019043
Validation loss: 1.8778446002673077

Epoch: 6| Step: 4
Training loss: 2.0890800952911377
Validation loss: 1.8607584276506979

Epoch: 6| Step: 5
Training loss: 1.6931567192077637
Validation loss: 1.8678696181184502

Epoch: 6| Step: 6
Training loss: 1.2680399417877197
Validation loss: 1.8657887725419895

Epoch: 6| Step: 7
Training loss: 1.586350679397583
Validation loss: 1.8706987775782102

Epoch: 6| Step: 8
Training loss: 2.707705020904541
Validation loss: 1.8665354251861572

Epoch: 6| Step: 9
Training loss: 1.9347045421600342
Validation loss: 1.8685514337273055

Epoch: 6| Step: 10
Training loss: 1.5740976333618164
Validation loss: 1.8566243815165695

Epoch: 6| Step: 11
Training loss: 1.8200517892837524
Validation loss: 1.8556260114075036

Epoch: 6| Step: 12
Training loss: 2.381603240966797
Validation loss: 1.8721147967923073

Epoch: 6| Step: 13
Training loss: 1.9087204933166504
Validation loss: 1.8710434462434502

Epoch: 146| Step: 0
Training loss: 1.8423516750335693
Validation loss: 1.883468766366282

Epoch: 6| Step: 1
Training loss: 3.3696300983428955
Validation loss: 1.884970244540963

Epoch: 6| Step: 2
Training loss: 1.595508098602295
Validation loss: 1.88370507378732

Epoch: 6| Step: 3
Training loss: 2.2121496200561523
Validation loss: 1.938364339131181

Epoch: 6| Step: 4
Training loss: 2.335730791091919
Validation loss: 1.9654434983448317

Epoch: 6| Step: 5
Training loss: 2.218496084213257
Validation loss: 1.9555261494011007

Epoch: 6| Step: 6
Training loss: 2.669198989868164
Validation loss: 1.925293678878456

Epoch: 6| Step: 7
Training loss: 2.105938673019409
Validation loss: 1.9020602664639872

Epoch: 6| Step: 8
Training loss: 1.4803909063339233
Validation loss: 1.874938746934296

Epoch: 6| Step: 9
Training loss: 1.1227248907089233
Validation loss: 1.8683862045247068

Epoch: 6| Step: 10
Training loss: 2.110090970993042
Validation loss: 1.8702562111680225

Epoch: 6| Step: 11
Training loss: 2.1135995388031006
Validation loss: 1.8780908405139882

Epoch: 6| Step: 12
Training loss: 1.7118756771087646
Validation loss: 1.8879253915561143

Epoch: 6| Step: 13
Training loss: 1.211654543876648
Validation loss: 1.889994079066861

Epoch: 147| Step: 0
Training loss: 2.181087017059326
Validation loss: 1.8734924895789034

Epoch: 6| Step: 1
Training loss: 2.1104822158813477
Validation loss: 1.867780690552086

Epoch: 6| Step: 2
Training loss: 1.8675451278686523
Validation loss: 1.8592442671457927

Epoch: 6| Step: 3
Training loss: 1.6943620443344116
Validation loss: 1.8494253594388244

Epoch: 6| Step: 4
Training loss: 2.014066457748413
Validation loss: 1.8506573861645115

Epoch: 6| Step: 5
Training loss: 2.641963243484497
Validation loss: 1.843214475980369

Epoch: 6| Step: 6
Training loss: 2.6733763217926025
Validation loss: 1.832867194247502

Epoch: 6| Step: 7
Training loss: 2.9188232421875
Validation loss: 1.8388301698110436

Epoch: 6| Step: 8
Training loss: 1.2629404067993164
Validation loss: 1.856262210876711

Epoch: 6| Step: 9
Training loss: 1.653364896774292
Validation loss: 1.8932487310901764

Epoch: 6| Step: 10
Training loss: 2.30723237991333
Validation loss: 1.9176080226898193

Epoch: 6| Step: 11
Training loss: 1.9652416706085205
Validation loss: 1.932494483968263

Epoch: 6| Step: 12
Training loss: 1.303647756576538
Validation loss: 1.943998303464664

Epoch: 6| Step: 13
Training loss: 1.652576208114624
Validation loss: 1.9159188296205254

Epoch: 148| Step: 0
Training loss: 2.2725882530212402
Validation loss: 1.8620714410658805

Epoch: 6| Step: 1
Training loss: 2.6052935123443604
Validation loss: 1.8570943135087208

Epoch: 6| Step: 2
Training loss: 1.8538434505462646
Validation loss: 1.8693481414548812

Epoch: 6| Step: 3
Training loss: 1.520263671875
Validation loss: 1.8746727525546987

Epoch: 6| Step: 4
Training loss: 1.8190335035324097
Validation loss: 1.874357186337953

Epoch: 6| Step: 5
Training loss: 2.350815773010254
Validation loss: 1.8630078761808333

Epoch: 6| Step: 6
Training loss: 2.3532514572143555
Validation loss: 1.8406432162048996

Epoch: 6| Step: 7
Training loss: 1.5581332445144653
Validation loss: 1.8361040469138854

Epoch: 6| Step: 8
Training loss: 2.14400577545166
Validation loss: 1.85146330248925

Epoch: 6| Step: 9
Training loss: 2.4445557594299316
Validation loss: 1.8959664426824099

Epoch: 6| Step: 10
Training loss: 2.3156661987304688
Validation loss: 1.923833195881177

Epoch: 6| Step: 11
Training loss: 2.088153839111328
Validation loss: 1.9383847380197177

Epoch: 6| Step: 12
Training loss: 1.8343901634216309
Validation loss: 1.9235643097149429

Epoch: 6| Step: 13
Training loss: 1.1041351556777954
Validation loss: 1.8982900419542867

Epoch: 149| Step: 0
Training loss: 2.3684539794921875
Validation loss: 1.8813669989185948

Epoch: 6| Step: 1
Training loss: 1.883955478668213
Validation loss: 1.8815125701248006

Epoch: 6| Step: 2
Training loss: 1.528593897819519
Validation loss: 1.885482342012467

Epoch: 6| Step: 3
Training loss: 2.4073967933654785
Validation loss: 1.8916609210352744

Epoch: 6| Step: 4
Training loss: 1.828593373298645
Validation loss: 1.8873434810228245

Epoch: 6| Step: 5
Training loss: 1.5738592147827148
Validation loss: 1.8836110843125211

Epoch: 6| Step: 6
Training loss: 2.2200968265533447
Validation loss: 1.880525710762188

Epoch: 6| Step: 7
Training loss: 2.390639305114746
Validation loss: 1.8979507325797953

Epoch: 6| Step: 8
Training loss: 1.8307675123214722
Validation loss: 1.8964006952060166

Epoch: 6| Step: 9
Training loss: 1.9632916450500488
Validation loss: 1.8964752881757674

Epoch: 6| Step: 10
Training loss: 1.7266204357147217
Validation loss: 1.8718916716114167

Epoch: 6| Step: 11
Training loss: 2.3621785640716553
Validation loss: 1.8584273361390637

Epoch: 6| Step: 12
Training loss: 1.9132590293884277
Validation loss: 1.8669938195136286

Epoch: 6| Step: 13
Training loss: 1.9899044036865234
Validation loss: 1.8673920939045567

Epoch: 150| Step: 0
Training loss: 2.328143358230591
Validation loss: 1.8863733737699446

Epoch: 6| Step: 1
Training loss: 2.1705098152160645
Validation loss: 1.8827408167623705

Epoch: 6| Step: 2
Training loss: 1.619558334350586
Validation loss: 1.920490441783782

Epoch: 6| Step: 3
Training loss: 2.052366256713867
Validation loss: 1.91948103391996

Epoch: 6| Step: 4
Training loss: 2.2534332275390625
Validation loss: 1.901796224296734

Epoch: 6| Step: 5
Training loss: 1.704180121421814
Validation loss: 1.901324737456537

Epoch: 6| Step: 6
Training loss: 1.5683863162994385
Validation loss: 1.8829590133441392

Epoch: 6| Step: 7
Training loss: 1.7138004302978516
Validation loss: 1.8764494785698511

Epoch: 6| Step: 8
Training loss: 1.9750995635986328
Validation loss: 1.8729840068406955

Epoch: 6| Step: 9
Training loss: 2.3648438453674316
Validation loss: 1.8818464125356367

Epoch: 6| Step: 10
Training loss: 2.4873263835906982
Validation loss: 1.8796774174577446

Epoch: 6| Step: 11
Training loss: 2.141932487487793
Validation loss: 1.8854908071538454

Epoch: 6| Step: 12
Training loss: 1.921109676361084
Validation loss: 1.9045806418183029

Epoch: 6| Step: 13
Training loss: 1.3560575246810913
Validation loss: 1.901646400010714

Epoch: 151| Step: 0
Training loss: 2.2960212230682373
Validation loss: 1.9044803483511812

Epoch: 6| Step: 1
Training loss: 1.3347578048706055
Validation loss: 1.9105690961243005

Epoch: 6| Step: 2
Training loss: 1.562914490699768
Validation loss: 1.9102305699420232

Epoch: 6| Step: 3
Training loss: 2.65867280960083
Validation loss: 1.917650657315408

Epoch: 6| Step: 4
Training loss: 2.16860032081604
Validation loss: 1.9092860632045294

Epoch: 6| Step: 5
Training loss: 2.2087059020996094
Validation loss: 1.902071552891885

Epoch: 6| Step: 6
Training loss: 2.7343578338623047
Validation loss: 1.9033213507744573

Epoch: 6| Step: 7
Training loss: 1.7565760612487793
Validation loss: 1.9091686881998533

Epoch: 6| Step: 8
Training loss: 2.1100587844848633
Validation loss: 1.9020317421164563

Epoch: 6| Step: 9
Training loss: 2.132397413253784
Validation loss: 1.8755429367865286

Epoch: 6| Step: 10
Training loss: 1.0846898555755615
Validation loss: 1.866969875110093

Epoch: 6| Step: 11
Training loss: 1.8202667236328125
Validation loss: 1.8548476772923623

Epoch: 6| Step: 12
Training loss: 1.9131752252578735
Validation loss: 1.8548525071913196

Epoch: 6| Step: 13
Training loss: 2.3205087184906006
Validation loss: 1.8655711322702386

Epoch: 152| Step: 0
Training loss: 1.936575174331665
Validation loss: 1.8654194057628672

Epoch: 6| Step: 1
Training loss: 2.3047633171081543
Validation loss: 1.842247683514831

Epoch: 6| Step: 2
Training loss: 1.6795825958251953
Validation loss: 1.8637122095272105

Epoch: 6| Step: 3
Training loss: 2.2467405796051025
Validation loss: 1.8973684221185663

Epoch: 6| Step: 4
Training loss: 2.3869643211364746
Validation loss: 1.9097945228699715

Epoch: 6| Step: 5
Training loss: 2.097229480743408
Validation loss: 1.893267894303927

Epoch: 6| Step: 6
Training loss: 1.6542689800262451
Validation loss: 1.9017114741827852

Epoch: 6| Step: 7
Training loss: 1.4173369407653809
Validation loss: 1.8892925836706673

Epoch: 6| Step: 8
Training loss: 1.7730603218078613
Validation loss: 1.8808496293201242

Epoch: 6| Step: 9
Training loss: 2.3639259338378906
Validation loss: 1.8696728470504924

Epoch: 6| Step: 10
Training loss: 1.8742122650146484
Validation loss: 1.8742026129076559

Epoch: 6| Step: 11
Training loss: 2.072779655456543
Validation loss: 1.8953744775505477

Epoch: 6| Step: 12
Training loss: 2.231403350830078
Validation loss: 1.9039910826631772

Epoch: 6| Step: 13
Training loss: 2.246302604675293
Validation loss: 1.8715183222165672

Epoch: 153| Step: 0
Training loss: 2.15798282623291
Validation loss: 1.8563195864359539

Epoch: 6| Step: 1
Training loss: 1.6834583282470703
Validation loss: 1.8625019173468313

Epoch: 6| Step: 2
Training loss: 2.035936117172241
Validation loss: 1.8914694709162558

Epoch: 6| Step: 3
Training loss: 1.6870933771133423
Validation loss: 1.9359907962942635

Epoch: 6| Step: 4
Training loss: 2.7631993293762207
Validation loss: 1.9750121754984702

Epoch: 6| Step: 5
Training loss: 1.8132933378219604
Validation loss: 1.9679708096288866

Epoch: 6| Step: 6
Training loss: 1.9816720485687256
Validation loss: 1.9311080478852796

Epoch: 6| Step: 7
Training loss: 1.683875322341919
Validation loss: 1.9040962444838656

Epoch: 6| Step: 8
Training loss: 1.4657783508300781
Validation loss: 1.8653747753430439

Epoch: 6| Step: 9
Training loss: 2.5956597328186035
Validation loss: 1.856436376930565

Epoch: 6| Step: 10
Training loss: 2.664921998977661
Validation loss: 1.869941758853133

Epoch: 6| Step: 11
Training loss: 1.601897954940796
Validation loss: 1.8975533182903002

Epoch: 6| Step: 12
Training loss: 2.058877944946289
Validation loss: 1.8883957427035096

Epoch: 6| Step: 13
Training loss: 2.2447032928466797
Validation loss: 1.903940644315494

Epoch: 154| Step: 0
Training loss: 1.431659460067749
Validation loss: 1.8879548336869927

Epoch: 6| Step: 1
Training loss: 1.935250997543335
Validation loss: 1.883383988052286

Epoch: 6| Step: 2
Training loss: 2.0473244190216064
Validation loss: 1.8843230714080155

Epoch: 6| Step: 3
Training loss: 1.433379888534546
Validation loss: 1.9270714611135504

Epoch: 6| Step: 4
Training loss: 2.3847267627716064
Validation loss: 1.9870467724338654

Epoch: 6| Step: 5
Training loss: 2.2017295360565186
Validation loss: 2.012298389147687

Epoch: 6| Step: 6
Training loss: 1.9965249300003052
Validation loss: 1.992610687850624

Epoch: 6| Step: 7
Training loss: 1.8099358081817627
Validation loss: 1.9760180134927072

Epoch: 6| Step: 8
Training loss: 1.8118960857391357
Validation loss: 1.9026691900786532

Epoch: 6| Step: 9
Training loss: 1.7323356866836548
Validation loss: 1.87530053687352

Epoch: 6| Step: 10
Training loss: 2.0678915977478027
Validation loss: 1.8754310236182263

Epoch: 6| Step: 11
Training loss: 2.662891387939453
Validation loss: 1.8969362179438274

Epoch: 6| Step: 12
Training loss: 2.8305916786193848
Validation loss: 1.8897340579699444

Epoch: 6| Step: 13
Training loss: 2.5454940795898438
Validation loss: 1.8823011716206868

Epoch: 155| Step: 0
Training loss: 1.5917186737060547
Validation loss: 1.8773178438986502

Epoch: 6| Step: 1
Training loss: 1.44490385055542
Validation loss: 1.8800265571122527

Epoch: 6| Step: 2
Training loss: 2.2494521141052246
Validation loss: 1.8661304520022484

Epoch: 6| Step: 3
Training loss: 1.513199806213379
Validation loss: 1.8663972872559742

Epoch: 6| Step: 4
Training loss: 2.562335729598999
Validation loss: 1.8861607889975271

Epoch: 6| Step: 5
Training loss: 1.5460776090621948
Validation loss: 1.901789770331434

Epoch: 6| Step: 6
Training loss: 2.4800760746002197
Validation loss: 1.9220629738223167

Epoch: 6| Step: 7
Training loss: 2.0985913276672363
Validation loss: 1.9253198164765553

Epoch: 6| Step: 8
Training loss: 2.2418899536132812
Validation loss: 1.9521332684383597

Epoch: 6| Step: 9
Training loss: 2.7074270248413086
Validation loss: 1.9467391813955

Epoch: 6| Step: 10
Training loss: 1.78128182888031
Validation loss: 1.9304335668522825

Epoch: 6| Step: 11
Training loss: 2.1368203163146973
Validation loss: 1.9014192319685412

Epoch: 6| Step: 12
Training loss: 1.5093311071395874
Validation loss: 1.8871270072075628

Epoch: 6| Step: 13
Training loss: 2.1480953693389893
Validation loss: 1.870466645045947

Epoch: 156| Step: 0
Training loss: 2.296504497528076
Validation loss: 1.858929548212277

Epoch: 6| Step: 1
Training loss: 1.723528265953064
Validation loss: 1.8572264384197932

Epoch: 6| Step: 2
Training loss: 2.105897903442383
Validation loss: 1.849549824191678

Epoch: 6| Step: 3
Training loss: 1.358860731124878
Validation loss: 1.85224667415824

Epoch: 6| Step: 4
Training loss: 2.0729782581329346
Validation loss: 1.8458171224081388

Epoch: 6| Step: 5
Training loss: 2.2057547569274902
Validation loss: 1.8603389263153076

Epoch: 6| Step: 6
Training loss: 2.3975353240966797
Validation loss: 1.8617078758055163

Epoch: 6| Step: 7
Training loss: 2.2122793197631836
Validation loss: 1.8640391647174794

Epoch: 6| Step: 8
Training loss: 0.8519166707992554
Validation loss: 1.8651490314032442

Epoch: 6| Step: 9
Training loss: 1.509535789489746
Validation loss: 1.8669711236030824

Epoch: 6| Step: 10
Training loss: 2.295182704925537
Validation loss: 1.8574405639402327

Epoch: 6| Step: 11
Training loss: 1.6973154544830322
Validation loss: 1.8654547622126918

Epoch: 6| Step: 12
Training loss: 2.565946578979492
Validation loss: 1.8772907833899222

Epoch: 6| Step: 13
Training loss: 2.80998158454895
Validation loss: 1.8940794519198838

Epoch: 157| Step: 0
Training loss: 2.388489007949829
Validation loss: 1.899749872505024

Epoch: 6| Step: 1
Training loss: 1.6672319173812866
Validation loss: 1.9134762415321924

Epoch: 6| Step: 2
Training loss: 2.7054762840270996
Validation loss: 1.9442914173167238

Epoch: 6| Step: 3
Training loss: 2.138505220413208
Validation loss: 1.9366592822536346

Epoch: 6| Step: 4
Training loss: 1.7369143962860107
Validation loss: 1.902366070337193

Epoch: 6| Step: 5
Training loss: 1.4924988746643066
Validation loss: 1.8705870131010651

Epoch: 6| Step: 6
Training loss: 2.374774932861328
Validation loss: 1.851726298691124

Epoch: 6| Step: 7
Training loss: 2.0917551517486572
Validation loss: 1.8679747786573184

Epoch: 6| Step: 8
Training loss: 1.9109759330749512
Validation loss: 1.8675349784153763

Epoch: 6| Step: 9
Training loss: 1.5830841064453125
Validation loss: 1.8515518608913626

Epoch: 6| Step: 10
Training loss: 2.523244857788086
Validation loss: 1.82771582629091

Epoch: 6| Step: 11
Training loss: 1.6432878971099854
Validation loss: 1.8334801402143253

Epoch: 6| Step: 12
Training loss: 1.6605989933013916
Validation loss: 1.8376071222366825

Epoch: 6| Step: 13
Training loss: 1.6612833738327026
Validation loss: 1.8432274223655782

Epoch: 158| Step: 0
Training loss: 2.117663860321045
Validation loss: 1.8726855824070592

Epoch: 6| Step: 1
Training loss: 2.6042280197143555
Validation loss: 1.9026198899874123

Epoch: 6| Step: 2
Training loss: 1.8203928470611572
Validation loss: 1.9404888691440705

Epoch: 6| Step: 3
Training loss: 1.3848158121109009
Validation loss: 1.9273555958142845

Epoch: 6| Step: 4
Training loss: 1.951593041419983
Validation loss: 1.9179655300673617

Epoch: 6| Step: 5
Training loss: 2.2576944828033447
Validation loss: 1.9100341348237888

Epoch: 6| Step: 6
Training loss: 2.1245787143707275
Validation loss: 1.877082396579045

Epoch: 6| Step: 7
Training loss: 2.417720317840576
Validation loss: 1.8772797302533222

Epoch: 6| Step: 8
Training loss: 1.4840285778045654
Validation loss: 1.8613603461173274

Epoch: 6| Step: 9
Training loss: 2.444451093673706
Validation loss: 1.8509381201959425

Epoch: 6| Step: 10
Training loss: 1.287219524383545
Validation loss: 1.8411093681089339

Epoch: 6| Step: 11
Training loss: 1.796296238899231
Validation loss: 1.852594341001203

Epoch: 6| Step: 12
Training loss: 2.034689426422119
Validation loss: 1.8726485467726184

Epoch: 6| Step: 13
Training loss: 1.9766120910644531
Validation loss: 1.8659561013662687

Epoch: 159| Step: 0
Training loss: 2.934875011444092
Validation loss: 1.856339370050738

Epoch: 6| Step: 1
Training loss: 1.7000017166137695
Validation loss: 1.849151280618483

Epoch: 6| Step: 2
Training loss: 1.3873414993286133
Validation loss: 1.8532315172174925

Epoch: 6| Step: 3
Training loss: 2.034284830093384
Validation loss: 1.8462181245127032

Epoch: 6| Step: 4
Training loss: 1.9042770862579346
Validation loss: 1.853091707793615

Epoch: 6| Step: 5
Training loss: 2.650456428527832
Validation loss: 1.852007790278363

Epoch: 6| Step: 6
Training loss: 2.2506303787231445
Validation loss: 1.8689506951198782

Epoch: 6| Step: 7
Training loss: 1.5613937377929688
Validation loss: 1.8687651490652433

Epoch: 6| Step: 8
Training loss: 2.1573691368103027
Validation loss: 1.8807172544540898

Epoch: 6| Step: 9
Training loss: 1.5773789882659912
Validation loss: 1.8871360735226703

Epoch: 6| Step: 10
Training loss: 2.0153069496154785
Validation loss: 1.8676424180307696

Epoch: 6| Step: 11
Training loss: 1.8042168617248535
Validation loss: 1.869080299972206

Epoch: 6| Step: 12
Training loss: 1.8181984424591064
Validation loss: 1.8601539288797686

Epoch: 6| Step: 13
Training loss: 1.351226806640625
Validation loss: 1.8696871188379103

Epoch: 160| Step: 0
Training loss: 1.6156069040298462
Validation loss: 1.868687137480705

Epoch: 6| Step: 1
Training loss: 1.7264504432678223
Validation loss: 1.8792603246627315

Epoch: 6| Step: 2
Training loss: 2.563823699951172
Validation loss: 1.872376077918596

Epoch: 6| Step: 3
Training loss: 1.575580358505249
Validation loss: 1.8725242589109687

Epoch: 6| Step: 4
Training loss: 2.322072982788086
Validation loss: 1.8851044216463644

Epoch: 6| Step: 5
Training loss: 2.058459758758545
Validation loss: 1.890637381102449

Epoch: 6| Step: 6
Training loss: 1.959686517715454
Validation loss: 1.8896623285867835

Epoch: 6| Step: 7
Training loss: 2.5147554874420166
Validation loss: 1.8943722812078332

Epoch: 6| Step: 8
Training loss: 1.786569356918335
Validation loss: 1.8832434326089837

Epoch: 6| Step: 9
Training loss: 1.7310700416564941
Validation loss: 1.8737253988942792

Epoch: 6| Step: 10
Training loss: 1.236891508102417
Validation loss: 1.8939270921932754

Epoch: 6| Step: 11
Training loss: 2.36915922164917
Validation loss: 1.8879298151180308

Epoch: 6| Step: 12
Training loss: 2.2830591201782227
Validation loss: 1.889721805049527

Epoch: 6| Step: 13
Training loss: 1.5034236907958984
Validation loss: 1.899870987861387

Epoch: 161| Step: 0
Training loss: 2.170332193374634
Validation loss: 1.8921461694984025

Epoch: 6| Step: 1
Training loss: 1.441624641418457
Validation loss: 1.8760736834618352

Epoch: 6| Step: 2
Training loss: 2.5427887439727783
Validation loss: 1.8570116771164762

Epoch: 6| Step: 3
Training loss: 2.9801390171051025
Validation loss: 1.8354546305953816

Epoch: 6| Step: 4
Training loss: 2.6422595977783203
Validation loss: 1.8428168527541622

Epoch: 6| Step: 5
Training loss: 1.5990499258041382
Validation loss: 1.8467386025254444

Epoch: 6| Step: 6
Training loss: 1.5523910522460938
Validation loss: 1.84795731113803

Epoch: 6| Step: 7
Training loss: 1.5183489322662354
Validation loss: 1.8362357283151278

Epoch: 6| Step: 8
Training loss: 1.245488166809082
Validation loss: 1.8492677724489601

Epoch: 6| Step: 9
Training loss: 1.9449795484542847
Validation loss: 1.8519421033961798

Epoch: 6| Step: 10
Training loss: 1.7718855142593384
Validation loss: 1.8647261178621681

Epoch: 6| Step: 11
Training loss: 1.944230556488037
Validation loss: 1.8677217229720084

Epoch: 6| Step: 12
Training loss: 1.7225134372711182
Validation loss: 1.881833346941138

Epoch: 6| Step: 13
Training loss: 2.198361396789551
Validation loss: 1.8839979261480353

Epoch: 162| Step: 0
Training loss: 1.4715156555175781
Validation loss: 1.8732866676904822

Epoch: 6| Step: 1
Training loss: 2.455709934234619
Validation loss: 1.8604806136059504

Epoch: 6| Step: 2
Training loss: 1.2811481952667236
Validation loss: 1.8593968447818552

Epoch: 6| Step: 3
Training loss: 1.4364242553710938
Validation loss: 1.869419192755094

Epoch: 6| Step: 4
Training loss: 1.9854341745376587
Validation loss: 1.8632782146494875

Epoch: 6| Step: 5
Training loss: 1.7614641189575195
Validation loss: 1.860270659128825

Epoch: 6| Step: 6
Training loss: 2.307548999786377
Validation loss: 1.8822274284978067

Epoch: 6| Step: 7
Training loss: 2.3083434104919434
Validation loss: 1.9239881064302178

Epoch: 6| Step: 8
Training loss: 2.2019612789154053
Validation loss: 1.9422945219983336

Epoch: 6| Step: 9
Training loss: 2.7914748191833496
Validation loss: 1.960922860330151

Epoch: 6| Step: 10
Training loss: 2.3102781772613525
Validation loss: 1.940065828702783

Epoch: 6| Step: 11
Training loss: 1.3486428260803223
Validation loss: 1.9225871716776202

Epoch: 6| Step: 12
Training loss: 1.3470277786254883
Validation loss: 1.8903281919417843

Epoch: 6| Step: 13
Training loss: 2.2827389240264893
Validation loss: 1.8714060142476072

Epoch: 163| Step: 0
Training loss: 2.007922410964966
Validation loss: 1.874833236458481

Epoch: 6| Step: 1
Training loss: 2.4316086769104004
Validation loss: 1.8732778064666256

Epoch: 6| Step: 2
Training loss: 2.9258782863616943
Validation loss: 1.8647318681081135

Epoch: 6| Step: 3
Training loss: 2.1485722064971924
Validation loss: 1.85334135383688

Epoch: 6| Step: 4
Training loss: 1.3090028762817383
Validation loss: 1.8293818414852183

Epoch: 6| Step: 5
Training loss: 1.8124966621398926
Validation loss: 1.831267733727732

Epoch: 6| Step: 6
Training loss: 2.0246341228485107
Validation loss: 1.8270042775779642

Epoch: 6| Step: 7
Training loss: 1.8882793188095093
Validation loss: 1.8257450467796736

Epoch: 6| Step: 8
Training loss: 1.2648508548736572
Validation loss: 1.8207889244120607

Epoch: 6| Step: 9
Training loss: 1.5024313926696777
Validation loss: 1.8087602712774788

Epoch: 6| Step: 10
Training loss: 2.080080032348633
Validation loss: 1.8118205198677637

Epoch: 6| Step: 11
Training loss: 2.013578176498413
Validation loss: 1.8061336125096967

Epoch: 6| Step: 12
Training loss: 1.546666145324707
Validation loss: 1.8185761397884739

Epoch: 6| Step: 13
Training loss: 2.3470845222473145
Validation loss: 1.8251848182370585

Epoch: 164| Step: 0
Training loss: 2.033311367034912
Validation loss: 1.8366059282774567

Epoch: 6| Step: 1
Training loss: 2.097774028778076
Validation loss: 1.8571519992684806

Epoch: 6| Step: 2
Training loss: 2.284865379333496
Validation loss: 1.8814706097366989

Epoch: 6| Step: 3
Training loss: 1.8716078996658325
Validation loss: 1.899710302711815

Epoch: 6| Step: 4
Training loss: 1.5405492782592773
Validation loss: 1.910977960914694

Epoch: 6| Step: 5
Training loss: 1.6615710258483887
Validation loss: 1.9446972480384253

Epoch: 6| Step: 6
Training loss: 2.3085427284240723
Validation loss: 1.9499134748212752

Epoch: 6| Step: 7
Training loss: 2.1107099056243896
Validation loss: 1.9750179090807516

Epoch: 6| Step: 8
Training loss: 1.7131948471069336
Validation loss: 2.003527823314872

Epoch: 6| Step: 9
Training loss: 2.1708173751831055
Validation loss: 1.9733624637767833

Epoch: 6| Step: 10
Training loss: 1.5944392681121826
Validation loss: 1.9352859117651497

Epoch: 6| Step: 11
Training loss: 1.8691623210906982
Validation loss: 1.9106459822705997

Epoch: 6| Step: 12
Training loss: 1.6976518630981445
Validation loss: 1.8867091184021325

Epoch: 6| Step: 13
Training loss: 2.1189684867858887
Validation loss: 1.885032553826609

Epoch: 165| Step: 0
Training loss: 1.3640317916870117
Validation loss: 1.8720876580925399

Epoch: 6| Step: 1
Training loss: 1.4077239036560059
Validation loss: 1.880777838409588

Epoch: 6| Step: 2
Training loss: 1.509812593460083
Validation loss: 1.8896769016019759

Epoch: 6| Step: 3
Training loss: 1.1605355739593506
Validation loss: 1.8809181515888502

Epoch: 6| Step: 4
Training loss: 2.5835938453674316
Validation loss: 1.8861090303749166

Epoch: 6| Step: 5
Training loss: 1.3201794624328613
Validation loss: 1.8909215209304646

Epoch: 6| Step: 6
Training loss: 1.832803726196289
Validation loss: 1.890784146965191

Epoch: 6| Step: 7
Training loss: 2.2761738300323486
Validation loss: 1.8915764798400223

Epoch: 6| Step: 8
Training loss: 2.4751877784729004
Validation loss: 1.8886316809602963

Epoch: 6| Step: 9
Training loss: 2.395808696746826
Validation loss: 1.894886310382556

Epoch: 6| Step: 10
Training loss: 1.9514598846435547
Validation loss: 1.8946721912712179

Epoch: 6| Step: 11
Training loss: 1.8557820320129395
Validation loss: 1.8738381644730926

Epoch: 6| Step: 12
Training loss: 2.5340006351470947
Validation loss: 1.850752471595682

Epoch: 6| Step: 13
Training loss: 2.0864062309265137
Validation loss: 1.8484121509777602

Epoch: 166| Step: 0
Training loss: 1.9741016626358032
Validation loss: 1.8481002289761779

Epoch: 6| Step: 1
Training loss: 2.1828513145446777
Validation loss: 1.8637291769827566

Epoch: 6| Step: 2
Training loss: 2.2426562309265137
Validation loss: 1.8809008393236386

Epoch: 6| Step: 3
Training loss: 1.205476999282837
Validation loss: 1.912040074666341

Epoch: 6| Step: 4
Training loss: 1.8850066661834717
Validation loss: 1.932611543645141

Epoch: 6| Step: 5
Training loss: 2.0870919227600098
Validation loss: 1.9760563835020988

Epoch: 6| Step: 6
Training loss: 1.4791839122772217
Validation loss: 1.9811028665111912

Epoch: 6| Step: 7
Training loss: 2.14963960647583
Validation loss: 1.9560822235640658

Epoch: 6| Step: 8
Training loss: 1.8623863458633423
Validation loss: 1.9229244506487282

Epoch: 6| Step: 9
Training loss: 1.864267110824585
Validation loss: 1.8908363926795222

Epoch: 6| Step: 10
Training loss: 2.44486141204834
Validation loss: 1.8786154498336136

Epoch: 6| Step: 11
Training loss: 1.7114425897598267
Validation loss: 1.8844895542308848

Epoch: 6| Step: 12
Training loss: 2.539036273956299
Validation loss: 1.8916999793821765

Epoch: 6| Step: 13
Training loss: 1.2369592189788818
Validation loss: 1.8717120847394388

Epoch: 167| Step: 0
Training loss: 1.8158538341522217
Validation loss: 1.8456813917365125

Epoch: 6| Step: 1
Training loss: 1.4702634811401367
Validation loss: 1.8515043117666756

Epoch: 6| Step: 2
Training loss: 2.1843817234039307
Validation loss: 1.8735698858896892

Epoch: 6| Step: 3
Training loss: 1.4661731719970703
Validation loss: 1.8873454934807234

Epoch: 6| Step: 4
Training loss: 1.8820226192474365
Validation loss: 1.8843796612114034

Epoch: 6| Step: 5
Training loss: 2.6499454975128174
Validation loss: 1.8637082974116008

Epoch: 6| Step: 6
Training loss: 1.7880327701568604
Validation loss: 1.8508074334872666

Epoch: 6| Step: 7
Training loss: 1.8385037183761597
Validation loss: 1.8111594953844625

Epoch: 6| Step: 8
Training loss: 1.6551826000213623
Validation loss: 1.8107739533147504

Epoch: 6| Step: 9
Training loss: 2.0834097862243652
Validation loss: 1.812077223613698

Epoch: 6| Step: 10
Training loss: 2.085692882537842
Validation loss: 1.824223082552674

Epoch: 6| Step: 11
Training loss: 1.9885724782943726
Validation loss: 1.8409895666183964

Epoch: 6| Step: 12
Training loss: 2.3550117015838623
Validation loss: 1.8439708781498734

Epoch: 6| Step: 13
Training loss: 1.7838257551193237
Validation loss: 1.8447391102390904

Epoch: 168| Step: 0
Training loss: 2.03682279586792
Validation loss: 1.8597245318915254

Epoch: 6| Step: 1
Training loss: 2.261496067047119
Validation loss: 1.8737970526500414

Epoch: 6| Step: 2
Training loss: 1.6970739364624023
Validation loss: 1.8883629537397815

Epoch: 6| Step: 3
Training loss: 1.856766939163208
Validation loss: 1.8989768835806078

Epoch: 6| Step: 4
Training loss: 1.515405297279358
Validation loss: 1.9238931261083132

Epoch: 6| Step: 5
Training loss: 1.4457242488861084
Validation loss: 1.9239709761834913

Epoch: 6| Step: 6
Training loss: 1.9224284887313843
Validation loss: 1.9371839954007057

Epoch: 6| Step: 7
Training loss: 1.869786024093628
Validation loss: 1.9472669939840994

Epoch: 6| Step: 8
Training loss: 2.4522552490234375
Validation loss: 1.9331932644690237

Epoch: 6| Step: 9
Training loss: 2.077448844909668
Validation loss: 1.9458768867677259

Epoch: 6| Step: 10
Training loss: 1.9532878398895264
Validation loss: 1.935540101861441

Epoch: 6| Step: 11
Training loss: 1.7420742511749268
Validation loss: 1.9324150444358907

Epoch: 6| Step: 12
Training loss: 2.093895196914673
Validation loss: 1.9455728800066057

Epoch: 6| Step: 13
Training loss: 1.6775751113891602
Validation loss: 1.930011144248388

Epoch: 169| Step: 0
Training loss: 1.8682430982589722
Validation loss: 1.919119401644635

Epoch: 6| Step: 1
Training loss: 2.0780553817749023
Validation loss: 1.900296325324684

Epoch: 6| Step: 2
Training loss: 1.8253231048583984
Validation loss: 1.8775036668264737

Epoch: 6| Step: 3
Training loss: 2.632236957550049
Validation loss: 1.8549067640817294

Epoch: 6| Step: 4
Training loss: 1.941641092300415
Validation loss: 1.849777211425125

Epoch: 6| Step: 5
Training loss: 1.515366792678833
Validation loss: 1.8445393398243894

Epoch: 6| Step: 6
Training loss: 2.003416061401367
Validation loss: 1.8445215712311447

Epoch: 6| Step: 7
Training loss: 1.9716261625289917
Validation loss: 1.8485860119583786

Epoch: 6| Step: 8
Training loss: 1.5046082735061646
Validation loss: 1.854346013838245

Epoch: 6| Step: 9
Training loss: 2.0881123542785645
Validation loss: 1.8738716392106907

Epoch: 6| Step: 10
Training loss: 2.4044189453125
Validation loss: 1.896860199589883

Epoch: 6| Step: 11
Training loss: 1.3432836532592773
Validation loss: 1.9059924182071482

Epoch: 6| Step: 12
Training loss: 1.7975306510925293
Validation loss: 1.9154423718811364

Epoch: 6| Step: 13
Training loss: 1.129529595375061
Validation loss: 1.894693224660812

Epoch: 170| Step: 0
Training loss: 1.8071019649505615
Validation loss: 1.8843641511855587

Epoch: 6| Step: 1
Training loss: 1.3159444332122803
Validation loss: 1.8775271959202264

Epoch: 6| Step: 2
Training loss: 1.8884849548339844
Validation loss: 1.893509195696923

Epoch: 6| Step: 3
Training loss: 2.08716082572937
Validation loss: 1.8692631003677205

Epoch: 6| Step: 4
Training loss: 1.928504228591919
Validation loss: 1.8656802997794202

Epoch: 6| Step: 5
Training loss: 3.00817608833313
Validation loss: 1.8766466750893542

Epoch: 6| Step: 6
Training loss: 2.070117473602295
Validation loss: 1.8747365654155772

Epoch: 6| Step: 7
Training loss: 2.207127809524536
Validation loss: 1.855396859107479

Epoch: 6| Step: 8
Training loss: 1.847590446472168
Validation loss: 1.860613328154369

Epoch: 6| Step: 9
Training loss: 1.1221791505813599
Validation loss: 1.8907506145456785

Epoch: 6| Step: 10
Training loss: 1.779030203819275
Validation loss: 1.9300197670536656

Epoch: 6| Step: 11
Training loss: 1.5856595039367676
Validation loss: 1.9583700779945619

Epoch: 6| Step: 12
Training loss: 1.7373046875
Validation loss: 1.9528441839320685

Epoch: 6| Step: 13
Training loss: 2.847172498703003
Validation loss: 1.9601205946296774

Epoch: 171| Step: 0
Training loss: 2.49867582321167
Validation loss: 1.9470801866182716

Epoch: 6| Step: 1
Training loss: 1.858954668045044
Validation loss: 1.9556766069063576

Epoch: 6| Step: 2
Training loss: 1.4613592624664307
Validation loss: 1.9515821677382275

Epoch: 6| Step: 3
Training loss: 2.259572744369507
Validation loss: 1.9181367197344381

Epoch: 6| Step: 4
Training loss: 1.3480210304260254
Validation loss: 1.8863313377544444

Epoch: 6| Step: 5
Training loss: 1.3283884525299072
Validation loss: 1.8734212665147678

Epoch: 6| Step: 6
Training loss: 1.668089747428894
Validation loss: 1.9019457294094948

Epoch: 6| Step: 7
Training loss: 1.7458158731460571
Validation loss: 1.9051222544844433

Epoch: 6| Step: 8
Training loss: 2.3503191471099854
Validation loss: 1.91685224604863

Epoch: 6| Step: 9
Training loss: 1.7095242738723755
Validation loss: 1.899885667267666

Epoch: 6| Step: 10
Training loss: 1.6095958948135376
Validation loss: 1.8853781889843684

Epoch: 6| Step: 11
Training loss: 2.156052827835083
Validation loss: 1.872646552260204

Epoch: 6| Step: 12
Training loss: 2.569089412689209
Validation loss: 1.861579820673953

Epoch: 6| Step: 13
Training loss: 2.030285358428955
Validation loss: 1.8577613138383435

Epoch: 172| Step: 0
Training loss: 2.1101574897766113
Validation loss: 1.854299860615884

Epoch: 6| Step: 1
Training loss: 1.6691389083862305
Validation loss: 1.8618582217924056

Epoch: 6| Step: 2
Training loss: 2.248778820037842
Validation loss: 1.8655282733260945

Epoch: 6| Step: 3
Training loss: 1.6642900705337524
Validation loss: 1.8735826925564838

Epoch: 6| Step: 4
Training loss: 1.679307460784912
Validation loss: 1.8632620060315697

Epoch: 6| Step: 5
Training loss: 1.4829453229904175
Validation loss: 1.8714620246682117

Epoch: 6| Step: 6
Training loss: 1.9805281162261963
Validation loss: 1.8652471752576931

Epoch: 6| Step: 7
Training loss: 1.640080213546753
Validation loss: 1.869430798356251

Epoch: 6| Step: 8
Training loss: 2.1874778270721436
Validation loss: 1.8663315567919003

Epoch: 6| Step: 9
Training loss: 1.813340663909912
Validation loss: 1.8729603636649348

Epoch: 6| Step: 10
Training loss: 1.5131672620773315
Validation loss: 1.8882403489082091

Epoch: 6| Step: 11
Training loss: 1.736700177192688
Validation loss: 1.880245989368808

Epoch: 6| Step: 12
Training loss: 2.5249624252319336
Validation loss: 1.896521504207324

Epoch: 6| Step: 13
Training loss: 1.7313077449798584
Validation loss: 1.8880407579483525

Epoch: 173| Step: 0
Training loss: 1.5006479024887085
Validation loss: 1.8890042240901659

Epoch: 6| Step: 1
Training loss: 1.8271598815917969
Validation loss: 1.8879604121690154

Epoch: 6| Step: 2
Training loss: 1.6461635828018188
Validation loss: 1.8911568836499286

Epoch: 6| Step: 3
Training loss: 2.3704135417938232
Validation loss: 1.890369353755828

Epoch: 6| Step: 4
Training loss: 1.8805363178253174
Validation loss: 1.8841806380979476

Epoch: 6| Step: 5
Training loss: 2.2024459838867188
Validation loss: 1.8958347612811672

Epoch: 6| Step: 6
Training loss: 1.9002506732940674
Validation loss: 1.9007529045945855

Epoch: 6| Step: 7
Training loss: 2.184356927871704
Validation loss: 1.8757855405089676

Epoch: 6| Step: 8
Training loss: 1.8564293384552002
Validation loss: 1.8788755850125385

Epoch: 6| Step: 9
Training loss: 1.1088809967041016
Validation loss: 1.855568931948754

Epoch: 6| Step: 10
Training loss: 1.7391842603683472
Validation loss: 1.8538263446541243

Epoch: 6| Step: 11
Training loss: 1.7056928873062134
Validation loss: 1.851518605345039

Epoch: 6| Step: 12
Training loss: 1.822522759437561
Validation loss: 1.8474657048461258

Epoch: 6| Step: 13
Training loss: 2.027013063430786
Validation loss: 1.8614032242887764

Epoch: 174| Step: 0
Training loss: 1.538910984992981
Validation loss: 1.8618250790462698

Epoch: 6| Step: 1
Training loss: 2.2365307807922363
Validation loss: 1.8559280351925922

Epoch: 6| Step: 2
Training loss: 1.6751422882080078
Validation loss: 1.8657049235477243

Epoch: 6| Step: 3
Training loss: 2.0780787467956543
Validation loss: 1.860477501346219

Epoch: 6| Step: 4
Training loss: 1.8700146675109863
Validation loss: 1.8641450905030774

Epoch: 6| Step: 5
Training loss: 1.6184738874435425
Validation loss: 1.8566661598861858

Epoch: 6| Step: 6
Training loss: 1.3701324462890625
Validation loss: 1.8633334072687293

Epoch: 6| Step: 7
Training loss: 1.6768779754638672
Validation loss: 1.858452085525759

Epoch: 6| Step: 8
Training loss: 1.4409162998199463
Validation loss: 1.8519696856057772

Epoch: 6| Step: 9
Training loss: 2.057109832763672
Validation loss: 1.8603842899363527

Epoch: 6| Step: 10
Training loss: 1.5541168451309204
Validation loss: 1.8798210941335207

Epoch: 6| Step: 11
Training loss: 1.633775234222412
Validation loss: 1.8805326390010055

Epoch: 6| Step: 12
Training loss: 3.164762496948242
Validation loss: 1.8908433811638945

Epoch: 6| Step: 13
Training loss: 1.015726923942566
Validation loss: 1.8964747305839293

Epoch: 175| Step: 0
Training loss: 1.2151638269424438
Validation loss: 1.89024257275366

Epoch: 6| Step: 1
Training loss: 1.7731002569198608
Validation loss: 1.8905948156951575

Epoch: 6| Step: 2
Training loss: 1.9354933500289917
Validation loss: 1.8989977426426385

Epoch: 6| Step: 3
Training loss: 1.7724839448928833
Validation loss: 1.8996761204094015

Epoch: 6| Step: 4
Training loss: 2.280601978302002
Validation loss: 1.9115832198050715

Epoch: 6| Step: 5
Training loss: 1.99176824092865
Validation loss: 1.894353525612944

Epoch: 6| Step: 6
Training loss: 1.6130502223968506
Validation loss: 1.8681160929382488

Epoch: 6| Step: 7
Training loss: 1.6169354915618896
Validation loss: 1.8294203845403527

Epoch: 6| Step: 8
Training loss: 2.1360158920288086
Validation loss: 1.8317825230219031

Epoch: 6| Step: 9
Training loss: 1.3831725120544434
Validation loss: 1.8229119905861475

Epoch: 6| Step: 10
Training loss: 2.0578668117523193
Validation loss: 1.8226532500277284

Epoch: 6| Step: 11
Training loss: 1.9005920886993408
Validation loss: 1.819553502144352

Epoch: 6| Step: 12
Training loss: 2.305976152420044
Validation loss: 1.8263181742801462

Epoch: 6| Step: 13
Training loss: 0.9333184361457825
Validation loss: 1.8243827614732968

Epoch: 176| Step: 0
Training loss: 1.9856109619140625
Validation loss: 1.8335689267804545

Epoch: 6| Step: 1
Training loss: 1.7740387916564941
Validation loss: 1.830819296580489

Epoch: 6| Step: 2
Training loss: 2.215175151824951
Validation loss: 1.845526687560543

Epoch: 6| Step: 3
Training loss: 1.161138892173767
Validation loss: 1.8469649925026843

Epoch: 6| Step: 4
Training loss: 2.3122763633728027
Validation loss: 1.849649933076674

Epoch: 6| Step: 5
Training loss: 1.7352548837661743
Validation loss: 1.8677967799607145

Epoch: 6| Step: 6
Training loss: 1.1055412292480469
Validation loss: 1.8721149121561358

Epoch: 6| Step: 7
Training loss: 1.530726671218872
Validation loss: 1.8759232951748757

Epoch: 6| Step: 8
Training loss: 1.3236398696899414
Validation loss: 1.8979482496938398

Epoch: 6| Step: 9
Training loss: 2.0935471057891846
Validation loss: 1.8907863683598016

Epoch: 6| Step: 10
Training loss: 2.2106854915618896
Validation loss: 1.8976994765702115

Epoch: 6| Step: 11
Training loss: 1.8809245824813843
Validation loss: 1.8909948448981009

Epoch: 6| Step: 12
Training loss: 1.9148468971252441
Validation loss: 1.8837084693293418

Epoch: 6| Step: 13
Training loss: 2.030592679977417
Validation loss: 1.8898651728066065

Epoch: 177| Step: 0
Training loss: 1.7399890422821045
Validation loss: 1.8938972168071295

Epoch: 6| Step: 1
Training loss: 1.1561241149902344
Validation loss: 1.8907751396138182

Epoch: 6| Step: 2
Training loss: 1.7083077430725098
Validation loss: 1.899497385947935

Epoch: 6| Step: 3
Training loss: 1.9993343353271484
Validation loss: 1.8877708399167625

Epoch: 6| Step: 4
Training loss: 1.3358166217803955
Validation loss: 1.9043989386609805

Epoch: 6| Step: 5
Training loss: 2.3043336868286133
Validation loss: 1.9112196712083713

Epoch: 6| Step: 6
Training loss: 1.3990715742111206
Validation loss: 1.907515020780666

Epoch: 6| Step: 7
Training loss: 1.4708691835403442
Validation loss: 1.8954312070723502

Epoch: 6| Step: 8
Training loss: 2.279588460922241
Validation loss: 1.8712728997712493

Epoch: 6| Step: 9
Training loss: 1.759974718093872
Validation loss: 1.8471869627634685

Epoch: 6| Step: 10
Training loss: 2.34545636177063
Validation loss: 1.8294488909423992

Epoch: 6| Step: 11
Training loss: 2.1235384941101074
Validation loss: 1.8138103895289923

Epoch: 6| Step: 12
Training loss: 1.8923699855804443
Validation loss: 1.8269597381673834

Epoch: 6| Step: 13
Training loss: 1.4893275499343872
Validation loss: 1.8247591603186823

Epoch: 178| Step: 0
Training loss: 1.8844170570373535
Validation loss: 1.8310053502359698

Epoch: 6| Step: 1
Training loss: 1.5812170505523682
Validation loss: 1.8424084981282551

Epoch: 6| Step: 2
Training loss: 2.133805990219116
Validation loss: 1.8625114630627375

Epoch: 6| Step: 3
Training loss: 2.277947425842285
Validation loss: 1.909073160540673

Epoch: 6| Step: 4
Training loss: 1.511216163635254
Validation loss: 1.9167866296665643

Epoch: 6| Step: 5
Training loss: 1.5533158779144287
Validation loss: 1.9098515254195019

Epoch: 6| Step: 6
Training loss: 1.920465350151062
Validation loss: 1.9147167077628515

Epoch: 6| Step: 7
Training loss: 1.1728523969650269
Validation loss: 1.9014879759921823

Epoch: 6| Step: 8
Training loss: 2.207387685775757
Validation loss: 1.9058165588686544

Epoch: 6| Step: 9
Training loss: 1.8445584774017334
Validation loss: 1.9162605065171436

Epoch: 6| Step: 10
Training loss: 2.248960494995117
Validation loss: 1.902155335231494

Epoch: 6| Step: 11
Training loss: 1.2970852851867676
Validation loss: 1.8797257074745752

Epoch: 6| Step: 12
Training loss: 1.6604243516921997
Validation loss: 1.8570809671955724

Epoch: 6| Step: 13
Training loss: 1.9643092155456543
Validation loss: 1.851145302095721

Epoch: 179| Step: 0
Training loss: 1.6813547611236572
Validation loss: 1.8292232559573265

Epoch: 6| Step: 1
Training loss: 1.3848695755004883
Validation loss: 1.8332504226315407

Epoch: 6| Step: 2
Training loss: 1.050415277481079
Validation loss: 1.82573438203463

Epoch: 6| Step: 3
Training loss: 1.9251697063446045
Validation loss: 1.8354017067981023

Epoch: 6| Step: 4
Training loss: 1.7932076454162598
Validation loss: 1.831736494136113

Epoch: 6| Step: 5
Training loss: 2.0657691955566406
Validation loss: 1.841655082600091

Epoch: 6| Step: 6
Training loss: 1.947209358215332
Validation loss: 1.841452826735794

Epoch: 6| Step: 7
Training loss: 2.277522087097168
Validation loss: 1.843673618890906

Epoch: 6| Step: 8
Training loss: 2.161799192428589
Validation loss: 1.8513614772468485

Epoch: 6| Step: 9
Training loss: 1.3530175685882568
Validation loss: 1.860663772911154

Epoch: 6| Step: 10
Training loss: 1.4320664405822754
Validation loss: 1.8861269399683962

Epoch: 6| Step: 11
Training loss: 2.185819149017334
Validation loss: 1.9015025413164528

Epoch: 6| Step: 12
Training loss: 2.0237483978271484
Validation loss: 1.925347069258331

Epoch: 6| Step: 13
Training loss: 0.9637858271598816
Validation loss: 1.9451329708099365

Epoch: 180| Step: 0
Training loss: 2.1202149391174316
Validation loss: 1.9536564965401926

Epoch: 6| Step: 1
Training loss: 1.7352039813995361
Validation loss: 1.9522663162600609

Epoch: 6| Step: 2
Training loss: 2.0315170288085938
Validation loss: 1.9664357708346458

Epoch: 6| Step: 3
Training loss: 1.8885834217071533
Validation loss: 1.9381478896705053

Epoch: 6| Step: 4
Training loss: 1.497788667678833
Validation loss: 1.9231133307180097

Epoch: 6| Step: 5
Training loss: 1.5500433444976807
Validation loss: 1.916230527303552

Epoch: 6| Step: 6
Training loss: 2.086193084716797
Validation loss: 1.908620503640944

Epoch: 6| Step: 7
Training loss: 1.9067708253860474
Validation loss: 1.8960555240672121

Epoch: 6| Step: 8
Training loss: 1.7270299196243286
Validation loss: 1.883407110808998

Epoch: 6| Step: 9
Training loss: 1.612396478652954
Validation loss: 1.8789500087820075

Epoch: 6| Step: 10
Training loss: 1.5009065866470337
Validation loss: 1.875817355289254

Epoch: 6| Step: 11
Training loss: 1.8281570672988892
Validation loss: 1.860463705114139

Epoch: 6| Step: 12
Training loss: 2.0376241207122803
Validation loss: 1.8611893474414785

Epoch: 6| Step: 13
Training loss: 1.2142226696014404
Validation loss: 1.86390971496541

Epoch: 181| Step: 0
Training loss: 2.3512814044952393
Validation loss: 1.871513578199571

Epoch: 6| Step: 1
Training loss: 1.3805179595947266
Validation loss: 1.8769834221050303

Epoch: 6| Step: 2
Training loss: 1.4776709079742432
Validation loss: 1.8632363760343162

Epoch: 6| Step: 3
Training loss: 1.2635066509246826
Validation loss: 1.8649615421090076

Epoch: 6| Step: 4
Training loss: 1.6691639423370361
Validation loss: 1.8611667233128701

Epoch: 6| Step: 5
Training loss: 1.0235289335250854
Validation loss: 1.8668036383967246

Epoch: 6| Step: 6
Training loss: 2.3370540142059326
Validation loss: 1.880373122871563

Epoch: 6| Step: 7
Training loss: 2.1954798698425293
Validation loss: 1.8957460862334057

Epoch: 6| Step: 8
Training loss: 2.07456636428833
Validation loss: 1.9273539102205666

Epoch: 6| Step: 9
Training loss: 1.426110029220581
Validation loss: 1.9368336969806301

Epoch: 6| Step: 10
Training loss: 1.6862175464630127
Validation loss: 1.9188287834967337

Epoch: 6| Step: 11
Training loss: 1.3284705877304077
Validation loss: 1.8986140246032386

Epoch: 6| Step: 12
Training loss: 2.511026382446289
Validation loss: 1.891195233150195

Epoch: 6| Step: 13
Training loss: 2.247363328933716
Validation loss: 1.8583512613850255

Epoch: 182| Step: 0
Training loss: 2.322014331817627
Validation loss: 1.8335698420001614

Epoch: 6| Step: 1
Training loss: 1.6909830570220947
Validation loss: 1.813462918804538

Epoch: 6| Step: 2
Training loss: 2.2423834800720215
Validation loss: 1.811279640402845

Epoch: 6| Step: 3
Training loss: 1.4094719886779785
Validation loss: 1.809055741115283

Epoch: 6| Step: 4
Training loss: 1.8529282808303833
Validation loss: 1.8331253733686221

Epoch: 6| Step: 5
Training loss: 1.238180160522461
Validation loss: 1.838156287388135

Epoch: 6| Step: 6
Training loss: 1.8766731023788452
Validation loss: 1.8478619360154676

Epoch: 6| Step: 7
Training loss: 1.5913033485412598
Validation loss: 1.818558692932129

Epoch: 6| Step: 8
Training loss: 2.786342144012451
Validation loss: 1.8082148849323232

Epoch: 6| Step: 9
Training loss: 1.653212547302246
Validation loss: 1.831228603598892

Epoch: 6| Step: 10
Training loss: 1.205538272857666
Validation loss: 1.858947438578452

Epoch: 6| Step: 11
Training loss: 2.0244879722595215
Validation loss: 1.8588578060109129

Epoch: 6| Step: 12
Training loss: 1.4088151454925537
Validation loss: 1.854442629762875

Epoch: 6| Step: 13
Training loss: 1.29590904712677
Validation loss: 1.8630649556395829

Epoch: 183| Step: 0
Training loss: 1.424025058746338
Validation loss: 1.8845311518638366

Epoch: 6| Step: 1
Training loss: 1.8268929719924927
Validation loss: 1.9142658338751843

Epoch: 6| Step: 2
Training loss: 1.6508269309997559
Validation loss: 1.910387928767871

Epoch: 6| Step: 3
Training loss: 2.129310369491577
Validation loss: 1.9032783431391562

Epoch: 6| Step: 4
Training loss: 2.0535669326782227
Validation loss: 1.895380707197292

Epoch: 6| Step: 5
Training loss: 1.657740592956543
Validation loss: 1.8938331193821405

Epoch: 6| Step: 6
Training loss: 2.0037126541137695
Validation loss: 1.8765192749679729

Epoch: 6| Step: 7
Training loss: 1.290611743927002
Validation loss: 1.8662327361363236

Epoch: 6| Step: 8
Training loss: 1.5172957181930542
Validation loss: 1.8457694181831934

Epoch: 6| Step: 9
Training loss: 1.504716396331787
Validation loss: 1.8574946631667435

Epoch: 6| Step: 10
Training loss: 1.9766323566436768
Validation loss: 1.8794861506390315

Epoch: 6| Step: 11
Training loss: 2.2230215072631836
Validation loss: 1.9174230675543509

Epoch: 6| Step: 12
Training loss: 2.0155670642852783
Validation loss: 1.941515379054572

Epoch: 6| Step: 13
Training loss: 1.935587763786316
Validation loss: 1.92415641584704

Epoch: 184| Step: 0
Training loss: 1.4022741317749023
Validation loss: 1.9634600980307466

Epoch: 6| Step: 1
Training loss: 2.047764539718628
Validation loss: 1.9835044850585282

Epoch: 6| Step: 2
Training loss: 1.3611910343170166
Validation loss: 2.010188651341264

Epoch: 6| Step: 3
Training loss: 1.5113487243652344
Validation loss: 2.015709073312821

Epoch: 6| Step: 4
Training loss: 1.9481041431427002
Validation loss: 2.044961388393115

Epoch: 6| Step: 5
Training loss: 1.8712553977966309
Validation loss: 1.9996877703615414

Epoch: 6| Step: 6
Training loss: 2.0735743045806885
Validation loss: 1.9749426816099434

Epoch: 6| Step: 7
Training loss: 1.456187129020691
Validation loss: 1.9280890111000306

Epoch: 6| Step: 8
Training loss: 1.6500890254974365
Validation loss: 1.8941959386230798

Epoch: 6| Step: 9
Training loss: 1.9306262731552124
Validation loss: 1.8630859057108562

Epoch: 6| Step: 10
Training loss: 1.5081913471221924
Validation loss: 1.8532718766120173

Epoch: 6| Step: 11
Training loss: 2.0239086151123047
Validation loss: 1.8562394957388602

Epoch: 6| Step: 12
Training loss: 2.367387294769287
Validation loss: 1.8413268430258638

Epoch: 6| Step: 13
Training loss: 1.431404709815979
Validation loss: 1.8297462130105624

Epoch: 185| Step: 0
Training loss: 1.8583643436431885
Validation loss: 1.8244582811991374

Epoch: 6| Step: 1
Training loss: 1.547588586807251
Validation loss: 1.8135491442936722

Epoch: 6| Step: 2
Training loss: 1.5280948877334595
Validation loss: 1.7925196488698323

Epoch: 6| Step: 3
Training loss: 1.9108505249023438
Validation loss: 1.8106559463726577

Epoch: 6| Step: 4
Training loss: 1.5702810287475586
Validation loss: 1.8119052110179779

Epoch: 6| Step: 5
Training loss: 1.8454747200012207
Validation loss: 1.8076085429037771

Epoch: 6| Step: 6
Training loss: 1.4454325437545776
Validation loss: 1.8210658565644295

Epoch: 6| Step: 7
Training loss: 1.6638227701187134
Validation loss: 1.8562796051784227

Epoch: 6| Step: 8
Training loss: 2.010556697845459
Validation loss: 1.8830273382125362

Epoch: 6| Step: 9
Training loss: 1.5032185316085815
Validation loss: 1.8907343738822526

Epoch: 6| Step: 10
Training loss: 1.9261723756790161
Validation loss: 1.9062684787217008

Epoch: 6| Step: 11
Training loss: 1.4794776439666748
Validation loss: 1.9224993541676512

Epoch: 6| Step: 12
Training loss: 2.037426710128784
Validation loss: 1.926427254112818

Epoch: 6| Step: 13
Training loss: 1.7534993886947632
Validation loss: 1.9276251587816464

Epoch: 186| Step: 0
Training loss: 1.0388097763061523
Validation loss: 1.902210218932039

Epoch: 6| Step: 1
Training loss: 1.9042447805404663
Validation loss: 1.9168271159613004

Epoch: 6| Step: 2
Training loss: 1.7951483726501465
Validation loss: 1.9137714075785812

Epoch: 6| Step: 3
Training loss: 1.6769545078277588
Validation loss: 1.923673810497407

Epoch: 6| Step: 4
Training loss: 2.1266891956329346
Validation loss: 1.9126436518084617

Epoch: 6| Step: 5
Training loss: 1.585843801498413
Validation loss: 1.8889703494246288

Epoch: 6| Step: 6
Training loss: 1.9136509895324707
Validation loss: 1.8693907286531182

Epoch: 6| Step: 7
Training loss: 1.604938268661499
Validation loss: 1.8602616017864597

Epoch: 6| Step: 8
Training loss: 1.8453693389892578
Validation loss: 1.8622298471389278

Epoch: 6| Step: 9
Training loss: 1.5619529485702515
Validation loss: 1.8471086204692881

Epoch: 6| Step: 10
Training loss: 1.4670228958129883
Validation loss: 1.8447631584700717

Epoch: 6| Step: 11
Training loss: 1.5791666507720947
Validation loss: 1.8585174506710422

Epoch: 6| Step: 12
Training loss: 1.9913688898086548
Validation loss: 1.8641849922877487

Epoch: 6| Step: 13
Training loss: 2.177337169647217
Validation loss: 1.8743177126812678

Epoch: 187| Step: 0
Training loss: 2.110304117202759
Validation loss: 1.8916409015655518

Epoch: 6| Step: 1
Training loss: 1.5085015296936035
Validation loss: 1.9133343478684783

Epoch: 6| Step: 2
Training loss: 1.2795779705047607
Validation loss: 1.9038443206458964

Epoch: 6| Step: 3
Training loss: 1.7399396896362305
Validation loss: 1.9000743781366656

Epoch: 6| Step: 4
Training loss: 0.8287034034729004
Validation loss: 1.9025224729250836

Epoch: 6| Step: 5
Training loss: 1.9623476266860962
Validation loss: 1.8871086438496907

Epoch: 6| Step: 6
Training loss: 2.9254560470581055
Validation loss: 1.8607935674728886

Epoch: 6| Step: 7
Training loss: 1.652402400970459
Validation loss: 1.858740088760212

Epoch: 6| Step: 8
Training loss: 1.2930201292037964
Validation loss: 1.85923324349106

Epoch: 6| Step: 9
Training loss: 1.818852424621582
Validation loss: 1.8409852622657694

Epoch: 6| Step: 10
Training loss: 2.0543558597564697
Validation loss: 1.8467242346015027

Epoch: 6| Step: 11
Training loss: 1.8361625671386719
Validation loss: 1.836643321539766

Epoch: 6| Step: 12
Training loss: 1.5916906595230103
Validation loss: 1.8598219130628852

Epoch: 6| Step: 13
Training loss: 1.0859375
Validation loss: 1.8823752890350998

Epoch: 188| Step: 0
Training loss: 2.021637439727783
Validation loss: 1.9146327921139297

Epoch: 6| Step: 1
Training loss: 1.4597973823547363
Validation loss: 1.9388259508276497

Epoch: 6| Step: 2
Training loss: 1.4105886220932007
Validation loss: 1.9662260188851306

Epoch: 6| Step: 3
Training loss: 2.1687960624694824
Validation loss: 1.9741532315490067

Epoch: 6| Step: 4
Training loss: 1.303899884223938
Validation loss: 1.9455623908709454

Epoch: 6| Step: 5
Training loss: 1.8625038862228394
Validation loss: 1.937907306096887

Epoch: 6| Step: 6
Training loss: 1.8436089754104614
Validation loss: 1.927841983815675

Epoch: 6| Step: 7
Training loss: 1.2629351615905762
Validation loss: 1.9147393344551005

Epoch: 6| Step: 8
Training loss: 1.3017477989196777
Validation loss: 1.9063189106602823

Epoch: 6| Step: 9
Training loss: 1.920233130455017
Validation loss: 1.8896544710282357

Epoch: 6| Step: 10
Training loss: 2.063237190246582
Validation loss: 1.8739374260748587

Epoch: 6| Step: 11
Training loss: 1.9481511116027832
Validation loss: 1.8830981523759904

Epoch: 6| Step: 12
Training loss: 1.0016688108444214
Validation loss: 1.8726855990707234

Epoch: 6| Step: 13
Training loss: 2.0700886249542236
Validation loss: 1.8683891309204923

Epoch: 189| Step: 0
Training loss: 2.2446093559265137
Validation loss: 1.8628014377368394

Epoch: 6| Step: 1
Training loss: 1.3144365549087524
Validation loss: 1.8482209059499926

Epoch: 6| Step: 2
Training loss: 1.6019763946533203
Validation loss: 1.8315327693057317

Epoch: 6| Step: 3
Training loss: 1.3898341655731201
Validation loss: 1.8184633716460197

Epoch: 6| Step: 4
Training loss: 1.6573741436004639
Validation loss: 1.8236552848610827

Epoch: 6| Step: 5
Training loss: 2.144657611846924
Validation loss: 1.8511780705503238

Epoch: 6| Step: 6
Training loss: 1.744033932685852
Validation loss: 1.8828236390185613

Epoch: 6| Step: 7
Training loss: 1.7994242906570435
Validation loss: 1.9177825809806905

Epoch: 6| Step: 8
Training loss: 0.8865250945091248
Validation loss: 1.9581285138284006

Epoch: 6| Step: 9
Training loss: 1.928067922592163
Validation loss: 1.9531006928413146

Epoch: 6| Step: 10
Training loss: 1.6344175338745117
Validation loss: 1.9345911049073743

Epoch: 6| Step: 11
Training loss: 1.415547251701355
Validation loss: 1.928336795940194

Epoch: 6| Step: 12
Training loss: 1.642301321029663
Validation loss: 1.9586678089634064

Epoch: 6| Step: 13
Training loss: 2.7070956230163574
Validation loss: 1.9472843267584359

Epoch: 190| Step: 0
Training loss: 2.0048670768737793
Validation loss: 1.971153240050039

Epoch: 6| Step: 1
Training loss: 1.677159309387207
Validation loss: 1.9499609290912587

Epoch: 6| Step: 2
Training loss: 1.6955924034118652
Validation loss: 1.9196198563421927

Epoch: 6| Step: 3
Training loss: 1.898343563079834
Validation loss: 1.896714202819332

Epoch: 6| Step: 4
Training loss: 1.652848720550537
Validation loss: 1.909009607889319

Epoch: 6| Step: 5
Training loss: 1.1139172315597534
Validation loss: 1.9101264733140186

Epoch: 6| Step: 6
Training loss: 2.007580041885376
Validation loss: 1.9040727705083869

Epoch: 6| Step: 7
Training loss: 1.5864970684051514
Validation loss: 1.893002272934042

Epoch: 6| Step: 8
Training loss: 1.6930434703826904
Validation loss: 1.8770055732419413

Epoch: 6| Step: 9
Training loss: 2.3408496379852295
Validation loss: 1.8739402114704091

Epoch: 6| Step: 10
Training loss: 1.3147372007369995
Validation loss: 1.8746338146989063

Epoch: 6| Step: 11
Training loss: 1.262037992477417
Validation loss: 1.8940487484778128

Epoch: 6| Step: 12
Training loss: 1.2753896713256836
Validation loss: 1.89762500280975

Epoch: 6| Step: 13
Training loss: 2.1296539306640625
Validation loss: 1.9184538074719009

Epoch: 191| Step: 0
Training loss: 0.7471903562545776
Validation loss: 1.9435953927296463

Epoch: 6| Step: 1
Training loss: 2.2561302185058594
Validation loss: 1.950957936625327

Epoch: 6| Step: 2
Training loss: 1.4150526523590088
Validation loss: 1.9877208855844313

Epoch: 6| Step: 3
Training loss: 2.635148525238037
Validation loss: 1.9810736602352512

Epoch: 6| Step: 4
Training loss: 2.2385168075561523
Validation loss: 1.9504422615933161

Epoch: 6| Step: 5
Training loss: 1.601945400238037
Validation loss: 1.908292934458743

Epoch: 6| Step: 6
Training loss: 0.9477217793464661
Validation loss: 1.9064890364164948

Epoch: 6| Step: 7
Training loss: 1.3782930374145508
Validation loss: 1.8806880956055017

Epoch: 6| Step: 8
Training loss: 1.5010379552841187
Validation loss: 1.8939438494302894

Epoch: 6| Step: 9
Training loss: 1.1416181325912476
Validation loss: 1.8776190639823995

Epoch: 6| Step: 10
Training loss: 1.7760083675384521
Validation loss: 1.8876155691762124

Epoch: 6| Step: 11
Training loss: 1.91141939163208
Validation loss: 1.8780310000142744

Epoch: 6| Step: 12
Training loss: 1.804818868637085
Validation loss: 1.8778746845901653

Epoch: 6| Step: 13
Training loss: 1.592037320137024
Validation loss: 1.8615019411169074

Epoch: 192| Step: 0
Training loss: 1.7301052808761597
Validation loss: 1.8657488310208885

Epoch: 6| Step: 1
Training loss: 1.5719184875488281
Validation loss: 1.8538435864192184

Epoch: 6| Step: 2
Training loss: 2.0322585105895996
Validation loss: 1.8736593236205399

Epoch: 6| Step: 3
Training loss: 1.4417142868041992
Validation loss: 1.8860128182236866

Epoch: 6| Step: 4
Training loss: 1.4086620807647705
Validation loss: 1.8681976103013562

Epoch: 6| Step: 5
Training loss: 2.03357195854187
Validation loss: 1.90505063661965

Epoch: 6| Step: 6
Training loss: 2.095609426498413
Validation loss: 1.9558948829609861

Epoch: 6| Step: 7
Training loss: 1.413391351699829
Validation loss: 1.9804272049216813

Epoch: 6| Step: 8
Training loss: 0.8540976643562317
Validation loss: 1.9737445731316843

Epoch: 6| Step: 9
Training loss: 1.6369199752807617
Validation loss: 1.9852432409922283

Epoch: 6| Step: 10
Training loss: 1.5693981647491455
Validation loss: 1.9823080493557839

Epoch: 6| Step: 11
Training loss: 1.9916338920593262
Validation loss: 1.9668331928150629

Epoch: 6| Step: 12
Training loss: 1.4834105968475342
Validation loss: 1.9533693995527042

Epoch: 6| Step: 13
Training loss: 1.9768401384353638
Validation loss: 1.9172886110121203

Epoch: 193| Step: 0
Training loss: 1.560690999031067
Validation loss: 1.8994721917695896

Epoch: 6| Step: 1
Training loss: 2.7047390937805176
Validation loss: 1.8882204871023855

Epoch: 6| Step: 2
Training loss: 1.3909969329833984
Validation loss: 1.834375048196444

Epoch: 6| Step: 3
Training loss: 1.7636420726776123
Validation loss: 1.835236846759755

Epoch: 6| Step: 4
Training loss: 1.9250482320785522
Validation loss: 1.8237366830149004

Epoch: 6| Step: 5
Training loss: 1.0063284635543823
Validation loss: 1.834948259015237

Epoch: 6| Step: 6
Training loss: 1.5387336015701294
Validation loss: 1.8253549401478102

Epoch: 6| Step: 7
Training loss: 1.2491822242736816
Validation loss: 1.8420365574539348

Epoch: 6| Step: 8
Training loss: 1.8194494247436523
Validation loss: 1.8348519571365849

Epoch: 6| Step: 9
Training loss: 1.4767124652862549
Validation loss: 1.858140553197553

Epoch: 6| Step: 10
Training loss: 1.4789916276931763
Validation loss: 1.884420484624883

Epoch: 6| Step: 11
Training loss: 1.190324306488037
Validation loss: 1.9296674164392615

Epoch: 6| Step: 12
Training loss: 1.753387689590454
Validation loss: 1.9602685128488848

Epoch: 6| Step: 13
Training loss: 1.4360321760177612
Validation loss: 1.9722277989951513

Epoch: 194| Step: 0
Training loss: 1.9900685548782349
Validation loss: 1.9829507181721349

Epoch: 6| Step: 1
Training loss: 1.1885037422180176
Validation loss: 1.971942493992467

Epoch: 6| Step: 2
Training loss: 1.4962667226791382
Validation loss: 1.9516254778831237

Epoch: 6| Step: 3
Training loss: 1.5891163349151611
Validation loss: 1.9643683023350214

Epoch: 6| Step: 4
Training loss: 1.41139554977417
Validation loss: 1.9395912770302064

Epoch: 6| Step: 5
Training loss: 1.2000675201416016
Validation loss: 1.9214607618188346

Epoch: 6| Step: 6
Training loss: 0.9599079489707947
Validation loss: 1.9270905076816518

Epoch: 6| Step: 7
Training loss: 1.7411022186279297
Validation loss: 1.9051489009652087

Epoch: 6| Step: 8
Training loss: 1.7338430881500244
Validation loss: 1.9093240512314664

Epoch: 6| Step: 9
Training loss: 1.2461203336715698
Validation loss: 1.9223745625506166

Epoch: 6| Step: 10
Training loss: 2.1511828899383545
Validation loss: 1.9296514885399931

Epoch: 6| Step: 11
Training loss: 2.0698294639587402
Validation loss: 1.9032069431838168

Epoch: 6| Step: 12
Training loss: 1.6216262578964233
Validation loss: 1.8767989002248293

Epoch: 6| Step: 13
Training loss: 2.0580759048461914
Validation loss: 1.8355352827297744

Epoch: 195| Step: 0
Training loss: 1.412975788116455
Validation loss: 1.863771088661686

Epoch: 6| Step: 1
Training loss: 1.3658121824264526
Validation loss: 1.879033186102426

Epoch: 6| Step: 2
Training loss: 2.23953914642334
Validation loss: 1.9170061824142293

Epoch: 6| Step: 3
Training loss: 1.4555160999298096
Validation loss: 1.9188205734375985

Epoch: 6| Step: 4
Training loss: 1.5855803489685059
Validation loss: 1.9160675643592753

Epoch: 6| Step: 5
Training loss: 1.6154365539550781
Validation loss: 1.914128162527597

Epoch: 6| Step: 6
Training loss: 1.2373875379562378
Validation loss: 1.8914312098615913

Epoch: 6| Step: 7
Training loss: 1.0003101825714111
Validation loss: 1.918617046007546

Epoch: 6| Step: 8
Training loss: 2.136183977127075
Validation loss: 1.9558292255606702

Epoch: 6| Step: 9
Training loss: 1.4309501647949219
Validation loss: 1.992352121619768

Epoch: 6| Step: 10
Training loss: 1.3261646032333374
Validation loss: 2.0023200973387687

Epoch: 6| Step: 11
Training loss: 1.7430989742279053
Validation loss: 1.9936830433466102

Epoch: 6| Step: 12
Training loss: 2.171076774597168
Validation loss: 1.9544935354622461

Epoch: 6| Step: 13
Training loss: 1.8671777248382568
Validation loss: 1.912359860635573

Epoch: 196| Step: 0
Training loss: 1.3437135219573975
Validation loss: 1.8864407359912831

Epoch: 6| Step: 1
Training loss: 2.45748233795166
Validation loss: 1.906752928610771

Epoch: 6| Step: 2
Training loss: 1.6210979223251343
Validation loss: 1.9023715462735904

Epoch: 6| Step: 3
Training loss: 1.477586030960083
Validation loss: 1.901920650594978

Epoch: 6| Step: 4
Training loss: 2.1441879272460938
Validation loss: 1.8841585484884118

Epoch: 6| Step: 5
Training loss: 1.150721549987793
Validation loss: 1.8662710318001368

Epoch: 6| Step: 6
Training loss: 1.0065076351165771
Validation loss: 1.8594674692359021

Epoch: 6| Step: 7
Training loss: 1.365786075592041
Validation loss: 1.865344956356992

Epoch: 6| Step: 8
Training loss: 1.5110437870025635
Validation loss: 1.8805104455640238

Epoch: 6| Step: 9
Training loss: 1.2449226379394531
Validation loss: 1.8961574287824734

Epoch: 6| Step: 10
Training loss: 1.875993251800537
Validation loss: 1.9229470452954691

Epoch: 6| Step: 11
Training loss: 1.4813274145126343
Validation loss: 1.9310906689654115

Epoch: 6| Step: 12
Training loss: 1.5816283226013184
Validation loss: 1.926438808441162

Epoch: 6| Step: 13
Training loss: 1.4660696983337402
Validation loss: 1.907551516768753

Epoch: 197| Step: 0
Training loss: 1.7060410976409912
Validation loss: 1.9186468585844962

Epoch: 6| Step: 1
Training loss: 0.7670325636863708
Validation loss: 1.8956670145834646

Epoch: 6| Step: 2
Training loss: 1.8801320791244507
Validation loss: 1.893421556359978

Epoch: 6| Step: 3
Training loss: 1.7168275117874146
Validation loss: 1.8695311879598966

Epoch: 6| Step: 4
Training loss: 1.5250369310379028
Validation loss: 1.8714153189812937

Epoch: 6| Step: 5
Training loss: 1.3347184658050537
Validation loss: 1.8486687162871003

Epoch: 6| Step: 6
Training loss: 1.6932802200317383
Validation loss: 1.8563178752058296

Epoch: 6| Step: 7
Training loss: 1.7066876888275146
Validation loss: 1.8706832034613496

Epoch: 6| Step: 8
Training loss: 1.6079872846603394
Validation loss: 1.8688730552632322

Epoch: 6| Step: 9
Training loss: 1.8983796834945679
Validation loss: 1.8800349876444826

Epoch: 6| Step: 10
Training loss: 1.816393256187439
Validation loss: 1.886458840421451

Epoch: 6| Step: 11
Training loss: 1.0100680589675903
Validation loss: 1.9232654725351641

Epoch: 6| Step: 12
Training loss: 1.0854823589324951
Validation loss: 1.9164646466573079

Epoch: 6| Step: 13
Training loss: 1.973501443862915
Validation loss: 1.9157772423118673

Epoch: 198| Step: 0
Training loss: 1.4926685094833374
Validation loss: 1.9384455373210292

Epoch: 6| Step: 1
Training loss: 1.3148536682128906
Validation loss: 1.9010521481114049

Epoch: 6| Step: 2
Training loss: 1.3166825771331787
Validation loss: 1.8576374002682265

Epoch: 6| Step: 3
Training loss: 1.1116348505020142
Validation loss: 1.8329423576272943

Epoch: 6| Step: 4
Training loss: 2.0707004070281982
Validation loss: 1.8102872102491316

Epoch: 6| Step: 5
Training loss: 1.6063309907913208
Validation loss: 1.8077832498858053

Epoch: 6| Step: 6
Training loss: 1.1845463514328003
Validation loss: 1.831471590585606

Epoch: 6| Step: 7
Training loss: 1.1307930946350098
Validation loss: 1.8440585008231543

Epoch: 6| Step: 8
Training loss: 1.913284420967102
Validation loss: 1.890628496805827

Epoch: 6| Step: 9
Training loss: 1.455843448638916
Validation loss: 1.888913954457929

Epoch: 6| Step: 10
Training loss: 1.942668080329895
Validation loss: 1.9158319516848492

Epoch: 6| Step: 11
Training loss: 1.995210886001587
Validation loss: 1.9202492006363407

Epoch: 6| Step: 12
Training loss: 1.5556509494781494
Validation loss: 1.9310809079036917

Epoch: 6| Step: 13
Training loss: 1.1395795345306396
Validation loss: 1.9302466338680637

Epoch: 199| Step: 0
Training loss: 2.341911554336548
Validation loss: 1.9253332384171025

Epoch: 6| Step: 1
Training loss: 1.2315880060195923
Validation loss: 1.9619392643692672

Epoch: 6| Step: 2
Training loss: 1.0685335397720337
Validation loss: 1.9803217200822727

Epoch: 6| Step: 3
Training loss: 1.4414602518081665
Validation loss: 1.9729719623442619

Epoch: 6| Step: 4
Training loss: 1.3694863319396973
Validation loss: 1.9313821972057383

Epoch: 6| Step: 5
Training loss: 1.464118480682373
Validation loss: 1.9378516981678624

Epoch: 6| Step: 6
Training loss: 2.0528695583343506
Validation loss: 1.9006150204648253

Epoch: 6| Step: 7
Training loss: 1.625038981437683
Validation loss: 1.91946852848094

Epoch: 6| Step: 8
Training loss: 1.6930155754089355
Validation loss: 1.9117374907257736

Epoch: 6| Step: 9
Training loss: 1.4805731773376465
Validation loss: 1.8844581598876624

Epoch: 6| Step: 10
Training loss: 1.3955631256103516
Validation loss: 1.8721905357094222

Epoch: 6| Step: 11
Training loss: 1.8751556873321533
Validation loss: 1.841018743412469

Epoch: 6| Step: 12
Training loss: 0.9769273400306702
Validation loss: 1.882275051968072

Epoch: 6| Step: 13
Training loss: 1.3346631526947021
Validation loss: 1.8932159177718624

Epoch: 200| Step: 0
Training loss: 1.6640369892120361
Validation loss: 1.915405361883102

Epoch: 6| Step: 1
Training loss: 0.9361713528633118
Validation loss: 1.934373499244772

Epoch: 6| Step: 2
Training loss: 1.374894142150879
Validation loss: 1.9292675141365296

Epoch: 6| Step: 3
Training loss: 1.2172887325286865
Validation loss: 1.9073087784551805

Epoch: 6| Step: 4
Training loss: 1.70772123336792
Validation loss: 1.8801969648689352

Epoch: 6| Step: 5
Training loss: 1.8738656044006348
Validation loss: 1.9138939688282628

Epoch: 6| Step: 6
Training loss: 1.8095297813415527
Validation loss: 1.9412028071700886

Epoch: 6| Step: 7
Training loss: 1.8922252655029297
Validation loss: 1.967805439426053

Epoch: 6| Step: 8
Training loss: 1.5699410438537598
Validation loss: 1.9571562377355431

Epoch: 6| Step: 9
Training loss: 1.2013493776321411
Validation loss: 1.9213011187891806

Epoch: 6| Step: 10
Training loss: 1.510428547859192
Validation loss: 1.8570280985165668

Epoch: 6| Step: 11
Training loss: 1.7716864347457886
Validation loss: 1.862514695813579

Epoch: 6| Step: 12
Training loss: 1.706571340560913
Validation loss: 1.856463368220996

Epoch: 6| Step: 13
Training loss: 1.0944675207138062
Validation loss: 1.849990685780843

Epoch: 201| Step: 0
Training loss: 1.8841617107391357
Validation loss: 1.8208900036350373

Epoch: 6| Step: 1
Training loss: 1.5696252584457397
Validation loss: 1.7938006898408294

Epoch: 6| Step: 2
Training loss: 1.4069843292236328
Validation loss: 1.7937367475160988

Epoch: 6| Step: 3
Training loss: 1.3915115594863892
Validation loss: 1.8028474584702523

Epoch: 6| Step: 4
Training loss: 1.9274585247039795
Validation loss: 1.840658926194714

Epoch: 6| Step: 5
Training loss: 1.4246742725372314
Validation loss: 1.893429248563705

Epoch: 6| Step: 6
Training loss: 0.965467095375061
Validation loss: 1.9186789438288698

Epoch: 6| Step: 7
Training loss: 2.0361859798431396
Validation loss: 1.9332626442755423

Epoch: 6| Step: 8
Training loss: 1.0245320796966553
Validation loss: 1.9687809969789238

Epoch: 6| Step: 9
Training loss: 1.1579149961471558
Validation loss: 1.9814258416493733

Epoch: 6| Step: 10
Training loss: 1.705857276916504
Validation loss: 1.994583527247111

Epoch: 6| Step: 11
Training loss: 2.281822919845581
Validation loss: 1.9789296004080004

Epoch: 6| Step: 12
Training loss: 1.2394239902496338
Validation loss: 1.9305228033373434

Epoch: 6| Step: 13
Training loss: 1.5948232412338257
Validation loss: 1.8964620418446039

Epoch: 202| Step: 0
Training loss: 1.269719123840332
Validation loss: 1.8668871028448946

Epoch: 6| Step: 1
Training loss: 1.4883067607879639
Validation loss: 1.8514889901684177

Epoch: 6| Step: 2
Training loss: 1.3583319187164307
Validation loss: 1.858060972664946

Epoch: 6| Step: 3
Training loss: 0.8714008927345276
Validation loss: 1.8889016848738476

Epoch: 6| Step: 4
Training loss: 2.0344552993774414
Validation loss: 1.89574856399208

Epoch: 6| Step: 5
Training loss: 1.1395272016525269
Validation loss: 1.9333713849385579

Epoch: 6| Step: 6
Training loss: 1.7315073013305664
Validation loss: 1.9643810577290033

Epoch: 6| Step: 7
Training loss: 1.7441956996917725
Validation loss: 2.010117066803799

Epoch: 6| Step: 8
Training loss: 1.003695011138916
Validation loss: 2.030687685935728

Epoch: 6| Step: 9
Training loss: 1.8035136461257935
Validation loss: 2.0190616051355996

Epoch: 6| Step: 10
Training loss: 1.6497470140457153
Validation loss: 1.9332315562873759

Epoch: 6| Step: 11
Training loss: 1.9928419589996338
Validation loss: 1.8798772686271257

Epoch: 6| Step: 12
Training loss: 1.869668960571289
Validation loss: 1.8344804061356412

Epoch: 6| Step: 13
Training loss: 0.7854321599006653
Validation loss: 1.82187395967463

Epoch: 203| Step: 0
Training loss: 1.4612075090408325
Validation loss: 1.816036303838094

Epoch: 6| Step: 1
Training loss: 1.503493070602417
Validation loss: 1.8308971851102767

Epoch: 6| Step: 2
Training loss: 1.4695863723754883
Validation loss: 1.829594155793549

Epoch: 6| Step: 3
Training loss: 1.4992620944976807
Validation loss: 1.8458884281496848

Epoch: 6| Step: 4
Training loss: 1.7809253931045532
Validation loss: 1.8737625383561658

Epoch: 6| Step: 5
Training loss: 1.1724700927734375
Validation loss: 1.8767155216586204

Epoch: 6| Step: 6
Training loss: 1.5981314182281494
Validation loss: 1.8910015693274878

Epoch: 6| Step: 7
Training loss: 1.4739322662353516
Validation loss: 1.900054794485851

Epoch: 6| Step: 8
Training loss: 1.595376968383789
Validation loss: 1.8859033738413165

Epoch: 6| Step: 9
Training loss: 1.090297818183899
Validation loss: 1.9006351578620173

Epoch: 6| Step: 10
Training loss: 1.6661837100982666
Validation loss: 1.8801328161711335

Epoch: 6| Step: 11
Training loss: 1.5447425842285156
Validation loss: 1.8680794879954348

Epoch: 6| Step: 12
Training loss: 1.8014715909957886
Validation loss: 1.8667833984539073

Epoch: 6| Step: 13
Training loss: 1.4111618995666504
Validation loss: 1.861594674407795

Epoch: 204| Step: 0
Training loss: 1.4116235971450806
Validation loss: 1.8535289110675934

Epoch: 6| Step: 1
Training loss: 1.5627152919769287
Validation loss: 1.8679669313533331

Epoch: 6| Step: 2
Training loss: 1.0369713306427002
Validation loss: 1.8647323269997873

Epoch: 6| Step: 3
Training loss: 1.124335527420044
Validation loss: 1.878600335890247

Epoch: 6| Step: 4
Training loss: 1.3153254985809326
Validation loss: 1.8976453837528025

Epoch: 6| Step: 5
Training loss: 1.6048146486282349
Validation loss: 1.9116148153940837

Epoch: 6| Step: 6
Training loss: 1.6298820972442627
Validation loss: 1.899474415727841

Epoch: 6| Step: 7
Training loss: 1.4934895038604736
Validation loss: 1.8878466967613465

Epoch: 6| Step: 8
Training loss: 1.8241262435913086
Validation loss: 1.877249160120564

Epoch: 6| Step: 9
Training loss: 1.4912774562835693
Validation loss: 1.8504784901936848

Epoch: 6| Step: 10
Training loss: 1.3757476806640625
Validation loss: 1.8383854422518002

Epoch: 6| Step: 11
Training loss: 1.385500192642212
Validation loss: 1.8782112495873564

Epoch: 6| Step: 12
Training loss: 1.7113561630249023
Validation loss: 1.877138836409456

Epoch: 6| Step: 13
Training loss: 1.5935064554214478
Validation loss: 1.9075183176225232

Epoch: 205| Step: 0
Training loss: 0.9777853488922119
Validation loss: 1.9339364369710286

Epoch: 6| Step: 1
Training loss: 1.4500014781951904
Validation loss: 1.962456815986223

Epoch: 6| Step: 2
Training loss: 1.1537224054336548
Validation loss: 1.9542225330106673

Epoch: 6| Step: 3
Training loss: 2.0049941539764404
Validation loss: 1.947315962083878

Epoch: 6| Step: 4
Training loss: 1.3723552227020264
Validation loss: 1.9172409606236283

Epoch: 6| Step: 5
Training loss: 1.188868761062622
Validation loss: 1.9285482950108026

Epoch: 6| Step: 6
Training loss: 1.3751521110534668
Validation loss: 1.9055211902946554

Epoch: 6| Step: 7
Training loss: 1.7108943462371826
Validation loss: 1.8975233877858808

Epoch: 6| Step: 8
Training loss: 1.6177196502685547
Validation loss: 1.885578957937097

Epoch: 6| Step: 9
Training loss: 1.609147548675537
Validation loss: 1.8622597212432532

Epoch: 6| Step: 10
Training loss: 1.4300875663757324
Validation loss: 1.8405133383248442

Epoch: 6| Step: 11
Training loss: 1.7825024127960205
Validation loss: 1.8302073491516935

Epoch: 6| Step: 12
Training loss: 1.3020051717758179
Validation loss: 1.8693580576168594

Epoch: 6| Step: 13
Training loss: 1.2124090194702148
Validation loss: 1.8922820155338576

Epoch: 206| Step: 0
Training loss: 1.6845955848693848
Validation loss: 1.9384293094758065

Epoch: 6| Step: 1
Training loss: 1.5161008834838867
Validation loss: 1.9888500526387205

Epoch: 6| Step: 2
Training loss: 0.7959723472595215
Validation loss: 2.0374148596999464

Epoch: 6| Step: 3
Training loss: 1.5753614902496338
Validation loss: 2.092382718158025

Epoch: 6| Step: 4
Training loss: 1.7644184827804565
Validation loss: 2.114026202950426

Epoch: 6| Step: 5
Training loss: 1.3695141077041626
Validation loss: 2.0949830983274724

Epoch: 6| Step: 6
Training loss: 1.4573121070861816
Validation loss: 2.038585538505226

Epoch: 6| Step: 7
Training loss: 1.768088698387146
Validation loss: 1.9887742406578475

Epoch: 6| Step: 8
Training loss: 1.379981279373169
Validation loss: 1.9403455462507022

Epoch: 6| Step: 9
Training loss: 0.8268760442733765
Validation loss: 1.867853860701284

Epoch: 6| Step: 10
Training loss: 2.078986406326294
Validation loss: 1.8503881910795807

Epoch: 6| Step: 11
Training loss: 1.6203744411468506
Validation loss: 1.8427150544299875

Epoch: 6| Step: 12
Training loss: 1.6041518449783325
Validation loss: 1.8412162244960826

Epoch: 6| Step: 13
Training loss: 1.0331707000732422
Validation loss: 1.8347436176833285

Epoch: 207| Step: 0
Training loss: 1.4647066593170166
Validation loss: 1.8268937423665037

Epoch: 6| Step: 1
Training loss: 1.4905955791473389
Validation loss: 1.8190500736236572

Epoch: 6| Step: 2
Training loss: 1.4891592264175415
Validation loss: 1.828066736139277

Epoch: 6| Step: 3
Training loss: 1.392142653465271
Validation loss: 1.819304386774699

Epoch: 6| Step: 4
Training loss: 1.4996907711029053
Validation loss: 1.8651606664862683

Epoch: 6| Step: 5
Training loss: 1.0643283128738403
Validation loss: 1.9007347527370657

Epoch: 6| Step: 6
Training loss: 1.3983559608459473
Validation loss: 1.9031008187160696

Epoch: 6| Step: 7
Training loss: 1.3224737644195557
Validation loss: 1.8828696332952028

Epoch: 6| Step: 8
Training loss: 1.479534387588501
Validation loss: 1.8769137346616356

Epoch: 6| Step: 9
Training loss: 1.0735586881637573
Validation loss: 1.8553341306665891

Epoch: 6| Step: 10
Training loss: 1.609569787979126
Validation loss: 1.8562485428266629

Epoch: 6| Step: 11
Training loss: 1.4294434785842896
Validation loss: 1.8351620922806442

Epoch: 6| Step: 12
Training loss: 1.4365673065185547
Validation loss: 1.8262772637028848

Epoch: 6| Step: 13
Training loss: 1.5813509225845337
Validation loss: 1.8342960662739252

Epoch: 208| Step: 0
Training loss: 1.393042802810669
Validation loss: 1.8326074718147196

Epoch: 6| Step: 1
Training loss: 1.1080772876739502
Validation loss: 1.8625258322684997

Epoch: 6| Step: 2
Training loss: 1.7844767570495605
Validation loss: 1.903660253811908

Epoch: 6| Step: 3
Training loss: 1.493900179862976
Validation loss: 1.9519281092510428

Epoch: 6| Step: 4
Training loss: 1.378904104232788
Validation loss: 1.9482754827827535

Epoch: 6| Step: 5
Training loss: 1.7692878246307373
Validation loss: 1.9230005010481803

Epoch: 6| Step: 6
Training loss: 1.1219980716705322
Validation loss: 1.9237627393455916

Epoch: 6| Step: 7
Training loss: 1.8553459644317627
Validation loss: 1.9152561003162014

Epoch: 6| Step: 8
Training loss: 1.181593894958496
Validation loss: 1.916924709914833

Epoch: 6| Step: 9
Training loss: 1.384676218032837
Validation loss: 1.8717547873015046

Epoch: 6| Step: 10
Training loss: 0.8786511421203613
Validation loss: 1.8606440482601043

Epoch: 6| Step: 11
Training loss: 1.387851357460022
Validation loss: 1.8614352928694857

Epoch: 6| Step: 12
Training loss: 1.564918875694275
Validation loss: 1.8705174038487096

Epoch: 6| Step: 13
Training loss: 1.4426119327545166
Validation loss: 1.8650083080414803

Epoch: 209| Step: 0
Training loss: 1.068449854850769
Validation loss: 1.8663372262831657

Epoch: 6| Step: 1
Training loss: 1.3055226802825928
Validation loss: 1.879378778960115

Epoch: 6| Step: 2
Training loss: 1.3795145750045776
Validation loss: 1.8833125983515093

Epoch: 6| Step: 3
Training loss: 1.0859965085983276
Validation loss: 1.92036110226826

Epoch: 6| Step: 4
Training loss: 1.2351716756820679
Validation loss: 1.9504505818889988

Epoch: 6| Step: 5
Training loss: 0.8396071791648865
Validation loss: 1.9451908783246112

Epoch: 6| Step: 6
Training loss: 1.205735683441162
Validation loss: 1.9466665919109056

Epoch: 6| Step: 7
Training loss: 0.8983972072601318
Validation loss: 1.9329618689834431

Epoch: 6| Step: 8
Training loss: 1.643686294555664
Validation loss: 1.925947182921953

Epoch: 6| Step: 9
Training loss: 2.060260057449341
Validation loss: 1.9363493509190057

Epoch: 6| Step: 10
Training loss: 1.5057555437088013
Validation loss: 1.9111018001392324

Epoch: 6| Step: 11
Training loss: 1.143469214439392
Validation loss: 1.886722457024359

Epoch: 6| Step: 12
Training loss: 2.0258400440216064
Validation loss: 1.903685700508856

Epoch: 6| Step: 13
Training loss: 1.3982712030410767
Validation loss: 1.8918309442458614

Epoch: 210| Step: 0
Training loss: 1.6351308822631836
Validation loss: 1.8868057086903562

Epoch: 6| Step: 1
Training loss: 1.4945013523101807
Validation loss: 1.8598245036217473

Epoch: 6| Step: 2
Training loss: 1.022998571395874
Validation loss: 1.8673915593854842

Epoch: 6| Step: 3
Training loss: 1.676053762435913
Validation loss: 1.8287077860165668

Epoch: 6| Step: 4
Training loss: 1.0370936393737793
Validation loss: 1.8303621610005696

Epoch: 6| Step: 5
Training loss: 1.3877942562103271
Validation loss: 1.8535015736856768

Epoch: 6| Step: 6
Training loss: 1.0649735927581787
Validation loss: 1.870238442574778

Epoch: 6| Step: 7
Training loss: 1.0560764074325562
Validation loss: 1.890377454219326

Epoch: 6| Step: 8
Training loss: 1.6035171747207642
Validation loss: 1.9472253232873895

Epoch: 6| Step: 9
Training loss: 1.466360330581665
Validation loss: 2.001515334652316

Epoch: 6| Step: 10
Training loss: 1.2954416275024414
Validation loss: 2.031410606958533

Epoch: 6| Step: 11
Training loss: 1.4188835620880127
Validation loss: 1.9942410786946614

Epoch: 6| Step: 12
Training loss: 1.1031432151794434
Validation loss: 2.0050439911503948

Epoch: 6| Step: 13
Training loss: 0.9104741215705872
Validation loss: 1.9331827266241914

Epoch: 211| Step: 0
Training loss: 1.2115683555603027
Validation loss: 1.9112367527459257

Epoch: 6| Step: 1
Training loss: 1.6889991760253906
Validation loss: 1.8643668787453764

Epoch: 6| Step: 2
Training loss: 1.335465669631958
Validation loss: 1.8280428378812728

Epoch: 6| Step: 3
Training loss: 1.5846045017242432
Validation loss: 1.8463822013588362

Epoch: 6| Step: 4
Training loss: 1.6201311349868774
Validation loss: 1.843331601030083

Epoch: 6| Step: 5
Training loss: 1.3778774738311768
Validation loss: 1.816885732835339

Epoch: 6| Step: 6
Training loss: 1.752720594406128
Validation loss: 1.8170246231940486

Epoch: 6| Step: 7
Training loss: 0.7946175336837769
Validation loss: 1.8226297850249915

Epoch: 6| Step: 8
Training loss: 0.816997766494751
Validation loss: 1.8556164951734646

Epoch: 6| Step: 9
Training loss: 1.094602108001709
Validation loss: 1.8694710231596423

Epoch: 6| Step: 10
Training loss: 1.4710575342178345
Validation loss: 1.8772076650332379

Epoch: 6| Step: 11
Training loss: 0.666654109954834
Validation loss: 1.8681529670633295

Epoch: 6| Step: 12
Training loss: 1.5191423892974854
Validation loss: 1.8651058840495285

Epoch: 6| Step: 13
Training loss: 1.2607176303863525
Validation loss: 1.8863346166508173

Epoch: 212| Step: 0
Training loss: 1.0897235870361328
Validation loss: 1.8650653990366126

Epoch: 6| Step: 1
Training loss: 1.024647831916809
Validation loss: 1.8852325075416154

Epoch: 6| Step: 2
Training loss: 1.1235852241516113
Validation loss: 1.9007224280347106

Epoch: 6| Step: 3
Training loss: 1.8076794147491455
Validation loss: 1.8770989089883783

Epoch: 6| Step: 4
Training loss: 0.9805036783218384
Validation loss: 1.8626403565047889

Epoch: 6| Step: 5
Training loss: 0.9265773296356201
Validation loss: 1.8710946472742225

Epoch: 6| Step: 6
Training loss: 1.6137268543243408
Validation loss: 1.8647247873326784

Epoch: 6| Step: 7
Training loss: 1.4891878366470337
Validation loss: 1.8763113508942306

Epoch: 6| Step: 8
Training loss: 1.2808983325958252
Validation loss: 1.8991019930890811

Epoch: 6| Step: 9
Training loss: 1.5326869487762451
Validation loss: 1.8788117798425819

Epoch: 6| Step: 10
Training loss: 1.4324777126312256
Validation loss: 1.8642448545784078

Epoch: 6| Step: 11
Training loss: 0.9047664403915405
Validation loss: 1.8541432067912111

Epoch: 6| Step: 12
Training loss: 1.2887628078460693
Validation loss: 1.8765383907543716

Epoch: 6| Step: 13
Training loss: 1.4499497413635254
Validation loss: 1.8728180969915083

Epoch: 213| Step: 0
Training loss: 1.6556355953216553
Validation loss: 1.8733881801687262

Epoch: 6| Step: 1
Training loss: 1.3902941942214966
Validation loss: 1.8537171143357472

Epoch: 6| Step: 2
Training loss: 1.2956011295318604
Validation loss: 1.835491882857456

Epoch: 6| Step: 3
Training loss: 1.5642013549804688
Validation loss: 1.8091025813933341

Epoch: 6| Step: 4
Training loss: 1.2083861827850342
Validation loss: 1.7878337316615607

Epoch: 6| Step: 5
Training loss: 0.7616890668869019
Validation loss: 1.796004472240325

Epoch: 6| Step: 6
Training loss: 1.067906379699707
Validation loss: 1.7936379935151787

Epoch: 6| Step: 7
Training loss: 1.1791845560073853
Validation loss: 1.7831003166014148

Epoch: 6| Step: 8
Training loss: 0.9832611083984375
Validation loss: 1.79184208121351

Epoch: 6| Step: 9
Training loss: 1.1398096084594727
Validation loss: 1.7896884359339231

Epoch: 6| Step: 10
Training loss: 1.4295090436935425
Validation loss: 1.8134799682965843

Epoch: 6| Step: 11
Training loss: 1.1038837432861328
Validation loss: 1.8597312896482405

Epoch: 6| Step: 12
Training loss: 1.5798089504241943
Validation loss: 1.861773108923307

Epoch: 6| Step: 13
Training loss: 1.6653697490692139
Validation loss: 1.9322644087576097

Epoch: 214| Step: 0
Training loss: 0.9919320940971375
Validation loss: 1.9321728701232581

Epoch: 6| Step: 1
Training loss: 1.3265516757965088
Validation loss: 1.9530442568563646

Epoch: 6| Step: 2
Training loss: 2.015418291091919
Validation loss: 1.9597606492298905

Epoch: 6| Step: 3
Training loss: 1.5552265644073486
Validation loss: 1.924619077354349

Epoch: 6| Step: 4
Training loss: 0.8540807366371155
Validation loss: 1.8923396141298356

Epoch: 6| Step: 5
Training loss: 1.4464895725250244
Validation loss: 1.858430452244256

Epoch: 6| Step: 6
Training loss: 1.1064460277557373
Validation loss: 1.817677592718473

Epoch: 6| Step: 7
Training loss: 1.1157771348953247
Validation loss: 1.7988780531831967

Epoch: 6| Step: 8
Training loss: 1.5957227945327759
Validation loss: 1.7975757519404094

Epoch: 6| Step: 9
Training loss: 1.2352614402770996
Validation loss: 1.7939973197957522

Epoch: 6| Step: 10
Training loss: 1.0762934684753418
Validation loss: 1.8106059810166717

Epoch: 6| Step: 11
Training loss: 0.7972182035446167
Validation loss: 1.8396332020400672

Epoch: 6| Step: 12
Training loss: 1.4539313316345215
Validation loss: 1.8935829106197561

Epoch: 6| Step: 13
Training loss: 0.9869000911712646
Validation loss: 1.9200060675221104

Epoch: 215| Step: 0
Training loss: 1.500115156173706
Validation loss: 1.9133966866359915

Epoch: 6| Step: 1
Training loss: 1.3049956560134888
Validation loss: 1.922360630445583

Epoch: 6| Step: 2
Training loss: 1.5195748805999756
Validation loss: 1.9088711456585956

Epoch: 6| Step: 3
Training loss: 1.603313684463501
Validation loss: 1.8536614615430114

Epoch: 6| Step: 4
Training loss: 0.9372076392173767
Validation loss: 1.8142708091325657

Epoch: 6| Step: 5
Training loss: 0.916789710521698
Validation loss: 1.8344065514943932

Epoch: 6| Step: 6
Training loss: 1.114603042602539
Validation loss: 1.8572500918501167

Epoch: 6| Step: 7
Training loss: 1.043164849281311
Validation loss: 1.82555982887104

Epoch: 6| Step: 8
Training loss: 1.1595687866210938
Validation loss: 1.835154394949636

Epoch: 6| Step: 9
Training loss: 1.2890667915344238
Validation loss: 1.8424621499994749

Epoch: 6| Step: 10
Training loss: 1.0234934091567993
Validation loss: 1.8628487138337986

Epoch: 6| Step: 11
Training loss: 1.7378324270248413
Validation loss: 1.9014820052731423

Epoch: 6| Step: 12
Training loss: 1.5138897895812988
Validation loss: 1.8803830499290137

Epoch: 6| Step: 13
Training loss: 0.6512750387191772
Validation loss: 1.8610842574027278

Epoch: 216| Step: 0
Training loss: 1.4840267896652222
Validation loss: 1.8309925820237847

Epoch: 6| Step: 1
Training loss: 1.0573394298553467
Validation loss: 1.8086680186692106

Epoch: 6| Step: 2
Training loss: 1.2711366415023804
Validation loss: 1.8261785853293635

Epoch: 6| Step: 3
Training loss: 0.9610846638679504
Validation loss: 1.8383293215946486

Epoch: 6| Step: 4
Training loss: 1.2944241762161255
Validation loss: 1.8112904179480769

Epoch: 6| Step: 5
Training loss: 1.4936443567276
Validation loss: 1.7981619681081464

Epoch: 6| Step: 6
Training loss: 1.4427378177642822
Validation loss: 1.7838791211446126

Epoch: 6| Step: 7
Training loss: 1.0583890676498413
Validation loss: 1.8136994095258816

Epoch: 6| Step: 8
Training loss: 1.2958685159683228
Validation loss: 1.7929961322456278

Epoch: 6| Step: 9
Training loss: 0.9624755382537842
Validation loss: 1.7956010398044382

Epoch: 6| Step: 10
Training loss: 1.289703130722046
Validation loss: 1.8191278134622881

Epoch: 6| Step: 11
Training loss: 1.4320987462997437
Validation loss: 1.8017760271667151

Epoch: 6| Step: 12
Training loss: 0.9367932081222534
Validation loss: 1.8383948379947292

Epoch: 6| Step: 13
Training loss: 1.1740703582763672
Validation loss: 1.8527059478144492

Epoch: 217| Step: 0
Training loss: 1.3686190843582153
Validation loss: 1.86393956599697

Epoch: 6| Step: 1
Training loss: 1.7561423778533936
Validation loss: 1.901031199321952

Epoch: 6| Step: 2
Training loss: 0.9609672427177429
Validation loss: 1.912859373195197

Epoch: 6| Step: 3
Training loss: 0.9662847518920898
Validation loss: 1.8907859145954091

Epoch: 6| Step: 4
Training loss: 0.6399828791618347
Validation loss: 1.8745487736117454

Epoch: 6| Step: 5
Training loss: 1.0803614854812622
Validation loss: 1.8789853511318084

Epoch: 6| Step: 6
Training loss: 1.4636398553848267
Validation loss: 1.8625132576111825

Epoch: 6| Step: 7
Training loss: 0.927405834197998
Validation loss: 1.841332366389613

Epoch: 6| Step: 8
Training loss: 1.31864595413208
Validation loss: 1.8451004810230707

Epoch: 6| Step: 9
Training loss: 1.4589797258377075
Validation loss: 1.8260533194388113

Epoch: 6| Step: 10
Training loss: 1.7350969314575195
Validation loss: 1.8143064014373287

Epoch: 6| Step: 11
Training loss: 0.6831746101379395
Validation loss: 1.8524931605144213

Epoch: 6| Step: 12
Training loss: 1.2570353746414185
Validation loss: 1.8703387603964856

Epoch: 6| Step: 13
Training loss: 0.9001687169075012
Validation loss: 1.8898156381422473

Epoch: 218| Step: 0
Training loss: 1.2181535959243774
Validation loss: 1.8951573474432832

Epoch: 6| Step: 1
Training loss: 1.0495591163635254
Validation loss: 1.8654343825514599

Epoch: 6| Step: 2
Training loss: 1.3571512699127197
Validation loss: 1.8232785155696254

Epoch: 6| Step: 3
Training loss: 1.2373228073120117
Validation loss: 1.7898988698118476

Epoch: 6| Step: 4
Training loss: 1.4443334341049194
Validation loss: 1.782911572405087

Epoch: 6| Step: 5
Training loss: 1.556011438369751
Validation loss: 1.7930100976779897

Epoch: 6| Step: 6
Training loss: 0.9362421631813049
Validation loss: 1.7968953501793645

Epoch: 6| Step: 7
Training loss: 0.9359211325645447
Validation loss: 1.803879814763223

Epoch: 6| Step: 8
Training loss: 1.077388048171997
Validation loss: 1.8134626470586306

Epoch: 6| Step: 9
Training loss: 1.2867224216461182
Validation loss: 1.849406006515667

Epoch: 6| Step: 10
Training loss: 1.1247756481170654
Validation loss: 1.8798995723006546

Epoch: 6| Step: 11
Training loss: 1.6204187870025635
Validation loss: 1.910738052860383

Epoch: 6| Step: 12
Training loss: 1.0534602403640747
Validation loss: 1.9201983091651753

Epoch: 6| Step: 13
Training loss: 0.35806190967559814
Validation loss: 1.952926497305593

Epoch: 219| Step: 0
Training loss: 1.5584995746612549
Validation loss: 1.9531799016460296

Epoch: 6| Step: 1
Training loss: 0.969727098941803
Validation loss: 1.945981917842742

Epoch: 6| Step: 2
Training loss: 1.3858897686004639
Validation loss: 1.9017744269422305

Epoch: 6| Step: 3
Training loss: 1.253415822982788
Validation loss: 1.8342486825040591

Epoch: 6| Step: 4
Training loss: 1.386425495147705
Validation loss: 1.794199025759133

Epoch: 6| Step: 5
Training loss: 1.2593896389007568
Validation loss: 1.7889170005757322

Epoch: 6| Step: 6
Training loss: 1.1518421173095703
Validation loss: 1.7486718162413566

Epoch: 6| Step: 7
Training loss: 0.908112645149231
Validation loss: 1.7661152872987973

Epoch: 6| Step: 8
Training loss: 1.1534075736999512
Validation loss: 1.759677872862867

Epoch: 6| Step: 9
Training loss: 1.579308271408081
Validation loss: 1.803353089158253

Epoch: 6| Step: 10
Training loss: 1.3641186952590942
Validation loss: 1.8389823590555499

Epoch: 6| Step: 11
Training loss: 0.850382924079895
Validation loss: 1.8805937510664745

Epoch: 6| Step: 12
Training loss: 1.2690215110778809
Validation loss: 1.930617235040152

Epoch: 6| Step: 13
Training loss: 0.5880022644996643
Validation loss: 1.9134486747044388

Epoch: 220| Step: 0
Training loss: 1.0459909439086914
Validation loss: 1.8885917971211095

Epoch: 6| Step: 1
Training loss: 0.718919038772583
Validation loss: 1.874887789449384

Epoch: 6| Step: 2
Training loss: 1.2733089923858643
Validation loss: 1.8539727323798723

Epoch: 6| Step: 3
Training loss: 0.7214272022247314
Validation loss: 1.8224046845589914

Epoch: 6| Step: 4
Training loss: 0.8214842081069946
Validation loss: 1.7935650361481534

Epoch: 6| Step: 5
Training loss: 1.7421506643295288
Validation loss: 1.8033330799430929

Epoch: 6| Step: 6
Training loss: 1.4736703634262085
Validation loss: 1.7987401331624677

Epoch: 6| Step: 7
Training loss: 0.9378213286399841
Validation loss: 1.8229335200402044

Epoch: 6| Step: 8
Training loss: 1.1904464960098267
Validation loss: 1.8308585792459466

Epoch: 6| Step: 9
Training loss: 1.4191489219665527
Validation loss: 1.8365142832520187

Epoch: 6| Step: 10
Training loss: 0.8379940986633301
Validation loss: 1.85206147163145

Epoch: 6| Step: 11
Training loss: 1.6609735488891602
Validation loss: 1.8794509441621843

Epoch: 6| Step: 12
Training loss: 1.2225911617279053
Validation loss: 1.8699544078560286

Epoch: 6| Step: 13
Training loss: 1.0458403825759888
Validation loss: 1.859937407637155

Epoch: 221| Step: 0
Training loss: 0.6858166456222534
Validation loss: 1.831953412743025

Epoch: 6| Step: 1
Training loss: 1.3292700052261353
Validation loss: 1.8582280220523957

Epoch: 6| Step: 2
Training loss: 0.9440704584121704
Validation loss: 1.8560213965754355

Epoch: 6| Step: 3
Training loss: 1.105051040649414
Validation loss: 1.8494127706814838

Epoch: 6| Step: 4
Training loss: 0.7430830001831055
Validation loss: 1.834744716203341

Epoch: 6| Step: 5
Training loss: 0.9558176398277283
Validation loss: 1.8049067361380464

Epoch: 6| Step: 6
Training loss: 1.3122899532318115
Validation loss: 1.7661550544923352

Epoch: 6| Step: 7
Training loss: 1.0760385990142822
Validation loss: 1.7648856075861121

Epoch: 6| Step: 8
Training loss: 1.6518185138702393
Validation loss: 1.769315270967381

Epoch: 6| Step: 9
Training loss: 1.5575969219207764
Validation loss: 1.810377069698867

Epoch: 6| Step: 10
Training loss: 1.4273314476013184
Validation loss: 1.84647842889191

Epoch: 6| Step: 11
Training loss: 1.173445463180542
Validation loss: 1.8699445686032694

Epoch: 6| Step: 12
Training loss: 1.0029411315917969
Validation loss: 1.8971647190791305

Epoch: 6| Step: 13
Training loss: 1.0225696563720703
Validation loss: 1.903060333703154

Epoch: 222| Step: 0
Training loss: 1.4558027982711792
Validation loss: 1.8544944858038297

Epoch: 6| Step: 1
Training loss: 1.3692080974578857
Validation loss: 1.8687286915317658

Epoch: 6| Step: 2
Training loss: 1.0072046518325806
Validation loss: 1.841792401447091

Epoch: 6| Step: 3
Training loss: 0.4943842887878418
Validation loss: 1.8429692163262317

Epoch: 6| Step: 4
Training loss: 1.2680931091308594
Validation loss: 1.8716586917959235

Epoch: 6| Step: 5
Training loss: 1.0218968391418457
Validation loss: 1.8336545818595475

Epoch: 6| Step: 6
Training loss: 0.7902685403823853
Validation loss: 1.8167479115147744

Epoch: 6| Step: 7
Training loss: 1.2945301532745361
Validation loss: 1.8141064233677362

Epoch: 6| Step: 8
Training loss: 1.6701085567474365
Validation loss: 1.8137443040006904

Epoch: 6| Step: 9
Training loss: 0.9566396474838257
Validation loss: 1.8026306398453251

Epoch: 6| Step: 10
Training loss: 1.1177308559417725
Validation loss: 1.7516005064851494

Epoch: 6| Step: 11
Training loss: 1.1548388004302979
Validation loss: 1.7449098761363695

Epoch: 6| Step: 12
Training loss: 1.4197392463684082
Validation loss: 1.7852657405279015

Epoch: 6| Step: 13
Training loss: 0.9584566950798035
Validation loss: 1.8235429602284585

Epoch: 223| Step: 0
Training loss: 0.6192327737808228
Validation loss: 1.878019348267586

Epoch: 6| Step: 1
Training loss: 0.9374445676803589
Validation loss: 1.9140658250419043

Epoch: 6| Step: 2
Training loss: 1.0141125917434692
Validation loss: 1.9819157162020284

Epoch: 6| Step: 3
Training loss: 1.2091717720031738
Validation loss: 2.021927164446923

Epoch: 6| Step: 4
Training loss: 1.3988598585128784
Validation loss: 2.052686828438954

Epoch: 6| Step: 5
Training loss: 1.3264470100402832
Validation loss: 2.044598542233949

Epoch: 6| Step: 6
Training loss: 1.5663206577301025
Validation loss: 2.011494235325885

Epoch: 6| Step: 7
Training loss: 1.1640527248382568
Validation loss: 1.9097108917851602

Epoch: 6| Step: 8
Training loss: 1.491997241973877
Validation loss: 1.8153508734959427

Epoch: 6| Step: 9
Training loss: 0.9611425399780273
Validation loss: 1.8102359207727576

Epoch: 6| Step: 10
Training loss: 1.3962632417678833
Validation loss: 1.800133010392548

Epoch: 6| Step: 11
Training loss: 0.7282708287239075
Validation loss: 1.8154575773464736

Epoch: 6| Step: 12
Training loss: 1.7184609174728394
Validation loss: 1.8112273318793184

Epoch: 6| Step: 13
Training loss: 1.0958367586135864
Validation loss: 1.8167738837580527

Epoch: 224| Step: 0
Training loss: 1.3889384269714355
Validation loss: 1.8467220183341735

Epoch: 6| Step: 1
Training loss: 1.626128911972046
Validation loss: 1.8758097976766608

Epoch: 6| Step: 2
Training loss: 1.4085538387298584
Validation loss: 1.9160826526662356

Epoch: 6| Step: 3
Training loss: 1.035888910293579
Validation loss: 1.9109497724040863

Epoch: 6| Step: 4
Training loss: 1.2287752628326416
Validation loss: 1.9230185221600276

Epoch: 6| Step: 5
Training loss: 0.9673659801483154
Validation loss: 1.8940776355804936

Epoch: 6| Step: 6
Training loss: 0.5211387276649475
Validation loss: 1.870233989530994

Epoch: 6| Step: 7
Training loss: 0.9642602801322937
Validation loss: 1.8601111545357654

Epoch: 6| Step: 8
Training loss: 0.8167557716369629
Validation loss: 1.8557355467991163

Epoch: 6| Step: 9
Training loss: 1.426314115524292
Validation loss: 1.8327454136263939

Epoch: 6| Step: 10
Training loss: 1.4247163534164429
Validation loss: 1.851124458415534

Epoch: 6| Step: 11
Training loss: 1.0221740007400513
Validation loss: 1.8181150497928742

Epoch: 6| Step: 12
Training loss: 1.0531851053237915
Validation loss: 1.814431445572966

Epoch: 6| Step: 13
Training loss: 1.2089108228683472
Validation loss: 1.843433258354023

Epoch: 225| Step: 0
Training loss: 1.351070523262024
Validation loss: 1.8675704245926232

Epoch: 6| Step: 1
Training loss: 0.8544085025787354
Validation loss: 1.8833962371272426

Epoch: 6| Step: 2
Training loss: 1.009727954864502
Validation loss: 1.9427996053490588

Epoch: 6| Step: 3
Training loss: 1.176513433456421
Validation loss: 1.9563913268427695

Epoch: 6| Step: 4
Training loss: 1.2745527029037476
Validation loss: 1.9759401839266542

Epoch: 6| Step: 5
Training loss: 1.4724247455596924
Validation loss: 1.935957484347846

Epoch: 6| Step: 6
Training loss: 1.316327452659607
Validation loss: 1.8715429434212305

Epoch: 6| Step: 7
Training loss: 1.4652576446533203
Validation loss: 1.8089371676086097

Epoch: 6| Step: 8
Training loss: 1.216609239578247
Validation loss: 1.7096243173845354

Epoch: 6| Step: 9
Training loss: 0.8444591760635376
Validation loss: 1.6847153709780784

Epoch: 6| Step: 10
Training loss: 0.7714188694953918
Validation loss: 1.6894872932023899

Epoch: 6| Step: 11
Training loss: 0.9608712792396545
Validation loss: 1.6659175170365201

Epoch: 6| Step: 12
Training loss: 1.5872342586517334
Validation loss: 1.6616131298003658

Epoch: 6| Step: 13
Training loss: 0.6393721103668213
Validation loss: 1.6938337702904978

Epoch: 226| Step: 0
Training loss: 1.1065207719802856
Validation loss: 1.7056091177848078

Epoch: 6| Step: 1
Training loss: 1.2587801218032837
Validation loss: 1.7173726776594758

Epoch: 6| Step: 2
Training loss: 1.5176308155059814
Validation loss: 1.7357935726001699

Epoch: 6| Step: 3
Training loss: 0.7687036991119385
Validation loss: 1.8022264460081696

Epoch: 6| Step: 4
Training loss: 0.6570658087730408
Validation loss: 1.883893015564129

Epoch: 6| Step: 5
Training loss: 1.2223340272903442
Validation loss: 1.9226275772176764

Epoch: 6| Step: 6
Training loss: 1.416908860206604
Validation loss: 1.9626054045974568

Epoch: 6| Step: 7
Training loss: 0.9618039131164551
Validation loss: 1.9739081910861436

Epoch: 6| Step: 8
Training loss: 1.3702608346939087
Validation loss: 1.9348848199331632

Epoch: 6| Step: 9
Training loss: 1.7497293949127197
Validation loss: 1.8877122543191398

Epoch: 6| Step: 10
Training loss: 1.4337574243545532
Validation loss: 1.8506221117511872

Epoch: 6| Step: 11
Training loss: 0.7965943813323975
Validation loss: 1.7786748511816866

Epoch: 6| Step: 12
Training loss: 0.9302071928977966
Validation loss: 1.767801825718213

Epoch: 6| Step: 13
Training loss: 0.8435066342353821
Validation loss: 1.7672029964385494

Epoch: 227| Step: 0
Training loss: 0.6465399265289307
Validation loss: 1.7666966274220457

Epoch: 6| Step: 1
Training loss: 1.1867892742156982
Validation loss: 1.7825291669496925

Epoch: 6| Step: 2
Training loss: 1.3582534790039062
Validation loss: 1.7932487995393815

Epoch: 6| Step: 3
Training loss: 1.3376898765563965
Validation loss: 1.8319922749714186

Epoch: 6| Step: 4
Training loss: 1.0656449794769287
Validation loss: 1.873733966581283

Epoch: 6| Step: 5
Training loss: 0.7578545808792114
Validation loss: 1.8954007946034914

Epoch: 6| Step: 6
Training loss: 1.499984622001648
Validation loss: 1.9105517056680494

Epoch: 6| Step: 7
Training loss: 0.8272502422332764
Validation loss: 1.9213960247655069

Epoch: 6| Step: 8
Training loss: 1.211045742034912
Validation loss: 1.936595473238217

Epoch: 6| Step: 9
Training loss: 1.0626899003982544
Validation loss: 1.9085505239425167

Epoch: 6| Step: 10
Training loss: 1.3042964935302734
Validation loss: 1.9049526363290765

Epoch: 6| Step: 11
Training loss: 1.1686266660690308
Validation loss: 1.8660455160243536

Epoch: 6| Step: 12
Training loss: 1.225358009338379
Validation loss: 1.844069121986307

Epoch: 6| Step: 13
Training loss: 0.2934401333332062
Validation loss: 1.8105691235552552

Epoch: 228| Step: 0
Training loss: 1.4643713235855103
Validation loss: 1.7818129139561807

Epoch: 6| Step: 1
Training loss: 1.2879759073257446
Validation loss: 1.774726842039375

Epoch: 6| Step: 2
Training loss: 0.6598883867263794
Validation loss: 1.773305167434036

Epoch: 6| Step: 3
Training loss: 1.1583356857299805
Validation loss: 1.8099823792775471

Epoch: 6| Step: 4
Training loss: 1.1022822856903076
Validation loss: 1.822191426830907

Epoch: 6| Step: 5
Training loss: 1.2512285709381104
Validation loss: 1.8479615731905865

Epoch: 6| Step: 6
Training loss: 1.060909390449524
Validation loss: 1.8809477885564168

Epoch: 6| Step: 7
Training loss: 1.5194344520568848
Validation loss: 1.9172940049120175

Epoch: 6| Step: 8
Training loss: 0.7697080373764038
Validation loss: 1.8918696193284885

Epoch: 6| Step: 9
Training loss: 1.02969491481781
Validation loss: 1.88695482284792

Epoch: 6| Step: 10
Training loss: 0.890997588634491
Validation loss: 1.8652071440091698

Epoch: 6| Step: 11
Training loss: 0.9909798502922058
Validation loss: 1.8707931605718469

Epoch: 6| Step: 12
Training loss: 0.8620040416717529
Validation loss: 1.850775752016293

Epoch: 6| Step: 13
Training loss: 1.1737245321273804
Validation loss: 1.8586384352817331

Epoch: 229| Step: 0
Training loss: 0.4913800060749054
Validation loss: 1.851066493218945

Epoch: 6| Step: 1
Training loss: 0.9181129932403564
Validation loss: 1.8622815608978271

Epoch: 6| Step: 2
Training loss: 0.7792026996612549
Validation loss: 1.8529853666982343

Epoch: 6| Step: 3
Training loss: 1.3660306930541992
Validation loss: 1.8609513492994412

Epoch: 6| Step: 4
Training loss: 1.4836757183074951
Validation loss: 1.8616254637318272

Epoch: 6| Step: 5
Training loss: 0.4660941958427429
Validation loss: 1.8650008132380824

Epoch: 6| Step: 6
Training loss: 1.3228572607040405
Validation loss: 1.8953538966435257

Epoch: 6| Step: 7
Training loss: 1.0725854635238647
Validation loss: 1.9007585856222338

Epoch: 6| Step: 8
Training loss: 0.8441137075424194
Validation loss: 1.9027911565637077

Epoch: 6| Step: 9
Training loss: 1.3623862266540527
Validation loss: 1.8987735753418298

Epoch: 6| Step: 10
Training loss: 1.382032871246338
Validation loss: 1.9101466478839997

Epoch: 6| Step: 11
Training loss: 1.2171919345855713
Validation loss: 1.918853949475032

Epoch: 6| Step: 12
Training loss: 0.7593580484390259
Validation loss: 1.8990459544684297

Epoch: 6| Step: 13
Training loss: 1.28420090675354
Validation loss: 1.8751883301683652

Epoch: 230| Step: 0
Training loss: 1.073385238647461
Validation loss: 1.8446363672133415

Epoch: 6| Step: 1
Training loss: 0.7696479558944702
Validation loss: 1.7890354856368034

Epoch: 6| Step: 2
Training loss: 0.8609778881072998
Validation loss: 1.7336172557646228

Epoch: 6| Step: 3
Training loss: 1.1525965929031372
Validation loss: 1.7284345280739568

Epoch: 6| Step: 4
Training loss: 1.1694926023483276
Validation loss: 1.7574651151575067

Epoch: 6| Step: 5
Training loss: 0.7493261098861694
Validation loss: 1.7454119497729885

Epoch: 6| Step: 6
Training loss: 0.9017391800880432
Validation loss: 1.768638292948405

Epoch: 6| Step: 7
Training loss: 1.1554291248321533
Validation loss: 1.826396667829124

Epoch: 6| Step: 8
Training loss: 1.4065797328948975
Validation loss: 1.9025353449647144

Epoch: 6| Step: 9
Training loss: 1.3609122037887573
Validation loss: 1.9954489020891086

Epoch: 6| Step: 10
Training loss: 1.0891423225402832
Validation loss: 1.9815193760779597

Epoch: 6| Step: 11
Training loss: 0.9635778665542603
Validation loss: 1.971116982480531

Epoch: 6| Step: 12
Training loss: 1.0582873821258545
Validation loss: 1.9153368626871417

Epoch: 6| Step: 13
Training loss: 1.4707826375961304
Validation loss: 1.8993401283858924

Epoch: 231| Step: 0
Training loss: 0.7449818849563599
Validation loss: 1.8595964113871257

Epoch: 6| Step: 1
Training loss: 1.0045101642608643
Validation loss: 1.805663707435772

Epoch: 6| Step: 2
Training loss: 0.8084144592285156
Validation loss: 1.7905478374932402

Epoch: 6| Step: 3
Training loss: 0.42793169617652893
Validation loss: 1.7877162797476656

Epoch: 6| Step: 4
Training loss: 1.205183744430542
Validation loss: 1.7990945282802786

Epoch: 6| Step: 5
Training loss: 1.2507877349853516
Validation loss: 1.7995910785531486

Epoch: 6| Step: 6
Training loss: 1.5332221984863281
Validation loss: 1.7910465604515486

Epoch: 6| Step: 7
Training loss: 1.0875217914581299
Validation loss: 1.8066781413170598

Epoch: 6| Step: 8
Training loss: 0.5602030754089355
Validation loss: 1.8341636298805155

Epoch: 6| Step: 9
Training loss: 0.9826783537864685
Validation loss: 1.837601892409786

Epoch: 6| Step: 10
Training loss: 1.4272164106369019
Validation loss: 1.8803032111096125

Epoch: 6| Step: 11
Training loss: 1.382141351699829
Validation loss: 1.867253606037427

Epoch: 6| Step: 12
Training loss: 1.382083773612976
Validation loss: 1.8653663025107434

Epoch: 6| Step: 13
Training loss: 1.340146541595459
Validation loss: 1.903971702821793

Epoch: 232| Step: 0
Training loss: 0.6394098997116089
Validation loss: 1.9118332427035096

Epoch: 6| Step: 1
Training loss: 1.1309900283813477
Validation loss: 1.8762194700138544

Epoch: 6| Step: 2
Training loss: 0.8155580759048462
Validation loss: 1.8748709988850418

Epoch: 6| Step: 3
Training loss: 1.2273430824279785
Validation loss: 1.832384902943847

Epoch: 6| Step: 4
Training loss: 1.1065126657485962
Validation loss: 1.8187900499631

Epoch: 6| Step: 5
Training loss: 1.2901602983474731
Validation loss: 1.8161053067894393

Epoch: 6| Step: 6
Training loss: 0.988895058631897
Validation loss: 1.8303584283398044

Epoch: 6| Step: 7
Training loss: 1.2078126668930054
Validation loss: 1.8519254974139634

Epoch: 6| Step: 8
Training loss: 0.7780470848083496
Validation loss: 1.8629595566821355

Epoch: 6| Step: 9
Training loss: 0.5914710760116577
Validation loss: 1.8562925528454524

Epoch: 6| Step: 10
Training loss: 0.6818031072616577
Validation loss: 1.8483413829598376

Epoch: 6| Step: 11
Training loss: 1.3472343683242798
Validation loss: 1.8324576629105436

Epoch: 6| Step: 12
Training loss: 1.3029276132583618
Validation loss: 1.8285682983295892

Epoch: 6| Step: 13
Training loss: 1.1288589239120483
Validation loss: 1.8197719191992154

Epoch: 233| Step: 0
Training loss: 0.9348541498184204
Validation loss: 1.8155367374420166

Epoch: 6| Step: 1
Training loss: 1.5587801933288574
Validation loss: 1.7797707793533162

Epoch: 6| Step: 2
Training loss: 1.0495367050170898
Validation loss: 1.7933678793650802

Epoch: 6| Step: 3
Training loss: 0.8301026821136475
Validation loss: 1.7923807482565604

Epoch: 6| Step: 4
Training loss: 1.0226794481277466
Validation loss: 1.7543310939624746

Epoch: 6| Step: 5
Training loss: 1.2624402046203613
Validation loss: 1.7751638094584148

Epoch: 6| Step: 6
Training loss: 1.0172643661499023
Validation loss: 1.7801078134967434

Epoch: 6| Step: 7
Training loss: 1.0306005477905273
Validation loss: 1.7979795663587508

Epoch: 6| Step: 8
Training loss: 0.9263781905174255
Validation loss: 1.800974848449871

Epoch: 6| Step: 9
Training loss: 0.7384380102157593
Validation loss: 1.8246407175576815

Epoch: 6| Step: 10
Training loss: 1.3194276094436646
Validation loss: 1.8244207418093117

Epoch: 6| Step: 11
Training loss: 0.9856147766113281
Validation loss: 1.829403474766721

Epoch: 6| Step: 12
Training loss: 0.7801588773727417
Validation loss: 1.854090440657831

Epoch: 6| Step: 13
Training loss: 0.5398262143135071
Validation loss: 1.8685908009929042

Epoch: 234| Step: 0
Training loss: 1.0603814125061035
Validation loss: 1.872108268481429

Epoch: 6| Step: 1
Training loss: 0.9890068173408508
Validation loss: 1.8535840844595304

Epoch: 6| Step: 2
Training loss: 1.3841127157211304
Validation loss: 1.848850215634992

Epoch: 6| Step: 3
Training loss: 1.0122078657150269
Validation loss: 1.809675580711775

Epoch: 6| Step: 4
Training loss: 0.5735059976577759
Validation loss: 1.756549339140615

Epoch: 6| Step: 5
Training loss: 0.7681317329406738
Validation loss: 1.7586094397370533

Epoch: 6| Step: 6
Training loss: 1.5438382625579834
Validation loss: 1.7650557923060592

Epoch: 6| Step: 7
Training loss: 0.7912972569465637
Validation loss: 1.7573931947831185

Epoch: 6| Step: 8
Training loss: 0.8305490016937256
Validation loss: 1.764458869093208

Epoch: 6| Step: 9
Training loss: 0.6519491672515869
Validation loss: 1.7820307221463931

Epoch: 6| Step: 10
Training loss: 1.1594674587249756
Validation loss: 1.7766623484191073

Epoch: 6| Step: 11
Training loss: 1.077282190322876
Validation loss: 1.79476394191865

Epoch: 6| Step: 12
Training loss: 1.0668129920959473
Validation loss: 1.8457444521688646

Epoch: 6| Step: 13
Training loss: 0.7590527534484863
Validation loss: 1.8324788167912474

Epoch: 235| Step: 0
Training loss: 1.4206284284591675
Validation loss: 1.8863294739877023

Epoch: 6| Step: 1
Training loss: 1.1230000257492065
Validation loss: 1.8727516410171345

Epoch: 6| Step: 2
Training loss: 1.1656301021575928
Validation loss: 1.8376138748661164

Epoch: 6| Step: 3
Training loss: 1.2041597366333008
Validation loss: 1.7961659995458459

Epoch: 6| Step: 4
Training loss: 0.5990245342254639
Validation loss: 1.7515006373005528

Epoch: 6| Step: 5
Training loss: 1.1454501152038574
Validation loss: 1.7212225596110027

Epoch: 6| Step: 6
Training loss: 1.2182968854904175
Validation loss: 1.7059618503816667

Epoch: 6| Step: 7
Training loss: 0.6089256405830383
Validation loss: 1.7309457781494304

Epoch: 6| Step: 8
Training loss: 0.5540269613265991
Validation loss: 1.7194681398330196

Epoch: 6| Step: 9
Training loss: 1.2708934545516968
Validation loss: 1.7622638171718967

Epoch: 6| Step: 10
Training loss: 0.7811576128005981
Validation loss: 1.763471206029256

Epoch: 6| Step: 11
Training loss: 0.9183499217033386
Validation loss: 1.7619748141175957

Epoch: 6| Step: 12
Training loss: 0.695366382598877
Validation loss: 1.7801899679245488

Epoch: 6| Step: 13
Training loss: 1.1396546363830566
Validation loss: 1.7816933867751912

Epoch: 236| Step: 0
Training loss: 0.7914760112762451
Validation loss: 1.8387129614430089

Epoch: 6| Step: 1
Training loss: 1.0866689682006836
Validation loss: 1.8657019234472705

Epoch: 6| Step: 2
Training loss: 0.9276649355888367
Validation loss: 1.89842390501371

Epoch: 6| Step: 3
Training loss: 0.8315385580062866
Validation loss: 1.9054691073715047

Epoch: 6| Step: 4
Training loss: 1.0838818550109863
Validation loss: 1.8990242506868096

Epoch: 6| Step: 5
Training loss: 1.682908058166504
Validation loss: 1.909586582132565

Epoch: 6| Step: 6
Training loss: 0.6992425918579102
Validation loss: 1.8350547821291032

Epoch: 6| Step: 7
Training loss: 0.651202917098999
Validation loss: 1.7669420960128948

Epoch: 6| Step: 8
Training loss: 1.001435399055481
Validation loss: 1.7304773715234572

Epoch: 6| Step: 9
Training loss: 1.4693853855133057
Validation loss: 1.7136633101330008

Epoch: 6| Step: 10
Training loss: 1.1671035289764404
Validation loss: 1.7193043001236454

Epoch: 6| Step: 11
Training loss: 1.1139333248138428
Validation loss: 1.7071860182669856

Epoch: 6| Step: 12
Training loss: 1.0404467582702637
Validation loss: 1.7393543745881768

Epoch: 6| Step: 13
Training loss: 0.7407844066619873
Validation loss: 1.7792791986978183

Epoch: 237| Step: 0
Training loss: 0.9619517922401428
Validation loss: 1.830436796270391

Epoch: 6| Step: 1
Training loss: 0.796697199344635
Validation loss: 1.859900568121223

Epoch: 6| Step: 2
Training loss: 1.5715687274932861
Validation loss: 1.901532882003374

Epoch: 6| Step: 3
Training loss: 0.8888473510742188
Validation loss: 1.9009255145185737

Epoch: 6| Step: 4
Training loss: 0.6392806768417358
Validation loss: 1.889436114218927

Epoch: 6| Step: 5
Training loss: 0.9009095430374146
Validation loss: 1.8503524077835904

Epoch: 6| Step: 6
Training loss: 1.2036240100860596
Validation loss: 1.806427240371704

Epoch: 6| Step: 7
Training loss: 0.8386111259460449
Validation loss: 1.7796030685465822

Epoch: 6| Step: 8
Training loss: 1.1678367853164673
Validation loss: 1.7529652836502239

Epoch: 6| Step: 9
Training loss: 0.8378164768218994
Validation loss: 1.7666864305414178

Epoch: 6| Step: 10
Training loss: 0.7594674825668335
Validation loss: 1.732320165121427

Epoch: 6| Step: 11
Training loss: 1.3759691715240479
Validation loss: 1.7540508931682957

Epoch: 6| Step: 12
Training loss: 0.8927046060562134
Validation loss: 1.7666543299152004

Epoch: 6| Step: 13
Training loss: 0.9461209774017334
Validation loss: 1.7751347300826863

Epoch: 238| Step: 0
Training loss: 0.9525957107543945
Validation loss: 1.8115566366462297

Epoch: 6| Step: 1
Training loss: 1.3364896774291992
Validation loss: 1.8626061729205552

Epoch: 6| Step: 2
Training loss: 0.746480405330658
Validation loss: 1.8770536197129117

Epoch: 6| Step: 3
Training loss: 1.1156513690948486
Validation loss: 1.9026465749227872

Epoch: 6| Step: 4
Training loss: 0.588908851146698
Validation loss: 1.9071108448889948

Epoch: 6| Step: 5
Training loss: 0.8498769998550415
Validation loss: 1.87889188848516

Epoch: 6| Step: 6
Training loss: 1.4580388069152832
Validation loss: 1.8262316437177761

Epoch: 6| Step: 7
Training loss: 1.04119074344635
Validation loss: 1.7746755397447975

Epoch: 6| Step: 8
Training loss: 1.0313791036605835
Validation loss: 1.724330538062639

Epoch: 6| Step: 9
Training loss: 0.7743333578109741
Validation loss: 1.7188034326799455

Epoch: 6| Step: 10
Training loss: 0.6388806104660034
Validation loss: 1.7277342683525496

Epoch: 6| Step: 11
Training loss: 1.2183623313903809
Validation loss: 1.708643074958555

Epoch: 6| Step: 12
Training loss: 0.7960019707679749
Validation loss: 1.724266004818742

Epoch: 6| Step: 13
Training loss: 0.8270986080169678
Validation loss: 1.7495375807567308

Epoch: 239| Step: 0
Training loss: 0.3741542398929596
Validation loss: 1.7886901222249514

Epoch: 6| Step: 1
Training loss: 1.193466305732727
Validation loss: 1.8257695013476956

Epoch: 6| Step: 2
Training loss: 1.0932492017745972
Validation loss: 1.8227377181412072

Epoch: 6| Step: 3
Training loss: 0.5854941606521606
Validation loss: 1.8332381081837479

Epoch: 6| Step: 4
Training loss: 0.819611668586731
Validation loss: 1.8468497414742746

Epoch: 6| Step: 5
Training loss: 1.0093505382537842
Validation loss: 1.8877872190167826

Epoch: 6| Step: 6
Training loss: 1.1755632162094116
Validation loss: 1.8969257826446204

Epoch: 6| Step: 7
Training loss: 1.0099925994873047
Validation loss: 1.901408367259528

Epoch: 6| Step: 8
Training loss: 1.0688668489456177
Validation loss: 1.8874253790865663

Epoch: 6| Step: 9
Training loss: 1.0700485706329346
Validation loss: 1.860293206348214

Epoch: 6| Step: 10
Training loss: 1.4415762424468994
Validation loss: 1.8512315775758477

Epoch: 6| Step: 11
Training loss: 0.8238674402236938
Validation loss: 1.821047450906487

Epoch: 6| Step: 12
Training loss: 0.8413364291191101
Validation loss: 1.8468718016019432

Epoch: 6| Step: 13
Training loss: 1.1413747072219849
Validation loss: 1.8146344128475393

Epoch: 240| Step: 0
Training loss: 0.714152991771698
Validation loss: 1.8137050014670177

Epoch: 6| Step: 1
Training loss: 0.4326631426811218
Validation loss: 1.8215068835084156

Epoch: 6| Step: 2
Training loss: 0.9857573509216309
Validation loss: 1.8284983609312324

Epoch: 6| Step: 3
Training loss: 0.9507526159286499
Validation loss: 1.8130292636091991

Epoch: 6| Step: 4
Training loss: 0.6444200277328491
Validation loss: 1.8157379447772939

Epoch: 6| Step: 5
Training loss: 1.0965616703033447
Validation loss: 1.8019851176969466

Epoch: 6| Step: 6
Training loss: 1.3844013214111328
Validation loss: 1.821268532865791

Epoch: 6| Step: 7
Training loss: 0.8769299387931824
Validation loss: 1.8322452140110794

Epoch: 6| Step: 8
Training loss: 1.082795262336731
Validation loss: 1.8707120059638895

Epoch: 6| Step: 9
Training loss: 0.888534665107727
Validation loss: 1.8653037342973935

Epoch: 6| Step: 10
Training loss: 0.8209612369537354
Validation loss: 1.8771779614110147

Epoch: 6| Step: 11
Training loss: 0.9868221282958984
Validation loss: 1.8803967993746522

Epoch: 6| Step: 12
Training loss: 0.7205376625061035
Validation loss: 1.8589052231081071

Epoch: 6| Step: 13
Training loss: 1.4929499626159668
Validation loss: 1.8541574042330506

Epoch: 241| Step: 0
Training loss: 0.9811983704566956
Validation loss: 1.833172086746462

Epoch: 6| Step: 1
Training loss: 0.8517189025878906
Validation loss: 1.7608909478751562

Epoch: 6| Step: 2
Training loss: 1.0643539428710938
Validation loss: 1.7469165812256515

Epoch: 6| Step: 3
Training loss: 0.7909821271896362
Validation loss: 1.7194233581583986

Epoch: 6| Step: 4
Training loss: 0.9284523725509644
Validation loss: 1.7320726212634836

Epoch: 6| Step: 5
Training loss: 0.9317933917045593
Validation loss: 1.7629333760148735

Epoch: 6| Step: 6
Training loss: 0.7943390011787415
Validation loss: 1.7513221104939778

Epoch: 6| Step: 7
Training loss: 0.9987377524375916
Validation loss: 1.7572095445407334

Epoch: 6| Step: 8
Training loss: 0.6136660575866699
Validation loss: 1.7656917238748202

Epoch: 6| Step: 9
Training loss: 0.6872217655181885
Validation loss: 1.7705993472888906

Epoch: 6| Step: 10
Training loss: 0.7801563143730164
Validation loss: 1.7549026602058

Epoch: 6| Step: 11
Training loss: 0.9410727620124817
Validation loss: 1.7897206044966174

Epoch: 6| Step: 12
Training loss: 1.5425755977630615
Validation loss: 1.8203745452306603

Epoch: 6| Step: 13
Training loss: 1.2955008745193481
Validation loss: 1.804562186682096

Epoch: 242| Step: 0
Training loss: 0.7292119860649109
Validation loss: 1.8020081930263068

Epoch: 6| Step: 1
Training loss: 1.063542127609253
Validation loss: 1.7744817695310038

Epoch: 6| Step: 2
Training loss: 0.6960686445236206
Validation loss: 1.7470108001462874

Epoch: 6| Step: 3
Training loss: 0.7402902245521545
Validation loss: 1.7248447915559173

Epoch: 6| Step: 4
Training loss: 0.7825026512145996
Validation loss: 1.7456324228676416

Epoch: 6| Step: 5
Training loss: 0.9902399182319641
Validation loss: 1.744625259471196

Epoch: 6| Step: 6
Training loss: 1.2944978475570679
Validation loss: 1.7640149336989208

Epoch: 6| Step: 7
Training loss: 0.6124557256698608
Validation loss: 1.730586910760531

Epoch: 6| Step: 8
Training loss: 0.7669841647148132
Validation loss: 1.7352309342353576

Epoch: 6| Step: 9
Training loss: 1.0123131275177002
Validation loss: 1.7534368089450303

Epoch: 6| Step: 10
Training loss: 0.9904738068580627
Validation loss: 1.7891711188900856

Epoch: 6| Step: 11
Training loss: 0.94712233543396
Validation loss: 1.7997154330694547

Epoch: 6| Step: 12
Training loss: 1.0905722379684448
Validation loss: 1.8334928045990646

Epoch: 6| Step: 13
Training loss: 0.8036243915557861
Validation loss: 1.8597535702490038

Epoch: 243| Step: 0
Training loss: 0.8953520059585571
Validation loss: 1.8750720536837013

Epoch: 6| Step: 1
Training loss: 1.1051175594329834
Validation loss: 1.8716527133859613

Epoch: 6| Step: 2
Training loss: 0.7985485196113586
Validation loss: 1.8457827029689666

Epoch: 6| Step: 3
Training loss: 0.46113502979278564
Validation loss: 1.8315700433587516

Epoch: 6| Step: 4
Training loss: 0.4512868821620941
Validation loss: 1.8308860691644813

Epoch: 6| Step: 5
Training loss: 0.6698125600814819
Validation loss: 1.7980671890320317

Epoch: 6| Step: 6
Training loss: 1.43342924118042
Validation loss: 1.7895187011329077

Epoch: 6| Step: 7
Training loss: 1.3766661882400513
Validation loss: 1.763326960225259

Epoch: 6| Step: 8
Training loss: 0.8543466329574585
Validation loss: 1.735733929500785

Epoch: 6| Step: 9
Training loss: 0.9112422466278076
Validation loss: 1.7299707320428663

Epoch: 6| Step: 10
Training loss: 1.1280245780944824
Validation loss: 1.7282679593691261

Epoch: 6| Step: 11
Training loss: 0.9114182591438293
Validation loss: 1.7387937191993958

Epoch: 6| Step: 12
Training loss: 0.6426713466644287
Validation loss: 1.7109966560076642

Epoch: 6| Step: 13
Training loss: 0.878138542175293
Validation loss: 1.7082562587594474

Epoch: 244| Step: 0
Training loss: 0.8159309029579163
Validation loss: 1.71779235716789

Epoch: 6| Step: 1
Training loss: 1.0621044635772705
Validation loss: 1.7621977854800481

Epoch: 6| Step: 2
Training loss: 0.8340409994125366
Validation loss: 1.777056804267309

Epoch: 6| Step: 3
Training loss: 0.7004451751708984
Validation loss: 1.7803844803123063

Epoch: 6| Step: 4
Training loss: 1.0604829788208008
Validation loss: 1.7887382071505311

Epoch: 6| Step: 5
Training loss: 0.9654544591903687
Validation loss: 1.8056258001635153

Epoch: 6| Step: 6
Training loss: 0.9032504558563232
Validation loss: 1.8124463007014284

Epoch: 6| Step: 7
Training loss: 0.8540323972702026
Validation loss: 1.8228628763588526

Epoch: 6| Step: 8
Training loss: 0.9436315894126892
Validation loss: 1.827137799673183

Epoch: 6| Step: 9
Training loss: 0.41828304529190063
Validation loss: 1.8089941304217103

Epoch: 6| Step: 10
Training loss: 0.8688884377479553
Validation loss: 1.8080045882091726

Epoch: 6| Step: 11
Training loss: 0.931948184967041
Validation loss: 1.7768658835400817

Epoch: 6| Step: 12
Training loss: 0.812416672706604
Validation loss: 1.7548602037532355

Epoch: 6| Step: 13
Training loss: 1.0400439500808716
Validation loss: 1.7096342720011228

Epoch: 245| Step: 0
Training loss: 1.1451315879821777
Validation loss: 1.6928185570624568

Epoch: 6| Step: 1
Training loss: 0.5153491497039795
Validation loss: 1.688230272262327

Epoch: 6| Step: 2
Training loss: 0.9998835325241089
Validation loss: 1.6594826508593816

Epoch: 6| Step: 3
Training loss: 0.978562593460083
Validation loss: 1.677955691532422

Epoch: 6| Step: 4
Training loss: 0.7296712398529053
Validation loss: 1.6787497830647293

Epoch: 6| Step: 5
Training loss: 0.6991891860961914
Validation loss: 1.7206937907844462

Epoch: 6| Step: 6
Training loss: 1.1546673774719238
Validation loss: 1.77647066116333

Epoch: 6| Step: 7
Training loss: 1.2080541849136353
Validation loss: 1.839129000581721

Epoch: 6| Step: 8
Training loss: 0.9213111400604248
Validation loss: 1.9120947930120653

Epoch: 6| Step: 9
Training loss: 0.9896924495697021
Validation loss: 1.9485140897894417

Epoch: 6| Step: 10
Training loss: 1.0619057416915894
Validation loss: 1.9363806555348058

Epoch: 6| Step: 11
Training loss: 0.7277604937553406
Validation loss: 1.934061437524775

Epoch: 6| Step: 12
Training loss: 0.9054259061813354
Validation loss: 1.893869633315712

Epoch: 6| Step: 13
Training loss: 1.064562201499939
Validation loss: 1.8448601115134455

Epoch: 246| Step: 0
Training loss: 1.3747859001159668
Validation loss: 1.7994863910059775

Epoch: 6| Step: 1
Training loss: 1.0546789169311523
Validation loss: 1.7750962613731303

Epoch: 6| Step: 2
Training loss: 1.2317664623260498
Validation loss: 1.7609455226570048

Epoch: 6| Step: 3
Training loss: 0.8716006278991699
Validation loss: 1.6972384452819824

Epoch: 6| Step: 4
Training loss: 0.8280463218688965
Validation loss: 1.6943494119951803

Epoch: 6| Step: 5
Training loss: 0.9252970218658447
Validation loss: 1.7339123679745583

Epoch: 6| Step: 6
Training loss: 1.0293402671813965
Validation loss: 1.72517236714722

Epoch: 6| Step: 7
Training loss: 1.1606504917144775
Validation loss: 1.7592395736325173

Epoch: 6| Step: 8
Training loss: 0.84364914894104
Validation loss: 1.760976024853286

Epoch: 6| Step: 9
Training loss: 0.7950767874717712
Validation loss: 1.7771520999170118

Epoch: 6| Step: 10
Training loss: 0.8451086282730103
Validation loss: 1.7598824577946817

Epoch: 6| Step: 11
Training loss: 0.7007652521133423
Validation loss: 1.7488634945243917

Epoch: 6| Step: 12
Training loss: 0.6575507521629333
Validation loss: 1.7498801626184934

Epoch: 6| Step: 13
Training loss: 0.4860802888870239
Validation loss: 1.761355778222443

Epoch: 247| Step: 0
Training loss: 0.7110909819602966
Validation loss: 1.7805056674506075

Epoch: 6| Step: 1
Training loss: 0.9962809085845947
Validation loss: 1.7951714838704755

Epoch: 6| Step: 2
Training loss: 0.8262455463409424
Validation loss: 1.8145876392241447

Epoch: 6| Step: 3
Training loss: 0.4729994535446167
Validation loss: 1.8008250498002576

Epoch: 6| Step: 4
Training loss: 1.4606797695159912
Validation loss: 1.802068171962615

Epoch: 6| Step: 5
Training loss: 0.9234618544578552
Validation loss: 1.8204874838552167

Epoch: 6| Step: 6
Training loss: 0.7944959402084351
Validation loss: 1.7850640973737162

Epoch: 6| Step: 7
Training loss: 1.1291472911834717
Validation loss: 1.7853560716875139

Epoch: 6| Step: 8
Training loss: 0.8371502161026001
Validation loss: 1.7453670142799296

Epoch: 6| Step: 9
Training loss: 0.47560131549835205
Validation loss: 1.72151747826607

Epoch: 6| Step: 10
Training loss: 0.9668323397636414
Validation loss: 1.6774697380681192

Epoch: 6| Step: 11
Training loss: 0.7714138031005859
Validation loss: 1.7100829129577966

Epoch: 6| Step: 12
Training loss: 1.0852134227752686
Validation loss: 1.720663111696961

Epoch: 6| Step: 13
Training loss: 0.8281264901161194
Validation loss: 1.7559065536786151

Epoch: 248| Step: 0
Training loss: 1.318917989730835
Validation loss: 1.8150513633604972

Epoch: 6| Step: 1
Training loss: 0.7556010484695435
Validation loss: 1.832989461960331

Epoch: 6| Step: 2
Training loss: 0.6090518236160278
Validation loss: 1.8303885857264202

Epoch: 6| Step: 3
Training loss: 1.1518542766571045
Validation loss: 1.783744022410403

Epoch: 6| Step: 4
Training loss: 0.5283480286598206
Validation loss: 1.7919112508014967

Epoch: 6| Step: 5
Training loss: 0.6944974660873413
Validation loss: 1.821265491106177

Epoch: 6| Step: 6
Training loss: 1.1378840208053589
Validation loss: 1.8418518971371394

Epoch: 6| Step: 7
Training loss: 0.8774428367614746
Validation loss: 1.854710368699925

Epoch: 6| Step: 8
Training loss: 0.7082836627960205
Validation loss: 1.8294065536991242

Epoch: 6| Step: 9
Training loss: 1.0749778747558594
Validation loss: 1.7879512553573937

Epoch: 6| Step: 10
Training loss: 1.0089974403381348
Validation loss: 1.781458059946696

Epoch: 6| Step: 11
Training loss: 1.2423756122589111
Validation loss: 1.7656368171015093

Epoch: 6| Step: 12
Training loss: 1.0060614347457886
Validation loss: 1.7831431281182073

Epoch: 6| Step: 13
Training loss: 0.6979323029518127
Validation loss: 1.7750872796581638

Epoch: 249| Step: 0
Training loss: 0.6848376989364624
Validation loss: 1.7421895445034068

Epoch: 6| Step: 1
Training loss: 0.590175986289978
Validation loss: 1.693202253310911

Epoch: 6| Step: 2
Training loss: 0.7766073942184448
Validation loss: 1.7200467663426553

Epoch: 6| Step: 3
Training loss: 1.148310661315918
Validation loss: 1.7245364060965918

Epoch: 6| Step: 4
Training loss: 0.915432333946228
Validation loss: 1.7515194531409972

Epoch: 6| Step: 5
Training loss: 1.0242300033569336
Validation loss: 1.7998022084595056

Epoch: 6| Step: 6
Training loss: 0.8915013074874878
Validation loss: 1.8245675627903273

Epoch: 6| Step: 7
Training loss: 1.1129345893859863
Validation loss: 1.8480968424068984

Epoch: 6| Step: 8
Training loss: 0.6414033770561218
Validation loss: 1.8658359255841983

Epoch: 6| Step: 9
Training loss: 1.1253690719604492
Validation loss: 1.8809538451574181

Epoch: 6| Step: 10
Training loss: 1.0398459434509277
Validation loss: 1.907299885185816

Epoch: 6| Step: 11
Training loss: 0.8393250703811646
Validation loss: 1.8910665255720898

Epoch: 6| Step: 12
Training loss: 0.975053071975708
Validation loss: 1.8470545776428715

Epoch: 6| Step: 13
Training loss: 0.8684828877449036
Validation loss: 1.8155896548301942

Epoch: 250| Step: 0
Training loss: 0.6666508913040161
Validation loss: 1.823643812569239

Epoch: 6| Step: 1
Training loss: 0.7874764800071716
Validation loss: 1.803453658216743

Epoch: 6| Step: 2
Training loss: 1.1099332571029663
Validation loss: 1.838348428408305

Epoch: 6| Step: 3
Training loss: 1.448248267173767
Validation loss: 1.8173452013282365

Epoch: 6| Step: 4
Training loss: 0.5253804922103882
Validation loss: 1.7806622494933426

Epoch: 6| Step: 5
Training loss: 0.9123849272727966
Validation loss: 1.779565797057203

Epoch: 6| Step: 6
Training loss: 0.7407302260398865
Validation loss: 1.7428619259147233

Epoch: 6| Step: 7
Training loss: 1.0999406576156616
Validation loss: 1.7664661048561014

Epoch: 6| Step: 8
Training loss: 1.0331720113754272
Validation loss: 1.7521232699835172

Epoch: 6| Step: 9
Training loss: 0.8298884630203247
Validation loss: 1.7663064913083149

Epoch: 6| Step: 10
Training loss: 0.9593225121498108
Validation loss: 1.7890777023889686

Epoch: 6| Step: 11
Training loss: 0.5064936876296997
Validation loss: 1.8328909976508028

Epoch: 6| Step: 12
Training loss: 0.43665480613708496
Validation loss: 1.8062641441181142

Epoch: 6| Step: 13
Training loss: 0.9427680969238281
Validation loss: 1.7943938022018762

Epoch: 251| Step: 0
Training loss: 1.0213415622711182
Validation loss: 1.8039328821243779

Epoch: 6| Step: 1
Training loss: 0.7096062302589417
Validation loss: 1.7725784611958328

Epoch: 6| Step: 2
Training loss: 0.46574366092681885
Validation loss: 1.7758718536746116

Epoch: 6| Step: 3
Training loss: 0.7353302240371704
Validation loss: 1.7547647260850476

Epoch: 6| Step: 4
Training loss: 0.4891720116138458
Validation loss: 1.7577617373517764

Epoch: 6| Step: 5
Training loss: 0.5190393924713135
Validation loss: 1.7435689164746193

Epoch: 6| Step: 6
Training loss: 0.8707039952278137
Validation loss: 1.7454437132804625

Epoch: 6| Step: 7
Training loss: 1.2726283073425293
Validation loss: 1.7338773204434303

Epoch: 6| Step: 8
Training loss: 0.7681440114974976
Validation loss: 1.741153145349154

Epoch: 6| Step: 9
Training loss: 0.5895688533782959
Validation loss: 1.7501164046666955

Epoch: 6| Step: 10
Training loss: 0.8948659896850586
Validation loss: 1.7679773928016744

Epoch: 6| Step: 11
Training loss: 1.1386868953704834
Validation loss: 1.7825150053988221

Epoch: 6| Step: 12
Training loss: 0.8480445742607117
Validation loss: 1.7901121083126272

Epoch: 6| Step: 13
Training loss: 0.5591864585876465
Validation loss: 1.799568828716073

Epoch: 252| Step: 0
Training loss: 1.0199053287506104
Validation loss: 1.809368976982691

Epoch: 6| Step: 1
Training loss: 1.0373845100402832
Validation loss: 1.7656249833363358

Epoch: 6| Step: 2
Training loss: 0.7276673316955566
Validation loss: 1.7728446222120715

Epoch: 6| Step: 3
Training loss: 0.776920735836029
Validation loss: 1.7250460655458513

Epoch: 6| Step: 4
Training loss: 0.5848181247711182
Validation loss: 1.6982231998956332

Epoch: 6| Step: 5
Training loss: 0.7264692783355713
Validation loss: 1.679849220860389

Epoch: 6| Step: 6
Training loss: 0.5952433347702026
Validation loss: 1.6729431344616799

Epoch: 6| Step: 7
Training loss: 1.1419622898101807
Validation loss: 1.6852243561898508

Epoch: 6| Step: 8
Training loss: 0.8780536651611328
Validation loss: 1.6735659812086372

Epoch: 6| Step: 9
Training loss: 0.547159731388092
Validation loss: 1.6955091389276649

Epoch: 6| Step: 10
Training loss: 0.9296106696128845
Validation loss: 1.7202631222304476

Epoch: 6| Step: 11
Training loss: 0.7344177961349487
Validation loss: 1.7377192858726747

Epoch: 6| Step: 12
Training loss: 0.8057452440261841
Validation loss: 1.7495355657351914

Epoch: 6| Step: 13
Training loss: 1.0358301401138306
Validation loss: 1.7829684659998903

Epoch: 253| Step: 0
Training loss: 0.6068063974380493
Validation loss: 1.7791815239896056

Epoch: 6| Step: 1
Training loss: 0.7280226349830627
Validation loss: 1.7722314839722009

Epoch: 6| Step: 2
Training loss: 1.0375710725784302
Validation loss: 1.7632580200831096

Epoch: 6| Step: 3
Training loss: 0.9817054867744446
Validation loss: 1.7703401606570008

Epoch: 6| Step: 4
Training loss: 0.8747493028640747
Validation loss: 1.7579530362159974

Epoch: 6| Step: 5
Training loss: 1.0542514324188232
Validation loss: 1.7548099012785061

Epoch: 6| Step: 6
Training loss: 0.6249142289161682
Validation loss: 1.7250540192409227

Epoch: 6| Step: 7
Training loss: 0.8764204978942871
Validation loss: 1.7342466436406618

Epoch: 6| Step: 8
Training loss: 0.5058314800262451
Validation loss: 1.7320532183493338

Epoch: 6| Step: 9
Training loss: 0.40544646978378296
Validation loss: 1.7612701462161156

Epoch: 6| Step: 10
Training loss: 0.8594585657119751
Validation loss: 1.784251098350812

Epoch: 6| Step: 11
Training loss: 1.1669020652770996
Validation loss: 1.7628255633897678

Epoch: 6| Step: 12
Training loss: 0.862093448638916
Validation loss: 1.7556574985545168

Epoch: 6| Step: 13
Training loss: 0.7580080628395081
Validation loss: 1.7454148325868832

Epoch: 254| Step: 0
Training loss: 0.6541556119918823
Validation loss: 1.6941919403691446

Epoch: 6| Step: 1
Training loss: 0.7294477820396423
Validation loss: 1.6749423460293842

Epoch: 6| Step: 2
Training loss: 1.0812855958938599
Validation loss: 1.6868027564018004

Epoch: 6| Step: 3
Training loss: 1.1794888973236084
Validation loss: 1.6678887618485319

Epoch: 6| Step: 4
Training loss: 1.3089826107025146
Validation loss: 1.6967330491670998

Epoch: 6| Step: 5
Training loss: 0.5336595177650452
Validation loss: 1.6802936471918577

Epoch: 6| Step: 6
Training loss: 0.7184954881668091
Validation loss: 1.6899185795937814

Epoch: 6| Step: 7
Training loss: 0.8295356631278992
Validation loss: 1.7172986999634774

Epoch: 6| Step: 8
Training loss: 1.2517350912094116
Validation loss: 1.7463921372608473

Epoch: 6| Step: 9
Training loss: 0.7279694080352783
Validation loss: 1.7804023232511295

Epoch: 6| Step: 10
Training loss: 0.443612277507782
Validation loss: 1.8085514025021625

Epoch: 6| Step: 11
Training loss: 0.5704954862594604
Validation loss: 1.8260800710288427

Epoch: 6| Step: 12
Training loss: 0.5686616897583008
Validation loss: 1.804186805602043

Epoch: 6| Step: 13
Training loss: 0.22789709270000458
Validation loss: 1.7980965427173081

Epoch: 255| Step: 0
Training loss: 0.47980865836143494
Validation loss: 1.8335376106282717

Epoch: 6| Step: 1
Training loss: 0.5673161745071411
Validation loss: 1.8015714537712835

Epoch: 6| Step: 2
Training loss: 0.9560773372650146
Validation loss: 1.7652455465767973

Epoch: 6| Step: 3
Training loss: 0.9963561296463013
Validation loss: 1.7351270619259085

Epoch: 6| Step: 4
Training loss: 0.6139416694641113
Validation loss: 1.73053910398996

Epoch: 6| Step: 5
Training loss: 0.8064583539962769
Validation loss: 1.7564986854471185

Epoch: 6| Step: 6
Training loss: 0.8666247129440308
Validation loss: 1.7530965894781134

Epoch: 6| Step: 7
Training loss: 0.7018312215805054
Validation loss: 1.717638696393659

Epoch: 6| Step: 8
Training loss: 0.8243111371994019
Validation loss: 1.73338669858953

Epoch: 6| Step: 9
Training loss: 0.7212989330291748
Validation loss: 1.7443290525867092

Epoch: 6| Step: 10
Training loss: 0.7225902080535889
Validation loss: 1.7751755970780567

Epoch: 6| Step: 11
Training loss: 0.7448422908782959
Validation loss: 1.792364566556869

Epoch: 6| Step: 12
Training loss: 1.060278058052063
Validation loss: 1.8089278769749466

Epoch: 6| Step: 13
Training loss: 0.8867659568786621
Validation loss: 1.7918394214363509

Epoch: 256| Step: 0
Training loss: 0.4700772762298584
Validation loss: 1.753693740854981

Epoch: 6| Step: 1
Training loss: 0.7477775812149048
Validation loss: 1.7229957990748908

Epoch: 6| Step: 2
Training loss: 0.7734553813934326
Validation loss: 1.7114442176716302

Epoch: 6| Step: 3
Training loss: 0.9219714403152466
Validation loss: 1.733701120140732

Epoch: 6| Step: 4
Training loss: 0.9007343053817749
Validation loss: 1.7144799463210567

Epoch: 6| Step: 5
Training loss: 0.5462449789047241
Validation loss: 1.7155763923480947

Epoch: 6| Step: 6
Training loss: 0.4215470850467682
Validation loss: 1.7256728372266215

Epoch: 6| Step: 7
Training loss: 0.6073540449142456
Validation loss: 1.724413828183246

Epoch: 6| Step: 8
Training loss: 0.6088088154792786
Validation loss: 1.7376875364652244

Epoch: 6| Step: 9
Training loss: 0.4310677647590637
Validation loss: 1.7368355233182189

Epoch: 6| Step: 10
Training loss: 1.1988641023635864
Validation loss: 1.7603719439557803

Epoch: 6| Step: 11
Training loss: 1.1105939149856567
Validation loss: 1.7535786154449626

Epoch: 6| Step: 12
Training loss: 0.9981755018234253
Validation loss: 1.7970210800888717

Epoch: 6| Step: 13
Training loss: 0.5110709071159363
Validation loss: 1.781723452511654

Epoch: 257| Step: 0
Training loss: 1.176879644393921
Validation loss: 1.859972107794977

Epoch: 6| Step: 1
Training loss: 0.6986728310585022
Validation loss: 1.8586529429240892

Epoch: 6| Step: 2
Training loss: 0.9203958511352539
Validation loss: 1.8899388620930333

Epoch: 6| Step: 3
Training loss: 1.0065656900405884
Validation loss: 1.9063868420098418

Epoch: 6| Step: 4
Training loss: 0.6597652435302734
Validation loss: 1.886191019447901

Epoch: 6| Step: 5
Training loss: 0.9993057250976562
Validation loss: 1.8012649910424345

Epoch: 6| Step: 6
Training loss: 0.41805532574653625
Validation loss: 1.8157724616348103

Epoch: 6| Step: 7
Training loss: 0.6093328595161438
Validation loss: 1.7978456533083351

Epoch: 6| Step: 8
Training loss: 0.6657046675682068
Validation loss: 1.790694793065389

Epoch: 6| Step: 9
Training loss: 0.6589868664741516
Validation loss: 1.7300623373318744

Epoch: 6| Step: 10
Training loss: 0.5629005432128906
Validation loss: 1.6890007770189674

Epoch: 6| Step: 11
Training loss: 0.8971439003944397
Validation loss: 1.682572396852637

Epoch: 6| Step: 12
Training loss: 0.8495438694953918
Validation loss: 1.7268678667724773

Epoch: 6| Step: 13
Training loss: 1.0770121812820435
Validation loss: 1.7132627476928055

Epoch: 258| Step: 0
Training loss: 0.6935338377952576
Validation loss: 1.7248757808439192

Epoch: 6| Step: 1
Training loss: 1.1277425289154053
Validation loss: 1.734994258931888

Epoch: 6| Step: 2
Training loss: 0.8845752477645874
Validation loss: 1.739650180262904

Epoch: 6| Step: 3
Training loss: 0.7092123031616211
Validation loss: 1.7827807626416605

Epoch: 6| Step: 4
Training loss: 0.6318160891532898
Validation loss: 1.7810466071610809

Epoch: 6| Step: 5
Training loss: 0.8724877834320068
Validation loss: 1.7949734195586173

Epoch: 6| Step: 6
Training loss: 0.29054099321365356
Validation loss: 1.8056653366293958

Epoch: 6| Step: 7
Training loss: 1.266088604927063
Validation loss: 1.7761846293685257

Epoch: 6| Step: 8
Training loss: 0.5327528119087219
Validation loss: 1.7864130914852183

Epoch: 6| Step: 9
Training loss: 0.5990320444107056
Validation loss: 1.7872759347320886

Epoch: 6| Step: 10
Training loss: 0.522284746170044
Validation loss: 1.7798987844938874

Epoch: 6| Step: 11
Training loss: 0.6097620129585266
Validation loss: 1.7743520890512774

Epoch: 6| Step: 12
Training loss: 0.7741323709487915
Validation loss: 1.7934473932430308

Epoch: 6| Step: 13
Training loss: 0.7408803105354309
Validation loss: 1.78319582375147

Epoch: 259| Step: 0
Training loss: 0.8297715187072754
Validation loss: 1.8033431717144546

Epoch: 6| Step: 1
Training loss: 0.9092649221420288
Validation loss: 1.7796794547829577

Epoch: 6| Step: 2
Training loss: 0.9149988889694214
Validation loss: 1.7896337034881755

Epoch: 6| Step: 3
Training loss: 0.7719841003417969
Validation loss: 1.795148018867739

Epoch: 6| Step: 4
Training loss: 0.7968947887420654
Validation loss: 1.7726243298540834

Epoch: 6| Step: 5
Training loss: 0.80579674243927
Validation loss: 1.7724326220891808

Epoch: 6| Step: 6
Training loss: 0.4512503445148468
Validation loss: 1.7279138718881915

Epoch: 6| Step: 7
Training loss: 0.4377727508544922
Validation loss: 1.7252900446614912

Epoch: 6| Step: 8
Training loss: 0.4027511179447174
Validation loss: 1.7272755369063346

Epoch: 6| Step: 9
Training loss: 0.5938270688056946
Validation loss: 1.7253405894002607

Epoch: 6| Step: 10
Training loss: 0.8047564625740051
Validation loss: 1.7303076687679495

Epoch: 6| Step: 11
Training loss: 0.9415941834449768
Validation loss: 1.7595993844411706

Epoch: 6| Step: 12
Training loss: 0.5308517813682556
Validation loss: 1.7420201711757208

Epoch: 6| Step: 13
Training loss: 0.7694774866104126
Validation loss: 1.7367973391727736

Epoch: 260| Step: 0
Training loss: 0.7970353364944458
Validation loss: 1.7541183015351653

Epoch: 6| Step: 1
Training loss: 0.5713667273521423
Validation loss: 1.7263526865231094

Epoch: 6| Step: 2
Training loss: 0.6747251749038696
Validation loss: 1.7482357858329691

Epoch: 6| Step: 3
Training loss: 0.9359986186027527
Validation loss: 1.7515608918282293

Epoch: 6| Step: 4
Training loss: 0.7293339371681213
Validation loss: 1.7589480248830651

Epoch: 6| Step: 5
Training loss: 0.3535834848880768
Validation loss: 1.7705682452007006

Epoch: 6| Step: 6
Training loss: 0.8258330225944519
Validation loss: 1.7641225040599864

Epoch: 6| Step: 7
Training loss: 0.552523672580719
Validation loss: 1.763321307397658

Epoch: 6| Step: 8
Training loss: 0.5647546052932739
Validation loss: 1.7803307476864065

Epoch: 6| Step: 9
Training loss: 0.6702941060066223
Validation loss: 1.8144048901014431

Epoch: 6| Step: 10
Training loss: 0.8996570706367493
Validation loss: 1.7682589818072576

Epoch: 6| Step: 11
Training loss: 0.8934609293937683
Validation loss: 1.746028051581434

Epoch: 6| Step: 12
Training loss: 1.0523127317428589
Validation loss: 1.7105287518552554

Epoch: 6| Step: 13
Training loss: 0.5547281503677368
Validation loss: 1.7231264986017698

Epoch: 261| Step: 0
Training loss: 0.29728466272354126
Validation loss: 1.7387430501240555

Epoch: 6| Step: 1
Training loss: 1.4572352170944214
Validation loss: 1.757437825202942

Epoch: 6| Step: 2
Training loss: 0.7691832780838013
Validation loss: 1.7690096401399182

Epoch: 6| Step: 3
Training loss: 1.023234486579895
Validation loss: 1.786343010522986

Epoch: 6| Step: 4
Training loss: 0.6797569394111633
Validation loss: 1.7877916084822787

Epoch: 6| Step: 5
Training loss: 0.41861122846603394
Validation loss: 1.806359867895803

Epoch: 6| Step: 6
Training loss: 0.8666650056838989
Validation loss: 1.7905445791059924

Epoch: 6| Step: 7
Training loss: 0.6859046220779419
Validation loss: 1.7744733787352038

Epoch: 6| Step: 8
Training loss: 0.7292137145996094
Validation loss: 1.7494424760982554

Epoch: 6| Step: 9
Training loss: 0.6304153203964233
Validation loss: 1.7135459915284188

Epoch: 6| Step: 10
Training loss: 0.5488454699516296
Validation loss: 1.720064422135712

Epoch: 6| Step: 11
Training loss: 1.1293542385101318
Validation loss: 1.7471659862866966

Epoch: 6| Step: 12
Training loss: 0.5043702125549316
Validation loss: 1.7705447558433778

Epoch: 6| Step: 13
Training loss: 0.6260455250740051
Validation loss: 1.7759795342722247

Epoch: 262| Step: 0
Training loss: 1.2128955125808716
Validation loss: 1.789836081125403

Epoch: 6| Step: 1
Training loss: 0.6879045367240906
Validation loss: 1.7828299076326433

Epoch: 6| Step: 2
Training loss: 0.6366574168205261
Validation loss: 1.8020680078896143

Epoch: 6| Step: 3
Training loss: 0.7138037085533142
Validation loss: 1.7986171540393625

Epoch: 6| Step: 4
Training loss: 0.6196495294570923
Validation loss: 1.7969681601370535

Epoch: 6| Step: 5
Training loss: 0.7931501269340515
Validation loss: 1.7314154204501901

Epoch: 6| Step: 6
Training loss: 0.6989398002624512
Validation loss: 1.708658214538328

Epoch: 6| Step: 7
Training loss: 0.4241567850112915
Validation loss: 1.694274733143468

Epoch: 6| Step: 8
Training loss: 0.7253422737121582
Validation loss: 1.6851100024356638

Epoch: 6| Step: 9
Training loss: 0.5965301990509033
Validation loss: 1.6913237828080372

Epoch: 6| Step: 10
Training loss: 0.9611437916755676
Validation loss: 1.693778093143176

Epoch: 6| Step: 11
Training loss: 0.9670524001121521
Validation loss: 1.6806132460153231

Epoch: 6| Step: 12
Training loss: 0.666336178779602
Validation loss: 1.731602225252377

Epoch: 6| Step: 13
Training loss: 0.8102205395698547
Validation loss: 1.7491743000604774

Epoch: 263| Step: 0
Training loss: 0.5517160892486572
Validation loss: 1.8221006983069963

Epoch: 6| Step: 1
Training loss: 0.6758511066436768
Validation loss: 1.8267462497116418

Epoch: 6| Step: 2
Training loss: 0.9581701755523682
Validation loss: 1.8207679922862718

Epoch: 6| Step: 3
Training loss: 0.7989197969436646
Validation loss: 1.818568468093872

Epoch: 6| Step: 4
Training loss: 0.7882450819015503
Validation loss: 1.8111163467489264

Epoch: 6| Step: 5
Training loss: 0.5396761894226074
Validation loss: 1.813952370356488

Epoch: 6| Step: 6
Training loss: 0.45812559127807617
Validation loss: 1.7838286071695306

Epoch: 6| Step: 7
Training loss: 0.7789780497550964
Validation loss: 1.7489256371733963

Epoch: 6| Step: 8
Training loss: 0.9416155815124512
Validation loss: 1.7434140430983676

Epoch: 6| Step: 9
Training loss: 0.8002543449401855
Validation loss: 1.7300217702824583

Epoch: 6| Step: 10
Training loss: 0.4363898038864136
Validation loss: 1.7353482964218303

Epoch: 6| Step: 11
Training loss: 1.0936369895935059
Validation loss: 1.7270977240736767

Epoch: 6| Step: 12
Training loss: 0.5139789581298828
Validation loss: 1.7190979962707849

Epoch: 6| Step: 13
Training loss: 1.00791597366333
Validation loss: 1.7169035083504134

Epoch: 264| Step: 0
Training loss: 0.73859041929245
Validation loss: 1.7608927629327262

Epoch: 6| Step: 1
Training loss: 0.49653634428977966
Validation loss: 1.7566602614618116

Epoch: 6| Step: 2
Training loss: 1.02743661403656
Validation loss: 1.7981600120503416

Epoch: 6| Step: 3
Training loss: 0.4968869090080261
Validation loss: 1.7880943898231751

Epoch: 6| Step: 4
Training loss: 0.776699423789978
Validation loss: 1.7820504634611067

Epoch: 6| Step: 5
Training loss: 0.9064958095550537
Validation loss: 1.757107114279142

Epoch: 6| Step: 6
Training loss: 0.4504707455635071
Validation loss: 1.7468802672560497

Epoch: 6| Step: 7
Training loss: 0.9194924831390381
Validation loss: 1.7319491729941419

Epoch: 6| Step: 8
Training loss: 0.8820294141769409
Validation loss: 1.7435885449891448

Epoch: 6| Step: 9
Training loss: 0.648207426071167
Validation loss: 1.7228570920164867

Epoch: 6| Step: 10
Training loss: 0.5704712867736816
Validation loss: 1.670777823335381

Epoch: 6| Step: 11
Training loss: 0.9290306568145752
Validation loss: 1.705981143059269

Epoch: 6| Step: 12
Training loss: 0.8772321939468384
Validation loss: 1.697363982918442

Epoch: 6| Step: 13
Training loss: 0.4046550691127777
Validation loss: 1.69873567294049

Epoch: 265| Step: 0
Training loss: 0.6846843361854553
Validation loss: 1.6884415047143095

Epoch: 6| Step: 1
Training loss: 0.7656593322753906
Validation loss: 1.6775505542755127

Epoch: 6| Step: 2
Training loss: 0.5303651094436646
Validation loss: 1.7048495623373217

Epoch: 6| Step: 3
Training loss: 0.5592973232269287
Validation loss: 1.7389463583628337

Epoch: 6| Step: 4
Training loss: 1.3124021291732788
Validation loss: 1.7581226107894734

Epoch: 6| Step: 5
Training loss: 1.036426305770874
Validation loss: 1.7600703111258886

Epoch: 6| Step: 6
Training loss: 0.8507658243179321
Validation loss: 1.7764042910709177

Epoch: 6| Step: 7
Training loss: 0.7289204597473145
Validation loss: 1.75143269185097

Epoch: 6| Step: 8
Training loss: 0.35661745071411133
Validation loss: 1.7520413603833926

Epoch: 6| Step: 9
Training loss: 0.5098968148231506
Validation loss: 1.7272265111246417

Epoch: 6| Step: 10
Training loss: 0.6813518404960632
Validation loss: 1.722931565776948

Epoch: 6| Step: 11
Training loss: 0.45643073320388794
Validation loss: 1.7272809167062082

Epoch: 6| Step: 12
Training loss: 0.5328545570373535
Validation loss: 1.7143391204136673

Epoch: 6| Step: 13
Training loss: 0.774370551109314
Validation loss: 1.7422202312818138

Epoch: 266| Step: 0
Training loss: 0.5643189549446106
Validation loss: 1.7492102769113356

Epoch: 6| Step: 1
Training loss: 0.7492449283599854
Validation loss: 1.802664682429324

Epoch: 6| Step: 2
Training loss: 0.6740572452545166
Validation loss: 1.8051165278239916

Epoch: 6| Step: 3
Training loss: 0.8794372081756592
Validation loss: 1.7952882320650163

Epoch: 6| Step: 4
Training loss: 0.8743273019790649
Validation loss: 1.7707617987868607

Epoch: 6| Step: 5
Training loss: 0.9557937979698181
Validation loss: 1.764654198000508

Epoch: 6| Step: 6
Training loss: 0.44888824224472046
Validation loss: 1.7456313922841062

Epoch: 6| Step: 7
Training loss: 0.5188602209091187
Validation loss: 1.7039008371291622

Epoch: 6| Step: 8
Training loss: 0.7400433421134949
Validation loss: 1.713030715142527

Epoch: 6| Step: 9
Training loss: 0.6253790855407715
Validation loss: 1.7088449911404682

Epoch: 6| Step: 10
Training loss: 0.3630949556827545
Validation loss: 1.7001222141327397

Epoch: 6| Step: 11
Training loss: 0.8777195811271667
Validation loss: 1.7101778702069355

Epoch: 6| Step: 12
Training loss: 0.5660302042961121
Validation loss: 1.7200923081367248

Epoch: 6| Step: 13
Training loss: 0.7183042168617249
Validation loss: 1.7502584713761524

Epoch: 267| Step: 0
Training loss: 0.6560733318328857
Validation loss: 1.7568822291589552

Epoch: 6| Step: 1
Training loss: 0.6983107328414917
Validation loss: 1.7436146274689706

Epoch: 6| Step: 2
Training loss: 0.7705646753311157
Validation loss: 1.7575023148649482

Epoch: 6| Step: 3
Training loss: 1.0526509284973145
Validation loss: 1.6949768399679532

Epoch: 6| Step: 4
Training loss: 0.7433419227600098
Validation loss: 1.676207846210849

Epoch: 6| Step: 5
Training loss: 0.3830986022949219
Validation loss: 1.6625537641586796

Epoch: 6| Step: 6
Training loss: 0.7751191854476929
Validation loss: 1.6791536320922196

Epoch: 6| Step: 7
Training loss: 0.8796319365501404
Validation loss: 1.7048557419930734

Epoch: 6| Step: 8
Training loss: 0.4820871949195862
Validation loss: 1.7398900703717304

Epoch: 6| Step: 9
Training loss: 0.7040269374847412
Validation loss: 1.7434169195031608

Epoch: 6| Step: 10
Training loss: 0.8667855858802795
Validation loss: 1.7644827327420634

Epoch: 6| Step: 11
Training loss: 0.6271824836730957
Validation loss: 1.7717058838054698

Epoch: 6| Step: 12
Training loss: 0.7177071571350098
Validation loss: 1.8263007774147937

Epoch: 6| Step: 13
Training loss: 0.5910286903381348
Validation loss: 1.7987679666088474

Epoch: 268| Step: 0
Training loss: 0.8883047699928284
Validation loss: 1.787735487825127

Epoch: 6| Step: 1
Training loss: 0.4776184558868408
Validation loss: 1.7293557659272225

Epoch: 6| Step: 2
Training loss: 0.5674682855606079
Validation loss: 1.708401418501331

Epoch: 6| Step: 3
Training loss: 0.5445223450660706
Validation loss: 1.6801045094766924

Epoch: 6| Step: 4
Training loss: 1.1234337091445923
Validation loss: 1.6656949007382957

Epoch: 6| Step: 5
Training loss: 0.8667893409729004
Validation loss: 1.686977392883711

Epoch: 6| Step: 6
Training loss: 0.7695150375366211
Validation loss: 1.6919903511642127

Epoch: 6| Step: 7
Training loss: 0.5567865371704102
Validation loss: 1.6911293665568035

Epoch: 6| Step: 8
Training loss: 0.5991545915603638
Validation loss: 1.692998396453037

Epoch: 6| Step: 9
Training loss: 0.5826560258865356
Validation loss: 1.7669431547964773

Epoch: 6| Step: 10
Training loss: 0.7864201068878174
Validation loss: 1.7930611653994488

Epoch: 6| Step: 11
Training loss: 0.7253944873809814
Validation loss: 1.7979107736259379

Epoch: 6| Step: 12
Training loss: 0.686987042427063
Validation loss: 1.7707642111726987

Epoch: 6| Step: 13
Training loss: 0.5665533542633057
Validation loss: 1.753340087911134

Epoch: 269| Step: 0
Training loss: 0.7278687357902527
Validation loss: 1.7552344747768935

Epoch: 6| Step: 1
Training loss: 0.5234292149543762
Validation loss: 1.7353817519321237

Epoch: 6| Step: 2
Training loss: 0.6701928377151489
Validation loss: 1.716950931856709

Epoch: 6| Step: 3
Training loss: 0.40277302265167236
Validation loss: 1.7338411320922196

Epoch: 6| Step: 4
Training loss: 0.8640964031219482
Validation loss: 1.7058906298811718

Epoch: 6| Step: 5
Training loss: 0.931476354598999
Validation loss: 1.7008885452824254

Epoch: 6| Step: 6
Training loss: 0.37680020928382874
Validation loss: 1.7017386523626183

Epoch: 6| Step: 7
Training loss: 0.9095320105552673
Validation loss: 1.6986323671956216

Epoch: 6| Step: 8
Training loss: 0.6164394617080688
Validation loss: 1.7418722362928494

Epoch: 6| Step: 9
Training loss: 0.583398163318634
Validation loss: 1.7323997853904642

Epoch: 6| Step: 10
Training loss: 0.4029673933982849
Validation loss: 1.742464393697759

Epoch: 6| Step: 11
Training loss: 0.5898034572601318
Validation loss: 1.7765334408770326

Epoch: 6| Step: 12
Training loss: 0.6023573875427246
Validation loss: 1.8090137691907986

Epoch: 6| Step: 13
Training loss: 1.2042393684387207
Validation loss: 1.7843437053823983

Epoch: 270| Step: 0
Training loss: 0.6136072874069214
Validation loss: 1.792388508396764

Epoch: 6| Step: 1
Training loss: 0.4721885621547699
Validation loss: 1.8115700585867769

Epoch: 6| Step: 2
Training loss: 0.5195170640945435
Validation loss: 1.7696237922996603

Epoch: 6| Step: 3
Training loss: 1.1764332056045532
Validation loss: 1.7634422907265284

Epoch: 6| Step: 4
Training loss: 0.7466621398925781
Validation loss: 1.7110530612289265

Epoch: 6| Step: 5
Training loss: 0.32468700408935547
Validation loss: 1.6683314666953137

Epoch: 6| Step: 6
Training loss: 0.6059982180595398
Validation loss: 1.682630192848944

Epoch: 6| Step: 7
Training loss: 0.8886886239051819
Validation loss: 1.7049740655447847

Epoch: 6| Step: 8
Training loss: 0.2951149642467499
Validation loss: 1.7184260327328917

Epoch: 6| Step: 9
Training loss: 0.8056646585464478
Validation loss: 1.6767961056001726

Epoch: 6| Step: 10
Training loss: 0.43968477845191956
Validation loss: 1.6891189544431624

Epoch: 6| Step: 11
Training loss: 0.7906018495559692
Validation loss: 1.743805108531829

Epoch: 6| Step: 12
Training loss: 0.8851701021194458
Validation loss: 1.7838428084568312

Epoch: 6| Step: 13
Training loss: 0.45460373163223267
Validation loss: 1.809091652593305

Epoch: 271| Step: 0
Training loss: 0.6229183077812195
Validation loss: 1.8398247841865785

Epoch: 6| Step: 1
Training loss: 0.35755038261413574
Validation loss: 1.8040212815807712

Epoch: 6| Step: 2
Training loss: 0.40096965432167053
Validation loss: 1.8118097243770477

Epoch: 6| Step: 3
Training loss: 0.5586822032928467
Validation loss: 1.8270279220355454

Epoch: 6| Step: 4
Training loss: 0.4903021454811096
Validation loss: 1.8471183187218123

Epoch: 6| Step: 5
Training loss: 1.0123951435089111
Validation loss: 1.8416771350368377

Epoch: 6| Step: 6
Training loss: 0.9608394503593445
Validation loss: 1.8141351758792836

Epoch: 6| Step: 7
Training loss: 0.802951991558075
Validation loss: 1.7703327645537674

Epoch: 6| Step: 8
Training loss: 0.832366406917572
Validation loss: 1.6988675645602647

Epoch: 6| Step: 9
Training loss: 0.7549711465835571
Validation loss: 1.6721045163369948

Epoch: 6| Step: 10
Training loss: 0.6848946213722229
Validation loss: 1.6908069887468893

Epoch: 6| Step: 11
Training loss: 0.6793994307518005
Validation loss: 1.7377828295512865

Epoch: 6| Step: 12
Training loss: 1.0104858875274658
Validation loss: 1.747362841841995

Epoch: 6| Step: 13
Training loss: 0.6246271729469299
Validation loss: 1.7853907949181014

Epoch: 272| Step: 0
Training loss: 0.6261370182037354
Validation loss: 1.8063477880211287

Epoch: 6| Step: 1
Training loss: 0.8169348239898682
Validation loss: 1.8246300528126378

Epoch: 6| Step: 2
Training loss: 0.692207932472229
Validation loss: 1.858784890943958

Epoch: 6| Step: 3
Training loss: 0.9236924648284912
Validation loss: 1.8982213184397707

Epoch: 6| Step: 4
Training loss: 1.123975396156311
Validation loss: 1.971167165745971

Epoch: 6| Step: 5
Training loss: 0.41816478967666626
Validation loss: 1.9128467152195592

Epoch: 6| Step: 6
Training loss: 0.8060789108276367
Validation loss: 1.8411727054144746

Epoch: 6| Step: 7
Training loss: 0.688410222530365
Validation loss: 1.794989837113247

Epoch: 6| Step: 8
Training loss: 0.44566014409065247
Validation loss: 1.7775572499921244

Epoch: 6| Step: 9
Training loss: 0.45293211936950684
Validation loss: 1.7478639784679617

Epoch: 6| Step: 10
Training loss: 0.6060747504234314
Validation loss: 1.7770402636579288

Epoch: 6| Step: 11
Training loss: 0.9673326015472412
Validation loss: 1.7878991762797039

Epoch: 6| Step: 12
Training loss: 0.7119945287704468
Validation loss: 1.7621263150245912

Epoch: 6| Step: 13
Training loss: 0.8161001205444336
Validation loss: 1.7468996496610745

Epoch: 273| Step: 0
Training loss: 0.5440247654914856
Validation loss: 1.7146606624767344

Epoch: 6| Step: 1
Training loss: 0.5618551969528198
Validation loss: 1.71144744401337

Epoch: 6| Step: 2
Training loss: 0.6966401934623718
Validation loss: 1.7255559595682288

Epoch: 6| Step: 3
Training loss: 0.5995075702667236
Validation loss: 1.725108995232531

Epoch: 6| Step: 4
Training loss: 0.8566706776618958
Validation loss: 1.7035102690419843

Epoch: 6| Step: 5
Training loss: 0.7042892575263977
Validation loss: 1.7711138020279587

Epoch: 6| Step: 6
Training loss: 0.7931158542633057
Validation loss: 1.7580235190288995

Epoch: 6| Step: 7
Training loss: 0.8520065546035767
Validation loss: 1.7622272506836922

Epoch: 6| Step: 8
Training loss: 0.6191375851631165
Validation loss: 1.7747667720240932

Epoch: 6| Step: 9
Training loss: 0.8189855813980103
Validation loss: 1.7725211522912467

Epoch: 6| Step: 10
Training loss: 0.7042551040649414
Validation loss: 1.7770929080183788

Epoch: 6| Step: 11
Training loss: 0.4796462059020996
Validation loss: 1.7801315579363095

Epoch: 6| Step: 12
Training loss: 0.6717082858085632
Validation loss: 1.7556536197662354

Epoch: 6| Step: 13
Training loss: 0.3946746587753296
Validation loss: 1.7126798514396913

Epoch: 274| Step: 0
Training loss: 0.5682565569877625
Validation loss: 1.7131986297586912

Epoch: 6| Step: 1
Training loss: 0.5820692777633667
Validation loss: 1.7128007283774755

Epoch: 6| Step: 2
Training loss: 0.6679583787918091
Validation loss: 1.7235569569372362

Epoch: 6| Step: 3
Training loss: 0.7005219459533691
Validation loss: 1.7268110513687134

Epoch: 6| Step: 4
Training loss: 0.6528966426849365
Validation loss: 1.76110843817393

Epoch: 6| Step: 5
Training loss: 1.08594810962677
Validation loss: 1.7603000171722905

Epoch: 6| Step: 6
Training loss: 0.5431263446807861
Validation loss: 1.7642243933934036

Epoch: 6| Step: 7
Training loss: 0.5612067580223083
Validation loss: 1.7637228991395684

Epoch: 6| Step: 8
Training loss: 0.452012836933136
Validation loss: 1.7447007035696378

Epoch: 6| Step: 9
Training loss: 0.6849544048309326
Validation loss: 1.7632156661761704

Epoch: 6| Step: 10
Training loss: 1.0212055444717407
Validation loss: 1.6949087612090572

Epoch: 6| Step: 11
Training loss: 0.6665490865707397
Validation loss: 1.6810749115482453

Epoch: 6| Step: 12
Training loss: 0.6186361908912659
Validation loss: 1.671371772725095

Epoch: 6| Step: 13
Training loss: 0.5963594913482666
Validation loss: 1.6495799364582184

Epoch: 275| Step: 0
Training loss: 0.5284122824668884
Validation loss: 1.6608966691519624

Epoch: 6| Step: 1
Training loss: 0.6541098356246948
Validation loss: 1.6750410513211322

Epoch: 6| Step: 2
Training loss: 0.5955162048339844
Validation loss: 1.6510316607772664

Epoch: 6| Step: 3
Training loss: 0.8728092908859253
Validation loss: 1.669422326549407

Epoch: 6| Step: 4
Training loss: 0.3195304870605469
Validation loss: 1.6738302374398837

Epoch: 6| Step: 5
Training loss: 0.7393268346786499
Validation loss: 1.7928990228201753

Epoch: 6| Step: 6
Training loss: 0.8939778804779053
Validation loss: 1.7834439264830722

Epoch: 6| Step: 7
Training loss: 0.8755826950073242
Validation loss: 1.8384833143603416

Epoch: 6| Step: 8
Training loss: 0.6104758977890015
Validation loss: 1.8446752871236494

Epoch: 6| Step: 9
Training loss: 0.42337939143180847
Validation loss: 1.7963006355429207

Epoch: 6| Step: 10
Training loss: 0.6378152966499329
Validation loss: 1.7734715502749208

Epoch: 6| Step: 11
Training loss: 0.7603781223297119
Validation loss: 1.7237094589458999

Epoch: 6| Step: 12
Training loss: 0.8075175881385803
Validation loss: 1.719372045609259

Epoch: 6| Step: 13
Training loss: 0.6080029010772705
Validation loss: 1.6964240074157715

Epoch: 276| Step: 0
Training loss: 0.3683836758136749
Validation loss: 1.7206972991266558

Epoch: 6| Step: 1
Training loss: 0.9518770575523376
Validation loss: 1.7198533832385976

Epoch: 6| Step: 2
Training loss: 0.5676076412200928
Validation loss: 1.7356467682828185

Epoch: 6| Step: 3
Training loss: 0.660269021987915
Validation loss: 1.720344679329985

Epoch: 6| Step: 4
Training loss: 0.49340343475341797
Validation loss: 1.7425381368206394

Epoch: 6| Step: 5
Training loss: 0.5113850831985474
Validation loss: 1.7570797243425924

Epoch: 6| Step: 6
Training loss: 0.5395470261573792
Validation loss: 1.752169180941838

Epoch: 6| Step: 7
Training loss: 0.39458805322647095
Validation loss: 1.7541516057906612

Epoch: 6| Step: 8
Training loss: 0.7179069519042969
Validation loss: 1.731272667966863

Epoch: 6| Step: 9
Training loss: 0.7106122970581055
Validation loss: 1.7304754693021056

Epoch: 6| Step: 10
Training loss: 0.46371111273765564
Validation loss: 1.7345298849126345

Epoch: 6| Step: 11
Training loss: 1.0334612131118774
Validation loss: 1.734860611218278

Epoch: 6| Step: 12
Training loss: 0.6050399541854858
Validation loss: 1.7675143570028327

Epoch: 6| Step: 13
Training loss: 0.74993497133255
Validation loss: 1.7659299130080848

Epoch: 277| Step: 0
Training loss: 0.45662087202072144
Validation loss: 1.7824021065106956

Epoch: 6| Step: 1
Training loss: 0.5025528073310852
Validation loss: 1.7859062917770878

Epoch: 6| Step: 2
Training loss: 0.6885974407196045
Validation loss: 1.7855329398185975

Epoch: 6| Step: 3
Training loss: 0.6252005696296692
Validation loss: 1.7578546847066572

Epoch: 6| Step: 4
Training loss: 0.6255720257759094
Validation loss: 1.76201295339933

Epoch: 6| Step: 5
Training loss: 0.45446422696113586
Validation loss: 1.7262798393926313

Epoch: 6| Step: 6
Training loss: 0.7251596450805664
Validation loss: 1.6805740018044748

Epoch: 6| Step: 7
Training loss: 1.0785772800445557
Validation loss: 1.7012890897771364

Epoch: 6| Step: 8
Training loss: 0.835183322429657
Validation loss: 1.6883280084979149

Epoch: 6| Step: 9
Training loss: 0.5476721525192261
Validation loss: 1.7006359715615549

Epoch: 6| Step: 10
Training loss: 0.45280948281288147
Validation loss: 1.6993287596651303

Epoch: 6| Step: 11
Training loss: 0.7214037179946899
Validation loss: 1.7409355909593645

Epoch: 6| Step: 12
Training loss: 0.7035822868347168
Validation loss: 1.7938830814053934

Epoch: 6| Step: 13
Training loss: 0.41696107387542725
Validation loss: 1.7919606098564722

Epoch: 278| Step: 0
Training loss: 0.46109068393707275
Validation loss: 1.845475414747833

Epoch: 6| Step: 1
Training loss: 0.7206968069076538
Validation loss: 1.8691562939715642

Epoch: 6| Step: 2
Training loss: 0.4931391477584839
Validation loss: 1.8912548993223457

Epoch: 6| Step: 3
Training loss: 0.9369211196899414
Validation loss: 1.8759187126672396

Epoch: 6| Step: 4
Training loss: 0.569846510887146
Validation loss: 1.8642065576327744

Epoch: 6| Step: 5
Training loss: 0.9360071420669556
Validation loss: 1.811030376342035

Epoch: 6| Step: 6
Training loss: 0.7692852020263672
Validation loss: 1.798899651855551

Epoch: 6| Step: 7
Training loss: 0.6856100559234619
Validation loss: 1.7671796788451493

Epoch: 6| Step: 8
Training loss: 0.5570628643035889
Validation loss: 1.7337119643406202

Epoch: 6| Step: 9
Training loss: 0.4661305844783783
Validation loss: 1.7230538155442925

Epoch: 6| Step: 10
Training loss: 0.8321295976638794
Validation loss: 1.6857106826638664

Epoch: 6| Step: 11
Training loss: 0.465700626373291
Validation loss: 1.7479085858150194

Epoch: 6| Step: 12
Training loss: 0.5289306640625
Validation loss: 1.75040062140393

Epoch: 6| Step: 13
Training loss: 0.5769670605659485
Validation loss: 1.7694603255999986

Epoch: 279| Step: 0
Training loss: 0.5221530795097351
Validation loss: 1.7746990983204176

Epoch: 6| Step: 1
Training loss: 0.5223506689071655
Validation loss: 1.7863000772332633

Epoch: 6| Step: 2
Training loss: 0.5869739651679993
Validation loss: 1.80076176504935

Epoch: 6| Step: 3
Training loss: 1.0128698348999023
Validation loss: 1.7828156396906862

Epoch: 6| Step: 4
Training loss: 0.552519679069519
Validation loss: 1.7586178138691893

Epoch: 6| Step: 5
Training loss: 0.6436923742294312
Validation loss: 1.7783852443900159

Epoch: 6| Step: 6
Training loss: 0.5881748199462891
Validation loss: 1.7814019277531614

Epoch: 6| Step: 7
Training loss: 0.4456624984741211
Validation loss: 1.8326560040955902

Epoch: 6| Step: 8
Training loss: 0.5411289930343628
Validation loss: 1.8123136399894633

Epoch: 6| Step: 9
Training loss: 0.20211203396320343
Validation loss: 1.78913281297171

Epoch: 6| Step: 10
Training loss: 0.6422201991081238
Validation loss: 1.7454831677098428

Epoch: 6| Step: 11
Training loss: 0.47489815950393677
Validation loss: 1.731305908131343

Epoch: 6| Step: 12
Training loss: 1.4222661256790161
Validation loss: 1.681421181207062

Epoch: 6| Step: 13
Training loss: 0.3033182919025421
Validation loss: 1.6732522338949225

Epoch: 280| Step: 0
Training loss: 0.9238787293434143
Validation loss: 1.6768957581571353

Epoch: 6| Step: 1
Training loss: 0.5366967916488647
Validation loss: 1.6705961958054574

Epoch: 6| Step: 2
Training loss: 0.5235518217086792
Validation loss: 1.7053126750453826

Epoch: 6| Step: 3
Training loss: 0.42529481649398804
Validation loss: 1.7562021388802478

Epoch: 6| Step: 4
Training loss: 1.1716922521591187
Validation loss: 1.8205203676736483

Epoch: 6| Step: 5
Training loss: 0.8366155028343201
Validation loss: 1.829182683780629

Epoch: 6| Step: 6
Training loss: 0.40309852361679077
Validation loss: 1.789207358514109

Epoch: 6| Step: 7
Training loss: 0.3393705189228058
Validation loss: 1.7745529208132016

Epoch: 6| Step: 8
Training loss: 0.6324607729911804
Validation loss: 1.7751342096636373

Epoch: 6| Step: 9
Training loss: 0.6121992468833923
Validation loss: 1.7466852523947274

Epoch: 6| Step: 10
Training loss: 0.6658433675765991
Validation loss: 1.732084208919156

Epoch: 6| Step: 11
Training loss: 0.284477174282074
Validation loss: 1.6885498954403786

Epoch: 6| Step: 12
Training loss: 0.7552619576454163
Validation loss: 1.6572378771279448

Epoch: 6| Step: 13
Training loss: 0.5711594223976135
Validation loss: 1.6677134806110012

Epoch: 281| Step: 0
Training loss: 0.9250363707542419
Validation loss: 1.66185079210548

Epoch: 6| Step: 1
Training loss: 0.6227432489395142
Validation loss: 1.6548098351365776

Epoch: 6| Step: 2
Training loss: 0.5852582454681396
Validation loss: 1.7061474246363486

Epoch: 6| Step: 3
Training loss: 0.4558739960193634
Validation loss: 1.7587864860411613

Epoch: 6| Step: 4
Training loss: 0.37335747480392456
Validation loss: 1.819430064129573

Epoch: 6| Step: 5
Training loss: 0.7868145108222961
Validation loss: 1.8544750880169611

Epoch: 6| Step: 6
Training loss: 0.46001744270324707
Validation loss: 1.8724595564667896

Epoch: 6| Step: 7
Training loss: 0.7600510120391846
Validation loss: 1.9113098229131391

Epoch: 6| Step: 8
Training loss: 0.46458280086517334
Validation loss: 1.8940326834237704

Epoch: 6| Step: 9
Training loss: 0.5543988943099976
Validation loss: 1.856548419562719

Epoch: 6| Step: 10
Training loss: 0.603452742099762
Validation loss: 1.8283060584017026

Epoch: 6| Step: 11
Training loss: 0.5476746559143066
Validation loss: 1.753332176516133

Epoch: 6| Step: 12
Training loss: 0.5593637228012085
Validation loss: 1.7152469170990812

Epoch: 6| Step: 13
Training loss: 0.5181717872619629
Validation loss: 1.683576335189163

Epoch: 282| Step: 0
Training loss: 0.7793024778366089
Validation loss: 1.660602472161734

Epoch: 6| Step: 1
Training loss: 0.9652203917503357
Validation loss: 1.650873916123503

Epoch: 6| Step: 2
Training loss: 0.6696364283561707
Validation loss: 1.6246217963516072

Epoch: 6| Step: 3
Training loss: 0.9037965536117554
Validation loss: 1.6491636473645446

Epoch: 6| Step: 4
Training loss: 0.659203290939331
Validation loss: 1.6544263465430147

Epoch: 6| Step: 5
Training loss: 0.5029162168502808
Validation loss: 1.6841925754342029

Epoch: 6| Step: 6
Training loss: 0.3432435989379883
Validation loss: 1.7176244015334754

Epoch: 6| Step: 7
Training loss: 0.4047684073448181
Validation loss: 1.7378578339853594

Epoch: 6| Step: 8
Training loss: 0.2752237915992737
Validation loss: 1.8128401079485494

Epoch: 6| Step: 9
Training loss: 0.5264227986335754
Validation loss: 1.8668342239113265

Epoch: 6| Step: 10
Training loss: 0.8877838253974915
Validation loss: 1.8700509507169005

Epoch: 6| Step: 11
Training loss: 0.32011890411376953
Validation loss: 1.9104698883589877

Epoch: 6| Step: 12
Training loss: 0.9588278532028198
Validation loss: 1.9252288187703779

Epoch: 6| Step: 13
Training loss: 0.9042385816574097
Validation loss: 1.8912009295596872

Epoch: 283| Step: 0
Training loss: 0.7758324146270752
Validation loss: 1.845778795980638

Epoch: 6| Step: 1
Training loss: 0.9503618478775024
Validation loss: 1.8503844866188623

Epoch: 6| Step: 2
Training loss: 0.5052580833435059
Validation loss: 1.7715728949475031

Epoch: 6| Step: 3
Training loss: 0.6288663148880005
Validation loss: 1.7091569862058085

Epoch: 6| Step: 4
Training loss: 0.38856205344200134
Validation loss: 1.693937760527416

Epoch: 6| Step: 5
Training loss: 0.8269134759902954
Validation loss: 1.6744061413631643

Epoch: 6| Step: 6
Training loss: 0.5891452431678772
Validation loss: 1.6899021556300502

Epoch: 6| Step: 7
Training loss: 0.5392955541610718
Validation loss: 1.7078371611974572

Epoch: 6| Step: 8
Training loss: 0.49287623167037964
Validation loss: 1.7419564493240849

Epoch: 6| Step: 9
Training loss: 0.765033483505249
Validation loss: 1.7396666157630183

Epoch: 6| Step: 10
Training loss: 0.5757649540901184
Validation loss: 1.748199709000126

Epoch: 6| Step: 11
Training loss: 0.32681185007095337
Validation loss: 1.7651301122480823

Epoch: 6| Step: 12
Training loss: 0.5432549715042114
Validation loss: 1.753226658349396

Epoch: 6| Step: 13
Training loss: 0.5252212882041931
Validation loss: 1.756528405733006

Epoch: 284| Step: 0
Training loss: 0.5728809833526611
Validation loss: 1.7389089574096024

Epoch: 6| Step: 1
Training loss: 0.37385568022727966
Validation loss: 1.7470821398560719

Epoch: 6| Step: 2
Training loss: 0.3737436532974243
Validation loss: 1.7535582345019105

Epoch: 6| Step: 3
Training loss: 0.8263223171234131
Validation loss: 1.7693589977038804

Epoch: 6| Step: 4
Training loss: 0.48335766792297363
Validation loss: 1.7832635897462086

Epoch: 6| Step: 5
Training loss: 0.7096197009086609
Validation loss: 1.7749470997882146

Epoch: 6| Step: 6
Training loss: 0.583918035030365
Validation loss: 1.761975581927966

Epoch: 6| Step: 7
Training loss: 0.40111103653907776
Validation loss: 1.751018681833821

Epoch: 6| Step: 8
Training loss: 0.6032524704933167
Validation loss: 1.7350442755606867

Epoch: 6| Step: 9
Training loss: 0.467857301235199
Validation loss: 1.732954018859453

Epoch: 6| Step: 10
Training loss: 0.7839210033416748
Validation loss: 1.7067017221963534

Epoch: 6| Step: 11
Training loss: 0.5839483141899109
Validation loss: 1.6910287808346491

Epoch: 6| Step: 12
Training loss: 0.7724119424819946
Validation loss: 1.6503801102279334

Epoch: 6| Step: 13
Training loss: 0.516787052154541
Validation loss: 1.671521758520475

Epoch: 285| Step: 0
Training loss: 0.5064079761505127
Validation loss: 1.6320704234543668

Epoch: 6| Step: 1
Training loss: 0.49650245904922485
Validation loss: 1.6480325165615286

Epoch: 6| Step: 2
Training loss: 0.7018948793411255
Validation loss: 1.642911050909309

Epoch: 6| Step: 3
Training loss: 0.35113221406936646
Validation loss: 1.6616912791805882

Epoch: 6| Step: 4
Training loss: 0.5992994904518127
Validation loss: 1.6733617013500584

Epoch: 6| Step: 5
Training loss: 0.5573167204856873
Validation loss: 1.6697289738603818

Epoch: 6| Step: 6
Training loss: 0.44100743532180786
Validation loss: 1.7073056928573116

Epoch: 6| Step: 7
Training loss: 0.654076099395752
Validation loss: 1.7284478051688081

Epoch: 6| Step: 8
Training loss: 0.5986008644104004
Validation loss: 1.8084303999459872

Epoch: 6| Step: 9
Training loss: 0.6926060914993286
Validation loss: 1.8100050098152571

Epoch: 6| Step: 10
Training loss: 0.6752101182937622
Validation loss: 1.8229961959264611

Epoch: 6| Step: 11
Training loss: 0.38602563738822937
Validation loss: 1.8308438344668316

Epoch: 6| Step: 12
Training loss: 0.5280284881591797
Validation loss: 1.795999095004092

Epoch: 6| Step: 13
Training loss: 0.519817590713501
Validation loss: 1.7559791085540608

Epoch: 286| Step: 0
Training loss: 0.39011427760124207
Validation loss: 1.7239155641166113

Epoch: 6| Step: 1
Training loss: 0.29129958152770996
Validation loss: 1.7054604086824643

Epoch: 6| Step: 2
Training loss: 0.6565471887588501
Validation loss: 1.6720778249925183

Epoch: 6| Step: 3
Training loss: 0.9346928596496582
Validation loss: 1.6431636502665858

Epoch: 6| Step: 4
Training loss: 0.5322946310043335
Validation loss: 1.6659899001480432

Epoch: 6| Step: 5
Training loss: 0.594031572341919
Validation loss: 1.673424272127049

Epoch: 6| Step: 6
Training loss: 0.49015241861343384
Validation loss: 1.7033188855776222

Epoch: 6| Step: 7
Training loss: 0.8341473340988159
Validation loss: 1.7369457842201315

Epoch: 6| Step: 8
Training loss: 0.3876570463180542
Validation loss: 1.7070790349796254

Epoch: 6| Step: 9
Training loss: 0.5013456344604492
Validation loss: 1.7053721412535636

Epoch: 6| Step: 10
Training loss: 0.46496066451072693
Validation loss: 1.6980894534818587

Epoch: 6| Step: 11
Training loss: 0.5230441689491272
Validation loss: 1.7359725108710669

Epoch: 6| Step: 12
Training loss: 0.6885457038879395
Validation loss: 1.764809686650512

Epoch: 6| Step: 13
Training loss: 0.4446209669113159
Validation loss: 1.776734628985005

Epoch: 287| Step: 0
Training loss: 0.6783425807952881
Validation loss: 1.7792462456610896

Epoch: 6| Step: 1
Training loss: 0.581034779548645
Validation loss: 1.7460967930414344

Epoch: 6| Step: 2
Training loss: 0.47915562987327576
Validation loss: 1.7163377243985412

Epoch: 6| Step: 3
Training loss: 0.3708201050758362
Validation loss: 1.697400660925014

Epoch: 6| Step: 4
Training loss: 1.196944236755371
Validation loss: 1.695051179137281

Epoch: 6| Step: 5
Training loss: 0.32870179414749146
Validation loss: 1.722025103466485

Epoch: 6| Step: 6
Training loss: 0.38325756788253784
Validation loss: 1.7464444150206864

Epoch: 6| Step: 7
Training loss: 0.4038241505622864
Validation loss: 1.7410413026809692

Epoch: 6| Step: 8
Training loss: 0.3124244511127472
Validation loss: 1.7368965982108988

Epoch: 6| Step: 9
Training loss: 0.6544317007064819
Validation loss: 1.713412978315866

Epoch: 6| Step: 10
Training loss: 0.547764003276825
Validation loss: 1.7231782123606691

Epoch: 6| Step: 11
Training loss: 0.5849336981773376
Validation loss: 1.7220070810728176

Epoch: 6| Step: 12
Training loss: 0.5763640403747559
Validation loss: 1.7034839712163454

Epoch: 6| Step: 13
Training loss: 0.43666571378707886
Validation loss: 1.739431499153055

Epoch: 288| Step: 0
Training loss: 0.35688894987106323
Validation loss: 1.7445940304827947

Epoch: 6| Step: 1
Training loss: 0.27994245290756226
Validation loss: 1.7253019296994774

Epoch: 6| Step: 2
Training loss: 0.4679306447505951
Validation loss: 1.7567119624025078

Epoch: 6| Step: 3
Training loss: 0.38427549600601196
Validation loss: 1.7477857566648913

Epoch: 6| Step: 4
Training loss: 0.5551438331604004
Validation loss: 1.7533659447905838

Epoch: 6| Step: 5
Training loss: 0.5374062657356262
Validation loss: 1.730425653919097

Epoch: 6| Step: 6
Training loss: 0.7841724157333374
Validation loss: 1.6792429583047026

Epoch: 6| Step: 7
Training loss: 0.6771104335784912
Validation loss: 1.6581140743788851

Epoch: 6| Step: 8
Training loss: 0.3573647439479828
Validation loss: 1.6517696944616174

Epoch: 6| Step: 9
Training loss: 0.619381308555603
Validation loss: 1.664560402593305

Epoch: 6| Step: 10
Training loss: 0.8433858752250671
Validation loss: 1.6682065520235287

Epoch: 6| Step: 11
Training loss: 0.5617771148681641
Validation loss: 1.6472185170778664

Epoch: 6| Step: 12
Training loss: 0.8094335794448853
Validation loss: 1.6623420574331795

Epoch: 6| Step: 13
Training loss: 0.33332934975624084
Validation loss: 1.6870097652558358

Epoch: 289| Step: 0
Training loss: 0.3877105712890625
Validation loss: 1.726939687164881

Epoch: 6| Step: 1
Training loss: 0.3973167836666107
Validation loss: 1.7141059008977746

Epoch: 6| Step: 2
Training loss: 0.6712660193443298
Validation loss: 1.7739933665080736

Epoch: 6| Step: 3
Training loss: 0.6153125762939453
Validation loss: 1.7848210668051114

Epoch: 6| Step: 4
Training loss: 0.6232366561889648
Validation loss: 1.795509284542453

Epoch: 6| Step: 5
Training loss: 0.9174085855484009
Validation loss: 1.768952182544175

Epoch: 6| Step: 6
Training loss: 0.36409443616867065
Validation loss: 1.7807467111977198

Epoch: 6| Step: 7
Training loss: 0.6250355243682861
Validation loss: 1.731796618430845

Epoch: 6| Step: 8
Training loss: 0.4110872447490692
Validation loss: 1.7446572844700148

Epoch: 6| Step: 9
Training loss: 0.6388789415359497
Validation loss: 1.718245348622722

Epoch: 6| Step: 10
Training loss: 0.3401302695274353
Validation loss: 1.7188485027641378

Epoch: 6| Step: 11
Training loss: 0.3911258578300476
Validation loss: 1.72053514757464

Epoch: 6| Step: 12
Training loss: 0.41144275665283203
Validation loss: 1.7356577355374572

Epoch: 6| Step: 13
Training loss: 0.27840569615364075
Validation loss: 1.7454016503467356

Epoch: 290| Step: 0
Training loss: 0.7989065051078796
Validation loss: 1.7657277571257723

Epoch: 6| Step: 1
Training loss: 0.7756455540657043
Validation loss: 1.7446322671828731

Epoch: 6| Step: 2
Training loss: 0.4874844551086426
Validation loss: 1.7400426480077928

Epoch: 6| Step: 3
Training loss: 0.5658310651779175
Validation loss: 1.7288830088030906

Epoch: 6| Step: 4
Training loss: 0.2831021547317505
Validation loss: 1.7235726797452537

Epoch: 6| Step: 5
Training loss: 0.6173051595687866
Validation loss: 1.6786600133424163

Epoch: 6| Step: 6
Training loss: 0.31043770909309387
Validation loss: 1.7105706366159583

Epoch: 6| Step: 7
Training loss: 0.5992773771286011
Validation loss: 1.6811869875077279

Epoch: 6| Step: 8
Training loss: 0.3842896819114685
Validation loss: 1.6729681402124383

Epoch: 6| Step: 9
Training loss: 0.4422447085380554
Validation loss: 1.6495056703526487

Epoch: 6| Step: 10
Training loss: 0.27287039160728455
Validation loss: 1.6536909354630338

Epoch: 6| Step: 11
Training loss: 0.635100245475769
Validation loss: 1.6446022500274002

Epoch: 6| Step: 12
Training loss: 0.5003001689910889
Validation loss: 1.643350576841703

Epoch: 6| Step: 13
Training loss: 0.8834396600723267
Validation loss: 1.6591274648584344

Epoch: 291| Step: 0
Training loss: 0.3432789146900177
Validation loss: 1.6676226777415122

Epoch: 6| Step: 1
Training loss: 0.8045770525932312
Validation loss: 1.6752269229581278

Epoch: 6| Step: 2
Training loss: 0.2931739091873169
Validation loss: 1.743459455428585

Epoch: 6| Step: 3
Training loss: 0.5347872972488403
Validation loss: 1.750782770495261

Epoch: 6| Step: 4
Training loss: 0.5717737674713135
Validation loss: 1.7526494264602661

Epoch: 6| Step: 5
Training loss: 0.5701655149459839
Validation loss: 1.7366413031854937

Epoch: 6| Step: 6
Training loss: 0.7172942161560059
Validation loss: 1.7045275831735263

Epoch: 6| Step: 7
Training loss: 0.44940757751464844
Validation loss: 1.6893583138783772

Epoch: 6| Step: 8
Training loss: 0.6632190942764282
Validation loss: 1.6659873070255402

Epoch: 6| Step: 9
Training loss: 0.39046964049339294
Validation loss: 1.6621700358647171

Epoch: 6| Step: 10
Training loss: 0.5396623611450195
Validation loss: 1.674113667139443

Epoch: 6| Step: 11
Training loss: 0.999752938747406
Validation loss: 1.647914344264615

Epoch: 6| Step: 12
Training loss: 0.34866979718208313
Validation loss: 1.689496301835583

Epoch: 6| Step: 13
Training loss: 0.2885783314704895
Validation loss: 1.686712985397667

Epoch: 292| Step: 0
Training loss: 0.6311506032943726
Validation loss: 1.7332834210447086

Epoch: 6| Step: 1
Training loss: 0.6552844047546387
Validation loss: 1.7725190244695193

Epoch: 6| Step: 2
Training loss: 0.34009653329849243
Validation loss: 1.749534514642531

Epoch: 6| Step: 3
Training loss: 0.6127167344093323
Validation loss: 1.7351404236209007

Epoch: 6| Step: 4
Training loss: 0.45423373579978943
Validation loss: 1.7372023713204168

Epoch: 6| Step: 5
Training loss: 0.6803070306777954
Validation loss: 1.7264914230633808

Epoch: 6| Step: 6
Training loss: 0.6650363206863403
Validation loss: 1.7172982423536238

Epoch: 6| Step: 7
Training loss: 0.20909623801708221
Validation loss: 1.6652160575312953

Epoch: 6| Step: 8
Training loss: 0.4314259886741638
Validation loss: 1.6687992952203239

Epoch: 6| Step: 9
Training loss: 0.5385845303535461
Validation loss: 1.6789134728011263

Epoch: 6| Step: 10
Training loss: 0.31557023525238037
Validation loss: 1.6896389120368547

Epoch: 6| Step: 11
Training loss: 0.2868081033229828
Validation loss: 1.679888016434126

Epoch: 6| Step: 12
Training loss: 0.5207030773162842
Validation loss: 1.6994222979391775

Epoch: 6| Step: 13
Training loss: 0.6532474756240845
Validation loss: 1.7035070978185183

Epoch: 293| Step: 0
Training loss: 0.932935893535614
Validation loss: 1.7284566830563288

Epoch: 6| Step: 1
Training loss: 0.4039638042449951
Validation loss: 1.7067918828738633

Epoch: 6| Step: 2
Training loss: 0.44115203619003296
Validation loss: 1.702072674228299

Epoch: 6| Step: 3
Training loss: 0.27940720319747925
Validation loss: 1.7122288544972737

Epoch: 6| Step: 4
Training loss: 0.6136870384216309
Validation loss: 1.7206760401366858

Epoch: 6| Step: 5
Training loss: 0.29866477847099304
Validation loss: 1.734819286613054

Epoch: 6| Step: 6
Training loss: 0.5204614400863647
Validation loss: 1.70011935182797

Epoch: 6| Step: 7
Training loss: 0.5051669478416443
Validation loss: 1.7088942771316857

Epoch: 6| Step: 8
Training loss: 0.39835792779922485
Validation loss: 1.6900497187850296

Epoch: 6| Step: 9
Training loss: 0.16437439620494843
Validation loss: 1.6888427760011406

Epoch: 6| Step: 10
Training loss: 0.342343807220459
Validation loss: 1.6826773016683516

Epoch: 6| Step: 11
Training loss: 0.4597379267215729
Validation loss: 1.6665037665315854

Epoch: 6| Step: 12
Training loss: 0.6153398752212524
Validation loss: 1.6547527056868359

Epoch: 6| Step: 13
Training loss: 0.720400333404541
Validation loss: 1.657081313030694

Epoch: 294| Step: 0
Training loss: 0.3802909553050995
Validation loss: 1.6610655271878807

Epoch: 6| Step: 1
Training loss: 0.6359193325042725
Validation loss: 1.6604233454632502

Epoch: 6| Step: 2
Training loss: 0.25952771306037903
Validation loss: 1.6898070176442463

Epoch: 6| Step: 3
Training loss: 0.5825076103210449
Validation loss: 1.6887959434140114

Epoch: 6| Step: 4
Training loss: 0.38660240173339844
Validation loss: 1.7188541889190674

Epoch: 6| Step: 5
Training loss: 0.5893978476524353
Validation loss: 1.713957962169442

Epoch: 6| Step: 6
Training loss: 0.5497611165046692
Validation loss: 1.679345553921115

Epoch: 6| Step: 7
Training loss: 0.2656219005584717
Validation loss: 1.6599670469119985

Epoch: 6| Step: 8
Training loss: 0.4459136128425598
Validation loss: 1.6563934215935328

Epoch: 6| Step: 9
Training loss: 0.640142560005188
Validation loss: 1.6467530118521823

Epoch: 6| Step: 10
Training loss: 0.47445201873779297
Validation loss: 1.6379664687700168

Epoch: 6| Step: 11
Training loss: 0.502181887626648
Validation loss: 1.6648588629179104

Epoch: 6| Step: 12
Training loss: 0.3181586265563965
Validation loss: 1.6646565186080111

Epoch: 6| Step: 13
Training loss: 0.7089662551879883
Validation loss: 1.6760548135285736

Epoch: 295| Step: 0
Training loss: 0.4101666808128357
Validation loss: 1.6682106320576002

Epoch: 6| Step: 1
Training loss: 0.36718618869781494
Validation loss: 1.7069411675135295

Epoch: 6| Step: 2
Training loss: 0.5606341361999512
Validation loss: 1.70361586283612

Epoch: 6| Step: 3
Training loss: 0.6346271634101868
Validation loss: 1.689006196555271

Epoch: 6| Step: 4
Training loss: 0.5557024478912354
Validation loss: 1.6915187374238045

Epoch: 6| Step: 5
Training loss: 1.0527455806732178
Validation loss: 1.6960828227381552

Epoch: 6| Step: 6
Training loss: 0.379169225692749
Validation loss: 1.7817138010455715

Epoch: 6| Step: 7
Training loss: 0.4350941777229309
Validation loss: 1.7854108964243243

Epoch: 6| Step: 8
Training loss: 0.5733112692832947
Validation loss: 1.74860776880736

Epoch: 6| Step: 9
Training loss: 0.43680450320243835
Validation loss: 1.738513469696045

Epoch: 6| Step: 10
Training loss: 0.2283231019973755
Validation loss: 1.6826197947225263

Epoch: 6| Step: 11
Training loss: 0.4391063451766968
Validation loss: 1.673938169274279

Epoch: 6| Step: 12
Training loss: 0.3053781986236572
Validation loss: 1.6615845887891707

Epoch: 6| Step: 13
Training loss: 0.4169200360774994
Validation loss: 1.6288095635752524

Epoch: 296| Step: 0
Training loss: 0.7069274187088013
Validation loss: 1.5857393369879773

Epoch: 6| Step: 1
Training loss: 0.47239628434181213
Validation loss: 1.5945530732472737

Epoch: 6| Step: 2
Training loss: 0.600373387336731
Validation loss: 1.595342743781305

Epoch: 6| Step: 3
Training loss: 0.3408390283584595
Validation loss: 1.6392303154032717

Epoch: 6| Step: 4
Training loss: 0.38466930389404297
Validation loss: 1.64681629596218

Epoch: 6| Step: 5
Training loss: 0.6855714321136475
Validation loss: 1.6738638172867477

Epoch: 6| Step: 6
Training loss: 1.041450023651123
Validation loss: 1.6936786687502297

Epoch: 6| Step: 7
Training loss: 0.4350423216819763
Validation loss: 1.6991256347266577

Epoch: 6| Step: 8
Training loss: 0.41132646799087524
Validation loss: 1.7316190619622507

Epoch: 6| Step: 9
Training loss: 0.6347980499267578
Validation loss: 1.728222447056924

Epoch: 6| Step: 10
Training loss: 0.4908483326435089
Validation loss: 1.7098967080475183

Epoch: 6| Step: 11
Training loss: 0.23220255970954895
Validation loss: 1.7219505784332112

Epoch: 6| Step: 12
Training loss: 0.44114330410957336
Validation loss: 1.6678229788298249

Epoch: 6| Step: 13
Training loss: 0.5870742797851562
Validation loss: 1.6704224014794955

Epoch: 297| Step: 0
Training loss: 0.8086606860160828
Validation loss: 1.659202492365273

Epoch: 6| Step: 1
Training loss: 0.5334379076957703
Validation loss: 1.6516377784872567

Epoch: 6| Step: 2
Training loss: 0.28707122802734375
Validation loss: 1.6532681398494269

Epoch: 6| Step: 3
Training loss: 0.6054539084434509
Validation loss: 1.6543922142315937

Epoch: 6| Step: 4
Training loss: 0.5658074617385864
Validation loss: 1.696501878000075

Epoch: 6| Step: 5
Training loss: 0.9021835327148438
Validation loss: 1.7131195017086562

Epoch: 6| Step: 6
Training loss: 0.40028491616249084
Validation loss: 1.7061668570323656

Epoch: 6| Step: 7
Training loss: 0.3463178277015686
Validation loss: 1.7097124668859667

Epoch: 6| Step: 8
Training loss: 0.76624995470047
Validation loss: 1.7148797037780925

Epoch: 6| Step: 9
Training loss: 0.4428056478500366
Validation loss: 1.6782482439471829

Epoch: 6| Step: 10
Training loss: 0.539700984954834
Validation loss: 1.6712795329350296

Epoch: 6| Step: 11
Training loss: 0.47099775075912476
Validation loss: 1.6685806999924362

Epoch: 6| Step: 12
Training loss: 0.22245477139949799
Validation loss: 1.6833819855925858

Epoch: 6| Step: 13
Training loss: 0.4040534198284149
Validation loss: 1.6617401620393157

Epoch: 298| Step: 0
Training loss: 0.39327099919319153
Validation loss: 1.697033771904566

Epoch: 6| Step: 1
Training loss: 0.47244906425476074
Validation loss: 1.6925715041416947

Epoch: 6| Step: 2
Training loss: 0.42169636487960815
Validation loss: 1.6806915370366906

Epoch: 6| Step: 3
Training loss: 0.32313698530197144
Validation loss: 1.7101725903890466

Epoch: 6| Step: 4
Training loss: 0.5378595590591431
Validation loss: 1.7065702279408772

Epoch: 6| Step: 5
Training loss: 0.5146598815917969
Validation loss: 1.719109324998753

Epoch: 6| Step: 6
Training loss: 0.2308661788702011
Validation loss: 1.7438950025907127

Epoch: 6| Step: 7
Training loss: 0.5542465448379517
Validation loss: 1.746081772670951

Epoch: 6| Step: 8
Training loss: 0.5146613121032715
Validation loss: 1.7564131188136276

Epoch: 6| Step: 9
Training loss: 0.5465072393417358
Validation loss: 1.766301884446093

Epoch: 6| Step: 10
Training loss: 0.5906462073326111
Validation loss: 1.7380046331754295

Epoch: 6| Step: 11
Training loss: 0.3876643776893616
Validation loss: 1.7346544291383477

Epoch: 6| Step: 12
Training loss: 0.46234747767448425
Validation loss: 1.7233006236373738

Epoch: 6| Step: 13
Training loss: 0.2406233698129654
Validation loss: 1.734124546409935

Epoch: 299| Step: 0
Training loss: 0.6243187189102173
Validation loss: 1.726130970062748

Epoch: 6| Step: 1
Training loss: 0.5177664160728455
Validation loss: 1.7334836477874427

Epoch: 6| Step: 2
Training loss: 0.44415539503097534
Validation loss: 1.7436236335385231

Epoch: 6| Step: 3
Training loss: 0.5893509984016418
Validation loss: 1.7118088936292997

Epoch: 6| Step: 4
Training loss: 0.6958848237991333
Validation loss: 1.698127572254468

Epoch: 6| Step: 5
Training loss: 0.42113375663757324
Validation loss: 1.6666917300993396

Epoch: 6| Step: 6
Training loss: 0.44795697927474976
Validation loss: 1.6714212407347977

Epoch: 6| Step: 7
Training loss: 0.5293919444084167
Validation loss: 1.674246459878901

Epoch: 6| Step: 8
Training loss: 0.3820648789405823
Validation loss: 1.6887061627962257

Epoch: 6| Step: 9
Training loss: 0.5800076723098755
Validation loss: 1.7135684797840733

Epoch: 6| Step: 10
Training loss: 0.35929855704307556
Validation loss: 1.7636431840158278

Epoch: 6| Step: 11
Training loss: 0.41229379177093506
Validation loss: 1.7532679034817604

Epoch: 6| Step: 12
Training loss: 0.39341652393341064
Validation loss: 1.7317655650518273

Epoch: 6| Step: 13
Training loss: 0.23113547265529633
Validation loss: 1.7009022787053099

Epoch: 300| Step: 0
Training loss: 0.4750162959098816
Validation loss: 1.6734256282929452

Epoch: 6| Step: 1
Training loss: 0.5059016942977905
Validation loss: 1.6558528625836937

Epoch: 6| Step: 2
Training loss: 0.34201234579086304
Validation loss: 1.6657106914827902

Epoch: 6| Step: 3
Training loss: 0.5543729662895203
Validation loss: 1.628171875912656

Epoch: 6| Step: 4
Training loss: 0.4136533737182617
Validation loss: 1.6400792508996942

Epoch: 6| Step: 5
Training loss: 0.4059930145740509
Validation loss: 1.6339651025751585

Epoch: 6| Step: 6
Training loss: 0.272172749042511
Validation loss: 1.6072029785443378

Epoch: 6| Step: 7
Training loss: 0.820212721824646
Validation loss: 1.6349839984729726

Epoch: 6| Step: 8
Training loss: 0.26440227031707764
Validation loss: 1.6304309124587684

Epoch: 6| Step: 9
Training loss: 0.33692848682403564
Validation loss: 1.634325858085386

Epoch: 6| Step: 10
Training loss: 0.2797737419605255
Validation loss: 1.6876794086989535

Epoch: 6| Step: 11
Training loss: 0.4163542687892914
Validation loss: 1.6470274739367987

Epoch: 6| Step: 12
Training loss: 0.4443706274032593
Validation loss: 1.64402186998757

Epoch: 6| Step: 13
Training loss: 0.2978519797325134
Validation loss: 1.6266947023330196

Epoch: 301| Step: 0
Training loss: 0.43355655670166016
Validation loss: 1.6523714129642775

Epoch: 6| Step: 1
Training loss: 0.3234798312187195
Validation loss: 1.6573360863552298

Epoch: 6| Step: 2
Training loss: 0.23165839910507202
Validation loss: 1.6800706668566632

Epoch: 6| Step: 3
Training loss: 0.32986754179000854
Validation loss: 1.6912894530962872

Epoch: 6| Step: 4
Training loss: 0.41346028447151184
Validation loss: 1.712476953383415

Epoch: 6| Step: 5
Training loss: 0.3283337652683258
Validation loss: 1.709552889229149

Epoch: 6| Step: 6
Training loss: 0.4430133104324341
Validation loss: 1.7250303811924432

Epoch: 6| Step: 7
Training loss: 0.44860273599624634
Validation loss: 1.6909295820420789

Epoch: 6| Step: 8
Training loss: 0.5108910202980042
Validation loss: 1.6867877129585511

Epoch: 6| Step: 9
Training loss: 0.4982531666755676
Validation loss: 1.6940429300390265

Epoch: 6| Step: 10
Training loss: 0.5040303468704224
Validation loss: 1.6487676482046805

Epoch: 6| Step: 11
Training loss: 0.44098129868507385
Validation loss: 1.6630775505496609

Epoch: 6| Step: 12
Training loss: 0.3205517530441284
Validation loss: 1.6506676212433846

Epoch: 6| Step: 13
Training loss: 0.5433964133262634
Validation loss: 1.6443833510080974

Epoch: 302| Step: 0
Training loss: 0.6729415059089661
Validation loss: 1.5935135131241174

Epoch: 6| Step: 1
Training loss: 0.3641645908355713
Validation loss: 1.5908048518242375

Epoch: 6| Step: 2
Training loss: 0.6072290539741516
Validation loss: 1.5805377370567733

Epoch: 6| Step: 3
Training loss: 0.2969113886356354
Validation loss: 1.5934437654351676

Epoch: 6| Step: 4
Training loss: 0.50974440574646
Validation loss: 1.5813414614687684

Epoch: 6| Step: 5
Training loss: 0.48243042826652527
Validation loss: 1.5755585291052376

Epoch: 6| Step: 6
Training loss: 0.2027476578950882
Validation loss: 1.6042013898972542

Epoch: 6| Step: 7
Training loss: 0.2549462914466858
Validation loss: 1.6143042669501355

Epoch: 6| Step: 8
Training loss: 0.6545999050140381
Validation loss: 1.6174206451703144

Epoch: 6| Step: 9
Training loss: 0.5230898261070251
Validation loss: 1.6165993405926613

Epoch: 6| Step: 10
Training loss: 0.3758291006088257
Validation loss: 1.63978313502445

Epoch: 6| Step: 11
Training loss: 0.37239739298820496
Validation loss: 1.6123621515048447

Epoch: 6| Step: 12
Training loss: 0.3045796751976013
Validation loss: 1.6236118578141736

Epoch: 6| Step: 13
Training loss: 0.37496721744537354
Validation loss: 1.6213533057961413

Epoch: 303| Step: 0
Training loss: 0.3531475067138672
Validation loss: 1.5972093753917243

Epoch: 6| Step: 1
Training loss: 0.44854551553726196
Validation loss: 1.6381259092720606

Epoch: 6| Step: 2
Training loss: 0.3091791868209839
Validation loss: 1.6629385320089196

Epoch: 6| Step: 3
Training loss: 0.40488195419311523
Validation loss: 1.6653106366434405

Epoch: 6| Step: 4
Training loss: 0.26173704862594604
Validation loss: 1.6583576202392578

Epoch: 6| Step: 5
Training loss: 0.3566731810569763
Validation loss: 1.6820878264724568

Epoch: 6| Step: 6
Training loss: 0.4738715887069702
Validation loss: 1.68523443770665

Epoch: 6| Step: 7
Training loss: 0.7231779098510742
Validation loss: 1.6839333734204691

Epoch: 6| Step: 8
Training loss: 0.5368677377700806
Validation loss: 1.6825105733768915

Epoch: 6| Step: 9
Training loss: 0.18945130705833435
Validation loss: 1.6527094033456617

Epoch: 6| Step: 10
Training loss: 0.35404449701309204
Validation loss: 1.6610450693356094

Epoch: 6| Step: 11
Training loss: 0.2807637155056
Validation loss: 1.6737479625209686

Epoch: 6| Step: 12
Training loss: 0.42793959379196167
Validation loss: 1.6670418734191566

Epoch: 6| Step: 13
Training loss: 0.4485344886779785
Validation loss: 1.6506076756344046

Epoch: 304| Step: 0
Training loss: 0.48578450083732605
Validation loss: 1.6474427689788163

Epoch: 6| Step: 1
Training loss: 0.3102005124092102
Validation loss: 1.645133408167029

Epoch: 6| Step: 2
Training loss: 0.26366162300109863
Validation loss: 1.6569359892158098

Epoch: 6| Step: 3
Training loss: 0.24723567068576813
Validation loss: 1.6548957593979374

Epoch: 6| Step: 4
Training loss: 0.42837679386138916
Validation loss: 1.6561016549346268

Epoch: 6| Step: 5
Training loss: 0.33161014318466187
Validation loss: 1.6542150576909382

Epoch: 6| Step: 6
Training loss: 0.21223759651184082
Validation loss: 1.6434179249630179

Epoch: 6| Step: 7
Training loss: 0.40219825506210327
Validation loss: 1.6686734973743398

Epoch: 6| Step: 8
Training loss: 0.4921538829803467
Validation loss: 1.6498731746468493

Epoch: 6| Step: 9
Training loss: 0.38019412755966187
Validation loss: 1.678077801581352

Epoch: 6| Step: 10
Training loss: 0.407292902469635
Validation loss: 1.6729235277380994

Epoch: 6| Step: 11
Training loss: 0.4921645522117615
Validation loss: 1.6698262742770615

Epoch: 6| Step: 12
Training loss: 0.5977954864501953
Validation loss: 1.6863794275509414

Epoch: 6| Step: 13
Training loss: 0.39053255319595337
Validation loss: 1.6989477033256202

Epoch: 305| Step: 0
Training loss: 0.243294820189476
Validation loss: 1.6846215186580535

Epoch: 6| Step: 1
Training loss: 0.5141202807426453
Validation loss: 1.6890734216218353

Epoch: 6| Step: 2
Training loss: 0.616523027420044
Validation loss: 1.6625342151170135

Epoch: 6| Step: 3
Training loss: 0.19850309193134308
Validation loss: 1.6372334931486396

Epoch: 6| Step: 4
Training loss: 0.4875568449497223
Validation loss: 1.6333276866584696

Epoch: 6| Step: 5
Training loss: 0.2763637900352478
Validation loss: 1.607178282994096

Epoch: 6| Step: 6
Training loss: 0.5289465188980103
Validation loss: 1.6394321457032235

Epoch: 6| Step: 7
Training loss: 0.5310940146446228
Validation loss: 1.6405042755988337

Epoch: 6| Step: 8
Training loss: 0.44339972734451294
Validation loss: 1.6234915948683215

Epoch: 6| Step: 9
Training loss: 0.2651607394218445
Validation loss: 1.642091517807335

Epoch: 6| Step: 10
Training loss: 0.3921163082122803
Validation loss: 1.618093834128431

Epoch: 6| Step: 11
Training loss: 0.48673713207244873
Validation loss: 1.623216317545983

Epoch: 6| Step: 12
Training loss: 0.3435521721839905
Validation loss: 1.6136500207326745

Epoch: 6| Step: 13
Training loss: 0.40656042098999023
Validation loss: 1.608216231869113

Epoch: 306| Step: 0
Training loss: 0.4059281349182129
Validation loss: 1.6470195144735358

Epoch: 6| Step: 1
Training loss: 0.512910008430481
Validation loss: 1.668553510019856

Epoch: 6| Step: 2
Training loss: 0.4346069097518921
Validation loss: 1.6987370175700034

Epoch: 6| Step: 3
Training loss: 0.486555814743042
Validation loss: 1.7055908595362017

Epoch: 6| Step: 4
Training loss: 0.42829686403274536
Validation loss: 1.7352158664375223

Epoch: 6| Step: 5
Training loss: 0.5756184458732605
Validation loss: 1.7626496361147972

Epoch: 6| Step: 6
Training loss: 0.6866886615753174
Validation loss: 1.7189403003261936

Epoch: 6| Step: 7
Training loss: 0.25608229637145996
Validation loss: 1.6883121895533737

Epoch: 6| Step: 8
Training loss: 0.36320698261260986
Validation loss: 1.6714029427497619

Epoch: 6| Step: 9
Training loss: 0.3192867934703827
Validation loss: 1.632055506911329

Epoch: 6| Step: 10
Training loss: 0.23064270615577698
Validation loss: 1.588194098523868

Epoch: 6| Step: 11
Training loss: 0.2769455313682556
Validation loss: 1.6014409757429553

Epoch: 6| Step: 12
Training loss: 0.44491660594940186
Validation loss: 1.5778325462854037

Epoch: 6| Step: 13
Training loss: 0.10604774206876755
Validation loss: 1.5800492891701319

Epoch: 307| Step: 0
Training loss: 0.3370300531387329
Validation loss: 1.5993960365172355

Epoch: 6| Step: 1
Training loss: 0.3071218729019165
Validation loss: 1.6338706862541936

Epoch: 6| Step: 2
Training loss: 0.43206390738487244
Validation loss: 1.6426050380993915

Epoch: 6| Step: 3
Training loss: 0.3972867727279663
Validation loss: 1.6158235534544914

Epoch: 6| Step: 4
Training loss: 0.47775477170944214
Validation loss: 1.61564596878585

Epoch: 6| Step: 5
Training loss: 0.26646316051483154
Validation loss: 1.6199869699375604

Epoch: 6| Step: 6
Training loss: 0.374592125415802
Validation loss: 1.6178537171374086

Epoch: 6| Step: 7
Training loss: 0.3537187874317169
Validation loss: 1.611763310688798

Epoch: 6| Step: 8
Training loss: 0.2477959543466568
Validation loss: 1.6278817845929054

Epoch: 6| Step: 9
Training loss: 0.6169193387031555
Validation loss: 1.6424199714455554

Epoch: 6| Step: 10
Training loss: 0.39456605911254883
Validation loss: 1.643212314574949

Epoch: 6| Step: 11
Training loss: 0.5025942325592041
Validation loss: 1.6827901281336302

Epoch: 6| Step: 12
Training loss: 0.357804536819458
Validation loss: 1.6998923286314933

Epoch: 6| Step: 13
Training loss: 0.40079671144485474
Validation loss: 1.7697969290517992

Epoch: 308| Step: 0
Training loss: 0.9376106858253479
Validation loss: 1.839675618756202

Epoch: 6| Step: 1
Training loss: 0.7107186317443848
Validation loss: 1.8252750032691545

Epoch: 6| Step: 2
Training loss: 0.2731797695159912
Validation loss: 1.7913723261125627

Epoch: 6| Step: 3
Training loss: 0.4396108388900757
Validation loss: 1.724856613784708

Epoch: 6| Step: 4
Training loss: 0.5490912199020386
Validation loss: 1.6503520075992872

Epoch: 6| Step: 5
Training loss: 0.2446560561656952
Validation loss: 1.6113268124159945

Epoch: 6| Step: 6
Training loss: 0.4886539578437805
Validation loss: 1.5999537885829966

Epoch: 6| Step: 7
Training loss: 0.4569617509841919
Validation loss: 1.5910006312913791

Epoch: 6| Step: 8
Training loss: 0.4099406599998474
Validation loss: 1.5969463907262331

Epoch: 6| Step: 9
Training loss: 0.47488275170326233
Validation loss: 1.5867750119137507

Epoch: 6| Step: 10
Training loss: 0.3987360894680023
Validation loss: 1.6023733974784933

Epoch: 6| Step: 11
Training loss: 0.21252267062664032
Validation loss: 1.634208494617093

Epoch: 6| Step: 12
Training loss: 0.1687578558921814
Validation loss: 1.6463851954347344

Epoch: 6| Step: 13
Training loss: 0.33822599053382874
Validation loss: 1.6746735906088224

Epoch: 309| Step: 0
Training loss: 0.35583969950675964
Validation loss: 1.6680410690205072

Epoch: 6| Step: 1
Training loss: 0.34334903955459595
Validation loss: 1.672942784524733

Epoch: 6| Step: 2
Training loss: 0.34913599491119385
Validation loss: 1.6695485345778927

Epoch: 6| Step: 3
Training loss: 0.4224870204925537
Validation loss: 1.6681709706142385

Epoch: 6| Step: 4
Training loss: 0.28799861669540405
Validation loss: 1.6070739152610942

Epoch: 6| Step: 5
Training loss: 0.3775053322315216
Validation loss: 1.6174748302787862

Epoch: 6| Step: 6
Training loss: 0.33228248357772827
Validation loss: 1.6208513065051007

Epoch: 6| Step: 7
Training loss: 0.2820274233818054
Validation loss: 1.6272209934009019

Epoch: 6| Step: 8
Training loss: 0.48682284355163574
Validation loss: 1.6195602058082499

Epoch: 6| Step: 9
Training loss: 0.331805557012558
Validation loss: 1.6166377734112483

Epoch: 6| Step: 10
Training loss: 0.30874401330947876
Validation loss: 1.6087374943558888

Epoch: 6| Step: 11
Training loss: 0.36965692043304443
Validation loss: 1.6302174855304021

Epoch: 6| Step: 12
Training loss: 0.368919312953949
Validation loss: 1.657144743909118

Epoch: 6| Step: 13
Training loss: 0.6636506915092468
Validation loss: 1.675723703958655

Epoch: 310| Step: 0
Training loss: 0.31302332878112793
Validation loss: 1.6909338210218696

Epoch: 6| Step: 1
Training loss: 0.3813260793685913
Validation loss: 1.695939379353677

Epoch: 6| Step: 2
Training loss: 0.4239141643047333
Validation loss: 1.6949138923357892

Epoch: 6| Step: 3
Training loss: 0.6670796275138855
Validation loss: 1.6950328247521513

Epoch: 6| Step: 4
Training loss: 0.34169328212738037
Validation loss: 1.6945391239658478

Epoch: 6| Step: 5
Training loss: 0.3418295085430145
Validation loss: 1.681342859422007

Epoch: 6| Step: 6
Training loss: 0.3969171643257141
Validation loss: 1.6560240150779806

Epoch: 6| Step: 7
Training loss: 0.3507041931152344
Validation loss: 1.6382117373968965

Epoch: 6| Step: 8
Training loss: 0.22655890882015228
Validation loss: 1.6128123011640323

Epoch: 6| Step: 9
Training loss: 0.29386237263679504
Validation loss: 1.6135071862128474

Epoch: 6| Step: 10
Training loss: 0.2774258255958557
Validation loss: 1.6202548268020793

Epoch: 6| Step: 11
Training loss: 0.13563703000545502
Validation loss: 1.6256798390419251

Epoch: 6| Step: 12
Training loss: 0.7579725980758667
Validation loss: 1.6430564644516155

Epoch: 6| Step: 13
Training loss: 0.4199182093143463
Validation loss: 1.6165609205922773

Epoch: 311| Step: 0
Training loss: 0.4371001422405243
Validation loss: 1.630457244893556

Epoch: 6| Step: 1
Training loss: 0.3782728910446167
Validation loss: 1.6629138582496232

Epoch: 6| Step: 2
Training loss: 0.4654708206653595
Validation loss: 1.6824958773069485

Epoch: 6| Step: 3
Training loss: 0.5145103335380554
Validation loss: 1.6924267097186017

Epoch: 6| Step: 4
Training loss: 0.5102916955947876
Validation loss: 1.6703555007134714

Epoch: 6| Step: 5
Training loss: 0.3885672092437744
Validation loss: 1.6871830032717796

Epoch: 6| Step: 6
Training loss: 0.28809645771980286
Validation loss: 1.6953145137397192

Epoch: 6| Step: 7
Training loss: 0.47439923882484436
Validation loss: 1.6917766870990876

Epoch: 6| Step: 8
Training loss: 0.24917326867580414
Validation loss: 1.6987909168325446

Epoch: 6| Step: 9
Training loss: 0.3784087002277374
Validation loss: 1.698403504586989

Epoch: 6| Step: 10
Training loss: 0.26171815395355225
Validation loss: 1.6775988737742107

Epoch: 6| Step: 11
Training loss: 0.44753485918045044
Validation loss: 1.6762366807588966

Epoch: 6| Step: 12
Training loss: 0.39082783460617065
Validation loss: 1.695540246143136

Epoch: 6| Step: 13
Training loss: 0.306216835975647
Validation loss: 1.7309633262695805

Epoch: 312| Step: 0
Training loss: 0.28674301505088806
Validation loss: 1.6972634971782725

Epoch: 6| Step: 1
Training loss: 0.18225958943367004
Validation loss: 1.7027472385796167

Epoch: 6| Step: 2
Training loss: 0.396117627620697
Validation loss: 1.7173079367606872

Epoch: 6| Step: 3
Training loss: 0.5226199626922607
Validation loss: 1.7137944429151473

Epoch: 6| Step: 4
Training loss: 0.4564720392227173
Validation loss: 1.6891510409693564

Epoch: 6| Step: 5
Training loss: 0.31212538480758667
Validation loss: 1.7074545737235778

Epoch: 6| Step: 6
Training loss: 0.2301505208015442
Validation loss: 1.715509101908694

Epoch: 6| Step: 7
Training loss: 0.2561766803264618
Validation loss: 1.6946730177889588

Epoch: 6| Step: 8
Training loss: 0.4976450800895691
Validation loss: 1.715097414549961

Epoch: 6| Step: 9
Training loss: 0.5085062384605408
Validation loss: 1.6734501443883425

Epoch: 6| Step: 10
Training loss: 0.7133429050445557
Validation loss: 1.645741529362176

Epoch: 6| Step: 11
Training loss: 0.36678507924079895
Validation loss: 1.6417483539991482

Epoch: 6| Step: 12
Training loss: 0.2524961233139038
Validation loss: 1.650356545243212

Epoch: 6| Step: 13
Training loss: 0.2557161748409271
Validation loss: 1.6274837127295874

Epoch: 313| Step: 0
Training loss: 0.5967352390289307
Validation loss: 1.623379962418669

Epoch: 6| Step: 1
Training loss: 0.27912193536758423
Validation loss: 1.6006656308327951

Epoch: 6| Step: 2
Training loss: 0.2955765128135681
Validation loss: 1.5803973021045807

Epoch: 6| Step: 3
Training loss: 0.21775053441524506
Validation loss: 1.5668865070548108

Epoch: 6| Step: 4
Training loss: 0.5904955863952637
Validation loss: 1.5864206526869087

Epoch: 6| Step: 5
Training loss: 0.5201674699783325
Validation loss: 1.601329727839398

Epoch: 6| Step: 6
Training loss: 0.48305368423461914
Validation loss: 1.6000321706136067

Epoch: 6| Step: 7
Training loss: 0.561629593372345
Validation loss: 1.6029963672802012

Epoch: 6| Step: 8
Training loss: 0.4537826180458069
Validation loss: 1.609817551028344

Epoch: 6| Step: 9
Training loss: 0.319643497467041
Validation loss: 1.633267359067035

Epoch: 6| Step: 10
Training loss: 0.13578549027442932
Validation loss: 1.6876365882094189

Epoch: 6| Step: 11
Training loss: 0.3754678964614868
Validation loss: 1.7316113838585474

Epoch: 6| Step: 12
Training loss: 0.3183381259441376
Validation loss: 1.7212630574421217

Epoch: 6| Step: 13
Training loss: 0.49772441387176514
Validation loss: 1.7220501579264158

Epoch: 314| Step: 0
Training loss: 0.45439833402633667
Validation loss: 1.7004262862666961

Epoch: 6| Step: 1
Training loss: 0.5517628192901611
Validation loss: 1.6350903511047363

Epoch: 6| Step: 2
Training loss: 0.2740623354911804
Validation loss: 1.6278506889138171

Epoch: 6| Step: 3
Training loss: 0.4396427273750305
Validation loss: 1.5907811759620585

Epoch: 6| Step: 4
Training loss: 0.3908979892730713
Validation loss: 1.600224838461927

Epoch: 6| Step: 5
Training loss: 0.3825906217098236
Validation loss: 1.5730763058508597

Epoch: 6| Step: 6
Training loss: 0.45499977469444275
Validation loss: 1.5724833562809934

Epoch: 6| Step: 7
Training loss: 0.2208830714225769
Validation loss: 1.5830661186607935

Epoch: 6| Step: 8
Training loss: 0.33726081252098083
Validation loss: 1.6003364811661422

Epoch: 6| Step: 9
Training loss: 0.22063304483890533
Validation loss: 1.6133817998311852

Epoch: 6| Step: 10
Training loss: 0.3048686385154724
Validation loss: 1.6855992168508551

Epoch: 6| Step: 11
Training loss: 0.3502282500267029
Validation loss: 1.6946109635855562

Epoch: 6| Step: 12
Training loss: 0.4041817784309387
Validation loss: 1.6917752835058397

Epoch: 6| Step: 13
Training loss: 0.41029152274131775
Validation loss: 1.6908573027580016

Epoch: 315| Step: 0
Training loss: 0.5148162841796875
Validation loss: 1.6924435182284283

Epoch: 6| Step: 1
Training loss: 0.32346874475479126
Validation loss: 1.6861965438371063

Epoch: 6| Step: 2
Training loss: 0.2538011372089386
Validation loss: 1.6392450909460745

Epoch: 6| Step: 3
Training loss: 0.35496896505355835
Validation loss: 1.6366306325440765

Epoch: 6| Step: 4
Training loss: 0.37886229157447815
Validation loss: 1.6125806403416458

Epoch: 6| Step: 5
Training loss: 0.360212117433548
Validation loss: 1.5799394640871274

Epoch: 6| Step: 6
Training loss: 0.4130701720714569
Validation loss: 1.5745887282074138

Epoch: 6| Step: 7
Training loss: 0.5383732318878174
Validation loss: 1.5910436235448366

Epoch: 6| Step: 8
Training loss: 0.3968814015388489
Validation loss: 1.625592944442585

Epoch: 6| Step: 9
Training loss: 0.4599226415157318
Validation loss: 1.6288962364196777

Epoch: 6| Step: 10
Training loss: 0.582369327545166
Validation loss: 1.6572284660031718

Epoch: 6| Step: 11
Training loss: 0.36991843581199646
Validation loss: 1.630387358768012

Epoch: 6| Step: 12
Training loss: 0.4065750539302826
Validation loss: 1.6106789368455128

Epoch: 6| Step: 13
Training loss: 0.23795479536056519
Validation loss: 1.635828241866122

Epoch: 316| Step: 0
Training loss: 0.39696744084358215
Validation loss: 1.6815783733962684

Epoch: 6| Step: 1
Training loss: 0.7139798998832703
Validation loss: 1.7290404253108527

Epoch: 6| Step: 2
Training loss: 0.498812735080719
Validation loss: 1.7717633119193457

Epoch: 6| Step: 3
Training loss: 0.5732611417770386
Validation loss: 1.737271212762402

Epoch: 6| Step: 4
Training loss: 0.29588061571121216
Validation loss: 1.6900616512503674

Epoch: 6| Step: 5
Training loss: 0.36088281869888306
Validation loss: 1.6449579654201385

Epoch: 6| Step: 6
Training loss: 0.3412942886352539
Validation loss: 1.6513739170566681

Epoch: 6| Step: 7
Training loss: 0.3416328430175781
Validation loss: 1.646869409468866

Epoch: 6| Step: 8
Training loss: 0.3332774043083191
Validation loss: 1.673243494443996

Epoch: 6| Step: 9
Training loss: 0.5806770920753479
Validation loss: 1.6728122516344952

Epoch: 6| Step: 10
Training loss: 0.4615391492843628
Validation loss: 1.6524294858337731

Epoch: 6| Step: 11
Training loss: 0.4319762587547302
Validation loss: 1.660776215214883

Epoch: 6| Step: 12
Training loss: 0.27751466631889343
Validation loss: 1.6640492344415316

Epoch: 6| Step: 13
Training loss: 0.12052162736654282
Validation loss: 1.6798349580457133

Epoch: 317| Step: 0
Training loss: 0.5197209715843201
Validation loss: 1.6666273775921072

Epoch: 6| Step: 1
Training loss: 0.3579607903957367
Validation loss: 1.6852505078879736

Epoch: 6| Step: 2
Training loss: 0.15734967589378357
Validation loss: 1.6765596225697508

Epoch: 6| Step: 3
Training loss: 0.21399061381816864
Validation loss: 1.6755636815101869

Epoch: 6| Step: 4
Training loss: 0.4239931106567383
Validation loss: 1.6811259587605794

Epoch: 6| Step: 5
Training loss: 0.25549808144569397
Validation loss: 1.6710802085937992

Epoch: 6| Step: 6
Training loss: 0.33477097749710083
Validation loss: 1.6801046197132399

Epoch: 6| Step: 7
Training loss: 0.517602801322937
Validation loss: 1.6749892747530373

Epoch: 6| Step: 8
Training loss: 0.483600914478302
Validation loss: 1.6536562583779777

Epoch: 6| Step: 9
Training loss: 0.28117814660072327
Validation loss: 1.62925898708323

Epoch: 6| Step: 10
Training loss: 0.18846085667610168
Validation loss: 1.6370990609609952

Epoch: 6| Step: 11
Training loss: 0.37672609090805054
Validation loss: 1.6208273928652528

Epoch: 6| Step: 12
Training loss: 0.27249979972839355
Validation loss: 1.5907815476899505

Epoch: 6| Step: 13
Training loss: 0.47980615496635437
Validation loss: 1.5965058931740381

Epoch: 318| Step: 0
Training loss: 0.20462241768836975
Validation loss: 1.6369259139542938

Epoch: 6| Step: 1
Training loss: 0.26633644104003906
Validation loss: 1.6240226889169345

Epoch: 6| Step: 2
Training loss: 0.24184061586856842
Validation loss: 1.6310613668093117

Epoch: 6| Step: 3
Training loss: 0.4987398684024811
Validation loss: 1.5989417388874998

Epoch: 6| Step: 4
Training loss: 0.24919813871383667
Validation loss: 1.60658654474443

Epoch: 6| Step: 5
Training loss: 0.30155256390571594
Validation loss: 1.6016804941238896

Epoch: 6| Step: 6
Training loss: 0.3949279189109802
Validation loss: 1.62219040624557

Epoch: 6| Step: 7
Training loss: 0.15716324746608734
Validation loss: 1.6500806462380193

Epoch: 6| Step: 8
Training loss: 0.3976143002510071
Validation loss: 1.6884434607721144

Epoch: 6| Step: 9
Training loss: 0.47854143381118774
Validation loss: 1.7006470259799753

Epoch: 6| Step: 10
Training loss: 0.7522167563438416
Validation loss: 1.6744015011736142

Epoch: 6| Step: 11
Training loss: 0.41807132959365845
Validation loss: 1.6423031873600458

Epoch: 6| Step: 12
Training loss: 0.2974556088447571
Validation loss: 1.595297731379027

Epoch: 6| Step: 13
Training loss: 0.2922717332839966
Validation loss: 1.5785543431517899

Epoch: 319| Step: 0
Training loss: 0.40333428978919983
Validation loss: 1.5616548074189054

Epoch: 6| Step: 1
Training loss: 0.5378800630569458
Validation loss: 1.584487271565263

Epoch: 6| Step: 2
Training loss: 0.26972606778144836
Validation loss: 1.6180343986839376

Epoch: 6| Step: 3
Training loss: 0.452968567609787
Validation loss: 1.6412457522525583

Epoch: 6| Step: 4
Training loss: 0.3690405488014221
Validation loss: 1.6639384223568825

Epoch: 6| Step: 5
Training loss: 0.3339901566505432
Validation loss: 1.6960219785731325

Epoch: 6| Step: 6
Training loss: 0.3329932689666748
Validation loss: 1.708961857262478

Epoch: 6| Step: 7
Training loss: 0.3581400215625763
Validation loss: 1.6986739122739403

Epoch: 6| Step: 8
Training loss: 0.6468433141708374
Validation loss: 1.7099122539643319

Epoch: 6| Step: 9
Training loss: 0.2094862312078476
Validation loss: 1.688925685421113

Epoch: 6| Step: 10
Training loss: 0.3751491904258728
Validation loss: 1.648209680793106

Epoch: 6| Step: 11
Training loss: 0.3731682002544403
Validation loss: 1.6754064559936523

Epoch: 6| Step: 12
Training loss: 0.39585620164871216
Validation loss: 1.6929459148837673

Epoch: 6| Step: 13
Training loss: 0.33576059341430664
Validation loss: 1.6809225390034337

Epoch: 320| Step: 0
Training loss: 0.2423706352710724
Validation loss: 1.6830590745454193

Epoch: 6| Step: 1
Training loss: 0.493241548538208
Validation loss: 1.6583243787929576

Epoch: 6| Step: 2
Training loss: 0.33813145756721497
Validation loss: 1.6628939913165184

Epoch: 6| Step: 3
Training loss: 0.5549303293228149
Validation loss: 1.6634061663381514

Epoch: 6| Step: 4
Training loss: 0.44367557764053345
Validation loss: 1.66784429934717

Epoch: 6| Step: 5
Training loss: 0.34980690479278564
Validation loss: 1.675192138200165

Epoch: 6| Step: 6
Training loss: 0.5071288347244263
Validation loss: 1.6842588980992634

Epoch: 6| Step: 7
Training loss: 0.34262174367904663
Validation loss: 1.6862083801659205

Epoch: 6| Step: 8
Training loss: 0.2007991075515747
Validation loss: 1.6420787354951263

Epoch: 6| Step: 9
Training loss: 0.28508034348487854
Validation loss: 1.6340172534347863

Epoch: 6| Step: 10
Training loss: 0.2515888810157776
Validation loss: 1.6256312285700152

Epoch: 6| Step: 11
Training loss: 0.4186728000640869
Validation loss: 1.5986545675544328

Epoch: 6| Step: 12
Training loss: 0.3884205222129822
Validation loss: 1.6088296405730709

Epoch: 6| Step: 13
Training loss: 0.30468475818634033
Validation loss: 1.5951212388212963

Epoch: 321| Step: 0
Training loss: 0.20836108922958374
Validation loss: 1.6251618733970068

Epoch: 6| Step: 1
Training loss: 0.45290833711624146
Validation loss: 1.6360636911084574

Epoch: 6| Step: 2
Training loss: 0.4024602770805359
Validation loss: 1.6284518241882324

Epoch: 6| Step: 3
Training loss: 0.2759433388710022
Validation loss: 1.63746516935287

Epoch: 6| Step: 4
Training loss: 0.2774167060852051
Validation loss: 1.6005757483102943

Epoch: 6| Step: 5
Training loss: 0.26120465993881226
Validation loss: 1.6001834433565858

Epoch: 6| Step: 6
Training loss: 0.3752850890159607
Validation loss: 1.5783565493040188

Epoch: 6| Step: 7
Training loss: 0.23027075827121735
Validation loss: 1.5627658123611121

Epoch: 6| Step: 8
Training loss: 0.3126196265220642
Validation loss: 1.5780731888227566

Epoch: 6| Step: 9
Training loss: 0.21424561738967896
Validation loss: 1.5898412530140211

Epoch: 6| Step: 10
Training loss: 0.601776123046875
Validation loss: 1.604384078774401

Epoch: 6| Step: 11
Training loss: 0.260178804397583
Validation loss: 1.5867378339972547

Epoch: 6| Step: 12
Training loss: 0.41879627108573914
Validation loss: 1.6445034941037495

Epoch: 6| Step: 13
Training loss: 0.3446749150753021
Validation loss: 1.6094515797912434

Epoch: 322| Step: 0
Training loss: 0.15481579303741455
Validation loss: 1.618912067464603

Epoch: 6| Step: 1
Training loss: 0.16603782773017883
Validation loss: 1.6478050613916049

Epoch: 6| Step: 2
Training loss: 0.30208146572113037
Validation loss: 1.6088404258092244

Epoch: 6| Step: 3
Training loss: 0.4433623254299164
Validation loss: 1.6118594907945203

Epoch: 6| Step: 4
Training loss: 0.22366780042648315
Validation loss: 1.5950596640186925

Epoch: 6| Step: 5
Training loss: 0.22745156288146973
Validation loss: 1.581652839978536

Epoch: 6| Step: 6
Training loss: 0.32787540555000305
Validation loss: 1.5874370374987203

Epoch: 6| Step: 7
Training loss: 0.22885443270206451
Validation loss: 1.5671255062985163

Epoch: 6| Step: 8
Training loss: 0.5524636507034302
Validation loss: 1.5890966846096901

Epoch: 6| Step: 9
Training loss: 0.37271225452423096
Validation loss: 1.6118254661560059

Epoch: 6| Step: 10
Training loss: 0.2215295284986496
Validation loss: 1.6159013702023415

Epoch: 6| Step: 11
Training loss: 0.20574963092803955
Validation loss: 1.5760864160394157

Epoch: 6| Step: 12
Training loss: 0.45349952578544617
Validation loss: 1.6118859321840349

Epoch: 6| Step: 13
Training loss: 0.4048725366592407
Validation loss: 1.578492550439732

Epoch: 323| Step: 0
Training loss: 0.16685611009597778
Validation loss: 1.582391845282688

Epoch: 6| Step: 1
Training loss: 0.37667009234428406
Validation loss: 1.546883265177409

Epoch: 6| Step: 2
Training loss: 0.33118677139282227
Validation loss: 1.5396374797308316

Epoch: 6| Step: 3
Training loss: 0.2816310524940491
Validation loss: 1.5531992412382556

Epoch: 6| Step: 4
Training loss: 0.23718610405921936
Validation loss: 1.5305472150925667

Epoch: 6| Step: 5
Training loss: 0.3216245770454407
Validation loss: 1.542147454395089

Epoch: 6| Step: 6
Training loss: 0.33023494482040405
Validation loss: 1.5789991399293304

Epoch: 6| Step: 7
Training loss: 0.3015713095664978
Validation loss: 1.5934149251189282

Epoch: 6| Step: 8
Training loss: 0.2520434856414795
Validation loss: 1.5920661111031809

Epoch: 6| Step: 9
Training loss: 0.30706721544265747
Validation loss: 1.5978796546177199

Epoch: 6| Step: 10
Training loss: 0.4657291769981384
Validation loss: 1.62463540287428

Epoch: 6| Step: 11
Training loss: 0.44132235646247864
Validation loss: 1.607306395807574

Epoch: 6| Step: 12
Training loss: 0.18381279706954956
Validation loss: 1.647756734201985

Epoch: 6| Step: 13
Training loss: 0.480862557888031
Validation loss: 1.651618653728116

Epoch: 324| Step: 0
Training loss: 0.4606033265590668
Validation loss: 1.623405949402881

Epoch: 6| Step: 1
Training loss: 0.4371269941329956
Validation loss: 1.6045522395000662

Epoch: 6| Step: 2
Training loss: 0.2847314774990082
Validation loss: 1.5505255204375072

Epoch: 6| Step: 3
Training loss: 0.28375208377838135
Validation loss: 1.5609366534858622

Epoch: 6| Step: 4
Training loss: 0.23942840099334717
Validation loss: 1.570462558859138

Epoch: 6| Step: 5
Training loss: 0.3477309048175812
Validation loss: 1.5472886408528974

Epoch: 6| Step: 6
Training loss: 0.3186953663825989
Validation loss: 1.5426671671611007

Epoch: 6| Step: 7
Training loss: 0.14736749231815338
Validation loss: 1.5576143521134571

Epoch: 6| Step: 8
Training loss: 0.31448012590408325
Validation loss: 1.6058375015053699

Epoch: 6| Step: 9
Training loss: 0.30526959896087646
Validation loss: 1.6434943522176435

Epoch: 6| Step: 10
Training loss: 0.3581081032752991
Validation loss: 1.642732862503298

Epoch: 6| Step: 11
Training loss: 0.30169790983200073
Validation loss: 1.651275029746435

Epoch: 6| Step: 12
Training loss: 0.22311392426490784
Validation loss: 1.6386389347814745

Epoch: 6| Step: 13
Training loss: 0.3600519299507141
Validation loss: 1.618387552999681

Epoch: 325| Step: 0
Training loss: 0.20774871110916138
Validation loss: 1.6128166029530187

Epoch: 6| Step: 1
Training loss: 0.2515323758125305
Validation loss: 1.6028635847953059

Epoch: 6| Step: 2
Training loss: 0.2042222023010254
Validation loss: 1.6121919706303587

Epoch: 6| Step: 3
Training loss: 0.6696432828903198
Validation loss: 1.6106523518921227

Epoch: 6| Step: 4
Training loss: 0.28784847259521484
Validation loss: 1.608667923558143

Epoch: 6| Step: 5
Training loss: 0.27906015515327454
Validation loss: 1.6139596072576379

Epoch: 6| Step: 6
Training loss: 0.29339343309402466
Validation loss: 1.6044459240410918

Epoch: 6| Step: 7
Training loss: 0.3856392800807953
Validation loss: 1.6119397019827237

Epoch: 6| Step: 8
Training loss: 0.35645392537117004
Validation loss: 1.591463008875488

Epoch: 6| Step: 9
Training loss: 0.23105306923389435
Validation loss: 1.591752040770746

Epoch: 6| Step: 10
Training loss: 0.29318803548812866
Validation loss: 1.6284456124869726

Epoch: 6| Step: 11
Training loss: 0.16108188033103943
Validation loss: 1.572912117486359

Epoch: 6| Step: 12
Training loss: 0.26262837648391724
Validation loss: 1.5620763442849601

Epoch: 6| Step: 13
Training loss: 0.3772087097167969
Validation loss: 1.5556489293293287

Epoch: 326| Step: 0
Training loss: 0.27389299869537354
Validation loss: 1.5368247262893184

Epoch: 6| Step: 1
Training loss: 0.32636159658432007
Validation loss: 1.5641579204990017

Epoch: 6| Step: 2
Training loss: 0.4659653902053833
Validation loss: 1.5673406303569835

Epoch: 6| Step: 3
Training loss: 0.2538691759109497
Validation loss: 1.5805582487454979

Epoch: 6| Step: 4
Training loss: 0.42607125639915466
Validation loss: 1.5730750663306123

Epoch: 6| Step: 5
Training loss: 0.2693403363227844
Validation loss: 1.570944461771237

Epoch: 6| Step: 6
Training loss: 0.30021315813064575
Validation loss: 1.5656614765044181

Epoch: 6| Step: 7
Training loss: 0.2744811475276947
Validation loss: 1.5660630195371565

Epoch: 6| Step: 8
Training loss: 0.13977812230587006
Validation loss: 1.6154021357977262

Epoch: 6| Step: 9
Training loss: 0.3060109615325928
Validation loss: 1.6550073969748713

Epoch: 6| Step: 10
Training loss: 0.36563435196876526
Validation loss: 1.6526605262551257

Epoch: 6| Step: 11
Training loss: 0.46767139434814453
Validation loss: 1.664248538273637

Epoch: 6| Step: 12
Training loss: 0.5664914846420288
Validation loss: 1.6292313850054176

Epoch: 6| Step: 13
Training loss: 0.40074408054351807
Validation loss: 1.618250625107878

Epoch: 327| Step: 0
Training loss: 0.24130159616470337
Validation loss: 1.6284348823690926

Epoch: 6| Step: 1
Training loss: 0.4065881371498108
Validation loss: 1.6245938911232898

Epoch: 6| Step: 2
Training loss: 0.38684195280075073
Validation loss: 1.6569343946313346

Epoch: 6| Step: 3
Training loss: 0.37701863050460815
Validation loss: 1.6399554693570702

Epoch: 6| Step: 4
Training loss: 0.3408695459365845
Validation loss: 1.6147881605291878

Epoch: 6| Step: 5
Training loss: 0.18996970355510712
Validation loss: 1.5843632349403955

Epoch: 6| Step: 6
Training loss: 0.3519732356071472
Validation loss: 1.5460832042078818

Epoch: 6| Step: 7
Training loss: 0.2951048016548157
Validation loss: 1.5484274478368862

Epoch: 6| Step: 8
Training loss: 0.28852665424346924
Validation loss: 1.5478607569971392

Epoch: 6| Step: 9
Training loss: 0.4043586552143097
Validation loss: 1.5722038989425988

Epoch: 6| Step: 10
Training loss: 0.20161673426628113
Validation loss: 1.5649566970845705

Epoch: 6| Step: 11
Training loss: 0.2784925401210785
Validation loss: 1.5823051262927312

Epoch: 6| Step: 12
Training loss: 0.302022784948349
Validation loss: 1.5640184712666336

Epoch: 6| Step: 13
Training loss: 0.15301679074764252
Validation loss: 1.5733939652801843

Epoch: 328| Step: 0
Training loss: 0.39296483993530273
Validation loss: 1.5830807032123688

Epoch: 6| Step: 1
Training loss: 0.21863652765750885
Validation loss: 1.573935342091386

Epoch: 6| Step: 2
Training loss: 0.47644221782684326
Validation loss: 1.5927596579315841

Epoch: 6| Step: 3
Training loss: 0.37645891308784485
Validation loss: 1.5817071237871725

Epoch: 6| Step: 4
Training loss: 0.40796875953674316
Validation loss: 1.5389625026333718

Epoch: 6| Step: 5
Training loss: 0.2036777138710022
Validation loss: 1.526418775640508

Epoch: 6| Step: 6
Training loss: 0.1906062513589859
Validation loss: 1.5122570376242361

Epoch: 6| Step: 7
Training loss: 0.20099641382694244
Validation loss: 1.5307050302464476

Epoch: 6| Step: 8
Training loss: 0.22781145572662354
Validation loss: 1.5096367097670031

Epoch: 6| Step: 9
Training loss: 0.3110489249229431
Validation loss: 1.4975969881139777

Epoch: 6| Step: 10
Training loss: 0.3424978256225586
Validation loss: 1.4986003880859704

Epoch: 6| Step: 11
Training loss: 0.29601025581359863
Validation loss: 1.5164607994018062

Epoch: 6| Step: 12
Training loss: 0.4595540761947632
Validation loss: 1.5262309543548092

Epoch: 6| Step: 13
Training loss: 0.24238494038581848
Validation loss: 1.5533100405047018

Epoch: 329| Step: 0
Training loss: 0.28656235337257385
Validation loss: 1.5792472259972685

Epoch: 6| Step: 1
Training loss: 0.5591480135917664
Validation loss: 1.6000872658145042

Epoch: 6| Step: 2
Training loss: 0.34391945600509644
Validation loss: 1.60120012170525

Epoch: 6| Step: 3
Training loss: 0.17877724766731262
Validation loss: 1.607743432444911

Epoch: 6| Step: 4
Training loss: 0.24791590869426727
Validation loss: 1.5784468753363496

Epoch: 6| Step: 5
Training loss: 0.3155152499675751
Validation loss: 1.6159231560204619

Epoch: 6| Step: 6
Training loss: 0.18218174576759338
Validation loss: 1.619178174644388

Epoch: 6| Step: 7
Training loss: 0.4701714515686035
Validation loss: 1.6180352805763163

Epoch: 6| Step: 8
Training loss: 0.23382531106472015
Validation loss: 1.6093820705208728

Epoch: 6| Step: 9
Training loss: 0.2395256608724594
Validation loss: 1.6197370893211775

Epoch: 6| Step: 10
Training loss: 0.20583611726760864
Validation loss: 1.6217639253985496

Epoch: 6| Step: 11
Training loss: 0.27247390151023865
Validation loss: 1.6290916883817284

Epoch: 6| Step: 12
Training loss: 0.5691208243370056
Validation loss: 1.6371603076175978

Epoch: 6| Step: 13
Training loss: 0.31601327657699585
Validation loss: 1.6704406225553123

Epoch: 330| Step: 0
Training loss: 0.33196210861206055
Validation loss: 1.716844081878662

Epoch: 6| Step: 1
Training loss: 0.5067334771156311
Validation loss: 1.7089789272636495

Epoch: 6| Step: 2
Training loss: 0.41257452964782715
Validation loss: 1.7129829955357376

Epoch: 6| Step: 3
Training loss: 0.3336031436920166
Validation loss: 1.6736377734009937

Epoch: 6| Step: 4
Training loss: 0.3452681005001068
Validation loss: 1.6151764956853722

Epoch: 6| Step: 5
Training loss: 0.16005484759807587
Validation loss: 1.6190677112148655

Epoch: 6| Step: 6
Training loss: 0.2383834570646286
Validation loss: 1.6033516545449533

Epoch: 6| Step: 7
Training loss: 0.31452760100364685
Validation loss: 1.6216046553786083

Epoch: 6| Step: 8
Training loss: 0.27522629499435425
Validation loss: 1.5910948873848043

Epoch: 6| Step: 9
Training loss: 0.28735509514808655
Validation loss: 1.5734881765098983

Epoch: 6| Step: 10
Training loss: 0.41950759291648865
Validation loss: 1.5711938501686178

Epoch: 6| Step: 11
Training loss: 0.2631995379924774
Validation loss: 1.5817651056474256

Epoch: 6| Step: 12
Training loss: 0.18681064248085022
Validation loss: 1.5617831624964231

Epoch: 6| Step: 13
Training loss: 0.25079667568206787
Validation loss: 1.5711863246015323

Epoch: 331| Step: 0
Training loss: 0.3019048869609833
Validation loss: 1.6174820853817848

Epoch: 6| Step: 1
Training loss: 0.23700854182243347
Validation loss: 1.6201280598999352

Epoch: 6| Step: 2
Training loss: 0.32256463170051575
Validation loss: 1.596783088099572

Epoch: 6| Step: 3
Training loss: 0.32846367359161377
Validation loss: 1.6064863128046836

Epoch: 6| Step: 4
Training loss: 0.2691521644592285
Validation loss: 1.6222299606569353

Epoch: 6| Step: 5
Training loss: 0.2752760052680969
Validation loss: 1.5985311487669587

Epoch: 6| Step: 6
Training loss: 0.2442094087600708
Validation loss: 1.591058955397657

Epoch: 6| Step: 7
Training loss: 0.25321152806282043
Validation loss: 1.5796138445536296

Epoch: 6| Step: 8
Training loss: 0.2284729778766632
Validation loss: 1.5587337657969484

Epoch: 6| Step: 9
Training loss: 0.2897998094558716
Validation loss: 1.5871927981735559

Epoch: 6| Step: 10
Training loss: 0.24070420861244202
Validation loss: 1.583330346691993

Epoch: 6| Step: 11
Training loss: 0.26549822092056274
Validation loss: 1.5994202744576238

Epoch: 6| Step: 12
Training loss: 0.31226015090942383
Validation loss: 1.5696767235314975

Epoch: 6| Step: 13
Training loss: 0.12538568675518036
Validation loss: 1.5778344446612942

Epoch: 332| Step: 0
Training loss: 0.17632445693016052
Validation loss: 1.562352543236107

Epoch: 6| Step: 1
Training loss: 0.1559823453426361
Validation loss: 1.5353936482501287

Epoch: 6| Step: 2
Training loss: 0.2642780542373657
Validation loss: 1.557807573708155

Epoch: 6| Step: 3
Training loss: 0.345345139503479
Validation loss: 1.5439848970341425

Epoch: 6| Step: 4
Training loss: 0.2237587422132492
Validation loss: 1.5787126697519773

Epoch: 6| Step: 5
Training loss: 0.16584298014640808
Validation loss: 1.5662627207335604

Epoch: 6| Step: 6
Training loss: 0.27809080481529236
Validation loss: 1.5832806377000705

Epoch: 6| Step: 7
Training loss: 0.13471123576164246
Validation loss: 1.5803838949049673

Epoch: 6| Step: 8
Training loss: 0.4107794463634491
Validation loss: 1.5708598257392965

Epoch: 6| Step: 9
Training loss: 0.470267117023468
Validation loss: 1.572603048816804

Epoch: 6| Step: 10
Training loss: 0.18425416946411133
Validation loss: 1.5882649511419318

Epoch: 6| Step: 11
Training loss: 0.2706567645072937
Validation loss: 1.5755735148665726

Epoch: 6| Step: 12
Training loss: 0.415005624294281
Validation loss: 1.5638221374122045

Epoch: 6| Step: 13
Training loss: 0.30933427810668945
Validation loss: 1.5768471892162035

Epoch: 333| Step: 0
Training loss: 0.19569456577301025
Validation loss: 1.5576458195204377

Epoch: 6| Step: 1
Training loss: 0.30985063314437866
Validation loss: 1.554941838787448

Epoch: 6| Step: 2
Training loss: 0.25707340240478516
Validation loss: 1.5536075112640217

Epoch: 6| Step: 3
Training loss: 0.38038086891174316
Validation loss: 1.5642771131248885

Epoch: 6| Step: 4
Training loss: 0.24100232124328613
Validation loss: 1.552875655953602

Epoch: 6| Step: 5
Training loss: 0.15277273952960968
Validation loss: 1.5564061243046996

Epoch: 6| Step: 6
Training loss: 0.3348004221916199
Validation loss: 1.5820336726404005

Epoch: 6| Step: 7
Training loss: 0.1663142740726471
Validation loss: 1.598808124501218

Epoch: 6| Step: 8
Training loss: 0.34277212619781494
Validation loss: 1.6038175077848538

Epoch: 6| Step: 9
Training loss: 0.1996675282716751
Validation loss: 1.604520816956797

Epoch: 6| Step: 10
Training loss: 0.1935947835445404
Validation loss: 1.5922748632328485

Epoch: 6| Step: 11
Training loss: 0.2640155255794525
Validation loss: 1.5871582364523282

Epoch: 6| Step: 12
Training loss: 0.463561475276947
Validation loss: 1.5300496342361614

Epoch: 6| Step: 13
Training loss: 0.34893515706062317
Validation loss: 1.4898737963809763

Epoch: 334| Step: 0
Training loss: 0.2512713670730591
Validation loss: 1.4795810753299343

Epoch: 6| Step: 1
Training loss: 0.2504630982875824
Validation loss: 1.4745485526259228

Epoch: 6| Step: 2
Training loss: 0.4330471456050873
Validation loss: 1.4705994090726298

Epoch: 6| Step: 3
Training loss: 0.30018436908721924
Validation loss: 1.5203578292682607

Epoch: 6| Step: 4
Training loss: 0.3303094506263733
Validation loss: 1.5153874889496834

Epoch: 6| Step: 5
Training loss: 0.48090916872024536
Validation loss: 1.4865036837516292

Epoch: 6| Step: 6
Training loss: 0.29919445514678955
Validation loss: 1.5051082026573919

Epoch: 6| Step: 7
Training loss: 0.2576586604118347
Validation loss: 1.5194482072707145

Epoch: 6| Step: 8
Training loss: 0.2093620002269745
Validation loss: 1.5376972754796345

Epoch: 6| Step: 9
Training loss: 0.23823358118534088
Validation loss: 1.5350252800090338

Epoch: 6| Step: 10
Training loss: 0.2545950412750244
Validation loss: 1.553844004549006

Epoch: 6| Step: 11
Training loss: 0.16643860936164856
Validation loss: 1.5807193504866732

Epoch: 6| Step: 12
Training loss: 0.19973698258399963
Validation loss: 1.5880565265173554

Epoch: 6| Step: 13
Training loss: 0.15660126507282257
Validation loss: 1.5584493196138771

Epoch: 335| Step: 0
Training loss: 0.1394745111465454
Validation loss: 1.5681983347861999

Epoch: 6| Step: 1
Training loss: 0.27294522523880005
Validation loss: 1.5419527907525339

Epoch: 6| Step: 2
Training loss: 0.2395399808883667
Validation loss: 1.5358909740242908

Epoch: 6| Step: 3
Training loss: 0.19028612971305847
Validation loss: 1.5400060851086852

Epoch: 6| Step: 4
Training loss: 0.35567355155944824
Validation loss: 1.5245264935237106

Epoch: 6| Step: 5
Training loss: 0.29953253269195557
Validation loss: 1.5278487410596622

Epoch: 6| Step: 6
Training loss: 0.15496782958507538
Validation loss: 1.530842677880359

Epoch: 6| Step: 7
Training loss: 0.19900086522102356
Validation loss: 1.558664232171992

Epoch: 6| Step: 8
Training loss: 0.4061817526817322
Validation loss: 1.5707619164579658

Epoch: 6| Step: 9
Training loss: 0.27021101117134094
Validation loss: 1.5626137750123137

Epoch: 6| Step: 10
Training loss: 0.3015201985836029
Validation loss: 1.5741809286097044

Epoch: 6| Step: 11
Training loss: 0.2870864272117615
Validation loss: 1.547690071085448

Epoch: 6| Step: 12
Training loss: 0.3920235335826874
Validation loss: 1.5414023001988728

Epoch: 6| Step: 13
Training loss: 0.37996095418930054
Validation loss: 1.5525852531515143

Epoch: 336| Step: 0
Training loss: 0.3368901014328003
Validation loss: 1.5870973179417271

Epoch: 6| Step: 1
Training loss: 0.19298899173736572
Validation loss: 1.5702460850438764

Epoch: 6| Step: 2
Training loss: 0.24369677901268005
Validation loss: 1.5340126188852454

Epoch: 6| Step: 3
Training loss: 0.2179524302482605
Validation loss: 1.5317648123669367

Epoch: 6| Step: 4
Training loss: 0.32053929567337036
Validation loss: 1.550199152961854

Epoch: 6| Step: 5
Training loss: 0.411729097366333
Validation loss: 1.5797252731938516

Epoch: 6| Step: 6
Training loss: 0.23473036289215088
Validation loss: 1.586676666813512

Epoch: 6| Step: 7
Training loss: 0.4475388526916504
Validation loss: 1.6079459267277871

Epoch: 6| Step: 8
Training loss: 0.3335757851600647
Validation loss: 1.5938736110605218

Epoch: 6| Step: 9
Training loss: 0.29423871636390686
Validation loss: 1.6070698320224721

Epoch: 6| Step: 10
Training loss: 0.12521527707576752
Validation loss: 1.5615590439047864

Epoch: 6| Step: 11
Training loss: 0.24661874771118164
Validation loss: 1.5558192306949246

Epoch: 6| Step: 12
Training loss: 0.34626442193984985
Validation loss: 1.5500578534218572

Epoch: 6| Step: 13
Training loss: 0.18577834963798523
Validation loss: 1.545873575313117

Epoch: 337| Step: 0
Training loss: 0.40985679626464844
Validation loss: 1.519845861260609

Epoch: 6| Step: 1
Training loss: 0.18726974725723267
Validation loss: 1.5060754411964006

Epoch: 6| Step: 2
Training loss: 0.332155704498291
Validation loss: 1.5050732102445377

Epoch: 6| Step: 3
Training loss: 0.24973703920841217
Validation loss: 1.5082724453300558

Epoch: 6| Step: 4
Training loss: 0.27586981654167175
Validation loss: 1.4885205427805583

Epoch: 6| Step: 5
Training loss: 0.26923829317092896
Validation loss: 1.4856671210258239

Epoch: 6| Step: 6
Training loss: 0.23560771346092224
Validation loss: 1.4847581899294289

Epoch: 6| Step: 7
Training loss: 0.24667441844940186
Validation loss: 1.4879889885584514

Epoch: 6| Step: 8
Training loss: 0.2837953269481659
Validation loss: 1.4843597847928283

Epoch: 6| Step: 9
Training loss: 0.42185521125793457
Validation loss: 1.5031777222951253

Epoch: 6| Step: 10
Training loss: 0.2950453460216522
Validation loss: 1.5248565468736874

Epoch: 6| Step: 11
Training loss: 0.26806414127349854
Validation loss: 1.516725722179618

Epoch: 6| Step: 12
Training loss: 0.32197827100753784
Validation loss: 1.5311816251406105

Epoch: 6| Step: 13
Training loss: 0.16742096841335297
Validation loss: 1.553676046350951

Epoch: 338| Step: 0
Training loss: 0.26405420899391174
Validation loss: 1.5371852177445606

Epoch: 6| Step: 1
Training loss: 0.22511708736419678
Validation loss: 1.5283493200937908

Epoch: 6| Step: 2
Training loss: 0.3166855573654175
Validation loss: 1.5313723382129465

Epoch: 6| Step: 3
Training loss: 0.5499285459518433
Validation loss: 1.53300392371352

Epoch: 6| Step: 4
Training loss: 0.21988001465797424
Validation loss: 1.5514829261328584

Epoch: 6| Step: 5
Training loss: 0.32602569460868835
Validation loss: 1.5335976987756708

Epoch: 6| Step: 6
Training loss: 0.22119037806987762
Validation loss: 1.5766219144226403

Epoch: 6| Step: 7
Training loss: 0.23977908492088318
Validation loss: 1.5706396231087305

Epoch: 6| Step: 8
Training loss: 0.16522550582885742
Validation loss: 1.5496565949532293

Epoch: 6| Step: 9
Training loss: 0.2262967824935913
Validation loss: 1.5536359907478414

Epoch: 6| Step: 10
Training loss: 0.21607336401939392
Validation loss: 1.539188979774393

Epoch: 6| Step: 11
Training loss: 0.3245989680290222
Validation loss: 1.5709371105317147

Epoch: 6| Step: 12
Training loss: 0.3943391442298889
Validation loss: 1.5662809982094714

Epoch: 6| Step: 13
Training loss: 0.2972569763660431
Validation loss: 1.536042441603958

Epoch: 339| Step: 0
Training loss: 0.1998218297958374
Validation loss: 1.4963642845871628

Epoch: 6| Step: 1
Training loss: 0.19968552887439728
Validation loss: 1.5184471107298327

Epoch: 6| Step: 2
Training loss: 0.23382773995399475
Validation loss: 1.505926106565742

Epoch: 6| Step: 3
Training loss: 0.20093286037445068
Validation loss: 1.5310707643467893

Epoch: 6| Step: 4
Training loss: 0.41897308826446533
Validation loss: 1.5559350405969927

Epoch: 6| Step: 5
Training loss: 0.3971625566482544
Validation loss: 1.5725063675193376

Epoch: 6| Step: 6
Training loss: 0.3895373046398163
Validation loss: 1.4895705067983238

Epoch: 6| Step: 7
Training loss: 0.13102975487709045
Validation loss: 1.4934235260050783

Epoch: 6| Step: 8
Training loss: 0.45694655179977417
Validation loss: 1.5130948328202771

Epoch: 6| Step: 9
Training loss: 0.26063695549964905
Validation loss: 1.5189504982322775

Epoch: 6| Step: 10
Training loss: 0.47565674781799316
Validation loss: 1.5250546624583583

Epoch: 6| Step: 11
Training loss: 0.29943835735321045
Validation loss: 1.5355141560236614

Epoch: 6| Step: 12
Training loss: 0.25302854180336
Validation loss: 1.5097586108792214

Epoch: 6| Step: 13
Training loss: 0.4031902551651001
Validation loss: 1.4833832043473438

Epoch: 340| Step: 0
Training loss: 0.11312387883663177
Validation loss: 1.510114182708084

Epoch: 6| Step: 1
Training loss: 0.20548853278160095
Validation loss: 1.507327240000489

Epoch: 6| Step: 2
Training loss: 0.20012906193733215
Validation loss: 1.52241805548309

Epoch: 6| Step: 3
Training loss: 0.1876644641160965
Validation loss: 1.5809965723304338

Epoch: 6| Step: 4
Training loss: 0.3443825840950012
Validation loss: 1.5574174388762443

Epoch: 6| Step: 5
Training loss: 0.24468189477920532
Validation loss: 1.5794499279350362

Epoch: 6| Step: 6
Training loss: 0.3310989439487457
Validation loss: 1.58197372446778

Epoch: 6| Step: 7
Training loss: 0.3459619879722595
Validation loss: 1.5803102703504666

Epoch: 6| Step: 8
Training loss: 0.28280654549598694
Validation loss: 1.574310552689337

Epoch: 6| Step: 9
Training loss: 0.2316228449344635
Validation loss: 1.5478116120061567

Epoch: 6| Step: 10
Training loss: 0.30942249298095703
Validation loss: 1.5534981681454567

Epoch: 6| Step: 11
Training loss: 0.33696115016937256
Validation loss: 1.5422463378598612

Epoch: 6| Step: 12
Training loss: 0.3481753468513489
Validation loss: 1.5342895356557702

Epoch: 6| Step: 13
Training loss: 0.2754655182361603
Validation loss: 1.5322603269289898

Epoch: 341| Step: 0
Training loss: 0.2813558280467987
Validation loss: 1.5454398816631687

Epoch: 6| Step: 1
Training loss: 0.22049354016780853
Validation loss: 1.530976333925801

Epoch: 6| Step: 2
Training loss: 0.2653340697288513
Validation loss: 1.5545868130140408

Epoch: 6| Step: 3
Training loss: 0.2861918807029724
Validation loss: 1.5404122503854896

Epoch: 6| Step: 4
Training loss: 0.3835669755935669
Validation loss: 1.571206941399523

Epoch: 6| Step: 5
Training loss: 0.25679606199264526
Validation loss: 1.554224689801534

Epoch: 6| Step: 6
Training loss: 0.21885080635547638
Validation loss: 1.5698077127497683

Epoch: 6| Step: 7
Training loss: 0.33321720361709595
Validation loss: 1.558442315747661

Epoch: 6| Step: 8
Training loss: 0.17422807216644287
Validation loss: 1.5713077873312018

Epoch: 6| Step: 9
Training loss: 0.20022308826446533
Validation loss: 1.5437514666588075

Epoch: 6| Step: 10
Training loss: 0.30730125308036804
Validation loss: 1.5471525128169725

Epoch: 6| Step: 11
Training loss: 0.2898293733596802
Validation loss: 1.5174530590734174

Epoch: 6| Step: 12
Training loss: 0.17608433961868286
Validation loss: 1.5129229842975576

Epoch: 6| Step: 13
Training loss: 0.22966483235359192
Validation loss: 1.5129562744530298

Epoch: 342| Step: 0
Training loss: 0.3643314242362976
Validation loss: 1.4706037159888976

Epoch: 6| Step: 1
Training loss: 0.21963857114315033
Validation loss: 1.476254302968261

Epoch: 6| Step: 2
Training loss: 0.34764763712882996
Validation loss: 1.5112938791192987

Epoch: 6| Step: 3
Training loss: 0.2987446188926697
Validation loss: 1.4985919613992014

Epoch: 6| Step: 4
Training loss: 0.27787432074546814
Validation loss: 1.5077748003826346

Epoch: 6| Step: 5
Training loss: 0.16101117432117462
Validation loss: 1.5333773487357683

Epoch: 6| Step: 6
Training loss: 0.11936032772064209
Validation loss: 1.5614754423018424

Epoch: 6| Step: 7
Training loss: 0.2510078251361847
Validation loss: 1.5889719122199601

Epoch: 6| Step: 8
Training loss: 0.3328895568847656
Validation loss: 1.6036050063307568

Epoch: 6| Step: 9
Training loss: 0.27668580412864685
Validation loss: 1.581799077731307

Epoch: 6| Step: 10
Training loss: 0.27754589915275574
Validation loss: 1.563311412770261

Epoch: 6| Step: 11
Training loss: 0.23673655092716217
Validation loss: 1.5388469670408516

Epoch: 6| Step: 12
Training loss: 0.2784135937690735
Validation loss: 1.5393410562187113

Epoch: 6| Step: 13
Training loss: 0.22335046529769897
Validation loss: 1.5085493544096589

Epoch: 343| Step: 0
Training loss: 0.2041652351617813
Validation loss: 1.5461682824678318

Epoch: 6| Step: 1
Training loss: 0.26588568091392517
Validation loss: 1.559100902849628

Epoch: 6| Step: 2
Training loss: 0.29014796018600464
Validation loss: 1.5459612210591633

Epoch: 6| Step: 3
Training loss: 0.2621626853942871
Validation loss: 1.5499971092388194

Epoch: 6| Step: 4
Training loss: 0.2925037145614624
Validation loss: 1.5210097271908996

Epoch: 6| Step: 5
Training loss: 0.06989501416683197
Validation loss: 1.5301316745819584

Epoch: 6| Step: 6
Training loss: 0.21654948592185974
Validation loss: 1.534450832233634

Epoch: 6| Step: 7
Training loss: 0.3650628328323364
Validation loss: 1.5119851327711535

Epoch: 6| Step: 8
Training loss: 0.1529628485441208
Validation loss: 1.5343675241675427

Epoch: 6| Step: 9
Training loss: 0.2139137089252472
Validation loss: 1.512118354920418

Epoch: 6| Step: 10
Training loss: 0.3834789991378784
Validation loss: 1.503829151071528

Epoch: 6| Step: 11
Training loss: 0.15264186263084412
Validation loss: 1.4976909122159403

Epoch: 6| Step: 12
Training loss: 0.37132975459098816
Validation loss: 1.4945603301448207

Epoch: 6| Step: 13
Training loss: 0.3157438039779663
Validation loss: 1.497162752254035

Epoch: 344| Step: 0
Training loss: 0.24810127913951874
Validation loss: 1.5156948540800361

Epoch: 6| Step: 1
Training loss: 0.42046716809272766
Validation loss: 1.5279747734787643

Epoch: 6| Step: 2
Training loss: 0.2631775438785553
Validation loss: 1.4955029846519552

Epoch: 6| Step: 3
Training loss: 0.229036346077919
Validation loss: 1.5155313502075851

Epoch: 6| Step: 4
Training loss: 0.22555801272392273
Validation loss: 1.5090568437371203

Epoch: 6| Step: 5
Training loss: 0.1585429310798645
Validation loss: 1.4982133283410022

Epoch: 6| Step: 6
Training loss: 0.24388504028320312
Validation loss: 1.5255756634537891

Epoch: 6| Step: 7
Training loss: 0.15390589833259583
Validation loss: 1.5393190076274257

Epoch: 6| Step: 8
Training loss: 0.32670503854751587
Validation loss: 1.5549829467650382

Epoch: 6| Step: 9
Training loss: 0.2512636184692383
Validation loss: 1.5592089840160903

Epoch: 6| Step: 10
Training loss: 0.38238728046417236
Validation loss: 1.5241866624483498

Epoch: 6| Step: 11
Training loss: 0.28546127676963806
Validation loss: 1.5161146515159196

Epoch: 6| Step: 12
Training loss: 0.3042249083518982
Validation loss: 1.5380028088887532

Epoch: 6| Step: 13
Training loss: 0.10290035605430603
Validation loss: 1.510660083063187

Epoch: 345| Step: 0
Training loss: 0.3148866891860962
Validation loss: 1.505829898259973

Epoch: 6| Step: 1
Training loss: 0.17216961085796356
Validation loss: 1.5148476810865505

Epoch: 6| Step: 2
Training loss: 0.2990652322769165
Validation loss: 1.5178109317697503

Epoch: 6| Step: 3
Training loss: 0.40905123949050903
Validation loss: 1.505563989762337

Epoch: 6| Step: 4
Training loss: 0.15015524625778198
Validation loss: 1.5058255516072756

Epoch: 6| Step: 5
Training loss: 0.20147573947906494
Validation loss: 1.5043666388398858

Epoch: 6| Step: 6
Training loss: 0.31597083806991577
Validation loss: 1.5188322605625275

Epoch: 6| Step: 7
Training loss: 0.2267666608095169
Validation loss: 1.5491399867560274

Epoch: 6| Step: 8
Training loss: 0.40490424633026123
Validation loss: 1.556364401694267

Epoch: 6| Step: 9
Training loss: 0.17232125997543335
Validation loss: 1.5963081236808532

Epoch: 6| Step: 10
Training loss: 0.23791244626045227
Validation loss: 1.6018638373703085

Epoch: 6| Step: 11
Training loss: 0.18820440769195557
Validation loss: 1.6181117103945823

Epoch: 6| Step: 12
Training loss: 0.24371908605098724
Validation loss: 1.608417607122852

Epoch: 6| Step: 13
Training loss: 0.2017459124326706
Validation loss: 1.593723508619493

Epoch: 346| Step: 0
Training loss: 0.13201461732387543
Validation loss: 1.5884154599200013

Epoch: 6| Step: 1
Training loss: 0.11316002905368805
Validation loss: 1.538727907724278

Epoch: 6| Step: 2
Training loss: 0.3629578948020935
Validation loss: 1.5370234789386872

Epoch: 6| Step: 3
Training loss: 0.29860660433769226
Validation loss: 1.540433838803281

Epoch: 6| Step: 4
Training loss: 0.2782195806503296
Validation loss: 1.5616552502878251

Epoch: 6| Step: 5
Training loss: 0.37416887283325195
Validation loss: 1.5219594291461411

Epoch: 6| Step: 6
Training loss: 0.2849231958389282
Validation loss: 1.5452525807965187

Epoch: 6| Step: 7
Training loss: 0.1595662385225296
Validation loss: 1.5448580134299494

Epoch: 6| Step: 8
Training loss: 0.359061598777771
Validation loss: 1.526039715736143

Epoch: 6| Step: 9
Training loss: 0.2694622874259949
Validation loss: 1.5523292223612468

Epoch: 6| Step: 10
Training loss: 0.13275793194770813
Validation loss: 1.536500225784958

Epoch: 6| Step: 11
Training loss: 0.31034255027770996
Validation loss: 1.5614106206483738

Epoch: 6| Step: 12
Training loss: 0.3011205196380615
Validation loss: 1.5976080099741619

Epoch: 6| Step: 13
Training loss: 0.10042016208171844
Validation loss: 1.613528364448137

Epoch: 347| Step: 0
Training loss: 0.36144450306892395
Validation loss: 1.6515043192012335

Epoch: 6| Step: 1
Training loss: 0.2509281635284424
Validation loss: 1.6591724029151342

Epoch: 6| Step: 2
Training loss: 0.2128782570362091
Validation loss: 1.6342024668570487

Epoch: 6| Step: 3
Training loss: 0.27739453315734863
Validation loss: 1.632287968871414

Epoch: 6| Step: 4
Training loss: 0.256940633058548
Validation loss: 1.585488200187683

Epoch: 6| Step: 5
Training loss: 0.22066032886505127
Validation loss: 1.5411998969252392

Epoch: 6| Step: 6
Training loss: 0.30754274129867554
Validation loss: 1.4919151644552908

Epoch: 6| Step: 7
Training loss: 0.23825795948505402
Validation loss: 1.4807490546216246

Epoch: 6| Step: 8
Training loss: 0.1626647412776947
Validation loss: 1.4639392783564906

Epoch: 6| Step: 9
Training loss: 0.3309495747089386
Validation loss: 1.432327728758576

Epoch: 6| Step: 10
Training loss: 0.28877657651901245
Validation loss: 1.4546717354046401

Epoch: 6| Step: 11
Training loss: 0.4514767527580261
Validation loss: 1.47209967208165

Epoch: 6| Step: 12
Training loss: 0.351534903049469
Validation loss: 1.4331364170197518

Epoch: 6| Step: 13
Training loss: 0.43771040439605713
Validation loss: 1.4394202386179278

Epoch: 348| Step: 0
Training loss: 0.38431835174560547
Validation loss: 1.459998583280912

Epoch: 6| Step: 1
Training loss: 0.25504615902900696
Validation loss: 1.4711211599329466

Epoch: 6| Step: 2
Training loss: 0.21087880432605743
Validation loss: 1.5213683882067282

Epoch: 6| Step: 3
Training loss: 0.3393426537513733
Validation loss: 1.550549086704049

Epoch: 6| Step: 4
Training loss: 0.40533769130706787
Validation loss: 1.5457677892459336

Epoch: 6| Step: 5
Training loss: 0.1783924400806427
Validation loss: 1.595087484646869

Epoch: 6| Step: 6
Training loss: 0.28137847781181335
Validation loss: 1.569719486339118

Epoch: 6| Step: 7
Training loss: 0.2627127170562744
Validation loss: 1.540033209708429

Epoch: 6| Step: 8
Training loss: 0.20384351909160614
Validation loss: 1.5319140316337667

Epoch: 6| Step: 9
Training loss: 0.260949969291687
Validation loss: 1.5132565318897206

Epoch: 6| Step: 10
Training loss: 0.1735600382089615
Validation loss: 1.4925180519780805

Epoch: 6| Step: 11
Training loss: 0.2655644416809082
Validation loss: 1.5181309638484832

Epoch: 6| Step: 12
Training loss: 0.4318215847015381
Validation loss: 1.526387273624379

Epoch: 6| Step: 13
Training loss: 0.15614016354084015
Validation loss: 1.5249565147584485

Epoch: 349| Step: 0
Training loss: 0.24815985560417175
Validation loss: 1.5142405815021966

Epoch: 6| Step: 1
Training loss: 0.3474476933479309
Validation loss: 1.5254600740248156

Epoch: 6| Step: 2
Training loss: 0.35013219714164734
Validation loss: 1.5084186568055102

Epoch: 6| Step: 3
Training loss: 0.14240527153015137
Validation loss: 1.522704053950566

Epoch: 6| Step: 4
Training loss: 0.21734604239463806
Validation loss: 1.5434272571276593

Epoch: 6| Step: 5
Training loss: 0.12691321969032288
Validation loss: 1.5760276394505655

Epoch: 6| Step: 6
Training loss: 0.34922927618026733
Validation loss: 1.5849642151145524

Epoch: 6| Step: 7
Training loss: 0.19547347724437714
Validation loss: 1.6060839160796134

Epoch: 6| Step: 8
Training loss: 0.3144732415676117
Validation loss: 1.6472071101588588

Epoch: 6| Step: 9
Training loss: 0.18816672265529633
Validation loss: 1.6405252192610054

Epoch: 6| Step: 10
Training loss: 0.3513685464859009
Validation loss: 1.616548175452858

Epoch: 6| Step: 11
Training loss: 0.26698964834213257
Validation loss: 1.5451131584823772

Epoch: 6| Step: 12
Training loss: 0.40741294622421265
Validation loss: 1.5200085716862832

Epoch: 6| Step: 13
Training loss: 0.2645358443260193
Validation loss: 1.473470910262036

Epoch: 350| Step: 0
Training loss: 0.20308047533035278
Validation loss: 1.454549269009662

Epoch: 6| Step: 1
Training loss: 0.3041180968284607
Validation loss: 1.447900692621867

Epoch: 6| Step: 2
Training loss: 0.23918995261192322
Validation loss: 1.4393738726133942

Epoch: 6| Step: 3
Training loss: 0.3808363378047943
Validation loss: 1.4490466528041388

Epoch: 6| Step: 4
Training loss: 0.2307606190443039
Validation loss: 1.4461512898886075

Epoch: 6| Step: 5
Training loss: 0.2509525716304779
Validation loss: 1.446599232253208

Epoch: 6| Step: 6
Training loss: 0.151066854596138
Validation loss: 1.4615030365605508

Epoch: 6| Step: 7
Training loss: 0.22719988226890564
Validation loss: 1.5096188975918678

Epoch: 6| Step: 8
Training loss: 0.19850388169288635
Validation loss: 1.520855640852323

Epoch: 6| Step: 9
Training loss: 0.3641311824321747
Validation loss: 1.581599864908444

Epoch: 6| Step: 10
Training loss: 0.28861451148986816
Validation loss: 1.5734482247342345

Epoch: 6| Step: 11
Training loss: 0.2745882570743561
Validation loss: 1.5836736015094224

Epoch: 6| Step: 12
Training loss: 0.14751818776130676
Validation loss: 1.5685064715723838

Epoch: 6| Step: 13
Training loss: 0.3636954128742218
Validation loss: 1.527823471253918

Epoch: 351| Step: 0
Training loss: 0.2619503140449524
Validation loss: 1.525115031068043

Epoch: 6| Step: 1
Training loss: 0.183784618973732
Validation loss: 1.4987032080209384

Epoch: 6| Step: 2
Training loss: 0.28181353211402893
Validation loss: 1.5030312012600642

Epoch: 6| Step: 3
Training loss: 0.31103336811065674
Validation loss: 1.486558405301904

Epoch: 6| Step: 4
Training loss: 0.23240721225738525
Validation loss: 1.4990653325152654

Epoch: 6| Step: 5
Training loss: 0.18192121386528015
Validation loss: 1.4861274259064787

Epoch: 6| Step: 6
Training loss: 0.15300650894641876
Validation loss: 1.5098545282117781

Epoch: 6| Step: 7
Training loss: 0.23176884651184082
Validation loss: 1.526500686522453

Epoch: 6| Step: 8
Training loss: 0.17507824301719666
Validation loss: 1.531435724227659

Epoch: 6| Step: 9
Training loss: 0.26386287808418274
Validation loss: 1.5549607251280098

Epoch: 6| Step: 10
Training loss: 0.5388818383216858
Validation loss: 1.591141052143548

Epoch: 6| Step: 11
Training loss: 0.21367153525352478
Validation loss: 1.5769110610408168

Epoch: 6| Step: 12
Training loss: 0.1337963044643402
Validation loss: 1.5399893817081247

Epoch: 6| Step: 13
Training loss: 0.3697182834148407
Validation loss: 1.5128357615522159

Epoch: 352| Step: 0
Training loss: 0.17284977436065674
Validation loss: 1.5260137691292712

Epoch: 6| Step: 1
Training loss: 0.2620616853237152
Validation loss: 1.4730385272733626

Epoch: 6| Step: 2
Training loss: 0.2874419093132019
Validation loss: 1.5104083130436559

Epoch: 6| Step: 3
Training loss: 0.2631451487541199
Validation loss: 1.5080950798526886

Epoch: 6| Step: 4
Training loss: 0.23477907478809357
Validation loss: 1.4825354686347387

Epoch: 6| Step: 5
Training loss: 0.19459682703018188
Validation loss: 1.502352923475286

Epoch: 6| Step: 6
Training loss: 0.31589990854263306
Validation loss: 1.485444567536795

Epoch: 6| Step: 7
Training loss: 0.19624027609825134
Validation loss: 1.5280344332418134

Epoch: 6| Step: 8
Training loss: 0.11645422875881195
Validation loss: 1.5079805594618603

Epoch: 6| Step: 9
Training loss: 0.08983072638511658
Validation loss: 1.534003969161741

Epoch: 6| Step: 10
Training loss: 0.18819120526313782
Validation loss: 1.5901112223184237

Epoch: 6| Step: 11
Training loss: 0.31432801485061646
Validation loss: 1.6054218123036046

Epoch: 6| Step: 12
Training loss: 0.23938113451004028
Validation loss: 1.6033583443651918

Epoch: 6| Step: 13
Training loss: 0.41842716932296753
Validation loss: 1.5863620119710122

Epoch: 353| Step: 0
Training loss: 0.22505801916122437
Validation loss: 1.5785442936804988

Epoch: 6| Step: 1
Training loss: 0.16217610239982605
Validation loss: 1.558926647709262

Epoch: 6| Step: 2
Training loss: 0.13718196749687195
Validation loss: 1.5463635806114442

Epoch: 6| Step: 3
Training loss: 0.31362810730934143
Validation loss: 1.5344400559702227

Epoch: 6| Step: 4
Training loss: 0.4208330512046814
Validation loss: 1.5072524496304092

Epoch: 6| Step: 5
Training loss: 0.3422244191169739
Validation loss: 1.5257082959657073

Epoch: 6| Step: 6
Training loss: 0.18364131450653076
Validation loss: 1.495321580158767

Epoch: 6| Step: 7
Training loss: 0.28537315130233765
Validation loss: 1.5158812025541901

Epoch: 6| Step: 8
Training loss: 0.17065399885177612
Validation loss: 1.4851484183342225

Epoch: 6| Step: 9
Training loss: 0.21356233954429626
Validation loss: 1.5026177513983943

Epoch: 6| Step: 10
Training loss: 0.24173158407211304
Validation loss: 1.467867778193566

Epoch: 6| Step: 11
Training loss: 0.1664990484714508
Validation loss: 1.4925611185771164

Epoch: 6| Step: 12
Training loss: 0.1404809057712555
Validation loss: 1.4763239237569994

Epoch: 6| Step: 13
Training loss: 0.14663946628570557
Validation loss: 1.4819545220303278

Epoch: 354| Step: 0
Training loss: 0.26778629422187805
Validation loss: 1.524709149073529

Epoch: 6| Step: 1
Training loss: 0.2370331585407257
Validation loss: 1.4896950439740253

Epoch: 6| Step: 2
Training loss: 0.29528671503067017
Validation loss: 1.4756577835288098

Epoch: 6| Step: 3
Training loss: 0.2434668242931366
Validation loss: 1.44231213549132

Epoch: 6| Step: 4
Training loss: 0.22603870928287506
Validation loss: 1.434922642605279

Epoch: 6| Step: 5
Training loss: 0.1836850941181183
Validation loss: 1.4480817112871396

Epoch: 6| Step: 6
Training loss: 0.26923251152038574
Validation loss: 1.464455532771285

Epoch: 6| Step: 7
Training loss: 0.19221264123916626
Validation loss: 1.4651875752274708

Epoch: 6| Step: 8
Training loss: 0.25694411993026733
Validation loss: 1.4815444536106561

Epoch: 6| Step: 9
Training loss: 0.3211483657360077
Validation loss: 1.5049864733090965

Epoch: 6| Step: 10
Training loss: 0.15297868847846985
Validation loss: 1.5028379514653196

Epoch: 6| Step: 11
Training loss: 0.28630122542381287
Validation loss: 1.516125209869877

Epoch: 6| Step: 12
Training loss: 0.3273774981498718
Validation loss: 1.5121240090298396

Epoch: 6| Step: 13
Training loss: 0.3398453891277313
Validation loss: 1.510235604419503

Epoch: 355| Step: 0
Training loss: 0.12280169129371643
Validation loss: 1.4839380261718587

Epoch: 6| Step: 1
Training loss: 0.17473959922790527
Validation loss: 1.4700346069951211

Epoch: 6| Step: 2
Training loss: 0.2186296582221985
Validation loss: 1.4619460836533578

Epoch: 6| Step: 3
Training loss: 0.2421552836894989
Validation loss: 1.465444162327756

Epoch: 6| Step: 4
Training loss: 0.29522502422332764
Validation loss: 1.4970248335151262

Epoch: 6| Step: 5
Training loss: 0.21755899488925934
Validation loss: 1.4950868737313054

Epoch: 6| Step: 6
Training loss: 0.1241556853055954
Validation loss: 1.487970281672734

Epoch: 6| Step: 7
Training loss: 0.23393499851226807
Validation loss: 1.4929231129666811

Epoch: 6| Step: 8
Training loss: 0.19580936431884766
Validation loss: 1.5149128180678173

Epoch: 6| Step: 9
Training loss: 0.18469305336475372
Validation loss: 1.5091961929875035

Epoch: 6| Step: 10
Training loss: 0.2689538896083832
Validation loss: 1.5358940427021315

Epoch: 6| Step: 11
Training loss: 0.30938661098480225
Validation loss: 1.5207547667205974

Epoch: 6| Step: 12
Training loss: 0.22100135684013367
Validation loss: 1.5572050707314604

Epoch: 6| Step: 13
Training loss: 0.42793676257133484
Validation loss: 1.5297690540231683

Epoch: 356| Step: 0
Training loss: 0.19035875797271729
Validation loss: 1.5396054201228644

Epoch: 6| Step: 1
Training loss: 0.22007393836975098
Validation loss: 1.557293709888253

Epoch: 6| Step: 2
Training loss: 0.26525115966796875
Validation loss: 1.552246516750705

Epoch: 6| Step: 3
Training loss: 0.14332085847854614
Validation loss: 1.5040504073583951

Epoch: 6| Step: 4
Training loss: 0.09409791976213455
Validation loss: 1.532106126508405

Epoch: 6| Step: 5
Training loss: 0.12886595726013184
Validation loss: 1.5419339338938396

Epoch: 6| Step: 6
Training loss: 0.23545639216899872
Validation loss: 1.538536214059399

Epoch: 6| Step: 7
Training loss: 0.1565154641866684
Validation loss: 1.5321358583306754

Epoch: 6| Step: 8
Training loss: 0.14487165212631226
Validation loss: 1.5558482626433014

Epoch: 6| Step: 9
Training loss: 0.1449863314628601
Validation loss: 1.5362524088992868

Epoch: 6| Step: 10
Training loss: 0.3202303946018219
Validation loss: 1.551359498372642

Epoch: 6| Step: 11
Training loss: 0.29251518845558167
Validation loss: 1.5332384288951915

Epoch: 6| Step: 12
Training loss: 0.20978841185569763
Validation loss: 1.5246065214116087

Epoch: 6| Step: 13
Training loss: 0.1935369223356247
Validation loss: 1.5372381364145586

Epoch: 357| Step: 0
Training loss: 0.31149592995643616
Validation loss: 1.5051479416508828

Epoch: 6| Step: 1
Training loss: 0.26839208602905273
Validation loss: 1.4712758448816114

Epoch: 6| Step: 2
Training loss: 0.2177901268005371
Validation loss: 1.4786969602748912

Epoch: 6| Step: 3
Training loss: 0.1803363710641861
Validation loss: 1.4731847009351176

Epoch: 6| Step: 4
Training loss: 0.1304631233215332
Validation loss: 1.461005146785449

Epoch: 6| Step: 5
Training loss: 0.12198162078857422
Validation loss: 1.4850029227554158

Epoch: 6| Step: 6
Training loss: 0.23212474584579468
Validation loss: 1.476656093392321

Epoch: 6| Step: 7
Training loss: 0.19975903630256653
Validation loss: 1.4463035022058794

Epoch: 6| Step: 8
Training loss: 0.1535111367702484
Validation loss: 1.47821811322243

Epoch: 6| Step: 9
Training loss: 0.14703762531280518
Validation loss: 1.4774615956890969

Epoch: 6| Step: 10
Training loss: 0.29555588960647583
Validation loss: 1.4946895312237483

Epoch: 6| Step: 11
Training loss: 0.14443078637123108
Validation loss: 1.4775194320627438

Epoch: 6| Step: 12
Training loss: 0.20383581519126892
Validation loss: 1.510459384610576

Epoch: 6| Step: 13
Training loss: 0.257842481136322
Validation loss: 1.5040293470505746

Epoch: 358| Step: 0
Training loss: 0.16833221912384033
Validation loss: 1.4724781679850754

Epoch: 6| Step: 1
Training loss: 0.15964049100875854
Validation loss: 1.4868657512049521

Epoch: 6| Step: 2
Training loss: 0.1811865121126175
Validation loss: 1.4705796459669709

Epoch: 6| Step: 3
Training loss: 0.1899203509092331
Validation loss: 1.4767549396843038

Epoch: 6| Step: 4
Training loss: 0.2348056435585022
Validation loss: 1.4934663106036443

Epoch: 6| Step: 5
Training loss: 0.14785155653953552
Validation loss: 1.492327062032556

Epoch: 6| Step: 6
Training loss: 0.18592767417430878
Validation loss: 1.4804030964451451

Epoch: 6| Step: 7
Training loss: 0.19555963575839996
Validation loss: 1.4857755514883226

Epoch: 6| Step: 8
Training loss: 0.10390470176935196
Validation loss: 1.5001637487001316

Epoch: 6| Step: 9
Training loss: 0.23136352002620697
Validation loss: 1.4959246086817917

Epoch: 6| Step: 10
Training loss: 0.3066442012786865
Validation loss: 1.5225820823382306

Epoch: 6| Step: 11
Training loss: 0.1408199518918991
Validation loss: 1.5478913476390224

Epoch: 6| Step: 12
Training loss: 0.23657415807247162
Validation loss: 1.5629165851941673

Epoch: 6| Step: 13
Training loss: 0.33083727955818176
Validation loss: 1.5301161196924025

Epoch: 359| Step: 0
Training loss: 0.31903767585754395
Validation loss: 1.50095352818889

Epoch: 6| Step: 1
Training loss: 0.21983632445335388
Validation loss: 1.4930224521185762

Epoch: 6| Step: 2
Training loss: 0.1589512974023819
Validation loss: 1.4962538262849212

Epoch: 6| Step: 3
Training loss: 0.2384563833475113
Validation loss: 1.5055974350180676

Epoch: 6| Step: 4
Training loss: 0.10814061760902405
Validation loss: 1.4982064193294895

Epoch: 6| Step: 5
Training loss: 0.23877361416816711
Validation loss: 1.5163219551886282

Epoch: 6| Step: 6
Training loss: 0.2689206004142761
Validation loss: 1.4846873706386936

Epoch: 6| Step: 7
Training loss: 0.2494201511144638
Validation loss: 1.4668343515806301

Epoch: 6| Step: 8
Training loss: 0.1064424216747284
Validation loss: 1.5092368446370608

Epoch: 6| Step: 9
Training loss: 0.22700253129005432
Validation loss: 1.466225427325054

Epoch: 6| Step: 10
Training loss: 0.21048220992088318
Validation loss: 1.4808101628416328

Epoch: 6| Step: 11
Training loss: 0.14713916182518005
Validation loss: 1.499957069273918

Epoch: 6| Step: 12
Training loss: 0.21505603194236755
Validation loss: 1.5003062307193715

Epoch: 6| Step: 13
Training loss: 0.2696199417114258
Validation loss: 1.5240461723778838

Epoch: 360| Step: 0
Training loss: 0.16506274044513702
Validation loss: 1.503821789577443

Epoch: 6| Step: 1
Training loss: 0.18536612391471863
Validation loss: 1.4980585511012743

Epoch: 6| Step: 2
Training loss: 0.26671209931373596
Validation loss: 1.4924317764979538

Epoch: 6| Step: 3
Training loss: 0.1806950718164444
Validation loss: 1.5248839739830262

Epoch: 6| Step: 4
Training loss: 0.2815309166908264
Validation loss: 1.5240585022075201

Epoch: 6| Step: 5
Training loss: 0.38542085886001587
Validation loss: 1.5322028078058714

Epoch: 6| Step: 6
Training loss: 0.20235206186771393
Validation loss: 1.4997179482572822

Epoch: 6| Step: 7
Training loss: 0.23730407655239105
Validation loss: 1.5042708381529777

Epoch: 6| Step: 8
Training loss: 0.329105943441391
Validation loss: 1.4908826197347333

Epoch: 6| Step: 9
Training loss: 0.2803220748901367
Validation loss: 1.4926471428204608

Epoch: 6| Step: 10
Training loss: 0.20088082551956177
Validation loss: 1.5101682293799616

Epoch: 6| Step: 11
Training loss: 0.20212611556053162
Validation loss: 1.43690235640413

Epoch: 6| Step: 12
Training loss: 0.11648955941200256
Validation loss: 1.468176418735135

Epoch: 6| Step: 13
Training loss: 0.26688891649246216
Validation loss: 1.4355857462011359

Epoch: 361| Step: 0
Training loss: 0.11602790653705597
Validation loss: 1.4775969930874404

Epoch: 6| Step: 1
Training loss: 0.30224472284317017
Validation loss: 1.4747232262806227

Epoch: 6| Step: 2
Training loss: 0.21454894542694092
Validation loss: 1.4866478648237003

Epoch: 6| Step: 3
Training loss: 0.29295819997787476
Validation loss: 1.4685321456642562

Epoch: 6| Step: 4
Training loss: 0.363750159740448
Validation loss: 1.4880723722519413

Epoch: 6| Step: 5
Training loss: 0.24151182174682617
Validation loss: 1.4677275611508278

Epoch: 6| Step: 6
Training loss: 0.21204520761966705
Validation loss: 1.4785288149310696

Epoch: 6| Step: 7
Training loss: 0.12359383702278137
Validation loss: 1.5037054784836308

Epoch: 6| Step: 8
Training loss: 0.17235910892486572
Validation loss: 1.5172575801931403

Epoch: 6| Step: 9
Training loss: 0.2470214068889618
Validation loss: 1.5222536786910026

Epoch: 6| Step: 10
Training loss: 0.14554429054260254
Validation loss: 1.5553964184176536

Epoch: 6| Step: 11
Training loss: 0.290397971868515
Validation loss: 1.5533796818025651

Epoch: 6| Step: 12
Training loss: 0.2130923867225647
Validation loss: 1.554848099908521

Epoch: 6| Step: 13
Training loss: 0.1615823358297348
Validation loss: 1.5381510616630636

Epoch: 362| Step: 0
Training loss: 0.16597045958042145
Validation loss: 1.514074807525963

Epoch: 6| Step: 1
Training loss: 0.20662130415439606
Validation loss: 1.553580081591042

Epoch: 6| Step: 2
Training loss: 0.23224440217018127
Validation loss: 1.553705027026515

Epoch: 6| Step: 3
Training loss: 0.31062230467796326
Validation loss: 1.5590437586589525

Epoch: 6| Step: 4
Training loss: 0.37583127617836
Validation loss: 1.5846261285966443

Epoch: 6| Step: 5
Training loss: 0.2064608931541443
Validation loss: 1.5755187067934262

Epoch: 6| Step: 6
Training loss: 0.26152604818344116
Validation loss: 1.5985004748067548

Epoch: 6| Step: 7
Training loss: 0.30559200048446655
Validation loss: 1.6042442860141877

Epoch: 6| Step: 8
Training loss: 0.22011283040046692
Validation loss: 1.5483491792473743

Epoch: 6| Step: 9
Training loss: 0.2047455906867981
Validation loss: 1.5341460499712216

Epoch: 6| Step: 10
Training loss: 0.29181262850761414
Validation loss: 1.5112110953177176

Epoch: 6| Step: 11
Training loss: 0.32258641719818115
Validation loss: 1.4708119771813835

Epoch: 6| Step: 12
Training loss: 0.2910413146018982
Validation loss: 1.456738466857582

Epoch: 6| Step: 13
Training loss: 0.22211101651191711
Validation loss: 1.4510709508772819

Epoch: 363| Step: 0
Training loss: 0.1990354359149933
Validation loss: 1.4388345678647358

Epoch: 6| Step: 1
Training loss: 0.32831159234046936
Validation loss: 1.4519308292737572

Epoch: 6| Step: 2
Training loss: 0.14258819818496704
Validation loss: 1.4892381698854509

Epoch: 6| Step: 3
Training loss: 0.15738996863365173
Validation loss: 1.4887960982579056

Epoch: 6| Step: 4
Training loss: 0.20183703303337097
Validation loss: 1.4873448200123285

Epoch: 6| Step: 5
Training loss: 0.27750688791275024
Validation loss: 1.5272312600125548

Epoch: 6| Step: 6
Training loss: 0.26505380868911743
Validation loss: 1.5208428329037083

Epoch: 6| Step: 7
Training loss: 0.3432081341743469
Validation loss: 1.5294972747884772

Epoch: 6| Step: 8
Training loss: 0.18921689689159393
Validation loss: 1.518596879897579

Epoch: 6| Step: 9
Training loss: 0.18517544865608215
Validation loss: 1.4889563629704137

Epoch: 6| Step: 10
Training loss: 0.28198498487472534
Validation loss: 1.4671852845017628

Epoch: 6| Step: 11
Training loss: 0.19648775458335876
Validation loss: 1.4367213749116468

Epoch: 6| Step: 12
Training loss: 0.30287501215934753
Validation loss: 1.4366938260293776

Epoch: 6| Step: 13
Training loss: 0.1769208312034607
Validation loss: 1.3962709685807586

Epoch: 364| Step: 0
Training loss: 0.33185088634490967
Validation loss: 1.4275168949557888

Epoch: 6| Step: 1
Training loss: 0.45655447244644165
Validation loss: 1.4547173912807176

Epoch: 6| Step: 2
Training loss: 0.15298008918762207
Validation loss: 1.4797789537778465

Epoch: 6| Step: 3
Training loss: 0.18476219475269318
Validation loss: 1.4733004807144083

Epoch: 6| Step: 4
Training loss: 0.3176111578941345
Validation loss: 1.4824877041642384

Epoch: 6| Step: 5
Training loss: 0.2722736895084381
Validation loss: 1.4967143330522763

Epoch: 6| Step: 6
Training loss: 0.12093901634216309
Validation loss: 1.465958183811557

Epoch: 6| Step: 7
Training loss: 0.18815970420837402
Validation loss: 1.4832259403761996

Epoch: 6| Step: 8
Training loss: 0.21072937548160553
Validation loss: 1.5225773229393909

Epoch: 6| Step: 9
Training loss: 0.2555141746997833
Validation loss: 1.538376445411354

Epoch: 6| Step: 10
Training loss: 0.19186852872371674
Validation loss: 1.508863801597267

Epoch: 6| Step: 11
Training loss: 0.14057417213916779
Validation loss: 1.48799640581172

Epoch: 6| Step: 12
Training loss: 0.1551855206489563
Validation loss: 1.4498058660056001

Epoch: 6| Step: 13
Training loss: 0.332362562417984
Validation loss: 1.4428671944525935

Epoch: 365| Step: 0
Training loss: 0.2675718069076538
Validation loss: 1.4500761083377305

Epoch: 6| Step: 1
Training loss: 0.19643890857696533
Validation loss: 1.4609273313194193

Epoch: 6| Step: 2
Training loss: 0.2725737690925598
Validation loss: 1.481135219656011

Epoch: 6| Step: 3
Training loss: 0.1707575023174286
Validation loss: 1.503678560256958

Epoch: 6| Step: 4
Training loss: 0.2577214241027832
Validation loss: 1.490243257373892

Epoch: 6| Step: 5
Training loss: 0.23055002093315125
Validation loss: 1.5148357447757517

Epoch: 6| Step: 6
Training loss: 0.17705024778842926
Validation loss: 1.5137626035239107

Epoch: 6| Step: 7
Training loss: 0.2056748867034912
Validation loss: 1.5011854966481526

Epoch: 6| Step: 8
Training loss: 0.2039957344532013
Validation loss: 1.516789432494871

Epoch: 6| Step: 9
Training loss: 0.17725668847560883
Validation loss: 1.5061395873305619

Epoch: 6| Step: 10
Training loss: 0.26010242104530334
Validation loss: 1.4949116835030176

Epoch: 6| Step: 11
Training loss: 0.19992196559906006
Validation loss: 1.4852740456981044

Epoch: 6| Step: 12
Training loss: 0.24928916990756989
Validation loss: 1.4749498431400587

Epoch: 6| Step: 13
Training loss: 0.1168150082230568
Validation loss: 1.4864656912383212

Epoch: 366| Step: 0
Training loss: 0.2920045852661133
Validation loss: 1.4695607385327738

Epoch: 6| Step: 1
Training loss: 0.1496146321296692
Validation loss: 1.4656885862350464

Epoch: 6| Step: 2
Training loss: 0.19052273035049438
Validation loss: 1.4769036731412333

Epoch: 6| Step: 3
Training loss: 0.1422843337059021
Validation loss: 1.4740911901638072

Epoch: 6| Step: 4
Training loss: 0.15974074602127075
Validation loss: 1.4625251113727529

Epoch: 6| Step: 5
Training loss: 0.15151719748973846
Validation loss: 1.4920885268078055

Epoch: 6| Step: 6
Training loss: 0.17436686158180237
Validation loss: 1.471251812032474

Epoch: 6| Step: 7
Training loss: 0.14899678528308868
Validation loss: 1.501159974323806

Epoch: 6| Step: 8
Training loss: 0.4746752679347992
Validation loss: 1.5091073506621904

Epoch: 6| Step: 9
Training loss: 0.16389721632003784
Validation loss: 1.506336494158673

Epoch: 6| Step: 10
Training loss: 0.2222670018672943
Validation loss: 1.507206501499299

Epoch: 6| Step: 11
Training loss: 0.22725075483322144
Validation loss: 1.4942087781044744

Epoch: 6| Step: 12
Training loss: 0.308047890663147
Validation loss: 1.4993416852848505

Epoch: 6| Step: 13
Training loss: 0.2624357044696808
Validation loss: 1.4941614161255539

Epoch: 367| Step: 0
Training loss: 0.25512343645095825
Validation loss: 1.4703083358785158

Epoch: 6| Step: 1
Training loss: 0.1715899407863617
Validation loss: 1.4790441413079538

Epoch: 6| Step: 2
Training loss: 0.3302731513977051
Validation loss: 1.4231064037610126

Epoch: 6| Step: 3
Training loss: 0.15428481996059418
Validation loss: 1.4234986535964473

Epoch: 6| Step: 4
Training loss: 0.16682341694831848
Validation loss: 1.420427660788259

Epoch: 6| Step: 5
Training loss: 0.10674755275249481
Validation loss: 1.4535515423743957

Epoch: 6| Step: 6
Training loss: 0.26481905579566956
Validation loss: 1.4488312377724597

Epoch: 6| Step: 7
Training loss: 0.22504565119743347
Validation loss: 1.4670281935763616

Epoch: 6| Step: 8
Training loss: 0.2640415132045746
Validation loss: 1.4879114871383996

Epoch: 6| Step: 9
Training loss: 0.18048235774040222
Validation loss: 1.476184421329088

Epoch: 6| Step: 10
Training loss: 0.2116526961326599
Validation loss: 1.432822645351451

Epoch: 6| Step: 11
Training loss: 0.17123569548130035
Validation loss: 1.4547961879802007

Epoch: 6| Step: 12
Training loss: 0.3080887794494629
Validation loss: 1.4317404775209324

Epoch: 6| Step: 13
Training loss: 0.0764889195561409
Validation loss: 1.4689726803892402

Epoch: 368| Step: 0
Training loss: 0.2653964161872864
Validation loss: 1.4835020008907522

Epoch: 6| Step: 1
Training loss: 0.15423721075057983
Validation loss: 1.465334778190941

Epoch: 6| Step: 2
Training loss: 0.1179458498954773
Validation loss: 1.4936143095775316

Epoch: 6| Step: 3
Training loss: 0.21813984215259552
Validation loss: 1.4873147395349318

Epoch: 6| Step: 4
Training loss: 0.29956984519958496
Validation loss: 1.4882745768434258

Epoch: 6| Step: 5
Training loss: 0.26221010088920593
Validation loss: 1.4642269431903798

Epoch: 6| Step: 6
Training loss: 0.2074999213218689
Validation loss: 1.4621997725579046

Epoch: 6| Step: 7
Training loss: 0.1096351146697998
Validation loss: 1.4296381204358992

Epoch: 6| Step: 8
Training loss: 0.18378719687461853
Validation loss: 1.4332389780270156

Epoch: 6| Step: 9
Training loss: 0.28118836879730225
Validation loss: 1.4201285685262373

Epoch: 6| Step: 10
Training loss: 0.2016831785440445
Validation loss: 1.4376700603833763

Epoch: 6| Step: 11
Training loss: 0.19164323806762695
Validation loss: 1.4332112842990505

Epoch: 6| Step: 12
Training loss: 0.21812626719474792
Validation loss: 1.4328664246425833

Epoch: 6| Step: 13
Training loss: 0.22504840791225433
Validation loss: 1.4504247429550334

Epoch: 369| Step: 0
Training loss: 0.18845036625862122
Validation loss: 1.4721571809502059

Epoch: 6| Step: 1
Training loss: 0.258248507976532
Validation loss: 1.4955624482964958

Epoch: 6| Step: 2
Training loss: 0.28915685415267944
Validation loss: 1.480069894944468

Epoch: 6| Step: 3
Training loss: 0.19368866086006165
Validation loss: 1.4974406444898216

Epoch: 6| Step: 4
Training loss: 0.13726156949996948
Validation loss: 1.515166477490497

Epoch: 6| Step: 5
Training loss: 0.19298610091209412
Validation loss: 1.521303686403459

Epoch: 6| Step: 6
Training loss: 0.1347772628068924
Validation loss: 1.5065594142483127

Epoch: 6| Step: 7
Training loss: 0.41594308614730835
Validation loss: 1.5232370489387101

Epoch: 6| Step: 8
Training loss: 0.2865000367164612
Validation loss: 1.539830243715676

Epoch: 6| Step: 9
Training loss: 0.1975039541721344
Validation loss: 1.4967333450112292

Epoch: 6| Step: 10
Training loss: 0.1687484085559845
Validation loss: 1.5039230892735143

Epoch: 6| Step: 11
Training loss: 0.1617758423089981
Validation loss: 1.4906614006206553

Epoch: 6| Step: 12
Training loss: 0.20794494450092316
Validation loss: 1.4644791028832878

Epoch: 6| Step: 13
Training loss: 0.09574730694293976
Validation loss: 1.4825964461090744

Epoch: 370| Step: 0
Training loss: 0.20013466477394104
Validation loss: 1.4673531311814503

Epoch: 6| Step: 1
Training loss: 0.14330413937568665
Validation loss: 1.4893005028847726

Epoch: 6| Step: 2
Training loss: 0.2260870635509491
Validation loss: 1.4618577931516914

Epoch: 6| Step: 3
Training loss: 0.28396105766296387
Validation loss: 1.4711570150108748

Epoch: 6| Step: 4
Training loss: 0.26527324318885803
Validation loss: 1.4683812818219584

Epoch: 6| Step: 5
Training loss: 0.11398488283157349
Validation loss: 1.4697883539302374

Epoch: 6| Step: 6
Training loss: 0.325124055147171
Validation loss: 1.4738546917515416

Epoch: 6| Step: 7
Training loss: 0.19563624262809753
Validation loss: 1.445786291553128

Epoch: 6| Step: 8
Training loss: 0.0873754471540451
Validation loss: 1.4433425908447595

Epoch: 6| Step: 9
Training loss: 0.1503271758556366
Validation loss: 1.4330004210113196

Epoch: 6| Step: 10
Training loss: 0.20683491230010986
Validation loss: 1.4415781574864541

Epoch: 6| Step: 11
Training loss: 0.3334868550300598
Validation loss: 1.4636808672258932

Epoch: 6| Step: 12
Training loss: 0.0791652500629425
Validation loss: 1.4586398191349481

Epoch: 6| Step: 13
Training loss: 0.12202266603708267
Validation loss: 1.4581870584077732

Epoch: 371| Step: 0
Training loss: 0.15263740718364716
Validation loss: 1.454523455071193

Epoch: 6| Step: 1
Training loss: 0.1526889204978943
Validation loss: 1.4508052384981545

Epoch: 6| Step: 2
Training loss: 0.2470037192106247
Validation loss: 1.4383204137125323

Epoch: 6| Step: 3
Training loss: 0.1860378086566925
Validation loss: 1.4455083070262786

Epoch: 6| Step: 4
Training loss: 0.16538307070732117
Validation loss: 1.4270019787614063

Epoch: 6| Step: 5
Training loss: 0.16659100353717804
Validation loss: 1.4602279560540312

Epoch: 6| Step: 6
Training loss: 0.15146304666996002
Validation loss: 1.439512010543577

Epoch: 6| Step: 7
Training loss: 0.14132077991962433
Validation loss: 1.4654314915339153

Epoch: 6| Step: 8
Training loss: 0.23359735310077667
Validation loss: 1.500259949955889

Epoch: 6| Step: 9
Training loss: 0.22598214447498322
Validation loss: 1.4771394280977146

Epoch: 6| Step: 10
Training loss: 0.20283091068267822
Validation loss: 1.4852229036310667

Epoch: 6| Step: 11
Training loss: 0.1778046190738678
Validation loss: 1.4818401900670861

Epoch: 6| Step: 12
Training loss: 0.1701985001564026
Validation loss: 1.4655477628912976

Epoch: 6| Step: 13
Training loss: 0.19652387499809265
Validation loss: 1.4564761551477576

Epoch: 372| Step: 0
Training loss: 0.2661965489387512
Validation loss: 1.4867799794802101

Epoch: 6| Step: 1
Training loss: 0.17481540143489838
Validation loss: 1.518068337953219

Epoch: 6| Step: 2
Training loss: 0.2067255824804306
Validation loss: 1.5178777601129265

Epoch: 6| Step: 3
Training loss: 0.21758154034614563
Validation loss: 1.5105519243465957

Epoch: 6| Step: 4
Training loss: 0.2783575654029846
Validation loss: 1.5399881460333382

Epoch: 6| Step: 5
Training loss: 0.12534397840499878
Validation loss: 1.5407854472437212

Epoch: 6| Step: 6
Training loss: 0.1730365753173828
Validation loss: 1.5305613651070544

Epoch: 6| Step: 7
Training loss: 0.2269303947687149
Validation loss: 1.5254439948707499

Epoch: 6| Step: 8
Training loss: 0.13159877061843872
Validation loss: 1.4921874820545156

Epoch: 6| Step: 9
Training loss: 0.2091296911239624
Validation loss: 1.4963816654297613

Epoch: 6| Step: 10
Training loss: 0.09983754903078079
Validation loss: 1.5168296419164187

Epoch: 6| Step: 11
Training loss: 0.2487073838710785
Validation loss: 1.5073341451665407

Epoch: 6| Step: 12
Training loss: 0.1236090436577797
Validation loss: 1.4931565933330084

Epoch: 6| Step: 13
Training loss: 0.2046942412853241
Validation loss: 1.4715249358966787

Epoch: 373| Step: 0
Training loss: 0.15418532490730286
Validation loss: 1.5095471855132812

Epoch: 6| Step: 1
Training loss: 0.14999935030937195
Validation loss: 1.4933982331265685

Epoch: 6| Step: 2
Training loss: 0.22275608777999878
Validation loss: 1.513687773417401

Epoch: 6| Step: 3
Training loss: 0.17420747876167297
Validation loss: 1.5624360346025037

Epoch: 6| Step: 4
Training loss: 0.3172924816608429
Validation loss: 1.524867227000575

Epoch: 6| Step: 5
Training loss: 0.21612648665905
Validation loss: 1.5075462838654876

Epoch: 6| Step: 6
Training loss: 0.17416691780090332
Validation loss: 1.4854494474267448

Epoch: 6| Step: 7
Training loss: 0.16413754224777222
Validation loss: 1.4499547481536865

Epoch: 6| Step: 8
Training loss: 0.18526549637317657
Validation loss: 1.4400441505575692

Epoch: 6| Step: 9
Training loss: 0.2437509298324585
Validation loss: 1.45787723090059

Epoch: 6| Step: 10
Training loss: 0.38113880157470703
Validation loss: 1.46049024469109

Epoch: 6| Step: 11
Training loss: 0.3139277696609497
Validation loss: 1.4581318324612034

Epoch: 6| Step: 12
Training loss: 0.23192541301250458
Validation loss: 1.462174577097739

Epoch: 6| Step: 13
Training loss: 0.1589396446943283
Validation loss: 1.4543096147557741

Epoch: 374| Step: 0
Training loss: 0.28771844506263733
Validation loss: 1.4982682440870552

Epoch: 6| Step: 1
Training loss: 0.29021555185317993
Validation loss: 1.531187690073444

Epoch: 6| Step: 2
Training loss: 0.24674078822135925
Validation loss: 1.5408393708608483

Epoch: 6| Step: 3
Training loss: 0.25121575593948364
Validation loss: 1.5025133035516227

Epoch: 6| Step: 4
Training loss: 0.12401292473077774
Validation loss: 1.493389089902242

Epoch: 6| Step: 5
Training loss: 0.193459615111351
Validation loss: 1.5008547318878995

Epoch: 6| Step: 6
Training loss: 0.24569743871688843
Validation loss: 1.5331156061541649

Epoch: 6| Step: 7
Training loss: 0.4111495316028595
Validation loss: 1.5889926084908106

Epoch: 6| Step: 8
Training loss: 0.6022339463233948
Validation loss: 1.5894792464471632

Epoch: 6| Step: 9
Training loss: 0.5213544368743896
Validation loss: 1.5423106980580155

Epoch: 6| Step: 10
Training loss: 0.1968218982219696
Validation loss: 1.5153063010143977

Epoch: 6| Step: 11
Training loss: 0.24766424298286438
Validation loss: 1.47860489865785

Epoch: 6| Step: 12
Training loss: 0.22017481923103333
Validation loss: 1.472866391622892

Epoch: 6| Step: 13
Training loss: 0.1470358967781067
Validation loss: 1.5124001118444628

Epoch: 375| Step: 0
Training loss: 0.28737202286720276
Validation loss: 1.5134785482960362

Epoch: 6| Step: 1
Training loss: 0.34409672021865845
Validation loss: 1.5281606784430883

Epoch: 6| Step: 2
Training loss: 0.33201712369918823
Validation loss: 1.5126530060204126

Epoch: 6| Step: 3
Training loss: 0.24006929993629456
Validation loss: 1.5077035132274832

Epoch: 6| Step: 4
Training loss: 0.1844518780708313
Validation loss: 1.4845229707738405

Epoch: 6| Step: 5
Training loss: 0.29232242703437805
Validation loss: 1.487840666565844

Epoch: 6| Step: 6
Training loss: 0.21093669533729553
Validation loss: 1.4870768247112152

Epoch: 6| Step: 7
Training loss: 0.30281493067741394
Validation loss: 1.5186323978567635

Epoch: 6| Step: 8
Training loss: 0.269471675157547
Validation loss: 1.498246572350943

Epoch: 6| Step: 9
Training loss: 0.25095805525779724
Validation loss: 1.501279789914367

Epoch: 6| Step: 10
Training loss: 0.16044753789901733
Validation loss: 1.4905018024547125

Epoch: 6| Step: 11
Training loss: 0.16171912848949432
Validation loss: 1.5138274303046606

Epoch: 6| Step: 12
Training loss: 0.35378384590148926
Validation loss: 1.5225374339729227

Epoch: 6| Step: 13
Training loss: 0.31269392371177673
Validation loss: 1.541065997974847

Epoch: 376| Step: 0
Training loss: 0.28481578826904297
Validation loss: 1.5481884428249892

Epoch: 6| Step: 1
Training loss: 0.19593727588653564
Validation loss: 1.5518831873452792

Epoch: 6| Step: 2
Training loss: 0.21518798172473907
Validation loss: 1.5301372851094892

Epoch: 6| Step: 3
Training loss: 0.18600156903266907
Validation loss: 1.5432118869596911

Epoch: 6| Step: 4
Training loss: 0.24975544214248657
Validation loss: 1.5372700409222675

Epoch: 6| Step: 5
Training loss: 0.2920773923397064
Validation loss: 1.4997056068912629

Epoch: 6| Step: 6
Training loss: 0.157317653298378
Validation loss: 1.4984871687427643

Epoch: 6| Step: 7
Training loss: 0.14896300435066223
Validation loss: 1.4648585396428262

Epoch: 6| Step: 8
Training loss: 0.2103051245212555
Validation loss: 1.4592533150026876

Epoch: 6| Step: 9
Training loss: 0.19142580032348633
Validation loss: 1.4441620008919829

Epoch: 6| Step: 10
Training loss: 0.2831380367279053
Validation loss: 1.4303355652798888

Epoch: 6| Step: 11
Training loss: 0.14740802347660065
Validation loss: 1.3944578491231447

Epoch: 6| Step: 12
Training loss: 0.094630166888237
Validation loss: 1.3987970800809963

Epoch: 6| Step: 13
Training loss: 0.19530317187309265
Validation loss: 1.4250249837034492

Epoch: 377| Step: 0
Training loss: 0.27755266427993774
Validation loss: 1.424150590614606

Epoch: 6| Step: 1
Training loss: 0.14809128642082214
Validation loss: 1.4333425914087603

Epoch: 6| Step: 2
Training loss: 0.19894403219223022
Validation loss: 1.4327696689995386

Epoch: 6| Step: 3
Training loss: 0.17971161007881165
Validation loss: 1.444965342039703

Epoch: 6| Step: 4
Training loss: 0.19871589541435242
Validation loss: 1.4105999008301766

Epoch: 6| Step: 5
Training loss: 0.2817612886428833
Validation loss: 1.3898292177466935

Epoch: 6| Step: 6
Training loss: 0.19461989402770996
Validation loss: 1.3876522202645578

Epoch: 6| Step: 7
Training loss: 0.18640479445457458
Validation loss: 1.3937772755981774

Epoch: 6| Step: 8
Training loss: 0.2540706992149353
Validation loss: 1.4026319775530087

Epoch: 6| Step: 9
Training loss: 0.09655189514160156
Validation loss: 1.414977922234484

Epoch: 6| Step: 10
Training loss: 0.22184062004089355
Validation loss: 1.4166769776293027

Epoch: 6| Step: 11
Training loss: 0.2572956681251526
Validation loss: 1.4230137819884925

Epoch: 6| Step: 12
Training loss: 0.19352787733078003
Validation loss: 1.4434547590953049

Epoch: 6| Step: 13
Training loss: 0.23033183813095093
Validation loss: 1.4376791331075853

Epoch: 378| Step: 0
Training loss: 0.175424724817276
Validation loss: 1.4461234564422278

Epoch: 6| Step: 1
Training loss: 0.11790838837623596
Validation loss: 1.4646775696867256

Epoch: 6| Step: 2
Training loss: 0.12000258266925812
Validation loss: 1.454076837467891

Epoch: 6| Step: 3
Training loss: 0.19481638073921204
Validation loss: 1.4510776291611374

Epoch: 6| Step: 4
Training loss: 0.16672983765602112
Validation loss: 1.4570819665026922

Epoch: 6| Step: 5
Training loss: 0.14944902062416077
Validation loss: 1.4516587026657597

Epoch: 6| Step: 6
Training loss: 0.2504473328590393
Validation loss: 1.4570315025186027

Epoch: 6| Step: 7
Training loss: 0.18816548585891724
Validation loss: 1.4391834838415987

Epoch: 6| Step: 8
Training loss: 0.11092444509267807
Validation loss: 1.4307319015584967

Epoch: 6| Step: 9
Training loss: 0.21810901165008545
Validation loss: 1.433430640928207

Epoch: 6| Step: 10
Training loss: 0.323576956987381
Validation loss: 1.448590402962059

Epoch: 6| Step: 11
Training loss: 0.2751810550689697
Validation loss: 1.452635822757598

Epoch: 6| Step: 12
Training loss: 0.2565695345401764
Validation loss: 1.4626546034248926

Epoch: 6| Step: 13
Training loss: 0.29869624972343445
Validation loss: 1.4723098239591044

Epoch: 379| Step: 0
Training loss: 0.19864782691001892
Validation loss: 1.485140964549075

Epoch: 6| Step: 1
Training loss: 0.20595884323120117
Validation loss: 1.5040192206700642

Epoch: 6| Step: 2
Training loss: 0.15834787487983704
Validation loss: 1.534802899565748

Epoch: 6| Step: 3
Training loss: 0.3155728876590729
Validation loss: 1.5109534135428808

Epoch: 6| Step: 4
Training loss: 0.22642144560813904
Validation loss: 1.4933343869383617

Epoch: 6| Step: 5
Training loss: 0.23050446808338165
Validation loss: 1.4825363191225196

Epoch: 6| Step: 6
Training loss: 0.16691181063652039
Validation loss: 1.4531550484318887

Epoch: 6| Step: 7
Training loss: 0.15445727109909058
Validation loss: 1.443365777692487

Epoch: 6| Step: 8
Training loss: 0.1915959268808365
Validation loss: 1.437980245518428

Epoch: 6| Step: 9
Training loss: 0.14045856893062592
Validation loss: 1.4702991644541423

Epoch: 6| Step: 10
Training loss: 0.16781799495220184
Validation loss: 1.4482464719844121

Epoch: 6| Step: 11
Training loss: 0.30740851163864136
Validation loss: 1.46077734808768

Epoch: 6| Step: 12
Training loss: 0.1828521490097046
Validation loss: 1.4577009242068055

Epoch: 6| Step: 13
Training loss: 0.20176845788955688
Validation loss: 1.4189955739564792

Epoch: 380| Step: 0
Training loss: 0.19454485177993774
Validation loss: 1.4478726143478065

Epoch: 6| Step: 1
Training loss: 0.18134891986846924
Validation loss: 1.4753447066071212

Epoch: 6| Step: 2
Training loss: 0.18195459246635437
Validation loss: 1.4853406695909397

Epoch: 6| Step: 3
Training loss: 0.17730677127838135
Validation loss: 1.5017051965959611

Epoch: 6| Step: 4
Training loss: 0.27282658219337463
Validation loss: 1.5061917586993145

Epoch: 6| Step: 5
Training loss: 0.13291484117507935
Validation loss: 1.4713830870966758

Epoch: 6| Step: 6
Training loss: 0.18348152935504913
Validation loss: 1.4478013259108349

Epoch: 6| Step: 7
Training loss: 0.11567126214504242
Validation loss: 1.4399766793815039

Epoch: 6| Step: 8
Training loss: 0.11155969649553299
Validation loss: 1.4294347968152774

Epoch: 6| Step: 9
Training loss: 0.14768898487091064
Validation loss: 1.4390892956846504

Epoch: 6| Step: 10
Training loss: 0.10550475120544434
Validation loss: 1.4395483770678121

Epoch: 6| Step: 11
Training loss: 0.16942112147808075
Validation loss: 1.4404845032640683

Epoch: 6| Step: 12
Training loss: 0.23179984092712402
Validation loss: 1.4623905381848734

Epoch: 6| Step: 13
Training loss: 0.2768799960613251
Validation loss: 1.4642710249911073

Epoch: 381| Step: 0
Training loss: 0.16538988053798676
Validation loss: 1.5050046315757177

Epoch: 6| Step: 1
Training loss: 0.11802691966295242
Validation loss: 1.5429810836750975

Epoch: 6| Step: 2
Training loss: 0.13670280575752258
Validation loss: 1.545134690500075

Epoch: 6| Step: 3
Training loss: 0.30225566029548645
Validation loss: 1.5486581056348738

Epoch: 6| Step: 4
Training loss: 0.24974000453948975
Validation loss: 1.5125971378818635

Epoch: 6| Step: 5
Training loss: 0.08488567918539047
Validation loss: 1.4822696191008373

Epoch: 6| Step: 6
Training loss: 0.18440653383731842
Validation loss: 1.4912792815957019

Epoch: 6| Step: 7
Training loss: 0.13577865064144135
Validation loss: 1.457706835962111

Epoch: 6| Step: 8
Training loss: 0.1073450967669487
Validation loss: 1.4458223414677445

Epoch: 6| Step: 9
Training loss: 0.2087126076221466
Validation loss: 1.4690402169381418

Epoch: 6| Step: 10
Training loss: 0.2531454265117645
Validation loss: 1.4524183298951836

Epoch: 6| Step: 11
Training loss: 0.2594342529773712
Validation loss: 1.4742540569715603

Epoch: 6| Step: 12
Training loss: 0.21123504638671875
Validation loss: 1.4601154122301327

Epoch: 6| Step: 13
Training loss: 0.21075458824634552
Validation loss: 1.4652846372255715

Epoch: 382| Step: 0
Training loss: 0.15498390793800354
Validation loss: 1.4685244303877636

Epoch: 6| Step: 1
Training loss: 0.18476200103759766
Validation loss: 1.4851648333252117

Epoch: 6| Step: 2
Training loss: 0.2064702808856964
Validation loss: 1.50732603380757

Epoch: 6| Step: 3
Training loss: 0.2598716914653778
Validation loss: 1.4931057274982493

Epoch: 6| Step: 4
Training loss: 0.15375858545303345
Validation loss: 1.50015281028645

Epoch: 6| Step: 5
Training loss: 0.11943633109331131
Validation loss: 1.4963825876994798

Epoch: 6| Step: 6
Training loss: 0.15339671075344086
Validation loss: 1.4921747574242212

Epoch: 6| Step: 7
Training loss: 0.10434629023075104
Validation loss: 1.4963362460495324

Epoch: 6| Step: 8
Training loss: 0.13826993107795715
Validation loss: 1.4881443592809862

Epoch: 6| Step: 9
Training loss: 0.32001781463623047
Validation loss: 1.485119438940479

Epoch: 6| Step: 10
Training loss: 0.19503194093704224
Validation loss: 1.4967087186792845

Epoch: 6| Step: 11
Training loss: 0.13296325504779816
Validation loss: 1.4702438897984003

Epoch: 6| Step: 12
Training loss: 0.13769519329071045
Validation loss: 1.4911076125278269

Epoch: 6| Step: 13
Training loss: 0.24444617331027985
Validation loss: 1.5055981771920317

Epoch: 383| Step: 0
Training loss: 0.13526810705661774
Validation loss: 1.4596379187799269

Epoch: 6| Step: 1
Training loss: 0.16215454041957855
Validation loss: 1.4826521444064316

Epoch: 6| Step: 2
Training loss: 0.11535361409187317
Validation loss: 1.4849897815335182

Epoch: 6| Step: 3
Training loss: 0.0982610359787941
Validation loss: 1.4506056603565012

Epoch: 6| Step: 4
Training loss: 0.1415337771177292
Validation loss: 1.4754273968358194

Epoch: 6| Step: 5
Training loss: 0.0902421772480011
Validation loss: 1.428350528081258

Epoch: 6| Step: 6
Training loss: 0.15249143540859222
Validation loss: 1.4237201226654874

Epoch: 6| Step: 7
Training loss: 0.18578238785266876
Validation loss: 1.4165895606881829

Epoch: 6| Step: 8
Training loss: 0.36466455459594727
Validation loss: 1.411175864358102

Epoch: 6| Step: 9
Training loss: 0.18446512520313263
Validation loss: 1.401720513579666

Epoch: 6| Step: 10
Training loss: 0.1606522798538208
Validation loss: 1.443817542445275

Epoch: 6| Step: 11
Training loss: 0.11929867416620255
Validation loss: 1.4398680143458868

Epoch: 6| Step: 12
Training loss: 0.1168660819530487
Validation loss: 1.469110406214191

Epoch: 6| Step: 13
Training loss: 0.2723151743412018
Validation loss: 1.4590563274198962

Epoch: 384| Step: 0
Training loss: 0.12035202234983444
Validation loss: 1.4197150033007386

Epoch: 6| Step: 1
Training loss: 0.12533524632453918
Validation loss: 1.4288542975661576

Epoch: 6| Step: 2
Training loss: 0.1684798002243042
Validation loss: 1.4163842624233616

Epoch: 6| Step: 3
Training loss: 0.24491474032402039
Validation loss: 1.4293038896335069

Epoch: 6| Step: 4
Training loss: 0.1308005154132843
Validation loss: 1.4342037939256238

Epoch: 6| Step: 5
Training loss: 0.24272173643112183
Validation loss: 1.4295482738043672

Epoch: 6| Step: 6
Training loss: 0.2035888135433197
Validation loss: 1.4330537614002024

Epoch: 6| Step: 7
Training loss: 0.20190265774726868
Validation loss: 1.4343236915526851

Epoch: 6| Step: 8
Training loss: 0.12898531556129456
Validation loss: 1.463912292193341

Epoch: 6| Step: 9
Training loss: 0.09065917879343033
Validation loss: 1.4908379585512224

Epoch: 6| Step: 10
Training loss: 0.18509122729301453
Validation loss: 1.4876117571707694

Epoch: 6| Step: 11
Training loss: 0.2253042459487915
Validation loss: 1.4785293859820212

Epoch: 6| Step: 12
Training loss: 0.11817169934511185
Validation loss: 1.4765456350900794

Epoch: 6| Step: 13
Training loss: 0.13787221908569336
Validation loss: 1.4681414250404603

Epoch: 385| Step: 0
Training loss: 0.16847388446331024
Validation loss: 1.4558624836706346

Epoch: 6| Step: 1
Training loss: 0.13940122723579407
Validation loss: 1.4640920034018896

Epoch: 6| Step: 2
Training loss: 0.11323922872543335
Validation loss: 1.4661659784214471

Epoch: 6| Step: 3
Training loss: 0.08822724223136902
Validation loss: 1.4779621554959206

Epoch: 6| Step: 4
Training loss: 0.13828060030937195
Validation loss: 1.4877591479209162

Epoch: 6| Step: 5
Training loss: 0.27298229932785034
Validation loss: 1.5012551456369378

Epoch: 6| Step: 6
Training loss: 0.1944904327392578
Validation loss: 1.528877467237493

Epoch: 6| Step: 7
Training loss: 0.11674793064594269
Validation loss: 1.4957319228879866

Epoch: 6| Step: 8
Training loss: 0.17443114519119263
Validation loss: 1.4913873851940196

Epoch: 6| Step: 9
Training loss: 0.15139587223529816
Validation loss: 1.5037334747211908

Epoch: 6| Step: 10
Training loss: 0.152266725897789
Validation loss: 1.497755499296291

Epoch: 6| Step: 11
Training loss: 0.3017736077308655
Validation loss: 1.5005519210651357

Epoch: 6| Step: 12
Training loss: 0.21221940219402313
Validation loss: 1.4840916215732534

Epoch: 6| Step: 13
Training loss: 0.4852012097835541
Validation loss: 1.494446616018972

Epoch: 386| Step: 0
Training loss: 0.17006154358386993
Validation loss: 1.4871234432343514

Epoch: 6| Step: 1
Training loss: 0.18940699100494385
Validation loss: 1.4736857452700216

Epoch: 6| Step: 2
Training loss: 0.26161009073257446
Validation loss: 1.4702813676608506

Epoch: 6| Step: 3
Training loss: 0.18532311916351318
Validation loss: 1.4852384572388024

Epoch: 6| Step: 4
Training loss: 0.27076107263565063
Validation loss: 1.4700650527913084

Epoch: 6| Step: 5
Training loss: 0.26648205518722534
Validation loss: 1.4745649688987321

Epoch: 6| Step: 6
Training loss: 0.13624480366706848
Validation loss: 1.454805120345085

Epoch: 6| Step: 7
Training loss: 0.1452970802783966
Validation loss: 1.4371350067918018

Epoch: 6| Step: 8
Training loss: 0.13708415627479553
Validation loss: 1.443327651228956

Epoch: 6| Step: 9
Training loss: 0.15798795223236084
Validation loss: 1.4271800569308701

Epoch: 6| Step: 10
Training loss: 0.20271584391593933
Validation loss: 1.4345082544511365

Epoch: 6| Step: 11
Training loss: 0.12406787276268005
Validation loss: 1.4308394373104136

Epoch: 6| Step: 12
Training loss: 0.23083364963531494
Validation loss: 1.4330126841862996

Epoch: 6| Step: 13
Training loss: 0.19637681543827057
Validation loss: 1.4459693572854484

Epoch: 387| Step: 0
Training loss: 0.09218962490558624
Validation loss: 1.4550592104593914

Epoch: 6| Step: 1
Training loss: 0.13756904006004333
Validation loss: 1.470018962378143

Epoch: 6| Step: 2
Training loss: 0.2152499258518219
Validation loss: 1.4875056743621826

Epoch: 6| Step: 3
Training loss: 0.17071570456027985
Validation loss: 1.5109861198291983

Epoch: 6| Step: 4
Training loss: 0.19967588782310486
Validation loss: 1.5318600439256238

Epoch: 6| Step: 5
Training loss: 0.1855984628200531
Validation loss: 1.5148315160505232

Epoch: 6| Step: 6
Training loss: 0.10772291570901871
Validation loss: 1.5160382652795443

Epoch: 6| Step: 7
Training loss: 0.19551774859428406
Validation loss: 1.516676091378735

Epoch: 6| Step: 8
Training loss: 0.13576385378837585
Validation loss: 1.4907378740208124

Epoch: 6| Step: 9
Training loss: 0.220878005027771
Validation loss: 1.4724432691451041

Epoch: 6| Step: 10
Training loss: 0.20951059460639954
Validation loss: 1.4766732262026878

Epoch: 6| Step: 11
Training loss: 0.25450605154037476
Validation loss: 1.4748351061215965

Epoch: 6| Step: 12
Training loss: 0.24441014230251312
Validation loss: 1.4643850364992697

Epoch: 6| Step: 13
Training loss: 0.11827569454908371
Validation loss: 1.472524178925381

Epoch: 388| Step: 0
Training loss: 0.1095728874206543
Validation loss: 1.4909213819811422

Epoch: 6| Step: 1
Training loss: 0.14848953485488892
Validation loss: 1.4793792027299122

Epoch: 6| Step: 2
Training loss: 0.10464313626289368
Validation loss: 1.494300147538544

Epoch: 6| Step: 3
Training loss: 0.14618007838726044
Validation loss: 1.4925765875847108

Epoch: 6| Step: 4
Training loss: 0.23010388016700745
Validation loss: 1.4970306863066971

Epoch: 6| Step: 5
Training loss: 0.21977928280830383
Validation loss: 1.5030259605376952

Epoch: 6| Step: 6
Training loss: 0.1009175032377243
Validation loss: 1.497386149821743

Epoch: 6| Step: 7
Training loss: 0.15023276209831238
Validation loss: 1.4818160482632217

Epoch: 6| Step: 8
Training loss: 0.16767165064811707
Validation loss: 1.463297777278449

Epoch: 6| Step: 9
Training loss: 0.09414298832416534
Validation loss: 1.460384004859514

Epoch: 6| Step: 10
Training loss: 0.14307895302772522
Validation loss: 1.4392727953131481

Epoch: 6| Step: 11
Training loss: 0.22011059522628784
Validation loss: 1.4221637236174716

Epoch: 6| Step: 12
Training loss: 0.1925262212753296
Validation loss: 1.4098067142630135

Epoch: 6| Step: 13
Training loss: 0.1668340116739273
Validation loss: 1.435420738753452

Epoch: 389| Step: 0
Training loss: 0.1592489778995514
Validation loss: 1.4340938880879393

Epoch: 6| Step: 1
Training loss: 0.20033365488052368
Validation loss: 1.417123306182123

Epoch: 6| Step: 2
Training loss: 0.16012197732925415
Validation loss: 1.4408691313958937

Epoch: 6| Step: 3
Training loss: 0.1579495072364807
Validation loss: 1.4532369714911266

Epoch: 6| Step: 4
Training loss: 0.23022502660751343
Validation loss: 1.453574626676498

Epoch: 6| Step: 5
Training loss: 0.08073539286851883
Validation loss: 1.4589270558408511

Epoch: 6| Step: 6
Training loss: 0.1536571979522705
Validation loss: 1.4615158996274393

Epoch: 6| Step: 7
Training loss: 0.14432106912136078
Validation loss: 1.45874406701775

Epoch: 6| Step: 8
Training loss: 0.16981446743011475
Validation loss: 1.4507015110344015

Epoch: 6| Step: 9
Training loss: 0.08839070051908493
Validation loss: 1.4566130099758026

Epoch: 6| Step: 10
Training loss: 0.22478598356246948
Validation loss: 1.4633520610870854

Epoch: 6| Step: 11
Training loss: 0.1582496017217636
Validation loss: 1.4472513109125116

Epoch: 6| Step: 12
Training loss: 0.12793198227882385
Validation loss: 1.4516038433198006

Epoch: 6| Step: 13
Training loss: 0.2202543020248413
Validation loss: 1.4304379737505348

Epoch: 390| Step: 0
Training loss: 0.12454918026924133
Validation loss: 1.4370722950145762

Epoch: 6| Step: 1
Training loss: 0.0837533175945282
Validation loss: 1.4454413242237543

Epoch: 6| Step: 2
Training loss: 0.11145004630088806
Validation loss: 1.4365490200699016

Epoch: 6| Step: 3
Training loss: 0.1527780294418335
Validation loss: 1.4668936806340371

Epoch: 6| Step: 4
Training loss: 0.1443588137626648
Validation loss: 1.4592599740592382

Epoch: 6| Step: 5
Training loss: 0.11542847752571106
Validation loss: 1.4475146698695358

Epoch: 6| Step: 6
Training loss: 0.26568078994750977
Validation loss: 1.4505247954399354

Epoch: 6| Step: 7
Training loss: 0.11216607689857483
Validation loss: 1.4685555940033288

Epoch: 6| Step: 8
Training loss: 0.22965456545352936
Validation loss: 1.486442655645391

Epoch: 6| Step: 9
Training loss: 0.09362515807151794
Validation loss: 1.494885783041677

Epoch: 6| Step: 10
Training loss: 0.19591906666755676
Validation loss: 1.5075270796334872

Epoch: 6| Step: 11
Training loss: 0.12680160999298096
Validation loss: 1.4932104669591433

Epoch: 6| Step: 12
Training loss: 0.2564127445220947
Validation loss: 1.4866174203093334

Epoch: 6| Step: 13
Training loss: 0.11851387470960617
Validation loss: 1.4810436041124406

Epoch: 391| Step: 0
Training loss: 0.16435545682907104
Validation loss: 1.5016742047443186

Epoch: 6| Step: 1
Training loss: 0.19310328364372253
Validation loss: 1.4607046009391866

Epoch: 6| Step: 2
Training loss: 0.17820166051387787
Validation loss: 1.4533608908294349

Epoch: 6| Step: 3
Training loss: 0.14918330311775208
Validation loss: 1.451005087744805

Epoch: 6| Step: 4
Training loss: 0.12676317989826202
Validation loss: 1.4806659888195735

Epoch: 6| Step: 5
Training loss: 0.16439461708068848
Validation loss: 1.4821667261021112

Epoch: 6| Step: 6
Training loss: 0.1744089424610138
Validation loss: 1.494786371466934

Epoch: 6| Step: 7
Training loss: 0.13234463334083557
Validation loss: 1.4981231138270388

Epoch: 6| Step: 8
Training loss: 0.14431338012218475
Validation loss: 1.4752405458881008

Epoch: 6| Step: 9
Training loss: 0.22192096710205078
Validation loss: 1.4640199266454226

Epoch: 6| Step: 10
Training loss: 0.11941385269165039
Validation loss: 1.4483196120108328

Epoch: 6| Step: 11
Training loss: 0.17952367663383484
Validation loss: 1.4450947533371628

Epoch: 6| Step: 12
Training loss: 0.15131039917469025
Validation loss: 1.446903859415362

Epoch: 6| Step: 13
Training loss: 0.21676702797412872
Validation loss: 1.4530678641411565

Epoch: 392| Step: 0
Training loss: 0.1628645956516266
Validation loss: 1.439586377912952

Epoch: 6| Step: 1
Training loss: 0.1555178165435791
Validation loss: 1.4032520376225954

Epoch: 6| Step: 2
Training loss: 0.16341456770896912
Validation loss: 1.4311105717894852

Epoch: 6| Step: 3
Training loss: 0.1792253851890564
Validation loss: 1.4135588228061635

Epoch: 6| Step: 4
Training loss: 0.15973886847496033
Validation loss: 1.4413761092770485

Epoch: 6| Step: 5
Training loss: 0.20877596735954285
Validation loss: 1.450429698472382

Epoch: 6| Step: 6
Training loss: 0.14727751910686493
Validation loss: 1.438465654209096

Epoch: 6| Step: 7
Training loss: 0.12995082139968872
Validation loss: 1.4500101330459758

Epoch: 6| Step: 8
Training loss: 0.17545531690120697
Validation loss: 1.4520787423656834

Epoch: 6| Step: 9
Training loss: 0.17757779359817505
Validation loss: 1.4639305632601503

Epoch: 6| Step: 10
Training loss: 0.2399807870388031
Validation loss: 1.4054273661746775

Epoch: 6| Step: 11
Training loss: 0.1407904028892517
Validation loss: 1.427601105423384

Epoch: 6| Step: 12
Training loss: 0.1887321025133133
Validation loss: 1.417671327949852

Epoch: 6| Step: 13
Training loss: 0.13204386830329895
Validation loss: 1.4193569690950456

Epoch: 393| Step: 0
Training loss: 0.2308976650238037
Validation loss: 1.3874860399512834

Epoch: 6| Step: 1
Training loss: 0.1138743907213211
Validation loss: 1.389597636397167

Epoch: 6| Step: 2
Training loss: 0.14274217188358307
Validation loss: 1.4151841812236334

Epoch: 6| Step: 3
Training loss: 0.09735211730003357
Validation loss: 1.4150058953992781

Epoch: 6| Step: 4
Training loss: 0.18950650095939636
Validation loss: 1.4238434324982345

Epoch: 6| Step: 5
Training loss: 0.1563214361667633
Validation loss: 1.4290906754873132

Epoch: 6| Step: 6
Training loss: 0.12291113287210464
Validation loss: 1.4633981341956763

Epoch: 6| Step: 7
Training loss: 0.144252210855484
Validation loss: 1.466237865468507

Epoch: 6| Step: 8
Training loss: 0.09375155717134476
Validation loss: 1.4898048600842875

Epoch: 6| Step: 9
Training loss: 0.11911896616220474
Validation loss: 1.5254058684072187

Epoch: 6| Step: 10
Training loss: 0.16172069311141968
Validation loss: 1.4968970168021418

Epoch: 6| Step: 11
Training loss: 0.1915905624628067
Validation loss: 1.4930884697104012

Epoch: 6| Step: 12
Training loss: 0.26589053869247437
Validation loss: 1.435811742659538

Epoch: 6| Step: 13
Training loss: 0.186627596616745
Validation loss: 1.4140445622064735

Epoch: 394| Step: 0
Training loss: 0.16649766266345978
Validation loss: 1.415601154809357

Epoch: 6| Step: 1
Training loss: 0.2553321123123169
Validation loss: 1.428715411052909

Epoch: 6| Step: 2
Training loss: 0.16863006353378296
Validation loss: 1.4226070757835143

Epoch: 6| Step: 3
Training loss: 0.13281935453414917
Validation loss: 1.4366812398356776

Epoch: 6| Step: 4
Training loss: 0.10757355391979218
Validation loss: 1.4448702771176574

Epoch: 6| Step: 5
Training loss: 0.12918448448181152
Validation loss: 1.4551508772757746

Epoch: 6| Step: 6
Training loss: 0.15092025697231293
Validation loss: 1.4973561020307644

Epoch: 6| Step: 7
Training loss: 0.1528356373310089
Validation loss: 1.4942093587690783

Epoch: 6| Step: 8
Training loss: 0.13174670934677124
Validation loss: 1.4888102136632448

Epoch: 6| Step: 9
Training loss: 0.1284146010875702
Validation loss: 1.5040576611795733

Epoch: 6| Step: 10
Training loss: 0.20742355287075043
Validation loss: 1.4987752437591553

Epoch: 6| Step: 11
Training loss: 0.1355498731136322
Validation loss: 1.5041294008172967

Epoch: 6| Step: 12
Training loss: 0.10543510317802429
Validation loss: 1.458432969226632

Epoch: 6| Step: 13
Training loss: 0.1399267464876175
Validation loss: 1.4635516930651922

Epoch: 395| Step: 0
Training loss: 0.15696841478347778
Validation loss: 1.4704504884699339

Epoch: 6| Step: 1
Training loss: 0.17838476598262787
Validation loss: 1.4660591694616503

Epoch: 6| Step: 2
Training loss: 0.11665119975805283
Validation loss: 1.446479292326076

Epoch: 6| Step: 3
Training loss: 0.09153258800506592
Validation loss: 1.4577365575298187

Epoch: 6| Step: 4
Training loss: 0.17682865262031555
Validation loss: 1.4723786769374725

Epoch: 6| Step: 5
Training loss: 0.23140251636505127
Validation loss: 1.4656849035652735

Epoch: 6| Step: 6
Training loss: 0.2614790201187134
Validation loss: 1.4730274446548954

Epoch: 6| Step: 7
Training loss: 0.1968214511871338
Validation loss: 1.4545140266418457

Epoch: 6| Step: 8
Training loss: 0.15194281935691833
Validation loss: 1.4344191576844902

Epoch: 6| Step: 9
Training loss: 0.11854209750890732
Validation loss: 1.4380531234125937

Epoch: 6| Step: 10
Training loss: 0.09775308519601822
Validation loss: 1.4251268281731555

Epoch: 6| Step: 11
Training loss: 0.13448747992515564
Validation loss: 1.45321443516721

Epoch: 6| Step: 12
Training loss: 0.1502971202135086
Validation loss: 1.4846089680989583

Epoch: 6| Step: 13
Training loss: 0.16618803143501282
Validation loss: 1.4663604388954818

Epoch: 396| Step: 0
Training loss: 0.09017934650182724
Validation loss: 1.4727635486151582

Epoch: 6| Step: 1
Training loss: 0.09565973281860352
Validation loss: 1.4756522178649902

Epoch: 6| Step: 2
Training loss: 0.19696234166622162
Validation loss: 1.4439712685923423

Epoch: 6| Step: 3
Training loss: 0.08586157113313675
Validation loss: 1.4546850650541243

Epoch: 6| Step: 4
Training loss: 0.19920791685581207
Validation loss: 1.489179802197282

Epoch: 6| Step: 5
Training loss: 0.21428067982196808
Validation loss: 1.49197171836771

Epoch: 6| Step: 6
Training loss: 0.13960495591163635
Validation loss: 1.4555801448001657

Epoch: 6| Step: 7
Training loss: 0.12394824624061584
Validation loss: 1.4600453351133613

Epoch: 6| Step: 8
Training loss: 0.15958543121814728
Validation loss: 1.4344843920841013

Epoch: 6| Step: 9
Training loss: 0.15368831157684326
Validation loss: 1.4462265840140722

Epoch: 6| Step: 10
Training loss: 0.09762265533208847
Validation loss: 1.4143046256034606

Epoch: 6| Step: 11
Training loss: 0.19108545780181885
Validation loss: 1.4551338175291657

Epoch: 6| Step: 12
Training loss: 0.16630470752716064
Validation loss: 1.4507884363974295

Epoch: 6| Step: 13
Training loss: 0.1371804028749466
Validation loss: 1.4563934315917313

Epoch: 397| Step: 0
Training loss: 0.1616268754005432
Validation loss: 1.4874389427964405

Epoch: 6| Step: 1
Training loss: 0.10602737963199615
Validation loss: 1.4960454869013962

Epoch: 6| Step: 2
Training loss: 0.09742443263530731
Validation loss: 1.4885861963354132

Epoch: 6| Step: 3
Training loss: 0.09590163081884384
Validation loss: 1.4360261681259319

Epoch: 6| Step: 4
Training loss: 0.1359359472990036
Validation loss: 1.4496524897954797

Epoch: 6| Step: 5
Training loss: 0.13115279376506805
Validation loss: 1.4342002279014998

Epoch: 6| Step: 6
Training loss: 0.09627579152584076
Validation loss: 1.405420716090869

Epoch: 6| Step: 7
Training loss: 0.1380908340215683
Validation loss: 1.4314652091713362

Epoch: 6| Step: 8
Training loss: 0.25191909074783325
Validation loss: 1.4016442427071192

Epoch: 6| Step: 9
Training loss: 0.1169734001159668
Validation loss: 1.412407648819749

Epoch: 6| Step: 10
Training loss: 0.17219510674476624
Validation loss: 1.4182172283049552

Epoch: 6| Step: 11
Training loss: 0.17090412974357605
Validation loss: 1.4230825952304307

Epoch: 6| Step: 12
Training loss: 0.11665638536214828
Validation loss: 1.4440827151780486

Epoch: 6| Step: 13
Training loss: 0.13524027168750763
Validation loss: 1.4623092130948139

Epoch: 398| Step: 0
Training loss: 0.09551364928483963
Validation loss: 1.4631764017125612

Epoch: 6| Step: 1
Training loss: 0.09001456201076508
Validation loss: 1.4638922970782045

Epoch: 6| Step: 2
Training loss: 0.2273346483707428
Validation loss: 1.524269155276719

Epoch: 6| Step: 3
Training loss: 0.24101504683494568
Validation loss: 1.518456051426549

Epoch: 6| Step: 4
Training loss: 0.10056313872337341
Validation loss: 1.4899365222582253

Epoch: 6| Step: 5
Training loss: 0.145941823720932
Validation loss: 1.4988491842823644

Epoch: 6| Step: 6
Training loss: 0.19544482231140137
Validation loss: 1.504333032074795

Epoch: 6| Step: 7
Training loss: 0.12790730595588684
Validation loss: 1.5000497820556804

Epoch: 6| Step: 8
Training loss: 0.11384257674217224
Validation loss: 1.4783348242441814

Epoch: 6| Step: 9
Training loss: 0.16610532999038696
Validation loss: 1.4776473468349827

Epoch: 6| Step: 10
Training loss: 0.11613394320011139
Validation loss: 1.4469720381562428

Epoch: 6| Step: 11
Training loss: 0.10279656946659088
Validation loss: 1.441385563983712

Epoch: 6| Step: 12
Training loss: 0.13580811023712158
Validation loss: 1.4092467843845327

Epoch: 6| Step: 13
Training loss: 0.11030974239110947
Validation loss: 1.4338060194446194

Epoch: 399| Step: 0
Training loss: 0.12949347496032715
Validation loss: 1.417718533546694

Epoch: 6| Step: 1
Training loss: 0.13922417163848877
Validation loss: 1.4183074838371688

Epoch: 6| Step: 2
Training loss: 0.15500688552856445
Validation loss: 1.4412299920153875

Epoch: 6| Step: 3
Training loss: 0.1737150251865387
Validation loss: 1.4325655634685228

Epoch: 6| Step: 4
Training loss: 0.15109886229038239
Validation loss: 1.4392738816558674

Epoch: 6| Step: 5
Training loss: 0.1505720466375351
Validation loss: 1.4369683175958612

Epoch: 6| Step: 6
Training loss: 0.13548167049884796
Validation loss: 1.4220640261967976

Epoch: 6| Step: 7
Training loss: 0.1277526170015335
Validation loss: 1.4240445590788318

Epoch: 6| Step: 8
Training loss: 0.15605759620666504
Validation loss: 1.4328960859647362

Epoch: 6| Step: 9
Training loss: 0.10773146152496338
Validation loss: 1.4527995131349052

Epoch: 6| Step: 10
Training loss: 0.12970416247844696
Validation loss: 1.4462262507407897

Epoch: 6| Step: 11
Training loss: 0.19167152047157288
Validation loss: 1.4534602395949825

Epoch: 6| Step: 12
Training loss: 0.08465349674224854
Validation loss: 1.4483683455374934

Epoch: 6| Step: 13
Training loss: 0.1253083497285843
Validation loss: 1.4663388203549128

Epoch: 400| Step: 0
Training loss: 0.24775826930999756
Validation loss: 1.522708623639999

Epoch: 6| Step: 1
Training loss: 0.19179967045783997
Validation loss: 1.5044932865327405

Epoch: 6| Step: 2
Training loss: 0.16657111048698425
Validation loss: 1.4991112139917189

Epoch: 6| Step: 3
Training loss: 0.19817550480365753
Validation loss: 1.5097250194959744

Epoch: 6| Step: 4
Training loss: 0.14318785071372986
Validation loss: 1.473661195847296

Epoch: 6| Step: 5
Training loss: 0.11207373440265656
Validation loss: 1.4759285116708407

Epoch: 6| Step: 6
Training loss: 0.15673373639583588
Validation loss: 1.4933716122822096

Epoch: 6| Step: 7
Training loss: 0.2039145529270172
Validation loss: 1.4901920300658031

Epoch: 6| Step: 8
Training loss: 0.2051757425069809
Validation loss: 1.4962136578816239

Epoch: 6| Step: 9
Training loss: 0.16148467361927032
Validation loss: 1.499966771371903

Epoch: 6| Step: 10
Training loss: 0.14149627089500427
Validation loss: 1.4620877350530317

Epoch: 6| Step: 11
Training loss: 0.15631502866744995
Validation loss: 1.498511577165255

Epoch: 6| Step: 12
Training loss: 0.12949113547801971
Validation loss: 1.4635440482888171

Epoch: 6| Step: 13
Training loss: 0.08750276267528534
Validation loss: 1.4796151063775504

Testing loss: 2.225394418504503
