Epoch: 1| Step: 0
Training loss: 5.593283521925259
Validation loss: 5.777538893067904

Epoch: 6| Step: 1
Training loss: 5.508012657045714
Validation loss: 5.752176237668794

Epoch: 6| Step: 2
Training loss: 5.145461013647733
Validation loss: 5.729548843777548

Epoch: 6| Step: 3
Training loss: 4.573206215325373
Validation loss: 5.705146488602809

Epoch: 6| Step: 4
Training loss: 5.666210530192197
Validation loss: 5.677574238396123

Epoch: 6| Step: 5
Training loss: 5.4917304552895425
Validation loss: 5.647118872696832

Epoch: 6| Step: 6
Training loss: 6.308230325251748
Validation loss: 5.612377980689071

Epoch: 6| Step: 7
Training loss: 6.323868589267662
Validation loss: 5.5721107701406405

Epoch: 6| Step: 8
Training loss: 6.536489620868429
Validation loss: 5.528492140779149

Epoch: 6| Step: 9
Training loss: 6.179104436285366
Validation loss: 5.4794074955849394

Epoch: 6| Step: 10
Training loss: 3.1680316660097985
Validation loss: 5.425776543973232

Epoch: 6| Step: 11
Training loss: 5.288404685828587
Validation loss: 5.369378701164769

Epoch: 6| Step: 12
Training loss: 6.073071887310202
Validation loss: 5.309418869481923

Epoch: 6| Step: 13
Training loss: 5.865798237131945
Validation loss: 5.246438311044473

Epoch: 2| Step: 0
Training loss: 4.3016184755030356
Validation loss: 5.18219338287422

Epoch: 6| Step: 1
Training loss: 5.005539686314507
Validation loss: 5.117279271844424

Epoch: 6| Step: 2
Training loss: 5.223561883895204
Validation loss: 5.048291351669549

Epoch: 6| Step: 3
Training loss: 4.745852215433222
Validation loss: 4.975566511734043

Epoch: 6| Step: 4
Training loss: 6.366828618145147
Validation loss: 4.899587649117465

Epoch: 6| Step: 5
Training loss: 5.152517921679413
Validation loss: 4.820392067036938

Epoch: 6| Step: 6
Training loss: 5.538000093701859
Validation loss: 4.742316332586812

Epoch: 6| Step: 7
Training loss: 4.556795499404013
Validation loss: 4.666195636187982

Epoch: 6| Step: 8
Training loss: 4.655355687632164
Validation loss: 4.597606224329956

Epoch: 6| Step: 9
Training loss: 3.1881705682037227
Validation loss: 4.531971440575879

Epoch: 6| Step: 10
Training loss: 5.005684101252616
Validation loss: 4.473140639489028

Epoch: 6| Step: 11
Training loss: 3.3476155121682614
Validation loss: 4.416778383488635

Epoch: 6| Step: 12
Training loss: 4.879539918942834
Validation loss: 4.366812620249819

Epoch: 6| Step: 13
Training loss: 4.535181063535693
Validation loss: 4.3290076724930335

Epoch: 3| Step: 0
Training loss: 4.952725270985994
Validation loss: 4.290882127693305

Epoch: 6| Step: 1
Training loss: 4.143114025626823
Validation loss: 4.2379723157437965

Epoch: 6| Step: 2
Training loss: 3.7372167779786962
Validation loss: 4.20410364434004

Epoch: 6| Step: 3
Training loss: 4.441567289709081
Validation loss: 4.177528114421848

Epoch: 6| Step: 4
Training loss: 4.502148009610463
Validation loss: 4.152717144221752

Epoch: 6| Step: 5
Training loss: 4.151002022981897
Validation loss: 4.130746432894492

Epoch: 6| Step: 6
Training loss: 4.633683584317159
Validation loss: 4.104476276565067

Epoch: 6| Step: 7
Training loss: 3.2385171360294582
Validation loss: 4.067677270687356

Epoch: 6| Step: 8
Training loss: 2.6905138726053135
Validation loss: 4.043331899686735

Epoch: 6| Step: 9
Training loss: 4.632505770173779
Validation loss: 4.038133074703589

Epoch: 6| Step: 10
Training loss: 3.6020081217503206
Validation loss: 4.027752687637509

Epoch: 6| Step: 11
Training loss: 4.715606653014756
Validation loss: 3.9902572163377372

Epoch: 6| Step: 12
Training loss: 4.089397650202226
Validation loss: 3.972364640435878

Epoch: 6| Step: 13
Training loss: 5.847080199791428
Validation loss: 3.9596092943891144

Epoch: 4| Step: 0
Training loss: 2.877772942796309
Validation loss: 3.941676868473301

Epoch: 6| Step: 1
Training loss: 3.6107148825254294
Validation loss: 3.931280527528305

Epoch: 6| Step: 2
Training loss: 3.843563540518413
Validation loss: 3.9151653147406402

Epoch: 6| Step: 3
Training loss: 4.871668533149089
Validation loss: 3.9083769017487557

Epoch: 6| Step: 4
Training loss: 3.764893013496688
Validation loss: 3.893896335460649

Epoch: 6| Step: 5
Training loss: 3.694942399377397
Validation loss: 3.8789554074796264

Epoch: 6| Step: 6
Training loss: 4.908471837488624
Validation loss: 3.864572599583119

Epoch: 6| Step: 7
Training loss: 4.240387536458264
Validation loss: 3.8544698612028125

Epoch: 6| Step: 8
Training loss: 3.6921817348465886
Validation loss: 3.847847701271806

Epoch: 6| Step: 9
Training loss: 4.660105088649382
Validation loss: 3.8344602364072573

Epoch: 6| Step: 10
Training loss: 4.724208478883328
Validation loss: 3.8193362583463966

Epoch: 6| Step: 11
Training loss: 2.2999806071583393
Validation loss: 3.8081228869136594

Epoch: 6| Step: 12
Training loss: 3.854998744464675
Validation loss: 3.8043294064582804

Epoch: 6| Step: 13
Training loss: 4.795045982355163
Validation loss: 3.793159935005337

Epoch: 5| Step: 0
Training loss: 3.6832081015400813
Validation loss: 3.7795556263075376

Epoch: 6| Step: 1
Training loss: 4.750666521390545
Validation loss: 3.7688351748012616

Epoch: 6| Step: 2
Training loss: 4.194191440140501
Validation loss: 3.759404976440508

Epoch: 6| Step: 3
Training loss: 3.44319471808351
Validation loss: 3.7465917693003044

Epoch: 6| Step: 4
Training loss: 2.9195095013468597
Validation loss: 3.7333148322071814

Epoch: 6| Step: 5
Training loss: 4.115099035209247
Validation loss: 3.7201795731636644

Epoch: 6| Step: 6
Training loss: 4.778744907720688
Validation loss: 3.712026134279184

Epoch: 6| Step: 7
Training loss: 4.048581268101683
Validation loss: 3.700965170840954

Epoch: 6| Step: 8
Training loss: 3.5020606922792226
Validation loss: 3.6845927081138696

Epoch: 6| Step: 9
Training loss: 3.8882259954382232
Validation loss: 3.6686832489058534

Epoch: 6| Step: 10
Training loss: 3.4405481868696266
Validation loss: 3.6575142850176263

Epoch: 6| Step: 11
Training loss: 3.2357222105546937
Validation loss: 3.6488041281706542

Epoch: 6| Step: 12
Training loss: 3.2559673106077986
Validation loss: 3.6364347174414924

Epoch: 6| Step: 13
Training loss: 5.112375853880257
Validation loss: 3.6237249681532666

Epoch: 6| Step: 0
Training loss: 3.8073227546699453
Validation loss: 3.6087124138271482

Epoch: 6| Step: 1
Training loss: 2.7428348135890777
Validation loss: 3.5935224235423573

Epoch: 6| Step: 2
Training loss: 4.232065394395673
Validation loss: 3.579005449260232

Epoch: 6| Step: 3
Training loss: 3.7202177597216717
Validation loss: 3.5615565675852454

Epoch: 6| Step: 4
Training loss: 4.306323064397391
Validation loss: 3.546121605184571

Epoch: 6| Step: 5
Training loss: 4.197806812044832
Validation loss: 3.5315502582495992

Epoch: 6| Step: 6
Training loss: 3.9191684578571016
Validation loss: 3.5126983573140658

Epoch: 6| Step: 7
Training loss: 3.859827177299917
Validation loss: 3.4989937743678223

Epoch: 6| Step: 8
Training loss: 3.2770239363661355
Validation loss: 3.4892580152837533

Epoch: 6| Step: 9
Training loss: 3.1853266767951496
Validation loss: 3.4818109567433564

Epoch: 6| Step: 10
Training loss: 2.614188500085074
Validation loss: 3.470423297696361

Epoch: 6| Step: 11
Training loss: 3.757728750203695
Validation loss: 3.45412050195537

Epoch: 6| Step: 12
Training loss: 4.382943054539488
Validation loss: 3.4485890550412366

Epoch: 6| Step: 13
Training loss: 3.634932492139587
Validation loss: 3.436365364285105

Epoch: 7| Step: 0
Training loss: 3.460947419920885
Validation loss: 3.419260946452464

Epoch: 6| Step: 1
Training loss: 3.7172948731175546
Validation loss: 3.406403678745643

Epoch: 6| Step: 2
Training loss: 3.8660908078394187
Validation loss: 3.394267324258926

Epoch: 6| Step: 3
Training loss: 3.595796881204007
Validation loss: 3.3826736315214796

Epoch: 6| Step: 4
Training loss: 4.228295949114818
Validation loss: 3.368791922247678

Epoch: 6| Step: 5
Training loss: 3.9894374624863898
Validation loss: 3.3536313841964573

Epoch: 6| Step: 6
Training loss: 2.9458285823138035
Validation loss: 3.3415917496446994

Epoch: 6| Step: 7
Training loss: 3.534979547120403
Validation loss: 3.3296618766724797

Epoch: 6| Step: 8
Training loss: 3.128301326267539
Validation loss: 3.316184319250185

Epoch: 6| Step: 9
Training loss: 3.7061549156819122
Validation loss: 3.303807569894743

Epoch: 6| Step: 10
Training loss: 2.8309244874014463
Validation loss: 3.298741375190219

Epoch: 6| Step: 11
Training loss: 4.04803992041403
Validation loss: 3.3224880716047736

Epoch: 6| Step: 12
Training loss: 3.525356810346832
Validation loss: 3.301894329284561

Epoch: 6| Step: 13
Training loss: 3.1101205210009737
Validation loss: 3.3030995481281606

Epoch: 8| Step: 0
Training loss: 3.524733751130349
Validation loss: 3.315642089651253

Epoch: 6| Step: 1
Training loss: 3.2520589908631288
Validation loss: 3.316047323110547

Epoch: 6| Step: 2
Training loss: 2.9837818455045437
Validation loss: 3.302730563769258

Epoch: 6| Step: 3
Training loss: 3.8518986120062
Validation loss: 3.2937196866419995

Epoch: 6| Step: 4
Training loss: 3.0257921931282876
Validation loss: 3.2709910397392536

Epoch: 6| Step: 5
Training loss: 3.71969387353548
Validation loss: 3.2378785727992447

Epoch: 6| Step: 6
Training loss: 3.7258988595238822
Validation loss: 3.2214467927010997

Epoch: 6| Step: 7
Training loss: 3.695969892098465
Validation loss: 3.2101224511512894

Epoch: 6| Step: 8
Training loss: 4.246371347009022
Validation loss: 3.2093834116778237

Epoch: 6| Step: 9
Training loss: 2.85527002397147
Validation loss: 3.1922407740186216

Epoch: 6| Step: 10
Training loss: 2.832498614453131
Validation loss: 3.177478942501831

Epoch: 6| Step: 11
Training loss: 4.063703857460297
Validation loss: 3.1702754272421036

Epoch: 6| Step: 12
Training loss: 3.121369350902879
Validation loss: 3.163766002549652

Epoch: 6| Step: 13
Training loss: 3.654674223068017
Validation loss: 3.15452779193056

Epoch: 9| Step: 0
Training loss: 2.971440752235011
Validation loss: 3.1437781670654323

Epoch: 6| Step: 1
Training loss: 3.508018028848007
Validation loss: 3.138265436083991

Epoch: 6| Step: 2
Training loss: 3.0857312097287166
Validation loss: 3.1286327109400545

Epoch: 6| Step: 3
Training loss: 3.404286229723746
Validation loss: 3.1209005461109895

Epoch: 6| Step: 4
Training loss: 2.670009653452592
Validation loss: 3.1201537301177065

Epoch: 6| Step: 5
Training loss: 3.1899938364477616
Validation loss: 3.1121730292858665

Epoch: 6| Step: 6
Training loss: 3.605691061884315
Validation loss: 3.127111567338182

Epoch: 6| Step: 7
Training loss: 4.023627830373778
Validation loss: 3.1056976190682555

Epoch: 6| Step: 8
Training loss: 2.9171839300786604
Validation loss: 3.101987823272385

Epoch: 6| Step: 9
Training loss: 3.783399995280963
Validation loss: 3.0941772878507248

Epoch: 6| Step: 10
Training loss: 2.593431568132073
Validation loss: 3.0844310169062257

Epoch: 6| Step: 11
Training loss: 4.3522133468897986
Validation loss: 3.07842726259522

Epoch: 6| Step: 12
Training loss: 3.3155712069391137
Validation loss: 3.0762620277821506

Epoch: 6| Step: 13
Training loss: 3.4975693300586475
Validation loss: 3.072245933673476

Epoch: 10| Step: 0
Training loss: 3.71479112204769
Validation loss: 3.0672832216537684

Epoch: 6| Step: 1
Training loss: 4.2344659887018405
Validation loss: 3.0643775831444233

Epoch: 6| Step: 2
Training loss: 3.0162991575621536
Validation loss: 3.054886517843264

Epoch: 6| Step: 3
Training loss: 3.0570463551109857
Validation loss: 3.047333252561892

Epoch: 6| Step: 4
Training loss: 2.6567088908817036
Validation loss: 3.0364064830081365

Epoch: 6| Step: 5
Training loss: 2.8118307376997542
Validation loss: 3.030706525432834

Epoch: 6| Step: 6
Training loss: 3.2168420859091404
Validation loss: 3.03013938853266

Epoch: 6| Step: 7
Training loss: 2.676285967596285
Validation loss: 3.024170596975651

Epoch: 6| Step: 8
Training loss: 3.4524985733416
Validation loss: 3.020444189911388

Epoch: 6| Step: 9
Training loss: 3.5172332475992514
Validation loss: 3.0173519476798982

Epoch: 6| Step: 10
Training loss: 3.71296768068384
Validation loss: 3.0123497371772454

Epoch: 6| Step: 11
Training loss: 3.540350336530425
Validation loss: 3.0370349155437735

Epoch: 6| Step: 12
Training loss: 2.7177950179366883
Validation loss: 3.006546997404297

Epoch: 6| Step: 13
Training loss: 4.1151113179423975
Validation loss: 3.00679253622788

Epoch: 11| Step: 0
Training loss: 3.983052830948389
Validation loss: 3.0040764492605816

Epoch: 6| Step: 1
Training loss: 3.7147840621437114
Validation loss: 2.9989149257430325

Epoch: 6| Step: 2
Training loss: 2.016041675643971
Validation loss: 2.9920924646671048

Epoch: 6| Step: 3
Training loss: 3.1329400471814646
Validation loss: 2.989520030498226

Epoch: 6| Step: 4
Training loss: 2.6328276229107117
Validation loss: 2.989135686949299

Epoch: 6| Step: 5
Training loss: 3.363483985523645
Validation loss: 2.992158030973119

Epoch: 6| Step: 6
Training loss: 3.4195836028984457
Validation loss: 2.991621059532031

Epoch: 6| Step: 7
Training loss: 3.327950486456735
Validation loss: 2.9912102664236753

Epoch: 6| Step: 8
Training loss: 3.0487001869977632
Validation loss: 2.985589090824142

Epoch: 6| Step: 9
Training loss: 3.1102710755382845
Validation loss: 2.980899427928242

Epoch: 6| Step: 10
Training loss: 3.284945051410098
Validation loss: 2.975755282295395

Epoch: 6| Step: 11
Training loss: 3.4357973910670836
Validation loss: 2.973911980194331

Epoch: 6| Step: 12
Training loss: 3.7525204135814776
Validation loss: 2.9803621518220247

Epoch: 6| Step: 13
Training loss: 3.3289908415604508
Validation loss: 2.966037727566906

Epoch: 12| Step: 0
Training loss: 3.167803928212745
Validation loss: 2.9694875572758925

Epoch: 6| Step: 1
Training loss: 3.672397917178525
Validation loss: 3.012699922921199

Epoch: 6| Step: 2
Training loss: 3.792870438752309
Validation loss: 3.0353798819189057

Epoch: 6| Step: 3
Training loss: 2.8494830348642197
Validation loss: 3.0126727504367037

Epoch: 6| Step: 4
Training loss: 2.7224915289068363
Validation loss: 3.0167227461157453

Epoch: 6| Step: 5
Training loss: 3.637873842095602
Validation loss: 3.014440537774463

Epoch: 6| Step: 6
Training loss: 2.3706598277592286
Validation loss: 2.9765500080325706

Epoch: 6| Step: 7
Training loss: 3.1642222423024653
Validation loss: 2.9645232598456226

Epoch: 6| Step: 8
Training loss: 3.2878279373739083
Validation loss: 2.9568863402962187

Epoch: 6| Step: 9
Training loss: 3.8294103838900093
Validation loss: 2.958519682907046

Epoch: 6| Step: 10
Training loss: 3.8571034283111274
Validation loss: 2.962975788587182

Epoch: 6| Step: 11
Training loss: 2.8958895195283203
Validation loss: 2.9598809740274716

Epoch: 6| Step: 12
Training loss: 2.967974430971465
Validation loss: 2.965200120215566

Epoch: 6| Step: 13
Training loss: 3.3005134067549164
Validation loss: 2.9586682670932127

Epoch: 13| Step: 0
Training loss: 3.5074498046415545
Validation loss: 2.9517033411421094

Epoch: 6| Step: 1
Training loss: 2.8204077707192527
Validation loss: 2.944586640384742

Epoch: 6| Step: 2
Training loss: 2.850297872135455
Validation loss: 2.938712212699572

Epoch: 6| Step: 3
Training loss: 3.0218066171287736
Validation loss: 2.9327559518393906

Epoch: 6| Step: 4
Training loss: 3.1629968426303017
Validation loss: 2.9323468675318822

Epoch: 6| Step: 5
Training loss: 3.3649373690032407
Validation loss: 2.9317580766166613

Epoch: 6| Step: 6
Training loss: 3.47757649582317
Validation loss: 2.922215811512382

Epoch: 6| Step: 7
Training loss: 4.217727424174515
Validation loss: 2.918124483848574

Epoch: 6| Step: 8
Training loss: 3.0172995231926665
Validation loss: 2.923121522205997

Epoch: 6| Step: 9
Training loss: 2.9335763577734273
Validation loss: 2.9301215848748248

Epoch: 6| Step: 10
Training loss: 3.081858428248309
Validation loss: 2.963681977191206

Epoch: 6| Step: 11
Training loss: 3.458584849085706
Validation loss: 2.917541636061195

Epoch: 6| Step: 12
Training loss: 2.837934311217431
Validation loss: 2.911996741493678

Epoch: 6| Step: 13
Training loss: 3.5744016506737677
Validation loss: 2.916472498558499

Epoch: 14| Step: 0
Training loss: 2.738822763748247
Validation loss: 2.902607486138609

Epoch: 6| Step: 1
Training loss: 3.406403564351279
Validation loss: 2.904006990434552

Epoch: 6| Step: 2
Training loss: 3.173570602533162
Validation loss: 2.9038032944107153

Epoch: 6| Step: 3
Training loss: 3.1212896063586757
Validation loss: 2.9056859981425234

Epoch: 6| Step: 4
Training loss: 3.324896020625853
Validation loss: 2.90727665454209

Epoch: 6| Step: 5
Training loss: 3.3952776370341122
Validation loss: 2.909368386810782

Epoch: 6| Step: 6
Training loss: 2.8727464551252293
Validation loss: 2.905161259919795

Epoch: 6| Step: 7
Training loss: 4.046513014698581
Validation loss: 2.8962393495452017

Epoch: 6| Step: 8
Training loss: 2.7440958800010824
Validation loss: 2.8923642633922846

Epoch: 6| Step: 9
Training loss: 3.314969851441608
Validation loss: 2.8903872519924065

Epoch: 6| Step: 10
Training loss: 3.627350538396553
Validation loss: 2.8906122483956382

Epoch: 6| Step: 11
Training loss: 2.4710685369294962
Validation loss: 2.8906967069938148

Epoch: 6| Step: 12
Training loss: 3.204493979084265
Validation loss: 2.8914816321247683

Epoch: 6| Step: 13
Training loss: 3.3535102217669053
Validation loss: 2.892296241604966

Epoch: 15| Step: 0
Training loss: 3.607369530447251
Validation loss: 2.8909911682340423

Epoch: 6| Step: 1
Training loss: 3.407445015523138
Validation loss: 2.8855375717193623

Epoch: 6| Step: 2
Training loss: 3.2021533515801726
Validation loss: 2.8848378802005397

Epoch: 6| Step: 3
Training loss: 3.215056735616406
Validation loss: 2.883903639517639

Epoch: 6| Step: 4
Training loss: 3.035255538514349
Validation loss: 2.8836044325150194

Epoch: 6| Step: 5
Training loss: 3.522629469691257
Validation loss: 2.8879409075196425

Epoch: 6| Step: 6
Training loss: 3.272587267453032
Validation loss: 2.8796932235514094

Epoch: 6| Step: 7
Training loss: 3.182923865488475
Validation loss: 2.876387912509125

Epoch: 6| Step: 8
Training loss: 2.8895637832416634
Validation loss: 2.876178977669759

Epoch: 6| Step: 9
Training loss: 3.035079739071442
Validation loss: 2.871895323341818

Epoch: 6| Step: 10
Training loss: 2.9230005065103173
Validation loss: 2.870184879235836

Epoch: 6| Step: 11
Training loss: 3.16351780853637
Validation loss: 2.8673010157043395

Epoch: 6| Step: 12
Training loss: 3.5353520966123706
Validation loss: 2.8684194217917356

Epoch: 6| Step: 13
Training loss: 2.249782551748361
Validation loss: 2.8666931747313646

Epoch: 16| Step: 0
Training loss: 3.536566049604867
Validation loss: 2.864940439527265

Epoch: 6| Step: 1
Training loss: 2.5631432074918905
Validation loss: 2.865349928378346

Epoch: 6| Step: 2
Training loss: 3.4023066101499753
Validation loss: 2.864828338139082

Epoch: 6| Step: 3
Training loss: 3.359681297355421
Validation loss: 2.8675799733093594

Epoch: 6| Step: 4
Training loss: 2.9135242609389045
Validation loss: 2.8642803192219377

Epoch: 6| Step: 5
Training loss: 2.9480482595523116
Validation loss: 2.866281647115787

Epoch: 6| Step: 6
Training loss: 3.6725489221148773
Validation loss: 2.8613474992119046

Epoch: 6| Step: 7
Training loss: 3.3094067796256517
Validation loss: 2.860455543792752

Epoch: 6| Step: 8
Training loss: 3.0806081602441573
Validation loss: 2.8580921921519318

Epoch: 6| Step: 9
Training loss: 2.601403492143571
Validation loss: 2.8574819230686277

Epoch: 6| Step: 10
Training loss: 3.2610381552748953
Validation loss: 2.8556341074540246

Epoch: 6| Step: 11
Training loss: 3.259343434781688
Validation loss: 2.8574558297225696

Epoch: 6| Step: 12
Training loss: 2.8909123458320525
Validation loss: 2.8533385581230437

Epoch: 6| Step: 13
Training loss: 3.8705283174492804
Validation loss: 2.854263200438041

Epoch: 17| Step: 0
Training loss: 2.5860222286853296
Validation loss: 2.8538808737182104

Epoch: 6| Step: 1
Training loss: 3.0160664447780996
Validation loss: 2.8523617139012605

Epoch: 6| Step: 2
Training loss: 2.792937848113576
Validation loss: 2.8510986076659077

Epoch: 6| Step: 3
Training loss: 3.188881668129904
Validation loss: 2.854506469168586

Epoch: 6| Step: 4
Training loss: 3.3221384570201624
Validation loss: 2.859447515760477

Epoch: 6| Step: 5
Training loss: 2.993195286847739
Validation loss: 2.856351264419941

Epoch: 6| Step: 6
Training loss: 3.4494458790149785
Validation loss: 2.8527803772206632

Epoch: 6| Step: 7
Training loss: 3.1270978371124776
Validation loss: 2.8470036409160997

Epoch: 6| Step: 8
Training loss: 3.7437338292149978
Validation loss: 2.855393365204634

Epoch: 6| Step: 9
Training loss: 3.283233333814028
Validation loss: 2.844156040870674

Epoch: 6| Step: 10
Training loss: 3.154572900558255
Validation loss: 2.843633186639337

Epoch: 6| Step: 11
Training loss: 2.9097224993972426
Validation loss: 2.840836267412374

Epoch: 6| Step: 12
Training loss: 3.2578224529599162
Validation loss: 2.8410157828782423

Epoch: 6| Step: 13
Training loss: 3.630214886360694
Validation loss: 2.8396252071869026

Epoch: 18| Step: 0
Training loss: 2.822876586254157
Validation loss: 2.8372665803291053

Epoch: 6| Step: 1
Training loss: 2.6427782297320013
Validation loss: 2.837119107369914

Epoch: 6| Step: 2
Training loss: 3.6511612390518566
Validation loss: 2.835656169100295

Epoch: 6| Step: 3
Training loss: 2.750987742505903
Validation loss: 2.8384527003757296

Epoch: 6| Step: 4
Training loss: 2.7899413019930894
Validation loss: 2.8327640441678272

Epoch: 6| Step: 5
Training loss: 3.4856268169363456
Validation loss: 2.8317874845121405

Epoch: 6| Step: 6
Training loss: 2.933602852432616
Validation loss: 2.830694369090061

Epoch: 6| Step: 7
Training loss: 3.3336760026910186
Validation loss: 2.8308947623478873

Epoch: 6| Step: 8
Training loss: 3.6656283873715565
Validation loss: 2.8241624708114865

Epoch: 6| Step: 9
Training loss: 3.3549676416601866
Validation loss: 2.828574962963272

Epoch: 6| Step: 10
Training loss: 3.3298432835081906
Validation loss: 2.824059585173101

Epoch: 6| Step: 11
Training loss: 2.6074895385649364
Validation loss: 2.833336837978717

Epoch: 6| Step: 12
Training loss: 2.8572111019430984
Validation loss: 2.8365108604535956

Epoch: 6| Step: 13
Training loss: 4.070619421459741
Validation loss: 2.8419774681912124

Epoch: 19| Step: 0
Training loss: 3.3493098444793326
Validation loss: 2.832710826272637

Epoch: 6| Step: 1
Training loss: 2.771034854836281
Validation loss: 2.8274661565626076

Epoch: 6| Step: 2
Training loss: 3.059160240981973
Validation loss: 2.8270708692954214

Epoch: 6| Step: 3
Training loss: 3.135297517424162
Validation loss: 2.8266021647913533

Epoch: 6| Step: 4
Training loss: 3.0147026904840417
Validation loss: 2.8291640837601686

Epoch: 6| Step: 5
Training loss: 2.957714248855163
Validation loss: 2.824012530622105

Epoch: 6| Step: 6
Training loss: 3.3330852098305574
Validation loss: 2.825194229039507

Epoch: 6| Step: 7
Training loss: 3.4333112685102543
Validation loss: 2.823403112704652

Epoch: 6| Step: 8
Training loss: 2.732237061800722
Validation loss: 2.8226496582266716

Epoch: 6| Step: 9
Training loss: 3.5058631833196587
Validation loss: 2.8214339037218803

Epoch: 6| Step: 10
Training loss: 3.495978633754219
Validation loss: 2.819931374026626

Epoch: 6| Step: 11
Training loss: 3.4196993386691954
Validation loss: 2.8206539184303323

Epoch: 6| Step: 12
Training loss: 2.771452889455139
Validation loss: 2.8169985627031986

Epoch: 6| Step: 13
Training loss: 3.0812229116614813
Validation loss: 2.8172806756891347

Epoch: 20| Step: 0
Training loss: 3.3246392993747858
Validation loss: 2.8156337675667586

Epoch: 6| Step: 1
Training loss: 2.8163138068869924
Validation loss: 2.8150110372303168

Epoch: 6| Step: 2
Training loss: 3.236645624843392
Validation loss: 2.81260755326456

Epoch: 6| Step: 3
Training loss: 2.574940141889509
Validation loss: 2.8115719757901334

Epoch: 6| Step: 4
Training loss: 3.7630553282462356
Validation loss: 2.8179163353439907

Epoch: 6| Step: 5
Training loss: 3.373682683362865
Validation loss: 2.8165512995409836

Epoch: 6| Step: 6
Training loss: 3.1524028937973294
Validation loss: 2.8170042951718433

Epoch: 6| Step: 7
Training loss: 3.0120556515520884
Validation loss: 2.8243353733133856

Epoch: 6| Step: 8
Training loss: 3.1569031898751887
Validation loss: 2.8195337011013577

Epoch: 6| Step: 9
Training loss: 3.0098803261320404
Validation loss: 2.81445771585218

Epoch: 6| Step: 10
Training loss: 3.589201860458281
Validation loss: 2.803237449245337

Epoch: 6| Step: 11
Training loss: 2.8530679151792877
Validation loss: 2.7984279185600847

Epoch: 6| Step: 12
Training loss: 2.9150976229461256
Validation loss: 2.795444817882286

Epoch: 6| Step: 13
Training loss: 2.768026569999667
Validation loss: 2.7978696481540055

Epoch: 21| Step: 0
Training loss: 3.381137776936334
Validation loss: 2.8021179580119817

Epoch: 6| Step: 1
Training loss: 2.6875251946266343
Validation loss: 2.79824994118051

Epoch: 6| Step: 2
Training loss: 2.7385863217185444
Validation loss: 2.799616316430833

Epoch: 6| Step: 3
Training loss: 2.9751718231077278
Validation loss: 2.7995841060963036

Epoch: 6| Step: 4
Training loss: 3.1298067890045584
Validation loss: 2.79915004954318

Epoch: 6| Step: 5
Training loss: 3.022318788307133
Validation loss: 2.8054805304806805

Epoch: 6| Step: 6
Training loss: 2.7434465175314906
Validation loss: 2.794801483412855

Epoch: 6| Step: 7
Training loss: 3.8826108454142956
Validation loss: 2.7885762160098357

Epoch: 6| Step: 8
Training loss: 2.736436339368505
Validation loss: 2.7901566771039383

Epoch: 6| Step: 9
Training loss: 3.2261950858644095
Validation loss: 2.788529021457673

Epoch: 6| Step: 10
Training loss: 3.4498562769047103
Validation loss: 2.791488646988744

Epoch: 6| Step: 11
Training loss: 3.191168077002324
Validation loss: 2.7935974069877645

Epoch: 6| Step: 12
Training loss: 3.146916403019822
Validation loss: 2.7964181385387903

Epoch: 6| Step: 13
Training loss: 3.4105861956468733
Validation loss: 2.796729351629765

Epoch: 22| Step: 0
Training loss: 2.8079437649739103
Validation loss: 2.7989381628086223

Epoch: 6| Step: 1
Training loss: 3.220777447122294
Validation loss: 2.798769771651531

Epoch: 6| Step: 2
Training loss: 3.035335972397789
Validation loss: 2.7879709720803234

Epoch: 6| Step: 3
Training loss: 2.959718156232288
Validation loss: 2.786648085424727

Epoch: 6| Step: 4
Training loss: 3.6854736450230083
Validation loss: 2.788905481854761

Epoch: 6| Step: 5
Training loss: 2.6582847431330094
Validation loss: 2.786824878362721

Epoch: 6| Step: 6
Training loss: 2.404237475308336
Validation loss: 2.788699747312708

Epoch: 6| Step: 7
Training loss: 2.3988588441423295
Validation loss: 2.787255327392468

Epoch: 6| Step: 8
Training loss: 3.036771798461751
Validation loss: 2.7905358485464395

Epoch: 6| Step: 9
Training loss: 3.775096204933902
Validation loss: 2.7850904285651006

Epoch: 6| Step: 10
Training loss: 3.514812460355421
Validation loss: 2.7836040412584784

Epoch: 6| Step: 11
Training loss: 3.6942051847483355
Validation loss: 2.782337888957955

Epoch: 6| Step: 12
Training loss: 2.7314197374059646
Validation loss: 2.779492270658297

Epoch: 6| Step: 13
Training loss: 3.3494184700973975
Validation loss: 2.7750196284936077

Epoch: 23| Step: 0
Training loss: 3.248836602542444
Validation loss: 2.774478539610203

Epoch: 6| Step: 1
Training loss: 3.2483337238977654
Validation loss: 2.7754910400165484

Epoch: 6| Step: 2
Training loss: 3.2307496323532536
Validation loss: 2.77015410474575

Epoch: 6| Step: 3
Training loss: 2.911650858856012
Validation loss: 2.7784230381772317

Epoch: 6| Step: 4
Training loss: 3.059865947604498
Validation loss: 2.7760345293280477

Epoch: 6| Step: 5
Training loss: 3.300500837525029
Validation loss: 2.7713378306952956

Epoch: 6| Step: 6
Training loss: 3.0530826811654195
Validation loss: 2.7687088634450117

Epoch: 6| Step: 7
Training loss: 2.527133372776607
Validation loss: 2.7657919730719933

Epoch: 6| Step: 8
Training loss: 2.929044688594007
Validation loss: 2.761783405608892

Epoch: 6| Step: 9
Training loss: 2.3619191177176533
Validation loss: 2.7641214128391414

Epoch: 6| Step: 10
Training loss: 3.1466010632653725
Validation loss: 2.765582433388858

Epoch: 6| Step: 11
Training loss: 3.1748006322547924
Validation loss: 2.7757629305078866

Epoch: 6| Step: 12
Training loss: 4.046822212493558
Validation loss: 2.7805368251798748

Epoch: 6| Step: 13
Training loss: 2.7762798519667946
Validation loss: 2.7667391927528375

Epoch: 24| Step: 0
Training loss: 2.915890690349418
Validation loss: 2.7621003272699376

Epoch: 6| Step: 1
Training loss: 3.0109327109377455
Validation loss: 2.75301266539836

Epoch: 6| Step: 2
Training loss: 2.9088925069105347
Validation loss: 2.7507174656927593

Epoch: 6| Step: 3
Training loss: 3.3404307780888267
Validation loss: 2.7540483498433868

Epoch: 6| Step: 4
Training loss: 3.1906998972083556
Validation loss: 2.7527290834578735

Epoch: 6| Step: 5
Training loss: 3.4188361064660553
Validation loss: 2.7489735485969016

Epoch: 6| Step: 6
Training loss: 3.047351349983152
Validation loss: 2.7514563924197386

Epoch: 6| Step: 7
Training loss: 2.759824111005581
Validation loss: 2.7519359486341957

Epoch: 6| Step: 8
Training loss: 3.375407724124176
Validation loss: 2.759373862860525

Epoch: 6| Step: 9
Training loss: 3.570969802818501
Validation loss: 2.791404814386131

Epoch: 6| Step: 10
Training loss: 2.5738091613283975
Validation loss: 2.8206426600906545

Epoch: 6| Step: 11
Training loss: 2.799269519614863
Validation loss: 2.8669095513351737

Epoch: 6| Step: 12
Training loss: 3.0593701932438777
Validation loss: 2.8505834499296383

Epoch: 6| Step: 13
Training loss: 3.2558239326767686
Validation loss: 2.78762194205216

Epoch: 25| Step: 0
Training loss: 3.3014896151887587
Validation loss: 2.767491222608187

Epoch: 6| Step: 1
Training loss: 2.9512932157280876
Validation loss: 2.7482113610151626

Epoch: 6| Step: 2
Training loss: 2.44476487727875
Validation loss: 2.7477428947038143

Epoch: 6| Step: 3
Training loss: 3.506081066719812
Validation loss: 2.7494773703728637

Epoch: 6| Step: 4
Training loss: 2.904536408613671
Validation loss: 2.7505635721631685

Epoch: 6| Step: 5
Training loss: 2.813414276715311
Validation loss: 2.7483812939662857

Epoch: 6| Step: 6
Training loss: 2.124343658512358
Validation loss: 2.755711522538937

Epoch: 6| Step: 7
Training loss: 4.057641513352173
Validation loss: 2.7585500010906503

Epoch: 6| Step: 8
Training loss: 3.3181162313437773
Validation loss: 2.760423101106939

Epoch: 6| Step: 9
Training loss: 3.3731332490660058
Validation loss: 2.755917701113566

Epoch: 6| Step: 10
Training loss: 3.177017027783172
Validation loss: 2.751761727014194

Epoch: 6| Step: 11
Training loss: 2.417872610322412
Validation loss: 2.743864843315117

Epoch: 6| Step: 12
Training loss: 3.271892756693549
Validation loss: 2.746814787684684

Epoch: 6| Step: 13
Training loss: 2.5928644713891598
Validation loss: 2.7419890448884248

Epoch: 26| Step: 0
Training loss: 2.82481907628094
Validation loss: 2.740218433092293

Epoch: 6| Step: 1
Training loss: 2.566293467187454
Validation loss: 2.7384371659358915

Epoch: 6| Step: 2
Training loss: 2.5562554543583884
Validation loss: 2.7380286792137096

Epoch: 6| Step: 3
Training loss: 2.6373131202190594
Validation loss: 2.7396286632715245

Epoch: 6| Step: 4
Training loss: 3.0902773701147224
Validation loss: 2.7361775924889757

Epoch: 6| Step: 5
Training loss: 2.735861063814836
Validation loss: 2.7318763691800263

Epoch: 6| Step: 6
Training loss: 2.7181413341881377
Validation loss: 2.7316508037105525

Epoch: 6| Step: 7
Training loss: 3.607643670005596
Validation loss: 2.73130597418838

Epoch: 6| Step: 8
Training loss: 3.079866333079842
Validation loss: 2.7310297835291433

Epoch: 6| Step: 9
Training loss: 4.0352316421895695
Validation loss: 2.7361037777703743

Epoch: 6| Step: 10
Training loss: 3.034907386032871
Validation loss: 2.7297480387534407

Epoch: 6| Step: 11
Training loss: 3.5811650717153523
Validation loss: 2.7330490586754577

Epoch: 6| Step: 12
Training loss: 3.127778610882856
Validation loss: 2.7233197039197377

Epoch: 6| Step: 13
Training loss: 2.841574035507007
Validation loss: 2.7205639649219977

Epoch: 27| Step: 0
Training loss: 3.1403251239083665
Validation loss: 2.720496935021382

Epoch: 6| Step: 1
Training loss: 3.218282424890243
Validation loss: 2.7196837016992754

Epoch: 6| Step: 2
Training loss: 3.279425995075622
Validation loss: 2.7200606499882634

Epoch: 6| Step: 3
Training loss: 3.931447539347139
Validation loss: 2.7207707830115253

Epoch: 6| Step: 4
Training loss: 3.1408079483114326
Validation loss: 2.7195163524135375

Epoch: 6| Step: 5
Training loss: 2.5505025106723185
Validation loss: 2.7165740502451037

Epoch: 6| Step: 6
Training loss: 3.2297504184538672
Validation loss: 2.720135852423873

Epoch: 6| Step: 7
Training loss: 2.7970435235596116
Validation loss: 2.7140845614097073

Epoch: 6| Step: 8
Training loss: 2.554659502068483
Validation loss: 2.7116018367076475

Epoch: 6| Step: 9
Training loss: 2.7626158297321703
Validation loss: 2.710695360937784

Epoch: 6| Step: 10
Training loss: 2.9332845756062023
Validation loss: 2.712087997699632

Epoch: 6| Step: 11
Training loss: 3.081178341664846
Validation loss: 2.716132628177582

Epoch: 6| Step: 12
Training loss: 2.354688625930284
Validation loss: 2.711335467442398

Epoch: 6| Step: 13
Training loss: 3.7250521816208617
Validation loss: 2.7119697992448724

Epoch: 28| Step: 0
Training loss: 3.368708928411648
Validation loss: 2.7099157946402888

Epoch: 6| Step: 1
Training loss: 3.7890690439698647
Validation loss: 2.711768530511037

Epoch: 6| Step: 2
Training loss: 3.4298952078868186
Validation loss: 2.7109454171017626

Epoch: 6| Step: 3
Training loss: 2.8495252046449315
Validation loss: 2.7150548383523216

Epoch: 6| Step: 4
Training loss: 2.5744923285605057
Validation loss: 2.7128541729081466

Epoch: 6| Step: 5
Training loss: 3.047499998497904
Validation loss: 2.7086897572120274

Epoch: 6| Step: 6
Training loss: 2.9544706962037317
Validation loss: 2.7101333237258225

Epoch: 6| Step: 7
Training loss: 2.3348924219153493
Validation loss: 2.7178652621184987

Epoch: 6| Step: 8
Training loss: 2.8519530982485275
Validation loss: 2.7337414538749187

Epoch: 6| Step: 9
Training loss: 3.1190880357182205
Validation loss: 2.7240919061861177

Epoch: 6| Step: 10
Training loss: 2.668932627519709
Validation loss: 2.711047170416696

Epoch: 6| Step: 11
Training loss: 2.8591430236437767
Validation loss: 2.7087247321161008

Epoch: 6| Step: 12
Training loss: 3.1732359724042047
Validation loss: 2.7030952333898686

Epoch: 6| Step: 13
Training loss: 3.313838328504917
Validation loss: 2.7013317065582942

Epoch: 29| Step: 0
Training loss: 3.3721103306794977
Validation loss: 2.7035431053360344

Epoch: 6| Step: 1
Training loss: 3.6615482643048005
Validation loss: 2.7168706900981636

Epoch: 6| Step: 2
Training loss: 2.9363829741202228
Validation loss: 2.696879922033433

Epoch: 6| Step: 3
Training loss: 3.1159414607022766
Validation loss: 2.6952998021465593

Epoch: 6| Step: 4
Training loss: 2.968528177105456
Validation loss: 2.694532289867743

Epoch: 6| Step: 5
Training loss: 3.2599979087027178
Validation loss: 2.7049369744681115

Epoch: 6| Step: 6
Training loss: 2.9928852592419566
Validation loss: 2.709369926449306

Epoch: 6| Step: 7
Training loss: 2.835997189400683
Validation loss: 2.706086452699126

Epoch: 6| Step: 8
Training loss: 2.961094029297583
Validation loss: 2.6916252302066703

Epoch: 6| Step: 9
Training loss: 3.209550469791626
Validation loss: 2.687624804190431

Epoch: 6| Step: 10
Training loss: 2.9511414986441316
Validation loss: 2.695449613032489

Epoch: 6| Step: 11
Training loss: 2.369567480417152
Validation loss: 2.7119558550039575

Epoch: 6| Step: 12
Training loss: 2.9933451910428337
Validation loss: 2.7186346278300237

Epoch: 6| Step: 13
Training loss: 2.3624006664242887
Validation loss: 2.736619514376973

Epoch: 30| Step: 0
Training loss: 3.1490585434027474
Validation loss: 2.7411855909975564

Epoch: 6| Step: 1
Training loss: 2.608088924506748
Validation loss: 2.758534744944838

Epoch: 6| Step: 2
Training loss: 3.0777513306266036
Validation loss: 2.7641347813643407

Epoch: 6| Step: 3
Training loss: 3.084191709751915
Validation loss: 2.7381457546488392

Epoch: 6| Step: 4
Training loss: 3.0313966066753606
Validation loss: 2.6951556834999764

Epoch: 6| Step: 5
Training loss: 2.7046574124272027
Validation loss: 2.700673280536364

Epoch: 6| Step: 6
Training loss: 3.363735190493255
Validation loss: 2.731966344108175

Epoch: 6| Step: 7
Training loss: 2.725676559313972
Validation loss: 2.7337680631758463

Epoch: 6| Step: 8
Training loss: 3.3102198976614865
Validation loss: 2.7614002304310525

Epoch: 6| Step: 9
Training loss: 3.322428094388622
Validation loss: 2.7742429731496894

Epoch: 6| Step: 10
Training loss: 2.496339979847078
Validation loss: 2.7396846287587877

Epoch: 6| Step: 11
Training loss: 3.594181731455101
Validation loss: 2.7215052999238925

Epoch: 6| Step: 12
Training loss: 3.280398012994342
Validation loss: 2.71392522207988

Epoch: 6| Step: 13
Training loss: 2.711609243227675
Validation loss: 2.6892736486473674

Epoch: 31| Step: 0
Training loss: 3.3005961891076963
Validation loss: 2.7095256525232125

Epoch: 6| Step: 1
Training loss: 2.939090217163547
Validation loss: 2.706167470742215

Epoch: 6| Step: 2
Training loss: 2.4432213955470123
Validation loss: 2.7024583024588615

Epoch: 6| Step: 3
Training loss: 3.639812067650936
Validation loss: 2.702778613063234

Epoch: 6| Step: 4
Training loss: 3.5970572471018896
Validation loss: 2.696146322223288

Epoch: 6| Step: 5
Training loss: 3.0613759371864444
Validation loss: 2.690574751993315

Epoch: 6| Step: 6
Training loss: 3.4078704059478775
Validation loss: 2.6855879724067027

Epoch: 6| Step: 7
Training loss: 3.3788131083622
Validation loss: 2.6857149320430773

Epoch: 6| Step: 8
Training loss: 2.9076469099563167
Validation loss: 2.6842830814078003

Epoch: 6| Step: 9
Training loss: 2.708940721530036
Validation loss: 2.6867124658488257

Epoch: 6| Step: 10
Training loss: 3.0361973610559647
Validation loss: 2.690424371886855

Epoch: 6| Step: 11
Training loss: 2.543907449334352
Validation loss: 2.686044898607344

Epoch: 6| Step: 12
Training loss: 1.9110920180000301
Validation loss: 2.687516510271935

Epoch: 6| Step: 13
Training loss: 2.9283004529044607
Validation loss: 2.6861247516778954

Epoch: 32| Step: 0
Training loss: 3.233326027721004
Validation loss: 2.6838710768371676

Epoch: 6| Step: 1
Training loss: 2.707003770829144
Validation loss: 2.6773533749348504

Epoch: 6| Step: 2
Training loss: 3.1696697517957952
Validation loss: 2.674940959864253

Epoch: 6| Step: 3
Training loss: 3.147093531001437
Validation loss: 2.6730802828258846

Epoch: 6| Step: 4
Training loss: 2.901612550368511
Validation loss: 2.6729952858651194

Epoch: 6| Step: 5
Training loss: 2.4599206185907843
Validation loss: 2.6703429440949575

Epoch: 6| Step: 6
Training loss: 3.6047785833034953
Validation loss: 2.668088057951397

Epoch: 6| Step: 7
Training loss: 3.5463393558919933
Validation loss: 2.6710641951590905

Epoch: 6| Step: 8
Training loss: 3.148522009082167
Validation loss: 2.675034392776639

Epoch: 6| Step: 9
Training loss: 3.153938882548854
Validation loss: 2.6796195853541196

Epoch: 6| Step: 10
Training loss: 3.170458247038718
Validation loss: 2.6833784269537295

Epoch: 6| Step: 11
Training loss: 2.603313234994881
Validation loss: 2.6809419352817923

Epoch: 6| Step: 12
Training loss: 2.5356232340869767
Validation loss: 2.680167139559846

Epoch: 6| Step: 13
Training loss: 2.01000144768658
Validation loss: 2.6696929753103475

Epoch: 33| Step: 0
Training loss: 2.9449190640945266
Validation loss: 2.6679799444155066

Epoch: 6| Step: 1
Training loss: 2.7404341349587065
Validation loss: 2.6652278235760285

Epoch: 6| Step: 2
Training loss: 2.626060816447732
Validation loss: 2.6692317314895564

Epoch: 6| Step: 3
Training loss: 2.7875486908496185
Validation loss: 2.665557383216221

Epoch: 6| Step: 4
Training loss: 3.4332494639056876
Validation loss: 2.6638319255956904

Epoch: 6| Step: 5
Training loss: 2.2698881883013833
Validation loss: 2.6595747801593537

Epoch: 6| Step: 6
Training loss: 3.159095916344895
Validation loss: 2.6610435206084615

Epoch: 6| Step: 7
Training loss: 2.9518319987844586
Validation loss: 2.6582890481957233

Epoch: 6| Step: 8
Training loss: 3.3417288117246797
Validation loss: 2.6549594724019308

Epoch: 6| Step: 9
Training loss: 3.038595992422088
Validation loss: 2.654441792294635

Epoch: 6| Step: 10
Training loss: 3.4330448757831036
Validation loss: 2.6533685737990838

Epoch: 6| Step: 11
Training loss: 3.4820233949842687
Validation loss: 2.653893265780611

Epoch: 6| Step: 12
Training loss: 2.688286865725163
Validation loss: 2.650459601987906

Epoch: 6| Step: 13
Training loss: 2.6436289117015694
Validation loss: 2.6510228098089024

Epoch: 34| Step: 0
Training loss: 3.3324983186710404
Validation loss: 2.652042224195743

Epoch: 6| Step: 1
Training loss: 2.470435231276787
Validation loss: 2.6507815454957964

Epoch: 6| Step: 2
Training loss: 2.8629358351296204
Validation loss: 2.6607375706072522

Epoch: 6| Step: 3
Training loss: 3.266462008883764
Validation loss: 2.660385299539974

Epoch: 6| Step: 4
Training loss: 2.787834858988023
Validation loss: 2.661567437394894

Epoch: 6| Step: 5
Training loss: 3.0158368762598857
Validation loss: 2.6761943333311353

Epoch: 6| Step: 6
Training loss: 2.9529517390373137
Validation loss: 2.682313661916225

Epoch: 6| Step: 7
Training loss: 2.973841266810989
Validation loss: 2.6730952891736877

Epoch: 6| Step: 8
Training loss: 3.103726571309974
Validation loss: 2.647109232649151

Epoch: 6| Step: 9
Training loss: 3.1736645090038187
Validation loss: 2.644184610101759

Epoch: 6| Step: 10
Training loss: 2.847249487356089
Validation loss: 2.645845943346916

Epoch: 6| Step: 11
Training loss: 2.7179422165073617
Validation loss: 2.6491398619461

Epoch: 6| Step: 12
Training loss: 3.6764858434024035
Validation loss: 2.6487437867378794

Epoch: 6| Step: 13
Training loss: 1.987334200103342
Validation loss: 2.647894170006911

Epoch: 35| Step: 0
Training loss: 3.113296259864225
Validation loss: 2.6460896985418567

Epoch: 6| Step: 1
Training loss: 3.310131449783188
Validation loss: 2.648429663203665

Epoch: 6| Step: 2
Training loss: 3.0812721236171714
Validation loss: 2.6463138905169243

Epoch: 6| Step: 3
Training loss: 3.274529249996407
Validation loss: 2.643678823902677

Epoch: 6| Step: 4
Training loss: 2.8626843255677987
Validation loss: 2.644391851649593

Epoch: 6| Step: 5
Training loss: 3.0361529153604336
Validation loss: 2.6428355554894827

Epoch: 6| Step: 6
Training loss: 2.8450790485468884
Validation loss: 2.6460370182477617

Epoch: 6| Step: 7
Training loss: 3.2387161975128707
Validation loss: 2.652444092152838

Epoch: 6| Step: 8
Training loss: 3.2398805798786783
Validation loss: 2.6542048824191005

Epoch: 6| Step: 9
Training loss: 3.1231168031766248
Validation loss: 2.654722150987265

Epoch: 6| Step: 10
Training loss: 2.8151066886238896
Validation loss: 2.646246320645289

Epoch: 6| Step: 11
Training loss: 2.7122203419052138
Validation loss: 2.6554181644073904

Epoch: 6| Step: 12
Training loss: 2.5572140766708094
Validation loss: 2.6549509770005386

Epoch: 6| Step: 13
Training loss: 1.7937404991190704
Validation loss: 2.65973656778997

Epoch: 36| Step: 0
Training loss: 3.26997983127172
Validation loss: 2.6780325150665636

Epoch: 6| Step: 1
Training loss: 3.30150246951496
Validation loss: 2.6848121589367717

Epoch: 6| Step: 2
Training loss: 3.192521571577137
Validation loss: 2.6663146850597075

Epoch: 6| Step: 3
Training loss: 2.8441684959920623
Validation loss: 2.6566239327235444

Epoch: 6| Step: 4
Training loss: 3.4132063641129284
Validation loss: 2.6532921195723795

Epoch: 6| Step: 5
Training loss: 3.2902487747147204
Validation loss: 2.6502038310394562

Epoch: 6| Step: 6
Training loss: 3.365746422067642
Validation loss: 2.6333726771608617

Epoch: 6| Step: 7
Training loss: 2.851461497569122
Validation loss: 2.635480655657109

Epoch: 6| Step: 8
Training loss: 2.9015142762383306
Validation loss: 2.634633012730953

Epoch: 6| Step: 9
Training loss: 2.75167934119827
Validation loss: 2.6381916004274024

Epoch: 6| Step: 10
Training loss: 2.693844248811172
Validation loss: 2.636557737696053

Epoch: 6| Step: 11
Training loss: 2.5037324699287145
Validation loss: 2.633502754700195

Epoch: 6| Step: 12
Training loss: 2.7365173666493754
Validation loss: 2.6344188717819192

Epoch: 6| Step: 13
Training loss: 1.7541789159399956
Validation loss: 2.63661992223971

Epoch: 37| Step: 0
Training loss: 2.5571460151500642
Validation loss: 2.63442219989558

Epoch: 6| Step: 1
Training loss: 3.639375267493926
Validation loss: 2.631943510692855

Epoch: 6| Step: 2
Training loss: 2.951300163182024
Validation loss: 2.6325355078082864

Epoch: 6| Step: 3
Training loss: 3.1022158302173266
Validation loss: 2.6302365274216783

Epoch: 6| Step: 4
Training loss: 2.5880308408358808
Validation loss: 2.6298937079482276

Epoch: 6| Step: 5
Training loss: 3.1117863338638903
Validation loss: 2.626941662066643

Epoch: 6| Step: 6
Training loss: 2.670276185799376
Validation loss: 2.62867832443701

Epoch: 6| Step: 7
Training loss: 3.46020086642535
Validation loss: 2.634760117784852

Epoch: 6| Step: 8
Training loss: 3.06414283752167
Validation loss: 2.637089359758093

Epoch: 6| Step: 9
Training loss: 2.7878298987624035
Validation loss: 2.6371511992992667

Epoch: 6| Step: 10
Training loss: 2.505237528947412
Validation loss: 2.632405176011408

Epoch: 6| Step: 11
Training loss: 3.0472133350812625
Validation loss: 2.6367708678204886

Epoch: 6| Step: 12
Training loss: 3.1663600538956023
Validation loss: 2.633664914531984

Epoch: 6| Step: 13
Training loss: 2.5293709644674727
Validation loss: 2.6320962789485147

Epoch: 38| Step: 0
Training loss: 2.858429298977146
Validation loss: 2.6352702345790604

Epoch: 6| Step: 1
Training loss: 2.4576510328448107
Validation loss: 2.623582427903137

Epoch: 6| Step: 2
Training loss: 3.1505244227245077
Validation loss: 2.6303023584779863

Epoch: 6| Step: 3
Training loss: 2.739670513975446
Validation loss: 2.6392193891866036

Epoch: 6| Step: 4
Training loss: 3.215699759782987
Validation loss: 2.6503905718002057

Epoch: 6| Step: 5
Training loss: 2.8249823881967524
Validation loss: 2.6457549466190797

Epoch: 6| Step: 6
Training loss: 3.376864448119966
Validation loss: 2.651958218571208

Epoch: 6| Step: 7
Training loss: 2.6603469668234476
Validation loss: 2.6530105806363156

Epoch: 6| Step: 8
Training loss: 2.894836656775159
Validation loss: 2.674005161697013

Epoch: 6| Step: 9
Training loss: 3.2737452833470133
Validation loss: 2.685304267970076

Epoch: 6| Step: 10
Training loss: 3.092302696699917
Validation loss: 2.6695586937356235

Epoch: 6| Step: 11
Training loss: 3.014691302183515
Validation loss: 2.640104500405824

Epoch: 6| Step: 12
Training loss: 2.785979974394039
Validation loss: 2.6350613465217454

Epoch: 6| Step: 13
Training loss: 3.7234905384814843
Validation loss: 2.6362221420092733

Epoch: 39| Step: 0
Training loss: 2.6417714175405447
Validation loss: 2.6389567136728753

Epoch: 6| Step: 1
Training loss: 2.6615664067631046
Validation loss: 2.636299905206932

Epoch: 6| Step: 2
Training loss: 3.467116512553493
Validation loss: 2.6390759110540296

Epoch: 6| Step: 3
Training loss: 3.573953787566255
Validation loss: 2.6339936405069952

Epoch: 6| Step: 4
Training loss: 2.8767727900880558
Validation loss: 2.6324633129450614

Epoch: 6| Step: 5
Training loss: 2.997184067621653
Validation loss: 2.629807994634848

Epoch: 6| Step: 6
Training loss: 3.3511168710516896
Validation loss: 2.6292103774308577

Epoch: 6| Step: 7
Training loss: 2.3863976694958233
Validation loss: 2.628750155138312

Epoch: 6| Step: 8
Training loss: 2.907005457980265
Validation loss: 2.6331924150248702

Epoch: 6| Step: 9
Training loss: 2.7178727411789634
Validation loss: 2.637986994234174

Epoch: 6| Step: 10
Training loss: 2.9338357675739437
Validation loss: 2.638543296928662

Epoch: 6| Step: 11
Training loss: 3.001278763664602
Validation loss: 2.6878035894474372

Epoch: 6| Step: 12
Training loss: 3.3219162601983974
Validation loss: 2.754859452965513

Epoch: 6| Step: 13
Training loss: 2.599844333683693
Validation loss: 2.7367142860116918

Epoch: 40| Step: 0
Training loss: 3.9311113148108126
Validation loss: 2.7084223178099944

Epoch: 6| Step: 1
Training loss: 2.98998942701837
Validation loss: 2.666780464246372

Epoch: 6| Step: 2
Training loss: 2.661200543862819
Validation loss: 2.6439533726475033

Epoch: 6| Step: 3
Training loss: 3.1632084953776745
Validation loss: 2.638818695726603

Epoch: 6| Step: 4
Training loss: 2.5344739563010816
Validation loss: 2.652295277704879

Epoch: 6| Step: 5
Training loss: 3.491452542994871
Validation loss: 2.6601041932956178

Epoch: 6| Step: 6
Training loss: 3.353118321962275
Validation loss: 2.644117453146602

Epoch: 6| Step: 7
Training loss: 2.973606995218386
Validation loss: 2.6399618686139084

Epoch: 6| Step: 8
Training loss: 2.4580243018790373
Validation loss: 2.6395674804669356

Epoch: 6| Step: 9
Training loss: 2.9318047362564315
Validation loss: 2.638528906342371

Epoch: 6| Step: 10
Training loss: 2.9133028160027394
Validation loss: 2.635040513817413

Epoch: 6| Step: 11
Training loss: 3.018534309468986
Validation loss: 2.633109955823581

Epoch: 6| Step: 12
Training loss: 2.5806927465081704
Validation loss: 2.6423295508377422

Epoch: 6| Step: 13
Training loss: 2.3968206168200963
Validation loss: 2.641779716600839

Epoch: 41| Step: 0
Training loss: 2.8493200394471003
Validation loss: 2.647239472898292

Epoch: 6| Step: 1
Training loss: 2.7707632146773356
Validation loss: 2.6442761368964662

Epoch: 6| Step: 2
Training loss: 2.4956839498182397
Validation loss: 2.6418933097940633

Epoch: 6| Step: 3
Training loss: 3.6518235759258
Validation loss: 2.643646165312748

Epoch: 6| Step: 4
Training loss: 2.56758515615123
Validation loss: 2.6402939867307795

Epoch: 6| Step: 5
Training loss: 3.5857375012310055
Validation loss: 2.642466910996755

Epoch: 6| Step: 6
Training loss: 2.908501030168749
Validation loss: 2.644629899414628

Epoch: 6| Step: 7
Training loss: 3.237747571750909
Validation loss: 2.65913520195437

Epoch: 6| Step: 8
Training loss: 2.8906348975759606
Validation loss: 2.6669254304010765

Epoch: 6| Step: 9
Training loss: 3.0570310690626545
Validation loss: 2.6667530375254915

Epoch: 6| Step: 10
Training loss: 3.037449268812223
Validation loss: 2.6415162048263294

Epoch: 6| Step: 11
Training loss: 2.854675433253951
Validation loss: 2.634627281435667

Epoch: 6| Step: 12
Training loss: 2.6634009650200947
Validation loss: 2.6324821005112207

Epoch: 6| Step: 13
Training loss: 3.19221521814592
Validation loss: 2.6316102520166087

Epoch: 42| Step: 0
Training loss: 3.1949674611233085
Validation loss: 2.6333643564733578

Epoch: 6| Step: 1
Training loss: 2.8774862734204563
Validation loss: 2.6329527002976367

Epoch: 6| Step: 2
Training loss: 2.2912203151779895
Validation loss: 2.6345603420973105

Epoch: 6| Step: 3
Training loss: 2.618519094115286
Validation loss: 2.631795964508318

Epoch: 6| Step: 4
Training loss: 3.3522257115339555
Validation loss: 2.630474758797659

Epoch: 6| Step: 5
Training loss: 3.117839697200837
Validation loss: 2.632445720174592

Epoch: 6| Step: 6
Training loss: 2.719632586459883
Validation loss: 2.617883383115129

Epoch: 6| Step: 7
Training loss: 3.2540957245723696
Validation loss: 2.6146897184558484

Epoch: 6| Step: 8
Training loss: 2.7316674478687646
Validation loss: 2.6116377920346894

Epoch: 6| Step: 9
Training loss: 3.2744069268580915
Validation loss: 2.6091519091483204

Epoch: 6| Step: 10
Training loss: 3.2685755491659463
Validation loss: 2.605598102237975

Epoch: 6| Step: 11
Training loss: 2.6503573410654186
Validation loss: 2.603364638997361

Epoch: 6| Step: 12
Training loss: 3.2285419146880314
Validation loss: 2.601954045286554

Epoch: 6| Step: 13
Training loss: 2.8601408386232055
Validation loss: 2.5999116866413794

Epoch: 43| Step: 0
Training loss: 2.6867751097584405
Validation loss: 2.5998860896662204

Epoch: 6| Step: 1
Training loss: 3.2332744107989573
Validation loss: 2.607717737262981

Epoch: 6| Step: 2
Training loss: 2.3923130433510775
Validation loss: 2.637261094769717

Epoch: 6| Step: 3
Training loss: 2.9450351574390834
Validation loss: 2.700396123265068

Epoch: 6| Step: 4
Training loss: 3.0088388252538523
Validation loss: 2.7182139244276513

Epoch: 6| Step: 5
Training loss: 3.4988515877157935
Validation loss: 2.7027514473026217

Epoch: 6| Step: 6
Training loss: 3.406683098093358
Validation loss: 2.6655432471521423

Epoch: 6| Step: 7
Training loss: 2.196808220620274
Validation loss: 2.612354008789121

Epoch: 6| Step: 8
Training loss: 2.713939049460133
Validation loss: 2.5933654041407186

Epoch: 6| Step: 9
Training loss: 2.9787507911773923
Validation loss: 2.5937953736949466

Epoch: 6| Step: 10
Training loss: 3.1551248792306206
Validation loss: 2.6051593681759404

Epoch: 6| Step: 11
Training loss: 2.858903856494855
Validation loss: 2.610020099507966

Epoch: 6| Step: 12
Training loss: 3.2514700865914516
Validation loss: 2.6065261947468055

Epoch: 6| Step: 13
Training loss: 3.019835226098544
Validation loss: 2.59965680805943

Epoch: 44| Step: 0
Training loss: 2.906157133197879
Validation loss: 2.600035297778936

Epoch: 6| Step: 1
Training loss: 3.0643963294908145
Validation loss: 2.6028429229806376

Epoch: 6| Step: 2
Training loss: 3.27210173745766
Validation loss: 2.607065966416098

Epoch: 6| Step: 3
Training loss: 3.139719362777819
Validation loss: 2.6105407032749555

Epoch: 6| Step: 4
Training loss: 2.93621522118769
Validation loss: 2.6012561226846977

Epoch: 6| Step: 5
Training loss: 2.7751521438268423
Validation loss: 2.598569817569538

Epoch: 6| Step: 6
Training loss: 2.8266744529269
Validation loss: 2.5949409637700214

Epoch: 6| Step: 7
Training loss: 3.0127236437586022
Validation loss: 2.591868254056407

Epoch: 6| Step: 8
Training loss: 2.4543799816573535
Validation loss: 2.5897406724887717

Epoch: 6| Step: 9
Training loss: 2.2800097294650032
Validation loss: 2.592598182578522

Epoch: 6| Step: 10
Training loss: 3.0264828349959134
Validation loss: 2.5967541803867613

Epoch: 6| Step: 11
Training loss: 3.604027820771914
Validation loss: 2.5938857401696005

Epoch: 6| Step: 12
Training loss: 2.627343357981126
Validation loss: 2.590496811837894

Epoch: 6| Step: 13
Training loss: 3.334285997312984
Validation loss: 2.5834801228949087

Epoch: 45| Step: 0
Training loss: 3.297107561776804
Validation loss: 2.5826325797573966

Epoch: 6| Step: 1
Training loss: 2.681015797592341
Validation loss: 2.5840944223585494

Epoch: 6| Step: 2
Training loss: 2.7269948709437584
Validation loss: 2.5800087349742125

Epoch: 6| Step: 3
Training loss: 3.3140284053158378
Validation loss: 2.5795640853715045

Epoch: 6| Step: 4
Training loss: 2.5308999655498274
Validation loss: 2.578206064709207

Epoch: 6| Step: 5
Training loss: 2.481855158192177
Validation loss: 2.587189188072216

Epoch: 6| Step: 6
Training loss: 2.6950372085408993
Validation loss: 2.597753075445032

Epoch: 6| Step: 7
Training loss: 2.408616227779126
Validation loss: 2.6072286908734177

Epoch: 6| Step: 8
Training loss: 3.0890176973388574
Validation loss: 2.6239707401669174

Epoch: 6| Step: 9
Training loss: 3.0590687428008465
Validation loss: 2.588431638360522

Epoch: 6| Step: 10
Training loss: 3.5102761501786004
Validation loss: 2.580061844336273

Epoch: 6| Step: 11
Training loss: 3.360638757797779
Validation loss: 2.5868453974405177

Epoch: 6| Step: 12
Training loss: 3.2828927423837055
Validation loss: 2.5821141181947334

Epoch: 6| Step: 13
Training loss: 1.8464933126841352
Validation loss: 2.578443426142143

Epoch: 46| Step: 0
Training loss: 3.157804200899071
Validation loss: 2.581401006664504

Epoch: 6| Step: 1
Training loss: 2.5141573587543915
Validation loss: 2.58181150395931

Epoch: 6| Step: 2
Training loss: 3.1831070791264717
Validation loss: 2.582751759083739

Epoch: 6| Step: 3
Training loss: 2.947344900876326
Validation loss: 2.5931232904552597

Epoch: 6| Step: 4
Training loss: 2.743666290883197
Validation loss: 2.6015436783444503

Epoch: 6| Step: 5
Training loss: 2.7883399860996643
Validation loss: 2.616421209025247

Epoch: 6| Step: 6
Training loss: 2.7989000203388006
Validation loss: 2.609153075443293

Epoch: 6| Step: 7
Training loss: 2.9666698998708645
Validation loss: 2.6093938761865867

Epoch: 6| Step: 8
Training loss: 3.1459557381030514
Validation loss: 2.599079461102463

Epoch: 6| Step: 9
Training loss: 2.7049476784883244
Validation loss: 2.5893415696287367

Epoch: 6| Step: 10
Training loss: 2.1592121510025617
Validation loss: 2.5801863696741867

Epoch: 6| Step: 11
Training loss: 3.139261889355671
Validation loss: 2.5765778832555433

Epoch: 6| Step: 12
Training loss: 3.629129622599192
Validation loss: 2.5721690949437406

Epoch: 6| Step: 13
Training loss: 2.871579831036077
Validation loss: 2.5698339367913543

Epoch: 47| Step: 0
Training loss: 3.2187092602568175
Validation loss: 2.5718874095507265

Epoch: 6| Step: 1
Training loss: 3.002145476870572
Validation loss: 2.569491927212497

Epoch: 6| Step: 2
Training loss: 2.4991762711545094
Validation loss: 2.5671132468159072

Epoch: 6| Step: 3
Training loss: 3.2233453926983815
Validation loss: 2.5675237444062557

Epoch: 6| Step: 4
Training loss: 2.710940138406047
Validation loss: 2.5674224293646803

Epoch: 6| Step: 5
Training loss: 2.728939910864542
Validation loss: 2.5688331731258205

Epoch: 6| Step: 6
Training loss: 3.4304153956010857
Validation loss: 2.5624302940382053

Epoch: 6| Step: 7
Training loss: 2.7322680393893646
Validation loss: 2.574557274825315

Epoch: 6| Step: 8
Training loss: 3.0587493350235215
Validation loss: 2.598020619477019

Epoch: 6| Step: 9
Training loss: 3.1735017861072303
Validation loss: 2.6180346290196885

Epoch: 6| Step: 10
Training loss: 3.0325891741718327
Validation loss: 2.6281539195703902

Epoch: 6| Step: 11
Training loss: 2.6939908975392197
Validation loss: 2.591469197412676

Epoch: 6| Step: 12
Training loss: 2.6613659229895097
Validation loss: 2.5794365652610893

Epoch: 6| Step: 13
Training loss: 2.7914608172537
Validation loss: 2.573955136172055

Epoch: 48| Step: 0
Training loss: 3.1802468147702694
Validation loss: 2.5660833789765203

Epoch: 6| Step: 1
Training loss: 3.1193622851929494
Validation loss: 2.56412594481466

Epoch: 6| Step: 2
Training loss: 2.877784044446304
Validation loss: 2.5587620017058597

Epoch: 6| Step: 3
Training loss: 3.1699248835090468
Validation loss: 2.5659447103554247

Epoch: 6| Step: 4
Training loss: 2.881385346582947
Validation loss: 2.563530603389033

Epoch: 6| Step: 5
Training loss: 2.7960981430270744
Validation loss: 2.5643151100257544

Epoch: 6| Step: 6
Training loss: 2.9369706021773863
Validation loss: 2.5633891994201945

Epoch: 6| Step: 7
Training loss: 3.070206890279724
Validation loss: 2.566871388020036

Epoch: 6| Step: 8
Training loss: 1.9684323856949246
Validation loss: 2.5657189253372876

Epoch: 6| Step: 9
Training loss: 3.103345997173668
Validation loss: 2.56732355032075

Epoch: 6| Step: 10
Training loss: 3.185359759890044
Validation loss: 2.5597489368811517

Epoch: 6| Step: 11
Training loss: 2.5892696060656775
Validation loss: 2.5578738076025616

Epoch: 6| Step: 12
Training loss: 2.5634367556433113
Validation loss: 2.5611884119259596

Epoch: 6| Step: 13
Training loss: 3.547097220160454
Validation loss: 2.562172877583548

Epoch: 49| Step: 0
Training loss: 3.5340438188427963
Validation loss: 2.5681613917709885

Epoch: 6| Step: 1
Training loss: 2.872278335026448
Validation loss: 2.584121324580328

Epoch: 6| Step: 2
Training loss: 2.66904500362663
Validation loss: 2.585925846329494

Epoch: 6| Step: 3
Training loss: 2.9590369090839825
Validation loss: 2.5994816380105443

Epoch: 6| Step: 4
Training loss: 2.4826339282954764
Validation loss: 2.5992115250967722

Epoch: 6| Step: 5
Training loss: 2.7428401159569766
Validation loss: 2.6288399539200586

Epoch: 6| Step: 6
Training loss: 2.720115669399618
Validation loss: 2.6034801712048776

Epoch: 6| Step: 7
Training loss: 2.9819319546852587
Validation loss: 2.5735315474358886

Epoch: 6| Step: 8
Training loss: 3.1446768211646665
Validation loss: 2.5672546144269126

Epoch: 6| Step: 9
Training loss: 2.7159904418462513
Validation loss: 2.561961882099784

Epoch: 6| Step: 10
Training loss: 3.3190263478657633
Validation loss: 2.559751567873743

Epoch: 6| Step: 11
Training loss: 2.3704151269652134
Validation loss: 2.5597311988928833

Epoch: 6| Step: 12
Training loss: 3.3043521503533673
Validation loss: 2.5613239529932814

Epoch: 6| Step: 13
Training loss: 3.008497442557903
Validation loss: 2.562374160922197

Epoch: 50| Step: 0
Training loss: 2.8574746075534074
Validation loss: 2.5682933726369557

Epoch: 6| Step: 1
Training loss: 3.6290301577927724
Validation loss: 2.5657632290383856

Epoch: 6| Step: 2
Training loss: 2.694086652991946
Validation loss: 2.5635263362023326

Epoch: 6| Step: 3
Training loss: 3.2715009910958623
Validation loss: 2.5644028584380805

Epoch: 6| Step: 4
Training loss: 2.9534153063945983
Validation loss: 2.564192640321312

Epoch: 6| Step: 5
Training loss: 2.925576868800201
Validation loss: 2.579933555868607

Epoch: 6| Step: 6
Training loss: 2.9228884321513537
Validation loss: 2.5919978735708815

Epoch: 6| Step: 7
Training loss: 2.3486104793636717
Validation loss: 2.5814573944018138

Epoch: 6| Step: 8
Training loss: 2.661847488608674
Validation loss: 2.56117145164668

Epoch: 6| Step: 9
Training loss: 2.8432690559566374
Validation loss: 2.5561028060738167

Epoch: 6| Step: 10
Training loss: 3.3167212598387446
Validation loss: 2.5583104456218817

Epoch: 6| Step: 11
Training loss: 2.6150012549840422
Validation loss: 2.560530732468629

Epoch: 6| Step: 12
Training loss: 3.107828186824098
Validation loss: 2.562412629637663

Epoch: 6| Step: 13
Training loss: 2.326269652187799
Validation loss: 2.559523678033741

Epoch: 51| Step: 0
Training loss: 3.10191531540795
Validation loss: 2.560139941622512

Epoch: 6| Step: 1
Training loss: 2.7959738190588967
Validation loss: 2.573368415632699

Epoch: 6| Step: 2
Training loss: 2.849645853626178
Validation loss: 2.5695369001710726

Epoch: 6| Step: 3
Training loss: 2.5803074702310527
Validation loss: 2.588392790731817

Epoch: 6| Step: 4
Training loss: 2.0531574542820565
Validation loss: 2.581962911325653

Epoch: 6| Step: 5
Training loss: 2.8789575952638047
Validation loss: 2.5809348318422525

Epoch: 6| Step: 6
Training loss: 2.7753518817943683
Validation loss: 2.5803143008147114

Epoch: 6| Step: 7
Training loss: 3.093095035773972
Validation loss: 2.57744964176278

Epoch: 6| Step: 8
Training loss: 3.175346091323372
Validation loss: 2.568560443021209

Epoch: 6| Step: 9
Training loss: 2.9641453419210446
Validation loss: 2.561326650429452

Epoch: 6| Step: 10
Training loss: 3.2919824826966857
Validation loss: 2.560972448251672

Epoch: 6| Step: 11
Training loss: 3.1975072211332405
Validation loss: 2.5656804982013655

Epoch: 6| Step: 12
Training loss: 2.825676295256364
Validation loss: 2.5605241334549995

Epoch: 6| Step: 13
Training loss: 3.2164562163086665
Validation loss: 2.558769628207825

Epoch: 52| Step: 0
Training loss: 3.0850204457203674
Validation loss: 2.552947760907393

Epoch: 6| Step: 1
Training loss: 2.7610035878137076
Validation loss: 2.5515922758707843

Epoch: 6| Step: 2
Training loss: 3.106617073460017
Validation loss: 2.556465516887666

Epoch: 6| Step: 3
Training loss: 3.2433104994604887
Validation loss: 2.556968613089029

Epoch: 6| Step: 4
Training loss: 3.398157147649601
Validation loss: 2.564999030864099

Epoch: 6| Step: 5
Training loss: 2.5429109018897913
Validation loss: 2.572589574651696

Epoch: 6| Step: 6
Training loss: 2.8047915468601032
Validation loss: 2.5973446130078504

Epoch: 6| Step: 7
Training loss: 2.6322218235191444
Validation loss: 2.6126942785246725

Epoch: 6| Step: 8
Training loss: 2.950129205492797
Validation loss: 2.6337651730707496

Epoch: 6| Step: 9
Training loss: 3.2224416950358115
Validation loss: 2.580167779587188

Epoch: 6| Step: 10
Training loss: 2.884025339277166
Validation loss: 2.5529349745439363

Epoch: 6| Step: 11
Training loss: 2.9646156836482866
Validation loss: 2.5481044756783855

Epoch: 6| Step: 12
Training loss: 2.5005438213143223
Validation loss: 2.5508708167077283

Epoch: 6| Step: 13
Training loss: 2.1615354470587804
Validation loss: 2.5543888054527715

Epoch: 53| Step: 0
Training loss: 3.234467878252053
Validation loss: 2.5649551017644234

Epoch: 6| Step: 1
Training loss: 3.12226045689942
Validation loss: 2.5871858368529526

Epoch: 6| Step: 2
Training loss: 3.060948348598134
Validation loss: 2.577576570918847

Epoch: 6| Step: 3
Training loss: 2.6415324260245714
Validation loss: 2.5529739871622326

Epoch: 6| Step: 4
Training loss: 2.373964786785795
Validation loss: 2.551749012696612

Epoch: 6| Step: 5
Training loss: 2.9799820288813916
Validation loss: 2.5572869052036054

Epoch: 6| Step: 6
Training loss: 2.232284528323633
Validation loss: 2.584583419301977

Epoch: 6| Step: 7
Training loss: 2.768790120335731
Validation loss: 2.6330736075289596

Epoch: 6| Step: 8
Training loss: 3.3294359947247445
Validation loss: 2.7145549227168813

Epoch: 6| Step: 9
Training loss: 2.5213315697308603
Validation loss: 2.700418240350331

Epoch: 6| Step: 10
Training loss: 3.0855293873234495
Validation loss: 2.6803610158672493

Epoch: 6| Step: 11
Training loss: 3.370641083455277
Validation loss: 2.6383507338696126

Epoch: 6| Step: 12
Training loss: 3.189505899603567
Validation loss: 2.5855612854624885

Epoch: 6| Step: 13
Training loss: 2.8136801045234017
Validation loss: 2.5548907176531306

Epoch: 54| Step: 0
Training loss: 2.8212506115684133
Validation loss: 2.553143695658369

Epoch: 6| Step: 1
Training loss: 3.426297191363073
Validation loss: 2.5494521003436175

Epoch: 6| Step: 2
Training loss: 3.4003415441065843
Validation loss: 2.5584927151077412

Epoch: 6| Step: 3
Training loss: 3.096029963523315
Validation loss: 2.5602744297406606

Epoch: 6| Step: 4
Training loss: 3.1374699321385124
Validation loss: 2.562030873349121

Epoch: 6| Step: 5
Training loss: 2.495773748621674
Validation loss: 2.5693285040032414

Epoch: 6| Step: 6
Training loss: 2.5608481688917464
Validation loss: 2.582307955086534

Epoch: 6| Step: 7
Training loss: 2.896894429788788
Validation loss: 2.584869449718007

Epoch: 6| Step: 8
Training loss: 3.0639212288354916
Validation loss: 2.5757207315226043

Epoch: 6| Step: 9
Training loss: 2.5103680195718248
Validation loss: 2.565463056995721

Epoch: 6| Step: 10
Training loss: 3.0074741718201072
Validation loss: 2.5653330541149475

Epoch: 6| Step: 11
Training loss: 3.062725136714283
Validation loss: 2.5691785902289506

Epoch: 6| Step: 12
Training loss: 2.5388217283678305
Validation loss: 2.5674525497551803

Epoch: 6| Step: 13
Training loss: 2.3332120886591694
Validation loss: 2.5636452167462425

Epoch: 55| Step: 0
Training loss: 3.2977701571885745
Validation loss: 2.5665147037078317

Epoch: 6| Step: 1
Training loss: 3.012846462223331
Validation loss: 2.5818161957003523

Epoch: 6| Step: 2
Training loss: 3.2178429371762323
Validation loss: 2.5905825818935115

Epoch: 6| Step: 3
Training loss: 3.463269277010237
Validation loss: 2.6095583033847976

Epoch: 6| Step: 4
Training loss: 2.5466773769725983
Validation loss: 2.5607793590165726

Epoch: 6| Step: 5
Training loss: 2.883907782012769
Validation loss: 2.5504145001258665

Epoch: 6| Step: 6
Training loss: 2.5976511101922837
Validation loss: 2.5443078279154143

Epoch: 6| Step: 7
Training loss: 2.6604573755776704
Validation loss: 2.542800499795414

Epoch: 6| Step: 8
Training loss: 2.264974566521069
Validation loss: 2.544716174800402

Epoch: 6| Step: 9
Training loss: 2.734344831027766
Validation loss: 2.547915897421757

Epoch: 6| Step: 10
Training loss: 2.813006969959942
Validation loss: 2.545502384944748

Epoch: 6| Step: 11
Training loss: 3.168482577684904
Validation loss: 2.5477858288134856

Epoch: 6| Step: 12
Training loss: 3.275701864032557
Validation loss: 2.5473620665371213

Epoch: 6| Step: 13
Training loss: 2.671054111665252
Validation loss: 2.547243726874282

Epoch: 56| Step: 0
Training loss: 2.6987860811762543
Validation loss: 2.5449433376223283

Epoch: 6| Step: 1
Training loss: 3.0950542744698457
Validation loss: 2.5411125314007768

Epoch: 6| Step: 2
Training loss: 3.1357256123530317
Validation loss: 2.5424987964605297

Epoch: 6| Step: 3
Training loss: 3.1439915164221537
Validation loss: 2.5479670672743158

Epoch: 6| Step: 4
Training loss: 3.305704451839668
Validation loss: 2.5512765164482563

Epoch: 6| Step: 5
Training loss: 2.972258091251623
Validation loss: 2.548830607341569

Epoch: 6| Step: 6
Training loss: 2.815624620647172
Validation loss: 2.5472580403827596

Epoch: 6| Step: 7
Training loss: 2.972821144613535
Validation loss: 2.556435215902183

Epoch: 6| Step: 8
Training loss: 3.0617609494691673
Validation loss: 2.5718915861120726

Epoch: 6| Step: 9
Training loss: 2.299939867975089
Validation loss: 2.5670365435677787

Epoch: 6| Step: 10
Training loss: 2.468091756249521
Validation loss: 2.5836745975195003

Epoch: 6| Step: 11
Training loss: 3.0968466009691347
Validation loss: 2.6000189695305207

Epoch: 6| Step: 12
Training loss: 2.810320709226706
Validation loss: 2.597332064945509

Epoch: 6| Step: 13
Training loss: 2.5117429551164077
Validation loss: 2.5913366898701256

Epoch: 57| Step: 0
Training loss: 2.8029932201628767
Validation loss: 2.5665615073096095

Epoch: 6| Step: 1
Training loss: 2.9022482937175154
Validation loss: 2.5566035053762834

Epoch: 6| Step: 2
Training loss: 2.844377050329889
Validation loss: 2.5417940184186167

Epoch: 6| Step: 3
Training loss: 2.9089049651042744
Validation loss: 2.5386161206098707

Epoch: 6| Step: 4
Training loss: 2.8887925396852765
Validation loss: 2.5356779555403346

Epoch: 6| Step: 5
Training loss: 3.0715893136225194
Validation loss: 2.5414846564580857

Epoch: 6| Step: 6
Training loss: 3.0723297248259858
Validation loss: 2.536809688005963

Epoch: 6| Step: 7
Training loss: 2.78488436063324
Validation loss: 2.5392502955552096

Epoch: 6| Step: 8
Training loss: 2.89430126764317
Validation loss: 2.537494068349972

Epoch: 6| Step: 9
Training loss: 2.5639729802081193
Validation loss: 2.5431717690025835

Epoch: 6| Step: 10
Training loss: 3.3363162681083947
Validation loss: 2.54132304112129

Epoch: 6| Step: 11
Training loss: 3.24240398373645
Validation loss: 2.5444890204127075

Epoch: 6| Step: 12
Training loss: 2.2721450120491933
Validation loss: 2.537469708791135

Epoch: 6| Step: 13
Training loss: 3.026346231826851
Validation loss: 2.5423376837330327

Epoch: 58| Step: 0
Training loss: 2.3353010350327117
Validation loss: 2.540776743660461

Epoch: 6| Step: 1
Training loss: 3.500569842135067
Validation loss: 2.543679667906417

Epoch: 6| Step: 2
Training loss: 3.002084008207296
Validation loss: 2.5470847531578262

Epoch: 6| Step: 3
Training loss: 2.7386678947840943
Validation loss: 2.5479145395928104

Epoch: 6| Step: 4
Training loss: 2.829452456018072
Validation loss: 2.546008258184211

Epoch: 6| Step: 5
Training loss: 2.2876797298010443
Validation loss: 2.551608273002705

Epoch: 6| Step: 6
Training loss: 3.384046510092718
Validation loss: 2.5581662146871027

Epoch: 6| Step: 7
Training loss: 2.345968290233378
Validation loss: 2.552571997068091

Epoch: 6| Step: 8
Training loss: 2.5173901353821746
Validation loss: 2.5404546387244897

Epoch: 6| Step: 9
Training loss: 3.036065906708939
Validation loss: 2.5461182956456168

Epoch: 6| Step: 10
Training loss: 3.2774604349199734
Validation loss: 2.5340805614428006

Epoch: 6| Step: 11
Training loss: 2.8246731425554654
Validation loss: 2.537201201674837

Epoch: 6| Step: 12
Training loss: 3.0904230281302674
Validation loss: 2.537745778686275

Epoch: 6| Step: 13
Training loss: 2.9819959175189372
Validation loss: 2.5342726683347117

Epoch: 59| Step: 0
Training loss: 2.673795489494496
Validation loss: 2.541529149599008

Epoch: 6| Step: 1
Training loss: 3.1701860112149767
Validation loss: 2.547486938908732

Epoch: 6| Step: 2
Training loss: 3.0560051693198536
Validation loss: 2.541346839183197

Epoch: 6| Step: 3
Training loss: 2.443748876078706
Validation loss: 2.5493303999007155

Epoch: 6| Step: 4
Training loss: 2.7425511654277326
Validation loss: 2.5502839703839633

Epoch: 6| Step: 5
Training loss: 3.346409960725694
Validation loss: 2.5522470505022716

Epoch: 6| Step: 6
Training loss: 2.994559441007565
Validation loss: 2.5489802549810583

Epoch: 6| Step: 7
Training loss: 2.461323831902898
Validation loss: 2.5439194829326786

Epoch: 6| Step: 8
Training loss: 2.811107884364565
Validation loss: 2.5381182625161047

Epoch: 6| Step: 9
Training loss: 2.5853034679910296
Validation loss: 2.5375457903407304

Epoch: 6| Step: 10
Training loss: 3.067546812165092
Validation loss: 2.5388473300933168

Epoch: 6| Step: 11
Training loss: 3.1940096038597536
Validation loss: 2.5402984352351132

Epoch: 6| Step: 12
Training loss: 2.86427412734017
Validation loss: 2.540905563809582

Epoch: 6| Step: 13
Training loss: 2.681888043797069
Validation loss: 2.5412763658682374

Epoch: 60| Step: 0
Training loss: 3.0282146554750358
Validation loss: 2.545335840198921

Epoch: 6| Step: 1
Training loss: 3.056630172955373
Validation loss: 2.5386786067959677

Epoch: 6| Step: 2
Training loss: 2.8346088754547143
Validation loss: 2.541177919164725

Epoch: 6| Step: 3
Training loss: 3.3249373236463806
Validation loss: 2.537806376052817

Epoch: 6| Step: 4
Training loss: 3.0152261895252606
Validation loss: 2.5325048818327507

Epoch: 6| Step: 5
Training loss: 2.8982869646407923
Validation loss: 2.5337400333655675

Epoch: 6| Step: 6
Training loss: 3.173973554360417
Validation loss: 2.5400351282774585

Epoch: 6| Step: 7
Training loss: 2.8193225761178886
Validation loss: 2.532760965208983

Epoch: 6| Step: 8
Training loss: 3.0292971898170373
Validation loss: 2.534837174928648

Epoch: 6| Step: 9
Training loss: 2.198948791088059
Validation loss: 2.532872613609737

Epoch: 6| Step: 10
Training loss: 2.8421604618675946
Validation loss: 2.5381286872788325

Epoch: 6| Step: 11
Training loss: 2.447819798494092
Validation loss: 2.539671780896239

Epoch: 6| Step: 12
Training loss: 2.563748962461651
Validation loss: 2.540226273176853

Epoch: 6| Step: 13
Training loss: 2.8517442619190425
Validation loss: 2.5557526586292387

Epoch: 61| Step: 0
Training loss: 3.512208083433823
Validation loss: 2.5533300157836725

Epoch: 6| Step: 1
Training loss: 2.916445660165176
Validation loss: 2.5433532818289715

Epoch: 6| Step: 2
Training loss: 2.356322581339474
Validation loss: 2.545575812406613

Epoch: 6| Step: 3
Training loss: 2.5202094532948176
Validation loss: 2.5474932879063923

Epoch: 6| Step: 4
Training loss: 2.7175784162702428
Validation loss: 2.5447755776160172

Epoch: 6| Step: 5
Training loss: 2.3634341860380625
Validation loss: 2.541840133987622

Epoch: 6| Step: 6
Training loss: 2.9179153131088467
Validation loss: 2.539750937754209

Epoch: 6| Step: 7
Training loss: 3.4490279666588557
Validation loss: 2.542878343413484

Epoch: 6| Step: 8
Training loss: 2.8809312093798267
Validation loss: 2.5458374648009214

Epoch: 6| Step: 9
Training loss: 3.096555728410259
Validation loss: 2.5449355991721188

Epoch: 6| Step: 10
Training loss: 2.9381865652743016
Validation loss: 2.541819098017155

Epoch: 6| Step: 11
Training loss: 2.649530955856387
Validation loss: 2.547894615294109

Epoch: 6| Step: 12
Training loss: 3.110037268265054
Validation loss: 2.575801537484433

Epoch: 6| Step: 13
Training loss: 2.706120765895228
Validation loss: 2.5811729166779616

Epoch: 62| Step: 0
Training loss: 2.8424106000733214
Validation loss: 2.5943315854448756

Epoch: 6| Step: 1
Training loss: 2.5688484451475455
Validation loss: 2.6163645450053847

Epoch: 6| Step: 2
Training loss: 2.6810155308069783
Validation loss: 2.6126601257882056

Epoch: 6| Step: 3
Training loss: 2.8520403735926565
Validation loss: 2.5968635434540563

Epoch: 6| Step: 4
Training loss: 3.2604428291286753
Validation loss: 2.5547016533895492

Epoch: 6| Step: 5
Training loss: 3.2533914037378793
Validation loss: 2.537481784032807

Epoch: 6| Step: 6
Training loss: 3.01167109311962
Validation loss: 2.534674371603054

Epoch: 6| Step: 7
Training loss: 3.029910391310297
Validation loss: 2.54021008325922

Epoch: 6| Step: 8
Training loss: 2.168848467523572
Validation loss: 2.5487848505987345

Epoch: 6| Step: 9
Training loss: 3.2043612443819547
Validation loss: 2.5464409728188175

Epoch: 6| Step: 10
Training loss: 3.0361797713178587
Validation loss: 2.543271523531514

Epoch: 6| Step: 11
Training loss: 3.06483028271799
Validation loss: 2.545336151421077

Epoch: 6| Step: 12
Training loss: 3.022534297120631
Validation loss: 2.5453181055091183

Epoch: 6| Step: 13
Training loss: 2.76326776252628
Validation loss: 2.5389868980744668

Epoch: 63| Step: 0
Training loss: 2.3480922909718407
Validation loss: 2.535376906195474

Epoch: 6| Step: 1
Training loss: 2.6065817861891962
Validation loss: 2.535205237831437

Epoch: 6| Step: 2
Training loss: 3.1087185727483893
Validation loss: 2.5378339512849983

Epoch: 6| Step: 3
Training loss: 3.4296004647092904
Validation loss: 2.5595711007513953

Epoch: 6| Step: 4
Training loss: 2.58814755873716
Validation loss: 2.587114129431351

Epoch: 6| Step: 5
Training loss: 2.684545800633821
Validation loss: 2.574669533341932

Epoch: 6| Step: 6
Training loss: 2.2657285469333415
Validation loss: 2.565821683973569

Epoch: 6| Step: 7
Training loss: 2.5701492396858616
Validation loss: 2.568431406404172

Epoch: 6| Step: 8
Training loss: 3.083309396874246
Validation loss: 2.5616428563413978

Epoch: 6| Step: 9
Training loss: 2.8851695775484214
Validation loss: 2.5518079403593608

Epoch: 6| Step: 10
Training loss: 3.064981972919862
Validation loss: 2.542461534901001

Epoch: 6| Step: 11
Training loss: 3.006530488504666
Validation loss: 2.547839012173728

Epoch: 6| Step: 12
Training loss: 3.0206532040965817
Validation loss: 2.5460082063275475

Epoch: 6| Step: 13
Training loss: 3.9349796766752387
Validation loss: 2.553057221126134

Epoch: 64| Step: 0
Training loss: 3.2345200658138364
Validation loss: 2.566714280196511

Epoch: 6| Step: 1
Training loss: 3.231226766417923
Validation loss: 2.5596074131366686

Epoch: 6| Step: 2
Training loss: 2.6081869195991993
Validation loss: 2.5279269498030237

Epoch: 6| Step: 3
Training loss: 3.3332062379131133
Validation loss: 2.5189848220576945

Epoch: 6| Step: 4
Training loss: 2.4626211068827564
Validation loss: 2.5342752650806033

Epoch: 6| Step: 5
Training loss: 3.5112728052155795
Validation loss: 2.6217336123514943

Epoch: 6| Step: 6
Training loss: 3.08134949931657
Validation loss: 2.5682863962887987

Epoch: 6| Step: 7
Training loss: 2.4876395794990547
Validation loss: 2.546638502450474

Epoch: 6| Step: 8
Training loss: 2.835838799558698
Validation loss: 2.52162946575266

Epoch: 6| Step: 9
Training loss: 2.8739323499518235
Validation loss: 2.5289261254525033

Epoch: 6| Step: 10
Training loss: 2.9613317061134525
Validation loss: 2.5321995341604646

Epoch: 6| Step: 11
Training loss: 3.0380292768844464
Validation loss: 2.530361492066564

Epoch: 6| Step: 12
Training loss: 2.024116785035006
Validation loss: 2.5303121166385516

Epoch: 6| Step: 13
Training loss: 2.423516387934414
Validation loss: 2.538088046522135

Epoch: 65| Step: 0
Training loss: 2.324644008167589
Validation loss: 2.546915098924382

Epoch: 6| Step: 1
Training loss: 2.8847057876114683
Validation loss: 2.552279606986292

Epoch: 6| Step: 2
Training loss: 3.2826962144928227
Validation loss: 2.5486209234325754

Epoch: 6| Step: 3
Training loss: 3.3212131131513902
Validation loss: 2.552983543907575

Epoch: 6| Step: 4
Training loss: 2.352757248631909
Validation loss: 2.549793372407566

Epoch: 6| Step: 5
Training loss: 3.103605659191991
Validation loss: 2.55079626326353

Epoch: 6| Step: 6
Training loss: 2.8440798054696654
Validation loss: 2.5450639111610873

Epoch: 6| Step: 7
Training loss: 2.8752628703809857
Validation loss: 2.5334312047926595

Epoch: 6| Step: 8
Training loss: 3.4915817383943155
Validation loss: 2.534199279574117

Epoch: 6| Step: 9
Training loss: 2.8866397913973127
Validation loss: 2.5270850136675422

Epoch: 6| Step: 10
Training loss: 2.6107187979672046
Validation loss: 2.520709082940516

Epoch: 6| Step: 11
Training loss: 2.3969019842307437
Validation loss: 2.5186275885515212

Epoch: 6| Step: 12
Training loss: 2.813545032900779
Validation loss: 2.515309532041807

Epoch: 6| Step: 13
Training loss: 2.7524512376892227
Validation loss: 2.5202410117389

Epoch: 66| Step: 0
Training loss: 2.7919764750126257
Validation loss: 2.5200134991041563

Epoch: 6| Step: 1
Training loss: 2.410625789168458
Validation loss: 2.545788031032118

Epoch: 6| Step: 2
Training loss: 3.3241476013243796
Validation loss: 2.5386123841342156

Epoch: 6| Step: 3
Training loss: 3.0010583917923466
Validation loss: 2.551805601563388

Epoch: 6| Step: 4
Training loss: 2.5423992122752157
Validation loss: 2.572954351368317

Epoch: 6| Step: 5
Training loss: 3.1308686654279656
Validation loss: 2.6136203171098304

Epoch: 6| Step: 6
Training loss: 3.456333792638207
Validation loss: 2.6886085204404653

Epoch: 6| Step: 7
Training loss: 2.355350118151683
Validation loss: 2.6929218139935363

Epoch: 6| Step: 8
Training loss: 3.7979491170535105
Validation loss: 2.607252044695906

Epoch: 6| Step: 9
Training loss: 2.6759296014133054
Validation loss: 2.5249091368897987

Epoch: 6| Step: 10
Training loss: 2.7266861414816246
Validation loss: 2.5145629238741956

Epoch: 6| Step: 11
Training loss: 2.7331690281432226
Validation loss: 2.5049344853033584

Epoch: 6| Step: 12
Training loss: 2.7442271588891765
Validation loss: 2.508102448787938

Epoch: 6| Step: 13
Training loss: 2.061590514363503
Validation loss: 2.507108729462669

Epoch: 67| Step: 0
Training loss: 3.057264406948097
Validation loss: 2.5081841259236004

Epoch: 6| Step: 1
Training loss: 2.9680997437530947
Validation loss: 2.5079601961082654

Epoch: 6| Step: 2
Training loss: 3.2380889356909788
Validation loss: 2.505743662370331

Epoch: 6| Step: 3
Training loss: 3.007380466892083
Validation loss: 2.5042198560297044

Epoch: 6| Step: 4
Training loss: 2.818801009907115
Validation loss: 2.502522549517936

Epoch: 6| Step: 5
Training loss: 2.712202233350206
Validation loss: 2.5031447300180676

Epoch: 6| Step: 6
Training loss: 3.0953995131577328
Validation loss: 2.5062603675100648

Epoch: 6| Step: 7
Training loss: 2.7039383563119754
Validation loss: 2.506638704662478

Epoch: 6| Step: 8
Training loss: 2.9538836438217726
Validation loss: 2.5155896150136865

Epoch: 6| Step: 9
Training loss: 2.934046236741326
Validation loss: 2.5461951568353367

Epoch: 6| Step: 10
Training loss: 2.8416842828318307
Validation loss: 2.5716919040024426

Epoch: 6| Step: 11
Training loss: 2.6285913514039763
Validation loss: 2.5966055696265307

Epoch: 6| Step: 12
Training loss: 2.2751211113184704
Validation loss: 2.584674767437217

Epoch: 6| Step: 13
Training loss: 2.945105912225996
Validation loss: 2.592803433455279

Epoch: 68| Step: 0
Training loss: 3.075674252905426
Validation loss: 2.533986803653576

Epoch: 6| Step: 1
Training loss: 2.996469009155134
Validation loss: 2.5078875287963807

Epoch: 6| Step: 2
Training loss: 2.8228041191234268
Validation loss: 2.5069471717967877

Epoch: 6| Step: 3
Training loss: 2.5896678191622833
Validation loss: 2.5057407076393132

Epoch: 6| Step: 4
Training loss: 3.2694163239583354
Validation loss: 2.5082290053598504

Epoch: 6| Step: 5
Training loss: 3.033603658962055
Validation loss: 2.5121630336611473

Epoch: 6| Step: 6
Training loss: 3.147623491720362
Validation loss: 2.5093371078819215

Epoch: 6| Step: 7
Training loss: 2.812915177960558
Validation loss: 2.513397137275486

Epoch: 6| Step: 8
Training loss: 2.6554151232770953
Validation loss: 2.511609801123315

Epoch: 6| Step: 9
Training loss: 2.9807560733476377
Validation loss: 2.5108628749373225

Epoch: 6| Step: 10
Training loss: 2.284829766841732
Validation loss: 2.508954746107238

Epoch: 6| Step: 11
Training loss: 3.518073420415024
Validation loss: 2.5072232420702902

Epoch: 6| Step: 12
Training loss: 2.0486925514829473
Validation loss: 2.5041953847098135

Epoch: 6| Step: 13
Training loss: 2.873181472830749
Validation loss: 2.506943509811436

Epoch: 69| Step: 0
Training loss: 2.7870442757759517
Validation loss: 2.5050353296064714

Epoch: 6| Step: 1
Training loss: 2.6113345161080166
Validation loss: 2.513755052898336

Epoch: 6| Step: 2
Training loss: 2.9957384995548
Validation loss: 2.518457934102417

Epoch: 6| Step: 3
Training loss: 2.781760951052417
Validation loss: 2.5295580571164638

Epoch: 6| Step: 4
Training loss: 2.4974445633945517
Validation loss: 2.557058084883231

Epoch: 6| Step: 5
Training loss: 2.210593045095128
Validation loss: 2.6113317417211124

Epoch: 6| Step: 6
Training loss: 2.723617405948717
Validation loss: 2.6405682524614713

Epoch: 6| Step: 7
Training loss: 2.900825770966505
Validation loss: 2.681431985814575

Epoch: 6| Step: 8
Training loss: 3.2264037751326833
Validation loss: 2.7472457871985028

Epoch: 6| Step: 9
Training loss: 3.1955745375058706
Validation loss: 2.8104573204999292

Epoch: 6| Step: 10
Training loss: 3.305788835117527
Validation loss: 2.7900087079683265

Epoch: 6| Step: 11
Training loss: 3.4363012824701866
Validation loss: 2.6773443808598953

Epoch: 6| Step: 12
Training loss: 2.719628290835665
Validation loss: 2.572853316437662

Epoch: 6| Step: 13
Training loss: 3.599155374626881
Validation loss: 2.525759296135258

Epoch: 70| Step: 0
Training loss: 2.6814930341076355
Validation loss: 2.5138796809924933

Epoch: 6| Step: 1
Training loss: 2.5260370523207425
Validation loss: 2.5347947236208657

Epoch: 6| Step: 2
Training loss: 3.313944951283397
Validation loss: 2.543467075811395

Epoch: 6| Step: 3
Training loss: 2.8217732458683904
Validation loss: 2.5588670915389207

Epoch: 6| Step: 4
Training loss: 3.0966585917071567
Validation loss: 2.573355625134565

Epoch: 6| Step: 5
Training loss: 3.5653578689099974
Validation loss: 2.58220066508076

Epoch: 6| Step: 6
Training loss: 3.107431082049528
Validation loss: 2.551376110845049

Epoch: 6| Step: 7
Training loss: 2.8725039385975264
Validation loss: 2.5320934823218155

Epoch: 6| Step: 8
Training loss: 3.3527861097713907
Validation loss: 2.5224949541834887

Epoch: 6| Step: 9
Training loss: 2.577914142655705
Validation loss: 2.5136622187690496

Epoch: 6| Step: 10
Training loss: 2.8470223850325564
Validation loss: 2.520348096327021

Epoch: 6| Step: 11
Training loss: 2.6731986174882816
Validation loss: 2.51456929686934

Epoch: 6| Step: 12
Training loss: 2.6422693674137663
Validation loss: 2.528831698062894

Epoch: 6| Step: 13
Training loss: 2.7327187017676597
Validation loss: 2.5333916139564248

Epoch: 71| Step: 0
Training loss: 2.9264383023900082
Validation loss: 2.5543125491199126

Epoch: 6| Step: 1
Training loss: 2.2417989254570037
Validation loss: 2.598419597886857

Epoch: 6| Step: 2
Training loss: 2.7231603344613844
Validation loss: 2.6303372178024618

Epoch: 6| Step: 3
Training loss: 2.812569935247036
Validation loss: 2.660821961928349

Epoch: 6| Step: 4
Training loss: 2.9418492686481748
Validation loss: 2.624511899947637

Epoch: 6| Step: 5
Training loss: 3.2640263052796645
Validation loss: 2.586704532111237

Epoch: 6| Step: 6
Training loss: 2.691877658790425
Validation loss: 2.5839330259653943

Epoch: 6| Step: 7
Training loss: 2.086427095369496
Validation loss: 2.59275753219599

Epoch: 6| Step: 8
Training loss: 3.1745762339463073
Validation loss: 2.5865442500844535

Epoch: 6| Step: 9
Training loss: 3.0459843825542916
Validation loss: 2.5752932930161156

Epoch: 6| Step: 10
Training loss: 2.6102220451057145
Validation loss: 2.5526117182584684

Epoch: 6| Step: 11
Training loss: 2.822697779954136
Validation loss: 2.540295888041398

Epoch: 6| Step: 12
Training loss: 3.434548515400339
Validation loss: 2.5030657336725124

Epoch: 6| Step: 13
Training loss: 3.5058707999465653
Validation loss: 2.4984973462595508

Epoch: 72| Step: 0
Training loss: 2.633712841001733
Validation loss: 2.5004262724850874

Epoch: 6| Step: 1
Training loss: 3.4205110522792714
Validation loss: 2.497664123274559

Epoch: 6| Step: 2
Training loss: 2.8218955038177005
Validation loss: 2.4944691122063323

Epoch: 6| Step: 3
Training loss: 3.552213172366776
Validation loss: 2.496756807514331

Epoch: 6| Step: 4
Training loss: 3.163483592632801
Validation loss: 2.4938364919468436

Epoch: 6| Step: 5
Training loss: 2.4489995198185093
Validation loss: 2.4982925254873725

Epoch: 6| Step: 6
Training loss: 2.913324912151442
Validation loss: 2.497298331348777

Epoch: 6| Step: 7
Training loss: 2.8161162122567065
Validation loss: 2.4919479830562117

Epoch: 6| Step: 8
Training loss: 2.75737916821741
Validation loss: 2.4900744034474283

Epoch: 6| Step: 9
Training loss: 2.739000778242699
Validation loss: 2.488690424208985

Epoch: 6| Step: 10
Training loss: 2.80675360359986
Validation loss: 2.4897547162716145

Epoch: 6| Step: 11
Training loss: 2.527505436107551
Validation loss: 2.4938024847557623

Epoch: 6| Step: 12
Training loss: 2.1781446677678655
Validation loss: 2.5085398052831964

Epoch: 6| Step: 13
Training loss: 3.0072403004329966
Validation loss: 2.528661990163465

Epoch: 73| Step: 0
Training loss: 2.6585950485437064
Validation loss: 2.5478275203151024

Epoch: 6| Step: 1
Training loss: 3.3191286377512443
Validation loss: 2.5728128415683575

Epoch: 6| Step: 2
Training loss: 3.763064705176061
Validation loss: 2.5902045889503804

Epoch: 6| Step: 3
Training loss: 3.0039233937660983
Validation loss: 2.5891729663609446

Epoch: 6| Step: 4
Training loss: 3.0058381177164204
Validation loss: 2.6090419360965877

Epoch: 6| Step: 5
Training loss: 2.8814922503993183
Validation loss: 2.568383925693457

Epoch: 6| Step: 6
Training loss: 2.2348414647756703
Validation loss: 2.516422544530535

Epoch: 6| Step: 7
Training loss: 2.8644767232765846
Validation loss: 2.498569657706903

Epoch: 6| Step: 8
Training loss: 2.6665666283280807
Validation loss: 2.4848521187154793

Epoch: 6| Step: 9
Training loss: 2.5275631651640365
Validation loss: 2.484092924956099

Epoch: 6| Step: 10
Training loss: 2.679614897431188
Validation loss: 2.491996581664021

Epoch: 6| Step: 11
Training loss: 2.7968905144799274
Validation loss: 2.491085733083282

Epoch: 6| Step: 12
Training loss: 2.211097522781169
Validation loss: 2.491389595850488

Epoch: 6| Step: 13
Training loss: 3.4073122100692808
Validation loss: 2.492215843835439

Epoch: 74| Step: 0
Training loss: 3.2491729857846496
Validation loss: 2.4854143408723437

Epoch: 6| Step: 1
Training loss: 2.5420702212619264
Validation loss: 2.489738482861979

Epoch: 6| Step: 2
Training loss: 2.6628906715575487
Validation loss: 2.483236490425875

Epoch: 6| Step: 3
Training loss: 2.410896373108744
Validation loss: 2.494681399295115

Epoch: 6| Step: 4
Training loss: 2.727578572261281
Validation loss: 2.499266758929866

Epoch: 6| Step: 5
Training loss: 3.0381185835798226
Validation loss: 2.502020845630793

Epoch: 6| Step: 6
Training loss: 2.673230457593722
Validation loss: 2.5005237481922116

Epoch: 6| Step: 7
Training loss: 2.584985194652667
Validation loss: 2.5006612026386854

Epoch: 6| Step: 8
Training loss: 2.7108679331007832
Validation loss: 2.514874647483127

Epoch: 6| Step: 9
Training loss: 2.7744111407169587
Validation loss: 2.518508525243181

Epoch: 6| Step: 10
Training loss: 2.9996844761544392
Validation loss: 2.5446516154185788

Epoch: 6| Step: 11
Training loss: 3.3219139635128188
Validation loss: 2.5268125297675312

Epoch: 6| Step: 12
Training loss: 3.1306738652737383
Validation loss: 2.5128202502505737

Epoch: 6| Step: 13
Training loss: 3.021234542687189
Validation loss: 2.4962611039857534

Epoch: 75| Step: 0
Training loss: 1.887771407565622
Validation loss: 2.484213817297971

Epoch: 6| Step: 1
Training loss: 2.7916290698200497
Validation loss: 2.4872022234432487

Epoch: 6| Step: 2
Training loss: 2.3724260938928925
Validation loss: 2.4836712077228458

Epoch: 6| Step: 3
Training loss: 2.09765602268097
Validation loss: 2.48074137731929

Epoch: 6| Step: 4
Training loss: 3.2497043475141614
Validation loss: 2.480529587005827

Epoch: 6| Step: 5
Training loss: 3.4402238631041855
Validation loss: 2.483684648969786

Epoch: 6| Step: 6
Training loss: 2.9363085988816318
Validation loss: 2.482382897868253

Epoch: 6| Step: 7
Training loss: 2.913367630897067
Validation loss: 2.4810914691728354

Epoch: 6| Step: 8
Training loss: 3.1954303896918503
Validation loss: 2.481188200080809

Epoch: 6| Step: 9
Training loss: 3.2081458957629994
Validation loss: 2.481762473687963

Epoch: 6| Step: 10
Training loss: 2.6867795466460196
Validation loss: 2.4789885238656297

Epoch: 6| Step: 11
Training loss: 3.0118344849986123
Validation loss: 2.4903161388906647

Epoch: 6| Step: 12
Training loss: 2.608767867125379
Validation loss: 2.4990349229683497

Epoch: 6| Step: 13
Training loss: 3.1215250149380953
Validation loss: 2.517142666872277

Epoch: 76| Step: 0
Training loss: 2.5584550892770537
Validation loss: 2.5349534021502325

Epoch: 6| Step: 1
Training loss: 2.85360970364892
Validation loss: 2.5598805262613777

Epoch: 6| Step: 2
Training loss: 2.9339635135953697
Validation loss: 2.5625808046788023

Epoch: 6| Step: 3
Training loss: 3.0623928751991167
Validation loss: 2.563253028448408

Epoch: 6| Step: 4
Training loss: 3.0653573544448647
Validation loss: 2.5544548077966116

Epoch: 6| Step: 5
Training loss: 2.55992723033714
Validation loss: 2.557962852359476

Epoch: 6| Step: 6
Training loss: 2.1714479314686757
Validation loss: 2.54766819661974

Epoch: 6| Step: 7
Training loss: 2.5603437888748894
Validation loss: 2.523505116473078

Epoch: 6| Step: 8
Training loss: 2.8598108845320676
Validation loss: 2.529650435080229

Epoch: 6| Step: 9
Training loss: 2.9122827735410524
Validation loss: 2.5374774740510344

Epoch: 6| Step: 10
Training loss: 3.3910181898677085
Validation loss: 2.5321036737128066

Epoch: 6| Step: 11
Training loss: 2.9268270541004395
Validation loss: 2.5146841961119915

Epoch: 6| Step: 12
Training loss: 2.95514412129915
Validation loss: 2.5100720522679483

Epoch: 6| Step: 13
Training loss: 2.3904278243785635
Validation loss: 2.49179527397211

Epoch: 77| Step: 0
Training loss: 2.4718917942561696
Validation loss: 2.489377426245925

Epoch: 6| Step: 1
Training loss: 2.9692798342476623
Validation loss: 2.4913702042644132

Epoch: 6| Step: 2
Training loss: 2.5804544733145125
Validation loss: 2.506330439937072

Epoch: 6| Step: 3
Training loss: 3.0123399620758513
Validation loss: 2.51574920121457

Epoch: 6| Step: 4
Training loss: 2.672572886915615
Validation loss: 2.52784028603854

Epoch: 6| Step: 5
Training loss: 2.740877800551077
Validation loss: 2.5481085644538983

Epoch: 6| Step: 6
Training loss: 2.6206767493828496
Validation loss: 2.5196983302989575

Epoch: 6| Step: 7
Training loss: 3.471696993627751
Validation loss: 2.518350976810077

Epoch: 6| Step: 8
Training loss: 3.041646373803017
Validation loss: 2.487057923896038

Epoch: 6| Step: 9
Training loss: 2.844960720012332
Validation loss: 2.4790278015237037

Epoch: 6| Step: 10
Training loss: 2.4110637916027304
Validation loss: 2.4781340008670876

Epoch: 6| Step: 11
Training loss: 3.0230539162358236
Validation loss: 2.4787219455159786

Epoch: 6| Step: 12
Training loss: 2.6281502304045405
Validation loss: 2.4810478378748098

Epoch: 6| Step: 13
Training loss: 3.2166776930335086
Validation loss: 2.4804607328893042

Epoch: 78| Step: 0
Training loss: 2.791351063287168
Validation loss: 2.4769077217628586

Epoch: 6| Step: 1
Training loss: 2.87632604784442
Validation loss: 2.4772700059378328

Epoch: 6| Step: 2
Training loss: 2.8974021851664675
Validation loss: 2.4773193623092222

Epoch: 6| Step: 3
Training loss: 3.3334208159093115
Validation loss: 2.4793111714740412

Epoch: 6| Step: 4
Training loss: 2.740833785174077
Validation loss: 2.4818350072561395

Epoch: 6| Step: 5
Training loss: 2.966495340379315
Validation loss: 2.4789994692622397

Epoch: 6| Step: 6
Training loss: 3.350587929903226
Validation loss: 2.4866370311688715

Epoch: 6| Step: 7
Training loss: 2.5334067869412755
Validation loss: 2.4867455566312318

Epoch: 6| Step: 8
Training loss: 2.601680352001702
Validation loss: 2.487716514129679

Epoch: 6| Step: 9
Training loss: 2.405656617557186
Validation loss: 2.4924844359256726

Epoch: 6| Step: 10
Training loss: 2.8948620235261484
Validation loss: 2.4986155727223163

Epoch: 6| Step: 11
Training loss: 3.184263044341513
Validation loss: 2.5146971927690807

Epoch: 6| Step: 12
Training loss: 2.508766254397101
Validation loss: 2.5275379481675606

Epoch: 6| Step: 13
Training loss: 1.7322612632091305
Validation loss: 2.527904927925024

Epoch: 79| Step: 0
Training loss: 3.2294904156897166
Validation loss: 2.5285505127271204

Epoch: 6| Step: 1
Training loss: 2.8610451411899738
Validation loss: 2.5207846777612106

Epoch: 6| Step: 2
Training loss: 2.9861101628580484
Validation loss: 2.512610171135182

Epoch: 6| Step: 3
Training loss: 2.820589934253023
Validation loss: 2.4988825320714345

Epoch: 6| Step: 4
Training loss: 3.322545779266595
Validation loss: 2.495098327317563

Epoch: 6| Step: 5
Training loss: 2.312747220408095
Validation loss: 2.5002389547528665

Epoch: 6| Step: 6
Training loss: 2.5963322298327802
Validation loss: 2.4866384116332556

Epoch: 6| Step: 7
Training loss: 2.895089326050329
Validation loss: 2.483314858094152

Epoch: 6| Step: 8
Training loss: 2.9214519663682434
Validation loss: 2.4829588858079434

Epoch: 6| Step: 9
Training loss: 2.895201653027702
Validation loss: 2.4798044418607144

Epoch: 6| Step: 10
Training loss: 2.569053179073559
Validation loss: 2.474832451391307

Epoch: 6| Step: 11
Training loss: 2.5075177646361393
Validation loss: 2.490824239071424

Epoch: 6| Step: 12
Training loss: 2.135082113219065
Validation loss: 2.493725443866723

Epoch: 6| Step: 13
Training loss: 3.294788441559456
Validation loss: 2.503718804554437

Epoch: 80| Step: 0
Training loss: 3.1087184193613395
Validation loss: 2.5095931424704023

Epoch: 6| Step: 1
Training loss: 2.9059900967454815
Validation loss: 2.5300635855723996

Epoch: 6| Step: 2
Training loss: 2.061617460144203
Validation loss: 2.560766218316574

Epoch: 6| Step: 3
Training loss: 2.361029038841627
Validation loss: 2.5694284113951262

Epoch: 6| Step: 4
Training loss: 2.922920733499088
Validation loss: 2.608814818225024

Epoch: 6| Step: 5
Training loss: 2.9586799490161906
Validation loss: 2.6691728423365326

Epoch: 6| Step: 6
Training loss: 3.4762108099853473
Validation loss: 2.668335990726377

Epoch: 6| Step: 7
Training loss: 2.667813074532579
Validation loss: 2.609888695404787

Epoch: 6| Step: 8
Training loss: 3.1203212044508035
Validation loss: 2.5548077099972804

Epoch: 6| Step: 9
Training loss: 2.7566716154977398
Validation loss: 2.5183567935631066

Epoch: 6| Step: 10
Training loss: 2.5326172703425027
Validation loss: 2.496851610103449

Epoch: 6| Step: 11
Training loss: 2.6821413954828235
Validation loss: 2.4814541239987054

Epoch: 6| Step: 12
Training loss: 2.947025842942292
Validation loss: 2.4757995620738034

Epoch: 6| Step: 13
Training loss: 2.3886679823212864
Validation loss: 2.474310544669866

Epoch: 81| Step: 0
Training loss: 3.0325085101908424
Validation loss: 2.476153566300788

Epoch: 6| Step: 1
Training loss: 3.229128060058826
Validation loss: 2.4801777144487285

Epoch: 6| Step: 2
Training loss: 2.7699963349961916
Validation loss: 2.4836435147263463

Epoch: 6| Step: 3
Training loss: 2.774518557188279
Validation loss: 2.4916304145283195

Epoch: 6| Step: 4
Training loss: 2.9626546827406393
Validation loss: 2.489602520875999

Epoch: 6| Step: 5
Training loss: 2.629115919619907
Validation loss: 2.4971322747308915

Epoch: 6| Step: 6
Training loss: 2.8421012374596595
Validation loss: 2.509407310976101

Epoch: 6| Step: 7
Training loss: 3.439818276773016
Validation loss: 2.5273260899015653

Epoch: 6| Step: 8
Training loss: 2.756289572226245
Validation loss: 2.530776904969624

Epoch: 6| Step: 9
Training loss: 3.1181232319496326
Validation loss: 2.5429387176586657

Epoch: 6| Step: 10
Training loss: 2.530564109275069
Validation loss: 2.489358689926179

Epoch: 6| Step: 11
Training loss: 2.975813483566645
Validation loss: 2.488194189333735

Epoch: 6| Step: 12
Training loss: 2.4275568116883712
Validation loss: 2.492518407616044

Epoch: 6| Step: 13
Training loss: 2.54275122677574
Validation loss: 2.526382521397729

Epoch: 82| Step: 0
Training loss: 2.526527048781124
Validation loss: 2.5654841469167287

Epoch: 6| Step: 1
Training loss: 3.130714989067743
Validation loss: 2.62343607663946

Epoch: 6| Step: 2
Training loss: 2.5977968565094596
Validation loss: 2.6704330098501714

Epoch: 6| Step: 3
Training loss: 2.7276950003535245
Validation loss: 2.646817746465566

Epoch: 6| Step: 4
Training loss: 3.0499449302829698
Validation loss: 2.6410272482057375

Epoch: 6| Step: 5
Training loss: 2.992111324605588
Validation loss: 2.577776032885283

Epoch: 6| Step: 6
Training loss: 2.6480418221954025
Validation loss: 2.547646934057861

Epoch: 6| Step: 7
Training loss: 2.905764303332849
Validation loss: 2.5078792752888712

Epoch: 6| Step: 8
Training loss: 2.4447051930314543
Validation loss: 2.4690170424035203

Epoch: 6| Step: 9
Training loss: 2.7133032949723503
Validation loss: 2.4716350436825483

Epoch: 6| Step: 10
Training loss: 2.713993691388573
Validation loss: 2.494495855651935

Epoch: 6| Step: 11
Training loss: 3.05990023132441
Validation loss: 2.509391239946181

Epoch: 6| Step: 12
Training loss: 3.5015529184750798
Validation loss: 2.512063578687855

Epoch: 6| Step: 13
Training loss: 2.8670589407805465
Validation loss: 2.510490672370758

Epoch: 83| Step: 0
Training loss: 2.876815388600793
Validation loss: 2.4988928076131947

Epoch: 6| Step: 1
Training loss: 3.201389493870948
Validation loss: 2.4928330233400646

Epoch: 6| Step: 2
Training loss: 2.4459688810862725
Validation loss: 2.5054801701506078

Epoch: 6| Step: 3
Training loss: 2.853435747620033
Validation loss: 2.500065995442528

Epoch: 6| Step: 4
Training loss: 2.826861188721132
Validation loss: 2.4934311531259534

Epoch: 6| Step: 5
Training loss: 2.6613322388003944
Validation loss: 2.4878927803242425

Epoch: 6| Step: 6
Training loss: 2.8253034985659133
Validation loss: 2.474017100820845

Epoch: 6| Step: 7
Training loss: 2.5801946482310223
Validation loss: 2.484636517566851

Epoch: 6| Step: 8
Training loss: 2.6617883725209808
Validation loss: 2.4911850736465655

Epoch: 6| Step: 9
Training loss: 3.387558213750768
Validation loss: 2.4963062635044406

Epoch: 6| Step: 10
Training loss: 3.2110662504125593
Validation loss: 2.487168792434542

Epoch: 6| Step: 11
Training loss: 2.90636386443191
Validation loss: 2.481551155859778

Epoch: 6| Step: 12
Training loss: 2.873816702766736
Validation loss: 2.4759590063445382

Epoch: 6| Step: 13
Training loss: 2.5262891405670147
Validation loss: 2.5007008790381358

Epoch: 84| Step: 0
Training loss: 3.52805041630505
Validation loss: 2.5395602809990327

Epoch: 6| Step: 1
Training loss: 3.1940470757021973
Validation loss: 2.5367383776835535

Epoch: 6| Step: 2
Training loss: 2.550187186308327
Validation loss: 2.524526454763828

Epoch: 6| Step: 3
Training loss: 2.899258314853148
Validation loss: 2.5596806352870174

Epoch: 6| Step: 4
Training loss: 3.2184419947540133
Validation loss: 2.5399462988139776

Epoch: 6| Step: 5
Training loss: 2.901023841862505
Validation loss: 2.513855402627944

Epoch: 6| Step: 6
Training loss: 2.934062651076472
Validation loss: 2.493557184605772

Epoch: 6| Step: 7
Training loss: 2.026458958765279
Validation loss: 2.4726295005130208

Epoch: 6| Step: 8
Training loss: 2.9631439281761045
Validation loss: 2.469228528604397

Epoch: 6| Step: 9
Training loss: 2.593836955255989
Validation loss: 2.4712298705493136

Epoch: 6| Step: 10
Training loss: 2.7020345263361185
Validation loss: 2.4684300763799434

Epoch: 6| Step: 11
Training loss: 2.593072090261937
Validation loss: 2.469963513807678

Epoch: 6| Step: 12
Training loss: 2.528574341779236
Validation loss: 2.479014600800492

Epoch: 6| Step: 13
Training loss: 2.7734905399032574
Validation loss: 2.471225526974116

Epoch: 85| Step: 0
Training loss: 2.5692590102449486
Validation loss: 2.4835734741897366

Epoch: 6| Step: 1
Training loss: 2.684046811168892
Validation loss: 2.5039867197307255

Epoch: 6| Step: 2
Training loss: 2.544710140247014
Validation loss: 2.489254216151112

Epoch: 6| Step: 3
Training loss: 3.365432742267272
Validation loss: 2.496056558815717

Epoch: 6| Step: 4
Training loss: 2.8454254580453306
Validation loss: 2.4978434941955574

Epoch: 6| Step: 5
Training loss: 2.874964506510696
Validation loss: 2.4943708952593204

Epoch: 6| Step: 6
Training loss: 2.682025567839615
Validation loss: 2.483032563500552

Epoch: 6| Step: 7
Training loss: 2.5590011155907546
Validation loss: 2.484964668235849

Epoch: 6| Step: 8
Training loss: 3.216575406481411
Validation loss: 2.46960370905529

Epoch: 6| Step: 9
Training loss: 2.2173337042726597
Validation loss: 2.4609409502183954

Epoch: 6| Step: 10
Training loss: 2.9309995434440848
Validation loss: 2.4617653147997727

Epoch: 6| Step: 11
Training loss: 2.6514000990705955
Validation loss: 2.460322262891433

Epoch: 6| Step: 12
Training loss: 2.7069095292462078
Validation loss: 2.461760989932228

Epoch: 6| Step: 13
Training loss: 3.341160850263205
Validation loss: 2.4683736584650005

Epoch: 86| Step: 0
Training loss: 3.2522091326594773
Validation loss: 2.4662673323747146

Epoch: 6| Step: 1
Training loss: 2.646341670506767
Validation loss: 2.4809697530264616

Epoch: 6| Step: 2
Training loss: 2.7193199524933287
Validation loss: 2.504145721650438

Epoch: 6| Step: 3
Training loss: 3.0473446215104283
Validation loss: 2.509931651681231

Epoch: 6| Step: 4
Training loss: 2.357580146438526
Validation loss: 2.556240776031931

Epoch: 6| Step: 5
Training loss: 2.7996487635612977
Validation loss: 2.59776784981107

Epoch: 6| Step: 6
Training loss: 3.219511367969731
Validation loss: 2.5997935444257996

Epoch: 6| Step: 7
Training loss: 3.5020473486696635
Validation loss: 2.587571281841115

Epoch: 6| Step: 8
Training loss: 2.2332282691649024
Validation loss: 2.5395003109975596

Epoch: 6| Step: 9
Training loss: 2.5881817348058873
Validation loss: 2.5126402200977127

Epoch: 6| Step: 10
Training loss: 2.6207767300540357
Validation loss: 2.495221715801812

Epoch: 6| Step: 11
Training loss: 2.438143131801811
Validation loss: 2.488191908200296

Epoch: 6| Step: 12
Training loss: 3.196213574192599
Validation loss: 2.4845098437090027

Epoch: 6| Step: 13
Training loss: 2.356343829565954
Validation loss: 2.4814029995138815

Epoch: 87| Step: 0
Training loss: 3.2320682574231148
Validation loss: 2.4829121360956847

Epoch: 6| Step: 1
Training loss: 2.650716785441918
Validation loss: 2.481120908964372

Epoch: 6| Step: 2
Training loss: 3.409059818010449
Validation loss: 2.4811273668250355

Epoch: 6| Step: 3
Training loss: 2.7496904719159234
Validation loss: 2.4814609787424455

Epoch: 6| Step: 4
Training loss: 3.363249491719978
Validation loss: 2.4862656212942995

Epoch: 6| Step: 5
Training loss: 2.3254199602406436
Validation loss: 2.4812065543289106

Epoch: 6| Step: 6
Training loss: 3.1808614977005383
Validation loss: 2.486088125011442

Epoch: 6| Step: 7
Training loss: 2.2701140031461575
Validation loss: 2.4877261669880766

Epoch: 6| Step: 8
Training loss: 2.783932881302575
Validation loss: 2.4903199190056156

Epoch: 6| Step: 9
Training loss: 2.61205469379149
Validation loss: 2.4941166026440715

Epoch: 6| Step: 10
Training loss: 2.6264840426916116
Validation loss: 2.506863302707396

Epoch: 6| Step: 11
Training loss: 2.5588457056287788
Validation loss: 2.5043469107920773

Epoch: 6| Step: 12
Training loss: 2.7847516593952135
Validation loss: 2.500503984534351

Epoch: 6| Step: 13
Training loss: 2.4180448701921757
Validation loss: 2.5035372198117183

Epoch: 88| Step: 0
Training loss: 2.800256315488652
Validation loss: 2.515673720037637

Epoch: 6| Step: 1
Training loss: 2.961934830076798
Validation loss: 2.523296158580785

Epoch: 6| Step: 2
Training loss: 2.8029358050439304
Validation loss: 2.529738322839447

Epoch: 6| Step: 3
Training loss: 3.0808451295612556
Validation loss: 2.538066471385373

Epoch: 6| Step: 4
Training loss: 2.205570027549191
Validation loss: 2.541718254661878

Epoch: 6| Step: 5
Training loss: 2.795556807356842
Validation loss: 2.5345917962644577

Epoch: 6| Step: 6
Training loss: 2.556418296291754
Validation loss: 2.538338355205392

Epoch: 6| Step: 7
Training loss: 2.7714201991666876
Validation loss: 2.5223225610275013

Epoch: 6| Step: 8
Training loss: 2.588819758766084
Validation loss: 2.5082580653093816

Epoch: 6| Step: 9
Training loss: 3.1938618022661998
Validation loss: 2.492513528244625

Epoch: 6| Step: 10
Training loss: 2.859574441259997
Validation loss: 2.490163773451328

Epoch: 6| Step: 11
Training loss: 2.796308065740066
Validation loss: 2.4851369413645013

Epoch: 6| Step: 12
Training loss: 2.5953272424654656
Validation loss: 2.4822428882688814

Epoch: 6| Step: 13
Training loss: 3.2203569567414427
Validation loss: 2.4790232565117782

Epoch: 89| Step: 0
Training loss: 2.7570572378134166
Validation loss: 2.479155399720533

Epoch: 6| Step: 1
Training loss: 2.739146750199488
Validation loss: 2.478220574962714

Epoch: 6| Step: 2
Training loss: 3.0221998259082286
Validation loss: 2.4827815537599633

Epoch: 6| Step: 3
Training loss: 1.5863109581118722
Validation loss: 2.4759072092574574

Epoch: 6| Step: 4
Training loss: 2.924893864719376
Validation loss: 2.4781514342746482

Epoch: 6| Step: 5
Training loss: 2.232560708308775
Validation loss: 2.4867734985834042

Epoch: 6| Step: 6
Training loss: 2.2509831293966034
Validation loss: 2.502942301180293

Epoch: 6| Step: 7
Training loss: 2.9057067035126547
Validation loss: 2.5215256859809587

Epoch: 6| Step: 8
Training loss: 3.255748945993966
Validation loss: 2.537854006086619

Epoch: 6| Step: 9
Training loss: 3.2145728997196974
Validation loss: 2.55351695681963

Epoch: 6| Step: 10
Training loss: 2.966619911968401
Validation loss: 2.608456772385734

Epoch: 6| Step: 11
Training loss: 2.7338652217324366
Validation loss: 2.590643410409634

Epoch: 6| Step: 12
Training loss: 3.0270706151986966
Validation loss: 2.5674089082748677

Epoch: 6| Step: 13
Training loss: 3.866504585771494
Validation loss: 2.516600848397153

Epoch: 90| Step: 0
Training loss: 2.5441477396669483
Validation loss: 2.475981816392243

Epoch: 6| Step: 1
Training loss: 2.5950979384093626
Validation loss: 2.459570897695804

Epoch: 6| Step: 2
Training loss: 2.2481249307691296
Validation loss: 2.4564795553310743

Epoch: 6| Step: 3
Training loss: 3.0176046722133223
Validation loss: 2.471968083394541

Epoch: 6| Step: 4
Training loss: 2.8197968664122546
Validation loss: 2.4775902284311804

Epoch: 6| Step: 5
Training loss: 3.4939892790989635
Validation loss: 2.482636559433641

Epoch: 6| Step: 6
Training loss: 2.5905689817844157
Validation loss: 2.4851298615571675

Epoch: 6| Step: 7
Training loss: 3.151822903891124
Validation loss: 2.4856179888475656

Epoch: 6| Step: 8
Training loss: 3.23215633350384
Validation loss: 2.482675175299201

Epoch: 6| Step: 9
Training loss: 2.5998175557021326
Validation loss: 2.4865765198884793

Epoch: 6| Step: 10
Training loss: 3.198255307702096
Validation loss: 2.484862925828328

Epoch: 6| Step: 11
Training loss: 3.0079298120385705
Validation loss: 2.482807695661167

Epoch: 6| Step: 12
Training loss: 2.7213464374827936
Validation loss: 2.481863605670415

Epoch: 6| Step: 13
Training loss: 2.894856093656214
Validation loss: 2.4805395386090217

Epoch: 91| Step: 0
Training loss: 2.6055915494744895
Validation loss: 2.4803596708372324

Epoch: 6| Step: 1
Training loss: 2.706924678581792
Validation loss: 2.476754961020619

Epoch: 6| Step: 2
Training loss: 2.96800463504892
Validation loss: 2.47338353127193

Epoch: 6| Step: 3
Training loss: 3.300534933255834
Validation loss: 2.4709375579831114

Epoch: 6| Step: 4
Training loss: 2.6581673377975363
Validation loss: 2.474006623518427

Epoch: 6| Step: 5
Training loss: 3.211499390085499
Validation loss: 2.4790377374388433

Epoch: 6| Step: 6
Training loss: 2.1866579887559094
Validation loss: 2.4964133540146034

Epoch: 6| Step: 7
Training loss: 3.1794085556008267
Validation loss: 2.500263575533905

Epoch: 6| Step: 8
Training loss: 2.3784672374317317
Validation loss: 2.5017664564999125

Epoch: 6| Step: 9
Training loss: 2.1914461781609247
Validation loss: 2.5189780205742767

Epoch: 6| Step: 10
Training loss: 3.3694001824837727
Validation loss: 2.528601279094904

Epoch: 6| Step: 11
Training loss: 3.154760330213512
Validation loss: 2.5375880986403265

Epoch: 6| Step: 12
Training loss: 2.819896043795753
Validation loss: 2.5227770039847344

Epoch: 6| Step: 13
Training loss: 2.401671078175136
Validation loss: 2.5147504122501236

Epoch: 92| Step: 0
Training loss: 2.8748006336912617
Validation loss: 2.5047952398675704

Epoch: 6| Step: 1
Training loss: 3.2884683321506407
Validation loss: 2.50290240629398

Epoch: 6| Step: 2
Training loss: 2.7150168384289777
Validation loss: 2.4950726856249097

Epoch: 6| Step: 3
Training loss: 2.4733777673368165
Validation loss: 2.4983422464091625

Epoch: 6| Step: 4
Training loss: 2.7184021825937688
Validation loss: 2.469910256185815

Epoch: 6| Step: 5
Training loss: 2.819483669573985
Validation loss: 2.4594660138415274

Epoch: 6| Step: 6
Training loss: 2.719343274158745
Validation loss: 2.4530669833099217

Epoch: 6| Step: 7
Training loss: 2.5482933915847927
Validation loss: 2.448685332718518

Epoch: 6| Step: 8
Training loss: 2.625339667732859
Validation loss: 2.458566692810838

Epoch: 6| Step: 9
Training loss: 2.8003251942756697
Validation loss: 2.46114580034957

Epoch: 6| Step: 10
Training loss: 2.9702014787966817
Validation loss: 2.49406061879225

Epoch: 6| Step: 11
Training loss: 2.5312411461192568
Validation loss: 2.521657676902246

Epoch: 6| Step: 12
Training loss: 3.077071730984195
Validation loss: 2.5611582679148004

Epoch: 6| Step: 13
Training loss: 2.9703005305354573
Validation loss: 2.5685832950646725

Epoch: 93| Step: 0
Training loss: 2.492267667144688
Validation loss: 2.5468049287923806

Epoch: 6| Step: 1
Training loss: 1.9453690608737357
Validation loss: 2.5313515733286103

Epoch: 6| Step: 2
Training loss: 3.0983059407446536
Validation loss: 2.512582389987943

Epoch: 6| Step: 3
Training loss: 2.933274496817787
Validation loss: 2.498058340328269

Epoch: 6| Step: 4
Training loss: 2.5493552645746824
Validation loss: 2.5018944504749046

Epoch: 6| Step: 5
Training loss: 2.6017564122786374
Validation loss: 2.532079230909935

Epoch: 6| Step: 6
Training loss: 2.83623963315035
Validation loss: 2.5216937351494835

Epoch: 6| Step: 7
Training loss: 2.775361417312005
Validation loss: 2.5175608648175665

Epoch: 6| Step: 8
Training loss: 3.0138547771377078
Validation loss: 2.510755489949725

Epoch: 6| Step: 9
Training loss: 2.5394619202061777
Validation loss: 2.480161806493552

Epoch: 6| Step: 10
Training loss: 2.6304820808999616
Validation loss: 2.4582143368571754

Epoch: 6| Step: 11
Training loss: 3.0965163068398964
Validation loss: 2.4552672780892424

Epoch: 6| Step: 12
Training loss: 3.2391578582991976
Validation loss: 2.452075189932104

Epoch: 6| Step: 13
Training loss: 2.957411626944914
Validation loss: 2.4503229871337187

Epoch: 94| Step: 0
Training loss: 3.272950493540424
Validation loss: 2.4499862339017264

Epoch: 6| Step: 1
Training loss: 2.4565180741415245
Validation loss: 2.4514921360799664

Epoch: 6| Step: 2
Training loss: 3.050696534215108
Validation loss: 2.456046273378496

Epoch: 6| Step: 3
Training loss: 2.842000234347501
Validation loss: 2.4545034790596634

Epoch: 6| Step: 4
Training loss: 2.8043709153888865
Validation loss: 2.452621344509623

Epoch: 6| Step: 5
Training loss: 2.8960219031396077
Validation loss: 2.4518119517210626

Epoch: 6| Step: 6
Training loss: 2.964310870827115
Validation loss: 2.4491984289381223

Epoch: 6| Step: 7
Training loss: 2.1435114202281924
Validation loss: 2.45492342003992

Epoch: 6| Step: 8
Training loss: 2.9383754643106275
Validation loss: 2.4540084336029073

Epoch: 6| Step: 9
Training loss: 1.9993411409421278
Validation loss: 2.4728447966442557

Epoch: 6| Step: 10
Training loss: 2.869759468871858
Validation loss: 2.5040045096259718

Epoch: 6| Step: 11
Training loss: 2.594113060233671
Validation loss: 2.521070806460029

Epoch: 6| Step: 12
Training loss: 3.0005403667799206
Validation loss: 2.533772587852793

Epoch: 6| Step: 13
Training loss: 2.8584282980696014
Validation loss: 2.5371250673530126

Epoch: 95| Step: 0
Training loss: 2.912292761244526
Validation loss: 2.554249422650154

Epoch: 6| Step: 1
Training loss: 3.355976319476162
Validation loss: 2.5515231420298257

Epoch: 6| Step: 2
Training loss: 2.062132253518129
Validation loss: 2.537303941193178

Epoch: 6| Step: 3
Training loss: 2.8674156659470142
Validation loss: 2.5213140403750525

Epoch: 6| Step: 4
Training loss: 2.7651504712955948
Validation loss: 2.504075647467352

Epoch: 6| Step: 5
Training loss: 2.2158089070470015
Validation loss: 2.475086595717651

Epoch: 6| Step: 6
Training loss: 2.6051565094717004
Validation loss: 2.463100567038474

Epoch: 6| Step: 7
Training loss: 2.638693108462633
Validation loss: 2.457709846735995

Epoch: 6| Step: 8
Training loss: 2.912463365578177
Validation loss: 2.448391529559515

Epoch: 6| Step: 9
Training loss: 3.301797816370716
Validation loss: 2.4527810987409646

Epoch: 6| Step: 10
Training loss: 2.9604821974829996
Validation loss: 2.4475786609786563

Epoch: 6| Step: 11
Training loss: 2.7592411825321372
Validation loss: 2.4555597553629607

Epoch: 6| Step: 12
Training loss: 2.2674534226988845
Validation loss: 2.454252742658524

Epoch: 6| Step: 13
Training loss: 3.2368179899042926
Validation loss: 2.452330046191631

Epoch: 96| Step: 0
Training loss: 2.36349259369434
Validation loss: 2.450938009484374

Epoch: 6| Step: 1
Training loss: 2.824924069624794
Validation loss: 2.4520101449560134

Epoch: 6| Step: 2
Training loss: 2.9973304314966964
Validation loss: 2.4596876411824056

Epoch: 6| Step: 3
Training loss: 2.709112603000038
Validation loss: 2.4535693446864926

Epoch: 6| Step: 4
Training loss: 2.101780536217879
Validation loss: 2.4710988918547128

Epoch: 6| Step: 5
Training loss: 2.7233315811089334
Validation loss: 2.4767305412822975

Epoch: 6| Step: 6
Training loss: 3.1854624500232007
Validation loss: 2.4966483455121384

Epoch: 6| Step: 7
Training loss: 2.7177645771897883
Validation loss: 2.527670763104831

Epoch: 6| Step: 8
Training loss: 2.967678318338302
Validation loss: 2.5516930253842727

Epoch: 6| Step: 9
Training loss: 2.9671453054118757
Validation loss: 2.5733066233598807

Epoch: 6| Step: 10
Training loss: 3.2401085496308784
Validation loss: 2.5308104740777546

Epoch: 6| Step: 11
Training loss: 2.283437646678159
Validation loss: 2.5064775892371203

Epoch: 6| Step: 12
Training loss: 2.6045205651458345
Validation loss: 2.4898057933396807

Epoch: 6| Step: 13
Training loss: 2.984664982792755
Validation loss: 2.4609305182932677

Epoch: 97| Step: 0
Training loss: 2.6855686256221465
Validation loss: 2.464274279137474

Epoch: 6| Step: 1
Training loss: 2.979032517905237
Validation loss: 2.4523727134021294

Epoch: 6| Step: 2
Training loss: 2.8911716253639406
Validation loss: 2.446379831894814

Epoch: 6| Step: 3
Training loss: 2.5985931771920967
Validation loss: 2.45164503312335

Epoch: 6| Step: 4
Training loss: 2.7000960650838244
Validation loss: 2.455856018440434

Epoch: 6| Step: 5
Training loss: 3.0507831255996156
Validation loss: 2.4563785043739674

Epoch: 6| Step: 6
Training loss: 2.747731747212357
Validation loss: 2.4452613852220138

Epoch: 6| Step: 7
Training loss: 2.4705207365362796
Validation loss: 2.4512602003763115

Epoch: 6| Step: 8
Training loss: 2.804969454648305
Validation loss: 2.446350249632848

Epoch: 6| Step: 9
Training loss: 2.7805173101683787
Validation loss: 2.4510731834301245

Epoch: 6| Step: 10
Training loss: 2.4180584769170754
Validation loss: 2.4497302505600262

Epoch: 6| Step: 11
Training loss: 2.2991823816355756
Validation loss: 2.4533509839512195

Epoch: 6| Step: 12
Training loss: 3.151025205626985
Validation loss: 2.45074203141675

Epoch: 6| Step: 13
Training loss: 2.9799311441748846
Validation loss: 2.441294622154014

Epoch: 98| Step: 0
Training loss: 2.4448409433251848
Validation loss: 2.4491448579422164

Epoch: 6| Step: 1
Training loss: 2.5601671346107686
Validation loss: 2.4457285128550637

Epoch: 6| Step: 2
Training loss: 3.047346029796646
Validation loss: 2.4479595158757714

Epoch: 6| Step: 3
Training loss: 2.265362217889441
Validation loss: 2.4461466091906434

Epoch: 6| Step: 4
Training loss: 2.4175032998095047
Validation loss: 2.440512972921807

Epoch: 6| Step: 5
Training loss: 3.01230197113158
Validation loss: 2.4422685893042275

Epoch: 6| Step: 6
Training loss: 2.4938489583584875
Validation loss: 2.445710975166382

Epoch: 6| Step: 7
Training loss: 2.9127338233703512
Validation loss: 2.4483570890462882

Epoch: 6| Step: 8
Training loss: 3.281343876540281
Validation loss: 2.453313330809658

Epoch: 6| Step: 9
Training loss: 2.3996239129082038
Validation loss: 2.4561263143995875

Epoch: 6| Step: 10
Training loss: 2.8458423672072386
Validation loss: 2.4747036844874333

Epoch: 6| Step: 11
Training loss: 3.4638783379701414
Validation loss: 2.4858628750966956

Epoch: 6| Step: 12
Training loss: 2.147373671274292
Validation loss: 2.5081386824914262

Epoch: 6| Step: 13
Training loss: 2.808124189956178
Validation loss: 2.5060966913297094

Epoch: 99| Step: 0
Training loss: 3.012693254912182
Validation loss: 2.5080833934052027

Epoch: 6| Step: 1
Training loss: 3.14488788738466
Validation loss: 2.4960542098910214

Epoch: 6| Step: 2
Training loss: 2.09718553315913
Validation loss: 2.468641046892725

Epoch: 6| Step: 3
Training loss: 3.2481204246501982
Validation loss: 2.4534796249514055

Epoch: 6| Step: 4
Training loss: 2.2810729493714144
Validation loss: 2.449182769861235

Epoch: 6| Step: 5
Training loss: 2.978968331375132
Validation loss: 2.445324030163624

Epoch: 6| Step: 6
Training loss: 2.4967042179449885
Validation loss: 2.4399130624662964

Epoch: 6| Step: 7
Training loss: 2.368448959989262
Validation loss: 2.4415490266130897

Epoch: 6| Step: 8
Training loss: 2.676516867547605
Validation loss: 2.4378822264669355

Epoch: 6| Step: 9
Training loss: 2.72003809790016
Validation loss: 2.444034325578566

Epoch: 6| Step: 10
Training loss: 2.6800608027378914
Validation loss: 2.4427096455671506

Epoch: 6| Step: 11
Training loss: 2.557176503205945
Validation loss: 2.4477134381100956

Epoch: 6| Step: 12
Training loss: 3.12207871269788
Validation loss: 2.455397198971863

Epoch: 6| Step: 13
Training loss: 3.104152568469366
Validation loss: 2.460447822028937

Epoch: 100| Step: 0
Training loss: 3.4621333344697995
Validation loss: 2.46537283410307

Epoch: 6| Step: 1
Training loss: 2.432691379244225
Validation loss: 2.4923304112010896

Epoch: 6| Step: 2
Training loss: 3.336999942878995
Validation loss: 2.5103294416294593

Epoch: 6| Step: 3
Training loss: 1.990387945268072
Validation loss: 2.5190646808669066

Epoch: 6| Step: 4
Training loss: 2.3284786902974726
Validation loss: 2.514184508656829

Epoch: 6| Step: 5
Training loss: 3.2354243690872293
Validation loss: 2.4760919389589264

Epoch: 6| Step: 6
Training loss: 2.711582250080236
Validation loss: 2.457947884513373

Epoch: 6| Step: 7
Training loss: 2.910077271893919
Validation loss: 2.441828369925675

Epoch: 6| Step: 8
Training loss: 1.8275099803897303
Validation loss: 2.437470972578792

Epoch: 6| Step: 9
Training loss: 2.8007758019472813
Validation loss: 2.450524086196106

Epoch: 6| Step: 10
Training loss: 2.818198809474612
Validation loss: 2.4472309790318456

Epoch: 6| Step: 11
Training loss: 2.883582366449608
Validation loss: 2.451678649471968

Epoch: 6| Step: 12
Training loss: 2.6240531485280645
Validation loss: 2.448995953329445

Epoch: 6| Step: 13
Training loss: 2.796883524450173
Validation loss: 2.449197541313981

Epoch: 101| Step: 0
Training loss: 2.3770979599721405
Validation loss: 2.452416638475414

Epoch: 6| Step: 1
Training loss: 2.7285278582179235
Validation loss: 2.4388180953339713

Epoch: 6| Step: 2
Training loss: 2.821069251318309
Validation loss: 2.4430241593897244

Epoch: 6| Step: 3
Training loss: 3.1321759040904835
Validation loss: 2.448460949929708

Epoch: 6| Step: 4
Training loss: 2.5591771050450127
Validation loss: 2.440783990130379

Epoch: 6| Step: 5
Training loss: 2.9139361724879946
Validation loss: 2.4537152072234996

Epoch: 6| Step: 6
Training loss: 2.153913697294547
Validation loss: 2.4560130497904167

Epoch: 6| Step: 7
Training loss: 2.961674339386106
Validation loss: 2.4606680565477994

Epoch: 6| Step: 8
Training loss: 3.0902347823639285
Validation loss: 2.481901708831934

Epoch: 6| Step: 9
Training loss: 2.693160195624173
Validation loss: 2.4753538213788024

Epoch: 6| Step: 10
Training loss: 2.634955012681196
Validation loss: 2.4721479789195633

Epoch: 6| Step: 11
Training loss: 2.422645593919295
Validation loss: 2.4616044012824068

Epoch: 6| Step: 12
Training loss: 2.9845080920196154
Validation loss: 2.4654232615594913

Epoch: 6| Step: 13
Training loss: 2.571175288411705
Validation loss: 2.4614420441147056

Epoch: 102| Step: 0
Training loss: 2.3866550168582448
Validation loss: 2.4556124535306707

Epoch: 6| Step: 1
Training loss: 2.983999817917233
Validation loss: 2.4553929004747648

Epoch: 6| Step: 2
Training loss: 3.0136949757094214
Validation loss: 2.457809388931949

Epoch: 6| Step: 3
Training loss: 3.1145168709866775
Validation loss: 2.470020003350505

Epoch: 6| Step: 4
Training loss: 2.666777270725419
Validation loss: 2.4639278241810234

Epoch: 6| Step: 5
Training loss: 2.319471418740381
Validation loss: 2.458355909952647

Epoch: 6| Step: 6
Training loss: 2.470561654484834
Validation loss: 2.456258402527207

Epoch: 6| Step: 7
Training loss: 3.1265563141219728
Validation loss: 2.4488086912257887

Epoch: 6| Step: 8
Training loss: 3.004414489372296
Validation loss: 2.4614695619556297

Epoch: 6| Step: 9
Training loss: 2.2238860524303705
Validation loss: 2.456760577765017

Epoch: 6| Step: 10
Training loss: 2.915496718680744
Validation loss: 2.4736360470613916

Epoch: 6| Step: 11
Training loss: 2.5234799219114628
Validation loss: 2.479475488314762

Epoch: 6| Step: 12
Training loss: 2.607554000192924
Validation loss: 2.4766128538543115

Epoch: 6| Step: 13
Training loss: 2.7344208631756404
Validation loss: 2.483851539598162

Epoch: 103| Step: 0
Training loss: 2.480539107638976
Validation loss: 2.483486610816979

Epoch: 6| Step: 1
Training loss: 2.298758013878814
Validation loss: 2.468242145980575

Epoch: 6| Step: 2
Training loss: 2.7200521222898715
Validation loss: 2.4724412101515654

Epoch: 6| Step: 3
Training loss: 2.4797240092925588
Validation loss: 2.4668223013774915

Epoch: 6| Step: 4
Training loss: 3.1364527075261077
Validation loss: 2.460008476655237

Epoch: 6| Step: 5
Training loss: 2.841192415847978
Validation loss: 2.4642627944675315

Epoch: 6| Step: 6
Training loss: 2.6787871246684665
Validation loss: 2.455368856107263

Epoch: 6| Step: 7
Training loss: 3.0292307626973347
Validation loss: 2.461957680930591

Epoch: 6| Step: 8
Training loss: 2.5253665506936906
Validation loss: 2.4694937253839755

Epoch: 6| Step: 9
Training loss: 2.6685390058457483
Validation loss: 2.4602958461218525

Epoch: 6| Step: 10
Training loss: 2.8866914946594755
Validation loss: 2.459746040551675

Epoch: 6| Step: 11
Training loss: 3.1482072845423175
Validation loss: 2.4823181231868747

Epoch: 6| Step: 12
Training loss: 2.1631705859565846
Validation loss: 2.481362183886624

Epoch: 6| Step: 13
Training loss: 3.1005121177235995
Validation loss: 2.4810529981171174

Epoch: 104| Step: 0
Training loss: 2.818858778518786
Validation loss: 2.48222558997514

Epoch: 6| Step: 1
Training loss: 2.5767962181452013
Validation loss: 2.494314749584645

Epoch: 6| Step: 2
Training loss: 2.41692333393089
Validation loss: 2.480543477279038

Epoch: 6| Step: 3
Training loss: 2.657928385330235
Validation loss: 2.479801094389502

Epoch: 6| Step: 4
Training loss: 2.6704191290390256
Validation loss: 2.485228787219091

Epoch: 6| Step: 5
Training loss: 2.7515571693832346
Validation loss: 2.4691916668172174

Epoch: 6| Step: 6
Training loss: 2.3704298117368094
Validation loss: 2.4536088547686825

Epoch: 6| Step: 7
Training loss: 3.0702208682454053
Validation loss: 2.443852804301326

Epoch: 6| Step: 8
Training loss: 2.7089646606168016
Validation loss: 2.4436174923949703

Epoch: 6| Step: 9
Training loss: 3.1287338837998364
Validation loss: 2.4524043085079703

Epoch: 6| Step: 10
Training loss: 2.8500544492640016
Validation loss: 2.4610200007722547

Epoch: 6| Step: 11
Training loss: 2.484829171370695
Validation loss: 2.4828604004284798

Epoch: 6| Step: 12
Training loss: 2.8913238505403736
Validation loss: 2.49673607041205

Epoch: 6| Step: 13
Training loss: 2.8220268808513427
Validation loss: 2.4987888263321283

Epoch: 105| Step: 0
Training loss: 2.747381524264179
Validation loss: 2.5060136239381436

Epoch: 6| Step: 1
Training loss: 3.1169197904505883
Validation loss: 2.523651400473977

Epoch: 6| Step: 2
Training loss: 2.7175093703121567
Validation loss: 2.5370228167424775

Epoch: 6| Step: 3
Training loss: 3.2759894936454828
Validation loss: 2.5479536552408355

Epoch: 6| Step: 4
Training loss: 2.1822511097152115
Validation loss: 2.5466684383111176

Epoch: 6| Step: 5
Training loss: 2.749822437449371
Validation loss: 2.5543768201715067

Epoch: 6| Step: 6
Training loss: 2.816553881792956
Validation loss: 2.5341124974825844

Epoch: 6| Step: 7
Training loss: 3.1540147779235834
Validation loss: 2.4926604770648857

Epoch: 6| Step: 8
Training loss: 2.8093113095337996
Validation loss: 2.4857854406599653

Epoch: 6| Step: 9
Training loss: 2.3299164504105194
Validation loss: 2.477385154787365

Epoch: 6| Step: 10
Training loss: 2.5959748067823636
Validation loss: 2.4721564450496207

Epoch: 6| Step: 11
Training loss: 2.8517755298209133
Validation loss: 2.479310910902685

Epoch: 6| Step: 12
Training loss: 2.385311829596722
Validation loss: 2.4593063905105317

Epoch: 6| Step: 13
Training loss: 2.939252939092827
Validation loss: 2.4600550749114647

Epoch: 106| Step: 0
Training loss: 2.9164428806738028
Validation loss: 2.458804215984891

Epoch: 6| Step: 1
Training loss: 3.457118560205717
Validation loss: 2.462161232934049

Epoch: 6| Step: 2
Training loss: 2.4369541437329563
Validation loss: 2.461213231367547

Epoch: 6| Step: 3
Training loss: 2.8152081484768563
Validation loss: 2.4676866672634286

Epoch: 6| Step: 4
Training loss: 2.8972096271511365
Validation loss: 2.4853951192772996

Epoch: 6| Step: 5
Training loss: 2.568315280782374
Validation loss: 2.493427194715364

Epoch: 6| Step: 6
Training loss: 3.3038460311759814
Validation loss: 2.5163224943159954

Epoch: 6| Step: 7
Training loss: 2.574221899004618
Validation loss: 2.536110527283119

Epoch: 6| Step: 8
Training loss: 2.3735999950160793
Validation loss: 2.5277471436453998

Epoch: 6| Step: 9
Training loss: 2.56224449558655
Validation loss: 2.515072761382908

Epoch: 6| Step: 10
Training loss: 2.725852458501523
Validation loss: 2.4945033939589667

Epoch: 6| Step: 11
Training loss: 2.5622858097530448
Validation loss: 2.468565067225083

Epoch: 6| Step: 12
Training loss: 2.3683839298707503
Validation loss: 2.464876566461843

Epoch: 6| Step: 13
Training loss: 2.783318168537911
Validation loss: 2.4644038307673277

Epoch: 107| Step: 0
Training loss: 2.067570089976476
Validation loss: 2.4510589577522848

Epoch: 6| Step: 1
Training loss: 2.7064282294735813
Validation loss: 2.455821206589412

Epoch: 6| Step: 2
Training loss: 3.129965994409471
Validation loss: 2.449312532017685

Epoch: 6| Step: 3
Training loss: 2.7844273280782748
Validation loss: 2.4481936093678014

Epoch: 6| Step: 4
Training loss: 2.9547791061846254
Validation loss: 2.457961027326321

Epoch: 6| Step: 5
Training loss: 2.684291432404386
Validation loss: 2.4618836375415305

Epoch: 6| Step: 6
Training loss: 2.3921335484595696
Validation loss: 2.4480189846406413

Epoch: 6| Step: 7
Training loss: 2.659933610245392
Validation loss: 2.458147033200687

Epoch: 6| Step: 8
Training loss: 2.3027992918847344
Validation loss: 2.4662767105639865

Epoch: 6| Step: 9
Training loss: 2.7519872594250137
Validation loss: 2.469687583274261

Epoch: 6| Step: 10
Training loss: 2.528445915912544
Validation loss: 2.4804392187511484

Epoch: 6| Step: 11
Training loss: 2.8324949108593196
Validation loss: 2.4794875616580794

Epoch: 6| Step: 12
Training loss: 3.3289183624698966
Validation loss: 2.4679843415706455

Epoch: 6| Step: 13
Training loss: 2.921376721331402
Validation loss: 2.4759542610412995

Epoch: 108| Step: 0
Training loss: 2.479604880020797
Validation loss: 2.465133489530202

Epoch: 6| Step: 1
Training loss: 2.576535746549438
Validation loss: 2.4638439427397927

Epoch: 6| Step: 2
Training loss: 2.7331396309517473
Validation loss: 2.452467134768604

Epoch: 6| Step: 3
Training loss: 2.634999891856588
Validation loss: 2.4454269185837814

Epoch: 6| Step: 4
Training loss: 2.085079631062347
Validation loss: 2.4392299734107548

Epoch: 6| Step: 5
Training loss: 2.867298092905002
Validation loss: 2.4394456782550376

Epoch: 6| Step: 6
Training loss: 2.6799028048754123
Validation loss: 2.4494889442257928

Epoch: 6| Step: 7
Training loss: 3.126493478572699
Validation loss: 2.4559570898515073

Epoch: 6| Step: 8
Training loss: 2.2074125517548864
Validation loss: 2.458911247657896

Epoch: 6| Step: 9
Training loss: 2.416996725058872
Validation loss: 2.4749096909155046

Epoch: 6| Step: 10
Training loss: 3.455541809261847
Validation loss: 2.4881869987077283

Epoch: 6| Step: 11
Training loss: 2.3855908814714577
Validation loss: 2.4698243914084284

Epoch: 6| Step: 12
Training loss: 3.1917727387201626
Validation loss: 2.4828510384146263

Epoch: 6| Step: 13
Training loss: 2.725397861378705
Validation loss: 2.4592357339794395

Epoch: 109| Step: 0
Training loss: 2.199441847656615
Validation loss: 2.4514813596330725

Epoch: 6| Step: 1
Training loss: 3.450791895553961
Validation loss: 2.4557079404351754

Epoch: 6| Step: 2
Training loss: 2.6448933791536975
Validation loss: 2.453485888073463

Epoch: 6| Step: 3
Training loss: 2.955375661450329
Validation loss: 2.446722265942208

Epoch: 6| Step: 4
Training loss: 2.948992385766466
Validation loss: 2.450082439184972

Epoch: 6| Step: 5
Training loss: 2.64355919692772
Validation loss: 2.4514676571111282

Epoch: 6| Step: 6
Training loss: 2.3311802830639237
Validation loss: 2.448352615890453

Epoch: 6| Step: 7
Training loss: 2.6975457269082552
Validation loss: 2.442675776695077

Epoch: 6| Step: 8
Training loss: 2.892840222236894
Validation loss: 2.4593851751526765

Epoch: 6| Step: 9
Training loss: 1.8925655274026036
Validation loss: 2.456333554278292

Epoch: 6| Step: 10
Training loss: 2.8195229902011705
Validation loss: 2.4620293630937526

Epoch: 6| Step: 11
Training loss: 2.692983311989204
Validation loss: 2.461017675700293

Epoch: 6| Step: 12
Training loss: 3.0915440873542748
Validation loss: 2.4624177006486696

Epoch: 6| Step: 13
Training loss: 1.279931995477803
Validation loss: 2.468654743401007

Epoch: 110| Step: 0
Training loss: 2.3221855438515764
Validation loss: 2.453582311385921

Epoch: 6| Step: 1
Training loss: 3.13488274946692
Validation loss: 2.4472092387584983

Epoch: 6| Step: 2
Training loss: 3.106508093076313
Validation loss: 2.4421318184264136

Epoch: 6| Step: 3
Training loss: 2.3784491940858556
Validation loss: 2.4329239207826387

Epoch: 6| Step: 4
Training loss: 2.505879450395763
Validation loss: 2.4252249190220367

Epoch: 6| Step: 5
Training loss: 3.038396061096129
Validation loss: 2.4313908448306543

Epoch: 6| Step: 6
Training loss: 2.5110195485960274
Validation loss: 2.421266442411935

Epoch: 6| Step: 7
Training loss: 2.5079649881842467
Validation loss: 2.4398721627180686

Epoch: 6| Step: 8
Training loss: 1.8145033189875126
Validation loss: 2.4324105808492376

Epoch: 6| Step: 9
Training loss: 3.144225831926409
Validation loss: 2.428631230095684

Epoch: 6| Step: 10
Training loss: 2.739736825875988
Validation loss: 2.4521889030175807

Epoch: 6| Step: 11
Training loss: 2.718990534522868
Validation loss: 2.446605547164224

Epoch: 6| Step: 12
Training loss: 2.5941213319000984
Validation loss: 2.4607487358883984

Epoch: 6| Step: 13
Training loss: 3.2802622443709746
Validation loss: 2.4661083758931635

Epoch: 111| Step: 0
Training loss: 2.2923438603300594
Validation loss: 2.4836537057106467

Epoch: 6| Step: 1
Training loss: 2.50816119375381
Validation loss: 2.499950688911516

Epoch: 6| Step: 2
Training loss: 3.1648350655486714
Validation loss: 2.4930219600493095

Epoch: 6| Step: 3
Training loss: 2.935727985046479
Validation loss: 2.4903501586892296

Epoch: 6| Step: 4
Training loss: 2.2462952100548432
Validation loss: 2.4719684723013273

Epoch: 6| Step: 5
Training loss: 2.6052057456626887
Validation loss: 2.460895798019431

Epoch: 6| Step: 6
Training loss: 2.551667834862413
Validation loss: 2.449411038101956

Epoch: 6| Step: 7
Training loss: 2.4689480665885775
Validation loss: 2.442144559272339

Epoch: 6| Step: 8
Training loss: 2.36640539562856
Validation loss: 2.4358608760089573

Epoch: 6| Step: 9
Training loss: 3.46569056951962
Validation loss: 2.4333449847079667

Epoch: 6| Step: 10
Training loss: 2.4997100661954903
Validation loss: 2.4319183698362012

Epoch: 6| Step: 11
Training loss: 2.8664483305118447
Validation loss: 2.435328737347744

Epoch: 6| Step: 12
Training loss: 2.9789888199938646
Validation loss: 2.436375984874121

Epoch: 6| Step: 13
Training loss: 2.655928827952276
Validation loss: 2.4506926439986985

Epoch: 112| Step: 0
Training loss: 2.540311347772518
Validation loss: 2.4649452381124424

Epoch: 6| Step: 1
Training loss: 2.1829825485936896
Validation loss: 2.4732106218870036

Epoch: 6| Step: 2
Training loss: 3.2007255685295894
Validation loss: 2.486038463214956

Epoch: 6| Step: 3
Training loss: 2.809062213055308
Validation loss: 2.4868322762755217

Epoch: 6| Step: 4
Training loss: 1.3728210784484305
Validation loss: 2.5045703233025067

Epoch: 6| Step: 5
Training loss: 2.8656174521310427
Validation loss: 2.4933893252603685

Epoch: 6| Step: 6
Training loss: 2.499840159074746
Validation loss: 2.476374691920329

Epoch: 6| Step: 7
Training loss: 3.146035463689808
Validation loss: 2.4776516658865537

Epoch: 6| Step: 8
Training loss: 2.604549491718207
Validation loss: 2.480879262335029

Epoch: 6| Step: 9
Training loss: 2.9923116394267377
Validation loss: 2.4691110691940055

Epoch: 6| Step: 10
Training loss: 2.892372221898026
Validation loss: 2.484316137339759

Epoch: 6| Step: 11
Training loss: 2.4654135068205165
Validation loss: 2.465123316618858

Epoch: 6| Step: 12
Training loss: 3.0824474058591327
Validation loss: 2.441952112615677

Epoch: 6| Step: 13
Training loss: 3.000725817298713
Validation loss: 2.429502427047654

Epoch: 113| Step: 0
Training loss: 3.384795772640552
Validation loss: 2.4312083331568117

Epoch: 6| Step: 1
Training loss: 2.8634611023834915
Validation loss: 2.4289405164335043

Epoch: 6| Step: 2
Training loss: 2.355264683324493
Validation loss: 2.4389911262964863

Epoch: 6| Step: 3
Training loss: 2.6003593893354116
Validation loss: 2.4407391335903097

Epoch: 6| Step: 4
Training loss: 3.1307177306348035
Validation loss: 2.4378985154657835

Epoch: 6| Step: 5
Training loss: 2.7637671140833615
Validation loss: 2.439707908526253

Epoch: 6| Step: 6
Training loss: 2.4322536446474152
Validation loss: 2.438106519251874

Epoch: 6| Step: 7
Training loss: 3.252528014359276
Validation loss: 2.4445449576970835

Epoch: 6| Step: 8
Training loss: 2.2923165064668343
Validation loss: 2.433704798815191

Epoch: 6| Step: 9
Training loss: 2.568066946577143
Validation loss: 2.4450283845415264

Epoch: 6| Step: 10
Training loss: 2.39008459827301
Validation loss: 2.44666609140967

Epoch: 6| Step: 11
Training loss: 2.6420964762812935
Validation loss: 2.460807745566911

Epoch: 6| Step: 12
Training loss: 2.3451875474188326
Validation loss: 2.4833571694746914

Epoch: 6| Step: 13
Training loss: 3.110832294580092
Validation loss: 2.5026030125212553

Epoch: 114| Step: 0
Training loss: 3.2450009559665207
Validation loss: 2.4814582151517315

Epoch: 6| Step: 1
Training loss: 2.6254362924489345
Validation loss: 2.47546444153598

Epoch: 6| Step: 2
Training loss: 2.474535572905491
Validation loss: 2.466283409991258

Epoch: 6| Step: 3
Training loss: 2.754229587484484
Validation loss: 2.4358870052371557

Epoch: 6| Step: 4
Training loss: 2.8881437632634968
Validation loss: 2.4382106143777484

Epoch: 6| Step: 5
Training loss: 2.065862515597204
Validation loss: 2.429849564955419

Epoch: 6| Step: 6
Training loss: 2.07037134626716
Validation loss: 2.4377895337873268

Epoch: 6| Step: 7
Training loss: 2.6799173951584865
Validation loss: 2.4341347589030558

Epoch: 6| Step: 8
Training loss: 3.119948003775808
Validation loss: 2.4315674027957437

Epoch: 6| Step: 9
Training loss: 2.72120958640807
Validation loss: 2.434905243208828

Epoch: 6| Step: 10
Training loss: 2.770095746144898
Validation loss: 2.429570078926428

Epoch: 6| Step: 11
Training loss: 2.1915435476012597
Validation loss: 2.4520540791379664

Epoch: 6| Step: 12
Training loss: 2.7018809018940897
Validation loss: 2.4493126010984074

Epoch: 6| Step: 13
Training loss: 3.2185888157457687
Validation loss: 2.449786530638056

Epoch: 115| Step: 0
Training loss: 2.4098384901196
Validation loss: 2.459569270645997

Epoch: 6| Step: 1
Training loss: 2.8445611153291774
Validation loss: 2.4688250342197358

Epoch: 6| Step: 2
Training loss: 2.9208133829245395
Validation loss: 2.458554583465948

Epoch: 6| Step: 3
Training loss: 2.3993990582876923
Validation loss: 2.463301755282658

Epoch: 6| Step: 4
Training loss: 2.904479441134781
Validation loss: 2.456061075574486

Epoch: 6| Step: 5
Training loss: 2.562596109960449
Validation loss: 2.4383043939719093

Epoch: 6| Step: 6
Training loss: 2.8241481745806656
Validation loss: 2.4389066063696005

Epoch: 6| Step: 7
Training loss: 2.111464532191608
Validation loss: 2.438254838740581

Epoch: 6| Step: 8
Training loss: 2.673783362538483
Validation loss: 2.4363191614047914

Epoch: 6| Step: 9
Training loss: 2.613329238336949
Validation loss: 2.4411303780838267

Epoch: 6| Step: 10
Training loss: 3.332549829589832
Validation loss: 2.434973376683764

Epoch: 6| Step: 11
Training loss: 2.3082122229285287
Validation loss: 2.437855115400613

Epoch: 6| Step: 12
Training loss: 2.847768773497014
Validation loss: 2.436732342465947

Epoch: 6| Step: 13
Training loss: 3.0640388826338336
Validation loss: 2.4320554209899603

Epoch: 116| Step: 0
Training loss: 2.252709664463431
Validation loss: 2.4317738301780825

Epoch: 6| Step: 1
Training loss: 2.353681655029294
Validation loss: 2.4365603516069387

Epoch: 6| Step: 2
Training loss: 2.907992917079774
Validation loss: 2.4390376488995282

Epoch: 6| Step: 3
Training loss: 2.1282391264082157
Validation loss: 2.43860169790481

Epoch: 6| Step: 4
Training loss: 2.783876700290779
Validation loss: 2.4501369993853768

Epoch: 6| Step: 5
Training loss: 2.967105610838883
Validation loss: 2.459809901809943

Epoch: 6| Step: 6
Training loss: 2.858471169962082
Validation loss: 2.473167210213468

Epoch: 6| Step: 7
Training loss: 2.2357301670556784
Validation loss: 2.4896260708939395

Epoch: 6| Step: 8
Training loss: 2.7190490207441043
Validation loss: 2.509268864938508

Epoch: 6| Step: 9
Training loss: 2.8774002670384475
Validation loss: 2.5072440987225404

Epoch: 6| Step: 10
Training loss: 3.007894301850302
Validation loss: 2.507339961017729

Epoch: 6| Step: 11
Training loss: 3.126475024203029
Validation loss: 2.4984677172002914

Epoch: 6| Step: 12
Training loss: 2.2685181134051295
Validation loss: 2.4520143589453904

Epoch: 6| Step: 13
Training loss: 3.3247514560133204
Validation loss: 2.4331341652548084

Epoch: 117| Step: 0
Training loss: 2.255591332830969
Validation loss: 2.4364318800203995

Epoch: 6| Step: 1
Training loss: 3.0999002686732062
Validation loss: 2.436972338807745

Epoch: 6| Step: 2
Training loss: 2.627499162726446
Validation loss: 2.435661125021407

Epoch: 6| Step: 3
Training loss: 2.209468285993606
Validation loss: 2.4352857073046943

Epoch: 6| Step: 4
Training loss: 2.669682456432295
Validation loss: 2.439773242079241

Epoch: 6| Step: 5
Training loss: 2.874616680299268
Validation loss: 2.445407511623222

Epoch: 6| Step: 6
Training loss: 2.692232533862545
Validation loss: 2.449264729783866

Epoch: 6| Step: 7
Training loss: 3.45108565787892
Validation loss: 2.445505012431005

Epoch: 6| Step: 8
Training loss: 2.599104444617796
Validation loss: 2.4532420282853087

Epoch: 6| Step: 9
Training loss: 2.4489634014181583
Validation loss: 2.448411683506

Epoch: 6| Step: 10
Training loss: 2.2533315788728703
Validation loss: 2.457353428601659

Epoch: 6| Step: 11
Training loss: 2.6851324254061986
Validation loss: 2.4632835600718326

Epoch: 6| Step: 12
Training loss: 2.581739077290346
Validation loss: 2.4672447912990743

Epoch: 6| Step: 13
Training loss: 2.8572566622820696
Validation loss: 2.4749005557181385

Epoch: 118| Step: 0
Training loss: 3.668278917679994
Validation loss: 2.4695716737684736

Epoch: 6| Step: 1
Training loss: 2.8738125546463817
Validation loss: 2.4717812387573828

Epoch: 6| Step: 2
Training loss: 2.890511175440545
Validation loss: 2.4695722758612995

Epoch: 6| Step: 3
Training loss: 2.224204437670737
Validation loss: 2.4585939931012235

Epoch: 6| Step: 4
Training loss: 2.5915909019099734
Validation loss: 2.430173392382858

Epoch: 6| Step: 5
Training loss: 2.4420190637142754
Validation loss: 2.4358508913219024

Epoch: 6| Step: 6
Training loss: 2.4559246051535726
Validation loss: 2.434659837191374

Epoch: 6| Step: 7
Training loss: 2.4429725444436072
Validation loss: 2.4337823355213763

Epoch: 6| Step: 8
Training loss: 2.7062609348560747
Validation loss: 2.4375532747625233

Epoch: 6| Step: 9
Training loss: 2.9922330768191743
Validation loss: 2.437584864230527

Epoch: 6| Step: 10
Training loss: 2.574270615467643
Validation loss: 2.4345339063177915

Epoch: 6| Step: 11
Training loss: 2.173283621018595
Validation loss: 2.4391860494530864

Epoch: 6| Step: 12
Training loss: 2.763153696176499
Validation loss: 2.442630976411411

Epoch: 6| Step: 13
Training loss: 2.240840068375281
Validation loss: 2.442429654662891

Epoch: 119| Step: 0
Training loss: 2.873208690367924
Validation loss: 2.456220168758898

Epoch: 6| Step: 1
Training loss: 2.661119731905925
Validation loss: 2.46796186480378

Epoch: 6| Step: 2
Training loss: 2.422197086697662
Validation loss: 2.4671165500736016

Epoch: 6| Step: 3
Training loss: 2.457531706720907
Validation loss: 2.464970726230905

Epoch: 6| Step: 4
Training loss: 2.370319070222282
Validation loss: 2.467468190638171

Epoch: 6| Step: 5
Training loss: 2.845634925669136
Validation loss: 2.4546810095935387

Epoch: 6| Step: 6
Training loss: 2.7155228677909538
Validation loss: 2.4541021861470766

Epoch: 6| Step: 7
Training loss: 2.724801530522417
Validation loss: 2.4413833090740042

Epoch: 6| Step: 8
Training loss: 2.9111636063240494
Validation loss: 2.42949983438986

Epoch: 6| Step: 9
Training loss: 2.5191339697079282
Validation loss: 2.4100155675228088

Epoch: 6| Step: 10
Training loss: 2.8819297534818413
Validation loss: 2.426982212261891

Epoch: 6| Step: 11
Training loss: 2.5708402422333494
Validation loss: 2.432516192840025

Epoch: 6| Step: 12
Training loss: 2.6102647920366047
Validation loss: 2.4297366222212444

Epoch: 6| Step: 13
Training loss: 2.8696245443672184
Validation loss: 2.433791152099975

Epoch: 120| Step: 0
Training loss: 3.2027679988744513
Validation loss: 2.4326871786783486

Epoch: 6| Step: 1
Training loss: 2.181560190437558
Validation loss: 2.437733854861137

Epoch: 6| Step: 2
Training loss: 2.512056271669911
Validation loss: 2.4383601040279976

Epoch: 6| Step: 3
Training loss: 2.0378718499051263
Validation loss: 2.445628842686451

Epoch: 6| Step: 4
Training loss: 2.2403637849501172
Validation loss: 2.4475253394337737

Epoch: 6| Step: 5
Training loss: 2.9260980615356447
Validation loss: 2.454489311908453

Epoch: 6| Step: 6
Training loss: 3.245652004623975
Validation loss: 2.4458023744838098

Epoch: 6| Step: 7
Training loss: 2.5638755269894653
Validation loss: 2.442716281590285

Epoch: 6| Step: 8
Training loss: 2.77193270411417
Validation loss: 2.438066539233497

Epoch: 6| Step: 9
Training loss: 2.642238327250349
Validation loss: 2.4220633738837454

Epoch: 6| Step: 10
Training loss: 2.543053691517718
Validation loss: 2.418554153096039

Epoch: 6| Step: 11
Training loss: 2.824845409383328
Validation loss: 2.4303812451027613

Epoch: 6| Step: 12
Training loss: 2.4437646811744305
Validation loss: 2.433316685246948

Epoch: 6| Step: 13
Training loss: 2.933817564125751
Validation loss: 2.444843434778489

Epoch: 121| Step: 0
Training loss: 2.0969221084237692
Validation loss: 2.4398707999241966

Epoch: 6| Step: 1
Training loss: 1.9370031642700882
Validation loss: 2.4538296424985897

Epoch: 6| Step: 2
Training loss: 2.5740952874592034
Validation loss: 2.4435419768361

Epoch: 6| Step: 3
Training loss: 2.645468248625578
Validation loss: 2.439755077875269

Epoch: 6| Step: 4
Training loss: 2.5986846494324864
Validation loss: 2.432923519312147

Epoch: 6| Step: 5
Training loss: 2.546021488143967
Validation loss: 2.4276231766300804

Epoch: 6| Step: 6
Training loss: 2.7940574391494892
Validation loss: 2.423716646929706

Epoch: 6| Step: 7
Training loss: 2.6101624905221343
Validation loss: 2.427835057503698

Epoch: 6| Step: 8
Training loss: 2.7974169328644694
Validation loss: 2.4153165564331043

Epoch: 6| Step: 9
Training loss: 2.6886830054909994
Validation loss: 2.4188435042860523

Epoch: 6| Step: 10
Training loss: 2.49964673407384
Validation loss: 2.423665224783569

Epoch: 6| Step: 11
Training loss: 3.329635921886123
Validation loss: 2.425425034835831

Epoch: 6| Step: 12
Training loss: 2.7794085632315277
Validation loss: 2.442411415222678

Epoch: 6| Step: 13
Training loss: 3.3060418277962955
Validation loss: 2.449434484719021

Epoch: 122| Step: 0
Training loss: 2.405335487869437
Validation loss: 2.4562212500671405

Epoch: 6| Step: 1
Training loss: 2.1280457603725877
Validation loss: 2.4694434329560275

Epoch: 6| Step: 2
Training loss: 2.2532843883924514
Validation loss: 2.4838786285542214

Epoch: 6| Step: 3
Training loss: 3.082801635537432
Validation loss: 2.4637012292565275

Epoch: 6| Step: 4
Training loss: 3.028528466524029
Validation loss: 2.461342037434558

Epoch: 6| Step: 5
Training loss: 2.0463960975499407
Validation loss: 2.4669326151073236

Epoch: 6| Step: 6
Training loss: 2.846159532505628
Validation loss: 2.453646847123861

Epoch: 6| Step: 7
Training loss: 2.709029611926281
Validation loss: 2.456120800135683

Epoch: 6| Step: 8
Training loss: 2.5079115613344696
Validation loss: 2.440828271848546

Epoch: 6| Step: 9
Training loss: 2.709192599412314
Validation loss: 2.4506917956210286

Epoch: 6| Step: 10
Training loss: 2.5813648558549347
Validation loss: 2.4458457724109968

Epoch: 6| Step: 11
Training loss: 3.289383462572093
Validation loss: 2.4577239442112786

Epoch: 6| Step: 12
Training loss: 2.7624201767379852
Validation loss: 2.454130885232126

Epoch: 6| Step: 13
Training loss: 1.994462513140784
Validation loss: 2.451246554139932

Epoch: 123| Step: 0
Training loss: 3.268741270677278
Validation loss: 2.456591779901234

Epoch: 6| Step: 1
Training loss: 2.553881783541799
Validation loss: 2.4625792439437766

Epoch: 6| Step: 2
Training loss: 2.5183875038418604
Validation loss: 2.449293692271232

Epoch: 6| Step: 3
Training loss: 2.496796940238615
Validation loss: 2.449721038210649

Epoch: 6| Step: 4
Training loss: 2.4663288460766433
Validation loss: 2.4440930276434503

Epoch: 6| Step: 5
Training loss: 2.4733710197531993
Validation loss: 2.4580490639000407

Epoch: 6| Step: 6
Training loss: 2.882769493878063
Validation loss: 2.4689610272817792

Epoch: 6| Step: 7
Training loss: 2.291333630955913
Validation loss: 2.4609545041545235

Epoch: 6| Step: 8
Training loss: 2.5408552677771263
Validation loss: 2.445297116928362

Epoch: 6| Step: 9
Training loss: 2.725914208582598
Validation loss: 2.442214258511738

Epoch: 6| Step: 10
Training loss: 2.7302453818797825
Validation loss: 2.4172525965023555

Epoch: 6| Step: 11
Training loss: 2.321125851270832
Validation loss: 2.411013921036451

Epoch: 6| Step: 12
Training loss: 3.061155530126894
Validation loss: 2.4239909952319914

Epoch: 6| Step: 13
Training loss: 2.7226976695255556
Validation loss: 2.4364210674752833

Epoch: 124| Step: 0
Training loss: 2.0768239243523876
Validation loss: 2.4416122445437747

Epoch: 6| Step: 1
Training loss: 1.87814855068884
Validation loss: 2.4479449097508006

Epoch: 6| Step: 2
Training loss: 2.713394151266895
Validation loss: 2.4522155085276727

Epoch: 6| Step: 3
Training loss: 2.9402125394640573
Validation loss: 2.474517599123501

Epoch: 6| Step: 4
Training loss: 2.7313987010569774
Validation loss: 2.4844585282636626

Epoch: 6| Step: 5
Training loss: 2.6495054899217494
Validation loss: 2.5026456441823957

Epoch: 6| Step: 6
Training loss: 2.8573866637974907
Validation loss: 2.499760780374377

Epoch: 6| Step: 7
Training loss: 2.801539277269287
Validation loss: 2.4836724917769173

Epoch: 6| Step: 8
Training loss: 2.4538564381224086
Validation loss: 2.462083252461364

Epoch: 6| Step: 9
Training loss: 2.9182432727290104
Validation loss: 2.460618880858784

Epoch: 6| Step: 10
Training loss: 2.6166953463916345
Validation loss: 2.4531818145825595

Epoch: 6| Step: 11
Training loss: 3.111946001501274
Validation loss: 2.4496748357100433

Epoch: 6| Step: 12
Training loss: 2.6919536504510546
Validation loss: 2.4433565001140765

Epoch: 6| Step: 13
Training loss: 2.3123984443428363
Validation loss: 2.4258912889671342

Epoch: 125| Step: 0
Training loss: 2.3882771849792648
Validation loss: 2.426559914829349

Epoch: 6| Step: 1
Training loss: 2.5314448717245104
Validation loss: 2.421583266985303

Epoch: 6| Step: 2
Training loss: 1.8179341114975367
Validation loss: 2.4184000862173995

Epoch: 6| Step: 3
Training loss: 2.540913538014628
Validation loss: 2.4224316124411955

Epoch: 6| Step: 4
Training loss: 2.7700626955614758
Validation loss: 2.423096258972853

Epoch: 6| Step: 5
Training loss: 2.983391884454751
Validation loss: 2.4184870548658397

Epoch: 6| Step: 6
Training loss: 2.1841446347115743
Validation loss: 2.425193367291373

Epoch: 6| Step: 7
Training loss: 2.1467627083675547
Validation loss: 2.4341228239652724

Epoch: 6| Step: 8
Training loss: 2.822463802784685
Validation loss: 2.458101463610785

Epoch: 6| Step: 9
Training loss: 2.8879124466577144
Validation loss: 2.479950064890091

Epoch: 6| Step: 10
Training loss: 3.157425463258044
Validation loss: 2.504704992761513

Epoch: 6| Step: 11
Training loss: 2.8303379231815082
Validation loss: 2.544603160049199

Epoch: 6| Step: 12
Training loss: 2.9192066758405395
Validation loss: 2.5804952515429913

Epoch: 6| Step: 13
Training loss: 2.84144767372326
Validation loss: 2.584761410088378

Epoch: 126| Step: 0
Training loss: 2.2851592756724095
Validation loss: 2.640199006887047

Epoch: 6| Step: 1
Training loss: 3.1710852029614274
Validation loss: 2.648669395176384

Epoch: 6| Step: 2
Training loss: 3.2010437693631912
Validation loss: 2.682214087369808

Epoch: 6| Step: 3
Training loss: 2.3288473762305943
Validation loss: 2.623435914423059

Epoch: 6| Step: 4
Training loss: 2.604300950720759
Validation loss: 2.575330298545753

Epoch: 6| Step: 5
Training loss: 2.425128154711099
Validation loss: 2.531683087313676

Epoch: 6| Step: 6
Training loss: 2.3062139079260033
Validation loss: 2.4869549559024806

Epoch: 6| Step: 7
Training loss: 2.8986638641390665
Validation loss: 2.461625351023783

Epoch: 6| Step: 8
Training loss: 2.9709788739336993
Validation loss: 2.439441138314694

Epoch: 6| Step: 9
Training loss: 2.862978139865148
Validation loss: 2.448505204316407

Epoch: 6| Step: 10
Training loss: 2.0809310668717553
Validation loss: 2.45984389119845

Epoch: 6| Step: 11
Training loss: 2.688612596733211
Validation loss: 2.474319941070341

Epoch: 6| Step: 12
Training loss: 2.5988354752627436
Validation loss: 2.477265620175036

Epoch: 6| Step: 13
Training loss: 2.859203229236967
Validation loss: 2.4645004697769397

Epoch: 127| Step: 0
Training loss: 2.67282792437369
Validation loss: 2.449653536784865

Epoch: 6| Step: 1
Training loss: 2.120958186923134
Validation loss: 2.4432134765646123

Epoch: 6| Step: 2
Training loss: 2.7193784316297065
Validation loss: 2.4422000200710174

Epoch: 6| Step: 3
Training loss: 2.9157691846319587
Validation loss: 2.438668985400211

Epoch: 6| Step: 4
Training loss: 2.777624531863251
Validation loss: 2.439905665983247

Epoch: 6| Step: 5
Training loss: 2.6260288583719795
Validation loss: 2.440066301055943

Epoch: 6| Step: 6
Training loss: 3.119599062027089
Validation loss: 2.453568317587227

Epoch: 6| Step: 7
Training loss: 2.634710244854417
Validation loss: 2.450190106103069

Epoch: 6| Step: 8
Training loss: 2.091383664362252
Validation loss: 2.4541077801602493

Epoch: 6| Step: 9
Training loss: 2.7757152391696702
Validation loss: 2.4439767843547275

Epoch: 6| Step: 10
Training loss: 2.067292627269467
Validation loss: 2.4652835543345923

Epoch: 6| Step: 11
Training loss: 2.6826232310179465
Validation loss: 2.4666509176800244

Epoch: 6| Step: 12
Training loss: 2.752574669070282
Validation loss: 2.4754846205106196

Epoch: 6| Step: 13
Training loss: 2.2658241973651614
Validation loss: 2.4929118372133887

Epoch: 128| Step: 0
Training loss: 2.800328514718271
Validation loss: 2.5139764770017003

Epoch: 6| Step: 1
Training loss: 2.2359516476570778
Validation loss: 2.5146785732287062

Epoch: 6| Step: 2
Training loss: 2.6365671976121554
Validation loss: 2.518898739142281

Epoch: 6| Step: 3
Training loss: 2.88494744370321
Validation loss: 2.502405513671097

Epoch: 6| Step: 4
Training loss: 1.942626446863741
Validation loss: 2.495366652297021

Epoch: 6| Step: 5
Training loss: 2.6168660891727167
Validation loss: 2.4796919713832715

Epoch: 6| Step: 6
Training loss: 2.760674221091431
Validation loss: 2.456371230005764

Epoch: 6| Step: 7
Training loss: 2.7596134864679955
Validation loss: 2.4524688177514045

Epoch: 6| Step: 8
Training loss: 2.596704294260996
Validation loss: 2.432330520388769

Epoch: 6| Step: 9
Training loss: 2.8359253938274662
Validation loss: 2.4340645523604736

Epoch: 6| Step: 10
Training loss: 2.5286080972754426
Validation loss: 2.4308953067584964

Epoch: 6| Step: 11
Training loss: 3.0747184686567683
Validation loss: 2.437588720860469

Epoch: 6| Step: 12
Training loss: 2.521587815885105
Validation loss: 2.449992941251242

Epoch: 6| Step: 13
Training loss: 1.8549857384269712
Validation loss: 2.458144755471297

Epoch: 129| Step: 0
Training loss: 2.862445121139129
Validation loss: 2.4634335304733592

Epoch: 6| Step: 1
Training loss: 2.927761411128503
Validation loss: 2.4677395999223677

Epoch: 6| Step: 2
Training loss: 2.37318983863984
Validation loss: 2.4575257032297464

Epoch: 6| Step: 3
Training loss: 1.7419789279228233
Validation loss: 2.448818941333533

Epoch: 6| Step: 4
Training loss: 2.675549306353512
Validation loss: 2.453870829366188

Epoch: 6| Step: 5
Training loss: 3.0187091769346823
Validation loss: 2.440653256694482

Epoch: 6| Step: 6
Training loss: 2.4051513145255874
Validation loss: 2.4293286569274612

Epoch: 6| Step: 7
Training loss: 2.810672929493817
Validation loss: 2.422856726065595

Epoch: 6| Step: 8
Training loss: 2.5692639284616594
Validation loss: 2.4289243383450496

Epoch: 6| Step: 9
Training loss: 2.484620280123578
Validation loss: 2.4433316484728724

Epoch: 6| Step: 10
Training loss: 3.1895174112282754
Validation loss: 2.463934416584087

Epoch: 6| Step: 11
Training loss: 1.9126838545844138
Validation loss: 2.451770646616481

Epoch: 6| Step: 12
Training loss: 2.579109512542177
Validation loss: 2.4601249847089064

Epoch: 6| Step: 13
Training loss: 2.1076830824929083
Validation loss: 2.459569801183176

Epoch: 130| Step: 0
Training loss: 2.935761282090205
Validation loss: 2.437864094969141

Epoch: 6| Step: 1
Training loss: 2.6900380592064583
Validation loss: 2.414356783361747

Epoch: 6| Step: 2
Training loss: 2.3634029136426054
Validation loss: 2.4280518665154593

Epoch: 6| Step: 3
Training loss: 2.4573867613430775
Validation loss: 2.4596378778473023

Epoch: 6| Step: 4
Training loss: 2.6139595736564023
Validation loss: 2.4661489283684386

Epoch: 6| Step: 5
Training loss: 2.6209580319511074
Validation loss: 2.4648127574294056

Epoch: 6| Step: 6
Training loss: 2.3317927201804354
Validation loss: 2.4653607280324814

Epoch: 6| Step: 7
Training loss: 2.686975206102436
Validation loss: 2.4620091373559974

Epoch: 6| Step: 8
Training loss: 2.7078075974602185
Validation loss: 2.461847200510098

Epoch: 6| Step: 9
Training loss: 2.494975572363275
Validation loss: 2.477509325593793

Epoch: 6| Step: 10
Training loss: 2.85575562587245
Validation loss: 2.463409378304122

Epoch: 6| Step: 11
Training loss: 2.007241728286338
Validation loss: 2.432960099218959

Epoch: 6| Step: 12
Training loss: 2.5467841945444736
Validation loss: 2.4351957213593245

Epoch: 6| Step: 13
Training loss: 2.9520114635978936
Validation loss: 2.421579368984955

Epoch: 131| Step: 0
Training loss: 2.779190329508628
Validation loss: 2.4246721081333273

Epoch: 6| Step: 1
Training loss: 2.2343227140271122
Validation loss: 2.4221647779246074

Epoch: 6| Step: 2
Training loss: 2.4206935831287857
Validation loss: 2.4162284112816796

Epoch: 6| Step: 3
Training loss: 2.541846618118706
Validation loss: 2.4382162322337506

Epoch: 6| Step: 4
Training loss: 2.5065939726671003
Validation loss: 2.448390457358213

Epoch: 6| Step: 5
Training loss: 2.266233796505198
Validation loss: 2.44995317089973

Epoch: 6| Step: 6
Training loss: 2.4452118776721545
Validation loss: 2.470586863638281

Epoch: 6| Step: 7
Training loss: 2.968325293428505
Validation loss: 2.4881625201320223

Epoch: 6| Step: 8
Training loss: 2.5559072586511116
Validation loss: 2.497035518771524

Epoch: 6| Step: 9
Training loss: 2.941694795151643
Validation loss: 2.5213042253060745

Epoch: 6| Step: 10
Training loss: 2.653585825732341
Validation loss: 2.5472727282011807

Epoch: 6| Step: 11
Training loss: 2.3706903004421207
Validation loss: 2.5374482425632654

Epoch: 6| Step: 12
Training loss: 2.5882031061343533
Validation loss: 2.5265876534326708

Epoch: 6| Step: 13
Training loss: 2.1674325640790584
Validation loss: 2.5052268834058666

Epoch: 132| Step: 0
Training loss: 2.3555987118220485
Validation loss: 2.479153715206519

Epoch: 6| Step: 1
Training loss: 2.981281374720257
Validation loss: 2.4623334247073116

Epoch: 6| Step: 2
Training loss: 2.6757039079835128
Validation loss: 2.421547237768315

Epoch: 6| Step: 3
Training loss: 2.8794181710201583
Validation loss: 2.405421706426921

Epoch: 6| Step: 4
Training loss: 2.0190405480071645
Validation loss: 2.4102904978637745

Epoch: 6| Step: 5
Training loss: 2.188288519294647
Validation loss: 2.4074543300447235

Epoch: 6| Step: 6
Training loss: 3.0157965576706762
Validation loss: 2.409743663363085

Epoch: 6| Step: 7
Training loss: 2.8150899194479804
Validation loss: 2.4264232986710432

Epoch: 6| Step: 8
Training loss: 2.1567722738470447
Validation loss: 2.446571914550602

Epoch: 6| Step: 9
Training loss: 2.312077251661667
Validation loss: 2.4585813129952654

Epoch: 6| Step: 10
Training loss: 2.637000039249285
Validation loss: 2.4612144083940595

Epoch: 6| Step: 11
Training loss: 2.5392325476410695
Validation loss: 2.4534159291159687

Epoch: 6| Step: 12
Training loss: 2.156843463111135
Validation loss: 2.4307719736000593

Epoch: 6| Step: 13
Training loss: 2.4962523026472465
Validation loss: 2.413009147723495

Epoch: 133| Step: 0
Training loss: 2.261630410691143
Validation loss: 2.3989581695025537

Epoch: 6| Step: 1
Training loss: 2.3116006906780657
Validation loss: 2.3947681768215827

Epoch: 6| Step: 2
Training loss: 2.9621275269270244
Validation loss: 2.401730633136629

Epoch: 6| Step: 3
Training loss: 2.8023708626143042
Validation loss: 2.401514614075439

Epoch: 6| Step: 4
Training loss: 2.718616087673915
Validation loss: 2.398725078145311

Epoch: 6| Step: 5
Training loss: 1.607194182166758
Validation loss: 2.395221287117586

Epoch: 6| Step: 6
Training loss: 2.792439956224422
Validation loss: 2.4153002807205692

Epoch: 6| Step: 7
Training loss: 2.1977106754142115
Validation loss: 2.4158023190912643

Epoch: 6| Step: 8
Training loss: 2.7903135256146445
Validation loss: 2.4145146492182836

Epoch: 6| Step: 9
Training loss: 2.6174851888767696
Validation loss: 2.424786274250033

Epoch: 6| Step: 10
Training loss: 1.8529422946556129
Validation loss: 2.4314304643660614

Epoch: 6| Step: 11
Training loss: 3.1148363773975327
Validation loss: 2.4437678629525474

Epoch: 6| Step: 12
Training loss: 2.430121576227029
Validation loss: 2.451750771234262

Epoch: 6| Step: 13
Training loss: 2.3640226351950093
Validation loss: 2.452180168268137

Epoch: 134| Step: 0
Training loss: 2.3216107265563752
Validation loss: 2.4785787916538706

Epoch: 6| Step: 1
Training loss: 2.5193079176696926
Validation loss: 2.474118941080209

Epoch: 6| Step: 2
Training loss: 2.579001722674702
Validation loss: 2.4770934288666244

Epoch: 6| Step: 3
Training loss: 2.5357471594416134
Validation loss: 2.462015624521246

Epoch: 6| Step: 4
Training loss: 1.6703205904216043
Validation loss: 2.47070825185442

Epoch: 6| Step: 5
Training loss: 2.103673845749857
Validation loss: 2.4426247872620364

Epoch: 6| Step: 6
Training loss: 1.6222440384278944
Validation loss: 2.4384980515659627

Epoch: 6| Step: 7
Training loss: 2.6804843084939476
Validation loss: 2.4142914692087

Epoch: 6| Step: 8
Training loss: 2.5473362791631233
Validation loss: 2.4113358828629328

Epoch: 6| Step: 9
Training loss: 2.7351074109787836
Validation loss: 2.422181377952117

Epoch: 6| Step: 10
Training loss: 2.886110977386612
Validation loss: 2.408435475757711

Epoch: 6| Step: 11
Training loss: 2.524391301124417
Validation loss: 2.4304545441794976

Epoch: 6| Step: 12
Training loss: 3.2113921871461115
Validation loss: 2.4424919429460634

Epoch: 6| Step: 13
Training loss: 2.78023244695591
Validation loss: 2.434284246098562

Epoch: 135| Step: 0
Training loss: 2.610683273092465
Validation loss: 2.448793144815643

Epoch: 6| Step: 1
Training loss: 1.5623174179212782
Validation loss: 2.4592847027782483

Epoch: 6| Step: 2
Training loss: 3.042841505884202
Validation loss: 2.469922803918204

Epoch: 6| Step: 3
Training loss: 2.40953058316876
Validation loss: 2.4573082835122437

Epoch: 6| Step: 4
Training loss: 2.58983113787818
Validation loss: 2.4718654191968024

Epoch: 6| Step: 5
Training loss: 2.712168037739421
Validation loss: 2.4765092962995405

Epoch: 6| Step: 6
Training loss: 1.8461612516340256
Validation loss: 2.463496553115959

Epoch: 6| Step: 7
Training loss: 2.643192014135577
Validation loss: 2.4693717625298595

Epoch: 6| Step: 8
Training loss: 1.6958128019522487
Validation loss: 2.4825680931716003

Epoch: 6| Step: 9
Training loss: 2.67346839909224
Validation loss: 2.486510752035555

Epoch: 6| Step: 10
Training loss: 2.9421073007212906
Validation loss: 2.4824151292798016

Epoch: 6| Step: 11
Training loss: 2.543970241900405
Validation loss: 2.484735574300097

Epoch: 6| Step: 12
Training loss: 2.6652334554022943
Validation loss: 2.473181213360186

Epoch: 6| Step: 13
Training loss: 2.867871444576906
Validation loss: 2.454458012074149

Epoch: 136| Step: 0
Training loss: 2.196181373110197
Validation loss: 2.4331668214666102

Epoch: 6| Step: 1
Training loss: 2.846403623513654
Validation loss: 2.4140185906921965

Epoch: 6| Step: 2
Training loss: 2.6054412977611108
Validation loss: 2.4099339333289342

Epoch: 6| Step: 3
Training loss: 2.7707096062668715
Validation loss: 2.389893166367448

Epoch: 6| Step: 4
Training loss: 2.4022429158208225
Validation loss: 2.4109051447147607

Epoch: 6| Step: 5
Training loss: 2.3102443106789408
Validation loss: 2.384395132553838

Epoch: 6| Step: 6
Training loss: 2.0056473156527685
Validation loss: 2.3983614608459654

Epoch: 6| Step: 7
Training loss: 2.6114148601316316
Validation loss: 2.3957351243558693

Epoch: 6| Step: 8
Training loss: 1.9366290688380556
Validation loss: 2.3856424687905733

Epoch: 6| Step: 9
Training loss: 2.7827338214527684
Validation loss: 2.370545850461842

Epoch: 6| Step: 10
Training loss: 2.510291279765186
Validation loss: 2.3601797168954026

Epoch: 6| Step: 11
Training loss: 2.4972804536443345
Validation loss: 2.3605381256111495

Epoch: 6| Step: 12
Training loss: 2.2111044237726873
Validation loss: 2.374384352849181

Epoch: 6| Step: 13
Training loss: 3.111054853278846
Validation loss: 2.367120938492441

Epoch: 137| Step: 0
Training loss: 2.8886974609562452
Validation loss: 2.3958619186030066

Epoch: 6| Step: 1
Training loss: 2.869978126150107
Validation loss: 2.4261205746763044

Epoch: 6| Step: 2
Training loss: 2.0811694796912246
Validation loss: 2.4238768762700467

Epoch: 6| Step: 3
Training loss: 2.539505670458912
Validation loss: 2.4504930516588606

Epoch: 6| Step: 4
Training loss: 2.6951645962589623
Validation loss: 2.4891810635156073

Epoch: 6| Step: 5
Training loss: 2.6417676270583557
Validation loss: 2.530227466246582

Epoch: 6| Step: 6
Training loss: 2.0287112289550433
Validation loss: 2.5240239303563032

Epoch: 6| Step: 7
Training loss: 1.9565709956736683
Validation loss: 2.511617057383799

Epoch: 6| Step: 8
Training loss: 2.508702010459336
Validation loss: 2.4888351904866584

Epoch: 6| Step: 9
Training loss: 2.2511424237293522
Validation loss: 2.4567962121406053

Epoch: 6| Step: 10
Training loss: 2.9502428310473015
Validation loss: 2.428502436165705

Epoch: 6| Step: 11
Training loss: 2.4292896595130222
Validation loss: 2.4017331751814606

Epoch: 6| Step: 12
Training loss: 2.225215142810513
Validation loss: 2.3757350498741814

Epoch: 6| Step: 13
Training loss: 1.7058575608558522
Validation loss: 2.3945280509758335

Epoch: 138| Step: 0
Training loss: 2.3363179691197926
Validation loss: 2.3834192819699775

Epoch: 6| Step: 1
Training loss: 2.4363965202102524
Validation loss: 2.3859161611309876

Epoch: 6| Step: 2
Training loss: 2.593307641236328
Validation loss: 2.3846896368930275

Epoch: 6| Step: 3
Training loss: 2.8208684399747805
Validation loss: 2.397685222219268

Epoch: 6| Step: 4
Training loss: 2.152608256348064
Validation loss: 2.399664360336628

Epoch: 6| Step: 5
Training loss: 1.8529853343599423
Validation loss: 2.4370464484601744

Epoch: 6| Step: 6
Training loss: 2.5774378005180942
Validation loss: 2.4826607372736587

Epoch: 6| Step: 7
Training loss: 2.5845305427138414
Validation loss: 2.4986275761533685

Epoch: 6| Step: 8
Training loss: 1.8327323694428328
Validation loss: 2.5259141455734526

Epoch: 6| Step: 9
Training loss: 2.542500489421486
Validation loss: 2.522715368798181

Epoch: 6| Step: 10
Training loss: 2.4511741121441486
Validation loss: 2.5006725529498954

Epoch: 6| Step: 11
Training loss: 2.762774016310012
Validation loss: 2.5134216352825036

Epoch: 6| Step: 12
Training loss: 2.9205387752383802
Validation loss: 2.522508656057944

Epoch: 6| Step: 13
Training loss: 1.9823725050618195
Validation loss: 2.5124284764795037

Epoch: 139| Step: 0
Training loss: 2.7467109778758827
Validation loss: 2.5226766209450946

Epoch: 6| Step: 1
Training loss: 2.6078091794513387
Validation loss: 2.505174595467479

Epoch: 6| Step: 2
Training loss: 2.547044245239378
Validation loss: 2.467468342328686

Epoch: 6| Step: 3
Training loss: 2.4027216420264956
Validation loss: 2.446447236072671

Epoch: 6| Step: 4
Training loss: 2.133240709181532
Validation loss: 2.436936041097738

Epoch: 6| Step: 5
Training loss: 2.6223815392284884
Validation loss: 2.4551527250014566

Epoch: 6| Step: 6
Training loss: 2.48247085631014
Validation loss: 2.45044057922426

Epoch: 6| Step: 7
Training loss: 2.1814388772680173
Validation loss: 2.4616775798398103

Epoch: 6| Step: 8
Training loss: 2.240740372202656
Validation loss: 2.437790854628081

Epoch: 6| Step: 9
Training loss: 2.4306807373750052
Validation loss: 2.4300558460367263

Epoch: 6| Step: 10
Training loss: 2.673673414905331
Validation loss: 2.446032187065101

Epoch: 6| Step: 11
Training loss: 2.4188365950349406
Validation loss: 2.435810096498568

Epoch: 6| Step: 12
Training loss: 2.5107239552284337
Validation loss: 2.4324483625775755

Epoch: 6| Step: 13
Training loss: 2.0613811810670115
Validation loss: 2.446802583685591

Epoch: 140| Step: 0
Training loss: 2.288867304164175
Validation loss: 2.4759121430996514

Epoch: 6| Step: 1
Training loss: 2.1251604356227394
Validation loss: 2.4560671150034836

Epoch: 6| Step: 2
Training loss: 2.7735195094059057
Validation loss: 2.458958295204119

Epoch: 6| Step: 3
Training loss: 2.6983760506459182
Validation loss: 2.4166422193123043

Epoch: 6| Step: 4
Training loss: 2.4769525551716347
Validation loss: 2.3951647984507423

Epoch: 6| Step: 5
Training loss: 2.3279955527141865
Validation loss: 2.3936530767962725

Epoch: 6| Step: 6
Training loss: 2.448187846861533
Validation loss: 2.3929251299033325

Epoch: 6| Step: 7
Training loss: 1.8152618412692325
Validation loss: 2.395628562904414

Epoch: 6| Step: 8
Training loss: 2.738985632227483
Validation loss: 2.4334070114323754

Epoch: 6| Step: 9
Training loss: 2.2311089393627106
Validation loss: 2.4802249849711626

Epoch: 6| Step: 10
Training loss: 2.034608031255856
Validation loss: 2.545029583182902

Epoch: 6| Step: 11
Training loss: 3.0774073659805596
Validation loss: 2.6057704300666775

Epoch: 6| Step: 12
Training loss: 2.7122474166065973
Validation loss: 2.6054194439978513

Epoch: 6| Step: 13
Training loss: 2.31487018674392
Validation loss: 2.569508402555987

Epoch: 141| Step: 0
Training loss: 2.2922836397964192
Validation loss: 2.5628791846675267

Epoch: 6| Step: 1
Training loss: 2.532739554219031
Validation loss: 2.485093098433234

Epoch: 6| Step: 2
Training loss: 2.602640564390263
Validation loss: 2.4281021969554972

Epoch: 6| Step: 3
Training loss: 2.5113156767972904
Validation loss: 2.4211040189256092

Epoch: 6| Step: 4
Training loss: 2.36745448857262
Validation loss: 2.419022226474301

Epoch: 6| Step: 5
Training loss: 2.274735227834327
Validation loss: 2.439045167312871

Epoch: 6| Step: 6
Training loss: 2.132036899490671
Validation loss: 2.4435438700254863

Epoch: 6| Step: 7
Training loss: 2.2360803458530625
Validation loss: 2.4385067060130097

Epoch: 6| Step: 8
Training loss: 2.335176886285165
Validation loss: 2.4160834306314674

Epoch: 6| Step: 9
Training loss: 1.813843919463694
Validation loss: 2.4293045160462343

Epoch: 6| Step: 10
Training loss: 2.3193293585433006
Validation loss: 2.4683571099554777

Epoch: 6| Step: 11
Training loss: 2.821823180473775
Validation loss: 2.476279259643665

Epoch: 6| Step: 12
Training loss: 2.7889627390739067
Validation loss: 2.455914917072913

Epoch: 6| Step: 13
Training loss: 2.758058358707114
Validation loss: 2.451852705102218

Epoch: 142| Step: 0
Training loss: 2.050359424623303
Validation loss: 2.415344142315977

Epoch: 6| Step: 1
Training loss: 2.3799286948670053
Validation loss: 2.3860754488059372

Epoch: 6| Step: 2
Training loss: 2.869558076761682
Validation loss: 2.3583935676180827

Epoch: 6| Step: 3
Training loss: 2.66457104793179
Validation loss: 2.3747845191978594

Epoch: 6| Step: 4
Training loss: 3.073055061629095
Validation loss: 2.406023677287274

Epoch: 6| Step: 5
Training loss: 2.3788248683996476
Validation loss: 2.42785872410219

Epoch: 6| Step: 6
Training loss: 2.4355950369887234
Validation loss: 2.474715392635808

Epoch: 6| Step: 7
Training loss: 2.470236029216452
Validation loss: 2.5318840586829974

Epoch: 6| Step: 8
Training loss: 2.327700172937394
Validation loss: 2.571550563993076

Epoch: 6| Step: 9
Training loss: 2.3668724328795987
Validation loss: 2.6347211174205407

Epoch: 6| Step: 10
Training loss: 1.6921602114857355
Validation loss: 2.6427313722576

Epoch: 6| Step: 11
Training loss: 2.4118892430233134
Validation loss: 2.653919859417211

Epoch: 6| Step: 12
Training loss: 2.4483376215444275
Validation loss: 2.5713299317439504

Epoch: 6| Step: 13
Training loss: 1.6572566302240672
Validation loss: 2.5202283849501215

Epoch: 143| Step: 0
Training loss: 2.4469573609971396
Validation loss: 2.56541323692735

Epoch: 6| Step: 1
Training loss: 2.1886687290128872
Validation loss: 2.564970415866619

Epoch: 6| Step: 2
Training loss: 2.2889306352670378
Validation loss: 2.628048231989645

Epoch: 6| Step: 3
Training loss: 3.0122386518263524
Validation loss: 2.589727168930885

Epoch: 6| Step: 4
Training loss: 2.164859005431351
Validation loss: 2.4707571162301774

Epoch: 6| Step: 5
Training loss: 2.262498263363672
Validation loss: 2.4648139805813996

Epoch: 6| Step: 6
Training loss: 2.0606423306163015
Validation loss: 2.4798276145494103

Epoch: 6| Step: 7
Training loss: 3.1459248173697616
Validation loss: 2.4816679551914396

Epoch: 6| Step: 8
Training loss: 2.3504042703803982
Validation loss: 2.4840148806149114

Epoch: 6| Step: 9
Training loss: 2.536334265168767
Validation loss: 2.493254536096541

Epoch: 6| Step: 10
Training loss: 2.6816539611262526
Validation loss: 2.4885840232794187

Epoch: 6| Step: 11
Training loss: 2.180681883708807
Validation loss: 2.452372726991959

Epoch: 6| Step: 12
Training loss: 2.1172018015473495
Validation loss: 2.4336076669323536

Epoch: 6| Step: 13
Training loss: 1.8089443715548255
Validation loss: 2.4215802857884254

Epoch: 144| Step: 0
Training loss: 1.9031494439720988
Validation loss: 2.4038619075855276

Epoch: 6| Step: 1
Training loss: 1.8774415967368239
Validation loss: 2.406211639639755

Epoch: 6| Step: 2
Training loss: 2.191192562136051
Validation loss: 2.414596742753109

Epoch: 6| Step: 3
Training loss: 1.7866685334001344
Validation loss: 2.4428566277353734

Epoch: 6| Step: 4
Training loss: 2.8288640695212144
Validation loss: 2.4556554176163123

Epoch: 6| Step: 5
Training loss: 2.9503590381476443
Validation loss: 2.4237300716164887

Epoch: 6| Step: 6
Training loss: 2.15352480516392
Validation loss: 2.4239850154894675

Epoch: 6| Step: 7
Training loss: 2.46192994466317
Validation loss: 2.4192639606252415

Epoch: 6| Step: 8
Training loss: 2.494739911545355
Validation loss: 2.421142156038607

Epoch: 6| Step: 9
Training loss: 2.4995587913282122
Validation loss: 2.4411755382840745

Epoch: 6| Step: 10
Training loss: 1.601589295698097
Validation loss: 2.4289480893208437

Epoch: 6| Step: 11
Training loss: 2.3261175525641793
Validation loss: 2.4455991706238804

Epoch: 6| Step: 12
Training loss: 2.517060054155074
Validation loss: 2.4529364018089734

Epoch: 6| Step: 13
Training loss: 2.9256187567005556
Validation loss: 2.463561105424904

Epoch: 145| Step: 0
Training loss: 2.1788157699033865
Validation loss: 2.4535495967208987

Epoch: 6| Step: 1
Training loss: 2.904803172286646
Validation loss: 2.4280312067550893

Epoch: 6| Step: 2
Training loss: 2.1158521882406887
Validation loss: 2.404977271963308

Epoch: 6| Step: 3
Training loss: 1.8827136001887523
Validation loss: 2.417694547528474

Epoch: 6| Step: 4
Training loss: 2.3451993402861753
Validation loss: 2.4057284821990517

Epoch: 6| Step: 5
Training loss: 2.3359733247083065
Validation loss: 2.404629774864732

Epoch: 6| Step: 6
Training loss: 2.548027854192286
Validation loss: 2.412405642619966

Epoch: 6| Step: 7
Training loss: 2.4638993136034766
Validation loss: 2.438474252729535

Epoch: 6| Step: 8
Training loss: 2.357226776924601
Validation loss: 2.4452997111838184

Epoch: 6| Step: 9
Training loss: 1.545202719218888
Validation loss: 2.5122729228683034

Epoch: 6| Step: 10
Training loss: 2.2995998283228243
Validation loss: 2.540754983499583

Epoch: 6| Step: 11
Training loss: 2.03084348865715
Validation loss: 2.568295289157956

Epoch: 6| Step: 12
Training loss: 2.834734028175844
Validation loss: 2.5713131245996323

Epoch: 6| Step: 13
Training loss: 1.9956916657927273
Validation loss: 2.572905091855057

Epoch: 146| Step: 0
Training loss: 1.8489628178358541
Validation loss: 2.5622779295764397

Epoch: 6| Step: 1
Training loss: 2.149538514045342
Validation loss: 2.570453010471444

Epoch: 6| Step: 2
Training loss: 2.433702298065717
Validation loss: 2.5232988987010905

Epoch: 6| Step: 3
Training loss: 2.861744883524971
Validation loss: 2.491660676376161

Epoch: 6| Step: 4
Training loss: 1.8602153898448428
Validation loss: 2.4831852611980816

Epoch: 6| Step: 5
Training loss: 2.3390116286622717
Validation loss: 2.4656272381293918

Epoch: 6| Step: 6
Training loss: 2.377890183514267
Validation loss: 2.4434790029292963

Epoch: 6| Step: 7
Training loss: 1.4591061951056137
Validation loss: 2.418555906317098

Epoch: 6| Step: 8
Training loss: 2.540166526802272
Validation loss: 2.4240051957393587

Epoch: 6| Step: 9
Training loss: 2.375121565267467
Validation loss: 2.4131892018145527

Epoch: 6| Step: 10
Training loss: 2.488354740225337
Validation loss: 2.424960068573842

Epoch: 6| Step: 11
Training loss: 1.9561411647563853
Validation loss: 2.449583520705307

Epoch: 6| Step: 12
Training loss: 2.31517451508052
Validation loss: 2.468943974434411

Epoch: 6| Step: 13
Training loss: 2.165646520730631
Validation loss: 2.516878450539622

Epoch: 147| Step: 0
Training loss: 2.306535400264505
Validation loss: 2.4903041499587206

Epoch: 6| Step: 1
Training loss: 2.169173722003489
Validation loss: 2.4745540718095214

Epoch: 6| Step: 2
Training loss: 2.5671258437216635
Validation loss: 2.448099931093786

Epoch: 6| Step: 3
Training loss: 1.961953010381354
Validation loss: 2.4434967307995286

Epoch: 6| Step: 4
Training loss: 1.5390604861483492
Validation loss: 2.4474911265992887

Epoch: 6| Step: 5
Training loss: 2.5093734494177182
Validation loss: 2.482763130614417

Epoch: 6| Step: 6
Training loss: 2.9805601013502865
Validation loss: 2.519995382742258

Epoch: 6| Step: 7
Training loss: 2.2791780442460055
Validation loss: 2.5181018903099552

Epoch: 6| Step: 8
Training loss: 2.324043126242867
Validation loss: 2.486839327525923

Epoch: 6| Step: 9
Training loss: 1.5884837489174861
Validation loss: 2.4420090333442754

Epoch: 6| Step: 10
Training loss: 1.8389714272764968
Validation loss: 2.411929813201538

Epoch: 6| Step: 11
Training loss: 2.1650520568650413
Validation loss: 2.4175625983687032

Epoch: 6| Step: 12
Training loss: 2.58562456064126
Validation loss: 2.461239988270135

Epoch: 6| Step: 13
Training loss: 1.7029080033958925
Validation loss: 2.5742907578692704

Epoch: 148| Step: 0
Training loss: 3.3119565409974157
Validation loss: 2.683486603176224

Epoch: 6| Step: 1
Training loss: 1.5352391033770485
Validation loss: 2.6164281079793814

Epoch: 6| Step: 2
Training loss: 2.626278883617681
Validation loss: 2.5577178981483466

Epoch: 6| Step: 3
Training loss: 2.288945530321241
Validation loss: 2.4691641478219912

Epoch: 6| Step: 4
Training loss: 1.9596657447538086
Validation loss: 2.394430005450243

Epoch: 6| Step: 5
Training loss: 2.3090369610775117
Validation loss: 2.3692394595401542

Epoch: 6| Step: 6
Training loss: 2.3666961462128033
Validation loss: 2.4273495789305852

Epoch: 6| Step: 7
Training loss: 2.2218607197878057
Validation loss: 2.4750989659852816

Epoch: 6| Step: 8
Training loss: 2.486882126331305
Validation loss: 2.549274784854416

Epoch: 6| Step: 9
Training loss: 2.377165158797282
Validation loss: 2.53924202283565

Epoch: 6| Step: 10
Training loss: 2.280374228232852
Validation loss: 2.4752546377688986

Epoch: 6| Step: 11
Training loss: 1.9654395714948851
Validation loss: 2.4362879353960665

Epoch: 6| Step: 12
Training loss: 1.9579695776347903
Validation loss: 2.4166943658493802

Epoch: 6| Step: 13
Training loss: 2.91753321899226
Validation loss: 2.4328350287520335

Epoch: 149| Step: 0
Training loss: 2.0375170935165356
Validation loss: 2.4627937739651675

Epoch: 6| Step: 1
Training loss: 2.411881631455074
Validation loss: 2.51019749029082

Epoch: 6| Step: 2
Training loss: 1.9146497176003703
Validation loss: 2.557127206431844

Epoch: 6| Step: 3
Training loss: 2.6487812730600138
Validation loss: 2.6034606997220306

Epoch: 6| Step: 4
Training loss: 2.4134572081975643
Validation loss: 2.6376851305995337

Epoch: 6| Step: 5
Training loss: 2.524218553538951
Validation loss: 2.609969618279479

Epoch: 6| Step: 6
Training loss: 2.2361406939058854
Validation loss: 2.5948561044408986

Epoch: 6| Step: 7
Training loss: 1.9794917057226844
Validation loss: 2.5871135576665445

Epoch: 6| Step: 8
Training loss: 2.2866833922920926
Validation loss: 2.587058225693893

Epoch: 6| Step: 9
Training loss: 1.6533691975846558
Validation loss: 2.5577084402805417

Epoch: 6| Step: 10
Training loss: 1.9542300950786498
Validation loss: 2.565274703971462

Epoch: 6| Step: 11
Training loss: 2.584564858857977
Validation loss: 2.5624488787450206

Epoch: 6| Step: 12
Training loss: 1.7924387694984516
Validation loss: 2.5003442670806457

Epoch: 6| Step: 13
Training loss: 2.053983502478681
Validation loss: 2.458543498561266

Epoch: 150| Step: 0
Training loss: 2.2817907868149745
Validation loss: 2.4299513319428594

Epoch: 6| Step: 1
Training loss: 2.2863611940735926
Validation loss: 2.4137613568174983

Epoch: 6| Step: 2
Training loss: 1.5918397113676401
Validation loss: 2.4215995301118842

Epoch: 6| Step: 3
Training loss: 2.3103875486593153
Validation loss: 2.4081190851563776

Epoch: 6| Step: 4
Training loss: 2.206146549036395
Validation loss: 2.438556940518591

Epoch: 6| Step: 5
Training loss: 2.0444995403928328
Validation loss: 2.4353968421323344

Epoch: 6| Step: 6
Training loss: 2.3980648981496113
Validation loss: 2.4539057315689625

Epoch: 6| Step: 7
Training loss: 1.7800154841746088
Validation loss: 2.471607665987966

Epoch: 6| Step: 8
Training loss: 2.1135751234339133
Validation loss: 2.477761576110726

Epoch: 6| Step: 9
Training loss: 1.7405717139588692
Validation loss: 2.5062419655654997

Epoch: 6| Step: 10
Training loss: 2.3662345151399613
Validation loss: 2.5177353572673464

Epoch: 6| Step: 11
Training loss: 2.4532179116312194
Validation loss: 2.509812871450688

Epoch: 6| Step: 12
Training loss: 2.016424567558036
Validation loss: 2.5131059988694

Epoch: 6| Step: 13
Training loss: 2.1571857799096
Validation loss: 2.5191725471501245

Epoch: 151| Step: 0
Training loss: 1.7541028700559165
Validation loss: 2.5166076308379846

Epoch: 6| Step: 1
Training loss: 2.1974086324990063
Validation loss: 2.5091375674118175

Epoch: 6| Step: 2
Training loss: 2.024728017367153
Validation loss: 2.4851396585691874

Epoch: 6| Step: 3
Training loss: 1.9631313499000644
Validation loss: 2.4946020969180465

Epoch: 6| Step: 4
Training loss: 2.0172279548872902
Validation loss: 2.4874759318172166

Epoch: 6| Step: 5
Training loss: 2.437652583114911
Validation loss: 2.51727225499847

Epoch: 6| Step: 6
Training loss: 2.4417886419284094
Validation loss: 2.5758945097746335

Epoch: 6| Step: 7
Training loss: 2.1536772486199376
Validation loss: 2.5765076795726762

Epoch: 6| Step: 8
Training loss: 1.779488411904505
Validation loss: 2.543318566877383

Epoch: 6| Step: 9
Training loss: 1.9370851380204477
Validation loss: 2.477692733020796

Epoch: 6| Step: 10
Training loss: 2.2464096245279657
Validation loss: 2.426775730129882

Epoch: 6| Step: 11
Training loss: 1.9670162135446505
Validation loss: 2.38967395524128

Epoch: 6| Step: 12
Training loss: 2.021182420080914
Validation loss: 2.379742846102782

Epoch: 6| Step: 13
Training loss: 2.386845911512504
Validation loss: 2.3735133560764257

Epoch: 152| Step: 0
Training loss: 1.6428726784937076
Validation loss: 2.4088279105864365

Epoch: 6| Step: 1
Training loss: 2.167899465742564
Validation loss: 2.457522910636419

Epoch: 6| Step: 2
Training loss: 2.317656464299925
Validation loss: 2.4740513965522637

Epoch: 6| Step: 3
Training loss: 2.271314540821497
Validation loss: 2.4746213519115736

Epoch: 6| Step: 4
Training loss: 1.9554176607365834
Validation loss: 2.4834626092797074

Epoch: 6| Step: 5
Training loss: 2.46433839287538
Validation loss: 2.489208254107624

Epoch: 6| Step: 6
Training loss: 2.5827982768863142
Validation loss: 2.492291102488636

Epoch: 6| Step: 7
Training loss: 2.390663296261887
Validation loss: 2.5278286758804316

Epoch: 6| Step: 8
Training loss: 1.5273185396187046
Validation loss: 2.5131267712516783

Epoch: 6| Step: 9
Training loss: 1.717449181483692
Validation loss: 2.4889865959328406

Epoch: 6| Step: 10
Training loss: 2.077716758611749
Validation loss: 2.476847606233571

Epoch: 6| Step: 11
Training loss: 1.6494503435082437
Validation loss: 2.494868000890579

Epoch: 6| Step: 12
Training loss: 2.167409793864228
Validation loss: 2.4796965544559137

Epoch: 6| Step: 13
Training loss: 1.5861934211085642
Validation loss: 2.46446951241847

Epoch: 153| Step: 0
Training loss: 2.1647683655338312
Validation loss: 2.4662122329733993

Epoch: 6| Step: 1
Training loss: 2.202156232663587
Validation loss: 2.473664341261257

Epoch: 6| Step: 2
Training loss: 2.270384531263329
Validation loss: 2.5086515322174683

Epoch: 6| Step: 3
Training loss: 1.915518693323413
Validation loss: 2.528013220677808

Epoch: 6| Step: 4
Training loss: 1.7940719634542228
Validation loss: 2.548704886978453

Epoch: 6| Step: 5
Training loss: 1.3607299891746822
Validation loss: 2.5674235237500476

Epoch: 6| Step: 6
Training loss: 2.3569468957601893
Validation loss: 2.5481213921396115

Epoch: 6| Step: 7
Training loss: 1.6712184579479101
Validation loss: 2.537016711343955

Epoch: 6| Step: 8
Training loss: 2.3265519940591894
Validation loss: 2.567837873853443

Epoch: 6| Step: 9
Training loss: 2.313846917577608
Validation loss: 2.5246061276167464

Epoch: 6| Step: 10
Training loss: 2.4645722204899956
Validation loss: 2.4682813619913233

Epoch: 6| Step: 11
Training loss: 1.7475328083805972
Validation loss: 2.3942435466350354

Epoch: 6| Step: 12
Training loss: 2.0101418842702277
Validation loss: 2.360024285519137

Epoch: 6| Step: 13
Training loss: 2.0732417275081922
Validation loss: 2.341986503416537

Epoch: 154| Step: 0
Training loss: 1.7009320621098687
Validation loss: 2.3686276077303834

Epoch: 6| Step: 1
Training loss: 2.096579049568627
Validation loss: 2.3736667971335454

Epoch: 6| Step: 2
Training loss: 2.2517646651139334
Validation loss: 2.4306722607308298

Epoch: 6| Step: 3
Training loss: 1.286852334829402
Validation loss: 2.46946971865043

Epoch: 6| Step: 4
Training loss: 2.430440019556061
Validation loss: 2.4966240392324854

Epoch: 6| Step: 5
Training loss: 1.529121632480211
Validation loss: 2.498059302953686

Epoch: 6| Step: 6
Training loss: 2.1154200084099615
Validation loss: 2.510931407912066

Epoch: 6| Step: 7
Training loss: 1.7151609922421516
Validation loss: 2.517251566727756

Epoch: 6| Step: 8
Training loss: 1.6483512964353082
Validation loss: 2.5273694913250964

Epoch: 6| Step: 9
Training loss: 2.190679909185287
Validation loss: 2.5390531816461426

Epoch: 6| Step: 10
Training loss: 2.5132516600124184
Validation loss: 2.5164522810565177

Epoch: 6| Step: 11
Training loss: 1.9073166286377445
Validation loss: 2.4695548213383454

Epoch: 6| Step: 12
Training loss: 2.109834635071529
Validation loss: 2.470720177119451

Epoch: 6| Step: 13
Training loss: 2.4563530742576565
Validation loss: 2.4450189531614503

Epoch: 155| Step: 0
Training loss: 1.6261882838883577
Validation loss: 2.423620563899259

Epoch: 6| Step: 1
Training loss: 1.9054568782622692
Validation loss: 2.4203744199135193

Epoch: 6| Step: 2
Training loss: 2.517820928094798
Validation loss: 2.4485556409765157

Epoch: 6| Step: 3
Training loss: 1.878130715055228
Validation loss: 2.462934685688082

Epoch: 6| Step: 4
Training loss: 2.297065259877478
Validation loss: 2.4740092835201875

Epoch: 6| Step: 5
Training loss: 1.958940925762863
Validation loss: 2.4866967399348137

Epoch: 6| Step: 6
Training loss: 1.744308480689601
Validation loss: 2.4905388429331117

Epoch: 6| Step: 7
Training loss: 1.6181306162147702
Validation loss: 2.4973221147080475

Epoch: 6| Step: 8
Training loss: 2.198136763076177
Validation loss: 2.4970017984736232

Epoch: 6| Step: 9
Training loss: 1.9287765762169382
Validation loss: 2.502712423139833

Epoch: 6| Step: 10
Training loss: 1.9872778738401469
Validation loss: 2.511730171802422

Epoch: 6| Step: 11
Training loss: 1.9231338719958941
Validation loss: 2.5200604964578392

Epoch: 6| Step: 12
Training loss: 1.9369602066702665
Validation loss: 2.535103977673871

Epoch: 6| Step: 13
Training loss: 2.394171284787214
Validation loss: 2.5081973484176436

Epoch: 156| Step: 0
Training loss: 1.7327947892572986
Validation loss: 2.491350082954728

Epoch: 6| Step: 1
Training loss: 2.1582305216021296
Validation loss: 2.4808400956267342

Epoch: 6| Step: 2
Training loss: 1.883494210194073
Validation loss: 2.493351348298376

Epoch: 6| Step: 3
Training loss: 2.0839824301112646
Validation loss: 2.438356466253905

Epoch: 6| Step: 4
Training loss: 1.8003468682601353
Validation loss: 2.432148488206391

Epoch: 6| Step: 5
Training loss: 1.8116991312626989
Validation loss: 2.4020923396577074

Epoch: 6| Step: 6
Training loss: 2.0223755866828594
Validation loss: 2.3885893986534112

Epoch: 6| Step: 7
Training loss: 2.0918954635453493
Validation loss: 2.3961706238847076

Epoch: 6| Step: 8
Training loss: 1.9250021203760137
Validation loss: 2.393463791339957

Epoch: 6| Step: 9
Training loss: 2.6086731840631168
Validation loss: 2.4255793382764996

Epoch: 6| Step: 10
Training loss: 1.7371166657144057
Validation loss: 2.445985119376478

Epoch: 6| Step: 11
Training loss: 1.9413520298837394
Validation loss: 2.4733202713228772

Epoch: 6| Step: 12
Training loss: 1.793776851546117
Validation loss: 2.5071220839124124

Epoch: 6| Step: 13
Training loss: 1.7896019401367544
Validation loss: 2.4753137759801316

Epoch: 157| Step: 0
Training loss: 1.2794011896133557
Validation loss: 2.4895054856558723

Epoch: 6| Step: 1
Training loss: 1.9391026790123331
Validation loss: 2.502030788601228

Epoch: 6| Step: 2
Training loss: 1.9297314843481645
Validation loss: 2.5267056258044365

Epoch: 6| Step: 3
Training loss: 2.7222740747958616
Validation loss: 2.577077891734442

Epoch: 6| Step: 4
Training loss: 1.7106706245646153
Validation loss: 2.541229113217803

Epoch: 6| Step: 5
Training loss: 1.8737760363621876
Validation loss: 2.539889245869784

Epoch: 6| Step: 6
Training loss: 2.111922132017495
Validation loss: 2.5371146273514995

Epoch: 6| Step: 7
Training loss: 1.8360769016017768
Validation loss: 2.5387560597814436

Epoch: 6| Step: 8
Training loss: 1.938856203969028
Validation loss: 2.482595132108028

Epoch: 6| Step: 9
Training loss: 1.5312225962152453
Validation loss: 2.4474371243805892

Epoch: 6| Step: 10
Training loss: 1.9262432913691239
Validation loss: 2.4438298118609976

Epoch: 6| Step: 11
Training loss: 1.3390217920656744
Validation loss: 2.4316239324587237

Epoch: 6| Step: 12
Training loss: 2.4324025381387733
Validation loss: 2.429018637943599

Epoch: 6| Step: 13
Training loss: 2.305798175664599
Validation loss: 2.446773996671594

Epoch: 158| Step: 0
Training loss: 2.0716731368700643
Validation loss: 2.4695951729272863

Epoch: 6| Step: 1
Training loss: 1.8569292925559902
Validation loss: 2.495717911854974

Epoch: 6| Step: 2
Training loss: 1.8764836481379543
Validation loss: 2.512218910043385

Epoch: 6| Step: 3
Training loss: 2.225966631479009
Validation loss: 2.5238078307972645

Epoch: 6| Step: 4
Training loss: 1.9990779420161724
Validation loss: 2.5343103659047337

Epoch: 6| Step: 5
Training loss: 2.020477486443211
Validation loss: 2.5223836366529317

Epoch: 6| Step: 6
Training loss: 2.040024687486752
Validation loss: 2.5089136624076906

Epoch: 6| Step: 7
Training loss: 1.835798867043955
Validation loss: 2.5179827003305983

Epoch: 6| Step: 8
Training loss: 1.6362046775048782
Validation loss: 2.5282037478918324

Epoch: 6| Step: 9
Training loss: 1.7924714905241983
Validation loss: 2.5272927402797616

Epoch: 6| Step: 10
Training loss: 1.5110364059061432
Validation loss: 2.4840352796194893

Epoch: 6| Step: 11
Training loss: 1.830339183121138
Validation loss: 2.4682412330067245

Epoch: 6| Step: 12
Training loss: 1.9177775549909968
Validation loss: 2.4636458643467445

Epoch: 6| Step: 13
Training loss: 1.5480520990953992
Validation loss: 2.436277825133656

Epoch: 159| Step: 0
Training loss: 1.9576531980936633
Validation loss: 2.4414784242523924

Epoch: 6| Step: 1
Training loss: 1.800440691936467
Validation loss: 2.4246390488598943

Epoch: 6| Step: 2
Training loss: 2.1441727913646593
Validation loss: 2.418213716870318

Epoch: 6| Step: 3
Training loss: 1.705807594262911
Validation loss: 2.437234220904957

Epoch: 6| Step: 4
Training loss: 2.0658943681624367
Validation loss: 2.465891276268139

Epoch: 6| Step: 5
Training loss: 1.5970965386665894
Validation loss: 2.498835166160974

Epoch: 6| Step: 6
Training loss: 1.9673073947962776
Validation loss: 2.5184267050174283

Epoch: 6| Step: 7
Training loss: 1.710461136506618
Validation loss: 2.5857056212427163

Epoch: 6| Step: 8
Training loss: 1.9574127739074492
Validation loss: 2.5492963496059273

Epoch: 6| Step: 9
Training loss: 1.5307241042776938
Validation loss: 2.517550766283097

Epoch: 6| Step: 10
Training loss: 1.7501648416539015
Validation loss: 2.479121304892661

Epoch: 6| Step: 11
Training loss: 1.9369904863382885
Validation loss: 2.4790263589098998

Epoch: 6| Step: 12
Training loss: 1.9766138846612518
Validation loss: 2.4856926128931747

Epoch: 6| Step: 13
Training loss: 1.6531472563372127
Validation loss: 2.4851404776500474

Epoch: 160| Step: 0
Training loss: 1.8320413357389955
Validation loss: 2.4796019747859894

Epoch: 6| Step: 1
Training loss: 1.700913839993891
Validation loss: 2.478244186589275

Epoch: 6| Step: 2
Training loss: 2.273343638157166
Validation loss: 2.5010485777863836

Epoch: 6| Step: 3
Training loss: 1.545457749439937
Validation loss: 2.478472928932821

Epoch: 6| Step: 4
Training loss: 1.7053702017969594
Validation loss: 2.4622088800597726

Epoch: 6| Step: 5
Training loss: 1.8820088044344723
Validation loss: 2.4260689805181435

Epoch: 6| Step: 6
Training loss: 1.873045856686376
Validation loss: 2.4322518623012717

Epoch: 6| Step: 7
Training loss: 1.6692564949296642
Validation loss: 2.4295690870543636

Epoch: 6| Step: 8
Training loss: 2.1126468855675204
Validation loss: 2.473040288892102

Epoch: 6| Step: 9
Training loss: 2.12696141993619
Validation loss: 2.5111349053034027

Epoch: 6| Step: 10
Training loss: 2.0584205974454175
Validation loss: 2.5254332404768984

Epoch: 6| Step: 11
Training loss: 1.4061011341561096
Validation loss: 2.556548866812525

Epoch: 6| Step: 12
Training loss: 1.5715372803477967
Validation loss: 2.5358750264995487

Epoch: 6| Step: 13
Training loss: 1.3090190139508622
Validation loss: 2.5449572752350758

Epoch: 161| Step: 0
Training loss: 1.6428209413366355
Validation loss: 2.571257957111856

Epoch: 6| Step: 1
Training loss: 2.0744752886907745
Validation loss: 2.5508333106107504

Epoch: 6| Step: 2
Training loss: 1.7063811087627188
Validation loss: 2.522769483093036

Epoch: 6| Step: 3
Training loss: 1.5463060816321752
Validation loss: 2.5014258610079785

Epoch: 6| Step: 4
Training loss: 1.736178242551103
Validation loss: 2.457804896471973

Epoch: 6| Step: 5
Training loss: 2.343081976739021
Validation loss: 2.4435095222325693

Epoch: 6| Step: 6
Training loss: 2.4895409190716133
Validation loss: 2.44538011810918

Epoch: 6| Step: 7
Training loss: 1.8157385470525325
Validation loss: 2.4366634522578687

Epoch: 6| Step: 8
Training loss: 1.1919801424215792
Validation loss: 2.4564832904579714

Epoch: 6| Step: 9
Training loss: 1.8136863772001235
Validation loss: 2.503135543214595

Epoch: 6| Step: 10
Training loss: 1.0088822357784135
Validation loss: 2.516468481197673

Epoch: 6| Step: 11
Training loss: 1.8959608838557198
Validation loss: 2.5275087061982675

Epoch: 6| Step: 12
Training loss: 1.299047511796377
Validation loss: 2.521792931809789

Epoch: 6| Step: 13
Training loss: 1.9897931838752885
Validation loss: 2.4895676742667425

Epoch: 162| Step: 0
Training loss: 1.6780611903385727
Validation loss: 2.4584712575017704

Epoch: 6| Step: 1
Training loss: 1.9505888074397506
Validation loss: 2.4293977994484846

Epoch: 6| Step: 2
Training loss: 2.0808492601197868
Validation loss: 2.44050670644504

Epoch: 6| Step: 3
Training loss: 1.5204304287720507
Validation loss: 2.4250125880877227

Epoch: 6| Step: 4
Training loss: 1.7248808667605429
Validation loss: 2.4124371968835647

Epoch: 6| Step: 5
Training loss: 2.1858688812719946
Validation loss: 2.4252107034579313

Epoch: 6| Step: 6
Training loss: 1.595980709963221
Validation loss: 2.4435400894155737

Epoch: 6| Step: 7
Training loss: 1.351996820598453
Validation loss: 2.481601212208703

Epoch: 6| Step: 8
Training loss: 1.651117830495281
Validation loss: 2.5264238131701946

Epoch: 6| Step: 9
Training loss: 1.5857174725420728
Validation loss: 2.5357465760944877

Epoch: 6| Step: 10
Training loss: 1.9703991960877774
Validation loss: 2.55586293556469

Epoch: 6| Step: 11
Training loss: 1.6397959476389703
Validation loss: 2.5572870605887075

Epoch: 6| Step: 12
Training loss: 1.7215297068908697
Validation loss: 2.5091834719321575

Epoch: 6| Step: 13
Training loss: 1.6676686215681205
Validation loss: 2.487429764798475

Epoch: 163| Step: 0
Training loss: 2.0376921393480276
Validation loss: 2.461860708844441

Epoch: 6| Step: 1
Training loss: 1.9530231296675622
Validation loss: 2.412552900465973

Epoch: 6| Step: 2
Training loss: 1.8738579132785107
Validation loss: 2.410826573423785

Epoch: 6| Step: 3
Training loss: 1.8522299034499943
Validation loss: 2.404272883702299

Epoch: 6| Step: 4
Training loss: 1.2015423459271384
Validation loss: 2.402781645740332

Epoch: 6| Step: 5
Training loss: 1.4548093816421663
Validation loss: 2.432833846425465

Epoch: 6| Step: 6
Training loss: 1.2594304548222393
Validation loss: 2.4527085860483866

Epoch: 6| Step: 7
Training loss: 1.9568784734060967
Validation loss: 2.481574596332143

Epoch: 6| Step: 8
Training loss: 1.6234064358042157
Validation loss: 2.494414312015307

Epoch: 6| Step: 9
Training loss: 1.60208709312894
Validation loss: 2.528387998139143

Epoch: 6| Step: 10
Training loss: 1.8985531618653597
Validation loss: 2.5395359251077076

Epoch: 6| Step: 11
Training loss: 1.857175921051476
Validation loss: 2.558553877194726

Epoch: 6| Step: 12
Training loss: 1.9997497640467248
Validation loss: 2.5636387897496715

Epoch: 6| Step: 13
Training loss: 1.5435275454224273
Validation loss: 2.541588477618667

Epoch: 164| Step: 0
Training loss: 1.3670353396074726
Validation loss: 2.5186055352390606

Epoch: 6| Step: 1
Training loss: 1.6410731112357237
Validation loss: 2.4846072226122344

Epoch: 6| Step: 2
Training loss: 1.898903118536822
Validation loss: 2.423159507621646

Epoch: 6| Step: 3
Training loss: 1.3030060309023874
Validation loss: 2.4079751887376157

Epoch: 6| Step: 4
Training loss: 1.7527646977977243
Validation loss: 2.397540435465428

Epoch: 6| Step: 5
Training loss: 1.64672994535821
Validation loss: 2.4134094914039776

Epoch: 6| Step: 6
Training loss: 1.862444931854707
Validation loss: 2.443024096427416

Epoch: 6| Step: 7
Training loss: 1.9701871319302662
Validation loss: 2.5061876396592093

Epoch: 6| Step: 8
Training loss: 1.5528689536067768
Validation loss: 2.5233717907015216

Epoch: 6| Step: 9
Training loss: 2.0108175981487983
Validation loss: 2.5884160718450966

Epoch: 6| Step: 10
Training loss: 1.4542440392022997
Validation loss: 2.6151801634443452

Epoch: 6| Step: 11
Training loss: 2.0299430750866
Validation loss: 2.596701821155812

Epoch: 6| Step: 12
Training loss: 1.9308502771223808
Validation loss: 2.519038581932181

Epoch: 6| Step: 13
Training loss: 1.251915322624243
Validation loss: 2.4636878423547435

Epoch: 165| Step: 0
Training loss: 1.7221654768109984
Validation loss: 2.429856256146001

Epoch: 6| Step: 1
Training loss: 1.731926504227631
Validation loss: 2.4158321915841983

Epoch: 6| Step: 2
Training loss: 1.9438218376401724
Validation loss: 2.443428445215882

Epoch: 6| Step: 3
Training loss: 1.618240382271575
Validation loss: 2.4826580979001633

Epoch: 6| Step: 4
Training loss: 1.7653102087761314
Validation loss: 2.520002038038139

Epoch: 6| Step: 5
Training loss: 1.7599334128744972
Validation loss: 2.527547291732076

Epoch: 6| Step: 6
Training loss: 1.7159409195659732
Validation loss: 2.533450829976804

Epoch: 6| Step: 7
Training loss: 1.3113225469166623
Validation loss: 2.494113514905019

Epoch: 6| Step: 8
Training loss: 2.062308793886195
Validation loss: 2.4782756080654433

Epoch: 6| Step: 9
Training loss: 1.5957981487542159
Validation loss: 2.4352638582871764

Epoch: 6| Step: 10
Training loss: 1.4317745130521027
Validation loss: 2.4158637997814463

Epoch: 6| Step: 11
Training loss: 1.8230493624392112
Validation loss: 2.4253731309762583

Epoch: 6| Step: 12
Training loss: 1.646885362625093
Validation loss: 2.417406890284491

Epoch: 6| Step: 13
Training loss: 1.4046596435228875
Validation loss: 2.4197018466786417

Epoch: 166| Step: 0
Training loss: 0.9446763980174007
Validation loss: 2.452064495505867

Epoch: 6| Step: 1
Training loss: 2.0858302856780693
Validation loss: 2.4732525919997257

Epoch: 6| Step: 2
Training loss: 1.2551705234684285
Validation loss: 2.480626467973807

Epoch: 6| Step: 3
Training loss: 1.5780539166144056
Validation loss: 2.5271391155495464

Epoch: 6| Step: 4
Training loss: 1.9052582959659101
Validation loss: 2.5365783928473618

Epoch: 6| Step: 5
Training loss: 1.9491136174718207
Validation loss: 2.55224418576894

Epoch: 6| Step: 6
Training loss: 1.8768657302754563
Validation loss: 2.532298137559862

Epoch: 6| Step: 7
Training loss: 1.634393246258913
Validation loss: 2.450473148129188

Epoch: 6| Step: 8
Training loss: 1.8789870151600991
Validation loss: 2.4439282137493694

Epoch: 6| Step: 9
Training loss: 1.5503250335020633
Validation loss: 2.417798021111719

Epoch: 6| Step: 10
Training loss: 1.9243922302128886
Validation loss: 2.386881676716087

Epoch: 6| Step: 11
Training loss: 1.4054187012985766
Validation loss: 2.3971879023409293

Epoch: 6| Step: 12
Training loss: 1.672127392693218
Validation loss: 2.412079201321467

Epoch: 6| Step: 13
Training loss: 1.4878209320835774
Validation loss: 2.4365360971951695

Epoch: 167| Step: 0
Training loss: 1.6573930790449762
Validation loss: 2.4345171630610363

Epoch: 6| Step: 1
Training loss: 1.3163722908326123
Validation loss: 2.4752665722015736

Epoch: 6| Step: 2
Training loss: 1.988882037754205
Validation loss: 2.498760919220653

Epoch: 6| Step: 3
Training loss: 1.521483748194672
Validation loss: 2.510381524162511

Epoch: 6| Step: 4
Training loss: 1.820956333233874
Validation loss: 2.493593992578409

Epoch: 6| Step: 5
Training loss: 1.7244987754740009
Validation loss: 2.5302440640196626

Epoch: 6| Step: 6
Training loss: 1.742749589643374
Validation loss: 2.552771327939165

Epoch: 6| Step: 7
Training loss: 1.8788997150394735
Validation loss: 2.5572016705409863

Epoch: 6| Step: 8
Training loss: 1.2833735383329077
Validation loss: 2.4960465653429207

Epoch: 6| Step: 9
Training loss: 1.952811620366873
Validation loss: 2.4550105797718635

Epoch: 6| Step: 10
Training loss: 1.526061395337513
Validation loss: 2.4212961326132554

Epoch: 6| Step: 11
Training loss: 1.5007500362774338
Validation loss: 2.395455856511948

Epoch: 6| Step: 12
Training loss: 1.5782827921626539
Validation loss: 2.37784500357037

Epoch: 6| Step: 13
Training loss: 1.3525833067560342
Validation loss: 2.3620423330228153

Epoch: 168| Step: 0
Training loss: 1.5800832552643846
Validation loss: 2.3364936006720396

Epoch: 6| Step: 1
Training loss: 0.9160156900694606
Validation loss: 2.3472272000283585

Epoch: 6| Step: 2
Training loss: 1.910755149394155
Validation loss: 2.362394658835142

Epoch: 6| Step: 3
Training loss: 1.7303772637357195
Validation loss: 2.3844323784549277

Epoch: 6| Step: 4
Training loss: 1.3823437947053019
Validation loss: 2.403225407762447

Epoch: 6| Step: 5
Training loss: 2.06879504751157
Validation loss: 2.432633486461236

Epoch: 6| Step: 6
Training loss: 1.3721350386479017
Validation loss: 2.476550745720228

Epoch: 6| Step: 7
Training loss: 2.016436509589278
Validation loss: 2.529667675606931

Epoch: 6| Step: 8
Training loss: 1.3391649845748115
Validation loss: 2.4807209308187494

Epoch: 6| Step: 9
Training loss: 1.1952445316313278
Validation loss: 2.4959825044859665

Epoch: 6| Step: 10
Training loss: 2.0141057639435993
Validation loss: 2.482349387496874

Epoch: 6| Step: 11
Training loss: 1.7715614916115079
Validation loss: 2.4838034855444473

Epoch: 6| Step: 12
Training loss: 1.5659590008899535
Validation loss: 2.469911656378485

Epoch: 6| Step: 13
Training loss: 1.2661046661542852
Validation loss: 2.430152244292108

Epoch: 169| Step: 0
Training loss: 2.089300409435345
Validation loss: 2.4048711850648603

Epoch: 6| Step: 1
Training loss: 1.6874444740485022
Validation loss: 2.3789358411494588

Epoch: 6| Step: 2
Training loss: 1.7705612048321748
Validation loss: 2.3680830468055856

Epoch: 6| Step: 3
Training loss: 1.420189749572017
Validation loss: 2.377748407078928

Epoch: 6| Step: 4
Training loss: 1.3869175298357632
Validation loss: 2.4057005377575535

Epoch: 6| Step: 5
Training loss: 1.7189708914564081
Validation loss: 2.414523395469417

Epoch: 6| Step: 6
Training loss: 1.6439563897235432
Validation loss: 2.4400416244592265

Epoch: 6| Step: 7
Training loss: 1.5476092512917587
Validation loss: 2.439850511332339

Epoch: 6| Step: 8
Training loss: 1.4544470730748007
Validation loss: 2.432932954378049

Epoch: 6| Step: 9
Training loss: 1.5951745641484512
Validation loss: 2.4672632627815716

Epoch: 6| Step: 10
Training loss: 1.6102696866977608
Validation loss: 2.4898158839368607

Epoch: 6| Step: 11
Training loss: 1.506058854127131
Validation loss: 2.467039321150559

Epoch: 6| Step: 12
Training loss: 1.489146784411487
Validation loss: 2.4865047267513236

Epoch: 6| Step: 13
Training loss: 1.4751776604421427
Validation loss: 2.4969092716781613

Epoch: 170| Step: 0
Training loss: 1.5395023085455142
Validation loss: 2.476315051060644

Epoch: 6| Step: 1
Training loss: 1.1846276730882306
Validation loss: 2.4396120129010916

Epoch: 6| Step: 2
Training loss: 1.8912542887939716
Validation loss: 2.4007146469064256

Epoch: 6| Step: 3
Training loss: 1.3800991183081672
Validation loss: 2.3610704471175716

Epoch: 6| Step: 4
Training loss: 1.731991065991202
Validation loss: 2.338891249041439

Epoch: 6| Step: 5
Training loss: 1.7990057875119765
Validation loss: 2.3199756927953077

Epoch: 6| Step: 6
Training loss: 1.5132803330544218
Validation loss: 2.3230122074267676

Epoch: 6| Step: 7
Training loss: 1.2890690658864505
Validation loss: 2.3620196306655705

Epoch: 6| Step: 8
Training loss: 1.529685486274929
Validation loss: 2.3863175424855383

Epoch: 6| Step: 9
Training loss: 2.2133038800742564
Validation loss: 2.446050336621929

Epoch: 6| Step: 10
Training loss: 1.4382917462846054
Validation loss: 2.476005619172576

Epoch: 6| Step: 11
Training loss: 1.3810331459183454
Validation loss: 2.527323536734103

Epoch: 6| Step: 12
Training loss: 1.4325792428512776
Validation loss: 2.5749006516426283

Epoch: 6| Step: 13
Training loss: 1.5607734296104225
Validation loss: 2.5544144197633702

Epoch: 171| Step: 0
Training loss: 1.4896399035971466
Validation loss: 2.561700975973724

Epoch: 6| Step: 1
Training loss: 1.2366431921061627
Validation loss: 2.5403422800717355

Epoch: 6| Step: 2
Training loss: 1.7717680614568694
Validation loss: 2.4969587511473588

Epoch: 6| Step: 3
Training loss: 1.821999288150552
Validation loss: 2.4677883199865533

Epoch: 6| Step: 4
Training loss: 1.8171176624736445
Validation loss: 2.419652830114128

Epoch: 6| Step: 5
Training loss: 2.009459298888425
Validation loss: 2.400585501103957

Epoch: 6| Step: 6
Training loss: 1.278174034241338
Validation loss: 2.3462108662857113

Epoch: 6| Step: 7
Training loss: 1.5332124551865791
Validation loss: 2.3586775730858847

Epoch: 6| Step: 8
Training loss: 1.6118701739791799
Validation loss: 2.319860918319548

Epoch: 6| Step: 9
Training loss: 1.2667237210390887
Validation loss: 2.3575292782467256

Epoch: 6| Step: 10
Training loss: 1.5037464403727092
Validation loss: 2.3782241613688466

Epoch: 6| Step: 11
Training loss: 1.2118041844012577
Validation loss: 2.4216170656247593

Epoch: 6| Step: 12
Training loss: 1.5602082803041675
Validation loss: 2.470097744418729

Epoch: 6| Step: 13
Training loss: 1.6770382592756614
Validation loss: 2.537040060725653

Epoch: 172| Step: 0
Training loss: 1.0798560909360344
Validation loss: 2.573908809144711

Epoch: 6| Step: 1
Training loss: 1.4292953036649687
Validation loss: 2.585794061521025

Epoch: 6| Step: 2
Training loss: 1.0517992385172403
Validation loss: 2.5440382931432137

Epoch: 6| Step: 3
Training loss: 1.8192778827375218
Validation loss: 2.500963699041161

Epoch: 6| Step: 4
Training loss: 1.7595324430604777
Validation loss: 2.453338311752874

Epoch: 6| Step: 5
Training loss: 1.3655373342209005
Validation loss: 2.3879048819000657

Epoch: 6| Step: 6
Training loss: 1.7437284352052667
Validation loss: 2.3464049693819646

Epoch: 6| Step: 7
Training loss: 1.521233475531898
Validation loss: 2.329978748279013

Epoch: 6| Step: 8
Training loss: 1.5081432552948049
Validation loss: 2.333029811502005

Epoch: 6| Step: 9
Training loss: 1.8168519488467738
Validation loss: 2.317911146709927

Epoch: 6| Step: 10
Training loss: 1.6418282592300562
Validation loss: 2.3363555293811635

Epoch: 6| Step: 11
Training loss: 1.9760447189583645
Validation loss: 2.4034909028981586

Epoch: 6| Step: 12
Training loss: 1.3875162329884057
Validation loss: 2.425472487764199

Epoch: 6| Step: 13
Training loss: 1.194648707960172
Validation loss: 2.47547919700663

Epoch: 173| Step: 0
Training loss: 1.6446046065327111
Validation loss: 2.5260015574346135

Epoch: 6| Step: 1
Training loss: 1.5834579251441776
Validation loss: 2.5371799696156536

Epoch: 6| Step: 2
Training loss: 1.5612202553400991
Validation loss: 2.5313116704410685

Epoch: 6| Step: 3
Training loss: 1.5871874013391123
Validation loss: 2.4877399150587713

Epoch: 6| Step: 4
Training loss: 1.841608646681411
Validation loss: 2.44404313244669

Epoch: 6| Step: 5
Training loss: 1.5335975868460823
Validation loss: 2.4009191697003716

Epoch: 6| Step: 6
Training loss: 1.7012001149125267
Validation loss: 2.3760776125953362

Epoch: 6| Step: 7
Training loss: 0.9541018123880174
Validation loss: 2.4003524695137677

Epoch: 6| Step: 8
Training loss: 1.3078509599688781
Validation loss: 2.402914026741731

Epoch: 6| Step: 9
Training loss: 1.1729373439956003
Validation loss: 2.418315278093426

Epoch: 6| Step: 10
Training loss: 0.9414377800817528
Validation loss: 2.4168081535644315

Epoch: 6| Step: 11
Training loss: 1.8582286987726078
Validation loss: 2.4380346274067453

Epoch: 6| Step: 12
Training loss: 1.7949089240768152
Validation loss: 2.444661154044532

Epoch: 6| Step: 13
Training loss: 1.3504080279406572
Validation loss: 2.4481589461643845

Epoch: 174| Step: 0
Training loss: 1.1672597410833596
Validation loss: 2.455587674247033

Epoch: 6| Step: 1
Training loss: 1.0537938040320416
Validation loss: 2.4465258977805204

Epoch: 6| Step: 2
Training loss: 1.5313065187572434
Validation loss: 2.4248143254315453

Epoch: 6| Step: 3
Training loss: 1.5269613348231985
Validation loss: 2.4331005655865856

Epoch: 6| Step: 4
Training loss: 1.5400406106325446
Validation loss: 2.4409888840158542

Epoch: 6| Step: 5
Training loss: 1.653313174291479
Validation loss: 2.4467535662446234

Epoch: 6| Step: 6
Training loss: 0.8819584048577177
Validation loss: 2.458948722290995

Epoch: 6| Step: 7
Training loss: 1.500723028766409
Validation loss: 2.441403625880646

Epoch: 6| Step: 8
Training loss: 1.2453553215140751
Validation loss: 2.4294181616149464

Epoch: 6| Step: 9
Training loss: 1.939822251150437
Validation loss: 2.382439702359302

Epoch: 6| Step: 10
Training loss: 1.985721761899167
Validation loss: 2.3857685411184497

Epoch: 6| Step: 11
Training loss: 1.3818927011861495
Validation loss: 2.3621921379300246

Epoch: 6| Step: 12
Training loss: 1.6089388061797907
Validation loss: 2.3579609939369672

Epoch: 6| Step: 13
Training loss: 1.4406363232347588
Validation loss: 2.390282427490234

Epoch: 175| Step: 0
Training loss: 1.0736105011815857
Validation loss: 2.396686923719451

Epoch: 6| Step: 1
Training loss: 1.0712709242781377
Validation loss: 2.423728727776113

Epoch: 6| Step: 2
Training loss: 1.4472026939970113
Validation loss: 2.452692902346318

Epoch: 6| Step: 3
Training loss: 1.2298824306061569
Validation loss: 2.450183147133625

Epoch: 6| Step: 4
Training loss: 1.5447120572252093
Validation loss: 2.472865640791631

Epoch: 6| Step: 5
Training loss: 1.8409024895657775
Validation loss: 2.4724622391549675

Epoch: 6| Step: 6
Training loss: 1.6361748786391968
Validation loss: 2.465864926436868

Epoch: 6| Step: 7
Training loss: 1.2148720103224222
Validation loss: 2.4586983412006798

Epoch: 6| Step: 8
Training loss: 1.1048978268090575
Validation loss: 2.4615299541069615

Epoch: 6| Step: 9
Training loss: 1.8915635608800576
Validation loss: 2.436922945848689

Epoch: 6| Step: 10
Training loss: 1.5143713731521584
Validation loss: 2.371104547979088

Epoch: 6| Step: 11
Training loss: 1.7630193607957139
Validation loss: 2.3585467705897303

Epoch: 6| Step: 12
Training loss: 1.3616733195462571
Validation loss: 2.361058940910273

Epoch: 6| Step: 13
Training loss: 1.6693584004572672
Validation loss: 2.374126861035511

Epoch: 176| Step: 0
Training loss: 1.3345249136481885
Validation loss: 2.39318732536479

Epoch: 6| Step: 1
Training loss: 1.3020481664359105
Validation loss: 2.3983320773062964

Epoch: 6| Step: 2
Training loss: 1.6428817486549288
Validation loss: 2.450506104729546

Epoch: 6| Step: 3
Training loss: 1.4753166473078274
Validation loss: 2.4271131032460933

Epoch: 6| Step: 4
Training loss: 1.6750346479106186
Validation loss: 2.4134889112315383

Epoch: 6| Step: 5
Training loss: 1.6660222079112326
Validation loss: 2.4269896254198495

Epoch: 6| Step: 6
Training loss: 1.410863598549432
Validation loss: 2.426592589259294

Epoch: 6| Step: 7
Training loss: 1.7829786913588512
Validation loss: 2.450026334370329

Epoch: 6| Step: 8
Training loss: 1.6663159080800465
Validation loss: 2.4801998892857857

Epoch: 6| Step: 9
Training loss: 1.2630276342254747
Validation loss: 2.4603436643097747

Epoch: 6| Step: 10
Training loss: 1.4063869833455613
Validation loss: 2.4360146152366315

Epoch: 6| Step: 11
Training loss: 1.2522481728371184
Validation loss: 2.4168223411170535

Epoch: 6| Step: 12
Training loss: 1.0408068477985906
Validation loss: 2.4203965781036576

Epoch: 6| Step: 13
Training loss: 1.284533921037019
Validation loss: 2.398532331250754

Epoch: 177| Step: 0
Training loss: 1.696119968768663
Validation loss: 2.4026687536954525

Epoch: 6| Step: 1
Training loss: 1.4006006570153477
Validation loss: 2.4261618525941855

Epoch: 6| Step: 2
Training loss: 1.7159659291866476
Validation loss: 2.401688662055783

Epoch: 6| Step: 3
Training loss: 1.5035371401747166
Validation loss: 2.3949661961265174

Epoch: 6| Step: 4
Training loss: 1.4424261191239083
Validation loss: 2.3791716918352037

Epoch: 6| Step: 5
Training loss: 1.7318412211939742
Validation loss: 2.3663140665434783

Epoch: 6| Step: 6
Training loss: 1.0351167491357827
Validation loss: 2.3780093856183764

Epoch: 6| Step: 7
Training loss: 1.2989078812742092
Validation loss: 2.3673735568858363

Epoch: 6| Step: 8
Training loss: 1.2020135675258052
Validation loss: 2.3801646679733173

Epoch: 6| Step: 9
Training loss: 0.9534598840957254
Validation loss: 2.4051337591580277

Epoch: 6| Step: 10
Training loss: 1.5491425049641643
Validation loss: 2.4181798091737488

Epoch: 6| Step: 11
Training loss: 1.7559624324507819
Validation loss: 2.480456150195078

Epoch: 6| Step: 12
Training loss: 0.6798706027290446
Validation loss: 2.4797441422327093

Epoch: 6| Step: 13
Training loss: 1.844725722418251
Validation loss: 2.5127082924071793

Epoch: 178| Step: 0
Training loss: 0.9986983410744427
Validation loss: 2.4954977009906325

Epoch: 6| Step: 1
Training loss: 1.433507433379386
Validation loss: 2.506096252990633

Epoch: 6| Step: 2
Training loss: 1.8648899898861169
Validation loss: 2.498536312103461

Epoch: 6| Step: 3
Training loss: 1.337591430177226
Validation loss: 2.4701081539746026

Epoch: 6| Step: 4
Training loss: 1.1127336192488373
Validation loss: 2.44337198563665

Epoch: 6| Step: 5
Training loss: 1.4350516159131987
Validation loss: 2.4424345296516248

Epoch: 6| Step: 6
Training loss: 1.0769072579961698
Validation loss: 2.441834995745204

Epoch: 6| Step: 7
Training loss: 1.6338696137868398
Validation loss: 2.460654229110156

Epoch: 6| Step: 8
Training loss: 1.3658205446657399
Validation loss: 2.489094108478332

Epoch: 6| Step: 9
Training loss: 1.5411818575433043
Validation loss: 2.4803354788355456

Epoch: 6| Step: 10
Training loss: 1.3826485660601135
Validation loss: 2.513951997658462

Epoch: 6| Step: 11
Training loss: 1.6369491087285704
Validation loss: 2.4898806120859276

Epoch: 6| Step: 12
Training loss: 1.4921466761891504
Validation loss: 2.438691296414319

Epoch: 6| Step: 13
Training loss: 1.553302704068434
Validation loss: 2.414449824574173

Epoch: 179| Step: 0
Training loss: 1.3860184741529815
Validation loss: 2.376806393640129

Epoch: 6| Step: 1
Training loss: 0.9375264799828845
Validation loss: 2.3761278355536

Epoch: 6| Step: 2
Training loss: 1.3522783269103282
Validation loss: 2.356800240470471

Epoch: 6| Step: 3
Training loss: 1.0489029102905876
Validation loss: 2.369173455604117

Epoch: 6| Step: 4
Training loss: 0.9242632367478869
Validation loss: 2.4066276749316815

Epoch: 6| Step: 5
Training loss: 1.4811069049204721
Validation loss: 2.392834398391707

Epoch: 6| Step: 6
Training loss: 1.4413675442592853
Validation loss: 2.4153046951495925

Epoch: 6| Step: 7
Training loss: 1.8993243120264214
Validation loss: 2.4687192309284467

Epoch: 6| Step: 8
Training loss: 1.5804752185668418
Validation loss: 2.519798743981899

Epoch: 6| Step: 9
Training loss: 1.8914480388299728
Validation loss: 2.5011049402739065

Epoch: 6| Step: 10
Training loss: 1.472016132173043
Validation loss: 2.5229643900111336

Epoch: 6| Step: 11
Training loss: 1.172652431738506
Validation loss: 2.5139730547008527

Epoch: 6| Step: 12
Training loss: 1.1949331641560237
Validation loss: 2.46968265568167

Epoch: 6| Step: 13
Training loss: 1.4082733856323566
Validation loss: 2.470000467088637

Epoch: 180| Step: 0
Training loss: 1.711348253526626
Validation loss: 2.4259055475696436

Epoch: 6| Step: 1
Training loss: 1.001055101244299
Validation loss: 2.4120513389580016

Epoch: 6| Step: 2
Training loss: 1.4659639271647482
Validation loss: 2.409683930888925

Epoch: 6| Step: 3
Training loss: 1.4391552890017867
Validation loss: 2.411516522201795

Epoch: 6| Step: 4
Training loss: 0.9274422597263631
Validation loss: 2.4203487428507353

Epoch: 6| Step: 5
Training loss: 0.7471894212903091
Validation loss: 2.416242847330078

Epoch: 6| Step: 6
Training loss: 1.0828670207247815
Validation loss: 2.4373127813093176

Epoch: 6| Step: 7
Training loss: 1.6603075384880446
Validation loss: 2.468874411967745

Epoch: 6| Step: 8
Training loss: 1.4143174083951073
Validation loss: 2.4774917645299577

Epoch: 6| Step: 9
Training loss: 1.4156143356494177
Validation loss: 2.452918435935958

Epoch: 6| Step: 10
Training loss: 1.5879452779263135
Validation loss: 2.414565228921116

Epoch: 6| Step: 11
Training loss: 1.283840305751339
Validation loss: 2.408871189756809

Epoch: 6| Step: 12
Training loss: 1.6981298706748618
Validation loss: 2.410246268818875

Epoch: 6| Step: 13
Training loss: 1.4856354030297856
Validation loss: 2.4049460579418196

Epoch: 181| Step: 0
Training loss: 1.1310976927006522
Validation loss: 2.43429402974387

Epoch: 6| Step: 1
Training loss: 1.1913833866114374
Validation loss: 2.436217707771406

Epoch: 6| Step: 2
Training loss: 1.638164018721534
Validation loss: 2.421963908997836

Epoch: 6| Step: 3
Training loss: 1.4522702564278724
Validation loss: 2.40561803992543

Epoch: 6| Step: 4
Training loss: 1.1431790849958765
Validation loss: 2.410707904004007

Epoch: 6| Step: 5
Training loss: 1.1305415047707887
Validation loss: 2.402395259299296

Epoch: 6| Step: 6
Training loss: 1.4677233252787327
Validation loss: 2.412542595100243

Epoch: 6| Step: 7
Training loss: 1.4251630723236004
Validation loss: 2.4269050023158467

Epoch: 6| Step: 8
Training loss: 1.4431722104101599
Validation loss: 2.455402188643658

Epoch: 6| Step: 9
Training loss: 1.5156843822683606
Validation loss: 2.519167861876591

Epoch: 6| Step: 10
Training loss: 1.591050947974034
Validation loss: 2.551083926376323

Epoch: 6| Step: 11
Training loss: 1.198398073186968
Validation loss: 2.5590236723132955

Epoch: 6| Step: 12
Training loss: 1.240549218772386
Validation loss: 2.5018255152182176

Epoch: 6| Step: 13
Training loss: 1.7617430420953732
Validation loss: 2.4383672407782826

Epoch: 182| Step: 0
Training loss: 0.9388749847818413
Validation loss: 2.3786485773134745

Epoch: 6| Step: 1
Training loss: 1.196300721403646
Validation loss: 2.3646558102057553

Epoch: 6| Step: 2
Training loss: 1.6307456336646462
Validation loss: 2.3260135307616436

Epoch: 6| Step: 3
Training loss: 1.6660586281131227
Validation loss: 2.313762741857306

Epoch: 6| Step: 4
Training loss: 1.160983782701806
Validation loss: 2.3250623369367034

Epoch: 6| Step: 5
Training loss: 1.5808530588214722
Validation loss: 2.342585988190148

Epoch: 6| Step: 6
Training loss: 0.9748628091882641
Validation loss: 2.379675330082983

Epoch: 6| Step: 7
Training loss: 1.4886301187441187
Validation loss: 2.4283764921347286

Epoch: 6| Step: 8
Training loss: 1.4896325412260698
Validation loss: 2.477638024287272

Epoch: 6| Step: 9
Training loss: 0.9924663242036703
Validation loss: 2.5153554227875796

Epoch: 6| Step: 10
Training loss: 2.0265496670471794
Validation loss: 2.5282901761216894

Epoch: 6| Step: 11
Training loss: 1.1058249826314805
Validation loss: 2.5167905471270275

Epoch: 6| Step: 12
Training loss: 0.8793062444295316
Validation loss: 2.484416180949956

Epoch: 6| Step: 13
Training loss: 1.395816712731244
Validation loss: 2.4670217250460618

Epoch: 183| Step: 0
Training loss: 1.319781044082024
Validation loss: 2.4438366619901704

Epoch: 6| Step: 1
Training loss: 1.4094689720611535
Validation loss: 2.413533991153789

Epoch: 6| Step: 2
Training loss: 1.5293059172186385
Validation loss: 2.388082522911233

Epoch: 6| Step: 3
Training loss: 1.523063887730787
Validation loss: 2.3717320496952836

Epoch: 6| Step: 4
Training loss: 1.4374981755784109
Validation loss: 2.351449726815493

Epoch: 6| Step: 5
Training loss: 1.2504826567559473
Validation loss: 2.358020805926032

Epoch: 6| Step: 6
Training loss: 1.4785033695413472
Validation loss: 2.3827862266572746

Epoch: 6| Step: 7
Training loss: 1.5118020993303565
Validation loss: 2.417557492423276

Epoch: 6| Step: 8
Training loss: 1.0662943463422199
Validation loss: 2.4144298245996367

Epoch: 6| Step: 9
Training loss: 1.1652183682515285
Validation loss: 2.4540649999990745

Epoch: 6| Step: 10
Training loss: 1.6141195636126857
Validation loss: 2.4460932297035507

Epoch: 6| Step: 11
Training loss: 1.1720363251586765
Validation loss: 2.438147419703199

Epoch: 6| Step: 12
Training loss: 1.1061328200870943
Validation loss: 2.4753574348160297

Epoch: 6| Step: 13
Training loss: 0.9751378463233404
Validation loss: 2.503242291380997

Epoch: 184| Step: 0
Training loss: 1.5723942863942797
Validation loss: 2.4815047019539107

Epoch: 6| Step: 1
Training loss: 1.509506459958032
Validation loss: 2.443285366594729

Epoch: 6| Step: 2
Training loss: 0.8564904787165711
Validation loss: 2.382467163172646

Epoch: 6| Step: 3
Training loss: 1.050616737165302
Validation loss: 2.3330482236940706

Epoch: 6| Step: 4
Training loss: 1.2358586533349796
Validation loss: 2.3196573684314323

Epoch: 6| Step: 5
Training loss: 1.0742412772850987
Validation loss: 2.299176758569029

Epoch: 6| Step: 6
Training loss: 1.2123844976567402
Validation loss: 2.303558861917117

Epoch: 6| Step: 7
Training loss: 1.3896066172801853
Validation loss: 2.3174673838473536

Epoch: 6| Step: 8
Training loss: 1.43401195444527
Validation loss: 2.386381784717312

Epoch: 6| Step: 9
Training loss: 1.6745247921183326
Validation loss: 2.4561079825295016

Epoch: 6| Step: 10
Training loss: 1.3201304654467987
Validation loss: 2.5654524455171672

Epoch: 6| Step: 11
Training loss: 1.3566752404372395
Validation loss: 2.579073707338913

Epoch: 6| Step: 12
Training loss: 0.9138297738400123
Validation loss: 2.5415052392600352

Epoch: 6| Step: 13
Training loss: 2.1310122091587123
Validation loss: 2.505641371452967

Epoch: 185| Step: 0
Training loss: 0.9900028176219416
Validation loss: 2.4509953151106227

Epoch: 6| Step: 1
Training loss: 1.7704085644669536
Validation loss: 2.411283321688035

Epoch: 6| Step: 2
Training loss: 1.1980963309633421
Validation loss: 2.365579743638608

Epoch: 6| Step: 3
Training loss: 1.1936981669252504
Validation loss: 2.31829382449059

Epoch: 6| Step: 4
Training loss: 1.0505141588842852
Validation loss: 2.3409515321765904

Epoch: 6| Step: 5
Training loss: 1.4130315236316326
Validation loss: 2.33807279622858

Epoch: 6| Step: 6
Training loss: 1.1183335088416093
Validation loss: 2.373449684187456

Epoch: 6| Step: 7
Training loss: 1.1275874159393218
Validation loss: 2.3775204225479527

Epoch: 6| Step: 8
Training loss: 1.8054053790246345
Validation loss: 2.464288570530038

Epoch: 6| Step: 9
Training loss: 1.326763307719234
Validation loss: 2.5396097683576575

Epoch: 6| Step: 10
Training loss: 1.690997561091509
Validation loss: 2.5904888724965214

Epoch: 6| Step: 11
Training loss: 1.4771821674519405
Validation loss: 2.605263504549083

Epoch: 6| Step: 12
Training loss: 0.9440595662268089
Validation loss: 2.5418459837255254

Epoch: 6| Step: 13
Training loss: 1.140038117223246
Validation loss: 2.471607866174521

Epoch: 186| Step: 0
Training loss: 1.340466902153857
Validation loss: 2.451168314809403

Epoch: 6| Step: 1
Training loss: 1.513671875
Validation loss: 2.4242285114937396

Epoch: 6| Step: 2
Training loss: 1.450328145221212
Validation loss: 2.3976131549863737

Epoch: 6| Step: 3
Training loss: 1.6800170575138806
Validation loss: 2.404099586915768

Epoch: 6| Step: 4
Training loss: 1.371469082226914
Validation loss: 2.3671002191355015

Epoch: 6| Step: 5
Training loss: 1.0189978128471524
Validation loss: 2.387747522172484

Epoch: 6| Step: 6
Training loss: 1.5817861861697124
Validation loss: 2.367028011338632

Epoch: 6| Step: 7
Training loss: 0.8569556078569256
Validation loss: 2.372731933328862

Epoch: 6| Step: 8
Training loss: 1.3571442025041724
Validation loss: 2.388504972449228

Epoch: 6| Step: 9
Training loss: 1.2438140871798735
Validation loss: 2.383845804600006

Epoch: 6| Step: 10
Training loss: 1.3174270611140455
Validation loss: 2.4264871674117257

Epoch: 6| Step: 11
Training loss: 1.4566897076341936
Validation loss: 2.4139031124200603

Epoch: 6| Step: 12
Training loss: 0.9079211381787823
Validation loss: 2.4500359065689588

Epoch: 6| Step: 13
Training loss: 1.1570144909682358
Validation loss: 2.466256679739606

Epoch: 187| Step: 0
Training loss: 1.1904903205532558
Validation loss: 2.4769135478645086

Epoch: 6| Step: 1
Training loss: 1.2214732921989322
Validation loss: 2.4910134452080577

Epoch: 6| Step: 2
Training loss: 1.279005270767387
Validation loss: 2.4678310398910543

Epoch: 6| Step: 3
Training loss: 1.9864346485963038
Validation loss: 2.4069998704320184

Epoch: 6| Step: 4
Training loss: 1.2160458030105328
Validation loss: 2.42710142108195

Epoch: 6| Step: 5
Training loss: 1.470778505133703
Validation loss: 2.427128970196708

Epoch: 6| Step: 6
Training loss: 1.1198024423953123
Validation loss: 2.3864406861891694

Epoch: 6| Step: 7
Training loss: 1.131559797408599
Validation loss: 2.386190535995247

Epoch: 6| Step: 8
Training loss: 1.1913503665012382
Validation loss: 2.406183226689294

Epoch: 6| Step: 9
Training loss: 1.0692285213779325
Validation loss: 2.4212952966995465

Epoch: 6| Step: 10
Training loss: 1.3271431378952778
Validation loss: 2.4545543956315803

Epoch: 6| Step: 11
Training loss: 0.8719632722749343
Validation loss: 2.467879864107955

Epoch: 6| Step: 12
Training loss: 1.5837910977565848
Validation loss: 2.4565377752845197

Epoch: 6| Step: 13
Training loss: 0.6654792706709686
Validation loss: 2.460580968023723

Epoch: 188| Step: 0
Training loss: 0.9655791040272326
Validation loss: 2.431837885196357

Epoch: 6| Step: 1
Training loss: 1.1631844812728804
Validation loss: 2.4498620242824076

Epoch: 6| Step: 2
Training loss: 1.196662688784421
Validation loss: 2.4837514732446433

Epoch: 6| Step: 3
Training loss: 1.275530259811608
Validation loss: 2.4487464610223837

Epoch: 6| Step: 4
Training loss: 1.2400904774728034
Validation loss: 2.421890002577007

Epoch: 6| Step: 5
Training loss: 1.3851808428531007
Validation loss: 2.4396660554010587

Epoch: 6| Step: 6
Training loss: 1.1719327785235507
Validation loss: 2.4264993855466024

Epoch: 6| Step: 7
Training loss: 1.2571152359696218
Validation loss: 2.3960246151987796

Epoch: 6| Step: 8
Training loss: 1.2998407761560065
Validation loss: 2.3684375058641107

Epoch: 6| Step: 9
Training loss: 1.8071152512107376
Validation loss: 2.3626534493471967

Epoch: 6| Step: 10
Training loss: 0.750388084776678
Validation loss: 2.37741122444411

Epoch: 6| Step: 11
Training loss: 1.2548587781927485
Validation loss: 2.403350210001564

Epoch: 6| Step: 12
Training loss: 1.488169668425235
Validation loss: 2.4414682126293563

Epoch: 6| Step: 13
Training loss: 1.3940807223844631
Validation loss: 2.4373869584435783

Epoch: 189| Step: 0
Training loss: 1.7801026781877942
Validation loss: 2.4097095524355523

Epoch: 6| Step: 1
Training loss: 0.6933620399101517
Validation loss: 2.373634772832008

Epoch: 6| Step: 2
Training loss: 1.3021094154288784
Validation loss: 2.364629184425986

Epoch: 6| Step: 3
Training loss: 1.3817621325944935
Validation loss: 2.3644952590048605

Epoch: 6| Step: 4
Training loss: 1.325506343899759
Validation loss: 2.34884835128016

Epoch: 6| Step: 5
Training loss: 1.2423343691581445
Validation loss: 2.3623079887631286

Epoch: 6| Step: 6
Training loss: 1.0753001370726747
Validation loss: 2.3668593193367116

Epoch: 6| Step: 7
Training loss: 0.8792958731118133
Validation loss: 2.3633523063720183

Epoch: 6| Step: 8
Training loss: 1.3538189172505923
Validation loss: 2.363770056717366

Epoch: 6| Step: 9
Training loss: 1.5363584669168806
Validation loss: 2.395810736451092

Epoch: 6| Step: 10
Training loss: 1.0524749153029345
Validation loss: 2.434168639189003

Epoch: 6| Step: 11
Training loss: 1.3943462516252507
Validation loss: 2.4533531668606114

Epoch: 6| Step: 12
Training loss: 1.026550683079818
Validation loss: 2.4689848562140244

Epoch: 6| Step: 13
Training loss: 1.318166399360334
Validation loss: 2.4899704307381545

Epoch: 190| Step: 0
Training loss: 1.3959332425624944
Validation loss: 2.483863556578742

Epoch: 6| Step: 1
Training loss: 0.8622970148697794
Validation loss: 2.4029514683581787

Epoch: 6| Step: 2
Training loss: 1.0960582898712696
Validation loss: 2.334819537563226

Epoch: 6| Step: 3
Training loss: 1.4911036524623211
Validation loss: 2.296638064134095

Epoch: 6| Step: 4
Training loss: 1.4112126416920348
Validation loss: 2.26466967307388

Epoch: 6| Step: 5
Training loss: 1.5908488627588842
Validation loss: 2.248514150817316

Epoch: 6| Step: 6
Training loss: 1.0267828508893952
Validation loss: 2.2459139804315758

Epoch: 6| Step: 7
Training loss: 1.3268048176328076
Validation loss: 2.2894242484624687

Epoch: 6| Step: 8
Training loss: 1.2994975953206458
Validation loss: 2.3766113227477015

Epoch: 6| Step: 9
Training loss: 1.1752515848161682
Validation loss: 2.43386788658576

Epoch: 6| Step: 10
Training loss: 0.9831737272939491
Validation loss: 2.493776284890756

Epoch: 6| Step: 11
Training loss: 1.744773485079496
Validation loss: 2.622081601187004

Epoch: 6| Step: 12
Training loss: 0.996442726189023
Validation loss: 2.6599965407390433

Epoch: 6| Step: 13
Training loss: 1.6655526809308472
Validation loss: 2.6616125728965856

Epoch: 191| Step: 0
Training loss: 1.3858488981359622
Validation loss: 2.594561919128567

Epoch: 6| Step: 1
Training loss: 1.1022907852652863
Validation loss: 2.4999675271786295

Epoch: 6| Step: 2
Training loss: 0.9963170418384231
Validation loss: 2.455548725322219

Epoch: 6| Step: 3
Training loss: 1.312545957214842
Validation loss: 2.3716862287273734

Epoch: 6| Step: 4
Training loss: 1.2974242001187242
Validation loss: 2.3676404730454395

Epoch: 6| Step: 5
Training loss: 1.2739147859846742
Validation loss: 2.364515041116654

Epoch: 6| Step: 6
Training loss: 1.9338075461822426
Validation loss: 2.3507363808789115

Epoch: 6| Step: 7
Training loss: 1.4307755462642775
Validation loss: 2.3671264207361484

Epoch: 6| Step: 8
Training loss: 1.4472612594559242
Validation loss: 2.3477409156016615

Epoch: 6| Step: 9
Training loss: 0.7824345572896433
Validation loss: 2.3613690139719554

Epoch: 6| Step: 10
Training loss: 1.072772963940157
Validation loss: 2.3776526994321685

Epoch: 6| Step: 11
Training loss: 1.4313051837793958
Validation loss: 2.3726944173193116

Epoch: 6| Step: 12
Training loss: 0.8996348819272082
Validation loss: 2.4128198873937152

Epoch: 6| Step: 13
Training loss: 1.2146832031927717
Validation loss: 2.4378619307899396

Epoch: 192| Step: 0
Training loss: 1.1530445101799214
Validation loss: 2.4496492386744717

Epoch: 6| Step: 1
Training loss: 0.9447963030335806
Validation loss: 2.437506514530821

Epoch: 6| Step: 2
Training loss: 1.3595535336470024
Validation loss: 2.3919247265579378

Epoch: 6| Step: 3
Training loss: 1.1353115534758775
Validation loss: 2.338459718258075

Epoch: 6| Step: 4
Training loss: 0.8260159536996222
Validation loss: 2.312201161629871

Epoch: 6| Step: 5
Training loss: 1.211076642317822
Validation loss: 2.300638570591638

Epoch: 6| Step: 6
Training loss: 1.50379884014265
Validation loss: 2.290761855894304

Epoch: 6| Step: 7
Training loss: 1.5898603208835813
Validation loss: 2.2732981983184968

Epoch: 6| Step: 8
Training loss: 1.101280338592555
Validation loss: 2.3306653470786327

Epoch: 6| Step: 9
Training loss: 1.128653105234268
Validation loss: 2.370798188261236

Epoch: 6| Step: 10
Training loss: 1.6205346303768804
Validation loss: 2.4557316056636775

Epoch: 6| Step: 11
Training loss: 1.3674824423769947
Validation loss: 2.4945909856693564

Epoch: 6| Step: 12
Training loss: 1.2271079533195262
Validation loss: 2.541275918969617

Epoch: 6| Step: 13
Training loss: 0.8919196172619867
Validation loss: 2.5779204873228356

Epoch: 193| Step: 0
Training loss: 1.0365418571415461
Validation loss: 2.5672364809256814

Epoch: 6| Step: 1
Training loss: 1.2607493263710305
Validation loss: 2.5654530910608586

Epoch: 6| Step: 2
Training loss: 1.1057600843886954
Validation loss: 2.513634980613939

Epoch: 6| Step: 3
Training loss: 1.0884905655591786
Validation loss: 2.448340361788963

Epoch: 6| Step: 4
Training loss: 1.1967114010545485
Validation loss: 2.3828514791225865

Epoch: 6| Step: 5
Training loss: 1.3404190118634964
Validation loss: 2.349567046785059

Epoch: 6| Step: 6
Training loss: 0.9983055540963396
Validation loss: 2.3280784182180536

Epoch: 6| Step: 7
Training loss: 1.3269851280937117
Validation loss: 2.335726709911205

Epoch: 6| Step: 8
Training loss: 1.6217970460007467
Validation loss: 2.3535591882251468

Epoch: 6| Step: 9
Training loss: 1.0722451685776373
Validation loss: 2.333117801040517

Epoch: 6| Step: 10
Training loss: 1.2913792916015114
Validation loss: 2.3232732104006706

Epoch: 6| Step: 11
Training loss: 1.4888918767886443
Validation loss: 2.3040628723123846

Epoch: 6| Step: 12
Training loss: 1.1798661456725088
Validation loss: 2.339813871540598

Epoch: 6| Step: 13
Training loss: 1.0810024176472635
Validation loss: 2.385509697826322

Epoch: 194| Step: 0
Training loss: 0.9040681949440064
Validation loss: 2.43588216187377

Epoch: 6| Step: 1
Training loss: 1.3615474661048967
Validation loss: 2.4663627123642695

Epoch: 6| Step: 2
Training loss: 0.9191529772082906
Validation loss: 2.4796504989981454

Epoch: 6| Step: 3
Training loss: 1.5648144936838182
Validation loss: 2.4625769776011825

Epoch: 6| Step: 4
Training loss: 1.2749170706463426
Validation loss: 2.421234869802995

Epoch: 6| Step: 5
Training loss: 1.2359527451916852
Validation loss: 2.409824831662599

Epoch: 6| Step: 6
Training loss: 0.9826770852928524
Validation loss: 2.3418888110018092

Epoch: 6| Step: 7
Training loss: 1.1396280922663131
Validation loss: 2.323832008515598

Epoch: 6| Step: 8
Training loss: 0.9522104722379586
Validation loss: 2.345438013951695

Epoch: 6| Step: 9
Training loss: 0.9289281933938183
Validation loss: 2.326106932594639

Epoch: 6| Step: 10
Training loss: 1.2278037138731583
Validation loss: 2.3274780958147345

Epoch: 6| Step: 11
Training loss: 1.786550499083571
Validation loss: 2.3593503476312128

Epoch: 6| Step: 12
Training loss: 1.2311392758537445
Validation loss: 2.364096820569349

Epoch: 6| Step: 13
Training loss: 0.8273599797747124
Validation loss: 2.383625020957979

Epoch: 195| Step: 0
Training loss: 1.3350229534933342
Validation loss: 2.358796145726082

Epoch: 6| Step: 1
Training loss: 1.0268071735106237
Validation loss: 2.3679079729862496

Epoch: 6| Step: 2
Training loss: 0.8800371142710441
Validation loss: 2.4158926835775145

Epoch: 6| Step: 3
Training loss: 0.7745976464965391
Validation loss: 2.390154309187978

Epoch: 6| Step: 4
Training loss: 1.3000797980832859
Validation loss: 2.41561851501125

Epoch: 6| Step: 5
Training loss: 1.0292860461249922
Validation loss: 2.4092912465766876

Epoch: 6| Step: 6
Training loss: 1.1585545127434047
Validation loss: 2.4369775124287423

Epoch: 6| Step: 7
Training loss: 1.0270933128836743
Validation loss: 2.4717047887913592

Epoch: 6| Step: 8
Training loss: 1.504645148737936
Validation loss: 2.506224565937219

Epoch: 6| Step: 9
Training loss: 1.1600889449713547
Validation loss: 2.492729901290748

Epoch: 6| Step: 10
Training loss: 1.6958764188699669
Validation loss: 2.4839110314952713

Epoch: 6| Step: 11
Training loss: 0.997429912705364
Validation loss: 2.4725221077409567

Epoch: 6| Step: 12
Training loss: 1.1739757781381306
Validation loss: 2.4301538899824333

Epoch: 6| Step: 13
Training loss: 0.8795628447490302
Validation loss: 2.389444427382404

Epoch: 196| Step: 0
Training loss: 1.2132250928194912
Validation loss: 2.3522243100623066

Epoch: 6| Step: 1
Training loss: 0.518546555162588
Validation loss: 2.3276388218572173

Epoch: 6| Step: 2
Training loss: 0.961944951369929
Validation loss: 2.3210613403692952

Epoch: 6| Step: 3
Training loss: 1.2040395357192946
Validation loss: 2.319179300870568

Epoch: 6| Step: 4
Training loss: 1.4269889837480032
Validation loss: 2.311631855394433

Epoch: 6| Step: 5
Training loss: 1.168684826017989
Validation loss: 2.343710733720553

Epoch: 6| Step: 6
Training loss: 1.4919886431581395
Validation loss: 2.3560895247866442

Epoch: 6| Step: 7
Training loss: 1.0490571239107551
Validation loss: 2.4092837683216723

Epoch: 6| Step: 8
Training loss: 1.2528078015477948
Validation loss: 2.4739746006860965

Epoch: 6| Step: 9
Training loss: 1.3525084344033278
Validation loss: 2.5195264636426153

Epoch: 6| Step: 10
Training loss: 1.2595556276340534
Validation loss: 2.5635575284032694

Epoch: 6| Step: 11
Training loss: 1.0420500177068137
Validation loss: 2.5862218719473646

Epoch: 6| Step: 12
Training loss: 1.0473297611732522
Validation loss: 2.5653082533675016

Epoch: 6| Step: 13
Training loss: 1.1623784627242384
Validation loss: 2.575528599664853

Epoch: 197| Step: 0
Training loss: 1.2260479667888469
Validation loss: 2.4970431284652164

Epoch: 6| Step: 1
Training loss: 1.2384484596354675
Validation loss: 2.387444286537152

Epoch: 6| Step: 2
Training loss: 1.098517355044287
Validation loss: 2.3272330263009002

Epoch: 6| Step: 3
Training loss: 1.318960276106024
Validation loss: 2.2891372477508027

Epoch: 6| Step: 4
Training loss: 1.224496303856514
Validation loss: 2.262304385887825

Epoch: 6| Step: 5
Training loss: 1.0173802979750013
Validation loss: 2.2692179941022403

Epoch: 6| Step: 6
Training loss: 0.9481968029094643
Validation loss: 2.318811420467137

Epoch: 6| Step: 7
Training loss: 1.4744052366719467
Validation loss: 2.3472007413436495

Epoch: 6| Step: 8
Training loss: 0.6692686315913419
Validation loss: 2.3556900232030054

Epoch: 6| Step: 9
Training loss: 1.1143457510078758
Validation loss: 2.434147501585747

Epoch: 6| Step: 10
Training loss: 1.129392789648868
Validation loss: 2.431022572416181

Epoch: 6| Step: 11
Training loss: 0.7443012054275742
Validation loss: 2.437697715197457

Epoch: 6| Step: 12
Training loss: 1.3149426754542706
Validation loss: 2.4223027100721586

Epoch: 6| Step: 13
Training loss: 1.6505561700442646
Validation loss: 2.4182567459051216

Epoch: 198| Step: 0
Training loss: 0.9213365825199223
Validation loss: 2.4630936294529975

Epoch: 6| Step: 1
Training loss: 0.9635809538108976
Validation loss: 2.4808999459764434

Epoch: 6| Step: 2
Training loss: 1.0652617856322482
Validation loss: 2.4537109193622477

Epoch: 6| Step: 3
Training loss: 1.0142171051242426
Validation loss: 2.403689914349336

Epoch: 6| Step: 4
Training loss: 0.7418615328073379
Validation loss: 2.402076074664512

Epoch: 6| Step: 5
Training loss: 1.339888502435688
Validation loss: 2.3767640514563118

Epoch: 6| Step: 6
Training loss: 0.9833479776477351
Validation loss: 2.367112550483371

Epoch: 6| Step: 7
Training loss: 1.09942213398757
Validation loss: 2.3343328098390255

Epoch: 6| Step: 8
Training loss: 1.1666037451715519
Validation loss: 2.3338153497988485

Epoch: 6| Step: 9
Training loss: 1.4195430202972397
Validation loss: 2.3545390872763194

Epoch: 6| Step: 10
Training loss: 1.0780098895112953
Validation loss: 2.371515080143071

Epoch: 6| Step: 11
Training loss: 1.2438396766576159
Validation loss: 2.388483351304916

Epoch: 6| Step: 12
Training loss: 1.625695153247596
Validation loss: 2.386723164660616

Epoch: 6| Step: 13
Training loss: 0.6170672528912544
Validation loss: 2.372606574031644

Epoch: 199| Step: 0
Training loss: 0.6532127394445988
Validation loss: 2.379391079687586

Epoch: 6| Step: 1
Training loss: 1.2687557257913007
Validation loss: 2.3525869111218203

Epoch: 6| Step: 2
Training loss: 1.2959251142341832
Validation loss: 2.355569497919036

Epoch: 6| Step: 3
Training loss: 0.8339207287697049
Validation loss: 2.3190677978401695

Epoch: 6| Step: 4
Training loss: 1.2027487228345541
Validation loss: 2.347020654902155

Epoch: 6| Step: 5
Training loss: 1.1270664098647796
Validation loss: 2.3342607745462187

Epoch: 6| Step: 6
Training loss: 0.8575977327576602
Validation loss: 2.308156483747598

Epoch: 6| Step: 7
Training loss: 1.0632841358243752
Validation loss: 2.318425534040038

Epoch: 6| Step: 8
Training loss: 1.0756385991213777
Validation loss: 2.325412227699588

Epoch: 6| Step: 9
Training loss: 0.9606658737729533
Validation loss: 2.3651607558840633

Epoch: 6| Step: 10
Training loss: 1.0490824641423786
Validation loss: 2.329880199720243

Epoch: 6| Step: 11
Training loss: 1.1485260390841052
Validation loss: 2.3365401595168116

Epoch: 6| Step: 12
Training loss: 1.462853221135013
Validation loss: 2.3694320894524066

Epoch: 6| Step: 13
Training loss: 1.2983394764831184
Validation loss: 2.3850749716336153

Epoch: 200| Step: 0
Training loss: 1.0947653281216145
Validation loss: 2.397812127178557

Epoch: 6| Step: 1
Training loss: 1.0118477639673267
Validation loss: 2.3844559361171163

Epoch: 6| Step: 2
Training loss: 1.0434933603877017
Validation loss: 2.397126818013955

Epoch: 6| Step: 3
Training loss: 0.9953344106133932
Validation loss: 2.370373412546404

Epoch: 6| Step: 4
Training loss: 1.2269757783359738
Validation loss: 2.370216980722975

Epoch: 6| Step: 5
Training loss: 1.001181857758463
Validation loss: 2.353284154405589

Epoch: 6| Step: 6
Training loss: 1.6017625637237483
Validation loss: 2.346859758595568

Epoch: 6| Step: 7
Training loss: 0.8701338332924833
Validation loss: 2.3896035088344347

Epoch: 6| Step: 8
Training loss: 1.2265698378033647
Validation loss: 2.3739832508158303

Epoch: 6| Step: 9
Training loss: 0.6832063939848961
Validation loss: 2.3918956489906082

Epoch: 6| Step: 10
Training loss: 0.7125991016199197
Validation loss: 2.3800683982867152

Epoch: 6| Step: 11
Training loss: 1.0456733069516577
Validation loss: 2.4116564277529484

Epoch: 6| Step: 12
Training loss: 1.2283351747472273
Validation loss: 2.4070212709326713

Epoch: 6| Step: 13
Training loss: 0.9725816690431088
Validation loss: 2.4101577178811797

Epoch: 201| Step: 0
Training loss: 0.7966730946583438
Validation loss: 2.41501420660623

Epoch: 6| Step: 1
Training loss: 0.8101353715286562
Validation loss: 2.3745774344925294

Epoch: 6| Step: 2
Training loss: 0.9420968842463288
Validation loss: 2.3296778339123754

Epoch: 6| Step: 3
Training loss: 0.9569030675876564
Validation loss: 2.3418042534839523

Epoch: 6| Step: 4
Training loss: 1.2719729842699914
Validation loss: 2.3067772186055855

Epoch: 6| Step: 5
Training loss: 1.328517093001477
Validation loss: 2.2697599409913587

Epoch: 6| Step: 6
Training loss: 1.1876034440610908
Validation loss: 2.317780766744246

Epoch: 6| Step: 7
Training loss: 0.9206731688619499
Validation loss: 2.326054656421382

Epoch: 6| Step: 8
Training loss: 1.2342419612994397
Validation loss: 2.3147408111346537

Epoch: 6| Step: 9
Training loss: 1.085636783375587
Validation loss: 2.347961461633433

Epoch: 6| Step: 10
Training loss: 1.018813600485626
Validation loss: 2.3759008025903428

Epoch: 6| Step: 11
Training loss: 0.9133147743409273
Validation loss: 2.36783990892624

Epoch: 6| Step: 12
Training loss: 1.0741653151660246
Validation loss: 2.354696462658412

Epoch: 6| Step: 13
Training loss: 1.005334809932923
Validation loss: 2.3336285739077285

Epoch: 202| Step: 0
Training loss: 1.2888087629801734
Validation loss: 2.2939930701679456

Epoch: 6| Step: 1
Training loss: 0.9309241780957025
Validation loss: 2.2970602800551307

Epoch: 6| Step: 2
Training loss: 1.176043965844519
Validation loss: 2.2765172631040334

Epoch: 6| Step: 3
Training loss: 0.826023205666703
Validation loss: 2.2858944446859053

Epoch: 6| Step: 4
Training loss: 0.880771065829553
Validation loss: 2.2838281494421793

Epoch: 6| Step: 5
Training loss: 1.347115493864054
Validation loss: 2.308885966896785

Epoch: 6| Step: 6
Training loss: 0.8192510731410383
Validation loss: 2.309653288518751

Epoch: 6| Step: 7
Training loss: 1.1100860251350222
Validation loss: 2.334661252210594

Epoch: 6| Step: 8
Training loss: 0.8421810539154616
Validation loss: 2.338929405894549

Epoch: 6| Step: 9
Training loss: 0.7742365553085503
Validation loss: 2.3467032352372326

Epoch: 6| Step: 10
Training loss: 0.9207576510598043
Validation loss: 2.341023790318328

Epoch: 6| Step: 11
Training loss: 1.330702266931355
Validation loss: 2.3443925782001203

Epoch: 6| Step: 12
Training loss: 1.1528707559973383
Validation loss: 2.3307059132817334

Epoch: 6| Step: 13
Training loss: 0.4792406933726074
Validation loss: 2.3398654321876666

Epoch: 203| Step: 0
Training loss: 0.9113046498387957
Validation loss: 2.3210786971618265

Epoch: 6| Step: 1
Training loss: 1.3968935493756687
Validation loss: 2.319349063302912

Epoch: 6| Step: 2
Training loss: 1.1795628968173837
Validation loss: 2.331007603365967

Epoch: 6| Step: 3
Training loss: 1.3471915950549205
Validation loss: 2.3398042713473504

Epoch: 6| Step: 4
Training loss: 1.0554228303239621
Validation loss: 2.338669779687911

Epoch: 6| Step: 5
Training loss: 0.9683605764980949
Validation loss: 2.34631180959183

Epoch: 6| Step: 6
Training loss: 0.7972140619330691
Validation loss: 2.37750753055752

Epoch: 6| Step: 7
Training loss: 0.8311145729515862
Validation loss: 2.3908580902585745

Epoch: 6| Step: 8
Training loss: 0.9064392023881346
Validation loss: 2.3750864136264753

Epoch: 6| Step: 9
Training loss: 1.1238453555783396
Validation loss: 2.4125946081628937

Epoch: 6| Step: 10
Training loss: 0.6927275236717417
Validation loss: 2.4193712824259235

Epoch: 6| Step: 11
Training loss: 1.150179521397534
Validation loss: 2.415901722493121

Epoch: 6| Step: 12
Training loss: 0.9079094524776771
Validation loss: 2.4170905948251833

Epoch: 6| Step: 13
Training loss: 0.6213443178695082
Validation loss: 2.3628982397651446

Epoch: 204| Step: 0
Training loss: 1.1567974856399446
Validation loss: 2.321501799592188

Epoch: 6| Step: 1
Training loss: 0.983555649556514
Validation loss: 2.300152953484949

Epoch: 6| Step: 2
Training loss: 0.9636085727591384
Validation loss: 2.319003056677351

Epoch: 6| Step: 3
Training loss: 1.152855090468503
Validation loss: 2.305652687855784

Epoch: 6| Step: 4
Training loss: 1.0060204238107642
Validation loss: 2.2717947748303153

Epoch: 6| Step: 5
Training loss: 0.5500109270484227
Validation loss: 2.291276518946836

Epoch: 6| Step: 6
Training loss: 0.7584632360542347
Validation loss: 2.2926702239201386

Epoch: 6| Step: 7
Training loss: 0.7421038931887015
Validation loss: 2.3014996839782698

Epoch: 6| Step: 8
Training loss: 0.9915741353715339
Validation loss: 2.3407429081907156

Epoch: 6| Step: 9
Training loss: 1.1356647232153987
Validation loss: 2.3304777005032653

Epoch: 6| Step: 10
Training loss: 0.7631404813278699
Validation loss: 2.342333150856236

Epoch: 6| Step: 11
Training loss: 1.1622595425560915
Validation loss: 2.3524625254569376

Epoch: 6| Step: 12
Training loss: 1.483253697961505
Validation loss: 2.3736911917341508

Epoch: 6| Step: 13
Training loss: 1.0047406243358814
Validation loss: 2.357612208309369

Epoch: 205| Step: 0
Training loss: 1.1292360345476433
Validation loss: 2.3250855021390993

Epoch: 6| Step: 1
Training loss: 0.9357911748609798
Validation loss: 2.3111084662179877

Epoch: 6| Step: 2
Training loss: 1.2120759596108055
Validation loss: 2.310318642760698

Epoch: 6| Step: 3
Training loss: 1.0463275901618183
Validation loss: 2.314093755906034

Epoch: 6| Step: 4
Training loss: 0.8844663943456221
Validation loss: 2.3324185136745985

Epoch: 6| Step: 5
Training loss: 0.8955090105720585
Validation loss: 2.3449193628313787

Epoch: 6| Step: 6
Training loss: 1.2993773252935186
Validation loss: 2.369586328163106

Epoch: 6| Step: 7
Training loss: 0.9195171526895357
Validation loss: 2.3598202053967374

Epoch: 6| Step: 8
Training loss: 1.012503654567575
Validation loss: 2.3609660010129816

Epoch: 6| Step: 9
Training loss: 1.055672644651748
Validation loss: 2.33350617087977

Epoch: 6| Step: 10
Training loss: 0.7898015253418881
Validation loss: 2.3431985776580806

Epoch: 6| Step: 11
Training loss: 1.3570693182560727
Validation loss: 2.3366860062193813

Epoch: 6| Step: 12
Training loss: 0.559190178285416
Validation loss: 2.332426423029899

Epoch: 6| Step: 13
Training loss: 0.41025160634704433
Validation loss: 2.3405820661049845

Epoch: 206| Step: 0
Training loss: 0.5347429336180833
Validation loss: 2.3510207045136005

Epoch: 6| Step: 1
Training loss: 0.9467422455237651
Validation loss: 2.3462134515479693

Epoch: 6| Step: 2
Training loss: 1.133002745339686
Validation loss: 2.3342036244460114

Epoch: 6| Step: 3
Training loss: 1.1746757607813418
Validation loss: 2.3252641876855566

Epoch: 6| Step: 4
Training loss: 1.0066608087946072
Validation loss: 2.293542328900911

Epoch: 6| Step: 5
Training loss: 1.2975016539164386
Validation loss: 2.272142580580913

Epoch: 6| Step: 6
Training loss: 0.6448850181024742
Validation loss: 2.3078571840326685

Epoch: 6| Step: 7
Training loss: 0.7625536524548039
Validation loss: 2.2900859668872373

Epoch: 6| Step: 8
Training loss: 1.2540008889488707
Validation loss: 2.314298068743512

Epoch: 6| Step: 9
Training loss: 1.067274529635169
Validation loss: 2.3860853635077737

Epoch: 6| Step: 10
Training loss: 1.1185240853094847
Validation loss: 2.4223384788150564

Epoch: 6| Step: 11
Training loss: 0.8153599874894285
Validation loss: 2.4598104406329075

Epoch: 6| Step: 12
Training loss: 0.8685232991885525
Validation loss: 2.483174355932205

Epoch: 6| Step: 13
Training loss: 0.9887569323078491
Validation loss: 2.4636447321866024

Epoch: 207| Step: 0
Training loss: 0.6217679377270229
Validation loss: 2.4695496988370236

Epoch: 6| Step: 1
Training loss: 1.0438692584404625
Validation loss: 2.4042857388025185

Epoch: 6| Step: 2
Training loss: 0.8989088066193355
Validation loss: 2.37876132036175

Epoch: 6| Step: 3
Training loss: 0.9511921153960121
Validation loss: 2.335393581320375

Epoch: 6| Step: 4
Training loss: 1.1226485897856755
Validation loss: 2.302751849334502

Epoch: 6| Step: 5
Training loss: 1.3480050782693807
Validation loss: 2.2888904072721687

Epoch: 6| Step: 6
Training loss: 0.8755626232030856
Validation loss: 2.291969729731978

Epoch: 6| Step: 7
Training loss: 0.9792051037217505
Validation loss: 2.3065144634439294

Epoch: 6| Step: 8
Training loss: 1.0902018078512075
Validation loss: 2.333025698517546

Epoch: 6| Step: 9
Training loss: 0.8725982127617022
Validation loss: 2.3541217614182677

Epoch: 6| Step: 10
Training loss: 1.0179247714165163
Validation loss: 2.4041609638008774

Epoch: 6| Step: 11
Training loss: 0.862423224418297
Validation loss: 2.4197785067048914

Epoch: 6| Step: 12
Training loss: 0.7552602991224562
Validation loss: 2.388159115314941

Epoch: 6| Step: 13
Training loss: 1.1619012726454787
Validation loss: 2.3885986814898765

Epoch: 208| Step: 0
Training loss: 1.033564657550107
Validation loss: 2.3739122037934086

Epoch: 6| Step: 1
Training loss: 0.9429237513009825
Validation loss: 2.3258118233063936

Epoch: 6| Step: 2
Training loss: 1.1330774457813675
Validation loss: 2.3331714935108057

Epoch: 6| Step: 3
Training loss: 0.9083423138679068
Validation loss: 2.375601309715845

Epoch: 6| Step: 4
Training loss: 0.886451512873433
Validation loss: 2.3586188076129386

Epoch: 6| Step: 5
Training loss: 0.7297685092174372
Validation loss: 2.361557391571069

Epoch: 6| Step: 6
Training loss: 1.0054315045860278
Validation loss: 2.391645559117941

Epoch: 6| Step: 7
Training loss: 0.9669020470335862
Validation loss: 2.4125480718901096

Epoch: 6| Step: 8
Training loss: 0.9301651440910815
Validation loss: 2.4093869338446217

Epoch: 6| Step: 9
Training loss: 1.0171969060272492
Validation loss: 2.3569832386512006

Epoch: 6| Step: 10
Training loss: 1.1459543799995002
Validation loss: 2.3729922676361297

Epoch: 6| Step: 11
Training loss: 0.8362745514645571
Validation loss: 2.356441455795394

Epoch: 6| Step: 12
Training loss: 0.9929268552764595
Validation loss: 2.292587083318014

Epoch: 6| Step: 13
Training loss: 0.5674940515618154
Validation loss: 2.3227452404753164

Epoch: 209| Step: 0
Training loss: 0.930664254635834
Validation loss: 2.3354156434714977

Epoch: 6| Step: 1
Training loss: 0.5773973009105872
Validation loss: 2.31112726603003

Epoch: 6| Step: 2
Training loss: 1.298977537811102
Validation loss: 2.3253959963353785

Epoch: 6| Step: 3
Training loss: 0.9827327653474587
Validation loss: 2.306224497223268

Epoch: 6| Step: 4
Training loss: 0.7143255554736427
Validation loss: 2.3081025447985866

Epoch: 6| Step: 5
Training loss: 0.7270729158924942
Validation loss: 2.32195963256695

Epoch: 6| Step: 6
Training loss: 0.8052870359528599
Validation loss: 2.3485578979608723

Epoch: 6| Step: 7
Training loss: 0.9847116651508663
Validation loss: 2.3441699575365496

Epoch: 6| Step: 8
Training loss: 1.3206272991429404
Validation loss: 2.3503757150716855

Epoch: 6| Step: 9
Training loss: 1.375128566626702
Validation loss: 2.357661913949326

Epoch: 6| Step: 10
Training loss: 0.8894395132786558
Validation loss: 2.3700864402771264

Epoch: 6| Step: 11
Training loss: 0.895966357327567
Validation loss: 2.3513940013482837

Epoch: 6| Step: 12
Training loss: 0.6112684519348357
Validation loss: 2.349213495554913

Epoch: 6| Step: 13
Training loss: 0.8703284558352263
Validation loss: 2.32335030405713

Epoch: 210| Step: 0
Training loss: 0.9215658930434368
Validation loss: 2.309590275900686

Epoch: 6| Step: 1
Training loss: 0.8167096172119167
Validation loss: 2.3013173747599396

Epoch: 6| Step: 2
Training loss: 0.7625896072891075
Validation loss: 2.307326927648025

Epoch: 6| Step: 3
Training loss: 0.8262904738123495
Validation loss: 2.325759639154106

Epoch: 6| Step: 4
Training loss: 0.6152735621975512
Validation loss: 2.3256433009576636

Epoch: 6| Step: 5
Training loss: 0.8098618151684698
Validation loss: 2.3425404906795637

Epoch: 6| Step: 6
Training loss: 1.0044963601456087
Validation loss: 2.3481338323967966

Epoch: 6| Step: 7
Training loss: 1.1326255380974226
Validation loss: 2.355420710132732

Epoch: 6| Step: 8
Training loss: 1.2575663450117942
Validation loss: 2.372043530015137

Epoch: 6| Step: 9
Training loss: 1.0472545789671797
Validation loss: 2.3826600288066224

Epoch: 6| Step: 10
Training loss: 1.004820173885927
Validation loss: 2.3978037973521054

Epoch: 6| Step: 11
Training loss: 0.6344387210356561
Validation loss: 2.382842121178867

Epoch: 6| Step: 12
Training loss: 1.2028920332039499
Validation loss: 2.3809217816831563

Epoch: 6| Step: 13
Training loss: 0.8780190291895139
Validation loss: 2.301305458674716

Epoch: 211| Step: 0
Training loss: 0.9843203817080215
Validation loss: 2.325969620266011

Epoch: 6| Step: 1
Training loss: 0.8717510326675849
Validation loss: 2.2812464547280746

Epoch: 6| Step: 2
Training loss: 0.7275538910244296
Validation loss: 2.282884954475532

Epoch: 6| Step: 3
Training loss: 0.5554181511819303
Validation loss: 2.298436205529468

Epoch: 6| Step: 4
Training loss: 0.9190418545383116
Validation loss: 2.3075497386935964

Epoch: 6| Step: 5
Training loss: 1.0037452776502065
Validation loss: 2.3265383149630465

Epoch: 6| Step: 6
Training loss: 1.3387305080729426
Validation loss: 2.319593469316766

Epoch: 6| Step: 7
Training loss: 0.6852366731914149
Validation loss: 2.357738398553886

Epoch: 6| Step: 8
Training loss: 0.940611666207842
Validation loss: 2.3852476912842686

Epoch: 6| Step: 9
Training loss: 0.9767400656439758
Validation loss: 2.409281293299319

Epoch: 6| Step: 10
Training loss: 0.4540942447852086
Validation loss: 2.3547367890603645

Epoch: 6| Step: 11
Training loss: 1.0428388421810024
Validation loss: 2.3138381713562093

Epoch: 6| Step: 12
Training loss: 1.0533109370599
Validation loss: 2.306417736689161

Epoch: 6| Step: 13
Training loss: 1.3138888141093503
Validation loss: 2.277038476083681

Epoch: 212| Step: 0
Training loss: 1.1230875820577624
Validation loss: 2.188973479323565

Epoch: 6| Step: 1
Training loss: 0.8373874674106826
Validation loss: 2.210952423055776

Epoch: 6| Step: 2
Training loss: 0.9447301221413356
Validation loss: 2.18375815728488

Epoch: 6| Step: 3
Training loss: 0.7034428831595232
Validation loss: 2.2376916125154445

Epoch: 6| Step: 4
Training loss: 0.9329157645928362
Validation loss: 2.268115871336033

Epoch: 6| Step: 5
Training loss: 1.1243797287727566
Validation loss: 2.3696416836920773

Epoch: 6| Step: 6
Training loss: 1.049679089507115
Validation loss: 2.377452670345329

Epoch: 6| Step: 7
Training loss: 0.7736627655278828
Validation loss: 2.463491457041779

Epoch: 6| Step: 8
Training loss: 1.2478423092723374
Validation loss: 2.39821169499305

Epoch: 6| Step: 9
Training loss: 0.8261495456428574
Validation loss: 2.376043046404394

Epoch: 6| Step: 10
Training loss: 0.8976917654901695
Validation loss: 2.327102382586094

Epoch: 6| Step: 11
Training loss: 0.7113707762683134
Validation loss: 2.2861455076920256

Epoch: 6| Step: 12
Training loss: 1.0509609933723272
Validation loss: 2.266025271080357

Epoch: 6| Step: 13
Training loss: 0.9509215289832832
Validation loss: 2.245029492158368

Epoch: 213| Step: 0
Training loss: 0.9143841169506413
Validation loss: 2.2320251534363735

Epoch: 6| Step: 1
Training loss: 0.8736540797114147
Validation loss: 2.226110251034263

Epoch: 6| Step: 2
Training loss: 1.0742297917578822
Validation loss: 2.221121758279243

Epoch: 6| Step: 3
Training loss: 0.8172528928190316
Validation loss: 2.2377913356806722

Epoch: 6| Step: 4
Training loss: 0.7692306628593958
Validation loss: 2.2637538981229013

Epoch: 6| Step: 5
Training loss: 1.134625477105604
Validation loss: 2.29658658843534

Epoch: 6| Step: 6
Training loss: 0.9630020727073887
Validation loss: 2.334357644043076

Epoch: 6| Step: 7
Training loss: 0.9408486008623108
Validation loss: 2.3780426764670093

Epoch: 6| Step: 8
Training loss: 0.8934860119720007
Validation loss: 2.429282228046421

Epoch: 6| Step: 9
Training loss: 0.445446596534736
Validation loss: 2.382398463198474

Epoch: 6| Step: 10
Training loss: 1.0692247864250246
Validation loss: 2.3791856437167493

Epoch: 6| Step: 11
Training loss: 0.8955501101289892
Validation loss: 2.3130440547297555

Epoch: 6| Step: 12
Training loss: 1.180745742786946
Validation loss: 2.324744204015554

Epoch: 6| Step: 13
Training loss: 0.7283726365231266
Validation loss: 2.3294210427977675

Epoch: 214| Step: 0
Training loss: 0.9753816102344232
Validation loss: 2.348536285107996

Epoch: 6| Step: 1
Training loss: 0.8337553545137926
Validation loss: 2.3385781359003697

Epoch: 6| Step: 2
Training loss: 1.0565307334405118
Validation loss: 2.3116013793872376

Epoch: 6| Step: 3
Training loss: 0.7616311047332991
Validation loss: 2.3388526005084214

Epoch: 6| Step: 4
Training loss: 0.9914392969321636
Validation loss: 2.340232295196464

Epoch: 6| Step: 5
Training loss: 0.9807602042650173
Validation loss: 2.3697369181193233

Epoch: 6| Step: 6
Training loss: 0.6414463314120087
Validation loss: 2.379167694177203

Epoch: 6| Step: 7
Training loss: 0.6816121617361606
Validation loss: 2.390436297877974

Epoch: 6| Step: 8
Training loss: 0.9247732348466147
Validation loss: 2.4065745038601465

Epoch: 6| Step: 9
Training loss: 1.0731900925354214
Validation loss: 2.407361515782387

Epoch: 6| Step: 10
Training loss: 0.795017770892482
Validation loss: 2.3702417331444114

Epoch: 6| Step: 11
Training loss: 0.8778274018274546
Validation loss: 2.3806190345523643

Epoch: 6| Step: 12
Training loss: 0.8569282379417745
Validation loss: 2.3510074665676832

Epoch: 6| Step: 13
Training loss: 0.9884322582567799
Validation loss: 2.3558798152242324

Epoch: 215| Step: 0
Training loss: 0.8057008307187666
Validation loss: 2.3695430044137824

Epoch: 6| Step: 1
Training loss: 1.0227543538293922
Validation loss: 2.305363697474331

Epoch: 6| Step: 2
Training loss: 0.8447529518547765
Validation loss: 2.291886395932849

Epoch: 6| Step: 3
Training loss: 0.9977207136126189
Validation loss: 2.3191421710054527

Epoch: 6| Step: 4
Training loss: 0.9825914968348238
Validation loss: 2.304686075345352

Epoch: 6| Step: 5
Training loss: 0.8167126824266884
Validation loss: 2.3086933843028663

Epoch: 6| Step: 6
Training loss: 1.0206164434556695
Validation loss: 2.298281021275377

Epoch: 6| Step: 7
Training loss: 0.7319123390374132
Validation loss: 2.295548079807333

Epoch: 6| Step: 8
Training loss: 0.954903116554562
Validation loss: 2.323999475255867

Epoch: 6| Step: 9
Training loss: 0.7721511856364445
Validation loss: 2.2836810868523254

Epoch: 6| Step: 10
Training loss: 0.6367717557035414
Validation loss: 2.276005824318318

Epoch: 6| Step: 11
Training loss: 0.8325397925274579
Validation loss: 2.3237114026926813

Epoch: 6| Step: 12
Training loss: 0.8581974631857644
Validation loss: 2.307437357039727

Epoch: 6| Step: 13
Training loss: 0.724134181413041
Validation loss: 2.3004729670986213

Epoch: 216| Step: 0
Training loss: 1.2980471450020172
Validation loss: 2.3125056017558667

Epoch: 6| Step: 1
Training loss: 0.8311823781552204
Validation loss: 2.340029843564895

Epoch: 6| Step: 2
Training loss: 0.7632222132268216
Validation loss: 2.3165894976293226

Epoch: 6| Step: 3
Training loss: 0.7880450950731794
Validation loss: 2.298118576666465

Epoch: 6| Step: 4
Training loss: 1.150806190028828
Validation loss: 2.2873732463295693

Epoch: 6| Step: 5
Training loss: 0.6834980924980152
Validation loss: 2.301590830387521

Epoch: 6| Step: 6
Training loss: 0.8899414383984412
Validation loss: 2.3133280279641224

Epoch: 6| Step: 7
Training loss: 1.0208565002200078
Validation loss: 2.2945249353762462

Epoch: 6| Step: 8
Training loss: 0.9156695202103812
Validation loss: 2.3066595462487283

Epoch: 6| Step: 9
Training loss: 0.4334648387458289
Validation loss: 2.340827409313902

Epoch: 6| Step: 10
Training loss: 0.6007636574896482
Validation loss: 2.3116195763178844

Epoch: 6| Step: 11
Training loss: 0.5184052965165878
Validation loss: 2.33373910002422

Epoch: 6| Step: 12
Training loss: 0.5824644281716237
Validation loss: 2.315819700809426

Epoch: 6| Step: 13
Training loss: 1.0923434341292702
Validation loss: 2.325388461605665

Epoch: 217| Step: 0
Training loss: 1.0433075315333964
Validation loss: 2.34091258747246

Epoch: 6| Step: 1
Training loss: 0.9401803800311642
Validation loss: 2.324486402454873

Epoch: 6| Step: 2
Training loss: 0.5428815538387143
Validation loss: 2.2852496625628578

Epoch: 6| Step: 3
Training loss: 0.910559438048454
Validation loss: 2.2885857303656234

Epoch: 6| Step: 4
Training loss: 0.5597217082054653
Validation loss: 2.299571596439532

Epoch: 6| Step: 5
Training loss: 0.5406976860444167
Validation loss: 2.271069429634235

Epoch: 6| Step: 6
Training loss: 0.9554044326007816
Validation loss: 2.2765912032024835

Epoch: 6| Step: 7
Training loss: 0.9801892189867489
Validation loss: 2.3072942636852516

Epoch: 6| Step: 8
Training loss: 0.9019912757916836
Validation loss: 2.312445432888863

Epoch: 6| Step: 9
Training loss: 0.7398895426740595
Validation loss: 2.312199244609601

Epoch: 6| Step: 10
Training loss: 1.0175608452265144
Validation loss: 2.2878421614738573

Epoch: 6| Step: 11
Training loss: 0.6503364150907754
Validation loss: 2.267285256837906

Epoch: 6| Step: 12
Training loss: 0.8690524281532319
Validation loss: 2.254070130505765

Epoch: 6| Step: 13
Training loss: 1.038510512965936
Validation loss: 2.2372562330885675

Epoch: 218| Step: 0
Training loss: 0.8887064162028618
Validation loss: 2.222703420054633

Epoch: 6| Step: 1
Training loss: 0.7932540305221886
Validation loss: 2.2507940062666316

Epoch: 6| Step: 2
Training loss: 0.551970638313167
Validation loss: 2.256173431194406

Epoch: 6| Step: 3
Training loss: 1.1595255360721495
Validation loss: 2.2788397766176463

Epoch: 6| Step: 4
Training loss: 0.7746788620861538
Validation loss: 2.283321614351762

Epoch: 6| Step: 5
Training loss: 0.4828263104880181
Validation loss: 2.2890815088701544

Epoch: 6| Step: 6
Training loss: 0.8107348855980276
Validation loss: 2.2785901655906544

Epoch: 6| Step: 7
Training loss: 0.522660718137519
Validation loss: 2.303655958547894

Epoch: 6| Step: 8
Training loss: 0.8253813584651979
Validation loss: 2.3280368129459834

Epoch: 6| Step: 9
Training loss: 1.047214851443398
Validation loss: 2.3190847257134344

Epoch: 6| Step: 10
Training loss: 0.612309262686007
Validation loss: 2.3104630350880986

Epoch: 6| Step: 11
Training loss: 1.0165621028867708
Validation loss: 2.3027959231229564

Epoch: 6| Step: 12
Training loss: 0.8877709821253432
Validation loss: 2.2846242707021553

Epoch: 6| Step: 13
Training loss: 1.0178256328743922
Validation loss: 2.327552795566524

Epoch: 219| Step: 0
Training loss: 0.5993458917608271
Validation loss: 2.3501182118856008

Epoch: 6| Step: 1
Training loss: 1.1308661215256441
Validation loss: 2.299913829475091

Epoch: 6| Step: 2
Training loss: 1.0739440566753402
Validation loss: 2.310033844015053

Epoch: 6| Step: 3
Training loss: 0.4585020574764817
Validation loss: 2.2935338143125623

Epoch: 6| Step: 4
Training loss: 0.6058054326317285
Validation loss: 2.260929388814988

Epoch: 6| Step: 5
Training loss: 0.9188088326852915
Validation loss: 2.3166256248584602

Epoch: 6| Step: 6
Training loss: 1.0257287621415796
Validation loss: 2.314895895322996

Epoch: 6| Step: 7
Training loss: 0.34606463178501984
Validation loss: 2.3459799797330483

Epoch: 6| Step: 8
Training loss: 1.215711964141873
Validation loss: 2.3672772586840254

Epoch: 6| Step: 9
Training loss: 0.831840672404492
Validation loss: 2.374000715271681

Epoch: 6| Step: 10
Training loss: 0.634668172544842
Validation loss: 2.375646585747342

Epoch: 6| Step: 11
Training loss: 0.793161753951947
Validation loss: 2.356450044977986

Epoch: 6| Step: 12
Training loss: 0.8949203311369028
Validation loss: 2.3369347949823065

Epoch: 6| Step: 13
Training loss: 0.11386602836267544
Validation loss: 2.3045378438789967

Epoch: 220| Step: 0
Training loss: 0.695537573572133
Validation loss: 2.2714286905086394

Epoch: 6| Step: 1
Training loss: 0.6885505365982497
Validation loss: 2.248839628901851

Epoch: 6| Step: 2
Training loss: 0.6733543388903337
Validation loss: 2.259930806015013

Epoch: 6| Step: 3
Training loss: 0.6530918697003564
Validation loss: 2.2549706010025528

Epoch: 6| Step: 4
Training loss: 1.028419598516626
Validation loss: 2.2684681502315382

Epoch: 6| Step: 5
Training loss: 0.8523288043675983
Validation loss: 2.2787509613865797

Epoch: 6| Step: 6
Training loss: 0.8948560566469712
Validation loss: 2.3249265165842226

Epoch: 6| Step: 7
Training loss: 0.9476367970456773
Validation loss: 2.339747884208347

Epoch: 6| Step: 8
Training loss: 0.9806569135443685
Validation loss: 2.359179154990075

Epoch: 6| Step: 9
Training loss: 0.7711111976945347
Validation loss: 2.3362201548884074

Epoch: 6| Step: 10
Training loss: 0.7882155981786891
Validation loss: 2.347061554467043

Epoch: 6| Step: 11
Training loss: 0.472189175939205
Validation loss: 2.3231700720554582

Epoch: 6| Step: 12
Training loss: 1.0399883992208356
Validation loss: 2.328794288604476

Epoch: 6| Step: 13
Training loss: 0.7109240436328462
Validation loss: 2.3016650342745777

Epoch: 221| Step: 0
Training loss: 0.8069009430110506
Validation loss: 2.295025384715962

Epoch: 6| Step: 1
Training loss: 0.7195280259315916
Validation loss: 2.296032643198425

Epoch: 6| Step: 2
Training loss: 0.9039977137021886
Validation loss: 2.2761593403851714

Epoch: 6| Step: 3
Training loss: 0.8508166625444312
Validation loss: 2.279235592137135

Epoch: 6| Step: 4
Training loss: 0.7411015245101005
Validation loss: 2.271252841664937

Epoch: 6| Step: 5
Training loss: 0.7197299579348757
Validation loss: 2.2726203541762513

Epoch: 6| Step: 6
Training loss: 1.028940968083435
Validation loss: 2.2907247746254202

Epoch: 6| Step: 7
Training loss: 0.5190727677498136
Validation loss: 2.303798441067558

Epoch: 6| Step: 8
Training loss: 0.4828512774947206
Validation loss: 2.2857675541583142

Epoch: 6| Step: 9
Training loss: 0.6967423556551442
Validation loss: 2.293923429848912

Epoch: 6| Step: 10
Training loss: 0.9682648274443446
Validation loss: 2.289786729091364

Epoch: 6| Step: 11
Training loss: 0.9658631102179548
Validation loss: 2.2813539687808797

Epoch: 6| Step: 12
Training loss: 0.9402393057249744
Validation loss: 2.27346494569525

Epoch: 6| Step: 13
Training loss: 0.6654947431028544
Validation loss: 2.283451042826891

Epoch: 222| Step: 0
Training loss: 0.8625808912850796
Validation loss: 2.296565274028257

Epoch: 6| Step: 1
Training loss: 0.9084291566531885
Validation loss: 2.2838149266905927

Epoch: 6| Step: 2
Training loss: 0.6179564309610356
Validation loss: 2.274685609719561

Epoch: 6| Step: 3
Training loss: 0.845055982270183
Validation loss: 2.3140451240833015

Epoch: 6| Step: 4
Training loss: 0.5729631983038398
Validation loss: 2.305012816558847

Epoch: 6| Step: 5
Training loss: 0.9968084725689584
Validation loss: 2.3262372828635622

Epoch: 6| Step: 6
Training loss: 1.1013173581327886
Validation loss: 2.2829446402333775

Epoch: 6| Step: 7
Training loss: 0.8173583105646636
Validation loss: 2.278895285644893

Epoch: 6| Step: 8
Training loss: 0.6050176847647493
Validation loss: 2.2949405013292674

Epoch: 6| Step: 9
Training loss: 0.6626023564351188
Validation loss: 2.2834534880758626

Epoch: 6| Step: 10
Training loss: 0.7459754650361381
Validation loss: 2.275667455223746

Epoch: 6| Step: 11
Training loss: 0.4483333652820127
Validation loss: 2.258393922560678

Epoch: 6| Step: 12
Training loss: 0.6555538572363039
Validation loss: 2.281737709926182

Epoch: 6| Step: 13
Training loss: 1.140180056808158
Validation loss: 2.2936971251449036

Epoch: 223| Step: 0
Training loss: 0.6479287507217212
Validation loss: 2.279894794438779

Epoch: 6| Step: 1
Training loss: 0.8800702334683848
Validation loss: 2.3108775936527532

Epoch: 6| Step: 2
Training loss: 0.7372066205218504
Validation loss: 2.3037381805513237

Epoch: 6| Step: 3
Training loss: 0.5761891507937047
Validation loss: 2.2747673979979512

Epoch: 6| Step: 4
Training loss: 0.5968468364841695
Validation loss: 2.2870040486371734

Epoch: 6| Step: 5
Training loss: 0.8048805819959312
Validation loss: 2.2500703406419422

Epoch: 6| Step: 6
Training loss: 0.8777346113176626
Validation loss: 2.2526289155676844

Epoch: 6| Step: 7
Training loss: 1.0380075017771921
Validation loss: 2.2469362891697537

Epoch: 6| Step: 8
Training loss: 0.5236968067169441
Validation loss: 2.2652213942562014

Epoch: 6| Step: 9
Training loss: 0.6605322855957391
Validation loss: 2.281003924426143

Epoch: 6| Step: 10
Training loss: 0.7254798370046538
Validation loss: 2.2688413009006423

Epoch: 6| Step: 11
Training loss: 0.7860216903338759
Validation loss: 2.3043507108307137

Epoch: 6| Step: 12
Training loss: 1.174926041243694
Validation loss: 2.297043598352847

Epoch: 6| Step: 13
Training loss: 0.5580005830877942
Validation loss: 2.2557253175509433

Epoch: 224| Step: 0
Training loss: 1.0030393308380627
Validation loss: 2.2780894463636887

Epoch: 6| Step: 1
Training loss: 0.9737022321587903
Validation loss: 2.275302769183368

Epoch: 6| Step: 2
Training loss: 0.8004153648563134
Validation loss: 2.264694105227509

Epoch: 6| Step: 3
Training loss: 0.6546823988467664
Validation loss: 2.2741930250679827

Epoch: 6| Step: 4
Training loss: 0.9787034332286111
Validation loss: 2.283533137990968

Epoch: 6| Step: 5
Training loss: 0.7033121071982789
Validation loss: 2.2640261169896796

Epoch: 6| Step: 6
Training loss: 0.6183241987796109
Validation loss: 2.2760790021667

Epoch: 6| Step: 7
Training loss: 0.9158072488788234
Validation loss: 2.279116946036111

Epoch: 6| Step: 8
Training loss: 0.8223509755542865
Validation loss: 2.2751264287523254

Epoch: 6| Step: 9
Training loss: 0.2878341609081114
Validation loss: 2.3094356346793

Epoch: 6| Step: 10
Training loss: 0.6998734845204475
Validation loss: 2.3203996918367222

Epoch: 6| Step: 11
Training loss: 0.9240826826629656
Validation loss: 2.3195545782671263

Epoch: 6| Step: 12
Training loss: 0.5358562485742304
Validation loss: 2.342020656049146

Epoch: 6| Step: 13
Training loss: 0.34679164959020886
Validation loss: 2.3262751932349217

Epoch: 225| Step: 0
Training loss: 1.0315392984290475
Validation loss: 2.3359744924069807

Epoch: 6| Step: 1
Training loss: 0.61438064681259
Validation loss: 2.320764283229509

Epoch: 6| Step: 2
Training loss: 0.8238387113047448
Validation loss: 2.3045159878324393

Epoch: 6| Step: 3
Training loss: 0.390581815239851
Validation loss: 2.2851336902717496

Epoch: 6| Step: 4
Training loss: 0.9204236907368615
Validation loss: 2.3070472412448586

Epoch: 6| Step: 5
Training loss: 0.7636708603483908
Validation loss: 2.289932316986554

Epoch: 6| Step: 6
Training loss: 0.5161856868484344
Validation loss: 2.2981240216053145

Epoch: 6| Step: 7
Training loss: 0.7422888435640557
Validation loss: 2.2988981704188047

Epoch: 6| Step: 8
Training loss: 0.9883097768895742
Validation loss: 2.287765355473436

Epoch: 6| Step: 9
Training loss: 0.7195980210858585
Validation loss: 2.3335483103337884

Epoch: 6| Step: 10
Training loss: 0.7511437754500798
Validation loss: 2.3085311171279663

Epoch: 6| Step: 11
Training loss: 0.7994268360883563
Validation loss: 2.3646423341879084

Epoch: 6| Step: 12
Training loss: 0.7268073377006861
Validation loss: 2.305383358134909

Epoch: 6| Step: 13
Training loss: 0.7484231505481767
Validation loss: 2.2978986008343885

Epoch: 226| Step: 0
Training loss: 0.6938122197336095
Validation loss: 2.267267155239687

Epoch: 6| Step: 1
Training loss: 0.865930763529549
Validation loss: 2.2560784789511046

Epoch: 6| Step: 2
Training loss: 0.8034719526692866
Validation loss: 2.2378904942227313

Epoch: 6| Step: 3
Training loss: 0.6869778817959893
Validation loss: 2.236468861675078

Epoch: 6| Step: 4
Training loss: 0.7295608998815982
Validation loss: 2.253244455813682

Epoch: 6| Step: 5
Training loss: 0.8220220644535005
Validation loss: 2.2815269485281577

Epoch: 6| Step: 6
Training loss: 0.879989939274498
Validation loss: 2.306716432426969

Epoch: 6| Step: 7
Training loss: 0.7104748908055005
Validation loss: 2.3192117830734316

Epoch: 6| Step: 8
Training loss: 0.34800430619792816
Validation loss: 2.301753274975597

Epoch: 6| Step: 9
Training loss: 0.796368157259934
Validation loss: 2.3158953572146226

Epoch: 6| Step: 10
Training loss: 0.7443809221418075
Validation loss: 2.2948765406934153

Epoch: 6| Step: 11
Training loss: 0.9125086300585521
Validation loss: 2.2800611802578366

Epoch: 6| Step: 12
Training loss: 0.6448287508463115
Validation loss: 2.278423185707076

Epoch: 6| Step: 13
Training loss: 0.8966645036964375
Validation loss: 2.255509545942222

Epoch: 227| Step: 0
Training loss: 0.954522000216628
Validation loss: 2.2655018587349702

Epoch: 6| Step: 1
Training loss: 0.420038499827342
Validation loss: 2.2148796825637818

Epoch: 6| Step: 2
Training loss: 0.983293181073751
Validation loss: 2.24277852967547

Epoch: 6| Step: 3
Training loss: 0.4967889495327809
Validation loss: 2.216769397300217

Epoch: 6| Step: 4
Training loss: 0.6841672181287147
Validation loss: 2.264749658727843

Epoch: 6| Step: 5
Training loss: 0.5341240332586001
Validation loss: 2.272650012803416

Epoch: 6| Step: 6
Training loss: 0.803911149405776
Validation loss: 2.3119602499148235

Epoch: 6| Step: 7
Training loss: 0.9899350528413438
Validation loss: 2.3178122144709308

Epoch: 6| Step: 8
Training loss: 0.5803595479978252
Validation loss: 2.3208117828484993

Epoch: 6| Step: 9
Training loss: 0.48086993208203577
Validation loss: 2.328016520993722

Epoch: 6| Step: 10
Training loss: 0.5763045853188306
Validation loss: 2.3073090668575897

Epoch: 6| Step: 11
Training loss: 0.7248235422003626
Validation loss: 2.2863339514033956

Epoch: 6| Step: 12
Training loss: 0.9807887675927204
Validation loss: 2.2748833116249054

Epoch: 6| Step: 13
Training loss: 1.0518914353009754
Validation loss: 2.256661630290638

Epoch: 228| Step: 0
Training loss: 0.835874252065715
Validation loss: 2.2764867060883596

Epoch: 6| Step: 1
Training loss: 0.6314047944661719
Validation loss: 2.2801045682985075

Epoch: 6| Step: 2
Training loss: 0.6730621185613376
Validation loss: 2.281733337637006

Epoch: 6| Step: 3
Training loss: 0.5550886235059722
Validation loss: 2.295878070304379

Epoch: 6| Step: 4
Training loss: 0.5282684413527148
Validation loss: 2.3039866899437533

Epoch: 6| Step: 5
Training loss: 0.7559983473184474
Validation loss: 2.3241121414675154

Epoch: 6| Step: 6
Training loss: 0.7467803591855271
Validation loss: 2.3140858559008897

Epoch: 6| Step: 7
Training loss: 0.8020129523836683
Validation loss: 2.294005624634856

Epoch: 6| Step: 8
Training loss: 0.9534658854262332
Validation loss: 2.2476837240356913

Epoch: 6| Step: 9
Training loss: 0.8151741038453553
Validation loss: 2.2326455703669654

Epoch: 6| Step: 10
Training loss: 0.7190894693541727
Validation loss: 2.23362672476836

Epoch: 6| Step: 11
Training loss: 0.9684190800193069
Validation loss: 2.229468988046313

Epoch: 6| Step: 12
Training loss: 0.7025086562549886
Validation loss: 2.2767822674402645

Epoch: 6| Step: 13
Training loss: 0.581034299348519
Validation loss: 2.3127042962282736

Epoch: 229| Step: 0
Training loss: 0.3467462932378917
Validation loss: 2.3509019659799915

Epoch: 6| Step: 1
Training loss: 0.5839144049226338
Validation loss: 2.362654898455622

Epoch: 6| Step: 2
Training loss: 0.5251836262598327
Validation loss: 2.3925676339484307

Epoch: 6| Step: 3
Training loss: 0.8701386283176604
Validation loss: 2.3990152495607133

Epoch: 6| Step: 4
Training loss: 0.8976303455409821
Validation loss: 2.3357587600462972

Epoch: 6| Step: 5
Training loss: 1.0342546099070642
Validation loss: 2.299552945190824

Epoch: 6| Step: 6
Training loss: 0.5868518561531556
Validation loss: 2.27345991643368

Epoch: 6| Step: 7
Training loss: 0.8277600401877481
Validation loss: 2.244797949968575

Epoch: 6| Step: 8
Training loss: 0.938039878526198
Validation loss: 2.2259818868143837

Epoch: 6| Step: 9
Training loss: 0.5806672158718614
Validation loss: 2.2312123376440116

Epoch: 6| Step: 10
Training loss: 0.7060131097689468
Validation loss: 2.229309580786164

Epoch: 6| Step: 11
Training loss: 0.6418364630462462
Validation loss: 2.25605306999048

Epoch: 6| Step: 12
Training loss: 0.8543633064078128
Validation loss: 2.245122521186478

Epoch: 6| Step: 13
Training loss: 0.6315569962040397
Validation loss: 2.2490280517723433

Epoch: 230| Step: 0
Training loss: 0.9026753530516367
Validation loss: 2.3096058391305014

Epoch: 6| Step: 1
Training loss: 0.8076069657072105
Validation loss: 2.310923644098943

Epoch: 6| Step: 2
Training loss: 0.6771195891038945
Validation loss: 2.3370866941052637

Epoch: 6| Step: 3
Training loss: 0.4045147700247857
Validation loss: 2.3254220118843034

Epoch: 6| Step: 4
Training loss: 0.6356883692778114
Validation loss: 2.3136423111555797

Epoch: 6| Step: 5
Training loss: 0.5616674089379693
Validation loss: 2.342870847920199

Epoch: 6| Step: 6
Training loss: 0.8454999437360333
Validation loss: 2.3437673769070835

Epoch: 6| Step: 7
Training loss: 1.0447012124629382
Validation loss: 2.3169011398036705

Epoch: 6| Step: 8
Training loss: 0.7716656049497261
Validation loss: 2.3151357452439933

Epoch: 6| Step: 9
Training loss: 0.469514890312776
Validation loss: 2.27821410043003

Epoch: 6| Step: 10
Training loss: 0.6836599699371584
Validation loss: 2.27348125801731

Epoch: 6| Step: 11
Training loss: 0.7862169682731107
Validation loss: 2.2469881333128794

Epoch: 6| Step: 12
Training loss: 0.5337584122792193
Validation loss: 2.230598083761144

Epoch: 6| Step: 13
Training loss: 0.8408127982660024
Validation loss: 2.271494667418502

Epoch: 231| Step: 0
Training loss: 0.578417008344583
Validation loss: 2.257973729746211

Epoch: 6| Step: 1
Training loss: 0.7408678871767185
Validation loss: 2.2828752979256453

Epoch: 6| Step: 2
Training loss: 0.42819022357048314
Validation loss: 2.2798866022022546

Epoch: 6| Step: 3
Training loss: 0.3104052310582393
Validation loss: 2.294995869473683

Epoch: 6| Step: 4
Training loss: 0.6359292266457498
Validation loss: 2.294475660299048

Epoch: 6| Step: 5
Training loss: 0.6549304684285995
Validation loss: 2.3154370412249885

Epoch: 6| Step: 6
Training loss: 0.7892326322643807
Validation loss: 2.3032362150331234

Epoch: 6| Step: 7
Training loss: 0.761116611463932
Validation loss: 2.305065899140641

Epoch: 6| Step: 8
Training loss: 0.7381295345984311
Validation loss: 2.2816274490544965

Epoch: 6| Step: 9
Training loss: 0.7711280869217946
Validation loss: 2.289619645946133

Epoch: 6| Step: 10
Training loss: 0.5488431935261116
Validation loss: 2.2764326794881713

Epoch: 6| Step: 11
Training loss: 0.9141485059656158
Validation loss: 2.26972291644796

Epoch: 6| Step: 12
Training loss: 0.8754893705549553
Validation loss: 2.2770076271410833

Epoch: 6| Step: 13
Training loss: 1.161081529516295
Validation loss: 2.291505273373099

Epoch: 232| Step: 0
Training loss: 0.7110709599577351
Validation loss: 2.273174756017997

Epoch: 6| Step: 1
Training loss: 0.27074362877035735
Validation loss: 2.268975098074949

Epoch: 6| Step: 2
Training loss: 0.7643767321138882
Validation loss: 2.290514760704838

Epoch: 6| Step: 3
Training loss: 0.971387779056549
Validation loss: 2.301094467158997

Epoch: 6| Step: 4
Training loss: 0.616957561297756
Validation loss: 2.305203855529908

Epoch: 6| Step: 5
Training loss: 0.8784753378878608
Validation loss: 2.3210896146056412

Epoch: 6| Step: 6
Training loss: 0.8133006186107354
Validation loss: 2.290593129817825

Epoch: 6| Step: 7
Training loss: 0.8863550187961328
Validation loss: 2.2860433677661725

Epoch: 6| Step: 8
Training loss: 0.48811519087876404
Validation loss: 2.281493682590022

Epoch: 6| Step: 9
Training loss: 0.8356620833985499
Validation loss: 2.237674831925585

Epoch: 6| Step: 10
Training loss: 0.49484173036240864
Validation loss: 2.2538292748467725

Epoch: 6| Step: 11
Training loss: 0.814283540849486
Validation loss: 2.239071911289977

Epoch: 6| Step: 12
Training loss: 0.35728239245746324
Validation loss: 2.256900042488092

Epoch: 6| Step: 13
Training loss: 0.5907344535044404
Validation loss: 2.304241043599669

Epoch: 233| Step: 0
Training loss: 0.8232470022402392
Validation loss: 2.2848831242115835

Epoch: 6| Step: 1
Training loss: 0.6154534570479575
Validation loss: 2.3274732812968972

Epoch: 6| Step: 2
Training loss: 0.4899909642417957
Validation loss: 2.3321063167243112

Epoch: 6| Step: 3
Training loss: 0.5722031282533416
Validation loss: 2.329040009476863

Epoch: 6| Step: 4
Training loss: 0.9618594701156503
Validation loss: 2.336370372266283

Epoch: 6| Step: 5
Training loss: 0.5460829039275629
Validation loss: 2.3329398362509504

Epoch: 6| Step: 6
Training loss: 0.684782923008272
Validation loss: 2.2697446828413117

Epoch: 6| Step: 7
Training loss: 0.620657425693155
Validation loss: 2.232332665736633

Epoch: 6| Step: 8
Training loss: 0.7151036858238684
Validation loss: 2.2425317410344383

Epoch: 6| Step: 9
Training loss: 0.9353948800170131
Validation loss: 2.2385545623245537

Epoch: 6| Step: 10
Training loss: 0.6110462843101281
Validation loss: 2.209741844014726

Epoch: 6| Step: 11
Training loss: 0.5495627160455302
Validation loss: 2.2576269082089078

Epoch: 6| Step: 12
Training loss: 0.6275194883929808
Validation loss: 2.2594568908453496

Epoch: 6| Step: 13
Training loss: 0.8669115950733604
Validation loss: 2.308533301494773

Epoch: 234| Step: 0
Training loss: 0.3363234720118691
Validation loss: 2.328225387387706

Epoch: 6| Step: 1
Training loss: 0.7859811198148552
Validation loss: 2.3242824921760725

Epoch: 6| Step: 2
Training loss: 0.555035602785118
Validation loss: 2.327120546712888

Epoch: 6| Step: 3
Training loss: 0.7443115358499369
Validation loss: 2.3241355527452385

Epoch: 6| Step: 4
Training loss: 0.47030375779857087
Validation loss: 2.3235474946723915

Epoch: 6| Step: 5
Training loss: 0.42155108555864496
Validation loss: 2.3050944307456858

Epoch: 6| Step: 6
Training loss: 0.5831896116680245
Validation loss: 2.2933356829040026

Epoch: 6| Step: 7
Training loss: 0.653734175853425
Validation loss: 2.2653846678316736

Epoch: 6| Step: 8
Training loss: 0.5765103913617149
Validation loss: 2.2576241000003363

Epoch: 6| Step: 9
Training loss: 0.9343544960961833
Validation loss: 2.2745370227672463

Epoch: 6| Step: 10
Training loss: 0.5684825069064532
Validation loss: 2.2521709260006992

Epoch: 6| Step: 11
Training loss: 0.8215705670366613
Validation loss: 2.2897473608883656

Epoch: 6| Step: 12
Training loss: 0.935682569629791
Validation loss: 2.317251323584679

Epoch: 6| Step: 13
Training loss: 0.9883866988908451
Validation loss: 2.30070162669706

Epoch: 235| Step: 0
Training loss: 0.6561449965985257
Validation loss: 2.3077473868277636

Epoch: 6| Step: 1
Training loss: 0.7875828986964044
Validation loss: 2.275046547620072

Epoch: 6| Step: 2
Training loss: 0.8173386209772192
Validation loss: 2.2741915300192015

Epoch: 6| Step: 3
Training loss: 0.5116977541743963
Validation loss: 2.2991342589806156

Epoch: 6| Step: 4
Training loss: 0.4804239019536704
Validation loss: 2.294613382502138

Epoch: 6| Step: 5
Training loss: 0.8913173326950178
Validation loss: 2.321718891205467

Epoch: 6| Step: 6
Training loss: 0.4487833317780819
Validation loss: 2.3133013112146665

Epoch: 6| Step: 7
Training loss: 0.6646560260475137
Validation loss: 2.359038296004127

Epoch: 6| Step: 8
Training loss: 0.7238823464306883
Validation loss: 2.3207716302690167

Epoch: 6| Step: 9
Training loss: 0.8304415277593129
Validation loss: 2.334303981601633

Epoch: 6| Step: 10
Training loss: 0.4625843982757577
Validation loss: 2.290202953318845

Epoch: 6| Step: 11
Training loss: 0.7241463222726078
Validation loss: 2.312577633495526

Epoch: 6| Step: 12
Training loss: 0.6183918176310773
Validation loss: 2.3113152202467426

Epoch: 6| Step: 13
Training loss: 0.6647323147435804
Validation loss: 2.3075244826566306

Epoch: 236| Step: 0
Training loss: 0.7071571027330927
Validation loss: 2.317588870730657

Epoch: 6| Step: 1
Training loss: 0.7640113173740043
Validation loss: 2.3161607970673352

Epoch: 6| Step: 2
Training loss: 0.7585109362986265
Validation loss: 2.2579279136063852

Epoch: 6| Step: 3
Training loss: 0.6273116040574483
Validation loss: 2.2489167856684515

Epoch: 6| Step: 4
Training loss: 0.7350813532590245
Validation loss: 2.260596697481517

Epoch: 6| Step: 5
Training loss: 0.8710387002973053
Validation loss: 2.242842655823152

Epoch: 6| Step: 6
Training loss: 0.6661357603487165
Validation loss: 2.2699765958795144

Epoch: 6| Step: 7
Training loss: 0.5401093090650059
Validation loss: 2.2507365512641946

Epoch: 6| Step: 8
Training loss: 0.5800540803492039
Validation loss: 2.320506132312321

Epoch: 6| Step: 9
Training loss: 0.45938315416741377
Validation loss: 2.3013886533116015

Epoch: 6| Step: 10
Training loss: 0.38939790630776944
Validation loss: 2.3536840224140705

Epoch: 6| Step: 11
Training loss: 0.5961332425575312
Validation loss: 2.365812913168592

Epoch: 6| Step: 12
Training loss: 0.7281220628409023
Validation loss: 2.361974142807548

Epoch: 6| Step: 13
Training loss: 0.7501716417363626
Validation loss: 2.347081373743977

Epoch: 237| Step: 0
Training loss: 0.41980253786094124
Validation loss: 2.2993550219297574

Epoch: 6| Step: 1
Training loss: 0.7085282300710517
Validation loss: 2.27846205141039

Epoch: 6| Step: 2
Training loss: 0.6117224838123396
Validation loss: 2.2726194421436428

Epoch: 6| Step: 3
Training loss: 0.5858045299968302
Validation loss: 2.292577793040794

Epoch: 6| Step: 4
Training loss: 0.8189524320242455
Validation loss: 2.2802110734482377

Epoch: 6| Step: 5
Training loss: 0.8411965054739191
Validation loss: 2.2417332541865695

Epoch: 6| Step: 6
Training loss: 0.520219447432611
Validation loss: 2.2953701462411322

Epoch: 6| Step: 7
Training loss: 0.5938224246375434
Validation loss: 2.24661361121153

Epoch: 6| Step: 8
Training loss: 0.7202114919810778
Validation loss: 2.323217206889268

Epoch: 6| Step: 9
Training loss: 0.7710552712282758
Validation loss: 2.3102218228277254

Epoch: 6| Step: 10
Training loss: 0.5149448995835245
Validation loss: 2.344431482045399

Epoch: 6| Step: 11
Training loss: 0.5264457403391978
Validation loss: 2.3393108864957446

Epoch: 6| Step: 12
Training loss: 0.5348084983609106
Validation loss: 2.336998845222343

Epoch: 6| Step: 13
Training loss: 0.8337085276616547
Validation loss: 2.3250395072520487

Epoch: 238| Step: 0
Training loss: 0.6859470080018665
Validation loss: 2.307704417418056

Epoch: 6| Step: 1
Training loss: 0.4913874890941442
Validation loss: 2.3037801500887753

Epoch: 6| Step: 2
Training loss: 0.7910930077648957
Validation loss: 2.305924945632567

Epoch: 6| Step: 3
Training loss: 0.9265821187867685
Validation loss: 2.3072053982108693

Epoch: 6| Step: 4
Training loss: 0.6682642233006004
Validation loss: 2.283403629403234

Epoch: 6| Step: 5
Training loss: 0.7725898644728769
Validation loss: 2.302417300117986

Epoch: 6| Step: 6
Training loss: 0.5563364636803783
Validation loss: 2.275525707291412

Epoch: 6| Step: 7
Training loss: 0.7251582778609694
Validation loss: 2.3241645672243108

Epoch: 6| Step: 8
Training loss: 0.5399185791268293
Validation loss: 2.331601404532514

Epoch: 6| Step: 9
Training loss: 0.5055215068094465
Validation loss: 2.3278072371841643

Epoch: 6| Step: 10
Training loss: 0.3263106593379852
Validation loss: 2.3215771305852044

Epoch: 6| Step: 11
Training loss: 0.7466700061087636
Validation loss: 2.319521278562146

Epoch: 6| Step: 12
Training loss: 0.5455187738056894
Validation loss: 2.340033457811076

Epoch: 6| Step: 13
Training loss: 0.6741239699913403
Validation loss: 2.3033643981608654

Epoch: 239| Step: 0
Training loss: 0.6725438359661633
Validation loss: 2.327126490859749

Epoch: 6| Step: 1
Training loss: 0.5630672032272783
Validation loss: 2.2858178334377963

Epoch: 6| Step: 2
Training loss: 0.7416264471300037
Validation loss: 2.249849726901078

Epoch: 6| Step: 3
Training loss: 0.8874749811433879
Validation loss: 2.2569080069234952

Epoch: 6| Step: 4
Training loss: 0.6881188728274548
Validation loss: 2.2576316945328943

Epoch: 6| Step: 5
Training loss: 0.5014677261225128
Validation loss: 2.264012690829567

Epoch: 6| Step: 6
Training loss: 0.7350130353147978
Validation loss: 2.2938271780152166

Epoch: 6| Step: 7
Training loss: 0.6864631810883
Validation loss: 2.2819053190762126

Epoch: 6| Step: 8
Training loss: 0.7727444558859533
Validation loss: 2.3175950066316187

Epoch: 6| Step: 9
Training loss: 0.44350501537820164
Validation loss: 2.2614780775245085

Epoch: 6| Step: 10
Training loss: 0.6016547887779724
Validation loss: 2.2592326802761127

Epoch: 6| Step: 11
Training loss: 0.4525383077918927
Validation loss: 2.2711183196606686

Epoch: 6| Step: 12
Training loss: 0.6968631597975656
Validation loss: 2.2779779864779934

Epoch: 6| Step: 13
Training loss: 0.3666932655389659
Validation loss: 2.2917235276969885

Epoch: 240| Step: 0
Training loss: 0.6203790066904998
Validation loss: 2.2727777129576787

Epoch: 6| Step: 1
Training loss: 0.7032538190033487
Validation loss: 2.264294991439584

Epoch: 6| Step: 2
Training loss: 0.45567209340526427
Validation loss: 2.2747033468603974

Epoch: 6| Step: 3
Training loss: 0.7581171033153947
Validation loss: 2.287167340934314

Epoch: 6| Step: 4
Training loss: 0.5568805913505325
Validation loss: 2.3181448029232112

Epoch: 6| Step: 5
Training loss: 0.844931446432148
Validation loss: 2.3235393123595824

Epoch: 6| Step: 6
Training loss: 0.6998989909387022
Validation loss: 2.325901259761777

Epoch: 6| Step: 7
Training loss: 0.7068392666825007
Validation loss: 2.3349423784436127

Epoch: 6| Step: 8
Training loss: 0.550924945240353
Validation loss: 2.2962869294969703

Epoch: 6| Step: 9
Training loss: 0.3715982120314351
Validation loss: 2.298101240011255

Epoch: 6| Step: 10
Training loss: 0.47151288544451575
Validation loss: 2.263893233338139

Epoch: 6| Step: 11
Training loss: 0.4757186422512662
Validation loss: 2.2712309847517753

Epoch: 6| Step: 12
Training loss: 0.6371950345718754
Validation loss: 2.298101833482342

Epoch: 6| Step: 13
Training loss: 0.9015744054791663
Validation loss: 2.265899924407128

Epoch: 241| Step: 0
Training loss: 0.9176481295758468
Validation loss: 2.2818893983989277

Epoch: 6| Step: 1
Training loss: 0.7248397830986977
Validation loss: 2.305368783351898

Epoch: 6| Step: 2
Training loss: 0.26349653842722526
Validation loss: 2.297475820924736

Epoch: 6| Step: 3
Training loss: 0.4170281173628416
Validation loss: 2.320911322326987

Epoch: 6| Step: 4
Training loss: 0.9471835700607705
Validation loss: 2.294916119172282

Epoch: 6| Step: 5
Training loss: 0.537506677896579
Validation loss: 2.3014284456252274

Epoch: 6| Step: 6
Training loss: 0.7471090069891273
Validation loss: 2.297822686586116

Epoch: 6| Step: 7
Training loss: 0.7350492425888598
Validation loss: 2.261013536477011

Epoch: 6| Step: 8
Training loss: 0.351634399691186
Validation loss: 2.249151667545304

Epoch: 6| Step: 9
Training loss: 0.28168319084201193
Validation loss: 2.257089175328965

Epoch: 6| Step: 10
Training loss: 0.5884828847601858
Validation loss: 2.2458805031864206

Epoch: 6| Step: 11
Training loss: 0.5906849351374579
Validation loss: 2.2320000661951482

Epoch: 6| Step: 12
Training loss: 0.5456851276332592
Validation loss: 2.24320701335749

Epoch: 6| Step: 13
Training loss: 0.4877950918401541
Validation loss: 2.2706637330933033

Epoch: 242| Step: 0
Training loss: 0.5552551427531746
Validation loss: 2.275013799939902

Epoch: 6| Step: 1
Training loss: 0.6643699831696912
Validation loss: 2.3013291813346766

Epoch: 6| Step: 2
Training loss: 0.9614704483993745
Validation loss: 2.2688102591449644

Epoch: 6| Step: 3
Training loss: 0.37681484156640466
Validation loss: 2.26232559927007

Epoch: 6| Step: 4
Training loss: 0.7883349926778522
Validation loss: 2.2740896141298412

Epoch: 6| Step: 5
Training loss: 0.43413810239110123
Validation loss: 2.2734135908859834

Epoch: 6| Step: 6
Training loss: 0.6596836452470897
Validation loss: 2.246845098078557

Epoch: 6| Step: 7
Training loss: 0.43750456398899423
Validation loss: 2.2467192090647754

Epoch: 6| Step: 8
Training loss: 0.5823984204078307
Validation loss: 2.2558137898038146

Epoch: 6| Step: 9
Training loss: 0.8209810348369323
Validation loss: 2.2940558261702377

Epoch: 6| Step: 10
Training loss: 0.5545940051734609
Validation loss: 2.3238851973668657

Epoch: 6| Step: 11
Training loss: 0.5824123133610697
Validation loss: 2.3117652830078637

Epoch: 6| Step: 12
Training loss: 0.507398612742394
Validation loss: 2.351150061710942

Epoch: 6| Step: 13
Training loss: 0.3377901931300165
Validation loss: 2.314280048512253

Epoch: 243| Step: 0
Training loss: 0.4250716850186949
Validation loss: 2.2941344631998732

Epoch: 6| Step: 1
Training loss: 0.44407218399065557
Validation loss: 2.2850094821279296

Epoch: 6| Step: 2
Training loss: 0.48418061139756075
Validation loss: 2.2663972154585923

Epoch: 6| Step: 3
Training loss: 0.6011812562563748
Validation loss: 2.2549389379845244

Epoch: 6| Step: 4
Training loss: 0.499015852838795
Validation loss: 2.263236308888516

Epoch: 6| Step: 5
Training loss: 0.6428276667384303
Validation loss: 2.2704936613889424

Epoch: 6| Step: 6
Training loss: 0.8735107623170406
Validation loss: 2.2679311091370695

Epoch: 6| Step: 7
Training loss: 0.4818436404363601
Validation loss: 2.285322917409689

Epoch: 6| Step: 8
Training loss: 0.7568825196728176
Validation loss: 2.2901063338210905

Epoch: 6| Step: 9
Training loss: 0.7917070922234192
Validation loss: 2.3087900429237607

Epoch: 6| Step: 10
Training loss: 0.5829731021944603
Validation loss: 2.3223610221759743

Epoch: 6| Step: 11
Training loss: 0.5832988325770151
Validation loss: 2.3421487316480456

Epoch: 6| Step: 12
Training loss: 0.707680504219631
Validation loss: 2.368857398322934

Epoch: 6| Step: 13
Training loss: 0.378588100458895
Validation loss: 2.36869166520428

Epoch: 244| Step: 0
Training loss: 0.7130036982912558
Validation loss: 2.3324419025806047

Epoch: 6| Step: 1
Training loss: 0.6189610073306182
Validation loss: 2.330419282746856

Epoch: 6| Step: 2
Training loss: 0.477716752208396
Validation loss: 2.2966119022461013

Epoch: 6| Step: 3
Training loss: 0.5500196778505262
Validation loss: 2.260795233415194

Epoch: 6| Step: 4
Training loss: 0.7090077041697015
Validation loss: 2.255149152979074

Epoch: 6| Step: 5
Training loss: 0.6542043592037787
Validation loss: 2.1889793919225027

Epoch: 6| Step: 6
Training loss: 0.8192516188036583
Validation loss: 2.2008884868169027

Epoch: 6| Step: 7
Training loss: 0.8035219881198015
Validation loss: 2.253464463039078

Epoch: 6| Step: 8
Training loss: 0.5010891912316595
Validation loss: 2.235521154076952

Epoch: 6| Step: 9
Training loss: 0.5770840681555668
Validation loss: 2.3308857105173484

Epoch: 6| Step: 10
Training loss: 0.6007888823224076
Validation loss: 2.328988247145575

Epoch: 6| Step: 11
Training loss: 0.44518288181559995
Validation loss: 2.3452587792390465

Epoch: 6| Step: 12
Training loss: 0.38867369608236807
Validation loss: 2.3176851583670035

Epoch: 6| Step: 13
Training loss: 0.518743448330974
Validation loss: 2.3069823149891486

Epoch: 245| Step: 0
Training loss: 0.5930647157958732
Validation loss: 2.316691764801234

Epoch: 6| Step: 1
Training loss: 0.4100681755325506
Validation loss: 2.2785964098842735

Epoch: 6| Step: 2
Training loss: 1.0207354570035294
Validation loss: 2.251541761396015

Epoch: 6| Step: 3
Training loss: 0.7268922939194868
Validation loss: 2.259453383143473

Epoch: 6| Step: 4
Training loss: 0.4881265929387827
Validation loss: 2.2318652338105514

Epoch: 6| Step: 5
Training loss: 0.4132816761786241
Validation loss: 2.2406093009277126

Epoch: 6| Step: 6
Training loss: 0.5241780806796187
Validation loss: 2.2775412155374717

Epoch: 6| Step: 7
Training loss: 0.41387357540340525
Validation loss: 2.2770146548822123

Epoch: 6| Step: 8
Training loss: 0.8564995603877608
Validation loss: 2.294644231607235

Epoch: 6| Step: 9
Training loss: 0.4888447676001018
Validation loss: 2.3055578358149638

Epoch: 6| Step: 10
Training loss: 0.5811683864106768
Validation loss: 2.3139048358079637

Epoch: 6| Step: 11
Training loss: 0.5180883232176242
Validation loss: 2.3240676633612267

Epoch: 6| Step: 12
Training loss: 0.5776136559778101
Validation loss: 2.303634449139188

Epoch: 6| Step: 13
Training loss: 0.2579124141480172
Validation loss: 2.27965882026392

Epoch: 246| Step: 0
Training loss: 0.7702378258094364
Validation loss: 2.2571562784097776

Epoch: 6| Step: 1
Training loss: 0.615222167847646
Validation loss: 2.2491954951221143

Epoch: 6| Step: 2
Training loss: 0.5099117025906881
Validation loss: 2.2346348271892573

Epoch: 6| Step: 3
Training loss: 0.759891215243479
Validation loss: 2.235601459021351

Epoch: 6| Step: 4
Training loss: 0.36274180815271984
Validation loss: 2.2540147869372174

Epoch: 6| Step: 5
Training loss: 0.6171723617435513
Validation loss: 2.254429795333126

Epoch: 6| Step: 6
Training loss: 0.754237364165281
Validation loss: 2.2492622991461415

Epoch: 6| Step: 7
Training loss: 0.19013711021159685
Validation loss: 2.2799189830386744

Epoch: 6| Step: 8
Training loss: 0.43385872176375295
Validation loss: 2.2355061089066415

Epoch: 6| Step: 9
Training loss: 0.7214526076001961
Validation loss: 2.290223445982638

Epoch: 6| Step: 10
Training loss: 0.4577727700918765
Validation loss: 2.2644187491217513

Epoch: 6| Step: 11
Training loss: 0.6397424293940693
Validation loss: 2.2610510335795593

Epoch: 6| Step: 12
Training loss: 0.5091748669406748
Validation loss: 2.2626819764485844

Epoch: 6| Step: 13
Training loss: 0.585827753597546
Validation loss: 2.268129106489852

Epoch: 247| Step: 0
Training loss: 0.4615892877469582
Validation loss: 2.2729735196114493

Epoch: 6| Step: 1
Training loss: 0.6001339584060162
Validation loss: 2.2669731149080974

Epoch: 6| Step: 2
Training loss: 0.5109127773638161
Validation loss: 2.2745380213815056

Epoch: 6| Step: 3
Training loss: 0.5948647524886282
Validation loss: 2.3172837841349336

Epoch: 6| Step: 4
Training loss: 0.49496472661697466
Validation loss: 2.2571767425783915

Epoch: 6| Step: 5
Training loss: 0.401369990503775
Validation loss: 2.2656821691013804

Epoch: 6| Step: 6
Training loss: 0.6491567460437757
Validation loss: 2.251645725988688

Epoch: 6| Step: 7
Training loss: 0.5734769220340002
Validation loss: 2.250854785577306

Epoch: 6| Step: 8
Training loss: 0.7853692368437549
Validation loss: 2.2483605401678264

Epoch: 6| Step: 9
Training loss: 0.8053431016098526
Validation loss: 2.261208783658527

Epoch: 6| Step: 10
Training loss: 0.5101458713474722
Validation loss: 2.29527929004413

Epoch: 6| Step: 11
Training loss: 0.645727284758914
Validation loss: 2.2873466450380766

Epoch: 6| Step: 12
Training loss: 0.44088192409056587
Validation loss: 2.273045133767212

Epoch: 6| Step: 13
Training loss: 0.33765196778540146
Validation loss: 2.294221996792196

Epoch: 248| Step: 0
Training loss: 0.7112456272305923
Validation loss: 2.3119944779571786

Epoch: 6| Step: 1
Training loss: 0.6555218062450933
Validation loss: 2.3199147960528173

Epoch: 6| Step: 2
Training loss: 0.38609838337049746
Validation loss: 2.2958913715328646

Epoch: 6| Step: 3
Training loss: 0.2651670097905913
Validation loss: 2.290639463269145

Epoch: 6| Step: 4
Training loss: 0.81514748812634
Validation loss: 2.265659935964407

Epoch: 6| Step: 5
Training loss: 0.3094602443316246
Validation loss: 2.25726753814546

Epoch: 6| Step: 6
Training loss: 0.5717111707228252
Validation loss: 2.273784933270093

Epoch: 6| Step: 7
Training loss: 0.5373882610036238
Validation loss: 2.2718198593378163

Epoch: 6| Step: 8
Training loss: 0.6865602486130302
Validation loss: 2.3040731499380604

Epoch: 6| Step: 9
Training loss: 0.45583513027071765
Validation loss: 2.255294106641861

Epoch: 6| Step: 10
Training loss: 0.4182544694263824
Validation loss: 2.240288390556491

Epoch: 6| Step: 11
Training loss: 0.5138353733028849
Validation loss: 2.254778649248521

Epoch: 6| Step: 12
Training loss: 0.8271987341278986
Validation loss: 2.275992992032055

Epoch: 6| Step: 13
Training loss: 0.5109600237160207
Validation loss: 2.298714433678495

Epoch: 249| Step: 0
Training loss: 0.6386648755171207
Validation loss: 2.3239846471254277

Epoch: 6| Step: 1
Training loss: 0.8243923998681809
Validation loss: 2.3294136757150308

Epoch: 6| Step: 2
Training loss: 0.5466834141426046
Validation loss: 2.3305109542098634

Epoch: 6| Step: 3
Training loss: 0.6638418392000719
Validation loss: 2.3119990863072264

Epoch: 6| Step: 4
Training loss: 0.38675446778856465
Validation loss: 2.279496134988104

Epoch: 6| Step: 5
Training loss: 0.6634376727843811
Validation loss: 2.304981779231541

Epoch: 6| Step: 6
Training loss: 0.39596546209844513
Validation loss: 2.299642726208937

Epoch: 6| Step: 7
Training loss: 0.5789842921071526
Validation loss: 2.2470034912260566

Epoch: 6| Step: 8
Training loss: 0.45995233612765246
Validation loss: 2.2564992644088475

Epoch: 6| Step: 9
Training loss: 0.4185422189682614
Validation loss: 2.2593964121513137

Epoch: 6| Step: 10
Training loss: 0.7112687146317557
Validation loss: 2.2619012586890483

Epoch: 6| Step: 11
Training loss: 0.3605222220377099
Validation loss: 2.2813354624519078

Epoch: 6| Step: 12
Training loss: 0.6147809976935869
Validation loss: 2.290005827295971

Epoch: 6| Step: 13
Training loss: 0.42788559491911715
Validation loss: 2.2863387964871342

Epoch: 250| Step: 0
Training loss: 0.6216063633281914
Validation loss: 2.2831892423327793

Epoch: 6| Step: 1
Training loss: 0.41735038292175913
Validation loss: 2.301654682407867

Epoch: 6| Step: 2
Training loss: 0.6420376252382154
Validation loss: 2.298437860759804

Epoch: 6| Step: 3
Training loss: 0.5935862968039166
Validation loss: 2.275762140444961

Epoch: 6| Step: 4
Training loss: 0.4642854431172512
Validation loss: 2.2303736637901856

Epoch: 6| Step: 5
Training loss: 0.5190765858024512
Validation loss: 2.231381460836991

Epoch: 6| Step: 6
Training loss: 0.6792861806017808
Validation loss: 2.2562022021425654

Epoch: 6| Step: 7
Training loss: 0.3335323286129325
Validation loss: 2.290106321087441

Epoch: 6| Step: 8
Training loss: 0.6533497346146073
Validation loss: 2.253104398344595

Epoch: 6| Step: 9
Training loss: 0.49806656144073425
Validation loss: 2.2834931023161578

Epoch: 6| Step: 10
Training loss: 0.5317503592360359
Validation loss: 2.299192940876662

Epoch: 6| Step: 11
Training loss: 0.49846072486653004
Validation loss: 2.3186376747605317

Epoch: 6| Step: 12
Training loss: 0.8285003387321558
Validation loss: 2.2793787565011163

Epoch: 6| Step: 13
Training loss: 0.3985397731192965
Validation loss: 2.2727813089450177

Epoch: 251| Step: 0
Training loss: 0.6330200137640003
Validation loss: 2.2903699345880533

Epoch: 6| Step: 1
Training loss: 0.46194096621984637
Validation loss: 2.3224699154645205

Epoch: 6| Step: 2
Training loss: 0.39899013565174374
Validation loss: 2.348565626885787

Epoch: 6| Step: 3
Training loss: 0.4257879169187136
Validation loss: 2.3573964170401975

Epoch: 6| Step: 4
Training loss: 0.713768405576782
Validation loss: 2.3479711988033802

Epoch: 6| Step: 5
Training loss: 0.6234465127546837
Validation loss: 2.3300444112614698

Epoch: 6| Step: 6
Training loss: 0.5528280765113692
Validation loss: 2.3048469156005673

Epoch: 6| Step: 7
Training loss: 0.7185160214596312
Validation loss: 2.292196646195945

Epoch: 6| Step: 8
Training loss: 0.7520462176674004
Validation loss: 2.304828140197354

Epoch: 6| Step: 9
Training loss: 0.20709246504168985
Validation loss: 2.287089722024557

Epoch: 6| Step: 10
Training loss: 0.6541005765327137
Validation loss: 2.348949002254059

Epoch: 6| Step: 11
Training loss: 0.20359544195612436
Validation loss: 2.3090357586612758

Epoch: 6| Step: 12
Training loss: 0.6456703293093674
Validation loss: 2.3246755483193398

Epoch: 6| Step: 13
Training loss: 0.6707872412427569
Validation loss: 2.297261467111318

Epoch: 252| Step: 0
Training loss: 0.5070215961965571
Validation loss: 2.2742917200681276

Epoch: 6| Step: 1
Training loss: 0.6175862484903766
Validation loss: 2.295321745969649

Epoch: 6| Step: 2
Training loss: 0.43309580072839116
Validation loss: 2.2893179670057253

Epoch: 6| Step: 3
Training loss: 0.47791193035453866
Validation loss: 2.356601984020251

Epoch: 6| Step: 4
Training loss: 0.4420642842866626
Validation loss: 2.4372755988071666

Epoch: 6| Step: 5
Training loss: 0.7392518460273592
Validation loss: 2.3856172518060967

Epoch: 6| Step: 6
Training loss: 0.6352950954351817
Validation loss: 2.364769618238915

Epoch: 6| Step: 7
Training loss: 0.5222565723624677
Validation loss: 2.2869010917253263

Epoch: 6| Step: 8
Training loss: 0.5785396223223288
Validation loss: 2.2410794544769037

Epoch: 6| Step: 9
Training loss: 0.5877148438311341
Validation loss: 2.204537078695121

Epoch: 6| Step: 10
Training loss: 0.4701148983591004
Validation loss: 2.1903069788178855

Epoch: 6| Step: 11
Training loss: 0.821038061516555
Validation loss: 2.1853395566579845

Epoch: 6| Step: 12
Training loss: 0.4036422442204869
Validation loss: 2.2329352946898102

Epoch: 6| Step: 13
Training loss: 0.8065652142390001
Validation loss: 2.2556630141146234

Epoch: 253| Step: 0
Training loss: 0.6374085323313264
Validation loss: 2.2944217695695115

Epoch: 6| Step: 1
Training loss: 0.3885863320225876
Validation loss: 2.3322188974408995

Epoch: 6| Step: 2
Training loss: 0.8262363706263929
Validation loss: 2.360021981524015

Epoch: 6| Step: 3
Training loss: 0.4819426221687881
Validation loss: 2.383739299936748

Epoch: 6| Step: 4
Training loss: 0.3147285037521182
Validation loss: 2.381246574101605

Epoch: 6| Step: 5
Training loss: 0.6878500394096455
Validation loss: 2.382785482134087

Epoch: 6| Step: 6
Training loss: 0.7338248688097513
Validation loss: 2.3307392247782097

Epoch: 6| Step: 7
Training loss: 0.5609660956869442
Validation loss: 2.3014031792233105

Epoch: 6| Step: 8
Training loss: 0.5435997294913707
Validation loss: 2.262746759316523

Epoch: 6| Step: 9
Training loss: 0.4699961628148513
Validation loss: 2.276368272028611

Epoch: 6| Step: 10
Training loss: 0.578632158060025
Validation loss: 2.256372397229275

Epoch: 6| Step: 11
Training loss: 0.46554480508522444
Validation loss: 2.24387054658831

Epoch: 6| Step: 12
Training loss: 0.4687620797190269
Validation loss: 2.2876618848325507

Epoch: 6| Step: 13
Training loss: 0.3175037095085972
Validation loss: 2.321188561780587

Epoch: 254| Step: 0
Training loss: 0.5265331112954785
Validation loss: 2.3571136607797407

Epoch: 6| Step: 1
Training loss: 0.6575154410750178
Validation loss: 2.3607084877646503

Epoch: 6| Step: 2
Training loss: 0.6543345198548465
Validation loss: 2.362056174439955

Epoch: 6| Step: 3
Training loss: 0.7239436873091127
Validation loss: 2.3808521972328394

Epoch: 6| Step: 4
Training loss: 0.3093232935264969
Validation loss: 2.3594541315701782

Epoch: 6| Step: 5
Training loss: 0.5024510151914624
Validation loss: 2.356105182913209

Epoch: 6| Step: 6
Training loss: 0.6139708365634363
Validation loss: 2.341895184274272

Epoch: 6| Step: 7
Training loss: 0.6453692450524461
Validation loss: 2.3324346763849815

Epoch: 6| Step: 8
Training loss: 0.6478053769107839
Validation loss: 2.3206353002901112

Epoch: 6| Step: 9
Training loss: 0.44898627526880275
Validation loss: 2.3169255179838024

Epoch: 6| Step: 10
Training loss: 0.29423323815927177
Validation loss: 2.286141428103512

Epoch: 6| Step: 11
Training loss: 0.5362445318836908
Validation loss: 2.2802073834936225

Epoch: 6| Step: 12
Training loss: 0.3880198007181581
Validation loss: 2.2749813583008724

Epoch: 6| Step: 13
Training loss: 0.28399498826544456
Validation loss: 2.2397905700757765

Epoch: 255| Step: 0
Training loss: 0.4832472439532916
Validation loss: 2.306648483263676

Epoch: 6| Step: 1
Training loss: 0.5194653921045754
Validation loss: 2.302288915047816

Epoch: 6| Step: 2
Training loss: 0.5193539080141419
Validation loss: 2.3065966457923452

Epoch: 6| Step: 3
Training loss: 0.5210310433560716
Validation loss: 2.341358298958299

Epoch: 6| Step: 4
Training loss: 0.40639207263052013
Validation loss: 2.317034662298112

Epoch: 6| Step: 5
Training loss: 0.4358222672399052
Validation loss: 2.3353161996801055

Epoch: 6| Step: 6
Training loss: 0.6841055126094657
Validation loss: 2.335064195119084

Epoch: 6| Step: 7
Training loss: 0.442618014902384
Validation loss: 2.330089105349965

Epoch: 6| Step: 8
Training loss: 0.6525882788020848
Validation loss: 2.3147399090527903

Epoch: 6| Step: 9
Training loss: 0.5397529326920658
Validation loss: 2.306797048367593

Epoch: 6| Step: 10
Training loss: 0.5280428173520517
Validation loss: 2.3209729981432208

Epoch: 6| Step: 11
Training loss: 0.7324318033181252
Validation loss: 2.2726177314469838

Epoch: 6| Step: 12
Training loss: 0.543337497778108
Validation loss: 2.272326943372344

Epoch: 6| Step: 13
Training loss: 0.3081859114835543
Validation loss: 2.2334233747350845

Epoch: 256| Step: 0
Training loss: 0.3163219151131128
Validation loss: 2.266538475023089

Epoch: 6| Step: 1
Training loss: 0.558884231692494
Validation loss: 2.2322406713380816

Epoch: 6| Step: 2
Training loss: 0.3868895259589062
Validation loss: 2.2801114673132985

Epoch: 6| Step: 3
Training loss: 0.6459673978237667
Validation loss: 2.2983844879040594

Epoch: 6| Step: 4
Training loss: 0.5263323091122931
Validation loss: 2.3397466353942273

Epoch: 6| Step: 5
Training loss: 0.29368633128126664
Validation loss: 2.337064133808401

Epoch: 6| Step: 6
Training loss: 0.7188415469042284
Validation loss: 2.351145162640669

Epoch: 6| Step: 7
Training loss: 0.5774711055462949
Validation loss: 2.3313635438450624

Epoch: 6| Step: 8
Training loss: 0.6742329362811169
Validation loss: 2.3019581173576236

Epoch: 6| Step: 9
Training loss: 0.6370475013948583
Validation loss: 2.2993012399872543

Epoch: 6| Step: 10
Training loss: 0.5002315700249207
Validation loss: 2.301061182736812

Epoch: 6| Step: 11
Training loss: 0.4560473194384813
Validation loss: 2.249731667673612

Epoch: 6| Step: 12
Training loss: 0.4327502078458572
Validation loss: 2.231009967775529

Epoch: 6| Step: 13
Training loss: 0.5486386878356639
Validation loss: 2.2592889842153823

Epoch: 257| Step: 0
Training loss: 0.6082239283419811
Validation loss: 2.2286275645523057

Epoch: 6| Step: 1
Training loss: 0.5221946251484113
Validation loss: 2.237542544182908

Epoch: 6| Step: 2
Training loss: 0.6665220600492436
Validation loss: 2.28331328564292

Epoch: 6| Step: 3
Training loss: 0.3807047016338953
Validation loss: 2.295714436109524

Epoch: 6| Step: 4
Training loss: 0.40558147443762477
Validation loss: 2.320517217060826

Epoch: 6| Step: 5
Training loss: 0.29866384840189775
Validation loss: 2.3501070813096847

Epoch: 6| Step: 6
Training loss: 0.2154085019191907
Validation loss: 2.356357144153182

Epoch: 6| Step: 7
Training loss: 0.6461591795849241
Validation loss: 2.371068631290662

Epoch: 6| Step: 8
Training loss: 0.39099189693927877
Validation loss: 2.3333992417720597

Epoch: 6| Step: 9
Training loss: 0.5589412595274181
Validation loss: 2.3141507013940275

Epoch: 6| Step: 10
Training loss: 0.2782941303988463
Validation loss: 2.2923394014679617

Epoch: 6| Step: 11
Training loss: 0.8047089805328506
Validation loss: 2.2803509905022743

Epoch: 6| Step: 12
Training loss: 0.7080515880863495
Validation loss: 2.2913989144650855

Epoch: 6| Step: 13
Training loss: 0.3737537218310443
Validation loss: 2.260039186343932

Epoch: 258| Step: 0
Training loss: 0.5699045995717771
Validation loss: 2.229915154740032

Epoch: 6| Step: 1
Training loss: 0.2876566905650796
Validation loss: 2.2334217620017203

Epoch: 6| Step: 2
Training loss: 0.32805144530072283
Validation loss: 2.2782875679916073

Epoch: 6| Step: 3
Training loss: 0.5626062451796079
Validation loss: 2.2748492148903767

Epoch: 6| Step: 4
Training loss: 0.6588071999879063
Validation loss: 2.3086974540224365

Epoch: 6| Step: 5
Training loss: 0.4761646986836022
Validation loss: 2.3391880130917913

Epoch: 6| Step: 6
Training loss: 0.5691997960736331
Validation loss: 2.326871619487326

Epoch: 6| Step: 7
Training loss: 0.4933836193274131
Validation loss: 2.3213134575490066

Epoch: 6| Step: 8
Training loss: 0.4050691388420041
Validation loss: 2.3343445817657047

Epoch: 6| Step: 9
Training loss: 0.5720928308828894
Validation loss: 2.2727129374002577

Epoch: 6| Step: 10
Training loss: 0.49368304148687997
Validation loss: 2.23593396886189

Epoch: 6| Step: 11
Training loss: 0.5629969626797042
Validation loss: 2.2408018360735555

Epoch: 6| Step: 12
Training loss: 0.6673122548446498
Validation loss: 2.246813238970251

Epoch: 6| Step: 13
Training loss: 0.43998626581886624
Validation loss: 2.23936225580245

Epoch: 259| Step: 0
Training loss: 0.5826038897458155
Validation loss: 2.2629023717919963

Epoch: 6| Step: 1
Training loss: 0.45887704771266136
Validation loss: 2.283627073853335

Epoch: 6| Step: 2
Training loss: 0.4077542954048485
Validation loss: 2.302594696907309

Epoch: 6| Step: 3
Training loss: 0.4045041792126736
Validation loss: 2.3384478278171974

Epoch: 6| Step: 4
Training loss: 0.6058048668942012
Validation loss: 2.3178075286407056

Epoch: 6| Step: 5
Training loss: 0.41840288308205165
Validation loss: 2.3464805399004125

Epoch: 6| Step: 6
Training loss: 0.5830170648246409
Validation loss: 2.325562174217537

Epoch: 6| Step: 7
Training loss: 0.6643369219858973
Validation loss: 2.2674181423866453

Epoch: 6| Step: 8
Training loss: 0.577204357865551
Validation loss: 2.279412815846946

Epoch: 6| Step: 9
Training loss: 0.6045078897978885
Validation loss: 2.2538489391693806

Epoch: 6| Step: 10
Training loss: 0.2994206730759195
Validation loss: 2.23987604352283

Epoch: 6| Step: 11
Training loss: 0.42928274337932004
Validation loss: 2.2440099488310308

Epoch: 6| Step: 12
Training loss: 0.5092994048770684
Validation loss: 2.261658887215992

Epoch: 6| Step: 13
Training loss: 0.6113773606433581
Validation loss: 2.3237925204062053

Epoch: 260| Step: 0
Training loss: 0.45842517308341485
Validation loss: 2.40548946724179

Epoch: 6| Step: 1
Training loss: 0.4545913352081384
Validation loss: 2.4447113811085637

Epoch: 6| Step: 2
Training loss: 0.43067484039867904
Validation loss: 2.3816340988414675

Epoch: 6| Step: 3
Training loss: 0.4335057624689088
Validation loss: 2.2809560043805215

Epoch: 6| Step: 4
Training loss: 0.40639331930519124
Validation loss: 2.2530393353799667

Epoch: 6| Step: 5
Training loss: 0.3554090722261372
Validation loss: 2.190245048363083

Epoch: 6| Step: 6
Training loss: 0.6702534380593032
Validation loss: 2.1892481602729714

Epoch: 6| Step: 7
Training loss: 0.6015898462990927
Validation loss: 2.1768777083588273

Epoch: 6| Step: 8
Training loss: 0.745471555104492
Validation loss: 2.1723239010126676

Epoch: 6| Step: 9
Training loss: 0.532853763134771
Validation loss: 2.1912177164553226

Epoch: 6| Step: 10
Training loss: 0.47506795321821277
Validation loss: 2.2270698739270385

Epoch: 6| Step: 11
Training loss: 0.55165812174104
Validation loss: 2.253759524151845

Epoch: 6| Step: 12
Training loss: 0.6654079943167232
Validation loss: 2.2715721793041013

Epoch: 6| Step: 13
Training loss: 0.6305689659970597
Validation loss: 2.2925815542209946

Epoch: 261| Step: 0
Training loss: 0.5886945329038068
Validation loss: 2.2860352323281727

Epoch: 6| Step: 1
Training loss: 0.537111317024188
Validation loss: 2.2951959016041212

Epoch: 6| Step: 2
Training loss: 0.6341041757302647
Validation loss: 2.2954986736896594

Epoch: 6| Step: 3
Training loss: 0.3147958345135192
Validation loss: 2.2818145390559357

Epoch: 6| Step: 4
Training loss: 0.7439539717823525
Validation loss: 2.2974808896722

Epoch: 6| Step: 5
Training loss: 0.5597345400775576
Validation loss: 2.2575757092372886

Epoch: 6| Step: 6
Training loss: 0.4554230851956887
Validation loss: 2.2686171504956927

Epoch: 6| Step: 7
Training loss: 0.4655891020589122
Validation loss: 2.254938548027706

Epoch: 6| Step: 8
Training loss: 0.3463835189925358
Validation loss: 2.284525258162415

Epoch: 6| Step: 9
Training loss: 0.45904842497955656
Validation loss: 2.261372016485301

Epoch: 6| Step: 10
Training loss: 0.38664177407853006
Validation loss: 2.3246399597485903

Epoch: 6| Step: 11
Training loss: 0.6171333675547424
Validation loss: 2.319835623919377

Epoch: 6| Step: 12
Training loss: 0.3406829666545695
Validation loss: 2.2784855874433068

Epoch: 6| Step: 13
Training loss: 0.6023794299689265
Validation loss: 2.293089615229402

Epoch: 262| Step: 0
Training loss: 0.31753369779556534
Validation loss: 2.3004703092597616

Epoch: 6| Step: 1
Training loss: 0.5446124001324439
Validation loss: 2.283631365617543

Epoch: 6| Step: 2
Training loss: 0.5058628509284234
Validation loss: 2.276876942331654

Epoch: 6| Step: 3
Training loss: 0.3673095297440988
Validation loss: 2.263987074804188

Epoch: 6| Step: 4
Training loss: 0.435760514076137
Validation loss: 2.2306933296329103

Epoch: 6| Step: 5
Training loss: 0.45172225937590155
Validation loss: 2.206067673850675

Epoch: 6| Step: 6
Training loss: 0.5228471985935158
Validation loss: 2.256683163681267

Epoch: 6| Step: 7
Training loss: 0.24481146390820815
Validation loss: 2.2814329565349345

Epoch: 6| Step: 8
Training loss: 0.5264986118305596
Validation loss: 2.271383036288327

Epoch: 6| Step: 9
Training loss: 0.5031246955349398
Validation loss: 2.276832059990187

Epoch: 6| Step: 10
Training loss: 0.6627958446893872
Validation loss: 2.3012013867169228

Epoch: 6| Step: 11
Training loss: 0.37331237133106293
Validation loss: 2.3063369324187466

Epoch: 6| Step: 12
Training loss: 0.7695990595495581
Validation loss: 2.254092516627375

Epoch: 6| Step: 13
Training loss: 0.6137072790314961
Validation loss: 2.2595867843084063

Epoch: 263| Step: 0
Training loss: 0.36977694934338634
Validation loss: 2.268047903402621

Epoch: 6| Step: 1
Training loss: 0.5250398393682989
Validation loss: 2.2068403583444858

Epoch: 6| Step: 2
Training loss: 0.5224177262449673
Validation loss: 2.227351847123106

Epoch: 6| Step: 3
Training loss: 0.464335299754834
Validation loss: 2.244941135620219

Epoch: 6| Step: 4
Training loss: 0.3217421470460328
Validation loss: 2.2207640381059557

Epoch: 6| Step: 5
Training loss: 0.3329059299548741
Validation loss: 2.2966287031753447

Epoch: 6| Step: 6
Training loss: 0.29639008722794963
Validation loss: 2.276310090787453

Epoch: 6| Step: 7
Training loss: 0.420499572814924
Validation loss: 2.3276302453090776

Epoch: 6| Step: 8
Training loss: 0.5932611661680811
Validation loss: 2.310371468063052

Epoch: 6| Step: 9
Training loss: 0.5720110642790254
Validation loss: 2.298687070863683

Epoch: 6| Step: 10
Training loss: 0.8042055927665585
Validation loss: 2.3644461892638495

Epoch: 6| Step: 11
Training loss: 0.4415314589629596
Validation loss: 2.3358814406862707

Epoch: 6| Step: 12
Training loss: 0.4247088795628505
Validation loss: 2.329992724056996

Epoch: 6| Step: 13
Training loss: 0.5966371062173611
Validation loss: 2.2932888706942838

Epoch: 264| Step: 0
Training loss: 0.37812626578379227
Validation loss: 2.3011097536223835

Epoch: 6| Step: 1
Training loss: 0.35981617674904587
Validation loss: 2.281516037286485

Epoch: 6| Step: 2
Training loss: 0.7325803864932234
Validation loss: 2.2671284570813275

Epoch: 6| Step: 3
Training loss: 0.4991624791484992
Validation loss: 2.238318008349804

Epoch: 6| Step: 4
Training loss: 0.5477541260592189
Validation loss: 2.2341065495443675

Epoch: 6| Step: 5
Training loss: 0.6583759748756922
Validation loss: 2.200146143357731

Epoch: 6| Step: 6
Training loss: 0.4921805668902656
Validation loss: 2.215842608382863

Epoch: 6| Step: 7
Training loss: 0.2512862821496621
Validation loss: 2.233068322617922

Epoch: 6| Step: 8
Training loss: 0.5344082414873154
Validation loss: 2.2367419255379932

Epoch: 6| Step: 9
Training loss: 0.45623037478945183
Validation loss: 2.2693949461445797

Epoch: 6| Step: 10
Training loss: 0.5177932580055878
Validation loss: 2.2416902476449394

Epoch: 6| Step: 11
Training loss: 0.3550039753221178
Validation loss: 2.2760973006257204

Epoch: 6| Step: 12
Training loss: 0.5474000590046665
Validation loss: 2.2915498951744113

Epoch: 6| Step: 13
Training loss: 0.2056999316548979
Validation loss: 2.2987719207371398

Epoch: 265| Step: 0
Training loss: 0.416087542841041
Validation loss: 2.3265571884363174

Epoch: 6| Step: 1
Training loss: 0.37414110688301766
Validation loss: 2.3029411171828684

Epoch: 6| Step: 2
Training loss: 0.40157589277799804
Validation loss: 2.3064359895223068

Epoch: 6| Step: 3
Training loss: 0.4814662657969706
Validation loss: 2.3082475238987215

Epoch: 6| Step: 4
Training loss: 0.5599952668603055
Validation loss: 2.2977512260086876

Epoch: 6| Step: 5
Training loss: 0.4666443260272187
Validation loss: 2.2548101115691135

Epoch: 6| Step: 6
Training loss: 0.5757445739079617
Validation loss: 2.279113413475103

Epoch: 6| Step: 7
Training loss: 0.5700816118223379
Validation loss: 2.2510128635544375

Epoch: 6| Step: 8
Training loss: 0.47098028167119255
Validation loss: 2.242813888955591

Epoch: 6| Step: 9
Training loss: 0.47777496938964337
Validation loss: 2.2650875168289777

Epoch: 6| Step: 10
Training loss: 0.5340619000944337
Validation loss: 2.266472863971449

Epoch: 6| Step: 11
Training loss: 0.5688993635130132
Validation loss: 2.27064994989

Epoch: 6| Step: 12
Training loss: 0.30315461063285826
Validation loss: 2.2510491426697588

Epoch: 6| Step: 13
Training loss: 0.4877472666121733
Validation loss: 2.290484084310927

Epoch: 266| Step: 0
Training loss: 0.6203004581233867
Validation loss: 2.2874737567316346

Epoch: 6| Step: 1
Training loss: 0.3464149001181015
Validation loss: 2.320758611930963

Epoch: 6| Step: 2
Training loss: 0.5884715407011969
Validation loss: 2.3403898987019436

Epoch: 6| Step: 3
Training loss: 0.32988730111916376
Validation loss: 2.312621594851499

Epoch: 6| Step: 4
Training loss: 0.4005153740790675
Validation loss: 2.2922593216463016

Epoch: 6| Step: 5
Training loss: 0.29959014273815776
Validation loss: 2.281334709542247

Epoch: 6| Step: 6
Training loss: 0.3109618000139026
Validation loss: 2.2803807616237424

Epoch: 6| Step: 7
Training loss: 0.6078305602148567
Validation loss: 2.2879703902157873

Epoch: 6| Step: 8
Training loss: 0.5130340329197162
Validation loss: 2.245736534957436

Epoch: 6| Step: 9
Training loss: 0.47244625313163574
Validation loss: 2.244104769122453

Epoch: 6| Step: 10
Training loss: 0.5537012223832877
Validation loss: 2.273201802836819

Epoch: 6| Step: 11
Training loss: 0.5374577172969797
Validation loss: 2.224827854769386

Epoch: 6| Step: 12
Training loss: 0.5431976384796979
Validation loss: 2.255631481858924

Epoch: 6| Step: 13
Training loss: 0.45382966135703706
Validation loss: 2.2282435762223267

Epoch: 267| Step: 0
Training loss: 0.5349275141926169
Validation loss: 2.2589621489826404

Epoch: 6| Step: 1
Training loss: 0.33636664547675543
Validation loss: 2.276653083115505

Epoch: 6| Step: 2
Training loss: 0.46467999370800045
Validation loss: 2.30525406397671

Epoch: 6| Step: 3
Training loss: 0.442758009498346
Validation loss: 2.3022016280410935

Epoch: 6| Step: 4
Training loss: 0.6421759370008797
Validation loss: 2.3199406575833725

Epoch: 6| Step: 5
Training loss: 0.42183331884120123
Validation loss: 2.3422396217018466

Epoch: 6| Step: 6
Training loss: 0.2944950526733512
Validation loss: 2.2845028796083717

Epoch: 6| Step: 7
Training loss: 0.8214396770686156
Validation loss: 2.2906219575294293

Epoch: 6| Step: 8
Training loss: 0.3580942552161654
Validation loss: 2.245009916164744

Epoch: 6| Step: 9
Training loss: 0.3501319389636233
Validation loss: 2.196694993971102

Epoch: 6| Step: 10
Training loss: 0.5252696185108984
Validation loss: 2.2102231406163995

Epoch: 6| Step: 11
Training loss: 0.4366647888311869
Validation loss: 2.2266905550068

Epoch: 6| Step: 12
Training loss: 0.553611194702889
Validation loss: 2.236523807811199

Epoch: 6| Step: 13
Training loss: 0.13310145052290348
Validation loss: 2.260162280981981

Epoch: 268| Step: 0
Training loss: 0.6949657046823691
Validation loss: 2.319413251001655

Epoch: 6| Step: 1
Training loss: 0.44484999547445786
Validation loss: 2.2964160788030505

Epoch: 6| Step: 2
Training loss: 0.46982611475617253
Validation loss: 2.3374757496872944

Epoch: 6| Step: 3
Training loss: 0.43568315640458055
Validation loss: 2.32295022928551

Epoch: 6| Step: 4
Training loss: 0.4891766692161885
Validation loss: 2.308746230135913

Epoch: 6| Step: 5
Training loss: 0.5022032593187236
Validation loss: 2.2615066047122507

Epoch: 6| Step: 6
Training loss: 0.40468841979758113
Validation loss: 2.2299764740879833

Epoch: 6| Step: 7
Training loss: 0.6272011144630593
Validation loss: 2.216078882825751

Epoch: 6| Step: 8
Training loss: 0.503308259274182
Validation loss: 2.239755648379705

Epoch: 6| Step: 9
Training loss: 0.3757547095556287
Validation loss: 2.2641943975344923

Epoch: 6| Step: 10
Training loss: 0.4211392875211118
Validation loss: 2.2664687105146886

Epoch: 6| Step: 11
Training loss: 0.32990863217932537
Validation loss: 2.265090611185667

Epoch: 6| Step: 12
Training loss: 0.38847940558020805
Validation loss: 2.3400518357118893

Epoch: 6| Step: 13
Training loss: 0.3421431612874655
Validation loss: 2.3356306095530046

Epoch: 269| Step: 0
Training loss: 0.4686013462866665
Validation loss: 2.3565533194239014

Epoch: 6| Step: 1
Training loss: 0.32400296395470807
Validation loss: 2.3532695636358203

Epoch: 6| Step: 2
Training loss: 0.5189915772454688
Validation loss: 2.3014737399857492

Epoch: 6| Step: 3
Training loss: 0.4238527176573554
Validation loss: 2.2694729793329107

Epoch: 6| Step: 4
Training loss: 0.44369136463206565
Validation loss: 2.252754659259156

Epoch: 6| Step: 5
Training loss: 0.4765089974309453
Validation loss: 2.23937926530049

Epoch: 6| Step: 6
Training loss: 0.1932611890480065
Validation loss: 2.230660261806972

Epoch: 6| Step: 7
Training loss: 0.7342350603245629
Validation loss: 2.3221732488213984

Epoch: 6| Step: 8
Training loss: 0.15987593845974835
Validation loss: 2.2785688606070917

Epoch: 6| Step: 9
Training loss: 0.3230680590214214
Validation loss: 2.3245281407540106

Epoch: 6| Step: 10
Training loss: 0.9045492853978412
Validation loss: 2.2995269658563116

Epoch: 6| Step: 11
Training loss: 0.28671995989053095
Validation loss: 2.315747785967015

Epoch: 6| Step: 12
Training loss: 0.2146510560532882
Validation loss: 2.2847463257819953

Epoch: 6| Step: 13
Training loss: 0.5026743120120949
Validation loss: 2.2466295422376015

Epoch: 270| Step: 0
Training loss: 0.39433020955536285
Validation loss: 2.2169745940634447

Epoch: 6| Step: 1
Training loss: 0.6519031521505192
Validation loss: 2.2263806421190218

Epoch: 6| Step: 2
Training loss: 0.5771484891371857
Validation loss: 2.2306741679833317

Epoch: 6| Step: 3
Training loss: 0.36971182252224877
Validation loss: 2.2059490460715687

Epoch: 6| Step: 4
Training loss: 0.6814263999109779
Validation loss: 2.22256530440706

Epoch: 6| Step: 5
Training loss: 0.4950116438170497
Validation loss: 2.2464441985692103

Epoch: 6| Step: 6
Training loss: 0.36994845688569333
Validation loss: 2.2786484466865895

Epoch: 6| Step: 7
Training loss: 0.4264407868060869
Validation loss: 2.2925863380173124

Epoch: 6| Step: 8
Training loss: 0.497856058704281
Validation loss: 2.315173122070676

Epoch: 6| Step: 9
Training loss: 0.26890075580452405
Validation loss: 2.3556703449163328

Epoch: 6| Step: 10
Training loss: 0.33985916190443033
Validation loss: 2.3369205140636273

Epoch: 6| Step: 11
Training loss: 0.45671014835741897
Validation loss: 2.3631693294949376

Epoch: 6| Step: 12
Training loss: 0.37167467523864567
Validation loss: 2.3053101168750203

Epoch: 6| Step: 13
Training loss: 0.46082188077541586
Validation loss: 2.3042305809220176

Epoch: 271| Step: 0
Training loss: 0.5915372423763958
Validation loss: 2.263424174920742

Epoch: 6| Step: 1
Training loss: 0.45171124143637575
Validation loss: 2.285266383240912

Epoch: 6| Step: 2
Training loss: 0.418483417262205
Validation loss: 2.2803528376125985

Epoch: 6| Step: 3
Training loss: 0.41403635410315764
Validation loss: 2.2683374176033224

Epoch: 6| Step: 4
Training loss: 0.307865127673136
Validation loss: 2.246572858833766

Epoch: 6| Step: 5
Training loss: 0.2569158741529105
Validation loss: 2.2835657873550783

Epoch: 6| Step: 6
Training loss: 0.5980597984866076
Validation loss: 2.2906463825964964

Epoch: 6| Step: 7
Training loss: 0.6583531602054867
Validation loss: 2.3072250065101945

Epoch: 6| Step: 8
Training loss: 0.5364123451248866
Validation loss: 2.3008922096997364

Epoch: 6| Step: 9
Training loss: 0.5933675287024253
Validation loss: 2.319813264408032

Epoch: 6| Step: 10
Training loss: 0.27856640560124524
Validation loss: 2.330497825820449

Epoch: 6| Step: 11
Training loss: 0.31344176482534775
Validation loss: 2.3385952590913845

Epoch: 6| Step: 12
Training loss: 0.40437233262162536
Validation loss: 2.329560546338625

Epoch: 6| Step: 13
Training loss: 0.2516623748930187
Validation loss: 2.299095985262981

Epoch: 272| Step: 0
Training loss: 0.19053505158976283
Validation loss: 2.3195461646906947

Epoch: 6| Step: 1
Training loss: 0.31547718458156127
Validation loss: 2.305649645712688

Epoch: 6| Step: 2
Training loss: 0.3858003403493053
Validation loss: 2.273338787931291

Epoch: 6| Step: 3
Training loss: 0.41093521625188806
Validation loss: 2.321098563789712

Epoch: 6| Step: 4
Training loss: 0.49465329259800156
Validation loss: 2.326903901763907

Epoch: 6| Step: 5
Training loss: 0.5402304118928885
Validation loss: 2.3009409089392907

Epoch: 6| Step: 6
Training loss: 0.5215476922732492
Validation loss: 2.322050130436823

Epoch: 6| Step: 7
Training loss: 0.4901203159613382
Validation loss: 2.283200183193063

Epoch: 6| Step: 8
Training loss: 0.22779283574743214
Validation loss: 2.290999017339195

Epoch: 6| Step: 9
Training loss: 0.3496900603888408
Validation loss: 2.2473120234529786

Epoch: 6| Step: 10
Training loss: 0.4646979672369631
Validation loss: 2.2519717515487225

Epoch: 6| Step: 11
Training loss: 0.5308946374629903
Validation loss: 2.229292005715114

Epoch: 6| Step: 12
Training loss: 0.5160065019885427
Validation loss: 2.2632271767831234

Epoch: 6| Step: 13
Training loss: 0.8078347666049355
Validation loss: 2.265050781489512

Epoch: 273| Step: 0
Training loss: 0.5867507631226214
Validation loss: 2.2714846774698967

Epoch: 6| Step: 1
Training loss: 0.5069149595189335
Validation loss: 2.2451318673823883

Epoch: 6| Step: 2
Training loss: 0.6188800636535856
Validation loss: 2.264237838264149

Epoch: 6| Step: 3
Training loss: 0.33330986442003163
Validation loss: 2.2851738834323045

Epoch: 6| Step: 4
Training loss: 0.5297063109622012
Validation loss: 2.2493645045169717

Epoch: 6| Step: 5
Training loss: 0.30231414669709056
Validation loss: 2.2431580841490364

Epoch: 6| Step: 6
Training loss: 0.47172446660320916
Validation loss: 2.2863307366661676

Epoch: 6| Step: 7
Training loss: 0.5455037773466578
Validation loss: 2.3073051202431305

Epoch: 6| Step: 8
Training loss: 0.28899162299891584
Validation loss: 2.2819218126054737

Epoch: 6| Step: 9
Training loss: 0.5849629244507939
Validation loss: 2.2870673450238304

Epoch: 6| Step: 10
Training loss: 0.257637108762086
Validation loss: 2.2957947706135022

Epoch: 6| Step: 11
Training loss: 0.3384669906222509
Validation loss: 2.3021201217697116

Epoch: 6| Step: 12
Training loss: 0.19860764815757945
Validation loss: 2.2938131350029547

Epoch: 6| Step: 13
Training loss: 0.5784831097806955
Validation loss: 2.2839677887897554

Epoch: 274| Step: 0
Training loss: 0.42319451711885164
Validation loss: 2.307853748228043

Epoch: 6| Step: 1
Training loss: 0.39475321427281446
Validation loss: 2.295232318659467

Epoch: 6| Step: 2
Training loss: 0.3995598711094088
Validation loss: 2.2803785362370004

Epoch: 6| Step: 3
Training loss: 0.24097628898438125
Validation loss: 2.2655618378035354

Epoch: 6| Step: 4
Training loss: 0.555472852259858
Validation loss: 2.3039403161323606

Epoch: 6| Step: 5
Training loss: 0.5293307979734816
Validation loss: 2.3068041120470544

Epoch: 6| Step: 6
Training loss: 0.23970505310699505
Validation loss: 2.3436228246606383

Epoch: 6| Step: 7
Training loss: 0.46724170574482504
Validation loss: 2.2753754631958714

Epoch: 6| Step: 8
Training loss: 0.2538003260405981
Validation loss: 2.2267719440147844

Epoch: 6| Step: 9
Training loss: 0.6118034245726583
Validation loss: 2.2946872841404287

Epoch: 6| Step: 10
Training loss: 0.39655408575271267
Validation loss: 2.265195793031229

Epoch: 6| Step: 11
Training loss: 0.4970229000720103
Validation loss: 2.2548268055673852

Epoch: 6| Step: 12
Training loss: 0.6039392163752559
Validation loss: 2.2530103379996933

Epoch: 6| Step: 13
Training loss: 0.33745235618987346
Validation loss: 2.270836009302187

Epoch: 275| Step: 0
Training loss: 0.46265456864432497
Validation loss: 2.2550626992544704

Epoch: 6| Step: 1
Training loss: 0.3654027132714461
Validation loss: 2.283663233089696

Epoch: 6| Step: 2
Training loss: 0.4023160461961672
Validation loss: 2.249923125928352

Epoch: 6| Step: 3
Training loss: 0.5075841537007176
Validation loss: 2.2828292493549722

Epoch: 6| Step: 4
Training loss: 0.5193746517194
Validation loss: 2.3042135149956917

Epoch: 6| Step: 5
Training loss: 0.5956689043065277
Validation loss: 2.332415782324855

Epoch: 6| Step: 6
Training loss: 0.5339555287470437
Validation loss: 2.3232661802420447

Epoch: 6| Step: 7
Training loss: 0.3114407229255803
Validation loss: 2.347182648783414

Epoch: 6| Step: 8
Training loss: 0.3489335203126606
Validation loss: 2.3019415457659527

Epoch: 6| Step: 9
Training loss: 0.5119406240966613
Validation loss: 2.3163525817361372

Epoch: 6| Step: 10
Training loss: 0.22998042015512524
Validation loss: 2.2942644611090572

Epoch: 6| Step: 11
Training loss: 0.38683731496419865
Validation loss: 2.2695510798722456

Epoch: 6| Step: 12
Training loss: 0.44268896023117527
Validation loss: 2.251020850527845

Epoch: 6| Step: 13
Training loss: 0.1971195926807541
Validation loss: 2.2447002694827676

Epoch: 276| Step: 0
Training loss: 0.3233864338500891
Validation loss: 2.26454960538069

Epoch: 6| Step: 1
Training loss: 0.5946878254619435
Validation loss: 2.260359935257454

Epoch: 6| Step: 2
Training loss: 0.4406350073793967
Validation loss: 2.264128782529149

Epoch: 6| Step: 3
Training loss: 0.5422816697717362
Validation loss: 2.268035156645093

Epoch: 6| Step: 4
Training loss: 0.5749945816531101
Validation loss: 2.295623428259628

Epoch: 6| Step: 5
Training loss: 0.41678280006675905
Validation loss: 2.304533881672471

Epoch: 6| Step: 6
Training loss: 0.5964647271118629
Validation loss: 2.307341291734265

Epoch: 6| Step: 7
Training loss: 0.34019124691687047
Validation loss: 2.3094881427245437

Epoch: 6| Step: 8
Training loss: 0.3282610293392646
Validation loss: 2.2472579591130306

Epoch: 6| Step: 9
Training loss: 0.40876495902660215
Validation loss: 2.242266122174808

Epoch: 6| Step: 10
Training loss: 0.2297641441377912
Validation loss: 2.223541480833271

Epoch: 6| Step: 11
Training loss: 0.29915828791168986
Validation loss: 2.224339563276221

Epoch: 6| Step: 12
Training loss: 0.3662976785293069
Validation loss: 2.2231477837344973

Epoch: 6| Step: 13
Training loss: 0.4329215328994332
Validation loss: 2.221632540136178

Epoch: 277| Step: 0
Training loss: 0.250524120481078
Validation loss: 2.2751523982491286

Epoch: 6| Step: 1
Training loss: 0.4451516178702851
Validation loss: 2.269632073866936

Epoch: 6| Step: 2
Training loss: 0.4823551981327057
Validation loss: 2.2768508100994507

Epoch: 6| Step: 3
Training loss: 0.47253654477417684
Validation loss: 2.3123601922740056

Epoch: 6| Step: 4
Training loss: 0.4761812529919555
Validation loss: 2.315608273416789

Epoch: 6| Step: 5
Training loss: 0.38592806816159037
Validation loss: 2.2623131103686323

Epoch: 6| Step: 6
Training loss: 0.45859304749729085
Validation loss: 2.258928190984848

Epoch: 6| Step: 7
Training loss: 0.4523329883408736
Validation loss: 2.2679568162604777

Epoch: 6| Step: 8
Training loss: 0.5189611993151833
Validation loss: 2.2366424914204117

Epoch: 6| Step: 9
Training loss: 0.2815958122336233
Validation loss: 2.2536878920971537

Epoch: 6| Step: 10
Training loss: 0.3961844225750573
Validation loss: 2.2188095507674173

Epoch: 6| Step: 11
Training loss: 0.3855948251204864
Validation loss: 2.239887735599557

Epoch: 6| Step: 12
Training loss: 0.38776254911671126
Validation loss: 2.3020953863568296

Epoch: 6| Step: 13
Training loss: 0.60576007356348
Validation loss: 2.2790881837100705

Epoch: 278| Step: 0
Training loss: 0.37156881742504877
Validation loss: 2.2642833750112956

Epoch: 6| Step: 1
Training loss: 0.20835562626456133
Validation loss: 2.2541154268292156

Epoch: 6| Step: 2
Training loss: 0.5088186420181954
Validation loss: 2.2299787052250073

Epoch: 6| Step: 3
Training loss: 0.513651220102197
Validation loss: 2.243101213017337

Epoch: 6| Step: 4
Training loss: 0.4927073110391067
Validation loss: 2.2383821551979945

Epoch: 6| Step: 5
Training loss: 0.5437706987234103
Validation loss: 2.218671601762136

Epoch: 6| Step: 6
Training loss: 0.44673201534273405
Validation loss: 2.2544230462961954

Epoch: 6| Step: 7
Training loss: 0.17415542007445678
Validation loss: 2.2594646431705496

Epoch: 6| Step: 8
Training loss: 0.5183613159787276
Validation loss: 2.23038926369149

Epoch: 6| Step: 9
Training loss: 0.5373080354376168
Validation loss: 2.283717161601739

Epoch: 6| Step: 10
Training loss: 0.45063485556736016
Validation loss: 2.234010786769852

Epoch: 6| Step: 11
Training loss: 0.2740170875732592
Validation loss: 2.2898915871192433

Epoch: 6| Step: 12
Training loss: 0.4262307969854937
Validation loss: 2.2844521477524724

Epoch: 6| Step: 13
Training loss: 0.11844901728429734
Validation loss: 2.2671414104984144

Epoch: 279| Step: 0
Training loss: 0.3790432790362911
Validation loss: 2.312085568231535

Epoch: 6| Step: 1
Training loss: 0.20133862482475393
Validation loss: 2.246009178049655

Epoch: 6| Step: 2
Training loss: 0.5110542700553763
Validation loss: 2.2423880431200107

Epoch: 6| Step: 3
Training loss: 0.2136896345718671
Validation loss: 2.278203669012239

Epoch: 6| Step: 4
Training loss: 0.37498021073578125
Validation loss: 2.2931419564709623

Epoch: 6| Step: 5
Training loss: 0.6061058384279133
Validation loss: 2.2836957478483026

Epoch: 6| Step: 6
Training loss: 0.618627582346563
Validation loss: 2.3034938406767895

Epoch: 6| Step: 7
Training loss: 0.5949046302144556
Validation loss: 2.302913752267608

Epoch: 6| Step: 8
Training loss: 0.4941424644948623
Validation loss: 2.291337969262225

Epoch: 6| Step: 9
Training loss: 0.30330816466894006
Validation loss: 2.3172957414090494

Epoch: 6| Step: 10
Training loss: 0.4602401760488817
Validation loss: 2.3069679775605323

Epoch: 6| Step: 11
Training loss: 0.23278243683640348
Validation loss: 2.3135890175762253

Epoch: 6| Step: 12
Training loss: 0.2976596276399505
Validation loss: 2.3415217953161003

Epoch: 6| Step: 13
Training loss: 0.15261629374320254
Validation loss: 2.355088203768691

Epoch: 280| Step: 0
Training loss: 0.5562392544512154
Validation loss: 2.330670258398652

Epoch: 6| Step: 1
Training loss: 0.4444902089352584
Validation loss: 2.3980397187873117

Epoch: 6| Step: 2
Training loss: 0.492877416114777
Validation loss: 2.3460121946742185

Epoch: 6| Step: 3
Training loss: 0.5597058942488866
Validation loss: 2.3223403400759293

Epoch: 6| Step: 4
Training loss: 0.39392333832308185
Validation loss: 2.3129645659469396

Epoch: 6| Step: 5
Training loss: 0.4876326258301918
Validation loss: 2.3129616220912657

Epoch: 6| Step: 6
Training loss: 0.20560989463538143
Validation loss: 2.2649692006357656

Epoch: 6| Step: 7
Training loss: 0.39325462242072545
Validation loss: 2.255406546027184

Epoch: 6| Step: 8
Training loss: 0.19068571632436257
Validation loss: 2.2499310472649166

Epoch: 6| Step: 9
Training loss: 0.26004396312210803
Validation loss: 2.235683398558234

Epoch: 6| Step: 10
Training loss: 0.33652108535343095
Validation loss: 2.222474769201668

Epoch: 6| Step: 11
Training loss: 0.4158409719141449
Validation loss: 2.2745632728767275

Epoch: 6| Step: 12
Training loss: 0.28003155841263383
Validation loss: 2.3104369060256755

Epoch: 6| Step: 13
Training loss: 0.8075402810174228
Validation loss: 2.303028496383587

Epoch: 281| Step: 0
Training loss: 0.3536663261097938
Validation loss: 2.291929129470574

Epoch: 6| Step: 1
Training loss: 0.6092531864973599
Validation loss: 2.3103824688363486

Epoch: 6| Step: 2
Training loss: 0.36228436929739755
Validation loss: 2.3144380706647802

Epoch: 6| Step: 3
Training loss: 0.3724272010059082
Validation loss: 2.3117559733229105

Epoch: 6| Step: 4
Training loss: 0.4309481594158806
Validation loss: 2.2972116732133703

Epoch: 6| Step: 5
Training loss: 0.22841822349791818
Validation loss: 2.2859599339961547

Epoch: 6| Step: 6
Training loss: 0.34961721741815
Validation loss: 2.2724482403154256

Epoch: 6| Step: 7
Training loss: 0.40923241614688227
Validation loss: 2.2448818817827565

Epoch: 6| Step: 8
Training loss: 0.1739533915978961
Validation loss: 2.3018937636753987

Epoch: 6| Step: 9
Training loss: 0.4199797124731236
Validation loss: 2.2550540388070828

Epoch: 6| Step: 10
Training loss: 0.522618863489218
Validation loss: 2.2896549620509865

Epoch: 6| Step: 11
Training loss: 0.5862941673656894
Validation loss: 2.2997011900124433

Epoch: 6| Step: 12
Training loss: 0.48485298568382224
Validation loss: 2.356573855192398

Epoch: 6| Step: 13
Training loss: 0.15019569520938764
Validation loss: 2.3559762843983556

Epoch: 282| Step: 0
Training loss: 0.5884917977959851
Validation loss: 2.371843186766797

Epoch: 6| Step: 1
Training loss: 0.4886441827454911
Validation loss: 2.352041936755138

Epoch: 6| Step: 2
Training loss: 0.3172413672196273
Validation loss: 2.3251373993155613

Epoch: 6| Step: 3
Training loss: 0.5176590190505957
Validation loss: 2.328390203945259

Epoch: 6| Step: 4
Training loss: 0.15303470348000328
Validation loss: 2.296507002774026

Epoch: 6| Step: 5
Training loss: 0.2643690288266177
Validation loss: 2.2983577167969784

Epoch: 6| Step: 6
Training loss: 0.23111816011667827
Validation loss: 2.2763691437054376

Epoch: 6| Step: 7
Training loss: 0.28655037990552207
Validation loss: 2.2796648502113777

Epoch: 6| Step: 8
Training loss: 0.5083637180263032
Validation loss: 2.2660298507321985

Epoch: 6| Step: 9
Training loss: 0.34490586067600093
Validation loss: 2.291164867542478

Epoch: 6| Step: 10
Training loss: 0.38207198551858085
Validation loss: 2.2870664101686624

Epoch: 6| Step: 11
Training loss: 0.4371658309190949
Validation loss: 2.304846081944765

Epoch: 6| Step: 12
Training loss: 0.5824333696363199
Validation loss: 2.307392074195393

Epoch: 6| Step: 13
Training loss: 0.4427229224400384
Validation loss: 2.311397765394567

Epoch: 283| Step: 0
Training loss: 0.5205961800116727
Validation loss: 2.3018373524912734

Epoch: 6| Step: 1
Training loss: 0.5503790990246665
Validation loss: 2.2488189945313004

Epoch: 6| Step: 2
Training loss: 0.4302450897118358
Validation loss: 2.2574749351589656

Epoch: 6| Step: 3
Training loss: 0.4069053792086519
Validation loss: 2.2207420173200636

Epoch: 6| Step: 4
Training loss: 0.3083678396458292
Validation loss: 2.248064436872048

Epoch: 6| Step: 5
Training loss: 0.35158677547142975
Validation loss: 2.276549039848161

Epoch: 6| Step: 6
Training loss: 0.5353629555337118
Validation loss: 2.294228406940814

Epoch: 6| Step: 7
Training loss: 0.5688939677366069
Validation loss: 2.2916156278354136

Epoch: 6| Step: 8
Training loss: 0.3772018876764751
Validation loss: 2.3442849372553796

Epoch: 6| Step: 9
Training loss: 0.30888964554843995
Validation loss: 2.3334110865258624

Epoch: 6| Step: 10
Training loss: 0.24305737311198322
Validation loss: 2.3202996392927906

Epoch: 6| Step: 11
Training loss: 0.2240624361423843
Validation loss: 2.3103152383578944

Epoch: 6| Step: 12
Training loss: 0.5011553528961965
Validation loss: 2.2977439314378523

Epoch: 6| Step: 13
Training loss: 0.19505556372545288
Validation loss: 2.2756666655159203

Epoch: 284| Step: 0
Training loss: 0.21305032741993274
Validation loss: 2.270867043687416

Epoch: 6| Step: 1
Training loss: 0.16678325789566859
Validation loss: 2.275021967465731

Epoch: 6| Step: 2
Training loss: 0.4092777107471959
Validation loss: 2.239318724613794

Epoch: 6| Step: 3
Training loss: 0.3854512723216134
Validation loss: 2.25544030016467

Epoch: 6| Step: 4
Training loss: 0.4926150296791422
Validation loss: 2.29313246720813

Epoch: 6| Step: 5
Training loss: 0.43048676800967034
Validation loss: 2.3471779959201453

Epoch: 6| Step: 6
Training loss: 0.5412027469209344
Validation loss: 2.3179180548589176

Epoch: 6| Step: 7
Training loss: 0.5523370183941869
Validation loss: 2.319063332876056

Epoch: 6| Step: 8
Training loss: 0.2289549850558049
Validation loss: 2.272058771750996

Epoch: 6| Step: 9
Training loss: 0.39636162798053953
Validation loss: 2.2512871764594986

Epoch: 6| Step: 10
Training loss: 0.4700302443005673
Validation loss: 2.2390748332178525

Epoch: 6| Step: 11
Training loss: 0.512512290621132
Validation loss: 2.2418375707270695

Epoch: 6| Step: 12
Training loss: 0.44571966663794027
Validation loss: 2.2564810808293805

Epoch: 6| Step: 13
Training loss: 0.4982500746344603
Validation loss: 2.2393138550714733

Epoch: 285| Step: 0
Training loss: 0.3435713238616123
Validation loss: 2.23832289265736

Epoch: 6| Step: 1
Training loss: 0.5373239816732585
Validation loss: 2.240399355127189

Epoch: 6| Step: 2
Training loss: 0.440004994055193
Validation loss: 2.2742840357558727

Epoch: 6| Step: 3
Training loss: 0.420597880737645
Validation loss: 2.3013367313392767

Epoch: 6| Step: 4
Training loss: 0.10540621722758349
Validation loss: 2.314066991496804

Epoch: 6| Step: 5
Training loss: 0.3875724347924661
Validation loss: 2.3703766717483945

Epoch: 6| Step: 6
Training loss: 0.4444515538971561
Validation loss: 2.3541291415655645

Epoch: 6| Step: 7
Training loss: 0.4273672923798594
Validation loss: 2.32873351458405

Epoch: 6| Step: 8
Training loss: 0.5334143307642701
Validation loss: 2.305697401114386

Epoch: 6| Step: 9
Training loss: 0.31608039654269987
Validation loss: 2.2565172348220996

Epoch: 6| Step: 10
Training loss: 0.5092735107511708
Validation loss: 2.2172911494409244

Epoch: 6| Step: 11
Training loss: 0.3089693897727222
Validation loss: 2.2660766830239623

Epoch: 6| Step: 12
Training loss: 0.395971652592541
Validation loss: 2.2783204615933346

Epoch: 6| Step: 13
Training loss: 0.5293016890979038
Validation loss: 2.2899134025028838

Epoch: 286| Step: 0
Training loss: 0.4509363757071223
Validation loss: 2.3229108983531135

Epoch: 6| Step: 1
Training loss: 0.17271367192693166
Validation loss: 2.3217945505445767

Epoch: 6| Step: 2
Training loss: 0.3166548611715789
Validation loss: 2.3622461940388955

Epoch: 6| Step: 3
Training loss: 0.3219077001090347
Validation loss: 2.3828887254830637

Epoch: 6| Step: 4
Training loss: 0.5329137722659554
Validation loss: 2.3444613213394905

Epoch: 6| Step: 5
Training loss: 0.37257677186387067
Validation loss: 2.2983541803462213

Epoch: 6| Step: 6
Training loss: 0.5469726475322486
Validation loss: 2.3143556970938572

Epoch: 6| Step: 7
Training loss: 0.47031384908286217
Validation loss: 2.286130728680829

Epoch: 6| Step: 8
Training loss: 0.34466550032269516
Validation loss: 2.2792396930845666

Epoch: 6| Step: 9
Training loss: 0.49738540105880863
Validation loss: 2.265541471158667

Epoch: 6| Step: 10
Training loss: 0.28128986605918943
Validation loss: 2.2945918000598606

Epoch: 6| Step: 11
Training loss: 0.4203224932535548
Validation loss: 2.31999023272255

Epoch: 6| Step: 12
Training loss: 0.447742524413169
Validation loss: 2.302377570547361

Epoch: 6| Step: 13
Training loss: 0.18920806884544125
Validation loss: 2.3294665852470593

Epoch: 287| Step: 0
Training loss: 0.5199875799401438
Validation loss: 2.314995669237713

Epoch: 6| Step: 1
Training loss: 0.3287785130272569
Validation loss: 2.2929921125346246

Epoch: 6| Step: 2
Training loss: 0.3078055879620438
Validation loss: 2.3115821664315206

Epoch: 6| Step: 3
Training loss: 0.41250031355643635
Validation loss: 2.2798113341244237

Epoch: 6| Step: 4
Training loss: 0.41147648091273675
Validation loss: 2.294640441408337

Epoch: 6| Step: 5
Training loss: 0.2780224595011012
Validation loss: 2.3233224694666594

Epoch: 6| Step: 6
Training loss: 0.19118880551987674
Validation loss: 2.3486687852128547

Epoch: 6| Step: 7
Training loss: 0.32693996334588177
Validation loss: 2.32085943172208

Epoch: 6| Step: 8
Training loss: 0.3780804513272531
Validation loss: 2.3585512086339517

Epoch: 6| Step: 9
Training loss: 0.3946793155621975
Validation loss: 2.3382885003817853

Epoch: 6| Step: 10
Training loss: 0.6267877758801115
Validation loss: 2.294183999267023

Epoch: 6| Step: 11
Training loss: 0.39724601914780094
Validation loss: 2.3095776834938087

Epoch: 6| Step: 12
Training loss: 0.4851589933800034
Validation loss: 2.259494171542139

Epoch: 6| Step: 13
Training loss: 0.25822401438368103
Validation loss: 2.270313033615472

Epoch: 288| Step: 0
Training loss: 0.3469139919188584
Validation loss: 2.2419793422981815

Epoch: 6| Step: 1
Training loss: 0.24183751012863522
Validation loss: 2.253429297615586

Epoch: 6| Step: 2
Training loss: 0.5519667508332555
Validation loss: 2.2750230540442025

Epoch: 6| Step: 3
Training loss: 0.2810501872345905
Validation loss: 2.3083307218316595

Epoch: 6| Step: 4
Training loss: 0.4044624395036621
Validation loss: 2.250622469527251

Epoch: 6| Step: 5
Training loss: 0.22542265560305583
Validation loss: 2.296900295006391

Epoch: 6| Step: 6
Training loss: 0.6533983124156838
Validation loss: 2.3243477436468507

Epoch: 6| Step: 7
Training loss: 0.338803079131078
Validation loss: 2.3368048143420457

Epoch: 6| Step: 8
Training loss: 0.22894051982065816
Validation loss: 2.3053260009136136

Epoch: 6| Step: 9
Training loss: 0.4486702265269933
Validation loss: 2.2936951591286583

Epoch: 6| Step: 10
Training loss: 0.43899065902891116
Validation loss: 2.2477807815961306

Epoch: 6| Step: 11
Training loss: 0.4149636951905397
Validation loss: 2.2541109702536377

Epoch: 6| Step: 12
Training loss: 0.5076205551076852
Validation loss: 2.210029865935979

Epoch: 6| Step: 13
Training loss: 0.35127050141409216
Validation loss: 2.2220698599428634

Epoch: 289| Step: 0
Training loss: 0.4394454277212173
Validation loss: 2.2144269503133733

Epoch: 6| Step: 1
Training loss: 0.5833179153947976
Validation loss: 2.2885514938789706

Epoch: 6| Step: 2
Training loss: 0.5238470496529055
Validation loss: 2.286261722444916

Epoch: 6| Step: 3
Training loss: 0.31585711640431
Validation loss: 2.2928138106586746

Epoch: 6| Step: 4
Training loss: 0.3126231308591014
Validation loss: 2.3341410252710895

Epoch: 6| Step: 5
Training loss: 0.4425299696552576
Validation loss: 2.336166206566855

Epoch: 6| Step: 6
Training loss: 0.3513042985277438
Validation loss: 2.317404841460024

Epoch: 6| Step: 7
Training loss: 0.36600954748948095
Validation loss: 2.288558308059386

Epoch: 6| Step: 8
Training loss: 0.23701401164388272
Validation loss: 2.2831927107618353

Epoch: 6| Step: 9
Training loss: 0.2226956483215787
Validation loss: 2.280848993940779

Epoch: 6| Step: 10
Training loss: 0.23723733990247436
Validation loss: 2.264390113139803

Epoch: 6| Step: 11
Training loss: 0.5891794670401489
Validation loss: 2.2471256970439883

Epoch: 6| Step: 12
Training loss: 0.3809576836888198
Validation loss: 2.242739188477733

Epoch: 6| Step: 13
Training loss: 0.11206581585367005
Validation loss: 2.29019354366918

Epoch: 290| Step: 0
Training loss: 0.2110277442036494
Validation loss: 2.2855887638356727

Epoch: 6| Step: 1
Training loss: 0.16790783686964508
Validation loss: 2.28262936274833

Epoch: 6| Step: 2
Training loss: 0.4067019736031753
Validation loss: 2.3165686693827308

Epoch: 6| Step: 3
Training loss: 0.4633037156420223
Validation loss: 2.3585821323203553

Epoch: 6| Step: 4
Training loss: 0.3842181847293973
Validation loss: 2.351819531110244

Epoch: 6| Step: 5
Training loss: 0.4432775951365254
Validation loss: 2.33664643362091

Epoch: 6| Step: 6
Training loss: 0.45725912950139647
Validation loss: 2.2849970785006395

Epoch: 6| Step: 7
Training loss: 0.33159371887917266
Validation loss: 2.2739315067810106

Epoch: 6| Step: 8
Training loss: 0.19696627461389335
Validation loss: 2.293235939752603

Epoch: 6| Step: 9
Training loss: 0.3837584854641635
Validation loss: 2.2751289595715325

Epoch: 6| Step: 10
Training loss: 0.3389531666847048
Validation loss: 2.2975520629671995

Epoch: 6| Step: 11
Training loss: 0.5831645199057608
Validation loss: 2.3081510513684713

Epoch: 6| Step: 12
Training loss: 0.30814969430048245
Validation loss: 2.2797295305720997

Epoch: 6| Step: 13
Training loss: 0.28869102424837356
Validation loss: 2.2751121700237347

Epoch: 291| Step: 0
Training loss: 0.435595881694359
Validation loss: 2.310424670114174

Epoch: 6| Step: 1
Training loss: 0.4323405981138516
Validation loss: 2.303489068403368

Epoch: 6| Step: 2
Training loss: 0.19966229448350295
Validation loss: 2.3235373947637665

Epoch: 6| Step: 3
Training loss: 0.3267418911663963
Validation loss: 2.3388378950452027

Epoch: 6| Step: 4
Training loss: 0.5540360399566636
Validation loss: 2.3113397582760973

Epoch: 6| Step: 5
Training loss: 0.29592400619776316
Validation loss: 2.338480266016478

Epoch: 6| Step: 6
Training loss: 0.35838654625730376
Validation loss: 2.292165763031592

Epoch: 6| Step: 7
Training loss: 0.3343652037495719
Validation loss: 2.248719320348514

Epoch: 6| Step: 8
Training loss: 0.3095009903653127
Validation loss: 2.256614578747908

Epoch: 6| Step: 9
Training loss: 0.36471751559443044
Validation loss: 2.287691165793134

Epoch: 6| Step: 10
Training loss: 0.23652161803045796
Validation loss: 2.305601059830739

Epoch: 6| Step: 11
Training loss: 0.32776910918342866
Validation loss: 2.3565617450177814

Epoch: 6| Step: 12
Training loss: 0.5950282542147926
Validation loss: 2.3767883242032943

Epoch: 6| Step: 13
Training loss: 0.21415569928737332
Validation loss: 2.373453639630138

Epoch: 292| Step: 0
Training loss: 0.34284976641916964
Validation loss: 2.3653143675675086

Epoch: 6| Step: 1
Training loss: 0.5155028574223325
Validation loss: 2.33389008013577

Epoch: 6| Step: 2
Training loss: 0.5024398937146968
Validation loss: 2.3083682943595782

Epoch: 6| Step: 3
Training loss: 0.46462578030762663
Validation loss: 2.3044689699868828

Epoch: 6| Step: 4
Training loss: 0.26201244500593096
Validation loss: 2.279192331528814

Epoch: 6| Step: 5
Training loss: 0.21878632175804144
Validation loss: 2.298440356987666

Epoch: 6| Step: 6
Training loss: 0.2469319419742233
Validation loss: 2.329273041848061

Epoch: 6| Step: 7
Training loss: 0.2758019804254788
Validation loss: 2.3326770854683945

Epoch: 6| Step: 8
Training loss: 0.3299116132234678
Validation loss: 2.3520345271693572

Epoch: 6| Step: 9
Training loss: 0.3924680337219725
Validation loss: 2.3713032471002577

Epoch: 6| Step: 10
Training loss: 0.48278857977416273
Validation loss: 2.3312217838478175

Epoch: 6| Step: 11
Training loss: 0.12908622431283104
Validation loss: 2.322633677948743

Epoch: 6| Step: 12
Training loss: 0.30986541978138377
Validation loss: 2.3215772283128175

Epoch: 6| Step: 13
Training loss: 0.5486731802625963
Validation loss: 2.28960482637752

Epoch: 293| Step: 0
Training loss: 0.4075865766494629
Validation loss: 2.2457342364273187

Epoch: 6| Step: 1
Training loss: 0.33483977948717086
Validation loss: 2.2517128984990946

Epoch: 6| Step: 2
Training loss: 0.5023861809307574
Validation loss: 2.231751309135203

Epoch: 6| Step: 3
Training loss: 0.43296293818504533
Validation loss: 2.2213852637645504

Epoch: 6| Step: 4
Training loss: 0.4630869839261064
Validation loss: 2.26628597689903

Epoch: 6| Step: 5
Training loss: 0.29122160975794587
Validation loss: 2.284296727263703

Epoch: 6| Step: 6
Training loss: 0.31308662666725656
Validation loss: 2.3055508728398206

Epoch: 6| Step: 7
Training loss: 0.34020934773839157
Validation loss: 2.3397901679105297

Epoch: 6| Step: 8
Training loss: 0.24946025608812278
Validation loss: 2.3703316384488127

Epoch: 6| Step: 9
Training loss: 0.5671397228452918
Validation loss: 2.3334984052590015

Epoch: 6| Step: 10
Training loss: 0.38503430275627554
Validation loss: 2.236093659412349

Epoch: 6| Step: 11
Training loss: 0.3841023610212564
Validation loss: 2.2593074197939034

Epoch: 6| Step: 12
Training loss: 0.32434087774113274
Validation loss: 2.2517794303098313

Epoch: 6| Step: 13
Training loss: 0.22113518073979094
Validation loss: 2.2517792703512147

Epoch: 294| Step: 0
Training loss: 0.33179835959385984
Validation loss: 2.2869769178752595

Epoch: 6| Step: 1
Training loss: 0.4091017837837063
Validation loss: 2.313604088516851

Epoch: 6| Step: 2
Training loss: 0.1885607635107047
Validation loss: 2.401197516011206

Epoch: 6| Step: 3
Training loss: 0.3757961087848138
Validation loss: 2.420546958748984

Epoch: 6| Step: 4
Training loss: 0.3308101414751898
Validation loss: 2.4770433895772594

Epoch: 6| Step: 5
Training loss: 0.43305279089919474
Validation loss: 2.430217848451643

Epoch: 6| Step: 6
Training loss: 0.3970196685543063
Validation loss: 2.333174814569

Epoch: 6| Step: 7
Training loss: 0.5647511734817289
Validation loss: 2.265951401420334

Epoch: 6| Step: 8
Training loss: 0.43675242995321484
Validation loss: 2.256465789126585

Epoch: 6| Step: 9
Training loss: 0.32303107706209055
Validation loss: 2.2619551574873413

Epoch: 6| Step: 10
Training loss: 0.43315556009654743
Validation loss: 2.2524236394889923

Epoch: 6| Step: 11
Training loss: 0.34168795348744907
Validation loss: 2.2756279095072296

Epoch: 6| Step: 12
Training loss: 0.35699879772186854
Validation loss: 2.320753438819716

Epoch: 6| Step: 13
Training loss: 0.1153145204279192
Validation loss: 2.3447874796015866

Epoch: 295| Step: 0
Training loss: 0.5481697015574898
Validation loss: 2.3423796965090853

Epoch: 6| Step: 1
Training loss: 0.23584725188630962
Validation loss: 2.3001980745754285

Epoch: 6| Step: 2
Training loss: 0.48854750431154587
Validation loss: 2.2862434257244555

Epoch: 6| Step: 3
Training loss: 0.5049000484394753
Validation loss: 2.26466776223131

Epoch: 6| Step: 4
Training loss: 0.440695722464024
Validation loss: 2.271590039504958

Epoch: 6| Step: 5
Training loss: 0.3200270613761378
Validation loss: 2.281791350822616

Epoch: 6| Step: 6
Training loss: 0.3112370959828048
Validation loss: 2.265443748661047

Epoch: 6| Step: 7
Training loss: 0.3687041593604135
Validation loss: 2.2750289072478513

Epoch: 6| Step: 8
Training loss: 0.4996480000756217
Validation loss: 2.3159821491504586

Epoch: 6| Step: 9
Training loss: 0.3134700976504325
Validation loss: 2.316732867819116

Epoch: 6| Step: 10
Training loss: 0.33317127858211276
Validation loss: 2.31794020979311

Epoch: 6| Step: 11
Training loss: 0.1891395293703927
Validation loss: 2.3341148509903284

Epoch: 6| Step: 12
Training loss: 0.34594756713940195
Validation loss: 2.3656754975760825

Epoch: 6| Step: 13
Training loss: 0.3088490239123161
Validation loss: 2.336885952299548

Epoch: 296| Step: 0
Training loss: 0.36361420662794924
Validation loss: 2.2988153169547174

Epoch: 6| Step: 1
Training loss: 0.21599833020860698
Validation loss: 2.273809431667062

Epoch: 6| Step: 2
Training loss: 0.45497138281840643
Validation loss: 2.281212209516918

Epoch: 6| Step: 3
Training loss: 0.3066169219362265
Validation loss: 2.262349543409669

Epoch: 6| Step: 4
Training loss: 0.5273330122243014
Validation loss: 2.258923730852966

Epoch: 6| Step: 5
Training loss: 0.45073961630935105
Validation loss: 2.250002990912087

Epoch: 6| Step: 6
Training loss: 0.3408441835804468
Validation loss: 2.2901101916939623

Epoch: 6| Step: 7
Training loss: 0.28365059064914233
Validation loss: 2.330378047096052

Epoch: 6| Step: 8
Training loss: 0.4183683891286966
Validation loss: 2.357026008511675

Epoch: 6| Step: 9
Training loss: 0.36378734980216587
Validation loss: 2.3789669319890585

Epoch: 6| Step: 10
Training loss: 0.32390701290175106
Validation loss: 2.3936692153457826

Epoch: 6| Step: 11
Training loss: 0.22870752639898037
Validation loss: 2.3477977470964486

Epoch: 6| Step: 12
Training loss: 0.3322573845418002
Validation loss: 2.2994799006284437

Epoch: 6| Step: 13
Training loss: 0.3476796624518995
Validation loss: 2.2785412884943455

Epoch: 297| Step: 0
Training loss: 0.3645324898644335
Validation loss: 2.2613117389425628

Epoch: 6| Step: 1
Training loss: 0.22399532304664502
Validation loss: 2.2653934822985256

Epoch: 6| Step: 2
Training loss: 0.3810518609767711
Validation loss: 2.322662621785281

Epoch: 6| Step: 3
Training loss: 0.47907980532410754
Validation loss: 2.2859144511150187

Epoch: 6| Step: 4
Training loss: 0.3050578995959366
Validation loss: 2.335095222346004

Epoch: 6| Step: 5
Training loss: 0.22084917451763839
Validation loss: 2.375291207405482

Epoch: 6| Step: 6
Training loss: 0.3280242810755101
Validation loss: 2.3623812518508407

Epoch: 6| Step: 7
Training loss: 0.5281513105982726
Validation loss: 2.3908532189400638

Epoch: 6| Step: 8
Training loss: 0.24043955995695135
Validation loss: 2.245678283873542

Epoch: 6| Step: 9
Training loss: 0.49480080512458535
Validation loss: 2.1955373665878075

Epoch: 6| Step: 10
Training loss: 0.480941260994228
Validation loss: 2.119137482659464

Epoch: 6| Step: 11
Training loss: 0.4102926663197741
Validation loss: 2.1259017095268025

Epoch: 6| Step: 12
Training loss: 0.36875689710212217
Validation loss: 2.1294473969386845

Epoch: 6| Step: 13
Training loss: 0.6743102629296779
Validation loss: 2.1876444943194384

Epoch: 298| Step: 0
Training loss: 0.5604633441852584
Validation loss: 2.2673967674784397

Epoch: 6| Step: 1
Training loss: 0.3617722745640227
Validation loss: 2.3443693905364182

Epoch: 6| Step: 2
Training loss: 0.32078710146554706
Validation loss: 2.3770036729677626

Epoch: 6| Step: 3
Training loss: 0.5430753863888154
Validation loss: 2.425885238348613

Epoch: 6| Step: 4
Training loss: 0.4144274704567683
Validation loss: 2.3882036975895313

Epoch: 6| Step: 5
Training loss: 0.4239296857385593
Validation loss: 2.2926116971149506

Epoch: 6| Step: 6
Training loss: 0.2505024539737844
Validation loss: 2.216944025817074

Epoch: 6| Step: 7
Training loss: 0.4350065977319689
Validation loss: 2.1706368402199767

Epoch: 6| Step: 8
Training loss: 0.5281921344048659
Validation loss: 2.2100293926548225

Epoch: 6| Step: 9
Training loss: 0.38301692097837214
Validation loss: 2.1867362978975167

Epoch: 6| Step: 10
Training loss: 0.3441484915865854
Validation loss: 2.240613457697831

Epoch: 6| Step: 11
Training loss: 0.4067652625835233
Validation loss: 2.3022435899563702

Epoch: 6| Step: 12
Training loss: 0.5559825822328359
Validation loss: 2.3567491585557385

Epoch: 6| Step: 13
Training loss: 0.41630001824369994
Validation loss: 2.4283275165939058

Epoch: 299| Step: 0
Training loss: 0.44277529116639236
Validation loss: 2.426251073644113

Epoch: 6| Step: 1
Training loss: 0.44628251820112885
Validation loss: 2.4773010682583294

Epoch: 6| Step: 2
Training loss: 0.3905132133749178
Validation loss: 2.4190291214180606

Epoch: 6| Step: 3
Training loss: 0.3896571758313415
Validation loss: 2.329654264845407

Epoch: 6| Step: 4
Training loss: 0.35907214298695944
Validation loss: 2.253292580069951

Epoch: 6| Step: 5
Training loss: 0.4315359411554397
Validation loss: 2.2282561369980205

Epoch: 6| Step: 6
Training loss: 0.3900437035282105
Validation loss: 2.209024348682069

Epoch: 6| Step: 7
Training loss: 0.36225403382771626
Validation loss: 2.220246541258346

Epoch: 6| Step: 8
Training loss: 0.42677151725639134
Validation loss: 2.218648537016242

Epoch: 6| Step: 9
Training loss: 0.5034020437095298
Validation loss: 2.2745454985763742

Epoch: 6| Step: 10
Training loss: 0.30972630274060897
Validation loss: 2.3318380228134474

Epoch: 6| Step: 11
Training loss: 0.5068778900835498
Validation loss: 2.354546569551959

Epoch: 6| Step: 12
Training loss: 0.2516076136351328
Validation loss: 2.3807000463055834

Epoch: 6| Step: 13
Training loss: 0.4532532674836822
Validation loss: 2.3628202320393683

Epoch: 300| Step: 0
Training loss: 0.18780517578125
Validation loss: 2.3197652315633763

Epoch: 6| Step: 1
Training loss: 0.27003451369593107
Validation loss: 2.2985767977049343

Epoch: 6| Step: 2
Training loss: 0.18809875610973043
Validation loss: 2.259802926695926

Epoch: 6| Step: 3
Training loss: 0.36165519551501096
Validation loss: 2.2603339840816266

Epoch: 6| Step: 4
Training loss: 0.605979064491648
Validation loss: 2.207915003139206

Epoch: 6| Step: 5
Training loss: 0.30612457490161743
Validation loss: 2.2193316237923786

Epoch: 6| Step: 6
Training loss: 0.26152639294778385
Validation loss: 2.2251398307845305

Epoch: 6| Step: 7
Training loss: 0.41351539526766706
Validation loss: 2.2754154107324163

Epoch: 6| Step: 8
Training loss: 0.38773643602249647
Validation loss: 2.3152617326589473

Epoch: 6| Step: 9
Training loss: 0.2597458480534337
Validation loss: 2.4006308286706814

Epoch: 6| Step: 10
Training loss: 0.5531128574913563
Validation loss: 2.370916974889569

Epoch: 6| Step: 11
Training loss: 0.40565121978868834
Validation loss: 2.4133730432578875

Epoch: 6| Step: 12
Training loss: 0.30950620210022906
Validation loss: 2.41399948240169

Epoch: 6| Step: 13
Training loss: 0.37483774092112476
Validation loss: 2.4009206838043538

Epoch: 301| Step: 0
Training loss: 0.3077819504076769
Validation loss: 2.368658520003029

Epoch: 6| Step: 1
Training loss: 0.2910480225214242
Validation loss: 2.3366539583797845

Epoch: 6| Step: 2
Training loss: 0.1908501116659104
Validation loss: 2.3392191363122645

Epoch: 6| Step: 3
Training loss: 0.26987004755519617
Validation loss: 2.287124024668418

Epoch: 6| Step: 4
Training loss: 0.43188386855563277
Validation loss: 2.3162224278223635

Epoch: 6| Step: 5
Training loss: 0.435276854425579
Validation loss: 2.298466712214632

Epoch: 6| Step: 6
Training loss: 0.4012123793200128
Validation loss: 2.312129200765709

Epoch: 6| Step: 7
Training loss: 0.4640976022359205
Validation loss: 2.329660114767738

Epoch: 6| Step: 8
Training loss: 0.4238243278649749
Validation loss: 2.3455245084129412

Epoch: 6| Step: 9
Training loss: 0.250659787244275
Validation loss: 2.3647137128424744

Epoch: 6| Step: 10
Training loss: 0.4495044628935901
Validation loss: 2.378826445062586

Epoch: 6| Step: 11
Training loss: 0.22240658197328597
Validation loss: 2.3859690329246797

Epoch: 6| Step: 12
Training loss: 0.34999140320165506
Validation loss: 2.4335865086549946

Epoch: 6| Step: 13
Training loss: 0.4931632013596674
Validation loss: 2.43469168005841

Epoch: 302| Step: 0
Training loss: 0.47382393353173685
Validation loss: 2.3796343602878274

Epoch: 6| Step: 1
Training loss: 0.3320370168746089
Validation loss: 2.3432928267023874

Epoch: 6| Step: 2
Training loss: 0.32717375016855854
Validation loss: 2.308224931073435

Epoch: 6| Step: 3
Training loss: 0.20607578476929128
Validation loss: 2.283346285924363

Epoch: 6| Step: 4
Training loss: 0.38172469994447433
Validation loss: 2.264250841901688

Epoch: 6| Step: 5
Training loss: 0.4742333763418466
Validation loss: 2.2457587707033158

Epoch: 6| Step: 6
Training loss: 0.3919373021953353
Validation loss: 2.2557413723162454

Epoch: 6| Step: 7
Training loss: 0.3626261721739682
Validation loss: 2.2720401733493736

Epoch: 6| Step: 8
Training loss: 0.3390463539533366
Validation loss: 2.32614718594632

Epoch: 6| Step: 9
Training loss: 0.4580866373713389
Validation loss: 2.3124276759337667

Epoch: 6| Step: 10
Training loss: 0.24018322004574272
Validation loss: 2.3728783028424605

Epoch: 6| Step: 11
Training loss: 0.2810842237400941
Validation loss: 2.384894706779681

Epoch: 6| Step: 12
Training loss: 0.2544015455102684
Validation loss: 2.3677426925834113

Epoch: 6| Step: 13
Training loss: 0.26987043406735123
Validation loss: 2.3819400593542777

Epoch: 303| Step: 0
Training loss: 0.298045786084427
Validation loss: 2.378432559379349

Epoch: 6| Step: 1
Training loss: 0.17109527151746368
Validation loss: 2.3319720202687346

Epoch: 6| Step: 2
Training loss: 0.413998508906789
Validation loss: 2.2905044681310214

Epoch: 6| Step: 3
Training loss: 0.2576019843693309
Validation loss: 2.283707394629094

Epoch: 6| Step: 4
Training loss: 0.4154447300836907
Validation loss: 2.321651194236981

Epoch: 6| Step: 5
Training loss: 0.3570739637070727
Validation loss: 2.3410018308469356

Epoch: 6| Step: 6
Training loss: 0.36300283448502435
Validation loss: 2.371677197491272

Epoch: 6| Step: 7
Training loss: 0.1942702139127809
Validation loss: 2.374572154066586

Epoch: 6| Step: 8
Training loss: 0.3030403313910043
Validation loss: 2.381348794701715

Epoch: 6| Step: 9
Training loss: 0.5461381034684818
Validation loss: 2.4219892429236793

Epoch: 6| Step: 10
Training loss: 0.4424490300150113
Validation loss: 2.4106270897982225

Epoch: 6| Step: 11
Training loss: 0.23021753812025372
Validation loss: 2.3651043399820906

Epoch: 6| Step: 12
Training loss: 0.49150719629221534
Validation loss: 2.345091993819454

Epoch: 6| Step: 13
Training loss: 0.23854232774806697
Validation loss: 2.303533045730675

Epoch: 304| Step: 0
Training loss: 0.2943088779781496
Validation loss: 2.27559135249122

Epoch: 6| Step: 1
Training loss: 0.4886214177636368
Validation loss: 2.2131996607670534

Epoch: 6| Step: 2
Training loss: 0.4221056907898291
Validation loss: 2.1897211579187954

Epoch: 6| Step: 3
Training loss: 0.24538533107581564
Validation loss: 2.23148597638408

Epoch: 6| Step: 4
Training loss: 0.3083768879353687
Validation loss: 2.23514928466876

Epoch: 6| Step: 5
Training loss: 0.5496420475751892
Validation loss: 2.2837148833374457

Epoch: 6| Step: 6
Training loss: 0.2884024998268825
Validation loss: 2.290014142859119

Epoch: 6| Step: 7
Training loss: 0.2584876266262981
Validation loss: 2.288203248018727

Epoch: 6| Step: 8
Training loss: 0.42966513142016766
Validation loss: 2.309740155180299

Epoch: 6| Step: 9
Training loss: 0.22815349609903265
Validation loss: 2.3226750574358728

Epoch: 6| Step: 10
Training loss: 0.278520425163946
Validation loss: 2.3633805242840773

Epoch: 6| Step: 11
Training loss: 0.4248388868574776
Validation loss: 2.3933687517629925

Epoch: 6| Step: 12
Training loss: 0.31050313485600955
Validation loss: 2.351125652125597

Epoch: 6| Step: 13
Training loss: 0.1846545597334109
Validation loss: 2.3444787044559128

Epoch: 305| Step: 0
Training loss: 0.31069606819992324
Validation loss: 2.323226601409228

Epoch: 6| Step: 1
Training loss: 0.29184743552980597
Validation loss: 2.346182569169346

Epoch: 6| Step: 2
Training loss: 0.43174329891537727
Validation loss: 2.3601779029312047

Epoch: 6| Step: 3
Training loss: 0.26068077364255227
Validation loss: 2.3714761849459647

Epoch: 6| Step: 4
Training loss: 0.4520883870464945
Validation loss: 2.410047114784883

Epoch: 6| Step: 5
Training loss: 0.2632564238663832
Validation loss: 2.4442500910058227

Epoch: 6| Step: 6
Training loss: 0.20276314342032883
Validation loss: 2.46629806187153

Epoch: 6| Step: 7
Training loss: 0.4289358500566061
Validation loss: 2.437630640677615

Epoch: 6| Step: 8
Training loss: 0.26767421305829253
Validation loss: 2.37371298001436

Epoch: 6| Step: 9
Training loss: 0.34599480473953614
Validation loss: 2.3833869665229392

Epoch: 6| Step: 10
Training loss: 0.293146778692556
Validation loss: 2.3446546355107256

Epoch: 6| Step: 11
Training loss: 0.4274163479134738
Validation loss: 2.345966436868073

Epoch: 6| Step: 12
Training loss: 0.25184512226200906
Validation loss: 2.325471614586931

Epoch: 6| Step: 13
Training loss: 0.3939667997992022
Validation loss: 2.3268877458080213

Epoch: 306| Step: 0
Training loss: 0.2930279608337784
Validation loss: 2.28012431689757

Epoch: 6| Step: 1
Training loss: 0.1762466098750196
Validation loss: 2.316557364881667

Epoch: 6| Step: 2
Training loss: 0.21486897753940895
Validation loss: 2.2943660931455634

Epoch: 6| Step: 3
Training loss: 0.19849931550088085
Validation loss: 2.324532286419699

Epoch: 6| Step: 4
Training loss: 0.5776433742781463
Validation loss: 2.3516032464408267

Epoch: 6| Step: 5
Training loss: 0.27263033123391933
Validation loss: 2.3124706008137648

Epoch: 6| Step: 6
Training loss: 0.4020348446355802
Validation loss: 2.3280089699681223

Epoch: 6| Step: 7
Training loss: 0.3738107499855151
Validation loss: 2.326376415307608

Epoch: 6| Step: 8
Training loss: 0.2898917803593537
Validation loss: 2.3088158547368662

Epoch: 6| Step: 9
Training loss: 0.35850194948589437
Validation loss: 2.2974756998549024

Epoch: 6| Step: 10
Training loss: 0.4874268342401878
Validation loss: 2.3210404031410428

Epoch: 6| Step: 11
Training loss: 0.3535195239784664
Validation loss: 2.304167118490436

Epoch: 6| Step: 12
Training loss: 0.1988544218139317
Validation loss: 2.321695581162804

Epoch: 6| Step: 13
Training loss: 0.154260136057205
Validation loss: 2.3398014094697492

Epoch: 307| Step: 0
Training loss: 0.2181571266075831
Validation loss: 2.367686757772591

Epoch: 6| Step: 1
Training loss: 0.3708072158460122
Validation loss: 2.3702248391175065

Epoch: 6| Step: 2
Training loss: 0.3931533243500874
Validation loss: 2.395070453616034

Epoch: 6| Step: 3
Training loss: 0.1519424459240051
Validation loss: 2.3235553978147565

Epoch: 6| Step: 4
Training loss: 0.36434919013976036
Validation loss: 2.3004797178283605

Epoch: 6| Step: 5
Training loss: 0.33925690900630695
Validation loss: 2.263357267295652

Epoch: 6| Step: 6
Training loss: 0.3335658680433263
Validation loss: 2.2493116973549383

Epoch: 6| Step: 7
Training loss: 0.3605778508296671
Validation loss: 2.281427008796022

Epoch: 6| Step: 8
Training loss: 0.35370957339027453
Validation loss: 2.2664842751927585

Epoch: 6| Step: 9
Training loss: 0.2779975089923829
Validation loss: 2.2769713273081

Epoch: 6| Step: 10
Training loss: 0.2609539957600154
Validation loss: 2.2984566749787962

Epoch: 6| Step: 11
Training loss: 0.3976659035400898
Validation loss: 2.306150099877797

Epoch: 6| Step: 12
Training loss: 0.31746440132197495
Validation loss: 2.295410080862277

Epoch: 6| Step: 13
Training loss: 0.36909712681490475
Validation loss: 2.334502692020074

Epoch: 308| Step: 0
Training loss: 0.1947294592761465
Validation loss: 2.3093614884267573

Epoch: 6| Step: 1
Training loss: 0.37884139459600397
Validation loss: 2.31627693251768

Epoch: 6| Step: 2
Training loss: 0.509584796739142
Validation loss: 2.2916425716740623

Epoch: 6| Step: 3
Training loss: 0.3744603884060355
Validation loss: 2.2852920277331856

Epoch: 6| Step: 4
Training loss: 0.32268825907953186
Validation loss: 2.2338814052888654

Epoch: 6| Step: 5
Training loss: 0.18909470583362545
Validation loss: 2.2325964051026

Epoch: 6| Step: 6
Training loss: 0.21984061777775077
Validation loss: 2.2440376184915056

Epoch: 6| Step: 7
Training loss: 0.21940861055956773
Validation loss: 2.30982226382598

Epoch: 6| Step: 8
Training loss: 0.37437486199581804
Validation loss: 2.335290690653615

Epoch: 6| Step: 9
Training loss: 0.3815223205931254
Validation loss: 2.3407761113502037

Epoch: 6| Step: 10
Training loss: 0.40849284791580226
Validation loss: 2.31916791734535

Epoch: 6| Step: 11
Training loss: 0.4286648805943463
Validation loss: 2.331773535064736

Epoch: 6| Step: 12
Training loss: 0.34312842264882965
Validation loss: 2.296243080224614

Epoch: 6| Step: 13
Training loss: 0.1359878553650599
Validation loss: 2.3359176860433637

Epoch: 309| Step: 0
Training loss: 0.36222846779496537
Validation loss: 2.3491055549521014

Epoch: 6| Step: 1
Training loss: 0.345247172739771
Validation loss: 2.350554814820196

Epoch: 6| Step: 2
Training loss: 0.31042859686043933
Validation loss: 2.321377690323444

Epoch: 6| Step: 3
Training loss: 0.38639478889371204
Validation loss: 2.333362534848616

Epoch: 6| Step: 4
Training loss: 0.359665690903464
Validation loss: 2.328505331993386

Epoch: 6| Step: 5
Training loss: 0.1988513681881917
Validation loss: 2.308208797648345

Epoch: 6| Step: 6
Training loss: 0.20086259121955377
Validation loss: 2.3243134297745653

Epoch: 6| Step: 7
Training loss: 0.20154776223588697
Validation loss: 2.3249101715606493

Epoch: 6| Step: 8
Training loss: 0.3123511913762302
Validation loss: 2.299658185082091

Epoch: 6| Step: 9
Training loss: 0.2857748402773027
Validation loss: 2.309244320216936

Epoch: 6| Step: 10
Training loss: 0.4747587369262532
Validation loss: 2.3351531224119086

Epoch: 6| Step: 11
Training loss: 0.2860854568612832
Validation loss: 2.36361133206287

Epoch: 6| Step: 12
Training loss: 0.3777622768823164
Validation loss: 2.3615969315726435

Epoch: 6| Step: 13
Training loss: 0.12994060091233267
Validation loss: 2.34911630340008

Epoch: 310| Step: 0
Training loss: 0.26750067822201035
Validation loss: 2.3370962879106774

Epoch: 6| Step: 1
Training loss: 0.33280381473437654
Validation loss: 2.3490325408150365

Epoch: 6| Step: 2
Training loss: 0.2877344735420135
Validation loss: 2.3382845676819963

Epoch: 6| Step: 3
Training loss: 0.13175926804834168
Validation loss: 2.309270342321828

Epoch: 6| Step: 4
Training loss: 0.44171066252487123
Validation loss: 2.286899544730012

Epoch: 6| Step: 5
Training loss: 0.31267811944170576
Validation loss: 2.3057997555652743

Epoch: 6| Step: 6
Training loss: 0.3487756794359131
Validation loss: 2.307982572405682

Epoch: 6| Step: 7
Training loss: 0.2512819532458813
Validation loss: 2.3247187620436387

Epoch: 6| Step: 8
Training loss: 0.23283245781986703
Validation loss: 2.3294092267297457

Epoch: 6| Step: 9
Training loss: 0.4395774665398836
Validation loss: 2.339021571878512

Epoch: 6| Step: 10
Training loss: 0.3901048630562624
Validation loss: 2.364086968720854

Epoch: 6| Step: 11
Training loss: 0.24773697003918463
Validation loss: 2.361358001296604

Epoch: 6| Step: 12
Training loss: 0.17558624259065084
Validation loss: 2.402579934146662

Epoch: 6| Step: 13
Training loss: 0.3015816430454437
Validation loss: 2.3541248421997

Epoch: 311| Step: 0
Training loss: 0.27175151936651154
Validation loss: 2.4302153462238194

Epoch: 6| Step: 1
Training loss: 0.24943612254304143
Validation loss: 2.4241077749330797

Epoch: 6| Step: 2
Training loss: 0.27091669517549405
Validation loss: 2.3744859543919117

Epoch: 6| Step: 3
Training loss: 0.36154098426942316
Validation loss: 2.311905479890135

Epoch: 6| Step: 4
Training loss: 0.4676766345179021
Validation loss: 2.295354408307059

Epoch: 6| Step: 5
Training loss: 0.26652953463930573
Validation loss: 2.2443656025020595

Epoch: 6| Step: 6
Training loss: 0.20143668328799327
Validation loss: 2.253960652196984

Epoch: 6| Step: 7
Training loss: 0.2969253146048576
Validation loss: 2.22906908882246

Epoch: 6| Step: 8
Training loss: 0.21498711744237062
Validation loss: 2.2234622732247606

Epoch: 6| Step: 9
Training loss: 0.345881507670314
Validation loss: 2.283053172792099

Epoch: 6| Step: 10
Training loss: 0.3147712425247621
Validation loss: 2.3258145513890303

Epoch: 6| Step: 11
Training loss: 0.2704266450482968
Validation loss: 2.3367345140763423

Epoch: 6| Step: 12
Training loss: 0.4918924082834622
Validation loss: 2.35599466633734

Epoch: 6| Step: 13
Training loss: 0.18276178275947885
Validation loss: 2.3789691788417273

Epoch: 312| Step: 0
Training loss: 0.2641776003339852
Validation loss: 2.381947607312179

Epoch: 6| Step: 1
Training loss: 0.48435411100567605
Validation loss: 2.360557228990934

Epoch: 6| Step: 2
Training loss: 0.3185781651492699
Validation loss: 2.336619900108501

Epoch: 6| Step: 3
Training loss: 0.3454339439563814
Validation loss: 2.3554638000511368

Epoch: 6| Step: 4
Training loss: 0.22717010479987826
Validation loss: 2.2974776090752282

Epoch: 6| Step: 5
Training loss: 0.3742140042953769
Validation loss: 2.3088889159489585

Epoch: 6| Step: 6
Training loss: 0.1546519334922591
Validation loss: 2.3290746788632988

Epoch: 6| Step: 7
Training loss: 0.363245829014155
Validation loss: 2.2986875493114596

Epoch: 6| Step: 8
Training loss: 0.19134140862629329
Validation loss: 2.331526364984263

Epoch: 6| Step: 9
Training loss: 0.2510257331387243
Validation loss: 2.363886204372228

Epoch: 6| Step: 10
Training loss: 0.3776228099912284
Validation loss: 2.351955942486803

Epoch: 6| Step: 11
Training loss: 0.2991233439521204
Validation loss: 2.374871125796854

Epoch: 6| Step: 12
Training loss: 0.12893439476944818
Validation loss: 2.4086871047596334

Epoch: 6| Step: 13
Training loss: 0.3406413135646715
Validation loss: 2.3667293183548006

Epoch: 313| Step: 0
Training loss: 0.3287515335264809
Validation loss: 2.3772379203325573

Epoch: 6| Step: 1
Training loss: 0.12977869837232234
Validation loss: 2.3455605659575074

Epoch: 6| Step: 2
Training loss: 0.33891661005994367
Validation loss: 2.3161030254617203

Epoch: 6| Step: 3
Training loss: 0.2578133814247554
Validation loss: 2.332104177522111

Epoch: 6| Step: 4
Training loss: 0.17692092619401228
Validation loss: 2.354189225144204

Epoch: 6| Step: 5
Training loss: 0.34577882875335153
Validation loss: 2.3270944165776783

Epoch: 6| Step: 6
Training loss: 0.19257406226586865
Validation loss: 2.3203496868199904

Epoch: 6| Step: 7
Training loss: 0.28524760520424597
Validation loss: 2.3135527321193314

Epoch: 6| Step: 8
Training loss: 0.3659195821791162
Validation loss: 2.3045276940310653

Epoch: 6| Step: 9
Training loss: 0.49398273463522085
Validation loss: 2.3741924465173763

Epoch: 6| Step: 10
Training loss: 0.37919132087886304
Validation loss: 2.4054777719838407

Epoch: 6| Step: 11
Training loss: 0.1549941015467127
Validation loss: 2.419783128032729

Epoch: 6| Step: 12
Training loss: 0.19681814636811903
Validation loss: 2.443190810211221

Epoch: 6| Step: 13
Training loss: 0.3031096439797912
Validation loss: 2.43461409860293

Epoch: 314| Step: 0
Training loss: 0.3138732539257126
Validation loss: 2.447310336251994

Epoch: 6| Step: 1
Training loss: 0.2128076829239062
Validation loss: 2.3859831567276073

Epoch: 6| Step: 2
Training loss: 0.4183710248021452
Validation loss: 2.3888008363853577

Epoch: 6| Step: 3
Training loss: 0.39165045606600485
Validation loss: 2.3331028880164557

Epoch: 6| Step: 4
Training loss: 0.20610237473725854
Validation loss: 2.327010796630882

Epoch: 6| Step: 5
Training loss: 0.2728590022870242
Validation loss: 2.3190253886251124

Epoch: 6| Step: 6
Training loss: 0.37626993202566333
Validation loss: 2.3035021854538966

Epoch: 6| Step: 7
Training loss: 0.29049995357362046
Validation loss: 2.308015291051051

Epoch: 6| Step: 8
Training loss: 0.21246021403185825
Validation loss: 2.2998653258521884

Epoch: 6| Step: 9
Training loss: 0.1288988226860474
Validation loss: 2.347744147802884

Epoch: 6| Step: 10
Training loss: 0.2048776100450944
Validation loss: 2.314790209686149

Epoch: 6| Step: 11
Training loss: 0.38349107040095537
Validation loss: 2.3838568792718196

Epoch: 6| Step: 12
Training loss: 0.27256852080289223
Validation loss: 2.361991821418693

Epoch: 6| Step: 13
Training loss: 0.3851707184958237
Validation loss: 2.3672761280849572

Epoch: 315| Step: 0
Training loss: 0.1837393406611312
Validation loss: 2.34065550375407

Epoch: 6| Step: 1
Training loss: 0.33795435530456097
Validation loss: 2.318052701034212

Epoch: 6| Step: 2
Training loss: 0.23496518531568125
Validation loss: 2.3615171393029746

Epoch: 6| Step: 3
Training loss: 0.284826715350253
Validation loss: 2.353282255600712

Epoch: 6| Step: 4
Training loss: 0.22531510481208317
Validation loss: 2.3904263347297583

Epoch: 6| Step: 5
Training loss: 0.40491747562845526
Validation loss: 2.370773418941162

Epoch: 6| Step: 6
Training loss: 0.16479865175900513
Validation loss: 2.3722003585047595

Epoch: 6| Step: 7
Training loss: 0.3092186792960527
Validation loss: 2.3707911357465274

Epoch: 6| Step: 8
Training loss: 0.2590280544909061
Validation loss: 2.334262123217209

Epoch: 6| Step: 9
Training loss: 0.3267963621539953
Validation loss: 2.329318295532867

Epoch: 6| Step: 10
Training loss: 0.2538567861647001
Validation loss: 2.3392092936666447

Epoch: 6| Step: 11
Training loss: 0.2941191656585365
Validation loss: 2.337277245415911

Epoch: 6| Step: 12
Training loss: 0.3157030580327511
Validation loss: 2.333352725179871

Epoch: 6| Step: 13
Training loss: 0.4486107069721639
Validation loss: 2.3285631402213482

Epoch: 316| Step: 0
Training loss: 0.33803851689232034
Validation loss: 2.406431370007152

Epoch: 6| Step: 1
Training loss: 0.3069380757134782
Validation loss: 2.450424889375658

Epoch: 6| Step: 2
Training loss: 0.2903080216586935
Validation loss: 2.467042693212003

Epoch: 6| Step: 3
Training loss: 0.3057137835833369
Validation loss: 2.4458856326084017

Epoch: 6| Step: 4
Training loss: 0.3495771297310571
Validation loss: 2.362700303764405

Epoch: 6| Step: 5
Training loss: 0.3628340398816326
Validation loss: 2.38387065317523

Epoch: 6| Step: 6
Training loss: 0.2631184173449225
Validation loss: 2.3494202374527156

Epoch: 6| Step: 7
Training loss: 0.3230154158232137
Validation loss: 2.267702762788104

Epoch: 6| Step: 8
Training loss: 0.24864401241467282
Validation loss: 2.26952431148057

Epoch: 6| Step: 9
Training loss: 0.2629210342572425
Validation loss: 2.299876903567692

Epoch: 6| Step: 10
Training loss: 0.3638475372856495
Validation loss: 2.2837470864118874

Epoch: 6| Step: 11
Training loss: 0.1974190030721223
Validation loss: 2.310980043704185

Epoch: 6| Step: 12
Training loss: 0.14010640391320792
Validation loss: 2.359496609729858

Epoch: 6| Step: 13
Training loss: 0.4817738060386978
Validation loss: 2.360944073378538

Epoch: 317| Step: 0
Training loss: 0.42429544026120475
Validation loss: 2.3936410090935816

Epoch: 6| Step: 1
Training loss: 0.4289437359269456
Validation loss: 2.3954568084634884

Epoch: 6| Step: 2
Training loss: 0.2127795673437728
Validation loss: 2.3576434835728017

Epoch: 6| Step: 3
Training loss: 0.18601458978985727
Validation loss: 2.3098545402108805

Epoch: 6| Step: 4
Training loss: 0.27499539848292526
Validation loss: 2.328654940625774

Epoch: 6| Step: 5
Training loss: 0.4045419549096575
Validation loss: 2.281708789630978

Epoch: 6| Step: 6
Training loss: 0.2954887222608485
Validation loss: 2.342571500413959

Epoch: 6| Step: 7
Training loss: 0.2769565565921621
Validation loss: 2.357477068130705

Epoch: 6| Step: 8
Training loss: 0.4372874152182987
Validation loss: 2.342492847795707

Epoch: 6| Step: 9
Training loss: 0.2527078959583629
Validation loss: 2.3463099106075562

Epoch: 6| Step: 10
Training loss: 0.2389086920424422
Validation loss: 2.3768818367063136

Epoch: 6| Step: 11
Training loss: 0.1951256048546262
Validation loss: 2.4115547014388468

Epoch: 6| Step: 12
Training loss: 0.29453436548826545
Validation loss: 2.385697649491747

Epoch: 6| Step: 13
Training loss: 0.15962967136264572
Validation loss: 2.3517232184569408

Epoch: 318| Step: 0
Training loss: 0.21755958971281372
Validation loss: 2.394563719639331

Epoch: 6| Step: 1
Training loss: 0.23540324518181702
Validation loss: 2.3762218908291453

Epoch: 6| Step: 2
Training loss: 0.19718104144853177
Validation loss: 2.367975318930354

Epoch: 6| Step: 3
Training loss: 0.5022789458007971
Validation loss: 2.3428541194020487

Epoch: 6| Step: 4
Training loss: 0.14728576158217815
Validation loss: 2.310362137226892

Epoch: 6| Step: 5
Training loss: 0.21376457539717514
Validation loss: 2.302138396984406

Epoch: 6| Step: 6
Training loss: 0.4127468945266839
Validation loss: 2.292611236408914

Epoch: 6| Step: 7
Training loss: 0.3512795051047449
Validation loss: 2.282524265442958

Epoch: 6| Step: 8
Training loss: 0.16846102281347225
Validation loss: 2.2792400473898815

Epoch: 6| Step: 9
Training loss: 0.35889402628614736
Validation loss: 2.305540139231228

Epoch: 6| Step: 10
Training loss: 0.3512091238191191
Validation loss: 2.3049760246119924

Epoch: 6| Step: 11
Training loss: 0.22574792965861618
Validation loss: 2.3317435356041054

Epoch: 6| Step: 12
Training loss: 0.25521916087530755
Validation loss: 2.378447699090424

Epoch: 6| Step: 13
Training loss: 0.227452601431215
Validation loss: 2.346519939005106

Epoch: 319| Step: 0
Training loss: 0.396401984011769
Validation loss: 2.387337426962885

Epoch: 6| Step: 1
Training loss: 0.22345930973395423
Validation loss: 2.375269310561513

Epoch: 6| Step: 2
Training loss: 0.2555302840386386
Validation loss: 2.3471653730706876

Epoch: 6| Step: 3
Training loss: 0.3793078781401989
Validation loss: 2.3341974080966037

Epoch: 6| Step: 4
Training loss: 0.3888995399984404
Validation loss: 2.324253699768146

Epoch: 6| Step: 5
Training loss: 0.20385941373114658
Validation loss: 2.323809756959119

Epoch: 6| Step: 6
Training loss: 0.14746429742686296
Validation loss: 2.3409706409801094

Epoch: 6| Step: 7
Training loss: 0.17233853257029644
Validation loss: 2.3683675860073135

Epoch: 6| Step: 8
Training loss: 0.3078028285254757
Validation loss: 2.39496243677785

Epoch: 6| Step: 9
Training loss: 0.3404703721090525
Validation loss: 2.410232038302367

Epoch: 6| Step: 10
Training loss: 0.21438216127940565
Validation loss: 2.3956653655578983

Epoch: 6| Step: 11
Training loss: 0.2518374155177806
Validation loss: 2.4099953169350203

Epoch: 6| Step: 12
Training loss: 0.29442070067661985
Validation loss: 2.364691244285583

Epoch: 6| Step: 13
Training loss: 0.42553521843652586
Validation loss: 2.350728124165187

Epoch: 320| Step: 0
Training loss: 0.3246463805037
Validation loss: 2.3244567517603474

Epoch: 6| Step: 1
Training loss: 0.29293614523972966
Validation loss: 2.280105673536473

Epoch: 6| Step: 2
Training loss: 0.349655702387829
Validation loss: 2.3095438186862727

Epoch: 6| Step: 3
Training loss: 0.25645627581599706
Validation loss: 2.2642302336207885

Epoch: 6| Step: 4
Training loss: 0.26966323937908987
Validation loss: 2.2560325930723977

Epoch: 6| Step: 5
Training loss: 0.16172182914087663
Validation loss: 2.268819781207999

Epoch: 6| Step: 6
Training loss: 0.4060309626559845
Validation loss: 2.3092711183178083

Epoch: 6| Step: 7
Training loss: 0.2465336213889364
Validation loss: 2.3342009599844937

Epoch: 6| Step: 8
Training loss: 0.25649550760900874
Validation loss: 2.334286019165691

Epoch: 6| Step: 9
Training loss: 0.245181443808385
Validation loss: 2.39585073998875

Epoch: 6| Step: 10
Training loss: 0.270755392866239
Validation loss: 2.4010105459808653

Epoch: 6| Step: 11
Training loss: 0.42235851836413135
Validation loss: 2.4092408945311603

Epoch: 6| Step: 12
Training loss: 0.3363821280938685
Validation loss: 2.4147588039802024

Epoch: 6| Step: 13
Training loss: 0.29726650122614884
Validation loss: 2.4031941912552854

Epoch: 321| Step: 0
Training loss: 0.32909042384827003
Validation loss: 2.4202189541687584

Epoch: 6| Step: 1
Training loss: 0.24992178647134256
Validation loss: 2.386614701281706

Epoch: 6| Step: 2
Training loss: 0.14588562348662204
Validation loss: 2.375595637673482

Epoch: 6| Step: 3
Training loss: 0.41973407893065146
Validation loss: 2.367833373790072

Epoch: 6| Step: 4
Training loss: 0.42638641188264803
Validation loss: 2.33990556334413

Epoch: 6| Step: 5
Training loss: 0.31052856871192175
Validation loss: 2.323631084791491

Epoch: 6| Step: 6
Training loss: 0.2932826839731042
Validation loss: 2.2983950229256958

Epoch: 6| Step: 7
Training loss: 0.39827784911327835
Validation loss: 2.3411428924278903

Epoch: 6| Step: 8
Training loss: 0.19121366660612657
Validation loss: 2.3638981100113288

Epoch: 6| Step: 9
Training loss: 0.18296754856187525
Validation loss: 2.363568311501769

Epoch: 6| Step: 10
Training loss: 0.1679044700317349
Validation loss: 2.3638872216354083

Epoch: 6| Step: 11
Training loss: 0.19831148824845451
Validation loss: 2.39828099169741

Epoch: 6| Step: 12
Training loss: 0.29110208289545586
Validation loss: 2.3792817228491994

Epoch: 6| Step: 13
Training loss: 0.3232731069661173
Validation loss: 2.3985200075259163

Epoch: 322| Step: 0
Training loss: 0.40780444959389733
Validation loss: 2.3868512512477174

Epoch: 6| Step: 1
Training loss: 0.25211965986184254
Validation loss: 2.3959521171011287

Epoch: 6| Step: 2
Training loss: 0.21111389131834613
Validation loss: 2.353058515983669

Epoch: 6| Step: 3
Training loss: 0.18251133467147626
Validation loss: 2.3470909518178837

Epoch: 6| Step: 4
Training loss: 0.12723635843411152
Validation loss: 2.3211158021238623

Epoch: 6| Step: 5
Training loss: 0.2556627843255133
Validation loss: 2.2890802959716474

Epoch: 6| Step: 6
Training loss: 0.28598207272266346
Validation loss: 2.2916516828373417

Epoch: 6| Step: 7
Training loss: 0.31355108878509785
Validation loss: 2.2707736536293184

Epoch: 6| Step: 8
Training loss: 0.1959325484968892
Validation loss: 2.294849131000056

Epoch: 6| Step: 9
Training loss: 0.19809450558664096
Validation loss: 2.3089371883774783

Epoch: 6| Step: 10
Training loss: 0.33027529047666715
Validation loss: 2.2924446336685063

Epoch: 6| Step: 11
Training loss: 0.4613286637731857
Validation loss: 2.3559263010776843

Epoch: 6| Step: 12
Training loss: 0.14807767925012214
Validation loss: 2.384032383045492

Epoch: 6| Step: 13
Training loss: 0.31651487958200464
Validation loss: 2.3457883080787303

Epoch: 323| Step: 0
Training loss: 0.2175512591748148
Validation loss: 2.2983169008828943

Epoch: 6| Step: 1
Training loss: 0.19581761846661966
Validation loss: 2.3092919285676823

Epoch: 6| Step: 2
Training loss: 0.22676780869221005
Validation loss: 2.289626635535984

Epoch: 6| Step: 3
Training loss: 0.4136341506427688
Validation loss: 2.2929763280917266

Epoch: 6| Step: 4
Training loss: 0.22700216121421987
Validation loss: 2.321075073281472

Epoch: 6| Step: 5
Training loss: 0.33902257605156544
Validation loss: 2.3069088822331723

Epoch: 6| Step: 6
Training loss: 0.23545744797301577
Validation loss: 2.337591458423767

Epoch: 6| Step: 7
Training loss: 0.18888873161826725
Validation loss: 2.325388795098864

Epoch: 6| Step: 8
Training loss: 0.408577523720757
Validation loss: 2.314278727521592

Epoch: 6| Step: 9
Training loss: 0.3054662558022061
Validation loss: 2.311853670471843

Epoch: 6| Step: 10
Training loss: 0.25232249545410873
Validation loss: 2.337720140768097

Epoch: 6| Step: 11
Training loss: 0.2761485444699313
Validation loss: 2.3158393424433936

Epoch: 6| Step: 12
Training loss: 0.23624872812806744
Validation loss: 2.3400176077827863

Epoch: 6| Step: 13
Training loss: 0.11704636260396507
Validation loss: 2.308946286255969

Epoch: 324| Step: 0
Training loss: 0.1995277066016964
Validation loss: 2.333202436030641

Epoch: 6| Step: 1
Training loss: 0.2518796000285409
Validation loss: 2.3003845312944944

Epoch: 6| Step: 2
Training loss: 0.33066529185319504
Validation loss: 2.341689241185389

Epoch: 6| Step: 3
Training loss: 0.18286682854033448
Validation loss: 2.3654774322586367

Epoch: 6| Step: 4
Training loss: 0.23196473565084733
Validation loss: 2.347526265640999

Epoch: 6| Step: 5
Training loss: 0.43659211371652196
Validation loss: 2.3206296308857843

Epoch: 6| Step: 6
Training loss: 0.20074487943045044
Validation loss: 2.3347478983067336

Epoch: 6| Step: 7
Training loss: 0.14573857231635592
Validation loss: 2.321483224042661

Epoch: 6| Step: 8
Training loss: 0.24883962092650036
Validation loss: 2.335767529552197

Epoch: 6| Step: 9
Training loss: 0.22834402145624372
Validation loss: 2.336545636160208

Epoch: 6| Step: 10
Training loss: 0.3653765315057355
Validation loss: 2.325525279652281

Epoch: 6| Step: 11
Training loss: 0.12440415018020462
Validation loss: 2.3362397226711216

Epoch: 6| Step: 12
Training loss: 0.20150037443869281
Validation loss: 2.34693334826533

Epoch: 6| Step: 13
Training loss: 0.4436011978282012
Validation loss: 2.333618183665091

Epoch: 325| Step: 0
Training loss: 0.33212990136741954
Validation loss: 2.3753594108738136

Epoch: 6| Step: 1
Training loss: 0.3341466275332221
Validation loss: 2.3586544465120522

Epoch: 6| Step: 2
Training loss: 0.2610301738339151
Validation loss: 2.350706017055841

Epoch: 6| Step: 3
Training loss: 0.3259894380489395
Validation loss: 2.347203744378411

Epoch: 6| Step: 4
Training loss: 0.28088344423089706
Validation loss: 2.3791608927554875

Epoch: 6| Step: 5
Training loss: 0.14981201880070985
Validation loss: 2.356559572533772

Epoch: 6| Step: 6
Training loss: 0.20766935437763426
Validation loss: 2.349702276397219

Epoch: 6| Step: 7
Training loss: 0.24482360675432474
Validation loss: 2.3291471122968552

Epoch: 6| Step: 8
Training loss: 0.2774151723530581
Validation loss: 2.2676609146400155

Epoch: 6| Step: 9
Training loss: 0.16069889598060985
Validation loss: 2.2715515595724263

Epoch: 6| Step: 10
Training loss: 0.35848472034740486
Validation loss: 2.291502245451652

Epoch: 6| Step: 11
Training loss: 0.20939506747740474
Validation loss: 2.314737796441034

Epoch: 6| Step: 12
Training loss: 0.30685827706915236
Validation loss: 2.3106236920639898

Epoch: 6| Step: 13
Training loss: 0.12915623873358234
Validation loss: 2.323537464273884

Epoch: 326| Step: 0
Training loss: 0.3008398395298843
Validation loss: 2.3784518084393427

Epoch: 6| Step: 1
Training loss: 0.1264798880800888
Validation loss: 2.3382272878779466

Epoch: 6| Step: 2
Training loss: 0.307085649752496
Validation loss: 2.342652603338861

Epoch: 6| Step: 3
Training loss: 0.2825119133564057
Validation loss: 2.3716672787655333

Epoch: 6| Step: 4
Training loss: 0.3520619130061122
Validation loss: 2.34894783118262

Epoch: 6| Step: 5
Training loss: 0.2420944681222196
Validation loss: 2.360582921109611

Epoch: 6| Step: 6
Training loss: 0.17477521701217327
Validation loss: 2.3249107614963735

Epoch: 6| Step: 7
Training loss: 0.3099962547291349
Validation loss: 2.3027153769659403

Epoch: 6| Step: 8
Training loss: 0.26067828706253177
Validation loss: 2.3436661025040477

Epoch: 6| Step: 9
Training loss: 0.16371519931060036
Validation loss: 2.352182026724102

Epoch: 6| Step: 10
Training loss: 0.3633979896920717
Validation loss: 2.3127171021786466

Epoch: 6| Step: 11
Training loss: 0.16200510946247382
Validation loss: 2.3412000154878716

Epoch: 6| Step: 12
Training loss: 0.15399063478904068
Validation loss: 2.3064110580824124

Epoch: 6| Step: 13
Training loss: 0.3520544107490774
Validation loss: 2.286170831703828

Epoch: 327| Step: 0
Training loss: 0.19580574695255026
Validation loss: 2.270876083543618

Epoch: 6| Step: 1
Training loss: 0.4270390821032487
Validation loss: 2.2617048148035623

Epoch: 6| Step: 2
Training loss: 0.17642732146372186
Validation loss: 2.2925663735969475

Epoch: 6| Step: 3
Training loss: 0.3278119433046456
Validation loss: 2.2847976216647528

Epoch: 6| Step: 4
Training loss: 0.34119050871512474
Validation loss: 2.324278338895449

Epoch: 6| Step: 5
Training loss: 0.15730444833051954
Validation loss: 2.3205789591409625

Epoch: 6| Step: 6
Training loss: 0.2453322056430403
Validation loss: 2.3405770737201212

Epoch: 6| Step: 7
Training loss: 0.08351295981244895
Validation loss: 2.3234918111254794

Epoch: 6| Step: 8
Training loss: 0.18766464514777095
Validation loss: 2.3979828774333716

Epoch: 6| Step: 9
Training loss: 0.31853222981244894
Validation loss: 2.3702346822187916

Epoch: 6| Step: 10
Training loss: 0.16564699647695216
Validation loss: 2.3480726246191095

Epoch: 6| Step: 11
Training loss: 0.30019135035107136
Validation loss: 2.3505442190983894

Epoch: 6| Step: 12
Training loss: 0.19440723434024892
Validation loss: 2.3361102136469074

Epoch: 6| Step: 13
Training loss: 0.33899845581982996
Validation loss: 2.2930516358339754

Epoch: 328| Step: 0
Training loss: 0.20914554620082113
Validation loss: 2.30709752680611

Epoch: 6| Step: 1
Training loss: 0.2388475598734275
Validation loss: 2.2996766916702525

Epoch: 6| Step: 2
Training loss: 0.16568620760869412
Validation loss: 2.328863503180627

Epoch: 6| Step: 3
Training loss: 0.108662061337299
Validation loss: 2.314186607472056

Epoch: 6| Step: 4
Training loss: 0.3745631216251862
Validation loss: 2.29755953556105

Epoch: 6| Step: 5
Training loss: 0.2020625056188024
Validation loss: 2.3353596479244385

Epoch: 6| Step: 6
Training loss: 0.2692674921936489
Validation loss: 2.313645118962732

Epoch: 6| Step: 7
Training loss: 0.5121198640006702
Validation loss: 2.3306688207524076

Epoch: 6| Step: 8
Training loss: 0.23719665046048927
Validation loss: 2.349016580299915

Epoch: 6| Step: 9
Training loss: 0.2036478209987983
Validation loss: 2.3635606945459635

Epoch: 6| Step: 10
Training loss: 0.15352484551614387
Validation loss: 2.3835619052774986

Epoch: 6| Step: 11
Training loss: 0.268557461810954
Validation loss: 2.3753557397534264

Epoch: 6| Step: 12
Training loss: 0.13054495373447286
Validation loss: 2.3353722522538694

Epoch: 6| Step: 13
Training loss: 0.2587807132165817
Validation loss: 2.3508666075897753

Epoch: 329| Step: 0
Training loss: 0.22892755890959857
Validation loss: 2.372471561810157

Epoch: 6| Step: 1
Training loss: 0.1854379334112026
Validation loss: 2.347487452398995

Epoch: 6| Step: 2
Training loss: 0.32507831886100536
Validation loss: 2.3468802748645783

Epoch: 6| Step: 3
Training loss: 0.2750918072561808
Validation loss: 2.344500532402585

Epoch: 6| Step: 4
Training loss: 0.3058693534616734
Validation loss: 2.3360251868675994

Epoch: 6| Step: 5
Training loss: 0.22948092980875598
Validation loss: 2.3160434016701825

Epoch: 6| Step: 6
Training loss: 0.2526690344091441
Validation loss: 2.35679465479968

Epoch: 6| Step: 7
Training loss: 0.2631191818880734
Validation loss: 2.320389455037955

Epoch: 6| Step: 8
Training loss: 0.16300977995960614
Validation loss: 2.312469828108667

Epoch: 6| Step: 9
Training loss: 0.2442353179398011
Validation loss: 2.3723516124559367

Epoch: 6| Step: 10
Training loss: 0.12640230554620016
Validation loss: 2.3585789877967023

Epoch: 6| Step: 11
Training loss: 0.3525173360200483
Validation loss: 2.352929167826939

Epoch: 6| Step: 12
Training loss: 0.33013606268370654
Validation loss: 2.3282805888613582

Epoch: 6| Step: 13
Training loss: 0.1299062363576618
Validation loss: 2.321501836034176

Epoch: 330| Step: 0
Training loss: 0.20125698400308917
Validation loss: 2.3331630955251907

Epoch: 6| Step: 1
Training loss: 0.12403275612493098
Validation loss: 2.3243610694572654

Epoch: 6| Step: 2
Training loss: 0.3198929108676973
Validation loss: 2.3400955843950517

Epoch: 6| Step: 3
Training loss: 0.2824524500166103
Validation loss: 2.3016605745348255

Epoch: 6| Step: 4
Training loss: 0.23876649663514063
Validation loss: 2.2824344861051498

Epoch: 6| Step: 5
Training loss: 0.2961467544500191
Validation loss: 2.2940184718266434

Epoch: 6| Step: 6
Training loss: 0.2151117473972173
Validation loss: 2.2757995257776575

Epoch: 6| Step: 7
Training loss: 0.4299419343356185
Validation loss: 2.2655134372308567

Epoch: 6| Step: 8
Training loss: 0.18038308228211478
Validation loss: 2.279270422398403

Epoch: 6| Step: 9
Training loss: 0.3859591296540322
Validation loss: 2.308095761661329

Epoch: 6| Step: 10
Training loss: 0.16066366157138548
Validation loss: 2.3256595126830346

Epoch: 6| Step: 11
Training loss: 0.2892400222242679
Validation loss: 2.302597824362464

Epoch: 6| Step: 12
Training loss: 0.22713765769038974
Validation loss: 2.343944123135186

Epoch: 6| Step: 13
Training loss: 0.1701840428089817
Validation loss: 2.357458563993021

Epoch: 331| Step: 0
Training loss: 0.22314963136683552
Validation loss: 2.340857333975884

Epoch: 6| Step: 1
Training loss: 0.3245020742989296
Validation loss: 2.380536590973642

Epoch: 6| Step: 2
Training loss: 0.3281754954403133
Validation loss: 2.337802205388524

Epoch: 6| Step: 3
Training loss: 0.3544649686425855
Validation loss: 2.383963921743517

Epoch: 6| Step: 4
Training loss: 0.2272983309022011
Validation loss: 2.3794175532102315

Epoch: 6| Step: 5
Training loss: 0.1483766343160122
Validation loss: 2.369210403015771

Epoch: 6| Step: 6
Training loss: 0.22971474427555397
Validation loss: 2.3443740681106617

Epoch: 6| Step: 7
Training loss: 0.1447554151575442
Validation loss: 2.3339296654180894

Epoch: 6| Step: 8
Training loss: 0.11169566169327183
Validation loss: 2.3367015250251923

Epoch: 6| Step: 9
Training loss: 0.40107365476514284
Validation loss: 2.3297382229185937

Epoch: 6| Step: 10
Training loss: 0.2838809878542121
Validation loss: 2.3121014012878955

Epoch: 6| Step: 11
Training loss: 0.21116567562373018
Validation loss: 2.3294115026743

Epoch: 6| Step: 12
Training loss: 0.2500289661792818
Validation loss: 2.3434156697586923

Epoch: 6| Step: 13
Training loss: 0.11658600778519439
Validation loss: 2.3433790437010544

Epoch: 332| Step: 0
Training loss: 0.2375354821904989
Validation loss: 2.3091564989989823

Epoch: 6| Step: 1
Training loss: 0.19407832260865
Validation loss: 2.315793098046722

Epoch: 6| Step: 2
Training loss: 0.2185468752421857
Validation loss: 2.3259224155586398

Epoch: 6| Step: 3
Training loss: 0.32944475159238534
Validation loss: 2.3288827805186676

Epoch: 6| Step: 4
Training loss: 0.22374913884109066
Validation loss: 2.3393431379345935

Epoch: 6| Step: 5
Training loss: 0.15511344968566687
Validation loss: 2.379179897249652

Epoch: 6| Step: 6
Training loss: 0.21464528540534822
Validation loss: 2.38667622329572

Epoch: 6| Step: 7
Training loss: 0.21227421897252108
Validation loss: 2.3913920983643333

Epoch: 6| Step: 8
Training loss: 0.13914764080319633
Validation loss: 2.3817713966709

Epoch: 6| Step: 9
Training loss: 0.23804424568629654
Validation loss: 2.3532000194296847

Epoch: 6| Step: 10
Training loss: 0.3575898698074363
Validation loss: 2.354948338934614

Epoch: 6| Step: 11
Training loss: 0.4577000281278282
Validation loss: 2.285495703885971

Epoch: 6| Step: 12
Training loss: 0.31132005611670366
Validation loss: 2.3160960897614955

Epoch: 6| Step: 13
Training loss: 0.21122909630106046
Validation loss: 2.2922105313493604

Epoch: 333| Step: 0
Training loss: 0.44199416581139717
Validation loss: 2.2797886436331942

Epoch: 6| Step: 1
Training loss: 0.2773740644409094
Validation loss: 2.295327347207089

Epoch: 6| Step: 2
Training loss: 0.22741874493483008
Validation loss: 2.333626767867606

Epoch: 6| Step: 3
Training loss: 0.20808209628567637
Validation loss: 2.3655833177647607

Epoch: 6| Step: 4
Training loss: 0.22165060482745064
Validation loss: 2.396372236302939

Epoch: 6| Step: 5
Training loss: 0.14576431682039317
Validation loss: 2.3984159769461546

Epoch: 6| Step: 6
Training loss: 0.24702140263685965
Validation loss: 2.384908164568106

Epoch: 6| Step: 7
Training loss: 0.40987473772464605
Validation loss: 2.340011642973298

Epoch: 6| Step: 8
Training loss: 0.1504599300069328
Validation loss: 2.311972456215351

Epoch: 6| Step: 9
Training loss: 0.16749375849453732
Validation loss: 2.2962255887355125

Epoch: 6| Step: 10
Training loss: 0.25882221225533103
Validation loss: 2.3007903467017283

Epoch: 6| Step: 11
Training loss: 0.19323672633708067
Validation loss: 2.2837824226090966

Epoch: 6| Step: 12
Training loss: 0.28002180706407637
Validation loss: 2.3057510927934546

Epoch: 6| Step: 13
Training loss: 0.2735492069404066
Validation loss: 2.3396659461808924

Epoch: 334| Step: 0
Training loss: 0.29345519054171953
Validation loss: 2.3332737403795294

Epoch: 6| Step: 1
Training loss: 0.13983207579319315
Validation loss: 2.3656164031009967

Epoch: 6| Step: 2
Training loss: 0.3208785057262735
Validation loss: 2.3400159808686745

Epoch: 6| Step: 3
Training loss: 0.26040295882704817
Validation loss: 2.3330118255202303

Epoch: 6| Step: 4
Training loss: 0.27560809862126867
Validation loss: 2.307607564456106

Epoch: 6| Step: 5
Training loss: 0.24455216626056225
Validation loss: 2.2921150413992226

Epoch: 6| Step: 6
Training loss: 0.18523291075219056
Validation loss: 2.3345998902451086

Epoch: 6| Step: 7
Training loss: 0.17425153363974555
Validation loss: 2.360169932334274

Epoch: 6| Step: 8
Training loss: 0.19496804380525903
Validation loss: 2.365101839863956

Epoch: 6| Step: 9
Training loss: 0.3357969034202123
Validation loss: 2.4109186439297026

Epoch: 6| Step: 10
Training loss: 0.2671738375689781
Validation loss: 2.4286793592785414

Epoch: 6| Step: 11
Training loss: 0.2545368433525684
Validation loss: 2.413033726263649

Epoch: 6| Step: 12
Training loss: 0.372884825016601
Validation loss: 2.3792106826564177

Epoch: 6| Step: 13
Training loss: 0.1239880639040046
Validation loss: 2.363522716780995

Epoch: 335| Step: 0
Training loss: 0.4009961829051377
Validation loss: 2.3560033131875286

Epoch: 6| Step: 1
Training loss: 0.16230411208104709
Validation loss: 2.343120899062439

Epoch: 6| Step: 2
Training loss: 0.3119492207050449
Validation loss: 2.3675635676818056

Epoch: 6| Step: 3
Training loss: 0.2198809102800027
Validation loss: 2.3346836962721684

Epoch: 6| Step: 4
Training loss: 0.13349107287773138
Validation loss: 2.354637492217627

Epoch: 6| Step: 5
Training loss: 0.20244145004632663
Validation loss: 2.34415664426641

Epoch: 6| Step: 6
Training loss: 0.26253342869756713
Validation loss: 2.3552932092925363

Epoch: 6| Step: 7
Training loss: 0.3296318536052427
Validation loss: 2.3501900981988952

Epoch: 6| Step: 8
Training loss: 0.20185388306990118
Validation loss: 2.3279413124787554

Epoch: 6| Step: 9
Training loss: 0.16656279431472742
Validation loss: 2.3448406544898224

Epoch: 6| Step: 10
Training loss: 0.14726157954399227
Validation loss: 2.3246475636242776

Epoch: 6| Step: 11
Training loss: 0.20670106036502958
Validation loss: 2.3315050885048776

Epoch: 6| Step: 12
Training loss: 0.36232134428575924
Validation loss: 2.370834076606978

Epoch: 6| Step: 13
Training loss: 0.2669863875344446
Validation loss: 2.395091728436942

Epoch: 336| Step: 0
Training loss: 0.359460447353309
Validation loss: 2.4136953048400387

Epoch: 6| Step: 1
Training loss: 0.12619707487735818
Validation loss: 2.3899804611752917

Epoch: 6| Step: 2
Training loss: 0.1702573577611523
Validation loss: 2.308681926310341

Epoch: 6| Step: 3
Training loss: 0.32486994965676214
Validation loss: 2.3131450605908093

Epoch: 6| Step: 4
Training loss: 0.3674440704980705
Validation loss: 2.3130084107755926

Epoch: 6| Step: 5
Training loss: 0.18823723100389314
Validation loss: 2.304881888830413

Epoch: 6| Step: 6
Training loss: 0.14981730282421016
Validation loss: 2.3171997692203834

Epoch: 6| Step: 7
Training loss: 0.15694395575885683
Validation loss: 2.293792565439153

Epoch: 6| Step: 8
Training loss: 0.22343310972048708
Validation loss: 2.3072861587331635

Epoch: 6| Step: 9
Training loss: 0.30614167214613996
Validation loss: 2.3187226989764573

Epoch: 6| Step: 10
Training loss: 0.2717884199905773
Validation loss: 2.390497441098747

Epoch: 6| Step: 11
Training loss: 0.3164850301742835
Validation loss: 2.419866114433007

Epoch: 6| Step: 12
Training loss: 0.33786626959545996
Validation loss: 2.3514552499564125

Epoch: 6| Step: 13
Training loss: 0.26817327985043843
Validation loss: 2.4066900994278666

Epoch: 337| Step: 0
Training loss: 0.18431960340505846
Validation loss: 2.3435788125582655

Epoch: 6| Step: 1
Training loss: 0.11267524206647776
Validation loss: 2.3405194387245336

Epoch: 6| Step: 2
Training loss: 0.35931883248631136
Validation loss: 2.3355169260272346

Epoch: 6| Step: 3
Training loss: 0.3198482358810796
Validation loss: 2.381508398630698

Epoch: 6| Step: 4
Training loss: 0.166650288243993
Validation loss: 2.3505772101907274

Epoch: 6| Step: 5
Training loss: 0.23516560564408953
Validation loss: 2.352870617797994

Epoch: 6| Step: 6
Training loss: 0.20208381688823723
Validation loss: 2.344762166549174

Epoch: 6| Step: 7
Training loss: 0.18069068093998245
Validation loss: 2.3268177342678067

Epoch: 6| Step: 8
Training loss: 0.22167110006361368
Validation loss: 2.331317822371176

Epoch: 6| Step: 9
Training loss: 0.35607895509483406
Validation loss: 2.316968689261437

Epoch: 6| Step: 10
Training loss: 0.4000887407273666
Validation loss: 2.38240116737469

Epoch: 6| Step: 11
Training loss: 0.1709319926426015
Validation loss: 2.339402475278038

Epoch: 6| Step: 12
Training loss: 0.17666859772664462
Validation loss: 2.3600164577924607

Epoch: 6| Step: 13
Training loss: 0.18908374209911108
Validation loss: 2.3915898183549027

Epoch: 338| Step: 0
Training loss: 0.15283697321400017
Validation loss: 2.3777852902504417

Epoch: 6| Step: 1
Training loss: 0.1845300620458287
Validation loss: 2.3809535389266

Epoch: 6| Step: 2
Training loss: 0.19772075799109587
Validation loss: 2.34307048942049

Epoch: 6| Step: 3
Training loss: 0.3136854574984832
Validation loss: 2.3993954020451396

Epoch: 6| Step: 4
Training loss: 0.21968212102108325
Validation loss: 2.3461050374522388

Epoch: 6| Step: 5
Training loss: 0.21428359440765396
Validation loss: 2.3663719773557568

Epoch: 6| Step: 6
Training loss: 0.2394691934841569
Validation loss: 2.346969390719174

Epoch: 6| Step: 7
Training loss: 0.24619277596612815
Validation loss: 2.3466765324894667

Epoch: 6| Step: 8
Training loss: 0.33133809159896294
Validation loss: 2.363565045080794

Epoch: 6| Step: 9
Training loss: 0.38982595735666126
Validation loss: 2.378727727566137

Epoch: 6| Step: 10
Training loss: 0.17660109806991156
Validation loss: 2.403946687058582

Epoch: 6| Step: 11
Training loss: 0.28335723630036513
Validation loss: 2.4011109834836732

Epoch: 6| Step: 12
Training loss: 0.33043067207735405
Validation loss: 2.356667359919666

Epoch: 6| Step: 13
Training loss: 0.33185138318430374
Validation loss: 2.3075176531025625

Epoch: 339| Step: 0
Training loss: 0.3443288264673598
Validation loss: 2.3471592740594835

Epoch: 6| Step: 1
Training loss: 0.26404873795170714
Validation loss: 2.307763962274785

Epoch: 6| Step: 2
Training loss: 0.25829580550998965
Validation loss: 2.3337296890520993

Epoch: 6| Step: 3
Training loss: 0.23840071856929268
Validation loss: 2.2999866390018533

Epoch: 6| Step: 4
Training loss: 0.26265534731535645
Validation loss: 2.3534438903739177

Epoch: 6| Step: 5
Training loss: 0.3011536089235189
Validation loss: 2.374379707942897

Epoch: 6| Step: 6
Training loss: 0.3975441772875573
Validation loss: 2.41145325521546

Epoch: 6| Step: 7
Training loss: 0.3571895198481229
Validation loss: 2.4091246245835958

Epoch: 6| Step: 8
Training loss: 0.3245769727856598
Validation loss: 2.3760951147947993

Epoch: 6| Step: 9
Training loss: 0.28261810914201074
Validation loss: 2.3034646398400733

Epoch: 6| Step: 10
Training loss: 0.4691431304331127
Validation loss: 2.247969184877915

Epoch: 6| Step: 11
Training loss: 0.3051958367433419
Validation loss: 2.2309796889376368

Epoch: 6| Step: 12
Training loss: 0.23270924217663647
Validation loss: 2.239176340365465

Epoch: 6| Step: 13
Training loss: 0.34582364411549826
Validation loss: 2.227152286776177

Epoch: 340| Step: 0
Training loss: 0.2915088902339714
Validation loss: 2.262618874292753

Epoch: 6| Step: 1
Training loss: 0.22289582798310656
Validation loss: 2.3018613795636207

Epoch: 6| Step: 2
Training loss: 0.26969338115587266
Validation loss: 2.382617316681762

Epoch: 6| Step: 3
Training loss: 0.3993754846274431
Validation loss: 2.364175670747934

Epoch: 6| Step: 4
Training loss: 0.39825424018944566
Validation loss: 2.372269534824234

Epoch: 6| Step: 5
Training loss: 0.3906343840425563
Validation loss: 2.327372404338761

Epoch: 6| Step: 6
Training loss: 0.2741751394344367
Validation loss: 2.294123190072388

Epoch: 6| Step: 7
Training loss: 0.20842035780709864
Validation loss: 2.266420454865375

Epoch: 6| Step: 8
Training loss: 0.21671824704794634
Validation loss: 2.26055996741483

Epoch: 6| Step: 9
Training loss: 0.2855862158564089
Validation loss: 2.2310109916182346

Epoch: 6| Step: 10
Training loss: 0.24983733070529265
Validation loss: 2.2574189425686826

Epoch: 6| Step: 11
Training loss: 0.14034046421184093
Validation loss: 2.280403335208042

Epoch: 6| Step: 12
Training loss: 0.2416793815101572
Validation loss: 2.2927465592358494

Epoch: 6| Step: 13
Training loss: 0.16291602071668987
Validation loss: 2.3632467461452635

Epoch: 341| Step: 0
Training loss: 0.32977196077081816
Validation loss: 2.397013145742196

Epoch: 6| Step: 1
Training loss: 0.24803771354997914
Validation loss: 2.4360990176630692

Epoch: 6| Step: 2
Training loss: 0.20448528157899892
Validation loss: 2.437230878076657

Epoch: 6| Step: 3
Training loss: 0.14002487823710555
Validation loss: 2.433138936646128

Epoch: 6| Step: 4
Training loss: 0.16023368824142523
Validation loss: 2.393872325676894

Epoch: 6| Step: 5
Training loss: 0.32870626055268276
Validation loss: 2.3963383538713336

Epoch: 6| Step: 6
Training loss: 0.299882164303873
Validation loss: 2.3127931632405456

Epoch: 6| Step: 7
Training loss: 0.31555921888846145
Validation loss: 2.307515233909625

Epoch: 6| Step: 8
Training loss: 0.12646874675840275
Validation loss: 2.3080038269152565

Epoch: 6| Step: 9
Training loss: 0.229817918159598
Validation loss: 2.31851312358161

Epoch: 6| Step: 10
Training loss: 0.1942605586483965
Validation loss: 2.346869249092273

Epoch: 6| Step: 11
Training loss: 0.18721334081612387
Validation loss: 2.3862825853131775

Epoch: 6| Step: 12
Training loss: 0.34685199377730513
Validation loss: 2.3956257158144814

Epoch: 6| Step: 13
Training loss: 0.25036133045812997
Validation loss: 2.3825756044672346

Epoch: 342| Step: 0
Training loss: 0.18115991129324896
Validation loss: 2.389857488068013

Epoch: 6| Step: 1
Training loss: 0.33606912562610786
Validation loss: 2.4252824738689904

Epoch: 6| Step: 2
Training loss: 0.4889721979007605
Validation loss: 2.4002282131341297

Epoch: 6| Step: 3
Training loss: 0.14711777122713574
Validation loss: 2.3719846520129235

Epoch: 6| Step: 4
Training loss: 0.19721236312502646
Validation loss: 2.382451310832654

Epoch: 6| Step: 5
Training loss: 0.21248118373365896
Validation loss: 2.3419696688314624

Epoch: 6| Step: 6
Training loss: 0.3391417344854415
Validation loss: 2.3481113965266145

Epoch: 6| Step: 7
Training loss: 0.14809343969550448
Validation loss: 2.3181337842439014

Epoch: 6| Step: 8
Training loss: 0.11311921501384456
Validation loss: 2.333811227763238

Epoch: 6| Step: 9
Training loss: 0.31034802722297755
Validation loss: 2.331683617985963

Epoch: 6| Step: 10
Training loss: 0.15116493495023214
Validation loss: 2.3592344873924684

Epoch: 6| Step: 11
Training loss: 0.28439093796638576
Validation loss: 2.366395199134886

Epoch: 6| Step: 12
Training loss: 0.18549083064081526
Validation loss: 2.3472441159549837

Epoch: 6| Step: 13
Training loss: 0.3381095463681665
Validation loss: 2.3627334386942307

Epoch: 343| Step: 0
Training loss: 0.1475968713299076
Validation loss: 2.3056830390176044

Epoch: 6| Step: 1
Training loss: 0.18982658740356695
Validation loss: 2.3209032395222557

Epoch: 6| Step: 2
Training loss: 0.2457295402070155
Validation loss: 2.295810416754361

Epoch: 6| Step: 3
Training loss: 0.27453164130472296
Validation loss: 2.285861946622432

Epoch: 6| Step: 4
Training loss: 0.1895668632213959
Validation loss: 2.2737445314574494

Epoch: 6| Step: 5
Training loss: 0.2266650132394773
Validation loss: 2.2655077526629883

Epoch: 6| Step: 6
Training loss: 0.2144119084118488
Validation loss: 2.299300150108612

Epoch: 6| Step: 7
Training loss: 0.22776894969441025
Validation loss: 2.2893561729529184

Epoch: 6| Step: 8
Training loss: 0.2857900134912567
Validation loss: 2.3400252542639586

Epoch: 6| Step: 9
Training loss: 0.27114304690712926
Validation loss: 2.352827377420595

Epoch: 6| Step: 10
Training loss: 0.26215847993730584
Validation loss: 2.3256253912336025

Epoch: 6| Step: 11
Training loss: 0.3057196691468635
Validation loss: 2.316400560284436

Epoch: 6| Step: 12
Training loss: 0.31881243991757763
Validation loss: 2.3647237095199602

Epoch: 6| Step: 13
Training loss: 0.3764674363498499
Validation loss: 2.3476796579953976

Epoch: 344| Step: 0
Training loss: 0.3218532582689824
Validation loss: 2.335068695360602

Epoch: 6| Step: 1
Training loss: 0.3074974432505561
Validation loss: 2.3255005743634847

Epoch: 6| Step: 2
Training loss: 0.23730319615276138
Validation loss: 2.3282997025606855

Epoch: 6| Step: 3
Training loss: 0.21970167230986232
Validation loss: 2.3123611776028214

Epoch: 6| Step: 4
Training loss: 0.2104223636919798
Validation loss: 2.3213417883509893

Epoch: 6| Step: 5
Training loss: 0.13579732474903428
Validation loss: 2.34908396132534

Epoch: 6| Step: 6
Training loss: 0.16837518887696862
Validation loss: 2.3697469109157563

Epoch: 6| Step: 7
Training loss: 0.2542713621265039
Validation loss: 2.4007096973441735

Epoch: 6| Step: 8
Training loss: 0.21184999402775237
Validation loss: 2.3799658388573133

Epoch: 6| Step: 9
Training loss: 0.36183860391538103
Validation loss: 2.410073415378122

Epoch: 6| Step: 10
Training loss: 0.2669058938648781
Validation loss: 2.378276938991097

Epoch: 6| Step: 11
Training loss: 0.3513476669037544
Validation loss: 2.3833395732910105

Epoch: 6| Step: 12
Training loss: 0.1589501428420939
Validation loss: 2.3559479587607015

Epoch: 6| Step: 13
Training loss: 0.16754426102723424
Validation loss: 2.3651353644234954

Epoch: 345| Step: 0
Training loss: 0.24997883200435606
Validation loss: 2.3229729547959734

Epoch: 6| Step: 1
Training loss: 0.20687331167263961
Validation loss: 2.3394610423951367

Epoch: 6| Step: 2
Training loss: 0.29338830787421016
Validation loss: 2.313884927912787

Epoch: 6| Step: 3
Training loss: 0.2982709464825919
Validation loss: 2.380866203872702

Epoch: 6| Step: 4
Training loss: 0.221538296952687
Validation loss: 2.4291121191267964

Epoch: 6| Step: 5
Training loss: 0.28669605217255667
Validation loss: 2.4559493160581383

Epoch: 6| Step: 6
Training loss: 0.24447429743288518
Validation loss: 2.486681482458753

Epoch: 6| Step: 7
Training loss: 0.25200973288817885
Validation loss: 2.46284115538751

Epoch: 6| Step: 8
Training loss: 0.30975021285480026
Validation loss: 2.43110580812864

Epoch: 6| Step: 9
Training loss: 0.12288321858936249
Validation loss: 2.411842224916089

Epoch: 6| Step: 10
Training loss: 0.13015511299314433
Validation loss: 2.3688130412245467

Epoch: 6| Step: 11
Training loss: 0.23798400286498325
Validation loss: 2.3279178425637923

Epoch: 6| Step: 12
Training loss: 0.30841485403190144
Validation loss: 2.3271625266668647

Epoch: 6| Step: 13
Training loss: 0.3819662783865089
Validation loss: 2.329720848660607

Epoch: 346| Step: 0
Training loss: 0.19289784306323393
Validation loss: 2.3580682389054446

Epoch: 6| Step: 1
Training loss: 0.215093432906035
Validation loss: 2.330268832460974

Epoch: 6| Step: 2
Training loss: 0.20664426335266772
Validation loss: 2.338889680532864

Epoch: 6| Step: 3
Training loss: 0.20889959665686827
Validation loss: 2.340646072398643

Epoch: 6| Step: 4
Training loss: 0.15731033320747695
Validation loss: 2.3638387867335555

Epoch: 6| Step: 5
Training loss: 0.14732962565922575
Validation loss: 2.3576491281253817

Epoch: 6| Step: 6
Training loss: 0.4089676482852634
Validation loss: 2.3631698328567206

Epoch: 6| Step: 7
Training loss: 0.20980973232854025
Validation loss: 2.372428027083241

Epoch: 6| Step: 8
Training loss: 0.2881462680555123
Validation loss: 2.3976465262198263

Epoch: 6| Step: 9
Training loss: 0.212509698155632
Validation loss: 2.3607337563453266

Epoch: 6| Step: 10
Training loss: 0.22154549389502917
Validation loss: 2.348832432489425

Epoch: 6| Step: 11
Training loss: 0.17021993825339107
Validation loss: 2.373552847580666

Epoch: 6| Step: 12
Training loss: 0.1677461635283074
Validation loss: 2.3640973063831603

Epoch: 6| Step: 13
Training loss: 0.40223331231993154
Validation loss: 2.341745212919054

Epoch: 347| Step: 0
Training loss: 0.20294033422802443
Validation loss: 2.3423591616153034

Epoch: 6| Step: 1
Training loss: 0.32351302126748904
Validation loss: 2.3429354285116193

Epoch: 6| Step: 2
Training loss: 0.2818620565238129
Validation loss: 2.371875835669689

Epoch: 6| Step: 3
Training loss: 0.14717851207406948
Validation loss: 2.3931072864247502

Epoch: 6| Step: 4
Training loss: 0.31336573843247556
Validation loss: 2.3604876980276392

Epoch: 6| Step: 5
Training loss: 0.16178217579350324
Validation loss: 2.369038174142362

Epoch: 6| Step: 6
Training loss: 0.15167704216170352
Validation loss: 2.3547543695876816

Epoch: 6| Step: 7
Training loss: 0.12619218928488704
Validation loss: 2.3721860591589294

Epoch: 6| Step: 8
Training loss: 0.30402693913960194
Validation loss: 2.3781278627163958

Epoch: 6| Step: 9
Training loss: 0.18454775596720377
Validation loss: 2.3588182987390884

Epoch: 6| Step: 10
Training loss: 0.2588056307113428
Validation loss: 2.3491793754673385

Epoch: 6| Step: 11
Training loss: 0.20479346000633858
Validation loss: 2.3328652985556797

Epoch: 6| Step: 12
Training loss: 0.22879619165886536
Validation loss: 2.3387948709500597

Epoch: 6| Step: 13
Training loss: 0.1271349851462128
Validation loss: 2.3382764226855683

Epoch: 348| Step: 0
Training loss: 0.1548638489744432
Validation loss: 2.3426809868662586

Epoch: 6| Step: 1
Training loss: 0.24336917300270203
Validation loss: 2.4128202985843084

Epoch: 6| Step: 2
Training loss: 0.1634066506295355
Validation loss: 2.373783626926792

Epoch: 6| Step: 3
Training loss: 0.1736479639966882
Validation loss: 2.362917271715507

Epoch: 6| Step: 4
Training loss: 0.17193730265482285
Validation loss: 2.3536702913313783

Epoch: 6| Step: 5
Training loss: 0.19250606326053932
Validation loss: 2.366979513443445

Epoch: 6| Step: 6
Training loss: 0.3823839240876842
Validation loss: 2.3960771526665643

Epoch: 6| Step: 7
Training loss: 0.33542158743208556
Validation loss: 2.3588268814405526

Epoch: 6| Step: 8
Training loss: 0.14123754738672598
Validation loss: 2.352116181739431

Epoch: 6| Step: 9
Training loss: 0.22591331803640147
Validation loss: 2.345214397203577

Epoch: 6| Step: 10
Training loss: 0.12638305906356734
Validation loss: 2.345869253344707

Epoch: 6| Step: 11
Training loss: 0.37950228973622685
Validation loss: 2.3488455211595314

Epoch: 6| Step: 12
Training loss: 0.14885717594031564
Validation loss: 2.3169993502608417

Epoch: 6| Step: 13
Training loss: 0.2073524520560011
Validation loss: 2.3293367271572363

Epoch: 349| Step: 0
Training loss: 0.28298560371951514
Validation loss: 2.3254875687184615

Epoch: 6| Step: 1
Training loss: 0.14418887491236212
Validation loss: 2.331123822864316

Epoch: 6| Step: 2
Training loss: 0.16229654330719817
Validation loss: 2.3113941995388223

Epoch: 6| Step: 3
Training loss: 0.2324238304248264
Validation loss: 2.313250308273802

Epoch: 6| Step: 4
Training loss: 0.27445251901300705
Validation loss: 2.324657156382512

Epoch: 6| Step: 5
Training loss: 0.18249735240779447
Validation loss: 2.3757598537916187

Epoch: 6| Step: 6
Training loss: 0.26867673008185056
Validation loss: 2.3278253008235774

Epoch: 6| Step: 7
Training loss: 0.12426590684167842
Validation loss: 2.339794595787464

Epoch: 6| Step: 8
Training loss: 0.3622081864565614
Validation loss: 2.3099404559491505

Epoch: 6| Step: 9
Training loss: 0.22493891383482217
Validation loss: 2.3487091070480948

Epoch: 6| Step: 10
Training loss: 0.11885045235572439
Validation loss: 2.3553091230569625

Epoch: 6| Step: 11
Training loss: 0.20467090138990746
Validation loss: 2.341950835276497

Epoch: 6| Step: 12
Training loss: 0.3530178992141141
Validation loss: 2.3362727407381705

Epoch: 6| Step: 13
Training loss: 0.14284258314852424
Validation loss: 2.3365544625095933

Epoch: 350| Step: 0
Training loss: 0.12072606563151124
Validation loss: 2.3736385502985713

Epoch: 6| Step: 1
Training loss: 0.17020601872357105
Validation loss: 2.387282702438184

Epoch: 6| Step: 2
Training loss: 0.333536438854325
Validation loss: 2.3689925245366736

Epoch: 6| Step: 3
Training loss: 0.35686902507182866
Validation loss: 2.369208019765498

Epoch: 6| Step: 4
Training loss: 0.17161409125211688
Validation loss: 2.3461048271032405

Epoch: 6| Step: 5
Training loss: 0.17161222983518312
Validation loss: 2.3461941898552197

Epoch: 6| Step: 6
Training loss: 0.2523253005992505
Validation loss: 2.306046807135492

Epoch: 6| Step: 7
Training loss: 0.249604799410771
Validation loss: 2.306204032245308

Epoch: 6| Step: 8
Training loss: 0.09659363548681751
Validation loss: 2.3281972053156887

Epoch: 6| Step: 9
Training loss: 0.19133644388103885
Validation loss: 2.3353274364292944

Epoch: 6| Step: 10
Training loss: 0.25045539684718177
Validation loss: 2.3569874969097477

Epoch: 6| Step: 11
Training loss: 0.27904814201574424
Validation loss: 2.3567618160090027

Epoch: 6| Step: 12
Training loss: 0.18126749866794056
Validation loss: 2.333037795703875

Epoch: 6| Step: 13
Training loss: 0.2276489254539662
Validation loss: 2.3397253925777197

Epoch: 351| Step: 0
Training loss: 0.31223428873892206
Validation loss: 2.36003929456385

Epoch: 6| Step: 1
Training loss: 0.24651431674130178
Validation loss: 2.3519682300662046

Epoch: 6| Step: 2
Training loss: 0.11760627704212977
Validation loss: 2.355693923036397

Epoch: 6| Step: 3
Training loss: 0.16387317723817962
Validation loss: 2.3355228051719363

Epoch: 6| Step: 4
Training loss: 0.28509225519171644
Validation loss: 2.311392718847495

Epoch: 6| Step: 5
Training loss: 0.22868675768675198
Validation loss: 2.3446896808407787

Epoch: 6| Step: 6
Training loss: 0.10931623532116755
Validation loss: 2.3097463441193447

Epoch: 6| Step: 7
Training loss: 0.1267745155415111
Validation loss: 2.2990324669585065

Epoch: 6| Step: 8
Training loss: 0.2660380265806622
Validation loss: 2.3201566685064425

Epoch: 6| Step: 9
Training loss: 0.3748014242200142
Validation loss: 2.254866977303621

Epoch: 6| Step: 10
Training loss: 0.33574462499172
Validation loss: 2.246720876722836

Epoch: 6| Step: 11
Training loss: 0.10068168527328021
Validation loss: 2.256625493947999

Epoch: 6| Step: 12
Training loss: 0.1932215729392622
Validation loss: 2.2378369259919157

Epoch: 6| Step: 13
Training loss: 0.16426381180701505
Validation loss: 2.26832624739363

Epoch: 352| Step: 0
Training loss: 0.1410101147153626
Validation loss: 2.2855594222905493

Epoch: 6| Step: 1
Training loss: 0.2324692814027723
Validation loss: 2.286264132169388

Epoch: 6| Step: 2
Training loss: 0.13591486424495075
Validation loss: 2.3375164653037386

Epoch: 6| Step: 3
Training loss: 0.3044644541953699
Validation loss: 2.345871833519285

Epoch: 6| Step: 4
Training loss: 0.13566416274972382
Validation loss: 2.375676456523957

Epoch: 6| Step: 5
Training loss: 0.249939553582659
Validation loss: 2.368167095784971

Epoch: 6| Step: 6
Training loss: 0.3847203106991455
Validation loss: 2.3821086315326045

Epoch: 6| Step: 7
Training loss: 0.1168584455595201
Validation loss: 2.3342077331583257

Epoch: 6| Step: 8
Training loss: 0.1363244979834989
Validation loss: 2.336904034621909

Epoch: 6| Step: 9
Training loss: 0.41403181934051214
Validation loss: 2.301579590996638

Epoch: 6| Step: 10
Training loss: 0.23852821746681646
Validation loss: 2.28020084567089

Epoch: 6| Step: 11
Training loss: 0.12631085863467334
Validation loss: 2.2510444018553133

Epoch: 6| Step: 12
Training loss: 0.18196077742644695
Validation loss: 2.323423087251088

Epoch: 6| Step: 13
Training loss: 0.24418950163824174
Validation loss: 2.331124096700684

Epoch: 353| Step: 0
Training loss: 0.22210397322637682
Validation loss: 2.339153996648411

Epoch: 6| Step: 1
Training loss: 0.18789424773786262
Validation loss: 2.378335964115394

Epoch: 6| Step: 2
Training loss: 0.2745832010224467
Validation loss: 2.4111710998833593

Epoch: 6| Step: 3
Training loss: 0.14206157809561293
Validation loss: 2.4224652510855407

Epoch: 6| Step: 4
Training loss: 0.18615348436940504
Validation loss: 2.409269871559614

Epoch: 6| Step: 5
Training loss: 0.2238009707637976
Validation loss: 2.4342044526314677

Epoch: 6| Step: 6
Training loss: 0.17809687317082484
Validation loss: 2.396978615144028

Epoch: 6| Step: 7
Training loss: 0.27044207328436537
Validation loss: 2.3741911097310497

Epoch: 6| Step: 8
Training loss: 0.22528849226493855
Validation loss: 2.3373984073656575

Epoch: 6| Step: 9
Training loss: 0.16714723538909002
Validation loss: 2.281816655747119

Epoch: 6| Step: 10
Training loss: 0.37859193802233454
Validation loss: 2.2585001052919296

Epoch: 6| Step: 11
Training loss: 0.12738643205934522
Validation loss: 2.2476635187472427

Epoch: 6| Step: 12
Training loss: 0.320602866890488
Validation loss: 2.2298756619006093

Epoch: 6| Step: 13
Training loss: 0.0932116448952115
Validation loss: 2.2662543826073307

Epoch: 354| Step: 0
Training loss: 0.24160606824147327
Validation loss: 2.2525689409612353

Epoch: 6| Step: 1
Training loss: 0.2235914550252945
Validation loss: 2.26345487033989

Epoch: 6| Step: 2
Training loss: 0.14371646147778608
Validation loss: 2.2800201717345048

Epoch: 6| Step: 3
Training loss: 0.11614472642793057
Validation loss: 2.3384207079357058

Epoch: 6| Step: 4
Training loss: 0.2316300021432775
Validation loss: 2.3290508835479877

Epoch: 6| Step: 5
Training loss: 0.28741813458152354
Validation loss: 2.392038519262487

Epoch: 6| Step: 6
Training loss: 0.25864204693308146
Validation loss: 2.378485256928119

Epoch: 6| Step: 7
Training loss: 0.30640128690443746
Validation loss: 2.3636049978229003

Epoch: 6| Step: 8
Training loss: 0.11652249158423522
Validation loss: 2.406818584273768

Epoch: 6| Step: 9
Training loss: 0.21088958125305893
Validation loss: 2.376650438092659

Epoch: 6| Step: 10
Training loss: 0.2115234079123183
Validation loss: 2.383286858299212

Epoch: 6| Step: 11
Training loss: 0.2082373288599794
Validation loss: 2.3932544430590728

Epoch: 6| Step: 12
Training loss: 0.3291666888989469
Validation loss: 2.339739102502642

Epoch: 6| Step: 13
Training loss: 0.23009758496200405
Validation loss: 2.355212473077998

Epoch: 355| Step: 0
Training loss: 0.36122133893688213
Validation loss: 2.346987164876189

Epoch: 6| Step: 1
Training loss: 0.1508594981923482
Validation loss: 2.4082990364669667

Epoch: 6| Step: 2
Training loss: 0.2178643468806435
Validation loss: 2.374407376420661

Epoch: 6| Step: 3
Training loss: 0.17507382138642796
Validation loss: 2.4098902091617465

Epoch: 6| Step: 4
Training loss: 0.19650909086363721
Validation loss: 2.3834461538986518

Epoch: 6| Step: 5
Training loss: 0.10685568632209339
Validation loss: 2.354186635572933

Epoch: 6| Step: 6
Training loss: 0.22733284442346566
Validation loss: 2.3635434702107796

Epoch: 6| Step: 7
Training loss: 0.20869886200242269
Validation loss: 2.331260610572408

Epoch: 6| Step: 8
Training loss: 0.2351900234872678
Validation loss: 2.3016368366337763

Epoch: 6| Step: 9
Training loss: 0.27165572158777884
Validation loss: 2.328992751422206

Epoch: 6| Step: 10
Training loss: 0.0987286621290684
Validation loss: 2.3147907922334565

Epoch: 6| Step: 11
Training loss: 0.19963528526541346
Validation loss: 2.3400815500893333

Epoch: 6| Step: 12
Training loss: 0.19796180628617485
Validation loss: 2.322946854431129

Epoch: 6| Step: 13
Training loss: 0.16660199673988485
Validation loss: 2.35739096871834

Epoch: 356| Step: 0
Training loss: 0.17768257560038245
Validation loss: 2.3738121544470383

Epoch: 6| Step: 1
Training loss: 0.1557140217521975
Validation loss: 2.3493214693912567

Epoch: 6| Step: 2
Training loss: 0.1210048910949944
Validation loss: 2.4014362308815493

Epoch: 6| Step: 3
Training loss: 0.18278663851731858
Validation loss: 2.400372648192263

Epoch: 6| Step: 4
Training loss: 0.2444093522271376
Validation loss: 2.412907007233747

Epoch: 6| Step: 5
Training loss: 0.14927059341494794
Validation loss: 2.386838149192821

Epoch: 6| Step: 6
Training loss: 0.13684836102278777
Validation loss: 2.4004146620415017

Epoch: 6| Step: 7
Training loss: 0.1898258024138451
Validation loss: 2.334329744669534

Epoch: 6| Step: 8
Training loss: 0.11113126398358601
Validation loss: 2.31193189175092

Epoch: 6| Step: 9
Training loss: 0.2797071737690353
Validation loss: 2.3140210684157188

Epoch: 6| Step: 10
Training loss: 0.33688761289407193
Validation loss: 2.26790224225161

Epoch: 6| Step: 11
Training loss: 0.3672522629784339
Validation loss: 2.2706151804621317

Epoch: 6| Step: 12
Training loss: 0.2888038741257747
Validation loss: 2.268947164760123

Epoch: 6| Step: 13
Training loss: 0.15915380747284247
Validation loss: 2.312890848722296

Epoch: 357| Step: 0
Training loss: 0.11503561302932984
Validation loss: 2.3046294783290726

Epoch: 6| Step: 1
Training loss: 0.2116934599323205
Validation loss: 2.364223791335627

Epoch: 6| Step: 2
Training loss: 0.18365618476068138
Validation loss: 2.368766400792926

Epoch: 6| Step: 3
Training loss: 0.2855157937017166
Validation loss: 2.4186031516481017

Epoch: 6| Step: 4
Training loss: 0.2702661391837396
Validation loss: 2.383238414810757

Epoch: 6| Step: 5
Training loss: 0.21225467678922685
Validation loss: 2.3390238592945214

Epoch: 6| Step: 6
Training loss: 0.22955702819347498
Validation loss: 2.3186818413047914

Epoch: 6| Step: 7
Training loss: 0.3251553072679703
Validation loss: 2.3037083067663326

Epoch: 6| Step: 8
Training loss: 0.19537974153794643
Validation loss: 2.262714424480825

Epoch: 6| Step: 9
Training loss: 0.2090157280335875
Validation loss: 2.271794882034477

Epoch: 6| Step: 10
Training loss: 0.21114415183305027
Validation loss: 2.286351999596563

Epoch: 6| Step: 11
Training loss: 0.11903258803359933
Validation loss: 2.28426634109231

Epoch: 6| Step: 12
Training loss: 0.1142872421966644
Validation loss: 2.2936172201481075

Epoch: 6| Step: 13
Training loss: 0.16898600689068735
Validation loss: 2.3079380122769506

Epoch: 358| Step: 0
Training loss: 0.26158777916915654
Validation loss: 2.3474172590944096

Epoch: 6| Step: 1
Training loss: 0.1464278938758772
Validation loss: 2.373429329539353

Epoch: 6| Step: 2
Training loss: 0.15772394915771995
Validation loss: 2.3639343200075356

Epoch: 6| Step: 3
Training loss: 0.29384099180068457
Validation loss: 2.4038718595731616

Epoch: 6| Step: 4
Training loss: 0.2604556134028572
Validation loss: 2.389463499219165

Epoch: 6| Step: 5
Training loss: 0.1533064623365806
Validation loss: 2.382256714011382

Epoch: 6| Step: 6
Training loss: 0.17516486925123345
Validation loss: 2.352887711066062

Epoch: 6| Step: 7
Training loss: 0.14292575966316357
Validation loss: 2.3676665934148273

Epoch: 6| Step: 8
Training loss: 0.30635487551295304
Validation loss: 2.3434247858434487

Epoch: 6| Step: 9
Training loss: 0.16671242619706111
Validation loss: 2.327535217199537

Epoch: 6| Step: 10
Training loss: 0.25209578090600115
Validation loss: 2.3159449458886843

Epoch: 6| Step: 11
Training loss: 0.2077373304153247
Validation loss: 2.279182694202863

Epoch: 6| Step: 12
Training loss: 0.18367461189103365
Validation loss: 2.2970674791426555

Epoch: 6| Step: 13
Training loss: 0.18078889400374923
Validation loss: 2.3003054860475127

Epoch: 359| Step: 0
Training loss: 0.2804767788133658
Validation loss: 2.3175589122125766

Epoch: 6| Step: 1
Training loss: 0.14324282812220263
Validation loss: 2.336749773645179

Epoch: 6| Step: 2
Training loss: 0.08356805399770424
Validation loss: 2.330457894029348

Epoch: 6| Step: 3
Training loss: 0.2274538953144006
Validation loss: 2.4211006866513376

Epoch: 6| Step: 4
Training loss: 0.11656512453075026
Validation loss: 2.412621411220469

Epoch: 6| Step: 5
Training loss: 0.2736079502178628
Validation loss: 2.406114806442021

Epoch: 6| Step: 6
Training loss: 0.23269699546893122
Validation loss: 2.413964646790706

Epoch: 6| Step: 7
Training loss: 0.29574375704901934
Validation loss: 2.368371154573252

Epoch: 6| Step: 8
Training loss: 0.2540663581170449
Validation loss: 2.3848542405115527

Epoch: 6| Step: 9
Training loss: 0.2793310718008581
Validation loss: 2.3602744973007206

Epoch: 6| Step: 10
Training loss: 0.18431065980426609
Validation loss: 2.314062104762399

Epoch: 6| Step: 11
Training loss: 0.18898645913156434
Validation loss: 2.279895838495632

Epoch: 6| Step: 12
Training loss: 0.19227713378785669
Validation loss: 2.2905480125877435

Epoch: 6| Step: 13
Training loss: 0.19136481907148437
Validation loss: 2.3087400451783457

Epoch: 360| Step: 0
Training loss: 0.16027052221917193
Validation loss: 2.333698269070853

Epoch: 6| Step: 1
Training loss: 0.16141239533076457
Validation loss: 2.356961895034012

Epoch: 6| Step: 2
Training loss: 0.14682846346640885
Validation loss: 2.3788323680467625

Epoch: 6| Step: 3
Training loss: 0.3032063404552632
Validation loss: 2.396677486088846

Epoch: 6| Step: 4
Training loss: 0.18710373688806214
Validation loss: 2.4125689062119915

Epoch: 6| Step: 5
Training loss: 0.324624141352667
Validation loss: 2.4287031612057914

Epoch: 6| Step: 6
Training loss: 0.29785705311201455
Validation loss: 2.386007350194089

Epoch: 6| Step: 7
Training loss: 0.15131431394464293
Validation loss: 2.353039634450554

Epoch: 6| Step: 8
Training loss: 0.276926008115619
Validation loss: 2.286767749218033

Epoch: 6| Step: 9
Training loss: 0.24889671242754705
Validation loss: 2.269240590610378

Epoch: 6| Step: 10
Training loss: 0.2105188453715098
Validation loss: 2.27188935288924

Epoch: 6| Step: 11
Training loss: 0.23474044125213048
Validation loss: 2.2232021198750904

Epoch: 6| Step: 12
Training loss: 0.24196509947813394
Validation loss: 2.2431299230559554

Epoch: 6| Step: 13
Training loss: 0.23426232808607875
Validation loss: 2.3318816128212085

Epoch: 361| Step: 0
Training loss: 0.19423081319883637
Validation loss: 2.341115889727966

Epoch: 6| Step: 1
Training loss: 0.2922109849436807
Validation loss: 2.358031301733173

Epoch: 6| Step: 2
Training loss: 0.29682255582870626
Validation loss: 2.3791239716441046

Epoch: 6| Step: 3
Training loss: 0.30552595876033406
Validation loss: 2.4009935233040194

Epoch: 6| Step: 4
Training loss: 0.16573605278146278
Validation loss: 2.3901135361784105

Epoch: 6| Step: 5
Training loss: 0.1525628458450473
Validation loss: 2.3856977967102164

Epoch: 6| Step: 6
Training loss: 0.17067737996255355
Validation loss: 2.343702631646037

Epoch: 6| Step: 7
Training loss: 0.16726611352463447
Validation loss: 2.392704963327241

Epoch: 6| Step: 8
Training loss: 0.23454288192052877
Validation loss: 2.342724537080151

Epoch: 6| Step: 9
Training loss: 0.2324891193469069
Validation loss: 2.3312820355391235

Epoch: 6| Step: 10
Training loss: 0.1780740196489166
Validation loss: 2.317654828325873

Epoch: 6| Step: 11
Training loss: 0.31516034699984097
Validation loss: 2.2972481922291474

Epoch: 6| Step: 12
Training loss: 0.32665439708975746
Validation loss: 2.322750828559923

Epoch: 6| Step: 13
Training loss: 0.10171712970029112
Validation loss: 2.367329101052821

Epoch: 362| Step: 0
Training loss: 0.17373490244808254
Validation loss: 2.4053854836265316

Epoch: 6| Step: 1
Training loss: 0.21258075280687516
Validation loss: 2.4519969383573534

Epoch: 6| Step: 2
Training loss: 0.16046314376427934
Validation loss: 2.481001682470904

Epoch: 6| Step: 3
Training loss: 0.350966085406013
Validation loss: 2.496926588371849

Epoch: 6| Step: 4
Training loss: 0.2991043260478307
Validation loss: 2.4369429405866954

Epoch: 6| Step: 5
Training loss: 0.17906035986215568
Validation loss: 2.3392467494192233

Epoch: 6| Step: 6
Training loss: 0.3020721206009098
Validation loss: 2.273591288710166

Epoch: 6| Step: 7
Training loss: 0.31883842606788565
Validation loss: 2.227511353627518

Epoch: 6| Step: 8
Training loss: 0.14966093499582406
Validation loss: 2.2609602530348716

Epoch: 6| Step: 9
Training loss: 0.18098619970182175
Validation loss: 2.294402760248999

Epoch: 6| Step: 10
Training loss: 0.23366571230144756
Validation loss: 2.2904622572938806

Epoch: 6| Step: 11
Training loss: 0.3572852702258708
Validation loss: 2.332986055041236

Epoch: 6| Step: 12
Training loss: 0.2541754542587872
Validation loss: 2.336537036348602

Epoch: 6| Step: 13
Training loss: 0.29233590758267525
Validation loss: 2.376469550924551

Epoch: 363| Step: 0
Training loss: 0.22511440388568488
Validation loss: 2.3696847860558097

Epoch: 6| Step: 1
Training loss: 0.28303542598066733
Validation loss: 2.357593924886576

Epoch: 6| Step: 2
Training loss: 0.2745625375929576
Validation loss: 2.3303816576098306

Epoch: 6| Step: 3
Training loss: 0.31395606329758974
Validation loss: 2.309922231362956

Epoch: 6| Step: 4
Training loss: 0.1258968648241216
Validation loss: 2.2799734852999034

Epoch: 6| Step: 5
Training loss: 0.16626999945380277
Validation loss: 2.2810230976696197

Epoch: 6| Step: 6
Training loss: 0.3576323509647491
Validation loss: 2.2802828048896955

Epoch: 6| Step: 7
Training loss: 0.19384092996683966
Validation loss: 2.2572932372392085

Epoch: 6| Step: 8
Training loss: 0.2268282959026826
Validation loss: 2.296264347103472

Epoch: 6| Step: 9
Training loss: 0.13170629414166798
Validation loss: 2.3109170517321873

Epoch: 6| Step: 10
Training loss: 0.13895261580711624
Validation loss: 2.2969198781313414

Epoch: 6| Step: 11
Training loss: 0.31493861470722617
Validation loss: 2.3436979915632064

Epoch: 6| Step: 12
Training loss: 0.1833837911589228
Validation loss: 2.328268894732276

Epoch: 6| Step: 13
Training loss: 0.3307735971458394
Validation loss: 2.338418994946274

Epoch: 364| Step: 0
Training loss: 0.37140620278569597
Validation loss: 2.2938664275829597

Epoch: 6| Step: 1
Training loss: 0.1639344646763317
Validation loss: 2.263025339011343

Epoch: 6| Step: 2
Training loss: 0.2963451878014883
Validation loss: 2.24135174159854

Epoch: 6| Step: 3
Training loss: 0.20480007213723042
Validation loss: 2.239461245193616

Epoch: 6| Step: 4
Training loss: 0.1961739900263046
Validation loss: 2.2568273985881575

Epoch: 6| Step: 5
Training loss: 0.28762589269082584
Validation loss: 2.2721367546369313

Epoch: 6| Step: 6
Training loss: 0.27055927158984194
Validation loss: 2.311821631584853

Epoch: 6| Step: 7
Training loss: 0.3741401709320633
Validation loss: 2.3531491295455833

Epoch: 6| Step: 8
Training loss: 0.26775227747588803
Validation loss: 2.3280442889997266

Epoch: 6| Step: 9
Training loss: 0.20537193686348054
Validation loss: 2.35737172114276

Epoch: 6| Step: 10
Training loss: 0.21544045034933154
Validation loss: 2.383843027858338

Epoch: 6| Step: 11
Training loss: 0.4343695701973292
Validation loss: 2.4091450748314633

Epoch: 6| Step: 12
Training loss: 0.2757522697459071
Validation loss: 2.3673623395879324

Epoch: 6| Step: 13
Training loss: 0.13801577996653708
Validation loss: 2.3702439774521227

Epoch: 365| Step: 0
Training loss: 0.21373608023789198
Validation loss: 2.3251634155527223

Epoch: 6| Step: 1
Training loss: 0.15740241410816785
Validation loss: 2.295961753312135

Epoch: 6| Step: 2
Training loss: 0.20356006063991397
Validation loss: 2.3073469671236437

Epoch: 6| Step: 3
Training loss: 0.14723053673541756
Validation loss: 2.3086692800895654

Epoch: 6| Step: 4
Training loss: 0.29837617793368065
Validation loss: 2.319001432708206

Epoch: 6| Step: 5
Training loss: 0.3640729828991159
Validation loss: 2.3286150289760026

Epoch: 6| Step: 6
Training loss: 0.29817802173627866
Validation loss: 2.3551534943313297

Epoch: 6| Step: 7
Training loss: 0.18849907379909403
Validation loss: 2.3639731566969275

Epoch: 6| Step: 8
Training loss: 0.3068058030685026
Validation loss: 2.394173269484791

Epoch: 6| Step: 9
Training loss: 0.14495183989652263
Validation loss: 2.393750582780373

Epoch: 6| Step: 10
Training loss: 0.25236861398750343
Validation loss: 2.3953652829335708

Epoch: 6| Step: 11
Training loss: 0.19130563037518603
Validation loss: 2.406119890854516

Epoch: 6| Step: 12
Training loss: 0.23457656775780733
Validation loss: 2.374392239019793

Epoch: 6| Step: 13
Training loss: 0.28081696339975565
Validation loss: 2.3759604488986796

Epoch: 366| Step: 0
Training loss: 0.1303443309731661
Validation loss: 2.333507307403695

Epoch: 6| Step: 1
Training loss: 0.3008451765420277
Validation loss: 2.295909766674361

Epoch: 6| Step: 2
Training loss: 0.2778127492639648
Validation loss: 2.267270448454565

Epoch: 6| Step: 3
Training loss: 0.16885663610421925
Validation loss: 2.2682340089813087

Epoch: 6| Step: 4
Training loss: 0.24762437537093818
Validation loss: 2.2723089366552194

Epoch: 6| Step: 5
Training loss: 0.1295849029473041
Validation loss: 2.283696791851318

Epoch: 6| Step: 6
Training loss: 0.34072100659990895
Validation loss: 2.308154601131458

Epoch: 6| Step: 7
Training loss: 0.31799466357911804
Validation loss: 2.2937382646821365

Epoch: 6| Step: 8
Training loss: 0.2571623435991075
Validation loss: 2.3819687744009097

Epoch: 6| Step: 9
Training loss: 0.2812315484458109
Validation loss: 2.3907528716452817

Epoch: 6| Step: 10
Training loss: 0.2657898223230104
Validation loss: 2.405745757227982

Epoch: 6| Step: 11
Training loss: 0.14154010622949698
Validation loss: 2.366788132121536

Epoch: 6| Step: 12
Training loss: 0.177531713705023
Validation loss: 2.3586785170561297

Epoch: 6| Step: 13
Training loss: 0.26434794747483104
Validation loss: 2.324983327273024

Epoch: 367| Step: 0
Training loss: 0.1966503102429831
Validation loss: 2.3209666005560723

Epoch: 6| Step: 1
Training loss: 0.2663778687067104
Validation loss: 2.3531287175034103

Epoch: 6| Step: 2
Training loss: 0.24551756330380592
Validation loss: 2.3714630849691556

Epoch: 6| Step: 3
Training loss: 0.2751621353585776
Validation loss: 2.4031800149889597

Epoch: 6| Step: 4
Training loss: 0.21174936882541992
Validation loss: 2.4306764595052677

Epoch: 6| Step: 5
Training loss: 0.37617536961089926
Validation loss: 2.403660263181572

Epoch: 6| Step: 6
Training loss: 0.33634776192115134
Validation loss: 2.350796844528083

Epoch: 6| Step: 7
Training loss: 0.26505578985537914
Validation loss: 2.3114851196556216

Epoch: 6| Step: 8
Training loss: 0.17379604000627297
Validation loss: 2.3269369757317984

Epoch: 6| Step: 9
Training loss: 0.2413677987397939
Validation loss: 2.2836736064526098

Epoch: 6| Step: 10
Training loss: 0.17763768175397812
Validation loss: 2.279494854008742

Epoch: 6| Step: 11
Training loss: 0.3884689337977233
Validation loss: 2.256630194068246

Epoch: 6| Step: 12
Training loss: 0.15511649975783917
Validation loss: 2.3180991724106654

Epoch: 6| Step: 13
Training loss: 0.14285045899780419
Validation loss: 2.347385433666741

Epoch: 368| Step: 0
Training loss: 0.49478645489273465
Validation loss: 2.4135754673375778

Epoch: 6| Step: 1
Training loss: 0.41007315384302084
Validation loss: 2.3874305692238034

Epoch: 6| Step: 2
Training loss: 0.18827920176551394
Validation loss: 2.2548508895943393

Epoch: 6| Step: 3
Training loss: 0.18711147187716495
Validation loss: 2.2045180025165703

Epoch: 6| Step: 4
Training loss: 0.320176886716782
Validation loss: 2.1695298903147417

Epoch: 6| Step: 5
Training loss: 0.40420722888973515
Validation loss: 2.189660364127266

Epoch: 6| Step: 6
Training loss: 0.440706660772651
Validation loss: 2.261045552653358

Epoch: 6| Step: 7
Training loss: 0.2803356354180824
Validation loss: 2.3363921728228725

Epoch: 6| Step: 8
Training loss: 0.25036753519750493
Validation loss: 2.4343861767998565

Epoch: 6| Step: 9
Training loss: 0.32159945675056156
Validation loss: 2.4955596149490105

Epoch: 6| Step: 10
Training loss: 0.42182240334880833
Validation loss: 2.50412990555439

Epoch: 6| Step: 11
Training loss: 0.32578652283863335
Validation loss: 2.44869213052766

Epoch: 6| Step: 12
Training loss: 0.16718626734911984
Validation loss: 2.332156406033658

Epoch: 6| Step: 13
Training loss: 0.2909397563990237
Validation loss: 2.2582205234712363

Epoch: 369| Step: 0
Training loss: 0.43174350599895206
Validation loss: 2.2472653103266147

Epoch: 6| Step: 1
Training loss: 0.31118155347295234
Validation loss: 2.2018232023147344

Epoch: 6| Step: 2
Training loss: 0.33954685220976794
Validation loss: 2.2441310130718253

Epoch: 6| Step: 3
Training loss: 0.2759837533671357
Validation loss: 2.2770943645213886

Epoch: 6| Step: 4
Training loss: 0.3198001066247668
Validation loss: 2.3547996801026403

Epoch: 6| Step: 5
Training loss: 0.2991258845629049
Validation loss: 2.4335781885610595

Epoch: 6| Step: 6
Training loss: 0.45895903497100593
Validation loss: 2.451224174377899

Epoch: 6| Step: 7
Training loss: 0.26620235527237623
Validation loss: 2.400421480137905

Epoch: 6| Step: 8
Training loss: 0.3203227576497438
Validation loss: 2.371592198416893

Epoch: 6| Step: 9
Training loss: 0.364761781163653
Validation loss: 2.3490195437703982

Epoch: 6| Step: 10
Training loss: 0.3281481371397018
Validation loss: 2.314745348673085

Epoch: 6| Step: 11
Training loss: 0.24127414199621997
Validation loss: 2.316745078298122

Epoch: 6| Step: 12
Training loss: 0.28529878215673604
Validation loss: 2.304530881159326

Epoch: 6| Step: 13
Training loss: 0.20982642189565837
Validation loss: 2.32445143523045

Epoch: 370| Step: 0
Training loss: 0.27090251784768654
Validation loss: 2.3484702200111167

Epoch: 6| Step: 1
Training loss: 0.370318838459607
Validation loss: 2.350111007861301

Epoch: 6| Step: 2
Training loss: 0.2801480960031651
Validation loss: 2.3519874869818014

Epoch: 6| Step: 3
Training loss: 0.30737042899376643
Validation loss: 2.352773483009711

Epoch: 6| Step: 4
Training loss: 0.2864160275286137
Validation loss: 2.278202036215336

Epoch: 6| Step: 5
Training loss: 0.3658768414163338
Validation loss: 2.278046855528436

Epoch: 6| Step: 6
Training loss: 0.3322117483165341
Validation loss: 2.2499664080811446

Epoch: 6| Step: 7
Training loss: 0.23140292845923743
Validation loss: 2.2643619919327036

Epoch: 6| Step: 8
Training loss: 0.22329135296644084
Validation loss: 2.2721956649781307

Epoch: 6| Step: 9
Training loss: 0.3235670802252933
Validation loss: 2.306099652474345

Epoch: 6| Step: 10
Training loss: 0.41610483994927094
Validation loss: 2.37929178653887

Epoch: 6| Step: 11
Training loss: 0.42657445813978334
Validation loss: 2.4273200699734216

Epoch: 6| Step: 12
Training loss: 0.2536250391170947
Validation loss: 2.4341551140930116

Epoch: 6| Step: 13
Training loss: 0.21401112211372175
Validation loss: 2.405171675713532

Epoch: 371| Step: 0
Training loss: 0.2689935046797994
Validation loss: 2.3897568532993976

Epoch: 6| Step: 1
Training loss: 0.32652393916493466
Validation loss: 2.3581256499185925

Epoch: 6| Step: 2
Training loss: 0.3660717101876907
Validation loss: 2.350702604618338

Epoch: 6| Step: 3
Training loss: 0.36607930169959885
Validation loss: 2.2984635914074745

Epoch: 6| Step: 4
Training loss: 0.14653489195458386
Validation loss: 2.3136882273499864

Epoch: 6| Step: 5
Training loss: 0.17106184095751217
Validation loss: 2.3702102487983856

Epoch: 6| Step: 6
Training loss: 0.2722582319397019
Validation loss: 2.3613994572720314

Epoch: 6| Step: 7
Training loss: 0.36834109474364934
Validation loss: 2.3950169403335444

Epoch: 6| Step: 8
Training loss: 0.27464750141911504
Validation loss: 2.375772321476908

Epoch: 6| Step: 9
Training loss: 0.3737742736997138
Validation loss: 2.407950222664528

Epoch: 6| Step: 10
Training loss: 0.17684915195350195
Validation loss: 2.3582132792515003

Epoch: 6| Step: 11
Training loss: 0.33689108507613186
Validation loss: 2.343839426829866

Epoch: 6| Step: 12
Training loss: 0.27377543683951205
Validation loss: 2.300605041663556

Epoch: 6| Step: 13
Training loss: 0.1586446311679293
Validation loss: 2.28978601478773

Epoch: 372| Step: 0
Training loss: 0.17585037779532908
Validation loss: 2.2726636011353634

Epoch: 6| Step: 1
Training loss: 0.2562841136834244
Validation loss: 2.268501396980528

Epoch: 6| Step: 2
Training loss: 0.32091527141268394
Validation loss: 2.257826081683701

Epoch: 6| Step: 3
Training loss: 0.40828514187779447
Validation loss: 2.2750537639685064

Epoch: 6| Step: 4
Training loss: 0.47161643668417397
Validation loss: 2.297260250161966

Epoch: 6| Step: 5
Training loss: 0.266257052999754
Validation loss: 2.299042782125795

Epoch: 6| Step: 6
Training loss: 0.2487014034619322
Validation loss: 2.3128057542128713

Epoch: 6| Step: 7
Training loss: 0.38705368180272604
Validation loss: 2.3651098810972773

Epoch: 6| Step: 8
Training loss: 0.3120798147094008
Validation loss: 2.3603295563862177

Epoch: 6| Step: 9
Training loss: 0.3006404571960974
Validation loss: 2.361148138879904

Epoch: 6| Step: 10
Training loss: 0.24413316333812318
Validation loss: 2.2954709810504226

Epoch: 6| Step: 11
Training loss: 0.30171072385712194
Validation loss: 2.3050507467951795

Epoch: 6| Step: 12
Training loss: 0.39019727177308955
Validation loss: 2.2817832097744977

Epoch: 6| Step: 13
Training loss: 0.39337646386644204
Validation loss: 2.289332455284796

Epoch: 373| Step: 0
Training loss: 0.33283380117886524
Validation loss: 2.286348344221033

Epoch: 6| Step: 1
Training loss: 0.3135784613394479
Validation loss: 2.362411396704463

Epoch: 6| Step: 2
Training loss: 0.3709631238216226
Validation loss: 2.3977762454243856

Epoch: 6| Step: 3
Training loss: 0.3295221668979427
Validation loss: 2.427334885753807

Epoch: 6| Step: 4
Training loss: 0.4293031534112452
Validation loss: 2.4813992729693752

Epoch: 6| Step: 5
Training loss: 0.3882501892929451
Validation loss: 2.449428180885416

Epoch: 6| Step: 6
Training loss: 0.3229157104272938
Validation loss: 2.4359449343583774

Epoch: 6| Step: 7
Training loss: 0.36688634006838966
Validation loss: 2.384400744957665

Epoch: 6| Step: 8
Training loss: 0.222723298267368
Validation loss: 2.348248952096027

Epoch: 6| Step: 9
Training loss: 0.18017525401464718
Validation loss: 2.320619666310709

Epoch: 6| Step: 10
Training loss: 0.2560272830640452
Validation loss: 2.2917503181322103

Epoch: 6| Step: 11
Training loss: 0.1679926456043707
Validation loss: 2.2960690213022423

Epoch: 6| Step: 12
Training loss: 0.24554255231401642
Validation loss: 2.3177963689934353

Epoch: 6| Step: 13
Training loss: 0.2540505805979121
Validation loss: 2.3022308666116422

Epoch: 374| Step: 0
Training loss: 0.4152565419981074
Validation loss: 2.3209856734211343

Epoch: 6| Step: 1
Training loss: 0.3473628659979156
Validation loss: 2.2790242607559232

Epoch: 6| Step: 2
Training loss: 0.21921738013059067
Validation loss: 2.334343796533149

Epoch: 6| Step: 3
Training loss: 0.22425118786572704
Validation loss: 2.327990775606913

Epoch: 6| Step: 4
Training loss: 0.2650517420592572
Validation loss: 2.3482113746421422

Epoch: 6| Step: 5
Training loss: 0.25517125087355946
Validation loss: 2.325136136865727

Epoch: 6| Step: 6
Training loss: 0.183081154798477
Validation loss: 2.365353950439676

Epoch: 6| Step: 7
Training loss: 0.2046881737588757
Validation loss: 2.344376860981634

Epoch: 6| Step: 8
Training loss: 0.13685675876162423
Validation loss: 2.355378470570489

Epoch: 6| Step: 9
Training loss: 0.2778871880405369
Validation loss: 2.3539918977501437

Epoch: 6| Step: 10
Training loss: 0.3291984324981978
Validation loss: 2.3629572169663353

Epoch: 6| Step: 11
Training loss: 0.23129942275637855
Validation loss: 2.364818891579335

Epoch: 6| Step: 12
Training loss: 0.3098898961863528
Validation loss: 2.413103997015997

Epoch: 6| Step: 13
Training loss: 0.1806288091957467
Validation loss: 2.416770293871487

Epoch: 375| Step: 0
Training loss: 0.3052168185299013
Validation loss: 2.456932479720224

Epoch: 6| Step: 1
Training loss: 0.18943405055344884
Validation loss: 2.4659624064110535

Epoch: 6| Step: 2
Training loss: 0.2897016572836394
Validation loss: 2.472354383389968

Epoch: 6| Step: 3
Training loss: 0.16289244954942095
Validation loss: 2.422262077612653

Epoch: 6| Step: 4
Training loss: 0.2859404506426882
Validation loss: 2.3883375880859394

Epoch: 6| Step: 5
Training loss: 0.21593679331375396
Validation loss: 2.3363859996035656

Epoch: 6| Step: 6
Training loss: 0.27269300196725743
Validation loss: 2.328373364645045

Epoch: 6| Step: 7
Training loss: 0.441594598471434
Validation loss: 2.2870034433185573

Epoch: 6| Step: 8
Training loss: 0.16829840890505718
Validation loss: 2.350787698141874

Epoch: 6| Step: 9
Training loss: 0.17337339909246893
Validation loss: 2.357033384459885

Epoch: 6| Step: 10
Training loss: 0.22501988422428032
Validation loss: 2.375382728804411

Epoch: 6| Step: 11
Training loss: 0.2277430491815712
Validation loss: 2.400376205756808

Epoch: 6| Step: 12
Training loss: 0.2058452608601215
Validation loss: 2.443797599212048

Epoch: 6| Step: 13
Training loss: 0.3740351901685465
Validation loss: 2.446442532029311

Epoch: 376| Step: 0
Training loss: 0.24476216354869101
Validation loss: 2.4147755515289506

Epoch: 6| Step: 1
Training loss: 0.1430139673362645
Validation loss: 2.3540077326429927

Epoch: 6| Step: 2
Training loss: 0.13086057064591952
Validation loss: 2.2837797913702134

Epoch: 6| Step: 3
Training loss: 0.22583575267363878
Validation loss: 2.2510901958090646

Epoch: 6| Step: 4
Training loss: 0.19166227656153442
Validation loss: 2.1819126525328363

Epoch: 6| Step: 5
Training loss: 0.2185122185319849
Validation loss: 2.18074508851586

Epoch: 6| Step: 6
Training loss: 0.22460549392664228
Validation loss: 2.195904739995623

Epoch: 6| Step: 7
Training loss: 0.38731605947846265
Validation loss: 2.2049194698562746

Epoch: 6| Step: 8
Training loss: 0.29075149736486255
Validation loss: 2.2267004275818945

Epoch: 6| Step: 9
Training loss: 0.13821525345842306
Validation loss: 2.2829359070074355

Epoch: 6| Step: 10
Training loss: 0.22879146164998562
Validation loss: 2.3158120275417278

Epoch: 6| Step: 11
Training loss: 0.2384658317432348
Validation loss: 2.371448124443357

Epoch: 6| Step: 12
Training loss: 0.27548651682854247
Validation loss: 2.406443395941223

Epoch: 6| Step: 13
Training loss: 0.190676602430101
Validation loss: 2.4561794847122487

Epoch: 377| Step: 0
Training loss: 0.3068176536041748
Validation loss: 2.4764053493099754

Epoch: 6| Step: 1
Training loss: 0.22586399957704897
Validation loss: 2.4883506995608076

Epoch: 6| Step: 2
Training loss: 0.35944962763271554
Validation loss: 2.433901417202795

Epoch: 6| Step: 3
Training loss: 0.2032387671621827
Validation loss: 2.426861169026638

Epoch: 6| Step: 4
Training loss: 0.2603516815482895
Validation loss: 2.3991492317913807

Epoch: 6| Step: 5
Training loss: 0.2189163273895354
Validation loss: 2.3255597997014696

Epoch: 6| Step: 6
Training loss: 0.2780043565353878
Validation loss: 2.308842467384509

Epoch: 6| Step: 7
Training loss: 0.12022894800590753
Validation loss: 2.3363868466939914

Epoch: 6| Step: 8
Training loss: 0.1465332331239491
Validation loss: 2.3219029271766827

Epoch: 6| Step: 9
Training loss: 0.27101718030116556
Validation loss: 2.3132203910935356

Epoch: 6| Step: 10
Training loss: 0.21961275332202465
Validation loss: 2.321144420844544

Epoch: 6| Step: 11
Training loss: 0.16175402334934436
Validation loss: 2.329853891195088

Epoch: 6| Step: 12
Training loss: 0.17875791672201366
Validation loss: 2.3325535845467686

Epoch: 6| Step: 13
Training loss: 0.15673295127861672
Validation loss: 2.367296563254906

Epoch: 378| Step: 0
Training loss: 0.32854008532530377
Validation loss: 2.3912477592986647

Epoch: 6| Step: 1
Training loss: 0.25543605933589325
Validation loss: 2.389801337112335

Epoch: 6| Step: 2
Training loss: 0.23442429977715976
Validation loss: 2.3931097803172405

Epoch: 6| Step: 3
Training loss: 0.29448647601449407
Validation loss: 2.3567623522849557

Epoch: 6| Step: 4
Training loss: 0.14203509032845735
Validation loss: 2.3455708071171952

Epoch: 6| Step: 5
Training loss: 0.19532938884194712
Validation loss: 2.3320809616655507

Epoch: 6| Step: 6
Training loss: 0.15258801269526368
Validation loss: 2.3298478866104104

Epoch: 6| Step: 7
Training loss: 0.1622478054916552
Validation loss: 2.306884670469951

Epoch: 6| Step: 8
Training loss: 0.1421855722024203
Validation loss: 2.3143899700173605

Epoch: 6| Step: 9
Training loss: 0.15370830111926803
Validation loss: 2.303356683956802

Epoch: 6| Step: 10
Training loss: 0.2560926640541648
Validation loss: 2.3053094818893003

Epoch: 6| Step: 11
Training loss: 0.2014145544750505
Validation loss: 2.320887311868591

Epoch: 6| Step: 12
Training loss: 0.24720545604656338
Validation loss: 2.2946656174847018

Epoch: 6| Step: 13
Training loss: 0.12033908398576271
Validation loss: 2.3103273323984346

Epoch: 379| Step: 0
Training loss: 0.14894455963312656
Validation loss: 2.322887354435491

Epoch: 6| Step: 1
Training loss: 0.13183961086100607
Validation loss: 2.2924139025809027

Epoch: 6| Step: 2
Training loss: 0.2229869127260801
Validation loss: 2.344230083121942

Epoch: 6| Step: 3
Training loss: 0.16626573123396132
Validation loss: 2.3979094915732673

Epoch: 6| Step: 4
Training loss: 0.29030614815159755
Validation loss: 2.3838390789002477

Epoch: 6| Step: 5
Training loss: 0.1711979992603938
Validation loss: 2.414457006516532

Epoch: 6| Step: 6
Training loss: 0.19975275574825455
Validation loss: 2.3566862368636654

Epoch: 6| Step: 7
Training loss: 0.17613705546838918
Validation loss: 2.3750070443343057

Epoch: 6| Step: 8
Training loss: 0.29359678980465165
Validation loss: 2.305625786543326

Epoch: 6| Step: 9
Training loss: 0.17580945530413603
Validation loss: 2.272007439883017

Epoch: 6| Step: 10
Training loss: 0.2619498499373465
Validation loss: 2.266560388497808

Epoch: 6| Step: 11
Training loss: 0.24427093842727146
Validation loss: 2.270451087838503

Epoch: 6| Step: 12
Training loss: 0.2118011472630655
Validation loss: 2.254274240534027

Epoch: 6| Step: 13
Training loss: 0.16653645664321465
Validation loss: 2.2589560376701945

Epoch: 380| Step: 0
Training loss: 0.17083831274424435
Validation loss: 2.3038732893510967

Epoch: 6| Step: 1
Training loss: 0.129478053361562
Validation loss: 2.3260243341154596

Epoch: 6| Step: 2
Training loss: 0.2532230134454658
Validation loss: 2.349131572026633

Epoch: 6| Step: 3
Training loss: 0.20098068818805867
Validation loss: 2.3766413539881874

Epoch: 6| Step: 4
Training loss: 0.3358404884432023
Validation loss: 2.376501236056281

Epoch: 6| Step: 5
Training loss: 0.2669814759947261
Validation loss: 2.4034027334686012

Epoch: 6| Step: 6
Training loss: 0.14833915740426296
Validation loss: 2.390302466486589

Epoch: 6| Step: 7
Training loss: 0.20310261492994486
Validation loss: 2.342031105341661

Epoch: 6| Step: 8
Training loss: 0.16675725662914426
Validation loss: 2.329390634446597

Epoch: 6| Step: 9
Training loss: 0.21549177407786302
Validation loss: 2.3097620228386977

Epoch: 6| Step: 10
Training loss: 0.17426022390900348
Validation loss: 2.293092896514107

Epoch: 6| Step: 11
Training loss: 0.17312848812335174
Validation loss: 2.2660599723469876

Epoch: 6| Step: 12
Training loss: 0.19485941786433314
Validation loss: 2.2438447908767727

Epoch: 6| Step: 13
Training loss: 0.16841690580733132
Validation loss: 2.253840181924272

Epoch: 381| Step: 0
Training loss: 0.14752423273264226
Validation loss: 2.25832014156824

Epoch: 6| Step: 1
Training loss: 0.1960751520889492
Validation loss: 2.275501073165084

Epoch: 6| Step: 2
Training loss: 0.12138644346542017
Validation loss: 2.334119129002236

Epoch: 6| Step: 3
Training loss: 0.17605382131528927
Validation loss: 2.397788883565383

Epoch: 6| Step: 4
Training loss: 0.33441773123745583
Validation loss: 2.394812663893597

Epoch: 6| Step: 5
Training loss: 0.2686412186366174
Validation loss: 2.404448454481496

Epoch: 6| Step: 6
Training loss: 0.23178858992604187
Validation loss: 2.3943680878938705

Epoch: 6| Step: 7
Training loss: 0.20637277034188156
Validation loss: 2.3481885789616217

Epoch: 6| Step: 8
Training loss: 0.272980266845597
Validation loss: 2.3490163286032444

Epoch: 6| Step: 9
Training loss: 0.16047655036487574
Validation loss: 2.290868202414145

Epoch: 6| Step: 10
Training loss: 0.1187886291340453
Validation loss: 2.2643844291483877

Epoch: 6| Step: 11
Training loss: 0.23291052412407892
Validation loss: 2.208619824905402

Epoch: 6| Step: 12
Training loss: 0.18999086339214574
Validation loss: 2.236241015299495

Epoch: 6| Step: 13
Training loss: 0.19176330156021384
Validation loss: 2.2266482745612017

Epoch: 382| Step: 0
Training loss: 0.21227373636280916
Validation loss: 2.239497170838193

Epoch: 6| Step: 1
Training loss: 0.28190055418376164
Validation loss: 2.2506544962620985

Epoch: 6| Step: 2
Training loss: 0.3063733703892113
Validation loss: 2.2405294844114123

Epoch: 6| Step: 3
Training loss: 0.34463706219027473
Validation loss: 2.2457266107927967

Epoch: 6| Step: 4
Training loss: 0.17925984866726732
Validation loss: 2.27437956985275

Epoch: 6| Step: 5
Training loss: 0.15108472248789925
Validation loss: 2.3421129762226562

Epoch: 6| Step: 6
Training loss: 0.16148707431406692
Validation loss: 2.3479245641842534

Epoch: 6| Step: 7
Training loss: 0.14430605897865603
Validation loss: 2.3658643054249957

Epoch: 6| Step: 8
Training loss: 0.2377910261446896
Validation loss: 2.3911805241680386

Epoch: 6| Step: 9
Training loss: 0.2032376307222826
Validation loss: 2.3942808095791572

Epoch: 6| Step: 10
Training loss: 0.17900009942051986
Validation loss: 2.40607421066679

Epoch: 6| Step: 11
Training loss: 0.1686165206670467
Validation loss: 2.40950328822184

Epoch: 6| Step: 12
Training loss: 0.23627549365664818
Validation loss: 2.3689353779638154

Epoch: 6| Step: 13
Training loss: 0.16711133755124014
Validation loss: 2.3630983815316937

Epoch: 383| Step: 0
Training loss: 0.21780845976301885
Validation loss: 2.3321770483509985

Epoch: 6| Step: 1
Training loss: 0.10847946952960454
Validation loss: 2.318592682531679

Epoch: 6| Step: 2
Training loss: 0.16786171030889532
Validation loss: 2.3251398123018308

Epoch: 6| Step: 3
Training loss: 0.2695809608725543
Validation loss: 2.322357261757671

Epoch: 6| Step: 4
Training loss: 0.17920163020452576
Validation loss: 2.3222176450879966

Epoch: 6| Step: 5
Training loss: 0.19791162112145746
Validation loss: 2.326929257045702

Epoch: 6| Step: 6
Training loss: 0.21226318009772294
Validation loss: 2.361287983907423

Epoch: 6| Step: 7
Training loss: 0.1534166458626477
Validation loss: 2.3823223673036718

Epoch: 6| Step: 8
Training loss: 0.16395413702882652
Validation loss: 2.395248467606044

Epoch: 6| Step: 9
Training loss: 0.1696100717562751
Validation loss: 2.4003393226025436

Epoch: 6| Step: 10
Training loss: 0.33494308691033
Validation loss: 2.392127396914988

Epoch: 6| Step: 11
Training loss: 0.1592581561405085
Validation loss: 2.392084343162

Epoch: 6| Step: 12
Training loss: 0.1266506773873138
Validation loss: 2.4038865951152673

Epoch: 6| Step: 13
Training loss: 0.2031135830971883
Validation loss: 2.3633740326809285

Epoch: 384| Step: 0
Training loss: 0.2441491774014715
Validation loss: 2.372910253218704

Epoch: 6| Step: 1
Training loss: 0.21624262301039618
Validation loss: 2.303227586017512

Epoch: 6| Step: 2
Training loss: 0.29951828687273957
Validation loss: 2.3204844830111018

Epoch: 6| Step: 3
Training loss: 0.15682446258485677
Validation loss: 2.2950205557366394

Epoch: 6| Step: 4
Training loss: 0.2073652164929074
Validation loss: 2.302157457129326

Epoch: 6| Step: 5
Training loss: 0.16482835218641909
Validation loss: 2.3084177393230405

Epoch: 6| Step: 6
Training loss: 0.16849469855639476
Validation loss: 2.3619062160067466

Epoch: 6| Step: 7
Training loss: 0.1906770810913347
Validation loss: 2.359070327190251

Epoch: 6| Step: 8
Training loss: 0.09495936132336716
Validation loss: 2.3696723793475174

Epoch: 6| Step: 9
Training loss: 0.27034421304767386
Validation loss: 2.364850158800885

Epoch: 6| Step: 10
Training loss: 0.11469413717330416
Validation loss: 2.3639660305464405

Epoch: 6| Step: 11
Training loss: 0.15665837803264096
Validation loss: 2.3814001348095886

Epoch: 6| Step: 12
Training loss: 0.21410990141476985
Validation loss: 2.363695725513695

Epoch: 6| Step: 13
Training loss: 0.16082880645847736
Validation loss: 2.3636248768669974

Epoch: 385| Step: 0
Training loss: 0.19404847243345927
Validation loss: 2.3689480514691597

Epoch: 6| Step: 1
Training loss: 0.1282427212079202
Validation loss: 2.292385110264547

Epoch: 6| Step: 2
Training loss: 0.23768385277286255
Validation loss: 2.2933730226583426

Epoch: 6| Step: 3
Training loss: 0.15274588987842536
Validation loss: 2.2798255806114702

Epoch: 6| Step: 4
Training loss: 0.3224243004617307
Validation loss: 2.2563503484516407

Epoch: 6| Step: 5
Training loss: 0.1354695264338646
Validation loss: 2.2543065019677337

Epoch: 6| Step: 6
Training loss: 0.17967673974368578
Validation loss: 2.266717601908981

Epoch: 6| Step: 7
Training loss: 0.2096583114979822
Validation loss: 2.28502570025568

Epoch: 6| Step: 8
Training loss: 0.22293409779986906
Validation loss: 2.3122321951839746

Epoch: 6| Step: 9
Training loss: 0.15772998961483098
Validation loss: 2.312567721248025

Epoch: 6| Step: 10
Training loss: 0.1396656425921437
Validation loss: 2.3260185037052787

Epoch: 6| Step: 11
Training loss: 0.11726037779319959
Validation loss: 2.3168823038545727

Epoch: 6| Step: 12
Training loss: 0.27041847599190316
Validation loss: 2.3495671449851305

Epoch: 6| Step: 13
Training loss: 0.07095029106436633
Validation loss: 2.340310836468754

Epoch: 386| Step: 0
Training loss: 0.2468367290408674
Validation loss: 2.3408554984674455

Epoch: 6| Step: 1
Training loss: 0.11656592349989871
Validation loss: 2.3375771716464544

Epoch: 6| Step: 2
Training loss: 0.22575314422753928
Validation loss: 2.363262212031339

Epoch: 6| Step: 3
Training loss: 0.15062176912649444
Validation loss: 2.380061455103212

Epoch: 6| Step: 4
Training loss: 0.12735085906329477
Validation loss: 2.4072951673330474

Epoch: 6| Step: 5
Training loss: 0.10655256869723026
Validation loss: 2.3848437595560728

Epoch: 6| Step: 6
Training loss: 0.1341413884704938
Validation loss: 2.42914179047621

Epoch: 6| Step: 7
Training loss: 0.3021749680848656
Validation loss: 2.406953869841568

Epoch: 6| Step: 8
Training loss: 0.14220216905989103
Validation loss: 2.395691053562744

Epoch: 6| Step: 9
Training loss: 0.1466233039710711
Validation loss: 2.389056262685378

Epoch: 6| Step: 10
Training loss: 0.18466721871968608
Validation loss: 2.3926037957909383

Epoch: 6| Step: 11
Training loss: 0.2698379236993844
Validation loss: 2.3623416728867714

Epoch: 6| Step: 12
Training loss: 0.12637832067816931
Validation loss: 2.33873668176989

Epoch: 6| Step: 13
Training loss: 0.15409637655179226
Validation loss: 2.3251233855326854

Epoch: 387| Step: 0
Training loss: 0.19392121694500963
Validation loss: 2.3479920989705807

Epoch: 6| Step: 1
Training loss: 0.22185825096633877
Validation loss: 2.358375081541749

Epoch: 6| Step: 2
Training loss: 0.12269002774312
Validation loss: 2.370533493715298

Epoch: 6| Step: 3
Training loss: 0.16342593061843927
Validation loss: 2.3923544711262985

Epoch: 6| Step: 4
Training loss: 0.14147541741336372
Validation loss: 2.3865029404765563

Epoch: 6| Step: 5
Training loss: 0.1956414694754517
Validation loss: 2.3535274937794695

Epoch: 6| Step: 6
Training loss: 0.14233486116378075
Validation loss: 2.3719844574689444

Epoch: 6| Step: 7
Training loss: 0.35031223504688547
Validation loss: 2.3620708862156405

Epoch: 6| Step: 8
Training loss: 0.10798058433928104
Validation loss: 2.3289351313584086

Epoch: 6| Step: 9
Training loss: 0.2301411968107292
Validation loss: 2.33322342563961

Epoch: 6| Step: 10
Training loss: 0.11626865652566888
Validation loss: 2.342538213810944

Epoch: 6| Step: 11
Training loss: 0.1358394274509833
Validation loss: 2.321080306975804

Epoch: 6| Step: 12
Training loss: 0.19047627979443932
Validation loss: 2.3097594600424216

Epoch: 6| Step: 13
Training loss: 0.16253102286106016
Validation loss: 2.338275583406157

Epoch: 388| Step: 0
Training loss: 0.1278618567215515
Validation loss: 2.328121566577226

Epoch: 6| Step: 1
Training loss: 0.20854750988675635
Validation loss: 2.330063996800241

Epoch: 6| Step: 2
Training loss: 0.15609998654268342
Validation loss: 2.359829828452933

Epoch: 6| Step: 3
Training loss: 0.16597522917310933
Validation loss: 2.3389371441669824

Epoch: 6| Step: 4
Training loss: 0.13577386774554337
Validation loss: 2.329103151909356

Epoch: 6| Step: 5
Training loss: 0.3124847646814115
Validation loss: 2.3068061602433314

Epoch: 6| Step: 6
Training loss: 0.14507342791618447
Validation loss: 2.3069411038097085

Epoch: 6| Step: 7
Training loss: 0.16000625518030545
Validation loss: 2.2937681297266868

Epoch: 6| Step: 8
Training loss: 0.16177376511634065
Validation loss: 2.3596408745529773

Epoch: 6| Step: 9
Training loss: 0.14099200359963868
Validation loss: 2.327591122323586

Epoch: 6| Step: 10
Training loss: 0.21416517948464264
Validation loss: 2.346521283907685

Epoch: 6| Step: 11
Training loss: 0.23587620298910725
Validation loss: 2.336024818128715

Epoch: 6| Step: 12
Training loss: 0.13626662837497727
Validation loss: 2.3528174195454135

Epoch: 6| Step: 13
Training loss: 0.1588680751110725
Validation loss: 2.319549970283578

Epoch: 389| Step: 0
Training loss: 0.11916124837637809
Validation loss: 2.3408402360933307

Epoch: 6| Step: 1
Training loss: 0.12432642594418548
Validation loss: 2.346005225007011

Epoch: 6| Step: 2
Training loss: 0.2547898689439494
Validation loss: 2.3271313226195174

Epoch: 6| Step: 3
Training loss: 0.27117301046078235
Validation loss: 2.333485229407296

Epoch: 6| Step: 4
Training loss: 0.12010395938638146
Validation loss: 2.33029756925014

Epoch: 6| Step: 5
Training loss: 0.13324801480074105
Validation loss: 2.3570635525710872

Epoch: 6| Step: 6
Training loss: 0.24596009333656843
Validation loss: 2.3742053160167074

Epoch: 6| Step: 7
Training loss: 0.09167309288326443
Validation loss: 2.3377306536970246

Epoch: 6| Step: 8
Training loss: 0.21512107290067067
Validation loss: 2.347061698647562

Epoch: 6| Step: 9
Training loss: 0.14333290692499778
Validation loss: 2.316192448309686

Epoch: 6| Step: 10
Training loss: 0.1696926631809371
Validation loss: 2.33961196253438

Epoch: 6| Step: 11
Training loss: 0.15089529991591072
Validation loss: 2.3331230285976745

Epoch: 6| Step: 12
Training loss: 0.09892405106442682
Validation loss: 2.3373636612749173

Epoch: 6| Step: 13
Training loss: 0.21842134855313233
Validation loss: 2.3508765742734847

Epoch: 390| Step: 0
Training loss: 0.16210809959921033
Validation loss: 2.360425854563047

Epoch: 6| Step: 1
Training loss: 0.09461522687490627
Validation loss: 2.293941021592378

Epoch: 6| Step: 2
Training loss: 0.16489906693631798
Validation loss: 2.329241146810731

Epoch: 6| Step: 3
Training loss: 0.2679713346395601
Validation loss: 2.310877579230817

Epoch: 6| Step: 4
Training loss: 0.15232407002613582
Validation loss: 2.328326315474808

Epoch: 6| Step: 5
Training loss: 0.2753011138674549
Validation loss: 2.304916477247663

Epoch: 6| Step: 6
Training loss: 0.18311149078638925
Validation loss: 2.300170681484622

Epoch: 6| Step: 7
Training loss: 0.14340559035178796
Validation loss: 2.327588207981241

Epoch: 6| Step: 8
Training loss: 0.13829816240671045
Validation loss: 2.307172830309711

Epoch: 6| Step: 9
Training loss: 0.18705456195637968
Validation loss: 2.3235923876502054

Epoch: 6| Step: 10
Training loss: 0.1349734279853499
Validation loss: 2.349069148025153

Epoch: 6| Step: 11
Training loss: 0.09024000377355994
Validation loss: 2.3287114001354503

Epoch: 6| Step: 12
Training loss: 0.23251175144450972
Validation loss: 2.3242084070356266

Epoch: 6| Step: 13
Training loss: 0.10170465387803067
Validation loss: 2.397413331129239

Epoch: 391| Step: 0
Training loss: 0.16553789853453685
Validation loss: 2.394091202714559

Epoch: 6| Step: 1
Training loss: 0.19919372850249029
Validation loss: 2.3675681848135945

Epoch: 6| Step: 2
Training loss: 0.19386931329622772
Validation loss: 2.3666409059388034

Epoch: 6| Step: 3
Training loss: 0.32647086048658164
Validation loss: 2.3804448810980547

Epoch: 6| Step: 4
Training loss: 0.17523016907146688
Validation loss: 2.3146548631385895

Epoch: 6| Step: 5
Training loss: 0.22904575022546123
Validation loss: 2.310756116713533

Epoch: 6| Step: 6
Training loss: 0.1010301834968136
Validation loss: 2.3390285875637433

Epoch: 6| Step: 7
Training loss: 0.13368845031457585
Validation loss: 2.3227517556751685

Epoch: 6| Step: 8
Training loss: 0.12113975220243672
Validation loss: 2.356418655960252

Epoch: 6| Step: 9
Training loss: 0.14397022544149513
Validation loss: 2.363629297784022

Epoch: 6| Step: 10
Training loss: 0.15749585446132086
Validation loss: 2.3149058327629484

Epoch: 6| Step: 11
Training loss: 0.19146256688791677
Validation loss: 2.336152670458524

Epoch: 6| Step: 12
Training loss: 0.08780463568676322
Validation loss: 2.341455685587474

Epoch: 6| Step: 13
Training loss: 0.11382787870041403
Validation loss: 2.3300022216406733

Epoch: 392| Step: 0
Training loss: 0.25473522429531453
Validation loss: 2.3532490529577603

Epoch: 6| Step: 1
Training loss: 0.14099200359963868
Validation loss: 2.341341387589958

Epoch: 6| Step: 2
Training loss: 0.21612491085101396
Validation loss: 2.3379268430462044

Epoch: 6| Step: 3
Training loss: 0.24618331853526368
Validation loss: 2.340165092434143

Epoch: 6| Step: 4
Training loss: 0.10083082166494586
Validation loss: 2.3237669334211004

Epoch: 6| Step: 5
Training loss: 0.23067647656685142
Validation loss: 2.3376507749785596

Epoch: 6| Step: 6
Training loss: 0.10242764914245242
Validation loss: 2.3500474142625047

Epoch: 6| Step: 7
Training loss: 0.17628007682892752
Validation loss: 2.340161134952828

Epoch: 6| Step: 8
Training loss: 0.11911925139771752
Validation loss: 2.3468083412398855

Epoch: 6| Step: 9
Training loss: 0.21289617198752037
Validation loss: 2.327198869262203

Epoch: 6| Step: 10
Training loss: 0.18440798529057517
Validation loss: 2.3469972665494874

Epoch: 6| Step: 11
Training loss: 0.13273548950885966
Validation loss: 2.349516453016801

Epoch: 6| Step: 12
Training loss: 0.18067846498559495
Validation loss: 2.358024830737649

Epoch: 6| Step: 13
Training loss: 0.15461357426157213
Validation loss: 2.3689733961120996

Epoch: 393| Step: 0
Training loss: 0.08599514545071169
Validation loss: 2.3483642451859628

Epoch: 6| Step: 1
Training loss: 0.15918038958997294
Validation loss: 2.3258613173924885

Epoch: 6| Step: 2
Training loss: 0.2197161862784376
Validation loss: 2.3316034391920044

Epoch: 6| Step: 3
Training loss: 0.17562054069294675
Validation loss: 2.3323415172383157

Epoch: 6| Step: 4
Training loss: 0.19278319081964923
Validation loss: 2.311821624931293

Epoch: 6| Step: 5
Training loss: 0.2010028462327071
Validation loss: 2.3347596719836368

Epoch: 6| Step: 6
Training loss: 0.16496696251596146
Validation loss: 2.306806698130712

Epoch: 6| Step: 7
Training loss: 0.23891607518821986
Validation loss: 2.32827054416904

Epoch: 6| Step: 8
Training loss: 0.263151205755853
Validation loss: 2.329959964138006

Epoch: 6| Step: 9
Training loss: 0.13660732906170361
Validation loss: 2.3345010629098475

Epoch: 6| Step: 10
Training loss: 0.11765883153512435
Validation loss: 2.3438413212530658

Epoch: 6| Step: 11
Training loss: 0.2648999472441284
Validation loss: 2.3495737914837744

Epoch: 6| Step: 12
Training loss: 0.15741385683222991
Validation loss: 2.360838598763064

Epoch: 6| Step: 13
Training loss: 0.13602111481045234
Validation loss: 2.3348359361918214

Epoch: 394| Step: 0
Training loss: 0.09863321379778213
Validation loss: 2.3476432704520667

Epoch: 6| Step: 1
Training loss: 0.12915936098152442
Validation loss: 2.3344217759750965

Epoch: 6| Step: 2
Training loss: 0.17673887499109758
Validation loss: 2.3188955693552655

Epoch: 6| Step: 3
Training loss: 0.24001794851015462
Validation loss: 2.3076018555457978

Epoch: 6| Step: 4
Training loss: 0.23277185040384352
Validation loss: 2.324803671926086

Epoch: 6| Step: 5
Training loss: 0.11733282932406697
Validation loss: 2.3374603983426607

Epoch: 6| Step: 6
Training loss: 0.13268098209721887
Validation loss: 2.33971304782414

Epoch: 6| Step: 7
Training loss: 0.26253782749098387
Validation loss: 2.363148608036743

Epoch: 6| Step: 8
Training loss: 0.2709866083907965
Validation loss: 2.3534808979102806

Epoch: 6| Step: 9
Training loss: 0.12637412746422538
Validation loss: 2.339457840391373

Epoch: 6| Step: 10
Training loss: 0.11550602171989734
Validation loss: 2.34866844465571

Epoch: 6| Step: 11
Training loss: 0.15274318879397186
Validation loss: 2.349707198114711

Epoch: 6| Step: 12
Training loss: 0.11999425179527443
Validation loss: 2.3611063356570408

Epoch: 6| Step: 13
Training loss: 0.10240330564871841
Validation loss: 2.3930505175298995

Epoch: 395| Step: 0
Training loss: 0.20694754365830537
Validation loss: 2.400427013953008

Epoch: 6| Step: 1
Training loss: 0.27450509784304095
Validation loss: 2.395371594191824

Epoch: 6| Step: 2
Training loss: 0.11881624290930899
Validation loss: 2.377160456774714

Epoch: 6| Step: 3
Training loss: 0.16030891051001206
Validation loss: 2.352166194799203

Epoch: 6| Step: 4
Training loss: 0.11699079057372153
Validation loss: 2.340590617784689

Epoch: 6| Step: 5
Training loss: 0.20410942902075513
Validation loss: 2.3360863037103075

Epoch: 6| Step: 6
Training loss: 0.1280472702825565
Validation loss: 2.3295096187528683

Epoch: 6| Step: 7
Training loss: 0.2559134302477051
Validation loss: 2.310285603307831

Epoch: 6| Step: 8
Training loss: 0.10639631386017145
Validation loss: 2.3262881377219764

Epoch: 6| Step: 9
Training loss: 0.11589360386791354
Validation loss: 2.3092427804185203

Epoch: 6| Step: 10
Training loss: 0.10504654867237022
Validation loss: 2.332269734539362

Epoch: 6| Step: 11
Training loss: 0.2596444442439657
Validation loss: 2.321751189641771

Epoch: 6| Step: 12
Training loss: 0.17003608022712766
Validation loss: 2.3498246092790303

Epoch: 6| Step: 13
Training loss: 0.12981344823119037
Validation loss: 2.33784236044799

Epoch: 396| Step: 0
Training loss: 0.12869230491520095
Validation loss: 2.377367462598212

Epoch: 6| Step: 1
Training loss: 0.21288711649952174
Validation loss: 2.3801072381635335

Epoch: 6| Step: 2
Training loss: 0.16653211695838588
Validation loss: 2.3817599915456014

Epoch: 6| Step: 3
Training loss: 0.1707287463638209
Validation loss: 2.3837902670012

Epoch: 6| Step: 4
Training loss: 0.2143291118293476
Validation loss: 2.3482522119827682

Epoch: 6| Step: 5
Training loss: 0.22588971974258165
Validation loss: 2.320961539468939

Epoch: 6| Step: 6
Training loss: 0.1290247473677675
Validation loss: 2.3155856090366735

Epoch: 6| Step: 7
Training loss: 0.1622658743968915
Validation loss: 2.3124956919711184

Epoch: 6| Step: 8
Training loss: 0.10658333954961449
Validation loss: 2.3115491322843007

Epoch: 6| Step: 9
Training loss: 0.16850276270994213
Validation loss: 2.300458380707414

Epoch: 6| Step: 10
Training loss: 0.14809030157615508
Validation loss: 2.305484904778987

Epoch: 6| Step: 11
Training loss: 0.1016741927073123
Validation loss: 2.300486262933204

Epoch: 6| Step: 12
Training loss: 0.23846031714740726
Validation loss: 2.3127706569422926

Epoch: 6| Step: 13
Training loss: 0.3208304149115132
Validation loss: 2.326155939889052

Epoch: 397| Step: 0
Training loss: 0.2087754069359858
Validation loss: 2.3477092414321543

Epoch: 6| Step: 1
Training loss: 0.16954210747612833
Validation loss: 2.378452912707763

Epoch: 6| Step: 2
Training loss: 0.2543470517769215
Validation loss: 2.375401877925898

Epoch: 6| Step: 3
Training loss: 0.10353784952364908
Validation loss: 2.3969332452503274

Epoch: 6| Step: 4
Training loss: 0.14630992674408122
Validation loss: 2.4311519382962206

Epoch: 6| Step: 5
Training loss: 0.24151051408525653
Validation loss: 2.394288640923279

Epoch: 6| Step: 6
Training loss: 0.18301824908385178
Validation loss: 2.3899350796435725

Epoch: 6| Step: 7
Training loss: 0.1794767283858689
Validation loss: 2.3666957085939253

Epoch: 6| Step: 8
Training loss: 0.12838615632634015
Validation loss: 2.346001068111914

Epoch: 6| Step: 9
Training loss: 0.13647740724592486
Validation loss: 2.319827783251332

Epoch: 6| Step: 10
Training loss: 0.0822378321873519
Validation loss: 2.3379159417244315

Epoch: 6| Step: 11
Training loss: 0.23559227975522437
Validation loss: 2.2803582226670263

Epoch: 6| Step: 12
Training loss: 0.17397974131442862
Validation loss: 2.2920404724101675

Epoch: 6| Step: 13
Training loss: 0.12794514919349081
Validation loss: 2.3098028540486544

Epoch: 398| Step: 0
Training loss: 0.23530987413873947
Validation loss: 2.3129213254733005

Epoch: 6| Step: 1
Training loss: 0.21313765830822218
Validation loss: 2.2902735261380927

Epoch: 6| Step: 2
Training loss: 0.31524558348742204
Validation loss: 2.314389609462267

Epoch: 6| Step: 3
Training loss: 0.10001225433665102
Validation loss: 2.3084258142040035

Epoch: 6| Step: 4
Training loss: 0.10995611718895669
Validation loss: 2.321593174422646

Epoch: 6| Step: 5
Training loss: 0.10893674308636458
Validation loss: 2.345660376558195

Epoch: 6| Step: 6
Training loss: 0.1279546844288638
Validation loss: 2.3394475779507355

Epoch: 6| Step: 7
Training loss: 0.10355057666120436
Validation loss: 2.3126338874528987

Epoch: 6| Step: 8
Training loss: 0.1622733011207046
Validation loss: 2.339779067639556

Epoch: 6| Step: 9
Training loss: 0.1178328269464989
Validation loss: 2.345310541004719

Epoch: 6| Step: 10
Training loss: 0.14668409719327688
Validation loss: 2.3395044903696283

Epoch: 6| Step: 11
Training loss: 0.17866791796253506
Validation loss: 2.320086367659318

Epoch: 6| Step: 12
Training loss: 0.09037757962385046
Validation loss: 2.340387983958735

Epoch: 6| Step: 13
Training loss: 0.075685085774143
Validation loss: 2.340985996683621

Epoch: 399| Step: 0
Training loss: 0.10129703619069025
Validation loss: 2.3582903226679006

Epoch: 6| Step: 1
Training loss: 0.30616959762018275
Validation loss: 2.379265593919878

Epoch: 6| Step: 2
Training loss: 0.10538037447499222
Validation loss: 2.3662719038851625

Epoch: 6| Step: 3
Training loss: 0.23425273885316614
Validation loss: 2.3655151071603275

Epoch: 6| Step: 4
Training loss: 0.0881994966042787
Validation loss: 2.3805104053203556

Epoch: 6| Step: 5
Training loss: 0.18880917546774678
Validation loss: 2.3628285951415546

Epoch: 6| Step: 6
Training loss: 0.12791519956596514
Validation loss: 2.4077704230953567

Epoch: 6| Step: 7
Training loss: 0.09941915506535917
Validation loss: 2.3544525265501193

Epoch: 6| Step: 8
Training loss: 0.21345598064020602
Validation loss: 2.3343191005599158

Epoch: 6| Step: 9
Training loss: 0.10130340281937153
Validation loss: 2.3374681617683493

Epoch: 6| Step: 10
Training loss: 0.08990821909513301
Validation loss: 2.358658666972449

Epoch: 6| Step: 11
Training loss: 0.08057515645915934
Validation loss: 2.3522203941226443

Epoch: 6| Step: 12
Training loss: 0.15825512702487424
Validation loss: 2.352852275737726

Epoch: 6| Step: 13
Training loss: 0.1248189837367176
Validation loss: 2.345996927601037

Epoch: 400| Step: 0
Training loss: 0.26636796715383554
Validation loss: 2.3650219111088906

Epoch: 6| Step: 1
Training loss: 0.09694066129703259
Validation loss: 2.3423822493353983

Epoch: 6| Step: 2
Training loss: 0.11897233114321192
Validation loss: 2.397573478110231

Epoch: 6| Step: 3
Training loss: 0.18059475574586306
Validation loss: 2.418100671696245

Epoch: 6| Step: 4
Training loss: 0.1304427674970482
Validation loss: 2.4293560963631067

Epoch: 6| Step: 5
Training loss: 0.12089859711323742
Validation loss: 2.4295504719675267

Epoch: 6| Step: 6
Training loss: 0.2116802877420101
Validation loss: 2.408957619123725

Epoch: 6| Step: 7
Training loss: 0.15984345920830878
Validation loss: 2.4119357399256667

Epoch: 6| Step: 8
Training loss: 0.09690793385129885
Validation loss: 2.407012283874548

Epoch: 6| Step: 9
Training loss: 0.22598581253941796
Validation loss: 2.4123995034489516

Epoch: 6| Step: 10
Training loss: 0.2386214298188036
Validation loss: 2.373726272775894

Epoch: 6| Step: 11
Training loss: 0.10116281634541359
Validation loss: 2.3687642351731943

Epoch: 6| Step: 12
Training loss: 0.08831831662395857
Validation loss: 2.4000438716512122

Epoch: 6| Step: 13
Training loss: 0.053985968761546
Validation loss: 2.3682165382152274

Epoch: 401| Step: 0
Training loss: 0.19080290778446515
Validation loss: 2.3627462138227093

Epoch: 6| Step: 1
Training loss: 0.24758497169106194
Validation loss: 2.37144451483347

Epoch: 6| Step: 2
Training loss: 0.1314255649986081
Validation loss: 2.3489706729730058

Epoch: 6| Step: 3
Training loss: 0.12541696176805767
Validation loss: 2.309254322775738

Epoch: 6| Step: 4
Training loss: 0.219282447427321
Validation loss: 2.3266795350328393

Epoch: 6| Step: 5
Training loss: 0.12776605318260592
Validation loss: 2.340890009289775

Epoch: 6| Step: 6
Training loss: 0.10692398690046326
Validation loss: 2.3469645096840237

Epoch: 6| Step: 7
Training loss: 0.11490863893685073
Validation loss: 2.3351222134254948

Epoch: 6| Step: 8
Training loss: 0.1082133999225497
Validation loss: 2.3575462186650356

Epoch: 6| Step: 9
Training loss: 0.17891094085007594
Validation loss: 2.353016360945314

Epoch: 6| Step: 10
Training loss: 0.08751821030426722
Validation loss: 2.3569745535202014

Epoch: 6| Step: 11
Training loss: 0.21120968671018797
Validation loss: 2.355503113111535

Epoch: 6| Step: 12
Training loss: 0.10707665371409375
Validation loss: 2.386403227773629

Epoch: 6| Step: 13
Training loss: 0.10653335097807348
Validation loss: 2.3682190897123667

Epoch: 402| Step: 0
Training loss: 0.13165894389390134
Validation loss: 2.3756879728676386

Epoch: 6| Step: 1
Training loss: 0.1380010889133912
Validation loss: 2.3710625472726066

Epoch: 6| Step: 2
Training loss: 0.13791846731783333
Validation loss: 2.4132312427082856

Epoch: 6| Step: 3
Training loss: 0.09557288416291117
Validation loss: 2.4039466657299835

Epoch: 6| Step: 4
Training loss: 0.09656252167371242
Validation loss: 2.398139948249821

Epoch: 6| Step: 5
Training loss: 0.2703403546749892
Validation loss: 2.4008089375890105

Epoch: 6| Step: 6
Training loss: 0.07098258124714812
Validation loss: 2.389277004755207

Epoch: 6| Step: 7
Training loss: 0.15741669667627195
Validation loss: 2.3192469099884288

Epoch: 6| Step: 8
Training loss: 0.1668661601246915
Validation loss: 2.34065284335119

Epoch: 6| Step: 9
Training loss: 0.20049853737635343
Validation loss: 2.2933431284344854

Epoch: 6| Step: 10
Training loss: 0.22431359926625613
Validation loss: 2.313309813442507

Epoch: 6| Step: 11
Training loss: 0.13012575073831803
Validation loss: 2.3017675229280967

Epoch: 6| Step: 12
Training loss: 0.14422107611998627
Validation loss: 2.264120248475771

Epoch: 6| Step: 13
Training loss: 0.08620288630226558
Validation loss: 2.3166412437403228

Epoch: 403| Step: 0
Training loss: 0.10343963604994784
Validation loss: 2.311772366993166

Epoch: 6| Step: 1
Training loss: 0.07511906659676648
Validation loss: 2.3550489207936236

Epoch: 6| Step: 2
Training loss: 0.13958103714188247
Validation loss: 2.3413189348087

Epoch: 6| Step: 3
Training loss: 0.11381298266868325
Validation loss: 2.3785499893176505

Epoch: 6| Step: 4
Training loss: 0.23856116878686773
Validation loss: 2.3807397728731416

Epoch: 6| Step: 5
Training loss: 0.26920549084407985
Validation loss: 2.3837557215038805

Epoch: 6| Step: 6
Training loss: 0.12315264197917913
Validation loss: 2.4041692534737575

Epoch: 6| Step: 7
Training loss: 0.06940950600905968
Validation loss: 2.415333426421369

Epoch: 6| Step: 8
Training loss: 0.11879208659694704
Validation loss: 2.3777806077829844

Epoch: 6| Step: 9
Training loss: 0.13897459809522575
Validation loss: 2.357246937600493

Epoch: 6| Step: 10
Training loss: 0.10244716886271056
Validation loss: 2.357479980322503

Epoch: 6| Step: 11
Training loss: 0.2431684746399414
Validation loss: 2.3365530120259748

Epoch: 6| Step: 12
Training loss: 0.21966933458849414
Validation loss: 2.372349273965706

Epoch: 6| Step: 13
Training loss: 0.09416884992433035
Validation loss: 2.3614961246194497

Epoch: 404| Step: 0
Training loss: 0.13251471795355382
Validation loss: 2.3629683472259737

Epoch: 6| Step: 1
Training loss: 0.10260510361513134
Validation loss: 2.3843692524276943

Epoch: 6| Step: 2
Training loss: 0.1117707788251594
Validation loss: 2.3937306015662463

Epoch: 6| Step: 3
Training loss: 0.2981048632564817
Validation loss: 2.402117761493411

Epoch: 6| Step: 4
Training loss: 0.14586844972312904
Validation loss: 2.3960422223281155

Epoch: 6| Step: 5
Training loss: 0.2907127750294881
Validation loss: 2.3460135229300207

Epoch: 6| Step: 6
Training loss: 0.10239235055267847
Validation loss: 2.3306644737095543

Epoch: 6| Step: 7
Training loss: 0.11710988494426104
Validation loss: 2.3449856679014744

Epoch: 6| Step: 8
Training loss: 0.1033633344458467
Validation loss: 2.3196803980732694

Epoch: 6| Step: 9
Training loss: 0.14955056879856243
Validation loss: 2.308792525738253

Epoch: 6| Step: 10
Training loss: 0.1123639447984841
Validation loss: 2.3135979741657446

Epoch: 6| Step: 11
Training loss: 0.10253107403109633
Validation loss: 2.314929107075405

Epoch: 6| Step: 12
Training loss: 0.160463683532177
Validation loss: 2.326167161374913

Epoch: 6| Step: 13
Training loss: 0.09970740562017476
Validation loss: 2.3551709901094107

Epoch: 405| Step: 0
Training loss: 0.11743781059695065
Validation loss: 2.317568140512797

Epoch: 6| Step: 1
Training loss: 0.25545316584472033
Validation loss: 2.3326600073053965

Epoch: 6| Step: 2
Training loss: 0.14009962355209504
Validation loss: 2.383527833752733

Epoch: 6| Step: 3
Training loss: 0.22278403914962805
Validation loss: 2.3731387962323938

Epoch: 6| Step: 4
Training loss: 0.12109427298156031
Validation loss: 2.369522254303343

Epoch: 6| Step: 5
Training loss: 0.12720505586223996
Validation loss: 2.3592328291779054

Epoch: 6| Step: 6
Training loss: 0.11604008818083016
Validation loss: 2.3692631274189835

Epoch: 6| Step: 7
Training loss: 0.16630935489572204
Validation loss: 2.3453881405217003

Epoch: 6| Step: 8
Training loss: 0.10231408460936102
Validation loss: 2.3497506890217332

Epoch: 6| Step: 9
Training loss: 0.13408337541699664
Validation loss: 2.3363063009559846

Epoch: 6| Step: 10
Training loss: 0.21700654759175556
Validation loss: 2.364151048919655

Epoch: 6| Step: 11
Training loss: 0.23256669221096693
Validation loss: 2.324045707484019

Epoch: 6| Step: 12
Training loss: 0.17082410013050323
Validation loss: 2.339327744597857

Epoch: 6| Step: 13
Training loss: 0.1356658377779755
Validation loss: 2.3296693595078226

Epoch: 406| Step: 0
Training loss: 0.11452455033304795
Validation loss: 2.3111626106603183

Epoch: 6| Step: 1
Training loss: 0.23039271830076394
Validation loss: 2.35657466674158

Epoch: 6| Step: 2
Training loss: 0.19072742172983334
Validation loss: 2.319087618683788

Epoch: 6| Step: 3
Training loss: 0.15791351394999661
Validation loss: 2.3519662718840064

Epoch: 6| Step: 4
Training loss: 0.11113747786398447
Validation loss: 2.3403303317091497

Epoch: 6| Step: 5
Training loss: 0.24506396593532478
Validation loss: 2.318318195766737

Epoch: 6| Step: 6
Training loss: 0.14022255637858222
Validation loss: 2.291440905267346

Epoch: 6| Step: 7
Training loss: 0.1887294278712735
Validation loss: 2.261361735244706

Epoch: 6| Step: 8
Training loss: 0.13237806400034624
Validation loss: 2.2706775602447262

Epoch: 6| Step: 9
Training loss: 0.09014969026710166
Validation loss: 2.2778497804679274

Epoch: 6| Step: 10
Training loss: 0.2132273557011775
Validation loss: 2.3070229898180585

Epoch: 6| Step: 11
Training loss: 0.15530446180462226
Validation loss: 2.339865595437414

Epoch: 6| Step: 12
Training loss: 0.11931328691210055
Validation loss: 2.3191768479676913

Epoch: 6| Step: 13
Training loss: 0.08790311724575851
Validation loss: 2.365330858253412

Epoch: 407| Step: 0
Training loss: 0.07941261404642652
Validation loss: 2.3555578451241583

Epoch: 6| Step: 1
Training loss: 0.1272139950109374
Validation loss: 2.354884515625304

Epoch: 6| Step: 2
Training loss: 0.10044402694858608
Validation loss: 2.367893014900337

Epoch: 6| Step: 3
Training loss: 0.2731626355278354
Validation loss: 2.3919249390402655

Epoch: 6| Step: 4
Training loss: 0.14273904185190195
Validation loss: 2.3810430036971595

Epoch: 6| Step: 5
Training loss: 0.14353148603762522
Validation loss: 2.3705849728851986

Epoch: 6| Step: 6
Training loss: 0.24689312186305493
Validation loss: 2.3284174059732776

Epoch: 6| Step: 7
Training loss: 0.1557024541056602
Validation loss: 2.3242381789196025

Epoch: 6| Step: 8
Training loss: 0.17350793130126743
Validation loss: 2.3140601405382037

Epoch: 6| Step: 9
Training loss: 0.12576786763811015
Validation loss: 2.3358303309839736

Epoch: 6| Step: 10
Training loss: 0.09914224615041653
Validation loss: 2.350878269461558

Epoch: 6| Step: 11
Training loss: 0.27867196605222094
Validation loss: 2.3474571710503347

Epoch: 6| Step: 12
Training loss: 0.09639646003606128
Validation loss: 2.40123576323164

Epoch: 6| Step: 13
Training loss: 0.06565595050245968
Validation loss: 2.410106427269111

Epoch: 408| Step: 0
Training loss: 0.17259799548447405
Validation loss: 2.4336507508738054

Epoch: 6| Step: 1
Training loss: 0.16513307139893477
Validation loss: 2.3687693678294384

Epoch: 6| Step: 2
Training loss: 0.2119120584560158
Validation loss: 2.3815158327739514

Epoch: 6| Step: 3
Training loss: 0.18428770762917449
Validation loss: 2.3551537359836017

Epoch: 6| Step: 4
Training loss: 0.12574176938762754
Validation loss: 2.331728965617602

Epoch: 6| Step: 5
Training loss: 0.12127581107808671
Validation loss: 2.2931712188833044

Epoch: 6| Step: 6
Training loss: 0.1697220339681258
Validation loss: 2.249974429533304

Epoch: 6| Step: 7
Training loss: 0.15235420337905903
Validation loss: 2.277599280910395

Epoch: 6| Step: 8
Training loss: 0.14302600120780107
Validation loss: 2.2883554904112624

Epoch: 6| Step: 9
Training loss: 0.20069442497038462
Validation loss: 2.313845389705744

Epoch: 6| Step: 10
Training loss: 0.2552129719111531
Validation loss: 2.282531489598566

Epoch: 6| Step: 11
Training loss: 0.20316239159558327
Validation loss: 2.340574593405604

Epoch: 6| Step: 12
Training loss: 0.15420019766730567
Validation loss: 2.362157693052147

Epoch: 6| Step: 13
Training loss: 0.21314817126436136
Validation loss: 2.424647210895636

Epoch: 409| Step: 0
Training loss: 0.24947685401232172
Validation loss: 2.4228441927607807

Epoch: 6| Step: 1
Training loss: 0.3343188523897651
Validation loss: 2.434198693869684

Epoch: 6| Step: 2
Training loss: 0.11518039085423377
Validation loss: 2.4076033846605305

Epoch: 6| Step: 3
Training loss: 0.0972542882540176
Validation loss: 2.3539125316405323

Epoch: 6| Step: 4
Training loss: 0.14685470816263968
Validation loss: 2.370761547828919

Epoch: 6| Step: 5
Training loss: 0.16490573124589808
Validation loss: 2.351403650166415

Epoch: 6| Step: 6
Training loss: 0.1714171032177539
Validation loss: 2.3430454805925476

Epoch: 6| Step: 7
Training loss: 0.13854312292447454
Validation loss: 2.34104132379948

Epoch: 6| Step: 8
Training loss: 0.19783763290430215
Validation loss: 2.3403272897305984

Epoch: 6| Step: 9
Training loss: 0.158979699818247
Validation loss: 2.3273628222212817

Epoch: 6| Step: 10
Training loss: 0.16951034302718582
Validation loss: 2.326398632396688

Epoch: 6| Step: 11
Training loss: 0.10251571752831554
Validation loss: 2.3312632080150877

Epoch: 6| Step: 12
Training loss: 0.11844980354618867
Validation loss: 2.343217513873411

Epoch: 6| Step: 13
Training loss: 0.06431352423551118
Validation loss: 2.3922252903324672

Epoch: 410| Step: 0
Training loss: 0.12147861893316733
Validation loss: 2.3654021012473985

Epoch: 6| Step: 1
Training loss: 0.1277422733373087
Validation loss: 2.393367350707292

Epoch: 6| Step: 2
Training loss: 0.12336119363566404
Validation loss: 2.392745300573403

Epoch: 6| Step: 3
Training loss: 0.24501131818620722
Validation loss: 2.4089865729546496

Epoch: 6| Step: 4
Training loss: 0.16493634972238078
Validation loss: 2.386977007338984

Epoch: 6| Step: 5
Training loss: 0.15637142708353508
Validation loss: 2.3470346340612545

Epoch: 6| Step: 6
Training loss: 0.08827434856732293
Validation loss: 2.3784068639023017

Epoch: 6| Step: 7
Training loss: 0.1464115152358785
Validation loss: 2.339746912604175

Epoch: 6| Step: 8
Training loss: 0.24612740634683444
Validation loss: 2.3233490400845205

Epoch: 6| Step: 9
Training loss: 0.1369145489954774
Validation loss: 2.3194072514414814

Epoch: 6| Step: 10
Training loss: 0.09867109839797499
Validation loss: 2.3094726086730613

Epoch: 6| Step: 11
Training loss: 0.1518489124808528
Validation loss: 2.3100871965845546

Epoch: 6| Step: 12
Training loss: 0.21096020152532882
Validation loss: 2.317429308372152

Epoch: 6| Step: 13
Training loss: 0.19145941482531825
Validation loss: 2.342403114003162

Epoch: 411| Step: 0
Training loss: 0.07506836045683166
Validation loss: 2.3834573067948535

Epoch: 6| Step: 1
Training loss: 0.1272323325760462
Validation loss: 2.4241103596095686

Epoch: 6| Step: 2
Training loss: 0.14665078565406267
Validation loss: 2.4709267957919994

Epoch: 6| Step: 3
Training loss: 0.15161208983397373
Validation loss: 2.4506342130001078

Epoch: 6| Step: 4
Training loss: 0.18397429776789243
Validation loss: 2.4611872241460846

Epoch: 6| Step: 5
Training loss: 0.11348152543736381
Validation loss: 2.417647649214595

Epoch: 6| Step: 6
Training loss: 0.11112173507939302
Validation loss: 2.4012920140662284

Epoch: 6| Step: 7
Training loss: 0.1812572535345945
Validation loss: 2.34326132872188

Epoch: 6| Step: 8
Training loss: 0.23378934804441626
Validation loss: 2.3169588063108826

Epoch: 6| Step: 9
Training loss: 0.33339929921374617
Validation loss: 2.3366649566514703

Epoch: 6| Step: 10
Training loss: 0.11644381742595755
Validation loss: 2.387194750543923

Epoch: 6| Step: 11
Training loss: 0.24702837742698228
Validation loss: 2.3887265371125492

Epoch: 6| Step: 12
Training loss: 0.23567753294731514
Validation loss: 2.384742685307285

Epoch: 6| Step: 13
Training loss: 0.20728902243999586
Validation loss: 2.423944996100667

Epoch: 412| Step: 0
Training loss: 0.21353970018892518
Validation loss: 2.3955466449803757

Epoch: 6| Step: 1
Training loss: 0.11622017334853443
Validation loss: 2.350864614138912

Epoch: 6| Step: 2
Training loss: 0.12497100270223396
Validation loss: 2.3931632682221107

Epoch: 6| Step: 3
Training loss: 0.1589755112053999
Validation loss: 2.3731238754381154

Epoch: 6| Step: 4
Training loss: 0.08591895282612783
Validation loss: 2.355086198651408

Epoch: 6| Step: 5
Training loss: 0.3103234188890202
Validation loss: 2.379225103565299

Epoch: 6| Step: 6
Training loss: 0.10843588208082647
Validation loss: 2.354980683749236

Epoch: 6| Step: 7
Training loss: 0.11959564369363031
Validation loss: 2.3252639556059576

Epoch: 6| Step: 8
Training loss: 0.22552094617375348
Validation loss: 2.322444499355477

Epoch: 6| Step: 9
Training loss: 0.11560668445843125
Validation loss: 2.2914292032559027

Epoch: 6| Step: 10
Training loss: 0.1475159371987607
Validation loss: 2.3201748552428096

Epoch: 6| Step: 11
Training loss: 0.16980797139869597
Validation loss: 2.3109415085695018

Epoch: 6| Step: 12
Training loss: 0.12725150183941822
Validation loss: 2.336724092662804

Epoch: 6| Step: 13
Training loss: 0.09060962398578386
Validation loss: 2.3396415419696375

Epoch: 413| Step: 0
Training loss: 0.23306748936192956
Validation loss: 2.332016798889025

Epoch: 6| Step: 1
Training loss: 0.15752975775956507
Validation loss: 2.3597479214975596

Epoch: 6| Step: 2
Training loss: 0.11127829691432177
Validation loss: 2.365186139484696

Epoch: 6| Step: 3
Training loss: 0.11469347538700293
Validation loss: 2.3755661721883174

Epoch: 6| Step: 4
Training loss: 0.21665286530651884
Validation loss: 2.3688684943669145

Epoch: 6| Step: 5
Training loss: 0.21598061696974888
Validation loss: 2.3531331499690142

Epoch: 6| Step: 6
Training loss: 0.10316193634407536
Validation loss: 2.3091601371429316

Epoch: 6| Step: 7
Training loss: 0.09783181621324542
Validation loss: 2.3473618174155826

Epoch: 6| Step: 8
Training loss: 0.13563638447079662
Validation loss: 2.3147200570713897

Epoch: 6| Step: 9
Training loss: 0.16957574427476632
Validation loss: 2.3210639635843573

Epoch: 6| Step: 10
Training loss: 0.18641721486971788
Validation loss: 2.3021055380198074

Epoch: 6| Step: 11
Training loss: 0.12081825543196283
Validation loss: 2.2856815261350025

Epoch: 6| Step: 12
Training loss: 0.17752576469753067
Validation loss: 2.314504018916032

Epoch: 6| Step: 13
Training loss: 0.1135143151571967
Validation loss: 2.3616861824951476

Epoch: 414| Step: 0
Training loss: 0.19829521033860015
Validation loss: 2.321222020903458

Epoch: 6| Step: 1
Training loss: 0.12296623281934421
Validation loss: 2.3498619754693846

Epoch: 6| Step: 2
Training loss: 0.14346720826241452
Validation loss: 2.3518864657159906

Epoch: 6| Step: 3
Training loss: 0.18578485987487178
Validation loss: 2.378400351872616

Epoch: 6| Step: 4
Training loss: 0.11680730498831154
Validation loss: 2.362870832261301

Epoch: 6| Step: 5
Training loss: 0.21894402073964875
Validation loss: 2.3493399186765505

Epoch: 6| Step: 6
Training loss: 0.061657313358961095
Validation loss: 2.351072196579213

Epoch: 6| Step: 7
Training loss: 0.14262360670427202
Validation loss: 2.3522268429404867

Epoch: 6| Step: 8
Training loss: 0.2561701568797188
Validation loss: 2.34725859400404

Epoch: 6| Step: 9
Training loss: 0.08923527706480486
Validation loss: 2.372816862404283

Epoch: 6| Step: 10
Training loss: 0.16484953363948188
Validation loss: 2.3518148329171944

Epoch: 6| Step: 11
Training loss: 0.16961406363916962
Validation loss: 2.340483757537395

Epoch: 6| Step: 12
Training loss: 0.10040265578976268
Validation loss: 2.3678611842640693

Epoch: 6| Step: 13
Training loss: 0.33224981631395184
Validation loss: 2.33222922851367

Epoch: 415| Step: 0
Training loss: 0.11354516380141895
Validation loss: 2.376126425410907

Epoch: 6| Step: 1
Training loss: 0.1116156045226451
Validation loss: 2.3332746116732013

Epoch: 6| Step: 2
Training loss: 0.181323030162732
Validation loss: 2.343737753559235

Epoch: 6| Step: 3
Training loss: 0.12364082943202694
Validation loss: 2.379948069167121

Epoch: 6| Step: 4
Training loss: 0.13253166857174126
Validation loss: 2.364878575649957

Epoch: 6| Step: 5
Training loss: 0.12325238670790914
Validation loss: 2.3773545530637468

Epoch: 6| Step: 6
Training loss: 0.12693314028211514
Validation loss: 2.4471642386179706

Epoch: 6| Step: 7
Training loss: 0.18001238849843848
Validation loss: 2.407400978094869

Epoch: 6| Step: 8
Training loss: 0.12110953843341106
Validation loss: 2.406587314708169

Epoch: 6| Step: 9
Training loss: 0.10933526202801037
Validation loss: 2.3925676146613974

Epoch: 6| Step: 10
Training loss: 0.25830089662834144
Validation loss: 2.383492151595602

Epoch: 6| Step: 11
Training loss: 0.16071978722344626
Validation loss: 2.3353975726773175

Epoch: 6| Step: 12
Training loss: 0.16022525440559837
Validation loss: 2.3675129107444755

Epoch: 6| Step: 13
Training loss: 0.36073274791121074
Validation loss: 2.343797581781023

Epoch: 416| Step: 0
Training loss: 0.20586485954955483
Validation loss: 2.317328675659569

Epoch: 6| Step: 1
Training loss: 0.20703969794257515
Validation loss: 2.306606720961599

Epoch: 6| Step: 2
Training loss: 0.21215943225289452
Validation loss: 2.2895530984956594

Epoch: 6| Step: 3
Training loss: 0.17890896274558932
Validation loss: 2.277499843084251

Epoch: 6| Step: 4
Training loss: 0.10947771018184897
Validation loss: 2.271133561809455

Epoch: 6| Step: 5
Training loss: 0.1283840816446446
Validation loss: 2.2685164770271973

Epoch: 6| Step: 6
Training loss: 0.13100704003483424
Validation loss: 2.291220653644452

Epoch: 6| Step: 7
Training loss: 0.16045153541308763
Validation loss: 2.2977278226048634

Epoch: 6| Step: 8
Training loss: 0.08865415274183576
Validation loss: 2.3516346253304996

Epoch: 6| Step: 9
Training loss: 0.1311399171329021
Validation loss: 2.370055149652196

Epoch: 6| Step: 10
Training loss: 0.16215609256481645
Validation loss: 2.382455665609653

Epoch: 6| Step: 11
Training loss: 0.12081415446214747
Validation loss: 2.4137914574262527

Epoch: 6| Step: 12
Training loss: 0.2770385943889926
Validation loss: 2.4007574369683526

Epoch: 6| Step: 13
Training loss: 0.1768176678218857
Validation loss: 2.3695173780713468

Epoch: 417| Step: 0
Training loss: 0.14586652792343793
Validation loss: 2.367516909673828

Epoch: 6| Step: 1
Training loss: 0.0916443531647151
Validation loss: 2.363884053802677

Epoch: 6| Step: 2
Training loss: 0.0935749217233705
Validation loss: 2.3947964693547714

Epoch: 6| Step: 3
Training loss: 0.20970332287812524
Validation loss: 2.364652352850174

Epoch: 6| Step: 4
Training loss: 0.07793560913839066
Validation loss: 2.3497943651404034

Epoch: 6| Step: 5
Training loss: 0.08416870592095194
Validation loss: 2.329600496812596

Epoch: 6| Step: 6
Training loss: 0.1245119618432159
Validation loss: 2.349178588645682

Epoch: 6| Step: 7
Training loss: 0.18981079867382103
Validation loss: 2.3365915427971853

Epoch: 6| Step: 8
Training loss: 0.22298810722462564
Validation loss: 2.3673079633390395

Epoch: 6| Step: 9
Training loss: 0.18905954673919573
Validation loss: 2.342247431127181

Epoch: 6| Step: 10
Training loss: 0.11246036437306939
Validation loss: 2.3562211290243806

Epoch: 6| Step: 11
Training loss: 0.23013247995844338
Validation loss: 2.3790137070366537

Epoch: 6| Step: 12
Training loss: 0.13526193477888668
Validation loss: 2.351265882550389

Epoch: 6| Step: 13
Training loss: 0.1544832178784172
Validation loss: 2.3861986716136414

Epoch: 418| Step: 0
Training loss: 0.09258103245382747
Validation loss: 2.3714696355071228

Epoch: 6| Step: 1
Training loss: 0.10854803536463295
Validation loss: 2.3358558670427487

Epoch: 6| Step: 2
Training loss: 0.10971235717021151
Validation loss: 2.292096323323444

Epoch: 6| Step: 3
Training loss: 0.12292509637701435
Validation loss: 2.2876655044901395

Epoch: 6| Step: 4
Training loss: 0.1841508246062328
Validation loss: 2.2724479478450115

Epoch: 6| Step: 5
Training loss: 0.1902011086361672
Validation loss: 2.269414887913366

Epoch: 6| Step: 6
Training loss: 0.1071439442125305
Validation loss: 2.2465851248494686

Epoch: 6| Step: 7
Training loss: 0.29241238217101745
Validation loss: 2.2572762514294027

Epoch: 6| Step: 8
Training loss: 0.11156950264813033
Validation loss: 2.269686908991942

Epoch: 6| Step: 9
Training loss: 0.16864627767586404
Validation loss: 2.2684187069540953

Epoch: 6| Step: 10
Training loss: 0.1182715817409263
Validation loss: 2.2916749307104953

Epoch: 6| Step: 11
Training loss: 0.2423136905348692
Validation loss: 2.3409889315805428

Epoch: 6| Step: 12
Training loss: 0.11622842689147567
Validation loss: 2.2928450753127767

Epoch: 6| Step: 13
Training loss: 0.07945730723473812
Validation loss: 2.39470931049571

Epoch: 419| Step: 0
Training loss: 0.1354138086702066
Validation loss: 2.330907892324928

Epoch: 6| Step: 1
Training loss: 0.13250757724310827
Validation loss: 2.3613645361687134

Epoch: 6| Step: 2
Training loss: 0.13933760723015093
Validation loss: 2.3540877930582034

Epoch: 6| Step: 3
Training loss: 0.11281804223064984
Validation loss: 2.339863338974289

Epoch: 6| Step: 4
Training loss: 0.0861177126306004
Validation loss: 2.3432750130357234

Epoch: 6| Step: 5
Training loss: 0.1067743116680592
Validation loss: 2.3368635068998276

Epoch: 6| Step: 6
Training loss: 0.2769229544278632
Validation loss: 2.327544826143184

Epoch: 6| Step: 7
Training loss: 0.12970830911271974
Validation loss: 2.3712242858053973

Epoch: 6| Step: 8
Training loss: 0.08244031851185793
Validation loss: 2.3520936326264534

Epoch: 6| Step: 9
Training loss: 0.13375121646399216
Validation loss: 2.3441740936190456

Epoch: 6| Step: 10
Training loss: 0.20689796259809395
Validation loss: 2.3825441346189318

Epoch: 6| Step: 11
Training loss: 0.12502915817166046
Validation loss: 2.314009508289757

Epoch: 6| Step: 12
Training loss: 0.15035279528934314
Validation loss: 2.3441975899724796

Epoch: 6| Step: 13
Training loss: 0.13527107818334994
Validation loss: 2.361471803521809

Epoch: 420| Step: 0
Training loss: 0.10842773110417964
Validation loss: 2.384267297340422

Epoch: 6| Step: 1
Training loss: 0.17270610637536649
Validation loss: 2.3601258263573075

Epoch: 6| Step: 2
Training loss: 0.14623150934802145
Validation loss: 2.378077533767769

Epoch: 6| Step: 3
Training loss: 0.12920965266463943
Validation loss: 2.3858476899496237

Epoch: 6| Step: 4
Training loss: 0.09820142681532046
Validation loss: 2.3663175301382857

Epoch: 6| Step: 5
Training loss: 0.10744801116651977
Validation loss: 2.3330908856659236

Epoch: 6| Step: 6
Training loss: 0.08740601451986628
Validation loss: 2.3567057728674934

Epoch: 6| Step: 7
Training loss: 0.21865897328326145
Validation loss: 2.317373126019114

Epoch: 6| Step: 8
Training loss: 0.09199470650206558
Validation loss: 2.329264076193785

Epoch: 6| Step: 9
Training loss: 0.09014901875960528
Validation loss: 2.2890962752699635

Epoch: 6| Step: 10
Training loss: 0.29980759510531474
Validation loss: 2.3099300390636426

Epoch: 6| Step: 11
Training loss: 0.10829459620736448
Validation loss: 2.257157530042739

Epoch: 6| Step: 12
Training loss: 0.12736465071954076
Validation loss: 2.2501940284664097

Epoch: 6| Step: 13
Training loss: 0.16405757260870485
Validation loss: 2.2618270633574484

Epoch: 421| Step: 0
Training loss: 0.11830301233246912
Validation loss: 2.2921083893444485

Epoch: 6| Step: 1
Training loss: 0.10297189368367955
Validation loss: 2.281398317171132

Epoch: 6| Step: 2
Training loss: 0.1411392689570811
Validation loss: 2.3062720372997703

Epoch: 6| Step: 3
Training loss: 0.13260428150958142
Validation loss: 2.34018196793575

Epoch: 6| Step: 4
Training loss: 0.21502792960165829
Validation loss: 2.3453791260713475

Epoch: 6| Step: 5
Training loss: 0.2178159509738441
Validation loss: 2.397902778324477

Epoch: 6| Step: 6
Training loss: 0.1121057157550644
Validation loss: 2.3914093097209803

Epoch: 6| Step: 7
Training loss: 0.08636402898160485
Validation loss: 2.3847628912546774

Epoch: 6| Step: 8
Training loss: 0.1454571309248491
Validation loss: 2.380628328545647

Epoch: 6| Step: 9
Training loss: 0.22321401970711252
Validation loss: 2.3710878985062585

Epoch: 6| Step: 10
Training loss: 0.13461469408397886
Validation loss: 2.342189455784377

Epoch: 6| Step: 11
Training loss: 0.13745342137611685
Validation loss: 2.335234006528821

Epoch: 6| Step: 12
Training loss: 0.14325658506882905
Validation loss: 2.343607974107396

Epoch: 6| Step: 13
Training loss: 0.14108501798069345
Validation loss: 2.355823267933526

Epoch: 422| Step: 0
Training loss: 0.1001304619227432
Validation loss: 2.3517445338564738

Epoch: 6| Step: 1
Training loss: 0.06844023282112162
Validation loss: 2.3128920463633307

Epoch: 6| Step: 2
Training loss: 0.1954878877896311
Validation loss: 2.3097891168266895

Epoch: 6| Step: 3
Training loss: 0.14979780696102696
Validation loss: 2.3191831139742374

Epoch: 6| Step: 4
Training loss: 0.19840402057901435
Validation loss: 2.3174350951236065

Epoch: 6| Step: 5
Training loss: 0.12272092244066413
Validation loss: 2.317791691979738

Epoch: 6| Step: 6
Training loss: 0.16032429345941998
Validation loss: 2.3232237649049146

Epoch: 6| Step: 7
Training loss: 0.11788410724902441
Validation loss: 2.318651026754038

Epoch: 6| Step: 8
Training loss: 0.1260237346719212
Validation loss: 2.291192626773662

Epoch: 6| Step: 9
Training loss: 0.11035950809331929
Validation loss: 2.327990174338222

Epoch: 6| Step: 10
Training loss: 0.2132769500382804
Validation loss: 2.34633757137968

Epoch: 6| Step: 11
Training loss: 0.11083742802882071
Validation loss: 2.33750063111066

Epoch: 6| Step: 12
Training loss: 0.12331396588030867
Validation loss: 2.3564897800113402

Epoch: 6| Step: 13
Training loss: 0.23879895487281874
Validation loss: 2.3381742904202545

Epoch: 423| Step: 0
Training loss: 0.08915780305629561
Validation loss: 2.340382441819892

Epoch: 6| Step: 1
Training loss: 0.0727255657220758
Validation loss: 2.3480404737040343

Epoch: 6| Step: 2
Training loss: 0.14417154425044293
Validation loss: 2.326323954541708

Epoch: 6| Step: 3
Training loss: 0.1316693560435272
Validation loss: 2.3194910123197823

Epoch: 6| Step: 4
Training loss: 0.1389580446833177
Validation loss: 2.3408527435593283

Epoch: 6| Step: 5
Training loss: 0.14198836409341706
Validation loss: 2.3411195044875948

Epoch: 6| Step: 6
Training loss: 0.29816725213558604
Validation loss: 2.3499291916588776

Epoch: 6| Step: 7
Training loss: 0.10345467986606519
Validation loss: 2.3197516760072006

Epoch: 6| Step: 8
Training loss: 0.22228256456020465
Validation loss: 2.2927470758223145

Epoch: 6| Step: 9
Training loss: 0.1527953362820916
Validation loss: 2.286595607671937

Epoch: 6| Step: 10
Training loss: 0.11911823109146917
Validation loss: 2.283187766929505

Epoch: 6| Step: 11
Training loss: 0.11496414406932172
Validation loss: 2.299323632837268

Epoch: 6| Step: 12
Training loss: 0.07544143143316036
Validation loss: 2.298349302031854

Epoch: 6| Step: 13
Training loss: 0.0725537882531751
Validation loss: 2.299649124034553

Epoch: 424| Step: 0
Training loss: 0.18297390089269128
Validation loss: 2.335281197562436

Epoch: 6| Step: 1
Training loss: 0.15251516821735903
Validation loss: 2.347330263182006

Epoch: 6| Step: 2
Training loss: 0.13310484406736783
Validation loss: 2.340747884341153

Epoch: 6| Step: 3
Training loss: 0.12359623661746859
Validation loss: 2.36695723319158

Epoch: 6| Step: 4
Training loss: 0.15718971436687004
Validation loss: 2.3421980474293487

Epoch: 6| Step: 5
Training loss: 0.14069195981076593
Validation loss: 2.337901910782771

Epoch: 6| Step: 6
Training loss: 0.23768202682641415
Validation loss: 2.3225968671104584

Epoch: 6| Step: 7
Training loss: 0.09813351355813145
Validation loss: 2.31792855474143

Epoch: 6| Step: 8
Training loss: 0.20904479534866252
Validation loss: 2.3014439125543333

Epoch: 6| Step: 9
Training loss: 0.1223236050103871
Validation loss: 2.3048532211208097

Epoch: 6| Step: 10
Training loss: 0.09166557478886606
Validation loss: 2.3273219366814883

Epoch: 6| Step: 11
Training loss: 0.1548962901097352
Validation loss: 2.3676611427395295

Epoch: 6| Step: 12
Training loss: 0.25567021548310703
Validation loss: 2.3461090007516576

Epoch: 6| Step: 13
Training loss: 0.10897015680521409
Validation loss: 2.357578082545995

Epoch: 425| Step: 0
Training loss: 0.1624450769591056
Validation loss: 2.353949659231588

Epoch: 6| Step: 1
Training loss: 0.14179609025259898
Validation loss: 2.364092940561711

Epoch: 6| Step: 2
Training loss: 0.12290618058374124
Validation loss: 2.355173455596216

Epoch: 6| Step: 3
Training loss: 0.0694202796629092
Validation loss: 2.3290418642035884

Epoch: 6| Step: 4
Training loss: 0.2291319922021806
Validation loss: 2.341998907885437

Epoch: 6| Step: 5
Training loss: 0.09850107024974109
Validation loss: 2.369659404631442

Epoch: 6| Step: 6
Training loss: 0.0789758660782646
Validation loss: 2.374418067016917

Epoch: 6| Step: 7
Training loss: 0.13879872953813605
Validation loss: 2.3580192186132405

Epoch: 6| Step: 8
Training loss: 0.15691336244403703
Validation loss: 2.3680630243937593

Epoch: 6| Step: 9
Training loss: 0.12635769226153784
Validation loss: 2.3884951429242656

Epoch: 6| Step: 10
Training loss: 0.07156381180031515
Validation loss: 2.368332148478304

Epoch: 6| Step: 11
Training loss: 0.0939930110714901
Validation loss: 2.3703334392348157

Epoch: 6| Step: 12
Training loss: 0.22086311550366589
Validation loss: 2.3796492117113437

Epoch: 6| Step: 13
Training loss: 0.23823396807726097
Validation loss: 2.371600111167727

Epoch: 426| Step: 0
Training loss: 0.07856550008527854
Validation loss: 2.37183828125908

Epoch: 6| Step: 1
Training loss: 0.1556957667287341
Validation loss: 2.3561980615751934

Epoch: 6| Step: 2
Training loss: 0.1522747519328092
Validation loss: 2.382529045686917

Epoch: 6| Step: 3
Training loss: 0.13270170835904185
Validation loss: 2.359557644210476

Epoch: 6| Step: 4
Training loss: 0.15120128030175004
Validation loss: 2.3956626924058075

Epoch: 6| Step: 5
Training loss: 0.1475106212461091
Validation loss: 2.4213359919685407

Epoch: 6| Step: 6
Training loss: 0.24577793413751964
Validation loss: 2.413255223558169

Epoch: 6| Step: 7
Training loss: 0.08256534850655853
Validation loss: 2.4119701996158738

Epoch: 6| Step: 8
Training loss: 0.13210049681154978
Validation loss: 2.419385511108175

Epoch: 6| Step: 9
Training loss: 0.21272211667822563
Validation loss: 2.399028179852882

Epoch: 6| Step: 10
Training loss: 0.11826638843316681
Validation loss: 2.3640724451669612

Epoch: 6| Step: 11
Training loss: 0.21614585248341917
Validation loss: 2.359943921361625

Epoch: 6| Step: 12
Training loss: 0.0883437239448177
Validation loss: 2.3756620869148923

Epoch: 6| Step: 13
Training loss: 0.11267550243092578
Validation loss: 2.342456923062339

Epoch: 427| Step: 0
Training loss: 0.0988031276556528
Validation loss: 2.315422703280351

Epoch: 6| Step: 1
Training loss: 0.14548508895503823
Validation loss: 2.250027235953268

Epoch: 6| Step: 2
Training loss: 0.13852288072777627
Validation loss: 2.265865137530173

Epoch: 6| Step: 3
Training loss: 0.1747151363874492
Validation loss: 2.2471798458498324

Epoch: 6| Step: 4
Training loss: 0.2309035870451039
Validation loss: 2.272615538504576

Epoch: 6| Step: 5
Training loss: 0.06500293570317123
Validation loss: 2.3001596084667697

Epoch: 6| Step: 6
Training loss: 0.12928578827683862
Validation loss: 2.341343338781584

Epoch: 6| Step: 7
Training loss: 0.21160609637088473
Validation loss: 2.295563903522501

Epoch: 6| Step: 8
Training loss: 0.22250689968651724
Validation loss: 2.3100807214076937

Epoch: 6| Step: 9
Training loss: 0.08462956359382612
Validation loss: 2.3163887400521213

Epoch: 6| Step: 10
Training loss: 0.12019176029117348
Validation loss: 2.3195732847571637

Epoch: 6| Step: 11
Training loss: 0.12341982090171923
Validation loss: 2.3192352637141846

Epoch: 6| Step: 12
Training loss: 0.15889027971944245
Validation loss: 2.2967214917424794

Epoch: 6| Step: 13
Training loss: 0.1363049921996694
Validation loss: 2.3022348931914984

Epoch: 428| Step: 0
Training loss: 0.22178759028399536
Validation loss: 2.3394092498299286

Epoch: 6| Step: 1
Training loss: 0.12467035024460911
Validation loss: 2.2958372449226467

Epoch: 6| Step: 2
Training loss: 0.09510659152940594
Validation loss: 2.2988412719911566

Epoch: 6| Step: 3
Training loss: 0.22543836283115457
Validation loss: 2.270309295955791

Epoch: 6| Step: 4
Training loss: 0.17160318295282273
Validation loss: 2.2871183512186923

Epoch: 6| Step: 5
Training loss: 0.14004814193001008
Validation loss: 2.2733157224339595

Epoch: 6| Step: 6
Training loss: 0.10596575898820648
Validation loss: 2.285103803253131

Epoch: 6| Step: 7
Training loss: 0.17411836760008012
Validation loss: 2.2999231447377455

Epoch: 6| Step: 8
Training loss: 0.17627503658584281
Validation loss: 2.3156879803251362

Epoch: 6| Step: 9
Training loss: 0.08973940719584254
Validation loss: 2.3344187976796102

Epoch: 6| Step: 10
Training loss: 0.08390142813649651
Validation loss: 2.372861979806736

Epoch: 6| Step: 11
Training loss: 0.09693267743432543
Validation loss: 2.37247290172653

Epoch: 6| Step: 12
Training loss: 0.10562916759445799
Validation loss: 2.4091546838952813

Epoch: 6| Step: 13
Training loss: 0.17395392162949577
Validation loss: 2.392596565394841

Epoch: 429| Step: 0
Training loss: 0.1418905006881151
Validation loss: 2.382988045189056

Epoch: 6| Step: 1
Training loss: 0.14209978652197475
Validation loss: 2.350278140119879

Epoch: 6| Step: 2
Training loss: 0.16176865286891784
Validation loss: 2.340330171778075

Epoch: 6| Step: 3
Training loss: 0.22252859672536351
Validation loss: 2.28305485321148

Epoch: 6| Step: 4
Training loss: 0.14652177333268102
Validation loss: 2.2709011956971255

Epoch: 6| Step: 5
Training loss: 0.1925080564596512
Validation loss: 2.2535436382672107

Epoch: 6| Step: 6
Training loss: 0.18218994140625
Validation loss: 2.2707170778628476

Epoch: 6| Step: 7
Training loss: 0.105925858654128
Validation loss: 2.277467601203438

Epoch: 6| Step: 8
Training loss: 0.07891276870843732
Validation loss: 2.320462725237781

Epoch: 6| Step: 9
Training loss: 0.21681007138890956
Validation loss: 2.3322947825200546

Epoch: 6| Step: 10
Training loss: 0.13096233843603833
Validation loss: 2.3575416308396604

Epoch: 6| Step: 11
Training loss: 0.08941046267987807
Validation loss: 2.347129082409945

Epoch: 6| Step: 12
Training loss: 0.15060062732614954
Validation loss: 2.3168030491160523

Epoch: 6| Step: 13
Training loss: 0.16988100459228206
Validation loss: 2.367260715496681

Epoch: 430| Step: 0
Training loss: 0.1885434758290978
Validation loss: 2.348277245054661

Epoch: 6| Step: 1
Training loss: 0.12164697100109585
Validation loss: 2.3133662850850953

Epoch: 6| Step: 2
Training loss: 0.1902763140309628
Validation loss: 2.3236684209531213

Epoch: 6| Step: 3
Training loss: 0.11420922998970306
Validation loss: 2.3184328719045

Epoch: 6| Step: 4
Training loss: 0.12704839799479736
Validation loss: 2.296530898632332

Epoch: 6| Step: 5
Training loss: 0.13555368191999756
Validation loss: 2.2775984839932626

Epoch: 6| Step: 6
Training loss: 0.13576498457671643
Validation loss: 2.297283417285165

Epoch: 6| Step: 7
Training loss: 0.07850542429236275
Validation loss: 2.2973372486978563

Epoch: 6| Step: 8
Training loss: 0.20498363497879854
Validation loss: 2.317751409654126

Epoch: 6| Step: 9
Training loss: 0.13917910798171915
Validation loss: 2.3270395108583224

Epoch: 6| Step: 10
Training loss: 0.1336227761909672
Validation loss: 2.337330112400174

Epoch: 6| Step: 11
Training loss: 0.10183475755623242
Validation loss: 2.3399803708864724

Epoch: 6| Step: 12
Training loss: 0.08414545801533463
Validation loss: 2.3576655821745724

Epoch: 6| Step: 13
Training loss: 0.1786169628433385
Validation loss: 2.348590487970182

Epoch: 431| Step: 0
Training loss: 0.12004016717439092
Validation loss: 2.3815240984676698

Epoch: 6| Step: 1
Training loss: 0.13740916313161472
Validation loss: 2.377346973269336

Epoch: 6| Step: 2
Training loss: 0.1502139490418603
Validation loss: 2.3762987932403528

Epoch: 6| Step: 3
Training loss: 0.14095239806889023
Validation loss: 2.3787445484742076

Epoch: 6| Step: 4
Training loss: 0.10066780906399028
Validation loss: 2.3474674006595504

Epoch: 6| Step: 5
Training loss: 0.08645461835214338
Validation loss: 2.3500040499378043

Epoch: 6| Step: 6
Training loss: 0.2307079092628362
Validation loss: 2.320990123089445

Epoch: 6| Step: 7
Training loss: 0.20262456650661104
Validation loss: 2.3425338794918407

Epoch: 6| Step: 8
Training loss: 0.1886768067941503
Validation loss: 2.305078709156529

Epoch: 6| Step: 9
Training loss: 0.2294657184676436
Validation loss: 2.335425392333559

Epoch: 6| Step: 10
Training loss: 0.10908236695650331
Validation loss: 2.390608159402105

Epoch: 6| Step: 11
Training loss: 0.10413945458535007
Validation loss: 2.3843590279237215

Epoch: 6| Step: 12
Training loss: 0.1559245176587359
Validation loss: 2.4436703379447207

Epoch: 6| Step: 13
Training loss: 0.10095128124745623
Validation loss: 2.468703480193047

Epoch: 432| Step: 0
Training loss: 0.2562061609589779
Validation loss: 2.4726923665323066

Epoch: 6| Step: 1
Training loss: 0.4025097846980231
Validation loss: 2.476119498472133

Epoch: 6| Step: 2
Training loss: 0.1210933962170755
Validation loss: 2.405485272728546

Epoch: 6| Step: 3
Training loss: 0.22252947561175082
Validation loss: 2.319089789790999

Epoch: 6| Step: 4
Training loss: 0.15659086478716908
Validation loss: 2.2970530736906776

Epoch: 6| Step: 5
Training loss: 0.24962366358734048
Validation loss: 2.2528354013719194

Epoch: 6| Step: 6
Training loss: 0.17347397248933716
Validation loss: 2.2692324932199495

Epoch: 6| Step: 7
Training loss: 0.19587456889613267
Validation loss: 2.271892148542892

Epoch: 6| Step: 8
Training loss: 0.300919934291911
Validation loss: 2.283775217564863

Epoch: 6| Step: 9
Training loss: 0.11836551014576156
Validation loss: 2.3214913230491194

Epoch: 6| Step: 10
Training loss: 0.1413545624702364
Validation loss: 2.3325245853936125

Epoch: 6| Step: 11
Training loss: 0.14223589388004831
Validation loss: 2.3376848198757756

Epoch: 6| Step: 12
Training loss: 0.22810972469607965
Validation loss: 2.3840339508877935

Epoch: 6| Step: 13
Training loss: 0.1985785538676799
Validation loss: 2.4020687938031333

Epoch: 433| Step: 0
Training loss: 0.3391068570176641
Validation loss: 2.3867861462628346

Epoch: 6| Step: 1
Training loss: 0.22032545065185002
Validation loss: 2.3535369464962175

Epoch: 6| Step: 2
Training loss: 0.2310203400957299
Validation loss: 2.274452321550385

Epoch: 6| Step: 3
Training loss: 0.11160983865751888
Validation loss: 2.2959928221302213

Epoch: 6| Step: 4
Training loss: 0.26370363397419744
Validation loss: 2.277719314495044

Epoch: 6| Step: 5
Training loss: 0.2009867399584126
Validation loss: 2.293047330396975

Epoch: 6| Step: 6
Training loss: 0.15668487827449434
Validation loss: 2.3280679063003427

Epoch: 6| Step: 7
Training loss: 0.12898753233383428
Validation loss: 2.3613164637099966

Epoch: 6| Step: 8
Training loss: 0.234506379498246
Validation loss: 2.333113400323835

Epoch: 6| Step: 9
Training loss: 0.1196324639861793
Validation loss: 2.3404427408338555

Epoch: 6| Step: 10
Training loss: 0.2691627415842283
Validation loss: 2.324227162655539

Epoch: 6| Step: 11
Training loss: 0.1302830616771724
Validation loss: 2.3339110328044628

Epoch: 6| Step: 12
Training loss: 0.20385570411186835
Validation loss: 2.299369949242377

Epoch: 6| Step: 13
Training loss: 0.22898533629909013
Validation loss: 2.3214080920978795

Epoch: 434| Step: 0
Training loss: 0.16232487705589727
Validation loss: 2.303810666130651

Epoch: 6| Step: 1
Training loss: 0.20984351844803226
Validation loss: 2.302900373597816

Epoch: 6| Step: 2
Training loss: 0.15935296298989757
Validation loss: 2.3474355191223384

Epoch: 6| Step: 3
Training loss: 0.2307834900713081
Validation loss: 2.3674622007457393

Epoch: 6| Step: 4
Training loss: 0.21761589167682774
Validation loss: 2.3783630896559687

Epoch: 6| Step: 5
Training loss: 0.20970429992744563
Validation loss: 2.419527523140109

Epoch: 6| Step: 6
Training loss: 0.28429782679629884
Validation loss: 2.418231670243379

Epoch: 6| Step: 7
Training loss: 0.21229368039175311
Validation loss: 2.4354469776245433

Epoch: 6| Step: 8
Training loss: 0.20564543955824505
Validation loss: 2.431487147984906

Epoch: 6| Step: 9
Training loss: 0.2084623930448919
Validation loss: 2.4224157178975374

Epoch: 6| Step: 10
Training loss: 0.320005968008418
Validation loss: 2.3649431853516107

Epoch: 6| Step: 11
Training loss: 0.1788815377171622
Validation loss: 2.2855813143560035

Epoch: 6| Step: 12
Training loss: 0.11637563814977768
Validation loss: 2.243960193993203

Epoch: 6| Step: 13
Training loss: 0.17864356308283247
Validation loss: 2.204414997138323

Epoch: 435| Step: 0
Training loss: 0.240341604538913
Validation loss: 2.199996142603083

Epoch: 6| Step: 1
Training loss: 0.1991513082003982
Validation loss: 2.2254935167658476

Epoch: 6| Step: 2
Training loss: 0.21670066141935065
Validation loss: 2.3295220269313757

Epoch: 6| Step: 3
Training loss: 0.15198288260874593
Validation loss: 2.3422631308938007

Epoch: 6| Step: 4
Training loss: 0.1059325976700335
Validation loss: 2.405047344804045

Epoch: 6| Step: 5
Training loss: 0.2947265281196913
Validation loss: 2.4638142444822275

Epoch: 6| Step: 6
Training loss: 0.2724338094133594
Validation loss: 2.4672266802383316

Epoch: 6| Step: 7
Training loss: 0.2743361148564785
Validation loss: 2.4580118832279547

Epoch: 6| Step: 8
Training loss: 0.1140854382965424
Validation loss: 2.371038629480732

Epoch: 6| Step: 9
Training loss: 0.32322979814002833
Validation loss: 2.288648789221497

Epoch: 6| Step: 10
Training loss: 0.30735552118951404
Validation loss: 2.2683332805578234

Epoch: 6| Step: 11
Training loss: 0.1717537647435779
Validation loss: 2.3020613764005913

Epoch: 6| Step: 12
Training loss: 0.25417825361064
Validation loss: 2.3208025978235765

Epoch: 6| Step: 13
Training loss: 0.18844718901869928
Validation loss: 2.345449598431018

Epoch: 436| Step: 0
Training loss: 0.188971664739316
Validation loss: 2.3798609131981454

Epoch: 6| Step: 1
Training loss: 0.1802457554683839
Validation loss: 2.4024055100185775

Epoch: 6| Step: 2
Training loss: 0.29262555683935243
Validation loss: 2.398518972351524

Epoch: 6| Step: 3
Training loss: 0.23693144845341138
Validation loss: 2.412325895941673

Epoch: 6| Step: 4
Training loss: 0.2258092097357601
Validation loss: 2.3847698110750457

Epoch: 6| Step: 5
Training loss: 0.2382081654516748
Validation loss: 2.39858014627615

Epoch: 6| Step: 6
Training loss: 0.15961911681960692
Validation loss: 2.3342731256196836

Epoch: 6| Step: 7
Training loss: 0.1866753044819191
Validation loss: 2.342768779162638

Epoch: 6| Step: 8
Training loss: 0.2465245397038694
Validation loss: 2.351893578189359

Epoch: 6| Step: 9
Training loss: 0.1921486276376322
Validation loss: 2.3377888070561204

Epoch: 6| Step: 10
Training loss: 0.29161680453835853
Validation loss: 2.341829824020409

Epoch: 6| Step: 11
Training loss: 0.18761120915542914
Validation loss: 2.3668206157106684

Epoch: 6| Step: 12
Training loss: 0.29040084777769365
Validation loss: 2.4069710886792897

Epoch: 6| Step: 13
Training loss: 0.3298063909027378
Validation loss: 2.4470874449246844

Epoch: 437| Step: 0
Training loss: 0.22977041869236062
Validation loss: 2.4588021713725774

Epoch: 6| Step: 1
Training loss: 0.19378194968532952
Validation loss: 2.446518869707589

Epoch: 6| Step: 2
Training loss: 0.16285490472245776
Validation loss: 2.4047540681964867

Epoch: 6| Step: 3
Training loss: 0.218868453447506
Validation loss: 2.402974655099847

Epoch: 6| Step: 4
Training loss: 0.14315509325687215
Validation loss: 2.3675126584424513

Epoch: 6| Step: 5
Training loss: 0.1850156507766689
Validation loss: 2.3329581304741005

Epoch: 6| Step: 6
Training loss: 0.285016848835739
Validation loss: 2.3113858666171523

Epoch: 6| Step: 7
Training loss: 0.32353047771393
Validation loss: 2.3242974717198215

Epoch: 6| Step: 8
Training loss: 0.27314569706918623
Validation loss: 2.319413499140831

Epoch: 6| Step: 9
Training loss: 0.32561729019321944
Validation loss: 2.3772005789637887

Epoch: 6| Step: 10
Training loss: 0.16635442831281208
Validation loss: 2.4328664170994116

Epoch: 6| Step: 11
Training loss: 0.2330081661506265
Validation loss: 2.486805495774214

Epoch: 6| Step: 12
Training loss: 0.34366023452168026
Validation loss: 2.448663372933515

Epoch: 6| Step: 13
Training loss: 0.15686545753332515
Validation loss: 2.4215724209584546

Epoch: 438| Step: 0
Training loss: 0.20324444010181106
Validation loss: 2.356126397737835

Epoch: 6| Step: 1
Training loss: 0.203313034396403
Validation loss: 2.3357873755139433

Epoch: 6| Step: 2
Training loss: 0.24870890032229154
Validation loss: 2.2713405555947666

Epoch: 6| Step: 3
Training loss: 0.2404676018576574
Validation loss: 2.2377836234073145

Epoch: 6| Step: 4
Training loss: 0.22964861793725105
Validation loss: 2.2224297871566616

Epoch: 6| Step: 5
Training loss: 0.24833438010736533
Validation loss: 2.2984017989993246

Epoch: 6| Step: 6
Training loss: 0.2981121111828768
Validation loss: 2.2863004919009966

Epoch: 6| Step: 7
Training loss: 0.26719416615608393
Validation loss: 2.3416872744076227

Epoch: 6| Step: 8
Training loss: 0.25271653432241536
Validation loss: 2.3433519841711083

Epoch: 6| Step: 9
Training loss: 0.12705374178416873
Validation loss: 2.4035141297673213

Epoch: 6| Step: 10
Training loss: 0.19335475106923897
Validation loss: 2.415244586470134

Epoch: 6| Step: 11
Training loss: 0.28832722274051176
Validation loss: 2.379875567154527

Epoch: 6| Step: 12
Training loss: 0.12298455628134669
Validation loss: 2.3813461743779922

Epoch: 6| Step: 13
Training loss: 0.24404132349406882
Validation loss: 2.3321349132501785

Epoch: 439| Step: 0
Training loss: 0.19371563429772207
Validation loss: 2.3050296544065394

Epoch: 6| Step: 1
Training loss: 0.12859045708149447
Validation loss: 2.29881227691538

Epoch: 6| Step: 2
Training loss: 0.21768804338504025
Validation loss: 2.289456866163694

Epoch: 6| Step: 3
Training loss: 0.14901660588555518
Validation loss: 2.293571643210394

Epoch: 6| Step: 4
Training loss: 0.23031188993230842
Validation loss: 2.3458320464964877

Epoch: 6| Step: 5
Training loss: 0.15954849019240303
Validation loss: 2.33454882441373

Epoch: 6| Step: 6
Training loss: 0.25248626369466554
Validation loss: 2.342490493177803

Epoch: 6| Step: 7
Training loss: 0.1545999785117607
Validation loss: 2.3636612146940497

Epoch: 6| Step: 8
Training loss: 0.212206019729612
Validation loss: 2.370087751255299

Epoch: 6| Step: 9
Training loss: 0.20795452527838704
Validation loss: 2.375468649876508

Epoch: 6| Step: 10
Training loss: 0.12186853134888465
Validation loss: 2.353753400925007

Epoch: 6| Step: 11
Training loss: 0.2488257876635234
Validation loss: 2.367935325165339

Epoch: 6| Step: 12
Training loss: 0.2151586652133992
Validation loss: 2.328493772762892

Epoch: 6| Step: 13
Training loss: 0.17588761608325174
Validation loss: 2.333855519629594

Epoch: 440| Step: 0
Training loss: 0.23590669020271743
Validation loss: 2.3317509535965177

Epoch: 6| Step: 1
Training loss: 0.1900815569265589
Validation loss: 2.356713101410711

Epoch: 6| Step: 2
Training loss: 0.23649528203536702
Validation loss: 2.3274440596805905

Epoch: 6| Step: 3
Training loss: 0.1631429081619944
Validation loss: 2.3644352459465816

Epoch: 6| Step: 4
Training loss: 0.21480063959564588
Validation loss: 2.3884963139257036

Epoch: 6| Step: 5
Training loss: 0.207089487917554
Validation loss: 2.375670592037574

Epoch: 6| Step: 6
Training loss: 0.09945018052254485
Validation loss: 2.3581418386410498

Epoch: 6| Step: 7
Training loss: 0.11443949380624266
Validation loss: 2.3537380958402356

Epoch: 6| Step: 8
Training loss: 0.16279583672718625
Validation loss: 2.359528370130177

Epoch: 6| Step: 9
Training loss: 0.2153261663974646
Validation loss: 2.3350254332872313

Epoch: 6| Step: 10
Training loss: 0.12004754908833087
Validation loss: 2.317848676022958

Epoch: 6| Step: 11
Training loss: 0.15813290250202802
Validation loss: 2.3251263228109313

Epoch: 6| Step: 12
Training loss: 0.22859010542273756
Validation loss: 2.324873526885918

Epoch: 6| Step: 13
Training loss: 0.12531934863327987
Validation loss: 2.3355095430474853

Epoch: 441| Step: 0
Training loss: 0.11973555345987047
Validation loss: 2.3716271407957357

Epoch: 6| Step: 1
Training loss: 0.18801544785822116
Validation loss: 2.403228253849686

Epoch: 6| Step: 2
Training loss: 0.3113260630463938
Validation loss: 2.416758838574761

Epoch: 6| Step: 3
Training loss: 0.1196216425344806
Validation loss: 2.34673170960364

Epoch: 6| Step: 4
Training loss: 0.22301228817945254
Validation loss: 2.325313554513981

Epoch: 6| Step: 5
Training loss: 0.1596798965245192
Validation loss: 2.291326103373594

Epoch: 6| Step: 6
Training loss: 0.18109029030971607
Validation loss: 2.239386216513275

Epoch: 6| Step: 7
Training loss: 0.1462078854759277
Validation loss: 2.20614765355949

Epoch: 6| Step: 8
Training loss: 0.17100903883058666
Validation loss: 2.234463508746663

Epoch: 6| Step: 9
Training loss: 0.1808649750207135
Validation loss: 2.2492074048961364

Epoch: 6| Step: 10
Training loss: 0.18609903395331315
Validation loss: 2.2569173809876317

Epoch: 6| Step: 11
Training loss: 0.1811259782631771
Validation loss: 2.2509636051800785

Epoch: 6| Step: 12
Training loss: 0.19374798727528272
Validation loss: 2.2937439312580348

Epoch: 6| Step: 13
Training loss: 0.08406831184135763
Validation loss: 2.3304879479910783

Epoch: 442| Step: 0
Training loss: 0.14100023381149576
Validation loss: 2.3310760252782283

Epoch: 6| Step: 1
Training loss: 0.27122809299657225
Validation loss: 2.3942255622199187

Epoch: 6| Step: 2
Training loss: 0.12868262169064393
Validation loss: 2.398020255460472

Epoch: 6| Step: 3
Training loss: 0.21393844427702205
Validation loss: 2.4001379002925702

Epoch: 6| Step: 4
Training loss: 0.2506514049709049
Validation loss: 2.367877856425186

Epoch: 6| Step: 5
Training loss: 0.13630370765780322
Validation loss: 2.3301846696177964

Epoch: 6| Step: 6
Training loss: 0.12848791965891485
Validation loss: 2.2673829519782998

Epoch: 6| Step: 7
Training loss: 0.13652758175913565
Validation loss: 2.246265381492586

Epoch: 6| Step: 8
Training loss: 0.16483847713624883
Validation loss: 2.2566675552596287

Epoch: 6| Step: 9
Training loss: 0.2244352163067441
Validation loss: 2.2332249234539727

Epoch: 6| Step: 10
Training loss: 0.11760365978781595
Validation loss: 2.2447798811693067

Epoch: 6| Step: 11
Training loss: 0.16011356157011544
Validation loss: 2.288708810802425

Epoch: 6| Step: 12
Training loss: 0.1135121450593081
Validation loss: 2.317404627952804

Epoch: 6| Step: 13
Training loss: 0.11644422532539923
Validation loss: 2.3713458262516425

Epoch: 443| Step: 0
Training loss: 0.17698587278788283
Validation loss: 2.3879146405822587

Epoch: 6| Step: 1
Training loss: 0.19019406731731273
Validation loss: 2.386989655401309

Epoch: 6| Step: 2
Training loss: 0.11512346102393128
Validation loss: 2.376131818905485

Epoch: 6| Step: 3
Training loss: 0.2057412914534004
Validation loss: 2.387259336975073

Epoch: 6| Step: 4
Training loss: 0.1291885031295313
Validation loss: 2.317686486818156

Epoch: 6| Step: 5
Training loss: 0.2056708534909147
Validation loss: 2.3431125947248725

Epoch: 6| Step: 6
Training loss: 0.13158577390344772
Validation loss: 2.2853998458766323

Epoch: 6| Step: 7
Training loss: 0.2073362461074711
Validation loss: 2.294039746756591

Epoch: 6| Step: 8
Training loss: 0.11744759227245499
Validation loss: 2.2662430126495434

Epoch: 6| Step: 9
Training loss: 0.2125707725871264
Validation loss: 2.3100560473744682

Epoch: 6| Step: 10
Training loss: 0.17925636773058187
Validation loss: 2.298509659132213

Epoch: 6| Step: 11
Training loss: 0.23077727534565387
Validation loss: 2.317893804355972

Epoch: 6| Step: 12
Training loss: 0.11853097665972964
Validation loss: 2.311471901783147

Epoch: 6| Step: 13
Training loss: 0.17977669823936823
Validation loss: 2.3265201245275895

Epoch: 444| Step: 0
Training loss: 0.14962551637431365
Validation loss: 2.3038807233599994

Epoch: 6| Step: 1
Training loss: 0.16875174353723146
Validation loss: 2.287271207183372

Epoch: 6| Step: 2
Training loss: 0.14632403181128215
Validation loss: 2.301039293110694

Epoch: 6| Step: 3
Training loss: 0.1450364266774294
Validation loss: 2.3207092305070693

Epoch: 6| Step: 4
Training loss: 0.14286898639451967
Validation loss: 2.3632655450429096

Epoch: 6| Step: 5
Training loss: 0.24150513842646676
Validation loss: 2.3605310731233864

Epoch: 6| Step: 6
Training loss: 0.1923045468760892
Validation loss: 2.368531268513023

Epoch: 6| Step: 7
Training loss: 0.14204774475418838
Validation loss: 2.344110350987298

Epoch: 6| Step: 8
Training loss: 0.08267004630756074
Validation loss: 2.3755271620173217

Epoch: 6| Step: 9
Training loss: 0.13565880114729748
Validation loss: 2.312593903279895

Epoch: 6| Step: 10
Training loss: 0.2077595209408572
Validation loss: 2.337339913053813

Epoch: 6| Step: 11
Training loss: 0.078004720604624
Validation loss: 2.3720196248167675

Epoch: 6| Step: 12
Training loss: 0.21984510826661868
Validation loss: 2.3370890305833405

Epoch: 6| Step: 13
Training loss: 0.07907085941341521
Validation loss: 2.3212923906186913

Epoch: 445| Step: 0
Training loss: 0.1842948533287273
Validation loss: 2.3360654245999286

Epoch: 6| Step: 1
Training loss: 0.20061152851176844
Validation loss: 2.358200664376602

Epoch: 6| Step: 2
Training loss: 0.08620925223255048
Validation loss: 2.361568284175629

Epoch: 6| Step: 3
Training loss: 0.10647567700905046
Validation loss: 2.357530301515169

Epoch: 6| Step: 4
Training loss: 0.13661256481322348
Validation loss: 2.3835737986826406

Epoch: 6| Step: 5
Training loss: 0.11218734913871631
Validation loss: 2.4303437002253343

Epoch: 6| Step: 6
Training loss: 0.2277533214140563
Validation loss: 2.3831010982279888

Epoch: 6| Step: 7
Training loss: 0.20225218170153983
Validation loss: 2.426708744603058

Epoch: 6| Step: 8
Training loss: 0.14012391168110472
Validation loss: 2.3922909904663396

Epoch: 6| Step: 9
Training loss: 0.10779655742944069
Validation loss: 2.3802838746471067

Epoch: 6| Step: 10
Training loss: 0.12468952498189886
Validation loss: 2.3742907684355217

Epoch: 6| Step: 11
Training loss: 0.0953558098387387
Validation loss: 2.358427763107569

Epoch: 6| Step: 12
Training loss: 0.11541105723549845
Validation loss: 2.3371475437887566

Epoch: 6| Step: 13
Training loss: 0.07138281040477634
Validation loss: 2.3600799902441807

Epoch: 446| Step: 0
Training loss: 0.09523870707071279
Validation loss: 2.3610344841973383

Epoch: 6| Step: 1
Training loss: 0.1424905952478848
Validation loss: 2.31219753270583

Epoch: 6| Step: 2
Training loss: 0.24138962154462587
Validation loss: 2.3086995599468136

Epoch: 6| Step: 3
Training loss: 0.13771713029875432
Validation loss: 2.327971010744469

Epoch: 6| Step: 4
Training loss: 0.12637218188361268
Validation loss: 2.2970713228133537

Epoch: 6| Step: 5
Training loss: 0.09621633409983883
Validation loss: 2.291171468068935

Epoch: 6| Step: 6
Training loss: 0.11518905039233931
Validation loss: 2.2657300280483232

Epoch: 6| Step: 7
Training loss: 0.15066638657921347
Validation loss: 2.2992732876423068

Epoch: 6| Step: 8
Training loss: 0.15601953556964962
Validation loss: 2.326876920571736

Epoch: 6| Step: 9
Training loss: 0.09851523274488051
Validation loss: 2.2805320811414873

Epoch: 6| Step: 10
Training loss: 0.09245242244414194
Validation loss: 2.3641175358852666

Epoch: 6| Step: 11
Training loss: 0.2073530718814333
Validation loss: 2.355563820086424

Epoch: 6| Step: 12
Training loss: 0.09556941988348933
Validation loss: 2.349382477952722

Epoch: 6| Step: 13
Training loss: 0.09867112199461267
Validation loss: 2.379359085022585

Epoch: 447| Step: 0
Training loss: 0.10811570385291829
Validation loss: 2.3795905202798435

Epoch: 6| Step: 1
Training loss: 0.13398631375303094
Validation loss: 2.4166858327216625

Epoch: 6| Step: 2
Training loss: 0.2097763936068665
Validation loss: 2.360013898513439

Epoch: 6| Step: 3
Training loss: 0.14240319481578217
Validation loss: 2.3904634351811023

Epoch: 6| Step: 4
Training loss: 0.17238345581944292
Validation loss: 2.3704944602051157

Epoch: 6| Step: 5
Training loss: 0.15105646296627448
Validation loss: 2.3352997594150557

Epoch: 6| Step: 6
Training loss: 0.12652338359486537
Validation loss: 2.3080956994611896

Epoch: 6| Step: 7
Training loss: 0.20478412808008725
Validation loss: 2.300828339862111

Epoch: 6| Step: 8
Training loss: 0.11421139499685663
Validation loss: 2.2917274720598195

Epoch: 6| Step: 9
Training loss: 0.0721509545625011
Validation loss: 2.3179309641721306

Epoch: 6| Step: 10
Training loss: 0.0882271153385316
Validation loss: 2.3246984212784816

Epoch: 6| Step: 11
Training loss: 0.12541089473424355
Validation loss: 2.3162944253255033

Epoch: 6| Step: 12
Training loss: 0.07736642437727718
Validation loss: 2.3477633552852484

Epoch: 6| Step: 13
Training loss: 0.16417897721871433
Validation loss: 2.3202664099447783

Epoch: 448| Step: 0
Training loss: 0.1130191549785944
Validation loss: 2.3705170046149253

Epoch: 6| Step: 1
Training loss: 0.12991766354495668
Validation loss: 2.396556717398112

Epoch: 6| Step: 2
Training loss: 0.1303650786765982
Validation loss: 2.3712307196989837

Epoch: 6| Step: 3
Training loss: 0.09781299885723152
Validation loss: 2.378280513438555

Epoch: 6| Step: 4
Training loss: 0.10947748900064816
Validation loss: 2.3589235148306047

Epoch: 6| Step: 5
Training loss: 0.1050243108710663
Validation loss: 2.3599841570109494

Epoch: 6| Step: 6
Training loss: 0.09636204489727775
Validation loss: 2.346782812113558

Epoch: 6| Step: 7
Training loss: 0.21140446896870668
Validation loss: 2.309961940488426

Epoch: 6| Step: 8
Training loss: 0.10783990670582075
Validation loss: 2.328899425697997

Epoch: 6| Step: 9
Training loss: 0.08618532556539157
Validation loss: 2.321195385073114

Epoch: 6| Step: 10
Training loss: 0.1895373147527208
Validation loss: 2.304377513552499

Epoch: 6| Step: 11
Training loss: 0.09952354473189388
Validation loss: 2.335443269715438

Epoch: 6| Step: 12
Training loss: 0.06644203470051639
Validation loss: 2.2608668358858997

Epoch: 6| Step: 13
Training loss: 0.23856677474323765
Validation loss: 2.300351537503197

Epoch: 449| Step: 0
Training loss: 0.1420389326722448
Validation loss: 2.2755577119357855

Epoch: 6| Step: 1
Training loss: 0.19864102349428503
Validation loss: 2.277705370828226

Epoch: 6| Step: 2
Training loss: 0.1374157170428114
Validation loss: 2.3354359907856668

Epoch: 6| Step: 3
Training loss: 0.1854946163268954
Validation loss: 2.2972649405189207

Epoch: 6| Step: 4
Training loss: 0.13910353997958577
Validation loss: 2.3530077123795405

Epoch: 6| Step: 5
Training loss: 0.0829747807471547
Validation loss: 2.3747214719080256

Epoch: 6| Step: 6
Training loss: 0.10847854231942962
Validation loss: 2.370580383798669

Epoch: 6| Step: 7
Training loss: 0.08659246502738212
Validation loss: 2.36851409439589

Epoch: 6| Step: 8
Training loss: 0.10867165165760995
Validation loss: 2.3552536766657246

Epoch: 6| Step: 9
Training loss: 0.10663798157765766
Validation loss: 2.3734421804936696

Epoch: 6| Step: 10
Training loss: 0.19134345289572052
Validation loss: 2.3910356646491855

Epoch: 6| Step: 11
Training loss: 0.14639860821284503
Validation loss: 2.4183115301294724

Epoch: 6| Step: 12
Training loss: 0.07907942473906125
Validation loss: 2.4158098684303972

Epoch: 6| Step: 13
Training loss: 0.06734199255002077
Validation loss: 2.4088917350112107

Epoch: 450| Step: 0
Training loss: 0.11906481112967952
Validation loss: 2.3380834671083623

Epoch: 6| Step: 1
Training loss: 0.06380526460125259
Validation loss: 2.342339211540493

Epoch: 6| Step: 2
Training loss: 0.10769006023806285
Validation loss: 2.388258296082267

Epoch: 6| Step: 3
Training loss: 0.15483546116466596
Validation loss: 2.3155118955407503

Epoch: 6| Step: 4
Training loss: 0.10762235833292134
Validation loss: 2.298619281948545

Epoch: 6| Step: 5
Training loss: 0.16395839726201628
Validation loss: 2.320444918048783

Epoch: 6| Step: 6
Training loss: 0.21732744812590868
Validation loss: 2.3365434072123312

Epoch: 6| Step: 7
Training loss: 0.10116979898804569
Validation loss: 2.3688675777250476

Epoch: 6| Step: 8
Training loss: 0.06244461019133703
Validation loss: 2.3785517138235672

Epoch: 6| Step: 9
Training loss: 0.1839466153412809
Validation loss: 2.382465397383003

Epoch: 6| Step: 10
Training loss: 0.07683961964188113
Validation loss: 2.350039091856361

Epoch: 6| Step: 11
Training loss: 0.11664527779667903
Validation loss: 2.4039856306303884

Epoch: 6| Step: 12
Training loss: 0.12149735071733797
Validation loss: 2.368792464915473

Epoch: 6| Step: 13
Training loss: 0.08573517499153842
Validation loss: 2.3745408383407263

Epoch: 451| Step: 0
Training loss: 0.09665191617580583
Validation loss: 2.35924085075287

Epoch: 6| Step: 1
Training loss: 0.0761404278226382
Validation loss: 2.337672289428489

Epoch: 6| Step: 2
Training loss: 0.18975063442229712
Validation loss: 2.2966122527550827

Epoch: 6| Step: 3
Training loss: 0.13740090082708262
Validation loss: 2.306986858897512

Epoch: 6| Step: 4
Training loss: 0.09080651906593458
Validation loss: 2.3189383457672395

Epoch: 6| Step: 5
Training loss: 0.16970244852016733
Validation loss: 2.277488879342599

Epoch: 6| Step: 6
Training loss: 0.14681855547642286
Validation loss: 2.2355416480059462

Epoch: 6| Step: 7
Training loss: 0.07096491237798117
Validation loss: 2.3012060863086403

Epoch: 6| Step: 8
Training loss: 0.14296729394556904
Validation loss: 2.29009539600952

Epoch: 6| Step: 9
Training loss: 0.09496681970339846
Validation loss: 2.3337390791524903

Epoch: 6| Step: 10
Training loss: 0.12346253503360774
Validation loss: 2.3443527026469932

Epoch: 6| Step: 11
Training loss: 0.09572128201509887
Validation loss: 2.3556024469266914

Epoch: 6| Step: 12
Training loss: 0.1268415400821699
Validation loss: 2.3687505877189396

Epoch: 6| Step: 13
Training loss: 0.22826731468921116
Validation loss: 2.4192545739798925

Epoch: 452| Step: 0
Training loss: 0.10621152805390069
Validation loss: 2.3935991714207816

Epoch: 6| Step: 1
Training loss: 0.17969279696079227
Validation loss: 2.370375444748868

Epoch: 6| Step: 2
Training loss: 0.07894585731937462
Validation loss: 2.3513884671608305

Epoch: 6| Step: 3
Training loss: 0.21299820552828938
Validation loss: 2.3592538164812304

Epoch: 6| Step: 4
Training loss: 0.09736905783884901
Validation loss: 2.327169722965519

Epoch: 6| Step: 5
Training loss: 0.11802247131582448
Validation loss: 2.301788300778831

Epoch: 6| Step: 6
Training loss: 0.09498375947536024
Validation loss: 2.303349381538992

Epoch: 6| Step: 7
Training loss: 0.09314463290854706
Validation loss: 2.2703862882446817

Epoch: 6| Step: 8
Training loss: 0.09579441037707345
Validation loss: 2.272179531848334

Epoch: 6| Step: 9
Training loss: 0.12181946348017869
Validation loss: 2.2696422419649167

Epoch: 6| Step: 10
Training loss: 0.24166503047937318
Validation loss: 2.2989502556343524

Epoch: 6| Step: 11
Training loss: 0.08708529267757231
Validation loss: 2.315959585286874

Epoch: 6| Step: 12
Training loss: 0.08786905871814003
Validation loss: 2.3733844843213783

Epoch: 6| Step: 13
Training loss: 0.11677777666852897
Validation loss: 2.3881968569572334

Epoch: 453| Step: 0
Training loss: 0.17586982932383
Validation loss: 2.4346680203878157

Epoch: 6| Step: 1
Training loss: 0.12906610085541953
Validation loss: 2.4211818013962985

Epoch: 6| Step: 2
Training loss: 0.14166174957797295
Validation loss: 2.415671501873642

Epoch: 6| Step: 3
Training loss: 0.09186492082070495
Validation loss: 2.3896693008968226

Epoch: 6| Step: 4
Training loss: 0.11693412091232093
Validation loss: 2.3251610715012454

Epoch: 6| Step: 5
Training loss: 0.08707253870422048
Validation loss: 2.287593887996123

Epoch: 6| Step: 6
Training loss: 0.15092161493844733
Validation loss: 2.252764074503904

Epoch: 6| Step: 7
Training loss: 0.16016245457795883
Validation loss: 2.249821503143539

Epoch: 6| Step: 8
Training loss: 0.1779850041550226
Validation loss: 2.243564229498076

Epoch: 6| Step: 9
Training loss: 0.13803685892984444
Validation loss: 2.278688318281333

Epoch: 6| Step: 10
Training loss: 0.09667532361903453
Validation loss: 2.2909475363505476

Epoch: 6| Step: 11
Training loss: 0.18196983652119683
Validation loss: 2.3385849433978296

Epoch: 6| Step: 12
Training loss: 0.039305050148387526
Validation loss: 2.350280978332426

Epoch: 6| Step: 13
Training loss: 0.14658260866339887
Validation loss: 2.3790751136505777

Epoch: 454| Step: 0
Training loss: 0.10554138525797806
Validation loss: 2.4102423684382632

Epoch: 6| Step: 1
Training loss: 0.11943526262940471
Validation loss: 2.4243747075431368

Epoch: 6| Step: 2
Training loss: 0.1389195285882566
Validation loss: 2.4317032987607163

Epoch: 6| Step: 3
Training loss: 0.08340993976113834
Validation loss: 2.398428321514315

Epoch: 6| Step: 4
Training loss: 0.13749079023208607
Validation loss: 2.3972242907167094

Epoch: 6| Step: 5
Training loss: 0.17608116313930966
Validation loss: 2.3600391430291356

Epoch: 6| Step: 6
Training loss: 0.12351315947092048
Validation loss: 2.3396430875114893

Epoch: 6| Step: 7
Training loss: 0.17487863755924973
Validation loss: 2.2908367216549466

Epoch: 6| Step: 8
Training loss: 0.21844789386136923
Validation loss: 2.2931986424834547

Epoch: 6| Step: 9
Training loss: 0.1634850842751174
Validation loss: 2.24825722242617

Epoch: 6| Step: 10
Training loss: 0.16842800387860093
Validation loss: 2.2719310678595677

Epoch: 6| Step: 11
Training loss: 0.0858087821979566
Validation loss: 2.2687481472399127

Epoch: 6| Step: 12
Training loss: 0.13305188791728614
Validation loss: 2.297446368965318

Epoch: 6| Step: 13
Training loss: 0.09070211327815722
Validation loss: 2.336385458650581

Epoch: 455| Step: 0
Training loss: 0.09650051005196551
Validation loss: 2.368128823281489

Epoch: 6| Step: 1
Training loss: 0.12475053660166506
Validation loss: 2.423455448356171

Epoch: 6| Step: 2
Training loss: 0.16356977769886602
Validation loss: 2.391884961484354

Epoch: 6| Step: 3
Training loss: 0.2126478946257996
Validation loss: 2.4435525532884634

Epoch: 6| Step: 4
Training loss: 0.1925665660430111
Validation loss: 2.40158787296024

Epoch: 6| Step: 5
Training loss: 0.18808243610612868
Validation loss: 2.3680867946964668

Epoch: 6| Step: 6
Training loss: 0.11506799631936424
Validation loss: 2.3531596062276523

Epoch: 6| Step: 7
Training loss: 0.1830186765330559
Validation loss: 2.3186304398187154

Epoch: 6| Step: 8
Training loss: 0.19629486037464472
Validation loss: 2.253312160333976

Epoch: 6| Step: 9
Training loss: 0.11872993883283571
Validation loss: 2.2776092884999675

Epoch: 6| Step: 10
Training loss: 0.10374004849856513
Validation loss: 2.266554879044463

Epoch: 6| Step: 11
Training loss: 0.18684316863195888
Validation loss: 2.2909374695282128

Epoch: 6| Step: 12
Training loss: 0.0686155763389386
Validation loss: 2.306328789088001

Epoch: 6| Step: 13
Training loss: 0.1211607616881828
Validation loss: 2.3007131428186427

Epoch: 456| Step: 0
Training loss: 0.12043560668697363
Validation loss: 2.333558859085505

Epoch: 6| Step: 1
Training loss: 0.16402900444698656
Validation loss: 2.373974083072464

Epoch: 6| Step: 2
Training loss: 0.1986490781232661
Validation loss: 2.3957846366852014

Epoch: 6| Step: 3
Training loss: 0.1927258294557157
Validation loss: 2.373591330724389

Epoch: 6| Step: 4
Training loss: 0.1384128582746943
Validation loss: 2.392586420516533

Epoch: 6| Step: 5
Training loss: 0.129439824652139
Validation loss: 2.3788597250157544

Epoch: 6| Step: 6
Training loss: 0.07333709925000281
Validation loss: 2.35179534131117

Epoch: 6| Step: 7
Training loss: 0.13276291370350735
Validation loss: 2.341001554333141

Epoch: 6| Step: 8
Training loss: 0.09134431639987403
Validation loss: 2.3354841832233997

Epoch: 6| Step: 9
Training loss: 0.10399010168165645
Validation loss: 2.3384812011473217

Epoch: 6| Step: 10
Training loss: 0.08640307327487502
Validation loss: 2.2648593241020465

Epoch: 6| Step: 11
Training loss: 0.09801327292966197
Validation loss: 2.2731520085850496

Epoch: 6| Step: 12
Training loss: 0.12811599153157838
Validation loss: 2.2665422833726327

Epoch: 6| Step: 13
Training loss: 0.15651832429413418
Validation loss: 2.2740512041133516

Epoch: 457| Step: 0
Training loss: 0.09852060696395103
Validation loss: 2.2805657938943225

Epoch: 6| Step: 1
Training loss: 0.0821273785425225
Validation loss: 2.2720181031350988

Epoch: 6| Step: 2
Training loss: 0.10618481126365202
Validation loss: 2.285509302776018

Epoch: 6| Step: 3
Training loss: 0.1190270367069734
Validation loss: 2.3247352385394726

Epoch: 6| Step: 4
Training loss: 0.17508621029481286
Validation loss: 2.2870588203411577

Epoch: 6| Step: 5
Training loss: 0.17634018937443285
Validation loss: 2.2865963291385936

Epoch: 6| Step: 6
Training loss: 0.09951108870526769
Validation loss: 2.3127519297926984

Epoch: 6| Step: 7
Training loss: 0.08215296888347128
Validation loss: 2.325826007647788

Epoch: 6| Step: 8
Training loss: 0.05907940267595249
Validation loss: 2.3325181282657113

Epoch: 6| Step: 9
Training loss: 0.18141146529961957
Validation loss: 2.329547496230236

Epoch: 6| Step: 10
Training loss: 0.08536714154138635
Validation loss: 2.3549118165849725

Epoch: 6| Step: 11
Training loss: 0.10225619400111015
Validation loss: 2.3440898864844435

Epoch: 6| Step: 12
Training loss: 0.13406901063648768
Validation loss: 2.3406562000693922

Epoch: 6| Step: 13
Training loss: 0.14267051002953254
Validation loss: 2.3337710445374067

Epoch: 458| Step: 0
Training loss: 0.09459749257434705
Validation loss: 2.3550887796136752

Epoch: 6| Step: 1
Training loss: 0.153276510116755
Validation loss: 2.343710226179513

Epoch: 6| Step: 2
Training loss: 0.09708870957118254
Validation loss: 2.3247645372122374

Epoch: 6| Step: 3
Training loss: 0.10700815031587771
Validation loss: 2.3173671455151537

Epoch: 6| Step: 4
Training loss: 0.06763555630382535
Validation loss: 2.3170964291317615

Epoch: 6| Step: 5
Training loss: 0.077283855086974
Validation loss: 2.3204983002623245

Epoch: 6| Step: 6
Training loss: 0.09581280767953769
Validation loss: 2.3135243447185125

Epoch: 6| Step: 7
Training loss: 0.17340130320855943
Validation loss: 2.3480948976362566

Epoch: 6| Step: 8
Training loss: 0.16899215181244606
Validation loss: 2.30957337667399

Epoch: 6| Step: 9
Training loss: 0.09610340042812845
Validation loss: 2.298015093602946

Epoch: 6| Step: 10
Training loss: 0.09477390502362809
Validation loss: 2.3203652115816613

Epoch: 6| Step: 11
Training loss: 0.11749005599631021
Validation loss: 2.3035180313211385

Epoch: 6| Step: 12
Training loss: 0.14303753922903717
Validation loss: 2.299987827757468

Epoch: 6| Step: 13
Training loss: 0.11222880329028759
Validation loss: 2.2979134913089663

Epoch: 459| Step: 0
Training loss: 0.13531447338665115
Validation loss: 2.300006824635318

Epoch: 6| Step: 1
Training loss: 0.09540497796053753
Validation loss: 2.286899008886463

Epoch: 6| Step: 2
Training loss: 0.18169677030719342
Validation loss: 2.28096288564701

Epoch: 6| Step: 3
Training loss: 0.07458764553701562
Validation loss: 2.287829891422755

Epoch: 6| Step: 4
Training loss: 0.09563048194306073
Validation loss: 2.303005037517144

Epoch: 6| Step: 5
Training loss: 0.14711714451065883
Validation loss: 2.274175579013435

Epoch: 6| Step: 6
Training loss: 0.09773649733302665
Validation loss: 2.2910942511254158

Epoch: 6| Step: 7
Training loss: 0.19235374502185856
Validation loss: 2.2744106934003883

Epoch: 6| Step: 8
Training loss: 0.07463179957839422
Validation loss: 2.275227556226071

Epoch: 6| Step: 9
Training loss: 0.09738361926764084
Validation loss: 2.3184995551760794

Epoch: 6| Step: 10
Training loss: 0.15609566695952165
Validation loss: 2.2562739924127624

Epoch: 6| Step: 11
Training loss: 0.08812412134283734
Validation loss: 2.3384776173906276

Epoch: 6| Step: 12
Training loss: 0.10229913252219626
Validation loss: 2.322930384011925

Epoch: 6| Step: 13
Training loss: 0.09201958707893661
Validation loss: 2.3281176244114143

Epoch: 460| Step: 0
Training loss: 0.08534794937272713
Validation loss: 2.3450882840624803

Epoch: 6| Step: 1
Training loss: 0.09707841628267484
Validation loss: 2.326473641743232

Epoch: 6| Step: 2
Training loss: 0.08619869700978497
Validation loss: 2.3361404983191045

Epoch: 6| Step: 3
Training loss: 0.18036342040687717
Validation loss: 2.358009174758062

Epoch: 6| Step: 4
Training loss: 0.1145117578599119
Validation loss: 2.3577443462436705

Epoch: 6| Step: 5
Training loss: 0.12642458418490535
Validation loss: 2.353509115445756

Epoch: 6| Step: 6
Training loss: 0.06634569211786413
Validation loss: 2.33635611862147

Epoch: 6| Step: 7
Training loss: 0.09657723363796113
Validation loss: 2.3745052338258015

Epoch: 6| Step: 8
Training loss: 0.0983515686046063
Validation loss: 2.3542559671484677

Epoch: 6| Step: 9
Training loss: 0.1545411120470177
Validation loss: 2.3468208808033926

Epoch: 6| Step: 10
Training loss: 0.05928721738468361
Validation loss: 2.3154704121227847

Epoch: 6| Step: 11
Training loss: 0.1743711818256539
Validation loss: 2.349783527603572

Epoch: 6| Step: 12
Training loss: 0.07394608807043702
Validation loss: 2.3060729653738417

Epoch: 6| Step: 13
Training loss: 0.10816532707370602
Validation loss: 2.3124227696598165

Epoch: 461| Step: 0
Training loss: 0.16709130675022618
Validation loss: 2.3185592794496865

Epoch: 6| Step: 1
Training loss: 0.11067215590634552
Validation loss: 2.328461664466877

Epoch: 6| Step: 2
Training loss: 0.15369530395925074
Validation loss: 2.2879382331389513

Epoch: 6| Step: 3
Training loss: 0.09133040835656404
Validation loss: 2.317213897303576

Epoch: 6| Step: 4
Training loss: 0.17074743957051977
Validation loss: 2.295734837141086

Epoch: 6| Step: 5
Training loss: 0.10632202463076988
Validation loss: 2.3174167192892536

Epoch: 6| Step: 6
Training loss: 0.12895613485392268
Validation loss: 2.3330461622742042

Epoch: 6| Step: 7
Training loss: 0.048083947773477916
Validation loss: 2.33033495591939

Epoch: 6| Step: 8
Training loss: 0.11465368405088601
Validation loss: 2.34088414252968

Epoch: 6| Step: 9
Training loss: 0.11222426810808797
Validation loss: 2.341107002279471

Epoch: 6| Step: 10
Training loss: 0.09234037210770084
Validation loss: 2.3250687706663173

Epoch: 6| Step: 11
Training loss: 0.10778574438781059
Validation loss: 2.3394355878783104

Epoch: 6| Step: 12
Training loss: 0.08255927691821127
Validation loss: 2.306101965875451

Epoch: 6| Step: 13
Training loss: 0.04581339038293282
Validation loss: 2.317172851498497

Epoch: 462| Step: 0
Training loss: 0.10195854801063921
Validation loss: 2.297288205797727

Epoch: 6| Step: 1
Training loss: 0.08935153931696402
Validation loss: 2.3145434478474387

Epoch: 6| Step: 2
Training loss: 0.11954705688578399
Validation loss: 2.300372605640684

Epoch: 6| Step: 3
Training loss: 0.17101453924553262
Validation loss: 2.33812934300347

Epoch: 6| Step: 4
Training loss: 0.09768170978546059
Validation loss: 2.2752918455577475

Epoch: 6| Step: 5
Training loss: 0.17733356849919527
Validation loss: 2.3204416489265878

Epoch: 6| Step: 6
Training loss: 0.06892148246342021
Validation loss: 2.284847734911086

Epoch: 6| Step: 7
Training loss: 0.07186267607186764
Validation loss: 2.265290797120748

Epoch: 6| Step: 8
Training loss: 0.14778538562088456
Validation loss: 2.2620052412862774

Epoch: 6| Step: 9
Training loss: 0.13467520984106107
Validation loss: 2.271845872274252

Epoch: 6| Step: 10
Training loss: 0.13930848899601833
Validation loss: 2.241160038403084

Epoch: 6| Step: 11
Training loss: 0.17533804863726768
Validation loss: 2.26882117160439

Epoch: 6| Step: 12
Training loss: 0.0821138771902571
Validation loss: 2.272340664506693

Epoch: 6| Step: 13
Training loss: 0.09065400555543404
Validation loss: 2.2985288335759573

Epoch: 463| Step: 0
Training loss: 0.09220091693841394
Validation loss: 2.305344257664525

Epoch: 6| Step: 1
Training loss: 0.07474133694925275
Validation loss: 2.318161211683897

Epoch: 6| Step: 2
Training loss: 0.06627749133569974
Validation loss: 2.3603499360248446

Epoch: 6| Step: 3
Training loss: 0.1487090362715877
Validation loss: 2.3748719462062335

Epoch: 6| Step: 4
Training loss: 0.08250504428621737
Validation loss: 2.3756253326507553

Epoch: 6| Step: 5
Training loss: 0.06011843607537308
Validation loss: 2.375589564709764

Epoch: 6| Step: 6
Training loss: 0.06369977000657605
Validation loss: 2.371360000393409

Epoch: 6| Step: 7
Training loss: 0.09761124527557483
Validation loss: 2.3599203677792113

Epoch: 6| Step: 8
Training loss: 0.10008974741883565
Validation loss: 2.3693535873232303

Epoch: 6| Step: 9
Training loss: 0.24299544497476955
Validation loss: 2.3495749818831717

Epoch: 6| Step: 10
Training loss: 0.056818147460834995
Validation loss: 2.3343224024135987

Epoch: 6| Step: 11
Training loss: 0.06521957023883468
Validation loss: 2.301822896144084

Epoch: 6| Step: 12
Training loss: 0.18275544343974354
Validation loss: 2.299845055652863

Epoch: 6| Step: 13
Training loss: 0.16318358849936934
Validation loss: 2.3222358890966106

Epoch: 464| Step: 0
Training loss: 0.1605739728422897
Validation loss: 2.2861888856701746

Epoch: 6| Step: 1
Training loss: 0.12384928092378183
Validation loss: 2.297525180062411

Epoch: 6| Step: 2
Training loss: 0.08839606545300425
Validation loss: 2.321369994013929

Epoch: 6| Step: 3
Training loss: 0.08971616247950831
Validation loss: 2.3448489308412768

Epoch: 6| Step: 4
Training loss: 0.12805349605169639
Validation loss: 2.3457860370946855

Epoch: 6| Step: 5
Training loss: 0.08706521970026039
Validation loss: 2.362607438200606

Epoch: 6| Step: 6
Training loss: 0.13842456551613325
Validation loss: 2.3423633085565276

Epoch: 6| Step: 7
Training loss: 0.11477470852796785
Validation loss: 2.370217833028259

Epoch: 6| Step: 8
Training loss: 0.17436140745776332
Validation loss: 2.336737328694798

Epoch: 6| Step: 9
Training loss: 0.11449190758599664
Validation loss: 2.3572443078859666

Epoch: 6| Step: 10
Training loss: 0.12300996756702502
Validation loss: 2.3059574166481562

Epoch: 6| Step: 11
Training loss: 0.10527360045609752
Validation loss: 2.284069600070841

Epoch: 6| Step: 12
Training loss: 0.16723610536880693
Validation loss: 2.227940762151185

Epoch: 6| Step: 13
Training loss: 0.12015297984471361
Validation loss: 2.2308813643395746

Epoch: 465| Step: 0
Training loss: 0.11831208486655465
Validation loss: 2.2416173567286948

Epoch: 6| Step: 1
Training loss: 0.19673573737997863
Validation loss: 2.2267744929498625

Epoch: 6| Step: 2
Training loss: 0.11741077293200793
Validation loss: 2.2822651904476206

Epoch: 6| Step: 3
Training loss: 0.08842156366043029
Validation loss: 2.2559345637863975

Epoch: 6| Step: 4
Training loss: 0.10637618803958915
Validation loss: 2.294143181173792

Epoch: 6| Step: 5
Training loss: 0.11681473174471163
Validation loss: 2.3217356620016214

Epoch: 6| Step: 6
Training loss: 0.08561850264272164
Validation loss: 2.3537679652784798

Epoch: 6| Step: 7
Training loss: 0.13720192679144946
Validation loss: 2.3645308261375906

Epoch: 6| Step: 8
Training loss: 0.081912022184576
Validation loss: 2.3547625724461088

Epoch: 6| Step: 9
Training loss: 0.17635426901716525
Validation loss: 2.3243990302818722

Epoch: 6| Step: 10
Training loss: 0.08508293666316688
Validation loss: 2.334975986877651

Epoch: 6| Step: 11
Training loss: 0.20003960299293158
Validation loss: 2.2991557670037888

Epoch: 6| Step: 12
Training loss: 0.1222887754613015
Validation loss: 2.273157935119627

Epoch: 6| Step: 13
Training loss: 0.11775156010871866
Validation loss: 2.2795389118626885

Epoch: 466| Step: 0
Training loss: 0.10047066203206798
Validation loss: 2.291356549203804

Epoch: 6| Step: 1
Training loss: 0.10277135966515655
Validation loss: 2.2858576612892496

Epoch: 6| Step: 2
Training loss: 0.16985185868770952
Validation loss: 2.2528224115004867

Epoch: 6| Step: 3
Training loss: 0.09058307097037877
Validation loss: 2.2698928923005663

Epoch: 6| Step: 4
Training loss: 0.13838927930720538
Validation loss: 2.2574750032963493

Epoch: 6| Step: 5
Training loss: 0.19523007561024247
Validation loss: 2.275988008906612

Epoch: 6| Step: 6
Training loss: 0.08306870751295524
Validation loss: 2.3120385662733014

Epoch: 6| Step: 7
Training loss: 0.22579411400708016
Validation loss: 2.309410223873404

Epoch: 6| Step: 8
Training loss: 0.08835974638411423
Validation loss: 2.3260566997902417

Epoch: 6| Step: 9
Training loss: 0.0784166851389948
Validation loss: 2.3604262911721605

Epoch: 6| Step: 10
Training loss: 0.13872320944305425
Validation loss: 2.3594436423640244

Epoch: 6| Step: 11
Training loss: 0.1372451593495627
Validation loss: 2.3728000401931717

Epoch: 6| Step: 12
Training loss: 0.10326642504263983
Validation loss: 2.3176894180357417

Epoch: 6| Step: 13
Training loss: 0.11186988667704985
Validation loss: 2.3239751985829784

Epoch: 467| Step: 0
Training loss: 0.08002095100404029
Validation loss: 2.293200949335418

Epoch: 6| Step: 1
Training loss: 0.10338946517909503
Validation loss: 2.2649048811790253

Epoch: 6| Step: 2
Training loss: 0.10581968344624305
Validation loss: 2.241958528152216

Epoch: 6| Step: 3
Training loss: 0.1157205798771643
Validation loss: 2.250962458299351

Epoch: 6| Step: 4
Training loss: 0.11519039656458448
Validation loss: 2.2847413819452402

Epoch: 6| Step: 5
Training loss: 0.12219737878241033
Validation loss: 2.3027333997465376

Epoch: 6| Step: 6
Training loss: 0.0944129530747193
Validation loss: 2.29639227999117

Epoch: 6| Step: 7
Training loss: 0.12063826373783147
Validation loss: 2.3664591334143354

Epoch: 6| Step: 8
Training loss: 0.09700247794880819
Validation loss: 2.3825312891803248

Epoch: 6| Step: 9
Training loss: 0.17621474854515626
Validation loss: 2.352489405544489

Epoch: 6| Step: 10
Training loss: 0.11870199506843745
Validation loss: 2.368881133058072

Epoch: 6| Step: 11
Training loss: 0.18847929008763478
Validation loss: 2.3666475667735942

Epoch: 6| Step: 12
Training loss: 0.17433863586245302
Validation loss: 2.3218323700423737

Epoch: 6| Step: 13
Training loss: 0.18404769577243638
Validation loss: 2.2944588748892882

Epoch: 468| Step: 0
Training loss: 0.1438180751905226
Validation loss: 2.276795667279169

Epoch: 6| Step: 1
Training loss: 0.11821587270058154
Validation loss: 2.283726753411871

Epoch: 6| Step: 2
Training loss: 0.09544362678797157
Validation loss: 2.296504518956867

Epoch: 6| Step: 3
Training loss: 0.09955447217248486
Validation loss: 2.3156496829575284

Epoch: 6| Step: 4
Training loss: 0.12566495400000782
Validation loss: 2.3344343831720167

Epoch: 6| Step: 5
Training loss: 0.1282264092993607
Validation loss: 2.2886006075013863

Epoch: 6| Step: 6
Training loss: 0.20464756590644306
Validation loss: 2.2996425662351982

Epoch: 6| Step: 7
Training loss: 0.11683389242940216
Validation loss: 2.2759081794166756

Epoch: 6| Step: 8
Training loss: 0.17126680183824175
Validation loss: 2.2580272289865735

Epoch: 6| Step: 9
Training loss: 0.12396334145818033
Validation loss: 2.2848154070953606

Epoch: 6| Step: 10
Training loss: 0.09880762377608018
Validation loss: 2.288735542436518

Epoch: 6| Step: 11
Training loss: 0.17960050799105748
Validation loss: 2.282658221964118

Epoch: 6| Step: 12
Training loss: 0.07191989652268926
Validation loss: 2.3113005447768473

Epoch: 6| Step: 13
Training loss: 0.08257780049295463
Validation loss: 2.2658266763454664

Epoch: 469| Step: 0
Training loss: 0.16343839899512427
Validation loss: 2.280830667287587

Epoch: 6| Step: 1
Training loss: 0.12263985329874975
Validation loss: 2.2618176070648435

Epoch: 6| Step: 2
Training loss: 0.08600344890908289
Validation loss: 2.2543789888599335

Epoch: 6| Step: 3
Training loss: 0.18835857631683317
Validation loss: 2.268043610408485

Epoch: 6| Step: 4
Training loss: 0.10048210006402224
Validation loss: 2.2184213617052375

Epoch: 6| Step: 5
Training loss: 0.13373161391197894
Validation loss: 2.2195066807955546

Epoch: 6| Step: 6
Training loss: 0.22258472967072843
Validation loss: 2.227541046048905

Epoch: 6| Step: 7
Training loss: 0.16968579719103563
Validation loss: 2.2936476643472012

Epoch: 6| Step: 8
Training loss: 0.11120091247394337
Validation loss: 2.3063998972020427

Epoch: 6| Step: 9
Training loss: 0.09777287195387323
Validation loss: 2.345563918657984

Epoch: 6| Step: 10
Training loss: 0.14443539972317532
Validation loss: 2.4048747061261433

Epoch: 6| Step: 11
Training loss: 0.168591117016346
Validation loss: 2.360517004738852

Epoch: 6| Step: 12
Training loss: 0.22783719942760894
Validation loss: 2.374388481647139

Epoch: 6| Step: 13
Training loss: 0.1123662696837496
Validation loss: 2.3766600350718012

Epoch: 470| Step: 0
Training loss: 0.11428373808860498
Validation loss: 2.3466169808699977

Epoch: 6| Step: 1
Training loss: 0.11358385938956161
Validation loss: 2.330358178169222

Epoch: 6| Step: 2
Training loss: 0.16774338751763374
Validation loss: 2.3344267134359384

Epoch: 6| Step: 3
Training loss: 0.07879716679240854
Validation loss: 2.2781747066674045

Epoch: 6| Step: 4
Training loss: 0.09998140795550299
Validation loss: 2.259468693771161

Epoch: 6| Step: 5
Training loss: 0.11757586816034873
Validation loss: 2.2525906580123327

Epoch: 6| Step: 6
Training loss: 0.1873768958644119
Validation loss: 2.2095704417395723

Epoch: 6| Step: 7
Training loss: 0.1570709595836487
Validation loss: 2.2116751442405427

Epoch: 6| Step: 8
Training loss: 0.17228842452499415
Validation loss: 2.2149094742960656

Epoch: 6| Step: 9
Training loss: 0.10581461392953777
Validation loss: 2.2462059594330746

Epoch: 6| Step: 10
Training loss: 0.06900185705878638
Validation loss: 2.236521612146645

Epoch: 6| Step: 11
Training loss: 0.17663070154807828
Validation loss: 2.240577092276897

Epoch: 6| Step: 12
Training loss: 0.11947686011336504
Validation loss: 2.2609035201468455

Epoch: 6| Step: 13
Training loss: 0.10087527169754706
Validation loss: 2.2606924102511723

Epoch: 471| Step: 0
Training loss: 0.18444943380318052
Validation loss: 2.293192902453318

Epoch: 6| Step: 1
Training loss: 0.1327799238195738
Validation loss: 2.3115133693432184

Epoch: 6| Step: 2
Training loss: 0.13982155879528263
Validation loss: 2.3305806386541885

Epoch: 6| Step: 3
Training loss: 0.16944098662592164
Validation loss: 2.31964135651768

Epoch: 6| Step: 4
Training loss: 0.11984188039830809
Validation loss: 2.28139472577639

Epoch: 6| Step: 5
Training loss: 0.10408834155154689
Validation loss: 2.290871868063103

Epoch: 6| Step: 6
Training loss: 0.07690026408929583
Validation loss: 2.2697042130635583

Epoch: 6| Step: 7
Training loss: 0.0921696338474864
Validation loss: 2.306874583178972

Epoch: 6| Step: 8
Training loss: 0.12560347824643037
Validation loss: 2.2939461319568326

Epoch: 6| Step: 9
Training loss: 0.09639611222584958
Validation loss: 2.2399864225133563

Epoch: 6| Step: 10
Training loss: 0.1593535708064152
Validation loss: 2.2410316433637822

Epoch: 6| Step: 11
Training loss: 0.15769245000532217
Validation loss: 2.266357994672278

Epoch: 6| Step: 12
Training loss: 0.10713472133213635
Validation loss: 2.2196278433621948

Epoch: 6| Step: 13
Training loss: 0.13866459464720568
Validation loss: 2.2361588583073324

Epoch: 472| Step: 0
Training loss: 0.09823264726005597
Validation loss: 2.2939257069149788

Epoch: 6| Step: 1
Training loss: 0.08743067766961174
Validation loss: 2.297959831115835

Epoch: 6| Step: 2
Training loss: 0.17067088645446915
Validation loss: 2.3187187297748952

Epoch: 6| Step: 3
Training loss: 0.11351943051679708
Validation loss: 2.346971789451761

Epoch: 6| Step: 4
Training loss: 0.1271234616713532
Validation loss: 2.336159032494077

Epoch: 6| Step: 5
Training loss: 0.12388921593523776
Validation loss: 2.3434674437916336

Epoch: 6| Step: 6
Training loss: 0.07711258187819135
Validation loss: 2.3447829203859065

Epoch: 6| Step: 7
Training loss: 0.08968295345013855
Validation loss: 2.3002767624179676

Epoch: 6| Step: 8
Training loss: 0.2208492335557323
Validation loss: 2.256133981543732

Epoch: 6| Step: 9
Training loss: 0.11023392356845009
Validation loss: 2.295718598631506

Epoch: 6| Step: 10
Training loss: 0.15584380877592954
Validation loss: 2.2643085783959034

Epoch: 6| Step: 11
Training loss: 0.10788311338966296
Validation loss: 2.23266655458097

Epoch: 6| Step: 12
Training loss: 0.1494717829295084
Validation loss: 2.2245595803757316

Epoch: 6| Step: 13
Training loss: 0.11080805284781821
Validation loss: 2.2213220063945966

Epoch: 473| Step: 0
Training loss: 0.14568501122098715
Validation loss: 2.238964753362785

Epoch: 6| Step: 1
Training loss: 0.14507210545949772
Validation loss: 2.249891893234857

Epoch: 6| Step: 2
Training loss: 0.10970532400179091
Validation loss: 2.2658441943202234

Epoch: 6| Step: 3
Training loss: 0.11247985695938995
Validation loss: 2.2621394586541816

Epoch: 6| Step: 4
Training loss: 0.0841047234213623
Validation loss: 2.3040807170985613

Epoch: 6| Step: 5
Training loss: 0.13530221482627675
Validation loss: 2.2911015075633316

Epoch: 6| Step: 6
Training loss: 0.0765654835800846
Validation loss: 2.293397450843329

Epoch: 6| Step: 7
Training loss: 0.10940058443021883
Validation loss: 2.339326816380743

Epoch: 6| Step: 8
Training loss: 0.15558140880517
Validation loss: 2.3214339342317927

Epoch: 6| Step: 9
Training loss: 0.17267190896740597
Validation loss: 2.3206231042044165

Epoch: 6| Step: 10
Training loss: 0.09331298337876355
Validation loss: 2.353606898470083

Epoch: 6| Step: 11
Training loss: 0.07286202953815486
Validation loss: 2.3784217580215214

Epoch: 6| Step: 12
Training loss: 0.17873725280459168
Validation loss: 2.3667490173437007

Epoch: 6| Step: 13
Training loss: 0.10965114457662196
Validation loss: 2.366273799850418

Epoch: 474| Step: 0
Training loss: 0.09996162102761115
Validation loss: 2.3729044505000085

Epoch: 6| Step: 1
Training loss: 0.09437329004961753
Validation loss: 2.358949180184955

Epoch: 6| Step: 2
Training loss: 0.10013481008854609
Validation loss: 2.3257061222452187

Epoch: 6| Step: 3
Training loss: 0.09515738587570623
Validation loss: 2.3349567741181634

Epoch: 6| Step: 4
Training loss: 0.1909130710451648
Validation loss: 2.297552126568594

Epoch: 6| Step: 5
Training loss: 0.0626900993093043
Validation loss: 2.253476334893203

Epoch: 6| Step: 6
Training loss: 0.15446523944964288
Validation loss: 2.2660486421414925

Epoch: 6| Step: 7
Training loss: 0.10280097934561616
Validation loss: 2.2421897615765274

Epoch: 6| Step: 8
Training loss: 0.10124048664440224
Validation loss: 2.2464828871760654

Epoch: 6| Step: 9
Training loss: 0.16049842219342203
Validation loss: 2.233903274174434

Epoch: 6| Step: 10
Training loss: 0.18533359114868542
Validation loss: 2.255801297808235

Epoch: 6| Step: 11
Training loss: 0.18612332394923203
Validation loss: 2.235769918247992

Epoch: 6| Step: 12
Training loss: 0.0857317803047422
Validation loss: 2.2782824154709553

Epoch: 6| Step: 13
Training loss: 0.11873378627288278
Validation loss: 2.2890576942799665

Epoch: 475| Step: 0
Training loss: 0.06333432400249127
Validation loss: 2.280383633431815

Epoch: 6| Step: 1
Training loss: 0.1477975035977791
Validation loss: 2.3174287618878995

Epoch: 6| Step: 2
Training loss: 0.10903128192198121
Validation loss: 2.2886680434791744

Epoch: 6| Step: 3
Training loss: 0.16067599072592365
Validation loss: 2.303465526304462

Epoch: 6| Step: 4
Training loss: 0.12284438562580519
Validation loss: 2.2769891412186136

Epoch: 6| Step: 5
Training loss: 0.12278568460403409
Validation loss: 2.284015959364599

Epoch: 6| Step: 6
Training loss: 0.11279876083100675
Validation loss: 2.248561388394743

Epoch: 6| Step: 7
Training loss: 0.08821268678994448
Validation loss: 2.3283463856169475

Epoch: 6| Step: 8
Training loss: 0.09626088320058306
Validation loss: 2.2881882153675646

Epoch: 6| Step: 9
Training loss: 0.18004181386145157
Validation loss: 2.291247427022408

Epoch: 6| Step: 10
Training loss: 0.18983434881472352
Validation loss: 2.3523427965781933

Epoch: 6| Step: 11
Training loss: 0.11673877955294136
Validation loss: 2.3647907721372023

Epoch: 6| Step: 12
Training loss: 0.19958720074717975
Validation loss: 2.343570854969912

Epoch: 6| Step: 13
Training loss: 0.044423822753899216
Validation loss: 2.398603581553839

Epoch: 476| Step: 0
Training loss: 0.11286613023719155
Validation loss: 2.3993101070138416

Epoch: 6| Step: 1
Training loss: 0.14631921994658217
Validation loss: 2.384502808839974

Epoch: 6| Step: 2
Training loss: 0.11090564874984271
Validation loss: 2.3541340028451683

Epoch: 6| Step: 3
Training loss: 0.13712382933239503
Validation loss: 2.3613765185752715

Epoch: 6| Step: 4
Training loss: 0.11900234405453868
Validation loss: 2.3449285266406594

Epoch: 6| Step: 5
Training loss: 0.11067426808834521
Validation loss: 2.310063750859334

Epoch: 6| Step: 6
Training loss: 0.14127083005536203
Validation loss: 2.2688729636866616

Epoch: 6| Step: 7
Training loss: 0.22122879217628458
Validation loss: 2.2627886014795298

Epoch: 6| Step: 8
Training loss: 0.13596913693039164
Validation loss: 2.2108967956068217

Epoch: 6| Step: 9
Training loss: 0.17634732967882616
Validation loss: 2.26084505432433

Epoch: 6| Step: 10
Training loss: 0.11575993609419474
Validation loss: 2.3091505294107275

Epoch: 6| Step: 11
Training loss: 0.1238106983088387
Validation loss: 2.3322776454984115

Epoch: 6| Step: 12
Training loss: 0.1021957462961523
Validation loss: 2.387853449746361

Epoch: 6| Step: 13
Training loss: 0.11046243684634563
Validation loss: 2.4050258542542284

Epoch: 477| Step: 0
Training loss: 0.1025747509566335
Validation loss: 2.3845082516584335

Epoch: 6| Step: 1
Training loss: 0.13587889888051133
Validation loss: 2.3442918661072456

Epoch: 6| Step: 2
Training loss: 0.08124500360165142
Validation loss: 2.3685286318444057

Epoch: 6| Step: 3
Training loss: 0.09079447758243198
Validation loss: 2.353018160819204

Epoch: 6| Step: 4
Training loss: 0.11028930291835119
Validation loss: 2.3490695059856948

Epoch: 6| Step: 5
Training loss: 0.10346839835136842
Validation loss: 2.3281179448502813

Epoch: 6| Step: 6
Training loss: 0.11628474768596599
Validation loss: 2.358745140728318

Epoch: 6| Step: 7
Training loss: 0.10047193195886835
Validation loss: 2.335301841350053

Epoch: 6| Step: 8
Training loss: 0.1692619333617336
Validation loss: 2.3592779461074853

Epoch: 6| Step: 9
Training loss: 0.11109550332511342
Validation loss: 2.3352330969939845

Epoch: 6| Step: 10
Training loss: 0.07893018642744731
Validation loss: 2.3091218408663843

Epoch: 6| Step: 11
Training loss: 0.18517886357698887
Validation loss: 2.355384598366163

Epoch: 6| Step: 12
Training loss: 0.11321357645896307
Validation loss: 2.3589194100433812

Epoch: 6| Step: 13
Training loss: 0.19615839884177935
Validation loss: 2.3457863682344597

Epoch: 478| Step: 0
Training loss: 0.11270111439280016
Validation loss: 2.373936272438796

Epoch: 6| Step: 1
Training loss: 0.09593502966437077
Validation loss: 2.374438652878761

Epoch: 6| Step: 2
Training loss: 0.18474777208012144
Validation loss: 2.3400030953402853

Epoch: 6| Step: 3
Training loss: 0.10826875472806205
Validation loss: 2.342347591402521

Epoch: 6| Step: 4
Training loss: 0.09850558015706833
Validation loss: 2.3190489794892595

Epoch: 6| Step: 5
Training loss: 0.15988201993945733
Validation loss: 2.2703274162080316

Epoch: 6| Step: 6
Training loss: 0.08813785642662199
Validation loss: 2.2837374941258735

Epoch: 6| Step: 7
Training loss: 0.14369574901784335
Validation loss: 2.259579933814445

Epoch: 6| Step: 8
Training loss: 0.18823812156983477
Validation loss: 2.26281182639832

Epoch: 6| Step: 9
Training loss: 0.0985838513611968
Validation loss: 2.27383169772413

Epoch: 6| Step: 10
Training loss: 0.14029808589541473
Validation loss: 2.2768525102968886

Epoch: 6| Step: 11
Training loss: 0.08906098602915473
Validation loss: 2.324569048964019

Epoch: 6| Step: 12
Training loss: 0.0799695302076244
Validation loss: 2.345929240303633

Epoch: 6| Step: 13
Training loss: 0.08844062062510111
Validation loss: 2.3363637326462503

Epoch: 479| Step: 0
Training loss: 0.17331818458741674
Validation loss: 2.3056845122568568

Epoch: 6| Step: 1
Training loss: 0.12305831855966204
Validation loss: 2.3350054057318403

Epoch: 6| Step: 2
Training loss: 0.15194801748561865
Validation loss: 2.35001815862192

Epoch: 6| Step: 3
Training loss: 0.08868180316010775
Validation loss: 2.3239957776086264

Epoch: 6| Step: 4
Training loss: 0.1706861212530502
Validation loss: 2.313585316587629

Epoch: 6| Step: 5
Training loss: 0.1371438502036447
Validation loss: 2.312970918056489

Epoch: 6| Step: 6
Training loss: 0.1389635671743277
Validation loss: 2.31455176607823

Epoch: 6| Step: 7
Training loss: 0.08433834047767999
Validation loss: 2.3264036166388604

Epoch: 6| Step: 8
Training loss: 0.1373863134949499
Validation loss: 2.3209043060012124

Epoch: 6| Step: 9
Training loss: 0.07061987818231963
Validation loss: 2.294531621206056

Epoch: 6| Step: 10
Training loss: 0.06773055228607643
Validation loss: 2.3285838900820046

Epoch: 6| Step: 11
Training loss: 0.06283201750665336
Validation loss: 2.276988506216235

Epoch: 6| Step: 12
Training loss: 0.11193007725743431
Validation loss: 2.309569618745136

Epoch: 6| Step: 13
Training loss: 0.05523281820590687
Validation loss: 2.2929596809657453

Epoch: 480| Step: 0
Training loss: 0.10619347204598908
Validation loss: 2.3196292010716117

Epoch: 6| Step: 1
Training loss: 0.13437349518221664
Validation loss: 2.278072392231993

Epoch: 6| Step: 2
Training loss: 0.06536350176525585
Validation loss: 2.251227590301531

Epoch: 6| Step: 3
Training loss: 0.100334273935731
Validation loss: 2.279815916444432

Epoch: 6| Step: 4
Training loss: 0.08392054882610411
Validation loss: 2.26491683851481

Epoch: 6| Step: 5
Training loss: 0.1116138814696998
Validation loss: 2.2476750020799434

Epoch: 6| Step: 6
Training loss: 0.07511311534411155
Validation loss: 2.259877974633213

Epoch: 6| Step: 7
Training loss: 0.09319044555310868
Validation loss: 2.295916328715166

Epoch: 6| Step: 8
Training loss: 0.085018702852861
Validation loss: 2.285003772013631

Epoch: 6| Step: 9
Training loss: 0.16533429076109177
Validation loss: 2.2972491474920287

Epoch: 6| Step: 10
Training loss: 0.08920801221696792
Validation loss: 2.2984250628090535

Epoch: 6| Step: 11
Training loss: 0.11756869148355145
Validation loss: 2.251971821560212

Epoch: 6| Step: 12
Training loss: 0.21537918647111237
Validation loss: 2.2795166761080035

Epoch: 6| Step: 13
Training loss: 0.08111989029969678
Validation loss: 2.2852562829787986

Epoch: 481| Step: 0
Training loss: 0.07581616757367254
Validation loss: 2.2854124441835197

Epoch: 6| Step: 1
Training loss: 0.06419256674897299
Validation loss: 2.3007731917452032

Epoch: 6| Step: 2
Training loss: 0.08810105564106602
Validation loss: 2.314858772061002

Epoch: 6| Step: 3
Training loss: 0.055751973718615
Validation loss: 2.2966046821956962

Epoch: 6| Step: 4
Training loss: 0.05847314104073803
Validation loss: 2.3094618655398955

Epoch: 6| Step: 5
Training loss: 0.171619566848438
Validation loss: 2.3393736596525128

Epoch: 6| Step: 6
Training loss: 0.0769714849131738
Validation loss: 2.32242257118382

Epoch: 6| Step: 7
Training loss: 0.0810203996776116
Validation loss: 2.326442489614666

Epoch: 6| Step: 8
Training loss: 0.0836708404127996
Validation loss: 2.316926771353029

Epoch: 6| Step: 9
Training loss: 0.11734229831076969
Validation loss: 2.314865647235256

Epoch: 6| Step: 10
Training loss: 0.13934082884634258
Validation loss: 2.3333766568098206

Epoch: 6| Step: 11
Training loss: 0.16570009652355377
Validation loss: 2.3288480009455843

Epoch: 6| Step: 12
Training loss: 0.12896433157546883
Validation loss: 2.32232749501424

Epoch: 6| Step: 13
Training loss: 0.05742681094448453
Validation loss: 2.303555512072643

Epoch: 482| Step: 0
Training loss: 0.09873743457161792
Validation loss: 2.323008068980609

Epoch: 6| Step: 1
Training loss: 0.06436502330747158
Validation loss: 2.3169066833393863

Epoch: 6| Step: 2
Training loss: 0.0992920674121385
Validation loss: 2.327321208562745

Epoch: 6| Step: 3
Training loss: 0.08233911214395156
Validation loss: 2.30161904084422

Epoch: 6| Step: 4
Training loss: 0.09142938060394441
Validation loss: 2.330657414147484

Epoch: 6| Step: 5
Training loss: 0.09570764998034388
Validation loss: 2.323185810257038

Epoch: 6| Step: 6
Training loss: 0.18226810484702238
Validation loss: 2.326995620273821

Epoch: 6| Step: 7
Training loss: 0.07843249128315302
Validation loss: 2.326716485117611

Epoch: 6| Step: 8
Training loss: 0.182438349745687
Validation loss: 2.336507431052128

Epoch: 6| Step: 9
Training loss: 0.1448714273874595
Validation loss: 2.357604225776152

Epoch: 6| Step: 10
Training loss: 0.06286319614329497
Validation loss: 2.3534231203220397

Epoch: 6| Step: 11
Training loss: 0.07858046444982879
Validation loss: 2.3650904437793128

Epoch: 6| Step: 12
Training loss: 0.09578603928557475
Validation loss: 2.3539487770762304

Epoch: 6| Step: 13
Training loss: 0.06397595927794558
Validation loss: 2.354970965764146

Epoch: 483| Step: 0
Training loss: 0.08572795636855023
Validation loss: 2.3459334836573595

Epoch: 6| Step: 1
Training loss: 0.16508317391743954
Validation loss: 2.311023907325005

Epoch: 6| Step: 2
Training loss: 0.09389893304941788
Validation loss: 2.2969488115737393

Epoch: 6| Step: 3
Training loss: 0.07522491392618467
Validation loss: 2.2915164709979643

Epoch: 6| Step: 4
Training loss: 0.1609330239182747
Validation loss: 2.256348691319253

Epoch: 6| Step: 5
Training loss: 0.1025512233970601
Validation loss: 2.2827311163644666

Epoch: 6| Step: 6
Training loss: 0.08048698961609607
Validation loss: 2.295874758384766

Epoch: 6| Step: 7
Training loss: 0.07996635661842413
Validation loss: 2.288279963138515

Epoch: 6| Step: 8
Training loss: 0.08220734315007759
Validation loss: 2.293817904216262

Epoch: 6| Step: 9
Training loss: 0.10080744602497371
Validation loss: 2.300758541516093

Epoch: 6| Step: 10
Training loss: 0.1294846059268454
Validation loss: 2.295641587682022

Epoch: 6| Step: 11
Training loss: 0.12066529215009848
Validation loss: 2.3218293579316462

Epoch: 6| Step: 12
Training loss: 0.0825075135142072
Validation loss: 2.3266912905893875

Epoch: 6| Step: 13
Training loss: 0.20046399392591008
Validation loss: 2.3456662226290104

Epoch: 484| Step: 0
Training loss: 0.10527479032875167
Validation loss: 2.383612462057019

Epoch: 6| Step: 1
Training loss: 0.10107746671903663
Validation loss: 2.3708896495397047

Epoch: 6| Step: 2
Training loss: 0.10588150145082749
Validation loss: 2.361284852758429

Epoch: 6| Step: 3
Training loss: 0.06945996541514471
Validation loss: 2.342128657735454

Epoch: 6| Step: 4
Training loss: 0.12033440557687457
Validation loss: 2.339562365688776

Epoch: 6| Step: 5
Training loss: 0.13431132493496925
Validation loss: 2.341888910618534

Epoch: 6| Step: 6
Training loss: 0.09185861986462752
Validation loss: 2.3173944232803767

Epoch: 6| Step: 7
Training loss: 0.08567793617674355
Validation loss: 2.322985598744654

Epoch: 6| Step: 8
Training loss: 0.1605165893873284
Validation loss: 2.305304966924496

Epoch: 6| Step: 9
Training loss: 0.16980465320545568
Validation loss: 2.316003089489956

Epoch: 6| Step: 10
Training loss: 0.10122791527735303
Validation loss: 2.3075638347594314

Epoch: 6| Step: 11
Training loss: 0.07722564648483905
Validation loss: 2.3229715642553903

Epoch: 6| Step: 12
Training loss: 0.1818792047866636
Validation loss: 2.3102977191418397

Epoch: 6| Step: 13
Training loss: 0.07590166177836394
Validation loss: 2.343157901695009

Epoch: 485| Step: 0
Training loss: 0.09755077865350678
Validation loss: 2.3311388607222954

Epoch: 6| Step: 1
Training loss: 0.11437156915730355
Validation loss: 2.36619701041725

Epoch: 6| Step: 2
Training loss: 0.11665211209623323
Validation loss: 2.316518944658905

Epoch: 6| Step: 3
Training loss: 0.2230439324527257
Validation loss: 2.316950940416951

Epoch: 6| Step: 4
Training loss: 0.07366354854815897
Validation loss: 2.3338834246720483

Epoch: 6| Step: 5
Training loss: 0.11017602699034629
Validation loss: 2.338770334880776

Epoch: 6| Step: 6
Training loss: 0.088512946010024
Validation loss: 2.332806910917419

Epoch: 6| Step: 7
Training loss: 0.06939770405433413
Validation loss: 2.2820051839369366

Epoch: 6| Step: 8
Training loss: 0.15615722166724413
Validation loss: 2.285676071744641

Epoch: 6| Step: 9
Training loss: 0.06860356313900642
Validation loss: 2.271815810446898

Epoch: 6| Step: 10
Training loss: 0.10663560167295766
Validation loss: 2.263669567501058

Epoch: 6| Step: 11
Training loss: 0.07267465050793398
Validation loss: 2.270661086652501

Epoch: 6| Step: 12
Training loss: 0.08469970596687766
Validation loss: 2.292420250127515

Epoch: 6| Step: 13
Training loss: 0.0904460290763617
Validation loss: 2.2927519855543426

Epoch: 486| Step: 0
Training loss: 0.09322437317564075
Validation loss: 2.2646755765257818

Epoch: 6| Step: 1
Training loss: 0.11442122226348148
Validation loss: 2.300394824239702

Epoch: 6| Step: 2
Training loss: 0.062187003410455674
Validation loss: 2.3067156400122357

Epoch: 6| Step: 3
Training loss: 0.15279828024936842
Validation loss: 2.3156988440281743

Epoch: 6| Step: 4
Training loss: 0.07643068800396813
Validation loss: 2.3284806478636524

Epoch: 6| Step: 5
Training loss: 0.05592326831654011
Validation loss: 2.3098931844869783

Epoch: 6| Step: 6
Training loss: 0.09392175240223875
Validation loss: 2.2964277492626644

Epoch: 6| Step: 7
Training loss: 0.12142954306491728
Validation loss: 2.3044447426008907

Epoch: 6| Step: 8
Training loss: 0.1727006652285504
Validation loss: 2.3143377626058332

Epoch: 6| Step: 9
Training loss: 0.07343059783823386
Validation loss: 2.3176278052743458

Epoch: 6| Step: 10
Training loss: 0.09318374449878238
Validation loss: 2.293803917308496

Epoch: 6| Step: 11
Training loss: 0.056742761044424696
Validation loss: 2.270096442457128

Epoch: 6| Step: 12
Training loss: 0.13238191226665522
Validation loss: 2.242167535599866

Epoch: 6| Step: 13
Training loss: 0.1907553504622172
Validation loss: 2.2352309724012756

Epoch: 487| Step: 0
Training loss: 0.0913901449345127
Validation loss: 2.2322988274808035

Epoch: 6| Step: 1
Training loss: 0.166629358054702
Validation loss: 2.2532489886259084

Epoch: 6| Step: 2
Training loss: 0.14781617959465007
Validation loss: 2.266552388418786

Epoch: 6| Step: 3
Training loss: 0.052507282416164355
Validation loss: 2.32435561097985

Epoch: 6| Step: 4
Training loss: 0.09826148357450412
Validation loss: 2.3498113149543345

Epoch: 6| Step: 5
Training loss: 0.08179976521972164
Validation loss: 2.347510394672548

Epoch: 6| Step: 6
Training loss: 0.12125151493782743
Validation loss: 2.364130821873095

Epoch: 6| Step: 7
Training loss: 0.17756780217615176
Validation loss: 2.3625524213498057

Epoch: 6| Step: 8
Training loss: 0.16148833155110465
Validation loss: 2.3062666060398445

Epoch: 6| Step: 9
Training loss: 0.12145319397444775
Validation loss: 2.2633510936603436

Epoch: 6| Step: 10
Training loss: 0.12370333325087969
Validation loss: 2.191464611246805

Epoch: 6| Step: 11
Training loss: 0.162263561367895
Validation loss: 2.189158478071739

Epoch: 6| Step: 12
Training loss: 0.1392221145565829
Validation loss: 2.1705626722668456

Epoch: 6| Step: 13
Training loss: 0.18074639995836161
Validation loss: 2.151482347428287

Epoch: 488| Step: 0
Training loss: 0.10867783477999592
Validation loss: 2.1792917299893015

Epoch: 6| Step: 1
Training loss: 0.12138986146131657
Validation loss: 2.2184577338061873

Epoch: 6| Step: 2
Training loss: 0.15355214128734052
Validation loss: 2.2550804202132815

Epoch: 6| Step: 3
Training loss: 0.08720674151621294
Validation loss: 2.290555523140758

Epoch: 6| Step: 4
Training loss: 0.09682735571279436
Validation loss: 2.329713925441015

Epoch: 6| Step: 5
Training loss: 0.17318022995195828
Validation loss: 2.3570923792507243

Epoch: 6| Step: 6
Training loss: 0.15556267723695644
Validation loss: 2.401187394659554

Epoch: 6| Step: 7
Training loss: 0.14728868288806568
Validation loss: 2.327730594561158

Epoch: 6| Step: 8
Training loss: 0.11856550406142692
Validation loss: 2.332112296256745

Epoch: 6| Step: 9
Training loss: 0.0930568882337117
Validation loss: 2.2643318601843005

Epoch: 6| Step: 10
Training loss: 0.1176640912339548
Validation loss: 2.238765602941707

Epoch: 6| Step: 11
Training loss: 0.0484588871930643
Validation loss: 2.2293658561906207

Epoch: 6| Step: 12
Training loss: 0.16736639492037955
Validation loss: 2.2129975678912306

Epoch: 6| Step: 13
Training loss: 0.20675528325303744
Validation loss: 2.2089413041843393

Epoch: 489| Step: 0
Training loss: 0.10156019831763595
Validation loss: 2.182088837559194

Epoch: 6| Step: 1
Training loss: 0.17800509616703805
Validation loss: 2.206698278076097

Epoch: 6| Step: 2
Training loss: 0.10592038096460157
Validation loss: 2.22515777391679

Epoch: 6| Step: 3
Training loss: 0.1052888510395442
Validation loss: 2.207604129602101

Epoch: 6| Step: 4
Training loss: 0.0922445278450774
Validation loss: 2.246778451530235

Epoch: 6| Step: 5
Training loss: 0.06694174583043075
Validation loss: 2.2610237013814944

Epoch: 6| Step: 6
Training loss: 0.1666399659932014
Validation loss: 2.2753808656634873

Epoch: 6| Step: 7
Training loss: 0.12073583931156497
Validation loss: 2.2771419791137006

Epoch: 6| Step: 8
Training loss: 0.0735524156030154
Validation loss: 2.3038881634650137

Epoch: 6| Step: 9
Training loss: 0.07960491681273783
Validation loss: 2.286722090696503

Epoch: 6| Step: 10
Training loss: 0.060327980224111594
Validation loss: 2.3019733680167502

Epoch: 6| Step: 11
Training loss: 0.08788425369481526
Validation loss: 2.292906888892595

Epoch: 6| Step: 12
Training loss: 0.09193791045636031
Validation loss: 2.313617963202725

Epoch: 6| Step: 13
Training loss: 0.18711405013580995
Validation loss: 2.2816872463569964

Epoch: 490| Step: 0
Training loss: 0.08049635587223722
Validation loss: 2.298275296727332

Epoch: 6| Step: 1
Training loss: 0.10452383221763387
Validation loss: 2.2444602627079866

Epoch: 6| Step: 2
Training loss: 0.17788272995950855
Validation loss: 2.266779434688265

Epoch: 6| Step: 3
Training loss: 0.09010512231125227
Validation loss: 2.2536689828341574

Epoch: 6| Step: 4
Training loss: 0.0956501376156657
Validation loss: 2.2534154618980264

Epoch: 6| Step: 5
Training loss: 0.15630402822999453
Validation loss: 2.2104519871494333

Epoch: 6| Step: 6
Training loss: 0.1006922807840119
Validation loss: 2.221695597692056

Epoch: 6| Step: 7
Training loss: 0.10793737784485347
Validation loss: 2.225362873432654

Epoch: 6| Step: 8
Training loss: 0.08937479029144013
Validation loss: 2.2183325647954186

Epoch: 6| Step: 9
Training loss: 0.05880484305830371
Validation loss: 2.2425798625441216

Epoch: 6| Step: 10
Training loss: 0.0910326976480953
Validation loss: 2.2608389594409313

Epoch: 6| Step: 11
Training loss: 0.1321385619025125
Validation loss: 2.225028825319455

Epoch: 6| Step: 12
Training loss: 0.14469544646355426
Validation loss: 2.2526679383786554

Epoch: 6| Step: 13
Training loss: 0.22586505515926844
Validation loss: 2.2413496301571474

Epoch: 491| Step: 0
Training loss: 0.08837508093211072
Validation loss: 2.2653560355721973

Epoch: 6| Step: 1
Training loss: 0.11375640826199862
Validation loss: 2.3525449601303303

Epoch: 6| Step: 2
Training loss: 0.06897370656100595
Validation loss: 2.350164462635537

Epoch: 6| Step: 3
Training loss: 0.19604879829118216
Validation loss: 2.3524926579205334

Epoch: 6| Step: 4
Training loss: 0.14501599907988652
Validation loss: 2.327702302970625

Epoch: 6| Step: 5
Training loss: 0.1298755772805441
Validation loss: 2.309748444092742

Epoch: 6| Step: 6
Training loss: 0.15483187623214362
Validation loss: 2.268779091538474

Epoch: 6| Step: 7
Training loss: 0.24153254763718202
Validation loss: 2.2477486032834664

Epoch: 6| Step: 8
Training loss: 0.09478690005289515
Validation loss: 2.2682178544549494

Epoch: 6| Step: 9
Training loss: 0.1365588615639858
Validation loss: 2.2597608375234484

Epoch: 6| Step: 10
Training loss: 0.23951824572225178
Validation loss: 2.2337428256444927

Epoch: 6| Step: 11
Training loss: 0.2076947717693666
Validation loss: 2.2437729085643454

Epoch: 6| Step: 12
Training loss: 0.14343368205223064
Validation loss: 2.3088674797180846

Epoch: 6| Step: 13
Training loss: 0.09777997285777514
Validation loss: 2.3448889821750454

Epoch: 492| Step: 0
Training loss: 0.16434865360557155
Validation loss: 2.396456423858037

Epoch: 6| Step: 1
Training loss: 0.2359956183440978
Validation loss: 2.407098311372651

Epoch: 6| Step: 2
Training loss: 0.09162965721911896
Validation loss: 2.367796682606579

Epoch: 6| Step: 3
Training loss: 0.23083158800231912
Validation loss: 2.3573983853929024

Epoch: 6| Step: 4
Training loss: 0.11358813121074954
Validation loss: 2.3020673576902766

Epoch: 6| Step: 5
Training loss: 0.09835179586804789
Validation loss: 2.259724211857749

Epoch: 6| Step: 6
Training loss: 0.12507578668308836
Validation loss: 2.207080438827852

Epoch: 6| Step: 7
Training loss: 0.18382109100463584
Validation loss: 2.157726090536887

Epoch: 6| Step: 8
Training loss: 0.16239260439591802
Validation loss: 2.1900570481397934

Epoch: 6| Step: 9
Training loss: 0.09873150618373164
Validation loss: 2.2020485542858683

Epoch: 6| Step: 10
Training loss: 0.1178491865973731
Validation loss: 2.2004282561563975

Epoch: 6| Step: 11
Training loss: 0.1120191260684775
Validation loss: 2.196261739105141

Epoch: 6| Step: 12
Training loss: 0.11210279146329391
Validation loss: 2.2169715773838328

Epoch: 6| Step: 13
Training loss: 0.22505348086539337
Validation loss: 2.2483743471300928

Epoch: 493| Step: 0
Training loss: 0.13136629589230828
Validation loss: 2.269066215518975

Epoch: 6| Step: 1
Training loss: 0.12274646797192328
Validation loss: 2.292055402060916

Epoch: 6| Step: 2
Training loss: 0.1590424864943317
Validation loss: 2.309792759523709

Epoch: 6| Step: 3
Training loss: 0.11497544033510966
Validation loss: 2.3012962044288665

Epoch: 6| Step: 4
Training loss: 0.17850090149777362
Validation loss: 2.3057767296010594

Epoch: 6| Step: 5
Training loss: 0.10537366201047942
Validation loss: 2.2874712765546334

Epoch: 6| Step: 6
Training loss: 0.15205948546871328
Validation loss: 2.2809102289593928

Epoch: 6| Step: 7
Training loss: 0.08450812769207995
Validation loss: 2.2963103297233287

Epoch: 6| Step: 8
Training loss: 0.07520381767921686
Validation loss: 2.2975525840522537

Epoch: 6| Step: 9
Training loss: 0.0688020270898682
Validation loss: 2.321630173436778

Epoch: 6| Step: 10
Training loss: 0.11026337568570849
Validation loss: 2.3183311968459215

Epoch: 6| Step: 11
Training loss: 0.16364743885630295
Validation loss: 2.32032830398794

Epoch: 6| Step: 12
Training loss: 0.09194422117245704
Validation loss: 2.332519735680073

Epoch: 6| Step: 13
Training loss: 0.11813988319999576
Validation loss: 2.3070160379324247

Epoch: 494| Step: 0
Training loss: 0.11466309000512415
Validation loss: 2.3438748638841735

Epoch: 6| Step: 1
Training loss: 0.14681835883221087
Validation loss: 2.342310841383422

Epoch: 6| Step: 2
Training loss: 0.1077986697987396
Validation loss: 2.3294810527287364

Epoch: 6| Step: 3
Training loss: 0.1388882372926951
Validation loss: 2.3030240103419075

Epoch: 6| Step: 4
Training loss: 0.11856638380922713
Validation loss: 2.2813234248575287

Epoch: 6| Step: 5
Training loss: 0.07901236426365633
Validation loss: 2.292039174393908

Epoch: 6| Step: 6
Training loss: 0.14715736923067574
Validation loss: 2.2868105728024304

Epoch: 6| Step: 7
Training loss: 0.07065717668866227
Validation loss: 2.3156631426840075

Epoch: 6| Step: 8
Training loss: 0.07658074451096177
Validation loss: 2.262221320890183

Epoch: 6| Step: 9
Training loss: 0.1134513531520117
Validation loss: 2.256750159555871

Epoch: 6| Step: 10
Training loss: 0.1155876305479672
Validation loss: 2.217629877430876

Epoch: 6| Step: 11
Training loss: 0.22296569469259248
Validation loss: 2.2627320906123223

Epoch: 6| Step: 12
Training loss: 0.1930867980777332
Validation loss: 2.2636764899908277

Epoch: 6| Step: 13
Training loss: 0.16734410732028115
Validation loss: 2.2723988396390933

Epoch: 495| Step: 0
Training loss: 0.1172483762931641
Validation loss: 2.313366016904015

Epoch: 6| Step: 1
Training loss: 0.11697440641160464
Validation loss: 2.320788431936363

Epoch: 6| Step: 2
Training loss: 0.09044415500332184
Validation loss: 2.3156047123842347

Epoch: 6| Step: 3
Training loss: 0.08247025841456972
Validation loss: 2.3321619638734217

Epoch: 6| Step: 4
Training loss: 0.10185313821030058
Validation loss: 2.3277588065117656

Epoch: 6| Step: 5
Training loss: 0.30866385520687295
Validation loss: 2.336993698187233

Epoch: 6| Step: 6
Training loss: 0.10797041940709602
Validation loss: 2.33474575603468

Epoch: 6| Step: 7
Training loss: 0.0840693974944532
Validation loss: 2.294364991425014

Epoch: 6| Step: 8
Training loss: 0.09502914121358486
Validation loss: 2.2989491828739212

Epoch: 6| Step: 9
Training loss: 0.17564539958035497
Validation loss: 2.3290901162990676

Epoch: 6| Step: 10
Training loss: 0.1855464935298813
Validation loss: 2.278661679167374

Epoch: 6| Step: 11
Training loss: 0.11132451938345077
Validation loss: 2.294151335910794

Epoch: 6| Step: 12
Training loss: 0.14993670936334674
Validation loss: 2.300302433489319

Epoch: 6| Step: 13
Training loss: 0.13782808652522008
Validation loss: 2.2938426682577138

Epoch: 496| Step: 0
Training loss: 0.238599252343825
Validation loss: 2.3149773247039143

Epoch: 6| Step: 1
Training loss: 0.14271714996566934
Validation loss: 2.2600168421106215

Epoch: 6| Step: 2
Training loss: 0.1368221164685294
Validation loss: 2.2408217788914166

Epoch: 6| Step: 3
Training loss: 0.1119543956556705
Validation loss: 2.243201069406472

Epoch: 6| Step: 4
Training loss: 0.17864791092253055
Validation loss: 2.1941500625918997

Epoch: 6| Step: 5
Training loss: 0.14944086270794746
Validation loss: 2.2640043533671346

Epoch: 6| Step: 6
Training loss: 0.17124184030389475
Validation loss: 2.2847024300619556

Epoch: 6| Step: 7
Training loss: 0.10922306014766978
Validation loss: 2.369790898949139

Epoch: 6| Step: 8
Training loss: 0.19720529823565605
Validation loss: 2.3904140035335915

Epoch: 6| Step: 9
Training loss: 0.1452873018423418
Validation loss: 2.4106968617605813

Epoch: 6| Step: 10
Training loss: 0.20254372910482307
Validation loss: 2.4558600175752385

Epoch: 6| Step: 11
Training loss: 0.12528700215976155
Validation loss: 2.3951974660744066

Epoch: 6| Step: 12
Training loss: 0.2260573609495435
Validation loss: 2.377685401721184

Epoch: 6| Step: 13
Training loss: 0.07786380796407924
Validation loss: 2.3516032148259787

Epoch: 497| Step: 0
Training loss: 0.14359847847601004
Validation loss: 2.3168788399397267

Epoch: 6| Step: 1
Training loss: 0.1367864985863263
Validation loss: 2.3361631822109064

Epoch: 6| Step: 2
Training loss: 0.16718504181953164
Validation loss: 2.3047605953092853

Epoch: 6| Step: 3
Training loss: 0.15057619214220144
Validation loss: 2.319684990049089

Epoch: 6| Step: 4
Training loss: 0.3064114388391756
Validation loss: 2.299428218741259

Epoch: 6| Step: 5
Training loss: 0.12593017137942014
Validation loss: 2.3589772421090904

Epoch: 6| Step: 6
Training loss: 0.18109359199773759
Validation loss: 2.386137153939901

Epoch: 6| Step: 7
Training loss: 0.17691967334302203
Validation loss: 2.418849994343116

Epoch: 6| Step: 8
Training loss: 0.14099682553163906
Validation loss: 2.391950468935896

Epoch: 6| Step: 9
Training loss: 0.21528716712048387
Validation loss: 2.3915771715741063

Epoch: 6| Step: 10
Training loss: 0.18801763726438922
Validation loss: 2.333427702699132

Epoch: 6| Step: 11
Training loss: 0.21757141287841567
Validation loss: 2.281508425061905

Epoch: 6| Step: 12
Training loss: 0.174834339461312
Validation loss: 2.239899651371602

Epoch: 6| Step: 13
Training loss: 0.13026543239493704
Validation loss: 2.185484210238593

Epoch: 498| Step: 0
Training loss: 0.15381912316505725
Validation loss: 2.1866570561104886

Epoch: 6| Step: 1
Training loss: 0.24011186251577787
Validation loss: 2.1670358838623467

Epoch: 6| Step: 2
Training loss: 0.16812818190956438
Validation loss: 2.1519346732634945

Epoch: 6| Step: 3
Training loss: 0.16536157460116335
Validation loss: 2.216337170824318

Epoch: 6| Step: 4
Training loss: 0.2095834754585659
Validation loss: 2.3016259530606655

Epoch: 6| Step: 5
Training loss: 0.19682300123132318
Validation loss: 2.3657850423149114

Epoch: 6| Step: 6
Training loss: 0.13468982804049942
Validation loss: 2.4105222874174377

Epoch: 6| Step: 7
Training loss: 0.17532290997256902
Validation loss: 2.4141601814599385

Epoch: 6| Step: 8
Training loss: 0.11633548553806303
Validation loss: 2.3674965906463528

Epoch: 6| Step: 9
Training loss: 0.18122751162221623
Validation loss: 2.35116589448109

Epoch: 6| Step: 10
Training loss: 0.10393085511082265
Validation loss: 2.264159782034732

Epoch: 6| Step: 11
Training loss: 0.16565779100459455
Validation loss: 2.2220703162380437

Epoch: 6| Step: 12
Training loss: 0.20825746267349232
Validation loss: 2.188735026422323

Epoch: 6| Step: 13
Training loss: 0.19383736494213005
Validation loss: 2.1469517951080634

Epoch: 499| Step: 0
Training loss: 0.201336469259008
Validation loss: 2.1460483479939625

Epoch: 6| Step: 1
Training loss: 0.16685256921552272
Validation loss: 2.167477521865321

Epoch: 6| Step: 2
Training loss: 0.14718482079871822
Validation loss: 2.183671095988697

Epoch: 6| Step: 3
Training loss: 0.1632885388294341
Validation loss: 2.3111017351647907

Epoch: 6| Step: 4
Training loss: 0.1039204195227797
Validation loss: 2.3825900571949927

Epoch: 6| Step: 5
Training loss: 0.341325773098754
Validation loss: 2.419876354709443

Epoch: 6| Step: 6
Training loss: 0.19705366323289789
Validation loss: 2.350379950397789

Epoch: 6| Step: 7
Training loss: 0.12654742928244725
Validation loss: 2.3150905144239315

Epoch: 6| Step: 8
Training loss: 0.22781848532005228
Validation loss: 2.2208341371061935

Epoch: 6| Step: 9
Training loss: 0.12327792409754626
Validation loss: 2.199875982439635

Epoch: 6| Step: 10
Training loss: 0.16695697033835669
Validation loss: 2.1561753240907686

Epoch: 6| Step: 11
Training loss: 0.1862719373136617
Validation loss: 2.177395617808762

Epoch: 6| Step: 12
Training loss: 0.25215749805579823
Validation loss: 2.2190681049234846

Epoch: 6| Step: 13
Training loss: 0.15547506568770517
Validation loss: 2.2661915671479576

Epoch: 500| Step: 0
Training loss: 0.14349659892780295
Validation loss: 2.363129156756525

Epoch: 6| Step: 1
Training loss: 0.2542109495160792
Validation loss: 2.426136353017204

Epoch: 6| Step: 2
Training loss: 0.1849144044244622
Validation loss: 2.4770099720483723

Epoch: 6| Step: 3
Training loss: 0.32073407227119105
Validation loss: 2.479238492718538

Epoch: 6| Step: 4
Training loss: 0.22603456878651693
Validation loss: 2.3808349607046457

Epoch: 6| Step: 5
Training loss: 0.1356820446676615
Validation loss: 2.2163903194664663

Epoch: 6| Step: 6
Training loss: 0.3806899647636831
Validation loss: 2.12896941024416

Epoch: 6| Step: 7
Training loss: 0.40964996334696413
Validation loss: 2.1595036227059468

Epoch: 6| Step: 8
Training loss: 0.2914928389449934
Validation loss: 2.1979669177254606

Epoch: 6| Step: 9
Training loss: 0.39606698150772074
Validation loss: 2.2723805993956003

Epoch: 6| Step: 10
Training loss: 0.548614541846492
Validation loss: 2.3644454151122867

Epoch: 6| Step: 11
Training loss: 0.19431764909578966
Validation loss: 2.3355359925797288

Epoch: 6| Step: 12
Training loss: 0.18294464169133415
Validation loss: 2.3043601338719566

Epoch: 6| Step: 13
Training loss: 0.2703021675957573
Validation loss: 2.336349600759533

Epoch: 501| Step: 0
Training loss: 0.4040867356114969
Validation loss: 2.389430862102537

Epoch: 6| Step: 1
Training loss: 0.21049778636756092
Validation loss: 2.354606794907617

Epoch: 6| Step: 2
Training loss: 0.32388996780772705
Validation loss: 2.3512372074105308

Epoch: 6| Step: 3
Training loss: 0.17069382544005998
Validation loss: 2.303271759224303

Epoch: 6| Step: 4
Training loss: 0.20115316174329062
Validation loss: 2.2430655473927876

Epoch: 6| Step: 5
Training loss: 0.24232095456225078
Validation loss: 2.2386669377914696

Epoch: 6| Step: 6
Training loss: 0.3416827965142799
Validation loss: 2.195728122379092

Epoch: 6| Step: 7
Training loss: 0.35937070843995184
Validation loss: 2.2352026191067447

Epoch: 6| Step: 8
Training loss: 0.37423331644461905
Validation loss: 2.2517255509373157

Epoch: 6| Step: 9
Training loss: 0.22188148052529935
Validation loss: 2.380722678211362

Epoch: 6| Step: 10
Training loss: 0.3754955038063088
Validation loss: 2.415276951724958

Epoch: 6| Step: 11
Training loss: 0.5508550229277335
Validation loss: 2.4129092920738007

Epoch: 6| Step: 12
Training loss: 0.4085541999595878
Validation loss: 2.3503871017880367

Epoch: 6| Step: 13
Training loss: 0.5010301289911981
Validation loss: 2.3011051591155294

Epoch: 502| Step: 0
Training loss: 0.37230804938140377
Validation loss: 2.4319003815163067

Epoch: 6| Step: 1
Training loss: 0.35571347709822104
Validation loss: 2.5028319183111294

Epoch: 6| Step: 2
Training loss: 0.5353296096570511
Validation loss: 2.5392224767375304

Epoch: 6| Step: 3
Training loss: 0.4981372377287585
Validation loss: 2.4161897825447687

Epoch: 6| Step: 4
Training loss: 0.36812000365177777
Validation loss: 2.2396836273866763

Epoch: 6| Step: 5
Training loss: 0.73355226897104
Validation loss: 2.171751900447575

Epoch: 6| Step: 6
Training loss: 0.6875142182700561
Validation loss: 2.1852553774557415

Epoch: 6| Step: 7
Training loss: 1.0310824286979157
Validation loss: 2.2922390708633316

Epoch: 6| Step: 8
Training loss: 1.4298919364805884
Validation loss: 2.532870462795427

Epoch: 6| Step: 9
Training loss: 0.497018882623982
Validation loss: 2.236066808074639

Epoch: 6| Step: 10
Training loss: 0.8425304641649223
Validation loss: 2.207853280948867

Epoch: 6| Step: 11
Training loss: 1.268296518697986
Validation loss: 2.2337149211493084

Epoch: 6| Step: 12
Training loss: 0.7091477891476694
Validation loss: 2.1952614732876614

Epoch: 6| Step: 13
Training loss: 0.5567753411286889
Validation loss: 2.3072903548230244

Epoch: 503| Step: 0
Training loss: 0.49971321941552677
Validation loss: 2.296500787086306

Epoch: 6| Step: 1
Training loss: 0.6945356036329753
Validation loss: 2.357346743321259

Epoch: 6| Step: 2
Training loss: 1.2424936936830557
Validation loss: 2.3826498071896127

Epoch: 6| Step: 3
Training loss: 1.1661747962770426
Validation loss: 2.3155167216433097

Epoch: 6| Step: 4
Training loss: 1.3267121822530215
Validation loss: 2.181412554839281

Epoch: 6| Step: 5
Training loss: 1.079696505077034
Validation loss: 2.1014435296784866

Epoch: 6| Step: 6
Training loss: 0.5749027304682882
Validation loss: 2.0760382952148553

Epoch: 6| Step: 7
Training loss: 1.0649720773036264
Validation loss: 2.1650236240414715

Epoch: 6| Step: 8
Training loss: 1.0290772060683784
Validation loss: 2.462477373063251

Epoch: 6| Step: 9
Training loss: 0.9362170341707973
Validation loss: 2.6088414763409418

Epoch: 6| Step: 10
Training loss: 0.8953965512112781
Validation loss: 2.6347111458760097

Epoch: 6| Step: 11
Training loss: 0.41058909873264415
Validation loss: 2.49929809766446

Epoch: 6| Step: 12
Training loss: 0.9986517579288334
Validation loss: 2.3873525279209695

Epoch: 6| Step: 13
Training loss: 1.0312198287711765
Validation loss: 2.4064826970011928

Epoch: 504| Step: 0
Training loss: 1.0433652317078403
Validation loss: 2.35708161931831

Epoch: 6| Step: 1
Training loss: 0.5426304264003785
Validation loss: 2.3651223680698257

Epoch: 6| Step: 2
Training loss: 0.4413160046172359
Validation loss: 2.3628518484896195

Epoch: 6| Step: 3
Training loss: 0.667820027174632
Validation loss: 2.395621031833191

Epoch: 6| Step: 4
Training loss: 0.5631131433218854
Validation loss: 2.4677177650264737

Epoch: 6| Step: 5
Training loss: 1.2044825140767357
Validation loss: 2.494875517521917

Epoch: 6| Step: 6
Training loss: 0.6566479248512526
Validation loss: 2.260187392508358

Epoch: 6| Step: 7
Training loss: 0.7443932132110245
Validation loss: 2.094167386436124

Epoch: 6| Step: 8
Training loss: 1.0017553658547573
Validation loss: 2.0696528686629674

Epoch: 6| Step: 9
Training loss: 0.8038032636302366
Validation loss: 2.041178695115716

Epoch: 6| Step: 10
Training loss: 0.6175522993697113
Validation loss: 2.1297003260161045

Epoch: 6| Step: 11
Training loss: 0.9053250558368935
Validation loss: 2.307025107827645

Epoch: 6| Step: 12
Training loss: 0.7352218209515176
Validation loss: 2.3933008188978957

Epoch: 6| Step: 13
Training loss: 0.6634488355734618
Validation loss: 2.44097352725961

Epoch: 505| Step: 0
Training loss: 0.624173332920645
Validation loss: 2.500026770417641

Epoch: 6| Step: 1
Training loss: 0.5944473287575802
Validation loss: 2.5173499388842298

Epoch: 6| Step: 2
Training loss: 0.7651350828346822
Validation loss: 2.528059864978432

Epoch: 6| Step: 3
Training loss: 0.5642196542019018
Validation loss: 2.4464942686736255

Epoch: 6| Step: 4
Training loss: 0.6378133060014745
Validation loss: 2.3718633307492913

Epoch: 6| Step: 5
Training loss: 0.6619160237625165
Validation loss: 2.3077544775921734

Epoch: 6| Step: 6
Training loss: 0.41356641813846046
Validation loss: 2.3049512848117097

Epoch: 6| Step: 7
Training loss: 0.5932973340807709
Validation loss: 2.2788195663296227

Epoch: 6| Step: 8
Training loss: 0.5057202298769089
Validation loss: 2.2846750598906276

Epoch: 6| Step: 9
Training loss: 0.5542881562378623
Validation loss: 2.329561881223526

Epoch: 6| Step: 10
Training loss: 0.4744176281056506
Validation loss: 2.3713599236364056

Epoch: 6| Step: 11
Training loss: 0.4542299150761892
Validation loss: 2.426569629780185

Epoch: 6| Step: 12
Training loss: 0.5933877944418728
Validation loss: 2.4595005948210256

Epoch: 6| Step: 13
Training loss: 0.24814642012596702
Validation loss: 2.4246525117898106

Epoch: 506| Step: 0
Training loss: 0.4338689394752613
Validation loss: 2.3976024785314647

Epoch: 6| Step: 1
Training loss: 0.4387346285656893
Validation loss: 2.31347219090963

Epoch: 6| Step: 2
Training loss: 0.2945457485283269
Validation loss: 2.2534062331092066

Epoch: 6| Step: 3
Training loss: 0.6495804193572856
Validation loss: 2.207463648026232

Epoch: 6| Step: 4
Training loss: 0.5685657768779891
Validation loss: 2.2176552838748895

Epoch: 6| Step: 5
Training loss: 0.6589696026623468
Validation loss: 2.255670229397422

Epoch: 6| Step: 6
Training loss: 0.5266401329881413
Validation loss: 2.2495950541820102

Epoch: 6| Step: 7
Training loss: 0.4197966455427802
Validation loss: 2.3133225279384257

Epoch: 6| Step: 8
Training loss: 0.4963479329531988
Validation loss: 2.328883542824467

Epoch: 6| Step: 9
Training loss: 0.36017097558888156
Validation loss: 2.409017652680301

Epoch: 6| Step: 10
Training loss: 0.5665254138690327
Validation loss: 2.476289459194232

Epoch: 6| Step: 11
Training loss: 0.5959392142308689
Validation loss: 2.548967958131063

Epoch: 6| Step: 12
Training loss: 0.5585090199478959
Validation loss: 2.5118373002795686

Epoch: 6| Step: 13
Training loss: 0.5367364594537688
Validation loss: 2.4404864373209394

Epoch: 507| Step: 0
Training loss: 0.40716779179573104
Validation loss: 2.3682635569839183

Epoch: 6| Step: 1
Training loss: 0.4613276301550089
Validation loss: 2.3034295477073843

Epoch: 6| Step: 2
Training loss: 0.6336407833304704
Validation loss: 2.271217779525541

Epoch: 6| Step: 3
Training loss: 0.3688012637049483
Validation loss: 2.3116068823990483

Epoch: 6| Step: 4
Training loss: 0.38053608402309164
Validation loss: 2.362063912921362

Epoch: 6| Step: 5
Training loss: 0.37619996802777567
Validation loss: 2.404062242625689

Epoch: 6| Step: 6
Training loss: 0.34936145964368676
Validation loss: 2.4438710382290036

Epoch: 6| Step: 7
Training loss: 0.23640363448486887
Validation loss: 2.4523103216989535

Epoch: 6| Step: 8
Training loss: 0.344919933948693
Validation loss: 2.4070045748733273

Epoch: 6| Step: 9
Training loss: 0.37283099254139923
Validation loss: 2.3959098093918154

Epoch: 6| Step: 10
Training loss: 0.3779567541242871
Validation loss: 2.421710961668358

Epoch: 6| Step: 11
Training loss: 0.38177950312756614
Validation loss: 2.3622941520771485

Epoch: 6| Step: 12
Training loss: 0.4030265939352919
Validation loss: 2.376569009989208

Epoch: 6| Step: 13
Training loss: 0.30513338328530154
Validation loss: 2.3271886419918686

Epoch: 508| Step: 0
Training loss: 0.2580931898379572
Validation loss: 2.330379686239198

Epoch: 6| Step: 1
Training loss: 0.42152174535614434
Validation loss: 2.3037500387062715

Epoch: 6| Step: 2
Training loss: 0.2884759880995149
Validation loss: 2.297086427908156

Epoch: 6| Step: 3
Training loss: 0.43857687161717146
Validation loss: 2.290242779910178

Epoch: 6| Step: 4
Training loss: 0.26192109271349523
Validation loss: 2.2502422948608394

Epoch: 6| Step: 5
Training loss: 0.3128142445808107
Validation loss: 2.210037833980236

Epoch: 6| Step: 6
Training loss: 0.419339561357906
Validation loss: 2.176487297095364

Epoch: 6| Step: 7
Training loss: 0.306592536605815
Validation loss: 2.1417860632831345

Epoch: 6| Step: 8
Training loss: 0.25540935455847547
Validation loss: 2.170975138759782

Epoch: 6| Step: 9
Training loss: 0.4162061729498561
Validation loss: 2.1563098977026547

Epoch: 6| Step: 10
Training loss: 0.24386722515203066
Validation loss: 2.1702263365050105

Epoch: 6| Step: 11
Training loss: 0.24856641381740777
Validation loss: 2.2056095272787455

Epoch: 6| Step: 12
Training loss: 0.23314208952417748
Validation loss: 2.226261979154963

Epoch: 6| Step: 13
Training loss: 0.327827273127776
Validation loss: 2.256001134732405

Epoch: 509| Step: 0
Training loss: 0.3172705583862807
Validation loss: 2.301293769226747

Epoch: 6| Step: 1
Training loss: 0.3307565680238799
Validation loss: 2.302890996905154

Epoch: 6| Step: 2
Training loss: 0.3672216683580919
Validation loss: 2.2970650176945253

Epoch: 6| Step: 3
Training loss: 0.2546317958177717
Validation loss: 2.2464063343972236

Epoch: 6| Step: 4
Training loss: 0.2752959853078412
Validation loss: 2.25806774682665

Epoch: 6| Step: 5
Training loss: 0.22424135326802733
Validation loss: 2.203025038292942

Epoch: 6| Step: 6
Training loss: 0.4366993048472601
Validation loss: 2.218951525643102

Epoch: 6| Step: 7
Training loss: 0.1620838076180855
Validation loss: 2.1952724664067005

Epoch: 6| Step: 8
Training loss: 0.3374220736044396
Validation loss: 2.219427058322991

Epoch: 6| Step: 9
Training loss: 0.2831023596033311
Validation loss: 2.240722902806407

Epoch: 6| Step: 10
Training loss: 0.2339447920980253
Validation loss: 2.210319743202652

Epoch: 6| Step: 11
Training loss: 0.38699494719471916
Validation loss: 2.262115503224521

Epoch: 6| Step: 12
Training loss: 0.2035757894783869
Validation loss: 2.2630258232994485

Epoch: 6| Step: 13
Training loss: 0.1585710744197185
Validation loss: 2.2699579725123966

Epoch: 510| Step: 0
Training loss: 0.3118929092027748
Validation loss: 2.2705109028569703

Epoch: 6| Step: 1
Training loss: 0.2844146858023033
Validation loss: 2.3173223410267236

Epoch: 6| Step: 2
Training loss: 0.2696628525699593
Validation loss: 2.3088705911816887

Epoch: 6| Step: 3
Training loss: 0.290834882792651
Validation loss: 2.312180925842969

Epoch: 6| Step: 4
Training loss: 0.20283696954231958
Validation loss: 2.3140119417428933

Epoch: 6| Step: 5
Training loss: 0.2729620751371107
Validation loss: 2.288266762190542

Epoch: 6| Step: 6
Training loss: 0.4331309451896566
Validation loss: 2.29514130286232

Epoch: 6| Step: 7
Training loss: 0.3169013376783425
Validation loss: 2.285750215793868

Epoch: 6| Step: 8
Training loss: 0.21136680820130024
Validation loss: 2.278897389298275

Epoch: 6| Step: 9
Training loss: 0.40773987835987113
Validation loss: 2.2838278126864355

Epoch: 6| Step: 10
Training loss: 0.2513049311632991
Validation loss: 2.2702155063487686

Epoch: 6| Step: 11
Training loss: 0.22127613861511652
Validation loss: 2.297680961526013

Epoch: 6| Step: 12
Training loss: 0.3330343465218131
Validation loss: 2.3268202320011335

Epoch: 6| Step: 13
Training loss: 0.19274155334724583
Validation loss: 2.3118993061566413

Epoch: 511| Step: 0
Training loss: 0.2786295728603433
Validation loss: 2.3396748317072134

Epoch: 6| Step: 1
Training loss: 0.268112776173091
Validation loss: 2.346930563898291

Epoch: 6| Step: 2
Training loss: 0.31576167489997287
Validation loss: 2.3194493729334305

Epoch: 6| Step: 3
Training loss: 0.4136168763050897
Validation loss: 2.3078405481590107

Epoch: 6| Step: 4
Training loss: 0.33553669551023463
Validation loss: 2.262870427203432

Epoch: 6| Step: 5
Training loss: 0.21644238538678426
Validation loss: 2.195832898897873

Epoch: 6| Step: 6
Training loss: 0.16541193424340847
Validation loss: 2.204844479644408

Epoch: 6| Step: 7
Training loss: 0.2599968562257044
Validation loss: 2.193828135967726

Epoch: 6| Step: 8
Training loss: 0.27279265524927504
Validation loss: 2.176766723213556

Epoch: 6| Step: 9
Training loss: 0.32168744557885864
Validation loss: 2.17936928570867

Epoch: 6| Step: 10
Training loss: 0.31356573767584417
Validation loss: 2.166825707122616

Epoch: 6| Step: 11
Training loss: 0.18688728635006613
Validation loss: 2.234214579752914

Epoch: 6| Step: 12
Training loss: 0.1758791386053657
Validation loss: 2.264072815786167

Epoch: 6| Step: 13
Training loss: 0.22861784091657028
Validation loss: 2.2658324104620413

Epoch: 512| Step: 0
Training loss: 0.3185615131856098
Validation loss: 2.3171782726842367

Epoch: 6| Step: 1
Training loss: 0.35505975522573674
Validation loss: 2.317789972592763

Epoch: 6| Step: 2
Training loss: 0.19757468496988004
Validation loss: 2.318296977764875

Epoch: 6| Step: 3
Training loss: 0.2726759796874138
Validation loss: 2.3269450623666166

Epoch: 6| Step: 4
Training loss: 0.2036969129758248
Validation loss: 2.301866189180141

Epoch: 6| Step: 5
Training loss: 0.23216571636363748
Validation loss: 2.2851524973529034

Epoch: 6| Step: 6
Training loss: 0.20802517491621988
Validation loss: 2.2648818378883386

Epoch: 6| Step: 7
Training loss: 0.2642087063270619
Validation loss: 2.2253804956622676

Epoch: 6| Step: 8
Training loss: 0.16553222739068124
Validation loss: 2.219346001784061

Epoch: 6| Step: 9
Training loss: 0.20685491609900242
Validation loss: 2.1816398482603563

Epoch: 6| Step: 10
Training loss: 0.20098746282232094
Validation loss: 2.1863567218370425

Epoch: 6| Step: 11
Training loss: 0.23820820454867622
Validation loss: 2.2304547839245337

Epoch: 6| Step: 12
Training loss: 0.30470559482151527
Validation loss: 2.2141263031685567

Epoch: 6| Step: 13
Training loss: 0.1643805996318164
Validation loss: 2.245209371368176

Epoch: 513| Step: 0
Training loss: 0.2960637703969579
Validation loss: 2.261226930920941

Epoch: 6| Step: 1
Training loss: 0.1675396361533528
Validation loss: 2.249102984497396

Epoch: 6| Step: 2
Training loss: 0.18272919713154426
Validation loss: 2.2933686172182557

Epoch: 6| Step: 3
Training loss: 0.1617020176786843
Validation loss: 2.28402657188497

Epoch: 6| Step: 4
Training loss: 0.24978030505574922
Validation loss: 2.2924618487127364

Epoch: 6| Step: 5
Training loss: 0.16829770058261262
Validation loss: 2.2876634268297966

Epoch: 6| Step: 6
Training loss: 0.3383373768961016
Validation loss: 2.2624310286420086

Epoch: 6| Step: 7
Training loss: 0.23408036786420597
Validation loss: 2.2712674575963594

Epoch: 6| Step: 8
Training loss: 0.18436274891900606
Validation loss: 2.2333841097989877

Epoch: 6| Step: 9
Training loss: 0.17277618424131583
Validation loss: 2.2404116354895423

Epoch: 6| Step: 10
Training loss: 0.20428469532241844
Validation loss: 2.199573601655107

Epoch: 6| Step: 11
Training loss: 0.1623558732628834
Validation loss: 2.176941574748268

Epoch: 6| Step: 12
Training loss: 0.2192892342470653
Validation loss: 2.2273043548206224

Epoch: 6| Step: 13
Training loss: 0.16175757577856228
Validation loss: 2.2262558776859316

Epoch: 514| Step: 0
Training loss: 0.10685069646482273
Validation loss: 2.2405250883447447

Epoch: 6| Step: 1
Training loss: 0.21791824521379838
Validation loss: 2.262692634079262

Epoch: 6| Step: 2
Training loss: 0.23513495896992154
Validation loss: 2.2603896373684442

Epoch: 6| Step: 3
Training loss: 0.1917736070429927
Validation loss: 2.263333714964926

Epoch: 6| Step: 4
Training loss: 0.11657133637165203
Validation loss: 2.271061151378793

Epoch: 6| Step: 5
Training loss: 0.19561694259625179
Validation loss: 2.2774768118491004

Epoch: 6| Step: 6
Training loss: 0.21310699911252437
Validation loss: 2.2961283174591043

Epoch: 6| Step: 7
Training loss: 0.19086311118067845
Validation loss: 2.2694342906693614

Epoch: 6| Step: 8
Training loss: 0.1761932313581601
Validation loss: 2.2569866904908116

Epoch: 6| Step: 9
Training loss: 0.1578523845127285
Validation loss: 2.286840403323319

Epoch: 6| Step: 10
Training loss: 0.1968047546529555
Validation loss: 2.2754244916686677

Epoch: 6| Step: 11
Training loss: 0.20155340883911138
Validation loss: 2.3031516631998423

Epoch: 6| Step: 12
Training loss: 0.2597556721781189
Validation loss: 2.3057188445801944

Epoch: 6| Step: 13
Training loss: 0.20504017433334534
Validation loss: 2.308610258294465

Epoch: 515| Step: 0
Training loss: 0.16557141507829706
Validation loss: 2.3106943484822664

Epoch: 6| Step: 1
Training loss: 0.20898177243332366
Validation loss: 2.3348140684000827

Epoch: 6| Step: 2
Training loss: 0.13330360381662845
Validation loss: 2.3369108866259696

Epoch: 6| Step: 3
Training loss: 0.1372538585103099
Validation loss: 2.345617914782898

Epoch: 6| Step: 4
Training loss: 0.20155626442601135
Validation loss: 2.3192895041687596

Epoch: 6| Step: 5
Training loss: 0.1837603036755339
Validation loss: 2.322798724615167

Epoch: 6| Step: 6
Training loss: 0.246525635265986
Validation loss: 2.33141908996558

Epoch: 6| Step: 7
Training loss: 0.08028669932262537
Validation loss: 2.3188978467743895

Epoch: 6| Step: 8
Training loss: 0.1530056902202861
Validation loss: 2.2929271852084687

Epoch: 6| Step: 9
Training loss: 0.20313556350236614
Validation loss: 2.2611267005237403

Epoch: 6| Step: 10
Training loss: 0.21372441965540406
Validation loss: 2.224968488704457

Epoch: 6| Step: 11
Training loss: 0.18845353455274058
Validation loss: 2.239483161187477

Epoch: 6| Step: 12
Training loss: 0.1566581699600682
Validation loss: 2.220169796287494

Epoch: 6| Step: 13
Training loss: 0.20179421723284782
Validation loss: 2.242775502838494

Epoch: 516| Step: 0
Training loss: 0.1369860692394283
Validation loss: 2.225068961256156

Epoch: 6| Step: 1
Training loss: 0.2167149638180084
Validation loss: 2.2488341472833038

Epoch: 6| Step: 2
Training loss: 0.16446997925387594
Validation loss: 2.243704642543123

Epoch: 6| Step: 3
Training loss: 0.18781501414477567
Validation loss: 2.2544878225711797

Epoch: 6| Step: 4
Training loss: 0.1771889586615694
Validation loss: 2.275064700005695

Epoch: 6| Step: 5
Training loss: 0.11988513520427856
Validation loss: 2.259687122717836

Epoch: 6| Step: 6
Training loss: 0.1551982949731481
Validation loss: 2.262202532819273

Epoch: 6| Step: 7
Training loss: 0.17000266598967173
Validation loss: 2.280972598621886

Epoch: 6| Step: 8
Training loss: 0.13384199835490337
Validation loss: 2.2980862369666313

Epoch: 6| Step: 9
Training loss: 0.12422157590278811
Validation loss: 2.2862894447754547

Epoch: 6| Step: 10
Training loss: 0.13454719477766014
Validation loss: 2.3053489363003004

Epoch: 6| Step: 11
Training loss: 0.1444964109135094
Validation loss: 2.2752666201763003

Epoch: 6| Step: 12
Training loss: 0.12261606290045728
Validation loss: 2.2982542601177998

Epoch: 6| Step: 13
Training loss: 0.12960919262331133
Validation loss: 2.2785897695555994

Epoch: 517| Step: 0
Training loss: 0.1345473332156405
Validation loss: 2.279855220564593

Epoch: 6| Step: 1
Training loss: 0.12110430917540628
Validation loss: 2.2741378496485725

Epoch: 6| Step: 2
Training loss: 0.21286210035259362
Validation loss: 2.298805394991962

Epoch: 6| Step: 3
Training loss: 0.1850492329104608
Validation loss: 2.2817388548207687

Epoch: 6| Step: 4
Training loss: 0.11796991303483226
Validation loss: 2.3146713846906737

Epoch: 6| Step: 5
Training loss: 0.18752823060816265
Validation loss: 2.2973867134750163

Epoch: 6| Step: 6
Training loss: 0.23735765564585645
Validation loss: 2.3084613209672877

Epoch: 6| Step: 7
Training loss: 0.1642158336725263
Validation loss: 2.322443467251361

Epoch: 6| Step: 8
Training loss: 0.2036943160066966
Validation loss: 2.3031534185595985

Epoch: 6| Step: 9
Training loss: 0.09819606358063876
Validation loss: 2.295041423154523

Epoch: 6| Step: 10
Training loss: 0.12361377355532076
Validation loss: 2.296207925177239

Epoch: 6| Step: 11
Training loss: 0.19651679687259782
Validation loss: 2.3121387894678613

Epoch: 6| Step: 12
Training loss: 0.1561850174244424
Validation loss: 2.28619346529959

Epoch: 6| Step: 13
Training loss: 0.2497610276210474
Validation loss: 2.283811073618349

Epoch: 518| Step: 0
Training loss: 0.14185142177275
Validation loss: 2.2551465860961515

Epoch: 6| Step: 1
Training loss: 0.19579321830013183
Validation loss: 2.2679245540113557

Epoch: 6| Step: 2
Training loss: 0.08176963961189564
Validation loss: 2.2404879262475634

Epoch: 6| Step: 3
Training loss: 0.15652131723939014
Validation loss: 2.2321267428541613

Epoch: 6| Step: 4
Training loss: 0.11332306419011373
Validation loss: 2.2259044965212316

Epoch: 6| Step: 5
Training loss: 0.11570419695458718
Validation loss: 2.189278167891143

Epoch: 6| Step: 6
Training loss: 0.1868227708832089
Validation loss: 2.2334504122373957

Epoch: 6| Step: 7
Training loss: 0.197845626094288
Validation loss: 2.26038592583096

Epoch: 6| Step: 8
Training loss: 0.18695072344693298
Validation loss: 2.2574426190695274

Epoch: 6| Step: 9
Training loss: 0.16488204348560365
Validation loss: 2.2875508762303056

Epoch: 6| Step: 10
Training loss: 0.1610126798916613
Validation loss: 2.2979730131960676

Epoch: 6| Step: 11
Training loss: 0.10782346220538452
Validation loss: 2.3329578354248475

Epoch: 6| Step: 12
Training loss: 0.164222684499137
Validation loss: 2.3353490491258655

Epoch: 6| Step: 13
Training loss: 0.27267234557991415
Validation loss: 2.331111207660862

Epoch: 519| Step: 0
Training loss: 0.1256686002358485
Validation loss: 2.343524758512042

Epoch: 6| Step: 1
Training loss: 0.16069923791185403
Validation loss: 2.362365078072456

Epoch: 6| Step: 2
Training loss: 0.15680780978009579
Validation loss: 2.344197652308315

Epoch: 6| Step: 3
Training loss: 0.11094079482867504
Validation loss: 2.3016670736781633

Epoch: 6| Step: 4
Training loss: 0.159717353859481
Validation loss: 2.2745953305106563

Epoch: 6| Step: 5
Training loss: 0.24121979453933967
Validation loss: 2.286010689023887

Epoch: 6| Step: 6
Training loss: 0.15034839730859512
Validation loss: 2.2716108355064075

Epoch: 6| Step: 7
Training loss: 0.1312174240058026
Validation loss: 2.2878928310454505

Epoch: 6| Step: 8
Training loss: 0.14727096446751825
Validation loss: 2.300699891752412

Epoch: 6| Step: 9
Training loss: 0.1682165004304141
Validation loss: 2.3052780226317253

Epoch: 6| Step: 10
Training loss: 0.2112633519495802
Validation loss: 2.3388881449060497

Epoch: 6| Step: 11
Training loss: 0.20266795090048345
Validation loss: 2.3017001638904837

Epoch: 6| Step: 12
Training loss: 0.15212267950226846
Validation loss: 2.3110043495621735

Epoch: 6| Step: 13
Training loss: 0.13436892074317894
Validation loss: 2.303544999539052

Epoch: 520| Step: 0
Training loss: 0.11487029638145653
Validation loss: 2.27736164486249

Epoch: 6| Step: 1
Training loss: 0.11951354946025411
Validation loss: 2.3062522730546706

Epoch: 6| Step: 2
Training loss: 0.13181728654964012
Validation loss: 2.3038345196169536

Epoch: 6| Step: 3
Training loss: 0.15554372786207796
Validation loss: 2.3025383830603685

Epoch: 6| Step: 4
Training loss: 0.15065788697495
Validation loss: 2.301918259582483

Epoch: 6| Step: 5
Training loss: 0.16563157369955483
Validation loss: 2.31132311197515

Epoch: 6| Step: 6
Training loss: 0.17959415042727017
Validation loss: 2.341713324636567

Epoch: 6| Step: 7
Training loss: 0.12065961139850725
Validation loss: 2.362456523466789

Epoch: 6| Step: 8
Training loss: 0.18248376715332099
Validation loss: 2.3691946340240153

Epoch: 6| Step: 9
Training loss: 0.14785826754767506
Validation loss: 2.3586206771223868

Epoch: 6| Step: 10
Training loss: 0.1412367231323851
Validation loss: 2.3431623459103896

Epoch: 6| Step: 11
Training loss: 0.128174511135643
Validation loss: 2.3117962813824655

Epoch: 6| Step: 12
Training loss: 0.15802880679348982
Validation loss: 2.31435873333171

Epoch: 6| Step: 13
Training loss: 0.07273777840577099
Validation loss: 2.294732647322591

Epoch: 521| Step: 0
Training loss: 0.07728860290685292
Validation loss: 2.277713657013204

Epoch: 6| Step: 1
Training loss: 0.14396453273616944
Validation loss: 2.2765234252460025

Epoch: 6| Step: 2
Training loss: 0.19352570517894066
Validation loss: 2.2906391633285623

Epoch: 6| Step: 3
Training loss: 0.13667743603600985
Validation loss: 2.3032542265033698

Epoch: 6| Step: 4
Training loss: 0.12677891589388682
Validation loss: 2.2868918641069818

Epoch: 6| Step: 5
Training loss: 0.17563630592024995
Validation loss: 2.287195073584618

Epoch: 6| Step: 6
Training loss: 0.14529178892226563
Validation loss: 2.332715964899895

Epoch: 6| Step: 7
Training loss: 0.17836178091651328
Validation loss: 2.344211218515085

Epoch: 6| Step: 8
Training loss: 0.11492269196728858
Validation loss: 2.324948968061537

Epoch: 6| Step: 9
Training loss: 0.10791125663783153
Validation loss: 2.317883446440458

Epoch: 6| Step: 10
Training loss: 0.17988979313629155
Validation loss: 2.322937135970882

Epoch: 6| Step: 11
Training loss: 0.19844018040746594
Validation loss: 2.3199772199450113

Epoch: 6| Step: 12
Training loss: 0.1278659792964377
Validation loss: 2.2897011207889957

Epoch: 6| Step: 13
Training loss: 0.1363867680029061
Validation loss: 2.3108956476270714

Epoch: 522| Step: 0
Training loss: 0.15810695126776805
Validation loss: 2.2841445241195615

Epoch: 6| Step: 1
Training loss: 0.1619966586185615
Validation loss: 2.2808390230457976

Epoch: 6| Step: 2
Training loss: 0.11735653210166364
Validation loss: 2.270292906640664

Epoch: 6| Step: 3
Training loss: 0.14113680105646953
Validation loss: 2.2501186193739042

Epoch: 6| Step: 4
Training loss: 0.1631883996042375
Validation loss: 2.272068766509531

Epoch: 6| Step: 5
Training loss: 0.13130666667540383
Validation loss: 2.2627722024439243

Epoch: 6| Step: 6
Training loss: 0.12258252825830285
Validation loss: 2.2888914617862226

Epoch: 6| Step: 7
Training loss: 0.09674169979143497
Validation loss: 2.2781683813210756

Epoch: 6| Step: 8
Training loss: 0.12492867014131188
Validation loss: 2.280476464689325

Epoch: 6| Step: 9
Training loss: 0.10168617311384509
Validation loss: 2.285407481315909

Epoch: 6| Step: 10
Training loss: 0.12519020272478415
Validation loss: 2.3095925846954155

Epoch: 6| Step: 11
Training loss: 0.18454862396532862
Validation loss: 2.345001727595354

Epoch: 6| Step: 12
Training loss: 0.09439961552912907
Validation loss: 2.291589719612248

Epoch: 6| Step: 13
Training loss: 0.1045740600059786
Validation loss: 2.3209176350138034

Epoch: 523| Step: 0
Training loss: 0.10749843643404276
Validation loss: 2.2918921990785908

Epoch: 6| Step: 1
Training loss: 0.09197857810750536
Validation loss: 2.3260025058223164

Epoch: 6| Step: 2
Training loss: 0.12589520037469484
Validation loss: 2.333620362126436

Epoch: 6| Step: 3
Training loss: 0.13626526145593496
Validation loss: 2.3218408785715834

Epoch: 6| Step: 4
Training loss: 0.10327768870805805
Validation loss: 2.316347510567636

Epoch: 6| Step: 5
Training loss: 0.1015351652994307
Validation loss: 2.306424314128099

Epoch: 6| Step: 6
Training loss: 0.12181484574931109
Validation loss: 2.3060472607105336

Epoch: 6| Step: 7
Training loss: 0.10029399503574662
Validation loss: 2.3163867481955136

Epoch: 6| Step: 8
Training loss: 0.13384075975874238
Validation loss: 2.326250038009216

Epoch: 6| Step: 9
Training loss: 0.14017604980400503
Validation loss: 2.299838882985259

Epoch: 6| Step: 10
Training loss: 0.09291887929214214
Validation loss: 2.2894207883542976

Epoch: 6| Step: 11
Training loss: 0.16947013175185804
Validation loss: 2.30454484718126

Epoch: 6| Step: 12
Training loss: 0.1582993462019207
Validation loss: 2.287597042683435

Epoch: 6| Step: 13
Training loss: 0.08926938292887854
Validation loss: 2.256086787751523

Epoch: 524| Step: 0
Training loss: 0.09690674215620505
Validation loss: 2.2864354997890173

Epoch: 6| Step: 1
Training loss: 0.09914838011300149
Validation loss: 2.315811401524176

Epoch: 6| Step: 2
Training loss: 0.14332575286828522
Validation loss: 2.261566245946964

Epoch: 6| Step: 3
Training loss: 0.08745811856537127
Validation loss: 2.2954776685920604

Epoch: 6| Step: 4
Training loss: 0.11264150118212547
Validation loss: 2.2912408569247322

Epoch: 6| Step: 5
Training loss: 0.12111541338924572
Validation loss: 2.3075534843582046

Epoch: 6| Step: 6
Training loss: 0.1389979504671727
Validation loss: 2.309893390919527

Epoch: 6| Step: 7
Training loss: 0.09349019091133323
Validation loss: 2.305625698146746

Epoch: 6| Step: 8
Training loss: 0.14824122075505716
Validation loss: 2.3313955198082303

Epoch: 6| Step: 9
Training loss: 0.13240015307486752
Validation loss: 2.303448594942617

Epoch: 6| Step: 10
Training loss: 0.11378490360515749
Validation loss: 2.3149846029007675

Epoch: 6| Step: 11
Training loss: 0.18477564697828483
Validation loss: 2.2864161078784133

Epoch: 6| Step: 12
Training loss: 0.09625643260472334
Validation loss: 2.2953659710808267

Epoch: 6| Step: 13
Training loss: 0.1222009188998335
Validation loss: 2.318954881021981

Epoch: 525| Step: 0
Training loss: 0.16954091545538402
Validation loss: 2.288198404361977

Epoch: 6| Step: 1
Training loss: 0.11714526846002844
Validation loss: 2.259861808019889

Epoch: 6| Step: 2
Training loss: 0.18816433873868038
Validation loss: 2.2966738376921914

Epoch: 6| Step: 3
Training loss: 0.07713411294765658
Validation loss: 2.269559756163454

Epoch: 6| Step: 4
Training loss: 0.19154581509125834
Validation loss: 2.2677686304824074

Epoch: 6| Step: 5
Training loss: 0.1253716561417298
Validation loss: 2.243394185472522

Epoch: 6| Step: 6
Training loss: 0.1284087725345381
Validation loss: 2.2947861210335057

Epoch: 6| Step: 7
Training loss: 0.09872873759426351
Validation loss: 2.2626049032838442

Epoch: 6| Step: 8
Training loss: 0.08603960712017678
Validation loss: 2.2630330830772607

Epoch: 6| Step: 9
Training loss: 0.11761892694348165
Validation loss: 2.2826279948016626

Epoch: 6| Step: 10
Training loss: 0.10588981324540905
Validation loss: 2.2930649344516145

Epoch: 6| Step: 11
Training loss: 0.1555793914835321
Validation loss: 2.313126840195229

Epoch: 6| Step: 12
Training loss: 0.10573848476205011
Validation loss: 2.312575406943379

Epoch: 6| Step: 13
Training loss: 0.1263427660661041
Validation loss: 2.309458254512742

Epoch: 526| Step: 0
Training loss: 0.12169319264640518
Validation loss: 2.318919052092366

Epoch: 6| Step: 1
Training loss: 0.049870034431799555
Validation loss: 2.297036754656974

Epoch: 6| Step: 2
Training loss: 0.14373610185733884
Validation loss: 2.274978879154197

Epoch: 6| Step: 3
Training loss: 0.0992688360476972
Validation loss: 2.2718712620212775

Epoch: 6| Step: 4
Training loss: 0.11459147404521552
Validation loss: 2.286120535517278

Epoch: 6| Step: 5
Training loss: 0.11847845137008876
Validation loss: 2.2542824018896357

Epoch: 6| Step: 6
Training loss: 0.21586669665085415
Validation loss: 2.265751586138673

Epoch: 6| Step: 7
Training loss: 0.159360706632728
Validation loss: 2.25821440106975

Epoch: 6| Step: 8
Training loss: 0.15671666314132393
Validation loss: 2.246789964489032

Epoch: 6| Step: 9
Training loss: 0.09572347599776787
Validation loss: 2.2549984363055446

Epoch: 6| Step: 10
Training loss: 0.10817489255701895
Validation loss: 2.2586414558181507

Epoch: 6| Step: 11
Training loss: 0.08934806313599472
Validation loss: 2.275821898106153

Epoch: 6| Step: 12
Training loss: 0.20708054729355452
Validation loss: 2.2712847744581675

Epoch: 6| Step: 13
Training loss: 0.06000407388262779
Validation loss: 2.291169044484044

Epoch: 527| Step: 0
Training loss: 0.17977768252045975
Validation loss: 2.3109299868421385

Epoch: 6| Step: 1
Training loss: 0.13521447278216667
Validation loss: 2.309140063442948

Epoch: 6| Step: 2
Training loss: 0.10653052287918056
Validation loss: 2.2736455666178355

Epoch: 6| Step: 3
Training loss: 0.08702020914117067
Validation loss: 2.3246325085879747

Epoch: 6| Step: 4
Training loss: 0.11832510008119614
Validation loss: 2.3159087670833585

Epoch: 6| Step: 5
Training loss: 0.18030621942460842
Validation loss: 2.293283110209002

Epoch: 6| Step: 6
Training loss: 0.0847320762729053
Validation loss: 2.2915470625317034

Epoch: 6| Step: 7
Training loss: 0.16891419669909452
Validation loss: 2.3169160641666178

Epoch: 6| Step: 8
Training loss: 0.08025655116376093
Validation loss: 2.273184457159378

Epoch: 6| Step: 9
Training loss: 0.09690810203289416
Validation loss: 2.2957427997365714

Epoch: 6| Step: 10
Training loss: 0.0983699421058011
Validation loss: 2.235261203113299

Epoch: 6| Step: 11
Training loss: 0.17774835468689654
Validation loss: 2.235290624283146

Epoch: 6| Step: 12
Training loss: 0.19473763743351097
Validation loss: 2.227148660856825

Epoch: 6| Step: 13
Training loss: 0.09290707650251653
Validation loss: 2.2090730361812896

Epoch: 528| Step: 0
Training loss: 0.20480946699870367
Validation loss: 2.2620164251433215

Epoch: 6| Step: 1
Training loss: 0.11071381146493102
Validation loss: 2.2335112996548045

Epoch: 6| Step: 2
Training loss: 0.15468929583537805
Validation loss: 2.278557379955618

Epoch: 6| Step: 3
Training loss: 0.10174953221991515
Validation loss: 2.2673370500841

Epoch: 6| Step: 4
Training loss: 0.11404268683836245
Validation loss: 2.296778047552536

Epoch: 6| Step: 5
Training loss: 0.11560599969998792
Validation loss: 2.3443224469670754

Epoch: 6| Step: 6
Training loss: 0.1756594235734658
Validation loss: 2.3155674083984876

Epoch: 6| Step: 7
Training loss: 0.12570696823096253
Validation loss: 2.330765091594041

Epoch: 6| Step: 8
Training loss: 0.1041394009271385
Validation loss: 2.343621077734649

Epoch: 6| Step: 9
Training loss: 0.11472654784906779
Validation loss: 2.3209902987122715

Epoch: 6| Step: 10
Training loss: 0.15198375275559894
Validation loss: 2.323989774434915

Epoch: 6| Step: 11
Training loss: 0.06164462400501579
Validation loss: 2.307437434812084

Epoch: 6| Step: 12
Training loss: 0.09850746158776659
Validation loss: 2.309989249653619

Epoch: 6| Step: 13
Training loss: 0.06981951357587261
Validation loss: 2.2726328687833877

Epoch: 529| Step: 0
Training loss: 0.09162605909734638
Validation loss: 2.262671676800432

Epoch: 6| Step: 1
Training loss: 0.08300465128993893
Validation loss: 2.263694824152251

Epoch: 6| Step: 2
Training loss: 0.09924143734564123
Validation loss: 2.272702529801439

Epoch: 6| Step: 3
Training loss: 0.091918144881169
Validation loss: 2.2834993107489434

Epoch: 6| Step: 4
Training loss: 0.0693159914205848
Validation loss: 2.265094941467046

Epoch: 6| Step: 5
Training loss: 0.12025575476237595
Validation loss: 2.305336628206783

Epoch: 6| Step: 6
Training loss: 0.16063041972876432
Validation loss: 2.3072850792929516

Epoch: 6| Step: 7
Training loss: 0.15322072141555057
Validation loss: 2.29305235471036

Epoch: 6| Step: 8
Training loss: 0.15434806312656277
Validation loss: 2.329730332497204

Epoch: 6| Step: 9
Training loss: 0.1464049441829979
Validation loss: 2.3247089925435676

Epoch: 6| Step: 10
Training loss: 0.059680098847440875
Validation loss: 2.3035614857266977

Epoch: 6| Step: 11
Training loss: 0.10231424845574623
Validation loss: 2.3043904786954683

Epoch: 6| Step: 12
Training loss: 0.09974160020132004
Validation loss: 2.310728783327964

Epoch: 6| Step: 13
Training loss: 0.08952853114641734
Validation loss: 2.3108860914854445

Epoch: 530| Step: 0
Training loss: 0.12573494029069135
Validation loss: 2.302453509983029

Epoch: 6| Step: 1
Training loss: 0.17763185164131368
Validation loss: 2.319463614420468

Epoch: 6| Step: 2
Training loss: 0.06680766263932003
Validation loss: 2.2724148076291457

Epoch: 6| Step: 3
Training loss: 0.13888715769430576
Validation loss: 2.297397918141909

Epoch: 6| Step: 4
Training loss: 0.16720428159752365
Validation loss: 2.3054163160539356

Epoch: 6| Step: 5
Training loss: 0.09099867953597413
Validation loss: 2.315590969725365

Epoch: 6| Step: 6
Training loss: 0.09238507145061477
Validation loss: 2.3237113169147907

Epoch: 6| Step: 7
Training loss: 0.0900763889403513
Validation loss: 2.293949329037067

Epoch: 6| Step: 8
Training loss: 0.12534976245875118
Validation loss: 2.3074361293471757

Epoch: 6| Step: 9
Training loss: 0.13263949177168374
Validation loss: 2.329109703258355

Epoch: 6| Step: 10
Training loss: 0.11644955987871695
Validation loss: 2.320334990598082

Epoch: 6| Step: 11
Training loss: 0.10318422350888971
Validation loss: 2.3082774760997724

Epoch: 6| Step: 12
Training loss: 0.13307307430588952
Validation loss: 2.297883300818666

Epoch: 6| Step: 13
Training loss: 0.17832191525059687
Validation loss: 2.307158474063995

Epoch: 531| Step: 0
Training loss: 0.12275184350416338
Validation loss: 2.269229023788574

Epoch: 6| Step: 1
Training loss: 0.1398083431557881
Validation loss: 2.29761267708658

Epoch: 6| Step: 2
Training loss: 0.1499793945007759
Validation loss: 2.273453148338106

Epoch: 6| Step: 3
Training loss: 0.1412302014624401
Validation loss: 2.261852219872905

Epoch: 6| Step: 4
Training loss: 0.11111250291224173
Validation loss: 2.2681934139173423

Epoch: 6| Step: 5
Training loss: 0.12679033112107221
Validation loss: 2.2981184372241

Epoch: 6| Step: 6
Training loss: 0.13302604253477254
Validation loss: 2.301713220966465

Epoch: 6| Step: 7
Training loss: 0.07764242859002825
Validation loss: 2.2920461180173577

Epoch: 6| Step: 8
Training loss: 0.14072999743148865
Validation loss: 2.2931324906853834

Epoch: 6| Step: 9
Training loss: 0.08168989353551447
Validation loss: 2.2942449577019297

Epoch: 6| Step: 10
Training loss: 0.1408166242055633
Validation loss: 2.299751992918804

Epoch: 6| Step: 11
Training loss: 0.1082121304782332
Validation loss: 2.2998075779697977

Epoch: 6| Step: 12
Training loss: 0.09545220353416561
Validation loss: 2.2902504476164625

Epoch: 6| Step: 13
Training loss: 0.1391338925925629
Validation loss: 2.3276874301435897

Epoch: 532| Step: 0
Training loss: 0.11045192694948505
Validation loss: 2.284783242641504

Epoch: 6| Step: 1
Training loss: 0.09291728061564425
Validation loss: 2.313007862138476

Epoch: 6| Step: 2
Training loss: 0.09757991668485633
Validation loss: 2.281809742788234

Epoch: 6| Step: 3
Training loss: 0.1335255750070221
Validation loss: 2.3085542433264514

Epoch: 6| Step: 4
Training loss: 0.1516588907379388
Validation loss: 2.2902196299976856

Epoch: 6| Step: 5
Training loss: 0.14203974571460268
Validation loss: 2.3008317661016733

Epoch: 6| Step: 6
Training loss: 0.126918186368483
Validation loss: 2.2910880364184503

Epoch: 6| Step: 7
Training loss: 0.12659969283726946
Validation loss: 2.294523541002868

Epoch: 6| Step: 8
Training loss: 0.09561714864736746
Validation loss: 2.297169872713049

Epoch: 6| Step: 9
Training loss: 0.11730086485826628
Validation loss: 2.2996749035575177

Epoch: 6| Step: 10
Training loss: 0.1375776085418764
Validation loss: 2.3031751044330364

Epoch: 6| Step: 11
Training loss: 0.13477410414185187
Validation loss: 2.297834050342457

Epoch: 6| Step: 12
Training loss: 0.14429319598016027
Validation loss: 2.265204694245881

Epoch: 6| Step: 13
Training loss: 0.11776328889256403
Validation loss: 2.2808876502760445

Epoch: 533| Step: 0
Training loss: 0.14151443563371952
Validation loss: 2.2784521235152053

Epoch: 6| Step: 1
Training loss: 0.10309405223713096
Validation loss: 2.2460179606915496

Epoch: 6| Step: 2
Training loss: 0.06737283964577258
Validation loss: 2.304636159595798

Epoch: 6| Step: 3
Training loss: 0.1418256302253032
Validation loss: 2.2691280775072964

Epoch: 6| Step: 4
Training loss: 0.13607450328330106
Validation loss: 2.290556884114572

Epoch: 6| Step: 5
Training loss: 0.1206491445308106
Validation loss: 2.3006406460060864

Epoch: 6| Step: 6
Training loss: 0.15616071653553038
Validation loss: 2.29670939414576

Epoch: 6| Step: 7
Training loss: 0.09492645605830181
Validation loss: 2.2904194754013028

Epoch: 6| Step: 8
Training loss: 0.16928285164838558
Validation loss: 2.3024906361807145

Epoch: 6| Step: 9
Training loss: 0.1838503525602183
Validation loss: 2.330811423901479

Epoch: 6| Step: 10
Training loss: 0.1066773973021487
Validation loss: 2.322577421977357

Epoch: 6| Step: 11
Training loss: 0.15903974595166406
Validation loss: 2.3284877580648735

Epoch: 6| Step: 12
Training loss: 0.11454720812702145
Validation loss: 2.335943884022346

Epoch: 6| Step: 13
Training loss: 0.08188601534395344
Validation loss: 2.3359914086078235

Epoch: 534| Step: 0
Training loss: 0.09418576017252415
Validation loss: 2.318670706320088

Epoch: 6| Step: 1
Training loss: 0.12357065195959614
Validation loss: 2.3203988438817107

Epoch: 6| Step: 2
Training loss: 0.07715064661267407
Validation loss: 2.322752954302187

Epoch: 6| Step: 3
Training loss: 0.12328813379526661
Validation loss: 2.312582121513092

Epoch: 6| Step: 4
Training loss: 0.18868463524421855
Validation loss: 2.321326581005238

Epoch: 6| Step: 5
Training loss: 0.1360437898436107
Validation loss: 2.312619382198479

Epoch: 6| Step: 6
Training loss: 0.06785197297401988
Validation loss: 2.3070629816445662

Epoch: 6| Step: 7
Training loss: 0.13747369232797538
Validation loss: 2.319683649480433

Epoch: 6| Step: 8
Training loss: 0.09123481993281732
Validation loss: 2.3012058673993425

Epoch: 6| Step: 9
Training loss: 0.16320861268484235
Validation loss: 2.320947177386702

Epoch: 6| Step: 10
Training loss: 0.07957398075155994
Validation loss: 2.2717530031900024

Epoch: 6| Step: 11
Training loss: 0.09972219062363848
Validation loss: 2.28187565940889

Epoch: 6| Step: 12
Training loss: 0.10371595467538582
Validation loss: 2.2870251158671238

Epoch: 6| Step: 13
Training loss: 0.2227406090994922
Validation loss: 2.2776942156082036

Epoch: 535| Step: 0
Training loss: 0.10202317571748834
Validation loss: 2.286149646706357

Epoch: 6| Step: 1
Training loss: 0.12948882787612623
Validation loss: 2.3173955212431157

Epoch: 6| Step: 2
Training loss: 0.1086722772701889
Validation loss: 2.3113704595614672

Epoch: 6| Step: 3
Training loss: 0.08703736335130621
Validation loss: 2.3123727057801866

Epoch: 6| Step: 4
Training loss: 0.12059749159898837
Validation loss: 2.3239394351944305

Epoch: 6| Step: 5
Training loss: 0.07678108032535409
Validation loss: 2.3231804847493525

Epoch: 6| Step: 6
Training loss: 0.11335460162481004
Validation loss: 2.3067188474564486

Epoch: 6| Step: 7
Training loss: 0.061537124231577464
Validation loss: 2.309271425829734

Epoch: 6| Step: 8
Training loss: 0.10354309797097234
Validation loss: 2.314970145044422

Epoch: 6| Step: 9
Training loss: 0.17782910934804605
Validation loss: 2.343268185111375

Epoch: 6| Step: 10
Training loss: 0.12747260694660933
Validation loss: 2.3047116302845487

Epoch: 6| Step: 11
Training loss: 0.09135425160471855
Validation loss: 2.3223047538041364

Epoch: 6| Step: 12
Training loss: 0.11889765932728451
Validation loss: 2.3092968303919483

Epoch: 6| Step: 13
Training loss: 0.18314289981993723
Validation loss: 2.2840155530460753

Epoch: 536| Step: 0
Training loss: 0.09182191568093372
Validation loss: 2.2635491660211104

Epoch: 6| Step: 1
Training loss: 0.11486486416008021
Validation loss: 2.2707345547227806

Epoch: 6| Step: 2
Training loss: 0.06738892126726853
Validation loss: 2.2378942665527535

Epoch: 6| Step: 3
Training loss: 0.11430385672573919
Validation loss: 2.2515284942076352

Epoch: 6| Step: 4
Training loss: 0.09391769669471993
Validation loss: 2.2597103500161064

Epoch: 6| Step: 5
Training loss: 0.15547857588958577
Validation loss: 2.243547360282348

Epoch: 6| Step: 6
Training loss: 0.08693390523305784
Validation loss: 2.2567099497736924

Epoch: 6| Step: 7
Training loss: 0.1536268826020915
Validation loss: 2.2414112557478565

Epoch: 6| Step: 8
Training loss: 0.12864246978558286
Validation loss: 2.2583568234927243

Epoch: 6| Step: 9
Training loss: 0.08954036323408718
Validation loss: 2.2755907531494284

Epoch: 6| Step: 10
Training loss: 0.07923977750550727
Validation loss: 2.2849318892108728

Epoch: 6| Step: 11
Training loss: 0.17924477104782865
Validation loss: 2.3327619523961878

Epoch: 6| Step: 12
Training loss: 0.08196428381168613
Validation loss: 2.3197043204546035

Epoch: 6| Step: 13
Training loss: 0.09316973618958951
Validation loss: 2.325035070295288

Epoch: 537| Step: 0
Training loss: 0.09438932499576813
Validation loss: 2.3309654053328424

Epoch: 6| Step: 1
Training loss: 0.09419114905808597
Validation loss: 2.3344942071271526

Epoch: 6| Step: 2
Training loss: 0.12268771250959502
Validation loss: 2.3203314196943365

Epoch: 6| Step: 3
Training loss: 0.13081706487543435
Validation loss: 2.3147899563444745

Epoch: 6| Step: 4
Training loss: 0.11268651984175164
Validation loss: 2.3216931607321296

Epoch: 6| Step: 5
Training loss: 0.11106069970536755
Validation loss: 2.3071609486337734

Epoch: 6| Step: 6
Training loss: 0.08965326931965847
Validation loss: 2.309888121334502

Epoch: 6| Step: 7
Training loss: 0.1688025703931226
Validation loss: 2.2499100041592976

Epoch: 6| Step: 8
Training loss: 0.08572851313123277
Validation loss: 2.2730364205906035

Epoch: 6| Step: 9
Training loss: 0.13409201577193514
Validation loss: 2.269657145002439

Epoch: 6| Step: 10
Training loss: 0.11230031709874648
Validation loss: 2.259719648923479

Epoch: 6| Step: 11
Training loss: 0.16078731024046683
Validation loss: 2.2649384994232413

Epoch: 6| Step: 12
Training loss: 0.16588311236191883
Validation loss: 2.2878383202265793

Epoch: 6| Step: 13
Training loss: 0.1214107816419925
Validation loss: 2.3057799361276743

Epoch: 538| Step: 0
Training loss: 0.10672210874480235
Validation loss: 2.2928417724293966

Epoch: 6| Step: 1
Training loss: 0.08084455794335087
Validation loss: 2.3061941754200763

Epoch: 6| Step: 2
Training loss: 0.15460007489700403
Validation loss: 2.31633214758194

Epoch: 6| Step: 3
Training loss: 0.14301220905596781
Validation loss: 2.3016609537912522

Epoch: 6| Step: 4
Training loss: 0.07799320727486662
Validation loss: 2.311436504763052

Epoch: 6| Step: 5
Training loss: 0.09436550348388173
Validation loss: 2.294003318033305

Epoch: 6| Step: 6
Training loss: 0.08096276091580255
Validation loss: 2.320223943084456

Epoch: 6| Step: 7
Training loss: 0.12553623782270434
Validation loss: 2.3483321432954885

Epoch: 6| Step: 8
Training loss: 0.08055339476970899
Validation loss: 2.334853100002989

Epoch: 6| Step: 9
Training loss: 0.12044084564693164
Validation loss: 2.3095403654103857

Epoch: 6| Step: 10
Training loss: 0.11757465623573761
Validation loss: 2.3084132193319555

Epoch: 6| Step: 11
Training loss: 0.05099252162331193
Validation loss: 2.3327581961060364

Epoch: 6| Step: 12
Training loss: 0.09444161453031609
Validation loss: 2.3009942408808

Epoch: 6| Step: 13
Training loss: 0.23101035020809546
Validation loss: 2.3050058841912717

Epoch: 539| Step: 0
Training loss: 0.06180677753263955
Validation loss: 2.3176728936629405

Epoch: 6| Step: 1
Training loss: 0.10654671240225101
Validation loss: 2.266871549643952

Epoch: 6| Step: 2
Training loss: 0.09489694000956941
Validation loss: 2.2702213586788367

Epoch: 6| Step: 3
Training loss: 0.10252737251130474
Validation loss: 2.2637035353467176

Epoch: 6| Step: 4
Training loss: 0.10074491807033391
Validation loss: 2.239582123199235

Epoch: 6| Step: 5
Training loss: 0.16979768753103072
Validation loss: 2.2343329900327173

Epoch: 6| Step: 6
Training loss: 0.14501384120271937
Validation loss: 2.265983009553012

Epoch: 6| Step: 7
Training loss: 0.09033197454502284
Validation loss: 2.2876386101853807

Epoch: 6| Step: 8
Training loss: 0.16056947201046837
Validation loss: 2.2619370041668856

Epoch: 6| Step: 9
Training loss: 0.11143768507738304
Validation loss: 2.271253514954755

Epoch: 6| Step: 10
Training loss: 0.08109442759287731
Validation loss: 2.2932294631085135

Epoch: 6| Step: 11
Training loss: 0.0636695056895713
Validation loss: 2.3013898079244255

Epoch: 6| Step: 12
Training loss: 0.09902525717664094
Validation loss: 2.3242025224342013

Epoch: 6| Step: 13
Training loss: 0.15128043365100655
Validation loss: 2.2972575116050833

Epoch: 540| Step: 0
Training loss: 0.07639511114966267
Validation loss: 2.315934591433517

Epoch: 6| Step: 1
Training loss: 0.12609789424358672
Validation loss: 2.305549787583417

Epoch: 6| Step: 2
Training loss: 0.12994623428381988
Validation loss: 2.3055005902392187

Epoch: 6| Step: 3
Training loss: 0.089482238354693
Validation loss: 2.3294012812666125

Epoch: 6| Step: 4
Training loss: 0.12774526975406966
Validation loss: 2.2934215713666655

Epoch: 6| Step: 5
Training loss: 0.16451226754376094
Validation loss: 2.2931395067401343

Epoch: 6| Step: 6
Training loss: 0.10642266688810446
Validation loss: 2.291612463018296

Epoch: 6| Step: 7
Training loss: 0.08170300899653499
Validation loss: 2.2998305360631957

Epoch: 6| Step: 8
Training loss: 0.09540704743582776
Validation loss: 2.2848426751646222

Epoch: 6| Step: 9
Training loss: 0.14823010663047032
Validation loss: 2.2545346592390216

Epoch: 6| Step: 10
Training loss: 0.07800001338945635
Validation loss: 2.2794104989772874

Epoch: 6| Step: 11
Training loss: 0.09008838167547772
Validation loss: 2.262677647780871

Epoch: 6| Step: 12
Training loss: 0.11915823540532917
Validation loss: 2.2738207078397386

Epoch: 6| Step: 13
Training loss: 0.10791227071079997
Validation loss: 2.2786579653274863

Epoch: 541| Step: 0
Training loss: 0.06475924276373311
Validation loss: 2.2871290647962343

Epoch: 6| Step: 1
Training loss: 0.11459107580541773
Validation loss: 2.2848988372174044

Epoch: 6| Step: 2
Training loss: 0.15343594897976032
Validation loss: 2.274133987507904

Epoch: 6| Step: 3
Training loss: 0.13788012688849716
Validation loss: 2.3191433516003883

Epoch: 6| Step: 4
Training loss: 0.09155448911892605
Validation loss: 2.321807419533693

Epoch: 6| Step: 5
Training loss: 0.10001486168635516
Validation loss: 2.3155997846102716

Epoch: 6| Step: 6
Training loss: 0.06046227343446626
Validation loss: 2.279468787778047

Epoch: 6| Step: 7
Training loss: 0.10231408460936102
Validation loss: 2.3186911309214553

Epoch: 6| Step: 8
Training loss: 0.07956992233529034
Validation loss: 2.313406509678744

Epoch: 6| Step: 9
Training loss: 0.1028325467581294
Validation loss: 2.2947352833188197

Epoch: 6| Step: 10
Training loss: 0.14245469485747722
Validation loss: 2.3150074157426856

Epoch: 6| Step: 11
Training loss: 0.07516273808578791
Validation loss: 2.303337366056283

Epoch: 6| Step: 12
Training loss: 0.10843221894110051
Validation loss: 2.319585004488893

Epoch: 6| Step: 13
Training loss: 0.10291640469225592
Validation loss: 2.282015496870501

Epoch: 542| Step: 0
Training loss: 0.09535766063226109
Validation loss: 2.3067700481536866

Epoch: 6| Step: 1
Training loss: 0.11639073031611856
Validation loss: 2.3298000408401514

Epoch: 6| Step: 2
Training loss: 0.07822819391334511
Validation loss: 2.302314810881711

Epoch: 6| Step: 3
Training loss: 0.10350593935440361
Validation loss: 2.2841845820469984

Epoch: 6| Step: 4
Training loss: 0.09735400156624398
Validation loss: 2.272923366760495

Epoch: 6| Step: 5
Training loss: 0.16988366892325313
Validation loss: 2.3184004517700916

Epoch: 6| Step: 6
Training loss: 0.1619430746078173
Validation loss: 2.332851612521536

Epoch: 6| Step: 7
Training loss: 0.05095221094951076
Validation loss: 2.3257698335774917

Epoch: 6| Step: 8
Training loss: 0.0932342528797422
Validation loss: 2.337374136870669

Epoch: 6| Step: 9
Training loss: 0.10458741349959509
Validation loss: 2.3335567629615905

Epoch: 6| Step: 10
Training loss: 0.14307929491958477
Validation loss: 2.347253754527301

Epoch: 6| Step: 11
Training loss: 0.11062465903396647
Validation loss: 2.327460195803453

Epoch: 6| Step: 12
Training loss: 0.1643064705789715
Validation loss: 2.333776272553693

Epoch: 6| Step: 13
Training loss: 0.10022752292430694
Validation loss: 2.3197134921457483

Epoch: 543| Step: 0
Training loss: 0.1822878269517775
Validation loss: 2.330320045988696

Epoch: 6| Step: 1
Training loss: 0.10038336939141022
Validation loss: 2.307712822510831

Epoch: 6| Step: 2
Training loss: 0.0683279101300563
Validation loss: 2.2910351782779483

Epoch: 6| Step: 3
Training loss: 0.1315170528764452
Validation loss: 2.304757150717215

Epoch: 6| Step: 4
Training loss: 0.1113901885520806
Validation loss: 2.2966764664373542

Epoch: 6| Step: 5
Training loss: 0.0902503907658843
Validation loss: 2.2958040210728687

Epoch: 6| Step: 6
Training loss: 0.10374777331892747
Validation loss: 2.301423445167648

Epoch: 6| Step: 7
Training loss: 0.08660396699058015
Validation loss: 2.3165217556194104

Epoch: 6| Step: 8
Training loss: 0.13145825717664872
Validation loss: 2.2741366501986993

Epoch: 6| Step: 9
Training loss: 0.146527817959903
Validation loss: 2.285677615081585

Epoch: 6| Step: 10
Training loss: 0.15859283907398516
Validation loss: 2.242596582424998

Epoch: 6| Step: 11
Training loss: 0.10995300443907494
Validation loss: 2.2664275963115337

Epoch: 6| Step: 12
Training loss: 0.09717411232700628
Validation loss: 2.296458976995361

Epoch: 6| Step: 13
Training loss: 0.060999344810256206
Validation loss: 2.287963165305453

Epoch: 544| Step: 0
Training loss: 0.1113064895487218
Validation loss: 2.2850165273313214

Epoch: 6| Step: 1
Training loss: 0.07556809256597921
Validation loss: 2.2828010037880433

Epoch: 6| Step: 2
Training loss: 0.12715396400313048
Validation loss: 2.3026014906830876

Epoch: 6| Step: 3
Training loss: 0.09181180284747009
Validation loss: 2.3082676386796392

Epoch: 6| Step: 4
Training loss: 0.14214145732366318
Validation loss: 2.309817917506209

Epoch: 6| Step: 5
Training loss: 0.15767717059130648
Validation loss: 2.2983213526100967

Epoch: 6| Step: 6
Training loss: 0.08042742272088305
Validation loss: 2.2801424440371925

Epoch: 6| Step: 7
Training loss: 0.11269722214639427
Validation loss: 2.3168592486126363

Epoch: 6| Step: 8
Training loss: 0.18416536908606002
Validation loss: 2.294079434659956

Epoch: 6| Step: 9
Training loss: 0.10818986329428977
Validation loss: 2.2966292155398027

Epoch: 6| Step: 10
Training loss: 0.06851712485665024
Validation loss: 2.287161136853874

Epoch: 6| Step: 11
Training loss: 0.09451572807023868
Validation loss: 2.2975051157315494

Epoch: 6| Step: 12
Training loss: 0.07146097383866262
Validation loss: 2.295883165470098

Epoch: 6| Step: 13
Training loss: 0.07854205215810198
Validation loss: 2.2905165123181126

Epoch: 545| Step: 0
Training loss: 0.12220677949313385
Validation loss: 2.3120561255214613

Epoch: 6| Step: 1
Training loss: 0.11268080877526292
Validation loss: 2.327135710412731

Epoch: 6| Step: 2
Training loss: 0.07951767697893959
Validation loss: 2.320559009627327

Epoch: 6| Step: 3
Training loss: 0.0914095661996362
Validation loss: 2.3204855093578156

Epoch: 6| Step: 4
Training loss: 0.09494348641043138
Validation loss: 2.296516479209511

Epoch: 6| Step: 5
Training loss: 0.08293517244180486
Validation loss: 2.2993320579735537

Epoch: 6| Step: 6
Training loss: 0.07973936872881153
Validation loss: 2.3149286746207958

Epoch: 6| Step: 7
Training loss: 0.1456330355792979
Validation loss: 2.3104620869528807

Epoch: 6| Step: 8
Training loss: 0.12149865382384775
Validation loss: 2.3036694841773167

Epoch: 6| Step: 9
Training loss: 0.07306160281110165
Validation loss: 2.288035137750229

Epoch: 6| Step: 10
Training loss: 0.06697522120933162
Validation loss: 2.3148136271971618

Epoch: 6| Step: 11
Training loss: 0.09723731781878349
Validation loss: 2.2881446204007965

Epoch: 6| Step: 12
Training loss: 0.06470790991401022
Validation loss: 2.275533553585728

Epoch: 6| Step: 13
Training loss: 0.1671291035424419
Validation loss: 2.2791307747702665

Epoch: 546| Step: 0
Training loss: 0.0920237568021404
Validation loss: 2.300622916613377

Epoch: 6| Step: 1
Training loss: 0.08368112184860323
Validation loss: 2.2777363633916954

Epoch: 6| Step: 2
Training loss: 0.08473805537347799
Validation loss: 2.2400984217314934

Epoch: 6| Step: 3
Training loss: 0.12431395663884302
Validation loss: 2.28001709876407

Epoch: 6| Step: 4
Training loss: 0.11837371245185502
Validation loss: 2.248039516078671

Epoch: 6| Step: 5
Training loss: 0.06028154132034998
Validation loss: 2.2797808206985373

Epoch: 6| Step: 6
Training loss: 0.10701416411776339
Validation loss: 2.2588245944881113

Epoch: 6| Step: 7
Training loss: 0.053998651214346015
Validation loss: 2.2872116847677617

Epoch: 6| Step: 8
Training loss: 0.0674680191844586
Validation loss: 2.3116243096257096

Epoch: 6| Step: 9
Training loss: 0.08224044249991576
Validation loss: 2.2833198589031865

Epoch: 6| Step: 10
Training loss: 0.08160575003171712
Validation loss: 2.30066256282554

Epoch: 6| Step: 11
Training loss: 0.17193675557325167
Validation loss: 2.2950451573980906

Epoch: 6| Step: 12
Training loss: 0.15253671016662124
Validation loss: 2.314529427518082

Epoch: 6| Step: 13
Training loss: 0.10093964726493661
Validation loss: 2.2890958261757044

Epoch: 547| Step: 0
Training loss: 0.09699200267213379
Validation loss: 2.283986312514149

Epoch: 6| Step: 1
Training loss: 0.10800332151461145
Validation loss: 2.2882660373293584

Epoch: 6| Step: 2
Training loss: 0.1285309964990655
Validation loss: 2.287733414032139

Epoch: 6| Step: 3
Training loss: 0.12417152529756412
Validation loss: 2.285660014697579

Epoch: 6| Step: 4
Training loss: 0.090248192724165
Validation loss: 2.2788917758017715

Epoch: 6| Step: 5
Training loss: 0.11866473694429529
Validation loss: 2.2933610471299124

Epoch: 6| Step: 6
Training loss: 0.08194193632735726
Validation loss: 2.2800847919815284

Epoch: 6| Step: 7
Training loss: 0.1484689741897737
Validation loss: 2.292127134164609

Epoch: 6| Step: 8
Training loss: 0.08377230839073786
Validation loss: 2.31022078748245

Epoch: 6| Step: 9
Training loss: 0.10753963691316913
Validation loss: 2.3311956603683033

Epoch: 6| Step: 10
Training loss: 0.10466601272238757
Validation loss: 2.2950847212405394

Epoch: 6| Step: 11
Training loss: 0.12798955841335352
Validation loss: 2.3148317950000794

Epoch: 6| Step: 12
Training loss: 0.08594749132509681
Validation loss: 2.302426287918251

Epoch: 6| Step: 13
Training loss: 0.10774347542106462
Validation loss: 2.3346560335880953

Epoch: 548| Step: 0
Training loss: 0.10795317090279623
Validation loss: 2.300988523082878

Epoch: 6| Step: 1
Training loss: 0.13869573495328125
Validation loss: 2.3372811666484483

Epoch: 6| Step: 2
Training loss: 0.10521867031675607
Validation loss: 2.3114598946955485

Epoch: 6| Step: 3
Training loss: 0.1122733113784087
Validation loss: 2.314710297425148

Epoch: 6| Step: 4
Training loss: 0.06480527534931055
Validation loss: 2.2817806739770106

Epoch: 6| Step: 5
Training loss: 0.11189336085960062
Validation loss: 2.3207533211735543

Epoch: 6| Step: 6
Training loss: 0.17248956846575034
Validation loss: 2.2826313186410943

Epoch: 6| Step: 7
Training loss: 0.12324158461312947
Validation loss: 2.3025337357342304

Epoch: 6| Step: 8
Training loss: 0.11954388224478307
Validation loss: 2.2699865585840993

Epoch: 6| Step: 9
Training loss: 0.08024354166840524
Validation loss: 2.276317620725052

Epoch: 6| Step: 10
Training loss: 0.09311338681897043
Validation loss: 2.270707479080611

Epoch: 6| Step: 11
Training loss: 0.06460735623481959
Validation loss: 2.2730870660616627

Epoch: 6| Step: 12
Training loss: 0.12844643803053418
Validation loss: 2.292732164093474

Epoch: 6| Step: 13
Training loss: 0.07566330545506542
Validation loss: 2.2797321175684324

Epoch: 549| Step: 0
Training loss: 0.0670356376030043
Validation loss: 2.2882578739425377

Epoch: 6| Step: 1
Training loss: 0.09641844682343524
Validation loss: 2.2983780374799996

Epoch: 6| Step: 2
Training loss: 0.08744603668590552
Validation loss: 2.3090627834534665

Epoch: 6| Step: 3
Training loss: 0.12392197611372606
Validation loss: 2.306530592048274

Epoch: 6| Step: 4
Training loss: 0.12449479455555146
Validation loss: 2.297134834522715

Epoch: 6| Step: 5
Training loss: 0.0828812026296218
Validation loss: 2.289941755697687

Epoch: 6| Step: 6
Training loss: 0.09709486775511485
Validation loss: 2.3089215151602867

Epoch: 6| Step: 7
Training loss: 0.14738897121168484
Validation loss: 2.275102090601461

Epoch: 6| Step: 8
Training loss: 0.1002505925141992
Validation loss: 2.3100615840313896

Epoch: 6| Step: 9
Training loss: 0.06944423934621459
Validation loss: 2.324306030785494

Epoch: 6| Step: 10
Training loss: 0.055418216158123104
Validation loss: 2.2946805082701314

Epoch: 6| Step: 11
Training loss: 0.06784643438788371
Validation loss: 2.3078163392272626

Epoch: 6| Step: 12
Training loss: 0.10426153591534865
Validation loss: 2.2864467323336504

Epoch: 6| Step: 13
Training loss: 0.08048871658344467
Validation loss: 2.3077558139816468

Epoch: 550| Step: 0
Training loss: 0.11876851740565753
Validation loss: 2.3141357868920998

Epoch: 6| Step: 1
Training loss: 0.07512647400780968
Validation loss: 2.2872989744404397

Epoch: 6| Step: 2
Training loss: 0.11591073538266862
Validation loss: 2.2885669279741463

Epoch: 6| Step: 3
Training loss: 0.10763635464687851
Validation loss: 2.329621853412506

Epoch: 6| Step: 4
Training loss: 0.08795701274692899
Validation loss: 2.315888201710546

Epoch: 6| Step: 5
Training loss: 0.10180630215009963
Validation loss: 2.306338765386718

Epoch: 6| Step: 6
Training loss: 0.18116967871462755
Validation loss: 2.3112583413285224

Epoch: 6| Step: 7
Training loss: 0.1102614667950865
Validation loss: 2.2908819512602374

Epoch: 6| Step: 8
Training loss: 0.0603988957971799
Validation loss: 2.3511700896757244

Epoch: 6| Step: 9
Training loss: 0.11888711175654644
Validation loss: 2.328589416814699

Epoch: 6| Step: 10
Training loss: 0.0637723998027747
Validation loss: 2.3354721601798016

Epoch: 6| Step: 11
Training loss: 0.07938137719676006
Validation loss: 2.312657529104379

Epoch: 6| Step: 12
Training loss: 0.07649529704468121
Validation loss: 2.322000725140298

Epoch: 6| Step: 13
Training loss: 0.06881036492481989
Validation loss: 2.3129907667623923

Epoch: 551| Step: 0
Training loss: 0.08455284810508525
Validation loss: 2.2892628551642464

Epoch: 6| Step: 1
Training loss: 0.08339755618413665
Validation loss: 2.304873724787092

Epoch: 6| Step: 2
Training loss: 0.07208720942138216
Validation loss: 2.3319698490623186

Epoch: 6| Step: 3
Training loss: 0.14796698183495696
Validation loss: 2.3259366703173185

Epoch: 6| Step: 4
Training loss: 0.09465805506283888
Validation loss: 2.3124190152528916

Epoch: 6| Step: 5
Training loss: 0.13471312122093773
Validation loss: 2.314345202602246

Epoch: 6| Step: 6
Training loss: 0.12600021731645522
Validation loss: 2.3287052098576635

Epoch: 6| Step: 7
Training loss: 0.08286343528572475
Validation loss: 2.2934878618162426

Epoch: 6| Step: 8
Training loss: 0.17007760880601777
Validation loss: 2.307530022610282

Epoch: 6| Step: 9
Training loss: 0.0887563664207987
Validation loss: 2.2988489059992308

Epoch: 6| Step: 10
Training loss: 0.08936077373161663
Validation loss: 2.2989866254852176

Epoch: 6| Step: 11
Training loss: 0.13456682386153293
Validation loss: 2.311693458288609

Epoch: 6| Step: 12
Training loss: 0.09878951079755967
Validation loss: 2.271157934586343

Epoch: 6| Step: 13
Training loss: 0.09420063571390193
Validation loss: 2.2615575367221235

Epoch: 552| Step: 0
Training loss: 0.0882744356074153
Validation loss: 2.3072169507605373

Epoch: 6| Step: 1
Training loss: 0.07358178563873617
Validation loss: 2.267797412023661

Epoch: 6| Step: 2
Training loss: 0.07056194998224381
Validation loss: 2.2693452880856295

Epoch: 6| Step: 3
Training loss: 0.08040044626312573
Validation loss: 2.2877986960622545

Epoch: 6| Step: 4
Training loss: 0.08187691042942583
Validation loss: 2.2914870291488443

Epoch: 6| Step: 5
Training loss: 0.1273999347660775
Validation loss: 2.2965217962217435

Epoch: 6| Step: 6
Training loss: 0.14097719989864
Validation loss: 2.285097966039415

Epoch: 6| Step: 7
Training loss: 0.1304164764623301
Validation loss: 2.2924780851297553

Epoch: 6| Step: 8
Training loss: 0.12185781293504444
Validation loss: 2.283859015701547

Epoch: 6| Step: 9
Training loss: 0.11940664547243497
Validation loss: 2.2869217314012804

Epoch: 6| Step: 10
Training loss: 0.11393299147981341
Validation loss: 2.289474277234965

Epoch: 6| Step: 11
Training loss: 0.11491020722353565
Validation loss: 2.291897623574801

Epoch: 6| Step: 12
Training loss: 0.12097082898007316
Validation loss: 2.2608139883903413

Epoch: 6| Step: 13
Training loss: 0.11919017839972941
Validation loss: 2.259102116777015

Epoch: 553| Step: 0
Training loss: 0.07797345722490934
Validation loss: 2.28395126289223

Epoch: 6| Step: 1
Training loss: 0.0879679657475965
Validation loss: 2.290136848760236

Epoch: 6| Step: 2
Training loss: 0.07703884102344931
Validation loss: 2.2738857917597226

Epoch: 6| Step: 3
Training loss: 0.1250033452659248
Validation loss: 2.279069742784918

Epoch: 6| Step: 4
Training loss: 0.1215877072032019
Validation loss: 2.2653838179563714

Epoch: 6| Step: 5
Training loss: 0.09072944237958766
Validation loss: 2.2795993464942628

Epoch: 6| Step: 6
Training loss: 0.09189947461606143
Validation loss: 2.3110057822469954

Epoch: 6| Step: 7
Training loss: 0.09380549040312794
Validation loss: 2.296926839786351

Epoch: 6| Step: 8
Training loss: 0.11302425566851972
Validation loss: 2.305840263359695

Epoch: 6| Step: 9
Training loss: 0.1532855267759261
Validation loss: 2.3137534418713868

Epoch: 6| Step: 10
Training loss: 0.048305258275410545
Validation loss: 2.285209374256847

Epoch: 6| Step: 11
Training loss: 0.11108073554685312
Validation loss: 2.306221904928663

Epoch: 6| Step: 12
Training loss: 0.07442690808518272
Validation loss: 2.298625449526537

Epoch: 6| Step: 13
Training loss: 0.06394884404431558
Validation loss: 2.299276984908551

Epoch: 554| Step: 0
Training loss: 0.11519402266200995
Validation loss: 2.281839820129847

Epoch: 6| Step: 1
Training loss: 0.09451894522416407
Validation loss: 2.307452980342549

Epoch: 6| Step: 2
Training loss: 0.1408117564190611
Validation loss: 2.269211373779258

Epoch: 6| Step: 3
Training loss: 0.1330434250174305
Validation loss: 2.3034760787102746

Epoch: 6| Step: 4
Training loss: 0.12287842103681826
Validation loss: 2.2955055197374667

Epoch: 6| Step: 5
Training loss: 0.11841898210366562
Validation loss: 2.2377342559797935

Epoch: 6| Step: 6
Training loss: 0.06977480693917369
Validation loss: 2.2768166459955

Epoch: 6| Step: 7
Training loss: 0.057081198538559974
Validation loss: 2.253303728098773

Epoch: 6| Step: 8
Training loss: 0.09345643951164903
Validation loss: 2.2725968758473414

Epoch: 6| Step: 9
Training loss: 0.09199494440762598
Validation loss: 2.284118338104671

Epoch: 6| Step: 10
Training loss: 0.09719529558391192
Validation loss: 2.2947146605754023

Epoch: 6| Step: 11
Training loss: 0.05410121098207931
Validation loss: 2.3010460335445386

Epoch: 6| Step: 12
Training loss: 0.14342655899564657
Validation loss: 2.301405059564688

Epoch: 6| Step: 13
Training loss: 0.052920866069265354
Validation loss: 2.3192566825999643

Epoch: 555| Step: 0
Training loss: 0.09942823657483879
Validation loss: 2.2993184193053273

Epoch: 6| Step: 1
Training loss: 0.07181037091086222
Validation loss: 2.312198603754581

Epoch: 6| Step: 2
Training loss: 0.09459204807269013
Validation loss: 2.317922186908736

Epoch: 6| Step: 3
Training loss: 0.13856300593599102
Validation loss: 2.32149024800537

Epoch: 6| Step: 4
Training loss: 0.12478681355747745
Validation loss: 2.2855545225556746

Epoch: 6| Step: 5
Training loss: 0.06678984100270934
Validation loss: 2.3148290207494173

Epoch: 6| Step: 6
Training loss: 0.08684442977546568
Validation loss: 2.2859499797867717

Epoch: 6| Step: 7
Training loss: 0.08206321456842118
Validation loss: 2.3139535691826465

Epoch: 6| Step: 8
Training loss: 0.12254764310388633
Validation loss: 2.3142898581597704

Epoch: 6| Step: 9
Training loss: 0.0709986290092054
Validation loss: 2.305958114825002

Epoch: 6| Step: 10
Training loss: 0.11346526245608322
Validation loss: 2.287596905261312

Epoch: 6| Step: 11
Training loss: 0.14674662955847326
Validation loss: 2.2667266396521306

Epoch: 6| Step: 12
Training loss: 0.07758743593287969
Validation loss: 2.266371900126635

Epoch: 6| Step: 13
Training loss: 0.0745360968271388
Validation loss: 2.262860360095264

Epoch: 556| Step: 0
Training loss: 0.08094715545937654
Validation loss: 2.284790078158807

Epoch: 6| Step: 1
Training loss: 0.07284939662996684
Validation loss: 2.2735129711999527

Epoch: 6| Step: 2
Training loss: 0.10771430699343541
Validation loss: 2.294790164865708

Epoch: 6| Step: 3
Training loss: 0.06719235788015963
Validation loss: 2.2719835185407566

Epoch: 6| Step: 4
Training loss: 0.10995695994553471
Validation loss: 2.293642089465619

Epoch: 6| Step: 5
Training loss: 0.08688600494471603
Validation loss: 2.2929500551050888

Epoch: 6| Step: 6
Training loss: 0.1035516064565758
Validation loss: 2.2913039187912583

Epoch: 6| Step: 7
Training loss: 0.12052452212677897
Validation loss: 2.325762012915005

Epoch: 6| Step: 8
Training loss: 0.1172451592693616
Validation loss: 2.290797006108956

Epoch: 6| Step: 9
Training loss: 0.12976368481806466
Validation loss: 2.2721087642852655

Epoch: 6| Step: 10
Training loss: 0.07070104216568968
Validation loss: 2.2971857343604567

Epoch: 6| Step: 11
Training loss: 0.09875979134298929
Validation loss: 2.3026192677461967

Epoch: 6| Step: 12
Training loss: 0.1444007825949443
Validation loss: 2.2878862406694025

Epoch: 6| Step: 13
Training loss: 0.0751444873953454
Validation loss: 2.264347244816317

Epoch: 557| Step: 0
Training loss: 0.0723466097202655
Validation loss: 2.28594922727549

Epoch: 6| Step: 1
Training loss: 0.12892572660406001
Validation loss: 2.2670453392803367

Epoch: 6| Step: 2
Training loss: 0.14373163748679504
Validation loss: 2.267101721713622

Epoch: 6| Step: 3
Training loss: 0.09173998693253456
Validation loss: 2.2746501834860364

Epoch: 6| Step: 4
Training loss: 0.07573843169085501
Validation loss: 2.3021188672991326

Epoch: 6| Step: 5
Training loss: 0.10500983781083956
Validation loss: 2.2917469398407952

Epoch: 6| Step: 6
Training loss: 0.11559240841970053
Validation loss: 2.321137447193468

Epoch: 6| Step: 7
Training loss: 0.10244989150900516
Validation loss: 2.2776174337742163

Epoch: 6| Step: 8
Training loss: 0.0732735471347404
Validation loss: 2.285890786335685

Epoch: 6| Step: 9
Training loss: 0.09335642893783563
Validation loss: 2.254346673309422

Epoch: 6| Step: 10
Training loss: 0.0712260660328058
Validation loss: 2.287794052131604

Epoch: 6| Step: 11
Training loss: 0.10943274165919098
Validation loss: 2.287658576707046

Epoch: 6| Step: 12
Training loss: 0.07097024368287332
Validation loss: 2.2946106407862894

Epoch: 6| Step: 13
Training loss: 0.08082319143430657
Validation loss: 2.289309505575414

Epoch: 558| Step: 0
Training loss: 0.08912980397614065
Validation loss: 2.2614173751419107

Epoch: 6| Step: 1
Training loss: 0.10916140681376488
Validation loss: 2.3130346188528104

Epoch: 6| Step: 2
Training loss: 0.12666985379803136
Validation loss: 2.2976881547637094

Epoch: 6| Step: 3
Training loss: 0.11181586486152284
Validation loss: 2.292070762230155

Epoch: 6| Step: 4
Training loss: 0.08324292209449691
Validation loss: 2.306795034614861

Epoch: 6| Step: 5
Training loss: 0.14101807309506303
Validation loss: 2.321330826261236

Epoch: 6| Step: 6
Training loss: 0.07899314903799867
Validation loss: 2.305255819959742

Epoch: 6| Step: 7
Training loss: 0.0663182818957626
Validation loss: 2.2975497677367644

Epoch: 6| Step: 8
Training loss: 0.09150889046202708
Validation loss: 2.3166431233329723

Epoch: 6| Step: 9
Training loss: 0.09599279337862777
Validation loss: 2.309877133744921

Epoch: 6| Step: 10
Training loss: 0.07820605007688115
Validation loss: 2.30816201607558

Epoch: 6| Step: 11
Training loss: 0.13672549367349252
Validation loss: 2.3027389673694856

Epoch: 6| Step: 12
Training loss: 0.1172604135337543
Validation loss: 2.2662245509111703

Epoch: 6| Step: 13
Training loss: 0.10186014210411697
Validation loss: 2.3098252471990675

Epoch: 559| Step: 0
Training loss: 0.08402828244260473
Validation loss: 2.2759641406657862

Epoch: 6| Step: 1
Training loss: 0.1371071883241874
Validation loss: 2.3140190166346755

Epoch: 6| Step: 2
Training loss: 0.09500268628061881
Validation loss: 2.31542235119009

Epoch: 6| Step: 3
Training loss: 0.12549371373629972
Validation loss: 2.337350925098405

Epoch: 6| Step: 4
Training loss: 0.11191772468260414
Validation loss: 2.337623654623573

Epoch: 6| Step: 5
Training loss: 0.07622979786172279
Validation loss: 2.31259554837692

Epoch: 6| Step: 6
Training loss: 0.11242051164172849
Validation loss: 2.3165940083072254

Epoch: 6| Step: 7
Training loss: 0.15433044913344482
Validation loss: 2.3161850679285765

Epoch: 6| Step: 8
Training loss: 0.07271452612427128
Validation loss: 2.2902404001175767

Epoch: 6| Step: 9
Training loss: 0.07975872236904831
Validation loss: 2.2771988061692325

Epoch: 6| Step: 10
Training loss: 0.07139363196697261
Validation loss: 2.281730028219186

Epoch: 6| Step: 11
Training loss: 0.1052445572003023
Validation loss: 2.2612636694272794

Epoch: 6| Step: 12
Training loss: 0.07332681852607857
Validation loss: 2.280322913791431

Epoch: 6| Step: 13
Training loss: 0.1244092594519124
Validation loss: 2.2817026572229095

Epoch: 560| Step: 0
Training loss: 0.062312212851301785
Validation loss: 2.293007428416256

Epoch: 6| Step: 1
Training loss: 0.10866601241181498
Validation loss: 2.2887090258664715

Epoch: 6| Step: 2
Training loss: 0.12509698383707452
Validation loss: 2.296630878770044

Epoch: 6| Step: 3
Training loss: 0.08355705367113492
Validation loss: 2.302338648688055

Epoch: 6| Step: 4
Training loss: 0.1018767355700837
Validation loss: 2.316759869219009

Epoch: 6| Step: 5
Training loss: 0.07547283359994619
Validation loss: 2.2914557571533662

Epoch: 6| Step: 6
Training loss: 0.1318322781655411
Validation loss: 2.3117565677244043

Epoch: 6| Step: 7
Training loss: 0.11510944059496166
Validation loss: 2.320377640486364

Epoch: 6| Step: 8
Training loss: 0.08679931545346087
Validation loss: 2.3266715361739916

Epoch: 6| Step: 9
Training loss: 0.13139091545106446
Validation loss: 2.2985474312338225

Epoch: 6| Step: 10
Training loss: 0.08161494795825933
Validation loss: 2.310809582685614

Epoch: 6| Step: 11
Training loss: 0.09020244479323515
Validation loss: 2.2956702743853534

Epoch: 6| Step: 12
Training loss: 0.10149045828338009
Validation loss: 2.310387399970903

Epoch: 6| Step: 13
Training loss: 0.06060207450255025
Validation loss: 2.336122258646715

Epoch: 561| Step: 0
Training loss: 0.08561798867526865
Validation loss: 2.31253740390725

Epoch: 6| Step: 1
Training loss: 0.1507335320503815
Validation loss: 2.2936568052682658

Epoch: 6| Step: 2
Training loss: 0.07403501555953201
Validation loss: 2.2772240495494764

Epoch: 6| Step: 3
Training loss: 0.08218843579666077
Validation loss: 2.294662478101317

Epoch: 6| Step: 4
Training loss: 0.05581340081634916
Validation loss: 2.314058905280735

Epoch: 6| Step: 5
Training loss: 0.07688907896579414
Validation loss: 2.2637606963493515

Epoch: 6| Step: 6
Training loss: 0.07270251129312763
Validation loss: 2.277523177442885

Epoch: 6| Step: 7
Training loss: 0.15130972848399996
Validation loss: 2.285914743825082

Epoch: 6| Step: 8
Training loss: 0.06328452846488147
Validation loss: 2.277764829052655

Epoch: 6| Step: 9
Training loss: 0.09928779021001831
Validation loss: 2.309597591886055

Epoch: 6| Step: 10
Training loss: 0.09382674433782637
Validation loss: 2.309015310827818

Epoch: 6| Step: 11
Training loss: 0.07363356607592864
Validation loss: 2.311174303714399

Epoch: 6| Step: 12
Training loss: 0.12294939509251124
Validation loss: 2.308224720049051

Epoch: 6| Step: 13
Training loss: 0.0946694132869969
Validation loss: 2.3254940001692197

Epoch: 562| Step: 0
Training loss: 0.11838633148490506
Validation loss: 2.3342070857153656

Epoch: 6| Step: 1
Training loss: 0.1204749029965593
Validation loss: 2.3267952699722714

Epoch: 6| Step: 2
Training loss: 0.08422129779794246
Validation loss: 2.3334111634325176

Epoch: 6| Step: 3
Training loss: 0.10693813993640407
Validation loss: 2.2752590923941636

Epoch: 6| Step: 4
Training loss: 0.05687127751571528
Validation loss: 2.2877144712827566

Epoch: 6| Step: 5
Training loss: 0.06810089698764776
Validation loss: 2.3149051082141896

Epoch: 6| Step: 6
Training loss: 0.1477778294994876
Validation loss: 2.3136487267793897

Epoch: 6| Step: 7
Training loss: 0.1661361425188473
Validation loss: 2.2984557012563966

Epoch: 6| Step: 8
Training loss: 0.08945767753377282
Validation loss: 2.3207977396321358

Epoch: 6| Step: 9
Training loss: 0.09078029037861333
Validation loss: 2.2925512409570388

Epoch: 6| Step: 10
Training loss: 0.09819783713186231
Validation loss: 2.2838882292397664

Epoch: 6| Step: 11
Training loss: 0.09984542888549147
Validation loss: 2.293606399395927

Epoch: 6| Step: 12
Training loss: 0.09607947561419308
Validation loss: 2.295914355945522

Epoch: 6| Step: 13
Training loss: 0.11216582129998548
Validation loss: 2.282239795015839

Epoch: 563| Step: 0
Training loss: 0.07357542840010324
Validation loss: 2.318563358388737

Epoch: 6| Step: 1
Training loss: 0.06706924663689891
Validation loss: 2.3304034184825517

Epoch: 6| Step: 2
Training loss: 0.06281204111965957
Validation loss: 2.292465260617612

Epoch: 6| Step: 3
Training loss: 0.15681583945594418
Validation loss: 2.3470037297188187

Epoch: 6| Step: 4
Training loss: 0.09495693391357665
Validation loss: 2.3337789295359963

Epoch: 6| Step: 5
Training loss: 0.13469406660672098
Validation loss: 2.3589442005890024

Epoch: 6| Step: 6
Training loss: 0.08069674612539551
Validation loss: 2.3344296115536642

Epoch: 6| Step: 7
Training loss: 0.07395389002338403
Validation loss: 2.3150318401649512

Epoch: 6| Step: 8
Training loss: 0.07136819967169128
Validation loss: 2.3526907081960213

Epoch: 6| Step: 9
Training loss: 0.09630954574860207
Validation loss: 2.319985938602433

Epoch: 6| Step: 10
Training loss: 0.08658944275274821
Validation loss: 2.321308808605097

Epoch: 6| Step: 11
Training loss: 0.12205056221451367
Validation loss: 2.3140498557533307

Epoch: 6| Step: 12
Training loss: 0.06694267795697294
Validation loss: 2.290177436578613

Epoch: 6| Step: 13
Training loss: 0.08257542359436625
Validation loss: 2.3208629178633164

Epoch: 564| Step: 0
Training loss: 0.08289722761936323
Validation loss: 2.278418493693527

Epoch: 6| Step: 1
Training loss: 0.11196546738758358
Validation loss: 2.292159181585686

Epoch: 6| Step: 2
Training loss: 0.13803595484064207
Validation loss: 2.2792322948395736

Epoch: 6| Step: 3
Training loss: 0.12731091626015115
Validation loss: 2.287356221067922

Epoch: 6| Step: 4
Training loss: 0.08842109495163687
Validation loss: 2.2614854119878314

Epoch: 6| Step: 5
Training loss: 0.08069366461483635
Validation loss: 2.3070647706983785

Epoch: 6| Step: 6
Training loss: 0.10543866081537204
Validation loss: 2.2968283224312276

Epoch: 6| Step: 7
Training loss: 0.14166587158522298
Validation loss: 2.304712684789908

Epoch: 6| Step: 8
Training loss: 0.08254546260257228
Validation loss: 2.304180638894122

Epoch: 6| Step: 9
Training loss: 0.11552270684888634
Validation loss: 2.345377201191501

Epoch: 6| Step: 10
Training loss: 0.08861815488990661
Validation loss: 2.3062283434182995

Epoch: 6| Step: 11
Training loss: 0.15487201552020885
Validation loss: 2.320196747754047

Epoch: 6| Step: 12
Training loss: 0.07315127134145603
Validation loss: 2.3096235173272004

Epoch: 6| Step: 13
Training loss: 0.13456872017282367
Validation loss: 2.3110529399892936

Epoch: 565| Step: 0
Training loss: 0.08932132798312223
Validation loss: 2.3227880872643025

Epoch: 6| Step: 1
Training loss: 0.0883487523521093
Validation loss: 2.3095502418100904

Epoch: 6| Step: 2
Training loss: 0.16471538178291828
Validation loss: 2.291687356924437

Epoch: 6| Step: 3
Training loss: 0.10338352879867256
Validation loss: 2.290588299608743

Epoch: 6| Step: 4
Training loss: 0.11853139701962877
Validation loss: 2.2829649498797333

Epoch: 6| Step: 5
Training loss: 0.11960763547543105
Validation loss: 2.260783509421413

Epoch: 6| Step: 6
Training loss: 0.0643536131827203
Validation loss: 2.28816517071259

Epoch: 6| Step: 7
Training loss: 0.1008646076922256
Validation loss: 2.3083210962093412

Epoch: 6| Step: 8
Training loss: 0.12142036981230177
Validation loss: 2.34378289859338

Epoch: 6| Step: 9
Training loss: 0.14902606776804794
Validation loss: 2.353339190212469

Epoch: 6| Step: 10
Training loss: 0.13613049109735892
Validation loss: 2.3589587111588064

Epoch: 6| Step: 11
Training loss: 0.0956380632693424
Validation loss: 2.3812312411714176

Epoch: 6| Step: 12
Training loss: 0.15945236277830296
Validation loss: 2.3720024527195167

Epoch: 6| Step: 13
Training loss: 0.18760430891641253
Validation loss: 2.365849844794791

Epoch: 566| Step: 0
Training loss: 0.10339543724823277
Validation loss: 2.3500603096247956

Epoch: 6| Step: 1
Training loss: 0.07226764830772518
Validation loss: 2.2895166784455743

Epoch: 6| Step: 2
Training loss: 0.10783380508691229
Validation loss: 2.283119446376614

Epoch: 6| Step: 3
Training loss: 0.136062470628843
Validation loss: 2.2869543705021176

Epoch: 6| Step: 4
Training loss: 0.12695382924984955
Validation loss: 2.2397865279545197

Epoch: 6| Step: 5
Training loss: 0.13711199065101742
Validation loss: 2.2473915400540285

Epoch: 6| Step: 6
Training loss: 0.20858975167317895
Validation loss: 2.269128515301293

Epoch: 6| Step: 7
Training loss: 0.15785221341382885
Validation loss: 2.2878292583087436

Epoch: 6| Step: 8
Training loss: 0.08221736865621326
Validation loss: 2.2932372605676514

Epoch: 6| Step: 9
Training loss: 0.15017206237768577
Validation loss: 2.3430412965634178

Epoch: 6| Step: 10
Training loss: 0.10689145830094755
Validation loss: 2.3604277335021906

Epoch: 6| Step: 11
Training loss: 0.13047853250434194
Validation loss: 2.361687819447918

Epoch: 6| Step: 12
Training loss: 0.07546805484621376
Validation loss: 2.377037230271192

Epoch: 6| Step: 13
Training loss: 0.18054464362765796
Validation loss: 2.3784780482836667

Epoch: 567| Step: 0
Training loss: 0.1252644394157902
Validation loss: 2.393203758961751

Epoch: 6| Step: 1
Training loss: 0.23273792736649979
Validation loss: 2.395730063917741

Epoch: 6| Step: 2
Training loss: 0.14464160211799068
Validation loss: 2.377440051341581

Epoch: 6| Step: 3
Training loss: 0.08725282197350215
Validation loss: 2.3896276063738324

Epoch: 6| Step: 4
Training loss: 0.13024846571111992
Validation loss: 2.341039649960546

Epoch: 6| Step: 5
Training loss: 0.10602536612829519
Validation loss: 2.31276506691316

Epoch: 6| Step: 6
Training loss: 0.12758978613442895
Validation loss: 2.3063306253971443

Epoch: 6| Step: 7
Training loss: 0.13071304651877363
Validation loss: 2.276304353782681

Epoch: 6| Step: 8
Training loss: 0.20065258185612234
Validation loss: 2.248955795375644

Epoch: 6| Step: 9
Training loss: 0.1278281864785808
Validation loss: 2.283024858129053

Epoch: 6| Step: 10
Training loss: 0.0911000568241587
Validation loss: 2.2454778114037084

Epoch: 6| Step: 11
Training loss: 0.14543406006302656
Validation loss: 2.2711428686921877

Epoch: 6| Step: 12
Training loss: 0.11664730976518448
Validation loss: 2.223324385172983

Epoch: 6| Step: 13
Training loss: 0.13819553606708676
Validation loss: 2.253088219539432

Epoch: 568| Step: 0
Training loss: 0.1639822241254526
Validation loss: 2.2558191675229695

Epoch: 6| Step: 1
Training loss: 0.1766432712429264
Validation loss: 2.2586709779262217

Epoch: 6| Step: 2
Training loss: 0.09145350864772468
Validation loss: 2.2929458836440095

Epoch: 6| Step: 3
Training loss: 0.12065997803117391
Validation loss: 2.318009784410386

Epoch: 6| Step: 4
Training loss: 0.12715553873275237
Validation loss: 2.3192877063064827

Epoch: 6| Step: 5
Training loss: 0.15008652893397845
Validation loss: 2.3672769229697987

Epoch: 6| Step: 6
Training loss: 0.265286047035728
Validation loss: 2.3301523480778292

Epoch: 6| Step: 7
Training loss: 0.11892708417905765
Validation loss: 2.301553288680486

Epoch: 6| Step: 8
Training loss: 0.08139827877325401
Validation loss: 2.284914465966267

Epoch: 6| Step: 9
Training loss: 0.12967291342042214
Validation loss: 2.2442992992586923

Epoch: 6| Step: 10
Training loss: 0.18518632692795253
Validation loss: 2.180910968321769

Epoch: 6| Step: 11
Training loss: 0.1705416142276581
Validation loss: 2.1893276742047396

Epoch: 6| Step: 12
Training loss: 0.21333353533555194
Validation loss: 2.173685995691632

Epoch: 6| Step: 13
Training loss: 0.10286637246310294
Validation loss: 2.2010065088263957

Epoch: 569| Step: 0
Training loss: 0.11214230449227292
Validation loss: 2.2353062437732705

Epoch: 6| Step: 1
Training loss: 0.10989065888804479
Validation loss: 2.284390298420608

Epoch: 6| Step: 2
Training loss: 0.11429808387847139
Validation loss: 2.3129447414007323

Epoch: 6| Step: 3
Training loss: 0.14372270184968927
Validation loss: 2.361938904039236

Epoch: 6| Step: 4
Training loss: 0.15180240942996057
Validation loss: 2.379763291911704

Epoch: 6| Step: 5
Training loss: 0.1445347875729211
Validation loss: 2.377125478180027

Epoch: 6| Step: 6
Training loss: 0.095051674537128
Validation loss: 2.3720590957973995

Epoch: 6| Step: 7
Training loss: 0.14489521130918062
Validation loss: 2.3449101235500476

Epoch: 6| Step: 8
Training loss: 0.11109129074717243
Validation loss: 2.3507347450245795

Epoch: 6| Step: 9
Training loss: 0.09743270082748608
Validation loss: 2.3153538431499587

Epoch: 6| Step: 10
Training loss: 0.11770398051377505
Validation loss: 2.3152450890888696

Epoch: 6| Step: 11
Training loss: 0.16378927185787592
Validation loss: 2.2547450398376787

Epoch: 6| Step: 12
Training loss: 0.09812317800956336
Validation loss: 2.2626124431411827

Epoch: 6| Step: 13
Training loss: 0.12593301863305184
Validation loss: 2.2626946468606244

Epoch: 570| Step: 0
Training loss: 0.1371701010965096
Validation loss: 2.2387067954399282

Epoch: 6| Step: 1
Training loss: 0.13959462122563107
Validation loss: 2.2290943487851718

Epoch: 6| Step: 2
Training loss: 0.1016519272008577
Validation loss: 2.231973252329399

Epoch: 6| Step: 3
Training loss: 0.14496688657871712
Validation loss: 2.2473185155010924

Epoch: 6| Step: 4
Training loss: 0.15128512465288949
Validation loss: 2.2729888948151826

Epoch: 6| Step: 5
Training loss: 0.07477399841443369
Validation loss: 2.2863558467048044

Epoch: 6| Step: 6
Training loss: 0.09899579194576866
Validation loss: 2.292068001254872

Epoch: 6| Step: 7
Training loss: 0.07793341032615309
Validation loss: 2.2879765002221837

Epoch: 6| Step: 8
Training loss: 0.15873056368791538
Validation loss: 2.309147294258255

Epoch: 6| Step: 9
Training loss: 0.12407767243897852
Validation loss: 2.296286451665436

Epoch: 6| Step: 10
Training loss: 0.13495342327569468
Validation loss: 2.2996535274762384

Epoch: 6| Step: 11
Training loss: 0.14064260213678734
Validation loss: 2.3089814710809327

Epoch: 6| Step: 12
Training loss: 0.07822686647188283
Validation loss: 2.3129181576656137

Epoch: 6| Step: 13
Training loss: 0.0939743813887844
Validation loss: 2.3254371924477217

Epoch: 571| Step: 0
Training loss: 0.13520068281695374
Validation loss: 2.3274374733522074

Epoch: 6| Step: 1
Training loss: 0.08825339578384586
Validation loss: 2.3443568548101306

Epoch: 6| Step: 2
Training loss: 0.09864722514840678
Validation loss: 2.307855611094619

Epoch: 6| Step: 3
Training loss: 0.10727034632022837
Validation loss: 2.3285897492989966

Epoch: 6| Step: 4
Training loss: 0.10927368052242782
Validation loss: 2.353636699862903

Epoch: 6| Step: 5
Training loss: 0.16461720809621386
Validation loss: 2.3272081334184413

Epoch: 6| Step: 6
Training loss: 0.1447686359444429
Validation loss: 2.2870876270273666

Epoch: 6| Step: 7
Training loss: 0.11224200116302238
Validation loss: 2.24435091303862

Epoch: 6| Step: 8
Training loss: 0.1562544285623479
Validation loss: 2.256722698019853

Epoch: 6| Step: 9
Training loss: 0.0961140355354018
Validation loss: 2.2276776799478664

Epoch: 6| Step: 10
Training loss: 0.13578796300985582
Validation loss: 2.179045497771209

Epoch: 6| Step: 11
Training loss: 0.1372332157658058
Validation loss: 2.210697434832239

Epoch: 6| Step: 12
Training loss: 0.14918125939870802
Validation loss: 2.212365103826366

Epoch: 6| Step: 13
Training loss: 0.11305808002563585
Validation loss: 2.2123266227824945

Epoch: 572| Step: 0
Training loss: 0.14572972778374071
Validation loss: 2.2820577726705147

Epoch: 6| Step: 1
Training loss: 0.16612938181126413
Validation loss: 2.2716723065700544

Epoch: 6| Step: 2
Training loss: 0.07785502217458357
Validation loss: 2.3118246334473667

Epoch: 6| Step: 3
Training loss: 0.1265162580690284
Validation loss: 2.3223824155451376

Epoch: 6| Step: 4
Training loss: 0.15031460289663848
Validation loss: 2.364556611689681

Epoch: 6| Step: 5
Training loss: 0.22729261091882902
Validation loss: 2.3787151428089404

Epoch: 6| Step: 6
Training loss: 0.12297095499764045
Validation loss: 2.388053708541222

Epoch: 6| Step: 7
Training loss: 0.16348416710670552
Validation loss: 2.416297552019638

Epoch: 6| Step: 8
Training loss: 0.116631927402298
Validation loss: 2.3648736811705673

Epoch: 6| Step: 9
Training loss: 0.16574087970009996
Validation loss: 2.3648017772280805

Epoch: 6| Step: 10
Training loss: 0.1705949977725003
Validation loss: 2.3736924650807043

Epoch: 6| Step: 11
Training loss: 0.10960819300165814
Validation loss: 2.331522685871531

Epoch: 6| Step: 12
Training loss: 0.0971759524492057
Validation loss: 2.281829818735906

Epoch: 6| Step: 13
Training loss: 0.07649278897421163
Validation loss: 2.260702619975117

Epoch: 573| Step: 0
Training loss: 0.21736099119931274
Validation loss: 2.2466550937197622

Epoch: 6| Step: 1
Training loss: 0.2193614469319349
Validation loss: 2.229118736134381

Epoch: 6| Step: 2
Training loss: 0.11739746199101203
Validation loss: 2.2581524155028627

Epoch: 6| Step: 3
Training loss: 0.09592066582966058
Validation loss: 2.2281134134245133

Epoch: 6| Step: 4
Training loss: 0.08046789793841153
Validation loss: 2.262836802026103

Epoch: 6| Step: 5
Training loss: 0.16154064239055546
Validation loss: 2.2880470509580486

Epoch: 6| Step: 6
Training loss: 0.12098266520887632
Validation loss: 2.3321776798688103

Epoch: 6| Step: 7
Training loss: 0.07635053748263719
Validation loss: 2.340137820459235

Epoch: 6| Step: 8
Training loss: 0.09822575448778742
Validation loss: 2.3814081000167215

Epoch: 6| Step: 9
Training loss: 0.19027727336615588
Validation loss: 2.3904830393959022

Epoch: 6| Step: 10
Training loss: 0.11848758514172654
Validation loss: 2.4014340285357245

Epoch: 6| Step: 11
Training loss: 0.13554589054068975
Validation loss: 2.387221021544967

Epoch: 6| Step: 12
Training loss: 0.12826823073240542
Validation loss: 2.3946646266610836

Epoch: 6| Step: 13
Training loss: 0.11130738901803984
Validation loss: 2.4018032450036153

Epoch: 574| Step: 0
Training loss: 0.14242412140581787
Validation loss: 2.358785187064554

Epoch: 6| Step: 1
Training loss: 0.13627291602597139
Validation loss: 2.3399611499149673

Epoch: 6| Step: 2
Training loss: 0.14581492994763368
Validation loss: 2.3524100900942497

Epoch: 6| Step: 3
Training loss: 0.11752414826802841
Validation loss: 2.3124179975209818

Epoch: 6| Step: 4
Training loss: 0.18576592013970686
Validation loss: 2.305209459446208

Epoch: 6| Step: 5
Training loss: 0.15246262558460186
Validation loss: 2.300980110139644

Epoch: 6| Step: 6
Training loss: 0.10924443899225803
Validation loss: 2.282867323576821

Epoch: 6| Step: 7
Training loss: 0.06113033312501531
Validation loss: 2.289897821866488

Epoch: 6| Step: 8
Training loss: 0.09872701131349328
Validation loss: 2.265735816154919

Epoch: 6| Step: 9
Training loss: 0.08780234459701505
Validation loss: 2.2842356683254277

Epoch: 6| Step: 10
Training loss: 0.11540173645603491
Validation loss: 2.296352410455985

Epoch: 6| Step: 11
Training loss: 0.11317880701009721
Validation loss: 2.2786601316410677

Epoch: 6| Step: 12
Training loss: 0.19288386049147777
Validation loss: 2.261918731127883

Epoch: 6| Step: 13
Training loss: 0.09782711816363132
Validation loss: 2.2943582660017885

Epoch: 575| Step: 0
Training loss: 0.13095716125117712
Validation loss: 2.298308185913147

Epoch: 6| Step: 1
Training loss: 0.08414009539473818
Validation loss: 2.2991704034726053

Epoch: 6| Step: 2
Training loss: 0.0782286730963218
Validation loss: 2.2859983250333875

Epoch: 6| Step: 3
Training loss: 0.10375490962614346
Validation loss: 2.3243977409607637

Epoch: 6| Step: 4
Training loss: 0.09152797109761626
Validation loss: 2.2936234749465583

Epoch: 6| Step: 5
Training loss: 0.1627232636326994
Validation loss: 2.33514126398842

Epoch: 6| Step: 6
Training loss: 0.09420019081653466
Validation loss: 2.3126460829924684

Epoch: 6| Step: 7
Training loss: 0.08657677709159796
Validation loss: 2.3024775785029408

Epoch: 6| Step: 8
Training loss: 0.0979571237540452
Validation loss: 2.314610243172236

Epoch: 6| Step: 9
Training loss: 0.14449762906988808
Validation loss: 2.304069112106181

Epoch: 6| Step: 10
Training loss: 0.1190055683582759
Validation loss: 2.3452576456771532

Epoch: 6| Step: 11
Training loss: 0.09891054501179718
Validation loss: 2.353732169613234

Epoch: 6| Step: 12
Training loss: 0.14261526120592477
Validation loss: 2.335115988542834

Epoch: 6| Step: 13
Training loss: 0.11554878387396161
Validation loss: 2.3413999428874

Epoch: 576| Step: 0
Training loss: 0.10146148408058298
Validation loss: 2.3382775705956527

Epoch: 6| Step: 1
Training loss: 0.14950465279693947
Validation loss: 2.3563079718486324

Epoch: 6| Step: 2
Training loss: 0.05270327869797752
Validation loss: 2.3240150523024528

Epoch: 6| Step: 3
Training loss: 0.10918725026778478
Validation loss: 2.3473766442203354

Epoch: 6| Step: 4
Training loss: 0.15792469554581612
Validation loss: 2.349032407123407

Epoch: 6| Step: 5
Training loss: 0.10756710811931398
Validation loss: 2.3059877632433032

Epoch: 6| Step: 6
Training loss: 0.07500278298857213
Validation loss: 2.2999801557308115

Epoch: 6| Step: 7
Training loss: 0.11200285030866775
Validation loss: 2.299652733185165

Epoch: 6| Step: 8
Training loss: 0.06352688188730356
Validation loss: 2.3009651971723595

Epoch: 6| Step: 9
Training loss: 0.1133612481822828
Validation loss: 2.24531098481901

Epoch: 6| Step: 10
Training loss: 0.10282571325790926
Validation loss: 2.2467866657870457

Epoch: 6| Step: 11
Training loss: 0.07867620745532494
Validation loss: 2.2258328321453913

Epoch: 6| Step: 12
Training loss: 0.07902261833052956
Validation loss: 2.230304913499828

Epoch: 6| Step: 13
Training loss: 0.09691790891776718
Validation loss: 2.2216879980163307

Epoch: 577| Step: 0
Training loss: 0.04344389347195207
Validation loss: 2.241056432743923

Epoch: 6| Step: 1
Training loss: 0.09967295169801933
Validation loss: 2.2606614323743335

Epoch: 6| Step: 2
Training loss: 0.0697677724268542
Validation loss: 2.261964162690674

Epoch: 6| Step: 3
Training loss: 0.08489718182590797
Validation loss: 2.2834835117699477

Epoch: 6| Step: 4
Training loss: 0.055362291241886574
Validation loss: 2.2775316432646933

Epoch: 6| Step: 5
Training loss: 0.1103114333655037
Validation loss: 2.3043516075231927

Epoch: 6| Step: 6
Training loss: 0.049984625598390175
Validation loss: 2.3235375293706593

Epoch: 6| Step: 7
Training loss: 0.09078716370432188
Validation loss: 2.3003487430030116

Epoch: 6| Step: 8
Training loss: 0.07456117615999422
Validation loss: 2.299148492499727

Epoch: 6| Step: 9
Training loss: 0.12257290182904841
Validation loss: 2.3069418372495645

Epoch: 6| Step: 10
Training loss: 0.1339962531404854
Validation loss: 2.320505238547963

Epoch: 6| Step: 11
Training loss: 0.1335625645561937
Validation loss: 2.3364191664755984

Epoch: 6| Step: 12
Training loss: 0.0939088806285313
Validation loss: 2.3297630791393527

Epoch: 6| Step: 13
Training loss: 0.1128123378224145
Validation loss: 2.330027249436698

Epoch: 578| Step: 0
Training loss: 0.09212267665573111
Validation loss: 2.303575831419861

Epoch: 6| Step: 1
Training loss: 0.11985555703789887
Validation loss: 2.312542069930178

Epoch: 6| Step: 2
Training loss: 0.11808678567085193
Validation loss: 2.302024135256275

Epoch: 6| Step: 3
Training loss: 0.08774000348085222
Validation loss: 2.308248644537971

Epoch: 6| Step: 4
Training loss: 0.06813943084496171
Validation loss: 2.289591932026342

Epoch: 6| Step: 5
Training loss: 0.05917598213895985
Validation loss: 2.288875834431815

Epoch: 6| Step: 6
Training loss: 0.09524931161517851
Validation loss: 2.279793608049612

Epoch: 6| Step: 7
Training loss: 0.04745550860449814
Validation loss: 2.2655928991728906

Epoch: 6| Step: 8
Training loss: 0.08024537832849911
Validation loss: 2.3006624057084784

Epoch: 6| Step: 9
Training loss: 0.06159642030870739
Validation loss: 2.277448206101522

Epoch: 6| Step: 10
Training loss: 0.08001068520247402
Validation loss: 2.2869913021626234

Epoch: 6| Step: 11
Training loss: 0.07701668474428336
Validation loss: 2.274024424998569

Epoch: 6| Step: 12
Training loss: 0.13839853237750716
Validation loss: 2.269175289855103

Epoch: 6| Step: 13
Training loss: 0.06890768450802984
Validation loss: 2.291600546530892

Epoch: 579| Step: 0
Training loss: 0.06212293608785085
Validation loss: 2.290594651934547

Epoch: 6| Step: 1
Training loss: 0.07112480208548713
Validation loss: 2.2518133162334344

Epoch: 6| Step: 2
Training loss: 0.06817722917528536
Validation loss: 2.285878780580539

Epoch: 6| Step: 3
Training loss: 0.07675126001670375
Validation loss: 2.267434386277611

Epoch: 6| Step: 4
Training loss: 0.062076427834861704
Validation loss: 2.2671370595313

Epoch: 6| Step: 5
Training loss: 0.0978435198967883
Validation loss: 2.2644398037275653

Epoch: 6| Step: 6
Training loss: 0.08955358211750629
Validation loss: 2.267393974761982

Epoch: 6| Step: 7
Training loss: 0.12451904499715204
Validation loss: 2.262224062197094

Epoch: 6| Step: 8
Training loss: 0.13049686808454444
Validation loss: 2.2836719938442833

Epoch: 6| Step: 9
Training loss: 0.07874363700387167
Validation loss: 2.288502522311436

Epoch: 6| Step: 10
Training loss: 0.13404875284683362
Validation loss: 2.2821945626346145

Epoch: 6| Step: 11
Training loss: 0.08493835598557802
Validation loss: 2.2897292963526428

Epoch: 6| Step: 12
Training loss: 0.08717727452478735
Validation loss: 2.284944979277041

Epoch: 6| Step: 13
Training loss: 0.10105256756334662
Validation loss: 2.286922791587353

Epoch: 580| Step: 0
Training loss: 0.13017096857559626
Validation loss: 2.290908080666693

Epoch: 6| Step: 1
Training loss: 0.06609319779095482
Validation loss: 2.306626724460101

Epoch: 6| Step: 2
Training loss: 0.06502894188205004
Validation loss: 2.3117097032443428

Epoch: 6| Step: 3
Training loss: 0.09303993797386843
Validation loss: 2.324397220379241

Epoch: 6| Step: 4
Training loss: 0.0834913977479175
Validation loss: 2.322965810057175

Epoch: 6| Step: 5
Training loss: 0.051836945212054744
Validation loss: 2.3181060064556207

Epoch: 6| Step: 6
Training loss: 0.07193953167211432
Validation loss: 2.3093238598998376

Epoch: 6| Step: 7
Training loss: 0.1313759160041634
Validation loss: 2.3364184653314566

Epoch: 6| Step: 8
Training loss: 0.12142417035346614
Validation loss: 2.3239213887860957

Epoch: 6| Step: 9
Training loss: 0.06773856829826663
Validation loss: 2.3170089121697193

Epoch: 6| Step: 10
Training loss: 0.08368632469195936
Validation loss: 2.307204130393634

Epoch: 6| Step: 11
Training loss: 0.06256885758784053
Validation loss: 2.293664208960101

Epoch: 6| Step: 12
Training loss: 0.15093443135879872
Validation loss: 2.302657620398928

Epoch: 6| Step: 13
Training loss: 0.05259510918734882
Validation loss: 2.280142087623431

Epoch: 581| Step: 0
Training loss: 0.09572562614928785
Validation loss: 2.281188778597291

Epoch: 6| Step: 1
Training loss: 0.06756194463968299
Validation loss: 2.2936622350916975

Epoch: 6| Step: 2
Training loss: 0.07627784253893725
Validation loss: 2.2934555649671644

Epoch: 6| Step: 3
Training loss: 0.07466422518885771
Validation loss: 2.2644124498821157

Epoch: 6| Step: 4
Training loss: 0.07592625325221038
Validation loss: 2.276069769532468

Epoch: 6| Step: 5
Training loss: 0.1436152557482184
Validation loss: 2.2581322562037602

Epoch: 6| Step: 6
Training loss: 0.09664920364827374
Validation loss: 2.2864332472187727

Epoch: 6| Step: 7
Training loss: 0.08499935531196419
Validation loss: 2.266464637925308

Epoch: 6| Step: 8
Training loss: 0.06846581755016486
Validation loss: 2.2849385840368037

Epoch: 6| Step: 9
Training loss: 0.06270370961935522
Validation loss: 2.2756777777275072

Epoch: 6| Step: 10
Training loss: 0.11394259996556229
Validation loss: 2.282233082725054

Epoch: 6| Step: 11
Training loss: 0.10468595133532685
Validation loss: 2.287601295060566

Epoch: 6| Step: 12
Training loss: 0.07753397182597935
Validation loss: 2.3179120193542833

Epoch: 6| Step: 13
Training loss: 0.1323488852958192
Validation loss: 2.288711456536846

Epoch: 582| Step: 0
Training loss: 0.08437984251766723
Validation loss: 2.3156107079575783

Epoch: 6| Step: 1
Training loss: 0.12869481606596994
Validation loss: 2.3184863681711048

Epoch: 6| Step: 2
Training loss: 0.09100615038693734
Validation loss: 2.336730610577273

Epoch: 6| Step: 3
Training loss: 0.10211324833278068
Validation loss: 2.346851303631785

Epoch: 6| Step: 4
Training loss: 0.0747805308637382
Validation loss: 2.3320377898252085

Epoch: 6| Step: 5
Training loss: 0.10995118756882402
Validation loss: 2.3585875572387933

Epoch: 6| Step: 6
Training loss: 0.05808132936429548
Validation loss: 2.365029265913759

Epoch: 6| Step: 7
Training loss: 0.13511215797232445
Validation loss: 2.350902828014045

Epoch: 6| Step: 8
Training loss: 0.07425392722651741
Validation loss: 2.3377588979463844

Epoch: 6| Step: 9
Training loss: 0.1688152429943247
Validation loss: 2.355101768745036

Epoch: 6| Step: 10
Training loss: 0.08503498489914259
Validation loss: 2.3317723014948757

Epoch: 6| Step: 11
Training loss: 0.09784140200982151
Validation loss: 2.3460714207111746

Epoch: 6| Step: 12
Training loss: 0.11016224767035333
Validation loss: 2.3204233543520836

Epoch: 6| Step: 13
Training loss: 0.07855282704005868
Validation loss: 2.278184699913605

Epoch: 583| Step: 0
Training loss: 0.09921318624320886
Validation loss: 2.29781882408994

Epoch: 6| Step: 1
Training loss: 0.1515906376626334
Validation loss: 2.2833219871107353

Epoch: 6| Step: 2
Training loss: 0.06788327773254475
Validation loss: 2.290522984881296

Epoch: 6| Step: 3
Training loss: 0.10315312034674876
Validation loss: 2.2992060548402184

Epoch: 6| Step: 4
Training loss: 0.1140613129632401
Validation loss: 2.2891544518304143

Epoch: 6| Step: 5
Training loss: 0.09493847376114971
Validation loss: 2.314420280259836

Epoch: 6| Step: 6
Training loss: 0.07484974039788608
Validation loss: 2.3029521100348633

Epoch: 6| Step: 7
Training loss: 0.11756126482531182
Validation loss: 2.2922891914203474

Epoch: 6| Step: 8
Training loss: 0.1192257452021215
Validation loss: 2.315808700403181

Epoch: 6| Step: 9
Training loss: 0.10159185792187206
Validation loss: 2.308377544408682

Epoch: 6| Step: 10
Training loss: 0.08469800438344866
Validation loss: 2.3015971503974906

Epoch: 6| Step: 11
Training loss: 0.07097220878285751
Validation loss: 2.3275743380958

Epoch: 6| Step: 12
Training loss: 0.07205708480543786
Validation loss: 2.308607459910332

Epoch: 6| Step: 13
Training loss: 0.22444127468131367
Validation loss: 2.313709884288435

Epoch: 584| Step: 0
Training loss: 0.07298812352225452
Validation loss: 2.3454122728884443

Epoch: 6| Step: 1
Training loss: 0.0501636861921596
Validation loss: 2.296720901263366

Epoch: 6| Step: 2
Training loss: 0.10229612363414389
Validation loss: 2.296997935381718

Epoch: 6| Step: 3
Training loss: 0.0953873611988447
Validation loss: 2.263020135881368

Epoch: 6| Step: 4
Training loss: 0.14585001600302686
Validation loss: 2.255953535879439

Epoch: 6| Step: 5
Training loss: 0.10390804242617337
Validation loss: 2.267179573190923

Epoch: 6| Step: 6
Training loss: 0.10123400106271203
Validation loss: 2.272751927260712

Epoch: 6| Step: 7
Training loss: 0.15190228050411703
Validation loss: 2.288012904451688

Epoch: 6| Step: 8
Training loss: 0.08993748771257827
Validation loss: 2.295495870489641

Epoch: 6| Step: 9
Training loss: 0.14520014808449536
Validation loss: 2.2874540542120605

Epoch: 6| Step: 10
Training loss: 0.1680616687326383
Validation loss: 2.3017870890072074

Epoch: 6| Step: 11
Training loss: 0.1578579775746407
Validation loss: 2.313616892257008

Epoch: 6| Step: 12
Training loss: 0.09555717939830188
Validation loss: 2.30330460934277

Epoch: 6| Step: 13
Training loss: 0.0955658677704011
Validation loss: 2.319835701276083

Epoch: 585| Step: 0
Training loss: 0.11952535857847181
Validation loss: 2.3309293227333607

Epoch: 6| Step: 1
Training loss: 0.09892450296041162
Validation loss: 2.336493405367395

Epoch: 6| Step: 2
Training loss: 0.10988620518892576
Validation loss: 2.358940814196924

Epoch: 6| Step: 3
Training loss: 0.11644816028192875
Validation loss: 2.3340669784588717

Epoch: 6| Step: 4
Training loss: 0.06483202161775653
Validation loss: 2.3217066685139476

Epoch: 6| Step: 5
Training loss: 0.07409563016698092
Validation loss: 2.348801028988505

Epoch: 6| Step: 6
Training loss: 0.13537984968033304
Validation loss: 2.3419423500017054

Epoch: 6| Step: 7
Training loss: 0.10001455439510207
Validation loss: 2.326338112067345

Epoch: 6| Step: 8
Training loss: 0.08991639683174453
Validation loss: 2.310901888939938

Epoch: 6| Step: 9
Training loss: 0.14649735075382833
Validation loss: 2.3049046317672754

Epoch: 6| Step: 10
Training loss: 0.07327200600490393
Validation loss: 2.282398716255055

Epoch: 6| Step: 11
Training loss: 0.0920175780550427
Validation loss: 2.2773134005140787

Epoch: 6| Step: 12
Training loss: 0.07206265194298705
Validation loss: 2.277291185244521

Epoch: 6| Step: 13
Training loss: 0.17121812619525406
Validation loss: 2.275184774349442

Epoch: 586| Step: 0
Training loss: 0.06414257720318162
Validation loss: 2.2956423883862893

Epoch: 6| Step: 1
Training loss: 0.03360347225925848
Validation loss: 2.287951969338536

Epoch: 6| Step: 2
Training loss: 0.058253234615763046
Validation loss: 2.2975879974743445

Epoch: 6| Step: 3
Training loss: 0.08852505060499889
Validation loss: 2.2724283488570776

Epoch: 6| Step: 4
Training loss: 0.09859887096206436
Validation loss: 2.3006924683585446

Epoch: 6| Step: 5
Training loss: 0.16958641503925337
Validation loss: 2.3110903384753114

Epoch: 6| Step: 6
Training loss: 0.06363337294657832
Validation loss: 2.2837508436134617

Epoch: 6| Step: 7
Training loss: 0.08149836228157167
Validation loss: 2.3250909655185805

Epoch: 6| Step: 8
Training loss: 0.10987274976830376
Validation loss: 2.2887933739395665

Epoch: 6| Step: 9
Training loss: 0.11440398981018148
Validation loss: 2.3134045160855425

Epoch: 6| Step: 10
Training loss: 0.08356902634799859
Validation loss: 2.342225549347182

Epoch: 6| Step: 11
Training loss: 0.1468700418244133
Validation loss: 2.326397429036155

Epoch: 6| Step: 12
Training loss: 0.12613685523459875
Validation loss: 2.3208287123614246

Epoch: 6| Step: 13
Training loss: 0.0795329335124459
Validation loss: 2.2912261949766997

Epoch: 587| Step: 0
Training loss: 0.10644474816828932
Validation loss: 2.292146970993415

Epoch: 6| Step: 1
Training loss: 0.08691212030448117
Validation loss: 2.2987289658940755

Epoch: 6| Step: 2
Training loss: 0.1283860982937415
Validation loss: 2.307583223375138

Epoch: 6| Step: 3
Training loss: 0.10187398389297847
Validation loss: 2.3191521839348184

Epoch: 6| Step: 4
Training loss: 0.12710962919175817
Validation loss: 2.3127884977241955

Epoch: 6| Step: 5
Training loss: 0.14028899794605373
Validation loss: 2.327981247792456

Epoch: 6| Step: 6
Training loss: 0.07304442727990873
Validation loss: 2.308781525161978

Epoch: 6| Step: 7
Training loss: 0.0678530229895547
Validation loss: 2.2867650989926327

Epoch: 6| Step: 8
Training loss: 0.09162781751914223
Validation loss: 2.3163209326819207

Epoch: 6| Step: 9
Training loss: 0.08671668765476742
Validation loss: 2.3043435128027667

Epoch: 6| Step: 10
Training loss: 0.11957572611330702
Validation loss: 2.3202264313423813

Epoch: 6| Step: 11
Training loss: 0.09141784904115824
Validation loss: 2.3049892900228026

Epoch: 6| Step: 12
Training loss: 0.06378090962870984
Validation loss: 2.3177431294528943

Epoch: 6| Step: 13
Training loss: 0.11852088757488176
Validation loss: 2.3296109069002267

Epoch: 588| Step: 0
Training loss: 0.16853636380137785
Validation loss: 2.321509904055336

Epoch: 6| Step: 1
Training loss: 0.12832281264100576
Validation loss: 2.3267316098570667

Epoch: 6| Step: 2
Training loss: 0.08877940610845961
Validation loss: 2.303883702464944

Epoch: 6| Step: 3
Training loss: 0.09151521040913878
Validation loss: 2.313841809340712

Epoch: 6| Step: 4
Training loss: 0.08229635463964367
Validation loss: 2.310809515566167

Epoch: 6| Step: 5
Training loss: 0.06593685585990963
Validation loss: 2.3255992930783145

Epoch: 6| Step: 6
Training loss: 0.10583775922514425
Validation loss: 2.295859353317597

Epoch: 6| Step: 7
Training loss: 0.11538273345290566
Validation loss: 2.299948236793396

Epoch: 6| Step: 8
Training loss: 0.09112426184654844
Validation loss: 2.26070273025678

Epoch: 6| Step: 9
Training loss: 0.08224958360307161
Validation loss: 2.259132215012557

Epoch: 6| Step: 10
Training loss: 0.1303314548767233
Validation loss: 2.267845799460082

Epoch: 6| Step: 11
Training loss: 0.09697834278655429
Validation loss: 2.2544292551834837

Epoch: 6| Step: 12
Training loss: 0.07141419428596318
Validation loss: 2.250729680667142

Epoch: 6| Step: 13
Training loss: 0.07685984583293823
Validation loss: 2.239286862033816

Epoch: 589| Step: 0
Training loss: 0.05573740527644795
Validation loss: 2.243598942226758

Epoch: 6| Step: 1
Training loss: 0.08366807993128066
Validation loss: 2.271994537622414

Epoch: 6| Step: 2
Training loss: 0.055385066091087884
Validation loss: 2.27102996442994

Epoch: 6| Step: 3
Training loss: 0.1520539241164605
Validation loss: 2.2749300602616565

Epoch: 6| Step: 4
Training loss: 0.07523354264469344
Validation loss: 2.3018498352178667

Epoch: 6| Step: 5
Training loss: 0.14305541090651896
Validation loss: 2.28673424897708

Epoch: 6| Step: 6
Training loss: 0.07877437009167614
Validation loss: 2.2832129205160814

Epoch: 6| Step: 7
Training loss: 0.07156134888189597
Validation loss: 2.3249662787402054

Epoch: 6| Step: 8
Training loss: 0.09311621234862312
Validation loss: 2.303052497114716

Epoch: 6| Step: 9
Training loss: 0.11485275830081695
Validation loss: 2.292717235495144

Epoch: 6| Step: 10
Training loss: 0.07708888229918744
Validation loss: 2.2921919381983322

Epoch: 6| Step: 11
Training loss: 0.09590428484086966
Validation loss: 2.279169542921544

Epoch: 6| Step: 12
Training loss: 0.11053673222519005
Validation loss: 2.309823564612637

Epoch: 6| Step: 13
Training loss: 0.10574488342929515
Validation loss: 2.2715702776536415

Epoch: 590| Step: 0
Training loss: 0.06916727452245626
Validation loss: 2.2980123023972734

Epoch: 6| Step: 1
Training loss: 0.07652978684789577
Validation loss: 2.288458741489781

Epoch: 6| Step: 2
Training loss: 0.12719085882236675
Validation loss: 2.3007769289426547

Epoch: 6| Step: 3
Training loss: 0.0916614344938747
Validation loss: 2.302490613355591

Epoch: 6| Step: 4
Training loss: 0.0774834878120317
Validation loss: 2.3015689708607416

Epoch: 6| Step: 5
Training loss: 0.11630522485269247
Validation loss: 2.3213403681194307

Epoch: 6| Step: 6
Training loss: 0.1355896648618896
Validation loss: 2.3076515899425827

Epoch: 6| Step: 7
Training loss: 0.10169311982078513
Validation loss: 2.311074409194753

Epoch: 6| Step: 8
Training loss: 0.09059788528483828
Validation loss: 2.2866911874083806

Epoch: 6| Step: 9
Training loss: 0.09983466886882582
Validation loss: 2.3046562981096765

Epoch: 6| Step: 10
Training loss: 0.08124564553476518
Validation loss: 2.289336833777433

Epoch: 6| Step: 11
Training loss: 0.0677628649069695
Validation loss: 2.298726185034789

Epoch: 6| Step: 12
Training loss: 0.03975480345071259
Validation loss: 2.277097724021167

Epoch: 6| Step: 13
Training loss: 0.052491434216647655
Validation loss: 2.312945014064211

Epoch: 591| Step: 0
Training loss: 0.08222248289267696
Validation loss: 2.2780255769742186

Epoch: 6| Step: 1
Training loss: 0.08121630343571752
Validation loss: 2.279614982898617

Epoch: 6| Step: 2
Training loss: 0.08112638531161127
Validation loss: 2.277754136146734

Epoch: 6| Step: 3
Training loss: 0.07766533570128095
Validation loss: 2.2735358604818523

Epoch: 6| Step: 4
Training loss: 0.0740177765093252
Validation loss: 2.278017080351929

Epoch: 6| Step: 5
Training loss: 0.10977426101270335
Validation loss: 2.2900369399751153

Epoch: 6| Step: 6
Training loss: 0.12112958823830158
Validation loss: 2.2459296801379613

Epoch: 6| Step: 7
Training loss: 0.09205158891329601
Validation loss: 2.2747227067613247

Epoch: 6| Step: 8
Training loss: 0.08181845790123779
Validation loss: 2.261703337853601

Epoch: 6| Step: 9
Training loss: 0.08776379281869011
Validation loss: 2.2784141797329753

Epoch: 6| Step: 10
Training loss: 0.09016647632918713
Validation loss: 2.265111684728831

Epoch: 6| Step: 11
Training loss: 0.06534246067798309
Validation loss: 2.261682211015984

Epoch: 6| Step: 12
Training loss: 0.1042418734935922
Validation loss: 2.264707952978488

Epoch: 6| Step: 13
Training loss: 0.05254322304967914
Validation loss: 2.2599193936075133

Epoch: 592| Step: 0
Training loss: 0.07797200003139948
Validation loss: 2.28201163345782

Epoch: 6| Step: 1
Training loss: 0.08547871761675137
Validation loss: 2.269193241225777

Epoch: 6| Step: 2
Training loss: 0.05834507824849796
Validation loss: 2.2838118470396354

Epoch: 6| Step: 3
Training loss: 0.08838230990605242
Validation loss: 2.2772242555661903

Epoch: 6| Step: 4
Training loss: 0.034927536483632386
Validation loss: 2.265172018185091

Epoch: 6| Step: 5
Training loss: 0.11469718621301155
Validation loss: 2.253378544809436

Epoch: 6| Step: 6
Training loss: 0.09788056360706446
Validation loss: 2.240750531825572

Epoch: 6| Step: 7
Training loss: 0.09173376876716506
Validation loss: 2.246926337786955

Epoch: 6| Step: 8
Training loss: 0.09099632557914959
Validation loss: 2.2405146187602965

Epoch: 6| Step: 9
Training loss: 0.08912607880878388
Validation loss: 2.2311722702799113

Epoch: 6| Step: 10
Training loss: 0.07660993522510783
Validation loss: 2.26010113150725

Epoch: 6| Step: 11
Training loss: 0.13453080271381804
Validation loss: 2.219632360799324

Epoch: 6| Step: 12
Training loss: 0.14307542844061966
Validation loss: 2.2626620427545583

Epoch: 6| Step: 13
Training loss: 0.08771869213960545
Validation loss: 2.282011587397903

Epoch: 593| Step: 0
Training loss: 0.12353727090103729
Validation loss: 2.280652961364293

Epoch: 6| Step: 1
Training loss: 0.08105964530581508
Validation loss: 2.2980181860139055

Epoch: 6| Step: 2
Training loss: 0.0627371565200963
Validation loss: 2.3195236576020317

Epoch: 6| Step: 3
Training loss: 0.08748446767328243
Validation loss: 2.3414129258400345

Epoch: 6| Step: 4
Training loss: 0.13439088356047302
Validation loss: 2.3146847351970594

Epoch: 6| Step: 5
Training loss: 0.09814035587064357
Validation loss: 2.3433500073018148

Epoch: 6| Step: 6
Training loss: 0.09167197536770554
Validation loss: 2.310025006781139

Epoch: 6| Step: 7
Training loss: 0.14213887577966122
Validation loss: 2.324250442621088

Epoch: 6| Step: 8
Training loss: 0.06604765391561694
Validation loss: 2.3348153530671394

Epoch: 6| Step: 9
Training loss: 0.0787125428748351
Validation loss: 2.3063283666922283

Epoch: 6| Step: 10
Training loss: 0.12287796628278247
Validation loss: 2.3332425746611576

Epoch: 6| Step: 11
Training loss: 0.11227238231914562
Validation loss: 2.2950892585449236

Epoch: 6| Step: 12
Training loss: 0.09301664697376272
Validation loss: 2.303267120056178

Epoch: 6| Step: 13
Training loss: 0.05860857577314167
Validation loss: 2.2975748343853817

Epoch: 594| Step: 0
Training loss: 0.07989538963471113
Validation loss: 2.281097122668577

Epoch: 6| Step: 1
Training loss: 0.07345257741281336
Validation loss: 2.2656930123298604

Epoch: 6| Step: 2
Training loss: 0.15327573845079903
Validation loss: 2.275635704472308

Epoch: 6| Step: 3
Training loss: 0.133110371511262
Validation loss: 2.293528618358215

Epoch: 6| Step: 4
Training loss: 0.08743536980510679
Validation loss: 2.308957461475032

Epoch: 6| Step: 5
Training loss: 0.149921453295458
Validation loss: 2.2789518991176103

Epoch: 6| Step: 6
Training loss: 0.07384668752644796
Validation loss: 2.296042102610419

Epoch: 6| Step: 7
Training loss: 0.0853881726868236
Validation loss: 2.3033307514203214

Epoch: 6| Step: 8
Training loss: 0.08918649821230065
Validation loss: 2.284202040600838

Epoch: 6| Step: 9
Training loss: 0.09269376144204626
Validation loss: 2.3198511935620423

Epoch: 6| Step: 10
Training loss: 0.0941620948653657
Validation loss: 2.3096816435805234

Epoch: 6| Step: 11
Training loss: 0.055451703306500524
Validation loss: 2.325777661929588

Epoch: 6| Step: 12
Training loss: 0.1528347246706616
Validation loss: 2.3176139086884535

Epoch: 6| Step: 13
Training loss: 0.09435799757376427
Validation loss: 2.311288520715909

Epoch: 595| Step: 0
Training loss: 0.0775837957791265
Validation loss: 2.323711800139395

Epoch: 6| Step: 1
Training loss: 0.09731555159083286
Validation loss: 2.304489061013777

Epoch: 6| Step: 2
Training loss: 0.08525096783375277
Validation loss: 2.313366894587435

Epoch: 6| Step: 3
Training loss: 0.09617859614706438
Validation loss: 2.299575395790716

Epoch: 6| Step: 4
Training loss: 0.08331121086488284
Validation loss: 2.307603756110404

Epoch: 6| Step: 5
Training loss: 0.07613254412020984
Validation loss: 2.2778707399097287

Epoch: 6| Step: 6
Training loss: 0.12058327350942309
Validation loss: 2.2840312052364116

Epoch: 6| Step: 7
Training loss: 0.0995621990237024
Validation loss: 2.28850637280593

Epoch: 6| Step: 8
Training loss: 0.09782521888804448
Validation loss: 2.262408270636644

Epoch: 6| Step: 9
Training loss: 0.08982837586924407
Validation loss: 2.288479185918934

Epoch: 6| Step: 10
Training loss: 0.11745286539553246
Validation loss: 2.2608043254501466

Epoch: 6| Step: 11
Training loss: 0.13664141238701658
Validation loss: 2.3002250103879547

Epoch: 6| Step: 12
Training loss: 0.10216747347260093
Validation loss: 2.3088406736012113

Epoch: 6| Step: 13
Training loss: 0.10023802242942098
Validation loss: 2.276904902778626

Epoch: 596| Step: 0
Training loss: 0.0835306698332653
Validation loss: 2.277598469360601

Epoch: 6| Step: 1
Training loss: 0.08976687376516601
Validation loss: 2.2767859618199253

Epoch: 6| Step: 2
Training loss: 0.08867592718301344
Validation loss: 2.29627216244705

Epoch: 6| Step: 3
Training loss: 0.09321798427566536
Validation loss: 2.294001678601432

Epoch: 6| Step: 4
Training loss: 0.11781167458186907
Validation loss: 2.3095932917633397

Epoch: 6| Step: 5
Training loss: 0.1360068725188836
Validation loss: 2.3149459251226485

Epoch: 6| Step: 6
Training loss: 0.11748133617026985
Validation loss: 2.3008108119206505

Epoch: 6| Step: 7
Training loss: 0.10781545064868985
Validation loss: 2.299032030398598

Epoch: 6| Step: 8
Training loss: 0.07638324241950283
Validation loss: 2.294333720665556

Epoch: 6| Step: 9
Training loss: 0.09520024896907708
Validation loss: 2.2891824526997895

Epoch: 6| Step: 10
Training loss: 0.10092595416724266
Validation loss: 2.2880568038878852

Epoch: 6| Step: 11
Training loss: 0.03982846186485317
Validation loss: 2.3031966198011524

Epoch: 6| Step: 12
Training loss: 0.12934129447523193
Validation loss: 2.298454446458882

Epoch: 6| Step: 13
Training loss: 0.07227536728632684
Validation loss: 2.3273457656461294

Epoch: 597| Step: 0
Training loss: 0.109466552734375
Validation loss: 2.2885438518461556

Epoch: 6| Step: 1
Training loss: 0.10520835804073433
Validation loss: 2.3213286174921746

Epoch: 6| Step: 2
Training loss: 0.05486303920156035
Validation loss: 2.3228976017472047

Epoch: 6| Step: 3
Training loss: 0.09788257122778844
Validation loss: 2.2821425656876757

Epoch: 6| Step: 4
Training loss: 0.08185993197885637
Validation loss: 2.3041860505937075

Epoch: 6| Step: 5
Training loss: 0.09743271516542136
Validation loss: 2.30914723208644

Epoch: 6| Step: 6
Training loss: 0.0636305408646033
Validation loss: 2.2907986254522146

Epoch: 6| Step: 7
Training loss: 0.06128939891088292
Validation loss: 2.3277991238089784

Epoch: 6| Step: 8
Training loss: 0.16111296907252018
Validation loss: 2.3091343491621705

Epoch: 6| Step: 9
Training loss: 0.10175668968415909
Validation loss: 2.316922153164013

Epoch: 6| Step: 10
Training loss: 0.09966134136964931
Validation loss: 2.3001411280552437

Epoch: 6| Step: 11
Training loss: 0.06812440133706674
Validation loss: 2.332755589338222

Epoch: 6| Step: 12
Training loss: 0.12460871639496202
Validation loss: 2.335943564657022

Epoch: 6| Step: 13
Training loss: 0.027326782956985315
Validation loss: 2.3217508296777423

Epoch: 598| Step: 0
Training loss: 0.06141081598889704
Validation loss: 2.3154442493309193

Epoch: 6| Step: 1
Training loss: 0.11966972822337499
Validation loss: 2.2834861248258926

Epoch: 6| Step: 2
Training loss: 0.06201624853755859
Validation loss: 2.298725289493665

Epoch: 6| Step: 3
Training loss: 0.1314825903532841
Validation loss: 2.3028259211831092

Epoch: 6| Step: 4
Training loss: 0.05937179922272925
Validation loss: 2.309148089169166

Epoch: 6| Step: 5
Training loss: 0.058536014324666596
Validation loss: 2.323790035966761

Epoch: 6| Step: 6
Training loss: 0.08070533795567762
Validation loss: 2.3157598438868257

Epoch: 6| Step: 7
Training loss: 0.06395042781142418
Validation loss: 2.325289479261739

Epoch: 6| Step: 8
Training loss: 0.09187961968173777
Validation loss: 2.309393734618462

Epoch: 6| Step: 9
Training loss: 0.055214484321225894
Validation loss: 2.355974174486872

Epoch: 6| Step: 10
Training loss: 0.07883087100963394
Validation loss: 2.3149529999285847

Epoch: 6| Step: 11
Training loss: 0.09075029812322467
Validation loss: 2.323935353556786

Epoch: 6| Step: 12
Training loss: 0.07400169757880547
Validation loss: 2.3230791962568764

Epoch: 6| Step: 13
Training loss: 0.09095947309856936
Validation loss: 2.348770751477249

Epoch: 599| Step: 0
Training loss: 0.0818743084330508
Validation loss: 2.3334204174819506

Epoch: 6| Step: 1
Training loss: 0.0674333072210559
Validation loss: 2.3347640448916462

Epoch: 6| Step: 2
Training loss: 0.05696251471617954
Validation loss: 2.308727776261062

Epoch: 6| Step: 3
Training loss: 0.06688345866208102
Validation loss: 2.2873732429672313

Epoch: 6| Step: 4
Training loss: 0.05781298239287603
Validation loss: 2.282765176790769

Epoch: 6| Step: 5
Training loss: 0.06068912454502097
Validation loss: 2.289103227260254

Epoch: 6| Step: 6
Training loss: 0.08989960033334009
Validation loss: 2.293481550758232

Epoch: 6| Step: 7
Training loss: 0.09654808720798333
Validation loss: 2.240066407157978

Epoch: 6| Step: 8
Training loss: 0.08643434234286691
Validation loss: 2.2573888964437034

Epoch: 6| Step: 9
Training loss: 0.08636826147466763
Validation loss: 2.2895086919570296

Epoch: 6| Step: 10
Training loss: 0.06521224428875864
Validation loss: 2.2901520561232456

Epoch: 6| Step: 11
Training loss: 0.11152414582222975
Validation loss: 2.259602399794481

Epoch: 6| Step: 12
Training loss: 0.12927126501176775
Validation loss: 2.273151117629895

Epoch: 6| Step: 13
Training loss: 0.06111518191255818
Validation loss: 2.300498349583638

Epoch: 600| Step: 0
Training loss: 0.10473530553216286
Validation loss: 2.3084153704934356

Epoch: 6| Step: 1
Training loss: 0.06494173250618344
Validation loss: 2.322653000369973

Epoch: 6| Step: 2
Training loss: 0.06544564180722766
Validation loss: 2.360508000820142

Epoch: 6| Step: 3
Training loss: 0.08595848640037104
Validation loss: 2.3370648188530767

Epoch: 6| Step: 4
Training loss: 0.05333168778280606
Validation loss: 2.338562039767247

Epoch: 6| Step: 5
Training loss: 0.08453807888281935
Validation loss: 2.3196975552178034

Epoch: 6| Step: 6
Training loss: 0.12047266115155378
Validation loss: 2.3382346129384084

Epoch: 6| Step: 7
Training loss: 0.07816120441307232
Validation loss: 2.3277802086429933

Epoch: 6| Step: 8
Training loss: 0.09501172432579712
Validation loss: 2.338801854431299

Epoch: 6| Step: 9
Training loss: 0.06666171847484752
Validation loss: 2.3286314779033583

Epoch: 6| Step: 10
Training loss: 0.0928497602827894
Validation loss: 2.3187448445640855

Epoch: 6| Step: 11
Training loss: 0.06715262528121325
Validation loss: 2.296119297190847

Epoch: 6| Step: 12
Training loss: 0.11608685352331916
Validation loss: 2.2966947682247394

Epoch: 6| Step: 13
Training loss: 0.15666843058116459
Validation loss: 2.3309908423636885

Testing loss: 2.683523513736101
