Epoch: 1| Step: 0
Training loss: 4.789694786071777
Validation loss: 5.226525906593569

Epoch: 5| Step: 1
Training loss: 5.677638053894043
Validation loss: 5.202751708287065

Epoch: 5| Step: 2
Training loss: 5.106015682220459
Validation loss: 5.176407219261251

Epoch: 5| Step: 3
Training loss: 5.5733160972595215
Validation loss: 5.147631527275167

Epoch: 5| Step: 4
Training loss: 4.468756675720215
Validation loss: 5.114027166879305

Epoch: 5| Step: 5
Training loss: 5.393351078033447
Validation loss: 5.076305999550768

Epoch: 5| Step: 6
Training loss: 4.962477684020996
Validation loss: 5.032841261997018

Epoch: 5| Step: 7
Training loss: 4.087676048278809
Validation loss: 4.984414085265128

Epoch: 5| Step: 8
Training loss: 4.590209007263184
Validation loss: 4.930594926239342

Epoch: 5| Step: 9
Training loss: 4.166391372680664
Validation loss: 4.871400110183224

Epoch: 5| Step: 10
Training loss: 4.50515604019165
Validation loss: 4.807498490938577

Epoch: 2| Step: 0
Training loss: 4.51625919342041
Validation loss: 4.739032119833013

Epoch: 5| Step: 1
Training loss: 3.041011095046997
Validation loss: 4.666420900693503

Epoch: 5| Step: 2
Training loss: 4.549064636230469
Validation loss: 4.5923961465076735

Epoch: 5| Step: 3
Training loss: 3.901132106781006
Validation loss: 4.5154495187984995

Epoch: 5| Step: 4
Training loss: 3.9831020832061768
Validation loss: 4.436130677500079

Epoch: 5| Step: 5
Training loss: 4.953331470489502
Validation loss: 4.35515889301095

Epoch: 5| Step: 6
Training loss: 4.601861000061035
Validation loss: 4.270914436668478

Epoch: 5| Step: 7
Training loss: 4.569497585296631
Validation loss: 4.190013752188734

Epoch: 5| Step: 8
Training loss: 3.4150898456573486
Validation loss: 4.109928561795142

Epoch: 5| Step: 9
Training loss: 3.5855422019958496
Validation loss: 4.034285376148839

Epoch: 5| Step: 10
Training loss: 4.634000778198242
Validation loss: 3.9619417959643948

Epoch: 3| Step: 0
Training loss: 4.479822635650635
Validation loss: 3.8986400840102986

Epoch: 5| Step: 1
Training loss: 2.99776554107666
Validation loss: 3.8358027576118388

Epoch: 5| Step: 2
Training loss: 4.545109748840332
Validation loss: 3.781566696782266

Epoch: 5| Step: 3
Training loss: 3.5943470001220703
Validation loss: 3.731916514776086

Epoch: 5| Step: 4
Training loss: 4.04164981842041
Validation loss: 3.683348232699979

Epoch: 5| Step: 5
Training loss: 2.7937943935394287
Validation loss: 3.6252394953081684

Epoch: 5| Step: 6
Training loss: 4.2430620193481445
Validation loss: 3.56818240175965

Epoch: 5| Step: 7
Training loss: 2.093090534210205
Validation loss: 3.5143188609871814

Epoch: 5| Step: 8
Training loss: 3.1190059185028076
Validation loss: 3.4714086901757026

Epoch: 5| Step: 9
Training loss: 3.6312732696533203
Validation loss: 3.4380678310189197

Epoch: 5| Step: 10
Training loss: 3.488454818725586
Validation loss: 3.4050799800503637

Epoch: 4| Step: 0
Training loss: 4.079319000244141
Validation loss: 3.3768432114713933

Epoch: 5| Step: 1
Training loss: 3.3799567222595215
Validation loss: 3.3423024249333206

Epoch: 5| Step: 2
Training loss: 3.9152863025665283
Validation loss: 3.305280036823724

Epoch: 5| Step: 3
Training loss: 3.3790087699890137
Validation loss: 3.276708302959319

Epoch: 5| Step: 4
Training loss: 2.8804965019226074
Validation loss: 3.24478312717971

Epoch: 5| Step: 5
Training loss: 3.7372994422912598
Validation loss: 3.2118092762526644

Epoch: 5| Step: 6
Training loss: 2.6445469856262207
Validation loss: 3.1873147333821943

Epoch: 5| Step: 7
Training loss: 2.681150436401367
Validation loss: 3.165043395052674

Epoch: 5| Step: 8
Training loss: 2.4774765968322754
Validation loss: 3.140822164473995

Epoch: 5| Step: 9
Training loss: 3.5425331592559814
Validation loss: 3.123924773226502

Epoch: 5| Step: 10
Training loss: 2.748971462249756
Validation loss: 3.110297877301452

Epoch: 5| Step: 0
Training loss: 2.715777635574341
Validation loss: 3.095340523668515

Epoch: 5| Step: 1
Training loss: 2.807922840118408
Validation loss: 3.0768942935492403

Epoch: 5| Step: 2
Training loss: 2.759105920791626
Validation loss: 3.066232419783069

Epoch: 5| Step: 3
Training loss: 3.1382224559783936
Validation loss: 3.053577269277265

Epoch: 5| Step: 4
Training loss: 3.272425889968872
Validation loss: 3.035036240854571

Epoch: 5| Step: 5
Training loss: 3.00072979927063
Validation loss: 3.0196166730696157

Epoch: 5| Step: 6
Training loss: 2.915586471557617
Validation loss: 3.0053321469214653

Epoch: 5| Step: 7
Training loss: 3.3532662391662598
Validation loss: 2.993842365921185

Epoch: 5| Step: 8
Training loss: 2.9031243324279785
Validation loss: 2.9853979361954557

Epoch: 5| Step: 9
Training loss: 3.2974464893341064
Validation loss: 2.9749747271178872

Epoch: 5| Step: 10
Training loss: 3.8408095836639404
Validation loss: 2.96302100663544

Epoch: 6| Step: 0
Training loss: 2.7951951026916504
Validation loss: 3.0534004883099626

Epoch: 5| Step: 1
Training loss: 2.845165729522705
Validation loss: 3.075162861936836

Epoch: 5| Step: 2
Training loss: 2.930421829223633
Validation loss: 3.021464906713014

Epoch: 5| Step: 3
Training loss: 3.3405025005340576
Validation loss: 2.9328794787006993

Epoch: 5| Step: 4
Training loss: 3.650329113006592
Validation loss: 2.956148068110148

Epoch: 5| Step: 5
Training loss: 2.829099178314209
Validation loss: 2.9644170140707367

Epoch: 5| Step: 6
Training loss: 3.9264068603515625
Validation loss: 2.9699119572998374

Epoch: 5| Step: 7
Training loss: 2.4650065898895264
Validation loss: 2.931032749914354

Epoch: 5| Step: 8
Training loss: 2.214420795440674
Validation loss: 2.9155631270459903

Epoch: 5| Step: 9
Training loss: 3.4206955432891846
Validation loss: 2.9064858523748254

Epoch: 5| Step: 10
Training loss: 3.0742990970611572
Validation loss: 2.896461007415607

Epoch: 7| Step: 0
Training loss: 2.875753879547119
Validation loss: 2.888397309087938

Epoch: 5| Step: 1
Training loss: 3.2313930988311768
Validation loss: 2.8834696918405514

Epoch: 5| Step: 2
Training loss: 2.804004669189453
Validation loss: 2.8729121556846042

Epoch: 5| Step: 3
Training loss: 3.1839816570281982
Validation loss: 2.866543480145034

Epoch: 5| Step: 4
Training loss: 2.727893829345703
Validation loss: 2.8661206255676928

Epoch: 5| Step: 5
Training loss: 2.4684078693389893
Validation loss: 2.857572470941851

Epoch: 5| Step: 6
Training loss: 2.6859660148620605
Validation loss: 2.8552945608733804

Epoch: 5| Step: 7
Training loss: 3.697047472000122
Validation loss: 2.8527222371870473

Epoch: 5| Step: 8
Training loss: 3.1755878925323486
Validation loss: 2.844274746474399

Epoch: 5| Step: 9
Training loss: 2.942929744720459
Validation loss: 2.834836898311492

Epoch: 5| Step: 10
Training loss: 2.8931992053985596
Validation loss: 2.824814675956644

Epoch: 8| Step: 0
Training loss: 2.9843368530273438
Validation loss: 2.817918162192068

Epoch: 5| Step: 1
Training loss: 3.5271964073181152
Validation loss: 2.8131068598839546

Epoch: 5| Step: 2
Training loss: 2.665173053741455
Validation loss: 2.805325590154176

Epoch: 5| Step: 3
Training loss: 2.739048480987549
Validation loss: 2.803199996230423

Epoch: 5| Step: 4
Training loss: 2.7922120094299316
Validation loss: 2.7934445360655427

Epoch: 5| Step: 5
Training loss: 2.375082492828369
Validation loss: 2.7858065841018513

Epoch: 5| Step: 6
Training loss: 3.319459915161133
Validation loss: 2.7801309118988695

Epoch: 5| Step: 7
Training loss: 2.6598992347717285
Validation loss: 2.7733051699976765

Epoch: 5| Step: 8
Training loss: 3.1093552112579346
Validation loss: 2.7677814601570048

Epoch: 5| Step: 9
Training loss: 3.033172845840454
Validation loss: 2.7610522752167075

Epoch: 5| Step: 10
Training loss: 2.9662816524505615
Validation loss: 2.770842972622123

Epoch: 9| Step: 0
Training loss: 2.8485286235809326
Validation loss: 2.7673775098657094

Epoch: 5| Step: 1
Training loss: 2.32757568359375
Validation loss: 2.7969296055455364

Epoch: 5| Step: 2
Training loss: 2.898329257965088
Validation loss: 2.81433500782136

Epoch: 5| Step: 3
Training loss: 2.634812831878662
Validation loss: 2.8262712878565632

Epoch: 5| Step: 4
Training loss: 2.436030387878418
Validation loss: 2.8034032672964115

Epoch: 5| Step: 5
Training loss: 3.578782558441162
Validation loss: 2.7974064580855833

Epoch: 5| Step: 6
Training loss: 3.0082664489746094
Validation loss: 2.7829784782983924

Epoch: 5| Step: 7
Training loss: 2.4957404136657715
Validation loss: 2.7755328147642073

Epoch: 5| Step: 8
Training loss: 3.7175192832946777
Validation loss: 2.774626678036105

Epoch: 5| Step: 9
Training loss: 3.8402557373046875
Validation loss: 2.7694180396295365

Epoch: 5| Step: 10
Training loss: 2.3157498836517334
Validation loss: 2.7536416745954946

Epoch: 10| Step: 0
Training loss: 2.313215970993042
Validation loss: 2.7526730106722925

Epoch: 5| Step: 1
Training loss: 3.2730870246887207
Validation loss: 2.7524028055129515

Epoch: 5| Step: 2
Training loss: 1.9129867553710938
Validation loss: 2.7551651616250314

Epoch: 5| Step: 3
Training loss: 2.961130142211914
Validation loss: 2.745566442448606

Epoch: 5| Step: 4
Training loss: 3.2406139373779297
Validation loss: 2.747272465818672

Epoch: 5| Step: 5
Training loss: 3.0337722301483154
Validation loss: 2.7515918670162076

Epoch: 5| Step: 6
Training loss: 2.6581101417541504
Validation loss: 2.7486914409104215

Epoch: 5| Step: 7
Training loss: 2.595489025115967
Validation loss: 2.7560413678487143

Epoch: 5| Step: 8
Training loss: 3.764199733734131
Validation loss: 2.741042311473559

Epoch: 5| Step: 9
Training loss: 2.8765697479248047
Validation loss: 2.729114047942623

Epoch: 5| Step: 10
Training loss: 3.28117299079895
Validation loss: 2.726314554932297

Epoch: 11| Step: 0
Training loss: 2.5905661582946777
Validation loss: 2.7251919366980113

Epoch: 5| Step: 1
Training loss: 3.595308303833008
Validation loss: 2.722772700812227

Epoch: 5| Step: 2
Training loss: 3.6775546073913574
Validation loss: 2.7173068215770106

Epoch: 5| Step: 3
Training loss: 2.3381924629211426
Validation loss: 2.711578292231406

Epoch: 5| Step: 4
Training loss: 2.8093106746673584
Validation loss: 2.712233228068198

Epoch: 5| Step: 5
Training loss: 2.759486198425293
Validation loss: 2.7072498131823797

Epoch: 5| Step: 6
Training loss: 3.1997222900390625
Validation loss: 2.701705148143153

Epoch: 5| Step: 7
Training loss: 2.560757875442505
Validation loss: 2.698579813844414

Epoch: 5| Step: 8
Training loss: 2.779442548751831
Validation loss: 2.6914564794109714

Epoch: 5| Step: 9
Training loss: 2.082007884979248
Validation loss: 2.687343958885439

Epoch: 5| Step: 10
Training loss: 3.296783447265625
Validation loss: 2.691366764806932

Epoch: 12| Step: 0
Training loss: 2.6863791942596436
Validation loss: 2.69360702524903

Epoch: 5| Step: 1
Training loss: 2.7219443321228027
Validation loss: 2.690774045964723

Epoch: 5| Step: 2
Training loss: 3.2110018730163574
Validation loss: 2.679133892059326

Epoch: 5| Step: 3
Training loss: 3.3176803588867188
Validation loss: 2.678470621826828

Epoch: 5| Step: 4
Training loss: 2.4985995292663574
Validation loss: 2.6803041837548696

Epoch: 5| Step: 5
Training loss: 2.5084939002990723
Validation loss: 2.68742194226993

Epoch: 5| Step: 6
Training loss: 3.431182861328125
Validation loss: 2.7277513165627756

Epoch: 5| Step: 7
Training loss: 2.9923136234283447
Validation loss: 2.6920417072952434

Epoch: 5| Step: 8
Training loss: 2.8617098331451416
Validation loss: 2.6720856594783005

Epoch: 5| Step: 9
Training loss: 2.036259889602661
Validation loss: 2.6811447707555627

Epoch: 5| Step: 10
Training loss: 3.2716832160949707
Validation loss: 2.7020866742698093

Epoch: 13| Step: 0
Training loss: 3.1727051734924316
Validation loss: 2.7314550927890244

Epoch: 5| Step: 1
Training loss: 3.0037388801574707
Validation loss: 2.7209212497998307

Epoch: 5| Step: 2
Training loss: 2.95625638961792
Validation loss: 2.6671969736776044

Epoch: 5| Step: 3
Training loss: 2.850480318069458
Validation loss: 2.661544579331593

Epoch: 5| Step: 4
Training loss: 2.6484992504119873
Validation loss: 2.6510719458262124

Epoch: 5| Step: 5
Training loss: 2.5743565559387207
Validation loss: 2.6493906051881853

Epoch: 5| Step: 6
Training loss: 2.713308334350586
Validation loss: 2.7379228684210006

Epoch: 5| Step: 7
Training loss: 3.5170340538024902
Validation loss: 2.7822233220582366

Epoch: 5| Step: 8
Training loss: 2.6629178524017334
Validation loss: 2.7317992974353094

Epoch: 5| Step: 9
Training loss: 2.8432703018188477
Validation loss: 2.7194270856918825

Epoch: 5| Step: 10
Training loss: 2.71658992767334
Validation loss: 2.7750235654974498

Epoch: 14| Step: 0
Training loss: 2.5294504165649414
Validation loss: 2.762497548134096

Epoch: 5| Step: 1
Training loss: 2.840214490890503
Validation loss: 2.7412919946896133

Epoch: 5| Step: 2
Training loss: 2.9392850399017334
Validation loss: 2.7488387861559467

Epoch: 5| Step: 3
Training loss: 2.7150120735168457
Validation loss: 2.753589745490782

Epoch: 5| Step: 4
Training loss: 2.720587968826294
Validation loss: 2.732799845357095

Epoch: 5| Step: 5
Training loss: 3.094550371170044
Validation loss: 2.6913294548629434

Epoch: 5| Step: 6
Training loss: 2.6685454845428467
Validation loss: 2.6827926943379063

Epoch: 5| Step: 7
Training loss: 2.7670388221740723
Validation loss: 2.70673773365636

Epoch: 5| Step: 8
Training loss: 3.717583179473877
Validation loss: 2.710247016722156

Epoch: 5| Step: 9
Training loss: 3.0935747623443604
Validation loss: 2.6893494667545443

Epoch: 5| Step: 10
Training loss: 2.563142776489258
Validation loss: 2.6180273640540337

Epoch: 15| Step: 0
Training loss: 2.903454303741455
Validation loss: 2.6213080293388775

Epoch: 5| Step: 1
Training loss: 2.585069179534912
Validation loss: 2.6216554000813472

Epoch: 5| Step: 2
Training loss: 2.5225443840026855
Validation loss: 2.6250752274708082

Epoch: 5| Step: 3
Training loss: 3.079310655593872
Validation loss: 2.6218697614567255

Epoch: 5| Step: 4
Training loss: 2.320514678955078
Validation loss: 2.6148677205526702

Epoch: 5| Step: 5
Training loss: 2.5727078914642334
Validation loss: 2.6061045867140575

Epoch: 5| Step: 6
Training loss: 2.820589065551758
Validation loss: 2.6006889702171407

Epoch: 5| Step: 7
Training loss: 2.9930472373962402
Validation loss: 2.5934253123498734

Epoch: 5| Step: 8
Training loss: 2.9499025344848633
Validation loss: 2.594725788280528

Epoch: 5| Step: 9
Training loss: 3.2277064323425293
Validation loss: 2.6131836393828034

Epoch: 5| Step: 10
Training loss: 2.949162006378174
Validation loss: 2.613046015462568

Epoch: 16| Step: 0
Training loss: 2.8270013332366943
Validation loss: 2.5712898828650035

Epoch: 5| Step: 1
Training loss: 2.9259326457977295
Validation loss: 2.575460846706103

Epoch: 5| Step: 2
Training loss: 3.274074077606201
Validation loss: 2.577924447674905

Epoch: 5| Step: 3
Training loss: 2.4734554290771484
Validation loss: 2.5768760199187906

Epoch: 5| Step: 4
Training loss: 2.9544014930725098
Validation loss: 2.578919836269912

Epoch: 5| Step: 5
Training loss: 1.8635351657867432
Validation loss: 2.574297458894791

Epoch: 5| Step: 6
Training loss: 3.238943099975586
Validation loss: 2.5778027529357583

Epoch: 5| Step: 7
Training loss: 2.566922664642334
Validation loss: 2.571657596095916

Epoch: 5| Step: 8
Training loss: 2.6111090183258057
Validation loss: 2.567478233768094

Epoch: 5| Step: 9
Training loss: 2.8952434062957764
Validation loss: 2.572234208865832

Epoch: 5| Step: 10
Training loss: 3.098322868347168
Validation loss: 2.57928906461244

Epoch: 17| Step: 0
Training loss: 2.6685097217559814
Validation loss: 2.5725127855936685

Epoch: 5| Step: 1
Training loss: 2.9547648429870605
Validation loss: 2.6008094741452124

Epoch: 5| Step: 2
Training loss: 2.9204959869384766
Validation loss: 2.6724577411528556

Epoch: 5| Step: 3
Training loss: 2.498645305633545
Validation loss: 2.67343444208945

Epoch: 5| Step: 4
Training loss: 3.3070740699768066
Validation loss: 2.5941176132489274

Epoch: 5| Step: 5
Training loss: 2.946145534515381
Validation loss: 2.5549284976015807

Epoch: 5| Step: 6
Training loss: 2.5779123306274414
Validation loss: 2.59412286614859

Epoch: 5| Step: 7
Training loss: 2.902186632156372
Validation loss: 2.6144403744769353

Epoch: 5| Step: 8
Training loss: 2.812544822692871
Validation loss: 2.5857714119777886

Epoch: 5| Step: 9
Training loss: 3.0189452171325684
Validation loss: 2.565830733186455

Epoch: 5| Step: 10
Training loss: 2.1865291595458984
Validation loss: 2.5459060310035624

Epoch: 18| Step: 0
Training loss: 2.648982286453247
Validation loss: 2.553429149812268

Epoch: 5| Step: 1
Training loss: 2.2436094284057617
Validation loss: 2.5588674519651677

Epoch: 5| Step: 2
Training loss: 3.0491645336151123
Validation loss: 2.5789342157302366

Epoch: 5| Step: 3
Training loss: 2.5009334087371826
Validation loss: 2.61092044461158

Epoch: 5| Step: 4
Training loss: 2.948620319366455
Validation loss: 2.672973330302905

Epoch: 5| Step: 5
Training loss: 2.897270441055298
Validation loss: 2.647645599098616

Epoch: 5| Step: 6
Training loss: 3.1690762042999268
Validation loss: 2.565988730358821

Epoch: 5| Step: 7
Training loss: 2.7892754077911377
Validation loss: 2.547682031508415

Epoch: 5| Step: 8
Training loss: 2.688206195831299
Validation loss: 2.5402939524701846

Epoch: 5| Step: 9
Training loss: 2.873748302459717
Validation loss: 2.533867364288658

Epoch: 5| Step: 10
Training loss: 2.77575421333313
Validation loss: 2.5381681739643054

Epoch: 19| Step: 0
Training loss: 3.0735926628112793
Validation loss: 2.5417322599759666

Epoch: 5| Step: 1
Training loss: 2.1509082317352295
Validation loss: 2.5519260898713143

Epoch: 5| Step: 2
Training loss: 2.552168369293213
Validation loss: 2.5528291040851223

Epoch: 5| Step: 3
Training loss: 3.397785186767578
Validation loss: 2.559467746365455

Epoch: 5| Step: 4
Training loss: 2.716050386428833
Validation loss: 2.5479042888969503

Epoch: 5| Step: 5
Training loss: 3.3281683921813965
Validation loss: 2.5422708731825634

Epoch: 5| Step: 6
Training loss: 2.7086637020111084
Validation loss: 2.529061109788956

Epoch: 5| Step: 7
Training loss: 2.7047743797302246
Validation loss: 2.525905252784811

Epoch: 5| Step: 8
Training loss: 2.4686472415924072
Validation loss: 2.518772050898562

Epoch: 5| Step: 9
Training loss: 2.7965948581695557
Validation loss: 2.5166181441276305

Epoch: 5| Step: 10
Training loss: 2.5401110649108887
Validation loss: 2.5127433935801187

Epoch: 20| Step: 0
Training loss: 3.1199591159820557
Validation loss: 2.5152048936454197

Epoch: 5| Step: 1
Training loss: 2.8908379077911377
Validation loss: 2.5152630908514864

Epoch: 5| Step: 2
Training loss: 2.370345115661621
Validation loss: 2.515432588515743

Epoch: 5| Step: 3
Training loss: 2.088766098022461
Validation loss: 2.529647922003141

Epoch: 5| Step: 4
Training loss: 3.187072277069092
Validation loss: 2.621360012280044

Epoch: 5| Step: 5
Training loss: 2.4229865074157715
Validation loss: 2.6127907537644908

Epoch: 5| Step: 6
Training loss: 3.1952600479125977
Validation loss: 2.6291064857154764

Epoch: 5| Step: 7
Training loss: 2.210921287536621
Validation loss: 2.5406703436246483

Epoch: 5| Step: 8
Training loss: 2.7332546710968018
Validation loss: 2.503060484445223

Epoch: 5| Step: 9
Training loss: 2.940433979034424
Validation loss: 2.5037257927720264

Epoch: 5| Step: 10
Training loss: 3.1453282833099365
Validation loss: 2.5008677103186168

Epoch: 21| Step: 0
Training loss: 2.8817954063415527
Validation loss: 2.4983847166902278

Epoch: 5| Step: 1
Training loss: 2.8066635131835938
Validation loss: 2.4997623005220966

Epoch: 5| Step: 2
Training loss: 1.937056303024292
Validation loss: 2.49828230181048

Epoch: 5| Step: 3
Training loss: 2.7590255737304688
Validation loss: 2.4971735297992663

Epoch: 5| Step: 4
Training loss: 3.1831841468811035
Validation loss: 2.4898832408330773

Epoch: 5| Step: 5
Training loss: 3.133878231048584
Validation loss: 2.4936839893300045

Epoch: 5| Step: 6
Training loss: 2.4559664726257324
Validation loss: 2.4967746144981793

Epoch: 5| Step: 7
Training loss: 3.293313503265381
Validation loss: 2.5016518613343597

Epoch: 5| Step: 8
Training loss: 2.5975189208984375
Validation loss: 2.50620085705993

Epoch: 5| Step: 9
Training loss: 2.588263988494873
Validation loss: 2.5195271533022643

Epoch: 5| Step: 10
Training loss: 2.272312641143799
Validation loss: 2.54617908693129

Epoch: 22| Step: 0
Training loss: 2.6713156700134277
Validation loss: 2.5761284469276347

Epoch: 5| Step: 1
Training loss: 2.6321513652801514
Validation loss: 2.546621778959869

Epoch: 5| Step: 2
Training loss: 3.5330893993377686
Validation loss: 2.5057429677696637

Epoch: 5| Step: 3
Training loss: 2.396986484527588
Validation loss: 2.490160393458541

Epoch: 5| Step: 4
Training loss: 2.98343825340271
Validation loss: 2.47563422623501

Epoch: 5| Step: 5
Training loss: 3.2726235389709473
Validation loss: 2.4731156005654285

Epoch: 5| Step: 6
Training loss: 3.5213687419891357
Validation loss: 2.4769086478858866

Epoch: 5| Step: 7
Training loss: 1.9478706121444702
Validation loss: 2.477096096161873

Epoch: 5| Step: 8
Training loss: 2.347792148590088
Validation loss: 2.4737700082922496

Epoch: 5| Step: 9
Training loss: 2.2751636505126953
Validation loss: 2.470721621667185

Epoch: 5| Step: 10
Training loss: 2.4687609672546387
Validation loss: 2.4720708426608833

Epoch: 23| Step: 0
Training loss: 2.491258382797241
Validation loss: 2.472919976839455

Epoch: 5| Step: 1
Training loss: 2.5788888931274414
Validation loss: 2.4709910910616637

Epoch: 5| Step: 2
Training loss: 2.2954835891723633
Validation loss: 2.476607984112155

Epoch: 5| Step: 3
Training loss: 2.8323073387145996
Validation loss: 2.4838941968897337

Epoch: 5| Step: 4
Training loss: 2.15028715133667
Validation loss: 2.488214738907353

Epoch: 5| Step: 5
Training loss: 2.7383663654327393
Validation loss: 2.502167063374673

Epoch: 5| Step: 6
Training loss: 3.234168291091919
Validation loss: 2.499553685547203

Epoch: 5| Step: 7
Training loss: 2.578327178955078
Validation loss: 2.4943370844728205

Epoch: 5| Step: 8
Training loss: 3.133979320526123
Validation loss: 2.4808044651503205

Epoch: 5| Step: 9
Training loss: 3.0260379314422607
Validation loss: 2.471143303378936

Epoch: 5| Step: 10
Training loss: 2.607640027999878
Validation loss: 2.461576869410853

Epoch: 24| Step: 0
Training loss: 2.75984787940979
Validation loss: 2.459778754941879

Epoch: 5| Step: 1
Training loss: 2.5626220703125
Validation loss: 2.4594591715002574

Epoch: 5| Step: 2
Training loss: 2.799849510192871
Validation loss: 2.4732870235238025

Epoch: 5| Step: 3
Training loss: 2.76912260055542
Validation loss: 2.4786902858364965

Epoch: 5| Step: 4
Training loss: 2.767646312713623
Validation loss: 2.457316583202731

Epoch: 5| Step: 5
Training loss: 2.4082894325256348
Validation loss: 2.452155977167109

Epoch: 5| Step: 6
Training loss: 2.316664457321167
Validation loss: 2.4671242493455128

Epoch: 5| Step: 7
Training loss: 3.1027064323425293
Validation loss: 2.504615222254107

Epoch: 5| Step: 8
Training loss: 2.425463914871216
Validation loss: 2.5289409852796987

Epoch: 5| Step: 9
Training loss: 3.4335830211639404
Validation loss: 2.5710935336287304

Epoch: 5| Step: 10
Training loss: 2.405970811843872
Validation loss: 2.510629129666154

Epoch: 25| Step: 0
Training loss: 3.0402023792266846
Validation loss: 2.47233118677652

Epoch: 5| Step: 1
Training loss: 3.186706304550171
Validation loss: 2.4462788874103176

Epoch: 5| Step: 2
Training loss: 2.5755395889282227
Validation loss: 2.445782084618845

Epoch: 5| Step: 3
Training loss: 2.6722593307495117
Validation loss: 2.453129001843032

Epoch: 5| Step: 4
Training loss: 2.9918484687805176
Validation loss: 2.4582943531774704

Epoch: 5| Step: 5
Training loss: 2.985630512237549
Validation loss: 2.450807858538884

Epoch: 5| Step: 6
Training loss: 2.3985860347747803
Validation loss: 2.4462346658911756

Epoch: 5| Step: 7
Training loss: 2.4953420162200928
Validation loss: 2.446989033811836

Epoch: 5| Step: 8
Training loss: 2.6524319648742676
Validation loss: 2.4410291410261586

Epoch: 5| Step: 9
Training loss: 2.854090929031372
Validation loss: 2.4406542214014197

Epoch: 5| Step: 10
Training loss: 1.7866076231002808
Validation loss: 2.441354831059774

Epoch: 26| Step: 0
Training loss: 2.588721513748169
Validation loss: 2.453526214886737

Epoch: 5| Step: 1
Training loss: 2.687553644180298
Validation loss: 2.479063093021352

Epoch: 5| Step: 2
Training loss: 3.421205997467041
Validation loss: 2.4961445100845827

Epoch: 5| Step: 3
Training loss: 2.797563076019287
Validation loss: 2.4940269839379097

Epoch: 5| Step: 4
Training loss: 2.1483023166656494
Validation loss: 2.4653502228439494

Epoch: 5| Step: 5
Training loss: 2.4052910804748535
Validation loss: 2.44640536462107

Epoch: 5| Step: 6
Training loss: 2.379380702972412
Validation loss: 2.4395683503920034

Epoch: 5| Step: 7
Training loss: 2.759451389312744
Validation loss: 2.4387540073804956

Epoch: 5| Step: 8
Training loss: 2.870405435562134
Validation loss: 2.435664858869327

Epoch: 5| Step: 9
Training loss: 2.582764148712158
Validation loss: 2.438193428900934

Epoch: 5| Step: 10
Training loss: 2.8883543014526367
Validation loss: 2.4362907768577657

Epoch: 27| Step: 0
Training loss: 2.6154589653015137
Validation loss: 2.4331537677395727

Epoch: 5| Step: 1
Training loss: 2.9328174591064453
Validation loss: 2.4348522668243735

Epoch: 5| Step: 2
Training loss: 1.9536828994750977
Validation loss: 2.4309958642528904

Epoch: 5| Step: 3
Training loss: 3.169285774230957
Validation loss: 2.438153471997989

Epoch: 5| Step: 4
Training loss: 2.5883841514587402
Validation loss: 2.4417073624108427

Epoch: 5| Step: 5
Training loss: 2.092628002166748
Validation loss: 2.43004185153592

Epoch: 5| Step: 6
Training loss: 2.5238521099090576
Validation loss: 2.431913470709196

Epoch: 5| Step: 7
Training loss: 2.869673013687134
Validation loss: 2.42622898983699

Epoch: 5| Step: 8
Training loss: 2.73181414604187
Validation loss: 2.428730090459188

Epoch: 5| Step: 9
Training loss: 2.3182692527770996
Validation loss: 2.4293150594157558

Epoch: 5| Step: 10
Training loss: 3.7540388107299805
Validation loss: 2.4281351668860323

Epoch: 28| Step: 0
Training loss: 3.1364188194274902
Validation loss: 2.4387141453322543

Epoch: 5| Step: 1
Training loss: 2.431070327758789
Validation loss: 2.439412537441459

Epoch: 5| Step: 2
Training loss: 2.558135986328125
Validation loss: 2.454568075877364

Epoch: 5| Step: 3
Training loss: 2.4581470489501953
Validation loss: 2.4648825122464086

Epoch: 5| Step: 4
Training loss: 3.119704008102417
Validation loss: 2.461444813718078

Epoch: 5| Step: 5
Training loss: 3.0839028358459473
Validation loss: 2.4653082483558246

Epoch: 5| Step: 6
Training loss: 2.5224175453186035
Validation loss: 2.4666320226525746

Epoch: 5| Step: 7
Training loss: 2.280414342880249
Validation loss: 2.4698002338409424

Epoch: 5| Step: 8
Training loss: 2.913182497024536
Validation loss: 2.443289872138731

Epoch: 5| Step: 9
Training loss: 2.1080868244171143
Validation loss: 2.431240738079112

Epoch: 5| Step: 10
Training loss: 2.744896411895752
Validation loss: 2.422742223226896

Epoch: 29| Step: 0
Training loss: 2.337230920791626
Validation loss: 2.420558714097546

Epoch: 5| Step: 1
Training loss: 2.6680562496185303
Validation loss: 2.419676762755199

Epoch: 5| Step: 2
Training loss: 3.230024814605713
Validation loss: 2.4211494307364188

Epoch: 5| Step: 3
Training loss: 2.777761220932007
Validation loss: 2.423047122134957

Epoch: 5| Step: 4
Training loss: 2.49545955657959
Validation loss: 2.4209261299461446

Epoch: 5| Step: 5
Training loss: 2.649399518966675
Validation loss: 2.4227463814520065

Epoch: 5| Step: 6
Training loss: 2.7662110328674316
Validation loss: 2.4242084615974018

Epoch: 5| Step: 7
Training loss: 2.5925228595733643
Validation loss: 2.4317668445648684

Epoch: 5| Step: 8
Training loss: 2.8352370262145996
Validation loss: 2.4607235129161547

Epoch: 5| Step: 9
Training loss: 2.5319879055023193
Validation loss: 2.4789160272126556

Epoch: 5| Step: 10
Training loss: 2.3799169063568115
Validation loss: 2.485368267182381

Epoch: 30| Step: 0
Training loss: 2.200235605239868
Validation loss: 2.474468256837578

Epoch: 5| Step: 1
Training loss: 2.6972053050994873
Validation loss: 2.440321860774871

Epoch: 5| Step: 2
Training loss: 2.8470757007598877
Validation loss: 2.4226064323097147

Epoch: 5| Step: 3
Training loss: 2.2125518321990967
Validation loss: 2.4172341233940533

Epoch: 5| Step: 4
Training loss: 2.697357416152954
Validation loss: 2.41346304134656

Epoch: 5| Step: 5
Training loss: 2.8726181983947754
Validation loss: 2.4087307119882233

Epoch: 5| Step: 6
Training loss: 2.4162259101867676
Validation loss: 2.4087874633009716

Epoch: 5| Step: 7
Training loss: 2.898102283477783
Validation loss: 2.4079136771540486

Epoch: 5| Step: 8
Training loss: 3.0520355701446533
Validation loss: 2.410082996532481

Epoch: 5| Step: 9
Training loss: 2.937678813934326
Validation loss: 2.410558413433772

Epoch: 5| Step: 10
Training loss: 2.357128620147705
Validation loss: 2.4099284859113794

Epoch: 31| Step: 0
Training loss: 2.7417538166046143
Validation loss: 2.403717517852783

Epoch: 5| Step: 1
Training loss: 2.900463104248047
Validation loss: 2.407510752319008

Epoch: 5| Step: 2
Training loss: 2.2378697395324707
Validation loss: 2.410020212973318

Epoch: 5| Step: 3
Training loss: 2.4869487285614014
Validation loss: 2.4081779577398814

Epoch: 5| Step: 4
Training loss: 3.358696460723877
Validation loss: 2.408356196136885

Epoch: 5| Step: 5
Training loss: 2.2965641021728516
Validation loss: 2.41171787118399

Epoch: 5| Step: 6
Training loss: 2.5117955207824707
Validation loss: 2.4087184321495796

Epoch: 5| Step: 7
Training loss: 2.6159818172454834
Validation loss: 2.4105257013792634

Epoch: 5| Step: 8
Training loss: 2.9328453540802
Validation loss: 2.409309782007689

Epoch: 5| Step: 9
Training loss: 2.546247959136963
Validation loss: 2.4042477094998924

Epoch: 5| Step: 10
Training loss: 2.466669797897339
Validation loss: 2.4036811474830873

Epoch: 32| Step: 0
Training loss: 2.5463707447052
Validation loss: 2.4119452968720467

Epoch: 5| Step: 1
Training loss: 2.8490467071533203
Validation loss: 2.410654216684321

Epoch: 5| Step: 2
Training loss: 2.5098164081573486
Validation loss: 2.4049568663361254

Epoch: 5| Step: 3
Training loss: 2.5920870304107666
Validation loss: 2.4101517892652944

Epoch: 5| Step: 4
Training loss: 2.4231529235839844
Validation loss: 2.4111166615639963

Epoch: 5| Step: 5
Training loss: 2.4034595489501953
Validation loss: 2.4192417642121673

Epoch: 5| Step: 6
Training loss: 3.5117905139923096
Validation loss: 2.418368588211716

Epoch: 5| Step: 7
Training loss: 2.4793200492858887
Validation loss: 2.4065228354546333

Epoch: 5| Step: 8
Training loss: 2.7956631183624268
Validation loss: 2.400455051852811

Epoch: 5| Step: 9
Training loss: 2.686671495437622
Validation loss: 2.394065469823858

Epoch: 5| Step: 10
Training loss: 2.202991485595703
Validation loss: 2.3891251984462945

Epoch: 33| Step: 0
Training loss: 2.8228707313537598
Validation loss: 2.3940802005029496

Epoch: 5| Step: 1
Training loss: 2.5285048484802246
Validation loss: 2.4074316845145276

Epoch: 5| Step: 2
Training loss: 2.7442660331726074
Validation loss: 2.408348898733816

Epoch: 5| Step: 3
Training loss: 2.3530120849609375
Validation loss: 2.403989125323552

Epoch: 5| Step: 4
Training loss: 2.7959041595458984
Validation loss: 2.401771068572998

Epoch: 5| Step: 5
Training loss: 2.3706507682800293
Validation loss: 2.3933959327718264

Epoch: 5| Step: 6
Training loss: 2.5547518730163574
Validation loss: 2.3825796855393278

Epoch: 5| Step: 7
Training loss: 2.556756019592285
Validation loss: 2.3796734707329863

Epoch: 5| Step: 8
Training loss: 3.102715253829956
Validation loss: 2.3810731441743913

Epoch: 5| Step: 9
Training loss: 2.4599759578704834
Validation loss: 2.3789286203281854

Epoch: 5| Step: 10
Training loss: 2.6385610103607178
Validation loss: 2.394734077556159

Epoch: 34| Step: 0
Training loss: 2.5689609050750732
Validation loss: 2.4427641002080773

Epoch: 5| Step: 1
Training loss: 2.7795956134796143
Validation loss: 2.5195056725573797

Epoch: 5| Step: 2
Training loss: 2.4605040550231934
Validation loss: 2.524898172706686

Epoch: 5| Step: 3
Training loss: 2.3963265419006348
Validation loss: 2.489706016355945

Epoch: 5| Step: 4
Training loss: 3.2030749320983887
Validation loss: 2.469256034461401

Epoch: 5| Step: 5
Training loss: 3.221892833709717
Validation loss: 2.431091505994079

Epoch: 5| Step: 6
Training loss: 2.056722640991211
Validation loss: 2.394290795890234

Epoch: 5| Step: 7
Training loss: 2.5992279052734375
Validation loss: 2.3906418174825688

Epoch: 5| Step: 8
Training loss: 2.5508806705474854
Validation loss: 2.386631375999861

Epoch: 5| Step: 9
Training loss: 2.6944072246551514
Validation loss: 2.38534979410069

Epoch: 5| Step: 10
Training loss: 2.898582935333252
Validation loss: 2.399283460391465

Epoch: 35| Step: 0
Training loss: 2.830096960067749
Validation loss: 2.4055606524149575

Epoch: 5| Step: 1
Training loss: 2.5761399269104004
Validation loss: 2.4034448503166117

Epoch: 5| Step: 2
Training loss: 2.0745856761932373
Validation loss: 2.402398660618772

Epoch: 5| Step: 3
Training loss: 2.3397152423858643
Validation loss: 2.378070213461435

Epoch: 5| Step: 4
Training loss: 2.804001808166504
Validation loss: 2.383281669309062

Epoch: 5| Step: 5
Training loss: 3.0569496154785156
Validation loss: 2.4136948611146662

Epoch: 5| Step: 6
Training loss: 2.125826597213745
Validation loss: 2.44649060310856

Epoch: 5| Step: 7
Training loss: 2.712209939956665
Validation loss: 2.503027859554496

Epoch: 5| Step: 8
Training loss: 2.5043282508850098
Validation loss: 2.5900546427695983

Epoch: 5| Step: 9
Training loss: 3.421267032623291
Validation loss: 2.5920963364262737

Epoch: 5| Step: 10
Training loss: 3.0401175022125244
Validation loss: 2.5053970634296374

Epoch: 36| Step: 0
Training loss: 2.4303832054138184
Validation loss: 2.449581038567328

Epoch: 5| Step: 1
Training loss: 2.7848734855651855
Validation loss: 2.41205237501411

Epoch: 5| Step: 2
Training loss: 3.286471128463745
Validation loss: 2.398276695641138

Epoch: 5| Step: 3
Training loss: 1.8279826641082764
Validation loss: 2.3914228972568305

Epoch: 5| Step: 4
Training loss: 2.727048873901367
Validation loss: 2.4071059150080525

Epoch: 5| Step: 5
Training loss: 2.964155673980713
Validation loss: 2.4363393424659647

Epoch: 5| Step: 6
Training loss: 2.0423521995544434
Validation loss: 2.4406013616951565

Epoch: 5| Step: 7
Training loss: 2.6190414428710938
Validation loss: 2.4282595983115574

Epoch: 5| Step: 8
Training loss: 3.185314655303955
Validation loss: 2.406719797401018

Epoch: 5| Step: 9
Training loss: 2.482828140258789
Validation loss: 2.393916306957122

Epoch: 5| Step: 10
Training loss: 3.0429160594940186
Validation loss: 2.3827405873165337

Epoch: 37| Step: 0
Training loss: 2.8474299907684326
Validation loss: 2.3810844805932816

Epoch: 5| Step: 1
Training loss: 2.3920741081237793
Validation loss: 2.375915934962611

Epoch: 5| Step: 2
Training loss: 2.7669901847839355
Validation loss: 2.3795468320128736

Epoch: 5| Step: 3
Training loss: 2.683732509613037
Validation loss: 2.380007818181028

Epoch: 5| Step: 4
Training loss: 2.5562450885772705
Validation loss: 2.3863111644662838

Epoch: 5| Step: 5
Training loss: 2.813074827194214
Validation loss: 2.393461852945307

Epoch: 5| Step: 6
Training loss: 2.2010624408721924
Validation loss: 2.4080485220878356

Epoch: 5| Step: 7
Training loss: 2.622241973876953
Validation loss: 2.4055215620225474

Epoch: 5| Step: 8
Training loss: 2.500054359436035
Validation loss: 2.3993840832864084

Epoch: 5| Step: 9
Training loss: 2.9344093799591064
Validation loss: 2.414743443971039

Epoch: 5| Step: 10
Training loss: 2.6145060062408447
Validation loss: 2.4103737595260784

Epoch: 38| Step: 0
Training loss: 2.627793312072754
Validation loss: 2.4107777431447017

Epoch: 5| Step: 1
Training loss: 3.150639772415161
Validation loss: 2.4208557528834187

Epoch: 5| Step: 2
Training loss: 2.2794687747955322
Validation loss: 2.4185731487889446

Epoch: 5| Step: 3
Training loss: 2.1596479415893555
Validation loss: 2.4126350546395905

Epoch: 5| Step: 4
Training loss: 2.5886611938476562
Validation loss: 2.4152092497835875

Epoch: 5| Step: 5
Training loss: 2.903505802154541
Validation loss: 2.3968709873896774

Epoch: 5| Step: 6
Training loss: 2.3966193199157715
Validation loss: 2.3885951247266544

Epoch: 5| Step: 7
Training loss: 2.468719720840454
Validation loss: 2.3640692182766494

Epoch: 5| Step: 8
Training loss: 2.4156277179718018
Validation loss: 2.350551523188109

Epoch: 5| Step: 9
Training loss: 2.9991397857666016
Validation loss: 2.3407549319728727

Epoch: 5| Step: 10
Training loss: 2.8447682857513428
Validation loss: 2.3352644238420712

Epoch: 39| Step: 0
Training loss: 2.5483298301696777
Validation loss: 2.338636234242429

Epoch: 5| Step: 1
Training loss: 1.91010320186615
Validation loss: 2.3410480201885266

Epoch: 5| Step: 2
Training loss: 2.4879939556121826
Validation loss: 2.343738379016999

Epoch: 5| Step: 3
Training loss: 2.5372936725616455
Validation loss: 2.334766621230751

Epoch: 5| Step: 4
Training loss: 2.5304291248321533
Validation loss: 2.336609878847676

Epoch: 5| Step: 5
Training loss: 3.1890480518341064
Validation loss: 2.3442177823794785

Epoch: 5| Step: 6
Training loss: 2.7439687252044678
Validation loss: 2.353364042056504

Epoch: 5| Step: 7
Training loss: 3.0342204570770264
Validation loss: 2.3665135650224585

Epoch: 5| Step: 8
Training loss: 2.9660515785217285
Validation loss: 2.3980920212243193

Epoch: 5| Step: 9
Training loss: 2.732983112335205
Validation loss: 2.395802979828209

Epoch: 5| Step: 10
Training loss: 2.058339834213257
Validation loss: 2.3836608830318657

Epoch: 40| Step: 0
Training loss: 2.3506698608398438
Validation loss: 2.3914507768487416

Epoch: 5| Step: 1
Training loss: 1.7856500148773193
Validation loss: 2.4053845815761115

Epoch: 5| Step: 2
Training loss: 2.6307806968688965
Validation loss: 2.389066550039476

Epoch: 5| Step: 3
Training loss: 2.7093262672424316
Validation loss: 2.3648523335815756

Epoch: 5| Step: 4
Training loss: 2.7917895317077637
Validation loss: 2.348334215020621

Epoch: 5| Step: 5
Training loss: 2.2021656036376953
Validation loss: 2.332209528133433

Epoch: 5| Step: 6
Training loss: 2.611691951751709
Validation loss: 2.325675872064406

Epoch: 5| Step: 7
Training loss: 2.4966232776641846
Validation loss: 2.3296620589430614

Epoch: 5| Step: 8
Training loss: 2.914403200149536
Validation loss: 2.332454614741828

Epoch: 5| Step: 9
Training loss: 3.101085662841797
Validation loss: 2.335966933158136

Epoch: 5| Step: 10
Training loss: 3.2631871700286865
Validation loss: 2.330955807880689

Epoch: 41| Step: 0
Training loss: 2.104423761367798
Validation loss: 2.3214472570726947

Epoch: 5| Step: 1
Training loss: 2.986288547515869
Validation loss: 2.325325599280737

Epoch: 5| Step: 2
Training loss: 2.874972105026245
Validation loss: 2.322777255888908

Epoch: 5| Step: 3
Training loss: 2.592150926589966
Validation loss: 2.323389558381932

Epoch: 5| Step: 4
Training loss: 2.7452967166900635
Validation loss: 2.3319041600791355

Epoch: 5| Step: 5
Training loss: 3.0111217498779297
Validation loss: 2.341155304703661

Epoch: 5| Step: 6
Training loss: 2.658226490020752
Validation loss: 2.362024507214946

Epoch: 5| Step: 7
Training loss: 2.5845072269439697
Validation loss: 2.3710712822534705

Epoch: 5| Step: 8
Training loss: 1.9822146892547607
Validation loss: 2.3878158164280716

Epoch: 5| Step: 9
Training loss: 2.314666986465454
Validation loss: 2.382365897137632

Epoch: 5| Step: 10
Training loss: 2.828192949295044
Validation loss: 2.364089091618856

Epoch: 42| Step: 0
Training loss: 2.6714940071105957
Validation loss: 2.3514817607018257

Epoch: 5| Step: 1
Training loss: 2.063805341720581
Validation loss: 2.336079451345628

Epoch: 5| Step: 2
Training loss: 1.9619566202163696
Validation loss: 2.324098676763555

Epoch: 5| Step: 3
Training loss: 3.1213080883026123
Validation loss: 2.3220972091920915

Epoch: 5| Step: 4
Training loss: 2.5098090171813965
Validation loss: 2.322339132267942

Epoch: 5| Step: 5
Training loss: 2.505314350128174
Validation loss: 2.3300601846428326

Epoch: 5| Step: 6
Training loss: 2.7832298278808594
Validation loss: 2.3282181280915455

Epoch: 5| Step: 7
Training loss: 2.9393582344055176
Validation loss: 2.3207284840204383

Epoch: 5| Step: 8
Training loss: 2.9624438285827637
Validation loss: 2.3144801073176886

Epoch: 5| Step: 9
Training loss: 2.530754804611206
Validation loss: 2.3047598690114994

Epoch: 5| Step: 10
Training loss: 2.4392757415771484
Validation loss: 2.3049662651554232

Epoch: 43| Step: 0
Training loss: 2.8091821670532227
Validation loss: 2.302067341343049

Epoch: 5| Step: 1
Training loss: 2.248775005340576
Validation loss: 2.306709116505038

Epoch: 5| Step: 2
Training loss: 3.07141375541687
Validation loss: 2.3113783841492026

Epoch: 5| Step: 3
Training loss: 2.563974142074585
Validation loss: 2.308967605713875

Epoch: 5| Step: 4
Training loss: 2.6102445125579834
Validation loss: 2.312648298919842

Epoch: 5| Step: 5
Training loss: 2.6500582695007324
Validation loss: 2.3094141278215634

Epoch: 5| Step: 6
Training loss: 2.0458645820617676
Validation loss: 2.3126242545343216

Epoch: 5| Step: 7
Training loss: 2.985675811767578
Validation loss: 2.31059165411098

Epoch: 5| Step: 8
Training loss: 2.597078323364258
Validation loss: 2.3107125195123817

Epoch: 5| Step: 9
Training loss: 2.612513780593872
Validation loss: 2.3019863584990143

Epoch: 5| Step: 10
Training loss: 2.3422186374664307
Validation loss: 2.308590696704003

Epoch: 44| Step: 0
Training loss: 3.1146442890167236
Validation loss: 2.3046221374183573

Epoch: 5| Step: 1
Training loss: 2.449685573577881
Validation loss: 2.3087688697281705

Epoch: 5| Step: 2
Training loss: 2.663018226623535
Validation loss: 2.3217571038071827

Epoch: 5| Step: 3
Training loss: 2.645707607269287
Validation loss: 2.3460446339781567

Epoch: 5| Step: 4
Training loss: 2.7027292251586914
Validation loss: 2.3523670011951077

Epoch: 5| Step: 5
Training loss: 2.6134588718414307
Validation loss: 2.3697484206127863

Epoch: 5| Step: 6
Training loss: 2.482503890991211
Validation loss: 2.3775200484901347

Epoch: 5| Step: 7
Training loss: 1.8275041580200195
Validation loss: 2.3465226388746694

Epoch: 5| Step: 8
Training loss: 2.2404165267944336
Validation loss: 2.3416727537749917

Epoch: 5| Step: 9
Training loss: 2.8972549438476562
Validation loss: 2.330867839115922

Epoch: 5| Step: 10
Training loss: 2.9360203742980957
Validation loss: 2.3313476936791533

Epoch: 45| Step: 0
Training loss: 1.7768760919570923
Validation loss: 2.3352282085726337

Epoch: 5| Step: 1
Training loss: 2.7794556617736816
Validation loss: 2.3383017329759497

Epoch: 5| Step: 2
Training loss: 2.234528064727783
Validation loss: 2.3485372040861394

Epoch: 5| Step: 3
Training loss: 2.940147876739502
Validation loss: 2.366212514138991

Epoch: 5| Step: 4
Training loss: 2.535057783126831
Validation loss: 2.3729218257370817

Epoch: 5| Step: 5
Training loss: 3.128230571746826
Validation loss: 2.362685121515746

Epoch: 5| Step: 6
Training loss: 3.03468656539917
Validation loss: 2.3557144698276313

Epoch: 5| Step: 7
Training loss: 2.3026583194732666
Validation loss: 2.343748514370252

Epoch: 5| Step: 8
Training loss: 2.9450621604919434
Validation loss: 2.332023596250883

Epoch: 5| Step: 9
Training loss: 2.353760242462158
Validation loss: 2.3198270079910115

Epoch: 5| Step: 10
Training loss: 2.595621109008789
Validation loss: 2.307932848571449

Epoch: 46| Step: 0
Training loss: 2.2832412719726562
Validation loss: 2.3052819646814817

Epoch: 5| Step: 1
Training loss: 2.0446019172668457
Validation loss: 2.2955738267590924

Epoch: 5| Step: 2
Training loss: 2.9808340072631836
Validation loss: 2.288210094615977

Epoch: 5| Step: 3
Training loss: 2.9862284660339355
Validation loss: 2.2880413211802

Epoch: 5| Step: 4
Training loss: 2.4710302352905273
Validation loss: 2.2838604078497937

Epoch: 5| Step: 5
Training loss: 2.6231517791748047
Validation loss: 2.2808667357249925

Epoch: 5| Step: 6
Training loss: 2.9521050453186035
Validation loss: 2.2790985825241252

Epoch: 5| Step: 7
Training loss: 2.746570110321045
Validation loss: 2.2858407651224444

Epoch: 5| Step: 8
Training loss: 2.135396957397461
Validation loss: 2.291315553008869

Epoch: 5| Step: 9
Training loss: 2.54345965385437
Validation loss: 2.301365747246691

Epoch: 5| Step: 10
Training loss: 2.547678232192993
Validation loss: 2.301429170434193

Epoch: 47| Step: 0
Training loss: 2.2635719776153564
Validation loss: 2.3335381092563754

Epoch: 5| Step: 1
Training loss: 2.7467007637023926
Validation loss: 2.353268346478862

Epoch: 5| Step: 2
Training loss: 3.2780113220214844
Validation loss: 2.375351667404175

Epoch: 5| Step: 3
Training loss: 2.5869956016540527
Validation loss: 2.3454026663175194

Epoch: 5| Step: 4
Training loss: 2.2205610275268555
Validation loss: 2.305310251892254

Epoch: 5| Step: 5
Training loss: 1.58480966091156
Validation loss: 2.2946839563308226

Epoch: 5| Step: 6
Training loss: 2.822713851928711
Validation loss: 2.2823623175262124

Epoch: 5| Step: 7
Training loss: 2.7696022987365723
Validation loss: 2.2924400247553343

Epoch: 5| Step: 8
Training loss: 2.444817066192627
Validation loss: 2.2920733497988794

Epoch: 5| Step: 9
Training loss: 2.4916832447052
Validation loss: 2.2971812627648793

Epoch: 5| Step: 10
Training loss: 3.266939163208008
Validation loss: 2.3095120819666053

Epoch: 48| Step: 0
Training loss: 2.222080945968628
Validation loss: 2.291710538248862

Epoch: 5| Step: 1
Training loss: 2.3301162719726562
Validation loss: 2.291324766733313

Epoch: 5| Step: 2
Training loss: 2.4284615516662598
Validation loss: 2.292937265929355

Epoch: 5| Step: 3
Training loss: 2.7943978309631348
Validation loss: 2.294671691874022

Epoch: 5| Step: 4
Training loss: 2.5590007305145264
Validation loss: 2.296534748487575

Epoch: 5| Step: 5
Training loss: 1.9710121154785156
Validation loss: 2.3118461511468373

Epoch: 5| Step: 6
Training loss: 2.523059368133545
Validation loss: 2.3200737994204284

Epoch: 5| Step: 7
Training loss: 3.167306661605835
Validation loss: 2.3439818915500434

Epoch: 5| Step: 8
Training loss: 2.7086026668548584
Validation loss: 2.357678735128013

Epoch: 5| Step: 9
Training loss: 2.4494996070861816
Validation loss: 2.351809265793011

Epoch: 5| Step: 10
Training loss: 3.1951904296875
Validation loss: 2.3237825106549006

Epoch: 49| Step: 0
Training loss: 2.7745883464813232
Validation loss: 2.2994228460455455

Epoch: 5| Step: 1
Training loss: 2.3773608207702637
Validation loss: 2.2922315533443163

Epoch: 5| Step: 2
Training loss: 2.187844753265381
Validation loss: 2.2841049522481938

Epoch: 5| Step: 3
Training loss: 2.527251720428467
Validation loss: 2.2798777190587853

Epoch: 5| Step: 4
Training loss: 2.6514341831207275
Validation loss: 2.2799581994292555

Epoch: 5| Step: 5
Training loss: 2.4271469116210938
Validation loss: 2.294266264925721

Epoch: 5| Step: 6
Training loss: 2.5488970279693604
Validation loss: 2.2918726269916823

Epoch: 5| Step: 7
Training loss: 2.399458885192871
Validation loss: 2.294657381631995

Epoch: 5| Step: 8
Training loss: 2.603935718536377
Validation loss: 2.290879241881832

Epoch: 5| Step: 9
Training loss: 3.1613476276397705
Validation loss: 2.290098459489884

Epoch: 5| Step: 10
Training loss: 2.631448745727539
Validation loss: 2.278419686901954

Epoch: 50| Step: 0
Training loss: 2.7854676246643066
Validation loss: 2.2675487636238016

Epoch: 5| Step: 1
Training loss: 2.210672616958618
Validation loss: 2.2705604671150126

Epoch: 5| Step: 2
Training loss: 2.461460590362549
Validation loss: 2.263247569402059

Epoch: 5| Step: 3
Training loss: 3.1953444480895996
Validation loss: 2.262787062634704

Epoch: 5| Step: 4
Training loss: 2.6276755332946777
Validation loss: 2.2658020142586

Epoch: 5| Step: 5
Training loss: 2.3213951587677
Validation loss: 2.267562884156422

Epoch: 5| Step: 6
Training loss: 2.4028916358947754
Validation loss: 2.272648706231066

Epoch: 5| Step: 7
Training loss: 2.7849669456481934
Validation loss: 2.2827197403036137

Epoch: 5| Step: 8
Training loss: 2.398080348968506
Validation loss: 2.2822516733600247

Epoch: 5| Step: 9
Training loss: 1.9346462488174438
Validation loss: 2.282288776930942

Epoch: 5| Step: 10
Training loss: 2.977048873901367
Validation loss: 2.2859817345937095

Epoch: 51| Step: 0
Training loss: 2.1746020317077637
Validation loss: 2.284850687109014

Epoch: 5| Step: 1
Training loss: 2.3950812816619873
Validation loss: 2.277019545596133

Epoch: 5| Step: 2
Training loss: 2.849959135055542
Validation loss: 2.2779888799113612

Epoch: 5| Step: 3
Training loss: 2.2139639854431152
Validation loss: 2.2771520819715274

Epoch: 5| Step: 4
Training loss: 2.837515115737915
Validation loss: 2.282580788417529

Epoch: 5| Step: 5
Training loss: 2.8261914253234863
Validation loss: 2.272823061994327

Epoch: 5| Step: 6
Training loss: 2.3271169662475586
Validation loss: 2.270112282486372

Epoch: 5| Step: 7
Training loss: 3.0066213607788086
Validation loss: 2.2566546688797655

Epoch: 5| Step: 8
Training loss: 2.526444673538208
Validation loss: 2.2409237636032926

Epoch: 5| Step: 9
Training loss: 2.5127217769622803
Validation loss: 2.2453541371130172

Epoch: 5| Step: 10
Training loss: 2.5131053924560547
Validation loss: 2.246263521973805

Epoch: 52| Step: 0
Training loss: 2.8150532245635986
Validation loss: 2.247435059598697

Epoch: 5| Step: 1
Training loss: 2.223832130432129
Validation loss: 2.253883218252531

Epoch: 5| Step: 2
Training loss: 2.6677000522613525
Validation loss: 2.282952498364192

Epoch: 5| Step: 3
Training loss: 1.9537967443466187
Validation loss: 2.3252586292964157

Epoch: 5| Step: 4
Training loss: 2.3811562061309814
Validation loss: 2.3703181923076673

Epoch: 5| Step: 5
Training loss: 3.264826536178589
Validation loss: 2.3685885142254572

Epoch: 5| Step: 6
Training loss: 2.6161599159240723
Validation loss: 2.364307621473907

Epoch: 5| Step: 7
Training loss: 2.431584596633911
Validation loss: 2.4022827891893286

Epoch: 5| Step: 8
Training loss: 2.6263203620910645
Validation loss: 2.388403279806978

Epoch: 5| Step: 9
Training loss: 2.3378078937530518
Validation loss: 2.356999138350128

Epoch: 5| Step: 10
Training loss: 2.755610942840576
Validation loss: 2.3166681335818384

Epoch: 53| Step: 0
Training loss: 2.526555061340332
Validation loss: 2.269453376852056

Epoch: 5| Step: 1
Training loss: 2.261218309402466
Validation loss: 2.256319307511853

Epoch: 5| Step: 2
Training loss: 2.471036195755005
Validation loss: 2.2492077350616455

Epoch: 5| Step: 3
Training loss: 2.3550829887390137
Validation loss: 2.2458794270792315

Epoch: 5| Step: 4
Training loss: 2.5457231998443604
Validation loss: 2.2661026139413156

Epoch: 5| Step: 5
Training loss: 2.629162549972534
Validation loss: 2.263151614896713

Epoch: 5| Step: 6
Training loss: 2.2242391109466553
Validation loss: 2.2432890989447154

Epoch: 5| Step: 7
Training loss: 3.110671281814575
Validation loss: 2.237411155495592

Epoch: 5| Step: 8
Training loss: 2.478707790374756
Validation loss: 2.244509304723432

Epoch: 5| Step: 9
Training loss: 2.867825746536255
Validation loss: 2.246722126519808

Epoch: 5| Step: 10
Training loss: 2.580065965652466
Validation loss: 2.254885632504699

Epoch: 54| Step: 0
Training loss: 2.32924485206604
Validation loss: 2.2741356690724692

Epoch: 5| Step: 1
Training loss: 2.720776081085205
Validation loss: 2.283333219507689

Epoch: 5| Step: 2
Training loss: 2.6319661140441895
Validation loss: 2.271704048238775

Epoch: 5| Step: 3
Training loss: 2.1980960369110107
Validation loss: 2.2733465087029243

Epoch: 5| Step: 4
Training loss: 2.283517360687256
Validation loss: 2.2653170952232937

Epoch: 5| Step: 5
Training loss: 1.9918029308319092
Validation loss: 2.274495501672068

Epoch: 5| Step: 6
Training loss: 2.7305049896240234
Validation loss: 2.2861840109671316

Epoch: 5| Step: 7
Training loss: 2.925459384918213
Validation loss: 2.2875448196165022

Epoch: 5| Step: 8
Training loss: 2.6581015586853027
Validation loss: 2.2800270844531316

Epoch: 5| Step: 9
Training loss: 3.0223114490509033
Validation loss: 2.2645664497088362

Epoch: 5| Step: 10
Training loss: 2.4519882202148438
Validation loss: 2.246842666338849

Epoch: 55| Step: 0
Training loss: 3.0935146808624268
Validation loss: 2.244182441824226

Epoch: 5| Step: 1
Training loss: 2.6360726356506348
Validation loss: 2.2392715587410876

Epoch: 5| Step: 2
Training loss: 3.290335178375244
Validation loss: 2.235825987272365

Epoch: 5| Step: 3
Training loss: 2.4015092849731445
Validation loss: 2.242710885181222

Epoch: 5| Step: 4
Training loss: 2.0322492122650146
Validation loss: 2.258943998685447

Epoch: 5| Step: 5
Training loss: 2.615079402923584
Validation loss: 2.287170999793596

Epoch: 5| Step: 6
Training loss: 1.8683334589004517
Validation loss: 2.278908693662254

Epoch: 5| Step: 7
Training loss: 2.8417932987213135
Validation loss: 2.2614114451152023

Epoch: 5| Step: 8
Training loss: 2.11979341506958
Validation loss: 2.240432116293138

Epoch: 5| Step: 9
Training loss: 2.5605008602142334
Validation loss: 2.229730729133852

Epoch: 5| Step: 10
Training loss: 2.4032576084136963
Validation loss: 2.2332812945048013

Epoch: 56| Step: 0
Training loss: 2.779658794403076
Validation loss: 2.2328494133487826

Epoch: 5| Step: 1
Training loss: 3.166900634765625
Validation loss: 2.228960548677752

Epoch: 5| Step: 2
Training loss: 2.454522132873535
Validation loss: 2.2247002509332474

Epoch: 5| Step: 3
Training loss: 2.6102097034454346
Validation loss: 2.231864739489812

Epoch: 5| Step: 4
Training loss: 2.861682891845703
Validation loss: 2.2264260374089724

Epoch: 5| Step: 5
Training loss: 1.9818131923675537
Validation loss: 2.2351814649438344

Epoch: 5| Step: 6
Training loss: 2.2080130577087402
Validation loss: 2.2344293671269573

Epoch: 5| Step: 7
Training loss: 2.2137978076934814
Validation loss: 2.247911055882772

Epoch: 5| Step: 8
Training loss: 2.032003164291382
Validation loss: 2.2277026407180296

Epoch: 5| Step: 9
Training loss: 2.483952045440674
Validation loss: 2.2221810535718034

Epoch: 5| Step: 10
Training loss: 3.072661876678467
Validation loss: 2.2107757445304625

Epoch: 57| Step: 0
Training loss: 2.6984455585479736
Validation loss: 2.2135133204921598

Epoch: 5| Step: 1
Training loss: 2.3236653804779053
Validation loss: 2.211494656019313

Epoch: 5| Step: 2
Training loss: 2.5204379558563232
Validation loss: 2.2130092395249235

Epoch: 5| Step: 3
Training loss: 3.1127891540527344
Validation loss: 2.2083483639583794

Epoch: 5| Step: 4
Training loss: 2.375572919845581
Validation loss: 2.205904658122729

Epoch: 5| Step: 5
Training loss: 2.563897132873535
Validation loss: 2.2108104331519014

Epoch: 5| Step: 6
Training loss: 2.66442608833313
Validation loss: 2.207954283683531

Epoch: 5| Step: 7
Training loss: 2.7752280235290527
Validation loss: 2.2126253753580074

Epoch: 5| Step: 8
Training loss: 1.8832156658172607
Validation loss: 2.2130928783006567

Epoch: 5| Step: 9
Training loss: 2.4319961071014404
Validation loss: 2.23976723353068

Epoch: 5| Step: 10
Training loss: 2.5871059894561768
Validation loss: 2.2723962901740946

Epoch: 58| Step: 0
Training loss: 3.3216896057128906
Validation loss: 2.3247527101988434

Epoch: 5| Step: 1
Training loss: 2.2914764881134033
Validation loss: 2.340550304740988

Epoch: 5| Step: 2
Training loss: 2.1735122203826904
Validation loss: 2.328567789446923

Epoch: 5| Step: 3
Training loss: 2.6860671043395996
Validation loss: 2.2946030734687723

Epoch: 5| Step: 4
Training loss: 3.078023910522461
Validation loss: 2.247890526248563

Epoch: 5| Step: 5
Training loss: 2.6485018730163574
Validation loss: 2.210000886712023

Epoch: 5| Step: 6
Training loss: 2.231529951095581
Validation loss: 2.200995550360731

Epoch: 5| Step: 7
Training loss: 2.4793643951416016
Validation loss: 2.1946762441306986

Epoch: 5| Step: 8
Training loss: 2.1176724433898926
Validation loss: 2.1934780664341424

Epoch: 5| Step: 9
Training loss: 2.663982629776001
Validation loss: 2.192728909113074

Epoch: 5| Step: 10
Training loss: 2.287095069885254
Validation loss: 2.199674383286507

Epoch: 59| Step: 0
Training loss: 2.2806718349456787
Validation loss: 2.2029605462986934

Epoch: 5| Step: 1
Training loss: 2.4944663047790527
Validation loss: 2.213832568096858

Epoch: 5| Step: 2
Training loss: 3.248206377029419
Validation loss: 2.2294412684696976

Epoch: 5| Step: 3
Training loss: 2.239854335784912
Validation loss: 2.2624975788977837

Epoch: 5| Step: 4
Training loss: 2.6680476665496826
Validation loss: 2.3001042027627268

Epoch: 5| Step: 5
Training loss: 2.460679292678833
Validation loss: 2.3278298377990723

Epoch: 5| Step: 6
Training loss: 2.097174882888794
Validation loss: 2.34374596482964

Epoch: 5| Step: 7
Training loss: 2.8301079273223877
Validation loss: 2.3343746739049114

Epoch: 5| Step: 8
Training loss: 2.6225104331970215
Validation loss: 2.341590109691825

Epoch: 5| Step: 9
Training loss: 2.4572863578796387
Validation loss: 2.3057061344064693

Epoch: 5| Step: 10
Training loss: 2.4715523719787598
Validation loss: 2.3355219312893447

Epoch: 60| Step: 0
Training loss: 2.6716675758361816
Validation loss: 2.326003428428404

Epoch: 5| Step: 1
Training loss: 2.9427967071533203
Validation loss: 2.2928834910033853

Epoch: 5| Step: 2
Training loss: 2.653364658355713
Validation loss: 2.227571218244491

Epoch: 5| Step: 3
Training loss: 2.073279857635498
Validation loss: 2.1906689854078394

Epoch: 5| Step: 4
Training loss: 2.3617446422576904
Validation loss: 2.2021777540124874

Epoch: 5| Step: 5
Training loss: 2.335366725921631
Validation loss: 2.257099913012597

Epoch: 5| Step: 6
Training loss: 2.1259729862213135
Validation loss: 2.307608501885527

Epoch: 5| Step: 7
Training loss: 2.593376636505127
Validation loss: 2.326248497091314

Epoch: 5| Step: 8
Training loss: 2.945831298828125
Validation loss: 2.3066734729274625

Epoch: 5| Step: 9
Training loss: 2.912850856781006
Validation loss: 2.2635379786132486

Epoch: 5| Step: 10
Training loss: 3.0881333351135254
Validation loss: 2.2317885352719213

Epoch: 61| Step: 0
Training loss: 2.9683330059051514
Validation loss: 2.2215639288707445

Epoch: 5| Step: 1
Training loss: 2.8509702682495117
Validation loss: 2.2121201279342815

Epoch: 5| Step: 2
Training loss: 2.264191150665283
Validation loss: 2.2323905396205124

Epoch: 5| Step: 3
Training loss: 2.5272464752197266
Validation loss: 2.2370966454987884

Epoch: 5| Step: 4
Training loss: 2.3369789123535156
Validation loss: 2.256018143828197

Epoch: 5| Step: 5
Training loss: 2.0568525791168213
Validation loss: 2.279957822574082

Epoch: 5| Step: 6
Training loss: 2.553377866744995
Validation loss: 2.3381510037247852

Epoch: 5| Step: 7
Training loss: 1.9086177349090576
Validation loss: 2.4533162886096584

Epoch: 5| Step: 8
Training loss: 3.5633959770202637
Validation loss: 2.5559705636834584

Epoch: 5| Step: 9
Training loss: 2.284438371658325
Validation loss: 2.521199885235038

Epoch: 5| Step: 10
Training loss: 2.3963449001312256
Validation loss: 2.4086793263753257

Epoch: 62| Step: 0
Training loss: 3.028614044189453
Validation loss: 2.359309506672685

Epoch: 5| Step: 1
Training loss: 2.758113384246826
Validation loss: 2.303550530505437

Epoch: 5| Step: 2
Training loss: 2.7984728813171387
Validation loss: 2.2548418250135196

Epoch: 5| Step: 3
Training loss: 2.353259563446045
Validation loss: 2.213794821052141

Epoch: 5| Step: 4
Training loss: 1.7174888849258423
Validation loss: 2.211997583348264

Epoch: 5| Step: 5
Training loss: 2.504887342453003
Validation loss: 2.2042862676805064

Epoch: 5| Step: 6
Training loss: 3.1186814308166504
Validation loss: 2.2066635854782595

Epoch: 5| Step: 7
Training loss: 2.441563367843628
Validation loss: 2.207651012687273

Epoch: 5| Step: 8
Training loss: 1.8390651941299438
Validation loss: 2.210910730464484

Epoch: 5| Step: 9
Training loss: 2.9353532791137695
Validation loss: 2.2318098519438054

Epoch: 5| Step: 10
Training loss: 2.4606943130493164
Validation loss: 2.211434079754737

Epoch: 63| Step: 0
Training loss: 1.996466875076294
Validation loss: 2.225858365335772

Epoch: 5| Step: 1
Training loss: 3.2166428565979004
Validation loss: 2.2335014817535237

Epoch: 5| Step: 2
Training loss: 2.247784376144409
Validation loss: 2.2535277605056763

Epoch: 5| Step: 3
Training loss: 2.0998008251190186
Validation loss: 2.24950825014422

Epoch: 5| Step: 4
Training loss: 2.867636203765869
Validation loss: 2.2498331659583637

Epoch: 5| Step: 5
Training loss: 2.5114364624023438
Validation loss: 2.2365075157534693

Epoch: 5| Step: 6
Training loss: 2.4779391288757324
Validation loss: 2.230912941758351

Epoch: 5| Step: 7
Training loss: 2.5183942317962646
Validation loss: 2.211123694655716

Epoch: 5| Step: 8
Training loss: 2.2518844604492188
Validation loss: 2.199684494285173

Epoch: 5| Step: 9
Training loss: 3.4939322471618652
Validation loss: 2.2158484151286464

Epoch: 5| Step: 10
Training loss: 1.8342727422714233
Validation loss: 2.189152697081207

Epoch: 64| Step: 0
Training loss: 2.2313570976257324
Validation loss: 2.1787343563572055

Epoch: 5| Step: 1
Training loss: 2.3834004402160645
Validation loss: 2.1639397349408878

Epoch: 5| Step: 2
Training loss: 2.54752516746521
Validation loss: 2.1643723928800194

Epoch: 5| Step: 3
Training loss: 2.4476630687713623
Validation loss: 2.1651998412224556

Epoch: 5| Step: 4
Training loss: 2.716191530227661
Validation loss: 2.184625279518866

Epoch: 5| Step: 5
Training loss: 2.2351791858673096
Validation loss: 2.197863285259534

Epoch: 5| Step: 6
Training loss: 2.232451915740967
Validation loss: 2.2116839167892293

Epoch: 5| Step: 7
Training loss: 2.5386805534362793
Validation loss: 2.194317440832815

Epoch: 5| Step: 8
Training loss: 2.4170055389404297
Validation loss: 2.2027227647842897

Epoch: 5| Step: 9
Training loss: 2.340064525604248
Validation loss: 2.191077927107452

Epoch: 5| Step: 10
Training loss: 3.516132116317749
Validation loss: 2.185751821405144

Epoch: 65| Step: 0
Training loss: 2.393214464187622
Validation loss: 2.1819096611392115

Epoch: 5| Step: 1
Training loss: 2.084397077560425
Validation loss: 2.1701755805682112

Epoch: 5| Step: 2
Training loss: 2.143842935562134
Validation loss: 2.1578459931958105

Epoch: 5| Step: 3
Training loss: 2.3770222663879395
Validation loss: 2.152535128337081

Epoch: 5| Step: 4
Training loss: 2.6661880016326904
Validation loss: 2.148700765384141

Epoch: 5| Step: 5
Training loss: 2.728494167327881
Validation loss: 2.148195561542306

Epoch: 5| Step: 6
Training loss: 2.67521595954895
Validation loss: 2.149321284345401

Epoch: 5| Step: 7
Training loss: 2.38865327835083
Validation loss: 2.152724859535053

Epoch: 5| Step: 8
Training loss: 2.6461269855499268
Validation loss: 2.1504055300066547

Epoch: 5| Step: 9
Training loss: 3.2109577655792236
Validation loss: 2.1466601689656577

Epoch: 5| Step: 10
Training loss: 2.068483829498291
Validation loss: 2.1442856788635254

Epoch: 66| Step: 0
Training loss: 2.472266435623169
Validation loss: 2.1653687159220376

Epoch: 5| Step: 1
Training loss: 1.8770999908447266
Validation loss: 2.1936424342534875

Epoch: 5| Step: 2
Training loss: 1.9955183267593384
Validation loss: 2.212493401701732

Epoch: 5| Step: 3
Training loss: 3.130033254623413
Validation loss: 2.2357680797576904

Epoch: 5| Step: 4
Training loss: 2.7086760997772217
Validation loss: 2.245044731324719

Epoch: 5| Step: 5
Training loss: 2.5080275535583496
Validation loss: 2.244501221564508

Epoch: 5| Step: 6
Training loss: 2.3820042610168457
Validation loss: 2.228795838612382

Epoch: 5| Step: 7
Training loss: 2.0919137001037598
Validation loss: 2.1960991121107534

Epoch: 5| Step: 8
Training loss: 3.014148712158203
Validation loss: 2.1813216952867407

Epoch: 5| Step: 9
Training loss: 2.5068068504333496
Validation loss: 2.1743635592922086

Epoch: 5| Step: 10
Training loss: 2.7186779975891113
Validation loss: 2.168689368873514

Epoch: 67| Step: 0
Training loss: 2.975677728652954
Validation loss: 2.1607796671569988

Epoch: 5| Step: 1
Training loss: 2.053462505340576
Validation loss: 2.1614067349382626

Epoch: 5| Step: 2
Training loss: 2.6994733810424805
Validation loss: 2.1709766464848674

Epoch: 5| Step: 3
Training loss: 2.4037938117980957
Validation loss: 2.175980216713362

Epoch: 5| Step: 4
Training loss: 2.1973395347595215
Validation loss: 2.1839673416588896

Epoch: 5| Step: 5
Training loss: 1.9667056798934937
Validation loss: 2.2097192707882134

Epoch: 5| Step: 6
Training loss: 3.473207950592041
Validation loss: 2.2181596679072224

Epoch: 5| Step: 7
Training loss: 2.4249155521392822
Validation loss: 2.207333322494261

Epoch: 5| Step: 8
Training loss: 2.2200608253479004
Validation loss: 2.2099460619752125

Epoch: 5| Step: 9
Training loss: 2.2827231884002686
Validation loss: 2.183806014317338

Epoch: 5| Step: 10
Training loss: 2.6168832778930664
Validation loss: 2.1758054353857554

Epoch: 68| Step: 0
Training loss: 2.38734769821167
Validation loss: 2.145000764118728

Epoch: 5| Step: 1
Training loss: 2.3328609466552734
Validation loss: 2.129486189093641

Epoch: 5| Step: 2
Training loss: 2.9883780479431152
Validation loss: 2.1261579990386963

Epoch: 5| Step: 3
Training loss: 2.2822697162628174
Validation loss: 2.1233582291551816

Epoch: 5| Step: 4
Training loss: 2.230546474456787
Validation loss: 2.1175673597602436

Epoch: 5| Step: 5
Training loss: 2.17907452583313
Validation loss: 2.1125679567296016

Epoch: 5| Step: 6
Training loss: 2.46745228767395
Validation loss: 2.1189722297012166

Epoch: 5| Step: 7
Training loss: 2.261976718902588
Validation loss: 2.125622122518478

Epoch: 5| Step: 8
Training loss: 2.3966727256774902
Validation loss: 2.126985906272806

Epoch: 5| Step: 9
Training loss: 2.8487467765808105
Validation loss: 2.140570634154863

Epoch: 5| Step: 10
Training loss: 2.960094690322876
Validation loss: 2.156514093440066

Epoch: 69| Step: 0
Training loss: 2.849788188934326
Validation loss: 2.1758356914725354

Epoch: 5| Step: 1
Training loss: 2.2975716590881348
Validation loss: 2.205482413691859

Epoch: 5| Step: 2
Training loss: 2.4871411323547363
Validation loss: 2.256581324403004

Epoch: 5| Step: 3
Training loss: 2.79559063911438
Validation loss: 2.3039342895630868

Epoch: 5| Step: 4
Training loss: 2.61191987991333
Validation loss: 2.322927480102867

Epoch: 5| Step: 5
Training loss: 2.3102304935455322
Validation loss: 2.3179086690307944

Epoch: 5| Step: 6
Training loss: 2.6144986152648926
Validation loss: 2.2867595034260906

Epoch: 5| Step: 7
Training loss: 2.314664363861084
Validation loss: 2.2583373387654624

Epoch: 5| Step: 8
Training loss: 2.2117881774902344
Validation loss: 2.216858048592844

Epoch: 5| Step: 9
Training loss: 2.736348867416382
Validation loss: 2.1773669437695573

Epoch: 5| Step: 10
Training loss: 2.09854793548584
Validation loss: 2.128670325843237

Epoch: 70| Step: 0
Training loss: 2.1858155727386475
Validation loss: 2.1134577258940666

Epoch: 5| Step: 1
Training loss: 2.613980293273926
Validation loss: 2.117653280176142

Epoch: 5| Step: 2
Training loss: 2.590717077255249
Validation loss: 2.117364170730755

Epoch: 5| Step: 3
Training loss: 2.5378293991088867
Validation loss: 2.1283871025167485

Epoch: 5| Step: 4
Training loss: 2.0564916133880615
Validation loss: 2.1279468767104612

Epoch: 5| Step: 5
Training loss: 2.937901020050049
Validation loss: 2.1207754022331646

Epoch: 5| Step: 6
Training loss: 2.2167468070983887
Validation loss: 2.1200876210325506

Epoch: 5| Step: 7
Training loss: 1.9322490692138672
Validation loss: 2.11788615616419

Epoch: 5| Step: 8
Training loss: 2.907648801803589
Validation loss: 2.11875577639508

Epoch: 5| Step: 9
Training loss: 3.0315022468566895
Validation loss: 2.123498514134397

Epoch: 5| Step: 10
Training loss: 2.3379945755004883
Validation loss: 2.1393009257572952

Epoch: 71| Step: 0
Training loss: 2.579542636871338
Validation loss: 2.1499219376553773

Epoch: 5| Step: 1
Training loss: 2.5832011699676514
Validation loss: 2.1700242950070288

Epoch: 5| Step: 2
Training loss: 2.460188388824463
Validation loss: 2.1868868617601294

Epoch: 5| Step: 3
Training loss: 1.8482625484466553
Validation loss: 2.2207460659806446

Epoch: 5| Step: 4
Training loss: 2.4636359214782715
Validation loss: 2.232871263257919

Epoch: 5| Step: 5
Training loss: 2.865783214569092
Validation loss: 2.2425932192033335

Epoch: 5| Step: 6
Training loss: 2.6675612926483154
Validation loss: 2.2262548092872865

Epoch: 5| Step: 7
Training loss: 2.3952314853668213
Validation loss: 2.191948042120985

Epoch: 5| Step: 8
Training loss: 2.7168755531311035
Validation loss: 2.179288564189788

Epoch: 5| Step: 9
Training loss: 2.7030909061431885
Validation loss: 2.189782488730646

Epoch: 5| Step: 10
Training loss: 2.021548271179199
Validation loss: 2.20238600238677

Epoch: 72| Step: 0
Training loss: 2.341130495071411
Validation loss: 2.2061596660203833

Epoch: 5| Step: 1
Training loss: 2.7454898357391357
Validation loss: 2.2082223123119724

Epoch: 5| Step: 2
Training loss: 2.2015414237976074
Validation loss: 2.191976071685873

Epoch: 5| Step: 3
Training loss: 2.969386577606201
Validation loss: 2.1624892321966027

Epoch: 5| Step: 4
Training loss: 2.500460147857666
Validation loss: 2.122713388935212

Epoch: 5| Step: 5
Training loss: 2.336472749710083
Validation loss: 2.112719543518559

Epoch: 5| Step: 6
Training loss: 2.6571884155273438
Validation loss: 2.109611972685783

Epoch: 5| Step: 7
Training loss: 2.350831985473633
Validation loss: 2.1127524158006072

Epoch: 5| Step: 8
Training loss: 1.9613075256347656
Validation loss: 2.11061434079242

Epoch: 5| Step: 9
Training loss: 2.7206642627716064
Validation loss: 2.111832836622833

Epoch: 5| Step: 10
Training loss: 2.6724941730499268
Validation loss: 2.110460030135288

Epoch: 73| Step: 0
Training loss: 2.9000771045684814
Validation loss: 2.116612874051576

Epoch: 5| Step: 1
Training loss: 2.379800319671631
Validation loss: 2.1174120697923886

Epoch: 5| Step: 2
Training loss: 3.055676221847534
Validation loss: 2.127729941439885

Epoch: 5| Step: 3
Training loss: 1.9102504253387451
Validation loss: 2.1219751988687823

Epoch: 5| Step: 4
Training loss: 2.212009906768799
Validation loss: 2.1357763339114446

Epoch: 5| Step: 5
Training loss: 2.377554178237915
Validation loss: 2.143132940415413

Epoch: 5| Step: 6
Training loss: 2.5440659523010254
Validation loss: 2.161331130612281

Epoch: 5| Step: 7
Training loss: 2.8729748725891113
Validation loss: 2.180130826529636

Epoch: 5| Step: 8
Training loss: 2.1700937747955322
Validation loss: 2.172665975427115

Epoch: 5| Step: 9
Training loss: 2.165743589401245
Validation loss: 2.224455110488399

Epoch: 5| Step: 10
Training loss: 2.7375168800354004
Validation loss: 2.2754937230899768

Epoch: 74| Step: 0
Training loss: 2.2947916984558105
Validation loss: 2.279001356453024

Epoch: 5| Step: 1
Training loss: 3.348363161087036
Validation loss: 2.284175688220609

Epoch: 5| Step: 2
Training loss: 1.5847980976104736
Validation loss: 2.294745813133896

Epoch: 5| Step: 3
Training loss: 2.3933169841766357
Validation loss: 2.244065800020772

Epoch: 5| Step: 4
Training loss: 2.456463575363159
Validation loss: 2.2247399514721287

Epoch: 5| Step: 5
Training loss: 2.7724802494049072
Validation loss: 2.184785960822977

Epoch: 5| Step: 6
Training loss: 2.7584426403045654
Validation loss: 2.164777683955367

Epoch: 5| Step: 7
Training loss: 2.0815610885620117
Validation loss: 2.139531056086222

Epoch: 5| Step: 8
Training loss: 2.1763243675231934
Validation loss: 2.1219346651466946

Epoch: 5| Step: 9
Training loss: 2.823305606842041
Validation loss: 2.1156027419592744

Epoch: 5| Step: 10
Training loss: 2.1347553730010986
Validation loss: 2.1141028224780993

Epoch: 75| Step: 0
Training loss: 2.413072347640991
Validation loss: 2.1076793939836564

Epoch: 5| Step: 1
Training loss: 2.5425209999084473
Validation loss: 2.1102470531258533

Epoch: 5| Step: 2
Training loss: 2.2319393157958984
Validation loss: 2.1113772725546234

Epoch: 5| Step: 3
Training loss: 2.2374541759490967
Validation loss: 2.115167271706366

Epoch: 5| Step: 4
Training loss: 3.2958717346191406
Validation loss: 2.1182125973445114

Epoch: 5| Step: 5
Training loss: 2.572108030319214
Validation loss: 2.1127067714609127

Epoch: 5| Step: 6
Training loss: 1.971972107887268
Validation loss: 2.1242665449778237

Epoch: 5| Step: 7
Training loss: 2.4712424278259277
Validation loss: 2.1315382757494525

Epoch: 5| Step: 8
Training loss: 2.317338705062866
Validation loss: 2.129067001804229

Epoch: 5| Step: 9
Training loss: 2.4258131980895996
Validation loss: 2.1595175291902278

Epoch: 5| Step: 10
Training loss: 2.549126386642456
Validation loss: 2.1661266191031343

Epoch: 76| Step: 0
Training loss: 2.1407642364501953
Validation loss: 2.1620890825025496

Epoch: 5| Step: 1
Training loss: 1.861922264099121
Validation loss: 2.1542558054770193

Epoch: 5| Step: 2
Training loss: 2.9686672687530518
Validation loss: 2.1483619238740657

Epoch: 5| Step: 3
Training loss: 2.9480252265930176
Validation loss: 2.1256440096004035

Epoch: 5| Step: 4
Training loss: 2.4745521545410156
Validation loss: 2.108944898010582

Epoch: 5| Step: 5
Training loss: 1.8403524160385132
Validation loss: 2.1036180219342633

Epoch: 5| Step: 6
Training loss: 2.670973300933838
Validation loss: 2.0941669453856764

Epoch: 5| Step: 7
Training loss: 1.9481494426727295
Validation loss: 2.0962826628838815

Epoch: 5| Step: 8
Training loss: 2.8476028442382812
Validation loss: 2.096583504830637

Epoch: 5| Step: 9
Training loss: 2.3494791984558105
Validation loss: 2.08572026606529

Epoch: 5| Step: 10
Training loss: 2.8733694553375244
Validation loss: 2.0969944295062812

Epoch: 77| Step: 0
Training loss: 2.4099509716033936
Validation loss: 2.0930679485362065

Epoch: 5| Step: 1
Training loss: 2.754624128341675
Validation loss: 2.0970507180818947

Epoch: 5| Step: 2
Training loss: 2.5370168685913086
Validation loss: 2.1040474189225065

Epoch: 5| Step: 3
Training loss: 1.8539921045303345
Validation loss: 2.1044841825321154

Epoch: 5| Step: 4
Training loss: 2.160076141357422
Validation loss: 2.113631563801919

Epoch: 5| Step: 5
Training loss: 2.9028682708740234
Validation loss: 2.109858576969434

Epoch: 5| Step: 6
Training loss: 2.632007122039795
Validation loss: 2.1292475679869294

Epoch: 5| Step: 7
Training loss: 2.560070514678955
Validation loss: 2.141910986233783

Epoch: 5| Step: 8
Training loss: 1.9644241333007812
Validation loss: 2.146595275530251

Epoch: 5| Step: 9
Training loss: 2.283935546875
Validation loss: 2.1491533479382916

Epoch: 5| Step: 10
Training loss: 2.7927043437957764
Validation loss: 2.1584704229908604

Epoch: 78| Step: 0
Training loss: 2.3103437423706055
Validation loss: 2.1502196455514557

Epoch: 5| Step: 1
Training loss: 2.227670192718506
Validation loss: 2.1576490453494492

Epoch: 5| Step: 2
Training loss: 2.7494993209838867
Validation loss: 2.1391447385152182

Epoch: 5| Step: 3
Training loss: 3.024684190750122
Validation loss: 2.1232557194207304

Epoch: 5| Step: 4
Training loss: 2.481688976287842
Validation loss: 2.1150982200458484

Epoch: 5| Step: 5
Training loss: 2.780487298965454
Validation loss: 2.124684464546942

Epoch: 5| Step: 6
Training loss: 2.6080586910247803
Validation loss: 2.1465863386789956

Epoch: 5| Step: 7
Training loss: 2.4081034660339355
Validation loss: 2.146631124199078

Epoch: 5| Step: 8
Training loss: 2.522186756134033
Validation loss: 2.144144588901151

Epoch: 5| Step: 9
Training loss: 1.6048316955566406
Validation loss: 2.1557817228378786

Epoch: 5| Step: 10
Training loss: 2.100327968597412
Validation loss: 2.1300295245262886

Epoch: 79| Step: 0
Training loss: 3.0620548725128174
Validation loss: 2.118495971925797

Epoch: 5| Step: 1
Training loss: 2.5251681804656982
Validation loss: 2.1065794537144322

Epoch: 5| Step: 2
Training loss: 2.5556042194366455
Validation loss: 2.099117386725641

Epoch: 5| Step: 3
Training loss: 1.9672352075576782
Validation loss: 2.1021289876712266

Epoch: 5| Step: 4
Training loss: 2.0728862285614014
Validation loss: 2.1141550822924544

Epoch: 5| Step: 5
Training loss: 2.7749807834625244
Validation loss: 2.120765819344469

Epoch: 5| Step: 6
Training loss: 2.304739236831665
Validation loss: 2.1264093486211633

Epoch: 5| Step: 7
Training loss: 2.472402572631836
Validation loss: 2.1147943517213226

Epoch: 5| Step: 8
Training loss: 2.1801116466522217
Validation loss: 2.0971111200189076

Epoch: 5| Step: 9
Training loss: 2.576223850250244
Validation loss: 2.086745596701099

Epoch: 5| Step: 10
Training loss: 2.4239299297332764
Validation loss: 2.091748076100503

Epoch: 80| Step: 0
Training loss: 2.340441942214966
Validation loss: 2.0938787767964024

Epoch: 5| Step: 1
Training loss: 2.273470401763916
Validation loss: 2.1032297393327117

Epoch: 5| Step: 2
Training loss: 2.3962268829345703
Validation loss: 2.1342626617800806

Epoch: 5| Step: 3
Training loss: 2.214500904083252
Validation loss: 2.1351590387282835

Epoch: 5| Step: 4
Training loss: 2.8080990314483643
Validation loss: 2.158580336519467

Epoch: 5| Step: 5
Training loss: 2.536877155303955
Validation loss: 2.1595126198184107

Epoch: 5| Step: 6
Training loss: 1.8672494888305664
Validation loss: 2.1435334579918974

Epoch: 5| Step: 7
Training loss: 2.7942850589752197
Validation loss: 2.130341652900942

Epoch: 5| Step: 8
Training loss: 2.1578047275543213
Validation loss: 2.1163647456835677

Epoch: 5| Step: 9
Training loss: 2.608248472213745
Validation loss: 2.117947309247909

Epoch: 5| Step: 10
Training loss: 2.6095151901245117
Validation loss: 2.1256802389698644

Epoch: 81| Step: 0
Training loss: 2.373847484588623
Validation loss: 2.1708576307501843

Epoch: 5| Step: 1
Training loss: 2.463284969329834
Validation loss: 2.228518816732591

Epoch: 5| Step: 2
Training loss: 2.2188289165496826
Validation loss: 2.2975677226179387

Epoch: 5| Step: 3
Training loss: 2.5167973041534424
Validation loss: 2.3793334781482653

Epoch: 5| Step: 4
Training loss: 2.4662363529205322
Validation loss: 2.327358394540766

Epoch: 5| Step: 5
Training loss: 2.0692501068115234
Validation loss: 2.2370641795537805

Epoch: 5| Step: 6
Training loss: 2.854825258255005
Validation loss: 2.1829139622308875

Epoch: 5| Step: 7
Training loss: 2.677293539047241
Validation loss: 2.127131526188184

Epoch: 5| Step: 8
Training loss: 2.4594826698303223
Validation loss: 2.107577136767808

Epoch: 5| Step: 9
Training loss: 2.2291035652160645
Validation loss: 2.0938410464153496

Epoch: 5| Step: 10
Training loss: 2.947324752807617
Validation loss: 2.0994738327559603

Epoch: 82| Step: 0
Training loss: 2.2053725719451904
Validation loss: 2.100466521837378

Epoch: 5| Step: 1
Training loss: 2.4367470741271973
Validation loss: 2.1063448664962605

Epoch: 5| Step: 2
Training loss: 2.3849546909332275
Validation loss: 2.0828369599516674

Epoch: 5| Step: 3
Training loss: 3.217620849609375
Validation loss: 2.0746023911301807

Epoch: 5| Step: 4
Training loss: 2.556053876876831
Validation loss: 2.0700751594317857

Epoch: 5| Step: 5
Training loss: 2.2979066371917725
Validation loss: 2.078605633909984

Epoch: 5| Step: 6
Training loss: 1.8532955646514893
Validation loss: 2.071996332496725

Epoch: 5| Step: 7
Training loss: 3.2110233306884766
Validation loss: 2.070311161779588

Epoch: 5| Step: 8
Training loss: 2.021104097366333
Validation loss: 2.071658916370843

Epoch: 5| Step: 9
Training loss: 2.3027045726776123
Validation loss: 2.064632496526164

Epoch: 5| Step: 10
Training loss: 2.426950454711914
Validation loss: 2.075319161979101

Epoch: 83| Step: 0
Training loss: 1.9852806329727173
Validation loss: 2.0875337021325224

Epoch: 5| Step: 1
Training loss: 3.018354892730713
Validation loss: 2.1098196737227903

Epoch: 5| Step: 2
Training loss: 1.7641818523406982
Validation loss: 2.167960751441217

Epoch: 5| Step: 3
Training loss: 2.9699559211730957
Validation loss: 2.19899651568423

Epoch: 5| Step: 4
Training loss: 1.9593772888183594
Validation loss: 2.2185770632118307

Epoch: 5| Step: 5
Training loss: 1.8582992553710938
Validation loss: 2.18077915458269

Epoch: 5| Step: 6
Training loss: 2.9375433921813965
Validation loss: 2.1885394844957577

Epoch: 5| Step: 7
Training loss: 2.175797462463379
Validation loss: 2.1764363319643083

Epoch: 5| Step: 8
Training loss: 2.5021190643310547
Validation loss: 2.144186847953386

Epoch: 5| Step: 9
Training loss: 2.5768885612487793
Validation loss: 2.120023624871367

Epoch: 5| Step: 10
Training loss: 3.1724066734313965
Validation loss: 2.0867092635041926

Epoch: 84| Step: 0
Training loss: 2.1295650005340576
Validation loss: 2.0625926268998014

Epoch: 5| Step: 1
Training loss: 2.4199492931365967
Validation loss: 2.0626185952976184

Epoch: 5| Step: 2
Training loss: 2.1469597816467285
Validation loss: 2.0687868723305325

Epoch: 5| Step: 3
Training loss: 3.021791934967041
Validation loss: 2.072574721869602

Epoch: 5| Step: 4
Training loss: 2.5832438468933105
Validation loss: 2.0739020903905234

Epoch: 5| Step: 5
Training loss: 3.3629379272460938
Validation loss: 2.0759140406885455

Epoch: 5| Step: 6
Training loss: 2.7363853454589844
Validation loss: 2.0659727050412084

Epoch: 5| Step: 7
Training loss: 1.4577828645706177
Validation loss: 2.063505834148776

Epoch: 5| Step: 8
Training loss: 2.5602164268493652
Validation loss: 2.0526227553685508

Epoch: 5| Step: 9
Training loss: 2.5969080924987793
Validation loss: 2.0358685601142144

Epoch: 5| Step: 10
Training loss: 2.019447088241577
Validation loss: 2.066943109676402

Epoch: 85| Step: 0
Training loss: 2.2857251167297363
Validation loss: 2.1206585514929985

Epoch: 5| Step: 1
Training loss: 2.719881772994995
Validation loss: 2.210030489070441

Epoch: 5| Step: 2
Training loss: 2.771883010864258
Validation loss: 2.227887702244584

Epoch: 5| Step: 3
Training loss: 2.994352102279663
Validation loss: 2.1867001261762393

Epoch: 5| Step: 4
Training loss: 1.7338802814483643
Validation loss: 2.163116398678031

Epoch: 5| Step: 5
Training loss: 3.028301239013672
Validation loss: 2.138710080936391

Epoch: 5| Step: 6
Training loss: 2.0604636669158936
Validation loss: 2.108611947746687

Epoch: 5| Step: 7
Training loss: 2.2037880420684814
Validation loss: 2.1005552148306244

Epoch: 5| Step: 8
Training loss: 1.9016929864883423
Validation loss: 2.08169690896106

Epoch: 5| Step: 9
Training loss: 2.692472219467163
Validation loss: 2.0809115978979293

Epoch: 5| Step: 10
Training loss: 2.294438362121582
Validation loss: 2.057075141578592

Epoch: 86| Step: 0
Training loss: 2.828948974609375
Validation loss: 2.040960919472479

Epoch: 5| Step: 1
Training loss: 2.6900296211242676
Validation loss: 2.038616607266088

Epoch: 5| Step: 2
Training loss: 2.6159472465515137
Validation loss: 2.0422554721114454

Epoch: 5| Step: 3
Training loss: 2.4145805835723877
Validation loss: 2.0449418021786596

Epoch: 5| Step: 4
Training loss: 1.8668270111083984
Validation loss: 2.047296094638045

Epoch: 5| Step: 5
Training loss: 2.033047914505005
Validation loss: 2.0421046159600698

Epoch: 5| Step: 6
Training loss: 2.448528528213501
Validation loss: 2.0547209657648557

Epoch: 5| Step: 7
Training loss: 2.410517692565918
Validation loss: 2.0543488071810816

Epoch: 5| Step: 8
Training loss: 1.6568533182144165
Validation loss: 2.0740494548633532

Epoch: 5| Step: 9
Training loss: 2.7684192657470703
Validation loss: 2.107838535821566

Epoch: 5| Step: 10
Training loss: 2.8284053802490234
Validation loss: 2.11956645852776

Epoch: 87| Step: 0
Training loss: 1.8409923315048218
Validation loss: 2.139833181135116

Epoch: 5| Step: 1
Training loss: 2.751328706741333
Validation loss: 2.1482848018728276

Epoch: 5| Step: 2
Training loss: 2.200192928314209
Validation loss: 2.1711580778962825

Epoch: 5| Step: 3
Training loss: 2.4573566913604736
Validation loss: 2.15121365106234

Epoch: 5| Step: 4
Training loss: 2.447193145751953
Validation loss: 2.135791399145639

Epoch: 5| Step: 5
Training loss: 2.5527615547180176
Validation loss: 2.115260895862374

Epoch: 5| Step: 6
Training loss: 2.547600269317627
Validation loss: 2.077123688113305

Epoch: 5| Step: 7
Training loss: 2.014583110809326
Validation loss: 2.059300611096044

Epoch: 5| Step: 8
Training loss: 2.5642943382263184
Validation loss: 2.0433396190725346

Epoch: 5| Step: 9
Training loss: 2.534252882003784
Validation loss: 2.0398848108066026

Epoch: 5| Step: 10
Training loss: 2.614349365234375
Validation loss: 2.0297962183593423

Epoch: 88| Step: 0
Training loss: 2.7001376152038574
Validation loss: 2.0268280147224345

Epoch: 5| Step: 1
Training loss: 2.6489076614379883
Validation loss: 2.027535548774145

Epoch: 5| Step: 2
Training loss: 2.012892246246338
Validation loss: 2.0316940417853733

Epoch: 5| Step: 3
Training loss: 2.511544704437256
Validation loss: 2.0380868886106756

Epoch: 5| Step: 4
Training loss: 1.8323237895965576
Validation loss: 2.0507112395378853

Epoch: 5| Step: 5
Training loss: 2.767066717147827
Validation loss: 2.0612836691641037

Epoch: 5| Step: 6
Training loss: 2.6133625507354736
Validation loss: 2.071795500734801

Epoch: 5| Step: 7
Training loss: 2.830090045928955
Validation loss: 2.0755631154583347

Epoch: 5| Step: 8
Training loss: 1.8576133251190186
Validation loss: 2.0966971125653995

Epoch: 5| Step: 9
Training loss: 2.5706536769866943
Validation loss: 2.111111622984691

Epoch: 5| Step: 10
Training loss: 2.1077511310577393
Validation loss: 2.1073994405807985

Epoch: 89| Step: 0
Training loss: 1.537644624710083
Validation loss: 2.0963754884658323

Epoch: 5| Step: 1
Training loss: 2.6707682609558105
Validation loss: 2.0737433766806

Epoch: 5| Step: 2
Training loss: 2.1948838233947754
Validation loss: 2.070382592498615

Epoch: 5| Step: 3
Training loss: 1.991973876953125
Validation loss: 2.062990880781604

Epoch: 5| Step: 4
Training loss: 2.2649548053741455
Validation loss: 2.0564613573012815

Epoch: 5| Step: 5
Training loss: 2.620774030685425
Validation loss: 2.0483411178793958

Epoch: 5| Step: 6
Training loss: 2.9087228775024414
Validation loss: 2.048190297618989

Epoch: 5| Step: 7
Training loss: 2.4487836360931396
Validation loss: 2.059196338858656

Epoch: 5| Step: 8
Training loss: 2.0493195056915283
Validation loss: 2.058086274772562

Epoch: 5| Step: 9
Training loss: 3.274488925933838
Validation loss: 2.0612815298059934

Epoch: 5| Step: 10
Training loss: 2.260946035385132
Validation loss: 2.080745117638701

Epoch: 90| Step: 0
Training loss: 2.331584930419922
Validation loss: 2.085467025797854

Epoch: 5| Step: 1
Training loss: 2.6111040115356445
Validation loss: 2.1106089648380073

Epoch: 5| Step: 2
Training loss: 3.206510066986084
Validation loss: 2.12317604531524

Epoch: 5| Step: 3
Training loss: 1.4624760150909424
Validation loss: 2.0977791406775035

Epoch: 5| Step: 4
Training loss: 2.500527858734131
Validation loss: 2.063300532679404

Epoch: 5| Step: 5
Training loss: 2.5318360328674316
Validation loss: 2.0428396899213075

Epoch: 5| Step: 6
Training loss: 2.771867275238037
Validation loss: 2.039901389870592

Epoch: 5| Step: 7
Training loss: 2.5048885345458984
Validation loss: 2.0452328523000083

Epoch: 5| Step: 8
Training loss: 2.125100612640381
Validation loss: 2.0445212958961405

Epoch: 5| Step: 9
Training loss: 2.1821866035461426
Validation loss: 2.052776548170274

Epoch: 5| Step: 10
Training loss: 2.2776386737823486
Validation loss: 2.0760071508346067

Epoch: 91| Step: 0
Training loss: 2.259495258331299
Validation loss: 2.081045171265961

Epoch: 5| Step: 1
Training loss: 2.7823920249938965
Validation loss: 2.08806876726048

Epoch: 5| Step: 2
Training loss: 2.338879346847534
Validation loss: 2.0838447975856003

Epoch: 5| Step: 3
Training loss: 2.459670305252075
Validation loss: 2.085281679707189

Epoch: 5| Step: 4
Training loss: 2.379373073577881
Validation loss: 2.07788081835675

Epoch: 5| Step: 5
Training loss: 2.253626585006714
Validation loss: 2.053328137243948

Epoch: 5| Step: 6
Training loss: 2.3435888290405273
Validation loss: 2.0532369036828317

Epoch: 5| Step: 7
Training loss: 2.1514525413513184
Validation loss: 2.0594641111230336

Epoch: 5| Step: 8
Training loss: 2.5065436363220215
Validation loss: 2.0737477681970082

Epoch: 5| Step: 9
Training loss: 2.8220181465148926
Validation loss: 2.0991697055037304

Epoch: 5| Step: 10
Training loss: 1.9676486253738403
Validation loss: 2.101133754176478

Epoch: 92| Step: 0
Training loss: 1.9955222606658936
Validation loss: 2.1110587940421155

Epoch: 5| Step: 1
Training loss: 2.3293297290802
Validation loss: 2.143708218810379

Epoch: 5| Step: 2
Training loss: 1.763238549232483
Validation loss: 2.1395318585057415

Epoch: 5| Step: 3
Training loss: 2.584195375442505
Validation loss: 2.131089982166085

Epoch: 5| Step: 4
Training loss: 2.3156542778015137
Validation loss: 2.133176362642678

Epoch: 5| Step: 5
Training loss: 2.513481378555298
Validation loss: 2.1163244055163477

Epoch: 5| Step: 6
Training loss: 2.8947672843933105
Validation loss: 2.072982447121733

Epoch: 5| Step: 7
Training loss: 1.960422158241272
Validation loss: 2.0653641480271534

Epoch: 5| Step: 8
Training loss: 2.252877712249756
Validation loss: 2.0387912232388734

Epoch: 5| Step: 9
Training loss: 2.838190793991089
Validation loss: 2.032959753467191

Epoch: 5| Step: 10
Training loss: 2.654879093170166
Validation loss: 2.0293790909551803

Epoch: 93| Step: 0
Training loss: 2.3074746131896973
Validation loss: 2.022320234647361

Epoch: 5| Step: 1
Training loss: 2.42214298248291
Validation loss: 2.0323294695987495

Epoch: 5| Step: 2
Training loss: 2.485445737838745
Validation loss: 2.0283831973229685

Epoch: 5| Step: 3
Training loss: 1.7651643753051758
Validation loss: 2.038377243985412

Epoch: 5| Step: 4
Training loss: 2.1640303134918213
Validation loss: 2.041725500937431

Epoch: 5| Step: 5
Training loss: 2.479562520980835
Validation loss: 2.0668180834862495

Epoch: 5| Step: 6
Training loss: 2.969125270843506
Validation loss: 2.0948472099919475

Epoch: 5| Step: 7
Training loss: 2.1832613945007324
Validation loss: 2.090054658151442

Epoch: 5| Step: 8
Training loss: 2.2677783966064453
Validation loss: 2.085747185573783

Epoch: 5| Step: 9
Training loss: 2.2404887676239014
Validation loss: 2.0734405607305546

Epoch: 5| Step: 10
Training loss: 2.941052198410034
Validation loss: 2.04634270616757

Epoch: 94| Step: 0
Training loss: 2.461237668991089
Validation loss: 2.024337193017365

Epoch: 5| Step: 1
Training loss: 2.3254380226135254
Validation loss: 2.028985354208177

Epoch: 5| Step: 2
Training loss: 2.857109546661377
Validation loss: 2.017454444721181

Epoch: 5| Step: 3
Training loss: 2.3648736476898193
Validation loss: 2.0184576190927976

Epoch: 5| Step: 4
Training loss: 2.217196226119995
Validation loss: 2.0115040476604173

Epoch: 5| Step: 5
Training loss: 2.2784969806671143
Validation loss: 2.003504687739957

Epoch: 5| Step: 6
Training loss: 1.924169898033142
Validation loss: 2.020166648331509

Epoch: 5| Step: 7
Training loss: 1.8945114612579346
Validation loss: 2.0306073581018755

Epoch: 5| Step: 8
Training loss: 2.4777350425720215
Validation loss: 2.0824863333855905

Epoch: 5| Step: 9
Training loss: 2.7669243812561035
Validation loss: 2.111805574868315

Epoch: 5| Step: 10
Training loss: 2.489661455154419
Validation loss: 2.136057061533774

Epoch: 95| Step: 0
Training loss: 2.4516143798828125
Validation loss: 2.1750214356248097

Epoch: 5| Step: 1
Training loss: 2.3833115100860596
Validation loss: 2.128575804413006

Epoch: 5| Step: 2
Training loss: 2.164506435394287
Validation loss: 2.087404263916836

Epoch: 5| Step: 3
Training loss: 1.5174610614776611
Validation loss: 2.0857460729537474

Epoch: 5| Step: 4
Training loss: 2.724483013153076
Validation loss: 2.079432190105479

Epoch: 5| Step: 5
Training loss: 2.984034299850464
Validation loss: 2.0567082666581675

Epoch: 5| Step: 6
Training loss: 2.256855010986328
Validation loss: 2.043025516694592

Epoch: 5| Step: 7
Training loss: 2.2731337547302246
Validation loss: 2.0342320319144958

Epoch: 5| Step: 8
Training loss: 2.1985061168670654
Validation loss: 2.0510584513346353

Epoch: 5| Step: 9
Training loss: 2.8610823154449463
Validation loss: 2.0493132901448075

Epoch: 5| Step: 10
Training loss: 2.3141801357269287
Validation loss: 2.064494791851249

Epoch: 96| Step: 0
Training loss: 1.6699340343475342
Validation loss: 2.0749756879703973

Epoch: 5| Step: 1
Training loss: 2.354548931121826
Validation loss: 2.0728494839001725

Epoch: 5| Step: 2
Training loss: 2.5567736625671387
Validation loss: 2.08536652083038

Epoch: 5| Step: 3
Training loss: 2.915109872817993
Validation loss: 2.0710569889314714

Epoch: 5| Step: 4
Training loss: 2.25986909866333
Validation loss: 2.0803927144696637

Epoch: 5| Step: 5
Training loss: 2.145023822784424
Validation loss: 2.07042081381685

Epoch: 5| Step: 6
Training loss: 3.022413730621338
Validation loss: 2.0764804706778577

Epoch: 5| Step: 7
Training loss: 2.1489124298095703
Validation loss: 2.078736045027292

Epoch: 5| Step: 8
Training loss: 2.435209274291992
Validation loss: 2.0932047431186964

Epoch: 5| Step: 9
Training loss: 2.2281994819641113
Validation loss: 2.117019171355873

Epoch: 5| Step: 10
Training loss: 2.4893243312835693
Validation loss: 2.1413071437548568

Epoch: 97| Step: 0
Training loss: 2.0770809650421143
Validation loss: 2.1491531992471344

Epoch: 5| Step: 1
Training loss: 2.2134017944335938
Validation loss: 2.134478578003504

Epoch: 5| Step: 2
Training loss: 2.738490581512451
Validation loss: 2.19476237604695

Epoch: 5| Step: 3
Training loss: 2.793335199356079
Validation loss: 2.1690618863669773

Epoch: 5| Step: 4
Training loss: 2.3674442768096924
Validation loss: 2.1587086544241956

Epoch: 5| Step: 5
Training loss: 2.4625067710876465
Validation loss: 2.1747646280514297

Epoch: 5| Step: 6
Training loss: 2.215549945831299
Validation loss: 2.145562776955225

Epoch: 5| Step: 7
Training loss: 1.8543440103530884
Validation loss: 2.100619998029483

Epoch: 5| Step: 8
Training loss: 2.670161485671997
Validation loss: 2.0916324533442014

Epoch: 5| Step: 9
Training loss: 2.4179625511169434
Validation loss: 2.077305075942829

Epoch: 5| Step: 10
Training loss: 2.374452590942383
Validation loss: 2.0674363131164224

Epoch: 98| Step: 0
Training loss: 2.9502012729644775
Validation loss: 2.0424693246041574

Epoch: 5| Step: 1
Training loss: 2.4486894607543945
Validation loss: 2.025368226471768

Epoch: 5| Step: 2
Training loss: 2.110703945159912
Validation loss: 2.0220361986467914

Epoch: 5| Step: 3
Training loss: 2.278686046600342
Validation loss: 2.026664399331616

Epoch: 5| Step: 4
Training loss: 2.593386173248291
Validation loss: 2.0366575999926497

Epoch: 5| Step: 5
Training loss: 2.5522725582122803
Validation loss: 2.0372098889402164

Epoch: 5| Step: 6
Training loss: 2.238248348236084
Validation loss: 2.0272753482223838

Epoch: 5| Step: 7
Training loss: 2.685821056365967
Validation loss: 2.028129780164329

Epoch: 5| Step: 8
Training loss: 1.8638404607772827
Validation loss: 2.0451255600939513

Epoch: 5| Step: 9
Training loss: 1.7800509929656982
Validation loss: 2.081920914752509

Epoch: 5| Step: 10
Training loss: 2.7278172969818115
Validation loss: 2.2088487481558197

Epoch: 99| Step: 0
Training loss: 2.3935654163360596
Validation loss: 2.2690744835843324

Epoch: 5| Step: 1
Training loss: 2.1959586143493652
Validation loss: 2.1878520340047856

Epoch: 5| Step: 2
Training loss: 2.077127695083618
Validation loss: 2.1385013941795594

Epoch: 5| Step: 3
Training loss: 2.387016773223877
Validation loss: 2.113607987280815

Epoch: 5| Step: 4
Training loss: 2.5018410682678223
Validation loss: 2.1093157081193823

Epoch: 5| Step: 5
Training loss: 1.8291981220245361
Validation loss: 2.0616763573820873

Epoch: 5| Step: 6
Training loss: 2.4265174865722656
Validation loss: 2.0385608314186014

Epoch: 5| Step: 7
Training loss: 2.708559513092041
Validation loss: 2.032980047246461

Epoch: 5| Step: 8
Training loss: 2.9779999256134033
Validation loss: 2.0303002429264847

Epoch: 5| Step: 9
Training loss: 2.8042759895324707
Validation loss: 2.023955483590403

Epoch: 5| Step: 10
Training loss: 1.5401943922042847
Validation loss: 2.0294503729830504

Epoch: 100| Step: 0
Training loss: 2.072984218597412
Validation loss: 2.0146101315816245

Epoch: 5| Step: 1
Training loss: 2.2670769691467285
Validation loss: 2.0251397214910036

Epoch: 5| Step: 2
Training loss: 2.2128045558929443
Validation loss: 2.0216876204295824

Epoch: 5| Step: 3
Training loss: 2.1903910636901855
Validation loss: 2.0196712132423156

Epoch: 5| Step: 4
Training loss: 2.5397629737854004
Validation loss: 2.021979578079716

Epoch: 5| Step: 5
Training loss: 1.9983012676239014
Validation loss: 2.0227734324752644

Epoch: 5| Step: 6
Training loss: 2.993016481399536
Validation loss: 2.0325317690449376

Epoch: 5| Step: 7
Training loss: 2.4790749549865723
Validation loss: 2.026147666797843

Epoch: 5| Step: 8
Training loss: 1.8212082386016846
Validation loss: 2.023344261671907

Epoch: 5| Step: 9
Training loss: 2.8360321521759033
Validation loss: 2.03964558211706

Epoch: 5| Step: 10
Training loss: 2.244610071182251
Validation loss: 2.0344856682644097

Epoch: 101| Step: 0
Training loss: 2.527616024017334
Validation loss: 2.0202066603527276

Epoch: 5| Step: 1
Training loss: 2.414254665374756
Validation loss: 2.0535996139690442

Epoch: 5| Step: 2
Training loss: 2.233389377593994
Validation loss: 2.064552762175119

Epoch: 5| Step: 3
Training loss: 2.0693631172180176
Validation loss: 2.1135510372859176

Epoch: 5| Step: 4
Training loss: 3.476471424102783
Validation loss: 2.1133226527962634

Epoch: 5| Step: 5
Training loss: 2.1133463382720947
Validation loss: 2.1064834235816874

Epoch: 5| Step: 6
Training loss: 2.331775665283203
Validation loss: 2.066068272436819

Epoch: 5| Step: 7
Training loss: 1.965592384338379
Validation loss: 2.056947241547287

Epoch: 5| Step: 8
Training loss: 2.0393447875976562
Validation loss: 2.045602156269935

Epoch: 5| Step: 9
Training loss: 2.793246030807495
Validation loss: 2.028891753124934

Epoch: 5| Step: 10
Training loss: 1.7067177295684814
Validation loss: 2.0091555746652747

Epoch: 102| Step: 0
Training loss: 2.3155651092529297
Validation loss: 2.0053932384778093

Epoch: 5| Step: 1
Training loss: 2.3120763301849365
Validation loss: 2.0154091952949442

Epoch: 5| Step: 2
Training loss: 2.0387563705444336
Validation loss: 2.0121640338692615

Epoch: 5| Step: 3
Training loss: 2.606203317642212
Validation loss: 2.01101259005967

Epoch: 5| Step: 4
Training loss: 2.349358558654785
Validation loss: 2.0189259462459113

Epoch: 5| Step: 5
Training loss: 2.6502885818481445
Validation loss: 2.0186703974200833

Epoch: 5| Step: 6
Training loss: 2.4287731647491455
Validation loss: 2.066763162612915

Epoch: 5| Step: 7
Training loss: 2.1280338764190674
Validation loss: 2.0760895872628815

Epoch: 5| Step: 8
Training loss: 1.9267772436141968
Validation loss: 2.072968303516347

Epoch: 5| Step: 9
Training loss: 2.7167110443115234
Validation loss: 2.047637624125327

Epoch: 5| Step: 10
Training loss: 2.3563039302825928
Validation loss: 2.0014249317107664

Epoch: 103| Step: 0
Training loss: 3.0219085216522217
Validation loss: 1.9940069055044523

Epoch: 5| Step: 1
Training loss: 1.6588428020477295
Validation loss: 1.9848512103480678

Epoch: 5| Step: 2
Training loss: 2.140720844268799
Validation loss: 1.9865129416988743

Epoch: 5| Step: 3
Training loss: 2.1025338172912598
Validation loss: 1.9894587237347838

Epoch: 5| Step: 4
Training loss: 1.799489974975586
Validation loss: 1.9788378028459446

Epoch: 5| Step: 5
Training loss: 2.836024522781372
Validation loss: 1.9858244311424993

Epoch: 5| Step: 6
Training loss: 2.857168197631836
Validation loss: 1.9904400328154206

Epoch: 5| Step: 7
Training loss: 2.2213244438171387
Validation loss: 2.005389357125887

Epoch: 5| Step: 8
Training loss: 2.773470878601074
Validation loss: 2.0076620271128993

Epoch: 5| Step: 9
Training loss: 2.0259194374084473
Validation loss: 2.016910401723718

Epoch: 5| Step: 10
Training loss: 1.955498218536377
Validation loss: 2.055247381169309

Epoch: 104| Step: 0
Training loss: 2.2492151260375977
Validation loss: 2.106198005778815

Epoch: 5| Step: 1
Training loss: 2.792677640914917
Validation loss: 2.1688736869442846

Epoch: 5| Step: 2
Training loss: 2.001620054244995
Validation loss: 2.1399515726233043

Epoch: 5| Step: 3
Training loss: 2.2570581436157227
Validation loss: 2.0742737811098815

Epoch: 5| Step: 4
Training loss: 2.506842851638794
Validation loss: 2.0568697965273293

Epoch: 5| Step: 5
Training loss: 2.7373061180114746
Validation loss: 2.0667507366467546

Epoch: 5| Step: 6
Training loss: 2.050692081451416
Validation loss: 2.0710463716137792

Epoch: 5| Step: 7
Training loss: 2.486206531524658
Validation loss: 2.0870283726722962

Epoch: 5| Step: 8
Training loss: 2.345395565032959
Validation loss: 2.0918221909512758

Epoch: 5| Step: 9
Training loss: 2.0715527534484863
Validation loss: 2.060840739998766

Epoch: 5| Step: 10
Training loss: 2.0579891204833984
Validation loss: 2.0522974985902027

Epoch: 105| Step: 0
Training loss: 2.4336342811584473
Validation loss: 2.026488668175154

Epoch: 5| Step: 1
Training loss: 2.2287940979003906
Validation loss: 2.0077121014236123

Epoch: 5| Step: 2
Training loss: 2.064007520675659
Validation loss: 1.9804211739570863

Epoch: 5| Step: 3
Training loss: 1.649193525314331
Validation loss: 1.9746476501546881

Epoch: 5| Step: 4
Training loss: 2.3013193607330322
Validation loss: 1.9838064383434992

Epoch: 5| Step: 5
Training loss: 2.442934513092041
Validation loss: 1.9871271579496321

Epoch: 5| Step: 6
Training loss: 2.269230365753174
Validation loss: 1.9734676396974953

Epoch: 5| Step: 7
Training loss: 2.7642695903778076
Validation loss: 1.9716419994190175

Epoch: 5| Step: 8
Training loss: 2.7168471813201904
Validation loss: 1.9724909079972135

Epoch: 5| Step: 9
Training loss: 2.475161075592041
Validation loss: 1.9764921152463524

Epoch: 5| Step: 10
Training loss: 2.2559027671813965
Validation loss: 1.9819815351117043

Epoch: 106| Step: 0
Training loss: 2.379211902618408
Validation loss: 1.9937835508777249

Epoch: 5| Step: 1
Training loss: 3.0075843334198
Validation loss: 2.0317888670070197

Epoch: 5| Step: 2
Training loss: 2.414865255355835
Validation loss: 2.0678377177125666

Epoch: 5| Step: 3
Training loss: 2.632215976715088
Validation loss: 2.1323860870894564

Epoch: 5| Step: 4
Training loss: 2.042954921722412
Validation loss: 2.113629653889646

Epoch: 5| Step: 5
Training loss: 1.878882646560669
Validation loss: 2.1100508141261276

Epoch: 5| Step: 6
Training loss: 2.412757396697998
Validation loss: 2.088704974420609

Epoch: 5| Step: 7
Training loss: 2.203508138656616
Validation loss: 2.0720905257809545

Epoch: 5| Step: 8
Training loss: 2.050321102142334
Validation loss: 2.0396000621139363

Epoch: 5| Step: 9
Training loss: 2.4815664291381836
Validation loss: 2.012428105518382

Epoch: 5| Step: 10
Training loss: 2.051518678665161
Validation loss: 1.9901932208768782

Epoch: 107| Step: 0
Training loss: 1.8123750686645508
Validation loss: 1.9754925338170861

Epoch: 5| Step: 1
Training loss: 2.2213146686553955
Validation loss: 1.965792643126621

Epoch: 5| Step: 2
Training loss: 2.3539416790008545
Validation loss: 1.9620054050158429

Epoch: 5| Step: 3
Training loss: 2.281837224960327
Validation loss: 1.953992054026614

Epoch: 5| Step: 4
Training loss: 3.0053024291992188
Validation loss: 1.9543790150714178

Epoch: 5| Step: 5
Training loss: 2.3158888816833496
Validation loss: 1.960174552855953

Epoch: 5| Step: 6
Training loss: 2.238384962081909
Validation loss: 1.9677771701607654

Epoch: 5| Step: 7
Training loss: 1.6722444295883179
Validation loss: 1.9924934371825187

Epoch: 5| Step: 8
Training loss: 2.740124464035034
Validation loss: 2.0210158799284246

Epoch: 5| Step: 9
Training loss: 2.4406466484069824
Validation loss: 2.0498906989251413

Epoch: 5| Step: 10
Training loss: 2.1820309162139893
Validation loss: 2.087696715067792

Epoch: 108| Step: 0
Training loss: 2.505152463912964
Validation loss: 2.163031583191246

Epoch: 5| Step: 1
Training loss: 2.3972747325897217
Validation loss: 2.2759010407232467

Epoch: 5| Step: 2
Training loss: 2.9392313957214355
Validation loss: 2.2584607472983738

Epoch: 5| Step: 3
Training loss: 2.2833335399627686
Validation loss: 2.160675464137908

Epoch: 5| Step: 4
Training loss: 2.3851521015167236
Validation loss: 2.0903778101808284

Epoch: 5| Step: 5
Training loss: 2.9859414100646973
Validation loss: 2.0479152023151355

Epoch: 5| Step: 6
Training loss: 2.140596389770508
Validation loss: 2.015988725487904

Epoch: 5| Step: 7
Training loss: 1.8047672510147095
Validation loss: 2.009135756441342

Epoch: 5| Step: 8
Training loss: 2.2249855995178223
Validation loss: 1.9940467098707795

Epoch: 5| Step: 9
Training loss: 2.1087334156036377
Validation loss: 1.9968130742349932

Epoch: 5| Step: 10
Training loss: 2.3319828510284424
Validation loss: 1.9751073237388366

Epoch: 109| Step: 0
Training loss: 3.0593628883361816
Validation loss: 1.9686340247431109

Epoch: 5| Step: 1
Training loss: 2.1522297859191895
Validation loss: 1.9961704182368454

Epoch: 5| Step: 2
Training loss: 2.372368812561035
Validation loss: 1.9868525048737884

Epoch: 5| Step: 3
Training loss: 2.103585720062256
Validation loss: 1.9735550713795487

Epoch: 5| Step: 4
Training loss: 2.2711315155029297
Validation loss: 1.9477960807020946

Epoch: 5| Step: 5
Training loss: 1.9423277378082275
Validation loss: 1.946225494466802

Epoch: 5| Step: 6
Training loss: 2.160128355026245
Validation loss: 1.976350176718927

Epoch: 5| Step: 7
Training loss: 2.144652843475342
Validation loss: 1.9981665303630214

Epoch: 5| Step: 8
Training loss: 2.595252275466919
Validation loss: 2.080656865591644

Epoch: 5| Step: 9
Training loss: 2.286968946456909
Validation loss: 2.112676312846522

Epoch: 5| Step: 10
Training loss: 2.361948013305664
Validation loss: 2.1396427000722578

Epoch: 110| Step: 0
Training loss: 2.2560477256774902
Validation loss: 2.1639232994407736

Epoch: 5| Step: 1
Training loss: 1.7101209163665771
Validation loss: 2.2109256175256546

Epoch: 5| Step: 2
Training loss: 2.3690297603607178
Validation loss: 2.225556808133279

Epoch: 5| Step: 3
Training loss: 2.2389492988586426
Validation loss: 2.162267413190616

Epoch: 5| Step: 4
Training loss: 1.9611600637435913
Validation loss: 2.059781074523926

Epoch: 5| Step: 5
Training loss: 2.5611732006073
Validation loss: 1.9905769658345047

Epoch: 5| Step: 6
Training loss: 2.17042875289917
Validation loss: 1.965925988330636

Epoch: 5| Step: 7
Training loss: 2.587512493133545
Validation loss: 1.9839345332114928

Epoch: 5| Step: 8
Training loss: 3.062762975692749
Validation loss: 2.0057930741258847

Epoch: 5| Step: 9
Training loss: 2.203885078430176
Validation loss: 2.018813121703363

Epoch: 5| Step: 10
Training loss: 2.5021955966949463
Validation loss: 2.0041237108169065

Epoch: 111| Step: 0
Training loss: 2.906402587890625
Validation loss: 2.0010070082961873

Epoch: 5| Step: 1
Training loss: 2.13448429107666
Validation loss: 1.9826000992969801

Epoch: 5| Step: 2
Training loss: 1.9759372472763062
Validation loss: 1.9672153739519016

Epoch: 5| Step: 3
Training loss: 2.9121620655059814
Validation loss: 1.9583160979773409

Epoch: 5| Step: 4
Training loss: 1.9299800395965576
Validation loss: 1.9530607449111117

Epoch: 5| Step: 5
Training loss: 2.5270841121673584
Validation loss: 1.95829644895369

Epoch: 5| Step: 6
Training loss: 2.8534553050994873
Validation loss: 1.9902308346122823

Epoch: 5| Step: 7
Training loss: 1.9426555633544922
Validation loss: 2.039044940343467

Epoch: 5| Step: 8
Training loss: 2.608595371246338
Validation loss: 2.113946335290068

Epoch: 5| Step: 9
Training loss: 2.070533275604248
Validation loss: 2.1222262100506852

Epoch: 5| Step: 10
Training loss: 1.889856219291687
Validation loss: 2.134520225627448

Epoch: 112| Step: 0
Training loss: 2.5911431312561035
Validation loss: 2.1180120206648305

Epoch: 5| Step: 1
Training loss: 2.3952300548553467
Validation loss: 2.0585809728150726

Epoch: 5| Step: 2
Training loss: 2.4566643238067627
Validation loss: 2.0363940474807576

Epoch: 5| Step: 3
Training loss: 2.536714553833008
Validation loss: 1.9811176817904237

Epoch: 5| Step: 4
Training loss: 1.7968660593032837
Validation loss: 1.9846246127159364

Epoch: 5| Step: 5
Training loss: 3.0152456760406494
Validation loss: 1.980289573310524

Epoch: 5| Step: 6
Training loss: 2.474518299102783
Validation loss: 1.9830612521017752

Epoch: 5| Step: 7
Training loss: 2.121461868286133
Validation loss: 1.9724386199828117

Epoch: 5| Step: 8
Training loss: 2.1917343139648438
Validation loss: 1.9784619449287333

Epoch: 5| Step: 9
Training loss: 2.437528610229492
Validation loss: 1.998527887046978

Epoch: 5| Step: 10
Training loss: 1.7286299467086792
Validation loss: 2.0044588837572324

Epoch: 113| Step: 0
Training loss: 2.6241917610168457
Validation loss: 2.0233992556089997

Epoch: 5| Step: 1
Training loss: 1.8477671146392822
Validation loss: 2.0076992216930596

Epoch: 5| Step: 2
Training loss: 3.3399529457092285
Validation loss: 2.0045486291249595

Epoch: 5| Step: 3
Training loss: 2.460134506225586
Validation loss: 2.004737713003671

Epoch: 5| Step: 4
Training loss: 2.106741428375244
Validation loss: 1.999034745718843

Epoch: 5| Step: 5
Training loss: 1.7745765447616577
Validation loss: 2.0140264252180695

Epoch: 5| Step: 6
Training loss: 2.0106492042541504
Validation loss: 2.0183923462385773

Epoch: 5| Step: 7
Training loss: 2.647259473800659
Validation loss: 1.9969802107862247

Epoch: 5| Step: 8
Training loss: 2.7289369106292725
Validation loss: 1.9799743621580062

Epoch: 5| Step: 9
Training loss: 2.0207936763763428
Validation loss: 2.001976679730159

Epoch: 5| Step: 10
Training loss: 1.8187682628631592
Validation loss: 2.023095193729606

Epoch: 114| Step: 0
Training loss: 2.059508800506592
Validation loss: 2.051225341776366

Epoch: 5| Step: 1
Training loss: 1.7164071798324585
Validation loss: 2.137126079169653

Epoch: 5| Step: 2
Training loss: 2.835967540740967
Validation loss: 2.1631124160623036

Epoch: 5| Step: 3
Training loss: 1.9536176919937134
Validation loss: 2.1682948194524294

Epoch: 5| Step: 4
Training loss: 2.3294219970703125
Validation loss: 2.115111057476331

Epoch: 5| Step: 5
Training loss: 2.4235949516296387
Validation loss: 2.0671846866607666

Epoch: 5| Step: 6
Training loss: 1.8986518383026123
Validation loss: 2.0110919219191357

Epoch: 5| Step: 7
Training loss: 2.2015156745910645
Validation loss: 1.9812367821252475

Epoch: 5| Step: 8
Training loss: 2.6406784057617188
Validation loss: 1.9569242641489992

Epoch: 5| Step: 9
Training loss: 2.7387681007385254
Validation loss: 1.9438849585030669

Epoch: 5| Step: 10
Training loss: 2.5733091831207275
Validation loss: 1.935701916294713

Epoch: 115| Step: 0
Training loss: 1.9071769714355469
Validation loss: 1.9353042853775846

Epoch: 5| Step: 1
Training loss: 2.8864729404449463
Validation loss: 1.939603941414946

Epoch: 5| Step: 2
Training loss: 2.923851728439331
Validation loss: 1.9513607845511487

Epoch: 5| Step: 3
Training loss: 2.189539670944214
Validation loss: 1.9547216776878602

Epoch: 5| Step: 4
Training loss: 2.117755889892578
Validation loss: 1.977954746574484

Epoch: 5| Step: 5
Training loss: 1.9469749927520752
Validation loss: 2.003561022461102

Epoch: 5| Step: 6
Training loss: 2.17824125289917
Validation loss: 2.033707188021752

Epoch: 5| Step: 7
Training loss: 2.4107253551483154
Validation loss: 2.0417525101733465

Epoch: 5| Step: 8
Training loss: 2.038954496383667
Validation loss: 1.9892449584058536

Epoch: 5| Step: 9
Training loss: 2.1225314140319824
Validation loss: 1.9540310303370159

Epoch: 5| Step: 10
Training loss: 2.197641372680664
Validation loss: 1.9391188365156933

Epoch: 116| Step: 0
Training loss: 2.7665047645568848
Validation loss: 1.9322211998765186

Epoch: 5| Step: 1
Training loss: 2.289747953414917
Validation loss: 1.936800431179744

Epoch: 5| Step: 2
Training loss: 2.0164389610290527
Validation loss: 1.9292763599785425

Epoch: 5| Step: 3
Training loss: 2.7303671836853027
Validation loss: 1.933853364759876

Epoch: 5| Step: 4
Training loss: 2.0352866649627686
Validation loss: 1.9630068117572415

Epoch: 5| Step: 5
Training loss: 2.1492862701416016
Validation loss: 2.0076788189590618

Epoch: 5| Step: 6
Training loss: 2.5087380409240723
Validation loss: 2.049920208992497

Epoch: 5| Step: 7
Training loss: 1.8581535816192627
Validation loss: 2.045680417809435

Epoch: 5| Step: 8
Training loss: 2.256587266921997
Validation loss: 2.0374443069581063

Epoch: 5| Step: 9
Training loss: 2.422762155532837
Validation loss: 1.9846887947410665

Epoch: 5| Step: 10
Training loss: 1.6938978433609009
Validation loss: 1.9695965577197332

Epoch: 117| Step: 0
Training loss: 1.8415594100952148
Validation loss: 1.9535772415899462

Epoch: 5| Step: 1
Training loss: 2.7410316467285156
Validation loss: 1.9488035837809246

Epoch: 5| Step: 2
Training loss: 2.854830265045166
Validation loss: 1.9455898192621046

Epoch: 5| Step: 3
Training loss: 2.6833910942077637
Validation loss: 1.9621677629409298

Epoch: 5| Step: 4
Training loss: 2.129507064819336
Validation loss: 1.9541475619039228

Epoch: 5| Step: 5
Training loss: 2.0261569023132324
Validation loss: 1.9589166064416208

Epoch: 5| Step: 6
Training loss: 1.9144554138183594
Validation loss: 1.9646601087303572

Epoch: 5| Step: 7
Training loss: 1.839920997619629
Validation loss: 1.966514523311328

Epoch: 5| Step: 8
Training loss: 2.460258960723877
Validation loss: 1.959214554038099

Epoch: 5| Step: 9
Training loss: 1.5691041946411133
Validation loss: 1.9681586885965

Epoch: 5| Step: 10
Training loss: 2.412447452545166
Validation loss: 1.951212057503321

Epoch: 118| Step: 0
Training loss: 2.4877705574035645
Validation loss: 1.9636194616235711

Epoch: 5| Step: 1
Training loss: 2.234475612640381
Validation loss: 1.961599531994071

Epoch: 5| Step: 2
Training loss: 2.0082759857177734
Validation loss: 1.969800135140778

Epoch: 5| Step: 3
Training loss: 2.464315891265869
Validation loss: 1.9845059879364506

Epoch: 5| Step: 4
Training loss: 2.2763144969940186
Validation loss: 1.9984487795060681

Epoch: 5| Step: 5
Training loss: 2.0152785778045654
Validation loss: 1.9855615528680945

Epoch: 5| Step: 6
Training loss: 2.0895514488220215
Validation loss: 1.9873349717868272

Epoch: 5| Step: 7
Training loss: 2.0034384727478027
Validation loss: 1.9682835314863472

Epoch: 5| Step: 8
Training loss: 2.7110817432403564
Validation loss: 1.9528865506572108

Epoch: 5| Step: 9
Training loss: 2.6175246238708496
Validation loss: 1.949858989766849

Epoch: 5| Step: 10
Training loss: 1.4773249626159668
Validation loss: 1.9429526893041467

Epoch: 119| Step: 0
Training loss: 2.1561379432678223
Validation loss: 1.943977273920531

Epoch: 5| Step: 1
Training loss: 2.0888774394989014
Validation loss: 1.938828094031221

Epoch: 5| Step: 2
Training loss: 2.404196262359619
Validation loss: 1.9398646329038887

Epoch: 5| Step: 3
Training loss: 2.8313724994659424
Validation loss: 1.9360875955191992

Epoch: 5| Step: 4
Training loss: 1.855735182762146
Validation loss: 1.924396248273952

Epoch: 5| Step: 5
Training loss: 2.4665050506591797
Validation loss: 1.9268172889627435

Epoch: 5| Step: 6
Training loss: 1.5012675523757935
Validation loss: 1.9263441652380011

Epoch: 5| Step: 7
Training loss: 2.126758098602295
Validation loss: 1.944885641015986

Epoch: 5| Step: 8
Training loss: 2.139704704284668
Validation loss: 1.9757169485092163

Epoch: 5| Step: 9
Training loss: 2.1909263134002686
Validation loss: 2.0127780334923857

Epoch: 5| Step: 10
Training loss: 2.663721799850464
Validation loss: 2.0608470901366203

Epoch: 120| Step: 0
Training loss: 2.4090137481689453
Validation loss: 2.0780403434589343

Epoch: 5| Step: 1
Training loss: 2.5214595794677734
Validation loss: 2.0682883262634277

Epoch: 5| Step: 2
Training loss: 2.281094551086426
Validation loss: 2.038363537480754

Epoch: 5| Step: 3
Training loss: 1.9600608348846436
Validation loss: 1.9973545253917735

Epoch: 5| Step: 4
Training loss: 2.752941608428955
Validation loss: 1.9634483398929719

Epoch: 5| Step: 5
Training loss: 1.7077146768569946
Validation loss: 1.9487920884163148

Epoch: 5| Step: 6
Training loss: 2.8882126808166504
Validation loss: 1.9479802116270988

Epoch: 5| Step: 7
Training loss: 2.6281485557556152
Validation loss: 1.939645263456529

Epoch: 5| Step: 8
Training loss: 2.584001064300537
Validation loss: 1.9410007704970658

Epoch: 5| Step: 9
Training loss: 1.5549046993255615
Validation loss: 1.9426903968216271

Epoch: 5| Step: 10
Training loss: 1.1130584478378296
Validation loss: 1.9468041671219694

Epoch: 121| Step: 0
Training loss: 1.602012276649475
Validation loss: 1.9495401895174416

Epoch: 5| Step: 1
Training loss: 2.1790809631347656
Validation loss: 1.9518471199979064

Epoch: 5| Step: 2
Training loss: 2.6917145252227783
Validation loss: 1.9641332267433085

Epoch: 5| Step: 3
Training loss: 1.883774757385254
Validation loss: 1.9684019652746056

Epoch: 5| Step: 4
Training loss: 2.299638271331787
Validation loss: 1.9852765965205368

Epoch: 5| Step: 5
Training loss: 3.21000599861145
Validation loss: 2.002309604357648

Epoch: 5| Step: 6
Training loss: 1.9416354894638062
Validation loss: 2.0165406670621646

Epoch: 5| Step: 7
Training loss: 2.0662789344787598
Validation loss: 2.0219021868962113

Epoch: 5| Step: 8
Training loss: 1.969670295715332
Validation loss: 2.0160463792021557

Epoch: 5| Step: 9
Training loss: 2.126394510269165
Validation loss: 2.0224986332719044

Epoch: 5| Step: 10
Training loss: 2.4246528148651123
Validation loss: 2.0328289052491546

Epoch: 122| Step: 0
Training loss: 1.829908013343811
Validation loss: 2.0082142109512002

Epoch: 5| Step: 1
Training loss: 1.7683178186416626
Validation loss: 1.9833922475896857

Epoch: 5| Step: 2
Training loss: 2.3914313316345215
Validation loss: 1.971739815127465

Epoch: 5| Step: 3
Training loss: 2.8080241680145264
Validation loss: 1.9584519914401475

Epoch: 5| Step: 4
Training loss: 2.0726311206817627
Validation loss: 1.9481181547205935

Epoch: 5| Step: 5
Training loss: 2.5716466903686523
Validation loss: 1.9468424153584305

Epoch: 5| Step: 6
Training loss: 1.8289165496826172
Validation loss: 1.9777879561147382

Epoch: 5| Step: 7
Training loss: 2.0774104595184326
Validation loss: 1.982460045045422

Epoch: 5| Step: 8
Training loss: 2.369030475616455
Validation loss: 2.017421086629232

Epoch: 5| Step: 9
Training loss: 2.163220167160034
Validation loss: 2.0004373827288227

Epoch: 5| Step: 10
Training loss: 2.347529172897339
Validation loss: 1.9745333784370012

Epoch: 123| Step: 0
Training loss: 1.0381954908370972
Validation loss: 1.9409112058660036

Epoch: 5| Step: 1
Training loss: 1.8622633218765259
Validation loss: 1.9363053229547316

Epoch: 5| Step: 2
Training loss: 2.1015374660491943
Validation loss: 1.9272940517753683

Epoch: 5| Step: 3
Training loss: 3.0875515937805176
Validation loss: 1.9442108767006987

Epoch: 5| Step: 4
Training loss: 2.5738799571990967
Validation loss: 1.95548975852228

Epoch: 5| Step: 5
Training loss: 2.3865292072296143
Validation loss: 1.9867127531318254

Epoch: 5| Step: 6
Training loss: 2.0114216804504395
Validation loss: 2.0524249166570683

Epoch: 5| Step: 7
Training loss: 2.8680336475372314
Validation loss: 2.1330513287616033

Epoch: 5| Step: 8
Training loss: 2.103358507156372
Validation loss: 2.1578743765431065

Epoch: 5| Step: 9
Training loss: 2.1707661151885986
Validation loss: 2.1615846003255537

Epoch: 5| Step: 10
Training loss: 2.552635908126831
Validation loss: 2.088862033300502

Epoch: 124| Step: 0
Training loss: 1.969503402709961
Validation loss: 2.009573649334651

Epoch: 5| Step: 1
Training loss: 1.8503135442733765
Validation loss: 1.9519942857885872

Epoch: 5| Step: 2
Training loss: 2.109344482421875
Validation loss: 1.9222128673266339

Epoch: 5| Step: 3
Training loss: 1.9167263507843018
Validation loss: 1.9258653374128445

Epoch: 5| Step: 4
Training loss: 1.7770156860351562
Validation loss: 1.9176368828742736

Epoch: 5| Step: 5
Training loss: 1.7910534143447876
Validation loss: 1.9208115403370192

Epoch: 5| Step: 6
Training loss: 2.913939952850342
Validation loss: 1.9192606364527056

Epoch: 5| Step: 7
Training loss: 2.50325345993042
Validation loss: 1.9235205752875215

Epoch: 5| Step: 8
Training loss: 2.860351085662842
Validation loss: 1.9649361794994724

Epoch: 5| Step: 9
Training loss: 2.3947248458862305
Validation loss: 1.988202694923647

Epoch: 5| Step: 10
Training loss: 2.1229631900787354
Validation loss: 2.0280811427741923

Epoch: 125| Step: 0
Training loss: 2.143981456756592
Validation loss: 2.043433074028261

Epoch: 5| Step: 1
Training loss: 2.136493682861328
Validation loss: 2.03816363247492

Epoch: 5| Step: 2
Training loss: 1.9380767345428467
Validation loss: 2.007535737047913

Epoch: 5| Step: 3
Training loss: 2.521472454071045
Validation loss: 1.9995855439093806

Epoch: 5| Step: 4
Training loss: 2.1526501178741455
Validation loss: 1.9947435932774698

Epoch: 5| Step: 5
Training loss: 1.7911258935928345
Validation loss: 2.0010425621463406

Epoch: 5| Step: 6
Training loss: 2.261378049850464
Validation loss: 2.0091567193308184

Epoch: 5| Step: 7
Training loss: 2.705880641937256
Validation loss: 2.0161031151330597

Epoch: 5| Step: 8
Training loss: 2.389737606048584
Validation loss: 1.975714506641511

Epoch: 5| Step: 9
Training loss: 2.137423038482666
Validation loss: 1.9669386097179946

Epoch: 5| Step: 10
Training loss: 2.2051773071289062
Validation loss: 1.961623502034013

Epoch: 126| Step: 0
Training loss: 2.2719974517822266
Validation loss: 1.946233569934804

Epoch: 5| Step: 1
Training loss: 1.6788387298583984
Validation loss: 1.9300835286417315

Epoch: 5| Step: 2
Training loss: 2.7438478469848633
Validation loss: 1.9678037794687415

Epoch: 5| Step: 3
Training loss: 2.11967396736145
Validation loss: 1.967258676405876

Epoch: 5| Step: 4
Training loss: 2.3291680812835693
Validation loss: 1.9747284073983469

Epoch: 5| Step: 5
Training loss: 2.1362404823303223
Validation loss: 1.9970844919963548

Epoch: 5| Step: 6
Training loss: 2.2744650840759277
Validation loss: 2.0114319926948956

Epoch: 5| Step: 7
Training loss: 1.9097801446914673
Validation loss: 1.9955869733646352

Epoch: 5| Step: 8
Training loss: 2.351872205734253
Validation loss: 2.00281851009656

Epoch: 5| Step: 9
Training loss: 2.23667573928833
Validation loss: 1.9873134487418718

Epoch: 5| Step: 10
Training loss: 1.9057435989379883
Validation loss: 1.9715262997534968

Epoch: 127| Step: 0
Training loss: 2.1533713340759277
Validation loss: 1.9589003568054528

Epoch: 5| Step: 1
Training loss: 2.0164105892181396
Validation loss: 1.9454490984639814

Epoch: 5| Step: 2
Training loss: 2.4930295944213867
Validation loss: 1.9563800468239734

Epoch: 5| Step: 3
Training loss: 1.7231369018554688
Validation loss: 1.956987719382009

Epoch: 5| Step: 4
Training loss: 1.891434907913208
Validation loss: 1.9679973458731046

Epoch: 5| Step: 5
Training loss: 2.421233654022217
Validation loss: 1.9856890209259526

Epoch: 5| Step: 6
Training loss: 2.4142444133758545
Validation loss: 2.0115648405526274

Epoch: 5| Step: 7
Training loss: 2.424278974533081
Validation loss: 2.0368213294654764

Epoch: 5| Step: 8
Training loss: 2.135024070739746
Validation loss: 2.0354126140635502

Epoch: 5| Step: 9
Training loss: 2.152690887451172
Validation loss: 2.006455725239169

Epoch: 5| Step: 10
Training loss: 1.78611421585083
Validation loss: 2.0028705955833517

Epoch: 128| Step: 0
Training loss: 2.489720582962036
Validation loss: 1.9678530564872168

Epoch: 5| Step: 1
Training loss: 1.6728832721710205
Validation loss: 1.9540200374459709

Epoch: 5| Step: 2
Training loss: 2.2303574085235596
Validation loss: 1.9532526718672885

Epoch: 5| Step: 3
Training loss: 2.179037570953369
Validation loss: 1.947248798544689

Epoch: 5| Step: 4
Training loss: 1.9433176517486572
Validation loss: 1.9582489498199955

Epoch: 5| Step: 5
Training loss: 2.6516637802124023
Validation loss: 1.938524107779226

Epoch: 5| Step: 6
Training loss: 1.8419338464736938
Validation loss: 1.9546097529831754

Epoch: 5| Step: 7
Training loss: 1.590488076210022
Validation loss: 1.9668550350332772

Epoch: 5| Step: 8
Training loss: 2.246886730194092
Validation loss: 1.9979831851938719

Epoch: 5| Step: 9
Training loss: 2.411417007446289
Validation loss: 2.028663294289702

Epoch: 5| Step: 10
Training loss: 2.424701452255249
Validation loss: 2.0526138890174126

Epoch: 129| Step: 0
Training loss: 2.1822280883789062
Validation loss: 2.065922483321159

Epoch: 5| Step: 1
Training loss: 2.0864081382751465
Validation loss: 2.0460513702002903

Epoch: 5| Step: 2
Training loss: 1.7633965015411377
Validation loss: 2.0268567544157787

Epoch: 5| Step: 3
Training loss: 2.1441142559051514
Validation loss: 1.982077105070955

Epoch: 5| Step: 4
Training loss: 2.242108106613159
Validation loss: 1.9821551897192513

Epoch: 5| Step: 5
Training loss: 2.6807198524475098
Validation loss: 1.9684373537699382

Epoch: 5| Step: 6
Training loss: 1.3596575260162354
Validation loss: 1.9669891685567877

Epoch: 5| Step: 7
Training loss: 2.6147143840789795
Validation loss: 1.9560631846868863

Epoch: 5| Step: 8
Training loss: 1.7866299152374268
Validation loss: 1.9433076522683586

Epoch: 5| Step: 9
Training loss: 2.5951576232910156
Validation loss: 1.9584374530341035

Epoch: 5| Step: 10
Training loss: 1.9119956493377686
Validation loss: 1.9355703053935882

Epoch: 130| Step: 0
Training loss: 1.7054580450057983
Validation loss: 1.9199099130527948

Epoch: 5| Step: 1
Training loss: 1.458133578300476
Validation loss: 1.929856615681802

Epoch: 5| Step: 2
Training loss: 2.3315625190734863
Validation loss: 1.9536126941762946

Epoch: 5| Step: 3
Training loss: 1.844718337059021
Validation loss: 1.9598788189631637

Epoch: 5| Step: 4
Training loss: 2.3105525970458984
Validation loss: 1.9740977428292716

Epoch: 5| Step: 5
Training loss: 2.234450101852417
Validation loss: 2.003211232923692

Epoch: 5| Step: 6
Training loss: 2.177053928375244
Validation loss: 2.023616078079388

Epoch: 5| Step: 7
Training loss: 2.371913433074951
Validation loss: 2.046529944225024

Epoch: 5| Step: 8
Training loss: 1.965376615524292
Validation loss: 2.0380489672383955

Epoch: 5| Step: 9
Training loss: 2.7946627140045166
Validation loss: 2.0043128882685015

Epoch: 5| Step: 10
Training loss: 2.168926954269409
Validation loss: 1.9696856198772308

Epoch: 131| Step: 0
Training loss: 2.3186697959899902
Validation loss: 1.9525863585933563

Epoch: 5| Step: 1
Training loss: 1.8887513875961304
Validation loss: 1.977581766343886

Epoch: 5| Step: 2
Training loss: 2.0262792110443115
Validation loss: 2.0113982269840855

Epoch: 5| Step: 3
Training loss: 1.9829702377319336
Validation loss: 2.0268896779706402

Epoch: 5| Step: 4
Training loss: 1.805131196975708
Validation loss: 2.0558254590598484

Epoch: 5| Step: 5
Training loss: 2.3046374320983887
Validation loss: 2.073773225148519

Epoch: 5| Step: 6
Training loss: 2.4488463401794434
Validation loss: 2.1143605580893894

Epoch: 5| Step: 7
Training loss: 2.653331756591797
Validation loss: 2.104927765425815

Epoch: 5| Step: 8
Training loss: 1.7065715789794922
Validation loss: 2.0855588259235507

Epoch: 5| Step: 9
Training loss: 2.1114330291748047
Validation loss: 2.0418198018945675

Epoch: 5| Step: 10
Training loss: 2.7145912647247314
Validation loss: 2.038173540945976

Epoch: 132| Step: 0
Training loss: 1.7399814128875732
Validation loss: 2.011885663514496

Epoch: 5| Step: 1
Training loss: 2.0376334190368652
Validation loss: 1.9836399555206299

Epoch: 5| Step: 2
Training loss: 1.8439195156097412
Validation loss: 1.9557449881748488

Epoch: 5| Step: 3
Training loss: 2.3614368438720703
Validation loss: 1.937268998033257

Epoch: 5| Step: 4
Training loss: 1.7055079936981201
Validation loss: 1.928379076783375

Epoch: 5| Step: 5
Training loss: 2.2025485038757324
Validation loss: 1.9493228427825435

Epoch: 5| Step: 6
Training loss: 1.983350157737732
Validation loss: 1.9608719605271534

Epoch: 5| Step: 7
Training loss: 2.2335216999053955
Validation loss: 1.9770839739871282

Epoch: 5| Step: 8
Training loss: 2.807595729827881
Validation loss: 1.9875207665146037

Epoch: 5| Step: 9
Training loss: 2.0557875633239746
Validation loss: 2.0311059259599253

Epoch: 5| Step: 10
Training loss: 2.301530599594116
Validation loss: 2.026694251644996

Epoch: 133| Step: 0
Training loss: 1.9983389377593994
Validation loss: 2.028531034787496

Epoch: 5| Step: 1
Training loss: 2.109387159347534
Validation loss: 2.0170906154058312

Epoch: 5| Step: 2
Training loss: 1.566121220588684
Validation loss: 2.0035520215188303

Epoch: 5| Step: 3
Training loss: 2.7210891246795654
Validation loss: 1.9792279658779022

Epoch: 5| Step: 4
Training loss: 2.467041492462158
Validation loss: 1.9882961601339362

Epoch: 5| Step: 5
Training loss: 1.7306028604507446
Validation loss: 1.9863825164815432

Epoch: 5| Step: 6
Training loss: 2.1541895866394043
Validation loss: 2.007287061342629

Epoch: 5| Step: 7
Training loss: 2.5430543422698975
Validation loss: 2.014320391480641

Epoch: 5| Step: 8
Training loss: 2.031094551086426
Validation loss: 2.050171741875269

Epoch: 5| Step: 9
Training loss: 2.273838996887207
Validation loss: 2.0803917954044957

Epoch: 5| Step: 10
Training loss: 1.7993276119232178
Validation loss: 2.075621893329005

Epoch: 134| Step: 0
Training loss: 2.1146819591522217
Validation loss: 2.0766510296893377

Epoch: 5| Step: 1
Training loss: 1.926519751548767
Validation loss: 2.07381837086011

Epoch: 5| Step: 2
Training loss: 1.7187496423721313
Validation loss: 2.0572776358614684

Epoch: 5| Step: 3
Training loss: 2.388399600982666
Validation loss: 2.088674000514451

Epoch: 5| Step: 4
Training loss: 1.4795277118682861
Validation loss: 2.093515093608569

Epoch: 5| Step: 5
Training loss: 1.9909111261367798
Validation loss: 2.083830416843455

Epoch: 5| Step: 6
Training loss: 2.568999767303467
Validation loss: 2.0728767482183312

Epoch: 5| Step: 7
Training loss: 2.150984287261963
Validation loss: 2.0466141803290254

Epoch: 5| Step: 8
Training loss: 1.720414400100708
Validation loss: 1.9938363798203007

Epoch: 5| Step: 9
Training loss: 2.2843289375305176
Validation loss: 1.967490514119466

Epoch: 5| Step: 10
Training loss: 2.995432138442993
Validation loss: 1.9632905183299896

Epoch: 135| Step: 0
Training loss: 2.4353840351104736
Validation loss: 1.9763976130434262

Epoch: 5| Step: 1
Training loss: 2.292253017425537
Validation loss: 1.9983136987173429

Epoch: 5| Step: 2
Training loss: 2.1938135623931885
Validation loss: 2.015347078282346

Epoch: 5| Step: 3
Training loss: 2.0989437103271484
Validation loss: 2.0048027987121255

Epoch: 5| Step: 4
Training loss: 1.8511106967926025
Validation loss: 2.007347087706289

Epoch: 5| Step: 5
Training loss: 1.7711204290390015
Validation loss: 1.9911099954317975

Epoch: 5| Step: 6
Training loss: 2.0542006492614746
Validation loss: 1.9949161929468955

Epoch: 5| Step: 7
Training loss: 2.0516200065612793
Validation loss: 2.0182890430573495

Epoch: 5| Step: 8
Training loss: 2.3052382469177246
Validation loss: 2.0355091556426017

Epoch: 5| Step: 9
Training loss: 2.3774495124816895
Validation loss: 2.0779664631812804

Epoch: 5| Step: 10
Training loss: 1.5197601318359375
Validation loss: 2.089307064651161

Epoch: 136| Step: 0
Training loss: 1.815167784690857
Validation loss: 2.0835344611957507

Epoch: 5| Step: 1
Training loss: 1.7675096988677979
Validation loss: 2.0365883522136237

Epoch: 5| Step: 2
Training loss: 2.137831211090088
Validation loss: 1.9938185971270326

Epoch: 5| Step: 3
Training loss: 1.679091453552246
Validation loss: 1.973203864148868

Epoch: 5| Step: 4
Training loss: 2.623739719390869
Validation loss: 1.9563384773910686

Epoch: 5| Step: 5
Training loss: 2.029292583465576
Validation loss: 1.9427776311033516

Epoch: 5| Step: 6
Training loss: 2.4808812141418457
Validation loss: 1.9361483538022606

Epoch: 5| Step: 7
Training loss: 2.919994354248047
Validation loss: 1.9507771204876643

Epoch: 5| Step: 8
Training loss: 2.0026168823242188
Validation loss: 1.9618334590747792

Epoch: 5| Step: 9
Training loss: 1.9050061702728271
Validation loss: 2.014677970640121

Epoch: 5| Step: 10
Training loss: 1.5165928602218628
Validation loss: 2.050436668498542

Epoch: 137| Step: 0
Training loss: 2.6087818145751953
Validation loss: 2.102976724665652

Epoch: 5| Step: 1
Training loss: 2.3752365112304688
Validation loss: 2.124967703255274

Epoch: 5| Step: 2
Training loss: 2.8878464698791504
Validation loss: 2.1724880164669407

Epoch: 5| Step: 3
Training loss: 1.9553954601287842
Validation loss: 2.175065855826101

Epoch: 5| Step: 4
Training loss: 2.405844211578369
Validation loss: 2.1543121773709535

Epoch: 5| Step: 5
Training loss: 1.8772414922714233
Validation loss: 2.1054323488666165

Epoch: 5| Step: 6
Training loss: 1.2086412906646729
Validation loss: 2.0507580926341396

Epoch: 5| Step: 7
Training loss: 1.2288399934768677
Validation loss: 2.0046828921123216

Epoch: 5| Step: 8
Training loss: 2.1443653106689453
Validation loss: 1.987783101297194

Epoch: 5| Step: 9
Training loss: 2.2142953872680664
Validation loss: 1.9960520357213996

Epoch: 5| Step: 10
Training loss: 2.4691317081451416
Validation loss: 1.9911888786541518

Epoch: 138| Step: 0
Training loss: 2.044785499572754
Validation loss: 1.9953125945983394

Epoch: 5| Step: 1
Training loss: 1.3064844608306885
Validation loss: 1.9895167325132637

Epoch: 5| Step: 2
Training loss: 1.8326549530029297
Validation loss: 2.0041659057781263

Epoch: 5| Step: 3
Training loss: 2.435713768005371
Validation loss: 2.00948001492408

Epoch: 5| Step: 4
Training loss: 2.2003517150878906
Validation loss: 2.0151199884312128

Epoch: 5| Step: 5
Training loss: 2.5064685344696045
Validation loss: 2.006394132491081

Epoch: 5| Step: 6
Training loss: 2.058885097503662
Validation loss: 2.0202427397492113

Epoch: 5| Step: 7
Training loss: 2.2466700077056885
Validation loss: 2.0712634363482074

Epoch: 5| Step: 8
Training loss: 1.7018448114395142
Validation loss: 2.1241007363924416

Epoch: 5| Step: 9
Training loss: 2.8362624645233154
Validation loss: 2.144868402070897

Epoch: 5| Step: 10
Training loss: 1.71256685256958
Validation loss: 2.144348846968784

Epoch: 139| Step: 0
Training loss: 1.8927719593048096
Validation loss: 2.128609685487645

Epoch: 5| Step: 1
Training loss: 2.0771539211273193
Validation loss: 2.098156662397487

Epoch: 5| Step: 2
Training loss: 2.2548112869262695
Validation loss: 2.0513112442467802

Epoch: 5| Step: 3
Training loss: 2.005812883377075
Validation loss: 2.01703974252106

Epoch: 5| Step: 4
Training loss: 2.5065207481384277
Validation loss: 2.0092041595007784

Epoch: 5| Step: 5
Training loss: 1.4972326755523682
Validation loss: 1.9939092256689583

Epoch: 5| Step: 6
Training loss: 2.266012191772461
Validation loss: 1.9719956203173565

Epoch: 5| Step: 7
Training loss: 1.7317352294921875
Validation loss: 1.9574241997093282

Epoch: 5| Step: 8
Training loss: 2.0811190605163574
Validation loss: 1.9494150223270539

Epoch: 5| Step: 9
Training loss: 1.895220160484314
Validation loss: 1.9676753039001136

Epoch: 5| Step: 10
Training loss: 2.091075897216797
Validation loss: 1.9545554422563123

Epoch: 140| Step: 0
Training loss: 1.9944744110107422
Validation loss: 1.986356790347766

Epoch: 5| Step: 1
Training loss: 2.026233434677124
Validation loss: 1.9836532736337313

Epoch: 5| Step: 2
Training loss: 1.3172169923782349
Validation loss: 1.991608517144316

Epoch: 5| Step: 3
Training loss: 1.5387365818023682
Validation loss: 2.002768314012917

Epoch: 5| Step: 4
Training loss: 2.537410020828247
Validation loss: 1.9761382033748012

Epoch: 5| Step: 5
Training loss: 2.322871208190918
Validation loss: 1.9577444650793587

Epoch: 5| Step: 6
Training loss: 1.9477170705795288
Validation loss: 1.942944049835205

Epoch: 5| Step: 7
Training loss: 1.8375835418701172
Validation loss: 1.9521776142940725

Epoch: 5| Step: 8
Training loss: 2.833604335784912
Validation loss: 1.9432908078675628

Epoch: 5| Step: 9
Training loss: 2.1375012397766113
Validation loss: 1.96471712153445

Epoch: 5| Step: 10
Training loss: 1.6305277347564697
Validation loss: 1.9745239160394157

Epoch: 141| Step: 0
Training loss: 1.7687793970108032
Validation loss: 1.9703528278617448

Epoch: 5| Step: 1
Training loss: 1.4716845750808716
Validation loss: 1.9862601295594247

Epoch: 5| Step: 2
Training loss: 1.4723304510116577
Validation loss: 1.9959504937612882

Epoch: 5| Step: 3
Training loss: 2.171083450317383
Validation loss: 1.9952053703287596

Epoch: 5| Step: 4
Training loss: 2.4548721313476562
Validation loss: 2.0253840928436606

Epoch: 5| Step: 5
Training loss: 1.9351085424423218
Validation loss: 2.0098313259822067

Epoch: 5| Step: 6
Training loss: 2.2163033485412598
Validation loss: 2.0131074536231255

Epoch: 5| Step: 7
Training loss: 2.267016887664795
Validation loss: 2.0066683036024853

Epoch: 5| Step: 8
Training loss: 1.6832374334335327
Validation loss: 2.017559746260284

Epoch: 5| Step: 9
Training loss: 2.376652479171753
Validation loss: 2.017071459883003

Epoch: 5| Step: 10
Training loss: 2.167851209640503
Validation loss: 2.015844383547383

Epoch: 142| Step: 0
Training loss: 1.7481193542480469
Validation loss: 2.0042919343517673

Epoch: 5| Step: 1
Training loss: 2.191227436065674
Validation loss: 1.9988957989600398

Epoch: 5| Step: 2
Training loss: 1.8362770080566406
Validation loss: 2.012832601865133

Epoch: 5| Step: 3
Training loss: 1.8671839237213135
Validation loss: 1.9882439721015193

Epoch: 5| Step: 4
Training loss: 1.3915035724639893
Validation loss: 1.9906364269154047

Epoch: 5| Step: 5
Training loss: 2.347959041595459
Validation loss: 2.0082650210267756

Epoch: 5| Step: 6
Training loss: 2.2499070167541504
Validation loss: 1.986201064561003

Epoch: 5| Step: 7
Training loss: 1.9331409931182861
Validation loss: 1.9893097608320174

Epoch: 5| Step: 8
Training loss: 2.8214268684387207
Validation loss: 1.9817420410853561

Epoch: 5| Step: 9
Training loss: 1.5064021348953247
Validation loss: 1.9750633214109687

Epoch: 5| Step: 10
Training loss: 2.2940824031829834
Validation loss: 1.9646433566206245

Epoch: 143| Step: 0
Training loss: 2.068572521209717
Validation loss: 1.9567762677387526

Epoch: 5| Step: 1
Training loss: 2.5125391483306885
Validation loss: 1.9449137513355543

Epoch: 5| Step: 2
Training loss: 1.7863903045654297
Validation loss: 1.9407756969492922

Epoch: 5| Step: 3
Training loss: 2.4160313606262207
Validation loss: 1.9396402630754697

Epoch: 5| Step: 4
Training loss: 2.1489739418029785
Validation loss: 1.9535053442883235

Epoch: 5| Step: 5
Training loss: 1.911669135093689
Validation loss: 1.9528262128112137

Epoch: 5| Step: 6
Training loss: 1.704241156578064
Validation loss: 1.9565587710308772

Epoch: 5| Step: 7
Training loss: 1.7527682781219482
Validation loss: 1.9556351528372815

Epoch: 5| Step: 8
Training loss: 2.0180554389953613
Validation loss: 1.9896816181880173

Epoch: 5| Step: 9
Training loss: 1.4634301662445068
Validation loss: 2.0395846289973103

Epoch: 5| Step: 10
Training loss: 1.8670194149017334
Validation loss: 2.063392880142376

Epoch: 144| Step: 0
Training loss: 2.0496630668640137
Validation loss: 2.069846413468802

Epoch: 5| Step: 1
Training loss: 1.7715622186660767
Validation loss: 2.0643480362430697

Epoch: 5| Step: 2
Training loss: 1.8377418518066406
Validation loss: 2.044848599741536

Epoch: 5| Step: 3
Training loss: 2.2198679447174072
Validation loss: 2.0154277175985356

Epoch: 5| Step: 4
Training loss: 2.078254461288452
Validation loss: 1.9971321449484876

Epoch: 5| Step: 5
Training loss: 2.1891093254089355
Validation loss: 1.989907803074006

Epoch: 5| Step: 6
Training loss: 1.5080257654190063
Validation loss: 1.9888247956511795

Epoch: 5| Step: 7
Training loss: 1.8286584615707397
Validation loss: 1.9706523546608545

Epoch: 5| Step: 8
Training loss: 1.8017141819000244
Validation loss: 1.9816015587058118

Epoch: 5| Step: 9
Training loss: 2.329542875289917
Validation loss: 1.9857354292305567

Epoch: 5| Step: 10
Training loss: 1.8994455337524414
Validation loss: 1.9994069043026175

Epoch: 145| Step: 0
Training loss: 2.471388339996338
Validation loss: 2.011307485641972

Epoch: 5| Step: 1
Training loss: 1.850856065750122
Validation loss: 2.0376347188026673

Epoch: 5| Step: 2
Training loss: 2.316890001296997
Validation loss: 2.053959120986282

Epoch: 5| Step: 3
Training loss: 1.1658822298049927
Validation loss: 2.057076979708928

Epoch: 5| Step: 4
Training loss: 1.8547776937484741
Validation loss: 2.040744848148797

Epoch: 5| Step: 5
Training loss: 2.1753878593444824
Validation loss: 2.0036300895034627

Epoch: 5| Step: 6
Training loss: 2.1242294311523438
Validation loss: 1.9827544791724092

Epoch: 5| Step: 7
Training loss: 2.1022934913635254
Validation loss: 1.969674451376802

Epoch: 5| Step: 8
Training loss: 1.7813928127288818
Validation loss: 1.9548171797106344

Epoch: 5| Step: 9
Training loss: 1.536582112312317
Validation loss: 1.959466854731242

Epoch: 5| Step: 10
Training loss: 2.1110057830810547
Validation loss: 1.9577801394206222

Epoch: 146| Step: 0
Training loss: 1.7400833368301392
Validation loss: 1.9530024925867717

Epoch: 5| Step: 1
Training loss: 2.1608872413635254
Validation loss: 1.965064646095358

Epoch: 5| Step: 2
Training loss: 2.5835213661193848
Validation loss: 1.9914395962992022

Epoch: 5| Step: 3
Training loss: 1.981616735458374
Validation loss: 2.0152725917036816

Epoch: 5| Step: 4
Training loss: 1.9886157512664795
Validation loss: 2.031896188694944

Epoch: 5| Step: 5
Training loss: 1.8509366512298584
Validation loss: 2.021473103953946

Epoch: 5| Step: 6
Training loss: 1.8036279678344727
Validation loss: 2.048838997399935

Epoch: 5| Step: 7
Training loss: 1.8238195180892944
Validation loss: 2.038576387589978

Epoch: 5| Step: 8
Training loss: 1.786489725112915
Validation loss: 2.027853560704057

Epoch: 5| Step: 9
Training loss: 1.616878867149353
Validation loss: 1.9996045276682863

Epoch: 5| Step: 10
Training loss: 1.8808317184448242
Validation loss: 1.9571232000986736

Epoch: 147| Step: 0
Training loss: 1.9681116342544556
Validation loss: 1.955236804100775

Epoch: 5| Step: 1
Training loss: 2.296018123626709
Validation loss: 1.9296413595958422

Epoch: 5| Step: 2
Training loss: 2.2884135246276855
Validation loss: 1.9257996595034035

Epoch: 5| Step: 3
Training loss: 2.1262266635894775
Validation loss: 1.9080707385975828

Epoch: 5| Step: 4
Training loss: 1.7794891595840454
Validation loss: 1.9000525141275058

Epoch: 5| Step: 5
Training loss: 1.338059663772583
Validation loss: 1.9075167499562746

Epoch: 5| Step: 6
Training loss: 2.4392573833465576
Validation loss: 1.9350512079013291

Epoch: 5| Step: 7
Training loss: 2.503915309906006
Validation loss: 1.9490482409795125

Epoch: 5| Step: 8
Training loss: 1.434169054031372
Validation loss: 1.9881496134624685

Epoch: 5| Step: 9
Training loss: 1.767037034034729
Validation loss: 2.0075678069104432

Epoch: 5| Step: 10
Training loss: 1.686996340751648
Validation loss: 2.0297774332825855

Epoch: 148| Step: 0
Training loss: 1.3531155586242676
Validation loss: 2.0331875867741083

Epoch: 5| Step: 1
Training loss: 2.4053945541381836
Validation loss: 2.049755791182159

Epoch: 5| Step: 2
Training loss: 1.995063066482544
Validation loss: 2.050670821179626

Epoch: 5| Step: 3
Training loss: 2.062351703643799
Validation loss: 2.0294026738853863

Epoch: 5| Step: 4
Training loss: 2.031679153442383
Validation loss: 2.023639340554514

Epoch: 5| Step: 5
Training loss: 1.6234385967254639
Validation loss: 2.0409086122307727

Epoch: 5| Step: 6
Training loss: 2.3433117866516113
Validation loss: 2.0342494005798013

Epoch: 5| Step: 7
Training loss: 1.85761296749115
Validation loss: 2.034278413300873

Epoch: 5| Step: 8
Training loss: 1.382466435432434
Validation loss: 2.0101585413820002

Epoch: 5| Step: 9
Training loss: 1.7683677673339844
Validation loss: 1.9837520840347453

Epoch: 5| Step: 10
Training loss: 2.774451732635498
Validation loss: 1.9828544842299594

Epoch: 149| Step: 0
Training loss: 2.6871485710144043
Validation loss: 1.9977931989136564

Epoch: 5| Step: 1
Training loss: 1.7722063064575195
Validation loss: 2.012051118317471

Epoch: 5| Step: 2
Training loss: 1.8399308919906616
Validation loss: 2.0444427331288657

Epoch: 5| Step: 3
Training loss: 1.8774564266204834
Validation loss: 2.056838083010848

Epoch: 5| Step: 4
Training loss: 2.0257694721221924
Validation loss: 2.0665232878859325

Epoch: 5| Step: 5
Training loss: 1.988448143005371
Validation loss: 2.0677135375238236

Epoch: 5| Step: 6
Training loss: 1.885040521621704
Validation loss: 2.01328787496013

Epoch: 5| Step: 7
Training loss: 1.7996574640274048
Validation loss: 1.9802690218853694

Epoch: 5| Step: 8
Training loss: 1.6681209802627563
Validation loss: 1.949036728951239

Epoch: 5| Step: 9
Training loss: 2.0581727027893066
Validation loss: 1.9291458706701956

Epoch: 5| Step: 10
Training loss: 1.487586498260498
Validation loss: 1.9147335778000534

Epoch: 150| Step: 0
Training loss: 2.1544883251190186
Validation loss: 1.9183167462707849

Epoch: 5| Step: 1
Training loss: 2.085758924484253
Validation loss: 1.936666548893016

Epoch: 5| Step: 2
Training loss: 1.8811010122299194
Validation loss: 1.9677013735617361

Epoch: 5| Step: 3
Training loss: 1.3116388320922852
Validation loss: 1.98542038343286

Epoch: 5| Step: 4
Training loss: 1.7236677408218384
Validation loss: 2.0085744447605585

Epoch: 5| Step: 5
Training loss: 2.4950644969940186
Validation loss: 2.042121716724929

Epoch: 5| Step: 6
Training loss: 1.775274634361267
Validation loss: 2.038886244579028

Epoch: 5| Step: 7
Training loss: 2.241457462310791
Validation loss: 2.042732136223906

Epoch: 5| Step: 8
Training loss: 1.53706693649292
Validation loss: 2.026958745013001

Epoch: 5| Step: 9
Training loss: 2.177171468734741
Validation loss: 2.0275181249905656

Epoch: 5| Step: 10
Training loss: 1.8932652473449707
Validation loss: 1.997574415258182

Epoch: 151| Step: 0
Training loss: 1.7615020275115967
Validation loss: 1.9505023635843748

Epoch: 5| Step: 1
Training loss: 1.664031982421875
Validation loss: 1.926628194829469

Epoch: 5| Step: 2
Training loss: 2.179856061935425
Validation loss: 1.9379064780409618

Epoch: 5| Step: 3
Training loss: 1.7973359823226929
Validation loss: 1.9500492054929015

Epoch: 5| Step: 4
Training loss: 2.0821375846862793
Validation loss: 1.9529857225315546

Epoch: 5| Step: 5
Training loss: 1.747452974319458
Validation loss: 1.9639643212800384

Epoch: 5| Step: 6
Training loss: 2.5088963508605957
Validation loss: 1.9537592036749727

Epoch: 5| Step: 7
Training loss: 1.7082487344741821
Validation loss: 1.9417605733358732

Epoch: 5| Step: 8
Training loss: 1.614811658859253
Validation loss: 1.9332243268207838

Epoch: 5| Step: 9
Training loss: 1.8315508365631104
Validation loss: 1.9514550701264413

Epoch: 5| Step: 10
Training loss: 1.8620343208312988
Validation loss: 1.9818660020828247

Epoch: 152| Step: 0
Training loss: 1.71514093875885
Validation loss: 2.0465778291866346

Epoch: 5| Step: 1
Training loss: 2.6999878883361816
Validation loss: 2.0863722831972185

Epoch: 5| Step: 2
Training loss: 1.6964489221572876
Validation loss: 2.0897826763891403

Epoch: 5| Step: 3
Training loss: 1.2938497066497803
Validation loss: 2.0686924355004424

Epoch: 5| Step: 4
Training loss: 2.086738109588623
Validation loss: 2.0444783382518317

Epoch: 5| Step: 5
Training loss: 1.4800223112106323
Validation loss: 1.996589341471272

Epoch: 5| Step: 6
Training loss: 1.6870867013931274
Validation loss: 1.9734772430953158

Epoch: 5| Step: 7
Training loss: 2.3828024864196777
Validation loss: 1.9821176528930664

Epoch: 5| Step: 8
Training loss: 2.203068256378174
Validation loss: 1.9815897326315604

Epoch: 5| Step: 9
Training loss: 1.8062684535980225
Validation loss: 1.9605012170730098

Epoch: 5| Step: 10
Training loss: 1.6601195335388184
Validation loss: 1.9675107899532522

Epoch: 153| Step: 0
Training loss: 2.4597105979919434
Validation loss: 1.9570678651973765

Epoch: 5| Step: 1
Training loss: 1.8774398565292358
Validation loss: 1.9643317653286843

Epoch: 5| Step: 2
Training loss: 2.1717231273651123
Validation loss: 1.95760892539896

Epoch: 5| Step: 3
Training loss: 2.17075777053833
Validation loss: 1.9668677135180401

Epoch: 5| Step: 4
Training loss: 1.7298355102539062
Validation loss: 1.9945625105211813

Epoch: 5| Step: 5
Training loss: 2.060610294342041
Validation loss: 2.0129759670585714

Epoch: 5| Step: 6
Training loss: 2.04742693901062
Validation loss: 2.0385232663923696

Epoch: 5| Step: 7
Training loss: 2.0995166301727295
Validation loss: 2.0524518669292493

Epoch: 5| Step: 8
Training loss: 1.3133646249771118
Validation loss: 2.0440298113771664

Epoch: 5| Step: 9
Training loss: 1.2751268148422241
Validation loss: 2.0273996412113147

Epoch: 5| Step: 10
Training loss: 1.4294114112854004
Validation loss: 2.0062652172580844

Epoch: 154| Step: 0
Training loss: 1.794528603553772
Validation loss: 1.9701579591279388

Epoch: 5| Step: 1
Training loss: 1.1847587823867798
Validation loss: 1.9651204565519929

Epoch: 5| Step: 2
Training loss: 2.30733323097229
Validation loss: 1.998891407443631

Epoch: 5| Step: 3
Training loss: 1.7150018215179443
Validation loss: 2.0004625422980196

Epoch: 5| Step: 4
Training loss: 1.9380289316177368
Validation loss: 1.991639773050944

Epoch: 5| Step: 5
Training loss: 1.3948233127593994
Validation loss: 2.007376483691636

Epoch: 5| Step: 6
Training loss: 2.1895911693573
Validation loss: 2.0230572326208955

Epoch: 5| Step: 7
Training loss: 2.1232895851135254
Validation loss: 2.013983416300948

Epoch: 5| Step: 8
Training loss: 2.096431255340576
Validation loss: 2.033789832104919

Epoch: 5| Step: 9
Training loss: 1.6065315008163452
Validation loss: 2.0606744340671006

Epoch: 5| Step: 10
Training loss: 2.4141056537628174
Validation loss: 2.0777690615705264

Epoch: 155| Step: 0
Training loss: 1.6401684284210205
Validation loss: 2.062388309868433

Epoch: 5| Step: 1
Training loss: 2.256634473800659
Validation loss: 2.0891481445681666

Epoch: 5| Step: 2
Training loss: 1.8756459951400757
Validation loss: 2.0841170562210904

Epoch: 5| Step: 3
Training loss: 1.6458709239959717
Validation loss: 2.064551627764138

Epoch: 5| Step: 4
Training loss: 1.1997801065444946
Validation loss: 2.0390826604699575

Epoch: 5| Step: 5
Training loss: 2.223827600479126
Validation loss: 2.0200538173798592

Epoch: 5| Step: 6
Training loss: 2.0628914833068848
Validation loss: 1.9971536846571072

Epoch: 5| Step: 7
Training loss: 2.2834949493408203
Validation loss: 1.991000222903426

Epoch: 5| Step: 8
Training loss: 1.5257899761199951
Validation loss: 1.989140566959176

Epoch: 5| Step: 9
Training loss: 1.698326826095581
Validation loss: 1.9946251928165395

Epoch: 5| Step: 10
Training loss: 2.34690523147583
Validation loss: 1.9811951088648971

Epoch: 156| Step: 0
Training loss: 1.5734831094741821
Validation loss: 1.969773354068879

Epoch: 5| Step: 1
Training loss: 1.6870015859603882
Validation loss: 1.9653739903562812

Epoch: 5| Step: 2
Training loss: 2.202993392944336
Validation loss: 1.9769361121680147

Epoch: 5| Step: 3
Training loss: 1.8922271728515625
Validation loss: 1.9731919611653974

Epoch: 5| Step: 4
Training loss: 1.2564550638198853
Validation loss: 1.9685133041874054

Epoch: 5| Step: 5
Training loss: 2.0708000659942627
Validation loss: 1.95323186151443

Epoch: 5| Step: 6
Training loss: 2.2696642875671387
Validation loss: 1.9685968211902085

Epoch: 5| Step: 7
Training loss: 1.572981595993042
Validation loss: 1.9611096433413926

Epoch: 5| Step: 8
Training loss: 1.7143628597259521
Validation loss: 1.9584817655624882

Epoch: 5| Step: 9
Training loss: 2.0751397609710693
Validation loss: 1.9490312619875836

Epoch: 5| Step: 10
Training loss: 1.720613718032837
Validation loss: 1.9452275819675897

Epoch: 157| Step: 0
Training loss: 2.1514334678649902
Validation loss: 1.944797118504842

Epoch: 5| Step: 1
Training loss: 1.5023729801177979
Validation loss: 1.951004707685081

Epoch: 5| Step: 2
Training loss: 2.3089747428894043
Validation loss: 1.9293256036696895

Epoch: 5| Step: 3
Training loss: 1.6549068689346313
Validation loss: 1.9283621080460087

Epoch: 5| Step: 4
Training loss: 1.2844408750534058
Validation loss: 1.922648053015432

Epoch: 5| Step: 5
Training loss: 1.7481998205184937
Validation loss: 1.9169115661292948

Epoch: 5| Step: 6
Training loss: 1.4137964248657227
Validation loss: 1.9212857561726724

Epoch: 5| Step: 7
Training loss: 1.6861436367034912
Validation loss: 1.945669408767454

Epoch: 5| Step: 8
Training loss: 1.8209476470947266
Validation loss: 1.9639580634332472

Epoch: 5| Step: 9
Training loss: 2.13986873626709
Validation loss: 1.9890176160361177

Epoch: 5| Step: 10
Training loss: 2.2225229740142822
Validation loss: 2.027658126687491

Epoch: 158| Step: 0
Training loss: 1.9491074085235596
Validation loss: 2.020433513067102

Epoch: 5| Step: 1
Training loss: 1.733573317527771
Validation loss: 1.9892788394804923

Epoch: 5| Step: 2
Training loss: 1.938024878501892
Validation loss: 1.9726507253544305

Epoch: 5| Step: 3
Training loss: 1.5904804468154907
Validation loss: 1.9579832643590949

Epoch: 5| Step: 4
Training loss: 2.2960636615753174
Validation loss: 1.956040346494285

Epoch: 5| Step: 5
Training loss: 1.6687732934951782
Validation loss: 1.9482024651701733

Epoch: 5| Step: 6
Training loss: 1.569079041481018
Validation loss: 1.9516501580515215

Epoch: 5| Step: 7
Training loss: 1.6088320016860962
Validation loss: 1.9652006254401257

Epoch: 5| Step: 8
Training loss: 1.686025857925415
Validation loss: 1.9628975160660282

Epoch: 5| Step: 9
Training loss: 1.7044098377227783
Validation loss: 1.9882445694297872

Epoch: 5| Step: 10
Training loss: 1.9583300352096558
Validation loss: 1.98743014694542

Epoch: 159| Step: 0
Training loss: 2.0195837020874023
Validation loss: 2.014152423028023

Epoch: 5| Step: 1
Training loss: 1.9344316720962524
Validation loss: 2.008703920149034

Epoch: 5| Step: 2
Training loss: 1.9101521968841553
Validation loss: 2.0229893397259455

Epoch: 5| Step: 3
Training loss: 1.6014734506607056
Validation loss: 2.0201625042064215

Epoch: 5| Step: 4
Training loss: 1.358982801437378
Validation loss: 2.011643389219879

Epoch: 5| Step: 5
Training loss: 2.185788631439209
Validation loss: 2.023192564646403

Epoch: 5| Step: 6
Training loss: 1.7907034158706665
Validation loss: 2.0176353710953907

Epoch: 5| Step: 7
Training loss: 1.3500959873199463
Validation loss: 1.9934935441581152

Epoch: 5| Step: 8
Training loss: 1.631121039390564
Validation loss: 1.9880674808256087

Epoch: 5| Step: 9
Training loss: 1.4738540649414062
Validation loss: 1.9700200775618195

Epoch: 5| Step: 10
Training loss: 2.3987812995910645
Validation loss: 1.9684884663551085

Epoch: 160| Step: 0
Training loss: 1.9924476146697998
Validation loss: 1.9493652287349905

Epoch: 5| Step: 1
Training loss: 1.6835178136825562
Validation loss: 1.955983390090286

Epoch: 5| Step: 2
Training loss: 1.5285438299179077
Validation loss: 1.9490175990648166

Epoch: 5| Step: 3
Training loss: 1.8596652746200562
Validation loss: 1.9447620453373078

Epoch: 5| Step: 4
Training loss: 2.3052330017089844
Validation loss: 1.9317049134162165

Epoch: 5| Step: 5
Training loss: 2.008513927459717
Validation loss: 1.9772918352516748

Epoch: 5| Step: 6
Training loss: 2.101588487625122
Validation loss: 1.9770844649243098

Epoch: 5| Step: 7
Training loss: 1.4849616289138794
Validation loss: 1.9951136086576728

Epoch: 5| Step: 8
Training loss: 1.2167108058929443
Validation loss: 1.975451031038838

Epoch: 5| Step: 9
Training loss: 1.7706400156021118
Validation loss: 1.9527355663238033

Epoch: 5| Step: 10
Training loss: 1.6743345260620117
Validation loss: 1.9567034423992198

Epoch: 161| Step: 0
Training loss: 1.7212146520614624
Validation loss: 1.940500965682409

Epoch: 5| Step: 1
Training loss: 2.0135574340820312
Validation loss: 1.9509969757449241

Epoch: 5| Step: 2
Training loss: 2.002816677093506
Validation loss: 1.9574419195934007

Epoch: 5| Step: 3
Training loss: 1.1083238124847412
Validation loss: 2.0041296969177904

Epoch: 5| Step: 4
Training loss: 2.118997573852539
Validation loss: 2.041628101820587

Epoch: 5| Step: 5
Training loss: 1.6258682012557983
Validation loss: 2.044716276148314

Epoch: 5| Step: 6
Training loss: 1.6097484827041626
Validation loss: 2.078998137545842

Epoch: 5| Step: 7
Training loss: 1.9436790943145752
Validation loss: 2.0852713354172243

Epoch: 5| Step: 8
Training loss: 1.952556848526001
Validation loss: 2.067180661744969

Epoch: 5| Step: 9
Training loss: 1.6999785900115967
Validation loss: 2.0333096775957333

Epoch: 5| Step: 10
Training loss: 1.7019673585891724
Validation loss: 2.0056098481660247

Epoch: 162| Step: 0
Training loss: 1.777870774269104
Validation loss: 1.9812127595306726

Epoch: 5| Step: 1
Training loss: 1.3711354732513428
Validation loss: 1.9473878260581725

Epoch: 5| Step: 2
Training loss: 1.7762882709503174
Validation loss: 1.9258900637267737

Epoch: 5| Step: 3
Training loss: 1.472534418106079
Validation loss: 1.9267717356322913

Epoch: 5| Step: 4
Training loss: 2.082960605621338
Validation loss: 1.930873578594577

Epoch: 5| Step: 5
Training loss: 2.395995616912842
Validation loss: 1.9421566763231832

Epoch: 5| Step: 6
Training loss: 1.8071048259735107
Validation loss: 1.9757885266375799

Epoch: 5| Step: 7
Training loss: 1.5828907489776611
Validation loss: 2.0028446964038316

Epoch: 5| Step: 8
Training loss: 1.4270074367523193
Validation loss: 2.002237417364633

Epoch: 5| Step: 9
Training loss: 2.0302891731262207
Validation loss: 1.9901914314557148

Epoch: 5| Step: 10
Training loss: 1.5306435823440552
Validation loss: 1.9953653838044854

Epoch: 163| Step: 0
Training loss: 1.821417212486267
Validation loss: 1.9811192904749224

Epoch: 5| Step: 1
Training loss: 2.2114920616149902
Validation loss: 1.9655613706957908

Epoch: 5| Step: 2
Training loss: 1.636111855506897
Validation loss: 1.9525351216716151

Epoch: 5| Step: 3
Training loss: 2.1331334114074707
Validation loss: 1.946033299610179

Epoch: 5| Step: 4
Training loss: 2.2105259895324707
Validation loss: 1.9597957685429563

Epoch: 5| Step: 5
Training loss: 1.8707717657089233
Validation loss: 1.9658351021428262

Epoch: 5| Step: 6
Training loss: 1.221866250038147
Validation loss: 1.9947861292028939

Epoch: 5| Step: 7
Training loss: 1.2569160461425781
Validation loss: 2.018375632583454

Epoch: 5| Step: 8
Training loss: 2.143355369567871
Validation loss: 2.036921730605505

Epoch: 5| Step: 9
Training loss: 1.4377763271331787
Validation loss: 2.0379572017218477

Epoch: 5| Step: 10
Training loss: 1.2494615316390991
Validation loss: 2.0358865363623506

Epoch: 164| Step: 0
Training loss: 1.4198973178863525
Validation loss: 2.0387153087123746

Epoch: 5| Step: 1
Training loss: 1.9375660419464111
Validation loss: 2.0132959555554133

Epoch: 5| Step: 2
Training loss: 2.3489675521850586
Validation loss: 1.9883647964846702

Epoch: 5| Step: 3
Training loss: 1.8734092712402344
Validation loss: 1.972432832564077

Epoch: 5| Step: 4
Training loss: 1.5576015710830688
Validation loss: 1.9680927825230423

Epoch: 5| Step: 5
Training loss: 2.5764782428741455
Validation loss: 1.9350461882929648

Epoch: 5| Step: 6
Training loss: 1.412917971611023
Validation loss: 1.9539076769223778

Epoch: 5| Step: 7
Training loss: 1.780231237411499
Validation loss: 1.962252978355654

Epoch: 5| Step: 8
Training loss: 1.27677321434021
Validation loss: 1.97477158423393

Epoch: 5| Step: 9
Training loss: 1.3149845600128174
Validation loss: 1.976591202520555

Epoch: 5| Step: 10
Training loss: 1.3704627752304077
Validation loss: 1.9823365801124162

Epoch: 165| Step: 0
Training loss: 1.0984468460083008
Validation loss: 1.9777291051803096

Epoch: 5| Step: 1
Training loss: 1.749072790145874
Validation loss: 1.9700640965533514

Epoch: 5| Step: 2
Training loss: 1.743598222732544
Validation loss: 1.939906850937874

Epoch: 5| Step: 3
Training loss: 1.5288580656051636
Validation loss: 1.9459123047449256

Epoch: 5| Step: 4
Training loss: 2.0021865367889404
Validation loss: 1.9454106669272146

Epoch: 5| Step: 5
Training loss: 1.5891281366348267
Validation loss: 1.9263968647167247

Epoch: 5| Step: 6
Training loss: 1.7648487091064453
Validation loss: 1.9426785874110397

Epoch: 5| Step: 7
Training loss: 1.9392099380493164
Validation loss: 1.9527054525190783

Epoch: 5| Step: 8
Training loss: 1.5292961597442627
Validation loss: 1.9771572569365143

Epoch: 5| Step: 9
Training loss: 2.004891872406006
Validation loss: 2.018453449331304

Epoch: 5| Step: 10
Training loss: 1.7792481184005737
Validation loss: 2.042053871257331

Epoch: 166| Step: 0
Training loss: 1.6533927917480469
Validation loss: 2.0735407567793325

Epoch: 5| Step: 1
Training loss: 1.461397647857666
Validation loss: 2.1216842154020905

Epoch: 5| Step: 2
Training loss: 1.6285825967788696
Validation loss: 2.122414022363642

Epoch: 5| Step: 3
Training loss: 0.7950563430786133
Validation loss: 2.0992597815810994

Epoch: 5| Step: 4
Training loss: 1.6834131479263306
Validation loss: 2.095126995476343

Epoch: 5| Step: 5
Training loss: 2.4569320678710938
Validation loss: 2.059935114716971

Epoch: 5| Step: 6
Training loss: 1.5094279050827026
Validation loss: 2.0137714275749783

Epoch: 5| Step: 7
Training loss: 1.9948184490203857
Validation loss: 1.977683062194496

Epoch: 5| Step: 8
Training loss: 1.944262146949768
Validation loss: 1.9340836924891318

Epoch: 5| Step: 9
Training loss: 1.6528873443603516
Validation loss: 1.9261350247167772

Epoch: 5| Step: 10
Training loss: 2.3631749153137207
Validation loss: 1.9144250526223132

Epoch: 167| Step: 0
Training loss: 2.105623722076416
Validation loss: 1.8833396280965498

Epoch: 5| Step: 1
Training loss: 1.4752358198165894
Validation loss: 1.8810540450516569

Epoch: 5| Step: 2
Training loss: 1.9448211193084717
Validation loss: 1.8888512067897345

Epoch: 5| Step: 3
Training loss: 1.7818043231964111
Validation loss: 1.8938967784245808

Epoch: 5| Step: 4
Training loss: 1.7518631219863892
Validation loss: 1.9262967096861972

Epoch: 5| Step: 5
Training loss: 1.5655664205551147
Validation loss: 1.9752345559417561

Epoch: 5| Step: 6
Training loss: 2.0879926681518555
Validation loss: 2.032572671931277

Epoch: 5| Step: 7
Training loss: 1.6022624969482422
Validation loss: 2.026552684845463

Epoch: 5| Step: 8
Training loss: 1.5811723470687866
Validation loss: 2.0193019938725296

Epoch: 5| Step: 9
Training loss: 1.809139609336853
Validation loss: 2.002338506842172

Epoch: 5| Step: 10
Training loss: 1.4354147911071777
Validation loss: 2.0088154961985927

Epoch: 168| Step: 0
Training loss: 1.9265066385269165
Validation loss: 1.9823543217874342

Epoch: 5| Step: 1
Training loss: 1.7161413431167603
Validation loss: 2.0004985704216907

Epoch: 5| Step: 2
Training loss: 1.426987886428833
Validation loss: 1.9912719457380232

Epoch: 5| Step: 3
Training loss: 1.3027359247207642
Validation loss: 1.9794232101850613

Epoch: 5| Step: 4
Training loss: 1.8928868770599365
Validation loss: 1.9634616298060263

Epoch: 5| Step: 5
Training loss: 1.781599760055542
Validation loss: 1.9706388071019163

Epoch: 5| Step: 6
Training loss: 1.6311792135238647
Validation loss: 1.9536965341978176

Epoch: 5| Step: 7
Training loss: 1.5546823740005493
Validation loss: 1.950865763489918

Epoch: 5| Step: 8
Training loss: 1.6946146488189697
Validation loss: 1.940923189604154

Epoch: 5| Step: 9
Training loss: 2.015488624572754
Validation loss: 1.9380825437525266

Epoch: 5| Step: 10
Training loss: 1.5607327222824097
Validation loss: 1.9774387216055265

Epoch: 169| Step: 0
Training loss: 1.5059211254119873
Validation loss: 2.001726440204087

Epoch: 5| Step: 1
Training loss: 1.825990080833435
Validation loss: 2.01320687032515

Epoch: 5| Step: 2
Training loss: 1.4521673917770386
Validation loss: 2.005717892800608

Epoch: 5| Step: 3
Training loss: 1.751227617263794
Validation loss: 2.038038105093023

Epoch: 5| Step: 4
Training loss: 2.1118273735046387
Validation loss: 2.031160790433166

Epoch: 5| Step: 5
Training loss: 1.2008355855941772
Validation loss: 2.0362409058437554

Epoch: 5| Step: 6
Training loss: 1.2596609592437744
Validation loss: 2.0084724503178752

Epoch: 5| Step: 7
Training loss: 1.5002597570419312
Validation loss: 1.9963062322267922

Epoch: 5| Step: 8
Training loss: 1.6401643753051758
Validation loss: 2.0012835315478745

Epoch: 5| Step: 9
Training loss: 1.610891342163086
Validation loss: 1.9987606092165875

Epoch: 5| Step: 10
Training loss: 2.4786593914031982
Validation loss: 1.9808340239268478

Epoch: 170| Step: 0
Training loss: 1.6534923315048218
Validation loss: 1.9621936762204735

Epoch: 5| Step: 1
Training loss: 1.6948044300079346
Validation loss: 1.9241061928451701

Epoch: 5| Step: 2
Training loss: 2.306442975997925
Validation loss: 1.9118109838936919

Epoch: 5| Step: 3
Training loss: 1.6318928003311157
Validation loss: 1.914923209016041

Epoch: 5| Step: 4
Training loss: 1.9679569005966187
Validation loss: 1.9032284636651315

Epoch: 5| Step: 5
Training loss: 1.4355435371398926
Validation loss: 1.9518250611520582

Epoch: 5| Step: 6
Training loss: 1.5915502309799194
Validation loss: 1.9491855764901767

Epoch: 5| Step: 7
Training loss: 1.283372402191162
Validation loss: 1.9537431040117819

Epoch: 5| Step: 8
Training loss: 0.9036634564399719
Validation loss: 1.9957307833497242

Epoch: 5| Step: 9
Training loss: 1.884590744972229
Validation loss: 2.0361507656753703

Epoch: 5| Step: 10
Training loss: 2.0519237518310547
Validation loss: 2.0434682907596713

Epoch: 171| Step: 0
Training loss: 1.253836989402771
Validation loss: 2.0223930138413624

Epoch: 5| Step: 1
Training loss: 1.7176506519317627
Validation loss: 2.0035272234229633

Epoch: 5| Step: 2
Training loss: 1.9644511938095093
Validation loss: 1.954735073992001

Epoch: 5| Step: 3
Training loss: 1.638650894165039
Validation loss: 1.9380629139561807

Epoch: 5| Step: 4
Training loss: 1.3233680725097656
Validation loss: 1.907010752667663

Epoch: 5| Step: 5
Training loss: 2.445084810256958
Validation loss: 1.9099966864432059

Epoch: 5| Step: 6
Training loss: 1.6413730382919312
Validation loss: 1.9326222429993332

Epoch: 5| Step: 7
Training loss: 1.6170717477798462
Validation loss: 1.9494177141497213

Epoch: 5| Step: 8
Training loss: 1.7552992105484009
Validation loss: 1.9509513442234327

Epoch: 5| Step: 9
Training loss: 1.1876657009124756
Validation loss: 1.9911546245698006

Epoch: 5| Step: 10
Training loss: 1.6794546842575073
Validation loss: 1.9838428881860548

Epoch: 172| Step: 0
Training loss: 1.344374418258667
Validation loss: 2.0075877892073763

Epoch: 5| Step: 1
Training loss: 1.8314058780670166
Validation loss: 2.0369322017956804

Epoch: 5| Step: 2
Training loss: 1.704453706741333
Validation loss: 2.0471956563252274

Epoch: 5| Step: 3
Training loss: 1.2516430616378784
Validation loss: 2.0152079251504715

Epoch: 5| Step: 4
Training loss: 1.8771734237670898
Validation loss: 1.9970029707877868

Epoch: 5| Step: 5
Training loss: 1.53476083278656
Validation loss: 1.9717676960011965

Epoch: 5| Step: 6
Training loss: 1.3176339864730835
Validation loss: 1.9725162906031455

Epoch: 5| Step: 7
Training loss: 1.792759656906128
Validation loss: 1.9907707565574235

Epoch: 5| Step: 8
Training loss: 1.9682848453521729
Validation loss: 1.9780774988153929

Epoch: 5| Step: 9
Training loss: 2.004579544067383
Validation loss: 1.9784639599502727

Epoch: 5| Step: 10
Training loss: 1.432671070098877
Validation loss: 1.9611319880331717

Epoch: 173| Step: 0
Training loss: 1.7290738821029663
Validation loss: 1.9572873782086115

Epoch: 5| Step: 1
Training loss: 1.8509266376495361
Validation loss: 1.9359504958634735

Epoch: 5| Step: 2
Training loss: 1.2273844480514526
Validation loss: 1.9598030864551503

Epoch: 5| Step: 3
Training loss: 2.013364315032959
Validation loss: 1.9664636606811194

Epoch: 5| Step: 4
Training loss: 1.6550261974334717
Validation loss: 1.9897336395837928

Epoch: 5| Step: 5
Training loss: 0.9382263422012329
Validation loss: 1.965358834112844

Epoch: 5| Step: 6
Training loss: 1.309187650680542
Validation loss: 1.9827252382873206

Epoch: 5| Step: 7
Training loss: 2.1773219108581543
Validation loss: 1.997614606734245

Epoch: 5| Step: 8
Training loss: 1.6443490982055664
Validation loss: 1.991953008918352

Epoch: 5| Step: 9
Training loss: 1.4947279691696167
Validation loss: 1.9798870599398048

Epoch: 5| Step: 10
Training loss: 1.814223289489746
Validation loss: 1.9720532842861709

Epoch: 174| Step: 0
Training loss: 1.1333647966384888
Validation loss: 1.9681484673612861

Epoch: 5| Step: 1
Training loss: 1.6665258407592773
Validation loss: 1.9633687439785208

Epoch: 5| Step: 2
Training loss: 1.5631823539733887
Validation loss: 1.976051402348344

Epoch: 5| Step: 3
Training loss: 1.7371448278427124
Validation loss: 1.999135942869289

Epoch: 5| Step: 4
Training loss: 1.7662594318389893
Validation loss: 2.006698598143875

Epoch: 5| Step: 5
Training loss: 1.2751338481903076
Validation loss: 1.9962359756551764

Epoch: 5| Step: 6
Training loss: 1.586382508277893
Validation loss: 2.0174018118971135

Epoch: 5| Step: 7
Training loss: 1.5678691864013672
Validation loss: 1.9923708977237824

Epoch: 5| Step: 8
Training loss: 1.9387531280517578
Validation loss: 1.9857063806185158

Epoch: 5| Step: 9
Training loss: 1.5721216201782227
Validation loss: 1.9780168200051913

Epoch: 5| Step: 10
Training loss: 1.6061660051345825
Validation loss: 1.9840129549785326

Epoch: 175| Step: 0
Training loss: 1.8186118602752686
Validation loss: 1.9626474841948478

Epoch: 5| Step: 1
Training loss: 1.5716307163238525
Validation loss: 1.9632634373121365

Epoch: 5| Step: 2
Training loss: 1.186012864112854
Validation loss: 1.9835955865921513

Epoch: 5| Step: 3
Training loss: 1.402463674545288
Validation loss: 2.0254377895785916

Epoch: 5| Step: 4
Training loss: 1.1159288883209229
Validation loss: 2.026652846285092

Epoch: 5| Step: 5
Training loss: 1.4918243885040283
Validation loss: 2.0685302801029657

Epoch: 5| Step: 6
Training loss: 1.3681659698486328
Validation loss: 2.0791471799214682

Epoch: 5| Step: 7
Training loss: 2.1610896587371826
Validation loss: 2.088999919993903

Epoch: 5| Step: 8
Training loss: 1.675548791885376
Validation loss: 2.0427855753129527

Epoch: 5| Step: 9
Training loss: 2.1909029483795166
Validation loss: 2.0054273477164646

Epoch: 5| Step: 10
Training loss: 1.37196683883667
Validation loss: 2.0064544652097966

Testing loss: 2.1645616955227323
