Epoch: 1| Step: 0
Training loss: 4.587507247924805
Validation loss: 5.1869415724149315

Epoch: 6| Step: 1
Training loss: 5.174737930297852
Validation loss: 5.15709319678686

Epoch: 6| Step: 2
Training loss: 5.411270618438721
Validation loss: 5.12968651453654

Epoch: 6| Step: 3
Training loss: 3.629394054412842
Validation loss: 5.100758024441299

Epoch: 6| Step: 4
Training loss: 5.430472373962402
Validation loss: 5.069169823841382

Epoch: 6| Step: 5
Training loss: 4.641346454620361
Validation loss: 5.034758301191433

Epoch: 6| Step: 6
Training loss: 4.662701606750488
Validation loss: 4.996544381623627

Epoch: 6| Step: 7
Training loss: 3.8714351654052734
Validation loss: 4.955777127255676

Epoch: 6| Step: 8
Training loss: 5.0479912757873535
Validation loss: 4.910149492243285

Epoch: 6| Step: 9
Training loss: 5.0865936279296875
Validation loss: 4.860056964300012

Epoch: 6| Step: 10
Training loss: 4.662293910980225
Validation loss: 4.804526887914186

Epoch: 6| Step: 11
Training loss: 4.350901126861572
Validation loss: 4.744352930335588

Epoch: 6| Step: 12
Training loss: 4.685550689697266
Validation loss: 4.6797929989394325

Epoch: 6| Step: 13
Training loss: 5.442150115966797
Validation loss: 4.61053341691212

Epoch: 2| Step: 0
Training loss: 5.907567024230957
Validation loss: 4.5372135613554265

Epoch: 6| Step: 1
Training loss: 4.004483222961426
Validation loss: 4.459451516469319

Epoch: 6| Step: 2
Training loss: 3.9958276748657227
Validation loss: 4.380774651804278

Epoch: 6| Step: 3
Training loss: 4.428587913513184
Validation loss: 4.3039185565005065

Epoch: 6| Step: 4
Training loss: 3.7048685550689697
Validation loss: 4.226654142461797

Epoch: 6| Step: 5
Training loss: 4.407976150512695
Validation loss: 4.150994018841815

Epoch: 6| Step: 6
Training loss: 2.7704830169677734
Validation loss: 4.07824908533404

Epoch: 6| Step: 7
Training loss: 3.240011692047119
Validation loss: 4.010841702902189

Epoch: 6| Step: 8
Training loss: 4.193111419677734
Validation loss: 3.943451020025438

Epoch: 6| Step: 9
Training loss: 3.4656412601470947
Validation loss: 3.879718113971013

Epoch: 6| Step: 10
Training loss: 3.792668342590332
Validation loss: 3.8174989018388974

Epoch: 6| Step: 11
Training loss: 3.3572146892547607
Validation loss: 3.762439097127607

Epoch: 6| Step: 12
Training loss: 3.1286444664001465
Validation loss: 3.7141911650216706

Epoch: 6| Step: 13
Training loss: 5.000171661376953
Validation loss: 3.666164982703424

Epoch: 3| Step: 0
Training loss: 3.3065619468688965
Validation loss: 3.6222388616172214

Epoch: 6| Step: 1
Training loss: 4.058755874633789
Validation loss: 3.5808367934278262

Epoch: 6| Step: 2
Training loss: 3.813426971435547
Validation loss: 3.5371109260025846

Epoch: 6| Step: 3
Training loss: 3.138608932495117
Validation loss: 3.504502506666286

Epoch: 6| Step: 4
Training loss: 3.486072063446045
Validation loss: 3.4730310465699885

Epoch: 6| Step: 5
Training loss: 3.6762404441833496
Validation loss: 3.4503208821819675

Epoch: 6| Step: 6
Training loss: 3.0164971351623535
Validation loss: 3.412236531575521

Epoch: 6| Step: 7
Training loss: 3.5392234325408936
Validation loss: 3.3986747162316435

Epoch: 6| Step: 8
Training loss: 3.600658655166626
Validation loss: 3.3815659041045816

Epoch: 6| Step: 9
Training loss: 2.6362712383270264
Validation loss: 3.3622483950789257

Epoch: 6| Step: 10
Training loss: 3.3454651832580566
Validation loss: 3.3472961046362437

Epoch: 6| Step: 11
Training loss: 2.715550184249878
Validation loss: 3.3212982941699285

Epoch: 6| Step: 12
Training loss: 3.85707950592041
Validation loss: 3.2951381385967298

Epoch: 6| Step: 13
Training loss: 2.9779279232025146
Validation loss: 3.2776255658877793

Epoch: 4| Step: 0
Training loss: 3.0727434158325195
Validation loss: 3.266240022515738

Epoch: 6| Step: 1
Training loss: 3.4280290603637695
Validation loss: 3.2430863764978226

Epoch: 6| Step: 2
Training loss: 3.188251495361328
Validation loss: 3.2263199847231627

Epoch: 6| Step: 3
Training loss: 3.9250643253326416
Validation loss: 3.204582886029315

Epoch: 6| Step: 4
Training loss: 2.3702495098114014
Validation loss: 3.195807582588606

Epoch: 6| Step: 5
Training loss: 3.4802188873291016
Validation loss: 3.174865461164905

Epoch: 6| Step: 6
Training loss: 2.6111340522766113
Validation loss: 3.167983139714887

Epoch: 6| Step: 7
Training loss: 2.966754674911499
Validation loss: 3.1432613736839703

Epoch: 6| Step: 8
Training loss: 3.538935661315918
Validation loss: 3.1297435273406324

Epoch: 6| Step: 9
Training loss: 3.3061137199401855
Validation loss: 3.1107907474681897

Epoch: 6| Step: 10
Training loss: 3.186316967010498
Validation loss: 3.1072082852804535

Epoch: 6| Step: 11
Training loss: 3.483567237854004
Validation loss: 3.1027723461069088

Epoch: 6| Step: 12
Training loss: 2.6760380268096924
Validation loss: 3.100658206529515

Epoch: 6| Step: 13
Training loss: 3.1896824836730957
Validation loss: 3.096434518855105

Epoch: 5| Step: 0
Training loss: 3.1998491287231445
Validation loss: 3.0785537124961935

Epoch: 6| Step: 1
Training loss: 3.231050491333008
Validation loss: 3.066989529517389

Epoch: 6| Step: 2
Training loss: 3.4843342304229736
Validation loss: 3.0565643797638598

Epoch: 6| Step: 3
Training loss: 1.180765151977539
Validation loss: 3.0374619294238347

Epoch: 6| Step: 4
Training loss: 3.222744941711426
Validation loss: 3.026904982905234

Epoch: 6| Step: 5
Training loss: 2.71169114112854
Validation loss: 3.0135558856430875

Epoch: 6| Step: 6
Training loss: 3.387868642807007
Validation loss: 2.998278981895857

Epoch: 6| Step: 7
Training loss: 2.6758575439453125
Validation loss: 2.99255540550396

Epoch: 6| Step: 8
Training loss: 3.5018794536590576
Validation loss: 2.987377192384453

Epoch: 6| Step: 9
Training loss: 2.8658533096313477
Validation loss: 2.9802040053952124

Epoch: 6| Step: 10
Training loss: 3.727138042449951
Validation loss: 2.968733333772229

Epoch: 6| Step: 11
Training loss: 3.302982807159424
Validation loss: 2.959435296315019

Epoch: 6| Step: 12
Training loss: 3.2278199195861816
Validation loss: 2.952831919475268

Epoch: 6| Step: 13
Training loss: 3.3018062114715576
Validation loss: 2.948951267427014

Epoch: 6| Step: 0
Training loss: 3.117978811264038
Validation loss: 2.928103185469104

Epoch: 6| Step: 1
Training loss: 2.9094200134277344
Validation loss: 2.923728827507265

Epoch: 6| Step: 2
Training loss: 2.671926498413086
Validation loss: 2.92432568406546

Epoch: 6| Step: 3
Training loss: 2.819235324859619
Validation loss: 2.924831046853014

Epoch: 6| Step: 4
Training loss: 1.9728015661239624
Validation loss: 2.9240853504468034

Epoch: 6| Step: 5
Training loss: 4.053208351135254
Validation loss: 2.9129813076347433

Epoch: 6| Step: 6
Training loss: 2.482755661010742
Validation loss: 2.8903501700329524

Epoch: 6| Step: 7
Training loss: 2.9834301471710205
Validation loss: 2.8781305538710726

Epoch: 6| Step: 8
Training loss: 3.9270031452178955
Validation loss: 2.8708129698230374

Epoch: 6| Step: 9
Training loss: 3.4657979011535645
Validation loss: 2.8681628473343386

Epoch: 6| Step: 10
Training loss: 2.9113969802856445
Validation loss: 2.8667897178280737

Epoch: 6| Step: 11
Training loss: 2.753056049346924
Validation loss: 2.8563073937610914

Epoch: 6| Step: 12
Training loss: 3.1895158290863037
Validation loss: 2.846702975611533

Epoch: 6| Step: 13
Training loss: 2.3425183296203613
Validation loss: 2.838205901525354

Epoch: 7| Step: 0
Training loss: 2.812382221221924
Validation loss: 2.8307668162930395

Epoch: 6| Step: 1
Training loss: 2.7079930305480957
Validation loss: 2.827392008996779

Epoch: 6| Step: 2
Training loss: 4.159944534301758
Validation loss: 2.829425060620872

Epoch: 6| Step: 3
Training loss: 3.0697007179260254
Validation loss: 2.82134993614689

Epoch: 6| Step: 4
Training loss: 2.8855271339416504
Validation loss: 2.813558469536484

Epoch: 6| Step: 5
Training loss: 2.8446874618530273
Validation loss: 2.8089417847253944

Epoch: 6| Step: 6
Training loss: 3.0824694633483887
Validation loss: 2.807627695862965

Epoch: 6| Step: 7
Training loss: 2.5080771446228027
Validation loss: 2.8063407354457404

Epoch: 6| Step: 8
Training loss: 3.2727770805358887
Validation loss: 2.8079426288604736

Epoch: 6| Step: 9
Training loss: 3.7000856399536133
Validation loss: 2.800623245136712

Epoch: 6| Step: 10
Training loss: 2.093404769897461
Validation loss: 2.794797205155896

Epoch: 6| Step: 11
Training loss: 2.275130271911621
Validation loss: 2.794993426210137

Epoch: 6| Step: 12
Training loss: 2.6391634941101074
Validation loss: 2.7996182877530336

Epoch: 6| Step: 13
Training loss: 3.098738670349121
Validation loss: 2.7820187999356176

Epoch: 8| Step: 0
Training loss: 2.5528030395507812
Validation loss: 2.772433529617966

Epoch: 6| Step: 1
Training loss: 3.639209270477295
Validation loss: 2.769291382963939

Epoch: 6| Step: 2
Training loss: 2.341136932373047
Validation loss: 2.7641764712590042

Epoch: 6| Step: 3
Training loss: 3.038832664489746
Validation loss: 2.7570117853021108

Epoch: 6| Step: 4
Training loss: 2.8271093368530273
Validation loss: 2.751170204531762

Epoch: 6| Step: 5
Training loss: 2.9431252479553223
Validation loss: 2.751876538799655

Epoch: 6| Step: 6
Training loss: 3.128092050552368
Validation loss: 2.7436638416782504

Epoch: 6| Step: 7
Training loss: 3.0331923961639404
Validation loss: 2.745474359040619

Epoch: 6| Step: 8
Training loss: 2.356865406036377
Validation loss: 2.7439056750266784

Epoch: 6| Step: 9
Training loss: 3.4381003379821777
Validation loss: 2.738328533787881

Epoch: 6| Step: 10
Training loss: 2.9695582389831543
Validation loss: 2.7282462581511466

Epoch: 6| Step: 11
Training loss: 2.951446056365967
Validation loss: 2.723865642342516

Epoch: 6| Step: 12
Training loss: 2.902890682220459
Validation loss: 2.71672317289537

Epoch: 6| Step: 13
Training loss: 2.11551570892334
Validation loss: 2.7203118852389756

Epoch: 9| Step: 0
Training loss: 3.8627119064331055
Validation loss: 2.731191683841008

Epoch: 6| Step: 1
Training loss: 1.849160075187683
Validation loss: 2.7332012909714893

Epoch: 6| Step: 2
Training loss: 2.362433433532715
Validation loss: 2.730500977526429

Epoch: 6| Step: 3
Training loss: 2.475119113922119
Validation loss: 2.7041310238581833

Epoch: 6| Step: 4
Training loss: 2.7581448554992676
Validation loss: 2.713172217851044

Epoch: 6| Step: 5
Training loss: 2.955235719680786
Validation loss: 2.7491600128912155

Epoch: 6| Step: 6
Training loss: 2.5619969367980957
Validation loss: 2.7134345346881497

Epoch: 6| Step: 7
Training loss: 2.8514132499694824
Validation loss: 2.7244744223933064

Epoch: 6| Step: 8
Training loss: 3.5385031700134277
Validation loss: 2.732324900165681

Epoch: 6| Step: 9
Training loss: 2.6204724311828613
Validation loss: 2.720739908115838

Epoch: 6| Step: 10
Training loss: 3.366746664047241
Validation loss: 2.7223007114984656

Epoch: 6| Step: 11
Training loss: 3.628258466720581
Validation loss: 2.715293038275934

Epoch: 6| Step: 12
Training loss: 3.0939934253692627
Validation loss: 2.707629519124185

Epoch: 6| Step: 13
Training loss: 2.0759458541870117
Validation loss: 2.700293443536246

Epoch: 10| Step: 0
Training loss: 2.9230284690856934
Validation loss: 2.696125756027878

Epoch: 6| Step: 1
Training loss: 3.64328932762146
Validation loss: 2.693884039437899

Epoch: 6| Step: 2
Training loss: 1.5799081325531006
Validation loss: 2.6918828820669525

Epoch: 6| Step: 3
Training loss: 2.7600326538085938
Validation loss: 2.6889192212012505

Epoch: 6| Step: 4
Training loss: 2.8712003231048584
Validation loss: 2.6880980947966218

Epoch: 6| Step: 5
Training loss: 3.0525877475738525
Validation loss: 2.6810468755742556

Epoch: 6| Step: 6
Training loss: 2.3808677196502686
Validation loss: 2.6802794189863306

Epoch: 6| Step: 7
Training loss: 3.418423891067505
Validation loss: 2.6735265613884054

Epoch: 6| Step: 8
Training loss: 2.2174572944641113
Validation loss: 2.671671580242854

Epoch: 6| Step: 9
Training loss: 3.320791721343994
Validation loss: 2.67003712859205

Epoch: 6| Step: 10
Training loss: 3.226423501968384
Validation loss: 2.671877517495104

Epoch: 6| Step: 11
Training loss: 2.617887496948242
Validation loss: 2.6700733682160736

Epoch: 6| Step: 12
Training loss: 3.120678424835205
Validation loss: 2.6665815794339744

Epoch: 6| Step: 13
Training loss: 2.9062716960906982
Validation loss: 2.662942050605692

Epoch: 11| Step: 0
Training loss: 2.516787528991699
Validation loss: 2.6623013532289894

Epoch: 6| Step: 1
Training loss: 2.889619827270508
Validation loss: 2.6599963429153606

Epoch: 6| Step: 2
Training loss: 3.3539929389953613
Validation loss: 2.656797332148398

Epoch: 6| Step: 3
Training loss: 2.722668170928955
Validation loss: 2.654493006326819

Epoch: 6| Step: 4
Training loss: 2.4833130836486816
Validation loss: 2.651996240820936

Epoch: 6| Step: 5
Training loss: 2.4574975967407227
Validation loss: 2.6509168455677647

Epoch: 6| Step: 6
Training loss: 3.2311439514160156
Validation loss: 2.6503028792719685

Epoch: 6| Step: 7
Training loss: 3.213845729827881
Validation loss: 2.6472537825184483

Epoch: 6| Step: 8
Training loss: 2.2865114212036133
Validation loss: 2.65341232925333

Epoch: 6| Step: 9
Training loss: 3.0985841751098633
Validation loss: 2.657108373539422

Epoch: 6| Step: 10
Training loss: 2.9339213371276855
Validation loss: 2.6568759128611577

Epoch: 6| Step: 11
Training loss: 3.46474552154541
Validation loss: 2.6553065315369637

Epoch: 6| Step: 12
Training loss: 2.734666585922241
Validation loss: 2.653572049192203

Epoch: 6| Step: 13
Training loss: 2.020655632019043
Validation loss: 2.649876909871255

Epoch: 12| Step: 0
Training loss: 2.9988534450531006
Validation loss: 2.6402401975406113

Epoch: 6| Step: 1
Training loss: 3.3886773586273193
Validation loss: 2.6376859449571177

Epoch: 6| Step: 2
Training loss: 2.9364492893218994
Validation loss: 2.6345028210711736

Epoch: 6| Step: 3
Training loss: 2.66085147857666
Validation loss: 2.634687856961322

Epoch: 6| Step: 4
Training loss: 2.7733824253082275
Validation loss: 2.6349087838203675

Epoch: 6| Step: 5
Training loss: 2.0985074043273926
Validation loss: 2.6311368198804956

Epoch: 6| Step: 6
Training loss: 2.3488759994506836
Validation loss: 2.6288631039281047

Epoch: 6| Step: 7
Training loss: 2.515040636062622
Validation loss: 2.6253364214333157

Epoch: 6| Step: 8
Training loss: 2.7641940116882324
Validation loss: 2.622435862018216

Epoch: 6| Step: 9
Training loss: 2.985288143157959
Validation loss: 2.620420612314696

Epoch: 6| Step: 10
Training loss: 2.4853696823120117
Validation loss: 2.6188789413821314

Epoch: 6| Step: 11
Training loss: 3.8775246143341064
Validation loss: 2.613361035623858

Epoch: 6| Step: 12
Training loss: 2.606867551803589
Validation loss: 2.6140584150950112

Epoch: 6| Step: 13
Training loss: 3.304807662963867
Validation loss: 2.6068971157073975

Epoch: 13| Step: 0
Training loss: 2.571528911590576
Validation loss: 2.6799254545601467

Epoch: 6| Step: 1
Training loss: 2.8509738445281982
Validation loss: 2.7004638974384596

Epoch: 6| Step: 2
Training loss: 2.642979145050049
Validation loss: 2.700088131812311

Epoch: 6| Step: 3
Training loss: 3.2050061225891113
Validation loss: 2.704351296988867

Epoch: 6| Step: 4
Training loss: 2.5471835136413574
Validation loss: 2.685670942388555

Epoch: 6| Step: 5
Training loss: 3.068552255630493
Validation loss: 2.6702339367199968

Epoch: 6| Step: 6
Training loss: 3.500929117202759
Validation loss: 2.6594478981469267

Epoch: 6| Step: 7
Training loss: 2.8671438694000244
Validation loss: 2.6568241324476016

Epoch: 6| Step: 8
Training loss: 2.5065393447875977
Validation loss: 2.647441920413766

Epoch: 6| Step: 9
Training loss: 3.3094775676727295
Validation loss: 2.6519580605209514

Epoch: 6| Step: 10
Training loss: 2.4014225006103516
Validation loss: 2.625693908301733

Epoch: 6| Step: 11
Training loss: 2.353869915008545
Validation loss: 2.6143393516540527

Epoch: 6| Step: 12
Training loss: 2.729154586791992
Validation loss: 2.6131485636516283

Epoch: 6| Step: 13
Training loss: 3.441687822341919
Validation loss: 2.6049918820781093

Epoch: 14| Step: 0
Training loss: 2.537459373474121
Validation loss: 2.6767022173891784

Epoch: 6| Step: 1
Training loss: 3.1224215030670166
Validation loss: 2.6447473392691663

Epoch: 6| Step: 2
Training loss: 2.28548002243042
Validation loss: 2.6453290549657678

Epoch: 6| Step: 3
Training loss: 2.957777261734009
Validation loss: 2.642754962367396

Epoch: 6| Step: 4
Training loss: 3.03206205368042
Validation loss: 2.647857509633546

Epoch: 6| Step: 5
Training loss: 3.4379518032073975
Validation loss: 2.6518795105718795

Epoch: 6| Step: 6
Training loss: 2.160668134689331
Validation loss: 2.655432039691556

Epoch: 6| Step: 7
Training loss: 3.3803634643554688
Validation loss: 2.6806711125117477

Epoch: 6| Step: 8
Training loss: 2.8914949893951416
Validation loss: 2.675409857944776

Epoch: 6| Step: 9
Training loss: 2.121351957321167
Validation loss: 2.643177229871032

Epoch: 6| Step: 10
Training loss: 3.018275260925293
Validation loss: 2.635832537886917

Epoch: 6| Step: 11
Training loss: 3.3603081703186035
Validation loss: 2.6435402439486597

Epoch: 6| Step: 12
Training loss: 2.483488082885742
Validation loss: 2.6334001582155944

Epoch: 6| Step: 13
Training loss: 2.9909539222717285
Validation loss: 2.6407383359888548

Epoch: 15| Step: 0
Training loss: 3.4390695095062256
Validation loss: 2.6241260779801237

Epoch: 6| Step: 1
Training loss: 2.508073568344116
Validation loss: 2.6214903067517024

Epoch: 6| Step: 2
Training loss: 3.7731144428253174
Validation loss: 2.628453867409819

Epoch: 6| Step: 3
Training loss: 3.4494874477386475
Validation loss: 2.6165621639579855

Epoch: 6| Step: 4
Training loss: 3.547635555267334
Validation loss: 2.605155929442375

Epoch: 6| Step: 5
Training loss: 3.021310329437256
Validation loss: 2.592215358570058

Epoch: 6| Step: 6
Training loss: 1.8964142799377441
Validation loss: 2.5707552663741575

Epoch: 6| Step: 7
Training loss: 3.4414005279541016
Validation loss: 2.5585313868779007

Epoch: 6| Step: 8
Training loss: 1.6416192054748535
Validation loss: 2.5557702074768724

Epoch: 6| Step: 9
Training loss: 2.616292953491211
Validation loss: 2.5607256376615135

Epoch: 6| Step: 10
Training loss: 2.6692075729370117
Validation loss: 2.5696154743112545

Epoch: 6| Step: 11
Training loss: 2.169616222381592
Validation loss: 2.5894177370173956

Epoch: 6| Step: 12
Training loss: 2.855269432067871
Validation loss: 2.5674601703561764

Epoch: 6| Step: 13
Training loss: 1.6670780181884766
Validation loss: 2.5590281307056384

Epoch: 16| Step: 0
Training loss: 2.274210214614868
Validation loss: 2.5554927318326888

Epoch: 6| Step: 1
Training loss: 3.3036508560180664
Validation loss: 2.5606544556156283

Epoch: 6| Step: 2
Training loss: 2.96590518951416
Validation loss: 2.563136472496935

Epoch: 6| Step: 3
Training loss: 1.9704455137252808
Validation loss: 2.5594581147675872

Epoch: 6| Step: 4
Training loss: 2.913662910461426
Validation loss: 2.557300321517452

Epoch: 6| Step: 5
Training loss: 1.9245598316192627
Validation loss: 2.5585456330289125

Epoch: 6| Step: 6
Training loss: 2.971527576446533
Validation loss: 2.5536158879597983

Epoch: 6| Step: 7
Training loss: 3.451198101043701
Validation loss: 2.5492980095647995

Epoch: 6| Step: 8
Training loss: 2.886293411254883
Validation loss: 2.5386407170244443

Epoch: 6| Step: 9
Training loss: 2.1009602546691895
Validation loss: 2.5350237251609884

Epoch: 6| Step: 10
Training loss: 3.1144580841064453
Validation loss: 2.5327476762956187

Epoch: 6| Step: 11
Training loss: 2.629175901412964
Validation loss: 2.5303907778955277

Epoch: 6| Step: 12
Training loss: 3.2652697563171387
Validation loss: 2.523075131959813

Epoch: 6| Step: 13
Training loss: 3.2220044136047363
Validation loss: 2.519950656480687

Epoch: 17| Step: 0
Training loss: 2.5115976333618164
Validation loss: 2.517303466796875

Epoch: 6| Step: 1
Training loss: 2.881911039352417
Validation loss: 2.5208163620323263

Epoch: 6| Step: 2
Training loss: 2.942499876022339
Validation loss: 2.5266803515854703

Epoch: 6| Step: 3
Training loss: 3.1902408599853516
Validation loss: 2.534316288527622

Epoch: 6| Step: 4
Training loss: 2.737281560897827
Validation loss: 2.5169132345466205

Epoch: 6| Step: 5
Training loss: 3.0860612392425537
Validation loss: 2.5201263786644064

Epoch: 6| Step: 6
Training loss: 2.6456193923950195
Validation loss: 2.5291301101766606

Epoch: 6| Step: 7
Training loss: 3.1716785430908203
Validation loss: 2.556851925388459

Epoch: 6| Step: 8
Training loss: 2.8391947746276855
Validation loss: 2.61690346143579

Epoch: 6| Step: 9
Training loss: 2.7460219860076904
Validation loss: 2.668931850823023

Epoch: 6| Step: 10
Training loss: 3.1044249534606934
Validation loss: 2.6492424472685783

Epoch: 6| Step: 11
Training loss: 2.5856807231903076
Validation loss: 2.595042990099999

Epoch: 6| Step: 12
Training loss: 2.4448161125183105
Validation loss: 2.5562048253192695

Epoch: 6| Step: 13
Training loss: 1.5880780220031738
Validation loss: 2.553718715585688

Epoch: 18| Step: 0
Training loss: 3.050391912460327
Validation loss: 2.54640705098388

Epoch: 6| Step: 1
Training loss: 2.392087697982788
Validation loss: 2.52121917663082

Epoch: 6| Step: 2
Training loss: 2.808415651321411
Validation loss: 2.5171269998755506

Epoch: 6| Step: 3
Training loss: 3.213914632797241
Validation loss: 2.5249557879663285

Epoch: 6| Step: 4
Training loss: 2.4451260566711426
Validation loss: 2.5231761855463826

Epoch: 6| Step: 5
Training loss: 3.1206703186035156
Validation loss: 2.513869454783778

Epoch: 6| Step: 6
Training loss: 2.5034844875335693
Validation loss: 2.5078075111553235

Epoch: 6| Step: 7
Training loss: 2.2399098873138428
Validation loss: 2.5038752068755445

Epoch: 6| Step: 8
Training loss: 2.845987319946289
Validation loss: 2.520858028883575

Epoch: 6| Step: 9
Training loss: 2.2870395183563232
Validation loss: 2.539078325353643

Epoch: 6| Step: 10
Training loss: 3.1910276412963867
Validation loss: 2.5480613298313592

Epoch: 6| Step: 11
Training loss: 2.372877836227417
Validation loss: 2.516827078275783

Epoch: 6| Step: 12
Training loss: 3.4335381984710693
Validation loss: 2.5011666743986067

Epoch: 6| Step: 13
Training loss: 2.5002288818359375
Validation loss: 2.49702444640539

Epoch: 19| Step: 0
Training loss: 3.304939031600952
Validation loss: 2.4963452482736237

Epoch: 6| Step: 1
Training loss: 2.427419900894165
Validation loss: 2.4976709401735695

Epoch: 6| Step: 2
Training loss: 2.492722511291504
Validation loss: 2.5017410119374595

Epoch: 6| Step: 3
Training loss: 3.087017059326172
Validation loss: 2.498746992439352

Epoch: 6| Step: 4
Training loss: 3.142026662826538
Validation loss: 2.505394563880018

Epoch: 6| Step: 5
Training loss: 2.167353630065918
Validation loss: 2.497042117580291

Epoch: 6| Step: 6
Training loss: 2.986032247543335
Validation loss: 2.4993993697627896

Epoch: 6| Step: 7
Training loss: 3.25880765914917
Validation loss: 2.4958233525676112

Epoch: 6| Step: 8
Training loss: 2.8897674083709717
Validation loss: 2.493609848842826

Epoch: 6| Step: 9
Training loss: 2.1903014183044434
Validation loss: 2.487003654562017

Epoch: 6| Step: 10
Training loss: 2.6720705032348633
Validation loss: 2.492249934904037

Epoch: 6| Step: 11
Training loss: 2.8574352264404297
Validation loss: 2.4960417132223807

Epoch: 6| Step: 12
Training loss: 2.445530414581299
Validation loss: 2.4871784769078737

Epoch: 6| Step: 13
Training loss: 1.9507628679275513
Validation loss: 2.4819099518560592

Epoch: 20| Step: 0
Training loss: 2.779953956604004
Validation loss: 2.4928622066333728

Epoch: 6| Step: 1
Training loss: 3.60591983795166
Validation loss: 2.4958737357970207

Epoch: 6| Step: 2
Training loss: 2.71584153175354
Validation loss: 2.475314268501856

Epoch: 6| Step: 3
Training loss: 2.2667062282562256
Validation loss: 2.471949173558143

Epoch: 6| Step: 4
Training loss: 2.9242730140686035
Validation loss: 2.474314369181151

Epoch: 6| Step: 5
Training loss: 3.140836715698242
Validation loss: 2.466574263829057

Epoch: 6| Step: 6
Training loss: 2.713449478149414
Validation loss: 2.4676781162138908

Epoch: 6| Step: 7
Training loss: 2.8550798892974854
Validation loss: 2.470989368295157

Epoch: 6| Step: 8
Training loss: 3.0589675903320312
Validation loss: 2.4847903123465915

Epoch: 6| Step: 9
Training loss: 1.3291237354278564
Validation loss: 2.4951902948400027

Epoch: 6| Step: 10
Training loss: 2.726280927658081
Validation loss: 2.5500563267738587

Epoch: 6| Step: 11
Training loss: 2.538097858428955
Validation loss: 2.576042425247931

Epoch: 6| Step: 12
Training loss: 2.8381547927856445
Validation loss: 2.5965300631779495

Epoch: 6| Step: 13
Training loss: 2.273399591445923
Validation loss: 2.589355425168109

Epoch: 21| Step: 0
Training loss: 2.363511562347412
Validation loss: 2.500017609647525

Epoch: 6| Step: 1
Training loss: 3.071462392807007
Validation loss: 2.4518514602415022

Epoch: 6| Step: 2
Training loss: 2.853518009185791
Validation loss: 2.4609119020482546

Epoch: 6| Step: 3
Training loss: 2.7489771842956543
Validation loss: 2.48918939405872

Epoch: 6| Step: 4
Training loss: 2.22861909866333
Validation loss: 2.486347593286986

Epoch: 6| Step: 5
Training loss: 3.275454521179199
Validation loss: 2.484466524534328

Epoch: 6| Step: 6
Training loss: 2.143862247467041
Validation loss: 2.485476686108497

Epoch: 6| Step: 7
Training loss: 2.499030590057373
Validation loss: 2.4701478071110223

Epoch: 6| Step: 8
Training loss: 2.8464889526367188
Validation loss: 2.4695922226034184

Epoch: 6| Step: 9
Training loss: 2.71763014793396
Validation loss: 2.4999972902318484

Epoch: 6| Step: 10
Training loss: 2.7286715507507324
Validation loss: 2.4866545866894465

Epoch: 6| Step: 11
Training loss: 2.7930755615234375
Validation loss: 2.483943926390781

Epoch: 6| Step: 12
Training loss: 2.8926782608032227
Validation loss: 2.481935836935556

Epoch: 6| Step: 13
Training loss: 2.928339719772339
Validation loss: 2.4591582936625325

Epoch: 22| Step: 0
Training loss: 3.3645830154418945
Validation loss: 2.4493498110002085

Epoch: 6| Step: 1
Training loss: 2.9855124950408936
Validation loss: 2.444491837614326

Epoch: 6| Step: 2
Training loss: 2.509472131729126
Validation loss: 2.4468479694858676

Epoch: 6| Step: 3
Training loss: 2.778103828430176
Validation loss: 2.4550269829329623

Epoch: 6| Step: 4
Training loss: 2.6114354133605957
Validation loss: 2.4634333323406916

Epoch: 6| Step: 5
Training loss: 2.7402634620666504
Validation loss: 2.451254762629027

Epoch: 6| Step: 6
Training loss: 2.716799259185791
Validation loss: 2.444647540328323

Epoch: 6| Step: 7
Training loss: 3.147386312484741
Validation loss: 2.445077660263226

Epoch: 6| Step: 8
Training loss: 2.2868800163269043
Validation loss: 2.4421687664524203

Epoch: 6| Step: 9
Training loss: 2.6614279747009277
Validation loss: 2.4421842328963743

Epoch: 6| Step: 10
Training loss: 3.1316447257995605
Validation loss: 2.450159098512383

Epoch: 6| Step: 11
Training loss: 2.0760958194732666
Validation loss: 2.483891464048816

Epoch: 6| Step: 12
Training loss: 2.3580026626586914
Validation loss: 2.4854976618161766

Epoch: 6| Step: 13
Training loss: 2.3503873348236084
Validation loss: 2.447565083862633

Epoch: 23| Step: 0
Training loss: 3.7263834476470947
Validation loss: 2.4428279425508235

Epoch: 6| Step: 1
Training loss: 2.41225266456604
Validation loss: 2.442507761780934

Epoch: 6| Step: 2
Training loss: 2.704758644104004
Validation loss: 2.453425902192311

Epoch: 6| Step: 3
Training loss: 3.182277202606201
Validation loss: 2.470662104186191

Epoch: 6| Step: 4
Training loss: 2.9401609897613525
Validation loss: 2.463778458615785

Epoch: 6| Step: 5
Training loss: 2.5856733322143555
Validation loss: 2.465196345442085

Epoch: 6| Step: 6
Training loss: 2.9959354400634766
Validation loss: 2.4461518513259066

Epoch: 6| Step: 7
Training loss: 2.39323091506958
Validation loss: 2.4276832739512124

Epoch: 6| Step: 8
Training loss: 2.378715991973877
Validation loss: 2.4207760108414518

Epoch: 6| Step: 9
Training loss: 2.6057443618774414
Validation loss: 2.420157071082823

Epoch: 6| Step: 10
Training loss: 3.0058231353759766
Validation loss: 2.420908538244104

Epoch: 6| Step: 11
Training loss: 2.0771775245666504
Validation loss: 2.4191759299206477

Epoch: 6| Step: 12
Training loss: 2.0368642807006836
Validation loss: 2.4172119837935253

Epoch: 6| Step: 13
Training loss: 2.3856375217437744
Validation loss: 2.418116013209025

Epoch: 24| Step: 0
Training loss: 3.1096458435058594
Validation loss: 2.419786273792226

Epoch: 6| Step: 1
Training loss: 2.878410577774048
Validation loss: 2.4158075265986945

Epoch: 6| Step: 2
Training loss: 2.293666362762451
Validation loss: 2.417758120003567

Epoch: 6| Step: 3
Training loss: 2.3763136863708496
Validation loss: 2.4178433418273926

Epoch: 6| Step: 4
Training loss: 3.323615550994873
Validation loss: 2.4167418069736932

Epoch: 6| Step: 5
Training loss: 1.742736577987671
Validation loss: 2.4143973037760746

Epoch: 6| Step: 6
Training loss: 3.177051067352295
Validation loss: 2.4211713062819613

Epoch: 6| Step: 7
Training loss: 2.9120566844940186
Validation loss: 2.4178291700219594

Epoch: 6| Step: 8
Training loss: 2.1856913566589355
Validation loss: 2.4275517143229

Epoch: 6| Step: 9
Training loss: 3.048980951309204
Validation loss: 2.4203009015770367

Epoch: 6| Step: 10
Training loss: 2.001805543899536
Validation loss: 2.410853096233901

Epoch: 6| Step: 11
Training loss: 2.4872946739196777
Validation loss: 2.411902860928607

Epoch: 6| Step: 12
Training loss: 2.6834354400634766
Validation loss: 2.413791546257593

Epoch: 6| Step: 13
Training loss: 3.533733367919922
Validation loss: 2.411179273359237

Epoch: 25| Step: 0
Training loss: 2.902210235595703
Validation loss: 2.407975589075396

Epoch: 6| Step: 1
Training loss: 3.042043685913086
Validation loss: 2.423258560960011

Epoch: 6| Step: 2
Training loss: 2.711388111114502
Validation loss: 2.431186055624357

Epoch: 6| Step: 3
Training loss: 2.4969258308410645
Validation loss: 2.445835618562596

Epoch: 6| Step: 4
Training loss: 2.776132583618164
Validation loss: 2.4630822199647144

Epoch: 6| Step: 5
Training loss: 2.542140245437622
Validation loss: 2.4634598185939174

Epoch: 6| Step: 6
Training loss: 2.7952027320861816
Validation loss: 2.435437697236256

Epoch: 6| Step: 7
Training loss: 3.1337838172912598
Validation loss: 2.4084295380500054

Epoch: 6| Step: 8
Training loss: 3.104991912841797
Validation loss: 2.4113193968290925

Epoch: 6| Step: 9
Training loss: 2.7170157432556152
Validation loss: 2.419422185549172

Epoch: 6| Step: 10
Training loss: 2.4329934120178223
Validation loss: 2.431016537450975

Epoch: 6| Step: 11
Training loss: 2.5358238220214844
Validation loss: 2.449050162428169

Epoch: 6| Step: 12
Training loss: 2.0888216495513916
Validation loss: 2.476368558022284

Epoch: 6| Step: 13
Training loss: 1.7673050165176392
Validation loss: 2.4948063050546954

Epoch: 26| Step: 0
Training loss: 2.9154038429260254
Validation loss: 2.566730965850174

Epoch: 6| Step: 1
Training loss: 2.6800594329833984
Validation loss: 2.5387129399084274

Epoch: 6| Step: 2
Training loss: 3.6460673809051514
Validation loss: 2.5087699146680933

Epoch: 6| Step: 3
Training loss: 2.3543949127197266
Validation loss: 2.469547456310641

Epoch: 6| Step: 4
Training loss: 2.793985605239868
Validation loss: 2.4729666274080992

Epoch: 6| Step: 5
Training loss: 2.2014412879943848
Validation loss: 2.4675723673194967

Epoch: 6| Step: 6
Training loss: 2.0698184967041016
Validation loss: 2.4651730547669115

Epoch: 6| Step: 7
Training loss: 2.754678964614868
Validation loss: 2.470716950713947

Epoch: 6| Step: 8
Training loss: 2.5491526126861572
Validation loss: 2.4833111557909238

Epoch: 6| Step: 9
Training loss: 2.7159337997436523
Validation loss: 2.550259429921386

Epoch: 6| Step: 10
Training loss: 3.2758164405822754
Validation loss: 2.609595585894841

Epoch: 6| Step: 11
Training loss: 2.153026580810547
Validation loss: 2.577247832411079

Epoch: 6| Step: 12
Training loss: 3.1642255783081055
Validation loss: 2.528375461537351

Epoch: 6| Step: 13
Training loss: 2.8453691005706787
Validation loss: 2.4822469398539555

Epoch: 27| Step: 0
Training loss: 2.7276177406311035
Validation loss: 2.4736135236678587

Epoch: 6| Step: 1
Training loss: 2.659529685974121
Validation loss: 2.4646150578734694

Epoch: 6| Step: 2
Training loss: 2.0737144947052
Validation loss: 2.4618788021866993

Epoch: 6| Step: 3
Training loss: 2.2263057231903076
Validation loss: 2.4590989312817975

Epoch: 6| Step: 4
Training loss: 2.8301947116851807
Validation loss: 2.4697392038119736

Epoch: 6| Step: 5
Training loss: 3.593834400177002
Validation loss: 2.468146803558514

Epoch: 6| Step: 6
Training loss: 2.7974207401275635
Validation loss: 2.4500922028736403

Epoch: 6| Step: 7
Training loss: 2.1820836067199707
Validation loss: 2.4517151924871627

Epoch: 6| Step: 8
Training loss: 2.89700984954834
Validation loss: 2.455575843011179

Epoch: 6| Step: 9
Training loss: 2.480588912963867
Validation loss: 2.4515415571069203

Epoch: 6| Step: 10
Training loss: 2.7538421154022217
Validation loss: 2.436281704133557

Epoch: 6| Step: 11
Training loss: 3.107736587524414
Validation loss: 2.4327007493665143

Epoch: 6| Step: 12
Training loss: 2.695802927017212
Validation loss: 2.425175569390738

Epoch: 6| Step: 13
Training loss: 2.1630067825317383
Validation loss: 2.411535173334101

Epoch: 28| Step: 0
Training loss: 2.800236225128174
Validation loss: 2.4043794139739005

Epoch: 6| Step: 1
Training loss: 2.7240500450134277
Validation loss: 2.4081757504452943

Epoch: 6| Step: 2
Training loss: 3.1848011016845703
Validation loss: 2.411456564421295

Epoch: 6| Step: 3
Training loss: 2.866046905517578
Validation loss: 2.4120269975354596

Epoch: 6| Step: 4
Training loss: 2.993037462234497
Validation loss: 2.4065181773195983

Epoch: 6| Step: 5
Training loss: 3.123455047607422
Validation loss: 2.4039522652984946

Epoch: 6| Step: 6
Training loss: 1.9407700300216675
Validation loss: 2.3941230415016093

Epoch: 6| Step: 7
Training loss: 2.4852819442749023
Validation loss: 2.3860793831527873

Epoch: 6| Step: 8
Training loss: 2.5586555004119873
Validation loss: 2.382823790273359

Epoch: 6| Step: 9
Training loss: 2.5601043701171875
Validation loss: 2.38036286446356

Epoch: 6| Step: 10
Training loss: 2.4506850242614746
Validation loss: 2.3777199714414534

Epoch: 6| Step: 11
Training loss: 2.0847482681274414
Validation loss: 2.3760906803992485

Epoch: 6| Step: 12
Training loss: 2.003251791000366
Validation loss: 2.3782425003667034

Epoch: 6| Step: 13
Training loss: 3.6129045486450195
Validation loss: 2.3843734777101906

Epoch: 29| Step: 0
Training loss: 2.805687665939331
Validation loss: 2.397588542712632

Epoch: 6| Step: 1
Training loss: 2.611941337585449
Validation loss: 2.3941185679487003

Epoch: 6| Step: 2
Training loss: 2.568246841430664
Validation loss: 2.390614233991151

Epoch: 6| Step: 3
Training loss: 2.7398664951324463
Validation loss: 2.384850086704377

Epoch: 6| Step: 4
Training loss: 3.0951366424560547
Validation loss: 2.379576821481028

Epoch: 6| Step: 5
Training loss: 2.333120822906494
Validation loss: 2.3753347371214177

Epoch: 6| Step: 6
Training loss: 2.4690098762512207
Validation loss: 2.3703908125559487

Epoch: 6| Step: 7
Training loss: 2.8312325477600098
Validation loss: 2.372687268000777

Epoch: 6| Step: 8
Training loss: 2.5598933696746826
Validation loss: 2.3735817017093783

Epoch: 6| Step: 9
Training loss: 2.285923719406128
Validation loss: 2.3779243525638374

Epoch: 6| Step: 10
Training loss: 3.201108455657959
Validation loss: 2.38617012064944

Epoch: 6| Step: 11
Training loss: 2.735149383544922
Validation loss: 2.40764344123102

Epoch: 6| Step: 12
Training loss: 1.872718334197998
Validation loss: 2.410136727876561

Epoch: 6| Step: 13
Training loss: 2.70485782623291
Validation loss: 2.4466693068063385

Epoch: 30| Step: 0
Training loss: 2.9054112434387207
Validation loss: 2.4239614343130462

Epoch: 6| Step: 1
Training loss: 2.530684471130371
Validation loss: 2.409861182653776

Epoch: 6| Step: 2
Training loss: 1.948348879814148
Validation loss: 2.394090765266008

Epoch: 6| Step: 3
Training loss: 2.545504570007324
Validation loss: 2.3874993324279785

Epoch: 6| Step: 4
Training loss: 2.8142316341400146
Validation loss: 2.3875107995925413

Epoch: 6| Step: 5
Training loss: 2.5039477348327637
Validation loss: 2.3803359872551373

Epoch: 6| Step: 6
Training loss: 2.6726176738739014
Validation loss: 2.3881876904477357

Epoch: 6| Step: 7
Training loss: 2.200363874435425
Validation loss: 2.393512241301998

Epoch: 6| Step: 8
Training loss: 3.044480800628662
Validation loss: 2.4013818720335602

Epoch: 6| Step: 9
Training loss: 2.2626185417175293
Validation loss: 2.4130776159224974

Epoch: 6| Step: 10
Training loss: 2.2370100021362305
Validation loss: 2.4142378094375774

Epoch: 6| Step: 11
Training loss: 3.1182868480682373
Validation loss: 2.4212487795019664

Epoch: 6| Step: 12
Training loss: 3.1799209117889404
Validation loss: 2.4473093145637104

Epoch: 6| Step: 13
Training loss: 2.952733278274536
Validation loss: 2.408229799680812

Epoch: 31| Step: 0
Training loss: 2.674610137939453
Validation loss: 2.383020054909491

Epoch: 6| Step: 1
Training loss: 2.7683467864990234
Validation loss: 2.3604314173421552

Epoch: 6| Step: 2
Training loss: 2.961900234222412
Validation loss: 2.3556968217254965

Epoch: 6| Step: 3
Training loss: 2.680105209350586
Validation loss: 2.3567338323080413

Epoch: 6| Step: 4
Training loss: 2.018766164779663
Validation loss: 2.3615046419123167

Epoch: 6| Step: 5
Training loss: 2.864342212677002
Validation loss: 2.3601935435366888

Epoch: 6| Step: 6
Training loss: 2.587017774581909
Validation loss: 2.3674848002772175

Epoch: 6| Step: 7
Training loss: 2.772465705871582
Validation loss: 2.3728103406967653

Epoch: 6| Step: 8
Training loss: 3.1279783248901367
Validation loss: 2.3841264837531635

Epoch: 6| Step: 9
Training loss: 2.406578540802002
Validation loss: 2.4138155457794026

Epoch: 6| Step: 10
Training loss: 2.4453959465026855
Validation loss: 2.3939637419998006

Epoch: 6| Step: 11
Training loss: 2.839186191558838
Validation loss: 2.367137691026093

Epoch: 6| Step: 12
Training loss: 2.67518949508667
Validation loss: 2.347769432170417

Epoch: 6| Step: 13
Training loss: 1.7360155582427979
Validation loss: 2.340226129818988

Epoch: 32| Step: 0
Training loss: 1.8844738006591797
Validation loss: 2.34357875393283

Epoch: 6| Step: 1
Training loss: 2.653968334197998
Validation loss: 2.3541465523422405

Epoch: 6| Step: 2
Training loss: 2.6043338775634766
Validation loss: 2.3939214214201896

Epoch: 6| Step: 3
Training loss: 3.2464871406555176
Validation loss: 2.4677994353796846

Epoch: 6| Step: 4
Training loss: 2.9294304847717285
Validation loss: 2.4783724841251167

Epoch: 6| Step: 5
Training loss: 3.1361308097839355
Validation loss: 2.4764017571685133

Epoch: 6| Step: 6
Training loss: 2.234708309173584
Validation loss: 2.43588928509784

Epoch: 6| Step: 7
Training loss: 2.1735117435455322
Validation loss: 2.3789460838481946

Epoch: 6| Step: 8
Training loss: 2.7063045501708984
Validation loss: 2.367869389954434

Epoch: 6| Step: 9
Training loss: 2.5672988891601562
Validation loss: 2.351872932526373

Epoch: 6| Step: 10
Training loss: 2.896792411804199
Validation loss: 2.3490461559705835

Epoch: 6| Step: 11
Training loss: 2.919128894805908
Validation loss: 2.3463130997073267

Epoch: 6| Step: 12
Training loss: 2.7165002822875977
Validation loss: 2.354673006201303

Epoch: 6| Step: 13
Training loss: 1.7652151584625244
Validation loss: 2.3621437575227473

Epoch: 33| Step: 0
Training loss: 2.5770139694213867
Validation loss: 2.366419235865275

Epoch: 6| Step: 1
Training loss: 2.4804158210754395
Validation loss: 2.370871341356667

Epoch: 6| Step: 2
Training loss: 2.6312923431396484
Validation loss: 2.373216308573241

Epoch: 6| Step: 3
Training loss: 3.148242473602295
Validation loss: 2.387678564235728

Epoch: 6| Step: 4
Training loss: 2.993978977203369
Validation loss: 2.388090564358619

Epoch: 6| Step: 5
Training loss: 2.6499738693237305
Validation loss: 2.4061704874038696

Epoch: 6| Step: 6
Training loss: 3.0297329425811768
Validation loss: 2.388808674709771

Epoch: 6| Step: 7
Training loss: 2.758218765258789
Validation loss: 2.37723099031756

Epoch: 6| Step: 8
Training loss: 2.233044385910034
Validation loss: 2.3636878357138684

Epoch: 6| Step: 9
Training loss: 2.5693819522857666
Validation loss: 2.354305512161665

Epoch: 6| Step: 10
Training loss: 2.7144155502319336
Validation loss: 2.3584358589623564

Epoch: 6| Step: 11
Training loss: 1.9816052913665771
Validation loss: 2.3447439260380243

Epoch: 6| Step: 12
Training loss: 2.5411295890808105
Validation loss: 2.3501093515785794

Epoch: 6| Step: 13
Training loss: 2.0731570720672607
Validation loss: 2.3624266834669214

Epoch: 34| Step: 0
Training loss: 3.0473597049713135
Validation loss: 2.386191680867185

Epoch: 6| Step: 1
Training loss: 2.614558696746826
Validation loss: 2.3899257054892917

Epoch: 6| Step: 2
Training loss: 2.549497127532959
Validation loss: 2.3850909074147544

Epoch: 6| Step: 3
Training loss: 3.264733076095581
Validation loss: 2.3745857618188344

Epoch: 6| Step: 4
Training loss: 1.9438915252685547
Validation loss: 2.360011098205402

Epoch: 6| Step: 5
Training loss: 1.8178019523620605
Validation loss: 2.3495565511847056

Epoch: 6| Step: 6
Training loss: 3.123061180114746
Validation loss: 2.3372968832651773

Epoch: 6| Step: 7
Training loss: 2.593196153640747
Validation loss: 2.327257243535852

Epoch: 6| Step: 8
Training loss: 2.7648019790649414
Validation loss: 2.330546527780512

Epoch: 6| Step: 9
Training loss: 2.465575933456421
Validation loss: 2.3325577602591565

Epoch: 6| Step: 10
Training loss: 2.6777279376983643
Validation loss: 2.333511460211969

Epoch: 6| Step: 11
Training loss: 3.1031570434570312
Validation loss: 2.3329169955304874

Epoch: 6| Step: 12
Training loss: 2.523385524749756
Validation loss: 2.3446707725524902

Epoch: 6| Step: 13
Training loss: 1.638946771621704
Validation loss: 2.357977787653605

Epoch: 35| Step: 0
Training loss: 2.8598480224609375
Validation loss: 2.406985628989435

Epoch: 6| Step: 1
Training loss: 3.2561147212982178
Validation loss: 2.466853339184997

Epoch: 6| Step: 2
Training loss: 3.109950542449951
Validation loss: 2.4880849033273678

Epoch: 6| Step: 3
Training loss: 2.348292827606201
Validation loss: 2.493042253678845

Epoch: 6| Step: 4
Training loss: 2.8131566047668457
Validation loss: 2.478083050379189

Epoch: 6| Step: 5
Training loss: 2.2848901748657227
Validation loss: 2.4414839642022246

Epoch: 6| Step: 6
Training loss: 2.538311004638672
Validation loss: 2.4168976891425347

Epoch: 6| Step: 7
Training loss: 2.6636428833007812
Validation loss: 2.382682559310749

Epoch: 6| Step: 8
Training loss: 2.1436550617218018
Validation loss: 2.355864163367979

Epoch: 6| Step: 9
Training loss: 2.859095573425293
Validation loss: 2.345973260941044

Epoch: 6| Step: 10
Training loss: 2.6235251426696777
Validation loss: 2.344415121181037

Epoch: 6| Step: 11
Training loss: 2.505835771560669
Validation loss: 2.355253368295649

Epoch: 6| Step: 12
Training loss: 1.9998375177383423
Validation loss: 2.3397531791399886

Epoch: 6| Step: 13
Training loss: 2.8981854915618896
Validation loss: 2.3435357898794194

Epoch: 36| Step: 0
Training loss: 2.6599984169006348
Validation loss: 2.3339661270059566

Epoch: 6| Step: 1
Training loss: 2.363462448120117
Validation loss: 2.3331259591605074

Epoch: 6| Step: 2
Training loss: 2.548881769180298
Validation loss: 2.341569423675537

Epoch: 6| Step: 3
Training loss: 2.609018564224243
Validation loss: 2.336026391675395

Epoch: 6| Step: 4
Training loss: 2.1577703952789307
Validation loss: 2.340534507587392

Epoch: 6| Step: 5
Training loss: 2.349912166595459
Validation loss: 2.3367657815256426

Epoch: 6| Step: 6
Training loss: 3.1394777297973633
Validation loss: 2.327186064053607

Epoch: 6| Step: 7
Training loss: 2.2621259689331055
Validation loss: 2.324044160945441

Epoch: 6| Step: 8
Training loss: 2.4181649684906006
Validation loss: 2.3351767447686966

Epoch: 6| Step: 9
Training loss: 3.3458943367004395
Validation loss: 2.3610822641721336

Epoch: 6| Step: 10
Training loss: 2.414064407348633
Validation loss: 2.4028006574159027

Epoch: 6| Step: 11
Training loss: 2.770195722579956
Validation loss: 2.439651420039515

Epoch: 6| Step: 12
Training loss: 2.6797261238098145
Validation loss: 2.456570786814536

Epoch: 6| Step: 13
Training loss: 2.7703428268432617
Validation loss: 2.447193355970485

Epoch: 37| Step: 0
Training loss: 3.4311423301696777
Validation loss: 2.4113777324717534

Epoch: 6| Step: 1
Training loss: 2.6699819564819336
Validation loss: 2.3702915586451048

Epoch: 6| Step: 2
Training loss: 2.5640969276428223
Validation loss: 2.3451303769183416

Epoch: 6| Step: 3
Training loss: 2.0103023052215576
Validation loss: 2.3186817656281176

Epoch: 6| Step: 4
Training loss: 2.8273730278015137
Validation loss: 2.297738354693177

Epoch: 6| Step: 5
Training loss: 2.4047253131866455
Validation loss: 2.299956424261934

Epoch: 6| Step: 6
Training loss: 3.2509453296661377
Validation loss: 2.3038963117907123

Epoch: 6| Step: 7
Training loss: 2.3993337154388428
Validation loss: 2.320824505180441

Epoch: 6| Step: 8
Training loss: 2.497690200805664
Validation loss: 2.3356294426866757

Epoch: 6| Step: 9
Training loss: 1.9775092601776123
Validation loss: 2.3548387071137786

Epoch: 6| Step: 10
Training loss: 2.0613760948181152
Validation loss: 2.393265878000567

Epoch: 6| Step: 11
Training loss: 2.7173855304718018
Validation loss: 2.4506868675190914

Epoch: 6| Step: 12
Training loss: 3.349846601486206
Validation loss: 2.476749691911923

Epoch: 6| Step: 13
Training loss: 1.8294358253479004
Validation loss: 2.468396573938349

Epoch: 38| Step: 0
Training loss: 2.759243965148926
Validation loss: 2.4655438366756646

Epoch: 6| Step: 1
Training loss: 2.3052988052368164
Validation loss: 2.4371552877528693

Epoch: 6| Step: 2
Training loss: 2.5066590309143066
Validation loss: 2.376905859157603

Epoch: 6| Step: 3
Training loss: 2.624680757522583
Validation loss: 2.356328069522817

Epoch: 6| Step: 4
Training loss: 2.765930652618408
Validation loss: 2.349960396366735

Epoch: 6| Step: 5
Training loss: 2.468907356262207
Validation loss: 2.3587988986763904

Epoch: 6| Step: 6
Training loss: 2.636969566345215
Validation loss: 2.3951412170164046

Epoch: 6| Step: 7
Training loss: 2.428218126296997
Validation loss: 2.430606117812536

Epoch: 6| Step: 8
Training loss: 3.2902770042419434
Validation loss: 2.4237160657041814

Epoch: 6| Step: 9
Training loss: 2.8747429847717285
Validation loss: 2.3834342418178434

Epoch: 6| Step: 10
Training loss: 2.292274236679077
Validation loss: 2.3401391378013034

Epoch: 6| Step: 11
Training loss: 2.4593920707702637
Validation loss: 2.31447874089723

Epoch: 6| Step: 12
Training loss: 2.551055431365967
Validation loss: 2.3000508841647895

Epoch: 6| Step: 13
Training loss: 2.232909679412842
Validation loss: 2.314926888353081

Epoch: 39| Step: 0
Training loss: 2.9285085201263428
Validation loss: 2.3032225139679445

Epoch: 6| Step: 1
Training loss: 2.296057939529419
Validation loss: 2.296295853071315

Epoch: 6| Step: 2
Training loss: 2.1913294792175293
Validation loss: 2.307751783760645

Epoch: 6| Step: 3
Training loss: 3.15594220161438
Validation loss: 2.3382258645949827

Epoch: 6| Step: 4
Training loss: 2.864968776702881
Validation loss: 2.358794935287968

Epoch: 6| Step: 5
Training loss: 2.5894381999969482
Validation loss: 2.3504442322638726

Epoch: 6| Step: 6
Training loss: 2.5632033348083496
Validation loss: 2.354046416539018

Epoch: 6| Step: 7
Training loss: 2.2730495929718018
Validation loss: 2.360543517656224

Epoch: 6| Step: 8
Training loss: 2.7961151599884033
Validation loss: 2.3510362435412664

Epoch: 6| Step: 9
Training loss: 2.315463066101074
Validation loss: 2.341486874447074

Epoch: 6| Step: 10
Training loss: 2.96579647064209
Validation loss: 2.327508036808301

Epoch: 6| Step: 11
Training loss: 2.4950170516967773
Validation loss: 2.316116407353391

Epoch: 6| Step: 12
Training loss: 2.2664804458618164
Validation loss: 2.315537514225129

Epoch: 6| Step: 13
Training loss: 2.221005439758301
Validation loss: 2.3193068222333024

Epoch: 40| Step: 0
Training loss: 2.0862603187561035
Validation loss: 2.359016913239674

Epoch: 6| Step: 1
Training loss: 2.5067620277404785
Validation loss: 2.374404920044766

Epoch: 6| Step: 2
Training loss: 2.5342984199523926
Validation loss: 2.3825653163335656

Epoch: 6| Step: 3
Training loss: 2.368793249130249
Validation loss: 2.3825479809955885

Epoch: 6| Step: 4
Training loss: 2.4572322368621826
Validation loss: 2.3582526855571295

Epoch: 6| Step: 5
Training loss: 2.775754928588867
Validation loss: 2.341091130369453

Epoch: 6| Step: 6
Training loss: 1.7346959114074707
Validation loss: 2.308987209873815

Epoch: 6| Step: 7
Training loss: 3.3038322925567627
Validation loss: 2.2990730706081597

Epoch: 6| Step: 8
Training loss: 2.7111246585845947
Validation loss: 2.291396984490015

Epoch: 6| Step: 9
Training loss: 2.762763023376465
Validation loss: 2.282137117078227

Epoch: 6| Step: 10
Training loss: 2.692286968231201
Validation loss: 2.2860301515107513

Epoch: 6| Step: 11
Training loss: 2.9987072944641113
Validation loss: 2.293011485889394

Epoch: 6| Step: 12
Training loss: 2.4652371406555176
Validation loss: 2.3249229077369935

Epoch: 6| Step: 13
Training loss: 2.6940507888793945
Validation loss: 2.3193675651345202

Epoch: 41| Step: 0
Training loss: 2.47464656829834
Validation loss: 2.321525478875765

Epoch: 6| Step: 1
Training loss: 2.6384172439575195
Validation loss: 2.328330268142044

Epoch: 6| Step: 2
Training loss: 2.2353615760803223
Validation loss: 2.3424001073324554

Epoch: 6| Step: 3
Training loss: 2.3284711837768555
Validation loss: 2.355074305688181

Epoch: 6| Step: 4
Training loss: 2.5272374153137207
Validation loss: 2.3626161031825568

Epoch: 6| Step: 5
Training loss: 2.255828857421875
Validation loss: 2.366972651532901

Epoch: 6| Step: 6
Training loss: 2.4949607849121094
Validation loss: 2.3319455782572427

Epoch: 6| Step: 7
Training loss: 2.6677308082580566
Validation loss: 2.3154424262303177

Epoch: 6| Step: 8
Training loss: 2.0516371726989746
Validation loss: 2.3114989726774153

Epoch: 6| Step: 9
Training loss: 2.750640869140625
Validation loss: 2.310938440343385

Epoch: 6| Step: 10
Training loss: 2.8468379974365234
Validation loss: 2.3123951599162114

Epoch: 6| Step: 11
Training loss: 3.5475382804870605
Validation loss: 2.302729450246339

Epoch: 6| Step: 12
Training loss: 2.2683067321777344
Validation loss: 2.2990921748581754

Epoch: 6| Step: 13
Training loss: 3.0035548210144043
Validation loss: 2.2926100377113587

Epoch: 42| Step: 0
Training loss: 2.887456178665161
Validation loss: 2.275551190940283

Epoch: 6| Step: 1
Training loss: 3.0307209491729736
Validation loss: 2.2689660851673414

Epoch: 6| Step: 2
Training loss: 2.1312336921691895
Validation loss: 2.270328947292861

Epoch: 6| Step: 3
Training loss: 2.2547144889831543
Validation loss: 2.261669780618401

Epoch: 6| Step: 4
Training loss: 2.7450218200683594
Validation loss: 2.263789289741106

Epoch: 6| Step: 5
Training loss: 2.0436787605285645
Validation loss: 2.2671748053643013

Epoch: 6| Step: 6
Training loss: 2.2179248332977295
Validation loss: 2.2611980207504763

Epoch: 6| Step: 7
Training loss: 3.1491312980651855
Validation loss: 2.26255355599106

Epoch: 6| Step: 8
Training loss: 2.577948808670044
Validation loss: 2.2694258882153417

Epoch: 6| Step: 9
Training loss: 2.058257818222046
Validation loss: 2.2754181149185344

Epoch: 6| Step: 10
Training loss: 2.5272674560546875
Validation loss: 2.2869697232400217

Epoch: 6| Step: 11
Training loss: 2.786982774734497
Validation loss: 2.309509563189681

Epoch: 6| Step: 12
Training loss: 2.9143199920654297
Validation loss: 2.3474120965567966

Epoch: 6| Step: 13
Training loss: 2.603449821472168
Validation loss: 2.3474272028092416

Epoch: 43| Step: 0
Training loss: 2.079464912414551
Validation loss: 2.325711278505223

Epoch: 6| Step: 1
Training loss: 3.1482157707214355
Validation loss: 2.3032427039197696

Epoch: 6| Step: 2
Training loss: 3.4636011123657227
Validation loss: 2.290523895653345

Epoch: 6| Step: 3
Training loss: 2.5639944076538086
Validation loss: 2.2701169739487352

Epoch: 6| Step: 4
Training loss: 2.4349942207336426
Validation loss: 2.2659945744340138

Epoch: 6| Step: 5
Training loss: 2.258910655975342
Validation loss: 2.265858596371066

Epoch: 6| Step: 6
Training loss: 2.016439914703369
Validation loss: 2.2664576525329263

Epoch: 6| Step: 7
Training loss: 2.625838041305542
Validation loss: 2.2555068872308217

Epoch: 6| Step: 8
Training loss: 2.4262869358062744
Validation loss: 2.260297106158349

Epoch: 6| Step: 9
Training loss: 2.7773115634918213
Validation loss: 2.2502929523426998

Epoch: 6| Step: 10
Training loss: 2.548218250274658
Validation loss: 2.2585018962942143

Epoch: 6| Step: 11
Training loss: 2.313520669937134
Validation loss: 2.256325042375954

Epoch: 6| Step: 12
Training loss: 2.498140573501587
Validation loss: 2.2662117353049656

Epoch: 6| Step: 13
Training loss: 2.4331488609313965
Validation loss: 2.2836755834599978

Epoch: 44| Step: 0
Training loss: 2.604365825653076
Validation loss: 2.265963891501068

Epoch: 6| Step: 1
Training loss: 3.451171398162842
Validation loss: 2.2733238871379564

Epoch: 6| Step: 2
Training loss: 2.6276917457580566
Validation loss: 2.273315724506173

Epoch: 6| Step: 3
Training loss: 2.565690040588379
Validation loss: 2.277331805998279

Epoch: 6| Step: 4
Training loss: 3.219951629638672
Validation loss: 2.295162276555133

Epoch: 6| Step: 5
Training loss: 2.2955682277679443
Validation loss: 2.306864592336839

Epoch: 6| Step: 6
Training loss: 2.8185014724731445
Validation loss: 2.3250549736843316

Epoch: 6| Step: 7
Training loss: 2.3445687294006348
Validation loss: 2.3476046964686406

Epoch: 6| Step: 8
Training loss: 2.6015655994415283
Validation loss: 2.391229908953431

Epoch: 6| Step: 9
Training loss: 1.7780486345291138
Validation loss: 2.4822086775174705

Epoch: 6| Step: 10
Training loss: 2.12483286857605
Validation loss: 2.554142480255455

Epoch: 6| Step: 11
Training loss: 2.736933708190918
Validation loss: 2.4185832136420795

Epoch: 6| Step: 12
Training loss: 2.159748077392578
Validation loss: 2.3389148789067424

Epoch: 6| Step: 13
Training loss: 2.5256130695343018
Validation loss: 2.2800394001827446

Epoch: 45| Step: 0
Training loss: 1.7401028871536255
Validation loss: 2.259728003573674

Epoch: 6| Step: 1
Training loss: 2.345177173614502
Validation loss: 2.258719498111356

Epoch: 6| Step: 2
Training loss: 2.232290506362915
Validation loss: 2.2580470936272734

Epoch: 6| Step: 3
Training loss: 2.9910483360290527
Validation loss: 2.246084326057024

Epoch: 6| Step: 4
Training loss: 2.3005261421203613
Validation loss: 2.2484820658160793

Epoch: 6| Step: 5
Training loss: 3.230192184448242
Validation loss: 2.2516426911918064

Epoch: 6| Step: 6
Training loss: 2.7866837978363037
Validation loss: 2.256512695743192

Epoch: 6| Step: 7
Training loss: 2.513129234313965
Validation loss: 2.256207832726099

Epoch: 6| Step: 8
Training loss: 2.482357978820801
Validation loss: 2.2549601626652542

Epoch: 6| Step: 9
Training loss: 2.5495755672454834
Validation loss: 2.2527421302692865

Epoch: 6| Step: 10
Training loss: 3.2172045707702637
Validation loss: 2.2485321157722065

Epoch: 6| Step: 11
Training loss: 2.76663875579834
Validation loss: 2.2547630674095562

Epoch: 6| Step: 12
Training loss: 2.2702722549438477
Validation loss: 2.2533593152159

Epoch: 6| Step: 13
Training loss: 2.1759872436523438
Validation loss: 2.2483519405447026

Epoch: 46| Step: 0
Training loss: 2.7436957359313965
Validation loss: 2.273729578141243

Epoch: 6| Step: 1
Training loss: 2.0809175968170166
Validation loss: 2.3057290661719536

Epoch: 6| Step: 2
Training loss: 2.454840660095215
Validation loss: 2.328434569861299

Epoch: 6| Step: 3
Training loss: 2.6522955894470215
Validation loss: 2.337750029820268

Epoch: 6| Step: 4
Training loss: 2.239521026611328
Validation loss: 2.3484870490207466

Epoch: 6| Step: 5
Training loss: 2.6945266723632812
Validation loss: 2.3577023885583364

Epoch: 6| Step: 6
Training loss: 2.251250743865967
Validation loss: 2.3570300661107546

Epoch: 6| Step: 7
Training loss: 3.5601983070373535
Validation loss: 2.338779039280389

Epoch: 6| Step: 8
Training loss: 2.541156768798828
Validation loss: 2.3085972442421863

Epoch: 6| Step: 9
Training loss: 2.5482935905456543
Validation loss: 2.26820433011619

Epoch: 6| Step: 10
Training loss: 2.354567527770996
Validation loss: 2.2497867614992204

Epoch: 6| Step: 11
Training loss: 2.7632384300231934
Validation loss: 2.2344959628197456

Epoch: 6| Step: 12
Training loss: 1.9998688697814941
Validation loss: 2.231863881952019

Epoch: 6| Step: 13
Training loss: 2.4630393981933594
Validation loss: 2.2298713332863263

Epoch: 47| Step: 0
Training loss: 2.4281532764434814
Validation loss: 2.2294351388049383

Epoch: 6| Step: 1
Training loss: 2.982685089111328
Validation loss: 2.2286338421606247

Epoch: 6| Step: 2
Training loss: 2.6206722259521484
Validation loss: 2.237226055514428

Epoch: 6| Step: 3
Training loss: 2.006814479827881
Validation loss: 2.2313252507999377

Epoch: 6| Step: 4
Training loss: 2.846122980117798
Validation loss: 2.2245284049741683

Epoch: 6| Step: 5
Training loss: 2.3634138107299805
Validation loss: 2.221473806647844

Epoch: 6| Step: 6
Training loss: 2.5662693977355957
Validation loss: 2.207493278288072

Epoch: 6| Step: 7
Training loss: 2.884653091430664
Validation loss: 2.2064622422700286

Epoch: 6| Step: 8
Training loss: 2.767890453338623
Validation loss: 2.208095445427843

Epoch: 6| Step: 9
Training loss: 2.5295634269714355
Validation loss: 2.2172951134302283

Epoch: 6| Step: 10
Training loss: 2.2478251457214355
Validation loss: 2.222825002926652

Epoch: 6| Step: 11
Training loss: 2.6366071701049805
Validation loss: 2.239649159933931

Epoch: 6| Step: 12
Training loss: 2.421156406402588
Validation loss: 2.249710572663174

Epoch: 6| Step: 13
Training loss: 2.4585134983062744
Validation loss: 2.2513805256094983

Epoch: 48| Step: 0
Training loss: 2.9450528621673584
Validation loss: 2.2543104028189056

Epoch: 6| Step: 1
Training loss: 1.841646432876587
Validation loss: 2.252466651701158

Epoch: 6| Step: 2
Training loss: 2.604253053665161
Validation loss: 2.2437819242477417

Epoch: 6| Step: 3
Training loss: 2.4460713863372803
Validation loss: 2.2342719903556247

Epoch: 6| Step: 4
Training loss: 3.365705728530884
Validation loss: 2.2396468218936714

Epoch: 6| Step: 5
Training loss: 2.8159284591674805
Validation loss: 2.233452671317644

Epoch: 6| Step: 6
Training loss: 2.460914134979248
Validation loss: 2.225840328842081

Epoch: 6| Step: 7
Training loss: 2.432194709777832
Validation loss: 2.220297610887917

Epoch: 6| Step: 8
Training loss: 3.138826608657837
Validation loss: 2.216572617971769

Epoch: 6| Step: 9
Training loss: 2.300550699234009
Validation loss: 2.2164919350736882

Epoch: 6| Step: 10
Training loss: 2.527100086212158
Validation loss: 2.22644317278298

Epoch: 6| Step: 11
Training loss: 2.140939950942993
Validation loss: 2.2386092268010622

Epoch: 6| Step: 12
Training loss: 2.25553560256958
Validation loss: 2.2478274376161638

Epoch: 6| Step: 13
Training loss: 1.8239737749099731
Validation loss: 2.2508398461085495

Epoch: 49| Step: 0
Training loss: 2.136720895767212
Validation loss: 2.257830394211636

Epoch: 6| Step: 1
Training loss: 3.1747913360595703
Validation loss: 2.2672603489250265

Epoch: 6| Step: 2
Training loss: 2.0625391006469727
Validation loss: 2.27664549760921

Epoch: 6| Step: 3
Training loss: 2.1386139392852783
Validation loss: 2.2943439509278987

Epoch: 6| Step: 4
Training loss: 2.443587303161621
Validation loss: 2.3012075629285587

Epoch: 6| Step: 5
Training loss: 3.5658321380615234
Validation loss: 2.310270796539963

Epoch: 6| Step: 6
Training loss: 1.7015843391418457
Validation loss: 2.2821679294750257

Epoch: 6| Step: 7
Training loss: 2.1439716815948486
Validation loss: 2.283395928721274

Epoch: 6| Step: 8
Training loss: 2.790621519088745
Validation loss: 2.2683605173582673

Epoch: 6| Step: 9
Training loss: 2.756844997406006
Validation loss: 2.2439718220823552

Epoch: 6| Step: 10
Training loss: 2.408217430114746
Validation loss: 2.216187351493425

Epoch: 6| Step: 11
Training loss: 2.961916923522949
Validation loss: 2.1943433336032334

Epoch: 6| Step: 12
Training loss: 1.9854592084884644
Validation loss: 2.191616940241988

Epoch: 6| Step: 13
Training loss: 3.1086699962615967
Validation loss: 2.1928025894267584

Epoch: 50| Step: 0
Training loss: 2.6873998641967773
Validation loss: 2.195687106860581

Epoch: 6| Step: 1
Training loss: 2.37050461769104
Validation loss: 2.2026263667691137

Epoch: 6| Step: 2
Training loss: 2.8822970390319824
Validation loss: 2.2040901594264533

Epoch: 6| Step: 3
Training loss: 3.1600916385650635
Validation loss: 2.200159401021978

Epoch: 6| Step: 4
Training loss: 3.1151537895202637
Validation loss: 2.192948040141854

Epoch: 6| Step: 5
Training loss: 2.145355701446533
Validation loss: 2.1879552769404587

Epoch: 6| Step: 6
Training loss: 2.618143081665039
Validation loss: 2.1850098076687066

Epoch: 6| Step: 7
Training loss: 2.906257152557373
Validation loss: 2.187532332635695

Epoch: 6| Step: 8
Training loss: 2.792252779006958
Validation loss: 2.188855872359327

Epoch: 6| Step: 9
Training loss: 2.6261305809020996
Validation loss: 2.190859809998543

Epoch: 6| Step: 10
Training loss: 1.943699598312378
Validation loss: 2.2073296910973004

Epoch: 6| Step: 11
Training loss: 1.564098834991455
Validation loss: 2.2249888040686168

Epoch: 6| Step: 12
Training loss: 2.080925464630127
Validation loss: 2.259408243240849

Epoch: 6| Step: 13
Training loss: 2.411982297897339
Validation loss: 2.2985455348927486

Epoch: 51| Step: 0
Training loss: 2.694488763809204
Validation loss: 2.37054604740553

Epoch: 6| Step: 1
Training loss: 2.3274855613708496
Validation loss: 2.411886929183878

Epoch: 6| Step: 2
Training loss: 3.0574910640716553
Validation loss: 2.381902566520117

Epoch: 6| Step: 3
Training loss: 3.593184232711792
Validation loss: 2.3314939032318773

Epoch: 6| Step: 4
Training loss: 2.7062435150146484
Validation loss: 2.3144633846898235

Epoch: 6| Step: 5
Training loss: 2.791424036026001
Validation loss: 2.2816053282830024

Epoch: 6| Step: 6
Training loss: 1.9311411380767822
Validation loss: 2.286605247887232

Epoch: 6| Step: 7
Training loss: 1.9112694263458252
Validation loss: 2.2836224391896236

Epoch: 6| Step: 8
Training loss: 3.3629202842712402
Validation loss: 2.2864588101704917

Epoch: 6| Step: 9
Training loss: 1.9009404182434082
Validation loss: 2.280625566359489

Epoch: 6| Step: 10
Training loss: 1.776870846748352
Validation loss: 2.2589980197209183

Epoch: 6| Step: 11
Training loss: 2.945314645767212
Validation loss: 2.224435665274179

Epoch: 6| Step: 12
Training loss: 2.014166831970215
Validation loss: 2.209860056959173

Epoch: 6| Step: 13
Training loss: 2.0434091091156006
Validation loss: 2.2164354580704884

Epoch: 52| Step: 0
Training loss: 2.624122142791748
Validation loss: 2.208147002804664

Epoch: 6| Step: 1
Training loss: 2.4776573181152344
Validation loss: 2.2266505264466807

Epoch: 6| Step: 2
Training loss: 2.774829149246216
Validation loss: 2.2220499169441963

Epoch: 6| Step: 3
Training loss: 2.819934844970703
Validation loss: 2.2202823674806984

Epoch: 6| Step: 4
Training loss: 2.2001328468322754
Validation loss: 2.209215025747976

Epoch: 6| Step: 5
Training loss: 2.265315532684326
Validation loss: 2.195918457482451

Epoch: 6| Step: 6
Training loss: 2.293304681777954
Validation loss: 2.1884388308371268

Epoch: 6| Step: 7
Training loss: 2.749781608581543
Validation loss: 2.195168366996191

Epoch: 6| Step: 8
Training loss: 2.8172109127044678
Validation loss: 2.195521434148153

Epoch: 6| Step: 9
Training loss: 2.2437777519226074
Validation loss: 2.1950148382494525

Epoch: 6| Step: 10
Training loss: 2.7292392253875732
Validation loss: 2.194672058987361

Epoch: 6| Step: 11
Training loss: 2.47499942779541
Validation loss: 2.195961921445785

Epoch: 6| Step: 12
Training loss: 2.2548468112945557
Validation loss: 2.2008314850509807

Epoch: 6| Step: 13
Training loss: 2.3936781883239746
Validation loss: 2.207324617652483

Epoch: 53| Step: 0
Training loss: 2.9309780597686768
Validation loss: 2.228136125431266

Epoch: 6| Step: 1
Training loss: 2.6747608184814453
Validation loss: 2.272702404247817

Epoch: 6| Step: 2
Training loss: 2.503126859664917
Validation loss: 2.267677535292923

Epoch: 6| Step: 3
Training loss: 2.00687313079834
Validation loss: 2.2573946829765075

Epoch: 6| Step: 4
Training loss: 2.558521032333374
Validation loss: 2.268227913046396

Epoch: 6| Step: 5
Training loss: 2.3568286895751953
Validation loss: 2.2574331555315243

Epoch: 6| Step: 6
Training loss: 2.264249324798584
Validation loss: 2.2382600974011164

Epoch: 6| Step: 7
Training loss: 1.9090943336486816
Validation loss: 2.22406933640921

Epoch: 6| Step: 8
Training loss: 2.451237201690674
Validation loss: 2.2150340746807795

Epoch: 6| Step: 9
Training loss: 2.772177219390869
Validation loss: 2.2081924817895375

Epoch: 6| Step: 10
Training loss: 2.4111461639404297
Validation loss: 2.2017977596611105

Epoch: 6| Step: 11
Training loss: 2.5829248428344727
Validation loss: 2.1947939729177826

Epoch: 6| Step: 12
Training loss: 2.9266719818115234
Validation loss: 2.1980341813897573

Epoch: 6| Step: 13
Training loss: 3.004507541656494
Validation loss: 2.20173744745152

Epoch: 54| Step: 0
Training loss: 2.1814475059509277
Validation loss: 2.2147845042649137

Epoch: 6| Step: 1
Training loss: 2.4629580974578857
Validation loss: 2.202042084868236

Epoch: 6| Step: 2
Training loss: 3.056288719177246
Validation loss: 2.211946000335037

Epoch: 6| Step: 3
Training loss: 2.6508116722106934
Validation loss: 2.2121519606600524

Epoch: 6| Step: 4
Training loss: 2.5735580921173096
Validation loss: 2.2092642681573027

Epoch: 6| Step: 5
Training loss: 2.714035749435425
Validation loss: 2.216684055584733

Epoch: 6| Step: 6
Training loss: 2.5301246643066406
Validation loss: 2.207135440200888

Epoch: 6| Step: 7
Training loss: 2.928318500518799
Validation loss: 2.1943764366129392

Epoch: 6| Step: 8
Training loss: 2.2105960845947266
Validation loss: 2.186930646178543

Epoch: 6| Step: 9
Training loss: 2.233436107635498
Validation loss: 2.189718673306127

Epoch: 6| Step: 10
Training loss: 2.1124818325042725
Validation loss: 2.187862347531062

Epoch: 6| Step: 11
Training loss: 2.3766727447509766
Validation loss: 2.1938448618817072

Epoch: 6| Step: 12
Training loss: 2.8187613487243652
Validation loss: 2.2026450044365338

Epoch: 6| Step: 13
Training loss: 1.472109317779541
Validation loss: 2.201758230886152

Epoch: 55| Step: 0
Training loss: 2.001638412475586
Validation loss: 2.196347500688286

Epoch: 6| Step: 1
Training loss: 2.4725587368011475
Validation loss: 2.2073634286080637

Epoch: 6| Step: 2
Training loss: 2.4549968242645264
Validation loss: 2.201180268359441

Epoch: 6| Step: 3
Training loss: 2.6205482482910156
Validation loss: 2.2070575016801075

Epoch: 6| Step: 4
Training loss: 2.3708136081695557
Validation loss: 2.2094754736910582

Epoch: 6| Step: 5
Training loss: 2.7047619819641113
Validation loss: 2.2199429991424724

Epoch: 6| Step: 6
Training loss: 2.5990755558013916
Validation loss: 2.1942644196171917

Epoch: 6| Step: 7
Training loss: 2.7013416290283203
Validation loss: 2.1811323806803715

Epoch: 6| Step: 8
Training loss: 2.137444019317627
Validation loss: 2.166861213663573

Epoch: 6| Step: 9
Training loss: 2.3243446350097656
Validation loss: 2.160229557303972

Epoch: 6| Step: 10
Training loss: 2.429291248321533
Validation loss: 2.1548130384055515

Epoch: 6| Step: 11
Training loss: 2.1908445358276367
Validation loss: 2.1479665310152116

Epoch: 6| Step: 12
Training loss: 3.063098430633545
Validation loss: 2.1506833043149722

Epoch: 6| Step: 13
Training loss: 3.1761627197265625
Validation loss: 2.149071631893035

Epoch: 56| Step: 0
Training loss: 2.7692480087280273
Validation loss: 2.148736943480789

Epoch: 6| Step: 1
Training loss: 2.313103675842285
Validation loss: 2.157855451747935

Epoch: 6| Step: 2
Training loss: 2.781238079071045
Validation loss: 2.174891002716557

Epoch: 6| Step: 3
Training loss: 2.115434408187866
Validation loss: 2.1932600493072183

Epoch: 6| Step: 4
Training loss: 2.8645057678222656
Validation loss: 2.2115643075717393

Epoch: 6| Step: 5
Training loss: 1.8457262516021729
Validation loss: 2.2202949626471407

Epoch: 6| Step: 6
Training loss: 2.2830638885498047
Validation loss: 2.207368302088912

Epoch: 6| Step: 7
Training loss: 2.3783998489379883
Validation loss: 2.1972079712857484

Epoch: 6| Step: 8
Training loss: 2.8628792762756348
Validation loss: 2.213070031135313

Epoch: 6| Step: 9
Training loss: 2.568272113800049
Validation loss: 2.215381540277953

Epoch: 6| Step: 10
Training loss: 2.5192975997924805
Validation loss: 2.223027451063997

Epoch: 6| Step: 11
Training loss: 2.9110777378082275
Validation loss: 2.211032190630513

Epoch: 6| Step: 12
Training loss: 2.478321075439453
Validation loss: 2.2123949399558445

Epoch: 6| Step: 13
Training loss: 1.9499855041503906
Validation loss: 2.230995633268869

Epoch: 57| Step: 0
Training loss: 2.6763644218444824
Validation loss: 2.226691686978904

Epoch: 6| Step: 1
Training loss: 1.982048749923706
Validation loss: 2.226119161933981

Epoch: 6| Step: 2
Training loss: 2.605790376663208
Validation loss: 2.21421246246625

Epoch: 6| Step: 3
Training loss: 2.9750518798828125
Validation loss: 2.214896886579452

Epoch: 6| Step: 4
Training loss: 2.1953883171081543
Validation loss: 2.2183940974614953

Epoch: 6| Step: 5
Training loss: 2.551638126373291
Validation loss: 2.232915868041336

Epoch: 6| Step: 6
Training loss: 2.6542625427246094
Validation loss: 2.2624982146806616

Epoch: 6| Step: 7
Training loss: 3.0845508575439453
Validation loss: 2.2655729196404897

Epoch: 6| Step: 8
Training loss: 2.7747058868408203
Validation loss: 2.239373778784147

Epoch: 6| Step: 9
Training loss: 1.9236767292022705
Validation loss: 2.2373067050851803

Epoch: 6| Step: 10
Training loss: 2.881847381591797
Validation loss: 2.2268538885219122

Epoch: 6| Step: 11
Training loss: 2.593656301498413
Validation loss: 2.224179756256842

Epoch: 6| Step: 12
Training loss: 1.9782090187072754
Validation loss: 2.2186824275601293

Epoch: 6| Step: 13
Training loss: 1.9477661848068237
Validation loss: 2.206066610992596

Epoch: 58| Step: 0
Training loss: 2.5147948265075684
Validation loss: 2.2004614901799027

Epoch: 6| Step: 1
Training loss: 2.065758228302002
Validation loss: 2.196475833974859

Epoch: 6| Step: 2
Training loss: 2.0490708351135254
Validation loss: 2.1981432360987507

Epoch: 6| Step: 3
Training loss: 2.1439385414123535
Validation loss: 2.193654280836864

Epoch: 6| Step: 4
Training loss: 3.0316386222839355
Validation loss: 2.1809022913696947

Epoch: 6| Step: 5
Training loss: 2.1997547149658203
Validation loss: 2.1851822919743036

Epoch: 6| Step: 6
Training loss: 2.943249225616455
Validation loss: 2.1797310985544676

Epoch: 6| Step: 7
Training loss: 2.3911542892456055
Validation loss: 2.178658985322522

Epoch: 6| Step: 8
Training loss: 1.9806206226348877
Validation loss: 2.1792161080145065

Epoch: 6| Step: 9
Training loss: 3.1145198345184326
Validation loss: 2.1848509696222123

Epoch: 6| Step: 10
Training loss: 3.0375168323516846
Validation loss: 2.2065952195916125

Epoch: 6| Step: 11
Training loss: 2.2317886352539062
Validation loss: 2.2108324240612727

Epoch: 6| Step: 12
Training loss: 2.288865566253662
Validation loss: 2.258527445536788

Epoch: 6| Step: 13
Training loss: 3.156580686569214
Validation loss: 2.2862240806702645

Epoch: 59| Step: 0
Training loss: 2.260948657989502
Validation loss: 2.3206668053903887

Epoch: 6| Step: 1
Training loss: 2.461336135864258
Validation loss: 2.2684804111398678

Epoch: 6| Step: 2
Training loss: 2.249866008758545
Validation loss: 2.2115937535480787

Epoch: 6| Step: 3
Training loss: 2.3280577659606934
Validation loss: 2.1723624121758247

Epoch: 6| Step: 4
Training loss: 1.9651825428009033
Validation loss: 2.1516145275485132

Epoch: 6| Step: 5
Training loss: 2.0729475021362305
Validation loss: 2.1579763530403056

Epoch: 6| Step: 6
Training loss: 2.8808774948120117
Validation loss: 2.1690712487825783

Epoch: 6| Step: 7
Training loss: 2.292447566986084
Validation loss: 2.170549863128252

Epoch: 6| Step: 8
Training loss: 2.8369827270507812
Validation loss: 2.1695442609889533

Epoch: 6| Step: 9
Training loss: 2.670663595199585
Validation loss: 2.1706129863697994

Epoch: 6| Step: 10
Training loss: 2.748514413833618
Validation loss: 2.1921396024765505

Epoch: 6| Step: 11
Training loss: 2.0710859298706055
Validation loss: 2.2020059118988695

Epoch: 6| Step: 12
Training loss: 2.9250917434692383
Validation loss: 2.1978677934215916

Epoch: 6| Step: 13
Training loss: 3.63956356048584
Validation loss: 2.176424326435212

Epoch: 60| Step: 0
Training loss: 3.170156478881836
Validation loss: 2.165203689247049

Epoch: 6| Step: 1
Training loss: 2.0594513416290283
Validation loss: 2.1451602520481234

Epoch: 6| Step: 2
Training loss: 3.3840432167053223
Validation loss: 2.1426580887968822

Epoch: 6| Step: 3
Training loss: 2.2621707916259766
Validation loss: 2.1422637854852984

Epoch: 6| Step: 4
Training loss: 2.9619572162628174
Validation loss: 2.134245002141563

Epoch: 6| Step: 5
Training loss: 2.563129425048828
Validation loss: 2.130258111543553

Epoch: 6| Step: 6
Training loss: 2.7019762992858887
Validation loss: 2.1300757264578216

Epoch: 6| Step: 7
Training loss: 2.654212474822998
Validation loss: 2.130928647133612

Epoch: 6| Step: 8
Training loss: 2.0352213382720947
Validation loss: 2.1313770945354173

Epoch: 6| Step: 9
Training loss: 1.7425875663757324
Validation loss: 2.1409220336585917

Epoch: 6| Step: 10
Training loss: 1.839526891708374
Validation loss: 2.163700721597159

Epoch: 6| Step: 11
Training loss: 2.727850914001465
Validation loss: 2.1893926897356586

Epoch: 6| Step: 12
Training loss: 2.194356918334961
Validation loss: 2.201864980882214

Epoch: 6| Step: 13
Training loss: 2.454207420349121
Validation loss: 2.2359947260989936

Epoch: 61| Step: 0
Training loss: 2.255059242248535
Validation loss: 2.2231239644430016

Epoch: 6| Step: 1
Training loss: 2.5977535247802734
Validation loss: 2.180265812463658

Epoch: 6| Step: 2
Training loss: 2.416313648223877
Validation loss: 2.1733484447643323

Epoch: 6| Step: 3
Training loss: 2.289029121398926
Validation loss: 2.156625629753195

Epoch: 6| Step: 4
Training loss: 2.445324420928955
Validation loss: 2.1490505280033236

Epoch: 6| Step: 5
Training loss: 2.333214521408081
Validation loss: 2.1552246488550657

Epoch: 6| Step: 6
Training loss: 2.8049278259277344
Validation loss: 2.1567062652239235

Epoch: 6| Step: 7
Training loss: 2.495194435119629
Validation loss: 2.153548261170746

Epoch: 6| Step: 8
Training loss: 2.4584062099456787
Validation loss: 2.1500260189015377

Epoch: 6| Step: 9
Training loss: 2.9502182006835938
Validation loss: 2.150277599211662

Epoch: 6| Step: 10
Training loss: 2.84441876411438
Validation loss: 2.1537878385154148

Epoch: 6| Step: 11
Training loss: 1.8285354375839233
Validation loss: 2.154376135077528

Epoch: 6| Step: 12
Training loss: 2.2035958766937256
Validation loss: 2.1670908620280604

Epoch: 6| Step: 13
Training loss: 2.5230932235717773
Validation loss: 2.172553321366669

Epoch: 62| Step: 0
Training loss: 2.548840284347534
Validation loss: 2.1622238697544223

Epoch: 6| Step: 1
Training loss: 2.4624104499816895
Validation loss: 2.163092629883879

Epoch: 6| Step: 2
Training loss: 2.5973615646362305
Validation loss: 2.141932410578574

Epoch: 6| Step: 3
Training loss: 2.3782262802124023
Validation loss: 2.1501582566127984

Epoch: 6| Step: 4
Training loss: 2.517518997192383
Validation loss: 2.1454639562996487

Epoch: 6| Step: 5
Training loss: 2.45719838142395
Validation loss: 2.1448676150332213

Epoch: 6| Step: 6
Training loss: 2.886605739593506
Validation loss: 2.1554095193903935

Epoch: 6| Step: 7
Training loss: 3.2203776836395264
Validation loss: 2.155498189310874

Epoch: 6| Step: 8
Training loss: 2.389357328414917
Validation loss: 2.148803132836537

Epoch: 6| Step: 9
Training loss: 1.4909077882766724
Validation loss: 2.147328028114893

Epoch: 6| Step: 10
Training loss: 3.116190195083618
Validation loss: 2.1427626994348343

Epoch: 6| Step: 11
Training loss: 1.7222638130187988
Validation loss: 2.126856052747337

Epoch: 6| Step: 12
Training loss: 2.4112510681152344
Validation loss: 2.137573920270448

Epoch: 6| Step: 13
Training loss: 2.1757779121398926
Validation loss: 2.143706497325692

Epoch: 63| Step: 0
Training loss: 2.2358412742614746
Validation loss: 2.1630589603095927

Epoch: 6| Step: 1
Training loss: 3.0975441932678223
Validation loss: 2.174023940999021

Epoch: 6| Step: 2
Training loss: 2.5551578998565674
Validation loss: 2.168274202654439

Epoch: 6| Step: 3
Training loss: 2.5600743293762207
Validation loss: 2.1551618217140116

Epoch: 6| Step: 4
Training loss: 2.294295310974121
Validation loss: 2.151829345251924

Epoch: 6| Step: 5
Training loss: 2.3495163917541504
Validation loss: 2.132419770763766

Epoch: 6| Step: 6
Training loss: 1.8247512578964233
Validation loss: 2.1326024942500617

Epoch: 6| Step: 7
Training loss: 2.404578924179077
Validation loss: 2.119409150974725

Epoch: 6| Step: 8
Training loss: 2.3627119064331055
Validation loss: 2.120323304207094

Epoch: 6| Step: 9
Training loss: 2.202606201171875
Validation loss: 2.128459184400497

Epoch: 6| Step: 10
Training loss: 2.268056869506836
Validation loss: 2.135513039045436

Epoch: 6| Step: 11
Training loss: 2.9897146224975586
Validation loss: 2.1583010381267917

Epoch: 6| Step: 12
Training loss: 2.6420400142669678
Validation loss: 2.1598308086395264

Epoch: 6| Step: 13
Training loss: 2.6597506999969482
Validation loss: 2.1718455501781997

Epoch: 64| Step: 0
Training loss: 2.249859094619751
Validation loss: 2.160622590331621

Epoch: 6| Step: 1
Training loss: 2.5968403816223145
Validation loss: 2.1337307037845736

Epoch: 6| Step: 2
Training loss: 2.4509425163269043
Validation loss: 2.1251645600923927

Epoch: 6| Step: 3
Training loss: 2.4222252368927
Validation loss: 2.108908127712947

Epoch: 6| Step: 4
Training loss: 2.7175452709198
Validation loss: 2.1069550386039158

Epoch: 6| Step: 5
Training loss: 2.695878505706787
Validation loss: 2.1046358231575257

Epoch: 6| Step: 6
Training loss: 2.3537330627441406
Validation loss: 2.1103165662416847

Epoch: 6| Step: 7
Training loss: 2.135254383087158
Validation loss: 2.1137056786526918

Epoch: 6| Step: 8
Training loss: 2.4478352069854736
Validation loss: 2.1346990331526725

Epoch: 6| Step: 9
Training loss: 2.3068270683288574
Validation loss: 2.1641259065238376

Epoch: 6| Step: 10
Training loss: 2.4456233978271484
Validation loss: 2.197952788363221

Epoch: 6| Step: 11
Training loss: 2.763026237487793
Validation loss: 2.2485733288590626

Epoch: 6| Step: 12
Training loss: 2.8358278274536133
Validation loss: 2.2241950650368967

Epoch: 6| Step: 13
Training loss: 2.0937066078186035
Validation loss: 2.1674481822598364

Epoch: 65| Step: 0
Training loss: 2.6356863975524902
Validation loss: 2.1425708237514702

Epoch: 6| Step: 1
Training loss: 2.565232038497925
Validation loss: 2.1366605835576213

Epoch: 6| Step: 2
Training loss: 2.131680488586426
Validation loss: 2.1289027262759466

Epoch: 6| Step: 3
Training loss: 2.499706745147705
Validation loss: 2.1235059640740834

Epoch: 6| Step: 4
Training loss: 2.718714952468872
Validation loss: 2.1276573058097594

Epoch: 6| Step: 5
Training loss: 2.916649103164673
Validation loss: 2.1404365262677594

Epoch: 6| Step: 6
Training loss: 2.2267751693725586
Validation loss: 2.158102212413665

Epoch: 6| Step: 7
Training loss: 1.5778032541275024
Validation loss: 2.1535596309169645

Epoch: 6| Step: 8
Training loss: 2.562854290008545
Validation loss: 2.1409434990216325

Epoch: 6| Step: 9
Training loss: 2.0163886547088623
Validation loss: 2.1196502357400875

Epoch: 6| Step: 10
Training loss: 3.0980019569396973
Validation loss: 2.135101731105517

Epoch: 6| Step: 11
Training loss: 2.672729253768921
Validation loss: 2.126795235500541

Epoch: 6| Step: 12
Training loss: 2.2395992279052734
Validation loss: 2.1304523175762546

Epoch: 6| Step: 13
Training loss: 2.263704538345337
Validation loss: 2.137090988056634

Epoch: 66| Step: 0
Training loss: 2.3710596561431885
Validation loss: 2.1155369204859578

Epoch: 6| Step: 1
Training loss: 2.725738048553467
Validation loss: 2.122293626108477

Epoch: 6| Step: 2
Training loss: 2.721947431564331
Validation loss: 2.1327254221003544

Epoch: 6| Step: 3
Training loss: 2.5612905025482178
Validation loss: 2.1408724707941853

Epoch: 6| Step: 4
Training loss: 2.2745046615600586
Validation loss: 2.117974747893631

Epoch: 6| Step: 5
Training loss: 1.53848397731781
Validation loss: 2.116190751393636

Epoch: 6| Step: 6
Training loss: 3.0279412269592285
Validation loss: 2.1133404060076644

Epoch: 6| Step: 7
Training loss: 2.2144711017608643
Validation loss: 2.1144883299386628

Epoch: 6| Step: 8
Training loss: 2.470710277557373
Validation loss: 2.122769909520303

Epoch: 6| Step: 9
Training loss: 2.3353805541992188
Validation loss: 2.1360184697694677

Epoch: 6| Step: 10
Training loss: 2.946704864501953
Validation loss: 2.142604012643137

Epoch: 6| Step: 11
Training loss: 2.1323766708374023
Validation loss: 2.128787120183309

Epoch: 6| Step: 12
Training loss: 2.3651156425476074
Validation loss: 2.1262798155507734

Epoch: 6| Step: 13
Training loss: 2.2682371139526367
Validation loss: 2.1313145032493015

Epoch: 67| Step: 0
Training loss: 2.319324254989624
Validation loss: 2.151016325078985

Epoch: 6| Step: 1
Training loss: 2.2025368213653564
Validation loss: 2.173225636123329

Epoch: 6| Step: 2
Training loss: 2.554173231124878
Validation loss: 2.18881485795462

Epoch: 6| Step: 3
Training loss: 2.956746816635132
Validation loss: 2.2002191876852386

Epoch: 6| Step: 4
Training loss: 2.3454484939575195
Validation loss: 2.2069812564439673

Epoch: 6| Step: 5
Training loss: 2.4116837978363037
Validation loss: 2.1743892315895326

Epoch: 6| Step: 6
Training loss: 2.0808591842651367
Validation loss: 2.1499201315705494

Epoch: 6| Step: 7
Training loss: 2.042783260345459
Validation loss: 2.12091487966558

Epoch: 6| Step: 8
Training loss: 3.000622272491455
Validation loss: 2.102749532268893

Epoch: 6| Step: 9
Training loss: 2.5501456260681152
Validation loss: 2.1023386370751167

Epoch: 6| Step: 10
Training loss: 2.2342004776000977
Validation loss: 2.0905197653719174

Epoch: 6| Step: 11
Training loss: 2.1120400428771973
Validation loss: 2.088980943925919

Epoch: 6| Step: 12
Training loss: 2.5066113471984863
Validation loss: 2.0901990552102365

Epoch: 6| Step: 13
Training loss: 3.3599350452423096
Validation loss: 2.0891073724274993

Epoch: 68| Step: 0
Training loss: 2.291261911392212
Validation loss: 2.096881115308372

Epoch: 6| Step: 1
Training loss: 2.1910769939422607
Validation loss: 2.105457475108485

Epoch: 6| Step: 2
Training loss: 2.5456719398498535
Validation loss: 2.1110134599029378

Epoch: 6| Step: 3
Training loss: 2.2815380096435547
Validation loss: 2.127498133208162

Epoch: 6| Step: 4
Training loss: 2.9440815448760986
Validation loss: 2.1421214483117543

Epoch: 6| Step: 5
Training loss: 2.274418592453003
Validation loss: 2.1361311456208587

Epoch: 6| Step: 6
Training loss: 3.0932881832122803
Validation loss: 2.1190953357245332

Epoch: 6| Step: 7
Training loss: 2.3911170959472656
Validation loss: 2.114846860208819

Epoch: 6| Step: 8
Training loss: 2.74819278717041
Validation loss: 2.1150007158197384

Epoch: 6| Step: 9
Training loss: 2.3920764923095703
Validation loss: 2.103719542103429

Epoch: 6| Step: 10
Training loss: 2.2892704010009766
Validation loss: 2.112751894099738

Epoch: 6| Step: 11
Training loss: 1.851745367050171
Validation loss: 2.1323390699202016

Epoch: 6| Step: 12
Training loss: 2.5662524700164795
Validation loss: 2.130842213989586

Epoch: 6| Step: 13
Training loss: 2.298187494277954
Validation loss: 2.1130710301860685

Epoch: 69| Step: 0
Training loss: 2.315134286880493
Validation loss: 2.116930607826479

Epoch: 6| Step: 1
Training loss: 2.4522268772125244
Validation loss: 2.1136360014638593

Epoch: 6| Step: 2
Training loss: 2.1866517066955566
Validation loss: 2.1186536409521617

Epoch: 6| Step: 3
Training loss: 2.9897255897521973
Validation loss: 2.116596216796547

Epoch: 6| Step: 4
Training loss: 2.1303021907806396
Validation loss: 2.117651681746206

Epoch: 6| Step: 5
Training loss: 2.240471839904785
Validation loss: 2.125681056771227

Epoch: 6| Step: 6
Training loss: 2.6643691062927246
Validation loss: 2.144720954279746

Epoch: 6| Step: 7
Training loss: 2.7722668647766113
Validation loss: 2.175587546440863

Epoch: 6| Step: 8
Training loss: 2.249488353729248
Validation loss: 2.2019368858747583

Epoch: 6| Step: 9
Training loss: 1.8332302570343018
Validation loss: 2.211901330178784

Epoch: 6| Step: 10
Training loss: 2.8102099895477295
Validation loss: 2.2190406501934095

Epoch: 6| Step: 11
Training loss: 2.8293962478637695
Validation loss: 2.197667148805434

Epoch: 6| Step: 12
Training loss: 2.4366047382354736
Validation loss: 2.1867325562302784

Epoch: 6| Step: 13
Training loss: 2.069504737854004
Validation loss: 2.1562564167925107

Epoch: 70| Step: 0
Training loss: 2.3544273376464844
Validation loss: 2.1235899771413496

Epoch: 6| Step: 1
Training loss: 2.7603073120117188
Validation loss: 2.09795198645643

Epoch: 6| Step: 2
Training loss: 2.864020586013794
Validation loss: 2.0977017674394833

Epoch: 6| Step: 3
Training loss: 2.710956573486328
Validation loss: 2.0893102615110335

Epoch: 6| Step: 4
Training loss: 2.492762804031372
Validation loss: 2.092926090763461

Epoch: 6| Step: 5
Training loss: 2.295689105987549
Validation loss: 2.09162611474273

Epoch: 6| Step: 6
Training loss: 2.718574047088623
Validation loss: 2.0873206123228996

Epoch: 6| Step: 7
Training loss: 2.5040225982666016
Validation loss: 2.0907764486087266

Epoch: 6| Step: 8
Training loss: 2.331221580505371
Validation loss: 2.09578868650621

Epoch: 6| Step: 9
Training loss: 2.402214527130127
Validation loss: 2.0902694527820875

Epoch: 6| Step: 10
Training loss: 2.246384859085083
Validation loss: 2.089061744751469

Epoch: 6| Step: 11
Training loss: 1.958585500717163
Validation loss: 2.0886767859100015

Epoch: 6| Step: 12
Training loss: 2.133002281188965
Validation loss: 2.090299262795397

Epoch: 6| Step: 13
Training loss: 2.4421069622039795
Validation loss: 2.124518540597731

Epoch: 71| Step: 0
Training loss: 3.367279291152954
Validation loss: 2.1464961036559074

Epoch: 6| Step: 1
Training loss: 1.9596898555755615
Validation loss: 2.17093922245887

Epoch: 6| Step: 2
Training loss: 2.232736110687256
Validation loss: 2.1796681547677643

Epoch: 6| Step: 3
Training loss: 2.144277572631836
Validation loss: 2.184439374554542

Epoch: 6| Step: 4
Training loss: 2.0631370544433594
Validation loss: 2.1634603572148148

Epoch: 6| Step: 5
Training loss: 2.431396007537842
Validation loss: 2.1269231393773067

Epoch: 6| Step: 6
Training loss: 2.6558618545532227
Validation loss: 2.110922013559649

Epoch: 6| Step: 7
Training loss: 2.5507593154907227
Validation loss: 2.0881994091054445

Epoch: 6| Step: 8
Training loss: 2.3741345405578613
Validation loss: 2.0655042304787585

Epoch: 6| Step: 9
Training loss: 2.054899215698242
Validation loss: 2.0623048684930287

Epoch: 6| Step: 10
Training loss: 2.6034250259399414
Validation loss: 2.0661686210222143

Epoch: 6| Step: 11
Training loss: 2.8743302822113037
Validation loss: 2.0676471187222387

Epoch: 6| Step: 12
Training loss: 2.611377716064453
Validation loss: 2.0680563193495556

Epoch: 6| Step: 13
Training loss: 1.8365364074707031
Validation loss: 2.0732019908966555

Epoch: 72| Step: 0
Training loss: 2.131559371948242
Validation loss: 2.077354311943054

Epoch: 6| Step: 1
Training loss: 3.3466148376464844
Validation loss: 2.0862038545711066

Epoch: 6| Step: 2
Training loss: 2.105839729309082
Validation loss: 2.088730127580704

Epoch: 6| Step: 3
Training loss: 2.4219558238983154
Validation loss: 2.1015597056317072

Epoch: 6| Step: 4
Training loss: 2.2137198448181152
Validation loss: 2.115881949342707

Epoch: 6| Step: 5
Training loss: 1.7719335556030273
Validation loss: 2.109412408644153

Epoch: 6| Step: 6
Training loss: 1.6109323501586914
Validation loss: 2.1118004488688644

Epoch: 6| Step: 7
Training loss: 2.0946590900421143
Validation loss: 2.1081231999140915

Epoch: 6| Step: 8
Training loss: 2.8777308464050293
Validation loss: 2.1095547599177205

Epoch: 6| Step: 9
Training loss: 2.818824291229248
Validation loss: 2.099110852005661

Epoch: 6| Step: 10
Training loss: 3.0810091495513916
Validation loss: 2.1068586790433494

Epoch: 6| Step: 11
Training loss: 2.7138919830322266
Validation loss: 2.1094274367055585

Epoch: 6| Step: 12
Training loss: 1.9388498067855835
Validation loss: 2.1237511763008694

Epoch: 6| Step: 13
Training loss: 2.7098066806793213
Validation loss: 2.127062374545682

Epoch: 73| Step: 0
Training loss: 1.4149283170700073
Validation loss: 2.158480854444606

Epoch: 6| Step: 1
Training loss: 2.563859224319458
Validation loss: 2.1963258148521505

Epoch: 6| Step: 2
Training loss: 3.1458096504211426
Validation loss: 2.2352663573398384

Epoch: 6| Step: 3
Training loss: 2.890364170074463
Validation loss: 2.2469247425756147

Epoch: 6| Step: 4
Training loss: 2.5691139698028564
Validation loss: 2.2714260444846204

Epoch: 6| Step: 5
Training loss: 2.084791898727417
Validation loss: 2.266824424907725

Epoch: 6| Step: 6
Training loss: 2.4662222862243652
Validation loss: 2.2472308117856263

Epoch: 6| Step: 7
Training loss: 2.2969865798950195
Validation loss: 2.2244148677395237

Epoch: 6| Step: 8
Training loss: 3.1525325775146484
Validation loss: 2.222222625568349

Epoch: 6| Step: 9
Training loss: 2.2775087356567383
Validation loss: 2.1899802761693157

Epoch: 6| Step: 10
Training loss: 2.883279800415039
Validation loss: 2.1586554204263995

Epoch: 6| Step: 11
Training loss: 2.4938254356384277
Validation loss: 2.127046710701399

Epoch: 6| Step: 12
Training loss: 2.0937676429748535
Validation loss: 2.1072307248269357

Epoch: 6| Step: 13
Training loss: 1.2349311113357544
Validation loss: 2.090088027779774

Epoch: 74| Step: 0
Training loss: 2.067680835723877
Validation loss: 2.0744260818727556

Epoch: 6| Step: 1
Training loss: 2.288788318634033
Validation loss: 2.0705181783245457

Epoch: 6| Step: 2
Training loss: 2.7640743255615234
Validation loss: 2.0819758035803355

Epoch: 6| Step: 3
Training loss: 2.3640968799591064
Validation loss: 2.089161999763981

Epoch: 6| Step: 4
Training loss: 1.736894130706787
Validation loss: 2.081522890316543

Epoch: 6| Step: 5
Training loss: 2.358941078186035
Validation loss: 2.083082437515259

Epoch: 6| Step: 6
Training loss: 2.5977706909179688
Validation loss: 2.0998057755090858

Epoch: 6| Step: 7
Training loss: 2.7120766639709473
Validation loss: 2.1016648866797007

Epoch: 6| Step: 8
Training loss: 2.7286458015441895
Validation loss: 2.100847598045103

Epoch: 6| Step: 9
Training loss: 2.4596681594848633
Validation loss: 2.1136833852337253

Epoch: 6| Step: 10
Training loss: 2.3401622772216797
Validation loss: 2.1067604800706268

Epoch: 6| Step: 11
Training loss: 2.516700029373169
Validation loss: 2.112638804220384

Epoch: 6| Step: 12
Training loss: 2.70399808883667
Validation loss: 2.108863825439125

Epoch: 6| Step: 13
Training loss: 1.7965314388275146
Validation loss: 2.132563042384322

Epoch: 75| Step: 0
Training loss: 1.968003273010254
Validation loss: 2.1604693371762513

Epoch: 6| Step: 1
Training loss: 3.0562524795532227
Validation loss: 2.173324059414607

Epoch: 6| Step: 2
Training loss: 1.6297119855880737
Validation loss: 2.1846753910023677

Epoch: 6| Step: 3
Training loss: 2.7562456130981445
Validation loss: 2.197083785969724

Epoch: 6| Step: 4
Training loss: 2.47857928276062
Validation loss: 2.196701552278252

Epoch: 6| Step: 5
Training loss: 2.2827765941619873
Validation loss: 2.1629243832762524

Epoch: 6| Step: 6
Training loss: 2.601050615310669
Validation loss: 2.1131925928977227

Epoch: 6| Step: 7
Training loss: 2.74908447265625
Validation loss: 2.0968089206244356

Epoch: 6| Step: 8
Training loss: 2.267331123352051
Validation loss: 2.076391637966197

Epoch: 6| Step: 9
Training loss: 3.012906551361084
Validation loss: 2.0683059141200077

Epoch: 6| Step: 10
Training loss: 2.0678043365478516
Validation loss: 2.0659836940867926

Epoch: 6| Step: 11
Training loss: 2.458367347717285
Validation loss: 2.0712933412162204

Epoch: 6| Step: 12
Training loss: 2.3786191940307617
Validation loss: 2.0687383246678177

Epoch: 6| Step: 13
Training loss: 2.632293224334717
Validation loss: 2.065678793896911

Epoch: 76| Step: 0
Training loss: 2.258525848388672
Validation loss: 2.059990411163658

Epoch: 6| Step: 1
Training loss: 2.2208876609802246
Validation loss: 2.0625265221441946

Epoch: 6| Step: 2
Training loss: 2.9109737873077393
Validation loss: 2.0639698966856925

Epoch: 6| Step: 3
Training loss: 1.853272795677185
Validation loss: 2.077201102369575

Epoch: 6| Step: 4
Training loss: 2.262300968170166
Validation loss: 2.0852511313653763

Epoch: 6| Step: 5
Training loss: 2.755023956298828
Validation loss: 2.0940026416573474

Epoch: 6| Step: 6
Training loss: 2.7021467685699463
Validation loss: 2.1035322835368495

Epoch: 6| Step: 7
Training loss: 2.5611791610717773
Validation loss: 2.093637107520975

Epoch: 6| Step: 8
Training loss: 2.097571849822998
Validation loss: 2.0994505561808103

Epoch: 6| Step: 9
Training loss: 2.104556083679199
Validation loss: 2.088330145805113

Epoch: 6| Step: 10
Training loss: 2.2549962997436523
Validation loss: 2.0794087020299767

Epoch: 6| Step: 11
Training loss: 1.9565659761428833
Validation loss: 2.0682650881428875

Epoch: 6| Step: 12
Training loss: 3.0243399143218994
Validation loss: 2.0676079104023595

Epoch: 6| Step: 13
Training loss: 3.0162930488586426
Validation loss: 2.0680853371979087

Epoch: 77| Step: 0
Training loss: 2.2885046005249023
Validation loss: 2.061789139624565

Epoch: 6| Step: 1
Training loss: 2.0405144691467285
Validation loss: 2.0669026656817366

Epoch: 6| Step: 2
Training loss: 1.5916178226470947
Validation loss: 2.06405448144482

Epoch: 6| Step: 3
Training loss: 2.548168897628784
Validation loss: 2.0790474312279814

Epoch: 6| Step: 4
Training loss: 2.1679787635803223
Validation loss: 2.087511882987074

Epoch: 6| Step: 5
Training loss: 2.857081651687622
Validation loss: 2.105918074166903

Epoch: 6| Step: 6
Training loss: 2.2543606758117676
Validation loss: 2.1217297430961364

Epoch: 6| Step: 7
Training loss: 2.1203432083129883
Validation loss: 2.146320401981313

Epoch: 6| Step: 8
Training loss: 2.4192306995391846
Validation loss: 2.181439774010771

Epoch: 6| Step: 9
Training loss: 2.686016082763672
Validation loss: 2.196211279079478

Epoch: 6| Step: 10
Training loss: 2.599343776702881
Validation loss: 2.154456474447763

Epoch: 6| Step: 11
Training loss: 2.982160806655884
Validation loss: 2.1206754176847395

Epoch: 6| Step: 12
Training loss: 2.2230756282806396
Validation loss: 2.083212765314246

Epoch: 6| Step: 13
Training loss: 2.7182366847991943
Validation loss: 2.073656669227026

Epoch: 78| Step: 0
Training loss: 2.0370826721191406
Validation loss: 2.05842468302737

Epoch: 6| Step: 1
Training loss: 2.424931526184082
Validation loss: 2.0360465254834903

Epoch: 6| Step: 2
Training loss: 2.265913486480713
Validation loss: 2.0317318401029034

Epoch: 6| Step: 3
Training loss: 1.7173470258712769
Validation loss: 2.0268800233000066

Epoch: 6| Step: 4
Training loss: 2.549877643585205
Validation loss: 2.0289420825178905

Epoch: 6| Step: 5
Training loss: 2.668370008468628
Validation loss: 2.0271556736320577

Epoch: 6| Step: 6
Training loss: 2.558882474899292
Validation loss: 2.0360014259174304

Epoch: 6| Step: 7
Training loss: 2.3159403800964355
Validation loss: 2.032992421939809

Epoch: 6| Step: 8
Training loss: 2.5068180561065674
Validation loss: 2.044040222321787

Epoch: 6| Step: 9
Training loss: 1.587809681892395
Validation loss: 2.0549097702067387

Epoch: 6| Step: 10
Training loss: 2.776365041732788
Validation loss: 2.070779385105256

Epoch: 6| Step: 11
Training loss: 2.47515869140625
Validation loss: 2.076771710508613

Epoch: 6| Step: 12
Training loss: 2.799137592315674
Validation loss: 2.0743702047614643

Epoch: 6| Step: 13
Training loss: 2.979666233062744
Validation loss: 2.0863277117411294

Epoch: 79| Step: 0
Training loss: 1.9803249835968018
Validation loss: 2.0780070981671734

Epoch: 6| Step: 1
Training loss: 2.728598117828369
Validation loss: 2.082170478759273

Epoch: 6| Step: 2
Training loss: 2.0112781524658203
Validation loss: 2.0733150743669078

Epoch: 6| Step: 3
Training loss: 1.9849035739898682
Validation loss: 2.0900109865332164

Epoch: 6| Step: 4
Training loss: 2.609466075897217
Validation loss: 2.1004007529186945

Epoch: 6| Step: 5
Training loss: 2.4684994220733643
Validation loss: 2.100950902508151

Epoch: 6| Step: 6
Training loss: 2.2616770267486572
Validation loss: 2.0900962378389094

Epoch: 6| Step: 7
Training loss: 2.496037244796753
Validation loss: 2.07724440738719

Epoch: 6| Step: 8
Training loss: 2.049079418182373
Validation loss: 2.057739919231784

Epoch: 6| Step: 9
Training loss: 2.2064709663391113
Validation loss: 2.049313449090527

Epoch: 6| Step: 10
Training loss: 2.5061874389648438
Validation loss: 2.038727334750596

Epoch: 6| Step: 11
Training loss: 2.3346240520477295
Validation loss: 2.041035641906082

Epoch: 6| Step: 12
Training loss: 2.8910136222839355
Validation loss: 2.037184158960978

Epoch: 6| Step: 13
Training loss: 2.807607889175415
Validation loss: 2.03127396234902

Epoch: 80| Step: 0
Training loss: 1.6737921237945557
Validation loss: 2.038129475808913

Epoch: 6| Step: 1
Training loss: 1.9711341857910156
Validation loss: 2.024359631282027

Epoch: 6| Step: 2
Training loss: 2.251244068145752
Validation loss: 2.0225969578630183

Epoch: 6| Step: 3
Training loss: 2.6657657623291016
Validation loss: 2.029748624370944

Epoch: 6| Step: 4
Training loss: 2.8607847690582275
Validation loss: 2.0257359371390393

Epoch: 6| Step: 5
Training loss: 2.2716495990753174
Validation loss: 2.0351427908866637

Epoch: 6| Step: 6
Training loss: 2.901625394821167
Validation loss: 2.0257839336190173

Epoch: 6| Step: 7
Training loss: 1.6805250644683838
Validation loss: 2.026081597933205

Epoch: 6| Step: 8
Training loss: 3.269495964050293
Validation loss: 2.0114983717600503

Epoch: 6| Step: 9
Training loss: 2.7360739707946777
Validation loss: 2.0215833289648897

Epoch: 6| Step: 10
Training loss: 2.208500862121582
Validation loss: 2.026721869745562

Epoch: 6| Step: 11
Training loss: 2.056781530380249
Validation loss: 2.0433497915985765

Epoch: 6| Step: 12
Training loss: 2.086094617843628
Validation loss: 2.0422004602288686

Epoch: 6| Step: 13
Training loss: 2.351813316345215
Validation loss: 2.05585301819668

Epoch: 81| Step: 0
Training loss: 3.113459587097168
Validation loss: 2.065058256990166

Epoch: 6| Step: 1
Training loss: 2.5527162551879883
Validation loss: 2.0590729251984627

Epoch: 6| Step: 2
Training loss: 2.176816940307617
Validation loss: 2.0469061123427523

Epoch: 6| Step: 3
Training loss: 1.8904972076416016
Validation loss: 2.0444094237460884

Epoch: 6| Step: 4
Training loss: 2.5057613849639893
Validation loss: 2.0350230765599076

Epoch: 6| Step: 5
Training loss: 1.8041834831237793
Validation loss: 2.0375534321672175

Epoch: 6| Step: 6
Training loss: 2.285524606704712
Validation loss: 2.0292928065023115

Epoch: 6| Step: 7
Training loss: 2.1480977535247803
Validation loss: 2.04490924906987

Epoch: 6| Step: 8
Training loss: 2.1611645221710205
Validation loss: 2.056972442134734

Epoch: 6| Step: 9
Training loss: 2.3033013343811035
Validation loss: 2.0787484568934285

Epoch: 6| Step: 10
Training loss: 1.5556762218475342
Validation loss: 2.1051531478922856

Epoch: 6| Step: 11
Training loss: 2.63519549369812
Validation loss: 2.1152523076662453

Epoch: 6| Step: 12
Training loss: 2.668933391571045
Validation loss: 2.1216468349579842

Epoch: 6| Step: 13
Training loss: 3.7258338928222656
Validation loss: 2.1173977057139077

Epoch: 82| Step: 0
Training loss: 1.9586608409881592
Validation loss: 2.1140820749344362

Epoch: 6| Step: 1
Training loss: 2.3031258583068848
Validation loss: 2.1053957067510134

Epoch: 6| Step: 2
Training loss: 2.3563528060913086
Validation loss: 2.0894951589645876

Epoch: 6| Step: 3
Training loss: 2.362266778945923
Validation loss: 2.0720618309513217

Epoch: 6| Step: 4
Training loss: 1.6009020805358887
Validation loss: 2.0566697646212835

Epoch: 6| Step: 5
Training loss: 2.7294697761535645
Validation loss: 2.0328096625625447

Epoch: 6| Step: 6
Training loss: 2.264394760131836
Validation loss: 2.037527914970152

Epoch: 6| Step: 7
Training loss: 2.314284086227417
Validation loss: 2.038896563232586

Epoch: 6| Step: 8
Training loss: 3.4437994956970215
Validation loss: 2.035327024357293

Epoch: 6| Step: 9
Training loss: 2.219297409057617
Validation loss: 2.0252407289320424

Epoch: 6| Step: 10
Training loss: 1.987484097480774
Validation loss: 2.023746564824094

Epoch: 6| Step: 11
Training loss: 2.8335862159729004
Validation loss: 2.0266472293484594

Epoch: 6| Step: 12
Training loss: 1.8906810283660889
Validation loss: 2.016762800114129

Epoch: 6| Step: 13
Training loss: 2.5741751194000244
Validation loss: 2.0164432807635237

Epoch: 83| Step: 0
Training loss: 2.540820598602295
Validation loss: 2.0252714644196215

Epoch: 6| Step: 1
Training loss: 2.6711738109588623
Validation loss: 2.0234757854092504

Epoch: 6| Step: 2
Training loss: 1.9486498832702637
Validation loss: 2.032160207789431

Epoch: 6| Step: 3
Training loss: 2.487771511077881
Validation loss: 2.0317511635441936

Epoch: 6| Step: 4
Training loss: 2.660637855529785
Validation loss: 2.0274839029517224

Epoch: 6| Step: 5
Training loss: 1.6555898189544678
Validation loss: 2.0225110336016585

Epoch: 6| Step: 6
Training loss: 2.074979782104492
Validation loss: 2.0286994313681

Epoch: 6| Step: 7
Training loss: 2.5951833724975586
Validation loss: 2.0395092374535015

Epoch: 6| Step: 8
Training loss: 1.553307056427002
Validation loss: 2.063504768956092

Epoch: 6| Step: 9
Training loss: 2.5130560398101807
Validation loss: 2.111393306844978

Epoch: 6| Step: 10
Training loss: 2.4975335597991943
Validation loss: 2.1164613000808226

Epoch: 6| Step: 11
Training loss: 1.9375145435333252
Validation loss: 2.1095466895770003

Epoch: 6| Step: 12
Training loss: 3.058475971221924
Validation loss: 2.09704686749366

Epoch: 6| Step: 13
Training loss: 2.9808404445648193
Validation loss: 2.072517277092062

Epoch: 84| Step: 0
Training loss: 2.054494619369507
Validation loss: 2.046078546072847

Epoch: 6| Step: 1
Training loss: 2.1392459869384766
Validation loss: 2.029619131036984

Epoch: 6| Step: 2
Training loss: 2.7738189697265625
Validation loss: 2.037031691561463

Epoch: 6| Step: 3
Training loss: 3.0947813987731934
Validation loss: 2.0389915781636394

Epoch: 6| Step: 4
Training loss: 1.9160706996917725
Validation loss: 2.0400607637179795

Epoch: 6| Step: 5
Training loss: 2.8585457801818848
Validation loss: 2.0393065098793275

Epoch: 6| Step: 6
Training loss: 1.9236043691635132
Validation loss: 2.060238238303892

Epoch: 6| Step: 7
Training loss: 2.7998783588409424
Validation loss: 2.0827698861399004

Epoch: 6| Step: 8
Training loss: 2.3487319946289062
Validation loss: 2.0664452275922223

Epoch: 6| Step: 9
Training loss: 2.5628206729888916
Validation loss: 2.0384315136940248

Epoch: 6| Step: 10
Training loss: 2.020381212234497
Validation loss: 2.0440318610078547

Epoch: 6| Step: 11
Training loss: 1.842494249343872
Validation loss: 2.0432686318633375

Epoch: 6| Step: 12
Training loss: 2.6741065979003906
Validation loss: 2.059638564304639

Epoch: 6| Step: 13
Training loss: 1.8975342512130737
Validation loss: 2.120084460063647

Epoch: 85| Step: 0
Training loss: 1.8278546333312988
Validation loss: 2.1315304925364833

Epoch: 6| Step: 1
Training loss: 2.393848419189453
Validation loss: 2.13717157225455

Epoch: 6| Step: 2
Training loss: 2.174677610397339
Validation loss: 2.118542286657518

Epoch: 6| Step: 3
Training loss: 2.2083966732025146
Validation loss: 2.1060043842561784

Epoch: 6| Step: 4
Training loss: 2.6603379249572754
Validation loss: 2.082979545798353

Epoch: 6| Step: 5
Training loss: 2.052772045135498
Validation loss: 2.080709357415476

Epoch: 6| Step: 6
Training loss: 1.9973342418670654
Validation loss: 2.061206304898826

Epoch: 6| Step: 7
Training loss: 2.1450774669647217
Validation loss: 2.046870546956216

Epoch: 6| Step: 8
Training loss: 2.4549944400787354
Validation loss: 2.0624450906630485

Epoch: 6| Step: 9
Training loss: 2.208930492401123
Validation loss: 2.0558504878833728

Epoch: 6| Step: 10
Training loss: 2.3305163383483887
Validation loss: 2.036303448420699

Epoch: 6| Step: 11
Training loss: 2.6143932342529297
Validation loss: 2.037090838596385

Epoch: 6| Step: 12
Training loss: 3.2202911376953125
Validation loss: 2.022361550279843

Epoch: 6| Step: 13
Training loss: 2.3469135761260986
Validation loss: 2.025295876687573

Epoch: 86| Step: 0
Training loss: 2.605242967605591
Validation loss: 2.018235973132554

Epoch: 6| Step: 1
Training loss: 2.2554502487182617
Validation loss: 2.0250670243335027

Epoch: 6| Step: 2
Training loss: 2.7222561836242676
Validation loss: 2.0174626432439333

Epoch: 6| Step: 3
Training loss: 2.4741580486297607
Validation loss: 2.0181158140141475

Epoch: 6| Step: 4
Training loss: 2.0213770866394043
Validation loss: 2.0184440971702657

Epoch: 6| Step: 5
Training loss: 1.6577250957489014
Validation loss: 2.0150134640355266

Epoch: 6| Step: 6
Training loss: 2.925126075744629
Validation loss: 2.0097619692484536

Epoch: 6| Step: 7
Training loss: 2.0989675521850586
Validation loss: 2.0090735048376103

Epoch: 6| Step: 8
Training loss: 2.4024431705474854
Validation loss: 2.02165626710461

Epoch: 6| Step: 9
Training loss: 1.9742883443832397
Validation loss: 2.0320956476273073

Epoch: 6| Step: 10
Training loss: 2.21565580368042
Validation loss: 2.0393766049415833

Epoch: 6| Step: 11
Training loss: 2.5445165634155273
Validation loss: 2.0513533110259683

Epoch: 6| Step: 12
Training loss: 2.8906712532043457
Validation loss: 2.0739538772131807

Epoch: 6| Step: 13
Training loss: 2.193952798843384
Validation loss: 2.050741275151571

Epoch: 87| Step: 0
Training loss: 1.4678486585617065
Validation loss: 2.0509680368567027

Epoch: 6| Step: 1
Training loss: 2.823763132095337
Validation loss: 2.054383659875521

Epoch: 6| Step: 2
Training loss: 2.2571845054626465
Validation loss: 2.030402227114606

Epoch: 6| Step: 3
Training loss: 1.9590113162994385
Validation loss: 2.026577381677525

Epoch: 6| Step: 4
Training loss: 2.2476234436035156
Validation loss: 2.002243095828641

Epoch: 6| Step: 5
Training loss: 2.127930164337158
Validation loss: 2.0032153526941934

Epoch: 6| Step: 6
Training loss: 1.88663649559021
Validation loss: 1.999527245439509

Epoch: 6| Step: 7
Training loss: 2.646982192993164
Validation loss: 2.014955826984939

Epoch: 6| Step: 8
Training loss: 3.2020325660705566
Validation loss: 2.0200688582594677

Epoch: 6| Step: 9
Training loss: 2.5764904022216797
Validation loss: 2.054767071559865

Epoch: 6| Step: 10
Training loss: 2.1941232681274414
Validation loss: 2.076728779782531

Epoch: 6| Step: 11
Training loss: 2.6818628311157227
Validation loss: 2.0827149909029723

Epoch: 6| Step: 12
Training loss: 2.441582202911377
Validation loss: 2.0962186064771426

Epoch: 6| Step: 13
Training loss: 1.9719573259353638
Validation loss: 2.102121768459197

Epoch: 88| Step: 0
Training loss: 1.9793897867202759
Validation loss: 2.074604953488996

Epoch: 6| Step: 1
Training loss: 2.0926952362060547
Validation loss: 2.0325663474298294

Epoch: 6| Step: 2
Training loss: 2.2106733322143555
Validation loss: 2.0173421636704476

Epoch: 6| Step: 3
Training loss: 2.3875651359558105
Validation loss: 2.0060122295092513

Epoch: 6| Step: 4
Training loss: 2.490950584411621
Validation loss: 1.991791973831833

Epoch: 6| Step: 5
Training loss: 2.4359471797943115
Validation loss: 1.9957193713034354

Epoch: 6| Step: 6
Training loss: 2.278463125228882
Validation loss: 2.000913384140179

Epoch: 6| Step: 7
Training loss: 2.696298122406006
Validation loss: 2.0064381463553316

Epoch: 6| Step: 8
Training loss: 2.3099234104156494
Validation loss: 1.9995693596460486

Epoch: 6| Step: 9
Training loss: 1.8552011251449585
Validation loss: 2.0051672099738993

Epoch: 6| Step: 10
Training loss: 1.7920732498168945
Validation loss: 2.002712316410516

Epoch: 6| Step: 11
Training loss: 2.7701094150543213
Validation loss: 2.009730815887451

Epoch: 6| Step: 12
Training loss: 2.6711037158966064
Validation loss: 2.0152717815932406

Epoch: 6| Step: 13
Training loss: 2.7303833961486816
Validation loss: 2.036461939093887

Epoch: 89| Step: 0
Training loss: 2.78574800491333
Validation loss: 2.0805185353884132

Epoch: 6| Step: 1
Training loss: 2.7521145343780518
Validation loss: 2.127680842594434

Epoch: 6| Step: 2
Training loss: 2.3783044815063477
Validation loss: 2.1392121686730334

Epoch: 6| Step: 3
Training loss: 1.8329215049743652
Validation loss: 2.1487756108724945

Epoch: 6| Step: 4
Training loss: 2.8441929817199707
Validation loss: 2.1369236284686672

Epoch: 6| Step: 5
Training loss: 2.533447265625
Validation loss: 2.1617054247087046

Epoch: 6| Step: 6
Training loss: 2.2619876861572266
Validation loss: 2.1824637433534027

Epoch: 6| Step: 7
Training loss: 2.3105692863464355
Validation loss: 2.1666656976105063

Epoch: 6| Step: 8
Training loss: 1.603840708732605
Validation loss: 2.1384708932650986

Epoch: 6| Step: 9
Training loss: 2.3863120079040527
Validation loss: 2.096402250310426

Epoch: 6| Step: 10
Training loss: 2.5516414642333984
Validation loss: 2.0602918773569088

Epoch: 6| Step: 11
Training loss: 2.121213436126709
Validation loss: 2.044486338092435

Epoch: 6| Step: 12
Training loss: 1.6933481693267822
Validation loss: 2.021787594723445

Epoch: 6| Step: 13
Training loss: 2.9411685466766357
Validation loss: 2.0233263200329197

Epoch: 90| Step: 0
Training loss: 2.1829147338867188
Validation loss: 2.024338194119033

Epoch: 6| Step: 1
Training loss: 1.6395244598388672
Validation loss: 2.0282987522822555

Epoch: 6| Step: 2
Training loss: 1.9795632362365723
Validation loss: 2.0156197009548062

Epoch: 6| Step: 3
Training loss: 2.070990800857544
Validation loss: 2.023081559006886

Epoch: 6| Step: 4
Training loss: 1.9499605894088745
Validation loss: 2.009347436248615

Epoch: 6| Step: 5
Training loss: 2.298910140991211
Validation loss: 2.0366030969927387

Epoch: 6| Step: 6
Training loss: 1.802172303199768
Validation loss: 2.0708279378952517

Epoch: 6| Step: 7
Training loss: 2.7093191146850586
Validation loss: 2.1078247152349

Epoch: 6| Step: 8
Training loss: 2.6428537368774414
Validation loss: 2.1478788468145553

Epoch: 6| Step: 9
Training loss: 2.7411351203918457
Validation loss: 2.1657565575774

Epoch: 6| Step: 10
Training loss: 3.4027130603790283
Validation loss: 2.159413844026545

Epoch: 6| Step: 11
Training loss: 2.2503929138183594
Validation loss: 2.169488401823146

Epoch: 6| Step: 12
Training loss: 2.5701093673706055
Validation loss: 2.136153777440389

Epoch: 6| Step: 13
Training loss: 2.8305652141571045
Validation loss: 2.090919138282858

Epoch: 91| Step: 0
Training loss: 2.3535256385803223
Validation loss: 2.030900970582039

Epoch: 6| Step: 1
Training loss: 2.6983776092529297
Validation loss: 2.008936421845549

Epoch: 6| Step: 2
Training loss: 2.51790452003479
Validation loss: 1.9919717234949912

Epoch: 6| Step: 3
Training loss: 1.4955503940582275
Validation loss: 1.999500528458626

Epoch: 6| Step: 4
Training loss: 2.466062068939209
Validation loss: 2.0023811927405735

Epoch: 6| Step: 5
Training loss: 2.2579119205474854
Validation loss: 2.019355102251935

Epoch: 6| Step: 6
Training loss: 2.403761863708496
Validation loss: 2.0248275546617407

Epoch: 6| Step: 7
Training loss: 2.613705635070801
Validation loss: 2.060856539716003

Epoch: 6| Step: 8
Training loss: 2.6816699504852295
Validation loss: 2.0712603856158514

Epoch: 6| Step: 9
Training loss: 2.199948787689209
Validation loss: 2.0597098719689155

Epoch: 6| Step: 10
Training loss: 2.29704213142395
Validation loss: 2.0474932129665087

Epoch: 6| Step: 11
Training loss: 2.3174784183502197
Validation loss: 2.0673729142835064

Epoch: 6| Step: 12
Training loss: 2.48042631149292
Validation loss: 2.073600635733656

Epoch: 6| Step: 13
Training loss: 1.6553155183792114
Validation loss: 2.0505965076467043

Epoch: 92| Step: 0
Training loss: 2.0537195205688477
Validation loss: 2.0776470835490892

Epoch: 6| Step: 1
Training loss: 2.150240898132324
Validation loss: 2.1027881176240983

Epoch: 6| Step: 2
Training loss: 2.143220901489258
Validation loss: 2.11256621601761

Epoch: 6| Step: 3
Training loss: 2.768584966659546
Validation loss: 2.095920406362062

Epoch: 6| Step: 4
Training loss: 2.5273594856262207
Validation loss: 2.0707417341970626

Epoch: 6| Step: 5
Training loss: 2.285412311553955
Validation loss: 2.0405961723737818

Epoch: 6| Step: 6
Training loss: 2.189077377319336
Validation loss: 2.033700987856875

Epoch: 6| Step: 7
Training loss: 1.603130578994751
Validation loss: 2.027284554255906

Epoch: 6| Step: 8
Training loss: 2.3592844009399414
Validation loss: 2.044411625913394

Epoch: 6| Step: 9
Training loss: 2.0613937377929688
Validation loss: 2.051716407140096

Epoch: 6| Step: 10
Training loss: 2.828596353530884
Validation loss: 2.059793876063439

Epoch: 6| Step: 11
Training loss: 2.651632308959961
Validation loss: 2.041904975009221

Epoch: 6| Step: 12
Training loss: 2.110286235809326
Validation loss: 2.027787016284081

Epoch: 6| Step: 13
Training loss: 2.8395471572875977
Validation loss: 2.015359483739381

Epoch: 93| Step: 0
Training loss: 1.833199381828308
Validation loss: 1.9916752512736986

Epoch: 6| Step: 1
Training loss: 1.8080015182495117
Validation loss: 1.9813871281121367

Epoch: 6| Step: 2
Training loss: 2.5403902530670166
Validation loss: 1.9843732900516962

Epoch: 6| Step: 3
Training loss: 2.407243490219116
Validation loss: 1.9779385366747457

Epoch: 6| Step: 4
Training loss: 2.1465930938720703
Validation loss: 1.9788445682935818

Epoch: 6| Step: 5
Training loss: 1.454087495803833
Validation loss: 1.9843510645692066

Epoch: 6| Step: 6
Training loss: 2.38608980178833
Validation loss: 1.989318306728076

Epoch: 6| Step: 7
Training loss: 2.551133394241333
Validation loss: 2.002756767375495

Epoch: 6| Step: 8
Training loss: 2.7588720321655273
Validation loss: 2.019131915543669

Epoch: 6| Step: 9
Training loss: 2.593411684036255
Validation loss: 2.0401020562776955

Epoch: 6| Step: 10
Training loss: 2.6378841400146484
Validation loss: 2.0430029233296714

Epoch: 6| Step: 11
Training loss: 2.543543815612793
Validation loss: 2.0584318766029934

Epoch: 6| Step: 12
Training loss: 2.233055591583252
Validation loss: 2.061128565060195

Epoch: 6| Step: 13
Training loss: 2.385043144226074
Validation loss: 2.041707900262648

Epoch: 94| Step: 0
Training loss: 2.3331515789031982
Validation loss: 2.0385153011609147

Epoch: 6| Step: 1
Training loss: 2.3043112754821777
Validation loss: 2.038523727847684

Epoch: 6| Step: 2
Training loss: 2.201443910598755
Validation loss: 2.035449504852295

Epoch: 6| Step: 3
Training loss: 2.360522985458374
Validation loss: 2.0190770395340456

Epoch: 6| Step: 4
Training loss: 2.1200058460235596
Validation loss: 2.0158750857076337

Epoch: 6| Step: 5
Training loss: 2.9737157821655273
Validation loss: 2.021158934921347

Epoch: 6| Step: 6
Training loss: 2.4885687828063965
Validation loss: 2.0152226007112892

Epoch: 6| Step: 7
Training loss: 2.7964818477630615
Validation loss: 2.0165866600569857

Epoch: 6| Step: 8
Training loss: 1.9137113094329834
Validation loss: 2.028759992250832

Epoch: 6| Step: 9
Training loss: 1.8055201768875122
Validation loss: 2.0409820438713155

Epoch: 6| Step: 10
Training loss: 2.237762451171875
Validation loss: 2.0270398470663253

Epoch: 6| Step: 11
Training loss: 1.919130802154541
Validation loss: 2.023975508187407

Epoch: 6| Step: 12
Training loss: 2.765028953552246
Validation loss: 2.0133417857590543

Epoch: 6| Step: 13
Training loss: 1.6405764818191528
Validation loss: 2.0070729768404396

Epoch: 95| Step: 0
Training loss: 2.0370371341705322
Validation loss: 2.009545665915294

Epoch: 6| Step: 1
Training loss: 2.6735877990722656
Validation loss: 2.02787422877486

Epoch: 6| Step: 2
Training loss: 1.608794927597046
Validation loss: 2.072286287943522

Epoch: 6| Step: 3
Training loss: 2.317574977874756
Validation loss: 2.075566070054167

Epoch: 6| Step: 4
Training loss: 2.837355852127075
Validation loss: 2.0558929802269064

Epoch: 6| Step: 5
Training loss: 1.5284764766693115
Validation loss: 2.033838778413752

Epoch: 6| Step: 6
Training loss: 2.7885689735412598
Validation loss: 2.0215836442926878

Epoch: 6| Step: 7
Training loss: 2.3240299224853516
Validation loss: 1.9905118865351523

Epoch: 6| Step: 8
Training loss: 2.021390438079834
Validation loss: 1.9819273923033027

Epoch: 6| Step: 9
Training loss: 2.288713216781616
Validation loss: 1.9863769520995438

Epoch: 6| Step: 10
Training loss: 2.0338220596313477
Validation loss: 1.9907683480170466

Epoch: 6| Step: 11
Training loss: 2.5864109992980957
Validation loss: 2.0350781486880396

Epoch: 6| Step: 12
Training loss: 2.932966709136963
Validation loss: 2.04833641359883

Epoch: 6| Step: 13
Training loss: 1.8907506465911865
Validation loss: 2.0484598618681713

Epoch: 96| Step: 0
Training loss: 2.2475199699401855
Validation loss: 2.0378338521526707

Epoch: 6| Step: 1
Training loss: 1.8905174732208252
Validation loss: 2.031416949405465

Epoch: 6| Step: 2
Training loss: 1.9537973403930664
Validation loss: 2.0305666641522477

Epoch: 6| Step: 3
Training loss: 2.2098560333251953
Validation loss: 2.041470871176771

Epoch: 6| Step: 4
Training loss: 2.748353958129883
Validation loss: 2.042383095269562

Epoch: 6| Step: 5
Training loss: 3.038177728652954
Validation loss: 2.0263686987661544

Epoch: 6| Step: 6
Training loss: 3.078763484954834
Validation loss: 2.0039126232106197

Epoch: 6| Step: 7
Training loss: 3.0649049282073975
Validation loss: 2.0102753254675094

Epoch: 6| Step: 8
Training loss: 1.783095121383667
Validation loss: 2.0133812478793565

Epoch: 6| Step: 9
Training loss: 1.5772027969360352
Validation loss: 2.0115591902886667

Epoch: 6| Step: 10
Training loss: 2.0299201011657715
Validation loss: 2.0252601536371375

Epoch: 6| Step: 11
Training loss: 1.8808975219726562
Validation loss: 2.0377001262480214

Epoch: 6| Step: 12
Training loss: 1.938265323638916
Validation loss: 2.041247497322739

Epoch: 6| Step: 13
Training loss: 2.4690637588500977
Validation loss: 2.05919542876623

Epoch: 97| Step: 0
Training loss: 2.2216241359710693
Validation loss: 2.057878601935602

Epoch: 6| Step: 1
Training loss: 2.4799633026123047
Validation loss: 2.042074015063624

Epoch: 6| Step: 2
Training loss: 2.3576693534851074
Validation loss: 2.0479935958821285

Epoch: 6| Step: 3
Training loss: 2.438882827758789
Validation loss: 2.054629236139277

Epoch: 6| Step: 4
Training loss: 2.0238232612609863
Validation loss: 2.0548040136214225

Epoch: 6| Step: 5
Training loss: 2.495189666748047
Validation loss: 2.050965650107271

Epoch: 6| Step: 6
Training loss: 1.899084448814392
Validation loss: 2.0439554311895884

Epoch: 6| Step: 7
Training loss: 1.9835200309753418
Validation loss: 2.0161637375431676

Epoch: 6| Step: 8
Training loss: 2.4500818252563477
Validation loss: 2.014968349087623

Epoch: 6| Step: 9
Training loss: 2.352409839630127
Validation loss: 1.999029267218805

Epoch: 6| Step: 10
Training loss: 2.3715121746063232
Validation loss: 1.991597225589137

Epoch: 6| Step: 11
Training loss: 1.4553062915802002
Validation loss: 1.9913099299194992

Epoch: 6| Step: 12
Training loss: 2.710038423538208
Validation loss: 1.9891571742232128

Epoch: 6| Step: 13
Training loss: 2.5017948150634766
Validation loss: 1.9821344870392994

Epoch: 98| Step: 0
Training loss: 1.714247703552246
Validation loss: 2.0006415446599326

Epoch: 6| Step: 1
Training loss: 2.145651340484619
Validation loss: 2.0010405842975905

Epoch: 6| Step: 2
Training loss: 1.8522506952285767
Validation loss: 2.013035358921174

Epoch: 6| Step: 3
Training loss: 2.4225497245788574
Validation loss: 2.017504419049909

Epoch: 6| Step: 4
Training loss: 1.9576038122177124
Validation loss: 2.0427167979619836

Epoch: 6| Step: 5
Training loss: 2.3294849395751953
Validation loss: 2.0507983238466325

Epoch: 6| Step: 6
Training loss: 2.6582837104797363
Validation loss: 2.0711378769208024

Epoch: 6| Step: 7
Training loss: 1.7861998081207275
Validation loss: 2.0806003232156076

Epoch: 6| Step: 8
Training loss: 2.53816556930542
Validation loss: 2.1265778951747443

Epoch: 6| Step: 9
Training loss: 2.1890869140625
Validation loss: 2.14991964960611

Epoch: 6| Step: 10
Training loss: 2.7721774578094482
Validation loss: 2.1384390143937964

Epoch: 6| Step: 11
Training loss: 2.3043856620788574
Validation loss: 2.0999258308000464

Epoch: 6| Step: 12
Training loss: 2.67706036567688
Validation loss: 2.092338574829922

Epoch: 6| Step: 13
Training loss: 3.0002281665802
Validation loss: 2.0577987419661654

Epoch: 99| Step: 0
Training loss: 2.551591634750366
Validation loss: 2.054039448820135

Epoch: 6| Step: 1
Training loss: 2.9413537979125977
Validation loss: 2.0577534667907225

Epoch: 6| Step: 2
Training loss: 2.519524574279785
Validation loss: 2.083689947282114

Epoch: 6| Step: 3
Training loss: 2.344200849533081
Validation loss: 2.081639932047936

Epoch: 6| Step: 4
Training loss: 1.5943679809570312
Validation loss: 2.082795686619256

Epoch: 6| Step: 5
Training loss: 1.5666191577911377
Validation loss: 2.0818178256352744

Epoch: 6| Step: 6
Training loss: 1.8544137477874756
Validation loss: 2.075433568287921

Epoch: 6| Step: 7
Training loss: 2.3312127590179443
Validation loss: 2.05243581597523

Epoch: 6| Step: 8
Training loss: 1.8475775718688965
Validation loss: 2.004964309353982

Epoch: 6| Step: 9
Training loss: 2.6360104084014893
Validation loss: 1.9805433788607198

Epoch: 6| Step: 10
Training loss: 2.004674196243286
Validation loss: 1.9649938319319038

Epoch: 6| Step: 11
Training loss: 2.858757972717285
Validation loss: 1.960181854104483

Epoch: 6| Step: 12
Training loss: 2.4990453720092773
Validation loss: 1.966131079581476

Epoch: 6| Step: 13
Training loss: 2.938735008239746
Validation loss: 1.9616558885061612

Epoch: 100| Step: 0
Training loss: 2.604966402053833
Validation loss: 1.960533836836456

Epoch: 6| Step: 1
Training loss: 2.062016487121582
Validation loss: 1.9784370686418267

Epoch: 6| Step: 2
Training loss: 1.670602798461914
Validation loss: 1.9767019184686805

Epoch: 6| Step: 3
Training loss: 2.030423402786255
Validation loss: 1.984048189655427

Epoch: 6| Step: 4
Training loss: 2.3494784832000732
Validation loss: 2.015012768648004

Epoch: 6| Step: 5
Training loss: 1.7586396932601929
Validation loss: 2.025328546442011

Epoch: 6| Step: 6
Training loss: 2.345714569091797
Validation loss: 2.0521304991937455

Epoch: 6| Step: 7
Training loss: 3.1145920753479004
Validation loss: 2.067175437045354

Epoch: 6| Step: 8
Training loss: 2.2697014808654785
Validation loss: 2.112254855453327

Epoch: 6| Step: 9
Training loss: 2.7897419929504395
Validation loss: 2.142586572195894

Epoch: 6| Step: 10
Training loss: 2.2943875789642334
Validation loss: 2.14543709575489

Epoch: 6| Step: 11
Training loss: 2.0406129360198975
Validation loss: 2.1498123740637176

Epoch: 6| Step: 12
Training loss: 2.4841160774230957
Validation loss: 2.128394485801779

Epoch: 6| Step: 13
Training loss: 1.7124667167663574
Validation loss: 2.1010632002225487

Epoch: 101| Step: 0
Training loss: 2.3291711807250977
Validation loss: 2.05827582779751

Epoch: 6| Step: 1
Training loss: 2.1831603050231934
Validation loss: 2.0254469866393716

Epoch: 6| Step: 2
Training loss: 2.9760303497314453
Validation loss: 1.9988128549309188

Epoch: 6| Step: 3
Training loss: 2.6013565063476562
Validation loss: 1.9734623098886142

Epoch: 6| Step: 4
Training loss: 2.3765294551849365
Validation loss: 1.9599939930823542

Epoch: 6| Step: 5
Training loss: 2.239299774169922
Validation loss: 1.9644667768991122

Epoch: 6| Step: 6
Training loss: 2.44413423538208
Validation loss: 1.9805490688611103

Epoch: 6| Step: 7
Training loss: 1.8284895420074463
Validation loss: 1.9799558372907742

Epoch: 6| Step: 8
Training loss: 1.8780943155288696
Validation loss: 1.9796090792584162

Epoch: 6| Step: 9
Training loss: 1.5394539833068848
Validation loss: 1.975080564457883

Epoch: 6| Step: 10
Training loss: 2.298628807067871
Validation loss: 1.9839589467612646

Epoch: 6| Step: 11
Training loss: 2.236112117767334
Validation loss: 1.9919448744866155

Epoch: 6| Step: 12
Training loss: 2.361459732055664
Validation loss: 2.018754595069475

Epoch: 6| Step: 13
Training loss: 2.3667898178100586
Validation loss: 2.0264357725779214

Epoch: 102| Step: 0
Training loss: 1.8721603155136108
Validation loss: 2.047852921229537

Epoch: 6| Step: 1
Training loss: 1.5789673328399658
Validation loss: 2.057751173614174

Epoch: 6| Step: 2
Training loss: 1.928760290145874
Validation loss: 2.1019590003516084

Epoch: 6| Step: 3
Training loss: 2.1658406257629395
Validation loss: 2.09233679181786

Epoch: 6| Step: 4
Training loss: 3.1475257873535156
Validation loss: 2.0703436674610263

Epoch: 6| Step: 5
Training loss: 2.362696409225464
Validation loss: 2.060948610305786

Epoch: 6| Step: 6
Training loss: 2.502084732055664
Validation loss: 2.0561232836015764

Epoch: 6| Step: 7
Training loss: 2.633234977722168
Validation loss: 2.031056224658925

Epoch: 6| Step: 8
Training loss: 2.3145949840545654
Validation loss: 2.025669697792299

Epoch: 6| Step: 9
Training loss: 2.795792818069458
Validation loss: 2.0129275629597325

Epoch: 6| Step: 10
Training loss: 1.8244761228561401
Validation loss: 1.984779728356228

Epoch: 6| Step: 11
Training loss: 2.674441337585449
Validation loss: 1.9827885807201426

Epoch: 6| Step: 12
Training loss: 1.5754241943359375
Validation loss: 1.9768325628772858

Epoch: 6| Step: 13
Training loss: 2.0086569786071777
Validation loss: 1.9895142957728396

Epoch: 103| Step: 0
Training loss: 2.8824548721313477
Validation loss: 2.0089413940265612

Epoch: 6| Step: 1
Training loss: 1.8061017990112305
Validation loss: 2.0006792686318837

Epoch: 6| Step: 2
Training loss: 2.44350528717041
Validation loss: 2.0014226564797024

Epoch: 6| Step: 3
Training loss: 2.6298296451568604
Validation loss: 1.9739327148724628

Epoch: 6| Step: 4
Training loss: 1.8735766410827637
Validation loss: 1.9642565481124385

Epoch: 6| Step: 5
Training loss: 2.032670021057129
Validation loss: 1.9588044843366068

Epoch: 6| Step: 6
Training loss: 2.0242507457733154
Validation loss: 1.9643459781523673

Epoch: 6| Step: 7
Training loss: 1.5776981115341187
Validation loss: 1.9647645168406989

Epoch: 6| Step: 8
Training loss: 2.310150384902954
Validation loss: 1.9714538435782156

Epoch: 6| Step: 9
Training loss: 1.8715674877166748
Validation loss: 1.9634610094049925

Epoch: 6| Step: 10
Training loss: 2.5330543518066406
Validation loss: 1.963401258632701

Epoch: 6| Step: 11
Training loss: 2.386138677597046
Validation loss: 1.9873342257674023

Epoch: 6| Step: 12
Training loss: 2.3669357299804688
Validation loss: 2.0315775845640447

Epoch: 6| Step: 13
Training loss: 3.0022518634796143
Validation loss: 2.0785752945048834

Epoch: 104| Step: 0
Training loss: 2.025587797164917
Validation loss: 2.1193747084627867

Epoch: 6| Step: 1
Training loss: 1.984086513519287
Validation loss: 2.1290795072432487

Epoch: 6| Step: 2
Training loss: 2.3998119831085205
Validation loss: 2.0557203228755663

Epoch: 6| Step: 3
Training loss: 2.6206250190734863
Validation loss: 2.0009095309883036

Epoch: 6| Step: 4
Training loss: 2.193881034851074
Validation loss: 1.984733872516181

Epoch: 6| Step: 5
Training loss: 2.50368595123291
Validation loss: 1.9678869888346682

Epoch: 6| Step: 6
Training loss: 2.462315320968628
Validation loss: 1.9800928920827887

Epoch: 6| Step: 7
Training loss: 2.0718533992767334
Validation loss: 1.9794957868514522

Epoch: 6| Step: 8
Training loss: 3.2752785682678223
Validation loss: 1.973113352252591

Epoch: 6| Step: 9
Training loss: 1.9932026863098145
Validation loss: 1.9885954549235683

Epoch: 6| Step: 10
Training loss: 2.091400623321533
Validation loss: 2.0139124983100483

Epoch: 6| Step: 11
Training loss: 2.3828694820404053
Validation loss: 2.0569258915480746

Epoch: 6| Step: 12
Training loss: 1.873213529586792
Validation loss: 2.087085998186501

Epoch: 6| Step: 13
Training loss: 1.6163095235824585
Validation loss: 2.0961231364998767

Epoch: 105| Step: 0
Training loss: 2.7426695823669434
Validation loss: 2.1104823081724104

Epoch: 6| Step: 1
Training loss: 2.967700481414795
Validation loss: 2.144782679055327

Epoch: 6| Step: 2
Training loss: 1.8996808528900146
Validation loss: 2.1286979003619124

Epoch: 6| Step: 3
Training loss: 1.8653783798217773
Validation loss: 2.100117673156082

Epoch: 6| Step: 4
Training loss: 2.102076768875122
Validation loss: 2.04680032883921

Epoch: 6| Step: 5
Training loss: 2.952404737472534
Validation loss: 2.022373625027236

Epoch: 6| Step: 6
Training loss: 2.616748809814453
Validation loss: 2.0051845709482827

Epoch: 6| Step: 7
Training loss: 1.8864436149597168
Validation loss: 2.0085339956386115

Epoch: 6| Step: 8
Training loss: 2.152287006378174
Validation loss: 2.0141952101902296

Epoch: 6| Step: 9
Training loss: 1.509073257446289
Validation loss: 2.0077428728021602

Epoch: 6| Step: 10
Training loss: 2.3052291870117188
Validation loss: 1.9960027125573927

Epoch: 6| Step: 11
Training loss: 2.2375261783599854
Validation loss: 2.0019219844572005

Epoch: 6| Step: 12
Training loss: 1.4926918745040894
Validation loss: 1.99842611564103

Epoch: 6| Step: 13
Training loss: 2.7332632541656494
Validation loss: 2.0097683142590266

Epoch: 106| Step: 0
Training loss: 1.7885196208953857
Validation loss: 2.01513095055857

Epoch: 6| Step: 1
Training loss: 2.802119255065918
Validation loss: 2.028633729104073

Epoch: 6| Step: 2
Training loss: 2.1973705291748047
Validation loss: 2.020941453595315

Epoch: 6| Step: 3
Training loss: 1.8274282217025757
Validation loss: 1.9921506386931225

Epoch: 6| Step: 4
Training loss: 2.3177709579467773
Validation loss: 1.9752803451271468

Epoch: 6| Step: 5
Training loss: 2.572293281555176
Validation loss: 1.9704927629040134

Epoch: 6| Step: 6
Training loss: 2.2466821670532227
Validation loss: 1.9718792566689112

Epoch: 6| Step: 7
Training loss: 2.5092480182647705
Validation loss: 1.971175475787091

Epoch: 6| Step: 8
Training loss: 2.455291509628296
Validation loss: 1.9770026053151777

Epoch: 6| Step: 9
Training loss: 1.9586377143859863
Validation loss: 1.9800222125104678

Epoch: 6| Step: 10
Training loss: 2.1657047271728516
Validation loss: 1.9844904112559494

Epoch: 6| Step: 11
Training loss: 2.0094571113586426
Validation loss: 1.9874078765992196

Epoch: 6| Step: 12
Training loss: 2.28749942779541
Validation loss: 2.0041406513542257

Epoch: 6| Step: 13
Training loss: 1.679560899734497
Validation loss: 1.9971274137496948

Epoch: 107| Step: 0
Training loss: 2.15991473197937
Validation loss: 2.016925609239968

Epoch: 6| Step: 1
Training loss: 2.1667985916137695
Validation loss: 2.022375747721682

Epoch: 6| Step: 2
Training loss: 2.3508119583129883
Validation loss: 2.0654689829836608

Epoch: 6| Step: 3
Training loss: 2.279874324798584
Validation loss: 2.0878906711455314

Epoch: 6| Step: 4
Training loss: 2.6860756874084473
Validation loss: 2.1012719728613414

Epoch: 6| Step: 5
Training loss: 2.528193473815918
Validation loss: 2.0839141799557592

Epoch: 6| Step: 6
Training loss: 2.244934558868408
Validation loss: 2.0363109098967684

Epoch: 6| Step: 7
Training loss: 2.568842887878418
Validation loss: 1.9958368398809945

Epoch: 6| Step: 8
Training loss: 1.8787524700164795
Validation loss: 1.9704689697552753

Epoch: 6| Step: 9
Training loss: 2.1192305088043213
Validation loss: 1.9576559758955432

Epoch: 6| Step: 10
Training loss: 1.64271879196167
Validation loss: 1.9644413814749768

Epoch: 6| Step: 11
Training loss: 1.8656941652297974
Validation loss: 1.9742042133885045

Epoch: 6| Step: 12
Training loss: 2.1244678497314453
Validation loss: 1.9736917967437415

Epoch: 6| Step: 13
Training loss: 2.57845139503479
Validation loss: 1.9775586333326114

Epoch: 108| Step: 0
Training loss: 2.9323692321777344
Validation loss: 1.9782626872421594

Epoch: 6| Step: 1
Training loss: 2.24714732170105
Validation loss: 1.982251831280288

Epoch: 6| Step: 2
Training loss: 1.6891522407531738
Validation loss: 1.9876530221713486

Epoch: 6| Step: 3
Training loss: 1.5525771379470825
Validation loss: 1.9754722887469875

Epoch: 6| Step: 4
Training loss: 2.683626651763916
Validation loss: 1.977482106096001

Epoch: 6| Step: 5
Training loss: 1.6057021617889404
Validation loss: 1.9833667688472296

Epoch: 6| Step: 6
Training loss: 2.1696014404296875
Validation loss: 2.0013774095043058

Epoch: 6| Step: 7
Training loss: 1.7104854583740234
Validation loss: 2.016739842712238

Epoch: 6| Step: 8
Training loss: 1.756943702697754
Validation loss: 2.0292003808483

Epoch: 6| Step: 9
Training loss: 2.48142409324646
Validation loss: 2.06609280519588

Epoch: 6| Step: 10
Training loss: 2.9547367095947266
Validation loss: 2.077587740395659

Epoch: 6| Step: 11
Training loss: 2.1576595306396484
Validation loss: 2.105266317244499

Epoch: 6| Step: 12
Training loss: 2.7362499237060547
Validation loss: 2.10447705945661

Epoch: 6| Step: 13
Training loss: 2.2213571071624756
Validation loss: 2.0770198863039733

Epoch: 109| Step: 0
Training loss: 1.9826425313949585
Validation loss: 2.0401681507787397

Epoch: 6| Step: 1
Training loss: 1.6514933109283447
Validation loss: 2.0385528354234594

Epoch: 6| Step: 2
Training loss: 2.669833183288574
Validation loss: 2.029187948473038

Epoch: 6| Step: 3
Training loss: 1.8487234115600586
Validation loss: 2.0277256888727986

Epoch: 6| Step: 4
Training loss: 2.468830108642578
Validation loss: 2.025009919238347

Epoch: 6| Step: 5
Training loss: 1.6896262168884277
Validation loss: 2.03354077441718

Epoch: 6| Step: 6
Training loss: 1.869812250137329
Validation loss: 2.017359205471572

Epoch: 6| Step: 7
Training loss: 2.5105602741241455
Validation loss: 2.0312192311850925

Epoch: 6| Step: 8
Training loss: 2.1446640491485596
Validation loss: 2.0378896510729225

Epoch: 6| Step: 9
Training loss: 2.5186095237731934
Validation loss: 2.0495553888300413

Epoch: 6| Step: 10
Training loss: 2.367997884750366
Validation loss: 2.0270187803494033

Epoch: 6| Step: 11
Training loss: 2.172264814376831
Validation loss: 2.01544552464639

Epoch: 6| Step: 12
Training loss: 2.2376341819763184
Validation loss: 2.0084558956084715

Epoch: 6| Step: 13
Training loss: 2.1162898540496826
Validation loss: 2.0051814586885515

Epoch: 110| Step: 0
Training loss: 1.760298252105713
Validation loss: 1.9816655779397616

Epoch: 6| Step: 1
Training loss: 2.073753833770752
Validation loss: 1.9738227423801218

Epoch: 6| Step: 2
Training loss: 1.8886113166809082
Validation loss: 1.9526130230196062

Epoch: 6| Step: 3
Training loss: 2.361743927001953
Validation loss: 1.9662416391475226

Epoch: 6| Step: 4
Training loss: 2.521366834640503
Validation loss: 1.9608938770909463

Epoch: 6| Step: 5
Training loss: 2.2320311069488525
Validation loss: 1.9494799644716325

Epoch: 6| Step: 6
Training loss: 2.022932767868042
Validation loss: 1.9588830535129835

Epoch: 6| Step: 7
Training loss: 2.3089113235473633
Validation loss: 1.9543159200299172

Epoch: 6| Step: 8
Training loss: 2.215050220489502
Validation loss: 1.9477665539710753

Epoch: 6| Step: 9
Training loss: 2.2237610816955566
Validation loss: 1.9498327329594602

Epoch: 6| Step: 10
Training loss: 2.0395591259002686
Validation loss: 1.964839130319575

Epoch: 6| Step: 11
Training loss: 2.047802209854126
Validation loss: 1.9864462306422572

Epoch: 6| Step: 12
Training loss: 2.0951220989227295
Validation loss: 1.9966185913291028

Epoch: 6| Step: 13
Training loss: 2.653611660003662
Validation loss: 2.0274526995997273

Epoch: 111| Step: 0
Training loss: 1.965505838394165
Validation loss: 2.0446422138521747

Epoch: 6| Step: 1
Training loss: 1.8624989986419678
Validation loss: 2.0495655959652317

Epoch: 6| Step: 2
Training loss: 1.9896373748779297
Validation loss: 2.0301665670128277

Epoch: 6| Step: 3
Training loss: 2.4987525939941406
Validation loss: 2.024981860191591

Epoch: 6| Step: 4
Training loss: 1.6873247623443604
Validation loss: 2.0085846352320846

Epoch: 6| Step: 5
Training loss: 2.44104266166687
Validation loss: 2.008045078605734

Epoch: 6| Step: 6
Training loss: 1.799202561378479
Validation loss: 1.9998272003666047

Epoch: 6| Step: 7
Training loss: 1.8792786598205566
Validation loss: 1.99308136458038

Epoch: 6| Step: 8
Training loss: 2.543126106262207
Validation loss: 1.9842840458757134

Epoch: 6| Step: 9
Training loss: 2.222297191619873
Validation loss: 1.9891730034223167

Epoch: 6| Step: 10
Training loss: 1.9451111555099487
Validation loss: 1.968823880277654

Epoch: 6| Step: 11
Training loss: 2.77479887008667
Validation loss: 1.9668005512606712

Epoch: 6| Step: 12
Training loss: 2.235471248626709
Validation loss: 1.9852133207423712

Epoch: 6| Step: 13
Training loss: 2.4969701766967773
Validation loss: 1.9897416291698333

Epoch: 112| Step: 0
Training loss: 2.0669057369232178
Validation loss: 1.9899288249272171

Epoch: 6| Step: 1
Training loss: 1.8325111865997314
Validation loss: 1.9921174754378617

Epoch: 6| Step: 2
Training loss: 1.9991507530212402
Validation loss: 1.9888472249430995

Epoch: 6| Step: 3
Training loss: 1.8586747646331787
Validation loss: 1.9958265930093744

Epoch: 6| Step: 4
Training loss: 1.6208267211914062
Validation loss: 2.0007834088417793

Epoch: 6| Step: 5
Training loss: 2.3503782749176025
Validation loss: 2.001128960681218

Epoch: 6| Step: 6
Training loss: 2.0670504570007324
Validation loss: 2.004178391989841

Epoch: 6| Step: 7
Training loss: 2.5373778343200684
Validation loss: 2.0002165686699653

Epoch: 6| Step: 8
Training loss: 1.9464565515518188
Validation loss: 1.9857149483055196

Epoch: 6| Step: 9
Training loss: 2.3666601181030273
Validation loss: 1.9841194934742425

Epoch: 6| Step: 10
Training loss: 1.7754162549972534
Validation loss: 1.981024411416823

Epoch: 6| Step: 11
Training loss: 3.1465141773223877
Validation loss: 2.001619622271548

Epoch: 6| Step: 12
Training loss: 1.9699301719665527
Validation loss: 2.0014390394251835

Epoch: 6| Step: 13
Training loss: 2.0381312370300293
Validation loss: 2.0048548418988466

Epoch: 113| Step: 0
Training loss: 1.601074457168579
Validation loss: 2.007822741744339

Epoch: 6| Step: 1
Training loss: 2.3175010681152344
Validation loss: 2.037965133625974

Epoch: 6| Step: 2
Training loss: 2.7955076694488525
Validation loss: 2.062501968876008

Epoch: 6| Step: 3
Training loss: 2.2922451496124268
Validation loss: 2.081595238818917

Epoch: 6| Step: 4
Training loss: 2.8911452293395996
Validation loss: 2.0862059875201155

Epoch: 6| Step: 5
Training loss: 1.6967271566390991
Validation loss: 2.0451554111255112

Epoch: 6| Step: 6
Training loss: 2.632256507873535
Validation loss: 2.004990872516427

Epoch: 6| Step: 7
Training loss: 2.0685572624206543
Validation loss: 1.989391210258648

Epoch: 6| Step: 8
Training loss: 1.865252137184143
Validation loss: 1.9807680114623039

Epoch: 6| Step: 9
Training loss: 1.9554269313812256
Validation loss: 1.9714836510278846

Epoch: 6| Step: 10
Training loss: 2.125885486602783
Validation loss: 1.9605366978594052

Epoch: 6| Step: 11
Training loss: 1.3406174182891846
Validation loss: 1.9558224370402675

Epoch: 6| Step: 12
Training loss: 2.1932716369628906
Validation loss: 1.9544986960708455

Epoch: 6| Step: 13
Training loss: 1.6609472036361694
Validation loss: 1.9746633960354714

Epoch: 114| Step: 0
Training loss: 2.3266191482543945
Validation loss: 1.9823696151856454

Epoch: 6| Step: 1
Training loss: 2.0556106567382812
Validation loss: 1.985681874777681

Epoch: 6| Step: 2
Training loss: 2.3529253005981445
Validation loss: 1.9881365273588447

Epoch: 6| Step: 3
Training loss: 1.8499243259429932
Validation loss: 1.9876961323522753

Epoch: 6| Step: 4
Training loss: 2.2762904167175293
Validation loss: 1.9715663617657078

Epoch: 6| Step: 5
Training loss: 2.2353405952453613
Validation loss: 1.9822538860382573

Epoch: 6| Step: 6
Training loss: 1.8060742616653442
Validation loss: 1.9875607618721582

Epoch: 6| Step: 7
Training loss: 1.7339191436767578
Validation loss: 1.9846119406402751

Epoch: 6| Step: 8
Training loss: 2.133267641067505
Validation loss: 2.000407582970076

Epoch: 6| Step: 9
Training loss: 1.682326316833496
Validation loss: 2.005048636467226

Epoch: 6| Step: 10
Training loss: 1.8688194751739502
Validation loss: 2.0187706562780563

Epoch: 6| Step: 11
Training loss: 2.20101261138916
Validation loss: 2.014754737577131

Epoch: 6| Step: 12
Training loss: 2.568516254425049
Validation loss: 2.0327066606090916

Epoch: 6| Step: 13
Training loss: 1.9386310577392578
Validation loss: 2.0357136893016037

Epoch: 115| Step: 0
Training loss: 2.1025099754333496
Validation loss: 2.0390043386849026

Epoch: 6| Step: 1
Training loss: 2.8826041221618652
Validation loss: 2.0354432380327614

Epoch: 6| Step: 2
Training loss: 1.7811368703842163
Validation loss: 2.0510816087004957

Epoch: 6| Step: 3
Training loss: 2.2213845252990723
Validation loss: 2.035136952195116

Epoch: 6| Step: 4
Training loss: 1.832667589187622
Validation loss: 2.0356569956707697

Epoch: 6| Step: 5
Training loss: 1.4956934452056885
Validation loss: 2.0368203052910427

Epoch: 6| Step: 6
Training loss: 1.6980869770050049
Validation loss: 2.0245545474431847

Epoch: 6| Step: 7
Training loss: 2.1231138706207275
Validation loss: 1.9979827788568312

Epoch: 6| Step: 8
Training loss: 1.9640638828277588
Validation loss: 2.003358035959223

Epoch: 6| Step: 9
Training loss: 2.5643296241760254
Validation loss: 2.0180973058105796

Epoch: 6| Step: 10
Training loss: 2.4934070110321045
Validation loss: 2.0286870220656037

Epoch: 6| Step: 11
Training loss: 2.117501974105835
Validation loss: 2.0290087576835387

Epoch: 6| Step: 12
Training loss: 1.5569077730178833
Validation loss: 2.0178381422514557

Epoch: 6| Step: 13
Training loss: 2.437626361846924
Validation loss: 2.0092993513230355

Epoch: 116| Step: 0
Training loss: 2.060795307159424
Validation loss: 1.9937955794795867

Epoch: 6| Step: 1
Training loss: 2.242976665496826
Validation loss: 2.0263128203730427

Epoch: 6| Step: 2
Training loss: 1.4777591228485107
Validation loss: 2.0620143464816514

Epoch: 6| Step: 3
Training loss: 2.276817798614502
Validation loss: 2.090757776332158

Epoch: 6| Step: 4
Training loss: 1.504014492034912
Validation loss: 2.0954050184578024

Epoch: 6| Step: 5
Training loss: 2.358802318572998
Validation loss: 2.0738860971184185

Epoch: 6| Step: 6
Training loss: 1.6882905960083008
Validation loss: 2.0168487102754655

Epoch: 6| Step: 7
Training loss: 2.437586784362793
Validation loss: 2.010262358573175

Epoch: 6| Step: 8
Training loss: 1.7387207746505737
Validation loss: 2.002989920236731

Epoch: 6| Step: 9
Training loss: 2.069521903991699
Validation loss: 2.0078515839833084

Epoch: 6| Step: 10
Training loss: 2.8814985752105713
Validation loss: 2.0128402979143205

Epoch: 6| Step: 11
Training loss: 2.526914119720459
Validation loss: 2.013527444613877

Epoch: 6| Step: 12
Training loss: 2.080451011657715
Validation loss: 2.01504930116797

Epoch: 6| Step: 13
Training loss: 1.723653793334961
Validation loss: 2.0050225334782756

Epoch: 117| Step: 0
Training loss: 3.0587668418884277
Validation loss: 1.9979126735400128

Epoch: 6| Step: 1
Training loss: 2.0452847480773926
Validation loss: 2.0024385195906445

Epoch: 6| Step: 2
Training loss: 2.250075578689575
Validation loss: 2.0130843975210704

Epoch: 6| Step: 3
Training loss: 1.657127022743225
Validation loss: 2.022635216354042

Epoch: 6| Step: 4
Training loss: 1.7621893882751465
Validation loss: 2.038155286542831

Epoch: 6| Step: 5
Training loss: 2.2405593395233154
Validation loss: 2.0354121961901264

Epoch: 6| Step: 6
Training loss: 1.901036024093628
Validation loss: 2.0467227556372203

Epoch: 6| Step: 7
Training loss: 1.718260407447815
Validation loss: 2.0433740859390586

Epoch: 6| Step: 8
Training loss: 2.4862775802612305
Validation loss: 2.0351836540365733

Epoch: 6| Step: 9
Training loss: 1.5357037782669067
Validation loss: 2.0108863717766217

Epoch: 6| Step: 10
Training loss: 2.3605852127075195
Validation loss: 2.0067929157646756

Epoch: 6| Step: 11
Training loss: 1.5333151817321777
Validation loss: 1.996062917094077

Epoch: 6| Step: 12
Training loss: 1.8762708902359009
Validation loss: 2.010875166103404

Epoch: 6| Step: 13
Training loss: 1.762953281402588
Validation loss: 2.002480278732956

Epoch: 118| Step: 0
Training loss: 1.996474027633667
Validation loss: 1.990924048167403

Epoch: 6| Step: 1
Training loss: 1.8365328311920166
Validation loss: 2.0126333416149182

Epoch: 6| Step: 2
Training loss: 2.515507936477661
Validation loss: 1.9849057902571976

Epoch: 6| Step: 3
Training loss: 2.0280842781066895
Validation loss: 1.9762631154829455

Epoch: 6| Step: 4
Training loss: 1.1119436025619507
Validation loss: 1.98997712391679

Epoch: 6| Step: 5
Training loss: 2.3615782260894775
Validation loss: 1.9985373173990557

Epoch: 6| Step: 6
Training loss: 1.5809416770935059
Validation loss: 1.990584647783669

Epoch: 6| Step: 7
Training loss: 2.2925198078155518
Validation loss: 2.0038864638215754

Epoch: 6| Step: 8
Training loss: 2.8841664791107178
Validation loss: 1.9979726140217116

Epoch: 6| Step: 9
Training loss: 1.9004364013671875
Validation loss: 1.9807791479172245

Epoch: 6| Step: 10
Training loss: 2.311899185180664
Validation loss: 1.9741789730646278

Epoch: 6| Step: 11
Training loss: 2.1748781204223633
Validation loss: 1.9639059523100495

Epoch: 6| Step: 12
Training loss: 1.7725555896759033
Validation loss: 1.9536997618213776

Epoch: 6| Step: 13
Training loss: 1.573091983795166
Validation loss: 1.9547275240703295

Epoch: 119| Step: 0
Training loss: 1.3875534534454346
Validation loss: 1.95592834103492

Epoch: 6| Step: 1
Training loss: 1.7605453729629517
Validation loss: 1.9540230792055848

Epoch: 6| Step: 2
Training loss: 2.2191529273986816
Validation loss: 1.972711404164632

Epoch: 6| Step: 3
Training loss: 1.6019151210784912
Validation loss: 1.9778400416015296

Epoch: 6| Step: 4
Training loss: 1.5826809406280518
Validation loss: 1.9966638857318508

Epoch: 6| Step: 5
Training loss: 2.665614366531372
Validation loss: 2.006091381913872

Epoch: 6| Step: 6
Training loss: 2.510819911956787
Validation loss: 2.040548978313323

Epoch: 6| Step: 7
Training loss: 2.0539400577545166
Validation loss: 2.0325326265827304

Epoch: 6| Step: 8
Training loss: 2.1741061210632324
Validation loss: 2.0284205047033166

Epoch: 6| Step: 9
Training loss: 1.8194260597229004
Validation loss: 2.023724489314582

Epoch: 6| Step: 10
Training loss: 2.4279613494873047
Validation loss: 2.027035218413158

Epoch: 6| Step: 11
Training loss: 2.209808349609375
Validation loss: 2.0556671465596845

Epoch: 6| Step: 12
Training loss: 1.7177116870880127
Validation loss: 2.0547373935740483

Epoch: 6| Step: 13
Training loss: 2.542611837387085
Validation loss: 2.074331441233235

Epoch: 120| Step: 0
Training loss: 2.570091724395752
Validation loss: 2.0574671055680964

Epoch: 6| Step: 1
Training loss: 1.5073795318603516
Validation loss: 2.049177900437386

Epoch: 6| Step: 2
Training loss: 2.0864553451538086
Validation loss: 2.06361416334747

Epoch: 6| Step: 3
Training loss: 2.7573180198669434
Validation loss: 2.0706717814168623

Epoch: 6| Step: 4
Training loss: 1.7373144626617432
Validation loss: 2.0964814488605787

Epoch: 6| Step: 5
Training loss: 1.759279489517212
Validation loss: 2.0758774934276456

Epoch: 6| Step: 6
Training loss: 1.5616105794906616
Validation loss: 2.0700350243558168

Epoch: 6| Step: 7
Training loss: 2.023946762084961
Validation loss: 2.0416989941750803

Epoch: 6| Step: 8
Training loss: 1.782774567604065
Validation loss: 2.022585961126512

Epoch: 6| Step: 9
Training loss: 1.7172765731811523
Validation loss: 2.0035947586900447

Epoch: 6| Step: 10
Training loss: 2.720432996749878
Validation loss: 1.9939724835016395

Epoch: 6| Step: 11
Training loss: 1.7773277759552002
Validation loss: 2.00850075034685

Epoch: 6| Step: 12
Training loss: 1.8254414796829224
Validation loss: 2.012244742403748

Epoch: 6| Step: 13
Training loss: 2.059333324432373
Validation loss: 2.0017389225703415

Epoch: 121| Step: 0
Training loss: 2.69468355178833
Validation loss: 1.9969806389142108

Epoch: 6| Step: 1
Training loss: 1.8118871450424194
Validation loss: 2.008250646693732

Epoch: 6| Step: 2
Training loss: 1.6644922494888306
Validation loss: 2.0132320734762374

Epoch: 6| Step: 3
Training loss: 2.1319308280944824
Validation loss: 2.026468151359148

Epoch: 6| Step: 4
Training loss: 1.707205057144165
Validation loss: 2.044823818309333

Epoch: 6| Step: 5
Training loss: 1.686812400817871
Validation loss: 2.0499504394428705

Epoch: 6| Step: 6
Training loss: 2.3289003372192383
Validation loss: 2.051084300523163

Epoch: 6| Step: 7
Training loss: 2.078237533569336
Validation loss: 2.050022940481863

Epoch: 6| Step: 8
Training loss: 2.5813546180725098
Validation loss: 2.0278486333867556

Epoch: 6| Step: 9
Training loss: 1.8329159021377563
Validation loss: 2.023654576270811

Epoch: 6| Step: 10
Training loss: 2.058397054672241
Validation loss: 2.0193693176392586

Epoch: 6| Step: 11
Training loss: 1.66612708568573
Validation loss: 2.017613431458832

Epoch: 6| Step: 12
Training loss: 1.454810619354248
Validation loss: 2.0089912055641093

Epoch: 6| Step: 13
Training loss: 2.2669837474823
Validation loss: 2.0093914898492957

Epoch: 122| Step: 0
Training loss: 2.325301170349121
Validation loss: 2.0154187935654835

Epoch: 6| Step: 1
Training loss: 1.757676601409912
Validation loss: 2.0080565188520696

Epoch: 6| Step: 2
Training loss: 2.032102584838867
Validation loss: 1.9958120302487445

Epoch: 6| Step: 3
Training loss: 2.1314117908477783
Validation loss: 1.9899303631115985

Epoch: 6| Step: 4
Training loss: 1.724696159362793
Validation loss: 1.9733776405293455

Epoch: 6| Step: 5
Training loss: 2.638331413269043
Validation loss: 1.9871184774624404

Epoch: 6| Step: 6
Training loss: 2.1505722999572754
Validation loss: 2.0154733632200506

Epoch: 6| Step: 7
Training loss: 2.3402795791625977
Validation loss: 2.026319831930181

Epoch: 6| Step: 8
Training loss: 2.02047061920166
Validation loss: 2.0536013303264493

Epoch: 6| Step: 9
Training loss: 2.137526750564575
Validation loss: 2.1001382040721115

Epoch: 6| Step: 10
Training loss: 1.5082306861877441
Validation loss: 2.106889975968228

Epoch: 6| Step: 11
Training loss: 1.5861051082611084
Validation loss: 2.082320806800678

Epoch: 6| Step: 12
Training loss: 1.7761917114257812
Validation loss: 2.0616119830839095

Epoch: 6| Step: 13
Training loss: 1.2840185165405273
Validation loss: 2.022385838211224

Epoch: 123| Step: 0
Training loss: 2.043051242828369
Validation loss: 2.002522841576607

Epoch: 6| Step: 1
Training loss: 1.8008332252502441
Validation loss: 1.9962532302384735

Epoch: 6| Step: 2
Training loss: 2.0862598419189453
Validation loss: 2.00611509302611

Epoch: 6| Step: 3
Training loss: 1.9465230703353882
Validation loss: 2.004826126560088

Epoch: 6| Step: 4
Training loss: 2.2170982360839844
Validation loss: 2.0007210957106722

Epoch: 6| Step: 5
Training loss: 1.9976798295974731
Validation loss: 2.0106937808375203

Epoch: 6| Step: 6
Training loss: 1.612403392791748
Validation loss: 2.0383876164754233

Epoch: 6| Step: 7
Training loss: 2.022446632385254
Validation loss: 2.0611550666952647

Epoch: 6| Step: 8
Training loss: 1.4242761135101318
Validation loss: 2.1084289678963284

Epoch: 6| Step: 9
Training loss: 2.739161491394043
Validation loss: 2.093432023961057

Epoch: 6| Step: 10
Training loss: 2.2140204906463623
Validation loss: 2.0685867571061656

Epoch: 6| Step: 11
Training loss: 1.895439863204956
Validation loss: 2.037976949445663

Epoch: 6| Step: 12
Training loss: 2.2156152725219727
Validation loss: 2.008268566541774

Epoch: 6| Step: 13
Training loss: 1.055052399635315
Validation loss: 2.002075849040862

Epoch: 124| Step: 0
Training loss: 1.2212302684783936
Validation loss: 1.990511586589198

Epoch: 6| Step: 1
Training loss: 2.0601930618286133
Validation loss: 1.9857595453980148

Epoch: 6| Step: 2
Training loss: 1.980845332145691
Validation loss: 1.9927666700014504

Epoch: 6| Step: 3
Training loss: 2.409423828125
Validation loss: 1.9910509650425245

Epoch: 6| Step: 4
Training loss: 1.7182457447052002
Validation loss: 2.0131020879232757

Epoch: 6| Step: 5
Training loss: 1.6666762828826904
Validation loss: 2.022515179008566

Epoch: 6| Step: 6
Training loss: 1.664905309677124
Validation loss: 2.031065301228595

Epoch: 6| Step: 7
Training loss: 1.8535585403442383
Validation loss: 2.0243453697491716

Epoch: 6| Step: 8
Training loss: 1.3324689865112305
Validation loss: 2.011341684608049

Epoch: 6| Step: 9
Training loss: 1.9350720643997192
Validation loss: 2.010739440559059

Epoch: 6| Step: 10
Training loss: 2.234809637069702
Validation loss: 1.9993104498873475

Epoch: 6| Step: 11
Training loss: 2.447969913482666
Validation loss: 1.976761423131471

Epoch: 6| Step: 12
Training loss: 2.2363898754119873
Validation loss: 1.9666146527054489

Epoch: 6| Step: 13
Training loss: 2.277148962020874
Validation loss: 1.9733209994531447

Epoch: 125| Step: 0
Training loss: 1.4600987434387207
Validation loss: 1.958101229001117

Epoch: 6| Step: 1
Training loss: 1.4851545095443726
Validation loss: 1.9520474505680863

Epoch: 6| Step: 2
Training loss: 2.230245590209961
Validation loss: 1.952240651653659

Epoch: 6| Step: 3
Training loss: 2.5748066902160645
Validation loss: 1.9525248004544167

Epoch: 6| Step: 4
Training loss: 2.3156583309173584
Validation loss: 1.9655797558446084

Epoch: 6| Step: 5
Training loss: 2.2372007369995117
Validation loss: 1.9658440671941286

Epoch: 6| Step: 6
Training loss: 1.170783281326294
Validation loss: 1.989188080192894

Epoch: 6| Step: 7
Training loss: 2.4643330574035645
Validation loss: 2.0099474563393542

Epoch: 6| Step: 8
Training loss: 1.728073239326477
Validation loss: 2.047782290366388

Epoch: 6| Step: 9
Training loss: 1.7339211702346802
Validation loss: 2.089189365345945

Epoch: 6| Step: 10
Training loss: 1.4649600982666016
Validation loss: 2.1273982550508235

Epoch: 6| Step: 11
Training loss: 2.846548557281494
Validation loss: 2.1210055556348575

Epoch: 6| Step: 12
Training loss: 1.7145510911941528
Validation loss: 2.080991114339521

Epoch: 6| Step: 13
Training loss: 1.2827918529510498
Validation loss: 2.0634627880588656

Epoch: 126| Step: 0
Training loss: 1.578894853591919
Validation loss: 2.0414557662061465

Epoch: 6| Step: 1
Training loss: 1.6899648904800415
Validation loss: 2.001367994534072

Epoch: 6| Step: 2
Training loss: 0.9354934692382812
Validation loss: 1.999437717981236

Epoch: 6| Step: 3
Training loss: 1.7511539459228516
Validation loss: 1.9902962535940192

Epoch: 6| Step: 4
Training loss: 1.6892523765563965
Validation loss: 1.9847478174394177

Epoch: 6| Step: 5
Training loss: 2.551950216293335
Validation loss: 2.001056614742484

Epoch: 6| Step: 6
Training loss: 2.4603452682495117
Validation loss: 2.0108772887978503

Epoch: 6| Step: 7
Training loss: 2.193547248840332
Validation loss: 2.048569684387535

Epoch: 6| Step: 8
Training loss: 2.247668504714966
Validation loss: 2.060888918497229

Epoch: 6| Step: 9
Training loss: 1.3835285902023315
Validation loss: 2.0811685490351852

Epoch: 6| Step: 10
Training loss: 2.7525267601013184
Validation loss: 2.090851278715236

Epoch: 6| Step: 11
Training loss: 1.4710071086883545
Validation loss: 2.0817696727732176

Epoch: 6| Step: 12
Training loss: 2.0212557315826416
Validation loss: 2.084073708903405

Epoch: 6| Step: 13
Training loss: 2.007220983505249
Validation loss: 2.0758551756540933

Epoch: 127| Step: 0
Training loss: 1.569562554359436
Validation loss: 2.0897129492093156

Epoch: 6| Step: 1
Training loss: 2.846055030822754
Validation loss: 2.089355989169049

Epoch: 6| Step: 2
Training loss: 1.224173903465271
Validation loss: 2.0245896539380475

Epoch: 6| Step: 3
Training loss: 2.391782760620117
Validation loss: 1.9958783247137581

Epoch: 6| Step: 4
Training loss: 1.9895431995391846
Validation loss: 1.969009655778126

Epoch: 6| Step: 5
Training loss: 1.6732635498046875
Validation loss: 1.9374559092265304

Epoch: 6| Step: 6
Training loss: 2.142068862915039
Validation loss: 1.9254900050419632

Epoch: 6| Step: 7
Training loss: 1.5876246690750122
Validation loss: 1.9327392475579375

Epoch: 6| Step: 8
Training loss: 2.162487030029297
Validation loss: 1.9461715734133156

Epoch: 6| Step: 9
Training loss: 2.004268169403076
Validation loss: 1.9640445901501564

Epoch: 6| Step: 10
Training loss: 1.4550211429595947
Validation loss: 1.966200956734278

Epoch: 6| Step: 11
Training loss: 2.1476333141326904
Validation loss: 1.9910984013670234

Epoch: 6| Step: 12
Training loss: 1.4492714405059814
Validation loss: 2.0180871025208504

Epoch: 6| Step: 13
Training loss: 2.134561777114868
Validation loss: 2.0599822434045936

Epoch: 128| Step: 0
Training loss: 2.1831929683685303
Validation loss: 2.1085725176718926

Epoch: 6| Step: 1
Training loss: 1.9928512573242188
Validation loss: 2.1671800151948006

Epoch: 6| Step: 2
Training loss: 1.8885095119476318
Validation loss: 2.1683585182312997

Epoch: 6| Step: 3
Training loss: 1.6852144002914429
Validation loss: 2.1848247179421048

Epoch: 6| Step: 4
Training loss: 3.6440882682800293
Validation loss: 2.159433436650102

Epoch: 6| Step: 5
Training loss: 1.762391209602356
Validation loss: 2.132963224123883

Epoch: 6| Step: 6
Training loss: 1.766385555267334
Validation loss: 2.103383110415551

Epoch: 6| Step: 7
Training loss: 2.036592960357666
Validation loss: 2.084377916910315

Epoch: 6| Step: 8
Training loss: 1.38997220993042
Validation loss: 2.0645592879223567

Epoch: 6| Step: 9
Training loss: 1.5814945697784424
Validation loss: 2.0184111723335842

Epoch: 6| Step: 10
Training loss: 1.1865822076797485
Validation loss: 2.014805809144051

Epoch: 6| Step: 11
Training loss: 1.6794981956481934
Validation loss: 2.0222485450006302

Epoch: 6| Step: 12
Training loss: 1.9544605016708374
Validation loss: 1.996713005086427

Epoch: 6| Step: 13
Training loss: 1.9674220085144043
Validation loss: 1.9944652306136263

Epoch: 129| Step: 0
Training loss: 1.6540286540985107
Validation loss: 1.9791166026105163

Epoch: 6| Step: 1
Training loss: 2.3711025714874268
Validation loss: 1.9865514078447897

Epoch: 6| Step: 2
Training loss: 1.179814100265503
Validation loss: 1.9790346366102978

Epoch: 6| Step: 3
Training loss: 2.217912197113037
Validation loss: 1.9835925127870293

Epoch: 6| Step: 4
Training loss: 1.9017348289489746
Validation loss: 1.983250973045185

Epoch: 6| Step: 5
Training loss: 2.175159454345703
Validation loss: 1.9698160002308507

Epoch: 6| Step: 6
Training loss: 2.0564913749694824
Validation loss: 2.0095613195050146

Epoch: 6| Step: 7
Training loss: 2.2853386402130127
Validation loss: 2.032793318071673

Epoch: 6| Step: 8
Training loss: 1.3694162368774414
Validation loss: 2.0419424541534914

Epoch: 6| Step: 9
Training loss: 1.3898489475250244
Validation loss: 2.0658623454391316

Epoch: 6| Step: 10
Training loss: 1.7302238941192627
Validation loss: 2.082520846397646

Epoch: 6| Step: 11
Training loss: 1.7177445888519287
Validation loss: 2.0730027280828005

Epoch: 6| Step: 12
Training loss: 1.7735711336135864
Validation loss: 2.064371041072312

Epoch: 6| Step: 13
Training loss: 2.1053686141967773
Validation loss: 2.039241524152858

Epoch: 130| Step: 0
Training loss: 1.3898518085479736
Validation loss: 2.0262155173927225

Epoch: 6| Step: 1
Training loss: 1.6200895309448242
Validation loss: 2.031083424886068

Epoch: 6| Step: 2
Training loss: 2.0640125274658203
Validation loss: 2.026576203684653

Epoch: 6| Step: 3
Training loss: 2.0045647621154785
Validation loss: 2.050673441220355

Epoch: 6| Step: 4
Training loss: 2.3865714073181152
Validation loss: 2.0556940904227634

Epoch: 6| Step: 5
Training loss: 1.7418853044509888
Validation loss: 2.064050010455552

Epoch: 6| Step: 6
Training loss: 2.484309434890747
Validation loss: 2.0502232543883787

Epoch: 6| Step: 7
Training loss: 1.9428291320800781
Validation loss: 2.032482849654331

Epoch: 6| Step: 8
Training loss: 1.392966866493225
Validation loss: 2.0158720683026057

Epoch: 6| Step: 9
Training loss: 1.277456521987915
Validation loss: 2.0292348220784175

Epoch: 6| Step: 10
Training loss: 1.3517212867736816
Validation loss: 2.063653879268195

Epoch: 6| Step: 11
Training loss: 2.2185983657836914
Validation loss: 2.0633041422854186

Epoch: 6| Step: 12
Training loss: 1.7123805284500122
Validation loss: 2.0925240029570875

Epoch: 6| Step: 13
Training loss: 1.8213011026382446
Validation loss: 2.101452837708176

Epoch: 131| Step: 0
Training loss: 1.6748535633087158
Validation loss: 2.1139797369639077

Epoch: 6| Step: 1
Training loss: 1.9056274890899658
Validation loss: 2.1000547434694026

Epoch: 6| Step: 2
Training loss: 2.1798486709594727
Validation loss: 2.078997588926746

Epoch: 6| Step: 3
Training loss: 1.9152107238769531
Validation loss: 2.044085000150947

Epoch: 6| Step: 4
Training loss: 2.0124077796936035
Validation loss: 2.0478455584536315

Epoch: 6| Step: 5
Training loss: 1.749172568321228
Validation loss: 2.033167956977762

Epoch: 6| Step: 6
Training loss: 1.5847220420837402
Validation loss: 2.0161636132065968

Epoch: 6| Step: 7
Training loss: 2.32547926902771
Validation loss: 1.9710476783014113

Epoch: 6| Step: 8
Training loss: 1.0169103145599365
Validation loss: 1.9450654316973943

Epoch: 6| Step: 9
Training loss: 3.0385091304779053
Validation loss: 1.9293548573729813

Epoch: 6| Step: 10
Training loss: 1.4221632480621338
Validation loss: 1.9458284685688634

Epoch: 6| Step: 11
Training loss: 1.628170371055603
Validation loss: 1.9544325605515511

Epoch: 6| Step: 12
Training loss: 1.6294258832931519
Validation loss: 1.9942851271680606

Epoch: 6| Step: 13
Training loss: 2.1954092979431152
Validation loss: 2.0374065829861547

Epoch: 132| Step: 0
Training loss: 1.7002888917922974
Validation loss: 2.061886731014457

Epoch: 6| Step: 1
Training loss: 1.995987892150879
Validation loss: 2.0921528313749578

Epoch: 6| Step: 2
Training loss: 1.1445229053497314
Validation loss: 2.11372701327006

Epoch: 6| Step: 3
Training loss: 1.6003985404968262
Validation loss: 2.128432789156514

Epoch: 6| Step: 4
Training loss: 1.651690125465393
Validation loss: 2.146265104252805

Epoch: 6| Step: 5
Training loss: 2.102011203765869
Validation loss: 2.1539968777728338

Epoch: 6| Step: 6
Training loss: 1.8023905754089355
Validation loss: 2.1240143417030253

Epoch: 6| Step: 7
Training loss: 1.9491779804229736
Validation loss: 2.109315226154943

Epoch: 6| Step: 8
Training loss: 1.6513186693191528
Validation loss: 2.095260135589107

Epoch: 6| Step: 9
Training loss: 2.327423572540283
Validation loss: 2.1043503925364506

Epoch: 6| Step: 10
Training loss: 1.6247735023498535
Validation loss: 2.100758844806302

Epoch: 6| Step: 11
Training loss: 1.8995507955551147
Validation loss: 2.05715666022352

Epoch: 6| Step: 12
Training loss: 2.1760356426239014
Validation loss: 2.0224199243771133

Epoch: 6| Step: 13
Training loss: 2.4693593978881836
Validation loss: 2.0046111973383094

Epoch: 133| Step: 0
Training loss: 1.7192096710205078
Validation loss: 2.000209555831007

Epoch: 6| Step: 1
Training loss: 1.3947049379348755
Validation loss: 1.977366534612512

Epoch: 6| Step: 2
Training loss: 1.5687814950942993
Validation loss: 1.9775323380706131

Epoch: 6| Step: 3
Training loss: 1.9961129426956177
Validation loss: 1.9599051155069822

Epoch: 6| Step: 4
Training loss: 1.8058326244354248
Validation loss: 1.9360347640129827

Epoch: 6| Step: 5
Training loss: 2.268955945968628
Validation loss: 1.9308609552280878

Epoch: 6| Step: 6
Training loss: 2.090169668197632
Validation loss: 1.940487442478057

Epoch: 6| Step: 7
Training loss: 1.3004708290100098
Validation loss: 1.9293949501488799

Epoch: 6| Step: 8
Training loss: 1.7340328693389893
Validation loss: 1.947992983684745

Epoch: 6| Step: 9
Training loss: 1.9925156831741333
Validation loss: 1.964823543384511

Epoch: 6| Step: 10
Training loss: 2.221891164779663
Validation loss: 2.000777303531606

Epoch: 6| Step: 11
Training loss: 1.6439462900161743
Validation loss: 2.027014709288074

Epoch: 6| Step: 12
Training loss: 2.159911632537842
Validation loss: 2.0672900445999636

Epoch: 6| Step: 13
Training loss: 1.3413478136062622
Validation loss: 2.1022628738034155

Epoch: 134| Step: 0
Training loss: 1.7147459983825684
Validation loss: 2.1200798583287064

Epoch: 6| Step: 1
Training loss: 2.1939804553985596
Validation loss: 2.131699151890252

Epoch: 6| Step: 2
Training loss: 1.7172175645828247
Validation loss: 2.128109106453516

Epoch: 6| Step: 3
Training loss: 2.183837413787842
Validation loss: 2.0515816929519817

Epoch: 6| Step: 4
Training loss: 1.4241063594818115
Validation loss: 1.9878166721713157

Epoch: 6| Step: 5
Training loss: 1.5630860328674316
Validation loss: 1.972526950220908

Epoch: 6| Step: 6
Training loss: 1.9718749523162842
Validation loss: 1.9755782824690624

Epoch: 6| Step: 7
Training loss: 1.9825830459594727
Validation loss: 1.9759126196625412

Epoch: 6| Step: 8
Training loss: 1.5019546747207642
Validation loss: 2.000531506794755

Epoch: 6| Step: 9
Training loss: 1.916841983795166
Validation loss: 1.991716379760414

Epoch: 6| Step: 10
Training loss: 2.3998444080352783
Validation loss: 2.0038506215618503

Epoch: 6| Step: 11
Training loss: 1.7270410060882568
Validation loss: 2.0177820600489134

Epoch: 6| Step: 12
Training loss: 2.1408565044403076
Validation loss: 2.0490283196972263

Epoch: 6| Step: 13
Training loss: 1.3761335611343384
Validation loss: 2.1071840178581978

Epoch: 135| Step: 0
Training loss: 1.883910894393921
Validation loss: 2.1579647628209924

Epoch: 6| Step: 1
Training loss: 2.0365495681762695
Validation loss: 2.1787583353698894

Epoch: 6| Step: 2
Training loss: 1.6505167484283447
Validation loss: 2.196815367667906

Epoch: 6| Step: 3
Training loss: 2.2297210693359375
Validation loss: 2.1904023347362394

Epoch: 6| Step: 4
Training loss: 1.7092947959899902
Validation loss: 2.183009204044137

Epoch: 6| Step: 5
Training loss: 2.0744831562042236
Validation loss: 2.1717281956826486

Epoch: 6| Step: 6
Training loss: 1.9430961608886719
Validation loss: 2.147539759194979

Epoch: 6| Step: 7
Training loss: 2.3830223083496094
Validation loss: 2.1198164365624868

Epoch: 6| Step: 8
Training loss: 1.9194626808166504
Validation loss: 2.0971162306365145

Epoch: 6| Step: 9
Training loss: 1.7804205417633057
Validation loss: 2.0784760854577504

Epoch: 6| Step: 10
Training loss: 2.107053756713867
Validation loss: 2.0490323394857426

Epoch: 6| Step: 11
Training loss: 0.8407475352287292
Validation loss: 2.01799330916456

Epoch: 6| Step: 12
Training loss: 1.5497199296951294
Validation loss: 1.9971429917120165

Epoch: 6| Step: 13
Training loss: 0.7745511531829834
Validation loss: 1.986408318242719

Epoch: 136| Step: 0
Training loss: 2.141261100769043
Validation loss: 1.9983404708164993

Epoch: 6| Step: 1
Training loss: 1.6503419876098633
Validation loss: 1.9860718122092627

Epoch: 6| Step: 2
Training loss: 1.8197040557861328
Validation loss: 2.017295111892044

Epoch: 6| Step: 3
Training loss: 1.5509899854660034
Validation loss: 1.9988819065914358

Epoch: 6| Step: 4
Training loss: 1.8473498821258545
Validation loss: 2.0263349420280865

Epoch: 6| Step: 5
Training loss: 1.717063307762146
Validation loss: 2.063272653087493

Epoch: 6| Step: 6
Training loss: 1.372310757637024
Validation loss: 2.104605537588878

Epoch: 6| Step: 7
Training loss: 1.1171672344207764
Validation loss: 2.1095101948707335

Epoch: 6| Step: 8
Training loss: 1.1583565473556519
Validation loss: 2.1051855535917383

Epoch: 6| Step: 9
Training loss: 2.4718129634857178
Validation loss: 2.1230149089649157

Epoch: 6| Step: 10
Training loss: 2.5042548179626465
Validation loss: 2.1318472508461244

Epoch: 6| Step: 11
Training loss: 1.9732073545455933
Validation loss: 2.1147836677489744

Epoch: 6| Step: 12
Training loss: 1.9419119358062744
Validation loss: 2.1200158134583504

Epoch: 6| Step: 13
Training loss: 1.8784518241882324
Validation loss: 2.1111526463621404

Epoch: 137| Step: 0
Training loss: 1.3960126638412476
Validation loss: 2.08442622487263

Epoch: 6| Step: 1
Training loss: 1.6023956537246704
Validation loss: 2.1033196474916194

Epoch: 6| Step: 2
Training loss: 1.7682342529296875
Validation loss: 2.133363982682587

Epoch: 6| Step: 3
Training loss: 1.991245985031128
Validation loss: 2.171270357665195

Epoch: 6| Step: 4
Training loss: 1.8514988422393799
Validation loss: 2.170366197504023

Epoch: 6| Step: 5
Training loss: 1.268784761428833
Validation loss: 2.1410064415265153

Epoch: 6| Step: 6
Training loss: 2.153120994567871
Validation loss: 2.09173979297761

Epoch: 6| Step: 7
Training loss: 1.3852285146713257
Validation loss: 2.0474882228400118

Epoch: 6| Step: 8
Training loss: 1.5242552757263184
Validation loss: 2.019389484518318

Epoch: 6| Step: 9
Training loss: 1.6788434982299805
Validation loss: 1.9753890524628341

Epoch: 6| Step: 10
Training loss: 2.1288013458251953
Validation loss: 1.9609035381706812

Epoch: 6| Step: 11
Training loss: 1.9919666051864624
Validation loss: 1.9274400972550916

Epoch: 6| Step: 12
Training loss: 1.6482727527618408
Validation loss: 1.9305830091558478

Epoch: 6| Step: 13
Training loss: 2.632537364959717
Validation loss: 1.930788319597962

Epoch: 138| Step: 0
Training loss: 2.2922163009643555
Validation loss: 1.941843690410737

Epoch: 6| Step: 1
Training loss: 1.8122034072875977
Validation loss: 1.9540385841041483

Epoch: 6| Step: 2
Training loss: 1.838879108428955
Validation loss: 1.979412091675625

Epoch: 6| Step: 3
Training loss: 2.0030956268310547
Validation loss: 2.0022296238971014

Epoch: 6| Step: 4
Training loss: 1.4544756412506104
Validation loss: 2.008395928208546

Epoch: 6| Step: 5
Training loss: 1.8495019674301147
Validation loss: 2.051091745335569

Epoch: 6| Step: 6
Training loss: 1.8707125186920166
Validation loss: 2.066909783629961

Epoch: 6| Step: 7
Training loss: 1.214998483657837
Validation loss: 2.067041354794656

Epoch: 6| Step: 8
Training loss: 1.7838547229766846
Validation loss: 2.09139262219911

Epoch: 6| Step: 9
Training loss: 1.6090717315673828
Validation loss: 2.082411191796744

Epoch: 6| Step: 10
Training loss: 1.893235445022583
Validation loss: 2.088603070987168

Epoch: 6| Step: 11
Training loss: 1.2216026782989502
Validation loss: 2.0916232396197576

Epoch: 6| Step: 12
Training loss: 1.1939373016357422
Validation loss: 2.1167452566085325

Epoch: 6| Step: 13
Training loss: 3.1961100101470947
Validation loss: 2.1379051490496566

Epoch: 139| Step: 0
Training loss: 2.1313765048980713
Validation loss: 2.1550067291464856

Epoch: 6| Step: 1
Training loss: 2.141895055770874
Validation loss: 2.1401869276518464

Epoch: 6| Step: 2
Training loss: 1.83859384059906
Validation loss: 2.1135116469475532

Epoch: 6| Step: 3
Training loss: 1.6292158365249634
Validation loss: 2.0988697621130172

Epoch: 6| Step: 4
Training loss: 0.9197290539741516
Validation loss: 2.0750377690920265

Epoch: 6| Step: 5
Training loss: 1.9227523803710938
Validation loss: 2.069145684601158

Epoch: 6| Step: 6
Training loss: 1.7462425231933594
Validation loss: 2.0602546776494672

Epoch: 6| Step: 7
Training loss: 1.3003008365631104
Validation loss: 2.067518006088913

Epoch: 6| Step: 8
Training loss: 2.3051960468292236
Validation loss: 2.0631376312625025

Epoch: 6| Step: 9
Training loss: 1.2886244058609009
Validation loss: 2.050832415139803

Epoch: 6| Step: 10
Training loss: 1.514136791229248
Validation loss: 2.044509736440515

Epoch: 6| Step: 11
Training loss: 1.6779402494430542
Validation loss: 2.040883466761599

Epoch: 6| Step: 12
Training loss: 1.3453853130340576
Validation loss: 2.0350224305224676

Epoch: 6| Step: 13
Training loss: 2.2863881587982178
Validation loss: 2.037569187020743

Epoch: 140| Step: 0
Training loss: 2.6085550785064697
Validation loss: 2.0325751586626937

Epoch: 6| Step: 1
Training loss: 1.3804473876953125
Validation loss: 2.055568864268641

Epoch: 6| Step: 2
Training loss: 1.2177292108535767
Validation loss: 2.049370863104379

Epoch: 6| Step: 3
Training loss: 1.4235141277313232
Validation loss: 2.0608536017838346

Epoch: 6| Step: 4
Training loss: 1.9887022972106934
Validation loss: 2.0424410873843777

Epoch: 6| Step: 5
Training loss: 1.7580889463424683
Validation loss: 2.0002783677911244

Epoch: 6| Step: 6
Training loss: 1.7150347232818604
Validation loss: 1.986520077592583

Epoch: 6| Step: 7
Training loss: 1.6958274841308594
Validation loss: 1.9902494876615462

Epoch: 6| Step: 8
Training loss: 1.7026786804199219
Validation loss: 2.000614620024158

Epoch: 6| Step: 9
Training loss: 1.6234697103500366
Validation loss: 2.003076655890352

Epoch: 6| Step: 10
Training loss: 1.9317388534545898
Validation loss: 2.0252496709105787

Epoch: 6| Step: 11
Training loss: 1.970536470413208
Validation loss: 2.011599927820185

Epoch: 6| Step: 12
Training loss: 1.3798880577087402
Validation loss: 2.0090673687637493

Epoch: 6| Step: 13
Training loss: 1.688524842262268
Validation loss: 2.0108093484755485

Epoch: 141| Step: 0
Training loss: 1.3370914459228516
Validation loss: 2.0219892673594977

Epoch: 6| Step: 1
Training loss: 1.988486647605896
Validation loss: 2.0676765108621247

Epoch: 6| Step: 2
Training loss: 2.079118251800537
Validation loss: 2.1002208699462233

Epoch: 6| Step: 3
Training loss: 1.7226405143737793
Validation loss: 2.1089244311855686

Epoch: 6| Step: 4
Training loss: 1.347727656364441
Validation loss: 2.079727936816472

Epoch: 6| Step: 5
Training loss: 1.3246805667877197
Validation loss: 2.1021789273908063

Epoch: 6| Step: 6
Training loss: 1.7290645837783813
Validation loss: 2.0455209696164696

Epoch: 6| Step: 7
Training loss: 1.4882029294967651
Validation loss: 2.026303291320801

Epoch: 6| Step: 8
Training loss: 1.6796698570251465
Validation loss: 2.028290457622979

Epoch: 6| Step: 9
Training loss: 1.7163981199264526
Validation loss: 2.0291808779521654

Epoch: 6| Step: 10
Training loss: 1.8359355926513672
Validation loss: 2.0202411272192515

Epoch: 6| Step: 11
Training loss: 1.9197232723236084
Validation loss: 2.0120964716839533

Epoch: 6| Step: 12
Training loss: 1.9723622798919678
Validation loss: 2.01397684953546

Epoch: 6| Step: 13
Training loss: 2.197856903076172
Validation loss: 2.023798001709805

Epoch: 142| Step: 0
Training loss: 2.030153751373291
Validation loss: 2.0716752390707693

Epoch: 6| Step: 1
Training loss: 1.7284221649169922
Validation loss: 2.0949404214018132

Epoch: 6| Step: 2
Training loss: 2.4221301078796387
Validation loss: 2.1229297602048485

Epoch: 6| Step: 3
Training loss: 1.6287463903427124
Validation loss: 2.127521353383218

Epoch: 6| Step: 4
Training loss: 1.66383695602417
Validation loss: 2.124826136455741

Epoch: 6| Step: 5
Training loss: 2.4255990982055664
Validation loss: 2.1478133714327248

Epoch: 6| Step: 6
Training loss: 1.7069377899169922
Validation loss: 2.113236770834974

Epoch: 6| Step: 7
Training loss: 1.1633628606796265
Validation loss: 2.055681747774924

Epoch: 6| Step: 8
Training loss: 1.1226205825805664
Validation loss: 2.0413031654973186

Epoch: 6| Step: 9
Training loss: 1.215104341506958
Validation loss: 2.0361939232836486

Epoch: 6| Step: 10
Training loss: 1.207395315170288
Validation loss: 2.032232598591876

Epoch: 6| Step: 11
Training loss: 1.7833154201507568
Validation loss: 2.032468698358023

Epoch: 6| Step: 12
Training loss: 1.6604270935058594
Validation loss: 2.0371022403881116

Epoch: 6| Step: 13
Training loss: 2.1177988052368164
Validation loss: 2.0325032754610945

Epoch: 143| Step: 0
Training loss: 1.6355177164077759
Validation loss: 2.0155250308334187

Epoch: 6| Step: 1
Training loss: 2.0953760147094727
Validation loss: 2.0418346992103

Epoch: 6| Step: 2
Training loss: 1.7973861694335938
Validation loss: 2.0343116842290407

Epoch: 6| Step: 3
Training loss: 1.111539363861084
Validation loss: 2.0718815557418333

Epoch: 6| Step: 4
Training loss: 1.5839836597442627
Validation loss: 2.0830581008747058

Epoch: 6| Step: 5
Training loss: 1.4148094654083252
Validation loss: 2.0833021184449554

Epoch: 6| Step: 6
Training loss: 1.5934009552001953
Validation loss: 2.0968267020358833

Epoch: 6| Step: 7
Training loss: 1.4234540462493896
Validation loss: 2.076155339517901

Epoch: 6| Step: 8
Training loss: 1.7379539012908936
Validation loss: 2.0670927134893273

Epoch: 6| Step: 9
Training loss: 0.9802050590515137
Validation loss: 2.04999255236759

Epoch: 6| Step: 10
Training loss: 1.7129971981048584
Validation loss: 2.0520230057418987

Epoch: 6| Step: 11
Training loss: 1.670833706855774
Validation loss: 2.0315258451687392

Epoch: 6| Step: 12
Training loss: 2.5315189361572266
Validation loss: 2.05091671277118

Epoch: 6| Step: 13
Training loss: 2.0972681045532227
Validation loss: 2.0510509885767454

Epoch: 144| Step: 0
Training loss: 1.4842562675476074
Validation loss: 2.005339371260776

Epoch: 6| Step: 1
Training loss: 1.2441363334655762
Validation loss: 1.9767250655799784

Epoch: 6| Step: 2
Training loss: 1.2615463733673096
Validation loss: 1.9866664255819013

Epoch: 6| Step: 3
Training loss: 2.0334153175354004
Validation loss: 2.001142740249634

Epoch: 6| Step: 4
Training loss: 1.6327159404754639
Validation loss: 2.0224919396062053

Epoch: 6| Step: 5
Training loss: 1.8488731384277344
Validation loss: 2.0516263848991803

Epoch: 6| Step: 6
Training loss: 1.649936556816101
Validation loss: 2.063720680052234

Epoch: 6| Step: 7
Training loss: 1.5863945484161377
Validation loss: 2.0588993641637985

Epoch: 6| Step: 8
Training loss: 2.0991930961608887
Validation loss: 2.044917498865435

Epoch: 6| Step: 9
Training loss: 1.8242332935333252
Validation loss: 2.0412890962375108

Epoch: 6| Step: 10
Training loss: 1.443908452987671
Validation loss: 2.025932529921173

Epoch: 6| Step: 11
Training loss: 1.3399101495742798
Validation loss: 2.040935080538514

Epoch: 6| Step: 12
Training loss: 1.8188090324401855
Validation loss: 2.0387724650803434

Epoch: 6| Step: 13
Training loss: 0.6928703784942627
Validation loss: 2.0300441198451544

Epoch: 145| Step: 0
Training loss: 1.1584734916687012
Validation loss: 2.0658353938851306

Epoch: 6| Step: 1
Training loss: 2.122873544692993
Validation loss: 2.0711974559291715

Epoch: 6| Step: 2
Training loss: 1.6540664434432983
Validation loss: 2.074102847806869

Epoch: 6| Step: 3
Training loss: 1.5295071601867676
Validation loss: 2.103097447784998

Epoch: 6| Step: 4
Training loss: 1.617781639099121
Validation loss: 2.127133478400528

Epoch: 6| Step: 5
Training loss: 1.6690160036087036
Validation loss: 2.1167245347012758

Epoch: 6| Step: 6
Training loss: 1.3181793689727783
Validation loss: 2.109934353059338

Epoch: 6| Step: 7
Training loss: 1.663748025894165
Validation loss: 2.09755358388347

Epoch: 6| Step: 8
Training loss: 1.4680520296096802
Validation loss: 2.1012820351508354

Epoch: 6| Step: 9
Training loss: 2.137763738632202
Validation loss: 2.0634247423500143

Epoch: 6| Step: 10
Training loss: 1.648118019104004
Validation loss: 2.0112895170847573

Epoch: 6| Step: 11
Training loss: 1.512502670288086
Validation loss: 1.981008985991119

Epoch: 6| Step: 12
Training loss: 1.1345807313919067
Validation loss: 1.9802631537119548

Epoch: 6| Step: 13
Training loss: 1.8418363332748413
Validation loss: 1.9729840755462646

Epoch: 146| Step: 0
Training loss: 1.69059419631958
Validation loss: 1.955642859141032

Epoch: 6| Step: 1
Training loss: 1.9274159669876099
Validation loss: 1.926068800751881

Epoch: 6| Step: 2
Training loss: 1.6751368045806885
Validation loss: 1.9186732576739403

Epoch: 6| Step: 3
Training loss: 2.069859027862549
Validation loss: 1.9041822469362648

Epoch: 6| Step: 4
Training loss: 1.136864423751831
Validation loss: 1.90086833764148

Epoch: 6| Step: 5
Training loss: 1.836143970489502
Validation loss: 1.8931237215636878

Epoch: 6| Step: 6
Training loss: 1.1064655780792236
Validation loss: 1.9300654549752512

Epoch: 6| Step: 7
Training loss: 1.8132610321044922
Validation loss: 1.9374214923509987

Epoch: 6| Step: 8
Training loss: 1.8049733638763428
Validation loss: 1.995413839176137

Epoch: 6| Step: 9
Training loss: 1.9219175577163696
Validation loss: 2.018576778391356

Epoch: 6| Step: 10
Training loss: 1.342307686805725
Validation loss: 2.0304128610959618

Epoch: 6| Step: 11
Training loss: 1.1021935939788818
Validation loss: 2.0510679675686743

Epoch: 6| Step: 12
Training loss: 2.0500471591949463
Validation loss: 2.0308379511679373

Epoch: 6| Step: 13
Training loss: 1.132478952407837
Validation loss: 2.0119455296506166

Epoch: 147| Step: 0
Training loss: 1.8915464878082275
Validation loss: 1.98199793728449

Epoch: 6| Step: 1
Training loss: 1.3370009660720825
Validation loss: 1.9393059899730067

Epoch: 6| Step: 2
Training loss: 1.9964542388916016
Validation loss: 1.9378358035959222

Epoch: 6| Step: 3
Training loss: 1.8961572647094727
Validation loss: 1.9314491184808875

Epoch: 6| Step: 4
Training loss: 2.0564255714416504
Validation loss: 1.9531210699389059

Epoch: 6| Step: 5
Training loss: 1.5946507453918457
Validation loss: 1.968161339400917

Epoch: 6| Step: 6
Training loss: 1.112142562866211
Validation loss: 1.9982615183758479

Epoch: 6| Step: 7
Training loss: 1.2494535446166992
Validation loss: 1.9805360250575568

Epoch: 6| Step: 8
Training loss: 1.311126947402954
Validation loss: 1.9865645798303748

Epoch: 6| Step: 9
Training loss: 1.4499245882034302
Validation loss: 1.9656973449132775

Epoch: 6| Step: 10
Training loss: 1.472615122795105
Validation loss: 1.9567797722355011

Epoch: 6| Step: 11
Training loss: 1.5122425556182861
Validation loss: 1.9723300318564139

Epoch: 6| Step: 12
Training loss: 1.5630567073822021
Validation loss: 1.9969156519059212

Epoch: 6| Step: 13
Training loss: 1.7269471883773804
Validation loss: 1.9919691470361525

Epoch: 148| Step: 0
Training loss: 1.2282402515411377
Validation loss: 1.9870828531121696

Epoch: 6| Step: 1
Training loss: 1.4639509916305542
Validation loss: 2.0020753055490474

Epoch: 6| Step: 2
Training loss: 1.091201901435852
Validation loss: 1.9963614351005965

Epoch: 6| Step: 3
Training loss: 2.2846362590789795
Validation loss: 1.982895787044238

Epoch: 6| Step: 4
Training loss: 1.185981035232544
Validation loss: 1.9648502283198859

Epoch: 6| Step: 5
Training loss: 1.7489545345306396
Validation loss: 1.949450369804136

Epoch: 6| Step: 6
Training loss: 1.5628643035888672
Validation loss: 1.9567700034828597

Epoch: 6| Step: 7
Training loss: 1.6803152561187744
Validation loss: 1.953538058906473

Epoch: 6| Step: 8
Training loss: 1.4063868522644043
Validation loss: 1.937908677644627

Epoch: 6| Step: 9
Training loss: 1.8146787881851196
Validation loss: 1.9625481290201987

Epoch: 6| Step: 10
Training loss: 1.62929105758667
Validation loss: 1.9665169946609005

Epoch: 6| Step: 11
Training loss: 1.521348237991333
Validation loss: 1.9637492600307669

Epoch: 6| Step: 12
Training loss: 1.4096825122833252
Validation loss: 1.9673367302904847

Epoch: 6| Step: 13
Training loss: 1.7916693687438965
Validation loss: 1.9506031364522955

Epoch: 149| Step: 0
Training loss: 1.5530869960784912
Validation loss: 1.9391376049287858

Epoch: 6| Step: 1
Training loss: 1.2908716201782227
Validation loss: 1.9259201570223736

Epoch: 6| Step: 2
Training loss: 1.5450069904327393
Validation loss: 1.941401885401818

Epoch: 6| Step: 3
Training loss: 1.280847191810608
Validation loss: 1.9601008122967136

Epoch: 6| Step: 4
Training loss: 0.966928243637085
Validation loss: 1.9545325822727655

Epoch: 6| Step: 5
Training loss: 1.9859619140625
Validation loss: 1.9264332837955926

Epoch: 6| Step: 6
Training loss: 1.7178986072540283
Validation loss: 1.9222377525862826

Epoch: 6| Step: 7
Training loss: 2.1109490394592285
Validation loss: 1.921668916620234

Epoch: 6| Step: 8
Training loss: 1.8810787200927734
Validation loss: 1.9321182209958312

Epoch: 6| Step: 9
Training loss: 1.5033928155899048
Validation loss: 1.9323645817336215

Epoch: 6| Step: 10
Training loss: 1.7463487386703491
Validation loss: 1.9563774780560566

Epoch: 6| Step: 11
Training loss: 1.2437925338745117
Validation loss: 1.9578951353667884

Epoch: 6| Step: 12
Training loss: 1.3600399494171143
Validation loss: 1.9730199818970056

Epoch: 6| Step: 13
Training loss: 1.3825852870941162
Validation loss: 1.9630322866542365

Epoch: 150| Step: 0
Training loss: 1.7744433879852295
Validation loss: 1.9452308813730876

Epoch: 6| Step: 1
Training loss: 1.2355523109436035
Validation loss: 1.946985508805962

Epoch: 6| Step: 2
Training loss: 1.6137418746948242
Validation loss: 1.9141301032035583

Epoch: 6| Step: 3
Training loss: 1.510711431503296
Validation loss: 1.929871884725427

Epoch: 6| Step: 4
Training loss: 1.1182286739349365
Validation loss: 1.9037138774830809

Epoch: 6| Step: 5
Training loss: 1.2949457168579102
Validation loss: 1.896972922868626

Epoch: 6| Step: 6
Training loss: 1.5386908054351807
Validation loss: 1.9231569895180323

Epoch: 6| Step: 7
Training loss: 1.6983495950698853
Validation loss: 1.902067348521243

Epoch: 6| Step: 8
Training loss: 1.3687078952789307
Validation loss: 1.9159700409058602

Epoch: 6| Step: 9
Training loss: 2.013339042663574
Validation loss: 1.9650796792840446

Epoch: 6| Step: 10
Training loss: 1.3300055265426636
Validation loss: 2.0042234454103696

Epoch: 6| Step: 11
Training loss: 1.285079002380371
Validation loss: 2.0097240683852986

Epoch: 6| Step: 12
Training loss: 1.7460920810699463
Validation loss: 2.0231713312928394

Epoch: 6| Step: 13
Training loss: 1.6384546756744385
Validation loss: 2.0107620569967453

Epoch: 151| Step: 0
Training loss: 1.435947060585022
Validation loss: 1.9769137008215791

Epoch: 6| Step: 1
Training loss: 1.5560758113861084
Validation loss: 1.9639898718044322

Epoch: 6| Step: 2
Training loss: 1.9441474676132202
Validation loss: 1.9424644106177873

Epoch: 6| Step: 3
Training loss: 1.576331377029419
Validation loss: 1.9417316234239967

Epoch: 6| Step: 4
Training loss: 1.6788301467895508
Validation loss: 1.935603500694357

Epoch: 6| Step: 5
Training loss: 1.1708779335021973
Validation loss: 1.9318083909250074

Epoch: 6| Step: 6
Training loss: 0.9596325159072876
Validation loss: 1.9256529987499278

Epoch: 6| Step: 7
Training loss: 1.028780460357666
Validation loss: 1.9373080589437996

Epoch: 6| Step: 8
Training loss: 1.2860687971115112
Validation loss: 1.931178549284576

Epoch: 6| Step: 9
Training loss: 1.7846497297286987
Validation loss: 1.9467493539215417

Epoch: 6| Step: 10
Training loss: 1.700456976890564
Validation loss: 1.9728295033977878

Epoch: 6| Step: 11
Training loss: 1.7352088689804077
Validation loss: 1.971590054932461

Epoch: 6| Step: 12
Training loss: 1.0126862525939941
Validation loss: 1.9814853706667501

Epoch: 6| Step: 13
Training loss: 2.568437099456787
Validation loss: 1.9940906929713424

Epoch: 152| Step: 0
Training loss: 1.1380774974822998
Validation loss: 1.983349379672799

Epoch: 6| Step: 1
Training loss: 1.1176866292953491
Validation loss: 1.9667599867748957

Epoch: 6| Step: 2
Training loss: 1.281595230102539
Validation loss: 1.9418883990215998

Epoch: 6| Step: 3
Training loss: 2.0848946571350098
Validation loss: 1.9400691447719451

Epoch: 6| Step: 4
Training loss: 1.4012677669525146
Validation loss: 1.9171766311891618

Epoch: 6| Step: 5
Training loss: 1.3833106756210327
Validation loss: 1.9033759922109625

Epoch: 6| Step: 6
Training loss: 2.0093934535980225
Validation loss: 1.8976889246253557

Epoch: 6| Step: 7
Training loss: 1.713953971862793
Validation loss: 1.8976412909005278

Epoch: 6| Step: 8
Training loss: 1.3728418350219727
Validation loss: 1.9155652651222803

Epoch: 6| Step: 9
Training loss: 1.2373658418655396
Validation loss: 1.9398782099446943

Epoch: 6| Step: 10
Training loss: 1.741349220275879
Validation loss: 1.954083937470631

Epoch: 6| Step: 11
Training loss: 1.8478672504425049
Validation loss: 1.949769353353849

Epoch: 6| Step: 12
Training loss: 1.0650699138641357
Validation loss: 1.9719446910324918

Epoch: 6| Step: 13
Training loss: 1.2290719747543335
Validation loss: 1.9575894468574113

Epoch: 153| Step: 0
Training loss: 1.1825518608093262
Validation loss: 1.9763801264506515

Epoch: 6| Step: 1
Training loss: 1.9506832361221313
Validation loss: 1.963130763781968

Epoch: 6| Step: 2
Training loss: 1.4104773998260498
Validation loss: 1.9844947707268499

Epoch: 6| Step: 3
Training loss: 1.4574905633926392
Validation loss: 1.9801015597517773

Epoch: 6| Step: 4
Training loss: 1.624009609222412
Validation loss: 1.999527863276902

Epoch: 6| Step: 5
Training loss: 0.9464281797409058
Validation loss: 1.978407782893027

Epoch: 6| Step: 6
Training loss: 1.9673454761505127
Validation loss: 1.9809873565550773

Epoch: 6| Step: 7
Training loss: 1.4919779300689697
Validation loss: 1.9411663637366345

Epoch: 6| Step: 8
Training loss: 1.4302005767822266
Validation loss: 1.9492458489633375

Epoch: 6| Step: 9
Training loss: 1.2894819974899292
Validation loss: 1.943738281085927

Epoch: 6| Step: 10
Training loss: 1.2169458866119385
Validation loss: 1.9455538847113167

Epoch: 6| Step: 11
Training loss: 1.6350362300872803
Validation loss: 1.9140500035337222

Epoch: 6| Step: 12
Training loss: 1.6353354454040527
Validation loss: 1.9092819882977394

Epoch: 6| Step: 13
Training loss: 1.6691784858703613
Validation loss: 1.8868165003356112

Epoch: 154| Step: 0
Training loss: 1.4953556060791016
Validation loss: 1.913045806269492

Epoch: 6| Step: 1
Training loss: 1.1686885356903076
Validation loss: 1.9143208919032928

Epoch: 6| Step: 2
Training loss: 1.4556682109832764
Validation loss: 1.9380864045953239

Epoch: 6| Step: 3
Training loss: 2.1014983654022217
Validation loss: 1.9610537149572884

Epoch: 6| Step: 4
Training loss: 1.416473627090454
Validation loss: 1.9794475788711219

Epoch: 6| Step: 5
Training loss: 1.731821060180664
Validation loss: 1.9847178715531544

Epoch: 6| Step: 6
Training loss: 1.0516338348388672
Validation loss: 1.9781263374513196

Epoch: 6| Step: 7
Training loss: 1.5988333225250244
Validation loss: 1.982530237526022

Epoch: 6| Step: 8
Training loss: 1.0902973413467407
Validation loss: 1.9751814744805778

Epoch: 6| Step: 9
Training loss: 1.7322325706481934
Validation loss: 1.9509545795379146

Epoch: 6| Step: 10
Training loss: 0.9655488133430481
Validation loss: 1.9538388944441272

Epoch: 6| Step: 11
Training loss: 1.2340704202651978
Validation loss: 1.952616125024775

Epoch: 6| Step: 12
Training loss: 1.7212904691696167
Validation loss: 1.9350102075966455

Epoch: 6| Step: 13
Training loss: 1.7050734758377075
Validation loss: 1.950590661776963

Epoch: 155| Step: 0
Training loss: 1.3388943672180176
Validation loss: 1.946964163934031

Epoch: 6| Step: 1
Training loss: 1.2127158641815186
Validation loss: 1.9285213588386454

Epoch: 6| Step: 2
Training loss: 0.9873974323272705
Validation loss: 1.9160121166577904

Epoch: 6| Step: 3
Training loss: 2.1145577430725098
Validation loss: 1.9243147860291183

Epoch: 6| Step: 4
Training loss: 1.3020904064178467
Validation loss: 1.9096432706361175

Epoch: 6| Step: 5
Training loss: 1.324092984199524
Validation loss: 1.9019563146816787

Epoch: 6| Step: 6
Training loss: 1.5306518077850342
Validation loss: 1.8748617608060119

Epoch: 6| Step: 7
Training loss: 1.340278148651123
Validation loss: 1.9046205525757165

Epoch: 6| Step: 8
Training loss: 1.558489441871643
Validation loss: 1.897480587805471

Epoch: 6| Step: 9
Training loss: 1.3681583404541016
Validation loss: 1.9098697541862406

Epoch: 6| Step: 10
Training loss: 1.3763161897659302
Validation loss: 1.9069729235864454

Epoch: 6| Step: 11
Training loss: 1.5982964038848877
Validation loss: 1.9279616186695714

Epoch: 6| Step: 12
Training loss: 1.916163682937622
Validation loss: 1.9234581121834375

Epoch: 6| Step: 13
Training loss: 1.4793322086334229
Validation loss: 1.9081236970040105

Epoch: 156| Step: 0
Training loss: 1.8139944076538086
Validation loss: 1.8930978070023239

Epoch: 6| Step: 1
Training loss: 0.9196020364761353
Validation loss: 1.8887707264192644

Epoch: 6| Step: 2
Training loss: 1.378815770149231
Validation loss: 1.8807214998429822

Epoch: 6| Step: 3
Training loss: 1.0932433605194092
Validation loss: 1.8636289655521352

Epoch: 6| Step: 4
Training loss: 1.421169638633728
Validation loss: 1.859994646041624

Epoch: 6| Step: 5
Training loss: 1.3760960102081299
Validation loss: 1.872084418932597

Epoch: 6| Step: 6
Training loss: 1.1361725330352783
Validation loss: 1.8788814826678204

Epoch: 6| Step: 7
Training loss: 1.242485761642456
Validation loss: 1.893176922234156

Epoch: 6| Step: 8
Training loss: 1.808068037033081
Validation loss: 1.9083903117846417

Epoch: 6| Step: 9
Training loss: 1.5029637813568115
Validation loss: 1.9290737362318142

Epoch: 6| Step: 10
Training loss: 1.250361680984497
Validation loss: 1.9187271723183252

Epoch: 6| Step: 11
Training loss: 2.243378162384033
Validation loss: 1.9012200447820848

Epoch: 6| Step: 12
Training loss: 0.8068416714668274
Validation loss: 1.8977992957638157

Epoch: 6| Step: 13
Training loss: 2.0712764263153076
Validation loss: 1.8977331781900058

Epoch: 157| Step: 0
Training loss: 1.4351128339767456
Validation loss: 1.908181434036583

Epoch: 6| Step: 1
Training loss: 1.6604944467544556
Validation loss: 1.9162352854205715

Epoch: 6| Step: 2
Training loss: 1.4288887977600098
Validation loss: 1.937918742497762

Epoch: 6| Step: 3
Training loss: 1.4540948867797852
Validation loss: 1.9190362768788491

Epoch: 6| Step: 4
Training loss: 1.2040858268737793
Validation loss: 1.9460403611583095

Epoch: 6| Step: 5
Training loss: 1.1529600620269775
Validation loss: 1.9969279689173545

Epoch: 6| Step: 6
Training loss: 1.586962103843689
Validation loss: 1.9944069308619345

Epoch: 6| Step: 7
Training loss: 1.843146562576294
Validation loss: 2.004626493300161

Epoch: 6| Step: 8
Training loss: 1.754241943359375
Validation loss: 2.0185798009236655

Epoch: 6| Step: 9
Training loss: 0.7858734130859375
Validation loss: 1.9979113840287732

Epoch: 6| Step: 10
Training loss: 1.1314984560012817
Validation loss: 1.9761061232577088

Epoch: 6| Step: 11
Training loss: 0.949772298336029
Validation loss: 1.9624496916288972

Epoch: 6| Step: 12
Training loss: 1.6245847940444946
Validation loss: 1.917348228475099

Epoch: 6| Step: 13
Training loss: 1.8648734092712402
Validation loss: 1.9055947360172067

Epoch: 158| Step: 0
Training loss: 1.1744731664657593
Validation loss: 1.8911097690623293

Epoch: 6| Step: 1
Training loss: 1.4089293479919434
Validation loss: 1.860329338299331

Epoch: 6| Step: 2
Training loss: 1.4864457845687866
Validation loss: 1.864768100041215

Epoch: 6| Step: 3
Training loss: 1.6438446044921875
Validation loss: 1.8665432609537596

Epoch: 6| Step: 4
Training loss: 1.7807340621948242
Validation loss: 1.8697280422333749

Epoch: 6| Step: 5
Training loss: 1.4345588684082031
Validation loss: 1.87310331098495

Epoch: 6| Step: 6
Training loss: 1.1796200275421143
Validation loss: 1.8887609089574506

Epoch: 6| Step: 7
Training loss: 1.579988718032837
Validation loss: 1.8842977298203336

Epoch: 6| Step: 8
Training loss: 0.7465355396270752
Validation loss: 1.8843524353478545

Epoch: 6| Step: 9
Training loss: 0.8479580283164978
Validation loss: 1.8661607721800446

Epoch: 6| Step: 10
Training loss: 1.6840513944625854
Validation loss: 1.872646236932406

Epoch: 6| Step: 11
Training loss: 1.2767579555511475
Validation loss: 1.8661242826010591

Epoch: 6| Step: 12
Training loss: 1.9438802003860474
Validation loss: 1.8702822821114653

Epoch: 6| Step: 13
Training loss: 1.5020586252212524
Validation loss: 1.891420720725931

Epoch: 159| Step: 0
Training loss: 1.4095861911773682
Validation loss: 1.90364791757317

Epoch: 6| Step: 1
Training loss: 1.6971144676208496
Validation loss: 1.8931524151115007

Epoch: 6| Step: 2
Training loss: 1.1017340421676636
Validation loss: 1.9239765867110221

Epoch: 6| Step: 3
Training loss: 1.5497357845306396
Validation loss: 1.9650044492495957

Epoch: 6| Step: 4
Training loss: 1.002407431602478
Validation loss: 1.9674647059491885

Epoch: 6| Step: 5
Training loss: 1.2547752857208252
Validation loss: 1.9889801830373786

Epoch: 6| Step: 6
Training loss: 1.1802897453308105
Validation loss: 1.9940849863072878

Epoch: 6| Step: 7
Training loss: 1.2052226066589355
Validation loss: 1.9872363446861185

Epoch: 6| Step: 8
Training loss: 1.7311713695526123
Validation loss: 1.9523327991526613

Epoch: 6| Step: 9
Training loss: 1.6035270690917969
Validation loss: 1.9515254112981981

Epoch: 6| Step: 10
Training loss: 1.5291773080825806
Validation loss: 1.9273870401484992

Epoch: 6| Step: 11
Training loss: 1.2958595752716064
Validation loss: 1.905735420924361

Epoch: 6| Step: 12
Training loss: 1.5933642387390137
Validation loss: 1.8962274700082757

Epoch: 6| Step: 13
Training loss: 0.6020859479904175
Validation loss: 1.8879358608235595

Epoch: 160| Step: 0
Training loss: 1.4971368312835693
Validation loss: 1.9243521792914278

Epoch: 6| Step: 1
Training loss: 1.457740068435669
Validation loss: 1.9321283768582087

Epoch: 6| Step: 2
Training loss: 1.1092166900634766
Validation loss: 1.9749881798221218

Epoch: 6| Step: 3
Training loss: 1.938122034072876
Validation loss: 1.9508211048700477

Epoch: 6| Step: 4
Training loss: 1.2701727151870728
Validation loss: 1.9502406107482089

Epoch: 6| Step: 5
Training loss: 1.3339347839355469
Validation loss: 1.9320781307835733

Epoch: 6| Step: 6
Training loss: 1.2139173746109009
Validation loss: 1.9332872923984323

Epoch: 6| Step: 7
Training loss: 1.0689141750335693
Validation loss: 1.9213424626217093

Epoch: 6| Step: 8
Training loss: 1.3201611042022705
Validation loss: 1.8994107323308145

Epoch: 6| Step: 9
Training loss: 1.3291449546813965
Validation loss: 1.8856689635143484

Epoch: 6| Step: 10
Training loss: 1.9069880247116089
Validation loss: 1.8805561142583047

Epoch: 6| Step: 11
Training loss: 0.9278932213783264
Validation loss: 1.8830266332113614

Epoch: 6| Step: 12
Training loss: 0.7321943640708923
Validation loss: 1.9005066720388268

Epoch: 6| Step: 13
Training loss: 2.2234339714050293
Validation loss: 1.9039478173819921

Epoch: 161| Step: 0
Training loss: 0.6840418577194214
Validation loss: 1.8962113600905224

Epoch: 6| Step: 1
Training loss: 0.9140053391456604
Validation loss: 1.8748404184977214

Epoch: 6| Step: 2
Training loss: 1.648085594177246
Validation loss: 1.9152897070812922

Epoch: 6| Step: 3
Training loss: 1.5013372898101807
Validation loss: 1.917493930426977

Epoch: 6| Step: 4
Training loss: 1.6153278350830078
Validation loss: 1.9317174342370802

Epoch: 6| Step: 5
Training loss: 1.4911203384399414
Validation loss: 1.9389535598857428

Epoch: 6| Step: 6
Training loss: 1.3837730884552002
Validation loss: 1.9438688652489775

Epoch: 6| Step: 7
Training loss: 1.4802429676055908
Validation loss: 1.9385031282260854

Epoch: 6| Step: 8
Training loss: 1.1549851894378662
Validation loss: 1.9361942801424252

Epoch: 6| Step: 9
Training loss: 1.5744785070419312
Validation loss: 1.8961227132428078

Epoch: 6| Step: 10
Training loss: 1.1961209774017334
Validation loss: 1.873787264670095

Epoch: 6| Step: 11
Training loss: 1.658266544342041
Validation loss: 1.858172421814293

Epoch: 6| Step: 12
Training loss: 0.9171831607818604
Validation loss: 1.8630471114189393

Epoch: 6| Step: 13
Training loss: 1.5482498407363892
Validation loss: 1.8586200667965798

Epoch: 162| Step: 0
Training loss: 1.0839508771896362
Validation loss: 1.8668114895461707

Epoch: 6| Step: 1
Training loss: 1.2832788228988647
Validation loss: 1.8706625661542338

Epoch: 6| Step: 2
Training loss: 1.3383634090423584
Validation loss: 1.8773183079176052

Epoch: 6| Step: 3
Training loss: 1.1287504434585571
Validation loss: 1.9220171128549883

Epoch: 6| Step: 4
Training loss: 1.4530638456344604
Validation loss: 1.9227410965068366

Epoch: 6| Step: 5
Training loss: 1.4680311679840088
Validation loss: 1.93815101474844

Epoch: 6| Step: 6
Training loss: 1.428356647491455
Validation loss: 1.9382736349618563

Epoch: 6| Step: 7
Training loss: 1.1358261108398438
Validation loss: 1.9306972808735345

Epoch: 6| Step: 8
Training loss: 1.8429268598556519
Validation loss: 1.9050331538723362

Epoch: 6| Step: 9
Training loss: 1.5931847095489502
Validation loss: 1.9332178408099758

Epoch: 6| Step: 10
Training loss: 1.5217444896697998
Validation loss: 1.9399673913114814

Epoch: 6| Step: 11
Training loss: 1.3046340942382812
Validation loss: 1.917087580568047

Epoch: 6| Step: 12
Training loss: 0.8711817264556885
Validation loss: 1.9111013822658087

Epoch: 6| Step: 13
Training loss: 1.1231746673583984
Validation loss: 1.9013692255943053

Epoch: 163| Step: 0
Training loss: 1.1209707260131836
Validation loss: 1.8732947534130466

Epoch: 6| Step: 1
Training loss: 1.4241374731063843
Validation loss: 1.8816975265420892

Epoch: 6| Step: 2
Training loss: 1.5248961448669434
Validation loss: 1.8810894232924267

Epoch: 6| Step: 3
Training loss: 1.3176939487457275
Validation loss: 1.9037722759349371

Epoch: 6| Step: 4
Training loss: 1.5268213748931885
Validation loss: 1.8864998407261346

Epoch: 6| Step: 5
Training loss: 1.1269761323928833
Validation loss: 1.8859378201987154

Epoch: 6| Step: 6
Training loss: 1.6761165857315063
Validation loss: 1.9148697635178924

Epoch: 6| Step: 7
Training loss: 1.4838736057281494
Validation loss: 1.918102051622124

Epoch: 6| Step: 8
Training loss: 1.0202717781066895
Validation loss: 1.9182428608658493

Epoch: 6| Step: 9
Training loss: 1.0071076154708862
Validation loss: 1.9223159679802515

Epoch: 6| Step: 10
Training loss: 1.412671685218811
Validation loss: 1.9316535803579515

Epoch: 6| Step: 11
Training loss: 1.0924535989761353
Validation loss: 1.9587724080649755

Epoch: 6| Step: 12
Training loss: 1.329001784324646
Validation loss: 1.941187197162259

Epoch: 6| Step: 13
Training loss: 1.9007601737976074
Validation loss: 1.9643197931269163

Epoch: 164| Step: 0
Training loss: 1.456276774406433
Validation loss: 1.9614079742021457

Epoch: 6| Step: 1
Training loss: 1.2643492221832275
Validation loss: 1.9536315766713952

Epoch: 6| Step: 2
Training loss: 0.5450474619865417
Validation loss: 1.9331516065905172

Epoch: 6| Step: 3
Training loss: 0.9469273090362549
Validation loss: 1.9219355403736074

Epoch: 6| Step: 4
Training loss: 1.200011968612671
Validation loss: 1.9156116285631735

Epoch: 6| Step: 5
Training loss: 1.2393975257873535
Validation loss: 1.903502493776301

Epoch: 6| Step: 6
Training loss: 1.3450034856796265
Validation loss: 1.881920595322886

Epoch: 6| Step: 7
Training loss: 1.476374864578247
Validation loss: 1.9165584348863172

Epoch: 6| Step: 8
Training loss: 1.7430840730667114
Validation loss: 1.9215217918478034

Epoch: 6| Step: 9
Training loss: 1.3483288288116455
Validation loss: 1.9485284128496725

Epoch: 6| Step: 10
Training loss: 0.9705634117126465
Validation loss: 1.9475877490094913

Epoch: 6| Step: 11
Training loss: 1.3618578910827637
Validation loss: 1.9056667961100096

Epoch: 6| Step: 12
Training loss: 1.4241324663162231
Validation loss: 1.9118068000321746

Epoch: 6| Step: 13
Training loss: 2.259371757507324
Validation loss: 1.8951367896090272

Epoch: 165| Step: 0
Training loss: 0.6252634525299072
Validation loss: 1.9033100771647629

Epoch: 6| Step: 1
Training loss: 1.4270422458648682
Validation loss: 1.9121360509626326

Epoch: 6| Step: 2
Training loss: 1.5897102355957031
Validation loss: 1.9244384086260231

Epoch: 6| Step: 3
Training loss: 1.7018252611160278
Validation loss: 1.9382244297253188

Epoch: 6| Step: 4
Training loss: 1.5314689874649048
Validation loss: 1.9370348991886261

Epoch: 6| Step: 5
Training loss: 1.2820297479629517
Validation loss: 1.9429180314463954

Epoch: 6| Step: 6
Training loss: 1.7728278636932373
Validation loss: 1.917819767869929

Epoch: 6| Step: 7
Training loss: 1.35148024559021
Validation loss: 1.8862546643903177

Epoch: 6| Step: 8
Training loss: 0.8281441926956177
Validation loss: 1.8749997558132294

Epoch: 6| Step: 9
Training loss: 1.5079905986785889
Validation loss: 1.860512589895597

Epoch: 6| Step: 10
Training loss: 1.5103774070739746
Validation loss: 1.8446468883945095

Epoch: 6| Step: 11
Training loss: 1.2000102996826172
Validation loss: 1.8513430421070387

Epoch: 6| Step: 12
Training loss: 1.5562009811401367
Validation loss: 1.8761249037199124

Epoch: 6| Step: 13
Training loss: 0.2782803475856781
Validation loss: 1.8741582619246615

Epoch: 166| Step: 0
Training loss: 1.1521614789962769
Validation loss: 1.8956997856017082

Epoch: 6| Step: 1
Training loss: 1.6215338706970215
Validation loss: 1.9104306069753503

Epoch: 6| Step: 2
Training loss: 0.9790593385696411
Validation loss: 1.9287349024126608

Epoch: 6| Step: 3
Training loss: 1.5383738279342651
Validation loss: 1.9655365200452908

Epoch: 6| Step: 4
Training loss: 1.009433627128601
Validation loss: 1.9701528395375898

Epoch: 6| Step: 5
Training loss: 1.2098090648651123
Validation loss: 1.9181435069730204

Epoch: 6| Step: 6
Training loss: 1.6401759386062622
Validation loss: 1.9256343213460778

Epoch: 6| Step: 7
Training loss: 1.653148889541626
Validation loss: 1.8609710854868735

Epoch: 6| Step: 8
Training loss: 1.171600341796875
Validation loss: 1.8783507116379277

Epoch: 6| Step: 9
Training loss: 1.186263084411621
Validation loss: 1.9036874809572775

Epoch: 6| Step: 10
Training loss: 1.6868219375610352
Validation loss: 1.92047107091514

Epoch: 6| Step: 11
Training loss: 0.6310979127883911
Validation loss: 1.923175532330749

Epoch: 6| Step: 12
Training loss: 1.405038595199585
Validation loss: 1.9305714035546908

Epoch: 6| Step: 13
Training loss: 0.9329216480255127
Validation loss: 1.9361185053343415

Epoch: 167| Step: 0
Training loss: 1.326729416847229
Validation loss: 2.014883064454602

Epoch: 6| Step: 1
Training loss: 1.0367430448532104
Validation loss: 2.0480872969473563

Epoch: 6| Step: 2
Training loss: 1.717078447341919
Validation loss: 2.065400864488335

Epoch: 6| Step: 3
Training loss: 1.0624489784240723
Validation loss: 2.0510756046541276

Epoch: 6| Step: 4
Training loss: 1.3059537410736084
Validation loss: 2.0150926369492725

Epoch: 6| Step: 5
Training loss: 1.5078761577606201
Validation loss: 1.9558797626085178

Epoch: 6| Step: 6
Training loss: 1.1734808683395386
Validation loss: 1.9212456108421407

Epoch: 6| Step: 7
Training loss: 1.1236034631729126
Validation loss: 1.887445096046694

Epoch: 6| Step: 8
Training loss: 1.4536607265472412
Validation loss: 1.8784987593209872

Epoch: 6| Step: 9
Training loss: 1.3403609991073608
Validation loss: 1.869226945343838

Epoch: 6| Step: 10
Training loss: 1.8612403869628906
Validation loss: 1.8938422690155685

Epoch: 6| Step: 11
Training loss: 0.9910570383071899
Validation loss: 1.8969470198436449

Epoch: 6| Step: 12
Training loss: 0.8033690452575684
Validation loss: 1.890505608691964

Epoch: 6| Step: 13
Training loss: 1.9996471405029297
Validation loss: 1.8959338754735968

Epoch: 168| Step: 0
Training loss: 1.131110668182373
Validation loss: 1.8902508738220378

Epoch: 6| Step: 1
Training loss: 1.403078556060791
Validation loss: 1.9013633971573205

Epoch: 6| Step: 2
Training loss: 1.16267991065979
Validation loss: 1.8718265141210249

Epoch: 6| Step: 3
Training loss: 1.5683481693267822
Validation loss: 1.895342085951118

Epoch: 6| Step: 4
Training loss: 1.0259079933166504
Validation loss: 1.8578510745879142

Epoch: 6| Step: 5
Training loss: 1.6230864524841309
Validation loss: 1.8560143927092194

Epoch: 6| Step: 6
Training loss: 0.8606237173080444
Validation loss: 1.8394289401269728

Epoch: 6| Step: 7
Training loss: 0.8517653346061707
Validation loss: 1.8443061561994656

Epoch: 6| Step: 8
Training loss: 1.1996723413467407
Validation loss: 1.8612774469519173

Epoch: 6| Step: 9
Training loss: 1.4298007488250732
Validation loss: 1.8486017514300603

Epoch: 6| Step: 10
Training loss: 1.5830175876617432
Validation loss: 1.8536873235497424

Epoch: 6| Step: 11
Training loss: 1.194514274597168
Validation loss: 1.8794518875819382

Epoch: 6| Step: 12
Training loss: 1.1089673042297363
Validation loss: 1.9092173063626854

Epoch: 6| Step: 13
Training loss: 1.0778496265411377
Validation loss: 1.954304684874832

Epoch: 169| Step: 0
Training loss: 1.4232147932052612
Validation loss: 1.9906721999568324

Epoch: 6| Step: 1
Training loss: 1.1769574880599976
Validation loss: 2.0269240794643277

Epoch: 6| Step: 2
Training loss: 1.5372962951660156
Validation loss: 2.022392024276077

Epoch: 6| Step: 3
Training loss: 1.1225820779800415
Validation loss: 1.9795480415385256

Epoch: 6| Step: 4
Training loss: 0.804496705532074
Validation loss: 1.9160225583660988

Epoch: 6| Step: 5
Training loss: 1.4858269691467285
Validation loss: 1.8681916331732145

Epoch: 6| Step: 6
Training loss: 1.2774935960769653
Validation loss: 1.8685969024576166

Epoch: 6| Step: 7
Training loss: 1.2457748651504517
Validation loss: 1.8596976264830558

Epoch: 6| Step: 8
Training loss: 1.1928999423980713
Validation loss: 1.8423643394183087

Epoch: 6| Step: 9
Training loss: 1.6088454723358154
Validation loss: 1.8835390972834762

Epoch: 6| Step: 10
Training loss: 1.4521301984786987
Validation loss: 1.8685838086630708

Epoch: 6| Step: 11
Training loss: 1.1012638807296753
Validation loss: 1.8643135780929236

Epoch: 6| Step: 12
Training loss: 0.9088778495788574
Validation loss: 1.8676410657103344

Epoch: 6| Step: 13
Training loss: 1.026898741722107
Validation loss: 1.8459681362234137

Epoch: 170| Step: 0
Training loss: 1.3845155239105225
Validation loss: 1.8400159420505646

Epoch: 6| Step: 1
Training loss: 1.1023598909378052
Validation loss: 1.8721330729863976

Epoch: 6| Step: 2
Training loss: 1.3326034545898438
Validation loss: 1.8613704596796343

Epoch: 6| Step: 3
Training loss: 1.2556219100952148
Validation loss: 1.8978339433670044

Epoch: 6| Step: 4
Training loss: 1.2674113512039185
Validation loss: 1.8639832055696877

Epoch: 6| Step: 5
Training loss: 1.0209333896636963
Validation loss: 1.8328878264273367

Epoch: 6| Step: 6
Training loss: 0.9125292897224426
Validation loss: 1.8495771500372118

Epoch: 6| Step: 7
Training loss: 0.8545676469802856
Validation loss: 1.8579413378110496

Epoch: 6| Step: 8
Training loss: 1.1687918901443481
Validation loss: 1.8348129436533938

Epoch: 6| Step: 9
Training loss: 1.400635838508606
Validation loss: 1.8714686209155666

Epoch: 6| Step: 10
Training loss: 1.2047977447509766
Validation loss: 1.8829878953195387

Epoch: 6| Step: 11
Training loss: 1.5596637725830078
Validation loss: 1.8942691587632703

Epoch: 6| Step: 12
Training loss: 1.192467451095581
Validation loss: 1.8458458274923346

Epoch: 6| Step: 13
Training loss: 1.1056238412857056
Validation loss: 1.8289322558269705

Epoch: 171| Step: 0
Training loss: 0.713080883026123
Validation loss: 1.8357458524806525

Epoch: 6| Step: 1
Training loss: 1.5651516914367676
Validation loss: 1.82388311688618

Epoch: 6| Step: 2
Training loss: 1.4038654565811157
Validation loss: 1.828425484318887

Epoch: 6| Step: 3
Training loss: 0.6745153665542603
Validation loss: 1.8495151945339736

Epoch: 6| Step: 4
Training loss: 1.378495216369629
Validation loss: 1.8711749840808172

Epoch: 6| Step: 5
Training loss: 0.7478690147399902
Validation loss: 1.906503083885357

Epoch: 6| Step: 6
Training loss: 0.9202002286911011
Validation loss: 1.904782005535659

Epoch: 6| Step: 7
Training loss: 1.4662038087844849
Validation loss: 1.9125323808321388

Epoch: 6| Step: 8
Training loss: 1.1526641845703125
Validation loss: 1.9037826625249719

Epoch: 6| Step: 9
Training loss: 0.9722086191177368
Validation loss: 1.9035265343163603

Epoch: 6| Step: 10
Training loss: 1.5934500694274902
Validation loss: 1.905619223912557

Epoch: 6| Step: 11
Training loss: 1.2261919975280762
Validation loss: 1.9001498030078026

Epoch: 6| Step: 12
Training loss: 1.317307472229004
Validation loss: 1.8850043537796184

Epoch: 6| Step: 13
Training loss: 1.5145392417907715
Validation loss: 1.8550706307093303

Epoch: 172| Step: 0
Training loss: 1.348433017730713
Validation loss: 1.8393842122888053

Epoch: 6| Step: 1
Training loss: 0.8431541919708252
Validation loss: 1.8284855965645082

Epoch: 6| Step: 2
Training loss: 1.2006335258483887
Validation loss: 1.8164692027594453

Epoch: 6| Step: 3
Training loss: 1.3146953582763672
Validation loss: 1.8119722553478774

Epoch: 6| Step: 4
Training loss: 1.3409429788589478
Validation loss: 1.8151499032974243

Epoch: 6| Step: 5
Training loss: 1.529539704322815
Validation loss: 1.8002091402648597

Epoch: 6| Step: 6
Training loss: 1.1055703163146973
Validation loss: 1.831654085907885

Epoch: 6| Step: 7
Training loss: 1.048637866973877
Validation loss: 1.821004399689295

Epoch: 6| Step: 8
Training loss: 1.4344425201416016
Validation loss: 1.8550623309227727

Epoch: 6| Step: 9
Training loss: 0.9439445734024048
Validation loss: 1.866182606707337

Epoch: 6| Step: 10
Training loss: 1.0730912685394287
Validation loss: 1.854371020870824

Epoch: 6| Step: 11
Training loss: 0.8776783347129822
Validation loss: 1.8617184521049581

Epoch: 6| Step: 12
Training loss: 0.8836606740951538
Validation loss: 1.8772335308854298

Epoch: 6| Step: 13
Training loss: 0.96849524974823
Validation loss: 1.8537914137686453

Epoch: 173| Step: 0
Training loss: 1.411091685295105
Validation loss: 1.8449955037845078

Epoch: 6| Step: 1
Training loss: 1.2642807960510254
Validation loss: 1.8801324264977568

Epoch: 6| Step: 2
Training loss: 0.932860255241394
Validation loss: 1.8731103327966505

Epoch: 6| Step: 3
Training loss: 1.322995662689209
Validation loss: 1.8632207262900569

Epoch: 6| Step: 4
Training loss: 1.1686184406280518
Validation loss: 1.871576552749962

Epoch: 6| Step: 5
Training loss: 1.0363686084747314
Validation loss: 1.8561307884031726

Epoch: 6| Step: 6
Training loss: 1.2419202327728271
Validation loss: 1.8483706084630822

Epoch: 6| Step: 7
Training loss: 0.8490795493125916
Validation loss: 1.86495037745404

Epoch: 6| Step: 8
Training loss: 1.267559289932251
Validation loss: 1.8626196320338915

Epoch: 6| Step: 9
Training loss: 0.8839576244354248
Validation loss: 1.8337811859705115

Epoch: 6| Step: 10
Training loss: 1.2300634384155273
Validation loss: 1.8695282948914396

Epoch: 6| Step: 11
Training loss: 1.3100757598876953
Validation loss: 1.8678981693842078

Epoch: 6| Step: 12
Training loss: 0.7325855493545532
Validation loss: 1.8340579822499266

Epoch: 6| Step: 13
Training loss: 1.0606269836425781
Validation loss: 1.8349135357846496

Epoch: 174| Step: 0
Training loss: 1.1010080575942993
Validation loss: 1.8475474529368903

Epoch: 6| Step: 1
Training loss: 1.192957878112793
Validation loss: 1.8613744743408696

Epoch: 6| Step: 2
Training loss: 0.9358705282211304
Validation loss: 1.8254262221756803

Epoch: 6| Step: 3
Training loss: 0.8990834951400757
Validation loss: 1.8387065126049904

Epoch: 6| Step: 4
Training loss: 1.6003490686416626
Validation loss: 1.8779706403773317

Epoch: 6| Step: 5
Training loss: 0.9369784593582153
Validation loss: 1.88983747266954

Epoch: 6| Step: 6
Training loss: 1.2077336311340332
Validation loss: 1.887536843617757

Epoch: 6| Step: 7
Training loss: 1.0040119886398315
Validation loss: 1.8518565354808685

Epoch: 6| Step: 8
Training loss: 0.77939772605896
Validation loss: 1.8391115306526102

Epoch: 6| Step: 9
Training loss: 0.9834715723991394
Validation loss: 1.8192129904224026

Epoch: 6| Step: 10
Training loss: 0.9002772569656372
Validation loss: 1.8212301949019074

Epoch: 6| Step: 11
Training loss: 1.3949081897735596
Validation loss: 1.8270728190739949

Epoch: 6| Step: 12
Training loss: 1.506646752357483
Validation loss: 1.8157401084899902

Epoch: 6| Step: 13
Training loss: 1.0159809589385986
Validation loss: 1.8432358439250658

Epoch: 175| Step: 0
Training loss: 1.1435718536376953
Validation loss: 1.8417390200399584

Epoch: 6| Step: 1
Training loss: 1.0181597471237183
Validation loss: 1.8560081040987404

Epoch: 6| Step: 2
Training loss: 0.9872477054595947
Validation loss: 1.8476971580136208

Epoch: 6| Step: 3
Training loss: 0.6696743965148926
Validation loss: 1.8549649715423584

Epoch: 6| Step: 4
Training loss: 1.2595657110214233
Validation loss: 1.855617328356671

Epoch: 6| Step: 5
Training loss: 1.0719964504241943
Validation loss: 1.8588591955041374

Epoch: 6| Step: 6
Training loss: 0.9263851046562195
Validation loss: 1.8502249153711463

Epoch: 6| Step: 7
Training loss: 1.239680528640747
Validation loss: 1.8517498995668145

Epoch: 6| Step: 8
Training loss: 1.1972774267196655
Validation loss: 1.8490360372809953

Epoch: 6| Step: 9
Training loss: 1.3353524208068848
Validation loss: 1.8446257063137588

Epoch: 6| Step: 10
Training loss: 1.5592957735061646
Validation loss: 1.8374992416751

Epoch: 6| Step: 11
Training loss: 1.1898837089538574
Validation loss: 1.8363586215562717

Epoch: 6| Step: 12
Training loss: 1.1541235446929932
Validation loss: 1.8170549664446103

Epoch: 6| Step: 13
Training loss: 0.6227260828018188
Validation loss: 1.8009886946729434

Epoch: 176| Step: 0
Training loss: 1.341701865196228
Validation loss: 1.81305278501203

Epoch: 6| Step: 1
Training loss: 1.6186553239822388
Validation loss: 1.7913385155380412

Epoch: 6| Step: 2
Training loss: 0.9670953154563904
Validation loss: 1.8209914161312966

Epoch: 6| Step: 3
Training loss: 0.6897670030593872
Validation loss: 1.7991272544348111

Epoch: 6| Step: 4
Training loss: 1.2472312450408936
Validation loss: 1.829831116942949

Epoch: 6| Step: 5
Training loss: 1.0816457271575928
Validation loss: 1.8690151911909862

Epoch: 6| Step: 6
Training loss: 1.2038390636444092
Validation loss: 1.856186423250424

Epoch: 6| Step: 7
Training loss: 0.9380671977996826
Validation loss: 1.8447840008684384

Epoch: 6| Step: 8
Training loss: 0.9862777590751648
Validation loss: 1.8473591560958533

Epoch: 6| Step: 9
Training loss: 1.0695291757583618
Validation loss: 1.8615790887545514

Epoch: 6| Step: 10
Training loss: 0.7012096643447876
Validation loss: 1.8846852574297177

Epoch: 6| Step: 11
Training loss: 1.264702558517456
Validation loss: 1.8845844755890548

Epoch: 6| Step: 12
Training loss: 1.1131949424743652
Validation loss: 1.8897966313105758

Epoch: 6| Step: 13
Training loss: 1.226577639579773
Validation loss: 1.8867632086559007

Epoch: 177| Step: 0
Training loss: 1.2349090576171875
Validation loss: 1.8751889774876256

Epoch: 6| Step: 1
Training loss: 1.2285621166229248
Validation loss: 1.8692533867333525

Epoch: 6| Step: 2
Training loss: 1.3713932037353516
Validation loss: 1.8891795732641732

Epoch: 6| Step: 3
Training loss: 1.0813498497009277
Validation loss: 1.9102757310354581

Epoch: 6| Step: 4
Training loss: 0.9693683385848999
Validation loss: 1.897156471847206

Epoch: 6| Step: 5
Training loss: 0.6916188597679138
Validation loss: 1.8860422847091511

Epoch: 6| Step: 6
Training loss: 0.8261963725090027
Validation loss: 1.8641503036663096

Epoch: 6| Step: 7
Training loss: 1.4803109169006348
Validation loss: 1.844204968021762

Epoch: 6| Step: 8
Training loss: 0.9382261037826538
Validation loss: 1.8512439907238047

Epoch: 6| Step: 9
Training loss: 1.0049993991851807
Validation loss: 1.8364510972012755

Epoch: 6| Step: 10
Training loss: 0.8730748891830444
Validation loss: 1.827143471728089

Epoch: 6| Step: 11
Training loss: 1.2884507179260254
Validation loss: 1.828709651065129

Epoch: 6| Step: 12
Training loss: 0.8067158460617065
Validation loss: 1.8504491377902288

Epoch: 6| Step: 13
Training loss: 1.0536518096923828
Validation loss: 1.8277860905534478

Epoch: 178| Step: 0
Training loss: 0.9199227690696716
Validation loss: 1.838752172326529

Epoch: 6| Step: 1
Training loss: 0.7207373380661011
Validation loss: 1.861237258039495

Epoch: 6| Step: 2
Training loss: 1.26278817653656
Validation loss: 1.8987436294555664

Epoch: 6| Step: 3
Training loss: 0.7295424938201904
Validation loss: 1.8826156995629753

Epoch: 6| Step: 4
Training loss: 1.0170732736587524
Validation loss: 1.8502685126437937

Epoch: 6| Step: 5
Training loss: 1.216243028640747
Validation loss: 1.846821056899204

Epoch: 6| Step: 6
Training loss: 0.9523493051528931
Validation loss: 1.8434939487006075

Epoch: 6| Step: 7
Training loss: 1.041748046875
Validation loss: 1.8348987230690577

Epoch: 6| Step: 8
Training loss: 1.0391796827316284
Validation loss: 1.7896861978756484

Epoch: 6| Step: 9
Training loss: 0.8364168405532837
Validation loss: 1.7983306197709934

Epoch: 6| Step: 10
Training loss: 0.9729554057121277
Validation loss: 1.8084726500254806

Epoch: 6| Step: 11
Training loss: 1.1768920421600342
Validation loss: 1.8200234290092223

Epoch: 6| Step: 12
Training loss: 1.515068769454956
Validation loss: 1.8659164905548096

Epoch: 6| Step: 13
Training loss: 1.5774216651916504
Validation loss: 1.870516627065597

Epoch: 179| Step: 0
Training loss: 1.1793445348739624
Validation loss: 1.8556795697058401

Epoch: 6| Step: 1
Training loss: 0.8823543787002563
Validation loss: 1.8495651227171703

Epoch: 6| Step: 2
Training loss: 1.3595807552337646
Validation loss: 1.8473151153133762

Epoch: 6| Step: 3
Training loss: 0.7286264896392822
Validation loss: 1.8274209345540693

Epoch: 6| Step: 4
Training loss: 0.8447672128677368
Validation loss: 1.8322850504229147

Epoch: 6| Step: 5
Training loss: 1.318368673324585
Validation loss: 1.8310008074647637

Epoch: 6| Step: 6
Training loss: 1.0971587896347046
Validation loss: 1.856340439088883

Epoch: 6| Step: 7
Training loss: 1.1272720098495483
Validation loss: 1.838428811360431

Epoch: 6| Step: 8
Training loss: 1.2251075506210327
Validation loss: 1.8576268790870585

Epoch: 6| Step: 9
Training loss: 1.572048544883728
Validation loss: 1.882325990225679

Epoch: 6| Step: 10
Training loss: 1.3508198261260986
Validation loss: 1.8649289300364833

Epoch: 6| Step: 11
Training loss: 0.6701646447181702
Validation loss: 1.908531468401673

Epoch: 6| Step: 12
Training loss: 0.6695563793182373
Validation loss: 1.9497790657063967

Epoch: 6| Step: 13
Training loss: 1.195602297782898
Validation loss: 1.9850424156394055

Epoch: 180| Step: 0
Training loss: 0.8842350244522095
Validation loss: 2.0194905778413177

Epoch: 6| Step: 1
Training loss: 1.0800235271453857
Validation loss: 1.9955634327344998

Epoch: 6| Step: 2
Training loss: 0.8539459705352783
Validation loss: 1.9599320145063504

Epoch: 6| Step: 3
Training loss: 1.0901318788528442
Validation loss: 1.9186368629496584

Epoch: 6| Step: 4
Training loss: 0.9136803150177002
Validation loss: 1.8599424746728712

Epoch: 6| Step: 5
Training loss: 0.8102330565452576
Validation loss: 1.8719172195721698

Epoch: 6| Step: 6
Training loss: 0.868948757648468
Validation loss: 1.8524147605383268

Epoch: 6| Step: 7
Training loss: 0.9010864496231079
Validation loss: 1.8524971149301017

Epoch: 6| Step: 8
Training loss: 1.1455597877502441
Validation loss: 1.8511933165211831

Epoch: 6| Step: 9
Training loss: 1.0205081701278687
Validation loss: 1.866194054644595

Epoch: 6| Step: 10
Training loss: 1.609339714050293
Validation loss: 1.8134695868338309

Epoch: 6| Step: 11
Training loss: 0.9580524563789368
Validation loss: 1.835443151894436

Epoch: 6| Step: 12
Training loss: 1.3808214664459229
Validation loss: 1.8668419891788113

Epoch: 6| Step: 13
Training loss: 1.3748302459716797
Validation loss: 1.8787159099373767

Epoch: 181| Step: 0
Training loss: 1.4398084878921509
Validation loss: 1.8562396944210093

Epoch: 6| Step: 1
Training loss: 0.9817747473716736
Validation loss: 1.8352732530204199

Epoch: 6| Step: 2
Training loss: 1.3921053409576416
Validation loss: 1.8301424634072088

Epoch: 6| Step: 3
Training loss: 1.1323891878128052
Validation loss: 1.8421122104890886

Epoch: 6| Step: 4
Training loss: 0.9808281660079956
Validation loss: 1.7968082991979455

Epoch: 6| Step: 5
Training loss: 0.8819542527198792
Validation loss: 1.8037132806675409

Epoch: 6| Step: 6
Training loss: 0.8256088495254517
Validation loss: 1.7823561109522337

Epoch: 6| Step: 7
Training loss: 0.8936102390289307
Validation loss: 1.8010342903034662

Epoch: 6| Step: 8
Training loss: 0.7140368819236755
Validation loss: 1.7816902565699753

Epoch: 6| Step: 9
Training loss: 0.8506160974502563
Validation loss: 1.7845007373440651

Epoch: 6| Step: 10
Training loss: 1.1315988302230835
Validation loss: 1.7846269043543006

Epoch: 6| Step: 11
Training loss: 0.8413028717041016
Validation loss: 1.791327320119386

Epoch: 6| Step: 12
Training loss: 1.2698113918304443
Validation loss: 1.781167125189176

Epoch: 6| Step: 13
Training loss: 0.8464767336845398
Validation loss: 1.7942709544653535

Epoch: 182| Step: 0
Training loss: 1.2727288007736206
Validation loss: 1.8282713082528883

Epoch: 6| Step: 1
Training loss: 0.9920642971992493
Validation loss: 1.805697621837739

Epoch: 6| Step: 2
Training loss: 0.941112220287323
Validation loss: 1.7899351709632463

Epoch: 6| Step: 3
Training loss: 0.958665668964386
Validation loss: 1.7716045341184061

Epoch: 6| Step: 4
Training loss: 0.715235710144043
Validation loss: 1.797701193440345

Epoch: 6| Step: 5
Training loss: 0.7303588390350342
Validation loss: 1.778123281335318

Epoch: 6| Step: 6
Training loss: 1.0455070734024048
Validation loss: 1.7800834166106356

Epoch: 6| Step: 7
Training loss: 1.5326306819915771
Validation loss: 1.7898668755767166

Epoch: 6| Step: 8
Training loss: 0.8129783272743225
Validation loss: 1.7959823044397498

Epoch: 6| Step: 9
Training loss: 0.7324175238609314
Validation loss: 1.7826650296488116

Epoch: 6| Step: 10
Training loss: 1.0466086864471436
Validation loss: 1.7847372511381745

Epoch: 6| Step: 11
Training loss: 0.7235631942749023
Validation loss: 1.7785238630028182

Epoch: 6| Step: 12
Training loss: 1.651582956314087
Validation loss: 1.7754739074296848

Epoch: 6| Step: 13
Training loss: 0.7963913083076477
Validation loss: 1.7662359335089242

Epoch: 183| Step: 0
Training loss: 0.7765563726425171
Validation loss: 1.7589449651779667

Epoch: 6| Step: 1
Training loss: 0.8347315788269043
Validation loss: 1.7355950263238722

Epoch: 6| Step: 2
Training loss: 1.0751397609710693
Validation loss: 1.7730558405640304

Epoch: 6| Step: 3
Training loss: 1.2037097215652466
Validation loss: 1.7938807856652044

Epoch: 6| Step: 4
Training loss: 0.5249708890914917
Validation loss: 1.826932353358115

Epoch: 6| Step: 5
Training loss: 1.0463621616363525
Validation loss: 1.84479094577092

Epoch: 6| Step: 6
Training loss: 1.0232605934143066
Validation loss: 1.8289529572251022

Epoch: 6| Step: 7
Training loss: 0.6620321273803711
Validation loss: 1.8295722533297796

Epoch: 6| Step: 8
Training loss: 1.0109198093414307
Validation loss: 1.812954774466894

Epoch: 6| Step: 9
Training loss: 1.5405466556549072
Validation loss: 1.7632323952131375

Epoch: 6| Step: 10
Training loss: 1.1221873760223389
Validation loss: 1.788434584935506

Epoch: 6| Step: 11
Training loss: 0.9049055576324463
Validation loss: 1.8042727196088402

Epoch: 6| Step: 12
Training loss: 0.9555402398109436
Validation loss: 1.777908484141032

Epoch: 6| Step: 13
Training loss: 1.1151803731918335
Validation loss: 1.793067915465242

Epoch: 184| Step: 0
Training loss: 1.2344605922698975
Validation loss: 1.7814694835293678

Epoch: 6| Step: 1
Training loss: 0.7965978980064392
Validation loss: 1.7849678108769078

Epoch: 6| Step: 2
Training loss: 1.2062711715698242
Validation loss: 1.806463062122304

Epoch: 6| Step: 3
Training loss: 0.9307762980461121
Validation loss: 1.807462392314788

Epoch: 6| Step: 4
Training loss: 0.9422389268875122
Validation loss: 1.8220201115454397

Epoch: 6| Step: 5
Training loss: 1.0412225723266602
Validation loss: 1.8590699395825785

Epoch: 6| Step: 6
Training loss: 1.060164213180542
Validation loss: 1.9153141475492907

Epoch: 6| Step: 7
Training loss: 0.9840612411499023
Validation loss: 1.9005168445648686

Epoch: 6| Step: 8
Training loss: 0.7287613153457642
Validation loss: 1.8458050322789017

Epoch: 6| Step: 9
Training loss: 1.0987603664398193
Validation loss: 1.8347841744781823

Epoch: 6| Step: 10
Training loss: 0.9219797253608704
Validation loss: 1.8088615094461749

Epoch: 6| Step: 11
Training loss: 0.6365999579429626
Validation loss: 1.7944508047514065

Epoch: 6| Step: 12
Training loss: 0.9308981895446777
Validation loss: 1.8022262691169657

Epoch: 6| Step: 13
Training loss: 1.529317021369934
Validation loss: 1.7887836810081237

Epoch: 185| Step: 0
Training loss: 0.9035610556602478
Validation loss: 1.8042990622981903

Epoch: 6| Step: 1
Training loss: 0.7683840990066528
Validation loss: 1.7672347227732341

Epoch: 6| Step: 2
Training loss: 1.0922138690948486
Validation loss: 1.7978913873754523

Epoch: 6| Step: 3
Training loss: 0.8995821475982666
Validation loss: 1.8197481439959617

Epoch: 6| Step: 4
Training loss: 0.5484310388565063
Validation loss: 1.8220715599675332

Epoch: 6| Step: 5
Training loss: 1.056888461112976
Validation loss: 1.832037930847496

Epoch: 6| Step: 6
Training loss: 0.9958015084266663
Validation loss: 1.8356986648292952

Epoch: 6| Step: 7
Training loss: 1.2379333972930908
Validation loss: 1.8190400972161243

Epoch: 6| Step: 8
Training loss: 0.8061206340789795
Validation loss: 1.7692940876048098

Epoch: 6| Step: 9
Training loss: 0.8390765190124512
Validation loss: 1.7758231496298185

Epoch: 6| Step: 10
Training loss: 1.2615511417388916
Validation loss: 1.777162371143218

Epoch: 6| Step: 11
Training loss: 1.3614964485168457
Validation loss: 1.7801548691206082

Epoch: 6| Step: 12
Training loss: 0.9489806294441223
Validation loss: 1.7938990772411387

Epoch: 6| Step: 13
Training loss: 0.773230791091919
Validation loss: 1.789075191302966

Epoch: 186| Step: 0
Training loss: 0.8796426653862
Validation loss: 1.8038245772802701

Epoch: 6| Step: 1
Training loss: 1.1570881605148315
Validation loss: 1.8570047578504008

Epoch: 6| Step: 2
Training loss: 1.4242167472839355
Validation loss: 1.8587976463379399

Epoch: 6| Step: 3
Training loss: 1.2648954391479492
Validation loss: 1.8829384414098596

Epoch: 6| Step: 4
Training loss: 0.7402887940406799
Validation loss: 1.8524849786553332

Epoch: 6| Step: 5
Training loss: 0.9766994714736938
Validation loss: 1.8349967387414747

Epoch: 6| Step: 6
Training loss: 0.6391956806182861
Validation loss: 1.776444258228425

Epoch: 6| Step: 7
Training loss: 0.49576282501220703
Validation loss: 1.777767942797753

Epoch: 6| Step: 8
Training loss: 0.9158850908279419
Validation loss: 1.7690679847553212

Epoch: 6| Step: 9
Training loss: 1.081758737564087
Validation loss: 1.8009677753653577

Epoch: 6| Step: 10
Training loss: 1.0324976444244385
Validation loss: 1.8110426279806322

Epoch: 6| Step: 11
Training loss: 0.6728762984275818
Validation loss: 1.7604335200402044

Epoch: 6| Step: 12
Training loss: 0.844017505645752
Validation loss: 1.8088709385164323

Epoch: 6| Step: 13
Training loss: 1.4073615074157715
Validation loss: 1.804125428199768

Epoch: 187| Step: 0
Training loss: 0.9392787218093872
Validation loss: 1.8121800525214082

Epoch: 6| Step: 1
Training loss: 1.0915981531143188
Validation loss: 1.7941570461437266

Epoch: 6| Step: 2
Training loss: 0.49393972754478455
Validation loss: 1.7830140680395148

Epoch: 6| Step: 3
Training loss: 0.48640167713165283
Validation loss: 1.7721071538104807

Epoch: 6| Step: 4
Training loss: 0.9319508075714111
Validation loss: 1.7665010690689087

Epoch: 6| Step: 5
Training loss: 1.0774247646331787
Validation loss: 1.7727995828915668

Epoch: 6| Step: 6
Training loss: 0.8158658742904663
Validation loss: 1.7848370382862706

Epoch: 6| Step: 7
Training loss: 1.0285918712615967
Validation loss: 1.8144532788184382

Epoch: 6| Step: 8
Training loss: 1.1051099300384521
Validation loss: 1.814326096606511

Epoch: 6| Step: 9
Training loss: 0.8369948863983154
Validation loss: 1.8193368475924256

Epoch: 6| Step: 10
Training loss: 1.023263692855835
Validation loss: 1.8373988084895636

Epoch: 6| Step: 11
Training loss: 1.1222858428955078
Validation loss: 1.8539727810890443

Epoch: 6| Step: 12
Training loss: 1.3122413158416748
Validation loss: 1.8507636695779779

Epoch: 6| Step: 13
Training loss: 1.0763007402420044
Validation loss: 1.8766295397153465

Epoch: 188| Step: 0
Training loss: 0.7295932173728943
Validation loss: 1.8569640677462342

Epoch: 6| Step: 1
Training loss: 0.5777502059936523
Validation loss: 1.8563167971949424

Epoch: 6| Step: 2
Training loss: 1.0701210498809814
Validation loss: 1.8220238941971973

Epoch: 6| Step: 3
Training loss: 0.7970720529556274
Validation loss: 1.7714311358749226

Epoch: 6| Step: 4
Training loss: 1.238757610321045
Validation loss: 1.7411174569078671

Epoch: 6| Step: 5
Training loss: 0.7856734991073608
Validation loss: 1.7196799760223718

Epoch: 6| Step: 6
Training loss: 1.0880472660064697
Validation loss: 1.7463116158721268

Epoch: 6| Step: 7
Training loss: 0.9949422478675842
Validation loss: 1.7499308060574275

Epoch: 6| Step: 8
Training loss: 0.9042069911956787
Validation loss: 1.7534675764781174

Epoch: 6| Step: 9
Training loss: 0.7667186260223389
Validation loss: 1.7726353304360503

Epoch: 6| Step: 10
Training loss: 1.3309040069580078
Validation loss: 1.7574955186536234

Epoch: 6| Step: 11
Training loss: 0.867110013961792
Validation loss: 1.8092031709609493

Epoch: 6| Step: 12
Training loss: 0.6898758411407471
Validation loss: 1.7426155805587769

Epoch: 6| Step: 13
Training loss: 1.3822779655456543
Validation loss: 1.7621411482493083

Epoch: 189| Step: 0
Training loss: 0.472680926322937
Validation loss: 1.7537892659505208

Epoch: 6| Step: 1
Training loss: 0.9467699527740479
Validation loss: 1.7582699316804127

Epoch: 6| Step: 2
Training loss: 0.7480213642120361
Validation loss: 1.7939805241041287

Epoch: 6| Step: 3
Training loss: 1.5292456150054932
Validation loss: 1.8115712109432425

Epoch: 6| Step: 4
Training loss: 0.8354009389877319
Validation loss: 1.8419241559120916

Epoch: 6| Step: 5
Training loss: 0.8936210870742798
Validation loss: 1.8519254961321432

Epoch: 6| Step: 6
Training loss: 0.9297724366188049
Validation loss: 1.8254101084124656

Epoch: 6| Step: 7
Training loss: 0.790329098701477
Validation loss: 1.8263860069295412

Epoch: 6| Step: 8
Training loss: 1.1230664253234863
Validation loss: 1.798129395772052

Epoch: 6| Step: 9
Training loss: 1.2806071043014526
Validation loss: 1.7785694291514735

Epoch: 6| Step: 10
Training loss: 0.9707783460617065
Validation loss: 1.769386940104987

Epoch: 6| Step: 11
Training loss: 0.8510488867759705
Validation loss: 1.7397108103639336

Epoch: 6| Step: 12
Training loss: 1.199859619140625
Validation loss: 1.739738727128634

Epoch: 6| Step: 13
Training loss: 0.5413334369659424
Validation loss: 1.7543735952787503

Epoch: 190| Step: 0
Training loss: 0.7804563045501709
Validation loss: 1.732050767508886

Epoch: 6| Step: 1
Training loss: 0.8251461982727051
Validation loss: 1.7704049028376097

Epoch: 6| Step: 2
Training loss: 0.6837139129638672
Validation loss: 1.7530644606518488

Epoch: 6| Step: 3
Training loss: 1.0575941801071167
Validation loss: 1.8569100826017317

Epoch: 6| Step: 4
Training loss: 1.4067609310150146
Validation loss: 1.870274664253317

Epoch: 6| Step: 5
Training loss: 0.9252728223800659
Validation loss: 1.9190432653632215

Epoch: 6| Step: 6
Training loss: 0.9101448059082031
Validation loss: 1.932534876690116

Epoch: 6| Step: 7
Training loss: 0.6763659119606018
Validation loss: 1.9220187728123

Epoch: 6| Step: 8
Training loss: 0.9642695188522339
Validation loss: 1.8963458704692062

Epoch: 6| Step: 9
Training loss: 1.2277346849441528
Validation loss: 1.86909689569986

Epoch: 6| Step: 10
Training loss: 1.0438984632492065
Validation loss: 1.8580894726578907

Epoch: 6| Step: 11
Training loss: 0.6569653153419495
Validation loss: 1.8025261843076317

Epoch: 6| Step: 12
Training loss: 1.1089410781860352
Validation loss: 1.7571466674086869

Epoch: 6| Step: 13
Training loss: 1.4265999794006348
Validation loss: 1.7316010152139971

Epoch: 191| Step: 0
Training loss: 0.9899932146072388
Validation loss: 1.730847353576332

Epoch: 6| Step: 1
Training loss: 0.5414859056472778
Validation loss: 1.7389538608571535

Epoch: 6| Step: 2
Training loss: 1.1005741357803345
Validation loss: 1.7102248514852216

Epoch: 6| Step: 3
Training loss: 1.0505324602127075
Validation loss: 1.6944778439819173

Epoch: 6| Step: 4
Training loss: 0.8074157238006592
Validation loss: 1.6963008924197125

Epoch: 6| Step: 5
Training loss: 1.1503095626831055
Validation loss: 1.7348673343658447

Epoch: 6| Step: 6
Training loss: 0.8593941926956177
Validation loss: 1.749243869576403

Epoch: 6| Step: 7
Training loss: 1.1088019609451294
Validation loss: 1.7767737783411497

Epoch: 6| Step: 8
Training loss: 1.191423773765564
Validation loss: 1.8041870312024189

Epoch: 6| Step: 9
Training loss: 0.6996477842330933
Validation loss: 1.8260259038658553

Epoch: 6| Step: 10
Training loss: 0.9642399549484253
Validation loss: 1.8208912303370814

Epoch: 6| Step: 11
Training loss: 0.8268815875053406
Validation loss: 1.8186480870810888

Epoch: 6| Step: 12
Training loss: 0.9552049040794373
Validation loss: 1.7993887227068666

Epoch: 6| Step: 13
Training loss: 0.53062504529953
Validation loss: 1.7757806419044413

Epoch: 192| Step: 0
Training loss: 1.024251937866211
Validation loss: 1.7676883461654826

Epoch: 6| Step: 1
Training loss: 1.0088732242584229
Validation loss: 1.7860337585531256

Epoch: 6| Step: 2
Training loss: 0.7504690289497375
Validation loss: 1.7670103747357604

Epoch: 6| Step: 3
Training loss: 0.5875591039657593
Validation loss: 1.7797364214415192

Epoch: 6| Step: 4
Training loss: 1.0993783473968506
Validation loss: 1.752433898628399

Epoch: 6| Step: 5
Training loss: 0.9175443649291992
Validation loss: 1.7690951708824403

Epoch: 6| Step: 6
Training loss: 1.2661967277526855
Validation loss: 1.7610136616614558

Epoch: 6| Step: 7
Training loss: 1.2038941383361816
Validation loss: 1.7725502085942093

Epoch: 6| Step: 8
Training loss: 0.9194949865341187
Validation loss: 1.7832285358059792

Epoch: 6| Step: 9
Training loss: 0.9985321164131165
Validation loss: 1.7845986927709272

Epoch: 6| Step: 10
Training loss: 1.3295955657958984
Validation loss: 1.757309729053128

Epoch: 6| Step: 11
Training loss: 0.4876689314842224
Validation loss: 1.7595671581965622

Epoch: 6| Step: 12
Training loss: 0.42026641964912415
Validation loss: 1.7632598184770154

Epoch: 6| Step: 13
Training loss: 0.4269365668296814
Validation loss: 1.7457669704191145

Epoch: 193| Step: 0
Training loss: 0.8088914752006531
Validation loss: 1.7589487606479275

Epoch: 6| Step: 1
Training loss: 1.056219220161438
Validation loss: 1.7817002381047895

Epoch: 6| Step: 2
Training loss: 0.8178176879882812
Validation loss: 1.7506084724139142

Epoch: 6| Step: 3
Training loss: 0.9943028688430786
Validation loss: 1.8151748065025575

Epoch: 6| Step: 4
Training loss: 0.5811101794242859
Validation loss: 1.7709804786148893

Epoch: 6| Step: 5
Training loss: 0.9632558822631836
Validation loss: 1.7643439359562372

Epoch: 6| Step: 6
Training loss: 0.49032729864120483
Validation loss: 1.7660882626810381

Epoch: 6| Step: 7
Training loss: 0.9988837242126465
Validation loss: 1.7572312483223536

Epoch: 6| Step: 8
Training loss: 0.7974728941917419
Validation loss: 1.759887860667321

Epoch: 6| Step: 9
Training loss: 1.1430318355560303
Validation loss: 1.7471596835761942

Epoch: 6| Step: 10
Training loss: 0.9160043001174927
Validation loss: 1.7382120919483963

Epoch: 6| Step: 11
Training loss: 0.7920170426368713
Validation loss: 1.7244775756712882

Epoch: 6| Step: 12
Training loss: 1.025864839553833
Validation loss: 1.758518188230453

Epoch: 6| Step: 13
Training loss: 1.1951968669891357
Validation loss: 1.706301103356064

Epoch: 194| Step: 0
Training loss: 1.0334138870239258
Validation loss: 1.7459713310323737

Epoch: 6| Step: 1
Training loss: 0.542570173740387
Validation loss: 1.722314142411755

Epoch: 6| Step: 2
Training loss: 0.5715627074241638
Validation loss: 1.7251703444347586

Epoch: 6| Step: 3
Training loss: 0.8220764398574829
Validation loss: 1.7305527707581878

Epoch: 6| Step: 4
Training loss: 0.6295179128646851
Validation loss: 1.7620094617207844

Epoch: 6| Step: 5
Training loss: 1.0255597829818726
Validation loss: 1.764293780890844

Epoch: 6| Step: 6
Training loss: 1.0126885175704956
Validation loss: 1.7694071031385852

Epoch: 6| Step: 7
Training loss: 0.7801104187965393
Validation loss: 1.7991885677460702

Epoch: 6| Step: 8
Training loss: 0.8595690727233887
Validation loss: 1.846912423769633

Epoch: 6| Step: 9
Training loss: 1.0111464262008667
Validation loss: 1.8444741028611378

Epoch: 6| Step: 10
Training loss: 0.7538304328918457
Validation loss: 1.858420314327363

Epoch: 6| Step: 11
Training loss: 0.9760722517967224
Validation loss: 1.7887167917784823

Epoch: 6| Step: 12
Training loss: 1.6219947338104248
Validation loss: 1.758621802894018

Epoch: 6| Step: 13
Training loss: 1.0387407541275024
Validation loss: 1.7597330347184212

Epoch: 195| Step: 0
Training loss: 0.835273027420044
Validation loss: 1.7545750243689424

Epoch: 6| Step: 1
Training loss: 1.1828904151916504
Validation loss: 1.734670619810781

Epoch: 6| Step: 2
Training loss: 1.105783224105835
Validation loss: 1.7534020229052472

Epoch: 6| Step: 3
Training loss: 0.8371262550354004
Validation loss: 1.7845212682600944

Epoch: 6| Step: 4
Training loss: 0.7286049127578735
Validation loss: 1.7892955400610482

Epoch: 6| Step: 5
Training loss: 0.5756474733352661
Validation loss: 1.7523343204170145

Epoch: 6| Step: 6
Training loss: 0.8022801876068115
Validation loss: 1.757331657153304

Epoch: 6| Step: 7
Training loss: 0.7522543668746948
Validation loss: 1.7857097682132517

Epoch: 6| Step: 8
Training loss: 1.0317211151123047
Validation loss: 1.8034696989161993

Epoch: 6| Step: 9
Training loss: 0.7510685920715332
Validation loss: 1.780691276314438

Epoch: 6| Step: 10
Training loss: 0.7451096177101135
Validation loss: 1.801211776271943

Epoch: 6| Step: 11
Training loss: 1.2269103527069092
Validation loss: 1.8090831438700359

Epoch: 6| Step: 12
Training loss: 0.8949360847473145
Validation loss: 1.80094963119876

Epoch: 6| Step: 13
Training loss: 1.1258989572525024
Validation loss: 1.8252701426065097

Epoch: 196| Step: 0
Training loss: 0.7457513809204102
Validation loss: 1.8161914592148156

Epoch: 6| Step: 1
Training loss: 0.7272559404373169
Validation loss: 1.794385281942224

Epoch: 6| Step: 2
Training loss: 1.0458455085754395
Validation loss: 1.7609964621964322

Epoch: 6| Step: 3
Training loss: 0.5873727798461914
Validation loss: 1.785289672113234

Epoch: 6| Step: 4
Training loss: 0.9828565120697021
Validation loss: 1.7761552846559914

Epoch: 6| Step: 5
Training loss: 0.9044727087020874
Validation loss: 1.7417355019559142

Epoch: 6| Step: 6
Training loss: 0.8282272219657898
Validation loss: 1.751139263952932

Epoch: 6| Step: 7
Training loss: 0.41781407594680786
Validation loss: 1.735361873462636

Epoch: 6| Step: 8
Training loss: 1.0800657272338867
Validation loss: 1.762818282650363

Epoch: 6| Step: 9
Training loss: 0.6177647709846497
Validation loss: 1.748972745351894

Epoch: 6| Step: 10
Training loss: 0.6937192678451538
Validation loss: 1.7675122035446988

Epoch: 6| Step: 11
Training loss: 1.0261809825897217
Validation loss: 1.7793563360808997

Epoch: 6| Step: 12
Training loss: 1.5056509971618652
Validation loss: 1.7600208161979594

Epoch: 6| Step: 13
Training loss: 0.6383551359176636
Validation loss: 1.722205428666966

Epoch: 197| Step: 0
Training loss: 1.0247328281402588
Validation loss: 1.7163057993817072

Epoch: 6| Step: 1
Training loss: 0.7178515195846558
Validation loss: 1.743719325270704

Epoch: 6| Step: 2
Training loss: 0.6374144554138184
Validation loss: 1.7614183733540196

Epoch: 6| Step: 3
Training loss: 1.0001871585845947
Validation loss: 1.746927733062416

Epoch: 6| Step: 4
Training loss: 1.0116353034973145
Validation loss: 1.7631634050799954

Epoch: 6| Step: 5
Training loss: 0.8101203441619873
Validation loss: 1.7415712213003507

Epoch: 6| Step: 6
Training loss: 0.5125942230224609
Validation loss: 1.779677874298506

Epoch: 6| Step: 7
Training loss: 0.7517179846763611
Validation loss: 1.8134617523480487

Epoch: 6| Step: 8
Training loss: 1.3272457122802734
Validation loss: 1.8559936605474001

Epoch: 6| Step: 9
Training loss: 0.7273517847061157
Validation loss: 1.8093023838535431

Epoch: 6| Step: 10
Training loss: 1.0785799026489258
Validation loss: 1.754674429534584

Epoch: 6| Step: 11
Training loss: 0.771363377571106
Validation loss: 1.686044426374538

Epoch: 6| Step: 12
Training loss: 1.0220942497253418
Validation loss: 1.6573686830459102

Epoch: 6| Step: 13
Training loss: 0.40644121170043945
Validation loss: 1.637946508264029

Epoch: 198| Step: 0
Training loss: 0.816508412361145
Validation loss: 1.6412032919545327

Epoch: 6| Step: 1
Training loss: 0.5059759616851807
Validation loss: 1.7085464167338547

Epoch: 6| Step: 2
Training loss: 0.8826862573623657
Validation loss: 1.74779623939145

Epoch: 6| Step: 3
Training loss: 1.1250207424163818
Validation loss: 1.750575807786757

Epoch: 6| Step: 4
Training loss: 0.8097836375236511
Validation loss: 1.7641140543004519

Epoch: 6| Step: 5
Training loss: 0.862236499786377
Validation loss: 1.7609226601098174

Epoch: 6| Step: 6
Training loss: 0.8639960289001465
Validation loss: 1.7388550389197566

Epoch: 6| Step: 7
Training loss: 1.1203594207763672
Validation loss: 1.755547991362951

Epoch: 6| Step: 8
Training loss: 1.045348048210144
Validation loss: 1.7746826307747954

Epoch: 6| Step: 9
Training loss: 0.6819471120834351
Validation loss: 1.7649923986004246

Epoch: 6| Step: 10
Training loss: 0.8737988471984863
Validation loss: 1.7676404624856927

Epoch: 6| Step: 11
Training loss: 0.8154305219650269
Validation loss: 1.7627416015953146

Epoch: 6| Step: 12
Training loss: 0.9913280010223389
Validation loss: 1.727854057024884

Epoch: 6| Step: 13
Training loss: 0.877953827381134
Validation loss: 1.7754300243111067

Epoch: 199| Step: 0
Training loss: 0.761277437210083
Validation loss: 1.727715822958177

Epoch: 6| Step: 1
Training loss: 0.6425515413284302
Validation loss: 1.7211629818844538

Epoch: 6| Step: 2
Training loss: 0.43171149492263794
Validation loss: 1.7320841820009294

Epoch: 6| Step: 3
Training loss: 0.5472691059112549
Validation loss: 1.752468143740008

Epoch: 6| Step: 4
Training loss: 0.6574007272720337
Validation loss: 1.7889745517443585

Epoch: 6| Step: 5
Training loss: 0.8993719220161438
Validation loss: 1.796803928190662

Epoch: 6| Step: 6
Training loss: 1.3343398571014404
Validation loss: 1.7989294580233994

Epoch: 6| Step: 7
Training loss: 0.8406822681427002
Validation loss: 1.7789849158256286

Epoch: 6| Step: 8
Training loss: 0.8501765131950378
Validation loss: 1.7349435052564066

Epoch: 6| Step: 9
Training loss: 1.0788829326629639
Validation loss: 1.7465045323935888

Epoch: 6| Step: 10
Training loss: 1.4380064010620117
Validation loss: 1.7050700841411468

Epoch: 6| Step: 11
Training loss: 0.9791055917739868
Validation loss: 1.7502765078698435

Epoch: 6| Step: 12
Training loss: 0.5954720377922058
Validation loss: 1.725885655290337

Epoch: 6| Step: 13
Training loss: 0.6690201163291931
Validation loss: 1.744377851486206

Epoch: 200| Step: 0
Training loss: 1.1464868783950806
Validation loss: 1.7310853517183693

Epoch: 6| Step: 1
Training loss: 1.0542607307434082
Validation loss: 1.7204169919413905

Epoch: 6| Step: 2
Training loss: 0.9594380259513855
Validation loss: 1.7160660746277019

Epoch: 6| Step: 3
Training loss: 0.7953749299049377
Validation loss: 1.737772455779455

Epoch: 6| Step: 4
Training loss: 0.8264203071594238
Validation loss: 1.7522384094935592

Epoch: 6| Step: 5
Training loss: 0.47843843698501587
Validation loss: 1.736991616987413

Epoch: 6| Step: 6
Training loss: 0.6896165013313293
Validation loss: 1.7274776633067797

Epoch: 6| Step: 7
Training loss: 0.7081139087677002
Validation loss: 1.7179121022583337

Epoch: 6| Step: 8
Training loss: 0.8781971335411072
Validation loss: 1.7319081573076145

Epoch: 6| Step: 9
Training loss: 1.2066700458526611
Validation loss: 1.7209015379669845

Epoch: 6| Step: 10
Training loss: 0.8269601464271545
Validation loss: 1.7251754832524124

Epoch: 6| Step: 11
Training loss: 0.5834962129592896
Validation loss: 1.6800051402020197

Epoch: 6| Step: 12
Training loss: 0.9730901122093201
Validation loss: 1.6695643227587464

Epoch: 6| Step: 13
Training loss: 0.6030046939849854
Validation loss: 1.6756761561157882

Epoch: 201| Step: 0
Training loss: 0.9148326516151428
Validation loss: 1.7073664703676779

Epoch: 6| Step: 1
Training loss: 0.6801363825798035
Validation loss: 1.743833331651585

Epoch: 6| Step: 2
Training loss: 1.332523226737976
Validation loss: 1.7865447600682576

Epoch: 6| Step: 3
Training loss: 0.6634134650230408
Validation loss: 1.838364488335066

Epoch: 6| Step: 4
Training loss: 0.9923893213272095
Validation loss: 1.8372581825461438

Epoch: 6| Step: 5
Training loss: 0.698330819606781
Validation loss: 1.8435217590742214

Epoch: 6| Step: 6
Training loss: 0.4856283962726593
Validation loss: 1.8138660487308298

Epoch: 6| Step: 7
Training loss: 0.7079634070396423
Validation loss: 1.753021071034093

Epoch: 6| Step: 8
Training loss: 1.281171441078186
Validation loss: 1.6852962624642156

Epoch: 6| Step: 9
Training loss: 0.47599172592163086
Validation loss: 1.6908062863093551

Epoch: 6| Step: 10
Training loss: 0.5865094661712646
Validation loss: 1.70433610229082

Epoch: 6| Step: 11
Training loss: 0.6502091884613037
Validation loss: 1.7188793382337015

Epoch: 6| Step: 12
Training loss: 0.8809857368469238
Validation loss: 1.7233986790462206

Epoch: 6| Step: 13
Training loss: 1.2737241983413696
Validation loss: 1.7062325618600334

Epoch: 202| Step: 0
Training loss: 0.9610112905502319
Validation loss: 1.6839185965958463

Epoch: 6| Step: 1
Training loss: 1.0002944469451904
Validation loss: 1.7533079911303777

Epoch: 6| Step: 2
Training loss: 1.155979037284851
Validation loss: 1.682280840412263

Epoch: 6| Step: 3
Training loss: 0.7365982532501221
Validation loss: 1.706583579381307

Epoch: 6| Step: 4
Training loss: 0.6738932132720947
Validation loss: 1.7335488693688506

Epoch: 6| Step: 5
Training loss: 0.8395600318908691
Validation loss: 1.7737383073376072

Epoch: 6| Step: 6
Training loss: 0.5848615169525146
Validation loss: 1.7453154415212653

Epoch: 6| Step: 7
Training loss: 0.919045090675354
Validation loss: 1.724889421975741

Epoch: 6| Step: 8
Training loss: 0.8410568237304688
Validation loss: 1.7599922123775686

Epoch: 6| Step: 9
Training loss: 0.6713038682937622
Validation loss: 1.7128784566797235

Epoch: 6| Step: 10
Training loss: 0.5107083320617676
Validation loss: 1.7026468784578386

Epoch: 6| Step: 11
Training loss: 0.9803251028060913
Validation loss: 1.7129353336108628

Epoch: 6| Step: 12
Training loss: 0.5168895721435547
Validation loss: 1.684975997094185

Epoch: 6| Step: 13
Training loss: 0.6446141004562378
Validation loss: 1.704970573866239

Epoch: 203| Step: 0
Training loss: 1.599910855293274
Validation loss: 1.6787660391099992

Epoch: 6| Step: 1
Training loss: 0.9462683200836182
Validation loss: 1.699753851018926

Epoch: 6| Step: 2
Training loss: 0.8107224702835083
Validation loss: 1.7127824611561273

Epoch: 6| Step: 3
Training loss: 0.4239506721496582
Validation loss: 1.7379635867252146

Epoch: 6| Step: 4
Training loss: 1.1017780303955078
Validation loss: 1.6844243746931835

Epoch: 6| Step: 5
Training loss: 0.804094135761261
Validation loss: 1.7338355407919934

Epoch: 6| Step: 6
Training loss: 0.5943108201026917
Validation loss: 1.720507239782682

Epoch: 6| Step: 7
Training loss: 0.3103671371936798
Validation loss: 1.7281095238142117

Epoch: 6| Step: 8
Training loss: 0.7581466436386108
Validation loss: 1.7113712526136828

Epoch: 6| Step: 9
Training loss: 0.9723864793777466
Validation loss: 1.726102158587466

Epoch: 6| Step: 10
Training loss: 0.49555981159210205
Validation loss: 1.7299455570918258

Epoch: 6| Step: 11
Training loss: 0.15636630356311798
Validation loss: 1.6813745985748947

Epoch: 6| Step: 12
Training loss: 0.8220049738883972
Validation loss: 1.7316113812949068

Epoch: 6| Step: 13
Training loss: 0.6929067969322205
Validation loss: 1.7082796045528945

Epoch: 204| Step: 0
Training loss: 0.6423358917236328
Validation loss: 1.6971536836316508

Epoch: 6| Step: 1
Training loss: 1.009209156036377
Validation loss: 1.6808665952374857

Epoch: 6| Step: 2
Training loss: 0.5808408260345459
Validation loss: 1.670362058506217

Epoch: 6| Step: 3
Training loss: 0.7551602125167847
Validation loss: 1.6602604382781572

Epoch: 6| Step: 4
Training loss: 0.5334345102310181
Validation loss: 1.6744373741970267

Epoch: 6| Step: 5
Training loss: 0.8677178621292114
Validation loss: 1.6563143537890526

Epoch: 6| Step: 6
Training loss: 0.862287163734436
Validation loss: 1.6661859994293542

Epoch: 6| Step: 7
Training loss: 0.6124106049537659
Validation loss: 1.6888418236086447

Epoch: 6| Step: 8
Training loss: 0.7358211278915405
Validation loss: 1.6875448265383322

Epoch: 6| Step: 9
Training loss: 1.1133232116699219
Validation loss: 1.7025059923048942

Epoch: 6| Step: 10
Training loss: 0.6287685632705688
Validation loss: 1.7200008887116627

Epoch: 6| Step: 11
Training loss: 0.5351047515869141
Validation loss: 1.733942481779283

Epoch: 6| Step: 12
Training loss: 0.8817416429519653
Validation loss: 1.749206413504898

Epoch: 6| Step: 13
Training loss: 0.6821663975715637
Validation loss: 1.7757020688826037

Epoch: 205| Step: 0
Training loss: 0.6240264177322388
Validation loss: 1.7698163781114804

Epoch: 6| Step: 1
Training loss: 0.7708377838134766
Validation loss: 1.7790195993197861

Epoch: 6| Step: 2
Training loss: 0.8407381772994995
Validation loss: 1.76517100872532

Epoch: 6| Step: 3
Training loss: 0.8052600026130676
Validation loss: 1.7561271549553

Epoch: 6| Step: 4
Training loss: 0.8111271858215332
Validation loss: 1.721463426466911

Epoch: 6| Step: 5
Training loss: 0.9060723185539246
Validation loss: 1.707230580750332

Epoch: 6| Step: 6
Training loss: 0.3135433793067932
Validation loss: 1.7176926751290598

Epoch: 6| Step: 7
Training loss: 0.7590010166168213
Validation loss: 1.737065238337363

Epoch: 6| Step: 8
Training loss: 0.7905141115188599
Validation loss: 1.7157229210740776

Epoch: 6| Step: 9
Training loss: 0.47426754236221313
Validation loss: 1.7236726258390693

Epoch: 6| Step: 10
Training loss: 0.9702103734016418
Validation loss: 1.7406910273336595

Epoch: 6| Step: 11
Training loss: 0.7581691741943359
Validation loss: 1.7485534093713249

Epoch: 6| Step: 12
Training loss: 1.00418221950531
Validation loss: 1.7891322758889967

Epoch: 6| Step: 13
Training loss: 0.4349134862422943
Validation loss: 1.7865589754555815

Epoch: 206| Step: 0
Training loss: 0.8105801343917847
Validation loss: 1.8088302535395469

Epoch: 6| Step: 1
Training loss: 0.39552780985832214
Validation loss: 1.7587999246453727

Epoch: 6| Step: 2
Training loss: 0.9878533482551575
Validation loss: 1.7668635832366122

Epoch: 6| Step: 3
Training loss: 0.6418925523757935
Validation loss: 1.7297509716403099

Epoch: 6| Step: 4
Training loss: 0.9961109757423401
Validation loss: 1.7473419609890188

Epoch: 6| Step: 5
Training loss: 0.49149301648139954
Validation loss: 1.736212674007621

Epoch: 6| Step: 6
Training loss: 0.6015863418579102
Validation loss: 1.7179777519677275

Epoch: 6| Step: 7
Training loss: 0.8600164651870728
Validation loss: 1.715455480801162

Epoch: 6| Step: 8
Training loss: 0.7871501445770264
Validation loss: 1.7342490996083906

Epoch: 6| Step: 9
Training loss: 0.7717581987380981
Validation loss: 1.718352335755543

Epoch: 6| Step: 10
Training loss: 0.6233012676239014
Validation loss: 1.6881792442772978

Epoch: 6| Step: 11
Training loss: 0.5770388841629028
Validation loss: 1.6833886177309099

Epoch: 6| Step: 12
Training loss: 0.6484749913215637
Validation loss: 1.7078297509942004

Epoch: 6| Step: 13
Training loss: 0.946173369884491
Validation loss: 1.7429155380495134

Epoch: 207| Step: 0
Training loss: 0.3283735513687134
Validation loss: 1.750587107032858

Epoch: 6| Step: 1
Training loss: 0.8415960073471069
Validation loss: 1.7734395752670944

Epoch: 6| Step: 2
Training loss: 1.0541114807128906
Validation loss: 1.744145078043784

Epoch: 6| Step: 3
Training loss: 0.8766319155693054
Validation loss: 1.7424531085516817

Epoch: 6| Step: 4
Training loss: 0.5908203125
Validation loss: 1.7559644688842118

Epoch: 6| Step: 5
Training loss: 0.7561114430427551
Validation loss: 1.7066857045696628

Epoch: 6| Step: 6
Training loss: 0.48903128504753113
Validation loss: 1.7114132642745972

Epoch: 6| Step: 7
Training loss: 1.0046875476837158
Validation loss: 1.7249681449705554

Epoch: 6| Step: 8
Training loss: 0.7359268665313721
Validation loss: 1.713841143474784

Epoch: 6| Step: 9
Training loss: 0.7392497062683105
Validation loss: 1.7095770874331075

Epoch: 6| Step: 10
Training loss: 0.7085009813308716
Validation loss: 1.721949509395066

Epoch: 6| Step: 11
Training loss: 0.8779955506324768
Validation loss: 1.6755601334315475

Epoch: 6| Step: 12
Training loss: 0.8217483758926392
Validation loss: 1.663782650424588

Epoch: 6| Step: 13
Training loss: 0.404497355222702
Validation loss: 1.689854924396802

Epoch: 208| Step: 0
Training loss: 0.755233883857727
Validation loss: 1.7299075357375606

Epoch: 6| Step: 1
Training loss: 0.6945990324020386
Validation loss: 1.741547288433198

Epoch: 6| Step: 2
Training loss: 0.8554439544677734
Validation loss: 1.7860696085037724

Epoch: 6| Step: 3
Training loss: 0.8100335597991943
Validation loss: 1.774546721930145

Epoch: 6| Step: 4
Training loss: 0.6554110050201416
Validation loss: 1.7425225729583411

Epoch: 6| Step: 5
Training loss: 0.7143422961235046
Validation loss: 1.7303425137714674

Epoch: 6| Step: 6
Training loss: 0.8947941660881042
Validation loss: 1.7687336155163345

Epoch: 6| Step: 7
Training loss: 0.6108272671699524
Validation loss: 1.7541273857957573

Epoch: 6| Step: 8
Training loss: 0.7442176938056946
Validation loss: 1.7126557532177176

Epoch: 6| Step: 9
Training loss: 1.2265123128890991
Validation loss: 1.6992950977817658

Epoch: 6| Step: 10
Training loss: 0.7843944430351257
Validation loss: 1.6859319556143977

Epoch: 6| Step: 11
Training loss: 0.5467185378074646
Validation loss: 1.6856991091082174

Epoch: 6| Step: 12
Training loss: 0.6332210302352905
Validation loss: 1.6923136621393182

Epoch: 6| Step: 13
Training loss: 0.5874705910682678
Validation loss: 1.700303985226539

Epoch: 209| Step: 0
Training loss: 0.49238431453704834
Validation loss: 1.7229446288078063

Epoch: 6| Step: 1
Training loss: 0.9642778635025024
Validation loss: 1.7202428656239663

Epoch: 6| Step: 2
Training loss: 0.47735631465911865
Validation loss: 1.6805752720884097

Epoch: 6| Step: 3
Training loss: 0.8336960673332214
Validation loss: 1.6644549703085294

Epoch: 6| Step: 4
Training loss: 0.5447897911071777
Validation loss: 1.6575855619163924

Epoch: 6| Step: 5
Training loss: 0.5847831964492798
Validation loss: 1.6832453666194793

Epoch: 6| Step: 6
Training loss: 0.9742722511291504
Validation loss: 1.670902967453003

Epoch: 6| Step: 7
Training loss: 0.7050014734268188
Validation loss: 1.66909227319943

Epoch: 6| Step: 8
Training loss: 0.9395439028739929
Validation loss: 1.6839879405113958

Epoch: 6| Step: 9
Training loss: 1.0444549322128296
Validation loss: 1.6799994399470668

Epoch: 6| Step: 10
Training loss: 1.0813016891479492
Validation loss: 1.653238957928073

Epoch: 6| Step: 11
Training loss: 0.6932981014251709
Validation loss: 1.6928088947009015

Epoch: 6| Step: 12
Training loss: 0.49130740761756897
Validation loss: 1.6691978246934953

Epoch: 6| Step: 13
Training loss: 0.8287038207054138
Validation loss: 1.677836020787557

Epoch: 210| Step: 0
Training loss: 0.7936058640480042
Validation loss: 1.6927595548732306

Epoch: 6| Step: 1
Training loss: 0.6110903024673462
Validation loss: 1.6901904101012855

Epoch: 6| Step: 2
Training loss: 0.7090293169021606
Validation loss: 1.6986127322719944

Epoch: 6| Step: 3
Training loss: 0.571397066116333
Validation loss: 1.709951252065679

Epoch: 6| Step: 4
Training loss: 0.8383394479751587
Validation loss: 1.7477035881370626

Epoch: 6| Step: 5
Training loss: 0.6153938174247742
Validation loss: 1.746435737097135

Epoch: 6| Step: 6
Training loss: 0.6021763682365417
Validation loss: 1.7873334192460584

Epoch: 6| Step: 7
Training loss: 0.5755859613418579
Validation loss: 1.7742046771510955

Epoch: 6| Step: 8
Training loss: 0.7651607394218445
Validation loss: 1.78133302093834

Epoch: 6| Step: 9
Training loss: 0.8724214434623718
Validation loss: 1.7715534625514862

Epoch: 6| Step: 10
Training loss: 0.647994875907898
Validation loss: 1.7605558159530803

Epoch: 6| Step: 11
Training loss: 1.018744945526123
Validation loss: 1.7371563590982908

Epoch: 6| Step: 12
Training loss: 0.6481491327285767
Validation loss: 1.797307211865661

Epoch: 6| Step: 13
Training loss: 1.4008127450942993
Validation loss: 1.758695287089194

Epoch: 211| Step: 0
Training loss: 0.6155006289482117
Validation loss: 1.7329479494402487

Epoch: 6| Step: 1
Training loss: 0.9162179231643677
Validation loss: 1.7157830679288475

Epoch: 6| Step: 2
Training loss: 0.9047235250473022
Validation loss: 1.7042462710411317

Epoch: 6| Step: 3
Training loss: 0.7708706855773926
Validation loss: 1.6843923112397552

Epoch: 6| Step: 4
Training loss: 0.5031051635742188
Validation loss: 1.662040860422196

Epoch: 6| Step: 5
Training loss: 0.6252144575119019
Validation loss: 1.681264071054356

Epoch: 6| Step: 6
Training loss: 0.6484072208404541
Validation loss: 1.6720097808427707

Epoch: 6| Step: 7
Training loss: 1.0445623397827148
Validation loss: 1.6692554296985749

Epoch: 6| Step: 8
Training loss: 0.6411496996879578
Validation loss: 1.6971983204605758

Epoch: 6| Step: 9
Training loss: 0.6153876185417175
Validation loss: 1.673404142420779

Epoch: 6| Step: 10
Training loss: 0.5941632390022278
Validation loss: 1.6840468850187076

Epoch: 6| Step: 11
Training loss: 0.48997050523757935
Validation loss: 1.7327910264333088

Epoch: 6| Step: 12
Training loss: 0.7719566822052002
Validation loss: 1.73240795699499

Epoch: 6| Step: 13
Training loss: 1.2461848258972168
Validation loss: 1.7392040221921858

Epoch: 212| Step: 0
Training loss: 0.5449506640434265
Validation loss: 1.7343083402161956

Epoch: 6| Step: 1
Training loss: 0.5723811388015747
Validation loss: 1.737777284396592

Epoch: 6| Step: 2
Training loss: 1.0606725215911865
Validation loss: 1.7373985398200251

Epoch: 6| Step: 3
Training loss: 1.038577675819397
Validation loss: 1.8009856093314387

Epoch: 6| Step: 4
Training loss: 0.6816408634185791
Validation loss: 1.8237121617922218

Epoch: 6| Step: 5
Training loss: 0.4597121477127075
Validation loss: 1.8380150525800643

Epoch: 6| Step: 6
Training loss: 0.8262709379196167
Validation loss: 1.838262217019194

Epoch: 6| Step: 7
Training loss: 0.9470345973968506
Validation loss: 1.80288060890731

Epoch: 6| Step: 8
Training loss: 0.7863553762435913
Validation loss: 1.8159419157171761

Epoch: 6| Step: 9
Training loss: 0.46100908517837524
Validation loss: 1.7382960511792092

Epoch: 6| Step: 10
Training loss: 0.5775836110115051
Validation loss: 1.6709280244765743

Epoch: 6| Step: 11
Training loss: 0.5152634978294373
Validation loss: 1.7237870052296629

Epoch: 6| Step: 12
Training loss: 1.1313804388046265
Validation loss: 1.699395666840256

Epoch: 6| Step: 13
Training loss: 0.7230468392372131
Validation loss: 1.7175145354322208

Epoch: 213| Step: 0
Training loss: 0.7720173001289368
Validation loss: 1.6944895739196448

Epoch: 6| Step: 1
Training loss: 0.6073800325393677
Validation loss: 1.6892056824058614

Epoch: 6| Step: 2
Training loss: 0.6578752994537354
Validation loss: 1.703097612627091

Epoch: 6| Step: 3
Training loss: 0.9885427951812744
Validation loss: 1.7054906878420102

Epoch: 6| Step: 4
Training loss: 0.8179006576538086
Validation loss: 1.6558944538075437

Epoch: 6| Step: 5
Training loss: 0.8996376395225525
Validation loss: 1.675547884356591

Epoch: 6| Step: 6
Training loss: 0.7405964136123657
Validation loss: 1.7183310203654791

Epoch: 6| Step: 7
Training loss: 0.5751873254776001
Validation loss: 1.730313462595786

Epoch: 6| Step: 8
Training loss: 0.765730619430542
Validation loss: 1.7278011152821202

Epoch: 6| Step: 9
Training loss: 0.6171868443489075
Validation loss: 1.7354219126444992

Epoch: 6| Step: 10
Training loss: 0.5977816581726074
Validation loss: 1.7230566111944055

Epoch: 6| Step: 11
Training loss: 0.7076685428619385
Validation loss: 1.7240509909968222

Epoch: 6| Step: 12
Training loss: 0.5864748358726501
Validation loss: 1.7470752808355516

Epoch: 6| Step: 13
Training loss: 0.928099513053894
Validation loss: 1.743180996628218

Epoch: 214| Step: 0
Training loss: 0.8651354312896729
Validation loss: 1.7138485318870955

Epoch: 6| Step: 1
Training loss: 0.5607459545135498
Validation loss: 1.69708312455044

Epoch: 6| Step: 2
Training loss: 0.5414654612541199
Validation loss: 1.6443110409603323

Epoch: 6| Step: 3
Training loss: 0.9061177968978882
Validation loss: 1.6664339303970337

Epoch: 6| Step: 4
Training loss: 0.8081961274147034
Validation loss: 1.664010646522686

Epoch: 6| Step: 5
Training loss: 0.7937049269676208
Validation loss: 1.6541861013699604

Epoch: 6| Step: 6
Training loss: 0.567347526550293
Validation loss: 1.6699330486277097

Epoch: 6| Step: 7
Training loss: 0.5483037829399109
Validation loss: 1.6920682794304305

Epoch: 6| Step: 8
Training loss: 0.6768912076950073
Validation loss: 1.6902687152226765

Epoch: 6| Step: 9
Training loss: 0.6271635293960571
Validation loss: 1.6712704999472505

Epoch: 6| Step: 10
Training loss: 0.663994312286377
Validation loss: 1.681793547445728

Epoch: 6| Step: 11
Training loss: 0.5205157399177551
Validation loss: 1.6947189787382722

Epoch: 6| Step: 12
Training loss: 0.9433621764183044
Validation loss: 1.7182158398371872

Epoch: 6| Step: 13
Training loss: 0.8736542463302612
Validation loss: 1.7090794476129676

Epoch: 215| Step: 0
Training loss: 0.5051474571228027
Validation loss: 1.7307012747692805

Epoch: 6| Step: 1
Training loss: 0.5644218325614929
Validation loss: 1.7462774784334245

Epoch: 6| Step: 2
Training loss: 0.5513107776641846
Validation loss: 1.7295173329691733

Epoch: 6| Step: 3
Training loss: 1.0458734035491943
Validation loss: 1.7344655375326834

Epoch: 6| Step: 4
Training loss: 0.687798023223877
Validation loss: 1.7183169318783669

Epoch: 6| Step: 5
Training loss: 0.7405200004577637
Validation loss: 1.7414500456984325

Epoch: 6| Step: 6
Training loss: 0.7773898243904114
Validation loss: 1.717125573465901

Epoch: 6| Step: 7
Training loss: 0.5162975788116455
Validation loss: 1.736579713001046

Epoch: 6| Step: 8
Training loss: 0.503284215927124
Validation loss: 1.7429799546477616

Epoch: 6| Step: 9
Training loss: 0.7809640169143677
Validation loss: 1.7395078764166882

Epoch: 6| Step: 10
Training loss: 0.5227817893028259
Validation loss: 1.700646444033551

Epoch: 6| Step: 11
Training loss: 0.6562708616256714
Validation loss: 1.6808933109365485

Epoch: 6| Step: 12
Training loss: 0.6694660782814026
Validation loss: 1.648649033679757

Epoch: 6| Step: 13
Training loss: 0.8169572353363037
Validation loss: 1.6777026499471357

Epoch: 216| Step: 0
Training loss: 0.46933406591415405
Validation loss: 1.6891605174669655

Epoch: 6| Step: 1
Training loss: 0.7331660985946655
Validation loss: 1.7548939079366705

Epoch: 6| Step: 2
Training loss: 0.7875869870185852
Validation loss: 1.7334555707952028

Epoch: 6| Step: 3
Training loss: 0.41376060247421265
Validation loss: 1.680359980111481

Epoch: 6| Step: 4
Training loss: 0.6395009756088257
Validation loss: 1.6567735800179102

Epoch: 6| Step: 5
Training loss: 1.026174783706665
Validation loss: 1.6413546915977233

Epoch: 6| Step: 6
Training loss: 0.5944731831550598
Validation loss: 1.6200348292627642

Epoch: 6| Step: 7
Training loss: 0.3968391418457031
Validation loss: 1.648975291559773

Epoch: 6| Step: 8
Training loss: 0.7674363255500793
Validation loss: 1.624748941390745

Epoch: 6| Step: 9
Training loss: 0.7516499161720276
Validation loss: 1.6223963704160465

Epoch: 6| Step: 10
Training loss: 0.6291036605834961
Validation loss: 1.622148480466617

Epoch: 6| Step: 11
Training loss: 1.0016505718231201
Validation loss: 1.6361751184668591

Epoch: 6| Step: 12
Training loss: 0.7709823250770569
Validation loss: 1.6471579741406184

Epoch: 6| Step: 13
Training loss: 0.9536473155021667
Validation loss: 1.6657398464859172

Epoch: 217| Step: 0
Training loss: 0.6027719974517822
Validation loss: 1.7180438451869513

Epoch: 6| Step: 1
Training loss: 0.8930764198303223
Validation loss: 1.7339272319629628

Epoch: 6| Step: 2
Training loss: 0.618182897567749
Validation loss: 1.745281320746227

Epoch: 6| Step: 3
Training loss: 0.7994869351387024
Validation loss: 1.720831964605598

Epoch: 6| Step: 4
Training loss: 0.5974861979484558
Validation loss: 1.7005524250768846

Epoch: 6| Step: 5
Training loss: 0.7008569240570068
Validation loss: 1.7159951733004661

Epoch: 6| Step: 6
Training loss: 1.2850703001022339
Validation loss: 1.691860152829078

Epoch: 6| Step: 7
Training loss: 0.7402525544166565
Validation loss: 1.668643452787912

Epoch: 6| Step: 8
Training loss: 0.5608358979225159
Validation loss: 1.669346228722603

Epoch: 6| Step: 9
Training loss: 0.92200767993927
Validation loss: 1.616876926473392

Epoch: 6| Step: 10
Training loss: 0.34439271688461304
Validation loss: 1.662394603093465

Epoch: 6| Step: 11
Training loss: 0.6366723775863647
Validation loss: 1.6187808385459326

Epoch: 6| Step: 12
Training loss: 0.5218251347541809
Validation loss: 1.6177198117779148

Epoch: 6| Step: 13
Training loss: 0.5798566341400146
Validation loss: 1.6629945975477978

Epoch: 218| Step: 0
Training loss: 0.5694501399993896
Validation loss: 1.682741218997586

Epoch: 6| Step: 1
Training loss: 0.6010513305664062
Validation loss: 1.7038618185186898

Epoch: 6| Step: 2
Training loss: 0.8143471479415894
Validation loss: 1.6740877474507978

Epoch: 6| Step: 3
Training loss: 0.6302799582481384
Validation loss: 1.698214465571988

Epoch: 6| Step: 4
Training loss: 0.5450900793075562
Validation loss: 1.651091573058918

Epoch: 6| Step: 5
Training loss: 0.5109750032424927
Validation loss: 1.6392150630233109

Epoch: 6| Step: 6
Training loss: 0.49576568603515625
Validation loss: 1.6359963186325566

Epoch: 6| Step: 7
Training loss: 0.5692546963691711
Validation loss: 1.6423882874109412

Epoch: 6| Step: 8
Training loss: 0.45940399169921875
Validation loss: 1.6616932884339364

Epoch: 6| Step: 9
Training loss: 0.8479762077331543
Validation loss: 1.6520798962603334

Epoch: 6| Step: 10
Training loss: 0.6148394346237183
Validation loss: 1.6983201196116786

Epoch: 6| Step: 11
Training loss: 1.1548054218292236
Validation loss: 1.693624593878305

Epoch: 6| Step: 12
Training loss: 0.6305806636810303
Validation loss: 1.6964967507188038

Epoch: 6| Step: 13
Training loss: 0.5590134859085083
Validation loss: 1.681640448108796

Epoch: 219| Step: 0
Training loss: 0.7475383877754211
Validation loss: 1.6869879230376212

Epoch: 6| Step: 1
Training loss: 0.4879556894302368
Validation loss: 1.6743785540262859

Epoch: 6| Step: 2
Training loss: 0.6121329069137573
Validation loss: 1.6321737099719305

Epoch: 6| Step: 3
Training loss: 0.4024229049682617
Validation loss: 1.611185848072011

Epoch: 6| Step: 4
Training loss: 0.9961816668510437
Validation loss: 1.6468947446474465

Epoch: 6| Step: 5
Training loss: 1.0783582925796509
Validation loss: 1.6287176647493917

Epoch: 6| Step: 6
Training loss: 0.6015580892562866
Validation loss: 1.6576348735440163

Epoch: 6| Step: 7
Training loss: 0.3212728500366211
Validation loss: 1.6401444173628283

Epoch: 6| Step: 8
Training loss: 0.6011519432067871
Validation loss: 1.6562486105067755

Epoch: 6| Step: 9
Training loss: 0.8812832832336426
Validation loss: 1.6968667404626006

Epoch: 6| Step: 10
Training loss: 0.5636301040649414
Validation loss: 1.6934599453403103

Epoch: 6| Step: 11
Training loss: 0.655236005783081
Validation loss: 1.692393046553417

Epoch: 6| Step: 12
Training loss: 0.6331998109817505
Validation loss: 1.6651155666638446

Epoch: 6| Step: 13
Training loss: 0.3920081853866577
Validation loss: 1.6550034528137536

Epoch: 220| Step: 0
Training loss: 0.7430707812309265
Validation loss: 1.6256223763189008

Epoch: 6| Step: 1
Training loss: 0.6681091785430908
Validation loss: 1.6031893376381166

Epoch: 6| Step: 2
Training loss: 0.9035725593566895
Validation loss: 1.6287928550474104

Epoch: 6| Step: 3
Training loss: 0.6106824278831482
Validation loss: 1.5981302158806914

Epoch: 6| Step: 4
Training loss: 0.37731462717056274
Validation loss: 1.6226305423244354

Epoch: 6| Step: 5
Training loss: 0.301005482673645
Validation loss: 1.5942339140881774

Epoch: 6| Step: 6
Training loss: 0.7096799612045288
Validation loss: 1.6137904749121716

Epoch: 6| Step: 7
Training loss: 0.9912453293800354
Validation loss: 1.6763513434317805

Epoch: 6| Step: 8
Training loss: 0.7082406282424927
Validation loss: 1.7124761778821227

Epoch: 6| Step: 9
Training loss: 0.6926654577255249
Validation loss: 1.7412946557485929

Epoch: 6| Step: 10
Training loss: 0.6128836870193481
Validation loss: 1.7819282765029578

Epoch: 6| Step: 11
Training loss: 0.3458099663257599
Validation loss: 1.7888811365250619

Epoch: 6| Step: 12
Training loss: 0.5621638298034668
Validation loss: 1.7839348098283172

Epoch: 6| Step: 13
Training loss: 1.1047803163528442
Validation loss: 1.7712007914820025

Epoch: 221| Step: 0
Training loss: 0.7785068154335022
Validation loss: 1.695618514091738

Epoch: 6| Step: 1
Training loss: 0.8785204887390137
Validation loss: 1.6780151833770096

Epoch: 6| Step: 2
Training loss: 0.6513931751251221
Validation loss: 1.6399033415702082

Epoch: 6| Step: 3
Training loss: 0.42838209867477417
Validation loss: 1.6067857973037227

Epoch: 6| Step: 4
Training loss: 0.4091389775276184
Validation loss: 1.629171222768804

Epoch: 6| Step: 5
Training loss: 0.9442793130874634
Validation loss: 1.6166425007645802

Epoch: 6| Step: 6
Training loss: 0.7287237644195557
Validation loss: 1.6283835967381795

Epoch: 6| Step: 7
Training loss: 0.7627336382865906
Validation loss: 1.6345377686203166

Epoch: 6| Step: 8
Training loss: 0.4535258114337921
Validation loss: 1.6316909238856325

Epoch: 6| Step: 9
Training loss: 0.5564957857131958
Validation loss: 1.66498512734649

Epoch: 6| Step: 10
Training loss: 0.698432445526123
Validation loss: 1.6756994724273682

Epoch: 6| Step: 11
Training loss: 0.761597752571106
Validation loss: 1.6498657080434984

Epoch: 6| Step: 12
Training loss: 0.8067925572395325
Validation loss: 1.704967055269467

Epoch: 6| Step: 13
Training loss: 0.37459948658943176
Validation loss: 1.6815390279216151

Epoch: 222| Step: 0
Training loss: 0.5992573499679565
Validation loss: 1.6593253638154717

Epoch: 6| Step: 1
Training loss: 0.8693438172340393
Validation loss: 1.6322636424854238

Epoch: 6| Step: 2
Training loss: 0.44825395941734314
Validation loss: 1.6244491005456576

Epoch: 6| Step: 3
Training loss: 0.6998271346092224
Validation loss: 1.618621277552779

Epoch: 6| Step: 4
Training loss: 0.39437633752822876
Validation loss: 1.6083138296681065

Epoch: 6| Step: 5
Training loss: 0.5756717920303345
Validation loss: 1.6434298356374104

Epoch: 6| Step: 6
Training loss: 1.092796802520752
Validation loss: 1.6276718980522566

Epoch: 6| Step: 7
Training loss: 0.3863605856895447
Validation loss: 1.6608151017978627

Epoch: 6| Step: 8
Training loss: 0.6176109910011292
Validation loss: 1.6629511361481042

Epoch: 6| Step: 9
Training loss: 0.769055962562561
Validation loss: 1.681016445159912

Epoch: 6| Step: 10
Training loss: 0.6303378343582153
Validation loss: 1.674125007403794

Epoch: 6| Step: 11
Training loss: 0.6583234667778015
Validation loss: 1.6857688170607372

Epoch: 6| Step: 12
Training loss: 0.7219012975692749
Validation loss: 1.7028167247772217

Epoch: 6| Step: 13
Training loss: 0.8843092918395996
Validation loss: 1.7687080880647064

Epoch: 223| Step: 0
Training loss: 0.7923648953437805
Validation loss: 1.7322187756979337

Epoch: 6| Step: 1
Training loss: 0.8466417789459229
Validation loss: 1.7231834139875186

Epoch: 6| Step: 2
Training loss: 0.20238398015499115
Validation loss: 1.6960892510670487

Epoch: 6| Step: 3
Training loss: 0.7209805250167847
Validation loss: 1.6628735296187862

Epoch: 6| Step: 4
Training loss: 0.7413127422332764
Validation loss: 1.6771952003561041

Epoch: 6| Step: 5
Training loss: 0.2903820276260376
Validation loss: 1.6530075509061095

Epoch: 6| Step: 6
Training loss: 0.6171975135803223
Validation loss: 1.6642148994630384

Epoch: 6| Step: 7
Training loss: 0.5871284008026123
Validation loss: 1.6649048225854033

Epoch: 6| Step: 8
Training loss: 0.5639321208000183
Validation loss: 1.6865107231242682

Epoch: 6| Step: 9
Training loss: 0.7338960766792297
Validation loss: 1.67880509232962

Epoch: 6| Step: 10
Training loss: 0.8969135284423828
Validation loss: 1.709013750476222

Epoch: 6| Step: 11
Training loss: 0.7590075731277466
Validation loss: 1.7073491158023957

Epoch: 6| Step: 12
Training loss: 0.47275084257125854
Validation loss: 1.715615439158614

Epoch: 6| Step: 13
Training loss: 1.0133795738220215
Validation loss: 1.7472407984477218

Epoch: 224| Step: 0
Training loss: 0.7984753847122192
Validation loss: 1.770493668894614

Epoch: 6| Step: 1
Training loss: 0.5409814119338989
Validation loss: 1.7866366729941419

Epoch: 6| Step: 2
Training loss: 0.5779761075973511
Validation loss: 1.7834292970677859

Epoch: 6| Step: 3
Training loss: 0.521213173866272
Validation loss: 1.7850450226055679

Epoch: 6| Step: 4
Training loss: 0.7141921520233154
Validation loss: 1.7586746997730707

Epoch: 6| Step: 5
Training loss: 0.5586150288581848
Validation loss: 1.6855671405792236

Epoch: 6| Step: 6
Training loss: 0.715469241142273
Validation loss: 1.7058935088496054

Epoch: 6| Step: 7
Training loss: 0.44068923592567444
Validation loss: 1.7176487471467705

Epoch: 6| Step: 8
Training loss: 0.4958365559577942
Validation loss: 1.7025447045603106

Epoch: 6| Step: 9
Training loss: 0.7484831213951111
Validation loss: 1.6839333747022895

Epoch: 6| Step: 10
Training loss: 0.6937015056610107
Validation loss: 1.6862993201901835

Epoch: 6| Step: 11
Training loss: 0.46849098801612854
Validation loss: 1.6981286541108163

Epoch: 6| Step: 12
Training loss: 0.42981234192848206
Validation loss: 1.7071760316048898

Epoch: 6| Step: 13
Training loss: 0.5873234272003174
Validation loss: 1.731347110963637

Epoch: 225| Step: 0
Training loss: 0.4882611632347107
Validation loss: 1.7411923587963145

Epoch: 6| Step: 1
Training loss: 0.4302038550376892
Validation loss: 1.7107590911208943

Epoch: 6| Step: 2
Training loss: 0.47694456577301025
Validation loss: 1.744780186683901

Epoch: 6| Step: 3
Training loss: 0.5811079740524292
Validation loss: 1.7350480710306475

Epoch: 6| Step: 4
Training loss: 0.9401848316192627
Validation loss: 1.7011529886594383

Epoch: 6| Step: 5
Training loss: 0.6915186047554016
Validation loss: 1.690330728407829

Epoch: 6| Step: 6
Training loss: 0.36523592472076416
Validation loss: 1.6744780572511817

Epoch: 6| Step: 7
Training loss: 0.579200267791748
Validation loss: 1.6670914708927114

Epoch: 6| Step: 8
Training loss: 0.5566645860671997
Validation loss: 1.6598947163551085

Epoch: 6| Step: 9
Training loss: 0.7368302941322327
Validation loss: 1.6780850964207803

Epoch: 6| Step: 10
Training loss: 0.6267425417900085
Validation loss: 1.6565993306457356

Epoch: 6| Step: 11
Training loss: 0.4397898316383362
Validation loss: 1.640736428640222

Epoch: 6| Step: 12
Training loss: 0.8601803183555603
Validation loss: 1.6551479927955135

Epoch: 6| Step: 13
Training loss: 0.5646352767944336
Validation loss: 1.642838010223963

Epoch: 226| Step: 0
Training loss: 0.40384265780448914
Validation loss: 1.6397577460094164

Epoch: 6| Step: 1
Training loss: 0.5631908178329468
Validation loss: 1.6800467737259404

Epoch: 6| Step: 2
Training loss: 1.278953194618225
Validation loss: 1.691992457194995

Epoch: 6| Step: 3
Training loss: 0.4278438091278076
Validation loss: 1.7087367926874468

Epoch: 6| Step: 4
Training loss: 1.0303685665130615
Validation loss: 1.719313794566739

Epoch: 6| Step: 5
Training loss: 0.48320817947387695
Validation loss: 1.7078861754427674

Epoch: 6| Step: 6
Training loss: 0.657991349697113
Validation loss: 1.6906526985988821

Epoch: 6| Step: 7
Training loss: 0.6445070505142212
Validation loss: 1.6825970885574177

Epoch: 6| Step: 8
Training loss: 0.2871444821357727
Validation loss: 1.6487491733284407

Epoch: 6| Step: 9
Training loss: 0.3885546028614044
Validation loss: 1.6571440171169978

Epoch: 6| Step: 10
Training loss: 0.7057191133499146
Validation loss: 1.6764210398479173

Epoch: 6| Step: 11
Training loss: 0.4363217055797577
Validation loss: 1.6678302800783547

Epoch: 6| Step: 12
Training loss: 0.42296987771987915
Validation loss: 1.6537302745285856

Epoch: 6| Step: 13
Training loss: 0.271750807762146
Validation loss: 1.6543772246247979

Epoch: 227| Step: 0
Training loss: 1.0868514776229858
Validation loss: 1.692311817599881

Epoch: 6| Step: 1
Training loss: 0.5273450613021851
Validation loss: 1.6870529997733332

Epoch: 6| Step: 2
Training loss: 0.5033183097839355
Validation loss: 1.6906342967864005

Epoch: 6| Step: 3
Training loss: 0.523087739944458
Validation loss: 1.7097386647296209

Epoch: 6| Step: 4
Training loss: 0.7494153380393982
Validation loss: 1.7251924148169897

Epoch: 6| Step: 5
Training loss: 0.27228087186813354
Validation loss: 1.7370747353440972

Epoch: 6| Step: 6
Training loss: 0.5373342037200928
Validation loss: 1.7011117409634333

Epoch: 6| Step: 7
Training loss: 0.6988650560379028
Validation loss: 1.6932177582094747

Epoch: 6| Step: 8
Training loss: 0.7206097841262817
Validation loss: 1.6767554231869277

Epoch: 6| Step: 9
Training loss: 0.24643129110336304
Validation loss: 1.6713764090691843

Epoch: 6| Step: 10
Training loss: 0.45310577750205994
Validation loss: 1.6367018722718762

Epoch: 6| Step: 11
Training loss: 0.5175817012786865
Validation loss: 1.6582256017192718

Epoch: 6| Step: 12
Training loss: 0.5489928126335144
Validation loss: 1.6521541405749578

Epoch: 6| Step: 13
Training loss: 0.8735940456390381
Validation loss: 1.6321895814711047

Epoch: 228| Step: 0
Training loss: 0.6166136264801025
Validation loss: 1.6205424057540072

Epoch: 6| Step: 1
Training loss: 0.961746335029602
Validation loss: 1.6210506039281045

Epoch: 6| Step: 2
Training loss: 0.6787565350532532
Validation loss: 1.61076025168101

Epoch: 6| Step: 3
Training loss: 0.43497759103775024
Validation loss: 1.6211322802369312

Epoch: 6| Step: 4
Training loss: 0.2712900638580322
Validation loss: 1.6514877042462748

Epoch: 6| Step: 5
Training loss: 0.8898991346359253
Validation loss: 1.6459235965564687

Epoch: 6| Step: 6
Training loss: 0.44156312942504883
Validation loss: 1.6329052691818566

Epoch: 6| Step: 7
Training loss: 0.4759150445461273
Validation loss: 1.6695681284832697

Epoch: 6| Step: 8
Training loss: 0.3103283643722534
Validation loss: 1.669831936077405

Epoch: 6| Step: 9
Training loss: 0.3106408715248108
Validation loss: 1.6626613473379483

Epoch: 6| Step: 10
Training loss: 0.6104050874710083
Validation loss: 1.663098624957505

Epoch: 6| Step: 11
Training loss: 0.6151069402694702
Validation loss: 1.6741952947390977

Epoch: 6| Step: 12
Training loss: 0.3752853274345398
Validation loss: 1.6671324417155275

Epoch: 6| Step: 13
Training loss: 0.9832797646522522
Validation loss: 1.644449185299617

Epoch: 229| Step: 0
Training loss: 0.3442901372909546
Validation loss: 1.6585269358850294

Epoch: 6| Step: 1
Training loss: 0.44882410764694214
Validation loss: 1.6688780630788496

Epoch: 6| Step: 2
Training loss: 1.2342820167541504
Validation loss: 1.6698881374892367

Epoch: 6| Step: 3
Training loss: 0.5704196691513062
Validation loss: 1.670790937639052

Epoch: 6| Step: 4
Training loss: 0.6452264785766602
Validation loss: 1.6807919561222036

Epoch: 6| Step: 5
Training loss: 0.3376251757144928
Validation loss: 1.66140914476046

Epoch: 6| Step: 6
Training loss: 0.4694445729255676
Validation loss: 1.6342630924717072

Epoch: 6| Step: 7
Training loss: 0.7595279216766357
Validation loss: 1.6489718652540637

Epoch: 6| Step: 8
Training loss: 0.3507327139377594
Validation loss: 1.658250617724593

Epoch: 6| Step: 9
Training loss: 0.45526689291000366
Validation loss: 1.6665504619639406

Epoch: 6| Step: 10
Training loss: 0.5453006029129028
Validation loss: 1.7022868074396604

Epoch: 6| Step: 11
Training loss: 0.5181103348731995
Validation loss: 1.6973971295100387

Epoch: 6| Step: 12
Training loss: 0.458432137966156
Validation loss: 1.6933965631710586

Epoch: 6| Step: 13
Training loss: 0.21886394917964935
Validation loss: 1.6583519456207112

Epoch: 230| Step: 0
Training loss: 0.7955827116966248
Validation loss: 1.7343324704836773

Epoch: 6| Step: 1
Training loss: 0.9795103073120117
Validation loss: 1.7482001050826041

Epoch: 6| Step: 2
Training loss: 0.429630845785141
Validation loss: 1.7148473993424447

Epoch: 6| Step: 3
Training loss: 0.6268374919891357
Validation loss: 1.684452328630673

Epoch: 6| Step: 4
Training loss: 0.37272757291793823
Validation loss: 1.668543973276692

Epoch: 6| Step: 5
Training loss: 0.4597737193107605
Validation loss: 1.6217114387019989

Epoch: 6| Step: 6
Training loss: 0.4459853172302246
Validation loss: 1.6099956432978313

Epoch: 6| Step: 7
Training loss: 0.4199340045452118
Validation loss: 1.6268380136900051

Epoch: 6| Step: 8
Training loss: 0.6696265339851379
Validation loss: 1.6276344406989314

Epoch: 6| Step: 9
Training loss: 0.6321824789047241
Validation loss: 1.619422238360169

Epoch: 6| Step: 10
Training loss: 0.6243769526481628
Validation loss: 1.6370711570144982

Epoch: 6| Step: 11
Training loss: 0.495888888835907
Validation loss: 1.6056358224602156

Epoch: 6| Step: 12
Training loss: 0.5028016567230225
Validation loss: 1.673584286884595

Epoch: 6| Step: 13
Training loss: 0.653464138507843
Validation loss: 1.6754594233728224

Epoch: 231| Step: 0
Training loss: 0.49114111065864563
Validation loss: 1.7079533069364485

Epoch: 6| Step: 1
Training loss: 0.42719101905822754
Validation loss: 1.696408284607754

Epoch: 6| Step: 2
Training loss: 0.6044268012046814
Validation loss: 1.7185286168129212

Epoch: 6| Step: 3
Training loss: 0.5032221078872681
Validation loss: 1.6871663729349773

Epoch: 6| Step: 4
Training loss: 0.31314292550086975
Validation loss: 1.6365215688623407

Epoch: 6| Step: 5
Training loss: 0.832500696182251
Validation loss: 1.6223975407179965

Epoch: 6| Step: 6
Training loss: 0.6131823062896729
Validation loss: 1.588396215951571

Epoch: 6| Step: 7
Training loss: 0.5107538104057312
Validation loss: 1.5809635039298766

Epoch: 6| Step: 8
Training loss: 1.024620771408081
Validation loss: 1.5888406025466097

Epoch: 6| Step: 9
Training loss: 0.6503709554672241
Validation loss: 1.6122368561324252

Epoch: 6| Step: 10
Training loss: 0.5035480856895447
Validation loss: 1.599047419845417

Epoch: 6| Step: 11
Training loss: 0.35634809732437134
Validation loss: 1.5951485454395253

Epoch: 6| Step: 12
Training loss: 0.33837229013442993
Validation loss: 1.6023922774099535

Epoch: 6| Step: 13
Training loss: 0.4450165033340454
Validation loss: 1.623971926268711

Epoch: 232| Step: 0
Training loss: 0.3198556900024414
Validation loss: 1.6409165308039675

Epoch: 6| Step: 1
Training loss: 0.6096978783607483
Validation loss: 1.6918120384216309

Epoch: 6| Step: 2
Training loss: 0.5462818145751953
Validation loss: 1.6739873770744569

Epoch: 6| Step: 3
Training loss: 0.260586678981781
Validation loss: 1.6927672663042623

Epoch: 6| Step: 4
Training loss: 0.4174838066101074
Validation loss: 1.6872781604848883

Epoch: 6| Step: 5
Training loss: 0.5479483604431152
Validation loss: 1.6897049155286563

Epoch: 6| Step: 6
Training loss: 0.634526252746582
Validation loss: 1.7067592887468235

Epoch: 6| Step: 7
Training loss: 0.8544794321060181
Validation loss: 1.6943347210525184

Epoch: 6| Step: 8
Training loss: 0.5328522324562073
Validation loss: 1.666667233231247

Epoch: 6| Step: 9
Training loss: 0.7685596942901611
Validation loss: 1.662405748521128

Epoch: 6| Step: 10
Training loss: 0.690213680267334
Validation loss: 1.6520598652542278

Epoch: 6| Step: 11
Training loss: 0.28456568717956543
Validation loss: 1.65625496192645

Epoch: 6| Step: 12
Training loss: 0.34125226736068726
Validation loss: 1.6607454604999994

Epoch: 6| Step: 13
Training loss: 0.8099105954170227
Validation loss: 1.6670622979440997

Epoch: 233| Step: 0
Training loss: 0.6199346780776978
Validation loss: 1.6811208468611523

Epoch: 6| Step: 1
Training loss: 0.6539003849029541
Validation loss: 1.6903447412675427

Epoch: 6| Step: 2
Training loss: 0.6382647752761841
Validation loss: 1.6725963059292044

Epoch: 6| Step: 3
Training loss: 0.4430217444896698
Validation loss: 1.6727548158296974

Epoch: 6| Step: 4
Training loss: 0.5965207815170288
Validation loss: 1.652120526118945

Epoch: 6| Step: 5
Training loss: 0.4359137713909149
Validation loss: 1.6685149656829013

Epoch: 6| Step: 6
Training loss: 0.5282201766967773
Validation loss: 1.6328912832403695

Epoch: 6| Step: 7
Training loss: 0.23859328031539917
Validation loss: 1.6352876854199234

Epoch: 6| Step: 8
Training loss: 0.5562964677810669
Validation loss: 1.6585830693603845

Epoch: 6| Step: 9
Training loss: 0.28618374466896057
Validation loss: 1.6653195709310553

Epoch: 6| Step: 10
Training loss: 0.8150551915168762
Validation loss: 1.6778095870889642

Epoch: 6| Step: 11
Training loss: 0.730850338935852
Validation loss: 1.6976728554694884

Epoch: 6| Step: 12
Training loss: 0.5184338092803955
Validation loss: 1.7134000678216257

Epoch: 6| Step: 13
Training loss: 0.1642640382051468
Validation loss: 1.6962464009561846

Epoch: 234| Step: 0
Training loss: 0.5186184048652649
Validation loss: 1.691734895911268

Epoch: 6| Step: 1
Training loss: 0.4115946292877197
Validation loss: 1.6627309873539915

Epoch: 6| Step: 2
Training loss: 0.5188039541244507
Validation loss: 1.6699176167929044

Epoch: 6| Step: 3
Training loss: 0.6054517030715942
Validation loss: 1.6725981004776493

Epoch: 6| Step: 4
Training loss: 0.5580427646636963
Validation loss: 1.6506893692478057

Epoch: 6| Step: 5
Training loss: 0.5730972290039062
Validation loss: 1.6245264814745994

Epoch: 6| Step: 6
Training loss: 0.7863155603408813
Validation loss: 1.6196666391946937

Epoch: 6| Step: 7
Training loss: 0.4412558674812317
Validation loss: 1.6254532516643565

Epoch: 6| Step: 8
Training loss: 0.7695252895355225
Validation loss: 1.6151927427578998

Epoch: 6| Step: 9
Training loss: 0.6661596298217773
Validation loss: 1.6575019526225265

Epoch: 6| Step: 10
Training loss: 0.33685457706451416
Validation loss: 1.6719725131988525

Epoch: 6| Step: 11
Training loss: 0.60631263256073
Validation loss: 1.683448600512679

Epoch: 6| Step: 12
Training loss: 0.5392978191375732
Validation loss: 1.6907408468184932

Epoch: 6| Step: 13
Training loss: 0.314175009727478
Validation loss: 1.7208387056986492

Epoch: 235| Step: 0
Training loss: 0.4782143235206604
Validation loss: 1.7147084743745866

Epoch: 6| Step: 1
Training loss: 0.4299812316894531
Validation loss: 1.7285948120137697

Epoch: 6| Step: 2
Training loss: 0.5712260007858276
Validation loss: 1.7542226775999992

Epoch: 6| Step: 3
Training loss: 0.43038350343704224
Validation loss: 1.7045050231359338

Epoch: 6| Step: 4
Training loss: 0.7609168291091919
Validation loss: 1.6913790625910605

Epoch: 6| Step: 5
Training loss: 0.4726775586605072
Validation loss: 1.7256590679127684

Epoch: 6| Step: 6
Training loss: 0.5925332307815552
Validation loss: 1.733036559115174

Epoch: 6| Step: 7
Training loss: 0.7930907607078552
Validation loss: 1.7136319350170832

Epoch: 6| Step: 8
Training loss: 0.49310582876205444
Validation loss: 1.7135439944523636

Epoch: 6| Step: 9
Training loss: 0.46897637844085693
Validation loss: 1.7179360646073536

Epoch: 6| Step: 10
Training loss: 0.4568936228752136
Validation loss: 1.7195916791116037

Epoch: 6| Step: 11
Training loss: 0.6709113717079163
Validation loss: 1.735985397010721

Epoch: 6| Step: 12
Training loss: 0.5971488952636719
Validation loss: 1.7103134111691547

Epoch: 6| Step: 13
Training loss: 0.35998693108558655
Validation loss: 1.7500144038149106

Epoch: 236| Step: 0
Training loss: 0.39924219250679016
Validation loss: 1.7322005328311716

Epoch: 6| Step: 1
Training loss: 0.4192977547645569
Validation loss: 1.7172669518378474

Epoch: 6| Step: 2
Training loss: 0.5891570448875427
Validation loss: 1.714166247716514

Epoch: 6| Step: 3
Training loss: 0.35969892144203186
Validation loss: 1.669460190239773

Epoch: 6| Step: 4
Training loss: 0.6304613351821899
Validation loss: 1.661902339227738

Epoch: 6| Step: 5
Training loss: 0.4952542781829834
Validation loss: 1.6818456521598242

Epoch: 6| Step: 6
Training loss: 0.6056393980979919
Validation loss: 1.6657742774614723

Epoch: 6| Step: 7
Training loss: 0.4593673050403595
Validation loss: 1.6700807591920257

Epoch: 6| Step: 8
Training loss: 0.48647329211235046
Validation loss: 1.7019967930291289

Epoch: 6| Step: 9
Training loss: 0.4716872572898865
Validation loss: 1.6969611285835184

Epoch: 6| Step: 10
Training loss: 0.446746289730072
Validation loss: 1.6982449203409173

Epoch: 6| Step: 11
Training loss: 0.8507013916969299
Validation loss: 1.672272705262707

Epoch: 6| Step: 12
Training loss: 0.33356088399887085
Validation loss: 1.681219962335402

Epoch: 6| Step: 13
Training loss: 0.4925675392150879
Validation loss: 1.6805129525482014

Epoch: 237| Step: 0
Training loss: 0.6470242738723755
Validation loss: 1.6895677517819148

Epoch: 6| Step: 1
Training loss: 0.49771401286125183
Validation loss: 1.7150144756481212

Epoch: 6| Step: 2
Training loss: 0.5029007792472839
Validation loss: 1.6935134895386235

Epoch: 6| Step: 3
Training loss: 0.2855755686759949
Validation loss: 1.6907958087100778

Epoch: 6| Step: 4
Training loss: 0.10022366046905518
Validation loss: 1.6715406012791458

Epoch: 6| Step: 5
Training loss: 0.4350683093070984
Validation loss: 1.6336430298384799

Epoch: 6| Step: 6
Training loss: 0.30241501331329346
Validation loss: 1.6391112599321591

Epoch: 6| Step: 7
Training loss: 0.3853045105934143
Validation loss: 1.6719293120086833

Epoch: 6| Step: 8
Training loss: 0.9598069787025452
Validation loss: 1.675913926093809

Epoch: 6| Step: 9
Training loss: 0.4636983573436737
Validation loss: 1.677685288972752

Epoch: 6| Step: 10
Training loss: 0.26914548873901367
Validation loss: 1.677442132785756

Epoch: 6| Step: 11
Training loss: 0.7041140198707581
Validation loss: 1.6886979405597975

Epoch: 6| Step: 12
Training loss: 0.5279591083526611
Validation loss: 1.7047771894803612

Epoch: 6| Step: 13
Training loss: 0.6760027408599854
Validation loss: 1.6534241181547924

Epoch: 238| Step: 0
Training loss: 0.1935880035161972
Validation loss: 1.6966527867060837

Epoch: 6| Step: 1
Training loss: 0.6324396133422852
Validation loss: 1.6552272253139044

Epoch: 6| Step: 2
Training loss: 0.40700387954711914
Validation loss: 1.643780682676582

Epoch: 6| Step: 3
Training loss: 0.6739009618759155
Validation loss: 1.6561340670431814

Epoch: 6| Step: 4
Training loss: 0.3593880534172058
Validation loss: 1.6626604475000852

Epoch: 6| Step: 5
Training loss: 0.5215706825256348
Validation loss: 1.657065253103933

Epoch: 6| Step: 6
Training loss: 0.4957597255706787
Validation loss: 1.6209455536257835

Epoch: 6| Step: 7
Training loss: 0.6234227418899536
Validation loss: 1.62550397329433

Epoch: 6| Step: 8
Training loss: 0.5176340341567993
Validation loss: 1.6189944410836825

Epoch: 6| Step: 9
Training loss: 0.47488540410995483
Validation loss: 1.663434290116833

Epoch: 6| Step: 10
Training loss: 0.5009434223175049
Validation loss: 1.6649905507282545

Epoch: 6| Step: 11
Training loss: 0.8176459074020386
Validation loss: 1.6715305941079253

Epoch: 6| Step: 12
Training loss: 0.40033143758773804
Validation loss: 1.6395480350781513

Epoch: 6| Step: 13
Training loss: 0.32404497265815735
Validation loss: 1.6445073222601285

Epoch: 239| Step: 0
Training loss: 0.37057584524154663
Validation loss: 1.6179678978458527

Epoch: 6| Step: 1
Training loss: 0.4895530939102173
Validation loss: 1.6147372684171122

Epoch: 6| Step: 2
Training loss: 0.35143136978149414
Validation loss: 1.643572151020009

Epoch: 6| Step: 3
Training loss: 0.5160571336746216
Validation loss: 1.6439350510156283

Epoch: 6| Step: 4
Training loss: 0.9182944893836975
Validation loss: 1.6609280827224895

Epoch: 6| Step: 5
Training loss: 0.46062394976615906
Validation loss: 1.6353895279668993

Epoch: 6| Step: 6
Training loss: 0.3670535683631897
Validation loss: 1.6683973484141852

Epoch: 6| Step: 7
Training loss: 0.24020695686340332
Validation loss: 1.6817631119041032

Epoch: 6| Step: 8
Training loss: 0.4312339127063751
Validation loss: 1.6801078550277218

Epoch: 6| Step: 9
Training loss: 0.36131417751312256
Validation loss: 1.6868621918462938

Epoch: 6| Step: 10
Training loss: 0.9122754335403442
Validation loss: 1.7202950831382506

Epoch: 6| Step: 11
Training loss: 0.6375320553779602
Validation loss: 1.7108458069063002

Epoch: 6| Step: 12
Training loss: 0.5719796419143677
Validation loss: 1.6980520409922446

Epoch: 6| Step: 13
Training loss: 0.5293939113616943
Validation loss: 1.7016003093411844

Epoch: 240| Step: 0
Training loss: 0.43664491176605225
Validation loss: 1.6804820914422312

Epoch: 6| Step: 1
Training loss: 0.7461479306221008
Validation loss: 1.660877057301101

Epoch: 6| Step: 2
Training loss: 0.4832107722759247
Validation loss: 1.6234170608623053

Epoch: 6| Step: 3
Training loss: 0.5021147131919861
Validation loss: 1.6440842600278958

Epoch: 6| Step: 4
Training loss: 0.6469377875328064
Validation loss: 1.6359150159743525

Epoch: 6| Step: 5
Training loss: 0.5494017601013184
Validation loss: 1.6405828460570304

Epoch: 6| Step: 6
Training loss: 0.3267032206058502
Validation loss: 1.6989220419237692

Epoch: 6| Step: 7
Training loss: 0.5338189601898193
Validation loss: 1.7031364223008514

Epoch: 6| Step: 8
Training loss: 0.43420687317848206
Validation loss: 1.7172803353237849

Epoch: 6| Step: 9
Training loss: 0.5512670874595642
Validation loss: 1.7564598450096705

Epoch: 6| Step: 10
Training loss: 0.2817932367324829
Validation loss: 1.7386517909265333

Epoch: 6| Step: 11
Training loss: 0.46220338344573975
Validation loss: 1.7441087307468537

Epoch: 6| Step: 12
Training loss: 0.6541340351104736
Validation loss: 1.7230250655963857

Epoch: 6| Step: 13
Training loss: 0.3774976432323456
Validation loss: 1.6873172585682203

Epoch: 241| Step: 0
Training loss: 0.4650120139122009
Validation loss: 1.6570076096442439

Epoch: 6| Step: 1
Training loss: 0.6576462388038635
Validation loss: 1.6577480736599173

Epoch: 6| Step: 2
Training loss: 0.29468387365341187
Validation loss: 1.65227460604842

Epoch: 6| Step: 3
Training loss: 0.2638252377510071
Validation loss: 1.6416301701658516

Epoch: 6| Step: 4
Training loss: 0.8970832824707031
Validation loss: 1.6819543633409726

Epoch: 6| Step: 5
Training loss: 0.29998356103897095
Validation loss: 1.6610975906413088

Epoch: 6| Step: 6
Training loss: 0.35545432567596436
Validation loss: 1.6539379319837015

Epoch: 6| Step: 7
Training loss: 0.3854500949382782
Validation loss: 1.6519808807680685

Epoch: 6| Step: 8
Training loss: 0.5843717455863953
Validation loss: 1.6810505588849385

Epoch: 6| Step: 9
Training loss: 0.6141185164451599
Validation loss: 1.653484413700719

Epoch: 6| Step: 10
Training loss: 0.4137424826622009
Validation loss: 1.6478577275430002

Epoch: 6| Step: 11
Training loss: 0.5332384705543518
Validation loss: 1.609786368185474

Epoch: 6| Step: 12
Training loss: 0.4911269247531891
Validation loss: 1.6059918544625724

Epoch: 6| Step: 13
Training loss: 0.5751546025276184
Validation loss: 1.580778383439587

Epoch: 242| Step: 0
Training loss: 0.6613210439682007
Validation loss: 1.5787160511939757

Epoch: 6| Step: 1
Training loss: 0.9262297749519348
Validation loss: 1.5749202453961937

Epoch: 6| Step: 2
Training loss: 0.515794038772583
Validation loss: 1.5997170696976364

Epoch: 6| Step: 3
Training loss: 0.4037535786628723
Validation loss: 1.6013123873741395

Epoch: 6| Step: 4
Training loss: 0.4477536082267761
Validation loss: 1.6140407990383845

Epoch: 6| Step: 5
Training loss: 0.4515961706638336
Validation loss: 1.6232187606955086

Epoch: 6| Step: 6
Training loss: 0.5303902626037598
Validation loss: 1.6362683978132022

Epoch: 6| Step: 7
Training loss: 0.5413132905960083
Validation loss: 1.6281753560548187

Epoch: 6| Step: 8
Training loss: 0.4499393701553345
Validation loss: 1.6323009537112327

Epoch: 6| Step: 9
Training loss: 0.28709307312965393
Validation loss: 1.634901431299025

Epoch: 6| Step: 10
Training loss: 0.414991557598114
Validation loss: 1.6719210634949386

Epoch: 6| Step: 11
Training loss: 0.4403182864189148
Validation loss: 1.6620244249220817

Epoch: 6| Step: 12
Training loss: 0.43526315689086914
Validation loss: 1.6968423653674383

Epoch: 6| Step: 13
Training loss: 0.59123694896698
Validation loss: 1.6727906004075082

Epoch: 243| Step: 0
Training loss: 0.5566017627716064
Validation loss: 1.6571086683580953

Epoch: 6| Step: 1
Training loss: 0.57663494348526
Validation loss: 1.6786163122423234

Epoch: 6| Step: 2
Training loss: 0.2867322564125061
Validation loss: 1.6804124116897583

Epoch: 6| Step: 3
Training loss: 0.6514418125152588
Validation loss: 1.6359710372904295

Epoch: 6| Step: 4
Training loss: 0.2516239881515503
Validation loss: 1.6652364064288396

Epoch: 6| Step: 5
Training loss: 0.5832786560058594
Validation loss: 1.6785383634669806

Epoch: 6| Step: 6
Training loss: 0.7385443449020386
Validation loss: 1.686694969413101

Epoch: 6| Step: 7
Training loss: 0.25352200865745544
Validation loss: 1.7236287927114835

Epoch: 6| Step: 8
Training loss: 0.30908098816871643
Validation loss: 1.7157641174972698

Epoch: 6| Step: 9
Training loss: 0.5450941324234009
Validation loss: 1.6891856167906074

Epoch: 6| Step: 10
Training loss: 0.41231709718704224
Validation loss: 1.742064360649355

Epoch: 6| Step: 11
Training loss: 0.5275102853775024
Validation loss: 1.735771402235954

Epoch: 6| Step: 12
Training loss: 0.2510852515697479
Validation loss: 1.7280418911287863

Epoch: 6| Step: 13
Training loss: 0.8006362318992615
Validation loss: 1.760725986573004

Epoch: 244| Step: 0
Training loss: 0.5110970139503479
Validation loss: 1.7336895017213718

Epoch: 6| Step: 1
Training loss: 0.4812195301055908
Validation loss: 1.741922258048929

Epoch: 6| Step: 2
Training loss: 0.759784460067749
Validation loss: 1.7623175920978669

Epoch: 6| Step: 3
Training loss: 0.2668377757072449
Validation loss: 1.7204980196491364

Epoch: 6| Step: 4
Training loss: 0.6018931269645691
Validation loss: 1.7023618810920305

Epoch: 6| Step: 5
Training loss: 0.5984786748886108
Validation loss: 1.6730872700291295

Epoch: 6| Step: 6
Training loss: 0.6058206558227539
Validation loss: 1.6731621706357567

Epoch: 6| Step: 7
Training loss: 0.32472991943359375
Validation loss: 1.6552032860376502

Epoch: 6| Step: 8
Training loss: 0.20854182541370392
Validation loss: 1.6711543747173843

Epoch: 6| Step: 9
Training loss: 0.5605931282043457
Validation loss: 1.6289656495535245

Epoch: 6| Step: 10
Training loss: 0.28502142429351807
Validation loss: 1.693795947618382

Epoch: 6| Step: 11
Training loss: 0.3656638264656067
Validation loss: 1.7054863809257426

Epoch: 6| Step: 12
Training loss: 0.2682744264602661
Validation loss: 1.6964240317703576

Epoch: 6| Step: 13
Training loss: 0.5019160509109497
Validation loss: 1.6875539133625646

Epoch: 245| Step: 0
Training loss: 0.454821914434433
Validation loss: 1.689643931645219

Epoch: 6| Step: 1
Training loss: 0.2874073088169098
Validation loss: 1.6797932322307298

Epoch: 6| Step: 2
Training loss: 0.40263622999191284
Validation loss: 1.638767808996221

Epoch: 6| Step: 3
Training loss: 0.42322003841400146
Validation loss: 1.6284825596758115

Epoch: 6| Step: 4
Training loss: 0.7653987407684326
Validation loss: 1.6684668884482434

Epoch: 6| Step: 5
Training loss: 0.20318260788917542
Validation loss: 1.65801985802189

Epoch: 6| Step: 6
Training loss: 0.5367348790168762
Validation loss: 1.650125552249211

Epoch: 6| Step: 7
Training loss: 0.6080939769744873
Validation loss: 1.6838869753704275

Epoch: 6| Step: 8
Training loss: 0.27817171812057495
Validation loss: 1.6466535688728414

Epoch: 6| Step: 9
Training loss: 0.3352891206741333
Validation loss: 1.6675975912360734

Epoch: 6| Step: 10
Training loss: 0.5353127717971802
Validation loss: 1.6927260865447342

Epoch: 6| Step: 11
Training loss: 0.3709140419960022
Validation loss: 1.6958604320403068

Epoch: 6| Step: 12
Training loss: 0.4719451069831848
Validation loss: 1.685810301893501

Epoch: 6| Step: 13
Training loss: 0.5274373292922974
Validation loss: 1.6582311558467087

Epoch: 246| Step: 0
Training loss: 0.2635555863380432
Validation loss: 1.6824516737332909

Epoch: 6| Step: 1
Training loss: 0.41284582018852234
Validation loss: 1.6660977063640472

Epoch: 6| Step: 2
Training loss: 0.41996514797210693
Validation loss: 1.66439619628332

Epoch: 6| Step: 3
Training loss: 0.419312447309494
Validation loss: 1.6730478296997726

Epoch: 6| Step: 4
Training loss: 0.4988347589969635
Validation loss: 1.653915483464477

Epoch: 6| Step: 5
Training loss: 0.4265223741531372
Validation loss: 1.6645284827037523

Epoch: 6| Step: 6
Training loss: 0.39195817708969116
Validation loss: 1.672211826488536

Epoch: 6| Step: 7
Training loss: 0.48288726806640625
Validation loss: 1.7123623855652348

Epoch: 6| Step: 8
Training loss: 0.4187193512916565
Validation loss: 1.72864531957975

Epoch: 6| Step: 9
Training loss: 0.606420636177063
Validation loss: 1.7028372851751183

Epoch: 6| Step: 10
Training loss: 0.6468708515167236
Validation loss: 1.705032507578532

Epoch: 6| Step: 11
Training loss: 0.7137210965156555
Validation loss: 1.6990913844877673

Epoch: 6| Step: 12
Training loss: 0.4544740617275238
Validation loss: 1.6824675170324181

Epoch: 6| Step: 13
Training loss: 0.47578349709510803
Validation loss: 1.6783908695302985

Epoch: 247| Step: 0
Training loss: 0.43541744351387024
Validation loss: 1.6971494831064695

Epoch: 6| Step: 1
Training loss: 0.2743775248527527
Validation loss: 1.6866144364879978

Epoch: 6| Step: 2
Training loss: 0.5350304245948792
Validation loss: 1.6988623257606261

Epoch: 6| Step: 3
Training loss: 0.2573041319847107
Validation loss: 1.7114873983526742

Epoch: 6| Step: 4
Training loss: 0.871202826499939
Validation loss: 1.7347223886879541

Epoch: 6| Step: 5
Training loss: 0.6261550188064575
Validation loss: 1.7610569807790941

Epoch: 6| Step: 6
Training loss: 0.423419326543808
Validation loss: 1.7665271675714882

Epoch: 6| Step: 7
Training loss: 0.23995988070964813
Validation loss: 1.7387940947727492

Epoch: 6| Step: 8
Training loss: 0.6409398317337036
Validation loss: 1.7640252318433536

Epoch: 6| Step: 9
Training loss: 0.511404275894165
Validation loss: 1.7778289446266748

Epoch: 6| Step: 10
Training loss: 0.38176339864730835
Validation loss: 1.745557938852618

Epoch: 6| Step: 11
Training loss: 0.47771120071411133
Validation loss: 1.7445361409136044

Epoch: 6| Step: 12
Training loss: 0.2104288637638092
Validation loss: 1.6815911813448834

Epoch: 6| Step: 13
Training loss: 0.6121895909309387
Validation loss: 1.701526273963272

Epoch: 248| Step: 0
Training loss: 0.2576414942741394
Validation loss: 1.7017577630217358

Epoch: 6| Step: 1
Training loss: 0.47283226251602173
Validation loss: 1.6716644866492159

Epoch: 6| Step: 2
Training loss: 0.4743790626525879
Validation loss: 1.6888752573279924

Epoch: 6| Step: 3
Training loss: 0.5889043807983398
Validation loss: 1.7001120351975965

Epoch: 6| Step: 4
Training loss: 0.273613303899765
Validation loss: 1.6686773479625743

Epoch: 6| Step: 5
Training loss: 0.37042558193206787
Validation loss: 1.6855209335204093

Epoch: 6| Step: 6
Training loss: 0.3609229624271393
Validation loss: 1.6532756666983328

Epoch: 6| Step: 7
Training loss: 0.4671213626861572
Validation loss: 1.6656318121058966

Epoch: 6| Step: 8
Training loss: 0.5503225326538086
Validation loss: 1.6566298302783762

Epoch: 6| Step: 9
Training loss: 0.3692362308502197
Validation loss: 1.7044728468823176

Epoch: 6| Step: 10
Training loss: 0.41160911321640015
Validation loss: 1.6936906383883568

Epoch: 6| Step: 11
Training loss: 0.8438284993171692
Validation loss: 1.6814887344196279

Epoch: 6| Step: 12
Training loss: 0.25488707423210144
Validation loss: 1.6866681768048195

Epoch: 6| Step: 13
Training loss: 0.6545501351356506
Validation loss: 1.6572988751114055

Epoch: 249| Step: 0
Training loss: 0.4273512661457062
Validation loss: 1.6390568594778738

Epoch: 6| Step: 1
Training loss: 0.47084856033325195
Validation loss: 1.6263023973793111

Epoch: 6| Step: 2
Training loss: 0.35978084802627563
Validation loss: 1.6518901099440872

Epoch: 6| Step: 3
Training loss: 0.3696640729904175
Validation loss: 1.6491313621562014

Epoch: 6| Step: 4
Training loss: 0.4848025441169739
Validation loss: 1.6230360090091664

Epoch: 6| Step: 5
Training loss: 0.627164363861084
Validation loss: 1.6102588330545733

Epoch: 6| Step: 6
Training loss: 0.5200206637382507
Validation loss: 1.6826039142506097

Epoch: 6| Step: 7
Training loss: 0.4014492630958557
Validation loss: 1.6549922727769422

Epoch: 6| Step: 8
Training loss: 0.11888150125741959
Validation loss: 1.6814761841168968

Epoch: 6| Step: 9
Training loss: 0.4253677725791931
Validation loss: 1.7296575506528218

Epoch: 6| Step: 10
Training loss: 0.7581498622894287
Validation loss: 1.7213428904933314

Epoch: 6| Step: 11
Training loss: 0.18448278307914734
Validation loss: 1.7703139730679092

Epoch: 6| Step: 12
Training loss: 0.4208301305770874
Validation loss: 1.7192280536056848

Epoch: 6| Step: 13
Training loss: 0.26070526242256165
Validation loss: 1.701185259767758

Epoch: 250| Step: 0
Training loss: 0.31186068058013916
Validation loss: 1.703600804011027

Epoch: 6| Step: 1
Training loss: 0.5122184753417969
Validation loss: 1.6730411860250658

Epoch: 6| Step: 2
Training loss: 0.718783974647522
Validation loss: 1.6729695438056864

Epoch: 6| Step: 3
Training loss: 0.18000048398971558
Validation loss: 1.668118707595333

Epoch: 6| Step: 4
Training loss: 0.5123078227043152
Validation loss: 1.6886037139482395

Epoch: 6| Step: 5
Training loss: 0.2762913703918457
Validation loss: 1.6645357916432042

Epoch: 6| Step: 6
Training loss: 0.5885698199272156
Validation loss: 1.6979666550954182

Epoch: 6| Step: 7
Training loss: 0.418867826461792
Validation loss: 1.7199056071619834

Epoch: 6| Step: 8
Training loss: 0.44239193201065063
Validation loss: 1.774846560211592

Epoch: 6| Step: 9
Training loss: 0.3638637661933899
Validation loss: 1.7779193514136857

Epoch: 6| Step: 10
Training loss: 0.6312050819396973
Validation loss: 1.7835870917125414

Epoch: 6| Step: 11
Training loss: 0.40374332666397095
Validation loss: 1.7403601113186087

Epoch: 6| Step: 12
Training loss: 0.36871469020843506
Validation loss: 1.7093995694191224

Epoch: 6| Step: 13
Training loss: 0.22113929688930511
Validation loss: 1.619007432332603

Epoch: 251| Step: 0
Training loss: 0.25066348910331726
Validation loss: 1.6425402933551418

Epoch: 6| Step: 1
Training loss: 0.3763434886932373
Validation loss: 1.6293108899106261

Epoch: 6| Step: 2
Training loss: 0.3910523056983948
Validation loss: 1.6321996091514506

Epoch: 6| Step: 3
Training loss: 0.29767876863479614
Validation loss: 1.6731570318181028

Epoch: 6| Step: 4
Training loss: 0.43232497572898865
Validation loss: 1.6734616833348428

Epoch: 6| Step: 5
Training loss: 0.6696532368659973
Validation loss: 1.7331073527695031

Epoch: 6| Step: 6
Training loss: 0.4537891447544098
Validation loss: 1.739376401388517

Epoch: 6| Step: 7
Training loss: 0.5917876958847046
Validation loss: 1.7303980460730932

Epoch: 6| Step: 8
Training loss: 0.46693819761276245
Validation loss: 1.7661042828713693

Epoch: 6| Step: 9
Training loss: 0.47247514128685
Validation loss: 1.7790799666476507

Epoch: 6| Step: 10
Training loss: 0.3683536946773529
Validation loss: 1.758313782753483

Epoch: 6| Step: 11
Training loss: 0.5562922954559326
Validation loss: 1.7395500393324002

Epoch: 6| Step: 12
Training loss: 0.6714586019515991
Validation loss: 1.7190183183198333

Epoch: 6| Step: 13
Training loss: 0.5419166088104248
Validation loss: 1.686232889852216

Epoch: 252| Step: 0
Training loss: 0.2694370746612549
Validation loss: 1.6456130050843762

Epoch: 6| Step: 1
Training loss: 0.5703132748603821
Validation loss: 1.651369748576995

Epoch: 6| Step: 2
Training loss: 0.35761550068855286
Validation loss: 1.6259588874796385

Epoch: 6| Step: 3
Training loss: 0.1761901080608368
Validation loss: 1.6321896160802534

Epoch: 6| Step: 4
Training loss: 0.6861166954040527
Validation loss: 1.684579526224444

Epoch: 6| Step: 5
Training loss: 0.37445032596588135
Validation loss: 1.6955962924547092

Epoch: 6| Step: 6
Training loss: 0.5104193687438965
Validation loss: 1.7372552348721413

Epoch: 6| Step: 7
Training loss: 0.5041149854660034
Validation loss: 1.7130292038763724

Epoch: 6| Step: 8
Training loss: 0.391997754573822
Validation loss: 1.7366895214203866

Epoch: 6| Step: 9
Training loss: 0.830057680606842
Validation loss: 1.6997364131353234

Epoch: 6| Step: 10
Training loss: 0.5547627806663513
Validation loss: 1.6789851778297014

Epoch: 6| Step: 11
Training loss: 0.4252505302429199
Validation loss: 1.692177959667739

Epoch: 6| Step: 12
Training loss: 0.3301953673362732
Validation loss: 1.668169129279352

Epoch: 6| Step: 13
Training loss: 0.2813991904258728
Validation loss: 1.6859477643043763

Epoch: 253| Step: 0
Training loss: 0.12125709652900696
Validation loss: 1.665430272779157

Epoch: 6| Step: 1
Training loss: 0.5726073980331421
Validation loss: 1.6783456597276913

Epoch: 6| Step: 2
Training loss: 0.35036736726760864
Validation loss: 1.6591395229421637

Epoch: 6| Step: 3
Training loss: 0.7587652802467346
Validation loss: 1.722382035306705

Epoch: 6| Step: 4
Training loss: 0.36035627126693726
Validation loss: 1.7199531088593185

Epoch: 6| Step: 5
Training loss: 0.23590433597564697
Validation loss: 1.7790706196138937

Epoch: 6| Step: 6
Training loss: 0.6626770496368408
Validation loss: 1.7455884679671256

Epoch: 6| Step: 7
Training loss: 0.4498121738433838
Validation loss: 1.7547613202884633

Epoch: 6| Step: 8
Training loss: 0.48527613282203674
Validation loss: 1.7372087945220291

Epoch: 6| Step: 9
Training loss: 0.4081406593322754
Validation loss: 1.714142507122409

Epoch: 6| Step: 10
Training loss: 0.3189765214920044
Validation loss: 1.7054677906856741

Epoch: 6| Step: 11
Training loss: 0.18160594999790192
Validation loss: 1.7097907912346624

Epoch: 6| Step: 12
Training loss: 0.46403223276138306
Validation loss: 1.6499308860430153

Epoch: 6| Step: 13
Training loss: 0.4188246428966522
Validation loss: 1.688801803896504

Epoch: 254| Step: 0
Training loss: 0.40622061491012573
Validation loss: 1.6782808893470353

Epoch: 6| Step: 1
Training loss: 0.4315897822380066
Validation loss: 1.6689680609651791

Epoch: 6| Step: 2
Training loss: 0.368776798248291
Validation loss: 1.7189429037032589

Epoch: 6| Step: 3
Training loss: 0.39102429151535034
Validation loss: 1.7006018969320482

Epoch: 6| Step: 4
Training loss: 0.345024049282074
Validation loss: 1.6941561391276698

Epoch: 6| Step: 5
Training loss: 0.2717602849006653
Validation loss: 1.72104714890962

Epoch: 6| Step: 6
Training loss: 0.46741580963134766
Validation loss: 1.7059010369803316

Epoch: 6| Step: 7
Training loss: 0.3903416097164154
Validation loss: 1.6886768584610314

Epoch: 6| Step: 8
Training loss: 0.2018609344959259
Validation loss: 1.7193376325791883

Epoch: 6| Step: 9
Training loss: 0.4206329882144928
Validation loss: 1.694305774986103

Epoch: 6| Step: 10
Training loss: 0.2901684045791626
Validation loss: 1.6933296406140892

Epoch: 6| Step: 11
Training loss: 0.2664129436016083
Validation loss: 1.6764186889894548

Epoch: 6| Step: 12
Training loss: 0.7589893937110901
Validation loss: 1.6825406384724442

Epoch: 6| Step: 13
Training loss: 0.43184006214141846
Validation loss: 1.6311705356003137

Epoch: 255| Step: 0
Training loss: 0.37258562445640564
Validation loss: 1.639953464590093

Epoch: 6| Step: 1
Training loss: 0.37211406230926514
Validation loss: 1.6336777940873177

Epoch: 6| Step: 2
Training loss: 0.5939106941223145
Validation loss: 1.6574575542121806

Epoch: 6| Step: 3
Training loss: 0.27147358655929565
Validation loss: 1.6534423443578905

Epoch: 6| Step: 4
Training loss: 0.44121846556663513
Validation loss: 1.6781484119353756

Epoch: 6| Step: 5
Training loss: 0.6830419898033142
Validation loss: 1.6450882983464066

Epoch: 6| Step: 6
Training loss: 0.1784842312335968
Validation loss: 1.6702384782093826

Epoch: 6| Step: 7
Training loss: 0.3428395986557007
Validation loss: 1.6607754345863097

Epoch: 6| Step: 8
Training loss: 0.6720802783966064
Validation loss: 1.6362931189998504

Epoch: 6| Step: 9
Training loss: 0.24956098198890686
Validation loss: 1.6546759092679588

Epoch: 6| Step: 10
Training loss: 0.2576692998409271
Validation loss: 1.6323295652225454

Epoch: 6| Step: 11
Training loss: 0.5542110204696655
Validation loss: 1.6525653613510953

Epoch: 6| Step: 12
Training loss: 0.3979203402996063
Validation loss: 1.649360756720266

Epoch: 6| Step: 13
Training loss: 0.2950507700443268
Validation loss: 1.6753086479761268

Epoch: 256| Step: 0
Training loss: 0.38641709089279175
Validation loss: 1.6560869742465276

Epoch: 6| Step: 1
Training loss: 0.4643113911151886
Validation loss: 1.668721818154858

Epoch: 6| Step: 2
Training loss: 0.37661975622177124
Validation loss: 1.7134017149607341

Epoch: 6| Step: 3
Training loss: 0.22697539627552032
Validation loss: 1.6789540513869254

Epoch: 6| Step: 4
Training loss: 0.4198700785636902
Validation loss: 1.6817544224441692

Epoch: 6| Step: 5
Training loss: 0.42324838042259216
Validation loss: 1.6255814080597253

Epoch: 6| Step: 6
Training loss: 0.2618129849433899
Validation loss: 1.6713738313285254

Epoch: 6| Step: 7
Training loss: 0.4068982005119324
Validation loss: 1.6462766957539383

Epoch: 6| Step: 8
Training loss: 0.22670120000839233
Validation loss: 1.6512962464363343

Epoch: 6| Step: 9
Training loss: 0.5766539573669434
Validation loss: 1.650533422347038

Epoch: 6| Step: 10
Training loss: 0.3935509920120239
Validation loss: 1.6504155000050862

Epoch: 6| Step: 11
Training loss: 0.26675504446029663
Validation loss: 1.6494218982676023

Epoch: 6| Step: 12
Training loss: 0.3726509213447571
Validation loss: 1.6371097500606249

Epoch: 6| Step: 13
Training loss: 0.6094779372215271
Validation loss: 1.6599521976645275

Epoch: 257| Step: 0
Training loss: 0.7130692005157471
Validation loss: 1.6759319331056328

Epoch: 6| Step: 1
Training loss: 0.33605995774269104
Validation loss: 1.7370074481092475

Epoch: 6| Step: 2
Training loss: 0.23176361620426178
Validation loss: 1.6984180058202436

Epoch: 6| Step: 3
Training loss: 0.34809398651123047
Validation loss: 1.6990332680363809

Epoch: 6| Step: 4
Training loss: 0.4024949073791504
Validation loss: 1.718227340329078

Epoch: 6| Step: 5
Training loss: 0.36645835638046265
Validation loss: 1.6701014919947552

Epoch: 6| Step: 6
Training loss: 0.3989623785018921
Validation loss: 1.6491603518045077

Epoch: 6| Step: 7
Training loss: 0.49658775329589844
Validation loss: 1.6518952820890693

Epoch: 6| Step: 8
Training loss: 0.47568851709365845
Validation loss: 1.6382362214467858

Epoch: 6| Step: 9
Training loss: 0.10080966353416443
Validation loss: 1.6308204961079422

Epoch: 6| Step: 10
Training loss: 0.44529348611831665
Validation loss: 1.659768396808255

Epoch: 6| Step: 11
Training loss: 0.2829510271549225
Validation loss: 1.6565386300445886

Epoch: 6| Step: 12
Training loss: 0.25467750430107117
Validation loss: 1.6572935888844151

Epoch: 6| Step: 13
Training loss: 0.623840868473053
Validation loss: 1.6727900364065682

Epoch: 258| Step: 0
Training loss: 0.7105610370635986
Validation loss: 1.6725750507846955

Epoch: 6| Step: 1
Training loss: 0.40587303042411804
Validation loss: 1.6476040053111252

Epoch: 6| Step: 2
Training loss: 0.46043580770492554
Validation loss: 1.6363716176761094

Epoch: 6| Step: 3
Training loss: 0.4505244493484497
Validation loss: 1.6340915913222938

Epoch: 6| Step: 4
Training loss: 0.3053227663040161
Validation loss: 1.6440804748124973

Epoch: 6| Step: 5
Training loss: 0.3906632959842682
Validation loss: 1.6312817783765896

Epoch: 6| Step: 6
Training loss: 0.26032888889312744
Validation loss: 1.64951999725834

Epoch: 6| Step: 7
Training loss: 0.25874003767967224
Validation loss: 1.6809627291976765

Epoch: 6| Step: 8
Training loss: 0.32573139667510986
Validation loss: 1.731804226034431

Epoch: 6| Step: 9
Training loss: 0.6046907305717468
Validation loss: 1.7279049927188503

Epoch: 6| Step: 10
Training loss: 0.3187786340713501
Validation loss: 1.6705004002458306

Epoch: 6| Step: 11
Training loss: 0.21925923228263855
Validation loss: 1.7219675317887337

Epoch: 6| Step: 12
Training loss: 0.44526031613349915
Validation loss: 1.6870018615517566

Epoch: 6| Step: 13
Training loss: 0.5307151079177856
Validation loss: 1.6950666340448524

Epoch: 259| Step: 0
Training loss: 0.37535396218299866
Validation loss: 1.6866582260336926

Epoch: 6| Step: 1
Training loss: 0.2536189556121826
Validation loss: 1.6695930239974812

Epoch: 6| Step: 2
Training loss: 0.42391759157180786
Validation loss: 1.6649132595267346

Epoch: 6| Step: 3
Training loss: 0.41299116611480713
Validation loss: 1.6191578244650235

Epoch: 6| Step: 4
Training loss: 0.5786413550376892
Validation loss: 1.6480594552973264

Epoch: 6| Step: 5
Training loss: 0.3668695092201233
Validation loss: 1.6280945616383706

Epoch: 6| Step: 6
Training loss: 0.29092878103256226
Validation loss: 1.6257428071832145

Epoch: 6| Step: 7
Training loss: 0.8303639888763428
Validation loss: 1.6202616076315604

Epoch: 6| Step: 8
Training loss: 0.3883853554725647
Validation loss: 1.6256770395463513

Epoch: 6| Step: 9
Training loss: 0.2580668330192566
Validation loss: 1.6468323148706907

Epoch: 6| Step: 10
Training loss: 0.5759437084197998
Validation loss: 1.6752448107606621

Epoch: 6| Step: 11
Training loss: 0.3191014230251312
Validation loss: 1.7268892885536276

Epoch: 6| Step: 12
Training loss: 0.259660005569458
Validation loss: 1.740215688623408

Epoch: 6| Step: 13
Training loss: 0.271891713142395
Validation loss: 1.784888175226027

Epoch: 260| Step: 0
Training loss: 0.34674376249313354
Validation loss: 1.7383506580065655

Epoch: 6| Step: 1
Training loss: 0.13149307668209076
Validation loss: 1.6872459175766155

Epoch: 6| Step: 2
Training loss: 0.2871752977371216
Validation loss: 1.6898233236805085

Epoch: 6| Step: 3
Training loss: 0.24131248891353607
Validation loss: 1.6983057311786118

Epoch: 6| Step: 4
Training loss: 0.4119710922241211
Validation loss: 1.709726361818211

Epoch: 6| Step: 5
Training loss: 0.43807485699653625
Validation loss: 1.6869716311013827

Epoch: 6| Step: 6
Training loss: 0.6507575511932373
Validation loss: 1.7085676449601368

Epoch: 6| Step: 7
Training loss: 0.5657958388328552
Validation loss: 1.7095327377319336

Epoch: 6| Step: 8
Training loss: 0.506237268447876
Validation loss: 1.7176971409910469

Epoch: 6| Step: 9
Training loss: 0.25338929891586304
Validation loss: 1.7155878992490872

Epoch: 6| Step: 10
Training loss: 0.30010947585105896
Validation loss: 1.7335563859631937

Epoch: 6| Step: 11
Training loss: 0.7427785396575928
Validation loss: 1.6990212061071908

Epoch: 6| Step: 12
Training loss: 0.5145132541656494
Validation loss: 1.7300599992916148

Epoch: 6| Step: 13
Training loss: 0.38258349895477295
Validation loss: 1.7210454825432069

Epoch: 261| Step: 0
Training loss: 0.5140329599380493
Validation loss: 1.6951187784953783

Epoch: 6| Step: 1
Training loss: 0.17164848744869232
Validation loss: 1.645761666759368

Epoch: 6| Step: 2
Training loss: 0.3683665692806244
Validation loss: 1.6289392389276975

Epoch: 6| Step: 3
Training loss: 0.4617479741573334
Validation loss: 1.6060169319952688

Epoch: 6| Step: 4
Training loss: 0.2956865131855011
Validation loss: 1.6231663585990987

Epoch: 6| Step: 5
Training loss: 0.4599824845790863
Validation loss: 1.5971750777254823

Epoch: 6| Step: 6
Training loss: 0.224632129073143
Validation loss: 1.568395536432984

Epoch: 6| Step: 7
Training loss: 0.262755811214447
Validation loss: 1.5837667475464523

Epoch: 6| Step: 8
Training loss: 0.37786275148391724
Validation loss: 1.5835074519598356

Epoch: 6| Step: 9
Training loss: 0.38097336888313293
Validation loss: 1.6099115661395493

Epoch: 6| Step: 10
Training loss: 0.3826715350151062
Validation loss: 1.6092244053399691

Epoch: 6| Step: 11
Training loss: 0.2869062125682831
Validation loss: 1.6245060402859923

Epoch: 6| Step: 12
Training loss: 0.4562970995903015
Validation loss: 1.5994964953391784

Epoch: 6| Step: 13
Training loss: 0.5193805694580078
Validation loss: 1.5966729169250817

Epoch: 262| Step: 0
Training loss: 0.2816038131713867
Validation loss: 1.6367960565833635

Epoch: 6| Step: 1
Training loss: 0.3181098401546478
Validation loss: 1.6022260342874834

Epoch: 6| Step: 2
Training loss: 0.3447687327861786
Validation loss: 1.6239990303593297

Epoch: 6| Step: 3
Training loss: 0.42638805508613586
Validation loss: 1.646518781620969

Epoch: 6| Step: 4
Training loss: 0.2968265414237976
Validation loss: 1.6010161330623012

Epoch: 6| Step: 5
Training loss: 0.40924304723739624
Validation loss: 1.6308706114369054

Epoch: 6| Step: 6
Training loss: 0.3856784701347351
Validation loss: 1.648181866574031

Epoch: 6| Step: 7
Training loss: 0.4202269911766052
Validation loss: 1.6452204437666043

Epoch: 6| Step: 8
Training loss: 0.367228627204895
Validation loss: 1.6624545410115232

Epoch: 6| Step: 9
Training loss: 0.8295308351516724
Validation loss: 1.649755234359413

Epoch: 6| Step: 10
Training loss: 0.26280564069747925
Validation loss: 1.670703177810997

Epoch: 6| Step: 11
Training loss: 0.3435114026069641
Validation loss: 1.6791421482639928

Epoch: 6| Step: 12
Training loss: 0.23056136071681976
Validation loss: 1.6414919002081758

Epoch: 6| Step: 13
Training loss: 0.43052947521209717
Validation loss: 1.6231075051010295

Epoch: 263| Step: 0
Training loss: 0.343669056892395
Validation loss: 1.566830095424447

Epoch: 6| Step: 1
Training loss: 0.6420514583587646
Validation loss: 1.5621818880881033

Epoch: 6| Step: 2
Training loss: 0.34069740772247314
Validation loss: 1.5619077861949962

Epoch: 6| Step: 3
Training loss: 0.36116331815719604
Validation loss: 1.5718887749538626

Epoch: 6| Step: 4
Training loss: 0.5668410062789917
Validation loss: 1.5639390541661171

Epoch: 6| Step: 5
Training loss: 0.2250598967075348
Validation loss: 1.5965621740587297

Epoch: 6| Step: 6
Training loss: 0.43976691365242004
Validation loss: 1.6434064193438458

Epoch: 6| Step: 7
Training loss: 0.28981131315231323
Validation loss: 1.639837461133157

Epoch: 6| Step: 8
Training loss: 0.7515802383422852
Validation loss: 1.7070500312312957

Epoch: 6| Step: 9
Training loss: 0.2726995646953583
Validation loss: 1.729838708395599

Epoch: 6| Step: 10
Training loss: 0.22873714566230774
Validation loss: 1.769680864067488

Epoch: 6| Step: 11
Training loss: 0.4847383201122284
Validation loss: 1.7533618480928483

Epoch: 6| Step: 12
Training loss: 0.4229070246219635
Validation loss: 1.7092572040455316

Epoch: 6| Step: 13
Training loss: 0.3204312324523926
Validation loss: 1.6862950683921896

Epoch: 264| Step: 0
Training loss: 0.29666125774383545
Validation loss: 1.6695494331339353

Epoch: 6| Step: 1
Training loss: 0.36846834421157837
Validation loss: 1.6237655070520216

Epoch: 6| Step: 2
Training loss: 0.35389649868011475
Validation loss: 1.564759942793077

Epoch: 6| Step: 3
Training loss: 0.3631373643875122
Validation loss: 1.582342907946597

Epoch: 6| Step: 4
Training loss: 0.3940553665161133
Validation loss: 1.625870882823903

Epoch: 6| Step: 5
Training loss: 0.31370434165000916
Validation loss: 1.610111303226922

Epoch: 6| Step: 6
Training loss: 0.49348658323287964
Validation loss: 1.6163674900608678

Epoch: 6| Step: 7
Training loss: 0.21736767888069153
Validation loss: 1.6158680018558298

Epoch: 6| Step: 8
Training loss: 0.44729775190353394
Validation loss: 1.6530353587160829

Epoch: 6| Step: 9
Training loss: 0.3778638243675232
Validation loss: 1.686579685057363

Epoch: 6| Step: 10
Training loss: 0.32751378417015076
Validation loss: 1.6692107826150873

Epoch: 6| Step: 11
Training loss: 0.40133780241012573
Validation loss: 1.7101676681990265

Epoch: 6| Step: 12
Training loss: 0.641923725605011
Validation loss: 1.707693838304089

Epoch: 6| Step: 13
Training loss: 0.4078790247440338
Validation loss: 1.7727159633431384

Epoch: 265| Step: 0
Training loss: 0.7745790481567383
Validation loss: 1.8059567123331048

Epoch: 6| Step: 1
Training loss: 0.327862948179245
Validation loss: 1.7645960610399964

Epoch: 6| Step: 2
Training loss: 0.3129362165927887
Validation loss: 1.746139298203171

Epoch: 6| Step: 3
Training loss: 0.35478341579437256
Validation loss: 1.7027930239195466

Epoch: 6| Step: 4
Training loss: 0.2695765197277069
Validation loss: 1.6568180899466238

Epoch: 6| Step: 5
Training loss: 0.32359322905540466
Validation loss: 1.635138415521191

Epoch: 6| Step: 6
Training loss: 0.3251456320285797
Validation loss: 1.6292898488301102

Epoch: 6| Step: 7
Training loss: 0.7876851558685303
Validation loss: 1.6243793490112468

Epoch: 6| Step: 8
Training loss: 0.5390710234642029
Validation loss: 1.601919174194336

Epoch: 6| Step: 9
Training loss: 0.4255630671977997
Validation loss: 1.6252595327233756

Epoch: 6| Step: 10
Training loss: 0.4547072649002075
Validation loss: 1.6467965213201379

Epoch: 6| Step: 11
Training loss: 0.727555513381958
Validation loss: 1.5845306432375343

Epoch: 6| Step: 12
Training loss: 0.38649100065231323
Validation loss: 1.5642900748919415

Epoch: 6| Step: 13
Training loss: 0.2705537974834442
Validation loss: 1.601175477427821

Epoch: 266| Step: 0
Training loss: 0.43022453784942627
Validation loss: 1.6547252503774499

Epoch: 6| Step: 1
Training loss: 0.47238674759864807
Validation loss: 1.6883037910666516

Epoch: 6| Step: 2
Training loss: 0.7234214544296265
Validation loss: 1.7163978725351312

Epoch: 6| Step: 3
Training loss: 0.3935575783252716
Validation loss: 1.706592623905469

Epoch: 6| Step: 4
Training loss: 0.27978307008743286
Validation loss: 1.7315521112052343

Epoch: 6| Step: 5
Training loss: 0.3779080808162689
Validation loss: 1.7158775509044688

Epoch: 6| Step: 6
Training loss: 0.5520532131195068
Validation loss: 1.7234740346990607

Epoch: 6| Step: 7
Training loss: 0.6235988140106201
Validation loss: 1.7126351787197975

Epoch: 6| Step: 8
Training loss: 0.3516284227371216
Validation loss: 1.7038061708532355

Epoch: 6| Step: 9
Training loss: 0.7176921367645264
Validation loss: 1.6595708554790867

Epoch: 6| Step: 10
Training loss: 0.225894033908844
Validation loss: 1.6445901175980926

Epoch: 6| Step: 11
Training loss: 0.21252590417861938
Validation loss: 1.6068742711056945

Epoch: 6| Step: 12
Training loss: 0.22227318584918976
Validation loss: 1.5995222278820571

Epoch: 6| Step: 13
Training loss: 0.24791282415390015
Validation loss: 1.6108619372049968

Epoch: 267| Step: 0
Training loss: 0.2569480538368225
Validation loss: 1.6289402054202171

Epoch: 6| Step: 1
Training loss: 0.4307585656642914
Validation loss: 1.6494249566908805

Epoch: 6| Step: 2
Training loss: 0.1289195716381073
Validation loss: 1.6584063922205279

Epoch: 6| Step: 3
Training loss: 0.634789228439331
Validation loss: 1.6335104601357573

Epoch: 6| Step: 4
Training loss: 0.5638399720191956
Validation loss: 1.629382497520857

Epoch: 6| Step: 5
Training loss: 0.5295454263687134
Validation loss: 1.636112710481049

Epoch: 6| Step: 6
Training loss: 0.20077204704284668
Validation loss: 1.636094500941615

Epoch: 6| Step: 7
Training loss: 0.3276170790195465
Validation loss: 1.6536799130901214

Epoch: 6| Step: 8
Training loss: 0.35275593400001526
Validation loss: 1.6741488864344936

Epoch: 6| Step: 9
Training loss: 0.399783194065094
Validation loss: 1.673129209908106

Epoch: 6| Step: 10
Training loss: 0.1721176952123642
Validation loss: 1.6480746538408342

Epoch: 6| Step: 11
Training loss: 0.5315859913825989
Validation loss: 1.6518653208209622

Epoch: 6| Step: 12
Training loss: 0.24281911551952362
Validation loss: 1.647787526089658

Epoch: 6| Step: 13
Training loss: 0.12271633744239807
Validation loss: 1.6324698309744559

Epoch: 268| Step: 0
Training loss: 0.29439568519592285
Validation loss: 1.6310158198879612

Epoch: 6| Step: 1
Training loss: 0.33197030425071716
Validation loss: 1.634494427711733

Epoch: 6| Step: 2
Training loss: 0.33201295137405396
Validation loss: 1.6382075509717386

Epoch: 6| Step: 3
Training loss: 0.30704909563064575
Validation loss: 1.6270403874817716

Epoch: 6| Step: 4
Training loss: 0.4344920217990875
Validation loss: 1.6316858965863463

Epoch: 6| Step: 5
Training loss: 0.2572214603424072
Validation loss: 1.6167364992121214

Epoch: 6| Step: 6
Training loss: 0.5353240966796875
Validation loss: 1.6168818153360838

Epoch: 6| Step: 7
Training loss: 0.1817174255847931
Validation loss: 1.6237410281294136

Epoch: 6| Step: 8
Training loss: 0.30707651376724243
Validation loss: 1.5582653322527487

Epoch: 6| Step: 9
Training loss: 0.513210654258728
Validation loss: 1.5553413732077486

Epoch: 6| Step: 10
Training loss: 0.3638020157814026
Validation loss: 1.5987717669497254

Epoch: 6| Step: 11
Training loss: 0.603971004486084
Validation loss: 1.6168256600697835

Epoch: 6| Step: 12
Training loss: 0.3829919099807739
Validation loss: 1.6394906479825255

Epoch: 6| Step: 13
Training loss: 0.4898575246334076
Validation loss: 1.6177507074930335

Epoch: 269| Step: 0
Training loss: 0.6174134016036987
Validation loss: 1.6164658877157396

Epoch: 6| Step: 1
Training loss: 0.38144394755363464
Validation loss: 1.6213291909105034

Epoch: 6| Step: 2
Training loss: 0.20200246572494507
Validation loss: 1.6209285618156515

Epoch: 6| Step: 3
Training loss: 0.26875191926956177
Validation loss: 1.5875237795614427

Epoch: 6| Step: 4
Training loss: 0.1895289272069931
Validation loss: 1.599632445202079

Epoch: 6| Step: 5
Training loss: 0.4893397092819214
Validation loss: 1.602203312740531

Epoch: 6| Step: 6
Training loss: 0.281027227640152
Validation loss: 1.5984243513435445

Epoch: 6| Step: 7
Training loss: 0.348024845123291
Validation loss: 1.5724922944140691

Epoch: 6| Step: 8
Training loss: 0.38853126764297485
Validation loss: 1.5715075635140943

Epoch: 6| Step: 9
Training loss: 0.33541882038116455
Validation loss: 1.5713248752778577

Epoch: 6| Step: 10
Training loss: 0.6750858426094055
Validation loss: 1.594881457667197

Epoch: 6| Step: 11
Training loss: 0.43308067321777344
Validation loss: 1.6117315728177306

Epoch: 6| Step: 12
Training loss: 0.35256338119506836
Validation loss: 1.6221761639400194

Epoch: 6| Step: 13
Training loss: 0.322025865316391
Validation loss: 1.6822996216435586

Epoch: 270| Step: 0
Training loss: 0.26962608098983765
Validation loss: 1.645546397855205

Epoch: 6| Step: 1
Training loss: 0.33515074849128723
Validation loss: 1.7285400462406937

Epoch: 6| Step: 2
Training loss: 0.43049246072769165
Validation loss: 1.7712023719664542

Epoch: 6| Step: 3
Training loss: 0.42185717821121216
Validation loss: 1.8086352630328106

Epoch: 6| Step: 4
Training loss: 0.2739132046699524
Validation loss: 1.7671312068098335

Epoch: 6| Step: 5
Training loss: 0.5900084376335144
Validation loss: 1.750514413720818

Epoch: 6| Step: 6
Training loss: 0.20457673072814941
Validation loss: 1.702118806941535

Epoch: 6| Step: 7
Training loss: 0.2908838987350464
Validation loss: 1.6708150345792052

Epoch: 6| Step: 8
Training loss: 0.325456440448761
Validation loss: 1.642740039415257

Epoch: 6| Step: 9
Training loss: 0.41312354803085327
Validation loss: 1.6253901220137073

Epoch: 6| Step: 10
Training loss: 0.22930908203125
Validation loss: 1.5889491227365309

Epoch: 6| Step: 11
Training loss: 0.7137057185173035
Validation loss: 1.5867124360094789

Epoch: 6| Step: 12
Training loss: 0.5541940927505493
Validation loss: 1.6286609852185814

Epoch: 6| Step: 13
Training loss: 0.6986979842185974
Validation loss: 1.603491670982812

Epoch: 271| Step: 0
Training loss: 0.5677964687347412
Validation loss: 1.5825397673473562

Epoch: 6| Step: 1
Training loss: 0.476185142993927
Validation loss: 1.5604524766245196

Epoch: 6| Step: 2
Training loss: 0.19152739644050598
Validation loss: 1.5971432757633988

Epoch: 6| Step: 3
Training loss: 0.35816699266433716
Validation loss: 1.6685921812570224

Epoch: 6| Step: 4
Training loss: 0.39449799060821533
Validation loss: 1.6997552328212286

Epoch: 6| Step: 5
Training loss: 0.2507903575897217
Validation loss: 1.717391901118781

Epoch: 6| Step: 6
Training loss: 0.3513046205043793
Validation loss: 1.7392588212925901

Epoch: 6| Step: 7
Training loss: 0.41529831290245056
Validation loss: 1.7047317566410187

Epoch: 6| Step: 8
Training loss: 0.42295974493026733
Validation loss: 1.7207770860323341

Epoch: 6| Step: 9
Training loss: 0.5169788599014282
Validation loss: 1.67427784140392

Epoch: 6| Step: 10
Training loss: 0.3087243437767029
Validation loss: 1.6561319776760635

Epoch: 6| Step: 11
Training loss: 0.37210890650749207
Validation loss: 1.63221271704602

Epoch: 6| Step: 12
Training loss: 0.5618227124214172
Validation loss: 1.591941002876528

Epoch: 6| Step: 13
Training loss: 0.22774529457092285
Validation loss: 1.6100761505865282

Epoch: 272| Step: 0
Training loss: 0.3244125545024872
Validation loss: 1.6102525316258913

Epoch: 6| Step: 1
Training loss: 0.3493829071521759
Validation loss: 1.5860368769655946

Epoch: 6| Step: 2
Training loss: 0.5772254467010498
Validation loss: 1.6196588957181541

Epoch: 6| Step: 3
Training loss: 0.42119112610816956
Validation loss: 1.617248850484048

Epoch: 6| Step: 4
Training loss: 0.47601318359375
Validation loss: 1.603081851877192

Epoch: 6| Step: 5
Training loss: 0.1911744475364685
Validation loss: 1.6244253061150993

Epoch: 6| Step: 6
Training loss: 0.2622811198234558
Validation loss: 1.609932791802191

Epoch: 6| Step: 7
Training loss: 0.33817195892333984
Validation loss: 1.6635944984292472

Epoch: 6| Step: 8
Training loss: 0.39324796199798584
Validation loss: 1.6747123592643327

Epoch: 6| Step: 9
Training loss: 0.2906249761581421
Validation loss: 1.6673768835683023

Epoch: 6| Step: 10
Training loss: 0.3955870270729065
Validation loss: 1.6556571696394233

Epoch: 6| Step: 11
Training loss: 0.42651182413101196
Validation loss: 1.626404207880779

Epoch: 6| Step: 12
Training loss: 0.21604546904563904
Validation loss: 1.5974766182643112

Epoch: 6| Step: 13
Training loss: 0.39346423745155334
Validation loss: 1.5823996297774776

Epoch: 273| Step: 0
Training loss: 0.37737756967544556
Validation loss: 1.583258536554152

Epoch: 6| Step: 1
Training loss: 0.3603713810443878
Validation loss: 1.5634705699900144

Epoch: 6| Step: 2
Training loss: 0.4762144684791565
Validation loss: 1.6010564552840365

Epoch: 6| Step: 3
Training loss: 0.2788506746292114
Validation loss: 1.5876773929083219

Epoch: 6| Step: 4
Training loss: 0.47551363706588745
Validation loss: 1.6015197730833484

Epoch: 6| Step: 5
Training loss: 0.5304856300354004
Validation loss: 1.6065814725814327

Epoch: 6| Step: 6
Training loss: 0.3736947178840637
Validation loss: 1.5646359574410222

Epoch: 6| Step: 7
Training loss: 0.2778928875923157
Validation loss: 1.591497835292611

Epoch: 6| Step: 8
Training loss: 0.4791882336139679
Validation loss: 1.5759991420212613

Epoch: 6| Step: 9
Training loss: 0.31921806931495667
Validation loss: 1.6168618625210178

Epoch: 6| Step: 10
Training loss: 0.24367520213127136
Validation loss: 1.6206379776359887

Epoch: 6| Step: 11
Training loss: 0.23713675141334534
Validation loss: 1.63231449614289

Epoch: 6| Step: 12
Training loss: 0.2063245326280594
Validation loss: 1.6079470496023855

Epoch: 6| Step: 13
Training loss: 0.2619785666465759
Validation loss: 1.6232320448403716

Epoch: 274| Step: 0
Training loss: 0.4135681390762329
Validation loss: 1.6017969154542493

Epoch: 6| Step: 1
Training loss: 0.33538198471069336
Validation loss: 1.599716717197049

Epoch: 6| Step: 2
Training loss: 0.42532259225845337
Validation loss: 1.6040647952787337

Epoch: 6| Step: 3
Training loss: 0.2400784194469452
Validation loss: 1.5858788644113848

Epoch: 6| Step: 4
Training loss: 0.21786090731620789
Validation loss: 1.561611254369059

Epoch: 6| Step: 5
Training loss: 0.6177443265914917
Validation loss: 1.5502577186912618

Epoch: 6| Step: 6
Training loss: 0.17406846582889557
Validation loss: 1.5906216341962096

Epoch: 6| Step: 7
Training loss: 0.35675227642059326
Validation loss: 1.5956345450493596

Epoch: 6| Step: 8
Training loss: 0.3847290277481079
Validation loss: 1.6643046050943353

Epoch: 6| Step: 9
Training loss: 0.3253556489944458
Validation loss: 1.6845760063458515

Epoch: 6| Step: 10
Training loss: 0.5266160368919373
Validation loss: 1.7302249298300794

Epoch: 6| Step: 11
Training loss: 0.2791667580604553
Validation loss: 1.7459271223314348

Epoch: 6| Step: 12
Training loss: 0.4426208734512329
Validation loss: 1.7916613368577854

Epoch: 6| Step: 13
Training loss: 0.14023269712924957
Validation loss: 1.748056714252759

Epoch: 275| Step: 0
Training loss: 0.2837812006473541
Validation loss: 1.7176287610043761

Epoch: 6| Step: 1
Training loss: 0.2757703363895416
Validation loss: 1.6733038271627119

Epoch: 6| Step: 2
Training loss: 0.4633835554122925
Validation loss: 1.6521626146890784

Epoch: 6| Step: 3
Training loss: 0.30741286277770996
Validation loss: 1.6339860885374007

Epoch: 6| Step: 4
Training loss: 0.18840518593788147
Validation loss: 1.6035157288274458

Epoch: 6| Step: 5
Training loss: 0.2398291826248169
Validation loss: 1.6133563710797219

Epoch: 6| Step: 6
Training loss: 0.24554678797721863
Validation loss: 1.6297665398607972

Epoch: 6| Step: 7
Training loss: 0.47546565532684326
Validation loss: 1.6230294012254285

Epoch: 6| Step: 8
Training loss: 0.33679139614105225
Validation loss: 1.6234291202278548

Epoch: 6| Step: 9
Training loss: 0.39510154724121094
Validation loss: 1.6128347996742494

Epoch: 6| Step: 10
Training loss: 0.2955743074417114
Validation loss: 1.6877535094497025

Epoch: 6| Step: 11
Training loss: 0.2429092824459076
Validation loss: 1.7259162587504233

Epoch: 6| Step: 12
Training loss: 0.40476834774017334
Validation loss: 1.7232931595976635

Epoch: 6| Step: 13
Training loss: 0.3684943914413452
Validation loss: 1.7439003670087425

Epoch: 276| Step: 0
Training loss: 0.4304550588130951
Validation loss: 1.7284046129513813

Epoch: 6| Step: 1
Training loss: 0.463220477104187
Validation loss: 1.7058027719938627

Epoch: 6| Step: 2
Training loss: 0.27741825580596924
Validation loss: 1.7041309918126752

Epoch: 6| Step: 3
Training loss: 0.25172680616378784
Validation loss: 1.680748720322886

Epoch: 6| Step: 4
Training loss: 0.3266837000846863
Validation loss: 1.6210090293679187

Epoch: 6| Step: 5
Training loss: 0.3160220980644226
Validation loss: 1.633153929505297

Epoch: 6| Step: 6
Training loss: 0.35238122940063477
Validation loss: 1.597118841704502

Epoch: 6| Step: 7
Training loss: 0.4398922026157379
Validation loss: 1.5672767982688

Epoch: 6| Step: 8
Training loss: 0.2598889172077179
Validation loss: 1.609079675007892

Epoch: 6| Step: 9
Training loss: 0.09895359724760056
Validation loss: 1.5983934223010976

Epoch: 6| Step: 10
Training loss: 0.2331782430410385
Validation loss: 1.5854150890022196

Epoch: 6| Step: 11
Training loss: 0.11200550943613052
Validation loss: 1.6125255284770843

Epoch: 6| Step: 12
Training loss: 0.34083718061447144
Validation loss: 1.5967501171173588

Epoch: 6| Step: 13
Training loss: 0.4506361782550812
Validation loss: 1.6238358994965911

Epoch: 277| Step: 0
Training loss: 0.10321445763111115
Validation loss: 1.6412572104443786

Epoch: 6| Step: 1
Training loss: 0.39026573300361633
Validation loss: 1.631583680388748

Epoch: 6| Step: 2
Training loss: 0.25306928157806396
Validation loss: 1.6504741714846702

Epoch: 6| Step: 3
Training loss: 0.228483647108078
Validation loss: 1.638445246604181

Epoch: 6| Step: 4
Training loss: 0.3406270742416382
Validation loss: 1.6463248883524249

Epoch: 6| Step: 5
Training loss: 0.3586650490760803
Validation loss: 1.6361046888495003

Epoch: 6| Step: 6
Training loss: 0.49079787731170654
Validation loss: 1.6199694974448091

Epoch: 6| Step: 7
Training loss: 0.19665612280368805
Validation loss: 1.5907636432237522

Epoch: 6| Step: 8
Training loss: 0.39606064558029175
Validation loss: 1.580228768369203

Epoch: 6| Step: 9
Training loss: 0.3718314468860626
Validation loss: 1.5595474858437814

Epoch: 6| Step: 10
Training loss: 0.2763550579547882
Validation loss: 1.5659396609952372

Epoch: 6| Step: 11
Training loss: 0.4002038538455963
Validation loss: 1.5833338954115426

Epoch: 6| Step: 12
Training loss: 0.30354124307632446
Validation loss: 1.6015667171888455

Epoch: 6| Step: 13
Training loss: 0.29445141553878784
Validation loss: 1.5811222432762064

Epoch: 278| Step: 0
Training loss: 0.20525769889354706
Validation loss: 1.5918923731773131

Epoch: 6| Step: 1
Training loss: 0.35294413566589355
Validation loss: 1.6234528480037567

Epoch: 6| Step: 2
Training loss: 0.24192896485328674
Validation loss: 1.623888422084111

Epoch: 6| Step: 3
Training loss: 0.24803949892520905
Validation loss: 1.621114759035008

Epoch: 6| Step: 4
Training loss: 0.2215244472026825
Validation loss: 1.6668238242467244

Epoch: 6| Step: 5
Training loss: 0.4743911623954773
Validation loss: 1.6675963658158497

Epoch: 6| Step: 6
Training loss: 0.34826675057411194
Validation loss: 1.6364067703165033

Epoch: 6| Step: 7
Training loss: 0.2417122721672058
Validation loss: 1.6392982070164015

Epoch: 6| Step: 8
Training loss: 0.268282949924469
Validation loss: 1.6541086294317757

Epoch: 6| Step: 9
Training loss: 0.27942368388175964
Validation loss: 1.623974407872846

Epoch: 6| Step: 10
Training loss: 0.15108180046081543
Validation loss: 1.5867619219646658

Epoch: 6| Step: 11
Training loss: 0.6967027187347412
Validation loss: 1.5989642937978108

Epoch: 6| Step: 12
Training loss: 0.24102143943309784
Validation loss: 1.582886354897612

Epoch: 6| Step: 13
Training loss: 0.3664771318435669
Validation loss: 1.574997627606956

Epoch: 279| Step: 0
Training loss: 0.25766369700431824
Validation loss: 1.6059680984866234

Epoch: 6| Step: 1
Training loss: 0.3663649559020996
Validation loss: 1.5955172174720353

Epoch: 6| Step: 2
Training loss: 0.22726662456989288
Validation loss: 1.5887168107494232

Epoch: 6| Step: 3
Training loss: 0.25623905658721924
Validation loss: 1.633712384008592

Epoch: 6| Step: 4
Training loss: 0.3937884271144867
Validation loss: 1.6557631313159902

Epoch: 6| Step: 5
Training loss: 0.19917653501033783
Validation loss: 1.6184445196582424

Epoch: 6| Step: 6
Training loss: 0.2879394590854645
Validation loss: 1.6634827518975863

Epoch: 6| Step: 7
Training loss: 0.1706010401248932
Validation loss: 1.6529771563827351

Epoch: 6| Step: 8
Training loss: 0.30085280537605286
Validation loss: 1.6957176590478549

Epoch: 6| Step: 9
Training loss: 0.40985244512557983
Validation loss: 1.700888733710012

Epoch: 6| Step: 10
Training loss: 0.2432699203491211
Validation loss: 1.6664347417892948

Epoch: 6| Step: 11
Training loss: 0.404962956905365
Validation loss: 1.683835555148381

Epoch: 6| Step: 12
Training loss: 0.4344102144241333
Validation loss: 1.6887537651164557

Epoch: 6| Step: 13
Training loss: 0.40292444825172424
Validation loss: 1.6331316078862836

Epoch: 280| Step: 0
Training loss: 0.27324172854423523
Validation loss: 1.6322131797831545

Epoch: 6| Step: 1
Training loss: 0.5943528413772583
Validation loss: 1.6766371521898495

Epoch: 6| Step: 2
Training loss: 0.27147018909454346
Validation loss: 1.6589684896571661

Epoch: 6| Step: 3
Training loss: 0.1665242314338684
Validation loss: 1.637812849014036

Epoch: 6| Step: 4
Training loss: 0.321854829788208
Validation loss: 1.6251004524128412

Epoch: 6| Step: 5
Training loss: 0.24754604697227478
Validation loss: 1.6256014236839869

Epoch: 6| Step: 6
Training loss: 0.33561766147613525
Validation loss: 1.606232339336026

Epoch: 6| Step: 7
Training loss: 0.4200284779071808
Validation loss: 1.5782066340087562

Epoch: 6| Step: 8
Training loss: 0.3251252770423889
Validation loss: 1.5478654728140882

Epoch: 6| Step: 9
Training loss: 0.32014337182044983
Validation loss: 1.5390382607777913

Epoch: 6| Step: 10
Training loss: 0.21700555086135864
Validation loss: 1.5271032984538744

Epoch: 6| Step: 11
Training loss: 0.45715564489364624
Validation loss: 1.535518818004157

Epoch: 6| Step: 12
Training loss: 0.3515293598175049
Validation loss: 1.5130498460544053

Epoch: 6| Step: 13
Training loss: 0.4026881456375122
Validation loss: 1.533034965556155

Epoch: 281| Step: 0
Training loss: 0.3219642639160156
Validation loss: 1.524788063059571

Epoch: 6| Step: 1
Training loss: 0.3677738606929779
Validation loss: 1.5815525747114612

Epoch: 6| Step: 2
Training loss: 0.20066691935062408
Validation loss: 1.5759743054707844

Epoch: 6| Step: 3
Training loss: 0.32482045888900757
Validation loss: 1.5792664174110658

Epoch: 6| Step: 4
Training loss: 0.16624534130096436
Validation loss: 1.664909097456163

Epoch: 6| Step: 5
Training loss: 0.41406282782554626
Validation loss: 1.6871195403478478

Epoch: 6| Step: 6
Training loss: 0.3021972179412842
Validation loss: 1.6951868469997118

Epoch: 6| Step: 7
Training loss: 0.4287470579147339
Validation loss: 1.6648820433565366

Epoch: 6| Step: 8
Training loss: 0.16647043824195862
Validation loss: 1.6114811512731737

Epoch: 6| Step: 9
Training loss: 0.23680107295513153
Validation loss: 1.5999315887369134

Epoch: 6| Step: 10
Training loss: 0.4646185338497162
Validation loss: 1.597763402487642

Epoch: 6| Step: 11
Training loss: 0.1910446584224701
Validation loss: 1.5788415414030834

Epoch: 6| Step: 12
Training loss: 0.42107316851615906
Validation loss: 1.6188546726780553

Epoch: 6| Step: 13
Training loss: 0.2521151006221771
Validation loss: 1.6106601658687796

Epoch: 282| Step: 0
Training loss: 0.21786996722221375
Validation loss: 1.6352463076191563

Epoch: 6| Step: 1
Training loss: 0.1866399049758911
Validation loss: 1.6400611349331435

Epoch: 6| Step: 2
Training loss: 0.25391459465026855
Validation loss: 1.6743836274711035

Epoch: 6| Step: 3
Training loss: 0.33651041984558105
Validation loss: 1.6794327805119176

Epoch: 6| Step: 4
Training loss: 0.311146080493927
Validation loss: 1.7062616053447928

Epoch: 6| Step: 5
Training loss: 0.29704320430755615
Validation loss: 1.7334133963431082

Epoch: 6| Step: 6
Training loss: 0.5626448392868042
Validation loss: 1.7349723282680716

Epoch: 6| Step: 7
Training loss: 0.2965158224105835
Validation loss: 1.7320585135490663

Epoch: 6| Step: 8
Training loss: 0.2513979971408844
Validation loss: 1.7205374766421575

Epoch: 6| Step: 9
Training loss: 0.3306127190589905
Validation loss: 1.721434808546497

Epoch: 6| Step: 10
Training loss: 0.4622127413749695
Validation loss: 1.667608049608046

Epoch: 6| Step: 11
Training loss: 0.305388867855072
Validation loss: 1.6335646490896902

Epoch: 6| Step: 12
Training loss: 0.3466871976852417
Validation loss: 1.639585530886086

Epoch: 6| Step: 13
Training loss: 0.16517788171768188
Validation loss: 1.6423153031256892

Epoch: 283| Step: 0
Training loss: 0.2760840654373169
Validation loss: 1.63730542121395

Epoch: 6| Step: 1
Training loss: 0.283354252576828
Validation loss: 1.6616362564025386

Epoch: 6| Step: 2
Training loss: 0.2720044255256653
Validation loss: 1.6536338072951122

Epoch: 6| Step: 3
Training loss: 0.35664331912994385
Validation loss: 1.6618996768869378

Epoch: 6| Step: 4
Training loss: 0.2877500653266907
Validation loss: 1.6445705839382705

Epoch: 6| Step: 5
Training loss: 0.3828420042991638
Validation loss: 1.6414331281056969

Epoch: 6| Step: 6
Training loss: 0.45908087491989136
Validation loss: 1.6487418297798402

Epoch: 6| Step: 7
Training loss: 0.23551411926746368
Validation loss: 1.6605447517928256

Epoch: 6| Step: 8
Training loss: 0.32741278409957886
Validation loss: 1.6791810925288866

Epoch: 6| Step: 9
Training loss: 0.3545464277267456
Validation loss: 1.655378307065656

Epoch: 6| Step: 10
Training loss: 0.2600192725658417
Validation loss: 1.7137696179010535

Epoch: 6| Step: 11
Training loss: 0.19879473745822906
Validation loss: 1.6995594322040517

Epoch: 6| Step: 12
Training loss: 0.5905624032020569
Validation loss: 1.7398707687213857

Epoch: 6| Step: 13
Training loss: 0.46048682928085327
Validation loss: 1.7502818017877557

Epoch: 284| Step: 0
Training loss: 0.4669296443462372
Validation loss: 1.725898378638811

Epoch: 6| Step: 1
Training loss: 0.44835829734802246
Validation loss: 1.7122504877787765

Epoch: 6| Step: 2
Training loss: 0.1858888864517212
Validation loss: 1.7051288133026452

Epoch: 6| Step: 3
Training loss: 0.3701765537261963
Validation loss: 1.6682220428220687

Epoch: 6| Step: 4
Training loss: 0.4548482298851013
Validation loss: 1.6391108548769386

Epoch: 6| Step: 5
Training loss: 0.33115553855895996
Validation loss: 1.649267937547417

Epoch: 6| Step: 6
Training loss: 0.35818958282470703
Validation loss: 1.6416602762796546

Epoch: 6| Step: 7
Training loss: 0.2852482199668884
Validation loss: 1.6491007292142479

Epoch: 6| Step: 8
Training loss: 0.3230454921722412
Validation loss: 1.6497170335503035

Epoch: 6| Step: 9
Training loss: 0.24242271482944489
Validation loss: 1.5979944454726351

Epoch: 6| Step: 10
Training loss: 0.31236088275909424
Validation loss: 1.6112278110237532

Epoch: 6| Step: 11
Training loss: 0.25713425874710083
Validation loss: 1.5935239202232772

Epoch: 6| Step: 12
Training loss: 0.3813396990299225
Validation loss: 1.5806376741778465

Epoch: 6| Step: 13
Training loss: 0.308768093585968
Validation loss: 1.5938676480324037

Epoch: 285| Step: 0
Training loss: 0.13809522986412048
Validation loss: 1.5187117335616902

Epoch: 6| Step: 1
Training loss: 0.21022221446037292
Validation loss: 1.5299189026637743

Epoch: 6| Step: 2
Training loss: 0.5467973351478577
Validation loss: 1.5811291638241018

Epoch: 6| Step: 3
Training loss: 0.2340334951877594
Validation loss: 1.5974034186332458

Epoch: 6| Step: 4
Training loss: 0.16510827839374542
Validation loss: 1.619123463989586

Epoch: 6| Step: 5
Training loss: 0.30047357082366943
Validation loss: 1.6272304115756866

Epoch: 6| Step: 6
Training loss: 0.3898213505744934
Validation loss: 1.6108873416018743

Epoch: 6| Step: 7
Training loss: 0.3599586486816406
Validation loss: 1.6182188962095527

Epoch: 6| Step: 8
Training loss: 0.2590830624103546
Validation loss: 1.5980988100010862

Epoch: 6| Step: 9
Training loss: 0.4378967881202698
Validation loss: 1.5740198178957867

Epoch: 6| Step: 10
Training loss: 0.2513509690761566
Validation loss: 1.588819852439306

Epoch: 6| Step: 11
Training loss: 0.2596469521522522
Validation loss: 1.5597026514750656

Epoch: 6| Step: 12
Training loss: 0.3890576958656311
Validation loss: 1.559306868942835

Epoch: 6| Step: 13
Training loss: 0.4236391484737396
Validation loss: 1.6126676323593303

Epoch: 286| Step: 0
Training loss: 0.3248850703239441
Validation loss: 1.591893837016116

Epoch: 6| Step: 1
Training loss: 0.12129099667072296
Validation loss: 1.5716309547424316

Epoch: 6| Step: 2
Training loss: 0.26458975672721863
Validation loss: 1.6301581103314635

Epoch: 6| Step: 3
Training loss: 0.2766975164413452
Validation loss: 1.6433911015910487

Epoch: 6| Step: 4
Training loss: 0.3559860587120056
Validation loss: 1.656835728435106

Epoch: 6| Step: 5
Training loss: 0.29542604088783264
Validation loss: 1.6447452781020955

Epoch: 6| Step: 6
Training loss: 0.1989934742450714
Validation loss: 1.6297805078567997

Epoch: 6| Step: 7
Training loss: 0.5092242956161499
Validation loss: 1.6527936612406084

Epoch: 6| Step: 8
Training loss: 0.30445852875709534
Validation loss: 1.620777235236219

Epoch: 6| Step: 9
Training loss: 0.1672014594078064
Validation loss: 1.6299810166000037

Epoch: 6| Step: 10
Training loss: 0.24337369203567505
Validation loss: 1.5947115139294696

Epoch: 6| Step: 11
Training loss: 0.3070034980773926
Validation loss: 1.587676917352984

Epoch: 6| Step: 12
Training loss: 0.24189995229244232
Validation loss: 1.5931557788643786

Epoch: 6| Step: 13
Training loss: 0.3393005132675171
Validation loss: 1.6166676955838357

Epoch: 287| Step: 0
Training loss: 0.0981680229306221
Validation loss: 1.6213283102999452

Epoch: 6| Step: 1
Training loss: 0.19943390786647797
Validation loss: 1.6195068949012346

Epoch: 6| Step: 2
Training loss: 0.2768678069114685
Validation loss: 1.6589964999947497

Epoch: 6| Step: 3
Training loss: 0.25704628229141235
Validation loss: 1.6290512149051954

Epoch: 6| Step: 4
Training loss: 0.156480610370636
Validation loss: 1.6486833685187883

Epoch: 6| Step: 5
Training loss: 0.2705194354057312
Validation loss: 1.627506362494602

Epoch: 6| Step: 6
Training loss: 0.5179226398468018
Validation loss: 1.6594729961887482

Epoch: 6| Step: 7
Training loss: 0.2869018614292145
Validation loss: 1.6277188267759097

Epoch: 6| Step: 8
Training loss: 0.3650904893875122
Validation loss: 1.6245630505264446

Epoch: 6| Step: 9
Training loss: 0.2771947681903839
Validation loss: 1.651380063385092

Epoch: 6| Step: 10
Training loss: 0.2015065997838974
Validation loss: 1.6602681964956305

Epoch: 6| Step: 11
Training loss: 0.2577331066131592
Validation loss: 1.676152798437303

Epoch: 6| Step: 12
Training loss: 0.2622148096561432
Validation loss: 1.6402342319488525

Epoch: 6| Step: 13
Training loss: 0.3365236818790436
Validation loss: 1.6648370091633131

Epoch: 288| Step: 0
Training loss: 0.3676339089870453
Validation loss: 1.6355256342118787

Epoch: 6| Step: 1
Training loss: 0.21441087126731873
Validation loss: 1.6437023275641984

Epoch: 6| Step: 2
Training loss: 0.2444075345993042
Validation loss: 1.6247708887182257

Epoch: 6| Step: 3
Training loss: 0.25006812810897827
Validation loss: 1.591325815005969

Epoch: 6| Step: 4
Training loss: 0.4327145218849182
Validation loss: 1.5616996954846125

Epoch: 6| Step: 5
Training loss: 0.34822189807891846
Validation loss: 1.5831702101615168

Epoch: 6| Step: 6
Training loss: 0.35738199949264526
Validation loss: 1.582656434787217

Epoch: 6| Step: 7
Training loss: 0.24070772528648376
Validation loss: 1.5253589153289795

Epoch: 6| Step: 8
Training loss: 0.34533360600471497
Validation loss: 1.557558790329964

Epoch: 6| Step: 9
Training loss: 0.23721694946289062
Validation loss: 1.5717723831053703

Epoch: 6| Step: 10
Training loss: 0.26502689719200134
Validation loss: 1.5916189173216462

Epoch: 6| Step: 11
Training loss: 0.3312094509601593
Validation loss: 1.6469184480687624

Epoch: 6| Step: 12
Training loss: 0.30135905742645264
Validation loss: 1.6300839313896753

Epoch: 6| Step: 13
Training loss: 0.25105637311935425
Validation loss: 1.6446958088105725

Epoch: 289| Step: 0
Training loss: 0.3052770495414734
Validation loss: 1.626590903087329

Epoch: 6| Step: 1
Training loss: 0.5439218282699585
Validation loss: 1.648596473919448

Epoch: 6| Step: 2
Training loss: 0.1536136269569397
Validation loss: 1.5972191390170847

Epoch: 6| Step: 3
Training loss: 0.20217159390449524
Validation loss: 1.5842153308212117

Epoch: 6| Step: 4
Training loss: 0.42233893275260925
Validation loss: 1.597510427557012

Epoch: 6| Step: 5
Training loss: 0.23716460168361664
Validation loss: 1.594362696011861

Epoch: 6| Step: 6
Training loss: 0.1900264322757721
Validation loss: 1.5695672355672365

Epoch: 6| Step: 7
Training loss: 0.3480623960494995
Validation loss: 1.572988748550415

Epoch: 6| Step: 8
Training loss: 0.36963868141174316
Validation loss: 1.5767550058262323

Epoch: 6| Step: 9
Training loss: 0.20886516571044922
Validation loss: 1.622925482770448

Epoch: 6| Step: 10
Training loss: 0.20325224101543427
Validation loss: 1.6594725206334104

Epoch: 6| Step: 11
Training loss: 0.3359188735485077
Validation loss: 1.6834306973283009

Epoch: 6| Step: 12
Training loss: 0.25986528396606445
Validation loss: 1.6636995269406227

Epoch: 6| Step: 13
Training loss: 0.33801302313804626
Validation loss: 1.6774258344404158

Epoch: 290| Step: 0
Training loss: 0.3216567635536194
Validation loss: 1.6446853094203497

Epoch: 6| Step: 1
Training loss: 0.15366055071353912
Validation loss: 1.6239584825372184

Epoch: 6| Step: 2
Training loss: 0.21466881036758423
Validation loss: 1.604210949713184

Epoch: 6| Step: 3
Training loss: 0.3039094805717468
Validation loss: 1.601368942568379

Epoch: 6| Step: 4
Training loss: 0.30540931224823
Validation loss: 1.576791392218682

Epoch: 6| Step: 5
Training loss: 0.5417633056640625
Validation loss: 1.5841530048719017

Epoch: 6| Step: 6
Training loss: 0.34511250257492065
Validation loss: 1.587238061812616

Epoch: 6| Step: 7
Training loss: 0.21920377016067505
Validation loss: 1.574561680516889

Epoch: 6| Step: 8
Training loss: 0.13462209701538086
Validation loss: 1.5653788120515886

Epoch: 6| Step: 9
Training loss: 0.20914660394191742
Validation loss: 1.5877176561663229

Epoch: 6| Step: 10
Training loss: 0.2096506953239441
Validation loss: 1.6126340973761775

Epoch: 6| Step: 11
Training loss: 0.23796114325523376
Validation loss: 1.6285988733332644

Epoch: 6| Step: 12
Training loss: 0.3360583782196045
Validation loss: 1.5956588022170528

Epoch: 6| Step: 13
Training loss: 0.24167653918266296
Validation loss: 1.6136734293353172

Epoch: 291| Step: 0
Training loss: 0.26803380250930786
Validation loss: 1.5820300348343388

Epoch: 6| Step: 1
Training loss: 0.16813132166862488
Validation loss: 1.6040841341018677

Epoch: 6| Step: 2
Training loss: 0.23551297187805176
Validation loss: 1.6061737005428602

Epoch: 6| Step: 3
Training loss: 0.32530009746551514
Validation loss: 1.589006588023196

Epoch: 6| Step: 4
Training loss: 0.31299304962158203
Validation loss: 1.5980646776896652

Epoch: 6| Step: 5
Training loss: 0.4891117513179779
Validation loss: 1.6138968749712872

Epoch: 6| Step: 6
Training loss: 0.2416810244321823
Validation loss: 1.5973330915615123

Epoch: 6| Step: 7
Training loss: 0.1481817364692688
Validation loss: 1.6036172784784788

Epoch: 6| Step: 8
Training loss: 0.36770614981651306
Validation loss: 1.6444438029361028

Epoch: 6| Step: 9
Training loss: 0.2700604498386383
Validation loss: 1.6730499190668906

Epoch: 6| Step: 10
Training loss: 0.14751538634300232
Validation loss: 1.6615659011307584

Epoch: 6| Step: 11
Training loss: 0.4086342453956604
Validation loss: 1.7004169302601968

Epoch: 6| Step: 12
Training loss: 0.21847902238368988
Validation loss: 1.679618545757827

Epoch: 6| Step: 13
Training loss: 0.2125050127506256
Validation loss: 1.6933636665344238

Epoch: 292| Step: 0
Training loss: 0.23664551973342896
Validation loss: 1.6685874551855109

Epoch: 6| Step: 1
Training loss: 0.32321783900260925
Validation loss: 1.6847574223754227

Epoch: 6| Step: 2
Training loss: 0.16840320825576782
Validation loss: 1.6885585720821092

Epoch: 6| Step: 3
Training loss: 0.18500933051109314
Validation loss: 1.6453354948310441

Epoch: 6| Step: 4
Training loss: 0.29124879837036133
Validation loss: 1.6632355054219563

Epoch: 6| Step: 5
Training loss: 0.19424286484718323
Validation loss: 1.6013439137448546

Epoch: 6| Step: 6
Training loss: 0.09019455313682556
Validation loss: 1.5943254450316071

Epoch: 6| Step: 7
Training loss: 0.24380861222743988
Validation loss: 1.5721591493134857

Epoch: 6| Step: 8
Training loss: 0.41920006275177
Validation loss: 1.5888478256041003

Epoch: 6| Step: 9
Training loss: 0.3005179166793823
Validation loss: 1.569243481082301

Epoch: 6| Step: 10
Training loss: 0.4262772798538208
Validation loss: 1.589501465520551

Epoch: 6| Step: 11
Training loss: 0.2892231345176697
Validation loss: 1.6090659685032342

Epoch: 6| Step: 12
Training loss: 0.28273385763168335
Validation loss: 1.6263422799366776

Epoch: 6| Step: 13
Training loss: 0.36516252160072327
Validation loss: 1.5942465810365574

Epoch: 293| Step: 0
Training loss: 0.2606458365917206
Validation loss: 1.6179315697762273

Epoch: 6| Step: 1
Training loss: 0.26345524191856384
Validation loss: 1.6383252336132912

Epoch: 6| Step: 2
Training loss: 0.19344481825828552
Validation loss: 1.6077084528502597

Epoch: 6| Step: 3
Training loss: 0.2436361163854599
Validation loss: 1.6350739579046927

Epoch: 6| Step: 4
Training loss: 0.1578860580921173
Validation loss: 1.6265649334076913

Epoch: 6| Step: 5
Training loss: 0.5261138081550598
Validation loss: 1.6698343702541885

Epoch: 6| Step: 6
Training loss: 0.4857409596443176
Validation loss: 1.6578033098610498

Epoch: 6| Step: 7
Training loss: 0.19693218171596527
Validation loss: 1.6502990876474688

Epoch: 6| Step: 8
Training loss: 0.2921985685825348
Validation loss: 1.6445991454585906

Epoch: 6| Step: 9
Training loss: 0.1963900625705719
Validation loss: 1.6035877197019515

Epoch: 6| Step: 10
Training loss: 0.18565773963928223
Validation loss: 1.6443444990342664

Epoch: 6| Step: 11
Training loss: 0.24629108607769012
Validation loss: 1.5664092174140356

Epoch: 6| Step: 12
Training loss: 0.3720688223838806
Validation loss: 1.6218927803859915

Epoch: 6| Step: 13
Training loss: 0.26531437039375305
Validation loss: 1.6031192502667826

Epoch: 294| Step: 0
Training loss: 0.3885476887226105
Validation loss: 1.6325530364949217

Epoch: 6| Step: 1
Training loss: 0.27615270018577576
Validation loss: 1.654424645567453

Epoch: 6| Step: 2
Training loss: 0.4094248414039612
Validation loss: 1.6926015256553568

Epoch: 6| Step: 3
Training loss: 0.3028339743614197
Validation loss: 1.7104235310708322

Epoch: 6| Step: 4
Training loss: 0.4183853566646576
Validation loss: 1.67243032686172

Epoch: 6| Step: 5
Training loss: 0.19918517768383026
Validation loss: 1.6739483879458519

Epoch: 6| Step: 6
Training loss: 0.2531142830848694
Validation loss: 1.6378003294749925

Epoch: 6| Step: 7
Training loss: 0.18365733325481415
Validation loss: 1.67314903325932

Epoch: 6| Step: 8
Training loss: 0.11882258951663971
Validation loss: 1.6390039638806415

Epoch: 6| Step: 9
Training loss: 0.5315200686454773
Validation loss: 1.6745344323496665

Epoch: 6| Step: 10
Training loss: 0.28345048427581787
Validation loss: 1.6676091276189333

Epoch: 6| Step: 11
Training loss: 0.28476110100746155
Validation loss: 1.6632791193582679

Epoch: 6| Step: 12
Training loss: 0.25586068630218506
Validation loss: 1.6501583117310719

Epoch: 6| Step: 13
Training loss: 0.3174450397491455
Validation loss: 1.5975352307801605

Epoch: 295| Step: 0
Training loss: 0.38294291496276855
Validation loss: 1.5715798254935973

Epoch: 6| Step: 1
Training loss: 0.2992839813232422
Validation loss: 1.5343084284054336

Epoch: 6| Step: 2
Training loss: 0.22057846188545227
Validation loss: 1.5448899589559084

Epoch: 6| Step: 3
Training loss: 0.23512965440750122
Validation loss: 1.559702806575324

Epoch: 6| Step: 4
Training loss: 0.3560091257095337
Validation loss: 1.5294683671766711

Epoch: 6| Step: 5
Training loss: 0.3127027750015259
Validation loss: 1.5455114239005632

Epoch: 6| Step: 6
Training loss: 0.26892948150634766
Validation loss: 1.6129815155459988

Epoch: 6| Step: 7
Training loss: 0.10579332709312439
Validation loss: 1.6012725317349998

Epoch: 6| Step: 8
Training loss: 0.46098563075065613
Validation loss: 1.6120309522075038

Epoch: 6| Step: 9
Training loss: 0.1231672465801239
Validation loss: 1.6424784891067012

Epoch: 6| Step: 10
Training loss: 0.35530519485473633
Validation loss: 1.6375873665655813

Epoch: 6| Step: 11
Training loss: 0.20665863156318665
Validation loss: 1.6332404587858467

Epoch: 6| Step: 12
Training loss: 0.2726042568683624
Validation loss: 1.5989777452202254

Epoch: 6| Step: 13
Training loss: 0.3249761164188385
Validation loss: 1.5781246180175452

Epoch: 296| Step: 0
Training loss: 0.20003917813301086
Validation loss: 1.5789619748310377

Epoch: 6| Step: 1
Training loss: 0.189784437417984
Validation loss: 1.5472399560354089

Epoch: 6| Step: 2
Training loss: 0.3914983868598938
Validation loss: 1.5152107848916003

Epoch: 6| Step: 3
Training loss: 0.47880616784095764
Validation loss: 1.537749428902903

Epoch: 6| Step: 4
Training loss: 0.1681756228208542
Validation loss: 1.5390913986390637

Epoch: 6| Step: 5
Training loss: 0.227876678109169
Validation loss: 1.542901933834117

Epoch: 6| Step: 6
Training loss: 0.15935051441192627
Validation loss: 1.6096177434408536

Epoch: 6| Step: 7
Training loss: 0.2791098952293396
Validation loss: 1.6121786602081791

Epoch: 6| Step: 8
Training loss: 0.14347922801971436
Validation loss: 1.599998979158299

Epoch: 6| Step: 9
Training loss: 0.2351876199245453
Validation loss: 1.6592513938103952

Epoch: 6| Step: 10
Training loss: 0.3082152009010315
Validation loss: 1.580397081631486

Epoch: 6| Step: 11
Training loss: 0.33151775598526
Validation loss: 1.6008094497906264

Epoch: 6| Step: 12
Training loss: 0.33555763959884644
Validation loss: 1.6248323840479697

Epoch: 6| Step: 13
Training loss: 0.25640684366226196
Validation loss: 1.5897480608314596

Epoch: 297| Step: 0
Training loss: 0.26710185408592224
Validation loss: 1.6351730387697938

Epoch: 6| Step: 1
Training loss: 0.28991270065307617
Validation loss: 1.5711375974839734

Epoch: 6| Step: 2
Training loss: 0.22471903264522552
Validation loss: 1.5944685141245525

Epoch: 6| Step: 3
Training loss: 0.23326227068901062
Validation loss: 1.5942531272929201

Epoch: 6| Step: 4
Training loss: 0.4996577501296997
Validation loss: 1.5726217941571308

Epoch: 6| Step: 5
Training loss: 0.30834364891052246
Validation loss: 1.6009211206948886

Epoch: 6| Step: 6
Training loss: 0.24785707890987396
Validation loss: 1.5865865426678811

Epoch: 6| Step: 7
Training loss: 0.1979990303516388
Validation loss: 1.5981990380953717

Epoch: 6| Step: 8
Training loss: 0.35658398270606995
Validation loss: 1.6056838958494124

Epoch: 6| Step: 9
Training loss: 0.2102242410182953
Validation loss: 1.6338992759745607

Epoch: 6| Step: 10
Training loss: 0.23684659600257874
Validation loss: 1.6183232671471053

Epoch: 6| Step: 11
Training loss: 0.19027945399284363
Validation loss: 1.6343646062317716

Epoch: 6| Step: 12
Training loss: 0.3740987181663513
Validation loss: 1.6279187817727365

Epoch: 6| Step: 13
Training loss: 0.4180203080177307
Validation loss: 1.6789983293061614

Epoch: 298| Step: 0
Training loss: 0.5226300358772278
Validation loss: 1.6288192259368075

Epoch: 6| Step: 1
Training loss: 0.3328394293785095
Validation loss: 1.6257565072787705

Epoch: 6| Step: 2
Training loss: 0.3247559070587158
Validation loss: 1.5930063852699854

Epoch: 6| Step: 3
Training loss: 0.397142618894577
Validation loss: 1.6089451825746925

Epoch: 6| Step: 4
Training loss: 0.26642441749572754
Validation loss: 1.6022284928188528

Epoch: 6| Step: 5
Training loss: 0.23377728462219238
Validation loss: 1.6178541850018244

Epoch: 6| Step: 6
Training loss: 0.17511184513568878
Validation loss: 1.6302768940566688

Epoch: 6| Step: 7
Training loss: 0.13669948279857635
Validation loss: 1.639157223445113

Epoch: 6| Step: 8
Training loss: 0.2522193491458893
Validation loss: 1.6341604750643495

Epoch: 6| Step: 9
Training loss: 0.4511639475822449
Validation loss: 1.6407029795390304

Epoch: 6| Step: 10
Training loss: 0.17445167899131775
Validation loss: 1.6285707309681883

Epoch: 6| Step: 11
Training loss: 0.21929673850536346
Validation loss: 1.6795777774626208

Epoch: 6| Step: 12
Training loss: 0.31182530522346497
Validation loss: 1.6793520963320168

Epoch: 6| Step: 13
Training loss: 0.3579132854938507
Validation loss: 1.685693569080804

Epoch: 299| Step: 0
Training loss: 0.23441889882087708
Validation loss: 1.6598034469030236

Epoch: 6| Step: 1
Training loss: 0.3506484627723694
Validation loss: 1.6358515575367918

Epoch: 6| Step: 2
Training loss: 0.41709885001182556
Validation loss: 1.6173042571672829

Epoch: 6| Step: 3
Training loss: 0.5181733965873718
Validation loss: 1.6246541789782944

Epoch: 6| Step: 4
Training loss: 0.4073888063430786
Validation loss: 1.5678794063547605

Epoch: 6| Step: 5
Training loss: 0.2546658217906952
Validation loss: 1.4931078380154026

Epoch: 6| Step: 6
Training loss: 0.23700881004333496
Validation loss: 1.5433895229011454

Epoch: 6| Step: 7
Training loss: 0.36651310324668884
Validation loss: 1.5531188236769808

Epoch: 6| Step: 8
Training loss: 0.6000849008560181
Validation loss: 1.57935962113001

Epoch: 6| Step: 9
Training loss: 0.37995678186416626
Validation loss: 1.5486064559669905

Epoch: 6| Step: 10
Training loss: 0.3484719395637512
Validation loss: 1.537577066370236

Epoch: 6| Step: 11
Training loss: 0.22279536724090576
Validation loss: 1.5254370063863776

Epoch: 6| Step: 12
Training loss: 0.2134677767753601
Validation loss: 1.5333097057957803

Epoch: 6| Step: 13
Training loss: 0.259835809469223
Validation loss: 1.5526174018459935

Epoch: 300| Step: 0
Training loss: 0.39417335391044617
Validation loss: 1.5895151181887555

Epoch: 6| Step: 1
Training loss: 0.3506215512752533
Validation loss: 1.6178202013815604

Epoch: 6| Step: 2
Training loss: 0.422709584236145
Validation loss: 1.6116912467505342

Epoch: 6| Step: 3
Training loss: 0.24295368790626526
Validation loss: 1.6169815922296176

Epoch: 6| Step: 4
Training loss: 0.31966081261634827
Validation loss: 1.633844615310751

Epoch: 6| Step: 5
Training loss: 0.2865111231803894
Validation loss: 1.6217031235335975

Epoch: 6| Step: 6
Training loss: 0.2588067948818207
Validation loss: 1.6164542423781527

Epoch: 6| Step: 7
Training loss: 0.25175830721855164
Validation loss: 1.6012103544768466

Epoch: 6| Step: 8
Training loss: 0.27757692337036133
Validation loss: 1.5925016108379568

Epoch: 6| Step: 9
Training loss: 0.22723379731178284
Validation loss: 1.6034901154938566

Epoch: 6| Step: 10
Training loss: 0.13430184125900269
Validation loss: 1.5769328609589608

Epoch: 6| Step: 11
Training loss: 0.23520106077194214
Validation loss: 1.5727001172240063

Epoch: 6| Step: 12
Training loss: 0.2708321213722229
Validation loss: 1.5708067180008016

Epoch: 6| Step: 13
Training loss: 0.21634121239185333
Validation loss: 1.5791138513113863

Epoch: 301| Step: 0
Training loss: 0.28485897183418274
Validation loss: 1.5609349845558085

Epoch: 6| Step: 1
Training loss: 0.18710142374038696
Validation loss: 1.553331498176821

Epoch: 6| Step: 2
Training loss: 0.27932173013687134
Validation loss: 1.5385486848892704

Epoch: 6| Step: 3
Training loss: 0.10530457645654678
Validation loss: 1.5784006016228789

Epoch: 6| Step: 4
Training loss: 0.15120835602283478
Validation loss: 1.6062838505673152

Epoch: 6| Step: 5
Training loss: 0.15945389866828918
Validation loss: 1.6363913179725729

Epoch: 6| Step: 6
Training loss: 0.38987743854522705
Validation loss: 1.655964345060369

Epoch: 6| Step: 7
Training loss: 0.21371597051620483
Validation loss: 1.6592648324146066

Epoch: 6| Step: 8
Training loss: 0.35519665479660034
Validation loss: 1.6351002685485347

Epoch: 6| Step: 9
Training loss: 0.2876487970352173
Validation loss: 1.632878431709864

Epoch: 6| Step: 10
Training loss: 0.20681452751159668
Validation loss: 1.6325331208526448

Epoch: 6| Step: 11
Training loss: 0.24957725405693054
Validation loss: 1.6009922489043205

Epoch: 6| Step: 12
Training loss: 0.34082484245300293
Validation loss: 1.5800922596326439

Epoch: 6| Step: 13
Training loss: 0.35001140832901
Validation loss: 1.5705916779015654

Epoch: 302| Step: 0
Training loss: 0.3604641556739807
Validation loss: 1.5861052402886011

Epoch: 6| Step: 1
Training loss: 0.4264189600944519
Validation loss: 1.5488932696721887

Epoch: 6| Step: 2
Training loss: 0.30100327730178833
Validation loss: 1.5588990437087191

Epoch: 6| Step: 3
Training loss: 0.2554595172405243
Validation loss: 1.5777011161209435

Epoch: 6| Step: 4
Training loss: 0.3149201273918152
Validation loss: 1.5702300161443732

Epoch: 6| Step: 5
Training loss: 0.2636364698410034
Validation loss: 1.554821143868149

Epoch: 6| Step: 6
Training loss: 0.3950391113758087
Validation loss: 1.5642343233990412

Epoch: 6| Step: 7
Training loss: 0.171696275472641
Validation loss: 1.5742131125542425

Epoch: 6| Step: 8
Training loss: 0.28838038444519043
Validation loss: 1.5826870138927172

Epoch: 6| Step: 9
Training loss: 0.2702557444572449
Validation loss: 1.5918043326306086

Epoch: 6| Step: 10
Training loss: 0.2118103802204132
Validation loss: 1.5798814617177492

Epoch: 6| Step: 11
Training loss: 0.2445010244846344
Validation loss: 1.5979271922060239

Epoch: 6| Step: 12
Training loss: 0.326617956161499
Validation loss: 1.5683781100857643

Epoch: 6| Step: 13
Training loss: 0.17471952736377716
Validation loss: 1.563698854497684

Epoch: 303| Step: 0
Training loss: 0.14326563477516174
Validation loss: 1.5195496953943723

Epoch: 6| Step: 1
Training loss: 0.1484585404396057
Validation loss: 1.4990068084450179

Epoch: 6| Step: 2
Training loss: 0.3045734167098999
Validation loss: 1.508881945763865

Epoch: 6| Step: 3
Training loss: 0.21189653873443604
Validation loss: 1.5004455171605593

Epoch: 6| Step: 4
Training loss: 0.5252920389175415
Validation loss: 1.5304466857705066

Epoch: 6| Step: 5
Training loss: 0.37493664026260376
Validation loss: 1.5567974300794705

Epoch: 6| Step: 6
Training loss: 0.09775593876838684
Validation loss: 1.569914125627087

Epoch: 6| Step: 7
Training loss: 0.3007497489452362
Validation loss: 1.601906458536784

Epoch: 6| Step: 8
Training loss: 0.2185106873512268
Validation loss: 1.6201955720942507

Epoch: 6| Step: 9
Training loss: 0.23308980464935303
Validation loss: 1.6494031375454319

Epoch: 6| Step: 10
Training loss: 0.22685524821281433
Validation loss: 1.655328837774133

Epoch: 6| Step: 11
Training loss: 0.18199996650218964
Validation loss: 1.6789307376389861

Epoch: 6| Step: 12
Training loss: 0.4033113121986389
Validation loss: 1.6671347541193808

Epoch: 6| Step: 13
Training loss: 0.18766851723194122
Validation loss: 1.6798703119318972

Epoch: 304| Step: 0
Training loss: 0.20731300115585327
Validation loss: 1.6592043933048044

Epoch: 6| Step: 1
Training loss: 0.21238502860069275
Validation loss: 1.6256732517673123

Epoch: 6| Step: 2
Training loss: 0.21117651462554932
Validation loss: 1.5919096982607277

Epoch: 6| Step: 3
Training loss: 0.49341559410095215
Validation loss: 1.6175315918460969

Epoch: 6| Step: 4
Training loss: 0.18794803321361542
Validation loss: 1.6044217809554069

Epoch: 6| Step: 5
Training loss: 0.4897536039352417
Validation loss: 1.5863769708141204

Epoch: 6| Step: 6
Training loss: 0.1093490868806839
Validation loss: 1.5563764841325822

Epoch: 6| Step: 7
Training loss: 0.29478153586387634
Validation loss: 1.5680817070827688

Epoch: 6| Step: 8
Training loss: 0.2256666123867035
Validation loss: 1.57492051329664

Epoch: 6| Step: 9
Training loss: 0.16317272186279297
Validation loss: 1.5978481808016378

Epoch: 6| Step: 10
Training loss: 0.22195418179035187
Validation loss: 1.5951251676005702

Epoch: 6| Step: 11
Training loss: 0.2426014244556427
Validation loss: 1.6044149168076054

Epoch: 6| Step: 12
Training loss: 0.24483567476272583
Validation loss: 1.6569681244511758

Epoch: 6| Step: 13
Training loss: 0.16934655606746674
Validation loss: 1.648228310769604

Epoch: 305| Step: 0
Training loss: 0.15073946118354797
Validation loss: 1.6701776186625164

Epoch: 6| Step: 1
Training loss: 0.21773366630077362
Validation loss: 1.6362121348739953

Epoch: 6| Step: 2
Training loss: 0.14314600825309753
Validation loss: 1.6334480854772753

Epoch: 6| Step: 3
Training loss: 0.13798509538173676
Validation loss: 1.6304204989505071

Epoch: 6| Step: 4
Training loss: 0.21666771173477173
Validation loss: 1.5930163424502137

Epoch: 6| Step: 5
Training loss: 0.2397187352180481
Validation loss: 1.6021457449082406

Epoch: 6| Step: 6
Training loss: 0.360079824924469
Validation loss: 1.5818211468317176

Epoch: 6| Step: 7
Training loss: 0.30878472328186035
Validation loss: 1.5853936262028192

Epoch: 6| Step: 8
Training loss: 0.25426435470581055
Validation loss: 1.5622449818477835

Epoch: 6| Step: 9
Training loss: 0.32820332050323486
Validation loss: 1.5906564317723757

Epoch: 6| Step: 10
Training loss: 0.19639155268669128
Validation loss: 1.6140847565025411

Epoch: 6| Step: 11
Training loss: 0.22090522944927216
Validation loss: 1.6240957065295147

Epoch: 6| Step: 12
Training loss: 0.39489054679870605
Validation loss: 1.6550665978462464

Epoch: 6| Step: 13
Training loss: 0.2346157729625702
Validation loss: 1.6638481424700828

Epoch: 306| Step: 0
Training loss: 0.2406800538301468
Validation loss: 1.624434562780524

Epoch: 6| Step: 1
Training loss: 0.3756908178329468
Validation loss: 1.6395176764457458

Epoch: 6| Step: 2
Training loss: 0.249054417014122
Validation loss: 1.6235558948209208

Epoch: 6| Step: 3
Training loss: 0.2592194080352783
Validation loss: 1.596658847665274

Epoch: 6| Step: 4
Training loss: 0.3707582354545593
Validation loss: 1.594770190536335

Epoch: 6| Step: 5
Training loss: 0.13531962037086487
Validation loss: 1.5762772790847286

Epoch: 6| Step: 6
Training loss: 0.35150453448295593
Validation loss: 1.613801328084802

Epoch: 6| Step: 7
Training loss: 0.32397568225860596
Validation loss: 1.603284091077825

Epoch: 6| Step: 8
Training loss: 0.22692495584487915
Validation loss: 1.6078793771805302

Epoch: 6| Step: 9
Training loss: 0.1910417675971985
Validation loss: 1.6305219319558912

Epoch: 6| Step: 10
Training loss: 0.18257181346416473
Validation loss: 1.6511627333138579

Epoch: 6| Step: 11
Training loss: 0.25251615047454834
Validation loss: 1.6506435563487392

Epoch: 6| Step: 12
Training loss: 0.25799989700317383
Validation loss: 1.628534334962086

Epoch: 6| Step: 13
Training loss: 0.09660018980503082
Validation loss: 1.685610709651824

Epoch: 307| Step: 0
Training loss: 0.20026463270187378
Validation loss: 1.6547923998166156

Epoch: 6| Step: 1
Training loss: 0.2762596607208252
Validation loss: 1.6447102356982488

Epoch: 6| Step: 2
Training loss: 0.214845210313797
Validation loss: 1.6480675076925626

Epoch: 6| Step: 3
Training loss: 0.3121733069419861
Validation loss: 1.687818838704017

Epoch: 6| Step: 4
Training loss: 0.3989490270614624
Validation loss: 1.6516443093617756

Epoch: 6| Step: 5
Training loss: 0.4146398603916168
Validation loss: 1.6906467137798187

Epoch: 6| Step: 6
Training loss: 0.11406337469816208
Validation loss: 1.679047183323932

Epoch: 6| Step: 7
Training loss: 0.2549237012863159
Validation loss: 1.682016231680429

Epoch: 6| Step: 8
Training loss: 0.29807713627815247
Validation loss: 1.6697447223048056

Epoch: 6| Step: 9
Training loss: 0.1858014166355133
Validation loss: 1.6657171018661991

Epoch: 6| Step: 10
Training loss: 0.13170430064201355
Validation loss: 1.6324575511358117

Epoch: 6| Step: 11
Training loss: 0.14848169684410095
Validation loss: 1.6019780212833035

Epoch: 6| Step: 12
Training loss: 0.18505430221557617
Validation loss: 1.6440088108021726

Epoch: 6| Step: 13
Training loss: 0.29155394434928894
Validation loss: 1.614710166890134

Epoch: 308| Step: 0
Training loss: 0.20568329095840454
Validation loss: 1.612844833763697

Epoch: 6| Step: 1
Training loss: 0.17638275027275085
Validation loss: 1.612247613168532

Epoch: 6| Step: 2
Training loss: 0.15905961394309998
Validation loss: 1.6141353371322795

Epoch: 6| Step: 3
Training loss: 0.3050176501274109
Validation loss: 1.615061992599118

Epoch: 6| Step: 4
Training loss: 0.1931019127368927
Validation loss: 1.6300124840069843

Epoch: 6| Step: 5
Training loss: 0.2737278938293457
Validation loss: 1.5923617437321653

Epoch: 6| Step: 6
Training loss: 0.3933537006378174
Validation loss: 1.5906580801933043

Epoch: 6| Step: 7
Training loss: 0.19134831428527832
Validation loss: 1.6046054376068937

Epoch: 6| Step: 8
Training loss: 0.22958345711231232
Validation loss: 1.5865135679962814

Epoch: 6| Step: 9
Training loss: 0.3525100350379944
Validation loss: 1.5721297571735997

Epoch: 6| Step: 10
Training loss: 0.34271639585494995
Validation loss: 1.6141972362354238

Epoch: 6| Step: 11
Training loss: 0.20169448852539062
Validation loss: 1.5611271332669001

Epoch: 6| Step: 12
Training loss: 0.3165889382362366
Validation loss: 1.592293332981807

Epoch: 6| Step: 13
Training loss: 0.34336057305336
Validation loss: 1.5907847958226358

Epoch: 309| Step: 0
Training loss: 0.28657326102256775
Validation loss: 1.589684776080552

Epoch: 6| Step: 1
Training loss: 0.27497339248657227
Validation loss: 1.598195469507607

Epoch: 6| Step: 2
Training loss: 0.20185509324073792
Validation loss: 1.6182468040015108

Epoch: 6| Step: 3
Training loss: 0.12083283066749573
Validation loss: 1.6659334628812728

Epoch: 6| Step: 4
Training loss: 0.28911852836608887
Validation loss: 1.6525529892213884

Epoch: 6| Step: 5
Training loss: 0.3355981111526489
Validation loss: 1.674230811416462

Epoch: 6| Step: 6
Training loss: 0.26163017749786377
Validation loss: 1.6511031607145905

Epoch: 6| Step: 7
Training loss: 0.1812526434659958
Validation loss: 1.6650949319203694

Epoch: 6| Step: 8
Training loss: 0.4152917265892029
Validation loss: 1.6076388807706936

Epoch: 6| Step: 9
Training loss: 0.2883192002773285
Validation loss: 1.5786768736377839

Epoch: 6| Step: 10
Training loss: 0.2559242248535156
Validation loss: 1.5733903672105523

Epoch: 6| Step: 11
Training loss: 0.2625022828578949
Validation loss: 1.5518136024475098

Epoch: 6| Step: 12
Training loss: 0.19554799795150757
Validation loss: 1.5570334208908903

Epoch: 6| Step: 13
Training loss: 0.21381385624408722
Validation loss: 1.5940110580895537

Epoch: 310| Step: 0
Training loss: 0.27088844776153564
Validation loss: 1.555055909259345

Epoch: 6| Step: 1
Training loss: 0.2616111934185028
Validation loss: 1.548472976171842

Epoch: 6| Step: 2
Training loss: 0.22188952565193176
Validation loss: 1.5564653681170555

Epoch: 6| Step: 3
Training loss: 0.3800409436225891
Validation loss: 1.5702987665771155

Epoch: 6| Step: 4
Training loss: 0.2376839816570282
Validation loss: 1.5856952058371676

Epoch: 6| Step: 5
Training loss: 0.21439531445503235
Validation loss: 1.5902257478365334

Epoch: 6| Step: 6
Training loss: 0.24282708764076233
Validation loss: 1.592617368185392

Epoch: 6| Step: 7
Training loss: 0.3119291663169861
Validation loss: 1.5636056392423567

Epoch: 6| Step: 8
Training loss: 0.4711291193962097
Validation loss: 1.5726565417423044

Epoch: 6| Step: 9
Training loss: 0.289462149143219
Validation loss: 1.5663406836089266

Epoch: 6| Step: 10
Training loss: 0.30312833189964294
Validation loss: 1.5882030264023812

Epoch: 6| Step: 11
Training loss: 0.19606970250606537
Validation loss: 1.5610597543818976

Epoch: 6| Step: 12
Training loss: 0.12700539827346802
Validation loss: 1.6029817494012977

Epoch: 6| Step: 13
Training loss: 0.3675476312637329
Validation loss: 1.5999022017243087

Epoch: 311| Step: 0
Training loss: 0.24279683828353882
Validation loss: 1.5871785122861144

Epoch: 6| Step: 1
Training loss: 0.17099666595458984
Validation loss: 1.62655044627446

Epoch: 6| Step: 2
Training loss: 0.24541112780570984
Validation loss: 1.6093871388384091

Epoch: 6| Step: 3
Training loss: 0.2717590034008026
Validation loss: 1.605918638808753

Epoch: 6| Step: 4
Training loss: 0.16301646828651428
Validation loss: 1.580697589023139

Epoch: 6| Step: 5
Training loss: 0.27977779507637024
Validation loss: 1.57973139901315

Epoch: 6| Step: 6
Training loss: 0.12778839468955994
Validation loss: 1.5784054904855707

Epoch: 6| Step: 7
Training loss: 0.2372514307498932
Validation loss: 1.5703483499506468

Epoch: 6| Step: 8
Training loss: 0.45308589935302734
Validation loss: 1.5857474906470186

Epoch: 6| Step: 9
Training loss: 0.26591452956199646
Validation loss: 1.6007416043230283

Epoch: 6| Step: 10
Training loss: 0.27718600630760193
Validation loss: 1.5905819387846096

Epoch: 6| Step: 11
Training loss: 0.2782796025276184
Validation loss: 1.5996265744650235

Epoch: 6| Step: 12
Training loss: 0.1957206130027771
Validation loss: 1.584731186589887

Epoch: 6| Step: 13
Training loss: 0.20584392547607422
Validation loss: 1.581108836717503

Epoch: 312| Step: 0
Training loss: 0.2674034833908081
Validation loss: 1.5553781012053132

Epoch: 6| Step: 1
Training loss: 0.25183919072151184
Validation loss: 1.5982386912069013

Epoch: 6| Step: 2
Training loss: 0.22557196021080017
Validation loss: 1.6108789610606369

Epoch: 6| Step: 3
Training loss: 0.19100703299045563
Validation loss: 1.5937022419386013

Epoch: 6| Step: 4
Training loss: 0.13534969091415405
Validation loss: 1.6041979494915213

Epoch: 6| Step: 5
Training loss: 0.29707446694374084
Validation loss: 1.6220774983847013

Epoch: 6| Step: 6
Training loss: 0.21294333040714264
Validation loss: 1.6019472665684198

Epoch: 6| Step: 7
Training loss: 0.2573137879371643
Validation loss: 1.5873261215866252

Epoch: 6| Step: 8
Training loss: 0.32595187425613403
Validation loss: 1.6022935310999553

Epoch: 6| Step: 9
Training loss: 0.31385618448257446
Validation loss: 1.58295537002625

Epoch: 6| Step: 10
Training loss: 0.22936998307704926
Validation loss: 1.5495836568135086

Epoch: 6| Step: 11
Training loss: 0.44078075885772705
Validation loss: 1.5580498903028426

Epoch: 6| Step: 12
Training loss: 0.1687835454940796
Validation loss: 1.5197221899545321

Epoch: 6| Step: 13
Training loss: 0.08339527994394302
Validation loss: 1.5481624167452577

Epoch: 313| Step: 0
Training loss: 0.19775667786598206
Validation loss: 1.5349574768415062

Epoch: 6| Step: 1
Training loss: 0.16822855174541473
Validation loss: 1.5432738591265935

Epoch: 6| Step: 2
Training loss: 0.15068703889846802
Validation loss: 1.5346764761914489

Epoch: 6| Step: 3
Training loss: 0.35466083884239197
Validation loss: 1.531638688938592

Epoch: 6| Step: 4
Training loss: 0.11192094534635544
Validation loss: 1.530082844918774

Epoch: 6| Step: 5
Training loss: 0.3178582191467285
Validation loss: 1.5245534976323445

Epoch: 6| Step: 6
Training loss: 0.33578091859817505
Validation loss: 1.5157134417564637

Epoch: 6| Step: 7
Training loss: 0.1118369996547699
Validation loss: 1.4939367694239463

Epoch: 6| Step: 8
Training loss: 0.1948508322238922
Validation loss: 1.5348933076345792

Epoch: 6| Step: 9
Training loss: 0.20755326747894287
Validation loss: 1.5212982264898156

Epoch: 6| Step: 10
Training loss: 0.16920050978660583
Validation loss: 1.5186542234113138

Epoch: 6| Step: 11
Training loss: 0.316891074180603
Validation loss: 1.519715762907459

Epoch: 6| Step: 12
Training loss: 0.2956670820713043
Validation loss: 1.5370992229830833

Epoch: 6| Step: 13
Training loss: 0.2551136910915375
Validation loss: 1.5349779718665666

Epoch: 314| Step: 0
Training loss: 0.12555408477783203
Validation loss: 1.58244449861588

Epoch: 6| Step: 1
Training loss: 0.23470646142959595
Validation loss: 1.6265036982874717

Epoch: 6| Step: 2
Training loss: 0.14548538625240326
Validation loss: 1.615303013914375

Epoch: 6| Step: 3
Training loss: 0.07853643596172333
Validation loss: 1.6317663961841213

Epoch: 6| Step: 4
Training loss: 0.2101716548204422
Validation loss: 1.613818633940912

Epoch: 6| Step: 5
Training loss: 0.4121220111846924
Validation loss: 1.6070182464456046

Epoch: 6| Step: 6
Training loss: 0.28087306022644043
Validation loss: 1.582291946616224

Epoch: 6| Step: 7
Training loss: 0.46568048000335693
Validation loss: 1.524739755097256

Epoch: 6| Step: 8
Training loss: 0.22735054790973663
Validation loss: 1.5460037108390563

Epoch: 6| Step: 9
Training loss: 0.2105102837085724
Validation loss: 1.5280497433036886

Epoch: 6| Step: 10
Training loss: 0.2231540083885193
Validation loss: 1.4977011148647597

Epoch: 6| Step: 11
Training loss: 0.1984909474849701
Validation loss: 1.5200501885465396

Epoch: 6| Step: 12
Training loss: 0.24898655712604523
Validation loss: 1.5151523441396735

Epoch: 6| Step: 13
Training loss: 0.1473744511604309
Validation loss: 1.5330920104057557

Epoch: 315| Step: 0
Training loss: 0.3537485897541046
Validation loss: 1.519441557186906

Epoch: 6| Step: 1
Training loss: 0.209633007645607
Validation loss: 1.5521712405707246

Epoch: 6| Step: 2
Training loss: 0.1858658641576767
Validation loss: 1.5500353767025856

Epoch: 6| Step: 3
Training loss: 0.15586978197097778
Validation loss: 1.5478180736623786

Epoch: 6| Step: 4
Training loss: 0.1578029990196228
Validation loss: 1.5822625647309005

Epoch: 6| Step: 5
Training loss: 0.2552403211593628
Validation loss: 1.5766789374812957

Epoch: 6| Step: 6
Training loss: 0.24367088079452515
Validation loss: 1.5515908823218396

Epoch: 6| Step: 7
Training loss: 0.25053906440734863
Validation loss: 1.5879355181929886

Epoch: 6| Step: 8
Training loss: 0.18127402663230896
Validation loss: 1.539246456597441

Epoch: 6| Step: 9
Training loss: 0.2179509401321411
Validation loss: 1.5345605598982943

Epoch: 6| Step: 10
Training loss: 0.12197474390268326
Validation loss: 1.576577510885013

Epoch: 6| Step: 11
Training loss: 0.325374037027359
Validation loss: 1.5867648970696233

Epoch: 6| Step: 12
Training loss: 0.22360309958457947
Validation loss: 1.5887195294903171

Epoch: 6| Step: 13
Training loss: 0.20687535405158997
Validation loss: 1.5688596784427602

Epoch: 316| Step: 0
Training loss: 0.41418716311454773
Validation loss: 1.5954536994298298

Epoch: 6| Step: 1
Training loss: 0.19274994730949402
Validation loss: 1.6090944543961556

Epoch: 6| Step: 2
Training loss: 0.1607622355222702
Validation loss: 1.5861553556175643

Epoch: 6| Step: 3
Training loss: 0.24247299134731293
Validation loss: 1.5642537199040896

Epoch: 6| Step: 4
Training loss: 0.1940838247537613
Validation loss: 1.5720579495993994

Epoch: 6| Step: 5
Training loss: 0.23800086975097656
Validation loss: 1.5564859810695852

Epoch: 6| Step: 6
Training loss: 0.23546530306339264
Validation loss: 1.5421877099621681

Epoch: 6| Step: 7
Training loss: 0.17598626017570496
Validation loss: 1.5594483806240944

Epoch: 6| Step: 8
Training loss: 0.16383348405361176
Validation loss: 1.5240112684106315

Epoch: 6| Step: 9
Training loss: 0.2840242385864258
Validation loss: 1.522544091106743

Epoch: 6| Step: 10
Training loss: 0.2577887773513794
Validation loss: 1.536400830873879

Epoch: 6| Step: 11
Training loss: 0.1030433177947998
Validation loss: 1.5191618588662916

Epoch: 6| Step: 12
Training loss: 0.18133997917175293
Validation loss: 1.5368353679615965

Epoch: 6| Step: 13
Training loss: 0.09139855951070786
Validation loss: 1.5115429124524515

Epoch: 317| Step: 0
Training loss: 0.14925548434257507
Validation loss: 1.5494694895641778

Epoch: 6| Step: 1
Training loss: 0.10274218022823334
Validation loss: 1.5716489130450833

Epoch: 6| Step: 2
Training loss: 0.22036254405975342
Validation loss: 1.5501171658116002

Epoch: 6| Step: 3
Training loss: 0.1438739001750946
Validation loss: 1.5538422830643193

Epoch: 6| Step: 4
Training loss: 0.15934628248214722
Validation loss: 1.5378360697018203

Epoch: 6| Step: 5
Training loss: 0.28529834747314453
Validation loss: 1.5405593533669748

Epoch: 6| Step: 6
Training loss: 0.28321367502212524
Validation loss: 1.5292456893510715

Epoch: 6| Step: 7
Training loss: 0.20794519782066345
Validation loss: 1.5154738862027404

Epoch: 6| Step: 8
Training loss: 0.1403001844882965
Validation loss: 1.524172334260838

Epoch: 6| Step: 9
Training loss: 0.258941650390625
Validation loss: 1.5563663577520719

Epoch: 6| Step: 10
Training loss: 0.4442163407802582
Validation loss: 1.5675093371381041

Epoch: 6| Step: 11
Training loss: 0.2081933319568634
Validation loss: 1.5835797312439128

Epoch: 6| Step: 12
Training loss: 0.14153960347175598
Validation loss: 1.5507711146467476

Epoch: 6| Step: 13
Training loss: 0.28665024042129517
Validation loss: 1.5843403672659269

Epoch: 318| Step: 0
Training loss: 0.18139831721782684
Validation loss: 1.6380202449778074

Epoch: 6| Step: 1
Training loss: 0.2680235505104065
Validation loss: 1.6443450271442372

Epoch: 6| Step: 2
Training loss: 0.3256295323371887
Validation loss: 1.6440726890358874

Epoch: 6| Step: 3
Training loss: 0.19784119725227356
Validation loss: 1.6495137022387596

Epoch: 6| Step: 4
Training loss: 0.23465564846992493
Validation loss: 1.607096584894324

Epoch: 6| Step: 5
Training loss: 0.14044919610023499
Validation loss: 1.5722948902396745

Epoch: 6| Step: 6
Training loss: 0.1926092803478241
Validation loss: 1.571101039968511

Epoch: 6| Step: 7
Training loss: 0.1645064502954483
Validation loss: 1.5505674987710931

Epoch: 6| Step: 8
Training loss: 0.22446419298648834
Validation loss: 1.5283307388264646

Epoch: 6| Step: 9
Training loss: 0.43865489959716797
Validation loss: 1.5383303383345246

Epoch: 6| Step: 10
Training loss: 0.18764224648475647
Validation loss: 1.5481365098748157

Epoch: 6| Step: 11
Training loss: 0.23712274432182312
Validation loss: 1.5311424309207546

Epoch: 6| Step: 12
Training loss: 0.1407584846019745
Validation loss: 1.5530105547238422

Epoch: 6| Step: 13
Training loss: 0.15249572694301605
Validation loss: 1.581266805689822

Epoch: 319| Step: 0
Training loss: 0.18892422318458557
Validation loss: 1.6014821708843272

Epoch: 6| Step: 1
Training loss: 0.18668988347053528
Validation loss: 1.5962172336475824

Epoch: 6| Step: 2
Training loss: 0.30771568417549133
Validation loss: 1.5890310015729678

Epoch: 6| Step: 3
Training loss: 0.22061297297477722
Validation loss: 1.574094900520899

Epoch: 6| Step: 4
Training loss: 0.17106887698173523
Validation loss: 1.568186995803669

Epoch: 6| Step: 5
Training loss: 0.10308452695608139
Validation loss: 1.59202988173372

Epoch: 6| Step: 6
Training loss: 0.2647589147090912
Validation loss: 1.5780339010300175

Epoch: 6| Step: 7
Training loss: 0.215614452958107
Validation loss: 1.5214580335924703

Epoch: 6| Step: 8
Training loss: 0.13848739862442017
Validation loss: 1.5424494845892793

Epoch: 6| Step: 9
Training loss: 0.17068511247634888
Validation loss: 1.5341517989353468

Epoch: 6| Step: 10
Training loss: 0.18078917264938354
Validation loss: 1.569613483644301

Epoch: 6| Step: 11
Training loss: 0.3781720995903015
Validation loss: 1.563680338603194

Epoch: 6| Step: 12
Training loss: 0.2799897789955139
Validation loss: 1.575961532131318

Epoch: 6| Step: 13
Training loss: 0.23335425555706024
Validation loss: 1.6001311937967937

Epoch: 320| Step: 0
Training loss: 0.25411319732666016
Validation loss: 1.6263500900678738

Epoch: 6| Step: 1
Training loss: 0.12866950035095215
Validation loss: 1.6214219908560477

Epoch: 6| Step: 2
Training loss: 0.18848435580730438
Validation loss: 1.6152047457233552

Epoch: 6| Step: 3
Training loss: 0.15000078082084656
Validation loss: 1.5963934685594292

Epoch: 6| Step: 4
Training loss: 0.3862929940223694
Validation loss: 1.5516778628031414

Epoch: 6| Step: 5
Training loss: 0.13048717379570007
Validation loss: 1.5782312923862087

Epoch: 6| Step: 6
Training loss: 0.24156638979911804
Validation loss: 1.5560224197244132

Epoch: 6| Step: 7
Training loss: 0.1487300992012024
Validation loss: 1.5600400996464554

Epoch: 6| Step: 8
Training loss: 0.26669570803642273
Validation loss: 1.5557049423135736

Epoch: 6| Step: 9
Training loss: 0.20237433910369873
Validation loss: 1.560819197726506

Epoch: 6| Step: 10
Training loss: 0.16724632680416107
Validation loss: 1.5889893308762582

Epoch: 6| Step: 11
Training loss: 0.2843599021434784
Validation loss: 1.6019904305857997

Epoch: 6| Step: 12
Training loss: 0.24335426092147827
Validation loss: 1.575630791725651

Epoch: 6| Step: 13
Training loss: 0.16647249460220337
Validation loss: 1.6481191496695242

Epoch: 321| Step: 0
Training loss: 0.3784630596637726
Validation loss: 1.6691447893778484

Epoch: 6| Step: 1
Training loss: 0.4334162473678589
Validation loss: 1.6507942022815827

Epoch: 6| Step: 2
Training loss: 0.19661764800548553
Validation loss: 1.6303934935600526

Epoch: 6| Step: 3
Training loss: 0.32850080728530884
Validation loss: 1.6330396154875397

Epoch: 6| Step: 4
Training loss: 0.13507303595542908
Validation loss: 1.6217489063098867

Epoch: 6| Step: 5
Training loss: 0.20864170789718628
Validation loss: 1.5963118255779307

Epoch: 6| Step: 6
Training loss: 0.1923929899930954
Validation loss: 1.5423088432640157

Epoch: 6| Step: 7
Training loss: 0.2395574152469635
Validation loss: 1.5685361226399739

Epoch: 6| Step: 8
Training loss: 0.3356921076774597
Validation loss: 1.582668637716642

Epoch: 6| Step: 9
Training loss: 0.26994943618774414
Validation loss: 1.5309078667753486

Epoch: 6| Step: 10
Training loss: 0.2863727807998657
Validation loss: 1.553927690752091

Epoch: 6| Step: 11
Training loss: 0.14464285969734192
Validation loss: 1.578119936809745

Epoch: 6| Step: 12
Training loss: 0.384061336517334
Validation loss: 1.5675001823773949

Epoch: 6| Step: 13
Training loss: 0.2970081865787506
Validation loss: 1.5786868192816292

Epoch: 322| Step: 0
Training loss: 0.3647202253341675
Validation loss: 1.5918941446529922

Epoch: 6| Step: 1
Training loss: 0.2640692889690399
Validation loss: 1.617338716342885

Epoch: 6| Step: 2
Training loss: 0.1844801902770996
Validation loss: 1.6150782544125792

Epoch: 6| Step: 3
Training loss: 0.27199235558509827
Validation loss: 1.6138466071057063

Epoch: 6| Step: 4
Training loss: 0.2616907060146332
Validation loss: 1.6257272689573226

Epoch: 6| Step: 5
Training loss: 0.282270610332489
Validation loss: 1.6410472995491439

Epoch: 6| Step: 6
Training loss: 0.28509169816970825
Validation loss: 1.5992855077148767

Epoch: 6| Step: 7
Training loss: 0.17054958641529083
Validation loss: 1.5955990411901986

Epoch: 6| Step: 8
Training loss: 0.33864879608154297
Validation loss: 1.591369625060789

Epoch: 6| Step: 9
Training loss: 0.09829013049602509
Validation loss: 1.576738647235337

Epoch: 6| Step: 10
Training loss: 0.12524184584617615
Validation loss: 1.5882319916961014

Epoch: 6| Step: 11
Training loss: 0.24217985570430756
Validation loss: 1.6068023853404547

Epoch: 6| Step: 12
Training loss: 0.22625477612018585
Validation loss: 1.573407897385218

Epoch: 6| Step: 13
Training loss: 0.2347804754972458
Validation loss: 1.601213510318469

Epoch: 323| Step: 0
Training loss: 0.2445048689842224
Validation loss: 1.576530086096897

Epoch: 6| Step: 1
Training loss: 0.3692113757133484
Validation loss: 1.598720750501079

Epoch: 6| Step: 2
Training loss: 0.17942795157432556
Validation loss: 1.6291755219941497

Epoch: 6| Step: 3
Training loss: 0.5142863988876343
Validation loss: 1.5990199888906171

Epoch: 6| Step: 4
Training loss: 0.13760879635810852
Validation loss: 1.5893851621176607

Epoch: 6| Step: 5
Training loss: 0.19141900539398193
Validation loss: 1.5499356254454582

Epoch: 6| Step: 6
Training loss: 0.3123628497123718
Validation loss: 1.559399676579301

Epoch: 6| Step: 7
Training loss: 0.08256527036428452
Validation loss: 1.5939562948801185

Epoch: 6| Step: 8
Training loss: 0.1124284639954567
Validation loss: 1.5810586470429615

Epoch: 6| Step: 9
Training loss: 0.1697039008140564
Validation loss: 1.5735358922712264

Epoch: 6| Step: 10
Training loss: 0.06615079194307327
Validation loss: 1.6019639891962851

Epoch: 6| Step: 11
Training loss: 0.17391642928123474
Validation loss: 1.6139920347480363

Epoch: 6| Step: 12
Training loss: 0.23095004260540009
Validation loss: 1.608992697090231

Epoch: 6| Step: 13
Training loss: 0.22177299857139587
Validation loss: 1.6233787946803595

Epoch: 324| Step: 0
Training loss: 0.12061548233032227
Validation loss: 1.6074553023102462

Epoch: 6| Step: 1
Training loss: 0.26554086804389954
Validation loss: 1.5911957576710691

Epoch: 6| Step: 2
Training loss: 0.15382416546344757
Validation loss: 1.60516877840924

Epoch: 6| Step: 3
Training loss: 0.17967858910560608
Validation loss: 1.5479878007724721

Epoch: 6| Step: 4
Training loss: 0.2051801085472107
Validation loss: 1.5567454279109996

Epoch: 6| Step: 5
Training loss: 0.2099112868309021
Validation loss: 1.5246680551959622

Epoch: 6| Step: 6
Training loss: 0.20478644967079163
Validation loss: 1.5543586207974343

Epoch: 6| Step: 7
Training loss: 0.19606100022792816
Validation loss: 1.55369270360598

Epoch: 6| Step: 8
Training loss: 0.15225178003311157
Validation loss: 1.5328701042359876

Epoch: 6| Step: 9
Training loss: 0.11275728791952133
Validation loss: 1.557866842516007

Epoch: 6| Step: 10
Training loss: 0.27434206008911133
Validation loss: 1.6324224587409728

Epoch: 6| Step: 11
Training loss: 0.4254647493362427
Validation loss: 1.623763790694616

Epoch: 6| Step: 12
Training loss: 0.29802948236465454
Validation loss: 1.6218127230162263

Epoch: 6| Step: 13
Training loss: 0.27582114934921265
Validation loss: 1.5968377718361475

Epoch: 325| Step: 0
Training loss: 0.1250801384449005
Validation loss: 1.6147919867628364

Epoch: 6| Step: 1
Training loss: 0.1279381662607193
Validation loss: 1.6342534685647616

Epoch: 6| Step: 2
Training loss: 0.2295222282409668
Validation loss: 1.6315195163091023

Epoch: 6| Step: 3
Training loss: 0.13153424859046936
Validation loss: 1.6466280260393698

Epoch: 6| Step: 4
Training loss: 0.28612154722213745
Validation loss: 1.6284275849660237

Epoch: 6| Step: 5
Training loss: 0.17270749807357788
Validation loss: 1.6282840454450218

Epoch: 6| Step: 6
Training loss: 0.2834217846393585
Validation loss: 1.6330823975224649

Epoch: 6| Step: 7
Training loss: 0.2761167883872986
Validation loss: 1.6279684856373777

Epoch: 6| Step: 8
Training loss: 0.1712302565574646
Validation loss: 1.6221588350111438

Epoch: 6| Step: 9
Training loss: 0.2473205178976059
Validation loss: 1.6087902310074016

Epoch: 6| Step: 10
Training loss: 0.42319443821907043
Validation loss: 1.612102771318087

Epoch: 6| Step: 11
Training loss: 0.46447277069091797
Validation loss: 1.6426014041387906

Epoch: 6| Step: 12
Training loss: 0.12089958786964417
Validation loss: 1.6273766666330316

Epoch: 6| Step: 13
Training loss: 0.3276579976081848
Validation loss: 1.6164143521298644

Epoch: 326| Step: 0
Training loss: 0.17494350671768188
Validation loss: 1.6259147633788407

Epoch: 6| Step: 1
Training loss: 0.1571100652217865
Validation loss: 1.5889712931007467

Epoch: 6| Step: 2
Training loss: 0.12580770254135132
Validation loss: 1.5902140858352825

Epoch: 6| Step: 3
Training loss: 0.20107927918434143
Validation loss: 1.5694272082339051

Epoch: 6| Step: 4
Training loss: 0.3086779713630676
Validation loss: 1.6375387304572648

Epoch: 6| Step: 5
Training loss: 0.24336504936218262
Validation loss: 1.6064579704756379

Epoch: 6| Step: 6
Training loss: 0.22826257348060608
Validation loss: 1.577009138240609

Epoch: 6| Step: 7
Training loss: 0.3386504054069519
Validation loss: 1.5805762967755717

Epoch: 6| Step: 8
Training loss: 0.17667147517204285
Validation loss: 1.630657866436948

Epoch: 6| Step: 9
Training loss: 0.30992037057876587
Validation loss: 1.5817024553975751

Epoch: 6| Step: 10
Training loss: 0.29692476987838745
Validation loss: 1.5883291434216242

Epoch: 6| Step: 11
Training loss: 0.1760883927345276
Validation loss: 1.6070868533144715

Epoch: 6| Step: 12
Training loss: 0.15115922689437866
Validation loss: 1.6095530243330105

Epoch: 6| Step: 13
Training loss: 0.28078392148017883
Validation loss: 1.6322727036732498

Epoch: 327| Step: 0
Training loss: 0.2736794054508209
Validation loss: 1.6412597433213265

Epoch: 6| Step: 1
Training loss: 0.20433413982391357
Validation loss: 1.6381440137022285

Epoch: 6| Step: 2
Training loss: 0.21281251311302185
Validation loss: 1.6281198506714196

Epoch: 6| Step: 3
Training loss: 0.26638126373291016
Validation loss: 1.6412948434070875

Epoch: 6| Step: 4
Training loss: 0.19810786843299866
Validation loss: 1.6443427531949935

Epoch: 6| Step: 5
Training loss: 0.2813868522644043
Validation loss: 1.6656929946714831

Epoch: 6| Step: 6
Training loss: 0.15361031889915466
Validation loss: 1.6267651575867847

Epoch: 6| Step: 7
Training loss: 0.16875149309635162
Validation loss: 1.6106701051035235

Epoch: 6| Step: 8
Training loss: 0.45889168977737427
Validation loss: 1.615660414900831

Epoch: 6| Step: 9
Training loss: 0.12488710880279541
Validation loss: 1.6165418894060197

Epoch: 6| Step: 10
Training loss: 0.15875917673110962
Validation loss: 1.6194217897230578

Epoch: 6| Step: 11
Training loss: 0.21128259599208832
Validation loss: 1.5909115819520847

Epoch: 6| Step: 12
Training loss: 0.19982615113258362
Validation loss: 1.5766097217477777

Epoch: 6| Step: 13
Training loss: 0.19271229207515717
Validation loss: 1.6052390016535276

Epoch: 328| Step: 0
Training loss: 0.1911948025226593
Validation loss: 1.5759449812673754

Epoch: 6| Step: 1
Training loss: 0.21951240301132202
Validation loss: 1.605994455275997

Epoch: 6| Step: 2
Training loss: 0.15532737970352173
Validation loss: 1.589241676433112

Epoch: 6| Step: 3
Training loss: 0.4567439556121826
Validation loss: 1.5753106891468007

Epoch: 6| Step: 4
Training loss: 0.2084098756313324
Validation loss: 1.5992425526342084

Epoch: 6| Step: 5
Training loss: 0.26739731431007385
Validation loss: 1.5953539827818513

Epoch: 6| Step: 6
Training loss: 0.22350554168224335
Validation loss: 1.5423094226467995

Epoch: 6| Step: 7
Training loss: 0.22546063363552094
Validation loss: 1.5685738543028473

Epoch: 6| Step: 8
Training loss: 0.27316251397132874
Validation loss: 1.5646310775510726

Epoch: 6| Step: 9
Training loss: 0.32635462284088135
Validation loss: 1.5929528551716958

Epoch: 6| Step: 10
Training loss: 0.23500046133995056
Validation loss: 1.5610290637580297

Epoch: 6| Step: 11
Training loss: 0.2628853917121887
Validation loss: 1.548503407868006

Epoch: 6| Step: 12
Training loss: 0.2517547309398651
Validation loss: 1.5657014141800583

Epoch: 6| Step: 13
Training loss: 0.14988642930984497
Validation loss: 1.5467202368602957

Epoch: 329| Step: 0
Training loss: 0.14839902520179749
Validation loss: 1.5605968749651344

Epoch: 6| Step: 1
Training loss: 0.30392396450042725
Validation loss: 1.5688799260764994

Epoch: 6| Step: 2
Training loss: 0.12865504622459412
Validation loss: 1.5840778632830548

Epoch: 6| Step: 3
Training loss: 0.2669474184513092
Validation loss: 1.5990146372907905

Epoch: 6| Step: 4
Training loss: 0.204964280128479
Validation loss: 1.6009521907375706

Epoch: 6| Step: 5
Training loss: 0.20586252212524414
Validation loss: 1.640171661171862

Epoch: 6| Step: 6
Training loss: 0.18285274505615234
Validation loss: 1.6433217499845771

Epoch: 6| Step: 7
Training loss: 0.158303365111351
Validation loss: 1.6507143384666854

Epoch: 6| Step: 8
Training loss: 0.24368610978126526
Validation loss: 1.6762346875283025

Epoch: 6| Step: 9
Training loss: 0.17087991535663605
Validation loss: 1.721180215958626

Epoch: 6| Step: 10
Training loss: 0.42335864901542664
Validation loss: 1.6920981907075452

Epoch: 6| Step: 11
Training loss: 0.12239354103803635
Validation loss: 1.6895666763346682

Epoch: 6| Step: 12
Training loss: 0.2633320391178131
Validation loss: 1.6874871369331115

Epoch: 6| Step: 13
Training loss: 0.12074007093906403
Validation loss: 1.6582446162418654

Epoch: 330| Step: 0
Training loss: 0.09596097469329834
Validation loss: 1.6527548784850745

Epoch: 6| Step: 1
Training loss: 0.1872718334197998
Validation loss: 1.64698576670821

Epoch: 6| Step: 2
Training loss: 0.10853669792413712
Validation loss: 1.6165930981277137

Epoch: 6| Step: 3
Training loss: 0.15462109446525574
Validation loss: 1.6162913781340404

Epoch: 6| Step: 4
Training loss: 0.4254409372806549
Validation loss: 1.5873865414691228

Epoch: 6| Step: 5
Training loss: 0.18383347988128662
Validation loss: 1.5800138083837365

Epoch: 6| Step: 6
Training loss: 0.28433746099472046
Validation loss: 1.5889246925230949

Epoch: 6| Step: 7
Training loss: 0.15531213581562042
Validation loss: 1.5851078366720548

Epoch: 6| Step: 8
Training loss: 0.2094086855649948
Validation loss: 1.5903969375036096

Epoch: 6| Step: 9
Training loss: 0.24940000474452972
Validation loss: 1.572877295555607

Epoch: 6| Step: 10
Training loss: 0.2493956983089447
Validation loss: 1.575814695768459

Epoch: 6| Step: 11
Training loss: 0.20680338144302368
Validation loss: 1.5632604809217556

Epoch: 6| Step: 12
Training loss: 0.1710606813430786
Validation loss: 1.5758462285482755

Epoch: 6| Step: 13
Training loss: 0.11859430372714996
Validation loss: 1.590338130151072

Epoch: 331| Step: 0
Training loss: 0.40846967697143555
Validation loss: 1.5934586499326973

Epoch: 6| Step: 1
Training loss: 0.22327885031700134
Validation loss: 1.5961334679716377

Epoch: 6| Step: 2
Training loss: 0.3039395213127136
Validation loss: 1.5910912854697115

Epoch: 6| Step: 3
Training loss: 0.19534139335155487
Validation loss: 1.5709706775603756

Epoch: 6| Step: 4
Training loss: 0.2019955813884735
Validation loss: 1.5672210019121888

Epoch: 6| Step: 5
Training loss: 0.19718129932880402
Validation loss: 1.548082056224987

Epoch: 6| Step: 6
Training loss: 0.14461424946784973
Validation loss: 1.5515582817856983

Epoch: 6| Step: 7
Training loss: 0.1492118537425995
Validation loss: 1.5373329052361109

Epoch: 6| Step: 8
Training loss: 0.28348463773727417
Validation loss: 1.5874870541275188

Epoch: 6| Step: 9
Training loss: 0.3307027220726013
Validation loss: 1.6191656102416336

Epoch: 6| Step: 10
Training loss: 0.3380244970321655
Validation loss: 1.5747252279712307

Epoch: 6| Step: 11
Training loss: 0.1868753433227539
Validation loss: 1.6034516596025037

Epoch: 6| Step: 12
Training loss: 0.1857217252254486
Validation loss: 1.575044257666475

Epoch: 6| Step: 13
Training loss: 0.1422460824251175
Validation loss: 1.599634244877805

Epoch: 332| Step: 0
Training loss: 0.12211356312036514
Validation loss: 1.6338717501650575

Epoch: 6| Step: 1
Training loss: 0.22918406128883362
Validation loss: 1.6564208320392075

Epoch: 6| Step: 2
Training loss: 0.38582390546798706
Validation loss: 1.6483868783520115

Epoch: 6| Step: 3
Training loss: 0.30984437465667725
Validation loss: 1.6443691484389766

Epoch: 6| Step: 4
Training loss: 0.33268988132476807
Validation loss: 1.5839701250035276

Epoch: 6| Step: 5
Training loss: 0.14952115714550018
Validation loss: 1.5625417591423116

Epoch: 6| Step: 6
Training loss: 0.20240658521652222
Validation loss: 1.561621226290221

Epoch: 6| Step: 7
Training loss: 0.3408709168434143
Validation loss: 1.5269672774499463

Epoch: 6| Step: 8
Training loss: 0.13539767265319824
Validation loss: 1.5316386940658733

Epoch: 6| Step: 9
Training loss: 0.45451870560646057
Validation loss: 1.5367654497905443

Epoch: 6| Step: 10
Training loss: 0.19264504313468933
Validation loss: 1.5512351746200232

Epoch: 6| Step: 11
Training loss: 0.2633247971534729
Validation loss: 1.570932743369892

Epoch: 6| Step: 12
Training loss: 0.2828943133354187
Validation loss: 1.6013344974928005

Epoch: 6| Step: 13
Training loss: 0.20252037048339844
Validation loss: 1.6064193543567453

Epoch: 333| Step: 0
Training loss: 0.39150774478912354
Validation loss: 1.5978689501362462

Epoch: 6| Step: 1
Training loss: 0.25355297327041626
Validation loss: 1.5845777168068835

Epoch: 6| Step: 2
Training loss: 0.22999230027198792
Validation loss: 1.5615786326828824

Epoch: 6| Step: 3
Training loss: 0.23200678825378418
Validation loss: 1.548123344298332

Epoch: 6| Step: 4
Training loss: 0.12086398899555206
Validation loss: 1.549434987447595

Epoch: 6| Step: 5
Training loss: 0.1670733392238617
Validation loss: 1.5256508486245268

Epoch: 6| Step: 6
Training loss: 0.11548979580402374
Validation loss: 1.5098546371665051

Epoch: 6| Step: 7
Training loss: 0.1922755241394043
Validation loss: 1.5771974530271304

Epoch: 6| Step: 8
Training loss: 0.19161412119865417
Validation loss: 1.5704293212582987

Epoch: 6| Step: 9
Training loss: 0.17351704835891724
Validation loss: 1.566917464297305

Epoch: 6| Step: 10
Training loss: 0.23298326134681702
Validation loss: 1.5568225024848856

Epoch: 6| Step: 11
Training loss: 0.16572652757167816
Validation loss: 1.5485457553658435

Epoch: 6| Step: 12
Training loss: 0.4320831298828125
Validation loss: 1.5367377983626498

Epoch: 6| Step: 13
Training loss: 0.38461992144584656
Validation loss: 1.5219300145743995

Epoch: 334| Step: 0
Training loss: 0.20544099807739258
Validation loss: 1.5536830316307724

Epoch: 6| Step: 1
Training loss: 0.25230368971824646
Validation loss: 1.575192629650075

Epoch: 6| Step: 2
Training loss: 0.11408970504999161
Validation loss: 1.5210225505213584

Epoch: 6| Step: 3
Training loss: 0.4223189651966095
Validation loss: 1.5581902823140543

Epoch: 6| Step: 4
Training loss: 0.1510436236858368
Validation loss: 1.5593314145200996

Epoch: 6| Step: 5
Training loss: 0.09375520050525665
Validation loss: 1.5690800477099676

Epoch: 6| Step: 6
Training loss: 0.2128756046295166
Validation loss: 1.5838389089030604

Epoch: 6| Step: 7
Training loss: 0.17484812438488007
Validation loss: 1.6244258649887577

Epoch: 6| Step: 8
Training loss: 0.13563565909862518
Validation loss: 1.6191757161130187

Epoch: 6| Step: 9
Training loss: 0.30125027894973755
Validation loss: 1.6181268576652772

Epoch: 6| Step: 10
Training loss: 0.29355406761169434
Validation loss: 1.659409571719426

Epoch: 6| Step: 11
Training loss: 0.2805598974227905
Validation loss: 1.6460144212169032

Epoch: 6| Step: 12
Training loss: 0.30059492588043213
Validation loss: 1.6674563871916903

Epoch: 6| Step: 13
Training loss: 0.21551597118377686
Validation loss: 1.6534085184015253

Epoch: 335| Step: 0
Training loss: 0.30731865763664246
Validation loss: 1.6084615684324695

Epoch: 6| Step: 1
Training loss: 0.21606914699077606
Validation loss: 1.6270419602753015

Epoch: 6| Step: 2
Training loss: 0.3048785328865051
Validation loss: 1.5942099453300558

Epoch: 6| Step: 3
Training loss: 0.24036860466003418
Validation loss: 1.5895468605461942

Epoch: 6| Step: 4
Training loss: 0.23386070132255554
Validation loss: 1.5414687715550905

Epoch: 6| Step: 5
Training loss: 0.16109904646873474
Validation loss: 1.5772340066971318

Epoch: 6| Step: 6
Training loss: 0.2706611752510071
Validation loss: 1.5444374968928676

Epoch: 6| Step: 7
Training loss: 0.2275697886943817
Validation loss: 1.5547704568473242

Epoch: 6| Step: 8
Training loss: 0.29790517687797546
Validation loss: 1.550657247984281

Epoch: 6| Step: 9
Training loss: 0.12586672604084015
Validation loss: 1.5628623206128356

Epoch: 6| Step: 10
Training loss: 0.24812108278274536
Validation loss: 1.5830963862839567

Epoch: 6| Step: 11
Training loss: 0.11908351629972458
Validation loss: 1.6155270453422301

Epoch: 6| Step: 12
Training loss: 0.2903127074241638
Validation loss: 1.6312443043596

Epoch: 6| Step: 13
Training loss: 0.11142231523990631
Validation loss: 1.6827056484837686

Epoch: 336| Step: 0
Training loss: 0.29975858330726624
Validation loss: 1.6784402913944696

Epoch: 6| Step: 1
Training loss: 0.23022286593914032
Validation loss: 1.6537223797972485

Epoch: 6| Step: 2
Training loss: 0.18147476017475128
Validation loss: 1.6471127874107772

Epoch: 6| Step: 3
Training loss: 0.18957510590553284
Validation loss: 1.6156288052117953

Epoch: 6| Step: 4
Training loss: 0.13048499822616577
Validation loss: 1.592320337090441

Epoch: 6| Step: 5
Training loss: 0.19850611686706543
Validation loss: 1.5793311249825261

Epoch: 6| Step: 6
Training loss: 0.19288784265518188
Validation loss: 1.600209169490363

Epoch: 6| Step: 7
Training loss: 0.291498601436615
Validation loss: 1.5689400114038938

Epoch: 6| Step: 8
Training loss: 0.5171013474464417
Validation loss: 1.5458565732484222

Epoch: 6| Step: 9
Training loss: 0.2238711416721344
Validation loss: 1.5220110826594855

Epoch: 6| Step: 10
Training loss: 0.2009197622537613
Validation loss: 1.4642904817417104

Epoch: 6| Step: 11
Training loss: 0.20562146604061127
Validation loss: 1.5159616624155352

Epoch: 6| Step: 12
Training loss: 0.18685045838356018
Validation loss: 1.5250404803983626

Epoch: 6| Step: 13
Training loss: 0.10158451646566391
Validation loss: 1.5412422867231472

Epoch: 337| Step: 0
Training loss: 0.23217053711414337
Validation loss: 1.5670680525482341

Epoch: 6| Step: 1
Training loss: 0.3397403359413147
Validation loss: 1.569956975598489

Epoch: 6| Step: 2
Training loss: 0.2803207039833069
Validation loss: 1.6185929903420069

Epoch: 6| Step: 3
Training loss: 0.20249775052070618
Validation loss: 1.5995651188717093

Epoch: 6| Step: 4
Training loss: 0.22091537714004517
Validation loss: 1.6054889771246141

Epoch: 6| Step: 5
Training loss: 0.2224714159965515
Validation loss: 1.6035640931898547

Epoch: 6| Step: 6
Training loss: 0.3209516406059265
Validation loss: 1.6215970490568428

Epoch: 6| Step: 7
Training loss: 0.14887882769107819
Validation loss: 1.5982113461340628

Epoch: 6| Step: 8
Training loss: 0.16129277646541595
Validation loss: 1.5791289767911356

Epoch: 6| Step: 9
Training loss: 0.13668259978294373
Validation loss: 1.5810515957493936

Epoch: 6| Step: 10
Training loss: 0.21075230836868286
Validation loss: 1.6008218475567397

Epoch: 6| Step: 11
Training loss: 0.1478579044342041
Validation loss: 1.5967098948776082

Epoch: 6| Step: 12
Training loss: 0.25416189432144165
Validation loss: 1.6252841103461482

Epoch: 6| Step: 13
Training loss: 0.3012460768222809
Validation loss: 1.6017030631342242

Epoch: 338| Step: 0
Training loss: 0.20506331324577332
Validation loss: 1.6284000053200671

Epoch: 6| Step: 1
Training loss: 0.1994299590587616
Validation loss: 1.6497143622367614

Epoch: 6| Step: 2
Training loss: 0.170844167470932
Validation loss: 1.625840263981973

Epoch: 6| Step: 3
Training loss: 0.22746655344963074
Validation loss: 1.607507469833538

Epoch: 6| Step: 4
Training loss: 0.15083608031272888
Validation loss: 1.6133023026168987

Epoch: 6| Step: 5
Training loss: 0.11597803980112076
Validation loss: 1.6359029303314865

Epoch: 6| Step: 6
Training loss: 0.20592547953128815
Validation loss: 1.616213575486214

Epoch: 6| Step: 7
Training loss: 0.2367885410785675
Validation loss: 1.6096626866248347

Epoch: 6| Step: 8
Training loss: 0.16647732257843018
Validation loss: 1.6001890526022962

Epoch: 6| Step: 9
Training loss: 0.3921077251434326
Validation loss: 1.6063014473966373

Epoch: 6| Step: 10
Training loss: 0.250946581363678
Validation loss: 1.600257376188873

Epoch: 6| Step: 11
Training loss: 0.14371077716350555
Validation loss: 1.5854910394196868

Epoch: 6| Step: 12
Training loss: 0.19244690239429474
Validation loss: 1.613673920272499

Epoch: 6| Step: 13
Training loss: 0.21783065795898438
Validation loss: 1.5870884874815583

Epoch: 339| Step: 0
Training loss: 0.18836352229118347
Validation loss: 1.6017913549177107

Epoch: 6| Step: 1
Training loss: 0.08236455917358398
Validation loss: 1.6112690670515901

Epoch: 6| Step: 2
Training loss: 0.24909953773021698
Validation loss: 1.6418962414546678

Epoch: 6| Step: 3
Training loss: 0.13809505105018616
Validation loss: 1.6275822577937957

Epoch: 6| Step: 4
Training loss: 0.23675522208213806
Validation loss: 1.6212327326497724

Epoch: 6| Step: 5
Training loss: 0.271479070186615
Validation loss: 1.6603234480786067

Epoch: 6| Step: 6
Training loss: 0.24714577198028564
Validation loss: 1.5671397601404498

Epoch: 6| Step: 7
Training loss: 0.18769828975200653
Validation loss: 1.6078088821903351

Epoch: 6| Step: 8
Training loss: 0.19406306743621826
Validation loss: 1.5640476237061203

Epoch: 6| Step: 9
Training loss: 0.14359119534492493
Validation loss: 1.5487855442108647

Epoch: 6| Step: 10
Training loss: 0.33762428164482117
Validation loss: 1.552514636388389

Epoch: 6| Step: 11
Training loss: 0.14551414549350739
Validation loss: 1.5391758795707458

Epoch: 6| Step: 12
Training loss: 0.161804661154747
Validation loss: 1.5281717802888604

Epoch: 6| Step: 13
Training loss: 0.19105273485183716
Validation loss: 1.5415485584607689

Epoch: 340| Step: 0
Training loss: 0.10139872133731842
Validation loss: 1.5613943902395104

Epoch: 6| Step: 1
Training loss: 0.13351094722747803
Validation loss: 1.5971330686282086

Epoch: 6| Step: 2
Training loss: 0.11866568773984909
Validation loss: 1.601268260709701

Epoch: 6| Step: 3
Training loss: 0.2752440273761749
Validation loss: 1.6088793995559856

Epoch: 6| Step: 4
Training loss: 0.22731967270374298
Validation loss: 1.6367053062685075

Epoch: 6| Step: 5
Training loss: 0.40976181626319885
Validation loss: 1.5797548550431446

Epoch: 6| Step: 6
Training loss: 0.24686266481876373
Validation loss: 1.569434723546428

Epoch: 6| Step: 7
Training loss: 0.1513962298631668
Validation loss: 1.5725504736746512

Epoch: 6| Step: 8
Training loss: 0.18068435788154602
Validation loss: 1.5596109577404556

Epoch: 6| Step: 9
Training loss: 0.2097901999950409
Validation loss: 1.5515049478059173

Epoch: 6| Step: 10
Training loss: 0.2877101004123688
Validation loss: 1.5482785240296395

Epoch: 6| Step: 11
Training loss: 0.20669429004192352
Validation loss: 1.5527044803865495

Epoch: 6| Step: 12
Training loss: 0.2486652433872223
Validation loss: 1.5527256957946285

Epoch: 6| Step: 13
Training loss: 0.24480792880058289
Validation loss: 1.5436689187121648

Epoch: 341| Step: 0
Training loss: 0.2542189955711365
Validation loss: 1.5551777533305589

Epoch: 6| Step: 1
Training loss: 0.1789308786392212
Validation loss: 1.5989366910790885

Epoch: 6| Step: 2
Training loss: 0.13926666975021362
Validation loss: 1.6004707505626063

Epoch: 6| Step: 3
Training loss: 0.19396139681339264
Validation loss: 1.644142807170909

Epoch: 6| Step: 4
Training loss: 0.26753583550453186
Validation loss: 1.6346703472957815

Epoch: 6| Step: 5
Training loss: 0.18054908514022827
Validation loss: 1.6279552828881048

Epoch: 6| Step: 6
Training loss: 0.10973343253135681
Validation loss: 1.6351321358834543

Epoch: 6| Step: 7
Training loss: 0.10163126140832901
Validation loss: 1.616748009958575

Epoch: 6| Step: 8
Training loss: 0.2804868221282959
Validation loss: 1.5772435319039129

Epoch: 6| Step: 9
Training loss: 0.21118995547294617
Validation loss: 1.5541607872132333

Epoch: 6| Step: 10
Training loss: 0.132413849234581
Validation loss: 1.5394786519388999

Epoch: 6| Step: 11
Training loss: 0.2019350826740265
Validation loss: 1.567771118174317

Epoch: 6| Step: 12
Training loss: 0.18378494679927826
Validation loss: 1.5326980724129626

Epoch: 6| Step: 13
Training loss: 0.09667104482650757
Validation loss: 1.540564747266872

Epoch: 342| Step: 0
Training loss: 0.18287932872772217
Validation loss: 1.5590412437274892

Epoch: 6| Step: 1
Training loss: 0.14886009693145752
Validation loss: 1.552966299877372

Epoch: 6| Step: 2
Training loss: 0.1590554565191269
Validation loss: 1.5569324967681721

Epoch: 6| Step: 3
Training loss: 0.15550333261489868
Validation loss: 1.5897793923654864

Epoch: 6| Step: 4
Training loss: 0.23706284165382385
Validation loss: 1.5939244429270427

Epoch: 6| Step: 5
Training loss: 0.13612335920333862
Validation loss: 1.5982061598890571

Epoch: 6| Step: 6
Training loss: 0.13439153134822845
Validation loss: 1.6125299264025945

Epoch: 6| Step: 7
Training loss: 0.11696052551269531
Validation loss: 1.6067302932021439

Epoch: 6| Step: 8
Training loss: 0.12039661407470703
Validation loss: 1.5953438448649582

Epoch: 6| Step: 9
Training loss: 0.19639402627944946
Validation loss: 1.5826008210900009

Epoch: 6| Step: 10
Training loss: 0.24090757966041565
Validation loss: 1.5123065017884778

Epoch: 6| Step: 11
Training loss: 0.1629113405942917
Validation loss: 1.5176690675879037

Epoch: 6| Step: 12
Training loss: 0.18044593930244446
Validation loss: 1.5116303813072942

Epoch: 6| Step: 13
Training loss: 0.419502854347229
Validation loss: 1.4910979335026076

Epoch: 343| Step: 0
Training loss: 0.11768028885126114
Validation loss: 1.501616306202386

Epoch: 6| Step: 1
Training loss: 0.17210951447486877
Validation loss: 1.5234706440279562

Epoch: 6| Step: 2
Training loss: 0.12546472251415253
Validation loss: 1.525059207793205

Epoch: 6| Step: 3
Training loss: 0.21027706563472748
Validation loss: 1.5538362085178334

Epoch: 6| Step: 4
Training loss: 0.13517531752586365
Validation loss: 1.5559243989247147

Epoch: 6| Step: 5
Training loss: 0.13121674954891205
Validation loss: 1.5764002364168885

Epoch: 6| Step: 6
Training loss: 0.20637287199497223
Validation loss: 1.579543226508684

Epoch: 6| Step: 7
Training loss: 0.24852538108825684
Validation loss: 1.580841440026478

Epoch: 6| Step: 8
Training loss: 0.10872702300548553
Validation loss: 1.6001187486033286

Epoch: 6| Step: 9
Training loss: 0.2028573751449585
Validation loss: 1.604059451369829

Epoch: 6| Step: 10
Training loss: 0.13671892881393433
Validation loss: 1.604631995642057

Epoch: 6| Step: 11
Training loss: 0.18452206254005432
Validation loss: 1.5573128295201126

Epoch: 6| Step: 12
Training loss: 0.3597988486289978
Validation loss: 1.5267130777400026

Epoch: 6| Step: 13
Training loss: 0.1590813845396042
Validation loss: 1.496794472458542

Epoch: 344| Step: 0
Training loss: 0.19710394740104675
Validation loss: 1.4887998809096634

Epoch: 6| Step: 1
Training loss: 0.19245091080665588
Validation loss: 1.532129080064835

Epoch: 6| Step: 2
Training loss: 0.3049963414669037
Validation loss: 1.528712204707566

Epoch: 6| Step: 3
Training loss: 0.20151841640472412
Validation loss: 1.54131140119286

Epoch: 6| Step: 4
Training loss: 0.15392644703388214
Validation loss: 1.563741865978446

Epoch: 6| Step: 5
Training loss: 0.1452949494123459
Validation loss: 1.5731824303186068

Epoch: 6| Step: 6
Training loss: 0.16011813282966614
Validation loss: 1.5794957965932868

Epoch: 6| Step: 7
Training loss: 0.1804075837135315
Validation loss: 1.6010916630427043

Epoch: 6| Step: 8
Training loss: 0.13882827758789062
Validation loss: 1.6337301795200636

Epoch: 6| Step: 9
Training loss: 0.28954070806503296
Validation loss: 1.6565152983511648

Epoch: 6| Step: 10
Training loss: 0.1919441819190979
Validation loss: 1.6592413943300965

Epoch: 6| Step: 11
Training loss: 0.2578944265842438
Validation loss: 1.6402680579052176

Epoch: 6| Step: 12
Training loss: 0.11368105560541153
Validation loss: 1.6497723517879364

Epoch: 6| Step: 13
Training loss: 0.2797876000404358
Validation loss: 1.618304419261153

Epoch: 345| Step: 0
Training loss: 0.12852290272712708
Validation loss: 1.6276223198060067

Epoch: 6| Step: 1
Training loss: 0.23928609490394592
Validation loss: 1.6236388965319561

Epoch: 6| Step: 2
Training loss: 0.2844034433364868
Validation loss: 1.6188209415763937

Epoch: 6| Step: 3
Training loss: 0.14609569311141968
Validation loss: 1.5874485495269939

Epoch: 6| Step: 4
Training loss: 0.2235628366470337
Validation loss: 1.5550662561129498

Epoch: 6| Step: 5
Training loss: 0.241513192653656
Validation loss: 1.546989280690429

Epoch: 6| Step: 6
Training loss: 0.19974899291992188
Validation loss: 1.539931897194155

Epoch: 6| Step: 7
Training loss: 0.1727212369441986
Validation loss: 1.5436724731999059

Epoch: 6| Step: 8
Training loss: 0.31829023361206055
Validation loss: 1.5613053767911849

Epoch: 6| Step: 9
Training loss: 0.25801604986190796
Validation loss: 1.5922151983425181

Epoch: 6| Step: 10
Training loss: 0.15083374083042145
Validation loss: 1.5914254367992442

Epoch: 6| Step: 11
Training loss: 0.12752284109592438
Validation loss: 1.554677729965538

Epoch: 6| Step: 12
Training loss: 0.20170512795448303
Validation loss: 1.602433439223997

Epoch: 6| Step: 13
Training loss: 0.3376416265964508
Validation loss: 1.6166683960986394

Epoch: 346| Step: 0
Training loss: 0.23683971166610718
Validation loss: 1.6254062306496404

Epoch: 6| Step: 1
Training loss: 0.12701468169689178
Validation loss: 1.6211243009054532

Epoch: 6| Step: 2
Training loss: 0.20536570250988007
Validation loss: 1.6082609417617961

Epoch: 6| Step: 3
Training loss: 0.3352140784263611
Validation loss: 1.5993303701441774

Epoch: 6| Step: 4
Training loss: 0.24846553802490234
Validation loss: 1.5884473170003583

Epoch: 6| Step: 5
Training loss: 0.12439154088497162
Validation loss: 1.5933516692089778

Epoch: 6| Step: 6
Training loss: 0.16534237563610077
Validation loss: 1.5521197306212557

Epoch: 6| Step: 7
Training loss: 0.1408429741859436
Validation loss: 1.5764136698938185

Epoch: 6| Step: 8
Training loss: 0.1610531210899353
Validation loss: 1.548079441952449

Epoch: 6| Step: 9
Training loss: 0.13692255318164825
Validation loss: 1.5396567480538481

Epoch: 6| Step: 10
Training loss: 0.12620234489440918
Validation loss: 1.544267290381975

Epoch: 6| Step: 11
Training loss: 0.12804800271987915
Validation loss: 1.5407484103274602

Epoch: 6| Step: 12
Training loss: 0.11962772160768509
Validation loss: 1.5457467379108552

Epoch: 6| Step: 13
Training loss: 0.2239808440208435
Validation loss: 1.5461402195756153

Epoch: 347| Step: 0
Training loss: 0.16012755036354065
Validation loss: 1.5221161624436736

Epoch: 6| Step: 1
Training loss: 0.15570738911628723
Validation loss: 1.5335659057863298

Epoch: 6| Step: 2
Training loss: 0.09827554225921631
Validation loss: 1.5722108207723147

Epoch: 6| Step: 3
Training loss: 0.11303918063640594
Validation loss: 1.5488985610264603

Epoch: 6| Step: 4
Training loss: 0.20725029706954956
Validation loss: 1.595517941700515

Epoch: 6| Step: 5
Training loss: 0.1450243890285492
Validation loss: 1.6181011815224924

Epoch: 6| Step: 6
Training loss: 0.15448716282844543
Validation loss: 1.6197567524448517

Epoch: 6| Step: 7
Training loss: 0.25050532817840576
Validation loss: 1.614849107239836

Epoch: 6| Step: 8
Training loss: 0.16289949417114258
Validation loss: 1.6439381530207973

Epoch: 6| Step: 9
Training loss: 0.3430062234401703
Validation loss: 1.6182246272281935

Epoch: 6| Step: 10
Training loss: 0.15591832995414734
Validation loss: 1.620931561275195

Epoch: 6| Step: 11
Training loss: 0.19373992085456848
Validation loss: 1.6333647363929338

Epoch: 6| Step: 12
Training loss: 0.12883688509464264
Validation loss: 1.6330125101151005

Epoch: 6| Step: 13
Training loss: 0.20343202352523804
Validation loss: 1.5879777708361227

Epoch: 348| Step: 0
Training loss: 0.1309889256954193
Validation loss: 1.6026655679107995

Epoch: 6| Step: 1
Training loss: 0.18075084686279297
Validation loss: 1.566342637103091

Epoch: 6| Step: 2
Training loss: 0.32605278491973877
Validation loss: 1.5731460022669967

Epoch: 6| Step: 3
Training loss: 0.14184223115444183
Validation loss: 1.5804753726528538

Epoch: 6| Step: 4
Training loss: 0.2752658426761627
Validation loss: 1.5492886330491753

Epoch: 6| Step: 5
Training loss: 0.17797410488128662
Validation loss: 1.562647186299806

Epoch: 6| Step: 6
Training loss: 0.10499481111764908
Validation loss: 1.5633790441738662

Epoch: 6| Step: 7
Training loss: 0.1734377145767212
Validation loss: 1.59733372734439

Epoch: 6| Step: 8
Training loss: 0.20387113094329834
Validation loss: 1.6293810490638978

Epoch: 6| Step: 9
Training loss: 0.18791544437408447
Validation loss: 1.616069068190872

Epoch: 6| Step: 10
Training loss: 0.18621793389320374
Validation loss: 1.5768038348485065

Epoch: 6| Step: 11
Training loss: 0.11157485842704773
Validation loss: 1.599785780393949

Epoch: 6| Step: 12
Training loss: 0.20718634128570557
Validation loss: 1.6065441100828108

Epoch: 6| Step: 13
Training loss: 0.1439548134803772
Validation loss: 1.5686877632653842

Epoch: 349| Step: 0
Training loss: 0.11924625188112259
Validation loss: 1.5854047729123024

Epoch: 6| Step: 1
Training loss: 0.1541561633348465
Validation loss: 1.5849811325791061

Epoch: 6| Step: 2
Training loss: 0.23915556073188782
Validation loss: 1.5775679849809217

Epoch: 6| Step: 3
Training loss: 0.14368420839309692
Validation loss: 1.5936718653607111

Epoch: 6| Step: 4
Training loss: 0.11908639967441559
Validation loss: 1.577708577597013

Epoch: 6| Step: 5
Training loss: 0.22587421536445618
Validation loss: 1.5795190013864988

Epoch: 6| Step: 6
Training loss: 0.1233518198132515
Validation loss: 1.5871338370025798

Epoch: 6| Step: 7
Training loss: 0.1136048287153244
Validation loss: 1.57607187122427

Epoch: 6| Step: 8
Training loss: 0.15420770645141602
Validation loss: 1.5862590792358562

Epoch: 6| Step: 9
Training loss: 0.1510206013917923
Validation loss: 1.5873463397384973

Epoch: 6| Step: 10
Training loss: 0.18847700953483582
Validation loss: 1.5897870166327364

Epoch: 6| Step: 11
Training loss: 0.2629855275154114
Validation loss: 1.5879459932286253

Epoch: 6| Step: 12
Training loss: 0.2101392298936844
Validation loss: 1.557144541894236

Epoch: 6| Step: 13
Training loss: 0.22503359615802765
Validation loss: 1.5523438684401973

Epoch: 350| Step: 0
Training loss: 0.18197926878929138
Validation loss: 1.555934759878343

Epoch: 6| Step: 1
Training loss: 0.1283947229385376
Validation loss: 1.5546977763534875

Epoch: 6| Step: 2
Training loss: 0.29641130566596985
Validation loss: 1.5554084963695978

Epoch: 6| Step: 3
Training loss: 0.1358119398355484
Validation loss: 1.5405847000819382

Epoch: 6| Step: 4
Training loss: 0.14558008313179016
Validation loss: 1.570116389182306

Epoch: 6| Step: 5
Training loss: 0.11407920718193054
Validation loss: 1.5903120694621917

Epoch: 6| Step: 6
Training loss: 0.1991133987903595
Validation loss: 1.5810568614672589

Epoch: 6| Step: 7
Training loss: 0.17397592961788177
Validation loss: 1.611556327471169

Epoch: 6| Step: 8
Training loss: 0.1376587152481079
Validation loss: 1.5991956662106257

Epoch: 6| Step: 9
Training loss: 0.13716581463813782
Validation loss: 1.6017220943204817

Epoch: 6| Step: 10
Training loss: 0.16003826260566711
Validation loss: 1.5973189236015402

Epoch: 6| Step: 11
Training loss: 0.08919095993041992
Validation loss: 1.6254845024437032

Epoch: 6| Step: 12
Training loss: 0.1528601497411728
Validation loss: 1.5966238610206112

Epoch: 6| Step: 13
Training loss: 0.3608802556991577
Validation loss: 1.5872158876029394

Epoch: 351| Step: 0
Training loss: 0.16586509346961975
Validation loss: 1.5869656147495392

Epoch: 6| Step: 1
Training loss: 0.0969112366437912
Validation loss: 1.5667699549787788

Epoch: 6| Step: 2
Training loss: 0.1711583286523819
Validation loss: 1.5327201351042716

Epoch: 6| Step: 3
Training loss: 0.23030927777290344
Validation loss: 1.54595124336981

Epoch: 6| Step: 4
Training loss: 0.1136448010802269
Validation loss: 1.5365078974795598

Epoch: 6| Step: 5
Training loss: 0.12529976665973663
Validation loss: 1.5276222626368205

Epoch: 6| Step: 6
Training loss: 0.16924287378787994
Validation loss: 1.535121512669389

Epoch: 6| Step: 7
Training loss: 0.18765491247177124
Validation loss: 1.5284505069896739

Epoch: 6| Step: 8
Training loss: 0.1606033891439438
Validation loss: 1.545736853794385

Epoch: 6| Step: 9
Training loss: 0.20087026059627533
Validation loss: 1.5549314329701085

Epoch: 6| Step: 10
Training loss: 0.15966162085533142
Validation loss: 1.534722258967738

Epoch: 6| Step: 11
Training loss: 0.12915576994419098
Validation loss: 1.561641973833884

Epoch: 6| Step: 12
Training loss: 0.4013276696205139
Validation loss: 1.5976186016554474

Epoch: 6| Step: 13
Training loss: 0.1830924153327942
Validation loss: 1.5962278073833835

Epoch: 352| Step: 0
Training loss: 0.12948554754257202
Validation loss: 1.6020726708955662

Epoch: 6| Step: 1
Training loss: 0.09260109066963196
Validation loss: 1.58393689381179

Epoch: 6| Step: 2
Training loss: 0.11298146843910217
Validation loss: 1.5834301094855032

Epoch: 6| Step: 3
Training loss: 0.17081017792224884
Validation loss: 1.5422038762800154

Epoch: 6| Step: 4
Training loss: 0.11825171858072281
Validation loss: 1.525579353814484

Epoch: 6| Step: 5
Training loss: 0.1648813784122467
Validation loss: 1.549312545407203

Epoch: 6| Step: 6
Training loss: 0.17501398921012878
Validation loss: 1.5415727400010633

Epoch: 6| Step: 7
Training loss: 0.14388947188854218
Validation loss: 1.5601767340014059

Epoch: 6| Step: 8
Training loss: 0.27210554480552673
Validation loss: 1.518544864910905

Epoch: 6| Step: 9
Training loss: 0.3691726326942444
Validation loss: 1.509630169919742

Epoch: 6| Step: 10
Training loss: 0.18015959858894348
Validation loss: 1.5415884615272604

Epoch: 6| Step: 11
Training loss: 0.23558613657951355
Validation loss: 1.5540320270804948

Epoch: 6| Step: 12
Training loss: 0.16039279103279114
Validation loss: 1.5931610548368065

Epoch: 6| Step: 13
Training loss: 0.1790163516998291
Validation loss: 1.5852596362431843

Epoch: 353| Step: 0
Training loss: 0.22369040548801422
Validation loss: 1.6063670342968357

Epoch: 6| Step: 1
Training loss: 0.18165871500968933
Validation loss: 1.6008947151963429

Epoch: 6| Step: 2
Training loss: 0.14749827980995178
Validation loss: 1.607262283243159

Epoch: 6| Step: 3
Training loss: 0.25881439447402954
Validation loss: 1.6305075435228245

Epoch: 6| Step: 4
Training loss: 0.16142162680625916
Validation loss: 1.6152983045065274

Epoch: 6| Step: 5
Training loss: 0.20179958641529083
Validation loss: 1.5974635257515857

Epoch: 6| Step: 6
Training loss: 0.273531973361969
Validation loss: 1.5988147233122139

Epoch: 6| Step: 7
Training loss: 0.19600048661231995
Validation loss: 1.6072423663190616

Epoch: 6| Step: 8
Training loss: 0.17575888335704803
Validation loss: 1.563328564807933

Epoch: 6| Step: 9
Training loss: 0.12603116035461426
Validation loss: 1.5561334131866373

Epoch: 6| Step: 10
Training loss: 0.09805385768413544
Validation loss: 1.5475304959922709

Epoch: 6| Step: 11
Training loss: 0.2414214313030243
Validation loss: 1.5394830809485527

Epoch: 6| Step: 12
Training loss: 0.12188258767127991
Validation loss: 1.558496808493009

Epoch: 6| Step: 13
Training loss: 0.13184218108654022
Validation loss: 1.5636992941620529

Epoch: 354| Step: 0
Training loss: 0.1294037252664566
Validation loss: 1.5773580048673896

Epoch: 6| Step: 1
Training loss: 0.2270357608795166
Validation loss: 1.616994357878162

Epoch: 6| Step: 2
Training loss: 0.3430039584636688
Validation loss: 1.6343727137452813

Epoch: 6| Step: 3
Training loss: 0.20840606093406677
Validation loss: 1.6404855315403273

Epoch: 6| Step: 4
Training loss: 0.2616075277328491
Validation loss: 1.6630024269062986

Epoch: 6| Step: 5
Training loss: 0.12938255071640015
Validation loss: 1.6499922942089778

Epoch: 6| Step: 6
Training loss: 0.5097882151603699
Validation loss: 1.644128445656069

Epoch: 6| Step: 7
Training loss: 0.1487044095993042
Validation loss: 1.6147260178801834

Epoch: 6| Step: 8
Training loss: 0.17717798054218292
Validation loss: 1.5849911307775846

Epoch: 6| Step: 9
Training loss: 0.20086684823036194
Validation loss: 1.617282473912803

Epoch: 6| Step: 10
Training loss: 0.16328591108322144
Validation loss: 1.5688170797081404

Epoch: 6| Step: 11
Training loss: 0.23588019609451294
Validation loss: 1.6173385753426501

Epoch: 6| Step: 12
Training loss: 0.28073829412460327
Validation loss: 1.5824813022408435

Epoch: 6| Step: 13
Training loss: 0.17762547731399536
Validation loss: 1.5807202477608957

Epoch: 355| Step: 0
Training loss: 0.18791088461875916
Validation loss: 1.5663976220674412

Epoch: 6| Step: 1
Training loss: 0.08840683847665787
Validation loss: 1.5601763661189745

Epoch: 6| Step: 2
Training loss: 0.07666194438934326
Validation loss: 1.5570318198973132

Epoch: 6| Step: 3
Training loss: 0.23740018904209137
Validation loss: 1.554359746235673

Epoch: 6| Step: 4
Training loss: 0.14490953087806702
Validation loss: 1.5584505360613587

Epoch: 6| Step: 5
Training loss: 0.09111001342535019
Validation loss: 1.5615096592134046

Epoch: 6| Step: 6
Training loss: 0.10340426862239838
Validation loss: 1.5531873017229059

Epoch: 6| Step: 7
Training loss: 0.22937092185020447
Validation loss: 1.5788519126112743

Epoch: 6| Step: 8
Training loss: 0.1348705291748047
Validation loss: 1.5505375554484706

Epoch: 6| Step: 9
Training loss: 0.1568109393119812
Validation loss: 1.5632296877522622

Epoch: 6| Step: 10
Training loss: 0.1385282576084137
Validation loss: 1.540952927322798

Epoch: 6| Step: 11
Training loss: 0.2820592522621155
Validation loss: 1.5417430913576515

Epoch: 6| Step: 12
Training loss: 0.15995317697525024
Validation loss: 1.5305075158355057

Epoch: 6| Step: 13
Training loss: 0.11270645260810852
Validation loss: 1.5248450079271871

Epoch: 356| Step: 0
Training loss: 0.2932296395301819
Validation loss: 1.5490833443980063

Epoch: 6| Step: 1
Training loss: 0.2337380051612854
Validation loss: 1.5459629745893582

Epoch: 6| Step: 2
Training loss: 0.20338481664657593
Validation loss: 1.5079701369808567

Epoch: 6| Step: 3
Training loss: 0.12418638169765472
Validation loss: 1.5227881400815901

Epoch: 6| Step: 4
Training loss: 0.1420448124408722
Validation loss: 1.5521429450281206

Epoch: 6| Step: 5
Training loss: 0.12240882962942123
Validation loss: 1.572359000482867

Epoch: 6| Step: 6
Training loss: 0.23057520389556885
Validation loss: 1.5892811462443361

Epoch: 6| Step: 7
Training loss: 0.14330539107322693
Validation loss: 1.6080869500355055

Epoch: 6| Step: 8
Training loss: 0.18167027831077576
Validation loss: 1.5813905039141256

Epoch: 6| Step: 9
Training loss: 0.18954771757125854
Validation loss: 1.5788205490317395

Epoch: 6| Step: 10
Training loss: 0.12733426690101624
Validation loss: 1.5729350857837225

Epoch: 6| Step: 11
Training loss: 0.0979476049542427
Validation loss: 1.5764154439331384

Epoch: 6| Step: 12
Training loss: 0.1785184144973755
Validation loss: 1.5632707861162

Epoch: 6| Step: 13
Training loss: 0.14633747935295105
Validation loss: 1.5597598950068157

Epoch: 357| Step: 0
Training loss: 0.1291172057390213
Validation loss: 1.5214566235901208

Epoch: 6| Step: 1
Training loss: 0.09391804039478302
Validation loss: 1.5576660774087394

Epoch: 6| Step: 2
Training loss: 0.104153111577034
Validation loss: 1.5556932662122993

Epoch: 6| Step: 3
Training loss: 0.12983369827270508
Validation loss: 1.5486965397352814

Epoch: 6| Step: 4
Training loss: 0.16144265234470367
Validation loss: 1.584066734519056

Epoch: 6| Step: 5
Training loss: 0.1110403910279274
Validation loss: 1.5853345112134052

Epoch: 6| Step: 6
Training loss: 0.14232546091079712
Validation loss: 1.599803283650388

Epoch: 6| Step: 7
Training loss: 0.09805619716644287
Validation loss: 1.6081156000014274

Epoch: 6| Step: 8
Training loss: 0.22818872332572937
Validation loss: 1.5909148044483636

Epoch: 6| Step: 9
Training loss: 0.21438394486904144
Validation loss: 1.5953975646726546

Epoch: 6| Step: 10
Training loss: 0.3563869595527649
Validation loss: 1.5841738100974792

Epoch: 6| Step: 11
Training loss: 0.1577061116695404
Validation loss: 1.5712778151676219

Epoch: 6| Step: 12
Training loss: 0.15166853368282318
Validation loss: 1.5915557210163405

Epoch: 6| Step: 13
Training loss: 0.21251437067985535
Validation loss: 1.5825620133389708

Epoch: 358| Step: 0
Training loss: 0.11913056671619415
Validation loss: 1.554789226542237

Epoch: 6| Step: 1
Training loss: 0.21129120886325836
Validation loss: 1.581937333588959

Epoch: 6| Step: 2
Training loss: 0.17134863138198853
Validation loss: 1.6012940163253455

Epoch: 6| Step: 3
Training loss: 0.20604941248893738
Validation loss: 1.5945714648051927

Epoch: 6| Step: 4
Training loss: 0.16356435418128967
Validation loss: 1.6058172359261462

Epoch: 6| Step: 5
Training loss: 0.15670248866081238
Validation loss: 1.6034379441251037

Epoch: 6| Step: 6
Training loss: 0.13778825104236603
Validation loss: 1.5888441070433585

Epoch: 6| Step: 7
Training loss: 0.11026269197463989
Validation loss: 1.5905722341229838

Epoch: 6| Step: 8
Training loss: 0.16517627239227295
Validation loss: 1.5586134784965104

Epoch: 6| Step: 9
Training loss: 0.09104964882135391
Validation loss: 1.5195513297152776

Epoch: 6| Step: 10
Training loss: 0.2529839873313904
Validation loss: 1.5362714464946459

Epoch: 6| Step: 11
Training loss: 0.12019127607345581
Validation loss: 1.5267344969575123

Epoch: 6| Step: 12
Training loss: 0.16704371571540833
Validation loss: 1.5188315568431732

Epoch: 6| Step: 13
Training loss: 0.1412474513053894
Validation loss: 1.509383149044488

Epoch: 359| Step: 0
Training loss: 0.22377680242061615
Validation loss: 1.5281107887145011

Epoch: 6| Step: 1
Training loss: 0.27495962381362915
Validation loss: 1.5388808955428421

Epoch: 6| Step: 2
Training loss: 0.16657215356826782
Validation loss: 1.545738524006259

Epoch: 6| Step: 3
Training loss: 0.11753172427415848
Validation loss: 1.5612954080745738

Epoch: 6| Step: 4
Training loss: 0.18870162963867188
Validation loss: 1.5522829883842058

Epoch: 6| Step: 5
Training loss: 0.16820396482944489
Validation loss: 1.5711119380048526

Epoch: 6| Step: 6
Training loss: 0.15478381514549255
Validation loss: 1.5905996394413773

Epoch: 6| Step: 7
Training loss: 0.1905839741230011
Validation loss: 1.6054446235779793

Epoch: 6| Step: 8
Training loss: 0.10961385071277618
Validation loss: 1.623258327925077

Epoch: 6| Step: 9
Training loss: 0.07611334323883057
Validation loss: 1.6379681505182737

Epoch: 6| Step: 10
Training loss: 0.13154730200767517
Validation loss: 1.632854748797673

Epoch: 6| Step: 11
Training loss: 0.11264549940824509
Validation loss: 1.654346550664594

Epoch: 6| Step: 12
Training loss: 0.18333834409713745
Validation loss: 1.6240227427533878

Epoch: 6| Step: 13
Training loss: 0.10192076861858368
Validation loss: 1.6317870911731516

Epoch: 360| Step: 0
Training loss: 0.1943904459476471
Validation loss: 1.5811418371815835

Epoch: 6| Step: 1
Training loss: 0.13572044670581818
Validation loss: 1.6097870244774768

Epoch: 6| Step: 2
Training loss: 0.17793282866477966
Validation loss: 1.5538867019837903

Epoch: 6| Step: 3
Training loss: 0.1602136641740799
Validation loss: 1.5724432096686414

Epoch: 6| Step: 4
Training loss: 0.09658823907375336
Validation loss: 1.5325634928159817

Epoch: 6| Step: 5
Training loss: 0.20381733775138855
Validation loss: 1.5516266028086345

Epoch: 6| Step: 6
Training loss: 0.20210181176662445
Validation loss: 1.5329792345723798

Epoch: 6| Step: 7
Training loss: 0.12137366831302643
Validation loss: 1.563962153209153

Epoch: 6| Step: 8
Training loss: 0.29760414361953735
Validation loss: 1.5298909807717929

Epoch: 6| Step: 9
Training loss: 0.09674209356307983
Validation loss: 1.5892699963303023

Epoch: 6| Step: 10
Training loss: 0.11489390581846237
Validation loss: 1.5471602216843636

Epoch: 6| Step: 11
Training loss: 0.20313730835914612
Validation loss: 1.579550903330567

Epoch: 6| Step: 12
Training loss: 0.15793931484222412
Validation loss: 1.580301147635265

Epoch: 6| Step: 13
Training loss: 0.0989990383386612
Validation loss: 1.6118204029657508

Epoch: 361| Step: 0
Training loss: 0.37898433208465576
Validation loss: 1.6147419021975609

Epoch: 6| Step: 1
Training loss: 0.1393151581287384
Validation loss: 1.6410428042052894

Epoch: 6| Step: 2
Training loss: 0.1832517385482788
Validation loss: 1.634333731025778

Epoch: 6| Step: 3
Training loss: 0.1645696461200714
Validation loss: 1.6091063791705715

Epoch: 6| Step: 4
Training loss: 0.18824182450771332
Validation loss: 1.5350166892492643

Epoch: 6| Step: 5
Training loss: 0.0653860867023468
Validation loss: 1.5118637123415548

Epoch: 6| Step: 6
Training loss: 0.12508971989154816
Validation loss: 1.51681395499937

Epoch: 6| Step: 7
Training loss: 0.23348820209503174
Validation loss: 1.4971650287669191

Epoch: 6| Step: 8
Training loss: 0.20307151973247528
Validation loss: 1.5209598169531873

Epoch: 6| Step: 9
Training loss: 0.13141554594039917
Validation loss: 1.5146878521929505

Epoch: 6| Step: 10
Training loss: 0.203194260597229
Validation loss: 1.517246195065078

Epoch: 6| Step: 11
Training loss: 0.12654295563697815
Validation loss: 1.4850809676672823

Epoch: 6| Step: 12
Training loss: 0.11838498711585999
Validation loss: 1.5097360982689807

Epoch: 6| Step: 13
Training loss: 0.19485649466514587
Validation loss: 1.5205077971181562

Epoch: 362| Step: 0
Training loss: 0.16017837822437286
Validation loss: 1.5346527753337738

Epoch: 6| Step: 1
Training loss: 0.2986633777618408
Validation loss: 1.5791433741969447

Epoch: 6| Step: 2
Training loss: 0.18609914183616638
Validation loss: 1.6245103920659711

Epoch: 6| Step: 3
Training loss: 0.3503725528717041
Validation loss: 1.6443410560648928

Epoch: 6| Step: 4
Training loss: 0.2711455523967743
Validation loss: 1.639064178671888

Epoch: 6| Step: 5
Training loss: 0.11929481476545334
Validation loss: 1.5961477230953913

Epoch: 6| Step: 6
Training loss: 0.1067977100610733
Validation loss: 1.566958720966052

Epoch: 6| Step: 7
Training loss: 0.14503034949302673
Validation loss: 1.528851564212512

Epoch: 6| Step: 8
Training loss: 0.08405441045761108
Validation loss: 1.5158644594171995

Epoch: 6| Step: 9
Training loss: 0.16829845309257507
Validation loss: 1.5272303460746683

Epoch: 6| Step: 10
Training loss: 0.18413402140140533
Validation loss: 1.5292460123697917

Epoch: 6| Step: 11
Training loss: 0.09064695239067078
Validation loss: 1.5255733049044045

Epoch: 6| Step: 12
Training loss: 0.14481499791145325
Validation loss: 1.4974417327552714

Epoch: 6| Step: 13
Training loss: 0.23918135464191437
Validation loss: 1.487624296578028

Epoch: 363| Step: 0
Training loss: 0.11384803801774979
Validation loss: 1.481673708526037

Epoch: 6| Step: 1
Training loss: 0.3370612561702728
Validation loss: 1.4920721694987307

Epoch: 6| Step: 2
Training loss: 0.1564331352710724
Validation loss: 1.4998893686520156

Epoch: 6| Step: 3
Training loss: 0.10555590689182281
Validation loss: 1.5452186164035593

Epoch: 6| Step: 4
Training loss: 0.18166978657245636
Validation loss: 1.558604419872325

Epoch: 6| Step: 5
Training loss: 0.11777535080909729
Validation loss: 1.5877275390009726

Epoch: 6| Step: 6
Training loss: 0.11546076089143753
Validation loss: 1.5478012792525753

Epoch: 6| Step: 7
Training loss: 0.1790468990802765
Validation loss: 1.5839796784103557

Epoch: 6| Step: 8
Training loss: 0.15565837919712067
Validation loss: 1.5457967609487555

Epoch: 6| Step: 9
Training loss: 0.16566461324691772
Validation loss: 1.538731518612113

Epoch: 6| Step: 10
Training loss: 0.09040413796901703
Validation loss: 1.518917215767727

Epoch: 6| Step: 11
Training loss: 0.1902417540550232
Validation loss: 1.5289716643671836

Epoch: 6| Step: 12
Training loss: 0.15398412942886353
Validation loss: 1.533589243888855

Epoch: 6| Step: 13
Training loss: 0.31921055912971497
Validation loss: 1.4996083603110364

Epoch: 364| Step: 0
Training loss: 0.14492356777191162
Validation loss: 1.565023006931428

Epoch: 6| Step: 1
Training loss: 0.1509249061346054
Validation loss: 1.534358186106528

Epoch: 6| Step: 2
Training loss: 0.18183957040309906
Validation loss: 1.5652542896168207

Epoch: 6| Step: 3
Training loss: 0.17648181319236755
Validation loss: 1.572212283329297

Epoch: 6| Step: 4
Training loss: 0.156636044383049
Validation loss: 1.5945828922333256

Epoch: 6| Step: 5
Training loss: 0.13252127170562744
Validation loss: 1.5989266275077738

Epoch: 6| Step: 6
Training loss: 0.18247878551483154
Validation loss: 1.5937607121723953

Epoch: 6| Step: 7
Training loss: 0.28012073040008545
Validation loss: 1.5873164156431794

Epoch: 6| Step: 8
Training loss: 0.2179216891527176
Validation loss: 1.5497763464527745

Epoch: 6| Step: 9
Training loss: 0.20577412843704224
Validation loss: 1.5586973185180335

Epoch: 6| Step: 10
Training loss: 0.11248056590557098
Validation loss: 1.5377384706210064

Epoch: 6| Step: 11
Training loss: 0.14912404119968414
Validation loss: 1.5224996625736196

Epoch: 6| Step: 12
Training loss: 0.13984474539756775
Validation loss: 1.512393945006914

Epoch: 6| Step: 13
Training loss: 0.17162057757377625
Validation loss: 1.507545477600508

Epoch: 365| Step: 0
Training loss: 0.09540878236293793
Validation loss: 1.5270232474932106

Epoch: 6| Step: 1
Training loss: 0.09665163606405258
Validation loss: 1.5487426455302904

Epoch: 6| Step: 2
Training loss: 0.1272745430469513
Validation loss: 1.5557699472673479

Epoch: 6| Step: 3
Training loss: 0.1684294044971466
Validation loss: 1.5193737835012457

Epoch: 6| Step: 4
Training loss: 0.18693187832832336
Validation loss: 1.5525576376145886

Epoch: 6| Step: 5
Training loss: 0.18423891067504883
Validation loss: 1.5713825584739767

Epoch: 6| Step: 6
Training loss: 0.17311984300613403
Validation loss: 1.5405040620475687

Epoch: 6| Step: 7
Training loss: 0.15767762064933777
Validation loss: 1.5483267550827355

Epoch: 6| Step: 8
Training loss: 0.1308702528476715
Validation loss: 1.5341368131740118

Epoch: 6| Step: 9
Training loss: 0.25332343578338623
Validation loss: 1.4994428926898586

Epoch: 6| Step: 10
Training loss: 0.18629124760627747
Validation loss: 1.5004756905699288

Epoch: 6| Step: 11
Training loss: 0.16211731731891632
Validation loss: 1.5486873119108138

Epoch: 6| Step: 12
Training loss: 0.32212087512016296
Validation loss: 1.5309076334840508

Epoch: 6| Step: 13
Training loss: 0.11936746537685394
Validation loss: 1.5753626547833925

Epoch: 366| Step: 0
Training loss: 0.18833687901496887
Validation loss: 1.5897017178996917

Epoch: 6| Step: 1
Training loss: 0.18077416718006134
Validation loss: 1.6236628870810232

Epoch: 6| Step: 2
Training loss: 0.2552270293235779
Validation loss: 1.6131612229090866

Epoch: 6| Step: 3
Training loss: 0.12974649667739868
Validation loss: 1.5627921896596109

Epoch: 6| Step: 4
Training loss: 0.0965084657073021
Validation loss: 1.5885393350355086

Epoch: 6| Step: 5
Training loss: 0.09393057227134705
Validation loss: 1.5482334962455175

Epoch: 6| Step: 6
Training loss: 0.1166897714138031
Validation loss: 1.5636558404532812

Epoch: 6| Step: 7
Training loss: 0.13368625938892365
Validation loss: 1.54256647504786

Epoch: 6| Step: 8
Training loss: 0.1411599963903427
Validation loss: 1.5888286636721702

Epoch: 6| Step: 9
Training loss: 0.19240854680538177
Validation loss: 1.5470117343369352

Epoch: 6| Step: 10
Training loss: 0.2029036283493042
Validation loss: 1.5579547676988827

Epoch: 6| Step: 11
Training loss: 0.19292138516902924
Validation loss: 1.550948376296669

Epoch: 6| Step: 12
Training loss: 0.1318991482257843
Validation loss: 1.5671638827170096

Epoch: 6| Step: 13
Training loss: 0.15206056833267212
Validation loss: 1.5535814069932508

Epoch: 367| Step: 0
Training loss: 0.3474397361278534
Validation loss: 1.5468007915763444

Epoch: 6| Step: 1
Training loss: 0.14462602138519287
Validation loss: 1.5344252535091933

Epoch: 6| Step: 2
Training loss: 0.30022895336151123
Validation loss: 1.568340181022562

Epoch: 6| Step: 3
Training loss: 0.29896989464759827
Validation loss: 1.5342841673922796

Epoch: 6| Step: 4
Training loss: 0.13745322823524475
Validation loss: 1.5698498551563551

Epoch: 6| Step: 5
Training loss: 0.13509823381900787
Validation loss: 1.5722439673639113

Epoch: 6| Step: 6
Training loss: 0.32197824120521545
Validation loss: 1.608940682103557

Epoch: 6| Step: 7
Training loss: 0.15611746907234192
Validation loss: 1.6490921179453533

Epoch: 6| Step: 8
Training loss: 0.2520976960659027
Validation loss: 1.6091319796859578

Epoch: 6| Step: 9
Training loss: 0.21416409313678741
Validation loss: 1.6085124643900062

Epoch: 6| Step: 10
Training loss: 0.09231552481651306
Validation loss: 1.5845722101067985

Epoch: 6| Step: 11
Training loss: 0.09111892431974411
Validation loss: 1.5787718731869933

Epoch: 6| Step: 12
Training loss: 0.116986483335495
Validation loss: 1.537845047571326

Epoch: 6| Step: 13
Training loss: 0.29200729727745056
Validation loss: 1.549730400885305

Epoch: 368| Step: 0
Training loss: 0.25298184156417847
Validation loss: 1.5147767111819277

Epoch: 6| Step: 1
Training loss: 0.20697012543678284
Validation loss: 1.513499790622342

Epoch: 6| Step: 2
Training loss: 0.1987864077091217
Validation loss: 1.5065841982441563

Epoch: 6| Step: 3
Training loss: 0.17714175581932068
Validation loss: 1.4818280960923882

Epoch: 6| Step: 4
Training loss: 0.19649802148342133
Validation loss: 1.5194196572867773

Epoch: 6| Step: 5
Training loss: 0.11199340969324112
Validation loss: 1.496435038505062

Epoch: 6| Step: 6
Training loss: 0.16355815529823303
Validation loss: 1.5136547767987816

Epoch: 6| Step: 7
Training loss: 0.11065389215946198
Validation loss: 1.5496438985229821

Epoch: 6| Step: 8
Training loss: 0.1496528685092926
Validation loss: 1.565040329451202

Epoch: 6| Step: 9
Training loss: 0.11442987620830536
Validation loss: 1.5941421562625515

Epoch: 6| Step: 10
Training loss: 0.12571638822555542
Validation loss: 1.6083217487540296

Epoch: 6| Step: 11
Training loss: 0.18159951269626617
Validation loss: 1.5905098453644784

Epoch: 6| Step: 12
Training loss: 0.3727659583091736
Validation loss: 1.6186286710923719

Epoch: 6| Step: 13
Training loss: 0.13417935371398926
Validation loss: 1.6136651346760411

Epoch: 369| Step: 0
Training loss: 0.13932755589485168
Validation loss: 1.588443753539875

Epoch: 6| Step: 1
Training loss: 0.23647524416446686
Validation loss: 1.5774694335076116

Epoch: 6| Step: 2
Training loss: 0.11706824600696564
Validation loss: 1.5400663537363852

Epoch: 6| Step: 3
Training loss: 0.3486722707748413
Validation loss: 1.5675757585033294

Epoch: 6| Step: 4
Training loss: 0.15336230397224426
Validation loss: 1.5348448843084357

Epoch: 6| Step: 5
Training loss: 0.18743810057640076
Validation loss: 1.5805173862364985

Epoch: 6| Step: 6
Training loss: 0.13567042350769043
Validation loss: 1.5599951872261621

Epoch: 6| Step: 7
Training loss: 0.13646697998046875
Validation loss: 1.5496993936518186

Epoch: 6| Step: 8
Training loss: 0.14795121550559998
Validation loss: 1.543052081138857

Epoch: 6| Step: 9
Training loss: 0.17302781343460083
Validation loss: 1.535071357603996

Epoch: 6| Step: 10
Training loss: 0.17670941352844238
Validation loss: 1.5276098084706131

Epoch: 6| Step: 11
Training loss: 0.2203768789768219
Validation loss: 1.5585371409693072

Epoch: 6| Step: 12
Training loss: 0.19662311673164368
Validation loss: 1.5512024382109284

Epoch: 6| Step: 13
Training loss: 0.08146592974662781
Validation loss: 1.6081314445823751

Epoch: 370| Step: 0
Training loss: 0.19262635707855225
Validation loss: 1.5713026312089735

Epoch: 6| Step: 1
Training loss: 0.13058049976825714
Validation loss: 1.602853104632388

Epoch: 6| Step: 2
Training loss: 0.13328991830348969
Validation loss: 1.5948577414276779

Epoch: 6| Step: 3
Training loss: 0.14156010746955872
Validation loss: 1.6263433015474709

Epoch: 6| Step: 4
Training loss: 0.16637679934501648
Validation loss: 1.6130468768458213

Epoch: 6| Step: 5
Training loss: 0.1624237298965454
Validation loss: 1.6138448458845898

Epoch: 6| Step: 6
Training loss: 0.12661463022232056
Validation loss: 1.6090189487703386

Epoch: 6| Step: 7
Training loss: 0.18183445930480957
Validation loss: 1.5910848725226618

Epoch: 6| Step: 8
Training loss: 0.11339856684207916
Validation loss: 1.6044840812683105

Epoch: 6| Step: 9
Training loss: 0.09716883301734924
Validation loss: 1.5699088560637606

Epoch: 6| Step: 10
Training loss: 0.2980513870716095
Validation loss: 1.598913961841214

Epoch: 6| Step: 11
Training loss: 0.1131843850016594
Validation loss: 1.5784091212416207

Epoch: 6| Step: 12
Training loss: 0.14808961749076843
Validation loss: 1.5402656447502874

Epoch: 6| Step: 13
Training loss: 0.18739169836044312
Validation loss: 1.5456143873994068

Epoch: 371| Step: 0
Training loss: 0.22181200981140137
Validation loss: 1.5388221535631406

Epoch: 6| Step: 1
Training loss: 0.15842048823833466
Validation loss: 1.532318066525203

Epoch: 6| Step: 2
Training loss: 0.1179884597659111
Validation loss: 1.5228676001230876

Epoch: 6| Step: 3
Training loss: 0.1357470005750656
Validation loss: 1.5370989050916446

Epoch: 6| Step: 4
Training loss: 0.0861867219209671
Validation loss: 1.5330245571751748

Epoch: 6| Step: 5
Training loss: 0.09708011150360107
Validation loss: 1.5686849586425289

Epoch: 6| Step: 6
Training loss: 0.27237650752067566
Validation loss: 1.6048679300533828

Epoch: 6| Step: 7
Training loss: 0.19090266525745392
Validation loss: 1.6294375645217074

Epoch: 6| Step: 8
Training loss: 0.11556506156921387
Validation loss: 1.6383986319265058

Epoch: 6| Step: 9
Training loss: 0.1079980880022049
Validation loss: 1.6506395673239103

Epoch: 6| Step: 10
Training loss: 0.23358365893363953
Validation loss: 1.6529333322278914

Epoch: 6| Step: 11
Training loss: 0.19981986284255981
Validation loss: 1.6428082809653333

Epoch: 6| Step: 12
Training loss: 0.11915849149227142
Validation loss: 1.6441619626937374

Epoch: 6| Step: 13
Training loss: 0.13878165185451508
Validation loss: 1.6162431714355305

Epoch: 372| Step: 0
Training loss: 0.11863400042057037
Validation loss: 1.620119669104135

Epoch: 6| Step: 1
Training loss: 0.22900786995887756
Validation loss: 1.5747567722874303

Epoch: 6| Step: 2
Training loss: 0.11706390976905823
Validation loss: 1.6069376507113058

Epoch: 6| Step: 3
Training loss: 0.18630078434944153
Validation loss: 1.6207527986136816

Epoch: 6| Step: 4
Training loss: 0.20851173996925354
Validation loss: 1.6103913245662567

Epoch: 6| Step: 5
Training loss: 0.17375591397285461
Validation loss: 1.5959513533499934

Epoch: 6| Step: 6
Training loss: 0.15652421116828918
Validation loss: 1.5961788905564176

Epoch: 6| Step: 7
Training loss: 0.13376332819461823
Validation loss: 1.5862763299736926

Epoch: 6| Step: 8
Training loss: 0.10294137895107269
Validation loss: 1.5947454693496868

Epoch: 6| Step: 9
Training loss: 0.17729079723358154
Validation loss: 1.5937297113480107

Epoch: 6| Step: 10
Training loss: 0.15320684015750885
Validation loss: 1.5738946673690632

Epoch: 6| Step: 11
Training loss: 0.26066216826438904
Validation loss: 1.5855530256866126

Epoch: 6| Step: 12
Training loss: 0.16551510989665985
Validation loss: 1.6259738001772153

Epoch: 6| Step: 13
Training loss: 0.2730189561843872
Validation loss: 1.6224200264100106

Epoch: 373| Step: 0
Training loss: 0.15769106149673462
Validation loss: 1.6200914190661522

Epoch: 6| Step: 1
Training loss: 0.1224445253610611
Validation loss: 1.598446101270696

Epoch: 6| Step: 2
Training loss: 0.10435998439788818
Validation loss: 1.5741461220607962

Epoch: 6| Step: 3
Training loss: 0.24618680775165558
Validation loss: 1.5704888541211364

Epoch: 6| Step: 4
Training loss: 0.21561020612716675
Validation loss: 1.5533282449168544

Epoch: 6| Step: 5
Training loss: 0.14429740607738495
Validation loss: 1.5537872852817658

Epoch: 6| Step: 6
Training loss: 0.11169880628585815
Validation loss: 1.5525015772029918

Epoch: 6| Step: 7
Training loss: 0.10844539105892181
Validation loss: 1.5456634426629672

Epoch: 6| Step: 8
Training loss: 0.16864952445030212
Validation loss: 1.5011300681739725

Epoch: 6| Step: 9
Training loss: 0.15032067894935608
Validation loss: 1.5445516494012648

Epoch: 6| Step: 10
Training loss: 0.2475486695766449
Validation loss: 1.5725065597923853

Epoch: 6| Step: 11
Training loss: 0.12741172313690186
Validation loss: 1.5759316695633756

Epoch: 6| Step: 12
Training loss: 0.14807400107383728
Validation loss: 1.576946904582362

Epoch: 6| Step: 13
Training loss: 0.1195928230881691
Validation loss: 1.5670000430076354

Epoch: 374| Step: 0
Training loss: 0.19837333261966705
Validation loss: 1.5648751156304472

Epoch: 6| Step: 1
Training loss: 0.09199538826942444
Validation loss: 1.5559574032342562

Epoch: 6| Step: 2
Training loss: 0.11489677429199219
Validation loss: 1.5890940645689606

Epoch: 6| Step: 3
Training loss: 0.11244793236255646
Validation loss: 1.558426974922098

Epoch: 6| Step: 4
Training loss: 0.25825563073158264
Validation loss: 1.571261966100303

Epoch: 6| Step: 5
Training loss: 0.1699257642030716
Validation loss: 1.5738940546589513

Epoch: 6| Step: 6
Training loss: 0.3610175848007202
Validation loss: 1.555132367277658

Epoch: 6| Step: 7
Training loss: 0.18145091831684113
Validation loss: 1.5729482737920617

Epoch: 6| Step: 8
Training loss: 0.162188321352005
Validation loss: 1.518795891474652

Epoch: 6| Step: 9
Training loss: 0.15559282898902893
Validation loss: 1.5336670055184314

Epoch: 6| Step: 10
Training loss: 0.13318803906440735
Validation loss: 1.5387430652495353

Epoch: 6| Step: 11
Training loss: 0.09227868914604187
Validation loss: 1.5354803146854523

Epoch: 6| Step: 12
Training loss: 0.1913762092590332
Validation loss: 1.5155719467388686

Epoch: 6| Step: 13
Training loss: 0.20091348886489868
Validation loss: 1.5237975581999748

Epoch: 375| Step: 0
Training loss: 0.12268901616334915
Validation loss: 1.5391299186214324

Epoch: 6| Step: 1
Training loss: 0.08050920069217682
Validation loss: 1.5460073358269149

Epoch: 6| Step: 2
Training loss: 0.1644880771636963
Validation loss: 1.541844734581568

Epoch: 6| Step: 3
Training loss: 0.2078445553779602
Validation loss: 1.5611733287893317

Epoch: 6| Step: 4
Training loss: 0.21236976981163025
Validation loss: 1.5966050317210536

Epoch: 6| Step: 5
Training loss: 0.18608629703521729
Validation loss: 1.5677823840930898

Epoch: 6| Step: 6
Training loss: 0.09263548254966736
Validation loss: 1.5255022612951135

Epoch: 6| Step: 7
Training loss: 0.11481070518493652
Validation loss: 1.5544779544235559

Epoch: 6| Step: 8
Training loss: 0.11772679537534714
Validation loss: 1.5454404046458583

Epoch: 6| Step: 9
Training loss: 0.14789995551109314
Validation loss: 1.5401411005245742

Epoch: 6| Step: 10
Training loss: 0.1375165432691574
Validation loss: 1.5412628573756064

Epoch: 6| Step: 11
Training loss: 0.29661571979522705
Validation loss: 1.5727551470520675

Epoch: 6| Step: 12
Training loss: 0.11276185512542725
Validation loss: 1.5664330784992506

Epoch: 6| Step: 13
Training loss: 0.1298190951347351
Validation loss: 1.559597856254988

Epoch: 376| Step: 0
Training loss: 0.13612300157546997
Validation loss: 1.571002019989875

Epoch: 6| Step: 1
Training loss: 0.26820695400238037
Validation loss: 1.575265569071616

Epoch: 6| Step: 2
Training loss: 0.11560618132352829
Validation loss: 1.5847053938014533

Epoch: 6| Step: 3
Training loss: 0.15628807246685028
Validation loss: 1.540166481848686

Epoch: 6| Step: 4
Training loss: 0.12148430943489075
Validation loss: 1.5543286383792918

Epoch: 6| Step: 5
Training loss: 0.2625882625579834
Validation loss: 1.5536808736862675

Epoch: 6| Step: 6
Training loss: 0.18133044242858887
Validation loss: 1.5438158166023992

Epoch: 6| Step: 7
Training loss: 0.1317710131406784
Validation loss: 1.5187117950890654

Epoch: 6| Step: 8
Training loss: 0.23366868495941162
Validation loss: 1.5028915072000155

Epoch: 6| Step: 9
Training loss: 0.20219500362873077
Validation loss: 1.4981245661294589

Epoch: 6| Step: 10
Training loss: 0.15334269404411316
Validation loss: 1.5186582521725727

Epoch: 6| Step: 11
Training loss: 0.18801604211330414
Validation loss: 1.5196566773999123

Epoch: 6| Step: 12
Training loss: 0.16976287961006165
Validation loss: 1.530583470098434

Epoch: 6| Step: 13
Training loss: 0.129629984498024
Validation loss: 1.5327096062321817

Epoch: 377| Step: 0
Training loss: 0.1832151561975479
Validation loss: 1.5587470710918467

Epoch: 6| Step: 1
Training loss: 0.1417405754327774
Validation loss: 1.5443715869739492

Epoch: 6| Step: 2
Training loss: 0.10548922419548035
Validation loss: 1.5695525548791374

Epoch: 6| Step: 3
Training loss: 0.15565818548202515
Validation loss: 1.5765462947148148

Epoch: 6| Step: 4
Training loss: 0.16869807243347168
Validation loss: 1.5757598710316483

Epoch: 6| Step: 5
Training loss: 0.17622853815555573
Validation loss: 1.603001158724549

Epoch: 6| Step: 6
Training loss: 0.286064088344574
Validation loss: 1.58665717417194

Epoch: 6| Step: 7
Training loss: 0.11917804926633835
Validation loss: 1.5922759495755678

Epoch: 6| Step: 8
Training loss: 0.11703360080718994
Validation loss: 1.558149932533182

Epoch: 6| Step: 9
Training loss: 0.21404168009757996
Validation loss: 1.5098310862818072

Epoch: 6| Step: 10
Training loss: 0.13357320427894592
Validation loss: 1.520747979482015

Epoch: 6| Step: 11
Training loss: 0.14932812750339508
Validation loss: 1.4917779789176038

Epoch: 6| Step: 12
Training loss: 0.12930996716022491
Validation loss: 1.4922003098713454

Epoch: 6| Step: 13
Training loss: 0.06147473305463791
Validation loss: 1.465606939408087

Epoch: 378| Step: 0
Training loss: 0.1214657798409462
Validation loss: 1.4937145094717703

Epoch: 6| Step: 1
Training loss: 0.1637851595878601
Validation loss: 1.5301357501296586

Epoch: 6| Step: 2
Training loss: 0.20787391066551208
Validation loss: 1.5141906610099218

Epoch: 6| Step: 3
Training loss: 0.1053399071097374
Validation loss: 1.5526310859187957

Epoch: 6| Step: 4
Training loss: 0.16100049018859863
Validation loss: 1.575144197351189

Epoch: 6| Step: 5
Training loss: 0.12765517830848694
Validation loss: 1.5865247339330695

Epoch: 6| Step: 6
Training loss: 0.17102664709091187
Validation loss: 1.569755006861943

Epoch: 6| Step: 7
Training loss: 0.13936206698417664
Validation loss: 1.5663620156626548

Epoch: 6| Step: 8
Training loss: 0.07597310841083527
Validation loss: 1.5769869153217604

Epoch: 6| Step: 9
Training loss: 0.22855761647224426
Validation loss: 1.5459779436870287

Epoch: 6| Step: 10
Training loss: 0.10800331830978394
Validation loss: 1.584375851897783

Epoch: 6| Step: 11
Training loss: 0.07832139730453491
Validation loss: 1.5398964189714002

Epoch: 6| Step: 12
Training loss: 0.13320350646972656
Validation loss: 1.5415803181227816

Epoch: 6| Step: 13
Training loss: 0.1367151439189911
Validation loss: 1.5203852160002596

Epoch: 379| Step: 0
Training loss: 0.1373264491558075
Validation loss: 1.511515704534387

Epoch: 6| Step: 1
Training loss: 0.15608364343643188
Validation loss: 1.5025113500574583

Epoch: 6| Step: 2
Training loss: 0.14292758703231812
Validation loss: 1.5196019526450866

Epoch: 6| Step: 3
Training loss: 0.10119957476854324
Validation loss: 1.4810652457257754

Epoch: 6| Step: 4
Training loss: 0.1663718819618225
Validation loss: 1.4974166859862625

Epoch: 6| Step: 5
Training loss: 0.20297355949878693
Validation loss: 1.5281992625164729

Epoch: 6| Step: 6
Training loss: 0.08042741566896439
Validation loss: 1.520348310470581

Epoch: 6| Step: 7
Training loss: 0.19263271987438202
Validation loss: 1.5253567605890253

Epoch: 6| Step: 8
Training loss: 0.1611931025981903
Validation loss: 1.5464418062599756

Epoch: 6| Step: 9
Training loss: 0.0885043740272522
Validation loss: 1.5629252669631795

Epoch: 6| Step: 10
Training loss: 0.12145058810710907
Validation loss: 1.55611462490533

Epoch: 6| Step: 11
Training loss: 0.13602516055107117
Validation loss: 1.5845177955524896

Epoch: 6| Step: 12
Training loss: 0.14940112829208374
Validation loss: 1.5820739391029521

Epoch: 6| Step: 13
Training loss: 0.17267031967639923
Validation loss: 1.5645567370999245

Epoch: 380| Step: 0
Training loss: 0.26139187812805176
Validation loss: 1.5971373447807886

Epoch: 6| Step: 1
Training loss: 0.10327181220054626
Validation loss: 1.603478523992723

Epoch: 6| Step: 2
Training loss: 0.16744846105575562
Validation loss: 1.5701908590973064

Epoch: 6| Step: 3
Training loss: 0.1145738959312439
Validation loss: 1.5537138959412933

Epoch: 6| Step: 4
Training loss: 0.2163415551185608
Validation loss: 1.5337802504980436

Epoch: 6| Step: 5
Training loss: 0.08980564773082733
Validation loss: 1.5551196618746685

Epoch: 6| Step: 6
Training loss: 0.18217793107032776
Validation loss: 1.5709349301553541

Epoch: 6| Step: 7
Training loss: 0.13369712233543396
Validation loss: 1.5459334260673934

Epoch: 6| Step: 8
Training loss: 0.14102159440517426
Validation loss: 1.5280256912272463

Epoch: 6| Step: 9
Training loss: 0.0640876442193985
Validation loss: 1.5147740930639289

Epoch: 6| Step: 10
Training loss: 0.10327640920877457
Validation loss: 1.5076447161295081

Epoch: 6| Step: 11
Training loss: 0.19167810678482056
Validation loss: 1.5144962764555407

Epoch: 6| Step: 12
Training loss: 0.14139342308044434
Validation loss: 1.5047660745600218

Epoch: 6| Step: 13
Training loss: 0.08509746938943863
Validation loss: 1.5380277120938866

Epoch: 381| Step: 0
Training loss: 0.3660379648208618
Validation loss: 1.5571437381928968

Epoch: 6| Step: 1
Training loss: 0.10522742569446564
Validation loss: 1.5748664903384384

Epoch: 6| Step: 2
Training loss: 0.25181588530540466
Validation loss: 1.6018085761736798

Epoch: 6| Step: 3
Training loss: 0.10266993939876556
Validation loss: 1.5950699019175705

Epoch: 6| Step: 4
Training loss: 0.1775369644165039
Validation loss: 1.612102953336572

Epoch: 6| Step: 5
Training loss: 0.1423337459564209
Validation loss: 1.604319554503246

Epoch: 6| Step: 6
Training loss: 0.13856258988380432
Validation loss: 1.6363974348191292

Epoch: 6| Step: 7
Training loss: 0.1750861406326294
Validation loss: 1.6136119186237294

Epoch: 6| Step: 8
Training loss: 0.08438310027122498
Validation loss: 1.6153730628310994

Epoch: 6| Step: 9
Training loss: 0.08192387223243713
Validation loss: 1.6242262983834872

Epoch: 6| Step: 10
Training loss: 0.22359858453273773
Validation loss: 1.6042243844719344

Epoch: 6| Step: 11
Training loss: 0.06787911057472229
Validation loss: 1.5664588892331688

Epoch: 6| Step: 12
Training loss: 0.14894378185272217
Validation loss: 1.5893825548951344

Epoch: 6| Step: 13
Training loss: 0.09763321280479431
Validation loss: 1.5492042046721264

Epoch: 382| Step: 0
Training loss: 0.09081115573644638
Validation loss: 1.557238931296974

Epoch: 6| Step: 1
Training loss: 0.18056637048721313
Validation loss: 1.5439130772826493

Epoch: 6| Step: 2
Training loss: 0.2645670473575592
Validation loss: 1.567465655265316

Epoch: 6| Step: 3
Training loss: 0.12920598685741425
Validation loss: 1.5781722043150215

Epoch: 6| Step: 4
Training loss: 0.10414137691259384
Validation loss: 1.5969215682757798

Epoch: 6| Step: 5
Training loss: 0.13937170803546906
Validation loss: 1.6256948901760964

Epoch: 6| Step: 6
Training loss: 0.1560356467962265
Validation loss: 1.6244238640672417

Epoch: 6| Step: 7
Training loss: 0.23136499524116516
Validation loss: 1.6112145236743394

Epoch: 6| Step: 8
Training loss: 0.10420779138803482
Validation loss: 1.5895140017232587

Epoch: 6| Step: 9
Training loss: 0.10553579032421112
Validation loss: 1.5988878562886228

Epoch: 6| Step: 10
Training loss: 0.11181165277957916
Validation loss: 1.583093084314818

Epoch: 6| Step: 11
Training loss: 0.09196010231971741
Validation loss: 1.5885845563744987

Epoch: 6| Step: 12
Training loss: 0.12241293489933014
Validation loss: 1.5793251856680839

Epoch: 6| Step: 13
Training loss: 0.04373103752732277
Validation loss: 1.5612563651095155

Epoch: 383| Step: 0
Training loss: 0.15454284846782684
Validation loss: 1.5520668619422502

Epoch: 6| Step: 1
Training loss: 0.17486560344696045
Validation loss: 1.546795554058526

Epoch: 6| Step: 2
Training loss: 0.1573067009449005
Validation loss: 1.5405553771603493

Epoch: 6| Step: 3
Training loss: 0.187635600566864
Validation loss: 1.526973086018716

Epoch: 6| Step: 4
Training loss: 0.15597638487815857
Validation loss: 1.5192704508381505

Epoch: 6| Step: 5
Training loss: 0.11992959678173065
Validation loss: 1.5369236571814424

Epoch: 6| Step: 6
Training loss: 0.136548712849617
Validation loss: 1.4892002164676625

Epoch: 6| Step: 7
Training loss: 0.14939650893211365
Validation loss: 1.561376739573735

Epoch: 6| Step: 8
Training loss: 0.10423915088176727
Validation loss: 1.567568063735962

Epoch: 6| Step: 9
Training loss: 0.09648315608501434
Validation loss: 1.5564146221324962

Epoch: 6| Step: 10
Training loss: 0.156332865357399
Validation loss: 1.5443406797224475

Epoch: 6| Step: 11
Training loss: 0.1357896625995636
Validation loss: 1.5627955916107341

Epoch: 6| Step: 12
Training loss: 0.11458675563335419
Validation loss: 1.5639042021125875

Epoch: 6| Step: 13
Training loss: 0.3221132755279541
Validation loss: 1.5519634728790612

Epoch: 384| Step: 0
Training loss: 0.17995893955230713
Validation loss: 1.5485963359955819

Epoch: 6| Step: 1
Training loss: 0.12417478859424591
Validation loss: 1.536472705102736

Epoch: 6| Step: 2
Training loss: 0.10276460647583008
Validation loss: 1.536393868025913

Epoch: 6| Step: 3
Training loss: 0.12649822235107422
Validation loss: 1.525321896358203

Epoch: 6| Step: 4
Training loss: 0.10355517268180847
Validation loss: 1.5578572557818504

Epoch: 6| Step: 5
Training loss: 0.19341027736663818
Validation loss: 1.5533921436596942

Epoch: 6| Step: 6
Training loss: 0.15125831961631775
Validation loss: 1.5711833712875203

Epoch: 6| Step: 7
Training loss: 0.11181871592998505
Validation loss: 1.5710772070833432

Epoch: 6| Step: 8
Training loss: 0.15968897938728333
Validation loss: 1.5593931303229382

Epoch: 6| Step: 9
Training loss: 0.0910317450761795
Validation loss: 1.534806627099232

Epoch: 6| Step: 10
Training loss: 0.12541280686855316
Validation loss: 1.5322719068937405

Epoch: 6| Step: 11
Training loss: 0.2972010374069214
Validation loss: 1.5441766477400256

Epoch: 6| Step: 12
Training loss: 0.1627979278564453
Validation loss: 1.5416370194445375

Epoch: 6| Step: 13
Training loss: 0.05960872396826744
Validation loss: 1.5517317005383071

Epoch: 385| Step: 0
Training loss: 0.09434668719768524
Validation loss: 1.5127726703561761

Epoch: 6| Step: 1
Training loss: 0.09236640483140945
Validation loss: 1.5608923435211182

Epoch: 6| Step: 2
Training loss: 0.07738472521305084
Validation loss: 1.5316669261583717

Epoch: 6| Step: 3
Training loss: 0.27160483598709106
Validation loss: 1.5547472943541825

Epoch: 6| Step: 4
Training loss: 0.12393909692764282
Validation loss: 1.5540505045203752

Epoch: 6| Step: 5
Training loss: 0.07840738445520401
Validation loss: 1.563508738112706

Epoch: 6| Step: 6
Training loss: 0.14429274201393127
Validation loss: 1.5812248055652907

Epoch: 6| Step: 7
Training loss: 0.12334713339805603
Validation loss: 1.579949022621237

Epoch: 6| Step: 8
Training loss: 0.12009761482477188
Validation loss: 1.5841770787392893

Epoch: 6| Step: 9
Training loss: 0.13768991827964783
Validation loss: 1.5878892316613147

Epoch: 6| Step: 10
Training loss: 0.17361631989479065
Validation loss: 1.5863176353516117

Epoch: 6| Step: 11
Training loss: 0.12004456669092178
Validation loss: 1.595686751027261

Epoch: 6| Step: 12
Training loss: 0.14124010503292084
Validation loss: 1.5914517294976018

Epoch: 6| Step: 13
Training loss: 0.2399343103170395
Validation loss: 1.626070826284347

Epoch: 386| Step: 0
Training loss: 0.09076111763715744
Validation loss: 1.611489983015163

Epoch: 6| Step: 1
Training loss: 0.12809261679649353
Validation loss: 1.6277393384646344

Epoch: 6| Step: 2
Training loss: 0.16091668605804443
Validation loss: 1.6316507734278196

Epoch: 6| Step: 3
Training loss: 0.13805055618286133
Validation loss: 1.6338574373593895

Epoch: 6| Step: 4
Training loss: 0.10335700213909149
Validation loss: 1.614083246518207

Epoch: 6| Step: 5
Training loss: 0.12194637954235077
Validation loss: 1.6046358180302445

Epoch: 6| Step: 6
Training loss: 0.10253651440143585
Validation loss: 1.6221893641256517

Epoch: 6| Step: 7
Training loss: 0.11961160600185394
Validation loss: 1.6092106584579713

Epoch: 6| Step: 8
Training loss: 0.07702549546957016
Validation loss: 1.583954063794946

Epoch: 6| Step: 9
Training loss: 0.11582408100366592
Validation loss: 1.5445845486015402

Epoch: 6| Step: 10
Training loss: 0.13698124885559082
Validation loss: 1.5348779539908133

Epoch: 6| Step: 11
Training loss: 0.30949684977531433
Validation loss: 1.505316570240964

Epoch: 6| Step: 12
Training loss: 0.14332401752471924
Validation loss: 1.510825954457765

Epoch: 6| Step: 13
Training loss: 0.19792839884757996
Validation loss: 1.4862897703724522

Epoch: 387| Step: 0
Training loss: 0.11807189136743546
Validation loss: 1.4775145899864934

Epoch: 6| Step: 1
Training loss: 0.1634281724691391
Validation loss: 1.4807290159245974

Epoch: 6| Step: 2
Training loss: 0.11684738099575043
Validation loss: 1.4856528928202968

Epoch: 6| Step: 3
Training loss: 0.18883433938026428
Validation loss: 1.4723412708569599

Epoch: 6| Step: 4
Training loss: 0.15085972845554352
Validation loss: 1.5378723272713282

Epoch: 6| Step: 5
Training loss: 0.1782563030719757
Validation loss: 1.5072885162086898

Epoch: 6| Step: 6
Training loss: 0.1120801717042923
Validation loss: 1.5490015200389329

Epoch: 6| Step: 7
Training loss: 0.1339195966720581
Validation loss: 1.5598177371486541

Epoch: 6| Step: 8
Training loss: 0.2997514605522156
Validation loss: 1.5541479908010012

Epoch: 6| Step: 9
Training loss: 0.11345250904560089
Validation loss: 1.5821929003602715

Epoch: 6| Step: 10
Training loss: 0.12416362762451172
Validation loss: 1.5995201564604236

Epoch: 6| Step: 11
Training loss: 0.14459791779518127
Validation loss: 1.5713433668177614

Epoch: 6| Step: 12
Training loss: 0.15454241633415222
Validation loss: 1.5990726178692234

Epoch: 6| Step: 13
Training loss: 0.16337867081165314
Validation loss: 1.5635808488374114

Epoch: 388| Step: 0
Training loss: 0.14220134913921356
Validation loss: 1.53974631140309

Epoch: 6| Step: 1
Training loss: 0.11186272650957108
Validation loss: 1.5086119585139777

Epoch: 6| Step: 2
Training loss: 0.1377735435962677
Validation loss: 1.4861316809090235

Epoch: 6| Step: 3
Training loss: 0.13244016468524933
Validation loss: 1.4817900311562322

Epoch: 6| Step: 4
Training loss: 0.19794347882270813
Validation loss: 1.486919447939883

Epoch: 6| Step: 5
Training loss: 0.19763578474521637
Validation loss: 1.4806016593851068

Epoch: 6| Step: 6
Training loss: 0.26619330048561096
Validation loss: 1.488658091073395

Epoch: 6| Step: 7
Training loss: 0.26239457726478577
Validation loss: 1.4676403358418455

Epoch: 6| Step: 8
Training loss: 0.1295965611934662
Validation loss: 1.5035353347819338

Epoch: 6| Step: 9
Training loss: 0.14703978598117828
Validation loss: 1.566199234736863

Epoch: 6| Step: 10
Training loss: 0.1464250087738037
Validation loss: 1.5618165103338097

Epoch: 6| Step: 11
Training loss: 0.08863639831542969
Validation loss: 1.5683120322483841

Epoch: 6| Step: 12
Training loss: 0.12839411199092865
Validation loss: 1.5805431040384437

Epoch: 6| Step: 13
Training loss: 0.24717766046524048
Validation loss: 1.6170723771536222

Epoch: 389| Step: 0
Training loss: 0.16184505820274353
Validation loss: 1.6388354083543182

Epoch: 6| Step: 1
Training loss: 0.3158184885978699
Validation loss: 1.6300081386361072

Epoch: 6| Step: 2
Training loss: 0.17496800422668457
Validation loss: 1.6198469836224791

Epoch: 6| Step: 3
Training loss: 0.17285895347595215
Validation loss: 1.5794259104677426

Epoch: 6| Step: 4
Training loss: 0.1312400996685028
Validation loss: 1.5522153518533195

Epoch: 6| Step: 5
Training loss: 0.11096488684415817
Validation loss: 1.546202451952042

Epoch: 6| Step: 6
Training loss: 0.1026645079255104
Validation loss: 1.5232494761866908

Epoch: 6| Step: 7
Training loss: 0.23622268438339233
Validation loss: 1.5163878112710931

Epoch: 6| Step: 8
Training loss: 0.2814023494720459
Validation loss: 1.4806644967807236

Epoch: 6| Step: 9
Training loss: 0.17286531627178192
Validation loss: 1.4920155188088775

Epoch: 6| Step: 10
Training loss: 0.14003339409828186
Validation loss: 1.4943727652231853

Epoch: 6| Step: 11
Training loss: 0.13744404911994934
Validation loss: 1.4809436721186484

Epoch: 6| Step: 12
Training loss: 0.11874648183584213
Validation loss: 1.4910110901760798

Epoch: 6| Step: 13
Training loss: 0.11257951706647873
Validation loss: 1.4972988995172645

Epoch: 390| Step: 0
Training loss: 0.10624907165765762
Validation loss: 1.478578294477155

Epoch: 6| Step: 1
Training loss: 0.15576794743537903
Validation loss: 1.4923109521148026

Epoch: 6| Step: 2
Training loss: 0.08340224623680115
Validation loss: 1.5065415251639582

Epoch: 6| Step: 3
Training loss: 0.18065977096557617
Validation loss: 1.5016160408655803

Epoch: 6| Step: 4
Training loss: 0.12368915230035782
Validation loss: 1.4910920063654582

Epoch: 6| Step: 5
Training loss: 0.11181898415088654
Validation loss: 1.47884920079221

Epoch: 6| Step: 6
Training loss: 0.16966748237609863
Validation loss: 1.4592596894951277

Epoch: 6| Step: 7
Training loss: 0.15654857456684113
Validation loss: 1.4832493515424832

Epoch: 6| Step: 8
Training loss: 0.2017119824886322
Validation loss: 1.468405996599505

Epoch: 6| Step: 9
Training loss: 0.0736895501613617
Validation loss: 1.4839017750114523

Epoch: 6| Step: 10
Training loss: 0.27618640661239624
Validation loss: 1.478403865650136

Epoch: 6| Step: 11
Training loss: 0.1506614238023758
Validation loss: 1.466525557220623

Epoch: 6| Step: 12
Training loss: 0.1477642059326172
Validation loss: 1.5017256800846388

Epoch: 6| Step: 13
Training loss: 0.05018634349107742
Validation loss: 1.5011277147518691

Epoch: 391| Step: 0
Training loss: 0.12898439168930054
Validation loss: 1.5153859635835052

Epoch: 6| Step: 1
Training loss: 0.14080080389976501
Validation loss: 1.516826278419905

Epoch: 6| Step: 2
Training loss: 0.09029220789670944
Validation loss: 1.5570948437977863

Epoch: 6| Step: 3
Training loss: 0.13245634734630585
Validation loss: 1.5338531976105065

Epoch: 6| Step: 4
Training loss: 0.09433872252702713
Validation loss: 1.5467802811694402

Epoch: 6| Step: 5
Training loss: 0.11278366297483444
Validation loss: 1.526598632976573

Epoch: 6| Step: 6
Training loss: 0.13073430955410004
Validation loss: 1.5463828566253826

Epoch: 6| Step: 7
Training loss: 0.12036862224340439
Validation loss: 1.5388653714169738

Epoch: 6| Step: 8
Training loss: 0.2745679020881653
Validation loss: 1.5646801443510159

Epoch: 6| Step: 9
Training loss: 0.1772853583097458
Validation loss: 1.5512882099356702

Epoch: 6| Step: 10
Training loss: 0.13201269507408142
Validation loss: 1.565545561493084

Epoch: 6| Step: 11
Training loss: 0.17017117142677307
Validation loss: 1.5512465603889958

Epoch: 6| Step: 12
Training loss: 0.10913226008415222
Validation loss: 1.5750585115084084

Epoch: 6| Step: 13
Training loss: 0.09431933611631393
Validation loss: 1.5625877508553125

Epoch: 392| Step: 0
Training loss: 0.16360104084014893
Validation loss: 1.5615288762636081

Epoch: 6| Step: 1
Training loss: 0.21330119669437408
Validation loss: 1.5541356366167787

Epoch: 6| Step: 2
Training loss: 0.11647684127092361
Validation loss: 1.5585184533108947

Epoch: 6| Step: 3
Training loss: 0.12297610193490982
Validation loss: 1.57322907704179

Epoch: 6| Step: 4
Training loss: 0.09183736145496368
Validation loss: 1.5928157503886888

Epoch: 6| Step: 5
Training loss: 0.1645900011062622
Validation loss: 1.5386649690648562

Epoch: 6| Step: 6
Training loss: 0.14396452903747559
Validation loss: 1.5075886941725207

Epoch: 6| Step: 7
Training loss: 0.09289874881505966
Validation loss: 1.5238841695170249

Epoch: 6| Step: 8
Training loss: 0.11592336744070053
Validation loss: 1.5202069385077364

Epoch: 6| Step: 9
Training loss: 0.19756387174129486
Validation loss: 1.5381734653185772

Epoch: 6| Step: 10
Training loss: 0.10869067907333374
Validation loss: 1.5069653154701315

Epoch: 6| Step: 11
Training loss: 0.14576730132102966
Validation loss: 1.5292868921833653

Epoch: 6| Step: 12
Training loss: 0.098039411008358
Validation loss: 1.5220124933027452

Epoch: 6| Step: 13
Training loss: 0.15956297516822815
Validation loss: 1.5112938932193223

Epoch: 393| Step: 0
Training loss: 0.0869818702340126
Validation loss: 1.5453253356359338

Epoch: 6| Step: 1
Training loss: 0.14602364599704742
Validation loss: 1.5142974763788202

Epoch: 6| Step: 2
Training loss: 0.08000105619430542
Validation loss: 1.5487982214138072

Epoch: 6| Step: 3
Training loss: 0.08696556091308594
Validation loss: 1.5463794508287985

Epoch: 6| Step: 4
Training loss: 0.21957626938819885
Validation loss: 1.5356217327938284

Epoch: 6| Step: 5
Training loss: 0.21539723873138428
Validation loss: 1.5176233027570991

Epoch: 6| Step: 6
Training loss: 0.11006955057382584
Validation loss: 1.5172333076436033

Epoch: 6| Step: 7
Training loss: 0.1095961406826973
Validation loss: 1.5198914120274205

Epoch: 6| Step: 8
Training loss: 0.1676967591047287
Validation loss: 1.5161613046482045

Epoch: 6| Step: 9
Training loss: 0.14375142753124237
Validation loss: 1.524677272765867

Epoch: 6| Step: 10
Training loss: 0.1344400942325592
Validation loss: 1.549366371605986

Epoch: 6| Step: 11
Training loss: 0.08770432323217392
Validation loss: 1.5202440331059117

Epoch: 6| Step: 12
Training loss: 0.09182162582874298
Validation loss: 1.542735033137824

Epoch: 6| Step: 13
Training loss: 0.09491048008203506
Validation loss: 1.5510014744215115

Epoch: 394| Step: 0
Training loss: 0.17496749758720398
Validation loss: 1.5692487916638773

Epoch: 6| Step: 1
Training loss: 0.16704072058200836
Validation loss: 1.5812907456069865

Epoch: 6| Step: 2
Training loss: 0.07026562839746475
Validation loss: 1.595293532135666

Epoch: 6| Step: 3
Training loss: 0.1492919623851776
Validation loss: 1.5649724186107676

Epoch: 6| Step: 4
Training loss: 0.13611188530921936
Validation loss: 1.5798086556055213

Epoch: 6| Step: 5
Training loss: 0.12103186547756195
Validation loss: 1.526536718491585

Epoch: 6| Step: 6
Training loss: 0.08989467471837997
Validation loss: 1.540384595112134

Epoch: 6| Step: 7
Training loss: 0.21487946808338165
Validation loss: 1.5409994561185119

Epoch: 6| Step: 8
Training loss: 0.20329250395298004
Validation loss: 1.5294503832376132

Epoch: 6| Step: 9
Training loss: 0.16598543524742126
Validation loss: 1.490176119471109

Epoch: 6| Step: 10
Training loss: 0.11096644401550293
Validation loss: 1.5070958137512207

Epoch: 6| Step: 11
Training loss: 0.1748049259185791
Validation loss: 1.5238416944780657

Epoch: 6| Step: 12
Training loss: 0.10634234547615051
Validation loss: 1.508253840989964

Epoch: 6| Step: 13
Training loss: 0.12477003037929535
Validation loss: 1.5295765784478956

Epoch: 395| Step: 0
Training loss: 0.09859028458595276
Validation loss: 1.5001292318426154

Epoch: 6| Step: 1
Training loss: 0.11677487194538116
Validation loss: 1.5102770789977042

Epoch: 6| Step: 2
Training loss: 0.12902992963790894
Validation loss: 1.502137606502861

Epoch: 6| Step: 3
Training loss: 0.1650351732969284
Validation loss: 1.5145076961927517

Epoch: 6| Step: 4
Training loss: 0.19803094863891602
Validation loss: 1.5324905777490267

Epoch: 6| Step: 5
Training loss: 0.20239409804344177
Validation loss: 1.5295879366577312

Epoch: 6| Step: 6
Training loss: 0.0999092385172844
Validation loss: 1.5122448910949051

Epoch: 6| Step: 7
Training loss: 0.1673067808151245
Validation loss: 1.5296134538547967

Epoch: 6| Step: 8
Training loss: 0.09727461636066437
Validation loss: 1.528856978621534

Epoch: 6| Step: 9
Training loss: 0.08501255512237549
Validation loss: 1.537631533479178

Epoch: 6| Step: 10
Training loss: 0.14368487894535065
Validation loss: 1.5429213123936807

Epoch: 6| Step: 11
Training loss: 0.10461696982383728
Validation loss: 1.5236278195534982

Epoch: 6| Step: 12
Training loss: 0.22097648680210114
Validation loss: 1.511172011334409

Epoch: 6| Step: 13
Training loss: 0.13721275329589844
Validation loss: 1.4825637699455343

Epoch: 396| Step: 0
Training loss: 0.14555004239082336
Validation loss: 1.5190113103517922

Epoch: 6| Step: 1
Training loss: 0.12534518539905548
Validation loss: 1.497181538612612

Epoch: 6| Step: 2
Training loss: 0.09740692377090454
Validation loss: 1.4959516807269024

Epoch: 6| Step: 3
Training loss: 0.06473182141780853
Validation loss: 1.502043721496418

Epoch: 6| Step: 4
Training loss: 0.17739099264144897
Validation loss: 1.519222737640463

Epoch: 6| Step: 5
Training loss: 0.09047216176986694
Validation loss: 1.5078417652396745

Epoch: 6| Step: 6
Training loss: 0.126177579164505
Validation loss: 1.5151688847490536

Epoch: 6| Step: 7
Training loss: 0.13121461868286133
Validation loss: 1.5070960470425185

Epoch: 6| Step: 8
Training loss: 0.12429752945899963
Validation loss: 1.526558110790868

Epoch: 6| Step: 9
Training loss: 0.12590277194976807
Validation loss: 1.531608449515476

Epoch: 6| Step: 10
Training loss: 0.13180449604988098
Validation loss: 1.5498438317288634

Epoch: 6| Step: 11
Training loss: 0.09644872695207596
Validation loss: 1.52933927248883

Epoch: 6| Step: 12
Training loss: 0.09253562986850739
Validation loss: 1.5467393782831007

Epoch: 6| Step: 13
Training loss: 0.1773916631937027
Validation loss: 1.5710784235308248

Epoch: 397| Step: 0
Training loss: 0.10826712101697922
Validation loss: 1.548298748590613

Epoch: 6| Step: 1
Training loss: 0.0645570456981659
Validation loss: 1.563800847658547

Epoch: 6| Step: 2
Training loss: 0.1705411970615387
Validation loss: 1.571283833954924

Epoch: 6| Step: 3
Training loss: 0.17085020244121552
Validation loss: 1.5979114027433499

Epoch: 6| Step: 4
Training loss: 0.2560637593269348
Validation loss: 1.5828183056205831

Epoch: 6| Step: 5
Training loss: 0.14684133231639862
Validation loss: 1.5911296490700013

Epoch: 6| Step: 6
Training loss: 0.11886487901210785
Validation loss: 1.589836920461347

Epoch: 6| Step: 7
Training loss: 0.1690417230129242
Validation loss: 1.5988151424674577

Epoch: 6| Step: 8
Training loss: 0.0818265900015831
Validation loss: 1.608458270308792

Epoch: 6| Step: 9
Training loss: 0.18951627612113953
Validation loss: 1.619026832683112

Epoch: 6| Step: 10
Training loss: 0.1353549361228943
Validation loss: 1.5962708457823722

Epoch: 6| Step: 11
Training loss: 0.13498982787132263
Validation loss: 1.5334201038524669

Epoch: 6| Step: 12
Training loss: 0.14586561918258667
Validation loss: 1.5210157216236155

Epoch: 6| Step: 13
Training loss: 0.11790083348751068
Validation loss: 1.5151952056474582

Epoch: 398| Step: 0
Training loss: 0.16408264636993408
Validation loss: 1.511360005665851

Epoch: 6| Step: 1
Training loss: 0.177753746509552
Validation loss: 1.542213277150226

Epoch: 6| Step: 2
Training loss: 0.17840862274169922
Validation loss: 1.5376780648385324

Epoch: 6| Step: 3
Training loss: 0.10378796607255936
Validation loss: 1.5357149429218744

Epoch: 6| Step: 4
Training loss: 0.1588052213191986
Validation loss: 1.5377878835124354

Epoch: 6| Step: 5
Training loss: 0.10792103409767151
Validation loss: 1.5488845391940045

Epoch: 6| Step: 6
Training loss: 0.14902767539024353
Validation loss: 1.544231625013454

Epoch: 6| Step: 7
Training loss: 0.09990258514881134
Validation loss: 1.5513512857498661

Epoch: 6| Step: 8
Training loss: 0.11212915182113647
Validation loss: 1.5457721256440686

Epoch: 6| Step: 9
Training loss: 0.20183473825454712
Validation loss: 1.5630102452411447

Epoch: 6| Step: 10
Training loss: 0.13084901869297028
Validation loss: 1.5735769541032854

Epoch: 6| Step: 11
Training loss: 0.13925811648368835
Validation loss: 1.58111725571335

Epoch: 6| Step: 12
Training loss: 0.09981858730316162
Validation loss: 1.5701586193935846

Epoch: 6| Step: 13
Training loss: 0.07004158198833466
Validation loss: 1.592898275262566

Epoch: 399| Step: 0
Training loss: 0.11329246312379837
Validation loss: 1.5986128366121681

Epoch: 6| Step: 1
Training loss: 0.15854209661483765
Validation loss: 1.5901947258621134

Epoch: 6| Step: 2
Training loss: 0.07852091640233994
Validation loss: 1.6165858545610983

Epoch: 6| Step: 3
Training loss: 0.11209508776664734
Validation loss: 1.6025842325661772

Epoch: 6| Step: 4
Training loss: 0.10281822085380554
Validation loss: 1.5798836933669222

Epoch: 6| Step: 5
Training loss: 0.10603064298629761
Validation loss: 1.6105047733552995

Epoch: 6| Step: 6
Training loss: 0.18014124035835266
Validation loss: 1.5812381300874936

Epoch: 6| Step: 7
Training loss: 0.055537328124046326
Validation loss: 1.5998892809755059

Epoch: 6| Step: 8
Training loss: 0.08019963651895523
Validation loss: 1.6269531826819144

Epoch: 6| Step: 9
Training loss: 0.2339760661125183
Validation loss: 1.5905157596834245

Epoch: 6| Step: 10
Training loss: 0.08237500488758087
Validation loss: 1.5888072624001452

Epoch: 6| Step: 11
Training loss: 0.15690220892429352
Validation loss: 1.594994395009933

Epoch: 6| Step: 12
Training loss: 0.11081618070602417
Validation loss: 1.5650506455411193

Epoch: 6| Step: 13
Training loss: 0.06278251856565475
Validation loss: 1.5818319359133322

Epoch: 400| Step: 0
Training loss: 0.10106725990772247
Validation loss: 1.5669271561407274

Epoch: 6| Step: 1
Training loss: 0.09464762359857559
Validation loss: 1.5464820707997968

Epoch: 6| Step: 2
Training loss: 0.1240871325135231
Validation loss: 1.5500829553091398

Epoch: 6| Step: 3
Training loss: 0.08375599980354309
Validation loss: 1.5430846829568186

Epoch: 6| Step: 4
Training loss: 0.11515937745571136
Validation loss: 1.534365520682386

Epoch: 6| Step: 5
Training loss: 0.12892483174800873
Validation loss: 1.5492533112084994

Epoch: 6| Step: 6
Training loss: 0.19191130995750427
Validation loss: 1.5411812445168853

Epoch: 6| Step: 7
Training loss: 0.17839661240577698
Validation loss: 1.5332524699549521

Epoch: 6| Step: 8
Training loss: 0.1078067347407341
Validation loss: 1.568189214634639

Epoch: 6| Step: 9
Training loss: 0.1302071362733841
Validation loss: 1.5596542114852576

Epoch: 6| Step: 10
Training loss: 0.06980754435062408
Validation loss: 1.5291129248116606

Epoch: 6| Step: 11
Training loss: 0.05517607927322388
Validation loss: 1.612556904874822

Epoch: 6| Step: 12
Training loss: 0.062261633574962616
Validation loss: 1.5890916406467397

Epoch: 6| Step: 13
Training loss: 0.11476092785596848
Validation loss: 1.588935516213858

Epoch: 401| Step: 0
Training loss: 0.088840052485466
Validation loss: 1.5793653277940647

Epoch: 6| Step: 1
Training loss: 0.10280253738164902
Validation loss: 1.5618230681265555

Epoch: 6| Step: 2
Training loss: 0.14891815185546875
Validation loss: 1.562271588592119

Epoch: 6| Step: 3
Training loss: 0.12046182155609131
Validation loss: 1.578638566437588

Epoch: 6| Step: 4
Training loss: 0.1737469583749771
Validation loss: 1.5686376633182648

Epoch: 6| Step: 5
Training loss: 0.11369805037975311
Validation loss: 1.5347029957720029

Epoch: 6| Step: 6
Training loss: 0.11459320038557053
Validation loss: 1.5255464251323412

Epoch: 6| Step: 7
Training loss: 0.08861120045185089
Validation loss: 1.5189840806427823

Epoch: 6| Step: 8
Training loss: 0.18206191062927246
Validation loss: 1.5109778424744964

Epoch: 6| Step: 9
Training loss: 0.16240984201431274
Validation loss: 1.5181679341100878

Epoch: 6| Step: 10
Training loss: 0.17913450300693512
Validation loss: 1.5002768385794856

Epoch: 6| Step: 11
Training loss: 0.11405296623706818
Validation loss: 1.5344643682561896

Epoch: 6| Step: 12
Training loss: 0.16476355493068695
Validation loss: 1.5117734289297493

Epoch: 6| Step: 13
Training loss: 0.2794383764266968
Validation loss: 1.516379015420073

Epoch: 402| Step: 0
Training loss: 0.1488419622182846
Validation loss: 1.522168182557629

Epoch: 6| Step: 1
Training loss: 0.07821500301361084
Validation loss: 1.5336413768029982

Epoch: 6| Step: 2
Training loss: 0.10783904790878296
Validation loss: 1.5463884402346868

Epoch: 6| Step: 3
Training loss: 0.12111605703830719
Validation loss: 1.551723995516377

Epoch: 6| Step: 4
Training loss: 0.1401871144771576
Validation loss: 1.5646191309857111

Epoch: 6| Step: 5
Training loss: 0.24664142727851868
Validation loss: 1.5539653339693624

Epoch: 6| Step: 6
Training loss: 0.16811537742614746
Validation loss: 1.5838077696420814

Epoch: 6| Step: 7
Training loss: 0.09675709903240204
Validation loss: 1.5771763260646532

Epoch: 6| Step: 8
Training loss: 0.10923559218645096
Validation loss: 1.5656448820585847

Epoch: 6| Step: 9
Training loss: 0.09884636849164963
Validation loss: 1.601704530818488

Epoch: 6| Step: 10
Training loss: 0.16108308732509613
Validation loss: 1.6114922723462504

Epoch: 6| Step: 11
Training loss: 0.15442270040512085
Validation loss: 1.581324795240997

Epoch: 6| Step: 12
Training loss: 0.12983438372612
Validation loss: 1.5439434794969455

Epoch: 6| Step: 13
Training loss: 0.08005303144454956
Validation loss: 1.5511005629775345

Epoch: 403| Step: 0
Training loss: 0.11015543341636658
Validation loss: 1.5082556432293308

Epoch: 6| Step: 1
Training loss: 0.11864560842514038
Validation loss: 1.5174953040256296

Epoch: 6| Step: 2
Training loss: 0.13404127955436707
Validation loss: 1.522727882990273

Epoch: 6| Step: 3
Training loss: 0.18659475445747375
Validation loss: 1.4896083826659827

Epoch: 6| Step: 4
Training loss: 0.22879205644130707
Validation loss: 1.463110678939409

Epoch: 6| Step: 5
Training loss: 0.11330168694257736
Validation loss: 1.4950642598572599

Epoch: 6| Step: 6
Training loss: 0.09608370065689087
Validation loss: 1.4994469893875944

Epoch: 6| Step: 7
Training loss: 0.12011696398258209
Validation loss: 1.5367125670115154

Epoch: 6| Step: 8
Training loss: 0.12127614766359329
Validation loss: 1.5462156444467523

Epoch: 6| Step: 9
Training loss: 0.1321452260017395
Validation loss: 1.5918661932791434

Epoch: 6| Step: 10
Training loss: 0.181132972240448
Validation loss: 1.6121698246207288

Epoch: 6| Step: 11
Training loss: 0.16961541771888733
Validation loss: 1.6142062602504608

Epoch: 6| Step: 12
Training loss: 0.07776395231485367
Validation loss: 1.5645034524702257

Epoch: 6| Step: 13
Training loss: 0.258444219827652
Validation loss: 1.5555096416063205

Epoch: 404| Step: 0
Training loss: 0.0818101018667221
Validation loss: 1.551379487078677

Epoch: 6| Step: 1
Training loss: 0.09138916432857513
Validation loss: 1.540674267276641

Epoch: 6| Step: 2
Training loss: 0.11465395987033844
Validation loss: 1.5332939124876452

Epoch: 6| Step: 3
Training loss: 0.12615182995796204
Validation loss: 1.5433262464820698

Epoch: 6| Step: 4
Training loss: 0.21111857891082764
Validation loss: 1.5241891786616335

Epoch: 6| Step: 5
Training loss: 0.12342874705791473
Validation loss: 1.5282821539909608

Epoch: 6| Step: 6
Training loss: 0.12351705133914948
Validation loss: 1.5170892041216615

Epoch: 6| Step: 7
Training loss: 0.08232096582651138
Validation loss: 1.536055621280465

Epoch: 6| Step: 8
Training loss: 0.08323480188846588
Validation loss: 1.5428793135509695

Epoch: 6| Step: 9
Training loss: 0.11231230944395065
Validation loss: 1.521017425803728

Epoch: 6| Step: 10
Training loss: 0.11606448888778687
Validation loss: 1.5138628816091886

Epoch: 6| Step: 11
Training loss: 0.08613283932209015
Validation loss: 1.5319987343203636

Epoch: 6| Step: 12
Training loss: 0.13129252195358276
Validation loss: 1.5045799427135016

Epoch: 6| Step: 13
Training loss: 0.23117512464523315
Validation loss: 1.5336587236773582

Epoch: 405| Step: 0
Training loss: 0.06754442304372787
Validation loss: 1.5137368466264458

Epoch: 6| Step: 1
Training loss: 0.1220489889383316
Validation loss: 1.5092867651293356

Epoch: 6| Step: 2
Training loss: 0.10285000503063202
Validation loss: 1.5279684297500118

Epoch: 6| Step: 3
Training loss: 0.12083979696035385
Validation loss: 1.5077815658302718

Epoch: 6| Step: 4
Training loss: 0.09364978969097137
Validation loss: 1.5320882156331053

Epoch: 6| Step: 5
Training loss: 0.16659945249557495
Validation loss: 1.5279664442103396

Epoch: 6| Step: 6
Training loss: 0.13226953148841858
Validation loss: 1.5130758721341369

Epoch: 6| Step: 7
Training loss: 0.07350912690162659
Validation loss: 1.506866539678266

Epoch: 6| Step: 8
Training loss: 0.13886412978172302
Validation loss: 1.5044954694727415

Epoch: 6| Step: 9
Training loss: 0.19834844768047333
Validation loss: 1.531613108932331

Epoch: 6| Step: 10
Training loss: 0.24742692708969116
Validation loss: 1.5163389367441977

Epoch: 6| Step: 11
Training loss: 0.08594417572021484
Validation loss: 1.5659373691005092

Epoch: 6| Step: 12
Training loss: 0.13448724150657654
Validation loss: 1.555307101177913

Epoch: 6| Step: 13
Training loss: 0.15560093522071838
Validation loss: 1.5759341793675576

Epoch: 406| Step: 0
Training loss: 0.059556957334280014
Validation loss: 1.5898417234420776

Epoch: 6| Step: 1
Training loss: 0.177777960896492
Validation loss: 1.5722980717177033

Epoch: 6| Step: 2
Training loss: 0.11698193103075027
Validation loss: 1.5645986641606977

Epoch: 6| Step: 3
Training loss: 0.17057250440120697
Validation loss: 1.554454686821148

Epoch: 6| Step: 4
Training loss: 0.21348775923252106
Validation loss: 1.5593355932543356

Epoch: 6| Step: 5
Training loss: 0.19936752319335938
Validation loss: 1.5401802665443831

Epoch: 6| Step: 6
Training loss: 0.07789988815784454
Validation loss: 1.5345063030078847

Epoch: 6| Step: 7
Training loss: 0.14311395585536957
Validation loss: 1.5505436787041285

Epoch: 6| Step: 8
Training loss: 0.1387215107679367
Validation loss: 1.5396427185304704

Epoch: 6| Step: 9
Training loss: 0.11196931451559067
Validation loss: 1.4949359201615857

Epoch: 6| Step: 10
Training loss: 0.1252174973487854
Validation loss: 1.4823507166677905

Epoch: 6| Step: 11
Training loss: 0.0885186493396759
Validation loss: 1.5094123130203576

Epoch: 6| Step: 12
Training loss: 0.09884870797395706
Validation loss: 1.4997670189026864

Epoch: 6| Step: 13
Training loss: 0.15156716108322144
Validation loss: 1.5186148369184105

Epoch: 407| Step: 0
Training loss: 0.09843360632658005
Validation loss: 1.53290787307165

Epoch: 6| Step: 1
Training loss: 0.14134404063224792
Validation loss: 1.5259021597523843

Epoch: 6| Step: 2
Training loss: 0.1071465015411377
Validation loss: 1.533900781344342

Epoch: 6| Step: 3
Training loss: 0.103499636054039
Validation loss: 1.512738884136241

Epoch: 6| Step: 4
Training loss: 0.1373002529144287
Validation loss: 1.5084345129228407

Epoch: 6| Step: 5
Training loss: 0.1595485359430313
Validation loss: 1.552297858781712

Epoch: 6| Step: 6
Training loss: 0.18582181632518768
Validation loss: 1.5129072563622588

Epoch: 6| Step: 7
Training loss: 0.12716278433799744
Validation loss: 1.5383467558891541

Epoch: 6| Step: 8
Training loss: 0.11953745782375336
Validation loss: 1.5330446522722962

Epoch: 6| Step: 9
Training loss: 0.12334484606981277
Validation loss: 1.4901992979870047

Epoch: 6| Step: 10
Training loss: 0.172202929854393
Validation loss: 1.4979514729592107

Epoch: 6| Step: 11
Training loss: 0.10481303185224533
Validation loss: 1.5107616314324

Epoch: 6| Step: 12
Training loss: 0.12837255001068115
Validation loss: 1.5312423584281758

Epoch: 6| Step: 13
Training loss: 0.09825264662504196
Validation loss: 1.5379113458818006

Epoch: 408| Step: 0
Training loss: 0.10498452931642532
Validation loss: 1.5310451305040749

Epoch: 6| Step: 1
Training loss: 0.18304480612277985
Validation loss: 1.508103552684989

Epoch: 6| Step: 2
Training loss: 0.08593954890966415
Validation loss: 1.470219217320924

Epoch: 6| Step: 3
Training loss: 0.063787542283535
Validation loss: 1.506009344131716

Epoch: 6| Step: 4
Training loss: 0.06821852922439575
Validation loss: 1.5266567622461626

Epoch: 6| Step: 5
Training loss: 0.15156258642673492
Validation loss: 1.5391568663299724

Epoch: 6| Step: 6
Training loss: 0.1659473478794098
Validation loss: 1.534343699614207

Epoch: 6| Step: 7
Training loss: 0.06830940395593643
Validation loss: 1.5845032392009613

Epoch: 6| Step: 8
Training loss: 0.1267450451850891
Validation loss: 1.576142155995933

Epoch: 6| Step: 9
Training loss: 0.13658815622329712
Validation loss: 1.5408762731859762

Epoch: 6| Step: 10
Training loss: 0.23217645287513733
Validation loss: 1.5301704957921018

Epoch: 6| Step: 11
Training loss: 0.08460620045661926
Validation loss: 1.5436006694711664

Epoch: 6| Step: 12
Training loss: 0.12263999879360199
Validation loss: 1.5603736946659703

Epoch: 6| Step: 13
Training loss: 0.06786300241947174
Validation loss: 1.544021459035976

Epoch: 409| Step: 0
Training loss: 0.14288756251335144
Validation loss: 1.5377309206993348

Epoch: 6| Step: 1
Training loss: 0.06747230887413025
Validation loss: 1.539228359858195

Epoch: 6| Step: 2
Training loss: 0.06304304301738739
Validation loss: 1.5279495100821219

Epoch: 6| Step: 3
Training loss: 0.1312204897403717
Validation loss: 1.5151324528519825

Epoch: 6| Step: 4
Training loss: 0.19384890794754028
Validation loss: 1.505118848175131

Epoch: 6| Step: 5
Training loss: 0.14058317244052887
Validation loss: 1.4964514445233088

Epoch: 6| Step: 6
Training loss: 0.17945462465286255
Validation loss: 1.5060037118132397

Epoch: 6| Step: 7
Training loss: 0.1374133825302124
Validation loss: 1.5036559438192716

Epoch: 6| Step: 8
Training loss: 0.21864694356918335
Validation loss: 1.5316088340615714

Epoch: 6| Step: 9
Training loss: 0.1414491832256317
Validation loss: 1.5095560550689697

Epoch: 6| Step: 10
Training loss: 0.07562731951475143
Validation loss: 1.5233355978483796

Epoch: 6| Step: 11
Training loss: 0.08653963357210159
Validation loss: 1.523242167247239

Epoch: 6| Step: 12
Training loss: 0.10610257089138031
Validation loss: 1.521183979126715

Epoch: 6| Step: 13
Training loss: 0.069294773042202
Validation loss: 1.5185821453730266

Epoch: 410| Step: 0
Training loss: 0.09475077688694
Validation loss: 1.5378278532335836

Epoch: 6| Step: 1
Training loss: 0.1191127598285675
Validation loss: 1.5429875350767566

Epoch: 6| Step: 2
Training loss: 0.17514866590499878
Validation loss: 1.5526532447466286

Epoch: 6| Step: 3
Training loss: 0.07120506465435028
Validation loss: 1.5550373318374797

Epoch: 6| Step: 4
Training loss: 0.12658578157424927
Validation loss: 1.5397516424937914

Epoch: 6| Step: 5
Training loss: 0.12529677152633667
Validation loss: 1.5628212472443939

Epoch: 6| Step: 6
Training loss: 0.19176654517650604
Validation loss: 1.5489835854499572

Epoch: 6| Step: 7
Training loss: 0.06122621148824692
Validation loss: 1.5683764808921403

Epoch: 6| Step: 8
Training loss: 0.08566322922706604
Validation loss: 1.522580890245335

Epoch: 6| Step: 9
Training loss: 0.1327132135629654
Validation loss: 1.5374882913404895

Epoch: 6| Step: 10
Training loss: 0.10383350402116776
Validation loss: 1.5269549380066574

Epoch: 6| Step: 11
Training loss: 0.11693680286407471
Validation loss: 1.4951942197738155

Epoch: 6| Step: 12
Training loss: 0.11128127574920654
Validation loss: 1.5114174171160626

Epoch: 6| Step: 13
Training loss: 0.32998424768447876
Validation loss: 1.534706623323502

Epoch: 411| Step: 0
Training loss: 0.1520078480243683
Validation loss: 1.5692286888758342

Epoch: 6| Step: 1
Training loss: 0.24492137134075165
Validation loss: 1.5320693882562781

Epoch: 6| Step: 2
Training loss: 0.08608187735080719
Validation loss: 1.5580534614542478

Epoch: 6| Step: 3
Training loss: 0.07673569023609161
Validation loss: 1.5200482158250705

Epoch: 6| Step: 4
Training loss: 0.10200783610343933
Validation loss: 1.5152581712251068

Epoch: 6| Step: 5
Training loss: 0.08981390297412872
Validation loss: 1.5107306793171873

Epoch: 6| Step: 6
Training loss: 0.09439218044281006
Validation loss: 1.5163440255708591

Epoch: 6| Step: 7
Training loss: 0.08563315868377686
Validation loss: 1.499653911077848

Epoch: 6| Step: 8
Training loss: 0.05471081659197807
Validation loss: 1.5004821067215295

Epoch: 6| Step: 9
Training loss: 0.09078219532966614
Validation loss: 1.5134502918489519

Epoch: 6| Step: 10
Training loss: 0.14149291813373566
Validation loss: 1.5158623854319255

Epoch: 6| Step: 11
Training loss: 0.16685974597930908
Validation loss: 1.5152252143429172

Epoch: 6| Step: 12
Training loss: 0.08809909969568253
Validation loss: 1.5095547963214178

Epoch: 6| Step: 13
Training loss: 0.11419132351875305
Validation loss: 1.5100328672316767

Epoch: 412| Step: 0
Training loss: 0.14861370623111725
Validation loss: 1.50819617830297

Epoch: 6| Step: 1
Training loss: 0.07535107433795929
Validation loss: 1.51832724771192

Epoch: 6| Step: 2
Training loss: 0.16762134432792664
Validation loss: 1.520634553765738

Epoch: 6| Step: 3
Training loss: 0.045389775186777115
Validation loss: 1.487215558687846

Epoch: 6| Step: 4
Training loss: 0.08175145834684372
Validation loss: 1.5102997108172345

Epoch: 6| Step: 5
Training loss: 0.1109766960144043
Validation loss: 1.5189179874235583

Epoch: 6| Step: 6
Training loss: 0.12875673174858093
Validation loss: 1.506009163395051

Epoch: 6| Step: 7
Training loss: 0.1056651696562767
Validation loss: 1.4839060248867157

Epoch: 6| Step: 8
Training loss: 0.17411768436431885
Validation loss: 1.4893181285550516

Epoch: 6| Step: 9
Training loss: 0.1646280586719513
Validation loss: 1.4853628463642572

Epoch: 6| Step: 10
Training loss: 0.11905636638402939
Validation loss: 1.4933842894851521

Epoch: 6| Step: 11
Training loss: 0.1488935798406601
Validation loss: 1.4777291115894113

Epoch: 6| Step: 12
Training loss: 0.13089072704315186
Validation loss: 1.4803939929572485

Epoch: 6| Step: 13
Training loss: 0.1112229973077774
Validation loss: 1.5218852066224622

Epoch: 413| Step: 0
Training loss: 0.20344185829162598
Validation loss: 1.5116078565197606

Epoch: 6| Step: 1
Training loss: 0.13000111281871796
Validation loss: 1.4901750190283662

Epoch: 6| Step: 2
Training loss: 0.19010141491889954
Validation loss: 1.5050747356107157

Epoch: 6| Step: 3
Training loss: 0.08135682344436646
Validation loss: 1.4869434525889735

Epoch: 6| Step: 4
Training loss: 0.09679684042930603
Validation loss: 1.5065518809903053

Epoch: 6| Step: 5
Training loss: 0.18674111366271973
Validation loss: 1.5091137757865332

Epoch: 6| Step: 6
Training loss: 0.08981436491012573
Validation loss: 1.5198885567726628

Epoch: 6| Step: 7
Training loss: 0.18014921247959137
Validation loss: 1.5155491418735956

Epoch: 6| Step: 8
Training loss: 0.13517573475837708
Validation loss: 1.509277541150329

Epoch: 6| Step: 9
Training loss: 0.22226910293102264
Validation loss: 1.510720754182467

Epoch: 6| Step: 10
Training loss: 0.09788241982460022
Validation loss: 1.5015196672049902

Epoch: 6| Step: 11
Training loss: 0.18938015401363373
Validation loss: 1.4945619990748744

Epoch: 6| Step: 12
Training loss: 0.07859908044338226
Validation loss: 1.4865785580809399

Epoch: 6| Step: 13
Training loss: 0.11928468197584152
Validation loss: 1.4814579320210282

Epoch: 414| Step: 0
Training loss: 0.14777158200740814
Validation loss: 1.494469060692736

Epoch: 6| Step: 1
Training loss: 0.09577830135822296
Validation loss: 1.4910246479895808

Epoch: 6| Step: 2
Training loss: 0.12470783293247223
Validation loss: 1.4940153091184554

Epoch: 6| Step: 3
Training loss: 0.12537533044815063
Validation loss: 1.5355657787733181

Epoch: 6| Step: 4
Training loss: 0.22608602046966553
Validation loss: 1.5037127451230121

Epoch: 6| Step: 5
Training loss: 0.12315769493579865
Validation loss: 1.5186535632738503

Epoch: 6| Step: 6
Training loss: 0.14186088740825653
Validation loss: 1.5398641645267446

Epoch: 6| Step: 7
Training loss: 0.18669641017913818
Validation loss: 1.543751037249001

Epoch: 6| Step: 8
Training loss: 0.13747036457061768
Validation loss: 1.5348174187444872

Epoch: 6| Step: 9
Training loss: 0.08278407156467438
Validation loss: 1.5316804737173102

Epoch: 6| Step: 10
Training loss: 0.1060841828584671
Validation loss: 1.5306731988024969

Epoch: 6| Step: 11
Training loss: 0.14351807534694672
Validation loss: 1.53875780874683

Epoch: 6| Step: 12
Training loss: 0.20337845385074615
Validation loss: 1.5759194089520363

Epoch: 6| Step: 13
Training loss: 0.11303862184286118
Validation loss: 1.521593169499469

Epoch: 415| Step: 0
Training loss: 0.13306695222854614
Validation loss: 1.5308027344365274

Epoch: 6| Step: 1
Training loss: 0.14399036765098572
Validation loss: 1.5331463236962595

Epoch: 6| Step: 2
Training loss: 0.1905691921710968
Validation loss: 1.5563263585490565

Epoch: 6| Step: 3
Training loss: 0.1551387906074524
Validation loss: 1.5486199445621942

Epoch: 6| Step: 4
Training loss: 0.15298452973365784
Validation loss: 1.5691758509605163

Epoch: 6| Step: 5
Training loss: 0.12169390916824341
Validation loss: 1.5700685106297976

Epoch: 6| Step: 6
Training loss: 0.1994142234325409
Validation loss: 1.5679380214342507

Epoch: 6| Step: 7
Training loss: 0.0974416732788086
Validation loss: 1.5634520899864934

Epoch: 6| Step: 8
Training loss: 0.24292424321174622
Validation loss: 1.5449538833351546

Epoch: 6| Step: 9
Training loss: 0.1164637953042984
Validation loss: 1.5295904272346086

Epoch: 6| Step: 10
Training loss: 0.19760754704475403
Validation loss: 1.5014701556133967

Epoch: 6| Step: 11
Training loss: 0.14672991633415222
Validation loss: 1.5092717947498444

Epoch: 6| Step: 12
Training loss: 0.08166012167930603
Validation loss: 1.4982282115567116

Epoch: 6| Step: 13
Training loss: 0.08206211775541306
Validation loss: 1.5078807389864357

Epoch: 416| Step: 0
Training loss: 0.1029900312423706
Validation loss: 1.5096700191497803

Epoch: 6| Step: 1
Training loss: 0.07961197197437286
Validation loss: 1.5072355526749805

Epoch: 6| Step: 2
Training loss: 0.09377889335155487
Validation loss: 1.50531207617893

Epoch: 6| Step: 3
Training loss: 0.12521180510520935
Validation loss: 1.5223851793555803

Epoch: 6| Step: 4
Training loss: 0.12546110153198242
Validation loss: 1.4664070337049422

Epoch: 6| Step: 5
Training loss: 0.12236760556697845
Validation loss: 1.5232863016025995

Epoch: 6| Step: 6
Training loss: 0.12810207903385162
Validation loss: 1.4994645093076973

Epoch: 6| Step: 7
Training loss: 0.14576971530914307
Validation loss: 1.5193832920443626

Epoch: 6| Step: 8
Training loss: 0.18634164333343506
Validation loss: 1.523531158765157

Epoch: 6| Step: 9
Training loss: 0.12798050045967102
Validation loss: 1.5193531244031844

Epoch: 6| Step: 10
Training loss: 0.15231969952583313
Validation loss: 1.5357381566878288

Epoch: 6| Step: 11
Training loss: 0.09240397810935974
Validation loss: 1.5177632762539772

Epoch: 6| Step: 12
Training loss: 0.06038565933704376
Validation loss: 1.5028889320229972

Epoch: 6| Step: 13
Training loss: 0.06050143018364906
Validation loss: 1.5183556746411067

Epoch: 417| Step: 0
Training loss: 0.18170109391212463
Validation loss: 1.5762139815156178

Epoch: 6| Step: 1
Training loss: 0.10903256386518478
Validation loss: 1.551865622561465

Epoch: 6| Step: 2
Training loss: 0.12055902183055878
Validation loss: 1.5641568347971926

Epoch: 6| Step: 3
Training loss: 0.1026993915438652
Validation loss: 1.5707197766150198

Epoch: 6| Step: 4
Training loss: 0.11515198647975922
Validation loss: 1.5722063536285071

Epoch: 6| Step: 5
Training loss: 0.15471991896629333
Validation loss: 1.556088020724635

Epoch: 6| Step: 6
Training loss: 0.0782628208398819
Validation loss: 1.5725537423164613

Epoch: 6| Step: 7
Training loss: 0.09110942482948303
Validation loss: 1.5351338553172287

Epoch: 6| Step: 8
Training loss: 0.24104508757591248
Validation loss: 1.5251143350396106

Epoch: 6| Step: 9
Training loss: 0.12105241417884827
Validation loss: 1.5090412734657206

Epoch: 6| Step: 10
Training loss: 0.063960961997509
Validation loss: 1.5142917440783592

Epoch: 6| Step: 11
Training loss: 0.09403789788484573
Validation loss: 1.5099622690549461

Epoch: 6| Step: 12
Training loss: 0.04888015240430832
Validation loss: 1.5025076914218165

Epoch: 6| Step: 13
Training loss: 0.1502515971660614
Validation loss: 1.4943957617205958

Epoch: 418| Step: 0
Training loss: 0.09265473484992981
Validation loss: 1.49262547621163

Epoch: 6| Step: 1
Training loss: 0.08559474349021912
Validation loss: 1.5000971645437262

Epoch: 6| Step: 2
Training loss: 0.08904406428337097
Validation loss: 1.50851297250358

Epoch: 6| Step: 3
Training loss: 0.07999370992183685
Validation loss: 1.4967058204835462

Epoch: 6| Step: 4
Training loss: 0.0821889340877533
Validation loss: 1.512776138961956

Epoch: 6| Step: 5
Training loss: 0.10733254253864288
Validation loss: 1.5113866329193115

Epoch: 6| Step: 6
Training loss: 0.1339612454175949
Validation loss: 1.5411491265860937

Epoch: 6| Step: 7
Training loss: 0.12023890018463135
Validation loss: 1.5158096872350222

Epoch: 6| Step: 8
Training loss: 0.16239623725414276
Validation loss: 1.5424581676401117

Epoch: 6| Step: 9
Training loss: 0.12527279555797577
Validation loss: 1.5462846179162302

Epoch: 6| Step: 10
Training loss: 0.09897211194038391
Validation loss: 1.5450336157634694

Epoch: 6| Step: 11
Training loss: 0.16790403425693512
Validation loss: 1.527156792661195

Epoch: 6| Step: 12
Training loss: 0.11701958626508713
Validation loss: 1.5203044094065183

Epoch: 6| Step: 13
Training loss: 0.182140052318573
Validation loss: 1.497207888992884

Epoch: 419| Step: 0
Training loss: 0.10641121119260788
Validation loss: 1.4474647134862921

Epoch: 6| Step: 1
Training loss: 0.14168059825897217
Validation loss: 1.474480901995013

Epoch: 6| Step: 2
Training loss: 0.07476520538330078
Validation loss: 1.4771664706609582

Epoch: 6| Step: 3
Training loss: 0.10186910629272461
Validation loss: 1.4842441992093158

Epoch: 6| Step: 4
Training loss: 0.0783403068780899
Validation loss: 1.513742603281493

Epoch: 6| Step: 5
Training loss: 0.10455962270498276
Validation loss: 1.512168938113797

Epoch: 6| Step: 6
Training loss: 0.10970115661621094
Validation loss: 1.5268857440640848

Epoch: 6| Step: 7
Training loss: 0.05282088369131088
Validation loss: 1.5426079111714517

Epoch: 6| Step: 8
Training loss: 0.07945038378238678
Validation loss: 1.5397027288713763

Epoch: 6| Step: 9
Training loss: 0.1838388741016388
Validation loss: 1.5680368664444133

Epoch: 6| Step: 10
Training loss: 0.2174188792705536
Validation loss: 1.5918488284592986

Epoch: 6| Step: 11
Training loss: 0.15681752562522888
Validation loss: 1.608603331350511

Epoch: 6| Step: 12
Training loss: 0.18848451972007751
Validation loss: 1.5919025892852454

Epoch: 6| Step: 13
Training loss: 0.11280258744955063
Validation loss: 1.585086513591069

Epoch: 420| Step: 0
Training loss: 0.03994324058294296
Validation loss: 1.5235272786950553

Epoch: 6| Step: 1
Training loss: 0.10427886247634888
Validation loss: 1.5716620363214964

Epoch: 6| Step: 2
Training loss: 0.12958817183971405
Validation loss: 1.5468586067999563

Epoch: 6| Step: 3
Training loss: 0.07703684270381927
Validation loss: 1.5426493806223716

Epoch: 6| Step: 4
Training loss: 0.11265669018030167
Validation loss: 1.5191743245688818

Epoch: 6| Step: 5
Training loss: 0.1367597132921219
Validation loss: 1.5266494110066404

Epoch: 6| Step: 6
Training loss: 0.23406293988227844
Validation loss: 1.5135081929545249

Epoch: 6| Step: 7
Training loss: 0.06614556163549423
Validation loss: 1.521575080451145

Epoch: 6| Step: 8
Training loss: 0.14141052961349487
Validation loss: 1.4852896339149886

Epoch: 6| Step: 9
Training loss: 0.05834498256444931
Validation loss: 1.5034094959176996

Epoch: 6| Step: 10
Training loss: 0.11963088810443878
Validation loss: 1.4888897339502971

Epoch: 6| Step: 11
Training loss: 0.0788726657629013
Validation loss: 1.4689504049157585

Epoch: 6| Step: 12
Training loss: 0.10962268710136414
Validation loss: 1.494576697708458

Epoch: 6| Step: 13
Training loss: 0.09321648627519608
Validation loss: 1.4410390905154649

Epoch: 421| Step: 0
Training loss: 0.09845754504203796
Validation loss: 1.4480504669168943

Epoch: 6| Step: 1
Training loss: 0.19510886073112488
Validation loss: 1.4418028913518435

Epoch: 6| Step: 2
Training loss: 0.09973874688148499
Validation loss: 1.4314286260194675

Epoch: 6| Step: 3
Training loss: 0.164453387260437
Validation loss: 1.4418951196055259

Epoch: 6| Step: 4
Training loss: 0.08313456177711487
Validation loss: 1.4670241366150558

Epoch: 6| Step: 5
Training loss: 0.09934650361537933
Validation loss: 1.442162630378559

Epoch: 6| Step: 6
Training loss: 0.16459618508815765
Validation loss: 1.4514628559030511

Epoch: 6| Step: 7
Training loss: 0.10630810260772705
Validation loss: 1.4760316469336068

Epoch: 6| Step: 8
Training loss: 0.10014621913433075
Validation loss: 1.5002408745468303

Epoch: 6| Step: 9
Training loss: 0.10648118704557419
Validation loss: 1.5349202720067834

Epoch: 6| Step: 10
Training loss: 0.12542103230953217
Validation loss: 1.5372304429290116

Epoch: 6| Step: 11
Training loss: 0.10007063299417496
Validation loss: 1.5860174061149679

Epoch: 6| Step: 12
Training loss: 0.13419362902641296
Validation loss: 1.5619195712509977

Epoch: 6| Step: 13
Training loss: 0.10606245696544647
Validation loss: 1.5724158825412873

Epoch: 422| Step: 0
Training loss: 0.19252192974090576
Validation loss: 1.565367538441894

Epoch: 6| Step: 1
Training loss: 0.12030649185180664
Validation loss: 1.5591141280307566

Epoch: 6| Step: 2
Training loss: 0.09001277387142181
Validation loss: 1.534242130094959

Epoch: 6| Step: 3
Training loss: 0.12093337625265121
Validation loss: 1.5268671743331417

Epoch: 6| Step: 4
Training loss: 0.09213373064994812
Validation loss: 1.5241418115554317

Epoch: 6| Step: 5
Training loss: 0.11466667056083679
Validation loss: 1.5077973040201331

Epoch: 6| Step: 6
Training loss: 0.08156336098909378
Validation loss: 1.4813212297296012

Epoch: 6| Step: 7
Training loss: 0.11712068319320679
Validation loss: 1.5034451920499083

Epoch: 6| Step: 8
Training loss: 0.15912967920303345
Validation loss: 1.4768886258525233

Epoch: 6| Step: 9
Training loss: 0.09228257089853287
Validation loss: 1.4695256807470833

Epoch: 6| Step: 10
Training loss: 0.09025775641202927
Validation loss: 1.4698960108141745

Epoch: 6| Step: 11
Training loss: 0.1718815267086029
Validation loss: 1.5032214118588356

Epoch: 6| Step: 12
Training loss: 0.14314135909080505
Validation loss: 1.4857686905450718

Epoch: 6| Step: 13
Training loss: 0.09495154768228531
Validation loss: 1.4867617340498074

Epoch: 423| Step: 0
Training loss: 0.13817143440246582
Validation loss: 1.499394178390503

Epoch: 6| Step: 1
Training loss: 0.07427819073200226
Validation loss: 1.4669485361345354

Epoch: 6| Step: 2
Training loss: 0.13802993297576904
Validation loss: 1.4790925800159413

Epoch: 6| Step: 3
Training loss: 0.08129797875881195
Validation loss: 1.4863645171606412

Epoch: 6| Step: 4
Training loss: 0.06260807812213898
Validation loss: 1.4774170114148049

Epoch: 6| Step: 5
Training loss: 0.14424577355384827
Validation loss: 1.4788882617027528

Epoch: 6| Step: 6
Training loss: 0.1154250055551529
Validation loss: 1.4867640041535901

Epoch: 6| Step: 7
Training loss: 0.13318729400634766
Validation loss: 1.4907568898252261

Epoch: 6| Step: 8
Training loss: 0.18694952130317688
Validation loss: 1.4814236087183799

Epoch: 6| Step: 9
Training loss: 0.1412857174873352
Validation loss: 1.452839486060604

Epoch: 6| Step: 10
Training loss: 0.13579539954662323
Validation loss: 1.450436528011035

Epoch: 6| Step: 11
Training loss: 0.13820716738700867
Validation loss: 1.463885489330497

Epoch: 6| Step: 12
Training loss: 0.11004970222711563
Validation loss: 1.4715409458324473

Epoch: 6| Step: 13
Training loss: 0.22647690773010254
Validation loss: 1.5188889862388693

Epoch: 424| Step: 0
Training loss: 0.1575128436088562
Validation loss: 1.4770053535379388

Epoch: 6| Step: 1
Training loss: 0.11272162199020386
Validation loss: 1.4976591756266933

Epoch: 6| Step: 2
Training loss: 0.10146203637123108
Validation loss: 1.5555807005974553

Epoch: 6| Step: 3
Training loss: 0.1925409734249115
Validation loss: 1.5572933125239548

Epoch: 6| Step: 4
Training loss: 0.14327752590179443
Validation loss: 1.531507138283022

Epoch: 6| Step: 5
Training loss: 0.09200775623321533
Validation loss: 1.5337757961724394

Epoch: 6| Step: 6
Training loss: 0.13480496406555176
Validation loss: 1.5154981959250666

Epoch: 6| Step: 7
Training loss: 0.1307944506406784
Validation loss: 1.5164997013666297

Epoch: 6| Step: 8
Training loss: 0.1279183179140091
Validation loss: 1.4841565367996052

Epoch: 6| Step: 9
Training loss: 0.13266441226005554
Validation loss: 1.5117425700669647

Epoch: 6| Step: 10
Training loss: 0.15645621716976166
Validation loss: 1.497354184427569

Epoch: 6| Step: 11
Training loss: 0.20426641404628754
Validation loss: 1.510636402714637

Epoch: 6| Step: 12
Training loss: 0.18754231929779053
Validation loss: 1.4746591455192977

Epoch: 6| Step: 13
Training loss: 0.37127500772476196
Validation loss: 1.4755398496504752

Epoch: 425| Step: 0
Training loss: 0.20862780511379242
Validation loss: 1.4502728767292474

Epoch: 6| Step: 1
Training loss: 0.21051469445228577
Validation loss: 1.4533650208544988

Epoch: 6| Step: 2
Training loss: 0.1826080083847046
Validation loss: 1.484415856740808

Epoch: 6| Step: 3
Training loss: 0.09712670743465424
Validation loss: 1.4862920033034457

Epoch: 6| Step: 4
Training loss: 0.12051595747470856
Validation loss: 1.4770806143360753

Epoch: 6| Step: 5
Training loss: 0.1155174970626831
Validation loss: 1.5264381849637596

Epoch: 6| Step: 6
Training loss: 0.09756806492805481
Validation loss: 1.5809076319458664

Epoch: 6| Step: 7
Training loss: 0.1688389927148819
Validation loss: 1.5710073863306353

Epoch: 6| Step: 8
Training loss: 0.16926893591880798
Validation loss: 1.5838659617208666

Epoch: 6| Step: 9
Training loss: 0.11917593330144882
Validation loss: 1.5613034643152708

Epoch: 6| Step: 10
Training loss: 0.3022249937057495
Validation loss: 1.5534866432989798

Epoch: 6| Step: 11
Training loss: 0.18788479268550873
Validation loss: 1.5273378510628977

Epoch: 6| Step: 12
Training loss: 0.08142080157995224
Validation loss: 1.4798152190382763

Epoch: 6| Step: 13
Training loss: 0.11491613835096359
Validation loss: 1.4679183280596169

Epoch: 426| Step: 0
Training loss: 0.10406310111284256
Validation loss: 1.4558355366030047

Epoch: 6| Step: 1
Training loss: 0.10545513033866882
Validation loss: 1.4373208976561023

Epoch: 6| Step: 2
Training loss: 0.2347410023212433
Validation loss: 1.451629800181235

Epoch: 6| Step: 3
Training loss: 0.1336623728275299
Validation loss: 1.4431585124743882

Epoch: 6| Step: 4
Training loss: 0.1266445368528366
Validation loss: 1.4555688083812754

Epoch: 6| Step: 5
Training loss: 0.0975160151720047
Validation loss: 1.4626409135838991

Epoch: 6| Step: 6
Training loss: 0.15440970659255981
Validation loss: 1.4805493931616507

Epoch: 6| Step: 7
Training loss: 0.12347166985273361
Validation loss: 1.4938968932756813

Epoch: 6| Step: 8
Training loss: 0.13229075074195862
Validation loss: 1.5076138691235614

Epoch: 6| Step: 9
Training loss: 0.1336548924446106
Validation loss: 1.5166827709444108

Epoch: 6| Step: 10
Training loss: 0.13967399299144745
Validation loss: 1.4975653450976136

Epoch: 6| Step: 11
Training loss: 0.166916623711586
Validation loss: 1.498045644452495

Epoch: 6| Step: 12
Training loss: 0.05246805027127266
Validation loss: 1.49868389227057

Epoch: 6| Step: 13
Training loss: 0.11967314779758453
Validation loss: 1.4736384371275544

Epoch: 427| Step: 0
Training loss: 0.11526834219694138
Validation loss: 1.476137872665159

Epoch: 6| Step: 1
Training loss: 0.11251988261938095
Validation loss: 1.4923520242014239

Epoch: 6| Step: 2
Training loss: 0.15551713109016418
Validation loss: 1.5148925832522813

Epoch: 6| Step: 3
Training loss: 0.09662848711013794
Validation loss: 1.4850324379500521

Epoch: 6| Step: 4
Training loss: 0.0754876360297203
Validation loss: 1.503809780202886

Epoch: 6| Step: 5
Training loss: 0.18476760387420654
Validation loss: 1.5154329281981274

Epoch: 6| Step: 6
Training loss: 0.1181926354765892
Validation loss: 1.5274791538074453

Epoch: 6| Step: 7
Training loss: 0.15461376309394836
Validation loss: 1.4791651105368009

Epoch: 6| Step: 8
Training loss: 0.06113339215517044
Validation loss: 1.5080380875577208

Epoch: 6| Step: 9
Training loss: 0.05418603494763374
Validation loss: 1.5208190769277594

Epoch: 6| Step: 10
Training loss: 0.1123766303062439
Validation loss: 1.485108729331724

Epoch: 6| Step: 11
Training loss: 0.1810654103755951
Validation loss: 1.5152881991478704

Epoch: 6| Step: 12
Training loss: 0.17548711597919464
Validation loss: 1.482281518238847

Epoch: 6| Step: 13
Training loss: 0.15136605501174927
Validation loss: 1.468197742457031

Epoch: 428| Step: 0
Training loss: 0.11563705652952194
Validation loss: 1.4777849438369914

Epoch: 6| Step: 1
Training loss: 0.12409758567810059
Validation loss: 1.494687940484734

Epoch: 6| Step: 2
Training loss: 0.088661789894104
Validation loss: 1.4762194297646964

Epoch: 6| Step: 3
Training loss: 0.1860111951828003
Validation loss: 1.5027324371440436

Epoch: 6| Step: 4
Training loss: 0.1128174215555191
Validation loss: 1.517275833314465

Epoch: 6| Step: 5
Training loss: 0.09734562039375305
Validation loss: 1.507831063962752

Epoch: 6| Step: 6
Training loss: 0.07319130003452301
Validation loss: 1.521633404557423

Epoch: 6| Step: 7
Training loss: 0.10996510088443756
Validation loss: 1.5221431088703934

Epoch: 6| Step: 8
Training loss: 0.09244319796562195
Validation loss: 1.5420402660164783

Epoch: 6| Step: 9
Training loss: 0.07528740167617798
Validation loss: 1.5421954290841215

Epoch: 6| Step: 10
Training loss: 0.15436643362045288
Validation loss: 1.5532209847563057

Epoch: 6| Step: 11
Training loss: 0.09651491045951843
Validation loss: 1.5439677103873222

Epoch: 6| Step: 12
Training loss: 0.09185013175010681
Validation loss: 1.5254857693949053

Epoch: 6| Step: 13
Training loss: 0.14536826312541962
Validation loss: 1.510203242301941

Epoch: 429| Step: 0
Training loss: 0.07823702692985535
Validation loss: 1.5028022873786189

Epoch: 6| Step: 1
Training loss: 0.11930852383375168
Validation loss: 1.4538580807306434

Epoch: 6| Step: 2
Training loss: 0.09812971204519272
Validation loss: 1.4621253026429044

Epoch: 6| Step: 3
Training loss: 0.12753231823444366
Validation loss: 1.4357563667399909

Epoch: 6| Step: 4
Training loss: 0.08125071227550507
Validation loss: 1.4687746109501008

Epoch: 6| Step: 5
Training loss: 0.13988693058490753
Validation loss: 1.468697278730331

Epoch: 6| Step: 6
Training loss: 0.07709899544715881
Validation loss: 1.5061622806774673

Epoch: 6| Step: 7
Training loss: 0.17294713854789734
Validation loss: 1.5176628328138781

Epoch: 6| Step: 8
Training loss: 0.17798498272895813
Validation loss: 1.4944200387565039

Epoch: 6| Step: 9
Training loss: 0.07027018070220947
Validation loss: 1.5304123611860379

Epoch: 6| Step: 10
Training loss: 0.0797385722398758
Validation loss: 1.5087234576543171

Epoch: 6| Step: 11
Training loss: 0.08952529728412628
Validation loss: 1.5417298142628004

Epoch: 6| Step: 12
Training loss: 0.09649695456027985
Validation loss: 1.51959159938238

Epoch: 6| Step: 13
Training loss: 0.062049031257629395
Validation loss: 1.5431295453861196

Epoch: 430| Step: 0
Training loss: 0.1631542444229126
Validation loss: 1.5473978032347977

Epoch: 6| Step: 1
Training loss: 0.13663485646247864
Validation loss: 1.5295638653539843

Epoch: 6| Step: 2
Training loss: 0.13681259751319885
Validation loss: 1.5449429032623128

Epoch: 6| Step: 3
Training loss: 0.0782390683889389
Validation loss: 1.5501613001669607

Epoch: 6| Step: 4
Training loss: 0.10976582765579224
Validation loss: 1.5447250104719592

Epoch: 6| Step: 5
Training loss: 0.12454689294099808
Validation loss: 1.5445936226075696

Epoch: 6| Step: 6
Training loss: 0.0792480930685997
Validation loss: 1.549153524060403

Epoch: 6| Step: 7
Training loss: 0.073754221200943
Validation loss: 1.5498981065647577

Epoch: 6| Step: 8
Training loss: 0.0733005553483963
Validation loss: 1.5570528314959617

Epoch: 6| Step: 9
Training loss: 0.07224693894386292
Validation loss: 1.5436289900092668

Epoch: 6| Step: 10
Training loss: 0.08673396706581116
Validation loss: 1.5438516088711318

Epoch: 6| Step: 11
Training loss: 0.20857734978199005
Validation loss: 1.5579296722207019

Epoch: 6| Step: 12
Training loss: 0.12086910754442215
Validation loss: 1.5812001023241269

Epoch: 6| Step: 13
Training loss: 0.06276656687259674
Validation loss: 1.5049924722281836

Epoch: 431| Step: 0
Training loss: 0.12078627943992615
Validation loss: 1.5117970166667816

Epoch: 6| Step: 1
Training loss: 0.2317533642053604
Validation loss: 1.5032947262128193

Epoch: 6| Step: 2
Training loss: 0.09666867554187775
Validation loss: 1.4917046998136787

Epoch: 6| Step: 3
Training loss: 0.23551568388938904
Validation loss: 1.4592058056144304

Epoch: 6| Step: 4
Training loss: 0.11436808109283447
Validation loss: 1.426659651981887

Epoch: 6| Step: 5
Training loss: 0.08943898230791092
Validation loss: 1.4238612587733934

Epoch: 6| Step: 6
Training loss: 0.11297869682312012
Validation loss: 1.428464235798005

Epoch: 6| Step: 7
Training loss: 0.11676566302776337
Validation loss: 1.4016729958595768

Epoch: 6| Step: 8
Training loss: 0.09549500793218613
Validation loss: 1.440831644560701

Epoch: 6| Step: 9
Training loss: 0.0962984710931778
Validation loss: 1.4509621743232972

Epoch: 6| Step: 10
Training loss: 0.09431985765695572
Validation loss: 1.5008102783592798

Epoch: 6| Step: 11
Training loss: 0.0872262567281723
Validation loss: 1.5058481052357664

Epoch: 6| Step: 12
Training loss: 0.11533290892839432
Validation loss: 1.5075437561158211

Epoch: 6| Step: 13
Training loss: 0.19947797060012817
Validation loss: 1.5271901827986523

Epoch: 432| Step: 0
Training loss: 0.13475674390792847
Validation loss: 1.4961367435352777

Epoch: 6| Step: 1
Training loss: 0.13586527109146118
Validation loss: 1.4989735304668386

Epoch: 6| Step: 2
Training loss: 0.10105006396770477
Validation loss: 1.4794826494750155

Epoch: 6| Step: 3
Training loss: 0.04974152892827988
Validation loss: 1.4691458837960356

Epoch: 6| Step: 4
Training loss: 0.10719525068998337
Validation loss: 1.4313808077125139

Epoch: 6| Step: 5
Training loss: 0.11814269423484802
Validation loss: 1.4669021739754626

Epoch: 6| Step: 6
Training loss: 0.10463117063045502
Validation loss: 1.466956510338732

Epoch: 6| Step: 7
Training loss: 0.08640480041503906
Validation loss: 1.4150577898948424

Epoch: 6| Step: 8
Training loss: 0.1179172471165657
Validation loss: 1.4498731179903912

Epoch: 6| Step: 9
Training loss: 0.12717561423778534
Validation loss: 1.4553913826583533

Epoch: 6| Step: 10
Training loss: 0.1255125105381012
Validation loss: 1.4795730870257142

Epoch: 6| Step: 11
Training loss: 0.08248322457075119
Validation loss: 1.4864319434729956

Epoch: 6| Step: 12
Training loss: 0.12165631353855133
Validation loss: 1.498961664015247

Epoch: 6| Step: 13
Training loss: 0.09276501089334488
Validation loss: 1.471398103621698

Epoch: 433| Step: 0
Training loss: 0.11575598269701004
Validation loss: 1.4995987646041378

Epoch: 6| Step: 1
Training loss: 0.09466501325368881
Validation loss: 1.5077366085462673

Epoch: 6| Step: 2
Training loss: 0.06062692776322365
Validation loss: 1.4860758166159354

Epoch: 6| Step: 3
Training loss: 0.11239299923181534
Validation loss: 1.4817622771827124

Epoch: 6| Step: 4
Training loss: 0.09583364427089691
Validation loss: 1.4772297220845376

Epoch: 6| Step: 5
Training loss: 0.09942369908094406
Validation loss: 1.4831179598326325

Epoch: 6| Step: 6
Training loss: 0.19042594730854034
Validation loss: 1.4708281460628714

Epoch: 6| Step: 7
Training loss: 0.07366792112588882
Validation loss: 1.4922176702048189

Epoch: 6| Step: 8
Training loss: 0.09049935638904572
Validation loss: 1.4800752827557184

Epoch: 6| Step: 9
Training loss: 0.07820852100849152
Validation loss: 1.471370042011302

Epoch: 6| Step: 10
Training loss: 0.100478895008564
Validation loss: 1.4905496220434866

Epoch: 6| Step: 11
Training loss: 0.12988339364528656
Validation loss: 1.5187708972602763

Epoch: 6| Step: 12
Training loss: 0.14630313217639923
Validation loss: 1.540341910495553

Epoch: 6| Step: 13
Training loss: 0.07424405962228775
Validation loss: 1.518630741744913

Epoch: 434| Step: 0
Training loss: 0.14143629372119904
Validation loss: 1.519609558966852

Epoch: 6| Step: 1
Training loss: 0.11131313443183899
Validation loss: 1.5181303472929104

Epoch: 6| Step: 2
Training loss: 0.10359175503253937
Validation loss: 1.502420207505585

Epoch: 6| Step: 3
Training loss: 0.0795646607875824
Validation loss: 1.4969484966288331

Epoch: 6| Step: 4
Training loss: 0.08493489027023315
Validation loss: 1.4865274416503085

Epoch: 6| Step: 5
Training loss: 0.1017536148428917
Validation loss: 1.4951592145427581

Epoch: 6| Step: 6
Training loss: 0.16882269084453583
Validation loss: 1.5080964501186083

Epoch: 6| Step: 7
Training loss: 0.07929082214832306
Validation loss: 1.4504803380658549

Epoch: 6| Step: 8
Training loss: 0.19366002082824707
Validation loss: 1.4644832546992967

Epoch: 6| Step: 9
Training loss: 0.21876683831214905
Validation loss: 1.429133839504693

Epoch: 6| Step: 10
Training loss: 0.12772081792354584
Validation loss: 1.43155683753311

Epoch: 6| Step: 11
Training loss: 0.1357998549938202
Validation loss: 1.400050647797123

Epoch: 6| Step: 12
Training loss: 0.10916867107152939
Validation loss: 1.4077463432024884

Epoch: 6| Step: 13
Training loss: 0.07206431776285172
Validation loss: 1.4513124406978648

Epoch: 435| Step: 0
Training loss: 0.16796518862247467
Validation loss: 1.4747711945605535

Epoch: 6| Step: 1
Training loss: 0.07619746774435043
Validation loss: 1.4753300528372488

Epoch: 6| Step: 2
Training loss: 0.08473455160856247
Validation loss: 1.496422638175308

Epoch: 6| Step: 3
Training loss: 0.11749748140573502
Validation loss: 1.4915823782643964

Epoch: 6| Step: 4
Training loss: 0.08078034222126007
Validation loss: 1.5331653010460637

Epoch: 6| Step: 5
Training loss: 0.14546562731266022
Validation loss: 1.5323393960152902

Epoch: 6| Step: 6
Training loss: 0.08282145857810974
Validation loss: 1.5323406291264359

Epoch: 6| Step: 7
Training loss: 0.17867805063724518
Validation loss: 1.5280762103296095

Epoch: 6| Step: 8
Training loss: 0.1575770080089569
Validation loss: 1.529762694912572

Epoch: 6| Step: 9
Training loss: 0.0722295492887497
Validation loss: 1.506579916964295

Epoch: 6| Step: 10
Training loss: 0.08590850979089737
Validation loss: 1.5175456193185621

Epoch: 6| Step: 11
Training loss: 0.07438969612121582
Validation loss: 1.4911016059178177

Epoch: 6| Step: 12
Training loss: 0.0876486599445343
Validation loss: 1.4828308692542456

Epoch: 6| Step: 13
Training loss: 0.10695847123861313
Validation loss: 1.5238605148048812

Epoch: 436| Step: 0
Training loss: 0.1071847677230835
Validation loss: 1.49318685454707

Epoch: 6| Step: 1
Training loss: 0.08185169100761414
Validation loss: 1.5037320788188646

Epoch: 6| Step: 2
Training loss: 0.07284758239984512
Validation loss: 1.4937397049319359

Epoch: 6| Step: 3
Training loss: 0.08224226534366608
Validation loss: 1.509155023482538

Epoch: 6| Step: 4
Training loss: 0.1924605667591095
Validation loss: 1.5139349006837415

Epoch: 6| Step: 5
Training loss: 0.07566998153924942
Validation loss: 1.5405498461056781

Epoch: 6| Step: 6
Training loss: 0.13565155863761902
Validation loss: 1.5256195478541876

Epoch: 6| Step: 7
Training loss: 0.0892844945192337
Validation loss: 1.529398605387698

Epoch: 6| Step: 8
Training loss: 0.06034151464700699
Validation loss: 1.5810773808469054

Epoch: 6| Step: 9
Training loss: 0.08883605897426605
Validation loss: 1.5604169150834442

Epoch: 6| Step: 10
Training loss: 0.10356208682060242
Validation loss: 1.5635087349081551

Epoch: 6| Step: 11
Training loss: 0.18066908419132233
Validation loss: 1.57189223330508

Epoch: 6| Step: 12
Training loss: 0.0724961906671524
Validation loss: 1.5599297964444725

Epoch: 6| Step: 13
Training loss: 0.12041527777910233
Validation loss: 1.5708392140685872

Epoch: 437| Step: 0
Training loss: 0.08848355710506439
Validation loss: 1.5513602418284262

Epoch: 6| Step: 1
Training loss: 0.09983521699905396
Validation loss: 1.5073727971764022

Epoch: 6| Step: 2
Training loss: 0.06374939531087875
Validation loss: 1.5228559047945085

Epoch: 6| Step: 3
Training loss: 0.1749488264322281
Validation loss: 1.510501362944162

Epoch: 6| Step: 4
Training loss: 0.1283199042081833
Validation loss: 1.4521505935217744

Epoch: 6| Step: 5
Training loss: 0.10054302960634232
Validation loss: 1.4567959129169423

Epoch: 6| Step: 6
Training loss: 0.10853902250528336
Validation loss: 1.484289457721095

Epoch: 6| Step: 7
Training loss: 0.08427558839321136
Validation loss: 1.4767534322636102

Epoch: 6| Step: 8
Training loss: 0.06623835861682892
Validation loss: 1.5001817390482912

Epoch: 6| Step: 9
Training loss: 0.06584860384464264
Validation loss: 1.5347142783544396

Epoch: 6| Step: 10
Training loss: 0.15174224972724915
Validation loss: 1.5448286956356418

Epoch: 6| Step: 11
Training loss: 0.07966474443674088
Validation loss: 1.5628501202470513

Epoch: 6| Step: 12
Training loss: 0.15338335931301117
Validation loss: 1.611143058346164

Epoch: 6| Step: 13
Training loss: 0.14898595213890076
Validation loss: 1.5656655655112317

Epoch: 438| Step: 0
Training loss: 0.09128522872924805
Validation loss: 1.5757393836975098

Epoch: 6| Step: 1
Training loss: 0.15033887326717377
Validation loss: 1.5762485842550955

Epoch: 6| Step: 2
Training loss: 0.09967350959777832
Validation loss: 1.549141888977379

Epoch: 6| Step: 3
Training loss: 0.11996279656887054
Validation loss: 1.5257414412754837

Epoch: 6| Step: 4
Training loss: 0.06780600547790527
Validation loss: 1.521176540723411

Epoch: 6| Step: 5
Training loss: 0.16438394784927368
Validation loss: 1.5130552848180134

Epoch: 6| Step: 6
Training loss: 0.11294631659984589
Validation loss: 1.5362216247025358

Epoch: 6| Step: 7
Training loss: 0.1527637392282486
Validation loss: 1.5183156626198882

Epoch: 6| Step: 8
Training loss: 0.17503395676612854
Validation loss: 1.5787428335476947

Epoch: 6| Step: 9
Training loss: 0.2097814828157425
Validation loss: 1.5755165200079642

Epoch: 6| Step: 10
Training loss: 0.18555289506912231
Validation loss: 1.547460183020561

Epoch: 6| Step: 11
Training loss: 0.17111288011074066
Validation loss: 1.538019121334117

Epoch: 6| Step: 12
Training loss: 0.11056171357631683
Validation loss: 1.5093531044580604

Epoch: 6| Step: 13
Training loss: 0.10651711374521255
Validation loss: 1.5072313816316667

Epoch: 439| Step: 0
Training loss: 0.1432090401649475
Validation loss: 1.4828771532222789

Epoch: 6| Step: 1
Training loss: 0.1851557195186615
Validation loss: 1.525878252521638

Epoch: 6| Step: 2
Training loss: 0.09701386839151382
Validation loss: 1.5212914072057253

Epoch: 6| Step: 3
Training loss: 0.1298188716173172
Validation loss: 1.5445496318160847

Epoch: 6| Step: 4
Training loss: 0.16434206068515778
Validation loss: 1.5425744556611585

Epoch: 6| Step: 5
Training loss: 0.1296812891960144
Validation loss: 1.5501806851356261

Epoch: 6| Step: 6
Training loss: 0.09708873182535172
Validation loss: 1.5623749340734174

Epoch: 6| Step: 7
Training loss: 0.1591878980398178
Validation loss: 1.5749857092416415

Epoch: 6| Step: 8
Training loss: 0.16566593945026398
Validation loss: 1.6162060614555114

Epoch: 6| Step: 9
Training loss: 0.13650104403495789
Validation loss: 1.5859021499592771

Epoch: 6| Step: 10
Training loss: 0.07226032763719559
Validation loss: 1.536553293146113

Epoch: 6| Step: 11
Training loss: 0.13248029351234436
Validation loss: 1.5384387495697185

Epoch: 6| Step: 12
Training loss: 0.11619038879871368
Validation loss: 1.5382625543943016

Epoch: 6| Step: 13
Training loss: 0.11747196316719055
Validation loss: 1.5322824896022837

Epoch: 440| Step: 0
Training loss: 0.10450994223356247
Validation loss: 1.5226261897753643

Epoch: 6| Step: 1
Training loss: 0.13878612220287323
Validation loss: 1.5329812258802435

Epoch: 6| Step: 2
Training loss: 0.07909578084945679
Validation loss: 1.539249723957431

Epoch: 6| Step: 3
Training loss: 0.12490630149841309
Validation loss: 1.5238769823505032

Epoch: 6| Step: 4
Training loss: 0.0990801528096199
Validation loss: 1.5298655033111572

Epoch: 6| Step: 5
Training loss: 0.16609998047351837
Validation loss: 1.5327756481785928

Epoch: 6| Step: 6
Training loss: 0.1221494972705841
Validation loss: 1.5378570300276562

Epoch: 6| Step: 7
Training loss: 0.11517061293125153
Validation loss: 1.561041957588606

Epoch: 6| Step: 8
Training loss: 0.24801021814346313
Validation loss: 1.5978638267004361

Epoch: 6| Step: 9
Training loss: 0.17240263521671295
Validation loss: 1.6409608843506023

Epoch: 6| Step: 10
Training loss: 0.1300419270992279
Validation loss: 1.6040927363980202

Epoch: 6| Step: 11
Training loss: 0.10699041187763214
Validation loss: 1.5768277132382957

Epoch: 6| Step: 12
Training loss: 0.14054125547409058
Validation loss: 1.5908234016869658

Epoch: 6| Step: 13
Training loss: 0.10622742027044296
Validation loss: 1.5684392952149915

Epoch: 441| Step: 0
Training loss: 0.1626782864332199
Validation loss: 1.5669059368871874

Epoch: 6| Step: 1
Training loss: 0.09556020796298981
Validation loss: 1.5272968353763703

Epoch: 6| Step: 2
Training loss: 0.17208066582679749
Validation loss: 1.5176567223764235

Epoch: 6| Step: 3
Training loss: 0.10623975098133087
Validation loss: 1.5138232169612762

Epoch: 6| Step: 4
Training loss: 0.11121658235788345
Validation loss: 1.504235694485326

Epoch: 6| Step: 5
Training loss: 0.1055525541305542
Validation loss: 1.5144627812088176

Epoch: 6| Step: 6
Training loss: 0.10304059088230133
Validation loss: 1.511598111480795

Epoch: 6| Step: 7
Training loss: 0.08467521518468857
Validation loss: 1.5362482352923321

Epoch: 6| Step: 8
Training loss: 0.08763953298330307
Validation loss: 1.5354336538622457

Epoch: 6| Step: 9
Training loss: 0.062303755432367325
Validation loss: 1.5454012757988387

Epoch: 6| Step: 10
Training loss: 0.13246026635169983
Validation loss: 1.5195692521269604

Epoch: 6| Step: 11
Training loss: 0.11392795294523239
Validation loss: 1.5620119469140166

Epoch: 6| Step: 12
Training loss: 0.11617304384708405
Validation loss: 1.5693517961809713

Epoch: 6| Step: 13
Training loss: 0.11449149250984192
Validation loss: 1.5725543806629796

Epoch: 442| Step: 0
Training loss: 0.08396564424037933
Validation loss: 1.568884272729197

Epoch: 6| Step: 1
Training loss: 0.07980012893676758
Validation loss: 1.5365421695093955

Epoch: 6| Step: 2
Training loss: 0.11715438961982727
Validation loss: 1.537029202266406

Epoch: 6| Step: 3
Training loss: 0.06305373460054398
Validation loss: 1.470039221548265

Epoch: 6| Step: 4
Training loss: 0.09780573844909668
Validation loss: 1.4631727254518898

Epoch: 6| Step: 5
Training loss: 0.10406181961297989
Validation loss: 1.4617334924718386

Epoch: 6| Step: 6
Training loss: 0.08814764767885208
Validation loss: 1.4734122599324873

Epoch: 6| Step: 7
Training loss: 0.13757377862930298
Validation loss: 1.4484624555034022

Epoch: 6| Step: 8
Training loss: 0.13942718505859375
Validation loss: 1.4365979856060398

Epoch: 6| Step: 9
Training loss: 0.08939126133918762
Validation loss: 1.4843851789351432

Epoch: 6| Step: 10
Training loss: 0.08218567073345184
Validation loss: 1.4691817529739872

Epoch: 6| Step: 11
Training loss: 0.10774478316307068
Validation loss: 1.483440133833116

Epoch: 6| Step: 12
Training loss: 0.08986669778823853
Validation loss: 1.4908380534059258

Epoch: 6| Step: 13
Training loss: 0.15328343212604523
Validation loss: 1.505066575542573

Epoch: 443| Step: 0
Training loss: 0.09206615388393402
Validation loss: 1.5143908210979995

Epoch: 6| Step: 1
Training loss: 0.1532076597213745
Validation loss: 1.5041590262484807

Epoch: 6| Step: 2
Training loss: 0.08975546061992645
Validation loss: 1.5190139688471311

Epoch: 6| Step: 3
Training loss: 0.11458682268857956
Validation loss: 1.4960700683696295

Epoch: 6| Step: 4
Training loss: 0.08977850526571274
Validation loss: 1.5004740017716602

Epoch: 6| Step: 5
Training loss: 0.0743865817785263
Validation loss: 1.4973111550013225

Epoch: 6| Step: 6
Training loss: 0.07351980358362198
Validation loss: 1.4829547712879796

Epoch: 6| Step: 7
Training loss: 0.12135859578847885
Validation loss: 1.4913629107577826

Epoch: 6| Step: 8
Training loss: 0.073865607380867
Validation loss: 1.5139363529861614

Epoch: 6| Step: 9
Training loss: 0.09071594476699829
Validation loss: 1.5061421278984315

Epoch: 6| Step: 10
Training loss: 0.08351509273052216
Validation loss: 1.5103287607110956

Epoch: 6| Step: 11
Training loss: 0.10061038285493851
Validation loss: 1.475004772986135

Epoch: 6| Step: 12
Training loss: 0.11307403445243835
Validation loss: 1.4932338037798483

Epoch: 6| Step: 13
Training loss: 0.0876934677362442
Validation loss: 1.4788142442703247

Epoch: 444| Step: 0
Training loss: 0.08836463838815689
Validation loss: 1.4866138735125143

Epoch: 6| Step: 1
Training loss: 0.12481896579265594
Validation loss: 1.4979339440663655

Epoch: 6| Step: 2
Training loss: 0.14916005730628967
Validation loss: 1.4856916114848147

Epoch: 6| Step: 3
Training loss: 0.11685357987880707
Validation loss: 1.4926390135160057

Epoch: 6| Step: 4
Training loss: 0.06732000410556793
Validation loss: 1.509931058012029

Epoch: 6| Step: 5
Training loss: 0.09952379763126373
Validation loss: 1.5242704037697083

Epoch: 6| Step: 6
Training loss: 0.07792901247739792
Validation loss: 1.5272837326090822

Epoch: 6| Step: 7
Training loss: 0.07427425682544708
Validation loss: 1.5221895056386148

Epoch: 6| Step: 8
Training loss: 0.12405714392662048
Validation loss: 1.5115357278495707

Epoch: 6| Step: 9
Training loss: 0.1087377518415451
Validation loss: 1.4915423406067716

Epoch: 6| Step: 10
Training loss: 0.1038205549120903
Validation loss: 1.5072589612776233

Epoch: 6| Step: 11
Training loss: 0.09050510823726654
Validation loss: 1.552497967596977

Epoch: 6| Step: 12
Training loss: 0.10657674074172974
Validation loss: 1.5356211213655369

Epoch: 6| Step: 13
Training loss: 0.073504239320755
Validation loss: 1.5296803802572272

Epoch: 445| Step: 0
Training loss: 0.08657442033290863
Validation loss: 1.5238328024905214

Epoch: 6| Step: 1
Training loss: 0.0854903981089592
Validation loss: 1.5329983811224661

Epoch: 6| Step: 2
Training loss: 0.17383205890655518
Validation loss: 1.5322397114128194

Epoch: 6| Step: 3
Training loss: 0.10769037902355194
Validation loss: 1.5573429343520955

Epoch: 6| Step: 4
Training loss: 0.09662254899740219
Validation loss: 1.5321128599105343

Epoch: 6| Step: 5
Training loss: 0.07325077056884766
Validation loss: 1.5438758237387544

Epoch: 6| Step: 6
Training loss: 0.0726739913225174
Validation loss: 1.5251666884268484

Epoch: 6| Step: 7
Training loss: 0.0673426166176796
Validation loss: 1.5149994345121487

Epoch: 6| Step: 8
Training loss: 0.08891046792268753
Validation loss: 1.5044803696293985

Epoch: 6| Step: 9
Training loss: 0.11941076070070267
Validation loss: 1.5263167171068088

Epoch: 6| Step: 10
Training loss: 0.06235995143651962
Validation loss: 1.5242723688002555

Epoch: 6| Step: 11
Training loss: 0.08595065772533417
Validation loss: 1.5315634396768385

Epoch: 6| Step: 12
Training loss: 0.0973164290189743
Validation loss: 1.5267241475402669

Epoch: 6| Step: 13
Training loss: 0.1877790093421936
Validation loss: 1.5252533189712032

Epoch: 446| Step: 0
Training loss: 0.0864100307226181
Validation loss: 1.5222627398788289

Epoch: 6| Step: 1
Training loss: 0.11508537828922272
Validation loss: 1.5174154543107556

Epoch: 6| Step: 2
Training loss: 0.06209205090999603
Validation loss: 1.5238888314975205

Epoch: 6| Step: 3
Training loss: 0.11072979867458344
Validation loss: 1.530549600560178

Epoch: 6| Step: 4
Training loss: 0.087893046438694
Validation loss: 1.5361232719113749

Epoch: 6| Step: 5
Training loss: 0.10386012494564056
Validation loss: 1.510934857911961

Epoch: 6| Step: 6
Training loss: 0.10399703681468964
Validation loss: 1.5331856268708424

Epoch: 6| Step: 7
Training loss: 0.09358596056699753
Validation loss: 1.5258181043850478

Epoch: 6| Step: 8
Training loss: 0.14876961708068848
Validation loss: 1.5359618144650613

Epoch: 6| Step: 9
Training loss: 0.09981989115476608
Validation loss: 1.5311742136555333

Epoch: 6| Step: 10
Training loss: 0.10496877133846283
Validation loss: 1.4855414577709731

Epoch: 6| Step: 11
Training loss: 0.0841934084892273
Validation loss: 1.5224476322051017

Epoch: 6| Step: 12
Training loss: 0.13589146733283997
Validation loss: 1.516255505623356

Epoch: 6| Step: 13
Training loss: 0.1314936727285385
Validation loss: 1.5047921262761599

Epoch: 447| Step: 0
Training loss: 0.08787459135055542
Validation loss: 1.5083852006543068

Epoch: 6| Step: 1
Training loss: 0.1644119918346405
Validation loss: 1.5350508016924704

Epoch: 6| Step: 2
Training loss: 0.14771315455436707
Validation loss: 1.5399878409601027

Epoch: 6| Step: 3
Training loss: 0.15426170825958252
Validation loss: 1.531470332094418

Epoch: 6| Step: 4
Training loss: 0.22123214602470398
Validation loss: 1.5296230700708204

Epoch: 6| Step: 5
Training loss: 0.10836467891931534
Validation loss: 1.5106448076104606

Epoch: 6| Step: 6
Training loss: 0.0893743634223938
Validation loss: 1.4910135807529572

Epoch: 6| Step: 7
Training loss: 0.12342645972967148
Validation loss: 1.497795436971931

Epoch: 6| Step: 8
Training loss: 0.10925254225730896
Validation loss: 1.523649808540139

Epoch: 6| Step: 9
Training loss: 0.08619024604558945
Validation loss: 1.52309363759974

Epoch: 6| Step: 10
Training loss: 0.0891532376408577
Validation loss: 1.54353412248755

Epoch: 6| Step: 11
Training loss: 0.16384832561016083
Validation loss: 1.5002401759547572

Epoch: 6| Step: 12
Training loss: 0.08457347750663757
Validation loss: 1.493474511049127

Epoch: 6| Step: 13
Training loss: 0.1374104619026184
Validation loss: 1.5079573508231872

Epoch: 448| Step: 0
Training loss: 0.05681310594081879
Validation loss: 1.50508758073212

Epoch: 6| Step: 1
Training loss: 0.0864061564207077
Validation loss: 1.4582664287218483

Epoch: 6| Step: 2
Training loss: 0.07244810461997986
Validation loss: 1.5087310152669107

Epoch: 6| Step: 3
Training loss: 0.1252298355102539
Validation loss: 1.4824860070341377

Epoch: 6| Step: 4
Training loss: 0.13823717832565308
Validation loss: 1.4625820959767988

Epoch: 6| Step: 5
Training loss: 0.12220693379640579
Validation loss: 1.5070482351446663

Epoch: 6| Step: 6
Training loss: 0.06580717861652374
Validation loss: 1.4716342008242043

Epoch: 6| Step: 7
Training loss: 0.10663408041000366
Validation loss: 1.4975349210923719

Epoch: 6| Step: 8
Training loss: 0.07614026218652725
Validation loss: 1.4953274694822167

Epoch: 6| Step: 9
Training loss: 0.1286546289920807
Validation loss: 1.4947349755994734

Epoch: 6| Step: 10
Training loss: 0.19883935153484344
Validation loss: 1.5507084887514833

Epoch: 6| Step: 11
Training loss: 0.21473616361618042
Validation loss: 1.5243383581920336

Epoch: 6| Step: 12
Training loss: 0.08180226385593414
Validation loss: 1.503937808416223

Epoch: 6| Step: 13
Training loss: 0.07600288838148117
Validation loss: 1.5083662079226585

Epoch: 449| Step: 0
Training loss: 0.08570953458547592
Validation loss: 1.5026404255179948

Epoch: 6| Step: 1
Training loss: 0.06851906329393387
Validation loss: 1.4813849810631043

Epoch: 6| Step: 2
Training loss: 0.0917590856552124
Validation loss: 1.5007006763130106

Epoch: 6| Step: 3
Training loss: 0.09008218348026276
Validation loss: 1.490076470118697

Epoch: 6| Step: 4
Training loss: 0.19487528502941132
Validation loss: 1.5084670666725404

Epoch: 6| Step: 5
Training loss: 0.11053651571273804
Validation loss: 1.5367292575938727

Epoch: 6| Step: 6
Training loss: 0.07523995637893677
Validation loss: 1.516615176713595

Epoch: 6| Step: 7
Training loss: 0.09017442166805267
Validation loss: 1.5063364044312508

Epoch: 6| Step: 8
Training loss: 0.09262239933013916
Validation loss: 1.488237210499343

Epoch: 6| Step: 9
Training loss: 0.1288938671350479
Validation loss: 1.490442716947166

Epoch: 6| Step: 10
Training loss: 0.13040131330490112
Validation loss: 1.5360691367938955

Epoch: 6| Step: 11
Training loss: 0.12017466872930527
Validation loss: 1.519831621518699

Epoch: 6| Step: 12
Training loss: 0.06055695563554764
Validation loss: 1.5440440267644904

Epoch: 6| Step: 13
Training loss: 0.09131547808647156
Validation loss: 1.5166037313399776

Epoch: 450| Step: 0
Training loss: 0.10269245505332947
Validation loss: 1.4959613264247935

Epoch: 6| Step: 1
Training loss: 0.08031927794218063
Validation loss: 1.5265636597910235

Epoch: 6| Step: 2
Training loss: 0.14404356479644775
Validation loss: 1.5323051124490716

Epoch: 6| Step: 3
Training loss: 0.07360417395830154
Validation loss: 1.5033486645708802

Epoch: 6| Step: 4
Training loss: 0.15827186405658722
Validation loss: 1.5005949210095149

Epoch: 6| Step: 5
Training loss: 0.07698342204093933
Validation loss: 1.480953307561977

Epoch: 6| Step: 6
Training loss: 0.06865828484296799
Validation loss: 1.4917247372288858

Epoch: 6| Step: 7
Training loss: 0.09590534120798111
Validation loss: 1.4814717141530847

Epoch: 6| Step: 8
Training loss: 0.12945520877838135
Validation loss: 1.469515383884471

Epoch: 6| Step: 9
Training loss: 0.06020679697394371
Validation loss: 1.4918191766226163

Epoch: 6| Step: 10
Training loss: 0.10703670978546143
Validation loss: 1.49408798063955

Epoch: 6| Step: 11
Training loss: 0.08841376006603241
Validation loss: 1.5006909049967283

Epoch: 6| Step: 12
Training loss: 0.15464356541633606
Validation loss: 1.4536200114475784

Epoch: 6| Step: 13
Training loss: 0.07701800763607025
Validation loss: 1.4753985417786466

Testing loss: 2.3993633217281767
