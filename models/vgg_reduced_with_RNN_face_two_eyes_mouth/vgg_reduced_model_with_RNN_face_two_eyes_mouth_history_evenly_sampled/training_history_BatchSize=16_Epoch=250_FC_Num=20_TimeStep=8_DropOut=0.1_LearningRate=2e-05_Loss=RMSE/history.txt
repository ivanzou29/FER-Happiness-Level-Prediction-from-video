Epoch: 1| Step: 0
Training loss: 6.648208560431019
Validation loss: 5.729558254369382

Epoch: 6| Step: 1
Training loss: 5.376688847142298
Validation loss: 5.705204539683901

Epoch: 6| Step: 2
Training loss: 5.014158801101738
Validation loss: 5.684303370706616

Epoch: 6| Step: 3
Training loss: 6.125511303794171
Validation loss: 5.665154678226684

Epoch: 6| Step: 4
Training loss: 5.66943643234927
Validation loss: 5.645253613679501

Epoch: 6| Step: 5
Training loss: 5.744974344991401
Validation loss: 5.621812314169773

Epoch: 6| Step: 6
Training loss: 5.033355461897217
Validation loss: 5.595458355028761

Epoch: 6| Step: 7
Training loss: 5.1229076301129925
Validation loss: 5.56447283998605

Epoch: 6| Step: 8
Training loss: 5.8617462649710745
Validation loss: 5.52930054151744

Epoch: 6| Step: 9
Training loss: 6.155566492235465
Validation loss: 5.489322257404358

Epoch: 6| Step: 10
Training loss: 5.382218769697837
Validation loss: 5.444260423488731

Epoch: 6| Step: 11
Training loss: 5.319787984079501
Validation loss: 5.393978265467892

Epoch: 6| Step: 12
Training loss: 5.402929090894167
Validation loss: 5.3396413720206395

Epoch: 6| Step: 13
Training loss: 5.084271745623911
Validation loss: 5.280908771502376

Epoch: 2| Step: 0
Training loss: 4.478570990172386
Validation loss: 5.2184384367033765

Epoch: 6| Step: 1
Training loss: 5.611951146125909
Validation loss: 5.1525668346946

Epoch: 6| Step: 2
Training loss: 4.822314274891291
Validation loss: 5.0839031827358925

Epoch: 6| Step: 3
Training loss: 6.295186992652477
Validation loss: 5.018251700556949

Epoch: 6| Step: 4
Training loss: 5.353807944465844
Validation loss: 4.9491122751895364

Epoch: 6| Step: 5
Training loss: 5.270710015142239
Validation loss: 4.883648250468374

Epoch: 6| Step: 6
Training loss: 3.998308777907991
Validation loss: 4.81846764946058

Epoch: 6| Step: 7
Training loss: 5.1424514633210014
Validation loss: 4.757611478577897

Epoch: 6| Step: 8
Training loss: 4.511621515456551
Validation loss: 4.6941718548052895

Epoch: 6| Step: 9
Training loss: 4.617698886390395
Validation loss: 4.6312765331631125

Epoch: 6| Step: 10
Training loss: 5.3200844871294395
Validation loss: 4.565586293072243

Epoch: 6| Step: 11
Training loss: 4.306056862363095
Validation loss: 4.506732528016196

Epoch: 6| Step: 12
Training loss: 3.6709640346875814
Validation loss: 4.4537038395594815

Epoch: 6| Step: 13
Training loss: 4.519660387362069
Validation loss: 4.405275466170711

Epoch: 3| Step: 0
Training loss: 5.144193668629343
Validation loss: 4.359392915088251

Epoch: 6| Step: 1
Training loss: 4.710781215017496
Validation loss: 4.3150198875733885

Epoch: 6| Step: 2
Training loss: 4.132152483036705
Validation loss: 4.270846811308805

Epoch: 6| Step: 3
Training loss: 5.541714871227972
Validation loss: 4.226652196332294

Epoch: 6| Step: 4
Training loss: 3.6686398803197036
Validation loss: 4.183424174436132

Epoch: 6| Step: 5
Training loss: 3.0260178548080625
Validation loss: 4.144956055135384

Epoch: 6| Step: 6
Training loss: 3.2591523632989707
Validation loss: 4.114372016004775

Epoch: 6| Step: 7
Training loss: 5.140076210852242
Validation loss: 4.09011627197271

Epoch: 6| Step: 8
Training loss: 3.256321847309722
Validation loss: 4.064166407686325

Epoch: 6| Step: 9
Training loss: 4.511892921421673
Validation loss: 4.040446073124148

Epoch: 6| Step: 10
Training loss: 3.734219855114394
Validation loss: 4.0141885897747915

Epoch: 6| Step: 11
Training loss: 3.613393948833669
Validation loss: 3.995405919879909

Epoch: 6| Step: 12
Training loss: 4.5180978307040345
Validation loss: 3.9774967179858787

Epoch: 6| Step: 13
Training loss: 5.000590670982361
Validation loss: 3.96116581831344

Epoch: 4| Step: 0
Training loss: 3.788486838116639
Validation loss: 3.947832525758585

Epoch: 6| Step: 1
Training loss: 4.37252519638453
Validation loss: 3.918603685601951

Epoch: 6| Step: 2
Training loss: 3.9346193948213712
Validation loss: 3.901783074742321

Epoch: 6| Step: 3
Training loss: 4.612466066644001
Validation loss: 3.8846652113558005

Epoch: 6| Step: 4
Training loss: 3.2720014749910717
Validation loss: 3.86736408094422

Epoch: 6| Step: 5
Training loss: 4.344937608137028
Validation loss: 3.8524765916455896

Epoch: 6| Step: 6
Training loss: 4.528710646893994
Validation loss: 3.83265517300993

Epoch: 6| Step: 7
Training loss: 4.961422297301269
Validation loss: 3.814723207993105

Epoch: 6| Step: 8
Training loss: 3.8107330730392386
Validation loss: 3.7934256990696595

Epoch: 6| Step: 9
Training loss: 4.379791687492691
Validation loss: 3.7817549097631433

Epoch: 6| Step: 10
Training loss: 2.9167137868798845
Validation loss: 3.7591217845796607

Epoch: 6| Step: 11
Training loss: 2.649566499772887
Validation loss: 3.7408257285687037

Epoch: 6| Step: 12
Training loss: 3.9862812344130947
Validation loss: 3.731835342203571

Epoch: 6| Step: 13
Training loss: 3.6373830612629723
Validation loss: 3.7158156775749815

Epoch: 5| Step: 0
Training loss: 4.130474734604138
Validation loss: 3.7122600961424466

Epoch: 6| Step: 1
Training loss: 4.489820410656343
Validation loss: 3.681149319530138

Epoch: 6| Step: 2
Training loss: 4.108607463447474
Validation loss: 3.6698094702625585

Epoch: 6| Step: 3
Training loss: 4.098393027631141
Validation loss: 3.6564118986042313

Epoch: 6| Step: 4
Training loss: 4.054017116275255
Validation loss: 3.6477064523802527

Epoch: 6| Step: 5
Training loss: 3.8403055528429997
Validation loss: 3.6336703008086957

Epoch: 6| Step: 6
Training loss: 3.7208651129435886
Validation loss: 3.6166219631324554

Epoch: 6| Step: 7
Training loss: 4.383003325906476
Validation loss: 3.5991274627417242

Epoch: 6| Step: 8
Training loss: 3.866016310774353
Validation loss: 3.580890535926578

Epoch: 6| Step: 9
Training loss: 3.5082803596852576
Validation loss: 3.562909550163253

Epoch: 6| Step: 10
Training loss: 2.975713814121285
Validation loss: 3.5512299752016894

Epoch: 6| Step: 11
Training loss: 3.0473186463368105
Validation loss: 3.543201033575209

Epoch: 6| Step: 12
Training loss: 3.3497700911243316
Validation loss: 3.5427661692259527

Epoch: 6| Step: 13
Training loss: 3.2839968854770922
Validation loss: 3.5225280223856013

Epoch: 6| Step: 0
Training loss: 3.868158638518666
Validation loss: 3.52544283564187

Epoch: 6| Step: 1
Training loss: 3.481097540264976
Validation loss: 3.5069017071744244

Epoch: 6| Step: 2
Training loss: 5.062396766646133
Validation loss: 3.5012709628972694

Epoch: 6| Step: 3
Training loss: 3.5386346891070377
Validation loss: 3.4913076407414074

Epoch: 6| Step: 4
Training loss: 3.0933500089141104
Validation loss: 3.484412567364361

Epoch: 6| Step: 5
Training loss: 3.3582699399759535
Validation loss: 3.4740955404218816

Epoch: 6| Step: 6
Training loss: 3.626605500472127
Validation loss: 3.461773829034775

Epoch: 6| Step: 7
Training loss: 4.022646216941022
Validation loss: 3.451774468558906

Epoch: 6| Step: 8
Training loss: 3.4339339746294275
Validation loss: 3.443666820118228

Epoch: 6| Step: 9
Training loss: 4.022938047352571
Validation loss: 3.433873341408875

Epoch: 6| Step: 10
Training loss: 3.0393339295762867
Validation loss: 3.4240166452098317

Epoch: 6| Step: 11
Training loss: 3.5358430142659336
Validation loss: 3.41727034045171

Epoch: 6| Step: 12
Training loss: 3.202826509291536
Validation loss: 3.4160393640011386

Epoch: 6| Step: 13
Training loss: 3.923604272406966
Validation loss: 3.402187167633025

Epoch: 7| Step: 0
Training loss: 3.4372908095083923
Validation loss: 3.387017535138793

Epoch: 6| Step: 1
Training loss: 3.0931838317073623
Validation loss: 3.3792962694148643

Epoch: 6| Step: 2
Training loss: 4.10274025129304
Validation loss: 3.373823060187855

Epoch: 6| Step: 3
Training loss: 3.8836909630164733
Validation loss: 3.367907023702421

Epoch: 6| Step: 4
Training loss: 3.20291896250453
Validation loss: 3.3601486944393613

Epoch: 6| Step: 5
Training loss: 3.4407840646949057
Validation loss: 3.3518262662272207

Epoch: 6| Step: 6
Training loss: 3.868980901233725
Validation loss: 3.3467144234938258

Epoch: 6| Step: 7
Training loss: 2.2915515061544847
Validation loss: 3.3406187232886055

Epoch: 6| Step: 8
Training loss: 3.622376380427563
Validation loss: 3.335424056471587

Epoch: 6| Step: 9
Training loss: 2.838549543363976
Validation loss: 3.329835461332421

Epoch: 6| Step: 10
Training loss: 4.204428091449761
Validation loss: 3.3239772381090376

Epoch: 6| Step: 11
Training loss: 4.003800970414658
Validation loss: 3.3205017723073342

Epoch: 6| Step: 12
Training loss: 3.4439777721259266
Validation loss: 3.3127531766348244

Epoch: 6| Step: 13
Training loss: 4.541676069244078
Validation loss: 3.3094141078313317

Epoch: 8| Step: 0
Training loss: 3.0244878477236163
Validation loss: 3.303277150252668

Epoch: 6| Step: 1
Training loss: 3.8365090249357015
Validation loss: 3.299348453191253

Epoch: 6| Step: 2
Training loss: 3.084687494064051
Validation loss: 3.3119799243798993

Epoch: 6| Step: 3
Training loss: 3.3766161969534414
Validation loss: 3.285061922082704

Epoch: 6| Step: 4
Training loss: 4.6122917645184724
Validation loss: 3.2864830778408707

Epoch: 6| Step: 5
Training loss: 4.076706211982703
Validation loss: 3.281146324539493

Epoch: 6| Step: 6
Training loss: 3.6713601908059585
Validation loss: 3.273065024482177

Epoch: 6| Step: 7
Training loss: 3.356834977244655
Validation loss: 3.2665852228483767

Epoch: 6| Step: 8
Training loss: 2.363766354040805
Validation loss: 3.2611729366184496

Epoch: 6| Step: 9
Training loss: 2.5880151797856175
Validation loss: 3.2730181902690663

Epoch: 6| Step: 10
Training loss: 3.895728873146072
Validation loss: 3.2647484043776047

Epoch: 6| Step: 11
Training loss: 3.740586354399433
Validation loss: 3.2550522271246742

Epoch: 6| Step: 12
Training loss: 3.4992623232977227
Validation loss: 3.2417562669172164

Epoch: 6| Step: 13
Training loss: 3.5135177061091607
Validation loss: 3.243999875168009

Epoch: 9| Step: 0
Training loss: 3.4283850766809714
Validation loss: 3.2394678713642033

Epoch: 6| Step: 1
Training loss: 4.133344590776762
Validation loss: 3.2478425979864243

Epoch: 6| Step: 2
Training loss: 2.834571362205242
Validation loss: 3.233792770617056

Epoch: 6| Step: 3
Training loss: 3.159371824479889
Validation loss: 3.2243385722220204

Epoch: 6| Step: 4
Training loss: 3.3542131377292392
Validation loss: 3.2128709401692337

Epoch: 6| Step: 5
Training loss: 3.220013416807288
Validation loss: 3.2067245511210314

Epoch: 6| Step: 6
Training loss: 3.481067267780808
Validation loss: 3.20063593388042

Epoch: 6| Step: 7
Training loss: 3.991855674733904
Validation loss: 3.1989173655547085

Epoch: 6| Step: 8
Training loss: 3.732704459311828
Validation loss: 3.215980639065207

Epoch: 6| Step: 9
Training loss: 3.404938891698524
Validation loss: 3.1872031942087564

Epoch: 6| Step: 10
Training loss: 3.1968442794203775
Validation loss: 3.1968768592047754

Epoch: 6| Step: 11
Training loss: 3.973055809130219
Validation loss: 3.2089966060546713

Epoch: 6| Step: 12
Training loss: 3.051002875372658
Validation loss: 3.2051907620852553

Epoch: 6| Step: 13
Training loss: 3.2947628251939145
Validation loss: 3.20378753989259

Epoch: 10| Step: 0
Training loss: 3.0027230937572655
Validation loss: 3.1796382188612466

Epoch: 6| Step: 1
Training loss: 3.387015676186761
Validation loss: 3.170580928270417

Epoch: 6| Step: 2
Training loss: 4.278447702858333
Validation loss: 3.1791821698286395

Epoch: 6| Step: 3
Training loss: 3.125465358417053
Validation loss: 3.1677790184737598

Epoch: 6| Step: 4
Training loss: 3.4173188556250853
Validation loss: 3.1652522609192326

Epoch: 6| Step: 5
Training loss: 3.678638997297305
Validation loss: 3.156627038353785

Epoch: 6| Step: 6
Training loss: 3.126825028606731
Validation loss: 3.1474861693115654

Epoch: 6| Step: 7
Training loss: 3.2668532110654933
Validation loss: 3.1440033757159482

Epoch: 6| Step: 8
Training loss: 3.1110617505048177
Validation loss: 3.1507000687741313

Epoch: 6| Step: 9
Training loss: 2.8596431418842774
Validation loss: 3.138469777930631

Epoch: 6| Step: 10
Training loss: 3.4672504654849026
Validation loss: 3.1341752206377467

Epoch: 6| Step: 11
Training loss: 4.150436580627929
Validation loss: 3.128828875411616

Epoch: 6| Step: 12
Training loss: 3.025589997314267
Validation loss: 3.1241331977935447

Epoch: 6| Step: 13
Training loss: 3.8147043828058607
Validation loss: 3.114781374672419

Epoch: 11| Step: 0
Training loss: 3.5374382957226156
Validation loss: 3.112766761844799

Epoch: 6| Step: 1
Training loss: 3.613318464757679
Validation loss: 3.1091652911435848

Epoch: 6| Step: 2
Training loss: 3.1821086391794555
Validation loss: 3.1078348206451287

Epoch: 6| Step: 3
Training loss: 3.4670854303327436
Validation loss: 3.1075031254452137

Epoch: 6| Step: 4
Training loss: 3.108834684573675
Validation loss: 3.1020567071902616

Epoch: 6| Step: 5
Training loss: 4.2331437576579
Validation loss: 3.099199514016742

Epoch: 6| Step: 6
Training loss: 3.3570156595082477
Validation loss: 3.0923993263593825

Epoch: 6| Step: 7
Training loss: 3.360095421480628
Validation loss: 3.086858994106102

Epoch: 6| Step: 8
Training loss: 3.284630042716697
Validation loss: 3.0881888789143894

Epoch: 6| Step: 9
Training loss: 3.4796123714070544
Validation loss: 3.0869463616142485

Epoch: 6| Step: 10
Training loss: 3.455802466336919
Validation loss: 3.079365327717913

Epoch: 6| Step: 11
Training loss: 2.544272936556886
Validation loss: 3.0731898004786435

Epoch: 6| Step: 12
Training loss: 3.5592122215714523
Validation loss: 3.0736850990897615

Epoch: 6| Step: 13
Training loss: 1.9933989188824288
Validation loss: 3.0679624576790747

Epoch: 12| Step: 0
Training loss: 4.210525067856253
Validation loss: 3.0652958252615865

Epoch: 6| Step: 1
Training loss: 3.007884473063402
Validation loss: 3.061827087809162

Epoch: 6| Step: 2
Training loss: 3.270428642620066
Validation loss: 3.0573513271643624

Epoch: 6| Step: 3
Training loss: 3.168023989721461
Validation loss: 3.055339604207849

Epoch: 6| Step: 4
Training loss: 3.4731631686749522
Validation loss: 3.0515309660312706

Epoch: 6| Step: 5
Training loss: 3.349617489284997
Validation loss: 3.0485746537353315

Epoch: 6| Step: 6
Training loss: 2.623817995161749
Validation loss: 3.0515219330883916

Epoch: 6| Step: 7
Training loss: 3.4957999505565995
Validation loss: 3.0505708847740274

Epoch: 6| Step: 8
Training loss: 2.7581197335171117
Validation loss: 3.0469060828403807

Epoch: 6| Step: 9
Training loss: 3.0642782225820526
Validation loss: 3.043022089475473

Epoch: 6| Step: 10
Training loss: 3.257796545927287
Validation loss: 3.04050522387825

Epoch: 6| Step: 11
Training loss: 3.697984693017931
Validation loss: 3.0351282311855856

Epoch: 6| Step: 12
Training loss: 3.312259737334305
Validation loss: 3.0289877926674103

Epoch: 6| Step: 13
Training loss: 3.9058085688077284
Validation loss: 3.0284599672021315

Epoch: 13| Step: 0
Training loss: 3.534913045199497
Validation loss: 3.03035965819506

Epoch: 6| Step: 1
Training loss: 3.316546290016656
Validation loss: 3.032955842856812

Epoch: 6| Step: 2
Training loss: 3.407660376062501
Validation loss: 3.0160175441838675

Epoch: 6| Step: 3
Training loss: 2.8231839174309252
Validation loss: 3.019925480011262

Epoch: 6| Step: 4
Training loss: 3.272867594706585
Validation loss: 3.0264620071847936

Epoch: 6| Step: 5
Training loss: 3.7076774331435827
Validation loss: 3.0099974638909446

Epoch: 6| Step: 6
Training loss: 3.1196438473606247
Validation loss: 3.0119507279461715

Epoch: 6| Step: 7
Training loss: 3.0085930145983912
Validation loss: 3.0122453821189485

Epoch: 6| Step: 8
Training loss: 3.3300434726019636
Validation loss: 3.015998456331943

Epoch: 6| Step: 9
Training loss: 3.4507446370029595
Validation loss: 3.014358103918471

Epoch: 6| Step: 10
Training loss: 4.044756832098877
Validation loss: 3.014098164989526

Epoch: 6| Step: 11
Training loss: 3.2718783286586905
Validation loss: 3.003386409805369

Epoch: 6| Step: 12
Training loss: 3.064700523295115
Validation loss: 3.0028443986352857

Epoch: 6| Step: 13
Training loss: 2.18199467667613
Validation loss: 2.999772553726319

Epoch: 14| Step: 0
Training loss: 3.4374545007642237
Validation loss: 3.012658999017067

Epoch: 6| Step: 1
Training loss: 3.7768069559444926
Validation loss: 2.9968078834338723

Epoch: 6| Step: 2
Training loss: 2.47658329422461
Validation loss: 2.9979636944998034

Epoch: 6| Step: 3
Training loss: 2.720815465925902
Validation loss: 3.0019120067647935

Epoch: 6| Step: 4
Training loss: 3.0384830030223573
Validation loss: 3.0089044381686665

Epoch: 6| Step: 5
Training loss: 3.481990117785932
Validation loss: 3.013548380687442

Epoch: 6| Step: 6
Training loss: 3.735326541991366
Validation loss: 3.0223203728122057

Epoch: 6| Step: 7
Training loss: 3.199687322599248
Validation loss: 3.0067526897888968

Epoch: 6| Step: 8
Training loss: 3.5372529445686895
Validation loss: 2.998224883469834

Epoch: 6| Step: 9
Training loss: 3.494880474267889
Validation loss: 2.9937950795224846

Epoch: 6| Step: 10
Training loss: 3.485515048745206
Validation loss: 2.990525972195198

Epoch: 6| Step: 11
Training loss: 3.2873742489279567
Validation loss: 2.990489038031699

Epoch: 6| Step: 12
Training loss: 3.492203339065031
Validation loss: 2.9975749711787323

Epoch: 6| Step: 13
Training loss: 2.047673542833134
Validation loss: 3.0384388506314965

Epoch: 15| Step: 0
Training loss: 3.0850270920217704
Validation loss: 3.0293759844459682

Epoch: 6| Step: 1
Training loss: 2.698177241600986
Validation loss: 2.9853442305693494

Epoch: 6| Step: 2
Training loss: 3.766024873008171
Validation loss: 2.9862343729240295

Epoch: 6| Step: 3
Training loss: 2.888053781489429
Validation loss: 3.005198663247526

Epoch: 6| Step: 4
Training loss: 2.701447776886971
Validation loss: 3.085843136228496

Epoch: 6| Step: 5
Training loss: 3.501125972012349
Validation loss: 3.122028335805951

Epoch: 6| Step: 6
Training loss: 3.2702026407058167
Validation loss: 3.1174983810398365

Epoch: 6| Step: 7
Training loss: 3.7373003494879447
Validation loss: 3.108177813288933

Epoch: 6| Step: 8
Training loss: 3.156499267404013
Validation loss: 3.0816781696320144

Epoch: 6| Step: 9
Training loss: 3.293082709280709
Validation loss: 3.0668908394615912

Epoch: 6| Step: 10
Training loss: 3.602335882002495
Validation loss: 3.0160556685254423

Epoch: 6| Step: 11
Training loss: 3.40571352032427
Validation loss: 3.014520625590385

Epoch: 6| Step: 12
Training loss: 3.7371881973695937
Validation loss: 3.05059291275117

Epoch: 6| Step: 13
Training loss: 3.7845765920885097
Validation loss: 3.0358385784638493

Epoch: 16| Step: 0
Training loss: 3.663565726043485
Validation loss: 3.0044128698250416

Epoch: 6| Step: 1
Training loss: 2.928303383978198
Validation loss: 2.9773702496822296

Epoch: 6| Step: 2
Training loss: 3.2334235077176685
Validation loss: 2.9768021041167807

Epoch: 6| Step: 3
Training loss: 3.279742666710129
Validation loss: 2.9800574974877305

Epoch: 6| Step: 4
Training loss: 3.047698393850338
Validation loss: 2.9830169603018404

Epoch: 6| Step: 5
Training loss: 3.183280096224727
Validation loss: 2.9808179302202276

Epoch: 6| Step: 6
Training loss: 4.328156949693109
Validation loss: 2.976923957142717

Epoch: 6| Step: 7
Training loss: 3.4945609200827965
Validation loss: 2.9672717331744525

Epoch: 6| Step: 8
Training loss: 2.9031762717064926
Validation loss: 2.966202697983813

Epoch: 6| Step: 9
Training loss: 2.9703019753499924
Validation loss: 2.967183993760496

Epoch: 6| Step: 10
Training loss: 3.129234649149999
Validation loss: 2.9735503112479384

Epoch: 6| Step: 11
Training loss: 3.3073364895564175
Validation loss: 2.975541518670937

Epoch: 6| Step: 12
Training loss: 2.9019890179521597
Validation loss: 2.980178698688786

Epoch: 6| Step: 13
Training loss: 3.183167598730687
Validation loss: 2.9888555987236987

Epoch: 17| Step: 0
Training loss: 3.428829563732211
Validation loss: 3.026750203992265

Epoch: 6| Step: 1
Training loss: 2.8050555569455784
Validation loss: 2.97214062883853

Epoch: 6| Step: 2
Training loss: 3.598389127392115
Validation loss: 2.992154054624286

Epoch: 6| Step: 3
Training loss: 3.616613486700316
Validation loss: 2.9599119587869507

Epoch: 6| Step: 4
Training loss: 2.7716323350656107
Validation loss: 2.9523902079183983

Epoch: 6| Step: 5
Training loss: 3.416051638693094
Validation loss: 2.9529775389644106

Epoch: 6| Step: 6
Training loss: 3.2139501245090956
Validation loss: 2.957646045865997

Epoch: 6| Step: 7
Training loss: 3.414774316392955
Validation loss: 2.9562575304901992

Epoch: 6| Step: 8
Training loss: 3.152048468202613
Validation loss: 2.951499868997087

Epoch: 6| Step: 9
Training loss: 2.918790116943172
Validation loss: 2.957443292909231

Epoch: 6| Step: 10
Training loss: 3.5410789151645368
Validation loss: 2.97162739935246

Epoch: 6| Step: 11
Training loss: 2.978182454470629
Validation loss: 2.961721762051567

Epoch: 6| Step: 12
Training loss: 3.21827323864053
Validation loss: 2.956994056129088

Epoch: 6| Step: 13
Training loss: 3.679656139977169
Validation loss: 2.9503092726571123

Epoch: 18| Step: 0
Training loss: 3.0670672244928223
Validation loss: 2.9450466114001

Epoch: 6| Step: 1
Training loss: 3.374279651767909
Validation loss: 2.940023240505474

Epoch: 6| Step: 2
Training loss: 3.0708901830109916
Validation loss: 2.9341697448012924

Epoch: 6| Step: 3
Training loss: 2.972409372191373
Validation loss: 2.9310181947260676

Epoch: 6| Step: 4
Training loss: 3.171595969869704
Validation loss: 2.9279086203764977

Epoch: 6| Step: 5
Training loss: 2.7343510217977673
Validation loss: 2.926931245388345

Epoch: 6| Step: 6
Training loss: 2.8158830429194617
Validation loss: 2.926002490024069

Epoch: 6| Step: 7
Training loss: 3.025311818090771
Validation loss: 2.9263608736688944

Epoch: 6| Step: 8
Training loss: 3.1500282528533634
Validation loss: 2.924179905724294

Epoch: 6| Step: 9
Training loss: 3.5021498753029507
Validation loss: 2.926311506040666

Epoch: 6| Step: 10
Training loss: 3.3923037543773833
Validation loss: 2.9261016431505746

Epoch: 6| Step: 11
Training loss: 3.901907009547668
Validation loss: 2.922766468277769

Epoch: 6| Step: 12
Training loss: 3.097620229042615
Validation loss: 2.920476675696052

Epoch: 6| Step: 13
Training loss: 4.163544184219761
Validation loss: 2.9195298312006637

Epoch: 19| Step: 0
Training loss: 4.101442985609941
Validation loss: 2.9185350987583827

Epoch: 6| Step: 1
Training loss: 3.323642488012596
Validation loss: 2.9146380499574778

Epoch: 6| Step: 2
Training loss: 3.239415760346885
Validation loss: 2.913088303934433

Epoch: 6| Step: 3
Training loss: 3.120985733473859
Validation loss: 2.9130656295589437

Epoch: 6| Step: 4
Training loss: 3.928489547966114
Validation loss: 2.9110780401130145

Epoch: 6| Step: 5
Training loss: 2.8647041064147567
Validation loss: 2.908109922108438

Epoch: 6| Step: 6
Training loss: 2.7169285076621117
Validation loss: 2.9068658577350175

Epoch: 6| Step: 7
Training loss: 3.185770201207605
Validation loss: 2.9074730497716352

Epoch: 6| Step: 8
Training loss: 2.457650062737082
Validation loss: 2.92137788320125

Epoch: 6| Step: 9
Training loss: 3.292008700084662
Validation loss: 2.9477832247563085

Epoch: 6| Step: 10
Training loss: 2.520500150578
Validation loss: 2.9948907622661265

Epoch: 6| Step: 11
Training loss: 2.6361744410691674
Validation loss: 3.0569112317787854

Epoch: 6| Step: 12
Training loss: 3.7868016370261057
Validation loss: 3.0734054624401

Epoch: 6| Step: 13
Training loss: 4.073041414787867
Validation loss: 3.0124114218799702

Epoch: 20| Step: 0
Training loss: 2.871662026562284
Validation loss: 2.9525324304050695

Epoch: 6| Step: 1
Training loss: 2.5330628861408164
Validation loss: 2.9282419472535004

Epoch: 6| Step: 2
Training loss: 3.236951897962291
Validation loss: 2.920150821062104

Epoch: 6| Step: 3
Training loss: 3.4521532719644368
Validation loss: 2.918949782923199

Epoch: 6| Step: 4
Training loss: 4.064572788513573
Validation loss: 2.924425126686478

Epoch: 6| Step: 5
Training loss: 3.1027462331484497
Validation loss: 2.9121509160947525

Epoch: 6| Step: 6
Training loss: 3.179915736299599
Validation loss: 2.9037182741175367

Epoch: 6| Step: 7
Training loss: 3.1416296419614738
Validation loss: 2.9004737788773927

Epoch: 6| Step: 8
Training loss: 3.7576674593971986
Validation loss: 2.8963611665004168

Epoch: 6| Step: 9
Training loss: 2.771807640315191
Validation loss: 2.894800251680708

Epoch: 6| Step: 10
Training loss: 2.9802297193837006
Validation loss: 2.8917889620384654

Epoch: 6| Step: 11
Training loss: 2.976980585487932
Validation loss: 2.8921893223000077

Epoch: 6| Step: 12
Training loss: 3.328212253340176
Validation loss: 2.891135463191716

Epoch: 6| Step: 13
Training loss: 3.568747413220111
Validation loss: 2.891685139336207

Epoch: 21| Step: 0
Training loss: 3.149259322748984
Validation loss: 2.891869936016971

Epoch: 6| Step: 1
Training loss: 3.072828819614083
Validation loss: 2.897866200769294

Epoch: 6| Step: 2
Training loss: 3.1659294742674158
Validation loss: 2.9064643861062174

Epoch: 6| Step: 3
Training loss: 2.8997171461347553
Validation loss: 2.9040384892448956

Epoch: 6| Step: 4
Training loss: 3.34099971999824
Validation loss: 2.8985658314337086

Epoch: 6| Step: 5
Training loss: 2.7899871062934487
Validation loss: 2.889784357500601

Epoch: 6| Step: 6
Training loss: 3.2970770462100245
Validation loss: 2.8857602988814848

Epoch: 6| Step: 7
Training loss: 2.971540404536586
Validation loss: 2.886939330284221

Epoch: 6| Step: 8
Training loss: 3.3860339888135913
Validation loss: 2.8898354775507755

Epoch: 6| Step: 9
Training loss: 2.7507066685696735
Validation loss: 2.892570247712677

Epoch: 6| Step: 10
Training loss: 3.07122090420198
Validation loss: 2.8933129404486397

Epoch: 6| Step: 11
Training loss: 3.4511348461157265
Validation loss: 2.8969833139789

Epoch: 6| Step: 12
Training loss: 3.641553637556728
Validation loss: 2.8983792875530767

Epoch: 6| Step: 13
Training loss: 4.038116757553183
Validation loss: 2.8919455117531165

Epoch: 22| Step: 0
Training loss: 3.3351686829053517
Validation loss: 2.89017527550937

Epoch: 6| Step: 1
Training loss: 3.4149233084203483
Validation loss: 2.8866170735695804

Epoch: 6| Step: 2
Training loss: 3.3755311901135925
Validation loss: 2.884196061945652

Epoch: 6| Step: 3
Training loss: 3.143769317628273
Validation loss: 2.8804616523899385

Epoch: 6| Step: 4
Training loss: 2.667808606101469
Validation loss: 2.8823970292199244

Epoch: 6| Step: 5
Training loss: 3.136611423580259
Validation loss: 2.8785872530416903

Epoch: 6| Step: 6
Training loss: 2.3666230085760764
Validation loss: 2.8806407516114656

Epoch: 6| Step: 7
Training loss: 3.584437104196818
Validation loss: 2.8847433687504145

Epoch: 6| Step: 8
Training loss: 3.3140112830219186
Validation loss: 2.8865894327126624

Epoch: 6| Step: 9
Training loss: 3.1155909988859043
Validation loss: 2.8829683100043932

Epoch: 6| Step: 10
Training loss: 2.774811138565256
Validation loss: 2.888050632032174

Epoch: 6| Step: 11
Training loss: 3.7753169905600545
Validation loss: 2.8876794948650493

Epoch: 6| Step: 12
Training loss: 3.698612989316234
Validation loss: 2.8821248694142554

Epoch: 6| Step: 13
Training loss: 2.173392554667884
Validation loss: 2.8754511938817755

Epoch: 23| Step: 0
Training loss: 3.086155519147844
Validation loss: 2.8722519423189743

Epoch: 6| Step: 1
Training loss: 3.402044657580622
Validation loss: 2.871154936299704

Epoch: 6| Step: 2
Training loss: 2.7534794036998207
Validation loss: 2.8707944554248708

Epoch: 6| Step: 3
Training loss: 2.691650025244448
Validation loss: 2.870370023185411

Epoch: 6| Step: 4
Training loss: 3.152016094437769
Validation loss: 2.8698271717252686

Epoch: 6| Step: 5
Training loss: 3.2107934478597864
Validation loss: 2.865961604565717

Epoch: 6| Step: 6
Training loss: 3.084655031673511
Validation loss: 2.868144510875626

Epoch: 6| Step: 7
Training loss: 3.264402900063856
Validation loss: 2.8683031671103514

Epoch: 6| Step: 8
Training loss: 2.595507290745583
Validation loss: 2.8647092467496926

Epoch: 6| Step: 9
Training loss: 3.8792069271523775
Validation loss: 2.8662991292662587

Epoch: 6| Step: 10
Training loss: 3.8528248418640785
Validation loss: 2.862489806015263

Epoch: 6| Step: 11
Training loss: 2.857488958649484
Validation loss: 2.862699641005996

Epoch: 6| Step: 12
Training loss: 3.0826792839489463
Validation loss: 2.8634277103942605

Epoch: 6| Step: 13
Training loss: 3.431726774850609
Validation loss: 2.8632291159449665

Epoch: 24| Step: 0
Training loss: 3.3238581137918803
Validation loss: 2.8647815523151716

Epoch: 6| Step: 1
Training loss: 3.0617825971849006
Validation loss: 2.8598227345098173

Epoch: 6| Step: 2
Training loss: 2.5857250668030716
Validation loss: 2.8604230963134727

Epoch: 6| Step: 3
Training loss: 3.072914011463807
Validation loss: 2.862380814568646

Epoch: 6| Step: 4
Training loss: 3.3139141590923877
Validation loss: 2.861095455769466

Epoch: 6| Step: 5
Training loss: 2.945874552638454
Validation loss: 2.865475865964336

Epoch: 6| Step: 6
Training loss: 2.6227739068515192
Validation loss: 2.866151781165744

Epoch: 6| Step: 7
Training loss: 3.1840754045155126
Validation loss: 2.864257270102467

Epoch: 6| Step: 8
Training loss: 3.6457815693404854
Validation loss: 2.8658125667320986

Epoch: 6| Step: 9
Training loss: 3.373371861832117
Validation loss: 2.864264532492603

Epoch: 6| Step: 10
Training loss: 3.332894359929988
Validation loss: 2.8595426812763463

Epoch: 6| Step: 11
Training loss: 2.8090203694697893
Validation loss: 2.8624692309167306

Epoch: 6| Step: 12
Training loss: 3.4445309952830763
Validation loss: 2.8658277947826343

Epoch: 6| Step: 13
Training loss: 3.872851114332202
Validation loss: 2.860125407300507

Epoch: 25| Step: 0
Training loss: 3.0254870818629405
Validation loss: 2.854191178109625

Epoch: 6| Step: 1
Training loss: 3.8400899938131
Validation loss: 2.8506640520406243

Epoch: 6| Step: 2
Training loss: 2.780926803497995
Validation loss: 2.8501838852159045

Epoch: 6| Step: 3
Training loss: 2.8584740058233473
Validation loss: 2.84998163963237

Epoch: 6| Step: 4
Training loss: 2.707626563554512
Validation loss: 2.850321996518666

Epoch: 6| Step: 5
Training loss: 2.852469689277534
Validation loss: 2.8508633230525504

Epoch: 6| Step: 6
Training loss: 3.0297517514904055
Validation loss: 2.8551937171869692

Epoch: 6| Step: 7
Training loss: 3.394432075201856
Validation loss: 2.8624495185914185

Epoch: 6| Step: 8
Training loss: 2.702473821098577
Validation loss: 2.869838128131523

Epoch: 6| Step: 9
Training loss: 4.072738890739689
Validation loss: 2.8744565566939477

Epoch: 6| Step: 10
Training loss: 3.2731397397763993
Validation loss: 2.8454221501350716

Epoch: 6| Step: 11
Training loss: 3.5153512805770197
Validation loss: 2.8481451194711958

Epoch: 6| Step: 12
Training loss: 2.9628416999091773
Validation loss: 2.8474870620784087

Epoch: 6| Step: 13
Training loss: 2.8825400619171155
Validation loss: 2.84708124054002

Epoch: 26| Step: 0
Training loss: 3.606515255168984
Validation loss: 2.8469895557335447

Epoch: 6| Step: 1
Training loss: 3.1926733184105793
Validation loss: 2.8459280031052168

Epoch: 6| Step: 2
Training loss: 3.3663297830866323
Validation loss: 2.847546491374746

Epoch: 6| Step: 3
Training loss: 2.909684151881179
Validation loss: 2.846879666945518

Epoch: 6| Step: 4
Training loss: 3.1329575502677636
Validation loss: 2.845915939431041

Epoch: 6| Step: 5
Training loss: 2.7909780383665743
Validation loss: 2.844238882897884

Epoch: 6| Step: 6
Training loss: 2.9328667645319473
Validation loss: 2.8444302022728127

Epoch: 6| Step: 7
Training loss: 3.29968026664108
Validation loss: 2.8429508882690024

Epoch: 6| Step: 8
Training loss: 3.5943786071324113
Validation loss: 2.8405661805379236

Epoch: 6| Step: 9
Training loss: 3.010621342196469
Validation loss: 2.8395707437782396

Epoch: 6| Step: 10
Training loss: 3.251784494970938
Validation loss: 2.840417439312965

Epoch: 6| Step: 11
Training loss: 2.558456580292538
Validation loss: 2.8392372624002413

Epoch: 6| Step: 12
Training loss: 3.133234390428097
Validation loss: 2.8419425040426955

Epoch: 6| Step: 13
Training loss: 3.393681989518742
Validation loss: 2.8482877507490216

Epoch: 27| Step: 0
Training loss: 3.8009602738783097
Validation loss: 2.854457074876055

Epoch: 6| Step: 1
Training loss: 2.744574570198561
Validation loss: 2.8481283899989287

Epoch: 6| Step: 2
Training loss: 2.7392508494786725
Validation loss: 2.842094568795924

Epoch: 6| Step: 3
Training loss: 3.1068899681269455
Validation loss: 2.8548699603726253

Epoch: 6| Step: 4
Training loss: 3.366107670168613
Validation loss: 2.8626994708548112

Epoch: 6| Step: 5
Training loss: 3.4864551852283943
Validation loss: 2.852209742630768

Epoch: 6| Step: 6
Training loss: 3.755540442452002
Validation loss: 2.8299938819416477

Epoch: 6| Step: 7
Training loss: 2.777480925486775
Validation loss: 2.8324196278393616

Epoch: 6| Step: 8
Training loss: 3.2130794017489452
Validation loss: 2.8327728244271473

Epoch: 6| Step: 9
Training loss: 3.290018336931974
Validation loss: 2.8365861749776036

Epoch: 6| Step: 10
Training loss: 2.9197828993369104
Validation loss: 2.8325126639904146

Epoch: 6| Step: 11
Training loss: 2.9732301336035465
Validation loss: 2.829659706785054

Epoch: 6| Step: 12
Training loss: 2.811748489006385
Validation loss: 2.8334947090108575

Epoch: 6| Step: 13
Training loss: 2.894007338086825
Validation loss: 2.836032472721556

Epoch: 28| Step: 0
Training loss: 2.858737061424983
Validation loss: 2.842648261755328

Epoch: 6| Step: 1
Training loss: 3.397475393625827
Validation loss: 2.8288414214907633

Epoch: 6| Step: 2
Training loss: 3.0623607993117226
Validation loss: 2.8246969058431186

Epoch: 6| Step: 3
Training loss: 3.136314508558451
Validation loss: 2.8296717908408513

Epoch: 6| Step: 4
Training loss: 3.3219021929743056
Validation loss: 2.861765384550808

Epoch: 6| Step: 5
Training loss: 3.6983700899621526
Validation loss: 2.8403527432401274

Epoch: 6| Step: 6
Training loss: 2.9645209457113024
Validation loss: 2.833781174102504

Epoch: 6| Step: 7
Training loss: 2.6110144849804238
Validation loss: 2.83519145278534

Epoch: 6| Step: 8
Training loss: 3.2049033089988437
Validation loss: 2.8375234860493634

Epoch: 6| Step: 9
Training loss: 3.0978622079426668
Validation loss: 2.8357655309135397

Epoch: 6| Step: 10
Training loss: 2.590494709856956
Validation loss: 2.8315834270125397

Epoch: 6| Step: 11
Training loss: 3.4223116940063507
Validation loss: 2.832385243550295

Epoch: 6| Step: 12
Training loss: 3.1041024903356225
Validation loss: 2.8305757471593

Epoch: 6| Step: 13
Training loss: 3.762947365154714
Validation loss: 2.8315454925136034

Epoch: 29| Step: 0
Training loss: 2.6737098862758537
Validation loss: 2.8244104533772836

Epoch: 6| Step: 1
Training loss: 3.3395189272325196
Validation loss: 2.8214571300367366

Epoch: 6| Step: 2
Training loss: 2.509905265752913
Validation loss: 2.820682917059736

Epoch: 6| Step: 3
Training loss: 3.1684980785140717
Validation loss: 2.820512619238339

Epoch: 6| Step: 4
Training loss: 2.7562979626969724
Validation loss: 2.8198728064410377

Epoch: 6| Step: 5
Training loss: 2.766217356893014
Validation loss: 2.8198165559764443

Epoch: 6| Step: 6
Training loss: 3.813370151964474
Validation loss: 2.817547859303475

Epoch: 6| Step: 7
Training loss: 3.1223288755048726
Validation loss: 2.818083438687401

Epoch: 6| Step: 8
Training loss: 2.9759610587207725
Validation loss: 2.817091275465872

Epoch: 6| Step: 9
Training loss: 2.620415089463665
Validation loss: 2.8167283189461347

Epoch: 6| Step: 10
Training loss: 3.1729145319717116
Validation loss: 2.8150568834967173

Epoch: 6| Step: 11
Training loss: 4.050799613476939
Validation loss: 2.8166145863323324

Epoch: 6| Step: 12
Training loss: 2.6368456096507664
Validation loss: 2.8151867474491525

Epoch: 6| Step: 13
Training loss: 4.25173824890562
Validation loss: 2.8158632466434534

Epoch: 30| Step: 0
Training loss: 2.7497255014923088
Validation loss: 2.813254834131986

Epoch: 6| Step: 1
Training loss: 3.3272481846839903
Validation loss: 2.814715784395004

Epoch: 6| Step: 2
Training loss: 3.5318616489258634
Validation loss: 2.8133048452114857

Epoch: 6| Step: 3
Training loss: 3.0907734124601256
Validation loss: 2.8228683973091453

Epoch: 6| Step: 4
Training loss: 3.799827401106298
Validation loss: 2.8262948923763114

Epoch: 6| Step: 5
Training loss: 3.6062944485521706
Validation loss: 2.835932030894704

Epoch: 6| Step: 6
Training loss: 2.3912067578120375
Validation loss: 2.8204237165767987

Epoch: 6| Step: 7
Training loss: 2.968679969363159
Validation loss: 2.812904320644251

Epoch: 6| Step: 8
Training loss: 3.7242680489742344
Validation loss: 2.811550274448989

Epoch: 6| Step: 9
Training loss: 2.5216626991430697
Validation loss: 2.8073122369013097

Epoch: 6| Step: 10
Training loss: 2.7852844807985147
Validation loss: 2.802236084793069

Epoch: 6| Step: 11
Training loss: 3.356443181507543
Validation loss: 2.8029766666198506

Epoch: 6| Step: 12
Training loss: 2.9449754112266358
Validation loss: 2.8011139730281878

Epoch: 6| Step: 13
Training loss: 2.0284634770581373
Validation loss: 2.80325947009142

Epoch: 31| Step: 0
Training loss: 3.260752131517482
Validation loss: 2.801125621947323

Epoch: 6| Step: 1
Training loss: 3.595385237467376
Validation loss: 2.8011783489914315

Epoch: 6| Step: 2
Training loss: 2.6385723916930597
Validation loss: 2.799510048850707

Epoch: 6| Step: 3
Training loss: 3.6266841264846734
Validation loss: 2.7986451907929277

Epoch: 6| Step: 4
Training loss: 3.142021513983623
Validation loss: 2.7982820422761505

Epoch: 6| Step: 5
Training loss: 3.1957109198237963
Validation loss: 2.7961154799473156

Epoch: 6| Step: 6
Training loss: 3.1062411517318487
Validation loss: 2.7941193820508974

Epoch: 6| Step: 7
Training loss: 2.9811556563254475
Validation loss: 2.793738260643901

Epoch: 6| Step: 8
Training loss: 2.3592334224841673
Validation loss: 2.793737752272354

Epoch: 6| Step: 9
Training loss: 3.123611752189758
Validation loss: 2.7916086671767513

Epoch: 6| Step: 10
Training loss: 3.187514809966743
Validation loss: 2.7914499600643943

Epoch: 6| Step: 11
Training loss: 3.6628348239790864
Validation loss: 2.7886079099646746

Epoch: 6| Step: 12
Training loss: 2.5647433625862406
Validation loss: 2.7914008657002753

Epoch: 6| Step: 13
Training loss: 2.680739304784194
Validation loss: 2.798715233171015

Epoch: 32| Step: 0
Training loss: 2.6271544198550947
Validation loss: 2.819512884820515

Epoch: 6| Step: 1
Training loss: 2.545176120802032
Validation loss: 2.8298643496217375

Epoch: 6| Step: 2
Training loss: 2.8379427123359937
Validation loss: 2.8149061932600925

Epoch: 6| Step: 3
Training loss: 2.587229794754277
Validation loss: 2.8078748265599254

Epoch: 6| Step: 4
Training loss: 3.432758737524213
Validation loss: 2.786051308720516

Epoch: 6| Step: 5
Training loss: 3.4541903272185785
Validation loss: 2.7881900871416248

Epoch: 6| Step: 6
Training loss: 3.4265887397286754
Validation loss: 2.7863512090853955

Epoch: 6| Step: 7
Training loss: 3.0588250980114258
Validation loss: 2.7864058635204216

Epoch: 6| Step: 8
Training loss: 3.465336400115694
Validation loss: 2.7855410185609757

Epoch: 6| Step: 9
Training loss: 3.4025318255817503
Validation loss: 2.7855904458217933

Epoch: 6| Step: 10
Training loss: 3.3984742612056293
Validation loss: 2.785137172363767

Epoch: 6| Step: 11
Training loss: 2.5819454669408866
Validation loss: 2.784642251375136

Epoch: 6| Step: 12
Training loss: 2.988231783189429
Validation loss: 2.784180794287556

Epoch: 6| Step: 13
Training loss: 3.731572460253592
Validation loss: 2.7846630015023637

Epoch: 33| Step: 0
Training loss: 2.6810596389596952
Validation loss: 2.784367456646107

Epoch: 6| Step: 1
Training loss: 3.504018111979039
Validation loss: 2.7934757212273724

Epoch: 6| Step: 2
Training loss: 2.6280648640795703
Validation loss: 2.7820308170426022

Epoch: 6| Step: 3
Training loss: 3.5184873330442685
Validation loss: 2.784557341705594

Epoch: 6| Step: 4
Training loss: 2.6457585201549776
Validation loss: 2.7874600327077155

Epoch: 6| Step: 5
Training loss: 3.5752083831023027
Validation loss: 2.7911223105972565

Epoch: 6| Step: 6
Training loss: 3.430149056001316
Validation loss: 2.792033354311789

Epoch: 6| Step: 7
Training loss: 2.9577197302664797
Validation loss: 2.7913000600443483

Epoch: 6| Step: 8
Training loss: 3.189675579734572
Validation loss: 2.7933375103595943

Epoch: 6| Step: 9
Training loss: 2.742774574493062
Validation loss: 2.7939106501574864

Epoch: 6| Step: 10
Training loss: 3.4388305863173314
Validation loss: 2.7951843803907743

Epoch: 6| Step: 11
Training loss: 3.20734020236489
Validation loss: 2.793159550974139

Epoch: 6| Step: 12
Training loss: 3.194648356540707
Validation loss: 2.7910557058288323

Epoch: 6| Step: 13
Training loss: 1.9464027995531965
Validation loss: 2.801278594631327

Epoch: 34| Step: 0
Training loss: 2.9944076866893066
Validation loss: 2.809659690886241

Epoch: 6| Step: 1
Training loss: 2.8599937895060514
Validation loss: 2.8164386994019757

Epoch: 6| Step: 2
Training loss: 2.887899897903752
Validation loss: 2.815147582992358

Epoch: 6| Step: 3
Training loss: 3.5521123592201325
Validation loss: 2.8341326071783337

Epoch: 6| Step: 4
Training loss: 3.7401887338109514
Validation loss: 2.8372299949481983

Epoch: 6| Step: 5
Training loss: 2.980741035952819
Validation loss: 2.8030355808370326

Epoch: 6| Step: 6
Training loss: 3.3748188676618436
Validation loss: 2.785504160600981

Epoch: 6| Step: 7
Training loss: 3.534616806433585
Validation loss: 2.7761654069655948

Epoch: 6| Step: 8
Training loss: 2.9841640857244
Validation loss: 2.7726166299105452

Epoch: 6| Step: 9
Training loss: 2.3799827908446725
Validation loss: 2.7666410194297417

Epoch: 6| Step: 10
Training loss: 3.110984194149819
Validation loss: 2.7692274127164986

Epoch: 6| Step: 11
Training loss: 2.5170155348664
Validation loss: 2.769683000177582

Epoch: 6| Step: 12
Training loss: 2.899682612973607
Validation loss: 2.7683568214700798

Epoch: 6| Step: 13
Training loss: 3.6899549426710987
Validation loss: 2.768125049816845

Epoch: 35| Step: 0
Training loss: 3.210941064094737
Validation loss: 2.76985903596151

Epoch: 6| Step: 1
Training loss: 2.9002285176709637
Validation loss: 2.7680232710091572

Epoch: 6| Step: 2
Training loss: 3.3494816791894944
Validation loss: 2.7728029178228644

Epoch: 6| Step: 3
Training loss: 3.1591245950084192
Validation loss: 2.7689548360458

Epoch: 6| Step: 4
Training loss: 3.6459818055938227
Validation loss: 2.7689264530006534

Epoch: 6| Step: 5
Training loss: 3.418984084684467
Validation loss: 2.7684342827316093

Epoch: 6| Step: 6
Training loss: 2.673240714129562
Validation loss: 2.7634311134157237

Epoch: 6| Step: 7
Training loss: 2.88479769203995
Validation loss: 2.762492277663282

Epoch: 6| Step: 8
Training loss: 3.191975611648511
Validation loss: 2.762356332311486

Epoch: 6| Step: 9
Training loss: 2.9364294170910386
Validation loss: 2.762958141581136

Epoch: 6| Step: 10
Training loss: 2.9997631615293487
Validation loss: 2.7622809716418923

Epoch: 6| Step: 11
Training loss: 2.5194761758152207
Validation loss: 2.762469336516264

Epoch: 6| Step: 12
Training loss: 3.280078206409282
Validation loss: 2.7632880562054174

Epoch: 6| Step: 13
Training loss: 2.92287472844144
Validation loss: 2.7645775394360594

Epoch: 36| Step: 0
Training loss: 3.05484172304898
Validation loss: 2.771915348198311

Epoch: 6| Step: 1
Training loss: 3.1608289985684004
Validation loss: 2.7818880730730076

Epoch: 6| Step: 2
Training loss: 3.4351347675567045
Validation loss: 2.797844155209846

Epoch: 6| Step: 3
Training loss: 2.601909625748274
Validation loss: 2.8016360602536206

Epoch: 6| Step: 4
Training loss: 3.353022188599594
Validation loss: 2.8049692691136405

Epoch: 6| Step: 5
Training loss: 2.7538937832164625
Validation loss: 2.7836232675479535

Epoch: 6| Step: 6
Training loss: 3.1532106779195237
Validation loss: 2.774153302037401

Epoch: 6| Step: 7
Training loss: 2.569102086350469
Validation loss: 2.762280673725534

Epoch: 6| Step: 8
Training loss: 2.8636724145004435
Validation loss: 2.7571302158675604

Epoch: 6| Step: 9
Training loss: 2.5150608354191704
Validation loss: 2.7581483300127436

Epoch: 6| Step: 10
Training loss: 3.740119506028191
Validation loss: 2.757161576729338

Epoch: 6| Step: 11
Training loss: 3.168910252358056
Validation loss: 2.7595239075970133

Epoch: 6| Step: 12
Training loss: 3.2821101923081626
Validation loss: 2.76072399977095

Epoch: 6| Step: 13
Training loss: 3.368849908200051
Validation loss: 2.7699120342490597

Epoch: 37| Step: 0
Training loss: 3.172977800755069
Validation loss: 2.75981431558479

Epoch: 6| Step: 1
Training loss: 2.6845273277751853
Validation loss: 2.7560410749163475

Epoch: 6| Step: 2
Training loss: 2.6053172100327013
Validation loss: 2.752332438431074

Epoch: 6| Step: 3
Training loss: 3.0035535111693963
Validation loss: 2.760120783848912

Epoch: 6| Step: 4
Training loss: 2.9855023396868874
Validation loss: 2.7886275375124385

Epoch: 6| Step: 5
Training loss: 2.4614884985841616
Validation loss: 2.83943832217747

Epoch: 6| Step: 6
Training loss: 2.8764077761934743
Validation loss: 2.7932014128051748

Epoch: 6| Step: 7
Training loss: 3.5713920046432985
Validation loss: 2.7525259929211034

Epoch: 6| Step: 8
Training loss: 2.9606651643908006
Validation loss: 2.748292084977898

Epoch: 6| Step: 9
Training loss: 3.607212227851682
Validation loss: 2.748947080886733

Epoch: 6| Step: 10
Training loss: 3.4630599908349944
Validation loss: 2.7510619289925895

Epoch: 6| Step: 11
Training loss: 3.368050095246773
Validation loss: 2.7512957912469194

Epoch: 6| Step: 12
Training loss: 3.31166296405966
Validation loss: 2.7511477718041815

Epoch: 6| Step: 13
Training loss: 2.708274830895466
Validation loss: 2.7510067480389075

Epoch: 38| Step: 0
Training loss: 3.1211583747905043
Validation loss: 2.752298327847568

Epoch: 6| Step: 1
Training loss: 3.0776298628181014
Validation loss: 2.7537222344690737

Epoch: 6| Step: 2
Training loss: 3.132324789616569
Validation loss: 2.7557146771871457

Epoch: 6| Step: 3
Training loss: 3.0412712014271075
Validation loss: 2.75966703080896

Epoch: 6| Step: 4
Training loss: 3.2738651551643385
Validation loss: 2.762337702312505

Epoch: 6| Step: 5
Training loss: 3.0895304563237045
Validation loss: 2.7578772862288763

Epoch: 6| Step: 6
Training loss: 3.426788008158142
Validation loss: 2.7595717644893534

Epoch: 6| Step: 7
Training loss: 3.371574783041177
Validation loss: 2.758371987955087

Epoch: 6| Step: 8
Training loss: 3.1799029902890004
Validation loss: 2.7540771924703313

Epoch: 6| Step: 9
Training loss: 2.6080731096551717
Validation loss: 2.7501880501283824

Epoch: 6| Step: 10
Training loss: 2.9029185571760654
Validation loss: 2.749580024950329

Epoch: 6| Step: 11
Training loss: 2.3516433042919878
Validation loss: 2.748846572889406

Epoch: 6| Step: 12
Training loss: 3.175189461649589
Validation loss: 2.7507128793671036

Epoch: 6| Step: 13
Training loss: 3.3706962554433706
Validation loss: 2.7525244375203255

Epoch: 39| Step: 0
Training loss: 3.5194300426364786
Validation loss: 2.751426114445972

Epoch: 6| Step: 1
Training loss: 3.3640607933964985
Validation loss: 2.7682650038058974

Epoch: 6| Step: 2
Training loss: 2.821483252824953
Validation loss: 2.7519668414220946

Epoch: 6| Step: 3
Training loss: 2.4377854008972233
Validation loss: 2.7454085273996722

Epoch: 6| Step: 4
Training loss: 3.6703038526930913
Validation loss: 2.74423392431402

Epoch: 6| Step: 5
Training loss: 3.02733146418878
Validation loss: 2.7406793899780593

Epoch: 6| Step: 6
Training loss: 2.5693030882663495
Validation loss: 2.739506569799921

Epoch: 6| Step: 7
Training loss: 2.917109882648209
Validation loss: 2.73915584552026

Epoch: 6| Step: 8
Training loss: 3.1224006523411174
Validation loss: 2.741385371418411

Epoch: 6| Step: 9
Training loss: 3.046669351533448
Validation loss: 2.7368636284232797

Epoch: 6| Step: 10
Training loss: 2.4164896494610004
Validation loss: 2.7398745255991996

Epoch: 6| Step: 11
Training loss: 3.3922205392290725
Validation loss: 2.738711971180443

Epoch: 6| Step: 12
Training loss: 2.7926346158850346
Validation loss: 2.734760600616547

Epoch: 6| Step: 13
Training loss: 3.8815884109368093
Validation loss: 2.732515053740408

Epoch: 40| Step: 0
Training loss: 3.4059434105321054
Validation loss: 2.7331827394082135

Epoch: 6| Step: 1
Training loss: 2.6556801577410876
Validation loss: 2.7341597333749297

Epoch: 6| Step: 2
Training loss: 2.726520789409424
Validation loss: 2.733774696939733

Epoch: 6| Step: 3
Training loss: 2.6748767075691173
Validation loss: 2.735705900679134

Epoch: 6| Step: 4
Training loss: 2.819160881461277
Validation loss: 2.7350519714048818

Epoch: 6| Step: 5
Training loss: 2.944533186800819
Validation loss: 2.7344604094448886

Epoch: 6| Step: 6
Training loss: 3.142063096294954
Validation loss: 2.7343504020651

Epoch: 6| Step: 7
Training loss: 3.0875332726295803
Validation loss: 2.733586677792732

Epoch: 6| Step: 8
Training loss: 2.640162139595228
Validation loss: 2.7329865392698323

Epoch: 6| Step: 9
Training loss: 3.5818547295825676
Validation loss: 2.732183111260832

Epoch: 6| Step: 10
Training loss: 3.3231411721533943
Validation loss: 2.731211853098856

Epoch: 6| Step: 11
Training loss: 3.081536895209214
Validation loss: 2.7305988579633103

Epoch: 6| Step: 12
Training loss: 3.6659446063146377
Validation loss: 2.729113641139385

Epoch: 6| Step: 13
Training loss: 2.9139083535176935
Validation loss: 2.7261962936174307

Epoch: 41| Step: 0
Training loss: 3.32492699793935
Validation loss: 2.7243990090611283

Epoch: 6| Step: 1
Training loss: 2.380868087139259
Validation loss: 2.7251495697347075

Epoch: 6| Step: 2
Training loss: 3.219848149196144
Validation loss: 2.7230747626447407

Epoch: 6| Step: 3
Training loss: 2.8675935961772745
Validation loss: 2.7235504521382983

Epoch: 6| Step: 4
Training loss: 2.665619694300891
Validation loss: 2.723478532211557

Epoch: 6| Step: 5
Training loss: 2.8321231800812123
Validation loss: 2.7260192373124505

Epoch: 6| Step: 6
Training loss: 3.781175092475361
Validation loss: 2.7314642508112215

Epoch: 6| Step: 7
Training loss: 2.937184418304187
Validation loss: 2.741074318743679

Epoch: 6| Step: 8
Training loss: 2.5332021838254803
Validation loss: 2.7432235351347196

Epoch: 6| Step: 9
Training loss: 3.5221009690532803
Validation loss: 2.725383119499998

Epoch: 6| Step: 10
Training loss: 3.42145372000945
Validation loss: 2.7227988546570385

Epoch: 6| Step: 11
Training loss: 2.798937159861492
Validation loss: 2.719882791799972

Epoch: 6| Step: 12
Training loss: 3.055824946078263
Validation loss: 2.718451654596558

Epoch: 6| Step: 13
Training loss: 3.0742350363390867
Validation loss: 2.7180116919463035

Epoch: 42| Step: 0
Training loss: 3.1919188443816444
Validation loss: 2.717819570450858

Epoch: 6| Step: 1
Training loss: 2.987560868540975
Validation loss: 2.715793060079745

Epoch: 6| Step: 2
Training loss: 2.63505562783287
Validation loss: 2.7172727738255404

Epoch: 6| Step: 3
Training loss: 2.820921771317414
Validation loss: 2.715690587777034

Epoch: 6| Step: 4
Training loss: 3.211691811870123
Validation loss: 2.715167236413914

Epoch: 6| Step: 5
Training loss: 2.7089417776706775
Validation loss: 2.714565269603967

Epoch: 6| Step: 6
Training loss: 3.2601756208892376
Validation loss: 2.7146134525619856

Epoch: 6| Step: 7
Training loss: 3.304758346195014
Validation loss: 2.7140696626790985

Epoch: 6| Step: 8
Training loss: 3.6023303225053374
Validation loss: 2.7140877153243754

Epoch: 6| Step: 9
Training loss: 2.8570605640821647
Validation loss: 2.7143795315028467

Epoch: 6| Step: 10
Training loss: 2.8735228351079307
Validation loss: 2.7137338589414277

Epoch: 6| Step: 11
Training loss: 2.8262567408539105
Validation loss: 2.7170994781174453

Epoch: 6| Step: 12
Training loss: 2.9801205972936837
Validation loss: 2.7247908423991127

Epoch: 6| Step: 13
Training loss: 3.4830967221976596
Validation loss: 2.731288959888634

Epoch: 43| Step: 0
Training loss: 2.8565227687147945
Validation loss: 2.739879538957961

Epoch: 6| Step: 1
Training loss: 2.6471513083763227
Validation loss: 2.7252137608984124

Epoch: 6| Step: 2
Training loss: 3.363856533352387
Validation loss: 2.7209036631075776

Epoch: 6| Step: 3
Training loss: 3.7141968878929523
Validation loss: 2.71813657500148

Epoch: 6| Step: 4
Training loss: 2.745144979959808
Validation loss: 2.71032331322193

Epoch: 6| Step: 5
Training loss: 2.820201501749038
Validation loss: 2.7076061310567656

Epoch: 6| Step: 6
Training loss: 3.0986378907439476
Validation loss: 2.711539230289284

Epoch: 6| Step: 7
Training loss: 3.226600184924828
Validation loss: 2.714053177917171

Epoch: 6| Step: 8
Training loss: 2.6274950794351746
Validation loss: 2.72011584941231

Epoch: 6| Step: 9
Training loss: 3.208786589737467
Validation loss: 2.7214938424313466

Epoch: 6| Step: 10
Training loss: 3.294843291751477
Validation loss: 2.7164914041475963

Epoch: 6| Step: 11
Training loss: 2.974656022645974
Validation loss: 2.713799647387428

Epoch: 6| Step: 12
Training loss: 2.8569759456381636
Validation loss: 2.71451982365906

Epoch: 6| Step: 13
Training loss: 3.1354956801756866
Validation loss: 2.712971147857005

Epoch: 44| Step: 0
Training loss: 2.7344056917920367
Validation loss: 2.711807897096149

Epoch: 6| Step: 1
Training loss: 3.4334315412481287
Validation loss: 2.710638825293736

Epoch: 6| Step: 2
Training loss: 2.834263162814354
Validation loss: 2.708379197659176

Epoch: 6| Step: 3
Training loss: 3.1287224533447318
Validation loss: 2.7077056977881933

Epoch: 6| Step: 4
Training loss: 3.1295232462143803
Validation loss: 2.711055991215244

Epoch: 6| Step: 5
Training loss: 3.0854609254233725
Validation loss: 2.7144462345768905

Epoch: 6| Step: 6
Training loss: 2.7985221232319657
Validation loss: 2.7163303967611125

Epoch: 6| Step: 7
Training loss: 2.191027603483926
Validation loss: 2.715908485940541

Epoch: 6| Step: 8
Training loss: 3.122257707906264
Validation loss: 2.720595606886459

Epoch: 6| Step: 9
Training loss: 3.3070146740039044
Validation loss: 2.7178432945585613

Epoch: 6| Step: 10
Training loss: 2.7945093134316883
Validation loss: 2.711491172342406

Epoch: 6| Step: 11
Training loss: 3.355887940837709
Validation loss: 2.7067396597635693

Epoch: 6| Step: 12
Training loss: 3.4349382044579526
Validation loss: 2.7048193241260994

Epoch: 6| Step: 13
Training loss: 3.0871009661465734
Validation loss: 2.7046700843579283

Epoch: 45| Step: 0
Training loss: 2.517671404309813
Validation loss: 2.704126213748639

Epoch: 6| Step: 1
Training loss: 3.096496595866511
Validation loss: 2.7036379696642454

Epoch: 6| Step: 2
Training loss: 3.2338931696886624
Validation loss: 2.7024210930290375

Epoch: 6| Step: 3
Training loss: 2.5149045113851733
Validation loss: 2.70243001502881

Epoch: 6| Step: 4
Training loss: 2.923311094796106
Validation loss: 2.700551954811898

Epoch: 6| Step: 5
Training loss: 2.478413464760698
Validation loss: 2.700818037830315

Epoch: 6| Step: 6
Training loss: 3.2467547132810775
Validation loss: 2.7041337308083984

Epoch: 6| Step: 7
Training loss: 3.106922505149256
Validation loss: 2.707673655708574

Epoch: 6| Step: 8
Training loss: 3.28110482030945
Validation loss: 2.7221604190859496

Epoch: 6| Step: 9
Training loss: 3.3683281402573026
Validation loss: 2.7242658298772566

Epoch: 6| Step: 10
Training loss: 2.8773198926621752
Validation loss: 2.7200007180243744

Epoch: 6| Step: 11
Training loss: 3.06496968240352
Validation loss: 2.705105396282993

Epoch: 6| Step: 12
Training loss: 3.7244575361518937
Validation loss: 2.69228602518628

Epoch: 6| Step: 13
Training loss: 2.7732539586329787
Validation loss: 2.6930867216058103

Epoch: 46| Step: 0
Training loss: 2.7460102269370505
Validation loss: 2.693728353354719

Epoch: 6| Step: 1
Training loss: 2.974505016277147
Validation loss: 2.6992743338461667

Epoch: 6| Step: 2
Training loss: 3.757968954846272
Validation loss: 2.7006031388173146

Epoch: 6| Step: 3
Training loss: 2.9094417642211936
Validation loss: 2.70773689637806

Epoch: 6| Step: 4
Training loss: 3.0871025107576635
Validation loss: 2.7134898483911916

Epoch: 6| Step: 5
Training loss: 3.6220327927164977
Validation loss: 2.7054708159450325

Epoch: 6| Step: 6
Training loss: 2.7554376767523356
Validation loss: 2.699289065406012

Epoch: 6| Step: 7
Training loss: 2.9743161673758194
Validation loss: 2.7060643658357773

Epoch: 6| Step: 8
Training loss: 2.8299861284866323
Validation loss: 2.7107591330682643

Epoch: 6| Step: 9
Training loss: 3.1510922430514072
Validation loss: 2.7216863092828008

Epoch: 6| Step: 10
Training loss: 3.2219179729626126
Validation loss: 2.7507505371521965

Epoch: 6| Step: 11
Training loss: 3.2027729120040185
Validation loss: 2.7620645069836085

Epoch: 6| Step: 12
Training loss: 2.4736420653449134
Validation loss: 2.7125418143246107

Epoch: 6| Step: 13
Training loss: 2.420949648384329
Validation loss: 2.695573107613331

Epoch: 47| Step: 0
Training loss: 2.8125367056252797
Validation loss: 2.6889024453517902

Epoch: 6| Step: 1
Training loss: 3.0170953358225017
Validation loss: 2.6855805895824827

Epoch: 6| Step: 2
Training loss: 2.709158805836546
Validation loss: 2.685067059294817

Epoch: 6| Step: 3
Training loss: 3.420504500226798
Validation loss: 2.68635580322109

Epoch: 6| Step: 4
Training loss: 3.010002151691263
Validation loss: 2.6865229641872235

Epoch: 6| Step: 5
Training loss: 2.3528801657676683
Validation loss: 2.6832311724174898

Epoch: 6| Step: 6
Training loss: 3.314539155759587
Validation loss: 2.684871432654999

Epoch: 6| Step: 7
Training loss: 2.931997786995962
Validation loss: 2.686020053736712

Epoch: 6| Step: 8
Training loss: 3.339047128359052
Validation loss: 2.6836751366166185

Epoch: 6| Step: 9
Training loss: 3.5828422535169513
Validation loss: 2.6862740206471543

Epoch: 6| Step: 10
Training loss: 2.600198840827528
Validation loss: 2.6852019955115907

Epoch: 6| Step: 11
Training loss: 3.330299490901183
Validation loss: 2.6828504532089044

Epoch: 6| Step: 12
Training loss: 2.939536342520123
Validation loss: 2.6813264621294466

Epoch: 6| Step: 13
Training loss: 2.6104867360016084
Validation loss: 2.6809063779859414

Epoch: 48| Step: 0
Training loss: 2.169599260164658
Validation loss: 2.6812439840214717

Epoch: 6| Step: 1
Training loss: 2.611380531623996
Validation loss: 2.6799298655210544

Epoch: 6| Step: 2
Training loss: 2.978877571502148
Validation loss: 2.6823819690146418

Epoch: 6| Step: 3
Training loss: 3.1436152101291706
Validation loss: 2.6807642856200924

Epoch: 6| Step: 4
Training loss: 2.996822740976269
Validation loss: 2.681524176290025

Epoch: 6| Step: 5
Training loss: 3.3420906584318213
Validation loss: 2.6810839417369006

Epoch: 6| Step: 6
Training loss: 3.227275040023698
Validation loss: 2.6836551484236777

Epoch: 6| Step: 7
Training loss: 3.099351378233723
Validation loss: 2.6765295711795045

Epoch: 6| Step: 8
Training loss: 2.4489465589631036
Validation loss: 2.674906357874324

Epoch: 6| Step: 9
Training loss: 3.230476130300669
Validation loss: 2.6747470021894397

Epoch: 6| Step: 10
Training loss: 2.602103054031967
Validation loss: 2.673564550126372

Epoch: 6| Step: 11
Training loss: 3.8407347723200824
Validation loss: 2.67427493958561

Epoch: 6| Step: 12
Training loss: 2.8423948307762306
Validation loss: 2.675471943259024

Epoch: 6| Step: 13
Training loss: 3.6718934403626053
Validation loss: 2.672241847802392

Epoch: 49| Step: 0
Training loss: 3.2701787273314906
Validation loss: 2.6716186682569396

Epoch: 6| Step: 1
Training loss: 2.959553498279713
Validation loss: 2.671779465588051

Epoch: 6| Step: 2
Training loss: 2.975686091961904
Validation loss: 2.6732278347145164

Epoch: 6| Step: 3
Training loss: 3.1692972466844753
Validation loss: 2.670192549324229

Epoch: 6| Step: 4
Training loss: 3.068932453643986
Validation loss: 2.6700418868417737

Epoch: 6| Step: 5
Training loss: 3.2749116259583118
Validation loss: 2.672380257730228

Epoch: 6| Step: 6
Training loss: 2.7324497093326316
Validation loss: 2.670614664319395

Epoch: 6| Step: 7
Training loss: 2.298266553713147
Validation loss: 2.6714151338473555

Epoch: 6| Step: 8
Training loss: 2.8738415913631243
Validation loss: 2.6703789386966075

Epoch: 6| Step: 9
Training loss: 2.4782914826126743
Validation loss: 2.672086657301358

Epoch: 6| Step: 10
Training loss: 2.9986488160477984
Validation loss: 2.6757034471286145

Epoch: 6| Step: 11
Training loss: 3.5880213979978204
Validation loss: 2.678377494569182

Epoch: 6| Step: 12
Training loss: 3.467441346346964
Validation loss: 2.673385173184611

Epoch: 6| Step: 13
Training loss: 2.7314070807008846
Validation loss: 2.6740152455673614

Epoch: 50| Step: 0
Training loss: 3.5357664140213623
Validation loss: 2.6707348245315288

Epoch: 6| Step: 1
Training loss: 2.463671131778071
Validation loss: 2.6680291704595143

Epoch: 6| Step: 2
Training loss: 2.844029674820529
Validation loss: 2.669675368601829

Epoch: 6| Step: 3
Training loss: 3.6490489765872853
Validation loss: 2.6734102227388665

Epoch: 6| Step: 4
Training loss: 3.009044999105302
Validation loss: 2.6706454821851064

Epoch: 6| Step: 5
Training loss: 2.7619122082667826
Validation loss: 2.66723699649149

Epoch: 6| Step: 6
Training loss: 2.8347093008584734
Validation loss: 2.6648604969954417

Epoch: 6| Step: 7
Training loss: 3.3688095682005113
Validation loss: 2.6650624888230428

Epoch: 6| Step: 8
Training loss: 2.8520382001011884
Validation loss: 2.665908548689286

Epoch: 6| Step: 9
Training loss: 2.868865891320187
Validation loss: 2.666169345791307

Epoch: 6| Step: 10
Training loss: 2.822234790461966
Validation loss: 2.6631029014029504

Epoch: 6| Step: 11
Training loss: 3.5770721885642325
Validation loss: 2.66178248780762

Epoch: 6| Step: 12
Training loss: 2.471155274524065
Validation loss: 2.6642518056099975

Epoch: 6| Step: 13
Training loss: 2.7815499304733957
Validation loss: 2.6807600663787943

Epoch: 51| Step: 0
Training loss: 3.7168113720240794
Validation loss: 2.680475164247198

Epoch: 6| Step: 1
Training loss: 2.75017243624971
Validation loss: 2.6651723626775605

Epoch: 6| Step: 2
Training loss: 2.8797213721598856
Validation loss: 2.6623274408746176

Epoch: 6| Step: 3
Training loss: 2.3777820956506868
Validation loss: 2.6600757494119405

Epoch: 6| Step: 4
Training loss: 2.890194752608864
Validation loss: 2.6581064318033047

Epoch: 6| Step: 5
Training loss: 3.2156027805164973
Validation loss: 2.6620479505601664

Epoch: 6| Step: 6
Training loss: 2.5951413019477756
Validation loss: 2.6625366527702234

Epoch: 6| Step: 7
Training loss: 3.123098634215789
Validation loss: 2.6639704558623096

Epoch: 6| Step: 8
Training loss: 3.1530228536825935
Validation loss: 2.6674613226865875

Epoch: 6| Step: 9
Training loss: 2.9503351182841357
Validation loss: 2.6718124538724775

Epoch: 6| Step: 10
Training loss: 3.3777197722702446
Validation loss: 2.6815218655437185

Epoch: 6| Step: 11
Training loss: 3.1183544450864513
Validation loss: 2.6884832231523212

Epoch: 6| Step: 12
Training loss: 3.0346096337036967
Validation loss: 2.7055840328621072

Epoch: 6| Step: 13
Training loss: 2.5465469617155416
Validation loss: 2.7087369600704054

Epoch: 52| Step: 0
Training loss: 2.7201601953174923
Validation loss: 2.6969180149588214

Epoch: 6| Step: 1
Training loss: 2.9354278073303623
Validation loss: 2.6815639797059347

Epoch: 6| Step: 2
Training loss: 2.954225688249674
Validation loss: 2.667612360600046

Epoch: 6| Step: 3
Training loss: 3.14219633809672
Validation loss: 2.6648158494205574

Epoch: 6| Step: 4
Training loss: 2.1287406087008534
Validation loss: 2.659952873620856

Epoch: 6| Step: 5
Training loss: 3.498196682259446
Validation loss: 2.663302065637411

Epoch: 6| Step: 6
Training loss: 3.201992225384968
Validation loss: 2.6607987304706495

Epoch: 6| Step: 7
Training loss: 2.764462328986197
Validation loss: 2.662905700669127

Epoch: 6| Step: 8
Training loss: 3.125552166794065
Validation loss: 2.662733260801841

Epoch: 6| Step: 9
Training loss: 3.242412219245375
Validation loss: 2.6619127074052247

Epoch: 6| Step: 10
Training loss: 3.0451249794453257
Validation loss: 2.661414138571174

Epoch: 6| Step: 11
Training loss: 3.113743459356997
Validation loss: 2.6599772902089915

Epoch: 6| Step: 12
Training loss: 3.425349174576723
Validation loss: 2.659333020656366

Epoch: 6| Step: 13
Training loss: 2.342898710144618
Validation loss: 2.655577482904806

Epoch: 53| Step: 0
Training loss: 2.9991458630580055
Validation loss: 2.6568807452644494

Epoch: 6| Step: 1
Training loss: 3.3167418185462605
Validation loss: 2.651754825410186

Epoch: 6| Step: 2
Training loss: 2.5654298733702827
Validation loss: 2.6521558804856076

Epoch: 6| Step: 3
Training loss: 2.89129399986448
Validation loss: 2.6520626169158974

Epoch: 6| Step: 4
Training loss: 3.3831588180207652
Validation loss: 2.65371760294913

Epoch: 6| Step: 5
Training loss: 3.048917271778847
Validation loss: 2.657481140468636

Epoch: 6| Step: 6
Training loss: 3.0442167766243347
Validation loss: 2.6613507512858554

Epoch: 6| Step: 7
Training loss: 2.873161391433761
Validation loss: 2.665050784825769

Epoch: 6| Step: 8
Training loss: 2.1370210032807666
Validation loss: 2.6658268764313164

Epoch: 6| Step: 9
Training loss: 2.358236379169366
Validation loss: 2.6693754864858144

Epoch: 6| Step: 10
Training loss: 3.2467849674904667
Validation loss: 2.6841501591543917

Epoch: 6| Step: 11
Training loss: 3.276532660454404
Validation loss: 2.686816959335717

Epoch: 6| Step: 12
Training loss: 3.3367538703958317
Validation loss: 2.684270656100614

Epoch: 6| Step: 13
Training loss: 3.3480203045556336
Validation loss: 2.6873958917567777

Epoch: 54| Step: 0
Training loss: 3.3486816545085603
Validation loss: 2.680271801183671

Epoch: 6| Step: 1
Training loss: 2.4867450277682033
Validation loss: 2.6595973639505233

Epoch: 6| Step: 2
Training loss: 2.6562913779233503
Validation loss: 2.6489579968255876

Epoch: 6| Step: 3
Training loss: 3.036049101501574
Validation loss: 2.6459848756019113

Epoch: 6| Step: 4
Training loss: 3.5811303190302137
Validation loss: 2.64575975461284

Epoch: 6| Step: 5
Training loss: 2.898440296757832
Validation loss: 2.6451987184607275

Epoch: 6| Step: 6
Training loss: 2.5720618883461785
Validation loss: 2.643999681484022

Epoch: 6| Step: 7
Training loss: 3.8088287437519366
Validation loss: 2.643534589905372

Epoch: 6| Step: 8
Training loss: 2.9642550521026383
Validation loss: 2.6448957529178534

Epoch: 6| Step: 9
Training loss: 2.938483215709899
Validation loss: 2.6428247589877873

Epoch: 6| Step: 10
Training loss: 2.4660166807639214
Validation loss: 2.6427636885652785

Epoch: 6| Step: 11
Training loss: 3.1432857345046177
Validation loss: 2.64221130458562

Epoch: 6| Step: 12
Training loss: 2.7966683593793378
Validation loss: 2.6433426688000625

Epoch: 6| Step: 13
Training loss: 2.8023477214511776
Validation loss: 2.6494599604509146

Epoch: 55| Step: 0
Training loss: 3.220041108668663
Validation loss: 2.6609629331782356

Epoch: 6| Step: 1
Training loss: 2.679697464904941
Validation loss: 2.667167886293437

Epoch: 6| Step: 2
Training loss: 3.3387676446206354
Validation loss: 2.7128682391606973

Epoch: 6| Step: 3
Training loss: 3.4116079205435703
Validation loss: 2.6708985833959877

Epoch: 6| Step: 4
Training loss: 2.340537756400384
Validation loss: 2.6531738034033836

Epoch: 6| Step: 5
Training loss: 3.4137391519950335
Validation loss: 2.6458357482413377

Epoch: 6| Step: 6
Training loss: 2.8811897321177824
Validation loss: 2.6474581022008294

Epoch: 6| Step: 7
Training loss: 3.310498766704284
Validation loss: 2.6605087662757985

Epoch: 6| Step: 8
Training loss: 2.6250210715765125
Validation loss: 2.6844860059443745

Epoch: 6| Step: 9
Training loss: 3.1398277978997298
Validation loss: 2.708203231835589

Epoch: 6| Step: 10
Training loss: 3.106326962290878
Validation loss: 2.7043060998163138

Epoch: 6| Step: 11
Training loss: 2.8166988818641885
Validation loss: 2.682331038481868

Epoch: 6| Step: 12
Training loss: 2.569613747274221
Validation loss: 2.6847968533174416

Epoch: 6| Step: 13
Training loss: 3.0880990871877865
Validation loss: 2.6820716179056823

Epoch: 56| Step: 0
Training loss: 3.215692642138109
Validation loss: 2.6902421591626915

Epoch: 6| Step: 1
Training loss: 2.5633334223429345
Validation loss: 2.7033400996812516

Epoch: 6| Step: 2
Training loss: 3.5969778409121034
Validation loss: 2.7154817967077576

Epoch: 6| Step: 3
Training loss: 2.9592364011895027
Validation loss: 2.729907739217616

Epoch: 6| Step: 4
Training loss: 2.871691583166292
Validation loss: 2.709596738368607

Epoch: 6| Step: 5
Training loss: 3.438093238271945
Validation loss: 2.7060292371769856

Epoch: 6| Step: 6
Training loss: 2.470512919586932
Validation loss: 2.6984400208137447

Epoch: 6| Step: 7
Training loss: 2.831941337473572
Validation loss: 2.67856403890861

Epoch: 6| Step: 8
Training loss: 2.9764327373905095
Validation loss: 2.673041567267925

Epoch: 6| Step: 9
Training loss: 3.2181410722744226
Validation loss: 2.665906865821158

Epoch: 6| Step: 10
Training loss: 3.2023022595240036
Validation loss: 2.663379526191155

Epoch: 6| Step: 11
Training loss: 2.7137042172021424
Validation loss: 2.6454513848372656

Epoch: 6| Step: 12
Training loss: 2.763805157039012
Validation loss: 2.63869278104792

Epoch: 6| Step: 13
Training loss: 3.1263671936008466
Validation loss: 2.6493574480617275

Epoch: 57| Step: 0
Training loss: 2.898589179087988
Validation loss: 2.640693682589065

Epoch: 6| Step: 1
Training loss: 2.8648357673161384
Validation loss: 2.6534295663229237

Epoch: 6| Step: 2
Training loss: 3.244395485454885
Validation loss: 2.6621793772758893

Epoch: 6| Step: 3
Training loss: 2.903858143980406
Validation loss: 2.6419667956553283

Epoch: 6| Step: 4
Training loss: 3.0968005620823367
Validation loss: 2.6315515360756576

Epoch: 6| Step: 5
Training loss: 2.9150068373951625
Validation loss: 2.631410516800998

Epoch: 6| Step: 6
Training loss: 3.502022567545594
Validation loss: 2.6309702553166994

Epoch: 6| Step: 7
Training loss: 2.922492140603572
Validation loss: 2.631415372437569

Epoch: 6| Step: 8
Training loss: 1.9771326019397577
Validation loss: 2.630224210353526

Epoch: 6| Step: 9
Training loss: 3.3436831173491313
Validation loss: 2.629010043505537

Epoch: 6| Step: 10
Training loss: 3.367610046355784
Validation loss: 2.627782954949369

Epoch: 6| Step: 11
Training loss: 2.254565164124707
Validation loss: 2.6267325743035577

Epoch: 6| Step: 12
Training loss: 3.1544454722641495
Validation loss: 2.625272575559474

Epoch: 6| Step: 13
Training loss: 3.1014676403846337
Validation loss: 2.6250240541636383

Epoch: 58| Step: 0
Training loss: 3.3570148072562467
Validation loss: 2.6267224670266462

Epoch: 6| Step: 1
Training loss: 2.8710072199439374
Validation loss: 2.6282233601769103

Epoch: 6| Step: 2
Training loss: 3.6150903410327277
Validation loss: 2.627067532990797

Epoch: 6| Step: 3
Training loss: 2.9132712264027916
Validation loss: 2.6271609686025656

Epoch: 6| Step: 4
Training loss: 2.90283741096274
Validation loss: 2.625981724967384

Epoch: 6| Step: 5
Training loss: 2.92353732714923
Validation loss: 2.624705465603512

Epoch: 6| Step: 6
Training loss: 2.152808829736481
Validation loss: 2.6276163958493965

Epoch: 6| Step: 7
Training loss: 3.54496626392663
Validation loss: 2.6286054482176042

Epoch: 6| Step: 8
Training loss: 3.087059106891761
Validation loss: 2.629497341739252

Epoch: 6| Step: 9
Training loss: 2.8735379357595945
Validation loss: 2.6271954626967555

Epoch: 6| Step: 10
Training loss: 3.2909415850814576
Validation loss: 2.625476762610472

Epoch: 6| Step: 11
Training loss: 2.2353703342647804
Validation loss: 2.6286647731865136

Epoch: 6| Step: 12
Training loss: 2.5572796191354508
Validation loss: 2.628689880248476

Epoch: 6| Step: 13
Training loss: 2.978085266040353
Validation loss: 2.632808996527898

Epoch: 59| Step: 0
Training loss: 3.0327004963761612
Validation loss: 2.631001227693309

Epoch: 6| Step: 1
Training loss: 3.1957316601697077
Validation loss: 2.651430090227164

Epoch: 6| Step: 2
Training loss: 2.8841817441860513
Validation loss: 2.6225841106890426

Epoch: 6| Step: 3
Training loss: 2.7318747288257166
Validation loss: 2.618679268348937

Epoch: 6| Step: 4
Training loss: 2.944669375035419
Validation loss: 2.6178383446648072

Epoch: 6| Step: 5
Training loss: 3.0617067516390635
Validation loss: 2.620487602561148

Epoch: 6| Step: 6
Training loss: 3.3930908237379627
Validation loss: 2.624718133820665

Epoch: 6| Step: 7
Training loss: 2.874576371536491
Validation loss: 2.6290224891285825

Epoch: 6| Step: 8
Training loss: 3.0706914226259014
Validation loss: 2.628501393929201

Epoch: 6| Step: 9
Training loss: 2.8068183306433196
Validation loss: 2.625406255307706

Epoch: 6| Step: 10
Training loss: 3.1399605271111937
Validation loss: 2.633159200911321

Epoch: 6| Step: 11
Training loss: 2.7672466976095405
Validation loss: 2.6386076868211323

Epoch: 6| Step: 12
Training loss: 3.182721314507494
Validation loss: 2.651189944541908

Epoch: 6| Step: 13
Training loss: 2.2199771335214593
Validation loss: 2.6466860828982584

Epoch: 60| Step: 0
Training loss: 2.8989002444475904
Validation loss: 2.6410762709265327

Epoch: 6| Step: 1
Training loss: 3.3396344392562205
Validation loss: 2.6159944418428247

Epoch: 6| Step: 2
Training loss: 2.9282258723745263
Validation loss: 2.6116549978452257

Epoch: 6| Step: 3
Training loss: 3.0826245257864247
Validation loss: 2.613863352472548

Epoch: 6| Step: 4
Training loss: 3.00004259715038
Validation loss: 2.6133355823687774

Epoch: 6| Step: 5
Training loss: 2.5822302298696163
Validation loss: 2.6187154346420534

Epoch: 6| Step: 6
Training loss: 2.936886175426223
Validation loss: 2.6155396981341386

Epoch: 6| Step: 7
Training loss: 2.696141300760361
Validation loss: 2.6124355206346284

Epoch: 6| Step: 8
Training loss: 3.0879245975756113
Validation loss: 2.6125661126931026

Epoch: 6| Step: 9
Training loss: 2.4492879611370824
Validation loss: 2.6113456136261584

Epoch: 6| Step: 10
Training loss: 2.892465201574909
Validation loss: 2.6068303467338585

Epoch: 6| Step: 11
Training loss: 2.809031742838694
Validation loss: 2.606530941339595

Epoch: 6| Step: 12
Training loss: 3.585977790955226
Validation loss: 2.6074322792968037

Epoch: 6| Step: 13
Training loss: 3.322249406329827
Validation loss: 2.6099471580720532

Epoch: 61| Step: 0
Training loss: 3.314923821173806
Validation loss: 2.6084662369146434

Epoch: 6| Step: 1
Training loss: 3.790516996928507
Validation loss: 2.6059274262500836

Epoch: 6| Step: 2
Training loss: 3.0301483354675103
Validation loss: 2.6040482088444703

Epoch: 6| Step: 3
Training loss: 2.502172860971856
Validation loss: 2.6023582417382194

Epoch: 6| Step: 4
Training loss: 2.9505371380608265
Validation loss: 2.605906797435667

Epoch: 6| Step: 5
Training loss: 2.941999195817102
Validation loss: 2.6017479599327573

Epoch: 6| Step: 6
Training loss: 2.232315287878177
Validation loss: 2.6054166456008794

Epoch: 6| Step: 7
Training loss: 2.5874811733869363
Validation loss: 2.6036056491789656

Epoch: 6| Step: 8
Training loss: 3.038520823553134
Validation loss: 2.606006649256755

Epoch: 6| Step: 9
Training loss: 2.9377707498645576
Validation loss: 2.6089898617879665

Epoch: 6| Step: 10
Training loss: 2.6055988696776655
Validation loss: 2.620418568416326

Epoch: 6| Step: 11
Training loss: 2.9005014314902775
Validation loss: 2.6292847676863382

Epoch: 6| Step: 12
Training loss: 3.35342234691182
Validation loss: 2.6334081325159713

Epoch: 6| Step: 13
Training loss: 3.1447082090638885
Validation loss: 2.6362620021826317

Epoch: 62| Step: 0
Training loss: 3.4307478740562964
Validation loss: 2.6043536119527246

Epoch: 6| Step: 1
Training loss: 3.248387156615217
Validation loss: 2.599177153773508

Epoch: 6| Step: 2
Training loss: 3.3557130238410533
Validation loss: 2.6004426632593214

Epoch: 6| Step: 3
Training loss: 2.742823165728522
Validation loss: 2.6065179162197993

Epoch: 6| Step: 4
Training loss: 2.8435294935649824
Validation loss: 2.61472920192809

Epoch: 6| Step: 5
Training loss: 3.2569280288235607
Validation loss: 2.6283791410432777

Epoch: 6| Step: 6
Training loss: 3.007380466892083
Validation loss: 2.633908581341892

Epoch: 6| Step: 7
Training loss: 2.7615245011579392
Validation loss: 2.624551935038994

Epoch: 6| Step: 8
Training loss: 2.5907702507649217
Validation loss: 2.659872481572332

Epoch: 6| Step: 9
Training loss: 3.121129194495234
Validation loss: 2.6104623190626772

Epoch: 6| Step: 10
Training loss: 2.127771701698935
Validation loss: 2.608534331369588

Epoch: 6| Step: 11
Training loss: 3.2210661323246055
Validation loss: 2.606227063280498

Epoch: 6| Step: 12
Training loss: 2.736610240129982
Validation loss: 2.6014354107780293

Epoch: 6| Step: 13
Training loss: 2.821009922181874
Validation loss: 2.6006874830886084

Epoch: 63| Step: 0
Training loss: 3.156182921046167
Validation loss: 2.608974180138736

Epoch: 6| Step: 1
Training loss: 3.160011844612811
Validation loss: 2.633200337086453

Epoch: 6| Step: 2
Training loss: 2.463317108135275
Validation loss: 2.646639902432035

Epoch: 6| Step: 3
Training loss: 2.7191125912968683
Validation loss: 2.648551620719056

Epoch: 6| Step: 4
Training loss: 3.245272499245688
Validation loss: 2.6612702502242294

Epoch: 6| Step: 5
Training loss: 3.0125647320262576
Validation loss: 2.6462464543374535

Epoch: 6| Step: 6
Training loss: 3.3958932758181715
Validation loss: 2.630697878360317

Epoch: 6| Step: 7
Training loss: 2.994771056173417
Validation loss: 2.6180309765140515

Epoch: 6| Step: 8
Training loss: 2.8812162120104006
Validation loss: 2.60788360510365

Epoch: 6| Step: 9
Training loss: 3.226927212476157
Validation loss: 2.608965867126482

Epoch: 6| Step: 10
Training loss: 3.2587403364371124
Validation loss: 2.6073265540954274

Epoch: 6| Step: 11
Training loss: 2.845065640461597
Validation loss: 2.6032114363186034

Epoch: 6| Step: 12
Training loss: 2.315837822528051
Validation loss: 2.6001280769626405

Epoch: 6| Step: 13
Training loss: 2.5497558776087548
Validation loss: 2.5973051347217377

Epoch: 64| Step: 0
Training loss: 3.0667702622814397
Validation loss: 2.5960960487392404

Epoch: 6| Step: 1
Training loss: 2.827010804616159
Validation loss: 2.593444978263797

Epoch: 6| Step: 2
Training loss: 3.05233541408911
Validation loss: 2.5977682682408934

Epoch: 6| Step: 3
Training loss: 3.180519238911998
Validation loss: 2.598375776010384

Epoch: 6| Step: 4
Training loss: 2.7413118273872357
Validation loss: 2.596805636235266

Epoch: 6| Step: 5
Training loss: 2.816108000011845
Validation loss: 2.599080366585242

Epoch: 6| Step: 6
Training loss: 3.0320505874359203
Validation loss: 2.595504540925024

Epoch: 6| Step: 7
Training loss: 3.1964698691413647
Validation loss: 2.5966580305140563

Epoch: 6| Step: 8
Training loss: 2.8239236891218646
Validation loss: 2.596195825632897

Epoch: 6| Step: 9
Training loss: 2.4138845236148243
Validation loss: 2.599169284838557

Epoch: 6| Step: 10
Training loss: 2.9975663486547552
Validation loss: 2.6006387459200173

Epoch: 6| Step: 11
Training loss: 2.8951874888689204
Validation loss: 2.606410188715321

Epoch: 6| Step: 12
Training loss: 3.079393154653646
Validation loss: 2.6168871850993116

Epoch: 6| Step: 13
Training loss: 3.3158371148315964
Validation loss: 2.633636005988219

Epoch: 65| Step: 0
Training loss: 3.2732675002937057
Validation loss: 2.607416599095207

Epoch: 6| Step: 1
Training loss: 2.9646620060196613
Validation loss: 2.5970977802159445

Epoch: 6| Step: 2
Training loss: 2.3131480984177437
Validation loss: 2.591738380769657

Epoch: 6| Step: 3
Training loss: 2.8829461456995524
Validation loss: 2.5941710878383817

Epoch: 6| Step: 4
Training loss: 3.013076733351146
Validation loss: 2.5912947585285755

Epoch: 6| Step: 5
Training loss: 3.2162674895017482
Validation loss: 2.5898264824345993

Epoch: 6| Step: 6
Training loss: 3.019686321111064
Validation loss: 2.592436781104612

Epoch: 6| Step: 7
Training loss: 3.3494809673820347
Validation loss: 2.6025855201712322

Epoch: 6| Step: 8
Training loss: 2.7418068298254776
Validation loss: 2.590492906743888

Epoch: 6| Step: 9
Training loss: 3.091644186947541
Validation loss: 2.5893675460787944

Epoch: 6| Step: 10
Training loss: 2.8039583836404383
Validation loss: 2.5941220256515676

Epoch: 6| Step: 11
Training loss: 2.6823730357645683
Validation loss: 2.587975973253105

Epoch: 6| Step: 12
Training loss: 3.088563984387686
Validation loss: 2.5853584696356333

Epoch: 6| Step: 13
Training loss: 2.4772082909801174
Validation loss: 2.590976058551915

Epoch: 66| Step: 0
Training loss: 2.9993631958614944
Validation loss: 2.6035753513182436

Epoch: 6| Step: 1
Training loss: 2.468346285102378
Validation loss: 2.6096440638839886

Epoch: 6| Step: 2
Training loss: 2.731160481467723
Validation loss: 2.6099194729925608

Epoch: 6| Step: 3
Training loss: 3.3287414552963552
Validation loss: 2.610598311720227

Epoch: 6| Step: 4
Training loss: 2.823262117276595
Validation loss: 2.6113199500530135

Epoch: 6| Step: 5
Training loss: 2.7020280850501726
Validation loss: 2.601812869264043

Epoch: 6| Step: 6
Training loss: 3.2023549712766926
Validation loss: 2.5960797174397086

Epoch: 6| Step: 7
Training loss: 2.7512685277541165
Validation loss: 2.5925235064930057

Epoch: 6| Step: 8
Training loss: 2.4952484753253095
Validation loss: 2.5926912847543506

Epoch: 6| Step: 9
Training loss: 3.5454924321317782
Validation loss: 2.5994989410468863

Epoch: 6| Step: 10
Training loss: 3.0262936056620315
Validation loss: 2.6161662220500577

Epoch: 6| Step: 11
Training loss: 3.6463685142446596
Validation loss: 2.6552417016455747

Epoch: 6| Step: 12
Training loss: 3.1216939604449094
Validation loss: 2.668499365531199

Epoch: 6| Step: 13
Training loss: 1.9072080612261872
Validation loss: 2.632567333336538

Epoch: 67| Step: 0
Training loss: 2.927144566955471
Validation loss: 2.6233199877182605

Epoch: 6| Step: 1
Training loss: 2.380173920119
Validation loss: 2.613448083126971

Epoch: 6| Step: 2
Training loss: 3.221811412698096
Validation loss: 2.609751737466706

Epoch: 6| Step: 3
Training loss: 3.4631463229148225
Validation loss: 2.618562123644478

Epoch: 6| Step: 4
Training loss: 2.7472556031704825
Validation loss: 2.596413069686847

Epoch: 6| Step: 5
Training loss: 3.259285500048315
Validation loss: 2.5945219968393562

Epoch: 6| Step: 6
Training loss: 2.7784547796710677
Validation loss: 2.598812572579035

Epoch: 6| Step: 7
Training loss: 2.4529726017550497
Validation loss: 2.6022308091330615

Epoch: 6| Step: 8
Training loss: 3.027309097583934
Validation loss: 2.6081268142952556

Epoch: 6| Step: 9
Training loss: 3.0890786710324547
Validation loss: 2.613401405572447

Epoch: 6| Step: 10
Training loss: 2.68776577367262
Validation loss: 2.624736861572627

Epoch: 6| Step: 11
Training loss: 3.0637503426534898
Validation loss: 2.616844218158149

Epoch: 6| Step: 12
Training loss: 3.1646179465200097
Validation loss: 2.601786806206668

Epoch: 6| Step: 13
Training loss: 3.0377768810276784
Validation loss: 2.599811399567291

Epoch: 68| Step: 0
Training loss: 2.7206596595594785
Validation loss: 2.5990049164959066

Epoch: 6| Step: 1
Training loss: 2.9571750862887365
Validation loss: 2.5968712673464243

Epoch: 6| Step: 2
Training loss: 2.565636552791628
Validation loss: 2.5961799175966993

Epoch: 6| Step: 3
Training loss: 2.969135460173445
Validation loss: 2.5926729000204585

Epoch: 6| Step: 4
Training loss: 2.9363391286834863
Validation loss: 2.5920772097804345

Epoch: 6| Step: 5
Training loss: 2.9604714059478043
Validation loss: 2.588524494736061

Epoch: 6| Step: 6
Training loss: 2.72766300934586
Validation loss: 2.5864784471248483

Epoch: 6| Step: 7
Training loss: 3.312663236230753
Validation loss: 2.589294331761202

Epoch: 6| Step: 8
Training loss: 2.4119399532479515
Validation loss: 2.607123440226954

Epoch: 6| Step: 9
Training loss: 3.6287695917486964
Validation loss: 2.641694056079511

Epoch: 6| Step: 10
Training loss: 3.2847840668705754
Validation loss: 2.629272620691382

Epoch: 6| Step: 11
Training loss: 2.9823289818027594
Validation loss: 2.592354459462409

Epoch: 6| Step: 12
Training loss: 3.3560415363037444
Validation loss: 2.5839617682955565

Epoch: 6| Step: 13
Training loss: 1.695439276811284
Validation loss: 2.5811538917156938

Epoch: 69| Step: 0
Training loss: 3.1704597510391115
Validation loss: 2.581916172937699

Epoch: 6| Step: 1
Training loss: 3.0816049800769183
Validation loss: 2.5822350995537033

Epoch: 6| Step: 2
Training loss: 2.9884607597737536
Validation loss: 2.58623669434485

Epoch: 6| Step: 3
Training loss: 2.756308083127681
Validation loss: 2.586996449246887

Epoch: 6| Step: 4
Training loss: 3.289251544077291
Validation loss: 2.5864168060045474

Epoch: 6| Step: 5
Training loss: 2.8389046439844927
Validation loss: 2.584614699577649

Epoch: 6| Step: 6
Training loss: 3.7037970983244533
Validation loss: 2.583520598344216

Epoch: 6| Step: 7
Training loss: 2.982557772055298
Validation loss: 2.5828756470450425

Epoch: 6| Step: 8
Training loss: 2.9320818666215307
Validation loss: 2.5843466981848744

Epoch: 6| Step: 9
Training loss: 2.654509479016459
Validation loss: 2.6298930519025636

Epoch: 6| Step: 10
Training loss: 2.9103440192150245
Validation loss: 2.6087079059089517

Epoch: 6| Step: 11
Training loss: 2.6519537794938617
Validation loss: 2.57650901288039

Epoch: 6| Step: 12
Training loss: 2.52136466571713
Validation loss: 2.5861565613884228

Epoch: 6| Step: 13
Training loss: 2.306093259204342
Validation loss: 2.595436026585332

Epoch: 70| Step: 0
Training loss: 2.589195481029417
Validation loss: 2.6140105780389913

Epoch: 6| Step: 1
Training loss: 3.1031130511004843
Validation loss: 2.633495519847928

Epoch: 6| Step: 2
Training loss: 3.1520236584312857
Validation loss: 2.6716445116291525

Epoch: 6| Step: 3
Training loss: 2.6792169719460333
Validation loss: 2.6907249498148578

Epoch: 6| Step: 4
Training loss: 2.7859846811797637
Validation loss: 2.666598561081215

Epoch: 6| Step: 5
Training loss: 2.8875817027237143
Validation loss: 2.6470262898116004

Epoch: 6| Step: 6
Training loss: 2.9399157391365245
Validation loss: 2.6381894120643183

Epoch: 6| Step: 7
Training loss: 3.099639219393972
Validation loss: 2.623742997514448

Epoch: 6| Step: 8
Training loss: 3.806367162645726
Validation loss: 2.598425571835875

Epoch: 6| Step: 9
Training loss: 2.841935134093754
Validation loss: 2.600225605023188

Epoch: 6| Step: 10
Training loss: 2.292761096292335
Validation loss: 2.589495716644355

Epoch: 6| Step: 11
Training loss: 2.3362990900049083
Validation loss: 2.5800312998050274

Epoch: 6| Step: 12
Training loss: 3.575144229993916
Validation loss: 2.5841207075099724

Epoch: 6| Step: 13
Training loss: 2.9058133689457835
Validation loss: 2.5738956030053695

Epoch: 71| Step: 0
Training loss: 2.711316524690193
Validation loss: 2.574144182596165

Epoch: 6| Step: 1
Training loss: 2.513953559938186
Validation loss: 2.578000780818964

Epoch: 6| Step: 2
Training loss: 3.0764880789865714
Validation loss: 2.5722551262998254

Epoch: 6| Step: 3
Training loss: 3.023158964984057
Validation loss: 2.5765886300002614

Epoch: 6| Step: 4
Training loss: 2.901104381346822
Validation loss: 2.58260696042236

Epoch: 6| Step: 5
Training loss: 3.490882578526953
Validation loss: 2.582708082308115

Epoch: 6| Step: 6
Training loss: 3.01360573637325
Validation loss: 2.5877106035383646

Epoch: 6| Step: 7
Training loss: 2.387002032211583
Validation loss: 2.5838925946787348

Epoch: 6| Step: 8
Training loss: 3.4917431576407028
Validation loss: 2.5724652276958304

Epoch: 6| Step: 9
Training loss: 3.1433711405719134
Validation loss: 2.567444454778937

Epoch: 6| Step: 10
Training loss: 2.8082138462474866
Validation loss: 2.5665194733561965

Epoch: 6| Step: 11
Training loss: 2.6790368538628706
Validation loss: 2.5650175789689227

Epoch: 6| Step: 12
Training loss: 2.7963094299303646
Validation loss: 2.567494109622345

Epoch: 6| Step: 13
Training loss: 2.8548160751610685
Validation loss: 2.5692871683800393

Epoch: 72| Step: 0
Training loss: 2.502445550682544
Validation loss: 2.571926667962834

Epoch: 6| Step: 1
Training loss: 3.2695226452713086
Validation loss: 2.571789048075065

Epoch: 6| Step: 2
Training loss: 3.2506531279200863
Validation loss: 2.5736025335778665

Epoch: 6| Step: 3
Training loss: 2.980457230891895
Validation loss: 2.5765656250863005

Epoch: 6| Step: 4
Training loss: 2.966201009172987
Validation loss: 2.5830280495382065

Epoch: 6| Step: 5
Training loss: 3.017219398681553
Validation loss: 2.5712554665109457

Epoch: 6| Step: 6
Training loss: 3.106312532774114
Validation loss: 2.5667119739605067

Epoch: 6| Step: 7
Training loss: 3.2543200610970326
Validation loss: 2.564131931674329

Epoch: 6| Step: 8
Training loss: 2.678941450446776
Validation loss: 2.5569912975262215

Epoch: 6| Step: 9
Training loss: 2.5286312921317435
Validation loss: 2.557965680621766

Epoch: 6| Step: 10
Training loss: 3.0111373161999304
Validation loss: 2.554952305116473

Epoch: 6| Step: 11
Training loss: 2.8744532853141176
Validation loss: 2.557411772634245

Epoch: 6| Step: 12
Training loss: 2.507022531220232
Validation loss: 2.556669490153684

Epoch: 6| Step: 13
Training loss: 2.8098647593470245
Validation loss: 2.556974390618873

Epoch: 73| Step: 0
Training loss: 3.4277000142953713
Validation loss: 2.564129699101207

Epoch: 6| Step: 1
Training loss: 2.7255082592612463
Validation loss: 2.555751280388206

Epoch: 6| Step: 2
Training loss: 3.1707659506603743
Validation loss: 2.558656237253361

Epoch: 6| Step: 3
Training loss: 2.423402956452612
Validation loss: 2.558766855938918

Epoch: 6| Step: 4
Training loss: 2.960708166415543
Validation loss: 2.55754271744592

Epoch: 6| Step: 5
Training loss: 3.117371058975164
Validation loss: 2.5539988464853436

Epoch: 6| Step: 6
Training loss: 2.741802308071355
Validation loss: 2.54916843469504

Epoch: 6| Step: 7
Training loss: 2.847558458111665
Validation loss: 2.548937593161117

Epoch: 6| Step: 8
Training loss: 2.3207924086445595
Validation loss: 2.548252522596686

Epoch: 6| Step: 9
Training loss: 3.069723213467267
Validation loss: 2.552925974946179

Epoch: 6| Step: 10
Training loss: 2.8406695774722666
Validation loss: 2.5552810210800354

Epoch: 6| Step: 11
Training loss: 3.0039513315456565
Validation loss: 2.5620121645332086

Epoch: 6| Step: 12
Training loss: 3.4149809765041526
Validation loss: 2.567664820338937

Epoch: 6| Step: 13
Training loss: 2.2910539212485506
Validation loss: 2.5594049656446343

Epoch: 74| Step: 0
Training loss: 2.8049455699297545
Validation loss: 2.5573252148640786

Epoch: 6| Step: 1
Training loss: 3.2085228075498207
Validation loss: 2.5529585940693247

Epoch: 6| Step: 2
Training loss: 2.393311032516304
Validation loss: 2.5495826736798803

Epoch: 6| Step: 3
Training loss: 3.215524483194984
Validation loss: 2.553628960670109

Epoch: 6| Step: 4
Training loss: 2.975439625802694
Validation loss: 2.5620965157269153

Epoch: 6| Step: 5
Training loss: 2.980174358822714
Validation loss: 2.5700205082787537

Epoch: 6| Step: 6
Training loss: 2.3404389453887244
Validation loss: 2.5832588487407

Epoch: 6| Step: 7
Training loss: 2.9865345755669948
Validation loss: 2.5801723789322453

Epoch: 6| Step: 8
Training loss: 3.3936100490088554
Validation loss: 2.5668780486175615

Epoch: 6| Step: 9
Training loss: 2.5806459990238553
Validation loss: 2.5510084385255185

Epoch: 6| Step: 10
Training loss: 2.9167824495131764
Validation loss: 2.547547164688577

Epoch: 6| Step: 11
Training loss: 3.314065815061991
Validation loss: 2.5433740168314265

Epoch: 6| Step: 12
Training loss: 2.1421278529972074
Validation loss: 2.546353541746124

Epoch: 6| Step: 13
Training loss: 3.4323280961568883
Validation loss: 2.5594164746340553

Epoch: 75| Step: 0
Training loss: 2.7392577254623425
Validation loss: 2.564566906414518

Epoch: 6| Step: 1
Training loss: 3.2832371098962385
Validation loss: 2.569704200927488

Epoch: 6| Step: 2
Training loss: 2.7959015073769384
Validation loss: 2.578488391114281

Epoch: 6| Step: 3
Training loss: 3.058167799403205
Validation loss: 2.583836102328202

Epoch: 6| Step: 4
Training loss: 3.2906343958069355
Validation loss: 2.587427337467991

Epoch: 6| Step: 5
Training loss: 2.434477668526595
Validation loss: 2.577506115943543

Epoch: 6| Step: 6
Training loss: 3.285288623224849
Validation loss: 2.571998582516628

Epoch: 6| Step: 7
Training loss: 3.3535169047118263
Validation loss: 2.566834900742397

Epoch: 6| Step: 8
Training loss: 2.8001696398980958
Validation loss: 2.5587578718433632

Epoch: 6| Step: 9
Training loss: 2.760452001573424
Validation loss: 2.5573647319080846

Epoch: 6| Step: 10
Training loss: 3.176286007415472
Validation loss: 2.55696306514418

Epoch: 6| Step: 11
Training loss: 2.6522385768797205
Validation loss: 2.5613076982528455

Epoch: 6| Step: 12
Training loss: 2.511757288232243
Validation loss: 2.57137244836848

Epoch: 6| Step: 13
Training loss: 2.8809356782797586
Validation loss: 2.570667217309448

Epoch: 76| Step: 0
Training loss: 2.9107506471413838
Validation loss: 2.560948023214214

Epoch: 6| Step: 1
Training loss: 3.6909625074311183
Validation loss: 2.5600309985441356

Epoch: 6| Step: 2
Training loss: 2.919571238614703
Validation loss: 2.5555091377823467

Epoch: 6| Step: 3
Training loss: 2.790954802740005
Validation loss: 2.5535514598380082

Epoch: 6| Step: 4
Training loss: 2.646228059975945
Validation loss: 2.557272494447466

Epoch: 6| Step: 5
Training loss: 2.7887988566962574
Validation loss: 2.5564239782929037

Epoch: 6| Step: 6
Training loss: 2.1742685425375496
Validation loss: 2.5562946128647845

Epoch: 6| Step: 7
Training loss: 2.631712822520441
Validation loss: 2.5589469229434307

Epoch: 6| Step: 8
Training loss: 3.3606037110698495
Validation loss: 2.5547714899466194

Epoch: 6| Step: 9
Training loss: 3.377400427648703
Validation loss: 2.561468001118151

Epoch: 6| Step: 10
Training loss: 2.733557355430774
Validation loss: 2.557321195960529

Epoch: 6| Step: 11
Training loss: 2.488408299530714
Validation loss: 2.556695847189209

Epoch: 6| Step: 12
Training loss: 3.3341182420400597
Validation loss: 2.5563968337371787

Epoch: 6| Step: 13
Training loss: 2.494894154354181
Validation loss: 2.555751974022705

Epoch: 77| Step: 0
Training loss: 3.2780263414982866
Validation loss: 2.559423274829852

Epoch: 6| Step: 1
Training loss: 3.5629207964885747
Validation loss: 2.5584387812384666

Epoch: 6| Step: 2
Training loss: 2.5835946986563214
Validation loss: 2.5535802419480738

Epoch: 6| Step: 3
Training loss: 2.968974054816139
Validation loss: 2.5534053526716076

Epoch: 6| Step: 4
Training loss: 2.0840943154649154
Validation loss: 2.5458519422988477

Epoch: 6| Step: 5
Training loss: 2.783627297720941
Validation loss: 2.5468560318825895

Epoch: 6| Step: 6
Training loss: 2.70791712766253
Validation loss: 2.547551795756313

Epoch: 6| Step: 7
Training loss: 2.735927380903126
Validation loss: 2.552015724985935

Epoch: 6| Step: 8
Training loss: 2.7370488635528285
Validation loss: 2.553861701016234

Epoch: 6| Step: 9
Training loss: 3.1368224244425043
Validation loss: 2.5461917083663144

Epoch: 6| Step: 10
Training loss: 2.8927235177209014
Validation loss: 2.5412369426512917

Epoch: 6| Step: 11
Training loss: 3.158798699496058
Validation loss: 2.544902158964953

Epoch: 6| Step: 12
Training loss: 2.5615932441998805
Validation loss: 2.5429992971344593

Epoch: 6| Step: 13
Training loss: 3.4231081617441643
Validation loss: 2.543205218857917

Epoch: 78| Step: 0
Training loss: 3.1865384016465983
Validation loss: 2.541137396785847

Epoch: 6| Step: 1
Training loss: 2.6805559091342657
Validation loss: 2.5437997631768496

Epoch: 6| Step: 2
Training loss: 3.074204945321213
Validation loss: 2.5439127017586105

Epoch: 6| Step: 3
Training loss: 2.524315270975532
Validation loss: 2.544504210343717

Epoch: 6| Step: 4
Training loss: 3.0810505088620634
Validation loss: 2.5455307665932656

Epoch: 6| Step: 5
Training loss: 2.6826666017472935
Validation loss: 2.557798803786684

Epoch: 6| Step: 6
Training loss: 3.2877048037014727
Validation loss: 2.5728495260559487

Epoch: 6| Step: 7
Training loss: 2.4437436076907484
Validation loss: 2.556476883675839

Epoch: 6| Step: 8
Training loss: 3.238862393901355
Validation loss: 2.5489261193305013

Epoch: 6| Step: 9
Training loss: 3.1358013402918825
Validation loss: 2.5415786672118434

Epoch: 6| Step: 10
Training loss: 2.87577958525361
Validation loss: 2.540074552989438

Epoch: 6| Step: 11
Training loss: 3.3933155266445088
Validation loss: 2.5359931885349076

Epoch: 6| Step: 12
Training loss: 2.4923704074239716
Validation loss: 2.537290933530357

Epoch: 6| Step: 13
Training loss: 1.5041914236016205
Validation loss: 2.536135469002857

Epoch: 79| Step: 0
Training loss: 2.6824643175181846
Validation loss: 2.5386085446472864

Epoch: 6| Step: 1
Training loss: 3.054625215407613
Validation loss: 2.5399230301487568

Epoch: 6| Step: 2
Training loss: 3.3838889719647955
Validation loss: 2.5381643080093754

Epoch: 6| Step: 3
Training loss: 2.614969617619719
Validation loss: 2.538693418978589

Epoch: 6| Step: 4
Training loss: 2.3624171166791674
Validation loss: 2.5458125254888713

Epoch: 6| Step: 5
Training loss: 3.113085502491892
Validation loss: 2.5480356245023343

Epoch: 6| Step: 6
Training loss: 2.671186748892884
Validation loss: 2.544541580019184

Epoch: 6| Step: 7
Training loss: 2.5978177816318255
Validation loss: 2.5494386629387376

Epoch: 6| Step: 8
Training loss: 2.3462400306323206
Validation loss: 2.562146030071997

Epoch: 6| Step: 9
Training loss: 3.1062652526112573
Validation loss: 2.5736663906442057

Epoch: 6| Step: 10
Training loss: 3.1603469696775384
Validation loss: 2.5829133697339395

Epoch: 6| Step: 11
Training loss: 3.596631296553708
Validation loss: 2.5904781324512864

Epoch: 6| Step: 12
Training loss: 2.944647837957436
Validation loss: 2.5692503442224184

Epoch: 6| Step: 13
Training loss: 2.239439020756213
Validation loss: 2.54732905420332

Epoch: 80| Step: 0
Training loss: 3.285544355511904
Validation loss: 2.5405566573683633

Epoch: 6| Step: 1
Training loss: 2.8672157722763103
Validation loss: 2.5343455390749816

Epoch: 6| Step: 2
Training loss: 2.729955272936963
Validation loss: 2.5345672378735253

Epoch: 6| Step: 3
Training loss: 3.2300464211071835
Validation loss: 2.536557522450823

Epoch: 6| Step: 4
Training loss: 2.6387461461952073
Validation loss: 2.5322644039179467

Epoch: 6| Step: 5
Training loss: 3.031195256633576
Validation loss: 2.532325952467823

Epoch: 6| Step: 6
Training loss: 2.7776634150381163
Validation loss: 2.5310772768899117

Epoch: 6| Step: 7
Training loss: 3.0000616703052567
Validation loss: 2.5324618042883706

Epoch: 6| Step: 8
Training loss: 2.9863439326245294
Validation loss: 2.529117753139952

Epoch: 6| Step: 9
Training loss: 2.9289159140194663
Validation loss: 2.529009059124058

Epoch: 6| Step: 10
Training loss: 2.9053458171131026
Validation loss: 2.5362182963147486

Epoch: 6| Step: 11
Training loss: 2.579489052323566
Validation loss: 2.546543614394309

Epoch: 6| Step: 12
Training loss: 2.618306845812875
Validation loss: 2.5565890476494135

Epoch: 6| Step: 13
Training loss: 2.850321627755863
Validation loss: 2.5722556874142755

Epoch: 81| Step: 0
Training loss: 2.7685862060044517
Validation loss: 2.5856407795086964

Epoch: 6| Step: 1
Training loss: 3.1371230913502903
Validation loss: 2.6294964243067755

Epoch: 6| Step: 2
Training loss: 2.8444658992209866
Validation loss: 2.6155793971487347

Epoch: 6| Step: 3
Training loss: 3.1461943025626278
Validation loss: 2.5717826229888514

Epoch: 6| Step: 4
Training loss: 3.1757771960017944
Validation loss: 2.5532240313376353

Epoch: 6| Step: 5
Training loss: 2.6596479336351817
Validation loss: 2.533630394263414

Epoch: 6| Step: 6
Training loss: 3.2459659482400287
Validation loss: 2.5282499521512314

Epoch: 6| Step: 7
Training loss: 2.709686078403484
Validation loss: 2.529182144447177

Epoch: 6| Step: 8
Training loss: 2.561860818928363
Validation loss: 2.5272687530713016

Epoch: 6| Step: 9
Training loss: 3.11318276511613
Validation loss: 2.5282625348222827

Epoch: 6| Step: 10
Training loss: 2.440613738557866
Validation loss: 2.5293037237398583

Epoch: 6| Step: 11
Training loss: 2.948262080971721
Validation loss: 2.528973441730224

Epoch: 6| Step: 12
Training loss: 2.828516474653753
Validation loss: 2.5283524439872487

Epoch: 6| Step: 13
Training loss: 2.7375807798128946
Validation loss: 2.525556838549852

Epoch: 82| Step: 0
Training loss: 3.179762480880365
Validation loss: 2.527370108050637

Epoch: 6| Step: 1
Training loss: 3.1633824500667993
Validation loss: 2.5287202940056597

Epoch: 6| Step: 2
Training loss: 3.1759788386026684
Validation loss: 2.524978568929254

Epoch: 6| Step: 3
Training loss: 2.639913338914973
Validation loss: 2.530569437008858

Epoch: 6| Step: 4
Training loss: 2.7920702362626253
Validation loss: 2.537816631882106

Epoch: 6| Step: 5
Training loss: 2.858084131912553
Validation loss: 2.5459554514426417

Epoch: 6| Step: 6
Training loss: 2.446362352320297
Validation loss: 2.57304792570465

Epoch: 6| Step: 7
Training loss: 2.021842534130342
Validation loss: 2.6023587953767846

Epoch: 6| Step: 8
Training loss: 2.6048829479607916
Validation loss: 2.6373583558630815

Epoch: 6| Step: 9
Training loss: 3.066874124586324
Validation loss: 2.6499936406544315

Epoch: 6| Step: 10
Training loss: 3.6212156865762712
Validation loss: 2.6264162725682665

Epoch: 6| Step: 11
Training loss: 2.909859005897726
Validation loss: 2.571465288685622

Epoch: 6| Step: 12
Training loss: 2.8314176328771383
Validation loss: 2.5527787745002333

Epoch: 6| Step: 13
Training loss: 3.3261971061139333
Validation loss: 2.5388630106945156

Epoch: 83| Step: 0
Training loss: 2.799407324053932
Validation loss: 2.5373847318960965

Epoch: 6| Step: 1
Training loss: 2.5994585940729666
Validation loss: 2.5426017343019884

Epoch: 6| Step: 2
Training loss: 3.3484609342281058
Validation loss: 2.545480198878059

Epoch: 6| Step: 3
Training loss: 2.633969559246668
Validation loss: 2.5418296165284406

Epoch: 6| Step: 4
Training loss: 3.0689131870116597
Validation loss: 2.5316553068606553

Epoch: 6| Step: 5
Training loss: 2.9712462521257783
Validation loss: 2.5315203464714418

Epoch: 6| Step: 6
Training loss: 2.5549941505917593
Validation loss: 2.5233870310466746

Epoch: 6| Step: 7
Training loss: 3.2661039010390978
Validation loss: 2.525391806629872

Epoch: 6| Step: 8
Training loss: 3.2475641365560315
Validation loss: 2.5214720416621086

Epoch: 6| Step: 9
Training loss: 2.9564695442085176
Validation loss: 2.5248120746352125

Epoch: 6| Step: 10
Training loss: 2.6525121082025955
Validation loss: 2.524816261038503

Epoch: 6| Step: 11
Training loss: 3.0908383626546403
Validation loss: 2.5286707973142444

Epoch: 6| Step: 12
Training loss: 2.8281455697844837
Validation loss: 2.533782134560245

Epoch: 6| Step: 13
Training loss: 2.025829771544279
Validation loss: 2.548838703097578

Epoch: 84| Step: 0
Training loss: 3.2288121838992874
Validation loss: 2.5701826795701552

Epoch: 6| Step: 1
Training loss: 2.7498712509534093
Validation loss: 2.5729882021647623

Epoch: 6| Step: 2
Training loss: 2.7351890006306956
Validation loss: 2.5490758051113533

Epoch: 6| Step: 3
Training loss: 2.6673529655740245
Validation loss: 2.5364584296883175

Epoch: 6| Step: 4
Training loss: 2.5759756665709452
Validation loss: 2.5271191867222993

Epoch: 6| Step: 5
Training loss: 2.602367562946907
Validation loss: 2.524404451421722

Epoch: 6| Step: 6
Training loss: 2.8726408857651067
Validation loss: 2.5165199757028294

Epoch: 6| Step: 7
Training loss: 2.386026684806079
Validation loss: 2.512933779281992

Epoch: 6| Step: 8
Training loss: 2.719804581185727
Validation loss: 2.513694407081166

Epoch: 6| Step: 9
Training loss: 2.5378664926535617
Validation loss: 2.513629896438396

Epoch: 6| Step: 10
Training loss: 3.2512976183368587
Validation loss: 2.5152258480207337

Epoch: 6| Step: 11
Training loss: 3.842156304678413
Validation loss: 2.516598655152763

Epoch: 6| Step: 12
Training loss: 3.27673697964372
Validation loss: 2.518906405426519

Epoch: 6| Step: 13
Training loss: 2.4628601314341942
Validation loss: 2.5196875240507453

Epoch: 85| Step: 0
Training loss: 2.116604094694319
Validation loss: 2.519585987210958

Epoch: 6| Step: 1
Training loss: 2.9294192585532737
Validation loss: 2.5222676911043593

Epoch: 6| Step: 2
Training loss: 2.8403753021915614
Validation loss: 2.5371979107324556

Epoch: 6| Step: 3
Training loss: 3.354670010979971
Validation loss: 2.553026813414393

Epoch: 6| Step: 4
Training loss: 2.473770444996579
Validation loss: 2.550695142633857

Epoch: 6| Step: 5
Training loss: 2.271298900323468
Validation loss: 2.5752704646773865

Epoch: 6| Step: 6
Training loss: 2.8093478870886917
Validation loss: 2.570908789312572

Epoch: 6| Step: 7
Training loss: 3.1704474182148235
Validation loss: 2.5823329301076057

Epoch: 6| Step: 8
Training loss: 2.6670553003677533
Validation loss: 2.5535878066226663

Epoch: 6| Step: 9
Training loss: 3.3596320475331836
Validation loss: 2.542193446615754

Epoch: 6| Step: 10
Training loss: 2.9040144659265295
Validation loss: 2.53043396381277

Epoch: 6| Step: 11
Training loss: 3.0957855309911317
Validation loss: 2.5130901116503663

Epoch: 6| Step: 12
Training loss: 2.907768591088584
Validation loss: 2.5068165600649723

Epoch: 6| Step: 13
Training loss: 3.27432100668361
Validation loss: 2.512566661690139

Epoch: 86| Step: 0
Training loss: 2.8624178012556643
Validation loss: 2.5124206210446243

Epoch: 6| Step: 1
Training loss: 2.2764222781970562
Validation loss: 2.5116375726142333

Epoch: 6| Step: 2
Training loss: 2.7895503966419524
Validation loss: 2.51150417621792

Epoch: 6| Step: 3
Training loss: 2.5701113914959532
Validation loss: 2.5093785800171964

Epoch: 6| Step: 4
Training loss: 3.2176596266860744
Validation loss: 2.510907660038606

Epoch: 6| Step: 5
Training loss: 2.8619284979674156
Validation loss: 2.5111810954032356

Epoch: 6| Step: 6
Training loss: 3.345225356284113
Validation loss: 2.5142088287084614

Epoch: 6| Step: 7
Training loss: 2.7121436873887195
Validation loss: 2.520419857157316

Epoch: 6| Step: 8
Training loss: 2.944826769048908
Validation loss: 2.521891820618476

Epoch: 6| Step: 9
Training loss: 2.666733641578122
Validation loss: 2.525133875389732

Epoch: 6| Step: 10
Training loss: 2.8935859979743714
Validation loss: 2.5211324203318144

Epoch: 6| Step: 11
Training loss: 2.9317905862919535
Validation loss: 2.5280536841877823

Epoch: 6| Step: 12
Training loss: 3.4813561469559877
Validation loss: 2.5265213888363833

Epoch: 6| Step: 13
Training loss: 2.2166466212501614
Validation loss: 2.521875661415385

Epoch: 87| Step: 0
Training loss: 2.954202606742979
Validation loss: 2.513296264333076

Epoch: 6| Step: 1
Training loss: 2.8518072989957557
Validation loss: 2.520272408051785

Epoch: 6| Step: 2
Training loss: 2.514791978609505
Validation loss: 2.5196892048674644

Epoch: 6| Step: 3
Training loss: 2.730217699725926
Validation loss: 2.5231636391737915

Epoch: 6| Step: 4
Training loss: 2.4291614809411666
Validation loss: 2.5255200792132415

Epoch: 6| Step: 5
Training loss: 2.8849732279733633
Validation loss: 2.530217768330606

Epoch: 6| Step: 6
Training loss: 3.4300046178936805
Validation loss: 2.5286883942888014

Epoch: 6| Step: 7
Training loss: 2.6795501228907783
Validation loss: 2.5248679807725685

Epoch: 6| Step: 8
Training loss: 3.3887205620601843
Validation loss: 2.5213448000432988

Epoch: 6| Step: 9
Training loss: 2.681898000525633
Validation loss: 2.5213689849400653

Epoch: 6| Step: 10
Training loss: 2.858833636956503
Validation loss: 2.5159405715661576

Epoch: 6| Step: 11
Training loss: 2.89866715418517
Validation loss: 2.5187465770196087

Epoch: 6| Step: 12
Training loss: 3.0084337261775014
Validation loss: 2.5151223258977544

Epoch: 6| Step: 13
Training loss: 2.591731561500427
Validation loss: 2.5111516456056115

Epoch: 88| Step: 0
Training loss: 2.895880792535355
Validation loss: 2.512761802953058

Epoch: 6| Step: 1
Training loss: 3.1307737799239934
Validation loss: 2.508353945832381

Epoch: 6| Step: 2
Training loss: 2.3553159041023934
Validation loss: 2.5076403963396103

Epoch: 6| Step: 3
Training loss: 2.6261543279013666
Validation loss: 2.5064524106922277

Epoch: 6| Step: 4
Training loss: 2.7378005886090904
Validation loss: 2.5062925352985226

Epoch: 6| Step: 5
Training loss: 2.481521599267642
Validation loss: 2.5094477491182907

Epoch: 6| Step: 6
Training loss: 2.5490522381116616
Validation loss: 2.524179179771111

Epoch: 6| Step: 7
Training loss: 2.9118090550835576
Validation loss: 2.5336524088741923

Epoch: 6| Step: 8
Training loss: 3.0502829248499
Validation loss: 2.5616325723066873

Epoch: 6| Step: 9
Training loss: 2.635147281996766
Validation loss: 2.5591038474502175

Epoch: 6| Step: 10
Training loss: 3.065391421193142
Validation loss: 2.5487608609713974

Epoch: 6| Step: 11
Training loss: 3.040620301606644
Validation loss: 2.5152199863147215

Epoch: 6| Step: 12
Training loss: 3.1464761915047212
Validation loss: 2.5085593410958076

Epoch: 6| Step: 13
Training loss: 3.7122633322343344
Validation loss: 2.5072214854113377

Epoch: 89| Step: 0
Training loss: 2.972433916517157
Validation loss: 2.510733203099123

Epoch: 6| Step: 1
Training loss: 2.949799456487863
Validation loss: 2.5170929801999913

Epoch: 6| Step: 2
Training loss: 1.9365119876032535
Validation loss: 2.521572466047245

Epoch: 6| Step: 3
Training loss: 3.469361122528288
Validation loss: 2.540327875119116

Epoch: 6| Step: 4
Training loss: 2.7824472143713597
Validation loss: 2.6060350418907388

Epoch: 6| Step: 5
Training loss: 2.812004893487224
Validation loss: 2.738620750059141

Epoch: 6| Step: 6
Training loss: 3.1474067003936916
Validation loss: 2.7310947075861476

Epoch: 6| Step: 7
Training loss: 3.497664353474391
Validation loss: 2.689439594960613

Epoch: 6| Step: 8
Training loss: 2.5773108844216868
Validation loss: 2.610466456494334

Epoch: 6| Step: 9
Training loss: 2.6557079884164163
Validation loss: 2.5665042858659874

Epoch: 6| Step: 10
Training loss: 2.9464128700267347
Validation loss: 2.542381945147729

Epoch: 6| Step: 11
Training loss: 2.3958793193439663
Validation loss: 2.5225594561090583

Epoch: 6| Step: 12
Training loss: 3.2688357981987926
Validation loss: 2.5173295425134827

Epoch: 6| Step: 13
Training loss: 3.5636252249152607
Validation loss: 2.518271762168541

Epoch: 90| Step: 0
Training loss: 2.8535537247199816
Validation loss: 2.516030651545614

Epoch: 6| Step: 1
Training loss: 2.9106672619189804
Validation loss: 2.530168616047985

Epoch: 6| Step: 2
Training loss: 2.500734984122754
Validation loss: 2.5386203266630485

Epoch: 6| Step: 3
Training loss: 3.138039506827652
Validation loss: 2.5702975528563075

Epoch: 6| Step: 4
Training loss: 2.929318987239851
Validation loss: 2.6007141397381397

Epoch: 6| Step: 5
Training loss: 3.0912576519678217
Validation loss: 2.630382641637469

Epoch: 6| Step: 6
Training loss: 2.98288581801998
Validation loss: 2.6128066862102997

Epoch: 6| Step: 7
Training loss: 2.697863181822468
Validation loss: 2.614892943632794

Epoch: 6| Step: 8
Training loss: 2.6760397236303333
Validation loss: 2.6147220386684586

Epoch: 6| Step: 9
Training loss: 2.9579109284335923
Validation loss: 2.6071979592015393

Epoch: 6| Step: 10
Training loss: 3.2452063787867127
Validation loss: 2.553672903903101

Epoch: 6| Step: 11
Training loss: 3.2985210919505987
Validation loss: 2.53025002162249

Epoch: 6| Step: 12
Training loss: 2.3433412322575515
Validation loss: 2.519443228003547

Epoch: 6| Step: 13
Training loss: 2.642156032959152
Validation loss: 2.5183568933252922

Epoch: 91| Step: 0
Training loss: 2.2634001232212237
Validation loss: 2.515071836867912

Epoch: 6| Step: 1
Training loss: 2.8731932560644675
Validation loss: 2.5152353494390196

Epoch: 6| Step: 2
Training loss: 2.3897312463303275
Validation loss: 2.516343257465677

Epoch: 6| Step: 3
Training loss: 1.994834667037827
Validation loss: 2.5185914304230175

Epoch: 6| Step: 4
Training loss: 3.3092472732577667
Validation loss: 2.5183889274712303

Epoch: 6| Step: 5
Training loss: 2.5902478577423
Validation loss: 2.515422908466861

Epoch: 6| Step: 6
Training loss: 3.3012333848066415
Validation loss: 2.5157856620816537

Epoch: 6| Step: 7
Training loss: 2.583336020027322
Validation loss: 2.5099204397639303

Epoch: 6| Step: 8
Training loss: 3.1208842831481705
Validation loss: 2.513755982996845

Epoch: 6| Step: 9
Training loss: 3.05416046044802
Validation loss: 2.5173835358111813

Epoch: 6| Step: 10
Training loss: 3.18263546615647
Validation loss: 2.525437665420532

Epoch: 6| Step: 11
Training loss: 3.2530542840518035
Validation loss: 2.533010021048897

Epoch: 6| Step: 12
Training loss: 3.034868106395692
Validation loss: 2.5427384536642985

Epoch: 6| Step: 13
Training loss: 2.3981619313140032
Validation loss: 2.5665491298818934

Epoch: 92| Step: 0
Training loss: 2.8222801551312817
Validation loss: 2.566965797305148

Epoch: 6| Step: 1
Training loss: 3.261116675813149
Validation loss: 2.5455906086262226

Epoch: 6| Step: 2
Training loss: 2.161487796689877
Validation loss: 2.520323718540199

Epoch: 6| Step: 3
Training loss: 2.69890260294112
Validation loss: 2.5078380257444035

Epoch: 6| Step: 4
Training loss: 2.7163426055781157
Validation loss: 2.503849810299388

Epoch: 6| Step: 5
Training loss: 3.117814156397165
Validation loss: 2.5132347475378625

Epoch: 6| Step: 6
Training loss: 3.1354395632156007
Validation loss: 2.5171679442148363

Epoch: 6| Step: 7
Training loss: 3.010550384895612
Validation loss: 2.517299168642303

Epoch: 6| Step: 8
Training loss: 3.1008324520605677
Validation loss: 2.517187628977059

Epoch: 6| Step: 9
Training loss: 3.2977273571424757
Validation loss: 2.5182283383269346

Epoch: 6| Step: 10
Training loss: 2.7990851167832167
Validation loss: 2.51055984453002

Epoch: 6| Step: 11
Training loss: 2.71539740097035
Validation loss: 2.5131974897097282

Epoch: 6| Step: 12
Training loss: 2.543890017093385
Validation loss: 2.5092389119972465

Epoch: 6| Step: 13
Training loss: 2.820509800653686
Validation loss: 2.495059207088238

Epoch: 93| Step: 0
Training loss: 3.040015691415545
Validation loss: 2.5015741786089913

Epoch: 6| Step: 1
Training loss: 2.7957312946677946
Validation loss: 2.500640333883464

Epoch: 6| Step: 2
Training loss: 2.6810294925386517
Validation loss: 2.500052065973678

Epoch: 6| Step: 3
Training loss: 2.8385639901406217
Validation loss: 2.5013212055798513

Epoch: 6| Step: 4
Training loss: 2.916367015886392
Validation loss: 2.4966952015108803

Epoch: 6| Step: 5
Training loss: 2.9921954680254546
Validation loss: 2.5022871886284017

Epoch: 6| Step: 6
Training loss: 2.3857884568464014
Validation loss: 2.505926792622615

Epoch: 6| Step: 7
Training loss: 3.0642828909257247
Validation loss: 2.5123600603629295

Epoch: 6| Step: 8
Training loss: 2.705890629894739
Validation loss: 2.51700605239045

Epoch: 6| Step: 9
Training loss: 2.3945133277010773
Validation loss: 2.51528424417694

Epoch: 6| Step: 10
Training loss: 2.838015801018136
Validation loss: 2.506848971266778

Epoch: 6| Step: 11
Training loss: 3.3538938296852483
Validation loss: 2.501285243117666

Epoch: 6| Step: 12
Training loss: 3.019996123658781
Validation loss: 2.5001367408518855

Epoch: 6| Step: 13
Training loss: 2.685734457227212
Validation loss: 2.496552463149897

Epoch: 94| Step: 0
Training loss: 2.573837414109765
Validation loss: 2.497756301877599

Epoch: 6| Step: 1
Training loss: 2.7297430424752243
Validation loss: 2.496354555443996

Epoch: 6| Step: 2
Training loss: 2.8530660767335916
Validation loss: 2.4980734682824766

Epoch: 6| Step: 3
Training loss: 2.0738635432527173
Validation loss: 2.4967791493006204

Epoch: 6| Step: 4
Training loss: 3.0625551179869412
Validation loss: 2.504149723519479

Epoch: 6| Step: 5
Training loss: 2.562377926779818
Validation loss: 2.510154011538747

Epoch: 6| Step: 6
Training loss: 2.6171131635898277
Validation loss: 2.515973594796129

Epoch: 6| Step: 7
Training loss: 3.6486119753433157
Validation loss: 2.516018524298929

Epoch: 6| Step: 8
Training loss: 2.5145284027783235
Validation loss: 2.508807607215056

Epoch: 6| Step: 9
Training loss: 3.010984655386125
Validation loss: 2.5133164853504844

Epoch: 6| Step: 10
Training loss: 2.683304461527233
Validation loss: 2.5061233643995293

Epoch: 6| Step: 11
Training loss: 3.3066883568154894
Validation loss: 2.503083950032479

Epoch: 6| Step: 12
Training loss: 2.948718461809571
Validation loss: 2.499277917090747

Epoch: 6| Step: 13
Training loss: 2.8547663000763754
Validation loss: 2.4925507640660647

Epoch: 95| Step: 0
Training loss: 2.4311842647187634
Validation loss: 2.493572796343665

Epoch: 6| Step: 1
Training loss: 3.191173306838691
Validation loss: 2.49385861523583

Epoch: 6| Step: 2
Training loss: 2.869725073695421
Validation loss: 2.4945423296971803

Epoch: 6| Step: 3
Training loss: 2.7583319415255105
Validation loss: 2.4864765807272864

Epoch: 6| Step: 4
Training loss: 3.2586557591386334
Validation loss: 2.4888013796854747

Epoch: 6| Step: 5
Training loss: 2.855870167791807
Validation loss: 2.49073589321667

Epoch: 6| Step: 6
Training loss: 2.9635500692685324
Validation loss: 2.494064181485165

Epoch: 6| Step: 7
Training loss: 3.5367674807154743
Validation loss: 2.4878263063570127

Epoch: 6| Step: 8
Training loss: 2.3465640658288156
Validation loss: 2.4991092304982536

Epoch: 6| Step: 9
Training loss: 2.095124889283877
Validation loss: 2.5034856809888524

Epoch: 6| Step: 10
Training loss: 2.802615449621919
Validation loss: 2.5028303490892188

Epoch: 6| Step: 11
Training loss: 2.74996376013719
Validation loss: 2.5042837921619854

Epoch: 6| Step: 12
Training loss: 2.7864184415344444
Validation loss: 2.4967973160370582

Epoch: 6| Step: 13
Training loss: 2.6784643823941185
Validation loss: 2.5024294667012903

Epoch: 96| Step: 0
Training loss: 3.0075673981912834
Validation loss: 2.503161338894798

Epoch: 6| Step: 1
Training loss: 3.102071494512638
Validation loss: 2.498982959933342

Epoch: 6| Step: 2
Training loss: 2.3463616633886435
Validation loss: 2.4950628937084907

Epoch: 6| Step: 3
Training loss: 2.7436409166067204
Validation loss: 2.49486045546467

Epoch: 6| Step: 4
Training loss: 3.366162066524051
Validation loss: 2.4989351378651503

Epoch: 6| Step: 5
Training loss: 2.075987670420819
Validation loss: 2.493427568965361

Epoch: 6| Step: 6
Training loss: 2.3245710859188606
Validation loss: 2.500351819539981

Epoch: 6| Step: 7
Training loss: 2.111166186478732
Validation loss: 2.4976958115926666

Epoch: 6| Step: 8
Training loss: 3.3051395332556766
Validation loss: 2.4980665729187406

Epoch: 6| Step: 9
Training loss: 2.803708811579436
Validation loss: 2.501847120068534

Epoch: 6| Step: 10
Training loss: 3.051050074183605
Validation loss: 2.495572453872213

Epoch: 6| Step: 11
Training loss: 3.022691107199182
Validation loss: 2.4941431514916608

Epoch: 6| Step: 12
Training loss: 3.291866602237811
Validation loss: 2.4931312996121258

Epoch: 6| Step: 13
Training loss: 2.3922803545570916
Validation loss: 2.489818087388356

Epoch: 97| Step: 0
Training loss: 2.015436089704496
Validation loss: 2.4869514819855305

Epoch: 6| Step: 1
Training loss: 2.7487093757933856
Validation loss: 2.489837421047133

Epoch: 6| Step: 2
Training loss: 3.3846231948989174
Validation loss: 2.48264750320367

Epoch: 6| Step: 3
Training loss: 2.9326230410156366
Validation loss: 2.482907545535819

Epoch: 6| Step: 4
Training loss: 2.218443191162066
Validation loss: 2.4829421572806467

Epoch: 6| Step: 5
Training loss: 2.374568799678274
Validation loss: 2.4805163932412526

Epoch: 6| Step: 6
Training loss: 2.807938161000598
Validation loss: 2.482175110367524

Epoch: 6| Step: 7
Training loss: 2.805528604946638
Validation loss: 2.4820651848777775

Epoch: 6| Step: 8
Training loss: 2.555522443953066
Validation loss: 2.4800835169875173

Epoch: 6| Step: 9
Training loss: 3.1078070132752282
Validation loss: 2.4876504038729124

Epoch: 6| Step: 10
Training loss: 2.6908959512600656
Validation loss: 2.4945762651412133

Epoch: 6| Step: 11
Training loss: 3.2345020803650355
Validation loss: 2.4864114402089283

Epoch: 6| Step: 12
Training loss: 3.3932803958393416
Validation loss: 2.4934852788765873

Epoch: 6| Step: 13
Training loss: 2.9234071682080778
Validation loss: 2.496980880654054

Epoch: 98| Step: 0
Training loss: 3.1171175917814926
Validation loss: 2.4973764538244274

Epoch: 6| Step: 1
Training loss: 2.7416563905409346
Validation loss: 2.504573463659344

Epoch: 6| Step: 2
Training loss: 2.8550477350256163
Validation loss: 2.5093973900823046

Epoch: 6| Step: 3
Training loss: 3.2473322850147808
Validation loss: 2.502479817413538

Epoch: 6| Step: 4
Training loss: 2.7154535061644167
Validation loss: 2.5043318207339467

Epoch: 6| Step: 5
Training loss: 2.4577583243964685
Validation loss: 2.49700115576714

Epoch: 6| Step: 6
Training loss: 2.7037160591044462
Validation loss: 2.491022755962092

Epoch: 6| Step: 7
Training loss: 2.9978086097299954
Validation loss: 2.487267109281111

Epoch: 6| Step: 8
Training loss: 2.067685976716321
Validation loss: 2.479639030232145

Epoch: 6| Step: 9
Training loss: 3.2399610849092113
Validation loss: 2.482528616456465

Epoch: 6| Step: 10
Training loss: 2.765630086258344
Validation loss: 2.4845890647672655

Epoch: 6| Step: 11
Training loss: 3.4207216871088386
Validation loss: 2.482557022034171

Epoch: 6| Step: 12
Training loss: 2.1370687529339913
Validation loss: 2.479597145471772

Epoch: 6| Step: 13
Training loss: 2.538256802005271
Validation loss: 2.483831718626411

Epoch: 99| Step: 0
Training loss: 2.6387776791969935
Validation loss: 2.4785469499451556

Epoch: 6| Step: 1
Training loss: 3.0824761788715493
Validation loss: 2.476728323082033

Epoch: 6| Step: 2
Training loss: 3.0424338814565335
Validation loss: 2.477289742809192

Epoch: 6| Step: 3
Training loss: 2.721550124321269
Validation loss: 2.4769790985849607

Epoch: 6| Step: 4
Training loss: 2.347605877683389
Validation loss: 2.4770088030450927

Epoch: 6| Step: 5
Training loss: 3.2370688604243356
Validation loss: 2.4833813258464947

Epoch: 6| Step: 6
Training loss: 3.1161123921859533
Validation loss: 2.499751386278538

Epoch: 6| Step: 7
Training loss: 2.9717345644785147
Validation loss: 2.508228996161023

Epoch: 6| Step: 8
Training loss: 2.594125375816308
Validation loss: 2.521521002029713

Epoch: 6| Step: 9
Training loss: 2.660335137042293
Validation loss: 2.534253641298541

Epoch: 6| Step: 10
Training loss: 2.634165249367268
Validation loss: 2.505460053696353

Epoch: 6| Step: 11
Training loss: 2.6102965777621807
Validation loss: 2.5041585411224005

Epoch: 6| Step: 12
Training loss: 2.7982371332545353
Validation loss: 2.4790607047830204

Epoch: 6| Step: 13
Training loss: 3.0902031497778544
Validation loss: 2.4709034908654384

Epoch: 100| Step: 0
Training loss: 2.8643112515791387
Validation loss: 2.4738593459389904

Epoch: 6| Step: 1
Training loss: 3.006064801449752
Validation loss: 2.4755640910350234

Epoch: 6| Step: 2
Training loss: 2.454483627895724
Validation loss: 2.4774443890822924

Epoch: 6| Step: 3
Training loss: 2.4211763420185632
Validation loss: 2.479494859193771

Epoch: 6| Step: 4
Training loss: 2.7003080651470115
Validation loss: 2.4770417445079156

Epoch: 6| Step: 5
Training loss: 3.0158561657472305
Validation loss: 2.478702138341535

Epoch: 6| Step: 6
Training loss: 2.47025205090641
Validation loss: 2.4717588919372204

Epoch: 6| Step: 7
Training loss: 2.991973630268762
Validation loss: 2.472040612933277

Epoch: 6| Step: 8
Training loss: 2.487232508246735
Validation loss: 2.471929821927263

Epoch: 6| Step: 9
Training loss: 2.907727429981681
Validation loss: 2.4688752873256257

Epoch: 6| Step: 10
Training loss: 3.3188815275806713
Validation loss: 2.4775778612895127

Epoch: 6| Step: 11
Training loss: 2.370658319200395
Validation loss: 2.4816098496005394

Epoch: 6| Step: 12
Training loss: 3.3904296537458953
Validation loss: 2.4944770061876476

Epoch: 6| Step: 13
Training loss: 2.7503726880085027
Validation loss: 2.4998806965981824

Epoch: 101| Step: 0
Training loss: 2.90468300854447
Validation loss: 2.50779300232706

Epoch: 6| Step: 1
Training loss: 2.9973482492195678
Validation loss: 2.5180471656344507

Epoch: 6| Step: 2
Training loss: 3.084840835595417
Validation loss: 2.521535715727914

Epoch: 6| Step: 3
Training loss: 2.489378107994643
Validation loss: 2.5507641773054233

Epoch: 6| Step: 4
Training loss: 2.310034803978776
Validation loss: 2.5516495192588393

Epoch: 6| Step: 5
Training loss: 3.1648117120308155
Validation loss: 2.542016539018699

Epoch: 6| Step: 6
Training loss: 2.416547366738276
Validation loss: 2.5325643574824532

Epoch: 6| Step: 7
Training loss: 2.70098554143669
Validation loss: 2.5166972952694824

Epoch: 6| Step: 8
Training loss: 2.475507445285475
Validation loss: 2.502572074738068

Epoch: 6| Step: 9
Training loss: 3.1199405148533113
Validation loss: 2.4900557881966026

Epoch: 6| Step: 10
Training loss: 3.114054010803626
Validation loss: 2.489163344824462

Epoch: 6| Step: 11
Training loss: 2.8526079325604385
Validation loss: 2.4812335006484765

Epoch: 6| Step: 12
Training loss: 3.0721209686621633
Validation loss: 2.4802767745764354

Epoch: 6| Step: 13
Training loss: 2.869955530121163
Validation loss: 2.4824935776093606

Epoch: 102| Step: 0
Training loss: 3.1425204654048446
Validation loss: 2.486267757260485

Epoch: 6| Step: 1
Training loss: 2.5593776754102127
Validation loss: 2.4897741930314945

Epoch: 6| Step: 2
Training loss: 2.4757242318374098
Validation loss: 2.483019273594066

Epoch: 6| Step: 3
Training loss: 2.727065687557179
Validation loss: 2.481368819855323

Epoch: 6| Step: 4
Training loss: 3.1457144270565625
Validation loss: 2.4762940413172596

Epoch: 6| Step: 5
Training loss: 2.8609644740118
Validation loss: 2.4757783760647945

Epoch: 6| Step: 6
Training loss: 2.9107573637252826
Validation loss: 2.4694730064188226

Epoch: 6| Step: 7
Training loss: 2.688859551333631
Validation loss: 2.469493894598177

Epoch: 6| Step: 8
Training loss: 2.188658707140136
Validation loss: 2.481824544364506

Epoch: 6| Step: 9
Training loss: 3.438165773594803
Validation loss: 2.4924829712724597

Epoch: 6| Step: 10
Training loss: 2.739730908343788
Validation loss: 2.5155654581205913

Epoch: 6| Step: 11
Training loss: 2.5879754739922856
Validation loss: 2.548717637229601

Epoch: 6| Step: 12
Training loss: 3.3476451397314175
Validation loss: 2.5426588836698487

Epoch: 6| Step: 13
Training loss: 2.6151011791312215
Validation loss: 2.521295820493755

Epoch: 103| Step: 0
Training loss: 2.5148311333815334
Validation loss: 2.5026974563921636

Epoch: 6| Step: 1
Training loss: 3.248302016155391
Validation loss: 2.4872763495414434

Epoch: 6| Step: 2
Training loss: 3.4395095499967785
Validation loss: 2.478352842688256

Epoch: 6| Step: 3
Training loss: 2.6350404272289834
Validation loss: 2.4664785024295557

Epoch: 6| Step: 4
Training loss: 2.4951807301412288
Validation loss: 2.469843886765487

Epoch: 6| Step: 5
Training loss: 2.232780688027841
Validation loss: 2.4657788126631277

Epoch: 6| Step: 6
Training loss: 2.4978085449676146
Validation loss: 2.469799109078732

Epoch: 6| Step: 7
Training loss: 3.303877638834795
Validation loss: 2.468062472660134

Epoch: 6| Step: 8
Training loss: 2.4973468053073855
Validation loss: 2.469716357644313

Epoch: 6| Step: 9
Training loss: 2.8642881114149237
Validation loss: 2.465666469736426

Epoch: 6| Step: 10
Training loss: 3.3709647462280734
Validation loss: 2.4673471521412513

Epoch: 6| Step: 11
Training loss: 2.576388057172789
Validation loss: 2.470265803863772

Epoch: 6| Step: 12
Training loss: 2.4428421558631075
Validation loss: 2.47230225413882

Epoch: 6| Step: 13
Training loss: 2.89336681753844
Validation loss: 2.4737915259160763

Epoch: 104| Step: 0
Training loss: 2.690203881177456
Validation loss: 2.489661773408393

Epoch: 6| Step: 1
Training loss: 2.032864090706853
Validation loss: 2.5142219965758605

Epoch: 6| Step: 2
Training loss: 3.233238130983474
Validation loss: 2.535869283291074

Epoch: 6| Step: 3
Training loss: 2.9293281029556293
Validation loss: 2.539335060604002

Epoch: 6| Step: 4
Training loss: 2.8799882819679077
Validation loss: 2.5477368122022073

Epoch: 6| Step: 5
Training loss: 2.9783196656849746
Validation loss: 2.5375282012440836

Epoch: 6| Step: 6
Training loss: 2.405714000107095
Validation loss: 2.5359458071146306

Epoch: 6| Step: 7
Training loss: 2.754447721452274
Validation loss: 2.5106904984206606

Epoch: 6| Step: 8
Training loss: 3.1969562956465976
Validation loss: 2.515572434945383

Epoch: 6| Step: 9
Training loss: 2.269885457379738
Validation loss: 2.52415521781901

Epoch: 6| Step: 10
Training loss: 2.8997444434853934
Validation loss: 2.5231390117156924

Epoch: 6| Step: 11
Training loss: 2.8499555684691886
Validation loss: 2.50824111303168

Epoch: 6| Step: 12
Training loss: 3.3294758092571737
Validation loss: 2.497800030304229

Epoch: 6| Step: 13
Training loss: 2.560746965657725
Validation loss: 2.486357431642036

Epoch: 105| Step: 0
Training loss: 2.5943437379310383
Validation loss: 2.484621287163878

Epoch: 6| Step: 1
Training loss: 2.2903047387200712
Validation loss: 2.4812760727572782

Epoch: 6| Step: 2
Training loss: 2.8701813162706364
Validation loss: 2.4816071058036875

Epoch: 6| Step: 3
Training loss: 2.610141298992836
Validation loss: 2.4851314357663994

Epoch: 6| Step: 4
Training loss: 3.2048531685222508
Validation loss: 2.48510268823789

Epoch: 6| Step: 5
Training loss: 2.9732121713467956
Validation loss: 2.4949182812258415

Epoch: 6| Step: 6
Training loss: 2.942980746373131
Validation loss: 2.5072920565291708

Epoch: 6| Step: 7
Training loss: 3.0425158495400066
Validation loss: 2.5141493674950057

Epoch: 6| Step: 8
Training loss: 2.938307306264919
Validation loss: 2.499744127366766

Epoch: 6| Step: 9
Training loss: 2.804937239980077
Validation loss: 2.487981051965543

Epoch: 6| Step: 10
Training loss: 3.1056490096071743
Validation loss: 2.4900125322447844

Epoch: 6| Step: 11
Training loss: 2.5760667387568392
Validation loss: 2.4762926338630655

Epoch: 6| Step: 12
Training loss: 2.7559938134399427
Validation loss: 2.4751227938280254

Epoch: 6| Step: 13
Training loss: 2.1624901082248136
Validation loss: 2.473975785112381

Epoch: 106| Step: 0
Training loss: 2.499969959078542
Validation loss: 2.4806783189546713

Epoch: 6| Step: 1
Training loss: 2.9060883836005984
Validation loss: 2.4758639577301254

Epoch: 6| Step: 2
Training loss: 2.7092093200361074
Validation loss: 2.475135775011791

Epoch: 6| Step: 3
Training loss: 2.0080714671042688
Validation loss: 2.476377962239415

Epoch: 6| Step: 4
Training loss: 3.2033954785286674
Validation loss: 2.4816105639582955

Epoch: 6| Step: 5
Training loss: 2.758683539879024
Validation loss: 2.4850968307863037

Epoch: 6| Step: 6
Training loss: 3.0633839479844105
Validation loss: 2.498563522986532

Epoch: 6| Step: 7
Training loss: 2.6011568503540965
Validation loss: 2.519507842143168

Epoch: 6| Step: 8
Training loss: 2.990220182598178
Validation loss: 2.526337054207003

Epoch: 6| Step: 9
Training loss: 3.3054876418487846
Validation loss: 2.536230660540597

Epoch: 6| Step: 10
Training loss: 2.784093453400817
Validation loss: 2.538308849827334

Epoch: 6| Step: 11
Training loss: 2.7767942075376064
Validation loss: 2.536216122056571

Epoch: 6| Step: 12
Training loss: 2.6647966106163055
Validation loss: 2.4895870067809436

Epoch: 6| Step: 13
Training loss: 2.8723455697322438
Validation loss: 2.4770850468813532

Epoch: 107| Step: 0
Training loss: 2.706220409064144
Validation loss: 2.46664605625403

Epoch: 6| Step: 1
Training loss: 3.220577721036828
Validation loss: 2.472827005477067

Epoch: 6| Step: 2
Training loss: 2.7413481816262
Validation loss: 2.4765833532282846

Epoch: 6| Step: 3
Training loss: 2.5908285946790914
Validation loss: 2.473390598059859

Epoch: 6| Step: 4
Training loss: 3.23746096318692
Validation loss: 2.464169197535514

Epoch: 6| Step: 5
Training loss: 2.5760299030369063
Validation loss: 2.4673346931354536

Epoch: 6| Step: 6
Training loss: 2.629453423565753
Validation loss: 2.4811234735120107

Epoch: 6| Step: 7
Training loss: 2.6312703220189753
Validation loss: 2.4851350803767382

Epoch: 6| Step: 8
Training loss: 3.1233946682319926
Validation loss: 2.4905896975394795

Epoch: 6| Step: 9
Training loss: 2.264423762235237
Validation loss: 2.4921019933546944

Epoch: 6| Step: 10
Training loss: 3.017754153947434
Validation loss: 2.5036298068006277

Epoch: 6| Step: 11
Training loss: 2.735086315822369
Validation loss: 2.508700724909784

Epoch: 6| Step: 12
Training loss: 2.91204322212756
Validation loss: 2.535522911725482

Epoch: 6| Step: 13
Training loss: 2.3604174199542207
Validation loss: 2.5642012964428567

Epoch: 108| Step: 0
Training loss: 2.3676690848695006
Validation loss: 2.5941337803624682

Epoch: 6| Step: 1
Training loss: 1.9968195303076446
Validation loss: 2.609867341539441

Epoch: 6| Step: 2
Training loss: 2.7133707784682346
Validation loss: 2.575985543031047

Epoch: 6| Step: 3
Training loss: 2.909562714745987
Validation loss: 2.5312991586294835

Epoch: 6| Step: 4
Training loss: 3.30246957792352
Validation loss: 2.510948630965403

Epoch: 6| Step: 5
Training loss: 3.4865909936788038
Validation loss: 2.4956094725003872

Epoch: 6| Step: 6
Training loss: 3.4017912353653905
Validation loss: 2.4817115972803765

Epoch: 6| Step: 7
Training loss: 2.4359121775213244
Validation loss: 2.478302557288721

Epoch: 6| Step: 8
Training loss: 2.019645407307566
Validation loss: 2.4783183064976066

Epoch: 6| Step: 9
Training loss: 2.7965172906508515
Validation loss: 2.4782521157005957

Epoch: 6| Step: 10
Training loss: 3.4111371459409203
Validation loss: 2.498437508044605

Epoch: 6| Step: 11
Training loss: 2.4340236033139155
Validation loss: 2.4955853892927693

Epoch: 6| Step: 12
Training loss: 3.173807542000565
Validation loss: 2.4875739438403364

Epoch: 6| Step: 13
Training loss: 1.8501967531688086
Validation loss: 2.4755358672211356

Epoch: 109| Step: 0
Training loss: 2.357760249444346
Validation loss: 2.4665146772003

Epoch: 6| Step: 1
Training loss: 3.1527545571464044
Validation loss: 2.4727844206099308

Epoch: 6| Step: 2
Training loss: 2.963877001373785
Validation loss: 2.491515672979873

Epoch: 6| Step: 3
Training loss: 2.9480765650937197
Validation loss: 2.506791130277889

Epoch: 6| Step: 4
Training loss: 2.7253021562675475
Validation loss: 2.539983563964663

Epoch: 6| Step: 5
Training loss: 2.751317575570266
Validation loss: 2.5190849344512594

Epoch: 6| Step: 6
Training loss: 2.427903087397525
Validation loss: 2.505369185885015

Epoch: 6| Step: 7
Training loss: 3.259771476178092
Validation loss: 2.4999934750133392

Epoch: 6| Step: 8
Training loss: 2.511034645427966
Validation loss: 2.4841914337110556

Epoch: 6| Step: 9
Training loss: 2.7454319206582483
Validation loss: 2.4835755598271385

Epoch: 6| Step: 10
Training loss: 2.745194397732436
Validation loss: 2.4800648009030892

Epoch: 6| Step: 11
Training loss: 3.1674558927600818
Validation loss: 2.4725624150518817

Epoch: 6| Step: 12
Training loss: 2.5911193744068908
Validation loss: 2.4686017545544767

Epoch: 6| Step: 13
Training loss: 2.786291632018225
Validation loss: 2.4639221510170124

Epoch: 110| Step: 0
Training loss: 2.7109396107250427
Validation loss: 2.4636190087019902

Epoch: 6| Step: 1
Training loss: 2.4386557748835327
Validation loss: 2.4639668742356204

Epoch: 6| Step: 2
Training loss: 3.3964972909832047
Validation loss: 2.4535203621259396

Epoch: 6| Step: 3
Training loss: 2.677788954386551
Validation loss: 2.4540062982867985

Epoch: 6| Step: 4
Training loss: 2.8439582496937215
Validation loss: 2.45709490949958

Epoch: 6| Step: 5
Training loss: 1.9262483660909469
Validation loss: 2.4608917799825796

Epoch: 6| Step: 6
Training loss: 3.0827983873279194
Validation loss: 2.459437119546808

Epoch: 6| Step: 7
Training loss: 2.6821055721182554
Validation loss: 2.4632516632296766

Epoch: 6| Step: 8
Training loss: 3.2205257517296317
Validation loss: 2.4613439924458844

Epoch: 6| Step: 9
Training loss: 2.5670512650248387
Validation loss: 2.4648359306480154

Epoch: 6| Step: 10
Training loss: 2.9781590783009735
Validation loss: 2.4696788699302727

Epoch: 6| Step: 11
Training loss: 2.6623961307520445
Validation loss: 2.4814125477900673

Epoch: 6| Step: 12
Training loss: 2.7544909133913595
Validation loss: 2.4852023241805457

Epoch: 6| Step: 13
Training loss: 2.5853635952093073
Validation loss: 2.495535518932752

Epoch: 111| Step: 0
Training loss: 2.6639329090090036
Validation loss: 2.4975766475528056

Epoch: 6| Step: 1
Training loss: 2.4273798247113136
Validation loss: 2.4946735244581917

Epoch: 6| Step: 2
Training loss: 2.710634066175375
Validation loss: 2.493628565998752

Epoch: 6| Step: 3
Training loss: 2.363006323594048
Validation loss: 2.484918960083767

Epoch: 6| Step: 4
Training loss: 3.0416626777796956
Validation loss: 2.4795430163939685

Epoch: 6| Step: 5
Training loss: 2.893196570450005
Validation loss: 2.4735125897347894

Epoch: 6| Step: 6
Training loss: 3.329107435047255
Validation loss: 2.4770719838024475

Epoch: 6| Step: 7
Training loss: 2.3833845608770012
Validation loss: 2.47510910514623

Epoch: 6| Step: 8
Training loss: 3.2040999254700937
Validation loss: 2.477297974048108

Epoch: 6| Step: 9
Training loss: 2.4756053916272096
Validation loss: 2.475967520532635

Epoch: 6| Step: 10
Training loss: 2.232097612194908
Validation loss: 2.4838386751821058

Epoch: 6| Step: 11
Training loss: 3.191327359031035
Validation loss: 2.5018865184162142

Epoch: 6| Step: 12
Training loss: 2.4354062991959036
Validation loss: 2.5121096624173056

Epoch: 6| Step: 13
Training loss: 3.1895737727391738
Validation loss: 2.532315063435969

Epoch: 112| Step: 0
Training loss: 2.995308068022934
Validation loss: 2.5691133852549526

Epoch: 6| Step: 1
Training loss: 3.040509112542199
Validation loss: 2.5883999595066993

Epoch: 6| Step: 2
Training loss: 2.6257640998096385
Validation loss: 2.6043825039582393

Epoch: 6| Step: 3
Training loss: 3.139435196393765
Validation loss: 2.558851045610904

Epoch: 6| Step: 4
Training loss: 2.7095349116141425
Validation loss: 2.5221754071318037

Epoch: 6| Step: 5
Training loss: 2.0328699548036293
Validation loss: 2.4812002330601874

Epoch: 6| Step: 6
Training loss: 2.3544605938102205
Validation loss: 2.4621494604019527

Epoch: 6| Step: 7
Training loss: 2.5838481841235628
Validation loss: 2.4487676788497454

Epoch: 6| Step: 8
Training loss: 3.080170392364048
Validation loss: 2.452809207075869

Epoch: 6| Step: 9
Training loss: 3.1507877636385064
Validation loss: 2.458431380290947

Epoch: 6| Step: 10
Training loss: 3.2098793829482397
Validation loss: 2.455034419844903

Epoch: 6| Step: 11
Training loss: 2.1826132550300144
Validation loss: 2.456980219375842

Epoch: 6| Step: 12
Training loss: 3.051070860183333
Validation loss: 2.4664206044384454

Epoch: 6| Step: 13
Training loss: 3.0541198671371426
Validation loss: 2.4607638244234247

Epoch: 113| Step: 0
Training loss: 2.793863305305342
Validation loss: 2.4613303125418238

Epoch: 6| Step: 1
Training loss: 2.25865986376612
Validation loss: 2.4583339056769016

Epoch: 6| Step: 2
Training loss: 2.7662192530588845
Validation loss: 2.4571600572324535

Epoch: 6| Step: 3
Training loss: 2.65872525840765
Validation loss: 2.470757864853515

Epoch: 6| Step: 4
Training loss: 2.4426857975053755
Validation loss: 2.4505748872062205

Epoch: 6| Step: 5
Training loss: 2.710181490884235
Validation loss: 2.4526137077875156

Epoch: 6| Step: 6
Training loss: 2.5857411105443786
Validation loss: 2.4548126533236556

Epoch: 6| Step: 7
Training loss: 2.9053054423132116
Validation loss: 2.4487366901023777

Epoch: 6| Step: 8
Training loss: 3.193941078516808
Validation loss: 2.4565974486004367

Epoch: 6| Step: 9
Training loss: 2.5269801543059947
Validation loss: 2.449288261536557

Epoch: 6| Step: 10
Training loss: 3.0620845590747208
Validation loss: 2.45422171766649

Epoch: 6| Step: 11
Training loss: 3.3038219283288326
Validation loss: 2.4607228183032626

Epoch: 6| Step: 12
Training loss: 2.5934034368785692
Validation loss: 2.4684621555618373

Epoch: 6| Step: 13
Training loss: 2.9956492028312227
Validation loss: 2.485617387547334

Epoch: 114| Step: 0
Training loss: 3.007927117083626
Validation loss: 2.494524034518379

Epoch: 6| Step: 1
Training loss: 2.985795407030844
Validation loss: 2.4974603022408766

Epoch: 6| Step: 2
Training loss: 2.161865441156999
Validation loss: 2.4921211210433563

Epoch: 6| Step: 3
Training loss: 2.44457245862393
Validation loss: 2.4834412997337174

Epoch: 6| Step: 4
Training loss: 2.758565826836472
Validation loss: 2.4746832639849616

Epoch: 6| Step: 5
Training loss: 2.773646215187937
Validation loss: 2.470629734381044

Epoch: 6| Step: 6
Training loss: 2.9365434103598287
Validation loss: 2.466370962400483

Epoch: 6| Step: 7
Training loss: 2.902129502943566
Validation loss: 2.473545906822884

Epoch: 6| Step: 8
Training loss: 2.9063894587045533
Validation loss: 2.472019671604744

Epoch: 6| Step: 9
Training loss: 3.0982863950602484
Validation loss: 2.487106981919274

Epoch: 6| Step: 10
Training loss: 2.952478408669928
Validation loss: 2.4911220146496804

Epoch: 6| Step: 11
Training loss: 2.4148792255601
Validation loss: 2.4904996716717545

Epoch: 6| Step: 12
Training loss: 2.3208461366182718
Validation loss: 2.4969518968537647

Epoch: 6| Step: 13
Training loss: 2.8354017524037363
Validation loss: 2.496092767102394

Epoch: 115| Step: 0
Training loss: 2.694298417983599
Validation loss: 2.4988317446678368

Epoch: 6| Step: 1
Training loss: 1.7962028241317018
Validation loss: 2.4884770522181316

Epoch: 6| Step: 2
Training loss: 2.4470029600162166
Validation loss: 2.486495284635544

Epoch: 6| Step: 3
Training loss: 2.7540347238427905
Validation loss: 2.4838015647253906

Epoch: 6| Step: 4
Training loss: 2.9175317480456817
Validation loss: 2.4825275228553627

Epoch: 6| Step: 5
Training loss: 2.3453531504443146
Validation loss: 2.4810091780809267

Epoch: 6| Step: 6
Training loss: 3.132933045919565
Validation loss: 2.476931441124958

Epoch: 6| Step: 7
Training loss: 2.9489322346339004
Validation loss: 2.4711580257761816

Epoch: 6| Step: 8
Training loss: 3.0325074094979008
Validation loss: 2.4670547182885105

Epoch: 6| Step: 9
Training loss: 2.931068034105766
Validation loss: 2.466880980789918

Epoch: 6| Step: 10
Training loss: 2.460060762724943
Validation loss: 2.4667231093780493

Epoch: 6| Step: 11
Training loss: 2.8386748583048176
Validation loss: 2.4687158954258988

Epoch: 6| Step: 12
Training loss: 3.1395383254894016
Validation loss: 2.464451568207054

Epoch: 6| Step: 13
Training loss: 2.657324719394798
Validation loss: 2.4675762064697877

Epoch: 116| Step: 0
Training loss: 2.605488789951745
Validation loss: 2.471282974210651

Epoch: 6| Step: 1
Training loss: 2.42532014994772
Validation loss: 2.4803750772756947

Epoch: 6| Step: 2
Training loss: 2.5068208153821745
Validation loss: 2.49655091154533

Epoch: 6| Step: 3
Training loss: 3.018503031293286
Validation loss: 2.5140142433526016

Epoch: 6| Step: 4
Training loss: 3.1090353008633014
Validation loss: 2.5266016192462604

Epoch: 6| Step: 5
Training loss: 2.2469100928185712
Validation loss: 2.5462771998220015

Epoch: 6| Step: 6
Training loss: 3.242302949987035
Validation loss: 2.54253043820852

Epoch: 6| Step: 7
Training loss: 3.1401378956055366
Validation loss: 2.5024876287569904

Epoch: 6| Step: 8
Training loss: 1.8382327402882508
Validation loss: 2.470813851690491

Epoch: 6| Step: 9
Training loss: 2.9732155392782023
Validation loss: 2.451692416691357

Epoch: 6| Step: 10
Training loss: 2.4263182213147525
Validation loss: 2.4360236784138163

Epoch: 6| Step: 11
Training loss: 3.199464669749243
Validation loss: 2.430415680860297

Epoch: 6| Step: 12
Training loss: 2.8142074488323487
Validation loss: 2.4348172279362723

Epoch: 6| Step: 13
Training loss: 2.7095633330221234
Validation loss: 2.4329412287342422

Epoch: 117| Step: 0
Training loss: 2.871315793125183
Validation loss: 2.431905108417756

Epoch: 6| Step: 1
Training loss: 2.779641532839518
Validation loss: 2.428755997716178

Epoch: 6| Step: 2
Training loss: 2.9283598879929285
Validation loss: 2.4324503798068893

Epoch: 6| Step: 3
Training loss: 1.889330333972956
Validation loss: 2.433712259966106

Epoch: 6| Step: 4
Training loss: 2.158327732545319
Validation loss: 2.4398405135515278

Epoch: 6| Step: 5
Training loss: 2.871675974660509
Validation loss: 2.4572564344392878

Epoch: 6| Step: 6
Training loss: 3.1620110537138535
Validation loss: 2.4750182520596424

Epoch: 6| Step: 7
Training loss: 2.766395763171577
Validation loss: 2.4854230299953635

Epoch: 6| Step: 8
Training loss: 2.255696925799925
Validation loss: 2.5077653221794085

Epoch: 6| Step: 9
Training loss: 2.619336785829825
Validation loss: 2.5123022758464013

Epoch: 6| Step: 10
Training loss: 2.821215878518183
Validation loss: 2.5016446528412013

Epoch: 6| Step: 11
Training loss: 3.411261415500907
Validation loss: 2.4884894774854183

Epoch: 6| Step: 12
Training loss: 2.9488570439927675
Validation loss: 2.4736974314154083

Epoch: 6| Step: 13
Training loss: 3.0073240205517267
Validation loss: 2.466774279329256

Epoch: 118| Step: 0
Training loss: 3.1291784199080377
Validation loss: 2.4509683930237833

Epoch: 6| Step: 1
Training loss: 2.8147977132259143
Validation loss: 2.439532801436306

Epoch: 6| Step: 2
Training loss: 2.5453089480436772
Validation loss: 2.4343734453709636

Epoch: 6| Step: 3
Training loss: 2.79937036110625
Validation loss: 2.4367856361156686

Epoch: 6| Step: 4
Training loss: 2.537187277028844
Validation loss: 2.4381793216420258

Epoch: 6| Step: 5
Training loss: 2.6563053798512346
Validation loss: 2.445313703551172

Epoch: 6| Step: 6
Training loss: 2.682606166932223
Validation loss: 2.4425064252900985

Epoch: 6| Step: 7
Training loss: 2.316760288606329
Validation loss: 2.45726361333409

Epoch: 6| Step: 8
Training loss: 3.1804183382496105
Validation loss: 2.4521747036759725

Epoch: 6| Step: 9
Training loss: 2.7367544230129788
Validation loss: 2.463672102636645

Epoch: 6| Step: 10
Training loss: 1.751265885405611
Validation loss: 2.474374614379101

Epoch: 6| Step: 11
Training loss: 2.9901088735603976
Validation loss: 2.4698705138406125

Epoch: 6| Step: 12
Training loss: 3.1050129873891783
Validation loss: 2.4837638086145404

Epoch: 6| Step: 13
Training loss: 2.9141413700997347
Validation loss: 2.4999273289608737

Epoch: 119| Step: 0
Training loss: 2.9945573709584234
Validation loss: 2.4704489935916123

Epoch: 6| Step: 1
Training loss: 2.9604408028728515
Validation loss: 2.446458683343787

Epoch: 6| Step: 2
Training loss: 2.592115967575828
Validation loss: 2.4426513542087256

Epoch: 6| Step: 3
Training loss: 2.5887971952769737
Validation loss: 2.4410989211386203

Epoch: 6| Step: 4
Training loss: 2.753864174379371
Validation loss: 2.4421007118814897

Epoch: 6| Step: 5
Training loss: 2.6244286414903533
Validation loss: 2.4387084041726586

Epoch: 6| Step: 6
Training loss: 2.335859928948227
Validation loss: 2.4425099886598884

Epoch: 6| Step: 7
Training loss: 3.023061329705638
Validation loss: 2.453248276338971

Epoch: 6| Step: 8
Training loss: 3.006828642610508
Validation loss: 2.4543923330350794

Epoch: 6| Step: 9
Training loss: 2.5382882683757617
Validation loss: 2.4609842963000608

Epoch: 6| Step: 10
Training loss: 2.8291748795837237
Validation loss: 2.466645492941195

Epoch: 6| Step: 11
Training loss: 2.3713015821896355
Validation loss: 2.4749403954558007

Epoch: 6| Step: 12
Training loss: 2.9496717496674325
Validation loss: 2.481913360299995

Epoch: 6| Step: 13
Training loss: 2.563338444939896
Validation loss: 2.488387037488837

Epoch: 120| Step: 0
Training loss: 2.6105809879771202
Validation loss: 2.500563194046519

Epoch: 6| Step: 1
Training loss: 2.5910659138736403
Validation loss: 2.492480242530716

Epoch: 6| Step: 2
Training loss: 2.491301471735464
Validation loss: 2.4868281743766527

Epoch: 6| Step: 3
Training loss: 2.873197902960253
Validation loss: 2.4923270887825475

Epoch: 6| Step: 4
Training loss: 2.5529572113073327
Validation loss: 2.485999329321556

Epoch: 6| Step: 5
Training loss: 2.631777415571519
Validation loss: 2.4792094224810692

Epoch: 6| Step: 6
Training loss: 2.6896214650644974
Validation loss: 2.471573112301051

Epoch: 6| Step: 7
Training loss: 3.197262493078414
Validation loss: 2.4704813225884803

Epoch: 6| Step: 8
Training loss: 2.416302379468654
Validation loss: 2.4645518294238062

Epoch: 6| Step: 9
Training loss: 2.3511820640666414
Validation loss: 2.466376902783666

Epoch: 6| Step: 10
Training loss: 2.948791553807698
Validation loss: 2.467232565568349

Epoch: 6| Step: 11
Training loss: 2.9440448977737113
Validation loss: 2.4653281031137113

Epoch: 6| Step: 12
Training loss: 2.8717256226984826
Validation loss: 2.471561055270941

Epoch: 6| Step: 13
Training loss: 3.0299554006989293
Validation loss: 2.4743835567365813

Epoch: 121| Step: 0
Training loss: 2.874146708036388
Validation loss: 2.4809040576769785

Epoch: 6| Step: 1
Training loss: 3.3440274987983765
Validation loss: 2.486568846202775

Epoch: 6| Step: 2
Training loss: 2.314223806875235
Validation loss: 2.509126625768847

Epoch: 6| Step: 3
Training loss: 2.4338494376238584
Validation loss: 2.535080692372402

Epoch: 6| Step: 4
Training loss: 2.8278422346015675
Validation loss: 2.5563351858040644

Epoch: 6| Step: 5
Training loss: 2.637679042434086
Validation loss: 2.566854147688685

Epoch: 6| Step: 6
Training loss: 3.143362190488984
Validation loss: 2.5669829679764815

Epoch: 6| Step: 7
Training loss: 2.8327780534740348
Validation loss: 2.548186395821489

Epoch: 6| Step: 8
Training loss: 2.9019070241534366
Validation loss: 2.52686801626102

Epoch: 6| Step: 9
Training loss: 2.308171422446602
Validation loss: 2.498324312553918

Epoch: 6| Step: 10
Training loss: 2.6706495542176385
Validation loss: 2.4800870573775278

Epoch: 6| Step: 11
Training loss: 2.696695697079614
Validation loss: 2.4552403642115603

Epoch: 6| Step: 12
Training loss: 2.1775641267883787
Validation loss: 2.454031242925294

Epoch: 6| Step: 13
Training loss: 2.6935375616649293
Validation loss: 2.447150772775804

Epoch: 122| Step: 0
Training loss: 3.3419010362383177
Validation loss: 2.449336694451586

Epoch: 6| Step: 1
Training loss: 3.061969010388749
Validation loss: 2.447828795968594

Epoch: 6| Step: 2
Training loss: 2.6331832126690187
Validation loss: 2.448128736146717

Epoch: 6| Step: 3
Training loss: 2.4134393276556896
Validation loss: 2.4526439848572648

Epoch: 6| Step: 4
Training loss: 2.2796505062874552
Validation loss: 2.448830880022036

Epoch: 6| Step: 5
Training loss: 2.868583484878346
Validation loss: 2.440852799751489

Epoch: 6| Step: 6
Training loss: 2.6237761051211455
Validation loss: 2.4453149196824167

Epoch: 6| Step: 7
Training loss: 2.039449954582984
Validation loss: 2.4675895296809087

Epoch: 6| Step: 8
Training loss: 2.5660322082234543
Validation loss: 2.5105624729507507

Epoch: 6| Step: 9
Training loss: 3.120094569069034
Validation loss: 2.5625369661807738

Epoch: 6| Step: 10
Training loss: 2.8427055033642548
Validation loss: 2.570699863622587

Epoch: 6| Step: 11
Training loss: 2.9582301018841246
Validation loss: 2.5878813962797

Epoch: 6| Step: 12
Training loss: 2.4445105264382043
Validation loss: 2.563002600353707

Epoch: 6| Step: 13
Training loss: 2.884485271160353
Validation loss: 2.568085791969942

Epoch: 123| Step: 0
Training loss: 2.9872192889374887
Validation loss: 2.590570110923747

Epoch: 6| Step: 1
Training loss: 2.6889663953968874
Validation loss: 2.5686105912926487

Epoch: 6| Step: 2
Training loss: 2.656502745328433
Validation loss: 2.5416514989466563

Epoch: 6| Step: 3
Training loss: 2.672015270098151
Validation loss: 2.5565353213059656

Epoch: 6| Step: 4
Training loss: 2.7432707904656035
Validation loss: 2.551989435641266

Epoch: 6| Step: 5
Training loss: 2.506056601656145
Validation loss: 2.5444095419386947

Epoch: 6| Step: 6
Training loss: 2.0984380817199493
Validation loss: 2.52695148821594

Epoch: 6| Step: 7
Training loss: 2.6659034789256255
Validation loss: 2.5065418697323305

Epoch: 6| Step: 8
Training loss: 2.963717240337929
Validation loss: 2.4814846721449006

Epoch: 6| Step: 9
Training loss: 2.587645367210846
Validation loss: 2.4783218369961846

Epoch: 6| Step: 10
Training loss: 2.782377978697199
Validation loss: 2.4620975112778236

Epoch: 6| Step: 11
Training loss: 3.0404140732499587
Validation loss: 2.4595882635972632

Epoch: 6| Step: 12
Training loss: 3.2619609811344845
Validation loss: 2.460226616417959

Epoch: 6| Step: 13
Training loss: 1.5367656939133212
Validation loss: 2.462231163623546

Epoch: 124| Step: 0
Training loss: 3.118389003249264
Validation loss: 2.456611350007157

Epoch: 6| Step: 1
Training loss: 2.481743816750383
Validation loss: 2.4589128381311305

Epoch: 6| Step: 2
Training loss: 2.794730787056088
Validation loss: 2.464844983537433

Epoch: 6| Step: 3
Training loss: 2.4521618549886797
Validation loss: 2.479802383548963

Epoch: 6| Step: 4
Training loss: 2.4432207124610303
Validation loss: 2.497082222746955

Epoch: 6| Step: 5
Training loss: 2.5927521957992865
Validation loss: 2.4940419407825534

Epoch: 6| Step: 6
Training loss: 2.114279238127581
Validation loss: 2.5127972440841093

Epoch: 6| Step: 7
Training loss: 2.8916587836811303
Validation loss: 2.522839860121369

Epoch: 6| Step: 8
Training loss: 2.6017910510413413
Validation loss: 2.5305469741373514

Epoch: 6| Step: 9
Training loss: 2.408195600784069
Validation loss: 2.5232947656597564

Epoch: 6| Step: 10
Training loss: 2.7088265679015855
Validation loss: 2.498408988526196

Epoch: 6| Step: 11
Training loss: 3.521265819704962
Validation loss: 2.481819662561888

Epoch: 6| Step: 12
Training loss: 2.7380418006152687
Validation loss: 2.481451560825911

Epoch: 6| Step: 13
Training loss: 2.8819370336067074
Validation loss: 2.4727213516507742

Epoch: 125| Step: 0
Training loss: 2.757357638186774
Validation loss: 2.467781100028368

Epoch: 6| Step: 1
Training loss: 2.966488910735978
Validation loss: 2.4638088441930175

Epoch: 6| Step: 2
Training loss: 2.400948964699439
Validation loss: 2.472805927739004

Epoch: 6| Step: 3
Training loss: 2.8499003543499764
Validation loss: 2.475280675327062

Epoch: 6| Step: 4
Training loss: 2.603317814128237
Validation loss: 2.477456250879224

Epoch: 6| Step: 5
Training loss: 2.0551171379396056
Validation loss: 2.474607804456998

Epoch: 6| Step: 6
Training loss: 2.6950301312689002
Validation loss: 2.479848051616321

Epoch: 6| Step: 7
Training loss: 2.91251018997178
Validation loss: 2.4860538035248485

Epoch: 6| Step: 8
Training loss: 2.7784973409934137
Validation loss: 2.4868354998540267

Epoch: 6| Step: 9
Training loss: 3.0257442851311653
Validation loss: 2.471166637424491

Epoch: 6| Step: 10
Training loss: 2.177349737437666
Validation loss: 2.4901633915042614

Epoch: 6| Step: 11
Training loss: 2.643090896873534
Validation loss: 2.470900176987049

Epoch: 6| Step: 12
Training loss: 2.7053676408980376
Validation loss: 2.4497157094111204

Epoch: 6| Step: 13
Training loss: 3.023801481038151
Validation loss: 2.4469469574625164

Epoch: 126| Step: 0
Training loss: 2.720134426469616
Validation loss: 2.4468001109912274

Epoch: 6| Step: 1
Training loss: 2.9236617719459757
Validation loss: 2.455027742977002

Epoch: 6| Step: 2
Training loss: 2.4409560131718364
Validation loss: 2.4441787055407116

Epoch: 6| Step: 3
Training loss: 2.771232480624807
Validation loss: 2.4511959511238333

Epoch: 6| Step: 4
Training loss: 2.5241664152584997
Validation loss: 2.456456765611485

Epoch: 6| Step: 5
Training loss: 2.7325691581552998
Validation loss: 2.4551099171033246

Epoch: 6| Step: 6
Training loss: 2.1716125110110545
Validation loss: 2.476899895989901

Epoch: 6| Step: 7
Training loss: 2.0505847655130474
Validation loss: 2.490054607300769

Epoch: 6| Step: 8
Training loss: 2.6229571613299596
Validation loss: 2.5136954320499556

Epoch: 6| Step: 9
Training loss: 2.9430504164011535
Validation loss: 2.5271318805259293

Epoch: 6| Step: 10
Training loss: 2.489431932599463
Validation loss: 2.5276317920139006

Epoch: 6| Step: 11
Training loss: 3.333476890015818
Validation loss: 2.5327464503327044

Epoch: 6| Step: 12
Training loss: 3.017677043787255
Validation loss: 2.5197610231242153

Epoch: 6| Step: 13
Training loss: 2.7591639333250777
Validation loss: 2.4967473487227507

Epoch: 127| Step: 0
Training loss: 2.7804548862901597
Validation loss: 2.483904220668501

Epoch: 6| Step: 1
Training loss: 2.4907569725844936
Validation loss: 2.468139579202085

Epoch: 6| Step: 2
Training loss: 3.025374863782379
Validation loss: 2.4612569257557655

Epoch: 6| Step: 3
Training loss: 2.0419941723821653
Validation loss: 2.4707609983818624

Epoch: 6| Step: 4
Training loss: 2.9413961990407627
Validation loss: 2.469246096524245

Epoch: 6| Step: 5
Training loss: 2.9485345918470838
Validation loss: 2.4703890436323555

Epoch: 6| Step: 6
Training loss: 2.9669278626346203
Validation loss: 2.46464779588464

Epoch: 6| Step: 7
Training loss: 2.7656310345427633
Validation loss: 2.467943061986533

Epoch: 6| Step: 8
Training loss: 2.42331529674438
Validation loss: 2.48019428280117

Epoch: 6| Step: 9
Training loss: 2.598687126569745
Validation loss: 2.489063441550194

Epoch: 6| Step: 10
Training loss: 2.4797770819921072
Validation loss: 2.5031722154627505

Epoch: 6| Step: 11
Training loss: 2.1955880097428597
Validation loss: 2.5119382062956355

Epoch: 6| Step: 12
Training loss: 3.0826067369084877
Validation loss: 2.5023466187299954

Epoch: 6| Step: 13
Training loss: 2.25921460607254
Validation loss: 2.5009295488969903

Epoch: 128| Step: 0
Training loss: 2.0755093971872305
Validation loss: 2.496504957530359

Epoch: 6| Step: 1
Training loss: 2.640149677541828
Validation loss: 2.509632422278988

Epoch: 6| Step: 2
Training loss: 2.462279713648437
Validation loss: 2.513587580604457

Epoch: 6| Step: 3
Training loss: 2.531272605512486
Validation loss: 2.518319006824186

Epoch: 6| Step: 4
Training loss: 3.0309734414956124
Validation loss: 2.510218590062107

Epoch: 6| Step: 5
Training loss: 1.8989829704400945
Validation loss: 2.5139821896639525

Epoch: 6| Step: 6
Training loss: 2.7180904596923026
Validation loss: 2.515666860686798

Epoch: 6| Step: 7
Training loss: 2.803154571615373
Validation loss: 2.51498411750235

Epoch: 6| Step: 8
Training loss: 2.7816439574609655
Validation loss: 2.516236182266998

Epoch: 6| Step: 9
Training loss: 2.644951520738727
Validation loss: 2.512542062496182

Epoch: 6| Step: 10
Training loss: 2.698140924233107
Validation loss: 2.52486430619541

Epoch: 6| Step: 11
Training loss: 2.9858645571468054
Validation loss: 2.5211163091384132

Epoch: 6| Step: 12
Training loss: 3.261133929607298
Validation loss: 2.505112216093022

Epoch: 6| Step: 13
Training loss: 2.4731856467923623
Validation loss: 2.4901244820128268

Epoch: 129| Step: 0
Training loss: 2.3751850056116823
Validation loss: 2.4783780760328487

Epoch: 6| Step: 1
Training loss: 2.535309538593253
Validation loss: 2.482994624304801

Epoch: 6| Step: 2
Training loss: 2.3858345254337032
Validation loss: 2.475837240828994

Epoch: 6| Step: 3
Training loss: 2.7473795283166695
Validation loss: 2.4917502281797534

Epoch: 6| Step: 4
Training loss: 2.575223735237298
Validation loss: 2.511177878575572

Epoch: 6| Step: 5
Training loss: 2.3737741619565784
Validation loss: 2.5310979635686026

Epoch: 6| Step: 6
Training loss: 3.4487155015802395
Validation loss: 2.5180622315320043

Epoch: 6| Step: 7
Training loss: 2.6460844406356117
Validation loss: 2.5083050519353005

Epoch: 6| Step: 8
Training loss: 2.568175566735489
Validation loss: 2.4937875632231314

Epoch: 6| Step: 9
Training loss: 2.412486429126895
Validation loss: 2.4954723798152454

Epoch: 6| Step: 10
Training loss: 3.0810220320674375
Validation loss: 2.4999076600608015

Epoch: 6| Step: 11
Training loss: 3.000896955552089
Validation loss: 2.5121018156803867

Epoch: 6| Step: 12
Training loss: 2.2411692364039832
Validation loss: 2.5122398081339137

Epoch: 6| Step: 13
Training loss: 3.2033797000012925
Validation loss: 2.5033865571657747

Epoch: 130| Step: 0
Training loss: 2.6290769252383623
Validation loss: 2.500186468163926

Epoch: 6| Step: 1
Training loss: 2.1510162967789874
Validation loss: 2.4933746058632424

Epoch: 6| Step: 2
Training loss: 2.7293924330496826
Validation loss: 2.4859378475748604

Epoch: 6| Step: 3
Training loss: 3.0161595636651537
Validation loss: 2.4812200962342543

Epoch: 6| Step: 4
Training loss: 2.6338497122350444
Validation loss: 2.4759243860267737

Epoch: 6| Step: 5
Training loss: 2.779743772540736
Validation loss: 2.4713272042598877

Epoch: 6| Step: 6
Training loss: 2.2814855584584772
Validation loss: 2.470946102961392

Epoch: 6| Step: 7
Training loss: 2.474184356537131
Validation loss: 2.463701381178975

Epoch: 6| Step: 8
Training loss: 2.6669426616259284
Validation loss: 2.466654744974454

Epoch: 6| Step: 9
Training loss: 2.0639973609227305
Validation loss: 2.4674352237042574

Epoch: 6| Step: 10
Training loss: 2.7067474612813127
Validation loss: 2.4742503069790565

Epoch: 6| Step: 11
Training loss: 3.678644182223823
Validation loss: 2.4850894547929343

Epoch: 6| Step: 12
Training loss: 2.605102787882065
Validation loss: 2.477158544303779

Epoch: 6| Step: 13
Training loss: 2.4715664406963387
Validation loss: 2.487757713962261

Epoch: 131| Step: 0
Training loss: 2.66057575519879
Validation loss: 2.496484873498448

Epoch: 6| Step: 1
Training loss: 2.560381036504822
Validation loss: 2.4990880820673147

Epoch: 6| Step: 2
Training loss: 1.629174665478569
Validation loss: 2.5144579990721696

Epoch: 6| Step: 3
Training loss: 2.6180844719928795
Validation loss: 2.5201233181133382

Epoch: 6| Step: 4
Training loss: 2.4360697536034115
Validation loss: 2.5336503993671644

Epoch: 6| Step: 5
Training loss: 3.1924445005415656
Validation loss: 2.5752172415689145

Epoch: 6| Step: 6
Training loss: 2.52058216031136
Validation loss: 2.5651852734147793

Epoch: 6| Step: 7
Training loss: 2.98429063607852
Validation loss: 2.549390747048066

Epoch: 6| Step: 8
Training loss: 2.9569341726758283
Validation loss: 2.510138728637747

Epoch: 6| Step: 9
Training loss: 3.1380091159121655
Validation loss: 2.4802396697416604

Epoch: 6| Step: 10
Training loss: 2.1676896199108033
Validation loss: 2.4617384511364233

Epoch: 6| Step: 11
Training loss: 2.545787743026497
Validation loss: 2.456326021985782

Epoch: 6| Step: 12
Training loss: 2.9404472013551817
Validation loss: 2.4611643040648103

Epoch: 6| Step: 13
Training loss: 2.7365279958565987
Validation loss: 2.457248394803384

Epoch: 132| Step: 0
Training loss: 2.612919210721566
Validation loss: 2.4573926869309752

Epoch: 6| Step: 1
Training loss: 2.1009015600355285
Validation loss: 2.4579353517885725

Epoch: 6| Step: 2
Training loss: 3.1417424126220257
Validation loss: 2.45431437887098

Epoch: 6| Step: 3
Training loss: 2.545203942032321
Validation loss: 2.4561286107011777

Epoch: 6| Step: 4
Training loss: 3.0832226363922413
Validation loss: 2.464102378010278

Epoch: 6| Step: 5
Training loss: 2.3854663516093964
Validation loss: 2.488888915588901

Epoch: 6| Step: 6
Training loss: 2.7247898930734573
Validation loss: 2.507920295178114

Epoch: 6| Step: 7
Training loss: 2.6611556585888585
Validation loss: 2.521556457301064

Epoch: 6| Step: 8
Training loss: 2.3808418504853917
Validation loss: 2.563217536836613

Epoch: 6| Step: 9
Training loss: 2.3067710639320156
Validation loss: 2.587107142397295

Epoch: 6| Step: 10
Training loss: 3.3533549461906955
Validation loss: 2.6665844814905437

Epoch: 6| Step: 11
Training loss: 2.5508984572397133
Validation loss: 2.598390046616148

Epoch: 6| Step: 12
Training loss: 3.135247480489541
Validation loss: 2.5334043582983483

Epoch: 6| Step: 13
Training loss: 2.4148940348627055
Validation loss: 2.4890789887772713

Epoch: 133| Step: 0
Training loss: 2.388492605573625
Validation loss: 2.4593947218708676

Epoch: 6| Step: 1
Training loss: 2.542006631429863
Validation loss: 2.4436572179361185

Epoch: 6| Step: 2
Training loss: 2.3675760384647835
Validation loss: 2.44570159673329

Epoch: 6| Step: 3
Training loss: 2.67003537029598
Validation loss: 2.4431053783668366

Epoch: 6| Step: 4
Training loss: 2.2603452000256086
Validation loss: 2.4406301563825004

Epoch: 6| Step: 5
Training loss: 3.0007181897398896
Validation loss: 2.435424720574489

Epoch: 6| Step: 6
Training loss: 2.8756106184309806
Validation loss: 2.4471841774404925

Epoch: 6| Step: 7
Training loss: 2.429538341985115
Validation loss: 2.4665101257606494

Epoch: 6| Step: 8
Training loss: 2.596810982072305
Validation loss: 2.4850522020812895

Epoch: 6| Step: 9
Training loss: 3.040629867753683
Validation loss: 2.501042020684379

Epoch: 6| Step: 10
Training loss: 2.9758219761463924
Validation loss: 2.5242069348475638

Epoch: 6| Step: 11
Training loss: 2.952351948307038
Validation loss: 2.5237988918926186

Epoch: 6| Step: 12
Training loss: 2.6689315555467807
Validation loss: 2.5185738728347076

Epoch: 6| Step: 13
Training loss: 3.1483329963852187
Validation loss: 2.508005392339659

Epoch: 134| Step: 0
Training loss: 2.577621410777499
Validation loss: 2.5062248973598384

Epoch: 6| Step: 1
Training loss: 2.916263025600548
Validation loss: 2.5114292927274806

Epoch: 6| Step: 2
Training loss: 2.108811140638223
Validation loss: 2.5164511889542043

Epoch: 6| Step: 3
Training loss: 3.237453746097027
Validation loss: 2.5164491820112174

Epoch: 6| Step: 4
Training loss: 2.3609950080699247
Validation loss: 2.521477174586988

Epoch: 6| Step: 5
Training loss: 3.04130052078499
Validation loss: 2.498220816599457

Epoch: 6| Step: 6
Training loss: 2.692434615507489
Validation loss: 2.477133049120113

Epoch: 6| Step: 7
Training loss: 2.461281016761239
Validation loss: 2.449814679610389

Epoch: 6| Step: 8
Training loss: 2.32007944497197
Validation loss: 2.446610441599882

Epoch: 6| Step: 9
Training loss: 2.4750798838660852
Validation loss: 2.441467559504044

Epoch: 6| Step: 10
Training loss: 2.4391097597556977
Validation loss: 2.431050902800748

Epoch: 6| Step: 11
Training loss: 2.146233999629246
Validation loss: 2.432061518977019

Epoch: 6| Step: 12
Training loss: 3.266255733048451
Validation loss: 2.4306183768697855

Epoch: 6| Step: 13
Training loss: 3.0199102284812933
Validation loss: 2.437211709844615

Epoch: 135| Step: 0
Training loss: 2.3925055792573073
Validation loss: 2.4334749909063826

Epoch: 6| Step: 1
Training loss: 2.3694315430604354
Validation loss: 2.4480687998509714

Epoch: 6| Step: 2
Training loss: 2.6563857099983057
Validation loss: 2.4547306196350935

Epoch: 6| Step: 3
Training loss: 3.0698536925602147
Validation loss: 2.4482579698712517

Epoch: 6| Step: 4
Training loss: 2.897048658579241
Validation loss: 2.4596391129532575

Epoch: 6| Step: 5
Training loss: 2.188936905998522
Validation loss: 2.460254678242882

Epoch: 6| Step: 6
Training loss: 2.571751432358907
Validation loss: 2.474034157040622

Epoch: 6| Step: 7
Training loss: 2.532027042883297
Validation loss: 2.497478612350617

Epoch: 6| Step: 8
Training loss: 2.067935370625136
Validation loss: 2.5396978303139046

Epoch: 6| Step: 9
Training loss: 3.0199815974401156
Validation loss: 2.5737041218094276

Epoch: 6| Step: 10
Training loss: 2.6584473440979703
Validation loss: 2.6070748164900333

Epoch: 6| Step: 11
Training loss: 2.7405486249557898
Validation loss: 2.6220482248201793

Epoch: 6| Step: 12
Training loss: 2.9640359494272452
Validation loss: 2.59156513470914

Epoch: 6| Step: 13
Training loss: 2.656641762958558
Validation loss: 2.585323792170601

Epoch: 136| Step: 0
Training loss: 2.9475597439600554
Validation loss: 2.575728558628656

Epoch: 6| Step: 1
Training loss: 2.342217109396315
Validation loss: 2.578109749120884

Epoch: 6| Step: 2
Training loss: 2.300857102288486
Validation loss: 2.5781434178743243

Epoch: 6| Step: 3
Training loss: 2.0915455386689357
Validation loss: 2.586526040702749

Epoch: 6| Step: 4
Training loss: 2.83361317617669
Validation loss: 2.5975496837571717

Epoch: 6| Step: 5
Training loss: 2.601941513541874
Validation loss: 2.58785139775821

Epoch: 6| Step: 6
Training loss: 2.8239080698757486
Validation loss: 2.5928988463069933

Epoch: 6| Step: 7
Training loss: 2.9647564177787444
Validation loss: 2.5523922366417082

Epoch: 6| Step: 8
Training loss: 2.3152262108769714
Validation loss: 2.5137703862218257

Epoch: 6| Step: 9
Training loss: 2.650533921058342
Validation loss: 2.487680037590376

Epoch: 6| Step: 10
Training loss: 2.7951600341839495
Validation loss: 2.480568049643283

Epoch: 6| Step: 11
Training loss: 2.6993816232743546
Validation loss: 2.480720900074336

Epoch: 6| Step: 12
Training loss: 2.9263105537572818
Validation loss: 2.476520909991802

Epoch: 6| Step: 13
Training loss: 2.7896113349889933
Validation loss: 2.465960675458811

Epoch: 137| Step: 0
Training loss: 3.1008119996329784
Validation loss: 2.4691520188092295

Epoch: 6| Step: 1
Training loss: 2.7857937504539634
Validation loss: 2.4730854614137043

Epoch: 6| Step: 2
Training loss: 2.6296501750869754
Validation loss: 2.474144278739778

Epoch: 6| Step: 3
Training loss: 2.695848848356227
Validation loss: 2.4768623369036926

Epoch: 6| Step: 4
Training loss: 3.086344168220231
Validation loss: 2.498042627314451

Epoch: 6| Step: 5
Training loss: 2.56967071590813
Validation loss: 2.5119151665358928

Epoch: 6| Step: 6
Training loss: 2.732618541606769
Validation loss: 2.5211507939219815

Epoch: 6| Step: 7
Training loss: 2.5129988331729414
Validation loss: 2.521304293431102

Epoch: 6| Step: 8
Training loss: 2.993601014445881
Validation loss: 2.5082223229138827

Epoch: 6| Step: 9
Training loss: 2.673787642646886
Validation loss: 2.5105637606104074

Epoch: 6| Step: 10
Training loss: 2.636252219288282
Validation loss: 2.5304104724226812

Epoch: 6| Step: 11
Training loss: 2.3440374579577608
Validation loss: 2.5494807457221658

Epoch: 6| Step: 12
Training loss: 2.5474974450874432
Validation loss: 2.578023688400583

Epoch: 6| Step: 13
Training loss: 1.8847389970390698
Validation loss: 2.5886655001953

Epoch: 138| Step: 0
Training loss: 2.520546973070931
Validation loss: 2.601301300408196

Epoch: 6| Step: 1
Training loss: 2.9176675623195023
Validation loss: 2.598999483436781

Epoch: 6| Step: 2
Training loss: 2.365211190599109
Validation loss: 2.6048404148550475

Epoch: 6| Step: 3
Training loss: 2.885323937276794
Validation loss: 2.5813714174814764

Epoch: 6| Step: 4
Training loss: 3.0167955093548637
Validation loss: 2.5406671801745944

Epoch: 6| Step: 5
Training loss: 2.110635564459652
Validation loss: 2.522430505490742

Epoch: 6| Step: 6
Training loss: 2.662705688411576
Validation loss: 2.4977262935010986

Epoch: 6| Step: 7
Training loss: 3.0599343588277303
Validation loss: 2.4790168976176274

Epoch: 6| Step: 8
Training loss: 2.485110096171595
Validation loss: 2.4783779110456345

Epoch: 6| Step: 9
Training loss: 2.2452520501713895
Validation loss: 2.4753407139508843

Epoch: 6| Step: 10
Training loss: 2.4087883577722353
Validation loss: 2.4671592868056136

Epoch: 6| Step: 11
Training loss: 3.1843108136088123
Validation loss: 2.4701554646314383

Epoch: 6| Step: 12
Training loss: 2.292828167272609
Validation loss: 2.4858178115263376

Epoch: 6| Step: 13
Training loss: 2.2105070847676243
Validation loss: 2.4847868468814776

Epoch: 139| Step: 0
Training loss: 2.223790313543986
Validation loss: 2.4953883079308423

Epoch: 6| Step: 1
Training loss: 2.883071515612428
Validation loss: 2.50457044101478

Epoch: 6| Step: 2
Training loss: 2.7779566092676165
Validation loss: 2.5279416485265562

Epoch: 6| Step: 3
Training loss: 2.9213584402489152
Validation loss: 2.5524771919897518

Epoch: 6| Step: 4
Training loss: 2.4934951078322176
Validation loss: 2.573448512452638

Epoch: 6| Step: 5
Training loss: 2.82877405632602
Validation loss: 2.6080863786455146

Epoch: 6| Step: 6
Training loss: 2.602073825384096
Validation loss: 2.6223014930825914

Epoch: 6| Step: 7
Training loss: 2.738209591525156
Validation loss: 2.6230012625535712

Epoch: 6| Step: 8
Training loss: 2.552901924314457
Validation loss: 2.589790992692546

Epoch: 6| Step: 9
Training loss: 2.4510032079046105
Validation loss: 2.5574468015043763

Epoch: 6| Step: 10
Training loss: 2.3760110811045765
Validation loss: 2.5043356933218144

Epoch: 6| Step: 11
Training loss: 2.501442016521235
Validation loss: 2.4901354114058982

Epoch: 6| Step: 12
Training loss: 2.913384489080248
Validation loss: 2.478451596138989

Epoch: 6| Step: 13
Training loss: 1.9072496263366405
Validation loss: 2.474610961081664

Epoch: 140| Step: 0
Training loss: 2.4014386712876026
Validation loss: 2.4654392084625028

Epoch: 6| Step: 1
Training loss: 2.861160804621499
Validation loss: 2.493010870551285

Epoch: 6| Step: 2
Training loss: 2.609965274769791
Validation loss: 2.516721148948022

Epoch: 6| Step: 3
Training loss: 3.1651241828938796
Validation loss: 2.529637752901345

Epoch: 6| Step: 4
Training loss: 1.9545372701679198
Validation loss: 2.52994949777933

Epoch: 6| Step: 5
Training loss: 2.0856519639395876
Validation loss: 2.546186490848976

Epoch: 6| Step: 6
Training loss: 3.104358402620249
Validation loss: 2.5562196870726432

Epoch: 6| Step: 7
Training loss: 2.2167284715492666
Validation loss: 2.5833903044082773

Epoch: 6| Step: 8
Training loss: 2.730448841464438
Validation loss: 2.587913166674688

Epoch: 6| Step: 9
Training loss: 3.0680673558626226
Validation loss: 2.589225075851913

Epoch: 6| Step: 10
Training loss: 2.6525339499412293
Validation loss: 2.6165239928380224

Epoch: 6| Step: 11
Training loss: 2.2067486337303355
Validation loss: 2.6182069284695557

Epoch: 6| Step: 12
Training loss: 2.589866948779016
Validation loss: 2.6266212954922303

Epoch: 6| Step: 13
Training loss: 2.884209849877412
Validation loss: 2.607661413036091

Epoch: 141| Step: 0
Training loss: 2.481255161846951
Validation loss: 2.58061880923732

Epoch: 6| Step: 1
Training loss: 2.9318318974911377
Validation loss: 2.5604897774597624

Epoch: 6| Step: 2
Training loss: 2.813779751702124
Validation loss: 2.5690777899950685

Epoch: 6| Step: 3
Training loss: 2.9802021992333723
Validation loss: 2.5449169651453465

Epoch: 6| Step: 4
Training loss: 2.539234894988786
Validation loss: 2.5330333304457495

Epoch: 6| Step: 5
Training loss: 2.6321852301839503
Validation loss: 2.526981293597801

Epoch: 6| Step: 6
Training loss: 2.4964324291580677
Validation loss: 2.5280037343265804

Epoch: 6| Step: 7
Training loss: 2.6310703388411505
Validation loss: 2.531385480161049

Epoch: 6| Step: 8
Training loss: 2.5342485539775694
Validation loss: 2.5266813154437457

Epoch: 6| Step: 9
Training loss: 2.464961368033673
Validation loss: 2.5196969618424445

Epoch: 6| Step: 10
Training loss: 2.1441247551334723
Validation loss: 2.5127932019146146

Epoch: 6| Step: 11
Training loss: 2.5225386303003217
Validation loss: 2.509270309066336

Epoch: 6| Step: 12
Training loss: 2.4932829264103082
Validation loss: 2.501982972019076

Epoch: 6| Step: 13
Training loss: 2.07900271129202
Validation loss: 2.505277528886597

Epoch: 142| Step: 0
Training loss: 2.4447633169248206
Validation loss: 2.5211272333197288

Epoch: 6| Step: 1
Training loss: 3.0705825648063074
Validation loss: 2.5398677193423507

Epoch: 6| Step: 2
Training loss: 1.9236686214414396
Validation loss: 2.556765094842779

Epoch: 6| Step: 3
Training loss: 2.9367702470482353
Validation loss: 2.578736277454431

Epoch: 6| Step: 4
Training loss: 3.1797993708245635
Validation loss: 2.5843230014694485

Epoch: 6| Step: 5
Training loss: 2.5065899777686798
Validation loss: 2.5740171200380786

Epoch: 6| Step: 6
Training loss: 1.6945794977589141
Validation loss: 2.534461853579187

Epoch: 6| Step: 7
Training loss: 2.449235785271448
Validation loss: 2.511386080805285

Epoch: 6| Step: 8
Training loss: 2.430038377749204
Validation loss: 2.4929398365395423

Epoch: 6| Step: 9
Training loss: 2.9809862639972255
Validation loss: 2.4714323004868417

Epoch: 6| Step: 10
Training loss: 2.464283729931524
Validation loss: 2.464781681260418

Epoch: 6| Step: 11
Training loss: 2.847405065439312
Validation loss: 2.453960770899463

Epoch: 6| Step: 12
Training loss: 2.409559080065718
Validation loss: 2.4562143384535498

Epoch: 6| Step: 13
Training loss: 2.4119452911043138
Validation loss: 2.464237595523204

Epoch: 143| Step: 0
Training loss: 2.374186928759585
Validation loss: 2.4764989351299556

Epoch: 6| Step: 1
Training loss: 2.3728286454440086
Validation loss: 2.49911507664964

Epoch: 6| Step: 2
Training loss: 3.0665906717034015
Validation loss: 2.5157626667288118

Epoch: 6| Step: 3
Training loss: 1.956547660241287
Validation loss: 2.5336029215174176

Epoch: 6| Step: 4
Training loss: 2.270047206303793
Validation loss: 2.56065018759428

Epoch: 6| Step: 5
Training loss: 2.6477174033145876
Validation loss: 2.5830057421398243

Epoch: 6| Step: 6
Training loss: 2.3877441401257453
Validation loss: 2.5724781422088214

Epoch: 6| Step: 7
Training loss: 2.892348152203868
Validation loss: 2.5560265065963286

Epoch: 6| Step: 8
Training loss: 2.4511054406148998
Validation loss: 2.5372201116279256

Epoch: 6| Step: 9
Training loss: 2.5891249451735563
Validation loss: 2.5313746620268693

Epoch: 6| Step: 10
Training loss: 2.2528511632257158
Validation loss: 2.5405949236466387

Epoch: 6| Step: 11
Training loss: 3.0607328960897675
Validation loss: 2.543548074922381

Epoch: 6| Step: 12
Training loss: 2.4506502728763095
Validation loss: 2.5507473648057566

Epoch: 6| Step: 13
Training loss: 2.5238122809378756
Validation loss: 2.5489110467743124

Epoch: 144| Step: 0
Training loss: 1.901426999131474
Validation loss: 2.5737211678391323

Epoch: 6| Step: 1
Training loss: 2.69326722317313
Validation loss: 2.5869671341517737

Epoch: 6| Step: 2
Training loss: 2.688140260590565
Validation loss: 2.5988489334669898

Epoch: 6| Step: 3
Training loss: 2.4312483015275137
Validation loss: 2.629568011351675

Epoch: 6| Step: 4
Training loss: 2.5789045600226874
Validation loss: 2.631850779641815

Epoch: 6| Step: 5
Training loss: 2.7901580112244715
Validation loss: 2.6242333282388253

Epoch: 6| Step: 6
Training loss: 2.0243157207858298
Validation loss: 2.613217222976714

Epoch: 6| Step: 7
Training loss: 2.7556532925360098
Validation loss: 2.6165040481832764

Epoch: 6| Step: 8
Training loss: 2.7803922895104813
Validation loss: 2.614350202660216

Epoch: 6| Step: 9
Training loss: 2.7489901335682467
Validation loss: 2.596075111714218

Epoch: 6| Step: 10
Training loss: 2.851993893952541
Validation loss: 2.5733018951827082

Epoch: 6| Step: 11
Training loss: 2.261246653354545
Validation loss: 2.5496394875947272

Epoch: 6| Step: 12
Training loss: 1.9127525362320292
Validation loss: 2.542951485731648

Epoch: 6| Step: 13
Training loss: 2.6931271746864134
Validation loss: 2.53750770842883

Epoch: 145| Step: 0
Training loss: 2.790408624374772
Validation loss: 2.546587120166879

Epoch: 6| Step: 1
Training loss: 2.9025814734301436
Validation loss: 2.5323010602908522

Epoch: 6| Step: 2
Training loss: 3.1629410628388555
Validation loss: 2.542083042104144

Epoch: 6| Step: 3
Training loss: 2.2525116359397446
Validation loss: 2.548976178164219

Epoch: 6| Step: 4
Training loss: 2.8701359610967323
Validation loss: 2.5674015850287826

Epoch: 6| Step: 5
Training loss: 2.460634630730395
Validation loss: 2.5579623913383958

Epoch: 6| Step: 6
Training loss: 2.3596033655261937
Validation loss: 2.5489288570426734

Epoch: 6| Step: 7
Training loss: 2.1701438096732404
Validation loss: 2.5452743806312887

Epoch: 6| Step: 8
Training loss: 1.7212772169433834
Validation loss: 2.542875587089213

Epoch: 6| Step: 9
Training loss: 2.529497364007376
Validation loss: 2.515988439263693

Epoch: 6| Step: 10
Training loss: 2.2067378296378757
Validation loss: 2.5132136414668222

Epoch: 6| Step: 11
Training loss: 2.480942952642228
Validation loss: 2.498607781593609

Epoch: 6| Step: 12
Training loss: 2.3804453614215513
Validation loss: 2.51005108199765

Epoch: 6| Step: 13
Training loss: 2.525991181069003
Validation loss: 2.5064765163132634

Epoch: 146| Step: 0
Training loss: 2.216770417311826
Validation loss: 2.5221136932061787

Epoch: 6| Step: 1
Training loss: 2.9483348608219666
Validation loss: 2.5196083677088894

Epoch: 6| Step: 2
Training loss: 3.057609701863242
Validation loss: 2.4996181586104793

Epoch: 6| Step: 3
Training loss: 2.700003613363603
Validation loss: 2.4744538993577208

Epoch: 6| Step: 4
Training loss: 2.4595480250915887
Validation loss: 2.474094910837476

Epoch: 6| Step: 5
Training loss: 2.6488282582134333
Validation loss: 2.4604984650336847

Epoch: 6| Step: 6
Training loss: 2.154430561638475
Validation loss: 2.4583817980038534

Epoch: 6| Step: 7
Training loss: 2.296546653062725
Validation loss: 2.4643093918613337

Epoch: 6| Step: 8
Training loss: 2.6438075643274086
Validation loss: 2.501907429035236

Epoch: 6| Step: 9
Training loss: 2.009570825031522
Validation loss: 2.5171833351699497

Epoch: 6| Step: 10
Training loss: 2.1494925942605065
Validation loss: 2.5145620287377652

Epoch: 6| Step: 11
Training loss: 3.0511424379561136
Validation loss: 2.5224068732471268

Epoch: 6| Step: 12
Training loss: 2.4864014811755646
Validation loss: 2.5418685565276014

Epoch: 6| Step: 13
Training loss: 2.656951721849682
Validation loss: 2.5530840427127206

Epoch: 147| Step: 0
Training loss: 2.637199211144326
Validation loss: 2.5912082037383857

Epoch: 6| Step: 1
Training loss: 1.973956051894776
Validation loss: 2.612889892119236

Epoch: 6| Step: 2
Training loss: 2.8919557549665384
Validation loss: 2.637290852052582

Epoch: 6| Step: 3
Training loss: 1.776555081287418
Validation loss: 2.6285306437348352

Epoch: 6| Step: 4
Training loss: 2.593869769536848
Validation loss: 2.6122909286392764

Epoch: 6| Step: 5
Training loss: 2.6701533252825724
Validation loss: 2.5845623384282774

Epoch: 6| Step: 6
Training loss: 2.652658255671208
Validation loss: 2.546718774560517

Epoch: 6| Step: 7
Training loss: 1.800002188151407
Validation loss: 2.531566635010523

Epoch: 6| Step: 8
Training loss: 2.9140575910020647
Validation loss: 2.5294092317224552

Epoch: 6| Step: 9
Training loss: 2.373029795141724
Validation loss: 2.504445172578211

Epoch: 6| Step: 10
Training loss: 2.8014531520049406
Validation loss: 2.513778981408743

Epoch: 6| Step: 11
Training loss: 2.337495622273798
Validation loss: 2.537415902949534

Epoch: 6| Step: 12
Training loss: 2.607937353949758
Validation loss: 2.5528217110581095

Epoch: 6| Step: 13
Training loss: 2.4343705261737814
Validation loss: 2.585163364540623

Epoch: 148| Step: 0
Training loss: 2.4476815834524244
Validation loss: 2.6045043299810993

Epoch: 6| Step: 1
Training loss: 2.316661286748041
Validation loss: 2.6347836800224997

Epoch: 6| Step: 2
Training loss: 2.1186924614309337
Validation loss: 2.6547437476074403

Epoch: 6| Step: 3
Training loss: 2.389309589788844
Validation loss: 2.677971018365377

Epoch: 6| Step: 4
Training loss: 2.275253357246319
Validation loss: 2.7150987117201852

Epoch: 6| Step: 5
Training loss: 2.513970630738226
Validation loss: 2.7160282563593614

Epoch: 6| Step: 6
Training loss: 2.5974196247372534
Validation loss: 2.676836348980985

Epoch: 6| Step: 7
Training loss: 2.2912774420144277
Validation loss: 2.645368119639178

Epoch: 6| Step: 8
Training loss: 2.955058438776958
Validation loss: 2.6247079758102263

Epoch: 6| Step: 9
Training loss: 2.422882658002794
Validation loss: 2.5984195821010116

Epoch: 6| Step: 10
Training loss: 2.6673901490435092
Validation loss: 2.5918942170527504

Epoch: 6| Step: 11
Training loss: 2.8493822934173867
Validation loss: 2.5676243385641624

Epoch: 6| Step: 12
Training loss: 2.630235083919247
Validation loss: 2.541991948481618

Epoch: 6| Step: 13
Training loss: 2.4847313967168696
Validation loss: 2.518585119517778

Epoch: 149| Step: 0
Training loss: 2.4202260956877657
Validation loss: 2.5029013277404717

Epoch: 6| Step: 1
Training loss: 1.8708142288807148
Validation loss: 2.50942399282309

Epoch: 6| Step: 2
Training loss: 2.4277002972077804
Validation loss: 2.5098144454999036

Epoch: 6| Step: 3
Training loss: 2.8893236684891335
Validation loss: 2.5174532746975795

Epoch: 6| Step: 4
Training loss: 2.470720494627679
Validation loss: 2.5180013453265047

Epoch: 6| Step: 5
Training loss: 2.3263802358994634
Validation loss: 2.528848579218492

Epoch: 6| Step: 6
Training loss: 2.729248123312264
Validation loss: 2.517921643187816

Epoch: 6| Step: 7
Training loss: 2.754414050312531
Validation loss: 2.5039740099526075

Epoch: 6| Step: 8
Training loss: 2.2930652396648847
Validation loss: 2.5107592331655026

Epoch: 6| Step: 9
Training loss: 2.608282168763036
Validation loss: 2.502172234962099

Epoch: 6| Step: 10
Training loss: 1.631109636486841
Validation loss: 2.4976544621219943

Epoch: 6| Step: 11
Training loss: 2.7874681205808245
Validation loss: 2.4907423035042378

Epoch: 6| Step: 12
Training loss: 2.7072188407337032
Validation loss: 2.5054386355320233

Epoch: 6| Step: 13
Training loss: 2.6716335254437316
Validation loss: 2.528445972692036

Epoch: 150| Step: 0
Training loss: 2.8231465901749946
Validation loss: 2.5542506611869036

Epoch: 6| Step: 1
Training loss: 2.1456770485071788
Validation loss: 2.5947614383685935

Epoch: 6| Step: 2
Training loss: 1.727361571842424
Validation loss: 2.638182989810668

Epoch: 6| Step: 3
Training loss: 2.8441079721356446
Validation loss: 2.6455551881698844

Epoch: 6| Step: 4
Training loss: 2.744526531194794
Validation loss: 2.6543767086549837

Epoch: 6| Step: 5
Training loss: 2.788825016970545
Validation loss: 2.6539419986820585

Epoch: 6| Step: 6
Training loss: 2.8473487970600195
Validation loss: 2.6149291907246224

Epoch: 6| Step: 7
Training loss: 2.568437907247561
Validation loss: 2.5832116812551154

Epoch: 6| Step: 8
Training loss: 1.9595380554008042
Validation loss: 2.584744470589933

Epoch: 6| Step: 9
Training loss: 1.7352307931826045
Validation loss: 2.5430349983366893

Epoch: 6| Step: 10
Training loss: 3.0603485335280816
Validation loss: 2.5089007251997435

Epoch: 6| Step: 11
Training loss: 2.45290466096572
Validation loss: 2.494848458570689

Epoch: 6| Step: 12
Training loss: 2.39831741479712
Validation loss: 2.4795236665696723

Epoch: 6| Step: 13
Training loss: 1.8039600177614143
Validation loss: 2.47292594849526

Epoch: 151| Step: 0
Training loss: 2.3601044796591584
Validation loss: 2.480610509155925

Epoch: 6| Step: 1
Training loss: 2.3740316725870128
Validation loss: 2.516103668521528

Epoch: 6| Step: 2
Training loss: 1.656667188967975
Validation loss: 2.5411956968720295

Epoch: 6| Step: 3
Training loss: 2.470777331055841
Validation loss: 2.5761670326650696

Epoch: 6| Step: 4
Training loss: 2.300511809085151
Validation loss: 2.580349301931971

Epoch: 6| Step: 5
Training loss: 2.8839883034689824
Validation loss: 2.5771594494544496

Epoch: 6| Step: 6
Training loss: 1.9637636890577725
Validation loss: 2.5272198827534615

Epoch: 6| Step: 7
Training loss: 3.169057412067734
Validation loss: 2.511033297773702

Epoch: 6| Step: 8
Training loss: 2.346905631158812
Validation loss: 2.49186502991524

Epoch: 6| Step: 9
Training loss: 2.288473737076326
Validation loss: 2.477632548587795

Epoch: 6| Step: 10
Training loss: 2.6825805706001136
Validation loss: 2.47458644248684

Epoch: 6| Step: 11
Training loss: 2.4686669444345757
Validation loss: 2.47664745316181

Epoch: 6| Step: 12
Training loss: 2.4160383218795447
Validation loss: 2.494970876586347

Epoch: 6| Step: 13
Training loss: 2.6058563447413428
Validation loss: 2.504795449683646

Epoch: 152| Step: 0
Training loss: 3.1371820661093244
Validation loss: 2.5175112505533885

Epoch: 6| Step: 1
Training loss: 2.731828299258286
Validation loss: 2.533952693876193

Epoch: 6| Step: 2
Training loss: 1.1838839335740408
Validation loss: 2.5460624382549675

Epoch: 6| Step: 3
Training loss: 2.12536045831979
Validation loss: 2.562464268853208

Epoch: 6| Step: 4
Training loss: 2.285930378525358
Validation loss: 2.5729044451918797

Epoch: 6| Step: 5
Training loss: 2.043935514190561
Validation loss: 2.561917358557726

Epoch: 6| Step: 6
Training loss: 1.8809639494633883
Validation loss: 2.5493525977127445

Epoch: 6| Step: 7
Training loss: 2.4174822932702416
Validation loss: 2.5451173014835797

Epoch: 6| Step: 8
Training loss: 2.2496240089763213
Validation loss: 2.543494993345419

Epoch: 6| Step: 9
Training loss: 2.8191664631259297
Validation loss: 2.560701016381403

Epoch: 6| Step: 10
Training loss: 2.575735846256118
Validation loss: 2.5694898589323363

Epoch: 6| Step: 11
Training loss: 2.77946020250947
Validation loss: 2.570869758172274

Epoch: 6| Step: 12
Training loss: 2.5624305901780016
Validation loss: 2.5808534704114776

Epoch: 6| Step: 13
Training loss: 2.394046603718814
Validation loss: 2.5819642388376143

Epoch: 153| Step: 0
Training loss: 2.7444876997761187
Validation loss: 2.59910651694961

Epoch: 6| Step: 1
Training loss: 2.1427800823161145
Validation loss: 2.6094186813690112

Epoch: 6| Step: 2
Training loss: 2.2739391494433385
Validation loss: 2.612534706861379

Epoch: 6| Step: 3
Training loss: 2.866601203200563
Validation loss: 2.6129834530438334

Epoch: 6| Step: 4
Training loss: 2.432455467137965
Validation loss: 2.6298401777882323

Epoch: 6| Step: 5
Training loss: 2.0671749884471144
Validation loss: 2.6076289836818

Epoch: 6| Step: 6
Training loss: 2.610119376540092
Validation loss: 2.571427566542285

Epoch: 6| Step: 7
Training loss: 1.7649960368168671
Validation loss: 2.55742279539248

Epoch: 6| Step: 8
Training loss: 2.2827539581374805
Validation loss: 2.5482206168858585

Epoch: 6| Step: 9
Training loss: 1.9276512615061698
Validation loss: 2.541294688643999

Epoch: 6| Step: 10
Training loss: 2.9568832138679575
Validation loss: 2.5338591114477325

Epoch: 6| Step: 11
Training loss: 2.6423144832801877
Validation loss: 2.5143581592322444

Epoch: 6| Step: 12
Training loss: 2.2617153767246
Validation loss: 2.518577623770429

Epoch: 6| Step: 13
Training loss: 2.715052754432331
Validation loss: 2.5275288966832843

Epoch: 154| Step: 0
Training loss: 1.7202420780690793
Validation loss: 2.5349996694656958

Epoch: 6| Step: 1
Training loss: 2.1561565655353783
Validation loss: 2.547769546061278

Epoch: 6| Step: 2
Training loss: 2.070464851963576
Validation loss: 2.572226448504183

Epoch: 6| Step: 3
Training loss: 2.2302669293543933
Validation loss: 2.5711517365235586

Epoch: 6| Step: 4
Training loss: 2.391535566859442
Validation loss: 2.558798330582671

Epoch: 6| Step: 5
Training loss: 3.0800663591642743
Validation loss: 2.549149600302406

Epoch: 6| Step: 6
Training loss: 1.7747494050554373
Validation loss: 2.5523359430260637

Epoch: 6| Step: 7
Training loss: 2.4261270912322956
Validation loss: 2.5471821543200996

Epoch: 6| Step: 8
Training loss: 2.410090366742853
Validation loss: 2.563519353881519

Epoch: 6| Step: 9
Training loss: 2.6649964784523776
Validation loss: 2.568736920274673

Epoch: 6| Step: 10
Training loss: 2.6134794014702276
Validation loss: 2.558801944406055

Epoch: 6| Step: 11
Training loss: 2.023301992702601
Validation loss: 2.5756983250061265

Epoch: 6| Step: 12
Training loss: 2.8963546466649785
Validation loss: 2.599620116273817

Epoch: 6| Step: 13
Training loss: 2.3398038067855276
Validation loss: 2.6126185209780917

Epoch: 155| Step: 0
Training loss: 1.4951434192312236
Validation loss: 2.607716050267226

Epoch: 6| Step: 1
Training loss: 2.012549604669381
Validation loss: 2.5966629225049283

Epoch: 6| Step: 2
Training loss: 2.039517523613361
Validation loss: 2.6102966779390506

Epoch: 6| Step: 3
Training loss: 2.2632676060627106
Validation loss: 2.607080184045239

Epoch: 6| Step: 4
Training loss: 2.826526506235896
Validation loss: 2.6195217810574594

Epoch: 6| Step: 5
Training loss: 2.021914229093507
Validation loss: 2.629935743269908

Epoch: 6| Step: 6
Training loss: 3.508758621232409
Validation loss: 2.638318681738489

Epoch: 6| Step: 7
Training loss: 1.8627783778507854
Validation loss: 2.623710348729393

Epoch: 6| Step: 8
Training loss: 1.9130798308590005
Validation loss: 2.6207174730358043

Epoch: 6| Step: 9
Training loss: 2.4688243613331053
Validation loss: 2.633250738052935

Epoch: 6| Step: 10
Training loss: 2.961962680939584
Validation loss: 2.6069845512098517

Epoch: 6| Step: 11
Training loss: 2.0382085305427045
Validation loss: 2.601639379629016

Epoch: 6| Step: 12
Training loss: 2.7256130543818573
Validation loss: 2.595604064992411

Epoch: 6| Step: 13
Training loss: 1.7207184356805
Validation loss: 2.574900078161407

Epoch: 156| Step: 0
Training loss: 2.5041910327946724
Validation loss: 2.5394108419580435

Epoch: 6| Step: 1
Training loss: 2.0591463509080667
Validation loss: 2.5493461960259824

Epoch: 6| Step: 2
Training loss: 2.2308744739628676
Validation loss: 2.5604928272062577

Epoch: 6| Step: 3
Training loss: 2.5511371545352084
Validation loss: 2.5622847932156265

Epoch: 6| Step: 4
Training loss: 2.548009701577106
Validation loss: 2.5724763683232323

Epoch: 6| Step: 5
Training loss: 1.8151884857543878
Validation loss: 2.5810654424224357

Epoch: 6| Step: 6
Training loss: 1.3625521746103748
Validation loss: 2.556495639016531

Epoch: 6| Step: 7
Training loss: 3.2586633682588073
Validation loss: 2.574811521570123

Epoch: 6| Step: 8
Training loss: 2.323160600612668
Validation loss: 2.5767560141408907

Epoch: 6| Step: 9
Training loss: 2.277721759706908
Validation loss: 2.5708577888960855

Epoch: 6| Step: 10
Training loss: 2.6968011697893934
Validation loss: 2.5548409834236674

Epoch: 6| Step: 11
Training loss: 2.109003104875503
Validation loss: 2.556058818360105

Epoch: 6| Step: 12
Training loss: 2.2669402415539883
Validation loss: 2.553714326624789

Epoch: 6| Step: 13
Training loss: 1.6395685336629753
Validation loss: 2.5581515152556653

Epoch: 157| Step: 0
Training loss: 2.0600735812332567
Validation loss: 2.5447557335124444

Epoch: 6| Step: 1
Training loss: 2.194507383364123
Validation loss: 2.5387645986517593

Epoch: 6| Step: 2
Training loss: 2.318327494581244
Validation loss: 2.569811272444215

Epoch: 6| Step: 3
Training loss: 2.809330574337848
Validation loss: 2.612715999809596

Epoch: 6| Step: 4
Training loss: 2.955065216016087
Validation loss: 2.628186646790355

Epoch: 6| Step: 5
Training loss: 1.8109959906413091
Validation loss: 2.6146935825090885

Epoch: 6| Step: 6
Training loss: 1.9869119241984772
Validation loss: 2.5753710762835214

Epoch: 6| Step: 7
Training loss: 2.1014713990840352
Validation loss: 2.5477164281665883

Epoch: 6| Step: 8
Training loss: 1.9558747123542028
Validation loss: 2.514215511557636

Epoch: 6| Step: 9
Training loss: 2.480626186871311
Validation loss: 2.501249230941104

Epoch: 6| Step: 10
Training loss: 2.117267677506293
Validation loss: 2.483099506502801

Epoch: 6| Step: 11
Training loss: 2.1244102108341703
Validation loss: 2.4778545064888675

Epoch: 6| Step: 12
Training loss: 2.919435839565222
Validation loss: 2.4821915889593833

Epoch: 6| Step: 13
Training loss: 1.7471555344685674
Validation loss: 2.487896804214928

Epoch: 158| Step: 0
Training loss: 1.7293552234595588
Validation loss: 2.490242091952517

Epoch: 6| Step: 1
Training loss: 2.859965279108311
Validation loss: 2.49582637731319

Epoch: 6| Step: 2
Training loss: 1.8625769733678044
Validation loss: 2.5278867301943126

Epoch: 6| Step: 3
Training loss: 2.50352991760431
Validation loss: 2.5242673778643367

Epoch: 6| Step: 4
Training loss: 1.817647661510014
Validation loss: 2.5286102142027005

Epoch: 6| Step: 5
Training loss: 2.0074564696042496
Validation loss: 2.511642690423104

Epoch: 6| Step: 6
Training loss: 2.3142895346985086
Validation loss: 2.5263316465138588

Epoch: 6| Step: 7
Training loss: 1.4856959839626327
Validation loss: 2.5468002359698096

Epoch: 6| Step: 8
Training loss: 2.7555050801282417
Validation loss: 2.5531330821790394

Epoch: 6| Step: 9
Training loss: 2.305687535452043
Validation loss: 2.577203459499074

Epoch: 6| Step: 10
Training loss: 2.6015905430287565
Validation loss: 2.596555499965372

Epoch: 6| Step: 11
Training loss: 2.1065579288321588
Validation loss: 2.5982438816731235

Epoch: 6| Step: 12
Training loss: 2.5754533276069838
Validation loss: 2.641746062158347

Epoch: 6| Step: 13
Training loss: 2.3007556544695236
Validation loss: 2.607005486173324

Epoch: 159| Step: 0
Training loss: 2.73330144243322
Validation loss: 2.5664473213638734

Epoch: 6| Step: 1
Training loss: 2.6622651153258583
Validation loss: 2.5449891956668216

Epoch: 6| Step: 2
Training loss: 2.5325305666495725
Validation loss: 2.5110959690574104

Epoch: 6| Step: 3
Training loss: 2.5011621634994676
Validation loss: 2.4971194191881576

Epoch: 6| Step: 4
Training loss: 2.028999020376481
Validation loss: 2.478028727458861

Epoch: 6| Step: 5
Training loss: 1.6236300929714533
Validation loss: 2.4717189049793333

Epoch: 6| Step: 6
Training loss: 1.8059893779759106
Validation loss: 2.4798654171499015

Epoch: 6| Step: 7
Training loss: 2.2584077782929723
Validation loss: 2.486632751621313

Epoch: 6| Step: 8
Training loss: 2.269368623825945
Validation loss: 2.522935500469728

Epoch: 6| Step: 9
Training loss: 2.234586478942482
Validation loss: 2.5595887857636646

Epoch: 6| Step: 10
Training loss: 2.57351846388083
Validation loss: 2.6103431939655906

Epoch: 6| Step: 11
Training loss: 2.4867572998356984
Validation loss: 2.54495798440327

Epoch: 6| Step: 12
Training loss: 2.2049315060035295
Validation loss: 2.541402874360952

Epoch: 6| Step: 13
Training loss: 1.5520848865202572
Validation loss: 2.5625932047751183

Epoch: 160| Step: 0
Training loss: 2.0540380575634294
Validation loss: 2.595996182095005

Epoch: 6| Step: 1
Training loss: 2.0190325182052695
Validation loss: 2.648489863937094

Epoch: 6| Step: 2
Training loss: 2.7051349730319476
Validation loss: 2.6632104986646468

Epoch: 6| Step: 3
Training loss: 2.4836609012036988
Validation loss: 2.6762845594684648

Epoch: 6| Step: 4
Training loss: 2.0113367403149263
Validation loss: 2.671205404223772

Epoch: 6| Step: 5
Training loss: 1.9886247679136992
Validation loss: 2.6151528562831095

Epoch: 6| Step: 6
Training loss: 2.317111494961826
Validation loss: 2.5854046668604584

Epoch: 6| Step: 7
Training loss: 2.37397894745051
Validation loss: 2.5524747870161

Epoch: 6| Step: 8
Training loss: 2.6362719347978656
Validation loss: 2.495080766752591

Epoch: 6| Step: 9
Training loss: 2.2321062640869105
Validation loss: 2.4841744307188187

Epoch: 6| Step: 10
Training loss: 2.5481232936498803
Validation loss: 2.4692409116077667

Epoch: 6| Step: 11
Training loss: 2.2333091914831638
Validation loss: 2.467534661359869

Epoch: 6| Step: 12
Training loss: 2.165438328303654
Validation loss: 2.482103998644142

Epoch: 6| Step: 13
Training loss: 2.380593489210277
Validation loss: 2.481320593739356

Epoch: 161| Step: 0
Training loss: 2.1362071985339717
Validation loss: 2.5359570889668577

Epoch: 6| Step: 1
Training loss: 1.982036143391981
Validation loss: 2.5262063702921265

Epoch: 6| Step: 2
Training loss: 1.6653728072316571
Validation loss: 2.5561505836080918

Epoch: 6| Step: 3
Training loss: 2.044945309567548
Validation loss: 2.588604861401052

Epoch: 6| Step: 4
Training loss: 2.0428428246399335
Validation loss: 2.6200468588628323

Epoch: 6| Step: 5
Training loss: 2.2626657035382
Validation loss: 2.665772598370186

Epoch: 6| Step: 6
Training loss: 2.645034809712773
Validation loss: 2.7017647201768096

Epoch: 6| Step: 7
Training loss: 2.785059944617186
Validation loss: 2.684276798087089

Epoch: 6| Step: 8
Training loss: 1.7569149184060047
Validation loss: 2.644996702318276

Epoch: 6| Step: 9
Training loss: 1.9152614653054576
Validation loss: 2.6199947576839073

Epoch: 6| Step: 10
Training loss: 2.27761258195645
Validation loss: 2.6049763732878577

Epoch: 6| Step: 11
Training loss: 2.912391981487555
Validation loss: 2.561495940644095

Epoch: 6| Step: 12
Training loss: 2.2725310206210736
Validation loss: 2.556083733925356

Epoch: 6| Step: 13
Training loss: 2.1099536243422508
Validation loss: 2.52586526071872

Epoch: 162| Step: 0
Training loss: 2.515299047357578
Validation loss: 2.498497840826681

Epoch: 6| Step: 1
Training loss: 1.816140957399049
Validation loss: 2.4721364670516657

Epoch: 6| Step: 2
Training loss: 2.3524118708157453
Validation loss: 2.4994137804744327

Epoch: 6| Step: 3
Training loss: 2.3164321872230427
Validation loss: 2.4834658971045322

Epoch: 6| Step: 4
Training loss: 2.730984225752429
Validation loss: 2.5016763481256734

Epoch: 6| Step: 5
Training loss: 2.248595329084247
Validation loss: 2.527476925078442

Epoch: 6| Step: 6
Training loss: 1.9678034247676321
Validation loss: 2.542399653934612

Epoch: 6| Step: 7
Training loss: 2.1371287731809607
Validation loss: 2.556653271500025

Epoch: 6| Step: 8
Training loss: 2.0438206138427617
Validation loss: 2.58517533154518

Epoch: 6| Step: 9
Training loss: 1.896590036420789
Validation loss: 2.607493874400473

Epoch: 6| Step: 10
Training loss: 2.3387699369786747
Validation loss: 2.6163565053368405

Epoch: 6| Step: 11
Training loss: 2.6776885203324463
Validation loss: 2.610214209467468

Epoch: 6| Step: 12
Training loss: 2.1966511727666034
Validation loss: 2.567553097277851

Epoch: 6| Step: 13
Training loss: 1.5447328936593847
Validation loss: 2.55341902572453

Epoch: 163| Step: 0
Training loss: 2.388198618509142
Validation loss: 2.510899052470209

Epoch: 6| Step: 1
Training loss: 1.744773485079496
Validation loss: 2.5272294836318308

Epoch: 6| Step: 2
Training loss: 1.6244231447289539
Validation loss: 2.5148822144112946

Epoch: 6| Step: 3
Training loss: 2.255499899490209
Validation loss: 2.5246390664382603

Epoch: 6| Step: 4
Training loss: 1.8517852520446159
Validation loss: 2.536750805063512

Epoch: 6| Step: 5
Training loss: 2.418691302235371
Validation loss: 2.547978485054837

Epoch: 6| Step: 6
Training loss: 2.289127075534326
Validation loss: 2.5471969844863414

Epoch: 6| Step: 7
Training loss: 2.163036116807749
Validation loss: 2.547507333334454

Epoch: 6| Step: 8
Training loss: 2.1206028266554746
Validation loss: 2.5634374476982553

Epoch: 6| Step: 9
Training loss: 2.2261991505542507
Validation loss: 2.5667665440027387

Epoch: 6| Step: 10
Training loss: 2.2303500970656955
Validation loss: 2.571652073782246

Epoch: 6| Step: 11
Training loss: 2.325452871208827
Validation loss: 2.553802524606515

Epoch: 6| Step: 12
Training loss: 2.18132127355741
Validation loss: 2.5592946560168572

Epoch: 6| Step: 13
Training loss: 2.4311993669665344
Validation loss: 2.574796526864659

Epoch: 164| Step: 0
Training loss: 2.4834278148454105
Validation loss: 2.6143330283162727

Epoch: 6| Step: 1
Training loss: 2.730150021353977
Validation loss: 2.621954180708275

Epoch: 6| Step: 2
Training loss: 1.9122924093639897
Validation loss: 2.578340514302748

Epoch: 6| Step: 3
Training loss: 2.2056547750623556
Validation loss: 2.551422096428863

Epoch: 6| Step: 4
Training loss: 2.516678299361201
Validation loss: 2.5511309432336993

Epoch: 6| Step: 5
Training loss: 2.175951528135544
Validation loss: 2.5158654002991416

Epoch: 6| Step: 6
Training loss: 2.1359230247514946
Validation loss: 2.513343588235632

Epoch: 6| Step: 7
Training loss: 1.6683997997619464
Validation loss: 2.5161912357641514

Epoch: 6| Step: 8
Training loss: 1.6958467547036327
Validation loss: 2.5210297092013993

Epoch: 6| Step: 9
Training loss: 2.0443956341076803
Validation loss: 2.525457936415574

Epoch: 6| Step: 10
Training loss: 1.672184710470891
Validation loss: 2.5354824268724747

Epoch: 6| Step: 11
Training loss: 2.432632868902688
Validation loss: 2.527162501414518

Epoch: 6| Step: 12
Training loss: 2.245973374831425
Validation loss: 2.53852493287552

Epoch: 6| Step: 13
Training loss: 1.5037842540058148
Validation loss: 2.546757597022567

Epoch: 165| Step: 0
Training loss: 1.806296155927228
Validation loss: 2.5709527328520307

Epoch: 6| Step: 1
Training loss: 1.1970590036648172
Validation loss: 2.603002807103411

Epoch: 6| Step: 2
Training loss: 2.5366915387385043
Validation loss: 2.623543673741093

Epoch: 6| Step: 3
Training loss: 1.7214126769340006
Validation loss: 2.628544207380523

Epoch: 6| Step: 4
Training loss: 2.5863048834160463
Validation loss: 2.6359757966748796

Epoch: 6| Step: 5
Training loss: 1.914901487241854
Validation loss: 2.635750170955502

Epoch: 6| Step: 6
Training loss: 1.9664712463961511
Validation loss: 2.6502231786792807

Epoch: 6| Step: 7
Training loss: 2.3627155225831817
Validation loss: 2.645484748907898

Epoch: 6| Step: 8
Training loss: 2.0465852954647525
Validation loss: 2.651432859398025

Epoch: 6| Step: 9
Training loss: 1.9459366007922712
Validation loss: 2.6517660525022952

Epoch: 6| Step: 10
Training loss: 2.323963003753752
Validation loss: 2.632343945662037

Epoch: 6| Step: 11
Training loss: 2.3480673127021867
Validation loss: 2.636886267344497

Epoch: 6| Step: 12
Training loss: 2.321507618155664
Validation loss: 2.624358800578372

Epoch: 6| Step: 13
Training loss: 1.5105113646538424
Validation loss: 2.5991790780982975

Epoch: 166| Step: 0
Training loss: 2.1189748954131944
Validation loss: 2.58048169115966

Epoch: 6| Step: 1
Training loss: 2.214115514234968
Validation loss: 2.5945149724448933

Epoch: 6| Step: 2
Training loss: 1.5446969313413665
Validation loss: 2.5904876834487847

Epoch: 6| Step: 3
Training loss: 2.2140192451639944
Validation loss: 2.581682215087788

Epoch: 6| Step: 4
Training loss: 1.8448377730217094
Validation loss: 2.5729249490185544

Epoch: 6| Step: 5
Training loss: 1.7646901179058314
Validation loss: 2.5672650896385454

Epoch: 6| Step: 6
Training loss: 2.8227721924545
Validation loss: 2.543889914301461

Epoch: 6| Step: 7
Training loss: 2.0251018498556608
Validation loss: 2.562286521128892

Epoch: 6| Step: 8
Training loss: 2.0492406089858863
Validation loss: 2.55164827544073

Epoch: 6| Step: 9
Training loss: 1.9449083145811978
Validation loss: 2.5487980812334765

Epoch: 6| Step: 10
Training loss: 1.9874114586643283
Validation loss: 2.5596776401587578

Epoch: 6| Step: 11
Training loss: 2.094781308470209
Validation loss: 2.5580311416926795

Epoch: 6| Step: 12
Training loss: 2.366003565059243
Validation loss: 2.551632433284342

Epoch: 6| Step: 13
Training loss: 2.1734972048141024
Validation loss: 2.541123818562355

Epoch: 167| Step: 0
Training loss: 2.2883902854898603
Validation loss: 2.545498370538912

Epoch: 6| Step: 1
Training loss: 2.3854607546090096
Validation loss: 2.538911845215767

Epoch: 6| Step: 2
Training loss: 2.1586666110068005
Validation loss: 2.5454483057536788

Epoch: 6| Step: 3
Training loss: 1.7523647407434417
Validation loss: 2.5496324189802277

Epoch: 6| Step: 4
Training loss: 1.7301546591054913
Validation loss: 2.5219928397213893

Epoch: 6| Step: 5
Training loss: 2.1170809673237794
Validation loss: 2.5368318104429424

Epoch: 6| Step: 6
Training loss: 2.1395534980077975
Validation loss: 2.532701824158588

Epoch: 6| Step: 7
Training loss: 2.1267179388883135
Validation loss: 2.5447235109443627

Epoch: 6| Step: 8
Training loss: 1.8713006719482532
Validation loss: 2.5402120098668455

Epoch: 6| Step: 9
Training loss: 2.5160584639047285
Validation loss: 2.5467239587747956

Epoch: 6| Step: 10
Training loss: 1.3043460970328107
Validation loss: 2.540386957712642

Epoch: 6| Step: 11
Training loss: 2.039024264974676
Validation loss: 2.54776092266068

Epoch: 6| Step: 12
Training loss: 2.3613644732003927
Validation loss: 2.539729360593159

Epoch: 6| Step: 13
Training loss: 1.9229661278719579
Validation loss: 2.584553828860181

Epoch: 168| Step: 0
Training loss: 2.36608437999872
Validation loss: 2.5847567246851946

Epoch: 6| Step: 1
Training loss: 2.0983188939323654
Validation loss: 2.6136952197446948

Epoch: 6| Step: 2
Training loss: 1.5914353410611575
Validation loss: 2.642463195730284

Epoch: 6| Step: 3
Training loss: 2.4077966846736336
Validation loss: 2.666512644136971

Epoch: 6| Step: 4
Training loss: 1.8243097776781911
Validation loss: 2.679604915954898

Epoch: 6| Step: 5
Training loss: 2.1663693688682466
Validation loss: 2.6928783904219706

Epoch: 6| Step: 6
Training loss: 2.258155031191938
Validation loss: 2.695895549528359

Epoch: 6| Step: 7
Training loss: 2.1808103451691254
Validation loss: 2.6835732816359887

Epoch: 6| Step: 8
Training loss: 1.9794008283793958
Validation loss: 2.6798224956732493

Epoch: 6| Step: 9
Training loss: 1.7900840807725629
Validation loss: 2.6501191596329856

Epoch: 6| Step: 10
Training loss: 1.503514543524512
Validation loss: 2.633121320830382

Epoch: 6| Step: 11
Training loss: 2.3726990244667707
Validation loss: 2.640442732876983

Epoch: 6| Step: 12
Training loss: 2.0222281004688685
Validation loss: 2.612606906347181

Epoch: 6| Step: 13
Training loss: 1.9184667869080982
Validation loss: 2.58762447673438

Epoch: 169| Step: 0
Training loss: 1.9843130026917042
Validation loss: 2.569165602252567

Epoch: 6| Step: 1
Training loss: 1.7128559661455771
Validation loss: 2.5571561347667062

Epoch: 6| Step: 2
Training loss: 2.516154452697187
Validation loss: 2.540076532182262

Epoch: 6| Step: 3
Training loss: 1.4435048939774218
Validation loss: 2.527523571668986

Epoch: 6| Step: 4
Training loss: 2.41547300741456
Validation loss: 2.547216116128742

Epoch: 6| Step: 5
Training loss: 2.2888926159829386
Validation loss: 2.5528042452906154

Epoch: 6| Step: 6
Training loss: 1.7613704362441556
Validation loss: 2.5569646141785154

Epoch: 6| Step: 7
Training loss: 2.0259005016059466
Validation loss: 2.601644782540395

Epoch: 6| Step: 8
Training loss: 2.1231942077442723
Validation loss: 2.602321192017141

Epoch: 6| Step: 9
Training loss: 2.1070821097533035
Validation loss: 2.593618535647552

Epoch: 6| Step: 10
Training loss: 2.0294667559276567
Validation loss: 2.599803636091501

Epoch: 6| Step: 11
Training loss: 2.337498784192427
Validation loss: 2.6127170035941125

Epoch: 6| Step: 12
Training loss: 1.728681825740288
Validation loss: 2.5946368211061417

Epoch: 6| Step: 13
Training loss: 1.7307379450782523
Validation loss: 2.60473550174688

Epoch: 170| Step: 0
Training loss: 2.5308368486973083
Validation loss: 2.6205270417215374

Epoch: 6| Step: 1
Training loss: 1.1718381240129012
Validation loss: 2.631339686229798

Epoch: 6| Step: 2
Training loss: 2.499430496198758
Validation loss: 2.653598901921613

Epoch: 6| Step: 3
Training loss: 1.7256454863363273
Validation loss: 2.643001347064227

Epoch: 6| Step: 4
Training loss: 1.7227718115557737
Validation loss: 2.657411786201256

Epoch: 6| Step: 5
Training loss: 1.370497701693768
Validation loss: 2.647428096066836

Epoch: 6| Step: 6
Training loss: 2.421663435032214
Validation loss: 2.6498064791228666

Epoch: 6| Step: 7
Training loss: 2.6309253483283332
Validation loss: 2.6268226450540233

Epoch: 6| Step: 8
Training loss: 1.7379191846637994
Validation loss: 2.625147028729993

Epoch: 6| Step: 9
Training loss: 1.7408677649239106
Validation loss: 2.6056019236918355

Epoch: 6| Step: 10
Training loss: 2.650620362705671
Validation loss: 2.6162179918333446

Epoch: 6| Step: 11
Training loss: 1.4786979935724092
Validation loss: 2.5909681409628496

Epoch: 6| Step: 12
Training loss: 2.045699619292394
Validation loss: 2.570191594804252

Epoch: 6| Step: 13
Training loss: 1.9490794894634103
Validation loss: 2.563052140204458

Epoch: 171| Step: 0
Training loss: 2.289552395316263
Validation loss: 2.549880076264081

Epoch: 6| Step: 1
Training loss: 2.3470805600045703
Validation loss: 2.545124902895567

Epoch: 6| Step: 2
Training loss: 1.8820148218688095
Validation loss: 2.546143650821435

Epoch: 6| Step: 3
Training loss: 1.8090707631860616
Validation loss: 2.541734023456588

Epoch: 6| Step: 4
Training loss: 1.7493877020916817
Validation loss: 2.5323694615589827

Epoch: 6| Step: 5
Training loss: 1.9833874986235154
Validation loss: 2.529436434811536

Epoch: 6| Step: 6
Training loss: 1.9062101641385485
Validation loss: 2.539805568255242

Epoch: 6| Step: 7
Training loss: 0.8756694616864393
Validation loss: 2.535672738632068

Epoch: 6| Step: 8
Training loss: 2.5082223147371256
Validation loss: 2.532750788609184

Epoch: 6| Step: 9
Training loss: 1.8293693415714252
Validation loss: 2.552712373305805

Epoch: 6| Step: 10
Training loss: 1.6940153582708797
Validation loss: 2.5824696148531796

Epoch: 6| Step: 11
Training loss: 2.4642841169300786
Validation loss: 2.611561026117114

Epoch: 6| Step: 12
Training loss: 2.4431200039808356
Validation loss: 2.6228113244981075

Epoch: 6| Step: 13
Training loss: 1.8573341389020135
Validation loss: 2.6209028139110218

Epoch: 172| Step: 0
Training loss: 1.9847967345471103
Validation loss: 2.59893578618568

Epoch: 6| Step: 1
Training loss: 2.9162376814940547
Validation loss: 2.5877933493047247

Epoch: 6| Step: 2
Training loss: 2.0113193152451996
Validation loss: 2.576472104877073

Epoch: 6| Step: 3
Training loss: 1.7436004519852966
Validation loss: 2.586108050986291

Epoch: 6| Step: 4
Training loss: 1.7519546219597144
Validation loss: 2.607393658715653

Epoch: 6| Step: 5
Training loss: 1.724529052799336
Validation loss: 2.5953824801326206

Epoch: 6| Step: 6
Training loss: 1.6856004832418696
Validation loss: 2.5858075429869336

Epoch: 6| Step: 7
Training loss: 1.6690845911292125
Validation loss: 2.5558042754275423

Epoch: 6| Step: 8
Training loss: 1.708018700383393
Validation loss: 2.508714840371275

Epoch: 6| Step: 9
Training loss: 2.241876773370914
Validation loss: 2.5020812098370886

Epoch: 6| Step: 10
Training loss: 2.356692070812833
Validation loss: 2.4929067076887685

Epoch: 6| Step: 11
Training loss: 1.761338694107788
Validation loss: 2.4893799462436537

Epoch: 6| Step: 12
Training loss: 2.0622400062144077
Validation loss: 2.4923302054787078

Epoch: 6| Step: 13
Training loss: 1.6214474947012993
Validation loss: 2.4895362459963355

Epoch: 173| Step: 0
Training loss: 1.5546370454968585
Validation loss: 2.518673161324668

Epoch: 6| Step: 1
Training loss: 1.82075632603196
Validation loss: 2.5312263470446883

Epoch: 6| Step: 2
Training loss: 2.0370341183741045
Validation loss: 2.5449081195256853

Epoch: 6| Step: 3
Training loss: 2.362222733954614
Validation loss: 2.545600893015706

Epoch: 6| Step: 4
Training loss: 1.6179128301029595
Validation loss: 2.56025226053538

Epoch: 6| Step: 5
Training loss: 2.283257110975581
Validation loss: 2.5728450441515447

Epoch: 6| Step: 6
Training loss: 2.2747174097970047
Validation loss: 2.596946849514902

Epoch: 6| Step: 7
Training loss: 1.908839109048266
Validation loss: 2.593445417161231

Epoch: 6| Step: 8
Training loss: 2.3713037941420643
Validation loss: 2.597121739914638

Epoch: 6| Step: 9
Training loss: 1.8595560450527924
Validation loss: 2.603961136777706

Epoch: 6| Step: 10
Training loss: 1.7986467996965367
Validation loss: 2.598484745254315

Epoch: 6| Step: 11
Training loss: 1.3585934200801963
Validation loss: 2.5828259936141897

Epoch: 6| Step: 12
Training loss: 2.213745706167424
Validation loss: 2.587662826669192

Epoch: 6| Step: 13
Training loss: 1.224209222713905
Validation loss: 2.566104551714823

Epoch: 174| Step: 0
Training loss: 2.1993392992604583
Validation loss: 2.568746014180684

Epoch: 6| Step: 1
Training loss: 1.6086763513597357
Validation loss: 2.5736518424970787

Epoch: 6| Step: 2
Training loss: 1.8513603261029095
Validation loss: 2.5791381893474057

Epoch: 6| Step: 3
Training loss: 2.477066325735402
Validation loss: 2.590001527739718

Epoch: 6| Step: 4
Training loss: 1.6995507628448319
Validation loss: 2.6009878001542726

Epoch: 6| Step: 5
Training loss: 2.0670814492723855
Validation loss: 2.606011621088817

Epoch: 6| Step: 6
Training loss: 1.8934091292687747
Validation loss: 2.607013279337465

Epoch: 6| Step: 7
Training loss: 1.7841080607885837
Validation loss: 2.5941506274203

Epoch: 6| Step: 8
Training loss: 2.0047041882647645
Validation loss: 2.6033038994464444

Epoch: 6| Step: 9
Training loss: 1.6044065948335573
Validation loss: 2.613479260216288

Epoch: 6| Step: 10
Training loss: 2.1818058562653078
Validation loss: 2.6012190483959197

Epoch: 6| Step: 11
Training loss: 1.951414961846214
Validation loss: 2.6003964541914564

Epoch: 6| Step: 12
Training loss: 1.7840877482127255
Validation loss: 2.5821886222392245

Epoch: 6| Step: 13
Training loss: 1.6723059695927862
Validation loss: 2.5756502158288366

Epoch: 175| Step: 0
Training loss: 2.072035392893441
Validation loss: 2.577259670998438

Epoch: 6| Step: 1
Training loss: 1.506370368675005
Validation loss: 2.571495866175735

Epoch: 6| Step: 2
Training loss: 1.8194035565131328
Validation loss: 2.5595341227857196

Epoch: 6| Step: 3
Training loss: 1.6304251269731853
Validation loss: 2.5657435462593927

Epoch: 6| Step: 4
Training loss: 1.5578195279038438
Validation loss: 2.5867268660854505

Epoch: 6| Step: 5
Training loss: 2.5763351238315417
Validation loss: 2.5862469548873737

Epoch: 6| Step: 6
Training loss: 1.9690068395291442
Validation loss: 2.582091505044377

Epoch: 6| Step: 7
Training loss: 2.0978678733305958
Validation loss: 2.6074800178903383

Epoch: 6| Step: 8
Training loss: 1.0442599758176727
Validation loss: 2.614534279948556

Epoch: 6| Step: 9
Training loss: 2.378717524617029
Validation loss: 2.6106790692296253

Epoch: 6| Step: 10
Training loss: 1.9961365099841493
Validation loss: 2.601669701020566

Epoch: 6| Step: 11
Training loss: 1.7152459926294314
Validation loss: 2.5830322616806134

Epoch: 6| Step: 12
Training loss: 2.1063261250399083
Validation loss: 2.5830050106650986

Epoch: 6| Step: 13
Training loss: 1.4619888357892101
Validation loss: 2.5613940884131114

Epoch: 176| Step: 0
Training loss: 2.104332215497627
Validation loss: 2.5568169915014307

Epoch: 6| Step: 1
Training loss: 1.4938755573191547
Validation loss: 2.5646294270627763

Epoch: 6| Step: 2
Training loss: 2.3196512943501597
Validation loss: 2.5495569213351597

Epoch: 6| Step: 3
Training loss: 1.617061444220963
Validation loss: 2.5581904989288695

Epoch: 6| Step: 4
Training loss: 1.6054515234401228
Validation loss: 2.562256273973916

Epoch: 6| Step: 5
Training loss: 2.0114565780318543
Validation loss: 2.546273199726393

Epoch: 6| Step: 6
Training loss: 1.5889524168520652
Validation loss: 2.541792428872463

Epoch: 6| Step: 7
Training loss: 2.303963240277246
Validation loss: 2.534529516813997

Epoch: 6| Step: 8
Training loss: 1.446542412450906
Validation loss: 2.5496600709265542

Epoch: 6| Step: 9
Training loss: 1.925227025504121
Validation loss: 2.5571311694977226

Epoch: 6| Step: 10
Training loss: 2.1646393926249607
Validation loss: 2.5763515713349787

Epoch: 6| Step: 11
Training loss: 1.674677985823296
Validation loss: 2.5760209905924505

Epoch: 6| Step: 12
Training loss: 2.1393139019197873
Validation loss: 2.567609382011881

Epoch: 6| Step: 13
Training loss: 2.278800799232036
Validation loss: 2.585200344314775

Epoch: 177| Step: 0
Training loss: 1.674534046782635
Validation loss: 2.564990757234693

Epoch: 6| Step: 1
Training loss: 2.0448000342388477
Validation loss: 2.5575159195639747

Epoch: 6| Step: 2
Training loss: 2.4704111039752155
Validation loss: 2.5431397420901725

Epoch: 6| Step: 3
Training loss: 1.6867596450378382
Validation loss: 2.5259489403770377

Epoch: 6| Step: 4
Training loss: 1.8473933155812337
Validation loss: 2.5472228603280453

Epoch: 6| Step: 5
Training loss: 1.8098065324520203
Validation loss: 2.5462918751755814

Epoch: 6| Step: 6
Training loss: 1.8589455244794502
Validation loss: 2.5693181180252447

Epoch: 6| Step: 7
Training loss: 2.2362893180311954
Validation loss: 2.551772033376253

Epoch: 6| Step: 8
Training loss: 1.9339483995506792
Validation loss: 2.5523061263724256

Epoch: 6| Step: 9
Training loss: 1.5077010197515013
Validation loss: 2.5545416163722767

Epoch: 6| Step: 10
Training loss: 1.8248874002496942
Validation loss: 2.5780459712878026

Epoch: 6| Step: 11
Training loss: 1.5671550834855432
Validation loss: 2.57985203367725

Epoch: 6| Step: 12
Training loss: 1.2681518102888565
Validation loss: 2.6055774324439476

Epoch: 6| Step: 13
Training loss: 1.880596709008498
Validation loss: 2.599106761565536

Epoch: 178| Step: 0
Training loss: 1.7755365930695028
Validation loss: 2.6117729951608606

Epoch: 6| Step: 1
Training loss: 2.1347908653728576
Validation loss: 2.6036354651987654

Epoch: 6| Step: 2
Training loss: 1.7182113496986557
Validation loss: 2.6137572832162466

Epoch: 6| Step: 3
Training loss: 1.671879492067381
Validation loss: 2.615886820392888

Epoch: 6| Step: 4
Training loss: 1.850569317826097
Validation loss: 2.5937840340520424

Epoch: 6| Step: 5
Training loss: 2.1919776865039258
Validation loss: 2.5659982836466004

Epoch: 6| Step: 6
Training loss: 1.2506402283465325
Validation loss: 2.5543342299161793

Epoch: 6| Step: 7
Training loss: 1.7038470496274511
Validation loss: 2.5487355122179127

Epoch: 6| Step: 8
Training loss: 1.6006440297000621
Validation loss: 2.5444804367744767

Epoch: 6| Step: 9
Training loss: 1.8007313355253525
Validation loss: 2.5288645260894103

Epoch: 6| Step: 10
Training loss: 2.019623095786846
Validation loss: 2.5091296040992117

Epoch: 6| Step: 11
Training loss: 2.4160152302697737
Validation loss: 2.4970020674657443

Epoch: 6| Step: 12
Training loss: 1.977613930874432
Validation loss: 2.4716187830592213

Epoch: 6| Step: 13
Training loss: 1.6064677228205089
Validation loss: 2.4578748149910004

Epoch: 179| Step: 0
Training loss: 2.350188909201885
Validation loss: 2.469040257151285

Epoch: 6| Step: 1
Training loss: 1.7044953598984314
Validation loss: 2.4701121715496277

Epoch: 6| Step: 2
Training loss: 1.5874994413119556
Validation loss: 2.5000901082935245

Epoch: 6| Step: 3
Training loss: 1.638773136397508
Validation loss: 2.511079068608198

Epoch: 6| Step: 4
Training loss: 1.6239372592983545
Validation loss: 2.524948508412683

Epoch: 6| Step: 5
Training loss: 1.6325076608054558
Validation loss: 2.5491898193258393

Epoch: 6| Step: 6
Training loss: 1.9988655806970699
Validation loss: 2.560105900913357

Epoch: 6| Step: 7
Training loss: 1.8775581075562924
Validation loss: 2.6070122979409156

Epoch: 6| Step: 8
Training loss: 2.336769389653143
Validation loss: 2.6127320289168385

Epoch: 6| Step: 9
Training loss: 1.4800786533591364
Validation loss: 2.6448822799121383

Epoch: 6| Step: 10
Training loss: 2.10242452987226
Validation loss: 2.633383316738066

Epoch: 6| Step: 11
Training loss: 1.4748138892223037
Validation loss: 2.619178191452535

Epoch: 6| Step: 12
Training loss: 1.858198803649458
Validation loss: 2.613451572334854

Epoch: 6| Step: 13
Training loss: 1.3657880323499334
Validation loss: 2.5966911082885544

Epoch: 180| Step: 0
Training loss: 2.394928294085958
Validation loss: 2.565424339226746

Epoch: 6| Step: 1
Training loss: 1.9446962291945196
Validation loss: 2.542893917496831

Epoch: 6| Step: 2
Training loss: 1.6494101597145212
Validation loss: 2.538914993582875

Epoch: 6| Step: 3
Training loss: 2.163178962446653
Validation loss: 2.5402939029643354

Epoch: 6| Step: 4
Training loss: 1.8810123686396487
Validation loss: 2.5248200265617036

Epoch: 6| Step: 5
Training loss: 1.1874829341264457
Validation loss: 2.5221717906347534

Epoch: 6| Step: 6
Training loss: 1.8985310598168026
Validation loss: 2.5141565063002176

Epoch: 6| Step: 7
Training loss: 1.2399605035644403
Validation loss: 2.515589236927078

Epoch: 6| Step: 8
Training loss: 1.7025158694027605
Validation loss: 2.5096685705599135

Epoch: 6| Step: 9
Training loss: 1.423187153446999
Validation loss: 2.507324495325621

Epoch: 6| Step: 10
Training loss: 1.6750053263337583
Validation loss: 2.5071932979220883

Epoch: 6| Step: 11
Training loss: 1.8646300610133943
Validation loss: 2.533976644117294

Epoch: 6| Step: 12
Training loss: 1.872860387084552
Validation loss: 2.5493690332609384

Epoch: 6| Step: 13
Training loss: 1.7941023291170266
Validation loss: 2.5503781915483605

Epoch: 181| Step: 0
Training loss: 1.5870932891578837
Validation loss: 2.5199235370836193

Epoch: 6| Step: 1
Training loss: 1.0769503732119643
Validation loss: 2.5238459721381648

Epoch: 6| Step: 2
Training loss: 1.711016997140883
Validation loss: 2.5570561870094393

Epoch: 6| Step: 3
Training loss: 2.164407310145534
Validation loss: 2.5610064053686856

Epoch: 6| Step: 4
Training loss: 1.8988339359498232
Validation loss: 2.5659364018092763

Epoch: 6| Step: 5
Training loss: 2.0505868583464215
Validation loss: 2.587852475579152

Epoch: 6| Step: 6
Training loss: 1.8570900348864512
Validation loss: 2.566794804388408

Epoch: 6| Step: 7
Training loss: 2.0448483050355324
Validation loss: 2.5715732598661316

Epoch: 6| Step: 8
Training loss: 1.8067824849287917
Validation loss: 2.570731488345847

Epoch: 6| Step: 9
Training loss: 1.4026667400935435
Validation loss: 2.56219103991767

Epoch: 6| Step: 10
Training loss: 1.7156559230887303
Validation loss: 2.564416640303404

Epoch: 6| Step: 11
Training loss: 1.7952046467362237
Validation loss: 2.5644553402969534

Epoch: 6| Step: 12
Training loss: 1.5462704642814291
Validation loss: 2.528677855584231

Epoch: 6| Step: 13
Training loss: 1.9982774588393608
Validation loss: 2.537052780677506

Epoch: 182| Step: 0
Training loss: 1.4545912369653868
Validation loss: 2.543653828586601

Epoch: 6| Step: 1
Training loss: 1.1248026780754539
Validation loss: 2.558103777096987

Epoch: 6| Step: 2
Training loss: 1.630940728813874
Validation loss: 2.556849828693905

Epoch: 6| Step: 3
Training loss: 2.1598240077765296
Validation loss: 2.553856190490568

Epoch: 6| Step: 4
Training loss: 1.7395427112823676
Validation loss: 2.558827255053173

Epoch: 6| Step: 5
Training loss: 2.0515396895524196
Validation loss: 2.536439034973365

Epoch: 6| Step: 6
Training loss: 1.81564026135122
Validation loss: 2.547192726169195

Epoch: 6| Step: 7
Training loss: 1.9034787655711383
Validation loss: 2.5356236021089726

Epoch: 6| Step: 8
Training loss: 1.9960602460763017
Validation loss: 2.5504348590793566

Epoch: 6| Step: 9
Training loss: 1.998690056966597
Validation loss: 2.564215737244022

Epoch: 6| Step: 10
Training loss: 1.586271128773036
Validation loss: 2.55610840653464

Epoch: 6| Step: 11
Training loss: 1.5172982958204877
Validation loss: 2.5717390156126996

Epoch: 6| Step: 12
Training loss: 1.5114786908675812
Validation loss: 2.5513105744796634

Epoch: 6| Step: 13
Training loss: 1.6389069780691252
Validation loss: 2.5654844486996993

Epoch: 183| Step: 0
Training loss: 1.6504195171287606
Validation loss: 2.6030397821218547

Epoch: 6| Step: 1
Training loss: 1.8097104935921866
Validation loss: 2.61303064823571

Epoch: 6| Step: 2
Training loss: 1.976647959433555
Validation loss: 2.611948750332441

Epoch: 6| Step: 3
Training loss: 1.8175282284356076
Validation loss: 2.6451415844502666

Epoch: 6| Step: 4
Training loss: 1.5522975475114724
Validation loss: 2.6299812171728068

Epoch: 6| Step: 5
Training loss: 1.4276174766182637
Validation loss: 2.603572510568017

Epoch: 6| Step: 6
Training loss: 2.038228650070512
Validation loss: 2.5817532238811354

Epoch: 6| Step: 7
Training loss: 1.0283192691634664
Validation loss: 2.586352411793751

Epoch: 6| Step: 8
Training loss: 1.4869976766294941
Validation loss: 2.577381402424601

Epoch: 6| Step: 9
Training loss: 1.9114582640381956
Validation loss: 2.5640354313514258

Epoch: 6| Step: 10
Training loss: 2.161248756880483
Validation loss: 2.54527387098003

Epoch: 6| Step: 11
Training loss: 1.7148280392841684
Validation loss: 2.5445374663692997

Epoch: 6| Step: 12
Training loss: 1.5918791018351925
Validation loss: 2.550202909773562

Epoch: 6| Step: 13
Training loss: 2.0864792023972183
Validation loss: 2.5533448253028017

Epoch: 184| Step: 0
Training loss: 1.7739154994928086
Validation loss: 2.541075298948608

Epoch: 6| Step: 1
Training loss: 1.6436147423854286
Validation loss: 2.5476583512605693

Epoch: 6| Step: 2
Training loss: 2.1330926173222546
Validation loss: 2.5476707389581974

Epoch: 6| Step: 3
Training loss: 1.767933779179723
Validation loss: 2.566975635525638

Epoch: 6| Step: 4
Training loss: 1.825275515309157
Validation loss: 2.555565243126459

Epoch: 6| Step: 5
Training loss: 1.5347965197561741
Validation loss: 2.5526187263982765

Epoch: 6| Step: 6
Training loss: 1.7693570284939684
Validation loss: 2.5672476162826854

Epoch: 6| Step: 7
Training loss: 1.3306345846924827
Validation loss: 2.534124889686645

Epoch: 6| Step: 8
Training loss: 1.7749049631385416
Validation loss: 2.5366943113831604

Epoch: 6| Step: 9
Training loss: 2.1235916856445987
Validation loss: 2.518582545274633

Epoch: 6| Step: 10
Training loss: 1.8673417414719138
Validation loss: 2.520897874554247

Epoch: 6| Step: 11
Training loss: 1.1855871454529168
Validation loss: 2.5286457120105554

Epoch: 6| Step: 12
Training loss: 1.4389901937239415
Validation loss: 2.5425544508270175

Epoch: 6| Step: 13
Training loss: 1.9582893150198213
Validation loss: 2.5471196563233893

Epoch: 185| Step: 0
Training loss: 1.6342883581241103
Validation loss: 2.5825594564262793

Epoch: 6| Step: 1
Training loss: 1.6869719350184207
Validation loss: 2.5729087825151336

Epoch: 6| Step: 2
Training loss: 1.5519580747850448
Validation loss: 2.5866230320344976

Epoch: 6| Step: 3
Training loss: 1.8844069065410356
Validation loss: 2.6102785016670462

Epoch: 6| Step: 4
Training loss: 1.6366290885019392
Validation loss: 2.597876620546288

Epoch: 6| Step: 5
Training loss: 1.82517336714335
Validation loss: 2.6177142227117245

Epoch: 6| Step: 6
Training loss: 1.895781994917511
Validation loss: 2.625099807224734

Epoch: 6| Step: 7
Training loss: 1.7600098841563023
Validation loss: 2.6224276258282773

Epoch: 6| Step: 8
Training loss: 1.4153760846982912
Validation loss: 2.601674721541207

Epoch: 6| Step: 9
Training loss: 1.1376553900921997
Validation loss: 2.5968612857117517

Epoch: 6| Step: 10
Training loss: 2.0287035899985484
Validation loss: 2.5867889948474447

Epoch: 6| Step: 11
Training loss: 1.7733762621284543
Validation loss: 2.5731594151693185

Epoch: 6| Step: 12
Training loss: 1.6641999666985774
Validation loss: 2.568531535334121

Epoch: 6| Step: 13
Training loss: 1.5733888772007147
Validation loss: 2.5623412684618474

Epoch: 186| Step: 0
Training loss: 1.5772344512632575
Validation loss: 2.5531532522705276

Epoch: 6| Step: 1
Training loss: 1.24992303611329
Validation loss: 2.5838077882205104

Epoch: 6| Step: 2
Training loss: 1.6046085327092736
Validation loss: 2.564805215734494

Epoch: 6| Step: 3
Training loss: 2.1927142532039174
Validation loss: 2.580634645311146

Epoch: 6| Step: 4
Training loss: 1.4144878274684431
Validation loss: 2.5902502142834156

Epoch: 6| Step: 5
Training loss: 1.3512412775483331
Validation loss: 2.578821511150756

Epoch: 6| Step: 6
Training loss: 1.4538008236057638
Validation loss: 2.5935936287747707

Epoch: 6| Step: 7
Training loss: 1.7453910215741137
Validation loss: 2.5927450647662016

Epoch: 6| Step: 8
Training loss: 2.1331402313734795
Validation loss: 2.581378096280526

Epoch: 6| Step: 9
Training loss: 1.5483620941863485
Validation loss: 2.5872427851907753

Epoch: 6| Step: 10
Training loss: 1.9140191520920566
Validation loss: 2.5693872938938775

Epoch: 6| Step: 11
Training loss: 1.3361620351815715
Validation loss: 2.5374297283389176

Epoch: 6| Step: 12
Training loss: 1.895932841222147
Validation loss: 2.5275314095789927

Epoch: 6| Step: 13
Training loss: 1.9225164444000595
Validation loss: 2.525756716009023

Epoch: 187| Step: 0
Training loss: 1.583600356356857
Validation loss: 2.5256878687009907

Epoch: 6| Step: 1
Training loss: 1.7175227552125334
Validation loss: 2.5454368504378766

Epoch: 6| Step: 2
Training loss: 1.6620025062496233
Validation loss: 2.5342448226957934

Epoch: 6| Step: 3
Training loss: 1.499400336881134
Validation loss: 2.5794440501319618

Epoch: 6| Step: 4
Training loss: 1.1316710937106285
Validation loss: 2.590137860509282

Epoch: 6| Step: 5
Training loss: 2.107439071118442
Validation loss: 2.602807446233065

Epoch: 6| Step: 6
Training loss: 1.5727316219121361
Validation loss: 2.6036942543669825

Epoch: 6| Step: 7
Training loss: 1.391047552824838
Validation loss: 2.611281060045411

Epoch: 6| Step: 8
Training loss: 1.764489272792223
Validation loss: 2.620804684870066

Epoch: 6| Step: 9
Training loss: 1.6115891123866175
Validation loss: 2.617433379513577

Epoch: 6| Step: 10
Training loss: 1.9100755545766466
Validation loss: 2.606048337981497

Epoch: 6| Step: 11
Training loss: 1.8838493056722805
Validation loss: 2.574077682193886

Epoch: 6| Step: 12
Training loss: 1.3909994756997914
Validation loss: 2.618054999723753

Epoch: 6| Step: 13
Training loss: 2.1653673115015573
Validation loss: 2.5402909308963872

Epoch: 188| Step: 0
Training loss: 1.6151672127908796
Validation loss: 2.542691334049988

Epoch: 6| Step: 1
Training loss: 1.7684048400117207
Validation loss: 2.5257486477687876

Epoch: 6| Step: 2
Training loss: 1.3279873944971154
Validation loss: 2.535152668200438

Epoch: 6| Step: 3
Training loss: 2.0184313732289882
Validation loss: 2.5497982085248356

Epoch: 6| Step: 4
Training loss: 1.9904689182671007
Validation loss: 2.5733152348764303

Epoch: 6| Step: 5
Training loss: 1.6183505828493372
Validation loss: 2.5562840616088165

Epoch: 6| Step: 6
Training loss: 1.208204372145129
Validation loss: 2.540287818547141

Epoch: 6| Step: 7
Training loss: 1.8588916567072251
Validation loss: 2.5590791791769254

Epoch: 6| Step: 8
Training loss: 1.8134490849678553
Validation loss: 2.5569494205675447

Epoch: 6| Step: 9
Training loss: 1.6657025489145927
Validation loss: 2.5507304833485724

Epoch: 6| Step: 10
Training loss: 1.4669303173009447
Validation loss: 2.559541596746829

Epoch: 6| Step: 11
Training loss: 1.4892510085654
Validation loss: 2.5835477625532004

Epoch: 6| Step: 12
Training loss: 1.7122102645471882
Validation loss: 2.5805866872696193

Epoch: 6| Step: 13
Training loss: 0.9649217087605997
Validation loss: 2.584657527826629

Epoch: 189| Step: 0
Training loss: 1.9883779565941817
Validation loss: 2.5644599188378407

Epoch: 6| Step: 1
Training loss: 1.7855400490906772
Validation loss: 2.572593082404729

Epoch: 6| Step: 2
Training loss: 1.8029410759325752
Validation loss: 2.568322644344783

Epoch: 6| Step: 3
Training loss: 1.1057654747532362
Validation loss: 2.5556774039762744

Epoch: 6| Step: 4
Training loss: 1.1112878989932593
Validation loss: 2.559628636438169

Epoch: 6| Step: 5
Training loss: 1.6559689121322925
Validation loss: 2.54951273923396

Epoch: 6| Step: 6
Training loss: 1.743920460781427
Validation loss: 2.5665466367092282

Epoch: 6| Step: 7
Training loss: 1.3843068383790127
Validation loss: 2.579951112231069

Epoch: 6| Step: 8
Training loss: 1.288329777402194
Validation loss: 2.553676199715482

Epoch: 6| Step: 9
Training loss: 1.5031444651400125
Validation loss: 2.562590668737711

Epoch: 6| Step: 10
Training loss: 1.9906751689248119
Validation loss: 2.5935157900430905

Epoch: 6| Step: 11
Training loss: 1.6032341397558443
Validation loss: 2.5991277180618138

Epoch: 6| Step: 12
Training loss: 1.7141815505852054
Validation loss: 2.607885190738484

Epoch: 6| Step: 13
Training loss: 1.5389198198358305
Validation loss: 2.6133528407649353

Epoch: 190| Step: 0
Training loss: 1.627232265453719
Validation loss: 2.6173701641784173

Epoch: 6| Step: 1
Training loss: 1.5226108753691332
Validation loss: 2.603463376148706

Epoch: 6| Step: 2
Training loss: 1.5154978905300964
Validation loss: 2.595270205804307

Epoch: 6| Step: 3
Training loss: 1.6253299378184107
Validation loss: 2.5812367662271676

Epoch: 6| Step: 4
Training loss: 1.5113333277293575
Validation loss: 2.5822247426529135

Epoch: 6| Step: 5
Training loss: 1.4944436158781027
Validation loss: 2.5640169281341123

Epoch: 6| Step: 6
Training loss: 1.8702699125790474
Validation loss: 2.5389828390367457

Epoch: 6| Step: 7
Training loss: 1.6530940379252104
Validation loss: 2.5158689290575933

Epoch: 6| Step: 8
Training loss: 1.8849528955903276
Validation loss: 2.543447659952421

Epoch: 6| Step: 9
Training loss: 1.721985009308715
Validation loss: 2.529692952447003

Epoch: 6| Step: 10
Training loss: 1.5214848451038265
Validation loss: 2.5347609943798317

Epoch: 6| Step: 11
Training loss: 1.344237305751326
Validation loss: 2.549636789859813

Epoch: 6| Step: 12
Training loss: 1.5060664528095433
Validation loss: 2.5589753117627043

Epoch: 6| Step: 13
Training loss: 1.5361390207678107
Validation loss: 2.5851800161896765

Epoch: 191| Step: 0
Training loss: 1.685898762877497
Validation loss: 2.5593445911824935

Epoch: 6| Step: 1
Training loss: 1.6631676502056039
Validation loss: 2.572326849288869

Epoch: 6| Step: 2
Training loss: 1.4388034550126616
Validation loss: 2.577847547570256

Epoch: 6| Step: 3
Training loss: 1.7568410944372617
Validation loss: 2.5785101847998533

Epoch: 6| Step: 4
Training loss: 1.5919867841085764
Validation loss: 2.5718189837511307

Epoch: 6| Step: 5
Training loss: 1.5577127744230346
Validation loss: 2.606767380749942

Epoch: 6| Step: 6
Training loss: 1.5441329234032735
Validation loss: 2.5890044645013037

Epoch: 6| Step: 7
Training loss: 1.4418371533410979
Validation loss: 2.5923507341843406

Epoch: 6| Step: 8
Training loss: 1.4348303011995378
Validation loss: 2.5981119036750773

Epoch: 6| Step: 9
Training loss: 1.8504091686682973
Validation loss: 2.6198929261295865

Epoch: 6| Step: 10
Training loss: 1.6688325954384702
Validation loss: 2.5943246949263346

Epoch: 6| Step: 11
Training loss: 1.9045021924571834
Validation loss: 2.5959577380071583

Epoch: 6| Step: 12
Training loss: 1.0286264280911244
Validation loss: 2.5999116659343477

Epoch: 6| Step: 13
Training loss: 1.168406120750226
Validation loss: 2.5652185571446937

Epoch: 192| Step: 0
Training loss: 1.3141960810963833
Validation loss: 2.5589539558101033

Epoch: 6| Step: 1
Training loss: 1.7109294176999454
Validation loss: 2.5447476912570473

Epoch: 6| Step: 2
Training loss: 1.562837182856752
Validation loss: 2.530857601157268

Epoch: 6| Step: 3
Training loss: 1.3032831182993554
Validation loss: 2.509845631082612

Epoch: 6| Step: 4
Training loss: 1.2302392170275953
Validation loss: 2.5198224162011353

Epoch: 6| Step: 5
Training loss: 1.7058423963242948
Validation loss: 2.5066928817034513

Epoch: 6| Step: 6
Training loss: 1.6645092431657165
Validation loss: 2.5060668252768856

Epoch: 6| Step: 7
Training loss: 1.6965584812759638
Validation loss: 2.4963409611069087

Epoch: 6| Step: 8
Training loss: 1.8271677494302776
Validation loss: 2.520310567294583

Epoch: 6| Step: 9
Training loss: 1.2112797899391683
Validation loss: 2.5237267588524857

Epoch: 6| Step: 10
Training loss: 1.5260774089633178
Validation loss: 2.5427625459834746

Epoch: 6| Step: 11
Training loss: 1.8491942635749432
Validation loss: 2.5662519148486838

Epoch: 6| Step: 12
Training loss: 1.9045909478466458
Validation loss: 2.56975811434368

Epoch: 6| Step: 13
Training loss: 1.3823760469961992
Validation loss: 2.585185064767203

Epoch: 193| Step: 0
Training loss: 1.9570144378488195
Validation loss: 2.5888698215789723

Epoch: 6| Step: 1
Training loss: 0.9438727898958945
Validation loss: 2.5944199332555087

Epoch: 6| Step: 2
Training loss: 2.012753355770893
Validation loss: 2.5834410221890436

Epoch: 6| Step: 3
Training loss: 1.4029294971634285
Validation loss: 2.572095073870911

Epoch: 6| Step: 4
Training loss: 1.8428029359721665
Validation loss: 2.5702037083215443

Epoch: 6| Step: 5
Training loss: 1.322179253375979
Validation loss: 2.5837759643687144

Epoch: 6| Step: 6
Training loss: 1.7730002515419374
Validation loss: 2.5804671392129372

Epoch: 6| Step: 7
Training loss: 1.3283666054368957
Validation loss: 2.570549523191021

Epoch: 6| Step: 8
Training loss: 1.8755398291088703
Validation loss: 2.573866600854505

Epoch: 6| Step: 9
Training loss: 1.860701912958311
Validation loss: 2.60701536701647

Epoch: 6| Step: 10
Training loss: 1.2106746265202921
Validation loss: 2.594554365722645

Epoch: 6| Step: 11
Training loss: 1.3211494366387813
Validation loss: 2.573843994428364

Epoch: 6| Step: 12
Training loss: 1.4648040359199797
Validation loss: 2.5633014093067827

Epoch: 6| Step: 13
Training loss: 1.2482406155405188
Validation loss: 2.5572083282541787

Epoch: 194| Step: 0
Training loss: 1.4956260328532383
Validation loss: 2.5442872949912543

Epoch: 6| Step: 1
Training loss: 1.6562035032259472
Validation loss: 2.5447156327993636

Epoch: 6| Step: 2
Training loss: 1.2083493045321396
Validation loss: 2.535238655273329

Epoch: 6| Step: 3
Training loss: 1.814334598607866
Validation loss: 2.5427102505602392

Epoch: 6| Step: 4
Training loss: 1.4230287503081205
Validation loss: 2.555208405263257

Epoch: 6| Step: 5
Training loss: 1.564266731883595
Validation loss: 2.5613636685753867

Epoch: 6| Step: 6
Training loss: 1.756134996008719
Validation loss: 2.5571143547474198

Epoch: 6| Step: 7
Training loss: 1.2376257668752773
Validation loss: 2.5621687542194875

Epoch: 6| Step: 8
Training loss: 1.5992818830185374
Validation loss: 2.517471974531503

Epoch: 6| Step: 9
Training loss: 1.6714645309678848
Validation loss: 2.535851193261963

Epoch: 6| Step: 10
Training loss: 1.180606155931727
Validation loss: 2.5607323601303555

Epoch: 6| Step: 11
Training loss: 1.6090200088233662
Validation loss: 2.5310541591441145

Epoch: 6| Step: 12
Training loss: 1.5434538646015048
Validation loss: 2.528094095840056

Epoch: 6| Step: 13
Training loss: 1.8179778488580653
Validation loss: 2.528163120989266

Epoch: 195| Step: 0
Training loss: 1.6350564094168427
Validation loss: 2.554540528510947

Epoch: 6| Step: 1
Training loss: 0.8812604781806213
Validation loss: 2.5893219631124285

Epoch: 6| Step: 2
Training loss: 1.3397338644181807
Validation loss: 2.5505335555830544

Epoch: 6| Step: 3
Training loss: 1.5265013574168733
Validation loss: 2.5768770888732915

Epoch: 6| Step: 4
Training loss: 1.4649228494268731
Validation loss: 2.582313191948626

Epoch: 6| Step: 5
Training loss: 1.3147375017418224
Validation loss: 2.56306173538912

Epoch: 6| Step: 6
Training loss: 1.554406528866378
Validation loss: 2.5681146996831994

Epoch: 6| Step: 7
Training loss: 2.235050232768666
Validation loss: 2.580859685673338

Epoch: 6| Step: 8
Training loss: 1.5623441999961067
Validation loss: 2.5646321829983356

Epoch: 6| Step: 9
Training loss: 1.6384052337024588
Validation loss: 2.582240814098894

Epoch: 6| Step: 10
Training loss: 1.2517385313751672
Validation loss: 2.567026152311422

Epoch: 6| Step: 11
Training loss: 1.6069357450940855
Validation loss: 2.5646214501270554

Epoch: 6| Step: 12
Training loss: 1.2138250563070139
Validation loss: 2.544031614064332

Epoch: 6| Step: 13
Training loss: 1.754768686293159
Validation loss: 2.5724316844393553

Epoch: 196| Step: 0
Training loss: 1.1049332686595208
Validation loss: 2.5599556002737054

Epoch: 6| Step: 1
Training loss: 0.9089360059090971
Validation loss: 2.5729644227591337

Epoch: 6| Step: 2
Training loss: 1.3473483411128317
Validation loss: 2.5717527182901794

Epoch: 6| Step: 3
Training loss: 1.5443361042331862
Validation loss: 2.5829338690438948

Epoch: 6| Step: 4
Training loss: 1.6000508687754484
Validation loss: 2.5666972545526576

Epoch: 6| Step: 5
Training loss: 1.8641942504470017
Validation loss: 2.568767905491625

Epoch: 6| Step: 6
Training loss: 1.8092070954577757
Validation loss: 2.566183900224955

Epoch: 6| Step: 7
Training loss: 1.9021051088767003
Validation loss: 2.5746050091160626

Epoch: 6| Step: 8
Training loss: 1.170720663566177
Validation loss: 2.5878087422377556

Epoch: 6| Step: 9
Training loss: 1.8636869552664215
Validation loss: 2.5622502076909566

Epoch: 6| Step: 10
Training loss: 1.5527970211419093
Validation loss: 2.544370330495043

Epoch: 6| Step: 11
Training loss: 1.2836459482994649
Validation loss: 2.5493231383565096

Epoch: 6| Step: 12
Training loss: 1.0177081532056813
Validation loss: 2.529080941152545

Epoch: 6| Step: 13
Training loss: 1.6771541920100417
Validation loss: 2.547071905153767

Epoch: 197| Step: 0
Training loss: 1.65597330337235
Validation loss: 2.558434307156253

Epoch: 6| Step: 1
Training loss: 1.2986443181588887
Validation loss: 2.560418809253567

Epoch: 6| Step: 2
Training loss: 1.6647310302038536
Validation loss: 2.568283550444382

Epoch: 6| Step: 3
Training loss: 1.3295988992473027
Validation loss: 2.5644275609744964

Epoch: 6| Step: 4
Training loss: 1.1457181121230908
Validation loss: 2.558776928067422

Epoch: 6| Step: 5
Training loss: 1.3776603451711544
Validation loss: 2.5689146697627203

Epoch: 6| Step: 6
Training loss: 1.1995111661886602
Validation loss: 2.5622764868091292

Epoch: 6| Step: 7
Training loss: 1.2646216665844083
Validation loss: 2.5728534639077103

Epoch: 6| Step: 8
Training loss: 1.5609658148014125
Validation loss: 2.542786392073267

Epoch: 6| Step: 9
Training loss: 1.6444512209595135
Validation loss: 2.5536765259836107

Epoch: 6| Step: 10
Training loss: 1.5944702914303253
Validation loss: 2.5590553181101603

Epoch: 6| Step: 11
Training loss: 1.5546112041825904
Validation loss: 2.5800344526453696

Epoch: 6| Step: 12
Training loss: 1.9575354864964631
Validation loss: 2.602109066814857

Epoch: 6| Step: 13
Training loss: 1.1095967138393013
Validation loss: 2.5976783654659914

Epoch: 198| Step: 0
Training loss: 1.281927348406694
Validation loss: 2.609276934573925

Epoch: 6| Step: 1
Training loss: 1.3954885066347404
Validation loss: 2.5996925309454935

Epoch: 6| Step: 2
Training loss: 1.4378197355861464
Validation loss: 2.626990065440906

Epoch: 6| Step: 3
Training loss: 1.6206654178097264
Validation loss: 2.6214133486327715

Epoch: 6| Step: 4
Training loss: 1.9238201935115689
Validation loss: 2.604572189422992

Epoch: 6| Step: 5
Training loss: 1.3346617111469106
Validation loss: 2.601278643150124

Epoch: 6| Step: 6
Training loss: 1.3084609234710574
Validation loss: 2.573058303601907

Epoch: 6| Step: 7
Training loss: 1.5471410811489164
Validation loss: 2.556432258588592

Epoch: 6| Step: 8
Training loss: 1.077647172387137
Validation loss: 2.5438202597245514

Epoch: 6| Step: 9
Training loss: 1.2886474866082738
Validation loss: 2.547662991182637

Epoch: 6| Step: 10
Training loss: 1.1676867090287981
Validation loss: 2.5705877708301674

Epoch: 6| Step: 11
Training loss: 1.8100644552230087
Validation loss: 2.5597664834574374

Epoch: 6| Step: 12
Training loss: 1.3904206200759617
Validation loss: 2.588915480832556

Epoch: 6| Step: 13
Training loss: 2.0115205833828913
Validation loss: 2.5849401542578434

Epoch: 199| Step: 0
Training loss: 1.6844342959128191
Validation loss: 2.595419225899723

Epoch: 6| Step: 1
Training loss: 1.1978541261131461
Validation loss: 2.6264052811896024

Epoch: 6| Step: 2
Training loss: 1.1973369633142406
Validation loss: 2.6125980048528206

Epoch: 6| Step: 3
Training loss: 1.5976987054308993
Validation loss: 2.6275605186581146

Epoch: 6| Step: 4
Training loss: 1.5330811275856067
Validation loss: 2.5984182847015074

Epoch: 6| Step: 5
Training loss: 1.2007155629385695
Validation loss: 2.5922440136219143

Epoch: 6| Step: 6
Training loss: 1.024373158237368
Validation loss: 2.572357657219285

Epoch: 6| Step: 7
Training loss: 1.7568696608813408
Validation loss: 2.550212927262233

Epoch: 6| Step: 8
Training loss: 1.3337962072317653
Validation loss: 2.5473039855775363

Epoch: 6| Step: 9
Training loss: 1.7698906876597347
Validation loss: 2.544984425457334

Epoch: 6| Step: 10
Training loss: 0.8032800532185355
Validation loss: 2.538254739583415

Epoch: 6| Step: 11
Training loss: 1.6688280237366695
Validation loss: 2.5330803989646986

Epoch: 6| Step: 12
Training loss: 1.2950346424373809
Validation loss: 2.555856355593604

Epoch: 6| Step: 13
Training loss: 1.9031193775413406
Validation loss: 2.542293395329426

Epoch: 200| Step: 0
Training loss: 1.5965999478368453
Validation loss: 2.5508926081611025

Epoch: 6| Step: 1
Training loss: 0.9915998626027198
Validation loss: 2.552891606072102

Epoch: 6| Step: 2
Training loss: 1.2586249339942563
Validation loss: 2.551355590593497

Epoch: 6| Step: 3
Training loss: 1.5439781267514254
Validation loss: 2.5890456521729757

Epoch: 6| Step: 4
Training loss: 1.2592614399562811
Validation loss: 2.5537772183675393

Epoch: 6| Step: 5
Training loss: 1.4087701468055236
Validation loss: 2.592306452708209

Epoch: 6| Step: 6
Training loss: 1.2482676900217151
Validation loss: 2.5801249890896103

Epoch: 6| Step: 7
Training loss: 1.5556188506161572
Validation loss: 2.5876324431927293

Epoch: 6| Step: 8
Training loss: 1.3862868805116548
Validation loss: 2.6027559928122295

Epoch: 6| Step: 9
Training loss: 1.6483959897857814
Validation loss: 2.5905089268944073

Epoch: 6| Step: 10
Training loss: 1.8561908802417983
Validation loss: 2.6181659366401617

Epoch: 6| Step: 11
Training loss: 1.169672816900603
Validation loss: 2.627375688413283

Epoch: 6| Step: 12
Training loss: 1.5752519950908552
Validation loss: 2.627079018795383

Epoch: 6| Step: 13
Training loss: 1.4356557376611803
Validation loss: 2.6157680824841534

Epoch: 201| Step: 0
Training loss: 1.1809118624526593
Validation loss: 2.62283576918053

Epoch: 6| Step: 1
Training loss: 1.48262611560347
Validation loss: 2.6065398069997037

Epoch: 6| Step: 2
Training loss: 1.190843593125207
Validation loss: 2.594191753645538

Epoch: 6| Step: 3
Training loss: 1.6312319027419342
Validation loss: 2.5735050246276807

Epoch: 6| Step: 4
Training loss: 1.076513772645154
Validation loss: 2.559182301086526

Epoch: 6| Step: 5
Training loss: 1.6410025026068704
Validation loss: 2.5654227813102235

Epoch: 6| Step: 6
Training loss: 1.480325173534526
Validation loss: 2.535269681821513

Epoch: 6| Step: 7
Training loss: 1.747884902695798
Validation loss: 2.5375132691065576

Epoch: 6| Step: 8
Training loss: 1.2050614564506397
Validation loss: 2.5511637531248286

Epoch: 6| Step: 9
Training loss: 1.3767048929894095
Validation loss: 2.544738239584808

Epoch: 6| Step: 10
Training loss: 1.6477920932037897
Validation loss: 2.565475998763109

Epoch: 6| Step: 11
Training loss: 1.308145019115613
Validation loss: 2.5671347416097556

Epoch: 6| Step: 12
Training loss: 1.3996789632282682
Validation loss: 2.591413597848299

Epoch: 6| Step: 13
Training loss: 1.164206886297613
Validation loss: 2.595319663134814

Epoch: 202| Step: 0
Training loss: 1.2060797437775517
Validation loss: 2.610992072053842

Epoch: 6| Step: 1
Training loss: 1.8412159461700597
Validation loss: 2.6120752755251995

Epoch: 6| Step: 2
Training loss: 1.2653464964569532
Validation loss: 2.606402491123696

Epoch: 6| Step: 3
Training loss: 1.1332954166651898
Validation loss: 2.6254507147635393

Epoch: 6| Step: 4
Training loss: 1.1902980966415129
Validation loss: 2.5982386088388236

Epoch: 6| Step: 5
Training loss: 1.6633810161236104
Validation loss: 2.5978491670256845

Epoch: 6| Step: 6
Training loss: 0.9883761153093623
Validation loss: 2.590998737630574

Epoch: 6| Step: 7
Training loss: 1.5607187417581825
Validation loss: 2.5699686617796185

Epoch: 6| Step: 8
Training loss: 1.6668280602830627
Validation loss: 2.5272836255325455

Epoch: 6| Step: 9
Training loss: 0.8394428804605881
Validation loss: 2.5408817015817147

Epoch: 6| Step: 10
Training loss: 1.1294697869639128
Validation loss: 2.5358731208597347

Epoch: 6| Step: 11
Training loss: 1.4823740271685653
Validation loss: 2.5277218290917522

Epoch: 6| Step: 12
Training loss: 1.3319663650057811
Validation loss: 2.551423272031621

Epoch: 6| Step: 13
Training loss: 2.187218784239893
Validation loss: 2.5612755187672462

Epoch: 203| Step: 0
Training loss: 1.3002887515186963
Validation loss: 2.567003861651325

Epoch: 6| Step: 1
Training loss: 1.1527752601769672
Validation loss: 2.5503453805979923

Epoch: 6| Step: 2
Training loss: 1.207469724745537
Validation loss: 2.5979467702761645

Epoch: 6| Step: 3
Training loss: 1.2549369592525348
Validation loss: 2.5722556923975293

Epoch: 6| Step: 4
Training loss: 0.7678284370404806
Validation loss: 2.5482070945146083

Epoch: 6| Step: 5
Training loss: 2.1835382826418903
Validation loss: 2.5768497150621563

Epoch: 6| Step: 6
Training loss: 1.3244083685134431
Validation loss: 2.575400096332342

Epoch: 6| Step: 7
Training loss: 1.3438895397036643
Validation loss: 2.5757723776414116

Epoch: 6| Step: 8
Training loss: 1.4385409525271702
Validation loss: 2.5673937704810843

Epoch: 6| Step: 9
Training loss: 1.1719859770043326
Validation loss: 2.5778822142238793

Epoch: 6| Step: 10
Training loss: 1.3408974377371181
Validation loss: 2.5468962287433317

Epoch: 6| Step: 11
Training loss: 1.396477759285575
Validation loss: 2.5572769274553244

Epoch: 6| Step: 12
Training loss: 1.3960186375081607
Validation loss: 2.5567683234998233

Epoch: 6| Step: 13
Training loss: 1.7823571227862762
Validation loss: 2.569379926897157

Epoch: 204| Step: 0
Training loss: 1.5125783600488558
Validation loss: 2.552102085134205

Epoch: 6| Step: 1
Training loss: 1.3687800695870103
Validation loss: 2.57970972959956

Epoch: 6| Step: 2
Training loss: 1.269482608743652
Validation loss: 2.605614166277779

Epoch: 6| Step: 3
Training loss: 0.8143676420217532
Validation loss: 2.584390028348782

Epoch: 6| Step: 4
Training loss: 1.2698127786551836
Validation loss: 2.632404972470966

Epoch: 6| Step: 5
Training loss: 1.1868418827428397
Validation loss: 2.638134245668806

Epoch: 6| Step: 6
Training loss: 1.2067762679613034
Validation loss: 2.6259739968827063

Epoch: 6| Step: 7
Training loss: 1.649775030231506
Validation loss: 2.627087084688716

Epoch: 6| Step: 8
Training loss: 1.0706831018968685
Validation loss: 2.626920667378342

Epoch: 6| Step: 9
Training loss: 1.538041914052515
Validation loss: 2.6091855742837673

Epoch: 6| Step: 10
Training loss: 1.192195243360338
Validation loss: 2.6094880919879033

Epoch: 6| Step: 11
Training loss: 1.535115093426919
Validation loss: 2.595263791929105

Epoch: 6| Step: 12
Training loss: 1.720055240586815
Validation loss: 2.557788773410594

Epoch: 6| Step: 13
Training loss: 1.5833553095179203
Validation loss: 2.566735476695608

Epoch: 205| Step: 0
Training loss: 1.180200881912039
Validation loss: 2.552397112028642

Epoch: 6| Step: 1
Training loss: 1.059906205759993
Validation loss: 2.5357463344653963

Epoch: 6| Step: 2
Training loss: 1.2255596264450404
Validation loss: 2.542335892850806

Epoch: 6| Step: 3
Training loss: 1.35846289365915
Validation loss: 2.5363354507970985

Epoch: 6| Step: 4
Training loss: 1.7133194876951274
Validation loss: 2.5572368817373357

Epoch: 6| Step: 5
Training loss: 1.235399762445927
Validation loss: 2.5604060992489064

Epoch: 6| Step: 6
Training loss: 1.0756661945724595
Validation loss: 2.561835103946677

Epoch: 6| Step: 7
Training loss: 1.2763767139922793
Validation loss: 2.556108064529773

Epoch: 6| Step: 8
Training loss: 1.2411230072641717
Validation loss: 2.5823850212656794

Epoch: 6| Step: 9
Training loss: 1.6378289511104946
Validation loss: 2.5732154993158067

Epoch: 6| Step: 10
Training loss: 1.1461624655377316
Validation loss: 2.597708410380403

Epoch: 6| Step: 11
Training loss: 1.872500024548519
Validation loss: 2.569639398380524

Epoch: 6| Step: 12
Training loss: 1.421216539779176
Validation loss: 2.5794969952083773

Epoch: 6| Step: 13
Training loss: 1.0850229048179085
Validation loss: 2.57270966663199

Epoch: 206| Step: 0
Training loss: 1.3010178542674973
Validation loss: 2.5882157306466853

Epoch: 6| Step: 1
Training loss: 1.0239125088553247
Validation loss: 2.560628360039846

Epoch: 6| Step: 2
Training loss: 0.9971721122699695
Validation loss: 2.549802807352168

Epoch: 6| Step: 3
Training loss: 1.4632483173662447
Validation loss: 2.548412866035061

Epoch: 6| Step: 4
Training loss: 1.6932398347998656
Validation loss: 2.5450328811225638

Epoch: 6| Step: 5
Training loss: 1.008457184638749
Validation loss: 2.54201102853228

Epoch: 6| Step: 6
Training loss: 1.114305740917062
Validation loss: 2.542303691040352

Epoch: 6| Step: 7
Training loss: 1.4777447039903437
Validation loss: 2.5627332651738306

Epoch: 6| Step: 8
Training loss: 1.2105462211220603
Validation loss: 2.560189759165158

Epoch: 6| Step: 9
Training loss: 1.5566963750603315
Validation loss: 2.54062063111366

Epoch: 6| Step: 10
Training loss: 0.9901984695455874
Validation loss: 2.5432689974596556

Epoch: 6| Step: 11
Training loss: 1.6093460376688946
Validation loss: 2.5750672992768906

Epoch: 6| Step: 12
Training loss: 1.0620648109933049
Validation loss: 2.522149094405447

Epoch: 6| Step: 13
Training loss: 2.2007269828586815
Validation loss: 2.53358689063636

Epoch: 207| Step: 0
Training loss: 1.4214293232085355
Validation loss: 2.532409229336108

Epoch: 6| Step: 1
Training loss: 1.028862472448643
Validation loss: 2.519920755651063

Epoch: 6| Step: 2
Training loss: 1.6945116814925176
Validation loss: 2.5656863975005657

Epoch: 6| Step: 3
Training loss: 1.5290887332913563
Validation loss: 2.5209549840871293

Epoch: 6| Step: 4
Training loss: 1.4046000656056217
Validation loss: 2.511470326598709

Epoch: 6| Step: 5
Training loss: 1.4842950096662775
Validation loss: 2.5147597380825935

Epoch: 6| Step: 6
Training loss: 1.1348268160842725
Validation loss: 2.535914537116344

Epoch: 6| Step: 7
Training loss: 1.9585746724645525
Validation loss: 2.5399167424703837

Epoch: 6| Step: 8
Training loss: 1.116920172445462
Validation loss: 2.548718596815186

Epoch: 6| Step: 9
Training loss: 0.9003905588013466
Validation loss: 2.567515916750741

Epoch: 6| Step: 10
Training loss: 1.5353898120672809
Validation loss: 2.574685407999289

Epoch: 6| Step: 11
Training loss: 0.9901735787472792
Validation loss: 2.568411861853302

Epoch: 6| Step: 12
Training loss: 1.0652151757228254
Validation loss: 2.576785754817479

Epoch: 6| Step: 13
Training loss: 0.9760292122995212
Validation loss: 2.5792755950291775

Epoch: 208| Step: 0
Training loss: 1.4908669905099965
Validation loss: 2.593938738364126

Epoch: 6| Step: 1
Training loss: 1.1498514411172447
Validation loss: 2.6120793510239166

Epoch: 6| Step: 2
Training loss: 1.3346817182247301
Validation loss: 2.6095994490890777

Epoch: 6| Step: 3
Training loss: 1.2571935137615078
Validation loss: 2.628788515599628

Epoch: 6| Step: 4
Training loss: 1.3400914266341237
Validation loss: 2.6170137159442866

Epoch: 6| Step: 5
Training loss: 1.3606760222751795
Validation loss: 2.6387719889641597

Epoch: 6| Step: 6
Training loss: 0.8036116658082219
Validation loss: 2.6187863619270595

Epoch: 6| Step: 7
Training loss: 1.136866032343262
Validation loss: 2.5899898683520295

Epoch: 6| Step: 8
Training loss: 1.8104357968260905
Validation loss: 2.5856676507693996

Epoch: 6| Step: 9
Training loss: 1.3735790713518232
Validation loss: 2.567690206364425

Epoch: 6| Step: 10
Training loss: 1.086591784192598
Validation loss: 2.557959333814419

Epoch: 6| Step: 11
Training loss: 1.5779931797078426
Validation loss: 2.5447713293507954

Epoch: 6| Step: 12
Training loss: 1.2221325615064378
Validation loss: 2.554231591267633

Epoch: 6| Step: 13
Training loss: 1.336997966488053
Validation loss: 2.535786015921805

Epoch: 209| Step: 0
Training loss: 1.14351476115852
Validation loss: 2.564855723792746

Epoch: 6| Step: 1
Training loss: 1.386652297455969
Validation loss: 2.556961677529454

Epoch: 6| Step: 2
Training loss: 0.9930280594179511
Validation loss: 2.5585678684178363

Epoch: 6| Step: 3
Training loss: 1.2593061215328474
Validation loss: 2.5749633156440943

Epoch: 6| Step: 4
Training loss: 2.023043325317592
Validation loss: 2.5933520548872013

Epoch: 6| Step: 5
Training loss: 1.1220550137664629
Validation loss: 2.583001811825433

Epoch: 6| Step: 6
Training loss: 1.405479559186217
Validation loss: 2.5967841580023383

Epoch: 6| Step: 7
Training loss: 0.9623006440827372
Validation loss: 2.579005022897959

Epoch: 6| Step: 8
Training loss: 1.0312813840772197
Validation loss: 2.579487053678404

Epoch: 6| Step: 9
Training loss: 1.3302359466355258
Validation loss: 2.5715150433434024

Epoch: 6| Step: 10
Training loss: 1.2742593371711741
Validation loss: 2.588755476318407

Epoch: 6| Step: 11
Training loss: 1.382329306800288
Validation loss: 2.552138301884383

Epoch: 6| Step: 12
Training loss: 1.1817418583153088
Validation loss: 2.5741267081316135

Epoch: 6| Step: 13
Training loss: 1.512412372919667
Validation loss: 2.565956339877002

Epoch: 210| Step: 0
Training loss: 1.3599658427436938
Validation loss: 2.5578095612774754

Epoch: 6| Step: 1
Training loss: 1.2032639064115986
Validation loss: 2.5575293135280983

Epoch: 6| Step: 2
Training loss: 1.3722478894206875
Validation loss: 2.583925374518683

Epoch: 6| Step: 3
Training loss: 1.3119922291508102
Validation loss: 2.562351427590816

Epoch: 6| Step: 4
Training loss: 1.531677342164226
Validation loss: 2.578237533723571

Epoch: 6| Step: 5
Training loss: 1.2187879507562795
Validation loss: 2.581951346949876

Epoch: 6| Step: 6
Training loss: 1.016896552271892
Validation loss: 2.571610715195205

Epoch: 6| Step: 7
Training loss: 0.9367250100277394
Validation loss: 2.5702868725671992

Epoch: 6| Step: 8
Training loss: 1.2692058909252135
Validation loss: 2.575832828859499

Epoch: 6| Step: 9
Training loss: 1.3481563358971362
Validation loss: 2.585924534730623

Epoch: 6| Step: 10
Training loss: 1.813133918138023
Validation loss: 2.5856575336763483

Epoch: 6| Step: 11
Training loss: 0.8475261184021108
Validation loss: 2.5772862635905383

Epoch: 6| Step: 12
Training loss: 1.1978150144929316
Validation loss: 2.584834396742567

Epoch: 6| Step: 13
Training loss: 1.4691467560911768
Validation loss: 2.55842334887839

Epoch: 211| Step: 0
Training loss: 1.5231849656727476
Validation loss: 2.5803263633329068

Epoch: 6| Step: 1
Training loss: 1.205931128222854
Validation loss: 2.5766586195536947

Epoch: 6| Step: 2
Training loss: 0.8599917539489544
Validation loss: 2.5724387736198544

Epoch: 6| Step: 3
Training loss: 1.3526717909265742
Validation loss: 2.5539433903162547

Epoch: 6| Step: 4
Training loss: 1.481604791957694
Validation loss: 2.5646318521262867

Epoch: 6| Step: 5
Training loss: 1.6519373761515788
Validation loss: 2.5846605936906433

Epoch: 6| Step: 6
Training loss: 1.4036522501254456
Validation loss: 2.566007109514712

Epoch: 6| Step: 7
Training loss: 0.9237959293618531
Validation loss: 2.578578136766385

Epoch: 6| Step: 8
Training loss: 1.1081540548320539
Validation loss: 2.594523387092132

Epoch: 6| Step: 9
Training loss: 1.309129474353602
Validation loss: 2.6043056093292245

Epoch: 6| Step: 10
Training loss: 0.9127813310535304
Validation loss: 2.592439943580091

Epoch: 6| Step: 11
Training loss: 1.3440178892443682
Validation loss: 2.599010345598111

Epoch: 6| Step: 12
Training loss: 1.038872149248174
Validation loss: 2.586828020171759

Epoch: 6| Step: 13
Training loss: 1.466629364160638
Validation loss: 2.561853863089811

Epoch: 212| Step: 0
Training loss: 1.1148210551271598
Validation loss: 2.55923755458044

Epoch: 6| Step: 1
Training loss: 1.4660945994051364
Validation loss: 2.5568469154754494

Epoch: 6| Step: 2
Training loss: 0.8745097421765421
Validation loss: 2.5588724645379086

Epoch: 6| Step: 3
Training loss: 1.7946087021278627
Validation loss: 2.549436083648774

Epoch: 6| Step: 4
Training loss: 0.9785737345909975
Validation loss: 2.5664052990257193

Epoch: 6| Step: 5
Training loss: 1.4635663375494665
Validation loss: 2.5647205083149305

Epoch: 6| Step: 6
Training loss: 0.9754088644904945
Validation loss: 2.5700627782373107

Epoch: 6| Step: 7
Training loss: 1.2849906652386103
Validation loss: 2.563782263838207

Epoch: 6| Step: 8
Training loss: 0.9129438157065866
Validation loss: 2.5994060595222637

Epoch: 6| Step: 9
Training loss: 1.1827608709519095
Validation loss: 2.6044005264775576

Epoch: 6| Step: 10
Training loss: 1.323188313305964
Validation loss: 2.609920818699507

Epoch: 6| Step: 11
Training loss: 1.3177070868967466
Validation loss: 2.5971783386118084

Epoch: 6| Step: 12
Training loss: 1.3551007301642197
Validation loss: 2.5965104361486118

Epoch: 6| Step: 13
Training loss: 1.2898624134619654
Validation loss: 2.5954045102707095

Epoch: 213| Step: 0
Training loss: 1.2522525994534128
Validation loss: 2.61855877243603

Epoch: 6| Step: 1
Training loss: 1.1310650205329567
Validation loss: 2.619884880653583

Epoch: 6| Step: 2
Training loss: 0.658449211867373
Validation loss: 2.589632871725509

Epoch: 6| Step: 3
Training loss: 1.8225141971071794
Validation loss: 2.5866589468159025

Epoch: 6| Step: 4
Training loss: 1.1163528632499022
Validation loss: 2.574540547997868

Epoch: 6| Step: 5
Training loss: 1.2257468068600414
Validation loss: 2.5575417050375893

Epoch: 6| Step: 6
Training loss: 1.1354750813614367
Validation loss: 2.567691234739779

Epoch: 6| Step: 7
Training loss: 1.496990044937211
Validation loss: 2.546875448935901

Epoch: 6| Step: 8
Training loss: 1.3157269001186382
Validation loss: 2.521561477710113

Epoch: 6| Step: 9
Training loss: 1.2190308369561003
Validation loss: 2.5391007090329025

Epoch: 6| Step: 10
Training loss: 1.3916978448051687
Validation loss: 2.5425911383225976

Epoch: 6| Step: 11
Training loss: 1.3965702057184333
Validation loss: 2.5534772075437253

Epoch: 6| Step: 12
Training loss: 1.2330596289343392
Validation loss: 2.5523337207255903

Epoch: 6| Step: 13
Training loss: 1.1219291631433381
Validation loss: 2.5781341274145895

Epoch: 214| Step: 0
Training loss: 0.6887219580118619
Validation loss: 2.5800910033942737

Epoch: 6| Step: 1
Training loss: 1.062923066675609
Validation loss: 2.5868241045841214

Epoch: 6| Step: 2
Training loss: 0.8372883799775453
Validation loss: 2.5993443738585937

Epoch: 6| Step: 3
Training loss: 1.6137452278096194
Validation loss: 2.611841091742947

Epoch: 6| Step: 4
Training loss: 1.020911032126641
Validation loss: 2.623186513410875

Epoch: 6| Step: 5
Training loss: 1.570913171467876
Validation loss: 2.630084056633147

Epoch: 6| Step: 6
Training loss: 1.2224937062793821
Validation loss: 2.608473115630149

Epoch: 6| Step: 7
Training loss: 1.1351959410604937
Validation loss: 2.615459539632238

Epoch: 6| Step: 8
Training loss: 1.4600274010268668
Validation loss: 2.605129446588123

Epoch: 6| Step: 9
Training loss: 1.0076672353218166
Validation loss: 2.5896936923559193

Epoch: 6| Step: 10
Training loss: 1.0652535605023068
Validation loss: 2.6174098187790333

Epoch: 6| Step: 11
Training loss: 1.1661517959903436
Validation loss: 2.5554410830191743

Epoch: 6| Step: 12
Training loss: 1.6887842166125135
Validation loss: 2.568060137574337

Epoch: 6| Step: 13
Training loss: 1.6299177729455314
Validation loss: 2.5607867012006627

Epoch: 215| Step: 0
Training loss: 1.60187873509478
Validation loss: 2.5465031925004213

Epoch: 6| Step: 1
Training loss: 0.9568729503268285
Validation loss: 2.551244827420173

Epoch: 6| Step: 2
Training loss: 1.1719869941601702
Validation loss: 2.5599971286311503

Epoch: 6| Step: 3
Training loss: 0.9481171546163842
Validation loss: 2.550006872719196

Epoch: 6| Step: 4
Training loss: 1.3414855329292947
Validation loss: 2.5483078621721766

Epoch: 6| Step: 5
Training loss: 1.010479259846271
Validation loss: 2.549516668886763

Epoch: 6| Step: 6
Training loss: 1.121759409780634
Validation loss: 2.573105573517601

Epoch: 6| Step: 7
Training loss: 1.7580145147590203
Validation loss: 2.553953110063815

Epoch: 6| Step: 8
Training loss: 1.1714692494178167
Validation loss: 2.5647199550479214

Epoch: 6| Step: 9
Training loss: 1.54216303008821
Validation loss: 2.5747580300974398

Epoch: 6| Step: 10
Training loss: 1.202771667516829
Validation loss: 2.581662284273099

Epoch: 6| Step: 11
Training loss: 0.8265334616393542
Validation loss: 2.5772643262636694

Epoch: 6| Step: 12
Training loss: 1.2132376206727593
Validation loss: 2.54410047132163

Epoch: 6| Step: 13
Training loss: 1.1399431672904135
Validation loss: 2.5767772921957754

Epoch: 216| Step: 0
Training loss: 1.1909974944779365
Validation loss: 2.5561458893889446

Epoch: 6| Step: 1
Training loss: 1.0752465342448296
Validation loss: 2.5702940479549685

Epoch: 6| Step: 2
Training loss: 1.4491200374905595
Validation loss: 2.572219751922759

Epoch: 6| Step: 3
Training loss: 1.0251519788325458
Validation loss: 2.5503628089235058

Epoch: 6| Step: 4
Training loss: 0.9245008475040328
Validation loss: 2.543227533637453

Epoch: 6| Step: 5
Training loss: 1.451103034254194
Validation loss: 2.5375134651040603

Epoch: 6| Step: 6
Training loss: 0.8026198702263441
Validation loss: 2.518495295808897

Epoch: 6| Step: 7
Training loss: 1.1421430753947779
Validation loss: 2.5371755080617575

Epoch: 6| Step: 8
Training loss: 1.9429592621636436
Validation loss: 2.554617465458112

Epoch: 6| Step: 9
Training loss: 0.8706949116390915
Validation loss: 2.5393805938954124

Epoch: 6| Step: 10
Training loss: 0.8841345686004406
Validation loss: 2.57949693855876

Epoch: 6| Step: 11
Training loss: 1.053779663446744
Validation loss: 2.6032351669176474

Epoch: 6| Step: 12
Training loss: 1.4638877902830096
Validation loss: 2.615911511085487

Epoch: 6| Step: 13
Training loss: 1.2795290670726815
Validation loss: 2.6022640249245734

Epoch: 217| Step: 0
Training loss: 1.2295278191042913
Validation loss: 2.5923616078871605

Epoch: 6| Step: 1
Training loss: 1.1362213409804724
Validation loss: 2.5864077370597958

Epoch: 6| Step: 2
Training loss: 1.0749368382905513
Validation loss: 2.5863542098636794

Epoch: 6| Step: 3
Training loss: 0.9959007525000979
Validation loss: 2.6082801361566856

Epoch: 6| Step: 4
Training loss: 1.6062518435219009
Validation loss: 2.567348031034978

Epoch: 6| Step: 5
Training loss: 0.7378525877115475
Validation loss: 2.5646112120235736

Epoch: 6| Step: 6
Training loss: 0.8921597625108489
Validation loss: 2.554614898421705

Epoch: 6| Step: 7
Training loss: 0.9792492946634876
Validation loss: 2.540800643702162

Epoch: 6| Step: 8
Training loss: 0.7315172636246502
Validation loss: 2.5487991423768945

Epoch: 6| Step: 9
Training loss: 1.1031812313109852
Validation loss: 2.5518271951591713

Epoch: 6| Step: 10
Training loss: 1.3281569533150666
Validation loss: 2.56355612135727

Epoch: 6| Step: 11
Training loss: 1.475537706416217
Validation loss: 2.5560238787902785

Epoch: 6| Step: 12
Training loss: 1.5902995737831913
Validation loss: 2.5359249497087037

Epoch: 6| Step: 13
Training loss: 1.5650182648589253
Validation loss: 2.5611913036904155

Epoch: 218| Step: 0
Training loss: 1.2880111105747691
Validation loss: 2.563322273982734

Epoch: 6| Step: 1
Training loss: 1.4173809756408622
Validation loss: 2.5625218046087532

Epoch: 6| Step: 2
Training loss: 1.2130332776888095
Validation loss: 2.5982293090781856

Epoch: 6| Step: 3
Training loss: 0.9529543239178969
Validation loss: 2.5891970107801217

Epoch: 6| Step: 4
Training loss: 0.977775339387854
Validation loss: 2.57449964358613

Epoch: 6| Step: 5
Training loss: 0.6687931305355135
Validation loss: 2.5958752929786315

Epoch: 6| Step: 6
Training loss: 1.3519526012367837
Validation loss: 2.576340465376024

Epoch: 6| Step: 7
Training loss: 0.8291073856216666
Validation loss: 2.587455896325974

Epoch: 6| Step: 8
Training loss: 1.570240835196174
Validation loss: 2.5777421837988546

Epoch: 6| Step: 9
Training loss: 1.3517838666147022
Validation loss: 2.5454019221829425

Epoch: 6| Step: 10
Training loss: 1.082295244423341
Validation loss: 2.5252793483154794

Epoch: 6| Step: 11
Training loss: 1.0076836200486334
Validation loss: 2.5388049337218717

Epoch: 6| Step: 12
Training loss: 1.4870048917114
Validation loss: 2.510013352024276

Epoch: 6| Step: 13
Training loss: 0.8373446163821485
Validation loss: 2.5324526853684395

Epoch: 219| Step: 0
Training loss: 1.1302369402709125
Validation loss: 2.5093102447205418

Epoch: 6| Step: 1
Training loss: 1.32503855487223
Validation loss: 2.5124882352954847

Epoch: 6| Step: 2
Training loss: 0.779737610821574
Validation loss: 2.5120122040840505

Epoch: 6| Step: 3
Training loss: 1.1355563903136978
Validation loss: 2.5196792450963423

Epoch: 6| Step: 4
Training loss: 0.6426953379854139
Validation loss: 2.5028213823806555

Epoch: 6| Step: 5
Training loss: 1.0557901905240739
Validation loss: 2.5488668243094224

Epoch: 6| Step: 6
Training loss: 1.137961321336016
Validation loss: 2.582279584511777

Epoch: 6| Step: 7
Training loss: 1.185228182395733
Validation loss: 2.6048197252699343

Epoch: 6| Step: 8
Training loss: 1.5357813060115066
Validation loss: 2.6185849172306845

Epoch: 6| Step: 9
Training loss: 0.9765005778707971
Validation loss: 2.6405974074371876

Epoch: 6| Step: 10
Training loss: 1.2805034043915882
Validation loss: 2.6548794515566634

Epoch: 6| Step: 11
Training loss: 1.8552216375331918
Validation loss: 2.6462930330515277

Epoch: 6| Step: 12
Training loss: 0.9619697051244755
Validation loss: 2.6262920440313238

Epoch: 6| Step: 13
Training loss: 0.9175971070230704
Validation loss: 2.617740689817698

Epoch: 220| Step: 0
Training loss: 1.2740056929229067
Validation loss: 2.613569912285994

Epoch: 6| Step: 1
Training loss: 1.165027858171841
Validation loss: 2.5974219599667863

Epoch: 6| Step: 2
Training loss: 1.3550863908486455
Validation loss: 2.536909472403021

Epoch: 6| Step: 3
Training loss: 1.233187333478042
Validation loss: 2.523878399290531

Epoch: 6| Step: 4
Training loss: 0.7565070243579928
Validation loss: 2.4831599889481857

Epoch: 6| Step: 5
Training loss: 0.9601318890155961
Validation loss: 2.46569818250096

Epoch: 6| Step: 6
Training loss: 0.8738150747839836
Validation loss: 2.4902279963483034

Epoch: 6| Step: 7
Training loss: 1.1825894164298392
Validation loss: 2.4767226735457406

Epoch: 6| Step: 8
Training loss: 1.29344809137742
Validation loss: 2.473529436965238

Epoch: 6| Step: 9
Training loss: 0.8033014600875618
Validation loss: 2.481066942290491

Epoch: 6| Step: 10
Training loss: 1.2017631750112712
Validation loss: 2.499483199180494

Epoch: 6| Step: 11
Training loss: 1.8637498949998792
Validation loss: 2.525335894831166

Epoch: 6| Step: 12
Training loss: 1.1914507748147898
Validation loss: 2.53622658496202

Epoch: 6| Step: 13
Training loss: 0.6527503339824312
Validation loss: 2.552932725149568

Epoch: 221| Step: 0
Training loss: 1.036916481370201
Validation loss: 2.5490954737796523

Epoch: 6| Step: 1
Training loss: 1.3555265298890435
Validation loss: 2.571075789911348

Epoch: 6| Step: 2
Training loss: 0.5544410749192672
Validation loss: 2.5743403463842993

Epoch: 6| Step: 3
Training loss: 0.955210358684449
Validation loss: 2.5901311958847106

Epoch: 6| Step: 4
Training loss: 1.0509577606453289
Validation loss: 2.571075634362471

Epoch: 6| Step: 5
Training loss: 1.2786589684624257
Validation loss: 2.5984254287769755

Epoch: 6| Step: 6
Training loss: 0.8065336216482988
Validation loss: 2.565756032986334

Epoch: 6| Step: 7
Training loss: 0.9777239187415315
Validation loss: 2.5829716196654595

Epoch: 6| Step: 8
Training loss: 1.366882202938796
Validation loss: 2.54287143344202

Epoch: 6| Step: 9
Training loss: 1.6832475416901207
Validation loss: 2.5590794381376782

Epoch: 6| Step: 10
Training loss: 0.7481118913488404
Validation loss: 2.5259606728457538

Epoch: 6| Step: 11
Training loss: 1.0159838702656123
Validation loss: 2.547807378999794

Epoch: 6| Step: 12
Training loss: 1.757851833327294
Validation loss: 2.55593917172018

Epoch: 6| Step: 13
Training loss: 0.9488712820805163
Validation loss: 2.5685234018382586

Epoch: 222| Step: 0
Training loss: 1.4135531356372486
Validation loss: 2.5993099771693946

Epoch: 6| Step: 1
Training loss: 0.7988599477086137
Validation loss: 2.58397911424129

Epoch: 6| Step: 2
Training loss: 1.3410050500352229
Validation loss: 2.5794521462113638

Epoch: 6| Step: 3
Training loss: 0.9164419585130373
Validation loss: 2.593145418876119

Epoch: 6| Step: 4
Training loss: 0.7783794308829279
Validation loss: 2.6163393931556906

Epoch: 6| Step: 5
Training loss: 1.0179936883876874
Validation loss: 2.632298616054817

Epoch: 6| Step: 6
Training loss: 1.1518308370882662
Validation loss: 2.6164908483360287

Epoch: 6| Step: 7
Training loss: 1.211275361211899
Validation loss: 2.59401622146773

Epoch: 6| Step: 8
Training loss: 0.8401020451278686
Validation loss: 2.5877977545480166

Epoch: 6| Step: 9
Training loss: 1.026838809470932
Validation loss: 2.5894340854723024

Epoch: 6| Step: 10
Training loss: 0.7559873487382786
Validation loss: 2.594710400425457

Epoch: 6| Step: 11
Training loss: 1.9106367946032348
Validation loss: 2.5609363489260346

Epoch: 6| Step: 12
Training loss: 1.3520799649534112
Validation loss: 2.550135347746304

Epoch: 6| Step: 13
Training loss: 1.1821937968655871
Validation loss: 2.5431654364336556

Epoch: 223| Step: 0
Training loss: 0.6293081101421562
Validation loss: 2.551419377468615

Epoch: 6| Step: 1
Training loss: 0.9925194132561376
Validation loss: 2.5622436301150744

Epoch: 6| Step: 2
Training loss: 1.0323360966046107
Validation loss: 2.5907718181773687

Epoch: 6| Step: 3
Training loss: 1.006858137239346
Validation loss: 2.5687133580060433

Epoch: 6| Step: 4
Training loss: 0.9442935843373688
Validation loss: 2.5905714706403953

Epoch: 6| Step: 5
Training loss: 1.1477051040918818
Validation loss: 2.5952272385635298

Epoch: 6| Step: 6
Training loss: 1.0077974776693501
Validation loss: 2.584958940110345

Epoch: 6| Step: 7
Training loss: 0.8953521826240026
Validation loss: 2.611964506383929

Epoch: 6| Step: 8
Training loss: 1.3528713878451901
Validation loss: 2.590030444982179

Epoch: 6| Step: 9
Training loss: 1.055774721738271
Validation loss: 2.588826438154914

Epoch: 6| Step: 10
Training loss: 0.9420110255728009
Validation loss: 2.5760892624841834

Epoch: 6| Step: 11
Training loss: 1.7123286892485927
Validation loss: 2.573284788593018

Epoch: 6| Step: 12
Training loss: 1.257495058175116
Validation loss: 2.570293847475265

Epoch: 6| Step: 13
Training loss: 1.420224415950732
Validation loss: 2.5611420131237903

Epoch: 224| Step: 0
Training loss: 1.0572194542990305
Validation loss: 2.5341966432972365

Epoch: 6| Step: 1
Training loss: 1.6024279233342138
Validation loss: 2.5231115004316216

Epoch: 6| Step: 2
Training loss: 0.8494755080421258
Validation loss: 2.521900668693863

Epoch: 6| Step: 3
Training loss: 1.110398693309037
Validation loss: 2.5319875855101586

Epoch: 6| Step: 4
Training loss: 1.2440774802767562
Validation loss: 2.532553885014517

Epoch: 6| Step: 5
Training loss: 0.9705469631405984
Validation loss: 2.567811608720642

Epoch: 6| Step: 6
Training loss: 1.2450083247446466
Validation loss: 2.5719733795590902

Epoch: 6| Step: 7
Training loss: 1.3523429425444857
Validation loss: 2.575446513993561

Epoch: 6| Step: 8
Training loss: 0.8426423042624547
Validation loss: 2.5665752690932493

Epoch: 6| Step: 9
Training loss: 1.3959592031786197
Validation loss: 2.5829346690233512

Epoch: 6| Step: 10
Training loss: 0.9621553844458047
Validation loss: 2.5642619794534514

Epoch: 6| Step: 11
Training loss: 0.9279338421464624
Validation loss: 2.5811648865817816

Epoch: 6| Step: 12
Training loss: 0.9046322754655255
Validation loss: 2.5561015654256596

Epoch: 6| Step: 13
Training loss: 0.8419395732965966
Validation loss: 2.570643302744397

Epoch: 225| Step: 0
Training loss: 1.2148460559884415
Validation loss: 2.583804759048029

Epoch: 6| Step: 1
Training loss: 0.6904097881983614
Validation loss: 2.5455865722034847

Epoch: 6| Step: 2
Training loss: 1.282413419660197
Validation loss: 2.5508669022061112

Epoch: 6| Step: 3
Training loss: 0.9409968328757099
Validation loss: 2.5546737850659365

Epoch: 6| Step: 4
Training loss: 1.70672031949069
Validation loss: 2.5396149095445844

Epoch: 6| Step: 5
Training loss: 1.1584776991935617
Validation loss: 2.555519137480442

Epoch: 6| Step: 6
Training loss: 1.2173970366537001
Validation loss: 2.549798711741917

Epoch: 6| Step: 7
Training loss: 1.0492711898412785
Validation loss: 2.5635758274311717

Epoch: 6| Step: 8
Training loss: 0.9174421057768386
Validation loss: 2.56312708631318

Epoch: 6| Step: 9
Training loss: 0.8467811602864019
Validation loss: 2.554101299762364

Epoch: 6| Step: 10
Training loss: 1.2444395367964598
Validation loss: 2.5541287096081797

Epoch: 6| Step: 11
Training loss: 0.8070127723255083
Validation loss: 2.542577081869575

Epoch: 6| Step: 12
Training loss: 0.8829801957187342
Validation loss: 2.5409961424860836

Epoch: 6| Step: 13
Training loss: 1.0304344304568274
Validation loss: 2.5628033410186037

Epoch: 226| Step: 0
Training loss: 0.8775631963899478
Validation loss: 2.5671425199964273

Epoch: 6| Step: 1
Training loss: 1.1428446662596454
Validation loss: 2.555115788960232

Epoch: 6| Step: 2
Training loss: 1.1316064136141335
Validation loss: 2.580315952074549

Epoch: 6| Step: 3
Training loss: 0.9203374616414507
Validation loss: 2.5781563884655254

Epoch: 6| Step: 4
Training loss: 1.1961659395345818
Validation loss: 2.5832566068954006

Epoch: 6| Step: 5
Training loss: 1.1361098084031658
Validation loss: 2.58011049127041

Epoch: 6| Step: 6
Training loss: 1.1341570011561382
Validation loss: 2.568512582422325

Epoch: 6| Step: 7
Training loss: 0.9302065706538936
Validation loss: 2.584096293429686

Epoch: 6| Step: 8
Training loss: 0.8804532148722023
Validation loss: 2.5471218504622333

Epoch: 6| Step: 9
Training loss: 0.9567382986939559
Validation loss: 2.563120470979459

Epoch: 6| Step: 10
Training loss: 0.9763323703455927
Validation loss: 2.5494562985754023

Epoch: 6| Step: 11
Training loss: 1.0235806430565038
Validation loss: 2.5612300161344406

Epoch: 6| Step: 12
Training loss: 0.8209164167527776
Validation loss: 2.5787784547523156

Epoch: 6| Step: 13
Training loss: 2.156732035397482
Validation loss: 2.5463916111725093

Epoch: 227| Step: 0
Training loss: 0.9332742184128684
Validation loss: 2.546074946993521

Epoch: 6| Step: 1
Training loss: 0.7991125817505771
Validation loss: 2.570378724794866

Epoch: 6| Step: 2
Training loss: 1.2449604489275636
Validation loss: 2.5622627254495844

Epoch: 6| Step: 3
Training loss: 0.6458969443793928
Validation loss: 2.5500703233725286

Epoch: 6| Step: 4
Training loss: 1.063510918740993
Validation loss: 2.5659322510229874

Epoch: 6| Step: 5
Training loss: 1.158753751483264
Validation loss: 2.5957532209789655

Epoch: 6| Step: 6
Training loss: 0.883444028492228
Validation loss: 2.5968075731769384

Epoch: 6| Step: 7
Training loss: 0.8680672178544657
Validation loss: 2.5797444805424825

Epoch: 6| Step: 8
Training loss: 1.2488837026018522
Validation loss: 2.568583731223727

Epoch: 6| Step: 9
Training loss: 1.2448634468781268
Validation loss: 2.578561866516218

Epoch: 6| Step: 10
Training loss: 1.1757120511295807
Validation loss: 2.558340467866799

Epoch: 6| Step: 11
Training loss: 1.1754758824836
Validation loss: 2.552210276805227

Epoch: 6| Step: 12
Training loss: 0.7447327588311551
Validation loss: 2.5807344666661662

Epoch: 6| Step: 13
Training loss: 1.8882648459413656
Validation loss: 2.57235408785354

Epoch: 228| Step: 0
Training loss: 1.1305199411819207
Validation loss: 2.576167870570779

Epoch: 6| Step: 1
Training loss: 0.8930202532689646
Validation loss: 2.5725886179909474

Epoch: 6| Step: 2
Training loss: 0.7434221137989361
Validation loss: 2.565784855041691

Epoch: 6| Step: 3
Training loss: 1.1213146882550125
Validation loss: 2.5922766774725474

Epoch: 6| Step: 4
Training loss: 0.8399296561373838
Validation loss: 2.5974627906125245

Epoch: 6| Step: 5
Training loss: 1.0196617306052238
Validation loss: 2.606692802258941

Epoch: 6| Step: 6
Training loss: 0.7924438016803234
Validation loss: 2.599213713728255

Epoch: 6| Step: 7
Training loss: 1.0314015363849338
Validation loss: 2.6134245924065693

Epoch: 6| Step: 8
Training loss: 1.0072224390383042
Validation loss: 2.583924239499243

Epoch: 6| Step: 9
Training loss: 1.1583565261403401
Validation loss: 2.6189994787744184

Epoch: 6| Step: 10
Training loss: 0.9417477063666784
Validation loss: 2.5989988235383032

Epoch: 6| Step: 11
Training loss: 0.9692468292090006
Validation loss: 2.5951706066989315

Epoch: 6| Step: 12
Training loss: 1.1211103378291551
Validation loss: 2.6099817647451347

Epoch: 6| Step: 13
Training loss: 2.1854924390352672
Validation loss: 2.602224971007022

Epoch: 229| Step: 0
Training loss: 1.877286724569075
Validation loss: 2.5850137100781247

Epoch: 6| Step: 1
Training loss: 0.7559942080866244
Validation loss: 2.5704059251590796

Epoch: 6| Step: 2
Training loss: 1.1676729267797237
Validation loss: 2.5582258783992415

Epoch: 6| Step: 3
Training loss: 1.279914718409538
Validation loss: 2.56180578713168

Epoch: 6| Step: 4
Training loss: 0.6852693566598369
Validation loss: 2.5596580242605405

Epoch: 6| Step: 5
Training loss: 1.0108243899619354
Validation loss: 2.562444058499707

Epoch: 6| Step: 6
Training loss: 0.9409029553120781
Validation loss: 2.5696718681975077

Epoch: 6| Step: 7
Training loss: 0.8363995923754165
Validation loss: 2.5550525248080302

Epoch: 6| Step: 8
Training loss: 0.9138777782579011
Validation loss: 2.5526753170750522

Epoch: 6| Step: 9
Training loss: 1.3533077988697733
Validation loss: 2.56875192839596

Epoch: 6| Step: 10
Training loss: 0.680281631547424
Validation loss: 2.5492302680092487

Epoch: 6| Step: 11
Training loss: 0.7182808464402664
Validation loss: 2.5600480905529133

Epoch: 6| Step: 12
Training loss: 0.9971489198131877
Validation loss: 2.58744457249511

Epoch: 6| Step: 13
Training loss: 0.8039167101358401
Validation loss: 2.573227048156379

Epoch: 230| Step: 0
Training loss: 1.2826970930145505
Validation loss: 2.5666004910972138

Epoch: 6| Step: 1
Training loss: 0.48015863598604064
Validation loss: 2.5641868265665413

Epoch: 6| Step: 2
Training loss: 0.7712524065323292
Validation loss: 2.5628661857736486

Epoch: 6| Step: 3
Training loss: 1.5782336962441041
Validation loss: 2.547815870429503

Epoch: 6| Step: 4
Training loss: 1.0297361301637364
Validation loss: 2.5572546580794784

Epoch: 6| Step: 5
Training loss: 1.2866653811163402
Validation loss: 2.5585331439721677

Epoch: 6| Step: 6
Training loss: 1.1250548879161295
Validation loss: 2.5661745954389006

Epoch: 6| Step: 7
Training loss: 1.009162353697511
Validation loss: 2.536158247288702

Epoch: 6| Step: 8
Training loss: 0.9699931628192735
Validation loss: 2.567217348689784

Epoch: 6| Step: 9
Training loss: 0.5617748460626928
Validation loss: 2.574646778881666

Epoch: 6| Step: 10
Training loss: 0.9770979672104035
Validation loss: 2.550595500539548

Epoch: 6| Step: 11
Training loss: 0.7816007970969862
Validation loss: 2.5555483127403376

Epoch: 6| Step: 12
Training loss: 1.19957258241974
Validation loss: 2.547845181190543

Epoch: 6| Step: 13
Training loss: 1.176700372204171
Validation loss: 2.605111031542824

Epoch: 231| Step: 0
Training loss: 1.493718984114287
Validation loss: 2.5688712656880623

Epoch: 6| Step: 1
Training loss: 1.056646040304977
Validation loss: 2.5940215503226516

Epoch: 6| Step: 2
Training loss: 0.962601871796656
Validation loss: 2.563726256320548

Epoch: 6| Step: 3
Training loss: 1.1618050826008963
Validation loss: 2.5642876810953656

Epoch: 6| Step: 4
Training loss: 0.9376735526613053
Validation loss: 2.5919737661176803

Epoch: 6| Step: 5
Training loss: 0.7841575685946915
Validation loss: 2.589022350975928

Epoch: 6| Step: 6
Training loss: 1.330777918251689
Validation loss: 2.595445812201173

Epoch: 6| Step: 7
Training loss: 1.0733875179731407
Validation loss: 2.597601576846652

Epoch: 6| Step: 8
Training loss: 0.8039404354852967
Validation loss: 2.5832423876560027

Epoch: 6| Step: 9
Training loss: 0.7940528487122278
Validation loss: 2.619928035507054

Epoch: 6| Step: 10
Training loss: 1.03401956588414
Validation loss: 2.605893104648969

Epoch: 6| Step: 11
Training loss: 1.2019949721328005
Validation loss: 2.601519679057973

Epoch: 6| Step: 12
Training loss: 0.7857785771435032
Validation loss: 2.612940078513697

Epoch: 6| Step: 13
Training loss: 0.9417175791207645
Validation loss: 2.6100253298786855

Epoch: 232| Step: 0
Training loss: 1.8697028674731526
Validation loss: 2.612942848249497

Epoch: 6| Step: 1
Training loss: 1.0974975145350925
Validation loss: 2.6399856437039193

Epoch: 6| Step: 2
Training loss: 1.1527249497765464
Validation loss: 2.622404300594439

Epoch: 6| Step: 3
Training loss: 1.0531205581888314
Validation loss: 2.614735038607337

Epoch: 6| Step: 4
Training loss: 1.112181431452848
Validation loss: 2.6004242603736314

Epoch: 6| Step: 5
Training loss: 0.5464288253854825
Validation loss: 2.576905177692709

Epoch: 6| Step: 6
Training loss: 0.880214819047196
Validation loss: 2.5746427056156507

Epoch: 6| Step: 7
Training loss: 1.0736956623259435
Validation loss: 2.564443302094335

Epoch: 6| Step: 8
Training loss: 0.923538130232734
Validation loss: 2.5718219642412454

Epoch: 6| Step: 9
Training loss: 0.707046276796947
Validation loss: 2.571019388867079

Epoch: 6| Step: 10
Training loss: 0.9803378561119425
Validation loss: 2.5849591067248343

Epoch: 6| Step: 11
Training loss: 0.7456097455954409
Validation loss: 2.552638581685603

Epoch: 6| Step: 12
Training loss: 1.034995070090969
Validation loss: 2.555843929833712

Epoch: 6| Step: 13
Training loss: 1.1611572981707843
Validation loss: 2.5975973261527234

Epoch: 233| Step: 0
Training loss: 0.7718754417016622
Validation loss: 2.5772979394164026

Epoch: 6| Step: 1
Training loss: 0.8291414249034945
Validation loss: 2.5923065051221323

Epoch: 6| Step: 2
Training loss: 1.0478775006983052
Validation loss: 2.569985101148384

Epoch: 6| Step: 3
Training loss: 0.9724389258577196
Validation loss: 2.5647893833777413

Epoch: 6| Step: 4
Training loss: 0.9621976637667401
Validation loss: 2.5740390890232026

Epoch: 6| Step: 5
Training loss: 0.8830385509491139
Validation loss: 2.562596926292924

Epoch: 6| Step: 6
Training loss: 0.8540635434370091
Validation loss: 2.5904337229677483

Epoch: 6| Step: 7
Training loss: 0.7809573960717816
Validation loss: 2.5619060028993124

Epoch: 6| Step: 8
Training loss: 1.787040534022454
Validation loss: 2.57734192769987

Epoch: 6| Step: 9
Training loss: 0.904560619146969
Validation loss: 2.581616181944541

Epoch: 6| Step: 10
Training loss: 1.3278289464954147
Validation loss: 2.5759293410489783

Epoch: 6| Step: 11
Training loss: 0.9345874047385548
Validation loss: 2.578593522075023

Epoch: 6| Step: 12
Training loss: 1.1361860357562907
Validation loss: 2.5632819886634435

Epoch: 6| Step: 13
Training loss: 0.5480784933875956
Validation loss: 2.564690072954441

Epoch: 234| Step: 0
Training loss: 0.9122209827829239
Validation loss: 2.531830925202197

Epoch: 6| Step: 1
Training loss: 0.6540666317433346
Validation loss: 2.5806829178647632

Epoch: 6| Step: 2
Training loss: 0.7308177828103977
Validation loss: 2.592469816817442

Epoch: 6| Step: 3
Training loss: 0.9909587670879866
Validation loss: 2.5441962175651014

Epoch: 6| Step: 4
Training loss: 1.7820650879332705
Validation loss: 2.5703050483819765

Epoch: 6| Step: 5
Training loss: 0.9190693203057884
Validation loss: 2.5535945540726277

Epoch: 6| Step: 6
Training loss: 0.9684441298940728
Validation loss: 2.5773668670410834

Epoch: 6| Step: 7
Training loss: 0.7153239903958271
Validation loss: 2.591286213687969

Epoch: 6| Step: 8
Training loss: 1.1997768830460924
Validation loss: 2.589773511944911

Epoch: 6| Step: 9
Training loss: 0.8397918685146939
Validation loss: 2.56844193570605

Epoch: 6| Step: 10
Training loss: 0.9734120324295051
Validation loss: 2.5606100644772924

Epoch: 6| Step: 11
Training loss: 1.0603133870151182
Validation loss: 2.5565102928155317

Epoch: 6| Step: 12
Training loss: 0.851296409540571
Validation loss: 2.5681370605614884

Epoch: 6| Step: 13
Training loss: 1.203024525596129
Validation loss: 2.599572444876052

Epoch: 235| Step: 0
Training loss: 0.7568883077898979
Validation loss: 2.606632370401241

Epoch: 6| Step: 1
Training loss: 1.030561101446684
Validation loss: 2.6282579339677183

Epoch: 6| Step: 2
Training loss: 0.6699142900487953
Validation loss: 2.5663405250605065

Epoch: 6| Step: 3
Training loss: 1.0662638251245735
Validation loss: 2.5630228293084496

Epoch: 6| Step: 4
Training loss: 1.1254368040017333
Validation loss: 2.5706146987176446

Epoch: 6| Step: 5
Training loss: 1.1417421592107395
Validation loss: 2.550078602182007

Epoch: 6| Step: 6
Training loss: 1.079313424832962
Validation loss: 2.564158222501144

Epoch: 6| Step: 7
Training loss: 0.8067717734212961
Validation loss: 2.5618597742028455

Epoch: 6| Step: 8
Training loss: 0.9566271804730887
Validation loss: 2.5359572931719643

Epoch: 6| Step: 9
Training loss: 0.7398215881702107
Validation loss: 2.5291783119305635

Epoch: 6| Step: 10
Training loss: 0.95720244452965
Validation loss: 2.5243571551217654

Epoch: 6| Step: 11
Training loss: 1.7808282587136472
Validation loss: 2.5350676298172323

Epoch: 6| Step: 12
Training loss: 0.5619334970984426
Validation loss: 2.511156656189384

Epoch: 6| Step: 13
Training loss: 0.7373512505992337
Validation loss: 2.5306371556916587

Epoch: 236| Step: 0
Training loss: 1.0023865831102847
Validation loss: 2.5065234320113134

Epoch: 6| Step: 1
Training loss: 0.6419977738543861
Validation loss: 2.5064004592631566

Epoch: 6| Step: 2
Training loss: 1.2659248656144089
Validation loss: 2.5138456706163432

Epoch: 6| Step: 3
Training loss: 0.9598370585642259
Validation loss: 2.5201834384396187

Epoch: 6| Step: 4
Training loss: 0.7258110262015642
Validation loss: 2.503372127991602

Epoch: 6| Step: 5
Training loss: 0.9804549197251191
Validation loss: 2.5219929159599266

Epoch: 6| Step: 6
Training loss: 1.019294097328217
Validation loss: 2.5435744444582795

Epoch: 6| Step: 7
Training loss: 1.0431825797232532
Validation loss: 2.555504869741184

Epoch: 6| Step: 8
Training loss: 1.5369679096274618
Validation loss: 2.544583014369167

Epoch: 6| Step: 9
Training loss: 0.47846139094466383
Validation loss: 2.5246139461514048

Epoch: 6| Step: 10
Training loss: 0.872818475327899
Validation loss: 2.5487036266353953

Epoch: 6| Step: 11
Training loss: 0.7950245933807332
Validation loss: 2.5450380204201393

Epoch: 6| Step: 12
Training loss: 1.2894111855292871
Validation loss: 2.546911004206622

Epoch: 6| Step: 13
Training loss: 0.5771542208360831
Validation loss: 2.5601339864837542

Epoch: 237| Step: 0
Training loss: 0.9334692453018677
Validation loss: 2.546160436328468

Epoch: 6| Step: 1
Training loss: 0.9025564232093283
Validation loss: 2.5037826572342174

Epoch: 6| Step: 2
Training loss: 0.938962177623945
Validation loss: 2.513565168936409

Epoch: 6| Step: 3
Training loss: 0.7352524648817681
Validation loss: 2.5145502420653703

Epoch: 6| Step: 4
Training loss: 1.101248189034851
Validation loss: 2.5075011386074766

Epoch: 6| Step: 5
Training loss: 1.0275662837495103
Validation loss: 2.530258442285146

Epoch: 6| Step: 6
Training loss: 0.8335594506254792
Validation loss: 2.5244303603231426

Epoch: 6| Step: 7
Training loss: 1.0827447625092776
Validation loss: 2.532569786790407

Epoch: 6| Step: 8
Training loss: 1.128068395235377
Validation loss: 2.536817133923791

Epoch: 6| Step: 9
Training loss: 0.9253577700346373
Validation loss: 2.5670243297176722

Epoch: 6| Step: 10
Training loss: 1.5595574709865805
Validation loss: 2.5397236170159347

Epoch: 6| Step: 11
Training loss: 0.8519682311372094
Validation loss: 2.5468096890490846

Epoch: 6| Step: 12
Training loss: 0.8222010353798217
Validation loss: 2.5399328747071093

Epoch: 6| Step: 13
Training loss: 0.6587922038216315
Validation loss: 2.55580811265404

Epoch: 238| Step: 0
Training loss: 0.6237784129993126
Validation loss: 2.5434017206919863

Epoch: 6| Step: 1
Training loss: 1.3376707021571743
Validation loss: 2.528954852284411

Epoch: 6| Step: 2
Training loss: 1.096693057541775
Validation loss: 2.5345343163096103

Epoch: 6| Step: 3
Training loss: 0.7626834336062774
Validation loss: 2.534796568377277

Epoch: 6| Step: 4
Training loss: 0.8441158490514634
Validation loss: 2.5000398068694145

Epoch: 6| Step: 5
Training loss: 0.7762383504045609
Validation loss: 2.4746619586078102

Epoch: 6| Step: 6
Training loss: 0.6984870534637749
Validation loss: 2.476667579022795

Epoch: 6| Step: 7
Training loss: 1.6570309651116932
Validation loss: 2.494893309703936

Epoch: 6| Step: 8
Training loss: 0.8973745941701062
Validation loss: 2.473247726446964

Epoch: 6| Step: 9
Training loss: 1.2447481453708027
Validation loss: 2.490891762072532

Epoch: 6| Step: 10
Training loss: 1.1331567175540112
Validation loss: 2.511491130883287

Epoch: 6| Step: 11
Training loss: 0.6915791828678939
Validation loss: 2.54970099829327

Epoch: 6| Step: 12
Training loss: 0.7199303430399714
Validation loss: 2.5652845986454866

Epoch: 6| Step: 13
Training loss: 1.469853250613347
Validation loss: 2.572635480994714

Epoch: 239| Step: 0
Training loss: 1.1650339463817885
Validation loss: 2.599823304570297

Epoch: 6| Step: 1
Training loss: 1.1955412602150999
Validation loss: 2.6048331673185783

Epoch: 6| Step: 2
Training loss: 0.8271768288091575
Validation loss: 2.556254428402672

Epoch: 6| Step: 3
Training loss: 1.2272761995895791
Validation loss: 2.5410615357672195

Epoch: 6| Step: 4
Training loss: 0.9542363675797481
Validation loss: 2.5496181720929587

Epoch: 6| Step: 5
Training loss: 0.9342326129115092
Validation loss: 2.4843591024104663

Epoch: 6| Step: 6
Training loss: 0.7735630280325761
Validation loss: 2.5143638674587163

Epoch: 6| Step: 7
Training loss: 0.9537133449045171
Validation loss: 2.4790091271074934

Epoch: 6| Step: 8
Training loss: 1.1486349130788691
Validation loss: 2.465332897206933

Epoch: 6| Step: 9
Training loss: 0.8983590796702624
Validation loss: 2.4751695358176757

Epoch: 6| Step: 10
Training loss: 0.9358450269152516
Validation loss: 2.485149431816151

Epoch: 6| Step: 11
Training loss: 1.0118001662085858
Validation loss: 2.48667253020102

Epoch: 6| Step: 12
Training loss: 1.5464152413891488
Validation loss: 2.497190519099075

Epoch: 6| Step: 13
Training loss: 0.6020482814269751
Validation loss: 2.508395454663083

Epoch: 240| Step: 0
Training loss: 1.004749226194199
Validation loss: 2.5082515250103423

Epoch: 6| Step: 1
Training loss: 0.44147868954560704
Validation loss: 2.5077902697988383

Epoch: 6| Step: 2
Training loss: 1.2239381937304448
Validation loss: 2.54198653980227

Epoch: 6| Step: 3
Training loss: 0.7910163031681121
Validation loss: 2.551466451445106

Epoch: 6| Step: 4
Training loss: 1.6373616778941817
Validation loss: 2.5838304076823118

Epoch: 6| Step: 5
Training loss: 0.8601055161484529
Validation loss: 2.616802964959474

Epoch: 6| Step: 6
Training loss: 0.5699235295146853
Validation loss: 2.5942603067756256

Epoch: 6| Step: 7
Training loss: 0.9497530967700073
Validation loss: 2.603066564380534

Epoch: 6| Step: 8
Training loss: 1.3122636491411235
Validation loss: 2.5906092613733005

Epoch: 6| Step: 9
Training loss: 0.8525628330198463
Validation loss: 2.597665022586107

Epoch: 6| Step: 10
Training loss: 0.8169785460359867
Validation loss: 2.5864261930896153

Epoch: 6| Step: 11
Training loss: 0.9902556227110514
Validation loss: 2.5753618056861964

Epoch: 6| Step: 12
Training loss: 0.698802141929416
Validation loss: 2.5478165848392913

Epoch: 6| Step: 13
Training loss: 0.8871553329328123
Validation loss: 2.5688807004208902

Epoch: 241| Step: 0
Training loss: 0.6693889622518829
Validation loss: 2.5586050722644607

Epoch: 6| Step: 1
Training loss: 1.8210639548595207
Validation loss: 2.56255141135885

Epoch: 6| Step: 2
Training loss: 1.1600530816133563
Validation loss: 2.52026415950061

Epoch: 6| Step: 3
Training loss: 0.6015258381558652
Validation loss: 2.495307881458906

Epoch: 6| Step: 4
Training loss: 0.9695912676853918
Validation loss: 2.4948457468022482

Epoch: 6| Step: 5
Training loss: 1.0354442267840385
Validation loss: 2.4943020542462877

Epoch: 6| Step: 6
Training loss: 0.7929640520830472
Validation loss: 2.493897808780262

Epoch: 6| Step: 7
Training loss: 0.7698195638664687
Validation loss: 2.4668859877635594

Epoch: 6| Step: 8
Training loss: 1.0302023912855658
Validation loss: 2.4951586165198636

Epoch: 6| Step: 9
Training loss: 0.9557774953377092
Validation loss: 2.4799371244129187

Epoch: 6| Step: 10
Training loss: 0.864267260828474
Validation loss: 2.4872299747353446

Epoch: 6| Step: 11
Training loss: 0.6143226286103297
Validation loss: 2.5119740580888776

Epoch: 6| Step: 12
Training loss: 0.9390719586243531
Validation loss: 2.510642537371357

Epoch: 6| Step: 13
Training loss: 0.8015012899901253
Validation loss: 2.531242782803274

Epoch: 242| Step: 0
Training loss: 0.6955333744655409
Validation loss: 2.5599812550220578

Epoch: 6| Step: 1
Training loss: 0.8552326242309279
Validation loss: 2.57579471682986

Epoch: 6| Step: 2
Training loss: 1.726191139847451
Validation loss: 2.580165417811869

Epoch: 6| Step: 3
Training loss: 0.7758233234717208
Validation loss: 2.5988612601463115

Epoch: 6| Step: 4
Training loss: 0.9110063503935955
Validation loss: 2.608303108546061

Epoch: 6| Step: 5
Training loss: 1.0377031196402506
Validation loss: 2.5709667239081178

Epoch: 6| Step: 6
Training loss: 0.8430237646950269
Validation loss: 2.576925496978097

Epoch: 6| Step: 7
Training loss: 0.7261090247836012
Validation loss: 2.550412928014671

Epoch: 6| Step: 8
Training loss: 0.8153417482755425
Validation loss: 2.5527736638418466

Epoch: 6| Step: 9
Training loss: 1.0348549458311211
Validation loss: 2.5388593079043194

Epoch: 6| Step: 10
Training loss: 1.0393543263832044
Validation loss: 2.5422486483340885

Epoch: 6| Step: 11
Training loss: 0.3775015285915727
Validation loss: 2.4950091248194015

Epoch: 6| Step: 12
Training loss: 1.104723514039979
Validation loss: 2.5187351671870837

Epoch: 6| Step: 13
Training loss: 0.8600324023596556
Validation loss: 2.5005892520620403

Epoch: 243| Step: 0
Training loss: 0.9203643382681623
Validation loss: 2.5138955978944306

Epoch: 6| Step: 1
Training loss: 0.798651230306531
Validation loss: 2.5113633738704437

Epoch: 6| Step: 2
Training loss: 0.8043496987632576
Validation loss: 2.5033489479482545

Epoch: 6| Step: 3
Training loss: 1.1012641556833476
Validation loss: 2.507465644090444

Epoch: 6| Step: 4
Training loss: 0.909650735901752
Validation loss: 2.5185552127371276

Epoch: 6| Step: 5
Training loss: 0.44132363550594
Validation loss: 2.4846170619254555

Epoch: 6| Step: 6
Training loss: 0.7999569627987306
Validation loss: 2.5188148532527306

Epoch: 6| Step: 7
Training loss: 0.5104483640002051
Validation loss: 2.526830075765383

Epoch: 6| Step: 8
Training loss: 1.7946059786458164
Validation loss: 2.51206720769613

Epoch: 6| Step: 9
Training loss: 0.9835396507117009
Validation loss: 2.540666410275209

Epoch: 6| Step: 10
Training loss: 0.8225764686030861
Validation loss: 2.5529324068199375

Epoch: 6| Step: 11
Training loss: 0.6440145560035281
Validation loss: 2.5259298100436602

Epoch: 6| Step: 12
Training loss: 0.875559253443441
Validation loss: 2.529047800681278

Epoch: 6| Step: 13
Training loss: 0.9264048797705379
Validation loss: 2.5156052795709276

Epoch: 244| Step: 0
Training loss: 1.1122004030555854
Validation loss: 2.5422166077753245

Epoch: 6| Step: 1
Training loss: 0.9306330000185743
Validation loss: 2.531179544857627

Epoch: 6| Step: 2
Training loss: 0.5058682120593336
Validation loss: 2.519439473268815

Epoch: 6| Step: 3
Training loss: 1.526736633926883
Validation loss: 2.517787004049072

Epoch: 6| Step: 4
Training loss: 0.6872211237475203
Validation loss: 2.5077962485421823

Epoch: 6| Step: 5
Training loss: 0.6629541459948587
Validation loss: 2.5084989891899925

Epoch: 6| Step: 6
Training loss: 1.0564747114246615
Validation loss: 2.5252106539807344

Epoch: 6| Step: 7
Training loss: 0.5081216311372421
Validation loss: 2.5005972261685647

Epoch: 6| Step: 8
Training loss: 0.9282739295022305
Validation loss: 2.478959847814226

Epoch: 6| Step: 9
Training loss: 0.7442298495249637
Validation loss: 2.4731543918071255

Epoch: 6| Step: 10
Training loss: 0.888320887074646
Validation loss: 2.524126271826889

Epoch: 6| Step: 11
Training loss: 1.0069599537732932
Validation loss: 2.4923345318168195

Epoch: 6| Step: 12
Training loss: 0.6093811866250582
Validation loss: 2.471677825714795

Epoch: 6| Step: 13
Training loss: 1.1188667854431151
Validation loss: 2.486814042927587

Epoch: 245| Step: 0
Training loss: 0.9822604461972729
Validation loss: 2.4879129275344223

Epoch: 6| Step: 1
Training loss: 0.6606849043436713
Validation loss: 2.500129401026705

Epoch: 6| Step: 2
Training loss: 0.7694490262945975
Validation loss: 2.493135726359782

Epoch: 6| Step: 3
Training loss: 0.7785230346265828
Validation loss: 2.494290678029428

Epoch: 6| Step: 4
Training loss: 0.8415369043944685
Validation loss: 2.4733273859712375

Epoch: 6| Step: 5
Training loss: 1.032691583754752
Validation loss: 2.5166534642970215

Epoch: 6| Step: 6
Training loss: 0.37650256332852156
Validation loss: 2.4883801884311367

Epoch: 6| Step: 7
Training loss: 1.6196554766578066
Validation loss: 2.493241574187763

Epoch: 6| Step: 8
Training loss: 1.1899791738146297
Validation loss: 2.499311454870301

Epoch: 6| Step: 9
Training loss: 0.777024476700485
Validation loss: 2.498027200530054

Epoch: 6| Step: 10
Training loss: 0.786642309905538
Validation loss: 2.5160781339122913

Epoch: 6| Step: 11
Training loss: 0.6986426638835654
Validation loss: 2.50634176713152

Epoch: 6| Step: 12
Training loss: 0.7253965230690692
Validation loss: 2.5196205951951036

Epoch: 6| Step: 13
Training loss: 0.33934325052125003
Validation loss: 2.5332882118038738

Epoch: 246| Step: 0
Training loss: 0.8772323605624851
Validation loss: 2.4822535291022096

Epoch: 6| Step: 1
Training loss: 1.0585555741862338
Validation loss: 2.5058510247829293

Epoch: 6| Step: 2
Training loss: 0.8030381938763107
Validation loss: 2.492128958682997

Epoch: 6| Step: 3
Training loss: 1.017200832015885
Validation loss: 2.483610804305377

Epoch: 6| Step: 4
Training loss: 0.43068731336045696
Validation loss: 2.4932710555948137

Epoch: 6| Step: 5
Training loss: 0.7978164870584258
Validation loss: 2.4904276869280575

Epoch: 6| Step: 6
Training loss: 0.7031761150854025
Validation loss: 2.5136350877027818

Epoch: 6| Step: 7
Training loss: 1.5809830572196453
Validation loss: 2.503572272363587

Epoch: 6| Step: 8
Training loss: 0.8683689763837795
Validation loss: 2.512402160140271

Epoch: 6| Step: 9
Training loss: 0.7373463599952441
Validation loss: 2.519942214008336

Epoch: 6| Step: 10
Training loss: 0.8134122275824177
Validation loss: 2.5350306483745637

Epoch: 6| Step: 11
Training loss: 0.7112850974328206
Validation loss: 2.5466133092446728

Epoch: 6| Step: 12
Training loss: 0.801249781056581
Validation loss: 2.532067053968674

Epoch: 6| Step: 13
Training loss: 0.4942670818651437
Validation loss: 2.531660583691744

Epoch: 247| Step: 0
Training loss: 1.1859964589778538
Validation loss: 2.554169121229696

Epoch: 6| Step: 1
Training loss: 0.49701359093579134
Validation loss: 2.5298445993169407

Epoch: 6| Step: 2
Training loss: 0.8319599676267239
Validation loss: 2.495517004515949

Epoch: 6| Step: 3
Training loss: 0.711608193077602
Validation loss: 2.4866572648442253

Epoch: 6| Step: 4
Training loss: 0.5009550867069347
Validation loss: 2.489556739291977

Epoch: 6| Step: 5
Training loss: 0.9468733771785515
Validation loss: 2.5173917484835404

Epoch: 6| Step: 6
Training loss: 0.5283574850998183
Validation loss: 2.4798837046889393

Epoch: 6| Step: 7
Training loss: 0.6593093179468125
Validation loss: 2.4804980566237664

Epoch: 6| Step: 8
Training loss: 0.9709530053989417
Validation loss: 2.493641406639709

Epoch: 6| Step: 9
Training loss: 0.9218760668214994
Validation loss: 2.499257421445496

Epoch: 6| Step: 10
Training loss: 0.8434245576886703
Validation loss: 2.502173403991649

Epoch: 6| Step: 11
Training loss: 1.583499556733802
Validation loss: 2.5083141257759713

Epoch: 6| Step: 12
Training loss: 0.7576720904021751
Validation loss: 2.4707111042527288

Epoch: 6| Step: 13
Training loss: 0.6140278687551706
Validation loss: 2.5150838218992457

Epoch: 248| Step: 0
Training loss: 0.8268760764186366
Validation loss: 2.502338049330116

Epoch: 6| Step: 1
Training loss: 1.6661276740511255
Validation loss: 2.52976299499229

Epoch: 6| Step: 2
Training loss: 1.0892991103123582
Validation loss: 2.5493365079887713

Epoch: 6| Step: 3
Training loss: 0.7696429331333425
Validation loss: 2.5612847592755323

Epoch: 6| Step: 4
Training loss: 0.8949575949058634
Validation loss: 2.563896446987331

Epoch: 6| Step: 5
Training loss: 0.314146330543737
Validation loss: 2.564429592350148

Epoch: 6| Step: 6
Training loss: 0.8401367031418
Validation loss: 2.57640853526593

Epoch: 6| Step: 7
Training loss: 0.8977588246357168
Validation loss: 2.535819323602006

Epoch: 6| Step: 8
Training loss: 0.8748493064817012
Validation loss: 2.5312923902342055

Epoch: 6| Step: 9
Training loss: 0.6795982872303714
Validation loss: 2.522771974816428

Epoch: 6| Step: 10
Training loss: 0.6635906787259621
Validation loss: 2.4973317820224494

Epoch: 6| Step: 11
Training loss: 0.8797073782102879
Validation loss: 2.467637488074146

Epoch: 6| Step: 12
Training loss: 0.5514714130694635
Validation loss: 2.4715660247576996

Epoch: 6| Step: 13
Training loss: 0.47539353444220783
Validation loss: 2.4645494541131545

Epoch: 249| Step: 0
Training loss: 0.7607020709095218
Validation loss: 2.458260496703671

Epoch: 6| Step: 1
Training loss: 0.6992801021319831
Validation loss: 2.473847299015223

Epoch: 6| Step: 2
Training loss: 0.6562837864489057
Validation loss: 2.4631740003726263

Epoch: 6| Step: 3
Training loss: 0.5394202993738054
Validation loss: 2.493614851422095

Epoch: 6| Step: 4
Training loss: 0.5547045852823722
Validation loss: 2.4946581837153246

Epoch: 6| Step: 5
Training loss: 1.535776959214449
Validation loss: 2.5041731449210136

Epoch: 6| Step: 6
Training loss: 0.852214248847328
Validation loss: 2.489272165917451

Epoch: 6| Step: 7
Training loss: 0.610700315400925
Validation loss: 2.5364660292550347

Epoch: 6| Step: 8
Training loss: 0.7884610593876626
Validation loss: 2.522683235631607

Epoch: 6| Step: 9
Training loss: 1.1303492632543701
Validation loss: 2.5351226302332845

Epoch: 6| Step: 10
Training loss: 0.9408918692864399
Validation loss: 2.5152254229939963

Epoch: 6| Step: 11
Training loss: 0.9229922555720486
Validation loss: 2.5040322559178283

Epoch: 6| Step: 12
Training loss: 0.8204250440142379
Validation loss: 2.51709312482594

Epoch: 6| Step: 13
Training loss: 1.0069786584821998
Validation loss: 2.4604163489679687

Epoch: 250| Step: 0
Training loss: 0.414186674967713
Validation loss: 2.4829895754757256

Epoch: 6| Step: 1
Training loss: 0.8826323468872691
Validation loss: 2.4944251013380976

Epoch: 6| Step: 2
Training loss: 0.48348890286504953
Validation loss: 2.485232890210438

Epoch: 6| Step: 3
Training loss: 0.7199792301970458
Validation loss: 2.4654863581180417

Epoch: 6| Step: 4
Training loss: 0.872846815156521
Validation loss: 2.491368788863085

Epoch: 6| Step: 5
Training loss: 1.801539726808173
Validation loss: 2.4798412952764775

Epoch: 6| Step: 6
Training loss: 0.9771190125729813
Validation loss: 2.49305087128222

Epoch: 6| Step: 7
Training loss: 0.5395037738466539
Validation loss: 2.479811309434976

Epoch: 6| Step: 8
Training loss: 0.8368741073774573
Validation loss: 2.433804179668747

Epoch: 6| Step: 9
Training loss: 0.9688796602662935
Validation loss: 2.498110572483699

Epoch: 6| Step: 10
Training loss: 0.7235662967726924
Validation loss: 2.504239105118194

Epoch: 6| Step: 11
Training loss: 0.49112457972387447
Validation loss: 2.473201942722959

Epoch: 6| Step: 12
Training loss: 0.6597996939518205
Validation loss: 2.4899031514811365

Epoch: 6| Step: 13
Training loss: 0.8257505817186072
Validation loss: 2.4950425761299417

Testing loss: 2.455065269439929
