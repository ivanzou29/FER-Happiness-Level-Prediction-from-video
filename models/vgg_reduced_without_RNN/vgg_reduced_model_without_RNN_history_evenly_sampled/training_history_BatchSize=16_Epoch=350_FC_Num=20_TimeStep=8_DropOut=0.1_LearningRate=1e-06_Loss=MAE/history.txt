Epoch: 1| Step: 0
Training loss: 1.8602358102798462
Validation loss: 3.186608922096991

Epoch: 6| Step: 1
Training loss: 2.941417694091797
Validation loss: 3.1854180930763163

Epoch: 6| Step: 2
Training loss: 4.795924186706543
Validation loss: 3.1825063997699368

Epoch: 6| Step: 3
Training loss: 3.0779480934143066
Validation loss: 3.1822051181588122

Epoch: 6| Step: 4
Training loss: 3.375441074371338
Validation loss: 3.1800092497179584

Epoch: 6| Step: 5
Training loss: 2.9804372787475586
Validation loss: 3.1808313451787478

Epoch: 6| Step: 6
Training loss: 3.6695449352264404
Validation loss: 3.1775596090542373

Epoch: 6| Step: 7
Training loss: 3.324190378189087
Validation loss: 3.1745185313686246

Epoch: 6| Step: 8
Training loss: 3.1224403381347656
Validation loss: 3.1761023382986746

Epoch: 6| Step: 9
Training loss: 3.3007962703704834
Validation loss: 3.1726487272529194

Epoch: 6| Step: 10
Training loss: 3.2176880836486816
Validation loss: 3.167912621651926

Epoch: 6| Step: 11
Training loss: 1.7542407512664795
Validation loss: 3.1681929070462465

Epoch: 6| Step: 12
Training loss: 3.8358044624328613
Validation loss: 3.168225247372863

Epoch: 6| Step: 13
Training loss: 3.435861349105835
Validation loss: 3.16795099935224

Epoch: 2| Step: 0
Training loss: 3.735745906829834
Validation loss: 3.165119122433406

Epoch: 6| Step: 1
Training loss: 3.388272762298584
Validation loss: 3.1630619700236986

Epoch: 6| Step: 2
Training loss: 2.802351474761963
Validation loss: 3.1599817301637385

Epoch: 6| Step: 3
Training loss: 2.372621774673462
Validation loss: 3.160620786810434

Epoch: 6| Step: 4
Training loss: 3.4498097896575928
Validation loss: 3.158744148028794

Epoch: 6| Step: 5
Training loss: 3.2763872146606445
Validation loss: 3.1565151932418987

Epoch: 6| Step: 6
Training loss: 3.224985122680664
Validation loss: 3.15592037734165

Epoch: 6| Step: 7
Training loss: 3.675057888031006
Validation loss: 3.1517171193194646

Epoch: 6| Step: 8
Training loss: 2.6079583168029785
Validation loss: 3.151850918287872

Epoch: 6| Step: 9
Training loss: 3.3753676414489746
Validation loss: 3.150181534469769

Epoch: 6| Step: 10
Training loss: 2.8834261894226074
Validation loss: 3.149229734174667

Epoch: 6| Step: 11
Training loss: 3.6126787662506104
Validation loss: 3.1467791398366294

Epoch: 6| Step: 12
Training loss: 2.8838953971862793
Validation loss: 3.1473657443959224

Epoch: 6| Step: 13
Training loss: 3.0206055641174316
Validation loss: 3.1452486668863604

Epoch: 3| Step: 0
Training loss: 3.5925920009613037
Validation loss: 3.1429452691026913

Epoch: 6| Step: 1
Training loss: 3.1156067848205566
Validation loss: 3.141448272171841

Epoch: 6| Step: 2
Training loss: 3.138214111328125
Validation loss: 3.142993801383562

Epoch: 6| Step: 3
Training loss: 4.15906286239624
Validation loss: 3.1390032255521385

Epoch: 6| Step: 4
Training loss: 3.7927749156951904
Validation loss: 3.1377910747322986

Epoch: 6| Step: 5
Training loss: 3.2656850814819336
Validation loss: 3.135796211099112

Epoch: 6| Step: 6
Training loss: 2.6141209602355957
Validation loss: 3.133390090798819

Epoch: 6| Step: 7
Training loss: 3.3649230003356934
Validation loss: 3.13326011678224

Epoch: 6| Step: 8
Training loss: 2.966294765472412
Validation loss: 3.1312358738273702

Epoch: 6| Step: 9
Training loss: 2.9320881366729736
Validation loss: 3.1300568862627913

Epoch: 6| Step: 10
Training loss: 2.6818952560424805
Validation loss: 3.1280899176033596

Epoch: 6| Step: 11
Training loss: 3.7194340229034424
Validation loss: 3.1278598359836045

Epoch: 6| Step: 12
Training loss: 1.8663640022277832
Validation loss: 3.1251239571520077

Epoch: 6| Step: 13
Training loss: 2.737971305847168
Validation loss: 3.124414369624148

Epoch: 4| Step: 0
Training loss: 2.7588257789611816
Validation loss: 3.1221200650738132

Epoch: 6| Step: 1
Training loss: 3.4627819061279297
Validation loss: 3.1221700406843618

Epoch: 6| Step: 2
Training loss: 2.7284088134765625
Validation loss: 3.1196219613475185

Epoch: 6| Step: 3
Training loss: 3.932889461517334
Validation loss: 3.1181788777792327

Epoch: 6| Step: 4
Training loss: 2.804680109024048
Validation loss: 3.117457148849323

Epoch: 6| Step: 5
Training loss: 4.110749244689941
Validation loss: 3.115216588461271

Epoch: 6| Step: 6
Training loss: 3.0938704013824463
Validation loss: 3.114983084381268

Epoch: 6| Step: 7
Training loss: 3.0481581687927246
Validation loss: 3.109129846736949

Epoch: 6| Step: 8
Training loss: 3.590827226638794
Validation loss: 3.110303842893211

Epoch: 6| Step: 9
Training loss: 2.944720506668091
Validation loss: 3.10955302176937

Epoch: 6| Step: 10
Training loss: 3.3518757820129395
Validation loss: 3.1090987702851653

Epoch: 6| Step: 11
Training loss: 1.8876787424087524
Validation loss: 3.106662306734311

Epoch: 6| Step: 12
Training loss: 3.2030529975891113
Validation loss: 3.1038715019020984

Epoch: 6| Step: 13
Training loss: 2.9316914081573486
Validation loss: 3.1021274097504152

Epoch: 5| Step: 0
Training loss: 3.5791125297546387
Validation loss: 3.101976692035634

Epoch: 6| Step: 1
Training loss: 2.852260112762451
Validation loss: 3.0981457156519734

Epoch: 6| Step: 2
Training loss: 3.1445159912109375
Validation loss: 3.099866965765594

Epoch: 6| Step: 3
Training loss: 3.36921763420105
Validation loss: 3.0961732351651756

Epoch: 6| Step: 4
Training loss: 2.4780807495117188
Validation loss: 3.0947582362800516

Epoch: 6| Step: 5
Training loss: 3.050628423690796
Validation loss: 3.091887702224075

Epoch: 6| Step: 6
Training loss: 3.1295204162597656
Validation loss: 3.09507506380799

Epoch: 6| Step: 7
Training loss: 3.476606607437134
Validation loss: 3.0910988212913595

Epoch: 6| Step: 8
Training loss: 3.3231723308563232
Validation loss: 3.0881205707468014

Epoch: 6| Step: 9
Training loss: 3.312838077545166
Validation loss: 3.0876767942982335

Epoch: 6| Step: 10
Training loss: 3.045289993286133
Validation loss: 3.084978872729886

Epoch: 6| Step: 11
Training loss: 2.8680419921875
Validation loss: 3.085291393341557

Epoch: 6| Step: 12
Training loss: 2.898735523223877
Validation loss: 3.08127696283402

Epoch: 6| Step: 13
Training loss: 3.193237781524658
Validation loss: 3.07972704210589

Epoch: 6| Step: 0
Training loss: 2.975846290588379
Validation loss: 3.078579987249067

Epoch: 6| Step: 1
Training loss: 2.601593017578125
Validation loss: 3.077910715533841

Epoch: 6| Step: 2
Training loss: 3.028895854949951
Validation loss: 3.0730099421675487

Epoch: 6| Step: 3
Training loss: 3.3190760612487793
Validation loss: 3.07451888310012

Epoch: 6| Step: 4
Training loss: 2.7708778381347656
Validation loss: 3.0713083359502975

Epoch: 6| Step: 5
Training loss: 2.962925672531128
Validation loss: 3.069996585128128

Epoch: 6| Step: 6
Training loss: 3.1964240074157715
Validation loss: 3.069449188888714

Epoch: 6| Step: 7
Training loss: 3.210808753967285
Validation loss: 3.067786888409686

Epoch: 6| Step: 8
Training loss: 3.4740521907806396
Validation loss: 3.0621447947717484

Epoch: 6| Step: 9
Training loss: 4.030559539794922
Validation loss: 3.065308283734065

Epoch: 6| Step: 10
Training loss: 2.941826343536377
Validation loss: 3.0618117240167435

Epoch: 6| Step: 11
Training loss: 2.346304416656494
Validation loss: 3.056283135567942

Epoch: 6| Step: 12
Training loss: 2.921201467514038
Validation loss: 3.056554776366039

Epoch: 6| Step: 13
Training loss: 4.1182780265808105
Validation loss: 3.052618085697133

Epoch: 7| Step: 0
Training loss: 1.9811781644821167
Validation loss: 3.052325722991779

Epoch: 6| Step: 1
Training loss: 3.692098379135132
Validation loss: 3.049537991964689

Epoch: 6| Step: 2
Training loss: 3.972726345062256
Validation loss: 3.0501527632436445

Epoch: 6| Step: 3
Training loss: 3.3523731231689453
Validation loss: 3.046826224173269

Epoch: 6| Step: 4
Training loss: 3.058426856994629
Validation loss: 3.044271448607086

Epoch: 6| Step: 5
Training loss: 3.1142468452453613
Validation loss: 3.0432995673148864

Epoch: 6| Step: 6
Training loss: 2.8808183670043945
Validation loss: 3.0418477058410645

Epoch: 6| Step: 7
Training loss: 2.5731632709503174
Validation loss: 3.0358767894006546

Epoch: 6| Step: 8
Training loss: 2.877300262451172
Validation loss: 3.0370620732666342

Epoch: 6| Step: 9
Training loss: 2.936169385910034
Validation loss: 3.034352610188146

Epoch: 6| Step: 10
Training loss: 2.9314770698547363
Validation loss: 3.0341699507928666

Epoch: 6| Step: 11
Training loss: 3.447870969772339
Validation loss: 3.0295963902627268

Epoch: 6| Step: 12
Training loss: 3.072740077972412
Validation loss: 3.0293231112982637

Epoch: 6| Step: 13
Training loss: 3.4656999111175537
Validation loss: 3.0246861442442863

Epoch: 8| Step: 0
Training loss: 2.4901885986328125
Validation loss: 3.022851418423396

Epoch: 6| Step: 1
Training loss: 2.6135811805725098
Validation loss: 3.0219603174476215

Epoch: 6| Step: 2
Training loss: 4.745838165283203
Validation loss: 3.0199536174856205

Epoch: 6| Step: 3
Training loss: 3.3760948181152344
Validation loss: 3.0137486765461583

Epoch: 6| Step: 4
Training loss: 2.354785203933716
Validation loss: 3.0120705327680035

Epoch: 6| Step: 5
Training loss: 2.8447482585906982
Validation loss: 3.0116713380300872

Epoch: 6| Step: 6
Training loss: 3.7057039737701416
Validation loss: 3.0056253171736196

Epoch: 6| Step: 7
Training loss: 3.808903455734253
Validation loss: 3.0059051872581564

Epoch: 6| Step: 8
Training loss: 2.349545478820801
Validation loss: 3.00469478484123

Epoch: 6| Step: 9
Training loss: 3.569413661956787
Validation loss: 2.998871172628095

Epoch: 6| Step: 10
Training loss: 2.5341036319732666
Validation loss: 2.995529754187471

Epoch: 6| Step: 11
Training loss: 2.946467399597168
Validation loss: 2.995844474402807

Epoch: 6| Step: 12
Training loss: 2.781315326690674
Validation loss: 2.9904809331381195

Epoch: 6| Step: 13
Training loss: 2.5375072956085205
Validation loss: 2.9897291967945714

Epoch: 9| Step: 0
Training loss: 3.394129753112793
Validation loss: 2.9873671172767557

Epoch: 6| Step: 1
Training loss: 2.1981375217437744
Validation loss: 2.981793060097643

Epoch: 6| Step: 2
Training loss: 2.4166595935821533
Validation loss: 2.9809700442898657

Epoch: 6| Step: 3
Training loss: 3.038038969039917
Validation loss: 2.9802115399350404

Epoch: 6| Step: 4
Training loss: 2.408217430114746
Validation loss: 2.9784127025194067

Epoch: 6| Step: 5
Training loss: 4.497533798217773
Validation loss: 2.9746101825468

Epoch: 6| Step: 6
Training loss: 3.1637356281280518
Validation loss: 2.9708018431099514

Epoch: 6| Step: 7
Training loss: 3.5251426696777344
Validation loss: 2.968619695273779

Epoch: 6| Step: 8
Training loss: 2.3028931617736816
Validation loss: 2.9659920430952504

Epoch: 6| Step: 9
Training loss: 2.9622364044189453
Validation loss: 2.9622371222383235

Epoch: 6| Step: 10
Training loss: 3.152047634124756
Validation loss: 2.962070152323733

Epoch: 6| Step: 11
Training loss: 2.642679214477539
Validation loss: 2.9574902544739428

Epoch: 6| Step: 12
Training loss: 3.215796947479248
Validation loss: 2.9553339019898446

Epoch: 6| Step: 13
Training loss: 4.023680210113525
Validation loss: 2.950095627897529

Epoch: 10| Step: 0
Training loss: 3.224282741546631
Validation loss: 2.9487044067792993

Epoch: 6| Step: 1
Training loss: 2.02018404006958
Validation loss: 2.9451507240213375

Epoch: 6| Step: 2
Training loss: 3.1767361164093018
Validation loss: 2.9422127995439755

Epoch: 6| Step: 3
Training loss: 3.8689494132995605
Validation loss: 2.938999411880329

Epoch: 6| Step: 4
Training loss: 3.8192105293273926
Validation loss: 2.933125642038161

Epoch: 6| Step: 5
Training loss: 3.0454769134521484
Validation loss: 2.9312119509584162

Epoch: 6| Step: 6
Training loss: 3.001288414001465
Validation loss: 2.9266980258367394

Epoch: 6| Step: 7
Training loss: 3.230811595916748
Validation loss: 2.9245121735398487

Epoch: 6| Step: 8
Training loss: 2.5714919567108154
Validation loss: 2.917828026638236

Epoch: 6| Step: 9
Training loss: 2.883441686630249
Validation loss: 2.9119661315794914

Epoch: 6| Step: 10
Training loss: 3.497476577758789
Validation loss: 2.908826084547145

Epoch: 6| Step: 11
Training loss: 2.7830657958984375
Validation loss: 2.906258849687474

Epoch: 6| Step: 12
Training loss: 2.0009877681732178
Validation loss: 2.900970571784563

Epoch: 6| Step: 13
Training loss: 2.887816905975342
Validation loss: 2.899245410837153

Epoch: 11| Step: 0
Training loss: 3.2190213203430176
Validation loss: 2.8963681651699926

Epoch: 6| Step: 1
Training loss: 2.3095264434814453
Validation loss: 2.8915002474220852

Epoch: 6| Step: 2
Training loss: 3.340907096862793
Validation loss: 2.8843354153376755

Epoch: 6| Step: 3
Training loss: 2.593585252761841
Validation loss: 2.883341386754026

Epoch: 6| Step: 4
Training loss: 3.021723985671997
Validation loss: 2.878801925207979

Epoch: 6| Step: 5
Training loss: 2.7691116333007812
Validation loss: 2.87833765117071

Epoch: 6| Step: 6
Training loss: 3.425011157989502
Validation loss: 2.872250456963816

Epoch: 6| Step: 7
Training loss: 2.5845518112182617
Validation loss: 2.8713296382657942

Epoch: 6| Step: 8
Training loss: 2.1475937366485596
Validation loss: 2.8662892849214616

Epoch: 6| Step: 9
Training loss: 3.5111968517303467
Validation loss: 2.861224566736529

Epoch: 6| Step: 10
Training loss: 3.032400369644165
Validation loss: 2.8600760480409027

Epoch: 6| Step: 11
Training loss: 2.931461811065674
Validation loss: 2.8506180804262877

Epoch: 6| Step: 12
Training loss: 3.4195899963378906
Validation loss: 2.846977312077758

Epoch: 6| Step: 13
Training loss: 3.422910451889038
Validation loss: 2.8445750333929576

Epoch: 12| Step: 0
Training loss: 2.888167381286621
Validation loss: 2.8377760071908273

Epoch: 6| Step: 1
Training loss: 3.4805116653442383
Validation loss: 2.8299625073709795

Epoch: 6| Step: 2
Training loss: 3.295135021209717
Validation loss: 2.830167596058179

Epoch: 6| Step: 3
Training loss: 1.8314127922058105
Validation loss: 2.8223871697661695

Epoch: 6| Step: 4
Training loss: 2.781619071960449
Validation loss: 2.8223820347939768

Epoch: 6| Step: 5
Training loss: 2.525752544403076
Validation loss: 2.8190136160901798

Epoch: 6| Step: 6
Training loss: 2.6205430030822754
Validation loss: 2.8129519031893824

Epoch: 6| Step: 7
Training loss: 4.034343719482422
Validation loss: 2.8057966232299805

Epoch: 6| Step: 8
Training loss: 3.267847776412964
Validation loss: 2.799893853484943

Epoch: 6| Step: 9
Training loss: 2.578517436981201
Validation loss: 2.7949251513327322

Epoch: 6| Step: 10
Training loss: 2.703350305557251
Validation loss: 2.794381103207988

Epoch: 6| Step: 11
Training loss: 3.0669617652893066
Validation loss: 2.7894504198464016

Epoch: 6| Step: 12
Training loss: 3.6441874504089355
Validation loss: 2.782312398315758

Epoch: 6| Step: 13
Training loss: 1.6899865865707397
Validation loss: 2.7792380522656184

Epoch: 13| Step: 0
Training loss: 2.7542619705200195
Validation loss: 2.7706574163129254

Epoch: 6| Step: 1
Training loss: 2.7599170207977295
Validation loss: 2.767296011729907

Epoch: 6| Step: 2
Training loss: 3.2032370567321777
Validation loss: 2.760181506474813

Epoch: 6| Step: 3
Training loss: 2.9929444789886475
Validation loss: 2.751534495302426

Epoch: 6| Step: 4
Training loss: 2.9385557174682617
Validation loss: 2.755899126811694

Epoch: 6| Step: 5
Training loss: 2.4748151302337646
Validation loss: 2.741008661126578

Epoch: 6| Step: 6
Training loss: 2.9301857948303223
Validation loss: 2.74196522466598

Epoch: 6| Step: 7
Training loss: 2.37894868850708
Validation loss: 2.730414262381933

Epoch: 6| Step: 8
Training loss: 3.157104015350342
Validation loss: 2.7337366662999636

Epoch: 6| Step: 9
Training loss: 3.164982318878174
Validation loss: 2.7213653082488687

Epoch: 6| Step: 10
Training loss: 2.786872386932373
Validation loss: 2.7141717890257477

Epoch: 6| Step: 11
Training loss: 3.102951765060425
Validation loss: 2.712547150991296

Epoch: 6| Step: 12
Training loss: 2.921657085418701
Validation loss: 2.7034649438755487

Epoch: 6| Step: 13
Training loss: 2.4912846088409424
Validation loss: 2.698164365624869

Epoch: 14| Step: 0
Training loss: 3.5950164794921875
Validation loss: 2.694383208469678

Epoch: 6| Step: 1
Training loss: 2.3447353839874268
Validation loss: 2.6882798928086475

Epoch: 6| Step: 2
Training loss: 2.1691129207611084
Validation loss: 2.6766429126903577

Epoch: 6| Step: 3
Training loss: 3.195784091949463
Validation loss: 2.6724161871017946

Epoch: 6| Step: 4
Training loss: 3.481886863708496
Validation loss: 2.6598349437918714

Epoch: 6| Step: 5
Training loss: 2.298858642578125
Validation loss: 2.656301103612428

Epoch: 6| Step: 6
Training loss: 2.7215583324432373
Validation loss: 2.65172081096198

Epoch: 6| Step: 7
Training loss: 2.4914581775665283
Validation loss: 2.643170490059801

Epoch: 6| Step: 8
Training loss: 2.5935235023498535
Validation loss: 2.631172905686081

Epoch: 6| Step: 9
Training loss: 2.4336533546447754
Validation loss: 2.6283925835804274

Epoch: 6| Step: 10
Training loss: 3.2644057273864746
Validation loss: 2.6245525331907373

Epoch: 6| Step: 11
Training loss: 2.8404147624969482
Validation loss: 2.614862060034147

Epoch: 6| Step: 12
Training loss: 2.8612112998962402
Validation loss: 2.6098452960291216

Epoch: 6| Step: 13
Training loss: 3.321540355682373
Validation loss: 2.6012517508640083

Epoch: 15| Step: 0
Training loss: 2.836935043334961
Validation loss: 2.5976219869429067

Epoch: 6| Step: 1
Training loss: 2.4759068489074707
Validation loss: 2.5899832684506654

Epoch: 6| Step: 2
Training loss: 2.6970252990722656
Validation loss: 2.5823520909073534

Epoch: 6| Step: 3
Training loss: 2.6757936477661133
Validation loss: 2.5724057100152455

Epoch: 6| Step: 4
Training loss: 3.2593536376953125
Validation loss: 2.5596199317645003

Epoch: 6| Step: 5
Training loss: 2.5130863189697266
Validation loss: 2.56122850859037

Epoch: 6| Step: 6
Training loss: 2.784733772277832
Validation loss: 2.5412341061458794

Epoch: 6| Step: 7
Training loss: 3.2380285263061523
Validation loss: 2.540219096727269

Epoch: 6| Step: 8
Training loss: 2.687772750854492
Validation loss: 2.5302538307764197

Epoch: 6| Step: 9
Training loss: 2.0990335941314697
Validation loss: 2.528145231226439

Epoch: 6| Step: 10
Training loss: 3.1005966663360596
Validation loss: 2.511410344031549

Epoch: 6| Step: 11
Training loss: 2.35013484954834
Validation loss: 2.509564076700518

Epoch: 6| Step: 12
Training loss: 3.0173020362854004
Validation loss: 2.49508079918482

Epoch: 6| Step: 13
Training loss: 2.7251760959625244
Validation loss: 2.497130524727606

Epoch: 16| Step: 0
Training loss: 3.01149845123291
Validation loss: 2.4823827307711364

Epoch: 6| Step: 1
Training loss: 3.0981979370117188
Validation loss: 2.478961785634359

Epoch: 6| Step: 2
Training loss: 2.176328659057617
Validation loss: 2.460530037521034

Epoch: 6| Step: 3
Training loss: 2.1473097801208496
Validation loss: 2.4476043665280907

Epoch: 6| Step: 4
Training loss: 2.2032923698425293
Validation loss: 2.4391164420753397

Epoch: 6| Step: 5
Training loss: 3.337423324584961
Validation loss: 2.4378190784044165

Epoch: 6| Step: 6
Training loss: 2.7417144775390625
Validation loss: 2.408724582323464

Epoch: 6| Step: 7
Training loss: 3.072356700897217
Validation loss: 2.410261454120759

Epoch: 6| Step: 8
Training loss: 2.6316580772399902
Validation loss: 2.3982521692911782

Epoch: 6| Step: 9
Training loss: 2.6983819007873535
Validation loss: 2.3977834768192743

Epoch: 6| Step: 10
Training loss: 2.2396860122680664
Validation loss: 2.382815399477559

Epoch: 6| Step: 11
Training loss: 2.9442715644836426
Validation loss: 2.3767072205902426

Epoch: 6| Step: 12
Training loss: 2.625946044921875
Validation loss: 2.3693897416514735

Epoch: 6| Step: 13
Training loss: 2.6651012897491455
Validation loss: 2.36185198701838

Epoch: 17| Step: 0
Training loss: 2.5296478271484375
Validation loss: 2.3475750107919016

Epoch: 6| Step: 1
Training loss: 2.8059773445129395
Validation loss: 2.348115133982833

Epoch: 6| Step: 2
Training loss: 2.478348731994629
Validation loss: 2.3272961134551675

Epoch: 6| Step: 3
Training loss: 2.4183051586151123
Validation loss: 2.3318232118442492

Epoch: 6| Step: 4
Training loss: 2.5808663368225098
Validation loss: 2.321597253122637

Epoch: 6| Step: 5
Training loss: 3.057835340499878
Validation loss: 2.3102465752632386

Epoch: 6| Step: 6
Training loss: 3.140648126602173
Validation loss: 2.305526337315959

Epoch: 6| Step: 7
Training loss: 2.0335488319396973
Validation loss: 2.299518559568672

Epoch: 6| Step: 8
Training loss: 3.013005018234253
Validation loss: 2.281701595552506

Epoch: 6| Step: 9
Training loss: 2.211606502532959
Validation loss: 2.2879922210529284

Epoch: 6| Step: 10
Training loss: 2.2193105220794678
Validation loss: 2.2706299776672036

Epoch: 6| Step: 11
Training loss: 2.311561107635498
Validation loss: 2.2684312712761665

Epoch: 6| Step: 12
Training loss: 2.886230707168579
Validation loss: 2.268714940676125

Epoch: 6| Step: 13
Training loss: 2.740027666091919
Validation loss: 2.264572097409156

Epoch: 18| Step: 0
Training loss: 2.7942376136779785
Validation loss: 2.250557513647182

Epoch: 6| Step: 1
Training loss: 2.4518628120422363
Validation loss: 2.2430885786651285

Epoch: 6| Step: 2
Training loss: 2.3151142597198486
Validation loss: 2.2379557137848227

Epoch: 6| Step: 3
Training loss: 2.8991594314575195
Validation loss: 2.2337537504011586

Epoch: 6| Step: 4
Training loss: 2.2522120475769043
Validation loss: 2.2230769383010043

Epoch: 6| Step: 5
Training loss: 1.8529407978057861
Validation loss: 2.217853758924751

Epoch: 6| Step: 6
Training loss: 2.7520651817321777
Validation loss: 2.2060140358504428

Epoch: 6| Step: 7
Training loss: 3.6388421058654785
Validation loss: 2.1988442790123726

Epoch: 6| Step: 8
Training loss: 2.0523197650909424
Validation loss: 2.1979213171107794

Epoch: 6| Step: 9
Training loss: 2.6367969512939453
Validation loss: 2.201858669198969

Epoch: 6| Step: 10
Training loss: 3.0534005165100098
Validation loss: 2.1836440178655807

Epoch: 6| Step: 11
Training loss: 2.3050317764282227
Validation loss: 2.1847742552398355

Epoch: 6| Step: 12
Training loss: 2.032888889312744
Validation loss: 2.178734358920846

Epoch: 6| Step: 13
Training loss: 2.444209098815918
Validation loss: 2.1784319659715057

Epoch: 19| Step: 0
Training loss: 2.191098213195801
Validation loss: 2.1596367359161377

Epoch: 6| Step: 1
Training loss: 2.412743091583252
Validation loss: 2.1579753660386607

Epoch: 6| Step: 2
Training loss: 2.1034491062164307
Validation loss: 2.1681154620262886

Epoch: 6| Step: 3
Training loss: 2.517784833908081
Validation loss: 2.137069648311984

Epoch: 6| Step: 4
Training loss: 2.167830467224121
Validation loss: 2.1464249677555536

Epoch: 6| Step: 5
Training loss: 3.0452065467834473
Validation loss: 2.1394055710043958

Epoch: 6| Step: 6
Training loss: 2.494683027267456
Validation loss: 2.1376173803883214

Epoch: 6| Step: 7
Training loss: 2.935211181640625
Validation loss: 2.1368755396976264

Epoch: 6| Step: 8
Training loss: 2.3827428817749023
Validation loss: 2.139984187259469

Epoch: 6| Step: 9
Training loss: 3.582939386367798
Validation loss: 2.127111014499459

Epoch: 6| Step: 10
Training loss: 2.5581746101379395
Validation loss: 2.1223896626503236

Epoch: 6| Step: 11
Training loss: 2.4293293952941895
Validation loss: 2.1162010879926783

Epoch: 6| Step: 12
Training loss: 1.7821227312088013
Validation loss: 2.1138313380620812

Epoch: 6| Step: 13
Training loss: 1.9853426218032837
Validation loss: 2.1138420694617817

Epoch: 20| Step: 0
Training loss: 1.5418434143066406
Validation loss: 2.115144806523477

Epoch: 6| Step: 1
Training loss: 2.5723342895507812
Validation loss: 2.101158759927237

Epoch: 6| Step: 2
Training loss: 2.243018865585327
Validation loss: 2.1086808340523833

Epoch: 6| Step: 3
Training loss: 2.557415008544922
Validation loss: 2.105453242537796

Epoch: 6| Step: 4
Training loss: 2.1348416805267334
Validation loss: 2.087064940442321

Epoch: 6| Step: 5
Training loss: 2.753157615661621
Validation loss: 2.0989431001806773

Epoch: 6| Step: 6
Training loss: 2.041447639465332
Validation loss: 2.085540948375579

Epoch: 6| Step: 7
Training loss: 2.9905524253845215
Validation loss: 2.0890432121933147

Epoch: 6| Step: 8
Training loss: 2.5691816806793213
Validation loss: 2.0898910312242407

Epoch: 6| Step: 9
Training loss: 3.4530513286590576
Validation loss: 2.084641928313881

Epoch: 6| Step: 10
Training loss: 2.373816728591919
Validation loss: 2.087104974254485

Epoch: 6| Step: 11
Training loss: 2.6237807273864746
Validation loss: 2.0699152126107165

Epoch: 6| Step: 12
Training loss: 2.0158584117889404
Validation loss: 2.070429377658393

Epoch: 6| Step: 13
Training loss: 2.687258243560791
Validation loss: 2.0811745569270146

Epoch: 21| Step: 0
Training loss: 2.2082526683807373
Validation loss: 2.060266620369368

Epoch: 6| Step: 1
Training loss: 2.7060837745666504
Validation loss: 2.0757924625950475

Epoch: 6| Step: 2
Training loss: 1.9797770977020264
Validation loss: 2.0871496315925353

Epoch: 6| Step: 3
Training loss: 2.7005510330200195
Validation loss: 2.057983056191475

Epoch: 6| Step: 4
Training loss: 2.9738564491271973
Validation loss: 2.0709917365863757

Epoch: 6| Step: 5
Training loss: 2.1247172355651855
Validation loss: 2.070011736244284

Epoch: 6| Step: 6
Training loss: 2.875577211380005
Validation loss: 2.0604133477774997

Epoch: 6| Step: 7
Training loss: 2.194021224975586
Validation loss: 2.078129214625205

Epoch: 6| Step: 8
Training loss: 2.575578212738037
Validation loss: 2.047300984782557

Epoch: 6| Step: 9
Training loss: 3.004425048828125
Validation loss: 2.06164804838037

Epoch: 6| Step: 10
Training loss: 2.184110403060913
Validation loss: 2.05924924342863

Epoch: 6| Step: 11
Training loss: 2.064574718475342
Validation loss: 2.065263876350977

Epoch: 6| Step: 12
Training loss: 2.054842948913574
Validation loss: 2.0700184760555143

Epoch: 6| Step: 13
Training loss: 2.5900185108184814
Validation loss: 2.060435643760107

Epoch: 22| Step: 0
Training loss: 1.6499923467636108
Validation loss: 2.0600459780744327

Epoch: 6| Step: 1
Training loss: 2.543443202972412
Validation loss: 2.0426663839688866

Epoch: 6| Step: 2
Training loss: 2.6059718132019043
Validation loss: 2.0613035322517477

Epoch: 6| Step: 3
Training loss: 2.3991289138793945
Validation loss: 2.048596100140643

Epoch: 6| Step: 4
Training loss: 2.869917631149292
Validation loss: 2.0525594321630334

Epoch: 6| Step: 5
Training loss: 2.7791905403137207
Validation loss: 2.0549992412649174

Epoch: 6| Step: 6
Training loss: 2.921539783477783
Validation loss: 2.045972051159028

Epoch: 6| Step: 7
Training loss: 2.8861727714538574
Validation loss: 2.046256774215288

Epoch: 6| Step: 8
Training loss: 2.2285866737365723
Validation loss: 2.039414287895285

Epoch: 6| Step: 9
Training loss: 2.1640310287475586
Validation loss: 2.0480491576656217

Epoch: 6| Step: 10
Training loss: 2.121629476547241
Validation loss: 2.053066225462062

Epoch: 6| Step: 11
Training loss: 2.492372989654541
Validation loss: 2.054182590976838

Epoch: 6| Step: 12
Training loss: 1.9523377418518066
Validation loss: 2.0580712902930474

Epoch: 6| Step: 13
Training loss: 2.479783535003662
Validation loss: 2.054200892807335

Epoch: 23| Step: 0
Training loss: 2.6242427825927734
Validation loss: 2.06214839284138

Epoch: 6| Step: 1
Training loss: 2.035896062850952
Validation loss: 2.0523683563355477

Epoch: 6| Step: 2
Training loss: 2.522463798522949
Validation loss: 2.0431810450810257

Epoch: 6| Step: 3
Training loss: 3.353855609893799
Validation loss: 2.0356301710169804

Epoch: 6| Step: 4
Training loss: 2.1271114349365234
Validation loss: 2.055559294198149

Epoch: 6| Step: 5
Training loss: 2.586353302001953
Validation loss: 2.037628412246704

Epoch: 6| Step: 6
Training loss: 1.8061447143554688
Validation loss: 2.0528235768759124

Epoch: 6| Step: 7
Training loss: 1.7589688301086426
Validation loss: 2.0587345605255454

Epoch: 6| Step: 8
Training loss: 2.3985955715179443
Validation loss: 2.05555623321123

Epoch: 6| Step: 9
Training loss: 2.382876396179199
Validation loss: 2.047303843241866

Epoch: 6| Step: 10
Training loss: 2.709476947784424
Validation loss: 2.0591818286526586

Epoch: 6| Step: 11
Training loss: 2.800358295440674
Validation loss: 2.055675179727616

Epoch: 6| Step: 12
Training loss: 2.2807130813598633
Validation loss: 2.0597985726530834

Epoch: 6| Step: 13
Training loss: 2.7900726795196533
Validation loss: 2.0579212839885423

Epoch: 24| Step: 0
Training loss: 2.453788995742798
Validation loss: 2.0367728561483402

Epoch: 6| Step: 1
Training loss: 2.516714096069336
Validation loss: 2.0545171332615677

Epoch: 6| Step: 2
Training loss: 1.8263683319091797
Validation loss: 2.0403202349139797

Epoch: 6| Step: 3
Training loss: 2.0777525901794434
Validation loss: 2.048414297001336

Epoch: 6| Step: 4
Training loss: 2.8295798301696777
Validation loss: 2.0361486686173307

Epoch: 6| Step: 5
Training loss: 3.033815383911133
Validation loss: 2.04772533652603

Epoch: 6| Step: 6
Training loss: 2.101675033569336
Validation loss: 2.0394176642100015

Epoch: 6| Step: 7
Training loss: 2.6847901344299316
Validation loss: 2.0429349304527364

Epoch: 6| Step: 8
Training loss: 3.0425126552581787
Validation loss: 2.043401215666084

Epoch: 6| Step: 9
Training loss: 2.536416530609131
Validation loss: 2.042533451511014

Epoch: 6| Step: 10
Training loss: 2.121473789215088
Validation loss: 2.0538459823977564

Epoch: 6| Step: 11
Training loss: 2.5720505714416504
Validation loss: 2.0419249137242637

Epoch: 6| Step: 12
Training loss: 1.8831300735473633
Validation loss: 2.0628311249517624

Epoch: 6| Step: 13
Training loss: 2.2300941944122314
Validation loss: 2.050675303705277

Epoch: 25| Step: 0
Training loss: 2.5522069931030273
Validation loss: 2.034533210979995

Epoch: 6| Step: 1
Training loss: 2.3082540035247803
Validation loss: 2.059701012026879

Epoch: 6| Step: 2
Training loss: 2.558138847351074
Validation loss: 2.0490444129513157

Epoch: 6| Step: 3
Training loss: 2.151662826538086
Validation loss: 2.046842195654428

Epoch: 6| Step: 4
Training loss: 2.720930814743042
Validation loss: 2.0544951090248684

Epoch: 6| Step: 5
Training loss: 2.2216131687164307
Validation loss: 2.064966268436883

Epoch: 6| Step: 6
Training loss: 2.179786205291748
Validation loss: 2.042565946937889

Epoch: 6| Step: 7
Training loss: 3.0263781547546387
Validation loss: 2.0608807148471957

Epoch: 6| Step: 8
Training loss: 2.3080735206604004
Validation loss: 2.0309358950584167

Epoch: 6| Step: 9
Training loss: 2.3989686965942383
Validation loss: 2.0536801686850925

Epoch: 6| Step: 10
Training loss: 2.3701975345611572
Validation loss: 2.0674165551380446

Epoch: 6| Step: 11
Training loss: 2.236818313598633
Validation loss: 2.063463149532195

Epoch: 6| Step: 12
Training loss: 2.6955149173736572
Validation loss: 2.0528687841148785

Epoch: 6| Step: 13
Training loss: 1.958853006362915
Validation loss: 2.037074524869201

Epoch: 26| Step: 0
Training loss: 1.9625545740127563
Validation loss: 2.051114425864271

Epoch: 6| Step: 1
Training loss: 2.319685220718384
Validation loss: 2.0407380237374255

Epoch: 6| Step: 2
Training loss: 2.5960140228271484
Validation loss: 2.054523685927032

Epoch: 6| Step: 3
Training loss: 2.907898187637329
Validation loss: 2.041847013658093

Epoch: 6| Step: 4
Training loss: 2.715555191040039
Validation loss: 2.0575262705485025

Epoch: 6| Step: 5
Training loss: 2.3465614318847656
Validation loss: 2.06279489045502

Epoch: 6| Step: 6
Training loss: 2.7704012393951416
Validation loss: 2.049858634189893

Epoch: 6| Step: 7
Training loss: 2.441739082336426
Validation loss: 2.049106897846345

Epoch: 6| Step: 8
Training loss: 3.153548240661621
Validation loss: 2.062007579752194

Epoch: 6| Step: 9
Training loss: 2.0160560607910156
Validation loss: 2.0504553664115166

Epoch: 6| Step: 10
Training loss: 2.2447452545166016
Validation loss: 2.04432423140413

Epoch: 6| Step: 11
Training loss: 1.9208179712295532
Validation loss: 2.050377035653719

Epoch: 6| Step: 12
Training loss: 2.2258219718933105
Validation loss: 2.04182844520897

Epoch: 6| Step: 13
Training loss: 2.0535390377044678
Validation loss: 2.0521141636756157

Epoch: 27| Step: 0
Training loss: 1.850542664527893
Validation loss: 2.0510389471566803

Epoch: 6| Step: 1
Training loss: 3.313145399093628
Validation loss: 2.0417605830777075

Epoch: 6| Step: 2
Training loss: 2.874631881713867
Validation loss: 2.041379236405896

Epoch: 6| Step: 3
Training loss: 2.095149517059326
Validation loss: 2.0688566700104745

Epoch: 6| Step: 4
Training loss: 3.137549638748169
Validation loss: 2.0458796178140948

Epoch: 6| Step: 5
Training loss: 2.7026994228363037
Validation loss: 2.04547369351951

Epoch: 6| Step: 6
Training loss: 2.164799928665161
Validation loss: 2.051294836946713

Epoch: 6| Step: 7
Training loss: 2.230706214904785
Validation loss: 2.0460445137434107

Epoch: 6| Step: 8
Training loss: 1.8343958854675293
Validation loss: 2.0520798493457097

Epoch: 6| Step: 9
Training loss: 2.185091495513916
Validation loss: 2.0288071452930407

Epoch: 6| Step: 10
Training loss: 2.9819674491882324
Validation loss: 2.0462623667973343

Epoch: 6| Step: 11
Training loss: 1.5258674621582031
Validation loss: 2.0337026837051555

Epoch: 6| Step: 12
Training loss: 2.8170952796936035
Validation loss: 2.0587271862132575

Epoch: 6| Step: 13
Training loss: 1.8165963888168335
Validation loss: 2.055836855724294

Epoch: 28| Step: 0
Training loss: 2.838228940963745
Validation loss: 2.041927259455445

Epoch: 6| Step: 1
Training loss: 2.6300058364868164
Validation loss: 2.0620775709870043

Epoch: 6| Step: 2
Training loss: 1.9018739461898804
Validation loss: 2.0379613753288024

Epoch: 6| Step: 3
Training loss: 2.233348846435547
Validation loss: 2.0482989088181527

Epoch: 6| Step: 4
Training loss: 2.1965322494506836
Validation loss: 2.0320864185210197

Epoch: 6| Step: 5
Training loss: 2.547548770904541
Validation loss: 2.043345179609073

Epoch: 6| Step: 6
Training loss: 2.2907676696777344
Validation loss: 2.0502259705656316

Epoch: 6| Step: 7
Training loss: 2.0266757011413574
Validation loss: 2.0377608396673716

Epoch: 6| Step: 8
Training loss: 2.51041316986084
Validation loss: 2.0482094544236378

Epoch: 6| Step: 9
Training loss: 2.7271485328674316
Validation loss: 2.0558522003953175

Epoch: 6| Step: 10
Training loss: 2.3500425815582275
Validation loss: 2.050651850238923

Epoch: 6| Step: 11
Training loss: 2.757826328277588
Validation loss: 2.05431737566507

Epoch: 6| Step: 12
Training loss: 2.2753548622131348
Validation loss: 2.0441116338135092

Epoch: 6| Step: 13
Training loss: 2.1412441730499268
Validation loss: 2.055996766654394

Epoch: 29| Step: 0
Training loss: 3.3838376998901367
Validation loss: 2.0361401611758816

Epoch: 6| Step: 1
Training loss: 2.319211483001709
Validation loss: 2.0545550392520044

Epoch: 6| Step: 2
Training loss: 2.3530774116516113
Validation loss: 2.0306423556420112

Epoch: 6| Step: 3
Training loss: 2.1671557426452637
Validation loss: 2.049627980878276

Epoch: 6| Step: 4
Training loss: 2.513038396835327
Validation loss: 2.044932214162683

Epoch: 6| Step: 5
Training loss: 2.7650182247161865
Validation loss: 2.046093499788674

Epoch: 6| Step: 6
Training loss: 1.6032276153564453
Validation loss: 2.03723914905261

Epoch: 6| Step: 7
Training loss: 2.090599536895752
Validation loss: 2.022107547329318

Epoch: 6| Step: 8
Training loss: 2.4205455780029297
Validation loss: 2.0207828937038297

Epoch: 6| Step: 9
Training loss: 2.462834358215332
Validation loss: 2.034541586393951

Epoch: 6| Step: 10
Training loss: 2.328197956085205
Validation loss: 2.0404831978582565

Epoch: 6| Step: 11
Training loss: 2.2608423233032227
Validation loss: 2.028345698951393

Epoch: 6| Step: 12
Training loss: 2.2578954696655273
Validation loss: 2.0381203095118203

Epoch: 6| Step: 13
Training loss: 2.5753989219665527
Validation loss: 2.0328897660778416

Epoch: 30| Step: 0
Training loss: 2.2994580268859863
Validation loss: 2.0430257140949206

Epoch: 6| Step: 1
Training loss: 2.6475539207458496
Validation loss: 2.024212368073002

Epoch: 6| Step: 2
Training loss: 2.629063367843628
Validation loss: 2.0305186381904026

Epoch: 6| Step: 3
Training loss: 2.354548931121826
Validation loss: 2.024817580817848

Epoch: 6| Step: 4
Training loss: 3.1459121704101562
Validation loss: 2.014044451457198

Epoch: 6| Step: 5
Training loss: 2.743562698364258
Validation loss: 2.0274429077743203

Epoch: 6| Step: 6
Training loss: 2.233639717102051
Validation loss: 2.0182414093325214

Epoch: 6| Step: 7
Training loss: 1.610464096069336
Validation loss: 2.035877930220737

Epoch: 6| Step: 8
Training loss: 2.5181493759155273
Validation loss: 2.011580539006059

Epoch: 6| Step: 9
Training loss: 1.7841304540634155
Validation loss: 2.0445508854363554

Epoch: 6| Step: 10
Training loss: 2.32731294631958
Validation loss: 2.005660428795763

Epoch: 6| Step: 11
Training loss: 2.506974935531616
Validation loss: 2.0284953501916703

Epoch: 6| Step: 12
Training loss: 1.8742048740386963
Validation loss: 2.0336026350657144

Epoch: 6| Step: 13
Training loss: 3.1151270866394043
Validation loss: 2.024230090520715

Epoch: 31| Step: 0
Training loss: 2.3493871688842773
Validation loss: 2.0258808289804766

Epoch: 6| Step: 1
Training loss: 1.7144684791564941
Validation loss: 2.0235594831487185

Epoch: 6| Step: 2
Training loss: 2.308492660522461
Validation loss: 2.0278744313024704

Epoch: 6| Step: 3
Training loss: 2.2998015880584717
Validation loss: 2.0319199613345567

Epoch: 6| Step: 4
Training loss: 2.2244515419006348
Validation loss: 2.014805891180551

Epoch: 6| Step: 5
Training loss: 1.9977755546569824
Validation loss: 2.029174462441475

Epoch: 6| Step: 6
Training loss: 2.2031612396240234
Validation loss: 2.015537013289749

Epoch: 6| Step: 7
Training loss: 2.8326826095581055
Validation loss: 2.039546981934578

Epoch: 6| Step: 8
Training loss: 2.167501926422119
Validation loss: 2.011741051109888

Epoch: 6| Step: 9
Training loss: 2.8212602138519287
Validation loss: 2.0289467714166127

Epoch: 6| Step: 10
Training loss: 2.8370554447174072
Validation loss: 2.027926757771482

Epoch: 6| Step: 11
Training loss: 2.7295312881469727
Validation loss: 2.03552117014444

Epoch: 6| Step: 12
Training loss: 2.131188154220581
Validation loss: 2.0185490269814768

Epoch: 6| Step: 13
Training loss: 3.362194538116455
Validation loss: 2.02425786500336

Epoch: 32| Step: 0
Training loss: 2.815094470977783
Validation loss: 2.028782234396986

Epoch: 6| Step: 1
Training loss: 2.094597339630127
Validation loss: 2.0301570943606797

Epoch: 6| Step: 2
Training loss: 2.0661778450012207
Validation loss: 2.0231834342402797

Epoch: 6| Step: 3
Training loss: 2.400200366973877
Validation loss: 2.027598241324066

Epoch: 6| Step: 4
Training loss: 2.74273419380188
Validation loss: 2.0238455354526477

Epoch: 6| Step: 5
Training loss: 2.2273244857788086
Validation loss: 2.0355210996443227

Epoch: 6| Step: 6
Training loss: 2.0144031047821045
Validation loss: 2.0151682194843086

Epoch: 6| Step: 7
Training loss: 2.5189571380615234
Validation loss: 2.0316608464846047

Epoch: 6| Step: 8
Training loss: 1.6594054698944092
Validation loss: 2.0435245780534643

Epoch: 6| Step: 9
Training loss: 2.223111867904663
Validation loss: 2.039536779926669

Epoch: 6| Step: 10
Training loss: 2.66803240776062
Validation loss: 2.033425272151988

Epoch: 6| Step: 11
Training loss: 2.5461082458496094
Validation loss: 2.0276046747802408

Epoch: 6| Step: 12
Training loss: 2.5938684940338135
Validation loss: 2.0363615405174995

Epoch: 6| Step: 13
Training loss: 3.12459135055542
Validation loss: 2.0218601085806407

Epoch: 33| Step: 0
Training loss: 2.156794548034668
Validation loss: 2.031298016989103

Epoch: 6| Step: 1
Training loss: 2.415494918823242
Validation loss: 2.0203543991170902

Epoch: 6| Step: 2
Training loss: 1.7510334253311157
Validation loss: 2.027009323079099

Epoch: 6| Step: 3
Training loss: 2.610330104827881
Validation loss: 2.025370285075198

Epoch: 6| Step: 4
Training loss: 2.227904796600342
Validation loss: 2.034965879173689

Epoch: 6| Step: 5
Training loss: 2.252924680709839
Validation loss: 2.027045225584379

Epoch: 6| Step: 6
Training loss: 1.8349400758743286
Validation loss: 2.0195424069640455

Epoch: 6| Step: 7
Training loss: 2.1389174461364746
Validation loss: 2.0220859742933706

Epoch: 6| Step: 8
Training loss: 2.507625102996826
Validation loss: 2.0373714803367533

Epoch: 6| Step: 9
Training loss: 2.472978115081787
Validation loss: 2.0325476661805184

Epoch: 6| Step: 10
Training loss: 3.2462172508239746
Validation loss: 2.052788862618067

Epoch: 6| Step: 11
Training loss: 2.423778533935547
Validation loss: 2.0147176557971584

Epoch: 6| Step: 12
Training loss: 2.5891051292419434
Validation loss: 2.0182357680413032

Epoch: 6| Step: 13
Training loss: 2.6927549839019775
Validation loss: 2.0222592135911346

Epoch: 34| Step: 0
Training loss: 2.1077284812927246
Validation loss: 2.024141042463241

Epoch: 6| Step: 1
Training loss: 2.4013664722442627
Validation loss: 2.02359656236505

Epoch: 6| Step: 2
Training loss: 2.128201961517334
Validation loss: 2.008034179287572

Epoch: 6| Step: 3
Training loss: 2.77315616607666
Validation loss: 2.0354725904362176

Epoch: 6| Step: 4
Training loss: 2.2787113189697266
Validation loss: 2.022676674268579

Epoch: 6| Step: 5
Training loss: 2.689281940460205
Validation loss: 2.038025841918043

Epoch: 6| Step: 6
Training loss: 1.9437304735183716
Validation loss: 2.0397961370406614

Epoch: 6| Step: 7
Training loss: 2.1204397678375244
Validation loss: 2.031233021008071

Epoch: 6| Step: 8
Training loss: 1.942973017692566
Validation loss: 2.0165833991060973

Epoch: 6| Step: 9
Training loss: 2.9024338722229004
Validation loss: 2.0270483160531647

Epoch: 6| Step: 10
Training loss: 2.582655906677246
Validation loss: 2.0357172296893213

Epoch: 6| Step: 11
Training loss: 2.4640932083129883
Validation loss: 2.0472550968970022

Epoch: 6| Step: 12
Training loss: 2.5526444911956787
Validation loss: 2.0464213817350325

Epoch: 6| Step: 13
Training loss: 2.2303242683410645
Validation loss: 2.030305339444068

Epoch: 35| Step: 0
Training loss: 2.5661892890930176
Validation loss: 2.0341510759886874

Epoch: 6| Step: 1
Training loss: 2.6353721618652344
Validation loss: 2.0259036094911638

Epoch: 6| Step: 2
Training loss: 2.229931354522705
Validation loss: 2.0294544748080674

Epoch: 6| Step: 3
Training loss: 2.2149276733398438
Validation loss: 2.032425581767995

Epoch: 6| Step: 4
Training loss: 2.5713367462158203
Validation loss: 2.0350597622574016

Epoch: 6| Step: 5
Training loss: 2.4117045402526855
Validation loss: 2.026960551097829

Epoch: 6| Step: 6
Training loss: 2.171560525894165
Validation loss: 2.035778635291643

Epoch: 6| Step: 7
Training loss: 2.3438668251037598
Validation loss: 2.0229971088388914

Epoch: 6| Step: 8
Training loss: 2.58730411529541
Validation loss: 2.019715493725192

Epoch: 6| Step: 9
Training loss: 2.0041375160217285
Validation loss: 1.999963363011678

Epoch: 6| Step: 10
Training loss: 2.859435558319092
Validation loss: 2.011945765505555

Epoch: 6| Step: 11
Training loss: 2.4489169120788574
Validation loss: 2.0401888970405824

Epoch: 6| Step: 12
Training loss: 1.930243730545044
Validation loss: 2.02011501789093

Epoch: 6| Step: 13
Training loss: 1.9453495740890503
Validation loss: 2.015910538293982

Epoch: 36| Step: 0
Training loss: 2.1401095390319824
Validation loss: 2.0165775898964173

Epoch: 6| Step: 1
Training loss: 1.7615973949432373
Validation loss: 2.0147350231806436

Epoch: 6| Step: 2
Training loss: 3.0344181060791016
Validation loss: 2.015669713738144

Epoch: 6| Step: 3
Training loss: 2.4133715629577637
Validation loss: 2.04349543458672

Epoch: 6| Step: 4
Training loss: 2.140475273132324
Validation loss: 2.0208753693488335

Epoch: 6| Step: 5
Training loss: 2.6491246223449707
Validation loss: 2.035378547124965

Epoch: 6| Step: 6
Training loss: 2.454211711883545
Validation loss: 2.0073729522766603

Epoch: 6| Step: 7
Training loss: 2.1107394695281982
Validation loss: 2.023017403899982

Epoch: 6| Step: 8
Training loss: 2.03236985206604
Validation loss: 2.018176749188413

Epoch: 6| Step: 9
Training loss: 3.033843755722046
Validation loss: 2.025461640409244

Epoch: 6| Step: 10
Training loss: 2.420567035675049
Validation loss: 2.0186034658903718

Epoch: 6| Step: 11
Training loss: 2.3045287132263184
Validation loss: 2.026523881061103

Epoch: 6| Step: 12
Training loss: 2.57389497756958
Validation loss: 2.0147205116928264

Epoch: 6| Step: 13
Training loss: 1.5158225297927856
Validation loss: 2.0075313647588096

Epoch: 37| Step: 0
Training loss: 2.622284412384033
Validation loss: 2.0147185248713337

Epoch: 6| Step: 1
Training loss: 2.3864974975585938
Validation loss: 2.014121990050039

Epoch: 6| Step: 2
Training loss: 2.765087604522705
Validation loss: 2.023372168182045

Epoch: 6| Step: 3
Training loss: 2.061372756958008
Validation loss: 2.017203216911644

Epoch: 6| Step: 4
Training loss: 2.6465892791748047
Validation loss: 2.033834808616228

Epoch: 6| Step: 5
Training loss: 2.324005603790283
Validation loss: 2.028949272248053

Epoch: 6| Step: 6
Training loss: 2.5666487216949463
Validation loss: 2.0156141865637993

Epoch: 6| Step: 7
Training loss: 2.62699031829834
Validation loss: 2.0172112641795987

Epoch: 6| Step: 8
Training loss: 1.8768645524978638
Validation loss: 2.0370012752471434

Epoch: 6| Step: 9
Training loss: 2.1652820110321045
Validation loss: 2.007792800985357

Epoch: 6| Step: 10
Training loss: 2.3293118476867676
Validation loss: 2.011058863773141

Epoch: 6| Step: 11
Training loss: 2.2060623168945312
Validation loss: 1.9898733374893025

Epoch: 6| Step: 12
Training loss: 2.3770742416381836
Validation loss: 2.0043480806453253

Epoch: 6| Step: 13
Training loss: 1.7130552530288696
Validation loss: 2.0100655658270723

Epoch: 38| Step: 0
Training loss: 2.2703781127929688
Validation loss: 2.0046352404420094

Epoch: 6| Step: 1
Training loss: 2.800739288330078
Validation loss: 2.003498802902878

Epoch: 6| Step: 2
Training loss: 2.5066685676574707
Validation loss: 2.0039328170079056

Epoch: 6| Step: 3
Training loss: 2.398782968521118
Validation loss: 2.0064857429073704

Epoch: 6| Step: 4
Training loss: 2.195730686187744
Validation loss: 2.004128964998389

Epoch: 6| Step: 5
Training loss: 2.842106819152832
Validation loss: 2.0064907612339145

Epoch: 6| Step: 6
Training loss: 2.330350399017334
Validation loss: 1.9866042572964904

Epoch: 6| Step: 7
Training loss: 2.1547155380249023
Validation loss: 1.9800328118826753

Epoch: 6| Step: 8
Training loss: 2.6033313274383545
Validation loss: 1.9937621547329811

Epoch: 6| Step: 9
Training loss: 2.0014936923980713
Validation loss: 2.005307323189192

Epoch: 6| Step: 10
Training loss: 2.701798439025879
Validation loss: 1.9830176176563385

Epoch: 6| Step: 11
Training loss: 1.7782493829727173
Validation loss: 2.007478585807226

Epoch: 6| Step: 12
Training loss: 2.4197916984558105
Validation loss: 2.002970669859199

Epoch: 6| Step: 13
Training loss: 1.7066874504089355
Validation loss: 1.9972916059596564

Epoch: 39| Step: 0
Training loss: 2.3499393463134766
Validation loss: 1.9849819931932675

Epoch: 6| Step: 1
Training loss: 2.675185203552246
Validation loss: 1.9919650887930265

Epoch: 6| Step: 2
Training loss: 2.6572377681732178
Validation loss: 2.0192956668074413

Epoch: 6| Step: 3
Training loss: 1.627192735671997
Validation loss: 2.0058370072354554

Epoch: 6| Step: 4
Training loss: 2.6168057918548584
Validation loss: 2.01636407708609

Epoch: 6| Step: 5
Training loss: 2.9394469261169434
Validation loss: 2.00659744457532

Epoch: 6| Step: 6
Training loss: 2.654749870300293
Validation loss: 2.011348642328734

Epoch: 6| Step: 7
Training loss: 2.6476035118103027
Validation loss: 2.014967765859378

Epoch: 6| Step: 8
Training loss: 2.0690500736236572
Validation loss: 2.0175379758240073

Epoch: 6| Step: 9
Training loss: 2.1335511207580566
Validation loss: 2.0215506963832404

Epoch: 6| Step: 10
Training loss: 2.004171133041382
Validation loss: 2.0152810863269273

Epoch: 6| Step: 11
Training loss: 2.2744410037994385
Validation loss: 2.013408645506828

Epoch: 6| Step: 12
Training loss: 1.4257513284683228
Validation loss: 2.0392211201370403

Epoch: 6| Step: 13
Training loss: 3.0760810375213623
Validation loss: 2.0197044187976467

Epoch: 40| Step: 0
Training loss: 2.3331995010375977
Validation loss: 2.016463687342982

Epoch: 6| Step: 1
Training loss: 2.029050588607788
Validation loss: 2.00642168137335

Epoch: 6| Step: 2
Training loss: 2.459409236907959
Validation loss: 2.003559089476062

Epoch: 6| Step: 3
Training loss: 2.606935739517212
Validation loss: 2.0237216398280156

Epoch: 6| Step: 4
Training loss: 1.8589632511138916
Validation loss: 2.024814756967688

Epoch: 6| Step: 5
Training loss: 2.019352912902832
Validation loss: 2.0128819698928506

Epoch: 6| Step: 6
Training loss: 2.312563419342041
Validation loss: 1.9953157132671726

Epoch: 6| Step: 7
Training loss: 1.664759874343872
Validation loss: 2.0022816965656896

Epoch: 6| Step: 8
Training loss: 2.68157958984375
Validation loss: 1.9997940665932112

Epoch: 6| Step: 9
Training loss: 2.4555776119232178
Validation loss: 2.0085521372415687

Epoch: 6| Step: 10
Training loss: 2.5194122791290283
Validation loss: 2.0107624159064343

Epoch: 6| Step: 11
Training loss: 2.575960159301758
Validation loss: 2.0197769544457875

Epoch: 6| Step: 12
Training loss: 3.1586649417877197
Validation loss: 1.996925074567077

Epoch: 6| Step: 13
Training loss: 2.1058835983276367
Validation loss: 2.003399597701206

Epoch: 41| Step: 0
Training loss: 2.532146453857422
Validation loss: 2.0120475997206984

Epoch: 6| Step: 1
Training loss: 3.1021013259887695
Validation loss: 2.01025656730898

Epoch: 6| Step: 2
Training loss: 1.7310240268707275
Validation loss: 2.0138299747179915

Epoch: 6| Step: 3
Training loss: 2.3117637634277344
Validation loss: 2.0080242259528047

Epoch: 6| Step: 4
Training loss: 1.9659206867218018
Validation loss: 2.008627583903651

Epoch: 6| Step: 5
Training loss: 2.1112756729125977
Validation loss: 2.035764240449475

Epoch: 6| Step: 6
Training loss: 2.4731287956237793
Validation loss: 2.0099930224880094

Epoch: 6| Step: 7
Training loss: 2.8374686241149902
Validation loss: 2.010908906177808

Epoch: 6| Step: 8
Training loss: 2.708430290222168
Validation loss: 2.0104792246254544

Epoch: 6| Step: 9
Training loss: 2.730210304260254
Validation loss: 2.0239382123434417

Epoch: 6| Step: 10
Training loss: 2.0747251510620117
Validation loss: 2.016076405843099

Epoch: 6| Step: 11
Training loss: 2.0380373001098633
Validation loss: 2.0032861707031087

Epoch: 6| Step: 12
Training loss: 2.235830783843994
Validation loss: 2.027596309620847

Epoch: 6| Step: 13
Training loss: 1.696830153465271
Validation loss: 2.017309437515915

Epoch: 42| Step: 0
Training loss: 2.452425241470337
Validation loss: 2.0341781967429706

Epoch: 6| Step: 1
Training loss: 3.2754812240600586
Validation loss: 2.0130805392419138

Epoch: 6| Step: 2
Training loss: 1.9475547075271606
Validation loss: 2.0017279014792493

Epoch: 6| Step: 3
Training loss: 1.5886547565460205
Validation loss: 2.016891699965282

Epoch: 6| Step: 4
Training loss: 2.226238250732422
Validation loss: 2.0153018825797626

Epoch: 6| Step: 5
Training loss: 2.543064832687378
Validation loss: 1.99643918519379

Epoch: 6| Step: 6
Training loss: 2.304410934448242
Validation loss: 1.9941729422538512

Epoch: 6| Step: 7
Training loss: 2.29414439201355
Validation loss: 2.02282145971893

Epoch: 6| Step: 8
Training loss: 2.142906665802002
Validation loss: 2.0173377939449844

Epoch: 6| Step: 9
Training loss: 2.65425443649292
Validation loss: 1.986982007180491

Epoch: 6| Step: 10
Training loss: 2.308804512023926
Validation loss: 1.9895412434813797

Epoch: 6| Step: 11
Training loss: 1.9443155527114868
Validation loss: 2.0030323613074517

Epoch: 6| Step: 12
Training loss: 2.4549286365509033
Validation loss: 2.0012333598188174

Epoch: 6| Step: 13
Training loss: 2.5611250400543213
Validation loss: 2.008001437751196

Epoch: 43| Step: 0
Training loss: 2.0030124187469482
Validation loss: 2.009108393423019

Epoch: 6| Step: 1
Training loss: 2.2024714946746826
Validation loss: 1.9870559605219031

Epoch: 6| Step: 2
Training loss: 2.4501471519470215
Validation loss: 1.9912110336365239

Epoch: 6| Step: 3
Training loss: 2.0537755489349365
Validation loss: 1.993304806370889

Epoch: 6| Step: 4
Training loss: 2.8797659873962402
Validation loss: 1.9882287363852225

Epoch: 6| Step: 5
Training loss: 2.857712507247925
Validation loss: 1.9981743853579286

Epoch: 6| Step: 6
Training loss: 1.816445231437683
Validation loss: 2.0040657904840287

Epoch: 6| Step: 7
Training loss: 1.8100224733352661
Validation loss: 1.9979370896534254

Epoch: 6| Step: 8
Training loss: 2.9099678993225098
Validation loss: 1.9937578875531432

Epoch: 6| Step: 9
Training loss: 2.267176628112793
Validation loss: 2.0064677205137027

Epoch: 6| Step: 10
Training loss: 2.8391146659851074
Validation loss: 1.9878244835843322

Epoch: 6| Step: 11
Training loss: 1.6885203123092651
Validation loss: 1.9979395917666856

Epoch: 6| Step: 12
Training loss: 2.419921398162842
Validation loss: 1.9799484078602125

Epoch: 6| Step: 13
Training loss: 2.0990896224975586
Validation loss: 2.0007907446994575

Epoch: 44| Step: 0
Training loss: 2.5796687602996826
Validation loss: 1.9898171437683927

Epoch: 6| Step: 1
Training loss: 2.9883627891540527
Validation loss: 1.997202293847197

Epoch: 6| Step: 2
Training loss: 2.0590054988861084
Validation loss: 1.9938028409916868

Epoch: 6| Step: 3
Training loss: 2.013739824295044
Validation loss: 1.9899529013582455

Epoch: 6| Step: 4
Training loss: 2.2767326831817627
Validation loss: 1.9895176015874392

Epoch: 6| Step: 5
Training loss: 2.236475944519043
Validation loss: 1.9956001697048065

Epoch: 6| Step: 6
Training loss: 2.6371049880981445
Validation loss: 1.9901563147062897

Epoch: 6| Step: 7
Training loss: 1.6202601194381714
Validation loss: 2.015404603814566

Epoch: 6| Step: 8
Training loss: 2.1123886108398438
Validation loss: 1.9792364464011243

Epoch: 6| Step: 9
Training loss: 2.1526880264282227
Validation loss: 2.0038445944427163

Epoch: 6| Step: 10
Training loss: 2.557554244995117
Validation loss: 2.0019395876956243

Epoch: 6| Step: 11
Training loss: 2.031636953353882
Validation loss: 1.983956717675732

Epoch: 6| Step: 12
Training loss: 2.2588706016540527
Validation loss: 1.9939904033496816

Epoch: 6| Step: 13
Training loss: 3.102025270462036
Validation loss: 1.9766148213417298

Epoch: 45| Step: 0
Training loss: 1.944636583328247
Validation loss: 1.9867852964708883

Epoch: 6| Step: 1
Training loss: 2.091860055923462
Validation loss: 1.9916820654305079

Epoch: 6| Step: 2
Training loss: 2.706421375274658
Validation loss: 2.005857172832694

Epoch: 6| Step: 3
Training loss: 1.9783294200897217
Validation loss: 1.9969430072333223

Epoch: 6| Step: 4
Training loss: 2.246901035308838
Validation loss: 2.008360570476901

Epoch: 6| Step: 5
Training loss: 3.243161678314209
Validation loss: 2.0054712013531755

Epoch: 6| Step: 6
Training loss: 2.753465175628662
Validation loss: 1.9948457594840758

Epoch: 6| Step: 7
Training loss: 1.5296255350112915
Validation loss: 1.9697934965933523

Epoch: 6| Step: 8
Training loss: 2.013345241546631
Validation loss: 2.0006194383867326

Epoch: 6| Step: 9
Training loss: 2.1193912029266357
Validation loss: 1.999231610246884

Epoch: 6| Step: 10
Training loss: 2.741335868835449
Validation loss: 1.9819106094298824

Epoch: 6| Step: 11
Training loss: 2.6884102821350098
Validation loss: 1.9801769461683048

Epoch: 6| Step: 12
Training loss: 2.530750274658203
Validation loss: 1.9678505697558004

Epoch: 6| Step: 13
Training loss: 1.357908844947815
Validation loss: 1.9711786649560417

Epoch: 46| Step: 0
Training loss: 2.3289132118225098
Validation loss: 1.9986371712018085

Epoch: 6| Step: 1
Training loss: 2.6048858165740967
Validation loss: 1.9733088375419698

Epoch: 6| Step: 2
Training loss: 1.8077510595321655
Validation loss: 1.9888030790513562

Epoch: 6| Step: 3
Training loss: 2.622777223587036
Validation loss: 2.000689727003856

Epoch: 6| Step: 4
Training loss: 2.427809715270996
Validation loss: 1.980310070899225

Epoch: 6| Step: 5
Training loss: 2.8013806343078613
Validation loss: 1.9748106669354182

Epoch: 6| Step: 6
Training loss: 2.149103879928589
Validation loss: 1.9785890425405195

Epoch: 6| Step: 7
Training loss: 2.268322229385376
Validation loss: 2.004980374408025

Epoch: 6| Step: 8
Training loss: 2.2848527431488037
Validation loss: 2.013721163554858

Epoch: 6| Step: 9
Training loss: 2.7228143215179443
Validation loss: 1.9868286117430656

Epoch: 6| Step: 10
Training loss: 2.2752342224121094
Validation loss: 1.9866719656093146

Epoch: 6| Step: 11
Training loss: 2.3923134803771973
Validation loss: 1.998622081613028

Epoch: 6| Step: 12
Training loss: 1.6769245862960815
Validation loss: 2.0053767478594215

Epoch: 6| Step: 13
Training loss: 1.4658527374267578
Validation loss: 1.9793774402269753

Epoch: 47| Step: 0
Training loss: 2.197521448135376
Validation loss: 1.9877211432303152

Epoch: 6| Step: 1
Training loss: 2.037513256072998
Validation loss: 1.9892904027815788

Epoch: 6| Step: 2
Training loss: 2.2664036750793457
Validation loss: 1.993985160704582

Epoch: 6| Step: 3
Training loss: 2.609157085418701
Validation loss: 1.9882466972515147

Epoch: 6| Step: 4
Training loss: 2.757896900177002
Validation loss: 1.9998451150873655

Epoch: 6| Step: 5
Training loss: 2.2589340209960938
Validation loss: 1.9886661088594826

Epoch: 6| Step: 6
Training loss: 1.8455277681350708
Validation loss: 1.9966613823367703

Epoch: 6| Step: 7
Training loss: 1.630411148071289
Validation loss: 1.9849872742929766

Epoch: 6| Step: 8
Training loss: 2.0208182334899902
Validation loss: 1.9826290312633719

Epoch: 6| Step: 9
Training loss: 2.4798078536987305
Validation loss: 1.9909000742820002

Epoch: 6| Step: 10
Training loss: 2.4116578102111816
Validation loss: 1.99406716515941

Epoch: 6| Step: 11
Training loss: 2.5935683250427246
Validation loss: 1.9837712728849022

Epoch: 6| Step: 12
Training loss: 2.659532070159912
Validation loss: 1.9976213696182414

Epoch: 6| Step: 13
Training loss: 2.5078909397125244
Validation loss: 1.9781902964397142

Epoch: 48| Step: 0
Training loss: 2.5404508113861084
Validation loss: 1.982995258864536

Epoch: 6| Step: 1
Training loss: 2.5072667598724365
Validation loss: 1.9756379358230098

Epoch: 6| Step: 2
Training loss: 2.6480512619018555
Validation loss: 1.9884924093882244

Epoch: 6| Step: 3
Training loss: 1.4349451065063477
Validation loss: 1.9798113966500888

Epoch: 6| Step: 4
Training loss: 2.4751334190368652
Validation loss: 1.9751082851040749

Epoch: 6| Step: 5
Training loss: 2.3697688579559326
Validation loss: 1.9783510943894744

Epoch: 6| Step: 6
Training loss: 2.3857455253601074
Validation loss: 1.9792544034219557

Epoch: 6| Step: 7
Training loss: 2.273042678833008
Validation loss: 2.003606286100162

Epoch: 6| Step: 8
Training loss: 1.7381296157836914
Validation loss: 1.979556151615676

Epoch: 6| Step: 9
Training loss: 2.9180378913879395
Validation loss: 1.9884110996800084

Epoch: 6| Step: 10
Training loss: 2.14522123336792
Validation loss: 1.997928765512282

Epoch: 6| Step: 11
Training loss: 2.4563398361206055
Validation loss: 1.998205195191086

Epoch: 6| Step: 12
Training loss: 2.1134114265441895
Validation loss: 1.9710789508717035

Epoch: 6| Step: 13
Training loss: 2.2469213008880615
Validation loss: 1.997565419443192

Epoch: 49| Step: 0
Training loss: 2.267235279083252
Validation loss: 1.99377429357139

Epoch: 6| Step: 1
Training loss: 2.787824869155884
Validation loss: 1.9877048077121857

Epoch: 6| Step: 2
Training loss: 2.0193772315979004
Validation loss: 2.0002755170227378

Epoch: 6| Step: 3
Training loss: 2.6642942428588867
Validation loss: 1.971497397268972

Epoch: 6| Step: 4
Training loss: 2.352431058883667
Validation loss: 1.9949303416795627

Epoch: 6| Step: 5
Training loss: 2.04268741607666
Validation loss: 1.9962605077733275

Epoch: 6| Step: 6
Training loss: 1.38356351852417
Validation loss: 1.9993490608789588

Epoch: 6| Step: 7
Training loss: 2.3026256561279297
Validation loss: 1.991760661525111

Epoch: 6| Step: 8
Training loss: 2.774627447128296
Validation loss: 1.989786612090244

Epoch: 6| Step: 9
Training loss: 2.6020658016204834
Validation loss: 2.0125271120379047

Epoch: 6| Step: 10
Training loss: 2.2146501541137695
Validation loss: 1.991368491162536

Epoch: 6| Step: 11
Training loss: 2.176597833633423
Validation loss: 2.000502678655809

Epoch: 6| Step: 12
Training loss: 2.06787109375
Validation loss: 1.995409716841995

Epoch: 6| Step: 13
Training loss: 2.4327428340911865
Validation loss: 1.9820586135310512

Epoch: 50| Step: 0
Training loss: 2.5497334003448486
Validation loss: 1.9922297539249543

Epoch: 6| Step: 1
Training loss: 2.2166073322296143
Validation loss: 1.998479381684334

Epoch: 6| Step: 2
Training loss: 2.2148241996765137
Validation loss: 1.998742703468569

Epoch: 6| Step: 3
Training loss: 2.074889898300171
Validation loss: 1.9825642429372317

Epoch: 6| Step: 4
Training loss: 2.4192328453063965
Validation loss: 1.9835949303001486

Epoch: 6| Step: 5
Training loss: 2.9621481895446777
Validation loss: 1.9936790197126326

Epoch: 6| Step: 6
Training loss: 2.1269664764404297
Validation loss: 1.9861600475926553

Epoch: 6| Step: 7
Training loss: 2.123189926147461
Validation loss: 1.9726574831111456

Epoch: 6| Step: 8
Training loss: 2.4967708587646484
Validation loss: 1.9981905209120883

Epoch: 6| Step: 9
Training loss: 2.6408629417419434
Validation loss: 1.9903212619084183

Epoch: 6| Step: 10
Training loss: 1.5695810317993164
Validation loss: 1.9833294319850143

Epoch: 6| Step: 11
Training loss: 2.4866387844085693
Validation loss: 2.002030000891737

Epoch: 6| Step: 12
Training loss: 2.4515442848205566
Validation loss: 1.9647436103513163

Epoch: 6| Step: 13
Training loss: 1.430837869644165
Validation loss: 1.980471500786402

Epoch: 51| Step: 0
Training loss: 2.278045177459717
Validation loss: 1.9741802343758204

Epoch: 6| Step: 1
Training loss: 2.6494317054748535
Validation loss: 1.9762173852612894

Epoch: 6| Step: 2
Training loss: 2.38362455368042
Validation loss: 1.9768927199866182

Epoch: 6| Step: 3
Training loss: 2.083031177520752
Validation loss: 1.9865751651025587

Epoch: 6| Step: 4
Training loss: 1.9157085418701172
Validation loss: 1.9881880872993059

Epoch: 6| Step: 5
Training loss: 2.2659220695495605
Validation loss: 1.9629393392993557

Epoch: 6| Step: 6
Training loss: 2.2358829975128174
Validation loss: 1.9873735494511102

Epoch: 6| Step: 7
Training loss: 1.5873489379882812
Validation loss: 1.988081814140402

Epoch: 6| Step: 8
Training loss: 2.8081679344177246
Validation loss: 1.9925097521915232

Epoch: 6| Step: 9
Training loss: 1.9267319440841675
Validation loss: 1.967331713245761

Epoch: 6| Step: 10
Training loss: 2.282376289367676
Validation loss: 1.9901701096565492

Epoch: 6| Step: 11
Training loss: 2.47240948677063
Validation loss: 1.968261008621544

Epoch: 6| Step: 12
Training loss: 2.8751492500305176
Validation loss: 1.9707821953681208

Epoch: 6| Step: 13
Training loss: 1.7699040174484253
Validation loss: 1.985211891512717

Epoch: 52| Step: 0
Training loss: 2.0950686931610107
Validation loss: 1.9733524604510235

Epoch: 6| Step: 1
Training loss: 2.6954193115234375
Validation loss: 1.9820547860155824

Epoch: 6| Step: 2
Training loss: 1.9679685831069946
Validation loss: 1.9764661891486055

Epoch: 6| Step: 3
Training loss: 2.548067569732666
Validation loss: 1.9838478975398566

Epoch: 6| Step: 4
Training loss: 2.31300687789917
Validation loss: 1.9735208890771354

Epoch: 6| Step: 5
Training loss: 2.1842894554138184
Validation loss: 1.9802747900767992

Epoch: 6| Step: 6
Training loss: 2.083747386932373
Validation loss: 1.9987106477060625

Epoch: 6| Step: 7
Training loss: 2.1472582817077637
Validation loss: 1.9800632974152923

Epoch: 6| Step: 8
Training loss: 2.444502353668213
Validation loss: 1.9577983220418294

Epoch: 6| Step: 9
Training loss: 2.1501035690307617
Validation loss: 1.966413442806531

Epoch: 6| Step: 10
Training loss: 1.931990146636963
Validation loss: 1.969056849838585

Epoch: 6| Step: 11
Training loss: 2.196204662322998
Validation loss: 1.9774059813509706

Epoch: 6| Step: 12
Training loss: 2.266170024871826
Validation loss: 1.9610042815567346

Epoch: 6| Step: 13
Training loss: 3.062809944152832
Validation loss: 1.963896333530385

Epoch: 53| Step: 0
Training loss: 2.332587480545044
Validation loss: 1.971485775004151

Epoch: 6| Step: 1
Training loss: 2.934284210205078
Validation loss: 1.950653652991018

Epoch: 6| Step: 2
Training loss: 2.553494930267334
Validation loss: 1.954818767886008

Epoch: 6| Step: 3
Training loss: 2.934461832046509
Validation loss: 1.968309506293266

Epoch: 6| Step: 4
Training loss: 2.669306755065918
Validation loss: 1.9552225323133572

Epoch: 6| Step: 5
Training loss: 2.133729934692383
Validation loss: 1.9501472416744436

Epoch: 6| Step: 6
Training loss: 2.2019286155700684
Validation loss: 1.9686725998437533

Epoch: 6| Step: 7
Training loss: 1.6403617858886719
Validation loss: 1.9829372744406424

Epoch: 6| Step: 8
Training loss: 1.8696091175079346
Validation loss: 1.980958233597458

Epoch: 6| Step: 9
Training loss: 1.5728874206542969
Validation loss: 1.9486730675543509

Epoch: 6| Step: 10
Training loss: 1.563441514968872
Validation loss: 1.9744637345754972

Epoch: 6| Step: 11
Training loss: 2.5616707801818848
Validation loss: 1.967378649660336

Epoch: 6| Step: 12
Training loss: 2.0580391883850098
Validation loss: 1.9585137110884472

Epoch: 6| Step: 13
Training loss: 2.9894816875457764
Validation loss: 1.9497753010001233

Epoch: 54| Step: 0
Training loss: 2.269087314605713
Validation loss: 1.9563445237375074

Epoch: 6| Step: 1
Training loss: 2.4819397926330566
Validation loss: 1.9735674294092322

Epoch: 6| Step: 2
Training loss: 1.8056198358535767
Validation loss: 1.9509945659227268

Epoch: 6| Step: 3
Training loss: 2.3528599739074707
Validation loss: 1.9561245825982863

Epoch: 6| Step: 4
Training loss: 1.9323182106018066
Validation loss: 1.9858970603635233

Epoch: 6| Step: 5
Training loss: 2.216890811920166
Validation loss: 1.9818339270930136

Epoch: 6| Step: 6
Training loss: 2.781066656112671
Validation loss: 1.9566342984476397

Epoch: 6| Step: 7
Training loss: 2.5231845378875732
Validation loss: 1.9465839465459187

Epoch: 6| Step: 8
Training loss: 2.6674463748931885
Validation loss: 1.9738192442924745

Epoch: 6| Step: 9
Training loss: 2.105212688446045
Validation loss: 1.9679839893053936

Epoch: 6| Step: 10
Training loss: 2.3961892127990723
Validation loss: 1.977962823324306

Epoch: 6| Step: 11
Training loss: 2.5582616329193115
Validation loss: 1.9656670529355285

Epoch: 6| Step: 12
Training loss: 1.7768189907073975
Validation loss: 1.9660727413751746

Epoch: 6| Step: 13
Training loss: 1.7114622592926025
Validation loss: 1.9472707535630913

Epoch: 55| Step: 0
Training loss: 2.764711380004883
Validation loss: 1.9872948623472644

Epoch: 6| Step: 1
Training loss: 2.2881662845611572
Validation loss: 1.971763018638857

Epoch: 6| Step: 2
Training loss: 1.9828006029129028
Validation loss: 1.9617426087779384

Epoch: 6| Step: 3
Training loss: 2.0504403114318848
Validation loss: 1.9542725073393954

Epoch: 6| Step: 4
Training loss: 1.7676340341567993
Validation loss: 1.9559579331387755

Epoch: 6| Step: 5
Training loss: 3.280881881713867
Validation loss: 1.9541856037673129

Epoch: 6| Step: 6
Training loss: 2.3886852264404297
Validation loss: 1.979454804492253

Epoch: 6| Step: 7
Training loss: 1.912480354309082
Validation loss: 1.9515822907929778

Epoch: 6| Step: 8
Training loss: 2.977729558944702
Validation loss: 1.9612375754182056

Epoch: 6| Step: 9
Training loss: 1.4117929935455322
Validation loss: 1.973593900280614

Epoch: 6| Step: 10
Training loss: 1.9847187995910645
Validation loss: 1.9922108060570174

Epoch: 6| Step: 11
Training loss: 2.48698353767395
Validation loss: 1.969323089045863

Epoch: 6| Step: 12
Training loss: 2.4129602909088135
Validation loss: 1.9796145872403217

Epoch: 6| Step: 13
Training loss: 1.623869776725769
Validation loss: 1.9552836007969354

Epoch: 56| Step: 0
Training loss: 1.7651668787002563
Validation loss: 1.9826908996028285

Epoch: 6| Step: 1
Training loss: 2.6057772636413574
Validation loss: 1.9770935671303862

Epoch: 6| Step: 2
Training loss: 2.070563316345215
Validation loss: 1.958806122502973

Epoch: 6| Step: 3
Training loss: 2.4150545597076416
Validation loss: 1.9639323039721417

Epoch: 6| Step: 4
Training loss: 1.559967279434204
Validation loss: 1.98132041833734

Epoch: 6| Step: 5
Training loss: 2.7970235347747803
Validation loss: 1.9584659094451575

Epoch: 6| Step: 6
Training loss: 1.8131979703903198
Validation loss: 1.9707189029262913

Epoch: 6| Step: 7
Training loss: 2.144202947616577
Validation loss: 1.9876426701904626

Epoch: 6| Step: 8
Training loss: 2.687643051147461
Validation loss: 1.9658960885899042

Epoch: 6| Step: 9
Training loss: 2.2600178718566895
Validation loss: 1.9434159186578566

Epoch: 6| Step: 10
Training loss: 2.395677089691162
Validation loss: 1.956253800340878

Epoch: 6| Step: 11
Training loss: 2.865133762359619
Validation loss: 1.9609066171030844

Epoch: 6| Step: 12
Training loss: 2.07738995552063
Validation loss: 1.9682562094862743

Epoch: 6| Step: 13
Training loss: 2.050705909729004
Validation loss: 1.9725556271050566

Epoch: 57| Step: 0
Training loss: 2.810239791870117
Validation loss: 1.967789339762862

Epoch: 6| Step: 1
Training loss: 1.9384596347808838
Validation loss: 1.9620428546782462

Epoch: 6| Step: 2
Training loss: 1.9237430095672607
Validation loss: 1.9547117294803742

Epoch: 6| Step: 3
Training loss: 2.5184502601623535
Validation loss: 1.9681219900808027

Epoch: 6| Step: 4
Training loss: 3.152017116546631
Validation loss: 1.9667689518261982

Epoch: 6| Step: 5
Training loss: 2.515150547027588
Validation loss: 1.9748820822726014

Epoch: 6| Step: 6
Training loss: 2.613490104675293
Validation loss: 1.9687597969526887

Epoch: 6| Step: 7
Training loss: 1.5089539289474487
Validation loss: 1.9771194483644219

Epoch: 6| Step: 8
Training loss: 2.4407615661621094
Validation loss: 1.967492099731199

Epoch: 6| Step: 9
Training loss: 2.154891014099121
Validation loss: 1.982203415645066

Epoch: 6| Step: 10
Training loss: 1.9153332710266113
Validation loss: 1.9827309526422972

Epoch: 6| Step: 11
Training loss: 1.7759099006652832
Validation loss: 1.9805535129321519

Epoch: 6| Step: 12
Training loss: 2.189319133758545
Validation loss: 1.984048056346114

Epoch: 6| Step: 13
Training loss: 1.8429731130599976
Validation loss: 1.9833107443266018

Epoch: 58| Step: 0
Training loss: 2.106048107147217
Validation loss: 2.003070774898734

Epoch: 6| Step: 1
Training loss: 2.3469343185424805
Validation loss: 1.9645375026169645

Epoch: 6| Step: 2
Training loss: 2.2816247940063477
Validation loss: 1.981431056094426

Epoch: 6| Step: 3
Training loss: 2.3759925365448
Validation loss: 1.9727856753974833

Epoch: 6| Step: 4
Training loss: 2.4095301628112793
Validation loss: 1.982349931552846

Epoch: 6| Step: 5
Training loss: 2.0815343856811523
Validation loss: 1.9686546479502032

Epoch: 6| Step: 6
Training loss: 1.742815613746643
Validation loss: 1.9747715342429377

Epoch: 6| Step: 7
Training loss: 2.6492831707000732
Validation loss: 1.9634622963525916

Epoch: 6| Step: 8
Training loss: 2.5933072566986084
Validation loss: 1.9781994178730955

Epoch: 6| Step: 9
Training loss: 1.5566895008087158
Validation loss: 1.970297195578134

Epoch: 6| Step: 10
Training loss: 2.3016152381896973
Validation loss: 1.9674635228290354

Epoch: 6| Step: 11
Training loss: 2.688467502593994
Validation loss: 1.9551920557534823

Epoch: 6| Step: 12
Training loss: 2.2287211418151855
Validation loss: 1.9529680898112636

Epoch: 6| Step: 13
Training loss: 1.928475260734558
Validation loss: 1.955212244423487

Epoch: 59| Step: 0
Training loss: 2.0468156337738037
Validation loss: 1.9618330053103867

Epoch: 6| Step: 1
Training loss: 2.1913657188415527
Validation loss: 1.94790607113992

Epoch: 6| Step: 2
Training loss: 2.273059129714966
Validation loss: 1.978406313926943

Epoch: 6| Step: 3
Training loss: 2.200885057449341
Validation loss: 1.9649849194352345

Epoch: 6| Step: 4
Training loss: 2.374980926513672
Validation loss: 1.9715183088856358

Epoch: 6| Step: 5
Training loss: 1.475672721862793
Validation loss: 1.968088787089112

Epoch: 6| Step: 6
Training loss: 2.3889217376708984
Validation loss: 1.9620958015482912

Epoch: 6| Step: 7
Training loss: 2.175631284713745
Validation loss: 1.9695518785907375

Epoch: 6| Step: 8
Training loss: 2.516500473022461
Validation loss: 1.9810554763322235

Epoch: 6| Step: 9
Training loss: 2.0219593048095703
Validation loss: 1.9517845979300879

Epoch: 6| Step: 10
Training loss: 2.856904983520508
Validation loss: 1.9932262128399265

Epoch: 6| Step: 11
Training loss: 2.131563186645508
Validation loss: 1.9699233103823919

Epoch: 6| Step: 12
Training loss: 2.432955741882324
Validation loss: 1.9672080496306061

Epoch: 6| Step: 13
Training loss: 2.324465751647949
Validation loss: 1.9724166765007922

Epoch: 60| Step: 0
Training loss: 1.8254948854446411
Validation loss: 1.9713460373622116

Epoch: 6| Step: 1
Training loss: 2.647688865661621
Validation loss: 1.978334000033717

Epoch: 6| Step: 2
Training loss: 2.9896156787872314
Validation loss: 1.9669993167282434

Epoch: 6| Step: 3
Training loss: 1.725610375404358
Validation loss: 1.9767931046024445

Epoch: 6| Step: 4
Training loss: 1.843718409538269
Validation loss: 1.985786904570877

Epoch: 6| Step: 5
Training loss: 2.3238303661346436
Validation loss: 1.9747183245997275

Epoch: 6| Step: 6
Training loss: 2.0568995475769043
Validation loss: 1.9661971420370123

Epoch: 6| Step: 7
Training loss: 2.2874693870544434
Validation loss: 1.9949730442416282

Epoch: 6| Step: 8
Training loss: 2.0970816612243652
Validation loss: 1.9795997578610656

Epoch: 6| Step: 9
Training loss: 2.0360872745513916
Validation loss: 1.9963253031494796

Epoch: 6| Step: 10
Training loss: 1.9800571203231812
Validation loss: 1.9659614229715

Epoch: 6| Step: 11
Training loss: 3.1238644123077393
Validation loss: 1.9956045766030588

Epoch: 6| Step: 12
Training loss: 2.578183650970459
Validation loss: 1.9936032218317832

Epoch: 6| Step: 13
Training loss: 1.7821714878082275
Validation loss: 2.001268563732024

Epoch: 61| Step: 0
Training loss: 2.2309117317199707
Validation loss: 2.0005573508560017

Epoch: 6| Step: 1
Training loss: 2.269507884979248
Validation loss: 1.9846775634314424

Epoch: 6| Step: 2
Training loss: 2.589198589324951
Validation loss: 2.011430989029587

Epoch: 6| Step: 3
Training loss: 2.6401405334472656
Validation loss: 1.9983823658317648

Epoch: 6| Step: 4
Training loss: 2.7378077507019043
Validation loss: 1.9989184435977732

Epoch: 6| Step: 5
Training loss: 2.0309536457061768
Validation loss: 1.9935638699480283

Epoch: 6| Step: 6
Training loss: 2.6853091716766357
Validation loss: 1.9759108584414247

Epoch: 6| Step: 7
Training loss: 1.5175707340240479
Validation loss: 2.0063692985042447

Epoch: 6| Step: 8
Training loss: 2.117206335067749
Validation loss: 1.9932689589838828

Epoch: 6| Step: 9
Training loss: 2.4117140769958496
Validation loss: 1.9913066074412356

Epoch: 6| Step: 10
Training loss: 1.8754804134368896
Validation loss: 1.9859273433685303

Epoch: 6| Step: 11
Training loss: 2.1080949306488037
Validation loss: 1.9831311420727802

Epoch: 6| Step: 12
Training loss: 2.2348246574401855
Validation loss: 1.988000092967864

Epoch: 6| Step: 13
Training loss: 1.9411849975585938
Validation loss: 1.993853230630198

Epoch: 62| Step: 0
Training loss: 3.3211779594421387
Validation loss: 1.9740046916469451

Epoch: 6| Step: 1
Training loss: 2.086141586303711
Validation loss: 1.96125457620108

Epoch: 6| Step: 2
Training loss: 2.529181480407715
Validation loss: 1.9773904367159771

Epoch: 6| Step: 3
Training loss: 2.414229393005371
Validation loss: 1.9818020443762503

Epoch: 6| Step: 4
Training loss: 2.2081732749938965
Validation loss: 1.9954363146135885

Epoch: 6| Step: 5
Training loss: 1.7531293630599976
Validation loss: 1.9727811351899178

Epoch: 6| Step: 6
Training loss: 1.8072134256362915
Validation loss: 1.9835386712064025

Epoch: 6| Step: 7
Training loss: 1.9061625003814697
Validation loss: 1.9899436043154808

Epoch: 6| Step: 8
Training loss: 2.4591126441955566
Validation loss: 1.986357271030385

Epoch: 6| Step: 9
Training loss: 2.4534502029418945
Validation loss: 1.9716959999453636

Epoch: 6| Step: 10
Training loss: 1.4201109409332275
Validation loss: 2.000507172717843

Epoch: 6| Step: 11
Training loss: 2.225390911102295
Validation loss: 1.9746815953203427

Epoch: 6| Step: 12
Training loss: 2.667957305908203
Validation loss: 1.9831680533706502

Epoch: 6| Step: 13
Training loss: 1.694346308708191
Validation loss: 1.9957467202217347

Epoch: 63| Step: 0
Training loss: 1.8285906314849854
Validation loss: 1.9730460002858152

Epoch: 6| Step: 1
Training loss: 2.815580368041992
Validation loss: 1.9896576686572003

Epoch: 6| Step: 2
Training loss: 2.2561469078063965
Validation loss: 1.992188811302185

Epoch: 6| Step: 3
Training loss: 1.8944344520568848
Validation loss: 1.9825641416734265

Epoch: 6| Step: 4
Training loss: 1.7945146560668945
Validation loss: 1.9672986345906411

Epoch: 6| Step: 5
Training loss: 2.768838405609131
Validation loss: 1.9552146914184734

Epoch: 6| Step: 6
Training loss: 2.5530216693878174
Validation loss: 1.9646785669429327

Epoch: 6| Step: 7
Training loss: 2.1309118270874023
Validation loss: 1.988383166251644

Epoch: 6| Step: 8
Training loss: 2.060636043548584
Validation loss: 1.952987140224826

Epoch: 6| Step: 9
Training loss: 2.482558250427246
Validation loss: 1.984601560459342

Epoch: 6| Step: 10
Training loss: 2.292943000793457
Validation loss: 1.9534889985156316

Epoch: 6| Step: 11
Training loss: 2.259235382080078
Validation loss: 1.9459057097793908

Epoch: 6| Step: 12
Training loss: 1.6628133058547974
Validation loss: 1.9541298804744598

Epoch: 6| Step: 13
Training loss: 2.7370870113372803
Validation loss: 1.937244176864624

Epoch: 64| Step: 0
Training loss: 1.8244609832763672
Validation loss: 1.9599580508406445

Epoch: 6| Step: 1
Training loss: 1.7677607536315918
Validation loss: 1.9689533236206218

Epoch: 6| Step: 2
Training loss: 2.5938172340393066
Validation loss: 1.9680543458589943

Epoch: 6| Step: 3
Training loss: 2.3093676567077637
Validation loss: 1.9861817680379397

Epoch: 6| Step: 4
Training loss: 2.6766347885131836
Validation loss: 1.9867035317164596

Epoch: 6| Step: 5
Training loss: 2.110563278198242
Validation loss: 1.956601014701269

Epoch: 6| Step: 6
Training loss: 2.3832058906555176
Validation loss: 1.9814790884653728

Epoch: 6| Step: 7
Training loss: 1.928299903869629
Validation loss: 1.9737077874522055

Epoch: 6| Step: 8
Training loss: 1.7127747535705566
Validation loss: 1.9955785402687647

Epoch: 6| Step: 9
Training loss: 2.774658203125
Validation loss: 1.9787470627856512

Epoch: 6| Step: 10
Training loss: 2.110433578491211
Validation loss: 1.9680524859377133

Epoch: 6| Step: 11
Training loss: 2.3744325637817383
Validation loss: 1.9895817733580066

Epoch: 6| Step: 12
Training loss: 2.492173194885254
Validation loss: 1.964582053563928

Epoch: 6| Step: 13
Training loss: 2.2063326835632324
Validation loss: 1.9818177915388537

Epoch: 65| Step: 0
Training loss: 2.1034352779388428
Validation loss: 1.987883037136447

Epoch: 6| Step: 1
Training loss: 2.1859488487243652
Validation loss: 1.977206540364091

Epoch: 6| Step: 2
Training loss: 2.3690099716186523
Validation loss: 1.9619772946962746

Epoch: 6| Step: 3
Training loss: 2.6493959426879883
Validation loss: 1.9801805596197806

Epoch: 6| Step: 4
Training loss: 1.8580906391143799
Validation loss: 1.9827360440325994

Epoch: 6| Step: 5
Training loss: 2.4850730895996094
Validation loss: 1.9850371217214933

Epoch: 6| Step: 6
Training loss: 2.236720561981201
Validation loss: 1.9832783001725391

Epoch: 6| Step: 7
Training loss: 2.0985162258148193
Validation loss: 1.9766560754468363

Epoch: 6| Step: 8
Training loss: 2.5252087116241455
Validation loss: 1.977750430824936

Epoch: 6| Step: 9
Training loss: 2.839406967163086
Validation loss: 1.9825097335282194

Epoch: 6| Step: 10
Training loss: 2.009636402130127
Validation loss: 1.9432836655647523

Epoch: 6| Step: 11
Training loss: 1.2318511009216309
Validation loss: 1.9993854363759358

Epoch: 6| Step: 12
Training loss: 2.278318405151367
Validation loss: 1.9843151800094112

Epoch: 6| Step: 13
Training loss: 2.398958921432495
Validation loss: 1.9499846402034964

Epoch: 66| Step: 0
Training loss: 2.197662353515625
Validation loss: 1.9898690805640271

Epoch: 6| Step: 1
Training loss: 1.9360250234603882
Validation loss: 1.9949084661340202

Epoch: 6| Step: 2
Training loss: 1.7662334442138672
Validation loss: 1.971393698005266

Epoch: 6| Step: 3
Training loss: 1.260764718055725
Validation loss: 1.9883747408466954

Epoch: 6| Step: 4
Training loss: 2.1749684810638428
Validation loss: 1.9732938735715804

Epoch: 6| Step: 5
Training loss: 2.194091558456421
Validation loss: 1.989173363613826

Epoch: 6| Step: 6
Training loss: 3.0252184867858887
Validation loss: 1.983981099179996

Epoch: 6| Step: 7
Training loss: 1.6892635822296143
Validation loss: 1.9723768618799025

Epoch: 6| Step: 8
Training loss: 1.924667239189148
Validation loss: 1.960807854129422

Epoch: 6| Step: 9
Training loss: 3.0716099739074707
Validation loss: 1.987094106212739

Epoch: 6| Step: 10
Training loss: 2.9374568462371826
Validation loss: 1.9853440125783284

Epoch: 6| Step: 11
Training loss: 2.743046760559082
Validation loss: 1.983323480493279

Epoch: 6| Step: 12
Training loss: 2.0629777908325195
Validation loss: 1.9934574609161706

Epoch: 6| Step: 13
Training loss: 2.0905344486236572
Validation loss: 1.991396395109033

Epoch: 67| Step: 0
Training loss: 2.3083152770996094
Validation loss: 1.9709931163377659

Epoch: 6| Step: 1
Training loss: 2.2698092460632324
Validation loss: 1.9729907461391982

Epoch: 6| Step: 2
Training loss: 2.264213800430298
Validation loss: 1.9842303619589856

Epoch: 6| Step: 3
Training loss: 2.3306961059570312
Validation loss: 1.9707003934409029

Epoch: 6| Step: 4
Training loss: 3.1446433067321777
Validation loss: 1.9873674787500852

Epoch: 6| Step: 5
Training loss: 2.2007126808166504
Validation loss: 1.9913729083153509

Epoch: 6| Step: 6
Training loss: 2.396916389465332
Validation loss: 1.9980079871352001

Epoch: 6| Step: 7
Training loss: 2.4717211723327637
Validation loss: 1.9866376640976116

Epoch: 6| Step: 8
Training loss: 2.015491008758545
Validation loss: 1.979645703428535

Epoch: 6| Step: 9
Training loss: 1.7805006504058838
Validation loss: 1.9949222546751781

Epoch: 6| Step: 10
Training loss: 1.45395827293396
Validation loss: 1.9772978392980431

Epoch: 6| Step: 11
Training loss: 2.078935146331787
Validation loss: 1.9852995359769432

Epoch: 6| Step: 12
Training loss: 2.2094435691833496
Validation loss: 1.9958497606297976

Epoch: 6| Step: 13
Training loss: 2.4659953117370605
Validation loss: 1.9924876241273777

Epoch: 68| Step: 0
Training loss: 1.9852936267852783
Validation loss: 1.9610298218265656

Epoch: 6| Step: 1
Training loss: 2.023646354675293
Validation loss: 1.9703249559607556

Epoch: 6| Step: 2
Training loss: 2.7014076709747314
Validation loss: 1.9669346130022438

Epoch: 6| Step: 3
Training loss: 1.8618264198303223
Validation loss: 1.9742213884989421

Epoch: 6| Step: 4
Training loss: 1.7630891799926758
Validation loss: 1.969202108280633

Epoch: 6| Step: 5
Training loss: 1.615447759628296
Validation loss: 1.9386159694322975

Epoch: 6| Step: 6
Training loss: 2.88669753074646
Validation loss: 1.9696804169685609

Epoch: 6| Step: 7
Training loss: 2.473525047302246
Validation loss: 1.973034893312762

Epoch: 6| Step: 8
Training loss: 1.986098051071167
Validation loss: 1.964933959386682

Epoch: 6| Step: 9
Training loss: 1.9430466890335083
Validation loss: 1.9573865962284867

Epoch: 6| Step: 10
Training loss: 2.740560531616211
Validation loss: 1.9735147491578133

Epoch: 6| Step: 11
Training loss: 2.1685585975646973
Validation loss: 1.9819225354861187

Epoch: 6| Step: 12
Training loss: 2.479541778564453
Validation loss: 1.9593344657651839

Epoch: 6| Step: 13
Training loss: 2.2956881523132324
Validation loss: 1.9536277786377938

Epoch: 69| Step: 0
Training loss: 2.7184486389160156
Validation loss: 1.954829559531263

Epoch: 6| Step: 1
Training loss: 1.763547658920288
Validation loss: 1.955767834058372

Epoch: 6| Step: 2
Training loss: 1.7215945720672607
Validation loss: 1.964999311713762

Epoch: 6| Step: 3
Training loss: 2.483177661895752
Validation loss: 1.9519081218268282

Epoch: 6| Step: 4
Training loss: 2.2473530769348145
Validation loss: 1.9714174757721603

Epoch: 6| Step: 5
Training loss: 2.088792562484741
Validation loss: 1.957453586721933

Epoch: 6| Step: 6
Training loss: 2.3380093574523926
Validation loss: 1.9623537512235745

Epoch: 6| Step: 7
Training loss: 2.3913116455078125
Validation loss: 1.9326737260305753

Epoch: 6| Step: 8
Training loss: 2.1198313236236572
Validation loss: 1.9885239857499317

Epoch: 6| Step: 9
Training loss: 2.324380397796631
Validation loss: 1.9591733447967037

Epoch: 6| Step: 10
Training loss: 2.2156481742858887
Validation loss: 1.9620600797796761

Epoch: 6| Step: 11
Training loss: 1.9695934057235718
Validation loss: 1.9869794230307303

Epoch: 6| Step: 12
Training loss: 2.395090103149414
Validation loss: 1.9564530029091785

Epoch: 6| Step: 13
Training loss: 2.4235668182373047
Validation loss: 1.9604350533536685

Epoch: 70| Step: 0
Training loss: 2.3165533542633057
Validation loss: 1.9771083157549623

Epoch: 6| Step: 1
Training loss: 2.1609420776367188
Validation loss: 1.942061738301349

Epoch: 6| Step: 2
Training loss: 2.2040047645568848
Validation loss: 1.9532956513025428

Epoch: 6| Step: 3
Training loss: 1.9269118309020996
Validation loss: 1.9804075648707729

Epoch: 6| Step: 4
Training loss: 2.2276506423950195
Validation loss: 1.9657584326241606

Epoch: 6| Step: 5
Training loss: 2.2000231742858887
Validation loss: 1.9379501419682656

Epoch: 6| Step: 6
Training loss: 2.4959375858306885
Validation loss: 1.9821184181397962

Epoch: 6| Step: 7
Training loss: 2.602519989013672
Validation loss: 1.9639942287116923

Epoch: 6| Step: 8
Training loss: 2.074246644973755
Validation loss: 1.9715920366266722

Epoch: 6| Step: 9
Training loss: 1.932479977607727
Validation loss: 1.9619793866270332

Epoch: 6| Step: 10
Training loss: 2.140533685684204
Validation loss: 1.959158387235416

Epoch: 6| Step: 11
Training loss: 2.1782984733581543
Validation loss: 1.9628489261032434

Epoch: 6| Step: 12
Training loss: 2.7182400226593018
Validation loss: 1.9568309848026564

Epoch: 6| Step: 13
Training loss: 1.3295502662658691
Validation loss: 1.9671395337709816

Epoch: 71| Step: 0
Training loss: 2.1106231212615967
Validation loss: 1.9655845601071593

Epoch: 6| Step: 1
Training loss: 2.763399124145508
Validation loss: 1.9677503006432646

Epoch: 6| Step: 2
Training loss: 1.9616539478302002
Validation loss: 1.9916493918306084

Epoch: 6| Step: 3
Training loss: 2.186067581176758
Validation loss: 1.961662737272119

Epoch: 6| Step: 4
Training loss: 2.0522165298461914
Validation loss: 1.9741828800529562

Epoch: 6| Step: 5
Training loss: 2.9225966930389404
Validation loss: 1.9758868140559043

Epoch: 6| Step: 6
Training loss: 2.1189963817596436
Validation loss: 1.9858382389109621

Epoch: 6| Step: 7
Training loss: 1.975084900856018
Validation loss: 1.9822888861420334

Epoch: 6| Step: 8
Training loss: 2.821014881134033
Validation loss: 1.9768841804996613

Epoch: 6| Step: 9
Training loss: 2.2603371143341064
Validation loss: 1.9644089552663988

Epoch: 6| Step: 10
Training loss: 1.6529452800750732
Validation loss: 1.967019691262194

Epoch: 6| Step: 11
Training loss: 2.1610636711120605
Validation loss: 1.961670708912675

Epoch: 6| Step: 12
Training loss: 2.079005479812622
Validation loss: 1.9897846855143064

Epoch: 6| Step: 13
Training loss: 1.8114746809005737
Validation loss: 1.9470764834393737

Epoch: 72| Step: 0
Training loss: 2.1460683345794678
Validation loss: 1.9729104939327444

Epoch: 6| Step: 1
Training loss: 2.171088695526123
Validation loss: 1.973479401680731

Epoch: 6| Step: 2
Training loss: 2.1240274906158447
Validation loss: 1.9837007804583477

Epoch: 6| Step: 3
Training loss: 1.573311686515808
Validation loss: 1.9810085040266796

Epoch: 6| Step: 4
Training loss: 2.603055953979492
Validation loss: 1.9951917253514773

Epoch: 6| Step: 5
Training loss: 2.330197334289551
Validation loss: 1.9627351901864494

Epoch: 6| Step: 6
Training loss: 1.951840877532959
Validation loss: 1.9993775672810052

Epoch: 6| Step: 7
Training loss: 2.717407703399658
Validation loss: 1.9708023468653362

Epoch: 6| Step: 8
Training loss: 1.8678460121154785
Validation loss: 1.9804949798891622

Epoch: 6| Step: 9
Training loss: 1.9663639068603516
Validation loss: 1.9547390014894548

Epoch: 6| Step: 10
Training loss: 2.4846584796905518
Validation loss: 1.9619349100256478

Epoch: 6| Step: 11
Training loss: 2.108517646789551
Validation loss: 1.9613689402098298

Epoch: 6| Step: 12
Training loss: 2.8057126998901367
Validation loss: 1.9858188834241641

Epoch: 6| Step: 13
Training loss: 1.901304006576538
Validation loss: 1.9499162076621928

Epoch: 73| Step: 0
Training loss: 2.125310182571411
Validation loss: 1.9538874920978342

Epoch: 6| Step: 1
Training loss: 2.0368752479553223
Validation loss: 1.973943220671787

Epoch: 6| Step: 2
Training loss: 2.24648380279541
Validation loss: 1.9902943821363552

Epoch: 6| Step: 3
Training loss: 2.121110200881958
Validation loss: 1.9799777282181608

Epoch: 6| Step: 4
Training loss: 2.508622646331787
Validation loss: 1.972122125728156

Epoch: 6| Step: 5
Training loss: 3.0558457374572754
Validation loss: 1.970066855030675

Epoch: 6| Step: 6
Training loss: 2.0188968181610107
Validation loss: 1.978022454887308

Epoch: 6| Step: 7
Training loss: 1.6648073196411133
Validation loss: 1.969783144612466

Epoch: 6| Step: 8
Training loss: 1.7375603914260864
Validation loss: 1.9800607183928132

Epoch: 6| Step: 9
Training loss: 2.1286916732788086
Validation loss: 2.003693103790283

Epoch: 6| Step: 10
Training loss: 2.1977169513702393
Validation loss: 1.9769630073219218

Epoch: 6| Step: 11
Training loss: 2.4897305965423584
Validation loss: 2.000437392983385

Epoch: 6| Step: 12
Training loss: 2.26710844039917
Validation loss: 1.972950609781409

Epoch: 6| Step: 13
Training loss: 2.591629981994629
Validation loss: 1.987956662331858

Epoch: 74| Step: 0
Training loss: 2.207996368408203
Validation loss: 1.9805473025127123

Epoch: 6| Step: 1
Training loss: 1.849426507949829
Validation loss: 1.9780158253126248

Epoch: 6| Step: 2
Training loss: 1.985114336013794
Validation loss: 1.9814378394875476

Epoch: 6| Step: 3
Training loss: 2.172391414642334
Validation loss: 1.9799942470365954

Epoch: 6| Step: 4
Training loss: 1.7699475288391113
Validation loss: 1.988579237332908

Epoch: 6| Step: 5
Training loss: 2.2879207134246826
Validation loss: 1.9869188570207166

Epoch: 6| Step: 6
Training loss: 2.8308448791503906
Validation loss: 1.9775369064782256

Epoch: 6| Step: 7
Training loss: 1.8721532821655273
Validation loss: 1.9735282928712907

Epoch: 6| Step: 8
Training loss: 3.0590782165527344
Validation loss: 1.9636139382598221

Epoch: 6| Step: 9
Training loss: 1.9001972675323486
Validation loss: 1.9885582103524158

Epoch: 6| Step: 10
Training loss: 1.9763164520263672
Validation loss: 1.9691790239785307

Epoch: 6| Step: 11
Training loss: 1.9644708633422852
Validation loss: 1.9683323778131956

Epoch: 6| Step: 12
Training loss: 2.3992207050323486
Validation loss: 1.97855552165739

Epoch: 6| Step: 13
Training loss: 2.744635820388794
Validation loss: 1.9647761339782386

Epoch: 75| Step: 0
Training loss: 2.521757125854492
Validation loss: 1.9712936057839343

Epoch: 6| Step: 1
Training loss: 1.876274824142456
Validation loss: 1.9588480329000821

Epoch: 6| Step: 2
Training loss: 2.2041895389556885
Validation loss: 1.9851943139106996

Epoch: 6| Step: 3
Training loss: 1.8775204420089722
Validation loss: 1.9479879794582244

Epoch: 6| Step: 4
Training loss: 2.2701539993286133
Validation loss: 1.9666503449921966

Epoch: 6| Step: 5
Training loss: 2.302072525024414
Validation loss: 1.9703028150784072

Epoch: 6| Step: 6
Training loss: 2.368508815765381
Validation loss: 1.9826754498225387

Epoch: 6| Step: 7
Training loss: 1.4669344425201416
Validation loss: 1.9618575355058074

Epoch: 6| Step: 8
Training loss: 2.974917411804199
Validation loss: 1.9539994501298474

Epoch: 6| Step: 9
Training loss: 2.39473557472229
Validation loss: 1.9547074712732786

Epoch: 6| Step: 10
Training loss: 2.246018886566162
Validation loss: 1.9621703624725342

Epoch: 6| Step: 11
Training loss: 2.433818817138672
Validation loss: 1.9569481060069094

Epoch: 6| Step: 12
Training loss: 2.214337110519409
Validation loss: 1.9274391743444628

Epoch: 6| Step: 13
Training loss: 1.3845540285110474
Validation loss: 1.9582253745807114

Epoch: 76| Step: 0
Training loss: 2.3339762687683105
Validation loss: 1.9482341889412171

Epoch: 6| Step: 1
Training loss: 2.0574228763580322
Validation loss: 1.9588737436520156

Epoch: 6| Step: 2
Training loss: 1.6849536895751953
Validation loss: 1.9518316150993429

Epoch: 6| Step: 3
Training loss: 1.4448795318603516
Validation loss: 1.9359830194903958

Epoch: 6| Step: 4
Training loss: 1.991036057472229
Validation loss: 1.9536640028799734

Epoch: 6| Step: 5
Training loss: 1.7653045654296875
Validation loss: 1.9677475729296285

Epoch: 6| Step: 6
Training loss: 1.8585206270217896
Validation loss: 1.9501082884368075

Epoch: 6| Step: 7
Training loss: 2.3745055198669434
Validation loss: 1.9428483965576335

Epoch: 6| Step: 8
Training loss: 2.4262280464172363
Validation loss: 1.936844818053707

Epoch: 6| Step: 9
Training loss: 2.521904945373535
Validation loss: 1.9385031205351635

Epoch: 6| Step: 10
Training loss: 2.8304858207702637
Validation loss: 1.950284122138895

Epoch: 6| Step: 11
Training loss: 3.259974479675293
Validation loss: 1.9347615882914553

Epoch: 6| Step: 12
Training loss: 2.1157877445220947
Validation loss: 1.9421124445494784

Epoch: 6| Step: 13
Training loss: 2.1705245971679688
Validation loss: 1.9471563190542243

Epoch: 77| Step: 0
Training loss: 2.5922932624816895
Validation loss: 1.9605565173651582

Epoch: 6| Step: 1
Training loss: 2.3302981853485107
Validation loss: 1.9522949277713735

Epoch: 6| Step: 2
Training loss: 1.6348011493682861
Validation loss: 1.9470868700294084

Epoch: 6| Step: 3
Training loss: 1.9190362691879272
Validation loss: 1.9555972212104387

Epoch: 6| Step: 4
Training loss: 1.9962455034255981
Validation loss: 1.973105756185388

Epoch: 6| Step: 5
Training loss: 2.924197196960449
Validation loss: 1.960442107210877

Epoch: 6| Step: 6
Training loss: 2.315586805343628
Validation loss: 1.9549663143773233

Epoch: 6| Step: 7
Training loss: 1.881277084350586
Validation loss: 1.958980482111695

Epoch: 6| Step: 8
Training loss: 2.358083963394165
Validation loss: 1.9684602060625631

Epoch: 6| Step: 9
Training loss: 2.701169013977051
Validation loss: 1.9817635602848505

Epoch: 6| Step: 10
Training loss: 1.5530200004577637
Validation loss: 1.9849476980906662

Epoch: 6| Step: 11
Training loss: 1.8245031833648682
Validation loss: 1.9699262854873494

Epoch: 6| Step: 12
Training loss: 2.563721179962158
Validation loss: 1.9892592019932245

Epoch: 6| Step: 13
Training loss: 2.2198240756988525
Validation loss: 1.99621126215945

Epoch: 78| Step: 0
Training loss: 1.795870304107666
Validation loss: 1.9580579932017992

Epoch: 6| Step: 1
Training loss: 3.0666065216064453
Validation loss: 1.969455530566554

Epoch: 6| Step: 2
Training loss: 1.4230155944824219
Validation loss: 1.9637879543406989

Epoch: 6| Step: 3
Training loss: 1.515242576599121
Validation loss: 1.9867571387239682

Epoch: 6| Step: 4
Training loss: 1.9358187913894653
Validation loss: 1.962293485159515

Epoch: 6| Step: 5
Training loss: 2.163865089416504
Validation loss: 1.9838970143307921

Epoch: 6| Step: 6
Training loss: 2.017608880996704
Validation loss: 1.9729348100641722

Epoch: 6| Step: 7
Training loss: 2.3847904205322266
Validation loss: 1.9601834166434504

Epoch: 6| Step: 8
Training loss: 2.262150764465332
Validation loss: 1.9791150631443146

Epoch: 6| Step: 9
Training loss: 2.687629461288452
Validation loss: 1.9575296499395882

Epoch: 6| Step: 10
Training loss: 2.9865150451660156
Validation loss: 1.991321374011296

Epoch: 6| Step: 11
Training loss: 3.1995630264282227
Validation loss: 1.9722086127086351

Epoch: 6| Step: 12
Training loss: 1.514978289604187
Validation loss: 1.9473178668688702

Epoch: 6| Step: 13
Training loss: 2.010146141052246
Validation loss: 1.955351577010206

Epoch: 79| Step: 0
Training loss: 2.5830626487731934
Validation loss: 1.9672568844210716

Epoch: 6| Step: 1
Training loss: 3.018617630004883
Validation loss: 1.9411579408953268

Epoch: 6| Step: 2
Training loss: 1.672757863998413
Validation loss: 1.9688428807002243

Epoch: 6| Step: 3
Training loss: 1.954551100730896
Validation loss: 1.9572562915022655

Epoch: 6| Step: 4
Training loss: 1.8385225534439087
Validation loss: 1.9407060146331787

Epoch: 6| Step: 5
Training loss: 2.169887065887451
Validation loss: 1.953071363510624

Epoch: 6| Step: 6
Training loss: 2.7071242332458496
Validation loss: 1.963179954918482

Epoch: 6| Step: 7
Training loss: 1.9029682874679565
Validation loss: 1.961078574580531

Epoch: 6| Step: 8
Training loss: 2.652848243713379
Validation loss: 1.9490117783187537

Epoch: 6| Step: 9
Training loss: 1.9422622919082642
Validation loss: 1.944353038264859

Epoch: 6| Step: 10
Training loss: 1.54245924949646
Validation loss: 1.9582006136576335

Epoch: 6| Step: 11
Training loss: 2.178511142730713
Validation loss: 1.9733177038931078

Epoch: 6| Step: 12
Training loss: 2.340322732925415
Validation loss: 1.9507546155683455

Epoch: 6| Step: 13
Training loss: 2.324439287185669
Validation loss: 1.9497575029250114

Epoch: 80| Step: 0
Training loss: 2.0897297859191895
Validation loss: 1.9539976837814494

Epoch: 6| Step: 1
Training loss: 2.7259597778320312
Validation loss: 1.9485603147937405

Epoch: 6| Step: 2
Training loss: 2.373915672302246
Validation loss: 1.967304539936845

Epoch: 6| Step: 3
Training loss: 2.0911355018615723
Validation loss: 1.9653931407518284

Epoch: 6| Step: 4
Training loss: 2.327214241027832
Validation loss: 1.9694084890427128

Epoch: 6| Step: 5
Training loss: 2.2956056594848633
Validation loss: 1.9232805364875383

Epoch: 6| Step: 6
Training loss: 1.8487743139266968
Validation loss: 1.9608528844771846

Epoch: 6| Step: 7
Training loss: 1.648707389831543
Validation loss: 1.9594551876027098

Epoch: 6| Step: 8
Training loss: 2.0853633880615234
Validation loss: 1.9829847146106023

Epoch: 6| Step: 9
Training loss: 2.3961410522460938
Validation loss: 1.983796142762707

Epoch: 6| Step: 10
Training loss: 2.598738431930542
Validation loss: 1.9564743516265706

Epoch: 6| Step: 11
Training loss: 2.1477060317993164
Validation loss: 1.9757035111868253

Epoch: 6| Step: 12
Training loss: 1.9125667810440063
Validation loss: 1.977800779445197

Epoch: 6| Step: 13
Training loss: 2.1379427909851074
Validation loss: 1.9584332140543128

Epoch: 81| Step: 0
Training loss: 2.2840490341186523
Validation loss: 1.9850730255085935

Epoch: 6| Step: 1
Training loss: 2.517058849334717
Validation loss: 1.975573706370528

Epoch: 6| Step: 2
Training loss: 1.8601446151733398
Validation loss: 1.9796823327259352

Epoch: 6| Step: 3
Training loss: 2.3111026287078857
Validation loss: 1.9758428630008493

Epoch: 6| Step: 4
Training loss: 2.09582257270813
Validation loss: 1.9340661187325754

Epoch: 6| Step: 5
Training loss: 2.422734022140503
Validation loss: 1.9572640875334382

Epoch: 6| Step: 6
Training loss: 2.149470329284668
Validation loss: 1.948607272999261

Epoch: 6| Step: 7
Training loss: 2.2400805950164795
Validation loss: 1.968650871707547

Epoch: 6| Step: 8
Training loss: 2.31845760345459
Validation loss: 1.9659901408738987

Epoch: 6| Step: 9
Training loss: 1.8626277446746826
Validation loss: 1.9763702525887439

Epoch: 6| Step: 10
Training loss: 2.6697771549224854
Validation loss: 1.9799824555714924

Epoch: 6| Step: 11
Training loss: 2.2787537574768066
Validation loss: 1.9475246001315374

Epoch: 6| Step: 12
Training loss: 2.2674288749694824
Validation loss: 1.9480272185417913

Epoch: 6| Step: 13
Training loss: 1.2599105834960938
Validation loss: 1.9807573954264324

Epoch: 82| Step: 0
Training loss: 2.4706685543060303
Validation loss: 2.00051760801705

Epoch: 6| Step: 1
Training loss: 2.2293665409088135
Validation loss: 2.0018866574892433

Epoch: 6| Step: 2
Training loss: 2.1857547760009766
Validation loss: 1.976293722788493

Epoch: 6| Step: 3
Training loss: 1.7714955806732178
Validation loss: 1.969420736835849

Epoch: 6| Step: 4
Training loss: 2.6213855743408203
Validation loss: 1.9907657125944733

Epoch: 6| Step: 5
Training loss: 2.1594247817993164
Validation loss: 1.9809618432034728

Epoch: 6| Step: 6
Training loss: 1.8902666568756104
Validation loss: 1.993487532420825

Epoch: 6| Step: 7
Training loss: 2.1405277252197266
Validation loss: 1.9926719627072733

Epoch: 6| Step: 8
Training loss: 2.055589437484741
Validation loss: 1.9913968373370428

Epoch: 6| Step: 9
Training loss: 2.2977089881896973
Validation loss: 1.9910199539635771

Epoch: 6| Step: 10
Training loss: 2.3649163246154785
Validation loss: 1.996933380762736

Epoch: 6| Step: 11
Training loss: 2.077537775039673
Validation loss: 1.9866310704138972

Epoch: 6| Step: 12
Training loss: 2.2667393684387207
Validation loss: 2.0006095247883953

Epoch: 6| Step: 13
Training loss: 2.338423728942871
Validation loss: 1.9877570354810326

Epoch: 83| Step: 0
Training loss: 1.9328372478485107
Validation loss: 1.9684539764158187

Epoch: 6| Step: 1
Training loss: 2.3137426376342773
Validation loss: 2.005862687223701

Epoch: 6| Step: 2
Training loss: 2.4823226928710938
Validation loss: 1.9825862300011419

Epoch: 6| Step: 3
Training loss: 2.839754343032837
Validation loss: 1.9808941451452111

Epoch: 6| Step: 4
Training loss: 2.0865697860717773
Validation loss: 1.971531411652924

Epoch: 6| Step: 5
Training loss: 2.0648159980773926
Validation loss: 1.995287190201462

Epoch: 6| Step: 6
Training loss: 3.0587782859802246
Validation loss: 1.9671998459805724

Epoch: 6| Step: 7
Training loss: 1.7906256914138794
Validation loss: 1.977498141668176

Epoch: 6| Step: 8
Training loss: 2.112438678741455
Validation loss: 2.0136763562438307

Epoch: 6| Step: 9
Training loss: 1.670727014541626
Validation loss: 1.9848202672055972

Epoch: 6| Step: 10
Training loss: 2.6027560234069824
Validation loss: 1.9862165194685741

Epoch: 6| Step: 11
Training loss: 2.4357211589813232
Validation loss: 1.990943826654906

Epoch: 6| Step: 12
Training loss: 1.7530279159545898
Validation loss: 1.9703479261808499

Epoch: 6| Step: 13
Training loss: 1.497538447380066
Validation loss: 1.9718548290191158

Epoch: 84| Step: 0
Training loss: 2.230614185333252
Validation loss: 1.9781845282482844

Epoch: 6| Step: 1
Training loss: 2.336280345916748
Validation loss: 1.957354127719838

Epoch: 6| Step: 2
Training loss: 2.34240460395813
Validation loss: 2.000421252301944

Epoch: 6| Step: 3
Training loss: 2.3743491172790527
Validation loss: 1.9858666568674066

Epoch: 6| Step: 4
Training loss: 2.264495849609375
Validation loss: 1.9610395867337462

Epoch: 6| Step: 5
Training loss: 2.5230071544647217
Validation loss: 1.9583067509435839

Epoch: 6| Step: 6
Training loss: 1.7590365409851074
Validation loss: 1.9915768408006238

Epoch: 6| Step: 7
Training loss: 2.0776281356811523
Validation loss: 1.995363325201055

Epoch: 6| Step: 8
Training loss: 2.053889036178589
Validation loss: 1.978114552395318

Epoch: 6| Step: 9
Training loss: 1.6938881874084473
Validation loss: 1.9864621149596347

Epoch: 6| Step: 10
Training loss: 2.5300211906433105
Validation loss: 1.9969780034916376

Epoch: 6| Step: 11
Training loss: 2.047832727432251
Validation loss: 1.9602928930713284

Epoch: 6| Step: 12
Training loss: 2.2074170112609863
Validation loss: 1.993709469354281

Epoch: 6| Step: 13
Training loss: 2.3244831562042236
Validation loss: 1.9902973739049767

Epoch: 85| Step: 0
Training loss: 1.868382215499878
Validation loss: 1.9846930273117558

Epoch: 6| Step: 1
Training loss: 1.9933418035507202
Validation loss: 1.9935688895563926

Epoch: 6| Step: 2
Training loss: 2.104332208633423
Validation loss: 1.9761644973549792

Epoch: 6| Step: 3
Training loss: 2.515228509902954
Validation loss: 1.9717512015373475

Epoch: 6| Step: 4
Training loss: 2.8679847717285156
Validation loss: 1.962995506102039

Epoch: 6| Step: 5
Training loss: 1.8208991289138794
Validation loss: 1.9831324136385353

Epoch: 6| Step: 6
Training loss: 2.711355686187744
Validation loss: 1.9595066667884908

Epoch: 6| Step: 7
Training loss: 2.1707634925842285
Validation loss: 1.9598866572944067

Epoch: 6| Step: 8
Training loss: 2.435704469680786
Validation loss: 1.9611005219080115

Epoch: 6| Step: 9
Training loss: 2.4630250930786133
Validation loss: 1.9534273096310195

Epoch: 6| Step: 10
Training loss: 1.8932442665100098
Validation loss: 1.9705579280853271

Epoch: 6| Step: 11
Training loss: 2.0665841102600098
Validation loss: 1.9697381014465003

Epoch: 6| Step: 12
Training loss: 1.6794655323028564
Validation loss: 1.9733724119842693

Epoch: 6| Step: 13
Training loss: 2.1589529514312744
Validation loss: 1.931741132531115

Epoch: 86| Step: 0
Training loss: 2.2040514945983887
Validation loss: 1.964288680784164

Epoch: 6| Step: 1
Training loss: 1.6560111045837402
Validation loss: 1.9820512417824037

Epoch: 6| Step: 2
Training loss: 2.7560291290283203
Validation loss: 2.000642232997443

Epoch: 6| Step: 3
Training loss: 1.7311640977859497
Validation loss: 1.9638868634418776

Epoch: 6| Step: 4
Training loss: 2.780151844024658
Validation loss: 1.9598992101607784

Epoch: 6| Step: 5
Training loss: 1.5757954120635986
Validation loss: 1.9847454614536737

Epoch: 6| Step: 6
Training loss: 2.1599068641662598
Validation loss: 1.969565745322935

Epoch: 6| Step: 7
Training loss: 2.229426145553589
Validation loss: 1.9830377640262726

Epoch: 6| Step: 8
Training loss: 2.7397427558898926
Validation loss: 1.965653407958246

Epoch: 6| Step: 9
Training loss: 1.7244558334350586
Validation loss: 1.979642411713959

Epoch: 6| Step: 10
Training loss: 1.8670947551727295
Validation loss: 1.9782821696291688

Epoch: 6| Step: 11
Training loss: 2.6303794384002686
Validation loss: 1.9740181738330471

Epoch: 6| Step: 12
Training loss: 2.237583637237549
Validation loss: 1.978171653645013

Epoch: 6| Step: 13
Training loss: 2.358574151992798
Validation loss: 1.9805582710491714

Epoch: 87| Step: 0
Training loss: 2.513699531555176
Validation loss: 1.977658135916597

Epoch: 6| Step: 1
Training loss: 2.765333652496338
Validation loss: 1.963088612402639

Epoch: 6| Step: 2
Training loss: 2.5776455402374268
Validation loss: 1.9695999532617547

Epoch: 6| Step: 3
Training loss: 2.5379438400268555
Validation loss: 1.9669958083860335

Epoch: 6| Step: 4
Training loss: 1.6689642667770386
Validation loss: 1.9630496937741515

Epoch: 6| Step: 5
Training loss: 2.249708890914917
Validation loss: 1.948878376714645

Epoch: 6| Step: 6
Training loss: 2.532766819000244
Validation loss: 1.9622160926941903

Epoch: 6| Step: 7
Training loss: 2.1476166248321533
Validation loss: 1.9663958229044431

Epoch: 6| Step: 8
Training loss: 1.4828569889068604
Validation loss: 1.9376117785771687

Epoch: 6| Step: 9
Training loss: 1.9395277500152588
Validation loss: 1.9391850104895971

Epoch: 6| Step: 10
Training loss: 2.423370599746704
Validation loss: 1.960966294811618

Epoch: 6| Step: 11
Training loss: 2.035978317260742
Validation loss: 1.9545304672692412

Epoch: 6| Step: 12
Training loss: 1.5308396816253662
Validation loss: 1.925920541568469

Epoch: 6| Step: 13
Training loss: 2.1539201736450195
Validation loss: 1.9542470080878145

Epoch: 88| Step: 0
Training loss: 2.2563962936401367
Validation loss: 1.9713161773579095

Epoch: 6| Step: 1
Training loss: 1.535361886024475
Validation loss: 1.9395084970740861

Epoch: 6| Step: 2
Training loss: 2.044424057006836
Validation loss: 1.9403335612307313

Epoch: 6| Step: 3
Training loss: 2.1966328620910645
Validation loss: 1.9562130461456955

Epoch: 6| Step: 4
Training loss: 2.6737422943115234
Validation loss: 1.9634990230683358

Epoch: 6| Step: 5
Training loss: 1.9404892921447754
Validation loss: 1.970048939028094

Epoch: 6| Step: 6
Training loss: 2.5688765048980713
Validation loss: 1.9890012151451522

Epoch: 6| Step: 7
Training loss: 1.8746955394744873
Validation loss: 1.9771829471793225

Epoch: 6| Step: 8
Training loss: 1.9493348598480225
Validation loss: 1.9522012305516068

Epoch: 6| Step: 9
Training loss: 2.3003244400024414
Validation loss: 1.9802358176118584

Epoch: 6| Step: 10
Training loss: 2.12593412399292
Validation loss: 1.967673304260418

Epoch: 6| Step: 11
Training loss: 2.316894054412842
Validation loss: 1.9782293035138039

Epoch: 6| Step: 12
Training loss: 2.434566020965576
Validation loss: 1.984375661419284

Epoch: 6| Step: 13
Training loss: 2.2294318675994873
Validation loss: 1.9715775866662302

Epoch: 89| Step: 0
Training loss: 1.3999109268188477
Validation loss: 1.9547343369453185

Epoch: 6| Step: 1
Training loss: 2.3815102577209473
Validation loss: 1.9576538403828938

Epoch: 6| Step: 2
Training loss: 2.474369525909424
Validation loss: 1.995554429869498

Epoch: 6| Step: 3
Training loss: 2.199401378631592
Validation loss: 1.960683527813163

Epoch: 6| Step: 4
Training loss: 1.848961353302002
Validation loss: 1.9925325096294444

Epoch: 6| Step: 5
Training loss: 1.7021360397338867
Validation loss: 1.9488305173894411

Epoch: 6| Step: 6
Training loss: 2.757664203643799
Validation loss: 1.9592696671844811

Epoch: 6| Step: 7
Training loss: 1.6147822141647339
Validation loss: 1.962395021992345

Epoch: 6| Step: 8
Training loss: 2.428431749343872
Validation loss: 1.9876586288534186

Epoch: 6| Step: 9
Training loss: 1.8595975637435913
Validation loss: 1.9644666935807915

Epoch: 6| Step: 10
Training loss: 2.576204299926758
Validation loss: 1.9776933180388583

Epoch: 6| Step: 11
Training loss: 1.8789794445037842
Validation loss: 1.9682589141271447

Epoch: 6| Step: 12
Training loss: 3.2238543033599854
Validation loss: 1.9663441194001066

Epoch: 6| Step: 13
Training loss: 1.989948034286499
Validation loss: 1.9842789967854817

Epoch: 90| Step: 0
Training loss: 2.300682306289673
Validation loss: 1.9688534890451739

Epoch: 6| Step: 1
Training loss: 2.4284772872924805
Validation loss: 1.9540589112107472

Epoch: 6| Step: 2
Training loss: 2.0165605545043945
Validation loss: 1.9841748873392742

Epoch: 6| Step: 3
Training loss: 1.5155515670776367
Validation loss: 1.967895883385853

Epoch: 6| Step: 4
Training loss: 1.692021369934082
Validation loss: 1.99464766440853

Epoch: 6| Step: 5
Training loss: 2.121046543121338
Validation loss: 1.9938208492853309

Epoch: 6| Step: 6
Training loss: 3.104790687561035
Validation loss: 1.9869547825987621

Epoch: 6| Step: 7
Training loss: 2.338799476623535
Validation loss: 1.975512857078224

Epoch: 6| Step: 8
Training loss: 2.0846400260925293
Validation loss: 1.9652737686710973

Epoch: 6| Step: 9
Training loss: 2.237710475921631
Validation loss: 1.957607033432171

Epoch: 6| Step: 10
Training loss: 2.23091983795166
Validation loss: 1.9724153703258884

Epoch: 6| Step: 11
Training loss: 2.203798294067383
Validation loss: 1.9732240592279742

Epoch: 6| Step: 12
Training loss: 2.0349998474121094
Validation loss: 1.9605792132757043

Epoch: 6| Step: 13
Training loss: 2.330815553665161
Validation loss: 1.9872744544859855

Epoch: 91| Step: 0
Training loss: 2.1038379669189453
Validation loss: 1.9811883344445178

Epoch: 6| Step: 1
Training loss: 1.7631915807724
Validation loss: 1.9634327196305799

Epoch: 6| Step: 2
Training loss: 2.2166495323181152
Validation loss: 1.972005933843633

Epoch: 6| Step: 3
Training loss: 2.545750617980957
Validation loss: 1.9892938239600069

Epoch: 6| Step: 4
Training loss: 1.6461055278778076
Validation loss: 1.9838435957508702

Epoch: 6| Step: 5
Training loss: 2.3597891330718994
Validation loss: 1.9618918562448153

Epoch: 6| Step: 6
Training loss: 1.945726990699768
Validation loss: 1.973131182373211

Epoch: 6| Step: 7
Training loss: 1.5822272300720215
Validation loss: 1.9878215892340547

Epoch: 6| Step: 8
Training loss: 3.2343006134033203
Validation loss: 1.9619813401211974

Epoch: 6| Step: 9
Training loss: 2.339137315750122
Validation loss: 1.9503896031328427

Epoch: 6| Step: 10
Training loss: 2.7763400077819824
Validation loss: 1.9689799880468717

Epoch: 6| Step: 11
Training loss: 2.232752799987793
Validation loss: 1.9719794962995796

Epoch: 6| Step: 12
Training loss: 1.6615501642227173
Validation loss: 1.9941481992762575

Epoch: 6| Step: 13
Training loss: 2.082087993621826
Validation loss: 1.950664097262967

Epoch: 92| Step: 0
Training loss: 1.2714840173721313
Validation loss: 1.9681481110152377

Epoch: 6| Step: 1
Training loss: 1.5709123611450195
Validation loss: 1.9814827993351927

Epoch: 6| Step: 2
Training loss: 2.429593801498413
Validation loss: 1.9789738167998612

Epoch: 6| Step: 3
Training loss: 1.4322283267974854
Validation loss: 2.0005729057455577

Epoch: 6| Step: 4
Training loss: 2.800049304962158
Validation loss: 1.9732066226261917

Epoch: 6| Step: 5
Training loss: 2.8701014518737793
Validation loss: 1.984798800560736

Epoch: 6| Step: 6
Training loss: 2.523655652999878
Validation loss: 1.9923168843792332

Epoch: 6| Step: 7
Training loss: 1.9271371364593506
Validation loss: 1.982976887815742

Epoch: 6| Step: 8
Training loss: 1.7291014194488525
Validation loss: 1.991599472620154

Epoch: 6| Step: 9
Training loss: 2.8590102195739746
Validation loss: 1.9813126107697845

Epoch: 6| Step: 10
Training loss: 1.9734398126602173
Validation loss: 1.9888730792589084

Epoch: 6| Step: 11
Training loss: 2.5238757133483887
Validation loss: 1.9911810723684167

Epoch: 6| Step: 12
Training loss: 2.5519309043884277
Validation loss: 1.9771753075302287

Epoch: 6| Step: 13
Training loss: 1.9219648838043213
Validation loss: 2.000140074760683

Epoch: 93| Step: 0
Training loss: 1.9714620113372803
Validation loss: 1.9986904282723703

Epoch: 6| Step: 1
Training loss: 2.044792413711548
Validation loss: 1.9795185840258034

Epoch: 6| Step: 2
Training loss: 2.2987473011016846
Validation loss: 1.9894807979624758

Epoch: 6| Step: 3
Training loss: 1.1894909143447876
Validation loss: 1.9635848345295075

Epoch: 6| Step: 4
Training loss: 1.7603849172592163
Validation loss: 1.9786107950313117

Epoch: 6| Step: 5
Training loss: 1.9133596420288086
Validation loss: 1.9772449590826546

Epoch: 6| Step: 6
Training loss: 2.5054783821105957
Validation loss: 1.9972684383392334

Epoch: 6| Step: 7
Training loss: 2.797882080078125
Validation loss: 1.9697997903311124

Epoch: 6| Step: 8
Training loss: 1.843979835510254
Validation loss: 1.9938065134068972

Epoch: 6| Step: 9
Training loss: 2.1884312629699707
Validation loss: 1.9899373669778146

Epoch: 6| Step: 10
Training loss: 2.2193188667297363
Validation loss: 2.003605135025517

Epoch: 6| Step: 11
Training loss: 2.420562267303467
Validation loss: 1.9909155984078684

Epoch: 6| Step: 12
Training loss: 2.7713441848754883
Validation loss: 2.0013688482264036

Epoch: 6| Step: 13
Training loss: 2.5998828411102295
Validation loss: 1.985724320975683

Epoch: 94| Step: 0
Training loss: 2.7555360794067383
Validation loss: 1.9841773227978778

Epoch: 6| Step: 1
Training loss: 1.8782734870910645
Validation loss: 1.97929520504449

Epoch: 6| Step: 2
Training loss: 2.4419679641723633
Validation loss: 1.993988234509704

Epoch: 6| Step: 3
Training loss: 2.0564985275268555
Validation loss: 1.967709300338581

Epoch: 6| Step: 4
Training loss: 1.5563578605651855
Validation loss: 1.9808663475898005

Epoch: 6| Step: 5
Training loss: 1.6767792701721191
Validation loss: 1.9652301688348093

Epoch: 6| Step: 6
Training loss: 1.7485713958740234
Validation loss: 1.987666227484262

Epoch: 6| Step: 7
Training loss: 1.8194464445114136
Validation loss: 1.973459812902635

Epoch: 6| Step: 8
Training loss: 2.8219621181488037
Validation loss: 1.98176178368189

Epoch: 6| Step: 9
Training loss: 2.7891669273376465
Validation loss: 1.9669487796803957

Epoch: 6| Step: 10
Training loss: 2.0568575859069824
Validation loss: 1.9866385318899666

Epoch: 6| Step: 11
Training loss: 2.1371941566467285
Validation loss: 1.9689107582133303

Epoch: 6| Step: 12
Training loss: 2.2140843868255615
Validation loss: 1.9766295443298996

Epoch: 6| Step: 13
Training loss: 2.405925989151001
Validation loss: 1.9780491064953547

Epoch: 95| Step: 0
Training loss: 2.261446475982666
Validation loss: 1.9644403970369728

Epoch: 6| Step: 1
Training loss: 2.534193992614746
Validation loss: 1.9769556163459696

Epoch: 6| Step: 2
Training loss: 2.1515021324157715
Validation loss: 1.9751964910056001

Epoch: 6| Step: 3
Training loss: 2.455220937728882
Validation loss: 1.978850959449686

Epoch: 6| Step: 4
Training loss: 2.242244243621826
Validation loss: 1.9720025229197677

Epoch: 6| Step: 5
Training loss: 2.38767147064209
Validation loss: 1.9804260218015282

Epoch: 6| Step: 6
Training loss: 1.7102079391479492
Validation loss: 1.9758560478046376

Epoch: 6| Step: 7
Training loss: 2.048153877258301
Validation loss: 1.9500653000288113

Epoch: 6| Step: 8
Training loss: 2.1381759643554688
Validation loss: 1.951707939947805

Epoch: 6| Step: 9
Training loss: 2.083521842956543
Validation loss: 1.9863726298014324

Epoch: 6| Step: 10
Training loss: 2.728440999984741
Validation loss: 1.9810254868640695

Epoch: 6| Step: 11
Training loss: 1.9937784671783447
Validation loss: 1.985276101737894

Epoch: 6| Step: 12
Training loss: 1.5267030000686646
Validation loss: 1.9614490309069235

Epoch: 6| Step: 13
Training loss: 2.0793087482452393
Validation loss: 1.9519703311304892

Epoch: 96| Step: 0
Training loss: 2.286189556121826
Validation loss: 1.970861101663241

Epoch: 6| Step: 1
Training loss: 2.0128746032714844
Validation loss: 1.9836769591095627

Epoch: 6| Step: 2
Training loss: 2.0275521278381348
Validation loss: 1.9714814078423284

Epoch: 6| Step: 3
Training loss: 2.0764286518096924
Validation loss: 1.9568048728409635

Epoch: 6| Step: 4
Training loss: 1.9614695310592651
Validation loss: 1.9881186408381308

Epoch: 6| Step: 5
Training loss: 2.702090263366699
Validation loss: 1.9636761616635066

Epoch: 6| Step: 6
Training loss: 2.4712424278259277
Validation loss: 1.993488105394507

Epoch: 6| Step: 7
Training loss: 1.7397202253341675
Validation loss: 2.007041682479202

Epoch: 6| Step: 8
Training loss: 2.0897715091705322
Validation loss: 1.970251428183689

Epoch: 6| Step: 9
Training loss: 2.219099283218384
Validation loss: 1.9883365426012265

Epoch: 6| Step: 10
Training loss: 2.776893138885498
Validation loss: 1.996112015939528

Epoch: 6| Step: 11
Training loss: 1.8657402992248535
Validation loss: 2.0035044608577603

Epoch: 6| Step: 12
Training loss: 1.573169231414795
Validation loss: 1.9841133650913034

Epoch: 6| Step: 13
Training loss: 3.1723039150238037
Validation loss: 1.972516312394091

Epoch: 97| Step: 0
Training loss: 2.355757713317871
Validation loss: 1.9665360271289785

Epoch: 6| Step: 1
Training loss: 2.9306740760803223
Validation loss: 1.9675948991570422

Epoch: 6| Step: 2
Training loss: 2.045693874359131
Validation loss: 1.9868022882810203

Epoch: 6| Step: 3
Training loss: 1.4338544607162476
Validation loss: 1.9821452620208904

Epoch: 6| Step: 4
Training loss: 2.059015989303589
Validation loss: 1.9528638201375161

Epoch: 6| Step: 5
Training loss: 2.0053422451019287
Validation loss: 1.991834363629741

Epoch: 6| Step: 6
Training loss: 3.009507656097412
Validation loss: 1.9748735312492616

Epoch: 6| Step: 7
Training loss: 2.3722567558288574
Validation loss: 1.9612202029074393

Epoch: 6| Step: 8
Training loss: 2.6451973915100098
Validation loss: 1.9597500062757922

Epoch: 6| Step: 9
Training loss: 1.8646825551986694
Validation loss: 1.9855534671455302

Epoch: 6| Step: 10
Training loss: 1.8272156715393066
Validation loss: 1.9768626843729327

Epoch: 6| Step: 11
Training loss: 2.060671329498291
Validation loss: 1.9688872880833124

Epoch: 6| Step: 12
Training loss: 1.7295747995376587
Validation loss: 1.9923092498574206

Epoch: 6| Step: 13
Training loss: 1.7941404581069946
Validation loss: 1.9609914979627054

Epoch: 98| Step: 0
Training loss: 2.3019754886627197
Validation loss: 1.9618664454388361

Epoch: 6| Step: 1
Training loss: 1.9831312894821167
Validation loss: 1.972989736064788

Epoch: 6| Step: 2
Training loss: 2.4800338745117188
Validation loss: 1.9806275983010568

Epoch: 6| Step: 3
Training loss: 2.57504940032959
Validation loss: 1.975900193696381

Epoch: 6| Step: 4
Training loss: 2.608224868774414
Validation loss: 1.9576435345475391

Epoch: 6| Step: 5
Training loss: 2.208374261856079
Validation loss: 1.941172933065763

Epoch: 6| Step: 6
Training loss: 2.126046657562256
Validation loss: 1.943003241733838

Epoch: 6| Step: 7
Training loss: 1.6983747482299805
Validation loss: 1.9625580951731691

Epoch: 6| Step: 8
Training loss: 2.151700973510742
Validation loss: 1.9549272470576788

Epoch: 6| Step: 9
Training loss: 1.0235960483551025
Validation loss: 1.9688827107029576

Epoch: 6| Step: 10
Training loss: 1.6042910814285278
Validation loss: 1.9524545105554725

Epoch: 6| Step: 11
Training loss: 2.4803202152252197
Validation loss: 1.9742555669558945

Epoch: 6| Step: 12
Training loss: 2.8709938526153564
Validation loss: 1.9826206520039549

Epoch: 6| Step: 13
Training loss: 1.8116800785064697
Validation loss: 1.9597904323249735

Epoch: 99| Step: 0
Training loss: 1.514258623123169
Validation loss: 1.9475066533652685

Epoch: 6| Step: 1
Training loss: 3.041437864303589
Validation loss: 1.9646394919323664

Epoch: 6| Step: 2
Training loss: 2.045996904373169
Validation loss: 1.9663697827246882

Epoch: 6| Step: 3
Training loss: 2.1431031227111816
Validation loss: 1.9554835340028167

Epoch: 6| Step: 4
Training loss: 1.8738174438476562
Validation loss: 1.9835395505351405

Epoch: 6| Step: 5
Training loss: 1.843693494796753
Validation loss: 1.970489610907852

Epoch: 6| Step: 6
Training loss: 2.6020798683166504
Validation loss: 1.9761861216637395

Epoch: 6| Step: 7
Training loss: 1.85563063621521
Validation loss: 1.9783174581425165

Epoch: 6| Step: 8
Training loss: 2.9197568893432617
Validation loss: 1.9652082996983682

Epoch: 6| Step: 9
Training loss: 2.608752727508545
Validation loss: 1.979509545910743

Epoch: 6| Step: 10
Training loss: 1.8252663612365723
Validation loss: 1.9663421928241689

Epoch: 6| Step: 11
Training loss: 1.6103674173355103
Validation loss: 1.9758415657986876

Epoch: 6| Step: 12
Training loss: 2.2242536544799805
Validation loss: 1.9593735433393908

Epoch: 6| Step: 13
Training loss: 2.2287404537200928
Validation loss: 1.9638761333239976

Epoch: 100| Step: 0
Training loss: 1.5226261615753174
Validation loss: 1.966521006758495

Epoch: 6| Step: 1
Training loss: 2.235382080078125
Validation loss: 1.9560124053749988

Epoch: 6| Step: 2
Training loss: 2.328829288482666
Validation loss: 1.9793032907670545

Epoch: 6| Step: 3
Training loss: 2.390481472015381
Validation loss: 1.987967662913825

Epoch: 6| Step: 4
Training loss: 2.5284457206726074
Validation loss: 1.996170554109799

Epoch: 6| Step: 5
Training loss: 2.9989962577819824
Validation loss: 1.9828173216953073

Epoch: 6| Step: 6
Training loss: 2.319955348968506
Validation loss: 2.008681507520778

Epoch: 6| Step: 7
Training loss: 2.1184310913085938
Validation loss: 1.968989513253653

Epoch: 6| Step: 8
Training loss: 1.9183125495910645
Validation loss: 1.9907622529614357

Epoch: 6| Step: 9
Training loss: 2.3388772010803223
Validation loss: 1.9745197321778984

Epoch: 6| Step: 10
Training loss: 2.619276285171509
Validation loss: 1.9846280902944586

Epoch: 6| Step: 11
Training loss: 1.5048459768295288
Validation loss: 1.9616146869556879

Epoch: 6| Step: 12
Training loss: 1.4183366298675537
Validation loss: 1.9912521749414422

Epoch: 6| Step: 13
Training loss: 1.7770800590515137
Validation loss: 1.9991662040833504

Epoch: 101| Step: 0
Training loss: 1.9620660543441772
Validation loss: 2.005445256028124

Epoch: 6| Step: 1
Training loss: 2.179276943206787
Validation loss: 1.9946248608250772

Epoch: 6| Step: 2
Training loss: 1.965674877166748
Validation loss: 1.9763304238678308

Epoch: 6| Step: 3
Training loss: 2.6785950660705566
Validation loss: 1.991434685645565

Epoch: 6| Step: 4
Training loss: 2.8538684844970703
Validation loss: 1.9954141545039352

Epoch: 6| Step: 5
Training loss: 1.802311897277832
Validation loss: 1.9767166478659517

Epoch: 6| Step: 6
Training loss: 2.464031457901001
Validation loss: 1.9851423950605496

Epoch: 6| Step: 7
Training loss: 1.9679346084594727
Validation loss: 1.9894954030231764

Epoch: 6| Step: 8
Training loss: 2.2685256004333496
Validation loss: 1.9755519807979625

Epoch: 6| Step: 9
Training loss: 2.2374675273895264
Validation loss: 1.9894610528023011

Epoch: 6| Step: 10
Training loss: 1.72392737865448
Validation loss: 1.9672494601177912

Epoch: 6| Step: 11
Training loss: 2.121028184890747
Validation loss: 1.9597123053766066

Epoch: 6| Step: 12
Training loss: 2.3315634727478027
Validation loss: 1.9664539496103923

Epoch: 6| Step: 13
Training loss: 1.394326090812683
Validation loss: 2.0034382779111146

Epoch: 102| Step: 0
Training loss: 1.9578919410705566
Validation loss: 1.997813028673972

Epoch: 6| Step: 1
Training loss: 2.2665607929229736
Validation loss: 1.9735812064140075

Epoch: 6| Step: 2
Training loss: 2.0015106201171875
Validation loss: 1.9891410527690765

Epoch: 6| Step: 3
Training loss: 2.505065441131592
Validation loss: 1.9964098776540449

Epoch: 6| Step: 4
Training loss: 1.6742918491363525
Validation loss: 1.9957676651657268

Epoch: 6| Step: 5
Training loss: 1.976047158241272
Validation loss: 1.9913858611096618

Epoch: 6| Step: 6
Training loss: 1.6474926471710205
Validation loss: 1.9878343356552945

Epoch: 6| Step: 7
Training loss: 2.090811252593994
Validation loss: 1.9957821125625281

Epoch: 6| Step: 8
Training loss: 2.516246795654297
Validation loss: 1.9749826590220134

Epoch: 6| Step: 9
Training loss: 2.74269962310791
Validation loss: 1.9730574623230965

Epoch: 6| Step: 10
Training loss: 2.461975574493408
Validation loss: 1.9748450152335628

Epoch: 6| Step: 11
Training loss: 2.3792107105255127
Validation loss: 1.9818533825617966

Epoch: 6| Step: 12
Training loss: 1.8591995239257812
Validation loss: 1.9727936137107112

Epoch: 6| Step: 13
Training loss: 2.322317123413086
Validation loss: 1.9690427908333399

Epoch: 103| Step: 0
Training loss: 1.9511901140213013
Validation loss: 1.9747266897591211

Epoch: 6| Step: 1
Training loss: 1.521323323249817
Validation loss: 1.9989452387696953

Epoch: 6| Step: 2
Training loss: 1.8005597591400146
Validation loss: 1.9966993716455275

Epoch: 6| Step: 3
Training loss: 3.4720606803894043
Validation loss: 2.005270904110324

Epoch: 6| Step: 4
Training loss: 2.8060178756713867
Validation loss: 1.9931382376660582

Epoch: 6| Step: 5
Training loss: 1.6275436878204346
Validation loss: 1.9965343629160235

Epoch: 6| Step: 6
Training loss: 2.552093982696533
Validation loss: 1.972904125849406

Epoch: 6| Step: 7
Training loss: 2.3559699058532715
Validation loss: 1.98779631686467

Epoch: 6| Step: 8
Training loss: 1.4247381687164307
Validation loss: 1.9780981053588211

Epoch: 6| Step: 9
Training loss: 2.5685172080993652
Validation loss: 1.9641530667581866

Epoch: 6| Step: 10
Training loss: 2.763611078262329
Validation loss: 1.9871213948854836

Epoch: 6| Step: 11
Training loss: 1.5555129051208496
Validation loss: 1.9882720183300715

Epoch: 6| Step: 12
Training loss: 1.9680659770965576
Validation loss: 1.966206196815737

Epoch: 6| Step: 13
Training loss: 1.6738706827163696
Validation loss: 1.9473394245229743

Epoch: 104| Step: 0
Training loss: 2.2534728050231934
Validation loss: 1.9740174944682787

Epoch: 6| Step: 1
Training loss: 1.7836514711380005
Validation loss: 1.984036942963959

Epoch: 6| Step: 2
Training loss: 1.7120580673217773
Validation loss: 1.9808446130444926

Epoch: 6| Step: 3
Training loss: 2.4939630031585693
Validation loss: 1.9623424840229813

Epoch: 6| Step: 4
Training loss: 2.0614686012268066
Validation loss: 1.9720430399781914

Epoch: 6| Step: 5
Training loss: 1.6041374206542969
Validation loss: 1.9547465680747904

Epoch: 6| Step: 6
Training loss: 2.813856601715088
Validation loss: 1.983633529755377

Epoch: 6| Step: 7
Training loss: 3.063169002532959
Validation loss: 1.9734202636185514

Epoch: 6| Step: 8
Training loss: 2.2182581424713135
Validation loss: 1.9582036361899426

Epoch: 6| Step: 9
Training loss: 1.9767935276031494
Validation loss: 1.9908909746395644

Epoch: 6| Step: 10
Training loss: 2.3551559448242188
Validation loss: 1.957453207303119

Epoch: 6| Step: 11
Training loss: 1.7743377685546875
Validation loss: 1.971594520794448

Epoch: 6| Step: 12
Training loss: 2.369638204574585
Validation loss: 1.972973051891532

Epoch: 6| Step: 13
Training loss: 1.4563887119293213
Validation loss: 1.979205657077092

Epoch: 105| Step: 0
Training loss: 1.7517640590667725
Validation loss: 1.952321643470436

Epoch: 6| Step: 1
Training loss: 1.9236642122268677
Validation loss: 1.9683833711890764

Epoch: 6| Step: 2
Training loss: 2.367743492126465
Validation loss: 1.9828954050617833

Epoch: 6| Step: 3
Training loss: 1.9565448760986328
Validation loss: 1.9630177072299424

Epoch: 6| Step: 4
Training loss: 1.6912205219268799
Validation loss: 1.9755268866016018

Epoch: 6| Step: 5
Training loss: 2.728203296661377
Validation loss: 1.9811081271017752

Epoch: 6| Step: 6
Training loss: 2.3927407264709473
Validation loss: 1.9679129046778525

Epoch: 6| Step: 7
Training loss: 2.401906728744507
Validation loss: 1.9978443396988737

Epoch: 6| Step: 8
Training loss: 2.563056468963623
Validation loss: 1.9806330639828917

Epoch: 6| Step: 9
Training loss: 2.019355297088623
Validation loss: 1.9935032501015613

Epoch: 6| Step: 10
Training loss: 1.7681233882904053
Validation loss: 1.9751216865354968

Epoch: 6| Step: 11
Training loss: 2.4782190322875977
Validation loss: 2.017054675727762

Epoch: 6| Step: 12
Training loss: 1.9872502088546753
Validation loss: 1.9855365509627967

Epoch: 6| Step: 13
Training loss: 1.8327715396881104
Validation loss: 1.9684671381468415

Epoch: 106| Step: 0
Training loss: 2.5879716873168945
Validation loss: 2.012599193921653

Epoch: 6| Step: 1
Training loss: 2.70029616355896
Validation loss: 2.0061581455251223

Epoch: 6| Step: 2
Training loss: 1.7889747619628906
Validation loss: 1.9996101151230514

Epoch: 6| Step: 3
Training loss: 2.356142520904541
Validation loss: 2.0032086974831036

Epoch: 6| Step: 4
Training loss: 1.9949569702148438
Validation loss: 1.9895321028206938

Epoch: 6| Step: 5
Training loss: 2.0137364864349365
Validation loss: 2.002034923081757

Epoch: 6| Step: 6
Training loss: 2.1158955097198486
Validation loss: 1.9827632288778982

Epoch: 6| Step: 7
Training loss: 1.918992519378662
Validation loss: 1.9898032244815622

Epoch: 6| Step: 8
Training loss: 2.583606719970703
Validation loss: 2.0147881148963847

Epoch: 6| Step: 9
Training loss: 2.409186363220215
Validation loss: 1.9838903501469602

Epoch: 6| Step: 10
Training loss: 1.8639369010925293
Validation loss: 2.019513790325452

Epoch: 6| Step: 11
Training loss: 1.4675052165985107
Validation loss: 1.993204919240808

Epoch: 6| Step: 12
Training loss: 2.14070463180542
Validation loss: 1.9779475324897355

Epoch: 6| Step: 13
Training loss: 2.1326894760131836
Validation loss: 1.9835436626147198

Epoch: 107| Step: 0
Training loss: 2.5367791652679443
Validation loss: 1.9922728999968498

Epoch: 6| Step: 1
Training loss: 2.2973132133483887
Validation loss: 1.9847014783531107

Epoch: 6| Step: 2
Training loss: 2.0818893909454346
Validation loss: 1.957593657637155

Epoch: 6| Step: 3
Training loss: 1.3438313007354736
Validation loss: 1.9720723680270615

Epoch: 6| Step: 4
Training loss: 1.907749891281128
Validation loss: 1.9402868106801023

Epoch: 6| Step: 5
Training loss: 2.0039515495300293
Validation loss: 1.9639929186913274

Epoch: 6| Step: 6
Training loss: 2.162447452545166
Validation loss: 1.9561201898000573

Epoch: 6| Step: 7
Training loss: 2.6571452617645264
Validation loss: 1.9785526516616985

Epoch: 6| Step: 8
Training loss: 2.1096529960632324
Validation loss: 1.9628911543917913

Epoch: 6| Step: 9
Training loss: 2.777848243713379
Validation loss: 1.9435040412410614

Epoch: 6| Step: 10
Training loss: 2.5138158798217773
Validation loss: 1.9621566111041653

Epoch: 6| Step: 11
Training loss: 2.026306390762329
Validation loss: 1.9868135939362228

Epoch: 6| Step: 12
Training loss: 2.0453097820281982
Validation loss: 1.9558925051842966

Epoch: 6| Step: 13
Training loss: 1.416430950164795
Validation loss: 1.9617672966372581

Epoch: 108| Step: 0
Training loss: 2.7279086112976074
Validation loss: 1.9826444912982244

Epoch: 6| Step: 1
Training loss: 2.0447702407836914
Validation loss: 1.9979595894454627

Epoch: 6| Step: 2
Training loss: 1.6076992750167847
Validation loss: 1.9549859851919196

Epoch: 6| Step: 3
Training loss: 3.014707565307617
Validation loss: 1.9651804739429104

Epoch: 6| Step: 4
Training loss: 2.2663702964782715
Validation loss: 1.9733334856648599

Epoch: 6| Step: 5
Training loss: 1.8260371685028076
Validation loss: 1.9577122888257426

Epoch: 6| Step: 6
Training loss: 1.9784958362579346
Validation loss: 1.9730937968018234

Epoch: 6| Step: 7
Training loss: 1.9118748903274536
Validation loss: 1.9725949315614597

Epoch: 6| Step: 8
Training loss: 1.6540005207061768
Validation loss: 1.9648303780504452

Epoch: 6| Step: 9
Training loss: 2.440608501434326
Validation loss: 1.9798755171478435

Epoch: 6| Step: 10
Training loss: 1.7311632633209229
Validation loss: 1.9639936211288616

Epoch: 6| Step: 11
Training loss: 1.8251125812530518
Validation loss: 1.9764050527285504

Epoch: 6| Step: 12
Training loss: 2.3913156986236572
Validation loss: 1.9823474935306016

Epoch: 6| Step: 13
Training loss: 3.322575569152832
Validation loss: 2.0122625750880085

Epoch: 109| Step: 0
Training loss: 1.779397964477539
Validation loss: 2.0088994887567337

Epoch: 6| Step: 1
Training loss: 2.0001723766326904
Validation loss: 1.980515049349877

Epoch: 6| Step: 2
Training loss: 1.9769394397735596
Validation loss: 1.9858597299104095

Epoch: 6| Step: 3
Training loss: 2.4858672618865967
Validation loss: 2.0037973439821632

Epoch: 6| Step: 4
Training loss: 2.5955986976623535
Validation loss: 1.996257225672404

Epoch: 6| Step: 5
Training loss: 1.8065898418426514
Validation loss: 1.9794587640352146

Epoch: 6| Step: 6
Training loss: 2.064814567565918
Validation loss: 1.990934475775688

Epoch: 6| Step: 7
Training loss: 2.518825054168701
Validation loss: 2.0158201289433304

Epoch: 6| Step: 8
Training loss: 2.2853922843933105
Validation loss: 1.9652235225964618

Epoch: 6| Step: 9
Training loss: 1.596711277961731
Validation loss: 1.9976508091854792

Epoch: 6| Step: 10
Training loss: 2.384457588195801
Validation loss: 1.9849138900797854

Epoch: 6| Step: 11
Training loss: 2.528326988220215
Validation loss: 1.9899149274313321

Epoch: 6| Step: 12
Training loss: 2.5270915031433105
Validation loss: 1.997730871682526

Epoch: 6| Step: 13
Training loss: 1.1781024932861328
Validation loss: 2.002249356239073

Epoch: 110| Step: 0
Training loss: 2.525798797607422
Validation loss: 1.987380935299781

Epoch: 6| Step: 1
Training loss: 1.860039234161377
Validation loss: 1.987834950929047

Epoch: 6| Step: 2
Training loss: 2.570767402648926
Validation loss: 2.013917310263521

Epoch: 6| Step: 3
Training loss: 2.325564384460449
Validation loss: 1.9795272452856905

Epoch: 6| Step: 4
Training loss: 2.018510580062866
Validation loss: 1.9989224146771174

Epoch: 6| Step: 5
Training loss: 2.07256817817688
Validation loss: 1.9856903271008564

Epoch: 6| Step: 6
Training loss: 2.030853271484375
Validation loss: 1.9663426465885614

Epoch: 6| Step: 7
Training loss: 2.3339219093322754
Validation loss: 1.9716611011053926

Epoch: 6| Step: 8
Training loss: 2.1762404441833496
Validation loss: 2.00078385491525

Epoch: 6| Step: 9
Training loss: 2.314237117767334
Validation loss: 1.9650238252455188

Epoch: 6| Step: 10
Training loss: 2.6821353435516357
Validation loss: 1.980867874237799

Epoch: 6| Step: 11
Training loss: 1.5157662630081177
Validation loss: 1.9691270859010759

Epoch: 6| Step: 12
Training loss: 1.6851848363876343
Validation loss: 1.9741706489234843

Epoch: 6| Step: 13
Training loss: 2.1302175521850586
Validation loss: 1.9698850493277273

Epoch: 111| Step: 0
Training loss: 1.7317237854003906
Validation loss: 1.9636640241069179

Epoch: 6| Step: 1
Training loss: 1.9369962215423584
Validation loss: 1.9782791035149687

Epoch: 6| Step: 2
Training loss: 1.774174690246582
Validation loss: 1.942108920825425

Epoch: 6| Step: 3
Training loss: 2.4151902198791504
Validation loss: 1.9759215770229217

Epoch: 6| Step: 4
Training loss: 2.1668481826782227
Validation loss: 1.9561993921956708

Epoch: 6| Step: 5
Training loss: 2.17313814163208
Validation loss: 1.9755079951337589

Epoch: 6| Step: 6
Training loss: 2.4433698654174805
Validation loss: 1.9741512985639675

Epoch: 6| Step: 7
Training loss: 2.1934890747070312
Validation loss: 1.9569608703736336

Epoch: 6| Step: 8
Training loss: 1.7480391263961792
Validation loss: 1.967203611968666

Epoch: 6| Step: 9
Training loss: 2.3995909690856934
Validation loss: 1.970982433647238

Epoch: 6| Step: 10
Training loss: 2.1384787559509277
Validation loss: 1.969503406555422

Epoch: 6| Step: 11
Training loss: 1.9255094528198242
Validation loss: 1.9632784961372294

Epoch: 6| Step: 12
Training loss: 2.650603771209717
Validation loss: 1.965360951680009

Epoch: 6| Step: 13
Training loss: 2.7153079509735107
Validation loss: 1.9508353125664495

Epoch: 112| Step: 0
Training loss: 2.2292795181274414
Validation loss: 1.962658110485282

Epoch: 6| Step: 1
Training loss: 3.016387462615967
Validation loss: 1.9837472925903976

Epoch: 6| Step: 2
Training loss: 2.3276801109313965
Validation loss: 1.9580421293935468

Epoch: 6| Step: 3
Training loss: 2.0863780975341797
Validation loss: 1.9426911620683567

Epoch: 6| Step: 4
Training loss: 2.3396148681640625
Validation loss: 1.9488291343053181

Epoch: 6| Step: 5
Training loss: 1.9764288663864136
Validation loss: 1.96747544247617

Epoch: 6| Step: 6
Training loss: 2.3533620834350586
Validation loss: 1.9704910747466549

Epoch: 6| Step: 7
Training loss: 2.378213405609131
Validation loss: 1.9815054708911526

Epoch: 6| Step: 8
Training loss: 1.8445991277694702
Validation loss: 1.9898544383305374

Epoch: 6| Step: 9
Training loss: 2.298445701599121
Validation loss: 1.9498964766020417

Epoch: 6| Step: 10
Training loss: 1.4607255458831787
Validation loss: 1.974993380167151

Epoch: 6| Step: 11
Training loss: 1.7559378147125244
Validation loss: 1.9716982636400449

Epoch: 6| Step: 12
Training loss: 2.2713565826416016
Validation loss: 1.9608417621222876

Epoch: 6| Step: 13
Training loss: 1.512876033782959
Validation loss: 1.955505016029522

Epoch: 113| Step: 0
Training loss: 1.8522562980651855
Validation loss: 1.968703935223241

Epoch: 6| Step: 1
Training loss: 1.6548166275024414
Validation loss: 2.004560802572517

Epoch: 6| Step: 2
Training loss: 2.0074288845062256
Validation loss: 1.9810392600233837

Epoch: 6| Step: 3
Training loss: 2.0441911220550537
Validation loss: 1.9758564656780613

Epoch: 6| Step: 4
Training loss: 2.194986343383789
Validation loss: 1.9919510502969064

Epoch: 6| Step: 5
Training loss: 2.0471673011779785
Validation loss: 1.9832191980013283

Epoch: 6| Step: 6
Training loss: 2.4411582946777344
Validation loss: 1.97158525066991

Epoch: 6| Step: 7
Training loss: 2.5020909309387207
Validation loss: 1.9883728898981565

Epoch: 6| Step: 8
Training loss: 2.25989031791687
Validation loss: 1.9865328432411276

Epoch: 6| Step: 9
Training loss: 2.570181369781494
Validation loss: 1.9897482933536652

Epoch: 6| Step: 10
Training loss: 2.2450971603393555
Validation loss: 2.0003459043400262

Epoch: 6| Step: 11
Training loss: 2.4113783836364746
Validation loss: 1.9815311021702264

Epoch: 6| Step: 12
Training loss: 2.0576553344726562
Validation loss: 1.9883269776580155

Epoch: 6| Step: 13
Training loss: 1.9058102369308472
Validation loss: 2.0062690011916624

Epoch: 114| Step: 0
Training loss: 2.1766018867492676
Validation loss: 1.9836443854916481

Epoch: 6| Step: 1
Training loss: 1.8323490619659424
Validation loss: 1.9767478653179702

Epoch: 6| Step: 2
Training loss: 2.3128347396850586
Validation loss: 1.9703552953658565

Epoch: 6| Step: 3
Training loss: 2.2946183681488037
Validation loss: 1.9948159084525159

Epoch: 6| Step: 4
Training loss: 2.0739357471466064
Validation loss: 2.0057454339919554

Epoch: 6| Step: 5
Training loss: 1.9272066354751587
Validation loss: 1.9975811742967176

Epoch: 6| Step: 6
Training loss: 2.1205666065216064
Validation loss: 1.9648148244427097

Epoch: 6| Step: 7
Training loss: 2.878366470336914
Validation loss: 1.9713107834580124

Epoch: 6| Step: 8
Training loss: 2.0891432762145996
Validation loss: 2.0028533140818277

Epoch: 6| Step: 9
Training loss: 1.8795361518859863
Validation loss: 2.000233737371301

Epoch: 6| Step: 10
Training loss: 2.1620147228240967
Validation loss: 1.9610199915465487

Epoch: 6| Step: 11
Training loss: 2.2637698650360107
Validation loss: 2.008482103706688

Epoch: 6| Step: 12
Training loss: 1.9332787990570068
Validation loss: 1.9846582733174807

Epoch: 6| Step: 13
Training loss: 1.6698802709579468
Validation loss: 1.9858763833199777

Epoch: 115| Step: 0
Training loss: 2.016252279281616
Validation loss: 1.9962294409351964

Epoch: 6| Step: 1
Training loss: 2.8424506187438965
Validation loss: 1.995823799922902

Epoch: 6| Step: 2
Training loss: 3.010507583618164
Validation loss: 1.9945843591484973

Epoch: 6| Step: 3
Training loss: 2.5945823192596436
Validation loss: 1.9736521859322824

Epoch: 6| Step: 4
Training loss: 2.327195882797241
Validation loss: 1.988684723454137

Epoch: 6| Step: 5
Training loss: 2.2977042198181152
Validation loss: 1.9855648920100222

Epoch: 6| Step: 6
Training loss: 1.574689269065857
Validation loss: 1.9728602260671637

Epoch: 6| Step: 7
Training loss: 2.297274351119995
Validation loss: 1.9909515932042112

Epoch: 6| Step: 8
Training loss: 2.350277900695801
Validation loss: 1.9757387074091102

Epoch: 6| Step: 9
Training loss: 1.7759391069412231
Validation loss: 1.9662986852789437

Epoch: 6| Step: 10
Training loss: 1.4712557792663574
Validation loss: 1.9538443267986338

Epoch: 6| Step: 11
Training loss: 1.5195766687393188
Validation loss: 1.9480435694417646

Epoch: 6| Step: 12
Training loss: 2.2769463062286377
Validation loss: 1.9529759268606863

Epoch: 6| Step: 13
Training loss: 1.3859782218933105
Validation loss: 1.9760237804023169

Epoch: 116| Step: 0
Training loss: 2.785362720489502
Validation loss: 1.9801138934268747

Epoch: 6| Step: 1
Training loss: 2.4518089294433594
Validation loss: 1.9762311558569632

Epoch: 6| Step: 2
Training loss: 2.1130433082580566
Validation loss: 1.9789286582700667

Epoch: 6| Step: 3
Training loss: 1.9569770097732544
Validation loss: 1.9749645263917985

Epoch: 6| Step: 4
Training loss: 2.1356513500213623
Validation loss: 1.9894634023789437

Epoch: 6| Step: 5
Training loss: 2.4892024993896484
Validation loss: 1.9852790242882186

Epoch: 6| Step: 6
Training loss: 2.6008338928222656
Validation loss: 1.974215051179291

Epoch: 6| Step: 7
Training loss: 1.868870735168457
Validation loss: 1.997816269115735

Epoch: 6| Step: 8
Training loss: 1.9879579544067383
Validation loss: 1.9897212853995703

Epoch: 6| Step: 9
Training loss: 1.9444677829742432
Validation loss: 2.0031196442983483

Epoch: 6| Step: 10
Training loss: 1.6932005882263184
Validation loss: 1.9789277481776413

Epoch: 6| Step: 11
Training loss: 2.190402030944824
Validation loss: 1.9850550338786135

Epoch: 6| Step: 12
Training loss: 2.0894250869750977
Validation loss: 1.99061720601974

Epoch: 6| Step: 13
Training loss: 1.3591963052749634
Validation loss: 1.9634575446446736

Epoch: 117| Step: 0
Training loss: 2.7449824810028076
Validation loss: 1.9999982746698524

Epoch: 6| Step: 1
Training loss: 2.261988639831543
Validation loss: 1.9802954312293761

Epoch: 6| Step: 2
Training loss: 0.9392763376235962
Validation loss: 1.985759629998156

Epoch: 6| Step: 3
Training loss: 2.398244619369507
Validation loss: 1.988990996473579

Epoch: 6| Step: 4
Training loss: 1.7455754280090332
Validation loss: 1.9804789327806043

Epoch: 6| Step: 5
Training loss: 1.7942506074905396
Validation loss: 2.0045920700155277

Epoch: 6| Step: 6
Training loss: 2.017266273498535
Validation loss: 1.9972121356635966

Epoch: 6| Step: 7
Training loss: 2.78281569480896
Validation loss: 1.9846741666076004

Epoch: 6| Step: 8
Training loss: 2.2610583305358887
Validation loss: 1.9929141229198826

Epoch: 6| Step: 9
Training loss: 2.0059194564819336
Validation loss: 1.9713336062687699

Epoch: 6| Step: 10
Training loss: 2.315852642059326
Validation loss: 1.975695102445541

Epoch: 6| Step: 11
Training loss: 2.699988842010498
Validation loss: 1.9915374760986657

Epoch: 6| Step: 12
Training loss: 1.9700300693511963
Validation loss: 1.9889030328360937

Epoch: 6| Step: 13
Training loss: 1.795916199684143
Validation loss: 1.9867122275854951

Epoch: 118| Step: 0
Training loss: 2.147134304046631
Validation loss: 1.9838830604348132

Epoch: 6| Step: 1
Training loss: 1.974815845489502
Validation loss: 1.9819503855961624

Epoch: 6| Step: 2
Training loss: 1.7691562175750732
Validation loss: 1.9706009152115032

Epoch: 6| Step: 3
Training loss: 2.3684134483337402
Validation loss: 1.9864041805267334

Epoch: 6| Step: 4
Training loss: 2.135688304901123
Validation loss: 1.977198875078591

Epoch: 6| Step: 5
Training loss: 1.836257815361023
Validation loss: 1.9938041779302782

Epoch: 6| Step: 6
Training loss: 2.270623207092285
Validation loss: 1.9387343493841027

Epoch: 6| Step: 7
Training loss: 2.220308780670166
Validation loss: 2.00179987056281

Epoch: 6| Step: 8
Training loss: 2.4384970664978027
Validation loss: 1.9645220105366041

Epoch: 6| Step: 9
Training loss: 1.812742829322815
Validation loss: 1.9802151597956175

Epoch: 6| Step: 10
Training loss: 2.363067626953125
Validation loss: 1.9885377384001208

Epoch: 6| Step: 11
Training loss: 2.1518571376800537
Validation loss: 1.9770720312672276

Epoch: 6| Step: 12
Training loss: 1.9033169746398926
Validation loss: 1.9941942794348604

Epoch: 6| Step: 13
Training loss: 2.764583110809326
Validation loss: 1.9956319216758973

Epoch: 119| Step: 0
Training loss: 1.4239847660064697
Validation loss: 2.0029798118017053

Epoch: 6| Step: 1
Training loss: 1.6483213901519775
Validation loss: 1.996835804754688

Epoch: 6| Step: 2
Training loss: 2.5444211959838867
Validation loss: 1.9979540660817137

Epoch: 6| Step: 3
Training loss: 2.5712568759918213
Validation loss: 1.9847466586738505

Epoch: 6| Step: 4
Training loss: 2.2135777473449707
Validation loss: 1.986695122975175

Epoch: 6| Step: 5
Training loss: 2.043458938598633
Validation loss: 1.9774470367739279

Epoch: 6| Step: 6
Training loss: 2.0163650512695312
Validation loss: 1.9880678551171416

Epoch: 6| Step: 7
Training loss: 2.179607391357422
Validation loss: 1.9640020093610209

Epoch: 6| Step: 8
Training loss: 1.8664584159851074
Validation loss: 1.9826051445417507

Epoch: 6| Step: 9
Training loss: 2.839113473892212
Validation loss: 1.9733220992549774

Epoch: 6| Step: 10
Training loss: 2.6242425441741943
Validation loss: 1.9848628133855841

Epoch: 6| Step: 11
Training loss: 2.07714581489563
Validation loss: 1.9832041942945091

Epoch: 6| Step: 12
Training loss: 1.6728291511535645
Validation loss: 1.9509961669163038

Epoch: 6| Step: 13
Training loss: 2.799516201019287
Validation loss: 1.974523413565851

Epoch: 120| Step: 0
Training loss: 2.245490074157715
Validation loss: 2.001239874029672

Epoch: 6| Step: 1
Training loss: 2.251448631286621
Validation loss: 1.9885924516185638

Epoch: 6| Step: 2
Training loss: 2.558856725692749
Validation loss: 1.998669865310833

Epoch: 6| Step: 3
Training loss: 1.5052986145019531
Validation loss: 2.001679753744474

Epoch: 6| Step: 4
Training loss: 1.7445460557937622
Validation loss: 1.9773298822423464

Epoch: 6| Step: 5
Training loss: 1.914933681488037
Validation loss: 1.9840804351273404

Epoch: 6| Step: 6
Training loss: 1.7403855323791504
Validation loss: 1.9924139335591307

Epoch: 6| Step: 7
Training loss: 1.779016137123108
Validation loss: 1.980628764757546

Epoch: 6| Step: 8
Training loss: 2.514768123626709
Validation loss: 1.987474960665549

Epoch: 6| Step: 9
Training loss: 2.2593562602996826
Validation loss: 1.9649621517427507

Epoch: 6| Step: 10
Training loss: 1.6557334661483765
Validation loss: 1.985439767119705

Epoch: 6| Step: 11
Training loss: 2.2580442428588867
Validation loss: 1.974204214670325

Epoch: 6| Step: 12
Training loss: 3.0517780780792236
Validation loss: 1.981871320355323

Epoch: 6| Step: 13
Training loss: 2.2167255878448486
Validation loss: 1.994883797502005

Epoch: 121| Step: 0
Training loss: 2.400251626968384
Validation loss: 1.9845716081639773

Epoch: 6| Step: 1
Training loss: 1.6303961277008057
Validation loss: 1.967552246585969

Epoch: 6| Step: 2
Training loss: 1.7208023071289062
Validation loss: 1.9864583630715646

Epoch: 6| Step: 3
Training loss: 2.0112361907958984
Validation loss: 1.967990941898797

Epoch: 6| Step: 4
Training loss: 1.885292410850525
Validation loss: 1.9921941859747774

Epoch: 6| Step: 5
Training loss: 2.640944004058838
Validation loss: 1.9938379410774476

Epoch: 6| Step: 6
Training loss: 2.64201021194458
Validation loss: 2.004143480331667

Epoch: 6| Step: 7
Training loss: 2.5831658840179443
Validation loss: 2.004567369338005

Epoch: 6| Step: 8
Training loss: 2.45084810256958
Validation loss: 2.008827781164518

Epoch: 6| Step: 9
Training loss: 2.7730979919433594
Validation loss: 2.006860089558427

Epoch: 6| Step: 10
Training loss: 1.2271742820739746
Validation loss: 2.005207247631524

Epoch: 6| Step: 11
Training loss: 1.9792017936706543
Validation loss: 2.005068435463854

Epoch: 6| Step: 12
Training loss: 1.9764981269836426
Validation loss: 1.9856564985808505

Epoch: 6| Step: 13
Training loss: 1.931546688079834
Validation loss: 1.9991737052958498

Epoch: 122| Step: 0
Training loss: 2.4650936126708984
Validation loss: 2.0145137053664013

Epoch: 6| Step: 1
Training loss: 2.0424983501434326
Validation loss: 2.0028942708046205

Epoch: 6| Step: 2
Training loss: 2.0280308723449707
Validation loss: 1.9897137072778517

Epoch: 6| Step: 3
Training loss: 1.8768965005874634
Validation loss: 2.000282797762143

Epoch: 6| Step: 4
Training loss: 2.2280056476593018
Validation loss: 2.00063479715778

Epoch: 6| Step: 5
Training loss: 2.190176010131836
Validation loss: 1.9862478740753666

Epoch: 6| Step: 6
Training loss: 2.4384446144104004
Validation loss: 1.9921644759434525

Epoch: 6| Step: 7
Training loss: 2.594043254852295
Validation loss: 1.995127139552947

Epoch: 6| Step: 8
Training loss: 2.002706527709961
Validation loss: 1.9718497209651495

Epoch: 6| Step: 9
Training loss: 1.8300588130950928
Validation loss: 1.9794988888566212

Epoch: 6| Step: 10
Training loss: 2.7381906509399414
Validation loss: 1.974873620976684

Epoch: 6| Step: 11
Training loss: 1.7774899005889893
Validation loss: 1.9549608974046604

Epoch: 6| Step: 12
Training loss: 1.9896411895751953
Validation loss: 1.9865449410612865

Epoch: 6| Step: 13
Training loss: 1.1246411800384521
Validation loss: 1.9656202421393445

Epoch: 123| Step: 0
Training loss: 2.1378414630889893
Validation loss: 1.9625757086661555

Epoch: 6| Step: 1
Training loss: 2.1200289726257324
Validation loss: 1.9565524490930701

Epoch: 6| Step: 2
Training loss: 2.1102328300476074
Validation loss: 1.976386881643726

Epoch: 6| Step: 3
Training loss: 1.8960938453674316
Validation loss: 1.96385476281566

Epoch: 6| Step: 4
Training loss: 2.6391444206237793
Validation loss: 1.955644852371626

Epoch: 6| Step: 5
Training loss: 2.043041706085205
Validation loss: 1.9919999081601378

Epoch: 6| Step: 6
Training loss: 1.6930971145629883
Validation loss: 1.980069088679488

Epoch: 6| Step: 7
Training loss: 2.0209462642669678
Validation loss: 1.9659047216497443

Epoch: 6| Step: 8
Training loss: 2.2429747581481934
Validation loss: 1.9938997786532167

Epoch: 6| Step: 9
Training loss: 2.357794761657715
Validation loss: 2.0223521494096324

Epoch: 6| Step: 10
Training loss: 2.1416821479797363
Validation loss: 2.0215473892868205

Epoch: 6| Step: 11
Training loss: 2.6412930488586426
Validation loss: 2.0174331447129608

Epoch: 6| Step: 12
Training loss: 1.6989465951919556
Validation loss: 1.9935036269567346

Epoch: 6| Step: 13
Training loss: 2.0330495834350586
Validation loss: 1.995821052981961

Epoch: 124| Step: 0
Training loss: 2.0007615089416504
Validation loss: 2.0026158209769958

Epoch: 6| Step: 1
Training loss: 2.0606939792633057
Validation loss: 1.9950526504106418

Epoch: 6| Step: 2
Training loss: 2.5608291625976562
Validation loss: 1.988293295265526

Epoch: 6| Step: 3
Training loss: 2.674510955810547
Validation loss: 1.989033245271252

Epoch: 6| Step: 4
Training loss: 2.214705467224121
Validation loss: 1.992079504074589

Epoch: 6| Step: 5
Training loss: 1.7629239559173584
Validation loss: 1.9960821866989136

Epoch: 6| Step: 6
Training loss: 2.390326499938965
Validation loss: 1.9830484774804884

Epoch: 6| Step: 7
Training loss: 2.1136269569396973
Validation loss: 1.9626672216641006

Epoch: 6| Step: 8
Training loss: 1.635794997215271
Validation loss: 1.996328265436234

Epoch: 6| Step: 9
Training loss: 2.3491969108581543
Validation loss: 1.9729904308114001

Epoch: 6| Step: 10
Training loss: 1.4823825359344482
Validation loss: 1.9937490993930447

Epoch: 6| Step: 11
Training loss: 2.4192371368408203
Validation loss: 2.0021140831773

Epoch: 6| Step: 12
Training loss: 2.3667685985565186
Validation loss: 1.9907730087157218

Epoch: 6| Step: 13
Training loss: 1.3476513624191284
Validation loss: 1.9774884562338553

Epoch: 125| Step: 0
Training loss: 1.832539439201355
Validation loss: 1.9992862619379514

Epoch: 6| Step: 1
Training loss: 2.350869655609131
Validation loss: 1.9659835023264731

Epoch: 6| Step: 2
Training loss: 2.2665131092071533
Validation loss: 1.9617562473461192

Epoch: 6| Step: 3
Training loss: 1.5514676570892334
Validation loss: 1.964950393604976

Epoch: 6| Step: 4
Training loss: 1.9685791730880737
Validation loss: 1.9963927153618104

Epoch: 6| Step: 5
Training loss: 1.9917786121368408
Validation loss: 1.9923609905345465

Epoch: 6| Step: 6
Training loss: 1.9118506908416748
Validation loss: 1.971881708791179

Epoch: 6| Step: 7
Training loss: 2.4018125534057617
Validation loss: 1.996764236880887

Epoch: 6| Step: 8
Training loss: 2.691439151763916
Validation loss: 1.9871019958167948

Epoch: 6| Step: 9
Training loss: 2.709810256958008
Validation loss: 1.967238292899183

Epoch: 6| Step: 10
Training loss: 1.7122604846954346
Validation loss: 1.983129898707072

Epoch: 6| Step: 11
Training loss: 2.203002452850342
Validation loss: 1.9809759457906086

Epoch: 6| Step: 12
Training loss: 1.900090217590332
Validation loss: 1.9969959899943361

Epoch: 6| Step: 13
Training loss: 1.9714808464050293
Validation loss: 1.9651807315887944

Epoch: 126| Step: 0
Training loss: 2.1676084995269775
Validation loss: 1.967500441817827

Epoch: 6| Step: 1
Training loss: 2.482276678085327
Validation loss: 1.9924063387737478

Epoch: 6| Step: 2
Training loss: 3.058422088623047
Validation loss: 1.99748662594826

Epoch: 6| Step: 3
Training loss: 1.9184117317199707
Validation loss: 1.973488341095627

Epoch: 6| Step: 4
Training loss: 1.825502872467041
Validation loss: 2.024965351627719

Epoch: 6| Step: 5
Training loss: 1.3950674533843994
Validation loss: 2.0027858775149108

Epoch: 6| Step: 6
Training loss: 2.0161752700805664
Validation loss: 1.9893990255171252

Epoch: 6| Step: 7
Training loss: 1.5661511421203613
Validation loss: 1.9524083804058772

Epoch: 6| Step: 8
Training loss: 2.9963011741638184
Validation loss: 1.9664304128257177

Epoch: 6| Step: 9
Training loss: 1.750219702720642
Validation loss: 1.9784934072084324

Epoch: 6| Step: 10
Training loss: 2.2071070671081543
Validation loss: 2.004344101875059

Epoch: 6| Step: 11
Training loss: 1.6189637184143066
Validation loss: 1.9933071277474845

Epoch: 6| Step: 12
Training loss: 2.1966938972473145
Validation loss: 1.9571281530523812

Epoch: 6| Step: 13
Training loss: 2.3666982650756836
Validation loss: 1.9932263128219112

Epoch: 127| Step: 0
Training loss: 1.7021640539169312
Validation loss: 1.9930941417653074

Epoch: 6| Step: 1
Training loss: 2.078099012374878
Validation loss: 1.9856476629934003

Epoch: 6| Step: 2
Training loss: 1.8219362497329712
Validation loss: 1.9659394141166442

Epoch: 6| Step: 3
Training loss: 2.115633964538574
Validation loss: 1.983727591012114

Epoch: 6| Step: 4
Training loss: 2.163698673248291
Validation loss: 1.9853132463270617

Epoch: 6| Step: 5
Training loss: 2.2094037532806396
Validation loss: 1.9812064760474748

Epoch: 6| Step: 6
Training loss: 2.77968430519104
Validation loss: 1.9868855220015331

Epoch: 6| Step: 7
Training loss: 2.312960147857666
Validation loss: 1.9623162669520224

Epoch: 6| Step: 8
Training loss: 2.921231269836426
Validation loss: 1.9807259305830924

Epoch: 6| Step: 9
Training loss: 1.8541102409362793
Validation loss: 1.9754696353789298

Epoch: 6| Step: 10
Training loss: 1.944719910621643
Validation loss: 1.9645698147435342

Epoch: 6| Step: 11
Training loss: 1.9462049007415771
Validation loss: 1.977652229288573

Epoch: 6| Step: 12
Training loss: 2.160083770751953
Validation loss: 2.0136905113855996

Epoch: 6| Step: 13
Training loss: 1.1240286827087402
Validation loss: 1.9908071871726745

Epoch: 128| Step: 0
Training loss: 1.7362403869628906
Validation loss: 1.990591674722651

Epoch: 6| Step: 1
Training loss: 1.814803957939148
Validation loss: 1.9908046030229138

Epoch: 6| Step: 2
Training loss: 2.3180689811706543
Validation loss: 1.9841239683089718

Epoch: 6| Step: 3
Training loss: 2.519465208053589
Validation loss: 1.979768371069303

Epoch: 6| Step: 4
Training loss: 1.754004716873169
Validation loss: 1.9900116484652284

Epoch: 6| Step: 5
Training loss: 2.3823182582855225
Validation loss: 1.9964156535363966

Epoch: 6| Step: 6
Training loss: 2.7316784858703613
Validation loss: 1.9924138515226302

Epoch: 6| Step: 7
Training loss: 1.406604290008545
Validation loss: 2.0070522895423313

Epoch: 6| Step: 8
Training loss: 1.9579933881759644
Validation loss: 2.0111871380959787

Epoch: 6| Step: 9
Training loss: 2.711254358291626
Validation loss: 2.035108804702759

Epoch: 6| Step: 10
Training loss: 2.161417007446289
Validation loss: 2.0081782520458265

Epoch: 6| Step: 11
Training loss: 2.660393238067627
Validation loss: 1.9965533338567263

Epoch: 6| Step: 12
Training loss: 1.9193499088287354
Validation loss: 2.0185471260419456

Epoch: 6| Step: 13
Training loss: 1.3562501668930054
Validation loss: 2.001523415247599

Epoch: 129| Step: 0
Training loss: 1.9506475925445557
Validation loss: 1.990088975557717

Epoch: 6| Step: 1
Training loss: 1.7155027389526367
Validation loss: 1.9870072385316253

Epoch: 6| Step: 2
Training loss: 1.898557186126709
Validation loss: 1.9946759875102709

Epoch: 6| Step: 3
Training loss: 2.1986401081085205
Validation loss: 1.9828964407726

Epoch: 6| Step: 4
Training loss: 2.1365232467651367
Validation loss: 2.0166704065056256

Epoch: 6| Step: 5
Training loss: 1.4591107368469238
Validation loss: 1.9912803249974405

Epoch: 6| Step: 6
Training loss: 2.1762523651123047
Validation loss: 2.0033120160461753

Epoch: 6| Step: 7
Training loss: 2.1131808757781982
Validation loss: 2.0099178155263266

Epoch: 6| Step: 8
Training loss: 2.640564441680908
Validation loss: 1.9937248242798673

Epoch: 6| Step: 9
Training loss: 2.2681021690368652
Validation loss: 2.0132154982577086

Epoch: 6| Step: 10
Training loss: 2.6467018127441406
Validation loss: 2.002127188508229

Epoch: 6| Step: 11
Training loss: 2.228459358215332
Validation loss: 1.9796973441236763

Epoch: 6| Step: 12
Training loss: 2.2772464752197266
Validation loss: 1.979785870480281

Epoch: 6| Step: 13
Training loss: 1.397700309753418
Validation loss: 1.9836285473198019

Epoch: 130| Step: 0
Training loss: 1.931480050086975
Validation loss: 1.9760701784523584

Epoch: 6| Step: 1
Training loss: 2.636000633239746
Validation loss: 2.0050581450103433

Epoch: 6| Step: 2
Training loss: 2.6152119636535645
Validation loss: 2.015805741792084

Epoch: 6| Step: 3
Training loss: 2.0425047874450684
Validation loss: 2.0232664051876275

Epoch: 6| Step: 4
Training loss: 1.8222333192825317
Validation loss: 2.0020518149099042

Epoch: 6| Step: 5
Training loss: 1.8440696001052856
Validation loss: 1.9855408181426346

Epoch: 6| Step: 6
Training loss: 2.543646812438965
Validation loss: 1.995753744597076

Epoch: 6| Step: 7
Training loss: 2.3912949562072754
Validation loss: 1.965966643825654

Epoch: 6| Step: 8
Training loss: 1.958244800567627
Validation loss: 1.99802396118

Epoch: 6| Step: 9
Training loss: 1.847621202468872
Validation loss: 1.989305192424405

Epoch: 6| Step: 10
Training loss: 2.4067437648773193
Validation loss: 2.000575172003879

Epoch: 6| Step: 11
Training loss: 1.4964542388916016
Validation loss: 2.005995426126706

Epoch: 6| Step: 12
Training loss: 1.7194169759750366
Validation loss: 1.9753398331262733

Epoch: 6| Step: 13
Training loss: 2.5619587898254395
Validation loss: 1.9936641159877981

Epoch: 131| Step: 0
Training loss: 1.5116076469421387
Validation loss: 2.004761262606549

Epoch: 6| Step: 1
Training loss: 2.4754180908203125
Validation loss: 1.9953014004615046

Epoch: 6| Step: 2
Training loss: 2.853891611099243
Validation loss: 1.989399092171782

Epoch: 6| Step: 3
Training loss: 2.382998466491699
Validation loss: 1.9982880136018157

Epoch: 6| Step: 4
Training loss: 2.020739793777466
Validation loss: 1.9992517386713335

Epoch: 6| Step: 5
Training loss: 2.4573049545288086
Validation loss: 1.9983818928400676

Epoch: 6| Step: 6
Training loss: 2.179253578186035
Validation loss: 1.9810608202411282

Epoch: 6| Step: 7
Training loss: 1.5191786289215088
Validation loss: 1.9741597944690334

Epoch: 6| Step: 8
Training loss: 2.0805840492248535
Validation loss: 2.0183076332974177

Epoch: 6| Step: 9
Training loss: 2.106217861175537
Validation loss: 1.9824568251127839

Epoch: 6| Step: 10
Training loss: 1.3618345260620117
Validation loss: 2.0085006785649124

Epoch: 6| Step: 11
Training loss: 2.227566719055176
Validation loss: 2.01925919389212

Epoch: 6| Step: 12
Training loss: 2.2974627017974854
Validation loss: 2.002820626381905

Epoch: 6| Step: 13
Training loss: 1.7040892839431763
Validation loss: 2.022899112393779

Epoch: 132| Step: 0
Training loss: 2.6868844032287598
Validation loss: 1.989883166487499

Epoch: 6| Step: 1
Training loss: 2.029391288757324
Validation loss: 1.9965360497915616

Epoch: 6| Step: 2
Training loss: 1.5464521646499634
Validation loss: 2.015761216481527

Epoch: 6| Step: 3
Training loss: 1.3444132804870605
Validation loss: 1.9821549910371021

Epoch: 6| Step: 4
Training loss: 2.298798084259033
Validation loss: 1.9828860298279793

Epoch: 6| Step: 5
Training loss: 2.336902141571045
Validation loss: 1.9540656279492121

Epoch: 6| Step: 6
Training loss: 2.447934627532959
Validation loss: 1.9957488685525873

Epoch: 6| Step: 7
Training loss: 2.254599094390869
Validation loss: 1.9571834841082174

Epoch: 6| Step: 8
Training loss: 1.948179006576538
Validation loss: 1.9609877447928152

Epoch: 6| Step: 9
Training loss: 1.6640925407409668
Validation loss: 1.9720103843237764

Epoch: 6| Step: 10
Training loss: 2.276309013366699
Validation loss: 2.0016454945328417

Epoch: 6| Step: 11
Training loss: 2.2806859016418457
Validation loss: 2.003363545222949

Epoch: 6| Step: 12
Training loss: 2.3450984954833984
Validation loss: 1.993230886356805

Epoch: 6| Step: 13
Training loss: 2.2893853187561035
Validation loss: 1.9679957153976604

Epoch: 133| Step: 0
Training loss: 2.0438578128814697
Validation loss: 1.969138591520248

Epoch: 6| Step: 1
Training loss: 2.245851993560791
Validation loss: 1.9916341663688741

Epoch: 6| Step: 2
Training loss: 2.4210023880004883
Validation loss: 1.972713908841533

Epoch: 6| Step: 3
Training loss: 2.092076539993286
Validation loss: 1.9466135617225402

Epoch: 6| Step: 4
Training loss: 2.0742783546447754
Validation loss: 1.9958926734103952

Epoch: 6| Step: 5
Training loss: 1.7004815340042114
Validation loss: 1.9624625752049107

Epoch: 6| Step: 6
Training loss: 2.2358736991882324
Validation loss: 1.9891177428665983

Epoch: 6| Step: 7
Training loss: 1.9078168869018555
Validation loss: 2.004900094001524

Epoch: 6| Step: 8
Training loss: 1.9052200317382812
Validation loss: 2.0066335149990615

Epoch: 6| Step: 9
Training loss: 2.5160586833953857
Validation loss: 2.0235921644395396

Epoch: 6| Step: 10
Training loss: 2.2928977012634277
Validation loss: 2.015785965868222

Epoch: 6| Step: 11
Training loss: 1.7895931005477905
Validation loss: 1.992563598899431

Epoch: 6| Step: 12
Training loss: 2.3863887786865234
Validation loss: 1.9973119740845056

Epoch: 6| Step: 13
Training loss: 1.7360297441482544
Validation loss: 2.007369424707146

Epoch: 134| Step: 0
Training loss: 2.5044257640838623
Validation loss: 2.0271134735435568

Epoch: 6| Step: 1
Training loss: 2.1397008895874023
Validation loss: 2.0106780477749404

Epoch: 6| Step: 2
Training loss: 1.979180097579956
Validation loss: 2.0262456222247054

Epoch: 6| Step: 3
Training loss: 2.4472832679748535
Validation loss: 2.0129274501595447

Epoch: 6| Step: 4
Training loss: 2.09989595413208
Validation loss: 2.0425519712509645

Epoch: 6| Step: 5
Training loss: 1.944528341293335
Validation loss: 2.0413158478275424

Epoch: 6| Step: 6
Training loss: 2.2143192291259766
Validation loss: 2.0477418220171364

Epoch: 6| Step: 7
Training loss: 2.29113507270813
Validation loss: 2.0121561147833384

Epoch: 6| Step: 8
Training loss: 1.8786427974700928
Validation loss: 2.0487874272049114

Epoch: 6| Step: 9
Training loss: 2.019941568374634
Validation loss: 2.0324172204540623

Epoch: 6| Step: 10
Training loss: 2.0187480449676514
Validation loss: 2.0288987159729004

Epoch: 6| Step: 11
Training loss: 1.9215328693389893
Validation loss: 2.0064380732915734

Epoch: 6| Step: 12
Training loss: 2.1042137145996094
Validation loss: 1.997068694842759

Epoch: 6| Step: 13
Training loss: 1.9903640747070312
Validation loss: 2.0127567091295795

Epoch: 135| Step: 0
Training loss: 2.3705530166625977
Validation loss: 2.0105060518428846

Epoch: 6| Step: 1
Training loss: 1.5045567750930786
Validation loss: 2.0459085356804634

Epoch: 6| Step: 2
Training loss: 1.4120640754699707
Validation loss: 2.0416448603394213

Epoch: 6| Step: 3
Training loss: 2.533092975616455
Validation loss: 2.009315639413813

Epoch: 6| Step: 4
Training loss: 2.7430567741394043
Validation loss: 2.0156741603728263

Epoch: 6| Step: 5
Training loss: 1.8604382276535034
Validation loss: 2.0209410305946105

Epoch: 6| Step: 6
Training loss: 1.0197175741195679
Validation loss: 2.0179877281188965

Epoch: 6| Step: 7
Training loss: 1.5479423999786377
Validation loss: 2.04413148408295

Epoch: 6| Step: 8
Training loss: 1.962965488433838
Validation loss: 2.0125694197993123

Epoch: 6| Step: 9
Training loss: 2.391529083251953
Validation loss: 2.0269318037135626

Epoch: 6| Step: 10
Training loss: 2.436635732650757
Validation loss: 1.996176455610542

Epoch: 6| Step: 11
Training loss: 2.663503885269165
Validation loss: 2.004739405006491

Epoch: 6| Step: 12
Training loss: 2.2883763313293457
Validation loss: 2.02361007659666

Epoch: 6| Step: 13
Training loss: 2.5666656494140625
Validation loss: 2.0173047306717082

Epoch: 136| Step: 0
Training loss: 2.388716697692871
Validation loss: 2.0094939893291843

Epoch: 6| Step: 1
Training loss: 2.2991793155670166
Validation loss: 2.010207527427263

Epoch: 6| Step: 2
Training loss: 1.913511037826538
Validation loss: 1.9904052006301058

Epoch: 6| Step: 3
Training loss: 2.463919162750244
Validation loss: 2.021463042946272

Epoch: 6| Step: 4
Training loss: 2.0746374130249023
Validation loss: 1.9779472940711564

Epoch: 6| Step: 5
Training loss: 1.771077275276184
Validation loss: 1.9993953166469451

Epoch: 6| Step: 6
Training loss: 2.3670763969421387
Validation loss: 2.0183914771644016

Epoch: 6| Step: 7
Training loss: 2.0966453552246094
Validation loss: 2.0163214847605717

Epoch: 6| Step: 8
Training loss: 2.197552442550659
Validation loss: 2.0365818956846833

Epoch: 6| Step: 9
Training loss: 1.6272974014282227
Validation loss: 2.0141996927158807

Epoch: 6| Step: 10
Training loss: 2.2274839878082275
Validation loss: 2.004317819431264

Epoch: 6| Step: 11
Training loss: 1.5536901950836182
Validation loss: 2.016774631315662

Epoch: 6| Step: 12
Training loss: 2.4273509979248047
Validation loss: 2.0089971455194617

Epoch: 6| Step: 13
Training loss: 1.645558476448059
Validation loss: 2.020572457262265

Epoch: 137| Step: 0
Training loss: 1.8070130348205566
Validation loss: 2.001575695571079

Epoch: 6| Step: 1
Training loss: 1.60965096950531
Validation loss: 2.0127292499747327

Epoch: 6| Step: 2
Training loss: 1.8625082969665527
Validation loss: 1.9996897687194168

Epoch: 6| Step: 3
Training loss: 1.7125129699707031
Validation loss: 1.9984578291575115

Epoch: 6| Step: 4
Training loss: 1.930540680885315
Validation loss: 1.9966294470653738

Epoch: 6| Step: 5
Training loss: 2.5123238563537598
Validation loss: 2.0095091301907777

Epoch: 6| Step: 6
Training loss: 2.353494882583618
Validation loss: 1.9599391516818796

Epoch: 6| Step: 7
Training loss: 1.8827733993530273
Validation loss: 1.997958178161293

Epoch: 6| Step: 8
Training loss: 1.8917791843414307
Validation loss: 1.9961054684013448

Epoch: 6| Step: 9
Training loss: 2.539217710494995
Validation loss: 2.019711508545824

Epoch: 6| Step: 10
Training loss: 2.8505923748016357
Validation loss: 1.972673942965846

Epoch: 6| Step: 11
Training loss: 2.5126070976257324
Validation loss: 1.9897255628339705

Epoch: 6| Step: 12
Training loss: 1.919973373413086
Validation loss: 1.9873039030259656

Epoch: 6| Step: 13
Training loss: 2.0235700607299805
Validation loss: 1.9840098965552546

Epoch: 138| Step: 0
Training loss: 1.9670904874801636
Validation loss: 1.9965719792150682

Epoch: 6| Step: 1
Training loss: 2.205324411392212
Validation loss: 2.0020018905721684

Epoch: 6| Step: 2
Training loss: 2.8546276092529297
Validation loss: 1.9984968951953355

Epoch: 6| Step: 3
Training loss: 2.6088361740112305
Validation loss: 1.9778435230255127

Epoch: 6| Step: 4
Training loss: 2.496217727661133
Validation loss: 1.981925231154247

Epoch: 6| Step: 5
Training loss: 1.6998469829559326
Validation loss: 1.991839780602404

Epoch: 6| Step: 6
Training loss: 1.7996729612350464
Validation loss: 1.9943081614791707

Epoch: 6| Step: 7
Training loss: 1.9596126079559326
Validation loss: 1.997181797540316

Epoch: 6| Step: 8
Training loss: 2.596707344055176
Validation loss: 1.9821715918920373

Epoch: 6| Step: 9
Training loss: 1.9673658609390259
Validation loss: 1.9786564278346237

Epoch: 6| Step: 10
Training loss: 1.8212506771087646
Validation loss: 1.9861599527379519

Epoch: 6| Step: 11
Training loss: 1.597341537475586
Validation loss: 1.9729500098895

Epoch: 6| Step: 12
Training loss: 2.0435667037963867
Validation loss: 1.9906564194669005

Epoch: 6| Step: 13
Training loss: 1.698850393295288
Validation loss: 1.999743103981018

Epoch: 139| Step: 0
Training loss: 1.846691608428955
Validation loss: 1.9794954702418337

Epoch: 6| Step: 1
Training loss: 2.4865946769714355
Validation loss: 1.9862019502988426

Epoch: 6| Step: 2
Training loss: 2.0284738540649414
Validation loss: 1.9688744775710567

Epoch: 6| Step: 3
Training loss: 2.7780096530914307
Validation loss: 2.0086685380628033

Epoch: 6| Step: 4
Training loss: 1.4905385971069336
Validation loss: 1.9970152429355088

Epoch: 6| Step: 5
Training loss: 1.875060796737671
Validation loss: 1.982217598986882

Epoch: 6| Step: 6
Training loss: 1.9301928281784058
Validation loss: 2.0015248278135895

Epoch: 6| Step: 7
Training loss: 2.5900230407714844
Validation loss: 1.999852849591163

Epoch: 6| Step: 8
Training loss: 2.6043319702148438
Validation loss: 1.9933591427341584

Epoch: 6| Step: 9
Training loss: 2.374354362487793
Validation loss: 1.9976434912732852

Epoch: 6| Step: 10
Training loss: 1.6056838035583496
Validation loss: 1.9937896497787968

Epoch: 6| Step: 11
Training loss: 2.0647268295288086
Validation loss: 1.9925749481365245

Epoch: 6| Step: 12
Training loss: 2.183481216430664
Validation loss: 1.9912888337207097

Epoch: 6| Step: 13
Training loss: 1.3501008749008179
Validation loss: 2.001050541477819

Epoch: 140| Step: 0
Training loss: 1.450891375541687
Validation loss: 2.0086037394821004

Epoch: 6| Step: 1
Training loss: 1.6833726167678833
Validation loss: 1.9898249436450262

Epoch: 6| Step: 2
Training loss: 2.810978889465332
Validation loss: 1.9786977293670818

Epoch: 6| Step: 3
Training loss: 2.203577995300293
Validation loss: 1.996354292797786

Epoch: 6| Step: 4
Training loss: 1.6374567747116089
Validation loss: 1.9525591814389793

Epoch: 6| Step: 5
Training loss: 2.554327964782715
Validation loss: 1.9823928071606545

Epoch: 6| Step: 6
Training loss: 2.07382869720459
Validation loss: 1.97042989859017

Epoch: 6| Step: 7
Training loss: 2.173781633377075
Validation loss: 1.9674328527142924

Epoch: 6| Step: 8
Training loss: 1.5473580360412598
Validation loss: 1.9994295566312728

Epoch: 6| Step: 9
Training loss: 1.9591269493103027
Validation loss: 1.9875061819630284

Epoch: 6| Step: 10
Training loss: 2.262803554534912
Validation loss: 1.9653777794171405

Epoch: 6| Step: 11
Training loss: 2.5776076316833496
Validation loss: 1.9759703810496996

Epoch: 6| Step: 12
Training loss: 2.2868027687072754
Validation loss: 1.9716129661888204

Epoch: 6| Step: 13
Training loss: 2.3426876068115234
Validation loss: 2.010491427554879

Epoch: 141| Step: 0
Training loss: 1.9433386325836182
Validation loss: 1.9757304729953888

Epoch: 6| Step: 1
Training loss: 1.7612110376358032
Validation loss: 1.996028854000953

Epoch: 6| Step: 2
Training loss: 1.8194856643676758
Validation loss: 1.9892363253460135

Epoch: 6| Step: 3
Training loss: 2.2274723052978516
Validation loss: 1.9945424436241068

Epoch: 6| Step: 4
Training loss: 2.1173973083496094
Validation loss: 1.964627165948191

Epoch: 6| Step: 5
Training loss: 1.9043941497802734
Validation loss: 1.9900920480810187

Epoch: 6| Step: 6
Training loss: 1.9688705205917358
Validation loss: 1.9805660504166798

Epoch: 6| Step: 7
Training loss: 1.6440248489379883
Validation loss: 1.9461817869576075

Epoch: 6| Step: 8
Training loss: 1.3857825994491577
Validation loss: 1.9659177154623053

Epoch: 6| Step: 9
Training loss: 2.6709227561950684
Validation loss: 1.9897576365419614

Epoch: 6| Step: 10
Training loss: 2.899940013885498
Validation loss: 1.980132975885945

Epoch: 6| Step: 11
Training loss: 2.3964412212371826
Validation loss: 1.9891373636902019

Epoch: 6| Step: 12
Training loss: 2.5364396572113037
Validation loss: 2.006007038136964

Epoch: 6| Step: 13
Training loss: 2.090442180633545
Validation loss: 1.9814692517762542

Epoch: 142| Step: 0
Training loss: 1.5878642797470093
Validation loss: 1.9970157543818157

Epoch: 6| Step: 1
Training loss: 3.095834255218506
Validation loss: 1.9785416638979347

Epoch: 6| Step: 2
Training loss: 2.2194700241088867
Validation loss: 1.993203927111882

Epoch: 6| Step: 3
Training loss: 2.431758403778076
Validation loss: 1.989468236123362

Epoch: 6| Step: 4
Training loss: 2.690659523010254
Validation loss: 1.9699962151947843

Epoch: 6| Step: 5
Training loss: 2.206267833709717
Validation loss: 1.979096253712972

Epoch: 6| Step: 6
Training loss: 2.0273938179016113
Validation loss: 1.9839423369335871

Epoch: 6| Step: 7
Training loss: 1.8905800580978394
Validation loss: 2.0050677509718042

Epoch: 6| Step: 8
Training loss: 2.104732036590576
Validation loss: 1.9581648995799403

Epoch: 6| Step: 9
Training loss: 1.5920851230621338
Validation loss: 1.9863999992288568

Epoch: 6| Step: 10
Training loss: 2.207890272140503
Validation loss: 1.9844522578741914

Epoch: 6| Step: 11
Training loss: 2.1897196769714355
Validation loss: 2.0094576330595117

Epoch: 6| Step: 12
Training loss: 1.8230276107788086
Validation loss: 2.0182203233882947

Epoch: 6| Step: 13
Training loss: 0.7624819278717041
Validation loss: 1.9930817850174443

Epoch: 143| Step: 0
Training loss: 1.5671532154083252
Validation loss: 1.9963856076681485

Epoch: 6| Step: 1
Training loss: 2.0461106300354004
Validation loss: 2.023231798602689

Epoch: 6| Step: 2
Training loss: 2.1470932960510254
Validation loss: 2.0089650307932208

Epoch: 6| Step: 3
Training loss: 1.767185926437378
Validation loss: 2.000470966421148

Epoch: 6| Step: 4
Training loss: 1.5955276489257812
Validation loss: 1.9939790118125178

Epoch: 6| Step: 5
Training loss: 2.474534034729004
Validation loss: 1.9870618145952943

Epoch: 6| Step: 6
Training loss: 2.227976083755493
Validation loss: 1.9866195442855998

Epoch: 6| Step: 7
Training loss: 1.849198818206787
Validation loss: 1.969997493169641

Epoch: 6| Step: 8
Training loss: 2.3186867237091064
Validation loss: 1.9774365399473457

Epoch: 6| Step: 9
Training loss: 1.843881607055664
Validation loss: 1.9902143542484572

Epoch: 6| Step: 10
Training loss: 2.453578472137451
Validation loss: 1.981587234363761

Epoch: 6| Step: 11
Training loss: 1.8595623970031738
Validation loss: 1.9937943232956754

Epoch: 6| Step: 12
Training loss: 2.883836507797241
Validation loss: 2.011347791200043

Epoch: 6| Step: 13
Training loss: 2.578540325164795
Validation loss: 1.996401112566712

Epoch: 144| Step: 0
Training loss: 2.457860231399536
Validation loss: 1.9705437152616438

Epoch: 6| Step: 1
Training loss: 1.7172658443450928
Validation loss: 1.9917614793264737

Epoch: 6| Step: 2
Training loss: 2.114596128463745
Validation loss: 1.9455871351303593

Epoch: 6| Step: 3
Training loss: 1.3692052364349365
Validation loss: 2.0057637973498275

Epoch: 6| Step: 4
Training loss: 2.894958734512329
Validation loss: 2.008964974393127

Epoch: 6| Step: 5
Training loss: 1.48562753200531
Validation loss: 2.013401940304746

Epoch: 6| Step: 6
Training loss: 2.1231846809387207
Validation loss: 2.022139596682723

Epoch: 6| Step: 7
Training loss: 1.7386500835418701
Validation loss: 2.0046374362002135

Epoch: 6| Step: 8
Training loss: 2.46335768699646
Validation loss: 1.99817310097397

Epoch: 6| Step: 9
Training loss: 2.6387572288513184
Validation loss: 2.042682565668578

Epoch: 6| Step: 10
Training loss: 2.174834728240967
Validation loss: 1.9903286221206828

Epoch: 6| Step: 11
Training loss: 2.0340473651885986
Validation loss: 1.9992636531911872

Epoch: 6| Step: 12
Training loss: 1.748530626296997
Validation loss: 2.0217389560514882

Epoch: 6| Step: 13
Training loss: 2.4655823707580566
Validation loss: 2.005073082062506

Epoch: 145| Step: 0
Training loss: 2.8986573219299316
Validation loss: 2.0206929586266957

Epoch: 6| Step: 1
Training loss: 2.306272029876709
Validation loss: 2.0214840622358423

Epoch: 6| Step: 2
Training loss: 1.7769064903259277
Validation loss: 2.008209566916189

Epoch: 6| Step: 3
Training loss: 2.0876107215881348
Validation loss: 2.0233628032028035

Epoch: 6| Step: 4
Training loss: 1.7499529123306274
Validation loss: 1.994775887458555

Epoch: 6| Step: 5
Training loss: 2.640392780303955
Validation loss: 1.9990836369094027

Epoch: 6| Step: 6
Training loss: 2.2699925899505615
Validation loss: 2.025772476709017

Epoch: 6| Step: 7
Training loss: 2.6851582527160645
Validation loss: 2.0144372473480883

Epoch: 6| Step: 8
Training loss: 2.2592999935150146
Validation loss: 2.0114811466586207

Epoch: 6| Step: 9
Training loss: 1.1782290935516357
Validation loss: 2.0259676748706448

Epoch: 6| Step: 10
Training loss: 2.0504040718078613
Validation loss: 2.028733247069902

Epoch: 6| Step: 11
Training loss: 1.9758951663970947
Validation loss: 2.025921660084878

Epoch: 6| Step: 12
Training loss: 1.70876145362854
Validation loss: 2.0055699092085644

Epoch: 6| Step: 13
Training loss: 1.6255578994750977
Validation loss: 1.9956429799397786

Epoch: 146| Step: 0
Training loss: 1.2679928541183472
Validation loss: 1.9819076291976436

Epoch: 6| Step: 1
Training loss: 2.2153022289276123
Validation loss: 2.0077198320819485

Epoch: 6| Step: 2
Training loss: 2.398707389831543
Validation loss: 2.0138577466369956

Epoch: 6| Step: 3
Training loss: 2.7567996978759766
Validation loss: 2.0134040847901375

Epoch: 6| Step: 4
Training loss: 1.6028614044189453
Validation loss: 1.9882857286801903

Epoch: 6| Step: 5
Training loss: 1.9377285242080688
Validation loss: 2.0082392910475373

Epoch: 6| Step: 6
Training loss: 1.9099243879318237
Validation loss: 1.9828508489875383

Epoch: 6| Step: 7
Training loss: 2.1392173767089844
Validation loss: 2.013547146192161

Epoch: 6| Step: 8
Training loss: 1.924802303314209
Validation loss: 2.0101989879403064

Epoch: 6| Step: 9
Training loss: 2.039079189300537
Validation loss: 1.9876574226604995

Epoch: 6| Step: 10
Training loss: 2.272517681121826
Validation loss: 1.9767730876963625

Epoch: 6| Step: 11
Training loss: 2.429609537124634
Validation loss: 2.0227101720789427

Epoch: 6| Step: 12
Training loss: 2.24601411819458
Validation loss: 1.990265747552277

Epoch: 6| Step: 13
Training loss: 2.062924385070801
Validation loss: 1.9715933210106307

Epoch: 147| Step: 0
Training loss: 1.9322589635849
Validation loss: 1.9853700168671147

Epoch: 6| Step: 1
Training loss: 1.7346653938293457
Validation loss: 2.0000649088172504

Epoch: 6| Step: 2
Training loss: 1.5571835041046143
Validation loss: 2.004253033668764

Epoch: 6| Step: 3
Training loss: 2.231278657913208
Validation loss: 1.9883011605149956

Epoch: 6| Step: 4
Training loss: 2.3044722080230713
Validation loss: 1.9599821952081495

Epoch: 6| Step: 5
Training loss: 2.1511096954345703
Validation loss: 1.9657934968189528

Epoch: 6| Step: 6
Training loss: 2.141017198562622
Validation loss: 1.9697149158805929

Epoch: 6| Step: 7
Training loss: 2.8721976280212402
Validation loss: 1.9661625867248864

Epoch: 6| Step: 8
Training loss: 2.0957841873168945
Validation loss: 2.0018196593048754

Epoch: 6| Step: 9
Training loss: 2.0513012409210205
Validation loss: 1.9924889995205788

Epoch: 6| Step: 10
Training loss: 1.5270161628723145
Validation loss: 1.9764206486363565

Epoch: 6| Step: 11
Training loss: 1.7686429023742676
Validation loss: 1.9769383335626254

Epoch: 6| Step: 12
Training loss: 2.353555679321289
Validation loss: 1.9865294630809496

Epoch: 6| Step: 13
Training loss: 2.852182626724243
Validation loss: 1.9881530948864516

Epoch: 148| Step: 0
Training loss: 2.0192127227783203
Validation loss: 1.9691387222659202

Epoch: 6| Step: 1
Training loss: 2.235203981399536
Validation loss: 1.9904644861016223

Epoch: 6| Step: 2
Training loss: 1.4260618686676025
Validation loss: 1.9845768302999518

Epoch: 6| Step: 3
Training loss: 2.809769630432129
Validation loss: 1.9868894136080177

Epoch: 6| Step: 4
Training loss: 2.235384702682495
Validation loss: 1.9783222982960362

Epoch: 6| Step: 5
Training loss: 1.5889626741409302
Validation loss: 2.0067518372689523

Epoch: 6| Step: 6
Training loss: 2.7912025451660156
Validation loss: 1.9965381109586327

Epoch: 6| Step: 7
Training loss: 2.4617998600006104
Validation loss: 1.99693283214364

Epoch: 6| Step: 8
Training loss: 2.4340672492980957
Validation loss: 1.978994664325509

Epoch: 6| Step: 9
Training loss: 1.6217763423919678
Validation loss: 1.9769192728945004

Epoch: 6| Step: 10
Training loss: 1.55302894115448
Validation loss: 1.9953205303479267

Epoch: 6| Step: 11
Training loss: 2.3094053268432617
Validation loss: 1.9882366144528953

Epoch: 6| Step: 12
Training loss: 1.6940280199050903
Validation loss: 1.996172385831033

Epoch: 6| Step: 13
Training loss: 1.9387879371643066
Validation loss: 1.9783183579803796

Epoch: 149| Step: 0
Training loss: 1.699068307876587
Validation loss: 1.9875759898975331

Epoch: 6| Step: 1
Training loss: 2.1928622722625732
Validation loss: 2.0147326941131265

Epoch: 6| Step: 2
Training loss: 1.6287004947662354
Validation loss: 2.0042983178169496

Epoch: 6| Step: 3
Training loss: 2.101229667663574
Validation loss: 1.9901340789692377

Epoch: 6| Step: 4
Training loss: 2.229494094848633
Validation loss: 2.007638144236739

Epoch: 6| Step: 5
Training loss: 2.537252426147461
Validation loss: 2.007779641817975

Epoch: 6| Step: 6
Training loss: 1.9040913581848145
Validation loss: 2.007294839428317

Epoch: 6| Step: 7
Training loss: 1.788530707359314
Validation loss: 2.0260556974718646

Epoch: 6| Step: 8
Training loss: 1.6441926956176758
Validation loss: 2.0351664609806512

Epoch: 6| Step: 9
Training loss: 2.115077495574951
Validation loss: 2.0409311671410837

Epoch: 6| Step: 10
Training loss: 2.4886083602905273
Validation loss: 2.0274730805427796

Epoch: 6| Step: 11
Training loss: 2.4199695587158203
Validation loss: 2.0441698323013964

Epoch: 6| Step: 12
Training loss: 2.3080220222473145
Validation loss: 1.9924393789742583

Epoch: 6| Step: 13
Training loss: 1.7839186191558838
Validation loss: 2.0177460396161644

Epoch: 150| Step: 0
Training loss: 2.3739609718322754
Validation loss: 2.044933347291844

Epoch: 6| Step: 1
Training loss: 1.6045111417770386
Validation loss: 2.025535815505571

Epoch: 6| Step: 2
Training loss: 2.0859568119049072
Validation loss: 2.0225852458707747

Epoch: 6| Step: 3
Training loss: 2.5487093925476074
Validation loss: 2.0039368009054535

Epoch: 6| Step: 4
Training loss: 1.9839247465133667
Validation loss: 2.0212657848993936

Epoch: 6| Step: 5
Training loss: 2.0032355785369873
Validation loss: 2.0171217892759588

Epoch: 6| Step: 6
Training loss: 2.4710404872894287
Validation loss: 1.9715315026621665

Epoch: 6| Step: 7
Training loss: 1.5849065780639648
Validation loss: 1.9986725007334063

Epoch: 6| Step: 8
Training loss: 1.8115633726119995
Validation loss: 2.010509631967032

Epoch: 6| Step: 9
Training loss: 2.3823485374450684
Validation loss: 2.00514877739773

Epoch: 6| Step: 10
Training loss: 1.8544816970825195
Validation loss: 2.026326051322363

Epoch: 6| Step: 11
Training loss: 2.5654711723327637
Validation loss: 2.0241147472012426

Epoch: 6| Step: 12
Training loss: 1.4836268424987793
Validation loss: 1.9814313098948488

Epoch: 6| Step: 13
Training loss: 2.427755117416382
Validation loss: 1.9874607337418424

Epoch: 151| Step: 0
Training loss: 1.7834715843200684
Validation loss: 1.995054998705464

Epoch: 6| Step: 1
Training loss: 2.5168120861053467
Validation loss: 2.007874401666785

Epoch: 6| Step: 2
Training loss: 2.558119058609009
Validation loss: 2.0174561572331253

Epoch: 6| Step: 3
Training loss: 2.2383248805999756
Validation loss: 1.9963696490051925

Epoch: 6| Step: 4
Training loss: 2.8388607501983643
Validation loss: 2.010332145998555

Epoch: 6| Step: 5
Training loss: 2.318394184112549
Validation loss: 2.0288298386399464

Epoch: 6| Step: 6
Training loss: 1.8174121379852295
Validation loss: 1.9710527107279787

Epoch: 6| Step: 7
Training loss: 1.1035666465759277
Validation loss: 2.006333807463287

Epoch: 6| Step: 8
Training loss: 1.8294975757598877
Validation loss: 2.0110975773103776

Epoch: 6| Step: 9
Training loss: 2.459482192993164
Validation loss: 2.0271656769578175

Epoch: 6| Step: 10
Training loss: 1.8443553447723389
Validation loss: 2.045074265490296

Epoch: 6| Step: 11
Training loss: 2.600013017654419
Validation loss: 2.0164057772646666

Epoch: 6| Step: 12
Training loss: 1.6292091608047485
Validation loss: 2.005996778447141

Epoch: 6| Step: 13
Training loss: 1.2369810342788696
Validation loss: 2.015264282944382

Epoch: 152| Step: 0
Training loss: 2.304144859313965
Validation loss: 2.010768746816984

Epoch: 6| Step: 1
Training loss: 1.8852977752685547
Validation loss: 1.9939413660316057

Epoch: 6| Step: 2
Training loss: 1.1336170434951782
Validation loss: 1.9903756418535787

Epoch: 6| Step: 3
Training loss: 2.550694227218628
Validation loss: 1.9886171458869852

Epoch: 6| Step: 4
Training loss: 1.8703393936157227
Validation loss: 2.027990468086735

Epoch: 6| Step: 5
Training loss: 1.415271282196045
Validation loss: 2.0160245715930896

Epoch: 6| Step: 6
Training loss: 2.5460424423217773
Validation loss: 2.0060744798311623

Epoch: 6| Step: 7
Training loss: 1.917341947555542
Validation loss: 2.025805998873967

Epoch: 6| Step: 8
Training loss: 1.854438066482544
Validation loss: 2.010764434773435

Epoch: 6| Step: 9
Training loss: 2.5234405994415283
Validation loss: 1.9929124539898289

Epoch: 6| Step: 10
Training loss: 1.9470709562301636
Validation loss: 1.996407130713104

Epoch: 6| Step: 11
Training loss: 2.6811838150024414
Validation loss: 1.9909439881642659

Epoch: 6| Step: 12
Training loss: 2.1757898330688477
Validation loss: 2.0020182235266573

Epoch: 6| Step: 13
Training loss: 1.8403570652008057
Validation loss: 2.016107177221647

Epoch: 153| Step: 0
Training loss: 2.354494571685791
Validation loss: 2.032696823919973

Epoch: 6| Step: 1
Training loss: 1.963377594947815
Validation loss: 2.012559880492508

Epoch: 6| Step: 2
Training loss: 2.3300533294677734
Validation loss: 2.005129691093199

Epoch: 6| Step: 3
Training loss: 2.445993423461914
Validation loss: 2.016305887570945

Epoch: 6| Step: 4
Training loss: 1.7360126972198486
Validation loss: 2.0262667056052917

Epoch: 6| Step: 5
Training loss: 2.542203903198242
Validation loss: 2.031812906265259

Epoch: 6| Step: 6
Training loss: 1.8593237400054932
Validation loss: 1.9950232678844082

Epoch: 6| Step: 7
Training loss: 1.5707595348358154
Validation loss: 2.0037890429137857

Epoch: 6| Step: 8
Training loss: 1.7096408605575562
Validation loss: 1.9572921337619904

Epoch: 6| Step: 9
Training loss: 2.60578989982605
Validation loss: 2.005375326320689

Epoch: 6| Step: 10
Training loss: 1.5758159160614014
Validation loss: 1.9985397092757686

Epoch: 6| Step: 11
Training loss: 2.112452507019043
Validation loss: 1.9928917167007283

Epoch: 6| Step: 12
Training loss: 2.6053614616394043
Validation loss: 2.000709033781482

Epoch: 6| Step: 13
Training loss: 0.9428623914718628
Validation loss: 2.005566539302949

Epoch: 154| Step: 0
Training loss: 1.618646264076233
Validation loss: 2.005324127853558

Epoch: 6| Step: 1
Training loss: 2.2403621673583984
Validation loss: 2.0182744367148286

Epoch: 6| Step: 2
Training loss: 1.6128029823303223
Validation loss: 1.9931938007313719

Epoch: 6| Step: 3
Training loss: 1.8592597246170044
Validation loss: 1.9921990210010159

Epoch: 6| Step: 4
Training loss: 2.4733030796051025
Validation loss: 1.9886285066604614

Epoch: 6| Step: 5
Training loss: 1.996908187866211
Validation loss: 1.977147445883802

Epoch: 6| Step: 6
Training loss: 2.0095081329345703
Validation loss: 1.9865411404640443

Epoch: 6| Step: 7
Training loss: 1.8731223344802856
Validation loss: 2.0160508642914476

Epoch: 6| Step: 8
Training loss: 2.145902633666992
Validation loss: 1.9966366188500517

Epoch: 6| Step: 9
Training loss: 2.146538734436035
Validation loss: 1.9978409121113438

Epoch: 6| Step: 10
Training loss: 2.416207790374756
Validation loss: 1.9889610172599874

Epoch: 6| Step: 11
Training loss: 2.1234843730926514
Validation loss: 1.9945036429230885

Epoch: 6| Step: 12
Training loss: 1.992488145828247
Validation loss: 2.001287926909744

Epoch: 6| Step: 13
Training loss: 2.4026615619659424
Validation loss: 2.0013707030204033

Epoch: 155| Step: 0
Training loss: 2.18446683883667
Validation loss: 1.9831753418009768

Epoch: 6| Step: 1
Training loss: 2.2489736080169678
Validation loss: 1.978746521857477

Epoch: 6| Step: 2
Training loss: 1.9934359788894653
Validation loss: 1.9966775191727506

Epoch: 6| Step: 3
Training loss: 1.389784812927246
Validation loss: 1.9961633323341288

Epoch: 6| Step: 4
Training loss: 1.7487396001815796
Validation loss: 1.9779272233286211

Epoch: 6| Step: 5
Training loss: 2.157895088195801
Validation loss: 2.006412713758407

Epoch: 6| Step: 6
Training loss: 1.783513069152832
Validation loss: 2.0029847122007802

Epoch: 6| Step: 7
Training loss: 2.1166012287139893
Validation loss: 2.035234598703282

Epoch: 6| Step: 8
Training loss: 2.4190633296966553
Validation loss: 1.9798209128841278

Epoch: 6| Step: 9
Training loss: 2.182971715927124
Validation loss: 1.9555991964955484

Epoch: 6| Step: 10
Training loss: 2.783297061920166
Validation loss: 1.983563635938911

Epoch: 6| Step: 11
Training loss: 2.4640278816223145
Validation loss: 1.9999134348284813

Epoch: 6| Step: 12
Training loss: 1.8490296602249146
Validation loss: 2.0010963627087173

Epoch: 6| Step: 13
Training loss: 0.9681606292724609
Validation loss: 1.9870661330479447

Epoch: 156| Step: 0
Training loss: 2.3613815307617188
Validation loss: 1.984920060762795

Epoch: 6| Step: 1
Training loss: 2.297720193862915
Validation loss: 1.9794273709738126

Epoch: 6| Step: 2
Training loss: 1.9083278179168701
Validation loss: 1.972729411176456

Epoch: 6| Step: 3
Training loss: 1.9196196794509888
Validation loss: 1.9970357123241629

Epoch: 6| Step: 4
Training loss: 2.106785774230957
Validation loss: 1.970189191961801

Epoch: 6| Step: 5
Training loss: 1.9258596897125244
Validation loss: 1.995779219494071

Epoch: 6| Step: 6
Training loss: 2.9168636798858643
Validation loss: 2.014284783794034

Epoch: 6| Step: 7
Training loss: 1.2464983463287354
Validation loss: 2.00443140281144

Epoch: 6| Step: 8
Training loss: 1.9506382942199707
Validation loss: 1.9861422341356996

Epoch: 6| Step: 9
Training loss: 1.8672326803207397
Validation loss: 2.0059798648280482

Epoch: 6| Step: 10
Training loss: 1.8452829122543335
Validation loss: 1.9655902718984952

Epoch: 6| Step: 11
Training loss: 2.574315071105957
Validation loss: 1.9991647530627508

Epoch: 6| Step: 12
Training loss: 2.354069232940674
Validation loss: 2.0372579764294367

Epoch: 6| Step: 13
Training loss: 1.1151113510131836
Validation loss: 1.9986203485919583

Epoch: 157| Step: 0
Training loss: 2.23583984375
Validation loss: 1.985148524725309

Epoch: 6| Step: 1
Training loss: 1.467647671699524
Validation loss: 1.9920584091576197

Epoch: 6| Step: 2
Training loss: 2.21669864654541
Validation loss: 2.000726238373787

Epoch: 6| Step: 3
Training loss: 1.654497742652893
Validation loss: 2.010925923624346

Epoch: 6| Step: 4
Training loss: 1.1974682807922363
Validation loss: 2.013971438971899

Epoch: 6| Step: 5
Training loss: 2.381267547607422
Validation loss: 2.0139877180899344

Epoch: 6| Step: 6
Training loss: 2.7788245677948
Validation loss: 2.0087301756746028

Epoch: 6| Step: 7
Training loss: 2.204434394836426
Validation loss: 2.0177163257393786

Epoch: 6| Step: 8
Training loss: 1.959350347518921
Validation loss: 2.031348254090996

Epoch: 6| Step: 9
Training loss: 2.108578681945801
Validation loss: 2.0153747515011857

Epoch: 6| Step: 10
Training loss: 2.7287681102752686
Validation loss: 2.018990429498816

Epoch: 6| Step: 11
Training loss: 1.9266740083694458
Validation loss: 2.031788246605986

Epoch: 6| Step: 12
Training loss: 1.9203970432281494
Validation loss: 2.0126783642717587

Epoch: 6| Step: 13
Training loss: 2.0204148292541504
Validation loss: 2.0100924455991356

Epoch: 158| Step: 0
Training loss: 1.7981023788452148
Validation loss: 2.0004283125682543

Epoch: 6| Step: 1
Training loss: 2.038045883178711
Validation loss: 2.0243900360599643

Epoch: 6| Step: 2
Training loss: 2.8180017471313477
Validation loss: 2.0061075225953133

Epoch: 6| Step: 3
Training loss: 2.3130998611450195
Validation loss: 2.046704041060581

Epoch: 6| Step: 4
Training loss: 1.628950595855713
Validation loss: 2.032436265740343

Epoch: 6| Step: 5
Training loss: 1.3063619136810303
Validation loss: 2.007371756338304

Epoch: 6| Step: 6
Training loss: 1.9334731101989746
Validation loss: 1.9993787337374944

Epoch: 6| Step: 7
Training loss: 1.9749627113342285
Validation loss: 2.0074836669429654

Epoch: 6| Step: 8
Training loss: 1.3609168529510498
Validation loss: 2.0276270425447853

Epoch: 6| Step: 9
Training loss: 1.8738243579864502
Validation loss: 2.0202687607016614

Epoch: 6| Step: 10
Training loss: 2.1379964351654053
Validation loss: 1.9948362535045994

Epoch: 6| Step: 11
Training loss: 2.882230281829834
Validation loss: 2.028417436025476

Epoch: 6| Step: 12
Training loss: 2.904750108718872
Validation loss: 2.0204460928517003

Epoch: 6| Step: 13
Training loss: 1.7505942583084106
Validation loss: 2.015936800228652

Epoch: 159| Step: 0
Training loss: 1.9569761753082275
Validation loss: 2.0262666158778693

Epoch: 6| Step: 1
Training loss: 2.278219223022461
Validation loss: 2.02761201320156

Epoch: 6| Step: 2
Training loss: 1.9758124351501465
Validation loss: 2.0334306070881505

Epoch: 6| Step: 3
Training loss: 1.9101810455322266
Validation loss: 2.0193588977218955

Epoch: 6| Step: 4
Training loss: 1.8472373485565186
Validation loss: 2.013020602605676

Epoch: 6| Step: 5
Training loss: 2.608433961868286
Validation loss: 1.982816275729928

Epoch: 6| Step: 6
Training loss: 2.431173801422119
Validation loss: 2.019340838155439

Epoch: 6| Step: 7
Training loss: 1.5159103870391846
Validation loss: 2.0001616131874824

Epoch: 6| Step: 8
Training loss: 2.0736446380615234
Validation loss: 1.9948924279982043

Epoch: 6| Step: 9
Training loss: 1.9566138982772827
Validation loss: 1.9888710565464471

Epoch: 6| Step: 10
Training loss: 2.1954147815704346
Validation loss: 1.9929777999078073

Epoch: 6| Step: 11
Training loss: 2.2210516929626465
Validation loss: 1.985475178687803

Epoch: 6| Step: 12
Training loss: 1.799273133277893
Validation loss: 1.9850304152375908

Epoch: 6| Step: 13
Training loss: 2.0131821632385254
Validation loss: 1.9736032127052225

Epoch: 160| Step: 0
Training loss: 1.3928906917572021
Validation loss: 1.9805863621414348

Epoch: 6| Step: 1
Training loss: 2.3619775772094727
Validation loss: 1.9961524509614514

Epoch: 6| Step: 2
Training loss: 2.288750648498535
Validation loss: 1.9873537889090918

Epoch: 6| Step: 3
Training loss: 2.8026256561279297
Validation loss: 1.9836963607418923

Epoch: 6| Step: 4
Training loss: 2.5196733474731445
Validation loss: 2.0007474127636162

Epoch: 6| Step: 5
Training loss: 2.267909288406372
Validation loss: 1.9720769748892835

Epoch: 6| Step: 6
Training loss: 1.1014344692230225
Validation loss: 2.011969445854105

Epoch: 6| Step: 7
Training loss: 2.616565704345703
Validation loss: 2.0053544352131505

Epoch: 6| Step: 8
Training loss: 2.3725924491882324
Validation loss: 1.975322360633522

Epoch: 6| Step: 9
Training loss: 1.6753355264663696
Validation loss: 1.9885054660099808

Epoch: 6| Step: 10
Training loss: 1.883545994758606
Validation loss: 1.9640590747197468

Epoch: 6| Step: 11
Training loss: 1.7201294898986816
Validation loss: 1.9847687572561286

Epoch: 6| Step: 12
Training loss: 2.210416078567505
Validation loss: 1.9819254695728261

Epoch: 6| Step: 13
Training loss: 1.907390832901001
Validation loss: 1.9878460489293581

Epoch: 161| Step: 0
Training loss: 1.826906681060791
Validation loss: 1.972971736743886

Epoch: 6| Step: 1
Training loss: 1.575890302658081
Validation loss: 2.0042781855470393

Epoch: 6| Step: 2
Training loss: 1.7375571727752686
Validation loss: 2.0066886486545688

Epoch: 6| Step: 3
Training loss: 1.9180359840393066
Validation loss: 2.025356331179219

Epoch: 6| Step: 4
Training loss: 2.788127899169922
Validation loss: 1.9855286946860693

Epoch: 6| Step: 5
Training loss: 1.617240309715271
Validation loss: 2.033522993005732

Epoch: 6| Step: 6
Training loss: 2.5564637184143066
Validation loss: 2.005560468601924

Epoch: 6| Step: 7
Training loss: 1.7381757497787476
Validation loss: 2.015550628785164

Epoch: 6| Step: 8
Training loss: 2.012366533279419
Validation loss: 2.0581956730094007

Epoch: 6| Step: 9
Training loss: 2.4590814113616943
Validation loss: 2.010210321795556

Epoch: 6| Step: 10
Training loss: 2.526674270629883
Validation loss: 2.0283636111085133

Epoch: 6| Step: 11
Training loss: 2.35105562210083
Validation loss: 2.010174059098767

Epoch: 6| Step: 12
Training loss: 1.4217588901519775
Validation loss: 2.008330334899246

Epoch: 6| Step: 13
Training loss: 2.0965471267700195
Validation loss: 2.0183945214876564

Epoch: 162| Step: 0
Training loss: 2.083552837371826
Validation loss: 2.0327039816046275

Epoch: 6| Step: 1
Training loss: 2.6798148155212402
Validation loss: 2.0061301057056715

Epoch: 6| Step: 2
Training loss: 2.251873254776001
Validation loss: 2.0108564015357726

Epoch: 6| Step: 3
Training loss: 2.6357345581054688
Validation loss: 2.0002679645374255

Epoch: 6| Step: 4
Training loss: 1.3992687463760376
Validation loss: 2.0290102984315608

Epoch: 6| Step: 5
Training loss: 2.243070125579834
Validation loss: 2.0545203019213933

Epoch: 6| Step: 6
Training loss: 1.6926623582839966
Validation loss: 2.045702285664056

Epoch: 6| Step: 7
Training loss: 1.503279447555542
Validation loss: 2.0310116621755783

Epoch: 6| Step: 8
Training loss: 1.6119499206542969
Validation loss: 2.018732351641501

Epoch: 6| Step: 9
Training loss: 2.1542608737945557
Validation loss: 2.0048311346320697

Epoch: 6| Step: 10
Training loss: 2.180183172225952
Validation loss: 1.9983201437099005

Epoch: 6| Step: 11
Training loss: 2.5668320655822754
Validation loss: 2.0295720305494083

Epoch: 6| Step: 12
Training loss: 1.8579025268554688
Validation loss: 2.009886351964807

Epoch: 6| Step: 13
Training loss: 2.220621109008789
Validation loss: 2.007743089429794

Epoch: 163| Step: 0
Training loss: 1.8652124404907227
Validation loss: 1.9980310342645133

Epoch: 6| Step: 1
Training loss: 1.3954384326934814
Validation loss: 1.992689481345556

Epoch: 6| Step: 2
Training loss: 2.120987892150879
Validation loss: 2.021917353394211

Epoch: 6| Step: 3
Training loss: 2.3120102882385254
Validation loss: 1.9902917492774226

Epoch: 6| Step: 4
Training loss: 2.5540781021118164
Validation loss: 2.021086906874052

Epoch: 6| Step: 5
Training loss: 2.301647186279297
Validation loss: 1.9983651638031006

Epoch: 6| Step: 6
Training loss: 1.9392898082733154
Validation loss: 1.9844524911654893

Epoch: 6| Step: 7
Training loss: 2.2057137489318848
Validation loss: 1.9956002594322286

Epoch: 6| Step: 8
Training loss: 1.8834574222564697
Validation loss: 1.9904234152968212

Epoch: 6| Step: 9
Training loss: 1.5438610315322876
Validation loss: 2.010179361989421

Epoch: 6| Step: 10
Training loss: 2.696716070175171
Validation loss: 2.0079745874609998

Epoch: 6| Step: 11
Training loss: 2.315577507019043
Validation loss: 2.030182928167364

Epoch: 6| Step: 12
Training loss: 1.5531537532806396
Validation loss: 2.0015096792610745

Epoch: 6| Step: 13
Training loss: 1.950919508934021
Validation loss: 2.0060060716444448

Epoch: 164| Step: 0
Training loss: 1.355104684829712
Validation loss: 1.9816137347170102

Epoch: 6| Step: 1
Training loss: 1.913067102432251
Validation loss: 1.9906527919154013

Epoch: 6| Step: 2
Training loss: 1.6165884733200073
Validation loss: 2.009886851874731

Epoch: 6| Step: 3
Training loss: 2.0090179443359375
Validation loss: 1.9816129874157649

Epoch: 6| Step: 4
Training loss: 1.6291379928588867
Validation loss: 2.008507492721722

Epoch: 6| Step: 5
Training loss: 2.4691555500030518
Validation loss: 2.006939093271891

Epoch: 6| Step: 6
Training loss: 2.5964529514312744
Validation loss: 2.016790046486803

Epoch: 6| Step: 7
Training loss: 2.6401543617248535
Validation loss: 2.0080140149721535

Epoch: 6| Step: 8
Training loss: 2.1247596740722656
Validation loss: 1.9957944449558054

Epoch: 6| Step: 9
Training loss: 1.8963046073913574
Validation loss: 2.012118354920418

Epoch: 6| Step: 10
Training loss: 1.9485232830047607
Validation loss: 2.017985701560974

Epoch: 6| Step: 11
Training loss: 2.2013537883758545
Validation loss: 1.9997901275593748

Epoch: 6| Step: 12
Training loss: 2.1810097694396973
Validation loss: 2.007189022597446

Epoch: 6| Step: 13
Training loss: 1.8329499959945679
Validation loss: 1.990453000991575

Epoch: 165| Step: 0
Training loss: 1.9970463514328003
Validation loss: 2.00599915494201

Epoch: 6| Step: 1
Training loss: 1.4068171977996826
Validation loss: 2.0087790925015687

Epoch: 6| Step: 2
Training loss: 2.13995099067688
Validation loss: 2.0010901522892777

Epoch: 6| Step: 3
Training loss: 2.6953234672546387
Validation loss: 1.9863079004390265

Epoch: 6| Step: 4
Training loss: 1.6881647109985352
Validation loss: 2.0154560894094486

Epoch: 6| Step: 5
Training loss: 2.476182460784912
Validation loss: 2.0070530958073114

Epoch: 6| Step: 6
Training loss: 1.6359589099884033
Validation loss: 2.0105368450123775

Epoch: 6| Step: 7
Training loss: 1.8938541412353516
Validation loss: 2.010694114110803

Epoch: 6| Step: 8
Training loss: 1.8262609243392944
Validation loss: 2.024212555218768

Epoch: 6| Step: 9
Training loss: 1.6855254173278809
Validation loss: 1.9986121372510028

Epoch: 6| Step: 10
Training loss: 2.510362148284912
Validation loss: 1.974482438897574

Epoch: 6| Step: 11
Training loss: 2.4588451385498047
Validation loss: 1.980369011561076

Epoch: 6| Step: 12
Training loss: 1.958525538444519
Validation loss: 1.9720632683846258

Epoch: 6| Step: 13
Training loss: 2.2191572189331055
Validation loss: 1.9986467669087071

Epoch: 166| Step: 0
Training loss: 2.2174758911132812
Validation loss: 1.9945332593815301

Epoch: 6| Step: 1
Training loss: 2.7660486698150635
Validation loss: 1.9836381866085915

Epoch: 6| Step: 2
Training loss: 1.5320775508880615
Validation loss: 2.011472009843396

Epoch: 6| Step: 3
Training loss: 2.2564048767089844
Validation loss: 1.9856804186298

Epoch: 6| Step: 4
Training loss: 1.907639741897583
Validation loss: 1.9834970710098103

Epoch: 6| Step: 5
Training loss: 1.8286644220352173
Validation loss: 2.0105155885860486

Epoch: 6| Step: 6
Training loss: 1.7429851293563843
Validation loss: 1.99073286210337

Epoch: 6| Step: 7
Training loss: 2.431954860687256
Validation loss: 2.003061067673468

Epoch: 6| Step: 8
Training loss: 1.7570281028747559
Validation loss: 1.9881931735623268

Epoch: 6| Step: 9
Training loss: 2.297942638397217
Validation loss: 1.988494521828108

Epoch: 6| Step: 10
Training loss: 2.0373215675354004
Validation loss: 1.9787537500422487

Epoch: 6| Step: 11
Training loss: 2.0905988216400146
Validation loss: 1.9589552904969902

Epoch: 6| Step: 12
Training loss: 2.164386749267578
Validation loss: 1.9941120186159689

Epoch: 6| Step: 13
Training loss: 1.5073717832565308
Validation loss: 1.9949296174510833

Epoch: 167| Step: 0
Training loss: 2.798877716064453
Validation loss: 1.9798328876495361

Epoch: 6| Step: 1
Training loss: 2.211967945098877
Validation loss: 1.9877981857586933

Epoch: 6| Step: 2
Training loss: 1.836024284362793
Validation loss: 1.997973713823544

Epoch: 6| Step: 3
Training loss: 2.0166964530944824
Validation loss: 2.0370388697552424

Epoch: 6| Step: 4
Training loss: 1.673400640487671
Validation loss: 1.9775579616587649

Epoch: 6| Step: 5
Training loss: 2.42067813873291
Validation loss: 1.985690132264168

Epoch: 6| Step: 6
Training loss: 2.341494083404541
Validation loss: 1.9878173694815686

Epoch: 6| Step: 7
Training loss: 2.2173190116882324
Validation loss: 2.0026375221949753

Epoch: 6| Step: 8
Training loss: 2.281723976135254
Validation loss: 2.0172569738921298

Epoch: 6| Step: 9
Training loss: 2.195601463317871
Validation loss: 2.011880064523348

Epoch: 6| Step: 10
Training loss: 1.7966701984405518
Validation loss: 2.015376560149654

Epoch: 6| Step: 11
Training loss: 1.5993179082870483
Validation loss: 2.0430681179928523

Epoch: 6| Step: 12
Training loss: 1.570286512374878
Validation loss: 2.0225953184148318

Epoch: 6| Step: 13
Training loss: 1.792285442352295
Validation loss: 2.02659261098472

Epoch: 168| Step: 0
Training loss: 1.6796531677246094
Validation loss: 2.0097301365226827

Epoch: 6| Step: 1
Training loss: 1.5300147533416748
Validation loss: 2.0150806724384265

Epoch: 6| Step: 2
Training loss: 3.039827823638916
Validation loss: 2.031146800646218

Epoch: 6| Step: 3
Training loss: 1.8135380744934082
Validation loss: 2.0459076691699285

Epoch: 6| Step: 4
Training loss: 1.8224339485168457
Validation loss: 2.0357368300038

Epoch: 6| Step: 5
Training loss: 2.670407295227051
Validation loss: 2.003555897743471

Epoch: 6| Step: 6
Training loss: 1.6499221324920654
Validation loss: 2.0118552920638875

Epoch: 6| Step: 7
Training loss: 1.5508496761322021
Validation loss: 2.0074030224994948

Epoch: 6| Step: 8
Training loss: 1.69197416305542
Validation loss: 2.014852867331556

Epoch: 6| Step: 9
Training loss: 2.3073134422302246
Validation loss: 1.994198206932314

Epoch: 6| Step: 10
Training loss: 2.268083095550537
Validation loss: 2.015297543617987

Epoch: 6| Step: 11
Training loss: 2.148259401321411
Validation loss: 2.0067651874275616

Epoch: 6| Step: 12
Training loss: 2.202981948852539
Validation loss: 2.023554660940683

Epoch: 6| Step: 13
Training loss: 2.1218936443328857
Validation loss: 2.004808400266914

Epoch: 169| Step: 0
Training loss: 2.2308387756347656
Validation loss: 2.0020182312175794

Epoch: 6| Step: 1
Training loss: 1.6778385639190674
Validation loss: 1.9959849337095856

Epoch: 6| Step: 2
Training loss: 1.5029977560043335
Validation loss: 2.0166585778677337

Epoch: 6| Step: 3
Training loss: 2.2948601245880127
Validation loss: 2.008106094534679

Epoch: 6| Step: 4
Training loss: 1.6950817108154297
Validation loss: 1.9870334363752795

Epoch: 6| Step: 5
Training loss: 2.758890151977539
Validation loss: 1.9868040969294887

Epoch: 6| Step: 6
Training loss: 1.7231186628341675
Validation loss: 2.0068578861093007

Epoch: 6| Step: 7
Training loss: 1.490755319595337
Validation loss: 1.9957984698716031

Epoch: 6| Step: 8
Training loss: 2.051194190979004
Validation loss: 2.019801847396358

Epoch: 6| Step: 9
Training loss: 2.248319387435913
Validation loss: 2.012738066334878

Epoch: 6| Step: 10
Training loss: 2.8158364295959473
Validation loss: 1.9855733956060102

Epoch: 6| Step: 11
Training loss: 1.8255298137664795
Validation loss: 2.004060158165552

Epoch: 6| Step: 12
Training loss: 2.552778959274292
Validation loss: 2.006610260214857

Epoch: 6| Step: 13
Training loss: 1.3139114379882812
Validation loss: 2.0040564601139357

Epoch: 170| Step: 0
Training loss: 1.7297420501708984
Validation loss: 2.0279653995267806

Epoch: 6| Step: 1
Training loss: 2.5001072883605957
Validation loss: 2.014109719184137

Epoch: 6| Step: 2
Training loss: 1.5800504684448242
Validation loss: 2.0416892933589157

Epoch: 6| Step: 3
Training loss: 2.4587008953094482
Validation loss: 2.018760638852273

Epoch: 6| Step: 4
Training loss: 2.347740888595581
Validation loss: 2.02392408668354

Epoch: 6| Step: 5
Training loss: 2.244396924972534
Validation loss: 2.015216291591685

Epoch: 6| Step: 6
Training loss: 2.03356671333313
Validation loss: 2.027148537738349

Epoch: 6| Step: 7
Training loss: 1.9517889022827148
Validation loss: 2.025250619457614

Epoch: 6| Step: 8
Training loss: 1.6885969638824463
Validation loss: 2.013632510298042

Epoch: 6| Step: 9
Training loss: 2.7616794109344482
Validation loss: 2.018861730893453

Epoch: 6| Step: 10
Training loss: 1.406883716583252
Validation loss: 2.0322241962596936

Epoch: 6| Step: 11
Training loss: 2.147307872772217
Validation loss: 2.0211502531523347

Epoch: 6| Step: 12
Training loss: 2.0448684692382812
Validation loss: 2.0296666032524517

Epoch: 6| Step: 13
Training loss: 1.7994645833969116
Validation loss: 2.034720831019904

Epoch: 171| Step: 0
Training loss: 2.0357322692871094
Validation loss: 2.030815186039094

Epoch: 6| Step: 1
Training loss: 2.7536473274230957
Validation loss: 2.005830867316133

Epoch: 6| Step: 2
Training loss: 1.4308189153671265
Validation loss: 2.027376608182025

Epoch: 6| Step: 3
Training loss: 1.8176229000091553
Validation loss: 2.0049938142940564

Epoch: 6| Step: 4
Training loss: 1.1951806545257568
Validation loss: 2.021897615924958

Epoch: 6| Step: 5
Training loss: 2.092200994491577
Validation loss: 2.0174418085364887

Epoch: 6| Step: 6
Training loss: 2.176384449005127
Validation loss: 2.032330289963753

Epoch: 6| Step: 7
Training loss: 2.1328110694885254
Validation loss: 2.0123769288421958

Epoch: 6| Step: 8
Training loss: 1.7216849327087402
Validation loss: 2.01513550871162

Epoch: 6| Step: 9
Training loss: 2.4332969188690186
Validation loss: 2.0439180045999508

Epoch: 6| Step: 10
Training loss: 2.235333204269409
Validation loss: 2.0228305093703733

Epoch: 6| Step: 11
Training loss: 2.226923942565918
Validation loss: 2.0171075918341197

Epoch: 6| Step: 12
Training loss: 2.038212299346924
Validation loss: 1.9910912488096504

Epoch: 6| Step: 13
Training loss: 2.0819666385650635
Validation loss: 1.9886448947332238

Epoch: 172| Step: 0
Training loss: 1.761357307434082
Validation loss: 2.010761776278096

Epoch: 6| Step: 1
Training loss: 1.4122567176818848
Validation loss: 2.0235329084498908

Epoch: 6| Step: 2
Training loss: 2.52016019821167
Validation loss: 2.009708586559501

Epoch: 6| Step: 3
Training loss: 2.0873045921325684
Validation loss: 2.0316902219608264

Epoch: 6| Step: 4
Training loss: 1.8076223134994507
Validation loss: 2.011019273470807

Epoch: 6| Step: 5
Training loss: 1.899144172668457
Validation loss: 2.0145925962796776

Epoch: 6| Step: 6
Training loss: 2.383636713027954
Validation loss: 1.9915549011640652

Epoch: 6| Step: 7
Training loss: 2.2233033180236816
Validation loss: 1.9787633726673741

Epoch: 6| Step: 8
Training loss: 2.280913829803467
Validation loss: 2.0125460445239978

Epoch: 6| Step: 9
Training loss: 1.7747156620025635
Validation loss: 1.995984705545569

Epoch: 6| Step: 10
Training loss: 1.8183903694152832
Validation loss: 1.982616022068967

Epoch: 6| Step: 11
Training loss: 2.5212531089782715
Validation loss: 2.0171174951778945

Epoch: 6| Step: 12
Training loss: 1.6972209215164185
Validation loss: 2.0107564054509646

Epoch: 6| Step: 13
Training loss: 2.0003950595855713
Validation loss: 1.9962050786582373

Epoch: 173| Step: 0
Training loss: 1.6873505115509033
Validation loss: 2.0089165036396315

Epoch: 6| Step: 1
Training loss: 1.2928338050842285
Validation loss: 1.9801474963465044

Epoch: 6| Step: 2
Training loss: 2.331531047821045
Validation loss: 2.0054261684417725

Epoch: 6| Step: 3
Training loss: 1.7667417526245117
Validation loss: 2.02218625878775

Epoch: 6| Step: 4
Training loss: 2.476121425628662
Validation loss: 1.9899361556576145

Epoch: 6| Step: 5
Training loss: 2.825035333633423
Validation loss: 2.0028580247714953

Epoch: 6| Step: 6
Training loss: 1.290000557899475
Validation loss: 2.032524211432344

Epoch: 6| Step: 7
Training loss: 2.4188621044158936
Validation loss: 1.9708525160307526

Epoch: 6| Step: 8
Training loss: 1.3278956413269043
Validation loss: 2.003390733913709

Epoch: 6| Step: 9
Training loss: 2.5194549560546875
Validation loss: 2.0136277239809752

Epoch: 6| Step: 10
Training loss: 1.8253109455108643
Validation loss: 2.0111393813164002

Epoch: 6| Step: 11
Training loss: 2.5764012336730957
Validation loss: 2.016801498269522

Epoch: 6| Step: 12
Training loss: 1.9293032884597778
Validation loss: 2.0077972245472733

Epoch: 6| Step: 13
Training loss: 2.3586225509643555
Validation loss: 2.0386005665666316

Epoch: 174| Step: 0
Training loss: 1.5319966077804565
Validation loss: 2.020676241126112

Epoch: 6| Step: 1
Training loss: 2.4103188514709473
Validation loss: 2.009621089504611

Epoch: 6| Step: 2
Training loss: 2.8279576301574707
Validation loss: 2.021427477559736

Epoch: 6| Step: 3
Training loss: 2.322681427001953
Validation loss: 2.004193590533349

Epoch: 6| Step: 4
Training loss: 2.5462777614593506
Validation loss: 2.049839453030658

Epoch: 6| Step: 5
Training loss: 1.8205146789550781
Validation loss: 2.0126856693657498

Epoch: 6| Step: 6
Training loss: 1.7698832750320435
Validation loss: 1.998711488580191

Epoch: 6| Step: 7
Training loss: 2.2442848682403564
Validation loss: 2.0112984052268406

Epoch: 6| Step: 8
Training loss: 1.7449092864990234
Validation loss: 1.9842687832411898

Epoch: 6| Step: 9
Training loss: 2.0215883255004883
Validation loss: 1.9976314870260095

Epoch: 6| Step: 10
Training loss: 2.0062642097473145
Validation loss: 1.9891800418976815

Epoch: 6| Step: 11
Training loss: 1.9856473207473755
Validation loss: 1.9870212860004877

Epoch: 6| Step: 12
Training loss: 1.8026468753814697
Validation loss: 2.0088791969001933

Epoch: 6| Step: 13
Training loss: 1.2268755435943604
Validation loss: 2.0167193053871073

Epoch: 175| Step: 0
Training loss: 1.8724772930145264
Validation loss: 1.9794363514069588

Epoch: 6| Step: 1
Training loss: 2.330974578857422
Validation loss: 1.9859455990534958

Epoch: 6| Step: 2
Training loss: 2.005005359649658
Validation loss: 2.0262689026453162

Epoch: 6| Step: 3
Training loss: 1.682051658630371
Validation loss: 2.0254236857096353

Epoch: 6| Step: 4
Training loss: 2.272470235824585
Validation loss: 1.9813661549680976

Epoch: 6| Step: 5
Training loss: 2.0905022621154785
Validation loss: 2.019293554367558

Epoch: 6| Step: 6
Training loss: 2.0040862560272217
Validation loss: 2.005277297830069

Epoch: 6| Step: 7
Training loss: 2.015502691268921
Validation loss: 2.0224134511845087

Epoch: 6| Step: 8
Training loss: 1.9562158584594727
Validation loss: 2.018176694070139

Epoch: 6| Step: 9
Training loss: 2.433851718902588
Validation loss: 2.0181201786123295

Epoch: 6| Step: 10
Training loss: 2.273277759552002
Validation loss: 2.0382770492184545

Epoch: 6| Step: 11
Training loss: 1.9434254169464111
Validation loss: 2.0021626295581942

Epoch: 6| Step: 12
Training loss: 1.67654550075531
Validation loss: 2.0011226361797703

Epoch: 6| Step: 13
Training loss: 1.513669490814209
Validation loss: 2.008869089106078

Epoch: 176| Step: 0
Training loss: 2.2783591747283936
Validation loss: 2.0183690837634507

Epoch: 6| Step: 1
Training loss: 1.7555617094039917
Validation loss: 1.99981693426768

Epoch: 6| Step: 2
Training loss: 2.227637529373169
Validation loss: 2.0150101364299817

Epoch: 6| Step: 3
Training loss: 1.8621817827224731
Validation loss: 2.009405961600683

Epoch: 6| Step: 4
Training loss: 2.2871460914611816
Validation loss: 2.0260144202939925

Epoch: 6| Step: 5
Training loss: 1.4942970275878906
Validation loss: 2.022949646877986

Epoch: 6| Step: 6
Training loss: 1.7474570274353027
Validation loss: 2.0071081628081617

Epoch: 6| Step: 7
Training loss: 1.875583529472351
Validation loss: 1.9987410935022498

Epoch: 6| Step: 8
Training loss: 1.8976681232452393
Validation loss: 2.013189431159727

Epoch: 6| Step: 9
Training loss: 2.082185745239258
Validation loss: 2.0029359876468615

Epoch: 6| Step: 10
Training loss: 2.4014391899108887
Validation loss: 2.010540934019191

Epoch: 6| Step: 11
Training loss: 2.34730863571167
Validation loss: 1.994463602701823

Epoch: 6| Step: 12
Training loss: 1.9271278381347656
Validation loss: 2.0173006775558635

Epoch: 6| Step: 13
Training loss: 2.220841407775879
Validation loss: 2.004133834633776

Epoch: 177| Step: 0
Training loss: 2.4389162063598633
Validation loss: 2.019391004757215

Epoch: 6| Step: 1
Training loss: 2.256321907043457
Validation loss: 2.0074126605064637

Epoch: 6| Step: 2
Training loss: 1.9992828369140625
Validation loss: 2.001321449074694

Epoch: 6| Step: 3
Training loss: 1.4124523401260376
Validation loss: 2.0142429567152456

Epoch: 6| Step: 4
Training loss: 2.8790225982666016
Validation loss: 2.0261128576852943

Epoch: 6| Step: 5
Training loss: 2.104187488555908
Validation loss: 2.0144328507043983

Epoch: 6| Step: 6
Training loss: 1.7209088802337646
Validation loss: 1.9911993139533586

Epoch: 6| Step: 7
Training loss: 1.6123350858688354
Validation loss: 2.0001163316029373

Epoch: 6| Step: 8
Training loss: 1.9451355934143066
Validation loss: 2.023636773068418

Epoch: 6| Step: 9
Training loss: 1.9097909927368164
Validation loss: 2.000990862487465

Epoch: 6| Step: 10
Training loss: 2.2960424423217773
Validation loss: 2.0055383559196227

Epoch: 6| Step: 11
Training loss: 1.6797075271606445
Validation loss: 2.0076827310746714

Epoch: 6| Step: 12
Training loss: 1.9499698877334595
Validation loss: 2.0175174102988294

Epoch: 6| Step: 13
Training loss: 2.7999589443206787
Validation loss: 2.0019413553258425

Epoch: 178| Step: 0
Training loss: 2.622084617614746
Validation loss: 1.9689904797461726

Epoch: 6| Step: 1
Training loss: 2.61116886138916
Validation loss: 2.0055099046358498

Epoch: 6| Step: 2
Training loss: 2.6688919067382812
Validation loss: 2.026956514645648

Epoch: 6| Step: 3
Training loss: 1.6023435592651367
Validation loss: 1.9816659214676067

Epoch: 6| Step: 4
Training loss: 1.4853590726852417
Validation loss: 2.0115507059199835

Epoch: 6| Step: 5
Training loss: 2.321746826171875
Validation loss: 2.0055700309814943

Epoch: 6| Step: 6
Training loss: 1.969236135482788
Validation loss: 1.9867684225882254

Epoch: 6| Step: 7
Training loss: 2.002387523651123
Validation loss: 1.9981115389895696

Epoch: 6| Step: 8
Training loss: 1.5749156475067139
Validation loss: 2.035547838416151

Epoch: 6| Step: 9
Training loss: 1.6331262588500977
Validation loss: 1.9994400906306442

Epoch: 6| Step: 10
Training loss: 1.6302428245544434
Validation loss: 2.000097893899487

Epoch: 6| Step: 11
Training loss: 2.693067789077759
Validation loss: 1.9853250006193757

Epoch: 6| Step: 12
Training loss: 1.9322197437286377
Validation loss: 1.9890586817136375

Epoch: 6| Step: 13
Training loss: 1.1814515590667725
Validation loss: 2.0214644478213404

Epoch: 179| Step: 0
Training loss: 1.740866780281067
Validation loss: 2.0240940842577206

Epoch: 6| Step: 1
Training loss: 2.272378921508789
Validation loss: 1.984698421211653

Epoch: 6| Step: 2
Training loss: 2.11153507232666
Validation loss: 1.9895398462972333

Epoch: 6| Step: 3
Training loss: 1.8590353727340698
Validation loss: 1.9988941620754939

Epoch: 6| Step: 4
Training loss: 1.9018723964691162
Validation loss: 2.0063836369463193

Epoch: 6| Step: 5
Training loss: 2.137989044189453
Validation loss: 2.00676235588648

Epoch: 6| Step: 6
Training loss: 1.7164853811264038
Validation loss: 2.010252296283681

Epoch: 6| Step: 7
Training loss: 1.9573745727539062
Validation loss: 1.9922413877261582

Epoch: 6| Step: 8
Training loss: 1.9040210247039795
Validation loss: 1.9984744300124466

Epoch: 6| Step: 9
Training loss: 1.840103030204773
Validation loss: 2.0270663051195044

Epoch: 6| Step: 10
Training loss: 2.7829842567443848
Validation loss: 2.001016827039821

Epoch: 6| Step: 11
Training loss: 1.933193325996399
Validation loss: 1.9907840887705486

Epoch: 6| Step: 12
Training loss: 1.873435378074646
Validation loss: 1.9937232681500014

Epoch: 6| Step: 13
Training loss: 2.3932669162750244
Validation loss: 1.9957651938161542

Epoch: 180| Step: 0
Training loss: 2.629721164703369
Validation loss: 2.009995537419473

Epoch: 6| Step: 1
Training loss: 1.898526906967163
Validation loss: 2.0328352784597747

Epoch: 6| Step: 2
Training loss: 1.9932608604431152
Validation loss: 2.0166550759346253

Epoch: 6| Step: 3
Training loss: 2.2569034099578857
Validation loss: 1.9859590786759571

Epoch: 6| Step: 4
Training loss: 2.2710254192352295
Validation loss: 2.0133400155651953

Epoch: 6| Step: 5
Training loss: 1.8822410106658936
Validation loss: 1.9904131427887948

Epoch: 6| Step: 6
Training loss: 2.2213563919067383
Validation loss: 2.020562377027286

Epoch: 6| Step: 7
Training loss: 2.1017706394195557
Validation loss: 1.995324473227224

Epoch: 6| Step: 8
Training loss: 2.1859641075134277
Validation loss: 2.011952451480332

Epoch: 6| Step: 9
Training loss: 1.584846019744873
Validation loss: 2.0112041734880015

Epoch: 6| Step: 10
Training loss: 2.51151442527771
Validation loss: 2.0147489155492475

Epoch: 6| Step: 11
Training loss: 1.3255516290664673
Validation loss: 2.0239788793748423

Epoch: 6| Step: 12
Training loss: 2.0386037826538086
Validation loss: 1.9952265242094636

Epoch: 6| Step: 13
Training loss: 1.314688801765442
Validation loss: 2.0249410265235492

Epoch: 181| Step: 0
Training loss: 2.5528976917266846
Validation loss: 2.0209410113673054

Epoch: 6| Step: 1
Training loss: 1.3617010116577148
Validation loss: 1.9990423417860461

Epoch: 6| Step: 2
Training loss: 2.198385715484619
Validation loss: 2.0087824124161915

Epoch: 6| Step: 3
Training loss: 2.034166097640991
Validation loss: 2.0093977733324935

Epoch: 6| Step: 4
Training loss: 1.6653025150299072
Validation loss: 2.0257319814415387

Epoch: 6| Step: 5
Training loss: 1.921104907989502
Validation loss: 2.013143621465211

Epoch: 6| Step: 6
Training loss: 1.784602403640747
Validation loss: 2.01461822243147

Epoch: 6| Step: 7
Training loss: 2.3422183990478516
Validation loss: 2.02817658070595

Epoch: 6| Step: 8
Training loss: 2.0664966106414795
Validation loss: 1.9854271104258876

Epoch: 6| Step: 9
Training loss: 1.916108250617981
Validation loss: 1.9929430625771964

Epoch: 6| Step: 10
Training loss: 2.568035125732422
Validation loss: 2.0112452622382873

Epoch: 6| Step: 11
Training loss: 1.6634384393692017
Validation loss: 2.0034717795669392

Epoch: 6| Step: 12
Training loss: 2.5291028022766113
Validation loss: 1.9939215067894227

Epoch: 6| Step: 13
Training loss: 1.6150376796722412
Validation loss: 1.9993658809251682

Epoch: 182| Step: 0
Training loss: 1.9199508428573608
Validation loss: 1.9822856751821374

Epoch: 6| Step: 1
Training loss: 3.136308431625366
Validation loss: 2.0143701466180945

Epoch: 6| Step: 2
Training loss: 1.872622013092041
Validation loss: 1.987867388674008

Epoch: 6| Step: 3
Training loss: 1.5548275709152222
Validation loss: 1.9815936960199827

Epoch: 6| Step: 4
Training loss: 2.1353960037231445
Validation loss: 1.9758788129334808

Epoch: 6| Step: 5
Training loss: 2.529223680496216
Validation loss: 1.9954725004011584

Epoch: 6| Step: 6
Training loss: 1.5377542972564697
Validation loss: 1.9782948263229863

Epoch: 6| Step: 7
Training loss: 2.352046012878418
Validation loss: 1.984057044470182

Epoch: 6| Step: 8
Training loss: 2.480781078338623
Validation loss: 1.989640010300503

Epoch: 6| Step: 9
Training loss: 1.7263106107711792
Validation loss: 1.9937134532518284

Epoch: 6| Step: 10
Training loss: 1.5542080402374268
Validation loss: 2.013034310392154

Epoch: 6| Step: 11
Training loss: 1.798835277557373
Validation loss: 1.988738344561669

Epoch: 6| Step: 12
Training loss: 1.751424789428711
Validation loss: 1.9957925542708366

Epoch: 6| Step: 13
Training loss: 1.9433485269546509
Validation loss: 2.0191912933062484

Epoch: 183| Step: 0
Training loss: 2.19166898727417
Validation loss: 2.012308564237369

Epoch: 6| Step: 1
Training loss: 2.015493869781494
Validation loss: 2.0051632901673675

Epoch: 6| Step: 2
Training loss: 1.9339044094085693
Validation loss: 1.9838959734926942

Epoch: 6| Step: 3
Training loss: 2.720633029937744
Validation loss: 2.0132292162987495

Epoch: 6| Step: 4
Training loss: 2.5284900665283203
Validation loss: 1.9977707350125877

Epoch: 6| Step: 5
Training loss: 1.5123802423477173
Validation loss: 2.0349922231448594

Epoch: 6| Step: 6
Training loss: 1.690399408340454
Validation loss: 2.029810664474323

Epoch: 6| Step: 7
Training loss: 2.1878392696380615
Validation loss: 2.0076913474708475

Epoch: 6| Step: 8
Training loss: 1.7913954257965088
Validation loss: 2.0477528084990797

Epoch: 6| Step: 9
Training loss: 2.5830655097961426
Validation loss: 2.0216301384792534

Epoch: 6| Step: 10
Training loss: 1.8267927169799805
Validation loss: 2.03328844552399

Epoch: 6| Step: 11
Training loss: 1.5279088020324707
Validation loss: 2.019480110496603

Epoch: 6| Step: 12
Training loss: 1.3775341510772705
Validation loss: 2.035514332914865

Epoch: 6| Step: 13
Training loss: 2.4512808322906494
Validation loss: 1.9976617713128366

Epoch: 184| Step: 0
Training loss: 2.2402291297912598
Validation loss: 1.9832321392592562

Epoch: 6| Step: 1
Training loss: 2.177159309387207
Validation loss: 2.0424813301332536

Epoch: 6| Step: 2
Training loss: 1.929248571395874
Validation loss: 2.0087840095643075

Epoch: 6| Step: 3
Training loss: 1.7844206094741821
Validation loss: 2.00270813767628

Epoch: 6| Step: 4
Training loss: 2.9990310668945312
Validation loss: 2.0048017091648553

Epoch: 6| Step: 5
Training loss: 1.2220723628997803
Validation loss: 2.0211199739927888

Epoch: 6| Step: 6
Training loss: 1.126654863357544
Validation loss: 2.004171468878305

Epoch: 6| Step: 7
Training loss: 2.228341579437256
Validation loss: 1.9904521639629076

Epoch: 6| Step: 8
Training loss: 1.9812787771224976
Validation loss: 2.014795487926852

Epoch: 6| Step: 9
Training loss: 2.6690235137939453
Validation loss: 2.005481122642435

Epoch: 6| Step: 10
Training loss: 2.3205504417419434
Validation loss: 2.005567317367882

Epoch: 6| Step: 11
Training loss: 1.9039885997772217
Validation loss: 2.006067998947636

Epoch: 6| Step: 12
Training loss: 1.4429867267608643
Validation loss: 2.0451659079520934

Epoch: 6| Step: 13
Training loss: 2.0600826740264893
Validation loss: 1.9844529116025535

Epoch: 185| Step: 0
Training loss: 2.3769187927246094
Validation loss: 2.0214325920228036

Epoch: 6| Step: 1
Training loss: 2.727400541305542
Validation loss: 2.0251318998234247

Epoch: 6| Step: 2
Training loss: 1.924452543258667
Validation loss: 2.004302724715202

Epoch: 6| Step: 3
Training loss: 2.5065817832946777
Validation loss: 2.0243016353217502

Epoch: 6| Step: 4
Training loss: 2.293729782104492
Validation loss: 1.9995644912924817

Epoch: 6| Step: 5
Training loss: 1.1719509363174438
Validation loss: 2.0035212501402824

Epoch: 6| Step: 6
Training loss: 2.0890235900878906
Validation loss: 2.0166427602050123

Epoch: 6| Step: 7
Training loss: 1.7383687496185303
Validation loss: 1.9999989771073865

Epoch: 6| Step: 8
Training loss: 1.7934117317199707
Validation loss: 2.002779342794931

Epoch: 6| Step: 9
Training loss: 1.968968152999878
Validation loss: 2.016552584145659

Epoch: 6| Step: 10
Training loss: 1.7740715742111206
Validation loss: 2.020633146327029

Epoch: 6| Step: 11
Training loss: 1.7332921028137207
Validation loss: 2.011180805903609

Epoch: 6| Step: 12
Training loss: 1.7358027696609497
Validation loss: 1.9846741589166785

Epoch: 6| Step: 13
Training loss: 2.7891974449157715
Validation loss: 1.995123819638324

Epoch: 186| Step: 0
Training loss: 3.0260000228881836
Validation loss: 1.9886171740870322

Epoch: 6| Step: 1
Training loss: 2.0877485275268555
Validation loss: 2.0005090134118193

Epoch: 6| Step: 2
Training loss: 1.4080543518066406
Validation loss: 2.002515369845975

Epoch: 6| Step: 3
Training loss: 2.3604931831359863
Validation loss: 2.0132530709748626

Epoch: 6| Step: 4
Training loss: 1.4348077774047852
Validation loss: 2.0127859500146683

Epoch: 6| Step: 5
Training loss: 1.9410316944122314
Validation loss: 2.017949979792359

Epoch: 6| Step: 6
Training loss: 2.5614912509918213
Validation loss: 2.03296979524756

Epoch: 6| Step: 7
Training loss: 1.0769975185394287
Validation loss: 2.035663191990186

Epoch: 6| Step: 8
Training loss: 2.723984956741333
Validation loss: 2.0385277027724893

Epoch: 6| Step: 9
Training loss: 1.6752097606658936
Validation loss: 2.0512121082634054

Epoch: 6| Step: 10
Training loss: 1.6358811855316162
Validation loss: 2.0346182597580778

Epoch: 6| Step: 11
Training loss: 1.8361774682998657
Validation loss: 2.024057448551219

Epoch: 6| Step: 12
Training loss: 2.15578031539917
Validation loss: 2.029583259295392

Epoch: 6| Step: 13
Training loss: 2.3888301849365234
Validation loss: 2.0300564471111504

Epoch: 187| Step: 0
Training loss: 1.7692235708236694
Validation loss: 2.0287878128790084

Epoch: 6| Step: 1
Training loss: 2.1511874198913574
Validation loss: 1.9980128093432354

Epoch: 6| Step: 2
Training loss: 2.5664055347442627
Validation loss: 2.01428807679043

Epoch: 6| Step: 3
Training loss: 1.9041502475738525
Validation loss: 1.9901451346694783

Epoch: 6| Step: 4
Training loss: 1.9781715869903564
Validation loss: 1.9924202965151878

Epoch: 6| Step: 5
Training loss: 2.4075779914855957
Validation loss: 2.0075207269319923

Epoch: 6| Step: 6
Training loss: 2.3018250465393066
Validation loss: 1.985031170229758

Epoch: 6| Step: 7
Training loss: 1.5994070768356323
Validation loss: 1.9808192330022012

Epoch: 6| Step: 8
Training loss: 1.2829546928405762
Validation loss: 1.968075825322059

Epoch: 6| Step: 9
Training loss: 2.2805349826812744
Validation loss: 1.9970542820551063

Epoch: 6| Step: 10
Training loss: 2.463435649871826
Validation loss: 2.000647429497011

Epoch: 6| Step: 11
Training loss: 1.5303809642791748
Validation loss: 2.00645625334914

Epoch: 6| Step: 12
Training loss: 1.772582769393921
Validation loss: 1.9953177385432745

Epoch: 6| Step: 13
Training loss: 2.2441062927246094
Validation loss: 2.002298608902962

Epoch: 188| Step: 0
Training loss: 1.993660807609558
Validation loss: 2.0112826029459634

Epoch: 6| Step: 1
Training loss: 1.6590826511383057
Validation loss: 1.9934739758891444

Epoch: 6| Step: 2
Training loss: 1.6601817607879639
Validation loss: 1.9802245029839136

Epoch: 6| Step: 3
Training loss: 1.83309006690979
Validation loss: 2.000109400800479

Epoch: 6| Step: 4
Training loss: 1.7627251148223877
Validation loss: 2.000883362626517

Epoch: 6| Step: 5
Training loss: 1.8334147930145264
Validation loss: 1.9921717156646073

Epoch: 6| Step: 6
Training loss: 2.2957046031951904
Validation loss: 1.998562027049321

Epoch: 6| Step: 7
Training loss: 1.958470344543457
Validation loss: 1.9674349497723322

Epoch: 6| Step: 8
Training loss: 2.570456027984619
Validation loss: 1.9918108832451604

Epoch: 6| Step: 9
Training loss: 2.5793209075927734
Validation loss: 2.021302148859988

Epoch: 6| Step: 10
Training loss: 1.6870982646942139
Validation loss: 1.9980049646028908

Epoch: 6| Step: 11
Training loss: 1.6725761890411377
Validation loss: 2.047731125226585

Epoch: 6| Step: 12
Training loss: 2.554640769958496
Validation loss: 1.9993212992145168

Epoch: 6| Step: 13
Training loss: 2.3704617023468018
Validation loss: 1.9707069114972187

Epoch: 189| Step: 0
Training loss: 2.152843475341797
Validation loss: 1.9999832773721347

Epoch: 6| Step: 1
Training loss: 1.8812847137451172
Validation loss: 1.9635847512111868

Epoch: 6| Step: 2
Training loss: 1.8651351928710938
Validation loss: 1.9826640108580231

Epoch: 6| Step: 3
Training loss: 1.7563230991363525
Validation loss: 1.992633047924247

Epoch: 6| Step: 4
Training loss: 2.2746787071228027
Validation loss: 1.9963011921093028

Epoch: 6| Step: 5
Training loss: 1.3016027212142944
Validation loss: 2.0312948714020433

Epoch: 6| Step: 6
Training loss: 2.216752529144287
Validation loss: 1.9940867834193732

Epoch: 6| Step: 7
Training loss: 2.3285021781921387
Validation loss: 2.0095664301226215

Epoch: 6| Step: 8
Training loss: 2.0801095962524414
Validation loss: 2.0103559109472458

Epoch: 6| Step: 9
Training loss: 2.2369601726531982
Validation loss: 2.006179763424781

Epoch: 6| Step: 10
Training loss: 2.058926820755005
Validation loss: 2.0086841749888595

Epoch: 6| Step: 11
Training loss: 2.179783821105957
Validation loss: 2.028348981693227

Epoch: 6| Step: 12
Training loss: 1.8345972299575806
Validation loss: 2.0260244133651897

Epoch: 6| Step: 13
Training loss: 1.6052416563034058
Validation loss: 2.0311189928362445

Epoch: 190| Step: 0
Training loss: 1.9633723497390747
Validation loss: 2.021078460959978

Epoch: 6| Step: 1
Training loss: 1.6146434545516968
Validation loss: 2.014636719098655

Epoch: 6| Step: 2
Training loss: 2.304713726043701
Validation loss: 2.044076914428383

Epoch: 6| Step: 3
Training loss: 2.3272433280944824
Validation loss: 2.0386479875092864

Epoch: 6| Step: 4
Training loss: 2.4416353702545166
Validation loss: 1.994197327603576

Epoch: 6| Step: 5
Training loss: 1.5281288623809814
Validation loss: 2.018068130298327

Epoch: 6| Step: 6
Training loss: 1.5831360816955566
Validation loss: 2.0243788790959183

Epoch: 6| Step: 7
Training loss: 2.7892656326293945
Validation loss: 1.9982262875444146

Epoch: 6| Step: 8
Training loss: 1.7366142272949219
Validation loss: 2.0222710845290974

Epoch: 6| Step: 9
Training loss: 2.196500778198242
Validation loss: 2.007998438291652

Epoch: 6| Step: 10
Training loss: 1.898472785949707
Validation loss: 2.006061230936358

Epoch: 6| Step: 11
Training loss: 2.335676431655884
Validation loss: 2.02107641132929

Epoch: 6| Step: 12
Training loss: 1.6803135871887207
Validation loss: 2.037371649537035

Epoch: 6| Step: 13
Training loss: 1.6797597408294678
Validation loss: 2.035764645504695

Epoch: 191| Step: 0
Training loss: 2.3918614387512207
Validation loss: 1.9944502486977527

Epoch: 6| Step: 1
Training loss: 2.3381102085113525
Validation loss: 2.0105331097879717

Epoch: 6| Step: 2
Training loss: 2.198024272918701
Validation loss: 2.023107108249459

Epoch: 6| Step: 3
Training loss: 2.6462185382843018
Validation loss: 2.0185845910861926

Epoch: 6| Step: 4
Training loss: 1.6967785358428955
Validation loss: 2.0147813699578725

Epoch: 6| Step: 5
Training loss: 2.126521348953247
Validation loss: 2.02316975849931

Epoch: 6| Step: 6
Training loss: 2.087394952774048
Validation loss: 2.0495295191323883

Epoch: 6| Step: 7
Training loss: 1.5989149808883667
Validation loss: 2.036001087516867

Epoch: 6| Step: 8
Training loss: 1.6635472774505615
Validation loss: 2.050516761759276

Epoch: 6| Step: 9
Training loss: 1.5289647579193115
Validation loss: 1.9961792128060454

Epoch: 6| Step: 10
Training loss: 2.0868992805480957
Validation loss: 1.9955311488079768

Epoch: 6| Step: 11
Training loss: 2.0882010459899902
Validation loss: 2.0081091901307464

Epoch: 6| Step: 12
Training loss: 1.8996949195861816
Validation loss: 2.031028163048529

Epoch: 6| Step: 13
Training loss: 1.5658713579177856
Validation loss: 2.017595652611025

Epoch: 192| Step: 0
Training loss: 1.899530053138733
Validation loss: 2.0051296603295112

Epoch: 6| Step: 1
Training loss: 1.907836675643921
Validation loss: 2.011196158265555

Epoch: 6| Step: 2
Training loss: 2.5250725746154785
Validation loss: 2.0177639351096204

Epoch: 6| Step: 3
Training loss: 1.9798692464828491
Validation loss: 2.041554104897284

Epoch: 6| Step: 4
Training loss: 2.1435983180999756
Validation loss: 2.014766280369092

Epoch: 6| Step: 5
Training loss: 2.332096576690674
Validation loss: 2.0098792737530125

Epoch: 6| Step: 6
Training loss: 2.036184787750244
Validation loss: 2.0364999207117225

Epoch: 6| Step: 7
Training loss: 1.8598424196243286
Validation loss: 2.0063487483609106

Epoch: 6| Step: 8
Training loss: 2.004380702972412
Validation loss: 2.0108830210983113

Epoch: 6| Step: 9
Training loss: 2.036978244781494
Validation loss: 2.0142847825122137

Epoch: 6| Step: 10
Training loss: 2.1448917388916016
Validation loss: 2.020688086427668

Epoch: 6| Step: 11
Training loss: 2.075636386871338
Validation loss: 2.019006908580821

Epoch: 6| Step: 12
Training loss: 1.64882493019104
Validation loss: 1.9899365158491238

Epoch: 6| Step: 13
Training loss: 1.0432813167572021
Validation loss: 1.998796405330781

Epoch: 193| Step: 0
Training loss: 1.7297554016113281
Validation loss: 1.9607545393769459

Epoch: 6| Step: 1
Training loss: 2.3539023399353027
Validation loss: 2.008648257101736

Epoch: 6| Step: 2
Training loss: 1.4925658702850342
Validation loss: 2.0384374997949086

Epoch: 6| Step: 3
Training loss: 1.0831499099731445
Validation loss: 2.0457328019603604

Epoch: 6| Step: 4
Training loss: 2.1921768188476562
Validation loss: 2.0135215367040327

Epoch: 6| Step: 5
Training loss: 1.910618782043457
Validation loss: 1.9886525625823646

Epoch: 6| Step: 6
Training loss: 1.9214937686920166
Validation loss: 2.0020858472393406

Epoch: 6| Step: 7
Training loss: 1.6081056594848633
Validation loss: 2.041356122621926

Epoch: 6| Step: 8
Training loss: 3.0356812477111816
Validation loss: 1.9876079085052654

Epoch: 6| Step: 9
Training loss: 2.5478127002716064
Validation loss: 2.02359571508182

Epoch: 6| Step: 10
Training loss: 2.485875368118286
Validation loss: 2.0013172472676923

Epoch: 6| Step: 11
Training loss: 1.887183427810669
Validation loss: 2.0239074217375888

Epoch: 6| Step: 12
Training loss: 1.7576189041137695
Validation loss: 2.027435965435479

Epoch: 6| Step: 13
Training loss: 1.7933415174484253
Validation loss: 2.0399503374612458

Epoch: 194| Step: 0
Training loss: 2.1195831298828125
Validation loss: 2.020561602807814

Epoch: 6| Step: 1
Training loss: 2.3639161586761475
Validation loss: 2.0279143369326027

Epoch: 6| Step: 2
Training loss: 2.3302886486053467
Validation loss: 2.032159545088327

Epoch: 6| Step: 3
Training loss: 2.035727024078369
Validation loss: 2.031577306409036

Epoch: 6| Step: 4
Training loss: 2.3284735679626465
Validation loss: 2.014203034421449

Epoch: 6| Step: 5
Training loss: 1.6319061517715454
Validation loss: 2.0252341826756797

Epoch: 6| Step: 6
Training loss: 1.785330891609192
Validation loss: 1.9898028604445919

Epoch: 6| Step: 7
Training loss: 1.8949460983276367
Validation loss: 2.0108271542415825

Epoch: 6| Step: 8
Training loss: 1.8623069524765015
Validation loss: 2.001389636788317

Epoch: 6| Step: 9
Training loss: 2.4644980430603027
Validation loss: 2.023863669364683

Epoch: 6| Step: 10
Training loss: 1.1672422885894775
Validation loss: 2.0156627239719516

Epoch: 6| Step: 11
Training loss: 1.8439980745315552
Validation loss: 1.9945780000379008

Epoch: 6| Step: 12
Training loss: 2.2969279289245605
Validation loss: 2.030956663111205

Epoch: 6| Step: 13
Training loss: 1.7578492164611816
Validation loss: 2.006185749525665

Epoch: 195| Step: 0
Training loss: 2.8662338256835938
Validation loss: 2.0236222128714285

Epoch: 6| Step: 1
Training loss: 1.6468086242675781
Validation loss: 1.9993007721439484

Epoch: 6| Step: 2
Training loss: 1.8454344272613525
Validation loss: 1.9944135758184618

Epoch: 6| Step: 3
Training loss: 2.0636820793151855
Validation loss: 2.000914649296832

Epoch: 6| Step: 4
Training loss: 2.1474761962890625
Validation loss: 1.976046698067778

Epoch: 6| Step: 5
Training loss: 1.8817687034606934
Validation loss: 2.00189471244812

Epoch: 6| Step: 6
Training loss: 1.2349653244018555
Validation loss: 1.9874300238906697

Epoch: 6| Step: 7
Training loss: 1.987412452697754
Validation loss: 2.0151006355080554

Epoch: 6| Step: 8
Training loss: 1.6516101360321045
Validation loss: 2.032494721874114

Epoch: 6| Step: 9
Training loss: 2.156989097595215
Validation loss: 2.023603343194531

Epoch: 6| Step: 10
Training loss: 1.991635799407959
Validation loss: 2.000015419016602

Epoch: 6| Step: 11
Training loss: 2.000288724899292
Validation loss: 1.9887601406343522

Epoch: 6| Step: 12
Training loss: 2.30519700050354
Validation loss: 2.0031930092842347

Epoch: 6| Step: 13
Training loss: 2.147627830505371
Validation loss: 1.9999063502075851

Epoch: 196| Step: 0
Training loss: 2.369428873062134
Validation loss: 2.0136794095398276

Epoch: 6| Step: 1
Training loss: 2.1900978088378906
Validation loss: 1.996863377991543

Epoch: 6| Step: 2
Training loss: 1.5733102560043335
Validation loss: 2.0485975332157587

Epoch: 6| Step: 3
Training loss: 1.2156977653503418
Validation loss: 2.0038009023153656

Epoch: 6| Step: 4
Training loss: 2.2061734199523926
Validation loss: 2.012171467145284

Epoch: 6| Step: 5
Training loss: 1.9787756204605103
Validation loss: 2.018615298373725

Epoch: 6| Step: 6
Training loss: 1.9480271339416504
Validation loss: 2.010750397559135

Epoch: 6| Step: 7
Training loss: 2.1399054527282715
Validation loss: 2.0284663823343094

Epoch: 6| Step: 8
Training loss: 2.4814186096191406
Validation loss: 1.997445055233535

Epoch: 6| Step: 9
Training loss: 1.8198041915893555
Validation loss: 2.0429255847007997

Epoch: 6| Step: 10
Training loss: 2.1547658443450928
Validation loss: 2.035191810259255

Epoch: 6| Step: 11
Training loss: 1.781585931777954
Validation loss: 2.0085035895788543

Epoch: 6| Step: 12
Training loss: 2.1467418670654297
Validation loss: 2.0381420940481205

Epoch: 6| Step: 13
Training loss: 1.556182861328125
Validation loss: 2.026357521292984

Epoch: 197| Step: 0
Training loss: 2.007821559906006
Validation loss: 2.034599102953429

Epoch: 6| Step: 1
Training loss: 1.8038983345031738
Validation loss: 2.042383599024947

Epoch: 6| Step: 2
Training loss: 2.0048158168792725
Validation loss: 2.032948998994725

Epoch: 6| Step: 3
Training loss: 1.313805341720581
Validation loss: 2.027863178201901

Epoch: 6| Step: 4
Training loss: 2.376685619354248
Validation loss: 2.014994901995505

Epoch: 6| Step: 5
Training loss: 1.1379222869873047
Validation loss: 1.9955271700377106

Epoch: 6| Step: 6
Training loss: 2.3549938201904297
Validation loss: 2.023583468570504

Epoch: 6| Step: 7
Training loss: 2.1701202392578125
Validation loss: 2.048570731634735

Epoch: 6| Step: 8
Training loss: 2.292330265045166
Validation loss: 2.0031447154219433

Epoch: 6| Step: 9
Training loss: 2.1430230140686035
Validation loss: 2.019909945867395

Epoch: 6| Step: 10
Training loss: 2.087139129638672
Validation loss: 2.003123878150858

Epoch: 6| Step: 11
Training loss: 2.0125503540039062
Validation loss: 2.015303345136745

Epoch: 6| Step: 12
Training loss: 2.4517428874969482
Validation loss: 2.018281726426976

Epoch: 6| Step: 13
Training loss: 2.058145046234131
Validation loss: 2.0287050918866227

Epoch: 198| Step: 0
Training loss: 1.9890847206115723
Validation loss: 2.0112579637958157

Epoch: 6| Step: 1
Training loss: 1.972052812576294
Validation loss: 2.0187163686239593

Epoch: 6| Step: 2
Training loss: 1.7551238536834717
Validation loss: 1.9868913683840024

Epoch: 6| Step: 3
Training loss: 1.0919349193572998
Validation loss: 1.9610835275342386

Epoch: 6| Step: 4
Training loss: 1.9325987100601196
Validation loss: 2.005653947912237

Epoch: 6| Step: 5
Training loss: 1.936975121498108
Validation loss: 2.0071097548289965

Epoch: 6| Step: 6
Training loss: 2.2256040573120117
Validation loss: 2.0323066993426253

Epoch: 6| Step: 7
Training loss: 2.388340711593628
Validation loss: 1.9877741157367665

Epoch: 6| Step: 8
Training loss: 2.2758851051330566
Validation loss: 2.0283257243453816

Epoch: 6| Step: 9
Training loss: 3.076993942260742
Validation loss: 1.9690551142538748

Epoch: 6| Step: 10
Training loss: 2.223775625228882
Validation loss: 2.0037362575531006

Epoch: 6| Step: 11
Training loss: 1.6155122518539429
Validation loss: 2.009396517148582

Epoch: 6| Step: 12
Training loss: 1.4791043996810913
Validation loss: 2.001614814163536

Epoch: 6| Step: 13
Training loss: 1.763074278831482
Validation loss: 2.0024337435281403

Epoch: 199| Step: 0
Training loss: 1.6247655153274536
Validation loss: 1.978111251708

Epoch: 6| Step: 1
Training loss: 2.7454872131347656
Validation loss: 2.0023161390776276

Epoch: 6| Step: 2
Training loss: 2.2489829063415527
Validation loss: 2.0092102071290374

Epoch: 6| Step: 3
Training loss: 1.6471049785614014
Validation loss: 2.025414638621833

Epoch: 6| Step: 4
Training loss: 1.7391326427459717
Validation loss: 2.010249868515999

Epoch: 6| Step: 5
Training loss: 2.1555519104003906
Validation loss: 1.988216471928422

Epoch: 6| Step: 6
Training loss: 1.2539820671081543
Validation loss: 2.0034268492011615

Epoch: 6| Step: 7
Training loss: 2.0969395637512207
Validation loss: 2.0127060797906693

Epoch: 6| Step: 8
Training loss: 2.286008358001709
Validation loss: 2.0139302079395582

Epoch: 6| Step: 9
Training loss: 2.040731906890869
Validation loss: 2.009637241722435

Epoch: 6| Step: 10
Training loss: 2.240128517150879
Validation loss: 1.9888896301228514

Epoch: 6| Step: 11
Training loss: 2.193678379058838
Validation loss: 1.995377367542636

Epoch: 6| Step: 12
Training loss: 1.8673927783966064
Validation loss: 1.9836554091463807

Epoch: 6| Step: 13
Training loss: 1.381707787513733
Validation loss: 2.0115439404723463

Epoch: 200| Step: 0
Training loss: 2.1665730476379395
Validation loss: 2.035158436785462

Epoch: 6| Step: 1
Training loss: 2.5499424934387207
Validation loss: 1.9946556988582815

Epoch: 6| Step: 2
Training loss: 1.0798213481903076
Validation loss: 2.014062859678781

Epoch: 6| Step: 3
Training loss: 2.262179374694824
Validation loss: 1.9897648698540145

Epoch: 6| Step: 4
Training loss: 2.0723559856414795
Validation loss: 2.004528163581766

Epoch: 6| Step: 5
Training loss: 2.594442367553711
Validation loss: 2.0184525853844097

Epoch: 6| Step: 6
Training loss: 1.8088421821594238
Validation loss: 2.0063856135132494

Epoch: 6| Step: 7
Training loss: 1.3617537021636963
Validation loss: 2.00499048027941

Epoch: 6| Step: 8
Training loss: 1.0943515300750732
Validation loss: 1.986354733026156

Epoch: 6| Step: 9
Training loss: 2.67760968208313
Validation loss: 1.9820922446507279

Epoch: 6| Step: 10
Training loss: 1.811181902885437
Validation loss: 2.0170711445552048

Epoch: 6| Step: 11
Training loss: 2.0008864402770996
Validation loss: 2.0142553647359214

Epoch: 6| Step: 12
Training loss: 2.641869306564331
Validation loss: 1.9989863544382074

Epoch: 6| Step: 13
Training loss: 1.430104374885559
Validation loss: 2.0000303535051245

Epoch: 201| Step: 0
Training loss: 2.2182295322418213
Validation loss: 2.008548587881109

Epoch: 6| Step: 1
Training loss: 2.7184743881225586
Validation loss: 2.011163914075462

Epoch: 6| Step: 2
Training loss: 1.7001309394836426
Validation loss: 2.0092559399143344

Epoch: 6| Step: 3
Training loss: 2.5399632453918457
Validation loss: 1.9857829501551967

Epoch: 6| Step: 4
Training loss: 1.8044757843017578
Validation loss: 1.9894989587927376

Epoch: 6| Step: 5
Training loss: 1.2374507188796997
Validation loss: 1.9640982830396263

Epoch: 6| Step: 6
Training loss: 2.082284927368164
Validation loss: 1.995473527139233

Epoch: 6| Step: 7
Training loss: 2.2451796531677246
Validation loss: 2.0017302702831965

Epoch: 6| Step: 8
Training loss: 1.7589607238769531
Validation loss: 1.9765886299071773

Epoch: 6| Step: 9
Training loss: 1.826321005821228
Validation loss: 2.008777391526007

Epoch: 6| Step: 10
Training loss: 2.3392395973205566
Validation loss: 2.012324528027606

Epoch: 6| Step: 11
Training loss: 2.3417630195617676
Validation loss: 2.0192141250897477

Epoch: 6| Step: 12
Training loss: 1.0870853662490845
Validation loss: 1.9972053099704046

Epoch: 6| Step: 13
Training loss: 2.0347821712493896
Validation loss: 1.9943851655529392

Epoch: 202| Step: 0
Training loss: 1.50227952003479
Validation loss: 2.00945347098894

Epoch: 6| Step: 1
Training loss: 1.842289924621582
Validation loss: 2.0104619110784223

Epoch: 6| Step: 2
Training loss: 1.7114683389663696
Validation loss: 2.0162138656903337

Epoch: 6| Step: 3
Training loss: 1.8879146575927734
Validation loss: 2.0114582661659486

Epoch: 6| Step: 4
Training loss: 2.075617551803589
Validation loss: 2.021641118552095

Epoch: 6| Step: 5
Training loss: 2.375821590423584
Validation loss: 2.0043955285062074

Epoch: 6| Step: 6
Training loss: 2.0270581245422363
Validation loss: 2.008706590180756

Epoch: 6| Step: 7
Training loss: 1.8512929677963257
Validation loss: 2.0156041088924614

Epoch: 6| Step: 8
Training loss: 2.757777690887451
Validation loss: 2.016187503773679

Epoch: 6| Step: 9
Training loss: 1.8185409307479858
Validation loss: 1.9815520522414998

Epoch: 6| Step: 10
Training loss: 1.9482817649841309
Validation loss: 2.013853075683758

Epoch: 6| Step: 11
Training loss: 2.1192336082458496
Validation loss: 2.0056242968446467

Epoch: 6| Step: 12
Training loss: 2.1457979679107666
Validation loss: 2.009318454291231

Epoch: 6| Step: 13
Training loss: 1.7314141988754272
Validation loss: 2.0118805695605535

Epoch: 203| Step: 0
Training loss: 1.4129061698913574
Validation loss: 2.0307128070503153

Epoch: 6| Step: 1
Training loss: 2.023172378540039
Validation loss: 2.0481429176945842

Epoch: 6| Step: 2
Training loss: 1.9281364679336548
Validation loss: 2.01380415116587

Epoch: 6| Step: 3
Training loss: 2.556426525115967
Validation loss: 2.0236089985857726

Epoch: 6| Step: 4
Training loss: 2.1226587295532227
Validation loss: 2.039867885651127

Epoch: 6| Step: 5
Training loss: 2.4157941341400146
Validation loss: 2.0039733430390716

Epoch: 6| Step: 6
Training loss: 1.8478026390075684
Validation loss: 2.0341277507043656

Epoch: 6| Step: 7
Training loss: 1.8864772319793701
Validation loss: 2.0224721354822957

Epoch: 6| Step: 8
Training loss: 2.174837350845337
Validation loss: 2.0557583993481052

Epoch: 6| Step: 9
Training loss: 1.6788151264190674
Validation loss: 2.010477017330867

Epoch: 6| Step: 10
Training loss: 1.9499051570892334
Validation loss: 2.0318163056527414

Epoch: 6| Step: 11
Training loss: 1.8801442384719849
Validation loss: 2.007859806860647

Epoch: 6| Step: 12
Training loss: 2.221414566040039
Validation loss: 2.0143516832782375

Epoch: 6| Step: 13
Training loss: 1.480309009552002
Validation loss: 1.9975897035291117

Epoch: 204| Step: 0
Training loss: 2.106645107269287
Validation loss: 2.0128405965784544

Epoch: 6| Step: 1
Training loss: 2.64329195022583
Validation loss: 2.008630465435725

Epoch: 6| Step: 2
Training loss: 2.7791740894317627
Validation loss: 1.9896629048931984

Epoch: 6| Step: 3
Training loss: 1.7948659658432007
Validation loss: 2.0078529952674784

Epoch: 6| Step: 4
Training loss: 1.729661464691162
Validation loss: 2.003869874503023

Epoch: 6| Step: 5
Training loss: 2.2028210163116455
Validation loss: 2.0338916778564453

Epoch: 6| Step: 6
Training loss: 2.480057716369629
Validation loss: 1.9963565898197952

Epoch: 6| Step: 7
Training loss: 0.7931188344955444
Validation loss: 1.9892796136999642

Epoch: 6| Step: 8
Training loss: 1.7751290798187256
Validation loss: 2.003937026505829

Epoch: 6| Step: 9
Training loss: 1.5243632793426514
Validation loss: 2.0297988255818686

Epoch: 6| Step: 10
Training loss: 1.54020357131958
Validation loss: 1.9993015745634675

Epoch: 6| Step: 11
Training loss: 2.0936660766601562
Validation loss: 2.005131334386846

Epoch: 6| Step: 12
Training loss: 2.1045947074890137
Validation loss: 2.0228735144420336

Epoch: 6| Step: 13
Training loss: 2.2545909881591797
Validation loss: 1.9848356631494337

Epoch: 205| Step: 0
Training loss: 1.3576879501342773
Validation loss: 1.9886040354287753

Epoch: 6| Step: 1
Training loss: 2.2548117637634277
Validation loss: 1.987574359422089

Epoch: 6| Step: 2
Training loss: 1.7784420251846313
Validation loss: 1.999538178084999

Epoch: 6| Step: 3
Training loss: 1.9312379360198975
Validation loss: 1.995517179530154

Epoch: 6| Step: 4
Training loss: 2.183135509490967
Validation loss: 2.0286918583736626

Epoch: 6| Step: 5
Training loss: 2.5088717937469482
Validation loss: 1.9766490690169796

Epoch: 6| Step: 6
Training loss: 2.8033175468444824
Validation loss: 1.9906301293321835

Epoch: 6| Step: 7
Training loss: 1.4104139804840088
Validation loss: 1.9889552772686045

Epoch: 6| Step: 8
Training loss: 2.6820757389068604
Validation loss: 1.992272905124131

Epoch: 6| Step: 9
Training loss: 1.8310049772262573
Validation loss: 1.9873901336423812

Epoch: 6| Step: 10
Training loss: 2.0570507049560547
Validation loss: 1.9993948269915838

Epoch: 6| Step: 11
Training loss: 1.2796616554260254
Validation loss: 1.983008236013433

Epoch: 6| Step: 12
Training loss: 1.9476513862609863
Validation loss: 2.0076898772229432

Epoch: 6| Step: 13
Training loss: 1.286035418510437
Validation loss: 1.9888914990168747

Epoch: 206| Step: 0
Training loss: 2.287108898162842
Validation loss: 2.0005189705920476

Epoch: 6| Step: 1
Training loss: 2.223630428314209
Validation loss: 2.002788048918529

Epoch: 6| Step: 2
Training loss: 2.0781099796295166
Validation loss: 2.031913370214483

Epoch: 6| Step: 3
Training loss: 1.6418182849884033
Validation loss: 2.0359394934869584

Epoch: 6| Step: 4
Training loss: 3.0573031902313232
Validation loss: 2.0190094722214567

Epoch: 6| Step: 5
Training loss: 1.3708266019821167
Validation loss: 2.045855345264558

Epoch: 6| Step: 6
Training loss: 1.950540542602539
Validation loss: 2.0173232555389404

Epoch: 6| Step: 7
Training loss: 1.2473781108856201
Validation loss: 2.0146093932531213

Epoch: 6| Step: 8
Training loss: 2.210235595703125
Validation loss: 2.057086031924012

Epoch: 6| Step: 9
Training loss: 2.087956428527832
Validation loss: 2.00137230401398

Epoch: 6| Step: 10
Training loss: 2.0432004928588867
Validation loss: 2.0247331857681274

Epoch: 6| Step: 11
Training loss: 2.2848715782165527
Validation loss: 2.015937976939704

Epoch: 6| Step: 12
Training loss: 2.080386161804199
Validation loss: 2.0074450585149948

Epoch: 6| Step: 13
Training loss: 1.1787675619125366
Validation loss: 1.9787430506880566

Epoch: 207| Step: 0
Training loss: 1.9782893657684326
Validation loss: 2.024431244019539

Epoch: 6| Step: 1
Training loss: 1.0734314918518066
Validation loss: 2.026964364513274

Epoch: 6| Step: 2
Training loss: 1.8306180238723755
Validation loss: 2.033785496988604

Epoch: 6| Step: 3
Training loss: 2.305684804916382
Validation loss: 2.025277078792613

Epoch: 6| Step: 4
Training loss: 2.166584014892578
Validation loss: 1.999827831022201

Epoch: 6| Step: 5
Training loss: 2.122647762298584
Validation loss: 2.0005648571957826

Epoch: 6| Step: 6
Training loss: 2.9386439323425293
Validation loss: 1.9859139983372023

Epoch: 6| Step: 7
Training loss: 2.2372026443481445
Validation loss: 2.037325462987346

Epoch: 6| Step: 8
Training loss: 1.7388792037963867
Validation loss: 2.018974906654768

Epoch: 6| Step: 9
Training loss: 1.8053690195083618
Validation loss: 2.02826629787363

Epoch: 6| Step: 10
Training loss: 1.6294548511505127
Validation loss: 2.020289715900216

Epoch: 6| Step: 11
Training loss: 2.035611629486084
Validation loss: 2.023345430692037

Epoch: 6| Step: 12
Training loss: 1.5991873741149902
Validation loss: 2.012066553997737

Epoch: 6| Step: 13
Training loss: 1.6145594120025635
Validation loss: 2.0411637085740284

Epoch: 208| Step: 0
Training loss: 2.884453058242798
Validation loss: 2.0251159770514375

Epoch: 6| Step: 1
Training loss: 1.7928380966186523
Validation loss: 2.0118686742680048

Epoch: 6| Step: 2
Training loss: 1.7235584259033203
Validation loss: 2.012947428611017

Epoch: 6| Step: 3
Training loss: 2.1766018867492676
Validation loss: 2.010004174324774

Epoch: 6| Step: 4
Training loss: 1.951338291168213
Validation loss: 1.966148902011174

Epoch: 6| Step: 5
Training loss: 2.1971921920776367
Validation loss: 2.0342797617758475

Epoch: 6| Step: 6
Training loss: 1.7415357828140259
Validation loss: 2.007490102962781

Epoch: 6| Step: 7
Training loss: 2.3605880737304688
Validation loss: 1.9723547427884993

Epoch: 6| Step: 8
Training loss: 2.2279891967773438
Validation loss: 2.0215539957887385

Epoch: 6| Step: 9
Training loss: 1.792382836341858
Validation loss: 1.9919429825198265

Epoch: 6| Step: 10
Training loss: 1.3552929162979126
Validation loss: 1.9972483573421356

Epoch: 6| Step: 11
Training loss: 1.334301233291626
Validation loss: 2.0167316775168143

Epoch: 6| Step: 12
Training loss: 2.0697784423828125
Validation loss: 1.9937058494937034

Epoch: 6| Step: 13
Training loss: 2.0984890460968018
Validation loss: 1.999537298756261

Epoch: 209| Step: 0
Training loss: 1.6988017559051514
Validation loss: 2.0154354123659033

Epoch: 6| Step: 1
Training loss: 1.735675573348999
Validation loss: 2.0157098103595037

Epoch: 6| Step: 2
Training loss: 2.2651379108428955
Validation loss: 2.0057176979639197

Epoch: 6| Step: 3
Training loss: 2.6181249618530273
Validation loss: 2.01718823371395

Epoch: 6| Step: 4
Training loss: 2.1923749446868896
Validation loss: 2.0065439721589446

Epoch: 6| Step: 5
Training loss: 1.8188514709472656
Validation loss: 2.00775937111147

Epoch: 6| Step: 6
Training loss: 1.7516372203826904
Validation loss: 2.0040719534761164

Epoch: 6| Step: 7
Training loss: 1.7234721183776855
Validation loss: 2.0449801760335125

Epoch: 6| Step: 8
Training loss: 2.0727148056030273
Validation loss: 2.0246731594044673

Epoch: 6| Step: 9
Training loss: 2.405241012573242
Validation loss: 2.0299882734975507

Epoch: 6| Step: 10
Training loss: 1.5496399402618408
Validation loss: 2.032689244516434

Epoch: 6| Step: 11
Training loss: 2.0948734283447266
Validation loss: 2.0526588065649873

Epoch: 6| Step: 12
Training loss: 1.268527626991272
Validation loss: 2.046391661449145

Epoch: 6| Step: 13
Training loss: 2.4286270141601562
Validation loss: 2.0297854369686497

Epoch: 210| Step: 0
Training loss: 2.2956809997558594
Validation loss: 2.0427006495896207

Epoch: 6| Step: 1
Training loss: 1.8499462604522705
Validation loss: 2.029665472686932

Epoch: 6| Step: 2
Training loss: 2.2519118785858154
Validation loss: 2.0384635938111173

Epoch: 6| Step: 3
Training loss: 2.003211736679077
Validation loss: 2.016609286749235

Epoch: 6| Step: 4
Training loss: 2.218362808227539
Validation loss: 2.0359052714481147

Epoch: 6| Step: 5
Training loss: 1.4763401746749878
Validation loss: 2.0072406312470794

Epoch: 6| Step: 6
Training loss: 2.365170955657959
Validation loss: 2.0349761785999423

Epoch: 6| Step: 7
Training loss: 2.163083791732788
Validation loss: 2.04638030452113

Epoch: 6| Step: 8
Training loss: 1.823005199432373
Validation loss: 2.0513009076477378

Epoch: 6| Step: 9
Training loss: 2.1395013332366943
Validation loss: 2.0016024740793372

Epoch: 6| Step: 10
Training loss: 1.5767526626586914
Validation loss: 2.022358981511926

Epoch: 6| Step: 11
Training loss: 2.110973358154297
Validation loss: 2.0221790190665954

Epoch: 6| Step: 12
Training loss: 1.7054498195648193
Validation loss: 2.02381117369539

Epoch: 6| Step: 13
Training loss: 1.6129289865493774
Validation loss: 2.0291906415775256

Epoch: 211| Step: 0
Training loss: 2.440269947052002
Validation loss: 1.9873836348133702

Epoch: 6| Step: 1
Training loss: 1.115980863571167
Validation loss: 2.0207747592720935

Epoch: 6| Step: 2
Training loss: 1.8808649778366089
Validation loss: 2.0211685498555503

Epoch: 6| Step: 3
Training loss: 1.7802842855453491
Validation loss: 2.0198003630484305

Epoch: 6| Step: 4
Training loss: 2.0027825832366943
Validation loss: 1.9936511580662062

Epoch: 6| Step: 5
Training loss: 2.250439405441284
Validation loss: 2.019771602845961

Epoch: 6| Step: 6
Training loss: 1.9218686819076538
Validation loss: 2.0118391334369616

Epoch: 6| Step: 7
Training loss: 2.2022697925567627
Validation loss: 1.9920593974410847

Epoch: 6| Step: 8
Training loss: 1.7137058973312378
Validation loss: 2.002674033564906

Epoch: 6| Step: 9
Training loss: 2.3733901977539062
Validation loss: 2.028356195777975

Epoch: 6| Step: 10
Training loss: 1.9671818017959595
Validation loss: 1.972651115027807

Epoch: 6| Step: 11
Training loss: 2.1485373973846436
Validation loss: 1.9987618282277098

Epoch: 6| Step: 12
Training loss: 1.7871859073638916
Validation loss: 2.003022446427294

Epoch: 6| Step: 13
Training loss: 1.7977267503738403
Validation loss: 1.9712390976567422

Epoch: 212| Step: 0
Training loss: 2.1457724571228027
Validation loss: 1.987226491333336

Epoch: 6| Step: 1
Training loss: 1.7122204303741455
Validation loss: 1.9824245411862609

Epoch: 6| Step: 2
Training loss: 1.670302152633667
Validation loss: 1.9820289534907187

Epoch: 6| Step: 3
Training loss: 1.3083982467651367
Validation loss: 2.0073165252644527

Epoch: 6| Step: 4
Training loss: 3.548093318939209
Validation loss: 2.006562402171473

Epoch: 6| Step: 5
Training loss: 1.8884754180908203
Validation loss: 1.9958689135889853

Epoch: 6| Step: 6
Training loss: 1.790618896484375
Validation loss: 2.0247648813391246

Epoch: 6| Step: 7
Training loss: 1.8473201990127563
Validation loss: 1.9895810234931208

Epoch: 6| Step: 8
Training loss: 1.8259596824645996
Validation loss: 2.0124721898827502

Epoch: 6| Step: 9
Training loss: 1.4304481744766235
Validation loss: 2.019994180689576

Epoch: 6| Step: 10
Training loss: 2.5834202766418457
Validation loss: 2.007981458017903

Epoch: 6| Step: 11
Training loss: 1.7354381084442139
Validation loss: 1.9952476101536905

Epoch: 6| Step: 12
Training loss: 1.7535202503204346
Validation loss: 2.0110960186168714

Epoch: 6| Step: 13
Training loss: 2.323842763900757
Validation loss: 2.0196204672577562

Epoch: 213| Step: 0
Training loss: 2.5361580848693848
Validation loss: 2.008716283305999

Epoch: 6| Step: 1
Training loss: 1.1826964616775513
Validation loss: 2.023140658614456

Epoch: 6| Step: 2
Training loss: 2.3637235164642334
Validation loss: 1.9775641682327434

Epoch: 6| Step: 3
Training loss: 1.8312299251556396
Validation loss: 1.9975390100991854

Epoch: 6| Step: 4
Training loss: 2.3449816703796387
Validation loss: 2.001175331813033

Epoch: 6| Step: 5
Training loss: 1.7925817966461182
Validation loss: 2.020136467872127

Epoch: 6| Step: 6
Training loss: 2.2267866134643555
Validation loss: 2.018140644155523

Epoch: 6| Step: 7
Training loss: 2.043142795562744
Validation loss: 2.012319263591561

Epoch: 6| Step: 8
Training loss: 1.5843669176101685
Validation loss: 2.0305730399265083

Epoch: 6| Step: 9
Training loss: 2.0691211223602295
Validation loss: 2.003403845653739

Epoch: 6| Step: 10
Training loss: 1.6196262836456299
Validation loss: 1.993024988840985

Epoch: 6| Step: 11
Training loss: 1.4334943294525146
Validation loss: 1.9960916772965462

Epoch: 6| Step: 12
Training loss: 2.1078085899353027
Validation loss: 1.98985884522879

Epoch: 6| Step: 13
Training loss: 2.9870800971984863
Validation loss: 1.9824863146710139

Epoch: 214| Step: 0
Training loss: 2.6258187294006348
Validation loss: 1.999090274175008

Epoch: 6| Step: 1
Training loss: 1.8352248668670654
Validation loss: 2.025801284338838

Epoch: 6| Step: 2
Training loss: 1.6151046752929688
Validation loss: 2.0094263271618913

Epoch: 6| Step: 3
Training loss: 2.3382272720336914
Validation loss: 2.052432192269192

Epoch: 6| Step: 4
Training loss: 2.1225523948669434
Validation loss: 1.9949293392960743

Epoch: 6| Step: 5
Training loss: 2.2832112312316895
Validation loss: 2.013096547895862

Epoch: 6| Step: 6
Training loss: 1.6309962272644043
Validation loss: 2.0219207348362094

Epoch: 6| Step: 7
Training loss: 1.890141248703003
Validation loss: 2.0149684388150453

Epoch: 6| Step: 8
Training loss: 2.4938459396362305
Validation loss: 2.0218697645330943

Epoch: 6| Step: 9
Training loss: 1.3992458581924438
Validation loss: 2.0182463981771983

Epoch: 6| Step: 10
Training loss: 2.2810182571411133
Validation loss: 2.027792694748089

Epoch: 6| Step: 11
Training loss: 1.4616870880126953
Validation loss: 2.0086619366881666

Epoch: 6| Step: 12
Training loss: 2.153707504272461
Validation loss: 2.0465112834848385

Epoch: 6| Step: 13
Training loss: 1.1942486763000488
Validation loss: 2.0119307784624

Epoch: 215| Step: 0
Training loss: 2.392580986022949
Validation loss: 2.025405377470037

Epoch: 6| Step: 1
Training loss: 1.3419852256774902
Validation loss: 2.0412966923047136

Epoch: 6| Step: 2
Training loss: 2.2071640491485596
Validation loss: 2.0275795305928876

Epoch: 6| Step: 3
Training loss: 2.14810848236084
Validation loss: 2.0396649555493425

Epoch: 6| Step: 4
Training loss: 1.8356826305389404
Validation loss: 2.0013523563261955

Epoch: 6| Step: 5
Training loss: 1.7847471237182617
Validation loss: 2.0206382710446595

Epoch: 6| Step: 6
Training loss: 1.82185697555542
Validation loss: 1.991407044472233

Epoch: 6| Step: 7
Training loss: 1.5699541568756104
Validation loss: 2.0091866652170816

Epoch: 6| Step: 8
Training loss: 2.840221881866455
Validation loss: 2.0013388408127653

Epoch: 6| Step: 9
Training loss: 1.8717130422592163
Validation loss: 2.0059524864278813

Epoch: 6| Step: 10
Training loss: 2.135533332824707
Validation loss: 2.0139709980257097

Epoch: 6| Step: 11
Training loss: 2.0647411346435547
Validation loss: 1.9714492674796813

Epoch: 6| Step: 12
Training loss: 1.4292837381362915
Validation loss: 2.0068448358966458

Epoch: 6| Step: 13
Training loss: 2.2975594997406006
Validation loss: 2.0168625590621785

Epoch: 216| Step: 0
Training loss: 1.6726539134979248
Validation loss: 1.9939370642426193

Epoch: 6| Step: 1
Training loss: 2.1821346282958984
Validation loss: 2.005573782869565

Epoch: 6| Step: 2
Training loss: 2.123128890991211
Validation loss: 2.0203133039577033

Epoch: 6| Step: 3
Training loss: 2.0352721214294434
Validation loss: 2.005171501508323

Epoch: 6| Step: 4
Training loss: 1.628416895866394
Validation loss: 2.0203452879382717

Epoch: 6| Step: 5
Training loss: 1.9888453483581543
Validation loss: 2.0459753979918776

Epoch: 6| Step: 6
Training loss: 2.509737968444824
Validation loss: 1.9957525807042276

Epoch: 6| Step: 7
Training loss: 2.385831594467163
Validation loss: 2.0222958403248943

Epoch: 6| Step: 8
Training loss: 1.4177541732788086
Validation loss: 2.0130614003827496

Epoch: 6| Step: 9
Training loss: 2.1435184478759766
Validation loss: 2.0168386582405335

Epoch: 6| Step: 10
Training loss: 2.0238380432128906
Validation loss: 1.9960029830214798

Epoch: 6| Step: 11
Training loss: 2.10591721534729
Validation loss: 2.0071301549993534

Epoch: 6| Step: 12
Training loss: 1.3374264240264893
Validation loss: 1.9737249151352914

Epoch: 6| Step: 13
Training loss: 1.6008232831954956
Validation loss: 2.0070091934614283

Epoch: 217| Step: 0
Training loss: 2.1721038818359375
Validation loss: 1.9901034306454402

Epoch: 6| Step: 1
Training loss: 2.0181407928466797
Validation loss: 1.9713294967528312

Epoch: 6| Step: 2
Training loss: 2.0789246559143066
Validation loss: 1.9925850719533942

Epoch: 6| Step: 3
Training loss: 1.8821932077407837
Validation loss: 2.003649112998798

Epoch: 6| Step: 4
Training loss: 1.8905742168426514
Validation loss: 2.023181438446045

Epoch: 6| Step: 5
Training loss: 2.332418918609619
Validation loss: 1.9940150399361887

Epoch: 6| Step: 6
Training loss: 1.0894393920898438
Validation loss: 1.997221335288017

Epoch: 6| Step: 7
Training loss: 1.9065589904785156
Validation loss: 2.0124878832089004

Epoch: 6| Step: 8
Training loss: 2.2695837020874023
Validation loss: 2.0085270481724895

Epoch: 6| Step: 9
Training loss: 1.9650636911392212
Validation loss: 2.0267319115259315

Epoch: 6| Step: 10
Training loss: 1.868217945098877
Validation loss: 2.0351187106101745

Epoch: 6| Step: 11
Training loss: 1.734879970550537
Validation loss: 1.970566467572284

Epoch: 6| Step: 12
Training loss: 2.3724870681762695
Validation loss: 2.032413116065405

Epoch: 6| Step: 13
Training loss: 1.7061569690704346
Validation loss: 2.009796077205289

Epoch: 218| Step: 0
Training loss: 2.352661609649658
Validation loss: 2.0042691743502052

Epoch: 6| Step: 1
Training loss: 2.432316780090332
Validation loss: 1.9949959734434723

Epoch: 6| Step: 2
Training loss: 2.0100784301757812
Validation loss: 2.0331566615771224

Epoch: 6| Step: 3
Training loss: 1.6830248832702637
Validation loss: 2.012074197492292

Epoch: 6| Step: 4
Training loss: 1.458451509475708
Validation loss: 2.0038711768324657

Epoch: 6| Step: 5
Training loss: 1.3896288871765137
Validation loss: 2.01334669000359

Epoch: 6| Step: 6
Training loss: 1.4712592363357544
Validation loss: 2.012760349499282

Epoch: 6| Step: 7
Training loss: 2.058608055114746
Validation loss: 1.9855152932546472

Epoch: 6| Step: 8
Training loss: 1.7818092107772827
Validation loss: 2.0290280977884927

Epoch: 6| Step: 9
Training loss: 1.7500574588775635
Validation loss: 2.0001018329333236

Epoch: 6| Step: 10
Training loss: 2.4869937896728516
Validation loss: 2.0002631218202653

Epoch: 6| Step: 11
Training loss: 2.622401237487793
Validation loss: 2.0095844871254376

Epoch: 6| Step: 12
Training loss: 1.7444117069244385
Validation loss: 2.0214240192085184

Epoch: 6| Step: 13
Training loss: 2.2283871173858643
Validation loss: 2.0150596095669653

Epoch: 219| Step: 0
Training loss: 2.7484560012817383
Validation loss: 2.0051390586360807

Epoch: 6| Step: 1
Training loss: 2.1496734619140625
Validation loss: 1.9947623591269217

Epoch: 6| Step: 2
Training loss: 2.125098943710327
Validation loss: 2.014614397479642

Epoch: 6| Step: 3
Training loss: 2.0994713306427
Validation loss: 2.013597584539844

Epoch: 6| Step: 4
Training loss: 1.473978042602539
Validation loss: 2.0239299266569075

Epoch: 6| Step: 5
Training loss: 1.7881135940551758
Validation loss: 2.002930530937769

Epoch: 6| Step: 6
Training loss: 2.2455637454986572
Validation loss: 2.0089847656988327

Epoch: 6| Step: 7
Training loss: 2.171625852584839
Validation loss: 1.9929272000507643

Epoch: 6| Step: 8
Training loss: 1.5053181648254395
Validation loss: 2.0047565929351316

Epoch: 6| Step: 9
Training loss: 1.45822012424469
Validation loss: 2.028850027309951

Epoch: 6| Step: 10
Training loss: 1.327214002609253
Validation loss: 1.9753754254310363

Epoch: 6| Step: 11
Training loss: 1.4931151866912842
Validation loss: 1.9954315539329284

Epoch: 6| Step: 12
Training loss: 2.1076955795288086
Validation loss: 1.9711541373242614

Epoch: 6| Step: 13
Training loss: 2.9615869522094727
Validation loss: 2.031607162567877

Epoch: 220| Step: 0
Training loss: 2.675076484680176
Validation loss: 2.0016709373843287

Epoch: 6| Step: 1
Training loss: 2.4368972778320312
Validation loss: 2.0158015322941605

Epoch: 6| Step: 2
Training loss: 2.2647323608398438
Validation loss: 2.0113435970839633

Epoch: 6| Step: 3
Training loss: 2.1994924545288086
Validation loss: 1.9938327996961531

Epoch: 6| Step: 4
Training loss: 1.7497644424438477
Validation loss: 2.0075567922284527

Epoch: 6| Step: 5
Training loss: 1.1326048374176025
Validation loss: 2.016934597364036

Epoch: 6| Step: 6
Training loss: 1.8084957599639893
Validation loss: 2.0081278713800574

Epoch: 6| Step: 7
Training loss: 1.8370654582977295
Validation loss: 2.024869324058615

Epoch: 6| Step: 8
Training loss: 2.2729525566101074
Validation loss: 2.0032841415815454

Epoch: 6| Step: 9
Training loss: 1.1864540576934814
Validation loss: 2.019904694249553

Epoch: 6| Step: 10
Training loss: 1.5303092002868652
Validation loss: 1.9986017109245382

Epoch: 6| Step: 11
Training loss: 1.7311427593231201
Validation loss: 2.01922938131517

Epoch: 6| Step: 12
Training loss: 2.6388626098632812
Validation loss: 1.994954421956052

Epoch: 6| Step: 13
Training loss: 1.9226679801940918
Validation loss: 2.0039031685039563

Epoch: 221| Step: 0
Training loss: 2.0982649326324463
Validation loss: 2.0074618311338526

Epoch: 6| Step: 1
Training loss: 2.0958800315856934
Validation loss: 2.012597685219139

Epoch: 6| Step: 2
Training loss: 2.1247689723968506
Validation loss: 2.0188669197020994

Epoch: 6| Step: 3
Training loss: 2.3191425800323486
Validation loss: 2.0528901623141382

Epoch: 6| Step: 4
Training loss: 2.396533489227295
Validation loss: 2.0227783905562533

Epoch: 6| Step: 5
Training loss: 1.713346004486084
Validation loss: 2.0332908861098753

Epoch: 6| Step: 6
Training loss: 2.131643533706665
Validation loss: 2.011964177572599

Epoch: 6| Step: 7
Training loss: 1.925068736076355
Validation loss: 2.0316286497218634

Epoch: 6| Step: 8
Training loss: 1.3559788465499878
Validation loss: 2.019265038992769

Epoch: 6| Step: 9
Training loss: 1.8266745805740356
Validation loss: 2.039846448488133

Epoch: 6| Step: 10
Training loss: 1.4433388710021973
Validation loss: 1.9833404735852314

Epoch: 6| Step: 11
Training loss: 2.243591070175171
Validation loss: 2.021606819604033

Epoch: 6| Step: 12
Training loss: 1.9123433828353882
Validation loss: 1.9824751423251243

Epoch: 6| Step: 13
Training loss: 1.2788071632385254
Validation loss: 2.031483111842986

Epoch: 222| Step: 0
Training loss: 2.0275683403015137
Validation loss: 2.0130944751924083

Epoch: 6| Step: 1
Training loss: 2.0698318481445312
Validation loss: 2.0091773617652153

Epoch: 6| Step: 2
Training loss: 1.6203126907348633
Validation loss: 2.014321650228193

Epoch: 6| Step: 3
Training loss: 1.826967716217041
Validation loss: 2.0182734612495667

Epoch: 6| Step: 4
Training loss: 2.093322515487671
Validation loss: 2.0074575049902803

Epoch: 6| Step: 5
Training loss: 2.2281525135040283
Validation loss: 2.007514848504015

Epoch: 6| Step: 6
Training loss: 2.800987720489502
Validation loss: 2.0341567070253435

Epoch: 6| Step: 7
Training loss: 2.7007293701171875
Validation loss: 1.9999520624837568

Epoch: 6| Step: 8
Training loss: 1.2761332988739014
Validation loss: 2.0267797106055805

Epoch: 6| Step: 9
Training loss: 1.3965153694152832
Validation loss: 1.9800908898794523

Epoch: 6| Step: 10
Training loss: 1.3274532556533813
Validation loss: 1.9852469915984778

Epoch: 6| Step: 11
Training loss: 1.0468190908432007
Validation loss: 2.0032448525069864

Epoch: 6| Step: 12
Training loss: 2.950207233428955
Validation loss: 2.0181048941868607

Epoch: 6| Step: 13
Training loss: 2.0227339267730713
Validation loss: 2.0087471674847346

Epoch: 223| Step: 0
Training loss: 2.5950541496276855
Validation loss: 2.0258787575588433

Epoch: 6| Step: 1
Training loss: 2.6083970069885254
Validation loss: 1.9853096008300781

Epoch: 6| Step: 2
Training loss: 1.2111936807632446
Validation loss: 1.974521585690078

Epoch: 6| Step: 3
Training loss: 2.290487766265869
Validation loss: 2.0272621929004626

Epoch: 6| Step: 4
Training loss: 1.4007352590560913
Validation loss: 1.999364831114328

Epoch: 6| Step: 5
Training loss: 2.1070919036865234
Validation loss: 1.997755527496338

Epoch: 6| Step: 6
Training loss: 1.3852208852767944
Validation loss: 1.9888357603421776

Epoch: 6| Step: 7
Training loss: 1.62221360206604
Validation loss: 2.06067063987896

Epoch: 6| Step: 8
Training loss: 1.9277342557907104
Validation loss: 1.991194821173145

Epoch: 6| Step: 9
Training loss: 1.2144569158554077
Validation loss: 2.0394819372443744

Epoch: 6| Step: 10
Training loss: 2.0025744438171387
Validation loss: 2.0148858562592538

Epoch: 6| Step: 11
Training loss: 2.1968538761138916
Validation loss: 1.983952522277832

Epoch: 6| Step: 12
Training loss: 2.6064794063568115
Validation loss: 2.03879669661163

Epoch: 6| Step: 13
Training loss: 2.14508318901062
Validation loss: 2.0234390151116157

Epoch: 224| Step: 0
Training loss: 2.034125328063965
Validation loss: 2.040315079432662

Epoch: 6| Step: 1
Training loss: 2.061197280883789
Validation loss: 2.036630421556452

Epoch: 6| Step: 2
Training loss: 1.9373606443405151
Validation loss: 1.9871239405806347

Epoch: 6| Step: 3
Training loss: 2.47373366355896
Validation loss: 2.0187650252414007

Epoch: 6| Step: 4
Training loss: 1.680952548980713
Validation loss: 1.979728675657703

Epoch: 6| Step: 5
Training loss: 1.7568471431732178
Validation loss: 2.0220581446924517

Epoch: 6| Step: 6
Training loss: 1.7384549379348755
Validation loss: 2.043588726751266

Epoch: 6| Step: 7
Training loss: 1.7854671478271484
Validation loss: 2.030706044166319

Epoch: 6| Step: 8
Training loss: 1.8617234230041504
Validation loss: 1.9998337761048348

Epoch: 6| Step: 9
Training loss: 2.1263351440429688
Validation loss: 2.0305522077827045

Epoch: 6| Step: 10
Training loss: 1.5776433944702148
Validation loss: 2.045991031072473

Epoch: 6| Step: 11
Training loss: 2.2745776176452637
Validation loss: 2.0353434008936726

Epoch: 6| Step: 12
Training loss: 1.9723044633865356
Validation loss: 1.9971072340524325

Epoch: 6| Step: 13
Training loss: 2.2171237468719482
Validation loss: 2.0301864403550343

Epoch: 225| Step: 0
Training loss: 1.037221908569336
Validation loss: 2.016617008434829

Epoch: 6| Step: 1
Training loss: 1.8825626373291016
Validation loss: 2.0133301365760063

Epoch: 6| Step: 2
Training loss: 2.0387916564941406
Validation loss: 2.012617027887734

Epoch: 6| Step: 3
Training loss: 2.455447196960449
Validation loss: 2.0237627965147778

Epoch: 6| Step: 4
Training loss: 2.0848445892333984
Validation loss: 2.017718558670372

Epoch: 6| Step: 5
Training loss: 1.5142987966537476
Validation loss: 1.9866877396901448

Epoch: 6| Step: 6
Training loss: 1.866117238998413
Validation loss: 2.0172595618873514

Epoch: 6| Step: 7
Training loss: 1.973702311515808
Validation loss: 1.992958112429547

Epoch: 6| Step: 8
Training loss: 2.4173271656036377
Validation loss: 2.008361949715563

Epoch: 6| Step: 9
Training loss: 2.495375156402588
Validation loss: 1.9866665717094176

Epoch: 6| Step: 10
Training loss: 1.7915213108062744
Validation loss: 2.0049805025900564

Epoch: 6| Step: 11
Training loss: 2.087553024291992
Validation loss: 1.9964819928651214

Epoch: 6| Step: 12
Training loss: 1.4748772382736206
Validation loss: 2.0240973323904057

Epoch: 6| Step: 13
Training loss: 2.4602482318878174
Validation loss: 2.016128998930736

Epoch: 226| Step: 0
Training loss: 1.9112478494644165
Validation loss: 1.9892815415577223

Epoch: 6| Step: 1
Training loss: 2.145862579345703
Validation loss: 2.009537091819189

Epoch: 6| Step: 2
Training loss: 2.2935080528259277
Validation loss: 1.9741430013410506

Epoch: 6| Step: 3
Training loss: 1.7201941013336182
Validation loss: 1.9985094506253478

Epoch: 6| Step: 4
Training loss: 2.3380911350250244
Validation loss: 1.993634630275029

Epoch: 6| Step: 5
Training loss: 1.453535795211792
Validation loss: 2.0115587852334462

Epoch: 6| Step: 6
Training loss: 2.7959940433502197
Validation loss: 1.9967561460310412

Epoch: 6| Step: 7
Training loss: 1.5860437154769897
Validation loss: 1.99299055786543

Epoch: 6| Step: 8
Training loss: 1.958290934562683
Validation loss: 1.9858184693962015

Epoch: 6| Step: 9
Training loss: 1.1642274856567383
Validation loss: 2.012584017169091

Epoch: 6| Step: 10
Training loss: 1.8422739505767822
Validation loss: 2.0092413015263055

Epoch: 6| Step: 11
Training loss: 2.1342172622680664
Validation loss: 2.0096393656987015

Epoch: 6| Step: 12
Training loss: 1.651057481765747
Validation loss: 2.0123581822200487

Epoch: 6| Step: 13
Training loss: 2.432568073272705
Validation loss: 1.9965685952094294

Epoch: 227| Step: 0
Training loss: 2.070363759994507
Validation loss: 1.9986291944339711

Epoch: 6| Step: 1
Training loss: 1.7646749019622803
Validation loss: 2.0060178823368524

Epoch: 6| Step: 2
Training loss: 1.885406255722046
Validation loss: 2.0084404714645876

Epoch: 6| Step: 3
Training loss: 1.6340749263763428
Validation loss: 2.0057289715736144

Epoch: 6| Step: 4
Training loss: 1.899831771850586
Validation loss: 2.0421649179150982

Epoch: 6| Step: 5
Training loss: 2.6834521293640137
Validation loss: 2.0338624241531535

Epoch: 6| Step: 6
Training loss: 2.15570068359375
Validation loss: 2.004041821725907

Epoch: 6| Step: 7
Training loss: 1.85958731174469
Validation loss: 2.0054407068478164

Epoch: 6| Step: 8
Training loss: 1.2587337493896484
Validation loss: 2.010553270257929

Epoch: 6| Step: 9
Training loss: 2.0795276165008545
Validation loss: 2.011016350920482

Epoch: 6| Step: 10
Training loss: 2.309163808822632
Validation loss: 1.970096379198054

Epoch: 6| Step: 11
Training loss: 1.7118370532989502
Validation loss: 1.9976820817557714

Epoch: 6| Step: 12
Training loss: 2.168663501739502
Validation loss: 1.9898768342951292

Epoch: 6| Step: 13
Training loss: 1.122620701789856
Validation loss: 1.9801471476913781

Epoch: 228| Step: 0
Training loss: 1.869286298751831
Validation loss: 1.9967019737407725

Epoch: 6| Step: 1
Training loss: 1.8041880130767822
Validation loss: 2.0074719998144333

Epoch: 6| Step: 2
Training loss: 1.3043301105499268
Validation loss: 2.0066040677409016

Epoch: 6| Step: 3
Training loss: 2.4868650436401367
Validation loss: 1.9982176801209808

Epoch: 6| Step: 4
Training loss: 2.34651255607605
Validation loss: 2.0275551170431156

Epoch: 6| Step: 5
Training loss: 1.5098333358764648
Validation loss: 1.9825173859955163

Epoch: 6| Step: 6
Training loss: 2.2089996337890625
Validation loss: 1.9951263012424592

Epoch: 6| Step: 7
Training loss: 2.0348808765411377
Validation loss: 2.000511330942954

Epoch: 6| Step: 8
Training loss: 2.281477451324463
Validation loss: 1.9941476019479896

Epoch: 6| Step: 9
Training loss: 2.4878087043762207
Validation loss: 2.016974933685795

Epoch: 6| Step: 10
Training loss: 1.3580747842788696
Validation loss: 1.9963850949400215

Epoch: 6| Step: 11
Training loss: 1.9039485454559326
Validation loss: 2.0015701914346344

Epoch: 6| Step: 12
Training loss: 1.9238498210906982
Validation loss: 2.013441606234479

Epoch: 6| Step: 13
Training loss: 1.5349041223526
Validation loss: 2.0056672634616977

Epoch: 229| Step: 0
Training loss: 2.328929901123047
Validation loss: 1.988856691186146

Epoch: 6| Step: 1
Training loss: 1.7550407648086548
Validation loss: 2.0324295566928003

Epoch: 6| Step: 2
Training loss: 1.812880039215088
Validation loss: 2.0098982703301216

Epoch: 6| Step: 3
Training loss: 1.5064609050750732
Validation loss: 2.0097028286226335

Epoch: 6| Step: 4
Training loss: 2.365260601043701
Validation loss: 1.9964114735203404

Epoch: 6| Step: 5
Training loss: 1.9165273904800415
Validation loss: 2.0180423285371516

Epoch: 6| Step: 6
Training loss: 1.2477734088897705
Validation loss: 2.006083555119012

Epoch: 6| Step: 7
Training loss: 2.3302369117736816
Validation loss: 2.0191331281456897

Epoch: 6| Step: 8
Training loss: 1.845954418182373
Validation loss: 2.014602186859295

Epoch: 6| Step: 9
Training loss: 1.6535165309906006
Validation loss: 2.0061504443486533

Epoch: 6| Step: 10
Training loss: 1.9293891191482544
Validation loss: 2.038354368620021

Epoch: 6| Step: 11
Training loss: 2.677560806274414
Validation loss: 2.017641544342041

Epoch: 6| Step: 12
Training loss: 2.0099942684173584
Validation loss: 2.0108368358304425

Epoch: 6| Step: 13
Training loss: 2.042323589324951
Validation loss: 2.0110307816536195

Epoch: 230| Step: 0
Training loss: 2.040013313293457
Validation loss: 2.0189884452409643

Epoch: 6| Step: 1
Training loss: 1.6916208267211914
Validation loss: 2.0272988760343162

Epoch: 6| Step: 2
Training loss: 2.028285026550293
Validation loss: 2.0148842898748254

Epoch: 6| Step: 3
Training loss: 2.8693735599517822
Validation loss: 2.0340805848439536

Epoch: 6| Step: 4
Training loss: 2.024531126022339
Validation loss: 1.996692742070844

Epoch: 6| Step: 5
Training loss: 1.7150084972381592
Validation loss: 1.9980127401249383

Epoch: 6| Step: 6
Training loss: 2.0275697708129883
Validation loss: 2.0164755608445857

Epoch: 6| Step: 7
Training loss: 1.8692713975906372
Validation loss: 2.0185865945713495

Epoch: 6| Step: 8
Training loss: 1.496516227722168
Validation loss: 2.0138810462849115

Epoch: 6| Step: 9
Training loss: 2.209094524383545
Validation loss: 2.0048868130612116

Epoch: 6| Step: 10
Training loss: 1.4078218936920166
Validation loss: 2.0024589287337435

Epoch: 6| Step: 11
Training loss: 1.6635576486587524
Validation loss: 2.025435923248209

Epoch: 6| Step: 12
Training loss: 2.5855178833007812
Validation loss: 2.0084907957302627

Epoch: 6| Step: 13
Training loss: 0.9878851771354675
Validation loss: 2.030905235198236

Epoch: 231| Step: 0
Training loss: 1.6773171424865723
Validation loss: 2.0003763501362135

Epoch: 6| Step: 1
Training loss: 1.6601917743682861
Validation loss: 1.985946430954882

Epoch: 6| Step: 2
Training loss: 2.1930124759674072
Validation loss: 1.9831422951913649

Epoch: 6| Step: 3
Training loss: 2.0157570838928223
Validation loss: 1.9924941626928185

Epoch: 6| Step: 4
Training loss: 1.7044055461883545
Validation loss: 2.0079647469264206

Epoch: 6| Step: 5
Training loss: 1.794619083404541
Validation loss: 1.9976629249511226

Epoch: 6| Step: 6
Training loss: 1.8720567226409912
Validation loss: 1.992646853129069

Epoch: 6| Step: 7
Training loss: 2.283756732940674
Validation loss: 1.9936330497905772

Epoch: 6| Step: 8
Training loss: 1.8400591611862183
Validation loss: 1.9640608833682152

Epoch: 6| Step: 9
Training loss: 2.2606418132781982
Validation loss: 1.9890161098972443

Epoch: 6| Step: 10
Training loss: 1.5401158332824707
Validation loss: 2.0101974189922376

Epoch: 6| Step: 11
Training loss: 2.2145919799804688
Validation loss: 1.99028221894336

Epoch: 6| Step: 12
Training loss: 1.859391212463379
Validation loss: 2.012088052688106

Epoch: 6| Step: 13
Training loss: 2.2223172187805176
Validation loss: 2.0074552464228805

Epoch: 232| Step: 0
Training loss: 1.9621604681015015
Validation loss: 2.019475636943694

Epoch: 6| Step: 1
Training loss: 1.938076138496399
Validation loss: 2.0029251396015124

Epoch: 6| Step: 2
Training loss: 1.7767136096954346
Validation loss: 2.0062342766792542

Epoch: 6| Step: 3
Training loss: 2.2493531703948975
Validation loss: 2.0002565153183474

Epoch: 6| Step: 4
Training loss: 2.3194687366485596
Validation loss: 2.007407472979638

Epoch: 6| Step: 5
Training loss: 1.7961375713348389
Validation loss: 2.002225532326647

Epoch: 6| Step: 6
Training loss: 1.6657644510269165
Validation loss: 2.021486372076055

Epoch: 6| Step: 7
Training loss: 1.3905971050262451
Validation loss: 2.035220116697332

Epoch: 6| Step: 8
Training loss: 1.7458668947219849
Validation loss: 2.029991196047875

Epoch: 6| Step: 9
Training loss: 1.9399744272232056
Validation loss: 2.015329767298955

Epoch: 6| Step: 10
Training loss: 2.393033981323242
Validation loss: 2.0285413367773897

Epoch: 6| Step: 11
Training loss: 1.7568607330322266
Validation loss: 2.0380708479112193

Epoch: 6| Step: 12
Training loss: 2.4403483867645264
Validation loss: 2.0273776310746388

Epoch: 6| Step: 13
Training loss: 1.6419241428375244
Validation loss: 2.0379119919192408

Epoch: 233| Step: 0
Training loss: 2.128167152404785
Validation loss: 2.0362101062651603

Epoch: 6| Step: 1
Training loss: 2.1681199073791504
Validation loss: 2.0466231402530464

Epoch: 6| Step: 2
Training loss: 1.5645244121551514
Validation loss: 2.052818600849439

Epoch: 6| Step: 3
Training loss: 2.374546766281128
Validation loss: 2.030952876613986

Epoch: 6| Step: 4
Training loss: 1.9590630531311035
Validation loss: 2.0202180211262037

Epoch: 6| Step: 5
Training loss: 1.5842305421829224
Validation loss: 2.019288509122787

Epoch: 6| Step: 6
Training loss: 1.600523829460144
Validation loss: 2.016800941959504

Epoch: 6| Step: 7
Training loss: 1.9510990381240845
Validation loss: 2.02894881720184

Epoch: 6| Step: 8
Training loss: 2.0858373641967773
Validation loss: 1.9915457053851056

Epoch: 6| Step: 9
Training loss: 2.3168411254882812
Validation loss: 2.0362748535730506

Epoch: 6| Step: 10
Training loss: 1.8484567403793335
Validation loss: 2.041048742109729

Epoch: 6| Step: 11
Training loss: 1.592379093170166
Validation loss: 2.0290900558553715

Epoch: 6| Step: 12
Training loss: 2.172379493713379
Validation loss: 2.019997563413394

Epoch: 6| Step: 13
Training loss: 1.8089978694915771
Validation loss: 2.0282824193277667

Epoch: 234| Step: 0
Training loss: 1.7536535263061523
Validation loss: 2.028757070982328

Epoch: 6| Step: 1
Training loss: 1.0847991704940796
Validation loss: 2.0170154186987106

Epoch: 6| Step: 2
Training loss: 1.8889954090118408
Validation loss: 2.044989360276089

Epoch: 6| Step: 3
Training loss: 1.906779170036316
Validation loss: 2.0173140546326995

Epoch: 6| Step: 4
Training loss: 1.7625808715820312
Validation loss: 2.0105039701666882

Epoch: 6| Step: 5
Training loss: 1.3113815784454346
Validation loss: 2.0392015146952804

Epoch: 6| Step: 6
Training loss: 2.5176234245300293
Validation loss: 2.004694833550402

Epoch: 6| Step: 7
Training loss: 2.293785572052002
Validation loss: 2.0078941019632484

Epoch: 6| Step: 8
Training loss: 2.440528154373169
Validation loss: 1.947228024082799

Epoch: 6| Step: 9
Training loss: 1.996248722076416
Validation loss: 1.990047756061759

Epoch: 6| Step: 10
Training loss: 2.0512537956237793
Validation loss: 2.0061911254800777

Epoch: 6| Step: 11
Training loss: 2.1816015243530273
Validation loss: 2.0049774082758094

Epoch: 6| Step: 12
Training loss: 1.613905429840088
Validation loss: 2.025490403175354

Epoch: 6| Step: 13
Training loss: 2.25776743888855
Validation loss: 2.0363155564954205

Epoch: 235| Step: 0
Training loss: 2.1879923343658447
Validation loss: 1.9966135307024884

Epoch: 6| Step: 1
Training loss: 1.9719942808151245
Validation loss: 2.011467827263699

Epoch: 6| Step: 2
Training loss: 1.8578554391860962
Validation loss: 2.007887740289011

Epoch: 6| Step: 3
Training loss: 1.6202586889266968
Validation loss: 2.003125847026866

Epoch: 6| Step: 4
Training loss: 2.394327163696289
Validation loss: 2.0176263906622447

Epoch: 6| Step: 5
Training loss: 1.9410264492034912
Validation loss: 2.0369613683351906

Epoch: 6| Step: 6
Training loss: 2.0232162475585938
Validation loss: 2.0464333552186207

Epoch: 6| Step: 7
Training loss: 1.7032153606414795
Validation loss: 2.051453246865221

Epoch: 6| Step: 8
Training loss: 2.067880630493164
Validation loss: 2.034662156976679

Epoch: 6| Step: 9
Training loss: 1.5424127578735352
Validation loss: 2.0296562230715187

Epoch: 6| Step: 10
Training loss: 1.6875877380371094
Validation loss: 2.056739354646334

Epoch: 6| Step: 11
Training loss: 1.6325836181640625
Validation loss: 2.027200693725258

Epoch: 6| Step: 12
Training loss: 2.1345338821411133
Validation loss: 2.040325487813642

Epoch: 6| Step: 13
Training loss: 2.1745760440826416
Validation loss: 2.0074199925186815

Epoch: 236| Step: 0
Training loss: 2.080599069595337
Validation loss: 2.0399254432288547

Epoch: 6| Step: 1
Training loss: 2.1490721702575684
Validation loss: 2.0241723778427287

Epoch: 6| Step: 2
Training loss: 1.5745834112167358
Validation loss: 2.0171267729933544

Epoch: 6| Step: 3
Training loss: 2.2984185218811035
Validation loss: 1.992581695638677

Epoch: 6| Step: 4
Training loss: 2.9628753662109375
Validation loss: 2.002191746106712

Epoch: 6| Step: 5
Training loss: 1.6631910800933838
Validation loss: 2.0221121811097666

Epoch: 6| Step: 6
Training loss: 2.002203941345215
Validation loss: 2.0328020011225054

Epoch: 6| Step: 7
Training loss: 1.73329758644104
Validation loss: 1.969268109208794

Epoch: 6| Step: 8
Training loss: 1.6754156351089478
Validation loss: 2.0053192095089982

Epoch: 6| Step: 9
Training loss: 1.408400058746338
Validation loss: 2.0003100518257386

Epoch: 6| Step: 10
Training loss: 2.3862500190734863
Validation loss: 1.9559989308798185

Epoch: 6| Step: 11
Training loss: 1.3839117288589478
Validation loss: 2.0156066699694564

Epoch: 6| Step: 12
Training loss: 1.6907496452331543
Validation loss: 1.9956261932208974

Epoch: 6| Step: 13
Training loss: 1.9123892784118652
Validation loss: 2.042030306272609

Epoch: 237| Step: 0
Training loss: 1.5475704669952393
Validation loss: 2.008088950187929

Epoch: 6| Step: 1
Training loss: 1.2869454622268677
Validation loss: 2.0009912111425914

Epoch: 6| Step: 2
Training loss: 1.9544119834899902
Validation loss: 2.0026221134329356

Epoch: 6| Step: 3
Training loss: 2.6602890491485596
Validation loss: 2.000374604296941

Epoch: 6| Step: 4
Training loss: 1.8214892148971558
Validation loss: 1.9978779721003708

Epoch: 6| Step: 5
Training loss: 2.3040733337402344
Validation loss: 2.01864807580107

Epoch: 6| Step: 6
Training loss: 1.7395097017288208
Validation loss: 2.0123683175733014

Epoch: 6| Step: 7
Training loss: 2.3982396125793457
Validation loss: 2.026529577470595

Epoch: 6| Step: 8
Training loss: 1.8150566816329956
Validation loss: 2.0039972143788494

Epoch: 6| Step: 9
Training loss: 1.5117896795272827
Validation loss: 2.0024679322396555

Epoch: 6| Step: 10
Training loss: 2.1020078659057617
Validation loss: 2.01433087677084

Epoch: 6| Step: 11
Training loss: 1.9682960510253906
Validation loss: 2.0228421252260924

Epoch: 6| Step: 12
Training loss: 2.347315549850464
Validation loss: 2.0370512829031995

Epoch: 6| Step: 13
Training loss: 1.4271200895309448
Validation loss: 2.0263892219912623

Epoch: 238| Step: 0
Training loss: 2.2945258617401123
Validation loss: 2.0314678838176112

Epoch: 6| Step: 1
Training loss: 2.2228801250457764
Validation loss: 2.0141781645436443

Epoch: 6| Step: 2
Training loss: 1.9172468185424805
Validation loss: 2.0244351176805395

Epoch: 6| Step: 3
Training loss: 1.80448317527771
Validation loss: 2.01130989930963

Epoch: 6| Step: 4
Training loss: 2.141167163848877
Validation loss: 2.0273029163319576

Epoch: 6| Step: 5
Training loss: 2.499427080154419
Validation loss: 2.0307658103204544

Epoch: 6| Step: 6
Training loss: 1.7397812604904175
Validation loss: 2.015917331941666

Epoch: 6| Step: 7
Training loss: 1.2870277166366577
Validation loss: 1.999993392216262

Epoch: 6| Step: 8
Training loss: 1.7394860982894897
Validation loss: 2.0054262171509447

Epoch: 6| Step: 9
Training loss: 1.263256549835205
Validation loss: 2.0061914715715634

Epoch: 6| Step: 10
Training loss: 2.2616941928863525
Validation loss: 1.9946936586851716

Epoch: 6| Step: 11
Training loss: 2.514954090118408
Validation loss: 2.0033755481884046

Epoch: 6| Step: 12
Training loss: 1.7516320943832397
Validation loss: 2.0035911401112876

Epoch: 6| Step: 13
Training loss: 1.39665949344635
Validation loss: 1.9929950493638233

Epoch: 239| Step: 0
Training loss: 2.740187644958496
Validation loss: 2.0179825495648127

Epoch: 6| Step: 1
Training loss: 1.749023675918579
Validation loss: 1.9970520055422218

Epoch: 6| Step: 2
Training loss: 1.4572734832763672
Validation loss: 2.0173967115340696

Epoch: 6| Step: 3
Training loss: 1.4892246723175049
Validation loss: 2.0216970084815897

Epoch: 6| Step: 4
Training loss: 1.739152193069458
Validation loss: 2.027190096916691

Epoch: 6| Step: 5
Training loss: 1.916306972503662
Validation loss: 2.024090096514712

Epoch: 6| Step: 6
Training loss: 2.2844510078430176
Validation loss: 2.011325684926843

Epoch: 6| Step: 7
Training loss: 2.0366439819335938
Validation loss: 2.0030602357720815

Epoch: 6| Step: 8
Training loss: 2.152794122695923
Validation loss: 1.9859894731993317

Epoch: 6| Step: 9
Training loss: 0.9346003532409668
Validation loss: 2.036759207325597

Epoch: 6| Step: 10
Training loss: 2.0358519554138184
Validation loss: 1.9936999197929137

Epoch: 6| Step: 11
Training loss: 2.4156503677368164
Validation loss: 2.01746533250296

Epoch: 6| Step: 12
Training loss: 1.994978904724121
Validation loss: 1.9906345067485687

Epoch: 6| Step: 13
Training loss: 1.6941171884536743
Validation loss: 2.0137484919640327

Epoch: 240| Step: 0
Training loss: 2.348008632659912
Validation loss: 2.0414638416741484

Epoch: 6| Step: 1
Training loss: 1.5415043830871582
Validation loss: 1.988190822703864

Epoch: 6| Step: 2
Training loss: 2.038989543914795
Validation loss: 2.0246451375305012

Epoch: 6| Step: 3
Training loss: 1.8144471645355225
Validation loss: 1.9934702278465353

Epoch: 6| Step: 4
Training loss: 2.130779266357422
Validation loss: 2.0093299868286296

Epoch: 6| Step: 5
Training loss: 2.4833686351776123
Validation loss: 2.0169057679432694

Epoch: 6| Step: 6
Training loss: 1.2431097030639648
Validation loss: 1.9915002161456692

Epoch: 6| Step: 7
Training loss: 1.8142340183258057
Validation loss: 2.037274859284842

Epoch: 6| Step: 8
Training loss: 1.8678367137908936
Validation loss: 2.0196286542441255

Epoch: 6| Step: 9
Training loss: 1.8848830461502075
Validation loss: 2.0150567229076097

Epoch: 6| Step: 10
Training loss: 1.7745139598846436
Validation loss: 2.0046580683800483

Epoch: 6| Step: 11
Training loss: 2.318744659423828
Validation loss: 1.9854109056534306

Epoch: 6| Step: 12
Training loss: 1.554530143737793
Validation loss: 2.0197360592503704

Epoch: 6| Step: 13
Training loss: 1.7724252939224243
Validation loss: 2.0194047035709506

Epoch: 241| Step: 0
Training loss: 1.6605267524719238
Validation loss: 2.03633023846534

Epoch: 6| Step: 1
Training loss: 1.825964093208313
Validation loss: 2.043994980473672

Epoch: 6| Step: 2
Training loss: 1.3369660377502441
Validation loss: 2.039490653622535

Epoch: 6| Step: 3
Training loss: 2.2070722579956055
Validation loss: 2.0225598940285305

Epoch: 6| Step: 4
Training loss: 2.111119508743286
Validation loss: 2.030540212508171

Epoch: 6| Step: 5
Training loss: 1.7973917722702026
Validation loss: 2.034536998759034

Epoch: 6| Step: 6
Training loss: 2.3330352306365967
Validation loss: 1.9980135553626603

Epoch: 6| Step: 7
Training loss: 2.3050084114074707
Validation loss: 2.0172541974693217

Epoch: 6| Step: 8
Training loss: 2.04725980758667
Validation loss: 1.9879116153204313

Epoch: 6| Step: 9
Training loss: 1.6085870265960693
Validation loss: 2.0036859653329335

Epoch: 6| Step: 10
Training loss: 2.168914794921875
Validation loss: 2.0237019908043647

Epoch: 6| Step: 11
Training loss: 1.3479344844818115
Validation loss: 2.0244156288844284

Epoch: 6| Step: 12
Training loss: 2.431137800216675
Validation loss: 2.0023155443130003

Epoch: 6| Step: 13
Training loss: 1.4661134481430054
Validation loss: 2.0598046318177254

Epoch: 242| Step: 0
Training loss: 1.499743938446045
Validation loss: 2.0480694027357202

Epoch: 6| Step: 1
Training loss: 1.5910619497299194
Validation loss: 2.0122675600872246

Epoch: 6| Step: 2
Training loss: 2.227003335952759
Validation loss: 2.0322087016156924

Epoch: 6| Step: 3
Training loss: 1.8357189893722534
Validation loss: 2.04300344374872

Epoch: 6| Step: 4
Training loss: 1.8085756301879883
Validation loss: 2.026711061436643

Epoch: 6| Step: 5
Training loss: 1.7808444499969482
Validation loss: 2.0099727927997546

Epoch: 6| Step: 6
Training loss: 2.1149168014526367
Validation loss: 2.031484778209399

Epoch: 6| Step: 7
Training loss: 2.0091025829315186
Validation loss: 2.026566775896216

Epoch: 6| Step: 8
Training loss: 1.8864482641220093
Validation loss: 2.036065863024804

Epoch: 6| Step: 9
Training loss: 1.6599576473236084
Validation loss: 2.0136087248402257

Epoch: 6| Step: 10
Training loss: 2.6963729858398438
Validation loss: 2.0036397569922992

Epoch: 6| Step: 11
Training loss: 1.4153318405151367
Validation loss: 2.054191538082656

Epoch: 6| Step: 12
Training loss: 2.6212878227233887
Validation loss: 1.9969106874158304

Epoch: 6| Step: 13
Training loss: 1.7031652927398682
Validation loss: 2.0185730047123407

Epoch: 243| Step: 0
Training loss: 2.1519737243652344
Validation loss: 2.0252396932212253

Epoch: 6| Step: 1
Training loss: 2.153884172439575
Validation loss: 2.0535474259366273

Epoch: 6| Step: 2
Training loss: 2.0040640830993652
Validation loss: 1.9948237211473527

Epoch: 6| Step: 3
Training loss: 2.5418615341186523
Validation loss: 1.9914628292924614

Epoch: 6| Step: 4
Training loss: 2.3323662281036377
Validation loss: 1.9924179866749754

Epoch: 6| Step: 5
Training loss: 1.6320817470550537
Validation loss: 2.010286247858437

Epoch: 6| Step: 6
Training loss: 1.6077048778533936
Validation loss: 2.021352198816115

Epoch: 6| Step: 7
Training loss: 1.954881191253662
Validation loss: 2.0408891503528883

Epoch: 6| Step: 8
Training loss: 2.0165486335754395
Validation loss: 2.019348659823018

Epoch: 6| Step: 9
Training loss: 1.3367831707000732
Validation loss: 2.0289262597278883

Epoch: 6| Step: 10
Training loss: 1.7141625881195068
Validation loss: 2.053552322490241

Epoch: 6| Step: 11
Training loss: 1.9405522346496582
Validation loss: 2.020624981131605

Epoch: 6| Step: 12
Training loss: 1.590444564819336
Validation loss: 2.043488887048537

Epoch: 6| Step: 13
Training loss: 2.0664637088775635
Validation loss: 2.019601627062726

Epoch: 244| Step: 0
Training loss: 1.9420183897018433
Validation loss: 2.012181689662318

Epoch: 6| Step: 1
Training loss: 1.803722620010376
Validation loss: 2.040084851685391

Epoch: 6| Step: 2
Training loss: 2.613393545150757
Validation loss: 2.0428456696130897

Epoch: 6| Step: 3
Training loss: 1.5607274770736694
Validation loss: 2.0489163578197522

Epoch: 6| Step: 4
Training loss: 2.0973353385925293
Validation loss: 2.0337327372643257

Epoch: 6| Step: 5
Training loss: 1.7678841352462769
Validation loss: 2.0128008486122213

Epoch: 6| Step: 6
Training loss: 2.0802173614501953
Validation loss: 2.0157898895202147

Epoch: 6| Step: 7
Training loss: 2.06210994720459
Validation loss: 2.022272079221664

Epoch: 6| Step: 8
Training loss: 1.9034234285354614
Validation loss: 2.03461040219953

Epoch: 6| Step: 9
Training loss: 1.2068591117858887
Validation loss: 2.035771296870324

Epoch: 6| Step: 10
Training loss: 2.5565297603607178
Validation loss: 2.0155977485000447

Epoch: 6| Step: 11
Training loss: 1.8959431648254395
Validation loss: 2.0146334619932276

Epoch: 6| Step: 12
Training loss: 1.6180839538574219
Validation loss: 2.009451754631535

Epoch: 6| Step: 13
Training loss: 1.5577101707458496
Validation loss: 2.0275531071488575

Epoch: 245| Step: 0
Training loss: 2.086775302886963
Validation loss: 2.0113746517448017

Epoch: 6| Step: 1
Training loss: 1.1857236623764038
Validation loss: 2.0043324655102146

Epoch: 6| Step: 2
Training loss: 1.953683614730835
Validation loss: 2.0171461694984028

Epoch: 6| Step: 3
Training loss: 2.885211706161499
Validation loss: 2.009157278204477

Epoch: 6| Step: 4
Training loss: 2.143399953842163
Validation loss: 2.0107439102665072

Epoch: 6| Step: 5
Training loss: 1.5917898416519165
Validation loss: 2.0138411380911387

Epoch: 6| Step: 6
Training loss: 2.054880380630493
Validation loss: 2.023748856718822

Epoch: 6| Step: 7
Training loss: 1.2972493171691895
Validation loss: 2.0132425344118507

Epoch: 6| Step: 8
Training loss: 1.5646729469299316
Validation loss: 2.0124113021358365

Epoch: 6| Step: 9
Training loss: 2.0578553676605225
Validation loss: 1.9875588391416816

Epoch: 6| Step: 10
Training loss: 2.1342971324920654
Validation loss: 1.9986183130612938

Epoch: 6| Step: 11
Training loss: 1.3427242040634155
Validation loss: 2.03600747354569

Epoch: 6| Step: 12
Training loss: 2.2031140327453613
Validation loss: 2.0222701770003124

Epoch: 6| Step: 13
Training loss: 2.1010751724243164
Validation loss: 2.024651285140745

Epoch: 246| Step: 0
Training loss: 1.6931381225585938
Validation loss: 2.0210489585835445

Epoch: 6| Step: 1
Training loss: 2.6523385047912598
Validation loss: 2.017135134307287

Epoch: 6| Step: 2
Training loss: 2.332064628601074
Validation loss: 2.008423315581455

Epoch: 6| Step: 3
Training loss: 1.2877180576324463
Validation loss: 2.049121267052107

Epoch: 6| Step: 4
Training loss: 1.644096851348877
Validation loss: 1.9975210261601273

Epoch: 6| Step: 5
Training loss: 1.9162487983703613
Validation loss: 2.0448202381851854

Epoch: 6| Step: 6
Training loss: 1.7743576765060425
Validation loss: 2.0317601388500584

Epoch: 6| Step: 7
Training loss: 2.3450939655303955
Validation loss: 1.9899216851880472

Epoch: 6| Step: 8
Training loss: 1.466460943222046
Validation loss: 2.00153556049511

Epoch: 6| Step: 9
Training loss: 1.6755818128585815
Validation loss: 2.0177178382873535

Epoch: 6| Step: 10
Training loss: 2.0384583473205566
Validation loss: 2.0189723212231874

Epoch: 6| Step: 11
Training loss: 2.715510606765747
Validation loss: 1.9848891099294026

Epoch: 6| Step: 12
Training loss: 1.480642318725586
Validation loss: 2.037109282708937

Epoch: 6| Step: 13
Training loss: 1.9180643558502197
Validation loss: 2.060780725171489

Epoch: 247| Step: 0
Training loss: 2.3930792808532715
Validation loss: 2.0114856214933496

Epoch: 6| Step: 1
Training loss: 2.1487035751342773
Validation loss: 1.995567798614502

Epoch: 6| Step: 2
Training loss: 1.7104253768920898
Validation loss: 2.040852513364566

Epoch: 6| Step: 3
Training loss: 1.3950632810592651
Validation loss: 2.0100856852787796

Epoch: 6| Step: 4
Training loss: 1.379239559173584
Validation loss: 1.9909005972646898

Epoch: 6| Step: 5
Training loss: 2.3065781593322754
Validation loss: 2.0126849515463716

Epoch: 6| Step: 6
Training loss: 1.716768503189087
Validation loss: 2.0122677972239833

Epoch: 6| Step: 7
Training loss: 1.4986882209777832
Validation loss: 1.9863887230555217

Epoch: 6| Step: 8
Training loss: 2.0217161178588867
Validation loss: 2.0150701063935474

Epoch: 6| Step: 9
Training loss: 1.363358736038208
Validation loss: 2.027980823670664

Epoch: 6| Step: 10
Training loss: 2.1463329792022705
Validation loss: 2.0422836631856938

Epoch: 6| Step: 11
Training loss: 1.743829607963562
Validation loss: 1.9939828277916036

Epoch: 6| Step: 12
Training loss: 2.916619062423706
Validation loss: 2.0355665196654615

Epoch: 6| Step: 13
Training loss: 1.700385570526123
Validation loss: 2.0037912450810915

Epoch: 248| Step: 0
Training loss: 2.1689414978027344
Validation loss: 2.049997281002742

Epoch: 6| Step: 1
Training loss: 1.7873106002807617
Validation loss: 2.008957455235143

Epoch: 6| Step: 2
Training loss: 1.7950818538665771
Validation loss: 2.0363599843876337

Epoch: 6| Step: 3
Training loss: 1.6336370706558228
Validation loss: 2.0264214315722064

Epoch: 6| Step: 4
Training loss: 1.879291296005249
Validation loss: 2.045882958237843

Epoch: 6| Step: 5
Training loss: 2.6569015979766846
Validation loss: 2.07642210683515

Epoch: 6| Step: 6
Training loss: 1.387551188468933
Validation loss: 2.07147482902773

Epoch: 6| Step: 7
Training loss: 1.641310214996338
Validation loss: 2.0625144640604653

Epoch: 6| Step: 8
Training loss: 1.4408543109893799
Validation loss: 2.065679762953071

Epoch: 6| Step: 9
Training loss: 1.6925817728042603
Validation loss: 2.039303228419314

Epoch: 6| Step: 10
Training loss: 2.230133295059204
Validation loss: 2.0800571749287267

Epoch: 6| Step: 11
Training loss: 2.6424262523651123
Validation loss: 2.0601272108734294

Epoch: 6| Step: 12
Training loss: 1.8423181772232056
Validation loss: 2.0180203965915147

Epoch: 6| Step: 13
Training loss: 2.607103109359741
Validation loss: 2.0372509366722515

Epoch: 249| Step: 0
Training loss: 2.145658016204834
Validation loss: 2.045894633057297

Epoch: 6| Step: 1
Training loss: 2.0448532104492188
Validation loss: 2.050745515413182

Epoch: 6| Step: 2
Training loss: 2.218021869659424
Validation loss: 2.0710498017649495

Epoch: 6| Step: 3
Training loss: 2.0478639602661133
Validation loss: 2.0280169415217575

Epoch: 6| Step: 4
Training loss: 1.6700749397277832
Validation loss: 2.0010134558523855

Epoch: 6| Step: 5
Training loss: 2.2313666343688965
Validation loss: 2.0072217064519084

Epoch: 6| Step: 6
Training loss: 1.4777573347091675
Validation loss: 1.9948824041633195

Epoch: 6| Step: 7
Training loss: 1.0024006366729736
Validation loss: 2.038614590962728

Epoch: 6| Step: 8
Training loss: 2.2682061195373535
Validation loss: 2.0363228192893406

Epoch: 6| Step: 9
Training loss: 2.2629823684692383
Validation loss: 2.041456563498384

Epoch: 6| Step: 10
Training loss: 1.4705735445022583
Validation loss: 2.012248969847156

Epoch: 6| Step: 11
Training loss: 1.8645367622375488
Validation loss: 1.995503056433893

Epoch: 6| Step: 12
Training loss: 2.2230639457702637
Validation loss: 1.9583233556439799

Epoch: 6| Step: 13
Training loss: 1.4218610525131226
Validation loss: 1.9966751067869124

Epoch: 250| Step: 0
Training loss: 2.022167682647705
Validation loss: 2.007507772855861

Epoch: 6| Step: 1
Training loss: 1.7987066507339478
Validation loss: 2.016649576925462

Epoch: 6| Step: 2
Training loss: 2.101945400238037
Validation loss: 1.999684913184053

Epoch: 6| Step: 3
Training loss: 1.7223271131515503
Validation loss: 2.023382097162226

Epoch: 6| Step: 4
Training loss: 2.0249059200286865
Validation loss: 2.008553807453443

Epoch: 6| Step: 5
Training loss: 1.9491411447525024
Validation loss: 2.0167437894369966

Epoch: 6| Step: 6
Training loss: 1.955268383026123
Validation loss: 1.9846945052505822

Epoch: 6| Step: 7
Training loss: 1.9575097560882568
Validation loss: 2.0055469774430796

Epoch: 6| Step: 8
Training loss: 2.2184805870056152
Validation loss: 2.0137521630974224

Epoch: 6| Step: 9
Training loss: 1.537117838859558
Validation loss: 2.0297602453539447

Epoch: 6| Step: 10
Training loss: 2.0514187812805176
Validation loss: 2.015580910508351

Epoch: 6| Step: 11
Training loss: 1.8759348392486572
Validation loss: 2.0427361816488285

Epoch: 6| Step: 12
Training loss: 1.6285009384155273
Validation loss: 2.0279832860474944

Epoch: 6| Step: 13
Training loss: 1.7866376638412476
Validation loss: 2.0173783494580175

Epoch: 251| Step: 0
Training loss: 2.0454652309417725
Validation loss: 1.9869890007921445

Epoch: 6| Step: 1
Training loss: 1.870678186416626
Validation loss: 2.0118160939985708

Epoch: 6| Step: 2
Training loss: 1.4556883573532104
Validation loss: 2.0222714408751457

Epoch: 6| Step: 3
Training loss: 2.280601978302002
Validation loss: 1.9899702405416837

Epoch: 6| Step: 4
Training loss: 1.9307998418807983
Validation loss: 2.0286227810767388

Epoch: 6| Step: 5
Training loss: 2.116020679473877
Validation loss: 1.984171264915056

Epoch: 6| Step: 6
Training loss: 1.880457878112793
Validation loss: 2.0186316274827525

Epoch: 6| Step: 7
Training loss: 1.491011142730713
Validation loss: 2.0163693479312363

Epoch: 6| Step: 8
Training loss: 2.107560157775879
Validation loss: 2.0282517428039224

Epoch: 6| Step: 9
Training loss: 1.8758206367492676
Validation loss: 1.9745284536833405

Epoch: 6| Step: 10
Training loss: 2.347731351852417
Validation loss: 2.0128240816054808

Epoch: 6| Step: 11
Training loss: 1.518609642982483
Validation loss: 2.008593738719981

Epoch: 6| Step: 12
Training loss: 1.7929071187973022
Validation loss: 2.0162505180604997

Epoch: 6| Step: 13
Training loss: 1.4420198202133179
Validation loss: 2.0228824692387737

Epoch: 252| Step: 0
Training loss: 2.040048122406006
Validation loss: 2.017963650406048

Epoch: 6| Step: 1
Training loss: 2.747255325317383
Validation loss: 2.017742973501964

Epoch: 6| Step: 2
Training loss: 2.3309879302978516
Validation loss: 2.009418502930672

Epoch: 6| Step: 3
Training loss: 2.1551918983459473
Validation loss: 2.017348758635982

Epoch: 6| Step: 4
Training loss: 1.6463274955749512
Validation loss: 2.022012218352287

Epoch: 6| Step: 5
Training loss: 1.2259341478347778
Validation loss: 2.009490923214984

Epoch: 6| Step: 6
Training loss: 1.774419903755188
Validation loss: 2.0218618069925616

Epoch: 6| Step: 7
Training loss: 1.678321361541748
Validation loss: 2.0222053604741252

Epoch: 6| Step: 8
Training loss: 1.9033422470092773
Validation loss: 2.0241721842878606

Epoch: 6| Step: 9
Training loss: 1.7624626159667969
Validation loss: 2.032877206802368

Epoch: 6| Step: 10
Training loss: 2.273015260696411
Validation loss: 2.0306974995520806

Epoch: 6| Step: 11
Training loss: 1.6466315984725952
Validation loss: 2.037725261462632

Epoch: 6| Step: 12
Training loss: 1.2344814538955688
Validation loss: 2.041413621235919

Epoch: 6| Step: 13
Training loss: 2.4028141498565674
Validation loss: 2.027810109558926

Epoch: 253| Step: 0
Training loss: 2.099313259124756
Validation loss: 2.0101291825694423

Epoch: 6| Step: 1
Training loss: 2.259190797805786
Validation loss: 2.0041551961693713

Epoch: 6| Step: 2
Training loss: 1.5866097211837769
Validation loss: 2.0225210164182927

Epoch: 6| Step: 3
Training loss: 2.517629623413086
Validation loss: 2.0067914955077635

Epoch: 6| Step: 4
Training loss: 1.615450143814087
Validation loss: 2.005224904706401

Epoch: 6| Step: 5
Training loss: 1.9709652662277222
Validation loss: 2.0325425081355597

Epoch: 6| Step: 6
Training loss: 1.553680181503296
Validation loss: 2.0168272526033464

Epoch: 6| Step: 7
Training loss: 1.9008972644805908
Validation loss: 2.0111334323883057

Epoch: 6| Step: 8
Training loss: 2.377204418182373
Validation loss: 2.016328142535302

Epoch: 6| Step: 9
Training loss: 1.3452414274215698
Validation loss: 2.016356042636338

Epoch: 6| Step: 10
Training loss: 2.21864914894104
Validation loss: 2.001781346977398

Epoch: 6| Step: 11
Training loss: 1.3890302181243896
Validation loss: 2.0152833961671397

Epoch: 6| Step: 12
Training loss: 1.7866837978363037
Validation loss: 2.048161715589544

Epoch: 6| Step: 13
Training loss: 1.6754082441329956
Validation loss: 2.004369469099147

Epoch: 254| Step: 0
Training loss: 1.9824776649475098
Validation loss: 2.024253983651438

Epoch: 6| Step: 1
Training loss: 2.4014811515808105
Validation loss: 2.0122361067802674

Epoch: 6| Step: 2
Training loss: 2.1553843021392822
Validation loss: 1.996750348357744

Epoch: 6| Step: 3
Training loss: 1.7030991315841675
Validation loss: 2.0288076785302933

Epoch: 6| Step: 4
Training loss: 1.6034208536148071
Validation loss: 2.0663443970423874

Epoch: 6| Step: 5
Training loss: 1.5420399904251099
Validation loss: 2.018586613798654

Epoch: 6| Step: 6
Training loss: 2.4277217388153076
Validation loss: 2.013908111920921

Epoch: 6| Step: 7
Training loss: 2.038943290710449
Validation loss: 2.036046471647037

Epoch: 6| Step: 8
Training loss: 1.3748985528945923
Validation loss: 2.021326991819566

Epoch: 6| Step: 9
Training loss: 2.1355507373809814
Validation loss: 2.036602773974019

Epoch: 6| Step: 10
Training loss: 1.9778248071670532
Validation loss: 2.0379165705814155

Epoch: 6| Step: 11
Training loss: 1.24296236038208
Validation loss: 2.0542941785627797

Epoch: 6| Step: 12
Training loss: 1.817004680633545
Validation loss: 1.9926323916322441

Epoch: 6| Step: 13
Training loss: 2.0952272415161133
Validation loss: 2.052748123804728

Epoch: 255| Step: 0
Training loss: 2.2978813648223877
Validation loss: 2.0225232826766146

Epoch: 6| Step: 1
Training loss: 2.128633499145508
Validation loss: 2.0218836479289557

Epoch: 6| Step: 2
Training loss: 1.6799018383026123
Validation loss: 2.04284324953633

Epoch: 6| Step: 3
Training loss: 2.4243249893188477
Validation loss: 2.030999357982348

Epoch: 6| Step: 4
Training loss: 2.3297853469848633
Validation loss: 2.0224116873997513

Epoch: 6| Step: 5
Training loss: 1.3875048160552979
Validation loss: 2.0228441992113666

Epoch: 6| Step: 6
Training loss: 1.9141557216644287
Validation loss: 2.0041714252964145

Epoch: 6| Step: 7
Training loss: 1.2538503408432007
Validation loss: 1.9908255018213743

Epoch: 6| Step: 8
Training loss: 1.8863162994384766
Validation loss: 2.0551748455211682

Epoch: 6| Step: 9
Training loss: 1.247581958770752
Validation loss: 2.0053965917197605

Epoch: 6| Step: 10
Training loss: 1.637425422668457
Validation loss: 2.024415707075468

Epoch: 6| Step: 11
Training loss: 1.779705286026001
Validation loss: 2.016054766152495

Epoch: 6| Step: 12
Training loss: 1.906653642654419
Validation loss: 2.0628284177472516

Epoch: 6| Step: 13
Training loss: 2.3922348022460938
Validation loss: 2.021051455569524

Epoch: 256| Step: 0
Training loss: 1.89215087890625
Validation loss: 2.015158804514075

Epoch: 6| Step: 1
Training loss: 1.4952837228775024
Validation loss: 1.9823072097634757

Epoch: 6| Step: 2
Training loss: 1.7582837343215942
Validation loss: 2.0235635452373053

Epoch: 6| Step: 3
Training loss: 1.7267355918884277
Validation loss: 1.9982063065293014

Epoch: 6| Step: 4
Training loss: 2.2189178466796875
Validation loss: 1.9810510386702835

Epoch: 6| Step: 5
Training loss: 1.8747735023498535
Validation loss: 1.9916734746707383

Epoch: 6| Step: 6
Training loss: 1.8566701412200928
Validation loss: 1.9950554499062159

Epoch: 6| Step: 7
Training loss: 1.3987679481506348
Validation loss: 2.01050280755566

Epoch: 6| Step: 8
Training loss: 2.4938251972198486
Validation loss: 2.001236108041579

Epoch: 6| Step: 9
Training loss: 2.321913242340088
Validation loss: 1.9802878415712746

Epoch: 6| Step: 10
Training loss: 1.256451964378357
Validation loss: 1.9663681278946579

Epoch: 6| Step: 11
Training loss: 1.8966617584228516
Validation loss: 2.032935078426074

Epoch: 6| Step: 12
Training loss: 2.103639602661133
Validation loss: 2.0186924844659786

Epoch: 6| Step: 13
Training loss: 2.0534698963165283
Validation loss: 2.010420855655465

Epoch: 257| Step: 0
Training loss: 1.8749631643295288
Validation loss: 1.9871124336796422

Epoch: 6| Step: 1
Training loss: 2.0887136459350586
Validation loss: 2.0090802061942314

Epoch: 6| Step: 2
Training loss: 2.6511688232421875
Validation loss: 2.011316963421401

Epoch: 6| Step: 3
Training loss: 1.5184359550476074
Validation loss: 1.9994790284864363

Epoch: 6| Step: 4
Training loss: 1.5273699760437012
Validation loss: 2.005340923545181

Epoch: 6| Step: 5
Training loss: 2.329233169555664
Validation loss: 2.0098766921668925

Epoch: 6| Step: 6
Training loss: 1.9422158002853394
Validation loss: 1.9964714909112582

Epoch: 6| Step: 7
Training loss: 1.7360727787017822
Validation loss: 2.0220345245894564

Epoch: 6| Step: 8
Training loss: 1.7702301740646362
Validation loss: 2.0076410232051725

Epoch: 6| Step: 9
Training loss: 2.121049642562866
Validation loss: 2.019780279487692

Epoch: 6| Step: 10
Training loss: 2.587587356567383
Validation loss: 1.9909972195984216

Epoch: 6| Step: 11
Training loss: 1.6175246238708496
Validation loss: 2.0033486376526537

Epoch: 6| Step: 12
Training loss: 1.0498182773590088
Validation loss: 2.0152032336881085

Epoch: 6| Step: 13
Training loss: 1.4836190938949585
Validation loss: 2.0031408033063336

Epoch: 258| Step: 0
Training loss: 2.3787550926208496
Validation loss: 2.0289163845841602

Epoch: 6| Step: 1
Training loss: 2.0167996883392334
Validation loss: 2.0328158640092417

Epoch: 6| Step: 2
Training loss: 2.210826873779297
Validation loss: 2.038885062740695

Epoch: 6| Step: 3
Training loss: 2.124394178390503
Validation loss: 2.0174446003411406

Epoch: 6| Step: 4
Training loss: 2.1798484325408936
Validation loss: 2.084293032205233

Epoch: 6| Step: 5
Training loss: 0.7549645900726318
Validation loss: 2.046710011779621

Epoch: 6| Step: 6
Training loss: 0.9358872771263123
Validation loss: 2.043765852528234

Epoch: 6| Step: 7
Training loss: 2.0887343883514404
Validation loss: 2.0664078753481627

Epoch: 6| Step: 8
Training loss: 2.1663756370544434
Validation loss: 2.0639225295794907

Epoch: 6| Step: 9
Training loss: 1.7284350395202637
Validation loss: 2.050799310848277

Epoch: 6| Step: 10
Training loss: 1.5796958208084106
Validation loss: 2.044347325960795

Epoch: 6| Step: 11
Training loss: 1.9290344715118408
Validation loss: 2.049269837717856

Epoch: 6| Step: 12
Training loss: 1.7739994525909424
Validation loss: 2.056017570598151

Epoch: 6| Step: 13
Training loss: 2.5622997283935547
Validation loss: 2.0510155180449128

Epoch: 259| Step: 0
Training loss: 1.650071620941162
Validation loss: 2.031709953020978

Epoch: 6| Step: 1
Training loss: 1.8594706058502197
Validation loss: 2.001177777526199

Epoch: 6| Step: 2
Training loss: 1.761223316192627
Validation loss: 2.0114501701888217

Epoch: 6| Step: 3
Training loss: 1.6278735399246216
Validation loss: 1.9916211687108523

Epoch: 6| Step: 4
Training loss: 1.7759380340576172
Validation loss: 1.9947908629653275

Epoch: 6| Step: 5
Training loss: 2.006585121154785
Validation loss: 1.9620117859173847

Epoch: 6| Step: 6
Training loss: 2.2403125762939453
Validation loss: 2.0050347684532084

Epoch: 6| Step: 7
Training loss: 2.0384650230407715
Validation loss: 2.0348786692465506

Epoch: 6| Step: 8
Training loss: 2.4782357215881348
Validation loss: 1.997855592799443

Epoch: 6| Step: 9
Training loss: 1.5389988422393799
Validation loss: 2.011918975460914

Epoch: 6| Step: 10
Training loss: 1.9032821655273438
Validation loss: 2.041572542600734

Epoch: 6| Step: 11
Training loss: 1.822015404701233
Validation loss: 2.00301650006284

Epoch: 6| Step: 12
Training loss: 2.221200466156006
Validation loss: 2.0344797718909478

Epoch: 6| Step: 13
Training loss: 2.114567756652832
Validation loss: 1.9939539791435323

Epoch: 260| Step: 0
Training loss: 1.6999611854553223
Validation loss: 2.02356247619916

Epoch: 6| Step: 1
Training loss: 1.9838348627090454
Validation loss: 2.044421439529747

Epoch: 6| Step: 2
Training loss: 1.8510888814926147
Validation loss: 2.0313198874073644

Epoch: 6| Step: 3
Training loss: 1.6356664896011353
Validation loss: 2.0059615360793246

Epoch: 6| Step: 4
Training loss: 1.762887716293335
Validation loss: 2.007942566307642

Epoch: 6| Step: 5
Training loss: 1.8108086585998535
Validation loss: 2.0178118905713482

Epoch: 6| Step: 6
Training loss: 2.5558061599731445
Validation loss: 2.0444476271188385

Epoch: 6| Step: 7
Training loss: 2.7615795135498047
Validation loss: 2.017157182898573

Epoch: 6| Step: 8
Training loss: 1.7379481792449951
Validation loss: 2.031538640299151

Epoch: 6| Step: 9
Training loss: 1.6181349754333496
Validation loss: 2.0337945876582975

Epoch: 6| Step: 10
Training loss: 1.9632415771484375
Validation loss: 2.0210217737382457

Epoch: 6| Step: 11
Training loss: 1.912815809249878
Validation loss: 2.0265205598646596

Epoch: 6| Step: 12
Training loss: 1.4753310680389404
Validation loss: 2.0596340766517063

Epoch: 6| Step: 13
Training loss: 1.5125558376312256
Validation loss: 2.048025920826902

Epoch: 261| Step: 0
Training loss: 1.5469646453857422
Validation loss: 2.0169245171290573

Epoch: 6| Step: 1
Training loss: 1.5423953533172607
Validation loss: 2.0572552475877988

Epoch: 6| Step: 2
Training loss: 2.0687429904937744
Validation loss: 2.0025031540983464

Epoch: 6| Step: 3
Training loss: 2.1054487228393555
Validation loss: 2.020175233963997

Epoch: 6| Step: 4
Training loss: 1.3697054386138916
Validation loss: 2.0275452111357

Epoch: 6| Step: 5
Training loss: 1.8043193817138672
Validation loss: 2.029754202852967

Epoch: 6| Step: 6
Training loss: 2.145519971847534
Validation loss: 2.0203538222979476

Epoch: 6| Step: 7
Training loss: 2.107866048812866
Validation loss: 2.014632760837514

Epoch: 6| Step: 8
Training loss: 1.4756968021392822
Validation loss: 2.0115621064298894

Epoch: 6| Step: 9
Training loss: 2.3647992610931396
Validation loss: 2.0328500014479443

Epoch: 6| Step: 10
Training loss: 2.054255247116089
Validation loss: 2.0392331102842927

Epoch: 6| Step: 11
Training loss: 1.5814661979675293
Validation loss: 2.0391665594552153

Epoch: 6| Step: 12
Training loss: 2.0052123069763184
Validation loss: 2.0436206838136077

Epoch: 6| Step: 13
Training loss: 1.9563465118408203
Validation loss: 1.9822871249209169

Epoch: 262| Step: 0
Training loss: 1.057991862297058
Validation loss: 2.0338092696282173

Epoch: 6| Step: 1
Training loss: 1.6266703605651855
Validation loss: 2.028379196761757

Epoch: 6| Step: 2
Training loss: 1.981906771659851
Validation loss: 2.0146892557861986

Epoch: 6| Step: 3
Training loss: 2.1648526191711426
Validation loss: 2.002999287779613

Epoch: 6| Step: 4
Training loss: 2.174172878265381
Validation loss: 1.996189126404383

Epoch: 6| Step: 5
Training loss: 2.450068473815918
Validation loss: 1.9936470241956814

Epoch: 6| Step: 6
Training loss: 1.3891754150390625
Validation loss: 2.046521061210222

Epoch: 6| Step: 7
Training loss: 1.1324247121810913
Validation loss: 2.0322876027835313

Epoch: 6| Step: 8
Training loss: 2.296319007873535
Validation loss: 2.0139614971735145

Epoch: 6| Step: 9
Training loss: 1.9206781387329102
Validation loss: 2.015841326405925

Epoch: 6| Step: 10
Training loss: 1.6796211004257202
Validation loss: 2.025665042220905

Epoch: 6| Step: 11
Training loss: 2.110621690750122
Validation loss: 2.048054331092424

Epoch: 6| Step: 12
Training loss: 2.25213360786438
Validation loss: 2.039678940209009

Epoch: 6| Step: 13
Training loss: 2.384509801864624
Validation loss: 2.0340866811813845

Epoch: 263| Step: 0
Training loss: 0.9038788080215454
Validation loss: 2.046277426904248

Epoch: 6| Step: 1
Training loss: 2.513624668121338
Validation loss: 2.0283720980408373

Epoch: 6| Step: 2
Training loss: 1.51132333278656
Validation loss: 2.0461680914766047

Epoch: 6| Step: 3
Training loss: 1.447082757949829
Validation loss: 2.0381586295302196

Epoch: 6| Step: 4
Training loss: 2.220720052719116
Validation loss: 2.0145015921643985

Epoch: 6| Step: 5
Training loss: 2.0634758472442627
Validation loss: 2.0239484951060307

Epoch: 6| Step: 6
Training loss: 1.8713997602462769
Validation loss: 1.98706304770644

Epoch: 6| Step: 7
Training loss: 2.2926182746887207
Validation loss: 2.0718509176725983

Epoch: 6| Step: 8
Training loss: 1.1538517475128174
Validation loss: 1.9965561025886125

Epoch: 6| Step: 9
Training loss: 2.076059341430664
Validation loss: 2.0193466614651423

Epoch: 6| Step: 10
Training loss: 2.3544583320617676
Validation loss: 1.9975813755425074

Epoch: 6| Step: 11
Training loss: 2.191436290740967
Validation loss: 2.0163009794809486

Epoch: 6| Step: 12
Training loss: 1.9740869998931885
Validation loss: 2.025195866502741

Epoch: 6| Step: 13
Training loss: 1.4742350578308105
Validation loss: 1.9892371469928372

Epoch: 264| Step: 0
Training loss: 1.8286495208740234
Validation loss: 2.0436299206108175

Epoch: 6| Step: 1
Training loss: 1.7749292850494385
Validation loss: 1.9862348751355243

Epoch: 6| Step: 2
Training loss: 1.9737571477890015
Validation loss: 1.9927580164324852

Epoch: 6| Step: 3
Training loss: 2.0911378860473633
Validation loss: 2.0074266772116385

Epoch: 6| Step: 4
Training loss: 2.129944324493408
Validation loss: 2.037153079945554

Epoch: 6| Step: 5
Training loss: 1.3474825620651245
Validation loss: 2.00805397956602

Epoch: 6| Step: 6
Training loss: 1.9575939178466797
Validation loss: 1.9783482128574001

Epoch: 6| Step: 7
Training loss: 2.220771312713623
Validation loss: 2.0003918140165267

Epoch: 6| Step: 8
Training loss: 2.1392765045166016
Validation loss: 2.0177248780445387

Epoch: 6| Step: 9
Training loss: 1.73470139503479
Validation loss: 2.01522720116441

Epoch: 6| Step: 10
Training loss: 1.6642420291900635
Validation loss: 1.9962890942891438

Epoch: 6| Step: 11
Training loss: 2.172086715698242
Validation loss: 2.0507464255056074

Epoch: 6| Step: 12
Training loss: 1.1601482629776
Validation loss: 2.031362332323546

Epoch: 6| Step: 13
Training loss: 2.2755444049835205
Validation loss: 2.034138884595645

Epoch: 265| Step: 0
Training loss: 1.8283448219299316
Validation loss: 1.99830327879998

Epoch: 6| Step: 1
Training loss: 2.507786273956299
Validation loss: 1.995189876966579

Epoch: 6| Step: 2
Training loss: 1.6275475025177002
Validation loss: 2.019822253975817

Epoch: 6| Step: 3
Training loss: 1.4176450967788696
Validation loss: 2.0372345088630595

Epoch: 6| Step: 4
Training loss: 2.084304094314575
Validation loss: 2.026996394639374

Epoch: 6| Step: 5
Training loss: 1.6010606288909912
Validation loss: 2.008576253409027

Epoch: 6| Step: 6
Training loss: 2.2787647247314453
Validation loss: 2.04297629479439

Epoch: 6| Step: 7
Training loss: 1.828101634979248
Validation loss: 2.026842224982477

Epoch: 6| Step: 8
Training loss: 1.6579549312591553
Validation loss: 2.063687083541706

Epoch: 6| Step: 9
Training loss: 2.0672214031219482
Validation loss: 2.053865276357179

Epoch: 6| Step: 10
Training loss: 1.8370287418365479
Validation loss: 2.0335657186405633

Epoch: 6| Step: 11
Training loss: 1.745079755783081
Validation loss: 2.0856969997447026

Epoch: 6| Step: 12
Training loss: 2.026115894317627
Validation loss: 2.0185352730494674

Epoch: 6| Step: 13
Training loss: 1.7597578763961792
Validation loss: 2.0454669690901235

Epoch: 266| Step: 0
Training loss: 1.6399149894714355
Validation loss: 2.0605833825244697

Epoch: 6| Step: 1
Training loss: 2.7656683921813965
Validation loss: 2.0291688442230225

Epoch: 6| Step: 2
Training loss: 1.139307975769043
Validation loss: 2.023424715124151

Epoch: 6| Step: 3
Training loss: 2.091792106628418
Validation loss: 2.0448673284181984

Epoch: 6| Step: 4
Training loss: 1.374871015548706
Validation loss: 2.0134593350912935

Epoch: 6| Step: 5
Training loss: 1.974790334701538
Validation loss: 2.011739453961772

Epoch: 6| Step: 6
Training loss: 1.327953577041626
Validation loss: 2.026225761700702

Epoch: 6| Step: 7
Training loss: 2.134570598602295
Validation loss: 2.021143226213353

Epoch: 6| Step: 8
Training loss: 2.328479766845703
Validation loss: 2.027196499609178

Epoch: 6| Step: 9
Training loss: 1.4809905290603638
Validation loss: 2.0022812274194535

Epoch: 6| Step: 10
Training loss: 2.059253215789795
Validation loss: 2.0218336889820714

Epoch: 6| Step: 11
Training loss: 1.5361459255218506
Validation loss: 2.03040914381704

Epoch: 6| Step: 12
Training loss: 2.4482967853546143
Validation loss: 2.0030701826977473

Epoch: 6| Step: 13
Training loss: 1.978830337524414
Validation loss: 2.0053121146335395

Epoch: 267| Step: 0
Training loss: 1.9929497241973877
Validation loss: 1.9916705252021871

Epoch: 6| Step: 1
Training loss: 1.932472825050354
Validation loss: 1.9779261747996013

Epoch: 6| Step: 2
Training loss: 2.3760504722595215
Validation loss: 2.0013371898281958

Epoch: 6| Step: 3
Training loss: 1.819627285003662
Validation loss: 2.016177024892581

Epoch: 6| Step: 4
Training loss: 1.7635705471038818
Validation loss: 2.0522538538902038

Epoch: 6| Step: 5
Training loss: 2.1305079460144043
Validation loss: 1.9921412185956073

Epoch: 6| Step: 6
Training loss: 1.2516995668411255
Validation loss: 1.9941611033613964

Epoch: 6| Step: 7
Training loss: 1.651181936264038
Validation loss: 2.030028008645581

Epoch: 6| Step: 8
Training loss: 1.806868553161621
Validation loss: 2.032266410448218

Epoch: 6| Step: 9
Training loss: 1.3076612949371338
Validation loss: 2.028237999126475

Epoch: 6| Step: 10
Training loss: 2.6719608306884766
Validation loss: 1.992300420679072

Epoch: 6| Step: 11
Training loss: 1.6184020042419434
Validation loss: 2.0140943475948867

Epoch: 6| Step: 12
Training loss: 1.4974100589752197
Validation loss: 2.0221019739745767

Epoch: 6| Step: 13
Training loss: 2.2506535053253174
Validation loss: 2.0186795829444804

Epoch: 268| Step: 0
Training loss: 1.860132098197937
Validation loss: 2.010077157328206

Epoch: 6| Step: 1
Training loss: 1.6974613666534424
Validation loss: 2.002906753170875

Epoch: 6| Step: 2
Training loss: 1.819180965423584
Validation loss: 2.0372661518794235

Epoch: 6| Step: 3
Training loss: 2.25152587890625
Validation loss: 2.063642253157913

Epoch: 6| Step: 4
Training loss: 2.0331919193267822
Validation loss: 2.0262439045854794

Epoch: 6| Step: 5
Training loss: 1.6811012029647827
Validation loss: 2.068603733534454

Epoch: 6| Step: 6
Training loss: 1.9581727981567383
Validation loss: 2.052475337059267

Epoch: 6| Step: 7
Training loss: 1.9701619148254395
Validation loss: 2.067376180361676

Epoch: 6| Step: 8
Training loss: 1.8645210266113281
Validation loss: 2.0445737146562144

Epoch: 6| Step: 9
Training loss: 1.9915363788604736
Validation loss: 2.0524019349005913

Epoch: 6| Step: 10
Training loss: 1.7813141345977783
Validation loss: 2.037334326774843

Epoch: 6| Step: 11
Training loss: 2.0015439987182617
Validation loss: 2.044850457099176

Epoch: 6| Step: 12
Training loss: 1.4403858184814453
Validation loss: 1.9972589836325696

Epoch: 6| Step: 13
Training loss: 1.8364359140396118
Validation loss: 2.0289625762611307

Epoch: 269| Step: 0
Training loss: 1.763655424118042
Validation loss: 2.00634527590967

Epoch: 6| Step: 1
Training loss: 1.6946697235107422
Validation loss: 2.041140975490693

Epoch: 6| Step: 2
Training loss: 1.5258853435516357
Validation loss: 2.0083598667575466

Epoch: 6| Step: 3
Training loss: 2.026641845703125
Validation loss: 2.029217327794721

Epoch: 6| Step: 4
Training loss: 1.8763420581817627
Validation loss: 2.033604819287536

Epoch: 6| Step: 5
Training loss: 2.2002906799316406
Validation loss: 2.026716951401003

Epoch: 6| Step: 6
Training loss: 2.048194646835327
Validation loss: 2.007832439996863

Epoch: 6| Step: 7
Training loss: 2.1462903022766113
Validation loss: 2.0550810393466743

Epoch: 6| Step: 8
Training loss: 1.756502628326416
Validation loss: 2.049430990731844

Epoch: 6| Step: 9
Training loss: 1.5693416595458984
Validation loss: 2.036855464340538

Epoch: 6| Step: 10
Training loss: 1.6475601196289062
Validation loss: 1.9928892543238979

Epoch: 6| Step: 11
Training loss: 1.9617018699645996
Validation loss: 2.055159571350262

Epoch: 6| Step: 12
Training loss: 1.9824695587158203
Validation loss: 1.9979192454327819

Epoch: 6| Step: 13
Training loss: 1.9150434732437134
Validation loss: 2.0035930602781233

Epoch: 270| Step: 0
Training loss: 1.9287664890289307
Validation loss: 2.038723140634516

Epoch: 6| Step: 1
Training loss: 2.02620530128479
Validation loss: 2.01062391009382

Epoch: 6| Step: 2
Training loss: 1.9852097034454346
Validation loss: 2.027181645875336

Epoch: 6| Step: 3
Training loss: 1.9023163318634033
Validation loss: 2.0304724388225104

Epoch: 6| Step: 4
Training loss: 1.2759106159210205
Validation loss: 2.0478344963442896

Epoch: 6| Step: 5
Training loss: 1.5753769874572754
Validation loss: 2.0548022947003766

Epoch: 6| Step: 6
Training loss: 1.4367835521697998
Validation loss: 2.009576796203531

Epoch: 6| Step: 7
Training loss: 2.418348789215088
Validation loss: 2.0675112432049167

Epoch: 6| Step: 8
Training loss: 1.5958280563354492
Validation loss: 2.079425069593614

Epoch: 6| Step: 9
Training loss: 2.1772398948669434
Validation loss: 2.031769819157098

Epoch: 6| Step: 10
Training loss: 1.8041467666625977
Validation loss: 2.07413084788989

Epoch: 6| Step: 11
Training loss: 1.7095465660095215
Validation loss: 2.046668001400527

Epoch: 6| Step: 12
Training loss: 2.433485507965088
Validation loss: 2.0491053750438075

Epoch: 6| Step: 13
Training loss: 1.8781172037124634
Validation loss: 2.0553393953589985

Epoch: 271| Step: 0
Training loss: 1.3459994792938232
Validation loss: 2.051023913967994

Epoch: 6| Step: 1
Training loss: 1.527390718460083
Validation loss: 2.052829885995516

Epoch: 6| Step: 2
Training loss: 1.6725242137908936
Validation loss: 2.0751124761437856

Epoch: 6| Step: 3
Training loss: 1.5612146854400635
Validation loss: 2.013852810346952

Epoch: 6| Step: 4
Training loss: 1.919618010520935
Validation loss: 2.0591086367125153

Epoch: 6| Step: 5
Training loss: 1.9273407459259033
Validation loss: 2.026076360415387

Epoch: 6| Step: 6
Training loss: 1.5811353921890259
Validation loss: 2.0405771834875948

Epoch: 6| Step: 7
Training loss: 2.013723850250244
Validation loss: 2.0393650224131923

Epoch: 6| Step: 8
Training loss: 1.599492073059082
Validation loss: 2.0350693733461442

Epoch: 6| Step: 9
Training loss: 1.9589958190917969
Validation loss: 2.0189173298497356

Epoch: 6| Step: 10
Training loss: 1.8795177936553955
Validation loss: 1.9894543283729142

Epoch: 6| Step: 11
Training loss: 2.875549793243408
Validation loss: 2.0306093115960397

Epoch: 6| Step: 12
Training loss: 1.7031660079956055
Validation loss: 2.0262903526265132

Epoch: 6| Step: 13
Training loss: 1.9206891059875488
Validation loss: 2.033486559826841

Epoch: 272| Step: 0
Training loss: 1.821922779083252
Validation loss: 1.9881829356634488

Epoch: 6| Step: 1
Training loss: 1.1347671747207642
Validation loss: 2.0308454036712646

Epoch: 6| Step: 2
Training loss: 1.517973780632019
Validation loss: 2.035471280415853

Epoch: 6| Step: 3
Training loss: 2.409055233001709
Validation loss: 2.0365932731218237

Epoch: 6| Step: 4
Training loss: 3.112474203109741
Validation loss: 2.0511475916831725

Epoch: 6| Step: 5
Training loss: 2.0808258056640625
Validation loss: 2.005847771962484

Epoch: 6| Step: 6
Training loss: 1.8240715265274048
Validation loss: 2.028889371502784

Epoch: 6| Step: 7
Training loss: 1.082301378250122
Validation loss: 2.053221535939042

Epoch: 6| Step: 8
Training loss: 1.5970869064331055
Validation loss: 2.0377038063541537

Epoch: 6| Step: 9
Training loss: 2.251298666000366
Validation loss: 2.032558830835486

Epoch: 6| Step: 10
Training loss: 1.7211921215057373
Validation loss: 2.023938840435397

Epoch: 6| Step: 11
Training loss: 2.1910204887390137
Validation loss: 2.0322195458155807

Epoch: 6| Step: 12
Training loss: 1.4803277254104614
Validation loss: 1.994562913012761

Epoch: 6| Step: 13
Training loss: 1.76199471950531
Validation loss: 2.03937219419787

Epoch: 273| Step: 0
Training loss: 1.5549542903900146
Validation loss: 2.0314358870188394

Epoch: 6| Step: 1
Training loss: 2.5931477546691895
Validation loss: 2.0435385011857554

Epoch: 6| Step: 2
Training loss: 1.0828845500946045
Validation loss: 2.0452476637337798

Epoch: 6| Step: 3
Training loss: 2.557767629623413
Validation loss: 2.0618740538115143

Epoch: 6| Step: 4
Training loss: 1.124173879623413
Validation loss: 2.0519946134218605

Epoch: 6| Step: 5
Training loss: 2.1909008026123047
Validation loss: 2.0398485173461256

Epoch: 6| Step: 6
Training loss: 1.4711426496505737
Validation loss: 2.0304975355825117

Epoch: 6| Step: 7
Training loss: 2.4157087802886963
Validation loss: 2.0252343018849692

Epoch: 6| Step: 8
Training loss: 1.6352407932281494
Validation loss: 1.9754422121150519

Epoch: 6| Step: 9
Training loss: 1.7903835773468018
Validation loss: 2.0396092296928487

Epoch: 6| Step: 10
Training loss: 2.0644044876098633
Validation loss: 1.9936448374102194

Epoch: 6| Step: 11
Training loss: 1.852812647819519
Validation loss: 2.010947850442702

Epoch: 6| Step: 12
Training loss: 1.71448814868927
Validation loss: 2.0261873070911696

Epoch: 6| Step: 13
Training loss: 2.1737453937530518
Validation loss: 2.0223616464163667

Epoch: 274| Step: 0
Training loss: 1.9555643796920776
Validation loss: 2.062993739240913

Epoch: 6| Step: 1
Training loss: 1.9054272174835205
Validation loss: 2.0080481395926526

Epoch: 6| Step: 2
Training loss: 1.8176149129867554
Validation loss: 2.0533016971362534

Epoch: 6| Step: 3
Training loss: 1.8048113584518433
Validation loss: 2.0688266574695544

Epoch: 6| Step: 4
Training loss: 2.2850868701934814
Validation loss: 2.050599144351098

Epoch: 6| Step: 5
Training loss: 1.8427518606185913
Validation loss: 2.052164791732706

Epoch: 6| Step: 6
Training loss: 1.5783684253692627
Validation loss: 2.0684986460593437

Epoch: 6| Step: 7
Training loss: 1.9782553911209106
Validation loss: 2.043443282445272

Epoch: 6| Step: 8
Training loss: 1.5966551303863525
Validation loss: 2.0410202292985815

Epoch: 6| Step: 9
Training loss: 1.8740147352218628
Validation loss: 2.052510330753942

Epoch: 6| Step: 10
Training loss: 1.5176234245300293
Validation loss: 2.0518429612600677

Epoch: 6| Step: 11
Training loss: 1.961852788925171
Validation loss: 1.9983045080656647

Epoch: 6| Step: 12
Training loss: 2.224299192428589
Validation loss: 2.04810510143157

Epoch: 6| Step: 13
Training loss: 1.3141616582870483
Validation loss: 2.060784650105302

Epoch: 275| Step: 0
Training loss: 1.9415802955627441
Validation loss: 2.053832123356481

Epoch: 6| Step: 1
Training loss: 2.2241005897521973
Validation loss: 2.027922486746183

Epoch: 6| Step: 2
Training loss: 1.7483797073364258
Validation loss: 2.0207536143641316

Epoch: 6| Step: 3
Training loss: 1.6106212139129639
Validation loss: 2.0346436051912207

Epoch: 6| Step: 4
Training loss: 2.1094799041748047
Validation loss: 2.025776228597087

Epoch: 6| Step: 5
Training loss: 1.6626447439193726
Validation loss: 2.042398691177368

Epoch: 6| Step: 6
Training loss: 2.1121621131896973
Validation loss: 2.0117262704398042

Epoch: 6| Step: 7
Training loss: 1.5120627880096436
Validation loss: 2.032287041346232

Epoch: 6| Step: 8
Training loss: 1.8543773889541626
Validation loss: 2.0161485569451445

Epoch: 6| Step: 9
Training loss: 1.952570915222168
Validation loss: 2.0215024281573553

Epoch: 6| Step: 10
Training loss: 1.5586295127868652
Validation loss: 2.0412842368566864

Epoch: 6| Step: 11
Training loss: 2.1074957847595215
Validation loss: 2.021704339211987

Epoch: 6| Step: 12
Training loss: 1.4206657409667969
Validation loss: 2.0605850501727034

Epoch: 6| Step: 13
Training loss: 1.8096097707748413
Validation loss: 2.0250145645551783

Epoch: 276| Step: 0
Training loss: 2.0265491008758545
Validation loss: 2.0216249676160913

Epoch: 6| Step: 1
Training loss: 1.7856816053390503
Validation loss: 1.9919090706815001

Epoch: 6| Step: 2
Training loss: 1.5459628105163574
Validation loss: 2.044752574736072

Epoch: 6| Step: 3
Training loss: 1.3099896907806396
Validation loss: 2.008369739337634

Epoch: 6| Step: 4
Training loss: 1.7964763641357422
Validation loss: 2.017507481318648

Epoch: 6| Step: 5
Training loss: 1.997792363166809
Validation loss: 2.027069910880058

Epoch: 6| Step: 6
Training loss: 1.75360107421875
Validation loss: 2.0141651527855986

Epoch: 6| Step: 7
Training loss: 1.9388799667358398
Validation loss: 2.0041082597547963

Epoch: 6| Step: 8
Training loss: 2.0837197303771973
Validation loss: 2.0502914254383375

Epoch: 6| Step: 9
Training loss: 2.424988269805908
Validation loss: 2.0047062238057456

Epoch: 6| Step: 10
Training loss: 1.8464241027832031
Validation loss: 2.0432654606398715

Epoch: 6| Step: 11
Training loss: 2.445599317550659
Validation loss: 2.030927365826022

Epoch: 6| Step: 12
Training loss: 1.2392778396606445
Validation loss: 2.0115833103015857

Epoch: 6| Step: 13
Training loss: 1.3704888820648193
Validation loss: 2.0714784745247132

Epoch: 277| Step: 0
Training loss: 1.3310489654541016
Validation loss: 2.041544896300121

Epoch: 6| Step: 1
Training loss: 1.4507977962493896
Validation loss: 2.0688047947422152

Epoch: 6| Step: 2
Training loss: 2.289217948913574
Validation loss: 2.087924731675015

Epoch: 6| Step: 3
Training loss: 2.6014506816864014
Validation loss: 2.0316457671503865

Epoch: 6| Step: 4
Training loss: 1.7040746212005615
Validation loss: 2.057143001146214

Epoch: 6| Step: 5
Training loss: 1.9281013011932373
Validation loss: 2.0559198112897974

Epoch: 6| Step: 6
Training loss: 2.1612470149993896
Validation loss: 2.0511277760228803

Epoch: 6| Step: 7
Training loss: 1.6905596256256104
Validation loss: 2.0787399763702066

Epoch: 6| Step: 8
Training loss: 2.001145124435425
Validation loss: 2.067763674643732

Epoch: 6| Step: 9
Training loss: 2.038302421569824
Validation loss: 2.0553461044065413

Epoch: 6| Step: 10
Training loss: 1.340027093887329
Validation loss: 2.056780466469385

Epoch: 6| Step: 11
Training loss: 1.4939931631088257
Validation loss: 2.046418741185178

Epoch: 6| Step: 12
Training loss: 1.6977698802947998
Validation loss: 2.0298413973982616

Epoch: 6| Step: 13
Training loss: 2.216063976287842
Validation loss: 2.034018216594573

Epoch: 278| Step: 0
Training loss: 1.6450912952423096
Validation loss: 2.063442302006547

Epoch: 6| Step: 1
Training loss: 1.4358315467834473
Validation loss: 2.0145065553726687

Epoch: 6| Step: 2
Training loss: 1.9299383163452148
Validation loss: 2.0193268714412564

Epoch: 6| Step: 3
Training loss: 1.141378402709961
Validation loss: 2.0425166494102887

Epoch: 6| Step: 4
Training loss: 2.5985231399536133
Validation loss: 2.0372159737412647

Epoch: 6| Step: 5
Training loss: 1.5983866453170776
Validation loss: 2.026396307893979

Epoch: 6| Step: 6
Training loss: 2.0215070247650146
Validation loss: 2.0297341128831268

Epoch: 6| Step: 7
Training loss: 1.7576276063919067
Validation loss: 1.990628550129552

Epoch: 6| Step: 8
Training loss: 2.0985100269317627
Validation loss: 2.0377742372533327

Epoch: 6| Step: 9
Training loss: 1.7093539237976074
Validation loss: 2.009542079382045

Epoch: 6| Step: 10
Training loss: 1.8441752195358276
Validation loss: 2.001701529308032

Epoch: 6| Step: 11
Training loss: 1.7416441440582275
Validation loss: 2.0248586541862896

Epoch: 6| Step: 12
Training loss: 2.3154516220092773
Validation loss: 2.057654849944576

Epoch: 6| Step: 13
Training loss: 2.3444736003875732
Validation loss: 1.9992916353287236

Epoch: 279| Step: 0
Training loss: 1.1788625717163086
Validation loss: 2.012485375968359

Epoch: 6| Step: 1
Training loss: 1.4742538928985596
Validation loss: 2.0136261460601643

Epoch: 6| Step: 2
Training loss: 2.5118656158447266
Validation loss: 2.029418881221484

Epoch: 6| Step: 3
Training loss: 1.9395949840545654
Validation loss: 1.9973993211664178

Epoch: 6| Step: 4
Training loss: 1.450247049331665
Validation loss: 2.0229832446703346

Epoch: 6| Step: 5
Training loss: 1.772157907485962
Validation loss: 2.029321211640553

Epoch: 6| Step: 6
Training loss: 1.970108985900879
Validation loss: 2.047955177163565

Epoch: 6| Step: 7
Training loss: 1.7837731838226318
Validation loss: 2.0063232606457126

Epoch: 6| Step: 8
Training loss: 1.732527494430542
Validation loss: 2.07487045052231

Epoch: 6| Step: 9
Training loss: 2.786731004714966
Validation loss: 2.03647280252108

Epoch: 6| Step: 10
Training loss: 2.2021617889404297
Validation loss: 2.0770341670641335

Epoch: 6| Step: 11
Training loss: 1.6486778259277344
Validation loss: 2.0457608789526005

Epoch: 6| Step: 12
Training loss: 1.7154513597488403
Validation loss: 2.012618196907864

Epoch: 6| Step: 13
Training loss: 1.4257842302322388
Validation loss: 2.0311621235262964

Epoch: 280| Step: 0
Training loss: 1.507643699645996
Validation loss: 2.074973148684348

Epoch: 6| Step: 1
Training loss: 1.750246524810791
Validation loss: 2.0691560135092786

Epoch: 6| Step: 2
Training loss: 2.073554277420044
Validation loss: 1.9855669493316321

Epoch: 6| Step: 3
Training loss: 1.502218246459961
Validation loss: 2.0481205601846018

Epoch: 6| Step: 4
Training loss: 2.346888542175293
Validation loss: 2.0356568521068943

Epoch: 6| Step: 5
Training loss: 1.8156429529190063
Validation loss: 2.040265558868326

Epoch: 6| Step: 6
Training loss: 1.9996404647827148
Validation loss: 1.9811715284983318

Epoch: 6| Step: 7
Training loss: 1.5100247859954834
Validation loss: 2.0368608505495134

Epoch: 6| Step: 8
Training loss: 2.119734525680542
Validation loss: 2.0236647282877276

Epoch: 6| Step: 9
Training loss: 2.3008453845977783
Validation loss: 2.0289967367725987

Epoch: 6| Step: 10
Training loss: 2.112569570541382
Validation loss: 2.009590005361906

Epoch: 6| Step: 11
Training loss: 1.8585073947906494
Validation loss: 2.0127017664653

Epoch: 6| Step: 12
Training loss: 1.313894271850586
Validation loss: 2.005869303980181

Epoch: 6| Step: 13
Training loss: 1.323362946510315
Validation loss: 2.039614908156856

Epoch: 281| Step: 0
Training loss: 2.1460423469543457
Validation loss: 2.055994754196495

Epoch: 6| Step: 1
Training loss: 1.583456039428711
Validation loss: 2.0239455315374557

Epoch: 6| Step: 2
Training loss: 1.4996767044067383
Validation loss: 2.0940671133738693

Epoch: 6| Step: 3
Training loss: 1.842534065246582
Validation loss: 2.0528352927136164

Epoch: 6| Step: 4
Training loss: 1.812826156616211
Validation loss: 2.0387132462634834

Epoch: 6| Step: 5
Training loss: 1.4983866214752197
Validation loss: 2.053467345494096

Epoch: 6| Step: 6
Training loss: 1.3178433179855347
Validation loss: 2.029083041734593

Epoch: 6| Step: 7
Training loss: 1.9227135181427002
Validation loss: 2.0345063337715725

Epoch: 6| Step: 8
Training loss: 1.9334713220596313
Validation loss: 2.0244113001772153

Epoch: 6| Step: 9
Training loss: 1.8838701248168945
Validation loss: 2.027086482253126

Epoch: 6| Step: 10
Training loss: 1.7789556980133057
Validation loss: 2.0590845051632134

Epoch: 6| Step: 11
Training loss: 1.8901253938674927
Validation loss: 2.0223896221448014

Epoch: 6| Step: 12
Training loss: 2.533548593521118
Validation loss: 2.0334557833210116

Epoch: 6| Step: 13
Training loss: 2.1324079036712646
Validation loss: 2.053023633136544

Epoch: 282| Step: 0
Training loss: 1.5703368186950684
Validation loss: 2.0461768040093045

Epoch: 6| Step: 1
Training loss: 1.721449613571167
Validation loss: 2.075964488008971

Epoch: 6| Step: 2
Training loss: 1.948535442352295
Validation loss: 2.0257367933950117

Epoch: 6| Step: 3
Training loss: 1.8754408359527588
Validation loss: 2.0163778938272947

Epoch: 6| Step: 4
Training loss: 2.383328437805176
Validation loss: 2.00195288401778

Epoch: 6| Step: 5
Training loss: 2.153928279876709
Validation loss: 2.032893641020662

Epoch: 6| Step: 6
Training loss: 1.638363003730774
Validation loss: 2.0293936549976306

Epoch: 6| Step: 7
Training loss: 1.7525813579559326
Validation loss: 2.0160954049838486

Epoch: 6| Step: 8
Training loss: 1.7347145080566406
Validation loss: 2.0265397666603007

Epoch: 6| Step: 9
Training loss: 1.7629647254943848
Validation loss: 2.0579238002018263

Epoch: 6| Step: 10
Training loss: 1.7847908735275269
Validation loss: 2.029189617403092

Epoch: 6| Step: 11
Training loss: 1.574751853942871
Validation loss: 2.0108750917578257

Epoch: 6| Step: 12
Training loss: 1.650663137435913
Validation loss: 1.9949014443223194

Epoch: 6| Step: 13
Training loss: 2.1272330284118652
Validation loss: 2.0079105323360813

Epoch: 283| Step: 0
Training loss: 2.222921133041382
Validation loss: 2.0123175587705386

Epoch: 6| Step: 1
Training loss: 1.6626513004302979
Validation loss: 2.036166834574874

Epoch: 6| Step: 2
Training loss: 1.9103392362594604
Validation loss: 2.0583903187064716

Epoch: 6| Step: 3
Training loss: 1.7067890167236328
Validation loss: 2.0230611216637397

Epoch: 6| Step: 4
Training loss: 1.4057856798171997
Validation loss: 2.06381816505104

Epoch: 6| Step: 5
Training loss: 2.616394519805908
Validation loss: 2.02164658423393

Epoch: 6| Step: 6
Training loss: 1.163480520248413
Validation loss: 2.027230183283488

Epoch: 6| Step: 7
Training loss: 2.2303085327148438
Validation loss: 2.038017306276547

Epoch: 6| Step: 8
Training loss: 2.18202543258667
Validation loss: 2.0618349775191276

Epoch: 6| Step: 9
Training loss: 1.3830530643463135
Validation loss: 2.0229730426624255

Epoch: 6| Step: 10
Training loss: 1.7498207092285156
Validation loss: 2.0167821581645677

Epoch: 6| Step: 11
Training loss: 1.7675046920776367
Validation loss: 2.04204055570787

Epoch: 6| Step: 12
Training loss: 1.949008822441101
Validation loss: 2.0160009476446334

Epoch: 6| Step: 13
Training loss: 1.3960069417953491
Validation loss: 2.06038555406755

Epoch: 284| Step: 0
Training loss: 1.9626851081848145
Validation loss: 2.0388359869680097

Epoch: 6| Step: 1
Training loss: 2.2524781227111816
Validation loss: 2.012857828088986

Epoch: 6| Step: 2
Training loss: 1.5196263790130615
Validation loss: 2.016965575115655

Epoch: 6| Step: 3
Training loss: 1.526298999786377
Validation loss: 2.0097944505753054

Epoch: 6| Step: 4
Training loss: 1.858340859413147
Validation loss: 2.0359259164461525

Epoch: 6| Step: 5
Training loss: 1.7440760135650635
Validation loss: 2.040516144485884

Epoch: 6| Step: 6
Training loss: 1.9689676761627197
Validation loss: 1.9994327919457549

Epoch: 6| Step: 7
Training loss: 2.123819351196289
Validation loss: 1.9999780552361601

Epoch: 6| Step: 8
Training loss: 1.862757682800293
Validation loss: 2.0291006539457586

Epoch: 6| Step: 9
Training loss: 2.5250370502471924
Validation loss: 2.0190053742419005

Epoch: 6| Step: 10
Training loss: 1.4518587589263916
Validation loss: 2.0368458904245847

Epoch: 6| Step: 11
Training loss: 2.2266759872436523
Validation loss: 2.047671861546014

Epoch: 6| Step: 12
Training loss: 1.0183303356170654
Validation loss: 2.037789862643006

Epoch: 6| Step: 13
Training loss: 1.6217164993286133
Validation loss: 2.0066154105688936

Epoch: 285| Step: 0
Training loss: 1.8862082958221436
Validation loss: 2.0584569784902755

Epoch: 6| Step: 1
Training loss: 1.9302163124084473
Validation loss: 2.0556349523605837

Epoch: 6| Step: 2
Training loss: 1.472374677658081
Validation loss: 2.064751458424394

Epoch: 6| Step: 3
Training loss: 1.7672299146652222
Validation loss: 2.0500297213113434

Epoch: 6| Step: 4
Training loss: 2.2463479042053223
Validation loss: 2.051827266652097

Epoch: 6| Step: 5
Training loss: 1.3666737079620361
Validation loss: 2.060417195802094

Epoch: 6| Step: 6
Training loss: 1.9050111770629883
Validation loss: 2.096265838992211

Epoch: 6| Step: 7
Training loss: 1.6198481321334839
Validation loss: 2.0577470256436254

Epoch: 6| Step: 8
Training loss: 2.2321863174438477
Validation loss: 2.0800650478691183

Epoch: 6| Step: 9
Training loss: 2.40255069732666
Validation loss: 2.105556241927608

Epoch: 6| Step: 10
Training loss: 1.3995802402496338
Validation loss: 2.0889700343531947

Epoch: 6| Step: 11
Training loss: 1.7278680801391602
Validation loss: 2.0931701993429535

Epoch: 6| Step: 12
Training loss: 2.3329355716705322
Validation loss: 2.0715208489407777

Epoch: 6| Step: 13
Training loss: 0.8873304128646851
Validation loss: 2.063224166952154

Epoch: 286| Step: 0
Training loss: 2.0852138996124268
Validation loss: 2.041631233307623

Epoch: 6| Step: 1
Training loss: 1.7468581199645996
Validation loss: 2.0556334500671714

Epoch: 6| Step: 2
Training loss: 1.6351947784423828
Validation loss: 2.0497408861755044

Epoch: 6| Step: 3
Training loss: 1.9677780866622925
Validation loss: 2.039635891555458

Epoch: 6| Step: 4
Training loss: 1.8309214115142822
Validation loss: 2.0563284607343775

Epoch: 6| Step: 5
Training loss: 2.5715270042419434
Validation loss: 2.0112184850118493

Epoch: 6| Step: 6
Training loss: 2.169877767562866
Validation loss: 2.0132756694670646

Epoch: 6| Step: 7
Training loss: 2.1182408332824707
Validation loss: 2.0338749783013457

Epoch: 6| Step: 8
Training loss: 1.5865254402160645
Validation loss: 2.0245712431528236

Epoch: 6| Step: 9
Training loss: 1.2942107915878296
Validation loss: 2.017521063486735

Epoch: 6| Step: 10
Training loss: 1.0433907508850098
Validation loss: 1.9937382385294924

Epoch: 6| Step: 11
Training loss: 2.0661683082580566
Validation loss: 2.0263652763059063

Epoch: 6| Step: 12
Training loss: 1.7874457836151123
Validation loss: 2.0430403460738478

Epoch: 6| Step: 13
Training loss: 1.5814735889434814
Validation loss: 2.032212139457785

Epoch: 287| Step: 0
Training loss: 1.8516294956207275
Validation loss: 2.007047112270068

Epoch: 6| Step: 1
Training loss: 2.1134777069091797
Validation loss: 2.008845288266418

Epoch: 6| Step: 2
Training loss: 1.8748013973236084
Validation loss: 2.0515117863173127

Epoch: 6| Step: 3
Training loss: 1.7389442920684814
Validation loss: 2.0242456197738647

Epoch: 6| Step: 4
Training loss: 2.129523992538452
Validation loss: 2.0194713851457

Epoch: 6| Step: 5
Training loss: 2.0388059616088867
Validation loss: 2.093527922066309

Epoch: 6| Step: 6
Training loss: 2.240886688232422
Validation loss: 2.0623343606148996

Epoch: 6| Step: 7
Training loss: 1.396350622177124
Validation loss: 2.0413265587181173

Epoch: 6| Step: 8
Training loss: 0.9801523685455322
Validation loss: 2.0557373262220815

Epoch: 6| Step: 9
Training loss: 1.882430076599121
Validation loss: 2.04619998188429

Epoch: 6| Step: 10
Training loss: 1.8789904117584229
Validation loss: 2.05952751123777

Epoch: 6| Step: 11
Training loss: 1.8469103574752808
Validation loss: 2.042516269991475

Epoch: 6| Step: 12
Training loss: 1.5848708152770996
Validation loss: 2.0523713083677393

Epoch: 6| Step: 13
Training loss: 1.8892974853515625
Validation loss: 2.031747500101725

Epoch: 288| Step: 0
Training loss: 1.7242026329040527
Validation loss: 2.0426213561847644

Epoch: 6| Step: 1
Training loss: 1.5585899353027344
Validation loss: 2.033023213827482

Epoch: 6| Step: 2
Training loss: 1.5334231853485107
Validation loss: 2.041478116025207

Epoch: 6| Step: 3
Training loss: 2.122469186782837
Validation loss: 2.01252398695997

Epoch: 6| Step: 4
Training loss: 1.994694471359253
Validation loss: 2.0256040429556244

Epoch: 6| Step: 5
Training loss: 2.0774896144866943
Validation loss: 2.046157572859077

Epoch: 6| Step: 6
Training loss: 1.7778911590576172
Validation loss: 2.038975497727753

Epoch: 6| Step: 7
Training loss: 1.0568819046020508
Validation loss: 2.0305885730251187

Epoch: 6| Step: 8
Training loss: 1.7539632320404053
Validation loss: 2.0627620579094015

Epoch: 6| Step: 9
Training loss: 1.216968059539795
Validation loss: 2.0694966726405646

Epoch: 6| Step: 10
Training loss: 2.128417491912842
Validation loss: 2.073219653098814

Epoch: 6| Step: 11
Training loss: 2.126948356628418
Validation loss: 2.0166730675646054

Epoch: 6| Step: 12
Training loss: 2.5015406608581543
Validation loss: 2.0429350842711744

Epoch: 6| Step: 13
Training loss: 1.8860135078430176
Validation loss: 2.030624229420898

Epoch: 289| Step: 0
Training loss: 1.7352490425109863
Validation loss: 2.0327734075566775

Epoch: 6| Step: 1
Training loss: 1.8070604801177979
Validation loss: 2.0476455624385546

Epoch: 6| Step: 2
Training loss: 1.5661532878875732
Validation loss: 2.0233093974410847

Epoch: 6| Step: 3
Training loss: 2.0589256286621094
Validation loss: 2.043270944267191

Epoch: 6| Step: 4
Training loss: 1.2687753438949585
Validation loss: 2.0203666610102498

Epoch: 6| Step: 5
Training loss: 2.186476707458496
Validation loss: 1.9915230094745595

Epoch: 6| Step: 6
Training loss: 2.1736464500427246
Validation loss: 2.0308152552573913

Epoch: 6| Step: 7
Training loss: 1.8583335876464844
Validation loss: 2.0049118072755876

Epoch: 6| Step: 8
Training loss: 1.7478539943695068
Validation loss: 2.0167860574619745

Epoch: 6| Step: 9
Training loss: 2.0648727416992188
Validation loss: 2.030046357903429

Epoch: 6| Step: 10
Training loss: 1.5992484092712402
Validation loss: 2.0234748009712464

Epoch: 6| Step: 11
Training loss: 1.791290521621704
Validation loss: 2.0310193620702273

Epoch: 6| Step: 12
Training loss: 1.5743093490600586
Validation loss: 2.0225834051767984

Epoch: 6| Step: 13
Training loss: 2.276076078414917
Validation loss: 2.0454007822980165

Epoch: 290| Step: 0
Training loss: 1.9964323043823242
Validation loss: 2.016836817546557

Epoch: 6| Step: 1
Training loss: 1.8263676166534424
Validation loss: 2.0363711823699293

Epoch: 6| Step: 2
Training loss: 1.3150310516357422
Validation loss: 2.0578887026797057

Epoch: 6| Step: 3
Training loss: 1.7462464570999146
Validation loss: 2.035844638783445

Epoch: 6| Step: 4
Training loss: 2.0133724212646484
Validation loss: 2.014878487074247

Epoch: 6| Step: 5
Training loss: 2.2153191566467285
Validation loss: 2.030386265888009

Epoch: 6| Step: 6
Training loss: 2.201706886291504
Validation loss: 2.0296790522913777

Epoch: 6| Step: 7
Training loss: 1.9325522184371948
Validation loss: 2.032987659977328

Epoch: 6| Step: 8
Training loss: 1.0703411102294922
Validation loss: 2.0704470501151135

Epoch: 6| Step: 9
Training loss: 1.6574959754943848
Validation loss: 2.039055267969767

Epoch: 6| Step: 10
Training loss: 1.6061573028564453
Validation loss: 2.0724917368222306

Epoch: 6| Step: 11
Training loss: 2.031672477722168
Validation loss: 2.0261353138954408

Epoch: 6| Step: 12
Training loss: 1.995482087135315
Validation loss: 2.0332344988340973

Epoch: 6| Step: 13
Training loss: 1.607202172279358
Validation loss: 2.0523040525374876

Epoch: 291| Step: 0
Training loss: 1.3150030374526978
Validation loss: 2.087803211263431

Epoch: 6| Step: 1
Training loss: 2.1952414512634277
Validation loss: 2.066483069491643

Epoch: 6| Step: 2
Training loss: 1.4380723237991333
Validation loss: 2.0679895083109536

Epoch: 6| Step: 3
Training loss: 2.2680115699768066
Validation loss: 2.0317518505998837

Epoch: 6| Step: 4
Training loss: 2.0909807682037354
Validation loss: 2.0388432138709613

Epoch: 6| Step: 5
Training loss: 2.2753098011016846
Validation loss: 2.054000759637484

Epoch: 6| Step: 6
Training loss: 2.4239070415496826
Validation loss: 2.067058822160126

Epoch: 6| Step: 7
Training loss: 1.962432861328125
Validation loss: 2.052901660242388

Epoch: 6| Step: 8
Training loss: 1.6922215223312378
Validation loss: 2.050567844862579

Epoch: 6| Step: 9
Training loss: 0.8335703611373901
Validation loss: 2.061620848153227

Epoch: 6| Step: 10
Training loss: 2.020937442779541
Validation loss: 2.0531455034850747

Epoch: 6| Step: 11
Training loss: 1.8330879211425781
Validation loss: 2.0811113760035527

Epoch: 6| Step: 12
Training loss: 1.580538272857666
Validation loss: 2.0539238401638564

Epoch: 6| Step: 13
Training loss: 1.2366327047348022
Validation loss: 2.057116962248279

Epoch: 292| Step: 0
Training loss: 1.2703907489776611
Validation loss: 2.0368621656971593

Epoch: 6| Step: 1
Training loss: 1.9955182075500488
Validation loss: 2.0607083638509116

Epoch: 6| Step: 2
Training loss: 1.9765219688415527
Validation loss: 2.0539771843982

Epoch: 6| Step: 3
Training loss: 1.4371644258499146
Validation loss: 2.044949634100801

Epoch: 6| Step: 4
Training loss: 1.6615581512451172
Validation loss: 2.068965427337154

Epoch: 6| Step: 5
Training loss: 1.8574705123901367
Validation loss: 2.0317113168777956

Epoch: 6| Step: 6
Training loss: 1.5259130001068115
Validation loss: 2.015440735765683

Epoch: 6| Step: 7
Training loss: 1.6972336769104004
Validation loss: 2.0248290261914654

Epoch: 6| Step: 8
Training loss: 1.517060399055481
Validation loss: 2.0514992590873473

Epoch: 6| Step: 9
Training loss: 2.575960159301758
Validation loss: 2.0302591682762228

Epoch: 6| Step: 10
Training loss: 1.7755217552185059
Validation loss: 2.040543403676761

Epoch: 6| Step: 11
Training loss: 2.048337459564209
Validation loss: 2.0458387508187243

Epoch: 6| Step: 12
Training loss: 2.511101484298706
Validation loss: 2.015463941840715

Epoch: 6| Step: 13
Training loss: 1.2583831548690796
Validation loss: 2.015088783797397

Epoch: 293| Step: 0
Training loss: 1.864132285118103
Validation loss: 2.036646648119855

Epoch: 6| Step: 1
Training loss: 2.351334571838379
Validation loss: 2.0275017497360066

Epoch: 6| Step: 2
Training loss: 1.693878173828125
Validation loss: 2.014554778734843

Epoch: 6| Step: 3
Training loss: 1.3047834634780884
Validation loss: 2.027832720869331

Epoch: 6| Step: 4
Training loss: 1.5275633335113525
Validation loss: 2.033440738595942

Epoch: 6| Step: 5
Training loss: 1.4047191143035889
Validation loss: 2.0512182968918995

Epoch: 6| Step: 6
Training loss: 2.4355502128601074
Validation loss: 2.029102853549424

Epoch: 6| Step: 7
Training loss: 1.5384421348571777
Validation loss: 2.0948236450072257

Epoch: 6| Step: 8
Training loss: 1.4285407066345215
Validation loss: 2.014991294953131

Epoch: 6| Step: 9
Training loss: 1.9471056461334229
Validation loss: 2.0459504024956816

Epoch: 6| Step: 10
Training loss: 2.1437268257141113
Validation loss: 2.0118533116514965

Epoch: 6| Step: 11
Training loss: 2.112205982208252
Validation loss: 2.0380670639776413

Epoch: 6| Step: 12
Training loss: 2.3140292167663574
Validation loss: 2.0179485979900567

Epoch: 6| Step: 13
Training loss: 0.8673251867294312
Validation loss: 2.028387377339025

Epoch: 294| Step: 0
Training loss: 1.9661991596221924
Validation loss: 2.0375428635586976

Epoch: 6| Step: 1
Training loss: 1.7335511445999146
Validation loss: 2.0094877340460338

Epoch: 6| Step: 2
Training loss: 1.797832727432251
Validation loss: 2.0170610963657336

Epoch: 6| Step: 3
Training loss: 2.529106616973877
Validation loss: 1.9989691985550748

Epoch: 6| Step: 4
Training loss: 1.8288016319274902
Validation loss: 2.0374422945002073

Epoch: 6| Step: 5
Training loss: 1.8800581693649292
Validation loss: 2.0088179778027278

Epoch: 6| Step: 6
Training loss: 1.244619369506836
Validation loss: 2.000884226573411

Epoch: 6| Step: 7
Training loss: 2.224865436553955
Validation loss: 2.059929927190145

Epoch: 6| Step: 8
Training loss: 1.6735210418701172
Validation loss: 2.0117101425765664

Epoch: 6| Step: 9
Training loss: 1.8593428134918213
Validation loss: 2.018529509985319

Epoch: 6| Step: 10
Training loss: 1.6603623628616333
Validation loss: 2.030513894173407

Epoch: 6| Step: 11
Training loss: 1.577480435371399
Validation loss: 2.024760312931512

Epoch: 6| Step: 12
Training loss: 1.7170982360839844
Validation loss: 2.011709767003213

Epoch: 6| Step: 13
Training loss: 1.1086381673812866
Validation loss: 2.0585356861032467

Epoch: 295| Step: 0
Training loss: 1.6347360610961914
Validation loss: 2.0472313306664907

Epoch: 6| Step: 1
Training loss: 1.6915289163589478
Validation loss: 2.0507067916213826

Epoch: 6| Step: 2
Training loss: 1.2673742771148682
Validation loss: 2.041148381848489

Epoch: 6| Step: 3
Training loss: 1.5270003080368042
Validation loss: 2.05052371691632

Epoch: 6| Step: 4
Training loss: 1.913853645324707
Validation loss: 2.04410598867683

Epoch: 6| Step: 5
Training loss: 1.2071187496185303
Validation loss: 2.032166609200098

Epoch: 6| Step: 6
Training loss: 2.5430188179016113
Validation loss: 2.0241774769239527

Epoch: 6| Step: 7
Training loss: 1.3258885145187378
Validation loss: 2.060430380605882

Epoch: 6| Step: 8
Training loss: 1.8959226608276367
Validation loss: 2.0314222715234243

Epoch: 6| Step: 9
Training loss: 1.696117639541626
Validation loss: 2.054404133109636

Epoch: 6| Step: 10
Training loss: 2.8134422302246094
Validation loss: 2.0656263136094615

Epoch: 6| Step: 11
Training loss: 2.1133623123168945
Validation loss: 2.0569902376462053

Epoch: 6| Step: 12
Training loss: 2.080040454864502
Validation loss: 2.072927631357665

Epoch: 6| Step: 13
Training loss: 1.754634141921997
Validation loss: 2.0793221663403254

Epoch: 296| Step: 0
Training loss: 0.9491177797317505
Validation loss: 2.020768297615872

Epoch: 6| Step: 1
Training loss: 1.1042542457580566
Validation loss: 1.9946132552239202

Epoch: 6| Step: 2
Training loss: 1.6077686548233032
Validation loss: 2.0327151167777275

Epoch: 6| Step: 3
Training loss: 1.9287972450256348
Validation loss: 2.02458744536164

Epoch: 6| Step: 4
Training loss: 1.9634575843811035
Validation loss: 2.0106628018040813

Epoch: 6| Step: 5
Training loss: 1.3946125507354736
Validation loss: 2.0178346480092695

Epoch: 6| Step: 6
Training loss: 2.5689001083374023
Validation loss: 2.0471461819064234

Epoch: 6| Step: 7
Training loss: 1.7340774536132812
Validation loss: 1.9926283180072744

Epoch: 6| Step: 8
Training loss: 1.7201271057128906
Validation loss: 2.0322383808833298

Epoch: 6| Step: 9
Training loss: 1.7686076164245605
Validation loss: 2.0041000637956845

Epoch: 6| Step: 10
Training loss: 2.1338508129119873
Validation loss: 1.9907462571256904

Epoch: 6| Step: 11
Training loss: 2.1066365242004395
Validation loss: 2.01510460786922

Epoch: 6| Step: 12
Training loss: 2.615236520767212
Validation loss: 2.022315109929731

Epoch: 6| Step: 13
Training loss: 1.4927781820297241
Validation loss: 2.014413745172562

Epoch: 297| Step: 0
Training loss: 2.2277541160583496
Validation loss: 2.0172733722194547

Epoch: 6| Step: 1
Training loss: 1.5511488914489746
Validation loss: 1.9958543649283789

Epoch: 6| Step: 2
Training loss: 1.8159254789352417
Validation loss: 2.0423416758096344

Epoch: 6| Step: 3
Training loss: 2.108410358428955
Validation loss: 2.036887356030044

Epoch: 6| Step: 4
Training loss: 1.873225450515747
Validation loss: 2.0268860196554535

Epoch: 6| Step: 5
Training loss: 2.1381022930145264
Validation loss: 2.044112705415295

Epoch: 6| Step: 6
Training loss: 2.2565622329711914
Validation loss: 2.06667039984016

Epoch: 6| Step: 7
Training loss: 1.6477384567260742
Validation loss: 2.0602471520823817

Epoch: 6| Step: 8
Training loss: 1.5727988481521606
Validation loss: 2.0390560242437545

Epoch: 6| Step: 9
Training loss: 1.4681990146636963
Validation loss: 2.0375042858944146

Epoch: 6| Step: 10
Training loss: 1.5351588726043701
Validation loss: 2.0591279639992663

Epoch: 6| Step: 11
Training loss: 1.7070260047912598
Validation loss: 2.017900493837172

Epoch: 6| Step: 12
Training loss: 1.7028132677078247
Validation loss: 2.024695240041261

Epoch: 6| Step: 13
Training loss: 1.4703660011291504
Validation loss: 1.986375901006883

Epoch: 298| Step: 0
Training loss: 1.3409569263458252
Validation loss: 2.0438232242420153

Epoch: 6| Step: 1
Training loss: 1.6704411506652832
Validation loss: 2.0248494994255806

Epoch: 6| Step: 2
Training loss: 2.1798272132873535
Validation loss: 2.019259541265426

Epoch: 6| Step: 3
Training loss: 1.869854211807251
Validation loss: 2.0111724561260593

Epoch: 6| Step: 4
Training loss: 0.8179623484611511
Validation loss: 1.983839254225454

Epoch: 6| Step: 5
Training loss: 2.2673721313476562
Validation loss: 2.0081739771750664

Epoch: 6| Step: 6
Training loss: 1.9543273448944092
Validation loss: 2.045031800064989

Epoch: 6| Step: 7
Training loss: 2.5653529167175293
Validation loss: 2.0169576188569427

Epoch: 6| Step: 8
Training loss: 1.5674846172332764
Validation loss: 2.0195025013339136

Epoch: 6| Step: 9
Training loss: 2.002873182296753
Validation loss: 2.0170690064789145

Epoch: 6| Step: 10
Training loss: 1.9335482120513916
Validation loss: 2.038556488611365

Epoch: 6| Step: 11
Training loss: 1.4899935722351074
Validation loss: 2.002953060211674

Epoch: 6| Step: 12
Training loss: 1.6963543891906738
Validation loss: 2.0377179448322584

Epoch: 6| Step: 13
Training loss: 2.1539413928985596
Validation loss: 2.002855552140103

Epoch: 299| Step: 0
Training loss: 1.4300872087478638
Validation loss: 2.015419255020798

Epoch: 6| Step: 1
Training loss: 1.9846293926239014
Validation loss: 2.070045742937314

Epoch: 6| Step: 2
Training loss: 1.3873374462127686
Validation loss: 2.03998928172614

Epoch: 6| Step: 3
Training loss: 1.6738593578338623
Validation loss: 2.0598667155029955

Epoch: 6| Step: 4
Training loss: 1.4053893089294434
Validation loss: 2.0401869845646683

Epoch: 6| Step: 5
Training loss: 1.3807730674743652
Validation loss: 2.05517029505904

Epoch: 6| Step: 6
Training loss: 2.1963448524475098
Validation loss: 2.077559935149326

Epoch: 6| Step: 7
Training loss: 1.7084728479385376
Validation loss: 2.063393008324408

Epoch: 6| Step: 8
Training loss: 1.9216407537460327
Validation loss: 2.0613766742008988

Epoch: 6| Step: 9
Training loss: 1.7660592794418335
Validation loss: 2.0330106340428835

Epoch: 6| Step: 10
Training loss: 1.5532341003417969
Validation loss: 2.033376823189438

Epoch: 6| Step: 11
Training loss: 2.733466148376465
Validation loss: 2.0422984374466764

Epoch: 6| Step: 12
Training loss: 1.8684799671173096
Validation loss: 2.0675511103804394

Epoch: 6| Step: 13
Training loss: 2.1926212310791016
Validation loss: 2.0195498338309665

Epoch: 300| Step: 0
Training loss: 1.6486971378326416
Validation loss: 2.0314733956449773

Epoch: 6| Step: 1
Training loss: 1.692011833190918
Validation loss: 2.0327172292176114

Epoch: 6| Step: 2
Training loss: 1.726827621459961
Validation loss: 2.0555011739013014

Epoch: 6| Step: 3
Training loss: 2.114748001098633
Validation loss: 2.02226855421579

Epoch: 6| Step: 4
Training loss: 2.1448206901550293
Validation loss: 2.026996651003438

Epoch: 6| Step: 5
Training loss: 2.3005361557006836
Validation loss: 2.034749892450148

Epoch: 6| Step: 6
Training loss: 1.9646791219711304
Validation loss: 2.0459342695051626

Epoch: 6| Step: 7
Training loss: 1.8178355693817139
Validation loss: 2.0324949295290056

Epoch: 6| Step: 8
Training loss: 1.839670181274414
Validation loss: 2.0530245227198445

Epoch: 6| Step: 9
Training loss: 2.0312864780426025
Validation loss: 2.0274955585438716

Epoch: 6| Step: 10
Training loss: 1.6750235557556152
Validation loss: 2.025464225840825

Epoch: 6| Step: 11
Training loss: 0.6964500546455383
Validation loss: 2.0427614873455417

Epoch: 6| Step: 12
Training loss: 1.6398706436157227
Validation loss: 2.041468593382066

Epoch: 6| Step: 13
Training loss: 2.012665271759033
Validation loss: 2.072763358393023

Epoch: 301| Step: 0
Training loss: 2.2870571613311768
Validation loss: 2.0503249168395996

Epoch: 6| Step: 1
Training loss: 2.1454648971557617
Validation loss: 2.0195943027414303

Epoch: 6| Step: 2
Training loss: 2.70845365524292
Validation loss: 2.006195769515089

Epoch: 6| Step: 3
Training loss: 2.3727529048919678
Validation loss: 2.0487805387025237

Epoch: 6| Step: 4
Training loss: 1.6595854759216309
Validation loss: 2.0639284836348666

Epoch: 6| Step: 5
Training loss: 1.7695415019989014
Validation loss: 2.0244375108390726

Epoch: 6| Step: 6
Training loss: 2.0237646102905273
Validation loss: 2.031238437980734

Epoch: 6| Step: 7
Training loss: 1.239109992980957
Validation loss: 2.0357826473892375

Epoch: 6| Step: 8
Training loss: 1.4628348350524902
Validation loss: 2.0403292614926576

Epoch: 6| Step: 9
Training loss: 1.357947826385498
Validation loss: 2.0180711412942536

Epoch: 6| Step: 10
Training loss: 0.8754944801330566
Validation loss: 2.0155020170314337

Epoch: 6| Step: 11
Training loss: 2.31002140045166
Validation loss: 2.0281697447581957

Epoch: 6| Step: 12
Training loss: 1.3359081745147705
Validation loss: 2.049958162410285

Epoch: 6| Step: 13
Training loss: 1.4287909269332886
Validation loss: 2.0253732178800847

Epoch: 302| Step: 0
Training loss: 1.7956583499908447
Validation loss: 1.9977652603580105

Epoch: 6| Step: 1
Training loss: 1.6821179389953613
Validation loss: 2.0426776896240892

Epoch: 6| Step: 2
Training loss: 1.2030773162841797
Validation loss: 2.0178260675040622

Epoch: 6| Step: 3
Training loss: 1.5702338218688965
Validation loss: 2.031932919256149

Epoch: 6| Step: 4
Training loss: 1.6619027853012085
Validation loss: 2.0357952758830082

Epoch: 6| Step: 5
Training loss: 1.942196011543274
Validation loss: 2.047595275345669

Epoch: 6| Step: 6
Training loss: 2.3897252082824707
Validation loss: 2.0580708557559597

Epoch: 6| Step: 7
Training loss: 1.4311189651489258
Validation loss: 2.0216025793424217

Epoch: 6| Step: 8
Training loss: 1.587230920791626
Validation loss: 2.030051976121882

Epoch: 6| Step: 9
Training loss: 1.8560094833374023
Validation loss: 2.1006742369744087

Epoch: 6| Step: 10
Training loss: 2.0407233238220215
Validation loss: 2.050345964329217

Epoch: 6| Step: 11
Training loss: 1.9497767686843872
Validation loss: 2.0589469363612514

Epoch: 6| Step: 12
Training loss: 1.515161156654358
Validation loss: 2.0106450896109305

Epoch: 6| Step: 13
Training loss: 2.288485527038574
Validation loss: 2.007345370067063

Epoch: 303| Step: 0
Training loss: 1.20659339427948
Validation loss: 2.050943975807518

Epoch: 6| Step: 1
Training loss: 1.5976773500442505
Validation loss: 2.0241180260976157

Epoch: 6| Step: 2
Training loss: 2.0103044509887695
Validation loss: 2.0367563937299993

Epoch: 6| Step: 3
Training loss: 2.0748205184936523
Validation loss: 2.039126273124449

Epoch: 6| Step: 4
Training loss: 1.846170425415039
Validation loss: 2.0199075565543225

Epoch: 6| Step: 5
Training loss: 2.469296455383301
Validation loss: 2.0190101003134124

Epoch: 6| Step: 6
Training loss: 1.5863350629806519
Validation loss: 2.054777576077369

Epoch: 6| Step: 7
Training loss: 1.5011677742004395
Validation loss: 2.0025940518225394

Epoch: 6| Step: 8
Training loss: 1.6533122062683105
Validation loss: 2.0051262301783406

Epoch: 6| Step: 9
Training loss: 1.9227207899093628
Validation loss: 2.058649642493135

Epoch: 6| Step: 10
Training loss: 1.546759843826294
Validation loss: 2.0502803889654015

Epoch: 6| Step: 11
Training loss: 1.9926003217697144
Validation loss: 1.9991984457098029

Epoch: 6| Step: 12
Training loss: 1.380505084991455
Validation loss: 2.0205930663693334

Epoch: 6| Step: 13
Training loss: 2.1103153228759766
Validation loss: 2.017573921911178

Epoch: 304| Step: 0
Training loss: 1.97301185131073
Validation loss: 2.0288013463379233

Epoch: 6| Step: 1
Training loss: 2.2369327545166016
Validation loss: 2.0250704198755245

Epoch: 6| Step: 2
Training loss: 1.354360580444336
Validation loss: 2.0512691672130297

Epoch: 6| Step: 3
Training loss: 1.883765459060669
Validation loss: 2.036500726976702

Epoch: 6| Step: 4
Training loss: 2.073949098587036
Validation loss: 2.0541534064918436

Epoch: 6| Step: 5
Training loss: 1.9365253448486328
Validation loss: 2.0463998791992024

Epoch: 6| Step: 6
Training loss: 1.880040168762207
Validation loss: 1.9994352914953744

Epoch: 6| Step: 7
Training loss: 1.4712237119674683
Validation loss: 2.024820932777979

Epoch: 6| Step: 8
Training loss: 1.9061532020568848
Validation loss: 2.0648830116436048

Epoch: 6| Step: 9
Training loss: 1.6424715518951416
Validation loss: 2.056146216648881

Epoch: 6| Step: 10
Training loss: 1.4632906913757324
Validation loss: 2.08355309373589

Epoch: 6| Step: 11
Training loss: 1.4838148355484009
Validation loss: 2.059136261222183

Epoch: 6| Step: 12
Training loss: 2.4508814811706543
Validation loss: 2.03538195548519

Epoch: 6| Step: 13
Training loss: 0.8846263885498047
Validation loss: 2.070627389415618

Epoch: 305| Step: 0
Training loss: 1.6721142530441284
Validation loss: 2.067976397852744

Epoch: 6| Step: 1
Training loss: 1.9132604598999023
Validation loss: 2.0394586696419665

Epoch: 6| Step: 2
Training loss: 2.056551218032837
Validation loss: 2.0403229254548267

Epoch: 6| Step: 3
Training loss: 2.062836170196533
Validation loss: 2.0452229438289518

Epoch: 6| Step: 4
Training loss: 1.320333480834961
Validation loss: 2.0410610834757485

Epoch: 6| Step: 5
Training loss: 2.0572328567504883
Validation loss: 2.0530403557644097

Epoch: 6| Step: 6
Training loss: 1.730459451675415
Validation loss: 2.0224655571804253

Epoch: 6| Step: 7
Training loss: 1.7271525859832764
Validation loss: 2.011892949381182

Epoch: 6| Step: 8
Training loss: 1.9356366395950317
Validation loss: 2.059475580851237

Epoch: 6| Step: 9
Training loss: 2.0119383335113525
Validation loss: 2.0444366624278407

Epoch: 6| Step: 10
Training loss: 2.2603721618652344
Validation loss: 2.0478944419532694

Epoch: 6| Step: 11
Training loss: 1.1948401927947998
Validation loss: 2.0926078340058685

Epoch: 6| Step: 12
Training loss: 1.0959727764129639
Validation loss: 2.0302267177130586

Epoch: 6| Step: 13
Training loss: 2.229172706604004
Validation loss: 2.0217058786781887

Epoch: 306| Step: 0
Training loss: 1.7948191165924072
Validation loss: 2.060840106779529

Epoch: 6| Step: 1
Training loss: 1.9846463203430176
Validation loss: 2.043731843271563

Epoch: 6| Step: 2
Training loss: 1.6678516864776611
Validation loss: 2.0723624511431624

Epoch: 6| Step: 3
Training loss: 1.9539217948913574
Validation loss: 2.0390140779556765

Epoch: 6| Step: 4
Training loss: 2.074958324432373
Validation loss: 2.0434585181615685

Epoch: 6| Step: 5
Training loss: 1.7361085414886475
Validation loss: 2.0347586126737696

Epoch: 6| Step: 6
Training loss: 1.4776103496551514
Validation loss: 2.0607652728275587

Epoch: 6| Step: 7
Training loss: 2.4204258918762207
Validation loss: 2.0307806768724994

Epoch: 6| Step: 8
Training loss: 1.5202527046203613
Validation loss: 2.054052447759977

Epoch: 6| Step: 9
Training loss: 1.346531867980957
Validation loss: 2.0357627099560154

Epoch: 6| Step: 10
Training loss: 1.598016381263733
Validation loss: 2.068587145497722

Epoch: 6| Step: 11
Training loss: 1.5195693969726562
Validation loss: 2.063656469827057

Epoch: 6| Step: 12
Training loss: 1.7716121673583984
Validation loss: 2.052927141548485

Epoch: 6| Step: 13
Training loss: 1.6760063171386719
Validation loss: 2.058593519272343

Epoch: 307| Step: 0
Training loss: 1.6268818378448486
Validation loss: 2.05535747415276

Epoch: 6| Step: 1
Training loss: 1.956162452697754
Validation loss: 2.013353675924322

Epoch: 6| Step: 2
Training loss: 1.424013614654541
Validation loss: 2.0121838892659833

Epoch: 6| Step: 3
Training loss: 1.9102892875671387
Validation loss: 2.029160488036371

Epoch: 6| Step: 4
Training loss: 2.0246543884277344
Validation loss: 2.029159415152765

Epoch: 6| Step: 5
Training loss: 2.851224899291992
Validation loss: 2.0613433455908172

Epoch: 6| Step: 6
Training loss: 1.289396047592163
Validation loss: 2.041366092620357

Epoch: 6| Step: 7
Training loss: 1.6461410522460938
Validation loss: 2.0357006134525424

Epoch: 6| Step: 8
Training loss: 1.759078025817871
Validation loss: 2.028952343489534

Epoch: 6| Step: 9
Training loss: 2.4718425273895264
Validation loss: 2.0708392153504076

Epoch: 6| Step: 10
Training loss: 1.1053380966186523
Validation loss: 2.0232868861126643

Epoch: 6| Step: 11
Training loss: 1.1420257091522217
Validation loss: 2.0254969801954044

Epoch: 6| Step: 12
Training loss: 1.4896255731582642
Validation loss: 2.0764602115077357

Epoch: 6| Step: 13
Training loss: 1.9013527631759644
Validation loss: 2.0236760749611804

Epoch: 308| Step: 0
Training loss: 1.4968849420547485
Validation loss: 2.0654328843598724

Epoch: 6| Step: 1
Training loss: 2.5521998405456543
Validation loss: 2.059996674137731

Epoch: 6| Step: 2
Training loss: 1.2999255657196045
Validation loss: 2.009791839507318

Epoch: 6| Step: 3
Training loss: 1.5316760540008545
Validation loss: 2.032782749463153

Epoch: 6| Step: 4
Training loss: 2.113224506378174
Validation loss: 2.034330903842885

Epoch: 6| Step: 5
Training loss: 1.5430941581726074
Validation loss: 2.053824442689137

Epoch: 6| Step: 6
Training loss: 1.754858136177063
Validation loss: 2.027697411916589

Epoch: 6| Step: 7
Training loss: 2.4978511333465576
Validation loss: 2.0144052941312074

Epoch: 6| Step: 8
Training loss: 1.1743619441986084
Validation loss: 2.0360260727585002

Epoch: 6| Step: 9
Training loss: 2.481595993041992
Validation loss: 2.0103535241978143

Epoch: 6| Step: 10
Training loss: 1.4157789945602417
Validation loss: 2.0476904761406685

Epoch: 6| Step: 11
Training loss: 1.8060615062713623
Validation loss: 2.036008572065702

Epoch: 6| Step: 12
Training loss: 1.5570850372314453
Validation loss: 2.0556935648764334

Epoch: 6| Step: 13
Training loss: 1.4173071384429932
Validation loss: 2.0425815197729293

Epoch: 309| Step: 0
Training loss: 1.4613882303237915
Validation loss: 2.0237504628396805

Epoch: 6| Step: 1
Training loss: 1.904090404510498
Validation loss: 2.0486034539438065

Epoch: 6| Step: 2
Training loss: 1.9362094402313232
Validation loss: 2.065432797196091

Epoch: 6| Step: 3
Training loss: 1.4056737422943115
Validation loss: 2.0270083770957044

Epoch: 6| Step: 4
Training loss: 1.7185747623443604
Validation loss: 2.012506833640478

Epoch: 6| Step: 5
Training loss: 1.4942547082901
Validation loss: 2.058272889865342

Epoch: 6| Step: 6
Training loss: 1.9707732200622559
Validation loss: 2.0815658030971402

Epoch: 6| Step: 7
Training loss: 1.9219295978546143
Validation loss: 2.042223997013543

Epoch: 6| Step: 8
Training loss: 1.9477331638336182
Validation loss: 2.04348244718326

Epoch: 6| Step: 9
Training loss: 1.6387073993682861
Validation loss: 2.030694277055802

Epoch: 6| Step: 10
Training loss: 1.516381025314331
Validation loss: 2.037481459238196

Epoch: 6| Step: 11
Training loss: 1.8014142513275146
Validation loss: 2.0276163854906635

Epoch: 6| Step: 12
Training loss: 1.5538256168365479
Validation loss: 2.0720925741298224

Epoch: 6| Step: 13
Training loss: 2.5554511547088623
Validation loss: 2.0394635187682284

Epoch: 310| Step: 0
Training loss: 2.3468546867370605
Validation loss: 2.047704428754827

Epoch: 6| Step: 1
Training loss: 2.42291259765625
Validation loss: 2.040808250827174

Epoch: 6| Step: 2
Training loss: 1.2012786865234375
Validation loss: 2.0409111681804863

Epoch: 6| Step: 3
Training loss: 2.174354076385498
Validation loss: 2.0377262792279645

Epoch: 6| Step: 4
Training loss: 1.6986911296844482
Validation loss: 2.034841396475351

Epoch: 6| Step: 5
Training loss: 1.6122071743011475
Validation loss: 2.014956009003424

Epoch: 6| Step: 6
Training loss: 1.4687907695770264
Validation loss: 2.04304644625674

Epoch: 6| Step: 7
Training loss: 1.6486386060714722
Validation loss: 1.9781668199005948

Epoch: 6| Step: 8
Training loss: 2.1144914627075195
Validation loss: 2.000646100249342

Epoch: 6| Step: 9
Training loss: 1.6725441217422485
Validation loss: 2.015356981626121

Epoch: 6| Step: 10
Training loss: 1.390507459640503
Validation loss: 2.034086417126399

Epoch: 6| Step: 11
Training loss: 1.573926568031311
Validation loss: 2.018373374016054

Epoch: 6| Step: 12
Training loss: 2.057691812515259
Validation loss: 2.0224916037692817

Epoch: 6| Step: 13
Training loss: 0.7191579341888428
Validation loss: 2.0026462155003704

Epoch: 311| Step: 0
Training loss: 1.4565469026565552
Validation loss: 2.0396726003257175

Epoch: 6| Step: 1
Training loss: 1.8024101257324219
Validation loss: 2.042339445442282

Epoch: 6| Step: 2
Training loss: 2.1566452980041504
Validation loss: 2.0231714453748477

Epoch: 6| Step: 3
Training loss: 1.5580167770385742
Validation loss: 2.052958579473598

Epoch: 6| Step: 4
Training loss: 1.9267001152038574
Validation loss: 2.019921184867941

Epoch: 6| Step: 5
Training loss: 1.2226283550262451
Validation loss: 2.0329036097372732

Epoch: 6| Step: 6
Training loss: 1.7261360883712769
Validation loss: 2.0142190302571943

Epoch: 6| Step: 7
Training loss: 1.140099287033081
Validation loss: 2.055014569272277

Epoch: 6| Step: 8
Training loss: 1.802697777748108
Validation loss: 2.0450161964662614

Epoch: 6| Step: 9
Training loss: 2.204753875732422
Validation loss: 2.0364207157524685

Epoch: 6| Step: 10
Training loss: 1.9586937427520752
Validation loss: 2.036142083906358

Epoch: 6| Step: 11
Training loss: 2.313394069671631
Validation loss: 2.051592855043309

Epoch: 6| Step: 12
Training loss: 1.5271148681640625
Validation loss: 2.04254117960571

Epoch: 6| Step: 13
Training loss: 2.1917202472686768
Validation loss: 2.020404842592055

Epoch: 312| Step: 0
Training loss: 1.4779126644134521
Validation loss: 2.041461234451622

Epoch: 6| Step: 1
Training loss: 1.8076287508010864
Validation loss: 2.0280524607627624

Epoch: 6| Step: 2
Training loss: 1.456971287727356
Validation loss: 2.04378068318931

Epoch: 6| Step: 3
Training loss: 2.736830234527588
Validation loss: 2.037559208049569

Epoch: 6| Step: 4
Training loss: 1.7326438426971436
Validation loss: 1.989178455004128

Epoch: 6| Step: 5
Training loss: 1.3732476234436035
Validation loss: 2.0254596125695015

Epoch: 6| Step: 6
Training loss: 1.2238839864730835
Validation loss: 2.0083731143705306

Epoch: 6| Step: 7
Training loss: 1.4783589839935303
Validation loss: 1.9973584195618987

Epoch: 6| Step: 8
Training loss: 2.1723756790161133
Validation loss: 2.0325686470154793

Epoch: 6| Step: 9
Training loss: 2.7821457386016846
Validation loss: 2.035765165923744

Epoch: 6| Step: 10
Training loss: 1.3119919300079346
Validation loss: 1.996255123487083

Epoch: 6| Step: 11
Training loss: 1.8469159603118896
Validation loss: 2.0157651132152927

Epoch: 6| Step: 12
Training loss: 1.8069570064544678
Validation loss: 2.0160957203116467

Epoch: 6| Step: 13
Training loss: 1.8147337436676025
Validation loss: 2.045916682930403

Epoch: 313| Step: 0
Training loss: 1.7662827968597412
Validation loss: 2.038654088973999

Epoch: 6| Step: 1
Training loss: 1.1842193603515625
Validation loss: 2.035582665474184

Epoch: 6| Step: 2
Training loss: 2.175238609313965
Validation loss: 2.059884432823427

Epoch: 6| Step: 3
Training loss: 1.1423848867416382
Validation loss: 2.032738918899208

Epoch: 6| Step: 4
Training loss: 1.5397989749908447
Validation loss: 2.0892520899413736

Epoch: 6| Step: 5
Training loss: 1.9158015251159668
Validation loss: 2.0743565764478458

Epoch: 6| Step: 6
Training loss: 1.4300000667572021
Validation loss: 2.0661902966037875

Epoch: 6| Step: 7
Training loss: 2.5399281978607178
Validation loss: 2.0720972245739353

Epoch: 6| Step: 8
Training loss: 1.8773534297943115
Validation loss: 2.0694374230600174

Epoch: 6| Step: 9
Training loss: 1.8330305814743042
Validation loss: 2.0728609587556575

Epoch: 6| Step: 10
Training loss: 1.254986047744751
Validation loss: 2.097065030887563

Epoch: 6| Step: 11
Training loss: 1.7991418838500977
Validation loss: 2.0496231125247095

Epoch: 6| Step: 12
Training loss: 2.5397531986236572
Validation loss: 2.0667320374519593

Epoch: 6| Step: 13
Training loss: 1.7775752544403076
Validation loss: 2.0816632304140317

Epoch: 314| Step: 0
Training loss: 1.8575372695922852
Validation loss: 2.0819313692790207

Epoch: 6| Step: 1
Training loss: 1.7759877443313599
Validation loss: 2.058526469815162

Epoch: 6| Step: 2
Training loss: 1.9552125930786133
Validation loss: 2.028726645695266

Epoch: 6| Step: 3
Training loss: 1.841202974319458
Validation loss: 2.032740350692503

Epoch: 6| Step: 4
Training loss: 1.705604076385498
Validation loss: 2.049592400109896

Epoch: 6| Step: 5
Training loss: 2.07747745513916
Validation loss: 2.0465593107285036

Epoch: 6| Step: 6
Training loss: 1.7214159965515137
Validation loss: 2.0451781236997215

Epoch: 6| Step: 7
Training loss: 1.5900667905807495
Validation loss: 2.018470589832593

Epoch: 6| Step: 8
Training loss: 1.838880181312561
Validation loss: 2.0120592655674105

Epoch: 6| Step: 9
Training loss: 1.9313950538635254
Validation loss: 2.027225238020702

Epoch: 6| Step: 10
Training loss: 0.9679436683654785
Validation loss: 2.0419743625066613

Epoch: 6| Step: 11
Training loss: 1.7498767375946045
Validation loss: 2.0321125125372284

Epoch: 6| Step: 12
Training loss: 1.9203822612762451
Validation loss: 2.066606713879493

Epoch: 6| Step: 13
Training loss: 1.7873872518539429
Validation loss: 2.0072182109279018

Epoch: 315| Step: 0
Training loss: 1.7312345504760742
Validation loss: 2.064740561669873

Epoch: 6| Step: 1
Training loss: 1.407954216003418
Validation loss: 2.028554980472852

Epoch: 6| Step: 2
Training loss: 1.51716148853302
Validation loss: 2.0568128606324554

Epoch: 6| Step: 3
Training loss: 2.2751755714416504
Validation loss: 2.045366197504023

Epoch: 6| Step: 4
Training loss: 1.612032175064087
Validation loss: 2.0085540535629436

Epoch: 6| Step: 5
Training loss: 2.082341194152832
Validation loss: 2.007805760188769

Epoch: 6| Step: 6
Training loss: 1.9295681715011597
Validation loss: 2.026344149343429

Epoch: 6| Step: 7
Training loss: 1.3498300313949585
Validation loss: 2.0168983705582155

Epoch: 6| Step: 8
Training loss: 1.724078893661499
Validation loss: 2.02966978216684

Epoch: 6| Step: 9
Training loss: 1.6830552816390991
Validation loss: 2.0375780213263726

Epoch: 6| Step: 10
Training loss: 1.672721028327942
Validation loss: 2.0102935439796856

Epoch: 6| Step: 11
Training loss: 1.8781285285949707
Validation loss: 2.0096980320510043

Epoch: 6| Step: 12
Training loss: 1.8280725479125977
Validation loss: 2.0089886970417474

Epoch: 6| Step: 13
Training loss: 1.8028512001037598
Validation loss: 2.0218740099219867

Epoch: 316| Step: 0
Training loss: 1.304680347442627
Validation loss: 2.0326720924787622

Epoch: 6| Step: 1
Training loss: 1.9229646921157837
Validation loss: 2.0684028440906155

Epoch: 6| Step: 2
Training loss: 1.3919930458068848
Validation loss: 2.072045240350949

Epoch: 6| Step: 3
Training loss: 1.790494441986084
Validation loss: 2.0647637164720924

Epoch: 6| Step: 4
Training loss: 1.3818690776824951
Validation loss: 2.078852907303841

Epoch: 6| Step: 5
Training loss: 1.7146518230438232
Validation loss: 2.071252125565724

Epoch: 6| Step: 6
Training loss: 1.4975682497024536
Validation loss: 2.0227641072324527

Epoch: 6| Step: 7
Training loss: 2.185356616973877
Validation loss: 2.0781532231197564

Epoch: 6| Step: 8
Training loss: 1.4506242275238037
Validation loss: 2.0606282680265364

Epoch: 6| Step: 9
Training loss: 2.452723503112793
Validation loss: 2.052257744214868

Epoch: 6| Step: 10
Training loss: 1.9810062646865845
Validation loss: 2.0780779982125885

Epoch: 6| Step: 11
Training loss: 2.2707865238189697
Validation loss: 2.043198343246214

Epoch: 6| Step: 12
Training loss: 1.809348225593567
Validation loss: 2.023389691947609

Epoch: 6| Step: 13
Training loss: 1.5010100603103638
Validation loss: 2.063387741324722

Epoch: 317| Step: 0
Training loss: 0.9656947255134583
Validation loss: 2.067734210721908

Epoch: 6| Step: 1
Training loss: 1.7807998657226562
Validation loss: 2.0650637880448373

Epoch: 6| Step: 2
Training loss: 1.9010783433914185
Validation loss: 2.069879219096194

Epoch: 6| Step: 3
Training loss: 1.6291242837905884
Validation loss: 2.053366179107338

Epoch: 6| Step: 4
Training loss: 2.057523012161255
Validation loss: 2.063080487712737

Epoch: 6| Step: 5
Training loss: 2.537850856781006
Validation loss: 2.0598075646226124

Epoch: 6| Step: 6
Training loss: 2.0167179107666016
Validation loss: 2.041532706188899

Epoch: 6| Step: 7
Training loss: 2.057447910308838
Validation loss: 2.044297561850599

Epoch: 6| Step: 8
Training loss: 2.018998622894287
Validation loss: 2.0240798970704437

Epoch: 6| Step: 9
Training loss: 1.3487014770507812
Validation loss: 2.0300133882030362

Epoch: 6| Step: 10
Training loss: 1.145228624343872
Validation loss: 2.0668175887036067

Epoch: 6| Step: 11
Training loss: 1.6160550117492676
Validation loss: 2.0199706656958467

Epoch: 6| Step: 12
Training loss: 1.533613920211792
Validation loss: 2.0620108932577152

Epoch: 6| Step: 13
Training loss: 1.8180193901062012
Validation loss: 2.063347183248048

Epoch: 318| Step: 0
Training loss: 1.9871526956558228
Validation loss: 2.016891938383861

Epoch: 6| Step: 1
Training loss: 1.6970744132995605
Validation loss: 2.0492596523736113

Epoch: 6| Step: 2
Training loss: 1.9366092681884766
Validation loss: 2.0110445086674025

Epoch: 6| Step: 3
Training loss: 2.4526150226593018
Validation loss: 2.075660328711233

Epoch: 6| Step: 4
Training loss: 1.0598115921020508
Validation loss: 2.0280770870947067

Epoch: 6| Step: 5
Training loss: 1.697250247001648
Validation loss: 2.0015478954520276

Epoch: 6| Step: 6
Training loss: 1.2888431549072266
Validation loss: 2.008352009198999

Epoch: 6| Step: 7
Training loss: 1.6248329877853394
Validation loss: 1.999931893041057

Epoch: 6| Step: 8
Training loss: 1.7560456991195679
Validation loss: 2.062337961248172

Epoch: 6| Step: 9
Training loss: 1.9507145881652832
Validation loss: 2.002376194923155

Epoch: 6| Step: 10
Training loss: 1.4940786361694336
Validation loss: 2.0396418750927015

Epoch: 6| Step: 11
Training loss: 1.7432507276535034
Validation loss: 2.017950934748496

Epoch: 6| Step: 12
Training loss: 1.939354419708252
Validation loss: 1.9848629454130768

Epoch: 6| Step: 13
Training loss: 1.772952914237976
Validation loss: 2.024395509432721

Epoch: 319| Step: 0
Training loss: 1.9800353050231934
Validation loss: 2.0573401848475137

Epoch: 6| Step: 1
Training loss: 1.886163592338562
Validation loss: 2.002109650642641

Epoch: 6| Step: 2
Training loss: 1.5673019886016846
Validation loss: 2.0108184006906327

Epoch: 6| Step: 3
Training loss: 2.6599230766296387
Validation loss: 2.020577826807576

Epoch: 6| Step: 4
Training loss: 1.4596483707427979
Validation loss: 2.018074631690979

Epoch: 6| Step: 5
Training loss: 2.305440664291382
Validation loss: 2.0095210818834204

Epoch: 6| Step: 6
Training loss: 1.6980359554290771
Validation loss: 2.026380305649132

Epoch: 6| Step: 7
Training loss: 2.0921692848205566
Validation loss: 1.9926861998855427

Epoch: 6| Step: 8
Training loss: 1.8782309293746948
Validation loss: 1.9976104421000327

Epoch: 6| Step: 9
Training loss: 0.8964266777038574
Validation loss: 2.0267553291013165

Epoch: 6| Step: 10
Training loss: 1.193307876586914
Validation loss: 2.027674069968603

Epoch: 6| Step: 11
Training loss: 1.8644921779632568
Validation loss: 2.0484556767248336

Epoch: 6| Step: 12
Training loss: 1.4233075380325317
Validation loss: 1.997303714034378

Epoch: 6| Step: 13
Training loss: 1.911437749862671
Validation loss: 2.034833138988864

Epoch: 320| Step: 0
Training loss: 2.4163191318511963
Validation loss: 2.042316072730608

Epoch: 6| Step: 1
Training loss: 2.5385451316833496
Validation loss: 2.0477706001650904

Epoch: 6| Step: 2
Training loss: 1.5455889701843262
Validation loss: 2.0718043286313295

Epoch: 6| Step: 3
Training loss: 1.6151056289672852
Validation loss: 2.063908096282713

Epoch: 6| Step: 4
Training loss: 1.1348564624786377
Validation loss: 2.0132759437766126

Epoch: 6| Step: 5
Training loss: 1.8323328495025635
Validation loss: 2.045083571505803

Epoch: 6| Step: 6
Training loss: 1.906757116317749
Validation loss: 2.00269438118063

Epoch: 6| Step: 7
Training loss: 1.8048503398895264
Validation loss: 2.096462377937891

Epoch: 6| Step: 8
Training loss: 1.4724655151367188
Validation loss: 2.0656174587947067

Epoch: 6| Step: 9
Training loss: 1.2001999616622925
Validation loss: 2.0566533944940053

Epoch: 6| Step: 10
Training loss: 1.6307679414749146
Validation loss: 2.084792644746842

Epoch: 6| Step: 11
Training loss: 2.5389702320098877
Validation loss: 2.0136078967843005

Epoch: 6| Step: 12
Training loss: 1.5844438076019287
Validation loss: 2.0715057901156846

Epoch: 6| Step: 13
Training loss: 1.0923658609390259
Validation loss: 2.031280889306017

Epoch: 321| Step: 0
Training loss: 1.9758515357971191
Validation loss: 2.034219397011624

Epoch: 6| Step: 1
Training loss: 1.5719152688980103
Validation loss: 2.0464458927031486

Epoch: 6| Step: 2
Training loss: 2.50600528717041
Validation loss: 2.0987702005652973

Epoch: 6| Step: 3
Training loss: 1.5514657497406006
Validation loss: 2.0646881108642905

Epoch: 6| Step: 4
Training loss: 1.42531156539917
Validation loss: 2.0719750183884815

Epoch: 6| Step: 5
Training loss: 2.3709099292755127
Validation loss: 2.0427248695845246

Epoch: 6| Step: 6
Training loss: 1.6523994207382202
Validation loss: 2.024971651774581

Epoch: 6| Step: 7
Training loss: 1.1197487115859985
Validation loss: 2.0096164031695296

Epoch: 6| Step: 8
Training loss: 1.7270886898040771
Validation loss: 2.0289412467710433

Epoch: 6| Step: 9
Training loss: 2.085193157196045
Validation loss: 2.041559934616089

Epoch: 6| Step: 10
Training loss: 1.4822759628295898
Validation loss: 2.0275779577993576

Epoch: 6| Step: 11
Training loss: 1.4612383842468262
Validation loss: 2.024084888478761

Epoch: 6| Step: 12
Training loss: 1.8086457252502441
Validation loss: 2.024049248746646

Epoch: 6| Step: 13
Training loss: 1.4530692100524902
Validation loss: 2.0485432788889897

Epoch: 322| Step: 0
Training loss: 1.3167459964752197
Validation loss: 2.0633573378286054

Epoch: 6| Step: 1
Training loss: 1.652674674987793
Validation loss: 2.029083728790283

Epoch: 6| Step: 2
Training loss: 1.5931848287582397
Validation loss: 2.0218883188821937

Epoch: 6| Step: 3
Training loss: 1.8775043487548828
Validation loss: 2.0517499241777646

Epoch: 6| Step: 4
Training loss: 1.4846417903900146
Validation loss: 2.0575423984117407

Epoch: 6| Step: 5
Training loss: 1.5882513523101807
Validation loss: 2.031504541315058

Epoch: 6| Step: 6
Training loss: 1.3937150239944458
Validation loss: 2.017635073713077

Epoch: 6| Step: 7
Training loss: 2.3981919288635254
Validation loss: 2.037801806644727

Epoch: 6| Step: 8
Training loss: 2.0101513862609863
Validation loss: 2.0442170366164176

Epoch: 6| Step: 9
Training loss: 2.047354221343994
Validation loss: 2.0231919339908067

Epoch: 6| Step: 10
Training loss: 1.968491554260254
Validation loss: 2.061292145841865

Epoch: 6| Step: 11
Training loss: 1.5907646417617798
Validation loss: 2.051897179695868

Epoch: 6| Step: 12
Training loss: 1.742565631866455
Validation loss: 2.0206526863959526

Epoch: 6| Step: 13
Training loss: 1.5360760688781738
Validation loss: 2.038652008579623

Epoch: 323| Step: 0
Training loss: 1.2964041233062744
Validation loss: 2.0878646322475967

Epoch: 6| Step: 1
Training loss: 2.1531336307525635
Validation loss: 2.06109409306639

Epoch: 6| Step: 2
Training loss: 2.314429759979248
Validation loss: 2.093124892122002

Epoch: 6| Step: 3
Training loss: 1.9903444051742554
Validation loss: 2.0681525917463404

Epoch: 6| Step: 4
Training loss: 1.583362102508545
Validation loss: 2.0983074711215113

Epoch: 6| Step: 5
Training loss: 2.0946080684661865
Validation loss: 2.1093039256270214

Epoch: 6| Step: 6
Training loss: 1.3664902448654175
Validation loss: 2.0570065898279988

Epoch: 6| Step: 7
Training loss: 1.3860985040664673
Validation loss: 2.0689319295267903

Epoch: 6| Step: 8
Training loss: 1.5276247262954712
Validation loss: 2.026963189084043

Epoch: 6| Step: 9
Training loss: 1.854790449142456
Validation loss: 2.0634637801877913

Epoch: 6| Step: 10
Training loss: 1.739703893661499
Validation loss: 2.023995719930177

Epoch: 6| Step: 11
Training loss: 2.2360105514526367
Validation loss: 2.027667817249093

Epoch: 6| Step: 12
Training loss: 1.343397617340088
Validation loss: 2.031741537073607

Epoch: 6| Step: 13
Training loss: 1.4615323543548584
Validation loss: 2.013554803786739

Epoch: 324| Step: 0
Training loss: 2.3262698650360107
Validation loss: 2.046460751564272

Epoch: 6| Step: 1
Training loss: 0.9721135497093201
Validation loss: 2.022549598447738

Epoch: 6| Step: 2
Training loss: 1.0549874305725098
Validation loss: 2.0646241249576693

Epoch: 6| Step: 3
Training loss: 1.8324604034423828
Validation loss: 2.064636589378439

Epoch: 6| Step: 4
Training loss: 2.2536213397979736
Validation loss: 1.9972169399261475

Epoch: 6| Step: 5
Training loss: 1.8769540786743164
Validation loss: 2.0234483326635053

Epoch: 6| Step: 6
Training loss: 2.1306817531585693
Validation loss: 2.0582854542680966

Epoch: 6| Step: 7
Training loss: 1.8148707151412964
Validation loss: 2.012302173081265

Epoch: 6| Step: 8
Training loss: 1.4047255516052246
Validation loss: 2.0813331911640782

Epoch: 6| Step: 9
Training loss: 1.0893795490264893
Validation loss: 2.0246570264139483

Epoch: 6| Step: 10
Training loss: 2.150761127471924
Validation loss: 2.057054606817102

Epoch: 6| Step: 11
Training loss: 1.5621140003204346
Validation loss: 2.0463185566727833

Epoch: 6| Step: 12
Training loss: 2.186443567276001
Validation loss: 2.0252692186704246

Epoch: 6| Step: 13
Training loss: 1.5850300788879395
Validation loss: 2.0544694290366223

Epoch: 325| Step: 0
Training loss: 2.015336513519287
Validation loss: 2.0425046464448333

Epoch: 6| Step: 1
Training loss: 1.5625360012054443
Validation loss: 1.9931263193007438

Epoch: 6| Step: 2
Training loss: 2.2631242275238037
Validation loss: 1.991340579525117

Epoch: 6| Step: 3
Training loss: 1.7468047142028809
Validation loss: 2.053196904479816

Epoch: 6| Step: 4
Training loss: 1.7368733882904053
Validation loss: 2.0450949502247635

Epoch: 6| Step: 5
Training loss: 1.3301613330841064
Validation loss: 2.059765274806689

Epoch: 6| Step: 6
Training loss: 1.7837486267089844
Validation loss: 2.0678083742818525

Epoch: 6| Step: 7
Training loss: 1.5825374126434326
Validation loss: 2.057022266490485

Epoch: 6| Step: 8
Training loss: 1.8593939542770386
Validation loss: 2.043874935437274

Epoch: 6| Step: 9
Training loss: 1.633908987045288
Validation loss: 2.060396008594062

Epoch: 6| Step: 10
Training loss: 0.9527875781059265
Validation loss: 2.0476233305469638

Epoch: 6| Step: 11
Training loss: 1.4612066745758057
Validation loss: 2.0379596576895764

Epoch: 6| Step: 12
Training loss: 2.4196677207946777
Validation loss: 2.0091877534825313

Epoch: 6| Step: 13
Training loss: 1.6237897872924805
Validation loss: 2.0356156620928036

Epoch: 326| Step: 0
Training loss: 1.5973234176635742
Validation loss: 2.0633435595420098

Epoch: 6| Step: 1
Training loss: 1.3698650598526
Validation loss: 2.0478353038910897

Epoch: 6| Step: 2
Training loss: 1.960113525390625
Validation loss: 2.0683851062610583

Epoch: 6| Step: 3
Training loss: 0.9912533164024353
Validation loss: 2.0621970738134077

Epoch: 6| Step: 4
Training loss: 2.028733968734741
Validation loss: 2.0037027994791665

Epoch: 6| Step: 5
Training loss: 1.2446062564849854
Validation loss: 2.0483566843053347

Epoch: 6| Step: 6
Training loss: 2.7227907180786133
Validation loss: 2.053461185065649

Epoch: 6| Step: 7
Training loss: 2.1751396656036377
Validation loss: 2.072338027338828

Epoch: 6| Step: 8
Training loss: 1.8417391777038574
Validation loss: 2.0046271175466557

Epoch: 6| Step: 9
Training loss: 1.5158605575561523
Validation loss: 2.014854969516877

Epoch: 6| Step: 10
Training loss: 1.352882742881775
Validation loss: 2.0312298049208937

Epoch: 6| Step: 11
Training loss: 1.9209835529327393
Validation loss: 2.0367109467906337

Epoch: 6| Step: 12
Training loss: 2.051085948944092
Validation loss: 2.042503067242202

Epoch: 6| Step: 13
Training loss: 1.5532599687576294
Validation loss: 2.0118863608247493

Epoch: 327| Step: 0
Training loss: 2.4604976177215576
Validation loss: 2.059130773749403

Epoch: 6| Step: 1
Training loss: 1.0053761005401611
Validation loss: 2.021075879373858

Epoch: 6| Step: 2
Training loss: 1.4792776107788086
Validation loss: 2.0173539910265195

Epoch: 6| Step: 3
Training loss: 1.9181339740753174
Validation loss: 2.0611961041727374

Epoch: 6| Step: 4
Training loss: 1.879155158996582
Validation loss: 2.0172307222120223

Epoch: 6| Step: 5
Training loss: 1.8555560111999512
Validation loss: 2.05561565327388

Epoch: 6| Step: 6
Training loss: 1.474316120147705
Validation loss: 2.0588869907522716

Epoch: 6| Step: 7
Training loss: 1.158522129058838
Validation loss: 2.0703429752780544

Epoch: 6| Step: 8
Training loss: 2.042860507965088
Validation loss: 2.0652888359562045

Epoch: 6| Step: 9
Training loss: 2.24725341796875
Validation loss: 2.019091442067136

Epoch: 6| Step: 10
Training loss: 2.4267611503601074
Validation loss: 2.044868037264834

Epoch: 6| Step: 11
Training loss: 1.2362446784973145
Validation loss: 2.026955417407456

Epoch: 6| Step: 12
Training loss: 1.1298576593399048
Validation loss: 2.0410377569096063

Epoch: 6| Step: 13
Training loss: 1.942201852798462
Validation loss: 2.0519845562596477

Epoch: 328| Step: 0
Training loss: 1.704354166984558
Validation loss: 2.054788540768367

Epoch: 6| Step: 1
Training loss: 1.741884708404541
Validation loss: 2.0225708638468096

Epoch: 6| Step: 2
Training loss: 1.9520323276519775
Validation loss: 2.019871086202642

Epoch: 6| Step: 3
Training loss: 1.2885676622390747
Validation loss: 2.004841337921799

Epoch: 6| Step: 4
Training loss: 2.170062780380249
Validation loss: 2.037984650622132

Epoch: 6| Step: 5
Training loss: 1.3755371570587158
Validation loss: 2.027813370509814

Epoch: 6| Step: 6
Training loss: 1.4501627683639526
Validation loss: 2.054496357517858

Epoch: 6| Step: 7
Training loss: 2.300431251525879
Validation loss: 2.016641568112117

Epoch: 6| Step: 8
Training loss: 1.802513599395752
Validation loss: 2.0185388724009194

Epoch: 6| Step: 9
Training loss: 1.7681808471679688
Validation loss: 2.0068814844213505

Epoch: 6| Step: 10
Training loss: 1.6554408073425293
Validation loss: 2.0762972267725135

Epoch: 6| Step: 11
Training loss: 1.2699884176254272
Validation loss: 2.028919119988718

Epoch: 6| Step: 12
Training loss: 1.5826431512832642
Validation loss: 2.0380295066423315

Epoch: 6| Step: 13
Training loss: 2.166131019592285
Validation loss: 2.0366949881276777

Epoch: 329| Step: 0
Training loss: 2.314211368560791
Validation loss: 2.038136189983737

Epoch: 6| Step: 1
Training loss: 1.300462007522583
Validation loss: 2.059044640551331

Epoch: 6| Step: 2
Training loss: 1.739181637763977
Validation loss: 2.0319843651146017

Epoch: 6| Step: 3
Training loss: 2.0997774600982666
Validation loss: 1.9974071056612077

Epoch: 6| Step: 4
Training loss: 2.2896175384521484
Validation loss: 2.0465569662791427

Epoch: 6| Step: 5
Training loss: 1.5302280187606812
Validation loss: 2.027248477423063

Epoch: 6| Step: 6
Training loss: 2.633094310760498
Validation loss: 2.0216662268484793

Epoch: 6| Step: 7
Training loss: 1.262927770614624
Validation loss: 2.022096614683828

Epoch: 6| Step: 8
Training loss: 1.351568579673767
Validation loss: 2.032658694892801

Epoch: 6| Step: 9
Training loss: 1.024327278137207
Validation loss: 2.0304014759678997

Epoch: 6| Step: 10
Training loss: 1.6239056587219238
Validation loss: 2.0390739274281326

Epoch: 6| Step: 11
Training loss: 1.3195738792419434
Validation loss: 2.042587972456409

Epoch: 6| Step: 12
Training loss: 2.3248467445373535
Validation loss: 2.0360952500374085

Epoch: 6| Step: 13
Training loss: 1.5774550437927246
Validation loss: 2.028701356662217

Epoch: 330| Step: 0
Training loss: 1.7806357145309448
Validation loss: 2.068984507232584

Epoch: 6| Step: 1
Training loss: 1.8737027645111084
Validation loss: 2.0780715109199606

Epoch: 6| Step: 2
Training loss: 1.6715114116668701
Validation loss: 2.022485790714141

Epoch: 6| Step: 3
Training loss: 1.3951555490493774
Validation loss: 2.026736490188106

Epoch: 6| Step: 4
Training loss: 2.377218246459961
Validation loss: 2.0318808735057874

Epoch: 6| Step: 5
Training loss: 1.2573132514953613
Validation loss: 2.051463960319437

Epoch: 6| Step: 6
Training loss: 2.609099864959717
Validation loss: 2.00766933092507

Epoch: 6| Step: 7
Training loss: 1.5454952716827393
Validation loss: 2.029019018655182

Epoch: 6| Step: 8
Training loss: 1.31636643409729
Validation loss: 2.0515367497680006

Epoch: 6| Step: 9
Training loss: 1.528989315032959
Validation loss: 2.000195896753701

Epoch: 6| Step: 10
Training loss: 1.7219822406768799
Validation loss: 2.065981957220262

Epoch: 6| Step: 11
Training loss: 1.6515754461288452
Validation loss: 2.050733467584015

Epoch: 6| Step: 12
Training loss: 2.0719306468963623
Validation loss: 2.0723633061173143

Epoch: 6| Step: 13
Training loss: 0.7178347110748291
Validation loss: 2.0890901550169914

Epoch: 331| Step: 0
Training loss: 1.149200201034546
Validation loss: 2.042093018049835

Epoch: 6| Step: 1
Training loss: 1.159151554107666
Validation loss: 2.0543217274450485

Epoch: 6| Step: 2
Training loss: 1.2683781385421753
Validation loss: 2.0464099325159544

Epoch: 6| Step: 3
Training loss: 2.030435562133789
Validation loss: 2.034224997284592

Epoch: 6| Step: 4
Training loss: 2.6944897174835205
Validation loss: 2.052444787435634

Epoch: 6| Step: 5
Training loss: 1.8620673418045044
Validation loss: 2.05485204983783

Epoch: 6| Step: 6
Training loss: 1.5631603002548218
Validation loss: 2.0549851771323913

Epoch: 6| Step: 7
Training loss: 1.1470149755477905
Validation loss: 2.0262763051576513

Epoch: 6| Step: 8
Training loss: 2.207486867904663
Validation loss: 2.0422338157571773

Epoch: 6| Step: 9
Training loss: 1.7029047012329102
Validation loss: 2.062946052961452

Epoch: 6| Step: 10
Training loss: 1.3437169790267944
Validation loss: 2.057423590331949

Epoch: 6| Step: 11
Training loss: 2.1351609230041504
Validation loss: 2.0191046217436432

Epoch: 6| Step: 12
Training loss: 2.3481333255767822
Validation loss: 2.0142152668327413

Epoch: 6| Step: 13
Training loss: 1.8277738094329834
Validation loss: 1.9998426181013866

Epoch: 332| Step: 0
Training loss: 1.896227240562439
Validation loss: 2.036480542152159

Epoch: 6| Step: 1
Training loss: 1.7535117864608765
Validation loss: 2.0713639413156817

Epoch: 6| Step: 2
Training loss: 1.0954062938690186
Validation loss: 2.0231776647670294

Epoch: 6| Step: 3
Training loss: 1.0107147693634033
Validation loss: 2.0652810886342037

Epoch: 6| Step: 4
Training loss: 1.4882800579071045
Validation loss: 2.0497387198991674

Epoch: 6| Step: 5
Training loss: 1.7422640323638916
Validation loss: 2.0884889594970213

Epoch: 6| Step: 6
Training loss: 2.3198161125183105
Validation loss: 2.0687508454886814

Epoch: 6| Step: 7
Training loss: 1.5466281175613403
Validation loss: 2.1023260278086506

Epoch: 6| Step: 8
Training loss: 2.066333770751953
Validation loss: 2.05992635860238

Epoch: 6| Step: 9
Training loss: 1.6712706089019775
Validation loss: 2.0488957282035583

Epoch: 6| Step: 10
Training loss: 1.578493595123291
Validation loss: 2.0573793252309165

Epoch: 6| Step: 11
Training loss: 2.065371513366699
Validation loss: 2.084569331138365

Epoch: 6| Step: 12
Training loss: 2.404604911804199
Validation loss: 2.0597818923252884

Epoch: 6| Step: 13
Training loss: 1.0225623846054077
Validation loss: 2.0730393368710756

Epoch: 333| Step: 0
Training loss: 2.3953051567077637
Validation loss: 2.0317150315930768

Epoch: 6| Step: 1
Training loss: 1.3696132898330688
Validation loss: 2.045937463801394

Epoch: 6| Step: 2
Training loss: 1.7150046825408936
Validation loss: 2.0293779873078868

Epoch: 6| Step: 3
Training loss: 2.2560346126556396
Validation loss: 2.0438962815910258

Epoch: 6| Step: 4
Training loss: 1.4888215065002441
Validation loss: 2.0072269208969606

Epoch: 6| Step: 5
Training loss: 2.4557878971099854
Validation loss: 2.0186121297138993

Epoch: 6| Step: 6
Training loss: 1.2045538425445557
Validation loss: 2.0269336110802105

Epoch: 6| Step: 7
Training loss: 1.6130197048187256
Validation loss: 2.0127413862495014

Epoch: 6| Step: 8
Training loss: 1.4359629154205322
Validation loss: 2.0136096554417766

Epoch: 6| Step: 9
Training loss: 1.709168553352356
Validation loss: 2.0580458384688183

Epoch: 6| Step: 10
Training loss: 1.8566863536834717
Validation loss: 2.0213831868222965

Epoch: 6| Step: 11
Training loss: 1.6945991516113281
Validation loss: 2.0303220287446053

Epoch: 6| Step: 12
Training loss: 1.1039658784866333
Validation loss: 2.03653649873631

Epoch: 6| Step: 13
Training loss: 1.757454514503479
Validation loss: 2.0099465744469756

Epoch: 334| Step: 0
Training loss: 1.284275770187378
Validation loss: 2.01820848577766

Epoch: 6| Step: 1
Training loss: 1.8354127407073975
Validation loss: 2.0518970899684454

Epoch: 6| Step: 2
Training loss: 1.7702701091766357
Validation loss: 2.0488715940906155

Epoch: 6| Step: 3
Training loss: 2.1783790588378906
Validation loss: 2.024379309787545

Epoch: 6| Step: 4
Training loss: 1.7063753604888916
Validation loss: 2.0382101228160243

Epoch: 6| Step: 5
Training loss: 1.9319839477539062
Validation loss: 2.0252836955490934

Epoch: 6| Step: 6
Training loss: 1.4811246395111084
Validation loss: 1.9927068666745258

Epoch: 6| Step: 7
Training loss: 2.153441905975342
Validation loss: 2.059836741416685

Epoch: 6| Step: 8
Training loss: 1.746854305267334
Validation loss: 2.0378315077033093

Epoch: 6| Step: 9
Training loss: 1.8309985399246216
Validation loss: 2.067896504555979

Epoch: 6| Step: 10
Training loss: 1.6870722770690918
Validation loss: 2.0680710192649596

Epoch: 6| Step: 11
Training loss: 1.599718689918518
Validation loss: 2.0790534429652716

Epoch: 6| Step: 12
Training loss: 1.613394856452942
Validation loss: 2.079326150237873

Epoch: 6| Step: 13
Training loss: 1.3856256008148193
Validation loss: 2.0337525811246646

Epoch: 335| Step: 0
Training loss: 1.643359661102295
Validation loss: 2.0531178853845082

Epoch: 6| Step: 1
Training loss: 1.5027307271957397
Validation loss: 2.071509597122028

Epoch: 6| Step: 2
Training loss: 1.4631428718566895
Validation loss: 2.0468411086707987

Epoch: 6| Step: 3
Training loss: 2.681166648864746
Validation loss: 2.0844369357632053

Epoch: 6| Step: 4
Training loss: 1.8062527179718018
Validation loss: 2.0663893966264624

Epoch: 6| Step: 5
Training loss: 1.862908959388733
Validation loss: 2.0588678134384977

Epoch: 6| Step: 6
Training loss: 1.0267589092254639
Validation loss: 2.090067973700903

Epoch: 6| Step: 7
Training loss: 1.920237421989441
Validation loss: 2.077565218812676

Epoch: 6| Step: 8
Training loss: 2.0154027938842773
Validation loss: 2.0575328591049358

Epoch: 6| Step: 9
Training loss: 1.993858814239502
Validation loss: 2.0417575451635543

Epoch: 6| Step: 10
Training loss: 1.0713920593261719
Validation loss: 2.0737920627799085

Epoch: 6| Step: 11
Training loss: 1.5713775157928467
Validation loss: 2.0448455246545936

Epoch: 6| Step: 12
Training loss: 1.4242526292800903
Validation loss: 2.0363046584590787

Epoch: 6| Step: 13
Training loss: 2.427485466003418
Validation loss: 2.031656383186258

Epoch: 336| Step: 0
Training loss: 1.659088373184204
Validation loss: 2.054129098051338

Epoch: 6| Step: 1
Training loss: 1.9478206634521484
Validation loss: 2.0108304869744087

Epoch: 6| Step: 2
Training loss: 1.9381153583526611
Validation loss: 2.0212606127544115

Epoch: 6| Step: 3
Training loss: 1.6144732236862183
Validation loss: 2.029814076680009

Epoch: 6| Step: 4
Training loss: 1.7492156028747559
Validation loss: 2.0282746156056723

Epoch: 6| Step: 5
Training loss: 1.2336411476135254
Validation loss: 2.044873442701114

Epoch: 6| Step: 6
Training loss: 1.4325337409973145
Validation loss: 2.0314825568147885

Epoch: 6| Step: 7
Training loss: 2.055337905883789
Validation loss: 2.0361968137884654

Epoch: 6| Step: 8
Training loss: 1.7541214227676392
Validation loss: 2.0627662084435903

Epoch: 6| Step: 9
Training loss: 1.5828934907913208
Validation loss: 1.9971407075082102

Epoch: 6| Step: 10
Training loss: 2.280862331390381
Validation loss: 1.9878062868631015

Epoch: 6| Step: 11
Training loss: 1.5586515665054321
Validation loss: 2.0131815095101633

Epoch: 6| Step: 12
Training loss: 1.5532405376434326
Validation loss: 2.029316016422805

Epoch: 6| Step: 13
Training loss: 1.671426773071289
Validation loss: 2.0129425858938568

Epoch: 337| Step: 0
Training loss: 1.9107013940811157
Validation loss: 2.0336906576669342

Epoch: 6| Step: 1
Training loss: 1.3208943605422974
Validation loss: 2.003941562867934

Epoch: 6| Step: 2
Training loss: 2.312878370285034
Validation loss: 2.068087693183653

Epoch: 6| Step: 3
Training loss: 1.0883196592330933
Validation loss: 2.016869673164942

Epoch: 6| Step: 4
Training loss: 1.830727219581604
Validation loss: 2.045595230594758

Epoch: 6| Step: 5
Training loss: 1.5418564081192017
Validation loss: 2.068100263995509

Epoch: 6| Step: 6
Training loss: 2.0273890495300293
Validation loss: 2.033828661005984

Epoch: 6| Step: 7
Training loss: 1.8937333822250366
Validation loss: 2.0464432367714505

Epoch: 6| Step: 8
Training loss: 1.9194083213806152
Validation loss: 2.0496292601349535

Epoch: 6| Step: 9
Training loss: 1.7514190673828125
Validation loss: 2.07294863013811

Epoch: 6| Step: 10
Training loss: 1.5408356189727783
Validation loss: 2.0619887113571167

Epoch: 6| Step: 11
Training loss: 1.2422711849212646
Validation loss: 2.063920736312866

Epoch: 6| Step: 12
Training loss: 1.462170124053955
Validation loss: 2.053934048580867

Epoch: 6| Step: 13
Training loss: 1.893526554107666
Validation loss: 2.0926517568608767

Epoch: 338| Step: 0
Training loss: 2.1829586029052734
Validation loss: 2.063160166945509

Epoch: 6| Step: 1
Training loss: 1.6964259147644043
Validation loss: 2.0871893231586744

Epoch: 6| Step: 2
Training loss: 1.438683271408081
Validation loss: 2.0616260215800297

Epoch: 6| Step: 3
Training loss: 1.6987113952636719
Validation loss: 2.052824879205355

Epoch: 6| Step: 4
Training loss: 1.3731756210327148
Validation loss: 2.0159769212045977

Epoch: 6| Step: 5
Training loss: 1.8606969118118286
Validation loss: 2.07151710858909

Epoch: 6| Step: 6
Training loss: 1.653153657913208
Validation loss: 2.025846896633025

Epoch: 6| Step: 7
Training loss: 1.8067158460617065
Validation loss: 1.9965884018969793

Epoch: 6| Step: 8
Training loss: 1.7034647464752197
Validation loss: 2.0466443120792346

Epoch: 6| Step: 9
Training loss: 2.9777469635009766
Validation loss: 2.057366480109512

Epoch: 6| Step: 10
Training loss: 1.1939804553985596
Validation loss: 2.056504149590769

Epoch: 6| Step: 11
Training loss: 2.0017952919006348
Validation loss: 1.9877366840198476

Epoch: 6| Step: 12
Training loss: 0.8980369567871094
Validation loss: 2.028736191411172

Epoch: 6| Step: 13
Training loss: 1.5606439113616943
Validation loss: 2.025997149047031

Epoch: 339| Step: 0
Training loss: 1.4544670581817627
Validation loss: 2.0490615842162923

Epoch: 6| Step: 1
Training loss: 0.9788561463356018
Validation loss: 2.0482042245967413

Epoch: 6| Step: 2
Training loss: 2.2026586532592773
Validation loss: 2.062485284702752

Epoch: 6| Step: 3
Training loss: 1.8204973936080933
Validation loss: 2.053470834609001

Epoch: 6| Step: 4
Training loss: 1.5398122072219849
Validation loss: 2.097009842113782

Epoch: 6| Step: 5
Training loss: 2.3244829177856445
Validation loss: 2.0589008997845393

Epoch: 6| Step: 6
Training loss: 1.9260236024856567
Validation loss: 2.068611709020471

Epoch: 6| Step: 7
Training loss: 1.7618677616119385
Validation loss: 2.1053130498496433

Epoch: 6| Step: 8
Training loss: 1.3143682479858398
Validation loss: 2.072093230421825

Epoch: 6| Step: 9
Training loss: 2.2758758068084717
Validation loss: 2.0642403594909178

Epoch: 6| Step: 10
Training loss: 1.1622614860534668
Validation loss: 2.065585405595841

Epoch: 6| Step: 11
Training loss: 2.1284749507904053
Validation loss: 2.0968042112165883

Epoch: 6| Step: 12
Training loss: 1.4525456428527832
Validation loss: 2.0586727434589016

Epoch: 6| Step: 13
Training loss: 1.4450424909591675
Validation loss: 2.0502224840143675

Epoch: 340| Step: 0
Training loss: 1.5632182359695435
Validation loss: 2.0658360745317195

Epoch: 6| Step: 1
Training loss: 1.793175458908081
Validation loss: 2.046330549383676

Epoch: 6| Step: 2
Training loss: 2.1758170127868652
Validation loss: 2.0874373976902296

Epoch: 6| Step: 3
Training loss: 0.7028452157974243
Validation loss: 2.031939974395178

Epoch: 6| Step: 4
Training loss: 1.4958574771881104
Validation loss: 2.0266500160258305

Epoch: 6| Step: 5
Training loss: 1.9915028810501099
Validation loss: 2.030366269491052

Epoch: 6| Step: 6
Training loss: 1.6978223323822021
Validation loss: 2.0192373875648744

Epoch: 6| Step: 7
Training loss: 1.2408390045166016
Validation loss: 2.0568374856825797

Epoch: 6| Step: 8
Training loss: 1.6503050327301025
Validation loss: 2.0165851782726985

Epoch: 6| Step: 9
Training loss: 2.20060658454895
Validation loss: 2.0413184268500215

Epoch: 6| Step: 10
Training loss: 2.021207809448242
Validation loss: 2.0192728222057386

Epoch: 6| Step: 11
Training loss: 2.800525665283203
Validation loss: 2.0458239534849763

Epoch: 6| Step: 12
Training loss: 0.9637418389320374
Validation loss: 2.0388915308060183

Epoch: 6| Step: 13
Training loss: 1.152443766593933
Validation loss: 2.043491373779953

Epoch: 341| Step: 0
Training loss: 1.8347700834274292
Validation loss: 2.013170935774362

Epoch: 6| Step: 1
Training loss: 1.4097753763198853
Validation loss: 2.028345879688058

Epoch: 6| Step: 2
Training loss: 2.01566743850708
Validation loss: 1.9825352289343392

Epoch: 6| Step: 3
Training loss: 1.5376524925231934
Validation loss: 2.001257647750198

Epoch: 6| Step: 4
Training loss: 1.7416338920593262
Validation loss: 1.9959050122127737

Epoch: 6| Step: 5
Training loss: 1.5637447834014893
Validation loss: 2.0265978600389216

Epoch: 6| Step: 6
Training loss: 1.3483980894088745
Validation loss: 2.021753693139681

Epoch: 6| Step: 7
Training loss: 2.3950588703155518
Validation loss: 2.0840027524578955

Epoch: 6| Step: 8
Training loss: 1.4917783737182617
Validation loss: 1.991491722804244

Epoch: 6| Step: 9
Training loss: 1.357001781463623
Validation loss: 2.023092177606398

Epoch: 6| Step: 10
Training loss: 1.5821166038513184
Validation loss: 2.0159457896345403

Epoch: 6| Step: 11
Training loss: 1.899870753288269
Validation loss: 2.0008761344417447

Epoch: 6| Step: 12
Training loss: 2.082357883453369
Validation loss: 1.9913202678003619

Epoch: 6| Step: 13
Training loss: 1.11037278175354
Validation loss: 2.0834565495931976

Epoch: 342| Step: 0
Training loss: 1.6471511125564575
Validation loss: 2.0361363862150457

Epoch: 6| Step: 1
Training loss: 2.7080984115600586
Validation loss: 2.0411685269366027

Epoch: 6| Step: 2
Training loss: 1.8922277688980103
Validation loss: 2.04186390548624

Epoch: 6| Step: 3
Training loss: 1.8606042861938477
Validation loss: 2.035966025885715

Epoch: 6| Step: 4
Training loss: 1.2466838359832764
Validation loss: 2.039694522016792

Epoch: 6| Step: 5
Training loss: 1.453926682472229
Validation loss: 2.031324473760461

Epoch: 6| Step: 6
Training loss: 2.038043737411499
Validation loss: 2.0221304867857244

Epoch: 6| Step: 7
Training loss: 1.4084808826446533
Validation loss: 2.0602767621317217

Epoch: 6| Step: 8
Training loss: 2.056567668914795
Validation loss: 2.080005133023826

Epoch: 6| Step: 9
Training loss: 1.3251674175262451
Validation loss: 2.040432886410785

Epoch: 6| Step: 10
Training loss: 1.8024064302444458
Validation loss: 2.017844253970731

Epoch: 6| Step: 11
Training loss: 1.6568970680236816
Validation loss: 2.0820775224316503

Epoch: 6| Step: 12
Training loss: 1.2527790069580078
Validation loss: 2.051165780713481

Epoch: 6| Step: 13
Training loss: 1.525895595550537
Validation loss: 2.0802200891638316

Epoch: 343| Step: 0
Training loss: 1.3977291584014893
Validation loss: 2.061914695206509

Epoch: 6| Step: 1
Training loss: 1.3279857635498047
Validation loss: 2.090385639539329

Epoch: 6| Step: 2
Training loss: 2.1752736568450928
Validation loss: 2.045495246046333

Epoch: 6| Step: 3
Training loss: 1.5164453983306885
Validation loss: 2.058395754906439

Epoch: 6| Step: 4
Training loss: 1.7063350677490234
Validation loss: 2.0419693685347036

Epoch: 6| Step: 5
Training loss: 1.9835827350616455
Validation loss: 2.0270297732404483

Epoch: 6| Step: 6
Training loss: 1.4192326068878174
Validation loss: 2.024784820054167

Epoch: 6| Step: 7
Training loss: 1.7546900510787964
Validation loss: 2.0786892778129986

Epoch: 6| Step: 8
Training loss: 1.2529799938201904
Validation loss: 2.07527018362476

Epoch: 6| Step: 9
Training loss: 2.6346921920776367
Validation loss: 2.081193723986226

Epoch: 6| Step: 10
Training loss: 1.7117767333984375
Validation loss: 2.0704722686480452

Epoch: 6| Step: 11
Training loss: 1.5929505825042725
Validation loss: 2.071122480976966

Epoch: 6| Step: 12
Training loss: 2.01737642288208
Validation loss: 2.0796939531962075

Epoch: 6| Step: 13
Training loss: 1.715541124343872
Validation loss: 2.0981434724664174

Epoch: 344| Step: 0
Training loss: 1.9374520778656006
Validation loss: 2.082505677336006

Epoch: 6| Step: 1
Training loss: 1.6988555192947388
Validation loss: 2.108048318534769

Epoch: 6| Step: 2
Training loss: 0.8701050281524658
Validation loss: 2.088667526040026

Epoch: 6| Step: 3
Training loss: 1.3699744939804077
Validation loss: 2.0919341682105936

Epoch: 6| Step: 4
Training loss: 1.9424715042114258
Validation loss: 2.0389825221030944

Epoch: 6| Step: 5
Training loss: 1.4360277652740479
Validation loss: 2.0386425141365296

Epoch: 6| Step: 6
Training loss: 2.275327682495117
Validation loss: 2.029657017800116

Epoch: 6| Step: 7
Training loss: 2.0442676544189453
Validation loss: 2.0858200109133156

Epoch: 6| Step: 8
Training loss: 1.6732443571090698
Validation loss: 2.0483057088749383

Epoch: 6| Step: 9
Training loss: 1.2921741008758545
Validation loss: 2.0447537950290147

Epoch: 6| Step: 10
Training loss: 1.4171912670135498
Validation loss: 2.053805351257324

Epoch: 6| Step: 11
Training loss: 1.7436612844467163
Validation loss: 2.0349052336908158

Epoch: 6| Step: 12
Training loss: 2.1843931674957275
Validation loss: 2.042857159850418

Epoch: 6| Step: 13
Training loss: 1.5706806182861328
Validation loss: 2.033078747410928

Epoch: 345| Step: 0
Training loss: 1.2925364971160889
Validation loss: 2.02694042523702

Epoch: 6| Step: 1
Training loss: 1.6432464122772217
Validation loss: 1.9798898337989725

Epoch: 6| Step: 2
Training loss: 1.5752918720245361
Validation loss: 2.0096261911494757

Epoch: 6| Step: 3
Training loss: 1.7419483661651611
Validation loss: 2.033002858520836

Epoch: 6| Step: 4
Training loss: 1.7270123958587646
Validation loss: 2.045087557966991

Epoch: 6| Step: 5
Training loss: 2.120180130004883
Validation loss: 2.0216045046365387

Epoch: 6| Step: 6
Training loss: 1.9298279285430908
Validation loss: 2.0230862504692486

Epoch: 6| Step: 7
Training loss: 1.467207670211792
Validation loss: 2.0574190091061335

Epoch: 6| Step: 8
Training loss: 2.307929515838623
Validation loss: 2.0309551531268704

Epoch: 6| Step: 9
Training loss: 1.7436877489089966
Validation loss: 2.0530974723959483

Epoch: 6| Step: 10
Training loss: 1.8634361028671265
Validation loss: 2.055048076055383

Epoch: 6| Step: 11
Training loss: 1.0854562520980835
Validation loss: 2.077816468413158

Epoch: 6| Step: 12
Training loss: 1.7410681247711182
Validation loss: 2.0409042989054034

Epoch: 6| Step: 13
Training loss: 1.4118962287902832
Validation loss: 2.0620485518568303

Epoch: 346| Step: 0
Training loss: 1.4470765590667725
Validation loss: 2.08465576171875

Epoch: 6| Step: 1
Training loss: 2.5524942874908447
Validation loss: 2.1005260662365983

Epoch: 6| Step: 2
Training loss: 1.9427942037582397
Validation loss: 2.0480739455069266

Epoch: 6| Step: 3
Training loss: 1.8656235933303833
Validation loss: 2.063487063172043

Epoch: 6| Step: 4
Training loss: 1.7195980548858643
Validation loss: 2.0690357582543486

Epoch: 6| Step: 5
Training loss: 2.5014243125915527
Validation loss: 2.087313436692761

Epoch: 6| Step: 6
Training loss: 1.09223210811615
Validation loss: 2.047614546232326

Epoch: 6| Step: 7
Training loss: 1.6442235708236694
Validation loss: 2.079721091895975

Epoch: 6| Step: 8
Training loss: 1.7128486633300781
Validation loss: 2.0138157721488708

Epoch: 6| Step: 9
Training loss: 1.3700048923492432
Validation loss: 2.0577635162620136

Epoch: 6| Step: 10
Training loss: 1.4985241889953613
Validation loss: 2.033995082301478

Epoch: 6| Step: 11
Training loss: 1.5240821838378906
Validation loss: 2.068819243420837

Epoch: 6| Step: 12
Training loss: 1.3362970352172852
Validation loss: 2.0261367726069626

Epoch: 6| Step: 13
Training loss: 1.8086858987808228
Validation loss: 2.0100172347919916

Epoch: 347| Step: 0
Training loss: 1.8312170505523682
Validation loss: 2.053987964507072

Epoch: 6| Step: 1
Training loss: 2.240125894546509
Validation loss: 2.0261345499305317

Epoch: 6| Step: 2
Training loss: 1.8944714069366455
Validation loss: 2.0290470533473517

Epoch: 6| Step: 3
Training loss: 1.8186355829238892
Validation loss: 2.0235951472354192

Epoch: 6| Step: 4
Training loss: 1.4260165691375732
Validation loss: 2.0383074411781887

Epoch: 6| Step: 5
Training loss: 1.2325665950775146
Validation loss: 2.039975581630584

Epoch: 6| Step: 6
Training loss: 2.118455410003662
Validation loss: 2.0414760189671672

Epoch: 6| Step: 7
Training loss: 1.4036149978637695
Validation loss: 2.0242048745514243

Epoch: 6| Step: 8
Training loss: 1.3620808124542236
Validation loss: 2.016924665820214

Epoch: 6| Step: 9
Training loss: 2.004307746887207
Validation loss: 1.9885064812116726

Epoch: 6| Step: 10
Training loss: 1.9032611846923828
Validation loss: 2.020233524742947

Epoch: 6| Step: 11
Training loss: 0.9710673689842224
Validation loss: 1.9923519895922752

Epoch: 6| Step: 12
Training loss: 1.6311795711517334
Validation loss: 2.0426651047122095

Epoch: 6| Step: 13
Training loss: 2.324293375015259
Validation loss: 2.0357356430381857

Epoch: 348| Step: 0
Training loss: 1.6700383424758911
Validation loss: 2.0279131999579807

Epoch: 6| Step: 1
Training loss: 1.9571759700775146
Validation loss: 2.053091385031259

Epoch: 6| Step: 2
Training loss: 1.810302495956421
Validation loss: 2.0156357313997004

Epoch: 6| Step: 3
Training loss: 1.4121592044830322
Validation loss: 2.0521134330380346

Epoch: 6| Step: 4
Training loss: 1.8902101516723633
Validation loss: 2.0586930141654065

Epoch: 6| Step: 5
Training loss: 1.580222249031067
Validation loss: 2.0422780218944756

Epoch: 6| Step: 6
Training loss: 1.296122670173645
Validation loss: 2.0472703774770102

Epoch: 6| Step: 7
Training loss: 1.9060312509536743
Validation loss: 2.0417098947750625

Epoch: 6| Step: 8
Training loss: 1.6206096410751343
Validation loss: 2.0112094417695077

Epoch: 6| Step: 9
Training loss: 1.6850314140319824
Validation loss: 2.0413975587455173

Epoch: 6| Step: 10
Training loss: 1.7042021751403809
Validation loss: 2.0387691861839703

Epoch: 6| Step: 11
Training loss: 1.8744122982025146
Validation loss: 2.0544028230892715

Epoch: 6| Step: 12
Training loss: 1.6408253908157349
Validation loss: 2.0638359285170034

Epoch: 6| Step: 13
Training loss: 1.7969406843185425
Validation loss: 2.0156529847011773

Epoch: 349| Step: 0
Training loss: 1.7018814086914062
Validation loss: 2.0642752057762555

Epoch: 6| Step: 1
Training loss: 1.18892240524292
Validation loss: 2.0679481183328936

Epoch: 6| Step: 2
Training loss: 1.486861228942871
Validation loss: 2.0229560816159813

Epoch: 6| Step: 3
Training loss: 1.6088800430297852
Validation loss: 2.051512054217759

Epoch: 6| Step: 4
Training loss: 1.8252819776535034
Validation loss: 2.027442432218982

Epoch: 6| Step: 5
Training loss: 1.8010470867156982
Validation loss: 2.0660453457986154

Epoch: 6| Step: 6
Training loss: 1.6257489919662476
Validation loss: 2.022131513523799

Epoch: 6| Step: 7
Training loss: 1.5689945220947266
Validation loss: 2.033696233585317

Epoch: 6| Step: 8
Training loss: 1.2382802963256836
Validation loss: 1.983897339913153

Epoch: 6| Step: 9
Training loss: 1.2298157215118408
Validation loss: 2.016680609795355

Epoch: 6| Step: 10
Training loss: 2.751344680786133
Validation loss: 2.0541975498199463

Epoch: 6| Step: 11
Training loss: 1.9894388914108276
Validation loss: 2.011651351887693

Epoch: 6| Step: 12
Training loss: 1.4968457221984863
Validation loss: 2.0448926148876065

Epoch: 6| Step: 13
Training loss: 2.1448163986206055
Validation loss: 2.0185072140027116

Epoch: 350| Step: 0
Training loss: 1.6998440027236938
Validation loss: 2.054551319409442

Epoch: 6| Step: 1
Training loss: 1.5464779138565063
Validation loss: 2.057861997235206

Epoch: 6| Step: 2
Training loss: 2.04256534576416
Validation loss: 2.02304260705107

Epoch: 6| Step: 3
Training loss: 1.850304126739502
Validation loss: 2.076287337528762

Epoch: 6| Step: 4
Training loss: 2.1166648864746094
Validation loss: 2.0580755946456746

Epoch: 6| Step: 5
Training loss: 1.0998022556304932
Validation loss: 2.0066329048525904

Epoch: 6| Step: 6
Training loss: 2.0302796363830566
Validation loss: 2.041023205685359

Epoch: 6| Step: 7
Training loss: 2.0617618560791016
Validation loss: 2.0813717444737754

Epoch: 6| Step: 8
Training loss: 1.4251705408096313
Validation loss: 2.098194065914359

Epoch: 6| Step: 9
Training loss: 1.4595146179199219
Validation loss: 2.042119851676367

Epoch: 6| Step: 10
Training loss: 1.4034523963928223
Validation loss: 2.0848901015456005

Epoch: 6| Step: 11
Training loss: 1.0103507041931152
Validation loss: 2.0722151687068324

Epoch: 6| Step: 12
Training loss: 2.1646554470062256
Validation loss: 2.048078510069078

Epoch: 6| Step: 13
Training loss: 2.041668653488159
Validation loss: 2.074341453531737

Testing loss: 2.0894115103615656
