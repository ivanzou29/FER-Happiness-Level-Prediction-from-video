Epoch: 1| Step: 0
Training loss: 6.477091312408447
Validation loss: 5.807474146607102

Epoch: 5| Step: 1
Training loss: 5.175447940826416
Validation loss: 5.801680616153184

Epoch: 5| Step: 2
Training loss: 4.813040256500244
Validation loss: 5.794733067994477

Epoch: 5| Step: 3
Training loss: 6.001223564147949
Validation loss: 5.789919284082228

Epoch: 5| Step: 4
Training loss: 6.781167030334473
Validation loss: 5.783932326942362

Epoch: 5| Step: 5
Training loss: 4.9502363204956055
Validation loss: 5.77971202070995

Epoch: 5| Step: 6
Training loss: 4.176893711090088
Validation loss: 5.773037454133393

Epoch: 5| Step: 7
Training loss: 5.8929901123046875
Validation loss: 5.767287782443467

Epoch: 5| Step: 8
Training loss: 5.505976676940918
Validation loss: 5.763237194348407

Epoch: 5| Step: 9
Training loss: 5.766968727111816
Validation loss: 5.75691020616921

Epoch: 5| Step: 10
Training loss: 5.796658515930176
Validation loss: 5.751915977847192

Epoch: 2| Step: 0
Training loss: 6.27134370803833
Validation loss: 5.746723728795206

Epoch: 5| Step: 1
Training loss: 5.157101154327393
Validation loss: 5.7430023839396815

Epoch: 5| Step: 2
Training loss: 4.210585117340088
Validation loss: 5.736681794607511

Epoch: 5| Step: 3
Training loss: 5.79903507232666
Validation loss: 5.728947982993177

Epoch: 5| Step: 4
Training loss: 6.264666557312012
Validation loss: 5.722923340335969

Epoch: 5| Step: 5
Training loss: 6.143159866333008
Validation loss: 5.718968827237365

Epoch: 5| Step: 6
Training loss: 4.918644905090332
Validation loss: 5.71384197153071

Epoch: 5| Step: 7
Training loss: 4.930854797363281
Validation loss: 5.707143306732178

Epoch: 5| Step: 8
Training loss: 4.970673084259033
Validation loss: 5.70380671306323

Epoch: 5| Step: 9
Training loss: 5.806898593902588
Validation loss: 5.697004856601838

Epoch: 5| Step: 10
Training loss: 6.252979278564453
Validation loss: 5.693935891633393

Epoch: 3| Step: 0
Training loss: 5.690251350402832
Validation loss: 5.685754114581693

Epoch: 5| Step: 1
Training loss: 5.5760369300842285
Validation loss: 5.678964307231288

Epoch: 5| Step: 2
Training loss: 6.264339447021484
Validation loss: 5.675066491608979

Epoch: 5| Step: 3
Training loss: 6.257460594177246
Validation loss: 5.6702711402729

Epoch: 5| Step: 4
Training loss: 5.609879970550537
Validation loss: 5.661683959345663

Epoch: 5| Step: 5
Training loss: 4.937403202056885
Validation loss: 5.657885592470887

Epoch: 5| Step: 6
Training loss: 5.534825325012207
Validation loss: 5.654403071249685

Epoch: 5| Step: 7
Training loss: 4.754065990447998
Validation loss: 5.643521790863366

Epoch: 5| Step: 8
Training loss: 3.9527153968811035
Validation loss: 5.6386312618050525

Epoch: 5| Step: 9
Training loss: 5.680052280426025
Validation loss: 5.634637176349599

Epoch: 5| Step: 10
Training loss: 5.73157262802124
Validation loss: 5.632456964062106

Epoch: 4| Step: 0
Training loss: 5.744688510894775
Validation loss: 5.625955263773601

Epoch: 5| Step: 1
Training loss: 4.830446720123291
Validation loss: 5.617681452023086

Epoch: 5| Step: 2
Training loss: 6.100771903991699
Validation loss: 5.612318336322743

Epoch: 5| Step: 3
Training loss: 5.760120391845703
Validation loss: 5.606164855341757

Epoch: 5| Step: 4
Training loss: 4.8081512451171875
Validation loss: 5.60037475503901

Epoch: 5| Step: 5
Training loss: 4.913795471191406
Validation loss: 5.5928566020022155

Epoch: 5| Step: 6
Training loss: 5.605057239532471
Validation loss: 5.590244723904517

Epoch: 5| Step: 7
Training loss: 4.279526710510254
Validation loss: 5.582587729218186

Epoch: 5| Step: 8
Training loss: 6.624711036682129
Validation loss: 5.57501535518195

Epoch: 5| Step: 9
Training loss: 6.006580352783203
Validation loss: 5.571340807022587

Epoch: 5| Step: 10
Training loss: 4.418435573577881
Validation loss: 5.56601833528088

Epoch: 5| Step: 0
Training loss: 5.282158851623535
Validation loss: 5.55992514600036

Epoch: 5| Step: 1
Training loss: 4.964954376220703
Validation loss: 5.552642904302125

Epoch: 5| Step: 2
Training loss: 6.391955375671387
Validation loss: 5.549956362734559

Epoch: 5| Step: 3
Training loss: 4.380218982696533
Validation loss: 5.544323639203143

Epoch: 5| Step: 4
Training loss: 5.321609020233154
Validation loss: 5.536046551119897

Epoch: 5| Step: 5
Training loss: 6.461157321929932
Validation loss: 5.53177700760544

Epoch: 5| Step: 6
Training loss: 6.597006320953369
Validation loss: 5.5255378856453845

Epoch: 5| Step: 7
Training loss: 5.70795202255249
Validation loss: 5.516380238276656

Epoch: 5| Step: 8
Training loss: 3.7725205421447754
Validation loss: 5.512872131921911

Epoch: 5| Step: 9
Training loss: 5.331219673156738
Validation loss: 5.506132669346307

Epoch: 5| Step: 10
Training loss: 4.090620994567871
Validation loss: 5.500425046490085

Epoch: 6| Step: 0
Training loss: 5.06047248840332
Validation loss: 5.493661331874068

Epoch: 5| Step: 1
Training loss: 5.194415092468262
Validation loss: 5.487352704489103

Epoch: 5| Step: 2
Training loss: 6.2576398849487305
Validation loss: 5.479732800555485

Epoch: 5| Step: 3
Training loss: 5.106404781341553
Validation loss: 5.47262744493382

Epoch: 5| Step: 4
Training loss: 6.276346206665039
Validation loss: 5.467962746979088

Epoch: 5| Step: 5
Training loss: 5.476102828979492
Validation loss: 5.459701158667124

Epoch: 5| Step: 6
Training loss: 5.268160343170166
Validation loss: 5.453094113257624

Epoch: 5| Step: 7
Training loss: 5.325743198394775
Validation loss: 5.447358382645474

Epoch: 5| Step: 8
Training loss: 4.661798000335693
Validation loss: 5.443465140558058

Epoch: 5| Step: 9
Training loss: 4.638794898986816
Validation loss: 5.434893423511136

Epoch: 5| Step: 10
Training loss: 4.286828517913818
Validation loss: 5.428279784417922

Epoch: 7| Step: 0
Training loss: 5.157557487487793
Validation loss: 5.4174495461166545

Epoch: 5| Step: 1
Training loss: 6.014423370361328
Validation loss: 5.41324189401442

Epoch: 5| Step: 2
Training loss: 4.850296974182129
Validation loss: 5.404328858980569

Epoch: 5| Step: 3
Training loss: 5.768041133880615
Validation loss: 5.399555196044266

Epoch: 5| Step: 4
Training loss: 4.812315940856934
Validation loss: 5.390220016561528

Epoch: 5| Step: 5
Training loss: 4.979437351226807
Validation loss: 5.382913671514039

Epoch: 5| Step: 6
Training loss: 4.1673078536987305
Validation loss: 5.375983756075623

Epoch: 5| Step: 7
Training loss: 5.0595831871032715
Validation loss: 5.370025460438062

Epoch: 5| Step: 8
Training loss: 4.968670845031738
Validation loss: 5.35966278917046

Epoch: 5| Step: 9
Training loss: 4.755630016326904
Validation loss: 5.354659936761343

Epoch: 5| Step: 10
Training loss: 6.49628210067749
Validation loss: 5.343164500369821

Epoch: 8| Step: 0
Training loss: 4.7305402755737305
Validation loss: 5.3358721681820445

Epoch: 5| Step: 1
Training loss: 3.993445873260498
Validation loss: 5.327381144287766

Epoch: 5| Step: 2
Training loss: 5.429289817810059
Validation loss: 5.318643246927569

Epoch: 5| Step: 3
Training loss: 5.456671714782715
Validation loss: 5.310474836698142

Epoch: 5| Step: 4
Training loss: 5.928702354431152
Validation loss: 5.302578726122456

Epoch: 5| Step: 5
Training loss: 5.317395210266113
Validation loss: 5.2965571034339165

Epoch: 5| Step: 6
Training loss: 4.729559421539307
Validation loss: 5.290272487107144

Epoch: 5| Step: 7
Training loss: 4.541071891784668
Validation loss: 5.277272973009335

Epoch: 5| Step: 8
Training loss: 4.175640106201172
Validation loss: 5.269140202512023

Epoch: 5| Step: 9
Training loss: 5.584146976470947
Validation loss: 5.262633446724184

Epoch: 5| Step: 10
Training loss: 6.116661071777344
Validation loss: 5.252097929677656

Epoch: 9| Step: 0
Training loss: 4.901883125305176
Validation loss: 5.241899213483257

Epoch: 5| Step: 1
Training loss: 4.85445499420166
Validation loss: 5.238485187612554

Epoch: 5| Step: 2
Training loss: 4.705930233001709
Validation loss: 5.223690366232267

Epoch: 5| Step: 3
Training loss: 4.638344764709473
Validation loss: 5.213939220674576

Epoch: 5| Step: 4
Training loss: 5.132083415985107
Validation loss: 5.205942415422009

Epoch: 5| Step: 5
Training loss: 5.617739677429199
Validation loss: 5.194739659627278

Epoch: 5| Step: 6
Training loss: 4.997796058654785
Validation loss: 5.184652225945586

Epoch: 5| Step: 7
Training loss: 4.961514949798584
Validation loss: 5.180102327818512

Epoch: 5| Step: 8
Training loss: 4.221124172210693
Validation loss: 5.167166668881652

Epoch: 5| Step: 9
Training loss: 5.189397811889648
Validation loss: 5.16089044591432

Epoch: 5| Step: 10
Training loss: 5.5870137214660645
Validation loss: 5.145377284737044

Epoch: 10| Step: 0
Training loss: 4.796085357666016
Validation loss: 5.135466478204214

Epoch: 5| Step: 1
Training loss: 4.927180290222168
Validation loss: 5.127678168717251

Epoch: 5| Step: 2
Training loss: 5.28670597076416
Validation loss: 5.116436312275548

Epoch: 5| Step: 3
Training loss: 5.850356101989746
Validation loss: 5.112026188963203

Epoch: 5| Step: 4
Training loss: 4.438837051391602
Validation loss: 5.092887786126906

Epoch: 5| Step: 5
Training loss: 4.78183650970459
Validation loss: 5.087918953229022

Epoch: 5| Step: 6
Training loss: 4.729147434234619
Validation loss: 5.0743888270470405

Epoch: 5| Step: 7
Training loss: 4.378218650817871
Validation loss: 5.059520300998483

Epoch: 5| Step: 8
Training loss: 5.577272891998291
Validation loss: 5.045902775179956

Epoch: 5| Step: 9
Training loss: 5.2342376708984375
Validation loss: 5.042908289099253

Epoch: 5| Step: 10
Training loss: 3.191596508026123
Validation loss: 5.022511892421271

Epoch: 11| Step: 0
Training loss: 4.205347061157227
Validation loss: 5.015625799855878

Epoch: 5| Step: 1
Training loss: 5.181898593902588
Validation loss: 5.0061858700167745

Epoch: 5| Step: 2
Training loss: 5.950727462768555
Validation loss: 4.990655324792349

Epoch: 5| Step: 3
Training loss: 5.421358585357666
Validation loss: 4.985795369712255

Epoch: 5| Step: 4
Training loss: 5.3085174560546875
Validation loss: 4.970578870465679

Epoch: 5| Step: 5
Training loss: 3.9895408153533936
Validation loss: 4.95976439855432

Epoch: 5| Step: 6
Training loss: 4.374683856964111
Validation loss: 4.946611209582257

Epoch: 5| Step: 7
Training loss: 4.044533729553223
Validation loss: 4.937993700786303

Epoch: 5| Step: 8
Training loss: 4.349462032318115
Validation loss: 4.922832586432016

Epoch: 5| Step: 9
Training loss: 3.434462308883667
Validation loss: 4.907103220621745

Epoch: 5| Step: 10
Training loss: 6.0079240798950195
Validation loss: 4.8961623868634625

Epoch: 12| Step: 0
Training loss: 3.9177136421203613
Validation loss: 4.8823752018713185

Epoch: 5| Step: 1
Training loss: 4.8524980545043945
Validation loss: 4.87076348130421

Epoch: 5| Step: 2
Training loss: 5.0835185050964355
Validation loss: 4.856830750742266

Epoch: 5| Step: 3
Training loss: 5.005212306976318
Validation loss: 4.844612101072906

Epoch: 5| Step: 4
Training loss: 3.949848175048828
Validation loss: 4.828696056078839

Epoch: 5| Step: 5
Training loss: 3.1992058753967285
Validation loss: 4.818227388525522

Epoch: 5| Step: 6
Training loss: 4.679730415344238
Validation loss: 4.801764031892182

Epoch: 5| Step: 7
Training loss: 5.6101179122924805
Validation loss: 4.788850948374758

Epoch: 5| Step: 8
Training loss: 4.656342029571533
Validation loss: 4.77303191666962

Epoch: 5| Step: 9
Training loss: 4.810555458068848
Validation loss: 4.758053143819173

Epoch: 5| Step: 10
Training loss: 4.760619163513184
Validation loss: 4.742260189466579

Epoch: 13| Step: 0
Training loss: 4.070234775543213
Validation loss: 4.736610402343094

Epoch: 5| Step: 1
Training loss: 4.337366580963135
Validation loss: 4.715112814339259

Epoch: 5| Step: 2
Training loss: 3.715740919113159
Validation loss: 4.702852643946166

Epoch: 5| Step: 3
Training loss: 4.758038520812988
Validation loss: 4.684081282666934

Epoch: 5| Step: 4
Training loss: 4.345832824707031
Validation loss: 4.67143621752339

Epoch: 5| Step: 5
Training loss: 4.271485805511475
Validation loss: 4.654161135355632

Epoch: 5| Step: 6
Training loss: 5.36682653427124
Validation loss: 4.640742081467823

Epoch: 5| Step: 7
Training loss: 4.659157752990723
Validation loss: 4.616707735164191

Epoch: 5| Step: 8
Training loss: 3.555985689163208
Validation loss: 4.611921479625087

Epoch: 5| Step: 9
Training loss: 4.990518569946289
Validation loss: 4.591875676185854

Epoch: 5| Step: 10
Training loss: 4.583614826202393
Validation loss: 4.576723211555071

Epoch: 14| Step: 0
Training loss: 4.7299699783325195
Validation loss: 4.556290493216566

Epoch: 5| Step: 1
Training loss: 4.699915409088135
Validation loss: 4.540296564819992

Epoch: 5| Step: 2
Training loss: 4.95975923538208
Validation loss: 4.522158971396825

Epoch: 5| Step: 3
Training loss: 4.629342555999756
Validation loss: 4.507449790995608

Epoch: 5| Step: 4
Training loss: 3.9539616107940674
Validation loss: 4.492514676945184

Epoch: 5| Step: 5
Training loss: 4.293089389801025
Validation loss: 4.465468734823247

Epoch: 5| Step: 6
Training loss: 4.5425567626953125
Validation loss: 4.453919497869348

Epoch: 5| Step: 7
Training loss: 3.3372673988342285
Validation loss: 4.437056315842495

Epoch: 5| Step: 8
Training loss: 3.8023629188537598
Validation loss: 4.416350697958341

Epoch: 5| Step: 9
Training loss: 3.5703399181365967
Validation loss: 4.400522960129605

Epoch: 5| Step: 10
Training loss: 4.075502395629883
Validation loss: 4.3821849207724295

Epoch: 15| Step: 0
Training loss: 3.979485273361206
Validation loss: 4.360832598901564

Epoch: 5| Step: 1
Training loss: 3.870983839035034
Validation loss: 4.346477811054517

Epoch: 5| Step: 2
Training loss: 3.905628204345703
Validation loss: 4.325577712828113

Epoch: 5| Step: 3
Training loss: 4.46195650100708
Validation loss: 4.314137525455926

Epoch: 5| Step: 4
Training loss: 3.773672580718994
Validation loss: 4.2908489165767545

Epoch: 5| Step: 5
Training loss: 4.354753494262695
Validation loss: 4.268514487051195

Epoch: 5| Step: 6
Training loss: 4.114283561706543
Validation loss: 4.252711644736669

Epoch: 5| Step: 7
Training loss: 4.114384651184082
Validation loss: 4.2296808611962105

Epoch: 5| Step: 8
Training loss: 3.919034481048584
Validation loss: 4.213212228590442

Epoch: 5| Step: 9
Training loss: 3.546604633331299
Validation loss: 4.183341944089499

Epoch: 5| Step: 10
Training loss: 4.540705680847168
Validation loss: 4.174184845339868

Epoch: 16| Step: 0
Training loss: 3.7155418395996094
Validation loss: 4.15977281652471

Epoch: 5| Step: 1
Training loss: 3.728853940963745
Validation loss: 4.130226350599719

Epoch: 5| Step: 2
Training loss: 3.647418260574341
Validation loss: 4.106671264094691

Epoch: 5| Step: 3
Training loss: 3.482292652130127
Validation loss: 4.100756932330388

Epoch: 5| Step: 4
Training loss: 3.401172637939453
Validation loss: 4.076625311246482

Epoch: 5| Step: 5
Training loss: 3.86875581741333
Validation loss: 4.049839768358456

Epoch: 5| Step: 6
Training loss: 3.235508680343628
Validation loss: 4.02967514786669

Epoch: 5| Step: 7
Training loss: 4.793722629547119
Validation loss: 4.005915831494075

Epoch: 5| Step: 8
Training loss: 4.800360679626465
Validation loss: 3.99553576079748

Epoch: 5| Step: 9
Training loss: 3.8950748443603516
Validation loss: 3.9704812060120287

Epoch: 5| Step: 10
Training loss: 3.809356212615967
Validation loss: 3.9581055641174316

Epoch: 17| Step: 0
Training loss: 4.30844783782959
Validation loss: 3.9309434762565036

Epoch: 5| Step: 1
Training loss: 3.255748748779297
Validation loss: 3.9120485192985943

Epoch: 5| Step: 2
Training loss: 3.165165424346924
Validation loss: 3.8832562995213333

Epoch: 5| Step: 3
Training loss: 3.533087968826294
Validation loss: 3.8741364299610095

Epoch: 5| Step: 4
Training loss: 3.4518799781799316
Validation loss: 3.8446355686392835

Epoch: 5| Step: 5
Training loss: 3.651715040206909
Validation loss: 3.828681553563764

Epoch: 5| Step: 6
Training loss: 3.5902152061462402
Validation loss: 3.806161126782817

Epoch: 5| Step: 7
Training loss: 3.3564181327819824
Validation loss: 3.788752786574825

Epoch: 5| Step: 8
Training loss: 4.7015910148620605
Validation loss: 3.76810642468032

Epoch: 5| Step: 9
Training loss: 3.41666841506958
Validation loss: 3.7413693038366174

Epoch: 5| Step: 10
Training loss: 4.0436248779296875
Validation loss: 3.7186699426302345

Epoch: 18| Step: 0
Training loss: 3.3310885429382324
Validation loss: 3.7141649620507353

Epoch: 5| Step: 1
Training loss: 4.335534572601318
Validation loss: 3.686384436904743

Epoch: 5| Step: 2
Training loss: 3.1648552417755127
Validation loss: 3.6618028302346506

Epoch: 5| Step: 3
Training loss: 3.0136358737945557
Validation loss: 3.632939969339678

Epoch: 5| Step: 4
Training loss: 3.3499057292938232
Validation loss: 3.6127233915431525

Epoch: 5| Step: 5
Training loss: 3.8414559364318848
Validation loss: 3.6067173070805048

Epoch: 5| Step: 6
Training loss: 3.2592194080352783
Validation loss: 3.568230393112347

Epoch: 5| Step: 7
Training loss: 2.8070006370544434
Validation loss: 3.5589854255799325

Epoch: 5| Step: 8
Training loss: 4.150666236877441
Validation loss: 3.5339330755254275

Epoch: 5| Step: 9
Training loss: 3.456857204437256
Validation loss: 3.513244039268904

Epoch: 5| Step: 10
Training loss: 3.63079571723938
Validation loss: 3.5016994732682423

Epoch: 19| Step: 0
Training loss: 3.0142855644226074
Validation loss: 3.472531754483459

Epoch: 5| Step: 1
Training loss: 4.1668314933776855
Validation loss: 3.453815060277139

Epoch: 5| Step: 2
Training loss: 2.864745616912842
Validation loss: 3.4185166410220567

Epoch: 5| Step: 3
Training loss: 3.1328933238983154
Validation loss: 3.404173328030494

Epoch: 5| Step: 4
Training loss: 3.839031219482422
Validation loss: 3.3979303324094383

Epoch: 5| Step: 5
Training loss: 2.363377571105957
Validation loss: 3.351494430213846

Epoch: 5| Step: 6
Training loss: 3.684946060180664
Validation loss: 3.346737571941909

Epoch: 5| Step: 7
Training loss: 2.740478992462158
Validation loss: 3.3157517884367254

Epoch: 5| Step: 8
Training loss: 3.810631513595581
Validation loss: 3.3066266403403333

Epoch: 5| Step: 9
Training loss: 3.2754101753234863
Validation loss: 3.2726382388863513

Epoch: 5| Step: 10
Training loss: 3.1380481719970703
Validation loss: 3.256042565068891

Epoch: 20| Step: 0
Training loss: 3.223212480545044
Validation loss: 3.2528967908633653

Epoch: 5| Step: 1
Training loss: 3.10113263130188
Validation loss: 3.2129992797810543

Epoch: 5| Step: 2
Training loss: 3.397836208343506
Validation loss: 3.1895077869456303

Epoch: 5| Step: 3
Training loss: 2.7248761653900146
Validation loss: 3.164624798682428

Epoch: 5| Step: 4
Training loss: 3.0794429779052734
Validation loss: 3.138655242099557

Epoch: 5| Step: 5
Training loss: 2.6751067638397217
Validation loss: 3.1185402562541347

Epoch: 5| Step: 6
Training loss: 3.919447422027588
Validation loss: 3.103351475090109

Epoch: 5| Step: 7
Training loss: 3.2414824962615967
Validation loss: 3.0887019352246354

Epoch: 5| Step: 8
Training loss: 3.6205947399139404
Validation loss: 3.034571760444231

Epoch: 5| Step: 9
Training loss: 2.8254337310791016
Validation loss: 3.0205813992408013

Epoch: 5| Step: 10
Training loss: 2.2333855628967285
Validation loss: 3.016274934173912

Epoch: 21| Step: 0
Training loss: 3.0528597831726074
Validation loss: 3.0064555009206138

Epoch: 5| Step: 1
Training loss: 2.312967300415039
Validation loss: 2.969384939439835

Epoch: 5| Step: 2
Training loss: 3.6327743530273438
Validation loss: 2.9531187934260212

Epoch: 5| Step: 3
Training loss: 2.764901638031006
Validation loss: 2.923902841024501

Epoch: 5| Step: 4
Training loss: 2.4178497791290283
Validation loss: 2.9127660541124243

Epoch: 5| Step: 5
Training loss: 2.7644476890563965
Validation loss: 2.871651718693395

Epoch: 5| Step: 6
Training loss: 2.7076938152313232
Validation loss: 2.870341016400245

Epoch: 5| Step: 7
Training loss: 3.605262041091919
Validation loss: 2.869268150739772

Epoch: 5| Step: 8
Training loss: 2.942314386367798
Validation loss: 2.8357239307895785

Epoch: 5| Step: 9
Training loss: 3.7097809314727783
Validation loss: 2.8208977868480067

Epoch: 5| Step: 10
Training loss: 2.2769343852996826
Validation loss: 2.8255300701305432

Epoch: 22| Step: 0
Training loss: 2.2375378608703613
Validation loss: 2.7671614744329966

Epoch: 5| Step: 1
Training loss: 2.125005006790161
Validation loss: 2.7706465798039592

Epoch: 5| Step: 2
Training loss: 3.2113170623779297
Validation loss: 2.7563343509551017

Epoch: 5| Step: 3
Training loss: 2.8621487617492676
Validation loss: 2.729194818004485

Epoch: 5| Step: 4
Training loss: 3.052553176879883
Validation loss: 2.717501973593107

Epoch: 5| Step: 5
Training loss: 2.9760324954986572
Validation loss: 2.682971736436249

Epoch: 5| Step: 6
Training loss: 3.191977024078369
Validation loss: 2.6801532699215795

Epoch: 5| Step: 7
Training loss: 2.8359131813049316
Validation loss: 2.6683001159339823

Epoch: 5| Step: 8
Training loss: 2.748117446899414
Validation loss: 2.643655123249177

Epoch: 5| Step: 9
Training loss: 3.0324950218200684
Validation loss: 2.623453576077697

Epoch: 5| Step: 10
Training loss: 2.4080700874328613
Validation loss: 2.605204184850057

Epoch: 23| Step: 0
Training loss: 2.8964455127716064
Validation loss: 2.5782399280096895

Epoch: 5| Step: 1
Training loss: 3.1226909160614014
Validation loss: 2.576242382808398

Epoch: 5| Step: 2
Training loss: 3.0118439197540283
Validation loss: 2.557326179678722

Epoch: 5| Step: 3
Training loss: 2.406071901321411
Validation loss: 2.5363101549046014

Epoch: 5| Step: 4
Training loss: 2.806896686553955
Validation loss: 2.520406751222508

Epoch: 5| Step: 5
Training loss: 2.5560479164123535
Validation loss: 2.499839354586858

Epoch: 5| Step: 6
Training loss: 2.7706522941589355
Validation loss: 2.494816010998141

Epoch: 5| Step: 7
Training loss: 2.213702917098999
Validation loss: 2.476175046736194

Epoch: 5| Step: 8
Training loss: 2.9223732948303223
Validation loss: 2.452128853849185

Epoch: 5| Step: 9
Training loss: 2.448263168334961
Validation loss: 2.4413212678765737

Epoch: 5| Step: 10
Training loss: 2.139845132827759
Validation loss: 2.431419513558829

Epoch: 24| Step: 0
Training loss: 3.022318124771118
Validation loss: 2.4094444679957565

Epoch: 5| Step: 1
Training loss: 2.348747730255127
Validation loss: 2.3945602575937905

Epoch: 5| Step: 2
Training loss: 2.465078115463257
Validation loss: 2.3823900171505508

Epoch: 5| Step: 3
Training loss: 2.492788791656494
Validation loss: 2.375038534082392

Epoch: 5| Step: 4
Training loss: 2.5091280937194824
Validation loss: 2.324614614568731

Epoch: 5| Step: 5
Training loss: 2.4984874725341797
Validation loss: 2.336784037210608

Epoch: 5| Step: 6
Training loss: 2.71506667137146
Validation loss: 2.3346907759225495

Epoch: 5| Step: 7
Training loss: 2.0738892555236816
Validation loss: 2.3285197058031635

Epoch: 5| Step: 8
Training loss: 3.234656572341919
Validation loss: 2.3161545927806566

Epoch: 5| Step: 9
Training loss: 2.273543119430542
Validation loss: 2.2938748354552896

Epoch: 5| Step: 10
Training loss: 2.478175401687622
Validation loss: 2.2801862839729554

Epoch: 25| Step: 0
Training loss: 2.7410826683044434
Validation loss: 2.2474145312463083

Epoch: 5| Step: 1
Training loss: 3.3040931224823
Validation loss: 2.2505939788715814

Epoch: 5| Step: 2
Training loss: 2.2495505809783936
Validation loss: 2.2600189921676472

Epoch: 5| Step: 3
Training loss: 2.9824395179748535
Validation loss: 2.23407647942984

Epoch: 5| Step: 4
Training loss: 2.551494598388672
Validation loss: 2.2374866162576983

Epoch: 5| Step: 5
Training loss: 2.236114025115967
Validation loss: 2.2273637235805555

Epoch: 5| Step: 6
Training loss: 2.488858699798584
Validation loss: 2.211098071067564

Epoch: 5| Step: 7
Training loss: 2.358201265335083
Validation loss: 2.2033773724750807

Epoch: 5| Step: 8
Training loss: 2.1190292835235596
Validation loss: 2.203461911088677

Epoch: 5| Step: 9
Training loss: 2.0797362327575684
Validation loss: 2.2107003811867005

Epoch: 5| Step: 10
Training loss: 2.2948551177978516
Validation loss: 2.199347970306232

Epoch: 26| Step: 0
Training loss: 2.943398952484131
Validation loss: 2.1852505924881145

Epoch: 5| Step: 1
Training loss: 2.1420044898986816
Validation loss: 2.1956359519753406

Epoch: 5| Step: 2
Training loss: 2.249889373779297
Validation loss: 2.1960560403844362

Epoch: 5| Step: 3
Training loss: 2.466437816619873
Validation loss: 2.181181033452352

Epoch: 5| Step: 4
Training loss: 2.260267734527588
Validation loss: 2.166757038844529

Epoch: 5| Step: 5
Training loss: 2.7837085723876953
Validation loss: 2.1564146036742837

Epoch: 5| Step: 6
Training loss: 2.2077977657318115
Validation loss: 2.1658455761530067

Epoch: 5| Step: 7
Training loss: 2.5592856407165527
Validation loss: 2.1622304057562225

Epoch: 5| Step: 8
Training loss: 2.8370585441589355
Validation loss: 2.1525632771112586

Epoch: 5| Step: 9
Training loss: 2.351010799407959
Validation loss: 2.145504109321102

Epoch: 5| Step: 10
Training loss: 2.3377349376678467
Validation loss: 2.139677741194284

Epoch: 27| Step: 0
Training loss: 2.333397626876831
Validation loss: 2.1568140470853416

Epoch: 5| Step: 1
Training loss: 2.8880581855773926
Validation loss: 2.142216897779895

Epoch: 5| Step: 2
Training loss: 2.121455669403076
Validation loss: 2.165037264106094

Epoch: 5| Step: 3
Training loss: 2.5641162395477295
Validation loss: 2.1397571768811954

Epoch: 5| Step: 4
Training loss: 2.326993703842163
Validation loss: 2.164563017506753

Epoch: 5| Step: 5
Training loss: 2.3602375984191895
Validation loss: 2.156083212103895

Epoch: 5| Step: 6
Training loss: 2.597867488861084
Validation loss: 2.1492476104408182

Epoch: 5| Step: 7
Training loss: 2.4709606170654297
Validation loss: 2.169880574749362

Epoch: 5| Step: 8
Training loss: 3.0531997680664062
Validation loss: 2.155736874508601

Epoch: 5| Step: 9
Training loss: 2.233741044998169
Validation loss: 2.1382566036716586

Epoch: 5| Step: 10
Training loss: 1.906657099723816
Validation loss: 2.1378530379264586

Epoch: 28| Step: 0
Training loss: 1.9816112518310547
Validation loss: 2.135917350810061

Epoch: 5| Step: 1
Training loss: 2.800689697265625
Validation loss: 2.1423800222335325

Epoch: 5| Step: 2
Training loss: 2.6598453521728516
Validation loss: 2.1198476463235836

Epoch: 5| Step: 3
Training loss: 2.0853703022003174
Validation loss: 2.1297727579711587

Epoch: 5| Step: 4
Training loss: 3.109144687652588
Validation loss: 2.139549147698187

Epoch: 5| Step: 5
Training loss: 2.7522425651550293
Validation loss: 2.152759341783421

Epoch: 5| Step: 6
Training loss: 2.325620651245117
Validation loss: 2.130695653218095

Epoch: 5| Step: 7
Training loss: 1.975865125656128
Validation loss: 2.114223962189049

Epoch: 5| Step: 8
Training loss: 2.2838234901428223
Validation loss: 2.125022845883523

Epoch: 5| Step: 9
Training loss: 2.515065908432007
Validation loss: 2.1215448482062227

Epoch: 5| Step: 10
Training loss: 2.320284605026245
Validation loss: 2.1284255391807965

Epoch: 29| Step: 0
Training loss: 2.134101629257202
Validation loss: 2.1120408965695288

Epoch: 5| Step: 1
Training loss: 2.489258050918579
Validation loss: 2.1624027785434516

Epoch: 5| Step: 2
Training loss: 2.0212361812591553
Validation loss: 2.1344444239011375

Epoch: 5| Step: 3
Training loss: 2.6909210681915283
Validation loss: 2.12544862685665

Epoch: 5| Step: 4
Training loss: 2.8698208332061768
Validation loss: 2.1258664310619397

Epoch: 5| Step: 5
Training loss: 2.2628467082977295
Validation loss: 2.1184189755429506

Epoch: 5| Step: 6
Training loss: 2.577871084213257
Validation loss: 2.123800129018804

Epoch: 5| Step: 7
Training loss: 1.8858217000961304
Validation loss: 2.1214702180636826

Epoch: 5| Step: 8
Training loss: 2.8539879322052
Validation loss: 2.1133213581577426

Epoch: 5| Step: 9
Training loss: 2.4660305976867676
Validation loss: 2.1143456915373444

Epoch: 5| Step: 10
Training loss: 2.798085927963257
Validation loss: 2.1006244613278295

Epoch: 30| Step: 0
Training loss: 2.0314555168151855
Validation loss: 2.1287640730539956

Epoch: 5| Step: 1
Training loss: 2.670607805252075
Validation loss: 2.0796959477086223

Epoch: 5| Step: 2
Training loss: 2.2783820629119873
Validation loss: 2.0927911727659163

Epoch: 5| Step: 3
Training loss: 2.6108498573303223
Validation loss: 2.1099416158532582

Epoch: 5| Step: 4
Training loss: 3.2577030658721924
Validation loss: 2.0902732931157595

Epoch: 5| Step: 5
Training loss: 2.266476631164551
Validation loss: 2.099952786199508

Epoch: 5| Step: 6
Training loss: 2.554872512817383
Validation loss: 2.0774895221956315

Epoch: 5| Step: 7
Training loss: 2.5617172718048096
Validation loss: 2.093238740838984

Epoch: 5| Step: 8
Training loss: 1.7521272897720337
Validation loss: 2.0750930014476983

Epoch: 5| Step: 9
Training loss: 2.7818655967712402
Validation loss: 2.099437695677562

Epoch: 5| Step: 10
Training loss: 1.9959548711776733
Validation loss: 2.1118061452783565

Epoch: 31| Step: 0
Training loss: 2.39251708984375
Validation loss: 2.0895049123353857

Epoch: 5| Step: 1
Training loss: 2.945819616317749
Validation loss: 2.121753446517452

Epoch: 5| Step: 2
Training loss: 2.694546937942505
Validation loss: 2.1039218518041793

Epoch: 5| Step: 3
Training loss: 2.0165786743164062
Validation loss: 2.1126170850569204

Epoch: 5| Step: 4
Training loss: 2.478123903274536
Validation loss: 2.069143477306571

Epoch: 5| Step: 5
Training loss: 2.5780320167541504
Validation loss: 2.0668730863960842

Epoch: 5| Step: 6
Training loss: 2.4297947883605957
Validation loss: 2.092178721581736

Epoch: 5| Step: 7
Training loss: 2.6497159004211426
Validation loss: 2.097661890009398

Epoch: 5| Step: 8
Training loss: 2.100520372390747
Validation loss: 2.0784799616823912

Epoch: 5| Step: 9
Training loss: 2.246194839477539
Validation loss: 2.1151724502604496

Epoch: 5| Step: 10
Training loss: 2.417330265045166
Validation loss: 2.104593041122601

Epoch: 32| Step: 0
Training loss: 2.8027777671813965
Validation loss: 2.0938214461008706

Epoch: 5| Step: 1
Training loss: 2.6696155071258545
Validation loss: 2.1005459703424925

Epoch: 5| Step: 2
Training loss: 2.154628276824951
Validation loss: 2.065280350305701

Epoch: 5| Step: 3
Training loss: 2.1704046726226807
Validation loss: 2.1130159080669446

Epoch: 5| Step: 4
Training loss: 2.0352773666381836
Validation loss: 2.093340148207962

Epoch: 5| Step: 5
Training loss: 2.815743923187256
Validation loss: 2.0837379194075063

Epoch: 5| Step: 6
Training loss: 2.8901901245117188
Validation loss: 2.0873269701516755

Epoch: 5| Step: 7
Training loss: 2.720698833465576
Validation loss: 2.0749650104071504

Epoch: 5| Step: 8
Training loss: 2.4545681476593018
Validation loss: 2.0819302887044926

Epoch: 5| Step: 9
Training loss: 2.036263942718506
Validation loss: 2.0901151908341276

Epoch: 5| Step: 10
Training loss: 1.9263588190078735
Validation loss: 2.1008198491988646

Epoch: 33| Step: 0
Training loss: 2.7628092765808105
Validation loss: 2.092466118515179

Epoch: 5| Step: 1
Training loss: 2.1093039512634277
Validation loss: 2.092269277059904

Epoch: 5| Step: 2
Training loss: 2.398510456085205
Validation loss: 2.0973490835517965

Epoch: 5| Step: 3
Training loss: 2.5470902919769287
Validation loss: 2.075960659211682

Epoch: 5| Step: 4
Training loss: 2.3070015907287598
Validation loss: 2.102655940158393

Epoch: 5| Step: 5
Training loss: 2.8205008506774902
Validation loss: 2.1011355974340953

Epoch: 5| Step: 6
Training loss: 2.1180710792541504
Validation loss: 2.1320388047925887

Epoch: 5| Step: 7
Training loss: 2.808563709259033
Validation loss: 2.094166768494473

Epoch: 5| Step: 8
Training loss: 1.9684638977050781
Validation loss: 2.094122281638525

Epoch: 5| Step: 9
Training loss: 2.4273078441619873
Validation loss: 2.0988009181073917

Epoch: 5| Step: 10
Training loss: 2.352557420730591
Validation loss: 2.0915998951081307

Epoch: 34| Step: 0
Training loss: 2.6683602333068848
Validation loss: 2.0998508827660674

Epoch: 5| Step: 1
Training loss: 1.7922022342681885
Validation loss: 2.0812737172649753

Epoch: 5| Step: 2
Training loss: 2.6480183601379395
Validation loss: 2.091353113933276

Epoch: 5| Step: 3
Training loss: 2.5575027465820312
Validation loss: 2.1031892722652805

Epoch: 5| Step: 4
Training loss: 2.390429973602295
Validation loss: 2.082379807708084

Epoch: 5| Step: 5
Training loss: 2.8648688793182373
Validation loss: 2.1008925181563183

Epoch: 5| Step: 6
Training loss: 2.5518698692321777
Validation loss: 2.0969511885796823

Epoch: 5| Step: 7
Training loss: 2.431278944015503
Validation loss: 2.0957916744293703

Epoch: 5| Step: 8
Training loss: 2.5202229022979736
Validation loss: 2.0954743405824066

Epoch: 5| Step: 9
Training loss: 1.846107840538025
Validation loss: 2.0939546938865417

Epoch: 5| Step: 10
Training loss: 2.19187068939209
Validation loss: 2.0827263683401127

Epoch: 35| Step: 0
Training loss: 3.086411952972412
Validation loss: 2.0930843558362735

Epoch: 5| Step: 1
Training loss: 2.250887393951416
Validation loss: 2.079721448242023

Epoch: 5| Step: 2
Training loss: 2.9202587604522705
Validation loss: 2.1072742144266763

Epoch: 5| Step: 3
Training loss: 2.8423266410827637
Validation loss: 2.101112440068235

Epoch: 5| Step: 4
Training loss: 2.3691768646240234
Validation loss: 2.111913893812446

Epoch: 5| Step: 5
Training loss: 1.731663465499878
Validation loss: 2.075793855933733

Epoch: 5| Step: 6
Training loss: 1.9282869100570679
Validation loss: 2.087118523095244

Epoch: 5| Step: 7
Training loss: 1.9844119548797607
Validation loss: 2.090995816774266

Epoch: 5| Step: 8
Training loss: 1.648712396621704
Validation loss: 2.0803347249184885

Epoch: 5| Step: 9
Training loss: 2.5868489742279053
Validation loss: 2.1124000523679998

Epoch: 5| Step: 10
Training loss: 3.2454166412353516
Validation loss: 2.100075080830564

Epoch: 36| Step: 0
Training loss: 2.828739881515503
Validation loss: 2.0908780943962837

Epoch: 5| Step: 1
Training loss: 2.8746323585510254
Validation loss: 2.123694855679748

Epoch: 5| Step: 2
Training loss: 2.7609715461730957
Validation loss: 2.108080844725332

Epoch: 5| Step: 3
Training loss: 2.6308770179748535
Validation loss: 2.1297285633702434

Epoch: 5| Step: 4
Training loss: 2.2907238006591797
Validation loss: 2.1057187921257428

Epoch: 5| Step: 5
Training loss: 1.9664795398712158
Validation loss: 2.1002253152990855

Epoch: 5| Step: 6
Training loss: 1.9595266580581665
Validation loss: 2.1153283837021037

Epoch: 5| Step: 7
Training loss: 1.822169542312622
Validation loss: 2.1059692444339877

Epoch: 5| Step: 8
Training loss: 2.574570655822754
Validation loss: 2.1147329781645086

Epoch: 5| Step: 9
Training loss: 2.6758949756622314
Validation loss: 2.099980074872253

Epoch: 5| Step: 10
Training loss: 1.976616621017456
Validation loss: 2.1127314234292633

Epoch: 37| Step: 0
Training loss: 2.563730478286743
Validation loss: 2.142499654523788

Epoch: 5| Step: 1
Training loss: 2.4503438472747803
Validation loss: 2.1076590104769637

Epoch: 5| Step: 2
Training loss: 2.156378746032715
Validation loss: 2.1283736921125844

Epoch: 5| Step: 3
Training loss: 2.096379518508911
Validation loss: 2.1332580581788094

Epoch: 5| Step: 4
Training loss: 1.9381883144378662
Validation loss: 2.096213089522495

Epoch: 5| Step: 5
Training loss: 2.5395023822784424
Validation loss: 2.1036902037999963

Epoch: 5| Step: 6
Training loss: 2.1038036346435547
Validation loss: 2.106985607454854

Epoch: 5| Step: 7
Training loss: 2.269011974334717
Validation loss: 2.068359460881961

Epoch: 5| Step: 8
Training loss: 3.4745898246765137
Validation loss: 2.111444274584452

Epoch: 5| Step: 9
Training loss: 2.505067825317383
Validation loss: 2.094487379955989

Epoch: 5| Step: 10
Training loss: 2.1083288192749023
Validation loss: 2.0952900763480895

Epoch: 38| Step: 0
Training loss: 2.1000030040740967
Validation loss: 2.0785241665378695

Epoch: 5| Step: 1
Training loss: 2.8659145832061768
Validation loss: 2.1017291802231983

Epoch: 5| Step: 2
Training loss: 2.5379421710968018
Validation loss: 2.1063793833537767

Epoch: 5| Step: 3
Training loss: 2.3342907428741455
Validation loss: 2.100050260943751

Epoch: 5| Step: 4
Training loss: 1.9765300750732422
Validation loss: 2.1018287815073484

Epoch: 5| Step: 5
Training loss: 2.179927349090576
Validation loss: 2.0870414574941

Epoch: 5| Step: 6
Training loss: 2.7090868949890137
Validation loss: 2.0935147398261615

Epoch: 5| Step: 7
Training loss: 2.359562635421753
Validation loss: 2.0881042941924064

Epoch: 5| Step: 8
Training loss: 2.8726389408111572
Validation loss: 2.0844090574531147

Epoch: 5| Step: 9
Training loss: 2.130295991897583
Validation loss: 2.085506926300705

Epoch: 5| Step: 10
Training loss: 2.2511024475097656
Validation loss: 2.0862287693126227

Epoch: 39| Step: 0
Training loss: 1.855534553527832
Validation loss: 2.104491062061761

Epoch: 5| Step: 1
Training loss: 1.7053619623184204
Validation loss: 2.0769869601854714

Epoch: 5| Step: 2
Training loss: 2.7145168781280518
Validation loss: 2.0912511502542803

Epoch: 5| Step: 3
Training loss: 3.351334810256958
Validation loss: 2.105934432757798

Epoch: 5| Step: 4
Training loss: 2.890902042388916
Validation loss: 2.075856549765474

Epoch: 5| Step: 5
Training loss: 3.1193745136260986
Validation loss: 2.0962222904287358

Epoch: 5| Step: 6
Training loss: 1.7484960556030273
Validation loss: 2.098299839163339

Epoch: 5| Step: 7
Training loss: 2.902984142303467
Validation loss: 2.111534382707329

Epoch: 5| Step: 8
Training loss: 1.5771549940109253
Validation loss: 2.101854475595618

Epoch: 5| Step: 9
Training loss: 2.4081764221191406
Validation loss: 2.0959030825604676

Epoch: 5| Step: 10
Training loss: 1.9236050844192505
Validation loss: 2.0778879081049273

Epoch: 40| Step: 0
Training loss: 3.0787508487701416
Validation loss: 2.0977054629274594

Epoch: 5| Step: 1
Training loss: 2.4066176414489746
Validation loss: 2.089596129232837

Epoch: 5| Step: 2
Training loss: 2.3144497871398926
Validation loss: 2.103412699955766

Epoch: 5| Step: 3
Training loss: 2.317100763320923
Validation loss: 2.1082327135147585

Epoch: 5| Step: 4
Training loss: 2.2409205436706543
Validation loss: 2.0664177402373283

Epoch: 5| Step: 5
Training loss: 2.0901246070861816
Validation loss: 2.096615602893214

Epoch: 5| Step: 6
Training loss: 2.3764288425445557
Validation loss: 2.089884142721853

Epoch: 5| Step: 7
Training loss: 2.7755048274993896
Validation loss: 2.0733927398599605

Epoch: 5| Step: 8
Training loss: 2.6778416633605957
Validation loss: 2.105670670027374

Epoch: 5| Step: 9
Training loss: 2.1695048809051514
Validation loss: 2.0773975015968404

Epoch: 5| Step: 10
Training loss: 1.6281064748764038
Validation loss: 2.0907625357309976

Epoch: 41| Step: 0
Training loss: 2.9131433963775635
Validation loss: 2.1091376145680747

Epoch: 5| Step: 1
Training loss: 2.166003465652466
Validation loss: 2.0915375486496957

Epoch: 5| Step: 2
Training loss: 2.237351894378662
Validation loss: 2.1065192389231857

Epoch: 5| Step: 3
Training loss: 2.297168016433716
Validation loss: 2.1100920425948275

Epoch: 5| Step: 4
Training loss: 2.1152520179748535
Validation loss: 2.0611905179997927

Epoch: 5| Step: 5
Training loss: 2.244107961654663
Validation loss: 2.0838220337385773

Epoch: 5| Step: 6
Training loss: 2.6881861686706543
Validation loss: 2.0741821027571157

Epoch: 5| Step: 7
Training loss: 2.029902458190918
Validation loss: 2.09050436558262

Epoch: 5| Step: 8
Training loss: 2.1198458671569824
Validation loss: 2.0891696099312074

Epoch: 5| Step: 9
Training loss: 2.152737855911255
Validation loss: 2.092150988117341

Epoch: 5| Step: 10
Training loss: 2.9791412353515625
Validation loss: 2.1084985566395584

Epoch: 42| Step: 0
Training loss: 2.287104368209839
Validation loss: 2.091049212281422

Epoch: 5| Step: 1
Training loss: 2.172780990600586
Validation loss: 2.0815346920362083

Epoch: 5| Step: 2
Training loss: 2.4428462982177734
Validation loss: 2.091580502448543

Epoch: 5| Step: 3
Training loss: 2.4520087242126465
Validation loss: 2.0854842842266126

Epoch: 5| Step: 4
Training loss: 2.1653354167938232
Validation loss: 2.105953385753016

Epoch: 5| Step: 5
Training loss: 2.594881534576416
Validation loss: 2.1001428557980444

Epoch: 5| Step: 6
Training loss: 1.8906638622283936
Validation loss: 2.100020326593871

Epoch: 5| Step: 7
Training loss: 1.9393436908721924
Validation loss: 2.091113923698343

Epoch: 5| Step: 8
Training loss: 3.202442169189453
Validation loss: 2.0932119636125464

Epoch: 5| Step: 9
Training loss: 2.2530012130737305
Validation loss: 2.1144012366571734

Epoch: 5| Step: 10
Training loss: 2.5790293216705322
Validation loss: 2.0831349639482397

Epoch: 43| Step: 0
Training loss: 2.3366429805755615
Validation loss: 2.081878621091125

Epoch: 5| Step: 1
Training loss: 2.3305842876434326
Validation loss: 2.0871486356181483

Epoch: 5| Step: 2
Training loss: 1.8083785772323608
Validation loss: 2.1057186152345393

Epoch: 5| Step: 3
Training loss: 2.3847835063934326
Validation loss: 2.1208966162896927

Epoch: 5| Step: 4
Training loss: 2.004335880279541
Validation loss: 2.0983862248800134

Epoch: 5| Step: 5
Training loss: 2.6655893325805664
Validation loss: 2.0836848853736796

Epoch: 5| Step: 6
Training loss: 2.6573586463928223
Validation loss: 2.079039869769927

Epoch: 5| Step: 7
Training loss: 2.2646262645721436
Validation loss: 2.0992366959971767

Epoch: 5| Step: 8
Training loss: 2.5251059532165527
Validation loss: 2.091475545719106

Epoch: 5| Step: 9
Training loss: 2.707359552383423
Validation loss: 2.097082584134994

Epoch: 5| Step: 10
Training loss: 2.091376781463623
Validation loss: 2.095851121410247

Epoch: 44| Step: 0
Training loss: 2.2308096885681152
Validation loss: 2.0841285387674966

Epoch: 5| Step: 1
Training loss: 2.281977653503418
Validation loss: 2.075198778542139

Epoch: 5| Step: 2
Training loss: 2.3820600509643555
Validation loss: 2.085431601411553

Epoch: 5| Step: 3
Training loss: 2.5418753623962402
Validation loss: 2.0716711282730103

Epoch: 5| Step: 4
Training loss: 2.4518802165985107
Validation loss: 2.0709536357592513

Epoch: 5| Step: 5
Training loss: 1.7600723505020142
Validation loss: 2.083546656434254

Epoch: 5| Step: 6
Training loss: 2.0783138275146484
Validation loss: 2.074948157033613

Epoch: 5| Step: 7
Training loss: 2.7432796955108643
Validation loss: 2.0584272953771774

Epoch: 5| Step: 8
Training loss: 2.1783196926116943
Validation loss: 2.033622500716999

Epoch: 5| Step: 9
Training loss: 2.343902111053467
Validation loss: 2.0950816613371654

Epoch: 5| Step: 10
Training loss: 3.1806252002716064
Validation loss: 2.0763032949098976

Epoch: 45| Step: 0
Training loss: 2.3100857734680176
Validation loss: 2.050387869599045

Epoch: 5| Step: 1
Training loss: 2.2939059734344482
Validation loss: 2.0828393569556614

Epoch: 5| Step: 2
Training loss: 3.094273328781128
Validation loss: 2.053936021302336

Epoch: 5| Step: 3
Training loss: 2.3777565956115723
Validation loss: 2.054011317991441

Epoch: 5| Step: 4
Training loss: 2.7830629348754883
Validation loss: 2.064040759558319

Epoch: 5| Step: 5
Training loss: 2.864190101623535
Validation loss: 2.081649798218922

Epoch: 5| Step: 6
Training loss: 2.010228157043457
Validation loss: 2.079781146459682

Epoch: 5| Step: 7
Training loss: 2.0014331340789795
Validation loss: 2.0718026545739945

Epoch: 5| Step: 8
Training loss: 2.2729029655456543
Validation loss: 2.0702254592731433

Epoch: 5| Step: 9
Training loss: 2.1599838733673096
Validation loss: 2.065608573216264

Epoch: 5| Step: 10
Training loss: 1.826195478439331
Validation loss: 2.0849296354478404

Epoch: 46| Step: 0
Training loss: 2.615476131439209
Validation loss: 2.0676731986384236

Epoch: 5| Step: 1
Training loss: 2.4531407356262207
Validation loss: 2.0895977994447112

Epoch: 5| Step: 2
Training loss: 2.524310350418091
Validation loss: 2.067828029714605

Epoch: 5| Step: 3
Training loss: 1.776618242263794
Validation loss: 2.059143881643972

Epoch: 5| Step: 4
Training loss: 2.25144624710083
Validation loss: 2.03657272554213

Epoch: 5| Step: 5
Training loss: 2.3401846885681152
Validation loss: 2.0752631707858016

Epoch: 5| Step: 6
Training loss: 2.6268627643585205
Validation loss: 2.0832142932440645

Epoch: 5| Step: 7
Training loss: 2.5413410663604736
Validation loss: 2.077784472896207

Epoch: 5| Step: 8
Training loss: 2.644782543182373
Validation loss: 2.0899419733273086

Epoch: 5| Step: 9
Training loss: 2.33894944190979
Validation loss: 2.07282575227881

Epoch: 5| Step: 10
Training loss: 1.718720555305481
Validation loss: 2.0832471539897304

Epoch: 47| Step: 0
Training loss: 2.112020254135132
Validation loss: 2.072077324313502

Epoch: 5| Step: 1
Training loss: 2.889749050140381
Validation loss: 2.066810466909921

Epoch: 5| Step: 2
Training loss: 2.3826351165771484
Validation loss: 2.0671988584661998

Epoch: 5| Step: 3
Training loss: 2.645131826400757
Validation loss: 2.0714123966873332

Epoch: 5| Step: 4
Training loss: 1.8034290075302124
Validation loss: 2.054518847055333

Epoch: 5| Step: 5
Training loss: 2.4590630531311035
Validation loss: 2.0696056222402923

Epoch: 5| Step: 6
Training loss: 2.5274500846862793
Validation loss: 2.0768396700582197

Epoch: 5| Step: 7
Training loss: 2.0753297805786133
Validation loss: 2.0752006602543656

Epoch: 5| Step: 8
Training loss: 2.2108118534088135
Validation loss: 2.077406411529869

Epoch: 5| Step: 9
Training loss: 2.666752576828003
Validation loss: 2.0712984633702103

Epoch: 5| Step: 10
Training loss: 2.3464314937591553
Validation loss: 2.0738995344408098

Epoch: 48| Step: 0
Training loss: 3.403723955154419
Validation loss: 2.0634782903937885

Epoch: 5| Step: 1
Training loss: 2.2033019065856934
Validation loss: 2.088295054692094

Epoch: 5| Step: 2
Training loss: 2.225625514984131
Validation loss: 2.079249123091339

Epoch: 5| Step: 3
Training loss: 1.7228853702545166
Validation loss: 2.0767109342800674

Epoch: 5| Step: 4
Training loss: 2.3426926136016846
Validation loss: 2.058020878863591

Epoch: 5| Step: 5
Training loss: 2.301619052886963
Validation loss: 2.05294051477986

Epoch: 5| Step: 6
Training loss: 2.3996033668518066
Validation loss: 2.098389051293814

Epoch: 5| Step: 7
Training loss: 1.924054741859436
Validation loss: 2.082215460397864

Epoch: 5| Step: 8
Training loss: 2.7697558403015137
Validation loss: 2.0410519415332424

Epoch: 5| Step: 9
Training loss: 2.178960084915161
Validation loss: 2.0729229834771927

Epoch: 5| Step: 10
Training loss: 2.322896957397461
Validation loss: 2.0649049243619366

Epoch: 49| Step: 0
Training loss: 2.4327425956726074
Validation loss: 2.068305900019984

Epoch: 5| Step: 1
Training loss: 2.05936336517334
Validation loss: 2.071700685767717

Epoch: 5| Step: 2
Training loss: 1.6728616952896118
Validation loss: 2.080914778094138

Epoch: 5| Step: 3
Training loss: 2.535498857498169
Validation loss: 2.074460901239867

Epoch: 5| Step: 4
Training loss: 2.1101207733154297
Validation loss: 2.059171968890775

Epoch: 5| Step: 5
Training loss: 3.123599052429199
Validation loss: 2.0684060499232304

Epoch: 5| Step: 6
Training loss: 2.3400301933288574
Validation loss: 2.0510698851718696

Epoch: 5| Step: 7
Training loss: 1.9433876276016235
Validation loss: 2.0590182658164733

Epoch: 5| Step: 8
Training loss: 2.2913291454315186
Validation loss: 2.067873938109285

Epoch: 5| Step: 9
Training loss: 2.648862600326538
Validation loss: 2.0658969186967417

Epoch: 5| Step: 10
Training loss: 2.5659615993499756
Validation loss: 2.0595472999798354

Epoch: 50| Step: 0
Training loss: 2.4523041248321533
Validation loss: 2.060353458568614

Epoch: 5| Step: 1
Training loss: 2.676215648651123
Validation loss: 2.0545390011161886

Epoch: 5| Step: 2
Training loss: 2.5893616676330566
Validation loss: 2.0779590299052577

Epoch: 5| Step: 3
Training loss: 2.6673364639282227
Validation loss: 2.0413809412269184

Epoch: 5| Step: 4
Training loss: 2.5485260486602783
Validation loss: 2.045360251139569

Epoch: 5| Step: 5
Training loss: 2.3018784523010254
Validation loss: 2.056915457530688

Epoch: 5| Step: 6
Training loss: 2.3797755241394043
Validation loss: 2.0468359634440434

Epoch: 5| Step: 7
Training loss: 2.0228941440582275
Validation loss: 2.063310862869345

Epoch: 5| Step: 8
Training loss: 2.0072169303894043
Validation loss: 2.0434843199227446

Epoch: 5| Step: 9
Training loss: 1.980648398399353
Validation loss: 2.0424425986505326

Epoch: 5| Step: 10
Training loss: 1.8471899032592773
Validation loss: 2.0671741859887236

Testing loss: 2.136564122305976
